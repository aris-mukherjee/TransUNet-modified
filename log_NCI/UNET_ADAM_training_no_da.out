2021-11-30 13:28:25,932 Logging directory: /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/TransUNet/log_dir/trRUNMC_cv1_no_da_r3/i2i2l/
2021-11-30 13:28:25,933 Tensorboard directory: /scratch_net/biwidl217_second/arismu/Tensorboard/trRUNMC_cv1_no_da_r3/i2i2l/
2021-11-30 13:28:25,933 ============================================================
2021-11-30 13:28:25,933 EXPERIMENT NAME: trRUNMC_cv1_no_da_r3/i2i2l/
2021-11-30 13:28:25,933 ============================================================
2021-11-30 13:28:25,933 Loading data...
2021-11-30 13:28:25,933 Reading NCI - RUNMC images...
2021-11-30 13:28:25,933 Data root directory: /itet-stor/arismu/bmicdatasets-originals/Originals/Challenge_Datasets/NCI_Prostate/
2021-11-30 13:28:25,934 Already preprocessed this configuration. Loading now!
2021-11-30 13:28:25,954 Training Images: (256, 256, 286)
2021-11-30 13:28:25,954 Training Labels: (256, 256, 286)
2021-11-30 13:28:25,954 Validation Images: (256, 256, 98)
2021-11-30 13:28:25,954 Validation Labels: (256, 256, 98)
2021-11-30 13:28:25,954 ============================================================
2021-11-30 13:28:26,005 17 iterations per epoch. 6800 max iterations 
  0%|                                         | 0/400 [00:00<?, ?it/s]2021-11-30 13:28:28,472 iteration 1 : loss : 1.062712, loss_ce: 1.355345
2021-11-30 13:28:29,672 iteration 2 : loss : 1.023057, loss_ce: 1.291629
2021-11-30 13:28:30,875 iteration 3 : loss : 0.941525, loss_ce: 1.159394
2021-11-30 13:28:32,069 iteration 4 : loss : 0.854546, loss_ce: 1.007761
2021-11-30 13:28:33,273 iteration 5 : loss : 0.762861, loss_ce: 0.858656
2021-11-30 13:28:34,476 iteration 6 : loss : 0.750863, loss_ce: 0.831527
2021-11-30 13:28:35,680 iteration 7 : loss : 0.698264, loss_ce: 0.752782
2021-11-30 13:28:36,896 iteration 8 : loss : 0.661350, loss_ce: 0.665106
2021-11-30 13:28:38,107 iteration 9 : loss : 0.625742, loss_ce: 0.659303
2021-11-30 13:28:39,326 iteration 10 : loss : 0.614826, loss_ce: 0.586921
2021-11-30 13:28:40,535 iteration 11 : loss : 0.638093, loss_ce: 0.666793
2021-11-30 13:28:41,744 iteration 12 : loss : 0.601290, loss_ce: 0.594073
2021-11-30 13:28:42,958 iteration 13 : loss : 0.590211, loss_ce: 0.574676
2021-11-30 13:28:44,172 iteration 14 : loss : 0.548168, loss_ce: 0.524852
2021-11-30 13:28:45,384 iteration 15 : loss : 0.522956, loss_ce: 0.492740
2021-11-30 13:28:46,597 iteration 16 : loss : 0.529126, loss_ce: 0.493058
2021-11-30 13:28:47,804 iteration 17 : loss : 0.512676, loss_ce: 0.482427
  0%|                               | 1/400 [00:21<2:25:31, 21.88s/it]2021-11-30 13:28:49,105 iteration 18 : loss : 0.530219, loss_ce: 0.482246
2021-11-30 13:28:50,313 iteration 19 : loss : 0.486829, loss_ce: 0.439470
2021-11-30 13:28:51,530 iteration 20 : loss : 0.507615, loss_ce: 0.453607
2021-11-30 13:28:52,739 iteration 21 : loss : 0.476960, loss_ce: 0.426936
2021-11-30 13:28:53,944 iteration 22 : loss : 0.454802, loss_ce: 0.416720
2021-11-30 13:28:55,158 iteration 23 : loss : 0.442720, loss_ce: 0.389128
2021-11-30 13:28:56,366 iteration 24 : loss : 0.488392, loss_ce: 0.422780
2021-11-30 13:28:57,586 iteration 25 : loss : 0.448268, loss_ce: 0.372885
2021-11-30 13:28:58,806 iteration 26 : loss : 0.405895, loss_ce: 0.352928
2021-11-30 13:29:00,021 iteration 27 : loss : 0.422374, loss_ce: 0.361146
2021-11-30 13:29:01,238 iteration 28 : loss : 0.422870, loss_ce: 0.344398
2021-11-30 13:29:02,450 iteration 29 : loss : 0.421840, loss_ce: 0.346574
2021-11-30 13:29:03,675 iteration 30 : loss : 0.389837, loss_ce: 0.319410
2021-11-30 13:29:04,885 iteration 31 : loss : 0.386646, loss_ce: 0.304147
2021-11-30 13:29:06,105 iteration 32 : loss : 0.398998, loss_ce: 0.318087
2021-11-30 13:29:07,321 iteration 33 : loss : 0.380724, loss_ce: 0.293447
2021-11-30 13:29:08,540 iteration 34 : loss : 0.376185, loss_ce: 0.288680
  0%|▏                              | 2/400 [00:42<2:20:38, 21.20s/it]2021-11-30 13:29:09,837 iteration 35 : loss : 0.362255, loss_ce: 0.274789
2021-11-30 13:29:11,058 iteration 36 : loss : 0.372809, loss_ce: 0.270367
2021-11-30 13:29:12,277 iteration 37 : loss : 0.347628, loss_ce: 0.258568
2021-11-30 13:29:13,495 iteration 38 : loss : 0.335032, loss_ce: 0.248327
2021-11-30 13:29:14,713 iteration 39 : loss : 0.338149, loss_ce: 0.240367
2021-11-30 13:29:15,932 iteration 40 : loss : 0.298651, loss_ce: 0.223189
2021-11-30 13:29:17,148 iteration 41 : loss : 0.328344, loss_ce: 0.244542
2021-11-30 13:29:18,369 iteration 42 : loss : 0.297507, loss_ce: 0.219011
2021-11-30 13:29:19,587 iteration 43 : loss : 0.320821, loss_ce: 0.217312
2021-11-30 13:29:20,813 iteration 44 : loss : 0.320208, loss_ce: 0.212578
2021-11-30 13:29:22,031 iteration 45 : loss : 0.297720, loss_ce: 0.201963
2021-11-30 13:29:23,247 iteration 46 : loss : 0.327932, loss_ce: 0.221192
2021-11-30 13:29:24,469 iteration 47 : loss : 0.280114, loss_ce: 0.197147
2021-11-30 13:29:25,687 iteration 48 : loss : 0.284520, loss_ce: 0.187967
2021-11-30 13:29:26,910 iteration 49 : loss : 0.277581, loss_ce: 0.182943
2021-11-30 13:29:28,129 iteration 50 : loss : 0.268372, loss_ce: 0.186676
2021-11-30 13:29:29,349 iteration 51 : loss : 0.278304, loss_ce: 0.189597
  1%|▏                              | 3/400 [01:03<2:19:05, 21.02s/it]2021-11-30 13:29:30,650 iteration 52 : loss : 0.266752, loss_ce: 0.187790
2021-11-30 13:29:31,874 iteration 53 : loss : 0.274083, loss_ce: 0.189221
2021-11-30 13:29:33,092 iteration 54 : loss : 0.286632, loss_ce: 0.178910
2021-11-30 13:29:34,314 iteration 55 : loss : 0.227150, loss_ce: 0.155599
2021-11-30 13:29:35,536 iteration 56 : loss : 0.279661, loss_ce: 0.168962
2021-11-30 13:29:36,750 iteration 57 : loss : 0.332860, loss_ce: 0.183336
2021-11-30 13:29:37,968 iteration 58 : loss : 0.262402, loss_ce: 0.158929
2021-11-30 13:29:39,189 iteration 59 : loss : 0.266291, loss_ce: 0.161948
2021-11-30 13:29:40,407 iteration 60 : loss : 0.258014, loss_ce: 0.160189
2021-11-30 13:29:41,622 iteration 61 : loss : 0.245004, loss_ce: 0.152234
2021-11-30 13:29:42,844 iteration 62 : loss : 0.243273, loss_ce: 0.149907
2021-11-30 13:29:44,069 iteration 63 : loss : 0.263475, loss_ce: 0.167631
2021-11-30 13:29:45,288 iteration 64 : loss : 0.297049, loss_ce: 0.169177
2021-11-30 13:29:46,513 iteration 65 : loss : 0.212323, loss_ce: 0.139342
2021-11-30 13:29:47,727 iteration 66 : loss : 0.288953, loss_ce: 0.152519
2021-11-30 13:29:48,937 iteration 67 : loss : 0.248133, loss_ce: 0.146214
2021-11-30 13:29:50,153 iteration 68 : loss : 0.293609, loss_ce: 0.163046
  1%|▎                              | 4/400 [01:24<2:18:10, 20.94s/it]2021-11-30 13:29:51,442 iteration 69 : loss : 0.245359, loss_ce: 0.138591
2021-11-30 13:29:52,660 iteration 70 : loss : 0.277730, loss_ce: 0.149634
2021-11-30 13:29:53,878 iteration 71 : loss : 0.228599, loss_ce: 0.129347
2021-11-30 13:29:55,096 iteration 72 : loss : 0.230612, loss_ce: 0.130752
2021-11-30 13:29:56,312 iteration 73 : loss : 0.245596, loss_ce: 0.136608
2021-11-30 13:29:57,523 iteration 74 : loss : 0.236358, loss_ce: 0.132981
2021-11-30 13:29:58,744 iteration 75 : loss : 0.246596, loss_ce: 0.135450
2021-11-30 13:29:59,961 iteration 76 : loss : 0.231488, loss_ce: 0.125859
2021-11-30 13:30:01,175 iteration 77 : loss : 0.202788, loss_ce: 0.119634
2021-11-30 13:30:02,393 iteration 78 : loss : 0.234193, loss_ce: 0.122223
2021-11-30 13:30:03,603 iteration 79 : loss : 0.256550, loss_ce: 0.120895
2021-11-30 13:30:04,818 iteration 80 : loss : 0.221250, loss_ce: 0.121402
2021-11-30 13:30:06,033 iteration 81 : loss : 0.196394, loss_ce: 0.111313
2021-11-30 13:30:07,248 iteration 82 : loss : 0.245230, loss_ce: 0.115752
2021-11-30 13:30:08,465 iteration 83 : loss : 0.255366, loss_ce: 0.149302
2021-11-30 13:30:09,680 iteration 84 : loss : 0.167256, loss_ce: 0.097579
2021-11-30 13:30:09,681 Training Data Eval:
2021-11-30 13:30:16,551   Average segmentation loss on training set: 0.2669
2021-11-30 13:30:16,551 Validation Data Eval:
2021-11-30 13:30:18,917   Average segmentation loss on validation set: 0.2468
2021-11-30 13:30:20,872 Found new lowest validation loss at iteration 84! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/UNET_RUNMC/ADAM/ADAM_best_val_loss_no_da.pth
2021-11-30 13:30:22,101 iteration 85 : loss : 0.204939, loss_ce: 0.113264
  1%|▍                              | 5/400 [01:56<2:43:58, 24.91s/it]2021-11-30 13:30:23,395 iteration 86 : loss : 0.205093, loss_ce: 0.113503
2021-11-30 13:30:24,614 iteration 87 : loss : 0.195625, loss_ce: 0.119897
2021-11-30 13:30:25,836 iteration 88 : loss : 0.238793, loss_ce: 0.129251
2021-11-30 13:30:27,055 iteration 89 : loss : 0.180923, loss_ce: 0.107603
2021-11-30 13:30:28,275 iteration 90 : loss : 0.237057, loss_ce: 0.127165
2021-11-30 13:30:29,493 iteration 91 : loss : 0.177759, loss_ce: 0.107282
2021-11-30 13:30:30,717 iteration 92 : loss : 0.236464, loss_ce: 0.106530
2021-11-30 13:30:31,939 iteration 93 : loss : 0.216412, loss_ce: 0.096531
2021-11-30 13:30:33,162 iteration 94 : loss : 0.190750, loss_ce: 0.091767
2021-11-30 13:30:34,384 iteration 95 : loss : 0.167371, loss_ce: 0.087278
2021-11-30 13:30:35,607 iteration 96 : loss : 0.201953, loss_ce: 0.110615
2021-11-30 13:30:36,836 iteration 97 : loss : 0.204466, loss_ce: 0.113593
2021-11-30 13:30:38,059 iteration 98 : loss : 0.241895, loss_ce: 0.124419
2021-11-30 13:30:39,281 iteration 99 : loss : 0.249459, loss_ce: 0.128596
2021-11-30 13:30:40,505 iteration 100 : loss : 0.170396, loss_ce: 0.099834
2021-11-30 13:30:41,721 iteration 101 : loss : 0.193228, loss_ce: 0.096464
2021-11-30 13:30:42,945 iteration 102 : loss : 0.279513, loss_ce: 0.149865
  2%|▍                              | 6/400 [02:17<2:34:28, 23.52s/it]2021-11-30 13:30:44,233 iteration 103 : loss : 0.202463, loss_ce: 0.104995
2021-11-30 13:30:45,457 iteration 104 : loss : 0.201542, loss_ce: 0.098303
2021-11-30 13:30:46,674 iteration 105 : loss : 0.141964, loss_ce: 0.086111
2021-11-30 13:30:47,900 iteration 106 : loss : 0.162459, loss_ce: 0.092144
2021-11-30 13:30:49,116 iteration 107 : loss : 0.248690, loss_ce: 0.129697
2021-11-30 13:30:50,336 iteration 108 : loss : 0.158450, loss_ce: 0.101098
2021-11-30 13:30:51,551 iteration 109 : loss : 0.191155, loss_ce: 0.093463
2021-11-30 13:30:52,771 iteration 110 : loss : 0.203260, loss_ce: 0.095281
2021-11-30 13:30:53,993 iteration 111 : loss : 0.195647, loss_ce: 0.088186
2021-11-30 13:30:55,208 iteration 112 : loss : 0.192821, loss_ce: 0.088744
2021-11-30 13:30:56,426 iteration 113 : loss : 0.145677, loss_ce: 0.071670
2021-11-30 13:30:57,642 iteration 114 : loss : 0.236326, loss_ce: 0.125811
2021-11-30 13:30:58,862 iteration 115 : loss : 0.191016, loss_ce: 0.086871
2021-11-30 13:31:00,083 iteration 116 : loss : 0.195998, loss_ce: 0.093490
2021-11-30 13:31:01,302 iteration 117 : loss : 0.174470, loss_ce: 0.078380
2021-11-30 13:31:02,521 iteration 118 : loss : 0.149212, loss_ce: 0.084951
2021-11-30 13:31:03,738 iteration 119 : loss : 0.179044, loss_ce: 0.087847
  2%|▌                              | 7/400 [02:37<2:28:13, 22.63s/it]2021-11-30 13:31:05,019 iteration 120 : loss : 0.228044, loss_ce: 0.081052
2021-11-30 13:31:06,236 iteration 121 : loss : 0.185230, loss_ce: 0.084725
2021-11-30 13:31:07,456 iteration 122 : loss : 0.171187, loss_ce: 0.083217
2021-11-30 13:31:08,673 iteration 123 : loss : 0.204833, loss_ce: 0.105544
2021-11-30 13:31:09,888 iteration 124 : loss : 0.194019, loss_ce: 0.087160
2021-11-30 13:31:11,100 iteration 125 : loss : 0.163096, loss_ce: 0.094437
2021-11-30 13:31:12,309 iteration 126 : loss : 0.162425, loss_ce: 0.084155
2021-11-30 13:31:13,535 iteration 127 : loss : 0.254786, loss_ce: 0.098066
2021-11-30 13:31:14,750 iteration 128 : loss : 0.161077, loss_ce: 0.082051
2021-11-30 13:31:15,970 iteration 129 : loss : 0.193633, loss_ce: 0.090705
2021-11-30 13:31:17,190 iteration 130 : loss : 0.154952, loss_ce: 0.073881
2021-11-30 13:31:18,407 iteration 131 : loss : 0.195137, loss_ce: 0.095044
2021-11-30 13:31:19,621 iteration 132 : loss : 0.147855, loss_ce: 0.075641
2021-11-30 13:31:20,841 iteration 133 : loss : 0.144616, loss_ce: 0.069295
2021-11-30 13:31:22,059 iteration 134 : loss : 0.182536, loss_ce: 0.092130
2021-11-30 13:31:23,275 iteration 135 : loss : 0.133574, loss_ce: 0.078503
2021-11-30 13:31:24,495 iteration 136 : loss : 0.133980, loss_ce: 0.064036
  2%|▌                              | 8/400 [02:58<2:23:57, 22.03s/it]2021-11-30 13:31:25,776 iteration 137 : loss : 0.152070, loss_ce: 0.071859
2021-11-30 13:31:26,995 iteration 138 : loss : 0.133038, loss_ce: 0.059274
2021-11-30 13:31:28,208 iteration 139 : loss : 0.140618, loss_ce: 0.064731
2021-11-30 13:31:29,425 iteration 140 : loss : 0.143041, loss_ce: 0.071013
2021-11-30 13:31:30,648 iteration 141 : loss : 0.132810, loss_ce: 0.063209
2021-11-30 13:31:31,862 iteration 142 : loss : 0.151548, loss_ce: 0.076283
2021-11-30 13:31:33,075 iteration 143 : loss : 0.153068, loss_ce: 0.086500
2021-11-30 13:31:34,292 iteration 144 : loss : 0.182923, loss_ce: 0.070859
2021-11-30 13:31:35,513 iteration 145 : loss : 0.172909, loss_ce: 0.092914
2021-11-30 13:31:36,733 iteration 146 : loss : 0.184750, loss_ce: 0.087994
2021-11-30 13:31:37,956 iteration 147 : loss : 0.180312, loss_ce: 0.075033
2021-11-30 13:31:39,178 iteration 148 : loss : 0.152211, loss_ce: 0.083650
2021-11-30 13:31:40,390 iteration 149 : loss : 0.138017, loss_ce: 0.060362
2021-11-30 13:31:41,614 iteration 150 : loss : 0.200344, loss_ce: 0.092820
2021-11-30 13:31:42,828 iteration 151 : loss : 0.154362, loss_ce: 0.062849
2021-11-30 13:31:44,048 iteration 152 : loss : 0.138330, loss_ce: 0.068376
2021-11-30 13:31:45,269 iteration 153 : loss : 0.155552, loss_ce: 0.071196
  2%|▋                              | 9/400 [03:19<2:21:02, 21.64s/it]2021-11-30 13:31:46,558 iteration 154 : loss : 0.121333, loss_ce: 0.059010
2021-11-30 13:31:47,774 iteration 155 : loss : 0.153265, loss_ce: 0.072691
2021-11-30 13:31:48,996 iteration 156 : loss : 0.165522, loss_ce: 0.081480
2021-11-30 13:31:50,213 iteration 157 : loss : 0.168113, loss_ce: 0.072076
2021-11-30 13:31:51,434 iteration 158 : loss : 0.137787, loss_ce: 0.061960
2021-11-30 13:31:52,655 iteration 159 : loss : 0.148936, loss_ce: 0.065812
2021-11-30 13:31:53,876 iteration 160 : loss : 0.184688, loss_ce: 0.073855
2021-11-30 13:31:55,090 iteration 161 : loss : 0.154479, loss_ce: 0.057557
2021-11-30 13:31:56,315 iteration 162 : loss : 0.170681, loss_ce: 0.063610
2021-11-30 13:31:57,531 iteration 163 : loss : 0.144432, loss_ce: 0.073020
2021-11-30 13:31:58,757 iteration 164 : loss : 0.153476, loss_ce: 0.077557
2021-11-30 13:31:59,980 iteration 165 : loss : 0.184513, loss_ce: 0.090655
2021-11-30 13:32:01,204 iteration 166 : loss : 0.153095, loss_ce: 0.064781
2021-11-30 13:32:02,418 iteration 167 : loss : 0.154476, loss_ce: 0.072156
2021-11-30 13:32:03,642 iteration 168 : loss : 0.152554, loss_ce: 0.067541
2021-11-30 13:32:04,863 iteration 169 : loss : 0.133296, loss_ce: 0.067508
2021-11-30 13:32:04,863 Training Data Eval:
2021-11-30 13:32:11,751   Average segmentation loss on training set: 0.2024
2021-11-30 13:32:11,752 Validation Data Eval:
2021-11-30 13:32:14,117   Average segmentation loss on validation set: 0.2680
2021-11-30 13:32:15,338 iteration 170 : loss : 0.173769, loss_ce: 0.070279
  2%|▊                             | 10/400 [03:49<2:37:34, 24.24s/it]2021-11-30 13:32:16,622 iteration 171 : loss : 0.133315, loss_ce: 0.060398
2021-11-30 13:32:17,841 iteration 172 : loss : 0.118043, loss_ce: 0.060737
2021-11-30 13:32:19,053 iteration 173 : loss : 0.150397, loss_ce: 0.062445
2021-11-30 13:32:20,273 iteration 174 : loss : 0.122639, loss_ce: 0.057989
2021-11-30 13:32:21,486 iteration 175 : loss : 0.160005, loss_ce: 0.072198
2021-11-30 13:32:22,711 iteration 176 : loss : 0.095437, loss_ce: 0.048611
2021-11-30 13:32:23,934 iteration 177 : loss : 0.161217, loss_ce: 0.071769
2021-11-30 13:32:25,152 iteration 178 : loss : 0.129844, loss_ce: 0.062828
2021-11-30 13:32:26,367 iteration 179 : loss : 0.130863, loss_ce: 0.054111
2021-11-30 13:32:27,586 iteration 180 : loss : 0.172500, loss_ce: 0.072954
2021-11-30 13:32:28,805 iteration 181 : loss : 0.191634, loss_ce: 0.113893
2021-11-30 13:32:30,022 iteration 182 : loss : 0.180613, loss_ce: 0.067652
2021-11-30 13:32:31,239 iteration 183 : loss : 0.109836, loss_ce: 0.048069
2021-11-30 13:32:32,461 iteration 184 : loss : 0.119137, loss_ce: 0.047804
2021-11-30 13:32:33,678 iteration 185 : loss : 0.117957, loss_ce: 0.055470
2021-11-30 13:32:34,895 iteration 186 : loss : 0.108270, loss_ce: 0.045073
2021-11-30 13:32:36,116 iteration 187 : loss : 0.116897, loss_ce: 0.052402
  3%|▊                             | 11/400 [04:10<2:30:17, 23.18s/it]2021-11-30 13:32:37,407 iteration 188 : loss : 0.161228, loss_ce: 0.058488
2021-11-30 13:32:38,615 iteration 189 : loss : 0.127481, loss_ce: 0.060427
2021-11-30 13:32:39,838 iteration 190 : loss : 0.114390, loss_ce: 0.053489
2021-11-30 13:32:41,054 iteration 191 : loss : 0.093826, loss_ce: 0.046599
2021-11-30 13:32:42,267 iteration 192 : loss : 0.115518, loss_ce: 0.063270
2021-11-30 13:32:43,484 iteration 193 : loss : 0.162649, loss_ce: 0.072526
2021-11-30 13:32:44,699 iteration 194 : loss : 0.132772, loss_ce: 0.069257
2021-11-30 13:32:45,920 iteration 195 : loss : 0.123757, loss_ce: 0.050780
2021-11-30 13:32:47,140 iteration 196 : loss : 0.129396, loss_ce: 0.059348
2021-11-30 13:32:48,364 iteration 197 : loss : 0.140624, loss_ce: 0.052300
2021-11-30 13:32:49,584 iteration 198 : loss : 0.153396, loss_ce: 0.065626
2021-11-30 13:32:50,802 iteration 199 : loss : 0.153099, loss_ce: 0.074540
2021-11-30 13:32:52,020 iteration 200 : loss : 0.162212, loss_ce: 0.062755
2021-11-30 13:32:53,242 iteration 201 : loss : 0.167878, loss_ce: 0.064982
2021-11-30 13:32:54,464 iteration 202 : loss : 0.135055, loss_ce: 0.064878
2021-11-30 13:32:55,679 iteration 203 : loss : 0.114421, loss_ce: 0.048644
2021-11-30 13:32:56,897 iteration 204 : loss : 0.115982, loss_ce: 0.059735
  3%|▉                             | 12/400 [04:30<2:25:11, 22.45s/it]2021-11-30 13:32:58,185 iteration 205 : loss : 0.153857, loss_ce: 0.064442
2021-11-30 13:32:59,411 iteration 206 : loss : 0.132490, loss_ce: 0.054250
2021-11-30 13:33:00,631 iteration 207 : loss : 0.120577, loss_ce: 0.051721
2021-11-30 13:33:01,853 iteration 208 : loss : 0.176122, loss_ce: 0.063382
2021-11-30 13:33:03,078 iteration 209 : loss : 0.124387, loss_ce: 0.062462
2021-11-30 13:33:04,296 iteration 210 : loss : 0.119816, loss_ce: 0.045710
2021-11-30 13:33:05,512 iteration 211 : loss : 0.105397, loss_ce: 0.048621
2021-11-30 13:33:06,727 iteration 212 : loss : 0.102142, loss_ce: 0.046992
2021-11-30 13:33:07,952 iteration 213 : loss : 0.095696, loss_ce: 0.044179
2021-11-30 13:33:09,170 iteration 214 : loss : 0.097521, loss_ce: 0.041274
2021-11-30 13:33:10,398 iteration 215 : loss : 0.130671, loss_ce: 0.067023
2021-11-30 13:33:11,621 iteration 216 : loss : 0.150506, loss_ce: 0.078589
2021-11-30 13:33:12,839 iteration 217 : loss : 0.201571, loss_ce: 0.080432
2021-11-30 13:33:14,062 iteration 218 : loss : 0.166857, loss_ce: 0.065059
2021-11-30 13:33:15,289 iteration 219 : loss : 0.132605, loss_ce: 0.059998
2021-11-30 13:33:16,503 iteration 220 : loss : 0.160803, loss_ce: 0.068280
2021-11-30 13:33:17,716 iteration 221 : loss : 0.122923, loss_ce: 0.050147
  3%|▉                             | 13/400 [04:51<2:21:37, 21.96s/it]2021-11-30 13:33:19,005 iteration 222 : loss : 0.144589, loss_ce: 0.061555
2021-11-30 13:33:20,227 iteration 223 : loss : 0.136631, loss_ce: 0.058440
2021-11-30 13:33:21,442 iteration 224 : loss : 0.115286, loss_ce: 0.046482
2021-11-30 13:33:22,673 iteration 225 : loss : 0.131183, loss_ce: 0.046901
2021-11-30 13:33:23,897 iteration 226 : loss : 0.113852, loss_ce: 0.058716
2021-11-30 13:33:25,113 iteration 227 : loss : 0.123344, loss_ce: 0.055454
2021-11-30 13:33:26,331 iteration 228 : loss : 0.103921, loss_ce: 0.050474
2021-11-30 13:33:27,548 iteration 229 : loss : 0.103070, loss_ce: 0.041198
2021-11-30 13:33:28,773 iteration 230 : loss : 0.146950, loss_ce: 0.073656
2021-11-30 13:33:29,996 iteration 231 : loss : 0.107896, loss_ce: 0.041748
2021-11-30 13:33:31,215 iteration 232 : loss : 0.131817, loss_ce: 0.053328
2021-11-30 13:33:32,430 iteration 233 : loss : 0.131501, loss_ce: 0.058612
2021-11-30 13:33:33,649 iteration 234 : loss : 0.112970, loss_ce: 0.046796
2021-11-30 13:33:34,877 iteration 235 : loss : 0.177835, loss_ce: 0.086200
2021-11-30 13:33:36,093 iteration 236 : loss : 0.144415, loss_ce: 0.066201
2021-11-30 13:33:37,314 iteration 237 : loss : 0.119805, loss_ce: 0.044787
2021-11-30 13:33:38,536 iteration 238 : loss : 0.186604, loss_ce: 0.061518
  4%|█                             | 14/400 [05:12<2:19:02, 21.61s/it]2021-11-30 13:33:39,822 iteration 239 : loss : 0.113679, loss_ce: 0.049750
2021-11-30 13:33:41,045 iteration 240 : loss : 0.159740, loss_ce: 0.065735
2021-11-30 13:33:42,259 iteration 241 : loss : 0.134352, loss_ce: 0.064025
2021-11-30 13:33:43,481 iteration 242 : loss : 0.129139, loss_ce: 0.062247
2021-11-30 13:33:44,703 iteration 243 : loss : 0.156419, loss_ce: 0.070487
2021-11-30 13:33:45,921 iteration 244 : loss : 0.129238, loss_ce: 0.050726
2021-11-30 13:33:47,136 iteration 245 : loss : 0.130178, loss_ce: 0.057360
2021-11-30 13:33:48,352 iteration 246 : loss : 0.142370, loss_ce: 0.062900
2021-11-30 13:33:49,575 iteration 247 : loss : 0.129233, loss_ce: 0.046475
2021-11-30 13:33:50,799 iteration 248 : loss : 0.134490, loss_ce: 0.060898
2021-11-30 13:33:52,015 iteration 249 : loss : 0.109824, loss_ce: 0.048164
2021-11-30 13:33:53,235 iteration 250 : loss : 0.111367, loss_ce: 0.050193
2021-11-30 13:33:54,456 iteration 251 : loss : 0.126515, loss_ce: 0.055986
2021-11-30 13:33:55,672 iteration 252 : loss : 0.136321, loss_ce: 0.061633
2021-11-30 13:33:56,887 iteration 253 : loss : 0.102744, loss_ce: 0.053424
2021-11-30 13:33:58,107 iteration 254 : loss : 0.142986, loss_ce: 0.054137
2021-11-30 13:33:58,107 Training Data Eval:
2021-11-30 13:34:05,006   Average segmentation loss on training set: 0.3944
2021-11-30 13:34:05,007 Validation Data Eval:
2021-11-30 13:34:07,368   Average segmentation loss on validation set: 0.3405
2021-11-30 13:34:08,593 iteration 255 : loss : 0.159301, loss_ce: 0.053371
  4%|█▏                            | 15/400 [05:42<2:35:00, 24.16s/it]2021-11-30 13:34:09,883 iteration 256 : loss : 0.127708, loss_ce: 0.049381
2021-11-30 13:34:11,104 iteration 257 : loss : 0.145721, loss_ce: 0.056929
2021-11-30 13:34:12,327 iteration 258 : loss : 0.099022, loss_ce: 0.037257
2021-11-30 13:34:13,543 iteration 259 : loss : 0.131681, loss_ce: 0.041354
2021-11-30 13:34:14,769 iteration 260 : loss : 0.126487, loss_ce: 0.047838
2021-11-30 13:34:15,986 iteration 261 : loss : 0.133720, loss_ce: 0.059105
2021-11-30 13:34:17,205 iteration 262 : loss : 0.103730, loss_ce: 0.042891
2021-11-30 13:34:18,426 iteration 263 : loss : 0.117804, loss_ce: 0.054912
2021-11-30 13:34:19,634 iteration 264 : loss : 0.115472, loss_ce: 0.053727
2021-11-30 13:34:20,856 iteration 265 : loss : 0.122506, loss_ce: 0.044725
2021-11-30 13:34:22,078 iteration 266 : loss : 0.094049, loss_ce: 0.042629
2021-11-30 13:34:23,303 iteration 267 : loss : 0.116387, loss_ce: 0.049909
2021-11-30 13:34:24,526 iteration 268 : loss : 0.102204, loss_ce: 0.041413
2021-11-30 13:34:25,743 iteration 269 : loss : 0.121624, loss_ce: 0.048691
2021-11-30 13:34:26,970 iteration 270 : loss : 0.121396, loss_ce: 0.038438
2021-11-30 13:34:28,186 iteration 271 : loss : 0.151277, loss_ce: 0.067425
2021-11-30 13:34:29,401 iteration 272 : loss : 0.123962, loss_ce: 0.062322
  4%|█▏                            | 16/400 [06:03<2:28:09, 23.15s/it]2021-11-30 13:34:30,696 iteration 273 : loss : 0.069745, loss_ce: 0.030323
2021-11-30 13:34:31,908 iteration 274 : loss : 0.126571, loss_ce: 0.054058
2021-11-30 13:34:33,124 iteration 275 : loss : 0.139941, loss_ce: 0.053890
2021-11-30 13:34:34,343 iteration 276 : loss : 0.106869, loss_ce: 0.044554
2021-11-30 13:34:35,563 iteration 277 : loss : 0.119873, loss_ce: 0.049012
2021-11-30 13:34:36,784 iteration 278 : loss : 0.116480, loss_ce: 0.045418
2021-11-30 13:34:38,007 iteration 279 : loss : 0.115075, loss_ce: 0.055248
2021-11-30 13:34:39,230 iteration 280 : loss : 0.101230, loss_ce: 0.040701
2021-11-30 13:34:40,449 iteration 281 : loss : 0.161345, loss_ce: 0.049069
2021-11-30 13:34:41,670 iteration 282 : loss : 0.145257, loss_ce: 0.061580
2021-11-30 13:34:42,892 iteration 283 : loss : 0.087943, loss_ce: 0.037937
2021-11-30 13:34:44,113 iteration 284 : loss : 0.107550, loss_ce: 0.043621
2021-11-30 13:34:45,336 iteration 285 : loss : 0.106433, loss_ce: 0.054551
2021-11-30 13:34:46,546 iteration 286 : loss : 0.081228, loss_ce: 0.039174
2021-11-30 13:34:47,766 iteration 287 : loss : 0.090644, loss_ce: 0.042800
2021-11-30 13:34:48,994 iteration 288 : loss : 0.102488, loss_ce: 0.048328
2021-11-30 13:34:50,211 iteration 289 : loss : 0.117616, loss_ce: 0.058629
  4%|█▎                            | 17/400 [06:24<2:23:17, 22.45s/it]2021-11-30 13:34:51,505 iteration 290 : loss : 0.093664, loss_ce: 0.047118
2021-11-30 13:34:52,716 iteration 291 : loss : 0.111601, loss_ce: 0.052223
2021-11-30 13:34:53,936 iteration 292 : loss : 0.096553, loss_ce: 0.044683
2021-11-30 13:34:55,141 iteration 293 : loss : 0.150780, loss_ce: 0.058548
2021-11-30 13:34:56,349 iteration 294 : loss : 0.101602, loss_ce: 0.046036
2021-11-30 13:34:57,568 iteration 295 : loss : 0.093374, loss_ce: 0.034906
2021-11-30 13:34:58,789 iteration 296 : loss : 0.085224, loss_ce: 0.034356
2021-11-30 13:35:00,008 iteration 297 : loss : 0.096674, loss_ce: 0.038024
2021-11-30 13:35:01,223 iteration 298 : loss : 0.074105, loss_ce: 0.037846
2021-11-30 13:35:02,434 iteration 299 : loss : 0.103267, loss_ce: 0.041768
2021-11-30 13:35:03,653 iteration 300 : loss : 0.129782, loss_ce: 0.051386
2021-11-30 13:35:04,871 iteration 301 : loss : 0.099252, loss_ce: 0.039541
2021-11-30 13:35:06,088 iteration 302 : loss : 0.126837, loss_ce: 0.042390
2021-11-30 13:35:07,303 iteration 303 : loss : 0.122034, loss_ce: 0.056642
2021-11-30 13:35:08,520 iteration 304 : loss : 0.090370, loss_ce: 0.040749
2021-11-30 13:35:09,748 iteration 305 : loss : 0.091825, loss_ce: 0.031301
2021-11-30 13:35:10,967 iteration 306 : loss : 0.140903, loss_ce: 0.066356
  4%|█▎                            | 18/400 [06:45<2:19:40, 21.94s/it]2021-11-30 13:35:12,249 iteration 307 : loss : 0.117664, loss_ce: 0.043238
2021-11-30 13:35:13,473 iteration 308 : loss : 0.101840, loss_ce: 0.051038
2021-11-30 13:35:14,691 iteration 309 : loss : 0.112329, loss_ce: 0.055083
2021-11-30 13:35:15,914 iteration 310 : loss : 0.092514, loss_ce: 0.043060
2021-11-30 13:35:17,121 iteration 311 : loss : 0.130990, loss_ce: 0.045525
2021-11-30 13:35:18,340 iteration 312 : loss : 0.103287, loss_ce: 0.045052
2021-11-30 13:35:19,556 iteration 313 : loss : 0.143254, loss_ce: 0.055089
2021-11-30 13:35:20,776 iteration 314 : loss : 0.095759, loss_ce: 0.042943
2021-11-30 13:35:21,991 iteration 315 : loss : 0.133008, loss_ce: 0.050263
2021-11-30 13:35:23,216 iteration 316 : loss : 0.127067, loss_ce: 0.053799
2021-11-30 13:35:24,433 iteration 317 : loss : 0.104576, loss_ce: 0.043413
2021-11-30 13:35:25,651 iteration 318 : loss : 0.129947, loss_ce: 0.039726
2021-11-30 13:35:26,870 iteration 319 : loss : 0.122904, loss_ce: 0.046281
2021-11-30 13:35:28,091 iteration 320 : loss : 0.133933, loss_ce: 0.062552
2021-11-30 13:35:29,308 iteration 321 : loss : 0.112681, loss_ce: 0.043065
2021-11-30 13:35:30,523 iteration 322 : loss : 0.105345, loss_ce: 0.041690
2021-11-30 13:35:31,741 iteration 323 : loss : 0.083624, loss_ce: 0.039536
  5%|█▍                            | 19/400 [07:05<2:17:05, 21.59s/it]2021-11-30 13:35:33,024 iteration 324 : loss : 0.083225, loss_ce: 0.036004
2021-11-30 13:35:34,244 iteration 325 : loss : 0.097250, loss_ce: 0.038650
2021-11-30 13:35:35,465 iteration 326 : loss : 0.119659, loss_ce: 0.055362
2021-11-30 13:35:36,675 iteration 327 : loss : 0.141812, loss_ce: 0.061710
2021-11-30 13:35:37,895 iteration 328 : loss : 0.109059, loss_ce: 0.041602
2021-11-30 13:35:39,115 iteration 329 : loss : 0.088795, loss_ce: 0.034747
2021-11-30 13:35:40,330 iteration 330 : loss : 0.091951, loss_ce: 0.045224
2021-11-30 13:35:41,547 iteration 331 : loss : 0.110830, loss_ce: 0.041645
2021-11-30 13:35:42,766 iteration 332 : loss : 0.142642, loss_ce: 0.052835
2021-11-30 13:35:43,983 iteration 333 : loss : 0.098423, loss_ce: 0.042477
2021-11-30 13:35:45,203 iteration 334 : loss : 0.095938, loss_ce: 0.040599
2021-11-30 13:35:46,419 iteration 335 : loss : 0.100552, loss_ce: 0.047048
2021-11-30 13:35:47,639 iteration 336 : loss : 0.107417, loss_ce: 0.051125
2021-11-30 13:35:48,855 iteration 337 : loss : 0.138328, loss_ce: 0.044739
2021-11-30 13:35:50,073 iteration 338 : loss : 0.126966, loss_ce: 0.047065
2021-11-30 13:35:51,297 iteration 339 : loss : 0.106431, loss_ce: 0.056072
2021-11-30 13:35:51,297 Training Data Eval:
2021-11-30 13:35:58,202   Average segmentation loss on training set: 0.1142
2021-11-30 13:35:58,202 Validation Data Eval:
2021-11-30 13:36:00,579   Average segmentation loss on validation set: 0.1329
2021-11-30 13:36:02,811 Found new lowest validation loss at iteration 339! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/UNET_RUNMC/ADAM/ADAM_best_val_loss_no_da.pth
2021-11-30 13:36:04,025 iteration 340 : loss : 0.105847, loss_ce: 0.046257
  5%|█▌                            | 20/400 [07:38<2:37:03, 24.80s/it]2021-11-30 13:36:05,304 iteration 341 : loss : 0.081396, loss_ce: 0.035533
2021-11-30 13:36:06,523 iteration 342 : loss : 0.067188, loss_ce: 0.032972
2021-11-30 13:36:07,746 iteration 343 : loss : 0.085391, loss_ce: 0.037663
2021-11-30 13:36:08,964 iteration 344 : loss : 0.101945, loss_ce: 0.042664
2021-11-30 13:36:10,187 iteration 345 : loss : 0.103408, loss_ce: 0.042647
2021-11-30 13:36:11,401 iteration 346 : loss : 0.113691, loss_ce: 0.042359
2021-11-30 13:36:12,619 iteration 347 : loss : 0.088502, loss_ce: 0.041597
2021-11-30 13:36:13,828 iteration 348 : loss : 0.096048, loss_ce: 0.044312
2021-11-30 13:36:15,045 iteration 349 : loss : 0.086889, loss_ce: 0.033521
2021-11-30 13:36:16,260 iteration 350 : loss : 0.119348, loss_ce: 0.044776
2021-11-30 13:36:17,482 iteration 351 : loss : 0.086602, loss_ce: 0.032839
2021-11-30 13:36:18,700 iteration 352 : loss : 0.099130, loss_ce: 0.036769
2021-11-30 13:36:19,917 iteration 353 : loss : 0.106610, loss_ce: 0.050530
2021-11-30 13:36:21,129 iteration 354 : loss : 0.093111, loss_ce: 0.037121
2021-11-30 13:36:22,337 iteration 355 : loss : 0.186707, loss_ce: 0.051237
2021-11-30 13:36:23,550 iteration 356 : loss : 0.085944, loss_ce: 0.037975
2021-11-30 13:36:24,768 iteration 357 : loss : 0.089618, loss_ce: 0.044762
  5%|█▌                            | 21/400 [07:58<2:28:58, 23.58s/it]2021-11-30 13:36:26,062 iteration 358 : loss : 0.119257, loss_ce: 0.034993
2021-11-30 13:36:27,282 iteration 359 : loss : 0.134439, loss_ce: 0.049487
2021-11-30 13:36:28,505 iteration 360 : loss : 0.097109, loss_ce: 0.033067
2021-11-30 13:36:29,724 iteration 361 : loss : 0.113919, loss_ce: 0.044486
2021-11-30 13:36:30,949 iteration 362 : loss : 0.123902, loss_ce: 0.055127
2021-11-30 13:36:32,172 iteration 363 : loss : 0.089894, loss_ce: 0.033340
2021-11-30 13:36:33,404 iteration 364 : loss : 0.086803, loss_ce: 0.037555
2021-11-30 13:36:34,625 iteration 365 : loss : 0.084060, loss_ce: 0.036784
2021-11-30 13:36:35,842 iteration 366 : loss : 0.106720, loss_ce: 0.046626
2021-11-30 13:36:37,061 iteration 367 : loss : 0.106109, loss_ce: 0.044975
2021-11-30 13:36:38,283 iteration 368 : loss : 0.109444, loss_ce: 0.052072
2021-11-30 13:36:39,496 iteration 369 : loss : 0.106438, loss_ce: 0.041234
2021-11-30 13:36:40,716 iteration 370 : loss : 0.063249, loss_ce: 0.027455
2021-11-30 13:36:41,937 iteration 371 : loss : 0.085339, loss_ce: 0.039796
2021-11-30 13:36:43,156 iteration 372 : loss : 0.082005, loss_ce: 0.032993
2021-11-30 13:36:44,368 iteration 373 : loss : 0.113898, loss_ce: 0.046953
2021-11-30 13:36:45,591 iteration 374 : loss : 0.054525, loss_ce: 0.025075
  6%|█▋                            | 22/400 [08:19<2:23:20, 22.75s/it]2021-11-30 13:36:46,880 iteration 375 : loss : 0.087162, loss_ce: 0.033978
2021-11-30 13:36:48,100 iteration 376 : loss : 0.088882, loss_ce: 0.035960
2021-11-30 13:36:49,326 iteration 377 : loss : 0.101491, loss_ce: 0.036263
2021-11-30 13:36:50,548 iteration 378 : loss : 0.103049, loss_ce: 0.048842
2021-11-30 13:36:51,770 iteration 379 : loss : 0.089260, loss_ce: 0.038819
2021-11-30 13:36:52,982 iteration 380 : loss : 0.087561, loss_ce: 0.039569
2021-11-30 13:36:54,200 iteration 381 : loss : 0.069229, loss_ce: 0.032471
2021-11-30 13:36:55,428 iteration 382 : loss : 0.111693, loss_ce: 0.040951
2021-11-30 13:36:56,647 iteration 383 : loss : 0.128850, loss_ce: 0.036797
2021-11-30 13:36:57,866 iteration 384 : loss : 0.068984, loss_ce: 0.033683
2021-11-30 13:36:59,087 iteration 385 : loss : 0.084592, loss_ce: 0.033517
2021-11-30 13:37:00,317 iteration 386 : loss : 0.084565, loss_ce: 0.035939
2021-11-30 13:37:01,544 iteration 387 : loss : 0.109272, loss_ce: 0.038716
2021-11-30 13:37:02,763 iteration 388 : loss : 0.086890, loss_ce: 0.036946
2021-11-30 13:37:03,986 iteration 389 : loss : 0.120439, loss_ce: 0.041878
2021-11-30 13:37:05,208 iteration 390 : loss : 0.075356, loss_ce: 0.033291
2021-11-30 13:37:06,428 iteration 391 : loss : 0.093504, loss_ce: 0.043771
  6%|█▋                            | 23/400 [08:40<2:19:21, 22.18s/it]2021-11-30 13:37:07,718 iteration 392 : loss : 0.075236, loss_ce: 0.035911
2021-11-30 13:37:08,941 iteration 393 : loss : 0.056503, loss_ce: 0.025651
2021-11-30 13:37:10,168 iteration 394 : loss : 0.150730, loss_ce: 0.041468
2021-11-30 13:37:11,392 iteration 395 : loss : 0.069684, loss_ce: 0.032931
2021-11-30 13:37:12,617 iteration 396 : loss : 0.078913, loss_ce: 0.030533
2021-11-30 13:37:13,842 iteration 397 : loss : 0.094390, loss_ce: 0.039295
2021-11-30 13:37:15,064 iteration 398 : loss : 0.081360, loss_ce: 0.036040
2021-11-30 13:37:16,285 iteration 399 : loss : 0.057079, loss_ce: 0.026909
2021-11-30 13:37:17,503 iteration 400 : loss : 0.101588, loss_ce: 0.043285
2021-11-30 13:37:18,732 iteration 401 : loss : 0.121429, loss_ce: 0.047917
2021-11-30 13:37:19,955 iteration 402 : loss : 0.084787, loss_ce: 0.035087
2021-11-30 13:37:21,174 iteration 403 : loss : 0.075258, loss_ce: 0.035147
2021-11-30 13:37:22,399 iteration 404 : loss : 0.094045, loss_ce: 0.030199
2021-11-30 13:37:23,625 iteration 405 : loss : 0.079553, loss_ce: 0.033336
2021-11-30 13:37:24,842 iteration 406 : loss : 0.124238, loss_ce: 0.044247
2021-11-30 13:37:26,058 iteration 407 : loss : 0.066807, loss_ce: 0.031676
2021-11-30 13:37:27,277 iteration 408 : loss : 0.080439, loss_ce: 0.033195
  6%|█▊                            | 24/400 [09:01<2:16:29, 21.78s/it]2021-11-30 13:37:28,565 iteration 409 : loss : 0.095530, loss_ce: 0.044031
2021-11-30 13:37:29,784 iteration 410 : loss : 0.060950, loss_ce: 0.024473
2021-11-30 13:37:31,004 iteration 411 : loss : 0.056925, loss_ce: 0.024740
2021-11-30 13:37:32,221 iteration 412 : loss : 0.070698, loss_ce: 0.030458
2021-11-30 13:37:33,443 iteration 413 : loss : 0.073928, loss_ce: 0.030986
2021-11-30 13:37:34,670 iteration 414 : loss : 0.085566, loss_ce: 0.032809
2021-11-30 13:37:35,882 iteration 415 : loss : 0.103130, loss_ce: 0.046134
2021-11-30 13:37:37,095 iteration 416 : loss : 0.079122, loss_ce: 0.038852
2021-11-30 13:37:38,316 iteration 417 : loss : 0.102507, loss_ce: 0.033694
2021-11-30 13:37:39,543 iteration 418 : loss : 0.075697, loss_ce: 0.030374
2021-11-30 13:37:40,764 iteration 419 : loss : 0.072539, loss_ce: 0.034591
2021-11-30 13:37:41,987 iteration 420 : loss : 0.067487, loss_ce: 0.030695
2021-11-30 13:37:43,210 iteration 421 : loss : 0.077293, loss_ce: 0.033037
2021-11-30 13:37:44,428 iteration 422 : loss : 0.091093, loss_ce: 0.032063
2021-11-30 13:37:45,647 iteration 423 : loss : 0.081731, loss_ce: 0.036877
2021-11-30 13:37:46,863 iteration 424 : loss : 0.075336, loss_ce: 0.031144
2021-11-30 13:37:46,864 Training Data Eval:
2021-11-30 13:37:53,775   Average segmentation loss on training set: 0.1095
2021-11-30 13:37:53,776 Validation Data Eval:
2021-11-30 13:37:56,140   Average segmentation loss on validation set: 0.1863
2021-11-30 13:37:57,360 iteration 425 : loss : 0.085664, loss_ce: 0.034176
  6%|█▉                            | 25/400 [09:31<2:31:41, 24.27s/it]2021-11-30 13:37:58,649 iteration 426 : loss : 0.069589, loss_ce: 0.029426
2021-11-30 13:37:59,868 iteration 427 : loss : 0.060802, loss_ce: 0.030755
2021-11-30 13:38:01,079 iteration 428 : loss : 0.099806, loss_ce: 0.033384
2021-11-30 13:38:02,307 iteration 429 : loss : 0.086877, loss_ce: 0.034204
2021-11-30 13:38:03,524 iteration 430 : loss : 0.137277, loss_ce: 0.033476
2021-11-30 13:38:04,750 iteration 431 : loss : 0.084694, loss_ce: 0.036436
2021-11-30 13:38:05,968 iteration 432 : loss : 0.079942, loss_ce: 0.028593
2021-11-30 13:38:07,183 iteration 433 : loss : 0.065059, loss_ce: 0.030637
2021-11-30 13:38:08,402 iteration 434 : loss : 0.106302, loss_ce: 0.028361
2021-11-30 13:38:09,631 iteration 435 : loss : 0.060025, loss_ce: 0.026097
2021-11-30 13:38:10,852 iteration 436 : loss : 0.097717, loss_ce: 0.044300
2021-11-30 13:38:12,069 iteration 437 : loss : 0.095291, loss_ce: 0.036130
2021-11-30 13:38:13,289 iteration 438 : loss : 0.121954, loss_ce: 0.062366
2021-11-30 13:38:14,514 iteration 439 : loss : 0.106888, loss_ce: 0.041443
2021-11-30 13:38:15,738 iteration 440 : loss : 0.101485, loss_ce: 0.034401
2021-11-30 13:38:16,957 iteration 441 : loss : 0.072727, loss_ce: 0.039014
2021-11-30 13:38:18,169 iteration 442 : loss : 0.081747, loss_ce: 0.042817
  6%|█▉                            | 26/400 [09:52<2:24:49, 23.23s/it]2021-11-30 13:38:19,463 iteration 443 : loss : 0.077342, loss_ce: 0.036637
2021-11-30 13:38:20,684 iteration 444 : loss : 0.066446, loss_ce: 0.030123
2021-11-30 13:38:21,902 iteration 445 : loss : 0.102621, loss_ce: 0.038911
2021-11-30 13:38:23,121 iteration 446 : loss : 0.080542, loss_ce: 0.035412
2021-11-30 13:38:24,345 iteration 447 : loss : 0.110702, loss_ce: 0.041105
2021-11-30 13:38:25,569 iteration 448 : loss : 0.093938, loss_ce: 0.035712
2021-11-30 13:38:26,787 iteration 449 : loss : 0.075619, loss_ce: 0.036180
2021-11-30 13:38:28,012 iteration 450 : loss : 0.079681, loss_ce: 0.028216
2021-11-30 13:38:29,235 iteration 451 : loss : 0.099449, loss_ce: 0.045653
2021-11-30 13:38:30,455 iteration 452 : loss : 0.072293, loss_ce: 0.033842
2021-11-30 13:38:31,673 iteration 453 : loss : 0.111727, loss_ce: 0.038397
2021-11-30 13:38:32,888 iteration 454 : loss : 0.068189, loss_ce: 0.027786
2021-11-30 13:38:34,113 iteration 455 : loss : 0.075260, loss_ce: 0.029171
2021-11-30 13:38:35,337 iteration 456 : loss : 0.075438, loss_ce: 0.028224
2021-11-30 13:38:36,553 iteration 457 : loss : 0.067472, loss_ce: 0.028301
2021-11-30 13:38:37,775 iteration 458 : loss : 0.113607, loss_ce: 0.049250
2021-11-30 13:38:38,995 iteration 459 : loss : 0.065587, loss_ce: 0.025188
  7%|██                            | 27/400 [10:13<2:19:56, 22.51s/it]2021-11-30 13:38:40,280 iteration 460 : loss : 0.076859, loss_ce: 0.034907
2021-11-30 13:38:41,496 iteration 461 : loss : 0.081715, loss_ce: 0.025524
2021-11-30 13:38:42,714 iteration 462 : loss : 0.091757, loss_ce: 0.029726
2021-11-30 13:38:43,937 iteration 463 : loss : 0.085389, loss_ce: 0.028327
2021-11-30 13:38:45,161 iteration 464 : loss : 0.099674, loss_ce: 0.035748
2021-11-30 13:38:46,383 iteration 465 : loss : 0.095344, loss_ce: 0.039379
2021-11-30 13:38:47,607 iteration 466 : loss : 0.082363, loss_ce: 0.036400
2021-11-30 13:38:48,833 iteration 467 : loss : 0.062626, loss_ce: 0.025155
2021-11-30 13:38:50,053 iteration 468 : loss : 0.064465, loss_ce: 0.024039
2021-11-30 13:38:51,271 iteration 469 : loss : 0.108425, loss_ce: 0.062733
2021-11-30 13:38:52,488 iteration 470 : loss : 0.059482, loss_ce: 0.025880
2021-11-30 13:38:53,707 iteration 471 : loss : 0.071648, loss_ce: 0.033630
2021-11-30 13:38:54,932 iteration 472 : loss : 0.052631, loss_ce: 0.023418
2021-11-30 13:38:56,148 iteration 473 : loss : 0.106128, loss_ce: 0.047710
2021-11-30 13:38:57,370 iteration 474 : loss : 0.059988, loss_ce: 0.022913
2021-11-30 13:38:58,593 iteration 475 : loss : 0.136917, loss_ce: 0.040006
2021-11-30 13:38:59,815 iteration 476 : loss : 0.101055, loss_ce: 0.036697
  7%|██                            | 28/400 [10:33<2:16:25, 22.00s/it]2021-11-30 13:39:01,105 iteration 477 : loss : 0.060182, loss_ce: 0.027464
2021-11-30 13:39:02,327 iteration 478 : loss : 0.069151, loss_ce: 0.029902
2021-11-30 13:39:03,552 iteration 479 : loss : 0.091301, loss_ce: 0.030037
2021-11-30 13:39:04,776 iteration 480 : loss : 0.120212, loss_ce: 0.040229
2021-11-30 13:39:06,001 iteration 481 : loss : 0.062569, loss_ce: 0.024727
2021-11-30 13:39:07,227 iteration 482 : loss : 0.091919, loss_ce: 0.034712
2021-11-30 13:39:08,450 iteration 483 : loss : 0.104447, loss_ce: 0.037423
2021-11-30 13:39:09,677 iteration 484 : loss : 0.136470, loss_ce: 0.068814
2021-11-30 13:39:10,896 iteration 485 : loss : 0.079668, loss_ce: 0.036655
2021-11-30 13:39:12,119 iteration 486 : loss : 0.076426, loss_ce: 0.027721
2021-11-30 13:39:13,333 iteration 487 : loss : 0.078738, loss_ce: 0.026350
2021-11-30 13:39:14,555 iteration 488 : loss : 0.094114, loss_ce: 0.043658
2021-11-30 13:39:15,776 iteration 489 : loss : 0.077199, loss_ce: 0.035020
2021-11-30 13:39:16,996 iteration 490 : loss : 0.098014, loss_ce: 0.041510
2021-11-30 13:39:18,215 iteration 491 : loss : 0.084364, loss_ce: 0.042067
2021-11-30 13:39:19,438 iteration 492 : loss : 0.061147, loss_ce: 0.027951
2021-11-30 13:39:20,657 iteration 493 : loss : 0.098802, loss_ce: 0.041973
  7%|██▏                           | 29/400 [10:54<2:13:54, 21.66s/it]2021-11-30 13:39:21,945 iteration 494 : loss : 0.119767, loss_ce: 0.040459
2021-11-30 13:39:23,165 iteration 495 : loss : 0.070836, loss_ce: 0.026981
2021-11-30 13:39:24,386 iteration 496 : loss : 0.075124, loss_ce: 0.030548
2021-11-30 13:39:25,600 iteration 497 : loss : 0.078387, loss_ce: 0.036363
2021-11-30 13:39:26,806 iteration 498 : loss : 0.083982, loss_ce: 0.034585
2021-11-30 13:39:28,036 iteration 499 : loss : 0.095854, loss_ce: 0.035556
2021-11-30 13:39:29,255 iteration 500 : loss : 0.065981, loss_ce: 0.026201
2021-11-30 13:39:30,472 iteration 501 : loss : 0.072096, loss_ce: 0.029298
2021-11-30 13:39:31,692 iteration 502 : loss : 0.080938, loss_ce: 0.039399
2021-11-30 13:39:32,905 iteration 503 : loss : 0.074993, loss_ce: 0.036387
2021-11-30 13:39:34,122 iteration 504 : loss : 0.071311, loss_ce: 0.028560
2021-11-30 13:39:35,343 iteration 505 : loss : 0.084942, loss_ce: 0.040560
2021-11-30 13:39:36,561 iteration 506 : loss : 0.057094, loss_ce: 0.024699
2021-11-30 13:39:37,780 iteration 507 : loss : 0.072273, loss_ce: 0.030008
2021-11-30 13:39:39,004 iteration 508 : loss : 0.067705, loss_ce: 0.027775
2021-11-30 13:39:40,224 iteration 509 : loss : 0.066545, loss_ce: 0.026476
2021-11-30 13:39:40,225 Training Data Eval:
2021-11-30 13:39:47,130   Average segmentation loss on training set: 0.0829
2021-11-30 13:39:47,131 Validation Data Eval:
2021-11-30 13:39:49,504   Average segmentation loss on validation set: 0.1507
2021-11-30 13:39:50,725 iteration 510 : loss : 0.084318, loss_ce: 0.026322
  8%|██▎                           | 30/400 [11:24<2:29:05, 24.18s/it]2021-11-30 13:39:52,016 iteration 511 : loss : 0.062472, loss_ce: 0.026895
2021-11-30 13:39:53,244 iteration 512 : loss : 0.075716, loss_ce: 0.039694
2021-11-30 13:39:54,469 iteration 513 : loss : 0.088475, loss_ce: 0.030117
2021-11-30 13:39:55,689 iteration 514 : loss : 0.053196, loss_ce: 0.021516
2021-11-30 13:39:56,910 iteration 515 : loss : 0.121073, loss_ce: 0.028926
2021-11-30 13:39:58,135 iteration 516 : loss : 0.082368, loss_ce: 0.031947
2021-11-30 13:39:59,360 iteration 517 : loss : 0.081246, loss_ce: 0.033010
2021-11-30 13:40:00,592 iteration 518 : loss : 0.065114, loss_ce: 0.028456
2021-11-30 13:40:01,807 iteration 519 : loss : 0.064016, loss_ce: 0.026329
2021-11-30 13:40:03,034 iteration 520 : loss : 0.066309, loss_ce: 0.028515
2021-11-30 13:40:04,259 iteration 521 : loss : 0.067944, loss_ce: 0.023665
2021-11-30 13:40:05,483 iteration 522 : loss : 0.072560, loss_ce: 0.036694
2021-11-30 13:40:06,714 iteration 523 : loss : 0.068679, loss_ce: 0.026640
2021-11-30 13:40:07,936 iteration 524 : loss : 0.074503, loss_ce: 0.037039
2021-11-30 13:40:09,160 iteration 525 : loss : 0.050101, loss_ce: 0.022707
2021-11-30 13:40:10,380 iteration 526 : loss : 0.071485, loss_ce: 0.032753
2021-11-30 13:40:11,604 iteration 527 : loss : 0.117768, loss_ce: 0.042361
  8%|██▎                           | 31/400 [11:45<2:22:36, 23.19s/it]2021-11-30 13:40:12,897 iteration 528 : loss : 0.050178, loss_ce: 0.021734
2021-11-30 13:40:14,124 iteration 529 : loss : 0.056235, loss_ce: 0.025342
2021-11-30 13:40:15,347 iteration 530 : loss : 0.073775, loss_ce: 0.024737
2021-11-30 13:40:16,574 iteration 531 : loss : 0.063115, loss_ce: 0.028518
2021-11-30 13:40:17,803 iteration 532 : loss : 0.077087, loss_ce: 0.035092
2021-11-30 13:40:19,024 iteration 533 : loss : 0.051211, loss_ce: 0.021534
2021-11-30 13:40:20,259 iteration 534 : loss : 0.076789, loss_ce: 0.023126
2021-11-30 13:40:21,484 iteration 535 : loss : 0.071553, loss_ce: 0.026560
2021-11-30 13:40:22,705 iteration 536 : loss : 0.048827, loss_ce: 0.019833
2021-11-30 13:40:23,927 iteration 537 : loss : 0.073861, loss_ce: 0.039072
2021-11-30 13:40:25,153 iteration 538 : loss : 0.073602, loss_ce: 0.028071
2021-11-30 13:40:26,380 iteration 539 : loss : 0.067639, loss_ce: 0.024233
2021-11-30 13:40:27,604 iteration 540 : loss : 0.090014, loss_ce: 0.041355
2021-11-30 13:40:28,826 iteration 541 : loss : 0.051428, loss_ce: 0.027082
2021-11-30 13:40:30,053 iteration 542 : loss : 0.073516, loss_ce: 0.026747
2021-11-30 13:40:31,273 iteration 543 : loss : 0.133543, loss_ce: 0.034751
2021-11-30 13:40:32,502 iteration 544 : loss : 0.071669, loss_ce: 0.028767
  8%|██▍                           | 32/400 [12:06<2:18:00, 22.50s/it]2021-11-30 13:40:33,799 iteration 545 : loss : 0.056802, loss_ce: 0.022645
2021-11-30 13:40:35,016 iteration 546 : loss : 0.091478, loss_ce: 0.027317
2021-11-30 13:40:36,236 iteration 547 : loss : 0.082721, loss_ce: 0.032292
2021-11-30 13:40:37,459 iteration 548 : loss : 0.064359, loss_ce: 0.027941
2021-11-30 13:40:38,686 iteration 549 : loss : 0.069473, loss_ce: 0.021788
2021-11-30 13:40:39,911 iteration 550 : loss : 0.073216, loss_ce: 0.027102
2021-11-30 13:40:41,135 iteration 551 : loss : 0.080862, loss_ce: 0.034590
2021-11-30 13:40:42,366 iteration 552 : loss : 0.095119, loss_ce: 0.047947
2021-11-30 13:40:43,584 iteration 553 : loss : 0.049131, loss_ce: 0.022069
2021-11-30 13:40:44,809 iteration 554 : loss : 0.084959, loss_ce: 0.041473
2021-11-30 13:40:46,043 iteration 555 : loss : 0.070757, loss_ce: 0.029076
2021-11-30 13:40:47,268 iteration 556 : loss : 0.064387, loss_ce: 0.030252
2021-11-30 13:40:48,486 iteration 557 : loss : 0.095006, loss_ce: 0.036875
2021-11-30 13:40:49,706 iteration 558 : loss : 0.055504, loss_ce: 0.024079
2021-11-30 13:40:50,926 iteration 559 : loss : 0.087999, loss_ce: 0.036741
2021-11-30 13:40:52,146 iteration 560 : loss : 0.088923, loss_ce: 0.038506
2021-11-30 13:40:53,371 iteration 561 : loss : 0.066495, loss_ce: 0.031835
  8%|██▍                           | 33/400 [12:27<2:14:37, 22.01s/it]2021-11-30 13:40:54,656 iteration 562 : loss : 0.050906, loss_ce: 0.023614
2021-11-30 13:40:55,879 iteration 563 : loss : 0.084122, loss_ce: 0.028291
2021-11-30 13:40:57,098 iteration 564 : loss : 0.069281, loss_ce: 0.025153
2021-11-30 13:40:58,322 iteration 565 : loss : 0.064884, loss_ce: 0.032301
2021-11-30 13:40:59,541 iteration 566 : loss : 0.062272, loss_ce: 0.025438
2021-11-30 13:41:00,760 iteration 567 : loss : 0.055952, loss_ce: 0.024925
2021-11-30 13:41:01,980 iteration 568 : loss : 0.057735, loss_ce: 0.024904
2021-11-30 13:41:03,198 iteration 569 : loss : 0.076024, loss_ce: 0.028467
2021-11-30 13:41:04,418 iteration 570 : loss : 0.064802, loss_ce: 0.023946
2021-11-30 13:41:05,632 iteration 571 : loss : 0.068075, loss_ce: 0.026617
2021-11-30 13:41:06,854 iteration 572 : loss : 0.054602, loss_ce: 0.025058
2021-11-30 13:41:08,078 iteration 573 : loss : 0.064607, loss_ce: 0.028327
2021-11-30 13:41:09,300 iteration 574 : loss : 0.064637, loss_ce: 0.025619
2021-11-30 13:41:10,524 iteration 575 : loss : 0.066050, loss_ce: 0.026741
2021-11-30 13:41:11,750 iteration 576 : loss : 0.056852, loss_ce: 0.025548
2021-11-30 13:41:12,974 iteration 577 : loss : 0.048137, loss_ce: 0.020402
2021-11-30 13:41:14,201 iteration 578 : loss : 0.083101, loss_ce: 0.034010
  8%|██▌                           | 34/400 [12:48<2:12:06, 21.66s/it]2021-11-30 13:41:15,488 iteration 579 : loss : 0.072051, loss_ce: 0.029097
2021-11-30 13:41:16,711 iteration 580 : loss : 0.055485, loss_ce: 0.019293
2021-11-30 13:41:17,930 iteration 581 : loss : 0.053793, loss_ce: 0.022181
2021-11-30 13:41:19,154 iteration 582 : loss : 0.045914, loss_ce: 0.019168
2021-11-30 13:41:20,376 iteration 583 : loss : 0.048533, loss_ce: 0.019966
2021-11-30 13:41:21,604 iteration 584 : loss : 0.056432, loss_ce: 0.021773
2021-11-30 13:41:22,816 iteration 585 : loss : 0.054690, loss_ce: 0.020628
2021-11-30 13:41:24,033 iteration 586 : loss : 0.054986, loss_ce: 0.019277
2021-11-30 13:41:25,256 iteration 587 : loss : 0.045113, loss_ce: 0.018938
2021-11-30 13:41:26,473 iteration 588 : loss : 0.061755, loss_ce: 0.031153
2021-11-30 13:41:27,701 iteration 589 : loss : 0.054341, loss_ce: 0.021588
2021-11-30 13:41:28,919 iteration 590 : loss : 0.075580, loss_ce: 0.024434
2021-11-30 13:41:30,141 iteration 591 : loss : 0.062493, loss_ce: 0.032488
2021-11-30 13:41:31,364 iteration 592 : loss : 0.055676, loss_ce: 0.023595
2021-11-30 13:41:32,591 iteration 593 : loss : 0.070223, loss_ce: 0.038388
2021-11-30 13:41:33,813 iteration 594 : loss : 0.048477, loss_ce: 0.021226
2021-11-30 13:41:33,814 Training Data Eval:
2021-11-30 13:41:40,732   Average segmentation loss on training set: 0.0997
2021-11-30 13:41:40,733 Validation Data Eval:
2021-11-30 13:41:43,103   Average segmentation loss on validation set: 0.1213
2021-11-30 13:41:45,160 Found new lowest validation loss at iteration 594! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/UNET_RUNMC/ADAM/ADAM_best_val_loss_no_da.pth
2021-11-30 13:41:46,390 iteration 595 : loss : 0.069433, loss_ce: 0.025199
  9%|██▋                           | 35/400 [13:20<2:30:58, 24.82s/it]2021-11-30 13:41:47,674 iteration 596 : loss : 0.066114, loss_ce: 0.026813
2021-11-30 13:41:48,893 iteration 597 : loss : 0.059013, loss_ce: 0.027820
2021-11-30 13:41:50,114 iteration 598 : loss : 0.073439, loss_ce: 0.025984
2021-11-30 13:41:51,329 iteration 599 : loss : 0.073344, loss_ce: 0.028608
2021-11-30 13:41:52,553 iteration 600 : loss : 0.058238, loss_ce: 0.028594
2021-11-30 13:41:53,776 iteration 601 : loss : 0.062396, loss_ce: 0.025131
2021-11-30 13:41:55,005 iteration 602 : loss : 0.055771, loss_ce: 0.028233
2021-11-30 13:41:56,213 iteration 603 : loss : 0.048068, loss_ce: 0.023038
2021-11-30 13:41:57,435 iteration 604 : loss : 0.053754, loss_ce: 0.022814
2021-11-30 13:41:58,651 iteration 605 : loss : 0.077579, loss_ce: 0.030936
2021-11-30 13:41:59,868 iteration 606 : loss : 0.050458, loss_ce: 0.020635
2021-11-30 13:42:01,100 iteration 607 : loss : 0.069617, loss_ce: 0.022980
2021-11-30 13:42:02,321 iteration 608 : loss : 0.071490, loss_ce: 0.030765
2021-11-30 13:42:03,539 iteration 609 : loss : 0.114841, loss_ce: 0.040490
2021-11-30 13:42:04,752 iteration 610 : loss : 0.067659, loss_ce: 0.024520
2021-11-30 13:42:05,973 iteration 611 : loss : 0.069074, loss_ce: 0.031954
2021-11-30 13:42:07,192 iteration 612 : loss : 0.060345, loss_ce: 0.021690
  9%|██▋                           | 36/400 [13:41<2:23:15, 23.61s/it]2021-11-30 13:42:08,474 iteration 613 : loss : 0.068754, loss_ce: 0.033745
2021-11-30 13:42:09,697 iteration 614 : loss : 0.065969, loss_ce: 0.021719
2021-11-30 13:42:10,908 iteration 615 : loss : 0.054552, loss_ce: 0.022974
2021-11-30 13:42:12,134 iteration 616 : loss : 0.064297, loss_ce: 0.025010
2021-11-30 13:42:13,359 iteration 617 : loss : 0.078135, loss_ce: 0.033308
2021-11-30 13:42:14,579 iteration 618 : loss : 0.051082, loss_ce: 0.020842
2021-11-30 13:42:15,800 iteration 619 : loss : 0.059701, loss_ce: 0.025663
2021-11-30 13:42:17,018 iteration 620 : loss : 0.050313, loss_ce: 0.022890
2021-11-30 13:42:18,235 iteration 621 : loss : 0.053191, loss_ce: 0.022775
2021-11-30 13:42:19,456 iteration 622 : loss : 0.075107, loss_ce: 0.023776
2021-11-30 13:42:20,683 iteration 623 : loss : 0.086184, loss_ce: 0.026903
2021-11-30 13:42:21,902 iteration 624 : loss : 0.068136, loss_ce: 0.031303
2021-11-30 13:42:23,120 iteration 625 : loss : 0.077431, loss_ce: 0.029526
2021-11-30 13:42:24,339 iteration 626 : loss : 0.077766, loss_ce: 0.039376
2021-11-30 13:42:25,555 iteration 627 : loss : 0.053603, loss_ce: 0.019782
2021-11-30 13:42:26,782 iteration 628 : loss : 0.064268, loss_ce: 0.024294
2021-11-30 13:42:28,006 iteration 629 : loss : 0.078409, loss_ce: 0.028836
  9%|██▊                           | 37/400 [14:02<2:17:46, 22.77s/it]2021-11-30 13:42:29,284 iteration 630 : loss : 0.057940, loss_ce: 0.024810
2021-11-30 13:42:30,504 iteration 631 : loss : 0.096904, loss_ce: 0.028542
2021-11-30 13:42:31,720 iteration 632 : loss : 0.049950, loss_ce: 0.021394
2021-11-30 13:42:32,940 iteration 633 : loss : 0.054127, loss_ce: 0.024570
2021-11-30 13:42:34,164 iteration 634 : loss : 0.087691, loss_ce: 0.029447
2021-11-30 13:42:35,385 iteration 635 : loss : 0.060239, loss_ce: 0.024132
2021-11-30 13:42:36,607 iteration 636 : loss : 0.056178, loss_ce: 0.026235
2021-11-30 13:42:37,819 iteration 637 : loss : 0.050275, loss_ce: 0.025369
2021-11-30 13:42:39,029 iteration 638 : loss : 0.065791, loss_ce: 0.023266
2021-11-30 13:42:40,258 iteration 639 : loss : 0.068923, loss_ce: 0.024489
2021-11-30 13:42:41,475 iteration 640 : loss : 0.068699, loss_ce: 0.034775
2021-11-30 13:42:42,698 iteration 641 : loss : 0.050646, loss_ce: 0.024052
2021-11-30 13:42:43,912 iteration 642 : loss : 0.049201, loss_ce: 0.023704
2021-11-30 13:42:45,138 iteration 643 : loss : 0.070074, loss_ce: 0.026007
2021-11-30 13:42:46,357 iteration 644 : loss : 0.058900, loss_ce: 0.021251
2021-11-30 13:42:47,578 iteration 645 : loss : 0.064891, loss_ce: 0.022545
2021-11-30 13:42:48,802 iteration 646 : loss : 0.077104, loss_ce: 0.024539
 10%|██▊                           | 38/400 [14:22<2:13:49, 22.18s/it]2021-11-30 13:42:50,083 iteration 647 : loss : 0.060337, loss_ce: 0.017258
2021-11-30 13:42:51,304 iteration 648 : loss : 0.050857, loss_ce: 0.020911
2021-11-30 13:42:52,512 iteration 649 : loss : 0.060788, loss_ce: 0.024151
2021-11-30 13:42:53,732 iteration 650 : loss : 0.064625, loss_ce: 0.030106
2021-11-30 13:42:54,950 iteration 651 : loss : 0.077188, loss_ce: 0.021044
2021-11-30 13:42:56,170 iteration 652 : loss : 0.051909, loss_ce: 0.021003
2021-11-30 13:42:57,383 iteration 653 : loss : 0.055382, loss_ce: 0.017959
2021-11-30 13:42:58,604 iteration 654 : loss : 0.064028, loss_ce: 0.034833
2021-11-30 13:42:59,824 iteration 655 : loss : 0.063758, loss_ce: 0.023573
2021-11-30 13:43:01,043 iteration 656 : loss : 0.066336, loss_ce: 0.027378
2021-11-30 13:43:02,263 iteration 657 : loss : 0.063235, loss_ce: 0.025114
2021-11-30 13:43:03,488 iteration 658 : loss : 0.051852, loss_ce: 0.023931
2021-11-30 13:43:04,705 iteration 659 : loss : 0.051194, loss_ce: 0.025809
2021-11-30 13:43:05,918 iteration 660 : loss : 0.071875, loss_ce: 0.029166
2021-11-30 13:43:07,135 iteration 661 : loss : 0.049510, loss_ce: 0.023343
2021-11-30 13:43:08,362 iteration 662 : loss : 0.043246, loss_ce: 0.018344
2021-11-30 13:43:09,585 iteration 663 : loss : 0.103082, loss_ce: 0.034425
 10%|██▉                           | 39/400 [14:43<2:10:55, 21.76s/it]2021-11-30 13:43:10,869 iteration 664 : loss : 0.044663, loss_ce: 0.020687
2021-11-30 13:43:12,095 iteration 665 : loss : 0.060821, loss_ce: 0.035575
2021-11-30 13:43:13,312 iteration 666 : loss : 0.089728, loss_ce: 0.032692
2021-11-30 13:43:14,536 iteration 667 : loss : 0.052378, loss_ce: 0.022144
2021-11-30 13:43:15,754 iteration 668 : loss : 0.058560, loss_ce: 0.019133
2021-11-30 13:43:16,972 iteration 669 : loss : 0.058633, loss_ce: 0.023959
2021-11-30 13:43:18,192 iteration 670 : loss : 0.049980, loss_ce: 0.019867
2021-11-30 13:43:19,416 iteration 671 : loss : 0.055471, loss_ce: 0.022254
2021-11-30 13:43:20,637 iteration 672 : loss : 0.066169, loss_ce: 0.026505
2021-11-30 13:43:21,861 iteration 673 : loss : 0.045963, loss_ce: 0.019661
2021-11-30 13:43:23,082 iteration 674 : loss : 0.057243, loss_ce: 0.022636
2021-11-30 13:43:24,303 iteration 675 : loss : 0.055818, loss_ce: 0.022964
2021-11-30 13:43:25,525 iteration 676 : loss : 0.056189, loss_ce: 0.021843
2021-11-30 13:43:26,743 iteration 677 : loss : 0.077333, loss_ce: 0.030689
2021-11-30 13:43:27,959 iteration 678 : loss : 0.043916, loss_ce: 0.017100
2021-11-30 13:43:29,180 iteration 679 : loss : 0.050051, loss_ce: 0.020594
2021-11-30 13:43:29,180 Training Data Eval:
2021-11-30 13:43:36,100   Average segmentation loss on training set: 0.0837
2021-11-30 13:43:36,101 Validation Data Eval:
2021-11-30 13:43:38,479   Average segmentation loss on validation set: 0.1220
2021-11-30 13:43:39,702 iteration 680 : loss : 0.050918, loss_ce: 0.020108
 10%|███                           | 40/400 [15:13<2:25:36, 24.27s/it]2021-11-30 13:43:40,987 iteration 681 : loss : 0.049010, loss_ce: 0.017980
2021-11-30 13:43:42,211 iteration 682 : loss : 0.045673, loss_ce: 0.020736
2021-11-30 13:43:43,428 iteration 683 : loss : 0.071082, loss_ce: 0.025279
2021-11-30 13:43:44,649 iteration 684 : loss : 0.038426, loss_ce: 0.016682
2021-11-30 13:43:45,868 iteration 685 : loss : 0.051923, loss_ce: 0.019660
2021-11-30 13:43:47,093 iteration 686 : loss : 0.038525, loss_ce: 0.014581
2021-11-30 13:43:48,308 iteration 687 : loss : 0.045200, loss_ce: 0.017689
2021-11-30 13:43:49,525 iteration 688 : loss : 0.052408, loss_ce: 0.021693
2021-11-30 13:43:50,749 iteration 689 : loss : 0.048313, loss_ce: 0.019654
2021-11-30 13:43:51,970 iteration 690 : loss : 0.067432, loss_ce: 0.032534
2021-11-30 13:43:53,196 iteration 691 : loss : 0.057740, loss_ce: 0.024817
2021-11-30 13:43:54,418 iteration 692 : loss : 0.045050, loss_ce: 0.017466
2021-11-30 13:43:55,639 iteration 693 : loss : 0.051268, loss_ce: 0.021989
2021-11-30 13:43:56,863 iteration 694 : loss : 0.063851, loss_ce: 0.025499
2021-11-30 13:43:58,079 iteration 695 : loss : 0.061294, loss_ce: 0.022380
2021-11-30 13:43:59,289 iteration 696 : loss : 0.051586, loss_ce: 0.020678
2021-11-30 13:44:00,506 iteration 697 : loss : 0.046921, loss_ce: 0.018764
 10%|███                           | 41/400 [15:34<2:18:59, 23.23s/it]2021-11-30 13:44:01,782 iteration 698 : loss : 0.052558, loss_ce: 0.021938
2021-11-30 13:44:03,004 iteration 699 : loss : 0.055825, loss_ce: 0.024853
2021-11-30 13:44:04,224 iteration 700 : loss : 0.049057, loss_ce: 0.021469
2021-11-30 13:44:05,439 iteration 701 : loss : 0.049021, loss_ce: 0.022675
2021-11-30 13:44:06,659 iteration 702 : loss : 0.065444, loss_ce: 0.023894
2021-11-30 13:44:07,876 iteration 703 : loss : 0.065884, loss_ce: 0.026480
2021-11-30 13:44:09,096 iteration 704 : loss : 0.050790, loss_ce: 0.020819
2021-11-30 13:44:10,315 iteration 705 : loss : 0.048903, loss_ce: 0.017212
2021-11-30 13:44:11,526 iteration 706 : loss : 0.053681, loss_ce: 0.022458
2021-11-30 13:44:12,751 iteration 707 : loss : 0.045590, loss_ce: 0.015308
2021-11-30 13:44:13,966 iteration 708 : loss : 0.054908, loss_ce: 0.025193
2021-11-30 13:44:15,195 iteration 709 : loss : 0.106279, loss_ce: 0.057806
2021-11-30 13:44:16,409 iteration 710 : loss : 0.048380, loss_ce: 0.019054
2021-11-30 13:44:17,629 iteration 711 : loss : 0.049779, loss_ce: 0.021315
2021-11-30 13:44:18,846 iteration 712 : loss : 0.041260, loss_ce: 0.020409
2021-11-30 13:44:20,054 iteration 713 : loss : 0.088903, loss_ce: 0.033020
2021-11-30 13:44:21,277 iteration 714 : loss : 0.069569, loss_ce: 0.024674
 10%|███▏                          | 42/400 [15:55<2:14:12, 22.49s/it]2021-11-30 13:44:22,547 iteration 715 : loss : 0.050038, loss_ce: 0.021563
2021-11-30 13:44:23,766 iteration 716 : loss : 0.054941, loss_ce: 0.020250
2021-11-30 13:44:24,981 iteration 717 : loss : 0.067994, loss_ce: 0.026679
2021-11-30 13:44:26,206 iteration 718 : loss : 0.063095, loss_ce: 0.027374
2021-11-30 13:44:27,427 iteration 719 : loss : 0.046299, loss_ce: 0.019769
2021-11-30 13:44:28,643 iteration 720 : loss : 0.052468, loss_ce: 0.023733
2021-11-30 13:44:29,863 iteration 721 : loss : 0.083712, loss_ce: 0.031640
2021-11-30 13:44:31,080 iteration 722 : loss : 0.067152, loss_ce: 0.021017
2021-11-30 13:44:32,306 iteration 723 : loss : 0.073941, loss_ce: 0.025339
2021-11-30 13:44:33,529 iteration 724 : loss : 0.053161, loss_ce: 0.025282
2021-11-30 13:44:34,735 iteration 725 : loss : 0.054726, loss_ce: 0.027326
2021-11-30 13:44:35,952 iteration 726 : loss : 0.058379, loss_ce: 0.020607
2021-11-30 13:44:37,168 iteration 727 : loss : 0.044022, loss_ce: 0.018719
2021-11-30 13:44:38,382 iteration 728 : loss : 0.047397, loss_ce: 0.021023
2021-11-30 13:44:39,606 iteration 729 : loss : 0.074887, loss_ce: 0.026901
2021-11-30 13:44:40,824 iteration 730 : loss : 0.061568, loss_ce: 0.022568
2021-11-30 13:44:42,041 iteration 731 : loss : 0.033829, loss_ce: 0.013739
 11%|███▏                          | 43/400 [16:16<2:10:44, 21.97s/it]2021-11-30 13:44:43,327 iteration 732 : loss : 0.048667, loss_ce: 0.016830
2021-11-30 13:44:44,552 iteration 733 : loss : 0.048111, loss_ce: 0.017229
2021-11-30 13:44:45,774 iteration 734 : loss : 0.062447, loss_ce: 0.025780
2021-11-30 13:44:46,997 iteration 735 : loss : 0.076712, loss_ce: 0.037613
2021-11-30 13:44:48,224 iteration 736 : loss : 0.048281, loss_ce: 0.017291
2021-11-30 13:44:49,447 iteration 737 : loss : 0.044203, loss_ce: 0.018887
2021-11-30 13:44:50,663 iteration 738 : loss : 0.053268, loss_ce: 0.018861
2021-11-30 13:44:51,886 iteration 739 : loss : 0.053661, loss_ce: 0.020170
2021-11-30 13:44:53,107 iteration 740 : loss : 0.073269, loss_ce: 0.018390
2021-11-30 13:44:54,328 iteration 741 : loss : 0.034942, loss_ce: 0.011801
2021-11-30 13:44:55,550 iteration 742 : loss : 0.093263, loss_ce: 0.037564
2021-11-30 13:44:56,774 iteration 743 : loss : 0.072730, loss_ce: 0.023774
2021-11-30 13:44:57,991 iteration 744 : loss : 0.077547, loss_ce: 0.035811
2021-11-30 13:44:59,212 iteration 745 : loss : 0.072101, loss_ce: 0.028457
2021-11-30 13:45:00,433 iteration 746 : loss : 0.053622, loss_ce: 0.022348
2021-11-30 13:45:01,648 iteration 747 : loss : 0.050700, loss_ce: 0.020479
2021-11-30 13:45:02,865 iteration 748 : loss : 0.081288, loss_ce: 0.035432
 11%|███▎                          | 44/400 [16:36<2:08:20, 21.63s/it]2021-11-30 13:45:04,147 iteration 749 : loss : 0.074170, loss_ce: 0.031927
2021-11-30 13:45:05,370 iteration 750 : loss : 0.069098, loss_ce: 0.026419
2021-11-30 13:45:06,590 iteration 751 : loss : 0.062861, loss_ce: 0.022920
2021-11-30 13:45:07,810 iteration 752 : loss : 0.050198, loss_ce: 0.021376
2021-11-30 13:45:09,029 iteration 753 : loss : 0.045049, loss_ce: 0.018874
2021-11-30 13:45:10,249 iteration 754 : loss : 0.046806, loss_ce: 0.017656
2021-11-30 13:45:11,478 iteration 755 : loss : 0.042286, loss_ce: 0.018635
2021-11-30 13:45:12,701 iteration 756 : loss : 0.079921, loss_ce: 0.030751
2021-11-30 13:45:13,919 iteration 757 : loss : 0.054264, loss_ce: 0.024571
2021-11-30 13:45:15,146 iteration 758 : loss : 0.058992, loss_ce: 0.018888
2021-11-30 13:45:16,370 iteration 759 : loss : 0.059558, loss_ce: 0.021907
2021-11-30 13:45:17,594 iteration 760 : loss : 0.049711, loss_ce: 0.020663
2021-11-30 13:45:18,818 iteration 761 : loss : 0.054246, loss_ce: 0.019295
2021-11-30 13:45:20,045 iteration 762 : loss : 0.061650, loss_ce: 0.025950
2021-11-30 13:45:21,265 iteration 763 : loss : 0.057887, loss_ce: 0.025743
2021-11-30 13:45:22,486 iteration 764 : loss : 0.047951, loss_ce: 0.020858
2021-11-30 13:45:22,486 Training Data Eval:
2021-11-30 13:45:29,394   Average segmentation loss on training set: 0.0453
2021-11-30 13:45:29,395 Validation Data Eval:
2021-11-30 13:45:31,776   Average segmentation loss on validation set: 0.1047
2021-11-30 13:45:33,817 Found new lowest validation loss at iteration 764! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/UNET_RUNMC/ADAM/ADAM_best_val_loss_no_da.pth
2021-11-30 13:45:35,040 iteration 765 : loss : 0.049931, loss_ce: 0.026305
 11%|███▍                          | 45/400 [17:09<2:26:41, 24.79s/it]2021-11-30 13:45:36,325 iteration 766 : loss : 0.051703, loss_ce: 0.021129
2021-11-30 13:45:37,544 iteration 767 : loss : 0.047857, loss_ce: 0.017719
2021-11-30 13:45:38,761 iteration 768 : loss : 0.045211, loss_ce: 0.017057
2021-11-30 13:45:39,982 iteration 769 : loss : 0.047879, loss_ce: 0.020924
2021-11-30 13:45:41,203 iteration 770 : loss : 0.055014, loss_ce: 0.020216
2021-11-30 13:45:42,422 iteration 771 : loss : 0.064353, loss_ce: 0.022854
2021-11-30 13:45:43,639 iteration 772 : loss : 0.078655, loss_ce: 0.032457
2021-11-30 13:45:44,859 iteration 773 : loss : 0.052052, loss_ce: 0.025554
2021-11-30 13:45:46,081 iteration 774 : loss : 0.050305, loss_ce: 0.019798
2021-11-30 13:45:47,304 iteration 775 : loss : 0.040008, loss_ce: 0.015399
2021-11-30 13:45:48,526 iteration 776 : loss : 0.048631, loss_ce: 0.017480
2021-11-30 13:45:49,744 iteration 777 : loss : 0.045374, loss_ce: 0.017662
2021-11-30 13:45:50,954 iteration 778 : loss : 0.063262, loss_ce: 0.019200
2021-11-30 13:45:52,174 iteration 779 : loss : 0.053771, loss_ce: 0.028381
2021-11-30 13:45:53,393 iteration 780 : loss : 0.052861, loss_ce: 0.019237
2021-11-30 13:45:54,614 iteration 781 : loss : 0.053614, loss_ce: 0.025427
2021-11-30 13:45:55,836 iteration 782 : loss : 0.038560, loss_ce: 0.016561
 12%|███▍                          | 46/400 [17:29<2:19:12, 23.59s/it]2021-11-30 13:45:57,125 iteration 783 : loss : 0.048630, loss_ce: 0.018304
2021-11-30 13:45:58,342 iteration 784 : loss : 0.052168, loss_ce: 0.020436
2021-11-30 13:45:59,561 iteration 785 : loss : 0.070504, loss_ce: 0.020590
2021-11-30 13:46:00,780 iteration 786 : loss : 0.050538, loss_ce: 0.015026
2021-11-30 13:46:02,000 iteration 787 : loss : 0.043249, loss_ce: 0.019003
2021-11-30 13:46:03,222 iteration 788 : loss : 0.050286, loss_ce: 0.021379
2021-11-30 13:46:04,448 iteration 789 : loss : 0.045508, loss_ce: 0.016272
2021-11-30 13:46:05,664 iteration 790 : loss : 0.053409, loss_ce: 0.019362
2021-11-30 13:46:06,886 iteration 791 : loss : 0.035955, loss_ce: 0.014216
2021-11-30 13:46:08,104 iteration 792 : loss : 0.042926, loss_ce: 0.018173
2021-11-30 13:46:09,321 iteration 793 : loss : 0.047586, loss_ce: 0.023527
2021-11-30 13:46:10,546 iteration 794 : loss : 0.043429, loss_ce: 0.016030
2021-11-30 13:46:11,767 iteration 795 : loss : 0.045824, loss_ce: 0.021929
2021-11-30 13:46:12,988 iteration 796 : loss : 0.053400, loss_ce: 0.020107
2021-11-30 13:46:14,213 iteration 797 : loss : 0.055417, loss_ce: 0.024133
2021-11-30 13:46:15,432 iteration 798 : loss : 0.044797, loss_ce: 0.018420
2021-11-30 13:46:16,654 iteration 799 : loss : 0.042340, loss_ce: 0.021055
 12%|███▌                          | 47/400 [17:50<2:13:54, 22.76s/it]2021-11-30 13:46:17,933 iteration 800 : loss : 0.041405, loss_ce: 0.016930
2021-11-30 13:46:19,151 iteration 801 : loss : 0.036252, loss_ce: 0.017462
2021-11-30 13:46:20,373 iteration 802 : loss : 0.062599, loss_ce: 0.020608
2021-11-30 13:46:21,594 iteration 803 : loss : 0.032286, loss_ce: 0.014069
2021-11-30 13:46:22,814 iteration 804 : loss : 0.048954, loss_ce: 0.018171
2021-11-30 13:46:24,040 iteration 805 : loss : 0.048734, loss_ce: 0.018346
2021-11-30 13:46:25,262 iteration 806 : loss : 0.041013, loss_ce: 0.018266
2021-11-30 13:46:26,472 iteration 807 : loss : 0.042663, loss_ce: 0.017076
2021-11-30 13:46:27,690 iteration 808 : loss : 0.050971, loss_ce: 0.017714
2021-11-30 13:46:28,914 iteration 809 : loss : 0.044460, loss_ce: 0.019144
2021-11-30 13:46:30,132 iteration 810 : loss : 0.064249, loss_ce: 0.020073
2021-11-30 13:46:31,358 iteration 811 : loss : 0.051226, loss_ce: 0.019677
2021-11-30 13:46:32,577 iteration 812 : loss : 0.054165, loss_ce: 0.021894
2021-11-30 13:46:33,801 iteration 813 : loss : 0.066495, loss_ce: 0.026737
2021-11-30 13:46:35,029 iteration 814 : loss : 0.044151, loss_ce: 0.019079
2021-11-30 13:46:36,250 iteration 815 : loss : 0.050176, loss_ce: 0.020473
2021-11-30 13:46:37,474 iteration 816 : loss : 0.052639, loss_ce: 0.021412
 12%|███▌                          | 48/400 [18:11<2:10:07, 22.18s/it]2021-11-30 13:46:38,773 iteration 817 : loss : 0.055908, loss_ce: 0.022678
2021-11-30 13:46:39,994 iteration 818 : loss : 0.042190, loss_ce: 0.019170
2021-11-30 13:46:41,218 iteration 819 : loss : 0.039633, loss_ce: 0.020260
2021-11-30 13:46:42,437 iteration 820 : loss : 0.062504, loss_ce: 0.022756
2021-11-30 13:46:43,655 iteration 821 : loss : 0.043596, loss_ce: 0.021206
2021-11-30 13:46:44,868 iteration 822 : loss : 0.048200, loss_ce: 0.020466
2021-11-30 13:46:46,083 iteration 823 : loss : 0.059806, loss_ce: 0.022088
2021-11-30 13:46:47,310 iteration 824 : loss : 0.056392, loss_ce: 0.021611
2021-11-30 13:46:48,534 iteration 825 : loss : 0.047295, loss_ce: 0.018833
2021-11-30 13:46:49,756 iteration 826 : loss : 0.037374, loss_ce: 0.017541
2021-11-30 13:46:50,979 iteration 827 : loss : 0.058191, loss_ce: 0.023708
2021-11-30 13:46:52,197 iteration 828 : loss : 0.046250, loss_ce: 0.020603
2021-11-30 13:46:53,410 iteration 829 : loss : 0.046177, loss_ce: 0.019755
2021-11-30 13:46:54,638 iteration 830 : loss : 0.075267, loss_ce: 0.019836
2021-11-30 13:46:55,848 iteration 831 : loss : 0.048964, loss_ce: 0.016227
2021-11-30 13:46:57,068 iteration 832 : loss : 0.048932, loss_ce: 0.018685
2021-11-30 13:46:58,285 iteration 833 : loss : 0.042948, loss_ce: 0.018064
 12%|███▋                          | 49/400 [18:32<2:07:20, 21.77s/it]2021-11-30 13:46:59,568 iteration 834 : loss : 0.061231, loss_ce: 0.028217
2021-11-30 13:47:00,782 iteration 835 : loss : 0.047586, loss_ce: 0.016160
2021-11-30 13:47:02,004 iteration 836 : loss : 0.041558, loss_ce: 0.017818
2021-11-30 13:47:03,222 iteration 837 : loss : 0.045425, loss_ce: 0.014612
2021-11-30 13:47:04,434 iteration 838 : loss : 0.040328, loss_ce: 0.017295
2021-11-30 13:47:05,648 iteration 839 : loss : 0.067902, loss_ce: 0.018728
2021-11-30 13:47:06,867 iteration 840 : loss : 0.053795, loss_ce: 0.022639
2021-11-30 13:47:08,089 iteration 841 : loss : 0.067430, loss_ce: 0.023020
2021-11-30 13:47:09,311 iteration 842 : loss : 0.056969, loss_ce: 0.020124
2021-11-30 13:47:10,535 iteration 843 : loss : 0.042809, loss_ce: 0.017752
2021-11-30 13:47:11,761 iteration 844 : loss : 0.055657, loss_ce: 0.026178
2021-11-30 13:47:12,984 iteration 845 : loss : 0.045726, loss_ce: 0.020393
2021-11-30 13:47:14,211 iteration 846 : loss : 0.049521, loss_ce: 0.018533
2021-11-30 13:47:15,440 iteration 847 : loss : 0.052656, loss_ce: 0.019124
2021-11-30 13:47:16,669 iteration 848 : loss : 0.052488, loss_ce: 0.016554
2021-11-30 13:47:17,892 iteration 849 : loss : 0.048957, loss_ce: 0.024281
2021-11-30 13:47:17,892 Training Data Eval:
2021-11-30 13:47:24,799   Average segmentation loss on training set: 0.0572
2021-11-30 13:47:24,800 Validation Data Eval:
2021-11-30 13:47:27,161   Average segmentation loss on validation set: 0.1001
2021-11-30 13:47:29,449 Found new lowest validation loss at iteration 849! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/UNET_RUNMC/ADAM/ADAM_best_val_loss_no_da.pth
2021-11-30 13:47:30,680 iteration 850 : loss : 0.050795, loss_ce: 0.018147
 12%|███▊                          | 50/400 [19:04<2:25:34, 24.96s/it]2021-11-30 13:47:31,968 iteration 851 : loss : 0.052930, loss_ce: 0.021366
2021-11-30 13:47:33,183 iteration 852 : loss : 0.042864, loss_ce: 0.015589
2021-11-30 13:47:34,390 iteration 853 : loss : 0.052121, loss_ce: 0.016845
2021-11-30 13:47:35,609 iteration 854 : loss : 0.041826, loss_ce: 0.021613
2021-11-30 13:47:36,834 iteration 855 : loss : 0.039275, loss_ce: 0.018289
2021-11-30 13:47:38,049 iteration 856 : loss : 0.058042, loss_ce: 0.020092
2021-11-30 13:47:39,271 iteration 857 : loss : 0.049844, loss_ce: 0.019234
2021-11-30 13:47:40,491 iteration 858 : loss : 0.044018, loss_ce: 0.017077
2021-11-30 13:47:41,710 iteration 859 : loss : 0.048774, loss_ce: 0.021163
2021-11-30 13:47:42,928 iteration 860 : loss : 0.043798, loss_ce: 0.016245
2021-11-30 13:47:44,155 iteration 861 : loss : 0.046737, loss_ce: 0.019476
2021-11-30 13:47:45,374 iteration 862 : loss : 0.054243, loss_ce: 0.022099
2021-11-30 13:47:46,591 iteration 863 : loss : 0.037224, loss_ce: 0.016580
2021-11-30 13:47:47,813 iteration 864 : loss : 0.043181, loss_ce: 0.017618
2021-11-30 13:47:49,043 iteration 865 : loss : 0.048508, loss_ce: 0.018776
2021-11-30 13:47:50,266 iteration 866 : loss : 0.042587, loss_ce: 0.015063
2021-11-30 13:47:51,493 iteration 867 : loss : 0.043337, loss_ce: 0.017103
 13%|███▊                          | 51/400 [19:25<2:17:55, 23.71s/it]2021-11-30 13:47:52,787 iteration 868 : loss : 0.036527, loss_ce: 0.015918
2021-11-30 13:47:54,006 iteration 869 : loss : 0.067334, loss_ce: 0.030730
2021-11-30 13:47:55,226 iteration 870 : loss : 0.042515, loss_ce: 0.017541
2021-11-30 13:47:56,449 iteration 871 : loss : 0.032098, loss_ce: 0.011958
2021-11-30 13:47:57,668 iteration 872 : loss : 0.033454, loss_ce: 0.015500
2021-11-30 13:47:58,889 iteration 873 : loss : 0.050221, loss_ce: 0.015054
2021-11-30 13:48:00,111 iteration 874 : loss : 0.044845, loss_ce: 0.018838
2021-11-30 13:48:01,338 iteration 875 : loss : 0.041223, loss_ce: 0.017623
2021-11-30 13:48:02,554 iteration 876 : loss : 0.045353, loss_ce: 0.017446
2021-11-30 13:48:03,777 iteration 877 : loss : 0.043745, loss_ce: 0.017882
2021-11-30 13:48:04,997 iteration 878 : loss : 0.037958, loss_ce: 0.015906
2021-11-30 13:48:06,215 iteration 879 : loss : 0.035685, loss_ce: 0.013932
2021-11-30 13:48:07,441 iteration 880 : loss : 0.063381, loss_ce: 0.035934
2021-11-30 13:48:08,665 iteration 881 : loss : 0.047823, loss_ce: 0.020847
2021-11-30 13:48:09,887 iteration 882 : loss : 0.045626, loss_ce: 0.016229
2021-11-30 13:48:11,106 iteration 883 : loss : 0.055172, loss_ce: 0.019336
2021-11-30 13:48:12,331 iteration 884 : loss : 0.035396, loss_ce: 0.016081
 13%|███▉                          | 52/400 [19:46<2:12:32, 22.85s/it]2021-11-30 13:48:13,626 iteration 885 : loss : 0.033905, loss_ce: 0.013924
2021-11-30 13:48:14,843 iteration 886 : loss : 0.041789, loss_ce: 0.020910
2021-11-30 13:48:16,057 iteration 887 : loss : 0.041908, loss_ce: 0.016265
2021-11-30 13:48:17,280 iteration 888 : loss : 0.041412, loss_ce: 0.014317
2021-11-30 13:48:18,503 iteration 889 : loss : 0.041389, loss_ce: 0.016011
2021-11-30 13:48:19,725 iteration 890 : loss : 0.042314, loss_ce: 0.017844
2021-11-30 13:48:20,957 iteration 891 : loss : 0.049878, loss_ce: 0.017178
2021-11-30 13:48:22,181 iteration 892 : loss : 0.050540, loss_ce: 0.020125
2021-11-30 13:48:23,403 iteration 893 : loss : 0.038748, loss_ce: 0.016130
2021-11-30 13:48:24,616 iteration 894 : loss : 0.041617, loss_ce: 0.017537
2021-11-30 13:48:25,842 iteration 895 : loss : 0.034035, loss_ce: 0.012060
2021-11-30 13:48:27,063 iteration 896 : loss : 0.030297, loss_ce: 0.011084
2021-11-30 13:48:28,281 iteration 897 : loss : 0.049844, loss_ce: 0.023590
2021-11-30 13:48:29,504 iteration 898 : loss : 0.036134, loss_ce: 0.017701
2021-11-30 13:48:30,723 iteration 899 : loss : 0.036807, loss_ce: 0.017238
2021-11-30 13:48:31,947 iteration 900 : loss : 0.042616, loss_ce: 0.015564
2021-11-30 13:48:33,167 iteration 901 : loss : 0.050617, loss_ce: 0.014392
 13%|███▉                          | 53/400 [20:07<2:08:39, 22.25s/it]2021-11-30 13:48:34,452 iteration 902 : loss : 0.032933, loss_ce: 0.013234
2021-11-30 13:48:35,675 iteration 903 : loss : 0.039961, loss_ce: 0.016268
2021-11-30 13:48:36,900 iteration 904 : loss : 0.039101, loss_ce: 0.018858
2021-11-30 13:48:38,115 iteration 905 : loss : 0.035215, loss_ce: 0.015258
2021-11-30 13:48:39,330 iteration 906 : loss : 0.036592, loss_ce: 0.018154
2021-11-30 13:48:40,551 iteration 907 : loss : 0.032489, loss_ce: 0.012185
2021-11-30 13:48:41,762 iteration 908 : loss : 0.057908, loss_ce: 0.018728
2021-11-30 13:48:42,985 iteration 909 : loss : 0.038709, loss_ce: 0.018026
2021-11-30 13:48:44,207 iteration 910 : loss : 0.032421, loss_ce: 0.014365
2021-11-30 13:48:45,428 iteration 911 : loss : 0.062880, loss_ce: 0.018664
2021-11-30 13:48:46,659 iteration 912 : loss : 0.047272, loss_ce: 0.015922
2021-11-30 13:48:47,885 iteration 913 : loss : 0.041995, loss_ce: 0.019877
2021-11-30 13:48:49,111 iteration 914 : loss : 0.040628, loss_ce: 0.017510
2021-11-30 13:48:50,336 iteration 915 : loss : 0.058763, loss_ce: 0.023030
2021-11-30 13:48:51,560 iteration 916 : loss : 0.039295, loss_ce: 0.014188
2021-11-30 13:48:52,781 iteration 917 : loss : 0.032595, loss_ce: 0.011507
2021-11-30 13:48:54,006 iteration 918 : loss : 0.050214, loss_ce: 0.019182
 14%|████                          | 54/400 [20:28<2:05:51, 21.82s/it]2021-11-30 13:48:55,298 iteration 919 : loss : 0.030182, loss_ce: 0.012982
2021-11-30 13:48:56,527 iteration 920 : loss : 0.037227, loss_ce: 0.016813
2021-11-30 13:48:57,755 iteration 921 : loss : 0.030506, loss_ce: 0.013401
2021-11-30 13:48:58,972 iteration 922 : loss : 0.056511, loss_ce: 0.016674
2021-11-30 13:49:00,194 iteration 923 : loss : 0.040744, loss_ce: 0.016548
2021-11-30 13:49:01,411 iteration 924 : loss : 0.040071, loss_ce: 0.015996
2021-11-30 13:49:02,630 iteration 925 : loss : 0.053692, loss_ce: 0.022566
2021-11-30 13:49:03,851 iteration 926 : loss : 0.041187, loss_ce: 0.019152
2021-11-30 13:49:05,071 iteration 927 : loss : 0.033888, loss_ce: 0.014263
2021-11-30 13:49:06,296 iteration 928 : loss : 0.046095, loss_ce: 0.018939
2021-11-30 13:49:07,509 iteration 929 : loss : 0.036131, loss_ce: 0.014299
2021-11-30 13:49:08,732 iteration 930 : loss : 0.049539, loss_ce: 0.019802
2021-11-30 13:49:09,953 iteration 931 : loss : 0.036925, loss_ce: 0.013134
2021-11-30 13:49:11,163 iteration 932 : loss : 0.052065, loss_ce: 0.017592
2021-11-30 13:49:12,391 iteration 933 : loss : 0.033798, loss_ce: 0.013629
2021-11-30 13:49:13,609 iteration 934 : loss : 0.047083, loss_ce: 0.021564
2021-11-30 13:49:13,609 Training Data Eval:
2021-11-30 13:49:20,523   Average segmentation loss on training set: 0.0452
2021-11-30 13:49:20,524 Validation Data Eval:
2021-11-30 13:49:22,897   Average segmentation loss on validation set: 0.1293
2021-11-30 13:49:24,122 iteration 935 : loss : 0.054197, loss_ce: 0.023328
 14%|████▏                         | 55/400 [20:58<2:19:47, 24.31s/it]2021-11-30 13:49:25,424 iteration 936 : loss : 0.051050, loss_ce: 0.020699
2021-11-30 13:49:26,646 iteration 937 : loss : 0.042945, loss_ce: 0.018960
2021-11-30 13:49:27,873 iteration 938 : loss : 0.045387, loss_ce: 0.015701
2021-11-30 13:49:29,098 iteration 939 : loss : 0.036454, loss_ce: 0.016223
2021-11-30 13:49:30,324 iteration 940 : loss : 0.043026, loss_ce: 0.014871
2021-11-30 13:49:31,544 iteration 941 : loss : 0.048731, loss_ce: 0.020451
2021-11-30 13:49:32,771 iteration 942 : loss : 0.034666, loss_ce: 0.014823
2021-11-30 13:49:33,996 iteration 943 : loss : 0.038925, loss_ce: 0.018042
2021-11-30 13:49:35,221 iteration 944 : loss : 0.035317, loss_ce: 0.017027
2021-11-30 13:49:36,443 iteration 945 : loss : 0.042289, loss_ce: 0.014217
2021-11-30 13:49:37,669 iteration 946 : loss : 0.034581, loss_ce: 0.014401
2021-11-30 13:49:38,893 iteration 947 : loss : 0.049739, loss_ce: 0.019827
2021-11-30 13:49:40,122 iteration 948 : loss : 0.038225, loss_ce: 0.016937
2021-11-30 13:49:41,344 iteration 949 : loss : 0.090289, loss_ce: 0.022450
2021-11-30 13:49:42,568 iteration 950 : loss : 0.052267, loss_ce: 0.021564
2021-11-30 13:49:43,796 iteration 951 : loss : 0.030658, loss_ce: 0.011189
2021-11-30 13:49:45,019 iteration 952 : loss : 0.044227, loss_ce: 0.016424
 14%|████▏                         | 56/400 [21:19<2:13:31, 23.29s/it]2021-11-30 13:49:46,317 iteration 953 : loss : 0.067677, loss_ce: 0.032036
2021-11-30 13:49:47,538 iteration 954 : loss : 0.037875, loss_ce: 0.013056
2021-11-30 13:49:48,755 iteration 955 : loss : 0.040604, loss_ce: 0.017107
2021-11-30 13:49:49,980 iteration 956 : loss : 0.046186, loss_ce: 0.016008
2021-11-30 13:49:51,208 iteration 957 : loss : 0.047492, loss_ce: 0.017741
2021-11-30 13:49:52,431 iteration 958 : loss : 0.032056, loss_ce: 0.012678
2021-11-30 13:49:53,657 iteration 959 : loss : 0.038462, loss_ce: 0.015674
2021-11-30 13:49:54,880 iteration 960 : loss : 0.047900, loss_ce: 0.022599
2021-11-30 13:49:56,103 iteration 961 : loss : 0.040877, loss_ce: 0.019230
2021-11-30 13:49:57,322 iteration 962 : loss : 0.082304, loss_ce: 0.027338
2021-11-30 13:49:58,549 iteration 963 : loss : 0.057891, loss_ce: 0.017398
2021-11-30 13:49:59,772 iteration 964 : loss : 0.041003, loss_ce: 0.016296
2021-11-30 13:50:00,996 iteration 965 : loss : 0.060364, loss_ce: 0.021767
2021-11-30 13:50:02,216 iteration 966 : loss : 0.036196, loss_ce: 0.014281
2021-11-30 13:50:03,434 iteration 967 : loss : 0.050912, loss_ce: 0.020400
2021-11-30 13:50:04,661 iteration 968 : loss : 0.047675, loss_ce: 0.019306
2021-11-30 13:50:05,880 iteration 969 : loss : 0.047188, loss_ce: 0.012767
 14%|████▎                         | 57/400 [21:39<2:08:57, 22.56s/it]2021-11-30 13:50:07,167 iteration 970 : loss : 0.036142, loss_ce: 0.013200
2021-11-30 13:50:08,387 iteration 971 : loss : 0.041877, loss_ce: 0.017401
2021-11-30 13:50:09,611 iteration 972 : loss : 0.037757, loss_ce: 0.012992
2021-11-30 13:50:10,834 iteration 973 : loss : 0.053852, loss_ce: 0.015178
2021-11-30 13:50:12,056 iteration 974 : loss : 0.049140, loss_ce: 0.015216
2021-11-30 13:50:13,273 iteration 975 : loss : 0.030920, loss_ce: 0.011388
2021-11-30 13:50:14,500 iteration 976 : loss : 0.034244, loss_ce: 0.013435
2021-11-30 13:50:15,719 iteration 977 : loss : 0.031152, loss_ce: 0.013010
2021-11-30 13:50:16,936 iteration 978 : loss : 0.036271, loss_ce: 0.013771
2021-11-30 13:50:18,145 iteration 979 : loss : 0.033307, loss_ce: 0.013571
2021-11-30 13:50:19,378 iteration 980 : loss : 0.044862, loss_ce: 0.012933
2021-11-30 13:50:20,598 iteration 981 : loss : 0.056451, loss_ce: 0.018899
2021-11-30 13:50:21,817 iteration 982 : loss : 0.038314, loss_ce: 0.015241
2021-11-30 13:50:23,038 iteration 983 : loss : 0.041920, loss_ce: 0.018104
2021-11-30 13:50:24,263 iteration 984 : loss : 0.034027, loss_ce: 0.013954
2021-11-30 13:50:25,482 iteration 985 : loss : 0.048417, loss_ce: 0.022622
2021-11-30 13:50:26,706 iteration 986 : loss : 0.040776, loss_ce: 0.018438
 14%|████▎                         | 58/400 [22:00<2:05:37, 22.04s/it]2021-11-30 13:50:27,999 iteration 987 : loss : 0.036048, loss_ce: 0.013355
2021-11-30 13:50:29,224 iteration 988 : loss : 0.037372, loss_ce: 0.014548
2021-11-30 13:50:30,443 iteration 989 : loss : 0.051829, loss_ce: 0.018113
2021-11-30 13:50:31,669 iteration 990 : loss : 0.044386, loss_ce: 0.014971
2021-11-30 13:50:32,889 iteration 991 : loss : 0.036197, loss_ce: 0.014230
2021-11-30 13:50:34,113 iteration 992 : loss : 0.038532, loss_ce: 0.015408
2021-11-30 13:50:35,334 iteration 993 : loss : 0.026151, loss_ce: 0.009761
2021-11-30 13:50:36,560 iteration 994 : loss : 0.033568, loss_ce: 0.014979
2021-11-30 13:50:37,781 iteration 995 : loss : 0.035448, loss_ce: 0.012536
2021-11-30 13:50:39,002 iteration 996 : loss : 0.035570, loss_ce: 0.015028
2021-11-30 13:50:40,221 iteration 997 : loss : 0.037561, loss_ce: 0.013051
2021-11-30 13:50:41,442 iteration 998 : loss : 0.038351, loss_ce: 0.016488
2021-11-30 13:50:42,672 iteration 999 : loss : 0.030694, loss_ce: 0.012878
2021-11-30 13:50:43,897 iteration 1000 : loss : 0.034810, loss_ce: 0.014590
2021-11-30 13:50:45,119 iteration 1001 : loss : 0.047402, loss_ce: 0.023190
2021-11-30 13:50:46,339 iteration 1002 : loss : 0.033727, loss_ce: 0.016628
2021-11-30 13:50:47,565 iteration 1003 : loss : 0.035597, loss_ce: 0.013407
 15%|████▍                         | 59/400 [22:21<2:03:14, 21.68s/it]2021-11-30 13:50:48,853 iteration 1004 : loss : 0.056906, loss_ce: 0.016564
2021-11-30 13:50:50,070 iteration 1005 : loss : 0.035322, loss_ce: 0.014086
2021-11-30 13:50:51,291 iteration 1006 : loss : 0.028647, loss_ce: 0.011816
2021-11-30 13:50:52,509 iteration 1007 : loss : 0.032765, loss_ce: 0.012537
2021-11-30 13:50:53,729 iteration 1008 : loss : 0.034238, loss_ce: 0.014691
2021-11-30 13:50:54,947 iteration 1009 : loss : 0.033141, loss_ce: 0.012889
2021-11-30 13:50:56,174 iteration 1010 : loss : 0.036414, loss_ce: 0.015071
2021-11-30 13:50:57,389 iteration 1011 : loss : 0.036708, loss_ce: 0.013111
2021-11-30 13:50:58,611 iteration 1012 : loss : 0.036851, loss_ce: 0.014158
2021-11-30 13:50:59,830 iteration 1013 : loss : 0.041923, loss_ce: 0.015015
2021-11-30 13:51:01,051 iteration 1014 : loss : 0.027990, loss_ce: 0.010440
2021-11-30 13:51:02,278 iteration 1015 : loss : 0.031804, loss_ce: 0.012913
2021-11-30 13:51:03,499 iteration 1016 : loss : 0.043005, loss_ce: 0.014863
2021-11-30 13:51:04,723 iteration 1017 : loss : 0.035121, loss_ce: 0.017039
2021-11-30 13:51:05,942 iteration 1018 : loss : 0.034066, loss_ce: 0.014130
2021-11-30 13:51:07,165 iteration 1019 : loss : 0.034837, loss_ce: 0.018409
2021-11-30 13:51:07,165 Training Data Eval:
2021-11-30 13:51:14,086   Average segmentation loss on training set: 0.0433
2021-11-30 13:51:14,087 Validation Data Eval:
2021-11-30 13:51:16,470   Average segmentation loss on validation set: 0.1562
2021-11-30 13:51:17,698 iteration 1020 : loss : 0.037728, loss_ce: 0.012928
 15%|████▌                         | 60/400 [22:51<2:17:14, 24.22s/it]2021-11-30 13:51:18,982 iteration 1021 : loss : 0.049028, loss_ce: 0.015370
2021-11-30 13:51:20,202 iteration 1022 : loss : 0.035186, loss_ce: 0.020527
2021-11-30 13:51:21,419 iteration 1023 : loss : 0.037848, loss_ce: 0.015164
2021-11-30 13:51:22,637 iteration 1024 : loss : 0.039073, loss_ce: 0.015201
2021-11-30 13:51:23,858 iteration 1025 : loss : 0.029296, loss_ce: 0.013233
2021-11-30 13:51:25,072 iteration 1026 : loss : 0.042350, loss_ce: 0.014864
2021-11-30 13:51:26,298 iteration 1027 : loss : 0.031712, loss_ce: 0.013737
2021-11-30 13:51:27,522 iteration 1028 : loss : 0.050596, loss_ce: 0.025017
2021-11-30 13:51:28,740 iteration 1029 : loss : 0.040775, loss_ce: 0.016267
2021-11-30 13:51:29,965 iteration 1030 : loss : 0.037213, loss_ce: 0.017953
2021-11-30 13:51:31,192 iteration 1031 : loss : 0.034464, loss_ce: 0.014278
2021-11-30 13:51:32,416 iteration 1032 : loss : 0.041584, loss_ce: 0.019042
2021-11-30 13:51:33,637 iteration 1033 : loss : 0.037371, loss_ce: 0.016163
2021-11-30 13:51:34,856 iteration 1034 : loss : 0.034104, loss_ce: 0.011407
2021-11-30 13:51:36,081 iteration 1035 : loss : 0.074844, loss_ce: 0.022155
2021-11-30 13:51:37,296 iteration 1036 : loss : 0.035516, loss_ce: 0.014072
2021-11-30 13:51:38,521 iteration 1037 : loss : 0.043742, loss_ce: 0.017468
 15%|████▌                         | 61/400 [23:12<2:11:05, 23.20s/it]2021-11-30 13:51:39,810 iteration 1038 : loss : 0.036631, loss_ce: 0.014482
2021-11-30 13:51:41,036 iteration 1039 : loss : 0.046068, loss_ce: 0.021149
2021-11-30 13:51:42,251 iteration 1040 : loss : 0.117308, loss_ce: 0.012877
2021-11-30 13:51:43,469 iteration 1041 : loss : 0.052438, loss_ce: 0.023102
2021-11-30 13:51:44,697 iteration 1042 : loss : 0.086849, loss_ce: 0.020555
2021-11-30 13:51:45,922 iteration 1043 : loss : 0.050199, loss_ce: 0.014291
2021-11-30 13:51:47,144 iteration 1044 : loss : 0.054889, loss_ce: 0.026565
2021-11-30 13:51:48,372 iteration 1045 : loss : 0.058743, loss_ce: 0.028573
2021-11-30 13:51:49,596 iteration 1046 : loss : 0.040257, loss_ce: 0.017228
2021-11-30 13:51:50,820 iteration 1047 : loss : 0.033510, loss_ce: 0.014835
2021-11-30 13:51:52,044 iteration 1048 : loss : 0.041674, loss_ce: 0.015578
2021-11-30 13:51:53,270 iteration 1049 : loss : 0.050865, loss_ce: 0.019054
2021-11-30 13:51:54,500 iteration 1050 : loss : 0.045581, loss_ce: 0.018397
2021-11-30 13:51:55,723 iteration 1051 : loss : 0.041196, loss_ce: 0.017883
2021-11-30 13:51:56,945 iteration 1052 : loss : 0.056226, loss_ce: 0.023943
2021-11-30 13:51:58,168 iteration 1053 : loss : 0.049487, loss_ce: 0.016725
2021-11-30 13:51:59,395 iteration 1054 : loss : 0.046867, loss_ce: 0.021178
 16%|████▋                         | 62/400 [23:33<2:06:45, 22.50s/it]2021-11-30 13:52:00,687 iteration 1055 : loss : 0.057117, loss_ce: 0.017010
2021-11-30 13:52:01,904 iteration 1056 : loss : 0.041469, loss_ce: 0.020056
2021-11-30 13:52:03,127 iteration 1057 : loss : 0.035612, loss_ce: 0.016028
2021-11-30 13:52:04,349 iteration 1058 : loss : 0.037579, loss_ce: 0.015220
2021-11-30 13:52:05,567 iteration 1059 : loss : 0.044399, loss_ce: 0.014261
2021-11-30 13:52:06,796 iteration 1060 : loss : 0.036380, loss_ce: 0.013674
2021-11-30 13:52:08,017 iteration 1061 : loss : 0.044243, loss_ce: 0.018412
2021-11-30 13:52:09,236 iteration 1062 : loss : 0.037379, loss_ce: 0.018436
2021-11-30 13:52:10,460 iteration 1063 : loss : 0.039724, loss_ce: 0.017798
2021-11-30 13:52:11,684 iteration 1064 : loss : 0.038268, loss_ce: 0.014443
2021-11-30 13:52:12,908 iteration 1065 : loss : 0.053315, loss_ce: 0.017119
2021-11-30 13:52:14,129 iteration 1066 : loss : 0.042305, loss_ce: 0.015178
2021-11-30 13:52:15,354 iteration 1067 : loss : 0.079254, loss_ce: 0.021669
2021-11-30 13:52:16,562 iteration 1068 : loss : 0.043426, loss_ce: 0.016801
2021-11-30 13:52:17,783 iteration 1069 : loss : 0.035329, loss_ce: 0.012953
2021-11-30 13:52:19,007 iteration 1070 : loss : 0.040554, loss_ce: 0.014404
2021-11-30 13:52:20,226 iteration 1071 : loss : 0.044426, loss_ce: 0.016171
 16%|████▋                         | 63/400 [23:54<2:03:34, 22.00s/it]2021-11-30 13:52:21,512 iteration 1072 : loss : 0.046129, loss_ce: 0.018625
2021-11-30 13:52:22,736 iteration 1073 : loss : 0.037619, loss_ce: 0.009072
2021-11-30 13:52:23,959 iteration 1074 : loss : 0.038741, loss_ce: 0.014100
2021-11-30 13:52:25,171 iteration 1075 : loss : 0.056373, loss_ce: 0.021247
2021-11-30 13:52:26,392 iteration 1076 : loss : 0.046348, loss_ce: 0.022013
2021-11-30 13:52:27,612 iteration 1077 : loss : 0.124243, loss_ce: 0.032701
2021-11-30 13:52:28,836 iteration 1078 : loss : 0.037418, loss_ce: 0.014279
2021-11-30 13:52:30,059 iteration 1079 : loss : 0.049882, loss_ce: 0.023022
2021-11-30 13:52:31,275 iteration 1080 : loss : 0.054811, loss_ce: 0.022257
2021-11-30 13:52:32,503 iteration 1081 : loss : 0.048604, loss_ce: 0.016548
2021-11-30 13:52:33,726 iteration 1082 : loss : 0.041267, loss_ce: 0.021558
2021-11-30 13:52:34,923 iteration 1083 : loss : 0.051725, loss_ce: 0.015426
2021-11-30 13:52:36,141 iteration 1084 : loss : 0.056467, loss_ce: 0.021906
2021-11-30 13:52:37,358 iteration 1085 : loss : 0.041463, loss_ce: 0.013389
2021-11-30 13:52:38,582 iteration 1086 : loss : 0.042058, loss_ce: 0.017616
2021-11-30 13:52:39,807 iteration 1087 : loss : 0.036227, loss_ce: 0.015177
2021-11-30 13:52:41,032 iteration 1088 : loss : 0.044458, loss_ce: 0.021057
 16%|████▊                         | 64/400 [24:15<2:01:12, 21.64s/it]2021-11-30 13:52:42,323 iteration 1089 : loss : 0.037620, loss_ce: 0.016204
2021-11-30 13:52:43,542 iteration 1090 : loss : 0.045204, loss_ce: 0.019281
2021-11-30 13:52:44,764 iteration 1091 : loss : 0.046239, loss_ce: 0.015807
2021-11-30 13:52:45,988 iteration 1092 : loss : 0.042101, loss_ce: 0.010953
2021-11-30 13:52:47,209 iteration 1093 : loss : 0.031632, loss_ce: 0.015320
2021-11-30 13:52:48,437 iteration 1094 : loss : 0.039752, loss_ce: 0.023114
2021-11-30 13:52:49,657 iteration 1095 : loss : 0.031089, loss_ce: 0.012033
2021-11-30 13:52:50,880 iteration 1096 : loss : 0.038060, loss_ce: 0.011182
2021-11-30 13:52:52,100 iteration 1097 : loss : 0.044789, loss_ce: 0.013884
2021-11-30 13:52:53,327 iteration 1098 : loss : 0.042394, loss_ce: 0.016125
2021-11-30 13:52:54,553 iteration 1099 : loss : 0.036656, loss_ce: 0.013050
2021-11-30 13:52:55,770 iteration 1100 : loss : 0.031545, loss_ce: 0.011933
2021-11-30 13:52:56,992 iteration 1101 : loss : 0.039835, loss_ce: 0.017270
2021-11-30 13:52:58,228 iteration 1102 : loss : 0.057651, loss_ce: 0.024461
2021-11-30 13:52:59,450 iteration 1103 : loss : 0.047278, loss_ce: 0.017571
2021-11-30 13:53:00,668 iteration 1104 : loss : 0.052757, loss_ce: 0.015914
2021-11-30 13:53:00,669 Training Data Eval:
2021-11-30 13:53:07,574   Average segmentation loss on training set: 0.0505
2021-11-30 13:53:07,574 Validation Data Eval:
2021-11-30 13:53:09,941   Average segmentation loss on validation set: 0.1644
2021-11-30 13:53:11,163 iteration 1105 : loss : 0.039266, loss_ce: 0.016407
 16%|████▉                         | 65/400 [24:45<2:15:03, 24.19s/it]2021-11-30 13:53:12,454 iteration 1106 : loss : 0.037627, loss_ce: 0.016595
2021-11-30 13:53:13,673 iteration 1107 : loss : 0.048383, loss_ce: 0.018946
2021-11-30 13:53:14,891 iteration 1108 : loss : 0.045576, loss_ce: 0.015062
2021-11-30 13:53:16,116 iteration 1109 : loss : 0.044649, loss_ce: 0.014859
2021-11-30 13:53:17,341 iteration 1110 : loss : 0.047686, loss_ce: 0.012983
2021-11-30 13:53:18,565 iteration 1111 : loss : 0.034337, loss_ce: 0.014617
2021-11-30 13:53:19,786 iteration 1112 : loss : 0.046145, loss_ce: 0.021825
2021-11-30 13:53:21,010 iteration 1113 : loss : 0.050813, loss_ce: 0.022143
2021-11-30 13:53:22,241 iteration 1114 : loss : 0.026477, loss_ce: 0.010739
2021-11-30 13:53:23,466 iteration 1115 : loss : 0.051096, loss_ce: 0.031387
2021-11-30 13:53:24,694 iteration 1116 : loss : 0.036829, loss_ce: 0.015021
2021-11-30 13:53:25,915 iteration 1117 : loss : 0.042134, loss_ce: 0.011512
2021-11-30 13:53:27,142 iteration 1118 : loss : 0.042740, loss_ce: 0.014934
2021-11-30 13:53:28,370 iteration 1119 : loss : 0.030926, loss_ce: 0.012611
2021-11-30 13:53:29,596 iteration 1120 : loss : 0.046818, loss_ce: 0.021872
2021-11-30 13:53:30,825 iteration 1121 : loss : 0.040245, loss_ce: 0.014892
2021-11-30 13:53:32,049 iteration 1122 : loss : 0.036320, loss_ce: 0.015349
 16%|████▉                         | 66/400 [25:06<2:09:08, 23.20s/it]2021-11-30 13:53:33,345 iteration 1123 : loss : 0.051987, loss_ce: 0.018125
2021-11-30 13:53:34,565 iteration 1124 : loss : 0.038515, loss_ce: 0.014396
2021-11-30 13:53:35,790 iteration 1125 : loss : 0.039595, loss_ce: 0.015382
2021-11-30 13:53:37,019 iteration 1126 : loss : 0.035892, loss_ce: 0.016327
2021-11-30 13:53:38,243 iteration 1127 : loss : 0.057151, loss_ce: 0.016739
2021-11-30 13:53:39,469 iteration 1128 : loss : 0.036523, loss_ce: 0.014933
2021-11-30 13:53:40,692 iteration 1129 : loss : 0.032613, loss_ce: 0.012666
2021-11-30 13:53:41,919 iteration 1130 : loss : 0.041372, loss_ce: 0.017887
2021-11-30 13:53:43,143 iteration 1131 : loss : 0.038706, loss_ce: 0.018192
2021-11-30 13:53:44,364 iteration 1132 : loss : 0.034774, loss_ce: 0.015248
2021-11-30 13:53:45,586 iteration 1133 : loss : 0.030484, loss_ce: 0.014324
2021-11-30 13:53:46,815 iteration 1134 : loss : 0.035253, loss_ce: 0.015761
2021-11-30 13:53:48,038 iteration 1135 : loss : 0.043165, loss_ce: 0.013801
2021-11-30 13:53:49,267 iteration 1136 : loss : 0.041498, loss_ce: 0.012634
2021-11-30 13:53:50,487 iteration 1137 : loss : 0.050873, loss_ce: 0.011965
2021-11-30 13:53:51,710 iteration 1138 : loss : 0.040844, loss_ce: 0.018652
2021-11-30 13:53:52,932 iteration 1139 : loss : 0.035671, loss_ce: 0.016965
 17%|█████                         | 67/400 [25:26<2:04:53, 22.50s/it]2021-11-30 13:53:54,232 iteration 1140 : loss : 0.036295, loss_ce: 0.012498
2021-11-30 13:53:55,457 iteration 1141 : loss : 0.033564, loss_ce: 0.013257
2021-11-30 13:53:56,686 iteration 1142 : loss : 0.032954, loss_ce: 0.012607
2021-11-30 13:53:57,910 iteration 1143 : loss : 0.043229, loss_ce: 0.013624
2021-11-30 13:53:59,139 iteration 1144 : loss : 0.035727, loss_ce: 0.011308
2021-11-30 13:54:00,361 iteration 1145 : loss : 0.029689, loss_ce: 0.013267
2021-11-30 13:54:01,581 iteration 1146 : loss : 0.040587, loss_ce: 0.018799
2021-11-30 13:54:02,807 iteration 1147 : loss : 0.040349, loss_ce: 0.021079
2021-11-30 13:54:04,028 iteration 1148 : loss : 0.032990, loss_ce: 0.010689
2021-11-30 13:54:05,258 iteration 1149 : loss : 0.024951, loss_ce: 0.010073
2021-11-30 13:54:06,476 iteration 1150 : loss : 0.035579, loss_ce: 0.013802
2021-11-30 13:54:07,692 iteration 1151 : loss : 0.033792, loss_ce: 0.013237
2021-11-30 13:54:08,922 iteration 1152 : loss : 0.041822, loss_ce: 0.015082
2021-11-30 13:54:10,149 iteration 1153 : loss : 0.031854, loss_ce: 0.012162
2021-11-30 13:54:11,375 iteration 1154 : loss : 0.034313, loss_ce: 0.012782
2021-11-30 13:54:12,595 iteration 1155 : loss : 0.032661, loss_ce: 0.013681
2021-11-30 13:54:13,819 iteration 1156 : loss : 0.022487, loss_ce: 0.009317
 17%|█████                         | 68/400 [25:47<2:01:50, 22.02s/it]2021-11-30 13:54:15,113 iteration 1157 : loss : 0.029600, loss_ce: 0.011316
2021-11-30 13:54:16,335 iteration 1158 : loss : 0.026423, loss_ce: 0.009026
2021-11-30 13:54:17,554 iteration 1159 : loss : 0.036834, loss_ce: 0.014693
2021-11-30 13:54:18,777 iteration 1160 : loss : 0.034441, loss_ce: 0.015211
2021-11-30 13:54:19,993 iteration 1161 : loss : 0.025281, loss_ce: 0.012607
2021-11-30 13:54:21,221 iteration 1162 : loss : 0.037079, loss_ce: 0.017818
2021-11-30 13:54:22,445 iteration 1163 : loss : 0.039579, loss_ce: 0.015181
2021-11-30 13:54:23,650 iteration 1164 : loss : 0.028846, loss_ce: 0.010102
2021-11-30 13:54:24,872 iteration 1165 : loss : 0.031856, loss_ce: 0.014162
2021-11-30 13:54:26,083 iteration 1166 : loss : 0.035090, loss_ce: 0.012382
2021-11-30 13:54:27,304 iteration 1167 : loss : 0.023111, loss_ce: 0.009292
2021-11-30 13:54:28,523 iteration 1168 : loss : 0.040515, loss_ce: 0.019573
2021-11-30 13:54:29,740 iteration 1169 : loss : 0.029951, loss_ce: 0.013665
2021-11-30 13:54:30,949 iteration 1170 : loss : 0.038563, loss_ce: 0.015123
2021-11-30 13:54:32,202 iteration 1171 : loss : 0.030879, loss_ce: 0.012509
2021-11-30 13:54:33,429 iteration 1172 : loss : 0.024289, loss_ce: 0.010170
2021-11-30 13:54:34,655 iteration 1173 : loss : 0.030528, loss_ce: 0.010948
 17%|█████▏                        | 69/400 [26:08<1:59:30, 21.66s/it]2021-11-30 13:54:35,944 iteration 1174 : loss : 0.028863, loss_ce: 0.011497
2021-11-30 13:54:37,160 iteration 1175 : loss : 0.033459, loss_ce: 0.015100
2021-11-30 13:54:38,373 iteration 1176 : loss : 0.035046, loss_ce: 0.019569
2021-11-30 13:54:39,580 iteration 1177 : loss : 0.041753, loss_ce: 0.019419
2021-11-30 13:54:40,793 iteration 1178 : loss : 0.034352, loss_ce: 0.013452
2021-11-30 13:54:42,012 iteration 1179 : loss : 0.027946, loss_ce: 0.013814
2021-11-30 13:54:43,236 iteration 1180 : loss : 0.047446, loss_ce: 0.016582
2021-11-30 13:54:44,458 iteration 1181 : loss : 0.024526, loss_ce: 0.008796
2021-11-30 13:54:45,680 iteration 1182 : loss : 0.040861, loss_ce: 0.014600
2021-11-30 13:54:46,899 iteration 1183 : loss : 0.027154, loss_ce: 0.009275
2021-11-30 13:54:48,118 iteration 1184 : loss : 0.038878, loss_ce: 0.015818
2021-11-30 13:54:49,339 iteration 1185 : loss : 0.032246, loss_ce: 0.009546
2021-11-30 13:54:50,560 iteration 1186 : loss : 0.031784, loss_ce: 0.013717
2021-11-30 13:54:51,775 iteration 1187 : loss : 0.036334, loss_ce: 0.014488
2021-11-30 13:54:52,994 iteration 1188 : loss : 0.027453, loss_ce: 0.010564
2021-11-30 13:54:54,213 iteration 1189 : loss : 0.028673, loss_ce: 0.011287
2021-11-30 13:54:54,214 Training Data Eval:
2021-11-30 13:55:01,126   Average segmentation loss on training set: 0.0282
2021-11-30 13:55:01,127 Validation Data Eval:
2021-11-30 13:55:03,514   Average segmentation loss on validation set: 0.1118
2021-11-30 13:55:04,735 iteration 1190 : loss : 0.033623, loss_ce: 0.012458
 18%|█████▎                        | 70/400 [26:38<2:13:02, 24.19s/it]2021-11-30 13:55:06,034 iteration 1191 : loss : 0.033619, loss_ce: 0.015895
2021-11-30 13:55:07,255 iteration 1192 : loss : 0.025984, loss_ce: 0.010894
2021-11-30 13:55:08,477 iteration 1193 : loss : 0.025649, loss_ce: 0.012221
2021-11-30 13:55:09,701 iteration 1194 : loss : 0.027043, loss_ce: 0.012374
2021-11-30 13:55:10,923 iteration 1195 : loss : 0.026787, loss_ce: 0.010774
2021-11-30 13:55:12,148 iteration 1196 : loss : 0.037606, loss_ce: 0.013092
2021-11-30 13:55:13,367 iteration 1197 : loss : 0.042471, loss_ce: 0.013115
2021-11-30 13:55:14,594 iteration 1198 : loss : 0.031992, loss_ce: 0.009802
2021-11-30 13:55:15,815 iteration 1199 : loss : 0.033577, loss_ce: 0.014566
2021-11-30 13:55:17,036 iteration 1200 : loss : 0.031037, loss_ce: 0.013258
2021-11-30 13:55:18,253 iteration 1201 : loss : 0.025577, loss_ce: 0.009735
2021-11-30 13:55:19,471 iteration 1202 : loss : 0.036233, loss_ce: 0.011080
2021-11-30 13:55:20,694 iteration 1203 : loss : 0.036800, loss_ce: 0.012563
2021-11-30 13:55:21,919 iteration 1204 : loss : 0.031888, loss_ce: 0.014320
2021-11-30 13:55:23,144 iteration 1205 : loss : 0.034787, loss_ce: 0.010642
2021-11-30 13:55:24,360 iteration 1206 : loss : 0.023861, loss_ce: 0.008903
2021-11-30 13:55:25,580 iteration 1207 : loss : 0.034231, loss_ce: 0.011678
 18%|█████▎                        | 71/400 [26:59<2:07:08, 23.19s/it]2021-11-30 13:55:26,868 iteration 1208 : loss : 0.028256, loss_ce: 0.010286
2021-11-30 13:55:28,088 iteration 1209 : loss : 0.038436, loss_ce: 0.014774
2021-11-30 13:55:29,309 iteration 1210 : loss : 0.023085, loss_ce: 0.010134
2021-11-30 13:55:30,529 iteration 1211 : loss : 0.026576, loss_ce: 0.009020
2021-11-30 13:55:31,753 iteration 1212 : loss : 0.030676, loss_ce: 0.014230
2021-11-30 13:55:32,972 iteration 1213 : loss : 0.030108, loss_ce: 0.011303
2021-11-30 13:55:34,196 iteration 1214 : loss : 0.026133, loss_ce: 0.011129
2021-11-30 13:55:35,420 iteration 1215 : loss : 0.021500, loss_ce: 0.009738
2021-11-30 13:55:36,642 iteration 1216 : loss : 0.027161, loss_ce: 0.011441
2021-11-30 13:55:37,864 iteration 1217 : loss : 0.026077, loss_ce: 0.010370
2021-11-30 13:55:39,081 iteration 1218 : loss : 0.039675, loss_ce: 0.015080
2021-11-30 13:55:40,307 iteration 1219 : loss : 0.027000, loss_ce: 0.010267
2021-11-30 13:55:41,525 iteration 1220 : loss : 0.033503, loss_ce: 0.010296
2021-11-30 13:55:42,749 iteration 1221 : loss : 0.032381, loss_ce: 0.013002
2021-11-30 13:55:43,975 iteration 1222 : loss : 0.044887, loss_ce: 0.020527
2021-11-30 13:55:45,192 iteration 1223 : loss : 0.033585, loss_ce: 0.012002
2021-11-30 13:55:46,409 iteration 1224 : loss : 0.032848, loss_ce: 0.012427
 18%|█████▍                        | 72/400 [27:20<2:02:52, 22.48s/it]2021-11-30 13:55:47,694 iteration 1225 : loss : 0.026747, loss_ce: 0.012022
2021-11-30 13:55:48,914 iteration 1226 : loss : 0.035920, loss_ce: 0.011229
2021-11-30 13:55:50,143 iteration 1227 : loss : 0.028801, loss_ce: 0.011800
2021-11-30 13:55:51,360 iteration 1228 : loss : 0.036252, loss_ce: 0.009915
2021-11-30 13:55:52,581 iteration 1229 : loss : 0.030579, loss_ce: 0.012230
2021-11-30 13:55:53,804 iteration 1230 : loss : 0.026565, loss_ce: 0.009623
2021-11-30 13:55:55,030 iteration 1231 : loss : 0.029491, loss_ce: 0.011094
2021-11-30 13:55:56,252 iteration 1232 : loss : 0.032831, loss_ce: 0.013138
2021-11-30 13:55:57,472 iteration 1233 : loss : 0.033050, loss_ce: 0.016488
2021-11-30 13:55:58,698 iteration 1234 : loss : 0.024611, loss_ce: 0.008971
2021-11-30 13:55:59,917 iteration 1235 : loss : 0.029961, loss_ce: 0.010111
2021-11-30 13:56:01,142 iteration 1236 : loss : 0.027032, loss_ce: 0.013322
2021-11-30 13:56:02,373 iteration 1237 : loss : 0.026571, loss_ce: 0.009887
2021-11-30 13:56:03,593 iteration 1238 : loss : 0.028376, loss_ce: 0.011320
2021-11-30 13:56:04,821 iteration 1239 : loss : 0.032846, loss_ce: 0.013866
2021-11-30 13:56:06,044 iteration 1240 : loss : 0.028829, loss_ce: 0.010178
2021-11-30 13:56:07,268 iteration 1241 : loss : 0.023490, loss_ce: 0.011228
 18%|█████▍                        | 73/400 [27:41<1:59:51, 21.99s/it]2021-11-30 13:56:08,561 iteration 1242 : loss : 0.026878, loss_ce: 0.008731
2021-11-30 13:56:09,790 iteration 1243 : loss : 0.043298, loss_ce: 0.018581
2021-11-30 13:56:11,013 iteration 1244 : loss : 0.025061, loss_ce: 0.011292
2021-11-30 13:56:12,240 iteration 1245 : loss : 0.024982, loss_ce: 0.011716
2021-11-30 13:56:13,463 iteration 1246 : loss : 0.030286, loss_ce: 0.012880
2021-11-30 13:56:14,681 iteration 1247 : loss : 0.029748, loss_ce: 0.009359
2021-11-30 13:56:15,902 iteration 1248 : loss : 0.031713, loss_ce: 0.012647
2021-11-30 13:56:17,125 iteration 1249 : loss : 0.037199, loss_ce: 0.012456
2021-11-30 13:56:18,351 iteration 1250 : loss : 0.032749, loss_ce: 0.013792
2021-11-30 13:56:19,577 iteration 1251 : loss : 0.025384, loss_ce: 0.011499
2021-11-30 13:56:20,801 iteration 1252 : loss : 0.028429, loss_ce: 0.009395
2021-11-30 13:56:22,025 iteration 1253 : loss : 0.026410, loss_ce: 0.011532
2021-11-30 13:56:23,247 iteration 1254 : loss : 0.030355, loss_ce: 0.015550
2021-11-30 13:56:24,474 iteration 1255 : loss : 0.028017, loss_ce: 0.013548
2021-11-30 13:56:25,692 iteration 1256 : loss : 0.035014, loss_ce: 0.013288
2021-11-30 13:56:26,911 iteration 1257 : loss : 0.033079, loss_ce: 0.011286
2021-11-30 13:56:28,131 iteration 1258 : loss : 0.034373, loss_ce: 0.010273
 18%|█████▌                        | 74/400 [28:02<1:57:39, 21.65s/it]2021-11-30 13:56:29,424 iteration 1259 : loss : 0.031118, loss_ce: 0.014267
2021-11-30 13:56:30,649 iteration 1260 : loss : 0.035498, loss_ce: 0.011752
2021-11-30 13:56:31,876 iteration 1261 : loss : 0.027820, loss_ce: 0.008924
2021-11-30 13:56:33,106 iteration 1262 : loss : 0.027634, loss_ce: 0.009121
2021-11-30 13:56:34,330 iteration 1263 : loss : 0.027363, loss_ce: 0.009790
2021-11-30 13:56:35,555 iteration 1264 : loss : 0.035270, loss_ce: 0.015558
2021-11-30 13:56:36,776 iteration 1265 : loss : 0.021131, loss_ce: 0.007810
2021-11-30 13:56:37,990 iteration 1266 : loss : 0.028594, loss_ce: 0.014172
2021-11-30 13:56:39,216 iteration 1267 : loss : 0.041114, loss_ce: 0.013999
2021-11-30 13:56:40,436 iteration 1268 : loss : 0.033016, loss_ce: 0.012822
2021-11-30 13:56:41,652 iteration 1269 : loss : 0.035189, loss_ce: 0.015326
2021-11-30 13:56:42,876 iteration 1270 : loss : 0.029997, loss_ce: 0.011352
2021-11-30 13:56:44,099 iteration 1271 : loss : 0.032919, loss_ce: 0.015895
2021-11-30 13:56:45,318 iteration 1272 : loss : 0.032358, loss_ce: 0.009571
2021-11-30 13:56:46,541 iteration 1273 : loss : 0.044525, loss_ce: 0.014897
2021-11-30 13:56:47,767 iteration 1274 : loss : 0.024937, loss_ce: 0.010990
2021-11-30 13:56:47,768 Training Data Eval:
2021-11-30 13:56:54,670   Average segmentation loss on training set: 0.0267
2021-11-30 13:56:54,670 Validation Data Eval:
2021-11-30 13:56:57,033   Average segmentation loss on validation set: 0.1242
2021-11-30 13:56:58,259 iteration 1275 : loss : 0.024859, loss_ce: 0.009352
 19%|█████▋                        | 75/400 [28:32<2:11:03, 24.20s/it]2021-11-30 13:56:59,555 iteration 1276 : loss : 0.027095, loss_ce: 0.011150
2021-11-30 13:57:00,777 iteration 1277 : loss : 0.033456, loss_ce: 0.011456
2021-11-30 13:57:02,004 iteration 1278 : loss : 0.033513, loss_ce: 0.011723
2021-11-30 13:57:03,226 iteration 1279 : loss : 0.033867, loss_ce: 0.015159
2021-11-30 13:57:04,452 iteration 1280 : loss : 0.027935, loss_ce: 0.011241
2021-11-30 13:57:05,680 iteration 1281 : loss : 0.023569, loss_ce: 0.009075
2021-11-30 13:57:06,903 iteration 1282 : loss : 0.032413, loss_ce: 0.009626
2021-11-30 13:57:08,127 iteration 1283 : loss : 0.039522, loss_ce: 0.015524
2021-11-30 13:57:09,350 iteration 1284 : loss : 0.032178, loss_ce: 0.013234
2021-11-30 13:57:10,573 iteration 1285 : loss : 0.027943, loss_ce: 0.011264
2021-11-30 13:57:11,799 iteration 1286 : loss : 0.031042, loss_ce: 0.012621
2021-11-30 13:57:13,015 iteration 1287 : loss : 0.029522, loss_ce: 0.012178
2021-11-30 13:57:14,237 iteration 1288 : loss : 0.032659, loss_ce: 0.011917
2021-11-30 13:57:15,466 iteration 1289 : loss : 0.028305, loss_ce: 0.013084
2021-11-30 13:57:16,694 iteration 1290 : loss : 0.023787, loss_ce: 0.009969
2021-11-30 13:57:17,914 iteration 1291 : loss : 0.029522, loss_ce: 0.008709
2021-11-30 13:57:19,137 iteration 1292 : loss : 0.026850, loss_ce: 0.009530
 19%|█████▋                        | 76/400 [28:53<2:05:16, 23.20s/it]2021-11-30 13:57:20,423 iteration 1293 : loss : 0.027409, loss_ce: 0.008976
2021-11-30 13:57:21,640 iteration 1294 : loss : 0.026699, loss_ce: 0.009295
2021-11-30 13:57:22,866 iteration 1295 : loss : 0.034732, loss_ce: 0.011309
2021-11-30 13:57:24,088 iteration 1296 : loss : 0.023063, loss_ce: 0.008544
2021-11-30 13:57:25,306 iteration 1297 : loss : 0.028168, loss_ce: 0.015644
2021-11-30 13:57:26,534 iteration 1298 : loss : 0.037084, loss_ce: 0.020267
2021-11-30 13:57:27,762 iteration 1299 : loss : 0.028932, loss_ce: 0.009234
2021-11-30 13:57:28,986 iteration 1300 : loss : 0.024751, loss_ce: 0.010229
2021-11-30 13:57:30,208 iteration 1301 : loss : 0.029223, loss_ce: 0.014025
2021-11-30 13:57:31,432 iteration 1302 : loss : 0.028881, loss_ce: 0.011066
2021-11-30 13:57:32,659 iteration 1303 : loss : 0.027685, loss_ce: 0.012705
2021-11-30 13:57:33,889 iteration 1304 : loss : 0.026596, loss_ce: 0.011423
2021-11-30 13:57:35,113 iteration 1305 : loss : 0.034065, loss_ce: 0.014419
2021-11-30 13:57:36,341 iteration 1306 : loss : 0.027186, loss_ce: 0.010321
2021-11-30 13:57:37,559 iteration 1307 : loss : 0.023020, loss_ce: 0.010691
2021-11-30 13:57:38,789 iteration 1308 : loss : 0.030306, loss_ce: 0.010553
2021-11-30 13:57:40,011 iteration 1309 : loss : 0.032177, loss_ce: 0.013633
 19%|█████▊                        | 77/400 [29:14<2:01:08, 22.50s/it]2021-11-30 13:57:41,302 iteration 1310 : loss : 0.029619, loss_ce: 0.015805
2021-11-30 13:57:42,520 iteration 1311 : loss : 0.024665, loss_ce: 0.009120
2021-11-30 13:57:43,743 iteration 1312 : loss : 0.028043, loss_ce: 0.009902
2021-11-30 13:57:44,968 iteration 1313 : loss : 0.024347, loss_ce: 0.009165
2021-11-30 13:57:46,195 iteration 1314 : loss : 0.027499, loss_ce: 0.011010
2021-11-30 13:57:47,414 iteration 1315 : loss : 0.029489, loss_ce: 0.011784
2021-11-30 13:57:48,630 iteration 1316 : loss : 0.031100, loss_ce: 0.011014
2021-11-30 13:57:49,850 iteration 1317 : loss : 0.027420, loss_ce: 0.009063
2021-11-30 13:57:51,067 iteration 1318 : loss : 0.036668, loss_ce: 0.012646
2021-11-30 13:57:52,289 iteration 1319 : loss : 0.032124, loss_ce: 0.013417
2021-11-30 13:57:53,512 iteration 1320 : loss : 0.026770, loss_ce: 0.011958
2021-11-30 13:57:54,741 iteration 1321 : loss : 0.033708, loss_ce: 0.010253
2021-11-30 13:57:55,969 iteration 1322 : loss : 0.029773, loss_ce: 0.011053
2021-11-30 13:57:57,195 iteration 1323 : loss : 0.027246, loss_ce: 0.008514
2021-11-30 13:57:58,415 iteration 1324 : loss : 0.035448, loss_ce: 0.013013
2021-11-30 13:57:59,632 iteration 1325 : loss : 0.023869, loss_ce: 0.008927
2021-11-30 13:58:00,848 iteration 1326 : loss : 0.029893, loss_ce: 0.014061
 20%|█████▊                        | 78/400 [29:34<1:58:04, 22.00s/it]2021-11-30 13:58:02,129 iteration 1327 : loss : 0.026873, loss_ce: 0.012043
2021-11-30 13:58:03,349 iteration 1328 : loss : 0.025582, loss_ce: 0.011684
2021-11-30 13:58:04,579 iteration 1329 : loss : 0.030968, loss_ce: 0.010665
2021-11-30 13:58:05,806 iteration 1330 : loss : 0.022898, loss_ce: 0.009042
2021-11-30 13:58:07,026 iteration 1331 : loss : 0.023805, loss_ce: 0.008616
2021-11-30 13:58:08,249 iteration 1332 : loss : 0.027130, loss_ce: 0.008306
2021-11-30 13:58:09,468 iteration 1333 : loss : 0.025077, loss_ce: 0.012155
2021-11-30 13:58:10,697 iteration 1334 : loss : 0.024232, loss_ce: 0.009926
2021-11-30 13:58:11,918 iteration 1335 : loss : 0.025710, loss_ce: 0.011540
2021-11-30 13:58:13,148 iteration 1336 : loss : 0.026085, loss_ce: 0.009670
2021-11-30 13:58:14,364 iteration 1337 : loss : 0.023625, loss_ce: 0.010379
2021-11-30 13:58:15,586 iteration 1338 : loss : 0.026053, loss_ce: 0.009757
2021-11-30 13:58:16,805 iteration 1339 : loss : 0.028548, loss_ce: 0.012038
2021-11-30 13:58:18,019 iteration 1340 : loss : 0.025803, loss_ce: 0.012914
2021-11-30 13:58:19,235 iteration 1341 : loss : 0.025556, loss_ce: 0.010056
2021-11-30 13:58:20,459 iteration 1342 : loss : 0.033685, loss_ce: 0.010427
2021-11-30 13:58:21,678 iteration 1343 : loss : 0.030058, loss_ce: 0.014633
 20%|█████▉                        | 79/400 [29:55<1:55:50, 21.65s/it]2021-11-30 13:58:22,979 iteration 1344 : loss : 0.020019, loss_ce: 0.007668
2021-11-30 13:58:24,199 iteration 1345 : loss : 0.024123, loss_ce: 0.010113
2021-11-30 13:58:25,422 iteration 1346 : loss : 0.024134, loss_ce: 0.010039
2021-11-30 13:58:26,649 iteration 1347 : loss : 0.023383, loss_ce: 0.008062
2021-11-30 13:58:27,872 iteration 1348 : loss : 0.035425, loss_ce: 0.013227
2021-11-30 13:58:29,095 iteration 1349 : loss : 0.032999, loss_ce: 0.009452
2021-11-30 13:58:30,318 iteration 1350 : loss : 0.019219, loss_ce: 0.007122
2021-11-30 13:58:31,531 iteration 1351 : loss : 0.025323, loss_ce: 0.007102
2021-11-30 13:58:32,747 iteration 1352 : loss : 0.030622, loss_ce: 0.011960
2021-11-30 13:58:33,977 iteration 1353 : loss : 0.020886, loss_ce: 0.007052
2021-11-30 13:58:35,205 iteration 1354 : loss : 0.023716, loss_ce: 0.009107
2021-11-30 13:58:36,426 iteration 1355 : loss : 0.030619, loss_ce: 0.016588
2021-11-30 13:58:37,653 iteration 1356 : loss : 0.028253, loss_ce: 0.014571
2021-11-30 13:58:38,876 iteration 1357 : loss : 0.024249, loss_ce: 0.011640
2021-11-30 13:58:40,101 iteration 1358 : loss : 0.027663, loss_ce: 0.009671
2021-11-30 13:58:41,327 iteration 1359 : loss : 0.025004, loss_ce: 0.010784
2021-11-30 13:58:41,328 Training Data Eval:
2021-11-30 13:58:48,252   Average segmentation loss on training set: 0.0318
2021-11-30 13:58:48,252 Validation Data Eval:
2021-11-30 13:58:50,628   Average segmentation loss on validation set: 0.1242
2021-11-30 13:58:51,856 iteration 1360 : loss : 0.021805, loss_ce: 0.010222
 20%|██████                        | 80/400 [30:25<2:09:06, 24.21s/it]2021-11-30 13:58:53,153 iteration 1361 : loss : 0.035131, loss_ce: 0.012674
2021-11-30 13:58:54,379 iteration 1362 : loss : 0.029186, loss_ce: 0.011192
2021-11-30 13:58:55,603 iteration 1363 : loss : 0.032798, loss_ce: 0.010763
2021-11-30 13:58:56,828 iteration 1364 : loss : 0.023042, loss_ce: 0.008017
2021-11-30 13:58:58,044 iteration 1365 : loss : 0.021175, loss_ce: 0.008776
2021-11-30 13:58:59,267 iteration 1366 : loss : 0.023898, loss_ce: 0.007930
2021-11-30 13:59:00,492 iteration 1367 : loss : 0.045176, loss_ce: 0.026523
2021-11-30 13:59:01,719 iteration 1368 : loss : 0.025723, loss_ce: 0.013146
2021-11-30 13:59:02,941 iteration 1369 : loss : 0.025698, loss_ce: 0.009945
2021-11-30 13:59:04,166 iteration 1370 : loss : 0.024849, loss_ce: 0.009288
2021-11-30 13:59:05,397 iteration 1371 : loss : 0.033142, loss_ce: 0.011589
2021-11-30 13:59:06,621 iteration 1372 : loss : 0.031385, loss_ce: 0.012046
2021-11-30 13:59:07,843 iteration 1373 : loss : 0.029141, loss_ce: 0.013217
2021-11-30 13:59:09,066 iteration 1374 : loss : 0.039358, loss_ce: 0.017886
2021-11-30 13:59:10,287 iteration 1375 : loss : 0.028460, loss_ce: 0.012784
2021-11-30 13:59:11,514 iteration 1376 : loss : 0.037458, loss_ce: 0.016545
2021-11-30 13:59:12,740 iteration 1377 : loss : 0.022974, loss_ce: 0.010026
 20%|██████                        | 81/400 [30:46<2:03:24, 23.21s/it]2021-11-30 13:59:14,031 iteration 1378 : loss : 0.028157, loss_ce: 0.011097
2021-11-30 13:59:15,256 iteration 1379 : loss : 0.030828, loss_ce: 0.011069
2021-11-30 13:59:16,482 iteration 1380 : loss : 0.040875, loss_ce: 0.020361
2021-11-30 13:59:17,705 iteration 1381 : loss : 0.038198, loss_ce: 0.013453
2021-11-30 13:59:18,928 iteration 1382 : loss : 0.020597, loss_ce: 0.008720
2021-11-30 13:59:20,155 iteration 1383 : loss : 0.024908, loss_ce: 0.010420
2021-11-30 13:59:21,379 iteration 1384 : loss : 0.059409, loss_ce: 0.015593
2021-11-30 13:59:22,609 iteration 1385 : loss : 0.024452, loss_ce: 0.008439
2021-11-30 13:59:23,833 iteration 1386 : loss : 0.028239, loss_ce: 0.009857
2021-11-30 13:59:25,055 iteration 1387 : loss : 0.033576, loss_ce: 0.015505
2021-11-30 13:59:26,279 iteration 1388 : loss : 0.039176, loss_ce: 0.013156
2021-11-30 13:59:27,502 iteration 1389 : loss : 0.030984, loss_ce: 0.006378
2021-11-30 13:59:28,728 iteration 1390 : loss : 0.030079, loss_ce: 0.010580
2021-11-30 13:59:29,944 iteration 1391 : loss : 0.034732, loss_ce: 0.011599
2021-11-30 13:59:31,165 iteration 1392 : loss : 0.028598, loss_ce: 0.012040
2021-11-30 13:59:32,392 iteration 1393 : loss : 0.042464, loss_ce: 0.014506
2021-11-30 13:59:33,612 iteration 1394 : loss : 0.041724, loss_ce: 0.018452
 20%|██████▏                       | 82/400 [31:07<1:59:18, 22.51s/it]2021-11-30 13:59:34,908 iteration 1395 : loss : 0.038695, loss_ce: 0.013964
2021-11-30 13:59:36,129 iteration 1396 : loss : 0.026001, loss_ce: 0.010179
2021-11-30 13:59:37,353 iteration 1397 : loss : 0.033273, loss_ce: 0.015354
2021-11-30 13:59:38,579 iteration 1398 : loss : 0.029502, loss_ce: 0.013060
2021-11-30 13:59:39,805 iteration 1399 : loss : 0.038619, loss_ce: 0.014906
2021-11-30 13:59:41,029 iteration 1400 : loss : 0.028162, loss_ce: 0.012082
2021-11-30 13:59:42,251 iteration 1401 : loss : 0.032772, loss_ce: 0.011691
2021-11-30 13:59:43,471 iteration 1402 : loss : 0.029109, loss_ce: 0.011883
2021-11-30 13:59:44,691 iteration 1403 : loss : 0.043535, loss_ce: 0.011935
2021-11-30 13:59:45,918 iteration 1404 : loss : 0.029364, loss_ce: 0.011806
2021-11-30 13:59:47,140 iteration 1405 : loss : 0.041435, loss_ce: 0.016333
2021-11-30 13:59:48,364 iteration 1406 : loss : 0.036514, loss_ce: 0.013210
2021-11-30 13:59:49,601 iteration 1407 : loss : 0.034023, loss_ce: 0.012069
2021-11-30 13:59:50,829 iteration 1408 : loss : 0.039174, loss_ce: 0.011262
2021-11-30 13:59:52,047 iteration 1409 : loss : 0.020264, loss_ce: 0.008016
2021-11-30 13:59:53,268 iteration 1410 : loss : 0.022706, loss_ce: 0.009285
2021-11-30 13:59:54,495 iteration 1411 : loss : 0.030306, loss_ce: 0.013168
 21%|██████▏                       | 83/400 [31:28<1:56:20, 22.02s/it]2021-11-30 13:59:55,784 iteration 1412 : loss : 0.051308, loss_ce: 0.016781
2021-11-30 13:59:57,000 iteration 1413 : loss : 0.033981, loss_ce: 0.014115
2021-11-30 13:59:58,221 iteration 1414 : loss : 0.029182, loss_ce: 0.009096
2021-11-30 13:59:59,442 iteration 1415 : loss : 0.035151, loss_ce: 0.016645
2021-11-30 14:00:00,665 iteration 1416 : loss : 0.041630, loss_ce: 0.017725
2021-11-30 14:00:01,885 iteration 1417 : loss : 0.029802, loss_ce: 0.010039
2021-11-30 14:00:03,110 iteration 1418 : loss : 0.034103, loss_ce: 0.014290
2021-11-30 14:00:04,330 iteration 1419 : loss : 0.029521, loss_ce: 0.012457
2021-11-30 14:00:05,548 iteration 1420 : loss : 0.032307, loss_ce: 0.014475
2021-11-30 14:00:06,766 iteration 1421 : loss : 0.034835, loss_ce: 0.013945
2021-11-30 14:00:07,997 iteration 1422 : loss : 0.026728, loss_ce: 0.012969
2021-11-30 14:00:09,218 iteration 1423 : loss : 0.024461, loss_ce: 0.009994
2021-11-30 14:00:10,439 iteration 1424 : loss : 0.034063, loss_ce: 0.012692
2021-11-30 14:00:11,660 iteration 1425 : loss : 0.037228, loss_ce: 0.018388
2021-11-30 14:00:12,886 iteration 1426 : loss : 0.037245, loss_ce: 0.013342
2021-11-30 14:00:14,103 iteration 1427 : loss : 0.120613, loss_ce: 0.031829
2021-11-30 14:00:15,321 iteration 1428 : loss : 0.028175, loss_ce: 0.012895
 21%|██████▎                       | 84/400 [31:49<1:54:05, 21.66s/it]2021-11-30 14:00:16,614 iteration 1429 : loss : 0.031537, loss_ce: 0.014463
2021-11-30 14:00:17,826 iteration 1430 : loss : 0.056578, loss_ce: 0.028024
2021-11-30 14:00:19,050 iteration 1431 : loss : 0.038489, loss_ce: 0.013887
2021-11-30 14:00:20,269 iteration 1432 : loss : 0.043927, loss_ce: 0.015825
2021-11-30 14:00:21,495 iteration 1433 : loss : 0.035237, loss_ce: 0.012800
2021-11-30 14:00:22,712 iteration 1434 : loss : 0.032021, loss_ce: 0.010962
2021-11-30 14:00:23,926 iteration 1435 : loss : 0.027637, loss_ce: 0.008692
2021-11-30 14:00:25,144 iteration 1436 : loss : 0.037852, loss_ce: 0.017544
2021-11-30 14:00:26,363 iteration 1437 : loss : 0.028724, loss_ce: 0.011358
2021-11-30 14:00:27,586 iteration 1438 : loss : 0.034780, loss_ce: 0.013057
2021-11-30 14:00:28,807 iteration 1439 : loss : 0.036130, loss_ce: 0.014503
2021-11-30 14:00:30,028 iteration 1440 : loss : 0.028191, loss_ce: 0.009655
2021-11-30 14:00:31,244 iteration 1441 : loss : 0.029282, loss_ce: 0.010970
2021-11-30 14:00:32,457 iteration 1442 : loss : 0.032286, loss_ce: 0.014786
2021-11-30 14:00:33,676 iteration 1443 : loss : 0.034347, loss_ce: 0.012412
2021-11-30 14:00:34,900 iteration 1444 : loss : 0.031367, loss_ce: 0.011757
2021-11-30 14:00:34,900 Training Data Eval:
2021-11-30 14:00:41,816   Average segmentation loss on training set: 0.0455
2021-11-30 14:00:41,817 Validation Data Eval:
2021-11-30 14:00:44,190   Average segmentation loss on validation set: 0.1126
2021-11-30 14:00:45,420 iteration 1445 : loss : 0.041581, loss_ce: 0.012347
 21%|██████▍                       | 85/400 [32:19<2:07:00, 24.19s/it]2021-11-30 14:00:46,714 iteration 1446 : loss : 0.029151, loss_ce: 0.009717
2021-11-30 14:00:47,938 iteration 1447 : loss : 0.031101, loss_ce: 0.009237
2021-11-30 14:00:49,152 iteration 1448 : loss : 0.035909, loss_ce: 0.013762
2021-11-30 14:00:50,371 iteration 1449 : loss : 0.024514, loss_ce: 0.009632
2021-11-30 14:00:51,587 iteration 1450 : loss : 0.035994, loss_ce: 0.015174
2021-11-30 14:00:52,813 iteration 1451 : loss : 0.033712, loss_ce: 0.009798
2021-11-30 14:00:54,032 iteration 1452 : loss : 0.028988, loss_ce: 0.009669
2021-11-30 14:00:55,247 iteration 1453 : loss : 0.032155, loss_ce: 0.012058
2021-11-30 14:00:56,462 iteration 1454 : loss : 0.028343, loss_ce: 0.010558
2021-11-30 14:00:57,685 iteration 1455 : loss : 0.036369, loss_ce: 0.018339
2021-11-30 14:00:58,912 iteration 1456 : loss : 0.049976, loss_ce: 0.014970
2021-11-30 14:01:00,139 iteration 1457 : loss : 0.031101, loss_ce: 0.010858
2021-11-30 14:01:01,359 iteration 1458 : loss : 0.027471, loss_ce: 0.011602
2021-11-30 14:01:02,579 iteration 1459 : loss : 0.032178, loss_ce: 0.015332
2021-11-30 14:01:03,807 iteration 1460 : loss : 0.031455, loss_ce: 0.012396
2021-11-30 14:01:05,032 iteration 1461 : loss : 0.037656, loss_ce: 0.015676
2021-11-30 14:01:06,255 iteration 1462 : loss : 0.027924, loss_ce: 0.010025
 22%|██████▍                       | 86/400 [32:40<2:01:20, 23.19s/it]2021-11-30 14:01:07,547 iteration 1463 : loss : 0.030225, loss_ce: 0.009044
2021-11-30 14:01:08,767 iteration 1464 : loss : 0.026597, loss_ce: 0.011095
2021-11-30 14:01:09,991 iteration 1465 : loss : 0.025116, loss_ce: 0.010888
2021-11-30 14:01:11,212 iteration 1466 : loss : 0.025412, loss_ce: 0.008771
2021-11-30 14:01:12,440 iteration 1467 : loss : 0.043065, loss_ce: 0.013053
2021-11-30 14:01:13,662 iteration 1468 : loss : 0.028922, loss_ce: 0.012829
2021-11-30 14:01:14,882 iteration 1469 : loss : 0.035201, loss_ce: 0.019093
2021-11-30 14:01:16,107 iteration 1470 : loss : 0.041034, loss_ce: 0.014692
2021-11-30 14:01:17,330 iteration 1471 : loss : 0.028215, loss_ce: 0.011621
2021-11-30 14:01:18,556 iteration 1472 : loss : 0.023602, loss_ce: 0.009601
2021-11-30 14:01:19,775 iteration 1473 : loss : 0.025352, loss_ce: 0.010049
2021-11-30 14:01:20,993 iteration 1474 : loss : 0.025028, loss_ce: 0.009588
2021-11-30 14:01:22,220 iteration 1475 : loss : 0.025371, loss_ce: 0.011834
2021-11-30 14:01:23,442 iteration 1476 : loss : 0.026532, loss_ce: 0.009976
2021-11-30 14:01:24,667 iteration 1477 : loss : 0.026605, loss_ce: 0.008530
2021-11-30 14:01:25,892 iteration 1478 : loss : 0.025213, loss_ce: 0.008867
2021-11-30 14:01:27,117 iteration 1479 : loss : 0.025254, loss_ce: 0.008283
 22%|██████▌                       | 87/400 [33:01<1:57:18, 22.49s/it]2021-11-30 14:01:28,406 iteration 1480 : loss : 0.023368, loss_ce: 0.009494
2021-11-30 14:01:29,633 iteration 1481 : loss : 0.025629, loss_ce: 0.008286
2021-11-30 14:01:30,859 iteration 1482 : loss : 0.026150, loss_ce: 0.010901
2021-11-30 14:01:32,087 iteration 1483 : loss : 0.022425, loss_ce: 0.009705
2021-11-30 14:01:33,308 iteration 1484 : loss : 0.028179, loss_ce: 0.014904
2021-11-30 14:01:34,532 iteration 1485 : loss : 0.021206, loss_ce: 0.009511
2021-11-30 14:01:35,761 iteration 1486 : loss : 0.027120, loss_ce: 0.012750
2021-11-30 14:01:36,981 iteration 1487 : loss : 0.037286, loss_ce: 0.011327
2021-11-30 14:01:38,205 iteration 1488 : loss : 0.026959, loss_ce: 0.009854
2021-11-30 14:01:39,426 iteration 1489 : loss : 0.029840, loss_ce: 0.009453
2021-11-30 14:01:40,648 iteration 1490 : loss : 0.024054, loss_ce: 0.008828
2021-11-30 14:01:41,871 iteration 1491 : loss : 0.027154, loss_ce: 0.012689
2021-11-30 14:01:43,089 iteration 1492 : loss : 0.034652, loss_ce: 0.012827
2021-11-30 14:01:44,317 iteration 1493 : loss : 0.027584, loss_ce: 0.009034
2021-11-30 14:01:45,543 iteration 1494 : loss : 0.026643, loss_ce: 0.010306
2021-11-30 14:01:46,767 iteration 1495 : loss : 0.024793, loss_ce: 0.010010
2021-11-30 14:01:47,983 iteration 1496 : loss : 0.047786, loss_ce: 0.010805
 22%|██████▌                       | 88/400 [33:22<1:54:24, 22.00s/it]2021-11-30 14:01:49,274 iteration 1497 : loss : 0.035415, loss_ce: 0.010805
2021-11-30 14:01:50,491 iteration 1498 : loss : 0.026401, loss_ce: 0.008782
2021-11-30 14:01:51,717 iteration 1499 : loss : 0.025656, loss_ce: 0.010372
2021-11-30 14:01:52,934 iteration 1500 : loss : 0.020841, loss_ce: 0.009321
2021-11-30 14:01:54,152 iteration 1501 : loss : 0.027843, loss_ce: 0.011292
2021-11-30 14:01:55,368 iteration 1502 : loss : 0.033938, loss_ce: 0.010471
2021-11-30 14:01:56,583 iteration 1503 : loss : 0.021621, loss_ce: 0.007291
2021-11-30 14:01:57,810 iteration 1504 : loss : 0.031794, loss_ce: 0.011317
2021-11-30 14:01:59,029 iteration 1505 : loss : 0.029905, loss_ce: 0.009658
2021-11-30 14:02:00,248 iteration 1506 : loss : 0.024035, loss_ce: 0.009998
2021-11-30 14:02:01,470 iteration 1507 : loss : 0.029504, loss_ce: 0.017249
2021-11-30 14:02:02,689 iteration 1508 : loss : 0.025206, loss_ce: 0.008424
2021-11-30 14:02:03,915 iteration 1509 : loss : 0.022558, loss_ce: 0.008820
2021-11-30 14:02:05,137 iteration 1510 : loss : 0.026383, loss_ce: 0.008858
2021-11-30 14:02:06,357 iteration 1511 : loss : 0.021017, loss_ce: 0.009272
2021-11-30 14:02:07,575 iteration 1512 : loss : 0.026536, loss_ce: 0.012702
2021-11-30 14:02:08,793 iteration 1513 : loss : 0.025779, loss_ce: 0.009295
 22%|██████▋                       | 89/400 [33:42<1:52:11, 21.64s/it]2021-11-30 14:02:10,080 iteration 1514 : loss : 0.028498, loss_ce: 0.011106
2021-11-30 14:02:11,307 iteration 1515 : loss : 0.022599, loss_ce: 0.009991
2021-11-30 14:02:12,523 iteration 1516 : loss : 0.029703, loss_ce: 0.011195
2021-11-30 14:02:13,744 iteration 1517 : loss : 0.029310, loss_ce: 0.010364
2021-11-30 14:02:14,965 iteration 1518 : loss : 0.035040, loss_ce: 0.012103
2021-11-30 14:02:16,185 iteration 1519 : loss : 0.022580, loss_ce: 0.010346
2021-11-30 14:02:17,410 iteration 1520 : loss : 0.026543, loss_ce: 0.010428
2021-11-30 14:02:18,623 iteration 1521 : loss : 0.030373, loss_ce: 0.012761
2021-11-30 14:02:19,847 iteration 1522 : loss : 0.025057, loss_ce: 0.009293
2021-11-30 14:02:21,062 iteration 1523 : loss : 0.025929, loss_ce: 0.008393
2021-11-30 14:02:22,289 iteration 1524 : loss : 0.023474, loss_ce: 0.010304
2021-11-30 14:02:23,506 iteration 1525 : loss : 0.025946, loss_ce: 0.010873
2021-11-30 14:02:24,724 iteration 1526 : loss : 0.026552, loss_ce: 0.010212
2021-11-30 14:02:25,945 iteration 1527 : loss : 0.031819, loss_ce: 0.010417
2021-11-30 14:02:27,164 iteration 1528 : loss : 0.029864, loss_ce: 0.007970
2021-11-30 14:02:28,386 iteration 1529 : loss : 0.028252, loss_ce: 0.013004
2021-11-30 14:02:28,386 Training Data Eval:
2021-11-30 14:02:35,296   Average segmentation loss on training set: 0.0290
2021-11-30 14:02:35,297 Validation Data Eval:
2021-11-30 14:02:37,665   Average segmentation loss on validation set: 0.1683
2021-11-30 14:02:38,889 iteration 1530 : loss : 0.023031, loss_ce: 0.008986
 22%|██████▊                       | 90/400 [34:12<2:04:56, 24.18s/it]2021-11-30 14:02:40,177 iteration 1531 : loss : 0.021980, loss_ce: 0.008606
2021-11-30 14:02:41,401 iteration 1532 : loss : 0.023435, loss_ce: 0.008797
2021-11-30 14:02:42,623 iteration 1533 : loss : 0.026864, loss_ce: 0.011211
2021-11-30 14:02:43,845 iteration 1534 : loss : 0.025249, loss_ce: 0.011555
2021-11-30 14:02:45,063 iteration 1535 : loss : 0.032001, loss_ce: 0.011812
2021-11-30 14:02:46,284 iteration 1536 : loss : 0.022296, loss_ce: 0.010064
2021-11-30 14:02:47,507 iteration 1537 : loss : 0.029825, loss_ce: 0.013222
2021-11-30 14:02:48,730 iteration 1538 : loss : 0.025795, loss_ce: 0.009113
2021-11-30 14:02:49,951 iteration 1539 : loss : 0.020717, loss_ce: 0.008645
2021-11-30 14:02:51,165 iteration 1540 : loss : 0.020968, loss_ce: 0.007665
2021-11-30 14:02:52,386 iteration 1541 : loss : 0.023632, loss_ce: 0.010389
2021-11-30 14:02:53,609 iteration 1542 : loss : 0.023321, loss_ce: 0.008926
2021-11-30 14:02:54,834 iteration 1543 : loss : 0.027248, loss_ce: 0.009505
2021-11-30 14:02:56,064 iteration 1544 : loss : 0.027102, loss_ce: 0.009402
2021-11-30 14:02:57,285 iteration 1545 : loss : 0.030659, loss_ce: 0.010307
2021-11-30 14:02:58,506 iteration 1546 : loss : 0.027564, loss_ce: 0.013225
2021-11-30 14:02:59,733 iteration 1547 : loss : 0.018923, loss_ce: 0.007199
 23%|██████▊                       | 91/400 [34:33<1:59:22, 23.18s/it]2021-11-30 14:03:01,018 iteration 1548 : loss : 0.022521, loss_ce: 0.005017
2021-11-30 14:03:02,240 iteration 1549 : loss : 0.021765, loss_ce: 0.006645
2021-11-30 14:03:03,458 iteration 1550 : loss : 0.025975, loss_ce: 0.008143
2021-11-30 14:03:04,682 iteration 1551 : loss : 0.022029, loss_ce: 0.010621
2021-11-30 14:03:05,904 iteration 1552 : loss : 0.021813, loss_ce: 0.007904
2021-11-30 14:03:07,128 iteration 1553 : loss : 0.024874, loss_ce: 0.008868
2021-11-30 14:03:08,350 iteration 1554 : loss : 0.026406, loss_ce: 0.009687
2021-11-30 14:03:09,578 iteration 1555 : loss : 0.024898, loss_ce: 0.009285
2021-11-30 14:03:10,801 iteration 1556 : loss : 0.018219, loss_ce: 0.007058
2021-11-30 14:03:12,027 iteration 1557 : loss : 0.023592, loss_ce: 0.009171
2021-11-30 14:03:13,255 iteration 1558 : loss : 0.017923, loss_ce: 0.008242
2021-11-30 14:03:14,474 iteration 1559 : loss : 0.036128, loss_ce: 0.013631
2021-11-30 14:03:15,691 iteration 1560 : loss : 0.029346, loss_ce: 0.009800
2021-11-30 14:03:16,913 iteration 1561 : loss : 0.021771, loss_ce: 0.010751
2021-11-30 14:03:18,137 iteration 1562 : loss : 0.032285, loss_ce: 0.015010
2021-11-30 14:03:19,352 iteration 1563 : loss : 0.025704, loss_ce: 0.010410
2021-11-30 14:03:20,568 iteration 1564 : loss : 0.028157, loss_ce: 0.013218
 23%|██████▉                       | 92/400 [34:54<1:55:22, 22.48s/it]2021-11-30 14:03:21,847 iteration 1565 : loss : 0.020732, loss_ce: 0.008066
2021-11-30 14:03:23,068 iteration 1566 : loss : 0.023853, loss_ce: 0.012101
2021-11-30 14:03:24,283 iteration 1567 : loss : 0.026018, loss_ce: 0.010026
2021-11-30 14:03:25,494 iteration 1568 : loss : 0.024138, loss_ce: 0.011942
2021-11-30 14:03:26,711 iteration 1569 : loss : 0.024186, loss_ce: 0.011355
2021-11-30 14:03:27,939 iteration 1570 : loss : 0.023444, loss_ce: 0.008088
2021-11-30 14:03:29,162 iteration 1571 : loss : 0.024606, loss_ce: 0.008151
2021-11-30 14:03:30,378 iteration 1572 : loss : 0.021356, loss_ce: 0.009172
2021-11-30 14:03:31,593 iteration 1573 : loss : 0.025790, loss_ce: 0.008275
2021-11-30 14:03:32,818 iteration 1574 : loss : 0.024289, loss_ce: 0.009293
2021-11-30 14:03:34,044 iteration 1575 : loss : 0.033845, loss_ce: 0.009704
2021-11-30 14:03:35,269 iteration 1576 : loss : 0.023022, loss_ce: 0.008797
2021-11-30 14:03:36,487 iteration 1577 : loss : 0.026269, loss_ce: 0.011261
2021-11-30 14:03:37,707 iteration 1578 : loss : 0.024130, loss_ce: 0.009748
2021-11-30 14:03:38,933 iteration 1579 : loss : 0.020391, loss_ce: 0.008659
2021-11-30 14:03:40,155 iteration 1580 : loss : 0.030454, loss_ce: 0.009049
2021-11-30 14:03:41,374 iteration 1581 : loss : 0.026253, loss_ce: 0.007423
 23%|██████▉                       | 93/400 [35:15<1:52:26, 21.97s/it]2021-11-30 14:03:42,659 iteration 1582 : loss : 0.029272, loss_ce: 0.010111
2021-11-30 14:03:43,875 iteration 1583 : loss : 0.017779, loss_ce: 0.007243
2021-11-30 14:03:45,096 iteration 1584 : loss : 0.019396, loss_ce: 0.006425
2021-11-30 14:03:46,316 iteration 1585 : loss : 0.030791, loss_ce: 0.012676
2021-11-30 14:03:47,537 iteration 1586 : loss : 0.044201, loss_ce: 0.019768
2021-11-30 14:03:48,764 iteration 1587 : loss : 0.031909, loss_ce: 0.018640
2021-11-30 14:03:49,986 iteration 1588 : loss : 0.029274, loss_ce: 0.008551
2021-11-30 14:03:51,202 iteration 1589 : loss : 0.024954, loss_ce: 0.010786
2021-11-30 14:03:52,425 iteration 1590 : loss : 0.022125, loss_ce: 0.008538
2021-11-30 14:03:53,652 iteration 1591 : loss : 0.033797, loss_ce: 0.010563
2021-11-30 14:03:54,866 iteration 1592 : loss : 0.028112, loss_ce: 0.013637
2021-11-30 14:03:56,086 iteration 1593 : loss : 0.029122, loss_ce: 0.010283
2021-11-30 14:03:57,303 iteration 1594 : loss : 0.021776, loss_ce: 0.009105
2021-11-30 14:03:58,523 iteration 1595 : loss : 0.023688, loss_ce: 0.009947
2021-11-30 14:03:59,741 iteration 1596 : loss : 0.021531, loss_ce: 0.009910
2021-11-30 14:04:00,961 iteration 1597 : loss : 0.024905, loss_ce: 0.010649
2021-11-30 14:04:02,186 iteration 1598 : loss : 0.024475, loss_ce: 0.008974
 24%|███████                       | 94/400 [35:36<1:50:17, 21.63s/it]2021-11-30 14:04:03,473 iteration 1599 : loss : 0.036038, loss_ce: 0.013186
2021-11-30 14:04:04,686 iteration 1600 : loss : 0.021560, loss_ce: 0.008213
2021-11-30 14:04:05,917 iteration 1601 : loss : 0.022695, loss_ce: 0.008092
2021-11-30 14:04:07,146 iteration 1602 : loss : 0.022061, loss_ce: 0.008572
2021-11-30 14:04:08,364 iteration 1603 : loss : 0.022761, loss_ce: 0.010013
2021-11-30 14:04:09,595 iteration 1604 : loss : 0.027614, loss_ce: 0.010319
2021-11-30 14:04:10,814 iteration 1605 : loss : 0.024759, loss_ce: 0.012346
2021-11-30 14:04:12,041 iteration 1606 : loss : 0.019444, loss_ce: 0.008327
2021-11-30 14:04:13,267 iteration 1607 : loss : 0.024415, loss_ce: 0.010110
2021-11-30 14:04:14,490 iteration 1608 : loss : 0.020421, loss_ce: 0.007887
2021-11-30 14:04:15,708 iteration 1609 : loss : 0.023584, loss_ce: 0.009919
2021-11-30 14:04:16,928 iteration 1610 : loss : 0.029852, loss_ce: 0.009783
2021-11-30 14:04:18,158 iteration 1611 : loss : 0.024876, loss_ce: 0.009016
2021-11-30 14:04:19,371 iteration 1612 : loss : 0.028404, loss_ce: 0.007776
2021-11-30 14:04:20,592 iteration 1613 : loss : 0.031638, loss_ce: 0.014776
2021-11-30 14:04:21,813 iteration 1614 : loss : 0.029667, loss_ce: 0.007997
2021-11-30 14:04:21,813 Training Data Eval:
2021-11-30 14:04:28,730   Average segmentation loss on training set: 0.0289
2021-11-30 14:04:28,730 Validation Data Eval:
2021-11-30 14:04:31,113   Average segmentation loss on validation set: 0.1096
2021-11-30 14:04:32,337 iteration 1615 : loss : 0.030288, loss_ce: 0.012340
 24%|███████▏                      | 95/400 [36:06<2:02:56, 24.18s/it]2021-11-30 14:04:33,643 iteration 1616 : loss : 0.027052, loss_ce: 0.007998
2021-11-30 14:04:34,869 iteration 1617 : loss : 0.028553, loss_ce: 0.012077
2021-11-30 14:04:36,098 iteration 1618 : loss : 0.025125, loss_ce: 0.010503
2021-11-30 14:04:37,324 iteration 1619 : loss : 0.026627, loss_ce: 0.007082
2021-11-30 14:04:38,551 iteration 1620 : loss : 0.020627, loss_ce: 0.008109
2021-11-30 14:04:39,773 iteration 1621 : loss : 0.022926, loss_ce: 0.008598
2021-11-30 14:04:40,994 iteration 1622 : loss : 0.019935, loss_ce: 0.007629
2021-11-30 14:04:42,214 iteration 1623 : loss : 0.019153, loss_ce: 0.009174
2021-11-30 14:04:43,434 iteration 1624 : loss : 0.022583, loss_ce: 0.009495
2021-11-30 14:04:44,658 iteration 1625 : loss : 0.025554, loss_ce: 0.008601
2021-11-30 14:04:45,875 iteration 1626 : loss : 0.018793, loss_ce: 0.008867
2021-11-30 14:04:47,096 iteration 1627 : loss : 0.021221, loss_ce: 0.008837
2021-11-30 14:04:48,312 iteration 1628 : loss : 0.017534, loss_ce: 0.007295
2021-11-30 14:04:49,537 iteration 1629 : loss : 0.024020, loss_ce: 0.010131
2021-11-30 14:04:50,759 iteration 1630 : loss : 0.023806, loss_ce: 0.009051
2021-11-30 14:04:51,985 iteration 1631 : loss : 0.022353, loss_ce: 0.008914
2021-11-30 14:04:53,203 iteration 1632 : loss : 0.026602, loss_ce: 0.012886
 24%|███████▏                      | 96/400 [36:27<1:57:28, 23.19s/it]2021-11-30 14:04:54,482 iteration 1633 : loss : 0.025220, loss_ce: 0.007493
2021-11-30 14:04:55,704 iteration 1634 : loss : 0.018823, loss_ce: 0.007411
2021-11-30 14:04:56,926 iteration 1635 : loss : 0.017690, loss_ce: 0.006328
2021-11-30 14:04:58,151 iteration 1636 : loss : 0.022024, loss_ce: 0.008681
2021-11-30 14:04:59,367 iteration 1637 : loss : 0.027255, loss_ce: 0.008304
2021-11-30 14:05:00,584 iteration 1638 : loss : 0.019082, loss_ce: 0.008079
2021-11-30 14:05:01,801 iteration 1639 : loss : 0.023512, loss_ce: 0.010814
2021-11-30 14:05:03,021 iteration 1640 : loss : 0.022679, loss_ce: 0.010634
2021-11-30 14:05:04,241 iteration 1641 : loss : 0.031380, loss_ce: 0.017053
2021-11-30 14:05:05,462 iteration 1642 : loss : 0.018268, loss_ce: 0.007723
2021-11-30 14:05:06,683 iteration 1643 : loss : 0.021916, loss_ce: 0.006585
2021-11-30 14:05:07,900 iteration 1644 : loss : 0.025600, loss_ce: 0.012811
2021-11-30 14:05:09,117 iteration 1645 : loss : 0.023193, loss_ce: 0.009906
2021-11-30 14:05:10,344 iteration 1646 : loss : 0.017409, loss_ce: 0.008619
2021-11-30 14:05:11,559 iteration 1647 : loss : 0.021905, loss_ce: 0.008358
2021-11-30 14:05:12,778 iteration 1648 : loss : 0.023137, loss_ce: 0.009739
2021-11-30 14:05:14,000 iteration 1649 : loss : 0.025886, loss_ce: 0.010721
 24%|███████▎                      | 97/400 [36:48<1:53:28, 22.47s/it]2021-11-30 14:05:15,290 iteration 1650 : loss : 0.034011, loss_ce: 0.012389
2021-11-30 14:05:16,510 iteration 1651 : loss : 0.020428, loss_ce: 0.008483
2021-11-30 14:05:17,733 iteration 1652 : loss : 0.021335, loss_ce: 0.008639
2021-11-30 14:05:18,960 iteration 1653 : loss : 0.020532, loss_ce: 0.008899
2021-11-30 14:05:20,177 iteration 1654 : loss : 0.024004, loss_ce: 0.009161
2021-11-30 14:05:21,400 iteration 1655 : loss : 0.017606, loss_ce: 0.007166
2021-11-30 14:05:22,615 iteration 1656 : loss : 0.022700, loss_ce: 0.009212
2021-11-30 14:05:23,836 iteration 1657 : loss : 0.017931, loss_ce: 0.006511
2021-11-30 14:05:25,065 iteration 1658 : loss : 0.020691, loss_ce: 0.008928
2021-11-30 14:05:26,288 iteration 1659 : loss : 0.025857, loss_ce: 0.008087
2021-11-30 14:05:27,505 iteration 1660 : loss : 0.036271, loss_ce: 0.010481
2021-11-30 14:05:28,727 iteration 1661 : loss : 0.023604, loss_ce: 0.007994
2021-11-30 14:05:29,950 iteration 1662 : loss : 0.021204, loss_ce: 0.012081
2021-11-30 14:05:31,173 iteration 1663 : loss : 0.023200, loss_ce: 0.007578
2021-11-30 14:05:32,392 iteration 1664 : loss : 0.027212, loss_ce: 0.013621
2021-11-30 14:05:33,615 iteration 1665 : loss : 0.023417, loss_ce: 0.007179
2021-11-30 14:05:34,836 iteration 1666 : loss : 0.024425, loss_ce: 0.010761
 24%|███████▎                      | 98/400 [37:08<1:50:38, 21.98s/it]2021-11-30 14:05:36,124 iteration 1667 : loss : 0.022247, loss_ce: 0.007566
2021-11-30 14:05:37,347 iteration 1668 : loss : 0.023546, loss_ce: 0.008972
2021-11-30 14:05:38,566 iteration 1669 : loss : 0.022281, loss_ce: 0.009403
2021-11-30 14:05:39,790 iteration 1670 : loss : 0.024078, loss_ce: 0.008111
2021-11-30 14:05:41,008 iteration 1671 : loss : 0.020444, loss_ce: 0.007671
2021-11-30 14:05:42,225 iteration 1672 : loss : 0.021586, loss_ce: 0.008113
2021-11-30 14:05:43,448 iteration 1673 : loss : 0.024663, loss_ce: 0.012768
2021-11-30 14:05:44,665 iteration 1674 : loss : 0.021177, loss_ce: 0.008606
2021-11-30 14:05:45,887 iteration 1675 : loss : 0.022851, loss_ce: 0.006687
2021-11-30 14:05:47,101 iteration 1676 : loss : 0.021843, loss_ce: 0.009243
2021-11-30 14:05:48,321 iteration 1677 : loss : 0.028427, loss_ce: 0.009841
2021-11-30 14:05:49,544 iteration 1678 : loss : 0.029094, loss_ce: 0.008594
2021-11-30 14:05:50,771 iteration 1679 : loss : 0.016979, loss_ce: 0.006013
2021-11-30 14:05:51,985 iteration 1680 : loss : 0.029598, loss_ce: 0.009261
2021-11-30 14:05:53,205 iteration 1681 : loss : 0.024542, loss_ce: 0.010397
2021-11-30 14:05:54,414 iteration 1682 : loss : 0.022173, loss_ce: 0.010073
2021-11-30 14:05:55,636 iteration 1683 : loss : 0.024446, loss_ce: 0.010446
 25%|███████▍                      | 99/400 [37:29<1:48:29, 21.63s/it]2021-11-30 14:05:56,924 iteration 1684 : loss : 0.024263, loss_ce: 0.008835
2021-11-30 14:05:58,149 iteration 1685 : loss : 0.022588, loss_ce: 0.009018
2021-11-30 14:05:59,362 iteration 1686 : loss : 0.023144, loss_ce: 0.009244
2021-11-30 14:06:00,586 iteration 1687 : loss : 0.032856, loss_ce: 0.009742
2021-11-30 14:06:01,793 iteration 1688 : loss : 0.020441, loss_ce: 0.008497
2021-11-30 14:06:03,012 iteration 1689 : loss : 0.017006, loss_ce: 0.007585
2021-11-30 14:06:04,227 iteration 1690 : loss : 0.021413, loss_ce: 0.006474
2021-11-30 14:06:05,440 iteration 1691 : loss : 0.032697, loss_ce: 0.012884
2021-11-30 14:06:06,670 iteration 1692 : loss : 0.021582, loss_ce: 0.008381
2021-11-30 14:06:07,882 iteration 1693 : loss : 0.019096, loss_ce: 0.007350
2021-11-30 14:06:09,101 iteration 1694 : loss : 0.019978, loss_ce: 0.008335
2021-11-30 14:06:10,316 iteration 1695 : loss : 0.030861, loss_ce: 0.010684
2021-11-30 14:06:11,536 iteration 1696 : loss : 0.025745, loss_ce: 0.009317
2021-11-30 14:06:12,749 iteration 1697 : loss : 0.025142, loss_ce: 0.008743
2021-11-30 14:06:13,965 iteration 1698 : loss : 0.016172, loss_ce: 0.007061
2021-11-30 14:06:15,187 iteration 1699 : loss : 0.018791, loss_ce: 0.008129
2021-11-30 14:06:15,187 Training Data Eval:
2021-11-30 14:06:22,109   Average segmentation loss on training set: 0.0232
2021-11-30 14:06:22,110 Validation Data Eval:
2021-11-30 14:06:24,481   Average segmentation loss on validation set: 0.1527
2021-11-30 14:06:25,709 iteration 1700 : loss : 0.018690, loss_ce: 0.007135
 25%|███████▎                     | 100/400 [37:59<2:00:47, 24.16s/it]2021-11-30 14:06:26,997 iteration 1701 : loss : 0.021657, loss_ce: 0.008706
2021-11-30 14:06:28,220 iteration 1702 : loss : 0.022263, loss_ce: 0.009233
2021-11-30 14:06:29,433 iteration 1703 : loss : 0.020843, loss_ce: 0.007457
2021-11-30 14:06:30,654 iteration 1704 : loss : 0.023371, loss_ce: 0.009169
2021-11-30 14:06:31,878 iteration 1705 : loss : 0.020125, loss_ce: 0.007400
2021-11-30 14:06:33,099 iteration 1706 : loss : 0.025869, loss_ce: 0.009382
2021-11-30 14:06:34,317 iteration 1707 : loss : 0.027192, loss_ce: 0.008194
2021-11-30 14:06:35,532 iteration 1708 : loss : 0.023458, loss_ce: 0.008230
2021-11-30 14:06:36,754 iteration 1709 : loss : 0.019562, loss_ce: 0.009212
2021-11-30 14:06:37,981 iteration 1710 : loss : 0.023887, loss_ce: 0.007357
2021-11-30 14:06:39,200 iteration 1711 : loss : 0.030684, loss_ce: 0.012703
2021-11-30 14:06:40,419 iteration 1712 : loss : 0.014684, loss_ce: 0.006603
2021-11-30 14:06:41,638 iteration 1713 : loss : 0.024471, loss_ce: 0.009835
2021-11-30 14:06:42,863 iteration 1714 : loss : 0.023717, loss_ce: 0.007603
2021-11-30 14:06:44,080 iteration 1715 : loss : 0.021964, loss_ce: 0.009190
2021-11-30 14:06:45,300 iteration 1716 : loss : 0.022454, loss_ce: 0.007409
2021-11-30 14:06:46,519 iteration 1717 : loss : 0.023195, loss_ce: 0.009085
 25%|███████▎                     | 101/400 [38:20<1:55:23, 23.15s/it]2021-11-30 14:06:47,803 iteration 1718 : loss : 0.020284, loss_ce: 0.008459
2021-11-30 14:06:49,023 iteration 1719 : loss : 0.023147, loss_ce: 0.007527
2021-11-30 14:06:50,243 iteration 1720 : loss : 0.017094, loss_ce: 0.007128
2021-11-30 14:06:51,471 iteration 1721 : loss : 0.021694, loss_ce: 0.010111
2021-11-30 14:06:52,690 iteration 1722 : loss : 0.022953, loss_ce: 0.009532
2021-11-30 14:06:53,912 iteration 1723 : loss : 0.027473, loss_ce: 0.009133
2021-11-30 14:06:55,131 iteration 1724 : loss : 0.015920, loss_ce: 0.005695
2021-11-30 14:06:56,355 iteration 1725 : loss : 0.017469, loss_ce: 0.007050
2021-11-30 14:06:57,581 iteration 1726 : loss : 0.018209, loss_ce: 0.008227
2021-11-30 14:06:58,802 iteration 1727 : loss : 0.018806, loss_ce: 0.008203
2021-11-30 14:07:00,021 iteration 1728 : loss : 0.021576, loss_ce: 0.007592
2021-11-30 14:07:01,246 iteration 1729 : loss : 0.035175, loss_ce: 0.010542
2021-11-30 14:07:02,465 iteration 1730 : loss : 0.025833, loss_ce: 0.011172
2021-11-30 14:07:03,682 iteration 1731 : loss : 0.023230, loss_ce: 0.008599
2021-11-30 14:07:04,902 iteration 1732 : loss : 0.018793, loss_ce: 0.008637
2021-11-30 14:07:06,125 iteration 1733 : loss : 0.016629, loss_ce: 0.005200
2021-11-30 14:07:07,343 iteration 1734 : loss : 0.022081, loss_ce: 0.009674
 26%|███████▍                     | 102/400 [38:41<1:51:32, 22.46s/it]2021-11-30 14:07:08,638 iteration 1735 : loss : 0.023121, loss_ce: 0.008131
2021-11-30 14:07:09,863 iteration 1736 : loss : 0.020275, loss_ce: 0.007223
2021-11-30 14:07:11,089 iteration 1737 : loss : 0.021205, loss_ce: 0.007941
2021-11-30 14:07:12,317 iteration 1738 : loss : 0.021430, loss_ce: 0.009756
2021-11-30 14:07:13,537 iteration 1739 : loss : 0.020174, loss_ce: 0.006208
2021-11-30 14:07:14,759 iteration 1740 : loss : 0.027139, loss_ce: 0.013229
2021-11-30 14:07:15,983 iteration 1741 : loss : 0.020221, loss_ce: 0.008217
2021-11-30 14:07:17,203 iteration 1742 : loss : 0.017360, loss_ce: 0.008464
2021-11-30 14:07:18,423 iteration 1743 : loss : 0.018710, loss_ce: 0.008115
2021-11-30 14:07:19,642 iteration 1744 : loss : 0.030905, loss_ce: 0.008987
2021-11-30 14:07:20,865 iteration 1745 : loss : 0.016492, loss_ce: 0.006738
2021-11-30 14:07:22,085 iteration 1746 : loss : 0.018572, loss_ce: 0.007074
2021-11-30 14:07:23,308 iteration 1747 : loss : 0.020518, loss_ce: 0.006347
2021-11-30 14:07:24,526 iteration 1748 : loss : 0.026174, loss_ce: 0.012357
2021-11-30 14:07:25,741 iteration 1749 : loss : 0.024409, loss_ce: 0.010162
2021-11-30 14:07:26,961 iteration 1750 : loss : 0.026566, loss_ce: 0.007476
2021-11-30 14:07:28,189 iteration 1751 : loss : 0.025054, loss_ce: 0.008716
 26%|███████▍                     | 103/400 [39:02<1:48:45, 21.97s/it]2021-11-30 14:07:29,482 iteration 1752 : loss : 0.029867, loss_ce: 0.007663
2021-11-30 14:07:30,704 iteration 1753 : loss : 0.020065, loss_ce: 0.008064
2021-11-30 14:07:31,922 iteration 1754 : loss : 0.016331, loss_ce: 0.005394
2021-11-30 14:07:33,147 iteration 1755 : loss : 0.023233, loss_ce: 0.007817
2021-11-30 14:07:34,365 iteration 1756 : loss : 0.027013, loss_ce: 0.013760
2021-11-30 14:07:35,582 iteration 1757 : loss : 0.021976, loss_ce: 0.009451
2021-11-30 14:07:36,806 iteration 1758 : loss : 0.031961, loss_ce: 0.008328
2021-11-30 14:07:38,020 iteration 1759 : loss : 0.020333, loss_ce: 0.006149
2021-11-30 14:07:39,244 iteration 1760 : loss : 0.027272, loss_ce: 0.009961
2021-11-30 14:07:40,464 iteration 1761 : loss : 0.025380, loss_ce: 0.008172
2021-11-30 14:07:41,691 iteration 1762 : loss : 0.024233, loss_ce: 0.011722
2021-11-30 14:07:42,910 iteration 1763 : loss : 0.020166, loss_ce: 0.006667
2021-11-30 14:07:44,132 iteration 1764 : loss : 0.023018, loss_ce: 0.011340
2021-11-30 14:07:45,353 iteration 1765 : loss : 0.023024, loss_ce: 0.011832
2021-11-30 14:07:46,573 iteration 1766 : loss : 0.020523, loss_ce: 0.007711
2021-11-30 14:07:47,791 iteration 1767 : loss : 0.026050, loss_ce: 0.014709
2021-11-30 14:07:49,015 iteration 1768 : loss : 0.022167, loss_ce: 0.008251
 26%|███████▌                     | 104/400 [39:23<1:46:42, 21.63s/it]2021-11-30 14:07:50,305 iteration 1769 : loss : 0.019404, loss_ce: 0.007234
2021-11-30 14:07:51,530 iteration 1770 : loss : 0.022788, loss_ce: 0.008999
2021-11-30 14:07:52,749 iteration 1771 : loss : 0.020639, loss_ce: 0.009154
2021-11-30 14:07:53,970 iteration 1772 : loss : 0.023663, loss_ce: 0.009558
2021-11-30 14:07:55,186 iteration 1773 : loss : 0.021768, loss_ce: 0.008241
2021-11-30 14:07:56,413 iteration 1774 : loss : 0.015645, loss_ce: 0.006901
2021-11-30 14:07:57,630 iteration 1775 : loss : 0.019508, loss_ce: 0.006715
2021-11-30 14:07:58,847 iteration 1776 : loss : 0.026205, loss_ce: 0.011218
2021-11-30 14:08:00,070 iteration 1777 : loss : 0.021156, loss_ce: 0.008434
2021-11-30 14:08:01,292 iteration 1778 : loss : 0.023694, loss_ce: 0.007820
2021-11-30 14:08:02,514 iteration 1779 : loss : 0.028113, loss_ce: 0.012923
2021-11-30 14:08:03,735 iteration 1780 : loss : 0.021577, loss_ce: 0.008101
2021-11-30 14:08:04,956 iteration 1781 : loss : 0.022775, loss_ce: 0.008886
2021-11-30 14:08:06,176 iteration 1782 : loss : 0.019642, loss_ce: 0.008428
2021-11-30 14:08:07,395 iteration 1783 : loss : 0.020563, loss_ce: 0.006689
2021-11-30 14:08:08,620 iteration 1784 : loss : 0.022547, loss_ce: 0.008675
2021-11-30 14:08:08,621 Training Data Eval:
2021-11-30 14:08:15,524   Average segmentation loss on training set: 0.0230
2021-11-30 14:08:15,524 Validation Data Eval:
2021-11-30 14:08:17,894   Average segmentation loss on validation set: 0.1439
2021-11-30 14:08:19,123 iteration 1785 : loss : 0.023783, loss_ce: 0.009734
 26%|███████▌                     | 105/400 [39:53<1:58:50, 24.17s/it]2021-11-30 14:08:20,417 iteration 1786 : loss : 0.021147, loss_ce: 0.008975
2021-11-30 14:08:21,636 iteration 1787 : loss : 0.021642, loss_ce: 0.008217
2021-11-30 14:08:22,857 iteration 1788 : loss : 0.018061, loss_ce: 0.006818
2021-11-30 14:08:24,081 iteration 1789 : loss : 0.019620, loss_ce: 0.007596
2021-11-30 14:08:25,302 iteration 1790 : loss : 0.019210, loss_ce: 0.006893
2021-11-30 14:08:26,519 iteration 1791 : loss : 0.024324, loss_ce: 0.012479
2021-11-30 14:08:27,727 iteration 1792 : loss : 0.023378, loss_ce: 0.008503
2021-11-30 14:08:28,950 iteration 1793 : loss : 0.018325, loss_ce: 0.009030
2021-11-30 14:08:30,166 iteration 1794 : loss : 0.018732, loss_ce: 0.007810
2021-11-30 14:08:31,381 iteration 1795 : loss : 0.019277, loss_ce: 0.007046
2021-11-30 14:08:32,601 iteration 1796 : loss : 0.026704, loss_ce: 0.010265
2021-11-30 14:08:33,824 iteration 1797 : loss : 0.023395, loss_ce: 0.006423
2021-11-30 14:08:35,042 iteration 1798 : loss : 0.018535, loss_ce: 0.007239
2021-11-30 14:08:36,262 iteration 1799 : loss : 0.019330, loss_ce: 0.006875
2021-11-30 14:08:37,477 iteration 1800 : loss : 0.026990, loss_ce: 0.008369
2021-11-30 14:08:38,692 iteration 1801 : loss : 0.023799, loss_ce: 0.008059
2021-11-30 14:08:39,919 iteration 1802 : loss : 0.024543, loss_ce: 0.010779
 26%|███████▋                     | 106/400 [40:13<1:53:28, 23.16s/it]2021-11-30 14:08:41,211 iteration 1803 : loss : 0.017840, loss_ce: 0.008718
2021-11-30 14:08:42,432 iteration 1804 : loss : 0.020871, loss_ce: 0.006419
2021-11-30 14:08:43,652 iteration 1805 : loss : 0.016825, loss_ce: 0.005529
2021-11-30 14:08:44,870 iteration 1806 : loss : 0.028253, loss_ce: 0.013543
2021-11-30 14:08:46,097 iteration 1807 : loss : 0.019779, loss_ce: 0.006124
2021-11-30 14:08:47,323 iteration 1808 : loss : 0.021497, loss_ce: 0.009653
2021-11-30 14:08:48,539 iteration 1809 : loss : 0.022306, loss_ce: 0.007502
2021-11-30 14:08:49,759 iteration 1810 : loss : 0.016173, loss_ce: 0.006063
2021-11-30 14:08:50,983 iteration 1811 : loss : 0.021776, loss_ce: 0.009319
2021-11-30 14:08:52,205 iteration 1812 : loss : 0.018845, loss_ce: 0.008275
2021-11-30 14:08:53,435 iteration 1813 : loss : 0.017450, loss_ce: 0.006978
2021-11-30 14:08:54,656 iteration 1814 : loss : 0.021995, loss_ce: 0.010289
2021-11-30 14:08:55,874 iteration 1815 : loss : 0.023694, loss_ce: 0.007425
2021-11-30 14:08:57,099 iteration 1816 : loss : 0.023752, loss_ce: 0.009886
2021-11-30 14:08:58,324 iteration 1817 : loss : 0.025134, loss_ce: 0.009085
2021-11-30 14:08:59,543 iteration 1818 : loss : 0.023303, loss_ce: 0.008764
2021-11-30 14:09:00,755 iteration 1819 : loss : 0.027851, loss_ce: 0.009691
 27%|███████▊                     | 107/400 [40:34<1:49:41, 22.46s/it]2021-11-30 14:09:02,048 iteration 1820 : loss : 0.023298, loss_ce: 0.006880
2021-11-30 14:09:03,267 iteration 1821 : loss : 0.019425, loss_ce: 0.007908
2021-11-30 14:09:04,489 iteration 1822 : loss : 0.021169, loss_ce: 0.005311
2021-11-30 14:09:05,715 iteration 1823 : loss : 0.025364, loss_ce: 0.009903
2021-11-30 14:09:06,938 iteration 1824 : loss : 0.021716, loss_ce: 0.008969
2021-11-30 14:09:08,165 iteration 1825 : loss : 0.026582, loss_ce: 0.010608
2021-11-30 14:09:09,384 iteration 1826 : loss : 0.027542, loss_ce: 0.012606
2021-11-30 14:09:10,609 iteration 1827 : loss : 0.018422, loss_ce: 0.007584
2021-11-30 14:09:11,832 iteration 1828 : loss : 0.019309, loss_ce: 0.006732
2021-11-30 14:09:13,050 iteration 1829 : loss : 0.018314, loss_ce: 0.009084
2021-11-30 14:09:14,270 iteration 1830 : loss : 0.023190, loss_ce: 0.010273
2021-11-30 14:09:15,491 iteration 1831 : loss : 0.026668, loss_ce: 0.009302
2021-11-30 14:09:16,709 iteration 1832 : loss : 0.020743, loss_ce: 0.010305
2021-11-30 14:09:17,928 iteration 1833 : loss : 0.024773, loss_ce: 0.009502
2021-11-30 14:09:19,145 iteration 1834 : loss : 0.019462, loss_ce: 0.007258
2021-11-30 14:09:20,368 iteration 1835 : loss : 0.024550, loss_ce: 0.008728
2021-11-30 14:09:21,591 iteration 1836 : loss : 0.021854, loss_ce: 0.008547
 27%|███████▊                     | 108/400 [40:55<1:46:56, 21.97s/it]2021-11-30 14:09:22,884 iteration 1837 : loss : 0.018220, loss_ce: 0.007415
2021-11-30 14:09:24,113 iteration 1838 : loss : 0.017699, loss_ce: 0.006394
2021-11-30 14:09:25,327 iteration 1839 : loss : 0.033556, loss_ce: 0.017750
2021-11-30 14:09:26,542 iteration 1840 : loss : 0.020908, loss_ce: 0.008051
2021-11-30 14:09:27,768 iteration 1841 : loss : 0.022483, loss_ce: 0.010896
2021-11-30 14:09:28,985 iteration 1842 : loss : 0.019261, loss_ce: 0.004926
2021-11-30 14:09:30,207 iteration 1843 : loss : 0.020509, loss_ce: 0.008727
2021-11-30 14:09:31,429 iteration 1844 : loss : 0.018090, loss_ce: 0.006965
2021-11-30 14:09:32,653 iteration 1845 : loss : 0.020480, loss_ce: 0.008835
2021-11-30 14:09:33,867 iteration 1846 : loss : 0.017831, loss_ce: 0.007811
2021-11-30 14:09:35,096 iteration 1847 : loss : 0.019382, loss_ce: 0.006840
2021-11-30 14:09:36,312 iteration 1848 : loss : 0.021203, loss_ce: 0.006900
2021-11-30 14:09:37,538 iteration 1849 : loss : 0.019420, loss_ce: 0.008642
2021-11-30 14:09:38,759 iteration 1850 : loss : 0.017296, loss_ce: 0.007675
2021-11-30 14:09:39,984 iteration 1851 : loss : 0.020101, loss_ce: 0.007049
2021-11-30 14:09:41,209 iteration 1852 : loss : 0.021717, loss_ce: 0.009437
2021-11-30 14:09:42,433 iteration 1853 : loss : 0.021462, loss_ce: 0.006899
 27%|███████▉                     | 109/400 [41:16<1:44:55, 21.63s/it]2021-11-30 14:09:43,717 iteration 1854 : loss : 0.022193, loss_ce: 0.008481
2021-11-30 14:09:44,940 iteration 1855 : loss : 0.019166, loss_ce: 0.008712
2021-11-30 14:09:46,155 iteration 1856 : loss : 0.020388, loss_ce: 0.006153
2021-11-30 14:09:47,378 iteration 1857 : loss : 0.022711, loss_ce: 0.009132
2021-11-30 14:09:48,595 iteration 1858 : loss : 0.017855, loss_ce: 0.007562
2021-11-30 14:09:49,820 iteration 1859 : loss : 0.023571, loss_ce: 0.007681
2021-11-30 14:09:51,038 iteration 1860 : loss : 0.020310, loss_ce: 0.007763
2021-11-30 14:09:52,253 iteration 1861 : loss : 0.017608, loss_ce: 0.006112
2021-11-30 14:09:53,471 iteration 1862 : loss : 0.017844, loss_ce: 0.006322
2021-11-30 14:09:54,686 iteration 1863 : loss : 0.024388, loss_ce: 0.010607
2021-11-30 14:09:55,911 iteration 1864 : loss : 0.019378, loss_ce: 0.007586
2021-11-30 14:09:57,137 iteration 1865 : loss : 0.023304, loss_ce: 0.010665
2021-11-30 14:09:58,359 iteration 1866 : loss : 0.021446, loss_ce: 0.008540
2021-11-30 14:09:59,574 iteration 1867 : loss : 0.021023, loss_ce: 0.009756
2021-11-30 14:10:00,791 iteration 1868 : loss : 0.016979, loss_ce: 0.006115
2021-11-30 14:10:02,014 iteration 1869 : loss : 0.019000, loss_ce: 0.006380
2021-11-30 14:10:02,014 Training Data Eval:
2021-11-30 14:10:08,915   Average segmentation loss on training set: 0.0245
2021-11-30 14:10:08,916 Validation Data Eval:
2021-11-30 14:10:11,291   Average segmentation loss on validation set: 0.1278
2021-11-30 14:10:12,521 iteration 1870 : loss : 0.025679, loss_ce: 0.009510
 28%|███████▉                     | 110/400 [41:46<1:56:49, 24.17s/it]2021-11-30 14:10:13,814 iteration 1871 : loss : 0.018436, loss_ce: 0.008299
2021-11-30 14:10:15,040 iteration 1872 : loss : 0.021762, loss_ce: 0.010852
2021-11-30 14:10:16,261 iteration 1873 : loss : 0.024578, loss_ce: 0.007815
2021-11-30 14:10:17,485 iteration 1874 : loss : 0.016757, loss_ce: 0.006823
2021-11-30 14:10:18,704 iteration 1875 : loss : 0.022693, loss_ce: 0.010772
2021-11-30 14:10:19,926 iteration 1876 : loss : 0.026407, loss_ce: 0.006516
2021-11-30 14:10:21,150 iteration 1877 : loss : 0.021029, loss_ce: 0.010876
2021-11-30 14:10:22,364 iteration 1878 : loss : 0.018493, loss_ce: 0.007307
2021-11-30 14:10:23,585 iteration 1879 : loss : 0.016553, loss_ce: 0.006664
2021-11-30 14:10:24,810 iteration 1880 : loss : 0.020853, loss_ce: 0.009542
2021-11-30 14:10:26,031 iteration 1881 : loss : 0.019324, loss_ce: 0.006979
2021-11-30 14:10:27,251 iteration 1882 : loss : 0.020933, loss_ce: 0.006742
2021-11-30 14:10:28,468 iteration 1883 : loss : 0.025908, loss_ce: 0.008407
2021-11-30 14:10:29,693 iteration 1884 : loss : 0.016176, loss_ce: 0.005620
2021-11-30 14:10:30,915 iteration 1885 : loss : 0.019789, loss_ce: 0.005886
2021-11-30 14:10:32,139 iteration 1886 : loss : 0.021274, loss_ce: 0.007992
2021-11-30 14:10:33,353 iteration 1887 : loss : 0.020021, loss_ce: 0.007398
 28%|████████                     | 111/400 [42:07<1:51:35, 23.17s/it]2021-11-30 14:10:34,639 iteration 1888 : loss : 0.022299, loss_ce: 0.007426
2021-11-30 14:10:35,856 iteration 1889 : loss : 0.021040, loss_ce: 0.010380
2021-11-30 14:10:37,065 iteration 1890 : loss : 0.014757, loss_ce: 0.005092
2021-11-30 14:10:38,285 iteration 1891 : loss : 0.016647, loss_ce: 0.007288
2021-11-30 14:10:39,511 iteration 1892 : loss : 0.019506, loss_ce: 0.006554
2021-11-30 14:10:40,726 iteration 1893 : loss : 0.016755, loss_ce: 0.007289
2021-11-30 14:10:41,948 iteration 1894 : loss : 0.019879, loss_ce: 0.007045
2021-11-30 14:10:43,166 iteration 1895 : loss : 0.025107, loss_ce: 0.007655
2021-11-30 14:10:44,386 iteration 1896 : loss : 0.019944, loss_ce: 0.006030
2021-11-30 14:10:45,608 iteration 1897 : loss : 0.019627, loss_ce: 0.007714
2021-11-30 14:10:46,831 iteration 1898 : loss : 0.019232, loss_ce: 0.006986
2021-11-30 14:10:48,052 iteration 1899 : loss : 0.017909, loss_ce: 0.006427
2021-11-30 14:10:49,273 iteration 1900 : loss : 0.019125, loss_ce: 0.007556
2021-11-30 14:10:50,497 iteration 1901 : loss : 0.020245, loss_ce: 0.006668
2021-11-30 14:10:51,730 iteration 1902 : loss : 0.017905, loss_ce: 0.005760
2021-11-30 14:10:52,953 iteration 1903 : loss : 0.017217, loss_ce: 0.007587
2021-11-30 14:10:54,172 iteration 1904 : loss : 0.016488, loss_ce: 0.007674
 28%|████████                     | 112/400 [42:28<1:47:49, 22.46s/it]2021-11-30 14:10:55,467 iteration 1905 : loss : 0.016215, loss_ce: 0.008012
2021-11-30 14:10:56,688 iteration 1906 : loss : 0.017625, loss_ce: 0.006840
2021-11-30 14:10:57,905 iteration 1907 : loss : 0.018200, loss_ce: 0.008090
2021-11-30 14:10:59,129 iteration 1908 : loss : 0.017875, loss_ce: 0.008020
2021-11-30 14:11:00,354 iteration 1909 : loss : 0.018368, loss_ce: 0.006754
2021-11-30 14:11:01,566 iteration 1910 : loss : 0.018424, loss_ce: 0.005744
2021-11-30 14:11:02,787 iteration 1911 : loss : 0.018211, loss_ce: 0.005836
2021-11-30 14:11:04,010 iteration 1912 : loss : 0.017410, loss_ce: 0.007345
2021-11-30 14:11:05,230 iteration 1913 : loss : 0.018728, loss_ce: 0.008465
2021-11-30 14:11:06,455 iteration 1914 : loss : 0.018160, loss_ce: 0.007681
2021-11-30 14:11:07,679 iteration 1915 : loss : 0.018490, loss_ce: 0.007453
2021-11-30 14:11:08,899 iteration 1916 : loss : 0.016218, loss_ce: 0.005364
2021-11-30 14:11:10,126 iteration 1917 : loss : 0.021333, loss_ce: 0.005417
2021-11-30 14:11:11,345 iteration 1918 : loss : 0.022416, loss_ce: 0.009727
2021-11-30 14:11:12,565 iteration 1919 : loss : 0.018777, loss_ce: 0.008040
2021-11-30 14:11:13,785 iteration 1920 : loss : 0.018291, loss_ce: 0.006517
2021-11-30 14:11:15,013 iteration 1921 : loss : 0.017364, loss_ce: 0.005116
 28%|████████▏                    | 113/400 [42:49<1:45:07, 21.98s/it]2021-11-30 14:11:16,294 iteration 1922 : loss : 0.017749, loss_ce: 0.006895
2021-11-30 14:11:17,517 iteration 1923 : loss : 0.018924, loss_ce: 0.006984
2021-11-30 14:11:18,740 iteration 1924 : loss : 0.016621, loss_ce: 0.005330
2021-11-30 14:11:19,964 iteration 1925 : loss : 0.014012, loss_ce: 0.006150
2021-11-30 14:11:21,175 iteration 1926 : loss : 0.017592, loss_ce: 0.007052
2021-11-30 14:11:22,399 iteration 1927 : loss : 0.035789, loss_ce: 0.009316
2021-11-30 14:11:23,620 iteration 1928 : loss : 0.016028, loss_ce: 0.004924
2021-11-30 14:11:24,846 iteration 1929 : loss : 0.016445, loss_ce: 0.006600
2021-11-30 14:11:26,066 iteration 1930 : loss : 0.025247, loss_ce: 0.005898
2021-11-30 14:11:27,286 iteration 1931 : loss : 0.019610, loss_ce: 0.008650
2021-11-30 14:11:28,510 iteration 1932 : loss : 0.019698, loss_ce: 0.006988
2021-11-30 14:11:29,730 iteration 1933 : loss : 0.020358, loss_ce: 0.006380
2021-11-30 14:11:30,953 iteration 1934 : loss : 0.024261, loss_ce: 0.009526
2021-11-30 14:11:32,178 iteration 1935 : loss : 0.016054, loss_ce: 0.006917
2021-11-30 14:11:33,398 iteration 1936 : loss : 0.013987, loss_ce: 0.005708
2021-11-30 14:11:34,621 iteration 1937 : loss : 0.015134, loss_ce: 0.006376
2021-11-30 14:11:35,841 iteration 1938 : loss : 0.022150, loss_ce: 0.007909
 28%|████████▎                    | 114/400 [43:09<1:43:07, 21.63s/it]2021-11-30 14:11:37,134 iteration 1939 : loss : 0.026340, loss_ce: 0.007793
2021-11-30 14:11:38,362 iteration 1940 : loss : 0.018808, loss_ce: 0.006681
2021-11-30 14:11:39,584 iteration 1941 : loss : 0.015034, loss_ce: 0.006800
2021-11-30 14:11:40,801 iteration 1942 : loss : 0.017880, loss_ce: 0.007932
2021-11-30 14:11:42,024 iteration 1943 : loss : 0.018188, loss_ce: 0.007054
2021-11-30 14:11:43,247 iteration 1944 : loss : 0.022288, loss_ce: 0.008425
2021-11-30 14:11:44,464 iteration 1945 : loss : 0.019211, loss_ce: 0.006586
2021-11-30 14:11:45,692 iteration 1946 : loss : 0.020841, loss_ce: 0.007277
2021-11-30 14:11:46,916 iteration 1947 : loss : 0.013823, loss_ce: 0.005367
2021-11-30 14:11:48,143 iteration 1948 : loss : 0.019321, loss_ce: 0.005596
2021-11-30 14:11:49,371 iteration 1949 : loss : 0.019072, loss_ce: 0.007417
2021-11-30 14:11:50,591 iteration 1950 : loss : 0.021099, loss_ce: 0.009094
2021-11-30 14:11:51,815 iteration 1951 : loss : 0.022404, loss_ce: 0.009672
2021-11-30 14:11:53,044 iteration 1952 : loss : 0.019494, loss_ce: 0.006776
2021-11-30 14:11:54,272 iteration 1953 : loss : 0.017703, loss_ce: 0.008060
2021-11-30 14:11:55,496 iteration 1954 : loss : 0.023058, loss_ce: 0.006733
2021-11-30 14:11:55,496 Training Data Eval:
2021-11-30 14:12:02,428   Average segmentation loss on training set: 0.0196
2021-11-30 14:12:02,428 Validation Data Eval:
2021-11-30 14:12:04,805   Average segmentation loss on validation set: 0.1216
2021-11-30 14:12:06,027 iteration 1955 : loss : 0.018801, loss_ce: 0.007261
 29%|████████▎                    | 115/400 [43:40<1:54:56, 24.20s/it]2021-11-30 14:12:07,317 iteration 1956 : loss : 0.018044, loss_ce: 0.006076
2021-11-30 14:12:08,542 iteration 1957 : loss : 0.019904, loss_ce: 0.006245
2021-11-30 14:12:09,763 iteration 1958 : loss : 0.022254, loss_ce: 0.008438
2021-11-30 14:12:10,991 iteration 1959 : loss : 0.023493, loss_ce: 0.008041
2021-11-30 14:12:12,207 iteration 1960 : loss : 0.018361, loss_ce: 0.006868
2021-11-30 14:12:13,430 iteration 1961 : loss : 0.021380, loss_ce: 0.005965
2021-11-30 14:12:14,655 iteration 1962 : loss : 0.021014, loss_ce: 0.009059
2021-11-30 14:12:15,871 iteration 1963 : loss : 0.020356, loss_ce: 0.008561
2021-11-30 14:12:17,089 iteration 1964 : loss : 0.017130, loss_ce: 0.005608
2021-11-30 14:12:18,314 iteration 1965 : loss : 0.016431, loss_ce: 0.007579
2021-11-30 14:12:19,539 iteration 1966 : loss : 0.021885, loss_ce: 0.006851
2021-11-30 14:12:20,759 iteration 1967 : loss : 0.021408, loss_ce: 0.008413
2021-11-30 14:12:21,986 iteration 1968 : loss : 0.017217, loss_ce: 0.008371
2021-11-30 14:12:23,210 iteration 1969 : loss : 0.022774, loss_ce: 0.007084
2021-11-30 14:12:24,434 iteration 1970 : loss : 0.019236, loss_ce: 0.009097
2021-11-30 14:12:25,659 iteration 1971 : loss : 0.022595, loss_ce: 0.011310
2021-11-30 14:12:26,874 iteration 1972 : loss : 0.021762, loss_ce: 0.008404
 29%|████████▍                    | 116/400 [44:00<1:49:46, 23.19s/it]2021-11-30 14:12:28,170 iteration 1973 : loss : 0.018937, loss_ce: 0.007488
2021-11-30 14:12:29,389 iteration 1974 : loss : 0.015439, loss_ce: 0.006658
2021-11-30 14:12:30,612 iteration 1975 : loss : 0.018468, loss_ce: 0.007675
2021-11-30 14:12:31,840 iteration 1976 : loss : 0.019456, loss_ce: 0.008278
2021-11-30 14:12:33,067 iteration 1977 : loss : 0.019844, loss_ce: 0.007606
2021-11-30 14:12:34,290 iteration 1978 : loss : 0.021333, loss_ce: 0.007103
2021-11-30 14:12:35,506 iteration 1979 : loss : 0.025251, loss_ce: 0.007519
2021-11-30 14:12:36,727 iteration 1980 : loss : 0.019450, loss_ce: 0.005860
2021-11-30 14:12:37,954 iteration 1981 : loss : 0.017266, loss_ce: 0.006798
2021-11-30 14:12:39,181 iteration 1982 : loss : 0.021727, loss_ce: 0.009009
2021-11-30 14:12:40,400 iteration 1983 : loss : 0.022792, loss_ce: 0.007383
2021-11-30 14:12:41,621 iteration 1984 : loss : 0.019168, loss_ce: 0.007864
2021-11-30 14:12:42,846 iteration 1985 : loss : 0.019022, loss_ce: 0.006750
2021-11-30 14:12:44,070 iteration 1986 : loss : 0.024719, loss_ce: 0.010547
2021-11-30 14:12:45,296 iteration 1987 : loss : 0.022492, loss_ce: 0.005968
2021-11-30 14:12:46,522 iteration 1988 : loss : 0.019226, loss_ce: 0.007114
2021-11-30 14:12:47,752 iteration 1989 : loss : 0.019824, loss_ce: 0.008614
 29%|████████▍                    | 117/400 [44:21<1:46:07, 22.50s/it]2021-11-30 14:12:49,048 iteration 1990 : loss : 0.017792, loss_ce: 0.007129
2021-11-30 14:12:50,274 iteration 1991 : loss : 0.020193, loss_ce: 0.007098
2021-11-30 14:12:51,496 iteration 1992 : loss : 0.016752, loss_ce: 0.006893
2021-11-30 14:12:52,718 iteration 1993 : loss : 0.015950, loss_ce: 0.006801
2021-11-30 14:12:53,940 iteration 1994 : loss : 0.020635, loss_ce: 0.005380
2021-11-30 14:12:55,164 iteration 1995 : loss : 0.014107, loss_ce: 0.004973
2021-11-30 14:12:56,385 iteration 1996 : loss : 0.024071, loss_ce: 0.006794
2021-11-30 14:12:57,601 iteration 1997 : loss : 0.017581, loss_ce: 0.005298
2021-11-30 14:12:58,823 iteration 1998 : loss : 0.024865, loss_ce: 0.013767
2021-11-30 14:13:00,050 iteration 1999 : loss : 0.024740, loss_ce: 0.014375
2021-11-30 14:13:01,265 iteration 2000 : loss : 0.029759, loss_ce: 0.014619
2021-11-30 14:13:02,484 iteration 2001 : loss : 0.013420, loss_ce: 0.006218
2021-11-30 14:13:03,707 iteration 2002 : loss : 0.020983, loss_ce: 0.008290
2021-11-30 14:13:04,930 iteration 2003 : loss : 0.017794, loss_ce: 0.007053
2021-11-30 14:13:06,156 iteration 2004 : loss : 0.026139, loss_ce: 0.008075
2021-11-30 14:13:07,377 iteration 2005 : loss : 0.017173, loss_ce: 0.007376
2021-11-30 14:13:08,606 iteration 2006 : loss : 0.023617, loss_ce: 0.010472
 30%|████████▌                    | 118/400 [44:42<1:43:25, 22.01s/it]2021-11-30 14:13:09,892 iteration 2007 : loss : 0.018454, loss_ce: 0.008300
2021-11-30 14:13:11,114 iteration 2008 : loss : 0.016434, loss_ce: 0.005681
2021-11-30 14:13:12,336 iteration 2009 : loss : 0.018496, loss_ce: 0.006494
2021-11-30 14:13:13,563 iteration 2010 : loss : 0.015471, loss_ce: 0.005858
2021-11-30 14:13:14,792 iteration 2011 : loss : 0.016825, loss_ce: 0.005273
2021-11-30 14:13:16,010 iteration 2012 : loss : 0.018750, loss_ce: 0.010214
2021-11-30 14:13:17,230 iteration 2013 : loss : 0.018696, loss_ce: 0.005316
2021-11-30 14:13:18,451 iteration 2014 : loss : 0.016794, loss_ce: 0.006601
2021-11-30 14:13:19,678 iteration 2015 : loss : 0.021769, loss_ce: 0.005830
2021-11-30 14:13:20,898 iteration 2016 : loss : 0.015785, loss_ce: 0.006889
2021-11-30 14:13:22,122 iteration 2017 : loss : 0.020959, loss_ce: 0.008980
2021-11-30 14:13:23,345 iteration 2018 : loss : 0.017790, loss_ce: 0.006987
2021-11-30 14:13:24,558 iteration 2019 : loss : 0.019753, loss_ce: 0.009426
2021-11-30 14:13:25,783 iteration 2020 : loss : 0.019838, loss_ce: 0.008070
2021-11-30 14:13:27,002 iteration 2021 : loss : 0.020041, loss_ce: 0.008175
2021-11-30 14:13:28,220 iteration 2022 : loss : 0.023751, loss_ce: 0.007025
2021-11-30 14:13:29,445 iteration 2023 : loss : 0.017658, loss_ce: 0.008151
 30%|████████▋                    | 119/400 [45:03<1:41:25, 21.66s/it]2021-11-30 14:13:30,734 iteration 2024 : loss : 0.022656, loss_ce: 0.007784
2021-11-30 14:13:31,955 iteration 2025 : loss : 0.016006, loss_ce: 0.005245
2021-11-30 14:13:33,171 iteration 2026 : loss : 0.023292, loss_ce: 0.007679
2021-11-30 14:13:34,388 iteration 2027 : loss : 0.018744, loss_ce: 0.008509
2021-11-30 14:13:35,608 iteration 2028 : loss : 0.018666, loss_ce: 0.008319
2021-11-30 14:13:36,836 iteration 2029 : loss : 0.023122, loss_ce: 0.007600
2021-11-30 14:13:38,060 iteration 2030 : loss : 0.022194, loss_ce: 0.006293
2021-11-30 14:13:39,284 iteration 2031 : loss : 0.018959, loss_ce: 0.006306
2021-11-30 14:13:40,503 iteration 2032 : loss : 0.018339, loss_ce: 0.007883
2021-11-30 14:13:41,719 iteration 2033 : loss : 0.019584, loss_ce: 0.006814
2021-11-30 14:13:42,936 iteration 2034 : loss : 0.020669, loss_ce: 0.007765
2021-11-30 14:13:44,161 iteration 2035 : loss : 0.021484, loss_ce: 0.007552
2021-11-30 14:13:45,381 iteration 2036 : loss : 0.019233, loss_ce: 0.008498
2021-11-30 14:13:46,593 iteration 2037 : loss : 0.016655, loss_ce: 0.005696
2021-11-30 14:13:47,813 iteration 2038 : loss : 0.019529, loss_ce: 0.004212
2021-11-30 14:13:49,035 iteration 2039 : loss : 0.018844, loss_ce: 0.007827
2021-11-30 14:13:49,035 Training Data Eval:
2021-11-30 14:13:55,949   Average segmentation loss on training set: 0.0189
2021-11-30 14:13:55,950 Validation Data Eval:
2021-11-30 14:13:58,327   Average segmentation loss on validation set: 0.1516
2021-11-30 14:13:59,548 iteration 2040 : loss : 0.014276, loss_ce: 0.006280
 30%|████████▋                    | 120/400 [45:33<1:52:52, 24.19s/it]2021-11-30 14:14:00,838 iteration 2041 : loss : 0.026516, loss_ce: 0.009413
2021-11-30 14:14:02,059 iteration 2042 : loss : 0.018258, loss_ce: 0.007654
2021-11-30 14:14:03,288 iteration 2043 : loss : 0.017163, loss_ce: 0.005806
2021-11-30 14:14:04,511 iteration 2044 : loss : 0.014528, loss_ce: 0.005166
2021-11-30 14:14:05,733 iteration 2045 : loss : 0.022549, loss_ce: 0.007541
2021-11-30 14:14:06,960 iteration 2046 : loss : 0.020028, loss_ce: 0.007421
2021-11-30 14:14:08,191 iteration 2047 : loss : 0.018546, loss_ce: 0.007479
2021-11-30 14:14:09,412 iteration 2048 : loss : 0.018037, loss_ce: 0.007984
2021-11-30 14:14:10,631 iteration 2049 : loss : 0.019530, loss_ce: 0.008350
2021-11-30 14:14:11,852 iteration 2050 : loss : 0.016238, loss_ce: 0.005782
2021-11-30 14:14:13,086 iteration 2051 : loss : 0.021604, loss_ce: 0.007893
2021-11-30 14:14:14,310 iteration 2052 : loss : 0.028318, loss_ce: 0.009763
2021-11-30 14:14:15,534 iteration 2053 : loss : 0.017426, loss_ce: 0.007303
2021-11-30 14:14:16,755 iteration 2054 : loss : 0.021962, loss_ce: 0.006226
2021-11-30 14:14:17,984 iteration 2055 : loss : 0.018806, loss_ce: 0.006757
2021-11-30 14:14:19,211 iteration 2056 : loss : 0.014586, loss_ce: 0.005066
2021-11-30 14:14:20,436 iteration 2057 : loss : 0.024158, loss_ce: 0.009168
 30%|████████▊                    | 121/400 [45:54<1:47:52, 23.20s/it]2021-11-30 14:14:21,734 iteration 2058 : loss : 0.015818, loss_ce: 0.005262
2021-11-30 14:14:22,962 iteration 2059 : loss : 0.016443, loss_ce: 0.007330
2021-11-30 14:14:24,184 iteration 2060 : loss : 0.016231, loss_ce: 0.007177
2021-11-30 14:14:25,407 iteration 2061 : loss : 0.016212, loss_ce: 0.006938
2021-11-30 14:14:26,632 iteration 2062 : loss : 0.021101, loss_ce: 0.006143
2021-11-30 14:14:27,857 iteration 2063 : loss : 0.015150, loss_ce: 0.006707
2021-11-30 14:14:29,078 iteration 2064 : loss : 0.015562, loss_ce: 0.006248
2021-11-30 14:14:30,305 iteration 2065 : loss : 0.017257, loss_ce: 0.005860
2021-11-30 14:14:31,528 iteration 2066 : loss : 0.018804, loss_ce: 0.008245
2021-11-30 14:14:32,762 iteration 2067 : loss : 0.016967, loss_ce: 0.006810
2021-11-30 14:14:33,984 iteration 2068 : loss : 0.018174, loss_ce: 0.007027
2021-11-30 14:14:35,203 iteration 2069 : loss : 0.018427, loss_ce: 0.005874
2021-11-30 14:14:36,426 iteration 2070 : loss : 0.014165, loss_ce: 0.004225
2021-11-30 14:14:37,646 iteration 2071 : loss : 0.021699, loss_ce: 0.006986
2021-11-30 14:14:38,870 iteration 2072 : loss : 0.018068, loss_ce: 0.007655
2021-11-30 14:14:40,098 iteration 2073 : loss : 0.014788, loss_ce: 0.004681
2021-11-30 14:14:41,321 iteration 2074 : loss : 0.017164, loss_ce: 0.006099
 30%|████████▊                    | 122/400 [46:15<1:44:16, 22.50s/it]2021-11-30 14:14:42,612 iteration 2075 : loss : 0.015585, loss_ce: 0.006781
2021-11-30 14:14:43,836 iteration 2076 : loss : 0.019093, loss_ce: 0.005666
2021-11-30 14:14:45,062 iteration 2077 : loss : 0.023306, loss_ce: 0.005602
2021-11-30 14:14:46,283 iteration 2078 : loss : 0.016761, loss_ce: 0.005244
2021-11-30 14:14:47,505 iteration 2079 : loss : 0.018071, loss_ce: 0.007443
2021-11-30 14:14:48,727 iteration 2080 : loss : 0.019947, loss_ce: 0.007367
2021-11-30 14:14:49,953 iteration 2081 : loss : 0.015352, loss_ce: 0.005233
2021-11-30 14:14:51,172 iteration 2082 : loss : 0.020155, loss_ce: 0.010019
2021-11-30 14:14:52,399 iteration 2083 : loss : 0.019599, loss_ce: 0.005448
2021-11-30 14:14:53,618 iteration 2084 : loss : 0.017511, loss_ce: 0.006477
2021-11-30 14:14:54,834 iteration 2085 : loss : 0.019498, loss_ce: 0.006887
2021-11-30 14:14:56,056 iteration 2086 : loss : 0.015646, loss_ce: 0.007399
2021-11-30 14:14:57,281 iteration 2087 : loss : 0.023053, loss_ce: 0.007471
2021-11-30 14:14:58,503 iteration 2088 : loss : 0.016671, loss_ce: 0.008057
2021-11-30 14:14:59,725 iteration 2089 : loss : 0.020406, loss_ce: 0.010444
2021-11-30 14:15:00,979 iteration 2090 : loss : 0.015723, loss_ce: 0.004638
2021-11-30 14:15:02,194 iteration 2091 : loss : 0.017816, loss_ce: 0.005778
 31%|████████▉                    | 123/400 [46:36<1:41:38, 22.01s/it]2021-11-30 14:15:03,482 iteration 2092 : loss : 0.019683, loss_ce: 0.006178
2021-11-30 14:15:04,703 iteration 2093 : loss : 0.019165, loss_ce: 0.007231
2021-11-30 14:15:05,926 iteration 2094 : loss : 0.016310, loss_ce: 0.006133
2021-11-30 14:15:07,148 iteration 2095 : loss : 0.018528, loss_ce: 0.006026
2021-11-30 14:15:08,365 iteration 2096 : loss : 0.015261, loss_ce: 0.005481
2021-11-30 14:15:09,587 iteration 2097 : loss : 0.020084, loss_ce: 0.006667
2021-11-30 14:15:10,801 iteration 2098 : loss : 0.019595, loss_ce: 0.008376
2021-11-30 14:15:12,021 iteration 2099 : loss : 0.014672, loss_ce: 0.006588
2021-11-30 14:15:13,244 iteration 2100 : loss : 0.016022, loss_ce: 0.004169
2021-11-30 14:15:14,468 iteration 2101 : loss : 0.015318, loss_ce: 0.005464
2021-11-30 14:15:15,685 iteration 2102 : loss : 0.021532, loss_ce: 0.012222
2021-11-30 14:15:16,905 iteration 2103 : loss : 0.016005, loss_ce: 0.006133
2021-11-30 14:15:18,125 iteration 2104 : loss : 0.014158, loss_ce: 0.005149
2021-11-30 14:15:19,350 iteration 2105 : loss : 0.019802, loss_ce: 0.008042
2021-11-30 14:15:20,568 iteration 2106 : loss : 0.017885, loss_ce: 0.008042
2021-11-30 14:15:21,784 iteration 2107 : loss : 0.018570, loss_ce: 0.007714
2021-11-30 14:15:23,008 iteration 2108 : loss : 0.015366, loss_ce: 0.007166
 31%|████████▉                    | 124/400 [46:57<1:39:36, 21.66s/it]2021-11-30 14:15:24,300 iteration 2109 : loss : 0.017107, loss_ce: 0.007769
2021-11-30 14:15:25,523 iteration 2110 : loss : 0.014707, loss_ce: 0.006931
2021-11-30 14:15:26,744 iteration 2111 : loss : 0.013775, loss_ce: 0.005463
2021-11-30 14:15:27,963 iteration 2112 : loss : 0.016558, loss_ce: 0.006643
2021-11-30 14:15:29,188 iteration 2113 : loss : 0.018432, loss_ce: 0.005845
2021-11-30 14:15:30,408 iteration 2114 : loss : 0.014697, loss_ce: 0.006051
2021-11-30 14:15:31,626 iteration 2115 : loss : 0.018158, loss_ce: 0.006551
2021-11-30 14:15:32,851 iteration 2116 : loss : 0.016326, loss_ce: 0.005644
2021-11-30 14:15:34,071 iteration 2117 : loss : 0.021762, loss_ce: 0.006866
2021-11-30 14:15:35,296 iteration 2118 : loss : 0.014844, loss_ce: 0.006107
2021-11-30 14:15:36,520 iteration 2119 : loss : 0.017849, loss_ce: 0.006134
2021-11-30 14:15:37,736 iteration 2120 : loss : 0.020002, loss_ce: 0.009920
2021-11-30 14:15:38,950 iteration 2121 : loss : 0.018888, loss_ce: 0.010786
2021-11-30 14:15:40,173 iteration 2122 : loss : 0.014211, loss_ce: 0.005151
2021-11-30 14:15:41,392 iteration 2123 : loss : 0.014568, loss_ce: 0.004987
2021-11-30 14:15:42,618 iteration 2124 : loss : 0.018042, loss_ce: 0.005475
2021-11-30 14:15:42,618 Training Data Eval:
2021-11-30 14:15:49,543   Average segmentation loss on training set: 0.0151
2021-11-30 14:15:49,543 Validation Data Eval:
2021-11-30 14:15:51,908   Average segmentation loss on validation set: 0.1265
2021-11-30 14:15:53,135 iteration 2125 : loss : 0.015422, loss_ce: 0.007004
 31%|█████████                    | 125/400 [47:27<1:50:53, 24.20s/it]2021-11-30 14:15:54,430 iteration 2126 : loss : 0.013810, loss_ce: 0.006824
2021-11-30 14:15:55,653 iteration 2127 : loss : 0.016256, loss_ce: 0.007514
2021-11-30 14:15:56,877 iteration 2128 : loss : 0.016955, loss_ce: 0.007245
2021-11-30 14:15:58,099 iteration 2129 : loss : 0.018089, loss_ce: 0.006734
2021-11-30 14:15:59,322 iteration 2130 : loss : 0.015727, loss_ce: 0.005687
2021-11-30 14:16:00,546 iteration 2131 : loss : 0.013307, loss_ce: 0.004925
2021-11-30 14:16:01,777 iteration 2132 : loss : 0.024882, loss_ce: 0.004063
2021-11-30 14:16:02,998 iteration 2133 : loss : 0.017923, loss_ce: 0.006788
2021-11-30 14:16:04,218 iteration 2134 : loss : 0.022514, loss_ce: 0.009961
2021-11-30 14:16:05,441 iteration 2135 : loss : 0.021567, loss_ce: 0.010366
2021-11-30 14:16:06,664 iteration 2136 : loss : 0.023523, loss_ce: 0.009827
2021-11-30 14:16:07,889 iteration 2137 : loss : 0.018833, loss_ce: 0.007258
2021-11-30 14:16:09,110 iteration 2138 : loss : 0.015743, loss_ce: 0.006220
2021-11-30 14:16:10,334 iteration 2139 : loss : 0.017427, loss_ce: 0.006737
2021-11-30 14:16:11,553 iteration 2140 : loss : 0.019053, loss_ce: 0.007564
2021-11-30 14:16:12,772 iteration 2141 : loss : 0.017389, loss_ce: 0.006474
2021-11-30 14:16:14,001 iteration 2142 : loss : 0.029815, loss_ce: 0.009418
 32%|█████████▏                   | 126/400 [47:48<1:45:55, 23.20s/it]2021-11-30 14:16:15,296 iteration 2143 : loss : 0.018891, loss_ce: 0.005999
2021-11-30 14:16:16,512 iteration 2144 : loss : 0.017534, loss_ce: 0.008966
2021-11-30 14:16:17,734 iteration 2145 : loss : 0.018417, loss_ce: 0.006383
2021-11-30 14:16:18,964 iteration 2146 : loss : 0.022051, loss_ce: 0.006682
2021-11-30 14:16:20,190 iteration 2147 : loss : 0.019097, loss_ce: 0.006955
2021-11-30 14:16:21,411 iteration 2148 : loss : 0.017314, loss_ce: 0.009298
2021-11-30 14:16:22,635 iteration 2149 : loss : 0.017722, loss_ce: 0.007742
2021-11-30 14:16:23,862 iteration 2150 : loss : 0.017404, loss_ce: 0.006794
2021-11-30 14:16:25,095 iteration 2151 : loss : 0.021474, loss_ce: 0.007179
2021-11-30 14:16:26,319 iteration 2152 : loss : 0.018179, loss_ce: 0.004686
2021-11-30 14:16:27,541 iteration 2153 : loss : 0.016760, loss_ce: 0.007237
2021-11-30 14:16:28,761 iteration 2154 : loss : 0.016758, loss_ce: 0.007032
2021-11-30 14:16:29,986 iteration 2155 : loss : 0.016010, loss_ce: 0.005755
2021-11-30 14:16:31,210 iteration 2156 : loss : 0.020431, loss_ce: 0.006737
2021-11-30 14:16:32,433 iteration 2157 : loss : 0.016859, loss_ce: 0.006894
2021-11-30 14:16:33,660 iteration 2158 : loss : 0.019309, loss_ce: 0.005604
2021-11-30 14:16:34,882 iteration 2159 : loss : 0.019388, loss_ce: 0.007757
 32%|█████████▏                   | 127/400 [48:08<1:42:23, 22.50s/it]2021-11-30 14:16:36,176 iteration 2160 : loss : 0.017264, loss_ce: 0.005885
2021-11-30 14:16:37,393 iteration 2161 : loss : 0.021537, loss_ce: 0.006475
2021-11-30 14:16:38,617 iteration 2162 : loss : 0.014327, loss_ce: 0.004738
2021-11-30 14:16:39,841 iteration 2163 : loss : 0.017304, loss_ce: 0.006436
2021-11-30 14:16:41,069 iteration 2164 : loss : 0.017165, loss_ce: 0.004898
2021-11-30 14:16:42,296 iteration 2165 : loss : 0.017645, loss_ce: 0.006384
2021-11-30 14:16:43,521 iteration 2166 : loss : 0.022558, loss_ce: 0.012436
2021-11-30 14:16:44,741 iteration 2167 : loss : 0.017307, loss_ce: 0.008603
2021-11-30 14:16:45,957 iteration 2168 : loss : 0.015578, loss_ce: 0.006670
2021-11-30 14:16:47,173 iteration 2169 : loss : 0.019683, loss_ce: 0.004166
2021-11-30 14:16:48,398 iteration 2170 : loss : 0.017869, loss_ce: 0.007982
2021-11-30 14:16:49,619 iteration 2171 : loss : 0.017318, loss_ce: 0.008780
2021-11-30 14:16:50,839 iteration 2172 : loss : 0.015524, loss_ce: 0.006917
2021-11-30 14:16:52,059 iteration 2173 : loss : 0.015077, loss_ce: 0.005741
2021-11-30 14:16:53,283 iteration 2174 : loss : 0.020994, loss_ce: 0.006409
2021-11-30 14:16:54,507 iteration 2175 : loss : 0.025153, loss_ce: 0.007541
2021-11-30 14:16:55,737 iteration 2176 : loss : 0.018972, loss_ce: 0.007739
 32%|█████████▎                   | 128/400 [48:29<1:39:46, 22.01s/it]2021-11-30 14:16:57,031 iteration 2177 : loss : 0.016396, loss_ce: 0.005632
2021-11-30 14:16:58,252 iteration 2178 : loss : 0.017854, loss_ce: 0.005760
2021-11-30 14:16:59,477 iteration 2179 : loss : 0.013282, loss_ce: 0.004739
2021-11-30 14:17:00,705 iteration 2180 : loss : 0.017821, loss_ce: 0.005291
2021-11-30 14:17:01,933 iteration 2181 : loss : 0.020988, loss_ce: 0.007687
2021-11-30 14:17:03,157 iteration 2182 : loss : 0.020546, loss_ce: 0.007225
2021-11-30 14:17:04,384 iteration 2183 : loss : 0.016844, loss_ce: 0.007562
2021-11-30 14:17:05,611 iteration 2184 : loss : 0.013639, loss_ce: 0.005331
2021-11-30 14:17:06,830 iteration 2185 : loss : 0.016839, loss_ce: 0.006306
2021-11-30 14:17:08,053 iteration 2186 : loss : 0.019780, loss_ce: 0.009039
2021-11-30 14:17:09,278 iteration 2187 : loss : 0.017408, loss_ce: 0.006604
2021-11-30 14:17:10,508 iteration 2188 : loss : 0.026073, loss_ce: 0.008089
2021-11-30 14:17:11,732 iteration 2189 : loss : 0.019527, loss_ce: 0.006439
2021-11-30 14:17:12,955 iteration 2190 : loss : 0.017424, loss_ce: 0.007887
2021-11-30 14:17:14,173 iteration 2191 : loss : 0.017537, loss_ce: 0.005207
2021-11-30 14:17:15,396 iteration 2192 : loss : 0.014805, loss_ce: 0.005567
2021-11-30 14:17:16,617 iteration 2193 : loss : 0.019373, loss_ce: 0.006862
 32%|█████████▎                   | 129/400 [48:50<1:37:52, 21.67s/it]2021-11-30 14:17:17,914 iteration 2194 : loss : 0.014835, loss_ce: 0.006352
2021-11-30 14:17:19,146 iteration 2195 : loss : 0.018285, loss_ce: 0.007050
2021-11-30 14:17:20,360 iteration 2196 : loss : 0.015471, loss_ce: 0.007304
2021-11-30 14:17:21,584 iteration 2197 : loss : 0.017282, loss_ce: 0.006736
2021-11-30 14:17:22,808 iteration 2198 : loss : 0.022254, loss_ce: 0.006628
2021-11-30 14:17:24,032 iteration 2199 : loss : 0.019390, loss_ce: 0.008478
2021-11-30 14:17:25,253 iteration 2200 : loss : 0.017050, loss_ce: 0.005360
2021-11-30 14:17:26,474 iteration 2201 : loss : 0.015725, loss_ce: 0.005317
2021-11-30 14:17:27,699 iteration 2202 : loss : 0.015109, loss_ce: 0.006315
2021-11-30 14:17:28,921 iteration 2203 : loss : 0.016170, loss_ce: 0.006023
2021-11-30 14:17:30,143 iteration 2204 : loss : 0.015121, loss_ce: 0.004568
2021-11-30 14:17:31,361 iteration 2205 : loss : 0.021081, loss_ce: 0.007235
2021-11-30 14:17:32,587 iteration 2206 : loss : 0.015041, loss_ce: 0.004918
2021-11-30 14:17:33,817 iteration 2207 : loss : 0.019397, loss_ce: 0.006288
2021-11-30 14:17:35,038 iteration 2208 : loss : 0.015914, loss_ce: 0.006508
2021-11-30 14:17:36,261 iteration 2209 : loss : 0.017974, loss_ce: 0.008551
2021-11-30 14:17:36,261 Training Data Eval:
2021-11-30 14:17:43,172   Average segmentation loss on training set: 0.0161
2021-11-30 14:17:43,172 Validation Data Eval:
2021-11-30 14:17:45,534   Average segmentation loss on validation set: 0.1072
2021-11-30 14:17:46,756 iteration 2210 : loss : 0.015333, loss_ce: 0.005252
 32%|█████████▍                   | 130/400 [49:20<1:48:56, 24.21s/it]2021-11-30 14:17:48,049 iteration 2211 : loss : 0.014790, loss_ce: 0.007095
2021-11-30 14:17:49,271 iteration 2212 : loss : 0.013463, loss_ce: 0.005899
2021-11-30 14:17:50,490 iteration 2213 : loss : 0.014828, loss_ce: 0.006864
2021-11-30 14:17:51,720 iteration 2214 : loss : 0.014351, loss_ce: 0.006560
2021-11-30 14:17:52,949 iteration 2215 : loss : 0.013875, loss_ce: 0.005338
2021-11-30 14:17:54,173 iteration 2216 : loss : 0.014546, loss_ce: 0.005806
2021-11-30 14:17:55,393 iteration 2217 : loss : 0.022116, loss_ce: 0.007470
2021-11-30 14:17:56,612 iteration 2218 : loss : 0.022112, loss_ce: 0.005665
2021-11-30 14:17:57,833 iteration 2219 : loss : 0.018884, loss_ce: 0.005985
2021-11-30 14:17:59,052 iteration 2220 : loss : 0.017953, loss_ce: 0.006692
2021-11-30 14:18:00,277 iteration 2221 : loss : 0.021010, loss_ce: 0.004595
2021-11-30 14:18:01,502 iteration 2222 : loss : 0.020324, loss_ce: 0.007796
2021-11-30 14:18:02,722 iteration 2223 : loss : 0.025381, loss_ce: 0.011738
2021-11-30 14:18:03,942 iteration 2224 : loss : 0.019288, loss_ce: 0.005567
2021-11-30 14:18:05,161 iteration 2225 : loss : 0.021631, loss_ce: 0.009773
2021-11-30 14:18:06,397 iteration 2226 : loss : 0.024468, loss_ce: 0.006905
2021-11-30 14:18:07,623 iteration 2227 : loss : 0.018330, loss_ce: 0.006838
 33%|█████████▍                   | 131/400 [49:41<1:44:02, 23.21s/it]2021-11-30 14:18:08,916 iteration 2228 : loss : 0.023007, loss_ce: 0.009449
2021-11-30 14:18:10,139 iteration 2229 : loss : 0.025305, loss_ce: 0.008143
2021-11-30 14:18:11,362 iteration 2230 : loss : 0.016715, loss_ce: 0.006942
2021-11-30 14:18:12,586 iteration 2231 : loss : 0.014793, loss_ce: 0.005502
2021-11-30 14:18:13,812 iteration 2232 : loss : 0.016383, loss_ce: 0.005293
2021-11-30 14:18:15,028 iteration 2233 : loss : 0.021995, loss_ce: 0.006891
2021-11-30 14:18:16,253 iteration 2234 : loss : 0.015237, loss_ce: 0.006056
2021-11-30 14:18:17,470 iteration 2235 : loss : 0.016976, loss_ce: 0.007507
2021-11-30 14:18:18,687 iteration 2236 : loss : 0.020294, loss_ce: 0.009327
2021-11-30 14:18:19,908 iteration 2237 : loss : 0.018890, loss_ce: 0.007424
2021-11-30 14:18:21,129 iteration 2238 : loss : 0.017971, loss_ce: 0.006467
2021-11-30 14:18:22,354 iteration 2239 : loss : 0.013895, loss_ce: 0.004184
2021-11-30 14:18:23,571 iteration 2240 : loss : 0.013907, loss_ce: 0.005325
2021-11-30 14:18:24,793 iteration 2241 : loss : 0.019436, loss_ce: 0.007053
2021-11-30 14:18:26,023 iteration 2242 : loss : 0.014540, loss_ce: 0.004540
2021-11-30 14:18:27,251 iteration 2243 : loss : 0.014361, loss_ce: 0.005363
2021-11-30 14:18:28,468 iteration 2244 : loss : 0.021282, loss_ce: 0.007033
 33%|█████████▌                   | 132/400 [50:02<1:40:29, 22.50s/it]2021-11-30 14:18:29,753 iteration 2245 : loss : 0.017897, loss_ce: 0.005826
2021-11-30 14:18:30,975 iteration 2246 : loss : 0.013654, loss_ce: 0.005823
2021-11-30 14:18:32,193 iteration 2247 : loss : 0.016598, loss_ce: 0.005986
2021-11-30 14:18:33,416 iteration 2248 : loss : 0.016026, loss_ce: 0.005724
2021-11-30 14:18:34,642 iteration 2249 : loss : 0.018062, loss_ce: 0.006796
2021-11-30 14:18:35,864 iteration 2250 : loss : 0.015171, loss_ce: 0.004901
2021-11-30 14:18:37,088 iteration 2251 : loss : 0.016701, loss_ce: 0.007536
2021-11-30 14:18:38,309 iteration 2252 : loss : 0.020248, loss_ce: 0.005303
2021-11-30 14:18:39,533 iteration 2253 : loss : 0.016392, loss_ce: 0.005941
2021-11-30 14:18:40,760 iteration 2254 : loss : 0.017130, loss_ce: 0.006925
2021-11-30 14:18:41,978 iteration 2255 : loss : 0.014471, loss_ce: 0.004864
2021-11-30 14:18:43,201 iteration 2256 : loss : 0.019878, loss_ce: 0.006002
2021-11-30 14:18:44,433 iteration 2257 : loss : 0.030941, loss_ce: 0.005977
2021-11-30 14:18:45,655 iteration 2258 : loss : 0.016038, loss_ce: 0.006930
2021-11-30 14:18:46,870 iteration 2259 : loss : 0.018916, loss_ce: 0.008138
2021-11-30 14:18:48,084 iteration 2260 : loss : 0.025319, loss_ce: 0.006676
2021-11-30 14:18:49,305 iteration 2261 : loss : 0.025126, loss_ce: 0.011063
 33%|█████████▋                   | 133/400 [50:23<1:37:54, 22.00s/it]2021-11-30 14:18:50,588 iteration 2262 : loss : 0.016707, loss_ce: 0.005371
2021-11-30 14:18:51,807 iteration 2263 : loss : 0.018495, loss_ce: 0.007326
2021-11-30 14:18:53,020 iteration 2264 : loss : 0.021064, loss_ce: 0.008815
2021-11-30 14:18:54,247 iteration 2265 : loss : 0.021122, loss_ce: 0.007352
2021-11-30 14:18:55,468 iteration 2266 : loss : 0.018924, loss_ce: 0.007177
2021-11-30 14:18:56,687 iteration 2267 : loss : 0.016732, loss_ce: 0.004463
2021-11-30 14:18:57,904 iteration 2268 : loss : 0.025898, loss_ce: 0.008916
2021-11-30 14:18:59,131 iteration 2269 : loss : 0.019297, loss_ce: 0.008410
2021-11-30 14:19:00,355 iteration 2270 : loss : 0.020709, loss_ce: 0.007798
2021-11-30 14:19:01,621 iteration 2271 : loss : 0.015604, loss_ce: 0.004775
2021-11-30 14:19:02,845 iteration 2272 : loss : 0.023165, loss_ce: 0.010110
2021-11-30 14:19:04,066 iteration 2273 : loss : 0.020800, loss_ce: 0.009024
2021-11-30 14:19:05,284 iteration 2274 : loss : 0.022510, loss_ce: 0.007197
2021-11-30 14:19:06,509 iteration 2275 : loss : 0.017106, loss_ce: 0.006050
2021-11-30 14:19:07,731 iteration 2276 : loss : 0.020636, loss_ce: 0.007555
2021-11-30 14:19:08,957 iteration 2277 : loss : 0.021878, loss_ce: 0.006168
2021-11-30 14:19:10,180 iteration 2278 : loss : 0.014410, loss_ce: 0.006355
 34%|█████████▋                   | 134/400 [50:44<1:36:02, 21.66s/it]2021-11-30 14:19:11,475 iteration 2279 : loss : 0.017737, loss_ce: 0.006507
2021-11-30 14:19:12,700 iteration 2280 : loss : 0.022026, loss_ce: 0.010186
2021-11-30 14:19:13,924 iteration 2281 : loss : 0.038854, loss_ce: 0.009033
2021-11-30 14:19:15,148 iteration 2282 : loss : 0.015562, loss_ce: 0.006591
2021-11-30 14:19:16,373 iteration 2283 : loss : 0.029182, loss_ce: 0.012786
2021-11-30 14:19:17,597 iteration 2284 : loss : 0.026653, loss_ce: 0.010225
2021-11-30 14:19:18,826 iteration 2285 : loss : 0.030184, loss_ce: 0.011962
2021-11-30 14:19:20,049 iteration 2286 : loss : 0.019752, loss_ce: 0.006127
2021-11-30 14:19:21,272 iteration 2287 : loss : 0.020649, loss_ce: 0.007940
2021-11-30 14:19:22,491 iteration 2288 : loss : 0.024964, loss_ce: 0.009259
2021-11-30 14:19:23,714 iteration 2289 : loss : 0.016631, loss_ce: 0.005830
2021-11-30 14:19:24,934 iteration 2290 : loss : 0.020164, loss_ce: 0.008767
2021-11-30 14:19:26,159 iteration 2291 : loss : 0.021134, loss_ce: 0.009066
2021-11-30 14:19:27,384 iteration 2292 : loss : 0.021199, loss_ce: 0.009860
2021-11-30 14:19:28,606 iteration 2293 : loss : 0.017945, loss_ce: 0.005704
2021-11-30 14:19:29,827 iteration 2294 : loss : 0.018865, loss_ce: 0.006493
2021-11-30 14:19:29,827 Training Data Eval:
2021-11-30 14:19:36,748   Average segmentation loss on training set: 0.0187
2021-11-30 14:19:36,748 Validation Data Eval:
2021-11-30 14:19:39,124   Average segmentation loss on validation set: 0.1118
2021-11-30 14:19:40,348 iteration 2295 : loss : 0.019198, loss_ce: 0.007137
 34%|█████████▊                   | 135/400 [51:14<1:46:56, 24.21s/it]2021-11-30 14:19:41,635 iteration 2296 : loss : 0.019529, loss_ce: 0.009468
2021-11-30 14:19:42,862 iteration 2297 : loss : 0.016161, loss_ce: 0.006236
2021-11-30 14:19:44,082 iteration 2298 : loss : 0.012874, loss_ce: 0.004463
2021-11-30 14:19:45,303 iteration 2299 : loss : 0.028404, loss_ce: 0.007130
2021-11-30 14:19:46,533 iteration 2300 : loss : 0.019355, loss_ce: 0.006186
2021-11-30 14:19:47,758 iteration 2301 : loss : 0.018853, loss_ce: 0.006024
2021-11-30 14:19:48,982 iteration 2302 : loss : 0.022023, loss_ce: 0.010930
2021-11-30 14:19:50,204 iteration 2303 : loss : 0.019049, loss_ce: 0.007362
2021-11-30 14:19:51,432 iteration 2304 : loss : 0.016997, loss_ce: 0.006387
2021-11-30 14:19:52,656 iteration 2305 : loss : 0.016005, loss_ce: 0.006652
2021-11-30 14:19:53,873 iteration 2306 : loss : 0.017588, loss_ce: 0.006926
2021-11-30 14:19:55,088 iteration 2307 : loss : 0.017146, loss_ce: 0.007879
2021-11-30 14:19:56,310 iteration 2308 : loss : 0.017521, loss_ce: 0.006617
2021-11-30 14:19:57,532 iteration 2309 : loss : 0.021639, loss_ce: 0.007556
2021-11-30 14:19:58,753 iteration 2310 : loss : 0.020807, loss_ce: 0.008486
2021-11-30 14:19:59,976 iteration 2311 : loss : 0.020917, loss_ce: 0.007896
2021-11-30 14:20:01,199 iteration 2312 : loss : 0.030653, loss_ce: 0.008480
 34%|█████████▊                   | 136/400 [51:35<1:42:06, 23.21s/it]2021-11-30 14:20:02,488 iteration 2313 : loss : 0.014708, loss_ce: 0.004634
2021-11-30 14:20:03,711 iteration 2314 : loss : 0.017368, loss_ce: 0.008906
2021-11-30 14:20:04,937 iteration 2315 : loss : 0.017642, loss_ce: 0.007295
2021-11-30 14:20:06,166 iteration 2316 : loss : 0.025479, loss_ce: 0.011763
2021-11-30 14:20:07,386 iteration 2317 : loss : 0.030179, loss_ce: 0.004820
2021-11-30 14:20:08,610 iteration 2318 : loss : 0.016294, loss_ce: 0.006665
2021-11-30 14:20:09,834 iteration 2319 : loss : 0.017311, loss_ce: 0.008803
2021-11-30 14:20:11,057 iteration 2320 : loss : 0.020146, loss_ce: 0.007876
2021-11-30 14:20:12,278 iteration 2321 : loss : 0.032385, loss_ce: 0.011461
2021-11-30 14:20:13,495 iteration 2322 : loss : 0.025170, loss_ce: 0.009425
2021-11-30 14:20:14,718 iteration 2323 : loss : 0.022261, loss_ce: 0.007932
2021-11-30 14:20:15,943 iteration 2324 : loss : 0.017625, loss_ce: 0.006923
2021-11-30 14:20:17,171 iteration 2325 : loss : 0.019752, loss_ce: 0.004598
2021-11-30 14:20:18,390 iteration 2326 : loss : 0.029986, loss_ce: 0.015507
2021-11-30 14:20:19,604 iteration 2327 : loss : 0.027025, loss_ce: 0.014336
2021-11-30 14:20:20,830 iteration 2328 : loss : 0.024096, loss_ce: 0.009817
2021-11-30 14:20:22,050 iteration 2329 : loss : 0.031591, loss_ce: 0.016876
 34%|█████████▉                   | 137/400 [51:56<1:38:37, 22.50s/it]2021-11-30 14:20:23,353 iteration 2330 : loss : 0.027197, loss_ce: 0.009222
2021-11-30 14:20:24,582 iteration 2331 : loss : 0.016315, loss_ce: 0.005908
2021-11-30 14:20:25,809 iteration 2332 : loss : 0.019204, loss_ce: 0.007723
2021-11-30 14:20:27,032 iteration 2333 : loss : 0.022264, loss_ce: 0.009510
2021-11-30 14:20:28,254 iteration 2334 : loss : 0.026475, loss_ce: 0.008944
2021-11-30 14:20:29,475 iteration 2335 : loss : 0.022442, loss_ce: 0.008834
2021-11-30 14:20:30,692 iteration 2336 : loss : 0.021879, loss_ce: 0.008801
2021-11-30 14:20:31,912 iteration 2337 : loss : 0.025214, loss_ce: 0.009614
2021-11-30 14:20:33,130 iteration 2338 : loss : 0.029542, loss_ce: 0.009237
2021-11-30 14:20:34,349 iteration 2339 : loss : 0.023721, loss_ce: 0.009697
2021-11-30 14:20:35,577 iteration 2340 : loss : 0.020223, loss_ce: 0.008126
2021-11-30 14:20:36,799 iteration 2341 : loss : 0.025744, loss_ce: 0.007392
2021-11-30 14:20:38,018 iteration 2342 : loss : 0.018845, loss_ce: 0.008671
2021-11-30 14:20:39,243 iteration 2343 : loss : 0.023369, loss_ce: 0.008039
2021-11-30 14:20:40,468 iteration 2344 : loss : 0.019419, loss_ce: 0.006958
2021-11-30 14:20:41,682 iteration 2345 : loss : 0.022458, loss_ce: 0.009082
2021-11-30 14:20:42,899 iteration 2346 : loss : 0.028242, loss_ce: 0.006764
 34%|██████████                   | 138/400 [52:16<1:36:04, 22.00s/it]2021-11-30 14:20:44,186 iteration 2347 : loss : 0.020742, loss_ce: 0.007901
2021-11-30 14:20:45,406 iteration 2348 : loss : 0.017520, loss_ce: 0.007471
2021-11-30 14:20:46,625 iteration 2349 : loss : 0.017495, loss_ce: 0.005174
2021-11-30 14:20:47,855 iteration 2350 : loss : 0.023478, loss_ce: 0.006742
2021-11-30 14:20:49,073 iteration 2351 : loss : 0.017803, loss_ce: 0.006835
2021-11-30 14:20:50,294 iteration 2352 : loss : 0.020969, loss_ce: 0.009209
2021-11-30 14:20:51,510 iteration 2353 : loss : 0.016522, loss_ce: 0.006373
2021-11-30 14:20:52,731 iteration 2354 : loss : 0.017118, loss_ce: 0.006275
2021-11-30 14:20:53,947 iteration 2355 : loss : 0.016831, loss_ce: 0.007681
2021-11-30 14:20:55,172 iteration 2356 : loss : 0.024820, loss_ce: 0.008620
2021-11-30 14:20:56,394 iteration 2357 : loss : 0.016308, loss_ce: 0.006027
2021-11-30 14:20:57,613 iteration 2358 : loss : 0.028712, loss_ce: 0.009497
2021-11-30 14:20:58,835 iteration 2359 : loss : 0.027677, loss_ce: 0.006420
2021-11-30 14:21:00,058 iteration 2360 : loss : 0.021786, loss_ce: 0.009345
2021-11-30 14:21:01,279 iteration 2361 : loss : 0.021998, loss_ce: 0.007999
2021-11-30 14:21:02,500 iteration 2362 : loss : 0.026871, loss_ce: 0.010045
2021-11-30 14:21:03,713 iteration 2363 : loss : 0.016511, loss_ce: 0.007170
 35%|██████████                   | 139/400 [52:37<1:34:09, 21.65s/it]2021-11-30 14:21:04,998 iteration 2364 : loss : 0.015986, loss_ce: 0.005927
2021-11-30 14:21:06,216 iteration 2365 : loss : 0.022138, loss_ce: 0.007707
2021-11-30 14:21:07,434 iteration 2366 : loss : 0.019283, loss_ce: 0.009749
2021-11-30 14:21:08,653 iteration 2367 : loss : 0.018117, loss_ce: 0.007712
2021-11-30 14:21:09,879 iteration 2368 : loss : 0.024633, loss_ce: 0.008008
2021-11-30 14:21:11,092 iteration 2369 : loss : 0.016373, loss_ce: 0.004998
2021-11-30 14:21:12,313 iteration 2370 : loss : 0.015813, loss_ce: 0.004288
2021-11-30 14:21:13,539 iteration 2371 : loss : 0.014112, loss_ce: 0.005771
2021-11-30 14:21:14,763 iteration 2372 : loss : 0.021930, loss_ce: 0.007611
2021-11-30 14:21:15,982 iteration 2373 : loss : 0.015477, loss_ce: 0.004601
2021-11-30 14:21:17,201 iteration 2374 : loss : 0.018769, loss_ce: 0.007271
2021-11-30 14:21:18,415 iteration 2375 : loss : 0.015645, loss_ce: 0.006188
2021-11-30 14:21:19,640 iteration 2376 : loss : 0.015575, loss_ce: 0.006889
2021-11-30 14:21:20,856 iteration 2377 : loss : 0.017579, loss_ce: 0.006232
2021-11-30 14:21:22,083 iteration 2378 : loss : 0.020176, loss_ce: 0.006111
2021-11-30 14:21:23,298 iteration 2379 : loss : 0.017726, loss_ce: 0.007246
2021-11-30 14:21:23,299 Training Data Eval:
2021-11-30 14:21:30,214   Average segmentation loss on training set: 0.0204
2021-11-30 14:21:30,215 Validation Data Eval:
2021-11-30 14:21:32,579   Average segmentation loss on validation set: 0.1542
2021-11-30 14:21:33,802 iteration 2380 : loss : 0.017539, loss_ce: 0.008037
 35%|██████████▏                  | 140/400 [53:07<1:44:46, 24.18s/it]2021-11-30 14:21:35,087 iteration 2381 : loss : 0.021079, loss_ce: 0.009922
2021-11-30 14:21:36,317 iteration 2382 : loss : 0.017555, loss_ce: 0.006335
2021-11-30 14:21:37,539 iteration 2383 : loss : 0.015730, loss_ce: 0.007571
2021-11-30 14:21:38,755 iteration 2384 : loss : 0.018303, loss_ce: 0.005765
2021-11-30 14:21:39,982 iteration 2385 : loss : 0.016607, loss_ce: 0.005633
2021-11-30 14:21:41,202 iteration 2386 : loss : 0.019660, loss_ce: 0.006284
2021-11-30 14:21:42,423 iteration 2387 : loss : 0.014006, loss_ce: 0.004335
2021-11-30 14:21:43,645 iteration 2388 : loss : 0.015391, loss_ce: 0.005481
2021-11-30 14:21:44,861 iteration 2389 : loss : 0.014896, loss_ce: 0.006700
2021-11-30 14:21:46,085 iteration 2390 : loss : 0.014946, loss_ce: 0.007034
2021-11-30 14:21:47,301 iteration 2391 : loss : 0.015911, loss_ce: 0.006059
2021-11-30 14:21:48,521 iteration 2392 : loss : 0.015997, loss_ce: 0.006490
2021-11-30 14:21:49,746 iteration 2393 : loss : 0.014121, loss_ce: 0.005241
2021-11-30 14:21:50,972 iteration 2394 : loss : 0.017041, loss_ce: 0.007129
2021-11-30 14:21:52,194 iteration 2395 : loss : 0.018582, loss_ce: 0.005872
2021-11-30 14:21:53,418 iteration 2396 : loss : 0.013610, loss_ce: 0.006174
2021-11-30 14:21:54,645 iteration 2397 : loss : 0.013028, loss_ce: 0.005383
 35%|██████████▏                  | 141/400 [53:28<1:40:03, 23.18s/it]2021-11-30 14:21:55,944 iteration 2398 : loss : 0.013224, loss_ce: 0.004975
2021-11-30 14:21:57,171 iteration 2399 : loss : 0.015073, loss_ce: 0.007352
2021-11-30 14:21:58,403 iteration 2400 : loss : 0.014173, loss_ce: 0.006131
2021-11-30 14:21:59,626 iteration 2401 : loss : 0.013414, loss_ce: 0.004966
2021-11-30 14:22:00,848 iteration 2402 : loss : 0.013134, loss_ce: 0.005051
2021-11-30 14:22:02,074 iteration 2403 : loss : 0.013197, loss_ce: 0.005272
2021-11-30 14:22:03,296 iteration 2404 : loss : 0.025334, loss_ce: 0.007687
2021-11-30 14:22:04,524 iteration 2405 : loss : 0.012895, loss_ce: 0.005074
2021-11-30 14:22:05,755 iteration 2406 : loss : 0.017824, loss_ce: 0.006744
2021-11-30 14:22:06,979 iteration 2407 : loss : 0.020141, loss_ce: 0.006321
2021-11-30 14:22:08,204 iteration 2408 : loss : 0.014365, loss_ce: 0.003981
2021-11-30 14:22:09,427 iteration 2409 : loss : 0.019810, loss_ce: 0.005235
2021-11-30 14:22:10,651 iteration 2410 : loss : 0.016315, loss_ce: 0.004978
2021-11-30 14:22:11,880 iteration 2411 : loss : 0.013317, loss_ce: 0.003642
2021-11-30 14:22:13,106 iteration 2412 : loss : 0.016897, loss_ce: 0.006570
2021-11-30 14:22:14,327 iteration 2413 : loss : 0.019434, loss_ce: 0.007961
2021-11-30 14:22:15,548 iteration 2414 : loss : 0.017717, loss_ce: 0.009171
 36%|██████████▎                  | 142/400 [53:49<1:36:44, 22.50s/it]2021-11-30 14:22:16,843 iteration 2415 : loss : 0.017781, loss_ce: 0.008638
2021-11-30 14:22:18,069 iteration 2416 : loss : 0.014059, loss_ce: 0.005779
2021-11-30 14:22:19,293 iteration 2417 : loss : 0.015263, loss_ce: 0.008195
2021-11-30 14:22:20,513 iteration 2418 : loss : 0.015402, loss_ce: 0.004755
2021-11-30 14:22:21,738 iteration 2419 : loss : 0.015538, loss_ce: 0.007211
2021-11-30 14:22:22,961 iteration 2420 : loss : 0.024510, loss_ce: 0.006105
2021-11-30 14:22:24,187 iteration 2421 : loss : 0.014452, loss_ce: 0.006080
2021-11-30 14:22:25,400 iteration 2422 : loss : 0.014996, loss_ce: 0.004666
2021-11-30 14:22:26,627 iteration 2423 : loss : 0.017344, loss_ce: 0.006363
2021-11-30 14:22:27,845 iteration 2424 : loss : 0.014688, loss_ce: 0.005250
2021-11-30 14:22:29,069 iteration 2425 : loss : 0.013594, loss_ce: 0.004860
2021-11-30 14:22:30,286 iteration 2426 : loss : 0.015035, loss_ce: 0.005692
2021-11-30 14:22:31,500 iteration 2427 : loss : 0.012242, loss_ce: 0.004217
2021-11-30 14:22:32,721 iteration 2428 : loss : 0.013812, loss_ce: 0.005089
2021-11-30 14:22:33,943 iteration 2429 : loss : 0.015751, loss_ce: 0.006180
2021-11-30 14:22:35,172 iteration 2430 : loss : 0.019060, loss_ce: 0.005196
2021-11-30 14:22:36,387 iteration 2431 : loss : 0.024317, loss_ce: 0.009009
 36%|██████████▎                  | 143/400 [54:10<1:34:13, 22.00s/it]2021-11-30 14:22:37,672 iteration 2432 : loss : 0.022803, loss_ce: 0.007302
2021-11-30 14:22:38,899 iteration 2433 : loss : 0.015217, loss_ce: 0.005653
2021-11-30 14:22:40,115 iteration 2434 : loss : 0.020192, loss_ce: 0.005720
2021-11-30 14:22:41,326 iteration 2435 : loss : 0.016733, loss_ce: 0.004857
2021-11-30 14:22:42,545 iteration 2436 : loss : 0.014360, loss_ce: 0.004233
2021-11-30 14:22:43,767 iteration 2437 : loss : 0.018102, loss_ce: 0.007730
2021-11-30 14:22:44,993 iteration 2438 : loss : 0.013925, loss_ce: 0.004733
2021-11-30 14:22:46,212 iteration 2439 : loss : 0.015745, loss_ce: 0.005624
2021-11-30 14:22:47,432 iteration 2440 : loss : 0.021113, loss_ce: 0.006633
2021-11-30 14:22:48,660 iteration 2441 : loss : 0.019610, loss_ce: 0.008582
2021-11-30 14:22:49,874 iteration 2442 : loss : 0.014854, loss_ce: 0.006271
2021-11-30 14:22:51,094 iteration 2443 : loss : 0.024523, loss_ce: 0.006100
2021-11-30 14:22:52,315 iteration 2444 : loss : 0.016865, loss_ce: 0.007360
2021-11-30 14:22:53,535 iteration 2445 : loss : 0.016953, loss_ce: 0.006958
2021-11-30 14:22:54,758 iteration 2446 : loss : 0.014240, loss_ce: 0.005896
2021-11-30 14:22:55,979 iteration 2447 : loss : 0.013786, loss_ce: 0.004909
2021-11-30 14:22:57,203 iteration 2448 : loss : 0.016018, loss_ce: 0.006723
 36%|██████████▍                  | 144/400 [54:31<1:32:21, 21.65s/it]2021-11-30 14:22:58,497 iteration 2449 : loss : 0.015083, loss_ce: 0.004718
2021-11-30 14:22:59,715 iteration 2450 : loss : 0.018830, loss_ce: 0.007987
2021-11-30 14:23:00,933 iteration 2451 : loss : 0.018408, loss_ce: 0.005807
2021-11-30 14:23:02,149 iteration 2452 : loss : 0.016025, loss_ce: 0.006820
2021-11-30 14:23:03,376 iteration 2453 : loss : 0.016707, loss_ce: 0.005550
2021-11-30 14:23:04,589 iteration 2454 : loss : 0.015421, loss_ce: 0.007159
2021-11-30 14:23:05,807 iteration 2455 : loss : 0.014114, loss_ce: 0.005269
2021-11-30 14:23:07,029 iteration 2456 : loss : 0.014082, loss_ce: 0.005528
2021-11-30 14:23:08,250 iteration 2457 : loss : 0.012662, loss_ce: 0.004227
2021-11-30 14:23:09,477 iteration 2458 : loss : 0.014991, loss_ce: 0.005513
2021-11-30 14:23:10,699 iteration 2459 : loss : 0.019515, loss_ce: 0.005294
2021-11-30 14:23:11,922 iteration 2460 : loss : 0.012301, loss_ce: 0.004202
2021-11-30 14:23:13,141 iteration 2461 : loss : 0.015921, loss_ce: 0.006966
2021-11-30 14:23:14,364 iteration 2462 : loss : 0.013372, loss_ce: 0.004879
2021-11-30 14:23:15,588 iteration 2463 : loss : 0.015979, loss_ce: 0.004897
2021-11-30 14:23:16,808 iteration 2464 : loss : 0.014661, loss_ce: 0.007468
2021-11-30 14:23:16,808 Training Data Eval:
2021-11-30 14:23:23,702   Average segmentation loss on training set: 0.0154
2021-11-30 14:23:23,702 Validation Data Eval:
2021-11-30 14:23:26,074   Average segmentation loss on validation set: 0.0978
2021-11-30 14:23:28,039 Found new lowest validation loss at iteration 2464! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/UNET_RUNMC/ADAM/ADAM_best_val_loss_no_da.pth
2021-11-30 14:23:29,268 iteration 2465 : loss : 0.015468, loss_ce: 0.004593
 36%|██████████▌                  | 145/400 [55:03<1:45:16, 24.77s/it]2021-11-30 14:23:30,556 iteration 2466 : loss : 0.013946, loss_ce: 0.005628
2021-11-30 14:23:31,778 iteration 2467 : loss : 0.012768, loss_ce: 0.004917
2021-11-30 14:23:32,995 iteration 2468 : loss : 0.018221, loss_ce: 0.009890
2021-11-30 14:23:34,208 iteration 2469 : loss : 0.016890, loss_ce: 0.005758
2021-11-30 14:23:35,427 iteration 2470 : loss : 0.017805, loss_ce: 0.005461
2021-11-30 14:23:36,642 iteration 2471 : loss : 0.014073, loss_ce: 0.005954
2021-11-30 14:23:37,858 iteration 2472 : loss : 0.014229, loss_ce: 0.005983
2021-11-30 14:23:39,084 iteration 2473 : loss : 0.016574, loss_ce: 0.005134
2021-11-30 14:23:40,301 iteration 2474 : loss : 0.014971, loss_ce: 0.005988
2021-11-30 14:23:41,517 iteration 2475 : loss : 0.013807, loss_ce: 0.004199
2021-11-30 14:23:42,741 iteration 2476 : loss : 0.015387, loss_ce: 0.003861
2021-11-30 14:23:43,958 iteration 2477 : loss : 0.013938, loss_ce: 0.005867
2021-11-30 14:23:45,179 iteration 2478 : loss : 0.015419, loss_ce: 0.006310
2021-11-30 14:23:46,399 iteration 2479 : loss : 0.014107, loss_ce: 0.004823
2021-11-30 14:23:47,621 iteration 2480 : loss : 0.015051, loss_ce: 0.005614
2021-11-30 14:23:48,839 iteration 2481 : loss : 0.012767, loss_ce: 0.005188
2021-11-30 14:23:50,066 iteration 2482 : loss : 0.015419, loss_ce: 0.006462
 36%|██████████▌                  | 146/400 [55:24<1:39:48, 23.58s/it]2021-11-30 14:23:51,358 iteration 2483 : loss : 0.016972, loss_ce: 0.004720
2021-11-30 14:23:52,579 iteration 2484 : loss : 0.013361, loss_ce: 0.006097
2021-11-30 14:23:53,804 iteration 2485 : loss : 0.015052, loss_ce: 0.004015
2021-11-30 14:23:55,026 iteration 2486 : loss : 0.013320, loss_ce: 0.004486
2021-11-30 14:23:56,242 iteration 2487 : loss : 0.013536, loss_ce: 0.004773
2021-11-30 14:23:57,464 iteration 2488 : loss : 0.014664, loss_ce: 0.004816
2021-11-30 14:23:58,684 iteration 2489 : loss : 0.012705, loss_ce: 0.005083
2021-11-30 14:23:59,909 iteration 2490 : loss : 0.014659, loss_ce: 0.006726
2021-11-30 14:24:01,128 iteration 2491 : loss : 0.018399, loss_ce: 0.005150
2021-11-30 14:24:02,349 iteration 2492 : loss : 0.012771, loss_ce: 0.005299
2021-11-30 14:24:03,569 iteration 2493 : loss : 0.013064, loss_ce: 0.004616
2021-11-30 14:24:04,794 iteration 2494 : loss : 0.013569, loss_ce: 0.004485
2021-11-30 14:24:06,014 iteration 2495 : loss : 0.012362, loss_ce: 0.005343
2021-11-30 14:24:07,236 iteration 2496 : loss : 0.011096, loss_ce: 0.004592
2021-11-30 14:24:08,454 iteration 2497 : loss : 0.013474, loss_ce: 0.005893
2021-11-30 14:24:09,662 iteration 2498 : loss : 0.016040, loss_ce: 0.007393
2021-11-30 14:24:10,880 iteration 2499 : loss : 0.018813, loss_ce: 0.007141
 37%|██████████▋                  | 147/400 [55:44<1:35:55, 22.75s/it]2021-11-30 14:24:12,175 iteration 2500 : loss : 0.014355, loss_ce: 0.005445
2021-11-30 14:24:13,397 iteration 2501 : loss : 0.013322, loss_ce: 0.004381
2021-11-30 14:24:14,624 iteration 2502 : loss : 0.014525, loss_ce: 0.007170
2021-11-30 14:24:15,844 iteration 2503 : loss : 0.018083, loss_ce: 0.005754
2021-11-30 14:24:17,057 iteration 2504 : loss : 0.013129, loss_ce: 0.004429
2021-11-30 14:24:18,275 iteration 2505 : loss : 0.012796, loss_ce: 0.004558
2021-11-30 14:24:19,495 iteration 2506 : loss : 0.014069, loss_ce: 0.005975
2021-11-30 14:24:20,721 iteration 2507 : loss : 0.012734, loss_ce: 0.005686
2021-11-30 14:24:21,943 iteration 2508 : loss : 0.015509, loss_ce: 0.006233
2021-11-30 14:24:23,159 iteration 2509 : loss : 0.012805, loss_ce: 0.005440
2021-11-30 14:24:24,377 iteration 2510 : loss : 0.012261, loss_ce: 0.004897
2021-11-30 14:24:25,599 iteration 2511 : loss : 0.012560, loss_ce: 0.004208
2021-11-30 14:24:26,829 iteration 2512 : loss : 0.014280, loss_ce: 0.005747
2021-11-30 14:24:28,047 iteration 2513 : loss : 0.012730, loss_ce: 0.004472
2021-11-30 14:24:29,266 iteration 2514 : loss : 0.015051, loss_ce: 0.004540
2021-11-30 14:24:30,488 iteration 2515 : loss : 0.011054, loss_ce: 0.003610
2021-11-30 14:24:31,707 iteration 2516 : loss : 0.013950, loss_ce: 0.004838
 37%|██████████▋                  | 148/400 [56:05<1:33:07, 22.17s/it]2021-11-30 14:24:33,002 iteration 2517 : loss : 0.015425, loss_ce: 0.005491
2021-11-30 14:24:34,226 iteration 2518 : loss : 0.013956, loss_ce: 0.005396
2021-11-30 14:24:35,444 iteration 2519 : loss : 0.011552, loss_ce: 0.004588
2021-11-30 14:24:36,667 iteration 2520 : loss : 0.012909, loss_ce: 0.004740
2021-11-30 14:24:37,893 iteration 2521 : loss : 0.013629, loss_ce: 0.005734
2021-11-30 14:24:39,113 iteration 2522 : loss : 0.014835, loss_ce: 0.004619
2021-11-30 14:24:40,332 iteration 2523 : loss : 0.012911, loss_ce: 0.004656
2021-11-30 14:24:41,551 iteration 2524 : loss : 0.017510, loss_ce: 0.005382
2021-11-30 14:24:42,772 iteration 2525 : loss : 0.012705, loss_ce: 0.005393
2021-11-30 14:24:43,997 iteration 2526 : loss : 0.014517, loss_ce: 0.005498
2021-11-30 14:24:45,220 iteration 2527 : loss : 0.011789, loss_ce: 0.004500
2021-11-30 14:24:46,437 iteration 2528 : loss : 0.014056, loss_ce: 0.004559
2021-11-30 14:24:47,660 iteration 2529 : loss : 0.011834, loss_ce: 0.003981
2021-11-30 14:24:48,885 iteration 2530 : loss : 0.017704, loss_ce: 0.008788
2021-11-30 14:24:50,100 iteration 2531 : loss : 0.012569, loss_ce: 0.003734
2021-11-30 14:24:51,321 iteration 2532 : loss : 0.012662, loss_ce: 0.005707
2021-11-30 14:24:52,545 iteration 2533 : loss : 0.012287, loss_ce: 0.004487
 37%|██████████▊                  | 149/400 [56:26<1:31:04, 21.77s/it]2021-11-30 14:24:53,835 iteration 2534 : loss : 0.013042, loss_ce: 0.004317
2021-11-30 14:24:55,047 iteration 2535 : loss : 0.013777, loss_ce: 0.004170
2021-11-30 14:24:56,268 iteration 2536 : loss : 0.009663, loss_ce: 0.003686
2021-11-30 14:24:57,484 iteration 2537 : loss : 0.014721, loss_ce: 0.005350
2021-11-30 14:24:58,703 iteration 2538 : loss : 0.014991, loss_ce: 0.004680
2021-11-30 14:24:59,923 iteration 2539 : loss : 0.012261, loss_ce: 0.005996
2021-11-30 14:25:01,149 iteration 2540 : loss : 0.018412, loss_ce: 0.008542
2021-11-30 14:25:02,366 iteration 2541 : loss : 0.013679, loss_ce: 0.004720
2021-11-30 14:25:03,584 iteration 2542 : loss : 0.013842, loss_ce: 0.005516
2021-11-30 14:25:04,805 iteration 2543 : loss : 0.014038, loss_ce: 0.005907
2021-11-30 14:25:06,022 iteration 2544 : loss : 0.015563, loss_ce: 0.006004
2021-11-30 14:25:07,237 iteration 2545 : loss : 0.014238, loss_ce: 0.005272
2021-11-30 14:25:08,455 iteration 2546 : loss : 0.011042, loss_ce: 0.005265
2021-11-30 14:25:09,678 iteration 2547 : loss : 0.017350, loss_ce: 0.004587
2021-11-30 14:25:10,908 iteration 2548 : loss : 0.013849, loss_ce: 0.005213
2021-11-30 14:25:12,138 iteration 2549 : loss : 0.020216, loss_ce: 0.005615
2021-11-30 14:25:12,138 Training Data Eval:
2021-11-30 14:25:19,064   Average segmentation loss on training set: 0.0136
2021-11-30 14:25:19,065 Validation Data Eval:
2021-11-30 14:25:21,433   Average segmentation loss on validation set: 0.1350
2021-11-30 14:25:22,662 iteration 2550 : loss : 0.013827, loss_ce: 0.004348
 38%|██████████▉                  | 150/400 [56:56<1:41:09, 24.28s/it]2021-11-30 14:25:23,957 iteration 2551 : loss : 0.013171, loss_ce: 0.005288
2021-11-30 14:25:25,180 iteration 2552 : loss : 0.015650, loss_ce: 0.006790
2021-11-30 14:25:26,402 iteration 2553 : loss : 0.018810, loss_ce: 0.009549
2021-11-30 14:25:27,635 iteration 2554 : loss : 0.015508, loss_ce: 0.004573
2021-11-30 14:25:28,860 iteration 2555 : loss : 0.019981, loss_ce: 0.006279
2021-11-30 14:25:30,082 iteration 2556 : loss : 0.011997, loss_ce: 0.005612
2021-11-30 14:25:31,307 iteration 2557 : loss : 0.017540, loss_ce: 0.006694
2021-11-30 14:25:32,534 iteration 2558 : loss : 0.013043, loss_ce: 0.004944
2021-11-30 14:25:33,754 iteration 2559 : loss : 0.015640, loss_ce: 0.006313
2021-11-30 14:25:34,973 iteration 2560 : loss : 0.018661, loss_ce: 0.005655
2021-11-30 14:25:36,200 iteration 2561 : loss : 0.017158, loss_ce: 0.005163
2021-11-30 14:25:37,411 iteration 2562 : loss : 0.015747, loss_ce: 0.006280
2021-11-30 14:25:38,641 iteration 2563 : loss : 0.012116, loss_ce: 0.005518
2021-11-30 14:25:39,863 iteration 2564 : loss : 0.012724, loss_ce: 0.004023
2021-11-30 14:25:41,089 iteration 2565 : loss : 0.014680, loss_ce: 0.005273
2021-11-30 14:25:42,316 iteration 2566 : loss : 0.021839, loss_ce: 0.007144
2021-11-30 14:25:43,539 iteration 2567 : loss : 0.023643, loss_ce: 0.005668
 38%|██████████▉                  | 151/400 [57:17<1:36:30, 23.26s/it]2021-11-30 14:25:44,829 iteration 2568 : loss : 0.014539, loss_ce: 0.006019
2021-11-30 14:25:46,050 iteration 2569 : loss : 0.019833, loss_ce: 0.007979
2021-11-30 14:25:47,280 iteration 2570 : loss : 0.012152, loss_ce: 0.003849
2021-11-30 14:25:48,503 iteration 2571 : loss : 0.016331, loss_ce: 0.006541
2021-11-30 14:25:49,725 iteration 2572 : loss : 0.018235, loss_ce: 0.004551
2021-11-30 14:25:50,949 iteration 2573 : loss : 0.014101, loss_ce: 0.005997
2021-11-30 14:25:52,170 iteration 2574 : loss : 0.019587, loss_ce: 0.006738
2021-11-30 14:25:53,390 iteration 2575 : loss : 0.021015, loss_ce: 0.007206
2021-11-30 14:25:54,612 iteration 2576 : loss : 0.013128, loss_ce: 0.006021
2021-11-30 14:25:55,832 iteration 2577 : loss : 0.014675, loss_ce: 0.005889
2021-11-30 14:25:57,055 iteration 2578 : loss : 0.014202, loss_ce: 0.006319
2021-11-30 14:25:58,285 iteration 2579 : loss : 0.017927, loss_ce: 0.007545
2021-11-30 14:25:59,501 iteration 2580 : loss : 0.019817, loss_ce: 0.005922
2021-11-30 14:26:00,724 iteration 2581 : loss : 0.015280, loss_ce: 0.004950
2021-11-30 14:26:01,949 iteration 2582 : loss : 0.014912, loss_ce: 0.005378
2021-11-30 14:26:03,164 iteration 2583 : loss : 0.013000, loss_ce: 0.004527
2021-11-30 14:26:04,385 iteration 2584 : loss : 0.014622, loss_ce: 0.006036
 38%|███████████                  | 152/400 [57:38<1:33:08, 22.53s/it]2021-11-30 14:26:05,670 iteration 2585 : loss : 0.019463, loss_ce: 0.007304
2021-11-30 14:26:06,889 iteration 2586 : loss : 0.012809, loss_ce: 0.004818
2021-11-30 14:26:08,117 iteration 2587 : loss : 0.012923, loss_ce: 0.004341
2021-11-30 14:26:09,338 iteration 2588 : loss : 0.015165, loss_ce: 0.005638
2021-11-30 14:26:10,558 iteration 2589 : loss : 0.019909, loss_ce: 0.007243
2021-11-30 14:26:11,780 iteration 2590 : loss : 0.015776, loss_ce: 0.007214
2021-11-30 14:26:13,003 iteration 2591 : loss : 0.012441, loss_ce: 0.003849
2021-11-30 14:26:14,219 iteration 2592 : loss : 0.014989, loss_ce: 0.005571
2021-11-30 14:26:15,442 iteration 2593 : loss : 0.016647, loss_ce: 0.004761
2021-11-30 14:26:16,665 iteration 2594 : loss : 0.014032, loss_ce: 0.004788
2021-11-30 14:26:17,883 iteration 2595 : loss : 0.012158, loss_ce: 0.005453
2021-11-30 14:26:19,105 iteration 2596 : loss : 0.019874, loss_ce: 0.010195
2021-11-30 14:26:20,322 iteration 2597 : loss : 0.020212, loss_ce: 0.005057
2021-11-30 14:26:21,540 iteration 2598 : loss : 0.011816, loss_ce: 0.005194
2021-11-30 14:26:22,766 iteration 2599 : loss : 0.012802, loss_ce: 0.004563
2021-11-30 14:26:23,986 iteration 2600 : loss : 0.011838, loss_ce: 0.005250
2021-11-30 14:26:25,210 iteration 2601 : loss : 0.013257, loss_ce: 0.004565
 38%|███████████                  | 153/400 [57:59<1:30:39, 22.02s/it]2021-11-30 14:26:26,496 iteration 2602 : loss : 0.015073, loss_ce: 0.006260
2021-11-30 14:26:27,714 iteration 2603 : loss : 0.014264, loss_ce: 0.005463
2021-11-30 14:26:28,936 iteration 2604 : loss : 0.014013, loss_ce: 0.004736
2021-11-30 14:26:30,158 iteration 2605 : loss : 0.015150, loss_ce: 0.008215
2021-11-30 14:26:31,383 iteration 2606 : loss : 0.013864, loss_ce: 0.006377
2021-11-30 14:26:32,613 iteration 2607 : loss : 0.015705, loss_ce: 0.004728
2021-11-30 14:26:33,837 iteration 2608 : loss : 0.019513, loss_ce: 0.004941
2021-11-30 14:26:35,058 iteration 2609 : loss : 0.014918, loss_ce: 0.006594
2021-11-30 14:26:36,286 iteration 2610 : loss : 0.016206, loss_ce: 0.004697
2021-11-30 14:26:37,510 iteration 2611 : loss : 0.018300, loss_ce: 0.007369
2021-11-30 14:26:38,728 iteration 2612 : loss : 0.013771, loss_ce: 0.004017
2021-11-30 14:26:39,957 iteration 2613 : loss : 0.018175, loss_ce: 0.007035
2021-11-30 14:26:41,178 iteration 2614 : loss : 0.015180, loss_ce: 0.008627
2021-11-30 14:26:42,396 iteration 2615 : loss : 0.022209, loss_ce: 0.005451
2021-11-30 14:26:43,623 iteration 2616 : loss : 0.020783, loss_ce: 0.004919
2021-11-30 14:26:44,852 iteration 2617 : loss : 0.012398, loss_ce: 0.005206
2021-11-30 14:26:46,076 iteration 2618 : loss : 0.014009, loss_ce: 0.005707
 38%|███████████▏                 | 154/400 [58:20<1:28:51, 21.67s/it]2021-11-30 14:26:47,357 iteration 2619 : loss : 0.021215, loss_ce: 0.005192
2021-11-30 14:26:48,579 iteration 2620 : loss : 0.012533, loss_ce: 0.004138
2021-11-30 14:26:49,798 iteration 2621 : loss : 0.013413, loss_ce: 0.005605
2021-11-30 14:26:51,026 iteration 2622 : loss : 0.014166, loss_ce: 0.005500
2021-11-30 14:26:52,249 iteration 2623 : loss : 0.015400, loss_ce: 0.006465
2021-11-30 14:26:53,475 iteration 2624 : loss : 0.017194, loss_ce: 0.005892
2021-11-30 14:26:54,707 iteration 2625 : loss : 0.017046, loss_ce: 0.007059
2021-11-30 14:26:55,921 iteration 2626 : loss : 0.012504, loss_ce: 0.006047
2021-11-30 14:26:57,149 iteration 2627 : loss : 0.013722, loss_ce: 0.005319
2021-11-30 14:26:58,377 iteration 2628 : loss : 0.014221, loss_ce: 0.005052
2021-11-30 14:26:59,596 iteration 2629 : loss : 0.011664, loss_ce: 0.004509
2021-11-30 14:27:00,823 iteration 2630 : loss : 0.017386, loss_ce: 0.006643
2021-11-30 14:27:02,044 iteration 2631 : loss : 0.016249, loss_ce: 0.005203
2021-11-30 14:27:03,264 iteration 2632 : loss : 0.011296, loss_ce: 0.004348
2021-11-30 14:27:04,484 iteration 2633 : loss : 0.016946, loss_ce: 0.007138
2021-11-30 14:27:05,706 iteration 2634 : loss : 0.015923, loss_ce: 0.006625
2021-11-30 14:27:05,706 Training Data Eval:
2021-11-30 14:27:12,641   Average segmentation loss on training set: 0.0149
2021-11-30 14:27:12,641 Validation Data Eval:
2021-11-30 14:27:15,015   Average segmentation loss on validation set: 0.1360
2021-11-30 14:27:16,252 iteration 2635 : loss : 0.020967, loss_ce: 0.006681
 39%|███████████▏                 | 155/400 [58:50<1:38:55, 24.23s/it]2021-11-30 14:27:17,548 iteration 2636 : loss : 0.013183, loss_ce: 0.005375
2021-11-30 14:27:18,777 iteration 2637 : loss : 0.011977, loss_ce: 0.005594
2021-11-30 14:27:20,012 iteration 2638 : loss : 0.015916, loss_ce: 0.006000
2021-11-30 14:27:21,235 iteration 2639 : loss : 0.015070, loss_ce: 0.005857
2021-11-30 14:27:22,458 iteration 2640 : loss : 0.016692, loss_ce: 0.005013
2021-11-30 14:27:23,678 iteration 2641 : loss : 0.017655, loss_ce: 0.005036
2021-11-30 14:27:24,904 iteration 2642 : loss : 0.013735, loss_ce: 0.005807
2021-11-30 14:27:26,136 iteration 2643 : loss : 0.017631, loss_ce: 0.005564
2021-11-30 14:27:27,357 iteration 2644 : loss : 0.011813, loss_ce: 0.004294
2021-11-30 14:27:28,579 iteration 2645 : loss : 0.012913, loss_ce: 0.004571
2021-11-30 14:27:29,804 iteration 2646 : loss : 0.017240, loss_ce: 0.008356
2021-11-30 14:27:31,032 iteration 2647 : loss : 0.016230, loss_ce: 0.005284
2021-11-30 14:27:32,252 iteration 2648 : loss : 0.012291, loss_ce: 0.004615
2021-11-30 14:27:33,475 iteration 2649 : loss : 0.012305, loss_ce: 0.004531
2021-11-30 14:27:34,693 iteration 2650 : loss : 0.012493, loss_ce: 0.005545
2021-11-30 14:27:35,913 iteration 2651 : loss : 0.010595, loss_ce: 0.004192
2021-11-30 14:27:37,140 iteration 2652 : loss : 0.013654, loss_ce: 0.006809
 39%|███████████▎                 | 156/400 [59:11<1:34:26, 23.22s/it]2021-11-30 14:27:38,434 iteration 2653 : loss : 0.016622, loss_ce: 0.004357
2021-11-30 14:27:39,657 iteration 2654 : loss : 0.016909, loss_ce: 0.004899
2021-11-30 14:27:40,879 iteration 2655 : loss : 0.016334, loss_ce: 0.007038
2021-11-30 14:27:42,095 iteration 2656 : loss : 0.011693, loss_ce: 0.003533
2021-11-30 14:27:43,319 iteration 2657 : loss : 0.012917, loss_ce: 0.005691
2021-11-30 14:27:44,538 iteration 2658 : loss : 0.013500, loss_ce: 0.004142
2021-11-30 14:27:45,759 iteration 2659 : loss : 0.013234, loss_ce: 0.004566
2021-11-30 14:27:46,981 iteration 2660 : loss : 0.012690, loss_ce: 0.006009
2021-11-30 14:27:48,205 iteration 2661 : loss : 0.014401, loss_ce: 0.007489
2021-11-30 14:27:49,424 iteration 2662 : loss : 0.015579, loss_ce: 0.006039
2021-11-30 14:27:50,643 iteration 2663 : loss : 0.013693, loss_ce: 0.006796
2021-11-30 14:27:51,864 iteration 2664 : loss : 0.014887, loss_ce: 0.005411
2021-11-30 14:27:53,072 iteration 2665 : loss : 0.012355, loss_ce: 0.005490
2021-11-30 14:27:54,292 iteration 2666 : loss : 0.012103, loss_ce: 0.005621
2021-11-30 14:27:55,510 iteration 2667 : loss : 0.013953, loss_ce: 0.005022
2021-11-30 14:27:56,736 iteration 2668 : loss : 0.012945, loss_ce: 0.005209
2021-11-30 14:27:57,952 iteration 2669 : loss : 0.011720, loss_ce: 0.004433
 39%|███████████▍                 | 157/400 [59:32<1:31:07, 22.50s/it]2021-11-30 14:27:59,240 iteration 2670 : loss : 0.011365, loss_ce: 0.004784
2021-11-30 14:28:00,462 iteration 2671 : loss : 0.021242, loss_ce: 0.005287
2021-11-30 14:28:01,681 iteration 2672 : loss : 0.012898, loss_ce: 0.006002
2021-11-30 14:28:02,899 iteration 2673 : loss : 0.014305, loss_ce: 0.005190
2021-11-30 14:28:04,119 iteration 2674 : loss : 0.010183, loss_ce: 0.004261
2021-11-30 14:28:05,337 iteration 2675 : loss : 0.013570, loss_ce: 0.006356
2021-11-30 14:28:06,556 iteration 2676 : loss : 0.013343, loss_ce: 0.007016
2021-11-30 14:28:07,776 iteration 2677 : loss : 0.014510, loss_ce: 0.005060
2021-11-30 14:28:09,002 iteration 2678 : loss : 0.013943, loss_ce: 0.004678
2021-11-30 14:28:10,226 iteration 2679 : loss : 0.011819, loss_ce: 0.003889
2021-11-30 14:28:11,446 iteration 2680 : loss : 0.012164, loss_ce: 0.004012
2021-11-30 14:28:12,670 iteration 2681 : loss : 0.011197, loss_ce: 0.004637
2021-11-30 14:28:13,888 iteration 2682 : loss : 0.016594, loss_ce: 0.005387
2021-11-30 14:28:15,115 iteration 2683 : loss : 0.013642, loss_ce: 0.004595
2021-11-30 14:28:16,342 iteration 2684 : loss : 0.010284, loss_ce: 0.003560
2021-11-30 14:28:17,571 iteration 2685 : loss : 0.013808, loss_ce: 0.003533
2021-11-30 14:28:18,793 iteration 2686 : loss : 0.012897, loss_ce: 0.006124
 40%|███████████▍                 | 158/400 [59:52<1:28:44, 22.00s/it]2021-11-30 14:28:20,082 iteration 2687 : loss : 0.015312, loss_ce: 0.004480
2021-11-30 14:28:21,300 iteration 2688 : loss : 0.012777, loss_ce: 0.005206
2021-11-30 14:28:22,525 iteration 2689 : loss : 0.015562, loss_ce: 0.004585
2021-11-30 14:28:23,749 iteration 2690 : loss : 0.012036, loss_ce: 0.004736
2021-11-30 14:28:24,967 iteration 2691 : loss : 0.014044, loss_ce: 0.004529
2021-11-30 14:28:26,186 iteration 2692 : loss : 0.013227, loss_ce: 0.005627
2021-11-30 14:28:27,413 iteration 2693 : loss : 0.012305, loss_ce: 0.004411
2021-11-30 14:28:28,641 iteration 2694 : loss : 0.012086, loss_ce: 0.005084
2021-11-30 14:28:29,869 iteration 2695 : loss : 0.014630, loss_ce: 0.006530
2021-11-30 14:28:31,093 iteration 2696 : loss : 0.016857, loss_ce: 0.006865
2021-11-30 14:28:32,318 iteration 2697 : loss : 0.010951, loss_ce: 0.004913
2021-11-30 14:28:33,545 iteration 2698 : loss : 0.014778, loss_ce: 0.007251
2021-11-30 14:28:34,768 iteration 2699 : loss : 0.010751, loss_ce: 0.003581
2021-11-30 14:28:35,989 iteration 2700 : loss : 0.012191, loss_ce: 0.004172
2021-11-30 14:28:37,210 iteration 2701 : loss : 0.010884, loss_ce: 0.004629
2021-11-30 14:28:38,430 iteration 2702 : loss : 0.012108, loss_ce: 0.004249
2021-11-30 14:28:39,658 iteration 2703 : loss : 0.010590, loss_ce: 0.003405
 40%|██████████▋                | 159/400 [1:00:13<1:26:59, 21.66s/it]2021-11-30 14:28:40,948 iteration 2704 : loss : 0.010828, loss_ce: 0.003908
2021-11-30 14:28:42,169 iteration 2705 : loss : 0.012483, loss_ce: 0.005696
2021-11-30 14:28:43,388 iteration 2706 : loss : 0.013520, loss_ce: 0.006797
2021-11-30 14:28:44,612 iteration 2707 : loss : 0.012509, loss_ce: 0.005280
2021-11-30 14:28:45,837 iteration 2708 : loss : 0.011479, loss_ce: 0.004180
2021-11-30 14:28:47,064 iteration 2709 : loss : 0.010555, loss_ce: 0.004386
2021-11-30 14:28:48,285 iteration 2710 : loss : 0.013758, loss_ce: 0.003855
2021-11-30 14:28:49,509 iteration 2711 : loss : 0.012221, loss_ce: 0.004453
2021-11-30 14:28:50,750 iteration 2712 : loss : 0.016537, loss_ce: 0.006132
2021-11-30 14:28:51,973 iteration 2713 : loss : 0.014250, loss_ce: 0.005581
2021-11-30 14:28:53,191 iteration 2714 : loss : 0.015020, loss_ce: 0.005759
2021-11-30 14:28:54,411 iteration 2715 : loss : 0.010166, loss_ce: 0.003098
2021-11-30 14:28:55,631 iteration 2716 : loss : 0.012625, loss_ce: 0.003947
2021-11-30 14:28:56,851 iteration 2717 : loss : 0.013285, loss_ce: 0.004145
2021-11-30 14:28:58,075 iteration 2718 : loss : 0.012233, loss_ce: 0.005067
2021-11-30 14:28:59,291 iteration 2719 : loss : 0.011166, loss_ce: 0.004690
2021-11-30 14:28:59,291 Training Data Eval:
2021-11-30 14:29:06,225   Average segmentation loss on training set: 0.0119
2021-11-30 14:29:06,226 Validation Data Eval:
2021-11-30 14:29:08,602   Average segmentation loss on validation set: 0.1426
2021-11-30 14:29:09,822 iteration 2720 : loss : 0.012091, loss_ce: 0.003292
 40%|██████████▊                | 160/400 [1:00:43<1:36:51, 24.21s/it]2021-11-30 14:29:11,109 iteration 2721 : loss : 0.011779, loss_ce: 0.004351
2021-11-30 14:29:12,333 iteration 2722 : loss : 0.019513, loss_ce: 0.003613
2021-11-30 14:29:13,551 iteration 2723 : loss : 0.012212, loss_ce: 0.005387
2021-11-30 14:29:14,774 iteration 2724 : loss : 0.013367, loss_ce: 0.006418
2021-11-30 14:29:16,001 iteration 2725 : loss : 0.011062, loss_ce: 0.003672
2021-11-30 14:29:17,209 iteration 2726 : loss : 0.015651, loss_ce: 0.004415
2021-11-30 14:29:18,429 iteration 2727 : loss : 0.012717, loss_ce: 0.003969
2021-11-30 14:29:19,655 iteration 2728 : loss : 0.015289, loss_ce: 0.003808
2021-11-30 14:29:20,877 iteration 2729 : loss : 0.016570, loss_ce: 0.006730
2021-11-30 14:29:22,096 iteration 2730 : loss : 0.012689, loss_ce: 0.004945
2021-11-30 14:29:23,314 iteration 2731 : loss : 0.012216, loss_ce: 0.004378
2021-11-30 14:29:24,532 iteration 2732 : loss : 0.013057, loss_ce: 0.007327
2021-11-30 14:29:25,748 iteration 2733 : loss : 0.014732, loss_ce: 0.007139
2021-11-30 14:29:26,964 iteration 2734 : loss : 0.011537, loss_ce: 0.004677
2021-11-30 14:29:28,190 iteration 2735 : loss : 0.013767, loss_ce: 0.005811
2021-11-30 14:29:29,409 iteration 2736 : loss : 0.011760, loss_ce: 0.004513
2021-11-30 14:29:30,627 iteration 2737 : loss : 0.015562, loss_ce: 0.005743
 40%|██████████▊                | 161/400 [1:01:04<1:32:21, 23.19s/it]2021-11-30 14:29:31,908 iteration 2738 : loss : 0.011872, loss_ce: 0.004235
2021-11-30 14:29:33,131 iteration 2739 : loss : 0.009644, loss_ce: 0.003828
2021-11-30 14:29:34,353 iteration 2740 : loss : 0.013351, loss_ce: 0.005011
2021-11-30 14:29:35,580 iteration 2741 : loss : 0.014388, loss_ce: 0.004943
2021-11-30 14:29:36,797 iteration 2742 : loss : 0.012432, loss_ce: 0.004934
2021-11-30 14:29:38,013 iteration 2743 : loss : 0.013722, loss_ce: 0.006749
2021-11-30 14:29:39,238 iteration 2744 : loss : 0.011457, loss_ce: 0.004051
2021-11-30 14:29:40,459 iteration 2745 : loss : 0.015863, loss_ce: 0.005349
2021-11-30 14:29:41,682 iteration 2746 : loss : 0.014485, loss_ce: 0.004766
2021-11-30 14:29:42,893 iteration 2747 : loss : 0.011203, loss_ce: 0.003997
2021-11-30 14:29:44,108 iteration 2748 : loss : 0.012882, loss_ce: 0.003799
2021-11-30 14:29:45,326 iteration 2749 : loss : 0.014383, loss_ce: 0.004999
2021-11-30 14:29:46,548 iteration 2750 : loss : 0.012300, loss_ce: 0.006053
2021-11-30 14:29:47,770 iteration 2751 : loss : 0.012490, loss_ce: 0.004195
2021-11-30 14:29:48,986 iteration 2752 : loss : 0.015072, loss_ce: 0.006279
2021-11-30 14:29:50,205 iteration 2753 : loss : 0.015455, loss_ce: 0.005287
2021-11-30 14:29:51,424 iteration 2754 : loss : 0.011202, loss_ce: 0.005476
 40%|██████████▉                | 162/400 [1:01:25<1:29:08, 22.47s/it]2021-11-30 14:29:52,709 iteration 2755 : loss : 0.012210, loss_ce: 0.004233
2021-11-30 14:29:53,935 iteration 2756 : loss : 0.012659, loss_ce: 0.004580
2021-11-30 14:29:55,161 iteration 2757 : loss : 0.012100, loss_ce: 0.003854
2021-11-30 14:29:56,388 iteration 2758 : loss : 0.011412, loss_ce: 0.003859
2021-11-30 14:29:57,612 iteration 2759 : loss : 0.010636, loss_ce: 0.005113
2021-11-30 14:29:58,836 iteration 2760 : loss : 0.013115, loss_ce: 0.005222
2021-11-30 14:30:00,058 iteration 2761 : loss : 0.011650, loss_ce: 0.005235
2021-11-30 14:30:01,283 iteration 2762 : loss : 0.016820, loss_ce: 0.006132
2021-11-30 14:30:02,506 iteration 2763 : loss : 0.015901, loss_ce: 0.004461
2021-11-30 14:30:03,725 iteration 2764 : loss : 0.013455, loss_ce: 0.003737
2021-11-30 14:30:04,955 iteration 2765 : loss : 0.010921, loss_ce: 0.004743
2021-11-30 14:30:06,176 iteration 2766 : loss : 0.011508, loss_ce: 0.004153
2021-11-30 14:30:07,403 iteration 2767 : loss : 0.011233, loss_ce: 0.004591
2021-11-30 14:30:08,629 iteration 2768 : loss : 0.010722, loss_ce: 0.003884
2021-11-30 14:30:09,860 iteration 2769 : loss : 0.012990, loss_ce: 0.004776
2021-11-30 14:30:11,087 iteration 2770 : loss : 0.010170, loss_ce: 0.004167
2021-11-30 14:30:12,357 iteration 2771 : loss : 0.009962, loss_ce: 0.004760
 41%|███████████                | 163/400 [1:01:46<1:26:56, 22.01s/it]2021-11-30 14:30:13,654 iteration 2772 : loss : 0.012164, loss_ce: 0.002661
2021-11-30 14:30:14,879 iteration 2773 : loss : 0.011913, loss_ce: 0.005372
2021-11-30 14:30:16,093 iteration 2774 : loss : 0.011128, loss_ce: 0.004847
2021-11-30 14:30:17,315 iteration 2775 : loss : 0.012953, loss_ce: 0.005407
2021-11-30 14:30:18,540 iteration 2776 : loss : 0.015443, loss_ce: 0.004626
2021-11-30 14:30:19,762 iteration 2777 : loss : 0.013222, loss_ce: 0.004387
2021-11-30 14:30:20,986 iteration 2778 : loss : 0.014552, loss_ce: 0.004690
2021-11-30 14:30:22,211 iteration 2779 : loss : 0.011076, loss_ce: 0.004388
2021-11-30 14:30:23,426 iteration 2780 : loss : 0.011310, loss_ce: 0.004666
2021-11-30 14:30:24,644 iteration 2781 : loss : 0.011278, loss_ce: 0.005290
2021-11-30 14:30:25,864 iteration 2782 : loss : 0.012759, loss_ce: 0.004053
2021-11-30 14:30:27,091 iteration 2783 : loss : 0.013019, loss_ce: 0.006313
2021-11-30 14:30:28,312 iteration 2784 : loss : 0.012667, loss_ce: 0.004882
2021-11-30 14:30:29,530 iteration 2785 : loss : 0.011822, loss_ce: 0.004341
2021-11-30 14:30:30,755 iteration 2786 : loss : 0.011709, loss_ce: 0.005326
2021-11-30 14:30:31,975 iteration 2787 : loss : 0.011734, loss_ce: 0.003796
2021-11-30 14:30:33,200 iteration 2788 : loss : 0.015530, loss_ce: 0.003576
 41%|███████████                | 164/400 [1:02:07<1:25:11, 21.66s/it]2021-11-30 14:30:34,493 iteration 2789 : loss : 0.009900, loss_ce: 0.003970
2021-11-30 14:30:35,720 iteration 2790 : loss : 0.012371, loss_ce: 0.004152
2021-11-30 14:30:36,943 iteration 2791 : loss : 0.012925, loss_ce: 0.003147
2021-11-30 14:30:38,169 iteration 2792 : loss : 0.011823, loss_ce: 0.004888
2021-11-30 14:30:39,397 iteration 2793 : loss : 0.008456, loss_ce: 0.003399
2021-11-30 14:30:40,614 iteration 2794 : loss : 0.010082, loss_ce: 0.004121
2021-11-30 14:30:41,838 iteration 2795 : loss : 0.014484, loss_ce: 0.004397
2021-11-30 14:30:43,064 iteration 2796 : loss : 0.011262, loss_ce: 0.003807
2021-11-30 14:30:44,294 iteration 2797 : loss : 0.011092, loss_ce: 0.004414
2021-11-30 14:30:45,515 iteration 2798 : loss : 0.014504, loss_ce: 0.006212
2021-11-30 14:30:46,732 iteration 2799 : loss : 0.013808, loss_ce: 0.004639
2021-11-30 14:30:47,956 iteration 2800 : loss : 0.012910, loss_ce: 0.004851
2021-11-30 14:30:49,174 iteration 2801 : loss : 0.010353, loss_ce: 0.004330
2021-11-30 14:30:50,403 iteration 2802 : loss : 0.015805, loss_ce: 0.004850
2021-11-30 14:30:51,624 iteration 2803 : loss : 0.016298, loss_ce: 0.005226
2021-11-30 14:30:52,837 iteration 2804 : loss : 0.012733, loss_ce: 0.005241
2021-11-30 14:30:52,838 Training Data Eval:
2021-11-30 14:30:59,726   Average segmentation loss on training set: 0.0105
2021-11-30 14:30:59,727 Validation Data Eval:
2021-11-30 14:31:02,095   Average segmentation loss on validation set: 0.1443
2021-11-30 14:31:03,315 iteration 2805 : loss : 0.011767, loss_ce: 0.005556
 41%|███████████▏               | 165/400 [1:02:37<1:34:45, 24.20s/it]2021-11-30 14:31:04,599 iteration 2806 : loss : 0.010422, loss_ce: 0.003914
2021-11-30 14:31:05,819 iteration 2807 : loss : 0.017065, loss_ce: 0.006279
2021-11-30 14:31:07,041 iteration 2808 : loss : 0.010111, loss_ce: 0.004212
2021-11-30 14:31:08,266 iteration 2809 : loss : 0.011176, loss_ce: 0.005032
2021-11-30 14:31:09,486 iteration 2810 : loss : 0.011167, loss_ce: 0.003808
2021-11-30 14:31:10,715 iteration 2811 : loss : 0.010972, loss_ce: 0.003998
2021-11-30 14:31:11,932 iteration 2812 : loss : 0.010303, loss_ce: 0.004815
2021-11-30 14:31:13,160 iteration 2813 : loss : 0.011383, loss_ce: 0.002781
2021-11-30 14:31:14,385 iteration 2814 : loss : 0.010333, loss_ce: 0.003819
2021-11-30 14:31:15,607 iteration 2815 : loss : 0.013499, loss_ce: 0.003369
2021-11-30 14:31:16,830 iteration 2816 : loss : 0.013916, loss_ce: 0.007033
2021-11-30 14:31:18,057 iteration 2817 : loss : 0.010481, loss_ce: 0.004670
2021-11-30 14:31:19,288 iteration 2818 : loss : 0.012922, loss_ce: 0.003999
2021-11-30 14:31:20,506 iteration 2819 : loss : 0.013006, loss_ce: 0.006219
2021-11-30 14:31:21,733 iteration 2820 : loss : 0.011643, loss_ce: 0.003669
2021-11-30 14:31:22,960 iteration 2821 : loss : 0.011376, loss_ce: 0.003698
2021-11-30 14:31:24,184 iteration 2822 : loss : 0.010183, loss_ce: 0.004092
 42%|███████████▏               | 166/400 [1:02:58<1:30:28, 23.20s/it]2021-11-30 14:31:25,488 iteration 2823 : loss : 0.010494, loss_ce: 0.004292
2021-11-30 14:31:26,708 iteration 2824 : loss : 0.012614, loss_ce: 0.003717
2021-11-30 14:31:27,932 iteration 2825 : loss : 0.010960, loss_ce: 0.004195
2021-11-30 14:31:29,156 iteration 2826 : loss : 0.011792, loss_ce: 0.004767
2021-11-30 14:31:30,379 iteration 2827 : loss : 0.010086, loss_ce: 0.004454
2021-11-30 14:31:31,603 iteration 2828 : loss : 0.012120, loss_ce: 0.005376
2021-11-30 14:31:32,826 iteration 2829 : loss : 0.011392, loss_ce: 0.004296
2021-11-30 14:31:34,044 iteration 2830 : loss : 0.010886, loss_ce: 0.004479
2021-11-30 14:31:35,267 iteration 2831 : loss : 0.011222, loss_ce: 0.003597
2021-11-30 14:31:36,486 iteration 2832 : loss : 0.009200, loss_ce: 0.003294
2021-11-30 14:31:37,707 iteration 2833 : loss : 0.011382, loss_ce: 0.004854
2021-11-30 14:31:38,928 iteration 2834 : loss : 0.010261, loss_ce: 0.003956
2021-11-30 14:31:40,161 iteration 2835 : loss : 0.011729, loss_ce: 0.004176
2021-11-30 14:31:41,385 iteration 2836 : loss : 0.013610, loss_ce: 0.004759
2021-11-30 14:31:42,614 iteration 2837 : loss : 0.009970, loss_ce: 0.002071
2021-11-30 14:31:43,832 iteration 2838 : loss : 0.011668, loss_ce: 0.005091
2021-11-30 14:31:45,048 iteration 2839 : loss : 0.010779, loss_ce: 0.003136
 42%|███████████▎               | 167/400 [1:03:19<1:27:22, 22.50s/it]2021-11-30 14:31:46,339 iteration 2840 : loss : 0.013275, loss_ce: 0.005900
2021-11-30 14:31:47,564 iteration 2841 : loss : 0.008929, loss_ce: 0.003464
2021-11-30 14:31:48,787 iteration 2842 : loss : 0.013291, loss_ce: 0.003648
2021-11-30 14:31:50,015 iteration 2843 : loss : 0.011717, loss_ce: 0.004284
2021-11-30 14:31:51,237 iteration 2844 : loss : 0.009190, loss_ce: 0.004033
2021-11-30 14:31:52,455 iteration 2845 : loss : 0.012213, loss_ce: 0.005748
2021-11-30 14:31:53,682 iteration 2846 : loss : 0.011464, loss_ce: 0.004081
2021-11-30 14:31:54,905 iteration 2847 : loss : 0.010942, loss_ce: 0.004922
2021-11-30 14:31:56,128 iteration 2848 : loss : 0.012170, loss_ce: 0.004754
2021-11-30 14:31:57,356 iteration 2849 : loss : 0.010552, loss_ce: 0.003964
2021-11-30 14:31:58,572 iteration 2850 : loss : 0.012545, loss_ce: 0.005329
2021-11-30 14:31:59,799 iteration 2851 : loss : 0.011467, loss_ce: 0.003730
2021-11-30 14:32:01,024 iteration 2852 : loss : 0.013210, loss_ce: 0.004506
2021-11-30 14:32:02,243 iteration 2853 : loss : 0.010108, loss_ce: 0.003095
2021-11-30 14:32:03,473 iteration 2854 : loss : 0.010671, loss_ce: 0.004132
2021-11-30 14:32:04,690 iteration 2855 : loss : 0.011225, loss_ce: 0.004395
2021-11-30 14:32:05,922 iteration 2856 : loss : 0.013370, loss_ce: 0.004580
 42%|███████████▎               | 168/400 [1:03:39<1:25:06, 22.01s/it]2021-11-30 14:32:07,212 iteration 2857 : loss : 0.010432, loss_ce: 0.003586
2021-11-30 14:32:08,421 iteration 2858 : loss : 0.011618, loss_ce: 0.003130
2021-11-30 14:32:09,637 iteration 2859 : loss : 0.012933, loss_ce: 0.006212
2021-11-30 14:32:10,861 iteration 2860 : loss : 0.012586, loss_ce: 0.006047
2021-11-30 14:32:12,088 iteration 2861 : loss : 0.011895, loss_ce: 0.004636
2021-11-30 14:32:13,310 iteration 2862 : loss : 0.009548, loss_ce: 0.004124
2021-11-30 14:32:14,534 iteration 2863 : loss : 0.015970, loss_ce: 0.002811
2021-11-30 14:32:15,761 iteration 2864 : loss : 0.012263, loss_ce: 0.004051
2021-11-30 14:32:16,992 iteration 2865 : loss : 0.009893, loss_ce: 0.004034
2021-11-30 14:32:18,218 iteration 2866 : loss : 0.010342, loss_ce: 0.002982
2021-11-30 14:32:19,440 iteration 2867 : loss : 0.011418, loss_ce: 0.004644
2021-11-30 14:32:20,663 iteration 2868 : loss : 0.011051, loss_ce: 0.004220
2021-11-30 14:32:21,890 iteration 2869 : loss : 0.011321, loss_ce: 0.004935
2021-11-30 14:32:23,110 iteration 2870 : loss : 0.012740, loss_ce: 0.005046
2021-11-30 14:32:24,328 iteration 2871 : loss : 0.014398, loss_ce: 0.004502
2021-11-30 14:32:25,551 iteration 2872 : loss : 0.012995, loss_ce: 0.004606
2021-11-30 14:32:26,771 iteration 2873 : loss : 0.012824, loss_ce: 0.004401
 42%|███████████▍               | 169/400 [1:04:00<1:23:24, 21.66s/it]2021-11-30 14:32:28,064 iteration 2874 : loss : 0.010005, loss_ce: 0.003728
2021-11-30 14:32:29,284 iteration 2875 : loss : 0.012813, loss_ce: 0.003484
2021-11-30 14:32:30,509 iteration 2876 : loss : 0.011317, loss_ce: 0.005291
2021-11-30 14:32:31,737 iteration 2877 : loss : 0.011066, loss_ce: 0.003739
2021-11-30 14:32:32,958 iteration 2878 : loss : 0.016457, loss_ce: 0.007464
2021-11-30 14:32:34,174 iteration 2879 : loss : 0.011396, loss_ce: 0.004096
2021-11-30 14:32:35,398 iteration 2880 : loss : 0.011347, loss_ce: 0.003969
2021-11-30 14:32:36,617 iteration 2881 : loss : 0.011914, loss_ce: 0.004201
2021-11-30 14:32:37,836 iteration 2882 : loss : 0.015403, loss_ce: 0.004964
2021-11-30 14:32:39,056 iteration 2883 : loss : 0.009929, loss_ce: 0.003646
2021-11-30 14:32:40,274 iteration 2884 : loss : 0.013360, loss_ce: 0.004673
2021-11-30 14:32:41,487 iteration 2885 : loss : 0.009953, loss_ce: 0.003704
2021-11-30 14:32:42,713 iteration 2886 : loss : 0.014867, loss_ce: 0.007302
2021-11-30 14:32:43,938 iteration 2887 : loss : 0.013285, loss_ce: 0.005278
2021-11-30 14:32:45,158 iteration 2888 : loss : 0.011791, loss_ce: 0.003367
2021-11-30 14:32:46,374 iteration 2889 : loss : 0.009404, loss_ce: 0.002964
2021-11-30 14:32:46,375 Training Data Eval:
2021-11-30 14:32:53,292   Average segmentation loss on training set: 0.0108
2021-11-30 14:32:53,293 Validation Data Eval:
2021-11-30 14:32:55,669   Average segmentation loss on validation set: 0.1458
2021-11-30 14:32:56,895 iteration 2890 : loss : 0.011393, loss_ce: 0.005130
 42%|███████████▍               | 170/400 [1:04:30<1:32:46, 24.20s/it]2021-11-30 14:32:58,192 iteration 2891 : loss : 0.010536, loss_ce: 0.004779
2021-11-30 14:32:59,421 iteration 2892 : loss : 0.011328, loss_ce: 0.003838
2021-11-30 14:33:00,639 iteration 2893 : loss : 0.013064, loss_ce: 0.005302
2021-11-30 14:33:01,853 iteration 2894 : loss : 0.010692, loss_ce: 0.003404
2021-11-30 14:33:03,080 iteration 2895 : loss : 0.013287, loss_ce: 0.005490
2021-11-30 14:33:04,308 iteration 2896 : loss : 0.010976, loss_ce: 0.002630
2021-11-30 14:33:05,531 iteration 2897 : loss : 0.009715, loss_ce: 0.003064
2021-11-30 14:33:06,750 iteration 2898 : loss : 0.011632, loss_ce: 0.004963
2021-11-30 14:33:07,966 iteration 2899 : loss : 0.011597, loss_ce: 0.003420
2021-11-30 14:33:09,187 iteration 2900 : loss : 0.011390, loss_ce: 0.005493
2021-11-30 14:33:10,410 iteration 2901 : loss : 0.012411, loss_ce: 0.004393
2021-11-30 14:33:11,632 iteration 2902 : loss : 0.020372, loss_ce: 0.004814
2021-11-30 14:33:12,857 iteration 2903 : loss : 0.011133, loss_ce: 0.004737
2021-11-30 14:33:14,076 iteration 2904 : loss : 0.013444, loss_ce: 0.005340
2021-11-30 14:33:15,304 iteration 2905 : loss : 0.012025, loss_ce: 0.004440
2021-11-30 14:33:16,532 iteration 2906 : loss : 0.015346, loss_ce: 0.006253
2021-11-30 14:33:17,753 iteration 2907 : loss : 0.011209, loss_ce: 0.005053
 43%|███████████▌               | 171/400 [1:04:51<1:28:32, 23.20s/it]2021-11-30 14:33:19,043 iteration 2908 : loss : 0.013564, loss_ce: 0.006551
2021-11-30 14:33:20,266 iteration 2909 : loss : 0.019818, loss_ce: 0.004320
2021-11-30 14:33:21,499 iteration 2910 : loss : 0.010893, loss_ce: 0.003915
2021-11-30 14:33:22,723 iteration 2911 : loss : 0.013766, loss_ce: 0.004472
2021-11-30 14:33:23,951 iteration 2912 : loss : 0.012755, loss_ce: 0.005099
2021-11-30 14:33:25,168 iteration 2913 : loss : 0.011897, loss_ce: 0.003677
2021-11-30 14:33:26,387 iteration 2914 : loss : 0.011594, loss_ce: 0.004206
2021-11-30 14:33:27,609 iteration 2915 : loss : 0.013168, loss_ce: 0.006276
2021-11-30 14:33:28,839 iteration 2916 : loss : 0.015475, loss_ce: 0.005615
2021-11-30 14:33:30,062 iteration 2917 : loss : 0.012281, loss_ce: 0.005351
2021-11-30 14:33:31,289 iteration 2918 : loss : 0.017559, loss_ce: 0.005660
2021-11-30 14:33:32,514 iteration 2919 : loss : 0.014357, loss_ce: 0.003144
2021-11-30 14:33:33,742 iteration 2920 : loss : 0.017036, loss_ce: 0.007251
2021-11-30 14:33:34,962 iteration 2921 : loss : 0.017479, loss_ce: 0.007029
2021-11-30 14:33:36,186 iteration 2922 : loss : 0.012234, loss_ce: 0.004671
2021-11-30 14:33:37,415 iteration 2923 : loss : 0.010496, loss_ce: 0.003525
2021-11-30 14:33:38,631 iteration 2924 : loss : 0.011505, loss_ce: 0.004760
 43%|███████████▌               | 172/400 [1:05:12<1:25:30, 22.50s/it]2021-11-30 14:33:39,937 iteration 2925 : loss : 0.009684, loss_ce: 0.003246
2021-11-30 14:33:41,152 iteration 2926 : loss : 0.010606, loss_ce: 0.004644
2021-11-30 14:33:42,367 iteration 2927 : loss : 0.022866, loss_ce: 0.006699
2021-11-30 14:33:43,592 iteration 2928 : loss : 0.014415, loss_ce: 0.006238
2021-11-30 14:33:44,811 iteration 2929 : loss : 0.010354, loss_ce: 0.004161
2021-11-30 14:33:46,032 iteration 2930 : loss : 0.011190, loss_ce: 0.005035
2021-11-30 14:33:47,249 iteration 2931 : loss : 0.012646, loss_ce: 0.005859
2021-11-30 14:33:48,471 iteration 2932 : loss : 0.015495, loss_ce: 0.004997
2021-11-30 14:33:49,689 iteration 2933 : loss : 0.013857, loss_ce: 0.004779
2021-11-30 14:33:50,908 iteration 2934 : loss : 0.010185, loss_ce: 0.004204
2021-11-30 14:33:52,132 iteration 2935 : loss : 0.020211, loss_ce: 0.007287
2021-11-30 14:33:53,350 iteration 2936 : loss : 0.013307, loss_ce: 0.003243
2021-11-30 14:33:54,569 iteration 2937 : loss : 0.018462, loss_ce: 0.005258
2021-11-30 14:33:55,790 iteration 2938 : loss : 0.015220, loss_ce: 0.005038
2021-11-30 14:33:57,006 iteration 2939 : loss : 0.013507, loss_ce: 0.005263
2021-11-30 14:33:58,230 iteration 2940 : loss : 0.018690, loss_ce: 0.007897
2021-11-30 14:33:59,452 iteration 2941 : loss : 0.013064, loss_ce: 0.005020
 43%|███████████▋               | 173/400 [1:05:33<1:23:13, 22.00s/it]2021-11-30 14:34:00,737 iteration 2942 : loss : 0.012570, loss_ce: 0.006187
2021-11-30 14:34:01,959 iteration 2943 : loss : 0.018305, loss_ce: 0.004338
2021-11-30 14:34:03,181 iteration 2944 : loss : 0.016144, loss_ce: 0.005197
2021-11-30 14:34:04,400 iteration 2945 : loss : 0.012675, loss_ce: 0.004156
2021-11-30 14:34:05,624 iteration 2946 : loss : 0.011176, loss_ce: 0.004336
2021-11-30 14:34:06,845 iteration 2947 : loss : 0.014591, loss_ce: 0.005458
2021-11-30 14:34:08,064 iteration 2948 : loss : 0.013593, loss_ce: 0.004926
2021-11-30 14:34:09,286 iteration 2949 : loss : 0.014064, loss_ce: 0.005894
2021-11-30 14:34:10,509 iteration 2950 : loss : 0.012201, loss_ce: 0.004523
2021-11-30 14:34:11,738 iteration 2951 : loss : 0.013322, loss_ce: 0.006094
2021-11-30 14:34:12,954 iteration 2952 : loss : 0.011577, loss_ce: 0.004332
2021-11-30 14:34:14,176 iteration 2953 : loss : 0.020010, loss_ce: 0.005041
2021-11-30 14:34:15,394 iteration 2954 : loss : 0.014125, loss_ce: 0.005648
2021-11-30 14:34:16,619 iteration 2955 : loss : 0.014463, loss_ce: 0.005938
2021-11-30 14:34:17,839 iteration 2956 : loss : 0.012941, loss_ce: 0.004606
2021-11-30 14:34:19,062 iteration 2957 : loss : 0.013583, loss_ce: 0.006223
2021-11-30 14:34:20,286 iteration 2958 : loss : 0.012885, loss_ce: 0.004777
 44%|███████████▋               | 174/400 [1:05:54<1:21:32, 21.65s/it]2021-11-30 14:34:21,570 iteration 2959 : loss : 0.012360, loss_ce: 0.004212
2021-11-30 14:34:22,795 iteration 2960 : loss : 0.014394, loss_ce: 0.006619
2021-11-30 14:34:24,025 iteration 2961 : loss : 0.015246, loss_ce: 0.005676
2021-11-30 14:34:25,248 iteration 2962 : loss : 0.016271, loss_ce: 0.005017
2021-11-30 14:34:26,476 iteration 2963 : loss : 0.012882, loss_ce: 0.004132
2021-11-30 14:34:27,707 iteration 2964 : loss : 0.012670, loss_ce: 0.005511
2021-11-30 14:34:28,937 iteration 2965 : loss : 0.012200, loss_ce: 0.004045
2021-11-30 14:34:30,162 iteration 2966 : loss : 0.012867, loss_ce: 0.004551
2021-11-30 14:34:31,390 iteration 2967 : loss : 0.013955, loss_ce: 0.005267
2021-11-30 14:34:32,615 iteration 2968 : loss : 0.012875, loss_ce: 0.004095
2021-11-30 14:34:33,835 iteration 2969 : loss : 0.010570, loss_ce: 0.003976
2021-11-30 14:34:35,059 iteration 2970 : loss : 0.013440, loss_ce: 0.005095
2021-11-30 14:34:36,279 iteration 2971 : loss : 0.011441, loss_ce: 0.003630
2021-11-30 14:34:37,507 iteration 2972 : loss : 0.011634, loss_ce: 0.003928
2021-11-30 14:34:38,724 iteration 2973 : loss : 0.012565, loss_ce: 0.005503
2021-11-30 14:34:39,948 iteration 2974 : loss : 0.012254, loss_ce: 0.005395
2021-11-30 14:34:39,948 Training Data Eval:
2021-11-30 14:34:46,867   Average segmentation loss on training set: 0.0158
2021-11-30 14:34:46,868 Validation Data Eval:
2021-11-30 14:34:49,234   Average segmentation loss on validation set: 0.1567
2021-11-30 14:34:50,462 iteration 2975 : loss : 0.010887, loss_ce: 0.004336
 44%|███████████▊               | 175/400 [1:06:24<1:30:46, 24.21s/it]2021-11-30 14:34:51,756 iteration 2976 : loss : 0.011547, loss_ce: 0.004332
2021-11-30 14:34:52,977 iteration 2977 : loss : 0.012651, loss_ce: 0.004195
2021-11-30 14:34:54,202 iteration 2978 : loss : 0.009986, loss_ce: 0.003088
2021-11-30 14:34:55,433 iteration 2979 : loss : 0.012033, loss_ce: 0.004988
2021-11-30 14:34:56,656 iteration 2980 : loss : 0.013343, loss_ce: 0.005920
2021-11-30 14:34:57,886 iteration 2981 : loss : 0.013044, loss_ce: 0.004339
2021-11-30 14:34:59,109 iteration 2982 : loss : 0.010100, loss_ce: 0.004156
2021-11-30 14:35:00,329 iteration 2983 : loss : 0.010215, loss_ce: 0.004675
2021-11-30 14:35:01,556 iteration 2984 : loss : 0.017594, loss_ce: 0.005705
2021-11-30 14:35:02,779 iteration 2985 : loss : 0.009991, loss_ce: 0.003697
2021-11-30 14:35:04,005 iteration 2986 : loss : 0.009376, loss_ce: 0.004244
2021-11-30 14:35:05,231 iteration 2987 : loss : 0.013765, loss_ce: 0.004656
2021-11-30 14:35:06,452 iteration 2988 : loss : 0.012604, loss_ce: 0.004062
2021-11-30 14:35:07,671 iteration 2989 : loss : 0.015654, loss_ce: 0.004325
2021-11-30 14:35:08,886 iteration 2990 : loss : 0.011670, loss_ce: 0.005638
2021-11-30 14:35:10,106 iteration 2991 : loss : 0.011552, loss_ce: 0.003053
2021-11-30 14:35:11,326 iteration 2992 : loss : 0.009534, loss_ce: 0.002830
 44%|███████████▉               | 176/400 [1:06:45<1:26:38, 23.21s/it]2021-11-30 14:35:12,620 iteration 2993 : loss : 0.010201, loss_ce: 0.004002
2021-11-30 14:35:13,840 iteration 2994 : loss : 0.011730, loss_ce: 0.004945
2021-11-30 14:35:15,063 iteration 2995 : loss : 0.014040, loss_ce: 0.005282
2021-11-30 14:35:16,283 iteration 2996 : loss : 0.012711, loss_ce: 0.003064
2021-11-30 14:35:17,505 iteration 2997 : loss : 0.015032, loss_ce: 0.006435
2021-11-30 14:35:18,731 iteration 2998 : loss : 0.015677, loss_ce: 0.005458
2021-11-30 14:35:19,954 iteration 2999 : loss : 0.011888, loss_ce: 0.003912
2021-11-30 14:35:21,175 iteration 3000 : loss : 0.011081, loss_ce: 0.004927
2021-11-30 14:35:22,397 iteration 3001 : loss : 0.012093, loss_ce: 0.005355
2021-11-30 14:35:23,624 iteration 3002 : loss : 0.012695, loss_ce: 0.004775
2021-11-30 14:35:24,853 iteration 3003 : loss : 0.047119, loss_ce: 0.004662
2021-11-30 14:35:26,072 iteration 3004 : loss : 0.012478, loss_ce: 0.005632
2021-11-30 14:35:27,298 iteration 3005 : loss : 0.024189, loss_ce: 0.008829
2021-11-30 14:35:28,523 iteration 3006 : loss : 0.039261, loss_ce: 0.012509
2021-11-30 14:35:29,752 iteration 3007 : loss : 0.030842, loss_ce: 0.012687
2021-11-30 14:35:30,979 iteration 3008 : loss : 0.022077, loss_ce: 0.010037
2021-11-30 14:35:32,198 iteration 3009 : loss : 0.023784, loss_ce: 0.009982
 44%|███████████▉               | 177/400 [1:07:06<1:23:38, 22.51s/it]2021-11-30 14:35:33,498 iteration 3010 : loss : 0.030734, loss_ce: 0.010687
2021-11-30 14:35:34,729 iteration 3011 : loss : 0.019341, loss_ce: 0.010638
2021-11-30 14:35:35,955 iteration 3012 : loss : 0.025394, loss_ce: 0.009942
2021-11-30 14:35:37,173 iteration 3013 : loss : 0.025545, loss_ce: 0.011479
2021-11-30 14:35:38,398 iteration 3014 : loss : 0.052724, loss_ce: 0.013436
2021-11-30 14:35:39,621 iteration 3015 : loss : 0.032446, loss_ce: 0.016024
2021-11-30 14:35:40,843 iteration 3016 : loss : 0.022258, loss_ce: 0.007001
2021-11-30 14:35:42,060 iteration 3017 : loss : 0.030371, loss_ce: 0.011165
2021-11-30 14:35:43,284 iteration 3018 : loss : 0.028687, loss_ce: 0.009685
2021-11-30 14:35:44,500 iteration 3019 : loss : 0.039117, loss_ce: 0.010177
2021-11-30 14:35:45,721 iteration 3020 : loss : 0.025032, loss_ce: 0.010903
2021-11-30 14:35:46,950 iteration 3021 : loss : 0.023961, loss_ce: 0.008335
2021-11-30 14:35:48,170 iteration 3022 : loss : 0.032538, loss_ce: 0.010405
2021-11-30 14:35:49,393 iteration 3023 : loss : 0.021941, loss_ce: 0.006695
2021-11-30 14:35:50,615 iteration 3024 : loss : 0.027907, loss_ce: 0.011825
2021-11-30 14:35:51,844 iteration 3025 : loss : 0.022197, loss_ce: 0.007552
2021-11-30 14:35:53,063 iteration 3026 : loss : 0.027821, loss_ce: 0.011869
 44%|████████████               | 178/400 [1:07:27<1:21:26, 22.01s/it]2021-11-30 14:35:54,345 iteration 3027 : loss : 0.019660, loss_ce: 0.006311
2021-11-30 14:35:55,560 iteration 3028 : loss : 0.019327, loss_ce: 0.006583
2021-11-30 14:35:56,774 iteration 3029 : loss : 0.022536, loss_ce: 0.007639
2021-11-30 14:35:57,992 iteration 3030 : loss : 0.024467, loss_ce: 0.008247
2021-11-30 14:35:59,216 iteration 3031 : loss : 0.021373, loss_ce: 0.009292
2021-11-30 14:36:00,438 iteration 3032 : loss : 0.017985, loss_ce: 0.007783
2021-11-30 14:36:01,657 iteration 3033 : loss : 0.018418, loss_ce: 0.006990
2021-11-30 14:36:02,884 iteration 3034 : loss : 0.019614, loss_ce: 0.006268
2021-11-30 14:36:04,103 iteration 3035 : loss : 0.020547, loss_ce: 0.006387
2021-11-30 14:36:05,331 iteration 3036 : loss : 0.016788, loss_ce: 0.007353
2021-11-30 14:36:06,552 iteration 3037 : loss : 0.039691, loss_ce: 0.006208
2021-11-30 14:36:07,768 iteration 3038 : loss : 0.024024, loss_ce: 0.009004
2021-11-30 14:36:08,990 iteration 3039 : loss : 0.021582, loss_ce: 0.006940
2021-11-30 14:36:10,216 iteration 3040 : loss : 0.023732, loss_ce: 0.007364
2021-11-30 14:36:11,445 iteration 3041 : loss : 0.022281, loss_ce: 0.009532
2021-11-30 14:36:12,665 iteration 3042 : loss : 0.030256, loss_ce: 0.010736
2021-11-30 14:36:13,890 iteration 3043 : loss : 0.015850, loss_ce: 0.007159
 45%|████████████               | 179/400 [1:07:47<1:19:46, 21.66s/it]2021-11-30 14:36:15,181 iteration 3044 : loss : 0.016556, loss_ce: 0.005984
2021-11-30 14:36:16,404 iteration 3045 : loss : 0.020887, loss_ce: 0.006345
2021-11-30 14:36:17,626 iteration 3046 : loss : 0.018671, loss_ce: 0.007638
2021-11-30 14:36:18,845 iteration 3047 : loss : 0.011948, loss_ce: 0.004256
2021-11-30 14:36:20,071 iteration 3048 : loss : 0.016934, loss_ce: 0.005683
2021-11-30 14:36:21,289 iteration 3049 : loss : 0.017994, loss_ce: 0.008286
2021-11-30 14:36:22,514 iteration 3050 : loss : 0.021640, loss_ce: 0.008053
2021-11-30 14:36:23,741 iteration 3051 : loss : 0.021417, loss_ce: 0.008416
2021-11-30 14:36:24,968 iteration 3052 : loss : 0.019097, loss_ce: 0.006444
2021-11-30 14:36:26,190 iteration 3053 : loss : 0.016417, loss_ce: 0.005805
2021-11-30 14:36:27,416 iteration 3054 : loss : 0.015745, loss_ce: 0.005509
2021-11-30 14:36:28,644 iteration 3055 : loss : 0.015133, loss_ce: 0.006814
2021-11-30 14:36:29,870 iteration 3056 : loss : 0.018092, loss_ce: 0.006936
2021-11-30 14:36:31,093 iteration 3057 : loss : 0.018090, loss_ce: 0.005269
2021-11-30 14:36:32,319 iteration 3058 : loss : 0.014235, loss_ce: 0.006196
2021-11-30 14:36:33,540 iteration 3059 : loss : 0.021427, loss_ce: 0.008053
2021-11-30 14:36:33,541 Training Data Eval:
2021-11-30 14:36:40,462   Average segmentation loss on training set: 0.0159
2021-11-30 14:36:40,462 Validation Data Eval:
2021-11-30 14:36:42,857   Average segmentation loss on validation set: 0.1351
2021-11-30 14:36:44,078 iteration 3060 : loss : 0.017202, loss_ce: 0.006131
 45%|████████████▏              | 180/400 [1:08:18<1:28:47, 24.22s/it]2021-11-30 14:36:45,366 iteration 3061 : loss : 0.012080, loss_ce: 0.004973
2021-11-30 14:36:46,592 iteration 3062 : loss : 0.014300, loss_ce: 0.005762
2021-11-30 14:36:47,814 iteration 3063 : loss : 0.013967, loss_ce: 0.004760
2021-11-30 14:36:49,032 iteration 3064 : loss : 0.017677, loss_ce: 0.005799
2021-11-30 14:36:50,247 iteration 3065 : loss : 0.013703, loss_ce: 0.004900
2021-11-30 14:36:51,463 iteration 3066 : loss : 0.013698, loss_ce: 0.006070
2021-11-30 14:36:52,681 iteration 3067 : loss : 0.019995, loss_ce: 0.007785
2021-11-30 14:36:53,896 iteration 3068 : loss : 0.015103, loss_ce: 0.005824
2021-11-30 14:36:55,108 iteration 3069 : loss : 0.013292, loss_ce: 0.004911
2021-11-30 14:36:56,329 iteration 3070 : loss : 0.012575, loss_ce: 0.005318
2021-11-30 14:36:57,546 iteration 3071 : loss : 0.013302, loss_ce: 0.004691
2021-11-30 14:36:58,766 iteration 3072 : loss : 0.011404, loss_ce: 0.004313
2021-11-30 14:36:59,986 iteration 3073 : loss : 0.016689, loss_ce: 0.008311
2021-11-30 14:37:01,202 iteration 3074 : loss : 0.016226, loss_ce: 0.005470
2021-11-30 14:37:02,424 iteration 3075 : loss : 0.013413, loss_ce: 0.004740
2021-11-30 14:37:03,647 iteration 3076 : loss : 0.013169, loss_ce: 0.005453
2021-11-30 14:37:04,870 iteration 3077 : loss : 0.019045, loss_ce: 0.004699
 45%|████████████▏              | 181/400 [1:08:38<1:24:38, 23.19s/it]2021-11-30 14:37:06,159 iteration 3078 : loss : 0.015455, loss_ce: 0.005270
2021-11-30 14:37:07,376 iteration 3079 : loss : 0.015131, loss_ce: 0.005180
2021-11-30 14:37:08,596 iteration 3080 : loss : 0.016160, loss_ce: 0.004520
2021-11-30 14:37:09,817 iteration 3081 : loss : 0.014481, loss_ce: 0.004120
2021-11-30 14:37:11,038 iteration 3082 : loss : 0.010315, loss_ce: 0.003664
2021-11-30 14:37:12,253 iteration 3083 : loss : 0.017047, loss_ce: 0.007110
2021-11-30 14:37:13,470 iteration 3084 : loss : 0.017053, loss_ce: 0.008931
2021-11-30 14:37:14,692 iteration 3085 : loss : 0.011039, loss_ce: 0.004932
2021-11-30 14:37:15,911 iteration 3086 : loss : 0.013261, loss_ce: 0.006100
2021-11-30 14:37:17,133 iteration 3087 : loss : 0.012768, loss_ce: 0.003772
2021-11-30 14:37:18,353 iteration 3088 : loss : 0.012126, loss_ce: 0.005057
2021-11-30 14:37:19,574 iteration 3089 : loss : 0.016252, loss_ce: 0.005049
2021-11-30 14:37:20,794 iteration 3090 : loss : 0.012773, loss_ce: 0.004878
2021-11-30 14:37:22,010 iteration 3091 : loss : 0.017846, loss_ce: 0.006003
2021-11-30 14:37:23,235 iteration 3092 : loss : 0.012236, loss_ce: 0.004806
2021-11-30 14:37:24,456 iteration 3093 : loss : 0.013546, loss_ce: 0.006060
2021-11-30 14:37:25,680 iteration 3094 : loss : 0.013490, loss_ce: 0.005528
 46%|████████████▎              | 182/400 [1:08:59<1:21:39, 22.47s/it]2021-11-30 14:37:26,974 iteration 3095 : loss : 0.012315, loss_ce: 0.005388
2021-11-30 14:37:28,197 iteration 3096 : loss : 0.011968, loss_ce: 0.005335
2021-11-30 14:37:29,420 iteration 3097 : loss : 0.010789, loss_ce: 0.004959
2021-11-30 14:37:30,646 iteration 3098 : loss : 0.014717, loss_ce: 0.002903
2021-11-30 14:37:31,866 iteration 3099 : loss : 0.012262, loss_ce: 0.005147
2021-11-30 14:37:33,086 iteration 3100 : loss : 0.014197, loss_ce: 0.002584
2021-11-30 14:37:34,309 iteration 3101 : loss : 0.019690, loss_ce: 0.008096
2021-11-30 14:37:35,537 iteration 3102 : loss : 0.012144, loss_ce: 0.004551
2021-11-30 14:37:36,761 iteration 3103 : loss : 0.011882, loss_ce: 0.005170
2021-11-30 14:37:37,988 iteration 3104 : loss : 0.012209, loss_ce: 0.004667
2021-11-30 14:37:39,217 iteration 3105 : loss : 0.011009, loss_ce: 0.002804
2021-11-30 14:37:40,444 iteration 3106 : loss : 0.013411, loss_ce: 0.005142
2021-11-30 14:37:41,665 iteration 3107 : loss : 0.013831, loss_ce: 0.004781
2021-11-30 14:37:42,895 iteration 3108 : loss : 0.013671, loss_ce: 0.006952
2021-11-30 14:37:44,105 iteration 3109 : loss : 0.017189, loss_ce: 0.006018
2021-11-30 14:37:45,324 iteration 3110 : loss : 0.014024, loss_ce: 0.005004
2021-11-30 14:37:46,552 iteration 3111 : loss : 0.011564, loss_ce: 0.004592
 46%|████████████▎              | 183/400 [1:09:20<1:19:32, 21.99s/it]2021-11-30 14:37:47,842 iteration 3112 : loss : 0.011154, loss_ce: 0.003609
2021-11-30 14:37:49,065 iteration 3113 : loss : 0.012719, loss_ce: 0.004892
2021-11-30 14:37:50,285 iteration 3114 : loss : 0.011474, loss_ce: 0.004030
2021-11-30 14:37:51,496 iteration 3115 : loss : 0.015796, loss_ce: 0.007981
2021-11-30 14:37:52,717 iteration 3116 : loss : 0.013515, loss_ce: 0.005249
2021-11-30 14:37:53,946 iteration 3117 : loss : 0.013866, loss_ce: 0.005061
2021-11-30 14:37:55,170 iteration 3118 : loss : 0.012669, loss_ce: 0.003575
2021-11-30 14:37:56,395 iteration 3119 : loss : 0.012020, loss_ce: 0.005933
2021-11-30 14:37:57,613 iteration 3120 : loss : 0.010727, loss_ce: 0.003470
2021-11-30 14:37:58,840 iteration 3121 : loss : 0.011377, loss_ce: 0.003799
2021-11-30 14:38:00,067 iteration 3122 : loss : 0.011479, loss_ce: 0.004817
2021-11-30 14:38:01,294 iteration 3123 : loss : 0.013488, loss_ce: 0.004241
2021-11-30 14:38:02,518 iteration 3124 : loss : 0.013041, loss_ce: 0.005319
2021-11-30 14:38:03,743 iteration 3125 : loss : 0.011484, loss_ce: 0.005592
2021-11-30 14:38:04,964 iteration 3126 : loss : 0.010810, loss_ce: 0.004937
2021-11-30 14:38:06,194 iteration 3127 : loss : 0.011993, loss_ce: 0.002643
2021-11-30 14:38:07,414 iteration 3128 : loss : 0.011232, loss_ce: 0.005253
 46%|████████████▍              | 184/400 [1:09:41<1:17:57, 21.65s/it]2021-11-30 14:38:08,708 iteration 3129 : loss : 0.013053, loss_ce: 0.005075
2021-11-30 14:38:09,935 iteration 3130 : loss : 0.010762, loss_ce: 0.004188
2021-11-30 14:38:11,160 iteration 3131 : loss : 0.011013, loss_ce: 0.004760
2021-11-30 14:38:12,386 iteration 3132 : loss : 0.010916, loss_ce: 0.004515
2021-11-30 14:38:13,607 iteration 3133 : loss : 0.012908, loss_ce: 0.004239
2021-11-30 14:38:14,832 iteration 3134 : loss : 0.009700, loss_ce: 0.004262
2021-11-30 14:38:16,054 iteration 3135 : loss : 0.010292, loss_ce: 0.003752
2021-11-30 14:38:17,282 iteration 3136 : loss : 0.010482, loss_ce: 0.003676
2021-11-30 14:38:18,507 iteration 3137 : loss : 0.010039, loss_ce: 0.003560
2021-11-30 14:38:19,727 iteration 3138 : loss : 0.011271, loss_ce: 0.005667
2021-11-30 14:38:20,952 iteration 3139 : loss : 0.009938, loss_ce: 0.003873
2021-11-30 14:38:22,174 iteration 3140 : loss : 0.008973, loss_ce: 0.003696
2021-11-30 14:38:23,394 iteration 3141 : loss : 0.011563, loss_ce: 0.003365
2021-11-30 14:38:24,612 iteration 3142 : loss : 0.012837, loss_ce: 0.005305
2021-11-30 14:38:25,830 iteration 3143 : loss : 0.012355, loss_ce: 0.003022
2021-11-30 14:38:27,051 iteration 3144 : loss : 0.012136, loss_ce: 0.004912
2021-11-30 14:38:27,051 Training Data Eval:
2021-11-30 14:38:33,967   Average segmentation loss on training set: 0.0119
2021-11-30 14:38:33,967 Validation Data Eval:
2021-11-30 14:38:36,346   Average segmentation loss on validation set: 0.1644
2021-11-30 14:38:37,572 iteration 3145 : loss : 0.010542, loss_ce: 0.003640
 46%|████████████▍              | 185/400 [1:10:11<1:26:44, 24.20s/it]2021-11-30 14:38:38,859 iteration 3146 : loss : 0.011672, loss_ce: 0.005992
2021-11-30 14:38:40,083 iteration 3147 : loss : 0.010663, loss_ce: 0.003301
2021-11-30 14:38:41,291 iteration 3148 : loss : 0.011116, loss_ce: 0.003385
2021-11-30 14:38:42,506 iteration 3149 : loss : 0.011087, loss_ce: 0.003436
2021-11-30 14:38:43,717 iteration 3150 : loss : 0.010901, loss_ce: 0.003898
2021-11-30 14:38:44,944 iteration 3151 : loss : 0.010630, loss_ce: 0.003712
2021-11-30 14:38:46,158 iteration 3152 : loss : 0.011369, loss_ce: 0.004973
2021-11-30 14:38:47,376 iteration 3153 : loss : 0.009214, loss_ce: 0.003130
2021-11-30 14:38:48,603 iteration 3154 : loss : 0.010019, loss_ce: 0.002696
2021-11-30 14:38:49,828 iteration 3155 : loss : 0.010020, loss_ce: 0.003613
2021-11-30 14:38:51,044 iteration 3156 : loss : 0.010760, loss_ce: 0.004786
2021-11-30 14:38:52,265 iteration 3157 : loss : 0.011348, loss_ce: 0.003997
2021-11-30 14:38:53,482 iteration 3158 : loss : 0.009475, loss_ce: 0.003625
2021-11-30 14:38:54,704 iteration 3159 : loss : 0.011537, loss_ce: 0.005138
2021-11-30 14:38:55,917 iteration 3160 : loss : 0.010720, loss_ce: 0.002920
2021-11-30 14:38:57,137 iteration 3161 : loss : 0.010958, loss_ce: 0.005985
2021-11-30 14:38:58,363 iteration 3162 : loss : 0.008769, loss_ce: 0.003953
 46%|████████████▌              | 186/400 [1:10:32<1:22:41, 23.18s/it]2021-11-30 14:38:59,694 iteration 3163 : loss : 0.010669, loss_ce: 0.003708
2021-11-30 14:39:00,911 iteration 3164 : loss : 0.010391, loss_ce: 0.003751
2021-11-30 14:39:02,135 iteration 3165 : loss : 0.011966, loss_ce: 0.006871
2021-11-30 14:39:03,361 iteration 3166 : loss : 0.009604, loss_ce: 0.003288
2021-11-30 14:39:04,582 iteration 3167 : loss : 0.013111, loss_ce: 0.006655
2021-11-30 14:39:05,808 iteration 3168 : loss : 0.011767, loss_ce: 0.003278
2021-11-30 14:39:07,028 iteration 3169 : loss : 0.012008, loss_ce: 0.003049
2021-11-30 14:39:08,257 iteration 3170 : loss : 0.010305, loss_ce: 0.003986
2021-11-30 14:39:09,476 iteration 3171 : loss : 0.011348, loss_ce: 0.004571
2021-11-30 14:39:10,700 iteration 3172 : loss : 0.012783, loss_ce: 0.004451
2021-11-30 14:39:11,928 iteration 3173 : loss : 0.009554, loss_ce: 0.003549
2021-11-30 14:39:13,151 iteration 3174 : loss : 0.011484, loss_ce: 0.003112
2021-11-30 14:39:14,376 iteration 3175 : loss : 0.009000, loss_ce: 0.002991
2021-11-30 14:39:15,600 iteration 3176 : loss : 0.008843, loss_ce: 0.003167
2021-11-30 14:39:16,813 iteration 3177 : loss : 0.014943, loss_ce: 0.005037
2021-11-30 14:39:18,040 iteration 3178 : loss : 0.014413, loss_ce: 0.004793
2021-11-30 14:39:19,260 iteration 3179 : loss : 0.010342, loss_ce: 0.004394
 47%|████████████▌              | 187/400 [1:10:53<1:19:51, 22.50s/it]2021-11-30 14:39:20,551 iteration 3180 : loss : 0.008683, loss_ce: 0.003556
2021-11-30 14:39:21,773 iteration 3181 : loss : 0.011482, loss_ce: 0.003027
2021-11-30 14:39:22,999 iteration 3182 : loss : 0.010688, loss_ce: 0.003818
2021-11-30 14:39:24,228 iteration 3183 : loss : 0.009847, loss_ce: 0.003172
2021-11-30 14:39:25,456 iteration 3184 : loss : 0.010798, loss_ce: 0.004608
2021-11-30 14:39:26,683 iteration 3185 : loss : 0.011817, loss_ce: 0.004946
2021-11-30 14:39:27,904 iteration 3186 : loss : 0.010906, loss_ce: 0.003533
2021-11-30 14:39:29,128 iteration 3187 : loss : 0.012947, loss_ce: 0.003512
2021-11-30 14:39:30,351 iteration 3188 : loss : 0.011738, loss_ce: 0.004466
2021-11-30 14:39:31,572 iteration 3189 : loss : 0.010540, loss_ce: 0.004505
2021-11-30 14:39:32,798 iteration 3190 : loss : 0.010828, loss_ce: 0.004070
2021-11-30 14:39:34,024 iteration 3191 : loss : 0.009553, loss_ce: 0.003298
2021-11-30 14:39:35,246 iteration 3192 : loss : 0.009519, loss_ce: 0.004773
2021-11-30 14:39:36,471 iteration 3193 : loss : 0.010730, loss_ce: 0.004894
2021-11-30 14:39:37,692 iteration 3194 : loss : 0.011608, loss_ce: 0.003882
2021-11-30 14:39:38,915 iteration 3195 : loss : 0.009901, loss_ce: 0.003709
2021-11-30 14:39:40,141 iteration 3196 : loss : 0.011764, loss_ce: 0.003834
 47%|████████████▋              | 188/400 [1:11:14<1:17:46, 22.01s/it]2021-11-30 14:39:41,433 iteration 3197 : loss : 0.009350, loss_ce: 0.002984
2021-11-30 14:39:42,653 iteration 3198 : loss : 0.011285, loss_ce: 0.004738
2021-11-30 14:39:43,880 iteration 3199 : loss : 0.011404, loss_ce: 0.006596
2021-11-30 14:39:45,107 iteration 3200 : loss : 0.009441, loss_ce: 0.004109
2021-11-30 14:39:46,333 iteration 3201 : loss : 0.012407, loss_ce: 0.004319
2021-11-30 14:39:47,560 iteration 3202 : loss : 0.011376, loss_ce: 0.003205
2021-11-30 14:39:48,777 iteration 3203 : loss : 0.007526, loss_ce: 0.002439
2021-11-30 14:39:50,006 iteration 3204 : loss : 0.009902, loss_ce: 0.004338
2021-11-30 14:39:51,227 iteration 3205 : loss : 0.009234, loss_ce: 0.003466
2021-11-30 14:39:52,450 iteration 3206 : loss : 0.012258, loss_ce: 0.004520
2021-11-30 14:39:53,672 iteration 3207 : loss : 0.012567, loss_ce: 0.004278
2021-11-30 14:39:54,902 iteration 3208 : loss : 0.012451, loss_ce: 0.007588
2021-11-30 14:39:56,124 iteration 3209 : loss : 0.009210, loss_ce: 0.003310
2021-11-30 14:39:57,344 iteration 3210 : loss : 0.010700, loss_ce: 0.003654
2021-11-30 14:39:58,566 iteration 3211 : loss : 0.010388, loss_ce: 0.003311
2021-11-30 14:39:59,782 iteration 3212 : loss : 0.010936, loss_ce: 0.003788
2021-11-30 14:40:01,002 iteration 3213 : loss : 0.008920, loss_ce: 0.002808
 47%|████████████▊              | 189/400 [1:11:35<1:16:11, 21.67s/it]2021-11-30 14:40:02,297 iteration 3214 : loss : 0.011548, loss_ce: 0.002905
2021-11-30 14:40:03,522 iteration 3215 : loss : 0.010952, loss_ce: 0.004869
2021-11-30 14:40:04,735 iteration 3216 : loss : 0.009493, loss_ce: 0.002235
2021-11-30 14:40:05,958 iteration 3217 : loss : 0.010778, loss_ce: 0.003794
2021-11-30 14:40:07,184 iteration 3218 : loss : 0.011934, loss_ce: 0.004485
2021-11-30 14:40:08,408 iteration 3219 : loss : 0.011495, loss_ce: 0.005571
2021-11-30 14:40:09,631 iteration 3220 : loss : 0.008614, loss_ce: 0.002789
2021-11-30 14:40:10,853 iteration 3221 : loss : 0.008079, loss_ce: 0.003357
2021-11-30 14:40:12,074 iteration 3222 : loss : 0.012425, loss_ce: 0.004130
2021-11-30 14:40:13,298 iteration 3223 : loss : 0.012539, loss_ce: 0.002899
2021-11-30 14:40:14,521 iteration 3224 : loss : 0.010176, loss_ce: 0.004949
2021-11-30 14:40:15,744 iteration 3225 : loss : 0.008757, loss_ce: 0.003932
2021-11-30 14:40:16,964 iteration 3226 : loss : 0.009642, loss_ce: 0.003921
2021-11-30 14:40:18,192 iteration 3227 : loss : 0.009894, loss_ce: 0.003794
2021-11-30 14:40:19,411 iteration 3228 : loss : 0.011358, loss_ce: 0.005985
2021-11-30 14:40:20,631 iteration 3229 : loss : 0.009506, loss_ce: 0.003383
2021-11-30 14:40:20,631 Training Data Eval:
2021-11-30 14:40:27,551   Average segmentation loss on training set: 0.0095
2021-11-30 14:40:27,551 Validation Data Eval:
2021-11-30 14:40:29,919   Average segmentation loss on validation set: 0.1344
2021-11-30 14:40:31,145 iteration 3230 : loss : 0.011836, loss_ce: 0.005068
 48%|████████████▊              | 190/400 [1:12:05<1:24:43, 24.21s/it]2021-11-30 14:40:32,440 iteration 3231 : loss : 0.012048, loss_ce: 0.004752
2021-11-30 14:40:33,666 iteration 3232 : loss : 0.013092, loss_ce: 0.003783
2021-11-30 14:40:34,884 iteration 3233 : loss : 0.009265, loss_ce: 0.003437
2021-11-30 14:40:36,108 iteration 3234 : loss : 0.009685, loss_ce: 0.004199
2021-11-30 14:40:37,327 iteration 3235 : loss : 0.011121, loss_ce: 0.003763
2021-11-30 14:40:38,552 iteration 3236 : loss : 0.009210, loss_ce: 0.004045
2021-11-30 14:40:39,776 iteration 3237 : loss : 0.008718, loss_ce: 0.004030
2021-11-30 14:40:41,002 iteration 3238 : loss : 0.011532, loss_ce: 0.003244
2021-11-30 14:40:42,220 iteration 3239 : loss : 0.011146, loss_ce: 0.003956
2021-11-30 14:40:43,447 iteration 3240 : loss : 0.010750, loss_ce: 0.003782
2021-11-30 14:40:44,674 iteration 3241 : loss : 0.009810, loss_ce: 0.004148
2021-11-30 14:40:45,886 iteration 3242 : loss : 0.009317, loss_ce: 0.003019
2021-11-30 14:40:47,115 iteration 3243 : loss : 0.017823, loss_ce: 0.005036
2021-11-30 14:40:48,330 iteration 3244 : loss : 0.011937, loss_ce: 0.006046
2021-11-30 14:40:49,558 iteration 3245 : loss : 0.010302, loss_ce: 0.004532
2021-11-30 14:40:50,783 iteration 3246 : loss : 0.010816, loss_ce: 0.003774
2021-11-30 14:40:52,009 iteration 3247 : loss : 0.008921, loss_ce: 0.003356
 48%|████████████▉              | 191/400 [1:12:26<1:20:49, 23.20s/it]2021-11-30 14:40:53,296 iteration 3248 : loss : 0.011081, loss_ce: 0.004025
2021-11-30 14:40:54,519 iteration 3249 : loss : 0.009661, loss_ce: 0.004246
2021-11-30 14:40:55,741 iteration 3250 : loss : 0.009088, loss_ce: 0.003683
2021-11-30 14:40:56,966 iteration 3251 : loss : 0.009581, loss_ce: 0.003643
2021-11-30 14:40:58,193 iteration 3252 : loss : 0.010937, loss_ce: 0.003597
2021-11-30 14:40:59,411 iteration 3253 : loss : 0.009181, loss_ce: 0.003449
2021-11-30 14:41:00,628 iteration 3254 : loss : 0.008692, loss_ce: 0.003677
2021-11-30 14:41:01,847 iteration 3255 : loss : 0.009682, loss_ce: 0.003277
2021-11-30 14:41:03,071 iteration 3256 : loss : 0.008894, loss_ce: 0.003161
2021-11-30 14:41:04,294 iteration 3257 : loss : 0.011014, loss_ce: 0.003381
2021-11-30 14:41:05,519 iteration 3258 : loss : 0.009774, loss_ce: 0.004728
2021-11-30 14:41:06,746 iteration 3259 : loss : 0.011161, loss_ce: 0.004085
2021-11-30 14:41:07,968 iteration 3260 : loss : 0.009708, loss_ce: 0.003859
2021-11-30 14:41:09,196 iteration 3261 : loss : 0.011600, loss_ce: 0.003803
2021-11-30 14:41:10,420 iteration 3262 : loss : 0.010908, loss_ce: 0.003260
2021-11-30 14:41:11,641 iteration 3263 : loss : 0.010465, loss_ce: 0.005226
2021-11-30 14:41:12,861 iteration 3264 : loss : 0.008300, loss_ce: 0.002496
 48%|████████████▉              | 192/400 [1:12:46<1:18:00, 22.50s/it]2021-11-30 14:41:14,146 iteration 3265 : loss : 0.014418, loss_ce: 0.004035
2021-11-30 14:41:15,358 iteration 3266 : loss : 0.008852, loss_ce: 0.004340
2021-11-30 14:41:16,580 iteration 3267 : loss : 0.008485, loss_ce: 0.004277
2021-11-30 14:41:17,795 iteration 3268 : loss : 0.009349, loss_ce: 0.002464
2021-11-30 14:41:19,025 iteration 3269 : loss : 0.007716, loss_ce: 0.003014
2021-11-30 14:41:20,240 iteration 3270 : loss : 0.011084, loss_ce: 0.003894
2021-11-30 14:41:21,461 iteration 3271 : loss : 0.009997, loss_ce: 0.003537
2021-11-30 14:41:22,679 iteration 3272 : loss : 0.011233, loss_ce: 0.004005
2021-11-30 14:41:23,899 iteration 3273 : loss : 0.007465, loss_ce: 0.002613
2021-11-30 14:41:25,123 iteration 3274 : loss : 0.010280, loss_ce: 0.002643
2021-11-30 14:41:26,338 iteration 3275 : loss : 0.009472, loss_ce: 0.003079
2021-11-30 14:41:27,562 iteration 3276 : loss : 0.008483, loss_ce: 0.003721
2021-11-30 14:41:28,783 iteration 3277 : loss : 0.012086, loss_ce: 0.005948
2021-11-30 14:41:30,002 iteration 3278 : loss : 0.012122, loss_ce: 0.003697
2021-11-30 14:41:31,223 iteration 3279 : loss : 0.008882, loss_ce: 0.003557
2021-11-30 14:41:32,445 iteration 3280 : loss : 0.011277, loss_ce: 0.004342
2021-11-30 14:41:33,669 iteration 3281 : loss : 0.008410, loss_ce: 0.002501
 48%|█████████████              | 193/400 [1:13:07<1:15:52, 21.99s/it]2021-11-30 14:41:34,958 iteration 3282 : loss : 0.010487, loss_ce: 0.004632
2021-11-30 14:41:36,181 iteration 3283 : loss : 0.009813, loss_ce: 0.004343
2021-11-30 14:41:37,404 iteration 3284 : loss : 0.010781, loss_ce: 0.004627
2021-11-30 14:41:38,630 iteration 3285 : loss : 0.008954, loss_ce: 0.003268
2021-11-30 14:41:39,836 iteration 3286 : loss : 0.009239, loss_ce: 0.003213
2021-11-30 14:41:41,044 iteration 3287 : loss : 0.010301, loss_ce: 0.002999
2021-11-30 14:41:42,257 iteration 3288 : loss : 0.009597, loss_ce: 0.002872
2021-11-30 14:41:43,476 iteration 3289 : loss : 0.008943, loss_ce: 0.004256
2021-11-30 14:41:44,699 iteration 3290 : loss : 0.008974, loss_ce: 0.002795
2021-11-30 14:41:45,918 iteration 3291 : loss : 0.010802, loss_ce: 0.002842
2021-11-30 14:41:47,143 iteration 3292 : loss : 0.008775, loss_ce: 0.003779
2021-11-30 14:41:48,355 iteration 3293 : loss : 0.008898, loss_ce: 0.003322
2021-11-30 14:41:49,577 iteration 3294 : loss : 0.009708, loss_ce: 0.004454
2021-11-30 14:41:50,799 iteration 3295 : loss : 0.008361, loss_ce: 0.003428
2021-11-30 14:41:52,022 iteration 3296 : loss : 0.008662, loss_ce: 0.002853
2021-11-30 14:41:53,242 iteration 3297 : loss : 0.011196, loss_ce: 0.002689
2021-11-30 14:41:54,467 iteration 3298 : loss : 0.009171, loss_ce: 0.003128
 48%|█████████████              | 194/400 [1:13:28<1:14:16, 21.63s/it]2021-11-30 14:41:55,749 iteration 3299 : loss : 0.012555, loss_ce: 0.002926
2021-11-30 14:41:56,957 iteration 3300 : loss : 0.009168, loss_ce: 0.003855
2021-11-30 14:41:58,185 iteration 3301 : loss : 0.010062, loss_ce: 0.002925
2021-11-30 14:41:59,407 iteration 3302 : loss : 0.008100, loss_ce: 0.003414
2021-11-30 14:42:00,635 iteration 3303 : loss : 0.007328, loss_ce: 0.002794
2021-11-30 14:42:01,850 iteration 3304 : loss : 0.008048, loss_ce: 0.003359
2021-11-30 14:42:03,069 iteration 3305 : loss : 0.010557, loss_ce: 0.004460
2021-11-30 14:42:04,296 iteration 3306 : loss : 0.009443, loss_ce: 0.003157
2021-11-30 14:42:05,520 iteration 3307 : loss : 0.009934, loss_ce: 0.003829
2021-11-30 14:42:06,736 iteration 3308 : loss : 0.010631, loss_ce: 0.003784
2021-11-30 14:42:07,959 iteration 3309 : loss : 0.009474, loss_ce: 0.004027
2021-11-30 14:42:09,175 iteration 3310 : loss : 0.009802, loss_ce: 0.005045
2021-11-30 14:42:10,387 iteration 3311 : loss : 0.009898, loss_ce: 0.003784
2021-11-30 14:42:11,609 iteration 3312 : loss : 0.011582, loss_ce: 0.003679
2021-11-30 14:42:12,839 iteration 3313 : loss : 0.012411, loss_ce: 0.003652
2021-11-30 14:42:14,061 iteration 3314 : loss : 0.008882, loss_ce: 0.004235
2021-11-30 14:42:14,061 Training Data Eval:
2021-11-30 14:42:21,006   Average segmentation loss on training set: 0.0119
2021-11-30 14:42:21,007 Validation Data Eval:
2021-11-30 14:42:23,402   Average segmentation loss on validation set: 0.1299
2021-11-30 14:42:24,624 iteration 3315 : loss : 0.010385, loss_ce: 0.003547
 49%|█████████████▏             | 195/400 [1:13:58<1:22:39, 24.19s/it]2021-11-30 14:42:25,928 iteration 3316 : loss : 0.010177, loss_ce: 0.003093
2021-11-30 14:42:27,150 iteration 3317 : loss : 0.009649, loss_ce: 0.003238
2021-11-30 14:42:28,369 iteration 3318 : loss : 0.009413, loss_ce: 0.003774
2021-11-30 14:42:29,652 iteration 3319 : loss : 0.008883, loss_ce: 0.003734
2021-11-30 14:42:30,874 iteration 3320 : loss : 0.010237, loss_ce: 0.003463
2021-11-30 14:42:32,093 iteration 3321 : loss : 0.011176, loss_ce: 0.004750
2021-11-30 14:42:33,318 iteration 3322 : loss : 0.008785, loss_ce: 0.004818
2021-11-30 14:42:34,543 iteration 3323 : loss : 0.010166, loss_ce: 0.002814
2021-11-30 14:42:35,769 iteration 3324 : loss : 0.008674, loss_ce: 0.003286
2021-11-30 14:42:36,991 iteration 3325 : loss : 0.011955, loss_ce: 0.004380
2021-11-30 14:42:38,208 iteration 3326 : loss : 0.010880, loss_ce: 0.004210
2021-11-30 14:42:39,426 iteration 3327 : loss : 0.007656, loss_ce: 0.002455
2021-11-30 14:42:40,651 iteration 3328 : loss : 0.010311, loss_ce: 0.002673
2021-11-30 14:42:41,868 iteration 3329 : loss : 0.009280, loss_ce: 0.003076
2021-11-30 14:42:43,097 iteration 3330 : loss : 0.008495, loss_ce: 0.003128
2021-11-30 14:42:44,319 iteration 3331 : loss : 0.011364, loss_ce: 0.005342
2021-11-30 14:42:45,546 iteration 3332 : loss : 0.010022, loss_ce: 0.003804
 49%|█████████████▏             | 196/400 [1:14:19<1:18:54, 23.21s/it]2021-11-30 14:42:46,833 iteration 3333 : loss : 0.007732, loss_ce: 0.003605
2021-11-30 14:42:48,056 iteration 3334 : loss : 0.009147, loss_ce: 0.003553
2021-11-30 14:42:49,280 iteration 3335 : loss : 0.008340, loss_ce: 0.003316
2021-11-30 14:42:50,503 iteration 3336 : loss : 0.009191, loss_ce: 0.003202
2021-11-30 14:42:51,726 iteration 3337 : loss : 0.007987, loss_ce: 0.003787
2021-11-30 14:42:52,955 iteration 3338 : loss : 0.009761, loss_ce: 0.003848
2021-11-30 14:42:54,176 iteration 3339 : loss : 0.008334, loss_ce: 0.003061
2021-11-30 14:42:55,397 iteration 3340 : loss : 0.008718, loss_ce: 0.003018
2021-11-30 14:42:56,623 iteration 3341 : loss : 0.011487, loss_ce: 0.003292
2021-11-30 14:42:57,849 iteration 3342 : loss : 0.006751, loss_ce: 0.002622
2021-11-30 14:42:59,066 iteration 3343 : loss : 0.008374, loss_ce: 0.003589
2021-11-30 14:43:00,288 iteration 3344 : loss : 0.009007, loss_ce: 0.003583
2021-11-30 14:43:01,509 iteration 3345 : loss : 0.010208, loss_ce: 0.003934
2021-11-30 14:43:02,731 iteration 3346 : loss : 0.008050, loss_ce: 0.002800
2021-11-30 14:43:03,949 iteration 3347 : loss : 0.011323, loss_ce: 0.003827
2021-11-30 14:43:05,173 iteration 3348 : loss : 0.011039, loss_ce: 0.003546
2021-11-30 14:43:06,392 iteration 3349 : loss : 0.008102, loss_ce: 0.003142
 49%|█████████████▎             | 197/400 [1:14:40<1:16:07, 22.50s/it]2021-11-30 14:43:07,679 iteration 3350 : loss : 0.008794, loss_ce: 0.002659
2021-11-30 14:43:08,902 iteration 3351 : loss : 0.009226, loss_ce: 0.004367
2021-11-30 14:43:10,126 iteration 3352 : loss : 0.008173, loss_ce: 0.002719
2021-11-30 14:43:11,352 iteration 3353 : loss : 0.008933, loss_ce: 0.003424
2021-11-30 14:43:12,573 iteration 3354 : loss : 0.010242, loss_ce: 0.002730
2021-11-30 14:43:13,791 iteration 3355 : loss : 0.008082, loss_ce: 0.003261
2021-11-30 14:43:15,013 iteration 3356 : loss : 0.008477, loss_ce: 0.003617
2021-11-30 14:43:16,235 iteration 3357 : loss : 0.007658, loss_ce: 0.003463
2021-11-30 14:43:17,461 iteration 3358 : loss : 0.008863, loss_ce: 0.002983
2021-11-30 14:43:18,684 iteration 3359 : loss : 0.008723, loss_ce: 0.002184
2021-11-30 14:43:19,908 iteration 3360 : loss : 0.009339, loss_ce: 0.004714
2021-11-30 14:43:21,128 iteration 3361 : loss : 0.009986, loss_ce: 0.002682
2021-11-30 14:43:22,354 iteration 3362 : loss : 0.009409, loss_ce: 0.003630
2021-11-30 14:43:23,574 iteration 3363 : loss : 0.008210, loss_ce: 0.002711
2021-11-30 14:43:24,798 iteration 3364 : loss : 0.009523, loss_ce: 0.004435
2021-11-30 14:43:26,026 iteration 3365 : loss : 0.007185, loss_ce: 0.002433
2021-11-30 14:43:27,253 iteration 3366 : loss : 0.010919, loss_ce: 0.004957
 50%|█████████████▎             | 198/400 [1:15:01<1:14:05, 22.01s/it]2021-11-30 14:43:28,551 iteration 3367 : loss : 0.011886, loss_ce: 0.004582
2021-11-30 14:43:29,770 iteration 3368 : loss : 0.010047, loss_ce: 0.003602
2021-11-30 14:43:30,986 iteration 3369 : loss : 0.011888, loss_ce: 0.004430
2021-11-30 14:43:32,205 iteration 3370 : loss : 0.013888, loss_ce: 0.004819
2021-11-30 14:43:33,429 iteration 3371 : loss : 0.009206, loss_ce: 0.003577
2021-11-30 14:43:34,657 iteration 3372 : loss : 0.007789, loss_ce: 0.003126
2021-11-30 14:43:35,880 iteration 3373 : loss : 0.009439, loss_ce: 0.003551
2021-11-30 14:43:37,103 iteration 3374 : loss : 0.011815, loss_ce: 0.003702
2021-11-30 14:43:38,328 iteration 3375 : loss : 0.010990, loss_ce: 0.005039
2021-11-30 14:43:39,558 iteration 3376 : loss : 0.011783, loss_ce: 0.002822
2021-11-30 14:43:40,786 iteration 3377 : loss : 0.007922, loss_ce: 0.002922
2021-11-30 14:43:42,010 iteration 3378 : loss : 0.011103, loss_ce: 0.004476
2021-11-30 14:43:43,238 iteration 3379 : loss : 0.009367, loss_ce: 0.004415
2021-11-30 14:43:44,471 iteration 3380 : loss : 0.009805, loss_ce: 0.003210
2021-11-30 14:43:45,699 iteration 3381 : loss : 0.010000, loss_ce: 0.003387
2021-11-30 14:43:46,928 iteration 3382 : loss : 0.007419, loss_ce: 0.002377
2021-11-30 14:43:48,153 iteration 3383 : loss : 0.007863, loss_ce: 0.002713
 50%|█████████████▍             | 199/400 [1:15:22<1:12:36, 21.68s/it]2021-11-30 14:43:49,447 iteration 3384 : loss : 0.008986, loss_ce: 0.003727
2021-11-30 14:43:50,672 iteration 3385 : loss : 0.008777, loss_ce: 0.003473
2021-11-30 14:43:51,898 iteration 3386 : loss : 0.007932, loss_ce: 0.002912
2021-11-30 14:43:53,124 iteration 3387 : loss : 0.008341, loss_ce: 0.004019
2021-11-30 14:43:54,354 iteration 3388 : loss : 0.008485, loss_ce: 0.003538
2021-11-30 14:43:55,577 iteration 3389 : loss : 0.009199, loss_ce: 0.002998
2021-11-30 14:43:56,807 iteration 3390 : loss : 0.006990, loss_ce: 0.002677
2021-11-30 14:43:58,037 iteration 3391 : loss : 0.014116, loss_ce: 0.005073
2021-11-30 14:43:59,257 iteration 3392 : loss : 0.008714, loss_ce: 0.002329
2021-11-30 14:44:00,474 iteration 3393 : loss : 0.008136, loss_ce: 0.002910
2021-11-30 14:44:01,690 iteration 3394 : loss : 0.011400, loss_ce: 0.004099
2021-11-30 14:44:02,914 iteration 3395 : loss : 0.008918, loss_ce: 0.002822
2021-11-30 14:44:04,142 iteration 3396 : loss : 0.009093, loss_ce: 0.003259
2021-11-30 14:44:05,366 iteration 3397 : loss : 0.007825, loss_ce: 0.002554
2021-11-30 14:44:06,594 iteration 3398 : loss : 0.008951, loss_ce: 0.002944
2021-11-30 14:44:07,814 iteration 3399 : loss : 0.009122, loss_ce: 0.004068
2021-11-30 14:44:07,814 Training Data Eval:
2021-11-30 14:44:14,738   Average segmentation loss on training set: 0.0084
2021-11-30 14:44:14,738 Validation Data Eval:
2021-11-30 14:44:17,121   Average segmentation loss on validation set: 0.1253
2021-11-30 14:44:18,344 iteration 3400 : loss : 0.009172, loss_ce: 0.003693
 50%|█████████████▌             | 200/400 [1:15:52<1:20:46, 24.23s/it]2021-11-30 14:44:19,634 iteration 3401 : loss : 0.011673, loss_ce: 0.004074
2021-11-30 14:44:20,853 iteration 3402 : loss : 0.009395, loss_ce: 0.004141
2021-11-30 14:44:22,070 iteration 3403 : loss : 0.009858, loss_ce: 0.004652
2021-11-30 14:44:23,295 iteration 3404 : loss : 0.007098, loss_ce: 0.002307
2021-11-30 14:44:24,504 iteration 3405 : loss : 0.008573, loss_ce: 0.003674
2021-11-30 14:44:25,727 iteration 3406 : loss : 0.008631, loss_ce: 0.004041
2021-11-30 14:44:26,950 iteration 3407 : loss : 0.009228, loss_ce: 0.003238
2021-11-30 14:44:28,168 iteration 3408 : loss : 0.008189, loss_ce: 0.002588
2021-11-30 14:44:29,389 iteration 3409 : loss : 0.008875, loss_ce: 0.002811
2021-11-30 14:44:30,601 iteration 3410 : loss : 0.010308, loss_ce: 0.003132
2021-11-30 14:44:31,825 iteration 3411 : loss : 0.009143, loss_ce: 0.003543
2021-11-30 14:44:33,043 iteration 3412 : loss : 0.009672, loss_ce: 0.004023
2021-11-30 14:44:34,264 iteration 3413 : loss : 0.011536, loss_ce: 0.004414
2021-11-30 14:44:35,489 iteration 3414 : loss : 0.011057, loss_ce: 0.004588
2021-11-30 14:44:36,708 iteration 3415 : loss : 0.007783, loss_ce: 0.003075
2021-11-30 14:44:37,940 iteration 3416 : loss : 0.010864, loss_ce: 0.003502
2021-11-30 14:44:39,161 iteration 3417 : loss : 0.012459, loss_ce: 0.004469
 50%|█████████████▌             | 201/400 [1:16:13<1:16:57, 23.21s/it]2021-11-30 14:44:40,450 iteration 3418 : loss : 0.009826, loss_ce: 0.004485
2021-11-30 14:44:41,673 iteration 3419 : loss : 0.011082, loss_ce: 0.003658
2021-11-30 14:44:42,900 iteration 3420 : loss : 0.007595, loss_ce: 0.003274
2021-11-30 14:44:44,121 iteration 3421 : loss : 0.008028, loss_ce: 0.003236
2021-11-30 14:44:45,337 iteration 3422 : loss : 0.010553, loss_ce: 0.004139
2021-11-30 14:44:46,562 iteration 3423 : loss : 0.009111, loss_ce: 0.003155
2021-11-30 14:44:47,780 iteration 3424 : loss : 0.008145, loss_ce: 0.003214
2021-11-30 14:44:48,998 iteration 3425 : loss : 0.008812, loss_ce: 0.003315
2021-11-30 14:44:50,219 iteration 3426 : loss : 0.009329, loss_ce: 0.003059
2021-11-30 14:44:51,440 iteration 3427 : loss : 0.007851, loss_ce: 0.002569
2021-11-30 14:44:52,662 iteration 3428 : loss : 0.010905, loss_ce: 0.003101
2021-11-30 14:44:53,881 iteration 3429 : loss : 0.011939, loss_ce: 0.003863
2021-11-30 14:44:55,099 iteration 3430 : loss : 0.007790, loss_ce: 0.002624
2021-11-30 14:44:56,317 iteration 3431 : loss : 0.009453, loss_ce: 0.003593
2021-11-30 14:44:57,542 iteration 3432 : loss : 0.009136, loss_ce: 0.003170
2021-11-30 14:44:58,768 iteration 3433 : loss : 0.008898, loss_ce: 0.003436
2021-11-30 14:44:59,984 iteration 3434 : loss : 0.008930, loss_ce: 0.003739
 50%|█████████████▋             | 202/400 [1:16:34<1:14:13, 22.49s/it]2021-11-30 14:45:01,269 iteration 3435 : loss : 0.007299, loss_ce: 0.002814
2021-11-30 14:45:02,489 iteration 3436 : loss : 0.008410, loss_ce: 0.003326
2021-11-30 14:45:03,711 iteration 3437 : loss : 0.008242, loss_ce: 0.002760
2021-11-30 14:45:04,935 iteration 3438 : loss : 0.011621, loss_ce: 0.003369
2021-11-30 14:45:06,161 iteration 3439 : loss : 0.010375, loss_ce: 0.003419
2021-11-30 14:45:07,386 iteration 3440 : loss : 0.008880, loss_ce: 0.003476
2021-11-30 14:45:08,602 iteration 3441 : loss : 0.010314, loss_ce: 0.003352
2021-11-30 14:45:09,828 iteration 3442 : loss : 0.010501, loss_ce: 0.003815
2021-11-30 14:45:11,048 iteration 3443 : loss : 0.007573, loss_ce: 0.002904
2021-11-30 14:45:12,274 iteration 3444 : loss : 0.007758, loss_ce: 0.002980
2021-11-30 14:45:13,499 iteration 3445 : loss : 0.010253, loss_ce: 0.003398
2021-11-30 14:45:14,718 iteration 3446 : loss : 0.009356, loss_ce: 0.003507
2021-11-30 14:45:15,939 iteration 3447 : loss : 0.011208, loss_ce: 0.003498
2021-11-30 14:45:17,158 iteration 3448 : loss : 0.008467, loss_ce: 0.003284
2021-11-30 14:45:18,380 iteration 3449 : loss : 0.008122, loss_ce: 0.003671
2021-11-30 14:45:19,605 iteration 3450 : loss : 0.009675, loss_ce: 0.004381
2021-11-30 14:45:20,831 iteration 3451 : loss : 0.007819, loss_ce: 0.003096
 51%|█████████████▋             | 203/400 [1:16:54<1:12:13, 22.00s/it]2021-11-30 14:45:22,129 iteration 3452 : loss : 0.008160, loss_ce: 0.003067
2021-11-30 14:45:23,350 iteration 3453 : loss : 0.009792, loss_ce: 0.003618
2021-11-30 14:45:24,573 iteration 3454 : loss : 0.008776, loss_ce: 0.002474
2021-11-30 14:45:25,794 iteration 3455 : loss : 0.008901, loss_ce: 0.003355
2021-11-30 14:45:27,022 iteration 3456 : loss : 0.009343, loss_ce: 0.002375
2021-11-30 14:45:28,250 iteration 3457 : loss : 0.007550, loss_ce: 0.002692
2021-11-30 14:45:29,479 iteration 3458 : loss : 0.011230, loss_ce: 0.003322
2021-11-30 14:45:30,701 iteration 3459 : loss : 0.008808, loss_ce: 0.003143
2021-11-30 14:45:31,932 iteration 3460 : loss : 0.010057, loss_ce: 0.004760
2021-11-30 14:45:33,160 iteration 3461 : loss : 0.008095, loss_ce: 0.003797
2021-11-30 14:45:34,382 iteration 3462 : loss : 0.007945, loss_ce: 0.003365
2021-11-30 14:45:35,606 iteration 3463 : loss : 0.008658, loss_ce: 0.003304
2021-11-30 14:45:36,832 iteration 3464 : loss : 0.009598, loss_ce: 0.003703
2021-11-30 14:45:38,057 iteration 3465 : loss : 0.009935, loss_ce: 0.003738
2021-11-30 14:45:39,282 iteration 3466 : loss : 0.011520, loss_ce: 0.004987
2021-11-30 14:45:40,505 iteration 3467 : loss : 0.011813, loss_ce: 0.006026
2021-11-30 14:45:41,728 iteration 3468 : loss : 0.009933, loss_ce: 0.003144
 51%|█████████████▊             | 204/400 [1:17:15<1:10:46, 21.67s/it]2021-11-30 14:45:43,017 iteration 3469 : loss : 0.009531, loss_ce: 0.003899
2021-11-30 14:45:44,243 iteration 3470 : loss : 0.008340, loss_ce: 0.002249
2021-11-30 14:45:45,466 iteration 3471 : loss : 0.007426, loss_ce: 0.003741
2021-11-30 14:45:46,687 iteration 3472 : loss : 0.010736, loss_ce: 0.003159
2021-11-30 14:45:47,910 iteration 3473 : loss : 0.010073, loss_ce: 0.003734
2021-11-30 14:45:49,133 iteration 3474 : loss : 0.012409, loss_ce: 0.004170
2021-11-30 14:45:50,352 iteration 3475 : loss : 0.012322, loss_ce: 0.002434
2021-11-30 14:45:51,573 iteration 3476 : loss : 0.010872, loss_ce: 0.002363
2021-11-30 14:45:52,798 iteration 3477 : loss : 0.011359, loss_ce: 0.004929
2021-11-30 14:45:54,020 iteration 3478 : loss : 0.011372, loss_ce: 0.004401
2021-11-30 14:45:55,246 iteration 3479 : loss : 0.009638, loss_ce: 0.003256
2021-11-30 14:45:56,469 iteration 3480 : loss : 0.008528, loss_ce: 0.003373
2021-11-30 14:45:57,690 iteration 3481 : loss : 0.010134, loss_ce: 0.004137
2021-11-30 14:45:58,909 iteration 3482 : loss : 0.009246, loss_ce: 0.003272
2021-11-30 14:46:00,136 iteration 3483 : loss : 0.008082, loss_ce: 0.002553
2021-11-30 14:46:01,358 iteration 3484 : loss : 0.009332, loss_ce: 0.004270
2021-11-30 14:46:01,359 Training Data Eval:
2021-11-30 14:46:08,271   Average segmentation loss on training set: 0.0111
2021-11-30 14:46:08,271 Validation Data Eval:
2021-11-30 14:46:10,641   Average segmentation loss on validation set: 0.1462
2021-11-30 14:46:11,871 iteration 3485 : loss : 0.010711, loss_ce: 0.004416
 51%|█████████████▊             | 205/400 [1:17:45<1:18:40, 24.21s/it]2021-11-30 14:46:13,164 iteration 3486 : loss : 0.011492, loss_ce: 0.003966
2021-11-30 14:46:14,391 iteration 3487 : loss : 0.008405, loss_ce: 0.003016
2021-11-30 14:46:15,613 iteration 3488 : loss : 0.011372, loss_ce: 0.002971
2021-11-30 14:46:16,833 iteration 3489 : loss : 0.008646, loss_ce: 0.002796
2021-11-30 14:46:18,059 iteration 3490 : loss : 0.009544, loss_ce: 0.002803
2021-11-30 14:46:19,282 iteration 3491 : loss : 0.011024, loss_ce: 0.002029
2021-11-30 14:46:20,497 iteration 3492 : loss : 0.009992, loss_ce: 0.003267
2021-11-30 14:46:21,713 iteration 3493 : loss : 0.009112, loss_ce: 0.003618
2021-11-30 14:46:22,930 iteration 3494 : loss : 0.010669, loss_ce: 0.004585
2021-11-30 14:46:24,157 iteration 3495 : loss : 0.009703, loss_ce: 0.003486
2021-11-30 14:46:25,376 iteration 3496 : loss : 0.008954, loss_ce: 0.003963
2021-11-30 14:46:26,601 iteration 3497 : loss : 0.011220, loss_ce: 0.003191
2021-11-30 14:46:27,821 iteration 3498 : loss : 0.011008, loss_ce: 0.005835
2021-11-30 14:46:29,045 iteration 3499 : loss : 0.008386, loss_ce: 0.003783
2021-11-30 14:46:30,265 iteration 3500 : loss : 0.010154, loss_ce: 0.003912
2021-11-30 14:46:31,496 iteration 3501 : loss : 0.011157, loss_ce: 0.002975
2021-11-30 14:46:32,721 iteration 3502 : loss : 0.009265, loss_ce: 0.004138
 52%|█████████████▉             | 206/400 [1:18:06<1:15:01, 23.20s/it]2021-11-30 14:46:34,015 iteration 3503 : loss : 0.010397, loss_ce: 0.003643
2021-11-30 14:46:35,243 iteration 3504 : loss : 0.007414, loss_ce: 0.002383
2021-11-30 14:46:36,465 iteration 3505 : loss : 0.007837, loss_ce: 0.002552
2021-11-30 14:46:37,687 iteration 3506 : loss : 0.007537, loss_ce: 0.003300
2021-11-30 14:46:38,912 iteration 3507 : loss : 0.011058, loss_ce: 0.003471
2021-11-30 14:46:40,133 iteration 3508 : loss : 0.013097, loss_ce: 0.004003
2021-11-30 14:46:41,360 iteration 3509 : loss : 0.012296, loss_ce: 0.005497
2021-11-30 14:46:42,579 iteration 3510 : loss : 0.010923, loss_ce: 0.004303
2021-11-30 14:46:43,801 iteration 3511 : loss : 0.009032, loss_ce: 0.004659
2021-11-30 14:46:45,025 iteration 3512 : loss : 0.009064, loss_ce: 0.002070
2021-11-30 14:46:46,246 iteration 3513 : loss : 0.008272, loss_ce: 0.003824
2021-11-30 14:46:47,474 iteration 3514 : loss : 0.008653, loss_ce: 0.003372
2021-11-30 14:46:48,690 iteration 3515 : loss : 0.009369, loss_ce: 0.002389
2021-11-30 14:46:49,915 iteration 3516 : loss : 0.009042, loss_ce: 0.003742
2021-11-30 14:46:51,142 iteration 3517 : loss : 0.008927, loss_ce: 0.003302
2021-11-30 14:46:52,364 iteration 3518 : loss : 0.011061, loss_ce: 0.004201
2021-11-30 14:46:53,592 iteration 3519 : loss : 0.009623, loss_ce: 0.003459
 52%|█████████████▉             | 207/400 [1:18:27<1:12:23, 22.50s/it]2021-11-30 14:46:54,874 iteration 3520 : loss : 0.006746, loss_ce: 0.002041
2021-11-30 14:46:56,095 iteration 3521 : loss : 0.008811, loss_ce: 0.002673
2021-11-30 14:46:57,315 iteration 3522 : loss : 0.010095, loss_ce: 0.003399
2021-11-30 14:46:58,531 iteration 3523 : loss : 0.008307, loss_ce: 0.003053
2021-11-30 14:46:59,759 iteration 3524 : loss : 0.007490, loss_ce: 0.003128
2021-11-30 14:47:00,985 iteration 3525 : loss : 0.009405, loss_ce: 0.003356
2021-11-30 14:47:02,209 iteration 3526 : loss : 0.007882, loss_ce: 0.002604
2021-11-30 14:47:03,421 iteration 3527 : loss : 0.008019, loss_ce: 0.004226
2021-11-30 14:47:04,644 iteration 3528 : loss : 0.010695, loss_ce: 0.002931
2021-11-30 14:47:05,867 iteration 3529 : loss : 0.008052, loss_ce: 0.003435
2021-11-30 14:47:07,097 iteration 3530 : loss : 0.009053, loss_ce: 0.004423
2021-11-30 14:47:08,316 iteration 3531 : loss : 0.010573, loss_ce: 0.004551
2021-11-30 14:47:09,540 iteration 3532 : loss : 0.007341, loss_ce: 0.003201
2021-11-30 14:47:10,769 iteration 3533 : loss : 0.010586, loss_ce: 0.004657
2021-11-30 14:47:11,993 iteration 3534 : loss : 0.010698, loss_ce: 0.003149
2021-11-30 14:47:13,214 iteration 3535 : loss : 0.009925, loss_ce: 0.003342
2021-11-30 14:47:14,430 iteration 3536 : loss : 0.010526, loss_ce: 0.004276
 52%|██████████████             | 208/400 [1:18:48<1:10:24, 22.00s/it]2021-11-30 14:47:15,724 iteration 3537 : loss : 0.005681, loss_ce: 0.001811
2021-11-30 14:47:16,943 iteration 3538 : loss : 0.010232, loss_ce: 0.004343
2021-11-30 14:47:18,176 iteration 3539 : loss : 0.009093, loss_ce: 0.003055
2021-11-30 14:47:19,401 iteration 3540 : loss : 0.008445, loss_ce: 0.002766
2021-11-30 14:47:20,620 iteration 3541 : loss : 0.007234, loss_ce: 0.003148
2021-11-30 14:47:21,838 iteration 3542 : loss : 0.007123, loss_ce: 0.002943
2021-11-30 14:47:23,063 iteration 3543 : loss : 0.008662, loss_ce: 0.002984
2021-11-30 14:47:24,288 iteration 3544 : loss : 0.007502, loss_ce: 0.003293
2021-11-30 14:47:25,514 iteration 3545 : loss : 0.008918, loss_ce: 0.002698
2021-11-30 14:47:26,737 iteration 3546 : loss : 0.007653, loss_ce: 0.003342
2021-11-30 14:47:27,960 iteration 3547 : loss : 0.009144, loss_ce: 0.004200
2021-11-30 14:47:29,191 iteration 3548 : loss : 0.009706, loss_ce: 0.004159
2021-11-30 14:47:30,415 iteration 3549 : loss : 0.008284, loss_ce: 0.002632
2021-11-30 14:47:31,627 iteration 3550 : loss : 0.006697, loss_ce: 0.002206
2021-11-30 14:47:32,845 iteration 3551 : loss : 0.008630, loss_ce: 0.004105
2021-11-30 14:47:34,071 iteration 3552 : loss : 0.008080, loss_ce: 0.002612
2021-11-30 14:47:35,291 iteration 3553 : loss : 0.007649, loss_ce: 0.002823
 52%|██████████████             | 209/400 [1:19:09<1:08:57, 21.66s/it]2021-11-30 14:47:36,581 iteration 3554 : loss : 0.008757, loss_ce: 0.002770
2021-11-30 14:47:37,799 iteration 3555 : loss : 0.008393, loss_ce: 0.002059
2021-11-30 14:47:39,022 iteration 3556 : loss : 0.007420, loss_ce: 0.003077
2021-11-30 14:47:40,248 iteration 3557 : loss : 0.008056, loss_ce: 0.002524
2021-11-30 14:47:41,469 iteration 3558 : loss : 0.012082, loss_ce: 0.006034
2021-11-30 14:47:42,691 iteration 3559 : loss : 0.008640, loss_ce: 0.003384
2021-11-30 14:47:43,914 iteration 3560 : loss : 0.009046, loss_ce: 0.003219
2021-11-30 14:47:45,135 iteration 3561 : loss : 0.008540, loss_ce: 0.002928
2021-11-30 14:47:46,356 iteration 3562 : loss : 0.007411, loss_ce: 0.003399
2021-11-30 14:47:47,587 iteration 3563 : loss : 0.010238, loss_ce: 0.003635
2021-11-30 14:47:48,808 iteration 3564 : loss : 0.007389, loss_ce: 0.003016
2021-11-30 14:47:50,028 iteration 3565 : loss : 0.008695, loss_ce: 0.004225
2021-11-30 14:47:51,243 iteration 3566 : loss : 0.009899, loss_ce: 0.003303
2021-11-30 14:47:52,469 iteration 3567 : loss : 0.006645, loss_ce: 0.002575
2021-11-30 14:47:53,698 iteration 3568 : loss : 0.009124, loss_ce: 0.003145
2021-11-30 14:47:54,920 iteration 3569 : loss : 0.008409, loss_ce: 0.002802
2021-11-30 14:47:54,921 Training Data Eval:
2021-11-30 14:48:01,831   Average segmentation loss on training set: 0.0086
2021-11-30 14:48:01,831 Validation Data Eval:
2021-11-30 14:48:04,202   Average segmentation loss on validation set: 0.1357
2021-11-30 14:48:05,433 iteration 3570 : loss : 0.007763, loss_ce: 0.003072
 52%|██████████████▏            | 210/400 [1:19:39<1:16:38, 24.20s/it]2021-11-30 14:48:06,723 iteration 3571 : loss : 0.009140, loss_ce: 0.004236
2021-11-30 14:48:07,949 iteration 3572 : loss : 0.007980, loss_ce: 0.002355
2021-11-30 14:48:09,175 iteration 3573 : loss : 0.008941, loss_ce: 0.002807
2021-11-30 14:48:10,406 iteration 3574 : loss : 0.008895, loss_ce: 0.001677
2021-11-30 14:48:11,632 iteration 3575 : loss : 0.007800, loss_ce: 0.003174
2021-11-30 14:48:12,862 iteration 3576 : loss : 0.008632, loss_ce: 0.002601
2021-11-30 14:48:14,090 iteration 3577 : loss : 0.007665, loss_ce: 0.002685
2021-11-30 14:48:15,317 iteration 3578 : loss : 0.008936, loss_ce: 0.003256
2021-11-30 14:48:16,542 iteration 3579 : loss : 0.009758, loss_ce: 0.004116
2021-11-30 14:48:17,770 iteration 3580 : loss : 0.007495, loss_ce: 0.002329
2021-11-30 14:48:18,993 iteration 3581 : loss : 0.008065, loss_ce: 0.003651
2021-11-30 14:48:20,219 iteration 3582 : loss : 0.009191, loss_ce: 0.003657
2021-11-30 14:48:21,447 iteration 3583 : loss : 0.007864, loss_ce: 0.003552
2021-11-30 14:48:22,675 iteration 3584 : loss : 0.008982, loss_ce: 0.003524
2021-11-30 14:48:23,894 iteration 3585 : loss : 0.008606, loss_ce: 0.003486
2021-11-30 14:48:25,119 iteration 3586 : loss : 0.007029, loss_ce: 0.003219
2021-11-30 14:48:26,345 iteration 3587 : loss : 0.007683, loss_ce: 0.002281
 53%|██████████████▏            | 211/400 [1:20:00<1:13:07, 23.22s/it]2021-11-30 14:48:27,641 iteration 3588 : loss : 0.009207, loss_ce: 0.003356
2021-11-30 14:48:28,860 iteration 3589 : loss : 0.007827, loss_ce: 0.002979
2021-11-30 14:48:30,092 iteration 3590 : loss : 0.007829, loss_ce: 0.003089
2021-11-30 14:48:31,318 iteration 3591 : loss : 0.010836, loss_ce: 0.003273
2021-11-30 14:48:32,545 iteration 3592 : loss : 0.010207, loss_ce: 0.004633
2021-11-30 14:48:33,781 iteration 3593 : loss : 0.006423, loss_ce: 0.002081
2021-11-30 14:48:35,010 iteration 3594 : loss : 0.008483, loss_ce: 0.002397
2021-11-30 14:48:36,246 iteration 3595 : loss : 0.007801, loss_ce: 0.003977
2021-11-30 14:48:37,468 iteration 3596 : loss : 0.009828, loss_ce: 0.003025
2021-11-30 14:48:38,701 iteration 3597 : loss : 0.007175, loss_ce: 0.001927
2021-11-30 14:48:39,920 iteration 3598 : loss : 0.007517, loss_ce: 0.003173
2021-11-30 14:48:41,144 iteration 3599 : loss : 0.007456, loss_ce: 0.002767
2021-11-30 14:48:42,361 iteration 3600 : loss : 0.007933, loss_ce: 0.003077
2021-11-30 14:48:43,573 iteration 3601 : loss : 0.007201, loss_ce: 0.003179
2021-11-30 14:48:44,793 iteration 3602 : loss : 0.010140, loss_ce: 0.003837
2021-11-30 14:48:46,011 iteration 3603 : loss : 0.008242, loss_ce: 0.003139
2021-11-30 14:48:47,232 iteration 3604 : loss : 0.007497, loss_ce: 0.003170
 53%|██████████████▎            | 212/400 [1:20:21<1:10:33, 22.52s/it]2021-11-30 14:48:48,529 iteration 3605 : loss : 0.007166, loss_ce: 0.002603
2021-11-30 14:48:49,752 iteration 3606 : loss : 0.007073, loss_ce: 0.002415
2021-11-30 14:48:50,974 iteration 3607 : loss : 0.008425, loss_ce: 0.002476
2021-11-30 14:48:52,193 iteration 3608 : loss : 0.007992, loss_ce: 0.003761
2021-11-30 14:48:53,415 iteration 3609 : loss : 0.008802, loss_ce: 0.004034
2021-11-30 14:48:54,639 iteration 3610 : loss : 0.007744, loss_ce: 0.002574
2021-11-30 14:48:55,860 iteration 3611 : loss : 0.011949, loss_ce: 0.003989
2021-11-30 14:48:57,087 iteration 3612 : loss : 0.006984, loss_ce: 0.002811
2021-11-30 14:48:58,306 iteration 3613 : loss : 0.008804, loss_ce: 0.004257
2021-11-30 14:48:59,529 iteration 3614 : loss : 0.009872, loss_ce: 0.003201
2021-11-30 14:49:00,752 iteration 3615 : loss : 0.009082, loss_ce: 0.002421
2021-11-30 14:49:01,977 iteration 3616 : loss : 0.007057, loss_ce: 0.002337
2021-11-30 14:49:03,200 iteration 3617 : loss : 0.006835, loss_ce: 0.002716
2021-11-30 14:49:04,423 iteration 3618 : loss : 0.007308, loss_ce: 0.002363
2021-11-30 14:49:05,643 iteration 3619 : loss : 0.011305, loss_ce: 0.006056
2021-11-30 14:49:06,860 iteration 3620 : loss : 0.007670, loss_ce: 0.003269
2021-11-30 14:49:08,080 iteration 3621 : loss : 0.008983, loss_ce: 0.003312
 53%|██████████████▍            | 213/400 [1:20:42<1:08:36, 22.01s/it]2021-11-30 14:49:09,353 iteration 3622 : loss : 0.007770, loss_ce: 0.003061
2021-11-30 14:49:10,571 iteration 3623 : loss : 0.007591, loss_ce: 0.003148
2021-11-30 14:49:11,790 iteration 3624 : loss : 0.007537, loss_ce: 0.003012
2021-11-30 14:49:13,010 iteration 3625 : loss : 0.009135, loss_ce: 0.003593
2021-11-30 14:49:14,228 iteration 3626 : loss : 0.009592, loss_ce: 0.002897
2021-11-30 14:49:15,447 iteration 3627 : loss : 0.007669, loss_ce: 0.002787
2021-11-30 14:49:16,670 iteration 3628 : loss : 0.009376, loss_ce: 0.003218
2021-11-30 14:49:17,892 iteration 3629 : loss : 0.009340, loss_ce: 0.003086
2021-11-30 14:49:19,111 iteration 3630 : loss : 0.008114, loss_ce: 0.003267
2021-11-30 14:49:20,338 iteration 3631 : loss : 0.008158, loss_ce: 0.002968
2021-11-30 14:49:21,556 iteration 3632 : loss : 0.007842, loss_ce: 0.002393
2021-11-30 14:49:22,780 iteration 3633 : loss : 0.011664, loss_ce: 0.004083
2021-11-30 14:49:24,005 iteration 3634 : loss : 0.009625, loss_ce: 0.004652
2021-11-30 14:49:25,220 iteration 3635 : loss : 0.009997, loss_ce: 0.003038
2021-11-30 14:49:26,441 iteration 3636 : loss : 0.006693, loss_ce: 0.001927
2021-11-30 14:49:27,667 iteration 3637 : loss : 0.007247, loss_ce: 0.003102
2021-11-30 14:49:28,891 iteration 3638 : loss : 0.011936, loss_ce: 0.004987
 54%|██████████████▍            | 214/400 [1:21:02<1:07:08, 21.66s/it]2021-11-30 14:49:30,173 iteration 3639 : loss : 0.010369, loss_ce: 0.002622
2021-11-30 14:49:31,398 iteration 3640 : loss : 0.012911, loss_ce: 0.004995
2021-11-30 14:49:32,624 iteration 3641 : loss : 0.010069, loss_ce: 0.003118
2021-11-30 14:49:33,845 iteration 3642 : loss : 0.011585, loss_ce: 0.005788
2021-11-30 14:49:35,070 iteration 3643 : loss : 0.010134, loss_ce: 0.004167
2021-11-30 14:49:36,301 iteration 3644 : loss : 0.010628, loss_ce: 0.003922
2021-11-30 14:49:37,524 iteration 3645 : loss : 0.010560, loss_ce: 0.004935
2021-11-30 14:49:38,745 iteration 3646 : loss : 0.007737, loss_ce: 0.002773
2021-11-30 14:49:39,968 iteration 3647 : loss : 0.008355, loss_ce: 0.003073
2021-11-30 14:49:41,191 iteration 3648 : loss : 0.007940, loss_ce: 0.002648
2021-11-30 14:49:42,414 iteration 3649 : loss : 0.009128, loss_ce: 0.003186
2021-11-30 14:49:43,634 iteration 3650 : loss : 0.008760, loss_ce: 0.003750
2021-11-30 14:49:44,857 iteration 3651 : loss : 0.009842, loss_ce: 0.002630
2021-11-30 14:49:46,084 iteration 3652 : loss : 0.006802, loss_ce: 0.002666
2021-11-30 14:49:47,305 iteration 3653 : loss : 0.008920, loss_ce: 0.003118
2021-11-30 14:49:48,532 iteration 3654 : loss : 0.011071, loss_ce: 0.004205
2021-11-30 14:49:48,533 Training Data Eval:
2021-11-30 14:49:55,461   Average segmentation loss on training set: 0.0099
2021-11-30 14:49:55,461 Validation Data Eval:
2021-11-30 14:49:57,831   Average segmentation loss on validation set: 0.1527
2021-11-30 14:49:59,062 iteration 3655 : loss : 0.009137, loss_ce: 0.002950
 54%|██████████████▌            | 215/400 [1:21:33<1:14:39, 24.21s/it]2021-11-30 14:50:00,360 iteration 3656 : loss : 0.009304, loss_ce: 0.003005
2021-11-30 14:50:01,583 iteration 3657 : loss : 0.009582, loss_ce: 0.003730
2021-11-30 14:50:02,809 iteration 3658 : loss : 0.010775, loss_ce: 0.003837
2021-11-30 14:50:04,038 iteration 3659 : loss : 0.009083, loss_ce: 0.003552
2021-11-30 14:50:05,256 iteration 3660 : loss : 0.008527, loss_ce: 0.002834
2021-11-30 14:50:06,480 iteration 3661 : loss : 0.009387, loss_ce: 0.004252
2021-11-30 14:50:07,709 iteration 3662 : loss : 0.009744, loss_ce: 0.003683
2021-11-30 14:50:08,938 iteration 3663 : loss : 0.009736, loss_ce: 0.003916
2021-11-30 14:50:10,152 iteration 3664 : loss : 0.007318, loss_ce: 0.002200
2021-11-30 14:50:11,375 iteration 3665 : loss : 0.009919, loss_ce: 0.003453
2021-11-30 14:50:12,595 iteration 3666 : loss : 0.010083, loss_ce: 0.003774
2021-11-30 14:50:13,821 iteration 3667 : loss : 0.007686, loss_ce: 0.002267
2021-11-30 14:50:15,043 iteration 3668 : loss : 0.010169, loss_ce: 0.004130
2021-11-30 14:50:16,263 iteration 3669 : loss : 0.008307, loss_ce: 0.003964
2021-11-30 14:50:17,486 iteration 3670 : loss : 0.007598, loss_ce: 0.002900
2021-11-30 14:50:18,705 iteration 3671 : loss : 0.008202, loss_ce: 0.002941
2021-11-30 14:50:19,926 iteration 3672 : loss : 0.008423, loss_ce: 0.003254
 54%|██████████████▌            | 216/400 [1:21:53<1:11:10, 23.21s/it]2021-11-30 14:50:21,221 iteration 3673 : loss : 0.006857, loss_ce: 0.002505
2021-11-30 14:50:22,446 iteration 3674 : loss : 0.008043, loss_ce: 0.004096
2021-11-30 14:50:23,669 iteration 3675 : loss : 0.009310, loss_ce: 0.002825
2021-11-30 14:50:24,894 iteration 3676 : loss : 0.008717, loss_ce: 0.003116
2021-11-30 14:50:26,122 iteration 3677 : loss : 0.008275, loss_ce: 0.003873
2021-11-30 14:50:27,343 iteration 3678 : loss : 0.008448, loss_ce: 0.002626
2021-11-30 14:50:28,566 iteration 3679 : loss : 0.007883, loss_ce: 0.002667
2021-11-30 14:50:29,792 iteration 3680 : loss : 0.008753, loss_ce: 0.002976
2021-11-30 14:50:31,021 iteration 3681 : loss : 0.007726, loss_ce: 0.003980
2021-11-30 14:50:32,244 iteration 3682 : loss : 0.008323, loss_ce: 0.003256
2021-11-30 14:50:33,464 iteration 3683 : loss : 0.007931, loss_ce: 0.002615
2021-11-30 14:50:34,684 iteration 3684 : loss : 0.008334, loss_ce: 0.002359
2021-11-30 14:50:35,911 iteration 3685 : loss : 0.008629, loss_ce: 0.003022
2021-11-30 14:50:37,137 iteration 3686 : loss : 0.008008, loss_ce: 0.002961
2021-11-30 14:50:38,359 iteration 3687 : loss : 0.007630, loss_ce: 0.002883
2021-11-30 14:50:39,579 iteration 3688 : loss : 0.008098, loss_ce: 0.003859
2021-11-30 14:50:40,808 iteration 3689 : loss : 0.013129, loss_ce: 0.003268
 54%|██████████████▋            | 217/400 [1:22:14<1:08:39, 22.51s/it]2021-11-30 14:50:42,101 iteration 3690 : loss : 0.007366, loss_ce: 0.003160
2021-11-30 14:50:43,324 iteration 3691 : loss : 0.010084, loss_ce: 0.003119
2021-11-30 14:50:44,547 iteration 3692 : loss : 0.006780, loss_ce: 0.002148
2021-11-30 14:50:45,769 iteration 3693 : loss : 0.009582, loss_ce: 0.003461
2021-11-30 14:50:46,995 iteration 3694 : loss : 0.008476, loss_ce: 0.004014
2021-11-30 14:50:48,221 iteration 3695 : loss : 0.009539, loss_ce: 0.003654
2021-11-30 14:50:49,449 iteration 3696 : loss : 0.007917, loss_ce: 0.003384
2021-11-30 14:50:50,672 iteration 3697 : loss : 0.008917, loss_ce: 0.002543
2021-11-30 14:50:51,894 iteration 3698 : loss : 0.007229, loss_ce: 0.003023
2021-11-30 14:50:53,115 iteration 3699 : loss : 0.007616, loss_ce: 0.002674
2021-11-30 14:50:54,342 iteration 3700 : loss : 0.008454, loss_ce: 0.003654
2021-11-30 14:50:55,567 iteration 3701 : loss : 0.008233, loss_ce: 0.002235
2021-11-30 14:50:56,797 iteration 3702 : loss : 0.008417, loss_ce: 0.002794
2021-11-30 14:50:58,019 iteration 3703 : loss : 0.007197, loss_ce: 0.002836
2021-11-30 14:50:59,246 iteration 3704 : loss : 0.008465, loss_ce: 0.003730
2021-11-30 14:51:00,469 iteration 3705 : loss : 0.007674, loss_ce: 0.002688
2021-11-30 14:51:01,690 iteration 3706 : loss : 0.009086, loss_ce: 0.003505
 55%|██████████████▋            | 218/400 [1:22:35<1:06:48, 22.02s/it]2021-11-30 14:51:02,988 iteration 3707 : loss : 0.007099, loss_ce: 0.002435
2021-11-30 14:51:04,211 iteration 3708 : loss : 0.007521, loss_ce: 0.003312
2021-11-30 14:51:05,438 iteration 3709 : loss : 0.007433, loss_ce: 0.002909
2021-11-30 14:51:06,666 iteration 3710 : loss : 0.008265, loss_ce: 0.003001
2021-11-30 14:51:07,884 iteration 3711 : loss : 0.007956, loss_ce: 0.003104
2021-11-30 14:51:09,104 iteration 3712 : loss : 0.009615, loss_ce: 0.002320
2021-11-30 14:51:10,329 iteration 3713 : loss : 0.008070, loss_ce: 0.002668
2021-11-30 14:51:11,554 iteration 3714 : loss : 0.007597, loss_ce: 0.004193
2021-11-30 14:51:12,778 iteration 3715 : loss : 0.009513, loss_ce: 0.003578
2021-11-30 14:51:14,004 iteration 3716 : loss : 0.008788, loss_ce: 0.004077
2021-11-30 14:51:15,229 iteration 3717 : loss : 0.008313, loss_ce: 0.002744
2021-11-30 14:51:16,455 iteration 3718 : loss : 0.009226, loss_ce: 0.003412
2021-11-30 14:51:17,679 iteration 3719 : loss : 0.008991, loss_ce: 0.004046
2021-11-30 14:51:18,898 iteration 3720 : loss : 0.008195, loss_ce: 0.002367
2021-11-30 14:51:20,123 iteration 3721 : loss : 0.007976, loss_ce: 0.002838
2021-11-30 14:51:21,347 iteration 3722 : loss : 0.007234, loss_ce: 0.002163
2021-11-30 14:51:22,576 iteration 3723 : loss : 0.006810, loss_ce: 0.002626
 55%|██████████████▊            | 219/400 [1:22:56<1:05:24, 21.68s/it]2021-11-30 14:51:23,880 iteration 3724 : loss : 0.009113, loss_ce: 0.002520
2021-11-30 14:51:25,110 iteration 3725 : loss : 0.008799, loss_ce: 0.002860
2021-11-30 14:51:26,336 iteration 3726 : loss : 0.008330, loss_ce: 0.002459
2021-11-30 14:51:27,562 iteration 3727 : loss : 0.008355, loss_ce: 0.004305
2021-11-30 14:51:28,789 iteration 3728 : loss : 0.009620, loss_ce: 0.004458
2021-11-30 14:51:30,019 iteration 3729 : loss : 0.008765, loss_ce: 0.002651
2021-11-30 14:51:31,248 iteration 3730 : loss : 0.008969, loss_ce: 0.002664
2021-11-30 14:51:32,468 iteration 3731 : loss : 0.008774, loss_ce: 0.003463
2021-11-30 14:51:33,687 iteration 3732 : loss : 0.005695, loss_ce: 0.002401
2021-11-30 14:51:34,905 iteration 3733 : loss : 0.009297, loss_ce: 0.002177
2021-11-30 14:51:36,128 iteration 3734 : loss : 0.010534, loss_ce: 0.004756
2021-11-30 14:51:37,354 iteration 3735 : loss : 0.008100, loss_ce: 0.003037
2021-11-30 14:51:38,583 iteration 3736 : loss : 0.009666, loss_ce: 0.003911
2021-11-30 14:51:39,803 iteration 3737 : loss : 0.007034, loss_ce: 0.002755
2021-11-30 14:51:41,030 iteration 3738 : loss : 0.008859, loss_ce: 0.005563
2021-11-30 14:51:42,258 iteration 3739 : loss : 0.014113, loss_ce: 0.003744
2021-11-30 14:51:42,258 Training Data Eval:
2021-11-30 14:51:49,182   Average segmentation loss on training set: 0.0089
2021-11-30 14:51:49,183 Validation Data Eval:
2021-11-30 14:51:51,553   Average segmentation loss on validation set: 0.1329
2021-11-30 14:51:52,782 iteration 3740 : loss : 0.008002, loss_ce: 0.003637
 55%|██████████████▊            | 220/400 [1:23:26<1:12:42, 24.24s/it]2021-11-30 14:51:54,078 iteration 3741 : loss : 0.007882, loss_ce: 0.004058
2021-11-30 14:51:55,308 iteration 3742 : loss : 0.008214, loss_ce: 0.002762
2021-11-30 14:51:56,530 iteration 3743 : loss : 0.009937, loss_ce: 0.003483
2021-11-30 14:51:57,756 iteration 3744 : loss : 0.008049, loss_ce: 0.003677
2021-11-30 14:51:58,983 iteration 3745 : loss : 0.008467, loss_ce: 0.002909
2021-11-30 14:52:00,210 iteration 3746 : loss : 0.008008, loss_ce: 0.002597
2021-11-30 14:52:01,436 iteration 3747 : loss : 0.008109, loss_ce: 0.003302
2021-11-30 14:52:02,658 iteration 3748 : loss : 0.007767, loss_ce: 0.002389
2021-11-30 14:52:03,880 iteration 3749 : loss : 0.008351, loss_ce: 0.003606
2021-11-30 14:52:05,103 iteration 3750 : loss : 0.008313, loss_ce: 0.003002
2021-11-30 14:52:06,328 iteration 3751 : loss : 0.007398, loss_ce: 0.002467
2021-11-30 14:52:07,549 iteration 3752 : loss : 0.009525, loss_ce: 0.002695
2021-11-30 14:52:08,776 iteration 3753 : loss : 0.007022, loss_ce: 0.002168
2021-11-30 14:52:10,008 iteration 3754 : loss : 0.007053, loss_ce: 0.002874
2021-11-30 14:52:11,233 iteration 3755 : loss : 0.008096, loss_ce: 0.003497
2021-11-30 14:52:12,461 iteration 3756 : loss : 0.008196, loss_ce: 0.003475
2021-11-30 14:52:13,688 iteration 3757 : loss : 0.008185, loss_ce: 0.003376
 55%|██████████████▉            | 221/400 [1:23:47<1:09:19, 23.24s/it]2021-11-30 14:52:14,976 iteration 3758 : loss : 0.008559, loss_ce: 0.002200
2021-11-30 14:52:16,196 iteration 3759 : loss : 0.006687, loss_ce: 0.002598
2021-11-30 14:52:17,424 iteration 3760 : loss : 0.007976, loss_ce: 0.003796
2021-11-30 14:52:18,651 iteration 3761 : loss : 0.007877, loss_ce: 0.002819
2021-11-30 14:52:19,876 iteration 3762 : loss : 0.006961, loss_ce: 0.002448
2021-11-30 14:52:21,095 iteration 3763 : loss : 0.007434, loss_ce: 0.001991
2021-11-30 14:52:22,316 iteration 3764 : loss : 0.007939, loss_ce: 0.003955
2021-11-30 14:52:23,541 iteration 3765 : loss : 0.007388, loss_ce: 0.002497
2021-11-30 14:52:24,768 iteration 3766 : loss : 0.007845, loss_ce: 0.002800
2021-11-30 14:52:25,993 iteration 3767 : loss : 0.006444, loss_ce: 0.002856
2021-11-30 14:52:27,215 iteration 3768 : loss : 0.006656, loss_ce: 0.003150
2021-11-30 14:52:28,437 iteration 3769 : loss : 0.005392, loss_ce: 0.002270
2021-11-30 14:52:29,663 iteration 3770 : loss : 0.007824, loss_ce: 0.002932
2021-11-30 14:52:30,890 iteration 3771 : loss : 0.009281, loss_ce: 0.003756
2021-11-30 14:52:32,115 iteration 3772 : loss : 0.006817, loss_ce: 0.002913
2021-11-30 14:52:33,337 iteration 3773 : loss : 0.007846, loss_ce: 0.002765
2021-11-30 14:52:34,564 iteration 3774 : loss : 0.006457, loss_ce: 0.002813
 56%|██████████████▉            | 222/400 [1:24:08<1:06:50, 22.53s/it]2021-11-30 14:52:35,855 iteration 3775 : loss : 0.007826, loss_ce: 0.003968
2021-11-30 14:52:37,082 iteration 3776 : loss : 0.005894, loss_ce: 0.002353
2021-11-30 14:52:38,300 iteration 3777 : loss : 0.007525, loss_ce: 0.002926
2021-11-30 14:52:39,524 iteration 3778 : loss : 0.006124, loss_ce: 0.001936
2021-11-30 14:52:40,750 iteration 3779 : loss : 0.009785, loss_ce: 0.003370
2021-11-30 14:52:41,971 iteration 3780 : loss : 0.007855, loss_ce: 0.002643
2021-11-30 14:52:43,198 iteration 3781 : loss : 0.006804, loss_ce: 0.002014
2021-11-30 14:52:44,422 iteration 3782 : loss : 0.008043, loss_ce: 0.003385
2021-11-30 14:52:45,644 iteration 3783 : loss : 0.006630, loss_ce: 0.002803
2021-11-30 14:52:46,871 iteration 3784 : loss : 0.007356, loss_ce: 0.003414
2021-11-30 14:52:48,097 iteration 3785 : loss : 0.008857, loss_ce: 0.003518
2021-11-30 14:52:49,329 iteration 3786 : loss : 0.005767, loss_ce: 0.001916
2021-11-30 14:52:50,552 iteration 3787 : loss : 0.006684, loss_ce: 0.002360
2021-11-30 14:52:51,778 iteration 3788 : loss : 0.006318, loss_ce: 0.002517
2021-11-30 14:52:53,002 iteration 3789 : loss : 0.007313, loss_ce: 0.002505
2021-11-30 14:52:54,225 iteration 3790 : loss : 0.007155, loss_ce: 0.002936
2021-11-30 14:52:55,454 iteration 3791 : loss : 0.007926, loss_ce: 0.002839
 56%|███████████████            | 223/400 [1:24:29<1:05:00, 22.04s/it]2021-11-30 14:52:56,752 iteration 3792 : loss : 0.006870, loss_ce: 0.002197
2021-11-30 14:52:57,983 iteration 3793 : loss : 0.007344, loss_ce: 0.003326
2021-11-30 14:52:59,202 iteration 3794 : loss : 0.006987, loss_ce: 0.002597
2021-11-30 14:53:00,421 iteration 3795 : loss : 0.006812, loss_ce: 0.003621
2021-11-30 14:53:01,644 iteration 3796 : loss : 0.008599, loss_ce: 0.002542
2021-11-30 14:53:02,874 iteration 3797 : loss : 0.006307, loss_ce: 0.002474
2021-11-30 14:53:04,096 iteration 3798 : loss : 0.008954, loss_ce: 0.003256
2021-11-30 14:53:05,317 iteration 3799 : loss : 0.006535, loss_ce: 0.002491
2021-11-30 14:53:06,539 iteration 3800 : loss : 0.007483, loss_ce: 0.002646
2021-11-30 14:53:07,756 iteration 3801 : loss : 0.008336, loss_ce: 0.002194
2021-11-30 14:53:08,980 iteration 3802 : loss : 0.006653, loss_ce: 0.002255
2021-11-30 14:53:10,199 iteration 3803 : loss : 0.006246, loss_ce: 0.002839
2021-11-30 14:53:11,419 iteration 3804 : loss : 0.005652, loss_ce: 0.001927
2021-11-30 14:53:12,645 iteration 3805 : loss : 0.006687, loss_ce: 0.002784
2021-11-30 14:53:13,863 iteration 3806 : loss : 0.007747, loss_ce: 0.002904
2021-11-30 14:53:15,083 iteration 3807 : loss : 0.006256, loss_ce: 0.001999
2021-11-30 14:53:16,316 iteration 3808 : loss : 0.006984, loss_ce: 0.002696
 56%|███████████████            | 224/400 [1:24:50<1:03:36, 21.68s/it]2021-11-30 14:53:17,608 iteration 3809 : loss : 0.005912, loss_ce: 0.002202
2021-11-30 14:53:18,836 iteration 3810 : loss : 0.007561, loss_ce: 0.003327
2021-11-30 14:53:20,050 iteration 3811 : loss : 0.010137, loss_ce: 0.002795
2021-11-30 14:53:21,276 iteration 3812 : loss : 0.007260, loss_ce: 0.002273
2021-11-30 14:53:22,500 iteration 3813 : loss : 0.006991, loss_ce: 0.003131
2021-11-30 14:53:23,724 iteration 3814 : loss : 0.010315, loss_ce: 0.002766
2021-11-30 14:53:24,948 iteration 3815 : loss : 0.008404, loss_ce: 0.003157
2021-11-30 14:53:26,173 iteration 3816 : loss : 0.006890, loss_ce: 0.002431
2021-11-30 14:53:27,392 iteration 3817 : loss : 0.010629, loss_ce: 0.003866
2021-11-30 14:53:28,617 iteration 3818 : loss : 0.009497, loss_ce: 0.003204
2021-11-30 14:53:29,842 iteration 3819 : loss : 0.009964, loss_ce: 0.004031
2021-11-30 14:53:31,059 iteration 3820 : loss : 0.006536, loss_ce: 0.002839
2021-11-30 14:53:32,284 iteration 3821 : loss : 0.011020, loss_ce: 0.004327
2021-11-30 14:53:33,508 iteration 3822 : loss : 0.009668, loss_ce: 0.003983
2021-11-30 14:53:34,732 iteration 3823 : loss : 0.009821, loss_ce: 0.002752
2021-11-30 14:53:35,952 iteration 3824 : loss : 0.009147, loss_ce: 0.003183
2021-11-30 14:53:35,952 Training Data Eval:
2021-11-30 14:53:42,857   Average segmentation loss on training set: 0.0080
2021-11-30 14:53:42,858 Validation Data Eval:
2021-11-30 14:53:45,230   Average segmentation loss on validation set: 0.1445
2021-11-30 14:53:46,458 iteration 3825 : loss : 0.007155, loss_ce: 0.002756
 56%|███████████████▏           | 225/400 [1:25:20<1:10:38, 24.22s/it]2021-11-30 14:53:47,747 iteration 3826 : loss : 0.007144, loss_ce: 0.002648
2021-11-30 14:53:48,972 iteration 3827 : loss : 0.009592, loss_ce: 0.004437
2021-11-30 14:53:50,191 iteration 3828 : loss : 0.010124, loss_ce: 0.002361
2021-11-30 14:53:51,410 iteration 3829 : loss : 0.008998, loss_ce: 0.003308
2021-11-30 14:53:52,634 iteration 3830 : loss : 0.009129, loss_ce: 0.003664
2021-11-30 14:53:53,856 iteration 3831 : loss : 0.008932, loss_ce: 0.003850
2021-11-30 14:53:55,075 iteration 3832 : loss : 0.008056, loss_ce: 0.002898
2021-11-30 14:53:56,295 iteration 3833 : loss : 0.010808, loss_ce: 0.004269
2021-11-30 14:53:57,517 iteration 3834 : loss : 0.007987, loss_ce: 0.003444
2021-11-30 14:53:58,741 iteration 3835 : loss : 0.007892, loss_ce: 0.002680
2021-11-30 14:53:59,959 iteration 3836 : loss : 0.009221, loss_ce: 0.003828
2021-11-30 14:54:01,183 iteration 3837 : loss : 0.008844, loss_ce: 0.003086
2021-11-30 14:54:02,406 iteration 3838 : loss : 0.007644, loss_ce: 0.002317
2021-11-30 14:54:03,632 iteration 3839 : loss : 0.009762, loss_ce: 0.003432
2021-11-30 14:54:04,860 iteration 3840 : loss : 0.007914, loss_ce: 0.002155
2021-11-30 14:54:06,085 iteration 3841 : loss : 0.007779, loss_ce: 0.003592
2021-11-30 14:54:07,305 iteration 3842 : loss : 0.008109, loss_ce: 0.003458
 56%|███████████████▎           | 226/400 [1:25:41<1:07:18, 23.21s/it]2021-11-30 14:54:08,598 iteration 3843 : loss : 0.008981, loss_ce: 0.002650
2021-11-30 14:54:09,819 iteration 3844 : loss : 0.008912, loss_ce: 0.004310
2021-11-30 14:54:11,045 iteration 3845 : loss : 0.010219, loss_ce: 0.002915
2021-11-30 14:54:12,268 iteration 3846 : loss : 0.007982, loss_ce: 0.003732
2021-11-30 14:54:13,491 iteration 3847 : loss : 0.006442, loss_ce: 0.002563
2021-11-30 14:54:14,714 iteration 3848 : loss : 0.008879, loss_ce: 0.002397
2021-11-30 14:54:15,940 iteration 3849 : loss : 0.009074, loss_ce: 0.002877
2021-11-30 14:54:17,158 iteration 3850 : loss : 0.010824, loss_ce: 0.004433
2021-11-30 14:54:18,380 iteration 3851 : loss : 0.007936, loss_ce: 0.003385
2021-11-30 14:54:19,604 iteration 3852 : loss : 0.007704, loss_ce: 0.002766
2021-11-30 14:54:20,831 iteration 3853 : loss : 0.007668, loss_ce: 0.003070
2021-11-30 14:54:22,063 iteration 3854 : loss : 0.008379, loss_ce: 0.002716
2021-11-30 14:54:23,290 iteration 3855 : loss : 0.007552, loss_ce: 0.002402
2021-11-30 14:54:24,513 iteration 3856 : loss : 0.007557, loss_ce: 0.003087
2021-11-30 14:54:25,737 iteration 3857 : loss : 0.006478, loss_ce: 0.002719
2021-11-30 14:54:26,961 iteration 3858 : loss : 0.008745, loss_ce: 0.003475
2021-11-30 14:54:28,176 iteration 3859 : loss : 0.007121, loss_ce: 0.003003
 57%|███████████████▎           | 227/400 [1:26:02<1:04:53, 22.51s/it]2021-11-30 14:54:29,470 iteration 3860 : loss : 0.006628, loss_ce: 0.002340
2021-11-30 14:54:30,689 iteration 3861 : loss : 0.007848, loss_ce: 0.003902
2021-11-30 14:54:31,910 iteration 3862 : loss : 0.007915, loss_ce: 0.001938
2021-11-30 14:54:33,132 iteration 3863 : loss : 0.008475, loss_ce: 0.003996
2021-11-30 14:54:34,352 iteration 3864 : loss : 0.006933, loss_ce: 0.002677
2021-11-30 14:54:35,574 iteration 3865 : loss : 0.006125, loss_ce: 0.002105
2021-11-30 14:54:36,797 iteration 3866 : loss : 0.009785, loss_ce: 0.003083
2021-11-30 14:54:38,024 iteration 3867 : loss : 0.007782, loss_ce: 0.003276
2021-11-30 14:54:39,251 iteration 3868 : loss : 0.006541, loss_ce: 0.002328
2021-11-30 14:54:40,478 iteration 3869 : loss : 0.007957, loss_ce: 0.003675
2021-11-30 14:54:41,706 iteration 3870 : loss : 0.007633, loss_ce: 0.003131
2021-11-30 14:54:42,922 iteration 3871 : loss : 0.007133, loss_ce: 0.002732
2021-11-30 14:54:44,140 iteration 3872 : loss : 0.007856, loss_ce: 0.002929
2021-11-30 14:54:45,364 iteration 3873 : loss : 0.005552, loss_ce: 0.002421
2021-11-30 14:54:46,584 iteration 3874 : loss : 0.007212, loss_ce: 0.002033
2021-11-30 14:54:47,810 iteration 3875 : loss : 0.007324, loss_ce: 0.003487
2021-11-30 14:54:49,033 iteration 3876 : loss : 0.008635, loss_ce: 0.003682
 57%|███████████████▍           | 228/400 [1:26:23<1:03:06, 22.01s/it]2021-11-30 14:54:50,332 iteration 3877 : loss : 0.007992, loss_ce: 0.003350
2021-11-30 14:54:51,553 iteration 3878 : loss : 0.006525, loss_ce: 0.002740
2021-11-30 14:54:52,776 iteration 3879 : loss : 0.009151, loss_ce: 0.001903
2021-11-30 14:54:54,003 iteration 3880 : loss : 0.010084, loss_ce: 0.003351
2021-11-30 14:54:55,219 iteration 3881 : loss : 0.005905, loss_ce: 0.002130
2021-11-30 14:54:56,440 iteration 3882 : loss : 0.006586, loss_ce: 0.002815
2021-11-30 14:54:57,668 iteration 3883 : loss : 0.007696, loss_ce: 0.003161
2021-11-30 14:54:58,891 iteration 3884 : loss : 0.008265, loss_ce: 0.003969
2021-11-30 14:55:00,105 iteration 3885 : loss : 0.006776, loss_ce: 0.002665
2021-11-30 14:55:01,330 iteration 3886 : loss : 0.007023, loss_ce: 0.003105
2021-11-30 14:55:02,552 iteration 3887 : loss : 0.008101, loss_ce: 0.003540
2021-11-30 14:55:03,777 iteration 3888 : loss : 0.005782, loss_ce: 0.002053
2021-11-30 14:55:04,998 iteration 3889 : loss : 0.007570, loss_ce: 0.002257
2021-11-30 14:55:06,222 iteration 3890 : loss : 0.007417, loss_ce: 0.002288
2021-11-30 14:55:07,442 iteration 3891 : loss : 0.006101, loss_ce: 0.002196
2021-11-30 14:55:08,665 iteration 3892 : loss : 0.007718, loss_ce: 0.002924
2021-11-30 14:55:09,894 iteration 3893 : loss : 0.006209, loss_ce: 0.002296
 57%|███████████████▍           | 229/400 [1:26:43<1:01:45, 21.67s/it]2021-11-30 14:55:11,185 iteration 3894 : loss : 0.006298, loss_ce: 0.002344
2021-11-30 14:55:12,408 iteration 3895 : loss : 0.009155, loss_ce: 0.002298
2021-11-30 14:55:13,622 iteration 3896 : loss : 0.006263, loss_ce: 0.002507
2021-11-30 14:55:14,837 iteration 3897 : loss : 0.006755, loss_ce: 0.002025
2021-11-30 14:55:16,063 iteration 3898 : loss : 0.006577, loss_ce: 0.002652
2021-11-30 14:55:17,288 iteration 3899 : loss : 0.006841, loss_ce: 0.002594
2021-11-30 14:55:18,516 iteration 3900 : loss : 0.007207, loss_ce: 0.002810
2021-11-30 14:55:19,737 iteration 3901 : loss : 0.007440, loss_ce: 0.003128
2021-11-30 14:55:20,959 iteration 3902 : loss : 0.008601, loss_ce: 0.003038
2021-11-30 14:55:22,179 iteration 3903 : loss : 0.007800, loss_ce: 0.003038
2021-11-30 14:55:23,400 iteration 3904 : loss : 0.007210, loss_ce: 0.002131
2021-11-30 14:55:24,623 iteration 3905 : loss : 0.005897, loss_ce: 0.001982
2021-11-30 14:55:25,839 iteration 3906 : loss : 0.008027, loss_ce: 0.002642
2021-11-30 14:55:27,069 iteration 3907 : loss : 0.006661, loss_ce: 0.003563
2021-11-30 14:55:28,294 iteration 3908 : loss : 0.007675, loss_ce: 0.003322
2021-11-30 14:55:29,515 iteration 3909 : loss : 0.006431, loss_ce: 0.002307
2021-11-30 14:55:29,515 Training Data Eval:
2021-11-30 14:55:36,423   Average segmentation loss on training set: 0.0071
2021-11-30 14:55:36,423 Validation Data Eval:
2021-11-30 14:55:38,795   Average segmentation loss on validation set: 0.1303
2021-11-30 14:55:40,020 iteration 3910 : loss : 0.007350, loss_ce: 0.002402
 57%|███████████████▌           | 230/400 [1:27:14<1:08:34, 24.20s/it]2021-11-30 14:55:41,314 iteration 3911 : loss : 0.005975, loss_ce: 0.002121
2021-11-30 14:55:42,531 iteration 3912 : loss : 0.009599, loss_ce: 0.002512
2021-11-30 14:55:43,753 iteration 3913 : loss : 0.010200, loss_ce: 0.004343
2021-11-30 14:55:44,975 iteration 3914 : loss : 0.007619, loss_ce: 0.002976
2021-11-30 14:55:46,199 iteration 3915 : loss : 0.008240, loss_ce: 0.002804
2021-11-30 14:55:47,423 iteration 3916 : loss : 0.009139, loss_ce: 0.002802
2021-11-30 14:55:48,645 iteration 3917 : loss : 0.008304, loss_ce: 0.004214
2021-11-30 14:55:49,869 iteration 3918 : loss : 0.007499, loss_ce: 0.002669
2021-11-30 14:55:51,087 iteration 3919 : loss : 0.007005, loss_ce: 0.002721
2021-11-30 14:55:52,314 iteration 3920 : loss : 0.006582, loss_ce: 0.002990
2021-11-30 14:55:53,535 iteration 3921 : loss : 0.007138, loss_ce: 0.003165
2021-11-30 14:55:54,761 iteration 3922 : loss : 0.005990, loss_ce: 0.001630
2021-11-30 14:55:55,988 iteration 3923 : loss : 0.007001, loss_ce: 0.002735
2021-11-30 14:55:57,211 iteration 3924 : loss : 0.009107, loss_ce: 0.004325
2021-11-30 14:55:58,431 iteration 3925 : loss : 0.006946, loss_ce: 0.002942
2021-11-30 14:55:59,652 iteration 3926 : loss : 0.013281, loss_ce: 0.002298
2021-11-30 14:56:00,871 iteration 3927 : loss : 0.009273, loss_ce: 0.002607
 58%|███████████████▌           | 231/400 [1:27:34<1:05:20, 23.20s/it]2021-11-30 14:56:02,169 iteration 3928 : loss : 0.009147, loss_ce: 0.002319
2021-11-30 14:56:03,389 iteration 3929 : loss : 0.012253, loss_ce: 0.004100
2021-11-30 14:56:04,612 iteration 3930 : loss : 0.006857, loss_ce: 0.002606
2021-11-30 14:56:05,829 iteration 3931 : loss : 0.010816, loss_ce: 0.004602
2021-11-30 14:56:07,055 iteration 3932 : loss : 0.011947, loss_ce: 0.003820
2021-11-30 14:56:08,275 iteration 3933 : loss : 0.009160, loss_ce: 0.004183
2021-11-30 14:56:09,497 iteration 3934 : loss : 0.010144, loss_ce: 0.003209
2021-11-30 14:56:10,718 iteration 3935 : loss : 0.007546, loss_ce: 0.002595
2021-11-30 14:56:11,938 iteration 3936 : loss : 0.007853, loss_ce: 0.003416
2021-11-30 14:56:13,158 iteration 3937 : loss : 0.008292, loss_ce: 0.002639
2021-11-30 14:56:14,385 iteration 3938 : loss : 0.009149, loss_ce: 0.004037
2021-11-30 14:56:15,604 iteration 3939 : loss : 0.009217, loss_ce: 0.002736
2021-11-30 14:56:16,825 iteration 3940 : loss : 0.008089, loss_ce: 0.003483
2021-11-30 14:56:18,049 iteration 3941 : loss : 0.007378, loss_ce: 0.003517
2021-11-30 14:56:19,275 iteration 3942 : loss : 0.010013, loss_ce: 0.002781
2021-11-30 14:56:20,496 iteration 3943 : loss : 0.007832, loss_ce: 0.003318
2021-11-30 14:56:21,728 iteration 3944 : loss : 0.006790, loss_ce: 0.002780
 58%|███████████████▋           | 232/400 [1:27:55<1:02:59, 22.50s/it]2021-11-30 14:56:23,019 iteration 3945 : loss : 0.007875, loss_ce: 0.002321
2021-11-30 14:56:24,244 iteration 3946 : loss : 0.008241, loss_ce: 0.003234
2021-11-30 14:56:25,472 iteration 3947 : loss : 0.012071, loss_ce: 0.005479
2021-11-30 14:56:26,700 iteration 3948 : loss : 0.008004, loss_ce: 0.003175
2021-11-30 14:56:27,927 iteration 3949 : loss : 0.008629, loss_ce: 0.003651
2021-11-30 14:56:29,146 iteration 3950 : loss : 0.007387, loss_ce: 0.003378
2021-11-30 14:56:30,368 iteration 3951 : loss : 0.007128, loss_ce: 0.002531
2021-11-30 14:56:31,595 iteration 3952 : loss : 0.009801, loss_ce: 0.004659
2021-11-30 14:56:32,819 iteration 3953 : loss : 0.009405, loss_ce: 0.003963
2021-11-30 14:56:34,040 iteration 3954 : loss : 0.009028, loss_ce: 0.003374
2021-11-30 14:56:35,261 iteration 3955 : loss : 0.007599, loss_ce: 0.003147
2021-11-30 14:56:36,487 iteration 3956 : loss : 0.007338, loss_ce: 0.003547
2021-11-30 14:56:37,710 iteration 3957 : loss : 0.008342, loss_ce: 0.003034
2021-11-30 14:56:38,937 iteration 3958 : loss : 0.008037, loss_ce: 0.001964
2021-11-30 14:56:40,159 iteration 3959 : loss : 0.007129, loss_ce: 0.002108
2021-11-30 14:56:41,382 iteration 3960 : loss : 0.008229, loss_ce: 0.002511
2021-11-30 14:56:42,601 iteration 3961 : loss : 0.008234, loss_ce: 0.002865
 58%|███████████████▋           | 233/400 [1:28:16<1:01:15, 22.01s/it]2021-11-30 14:56:43,894 iteration 3962 : loss : 0.009155, loss_ce: 0.002679
2021-11-30 14:56:45,120 iteration 3963 : loss : 0.008882, loss_ce: 0.003989
2021-11-30 14:56:46,339 iteration 3964 : loss : 0.007316, loss_ce: 0.003184
2021-11-30 14:56:47,554 iteration 3965 : loss : 0.007811, loss_ce: 0.003372
2021-11-30 14:56:48,778 iteration 3966 : loss : 0.008334, loss_ce: 0.003113
2021-11-30 14:56:50,000 iteration 3967 : loss : 0.007600, loss_ce: 0.002923
2021-11-30 14:56:51,228 iteration 3968 : loss : 0.007428, loss_ce: 0.001942
2021-11-30 14:56:52,448 iteration 3969 : loss : 0.008561, loss_ce: 0.003323
2021-11-30 14:56:53,669 iteration 3970 : loss : 0.007850, loss_ce: 0.003558
2021-11-30 14:56:54,895 iteration 3971 : loss : 0.011838, loss_ce: 0.003752
2021-11-30 14:56:56,120 iteration 3972 : loss : 0.008313, loss_ce: 0.003362
2021-11-30 14:56:57,335 iteration 3973 : loss : 0.007716, loss_ce: 0.003019
2021-11-30 14:56:58,555 iteration 3974 : loss : 0.009095, loss_ce: 0.002522
2021-11-30 14:56:59,781 iteration 3975 : loss : 0.009575, loss_ce: 0.002799
2021-11-30 14:57:01,004 iteration 3976 : loss : 0.008385, loss_ce: 0.002823
2021-11-30 14:57:02,226 iteration 3977 : loss : 0.005797, loss_ce: 0.002209
2021-11-30 14:57:03,448 iteration 3978 : loss : 0.009484, loss_ce: 0.003412
 58%|████████████████▉            | 234/400 [1:28:37<59:55, 21.66s/it]2021-11-30 14:57:04,740 iteration 3979 : loss : 0.007983, loss_ce: 0.001798
2021-11-30 14:57:05,959 iteration 3980 : loss : 0.007249, loss_ce: 0.002622
2021-11-30 14:57:07,178 iteration 3981 : loss : 0.009101, loss_ce: 0.004060
2021-11-30 14:57:08,403 iteration 3982 : loss : 0.007933, loss_ce: 0.002331
2021-11-30 14:57:09,628 iteration 3983 : loss : 0.008098, loss_ce: 0.002736
2021-11-30 14:57:10,847 iteration 3984 : loss : 0.008049, loss_ce: 0.002607
2021-11-30 14:57:12,068 iteration 3985 : loss : 0.007005, loss_ce: 0.003574
2021-11-30 14:57:13,297 iteration 3986 : loss : 0.007743, loss_ce: 0.002883
2021-11-30 14:57:14,521 iteration 3987 : loss : 0.008408, loss_ce: 0.003382
2021-11-30 14:57:15,734 iteration 3988 : loss : 0.008552, loss_ce: 0.003681
2021-11-30 14:57:16,954 iteration 3989 : loss : 0.006537, loss_ce: 0.002246
2021-11-30 14:57:18,182 iteration 3990 : loss : 0.007415, loss_ce: 0.003413
2021-11-30 14:57:19,401 iteration 3991 : loss : 0.008452, loss_ce: 0.002325
2021-11-30 14:57:20,628 iteration 3992 : loss : 0.010566, loss_ce: 0.004316
2021-11-30 14:57:21,855 iteration 3993 : loss : 0.008080, loss_ce: 0.003091
2021-11-30 14:57:23,083 iteration 3994 : loss : 0.004671, loss_ce: 0.001848
2021-11-30 14:57:23,084 Training Data Eval:
2021-11-30 14:57:29,998   Average segmentation loss on training set: 0.0076
2021-11-30 14:57:29,998 Validation Data Eval:
2021-11-30 14:57:32,382   Average segmentation loss on validation set: 0.1309
2021-11-30 14:57:33,605 iteration 3995 : loss : 0.007869, loss_ce: 0.002268
 59%|███████████████▊           | 235/400 [1:29:07<1:06:34, 24.21s/it]2021-11-30 14:57:34,903 iteration 3996 : loss : 0.009227, loss_ce: 0.003049
2021-11-30 14:57:36,126 iteration 3997 : loss : 0.006880, loss_ce: 0.003320
2021-11-30 14:57:37,348 iteration 3998 : loss : 0.006197, loss_ce: 0.001699
2021-11-30 14:57:38,571 iteration 3999 : loss : 0.007186, loss_ce: 0.002300
2021-11-30 14:57:39,798 iteration 4000 : loss : 0.008000, loss_ce: 0.003500
2021-11-30 14:57:41,021 iteration 4001 : loss : 0.005711, loss_ce: 0.002171
2021-11-30 14:57:42,247 iteration 4002 : loss : 0.006397, loss_ce: 0.002087
2021-11-30 14:57:43,460 iteration 4003 : loss : 0.008707, loss_ce: 0.003595
2021-11-30 14:57:44,682 iteration 4004 : loss : 0.007928, loss_ce: 0.003594
2021-11-30 14:57:45,905 iteration 4005 : loss : 0.007928, loss_ce: 0.002886
2021-11-30 14:57:47,121 iteration 4006 : loss : 0.009950, loss_ce: 0.002931
2021-11-30 14:57:48,343 iteration 4007 : loss : 0.005089, loss_ce: 0.002367
2021-11-30 14:57:49,564 iteration 4008 : loss : 0.006982, loss_ce: 0.002800
2021-11-30 14:57:50,783 iteration 4009 : loss : 0.006813, loss_ce: 0.002335
2021-11-30 14:57:52,014 iteration 4010 : loss : 0.009608, loss_ce: 0.002476
2021-11-30 14:57:53,237 iteration 4011 : loss : 0.007124, loss_ce: 0.002083
2021-11-30 14:57:54,455 iteration 4012 : loss : 0.005907, loss_ce: 0.002403
 59%|███████████████▉           | 236/400 [1:29:28<1:03:24, 23.20s/it]2021-11-30 14:57:55,738 iteration 4013 : loss : 0.006170, loss_ce: 0.002612
2021-11-30 14:57:56,957 iteration 4014 : loss : 0.006615, loss_ce: 0.003214
2021-11-30 14:57:58,177 iteration 4015 : loss : 0.009090, loss_ce: 0.004120
2021-11-30 14:57:59,407 iteration 4016 : loss : 0.007017, loss_ce: 0.002544
2021-11-30 14:58:00,633 iteration 4017 : loss : 0.007644, loss_ce: 0.002438
2021-11-30 14:58:01,853 iteration 4018 : loss : 0.006736, loss_ce: 0.003064
2021-11-30 14:58:03,071 iteration 4019 : loss : 0.007181, loss_ce: 0.002531
2021-11-30 14:58:04,298 iteration 4020 : loss : 0.007836, loss_ce: 0.002360
2021-11-30 14:58:05,527 iteration 4021 : loss : 0.007747, loss_ce: 0.002835
2021-11-30 14:58:06,753 iteration 4022 : loss : 0.008367, loss_ce: 0.002940
2021-11-30 14:58:07,973 iteration 4023 : loss : 0.007212, loss_ce: 0.003085
2021-11-30 14:58:09,203 iteration 4024 : loss : 0.007715, loss_ce: 0.002292
2021-11-30 14:58:10,428 iteration 4025 : loss : 0.005843, loss_ce: 0.002076
2021-11-30 14:58:11,652 iteration 4026 : loss : 0.007066, loss_ce: 0.002008
2021-11-30 14:58:12,869 iteration 4027 : loss : 0.005506, loss_ce: 0.002470
2021-11-30 14:58:14,096 iteration 4028 : loss : 0.007180, loss_ce: 0.002367
2021-11-30 14:58:15,316 iteration 4029 : loss : 0.007324, loss_ce: 0.002928
 59%|███████████████▉           | 237/400 [1:29:49<1:01:07, 22.50s/it]2021-11-30 14:58:16,612 iteration 4030 : loss : 0.005817, loss_ce: 0.002084
2021-11-30 14:58:17,837 iteration 4031 : loss : 0.007420, loss_ce: 0.002652
2021-11-30 14:58:19,058 iteration 4032 : loss : 0.006962, loss_ce: 0.001806
2021-11-30 14:58:20,274 iteration 4033 : loss : 0.006546, loss_ce: 0.002340
2021-11-30 14:58:21,499 iteration 4034 : loss : 0.006438, loss_ce: 0.001698
2021-11-30 14:58:22,726 iteration 4035 : loss : 0.006201, loss_ce: 0.002723
2021-11-30 14:58:23,941 iteration 4036 : loss : 0.006302, loss_ce: 0.002966
2021-11-30 14:58:25,159 iteration 4037 : loss : 0.007113, loss_ce: 0.002636
2021-11-30 14:58:26,371 iteration 4038 : loss : 0.009622, loss_ce: 0.002831
2021-11-30 14:58:27,592 iteration 4039 : loss : 0.006286, loss_ce: 0.002506
2021-11-30 14:58:28,820 iteration 4040 : loss : 0.005729, loss_ce: 0.002696
2021-11-30 14:58:30,046 iteration 4041 : loss : 0.009262, loss_ce: 0.004273
2021-11-30 14:58:31,257 iteration 4042 : loss : 0.007273, loss_ce: 0.002454
2021-11-30 14:58:32,483 iteration 4043 : loss : 0.007672, loss_ce: 0.003282
2021-11-30 14:58:33,711 iteration 4044 : loss : 0.008945, loss_ce: 0.002490
2021-11-30 14:58:34,938 iteration 4045 : loss : 0.006499, loss_ce: 0.002802
2021-11-30 14:58:36,165 iteration 4046 : loss : 0.005672, loss_ce: 0.001686
 60%|█████████████████▎           | 238/400 [1:30:10<59:24, 22.00s/it]2021-11-30 14:58:37,455 iteration 4047 : loss : 0.009727, loss_ce: 0.004077
2021-11-30 14:58:38,689 iteration 4048 : loss : 0.006563, loss_ce: 0.002520
2021-11-30 14:58:39,914 iteration 4049 : loss : 0.005546, loss_ce: 0.001657
2021-11-30 14:58:41,138 iteration 4050 : loss : 0.006905, loss_ce: 0.002863
2021-11-30 14:58:42,362 iteration 4051 : loss : 0.006695, loss_ce: 0.002574
2021-11-30 14:58:43,584 iteration 4052 : loss : 0.008619, loss_ce: 0.003413
2021-11-30 14:58:44,814 iteration 4053 : loss : 0.006809, loss_ce: 0.002851
2021-11-30 14:58:46,042 iteration 4054 : loss : 0.006052, loss_ce: 0.001979
2021-11-30 14:58:47,263 iteration 4055 : loss : 0.007355, loss_ce: 0.003236
2021-11-30 14:58:48,482 iteration 4056 : loss : 0.007263, loss_ce: 0.002322
2021-11-30 14:58:49,708 iteration 4057 : loss : 0.007431, loss_ce: 0.003004
2021-11-30 14:58:50,926 iteration 4058 : loss : 0.007324, loss_ce: 0.002098
2021-11-30 14:58:52,149 iteration 4059 : loss : 0.007390, loss_ce: 0.001557
2021-11-30 14:58:53,371 iteration 4060 : loss : 0.005833, loss_ce: 0.002249
2021-11-30 14:58:54,589 iteration 4061 : loss : 0.007461, loss_ce: 0.002971
2021-11-30 14:58:55,817 iteration 4062 : loss : 0.007995, loss_ce: 0.003793
2021-11-30 14:58:57,043 iteration 4063 : loss : 0.008148, loss_ce: 0.003031
 60%|█████████████████▎           | 239/400 [1:30:31<58:08, 21.67s/it]2021-11-30 14:58:58,335 iteration 4064 : loss : 0.007829, loss_ce: 0.003034
2021-11-30 14:58:59,560 iteration 4065 : loss : 0.007590, loss_ce: 0.003671
2021-11-30 14:59:00,782 iteration 4066 : loss : 0.007495, loss_ce: 0.002452
2021-11-30 14:59:02,014 iteration 4067 : loss : 0.006610, loss_ce: 0.002913
2021-11-30 14:59:03,245 iteration 4068 : loss : 0.007206, loss_ce: 0.002338
2021-11-30 14:59:04,472 iteration 4069 : loss : 0.005827, loss_ce: 0.001101
2021-11-30 14:59:05,696 iteration 4070 : loss : 0.008442, loss_ce: 0.003842
2021-11-30 14:59:06,923 iteration 4071 : loss : 0.008034, loss_ce: 0.003293
2021-11-30 14:59:08,147 iteration 4072 : loss : 0.007118, loss_ce: 0.003390
2021-11-30 14:59:09,370 iteration 4073 : loss : 0.007072, loss_ce: 0.002194
2021-11-30 14:59:10,591 iteration 4074 : loss : 0.010919, loss_ce: 0.002908
2021-11-30 14:59:11,818 iteration 4075 : loss : 0.008056, loss_ce: 0.003573
2021-11-30 14:59:13,049 iteration 4076 : loss : 0.006223, loss_ce: 0.002331
2021-11-30 14:59:14,274 iteration 4077 : loss : 0.007903, loss_ce: 0.003388
2021-11-30 14:59:15,500 iteration 4078 : loss : 0.006502, loss_ce: 0.002897
2021-11-30 14:59:16,719 iteration 4079 : loss : 0.007794, loss_ce: 0.002232
2021-11-30 14:59:16,719 Training Data Eval:
2021-11-30 14:59:23,668   Average segmentation loss on training set: 0.0081
2021-11-30 14:59:23,668 Validation Data Eval:
2021-11-30 14:59:26,045   Average segmentation loss on validation set: 0.1566
2021-11-30 14:59:27,279 iteration 4080 : loss : 0.007578, loss_ce: 0.003772
 60%|████████████████▏          | 240/400 [1:31:01<1:04:37, 24.24s/it]2021-11-30 14:59:28,563 iteration 4081 : loss : 0.009350, loss_ce: 0.004012
2021-11-30 14:59:29,789 iteration 4082 : loss : 0.005435, loss_ce: 0.002347
2021-11-30 14:59:31,018 iteration 4083 : loss : 0.006599, loss_ce: 0.002408
2021-11-30 14:59:32,242 iteration 4084 : loss : 0.006412, loss_ce: 0.002399
2021-11-30 14:59:33,464 iteration 4085 : loss : 0.008753, loss_ce: 0.003281
2021-11-30 14:59:34,691 iteration 4086 : loss : 0.007984, loss_ce: 0.003531
2021-11-30 14:59:35,918 iteration 4087 : loss : 0.006427, loss_ce: 0.002482
2021-11-30 14:59:37,143 iteration 4088 : loss : 0.006664, loss_ce: 0.002661
2021-11-30 14:59:38,370 iteration 4089 : loss : 0.005491, loss_ce: 0.002322
2021-11-30 14:59:39,586 iteration 4090 : loss : 0.010242, loss_ce: 0.003575
2021-11-30 14:59:40,811 iteration 4091 : loss : 0.006811, loss_ce: 0.002450
2021-11-30 14:59:42,035 iteration 4092 : loss : 0.006523, loss_ce: 0.002090
2021-11-30 14:59:43,263 iteration 4093 : loss : 0.007463, loss_ce: 0.003324
2021-11-30 14:59:44,490 iteration 4094 : loss : 0.005971, loss_ce: 0.002780
2021-11-30 14:59:45,716 iteration 4095 : loss : 0.006108, loss_ce: 0.001996
2021-11-30 14:59:46,938 iteration 4096 : loss : 0.007944, loss_ce: 0.003516
2021-11-30 14:59:48,165 iteration 4097 : loss : 0.006921, loss_ce: 0.002250
 60%|████████████████▎          | 241/400 [1:31:22<1:01:33, 23.23s/it]2021-11-30 14:59:49,455 iteration 4098 : loss : 0.006116, loss_ce: 0.002608
2021-11-30 14:59:50,679 iteration 4099 : loss : 0.007926, loss_ce: 0.002467
2021-11-30 14:59:51,902 iteration 4100 : loss : 0.005482, loss_ce: 0.001595
2021-11-30 14:59:53,132 iteration 4101 : loss : 0.006527, loss_ce: 0.002382
2021-11-30 14:59:54,356 iteration 4102 : loss : 0.005833, loss_ce: 0.002566
2021-11-30 14:59:55,573 iteration 4103 : loss : 0.007218, loss_ce: 0.002421
2021-11-30 14:59:56,794 iteration 4104 : loss : 0.006662, loss_ce: 0.003291
2021-11-30 14:59:58,016 iteration 4105 : loss : 0.006301, loss_ce: 0.002218
2021-11-30 14:59:59,234 iteration 4106 : loss : 0.006741, loss_ce: 0.003131
2021-11-30 15:00:00,456 iteration 4107 : loss : 0.006461, loss_ce: 0.002013
2021-11-30 15:00:01,680 iteration 4108 : loss : 0.006718, loss_ce: 0.002784
2021-11-30 15:00:02,897 iteration 4109 : loss : 0.007850, loss_ce: 0.003123
2021-11-30 15:00:04,115 iteration 4110 : loss : 0.007827, loss_ce: 0.002698
2021-11-30 15:00:05,338 iteration 4111 : loss : 0.008711, loss_ce: 0.002164
2021-11-30 15:00:06,562 iteration 4112 : loss : 0.006219, loss_ce: 0.002795
2021-11-30 15:00:07,779 iteration 4113 : loss : 0.005492, loss_ce: 0.001843
2021-11-30 15:00:09,000 iteration 4114 : loss : 0.006429, loss_ce: 0.002497
 60%|█████████████████▌           | 242/400 [1:31:43<59:17, 22.51s/it]2021-11-30 15:00:10,287 iteration 4115 : loss : 0.007580, loss_ce: 0.003175
2021-11-30 15:00:11,499 iteration 4116 : loss : 0.006667, loss_ce: 0.002260
2021-11-30 15:00:12,725 iteration 4117 : loss : 0.006701, loss_ce: 0.002001
2021-11-30 15:00:13,943 iteration 4118 : loss : 0.007420, loss_ce: 0.002443
2021-11-30 15:00:15,167 iteration 4119 : loss : 0.007116, loss_ce: 0.002546
2021-11-30 15:00:16,383 iteration 4120 : loss : 0.005424, loss_ce: 0.001751
2021-11-30 15:00:17,609 iteration 4121 : loss : 0.007878, loss_ce: 0.003538
2021-11-30 15:00:18,834 iteration 4122 : loss : 0.006428, loss_ce: 0.003070
2021-11-30 15:00:20,055 iteration 4123 : loss : 0.006793, loss_ce: 0.002425
2021-11-30 15:00:21,281 iteration 4124 : loss : 0.006312, loss_ce: 0.001831
2021-11-30 15:00:22,501 iteration 4125 : loss : 0.006301, loss_ce: 0.002375
2021-11-30 15:00:23,728 iteration 4126 : loss : 0.007012, loss_ce: 0.002823
2021-11-30 15:00:24,954 iteration 4127 : loss : 0.005993, loss_ce: 0.002906
2021-11-30 15:00:26,180 iteration 4128 : loss : 0.006050, loss_ce: 0.002805
2021-11-30 15:00:27,406 iteration 4129 : loss : 0.008100, loss_ce: 0.002555
2021-11-30 15:00:28,625 iteration 4130 : loss : 0.005446, loss_ce: 0.002009
2021-11-30 15:00:29,851 iteration 4131 : loss : 0.007025, loss_ce: 0.002188
 61%|█████████████████▌           | 243/400 [1:32:03<57:36, 22.01s/it]2021-11-30 15:00:31,133 iteration 4132 : loss : 0.006783, loss_ce: 0.003340
2021-11-30 15:00:32,359 iteration 4133 : loss : 0.007943, loss_ce: 0.003199
2021-11-30 15:00:33,581 iteration 4134 : loss : 0.006678, loss_ce: 0.002885
2021-11-30 15:00:34,801 iteration 4135 : loss : 0.006614, loss_ce: 0.002422
2021-11-30 15:00:36,024 iteration 4136 : loss : 0.007375, loss_ce: 0.003424
2021-11-30 15:00:37,246 iteration 4137 : loss : 0.006566, loss_ce: 0.001548
2021-11-30 15:00:38,473 iteration 4138 : loss : 0.006180, loss_ce: 0.002142
2021-11-30 15:00:39,697 iteration 4139 : loss : 0.007773, loss_ce: 0.002875
2021-11-30 15:00:40,915 iteration 4140 : loss : 0.005450, loss_ce: 0.002107
2021-11-30 15:00:42,142 iteration 4141 : loss : 0.007937, loss_ce: 0.002157
2021-11-30 15:00:43,363 iteration 4142 : loss : 0.007493, loss_ce: 0.002785
2021-11-30 15:00:44,591 iteration 4143 : loss : 0.006935, loss_ce: 0.002179
2021-11-30 15:00:45,816 iteration 4144 : loss : 0.007403, loss_ce: 0.003085
2021-11-30 15:00:47,046 iteration 4145 : loss : 0.006007, loss_ce: 0.002572
2021-11-30 15:00:48,266 iteration 4146 : loss : 0.006229, loss_ce: 0.002664
2021-11-30 15:00:49,488 iteration 4147 : loss : 0.006601, loss_ce: 0.002728
2021-11-30 15:00:50,716 iteration 4148 : loss : 0.008720, loss_ce: 0.002071
 61%|█████████████████▋           | 244/400 [1:32:24<56:20, 21.67s/it]2021-11-30 15:00:52,003 iteration 4149 : loss : 0.006599, loss_ce: 0.002414
2021-11-30 15:00:53,233 iteration 4150 : loss : 0.005702, loss_ce: 0.002365
2021-11-30 15:00:54,456 iteration 4151 : loss : 0.007052, loss_ce: 0.002667
2021-11-30 15:00:55,678 iteration 4152 : loss : 0.005678, loss_ce: 0.002000
2021-11-30 15:00:56,901 iteration 4153 : loss : 0.006477, loss_ce: 0.002436
2021-11-30 15:00:58,116 iteration 4154 : loss : 0.006955, loss_ce: 0.002130
2021-11-30 15:00:59,344 iteration 4155 : loss : 0.006425, loss_ce: 0.002423
2021-11-30 15:01:00,563 iteration 4156 : loss : 0.007397, loss_ce: 0.002335
2021-11-30 15:01:01,772 iteration 4157 : loss : 0.005369, loss_ce: 0.002089
2021-11-30 15:01:02,995 iteration 4158 : loss : 0.007108, loss_ce: 0.003220
2021-11-30 15:01:04,216 iteration 4159 : loss : 0.007934, loss_ce: 0.003540
2021-11-30 15:01:05,443 iteration 4160 : loss : 0.006636, loss_ce: 0.002514
2021-11-30 15:01:06,672 iteration 4161 : loss : 0.005997, loss_ce: 0.001984
2021-11-30 15:01:07,892 iteration 4162 : loss : 0.006550, loss_ce: 0.002434
2021-11-30 15:01:09,105 iteration 4163 : loss : 0.009228, loss_ce: 0.004081
2021-11-30 15:01:10,332 iteration 4164 : loss : 0.009191, loss_ce: 0.003343
2021-11-30 15:01:10,332 Training Data Eval:
2021-11-30 15:01:17,250   Average segmentation loss on training set: 0.0062
2021-11-30 15:01:17,250 Validation Data Eval:
2021-11-30 15:01:19,625   Average segmentation loss on validation set: 0.1434
2021-11-30 15:01:20,854 iteration 4165 : loss : 0.006329, loss_ce: 0.002231
 61%|████████████████▌          | 245/400 [1:32:54<1:02:32, 24.21s/it]2021-11-30 15:01:22,147 iteration 4166 : loss : 0.005645, loss_ce: 0.002327
2021-11-30 15:01:23,375 iteration 4167 : loss : 0.007721, loss_ce: 0.002128
2021-11-30 15:01:24,594 iteration 4168 : loss : 0.007911, loss_ce: 0.002910
2021-11-30 15:01:25,811 iteration 4169 : loss : 0.006065, loss_ce: 0.002728
2021-11-30 15:01:27,032 iteration 4170 : loss : 0.007025, loss_ce: 0.003305
2021-11-30 15:01:28,256 iteration 4171 : loss : 0.008186, loss_ce: 0.002513
2021-11-30 15:01:29,482 iteration 4172 : loss : 0.007938, loss_ce: 0.003752
2021-11-30 15:01:30,702 iteration 4173 : loss : 0.007527, loss_ce: 0.002550
2021-11-30 15:01:31,922 iteration 4174 : loss : 0.006855, loss_ce: 0.002192
2021-11-30 15:01:33,148 iteration 4175 : loss : 0.008384, loss_ce: 0.002431
2021-11-30 15:01:34,366 iteration 4176 : loss : 0.006802, loss_ce: 0.002517
2021-11-30 15:01:35,584 iteration 4177 : loss : 0.007402, loss_ce: 0.002441
2021-11-30 15:01:36,802 iteration 4178 : loss : 0.006742, loss_ce: 0.002654
2021-11-30 15:01:38,024 iteration 4179 : loss : 0.006819, loss_ce: 0.002761
2021-11-30 15:01:39,242 iteration 4180 : loss : 0.007837, loss_ce: 0.002314
2021-11-30 15:01:40,453 iteration 4181 : loss : 0.006499, loss_ce: 0.002360
2021-11-30 15:01:41,676 iteration 4182 : loss : 0.008059, loss_ce: 0.003807
 62%|█████████████████▊           | 246/400 [1:33:15<59:31, 23.19s/it]2021-11-30 15:01:42,961 iteration 4183 : loss : 0.005470, loss_ce: 0.002151
2021-11-30 15:01:44,182 iteration 4184 : loss : 0.007287, loss_ce: 0.002649
2021-11-30 15:01:45,404 iteration 4185 : loss : 0.005683, loss_ce: 0.002392
2021-11-30 15:01:46,616 iteration 4186 : loss : 0.007850, loss_ce: 0.004483
2021-11-30 15:01:47,839 iteration 4187 : loss : 0.006173, loss_ce: 0.002004
2021-11-30 15:01:49,067 iteration 4188 : loss : 0.006283, loss_ce: 0.002271
2021-11-30 15:01:50,291 iteration 4189 : loss : 0.007024, loss_ce: 0.002533
2021-11-30 15:01:51,507 iteration 4190 : loss : 0.005692, loss_ce: 0.001961
2021-11-30 15:01:52,726 iteration 4191 : loss : 0.006537, loss_ce: 0.001561
2021-11-30 15:01:53,944 iteration 4192 : loss : 0.010450, loss_ce: 0.004520
2021-11-30 15:01:55,164 iteration 4193 : loss : 0.006688, loss_ce: 0.002196
2021-11-30 15:01:56,395 iteration 4194 : loss : 0.007634, loss_ce: 0.003267
2021-11-30 15:01:57,613 iteration 4195 : loss : 0.007043, loss_ce: 0.003238
2021-11-30 15:01:58,832 iteration 4196 : loss : 0.007306, loss_ce: 0.002524
2021-11-30 15:02:00,059 iteration 4197 : loss : 0.007107, loss_ce: 0.002435
2021-11-30 15:02:01,282 iteration 4198 : loss : 0.007275, loss_ce: 0.002784
2021-11-30 15:02:02,495 iteration 4199 : loss : 0.008017, loss_ce: 0.002815
 62%|█████████████████▉           | 247/400 [1:33:36<57:19, 22.48s/it]2021-11-30 15:02:03,791 iteration 4200 : loss : 0.006271, loss_ce: 0.002666
2021-11-30 15:02:05,008 iteration 4201 : loss : 0.007183, loss_ce: 0.003630
2021-11-30 15:02:06,228 iteration 4202 : loss : 0.008210, loss_ce: 0.003041
2021-11-30 15:02:07,456 iteration 4203 : loss : 0.008700, loss_ce: 0.002583
2021-11-30 15:02:08,689 iteration 4204 : loss : 0.006147, loss_ce: 0.002076
2021-11-30 15:02:09,910 iteration 4205 : loss : 0.007313, loss_ce: 0.002971
2021-11-30 15:02:11,134 iteration 4206 : loss : 0.008504, loss_ce: 0.003537
2021-11-30 15:02:12,351 iteration 4207 : loss : 0.006641, loss_ce: 0.002617
2021-11-30 15:02:13,578 iteration 4208 : loss : 0.007581, loss_ce: 0.002671
2021-11-30 15:02:14,805 iteration 4209 : loss : 0.006861, loss_ce: 0.002375
2021-11-30 15:02:16,025 iteration 4210 : loss : 0.006073, loss_ce: 0.002317
2021-11-30 15:02:17,248 iteration 4211 : loss : 0.007337, loss_ce: 0.002077
2021-11-30 15:02:18,477 iteration 4212 : loss : 0.006211, loss_ce: 0.002342
2021-11-30 15:02:19,696 iteration 4213 : loss : 0.006573, loss_ce: 0.002245
2021-11-30 15:02:20,914 iteration 4214 : loss : 0.006739, loss_ce: 0.003235
2021-11-30 15:02:22,131 iteration 4215 : loss : 0.006870, loss_ce: 0.002507
2021-11-30 15:02:23,358 iteration 4216 : loss : 0.005157, loss_ce: 0.001876
 62%|█████████████████▉           | 248/400 [1:33:57<55:43, 21.99s/it]2021-11-30 15:02:24,654 iteration 4217 : loss : 0.007113, loss_ce: 0.003226
2021-11-30 15:02:25,874 iteration 4218 : loss : 0.007368, loss_ce: 0.002642
2021-11-30 15:02:27,096 iteration 4219 : loss : 0.006186, loss_ce: 0.002263
2021-11-30 15:02:28,322 iteration 4220 : loss : 0.005961, loss_ce: 0.002639
2021-11-30 15:02:29,546 iteration 4221 : loss : 0.007290, loss_ce: 0.003035
2021-11-30 15:02:30,768 iteration 4222 : loss : 0.006611, loss_ce: 0.002711
2021-11-30 15:02:31,992 iteration 4223 : loss : 0.006022, loss_ce: 0.002393
2021-11-30 15:02:33,216 iteration 4224 : loss : 0.007006, loss_ce: 0.002681
2021-11-30 15:02:34,433 iteration 4225 : loss : 0.005465, loss_ce: 0.002402
2021-11-30 15:02:35,667 iteration 4226 : loss : 0.005203, loss_ce: 0.002055
2021-11-30 15:02:36,889 iteration 4227 : loss : 0.005631, loss_ce: 0.001992
2021-11-30 15:02:38,110 iteration 4228 : loss : 0.007768, loss_ce: 0.002234
2021-11-30 15:02:39,323 iteration 4229 : loss : 0.006698, loss_ce: 0.003653
2021-11-30 15:02:40,538 iteration 4230 : loss : 0.006659, loss_ce: 0.001625
2021-11-30 15:02:41,763 iteration 4231 : loss : 0.006252, loss_ce: 0.001654
2021-11-30 15:02:42,992 iteration 4232 : loss : 0.007524, loss_ce: 0.002729
2021-11-30 15:02:44,217 iteration 4233 : loss : 0.006024, loss_ce: 0.002276
 62%|██████████████████           | 249/400 [1:34:18<54:30, 21.66s/it]2021-11-30 15:02:45,507 iteration 4234 : loss : 0.005111, loss_ce: 0.001773
2021-11-30 15:02:46,729 iteration 4235 : loss : 0.007282, loss_ce: 0.002571
2021-11-30 15:02:47,954 iteration 4236 : loss : 0.007104, loss_ce: 0.003048
2021-11-30 15:02:49,176 iteration 4237 : loss : 0.007062, loss_ce: 0.002048
2021-11-30 15:02:50,397 iteration 4238 : loss : 0.006316, loss_ce: 0.002366
2021-11-30 15:02:51,614 iteration 4239 : loss : 0.007186, loss_ce: 0.002100
2021-11-30 15:02:52,835 iteration 4240 : loss : 0.006511, loss_ce: 0.002977
2021-11-30 15:02:54,064 iteration 4241 : loss : 0.005766, loss_ce: 0.002462
2021-11-30 15:02:55,286 iteration 4242 : loss : 0.005617, loss_ce: 0.001955
2021-11-30 15:02:56,508 iteration 4243 : loss : 0.009413, loss_ce: 0.003875
2021-11-30 15:02:57,738 iteration 4244 : loss : 0.006596, loss_ce: 0.002441
2021-11-30 15:02:58,959 iteration 4245 : loss : 0.006704, loss_ce: 0.003021
2021-11-30 15:03:00,180 iteration 4246 : loss : 0.005671, loss_ce: 0.001562
2021-11-30 15:03:01,404 iteration 4247 : loss : 0.005595, loss_ce: 0.001936
2021-11-30 15:03:02,629 iteration 4248 : loss : 0.006218, loss_ce: 0.002581
2021-11-30 15:03:03,854 iteration 4249 : loss : 0.006193, loss_ce: 0.002816
2021-11-30 15:03:03,855 Training Data Eval:
2021-11-30 15:03:10,766   Average segmentation loss on training set: 0.0059
2021-11-30 15:03:10,767 Validation Data Eval:
2021-11-30 15:03:13,152   Average segmentation loss on validation set: 0.1261
2021-11-30 15:03:14,376 iteration 4250 : loss : 0.005818, loss_ce: 0.002496
 62%|████████████████▉          | 250/400 [1:34:48<1:00:31, 24.21s/it]2021-11-30 15:03:15,666 iteration 4251 : loss : 0.005612, loss_ce: 0.002335
2021-11-30 15:03:16,888 iteration 4252 : loss : 0.006300, loss_ce: 0.001697
2021-11-30 15:03:18,115 iteration 4253 : loss : 0.006512, loss_ce: 0.002676
2021-11-30 15:03:19,335 iteration 4254 : loss : 0.005520, loss_ce: 0.002455
2021-11-30 15:03:20,557 iteration 4255 : loss : 0.008987, loss_ce: 0.004100
2021-11-30 15:03:21,780 iteration 4256 : loss : 0.006259, loss_ce: 0.002126
2021-11-30 15:03:22,992 iteration 4257 : loss : 0.010179, loss_ce: 0.003175
2021-11-30 15:03:24,213 iteration 4258 : loss : 0.006950, loss_ce: 0.002918
2021-11-30 15:03:25,431 iteration 4259 : loss : 0.005604, loss_ce: 0.001980
2021-11-30 15:03:26,654 iteration 4260 : loss : 0.008140, loss_ce: 0.002952
2021-11-30 15:03:27,869 iteration 4261 : loss : 0.006628, loss_ce: 0.002215
2021-11-30 15:03:29,101 iteration 4262 : loss : 0.006463, loss_ce: 0.002582
2021-11-30 15:03:30,323 iteration 4263 : loss : 0.005946, loss_ce: 0.002095
2021-11-30 15:03:31,544 iteration 4264 : loss : 0.006114, loss_ce: 0.002655
2021-11-30 15:03:32,767 iteration 4265 : loss : 0.006248, loss_ce: 0.001848
2021-11-30 15:03:33,995 iteration 4266 : loss : 0.008333, loss_ce: 0.002811
2021-11-30 15:03:35,215 iteration 4267 : loss : 0.006895, loss_ce: 0.002512
 63%|██████████████████▏          | 251/400 [1:35:09<57:36, 23.20s/it]2021-11-30 15:03:36,512 iteration 4268 : loss : 0.005708, loss_ce: 0.002240
2021-11-30 15:03:37,731 iteration 4269 : loss : 0.008253, loss_ce: 0.002274
2021-11-30 15:03:38,953 iteration 4270 : loss : 0.006895, loss_ce: 0.002957
2021-11-30 15:03:40,180 iteration 4271 : loss : 0.005967, loss_ce: 0.002048
2021-11-30 15:03:41,401 iteration 4272 : loss : 0.008536, loss_ce: 0.003860
2021-11-30 15:03:42,626 iteration 4273 : loss : 0.011712, loss_ce: 0.002241
2021-11-30 15:03:43,849 iteration 4274 : loss : 0.006356, loss_ce: 0.002734
2021-11-30 15:03:45,068 iteration 4275 : loss : 0.007684, loss_ce: 0.002921
2021-11-30 15:03:46,279 iteration 4276 : loss : 0.007581, loss_ce: 0.003243
2021-11-30 15:03:47,501 iteration 4277 : loss : 0.008719, loss_ce: 0.002995
2021-11-30 15:03:48,724 iteration 4278 : loss : 0.008230, loss_ce: 0.003651
2021-11-30 15:03:49,943 iteration 4279 : loss : 0.007137, loss_ce: 0.002683
2021-11-30 15:03:51,163 iteration 4280 : loss : 0.008158, loss_ce: 0.003182
2021-11-30 15:03:52,387 iteration 4281 : loss : 0.006172, loss_ce: 0.002499
2021-11-30 15:03:53,608 iteration 4282 : loss : 0.008314, loss_ce: 0.001978
2021-11-30 15:03:54,834 iteration 4283 : loss : 0.008141, loss_ce: 0.002872
2021-11-30 15:03:56,061 iteration 4284 : loss : 0.006673, loss_ce: 0.002828
 63%|██████████████████▎          | 252/400 [1:35:30<55:28, 22.49s/it]2021-11-30 15:03:57,354 iteration 4285 : loss : 0.008238, loss_ce: 0.004121
2021-11-30 15:03:58,579 iteration 4286 : loss : 0.007348, loss_ce: 0.003398
2021-11-30 15:03:59,805 iteration 4287 : loss : 0.005962, loss_ce: 0.002608
2021-11-30 15:04:01,023 iteration 4288 : loss : 0.006317, loss_ce: 0.002446
2021-11-30 15:04:02,247 iteration 4289 : loss : 0.006957, loss_ce: 0.002873
2021-11-30 15:04:03,476 iteration 4290 : loss : 0.007510, loss_ce: 0.003370
2021-11-30 15:04:04,699 iteration 4291 : loss : 0.007258, loss_ce: 0.002145
2021-11-30 15:04:05,921 iteration 4292 : loss : 0.009242, loss_ce: 0.002036
2021-11-30 15:04:07,141 iteration 4293 : loss : 0.005923, loss_ce: 0.002271
2021-11-30 15:04:08,359 iteration 4294 : loss : 0.007284, loss_ce: 0.002868
2021-11-30 15:04:09,587 iteration 4295 : loss : 0.007483, loss_ce: 0.002869
2021-11-30 15:04:10,812 iteration 4296 : loss : 0.005847, loss_ce: 0.002371
2021-11-30 15:04:12,039 iteration 4297 : loss : 0.006048, loss_ce: 0.002428
2021-11-30 15:04:13,261 iteration 4298 : loss : 0.006501, loss_ce: 0.002587
2021-11-30 15:04:14,485 iteration 4299 : loss : 0.005667, loss_ce: 0.001671
2021-11-30 15:04:15,717 iteration 4300 : loss : 0.005699, loss_ce: 0.001804
2021-11-30 15:04:16,934 iteration 4301 : loss : 0.007131, loss_ce: 0.002638
 63%|██████████████████▎          | 253/400 [1:35:51<53:54, 22.01s/it]2021-11-30 15:04:18,237 iteration 4302 : loss : 0.005880, loss_ce: 0.002023
2021-11-30 15:04:19,462 iteration 4303 : loss : 0.005402, loss_ce: 0.001973
2021-11-30 15:04:20,687 iteration 4304 : loss : 0.007072, loss_ce: 0.003016
2021-11-30 15:04:21,909 iteration 4305 : loss : 0.006781, loss_ce: 0.002519
2021-11-30 15:04:23,128 iteration 4306 : loss : 0.006531, loss_ce: 0.002812
2021-11-30 15:04:24,348 iteration 4307 : loss : 0.005909, loss_ce: 0.001854
2021-11-30 15:04:25,574 iteration 4308 : loss : 0.007858, loss_ce: 0.002724
2021-11-30 15:04:26,798 iteration 4309 : loss : 0.006160, loss_ce: 0.002080
2021-11-30 15:04:28,022 iteration 4310 : loss : 0.007392, loss_ce: 0.003087
2021-11-30 15:04:29,245 iteration 4311 : loss : 0.006788, loss_ce: 0.002205
2021-11-30 15:04:30,474 iteration 4312 : loss : 0.007723, loss_ce: 0.002579
2021-11-30 15:04:31,694 iteration 4313 : loss : 0.006095, loss_ce: 0.001402
2021-11-30 15:04:32,921 iteration 4314 : loss : 0.007054, loss_ce: 0.002966
2021-11-30 15:04:34,142 iteration 4315 : loss : 0.007025, loss_ce: 0.003072
2021-11-30 15:04:35,364 iteration 4316 : loss : 0.004979, loss_ce: 0.001890
2021-11-30 15:04:36,594 iteration 4317 : loss : 0.009013, loss_ce: 0.003685
2021-11-30 15:04:37,821 iteration 4318 : loss : 0.006567, loss_ce: 0.003005
 64%|██████████████████▍          | 254/400 [1:36:11<52:43, 21.67s/it]2021-11-30 15:04:39,112 iteration 4319 : loss : 0.006033, loss_ce: 0.002549
2021-11-30 15:04:40,333 iteration 4320 : loss : 0.006179, loss_ce: 0.002212
2021-11-30 15:04:41,550 iteration 4321 : loss : 0.005768, loss_ce: 0.001766
2021-11-30 15:04:42,768 iteration 4322 : loss : 0.006181, loss_ce: 0.002312
2021-11-30 15:04:43,992 iteration 4323 : loss : 0.005462, loss_ce: 0.002118
2021-11-30 15:04:45,211 iteration 4324 : loss : 0.005642, loss_ce: 0.001897
2021-11-30 15:04:46,436 iteration 4325 : loss : 0.005595, loss_ce: 0.002625
2021-11-30 15:04:47,662 iteration 4326 : loss : 0.005638, loss_ce: 0.002254
2021-11-30 15:04:48,890 iteration 4327 : loss : 0.006746, loss_ce: 0.002664
2021-11-30 15:04:50,113 iteration 4328 : loss : 0.005678, loss_ce: 0.002345
2021-11-30 15:04:51,334 iteration 4329 : loss : 0.006798, loss_ce: 0.002762
2021-11-30 15:04:52,559 iteration 4330 : loss : 0.006579, loss_ce: 0.003420
2021-11-30 15:04:53,783 iteration 4331 : loss : 0.005470, loss_ce: 0.001628
2021-11-30 15:04:55,001 iteration 4332 : loss : 0.007244, loss_ce: 0.002813
2021-11-30 15:04:56,222 iteration 4333 : loss : 0.005074, loss_ce: 0.001470
2021-11-30 15:04:57,443 iteration 4334 : loss : 0.005773, loss_ce: 0.002412
2021-11-30 15:04:57,444 Training Data Eval:
2021-11-30 15:05:04,349   Average segmentation loss on training set: 0.0064
2021-11-30 15:05:04,349 Validation Data Eval:
2021-11-30 15:05:06,722   Average segmentation loss on validation set: 0.1307
2021-11-30 15:05:07,941 iteration 4335 : loss : 0.007065, loss_ce: 0.003319
 64%|██████████████████▍          | 255/400 [1:36:42<58:29, 24.21s/it]2021-11-30 15:05:09,229 iteration 4336 : loss : 0.006045, loss_ce: 0.002301
2021-11-30 15:05:10,446 iteration 4337 : loss : 0.007032, loss_ce: 0.003967
2021-11-30 15:05:11,660 iteration 4338 : loss : 0.005163, loss_ce: 0.001559
2021-11-30 15:05:12,874 iteration 4339 : loss : 0.005684, loss_ce: 0.001859
2021-11-30 15:05:14,097 iteration 4340 : loss : 0.006050, loss_ce: 0.002396
2021-11-30 15:05:15,322 iteration 4341 : loss : 0.005309, loss_ce: 0.002013
2021-11-30 15:05:16,545 iteration 4342 : loss : 0.005460, loss_ce: 0.002223
2021-11-30 15:05:17,760 iteration 4343 : loss : 0.005573, loss_ce: 0.001865
2021-11-30 15:05:18,984 iteration 4344 : loss : 0.004322, loss_ce: 0.001513
2021-11-30 15:05:20,204 iteration 4345 : loss : 0.005706, loss_ce: 0.001779
2021-11-30 15:05:21,427 iteration 4346 : loss : 0.006477, loss_ce: 0.003351
2021-11-30 15:05:22,647 iteration 4347 : loss : 0.005155, loss_ce: 0.002097
2021-11-30 15:05:23,864 iteration 4348 : loss : 0.004958, loss_ce: 0.001874
2021-11-30 15:05:25,090 iteration 4349 : loss : 0.009068, loss_ce: 0.002716
2021-11-30 15:05:26,306 iteration 4350 : loss : 0.005230, loss_ce: 0.001934
2021-11-30 15:05:27,532 iteration 4351 : loss : 0.004938, loss_ce: 0.001944
2021-11-30 15:05:28,755 iteration 4352 : loss : 0.006781, loss_ce: 0.002721
 64%|██████████████████▌          | 256/400 [1:37:02<55:38, 23.19s/it]2021-11-30 15:05:30,032 iteration 4353 : loss : 0.006288, loss_ce: 0.002224
2021-11-30 15:05:31,255 iteration 4354 : loss : 0.006154, loss_ce: 0.002263
2021-11-30 15:05:32,476 iteration 4355 : loss : 0.005564, loss_ce: 0.002568
2021-11-30 15:05:33,704 iteration 4356 : loss : 0.005627, loss_ce: 0.002446
2021-11-30 15:05:34,925 iteration 4357 : loss : 0.006447, loss_ce: 0.002474
2021-11-30 15:05:36,140 iteration 4358 : loss : 0.005251, loss_ce: 0.002242
2021-11-30 15:05:37,366 iteration 4359 : loss : 0.006195, loss_ce: 0.002199
2021-11-30 15:05:38,586 iteration 4360 : loss : 0.004663, loss_ce: 0.001663
2021-11-30 15:05:39,806 iteration 4361 : loss : 0.006923, loss_ce: 0.002148
2021-11-30 15:05:41,029 iteration 4362 : loss : 0.005084, loss_ce: 0.001495
2021-11-30 15:05:42,262 iteration 4363 : loss : 0.006003, loss_ce: 0.001913
2021-11-30 15:05:43,481 iteration 4364 : loss : 0.005482, loss_ce: 0.002179
2021-11-30 15:05:44,701 iteration 4365 : loss : 0.005696, loss_ce: 0.002990
2021-11-30 15:05:45,924 iteration 4366 : loss : 0.005333, loss_ce: 0.001358
2021-11-30 15:05:47,153 iteration 4367 : loss : 0.008973, loss_ce: 0.004133
2021-11-30 15:05:48,378 iteration 4368 : loss : 0.005337, loss_ce: 0.002291
2021-11-30 15:05:49,607 iteration 4369 : loss : 0.007601, loss_ce: 0.002741
 64%|██████████████████▋          | 257/400 [1:37:23<53:35, 22.49s/it]2021-11-30 15:05:50,899 iteration 4370 : loss : 0.006413, loss_ce: 0.002298
2021-11-30 15:05:52,123 iteration 4371 : loss : 0.007221, loss_ce: 0.002213
2021-11-30 15:05:53,345 iteration 4372 : loss : 0.005383, loss_ce: 0.002222
2021-11-30 15:05:54,566 iteration 4373 : loss : 0.006579, loss_ce: 0.002388
2021-11-30 15:05:55,789 iteration 4374 : loss : 0.006423, loss_ce: 0.002664
2021-11-30 15:05:57,020 iteration 4375 : loss : 0.006041, loss_ce: 0.002144
2021-11-30 15:05:58,244 iteration 4376 : loss : 0.007188, loss_ce: 0.003274
2021-11-30 15:05:59,467 iteration 4377 : loss : 0.005875, loss_ce: 0.002003
2021-11-30 15:06:00,687 iteration 4378 : loss : 0.005225, loss_ce: 0.001723
2021-11-30 15:06:01,913 iteration 4379 : loss : 0.005776, loss_ce: 0.002041
2021-11-30 15:06:03,140 iteration 4380 : loss : 0.005884, loss_ce: 0.002376
2021-11-30 15:06:04,364 iteration 4381 : loss : 0.005043, loss_ce: 0.001443
2021-11-30 15:06:05,589 iteration 4382 : loss : 0.006128, loss_ce: 0.001939
2021-11-30 15:06:06,814 iteration 4383 : loss : 0.005278, loss_ce: 0.002550
2021-11-30 15:06:08,038 iteration 4384 : loss : 0.005066, loss_ce: 0.001915
2021-11-30 15:06:09,259 iteration 4385 : loss : 0.006753, loss_ce: 0.002413
2021-11-30 15:06:10,478 iteration 4386 : loss : 0.008126, loss_ce: 0.003297
 64%|██████████████████▋          | 258/400 [1:37:44<52:04, 22.00s/it]2021-11-30 15:06:11,763 iteration 4387 : loss : 0.006526, loss_ce: 0.002700
2021-11-30 15:06:12,984 iteration 4388 : loss : 0.005703, loss_ce: 0.001681
2021-11-30 15:06:14,208 iteration 4389 : loss : 0.007348, loss_ce: 0.002880
2021-11-30 15:06:15,431 iteration 4390 : loss : 0.008746, loss_ce: 0.003389
2021-11-30 15:06:16,659 iteration 4391 : loss : 0.006059, loss_ce: 0.001928
2021-11-30 15:06:17,884 iteration 4392 : loss : 0.006619, loss_ce: 0.001875
2021-11-30 15:06:19,110 iteration 4393 : loss : 0.005311, loss_ce: 0.001882
2021-11-30 15:06:20,327 iteration 4394 : loss : 0.005011, loss_ce: 0.002279
2021-11-30 15:06:21,547 iteration 4395 : loss : 0.007098, loss_ce: 0.002439
2021-11-30 15:06:22,768 iteration 4396 : loss : 0.006077, loss_ce: 0.002527
2021-11-30 15:06:23,989 iteration 4397 : loss : 0.006000, loss_ce: 0.001985
2021-11-30 15:06:25,211 iteration 4398 : loss : 0.006775, loss_ce: 0.002357
2021-11-30 15:06:26,429 iteration 4399 : loss : 0.006354, loss_ce: 0.002477
2021-11-30 15:06:27,649 iteration 4400 : loss : 0.006568, loss_ce: 0.002491
2021-11-30 15:06:28,869 iteration 4401 : loss : 0.005137, loss_ce: 0.001763
2021-11-30 15:06:30,093 iteration 4402 : loss : 0.007203, loss_ce: 0.003736
2021-11-30 15:06:31,312 iteration 4403 : loss : 0.006722, loss_ce: 0.002650
 65%|██████████████████▊          | 259/400 [1:38:05<50:53, 21.65s/it]2021-11-30 15:06:32,608 iteration 4404 : loss : 0.005125, loss_ce: 0.001724
2021-11-30 15:06:33,835 iteration 4405 : loss : 0.006680, loss_ce: 0.001868
2021-11-30 15:06:35,059 iteration 4406 : loss : 0.005889, loss_ce: 0.001919
2021-11-30 15:06:36,273 iteration 4407 : loss : 0.006907, loss_ce: 0.002100
2021-11-30 15:06:37,502 iteration 4408 : loss : 0.005852, loss_ce: 0.002161
2021-11-30 15:06:38,714 iteration 4409 : loss : 0.005673, loss_ce: 0.001812
2021-11-30 15:06:39,932 iteration 4410 : loss : 0.005655, loss_ce: 0.002046
2021-11-30 15:06:41,150 iteration 4411 : loss : 0.006029, loss_ce: 0.002732
2021-11-30 15:06:42,355 iteration 4412 : loss : 0.005260, loss_ce: 0.002336
2021-11-30 15:06:43,567 iteration 4413 : loss : 0.008770, loss_ce: 0.004053
2021-11-30 15:06:44,785 iteration 4414 : loss : 0.007759, loss_ce: 0.002611
2021-11-30 15:06:46,008 iteration 4415 : loss : 0.005951, loss_ce: 0.001910
2021-11-30 15:06:47,226 iteration 4416 : loss : 0.007775, loss_ce: 0.003088
2021-11-30 15:06:48,438 iteration 4417 : loss : 0.008222, loss_ce: 0.003077
2021-11-30 15:06:49,654 iteration 4418 : loss : 0.005332, loss_ce: 0.002586
2021-11-30 15:06:50,868 iteration 4419 : loss : 0.007496, loss_ce: 0.003078
2021-11-30 15:06:50,868 Training Data Eval:
2021-11-30 15:06:57,784   Average segmentation loss on training set: 0.0066
2021-11-30 15:06:57,784 Validation Data Eval:
2021-11-30 15:07:00,166   Average segmentation loss on validation set: 0.1373
2021-11-30 15:07:01,382 iteration 4420 : loss : 0.006772, loss_ce: 0.002626
 65%|██████████████████▊          | 260/400 [1:38:35<56:24, 24.18s/it]2021-11-30 15:07:02,672 iteration 4421 : loss : 0.006399, loss_ce: 0.001863
2021-11-30 15:07:03,888 iteration 4422 : loss : 0.005592, loss_ce: 0.002404
2021-11-30 15:07:05,111 iteration 4423 : loss : 0.006381, loss_ce: 0.002811
2021-11-30 15:07:06,332 iteration 4424 : loss : 0.006318, loss_ce: 0.002965
2021-11-30 15:07:07,553 iteration 4425 : loss : 0.008964, loss_ce: 0.002504
2021-11-30 15:07:08,768 iteration 4426 : loss : 0.007099, loss_ce: 0.002832
2021-11-30 15:07:09,992 iteration 4427 : loss : 0.005779, loss_ce: 0.001766
2021-11-30 15:07:11,224 iteration 4428 : loss : 0.005047, loss_ce: 0.001915
2021-11-30 15:07:12,447 iteration 4429 : loss : 0.009177, loss_ce: 0.003059
2021-11-30 15:07:13,672 iteration 4430 : loss : 0.007450, loss_ce: 0.002577
2021-11-30 15:07:14,888 iteration 4431 : loss : 0.005478, loss_ce: 0.002099
2021-11-30 15:07:16,117 iteration 4432 : loss : 0.005236, loss_ce: 0.001857
2021-11-30 15:07:17,339 iteration 4433 : loss : 0.006576, loss_ce: 0.002472
2021-11-30 15:07:18,562 iteration 4434 : loss : 0.008418, loss_ce: 0.002459
2021-11-30 15:07:19,785 iteration 4435 : loss : 0.006022, loss_ce: 0.002248
2021-11-30 15:07:21,006 iteration 4436 : loss : 0.005830, loss_ce: 0.001602
2021-11-30 15:07:22,224 iteration 4437 : loss : 0.006674, loss_ce: 0.002866
 65%|██████████████████▉          | 261/400 [1:38:56<53:41, 23.18s/it]2021-11-30 15:07:23,517 iteration 4438 : loss : 0.005202, loss_ce: 0.002047
2021-11-30 15:07:24,735 iteration 4439 : loss : 0.005604, loss_ce: 0.002645
2021-11-30 15:07:25,952 iteration 4440 : loss : 0.006398, loss_ce: 0.001636
2021-11-30 15:07:27,177 iteration 4441 : loss : 0.006067, loss_ce: 0.003059
2021-11-30 15:07:28,398 iteration 4442 : loss : 0.005666, loss_ce: 0.001852
2021-11-30 15:07:29,622 iteration 4443 : loss : 0.005940, loss_ce: 0.002689
2021-11-30 15:07:30,842 iteration 4444 : loss : 0.004902, loss_ce: 0.001659
2021-11-30 15:07:32,067 iteration 4445 : loss : 0.006165, loss_ce: 0.002163
2021-11-30 15:07:33,283 iteration 4446 : loss : 0.007230, loss_ce: 0.003293
2021-11-30 15:07:34,506 iteration 4447 : loss : 0.005616, loss_ce: 0.001764
2021-11-30 15:07:35,727 iteration 4448 : loss : 0.007685, loss_ce: 0.001843
2021-11-30 15:07:36,952 iteration 4449 : loss : 0.005995, loss_ce: 0.002418
2021-11-30 15:07:38,170 iteration 4450 : loss : 0.006042, loss_ce: 0.001814
2021-11-30 15:07:39,393 iteration 4451 : loss : 0.005893, loss_ce: 0.002402
2021-11-30 15:07:40,619 iteration 4452 : loss : 0.007493, loss_ce: 0.002376
2021-11-30 15:07:41,843 iteration 4453 : loss : 0.007041, loss_ce: 0.001908
2021-11-30 15:07:43,071 iteration 4454 : loss : 0.006224, loss_ce: 0.002871
 66%|██████████████████▉          | 262/400 [1:39:17<51:42, 22.48s/it]2021-11-30 15:07:44,360 iteration 4455 : loss : 0.006171, loss_ce: 0.001963
2021-11-30 15:07:45,580 iteration 4456 : loss : 0.005565, loss_ce: 0.002131
2021-11-30 15:07:46,797 iteration 4457 : loss : 0.006796, loss_ce: 0.002724
2021-11-30 15:07:48,022 iteration 4458 : loss : 0.006813, loss_ce: 0.002525
2021-11-30 15:07:49,241 iteration 4459 : loss : 0.006596, loss_ce: 0.002599
2021-11-30 15:07:50,454 iteration 4460 : loss : 0.005450, loss_ce: 0.002335
2021-11-30 15:07:51,671 iteration 4461 : loss : 0.005325, loss_ce: 0.002061
2021-11-30 15:07:52,898 iteration 4462 : loss : 0.005043, loss_ce: 0.001926
2021-11-30 15:07:54,121 iteration 4463 : loss : 0.005909, loss_ce: 0.001930
2021-11-30 15:07:55,385 iteration 4464 : loss : 0.004810, loss_ce: 0.001920
2021-11-30 15:07:56,603 iteration 4465 : loss : 0.005622, loss_ce: 0.002350
2021-11-30 15:07:57,830 iteration 4466 : loss : 0.004665, loss_ce: 0.002033
2021-11-30 15:07:59,052 iteration 4467 : loss : 0.005434, loss_ce: 0.001530
2021-11-30 15:08:00,270 iteration 4468 : loss : 0.005760, loss_ce: 0.001773
2021-11-30 15:08:01,490 iteration 4469 : loss : 0.005470, loss_ce: 0.002254
2021-11-30 15:08:02,707 iteration 4470 : loss : 0.004254, loss_ce: 0.001672
2021-11-30 15:08:03,927 iteration 4471 : loss : 0.006827, loss_ce: 0.002660
 66%|███████████████████          | 263/400 [1:39:37<50:12, 21.99s/it]2021-11-30 15:08:05,222 iteration 4472 : loss : 0.005080, loss_ce: 0.001712
2021-11-30 15:08:06,435 iteration 4473 : loss : 0.005179, loss_ce: 0.001720
2021-11-30 15:08:07,659 iteration 4474 : loss : 0.004363, loss_ce: 0.001720
2021-11-30 15:08:08,880 iteration 4475 : loss : 0.005966, loss_ce: 0.002040
2021-11-30 15:08:10,103 iteration 4476 : loss : 0.006019, loss_ce: 0.002328
2021-11-30 15:08:11,327 iteration 4477 : loss : 0.004734, loss_ce: 0.001978
2021-11-30 15:08:12,552 iteration 4478 : loss : 0.006585, loss_ce: 0.002080
2021-11-30 15:08:13,775 iteration 4479 : loss : 0.006027, loss_ce: 0.001984
2021-11-30 15:08:15,001 iteration 4480 : loss : 0.005365, loss_ce: 0.001679
2021-11-30 15:08:16,227 iteration 4481 : loss : 0.005074, loss_ce: 0.001649
2021-11-30 15:08:17,449 iteration 4482 : loss : 0.005975, loss_ce: 0.002443
2021-11-30 15:08:18,674 iteration 4483 : loss : 0.006173, loss_ce: 0.002665
2021-11-30 15:08:19,893 iteration 4484 : loss : 0.006496, loss_ce: 0.003405
2021-11-30 15:08:21,121 iteration 4485 : loss : 0.004768, loss_ce: 0.001708
2021-11-30 15:08:22,338 iteration 4486 : loss : 0.005834, loss_ce: 0.002313
2021-11-30 15:08:23,562 iteration 4487 : loss : 0.005459, loss_ce: 0.002489
2021-11-30 15:08:24,784 iteration 4488 : loss : 0.005215, loss_ce: 0.001534
 66%|███████████████████▏         | 264/400 [1:39:58<49:04, 21.65s/it]2021-11-30 15:08:26,098 iteration 4489 : loss : 0.004774, loss_ce: 0.001657
2021-11-30 15:08:27,324 iteration 4490 : loss : 0.003777, loss_ce: 0.001418
2021-11-30 15:08:28,554 iteration 4491 : loss : 0.005974, loss_ce: 0.002572
2021-11-30 15:08:29,773 iteration 4492 : loss : 0.005096, loss_ce: 0.001587
2021-11-30 15:08:30,997 iteration 4493 : loss : 0.005631, loss_ce: 0.002647
2021-11-30 15:08:32,221 iteration 4494 : loss : 0.005476, loss_ce: 0.001975
2021-11-30 15:08:33,447 iteration 4495 : loss : 0.005719, loss_ce: 0.002038
2021-11-30 15:08:34,668 iteration 4496 : loss : 0.005128, loss_ce: 0.001470
2021-11-30 15:08:35,882 iteration 4497 : loss : 0.006039, loss_ce: 0.001674
2021-11-30 15:08:37,100 iteration 4498 : loss : 0.006028, loss_ce: 0.002239
2021-11-30 15:08:38,324 iteration 4499 : loss : 0.006284, loss_ce: 0.002824
2021-11-30 15:08:39,544 iteration 4500 : loss : 0.005729, loss_ce: 0.002814
2021-11-30 15:08:40,764 iteration 4501 : loss : 0.006706, loss_ce: 0.002015
2021-11-30 15:08:41,983 iteration 4502 : loss : 0.005772, loss_ce: 0.002613
2021-11-30 15:08:43,213 iteration 4503 : loss : 0.004964, loss_ce: 0.001369
2021-11-30 15:08:44,443 iteration 4504 : loss : 0.005769, loss_ce: 0.001830
2021-11-30 15:08:44,443 Training Data Eval:
2021-11-30 15:08:51,358   Average segmentation loss on training set: 0.0053
2021-11-30 15:08:51,359 Validation Data Eval:
2021-11-30 15:08:53,738   Average segmentation loss on validation set: 0.1295
2021-11-30 15:08:54,963 iteration 4505 : loss : 0.005316, loss_ce: 0.002216
 66%|███████████████████▏         | 265/400 [1:40:29<54:28, 24.21s/it]2021-11-30 15:08:56,253 iteration 4506 : loss : 0.005427, loss_ce: 0.002140
2021-11-30 15:08:57,471 iteration 4507 : loss : 0.005554, loss_ce: 0.002212
2021-11-30 15:08:58,689 iteration 4508 : loss : 0.004781, loss_ce: 0.001757
2021-11-30 15:08:59,914 iteration 4509 : loss : 0.004414, loss_ce: 0.001139
2021-11-30 15:09:01,142 iteration 4510 : loss : 0.004765, loss_ce: 0.001605
2021-11-30 15:09:02,368 iteration 4511 : loss : 0.006115, loss_ce: 0.002087
2021-11-30 15:09:03,588 iteration 4512 : loss : 0.005761, loss_ce: 0.001910
2021-11-30 15:09:04,807 iteration 4513 : loss : 0.005081, loss_ce: 0.001745
2021-11-30 15:09:06,037 iteration 4514 : loss : 0.005500, loss_ce: 0.001955
2021-11-30 15:09:07,260 iteration 4515 : loss : 0.005518, loss_ce: 0.002591
2021-11-30 15:09:08,482 iteration 4516 : loss : 0.005626, loss_ce: 0.002315
2021-11-30 15:09:09,698 iteration 4517 : loss : 0.008758, loss_ce: 0.001298
2021-11-30 15:09:10,918 iteration 4518 : loss : 0.006266, loss_ce: 0.002351
2021-11-30 15:09:12,139 iteration 4519 : loss : 0.007101, loss_ce: 0.003400
2021-11-30 15:09:13,363 iteration 4520 : loss : 0.007978, loss_ce: 0.002628
2021-11-30 15:09:14,584 iteration 4521 : loss : 0.006150, loss_ce: 0.002765
2021-11-30 15:09:15,802 iteration 4522 : loss : 0.005254, loss_ce: 0.002249
 66%|███████████████████▎         | 266/400 [1:40:49<51:48, 23.20s/it]2021-11-30 15:09:17,090 iteration 4523 : loss : 0.006890, loss_ce: 0.002292
2021-11-30 15:09:18,310 iteration 4524 : loss : 0.006013, loss_ce: 0.001615
2021-11-30 15:09:19,539 iteration 4525 : loss : 0.005778, loss_ce: 0.002702
2021-11-30 15:09:20,762 iteration 4526 : loss : 0.006855, loss_ce: 0.002367
2021-11-30 15:09:21,983 iteration 4527 : loss : 0.004977, loss_ce: 0.001583
2021-11-30 15:09:23,200 iteration 4528 : loss : 0.006637, loss_ce: 0.002943
2021-11-30 15:09:24,417 iteration 4529 : loss : 0.006699, loss_ce: 0.001858
2021-11-30 15:09:25,634 iteration 4530 : loss : 0.005629, loss_ce: 0.002082
2021-11-30 15:09:26,853 iteration 4531 : loss : 0.005494, loss_ce: 0.002098
2021-11-30 15:09:28,079 iteration 4532 : loss : 0.009665, loss_ce: 0.003749
2021-11-30 15:09:29,309 iteration 4533 : loss : 0.006470, loss_ce: 0.002305
2021-11-30 15:09:30,532 iteration 4534 : loss : 0.008452, loss_ce: 0.002903
2021-11-30 15:09:31,751 iteration 4535 : loss : 0.006127, loss_ce: 0.003002
2021-11-30 15:09:32,978 iteration 4536 : loss : 0.006142, loss_ce: 0.001927
2021-11-30 15:09:34,194 iteration 4537 : loss : 0.008199, loss_ce: 0.002613
2021-11-30 15:09:35,407 iteration 4538 : loss : 0.007134, loss_ce: 0.002721
2021-11-30 15:09:36,633 iteration 4539 : loss : 0.004317, loss_ce: 0.001733
 67%|███████████████████▎         | 267/400 [1:41:10<49:50, 22.49s/it]2021-11-30 15:09:37,925 iteration 4540 : loss : 0.008072, loss_ce: 0.002747
2021-11-30 15:09:39,145 iteration 4541 : loss : 0.006315, loss_ce: 0.002743
2021-11-30 15:09:40,363 iteration 4542 : loss : 0.005694, loss_ce: 0.002434
2021-11-30 15:09:41,582 iteration 4543 : loss : 0.005137, loss_ce: 0.001758
2021-11-30 15:09:42,800 iteration 4544 : loss : 0.006105, loss_ce: 0.002635
2021-11-30 15:09:44,021 iteration 4545 : loss : 0.007014, loss_ce: 0.002460
2021-11-30 15:09:45,249 iteration 4546 : loss : 0.005171, loss_ce: 0.001699
2021-11-30 15:09:46,477 iteration 4547 : loss : 0.005168, loss_ce: 0.001850
2021-11-30 15:09:47,704 iteration 4548 : loss : 0.006181, loss_ce: 0.001969
2021-11-30 15:09:48,925 iteration 4549 : loss : 0.006227, loss_ce: 0.001932
2021-11-30 15:09:50,150 iteration 4550 : loss : 0.004592, loss_ce: 0.001883
2021-11-30 15:09:51,372 iteration 4551 : loss : 0.004539, loss_ce: 0.001882
2021-11-30 15:09:52,598 iteration 4552 : loss : 0.005814, loss_ce: 0.002291
2021-11-30 15:09:53,826 iteration 4553 : loss : 0.005397, loss_ce: 0.002494
2021-11-30 15:09:55,057 iteration 4554 : loss : 0.006358, loss_ce: 0.001957
2021-11-30 15:09:56,283 iteration 4555 : loss : 0.006549, loss_ce: 0.002627
2021-11-30 15:09:57,505 iteration 4556 : loss : 0.005403, loss_ce: 0.002124
 67%|███████████████████▍         | 268/400 [1:41:31<48:24, 22.00s/it]2021-11-30 15:09:58,798 iteration 4557 : loss : 0.004438, loss_ce: 0.001357
2021-11-30 15:10:00,024 iteration 4558 : loss : 0.007314, loss_ce: 0.002008
2021-11-30 15:10:01,250 iteration 4559 : loss : 0.005272, loss_ce: 0.002216
2021-11-30 15:10:02,477 iteration 4560 : loss : 0.005937, loss_ce: 0.002230
2021-11-30 15:10:03,701 iteration 4561 : loss : 0.004981, loss_ce: 0.001458
2021-11-30 15:10:04,919 iteration 4562 : loss : 0.008552, loss_ce: 0.002246
2021-11-30 15:10:06,146 iteration 4563 : loss : 0.005468, loss_ce: 0.002303
2021-11-30 15:10:07,373 iteration 4564 : loss : 0.006155, loss_ce: 0.002275
2021-11-30 15:10:08,596 iteration 4565 : loss : 0.008859, loss_ce: 0.002466
2021-11-30 15:10:09,818 iteration 4566 : loss : 0.006004, loss_ce: 0.002547
2021-11-30 15:10:11,042 iteration 4567 : loss : 0.006074, loss_ce: 0.003173
2021-11-30 15:10:12,271 iteration 4568 : loss : 0.006563, loss_ce: 0.003000
2021-11-30 15:10:13,491 iteration 4569 : loss : 0.006520, loss_ce: 0.002052
2021-11-30 15:10:14,705 iteration 4570 : loss : 0.006264, loss_ce: 0.002750
2021-11-30 15:10:15,927 iteration 4571 : loss : 0.005259, loss_ce: 0.001888
2021-11-30 15:10:17,152 iteration 4572 : loss : 0.006024, loss_ce: 0.002459
2021-11-30 15:10:18,377 iteration 4573 : loss : 0.005302, loss_ce: 0.002245
 67%|███████████████████▌         | 269/400 [1:41:52<47:18, 21.66s/it]2021-11-30 15:10:19,670 iteration 4574 : loss : 0.005360, loss_ce: 0.001706
2021-11-30 15:10:20,889 iteration 4575 : loss : 0.005868, loss_ce: 0.003027
2021-11-30 15:10:22,095 iteration 4576 : loss : 0.005565, loss_ce: 0.001764
2021-11-30 15:10:23,313 iteration 4577 : loss : 0.006527, loss_ce: 0.001998
2021-11-30 15:10:24,529 iteration 4578 : loss : 0.006432, loss_ce: 0.002839
2021-11-30 15:10:25,750 iteration 4579 : loss : 0.007717, loss_ce: 0.002519
2021-11-30 15:10:26,981 iteration 4580 : loss : 0.006230, loss_ce: 0.002825
2021-11-30 15:10:28,197 iteration 4581 : loss : 0.005767, loss_ce: 0.002523
2021-11-30 15:10:29,408 iteration 4582 : loss : 0.006981, loss_ce: 0.002424
2021-11-30 15:10:30,624 iteration 4583 : loss : 0.007192, loss_ce: 0.002730
2021-11-30 15:10:31,845 iteration 4584 : loss : 0.005667, loss_ce: 0.002755
2021-11-30 15:10:33,068 iteration 4585 : loss : 0.007790, loss_ce: 0.001850
2021-11-30 15:10:34,297 iteration 4586 : loss : 0.006400, loss_ce: 0.002511
2021-11-30 15:10:35,518 iteration 4587 : loss : 0.007029, loss_ce: 0.002642
2021-11-30 15:10:36,743 iteration 4588 : loss : 0.007770, loss_ce: 0.003330
2021-11-30 15:10:37,958 iteration 4589 : loss : 0.006718, loss_ce: 0.003059
2021-11-30 15:10:37,959 Training Data Eval:
2021-11-30 15:10:44,872   Average segmentation loss on training set: 0.0055
2021-11-30 15:10:44,873 Validation Data Eval:
2021-11-30 15:10:47,246   Average segmentation loss on validation set: 0.1545
2021-11-30 15:10:48,473 iteration 4590 : loss : 0.006663, loss_ce: 0.003160
 68%|███████████████████▌         | 270/400 [1:42:22<52:24, 24.19s/it]2021-11-30 15:10:49,759 iteration 4591 : loss : 0.006369, loss_ce: 0.002390
2021-11-30 15:10:50,995 iteration 4592 : loss : 0.007123, loss_ce: 0.002063
2021-11-30 15:10:52,211 iteration 4593 : loss : 0.006035, loss_ce: 0.002467
2021-11-30 15:10:53,432 iteration 4594 : loss : 0.005955, loss_ce: 0.002150
2021-11-30 15:10:54,660 iteration 4595 : loss : 0.004712, loss_ce: 0.001933
2021-11-30 15:10:55,880 iteration 4596 : loss : 0.006932, loss_ce: 0.003062
2021-11-30 15:10:57,094 iteration 4597 : loss : 0.005285, loss_ce: 0.002381
2021-11-30 15:10:58,310 iteration 4598 : loss : 0.007605, loss_ce: 0.001511
2021-11-30 15:10:59,530 iteration 4599 : loss : 0.006034, loss_ce: 0.001551
2021-11-30 15:11:00,753 iteration 4600 : loss : 0.005847, loss_ce: 0.002530
2021-11-30 15:11:01,969 iteration 4601 : loss : 0.007164, loss_ce: 0.003827
2021-11-30 15:11:03,191 iteration 4602 : loss : 0.005466, loss_ce: 0.001298
2021-11-30 15:11:04,417 iteration 4603 : loss : 0.006208, loss_ce: 0.002209
2021-11-30 15:11:05,636 iteration 4604 : loss : 0.005118, loss_ce: 0.002154
2021-11-30 15:11:06,855 iteration 4605 : loss : 0.006506, loss_ce: 0.002779
2021-11-30 15:11:08,077 iteration 4606 : loss : 0.006139, loss_ce: 0.002463
2021-11-30 15:11:09,303 iteration 4607 : loss : 0.006593, loss_ce: 0.002932
 68%|███████████████████▋         | 271/400 [1:42:43<49:50, 23.18s/it]2021-11-30 15:11:10,593 iteration 4608 : loss : 0.005304, loss_ce: 0.001980
2021-11-30 15:11:11,817 iteration 4609 : loss : 0.005609, loss_ce: 0.002431
2021-11-30 15:11:13,044 iteration 4610 : loss : 0.005920, loss_ce: 0.001879
2021-11-30 15:11:14,270 iteration 4611 : loss : 0.005964, loss_ce: 0.002078
2021-11-30 15:11:15,501 iteration 4612 : loss : 0.005343, loss_ce: 0.002631
2021-11-30 15:11:16,723 iteration 4613 : loss : 0.004824, loss_ce: 0.002156
2021-11-30 15:11:17,952 iteration 4614 : loss : 0.006232, loss_ce: 0.002277
2021-11-30 15:11:19,174 iteration 4615 : loss : 0.006837, loss_ce: 0.002498
2021-11-30 15:11:20,390 iteration 4616 : loss : 0.005760, loss_ce: 0.001798
2021-11-30 15:11:21,614 iteration 4617 : loss : 0.006601, loss_ce: 0.002065
2021-11-30 15:11:22,842 iteration 4618 : loss : 0.006544, loss_ce: 0.002487
2021-11-30 15:11:24,057 iteration 4619 : loss : 0.006883, loss_ce: 0.002894
2021-11-30 15:11:25,314 iteration 4620 : loss : 0.006648, loss_ce: 0.002771
2021-11-30 15:11:26,539 iteration 4621 : loss : 0.008480, loss_ce: 0.002484
2021-11-30 15:11:27,767 iteration 4622 : loss : 0.005416, loss_ce: 0.002579
2021-11-30 15:11:28,995 iteration 4623 : loss : 0.006956, loss_ce: 0.002821
2021-11-30 15:11:30,217 iteration 4624 : loss : 0.004819, loss_ce: 0.001652
 68%|███████████████████▋         | 272/400 [1:43:04<48:00, 22.50s/it]2021-11-30 15:11:31,506 iteration 4625 : loss : 0.006708, loss_ce: 0.003061
2021-11-30 15:11:32,732 iteration 4626 : loss : 0.006829, loss_ce: 0.002462
2021-11-30 15:11:33,955 iteration 4627 : loss : 0.005467, loss_ce: 0.002059
2021-11-30 15:11:35,180 iteration 4628 : loss : 0.005264, loss_ce: 0.002081
2021-11-30 15:11:36,408 iteration 4629 : loss : 0.006878, loss_ce: 0.002397
2021-11-30 15:11:37,625 iteration 4630 : loss : 0.006860, loss_ce: 0.002423
2021-11-30 15:11:38,844 iteration 4631 : loss : 0.005602, loss_ce: 0.002145
2021-11-30 15:11:40,068 iteration 4632 : loss : 0.007248, loss_ce: 0.002027
2021-11-30 15:11:41,289 iteration 4633 : loss : 0.006313, loss_ce: 0.002888
2021-11-30 15:11:42,511 iteration 4634 : loss : 0.008660, loss_ce: 0.004011
2021-11-30 15:11:43,732 iteration 4635 : loss : 0.007572, loss_ce: 0.003043
2021-11-30 15:11:44,948 iteration 4636 : loss : 0.006001, loss_ce: 0.001990
2021-11-30 15:11:46,166 iteration 4637 : loss : 0.005011, loss_ce: 0.001506
2021-11-30 15:11:47,385 iteration 4638 : loss : 0.007335, loss_ce: 0.001631
2021-11-30 15:11:48,610 iteration 4639 : loss : 0.006807, loss_ce: 0.002384
2021-11-30 15:11:49,833 iteration 4640 : loss : 0.006167, loss_ce: 0.002427
2021-11-30 15:11:51,051 iteration 4641 : loss : 0.005193, loss_ce: 0.001858
 68%|███████████████████▊         | 273/400 [1:43:25<46:34, 22.00s/it]2021-11-30 15:11:52,338 iteration 4642 : loss : 0.006146, loss_ce: 0.002744
2021-11-30 15:11:53,557 iteration 4643 : loss : 0.005167, loss_ce: 0.001600
2021-11-30 15:11:54,780 iteration 4644 : loss : 0.006256, loss_ce: 0.002659
2021-11-30 15:11:56,026 iteration 4645 : loss : 0.007403, loss_ce: 0.002169
2021-11-30 15:11:57,248 iteration 4646 : loss : 0.006306, loss_ce: 0.002111
2021-11-30 15:11:58,468 iteration 4647 : loss : 0.006842, loss_ce: 0.001921
2021-11-30 15:11:59,699 iteration 4648 : loss : 0.005922, loss_ce: 0.001682
2021-11-30 15:12:00,925 iteration 4649 : loss : 0.006987, loss_ce: 0.002324
2021-11-30 15:12:02,147 iteration 4650 : loss : 0.006463, loss_ce: 0.002274
2021-11-30 15:12:03,369 iteration 4651 : loss : 0.005633, loss_ce: 0.002213
2021-11-30 15:12:04,594 iteration 4652 : loss : 0.006295, loss_ce: 0.002354
2021-11-30 15:12:05,815 iteration 4653 : loss : 0.007426, loss_ce: 0.002230
2021-11-30 15:12:07,033 iteration 4654 : loss : 0.006413, loss_ce: 0.002682
2021-11-30 15:12:08,258 iteration 4655 : loss : 0.005338, loss_ce: 0.002136
2021-11-30 15:12:09,486 iteration 4656 : loss : 0.008180, loss_ce: 0.002750
2021-11-30 15:12:10,706 iteration 4657 : loss : 0.006665, loss_ce: 0.003504
2021-11-30 15:12:11,930 iteration 4658 : loss : 0.007516, loss_ce: 0.003205
 68%|███████████████████▊         | 274/400 [1:43:45<45:29, 21.67s/it]2021-11-30 15:12:13,217 iteration 4659 : loss : 0.005712, loss_ce: 0.002365
2021-11-30 15:12:14,437 iteration 4660 : loss : 0.004672, loss_ce: 0.001358
2021-11-30 15:12:15,665 iteration 4661 : loss : 0.006405, loss_ce: 0.003191
2021-11-30 15:12:16,891 iteration 4662 : loss : 0.005585, loss_ce: 0.002227
2021-11-30 15:12:18,117 iteration 4663 : loss : 0.006085, loss_ce: 0.001944
2021-11-30 15:12:19,333 iteration 4664 : loss : 0.007233, loss_ce: 0.002240
2021-11-30 15:12:20,553 iteration 4665 : loss : 0.006556, loss_ce: 0.002414
2021-11-30 15:12:21,784 iteration 4666 : loss : 0.005628, loss_ce: 0.002482
2021-11-30 15:12:23,011 iteration 4667 : loss : 0.005821, loss_ce: 0.002604
2021-11-30 15:12:24,229 iteration 4668 : loss : 0.006135, loss_ce: 0.001630
2021-11-30 15:12:25,453 iteration 4669 : loss : 0.005409, loss_ce: 0.002156
2021-11-30 15:12:26,681 iteration 4670 : loss : 0.005843, loss_ce: 0.002524
2021-11-30 15:12:27,900 iteration 4671 : loss : 0.006222, loss_ce: 0.002371
2021-11-30 15:12:29,128 iteration 4672 : loss : 0.006144, loss_ce: 0.002157
2021-11-30 15:12:30,354 iteration 4673 : loss : 0.005853, loss_ce: 0.002393
2021-11-30 15:12:31,583 iteration 4674 : loss : 0.005079, loss_ce: 0.001609
2021-11-30 15:12:31,583 Training Data Eval:
2021-11-30 15:12:38,518   Average segmentation loss on training set: 0.0054
2021-11-30 15:12:38,518 Validation Data Eval:
2021-11-30 15:12:40,896   Average segmentation loss on validation set: 0.1381
2021-11-30 15:12:42,126 iteration 4675 : loss : 0.006118, loss_ce: 0.002291
 69%|███████████████████▉         | 275/400 [1:44:16<50:28, 24.23s/it]2021-11-30 15:12:43,424 iteration 4676 : loss : 0.005458, loss_ce: 0.002398
2021-11-30 15:12:44,652 iteration 4677 : loss : 0.004861, loss_ce: 0.001853
2021-11-30 15:12:45,877 iteration 4678 : loss : 0.006134, loss_ce: 0.002684
2021-11-30 15:12:47,096 iteration 4679 : loss : 0.005723, loss_ce: 0.001853
2021-11-30 15:12:48,326 iteration 4680 : loss : 0.004755, loss_ce: 0.001306
2021-11-30 15:12:49,551 iteration 4681 : loss : 0.006275, loss_ce: 0.001836
2021-11-30 15:12:50,784 iteration 4682 : loss : 0.004601, loss_ce: 0.001547
2021-11-30 15:12:52,016 iteration 4683 : loss : 0.005703, loss_ce: 0.002817
2021-11-30 15:12:53,240 iteration 4684 : loss : 0.005548, loss_ce: 0.001124
2021-11-30 15:12:54,467 iteration 4685 : loss : 0.005360, loss_ce: 0.002354
2021-11-30 15:12:55,703 iteration 4686 : loss : 0.005500, loss_ce: 0.001946
2021-11-30 15:12:56,930 iteration 4687 : loss : 0.005283, loss_ce: 0.001813
2021-11-30 15:12:58,150 iteration 4688 : loss : 0.006221, loss_ce: 0.002220
2021-11-30 15:12:59,379 iteration 4689 : loss : 0.005080, loss_ce: 0.002305
2021-11-30 15:13:00,607 iteration 4690 : loss : 0.006407, loss_ce: 0.003025
2021-11-30 15:13:01,826 iteration 4691 : loss : 0.005423, loss_ce: 0.002272
2021-11-30 15:13:03,053 iteration 4692 : loss : 0.006376, loss_ce: 0.002615
 69%|████████████████████         | 276/400 [1:44:37<48:01, 23.24s/it]2021-11-30 15:13:04,346 iteration 4693 : loss : 0.004712, loss_ce: 0.002082
2021-11-30 15:13:05,573 iteration 4694 : loss : 0.005975, loss_ce: 0.002140
2021-11-30 15:13:06,798 iteration 4695 : loss : 0.005029, loss_ce: 0.001549
2021-11-30 15:13:08,023 iteration 4696 : loss : 0.005106, loss_ce: 0.002111
2021-11-30 15:13:09,247 iteration 4697 : loss : 0.004609, loss_ce: 0.002082
2021-11-30 15:13:10,468 iteration 4698 : loss : 0.005283, loss_ce: 0.001603
2021-11-30 15:13:11,690 iteration 4699 : loss : 0.005998, loss_ce: 0.002196
2021-11-30 15:13:12,919 iteration 4700 : loss : 0.007504, loss_ce: 0.002459
2021-11-30 15:13:14,143 iteration 4701 : loss : 0.005562, loss_ce: 0.002593
2021-11-30 15:13:15,375 iteration 4702 : loss : 0.005297, loss_ce: 0.002031
2021-11-30 15:13:16,600 iteration 4703 : loss : 0.006959, loss_ce: 0.003309
2021-11-30 15:13:17,829 iteration 4704 : loss : 0.004602, loss_ce: 0.002338
2021-11-30 15:13:19,052 iteration 4705 : loss : 0.005853, loss_ce: 0.002382
2021-11-30 15:13:20,276 iteration 4706 : loss : 0.004401, loss_ce: 0.001652
2021-11-30 15:13:21,497 iteration 4707 : loss : 0.007506, loss_ce: 0.002179
2021-11-30 15:13:22,725 iteration 4708 : loss : 0.007704, loss_ce: 0.001898
2021-11-30 15:13:23,947 iteration 4709 : loss : 0.004517, loss_ce: 0.001356
 69%|████████████████████         | 277/400 [1:44:58<46:11, 22.53s/it]2021-11-30 15:13:25,234 iteration 4710 : loss : 0.005171, loss_ce: 0.002205
2021-11-30 15:13:26,457 iteration 4711 : loss : 0.007142, loss_ce: 0.003604
2021-11-30 15:13:27,685 iteration 4712 : loss : 0.005390, loss_ce: 0.001900
2021-11-30 15:13:28,908 iteration 4713 : loss : 0.005003, loss_ce: 0.001577
2021-11-30 15:13:30,138 iteration 4714 : loss : 0.005805, loss_ce: 0.001810
2021-11-30 15:13:31,356 iteration 4715 : loss : 0.006436, loss_ce: 0.002517
2021-11-30 15:13:32,581 iteration 4716 : loss : 0.006056, loss_ce: 0.001605
2021-11-30 15:13:33,805 iteration 4717 : loss : 0.006580, loss_ce: 0.002255
2021-11-30 15:13:35,030 iteration 4718 : loss : 0.005544, loss_ce: 0.001492
2021-11-30 15:13:36,252 iteration 4719 : loss : 0.008726, loss_ce: 0.001626
2021-11-30 15:13:37,477 iteration 4720 : loss : 0.005279, loss_ce: 0.002032
2021-11-30 15:13:38,696 iteration 4721 : loss : 0.005119, loss_ce: 0.002077
2021-11-30 15:13:39,924 iteration 4722 : loss : 0.006356, loss_ce: 0.002414
2021-11-30 15:13:41,147 iteration 4723 : loss : 0.005413, loss_ce: 0.002468
2021-11-30 15:13:42,369 iteration 4724 : loss : 0.005576, loss_ce: 0.002536
2021-11-30 15:13:43,594 iteration 4725 : loss : 0.006556, loss_ce: 0.002825
2021-11-30 15:13:44,821 iteration 4726 : loss : 0.005409, loss_ce: 0.001957
 70%|████████████████████▏        | 278/400 [1:45:18<44:48, 22.04s/it]2021-11-30 15:13:46,118 iteration 4727 : loss : 0.006471, loss_ce: 0.002870
2021-11-30 15:13:47,342 iteration 4728 : loss : 0.005523, loss_ce: 0.001914
2021-11-30 15:13:48,566 iteration 4729 : loss : 0.005192, loss_ce: 0.001810
2021-11-30 15:13:49,785 iteration 4730 : loss : 0.005768, loss_ce: 0.001759
2021-11-30 15:13:51,014 iteration 4731 : loss : 0.005177, loss_ce: 0.002648
2021-11-30 15:13:52,238 iteration 4732 : loss : 0.005339, loss_ce: 0.002219
2021-11-30 15:13:53,454 iteration 4733 : loss : 0.005810, loss_ce: 0.002468
2021-11-30 15:13:54,670 iteration 4734 : loss : 0.004383, loss_ce: 0.001779
2021-11-30 15:13:55,893 iteration 4735 : loss : 0.004754, loss_ce: 0.002123
2021-11-30 15:13:57,110 iteration 4736 : loss : 0.005969, loss_ce: 0.002350
2021-11-30 15:13:58,329 iteration 4737 : loss : 0.006598, loss_ce: 0.001336
2021-11-30 15:13:59,551 iteration 4738 : loss : 0.005947, loss_ce: 0.002199
2021-11-30 15:14:00,774 iteration 4739 : loss : 0.006132, loss_ce: 0.001888
2021-11-30 15:14:02,006 iteration 4740 : loss : 0.004903, loss_ce: 0.001416
2021-11-30 15:14:03,237 iteration 4741 : loss : 0.005246, loss_ce: 0.002325
2021-11-30 15:14:04,457 iteration 4742 : loss : 0.004711, loss_ce: 0.001597
2021-11-30 15:14:05,679 iteration 4743 : loss : 0.005682, loss_ce: 0.002128
 70%|████████████████████▏        | 279/400 [1:45:39<43:43, 21.68s/it]2021-11-30 15:14:06,963 iteration 4744 : loss : 0.004409, loss_ce: 0.001478
2021-11-30 15:14:08,185 iteration 4745 : loss : 0.004964, loss_ce: 0.001851
2021-11-30 15:14:09,409 iteration 4746 : loss : 0.004370, loss_ce: 0.001555
2021-11-30 15:14:10,629 iteration 4747 : loss : 0.004531, loss_ce: 0.001597
2021-11-30 15:14:11,846 iteration 4748 : loss : 0.006534, loss_ce: 0.003391
2021-11-30 15:14:13,067 iteration 4749 : loss : 0.005135, loss_ce: 0.002005
2021-11-30 15:14:14,294 iteration 4750 : loss : 0.003782, loss_ce: 0.000779
2021-11-30 15:14:15,519 iteration 4751 : loss : 0.005773, loss_ce: 0.002332
2021-11-30 15:14:16,745 iteration 4752 : loss : 0.004468, loss_ce: 0.001954
2021-11-30 15:14:17,966 iteration 4753 : loss : 0.004571, loss_ce: 0.001701
2021-11-30 15:14:19,188 iteration 4754 : loss : 0.005238, loss_ce: 0.002091
2021-11-30 15:14:20,409 iteration 4755 : loss : 0.005263, loss_ce: 0.002122
2021-11-30 15:14:21,628 iteration 4756 : loss : 0.005357, loss_ce: 0.001790
2021-11-30 15:14:22,848 iteration 4757 : loss : 0.007105, loss_ce: 0.003562
2021-11-30 15:14:24,082 iteration 4758 : loss : 0.005379, loss_ce: 0.001527
2021-11-30 15:14:25,313 iteration 4759 : loss : 0.006074, loss_ce: 0.001910
2021-11-30 15:14:25,313 Training Data Eval:
2021-11-30 15:14:32,256   Average segmentation loss on training set: 0.0050
2021-11-30 15:14:32,256 Validation Data Eval:
2021-11-30 15:14:34,631   Average segmentation loss on validation set: 0.1379
2021-11-30 15:14:35,852 iteration 4760 : loss : 0.004844, loss_ce: 0.002196
 70%|████████████████████▎        | 280/400 [1:46:09<48:27, 24.23s/it]2021-11-30 15:14:37,154 iteration 4761 : loss : 0.005660, loss_ce: 0.001913
2021-11-30 15:14:38,375 iteration 4762 : loss : 0.004606, loss_ce: 0.001795
2021-11-30 15:14:39,600 iteration 4763 : loss : 0.004791, loss_ce: 0.001787
2021-11-30 15:14:40,826 iteration 4764 : loss : 0.004474, loss_ce: 0.001568
2021-11-30 15:14:42,047 iteration 4765 : loss : 0.004926, loss_ce: 0.001655
2021-11-30 15:14:43,276 iteration 4766 : loss : 0.003970, loss_ce: 0.001251
2021-11-30 15:14:44,487 iteration 4767 : loss : 0.005008, loss_ce: 0.002301
2021-11-30 15:14:45,711 iteration 4768 : loss : 0.005665, loss_ce: 0.002354
2021-11-30 15:14:46,934 iteration 4769 : loss : 0.006287, loss_ce: 0.002286
2021-11-30 15:14:48,156 iteration 4770 : loss : 0.005340, loss_ce: 0.002115
2021-11-30 15:14:49,374 iteration 4771 : loss : 0.004881, loss_ce: 0.001606
2021-11-30 15:14:50,595 iteration 4772 : loss : 0.004593, loss_ce: 0.001864
2021-11-30 15:14:51,820 iteration 4773 : loss : 0.006773, loss_ce: 0.002962
2021-11-30 15:14:53,045 iteration 4774 : loss : 0.006295, loss_ce: 0.002429
2021-11-30 15:14:54,267 iteration 4775 : loss : 0.005405, loss_ce: 0.001829
2021-11-30 15:14:55,493 iteration 4776 : loss : 0.006079, loss_ce: 0.002890
2021-11-30 15:14:56,721 iteration 4777 : loss : 0.005083, loss_ce: 0.002351
 70%|████████████████████▎        | 281/400 [1:46:30<46:03, 23.22s/it]2021-11-30 15:14:58,014 iteration 4778 : loss : 0.003915, loss_ce: 0.001815
2021-11-30 15:14:59,240 iteration 4779 : loss : 0.004646, loss_ce: 0.002037
2021-11-30 15:15:00,464 iteration 4780 : loss : 0.004464, loss_ce: 0.001489
2021-11-30 15:15:01,684 iteration 4781 : loss : 0.007527, loss_ce: 0.002180
2021-11-30 15:15:02,911 iteration 4782 : loss : 0.005427, loss_ce: 0.002243
2021-11-30 15:15:04,133 iteration 4783 : loss : 0.005174, loss_ce: 0.001557
2021-11-30 15:15:05,350 iteration 4784 : loss : 0.005212, loss_ce: 0.001960
2021-11-30 15:15:06,565 iteration 4785 : loss : 0.004940, loss_ce: 0.002208
2021-11-30 15:15:07,780 iteration 4786 : loss : 0.005600, loss_ce: 0.002362
2021-11-30 15:15:09,003 iteration 4787 : loss : 0.006184, loss_ce: 0.002383
2021-11-30 15:15:10,223 iteration 4788 : loss : 0.005107, loss_ce: 0.002004
2021-11-30 15:15:11,450 iteration 4789 : loss : 0.006030, loss_ce: 0.002038
2021-11-30 15:15:12,664 iteration 4790 : loss : 0.005598, loss_ce: 0.002297
2021-11-30 15:15:13,883 iteration 4791 : loss : 0.005588, loss_ce: 0.002215
2021-11-30 15:15:15,103 iteration 4792 : loss : 0.004943, loss_ce: 0.002056
2021-11-30 15:15:16,320 iteration 4793 : loss : 0.004478, loss_ce: 0.002080
2021-11-30 15:15:17,542 iteration 4794 : loss : 0.005388, loss_ce: 0.001887
 70%|████████████████████▍        | 282/400 [1:46:51<44:15, 22.50s/it]2021-11-30 15:15:18,835 iteration 4795 : loss : 0.004524, loss_ce: 0.001351
2021-11-30 15:15:20,051 iteration 4796 : loss : 0.005527, loss_ce: 0.002968
2021-11-30 15:15:21,265 iteration 4797 : loss : 0.004960, loss_ce: 0.001395
2021-11-30 15:15:22,478 iteration 4798 : loss : 0.005467, loss_ce: 0.001681
2021-11-30 15:15:23,696 iteration 4799 : loss : 0.004582, loss_ce: 0.001792
2021-11-30 15:15:24,915 iteration 4800 : loss : 0.004692, loss_ce: 0.001632
2021-11-30 15:15:26,136 iteration 4801 : loss : 0.005758, loss_ce: 0.002970
2021-11-30 15:15:27,363 iteration 4802 : loss : 0.004629, loss_ce: 0.002501
2021-11-30 15:15:28,586 iteration 4803 : loss : 0.004409, loss_ce: 0.001811
2021-11-30 15:15:29,797 iteration 4804 : loss : 0.006383, loss_ce: 0.002846
2021-11-30 15:15:31,060 iteration 4805 : loss : 0.005969, loss_ce: 0.001880
2021-11-30 15:15:32,280 iteration 4806 : loss : 0.004803, loss_ce: 0.001845
2021-11-30 15:15:33,505 iteration 4807 : loss : 0.004584, loss_ce: 0.001527
2021-11-30 15:15:34,730 iteration 4808 : loss : 0.005889, loss_ce: 0.002088
2021-11-30 15:15:35,951 iteration 4809 : loss : 0.007115, loss_ce: 0.002208
2021-11-30 15:15:37,174 iteration 4810 : loss : 0.006038, loss_ce: 0.001672
2021-11-30 15:15:38,394 iteration 4811 : loss : 0.005005, loss_ce: 0.002066
 71%|████████████████████▌        | 283/400 [1:47:12<42:54, 22.00s/it]2021-11-30 15:15:39,679 iteration 4812 : loss : 0.006334, loss_ce: 0.001272
2021-11-30 15:15:40,902 iteration 4813 : loss : 0.005425, loss_ce: 0.002244
2021-11-30 15:15:42,118 iteration 4814 : loss : 0.004572, loss_ce: 0.001487
2021-11-30 15:15:43,342 iteration 4815 : loss : 0.004569, loss_ce: 0.001953
2021-11-30 15:15:44,565 iteration 4816 : loss : 0.005099, loss_ce: 0.002167
2021-11-30 15:15:45,781 iteration 4817 : loss : 0.004848, loss_ce: 0.001254
2021-11-30 15:15:47,004 iteration 4818 : loss : 0.004547, loss_ce: 0.002324
2021-11-30 15:15:48,224 iteration 4819 : loss : 0.006009, loss_ce: 0.002239
2021-11-30 15:15:49,439 iteration 4820 : loss : 0.006860, loss_ce: 0.002254
2021-11-30 15:15:50,662 iteration 4821 : loss : 0.005087, loss_ce: 0.001951
2021-11-30 15:15:51,880 iteration 4822 : loss : 0.004902, loss_ce: 0.002088
2021-11-30 15:15:53,101 iteration 4823 : loss : 0.005456, loss_ce: 0.001631
2021-11-30 15:15:54,320 iteration 4824 : loss : 0.005618, loss_ce: 0.002096
2021-11-30 15:15:55,549 iteration 4825 : loss : 0.005722, loss_ce: 0.001714
2021-11-30 15:15:56,768 iteration 4826 : loss : 0.006174, loss_ce: 0.003008
2021-11-30 15:15:57,995 iteration 4827 : loss : 0.005978, loss_ce: 0.002501
2021-11-30 15:15:59,217 iteration 4828 : loss : 0.004621, loss_ce: 0.001835
 71%|████████████████████▌        | 284/400 [1:47:33<41:51, 21.65s/it]2021-11-30 15:16:00,506 iteration 4829 : loss : 0.004594, loss_ce: 0.001662
2021-11-30 15:16:01,734 iteration 4830 : loss : 0.005125, loss_ce: 0.001926
2021-11-30 15:16:02,957 iteration 4831 : loss : 0.006377, loss_ce: 0.002670
2021-11-30 15:16:04,174 iteration 4832 : loss : 0.005052, loss_ce: 0.002048
2021-11-30 15:16:05,389 iteration 4833 : loss : 0.006551, loss_ce: 0.002068
2021-11-30 15:16:06,611 iteration 4834 : loss : 0.003873, loss_ce: 0.001404
2021-11-30 15:16:07,830 iteration 4835 : loss : 0.005491, loss_ce: 0.001557
2021-11-30 15:16:09,046 iteration 4836 : loss : 0.005998, loss_ce: 0.002611
2021-11-30 15:16:10,267 iteration 4837 : loss : 0.005129, loss_ce: 0.002167
2021-11-30 15:16:11,485 iteration 4838 : loss : 0.005045, loss_ce: 0.001234
2021-11-30 15:16:12,708 iteration 4839 : loss : 0.005330, loss_ce: 0.002344
2021-11-30 15:16:13,936 iteration 4840 : loss : 0.006459, loss_ce: 0.001927
2021-11-30 15:16:15,161 iteration 4841 : loss : 0.007108, loss_ce: 0.002522
2021-11-30 15:16:16,384 iteration 4842 : loss : 0.005088, loss_ce: 0.001758
2021-11-30 15:16:17,609 iteration 4843 : loss : 0.005473, loss_ce: 0.002279
2021-11-30 15:16:18,827 iteration 4844 : loss : 0.005564, loss_ce: 0.002219
2021-11-30 15:16:18,828 Training Data Eval:
2021-11-30 15:16:25,723   Average segmentation loss on training set: 0.0056
2021-11-30 15:16:25,723 Validation Data Eval:
2021-11-30 15:16:28,083   Average segmentation loss on validation set: 0.1418
2021-11-30 15:16:29,303 iteration 4845 : loss : 0.005401, loss_ce: 0.002206
 71%|████████████████████▋        | 285/400 [1:48:03<46:20, 24.18s/it]2021-11-30 15:16:30,579 iteration 4846 : loss : 0.005116, loss_ce: 0.002667
2021-11-30 15:16:31,796 iteration 4847 : loss : 0.008004, loss_ce: 0.003325
2021-11-30 15:16:33,005 iteration 4848 : loss : 0.005376, loss_ce: 0.002295
2021-11-30 15:16:34,228 iteration 4849 : loss : 0.006126, loss_ce: 0.002531
2021-11-30 15:16:35,452 iteration 4850 : loss : 0.008170, loss_ce: 0.002355
2021-11-30 15:16:36,676 iteration 4851 : loss : 0.005453, loss_ce: 0.001784
2021-11-30 15:16:37,890 iteration 4852 : loss : 0.004585, loss_ce: 0.001706
2021-11-30 15:16:39,108 iteration 4853 : loss : 0.005142, loss_ce: 0.001959
2021-11-30 15:16:40,333 iteration 4854 : loss : 0.004898, loss_ce: 0.001558
2021-11-30 15:16:41,554 iteration 4855 : loss : 0.006343, loss_ce: 0.002720
2021-11-30 15:16:42,769 iteration 4856 : loss : 0.005372, loss_ce: 0.001688
2021-11-30 15:16:43,988 iteration 4857 : loss : 0.004710, loss_ce: 0.001770
2021-11-30 15:16:45,207 iteration 4858 : loss : 0.005061, loss_ce: 0.002322
2021-11-30 15:16:46,425 iteration 4859 : loss : 0.005368, loss_ce: 0.001243
2021-11-30 15:16:47,639 iteration 4860 : loss : 0.005401, loss_ce: 0.002533
2021-11-30 15:16:48,861 iteration 4861 : loss : 0.007913, loss_ce: 0.002073
2021-11-30 15:16:50,078 iteration 4862 : loss : 0.003799, loss_ce: 0.001256
 72%|████████████████████▋        | 286/400 [1:48:24<44:00, 23.16s/it]2021-11-30 15:16:51,365 iteration 4863 : loss : 0.005210, loss_ce: 0.002099
2021-11-30 15:16:52,589 iteration 4864 : loss : 0.006420, loss_ce: 0.002150
2021-11-30 15:16:53,809 iteration 4865 : loss : 0.004712, loss_ce: 0.001960
2021-11-30 15:16:55,032 iteration 4866 : loss : 0.005623, loss_ce: 0.002152
2021-11-30 15:16:56,252 iteration 4867 : loss : 0.004935, loss_ce: 0.001749
2021-11-30 15:16:57,470 iteration 4868 : loss : 0.005499, loss_ce: 0.001405
2021-11-30 15:16:58,690 iteration 4869 : loss : 0.006658, loss_ce: 0.002164
2021-11-30 15:16:59,916 iteration 4870 : loss : 0.004438, loss_ce: 0.001738
2021-11-30 15:17:01,135 iteration 4871 : loss : 0.004495, loss_ce: 0.002056
2021-11-30 15:17:02,356 iteration 4872 : loss : 0.006739, loss_ce: 0.003000
2021-11-30 15:17:03,573 iteration 4873 : loss : 0.006135, loss_ce: 0.002826
2021-11-30 15:17:04,794 iteration 4874 : loss : 0.004324, loss_ce: 0.001330
2021-11-30 15:17:06,017 iteration 4875 : loss : 0.005753, loss_ce: 0.002261
2021-11-30 15:17:07,243 iteration 4876 : loss : 0.005410, loss_ce: 0.001675
2021-11-30 15:17:08,471 iteration 4877 : loss : 0.004818, loss_ce: 0.001907
2021-11-30 15:17:09,694 iteration 4878 : loss : 0.004844, loss_ce: 0.001843
2021-11-30 15:17:10,912 iteration 4879 : loss : 0.004655, loss_ce: 0.002206
 72%|████████████████████▊        | 287/400 [1:48:44<42:18, 22.46s/it]2021-11-30 15:17:12,193 iteration 4880 : loss : 0.004920, loss_ce: 0.002172
2021-11-30 15:17:13,414 iteration 4881 : loss : 0.004223, loss_ce: 0.001701
2021-11-30 15:17:14,636 iteration 4882 : loss : 0.005679, loss_ce: 0.002245
2021-11-30 15:17:15,857 iteration 4883 : loss : 0.004730, loss_ce: 0.002029
2021-11-30 15:17:17,082 iteration 4884 : loss : 0.006527, loss_ce: 0.001830
2021-11-30 15:17:18,311 iteration 4885 : loss : 0.003641, loss_ce: 0.001363
2021-11-30 15:17:19,548 iteration 4886 : loss : 0.005334, loss_ce: 0.001914
2021-11-30 15:17:20,759 iteration 4887 : loss : 0.006822, loss_ce: 0.002867
2021-11-30 15:17:21,987 iteration 4888 : loss : 0.005233, loss_ce: 0.002159
2021-11-30 15:17:23,209 iteration 4889 : loss : 0.017573, loss_ce: 0.005173
2021-11-30 15:17:24,436 iteration 4890 : loss : 0.005131, loss_ce: 0.002394
2021-11-30 15:17:25,659 iteration 4891 : loss : 0.007834, loss_ce: 0.003407
2021-11-30 15:17:26,882 iteration 4892 : loss : 0.006761, loss_ce: 0.002807
2021-11-30 15:17:28,111 iteration 4893 : loss : 0.006262, loss_ce: 0.002758
2021-11-30 15:17:29,337 iteration 4894 : loss : 0.007519, loss_ce: 0.002557
2021-11-30 15:17:30,567 iteration 4895 : loss : 0.015537, loss_ce: 0.010142
2021-11-30 15:17:31,792 iteration 4896 : loss : 0.009768, loss_ce: 0.004065
 72%|████████████████████▉        | 288/400 [1:49:05<41:02, 21.99s/it]2021-11-30 15:17:33,079 iteration 4897 : loss : 0.010183, loss_ce: 0.004755
2021-11-30 15:17:34,295 iteration 4898 : loss : 0.008082, loss_ce: 0.002725
2021-11-30 15:17:35,518 iteration 4899 : loss : 0.008585, loss_ce: 0.002694
2021-11-30 15:17:36,746 iteration 4900 : loss : 0.008312, loss_ce: 0.003914
2021-11-30 15:17:37,970 iteration 4901 : loss : 0.006598, loss_ce: 0.002681
2021-11-30 15:17:39,191 iteration 4902 : loss : 0.008488, loss_ce: 0.002957
2021-11-30 15:17:40,410 iteration 4903 : loss : 0.007346, loss_ce: 0.003375
2021-11-30 15:17:41,635 iteration 4904 : loss : 0.011068, loss_ce: 0.004868
2021-11-30 15:17:42,860 iteration 4905 : loss : 0.008010, loss_ce: 0.003062
2021-11-30 15:17:44,084 iteration 4906 : loss : 0.009348, loss_ce: 0.005320
2021-11-30 15:17:45,312 iteration 4907 : loss : 0.009507, loss_ce: 0.002935
2021-11-30 15:17:46,543 iteration 4908 : loss : 0.007783, loss_ce: 0.003490
2021-11-30 15:17:47,775 iteration 4909 : loss : 0.009386, loss_ce: 0.003332
2021-11-30 15:17:49,004 iteration 4910 : loss : 0.007350, loss_ce: 0.003198
2021-11-30 15:17:50,230 iteration 4911 : loss : 0.006378, loss_ce: 0.001922
2021-11-30 15:17:51,459 iteration 4912 : loss : 0.008502, loss_ce: 0.004452
2021-11-30 15:17:52,683 iteration 4913 : loss : 0.009766, loss_ce: 0.003248
 72%|████████████████████▉        | 289/400 [1:49:26<40:04, 21.66s/it]2021-11-30 15:17:53,975 iteration 4914 : loss : 0.006770, loss_ce: 0.002278
2021-11-30 15:17:55,201 iteration 4915 : loss : 0.006755, loss_ce: 0.002457
2021-11-30 15:17:56,431 iteration 4916 : loss : 0.006989, loss_ce: 0.003014
2021-11-30 15:17:57,656 iteration 4917 : loss : 0.007311, loss_ce: 0.002574
2021-11-30 15:17:58,881 iteration 4918 : loss : 0.008247, loss_ce: 0.003207
2021-11-30 15:18:00,098 iteration 4919 : loss : 0.007826, loss_ce: 0.004036
2021-11-30 15:18:01,320 iteration 4920 : loss : 0.007684, loss_ce: 0.002875
2021-11-30 15:18:02,544 iteration 4921 : loss : 0.007163, loss_ce: 0.002917
2021-11-30 15:18:03,768 iteration 4922 : loss : 0.008058, loss_ce: 0.003716
2021-11-30 15:18:04,989 iteration 4923 : loss : 0.006469, loss_ce: 0.002424
2021-11-30 15:18:06,206 iteration 4924 : loss : 0.005383, loss_ce: 0.002006
2021-11-30 15:18:07,425 iteration 4925 : loss : 0.006562, loss_ce: 0.002155
2021-11-30 15:18:08,648 iteration 4926 : loss : 0.007867, loss_ce: 0.003068
2021-11-30 15:18:09,874 iteration 4927 : loss : 0.007519, loss_ce: 0.002309
2021-11-30 15:18:11,096 iteration 4928 : loss : 0.005483, loss_ce: 0.002567
2021-11-30 15:18:12,313 iteration 4929 : loss : 0.006791, loss_ce: 0.002623
2021-11-30 15:18:12,314 Training Data Eval:
2021-11-30 15:18:19,227   Average segmentation loss on training set: 0.0066
2021-11-30 15:18:19,228 Validation Data Eval:
2021-11-30 15:18:21,601   Average segmentation loss on validation set: 0.1398
2021-11-30 15:18:22,827 iteration 4930 : loss : 0.006242, loss_ce: 0.002399
 72%|█████████████████████        | 290/400 [1:49:56<44:22, 24.20s/it]2021-11-30 15:18:24,124 iteration 4931 : loss : 0.005740, loss_ce: 0.001740
2021-11-30 15:18:25,352 iteration 4932 : loss : 0.006278, loss_ce: 0.003008
2021-11-30 15:18:26,575 iteration 4933 : loss : 0.006788, loss_ce: 0.003196
2021-11-30 15:18:27,797 iteration 4934 : loss : 0.006280, loss_ce: 0.001563
2021-11-30 15:18:29,014 iteration 4935 : loss : 0.005678, loss_ce: 0.001438
2021-11-30 15:18:30,294 iteration 4936 : loss : 0.006639, loss_ce: 0.003516
2021-11-30 15:18:31,512 iteration 4937 : loss : 0.006247, loss_ce: 0.003083
2021-11-30 15:18:32,725 iteration 4938 : loss : 0.008608, loss_ce: 0.002376
2021-11-30 15:18:33,941 iteration 4939 : loss : 0.005815, loss_ce: 0.002098
2021-11-30 15:18:35,173 iteration 4940 : loss : 0.009115, loss_ce: 0.003069
2021-11-30 15:18:36,395 iteration 4941 : loss : 0.006252, loss_ce: 0.002743
2021-11-30 15:18:37,616 iteration 4942 : loss : 0.007014, loss_ce: 0.003440
2021-11-30 15:18:38,832 iteration 4943 : loss : 0.005030, loss_ce: 0.001793
2021-11-30 15:18:40,051 iteration 4944 : loss : 0.004698, loss_ce: 0.001745
2021-11-30 15:18:41,266 iteration 4945 : loss : 0.004922, loss_ce: 0.001594
2021-11-30 15:18:42,489 iteration 4946 : loss : 0.007244, loss_ce: 0.001953
2021-11-30 15:18:43,711 iteration 4947 : loss : 0.006888, loss_ce: 0.002969
 73%|█████████████████████        | 291/400 [1:50:17<42:09, 23.21s/it]2021-11-30 15:18:45,000 iteration 4948 : loss : 0.007760, loss_ce: 0.002470
2021-11-30 15:18:46,214 iteration 4949 : loss : 0.006699, loss_ce: 0.002664
2021-11-30 15:18:47,434 iteration 4950 : loss : 0.005402, loss_ce: 0.001967
2021-11-30 15:18:48,661 iteration 4951 : loss : 0.005917, loss_ce: 0.002375
2021-11-30 15:18:49,866 iteration 4952 : loss : 0.007057, loss_ce: 0.002774
2021-11-30 15:18:51,088 iteration 4953 : loss : 0.005990, loss_ce: 0.002355
2021-11-30 15:18:52,314 iteration 4954 : loss : 0.005390, loss_ce: 0.002166
2021-11-30 15:18:53,527 iteration 4955 : loss : 0.006850, loss_ce: 0.002261
2021-11-30 15:18:54,744 iteration 4956 : loss : 0.006076, loss_ce: 0.001804
2021-11-30 15:18:55,969 iteration 4957 : loss : 0.005727, loss_ce: 0.002731
2021-11-30 15:18:57,188 iteration 4958 : loss : 0.005147, loss_ce: 0.001937
2021-11-30 15:18:58,405 iteration 4959 : loss : 0.007016, loss_ce: 0.003017
2021-11-30 15:18:59,616 iteration 4960 : loss : 0.006366, loss_ce: 0.002845
2021-11-30 15:19:00,841 iteration 4961 : loss : 0.007036, loss_ce: 0.002091
2021-11-30 15:19:02,057 iteration 4962 : loss : 0.007686, loss_ce: 0.002273
2021-11-30 15:19:03,286 iteration 4963 : loss : 0.005661, loss_ce: 0.002176
2021-11-30 15:19:04,508 iteration 4964 : loss : 0.006769, loss_ce: 0.002591
 73%|█████████████████████▏       | 292/400 [1:50:38<40:28, 22.48s/it]2021-11-30 15:19:05,794 iteration 4965 : loss : 0.006461, loss_ce: 0.003050
2021-11-30 15:19:07,014 iteration 4966 : loss : 0.006387, loss_ce: 0.002535
2021-11-30 15:19:08,245 iteration 4967 : loss : 0.006567, loss_ce: 0.002417
2021-11-30 15:19:09,468 iteration 4968 : loss : 0.006574, loss_ce: 0.002308
2021-11-30 15:19:10,684 iteration 4969 : loss : 0.004833, loss_ce: 0.001478
2021-11-30 15:19:11,908 iteration 4970 : loss : 0.004765, loss_ce: 0.001949
2021-11-30 15:19:13,124 iteration 4971 : loss : 0.005521, loss_ce: 0.002090
2021-11-30 15:19:14,348 iteration 4972 : loss : 0.004970, loss_ce: 0.001793
2021-11-30 15:19:15,575 iteration 4973 : loss : 0.004728, loss_ce: 0.002127
2021-11-30 15:19:16,800 iteration 4974 : loss : 0.005105, loss_ce: 0.001856
2021-11-30 15:19:18,027 iteration 4975 : loss : 0.005541, loss_ce: 0.001904
2021-11-30 15:19:19,248 iteration 4976 : loss : 0.004603, loss_ce: 0.001566
2021-11-30 15:19:20,471 iteration 4977 : loss : 0.005540, loss_ce: 0.002811
2021-11-30 15:19:21,697 iteration 4978 : loss : 0.005854, loss_ce: 0.001815
2021-11-30 15:19:22,919 iteration 4979 : loss : 0.008019, loss_ce: 0.003134
2021-11-30 15:19:24,135 iteration 4980 : loss : 0.004533, loss_ce: 0.001861
2021-11-30 15:19:25,360 iteration 4981 : loss : 0.005239, loss_ce: 0.002023
 73%|█████████████████████▏       | 293/400 [1:50:59<39:13, 22.00s/it]2021-11-30 15:19:26,649 iteration 4982 : loss : 0.006150, loss_ce: 0.001842
2021-11-30 15:19:27,871 iteration 4983 : loss : 0.003757, loss_ce: 0.001602
2021-11-30 15:19:29,093 iteration 4984 : loss : 0.005720, loss_ce: 0.002443
2021-11-30 15:19:30,316 iteration 4985 : loss : 0.004806, loss_ce: 0.001454
2021-11-30 15:19:31,536 iteration 4986 : loss : 0.005373, loss_ce: 0.002595
2021-11-30 15:19:32,751 iteration 4987 : loss : 0.004739, loss_ce: 0.001883
2021-11-30 15:19:33,969 iteration 4988 : loss : 0.005364, loss_ce: 0.001687
2021-11-30 15:19:35,189 iteration 4989 : loss : 0.004764, loss_ce: 0.001105
2021-11-30 15:19:36,410 iteration 4990 : loss : 0.004501, loss_ce: 0.001729
2021-11-30 15:19:37,629 iteration 4991 : loss : 0.004038, loss_ce: 0.001427
2021-11-30 15:19:38,846 iteration 4992 : loss : 0.005341, loss_ce: 0.001781
2021-11-30 15:19:40,070 iteration 4993 : loss : 0.005289, loss_ce: 0.001956
2021-11-30 15:19:41,291 iteration 4994 : loss : 0.004850, loss_ce: 0.002447
2021-11-30 15:19:42,512 iteration 4995 : loss : 0.004572, loss_ce: 0.002055
2021-11-30 15:19:43,733 iteration 4996 : loss : 0.005471, loss_ce: 0.001980
2021-11-30 15:19:44,959 iteration 4997 : loss : 0.005696, loss_ce: 0.002453
2021-11-30 15:19:46,179 iteration 4998 : loss : 0.006384, loss_ce: 0.002118
 74%|█████████████████████▎       | 294/400 [1:51:20<38:14, 21.64s/it]2021-11-30 15:19:47,466 iteration 4999 : loss : 0.004401, loss_ce: 0.001605
2021-11-30 15:19:48,682 iteration 5000 : loss : 0.004496, loss_ce: 0.001695
2021-11-30 15:19:49,906 iteration 5001 : loss : 0.006832, loss_ce: 0.003085
2021-11-30 15:19:51,121 iteration 5002 : loss : 0.005186, loss_ce: 0.001936
2021-11-30 15:19:52,336 iteration 5003 : loss : 0.005323, loss_ce: 0.001426
2021-11-30 15:19:53,555 iteration 5004 : loss : 0.004368, loss_ce: 0.001832
2021-11-30 15:19:54,775 iteration 5005 : loss : 0.004323, loss_ce: 0.001754
2021-11-30 15:19:56,004 iteration 5006 : loss : 0.004245, loss_ce: 0.001742
2021-11-30 15:19:57,225 iteration 5007 : loss : 0.005358, loss_ce: 0.001919
2021-11-30 15:19:58,439 iteration 5008 : loss : 0.006268, loss_ce: 0.002892
2021-11-30 15:19:59,656 iteration 5009 : loss : 0.005273, loss_ce: 0.002041
2021-11-30 15:20:00,894 iteration 5010 : loss : 0.006479, loss_ce: 0.001837
2021-11-30 15:20:02,117 iteration 5011 : loss : 0.005377, loss_ce: 0.002245
2021-11-30 15:20:03,329 iteration 5012 : loss : 0.006017, loss_ce: 0.001742
2021-11-30 15:20:04,558 iteration 5013 : loss : 0.006816, loss_ce: 0.002091
2021-11-30 15:20:05,785 iteration 5014 : loss : 0.005353, loss_ce: 0.001975
2021-11-30 15:20:05,785 Training Data Eval:
2021-11-30 15:20:12,743   Average segmentation loss on training set: 0.0067
2021-11-30 15:20:12,744 Validation Data Eval:
2021-11-30 15:20:15,111   Average segmentation loss on validation set: 0.1472
2021-11-30 15:20:16,336 iteration 5015 : loss : 0.004999, loss_ce: 0.002180
 74%|█████████████████████▍       | 295/400 [1:51:50<42:20, 24.20s/it]2021-11-30 15:20:17,630 iteration 5016 : loss : 0.005238, loss_ce: 0.001828
2021-11-30 15:20:18,853 iteration 5017 : loss : 0.004888, loss_ce: 0.001658
2021-11-30 15:20:20,072 iteration 5018 : loss : 0.004000, loss_ce: 0.001226
2021-11-30 15:20:21,294 iteration 5019 : loss : 0.004333, loss_ce: 0.002057
2021-11-30 15:20:22,515 iteration 5020 : loss : 0.009181, loss_ce: 0.002084
2021-11-30 15:20:23,741 iteration 5021 : loss : 0.005041, loss_ce: 0.001738
2021-11-30 15:20:24,964 iteration 5022 : loss : 0.004027, loss_ce: 0.001257
2021-11-30 15:20:26,191 iteration 5023 : loss : 0.006208, loss_ce: 0.002080
2021-11-30 15:20:27,417 iteration 5024 : loss : 0.007376, loss_ce: 0.003533
2021-11-30 15:20:28,639 iteration 5025 : loss : 0.006827, loss_ce: 0.002978
2021-11-30 15:20:29,857 iteration 5026 : loss : 0.005267, loss_ce: 0.002301
2021-11-30 15:20:31,082 iteration 5027 : loss : 0.003914, loss_ce: 0.001510
2021-11-30 15:20:32,313 iteration 5028 : loss : 0.005401, loss_ce: 0.001731
2021-11-30 15:20:33,534 iteration 5029 : loss : 0.005868, loss_ce: 0.001646
2021-11-30 15:20:34,760 iteration 5030 : loss : 0.006069, loss_ce: 0.002292
2021-11-30 15:20:35,988 iteration 5031 : loss : 0.004758, loss_ce: 0.002179
2021-11-30 15:20:37,215 iteration 5032 : loss : 0.005106, loss_ce: 0.002334
 74%|█████████████████████▍       | 296/400 [1:52:11<40:13, 23.20s/it]2021-11-30 15:20:38,511 iteration 5033 : loss : 0.004326, loss_ce: 0.001797
2021-11-30 15:20:39,731 iteration 5034 : loss : 0.006144, loss_ce: 0.003014
2021-11-30 15:20:40,955 iteration 5035 : loss : 0.004405, loss_ce: 0.001245
2021-11-30 15:20:42,180 iteration 5036 : loss : 0.004944, loss_ce: 0.002397
2021-11-30 15:20:43,404 iteration 5037 : loss : 0.005131, loss_ce: 0.001771
2021-11-30 15:20:44,619 iteration 5038 : loss : 0.004878, loss_ce: 0.002238
2021-11-30 15:20:45,843 iteration 5039 : loss : 0.008451, loss_ce: 0.002050
2021-11-30 15:20:47,072 iteration 5040 : loss : 0.004917, loss_ce: 0.001760
2021-11-30 15:20:48,309 iteration 5041 : loss : 0.005200, loss_ce: 0.001839
2021-11-30 15:20:49,524 iteration 5042 : loss : 0.005864, loss_ce: 0.002059
2021-11-30 15:20:50,746 iteration 5043 : loss : 0.005345, loss_ce: 0.002188
2021-11-30 15:20:51,971 iteration 5044 : loss : 0.005671, loss_ce: 0.002189
2021-11-30 15:20:53,194 iteration 5045 : loss : 0.005615, loss_ce: 0.002027
2021-11-30 15:20:54,411 iteration 5046 : loss : 0.006220, loss_ce: 0.002091
2021-11-30 15:20:55,632 iteration 5047 : loss : 0.005880, loss_ce: 0.002219
2021-11-30 15:20:56,845 iteration 5048 : loss : 0.005357, loss_ce: 0.001979
2021-11-30 15:20:58,065 iteration 5049 : loss : 0.006416, loss_ce: 0.002192
 74%|█████████████████████▌       | 297/400 [1:52:32<38:37, 22.50s/it]2021-11-30 15:20:59,361 iteration 5050 : loss : 0.005764, loss_ce: 0.001449
2021-11-30 15:21:00,587 iteration 5051 : loss : 0.005459, loss_ce: 0.001736
2021-11-30 15:21:01,807 iteration 5052 : loss : 0.005299, loss_ce: 0.002285
2021-11-30 15:21:03,029 iteration 5053 : loss : 0.004089, loss_ce: 0.001505
2021-11-30 15:21:04,256 iteration 5054 : loss : 0.005205, loss_ce: 0.001820
2021-11-30 15:21:05,482 iteration 5055 : loss : 0.005454, loss_ce: 0.002563
2021-11-30 15:21:06,707 iteration 5056 : loss : 0.005655, loss_ce: 0.002026
2021-11-30 15:21:07,945 iteration 5057 : loss : 0.006703, loss_ce: 0.002592
2021-11-30 15:21:09,161 iteration 5058 : loss : 0.004964, loss_ce: 0.001760
2021-11-30 15:21:10,388 iteration 5059 : loss : 0.004948, loss_ce: 0.002271
2021-11-30 15:21:11,610 iteration 5060 : loss : 0.005669, loss_ce: 0.002367
2021-11-30 15:21:12,835 iteration 5061 : loss : 0.006218, loss_ce: 0.002227
2021-11-30 15:21:14,053 iteration 5062 : loss : 0.004818, loss_ce: 0.001917
2021-11-30 15:21:15,278 iteration 5063 : loss : 0.004993, loss_ce: 0.002468
2021-11-30 15:21:16,498 iteration 5064 : loss : 0.005426, loss_ce: 0.001595
2021-11-30 15:21:17,725 iteration 5065 : loss : 0.005542, loss_ce: 0.001286
2021-11-30 15:21:18,949 iteration 5066 : loss : 0.004755, loss_ce: 0.001650
 74%|█████████████████████▌       | 298/400 [1:52:53<37:25, 22.01s/it]2021-11-30 15:21:20,239 iteration 5067 : loss : 0.006384, loss_ce: 0.003049
2021-11-30 15:21:21,462 iteration 5068 : loss : 0.005245, loss_ce: 0.001849
2021-11-30 15:21:22,691 iteration 5069 : loss : 0.004681, loss_ce: 0.001927
2021-11-30 15:21:23,915 iteration 5070 : loss : 0.004534, loss_ce: 0.001487
2021-11-30 15:21:25,135 iteration 5071 : loss : 0.004834, loss_ce: 0.001583
2021-11-30 15:21:26,356 iteration 5072 : loss : 0.004426, loss_ce: 0.001621
2021-11-30 15:21:27,579 iteration 5073 : loss : 0.004891, loss_ce: 0.001297
2021-11-30 15:21:28,802 iteration 5074 : loss : 0.003831, loss_ce: 0.001192
2021-11-30 15:21:30,032 iteration 5075 : loss : 0.006234, loss_ce: 0.002025
2021-11-30 15:21:31,252 iteration 5076 : loss : 0.004855, loss_ce: 0.001992
2021-11-30 15:21:32,471 iteration 5077 : loss : 0.005833, loss_ce: 0.002552
2021-11-30 15:21:33,703 iteration 5078 : loss : 0.005507, loss_ce: 0.002197
2021-11-30 15:21:34,927 iteration 5079 : loss : 0.006951, loss_ce: 0.002033
2021-11-30 15:21:36,155 iteration 5080 : loss : 0.005044, loss_ce: 0.002123
2021-11-30 15:21:37,386 iteration 5081 : loss : 0.004540, loss_ce: 0.001495
2021-11-30 15:21:38,614 iteration 5082 : loss : 0.006411, loss_ce: 0.003019
2021-11-30 15:21:39,844 iteration 5083 : loss : 0.005537, loss_ce: 0.001979
 75%|█████████████████████▋       | 299/400 [1:53:13<36:29, 21.68s/it]2021-11-30 15:21:41,135 iteration 5084 : loss : 0.005318, loss_ce: 0.002208
2021-11-30 15:21:42,350 iteration 5085 : loss : 0.003827, loss_ce: 0.001084
2021-11-30 15:21:43,576 iteration 5086 : loss : 0.004660, loss_ce: 0.002114
2021-11-30 15:21:44,802 iteration 5087 : loss : 0.007501, loss_ce: 0.002164
2021-11-30 15:21:46,030 iteration 5088 : loss : 0.005612, loss_ce: 0.001806
2021-11-30 15:21:47,254 iteration 5089 : loss : 0.004748, loss_ce: 0.001714
2021-11-30 15:21:48,485 iteration 5090 : loss : 0.004586, loss_ce: 0.002006
2021-11-30 15:21:49,710 iteration 5091 : loss : 0.005068, loss_ce: 0.001512
2021-11-30 15:21:50,932 iteration 5092 : loss : 0.005226, loss_ce: 0.002064
2021-11-30 15:21:52,154 iteration 5093 : loss : 0.004048, loss_ce: 0.001764
2021-11-30 15:21:53,378 iteration 5094 : loss : 0.006133, loss_ce: 0.001755
2021-11-30 15:21:54,604 iteration 5095 : loss : 0.005026, loss_ce: 0.002566
2021-11-30 15:21:55,824 iteration 5096 : loss : 0.005085, loss_ce: 0.002335
2021-11-30 15:21:57,042 iteration 5097 : loss : 0.006769, loss_ce: 0.002588
2021-11-30 15:21:58,264 iteration 5098 : loss : 0.005510, loss_ce: 0.002067
2021-11-30 15:21:59,483 iteration 5099 : loss : 0.004271, loss_ce: 0.001316
2021-11-30 15:21:59,483 Training Data Eval:
2021-11-30 15:22:06,416   Average segmentation loss on training set: 0.0048
2021-11-30 15:22:06,416 Validation Data Eval:
2021-11-30 15:22:08,807   Average segmentation loss on validation set: 0.1275
2021-11-30 15:22:10,036 iteration 5100 : loss : 0.005351, loss_ce: 0.002389
 75%|█████████████████████▊       | 300/400 [1:53:44<40:23, 24.23s/it]2021-11-30 15:22:11,328 iteration 5101 : loss : 0.006555, loss_ce: 0.002724
2021-11-30 15:22:12,557 iteration 5102 : loss : 0.006462, loss_ce: 0.002225
2021-11-30 15:22:13,785 iteration 5103 : loss : 0.005409, loss_ce: 0.001225
2021-11-30 15:22:15,008 iteration 5104 : loss : 0.004527, loss_ce: 0.001627
2021-11-30 15:22:16,228 iteration 5105 : loss : 0.005432, loss_ce: 0.002611
2021-11-30 15:22:17,451 iteration 5106 : loss : 0.004249, loss_ce: 0.001232
2021-11-30 15:22:18,672 iteration 5107 : loss : 0.005308, loss_ce: 0.002316
2021-11-30 15:22:19,895 iteration 5108 : loss : 0.005362, loss_ce: 0.002446
2021-11-30 15:22:21,120 iteration 5109 : loss : 0.004369, loss_ce: 0.001516
2021-11-30 15:22:22,339 iteration 5110 : loss : 0.004249, loss_ce: 0.001715
2021-11-30 15:22:23,558 iteration 5111 : loss : 0.004514, loss_ce: 0.001773
2021-11-30 15:22:24,775 iteration 5112 : loss : 0.004288, loss_ce: 0.001888
2021-11-30 15:22:25,997 iteration 5113 : loss : 0.005164, loss_ce: 0.001846
2021-11-30 15:22:27,227 iteration 5114 : loss : 0.006192, loss_ce: 0.001493
2021-11-30 15:22:28,446 iteration 5115 : loss : 0.005217, loss_ce: 0.002369
2021-11-30 15:22:29,668 iteration 5116 : loss : 0.004312, loss_ce: 0.001576
2021-11-30 15:22:30,885 iteration 5117 : loss : 0.003751, loss_ce: 0.001592
 75%|█████████████████████▊       | 301/400 [1:54:04<38:18, 23.22s/it]2021-11-30 15:22:32,203 iteration 5118 : loss : 0.004943, loss_ce: 0.002279
2021-11-30 15:22:33,428 iteration 5119 : loss : 0.004188, loss_ce: 0.001827
2021-11-30 15:22:34,651 iteration 5120 : loss : 0.005171, loss_ce: 0.001953
2021-11-30 15:22:35,874 iteration 5121 : loss : 0.005729, loss_ce: 0.002441
2021-11-30 15:22:37,098 iteration 5122 : loss : 0.005633, loss_ce: 0.001468
2021-11-30 15:22:38,321 iteration 5123 : loss : 0.006030, loss_ce: 0.002211
2021-11-30 15:22:39,544 iteration 5124 : loss : 0.004852, loss_ce: 0.001596
2021-11-30 15:22:40,766 iteration 5125 : loss : 0.005995, loss_ce: 0.002531
2021-11-30 15:22:41,986 iteration 5126 : loss : 0.004341, loss_ce: 0.001839
2021-11-30 15:22:43,190 iteration 5127 : loss : 0.004662, loss_ce: 0.001965
2021-11-30 15:22:44,411 iteration 5128 : loss : 0.005506, loss_ce: 0.002489
2021-11-30 15:22:45,639 iteration 5129 : loss : 0.005358, loss_ce: 0.001984
2021-11-30 15:22:46,860 iteration 5130 : loss : 0.003713, loss_ce: 0.001599
2021-11-30 15:22:48,086 iteration 5131 : loss : 0.004977, loss_ce: 0.001615
2021-11-30 15:22:49,312 iteration 5132 : loss : 0.005375, loss_ce: 0.001982
2021-11-30 15:22:50,538 iteration 5133 : loss : 0.004724, loss_ce: 0.001478
2021-11-30 15:22:51,753 iteration 5134 : loss : 0.005712, loss_ce: 0.001589
 76%|█████████████████████▉       | 302/400 [1:54:25<36:46, 22.51s/it]2021-11-30 15:22:53,046 iteration 5135 : loss : 0.004333, loss_ce: 0.001876
2021-11-30 15:22:54,269 iteration 5136 : loss : 0.004726, loss_ce: 0.002172
2021-11-30 15:22:55,493 iteration 5137 : loss : 0.004714, loss_ce: 0.001440
2021-11-30 15:22:56,718 iteration 5138 : loss : 0.005311, loss_ce: 0.002252
2021-11-30 15:22:57,937 iteration 5139 : loss : 0.005220, loss_ce: 0.002286
2021-11-30 15:22:59,156 iteration 5140 : loss : 0.004858, loss_ce: 0.001696
2021-11-30 15:23:00,382 iteration 5141 : loss : 0.004224, loss_ce: 0.001819
2021-11-30 15:23:01,608 iteration 5142 : loss : 0.004837, loss_ce: 0.001629
2021-11-30 15:23:02,835 iteration 5143 : loss : 0.004834, loss_ce: 0.001467
2021-11-30 15:23:04,064 iteration 5144 : loss : 0.004314, loss_ce: 0.001865
2021-11-30 15:23:05,290 iteration 5145 : loss : 0.005518, loss_ce: 0.001895
2021-11-30 15:23:06,521 iteration 5146 : loss : 0.005917, loss_ce: 0.002241
2021-11-30 15:23:07,746 iteration 5147 : loss : 0.004189, loss_ce: 0.001745
2021-11-30 15:23:08,972 iteration 5148 : loss : 0.005300, loss_ce: 0.002158
2021-11-30 15:23:10,189 iteration 5149 : loss : 0.004025, loss_ce: 0.001550
2021-11-30 15:23:11,416 iteration 5150 : loss : 0.004627, loss_ce: 0.002076
2021-11-30 15:23:12,639 iteration 5151 : loss : 0.003977, loss_ce: 0.001250
 76%|█████████████████████▉       | 303/400 [1:54:46<35:36, 22.02s/it]2021-11-30 15:23:13,931 iteration 5152 : loss : 0.005675, loss_ce: 0.002312
2021-11-30 15:23:15,157 iteration 5153 : loss : 0.004957, loss_ce: 0.001608
2021-11-30 15:23:16,389 iteration 5154 : loss : 0.003731, loss_ce: 0.001346
2021-11-30 15:23:17,612 iteration 5155 : loss : 0.004733, loss_ce: 0.001815
2021-11-30 15:23:18,838 iteration 5156 : loss : 0.004671, loss_ce: 0.002104
2021-11-30 15:23:20,059 iteration 5157 : loss : 0.006401, loss_ce: 0.001309
2021-11-30 15:23:21,288 iteration 5158 : loss : 0.005231, loss_ce: 0.001791
2021-11-30 15:23:22,516 iteration 5159 : loss : 0.005677, loss_ce: 0.002224
2021-11-30 15:23:23,739 iteration 5160 : loss : 0.005253, loss_ce: 0.001716
2021-11-30 15:23:24,966 iteration 5161 : loss : 0.005605, loss_ce: 0.002397
2021-11-30 15:23:26,189 iteration 5162 : loss : 0.007725, loss_ce: 0.001399
2021-11-30 15:23:27,414 iteration 5163 : loss : 0.003728, loss_ce: 0.001571
2021-11-30 15:23:28,635 iteration 5164 : loss : 0.005148, loss_ce: 0.002227
2021-11-30 15:23:29,858 iteration 5165 : loss : 0.006055, loss_ce: 0.001523
2021-11-30 15:23:31,089 iteration 5166 : loss : 0.005890, loss_ce: 0.003091
2021-11-30 15:23:32,312 iteration 5167 : loss : 0.005141, loss_ce: 0.001629
2021-11-30 15:23:33,540 iteration 5168 : loss : 0.004507, loss_ce: 0.002018
 76%|██████████████████████       | 304/400 [1:55:07<34:42, 21.69s/it]2021-11-30 15:23:34,832 iteration 5169 : loss : 0.004446, loss_ce: 0.001748
2021-11-30 15:23:36,052 iteration 5170 : loss : 0.005685, loss_ce: 0.002072
2021-11-30 15:23:37,267 iteration 5171 : loss : 0.004872, loss_ce: 0.002500
2021-11-30 15:23:38,488 iteration 5172 : loss : 0.007053, loss_ce: 0.002745
2021-11-30 15:23:39,714 iteration 5173 : loss : 0.005123, loss_ce: 0.001821
2021-11-30 15:23:40,945 iteration 5174 : loss : 0.005476, loss_ce: 0.001916
2021-11-30 15:23:42,169 iteration 5175 : loss : 0.004597, loss_ce: 0.001035
2021-11-30 15:23:43,390 iteration 5176 : loss : 0.004696, loss_ce: 0.001465
2021-11-30 15:23:44,619 iteration 5177 : loss : 0.004752, loss_ce: 0.001178
2021-11-30 15:23:45,845 iteration 5178 : loss : 0.005156, loss_ce: 0.002214
2021-11-30 15:23:47,064 iteration 5179 : loss : 0.003977, loss_ce: 0.001811
2021-11-30 15:23:48,290 iteration 5180 : loss : 0.006511, loss_ce: 0.001799
2021-11-30 15:23:49,502 iteration 5181 : loss : 0.005276, loss_ce: 0.001690
2021-11-30 15:23:50,724 iteration 5182 : loss : 0.005688, loss_ce: 0.002098
2021-11-30 15:23:51,947 iteration 5183 : loss : 0.005144, loss_ce: 0.001929
2021-11-30 15:23:53,169 iteration 5184 : loss : 0.005199, loss_ce: 0.001937
2021-11-30 15:23:53,169 Training Data Eval:
2021-11-30 15:24:00,099   Average segmentation loss on training set: 0.0060
2021-11-30 15:24:00,100 Validation Data Eval:
2021-11-30 15:24:02,480   Average segmentation loss on validation set: 0.1331
2021-11-30 15:24:03,694 iteration 5185 : loss : 0.005833, loss_ce: 0.002677
 76%|██████████████████████       | 305/400 [1:55:37<38:21, 24.23s/it]2021-11-30 15:24:04,993 iteration 5186 : loss : 0.005281, loss_ce: 0.001535
2021-11-30 15:24:06,213 iteration 5187 : loss : 0.005650, loss_ce: 0.002085
2021-11-30 15:24:07,440 iteration 5188 : loss : 0.004493, loss_ce: 0.002105
2021-11-30 15:24:08,662 iteration 5189 : loss : 0.003998, loss_ce: 0.001345
2021-11-30 15:24:09,877 iteration 5190 : loss : 0.004442, loss_ce: 0.001621
2021-11-30 15:24:11,102 iteration 5191 : loss : 0.004895, loss_ce: 0.001909
2021-11-30 15:24:12,325 iteration 5192 : loss : 0.004428, loss_ce: 0.001725
2021-11-30 15:24:13,551 iteration 5193 : loss : 0.005515, loss_ce: 0.002654
2021-11-30 15:24:14,776 iteration 5194 : loss : 0.005160, loss_ce: 0.002090
2021-11-30 15:24:16,004 iteration 5195 : loss : 0.004736, loss_ce: 0.001915
2021-11-30 15:24:17,235 iteration 5196 : loss : 0.005024, loss_ce: 0.002148
2021-11-30 15:24:18,459 iteration 5197 : loss : 0.005085, loss_ce: 0.001934
2021-11-30 15:24:19,680 iteration 5198 : loss : 0.004844, loss_ce: 0.001632
2021-11-30 15:24:20,908 iteration 5199 : loss : 0.005538, loss_ce: 0.001633
2021-11-30 15:24:22,135 iteration 5200 : loss : 0.005520, loss_ce: 0.001996
2021-11-30 15:24:23,364 iteration 5201 : loss : 0.005040, loss_ce: 0.001466
2021-11-30 15:24:24,578 iteration 5202 : loss : 0.003912, loss_ce: 0.001399
 76%|██████████████████████▏      | 306/400 [1:55:58<36:23, 23.22s/it]2021-11-30 15:24:25,872 iteration 5203 : loss : 0.004652, loss_ce: 0.001955
2021-11-30 15:24:27,091 iteration 5204 : loss : 0.004372, loss_ce: 0.002376
2021-11-30 15:24:28,312 iteration 5205 : loss : 0.005388, loss_ce: 0.002558
2021-11-30 15:24:29,551 iteration 5206 : loss : 0.005448, loss_ce: 0.001515
2021-11-30 15:24:30,777 iteration 5207 : loss : 0.004165, loss_ce: 0.001684
2021-11-30 15:24:32,001 iteration 5208 : loss : 0.006108, loss_ce: 0.002698
2021-11-30 15:24:33,228 iteration 5209 : loss : 0.004904, loss_ce: 0.000827
2021-11-30 15:24:34,457 iteration 5210 : loss : 0.005392, loss_ce: 0.002132
2021-11-30 15:24:35,677 iteration 5211 : loss : 0.004437, loss_ce: 0.001548
2021-11-30 15:24:36,901 iteration 5212 : loss : 0.005016, loss_ce: 0.001982
2021-11-30 15:24:38,120 iteration 5213 : loss : 0.004139, loss_ce: 0.001854
2021-11-30 15:24:39,343 iteration 5214 : loss : 0.009472, loss_ce: 0.002218
2021-11-30 15:24:40,571 iteration 5215 : loss : 0.004803, loss_ce: 0.001706
2021-11-30 15:24:41,792 iteration 5216 : loss : 0.003967, loss_ce: 0.001525
2021-11-30 15:24:43,014 iteration 5217 : loss : 0.004720, loss_ce: 0.001995
2021-11-30 15:24:44,240 iteration 5218 : loss : 0.004837, loss_ce: 0.001821
2021-11-30 15:24:45,464 iteration 5219 : loss : 0.004159, loss_ce: 0.001285
 77%|██████████████████████▎      | 307/400 [1:56:19<34:54, 22.52s/it]2021-11-30 15:24:46,763 iteration 5220 : loss : 0.004837, loss_ce: 0.002173
2021-11-30 15:24:47,987 iteration 5221 : loss : 0.004142, loss_ce: 0.001474
2021-11-30 15:24:49,214 iteration 5222 : loss : 0.004704, loss_ce: 0.002268
2021-11-30 15:24:50,446 iteration 5223 : loss : 0.006182, loss_ce: 0.001400
2021-11-30 15:24:51,670 iteration 5224 : loss : 0.003753, loss_ce: 0.001458
2021-11-30 15:24:52,894 iteration 5225 : loss : 0.004864, loss_ce: 0.001859
2021-11-30 15:24:54,121 iteration 5226 : loss : 0.004244, loss_ce: 0.002103
2021-11-30 15:24:55,347 iteration 5227 : loss : 0.003314, loss_ce: 0.001281
2021-11-30 15:24:56,575 iteration 5228 : loss : 0.005524, loss_ce: 0.002290
2021-11-30 15:24:57,798 iteration 5229 : loss : 0.003715, loss_ce: 0.001572
2021-11-30 15:24:59,025 iteration 5230 : loss : 0.005917, loss_ce: 0.001638
2021-11-30 15:25:00,251 iteration 5231 : loss : 0.006130, loss_ce: 0.001956
2021-11-30 15:25:01,472 iteration 5232 : loss : 0.004614, loss_ce: 0.001929
2021-11-30 15:25:02,694 iteration 5233 : loss : 0.004781, loss_ce: 0.001931
2021-11-30 15:25:03,921 iteration 5234 : loss : 0.004484, loss_ce: 0.001642
2021-11-30 15:25:05,148 iteration 5235 : loss : 0.003516, loss_ce: 0.001272
2021-11-30 15:25:06,371 iteration 5236 : loss : 0.003893, loss_ce: 0.001446
 77%|██████████████████████▎      | 308/400 [1:56:40<33:47, 22.04s/it]2021-11-30 15:25:07,668 iteration 5237 : loss : 0.005322, loss_ce: 0.002260
2021-11-30 15:25:08,896 iteration 5238 : loss : 0.004964, loss_ce: 0.001556
2021-11-30 15:25:10,128 iteration 5239 : loss : 0.004517, loss_ce: 0.002108
2021-11-30 15:25:11,355 iteration 5240 : loss : 0.004072, loss_ce: 0.001703
2021-11-30 15:25:12,578 iteration 5241 : loss : 0.004435, loss_ce: 0.001896
2021-11-30 15:25:13,808 iteration 5242 : loss : 0.004524, loss_ce: 0.001764
2021-11-30 15:25:15,026 iteration 5243 : loss : 0.004961, loss_ce: 0.001596
2021-11-30 15:25:16,249 iteration 5244 : loss : 0.004530, loss_ce: 0.001097
2021-11-30 15:25:17,467 iteration 5245 : loss : 0.004775, loss_ce: 0.001805
2021-11-30 15:25:18,692 iteration 5246 : loss : 0.005315, loss_ce: 0.002813
2021-11-30 15:25:19,913 iteration 5247 : loss : 0.007017, loss_ce: 0.001922
2021-11-30 15:25:21,148 iteration 5248 : loss : 0.004324, loss_ce: 0.001715
2021-11-30 15:25:22,374 iteration 5249 : loss : 0.004107, loss_ce: 0.001823
2021-11-30 15:25:23,598 iteration 5250 : loss : 0.003636, loss_ce: 0.000893
2021-11-30 15:25:24,828 iteration 5251 : loss : 0.004493, loss_ce: 0.001599
2021-11-30 15:25:26,059 iteration 5252 : loss : 0.003404, loss_ce: 0.001396
2021-11-30 15:25:27,286 iteration 5253 : loss : 0.004733, loss_ce: 0.001759
 77%|██████████████████████▍      | 309/400 [1:57:01<32:54, 21.70s/it]2021-11-30 15:25:28,584 iteration 5254 : loss : 0.005443, loss_ce: 0.001918
2021-11-30 15:25:29,808 iteration 5255 : loss : 0.005245, loss_ce: 0.001805
2021-11-30 15:25:31,034 iteration 5256 : loss : 0.006999, loss_ce: 0.001982
2021-11-30 15:25:32,262 iteration 5257 : loss : 0.004631, loss_ce: 0.001816
2021-11-30 15:25:33,489 iteration 5258 : loss : 0.003307, loss_ce: 0.001031
2021-11-30 15:25:34,714 iteration 5259 : loss : 0.004859, loss_ce: 0.002103
2021-11-30 15:25:35,946 iteration 5260 : loss : 0.005382, loss_ce: 0.002626
2021-11-30 15:25:37,176 iteration 5261 : loss : 0.004048, loss_ce: 0.001339
2021-11-30 15:25:38,406 iteration 5262 : loss : 0.003991, loss_ce: 0.001471
2021-11-30 15:25:39,635 iteration 5263 : loss : 0.004639, loss_ce: 0.001677
2021-11-30 15:25:40,863 iteration 5264 : loss : 0.004908, loss_ce: 0.001707
2021-11-30 15:25:42,087 iteration 5265 : loss : 0.005122, loss_ce: 0.002221
2021-11-30 15:25:43,312 iteration 5266 : loss : 0.004835, loss_ce: 0.002732
2021-11-30 15:25:44,540 iteration 5267 : loss : 0.004978, loss_ce: 0.001778
2021-11-30 15:25:45,770 iteration 5268 : loss : 0.005370, loss_ce: 0.002230
2021-11-30 15:25:47,001 iteration 5269 : loss : 0.003946, loss_ce: 0.001645
2021-11-30 15:25:47,001 Training Data Eval:
2021-11-30 15:25:53,961   Average segmentation loss on training set: 0.0052
2021-11-30 15:25:53,961 Validation Data Eval:
2021-11-30 15:25:56,346   Average segmentation loss on validation set: 0.1387
2021-11-30 15:25:57,570 iteration 5270 : loss : 0.004478, loss_ce: 0.001793
 78%|██████████████████████▍      | 310/400 [1:57:31<36:24, 24.27s/it]2021-11-30 15:25:58,862 iteration 5271 : loss : 0.004181, loss_ce: 0.001464
2021-11-30 15:26:00,084 iteration 5272 : loss : 0.004487, loss_ce: 0.001423
2021-11-30 15:26:01,305 iteration 5273 : loss : 0.003898, loss_ce: 0.001348
2021-11-30 15:26:02,531 iteration 5274 : loss : 0.004790, loss_ce: 0.002313
2021-11-30 15:26:03,764 iteration 5275 : loss : 0.004852, loss_ce: 0.001697
2021-11-30 15:26:04,992 iteration 5276 : loss : 0.005367, loss_ce: 0.002116
2021-11-30 15:26:06,214 iteration 5277 : loss : 0.003994, loss_ce: 0.001530
2021-11-30 15:26:07,446 iteration 5278 : loss : 0.004827, loss_ce: 0.001796
2021-11-30 15:26:08,668 iteration 5279 : loss : 0.004653, loss_ce: 0.001268
2021-11-30 15:26:09,898 iteration 5280 : loss : 0.004508, loss_ce: 0.001988
2021-11-30 15:26:11,121 iteration 5281 : loss : 0.005452, loss_ce: 0.001731
2021-11-30 15:26:12,349 iteration 5282 : loss : 0.004017, loss_ce: 0.001762
2021-11-30 15:26:13,570 iteration 5283 : loss : 0.003579, loss_ce: 0.001896
2021-11-30 15:26:14,794 iteration 5284 : loss : 0.004194, loss_ce: 0.001107
2021-11-30 15:26:16,020 iteration 5285 : loss : 0.004337, loss_ce: 0.001775
2021-11-30 15:26:17,252 iteration 5286 : loss : 0.003873, loss_ce: 0.002177
2021-11-30 15:26:18,474 iteration 5287 : loss : 0.005105, loss_ce: 0.001792
 78%|██████████████████████▌      | 311/400 [1:57:52<34:30, 23.27s/it]2021-11-30 15:26:19,776 iteration 5288 : loss : 0.004637, loss_ce: 0.002104
2021-11-30 15:26:21,001 iteration 5289 : loss : 0.004447, loss_ce: 0.002081
2021-11-30 15:26:22,228 iteration 5290 : loss : 0.004847, loss_ce: 0.001568
2021-11-30 15:26:23,457 iteration 5291 : loss : 0.005114, loss_ce: 0.002243
2021-11-30 15:26:24,685 iteration 5292 : loss : 0.003653, loss_ce: 0.001532
2021-11-30 15:26:25,911 iteration 5293 : loss : 0.003767, loss_ce: 0.001331
2021-11-30 15:26:27,135 iteration 5294 : loss : 0.005159, loss_ce: 0.001832
2021-11-30 15:26:28,359 iteration 5295 : loss : 0.004825, loss_ce: 0.002234
2021-11-30 15:26:29,582 iteration 5296 : loss : 0.003632, loss_ce: 0.001152
2021-11-30 15:26:30,808 iteration 5297 : loss : 0.003766, loss_ce: 0.001389
2021-11-30 15:26:32,033 iteration 5298 : loss : 0.005352, loss_ce: 0.001721
2021-11-30 15:26:33,259 iteration 5299 : loss : 0.003822, loss_ce: 0.001558
2021-11-30 15:26:34,482 iteration 5300 : loss : 0.003894, loss_ce: 0.001305
2021-11-30 15:26:35,702 iteration 5301 : loss : 0.003431, loss_ce: 0.001123
2021-11-30 15:26:36,919 iteration 5302 : loss : 0.004404, loss_ce: 0.001848
2021-11-30 15:26:38,147 iteration 5303 : loss : 0.003630, loss_ce: 0.001537
2021-11-30 15:26:39,367 iteration 5304 : loss : 0.003809, loss_ce: 0.001235
 78%|██████████████████████▌      | 312/400 [1:58:13<33:04, 22.55s/it]2021-11-30 15:26:40,660 iteration 5305 : loss : 0.004338, loss_ce: 0.001195
2021-11-30 15:26:41,895 iteration 5306 : loss : 0.004846, loss_ce: 0.002022
2021-11-30 15:26:43,120 iteration 5307 : loss : 0.003826, loss_ce: 0.001406
2021-11-30 15:26:44,351 iteration 5308 : loss : 0.003859, loss_ce: 0.001722
2021-11-30 15:26:45,572 iteration 5309 : loss : 0.004403, loss_ce: 0.002026
2021-11-30 15:26:46,800 iteration 5310 : loss : 0.004222, loss_ce: 0.001361
2021-11-30 15:26:48,029 iteration 5311 : loss : 0.004495, loss_ce: 0.001566
2021-11-30 15:26:49,255 iteration 5312 : loss : 0.004578, loss_ce: 0.001612
2021-11-30 15:26:50,482 iteration 5313 : loss : 0.005360, loss_ce: 0.002225
2021-11-30 15:26:51,706 iteration 5314 : loss : 0.004146, loss_ce: 0.001766
2021-11-30 15:26:52,933 iteration 5315 : loss : 0.003456, loss_ce: 0.001288
2021-11-30 15:26:54,162 iteration 5316 : loss : 0.004356, loss_ce: 0.002351
2021-11-30 15:26:55,387 iteration 5317 : loss : 0.003319, loss_ce: 0.001361
2021-11-30 15:26:56,613 iteration 5318 : loss : 0.005875, loss_ce: 0.001840
2021-11-30 15:26:57,835 iteration 5319 : loss : 0.003879, loss_ce: 0.001812
2021-11-30 15:26:59,066 iteration 5320 : loss : 0.004192, loss_ce: 0.001185
2021-11-30 15:27:00,295 iteration 5321 : loss : 0.005068, loss_ce: 0.001297
 78%|██████████████████████▋      | 313/400 [1:58:34<31:59, 22.07s/it]2021-11-30 15:27:01,596 iteration 5322 : loss : 0.004063, loss_ce: 0.000880
2021-11-30 15:27:02,824 iteration 5323 : loss : 0.005869, loss_ce: 0.001717
2021-11-30 15:27:04,051 iteration 5324 : loss : 0.004501, loss_ce: 0.002224
2021-11-30 15:27:05,281 iteration 5325 : loss : 0.006204, loss_ce: 0.002213
2021-11-30 15:27:06,509 iteration 5326 : loss : 0.005228, loss_ce: 0.001964
2021-11-30 15:27:07,740 iteration 5327 : loss : 0.004003, loss_ce: 0.001399
2021-11-30 15:27:08,970 iteration 5328 : loss : 0.004704, loss_ce: 0.001708
2021-11-30 15:27:10,199 iteration 5329 : loss : 0.005138, loss_ce: 0.002032
2021-11-30 15:27:11,424 iteration 5330 : loss : 0.003871, loss_ce: 0.001764
2021-11-30 15:27:12,654 iteration 5331 : loss : 0.004336, loss_ce: 0.001238
2021-11-30 15:27:13,875 iteration 5332 : loss : 0.005574, loss_ce: 0.001967
2021-11-30 15:27:15,106 iteration 5333 : loss : 0.004343, loss_ce: 0.001974
2021-11-30 15:27:16,329 iteration 5334 : loss : 0.003077, loss_ce: 0.001367
2021-11-30 15:27:17,555 iteration 5335 : loss : 0.004078, loss_ce: 0.001624
2021-11-30 15:27:18,785 iteration 5336 : loss : 0.006006, loss_ce: 0.002015
2021-11-30 15:27:20,015 iteration 5337 : loss : 0.003687, loss_ce: 0.001616
2021-11-30 15:27:21,245 iteration 5338 : loss : 0.004832, loss_ce: 0.002049
 78%|██████████████████████▊      | 314/400 [1:58:55<31:08, 21.73s/it]2021-11-30 15:27:22,539 iteration 5339 : loss : 0.004390, loss_ce: 0.001078
2021-11-30 15:27:23,768 iteration 5340 : loss : 0.004209, loss_ce: 0.000879
2021-11-30 15:27:24,996 iteration 5341 : loss : 0.004174, loss_ce: 0.001544
2021-11-30 15:27:26,218 iteration 5342 : loss : 0.005250, loss_ce: 0.002349
2021-11-30 15:27:27,447 iteration 5343 : loss : 0.004409, loss_ce: 0.002321
2021-11-30 15:27:28,674 iteration 5344 : loss : 0.004736, loss_ce: 0.001456
2021-11-30 15:27:29,904 iteration 5345 : loss : 0.003878, loss_ce: 0.001473
2021-11-30 15:27:31,130 iteration 5346 : loss : 0.003826, loss_ce: 0.001573
2021-11-30 15:27:32,360 iteration 5347 : loss : 0.004291, loss_ce: 0.001750
2021-11-30 15:27:33,589 iteration 5348 : loss : 0.004670, loss_ce: 0.001758
2021-11-30 15:27:34,812 iteration 5349 : loss : 0.004022, loss_ce: 0.001501
2021-11-30 15:27:36,037 iteration 5350 : loss : 0.005734, loss_ce: 0.002155
2021-11-30 15:27:37,272 iteration 5351 : loss : 0.004896, loss_ce: 0.002003
2021-11-30 15:27:38,498 iteration 5352 : loss : 0.003788, loss_ce: 0.001672
2021-11-30 15:27:39,721 iteration 5353 : loss : 0.003807, loss_ce: 0.001452
2021-11-30 15:27:40,949 iteration 5354 : loss : 0.003668, loss_ce: 0.001900
2021-11-30 15:27:40,949 Training Data Eval:
2021-11-30 15:27:47,905   Average segmentation loss on training set: 0.0041
2021-11-30 15:27:47,906 Validation Data Eval:
2021-11-30 15:27:50,281   Average segmentation loss on validation set: 0.1340
2021-11-30 15:27:51,507 iteration 5355 : loss : 0.005874, loss_ce: 0.001851
 79%|██████████████████████▊      | 315/400 [1:59:25<34:24, 24.29s/it]2021-11-30 15:27:52,808 iteration 5356 : loss : 0.003879, loss_ce: 0.001500
2021-11-30 15:27:54,033 iteration 5357 : loss : 0.004244, loss_ce: 0.001652
2021-11-30 15:27:55,259 iteration 5358 : loss : 0.004120, loss_ce: 0.001633
2021-11-30 15:27:56,485 iteration 5359 : loss : 0.003584, loss_ce: 0.001368
2021-11-30 15:27:57,712 iteration 5360 : loss : 0.004627, loss_ce: 0.001847
2021-11-30 15:27:58,936 iteration 5361 : loss : 0.003432, loss_ce: 0.001368
2021-11-30 15:28:00,157 iteration 5362 : loss : 0.003778, loss_ce: 0.001111
2021-11-30 15:28:01,382 iteration 5363 : loss : 0.004028, loss_ce: 0.001449
2021-11-30 15:28:02,602 iteration 5364 : loss : 0.003421, loss_ce: 0.001363
2021-11-30 15:28:03,828 iteration 5365 : loss : 0.003929, loss_ce: 0.001814
2021-11-30 15:28:05,054 iteration 5366 : loss : 0.004467, loss_ce: 0.001557
2021-11-30 15:28:06,275 iteration 5367 : loss : 0.004662, loss_ce: 0.001985
2021-11-30 15:28:07,496 iteration 5368 : loss : 0.003146, loss_ce: 0.001107
2021-11-30 15:28:08,722 iteration 5369 : loss : 0.005591, loss_ce: 0.002742
2021-11-30 15:28:09,943 iteration 5370 : loss : 0.003390, loss_ce: 0.001382
2021-11-30 15:28:11,176 iteration 5371 : loss : 0.004442, loss_ce: 0.001382
2021-11-30 15:28:12,406 iteration 5372 : loss : 0.004159, loss_ce: 0.001442
 79%|██████████████████████▉      | 316/400 [1:59:46<32:34, 23.27s/it]2021-11-30 15:28:13,699 iteration 5373 : loss : 0.004680, loss_ce: 0.002093
2021-11-30 15:28:14,919 iteration 5374 : loss : 0.004364, loss_ce: 0.001065
2021-11-30 15:28:16,138 iteration 5375 : loss : 0.003888, loss_ce: 0.001336
2021-11-30 15:28:17,366 iteration 5376 : loss : 0.005294, loss_ce: 0.001926
2021-11-30 15:28:18,597 iteration 5377 : loss : 0.007832, loss_ce: 0.001685
2021-11-30 15:28:19,817 iteration 5378 : loss : 0.003906, loss_ce: 0.001148
2021-11-30 15:28:21,041 iteration 5379 : loss : 0.005352, loss_ce: 0.002268
2021-11-30 15:28:22,268 iteration 5380 : loss : 0.006854, loss_ce: 0.001395
2021-11-30 15:28:23,491 iteration 5381 : loss : 0.004990, loss_ce: 0.002759
2021-11-30 15:28:24,711 iteration 5382 : loss : 0.004088, loss_ce: 0.001760
2021-11-30 15:28:25,930 iteration 5383 : loss : 0.005762, loss_ce: 0.002507
2021-11-30 15:28:27,159 iteration 5384 : loss : 0.004707, loss_ce: 0.002214
2021-11-30 15:28:28,391 iteration 5385 : loss : 0.004082, loss_ce: 0.001551
2021-11-30 15:28:29,623 iteration 5386 : loss : 0.006722, loss_ce: 0.002566
2021-11-30 15:28:30,846 iteration 5387 : loss : 0.004082, loss_ce: 0.002124
2021-11-30 15:28:32,080 iteration 5388 : loss : 0.004113, loss_ce: 0.001431
2021-11-30 15:28:33,307 iteration 5389 : loss : 0.004931, loss_ce: 0.001867
 79%|██████████████████████▉      | 317/400 [2:00:07<31:12, 22.56s/it]2021-11-30 15:28:34,598 iteration 5390 : loss : 0.004034, loss_ce: 0.001437
2021-11-30 15:28:35,824 iteration 5391 : loss : 0.004860, loss_ce: 0.001505
2021-11-30 15:28:37,050 iteration 5392 : loss : 0.005386, loss_ce: 0.002569
2021-11-30 15:28:38,279 iteration 5393 : loss : 0.005441, loss_ce: 0.002201
2021-11-30 15:28:39,507 iteration 5394 : loss : 0.006074, loss_ce: 0.002508
2021-11-30 15:28:40,737 iteration 5395 : loss : 0.004432, loss_ce: 0.001798
2021-11-30 15:28:41,962 iteration 5396 : loss : 0.004999, loss_ce: 0.001591
2021-11-30 15:28:43,193 iteration 5397 : loss : 0.004231, loss_ce: 0.001450
2021-11-30 15:28:44,425 iteration 5398 : loss : 0.004095, loss_ce: 0.001783
2021-11-30 15:28:45,659 iteration 5399 : loss : 0.003531, loss_ce: 0.001324
2021-11-30 15:28:46,886 iteration 5400 : loss : 0.004400, loss_ce: 0.002040
2021-11-30 15:28:48,110 iteration 5401 : loss : 0.004162, loss_ce: 0.001066
2021-11-30 15:28:49,331 iteration 5402 : loss : 0.004008, loss_ce: 0.001684
2021-11-30 15:28:50,554 iteration 5403 : loss : 0.004819, loss_ce: 0.001669
2021-11-30 15:28:51,787 iteration 5404 : loss : 0.003412, loss_ce: 0.001320
2021-11-30 15:28:53,014 iteration 5405 : loss : 0.004445, loss_ce: 0.001789
2021-11-30 15:28:54,237 iteration 5406 : loss : 0.004267, loss_ce: 0.001845
 80%|███████████████████████      | 318/400 [2:00:28<30:09, 22.07s/it]2021-11-30 15:28:55,530 iteration 5407 : loss : 0.005933, loss_ce: 0.003036
2021-11-30 15:28:56,752 iteration 5408 : loss : 0.004505, loss_ce: 0.001314
2021-11-30 15:28:57,980 iteration 5409 : loss : 0.004200, loss_ce: 0.001814
2021-11-30 15:28:59,203 iteration 5410 : loss : 0.003640, loss_ce: 0.001400
2021-11-30 15:29:00,432 iteration 5411 : loss : 0.005342, loss_ce: 0.001633
2021-11-30 15:29:01,658 iteration 5412 : loss : 0.004294, loss_ce: 0.001886
2021-11-30 15:29:02,886 iteration 5413 : loss : 0.003802, loss_ce: 0.001719
2021-11-30 15:29:04,110 iteration 5414 : loss : 0.003648, loss_ce: 0.001677
2021-11-30 15:29:05,337 iteration 5415 : loss : 0.003782, loss_ce: 0.001352
2021-11-30 15:29:06,564 iteration 5416 : loss : 0.004413, loss_ce: 0.001586
2021-11-30 15:29:07,791 iteration 5417 : loss : 0.004675, loss_ce: 0.001757
2021-11-30 15:29:09,016 iteration 5418 : loss : 0.004452, loss_ce: 0.001848
2021-11-30 15:29:10,235 iteration 5419 : loss : 0.004761, loss_ce: 0.001848
2021-11-30 15:29:11,461 iteration 5420 : loss : 0.003776, loss_ce: 0.001481
2021-11-30 15:29:12,687 iteration 5421 : loss : 0.003734, loss_ce: 0.001478
2021-11-30 15:29:13,909 iteration 5422 : loss : 0.004283, loss_ce: 0.001739
2021-11-30 15:29:15,134 iteration 5423 : loss : 0.004439, loss_ce: 0.001445
 80%|███████████████████████▏     | 319/400 [2:00:49<29:19, 21.72s/it]2021-11-30 15:29:16,416 iteration 5424 : loss : 0.003771, loss_ce: 0.001722
2021-11-30 15:29:17,638 iteration 5425 : loss : 0.005124, loss_ce: 0.002263
2021-11-30 15:29:18,859 iteration 5426 : loss : 0.003454, loss_ce: 0.001526
2021-11-30 15:29:20,080 iteration 5427 : loss : 0.004530, loss_ce: 0.001711
2021-11-30 15:29:21,303 iteration 5428 : loss : 0.004617, loss_ce: 0.001057
2021-11-30 15:29:22,531 iteration 5429 : loss : 0.004674, loss_ce: 0.002111
2021-11-30 15:29:23,754 iteration 5430 : loss : 0.003960, loss_ce: 0.001628
2021-11-30 15:29:24,984 iteration 5431 : loss : 0.004652, loss_ce: 0.001860
2021-11-30 15:29:26,218 iteration 5432 : loss : 0.004813, loss_ce: 0.001618
2021-11-30 15:29:27,443 iteration 5433 : loss : 0.003469, loss_ce: 0.001012
2021-11-30 15:29:28,671 iteration 5434 : loss : 0.004078, loss_ce: 0.001694
2021-11-30 15:29:29,902 iteration 5435 : loss : 0.004221, loss_ce: 0.001690
2021-11-30 15:29:31,130 iteration 5436 : loss : 0.003739, loss_ce: 0.001424
2021-11-30 15:29:32,361 iteration 5437 : loss : 0.004667, loss_ce: 0.001424
2021-11-30 15:29:33,589 iteration 5438 : loss : 0.004514, loss_ce: 0.001856
2021-11-30 15:29:34,821 iteration 5439 : loss : 0.004048, loss_ce: 0.001946
2021-11-30 15:29:34,822 Training Data Eval:
2021-11-30 15:29:41,759   Average segmentation loss on training set: 0.0043
2021-11-30 15:29:41,760 Validation Data Eval:
2021-11-30 15:29:44,127   Average segmentation loss on validation set: 0.1311
2021-11-30 15:29:45,355 iteration 5440 : loss : 0.003467, loss_ce: 0.001625
 80%|███████████████████████▏     | 320/400 [2:01:19<32:21, 24.27s/it]2021-11-30 15:29:46,644 iteration 5441 : loss : 0.004669, loss_ce: 0.001611
2021-11-30 15:29:47,866 iteration 5442 : loss : 0.003380, loss_ce: 0.001368
2021-11-30 15:29:49,094 iteration 5443 : loss : 0.004064, loss_ce: 0.001788
2021-11-30 15:29:50,322 iteration 5444 : loss : 0.003619, loss_ce: 0.001238
2021-11-30 15:29:51,544 iteration 5445 : loss : 0.004376, loss_ce: 0.001881
2021-11-30 15:29:52,774 iteration 5446 : loss : 0.004533, loss_ce: 0.001895
2021-11-30 15:29:54,000 iteration 5447 : loss : 0.005103, loss_ce: 0.001822
2021-11-30 15:29:55,227 iteration 5448 : loss : 0.004343, loss_ce: 0.001358
2021-11-30 15:29:56,449 iteration 5449 : loss : 0.004442, loss_ce: 0.002386
2021-11-30 15:29:57,674 iteration 5450 : loss : 0.005010, loss_ce: 0.002374
2021-11-30 15:29:58,899 iteration 5451 : loss : 0.004963, loss_ce: 0.001396
2021-11-30 15:30:00,123 iteration 5452 : loss : 0.004269, loss_ce: 0.001120
2021-11-30 15:30:01,349 iteration 5453 : loss : 0.003568, loss_ce: 0.001470
2021-11-30 15:30:02,567 iteration 5454 : loss : 0.004856, loss_ce: 0.001379
2021-11-30 15:30:03,793 iteration 5455 : loss : 0.003214, loss_ce: 0.001350
2021-11-30 15:30:05,010 iteration 5456 : loss : 0.004464, loss_ce: 0.001688
2021-11-30 15:30:06,239 iteration 5457 : loss : 0.004084, loss_ce: 0.001829
 80%|███████████████████████▎     | 321/400 [2:01:40<30:37, 23.25s/it]2021-11-30 15:30:07,534 iteration 5458 : loss : 0.004848, loss_ce: 0.001203
2021-11-30 15:30:08,760 iteration 5459 : loss : 0.004874, loss_ce: 0.002529
2021-11-30 15:30:09,983 iteration 5460 : loss : 0.003888, loss_ce: 0.001730
2021-11-30 15:30:11,199 iteration 5461 : loss : 0.004109, loss_ce: 0.001369
2021-11-30 15:30:12,420 iteration 5462 : loss : 0.004259, loss_ce: 0.001570
2021-11-30 15:30:13,649 iteration 5463 : loss : 0.005342, loss_ce: 0.002214
2021-11-30 15:30:14,875 iteration 5464 : loss : 0.004451, loss_ce: 0.001921
2021-11-30 15:30:16,103 iteration 5465 : loss : 0.004044, loss_ce: 0.001643
2021-11-30 15:30:17,334 iteration 5466 : loss : 0.004749, loss_ce: 0.001415
2021-11-30 15:30:18,559 iteration 5467 : loss : 0.004014, loss_ce: 0.001873
2021-11-30 15:30:19,789 iteration 5468 : loss : 0.004622, loss_ce: 0.002050
2021-11-30 15:30:21,011 iteration 5469 : loss : 0.005003, loss_ce: 0.002172
2021-11-30 15:30:22,236 iteration 5470 : loss : 0.004191, loss_ce: 0.001686
2021-11-30 15:30:23,466 iteration 5471 : loss : 0.004176, loss_ce: 0.001230
2021-11-30 15:30:24,689 iteration 5472 : loss : 0.004109, loss_ce: 0.001999
2021-11-30 15:30:25,918 iteration 5473 : loss : 0.004774, loss_ce: 0.001663
2021-11-30 15:30:27,146 iteration 5474 : loss : 0.004576, loss_ce: 0.001976
 80%|███████████████████████▎     | 322/400 [2:02:01<29:18, 22.55s/it]2021-11-30 15:30:28,431 iteration 5475 : loss : 0.003830, loss_ce: 0.001388
2021-11-30 15:30:29,652 iteration 5476 : loss : 0.003725, loss_ce: 0.001421
2021-11-30 15:30:30,875 iteration 5477 : loss : 0.003691, loss_ce: 0.001223
2021-11-30 15:30:32,102 iteration 5478 : loss : 0.003360, loss_ce: 0.001248
2021-11-30 15:30:33,326 iteration 5479 : loss : 0.004039, loss_ce: 0.001683
2021-11-30 15:30:34,550 iteration 5480 : loss : 0.004257, loss_ce: 0.001708
2021-11-30 15:30:35,772 iteration 5481 : loss : 0.003609, loss_ce: 0.001565
2021-11-30 15:30:37,004 iteration 5482 : loss : 0.004300, loss_ce: 0.001864
2021-11-30 15:30:38,232 iteration 5483 : loss : 0.003879, loss_ce: 0.001940
2021-11-30 15:30:39,457 iteration 5484 : loss : 0.004316, loss_ce: 0.001608
2021-11-30 15:30:40,678 iteration 5485 : loss : 0.003767, loss_ce: 0.001459
2021-11-30 15:30:41,906 iteration 5486 : loss : 0.004629, loss_ce: 0.002313
2021-11-30 15:30:43,137 iteration 5487 : loss : 0.003159, loss_ce: 0.001470
2021-11-30 15:30:44,367 iteration 5488 : loss : 0.005037, loss_ce: 0.001431
2021-11-30 15:30:45,587 iteration 5489 : loss : 0.005389, loss_ce: 0.001684
2021-11-30 15:30:46,820 iteration 5490 : loss : 0.004398, loss_ce: 0.001954
2021-11-30 15:30:48,041 iteration 5491 : loss : 0.003393, loss_ce: 0.001023
 81%|███████████████████████▍     | 323/400 [2:02:22<28:18, 22.05s/it]2021-11-30 15:30:49,332 iteration 5492 : loss : 0.004496, loss_ce: 0.001467
2021-11-30 15:30:50,555 iteration 5493 : loss : 0.004186, loss_ce: 0.001515
2021-11-30 15:30:51,777 iteration 5494 : loss : 0.003705, loss_ce: 0.001236
2021-11-30 15:30:53,008 iteration 5495 : loss : 0.004164, loss_ce: 0.001343
2021-11-30 15:30:54,235 iteration 5496 : loss : 0.004205, loss_ce: 0.001349
2021-11-30 15:30:55,462 iteration 5497 : loss : 0.004027, loss_ce: 0.001795
2021-11-30 15:30:56,690 iteration 5498 : loss : 0.004153, loss_ce: 0.001854
2021-11-30 15:30:57,923 iteration 5499 : loss : 0.003852, loss_ce: 0.001824
2021-11-30 15:30:59,153 iteration 5500 : loss : 0.004122, loss_ce: 0.001908
2021-11-30 15:31:00,378 iteration 5501 : loss : 0.004717, loss_ce: 0.002478
2021-11-30 15:31:01,602 iteration 5502 : loss : 0.003180, loss_ce: 0.001189
2021-11-30 15:31:02,822 iteration 5503 : loss : 0.003484, loss_ce: 0.001503
2021-11-30 15:31:04,050 iteration 5504 : loss : 0.004012, loss_ce: 0.001520
2021-11-30 15:31:05,269 iteration 5505 : loss : 0.004490, loss_ce: 0.001195
2021-11-30 15:31:06,497 iteration 5506 : loss : 0.004034, loss_ce: 0.001591
2021-11-30 15:31:07,724 iteration 5507 : loss : 0.004386, loss_ce: 0.001595
2021-11-30 15:31:08,948 iteration 5508 : loss : 0.005570, loss_ce: 0.002883
 81%|███████████████████████▍     | 324/400 [2:02:43<27:29, 21.71s/it]2021-11-30 15:31:10,241 iteration 5509 : loss : 0.003780, loss_ce: 0.001739
2021-11-30 15:31:11,460 iteration 5510 : loss : 0.004063, loss_ce: 0.001428
2021-11-30 15:31:12,686 iteration 5511 : loss : 0.003953, loss_ce: 0.001190
2021-11-30 15:31:13,911 iteration 5512 : loss : 0.004604, loss_ce: 0.001202
2021-11-30 15:31:15,136 iteration 5513 : loss : 0.003804, loss_ce: 0.001420
2021-11-30 15:31:16,357 iteration 5514 : loss : 0.004391, loss_ce: 0.001900
2021-11-30 15:31:17,584 iteration 5515 : loss : 0.003662, loss_ce: 0.001540
2021-11-30 15:31:18,809 iteration 5516 : loss : 0.005309, loss_ce: 0.002068
2021-11-30 15:31:20,025 iteration 5517 : loss : 0.003775, loss_ce: 0.001618
2021-11-30 15:31:21,254 iteration 5518 : loss : 0.004533, loss_ce: 0.002012
2021-11-30 15:31:22,478 iteration 5519 : loss : 0.003509, loss_ce: 0.001647
2021-11-30 15:31:23,704 iteration 5520 : loss : 0.003920, loss_ce: 0.001743
2021-11-30 15:31:24,934 iteration 5521 : loss : 0.004543, loss_ce: 0.001475
2021-11-30 15:31:26,158 iteration 5522 : loss : 0.003835, loss_ce: 0.001422
2021-11-30 15:31:27,381 iteration 5523 : loss : 0.003105, loss_ce: 0.001258
2021-11-30 15:31:28,608 iteration 5524 : loss : 0.003733, loss_ce: 0.001740
2021-11-30 15:31:28,609 Training Data Eval:
2021-11-30 15:31:35,551   Average segmentation loss on training set: 0.0042
2021-11-30 15:31:35,552 Validation Data Eval:
2021-11-30 15:31:37,931   Average segmentation loss on validation set: 0.1454
2021-11-30 15:31:39,151 iteration 5525 : loss : 0.004477, loss_ce: 0.001622
 81%|███████████████████████▌     | 325/400 [2:03:13<30:19, 24.26s/it]2021-11-30 15:31:40,452 iteration 5526 : loss : 0.003952, loss_ce: 0.001485
2021-11-30 15:31:41,673 iteration 5527 : loss : 0.003874, loss_ce: 0.000874
2021-11-30 15:31:42,891 iteration 5528 : loss : 0.003411, loss_ce: 0.001145
2021-11-30 15:31:44,118 iteration 5529 : loss : 0.004837, loss_ce: 0.001205
2021-11-30 15:31:45,342 iteration 5530 : loss : 0.004370, loss_ce: 0.001779
2021-11-30 15:31:46,566 iteration 5531 : loss : 0.003917, loss_ce: 0.002124
2021-11-30 15:31:47,795 iteration 5532 : loss : 0.031339, loss_ce: 0.001735
2021-11-30 15:31:49,026 iteration 5533 : loss : 0.005630, loss_ce: 0.002516
2021-11-30 15:31:50,249 iteration 5534 : loss : 0.008849, loss_ce: 0.003669
2021-11-30 15:31:51,474 iteration 5535 : loss : 0.020680, loss_ce: 0.008767
2021-11-30 15:31:52,706 iteration 5536 : loss : 0.020798, loss_ce: 0.009488
2021-11-30 15:31:53,932 iteration 5537 : loss : 0.029962, loss_ce: 0.015678
2021-11-30 15:31:55,157 iteration 5538 : loss : 0.023005, loss_ce: 0.015509
2021-11-30 15:31:56,380 iteration 5539 : loss : 0.018150, loss_ce: 0.006812
2021-11-30 15:31:57,610 iteration 5540 : loss : 0.018461, loss_ce: 0.008967
2021-11-30 15:31:58,837 iteration 5541 : loss : 0.029134, loss_ce: 0.009835
2021-11-30 15:32:00,068 iteration 5542 : loss : 0.018706, loss_ce: 0.005965
 82%|███████████████████████▋     | 326/400 [2:03:34<28:40, 23.26s/it]2021-11-30 15:32:01,361 iteration 5543 : loss : 0.020286, loss_ce: 0.008828
2021-11-30 15:32:02,586 iteration 5544 : loss : 0.022008, loss_ce: 0.011482
2021-11-30 15:32:03,814 iteration 5545 : loss : 0.020952, loss_ce: 0.007386
2021-11-30 15:32:05,046 iteration 5546 : loss : 0.018760, loss_ce: 0.007976
2021-11-30 15:32:06,276 iteration 5547 : loss : 0.015315, loss_ce: 0.005968
2021-11-30 15:32:07,502 iteration 5548 : loss : 0.020938, loss_ce: 0.011508
2021-11-30 15:32:08,736 iteration 5549 : loss : 0.014712, loss_ce: 0.007107
2021-11-30 15:32:09,966 iteration 5550 : loss : 0.018117, loss_ce: 0.003175
2021-11-30 15:32:11,186 iteration 5551 : loss : 0.015046, loss_ce: 0.005120
2021-11-30 15:32:12,415 iteration 5552 : loss : 0.011915, loss_ce: 0.005939
2021-11-30 15:32:13,635 iteration 5553 : loss : 0.014080, loss_ce: 0.005413
2021-11-30 15:32:14,859 iteration 5554 : loss : 0.011210, loss_ce: 0.004165
2021-11-30 15:32:16,085 iteration 5555 : loss : 0.011890, loss_ce: 0.005019
2021-11-30 15:32:17,312 iteration 5556 : loss : 0.009877, loss_ce: 0.003504
2021-11-30 15:32:18,538 iteration 5557 : loss : 0.013454, loss_ce: 0.005051
2021-11-30 15:32:19,769 iteration 5558 : loss : 0.014511, loss_ce: 0.006165
2021-11-30 15:32:20,991 iteration 5559 : loss : 0.014561, loss_ce: 0.005835
 82%|███████████████████████▋     | 327/400 [2:03:55<27:26, 22.56s/it]2021-11-30 15:32:22,295 iteration 5560 : loss : 0.007514, loss_ce: 0.003128
2021-11-30 15:32:23,524 iteration 5561 : loss : 0.014684, loss_ce: 0.004596
2021-11-30 15:32:24,756 iteration 5562 : loss : 0.012021, loss_ce: 0.003456
2021-11-30 15:32:25,977 iteration 5563 : loss : 0.011867, loss_ce: 0.003665
2021-11-30 15:32:27,196 iteration 5564 : loss : 0.010929, loss_ce: 0.004444
2021-11-30 15:32:28,426 iteration 5565 : loss : 0.011230, loss_ce: 0.004694
2021-11-30 15:32:29,651 iteration 5566 : loss : 0.011822, loss_ce: 0.005558
2021-11-30 15:32:30,872 iteration 5567 : loss : 0.012467, loss_ce: 0.005406
2021-11-30 15:32:32,095 iteration 5568 : loss : 0.010958, loss_ce: 0.004401
2021-11-30 15:32:33,318 iteration 5569 : loss : 0.008056, loss_ce: 0.002712
2021-11-30 15:32:34,548 iteration 5570 : loss : 0.009946, loss_ce: 0.003452
2021-11-30 15:32:35,773 iteration 5571 : loss : 0.014308, loss_ce: 0.003935
2021-11-30 15:32:37,000 iteration 5572 : loss : 0.010127, loss_ce: 0.003845
2021-11-30 15:32:38,227 iteration 5573 : loss : 0.009219, loss_ce: 0.003858
2021-11-30 15:32:39,454 iteration 5574 : loss : 0.009072, loss_ce: 0.003254
2021-11-30 15:32:40,684 iteration 5575 : loss : 0.014904, loss_ce: 0.004593
2021-11-30 15:32:41,910 iteration 5576 : loss : 0.011228, loss_ce: 0.004581
 82%|███████████████████████▊     | 328/400 [2:04:15<26:28, 22.07s/it]2021-11-30 15:32:43,204 iteration 5577 : loss : 0.011142, loss_ce: 0.005473
2021-11-30 15:32:44,431 iteration 5578 : loss : 0.007797, loss_ce: 0.002351
2021-11-30 15:32:45,658 iteration 5579 : loss : 0.007883, loss_ce: 0.002241
2021-11-30 15:32:46,882 iteration 5580 : loss : 0.007177, loss_ce: 0.002282
2021-11-30 15:32:48,104 iteration 5581 : loss : 0.007456, loss_ce: 0.002781
2021-11-30 15:32:49,331 iteration 5582 : loss : 0.008152, loss_ce: 0.003081
2021-11-30 15:32:50,549 iteration 5583 : loss : 0.008996, loss_ce: 0.002754
2021-11-30 15:32:51,772 iteration 5584 : loss : 0.006926, loss_ce: 0.002837
2021-11-30 15:32:53,014 iteration 5585 : loss : 0.008325, loss_ce: 0.003982
2021-11-30 15:32:54,238 iteration 5586 : loss : 0.007381, loss_ce: 0.002812
2021-11-30 15:32:55,461 iteration 5587 : loss : 0.005629, loss_ce: 0.002255
2021-11-30 15:32:56,683 iteration 5588 : loss : 0.008420, loss_ce: 0.003063
2021-11-30 15:32:57,905 iteration 5589 : loss : 0.010563, loss_ce: 0.002363
2021-11-30 15:32:59,134 iteration 5590 : loss : 0.007667, loss_ce: 0.003286
2021-11-30 15:33:00,358 iteration 5591 : loss : 0.007862, loss_ce: 0.004224
2021-11-30 15:33:01,583 iteration 5592 : loss : 0.006796, loss_ce: 0.002390
2021-11-30 15:33:02,804 iteration 5593 : loss : 0.006494, loss_ce: 0.002025
 82%|███████████████████████▊     | 329/400 [2:04:36<25:41, 21.71s/it]2021-11-30 15:33:04,087 iteration 5594 : loss : 0.007988, loss_ce: 0.003495
2021-11-30 15:33:05,315 iteration 5595 : loss : 0.007736, loss_ce: 0.002424
2021-11-30 15:33:06,546 iteration 5596 : loss : 0.005761, loss_ce: 0.002086
2021-11-30 15:33:07,764 iteration 5597 : loss : 0.006430, loss_ce: 0.003158
2021-11-30 15:33:08,989 iteration 5598 : loss : 0.008387, loss_ce: 0.002115
2021-11-30 15:33:10,216 iteration 5599 : loss : 0.006177, loss_ce: 0.002715
2021-11-30 15:33:11,445 iteration 5600 : loss : 0.006043, loss_ce: 0.002054
2021-11-30 15:33:12,675 iteration 5601 : loss : 0.007580, loss_ce: 0.002196
2021-11-30 15:33:13,902 iteration 5602 : loss : 0.006448, loss_ce: 0.003129
2021-11-30 15:33:15,138 iteration 5603 : loss : 0.006877, loss_ce: 0.003233
2021-11-30 15:33:16,366 iteration 5604 : loss : 0.005063, loss_ce: 0.002238
2021-11-30 15:33:17,591 iteration 5605 : loss : 0.006070, loss_ce: 0.001928
2021-11-30 15:33:18,813 iteration 5606 : loss : 0.006532, loss_ce: 0.001785
2021-11-30 15:33:20,042 iteration 5607 : loss : 0.005280, loss_ce: 0.001780
2021-11-30 15:33:21,269 iteration 5608 : loss : 0.006869, loss_ce: 0.002890
2021-11-30 15:33:22,494 iteration 5609 : loss : 0.007417, loss_ce: 0.003359
2021-11-30 15:33:22,495 Training Data Eval:
2021-11-30 15:33:29,440   Average segmentation loss on training set: 0.0065
2021-11-30 15:33:29,441 Validation Data Eval:
2021-11-30 15:33:31,824   Average segmentation loss on validation set: 0.1520
2021-11-30 15:33:33,052 iteration 5610 : loss : 0.006482, loss_ce: 0.002008
 82%|███████████████████████▉     | 330/400 [2:05:07<28:19, 24.28s/it]2021-11-30 15:33:34,350 iteration 5611 : loss : 0.005635, loss_ce: 0.001875
2021-11-30 15:33:35,578 iteration 5612 : loss : 0.006237, loss_ce: 0.001440
2021-11-30 15:33:36,804 iteration 5613 : loss : 0.005141, loss_ce: 0.002219
2021-11-30 15:33:38,029 iteration 5614 : loss : 0.004928, loss_ce: 0.002054
2021-11-30 15:33:39,257 iteration 5615 : loss : 0.008032, loss_ce: 0.002270
2021-11-30 15:33:40,478 iteration 5616 : loss : 0.006444, loss_ce: 0.002748
2021-11-30 15:33:41,696 iteration 5617 : loss : 0.006614, loss_ce: 0.001884
2021-11-30 15:33:42,920 iteration 5618 : loss : 0.004310, loss_ce: 0.001807
2021-11-30 15:33:44,140 iteration 5619 : loss : 0.006408, loss_ce: 0.003049
2021-11-30 15:33:45,378 iteration 5620 : loss : 0.004856, loss_ce: 0.001746
2021-11-30 15:33:46,591 iteration 5621 : loss : 0.004639, loss_ce: 0.001886
2021-11-30 15:33:47,813 iteration 5622 : loss : 0.004981, loss_ce: 0.002056
2021-11-30 15:33:49,041 iteration 5623 : loss : 0.006222, loss_ce: 0.002912
2021-11-30 15:33:50,266 iteration 5624 : loss : 0.007872, loss_ce: 0.001815
2021-11-30 15:33:51,495 iteration 5625 : loss : 0.005014, loss_ce: 0.001643
2021-11-30 15:33:52,711 iteration 5626 : loss : 0.005324, loss_ce: 0.002771
2021-11-30 15:33:53,939 iteration 5627 : loss : 0.006463, loss_ce: 0.003014
 83%|███████████████████████▉     | 331/400 [2:05:28<26:44, 23.26s/it]2021-11-30 15:33:55,241 iteration 5628 : loss : 0.004441, loss_ce: 0.001581
2021-11-30 15:33:56,467 iteration 5629 : loss : 0.005402, loss_ce: 0.002202
2021-11-30 15:33:57,681 iteration 5630 : loss : 0.004665, loss_ce: 0.001646
2021-11-30 15:33:58,902 iteration 5631 : loss : 0.004872, loss_ce: 0.001894
2021-11-30 15:34:00,126 iteration 5632 : loss : 0.005225, loss_ce: 0.002296
2021-11-30 15:34:01,340 iteration 5633 : loss : 0.004627, loss_ce: 0.002564
2021-11-30 15:34:02,566 iteration 5634 : loss : 0.004646, loss_ce: 0.001771
2021-11-30 15:34:03,794 iteration 5635 : loss : 0.005315, loss_ce: 0.002621
2021-11-30 15:34:05,008 iteration 5636 : loss : 0.004645, loss_ce: 0.001817
2021-11-30 15:34:06,230 iteration 5637 : loss : 0.006373, loss_ce: 0.001396
2021-11-30 15:34:07,454 iteration 5638 : loss : 0.004682, loss_ce: 0.002031
2021-11-30 15:34:08,682 iteration 5639 : loss : 0.005373, loss_ce: 0.002673
2021-11-30 15:34:09,902 iteration 5640 : loss : 0.005875, loss_ce: 0.001556
2021-11-30 15:34:11,117 iteration 5641 : loss : 0.007012, loss_ce: 0.002209
2021-11-30 15:34:12,341 iteration 5642 : loss : 0.005328, loss_ce: 0.001647
2021-11-30 15:34:13,554 iteration 5643 : loss : 0.005642, loss_ce: 0.001772
2021-11-30 15:34:14,780 iteration 5644 : loss : 0.005442, loss_ce: 0.002274
 83%|████████████████████████     | 332/400 [2:05:48<25:32, 22.53s/it]2021-11-30 15:34:16,075 iteration 5645 : loss : 0.005851, loss_ce: 0.002380
2021-11-30 15:34:17,294 iteration 5646 : loss : 0.004909, loss_ce: 0.002107
2021-11-30 15:34:18,514 iteration 5647 : loss : 0.004853, loss_ce: 0.002475
2021-11-30 15:34:19,740 iteration 5648 : loss : 0.004646, loss_ce: 0.001621
2021-11-30 15:34:20,964 iteration 5649 : loss : 0.004732, loss_ce: 0.002381
2021-11-30 15:34:22,184 iteration 5650 : loss : 0.004498, loss_ce: 0.002013
2021-11-30 15:34:23,405 iteration 5651 : loss : 0.004075, loss_ce: 0.001277
2021-11-30 15:34:24,628 iteration 5652 : loss : 0.004650, loss_ce: 0.001857
2021-11-30 15:34:25,855 iteration 5653 : loss : 0.003968, loss_ce: 0.001559
2021-11-30 15:34:27,071 iteration 5654 : loss : 0.005462, loss_ce: 0.001407
2021-11-30 15:34:28,289 iteration 5655 : loss : 0.004456, loss_ce: 0.001401
2021-11-30 15:34:29,505 iteration 5656 : loss : 0.004944, loss_ce: 0.002458
2021-11-30 15:34:30,728 iteration 5657 : loss : 0.004117, loss_ce: 0.001295
2021-11-30 15:34:31,954 iteration 5658 : loss : 0.004925, loss_ce: 0.001647
2021-11-30 15:34:33,177 iteration 5659 : loss : 0.004442, loss_ce: 0.001486
2021-11-30 15:34:34,402 iteration 5660 : loss : 0.005204, loss_ce: 0.002516
2021-11-30 15:34:35,627 iteration 5661 : loss : 0.004716, loss_ce: 0.002301
 83%|████████████████████████▏    | 333/400 [2:06:09<24:35, 22.03s/it]2021-11-30 15:34:36,921 iteration 5662 : loss : 0.004639, loss_ce: 0.002125
2021-11-30 15:34:38,153 iteration 5663 : loss : 0.004788, loss_ce: 0.002307
2021-11-30 15:34:39,379 iteration 5664 : loss : 0.004039, loss_ce: 0.001983
2021-11-30 15:34:40,607 iteration 5665 : loss : 0.004622, loss_ce: 0.001698
2021-11-30 15:34:41,823 iteration 5666 : loss : 0.005763, loss_ce: 0.002154
2021-11-30 15:34:43,055 iteration 5667 : loss : 0.004802, loss_ce: 0.001326
2021-11-30 15:34:44,282 iteration 5668 : loss : 0.004448, loss_ce: 0.001339
2021-11-30 15:34:45,508 iteration 5669 : loss : 0.005886, loss_ce: 0.002474
2021-11-30 15:34:46,728 iteration 5670 : loss : 0.004544, loss_ce: 0.001524
2021-11-30 15:34:47,958 iteration 5671 : loss : 0.005937, loss_ce: 0.002701
2021-11-30 15:34:49,186 iteration 5672 : loss : 0.005972, loss_ce: 0.002262
2021-11-30 15:34:50,412 iteration 5673 : loss : 0.005904, loss_ce: 0.001682
2021-11-30 15:34:51,636 iteration 5674 : loss : 0.004135, loss_ce: 0.001286
2021-11-30 15:34:52,867 iteration 5675 : loss : 0.006539, loss_ce: 0.002541
2021-11-30 15:34:54,091 iteration 5676 : loss : 0.004995, loss_ce: 0.002321
2021-11-30 15:34:55,320 iteration 5677 : loss : 0.005860, loss_ce: 0.002247
2021-11-30 15:34:56,553 iteration 5678 : loss : 0.004522, loss_ce: 0.001890
 84%|████████████████████████▏    | 334/400 [2:06:30<23:51, 21.70s/it]2021-11-30 15:34:57,850 iteration 5679 : loss : 0.005044, loss_ce: 0.001160
2021-11-30 15:34:59,074 iteration 5680 : loss : 0.004681, loss_ce: 0.002144
2021-11-30 15:35:00,305 iteration 5681 : loss : 0.004612, loss_ce: 0.002143
2021-11-30 15:35:01,527 iteration 5682 : loss : 0.004492, loss_ce: 0.002007
2021-11-30 15:35:02,761 iteration 5683 : loss : 0.005031, loss_ce: 0.001779
2021-11-30 15:35:03,988 iteration 5684 : loss : 0.004444, loss_ce: 0.001653
2021-11-30 15:35:05,196 iteration 5685 : loss : 0.003956, loss_ce: 0.001296
2021-11-30 15:35:06,420 iteration 5686 : loss : 0.004220, loss_ce: 0.002004
2021-11-30 15:35:07,646 iteration 5687 : loss : 0.005203, loss_ce: 0.001997
2021-11-30 15:35:08,872 iteration 5688 : loss : 0.005354, loss_ce: 0.002577
2021-11-30 15:35:10,097 iteration 5689 : loss : 0.006433, loss_ce: 0.001803
2021-11-30 15:35:11,321 iteration 5690 : loss : 0.005188, loss_ce: 0.001636
2021-11-30 15:35:12,542 iteration 5691 : loss : 0.004577, loss_ce: 0.001538
2021-11-30 15:35:13,765 iteration 5692 : loss : 0.005531, loss_ce: 0.001975
2021-11-30 15:35:14,991 iteration 5693 : loss : 0.004591, loss_ce: 0.002253
2021-11-30 15:35:16,208 iteration 5694 : loss : 0.005634, loss_ce: 0.002362
2021-11-30 15:35:16,208 Training Data Eval:
2021-11-30 15:35:23,135   Average segmentation loss on training set: 0.0054
2021-11-30 15:35:23,136 Validation Data Eval:
2021-11-30 15:35:25,491   Average segmentation loss on validation set: 0.1442
2021-11-30 15:35:26,715 iteration 5695 : loss : 0.004512, loss_ce: 0.001981
 84%|████████████████████████▎    | 335/400 [2:07:00<26:15, 24.24s/it]2021-11-30 15:35:28,005 iteration 5696 : loss : 0.005417, loss_ce: 0.002106
2021-11-30 15:35:29,226 iteration 5697 : loss : 0.005253, loss_ce: 0.001290
2021-11-30 15:35:30,448 iteration 5698 : loss : 0.004988, loss_ce: 0.001754
2021-11-30 15:35:31,666 iteration 5699 : loss : 0.004771, loss_ce: 0.001820
2021-11-30 15:35:32,881 iteration 5700 : loss : 0.003786, loss_ce: 0.001359
2021-11-30 15:35:34,105 iteration 5701 : loss : 0.004430, loss_ce: 0.002476
2021-11-30 15:35:35,325 iteration 5702 : loss : 0.004933, loss_ce: 0.001949
2021-11-30 15:35:36,548 iteration 5703 : loss : 0.003988, loss_ce: 0.001059
2021-11-30 15:35:37,772 iteration 5704 : loss : 0.004958, loss_ce: 0.002278
2021-11-30 15:35:38,994 iteration 5705 : loss : 0.004553, loss_ce: 0.001476
2021-11-30 15:35:40,211 iteration 5706 : loss : 0.003971, loss_ce: 0.001468
2021-11-30 15:35:41,431 iteration 5707 : loss : 0.004396, loss_ce: 0.001884
2021-11-30 15:35:42,652 iteration 5708 : loss : 0.004761, loss_ce: 0.001764
2021-11-30 15:35:43,867 iteration 5709 : loss : 0.006459, loss_ce: 0.003040
2021-11-30 15:35:45,087 iteration 5710 : loss : 0.003793, loss_ce: 0.001683
2021-11-30 15:35:46,300 iteration 5711 : loss : 0.004120, loss_ce: 0.002030
2021-11-30 15:35:47,511 iteration 5712 : loss : 0.004444, loss_ce: 0.002195
 84%|████████████████████████▎    | 336/400 [2:07:21<24:45, 23.20s/it]2021-11-30 15:35:48,808 iteration 5713 : loss : 0.005076, loss_ce: 0.001549
2021-11-30 15:35:50,028 iteration 5714 : loss : 0.004955, loss_ce: 0.001790
2021-11-30 15:35:51,259 iteration 5715 : loss : 0.004110, loss_ce: 0.001903
2021-11-30 15:35:52,481 iteration 5716 : loss : 0.005694, loss_ce: 0.001783
2021-11-30 15:35:53,706 iteration 5717 : loss : 0.004435, loss_ce: 0.002208
2021-11-30 15:35:54,925 iteration 5718 : loss : 0.003186, loss_ce: 0.001371
2021-11-30 15:35:56,151 iteration 5719 : loss : 0.003791, loss_ce: 0.001442
2021-11-30 15:35:57,374 iteration 5720 : loss : 0.004749, loss_ce: 0.002122
2021-11-30 15:35:58,607 iteration 5721 : loss : 0.004969, loss_ce: 0.002039
2021-11-30 15:35:59,828 iteration 5722 : loss : 0.004909, loss_ce: 0.001978
2021-11-30 15:36:01,048 iteration 5723 : loss : 0.003834, loss_ce: 0.001747
2021-11-30 15:36:02,268 iteration 5724 : loss : 0.005166, loss_ce: 0.001588
2021-11-30 15:36:03,491 iteration 5725 : loss : 0.003796, loss_ce: 0.001636
2021-11-30 15:36:04,707 iteration 5726 : loss : 0.003205, loss_ce: 0.001216
2021-11-30 15:36:05,923 iteration 5727 : loss : 0.004615, loss_ce: 0.001539
2021-11-30 15:36:07,152 iteration 5728 : loss : 0.005580, loss_ce: 0.002007
2021-11-30 15:36:08,380 iteration 5729 : loss : 0.004581, loss_ce: 0.001942
 84%|████████████████████████▍    | 337/400 [2:07:42<23:37, 22.50s/it]2021-11-30 15:36:09,673 iteration 5730 : loss : 0.004057, loss_ce: 0.001297
2021-11-30 15:36:10,902 iteration 5731 : loss : 0.004223, loss_ce: 0.001919
2021-11-30 15:36:12,127 iteration 5732 : loss : 0.004325, loss_ce: 0.001644
2021-11-30 15:36:13,352 iteration 5733 : loss : 0.005124, loss_ce: 0.001806
2021-11-30 15:36:14,568 iteration 5734 : loss : 0.004275, loss_ce: 0.001563
2021-11-30 15:36:15,784 iteration 5735 : loss : 0.004476, loss_ce: 0.002093
2021-11-30 15:36:17,001 iteration 5736 : loss : 0.011576, loss_ce: 0.002260
2021-11-30 15:36:18,228 iteration 5737 : loss : 0.004374, loss_ce: 0.001719
2021-11-30 15:36:19,450 iteration 5738 : loss : 0.004506, loss_ce: 0.001719
2021-11-30 15:36:20,675 iteration 5739 : loss : 0.004396, loss_ce: 0.001838
2021-11-30 15:36:21,904 iteration 5740 : loss : 0.005196, loss_ce: 0.002378
2021-11-30 15:36:23,134 iteration 5741 : loss : 0.004985, loss_ce: 0.001573
2021-11-30 15:36:24,356 iteration 5742 : loss : 0.004913, loss_ce: 0.002873
2021-11-30 15:36:25,579 iteration 5743 : loss : 0.004320, loss_ce: 0.001562
2021-11-30 15:36:26,804 iteration 5744 : loss : 0.004971, loss_ce: 0.002429
2021-11-30 15:36:28,024 iteration 5745 : loss : 0.003985, loss_ce: 0.001509
2021-11-30 15:36:29,242 iteration 5746 : loss : 0.006380, loss_ce: 0.001574
 84%|████████████████████████▌    | 338/400 [2:08:03<22:44, 22.01s/it]2021-11-30 15:36:30,524 iteration 5747 : loss : 0.005395, loss_ce: 0.001878
2021-11-30 15:36:31,737 iteration 5748 : loss : 0.004600, loss_ce: 0.001270
2021-11-30 15:36:32,961 iteration 5749 : loss : 0.004685, loss_ce: 0.001832
2021-11-30 15:36:34,183 iteration 5750 : loss : 0.004752, loss_ce: 0.001812
2021-11-30 15:36:35,408 iteration 5751 : loss : 0.004627, loss_ce: 0.001673
2021-11-30 15:36:36,631 iteration 5752 : loss : 0.005319, loss_ce: 0.001890
2021-11-30 15:36:37,850 iteration 5753 : loss : 0.004531, loss_ce: 0.002312
2021-11-30 15:36:39,072 iteration 5754 : loss : 0.004224, loss_ce: 0.001365
2021-11-30 15:36:40,298 iteration 5755 : loss : 0.003801, loss_ce: 0.001593
2021-11-30 15:36:41,524 iteration 5756 : loss : 0.005139, loss_ce: 0.002120
2021-11-30 15:36:42,738 iteration 5757 : loss : 0.003653, loss_ce: 0.001550
2021-11-30 15:36:43,959 iteration 5758 : loss : 0.004157, loss_ce: 0.002157
2021-11-30 15:36:45,188 iteration 5759 : loss : 0.003836, loss_ce: 0.001509
2021-11-30 15:36:46,409 iteration 5760 : loss : 0.003711, loss_ce: 0.001303
2021-11-30 15:36:47,626 iteration 5761 : loss : 0.006232, loss_ce: 0.001709
2021-11-30 15:36:48,847 iteration 5762 : loss : 0.003716, loss_ce: 0.001195
2021-11-30 15:36:50,072 iteration 5763 : loss : 0.005214, loss_ce: 0.001550
 85%|████████████████████████▌    | 339/400 [2:08:24<22:00, 21.65s/it]2021-11-30 15:36:51,357 iteration 5764 : loss : 0.004200, loss_ce: 0.001658
2021-11-30 15:36:52,581 iteration 5765 : loss : 0.004565, loss_ce: 0.001231
2021-11-30 15:36:53,810 iteration 5766 : loss : 0.005264, loss_ce: 0.001876
2021-11-30 15:36:55,027 iteration 5767 : loss : 0.005609, loss_ce: 0.002354
2021-11-30 15:36:56,244 iteration 5768 : loss : 0.004038, loss_ce: 0.001966
2021-11-30 15:36:57,467 iteration 5769 : loss : 0.004085, loss_ce: 0.001626
2021-11-30 15:36:58,690 iteration 5770 : loss : 0.004485, loss_ce: 0.002424
2021-11-30 15:36:59,911 iteration 5771 : loss : 0.004393, loss_ce: 0.001796
2021-11-30 15:37:01,133 iteration 5772 : loss : 0.003761, loss_ce: 0.001373
2021-11-30 15:37:02,354 iteration 5773 : loss : 0.005948, loss_ce: 0.001829
2021-11-30 15:37:03,576 iteration 5774 : loss : 0.003850, loss_ce: 0.001176
2021-11-30 15:37:04,797 iteration 5775 : loss : 0.003872, loss_ce: 0.001475
2021-11-30 15:37:06,019 iteration 5776 : loss : 0.004072, loss_ce: 0.001625
2021-11-30 15:37:07,241 iteration 5777 : loss : 0.004720, loss_ce: 0.001814
2021-11-30 15:37:08,466 iteration 5778 : loss : 0.004297, loss_ce: 0.001660
2021-11-30 15:37:09,698 iteration 5779 : loss : 0.004399, loss_ce: 0.001417
2021-11-30 15:37:09,698 Training Data Eval:
2021-11-30 15:37:16,634   Average segmentation loss on training set: 0.0037
2021-11-30 15:37:16,634 Validation Data Eval:
2021-11-30 15:37:19,013   Average segmentation loss on validation set: 0.1436
2021-11-30 15:37:20,239 iteration 5780 : loss : 0.003499, loss_ce: 0.001515
 85%|████████████████████████▋    | 340/400 [2:08:54<24:12, 24.21s/it]2021-11-30 15:37:21,529 iteration 5781 : loss : 0.003600, loss_ce: 0.001614
2021-11-30 15:37:22,752 iteration 5782 : loss : 0.004024, loss_ce: 0.001709
2021-11-30 15:37:23,968 iteration 5783 : loss : 0.003932, loss_ce: 0.001558
2021-11-30 15:37:25,197 iteration 5784 : loss : 0.003892, loss_ce: 0.001464
2021-11-30 15:37:26,417 iteration 5785 : loss : 0.004567, loss_ce: 0.001464
2021-11-30 15:37:27,642 iteration 5786 : loss : 0.004307, loss_ce: 0.001878
2021-11-30 15:37:28,867 iteration 5787 : loss : 0.003203, loss_ce: 0.001235
2021-11-30 15:37:30,095 iteration 5788 : loss : 0.004749, loss_ce: 0.001867
2021-11-30 15:37:31,323 iteration 5789 : loss : 0.003689, loss_ce: 0.001420
2021-11-30 15:37:32,540 iteration 5790 : loss : 0.005634, loss_ce: 0.002622
2021-11-30 15:37:33,764 iteration 5791 : loss : 0.003351, loss_ce: 0.001514
2021-11-30 15:37:34,993 iteration 5792 : loss : 0.003664, loss_ce: 0.001756
2021-11-30 15:37:36,214 iteration 5793 : loss : 0.003270, loss_ce: 0.001377
2021-11-30 15:37:37,444 iteration 5794 : loss : 0.003866, loss_ce: 0.001494
2021-11-30 15:37:38,671 iteration 5795 : loss : 0.003614, loss_ce: 0.001614
2021-11-30 15:37:39,898 iteration 5796 : loss : 0.003058, loss_ce: 0.001058
2021-11-30 15:37:41,131 iteration 5797 : loss : 0.004771, loss_ce: 0.001492
 85%|████████████████████████▋    | 341/400 [2:09:15<22:49, 23.21s/it]2021-11-30 15:37:42,409 iteration 5798 : loss : 0.004158, loss_ce: 0.001482
2021-11-30 15:37:43,639 iteration 5799 : loss : 0.004187, loss_ce: 0.001583
2021-11-30 15:37:44,865 iteration 5800 : loss : 0.004816, loss_ce: 0.001504
2021-11-30 15:37:46,095 iteration 5801 : loss : 0.003686, loss_ce: 0.001065
2021-11-30 15:37:47,320 iteration 5802 : loss : 0.003183, loss_ce: 0.001163
2021-11-30 15:37:48,541 iteration 5803 : loss : 0.004100, loss_ce: 0.002070
2021-11-30 15:37:49,767 iteration 5804 : loss : 0.003009, loss_ce: 0.001314
2021-11-30 15:37:50,995 iteration 5805 : loss : 0.003906, loss_ce: 0.001303
2021-11-30 15:37:52,216 iteration 5806 : loss : 0.003862, loss_ce: 0.001284
2021-11-30 15:37:53,441 iteration 5807 : loss : 0.003089, loss_ce: 0.001228
2021-11-30 15:37:54,671 iteration 5808 : loss : 0.003710, loss_ce: 0.001780
2021-11-30 15:37:55,899 iteration 5809 : loss : 0.003499, loss_ce: 0.001319
2021-11-30 15:37:57,135 iteration 5810 : loss : 0.003923, loss_ce: 0.001659
2021-11-30 15:37:58,358 iteration 5811 : loss : 0.004256, loss_ce: 0.002017
2021-11-30 15:37:59,585 iteration 5812 : loss : 0.003717, loss_ce: 0.001458
2021-11-30 15:38:00,813 iteration 5813 : loss : 0.003912, loss_ce: 0.001666
2021-11-30 15:38:02,037 iteration 5814 : loss : 0.003723, loss_ce: 0.001596
 86%|████████████████████████▊    | 342/400 [2:09:36<21:46, 22.52s/it]2021-11-30 15:38:03,336 iteration 5815 : loss : 0.005609, loss_ce: 0.001725
2021-11-30 15:38:04,558 iteration 5816 : loss : 0.004423, loss_ce: 0.001507
2021-11-30 15:38:05,778 iteration 5817 : loss : 0.004981, loss_ce: 0.002728
2021-11-30 15:38:07,001 iteration 5818 : loss : 0.003787, loss_ce: 0.001617
2021-11-30 15:38:08,220 iteration 5819 : loss : 0.003420, loss_ce: 0.001511
2021-11-30 15:38:09,437 iteration 5820 : loss : 0.003384, loss_ce: 0.001097
2021-11-30 15:38:10,656 iteration 5821 : loss : 0.004663, loss_ce: 0.001885
2021-11-30 15:38:11,876 iteration 5822 : loss : 0.003227, loss_ce: 0.000838
2021-11-30 15:38:13,095 iteration 5823 : loss : 0.003387, loss_ce: 0.001327
2021-11-30 15:38:14,321 iteration 5824 : loss : 0.003893, loss_ce: 0.001559
2021-11-30 15:38:15,547 iteration 5825 : loss : 0.003520, loss_ce: 0.001190
2021-11-30 15:38:16,753 iteration 5826 : loss : 0.003961, loss_ce: 0.001136
2021-11-30 15:38:17,967 iteration 5827 : loss : 0.004795, loss_ce: 0.001459
2021-11-30 15:38:19,199 iteration 5828 : loss : 0.003526, loss_ce: 0.001616
2021-11-30 15:38:20,419 iteration 5829 : loss : 0.004290, loss_ce: 0.001905
2021-11-30 15:38:21,635 iteration 5830 : loss : 0.005548, loss_ce: 0.002497
2021-11-30 15:38:22,852 iteration 5831 : loss : 0.004477, loss_ce: 0.001834
 86%|████████████████████████▊    | 343/400 [2:09:56<20:54, 22.01s/it]2021-11-30 15:38:24,142 iteration 5832 : loss : 0.005388, loss_ce: 0.002073
2021-11-30 15:38:25,363 iteration 5833 : loss : 0.005940, loss_ce: 0.001467
2021-11-30 15:38:26,589 iteration 5834 : loss : 0.006000, loss_ce: 0.001969
2021-11-30 15:38:27,811 iteration 5835 : loss : 0.004905, loss_ce: 0.001176
2021-11-30 15:38:29,045 iteration 5836 : loss : 0.003392, loss_ce: 0.001274
2021-11-30 15:38:30,268 iteration 5837 : loss : 0.004343, loss_ce: 0.001931
2021-11-30 15:38:31,492 iteration 5838 : loss : 0.005164, loss_ce: 0.001865
2021-11-30 15:38:32,713 iteration 5839 : loss : 0.004077, loss_ce: 0.001365
2021-11-30 15:38:33,934 iteration 5840 : loss : 0.004093, loss_ce: 0.001880
2021-11-30 15:38:35,150 iteration 5841 : loss : 0.004906, loss_ce: 0.002993
2021-11-30 15:38:36,369 iteration 5842 : loss : 0.003127, loss_ce: 0.000980
2021-11-30 15:38:37,594 iteration 5843 : loss : 0.003307, loss_ce: 0.001393
2021-11-30 15:38:38,811 iteration 5844 : loss : 0.004067, loss_ce: 0.001766
2021-11-30 15:38:40,033 iteration 5845 : loss : 0.004743, loss_ce: 0.001708
2021-11-30 15:38:41,255 iteration 5846 : loss : 0.003827, loss_ce: 0.001495
2021-11-30 15:38:42,473 iteration 5847 : loss : 0.003658, loss_ce: 0.001257
2021-11-30 15:38:43,699 iteration 5848 : loss : 0.003707, loss_ce: 0.001550
 86%|████████████████████████▉    | 344/400 [2:10:17<20:13, 21.66s/it]2021-11-30 15:38:44,993 iteration 5849 : loss : 0.003470, loss_ce: 0.001647
2021-11-30 15:38:46,218 iteration 5850 : loss : 0.003546, loss_ce: 0.001691
2021-11-30 15:38:47,439 iteration 5851 : loss : 0.006181, loss_ce: 0.001829
2021-11-30 15:38:48,656 iteration 5852 : loss : 0.003643, loss_ce: 0.001315
2021-11-30 15:38:49,877 iteration 5853 : loss : 0.004094, loss_ce: 0.001426
2021-11-30 15:38:51,106 iteration 5854 : loss : 0.003230, loss_ce: 0.001105
2021-11-30 15:38:52,336 iteration 5855 : loss : 0.003284, loss_ce: 0.001389
2021-11-30 15:38:53,557 iteration 5856 : loss : 0.004407, loss_ce: 0.001970
2021-11-30 15:38:54,784 iteration 5857 : loss : 0.004424, loss_ce: 0.001870
2021-11-30 15:38:56,004 iteration 5858 : loss : 0.004208, loss_ce: 0.001732
2021-11-30 15:38:57,234 iteration 5859 : loss : 0.003677, loss_ce: 0.001076
2021-11-30 15:38:58,457 iteration 5860 : loss : 0.003997, loss_ce: 0.001646
2021-11-30 15:38:59,676 iteration 5861 : loss : 0.004914, loss_ce: 0.002112
2021-11-30 15:39:00,904 iteration 5862 : loss : 0.004926, loss_ce: 0.001955
2021-11-30 15:39:02,128 iteration 5863 : loss : 0.003683, loss_ce: 0.001765
2021-11-30 15:39:03,347 iteration 5864 : loss : 0.003662, loss_ce: 0.001238
2021-11-30 15:39:03,347 Training Data Eval:
2021-11-30 15:39:10,284   Average segmentation loss on training set: 0.0041
2021-11-30 15:39:10,285 Validation Data Eval:
2021-11-30 15:39:12,653   Average segmentation loss on validation set: 0.1453
2021-11-30 15:39:13,884 iteration 5865 : loss : 0.003751, loss_ce: 0.001220
 86%|█████████████████████████    | 345/400 [2:10:47<22:12, 24.22s/it]2021-11-30 15:39:15,184 iteration 5866 : loss : 0.004253, loss_ce: 0.001217
2021-11-30 15:39:16,411 iteration 5867 : loss : 0.003566, loss_ce: 0.001498
2021-11-30 15:39:17,632 iteration 5868 : loss : 0.004449, loss_ce: 0.001903
2021-11-30 15:39:18,858 iteration 5869 : loss : 0.005070, loss_ce: 0.001716
2021-11-30 15:39:20,075 iteration 5870 : loss : 0.003135, loss_ce: 0.001067
2021-11-30 15:39:21,307 iteration 5871 : loss : 0.003345, loss_ce: 0.001278
2021-11-30 15:39:22,536 iteration 5872 : loss : 0.003924, loss_ce: 0.001482
2021-11-30 15:39:23,757 iteration 5873 : loss : 0.004199, loss_ce: 0.001856
2021-11-30 15:39:24,971 iteration 5874 : loss : 0.002936, loss_ce: 0.001069
2021-11-30 15:39:26,199 iteration 5875 : loss : 0.004412, loss_ce: 0.001577
2021-11-30 15:39:27,413 iteration 5876 : loss : 0.003034, loss_ce: 0.001257
2021-11-30 15:39:28,640 iteration 5877 : loss : 0.004020, loss_ce: 0.002019
2021-11-30 15:39:29,865 iteration 5878 : loss : 0.003777, loss_ce: 0.001793
2021-11-30 15:39:31,080 iteration 5879 : loss : 0.003524, loss_ce: 0.001236
2021-11-30 15:39:32,308 iteration 5880 : loss : 0.004501, loss_ce: 0.001462
2021-11-30 15:39:33,526 iteration 5881 : loss : 0.004304, loss_ce: 0.001270
2021-11-30 15:39:34,745 iteration 5882 : loss : 0.003781, loss_ce: 0.001749
 86%|█████████████████████████    | 346/400 [2:11:08<20:53, 23.21s/it]2021-11-30 15:39:36,019 iteration 5883 : loss : 0.003235, loss_ce: 0.001051
2021-11-30 15:39:37,246 iteration 5884 : loss : 0.003412, loss_ce: 0.001411
2021-11-30 15:39:38,467 iteration 5885 : loss : 0.004379, loss_ce: 0.001653
2021-11-30 15:39:39,688 iteration 5886 : loss : 0.003258, loss_ce: 0.001498
2021-11-30 15:39:40,911 iteration 5887 : loss : 0.003549, loss_ce: 0.001040
2021-11-30 15:39:42,139 iteration 5888 : loss : 0.003147, loss_ce: 0.001312
2021-11-30 15:39:43,360 iteration 5889 : loss : 0.003501, loss_ce: 0.001444
2021-11-30 15:39:44,585 iteration 5890 : loss : 0.004179, loss_ce: 0.001806
2021-11-30 15:39:45,805 iteration 5891 : loss : 0.004795, loss_ce: 0.001774
2021-11-30 15:39:47,020 iteration 5892 : loss : 0.004336, loss_ce: 0.001975
2021-11-30 15:39:48,246 iteration 5893 : loss : 0.003999, loss_ce: 0.001780
2021-11-30 15:39:49,472 iteration 5894 : loss : 0.003467, loss_ce: 0.001247
2021-11-30 15:39:50,689 iteration 5895 : loss : 0.003704, loss_ce: 0.001304
2021-11-30 15:39:51,915 iteration 5896 : loss : 0.003687, loss_ce: 0.001523
2021-11-30 15:39:53,137 iteration 5897 : loss : 0.003430, loss_ce: 0.001656
2021-11-30 15:39:54,353 iteration 5898 : loss : 0.003249, loss_ce: 0.001377
2021-11-30 15:39:55,571 iteration 5899 : loss : 0.003814, loss_ce: 0.001318
 87%|█████████████████████████▏   | 347/400 [2:11:29<19:52, 22.50s/it]2021-11-30 15:39:56,865 iteration 5900 : loss : 0.004518, loss_ce: 0.001286
2021-11-30 15:39:58,091 iteration 5901 : loss : 0.003353, loss_ce: 0.001473
2021-11-30 15:39:59,316 iteration 5902 : loss : 0.003114, loss_ce: 0.000894
2021-11-30 15:40:00,540 iteration 5903 : loss : 0.002979, loss_ce: 0.001195
2021-11-30 15:40:01,764 iteration 5904 : loss : 0.003340, loss_ce: 0.001119
2021-11-30 15:40:02,973 iteration 5905 : loss : 0.003426, loss_ce: 0.001305
2021-11-30 15:40:04,193 iteration 5906 : loss : 0.003293, loss_ce: 0.001274
2021-11-30 15:40:05,415 iteration 5907 : loss : 0.004225, loss_ce: 0.001655
2021-11-30 15:40:06,641 iteration 5908 : loss : 0.004747, loss_ce: 0.001258
2021-11-30 15:40:07,861 iteration 5909 : loss : 0.003755, loss_ce: 0.001070
2021-11-30 15:40:09,078 iteration 5910 : loss : 0.003782, loss_ce: 0.002239
2021-11-30 15:40:10,304 iteration 5911 : loss : 0.003705, loss_ce: 0.001498
2021-11-30 15:40:11,529 iteration 5912 : loss : 0.002918, loss_ce: 0.001234
2021-11-30 15:40:12,756 iteration 5913 : loss : 0.003057, loss_ce: 0.001035
2021-11-30 15:40:13,979 iteration 5914 : loss : 0.003881, loss_ce: 0.001875
2021-11-30 15:40:15,203 iteration 5915 : loss : 0.004098, loss_ce: 0.002258
2021-11-30 15:40:16,437 iteration 5916 : loss : 0.004373, loss_ce: 0.002201
 87%|█████████████████████████▏   | 348/400 [2:11:50<19:04, 22.01s/it]2021-11-30 15:40:17,732 iteration 5917 : loss : 0.003805, loss_ce: 0.002010
2021-11-30 15:40:18,955 iteration 5918 : loss : 0.003330, loss_ce: 0.001411
2021-11-30 15:40:20,181 iteration 5919 : loss : 0.003848, loss_ce: 0.001599
2021-11-30 15:40:21,401 iteration 5920 : loss : 0.003153, loss_ce: 0.001249
2021-11-30 15:40:22,632 iteration 5921 : loss : 0.003587, loss_ce: 0.001752
2021-11-30 15:40:23,859 iteration 5922 : loss : 0.004129, loss_ce: 0.001135
2021-11-30 15:40:25,080 iteration 5923 : loss : 0.003012, loss_ce: 0.001258
2021-11-30 15:40:26,311 iteration 5924 : loss : 0.003543, loss_ce: 0.001880
2021-11-30 15:40:27,528 iteration 5925 : loss : 0.002831, loss_ce: 0.001105
2021-11-30 15:40:28,752 iteration 5926 : loss : 0.003105, loss_ce: 0.001135
2021-11-30 15:40:29,976 iteration 5927 : loss : 0.004404, loss_ce: 0.001629
2021-11-30 15:40:31,198 iteration 5928 : loss : 0.003641, loss_ce: 0.001020
2021-11-30 15:40:32,430 iteration 5929 : loss : 0.003060, loss_ce: 0.001306
2021-11-30 15:40:33,655 iteration 5930 : loss : 0.003160, loss_ce: 0.001404
2021-11-30 15:40:34,876 iteration 5931 : loss : 0.004741, loss_ce: 0.001462
2021-11-30 15:40:36,090 iteration 5932 : loss : 0.003066, loss_ce: 0.001247
2021-11-30 15:40:37,318 iteration 5933 : loss : 0.002750, loss_ce: 0.001018
 87%|█████████████████████████▎   | 349/400 [2:12:11<18:25, 21.67s/it]2021-11-30 15:40:38,641 iteration 5934 : loss : 0.004026, loss_ce: 0.001868
2021-11-30 15:40:39,867 iteration 5935 : loss : 0.002974, loss_ce: 0.001199
2021-11-30 15:40:41,088 iteration 5936 : loss : 0.003523, loss_ce: 0.001342
2021-11-30 15:40:42,313 iteration 5937 : loss : 0.003271, loss_ce: 0.000977
2021-11-30 15:40:43,540 iteration 5938 : loss : 0.003517, loss_ce: 0.001398
2021-11-30 15:40:44,754 iteration 5939 : loss : 0.003223, loss_ce: 0.001606
2021-11-30 15:40:45,979 iteration 5940 : loss : 0.002708, loss_ce: 0.001079
2021-11-30 15:40:47,205 iteration 5941 : loss : 0.003603, loss_ce: 0.001839
2021-11-30 15:40:48,431 iteration 5942 : loss : 0.003583, loss_ce: 0.001704
2021-11-30 15:40:49,655 iteration 5943 : loss : 0.003019, loss_ce: 0.001242
2021-11-30 15:40:50,878 iteration 5944 : loss : 0.004171, loss_ce: 0.001647
2021-11-30 15:40:52,104 iteration 5945 : loss : 0.002857, loss_ce: 0.000915
2021-11-30 15:40:53,333 iteration 5946 : loss : 0.003021, loss_ce: 0.001262
2021-11-30 15:40:54,561 iteration 5947 : loss : 0.004645, loss_ce: 0.002314
2021-11-30 15:40:55,775 iteration 5948 : loss : 0.003724, loss_ce: 0.001470
2021-11-30 15:40:56,992 iteration 5949 : loss : 0.003762, loss_ce: 0.001409
2021-11-30 15:40:56,992 Training Data Eval:
2021-11-30 15:41:03,927   Average segmentation loss on training set: 0.0035
2021-11-30 15:41:03,928 Validation Data Eval:
2021-11-30 15:41:06,315   Average segmentation loss on validation set: 0.1486
2021-11-30 15:41:07,537 iteration 5950 : loss : 0.003329, loss_ce: 0.001354
 88%|█████████████████████████▍   | 350/400 [2:12:41<20:11, 24.23s/it]2021-11-30 15:41:08,827 iteration 5951 : loss : 0.003556, loss_ce: 0.001223
2021-11-30 15:41:10,037 iteration 5952 : loss : 0.003336, loss_ce: 0.001659
2021-11-30 15:41:11,263 iteration 5953 : loss : 0.003267, loss_ce: 0.001023
2021-11-30 15:41:12,478 iteration 5954 : loss : 0.003722, loss_ce: 0.001872
2021-11-30 15:41:13,700 iteration 5955 : loss : 0.003220, loss_ce: 0.001742
2021-11-30 15:41:14,929 iteration 5956 : loss : 0.002983, loss_ce: 0.001281
2021-11-30 15:41:16,140 iteration 5957 : loss : 0.005093, loss_ce: 0.002125
2021-11-30 15:41:17,366 iteration 5958 : loss : 0.002819, loss_ce: 0.001269
2021-11-30 15:41:18,588 iteration 5959 : loss : 0.003369, loss_ce: 0.001475
2021-11-30 15:41:19,801 iteration 5960 : loss : 0.003045, loss_ce: 0.001314
2021-11-30 15:41:21,025 iteration 5961 : loss : 0.004706, loss_ce: 0.001013
2021-11-30 15:41:22,251 iteration 5962 : loss : 0.003521, loss_ce: 0.001518
2021-11-30 15:41:23,477 iteration 5963 : loss : 0.003958, loss_ce: 0.001134
2021-11-30 15:41:24,687 iteration 5964 : loss : 0.004317, loss_ce: 0.001394
2021-11-30 15:41:25,903 iteration 5965 : loss : 0.003341, loss_ce: 0.001281
2021-11-30 15:41:27,128 iteration 5966 : loss : 0.003147, loss_ce: 0.000871
2021-11-30 15:41:28,340 iteration 5967 : loss : 0.004931, loss_ce: 0.001339
 88%|█████████████████████████▍   | 351/400 [2:13:02<18:56, 23.20s/it]2021-11-30 15:41:29,627 iteration 5968 : loss : 0.003222, loss_ce: 0.001282
2021-11-30 15:41:30,867 iteration 5969 : loss : 0.003394, loss_ce: 0.001229
2021-11-30 15:41:32,077 iteration 5970 : loss : 0.004741, loss_ce: 0.001702
2021-11-30 15:41:33,295 iteration 5971 : loss : 0.003141, loss_ce: 0.001169
2021-11-30 15:41:34,512 iteration 5972 : loss : 0.004693, loss_ce: 0.001912
2021-11-30 15:41:35,745 iteration 5973 : loss : 0.003286, loss_ce: 0.000884
2021-11-30 15:41:36,966 iteration 5974 : loss : 0.004062, loss_ce: 0.001777
2021-11-30 15:41:38,188 iteration 5975 : loss : 0.004087, loss_ce: 0.001575
2021-11-30 15:41:39,407 iteration 5976 : loss : 0.003608, loss_ce: 0.001307
2021-11-30 15:41:40,634 iteration 5977 : loss : 0.003162, loss_ce: 0.001219
2021-11-30 15:41:41,852 iteration 5978 : loss : 0.004390, loss_ce: 0.001693
2021-11-30 15:41:43,071 iteration 5979 : loss : 0.003232, loss_ce: 0.001188
2021-11-30 15:41:44,297 iteration 5980 : loss : 0.003978, loss_ce: 0.001598
2021-11-30 15:41:45,523 iteration 5981 : loss : 0.003182, loss_ce: 0.001404
2021-11-30 15:41:46,744 iteration 5982 : loss : 0.003388, loss_ce: 0.001718
2021-11-30 15:41:47,968 iteration 5983 : loss : 0.002934, loss_ce: 0.001132
2021-11-30 15:41:49,188 iteration 5984 : loss : 0.002892, loss_ce: 0.001109
 88%|█████████████████████████▌   | 352/400 [2:13:23<17:59, 22.50s/it]2021-11-30 15:41:50,478 iteration 5985 : loss : 0.004337, loss_ce: 0.001796
2021-11-30 15:41:51,696 iteration 5986 : loss : 0.003770, loss_ce: 0.001498
2021-11-30 15:41:52,918 iteration 5987 : loss : 0.004049, loss_ce: 0.001934
2021-11-30 15:41:54,147 iteration 5988 : loss : 0.002964, loss_ce: 0.000888
2021-11-30 15:41:55,375 iteration 5989 : loss : 0.003111, loss_ce: 0.000720
2021-11-30 15:41:56,596 iteration 5990 : loss : 0.002939, loss_ce: 0.001450
2021-11-30 15:41:57,819 iteration 5991 : loss : 0.004097, loss_ce: 0.002023
2021-11-30 15:41:59,047 iteration 5992 : loss : 0.003423, loss_ce: 0.001160
2021-11-30 15:42:00,267 iteration 5993 : loss : 0.003357, loss_ce: 0.001449
2021-11-30 15:42:01,490 iteration 5994 : loss : 0.003025, loss_ce: 0.000882
2021-11-30 15:42:02,712 iteration 5995 : loss : 0.003759, loss_ce: 0.001580
2021-11-30 15:42:03,941 iteration 5996 : loss : 0.004615, loss_ce: 0.001428
2021-11-30 15:42:05,162 iteration 5997 : loss : 0.003742, loss_ce: 0.001309
2021-11-30 15:42:06,389 iteration 5998 : loss : 0.003980, loss_ce: 0.002050
2021-11-30 15:42:07,609 iteration 5999 : loss : 0.004023, loss_ce: 0.001490
2021-11-30 15:42:08,833 iteration 6000 : loss : 0.003827, loss_ce: 0.001295
2021-11-30 15:42:10,052 iteration 6001 : loss : 0.003562, loss_ce: 0.001334
 88%|█████████████████████████▌   | 353/400 [2:13:44<17:14, 22.01s/it]2021-11-30 15:42:11,343 iteration 6002 : loss : 0.004403, loss_ce: 0.001981
2021-11-30 15:42:12,568 iteration 6003 : loss : 0.004287, loss_ce: 0.001460
2021-11-30 15:42:13,794 iteration 6004 : loss : 0.003077, loss_ce: 0.001223
2021-11-30 15:42:15,020 iteration 6005 : loss : 0.003976, loss_ce: 0.001839
2021-11-30 15:42:16,244 iteration 6006 : loss : 0.004275, loss_ce: 0.001495
2021-11-30 15:42:17,460 iteration 6007 : loss : 0.002678, loss_ce: 0.001011
2021-11-30 15:42:18,684 iteration 6008 : loss : 0.003204, loss_ce: 0.001134
2021-11-30 15:42:19,905 iteration 6009 : loss : 0.002708, loss_ce: 0.000917
2021-11-30 15:42:21,132 iteration 6010 : loss : 0.003996, loss_ce: 0.001931
2021-11-30 15:42:22,350 iteration 6011 : loss : 0.003538, loss_ce: 0.001365
2021-11-30 15:42:23,572 iteration 6012 : loss : 0.002565, loss_ce: 0.001168
2021-11-30 15:42:24,799 iteration 6013 : loss : 0.003533, loss_ce: 0.001634
2021-11-30 15:42:26,021 iteration 6014 : loss : 0.003919, loss_ce: 0.001362
2021-11-30 15:42:27,242 iteration 6015 : loss : 0.003144, loss_ce: 0.001303
2021-11-30 15:42:28,464 iteration 6016 : loss : 0.002658, loss_ce: 0.001007
2021-11-30 15:42:29,685 iteration 6017 : loss : 0.003019, loss_ce: 0.000859
2021-11-30 15:42:30,903 iteration 6018 : loss : 0.004281, loss_ce: 0.002194
 88%|█████████████████████████▋   | 354/400 [2:14:04<16:36, 21.66s/it]2021-11-30 15:42:32,199 iteration 6019 : loss : 0.003526, loss_ce: 0.001663
2021-11-30 15:42:33,428 iteration 6020 : loss : 0.003211, loss_ce: 0.001097
2021-11-30 15:42:34,645 iteration 6021 : loss : 0.003351, loss_ce: 0.001286
2021-11-30 15:42:35,871 iteration 6022 : loss : 0.004117, loss_ce: 0.001309
2021-11-30 15:42:37,099 iteration 6023 : loss : 0.003482, loss_ce: 0.001361
2021-11-30 15:42:38,322 iteration 6024 : loss : 0.003834, loss_ce: 0.001857
2021-11-30 15:42:39,555 iteration 6025 : loss : 0.002701, loss_ce: 0.000967
2021-11-30 15:42:40,783 iteration 6026 : loss : 0.003419, loss_ce: 0.001642
2021-11-30 15:42:42,005 iteration 6027 : loss : 0.003813, loss_ce: 0.001774
2021-11-30 15:42:43,230 iteration 6028 : loss : 0.003107, loss_ce: 0.001072
2021-11-30 15:42:44,464 iteration 6029 : loss : 0.003257, loss_ce: 0.001313
2021-11-30 15:42:45,691 iteration 6030 : loss : 0.002872, loss_ce: 0.001159
2021-11-30 15:42:46,914 iteration 6031 : loss : 0.002477, loss_ce: 0.000937
2021-11-30 15:42:48,145 iteration 6032 : loss : 0.003875, loss_ce: 0.001567
2021-11-30 15:42:49,374 iteration 6033 : loss : 0.003588, loss_ce: 0.001664
2021-11-30 15:42:50,596 iteration 6034 : loss : 0.004209, loss_ce: 0.001759
2021-11-30 15:42:50,596 Training Data Eval:
2021-11-30 15:42:57,528   Average segmentation loss on training set: 0.0032
2021-11-30 15:42:57,529 Validation Data Eval:
2021-11-30 15:42:59,904   Average segmentation loss on validation set: 0.1456
2021-11-30 15:43:01,136 iteration 6035 : loss : 0.003185, loss_ce: 0.001084
 89%|█████████████████████████▋   | 355/400 [2:14:35<18:10, 24.23s/it]2021-11-30 15:43:02,434 iteration 6036 : loss : 0.003364, loss_ce: 0.001328
2021-11-30 15:43:03,657 iteration 6037 : loss : 0.004114, loss_ce: 0.001741
2021-11-30 15:43:04,881 iteration 6038 : loss : 0.004204, loss_ce: 0.001345
2021-11-30 15:43:06,111 iteration 6039 : loss : 0.004021, loss_ce: 0.001555
2021-11-30 15:43:07,339 iteration 6040 : loss : 0.003361, loss_ce: 0.001435
2021-11-30 15:43:08,557 iteration 6041 : loss : 0.003121, loss_ce: 0.001416
2021-11-30 15:43:09,782 iteration 6042 : loss : 0.003433, loss_ce: 0.001725
2021-11-30 15:43:11,008 iteration 6043 : loss : 0.003794, loss_ce: 0.001598
2021-11-30 15:43:12,226 iteration 6044 : loss : 0.004232, loss_ce: 0.001580
2021-11-30 15:43:13,451 iteration 6045 : loss : 0.003305, loss_ce: 0.001149
2021-11-30 15:43:14,672 iteration 6046 : loss : 0.003594, loss_ce: 0.000913
2021-11-30 15:43:15,891 iteration 6047 : loss : 0.002870, loss_ce: 0.001214
2021-11-30 15:43:17,109 iteration 6048 : loss : 0.003061, loss_ce: 0.001699
2021-11-30 15:43:18,332 iteration 6049 : loss : 0.003018, loss_ce: 0.001241
2021-11-30 15:43:19,556 iteration 6050 : loss : 0.003022, loss_ce: 0.000849
2021-11-30 15:43:20,781 iteration 6051 : loss : 0.003257, loss_ce: 0.001356
2021-11-30 15:43:22,013 iteration 6052 : loss : 0.003790, loss_ce: 0.001121
 89%|█████████████████████████▊   | 356/400 [2:14:56<17:01, 23.22s/it]2021-11-30 15:43:23,303 iteration 6053 : loss : 0.003227, loss_ce: 0.001299
2021-11-30 15:43:24,544 iteration 6054 : loss : 0.003898, loss_ce: 0.001914
2021-11-30 15:43:25,766 iteration 6055 : loss : 0.002965, loss_ce: 0.001313
2021-11-30 15:43:26,992 iteration 6056 : loss : 0.003595, loss_ce: 0.001484
2021-11-30 15:43:28,217 iteration 6057 : loss : 0.003411, loss_ce: 0.000847
2021-11-30 15:43:29,445 iteration 6058 : loss : 0.003642, loss_ce: 0.001642
2021-11-30 15:43:30,676 iteration 6059 : loss : 0.003064, loss_ce: 0.001452
2021-11-30 15:43:31,903 iteration 6060 : loss : 0.002907, loss_ce: 0.001021
2021-11-30 15:43:33,124 iteration 6061 : loss : 0.003304, loss_ce: 0.001046
2021-11-30 15:43:34,348 iteration 6062 : loss : 0.002704, loss_ce: 0.000905
2021-11-30 15:43:35,575 iteration 6063 : loss : 0.004285, loss_ce: 0.001530
2021-11-30 15:43:36,804 iteration 6064 : loss : 0.003619, loss_ce: 0.001560
2021-11-30 15:43:38,028 iteration 6065 : loss : 0.003199, loss_ce: 0.001553
2021-11-30 15:43:39,256 iteration 6066 : loss : 0.003629, loss_ce: 0.001443
2021-11-30 15:43:40,479 iteration 6067 : loss : 0.003249, loss_ce: 0.001736
2021-11-30 15:43:41,704 iteration 6068 : loss : 0.003680, loss_ce: 0.001279
2021-11-30 15:43:42,928 iteration 6069 : loss : 0.003267, loss_ce: 0.001036
 89%|█████████████████████████▉   | 357/400 [2:15:16<16:08, 22.53s/it]2021-11-30 15:43:44,230 iteration 6070 : loss : 0.003319, loss_ce: 0.001498
2021-11-30 15:43:45,455 iteration 6071 : loss : 0.004770, loss_ce: 0.001939
2021-11-30 15:43:46,681 iteration 6072 : loss : 0.002603, loss_ce: 0.001205
2021-11-30 15:43:47,913 iteration 6073 : loss : 0.003103, loss_ce: 0.001279
2021-11-30 15:43:49,139 iteration 6074 : loss : 0.002869, loss_ce: 0.001360
2021-11-30 15:43:50,367 iteration 6075 : loss : 0.003438, loss_ce: 0.000953
2021-11-30 15:43:51,595 iteration 6076 : loss : 0.003048, loss_ce: 0.001156
2021-11-30 15:43:52,820 iteration 6077 : loss : 0.003280, loss_ce: 0.001286
2021-11-30 15:43:54,045 iteration 6078 : loss : 0.003410, loss_ce: 0.001515
2021-11-30 15:43:55,275 iteration 6079 : loss : 0.004093, loss_ce: 0.001771
2021-11-30 15:43:56,505 iteration 6080 : loss : 0.003420, loss_ce: 0.001726
2021-11-30 15:43:57,734 iteration 6081 : loss : 0.002573, loss_ce: 0.000902
2021-11-30 15:43:58,962 iteration 6082 : loss : 0.002702, loss_ce: 0.001289
2021-11-30 15:44:00,183 iteration 6083 : loss : 0.002629, loss_ce: 0.000986
2021-11-30 15:44:01,416 iteration 6084 : loss : 0.003299, loss_ce: 0.001595
2021-11-30 15:44:02,644 iteration 6085 : loss : 0.002933, loss_ce: 0.001023
2021-11-30 15:44:03,874 iteration 6086 : loss : 0.002941, loss_ce: 0.001059
 90%|█████████████████████████▉   | 358/400 [2:15:37<15:26, 22.06s/it]2021-11-30 15:44:05,170 iteration 6087 : loss : 0.003221, loss_ce: 0.001420
2021-11-30 15:44:06,393 iteration 6088 : loss : 0.002582, loss_ce: 0.000989
2021-11-30 15:44:07,619 iteration 6089 : loss : 0.003101, loss_ce: 0.001084
2021-11-30 15:44:08,845 iteration 6090 : loss : 0.003196, loss_ce: 0.001675
2021-11-30 15:44:10,074 iteration 6091 : loss : 0.003278, loss_ce: 0.001403
2021-11-30 15:44:11,302 iteration 6092 : loss : 0.002676, loss_ce: 0.001295
2021-11-30 15:44:12,526 iteration 6093 : loss : 0.003974, loss_ce: 0.001611
2021-11-30 15:44:13,745 iteration 6094 : loss : 0.002690, loss_ce: 0.001043
2021-11-30 15:44:14,977 iteration 6095 : loss : 0.003007, loss_ce: 0.001032
2021-11-30 15:44:16,206 iteration 6096 : loss : 0.003838, loss_ce: 0.001192
2021-11-30 15:44:17,432 iteration 6097 : loss : 0.002901, loss_ce: 0.001392
2021-11-30 15:44:18,656 iteration 6098 : loss : 0.003327, loss_ce: 0.001531
2021-11-30 15:44:19,883 iteration 6099 : loss : 0.002707, loss_ce: 0.000974
2021-11-30 15:44:21,110 iteration 6100 : loss : 0.003023, loss_ce: 0.001011
2021-11-30 15:44:22,333 iteration 6101 : loss : 0.004380, loss_ce: 0.001951
2021-11-30 15:44:23,569 iteration 6102 : loss : 0.002606, loss_ce: 0.000994
2021-11-30 15:44:24,796 iteration 6103 : loss : 0.002506, loss_ce: 0.000798
 90%|██████████████████████████   | 359/400 [2:15:58<14:50, 21.72s/it]2021-11-30 15:44:26,093 iteration 6104 : loss : 0.003861, loss_ce: 0.001587
2021-11-30 15:44:27,319 iteration 6105 : loss : 0.003646, loss_ce: 0.001050
2021-11-30 15:44:28,537 iteration 6106 : loss : 0.003282, loss_ce: 0.001512
2021-11-30 15:44:29,757 iteration 6107 : loss : 0.003364, loss_ce: 0.001012
2021-11-30 15:44:30,984 iteration 6108 : loss : 0.003664, loss_ce: 0.001409
2021-11-30 15:44:32,209 iteration 6109 : loss : 0.003383, loss_ce: 0.001200
2021-11-30 15:44:33,432 iteration 6110 : loss : 0.002818, loss_ce: 0.001241
2021-11-30 15:44:34,655 iteration 6111 : loss : 0.004002, loss_ce: 0.001714
2021-11-30 15:44:35,880 iteration 6112 : loss : 0.003377, loss_ce: 0.001683
2021-11-30 15:44:37,104 iteration 6113 : loss : 0.003027, loss_ce: 0.000963
2021-11-30 15:44:38,334 iteration 6114 : loss : 0.002534, loss_ce: 0.001075
2021-11-30 15:44:39,556 iteration 6115 : loss : 0.003425, loss_ce: 0.001491
2021-11-30 15:44:40,779 iteration 6116 : loss : 0.003388, loss_ce: 0.001047
2021-11-30 15:44:42,002 iteration 6117 : loss : 0.003497, loss_ce: 0.001245
2021-11-30 15:44:43,225 iteration 6118 : loss : 0.002659, loss_ce: 0.001138
2021-11-30 15:44:44,454 iteration 6119 : loss : 0.003132, loss_ce: 0.001601
2021-11-30 15:44:44,455 Training Data Eval:
2021-11-30 15:44:51,386   Average segmentation loss on training set: 0.0029
2021-11-30 15:44:51,386 Validation Data Eval:
2021-11-30 15:44:53,765   Average segmentation loss on validation set: 0.1491
2021-11-30 15:44:54,988 iteration 6120 : loss : 0.003376, loss_ce: 0.001621
 90%|██████████████████████████   | 360/400 [2:16:29<16:10, 24.26s/it]2021-11-30 15:44:56,276 iteration 6121 : loss : 0.002646, loss_ce: 0.000933
2021-11-30 15:44:57,503 iteration 6122 : loss : 0.003635, loss_ce: 0.001524
2021-11-30 15:44:58,729 iteration 6123 : loss : 0.003012, loss_ce: 0.001245
2021-11-30 15:44:59,945 iteration 6124 : loss : 0.003349, loss_ce: 0.001116
2021-11-30 15:45:01,165 iteration 6125 : loss : 0.003084, loss_ce: 0.001561
2021-11-30 15:45:02,384 iteration 6126 : loss : 0.003431, loss_ce: 0.001579
2021-11-30 15:45:03,605 iteration 6127 : loss : 0.002896, loss_ce: 0.001260
2021-11-30 15:45:04,829 iteration 6128 : loss : 0.003158, loss_ce: 0.000970
2021-11-30 15:45:06,043 iteration 6129 : loss : 0.004635, loss_ce: 0.001493
2021-11-30 15:45:07,273 iteration 6130 : loss : 0.003339, loss_ce: 0.001591
2021-11-30 15:45:08,491 iteration 6131 : loss : 0.003746, loss_ce: 0.001299
2021-11-30 15:45:09,724 iteration 6132 : loss : 0.002980, loss_ce: 0.001195
2021-11-30 15:45:10,944 iteration 6133 : loss : 0.003379, loss_ce: 0.001230
2021-11-30 15:45:12,170 iteration 6134 : loss : 0.002416, loss_ce: 0.000887
2021-11-30 15:45:13,395 iteration 6135 : loss : 0.002856, loss_ce: 0.000875
2021-11-30 15:45:14,616 iteration 6136 : loss : 0.002974, loss_ce: 0.001214
2021-11-30 15:45:15,838 iteration 6137 : loss : 0.005039, loss_ce: 0.002414
 90%|██████████████████████████▏  | 361/400 [2:16:49<15:06, 23.24s/it]2021-11-30 15:45:17,130 iteration 6138 : loss : 0.002825, loss_ce: 0.000824
2021-11-30 15:45:18,350 iteration 6139 : loss : 0.002701, loss_ce: 0.001078
2021-11-30 15:45:19,573 iteration 6140 : loss : 0.003351, loss_ce: 0.001455
2021-11-30 15:45:20,793 iteration 6141 : loss : 0.003626, loss_ce: 0.001482
2021-11-30 15:45:22,012 iteration 6142 : loss : 0.003189, loss_ce: 0.001248
2021-11-30 15:45:23,236 iteration 6143 : loss : 0.003187, loss_ce: 0.001445
2021-11-30 15:45:24,452 iteration 6144 : loss : 0.002841, loss_ce: 0.001002
2021-11-30 15:45:25,677 iteration 6145 : loss : 0.003044, loss_ce: 0.001161
2021-11-30 15:45:26,895 iteration 6146 : loss : 0.003081, loss_ce: 0.001213
2021-11-30 15:45:28,120 iteration 6147 : loss : 0.003558, loss_ce: 0.001461
2021-11-30 15:45:29,346 iteration 6148 : loss : 0.003382, loss_ce: 0.001718
2021-11-30 15:45:30,566 iteration 6149 : loss : 0.003093, loss_ce: 0.001040
2021-11-30 15:45:31,788 iteration 6150 : loss : 0.003751, loss_ce: 0.001903
2021-11-30 15:45:33,012 iteration 6151 : loss : 0.002774, loss_ce: 0.001229
2021-11-30 15:45:34,233 iteration 6152 : loss : 0.002559, loss_ce: 0.001044
2021-11-30 15:45:35,456 iteration 6153 : loss : 0.003250, loss_ce: 0.000931
2021-11-30 15:45:36,683 iteration 6154 : loss : 0.003529, loss_ce: 0.001529
 90%|██████████████████████████▏  | 362/400 [2:17:10<14:15, 22.52s/it]2021-11-30 15:45:37,969 iteration 6155 : loss : 0.003177, loss_ce: 0.001453
2021-11-30 15:45:39,189 iteration 6156 : loss : 0.003104, loss_ce: 0.001271
2021-11-30 15:45:40,406 iteration 6157 : loss : 0.004249, loss_ce: 0.001185
2021-11-30 15:45:41,624 iteration 6158 : loss : 0.002963, loss_ce: 0.001546
2021-11-30 15:45:42,844 iteration 6159 : loss : 0.003415, loss_ce: 0.000968
2021-11-30 15:45:44,062 iteration 6160 : loss : 0.003673, loss_ce: 0.001060
2021-11-30 15:45:45,287 iteration 6161 : loss : 0.003862, loss_ce: 0.001759
2021-11-30 15:45:46,512 iteration 6162 : loss : 0.004004, loss_ce: 0.001582
2021-11-30 15:45:47,735 iteration 6163 : loss : 0.002652, loss_ce: 0.001121
2021-11-30 15:45:48,960 iteration 6164 : loss : 0.002718, loss_ce: 0.001158
2021-11-30 15:45:50,190 iteration 6165 : loss : 0.002928, loss_ce: 0.001155
2021-11-30 15:45:51,410 iteration 6166 : loss : 0.002572, loss_ce: 0.001052
2021-11-30 15:45:52,638 iteration 6167 : loss : 0.003567, loss_ce: 0.001000
2021-11-30 15:45:53,871 iteration 6168 : loss : 0.003539, loss_ce: 0.001473
2021-11-30 15:45:55,091 iteration 6169 : loss : 0.004577, loss_ce: 0.002335
2021-11-30 15:45:56,325 iteration 6170 : loss : 0.003322, loss_ce: 0.001159
2021-11-30 15:45:57,549 iteration 6171 : loss : 0.003768, loss_ce: 0.001160
 91%|██████████████████████████▎  | 363/400 [2:17:31<13:34, 22.02s/it]2021-11-30 15:45:58,841 iteration 6172 : loss : 0.002503, loss_ce: 0.001313
2021-11-30 15:46:00,069 iteration 6173 : loss : 0.003055, loss_ce: 0.001104
2021-11-30 15:46:01,296 iteration 6174 : loss : 0.002917, loss_ce: 0.000969
2021-11-30 15:46:02,522 iteration 6175 : loss : 0.003122, loss_ce: 0.001043
2021-11-30 15:46:03,749 iteration 6176 : loss : 0.003165, loss_ce: 0.001495
2021-11-30 15:46:04,976 iteration 6177 : loss : 0.002722, loss_ce: 0.001351
2021-11-30 15:46:06,206 iteration 6178 : loss : 0.003527, loss_ce: 0.001430
2021-11-30 15:46:07,435 iteration 6179 : loss : 0.003618, loss_ce: 0.001493
2021-11-30 15:46:08,658 iteration 6180 : loss : 0.003066, loss_ce: 0.000972
2021-11-30 15:46:09,888 iteration 6181 : loss : 0.003778, loss_ce: 0.001097
2021-11-30 15:46:11,110 iteration 6182 : loss : 0.003379, loss_ce: 0.001333
2021-11-30 15:46:12,337 iteration 6183 : loss : 0.002970, loss_ce: 0.001253
2021-11-30 15:46:13,562 iteration 6184 : loss : 0.003467, loss_ce: 0.001096
2021-11-30 15:46:14,781 iteration 6185 : loss : 0.003207, loss_ce: 0.001466
2021-11-30 15:46:16,009 iteration 6186 : loss : 0.004065, loss_ce: 0.001284
2021-11-30 15:46:17,232 iteration 6187 : loss : 0.004103, loss_ce: 0.001742
2021-11-30 15:46:18,456 iteration 6188 : loss : 0.003311, loss_ce: 0.001314
 91%|██████████████████████████▍  | 364/400 [2:17:52<13:00, 21.69s/it]2021-11-30 15:46:19,754 iteration 6189 : loss : 0.003127, loss_ce: 0.000911
2021-11-30 15:46:20,976 iteration 6190 : loss : 0.003372, loss_ce: 0.001643
2021-11-30 15:46:22,202 iteration 6191 : loss : 0.002728, loss_ce: 0.000898
2021-11-30 15:46:23,427 iteration 6192 : loss : 0.003122, loss_ce: 0.001408
2021-11-30 15:46:24,654 iteration 6193 : loss : 0.003342, loss_ce: 0.001409
2021-11-30 15:46:25,885 iteration 6194 : loss : 0.002802, loss_ce: 0.001146
2021-11-30 15:46:27,109 iteration 6195 : loss : 0.002706, loss_ce: 0.000822
2021-11-30 15:46:28,328 iteration 6196 : loss : 0.003434, loss_ce: 0.001654
2021-11-30 15:46:29,549 iteration 6197 : loss : 0.003103, loss_ce: 0.001104
2021-11-30 15:46:30,769 iteration 6198 : loss : 0.003044, loss_ce: 0.001347
2021-11-30 15:46:31,992 iteration 6199 : loss : 0.003122, loss_ce: 0.001448
2021-11-30 15:46:33,218 iteration 6200 : loss : 0.002798, loss_ce: 0.001092
2021-11-30 15:46:34,439 iteration 6201 : loss : 0.002707, loss_ce: 0.000931
2021-11-30 15:46:35,667 iteration 6202 : loss : 0.003962, loss_ce: 0.001976
2021-11-30 15:46:36,900 iteration 6203 : loss : 0.003396, loss_ce: 0.001130
2021-11-30 15:46:38,124 iteration 6204 : loss : 0.003081, loss_ce: 0.001508
2021-11-30 15:46:38,125 Training Data Eval:
2021-11-30 15:46:45,070   Average segmentation loss on training set: 0.0027
2021-11-30 15:46:45,070 Validation Data Eval:
2021-11-30 15:46:47,445   Average segmentation loss on validation set: 0.1529
2021-11-30 15:46:48,669 iteration 6205 : loss : 0.003890, loss_ce: 0.001425
 91%|██████████████████████████▍  | 365/400 [2:18:22<14:08, 24.25s/it]2021-11-30 15:46:49,960 iteration 6206 : loss : 0.002923, loss_ce: 0.001242
2021-11-30 15:46:51,185 iteration 6207 : loss : 0.002286, loss_ce: 0.001001
2021-11-30 15:46:52,411 iteration 6208 : loss : 0.002846, loss_ce: 0.001092
2021-11-30 15:46:53,635 iteration 6209 : loss : 0.003449, loss_ce: 0.001463
2021-11-30 15:46:54,856 iteration 6210 : loss : 0.003749, loss_ce: 0.001181
2021-11-30 15:46:56,074 iteration 6211 : loss : 0.003561, loss_ce: 0.001488
2021-11-30 15:46:57,303 iteration 6212 : loss : 0.003701, loss_ce: 0.001767
2021-11-30 15:46:58,533 iteration 6213 : loss : 0.002836, loss_ce: 0.000942
2021-11-30 15:46:59,753 iteration 6214 : loss : 0.003455, loss_ce: 0.001953
2021-11-30 15:47:00,973 iteration 6215 : loss : 0.004149, loss_ce: 0.001689
2021-11-30 15:47:02,195 iteration 6216 : loss : 0.003678, loss_ce: 0.001036
2021-11-30 15:47:03,418 iteration 6217 : loss : 0.003513, loss_ce: 0.001505
2021-11-30 15:47:04,641 iteration 6218 : loss : 0.002860, loss_ce: 0.001487
2021-11-30 15:47:05,860 iteration 6219 : loss : 0.002748, loss_ce: 0.000855
2021-11-30 15:47:07,083 iteration 6220 : loss : 0.003028, loss_ce: 0.001257
2021-11-30 15:47:08,307 iteration 6221 : loss : 0.003518, loss_ce: 0.001507
2021-11-30 15:47:09,534 iteration 6222 : loss : 0.003347, loss_ce: 0.001303
 92%|██████████████████████████▌  | 366/400 [2:18:43<13:09, 23.23s/it]2021-11-30 15:47:10,833 iteration 6223 : loss : 0.003378, loss_ce: 0.001066
2021-11-30 15:47:12,050 iteration 6224 : loss : 0.003839, loss_ce: 0.001415
2021-11-30 15:47:13,272 iteration 6225 : loss : 0.003188, loss_ce: 0.001710
2021-11-30 15:47:14,501 iteration 6226 : loss : 0.002964, loss_ce: 0.001110
2021-11-30 15:47:15,729 iteration 6227 : loss : 0.003032, loss_ce: 0.001025
2021-11-30 15:47:16,944 iteration 6228 : loss : 0.003918, loss_ce: 0.001924
2021-11-30 15:47:18,168 iteration 6229 : loss : 0.002917, loss_ce: 0.001295
2021-11-30 15:47:19,394 iteration 6230 : loss : 0.003119, loss_ce: 0.001705
2021-11-30 15:47:20,613 iteration 6231 : loss : 0.003049, loss_ce: 0.001379
2021-11-30 15:47:21,840 iteration 6232 : loss : 0.002352, loss_ce: 0.000952
2021-11-30 15:47:23,067 iteration 6233 : loss : 0.002905, loss_ce: 0.000993
2021-11-30 15:47:24,295 iteration 6234 : loss : 0.003300, loss_ce: 0.001178
2021-11-30 15:47:25,517 iteration 6235 : loss : 0.003335, loss_ce: 0.001268
2021-11-30 15:47:26,742 iteration 6236 : loss : 0.003659, loss_ce: 0.001661
2021-11-30 15:47:27,960 iteration 6237 : loss : 0.002709, loss_ce: 0.001001
2021-11-30 15:47:29,187 iteration 6238 : loss : 0.003451, loss_ce: 0.001221
2021-11-30 15:47:30,410 iteration 6239 : loss : 0.003302, loss_ce: 0.001592
 92%|██████████████████████████▌  | 367/400 [2:19:04<12:23, 22.53s/it]2021-11-30 15:47:31,695 iteration 6240 : loss : 0.002766, loss_ce: 0.000958
2021-11-30 15:47:32,918 iteration 6241 : loss : 0.003354, loss_ce: 0.001184
2021-11-30 15:47:34,143 iteration 6242 : loss : 0.002638, loss_ce: 0.001040
2021-11-30 15:47:35,374 iteration 6243 : loss : 0.003054, loss_ce: 0.001457
2021-11-30 15:47:36,601 iteration 6244 : loss : 0.002872, loss_ce: 0.001103
2021-11-30 15:47:37,817 iteration 6245 : loss : 0.003073, loss_ce: 0.000867
2021-11-30 15:47:39,044 iteration 6246 : loss : 0.003078, loss_ce: 0.001511
2021-11-30 15:47:40,269 iteration 6247 : loss : 0.003262, loss_ce: 0.001449
2021-11-30 15:47:41,496 iteration 6248 : loss : 0.002478, loss_ce: 0.000869
2021-11-30 15:47:42,721 iteration 6249 : loss : 0.003287, loss_ce: 0.001351
2021-11-30 15:47:43,948 iteration 6250 : loss : 0.003164, loss_ce: 0.001269
2021-11-30 15:47:45,169 iteration 6251 : loss : 0.003235, loss_ce: 0.001285
2021-11-30 15:47:46,391 iteration 6252 : loss : 0.003047, loss_ce: 0.001350
2021-11-30 15:47:47,619 iteration 6253 : loss : 0.003318, loss_ce: 0.001646
2021-11-30 15:47:48,847 iteration 6254 : loss : 0.003417, loss_ce: 0.000904
2021-11-30 15:47:50,071 iteration 6255 : loss : 0.003573, loss_ce: 0.001879
2021-11-30 15:47:51,293 iteration 6256 : loss : 0.003709, loss_ce: 0.001595
 92%|██████████████████████████▋  | 368/400 [2:19:25<11:45, 22.03s/it]2021-11-30 15:47:52,588 iteration 6257 : loss : 0.002654, loss_ce: 0.001327
2021-11-30 15:47:53,806 iteration 6258 : loss : 0.002955, loss_ce: 0.001587
2021-11-30 15:47:55,028 iteration 6259 : loss : 0.002861, loss_ce: 0.001010
2021-11-30 15:47:56,247 iteration 6260 : loss : 0.003067, loss_ce: 0.001488
2021-11-30 15:47:57,470 iteration 6261 : loss : 0.003109, loss_ce: 0.001034
2021-11-30 15:47:58,692 iteration 6262 : loss : 0.002896, loss_ce: 0.001154
2021-11-30 15:47:59,920 iteration 6263 : loss : 0.002542, loss_ce: 0.001014
2021-11-30 15:48:01,153 iteration 6264 : loss : 0.003457, loss_ce: 0.001189
2021-11-30 15:48:02,373 iteration 6265 : loss : 0.003024, loss_ce: 0.001328
2021-11-30 15:48:03,591 iteration 6266 : loss : 0.003573, loss_ce: 0.001425
2021-11-30 15:48:04,823 iteration 6267 : loss : 0.002141, loss_ce: 0.000657
2021-11-30 15:48:06,051 iteration 6268 : loss : 0.002580, loss_ce: 0.001078
2021-11-30 15:48:07,276 iteration 6269 : loss : 0.002742, loss_ce: 0.000856
2021-11-30 15:48:08,501 iteration 6270 : loss : 0.003075, loss_ce: 0.001217
2021-11-30 15:48:09,728 iteration 6271 : loss : 0.003082, loss_ce: 0.001406
2021-11-30 15:48:10,952 iteration 6272 : loss : 0.002562, loss_ce: 0.001186
2021-11-30 15:48:12,175 iteration 6273 : loss : 0.002866, loss_ce: 0.001104
 92%|██████████████████████████▊  | 369/400 [2:19:46<11:12, 21.69s/it]2021-11-30 15:48:13,464 iteration 6274 : loss : 0.003542, loss_ce: 0.001596
2021-11-30 15:48:14,693 iteration 6275 : loss : 0.003240, loss_ce: 0.001329
2021-11-30 15:48:15,918 iteration 6276 : loss : 0.003006, loss_ce: 0.001276
2021-11-30 15:48:17,148 iteration 6277 : loss : 0.003548, loss_ce: 0.000919
2021-11-30 15:48:18,376 iteration 6278 : loss : 0.002490, loss_ce: 0.000846
2021-11-30 15:48:19,597 iteration 6279 : loss : 0.002590, loss_ce: 0.001029
2021-11-30 15:48:20,825 iteration 6280 : loss : 0.002843, loss_ce: 0.001331
2021-11-30 15:48:22,043 iteration 6281 : loss : 0.002988, loss_ce: 0.001426
2021-11-30 15:48:23,264 iteration 6282 : loss : 0.002911, loss_ce: 0.000996
2021-11-30 15:48:24,480 iteration 6283 : loss : 0.003572, loss_ce: 0.001533
2021-11-30 15:48:25,704 iteration 6284 : loss : 0.002904, loss_ce: 0.001404
2021-11-30 15:48:26,921 iteration 6285 : loss : 0.002984, loss_ce: 0.000956
2021-11-30 15:48:28,146 iteration 6286 : loss : 0.003703, loss_ce: 0.001571
2021-11-30 15:48:29,368 iteration 6287 : loss : 0.003076, loss_ce: 0.001071
2021-11-30 15:48:30,591 iteration 6288 : loss : 0.004836, loss_ce: 0.002362
2021-11-30 15:48:31,807 iteration 6289 : loss : 0.002963, loss_ce: 0.000930
2021-11-30 15:48:31,807 Training Data Eval:
2021-11-30 15:48:38,744   Average segmentation loss on training set: 0.0034
2021-11-30 15:48:38,744 Validation Data Eval:
2021-11-30 15:48:41,139   Average segmentation loss on validation set: 0.1507
2021-11-30 15:48:42,369 iteration 6290 : loss : 0.002841, loss_ce: 0.001174
 92%|██████████████████████████▊  | 370/400 [2:20:16<12:07, 24.24s/it]2021-11-30 15:48:43,669 iteration 6291 : loss : 0.002663, loss_ce: 0.001119
2021-11-30 15:48:44,893 iteration 6292 : loss : 0.003179, loss_ce: 0.001564
2021-11-30 15:48:46,120 iteration 6293 : loss : 0.002865, loss_ce: 0.001371
2021-11-30 15:48:47,346 iteration 6294 : loss : 0.004077, loss_ce: 0.001296
2021-11-30 15:48:48,569 iteration 6295 : loss : 0.003028, loss_ce: 0.001328
2021-11-30 15:48:49,795 iteration 6296 : loss : 0.002655, loss_ce: 0.001060
2021-11-30 15:48:51,028 iteration 6297 : loss : 0.002972, loss_ce: 0.000983
2021-11-30 15:48:52,265 iteration 6298 : loss : 0.002838, loss_ce: 0.001007
2021-11-30 15:48:53,490 iteration 6299 : loss : 0.002754, loss_ce: 0.001342
2021-11-30 15:48:54,713 iteration 6300 : loss : 0.002679, loss_ce: 0.001145
2021-11-30 15:48:55,938 iteration 6301 : loss : 0.002592, loss_ce: 0.001274
2021-11-30 15:48:57,162 iteration 6302 : loss : 0.002530, loss_ce: 0.000973
2021-11-30 15:48:58,389 iteration 6303 : loss : 0.003733, loss_ce: 0.001609
2021-11-30 15:48:59,613 iteration 6304 : loss : 0.003356, loss_ce: 0.001073
2021-11-30 15:49:00,837 iteration 6305 : loss : 0.003882, loss_ce: 0.001332
2021-11-30 15:49:02,065 iteration 6306 : loss : 0.003502, loss_ce: 0.001178
2021-11-30 15:49:03,286 iteration 6307 : loss : 0.002363, loss_ce: 0.000790
 93%|██████████████████████████▉  | 371/400 [2:20:37<11:14, 23.24s/it]2021-11-30 15:49:04,576 iteration 6308 : loss : 0.004804, loss_ce: 0.001574
2021-11-30 15:49:05,798 iteration 6309 : loss : 0.002497, loss_ce: 0.001092
2021-11-30 15:49:07,028 iteration 6310 : loss : 0.003480, loss_ce: 0.001325
2021-11-30 15:49:08,248 iteration 6311 : loss : 0.003121, loss_ce: 0.000958
2021-11-30 15:49:09,466 iteration 6312 : loss : 0.002234, loss_ce: 0.000944
2021-11-30 15:49:10,696 iteration 6313 : loss : 0.003012, loss_ce: 0.001433
2021-11-30 15:49:11,916 iteration 6314 : loss : 0.002678, loss_ce: 0.001092
2021-11-30 15:49:13,142 iteration 6315 : loss : 0.002567, loss_ce: 0.001007
2021-11-30 15:49:14,366 iteration 6316 : loss : 0.003678, loss_ce: 0.001542
2021-11-30 15:49:15,595 iteration 6317 : loss : 0.002869, loss_ce: 0.001457
2021-11-30 15:49:16,819 iteration 6318 : loss : 0.003114, loss_ce: 0.001670
2021-11-30 15:49:18,035 iteration 6319 : loss : 0.003303, loss_ce: 0.001013
2021-11-30 15:49:19,262 iteration 6320 : loss : 0.002499, loss_ce: 0.001024
2021-11-30 15:49:20,478 iteration 6321 : loss : 0.002872, loss_ce: 0.000916
2021-11-30 15:49:21,697 iteration 6322 : loss : 0.002456, loss_ce: 0.001052
2021-11-30 15:49:22,924 iteration 6323 : loss : 0.002836, loss_ce: 0.001207
2021-11-30 15:49:24,146 iteration 6324 : loss : 0.002655, loss_ce: 0.000982
 93%|██████████████████████████▉  | 372/400 [2:20:58<10:30, 22.53s/it]2021-11-30 15:49:25,445 iteration 6325 : loss : 0.003230, loss_ce: 0.001503
2021-11-30 15:49:26,674 iteration 6326 : loss : 0.003017, loss_ce: 0.001263
2021-11-30 15:49:27,898 iteration 6327 : loss : 0.002465, loss_ce: 0.000885
2021-11-30 15:49:29,123 iteration 6328 : loss : 0.002368, loss_ce: 0.001220
2021-11-30 15:49:30,347 iteration 6329 : loss : 0.002569, loss_ce: 0.000743
2021-11-30 15:49:31,567 iteration 6330 : loss : 0.002889, loss_ce: 0.001343
2021-11-30 15:49:32,787 iteration 6331 : loss : 0.002832, loss_ce: 0.001051
2021-11-30 15:49:34,008 iteration 6332 : loss : 0.002648, loss_ce: 0.001036
2021-11-30 15:49:35,229 iteration 6333 : loss : 0.002731, loss_ce: 0.001203
2021-11-30 15:49:36,462 iteration 6334 : loss : 0.004023, loss_ce: 0.001879
2021-11-30 15:49:37,685 iteration 6335 : loss : 0.002894, loss_ce: 0.001061
2021-11-30 15:49:38,907 iteration 6336 : loss : 0.002933, loss_ce: 0.001016
2021-11-30 15:49:40,137 iteration 6337 : loss : 0.003213, loss_ce: 0.001541
2021-11-30 15:49:41,364 iteration 6338 : loss : 0.003101, loss_ce: 0.001018
2021-11-30 15:49:42,587 iteration 6339 : loss : 0.002571, loss_ce: 0.001108
2021-11-30 15:49:43,801 iteration 6340 : loss : 0.002678, loss_ce: 0.000923
2021-11-30 15:49:45,034 iteration 6341 : loss : 0.002517, loss_ce: 0.001069
 93%|███████████████████████████  | 373/400 [2:21:19<09:54, 22.04s/it]2021-11-30 15:49:46,326 iteration 6342 : loss : 0.002775, loss_ce: 0.001252
2021-11-30 15:49:47,553 iteration 6343 : loss : 0.002863, loss_ce: 0.000971
2021-11-30 15:49:48,777 iteration 6344 : loss : 0.003442, loss_ce: 0.001278
2021-11-30 15:49:50,012 iteration 6345 : loss : 0.003262, loss_ce: 0.001334
2021-11-30 15:49:51,241 iteration 6346 : loss : 0.003291, loss_ce: 0.001125
2021-11-30 15:49:52,468 iteration 6347 : loss : 0.002771, loss_ce: 0.001010
2021-11-30 15:49:53,696 iteration 6348 : loss : 0.002560, loss_ce: 0.001120
2021-11-30 15:49:54,917 iteration 6349 : loss : 0.002408, loss_ce: 0.000913
2021-11-30 15:49:56,140 iteration 6350 : loss : 0.002566, loss_ce: 0.001152
2021-11-30 15:49:57,370 iteration 6351 : loss : 0.002477, loss_ce: 0.001048
2021-11-30 15:49:58,589 iteration 6352 : loss : 0.003827, loss_ce: 0.001776
2021-11-30 15:49:59,814 iteration 6353 : loss : 0.002291, loss_ce: 0.001104
2021-11-30 15:50:01,046 iteration 6354 : loss : 0.002878, loss_ce: 0.000732
2021-11-30 15:50:02,274 iteration 6355 : loss : 0.003348, loss_ce: 0.001628
2021-11-30 15:50:03,496 iteration 6356 : loss : 0.002638, loss_ce: 0.001088
2021-11-30 15:50:04,718 iteration 6357 : loss : 0.003983, loss_ce: 0.002119
2021-11-30 15:50:05,947 iteration 6358 : loss : 0.002799, loss_ce: 0.001018
 94%|███████████████████████████  | 374/400 [2:21:40<09:24, 21.70s/it]2021-11-30 15:50:07,243 iteration 6359 : loss : 0.003640, loss_ce: 0.001179
2021-11-30 15:50:08,468 iteration 6360 : loss : 0.002924, loss_ce: 0.001567
2021-11-30 15:50:09,688 iteration 6361 : loss : 0.002321, loss_ce: 0.000816
2021-11-30 15:50:10,914 iteration 6362 : loss : 0.003244, loss_ce: 0.001334
2021-11-30 15:50:12,140 iteration 6363 : loss : 0.003097, loss_ce: 0.001377
2021-11-30 15:50:13,358 iteration 6364 : loss : 0.003026, loss_ce: 0.001420
2021-11-30 15:50:14,581 iteration 6365 : loss : 0.003138, loss_ce: 0.001360
2021-11-30 15:50:15,791 iteration 6366 : loss : 0.002467, loss_ce: 0.001036
2021-11-30 15:50:17,008 iteration 6367 : loss : 0.002940, loss_ce: 0.000831
2021-11-30 15:50:18,231 iteration 6368 : loss : 0.003204, loss_ce: 0.001116
2021-11-30 15:50:19,460 iteration 6369 : loss : 0.003186, loss_ce: 0.001190
2021-11-30 15:50:20,681 iteration 6370 : loss : 0.003424, loss_ce: 0.001555
2021-11-30 15:50:21,906 iteration 6371 : loss : 0.003890, loss_ce: 0.001377
2021-11-30 15:50:23,130 iteration 6372 : loss : 0.002727, loss_ce: 0.000976
2021-11-30 15:50:24,352 iteration 6373 : loss : 0.003028, loss_ce: 0.001361
2021-11-30 15:50:25,577 iteration 6374 : loss : 0.002482, loss_ce: 0.000939
2021-11-30 15:50:25,577 Training Data Eval:
2021-11-30 15:50:32,490   Average segmentation loss on training set: 0.0028
2021-11-30 15:50:32,491 Validation Data Eval:
2021-11-30 15:50:34,855   Average segmentation loss on validation set: 0.1526
2021-11-30 15:50:36,080 iteration 6375 : loss : 0.003381, loss_ce: 0.001387
 94%|███████████████████████████▏ | 375/400 [2:22:10<10:05, 24.23s/it]2021-11-30 15:50:37,369 iteration 6376 : loss : 0.003388, loss_ce: 0.001611
2021-11-30 15:50:38,589 iteration 6377 : loss : 0.002988, loss_ce: 0.000822
2021-11-30 15:50:39,815 iteration 6378 : loss : 0.002360, loss_ce: 0.000798
2021-11-30 15:50:41,040 iteration 6379 : loss : 0.003246, loss_ce: 0.001467
2021-11-30 15:50:42,261 iteration 6380 : loss : 0.002425, loss_ce: 0.001001
2021-11-30 15:50:43,482 iteration 6381 : loss : 0.003013, loss_ce: 0.001447
2021-11-30 15:50:44,707 iteration 6382 : loss : 0.003221, loss_ce: 0.001703
2021-11-30 15:50:45,927 iteration 6383 : loss : 0.003065, loss_ce: 0.001051
2021-11-30 15:50:47,156 iteration 6384 : loss : 0.002819, loss_ce: 0.001169
2021-11-30 15:50:48,373 iteration 6385 : loss : 0.003330, loss_ce: 0.001473
2021-11-30 15:50:49,590 iteration 6386 : loss : 0.003243, loss_ce: 0.001134
2021-11-30 15:50:50,814 iteration 6387 : loss : 0.001967, loss_ce: 0.000787
2021-11-30 15:50:52,034 iteration 6388 : loss : 0.002905, loss_ce: 0.001181
2021-11-30 15:50:53,256 iteration 6389 : loss : 0.003499, loss_ce: 0.001166
2021-11-30 15:50:54,477 iteration 6390 : loss : 0.003156, loss_ce: 0.000950
2021-11-30 15:50:55,701 iteration 6391 : loss : 0.002793, loss_ce: 0.001328
2021-11-30 15:50:56,923 iteration 6392 : loss : 0.003605, loss_ce: 0.001828
 94%|███████████████████████████▎ | 376/400 [2:22:30<09:17, 23.21s/it]2021-11-30 15:50:58,224 iteration 6393 : loss : 0.002574, loss_ce: 0.001139
2021-11-30 15:50:59,451 iteration 6394 : loss : 0.002950, loss_ce: 0.001106
2021-11-30 15:51:00,672 iteration 6395 : loss : 0.003098, loss_ce: 0.001571
2021-11-30 15:51:01,888 iteration 6396 : loss : 0.002639, loss_ce: 0.001076
2021-11-30 15:51:03,105 iteration 6397 : loss : 0.002547, loss_ce: 0.001150
2021-11-30 15:51:04,327 iteration 6398 : loss : 0.002703, loss_ce: 0.000933
2021-11-30 15:51:05,556 iteration 6399 : loss : 0.003416, loss_ce: 0.001737
2021-11-30 15:51:06,776 iteration 6400 : loss : 0.002690, loss_ce: 0.001141
2021-11-30 15:51:08,002 iteration 6401 : loss : 0.003335, loss_ce: 0.001464
2021-11-30 15:51:09,223 iteration 6402 : loss : 0.003347, loss_ce: 0.001365
2021-11-30 15:51:10,454 iteration 6403 : loss : 0.002625, loss_ce: 0.001155
2021-11-30 15:51:11,678 iteration 6404 : loss : 0.003260, loss_ce: 0.001221
2021-11-30 15:51:12,903 iteration 6405 : loss : 0.002756, loss_ce: 0.000785
2021-11-30 15:51:14,119 iteration 6406 : loss : 0.002869, loss_ce: 0.000796
2021-11-30 15:51:15,344 iteration 6407 : loss : 0.003293, loss_ce: 0.001311
2021-11-30 15:51:16,568 iteration 6408 : loss : 0.003382, loss_ce: 0.001370
2021-11-30 15:51:17,784 iteration 6409 : loss : 0.004292, loss_ce: 0.001922
 94%|███████████████████████████▎ | 377/400 [2:22:51<08:37, 22.51s/it]2021-11-30 15:51:19,076 iteration 6410 : loss : 0.002844, loss_ce: 0.000696
2021-11-30 15:51:20,300 iteration 6411 : loss : 0.002536, loss_ce: 0.001107
2021-11-30 15:51:21,515 iteration 6412 : loss : 0.003857, loss_ce: 0.001354
2021-11-30 15:51:22,736 iteration 6413 : loss : 0.003591, loss_ce: 0.001594
2021-11-30 15:51:23,961 iteration 6414 : loss : 0.003417, loss_ce: 0.001359
2021-11-30 15:51:25,183 iteration 6415 : loss : 0.002718, loss_ce: 0.001056
2021-11-30 15:51:26,406 iteration 6416 : loss : 0.002485, loss_ce: 0.000922
2021-11-30 15:51:27,628 iteration 6417 : loss : 0.002974, loss_ce: 0.001323
2021-11-30 15:51:28,861 iteration 6418 : loss : 0.002992, loss_ce: 0.001378
2021-11-30 15:51:30,088 iteration 6419 : loss : 0.002195, loss_ce: 0.000738
2021-11-30 15:51:31,315 iteration 6420 : loss : 0.003918, loss_ce: 0.001741
2021-11-30 15:51:32,537 iteration 6421 : loss : 0.002717, loss_ce: 0.001191
2021-11-30 15:51:33,766 iteration 6422 : loss : 0.003930, loss_ce: 0.001403
2021-11-30 15:51:34,987 iteration 6423 : loss : 0.002723, loss_ce: 0.001118
2021-11-30 15:51:36,213 iteration 6424 : loss : 0.003791, loss_ce: 0.001499
2021-11-30 15:51:37,434 iteration 6425 : loss : 0.002938, loss_ce: 0.001103
2021-11-30 15:51:38,654 iteration 6426 : loss : 0.002554, loss_ce: 0.001026
 94%|███████████████████████████▍ | 378/400 [2:23:12<08:04, 22.02s/it]2021-11-30 15:51:39,956 iteration 6427 : loss : 0.002575, loss_ce: 0.001098
2021-11-30 15:51:41,173 iteration 6428 : loss : 0.003010, loss_ce: 0.001221
2021-11-30 15:51:42,395 iteration 6429 : loss : 0.002846, loss_ce: 0.001378
2021-11-30 15:51:43,615 iteration 6430 : loss : 0.003354, loss_ce: 0.001200
2021-11-30 15:51:44,836 iteration 6431 : loss : 0.003041, loss_ce: 0.000813
2021-11-30 15:51:46,063 iteration 6432 : loss : 0.002785, loss_ce: 0.001164
2021-11-30 15:51:47,286 iteration 6433 : loss : 0.002439, loss_ce: 0.000898
2021-11-30 15:51:48,512 iteration 6434 : loss : 0.002817, loss_ce: 0.001077
2021-11-30 15:51:49,724 iteration 6435 : loss : 0.002439, loss_ce: 0.000951
2021-11-30 15:51:50,944 iteration 6436 : loss : 0.002858, loss_ce: 0.001041
2021-11-30 15:51:52,168 iteration 6437 : loss : 0.003474, loss_ce: 0.001857
2021-11-30 15:51:53,386 iteration 6438 : loss : 0.002599, loss_ce: 0.000953
2021-11-30 15:51:54,609 iteration 6439 : loss : 0.002779, loss_ce: 0.001129
2021-11-30 15:51:55,831 iteration 6440 : loss : 0.004124, loss_ce: 0.001777
2021-11-30 15:51:57,058 iteration 6441 : loss : 0.002204, loss_ce: 0.001112
2021-11-30 15:51:58,278 iteration 6442 : loss : 0.002587, loss_ce: 0.001186
2021-11-30 15:51:59,506 iteration 6443 : loss : 0.002659, loss_ce: 0.001191
 95%|███████████████████████████▍ | 379/400 [2:23:33<07:34, 21.67s/it]2021-11-30 15:52:00,799 iteration 6444 : loss : 0.002238, loss_ce: 0.000695
2021-11-30 15:52:02,026 iteration 6445 : loss : 0.002628, loss_ce: 0.001253
2021-11-30 15:52:03,248 iteration 6446 : loss : 0.002693, loss_ce: 0.000903
2021-11-30 15:52:04,476 iteration 6447 : loss : 0.002970, loss_ce: 0.001233
2021-11-30 15:52:05,705 iteration 6448 : loss : 0.003222, loss_ce: 0.001620
2021-11-30 15:52:06,930 iteration 6449 : loss : 0.002995, loss_ce: 0.001222
2021-11-30 15:52:08,157 iteration 6450 : loss : 0.002903, loss_ce: 0.001143
2021-11-30 15:52:09,384 iteration 6451 : loss : 0.002181, loss_ce: 0.000909
2021-11-30 15:52:10,609 iteration 6452 : loss : 0.003248, loss_ce: 0.001388
2021-11-30 15:52:11,833 iteration 6453 : loss : 0.002718, loss_ce: 0.000912
2021-11-30 15:52:13,053 iteration 6454 : loss : 0.002630, loss_ce: 0.001334
2021-11-30 15:52:14,275 iteration 6455 : loss : 0.002747, loss_ce: 0.001029
2021-11-30 15:52:15,496 iteration 6456 : loss : 0.002772, loss_ce: 0.001269
2021-11-30 15:52:16,722 iteration 6457 : loss : 0.002528, loss_ce: 0.000983
2021-11-30 15:52:17,936 iteration 6458 : loss : 0.003963, loss_ce: 0.001253
2021-11-30 15:52:19,160 iteration 6459 : loss : 0.002680, loss_ce: 0.001118
2021-11-30 15:52:19,160 Training Data Eval:
2021-11-30 15:52:26,102   Average segmentation loss on training set: 0.0026
2021-11-30 15:52:26,102 Validation Data Eval:
2021-11-30 15:52:28,480   Average segmentation loss on validation set: 0.1543
2021-11-30 15:52:29,706 iteration 6460 : loss : 0.002684, loss_ce: 0.001091
 95%|███████████████████████████▌ | 380/400 [2:24:03<08:04, 24.23s/it]2021-11-30 15:52:31,000 iteration 6461 : loss : 0.002916, loss_ce: 0.001152
2021-11-30 15:52:32,221 iteration 6462 : loss : 0.002921, loss_ce: 0.001433
2021-11-30 15:52:33,438 iteration 6463 : loss : 0.002751, loss_ce: 0.000841
2021-11-30 15:52:34,663 iteration 6464 : loss : 0.002516, loss_ce: 0.001183
2021-11-30 15:52:35,885 iteration 6465 : loss : 0.002545, loss_ce: 0.000948
2021-11-30 15:52:37,113 iteration 6466 : loss : 0.003769, loss_ce: 0.001163
2021-11-30 15:52:38,334 iteration 6467 : loss : 0.002695, loss_ce: 0.001118
2021-11-30 15:52:39,553 iteration 6468 : loss : 0.002443, loss_ce: 0.001130
2021-11-30 15:52:40,777 iteration 6469 : loss : 0.003025, loss_ce: 0.001307
2021-11-30 15:52:41,989 iteration 6470 : loss : 0.002402, loss_ce: 0.000984
2021-11-30 15:52:43,219 iteration 6471 : loss : 0.003716, loss_ce: 0.001679
2021-11-30 15:52:44,435 iteration 6472 : loss : 0.002712, loss_ce: 0.001203
2021-11-30 15:52:45,663 iteration 6473 : loss : 0.002252, loss_ce: 0.001043
2021-11-30 15:52:46,888 iteration 6474 : loss : 0.002319, loss_ce: 0.000851
2021-11-30 15:52:48,118 iteration 6475 : loss : 0.002414, loss_ce: 0.000965
2021-11-30 15:52:49,343 iteration 6476 : loss : 0.003297, loss_ce: 0.001136
2021-11-30 15:52:50,577 iteration 6477 : loss : 0.003468, loss_ce: 0.001452
 95%|███████████████████████████▌ | 381/400 [2:24:24<07:21, 23.22s/it]2021-11-30 15:52:51,864 iteration 6478 : loss : 0.002832, loss_ce: 0.001169
2021-11-30 15:52:53,089 iteration 6479 : loss : 0.003746, loss_ce: 0.001549
2021-11-30 15:52:54,318 iteration 6480 : loss : 0.002574, loss_ce: 0.001115
2021-11-30 15:52:55,543 iteration 6481 : loss : 0.002755, loss_ce: 0.001206
2021-11-30 15:52:56,768 iteration 6482 : loss : 0.002364, loss_ce: 0.001066
2021-11-30 15:52:57,991 iteration 6483 : loss : 0.002431, loss_ce: 0.001022
2021-11-30 15:52:59,220 iteration 6484 : loss : 0.002420, loss_ce: 0.001161
2021-11-30 15:53:00,449 iteration 6485 : loss : 0.002901, loss_ce: 0.001414
2021-11-30 15:53:01,669 iteration 6486 : loss : 0.002767, loss_ce: 0.000651
2021-11-30 15:53:02,893 iteration 6487 : loss : 0.002972, loss_ce: 0.000911
2021-11-30 15:53:04,122 iteration 6488 : loss : 0.003070, loss_ce: 0.001009
2021-11-30 15:53:05,351 iteration 6489 : loss : 0.003774, loss_ce: 0.002063
2021-11-30 15:53:06,587 iteration 6490 : loss : 0.002720, loss_ce: 0.001230
2021-11-30 15:53:07,813 iteration 6491 : loss : 0.003357, loss_ce: 0.000879
2021-11-30 15:53:09,039 iteration 6492 : loss : 0.002859, loss_ce: 0.001419
2021-11-30 15:53:10,266 iteration 6493 : loss : 0.002042, loss_ce: 0.000795
2021-11-30 15:53:11,496 iteration 6494 : loss : 0.003270, loss_ce: 0.001103
 96%|███████████████████████████▋ | 382/400 [2:24:45<06:45, 22.53s/it]2021-11-30 15:53:12,795 iteration 6495 : loss : 0.002614, loss_ce: 0.001070
2021-11-30 15:53:14,014 iteration 6496 : loss : 0.002531, loss_ce: 0.001297
2021-11-30 15:53:15,232 iteration 6497 : loss : 0.003551, loss_ce: 0.001578
2021-11-30 15:53:16,455 iteration 6498 : loss : 0.003143, loss_ce: 0.001089
2021-11-30 15:53:17,687 iteration 6499 : loss : 0.002645, loss_ce: 0.001343
2021-11-30 15:53:18,904 iteration 6500 : loss : 0.002526, loss_ce: 0.000861
2021-11-30 15:53:20,131 iteration 6501 : loss : 0.002106, loss_ce: 0.000826
2021-11-30 15:53:21,360 iteration 6502 : loss : 0.002060, loss_ce: 0.000845
2021-11-30 15:53:22,592 iteration 6503 : loss : 0.003017, loss_ce: 0.001135
2021-11-30 15:53:23,820 iteration 6504 : loss : 0.002712, loss_ce: 0.000861
2021-11-30 15:53:25,039 iteration 6505 : loss : 0.002681, loss_ce: 0.001170
2021-11-30 15:53:26,264 iteration 6506 : loss : 0.003334, loss_ce: 0.001556
2021-11-30 15:53:27,498 iteration 6507 : loss : 0.003176, loss_ce: 0.001069
2021-11-30 15:53:28,724 iteration 6508 : loss : 0.002944, loss_ce: 0.001316
2021-11-30 15:53:29,938 iteration 6509 : loss : 0.002940, loss_ce: 0.001167
2021-11-30 15:53:31,163 iteration 6510 : loss : 0.002961, loss_ce: 0.001466
2021-11-30 15:53:32,390 iteration 6511 : loss : 0.003767, loss_ce: 0.001339
 96%|███████████████████████████▊ | 383/400 [2:25:06<06:14, 22.04s/it]2021-11-30 15:53:33,684 iteration 6512 : loss : 0.002208, loss_ce: 0.001080
2021-11-30 15:53:34,914 iteration 6513 : loss : 0.002505, loss_ce: 0.001338
2021-11-30 15:53:36,137 iteration 6514 : loss : 0.002587, loss_ce: 0.000975
2021-11-30 15:53:37,361 iteration 6515 : loss : 0.002400, loss_ce: 0.001176
2021-11-30 15:53:38,586 iteration 6516 : loss : 0.003275, loss_ce: 0.001696
2021-11-30 15:53:39,815 iteration 6517 : loss : 0.003207, loss_ce: 0.001160
2021-11-30 15:53:41,041 iteration 6518 : loss : 0.003124, loss_ce: 0.001018
2021-11-30 15:53:42,257 iteration 6519 : loss : 0.003105, loss_ce: 0.001236
2021-11-30 15:53:43,488 iteration 6520 : loss : 0.002852, loss_ce: 0.001530
2021-11-30 15:53:44,715 iteration 6521 : loss : 0.002369, loss_ce: 0.000915
2021-11-30 15:53:45,941 iteration 6522 : loss : 0.002637, loss_ce: 0.000889
2021-11-30 15:53:47,167 iteration 6523 : loss : 0.003150, loss_ce: 0.001390
2021-11-30 15:53:48,396 iteration 6524 : loss : 0.003386, loss_ce: 0.001587
2021-11-30 15:53:49,612 iteration 6525 : loss : 0.002315, loss_ce: 0.000916
2021-11-30 15:53:50,839 iteration 6526 : loss : 0.003124, loss_ce: 0.001044
2021-11-30 15:53:52,057 iteration 6527 : loss : 0.002539, loss_ce: 0.000976
2021-11-30 15:53:53,282 iteration 6528 : loss : 0.002034, loss_ce: 0.000702
 96%|███████████████████████████▊ | 384/400 [2:25:27<05:47, 21.69s/it]2021-11-30 15:53:54,569 iteration 6529 : loss : 0.002741, loss_ce: 0.000812
2021-11-30 15:53:55,793 iteration 6530 : loss : 0.002359, loss_ce: 0.000983
2021-11-30 15:53:57,021 iteration 6531 : loss : 0.002842, loss_ce: 0.001422
2021-11-30 15:53:58,239 iteration 6532 : loss : 0.003241, loss_ce: 0.001538
2021-11-30 15:53:59,460 iteration 6533 : loss : 0.002116, loss_ce: 0.000883
2021-11-30 15:54:00,685 iteration 6534 : loss : 0.003753, loss_ce: 0.001857
2021-11-30 15:54:01,910 iteration 6535 : loss : 0.002982, loss_ce: 0.000947
2021-11-30 15:54:03,128 iteration 6536 : loss : 0.002365, loss_ce: 0.000870
2021-11-30 15:54:04,347 iteration 6537 : loss : 0.002933, loss_ce: 0.001420
2021-11-30 15:54:05,565 iteration 6538 : loss : 0.003456, loss_ce: 0.001766
2021-11-30 15:54:06,792 iteration 6539 : loss : 0.002128, loss_ce: 0.000821
2021-11-30 15:54:08,013 iteration 6540 : loss : 0.002593, loss_ce: 0.000730
2021-11-30 15:54:09,232 iteration 6541 : loss : 0.002462, loss_ce: 0.001076
2021-11-30 15:54:10,457 iteration 6542 : loss : 0.002403, loss_ce: 0.001019
2021-11-30 15:54:11,682 iteration 6543 : loss : 0.002568, loss_ce: 0.001164
2021-11-30 15:54:12,905 iteration 6544 : loss : 0.003144, loss_ce: 0.000875
2021-11-30 15:54:12,905 Training Data Eval:
2021-11-30 15:54:19,844   Average segmentation loss on training set: 0.0025
2021-11-30 15:54:19,844 Validation Data Eval:
2021-11-30 15:54:22,222   Average segmentation loss on validation set: 0.1519
2021-11-30 15:54:23,457 iteration 6545 : loss : 0.002517, loss_ce: 0.000947
 96%|███████████████████████████▉ | 385/400 [2:25:57<06:03, 24.24s/it]2021-11-30 15:54:24,750 iteration 6546 : loss : 0.003134, loss_ce: 0.001450
2021-11-30 15:54:25,977 iteration 6547 : loss : 0.003490, loss_ce: 0.001362
2021-11-30 15:54:27,196 iteration 6548 : loss : 0.002360, loss_ce: 0.000824
2021-11-30 15:54:28,424 iteration 6549 : loss : 0.003382, loss_ce: 0.001351
2021-11-30 15:54:29,644 iteration 6550 : loss : 0.003240, loss_ce: 0.001367
2021-11-30 15:54:30,869 iteration 6551 : loss : 0.003959, loss_ce: 0.001737
2021-11-30 15:54:32,096 iteration 6552 : loss : 0.002356, loss_ce: 0.000858
2021-11-30 15:54:33,323 iteration 6553 : loss : 0.002267, loss_ce: 0.000888
2021-11-30 15:54:34,537 iteration 6554 : loss : 0.002513, loss_ce: 0.001035
2021-11-30 15:54:35,757 iteration 6555 : loss : 0.003082, loss_ce: 0.001494
2021-11-30 15:54:36,982 iteration 6556 : loss : 0.002807, loss_ce: 0.001069
2021-11-30 15:54:38,210 iteration 6557 : loss : 0.002379, loss_ce: 0.000924
2021-11-30 15:54:39,429 iteration 6558 : loss : 0.002262, loss_ce: 0.000848
2021-11-30 15:54:40,650 iteration 6559 : loss : 0.003112, loss_ce: 0.001536
2021-11-30 15:54:41,878 iteration 6560 : loss : 0.002669, loss_ce: 0.001080
2021-11-30 15:54:43,100 iteration 6561 : loss : 0.002265, loss_ce: 0.000667
2021-11-30 15:54:44,327 iteration 6562 : loss : 0.002558, loss_ce: 0.001265
 96%|███████████████████████████▉ | 386/400 [2:26:18<05:25, 23.23s/it]2021-11-30 15:54:45,608 iteration 6563 : loss : 0.003255, loss_ce: 0.001443
2021-11-30 15:54:46,835 iteration 6564 : loss : 0.003104, loss_ce: 0.001536
2021-11-30 15:54:48,048 iteration 6565 : loss : 0.002259, loss_ce: 0.001060
2021-11-30 15:54:49,268 iteration 6566 : loss : 0.002051, loss_ce: 0.000887
2021-11-30 15:54:50,492 iteration 6567 : loss : 0.002628, loss_ce: 0.000705
2021-11-30 15:54:51,713 iteration 6568 : loss : 0.002530, loss_ce: 0.000988
2021-11-30 15:54:52,937 iteration 6569 : loss : 0.003463, loss_ce: 0.001797
2021-11-30 15:54:54,153 iteration 6570 : loss : 0.002670, loss_ce: 0.001437
2021-11-30 15:54:55,371 iteration 6571 : loss : 0.002210, loss_ce: 0.000829
2021-11-30 15:54:56,588 iteration 6572 : loss : 0.003283, loss_ce: 0.001374
2021-11-30 15:54:57,817 iteration 6573 : loss : 0.002226, loss_ce: 0.000935
2021-11-30 15:54:59,034 iteration 6574 : loss : 0.002594, loss_ce: 0.000991
2021-11-30 15:55:00,260 iteration 6575 : loss : 0.002555, loss_ce: 0.000985
2021-11-30 15:55:01,487 iteration 6576 : loss : 0.002468, loss_ce: 0.000993
2021-11-30 15:55:02,715 iteration 6577 : loss : 0.003488, loss_ce: 0.001557
2021-11-30 15:55:03,941 iteration 6578 : loss : 0.002281, loss_ce: 0.001123
2021-11-30 15:55:05,161 iteration 6579 : loss : 0.002125, loss_ce: 0.000768
 97%|████████████████████████████ | 387/400 [2:26:39<04:52, 22.51s/it]2021-11-30 15:55:06,445 iteration 6580 : loss : 0.002186, loss_ce: 0.000924
2021-11-30 15:55:07,666 iteration 6581 : loss : 0.003254, loss_ce: 0.000776
2021-11-30 15:55:08,893 iteration 6582 : loss : 0.002772, loss_ce: 0.001186
2021-11-30 15:55:10,117 iteration 6583 : loss : 0.003280, loss_ce: 0.001571
2021-11-30 15:55:11,344 iteration 6584 : loss : 0.002564, loss_ce: 0.000957
2021-11-30 15:55:12,571 iteration 6585 : loss : 0.002305, loss_ce: 0.000966
2021-11-30 15:55:13,788 iteration 6586 : loss : 0.003490, loss_ce: 0.001330
2021-11-30 15:55:15,020 iteration 6587 : loss : 0.003299, loss_ce: 0.001407
2021-11-30 15:55:16,244 iteration 6588 : loss : 0.002949, loss_ce: 0.001508
2021-11-30 15:55:17,467 iteration 6589 : loss : 0.002931, loss_ce: 0.001153
2021-11-30 15:55:18,694 iteration 6590 : loss : 0.002983, loss_ce: 0.001036
2021-11-30 15:55:19,915 iteration 6591 : loss : 0.002960, loss_ce: 0.001578
2021-11-30 15:55:21,147 iteration 6592 : loss : 0.002355, loss_ce: 0.000671
2021-11-30 15:55:22,361 iteration 6593 : loss : 0.002406, loss_ce: 0.000834
2021-11-30 15:55:23,582 iteration 6594 : loss : 0.003412, loss_ce: 0.001829
2021-11-30 15:55:24,809 iteration 6595 : loss : 0.002436, loss_ce: 0.001148
2021-11-30 15:55:26,032 iteration 6596 : loss : 0.002696, loss_ce: 0.000794
 97%|████████████████████████████▏| 388/400 [2:27:00<04:24, 22.02s/it]2021-11-30 15:55:27,324 iteration 6597 : loss : 0.002999, loss_ce: 0.001061
2021-11-30 15:55:28,552 iteration 6598 : loss : 0.002981, loss_ce: 0.001608
2021-11-30 15:55:29,767 iteration 6599 : loss : 0.002026, loss_ce: 0.000855
2021-11-30 15:55:30,991 iteration 6600 : loss : 0.002522, loss_ce: 0.001182
2021-11-30 15:55:32,213 iteration 6601 : loss : 0.003101, loss_ce: 0.001549
2021-11-30 15:55:33,434 iteration 6602 : loss : 0.002869, loss_ce: 0.001282
2021-11-30 15:55:34,650 iteration 6603 : loss : 0.002666, loss_ce: 0.001368
2021-11-30 15:55:35,881 iteration 6604 : loss : 0.002186, loss_ce: 0.000920
2021-11-30 15:55:37,102 iteration 6605 : loss : 0.002014, loss_ce: 0.000715
2021-11-30 15:55:38,319 iteration 6606 : loss : 0.002400, loss_ce: 0.000894
2021-11-30 15:55:39,541 iteration 6607 : loss : 0.003101, loss_ce: 0.001243
2021-11-30 15:55:40,768 iteration 6608 : loss : 0.002548, loss_ce: 0.001031
2021-11-30 15:55:41,990 iteration 6609 : loss : 0.002285, loss_ce: 0.000858
2021-11-30 15:55:43,214 iteration 6610 : loss : 0.003732, loss_ce: 0.001353
2021-11-30 15:55:44,435 iteration 6611 : loss : 0.002512, loss_ce: 0.000719
2021-11-30 15:55:45,652 iteration 6612 : loss : 0.003095, loss_ce: 0.001539
2021-11-30 15:55:46,873 iteration 6613 : loss : 0.002365, loss_ce: 0.001124
 97%|████████████████████████████▏| 389/400 [2:27:20<03:58, 21.67s/it]2021-11-30 15:55:48,160 iteration 6614 : loss : 0.002575, loss_ce: 0.000745
2021-11-30 15:55:49,379 iteration 6615 : loss : 0.003963, loss_ce: 0.002153
2021-11-30 15:55:50,607 iteration 6616 : loss : 0.002793, loss_ce: 0.001229
2021-11-30 15:55:51,824 iteration 6617 : loss : 0.002603, loss_ce: 0.001050
2021-11-30 15:55:53,045 iteration 6618 : loss : 0.002374, loss_ce: 0.000999
2021-11-30 15:55:54,258 iteration 6619 : loss : 0.002441, loss_ce: 0.001201
2021-11-30 15:55:55,491 iteration 6620 : loss : 0.002988, loss_ce: 0.001604
2021-11-30 15:55:56,712 iteration 6621 : loss : 0.002944, loss_ce: 0.001292
2021-11-30 15:55:57,940 iteration 6622 : loss : 0.002417, loss_ce: 0.000813
2021-11-30 15:55:59,164 iteration 6623 : loss : 0.002534, loss_ce: 0.000900
2021-11-30 15:56:00,381 iteration 6624 : loss : 0.002815, loss_ce: 0.001320
2021-11-30 15:56:01,603 iteration 6625 : loss : 0.002302, loss_ce: 0.000819
2021-11-30 15:56:02,827 iteration 6626 : loss : 0.002560, loss_ce: 0.001160
2021-11-30 15:56:04,055 iteration 6627 : loss : 0.003397, loss_ce: 0.001178
2021-11-30 15:56:05,277 iteration 6628 : loss : 0.002661, loss_ce: 0.001137
2021-11-30 15:56:06,502 iteration 6629 : loss : 0.002329, loss_ce: 0.000751
2021-11-30 15:56:06,502 Training Data Eval:
2021-11-30 15:56:13,441   Average segmentation loss on training set: 0.0022
2021-11-30 15:56:13,441 Validation Data Eval:
2021-11-30 15:56:15,819   Average segmentation loss on validation set: 0.1541
2021-11-30 15:56:17,049 iteration 6630 : loss : 0.001991, loss_ce: 0.000663
 98%|████████████████████████████▎| 390/400 [2:27:51<04:02, 24.22s/it]2021-11-30 15:56:18,342 iteration 6631 : loss : 0.002354, loss_ce: 0.000979
2021-11-30 15:56:19,572 iteration 6632 : loss : 0.002595, loss_ce: 0.001017
2021-11-30 15:56:20,794 iteration 6633 : loss : 0.002339, loss_ce: 0.000907
2021-11-30 15:56:22,021 iteration 6634 : loss : 0.002536, loss_ce: 0.000704
2021-11-30 15:56:23,249 iteration 6635 : loss : 0.002360, loss_ce: 0.001198
2021-11-30 15:56:24,470 iteration 6636 : loss : 0.002434, loss_ce: 0.001165
2021-11-30 15:56:25,690 iteration 6637 : loss : 0.002810, loss_ce: 0.001161
2021-11-30 15:56:26,914 iteration 6638 : loss : 0.002780, loss_ce: 0.001580
2021-11-30 15:56:28,137 iteration 6639 : loss : 0.002208, loss_ce: 0.000921
2021-11-30 15:56:29,361 iteration 6640 : loss : 0.003540, loss_ce: 0.001160
2021-11-30 15:56:30,584 iteration 6641 : loss : 0.002365, loss_ce: 0.001059
2021-11-30 15:56:31,813 iteration 6642 : loss : 0.002649, loss_ce: 0.000808
2021-11-30 15:56:33,040 iteration 6643 : loss : 0.003645, loss_ce: 0.001585
2021-11-30 15:56:34,284 iteration 6644 : loss : 0.002927, loss_ce: 0.001259
2021-11-30 15:56:35,511 iteration 6645 : loss : 0.002752, loss_ce: 0.000962
2021-11-30 15:56:36,733 iteration 6646 : loss : 0.001932, loss_ce: 0.000745
2021-11-30 15:56:37,964 iteration 6647 : loss : 0.002263, loss_ce: 0.001131
 98%|████████████████████████████▎| 391/400 [2:28:12<03:29, 23.23s/it]2021-11-30 15:56:39,258 iteration 6648 : loss : 0.002985, loss_ce: 0.001226
2021-11-30 15:56:40,487 iteration 6649 : loss : 0.003276, loss_ce: 0.001040
2021-11-30 15:56:41,706 iteration 6650 : loss : 0.002980, loss_ce: 0.001634
2021-11-30 15:56:42,940 iteration 6651 : loss : 0.002541, loss_ce: 0.000758
2021-11-30 15:56:44,164 iteration 6652 : loss : 0.002805, loss_ce: 0.001413
2021-11-30 15:56:45,388 iteration 6653 : loss : 0.003890, loss_ce: 0.001748
2021-11-30 15:56:46,611 iteration 6654 : loss : 0.002408, loss_ce: 0.000990
2021-11-30 15:56:47,836 iteration 6655 : loss : 0.003393, loss_ce: 0.001146
2021-11-30 15:56:49,059 iteration 6656 : loss : 0.002149, loss_ce: 0.000859
2021-11-30 15:56:50,284 iteration 6657 : loss : 0.002527, loss_ce: 0.001257
2021-11-30 15:56:51,510 iteration 6658 : loss : 0.002706, loss_ce: 0.001038
2021-11-30 15:56:52,730 iteration 6659 : loss : 0.002031, loss_ce: 0.000777
2021-11-30 15:56:53,955 iteration 6660 : loss : 0.002670, loss_ce: 0.001315
2021-11-30 15:56:55,179 iteration 6661 : loss : 0.002788, loss_ce: 0.000972
2021-11-30 15:56:56,404 iteration 6662 : loss : 0.002494, loss_ce: 0.000937
2021-11-30 15:56:57,632 iteration 6663 : loss : 0.002116, loss_ce: 0.001084
2021-11-30 15:56:58,865 iteration 6664 : loss : 0.002872, loss_ce: 0.001002
 98%|████████████████████████████▍| 392/400 [2:28:32<03:00, 22.53s/it]2021-11-30 15:57:00,161 iteration 6665 : loss : 0.001992, loss_ce: 0.000805
2021-11-30 15:57:01,389 iteration 6666 : loss : 0.002421, loss_ce: 0.001154
2021-11-30 15:57:02,610 iteration 6667 : loss : 0.002489, loss_ce: 0.001138
2021-11-30 15:57:03,831 iteration 6668 : loss : 0.002767, loss_ce: 0.001436
2021-11-30 15:57:05,059 iteration 6669 : loss : 0.002468, loss_ce: 0.000986
2021-11-30 15:57:06,291 iteration 6670 : loss : 0.002907, loss_ce: 0.000954
2021-11-30 15:57:07,514 iteration 6671 : loss : 0.002513, loss_ce: 0.001009
2021-11-30 15:57:08,739 iteration 6672 : loss : 0.002295, loss_ce: 0.000855
2021-11-30 15:57:09,960 iteration 6673 : loss : 0.001882, loss_ce: 0.000638
2021-11-30 15:57:11,183 iteration 6674 : loss : 0.002487, loss_ce: 0.001326
2021-11-30 15:57:12,413 iteration 6675 : loss : 0.002669, loss_ce: 0.001022
2021-11-30 15:57:13,639 iteration 6676 : loss : 0.002895, loss_ce: 0.001274
2021-11-30 15:57:14,861 iteration 6677 : loss : 0.002973, loss_ce: 0.001364
2021-11-30 15:57:16,082 iteration 6678 : loss : 0.002589, loss_ce: 0.001112
2021-11-30 15:57:17,297 iteration 6679 : loss : 0.002993, loss_ce: 0.000869
2021-11-30 15:57:18,521 iteration 6680 : loss : 0.002072, loss_ce: 0.000953
2021-11-30 15:57:19,745 iteration 6681 : loss : 0.002243, loss_ce: 0.001045
 98%|████████████████████████████▍| 393/400 [2:28:53<02:34, 22.03s/it]2021-11-30 15:57:21,047 iteration 6682 : loss : 0.002142, loss_ce: 0.000970
2021-11-30 15:57:22,270 iteration 6683 : loss : 0.002382, loss_ce: 0.000750
2021-11-30 15:57:23,486 iteration 6684 : loss : 0.002562, loss_ce: 0.001349
2021-11-30 15:57:24,712 iteration 6685 : loss : 0.001883, loss_ce: 0.000775
2021-11-30 15:57:25,940 iteration 6686 : loss : 0.002782, loss_ce: 0.000969
2021-11-30 15:57:27,165 iteration 6687 : loss : 0.002867, loss_ce: 0.001205
2021-11-30 15:57:28,387 iteration 6688 : loss : 0.002713, loss_ce: 0.001251
2021-11-30 15:57:29,613 iteration 6689 : loss : 0.002532, loss_ce: 0.001052
2021-11-30 15:57:30,843 iteration 6690 : loss : 0.003222, loss_ce: 0.001624
2021-11-30 15:57:32,067 iteration 6691 : loss : 0.002878, loss_ce: 0.001279
2021-11-30 15:57:33,292 iteration 6692 : loss : 0.002201, loss_ce: 0.000991
2021-11-30 15:57:34,508 iteration 6693 : loss : 0.002316, loss_ce: 0.000913
2021-11-30 15:57:35,739 iteration 6694 : loss : 0.003054, loss_ce: 0.001280
2021-11-30 15:57:36,965 iteration 6695 : loss : 0.002978, loss_ce: 0.001091
2021-11-30 15:57:38,192 iteration 6696 : loss : 0.002408, loss_ce: 0.000906
2021-11-30 15:57:39,419 iteration 6697 : loss : 0.002184, loss_ce: 0.000912
2021-11-30 15:57:40,637 iteration 6698 : loss : 0.002097, loss_ce: 0.000819
 98%|████████████████████████████▌| 394/400 [2:29:14<02:10, 21.69s/it]2021-11-30 15:57:41,939 iteration 6699 : loss : 0.001774, loss_ce: 0.000787
2021-11-30 15:57:43,173 iteration 6700 : loss : 0.002169, loss_ce: 0.001182
2021-11-30 15:57:44,399 iteration 6701 : loss : 0.002429, loss_ce: 0.000968
2021-11-30 15:57:45,617 iteration 6702 : loss : 0.002668, loss_ce: 0.001093
2021-11-30 15:57:46,851 iteration 6703 : loss : 0.002726, loss_ce: 0.000952
2021-11-30 15:57:48,080 iteration 6704 : loss : 0.002697, loss_ce: 0.001401
2021-11-30 15:57:49,302 iteration 6705 : loss : 0.002516, loss_ce: 0.001066
2021-11-30 15:57:50,523 iteration 6706 : loss : 0.002775, loss_ce: 0.001191
2021-11-30 15:57:51,753 iteration 6707 : loss : 0.002313, loss_ce: 0.000714
2021-11-30 15:57:52,975 iteration 6708 : loss : 0.003276, loss_ce: 0.001315
2021-11-30 15:57:54,197 iteration 6709 : loss : 0.003113, loss_ce: 0.001081
2021-11-30 15:57:55,423 iteration 6710 : loss : 0.002481, loss_ce: 0.000875
2021-11-30 15:57:56,654 iteration 6711 : loss : 0.002381, loss_ce: 0.000910
2021-11-30 15:57:57,882 iteration 6712 : loss : 0.002630, loss_ce: 0.001502
2021-11-30 15:57:59,112 iteration 6713 : loss : 0.002399, loss_ce: 0.000837
2021-11-30 15:58:00,330 iteration 6714 : loss : 0.002954, loss_ce: 0.001412
2021-11-30 15:58:00,330 Training Data Eval:
2021-11-30 15:58:07,266   Average segmentation loss on training set: 0.0022
2021-11-30 15:58:07,267 Validation Data Eval:
2021-11-30 15:58:09,652   Average segmentation loss on validation set: 0.1527
2021-11-30 15:58:10,879 iteration 6715 : loss : 0.002495, loss_ce: 0.001282
 99%|████████████████████████████▋| 395/400 [2:29:44<02:01, 24.26s/it]2021-11-30 15:58:12,176 iteration 6716 : loss : 0.003133, loss_ce: 0.001584
2021-11-30 15:58:13,399 iteration 6717 : loss : 0.002288, loss_ce: 0.000855
2021-11-30 15:58:14,622 iteration 6718 : loss : 0.002669, loss_ce: 0.001353
2021-11-30 15:58:15,850 iteration 6719 : loss : 0.001985, loss_ce: 0.000704
2021-11-30 15:58:17,075 iteration 6720 : loss : 0.002347, loss_ce: 0.000896
2021-11-30 15:58:18,302 iteration 6721 : loss : 0.002442, loss_ce: 0.000896
2021-11-30 15:58:19,525 iteration 6722 : loss : 0.002053, loss_ce: 0.001050
2021-11-30 15:58:20,756 iteration 6723 : loss : 0.002844, loss_ce: 0.000996
2021-11-30 15:58:21,982 iteration 6724 : loss : 0.002602, loss_ce: 0.001006
2021-11-30 15:58:23,210 iteration 6725 : loss : 0.002412, loss_ce: 0.001141
2021-11-30 15:58:24,438 iteration 6726 : loss : 0.002629, loss_ce: 0.001172
2021-11-30 15:58:25,665 iteration 6727 : loss : 0.003079, loss_ce: 0.001262
2021-11-30 15:58:26,934 iteration 6728 : loss : 0.002120, loss_ce: 0.000952
2021-11-30 15:58:28,156 iteration 6729 : loss : 0.002442, loss_ce: 0.000757
2021-11-30 15:58:29,384 iteration 6730 : loss : 0.002696, loss_ce: 0.001381
2021-11-30 15:58:30,607 iteration 6731 : loss : 0.002294, loss_ce: 0.000750
2021-11-30 15:58:31,837 iteration 6732 : loss : 0.002957, loss_ce: 0.001046
 99%|████████████████████████████▋| 396/400 [2:30:05<01:33, 23.27s/it]2021-11-30 15:58:33,135 iteration 6733 : loss : 0.003441, loss_ce: 0.000965
2021-11-30 15:58:34,362 iteration 6734 : loss : 0.002831, loss_ce: 0.001024
2021-11-30 15:58:35,588 iteration 6735 : loss : 0.002740, loss_ce: 0.001259
2021-11-30 15:58:36,813 iteration 6736 : loss : 0.002637, loss_ce: 0.001230
2021-11-30 15:58:38,037 iteration 6737 : loss : 0.002185, loss_ce: 0.001003
2021-11-30 15:58:39,261 iteration 6738 : loss : 0.003008, loss_ce: 0.001162
2021-11-30 15:58:40,488 iteration 6739 : loss : 0.002093, loss_ce: 0.000758
2021-11-30 15:58:41,714 iteration 6740 : loss : 0.002109, loss_ce: 0.000828
2021-11-30 15:58:42,938 iteration 6741 : loss : 0.002286, loss_ce: 0.001055
2021-11-30 15:58:44,165 iteration 6742 : loss : 0.002517, loss_ce: 0.000956
2021-11-30 15:58:45,386 iteration 6743 : loss : 0.002258, loss_ce: 0.001072
2021-11-30 15:58:46,613 iteration 6744 : loss : 0.003052, loss_ce: 0.001466
2021-11-30 15:58:47,842 iteration 6745 : loss : 0.002423, loss_ce: 0.001239
2021-11-30 15:58:49,068 iteration 6746 : loss : 0.002064, loss_ce: 0.001016
2021-11-30 15:58:50,291 iteration 6747 : loss : 0.002501, loss_ce: 0.001108
2021-11-30 15:58:51,510 iteration 6748 : loss : 0.003024, loss_ce: 0.001460
2021-11-30 15:58:52,740 iteration 6749 : loss : 0.001896, loss_ce: 0.000603
 99%|████████████████████████████▊| 397/400 [2:30:26<01:07, 22.56s/it]2021-11-30 15:58:54,042 iteration 6750 : loss : 0.002333, loss_ce: 0.001049
2021-11-30 15:58:55,268 iteration 6751 : loss : 0.002447, loss_ce: 0.001243
2021-11-30 15:58:56,490 iteration 6752 : loss : 0.002561, loss_ce: 0.001140
2021-11-30 15:58:57,719 iteration 6753 : loss : 0.002209, loss_ce: 0.000697
2021-11-30 15:58:58,947 iteration 6754 : loss : 0.003215, loss_ce: 0.001378
2021-11-30 15:59:00,182 iteration 6755 : loss : 0.002798, loss_ce: 0.000947
2021-11-30 15:59:01,402 iteration 6756 : loss : 0.003403, loss_ce: 0.000895
2021-11-30 15:59:02,624 iteration 6757 : loss : 0.002257, loss_ce: 0.001068
2021-11-30 15:59:03,862 iteration 6758 : loss : 0.002269, loss_ce: 0.000756
2021-11-30 15:59:05,092 iteration 6759 : loss : 0.001901, loss_ce: 0.000683
2021-11-30 15:59:06,320 iteration 6760 : loss : 0.002908, loss_ce: 0.001184
2021-11-30 15:59:07,549 iteration 6761 : loss : 0.002153, loss_ce: 0.000916
2021-11-30 15:59:08,779 iteration 6762 : loss : 0.002731, loss_ce: 0.001106
2021-11-30 15:59:10,004 iteration 6763 : loss : 0.002813, loss_ce: 0.001153
2021-11-30 15:59:11,224 iteration 6764 : loss : 0.002741, loss_ce: 0.001401
2021-11-30 15:59:12,461 iteration 6765 : loss : 0.002470, loss_ce: 0.001246
2021-11-30 15:59:13,684 iteration 6766 : loss : 0.002304, loss_ce: 0.001114
100%|████████████████████████████▊| 398/400 [2:30:47<00:44, 22.07s/it]2021-11-30 15:59:14,984 iteration 6767 : loss : 0.002953, loss_ce: 0.001493
2021-11-30 15:59:16,199 iteration 6768 : loss : 0.002460, loss_ce: 0.000816
2021-11-30 15:59:17,429 iteration 6769 : loss : 0.002116, loss_ce: 0.000920
2021-11-30 15:59:18,665 iteration 6770 : loss : 0.002472, loss_ce: 0.001326
2021-11-30 15:59:19,895 iteration 6771 : loss : 0.002017, loss_ce: 0.000709
2021-11-30 15:59:21,121 iteration 6772 : loss : 0.002628, loss_ce: 0.001417
2021-11-30 15:59:22,349 iteration 6773 : loss : 0.002503, loss_ce: 0.000950
2021-11-30 15:59:23,574 iteration 6774 : loss : 0.002505, loss_ce: 0.000808
2021-11-30 15:59:24,802 iteration 6775 : loss : 0.002215, loss_ce: 0.000942
2021-11-30 15:59:26,021 iteration 6776 : loss : 0.002782, loss_ce: 0.001272
2021-11-30 15:59:27,247 iteration 6777 : loss : 0.002422, loss_ce: 0.000973
2021-11-30 15:59:28,471 iteration 6778 : loss : 0.002240, loss_ce: 0.000739
2021-11-30 15:59:29,700 iteration 6779 : loss : 0.002345, loss_ce: 0.000866
2021-11-30 15:59:30,926 iteration 6780 : loss : 0.002199, loss_ce: 0.000754
2021-11-30 15:59:32,153 iteration 6781 : loss : 0.002430, loss_ce: 0.001032
2021-11-30 15:59:33,375 iteration 6782 : loss : 0.002807, loss_ce: 0.001299
2021-11-30 15:59:34,606 iteration 6783 : loss : 0.002723, loss_ce: 0.001194
100%|████████████████████████████▉| 399/400 [2:31:08<00:21, 21.73s/it]2021-11-30 15:59:35,901 iteration 6784 : loss : 0.002352, loss_ce: 0.000629
2021-11-30 15:59:37,129 iteration 6785 : loss : 0.002548, loss_ce: 0.000911
2021-11-30 15:59:38,356 iteration 6786 : loss : 0.002275, loss_ce: 0.001107
2021-11-30 15:59:39,583 iteration 6787 : loss : 0.002994, loss_ce: 0.001008
2021-11-30 15:59:40,805 iteration 6788 : loss : 0.002473, loss_ce: 0.000898
2021-11-30 15:59:42,025 iteration 6789 : loss : 0.002687, loss_ce: 0.001361
2021-11-30 15:59:43,260 iteration 6790 : loss : 0.002821, loss_ce: 0.001593
2021-11-30 15:59:44,485 iteration 6791 : loss : 0.002438, loss_ce: 0.001275
2021-11-30 15:59:45,711 iteration 6792 : loss : 0.002241, loss_ce: 0.000793
2021-11-30 15:59:46,935 iteration 6793 : loss : 0.002458, loss_ce: 0.000923
2021-11-30 15:59:48,168 iteration 6794 : loss : 0.002162, loss_ce: 0.000904
2021-11-30 15:59:49,396 iteration 6795 : loss : 0.002574, loss_ce: 0.000955
2021-11-30 15:59:50,622 iteration 6796 : loss : 0.003424, loss_ce: 0.001163
2021-11-30 15:59:51,847 iteration 6797 : loss : 0.002972, loss_ce: 0.001334
2021-11-30 15:59:53,071 iteration 6798 : loss : 0.002863, loss_ce: 0.001432
2021-11-30 15:59:54,298 iteration 6799 : loss : 0.002232, loss_ce: 0.000984
2021-11-30 15:59:54,299 Training Data Eval:
2021-11-30 16:00:01,220   Average segmentation loss on training set: 0.0021
2021-11-30 16:00:01,220 Validation Data Eval:
2021-11-30 16:00:03,597   Average segmentation loss on validation set: 0.1517
2021-11-30 16:00:04,817 iteration 6800 : loss : 0.002558, loss_ce: 0.001274
100%|█████████████████████████████| 400/400 [2:31:38<00:00, 24.27s/it]100%|█████████████████████████████| 400/400 [2:31:38<00:00, 22.75s/it]
