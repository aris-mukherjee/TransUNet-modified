2021-12-02 22:33:05,858 Logging directory: /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/TransUNet/log_dir/trRUNMC_cv1_r3/i2i2l/
2021-12-02 22:33:05,859 Tensorboard directory: /scratch_net/biwidl217_second/arismu/Tensorboard/trRUNMC_cv1_r3/i2i2l/
2021-12-02 22:33:05,859 ============================================================
2021-12-02 22:33:05,859 EXPERIMENT NAME: trRUNMC_cv1_r3/i2i2l/
2021-12-02 22:33:05,859 ============================================================
2021-12-02 22:33:05,859 Loading data...
2021-12-02 22:33:05,859 Reading NCI - RUNMC images...
2021-12-02 22:33:05,859 Data root directory: /itet-stor/arismu/bmicdatasets-originals/Originals/Challenge_Datasets/NCI_Prostate/
2021-12-02 22:33:05,860 Already preprocessed this configuration. Loading now!
2021-12-02 22:33:05,877 Training Images: (256, 256, 286)
2021-12-02 22:33:05,877 Training Labels: (256, 256, 286)
2021-12-02 22:33:05,877 Validation Images: (256, 256, 98)
2021-12-02 22:33:05,877 Validation Labels: (256, 256, 98)
2021-12-02 22:33:05,877 ============================================================
2021-12-02 22:33:05,899 17 iterations per epoch. 6800 max iterations 
  0%|                                         | 0/400 [00:00<?, ?it/s]2021-12-02 22:33:08,388 iteration 1 : loss : 0.828568, loss_ce: 0.947402
2021-12-02 22:33:09,723 iteration 2 : loss : 0.795236, loss_ce: 0.905090
2021-12-02 22:33:11,161 iteration 3 : loss : 0.746313, loss_ce: 0.817755
2021-12-02 22:33:12,506 iteration 4 : loss : 0.712163, loss_ce: 0.753774
2021-12-02 22:33:13,856 iteration 5 : loss : 0.669340, loss_ce: 0.695891
2021-12-02 22:33:15,224 iteration 6 : loss : 0.627461, loss_ce: 0.622631
2021-12-02 22:33:16,652 iteration 7 : loss : 0.587447, loss_ce: 0.583399
2021-12-02 22:33:18,029 iteration 8 : loss : 0.574773, loss_ce: 0.526105
2021-12-02 22:33:19,425 iteration 9 : loss : 0.535512, loss_ce: 0.521274
2021-12-02 22:33:20,848 iteration 10 : loss : 0.550870, loss_ce: 0.486097
2021-12-02 22:33:22,318 iteration 11 : loss : 0.498885, loss_ce: 0.447022
2021-12-02 22:33:23,680 iteration 12 : loss : 0.492939, loss_ce: 0.423886
2021-12-02 22:33:25,022 iteration 13 : loss : 0.499693, loss_ce: 0.418198
2021-12-02 22:33:26,346 iteration 14 : loss : 0.455445, loss_ce: 0.380497
2021-12-02 22:33:27,735 iteration 15 : loss : 0.452261, loss_ce: 0.370382
2021-12-02 22:33:29,109 iteration 16 : loss : 0.489699, loss_ce: 0.391630
2021-12-02 22:33:30,474 iteration 17 : loss : 0.408893, loss_ce: 0.334921
  0%|                               | 1/400 [00:24<2:43:55, 24.65s/it]2021-12-02 22:33:31,950 iteration 18 : loss : 0.456558, loss_ce: 0.336168
2021-12-02 22:33:33,249 iteration 19 : loss : 0.380418, loss_ce: 0.290996
2021-12-02 22:33:34,685 iteration 20 : loss : 0.388836, loss_ce: 0.293466
2021-12-02 22:33:36,029 iteration 21 : loss : 0.440982, loss_ce: 0.314970
2021-12-02 22:33:37,400 iteration 22 : loss : 0.364307, loss_ce: 0.277080
2021-12-02 22:33:38,849 iteration 23 : loss : 0.384677, loss_ce: 0.264173
2021-12-02 22:33:40,228 iteration 24 : loss : 0.370398, loss_ce: 0.266791
2021-12-02 22:33:41,657 iteration 25 : loss : 0.452707, loss_ce: 0.345311
2021-12-02 22:33:43,015 iteration 26 : loss : 0.355697, loss_ce: 0.247632
2021-12-02 22:33:44,325 iteration 27 : loss : 0.348365, loss_ce: 0.247864
2021-12-02 22:33:45,640 iteration 28 : loss : 0.352355, loss_ce: 0.241535
2021-12-02 22:33:47,056 iteration 29 : loss : 0.339446, loss_ce: 0.225898
2021-12-02 22:33:48,458 iteration 30 : loss : 0.347798, loss_ce: 0.234934
2021-12-02 22:33:49,784 iteration 31 : loss : 0.331113, loss_ce: 0.224875
2021-12-02 22:33:51,211 iteration 32 : loss : 0.330478, loss_ce: 0.232544
2021-12-02 22:33:52,626 iteration 33 : loss : 0.328442, loss_ce: 0.227269
2021-12-02 22:33:54,043 iteration 34 : loss : 0.322801, loss_ce: 0.231096
  0%|▏                              | 2/400 [00:48<2:39:14, 24.01s/it]2021-12-02 22:33:55,517 iteration 35 : loss : 0.312193, loss_ce: 0.199614
2021-12-02 22:33:56,944 iteration 36 : loss : 0.312260, loss_ce: 0.206212
2021-12-02 22:33:58,379 iteration 37 : loss : 0.332629, loss_ce: 0.200722
2021-12-02 22:33:59,737 iteration 38 : loss : 0.318805, loss_ce: 0.205966
2021-12-02 22:34:01,101 iteration 39 : loss : 0.277373, loss_ce: 0.181195
2021-12-02 22:34:02,534 iteration 40 : loss : 0.323523, loss_ce: 0.205138
2021-12-02 22:34:03,961 iteration 41 : loss : 0.364966, loss_ce: 0.228523
2021-12-02 22:34:05,373 iteration 42 : loss : 0.292465, loss_ce: 0.184209
2021-12-02 22:34:06,693 iteration 43 : loss : 0.307129, loss_ce: 0.181035
2021-12-02 22:34:08,152 iteration 44 : loss : 0.276770, loss_ce: 0.169209
2021-12-02 22:34:09,568 iteration 45 : loss : 0.269383, loss_ce: 0.170102
2021-12-02 22:34:10,977 iteration 46 : loss : 0.282505, loss_ce: 0.164472
2021-12-02 22:34:12,420 iteration 47 : loss : 0.251193, loss_ce: 0.142419
2021-12-02 22:34:13,829 iteration 48 : loss : 0.255448, loss_ce: 0.153121
2021-12-02 22:34:15,290 iteration 49 : loss : 0.349322, loss_ce: 0.207717
2021-12-02 22:34:16,651 iteration 50 : loss : 0.362416, loss_ce: 0.203733
2021-12-02 22:34:17,993 iteration 51 : loss : 0.303060, loss_ce: 0.175415
  1%|▏                              | 3/400 [01:12<2:38:39, 23.98s/it]2021-12-02 22:34:19,499 iteration 52 : loss : 0.310660, loss_ce: 0.183152
2021-12-02 22:34:20,933 iteration 53 : loss : 0.316118, loss_ce: 0.178597
2021-12-02 22:34:22,338 iteration 54 : loss : 0.273899, loss_ce: 0.142473
2021-12-02 22:34:23,751 iteration 55 : loss : 0.281572, loss_ce: 0.159073
2021-12-02 22:34:25,153 iteration 56 : loss : 0.284886, loss_ce: 0.151405
2021-12-02 22:34:26,571 iteration 57 : loss : 0.240247, loss_ce: 0.129069
2021-12-02 22:34:27,990 iteration 58 : loss : 0.332447, loss_ce: 0.176247
2021-12-02 22:34:29,374 iteration 59 : loss : 0.250305, loss_ce: 0.141885
2021-12-02 22:34:30,837 iteration 60 : loss : 0.352981, loss_ce: 0.193014
2021-12-02 22:34:32,244 iteration 61 : loss : 0.281331, loss_ce: 0.167417
2021-12-02 22:34:33,640 iteration 62 : loss : 0.376897, loss_ce: 0.184395
2021-12-02 22:34:34,968 iteration 63 : loss : 0.326297, loss_ce: 0.187590
2021-12-02 22:34:36,398 iteration 64 : loss : 0.363979, loss_ce: 0.190926
2021-12-02 22:34:37,817 iteration 65 : loss : 0.294982, loss_ce: 0.145787
2021-12-02 22:34:39,269 iteration 66 : loss : 0.272170, loss_ce: 0.148212
2021-12-02 22:34:40,789 iteration 67 : loss : 0.280882, loss_ce: 0.127634
2021-12-02 22:34:42,234 iteration 68 : loss : 0.254495, loss_ce: 0.132147
  1%|▎                              | 4/400 [01:36<2:38:55, 24.08s/it]2021-12-02 22:34:43,768 iteration 69 : loss : 0.255856, loss_ce: 0.130407
2021-12-02 22:34:45,279 iteration 70 : loss : 0.246442, loss_ce: 0.124986
2021-12-02 22:34:46,682 iteration 71 : loss : 0.239160, loss_ce: 0.118043
2021-12-02 22:34:48,145 iteration 72 : loss : 0.246061, loss_ce: 0.126629
2021-12-02 22:34:49,562 iteration 73 : loss : 0.249013, loss_ce: 0.137157
2021-12-02 22:34:50,952 iteration 74 : loss : 0.233795, loss_ce: 0.120427
2021-12-02 22:34:52,373 iteration 75 : loss : 0.231517, loss_ce: 0.119729
2021-12-02 22:34:53,779 iteration 76 : loss : 0.254208, loss_ce: 0.132282
2021-12-02 22:34:55,118 iteration 77 : loss : 0.232764, loss_ce: 0.130388
2021-12-02 22:34:56,556 iteration 78 : loss : 0.267233, loss_ce: 0.146885
2021-12-02 22:34:57,962 iteration 79 : loss : 0.284645, loss_ce: 0.131783
2021-12-02 22:34:59,359 iteration 80 : loss : 0.239517, loss_ce: 0.135341
2021-12-02 22:35:00,753 iteration 81 : loss : 0.253587, loss_ce: 0.131362
2021-12-02 22:35:02,182 iteration 82 : loss : 0.233390, loss_ce: 0.112425
2021-12-02 22:35:03,604 iteration 83 : loss : 0.268764, loss_ce: 0.111348
2021-12-02 22:35:05,094 iteration 84 : loss : 0.231513, loss_ce: 0.134582
2021-12-02 22:35:05,095 Training Data Eval:
2021-12-02 22:35:12,399   Average segmentation loss on training set: 0.3996
2021-12-02 22:35:12,399 Validation Data Eval:
2021-12-02 22:35:15,018   Average segmentation loss on validation set: 0.3966
2021-12-02 22:35:16,949 Found new lowest validation loss at iteration 84! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/UNET_RUNMC/1channel_best_val_loss.pth
2021-12-02 22:35:18,361 iteration 85 : loss : 0.268872, loss_ce: 0.125584
  1%|▍                              | 5/400 [02:12<3:07:06, 28.42s/it]2021-12-02 22:35:19,804 iteration 86 : loss : 0.325316, loss_ce: 0.138160
2021-12-02 22:35:21,319 iteration 87 : loss : 0.228735, loss_ce: 0.118880
2021-12-02 22:35:22,661 iteration 88 : loss : 0.248230, loss_ce: 0.126335
2021-12-02 22:35:24,082 iteration 89 : loss : 0.248176, loss_ce: 0.121718
2021-12-02 22:35:25,488 iteration 90 : loss : 0.227749, loss_ce: 0.110861
2021-12-02 22:35:26,967 iteration 91 : loss : 0.249215, loss_ce: 0.144833
2021-12-02 22:35:28,356 iteration 92 : loss : 0.218746, loss_ce: 0.112419
2021-12-02 22:35:29,811 iteration 93 : loss : 0.275844, loss_ce: 0.122714
2021-12-02 22:35:31,260 iteration 94 : loss : 0.222814, loss_ce: 0.112808
2021-12-02 22:35:32,819 iteration 95 : loss : 0.229057, loss_ce: 0.124509
2021-12-02 22:35:34,240 iteration 96 : loss : 0.224268, loss_ce: 0.115469
2021-12-02 22:35:35,665 iteration 97 : loss : 0.268454, loss_ce: 0.129725
2021-12-02 22:35:37,106 iteration 98 : loss : 0.253350, loss_ce: 0.125181
2021-12-02 22:35:38,614 iteration 99 : loss : 0.217845, loss_ce: 0.106107
2021-12-02 22:35:40,082 iteration 100 : loss : 0.230271, loss_ce: 0.107694
2021-12-02 22:35:41,533 iteration 101 : loss : 0.158497, loss_ce: 0.072961
2021-12-02 22:35:42,933 iteration 102 : loss : 0.219180, loss_ce: 0.103198
  2%|▍                              | 6/400 [02:37<2:58:04, 27.12s/it]2021-12-02 22:35:44,539 iteration 103 : loss : 0.196697, loss_ce: 0.100591
2021-12-02 22:35:46,047 iteration 104 : loss : 0.237298, loss_ce: 0.121026
2021-12-02 22:35:47,594 iteration 105 : loss : 0.262058, loss_ce: 0.121833
2021-12-02 22:35:48,986 iteration 106 : loss : 0.243510, loss_ce: 0.114447
2021-12-02 22:35:50,563 iteration 107 : loss : 0.212784, loss_ce: 0.110711
2021-12-02 22:35:51,960 iteration 108 : loss : 0.279459, loss_ce: 0.134434
2021-12-02 22:35:53,399 iteration 109 : loss : 0.195297, loss_ce: 0.104142
2021-12-02 22:35:54,774 iteration 110 : loss : 0.189775, loss_ce: 0.090995
2021-12-02 22:35:56,241 iteration 111 : loss : 0.226293, loss_ce: 0.121248
2021-12-02 22:35:57,628 iteration 112 : loss : 0.198845, loss_ce: 0.087607
2021-12-02 22:35:59,084 iteration 113 : loss : 0.246632, loss_ce: 0.139837
2021-12-02 22:36:00,507 iteration 114 : loss : 0.249478, loss_ce: 0.095055
2021-12-02 22:36:01,971 iteration 115 : loss : 0.202233, loss_ce: 0.098631
2021-12-02 22:36:03,483 iteration 116 : loss : 0.236908, loss_ce: 0.114344
2021-12-02 22:36:04,976 iteration 117 : loss : 0.230954, loss_ce: 0.116853
2021-12-02 22:36:06,433 iteration 118 : loss : 0.247010, loss_ce: 0.119721
2021-12-02 22:36:07,904 iteration 119 : loss : 0.205431, loss_ce: 0.093043
  2%|▌                              | 7/400 [03:02<2:53:01, 26.42s/it]2021-12-02 22:36:09,390 iteration 120 : loss : 0.345521, loss_ce: 0.196836
2021-12-02 22:36:10,797 iteration 121 : loss : 0.162982, loss_ce: 0.079551
2021-12-02 22:36:12,300 iteration 122 : loss : 0.236844, loss_ce: 0.098463
2021-12-02 22:36:13,768 iteration 123 : loss : 0.238805, loss_ce: 0.103478
2021-12-02 22:36:15,205 iteration 124 : loss : 0.205505, loss_ce: 0.081763
2021-12-02 22:36:16,605 iteration 125 : loss : 0.213538, loss_ce: 0.111251
2021-12-02 22:36:18,061 iteration 126 : loss : 0.241968, loss_ce: 0.102697
2021-12-02 22:36:19,474 iteration 127 : loss : 0.214749, loss_ce: 0.106404
2021-12-02 22:36:20,904 iteration 128 : loss : 0.192787, loss_ce: 0.095526
2021-12-02 22:36:22,399 iteration 129 : loss : 0.234847, loss_ce: 0.106017
2021-12-02 22:36:23,826 iteration 130 : loss : 0.194460, loss_ce: 0.090141
2021-12-02 22:36:25,350 iteration 131 : loss : 0.217148, loss_ce: 0.110099
2021-12-02 22:36:26,889 iteration 132 : loss : 0.190000, loss_ce: 0.066042
2021-12-02 22:36:28,301 iteration 133 : loss : 0.192786, loss_ce: 0.081462
2021-12-02 22:36:29,817 iteration 134 : loss : 0.188869, loss_ce: 0.082166
2021-12-02 22:36:31,346 iteration 135 : loss : 0.208022, loss_ce: 0.093724
2021-12-02 22:36:32,807 iteration 136 : loss : 0.166367, loss_ce: 0.083159
  2%|▌                              | 8/400 [03:26<2:49:24, 25.93s/it]2021-12-02 22:36:34,369 iteration 137 : loss : 0.206200, loss_ce: 0.083516
2021-12-02 22:36:35,780 iteration 138 : loss : 0.187841, loss_ce: 0.105691
2021-12-02 22:36:37,270 iteration 139 : loss : 0.237761, loss_ce: 0.105806
2021-12-02 22:36:38,735 iteration 140 : loss : 0.183803, loss_ce: 0.077488
2021-12-02 22:36:40,236 iteration 141 : loss : 0.206455, loss_ce: 0.094855
2021-12-02 22:36:41,733 iteration 142 : loss : 0.197323, loss_ce: 0.087475
2021-12-02 22:36:43,259 iteration 143 : loss : 0.210451, loss_ce: 0.097498
2021-12-02 22:36:44,754 iteration 144 : loss : 0.174211, loss_ce: 0.081309
2021-12-02 22:36:46,200 iteration 145 : loss : 0.195531, loss_ce: 0.089855
2021-12-02 22:36:47,696 iteration 146 : loss : 0.155223, loss_ce: 0.081560
2021-12-02 22:36:49,195 iteration 147 : loss : 0.189420, loss_ce: 0.088272
2021-12-02 22:36:50,570 iteration 148 : loss : 0.187511, loss_ce: 0.090958
2021-12-02 22:36:52,020 iteration 149 : loss : 0.270247, loss_ce: 0.133530
2021-12-02 22:36:53,450 iteration 150 : loss : 0.228392, loss_ce: 0.091613
2021-12-02 22:36:54,885 iteration 151 : loss : 0.194575, loss_ce: 0.091246
2021-12-02 22:36:56,322 iteration 152 : loss : 0.211396, loss_ce: 0.076470
2021-12-02 22:36:57,808 iteration 153 : loss : 0.240338, loss_ce: 0.110459
  2%|▋                              | 9/400 [03:51<2:47:06, 25.64s/it]2021-12-02 22:36:59,267 iteration 154 : loss : 0.230596, loss_ce: 0.104462
2021-12-02 22:37:00,728 iteration 155 : loss : 0.196115, loss_ce: 0.078412
2021-12-02 22:37:02,263 iteration 156 : loss : 0.148739, loss_ce: 0.067418
2021-12-02 22:37:03,741 iteration 157 : loss : 0.212515, loss_ce: 0.086815
2021-12-02 22:37:05,308 iteration 158 : loss : 0.228065, loss_ce: 0.110908
2021-12-02 22:37:06,656 iteration 159 : loss : 0.172613, loss_ce: 0.079751
2021-12-02 22:37:08,184 iteration 160 : loss : 0.172511, loss_ce: 0.066333
2021-12-02 22:37:09,693 iteration 161 : loss : 0.265621, loss_ce: 0.111317
2021-12-02 22:37:11,204 iteration 162 : loss : 0.227960, loss_ce: 0.115046
2021-12-02 22:37:12,660 iteration 163 : loss : 0.257188, loss_ce: 0.123058
2021-12-02 22:37:14,151 iteration 164 : loss : 0.178978, loss_ce: 0.075480
2021-12-02 22:37:15,604 iteration 165 : loss : 0.219618, loss_ce: 0.105243
2021-12-02 22:37:17,047 iteration 166 : loss : 0.218789, loss_ce: 0.090547
2021-12-02 22:37:18,498 iteration 167 : loss : 0.163040, loss_ce: 0.067791
2021-12-02 22:37:19,976 iteration 168 : loss : 0.207527, loss_ce: 0.103332
2021-12-02 22:37:21,440 iteration 169 : loss : 0.183374, loss_ce: 0.095290
2021-12-02 22:37:21,441 Training Data Eval:
2021-12-02 22:37:28,855   Average segmentation loss on training set: 0.1698
2021-12-02 22:37:28,855 Validation Data Eval:
2021-12-02 22:37:31,434   Average segmentation loss on validation set: 0.2216
2021-12-02 22:37:33,444 Found new lowest validation loss at iteration 169! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/UNET_RUNMC/1channel_best_val_loss.pth
2021-12-02 22:37:34,943 iteration 170 : loss : 0.146170, loss_ce: 0.061470
  2%|▊                             | 10/400 [04:29<3:09:42, 29.19s/it]2021-12-02 22:37:36,409 iteration 171 : loss : 0.153901, loss_ce: 0.067090
2021-12-02 22:37:37,832 iteration 172 : loss : 0.165508, loss_ce: 0.079818
2021-12-02 22:37:39,266 iteration 173 : loss : 0.142030, loss_ce: 0.068213
2021-12-02 22:37:40,619 iteration 174 : loss : 0.176208, loss_ce: 0.079552
2021-12-02 22:37:41,964 iteration 175 : loss : 0.194750, loss_ce: 0.084763
2021-12-02 22:37:43,433 iteration 176 : loss : 0.160924, loss_ce: 0.082472
2021-12-02 22:37:44,896 iteration 177 : loss : 0.150872, loss_ce: 0.065777
2021-12-02 22:37:46,366 iteration 178 : loss : 0.171684, loss_ce: 0.083853
2021-12-02 22:37:47,837 iteration 179 : loss : 0.185197, loss_ce: 0.077257
2021-12-02 22:37:49,290 iteration 180 : loss : 0.126547, loss_ce: 0.050960
2021-12-02 22:37:50,783 iteration 181 : loss : 0.134177, loss_ce: 0.061495
2021-12-02 22:37:52,215 iteration 182 : loss : 0.125488, loss_ce: 0.054981
2021-12-02 22:37:53,630 iteration 183 : loss : 0.161499, loss_ce: 0.062214
2021-12-02 22:37:55,006 iteration 184 : loss : 0.184622, loss_ce: 0.070582
2021-12-02 22:37:56,517 iteration 185 : loss : 0.191530, loss_ce: 0.080521
2021-12-02 22:37:58,007 iteration 186 : loss : 0.203276, loss_ce: 0.093444
2021-12-02 22:37:59,513 iteration 187 : loss : 0.163388, loss_ce: 0.069960
  3%|▊                             | 11/400 [04:53<3:00:04, 27.77s/it]2021-12-02 22:38:01,043 iteration 188 : loss : 0.165445, loss_ce: 0.077019
2021-12-02 22:38:02,510 iteration 189 : loss : 0.166258, loss_ce: 0.071035
2021-12-02 22:38:03,981 iteration 190 : loss : 0.156815, loss_ce: 0.063111
2021-12-02 22:38:05,408 iteration 191 : loss : 0.149670, loss_ce: 0.060572
2021-12-02 22:38:06,817 iteration 192 : loss : 0.155514, loss_ce: 0.073627
2021-12-02 22:38:08,327 iteration 193 : loss : 0.159734, loss_ce: 0.069672
2021-12-02 22:38:09,761 iteration 194 : loss : 0.191926, loss_ce: 0.069587
2021-12-02 22:38:11,197 iteration 195 : loss : 0.156094, loss_ce: 0.066499
2021-12-02 22:38:12,590 iteration 196 : loss : 0.131876, loss_ce: 0.050851
2021-12-02 22:38:14,068 iteration 197 : loss : 0.160553, loss_ce: 0.066894
2021-12-02 22:38:15,585 iteration 198 : loss : 0.179110, loss_ce: 0.086892
2021-12-02 22:38:17,032 iteration 199 : loss : 0.174179, loss_ce: 0.065898
2021-12-02 22:38:18,472 iteration 200 : loss : 0.156193, loss_ce: 0.069888
2021-12-02 22:38:19,954 iteration 201 : loss : 0.109782, loss_ce: 0.048262
2021-12-02 22:38:21,443 iteration 202 : loss : 0.161974, loss_ce: 0.074093
2021-12-02 22:38:22,861 iteration 203 : loss : 0.138636, loss_ce: 0.061416
2021-12-02 22:38:24,399 iteration 204 : loss : 0.168665, loss_ce: 0.071641
  3%|▉                             | 12/400 [05:18<2:53:55, 26.90s/it]2021-12-02 22:38:25,871 iteration 205 : loss : 0.127837, loss_ce: 0.055759
2021-12-02 22:38:27,311 iteration 206 : loss : 0.162309, loss_ce: 0.062319
2021-12-02 22:38:28,776 iteration 207 : loss : 0.139422, loss_ce: 0.060545
2021-12-02 22:38:30,198 iteration 208 : loss : 0.194353, loss_ce: 0.069347
2021-12-02 22:38:31,736 iteration 209 : loss : 0.181524, loss_ce: 0.081074
2021-12-02 22:38:33,132 iteration 210 : loss : 0.130862, loss_ce: 0.049889
2021-12-02 22:38:34,651 iteration 211 : loss : 0.190070, loss_ce: 0.092323
2021-12-02 22:38:36,139 iteration 212 : loss : 0.178496, loss_ce: 0.070152
2021-12-02 22:38:37,697 iteration 213 : loss : 0.143620, loss_ce: 0.067360
2021-12-02 22:38:39,157 iteration 214 : loss : 0.150829, loss_ce: 0.054051
2021-12-02 22:38:40,627 iteration 215 : loss : 0.180946, loss_ce: 0.077495
2021-12-02 22:38:42,229 iteration 216 : loss : 0.147287, loss_ce: 0.058699
2021-12-02 22:38:43,765 iteration 217 : loss : 0.157700, loss_ce: 0.064406
2021-12-02 22:38:45,223 iteration 218 : loss : 0.200881, loss_ce: 0.100985
2021-12-02 22:38:46,585 iteration 219 : loss : 0.133227, loss_ce: 0.064113
2021-12-02 22:38:48,068 iteration 220 : loss : 0.124350, loss_ce: 0.057995
2021-12-02 22:38:49,546 iteration 221 : loss : 0.176890, loss_ce: 0.064845
  3%|▉                             | 13/400 [05:43<2:50:03, 26.37s/it]2021-12-02 22:38:51,081 iteration 222 : loss : 0.158228, loss_ce: 0.078149
2021-12-02 22:38:52,587 iteration 223 : loss : 0.143607, loss_ce: 0.060918
2021-12-02 22:38:54,041 iteration 224 : loss : 0.168985, loss_ce: 0.089605
2021-12-02 22:38:55,583 iteration 225 : loss : 0.277422, loss_ce: 0.091615
2021-12-02 22:38:57,032 iteration 226 : loss : 0.149165, loss_ce: 0.060704
2021-12-02 22:38:58,523 iteration 227 : loss : 0.162346, loss_ce: 0.073154
2021-12-02 22:38:59,988 iteration 228 : loss : 0.115352, loss_ce: 0.051324
2021-12-02 22:39:01,426 iteration 229 : loss : 0.152301, loss_ce: 0.056699
2021-12-02 22:39:02,911 iteration 230 : loss : 0.136589, loss_ce: 0.052604
2021-12-02 22:39:04,421 iteration 231 : loss : 0.201089, loss_ce: 0.080026
2021-12-02 22:39:05,927 iteration 232 : loss : 0.096161, loss_ce: 0.039698
2021-12-02 22:39:07,352 iteration 233 : loss : 0.167974, loss_ce: 0.072179
2021-12-02 22:39:08,867 iteration 234 : loss : 0.123235, loss_ce: 0.051093
2021-12-02 22:39:10,287 iteration 235 : loss : 0.144627, loss_ce: 0.063090
2021-12-02 22:39:11,766 iteration 236 : loss : 0.123970, loss_ce: 0.048989
2021-12-02 22:39:13,208 iteration 237 : loss : 0.129517, loss_ce: 0.056646
2021-12-02 22:39:14,684 iteration 238 : loss : 0.114249, loss_ce: 0.054200
  4%|█                             | 14/400 [06:08<2:47:14, 26.00s/it]2021-12-02 22:39:16,172 iteration 239 : loss : 0.152652, loss_ce: 0.058024
2021-12-02 22:39:17,665 iteration 240 : loss : 0.130818, loss_ce: 0.061291
2021-12-02 22:39:19,154 iteration 241 : loss : 0.198907, loss_ce: 0.078005
2021-12-02 22:39:20,622 iteration 242 : loss : 0.145273, loss_ce: 0.078177
2021-12-02 22:39:22,217 iteration 243 : loss : 0.161683, loss_ce: 0.071412
2021-12-02 22:39:23,632 iteration 244 : loss : 0.209662, loss_ce: 0.064298
2021-12-02 22:39:25,115 iteration 245 : loss : 0.155394, loss_ce: 0.079525
2021-12-02 22:39:26,634 iteration 246 : loss : 0.133508, loss_ce: 0.059236
2021-12-02 22:39:28,098 iteration 247 : loss : 0.161287, loss_ce: 0.060043
2021-12-02 22:39:29,546 iteration 248 : loss : 0.130670, loss_ce: 0.046384
2021-12-02 22:39:30,971 iteration 249 : loss : 0.166955, loss_ce: 0.085355
2021-12-02 22:39:32,407 iteration 250 : loss : 0.157261, loss_ce: 0.064334
2021-12-02 22:39:33,807 iteration 251 : loss : 0.146021, loss_ce: 0.053745
2021-12-02 22:39:35,266 iteration 252 : loss : 0.109580, loss_ce: 0.053731
2021-12-02 22:39:36,749 iteration 253 : loss : 0.156161, loss_ce: 0.071614
2021-12-02 22:39:38,286 iteration 254 : loss : 0.209352, loss_ce: 0.067634
2021-12-02 22:39:38,286 Training Data Eval:
2021-12-02 22:39:45,727   Average segmentation loss on training set: 0.1434
2021-12-02 22:39:45,727 Validation Data Eval:
2021-12-02 22:39:48,259   Average segmentation loss on validation set: 0.1553
2021-12-02 22:39:50,212 Found new lowest validation loss at iteration 254! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/UNET_RUNMC/1channel_best_val_loss.pth
2021-12-02 22:39:51,628 iteration 255 : loss : 0.133662, loss_ce: 0.058866
  4%|█▏                            | 15/400 [06:45<3:07:59, 29.30s/it]2021-12-02 22:39:53,111 iteration 256 : loss : 0.154402, loss_ce: 0.064507
2021-12-02 22:39:54,564 iteration 257 : loss : 0.114821, loss_ce: 0.046076
2021-12-02 22:39:56,063 iteration 258 : loss : 0.170804, loss_ce: 0.067320
2021-12-02 22:39:57,388 iteration 259 : loss : 0.113178, loss_ce: 0.049144
2021-12-02 22:39:58,852 iteration 260 : loss : 0.122442, loss_ce: 0.052644
2021-12-02 22:40:00,297 iteration 261 : loss : 0.217204, loss_ce: 0.076084
2021-12-02 22:40:01,851 iteration 262 : loss : 0.122130, loss_ce: 0.053665
2021-12-02 22:40:03,341 iteration 263 : loss : 0.140810, loss_ce: 0.063440
2021-12-02 22:40:04,847 iteration 264 : loss : 0.116748, loss_ce: 0.057075
2021-12-02 22:40:06,289 iteration 265 : loss : 0.114677, loss_ce: 0.050586
2021-12-02 22:40:07,770 iteration 266 : loss : 0.137166, loss_ce: 0.065767
2021-12-02 22:40:09,235 iteration 267 : loss : 0.111067, loss_ce: 0.037920
2021-12-02 22:40:10,702 iteration 268 : loss : 0.130514, loss_ce: 0.063088
2021-12-02 22:40:12,336 iteration 269 : loss : 0.135331, loss_ce: 0.045044
2021-12-02 22:40:13,897 iteration 270 : loss : 0.134978, loss_ce: 0.054811
2021-12-02 22:40:15,241 iteration 271 : loss : 0.124577, loss_ce: 0.042168
2021-12-02 22:40:16,710 iteration 272 : loss : 0.149452, loss_ce: 0.066702
  4%|█▏                            | 16/400 [07:10<2:59:22, 28.03s/it]2021-12-02 22:40:18,206 iteration 273 : loss : 0.129619, loss_ce: 0.052949
2021-12-02 22:40:19,637 iteration 274 : loss : 0.090073, loss_ce: 0.036943
2021-12-02 22:40:21,071 iteration 275 : loss : 0.113210, loss_ce: 0.047079
2021-12-02 22:40:22,544 iteration 276 : loss : 0.097348, loss_ce: 0.046969
2021-12-02 22:40:24,029 iteration 277 : loss : 0.105455, loss_ce: 0.043076
2021-12-02 22:40:25,371 iteration 278 : loss : 0.143408, loss_ce: 0.050007
2021-12-02 22:40:26,794 iteration 279 : loss : 0.162471, loss_ce: 0.059117
2021-12-02 22:40:28,210 iteration 280 : loss : 0.126157, loss_ce: 0.056321
2021-12-02 22:40:29,676 iteration 281 : loss : 0.109034, loss_ce: 0.046765
2021-12-02 22:40:31,128 iteration 282 : loss : 0.156078, loss_ce: 0.069789
2021-12-02 22:40:32,558 iteration 283 : loss : 0.135251, loss_ce: 0.071216
2021-12-02 22:40:34,065 iteration 284 : loss : 0.124076, loss_ce: 0.050193
2021-12-02 22:40:35,475 iteration 285 : loss : 0.143384, loss_ce: 0.049158
2021-12-02 22:40:36,905 iteration 286 : loss : 0.110339, loss_ce: 0.049562
2021-12-02 22:40:38,439 iteration 287 : loss : 0.102560, loss_ce: 0.044335
2021-12-02 22:40:39,961 iteration 288 : loss : 0.140050, loss_ce: 0.055856
2021-12-02 22:40:41,411 iteration 289 : loss : 0.099456, loss_ce: 0.039178
  4%|█▎                            | 17/400 [07:35<2:52:31, 27.03s/it]2021-12-02 22:40:42,931 iteration 290 : loss : 0.111148, loss_ce: 0.048388
2021-12-02 22:40:44,351 iteration 291 : loss : 0.100152, loss_ce: 0.038871
2021-12-02 22:40:45,778 iteration 292 : loss : 0.078952, loss_ce: 0.036916
2021-12-02 22:40:47,212 iteration 293 : loss : 0.107720, loss_ce: 0.046795
2021-12-02 22:40:48,673 iteration 294 : loss : 0.112032, loss_ce: 0.050473
2021-12-02 22:40:50,216 iteration 295 : loss : 0.115958, loss_ce: 0.044149
2021-12-02 22:40:51,648 iteration 296 : loss : 0.084472, loss_ce: 0.032690
2021-12-02 22:40:53,120 iteration 297 : loss : 0.121623, loss_ce: 0.040594
2021-12-02 22:40:54,546 iteration 298 : loss : 0.084316, loss_ce: 0.033909
2021-12-02 22:40:55,996 iteration 299 : loss : 0.126501, loss_ce: 0.055724
2021-12-02 22:40:57,452 iteration 300 : loss : 0.142168, loss_ce: 0.048422
2021-12-02 22:40:58,917 iteration 301 : loss : 0.142965, loss_ce: 0.074746
2021-12-02 22:41:00,447 iteration 302 : loss : 0.096972, loss_ce: 0.042139
2021-12-02 22:41:01,946 iteration 303 : loss : 0.142784, loss_ce: 0.060259
2021-12-02 22:41:03,426 iteration 304 : loss : 0.123567, loss_ce: 0.052468
2021-12-02 22:41:04,966 iteration 305 : loss : 0.087542, loss_ce: 0.042709
2021-12-02 22:41:06,482 iteration 306 : loss : 0.093776, loss_ce: 0.048125
  4%|█▎                            | 18/400 [08:00<2:48:20, 26.44s/it]2021-12-02 22:41:08,009 iteration 307 : loss : 0.153894, loss_ce: 0.059486
2021-12-02 22:41:09,438 iteration 308 : loss : 0.108881, loss_ce: 0.054793
2021-12-02 22:41:10,933 iteration 309 : loss : 0.180462, loss_ce: 0.077473
2021-12-02 22:41:12,439 iteration 310 : loss : 0.136682, loss_ce: 0.064466
2021-12-02 22:41:13,858 iteration 311 : loss : 0.164298, loss_ce: 0.058343
2021-12-02 22:41:15,311 iteration 312 : loss : 0.106458, loss_ce: 0.050044
2021-12-02 22:41:16,791 iteration 313 : loss : 0.180099, loss_ce: 0.108438
2021-12-02 22:41:18,195 iteration 314 : loss : 0.085001, loss_ce: 0.038634
2021-12-02 22:41:19,655 iteration 315 : loss : 0.133710, loss_ce: 0.046901
2021-12-02 22:41:21,134 iteration 316 : loss : 0.161235, loss_ce: 0.055795
2021-12-02 22:41:22,602 iteration 317 : loss : 0.112552, loss_ce: 0.045733
2021-12-02 22:41:24,074 iteration 318 : loss : 0.137589, loss_ce: 0.065548
2021-12-02 22:41:25,476 iteration 319 : loss : 0.132534, loss_ce: 0.051869
2021-12-02 22:41:27,038 iteration 320 : loss : 0.108108, loss_ce: 0.040218
2021-12-02 22:41:28,532 iteration 321 : loss : 0.111591, loss_ce: 0.033998
2021-12-02 22:41:29,981 iteration 322 : loss : 0.187889, loss_ce: 0.090901
2021-12-02 22:41:31,496 iteration 323 : loss : 0.162656, loss_ce: 0.054559
  5%|█▍                            | 19/400 [08:25<2:45:10, 26.01s/it]2021-12-02 22:41:33,012 iteration 324 : loss : 0.159339, loss_ce: 0.063666
2021-12-02 22:41:34,481 iteration 325 : loss : 0.156208, loss_ce: 0.050955
2021-12-02 22:41:35,970 iteration 326 : loss : 0.107382, loss_ce: 0.046926
2021-12-02 22:41:37,527 iteration 327 : loss : 0.157373, loss_ce: 0.072697
2021-12-02 22:41:38,980 iteration 328 : loss : 0.126430, loss_ce: 0.049266
2021-12-02 22:41:40,459 iteration 329 : loss : 0.147637, loss_ce: 0.076623
2021-12-02 22:41:41,958 iteration 330 : loss : 0.149465, loss_ce: 0.056539
2021-12-02 22:41:43,379 iteration 331 : loss : 0.100698, loss_ce: 0.044236
2021-12-02 22:41:44,839 iteration 332 : loss : 0.122603, loss_ce: 0.045842
2021-12-02 22:41:46,333 iteration 333 : loss : 0.110375, loss_ce: 0.051914
2021-12-02 22:41:47,800 iteration 334 : loss : 0.147331, loss_ce: 0.059145
2021-12-02 22:41:49,245 iteration 335 : loss : 0.164503, loss_ce: 0.055664
2021-12-02 22:41:50,768 iteration 336 : loss : 0.137312, loss_ce: 0.055197
2021-12-02 22:41:52,237 iteration 337 : loss : 0.123472, loss_ce: 0.043657
2021-12-02 22:41:53,665 iteration 338 : loss : 0.136107, loss_ce: 0.065583
2021-12-02 22:41:55,094 iteration 339 : loss : 0.119800, loss_ce: 0.045028
2021-12-02 22:41:55,094 Training Data Eval:
2021-12-02 22:42:02,456   Average segmentation loss on training set: 0.1571
2021-12-02 22:42:02,456 Validation Data Eval:
2021-12-02 22:42:05,019   Average segmentation loss on validation set: 0.2110
2021-12-02 22:42:06,542 iteration 340 : loss : 0.112350, loss_ce: 0.043804
  5%|█▌                            | 20/400 [09:00<3:01:54, 28.72s/it]2021-12-02 22:42:08,110 iteration 341 : loss : 0.073150, loss_ce: 0.033710
2021-12-02 22:42:09,602 iteration 342 : loss : 0.095393, loss_ce: 0.031936
2021-12-02 22:42:11,076 iteration 343 : loss : 0.137162, loss_ce: 0.054988
2021-12-02 22:42:12,567 iteration 344 : loss : 0.192748, loss_ce: 0.090343
2021-12-02 22:42:14,023 iteration 345 : loss : 0.094033, loss_ce: 0.031759
2021-12-02 22:42:15,548 iteration 346 : loss : 0.153920, loss_ce: 0.059215
2021-12-02 22:42:16,977 iteration 347 : loss : 0.124931, loss_ce: 0.062780
2021-12-02 22:42:18,484 iteration 348 : loss : 0.113682, loss_ce: 0.041542
2021-12-02 22:42:20,065 iteration 349 : loss : 0.153607, loss_ce: 0.073632
2021-12-02 22:42:21,516 iteration 350 : loss : 0.110469, loss_ce: 0.043167
2021-12-02 22:42:23,023 iteration 351 : loss : 0.100626, loss_ce: 0.044998
2021-12-02 22:42:24,507 iteration 352 : loss : 0.105270, loss_ce: 0.042307
2021-12-02 22:42:25,914 iteration 353 : loss : 0.099030, loss_ce: 0.043521
2021-12-02 22:42:27,381 iteration 354 : loss : 0.134804, loss_ce: 0.045017
2021-12-02 22:42:28,903 iteration 355 : loss : 0.137926, loss_ce: 0.057482
2021-12-02 22:42:30,486 iteration 356 : loss : 0.120564, loss_ce: 0.052226
2021-12-02 22:42:31,889 iteration 357 : loss : 0.095017, loss_ce: 0.038200
  5%|█▌                            | 21/400 [09:26<2:55:01, 27.71s/it]2021-12-02 22:42:33,431 iteration 358 : loss : 0.099198, loss_ce: 0.043415
2021-12-02 22:42:34,944 iteration 359 : loss : 0.124319, loss_ce: 0.048898
2021-12-02 22:42:36,344 iteration 360 : loss : 0.075363, loss_ce: 0.027255
2021-12-02 22:42:37,851 iteration 361 : loss : 0.134058, loss_ce: 0.042744
2021-12-02 22:42:39,397 iteration 362 : loss : 0.126179, loss_ce: 0.037683
2021-12-02 22:42:40,923 iteration 363 : loss : 0.132782, loss_ce: 0.051783
2021-12-02 22:42:42,410 iteration 364 : loss : 0.096147, loss_ce: 0.039635
2021-12-02 22:42:43,784 iteration 365 : loss : 0.116457, loss_ce: 0.057354
2021-12-02 22:42:45,294 iteration 366 : loss : 0.140318, loss_ce: 0.061513
2021-12-02 22:42:46,703 iteration 367 : loss : 0.096254, loss_ce: 0.038957
2021-12-02 22:42:48,205 iteration 368 : loss : 0.128557, loss_ce: 0.048517
2021-12-02 22:42:49,746 iteration 369 : loss : 0.130262, loss_ce: 0.042214
2021-12-02 22:42:51,257 iteration 370 : loss : 0.116691, loss_ce: 0.058721
2021-12-02 22:42:52,745 iteration 371 : loss : 0.157257, loss_ce: 0.045289
2021-12-02 22:42:54,247 iteration 372 : loss : 0.150962, loss_ce: 0.074452
2021-12-02 22:42:55,678 iteration 373 : loss : 0.131203, loss_ce: 0.043466
2021-12-02 22:42:57,137 iteration 374 : loss : 0.114732, loss_ce: 0.045895
  6%|█▋                            | 22/400 [09:51<2:49:55, 26.97s/it]2021-12-02 22:42:58,713 iteration 375 : loss : 0.159055, loss_ce: 0.071006
2021-12-02 22:43:00,119 iteration 376 : loss : 0.071000, loss_ce: 0.029011
2021-12-02 22:43:01,555 iteration 377 : loss : 0.067705, loss_ce: 0.025267
2021-12-02 22:43:03,083 iteration 378 : loss : 0.093776, loss_ce: 0.038288
2021-12-02 22:43:04,467 iteration 379 : loss : 0.111433, loss_ce: 0.047811
2021-12-02 22:43:05,974 iteration 380 : loss : 0.094386, loss_ce: 0.037393
2021-12-02 22:43:07,449 iteration 381 : loss : 0.087484, loss_ce: 0.032499
2021-12-02 22:43:08,848 iteration 382 : loss : 0.107455, loss_ce: 0.057576
2021-12-02 22:43:10,304 iteration 383 : loss : 0.151339, loss_ce: 0.054592
2021-12-02 22:43:11,776 iteration 384 : loss : 0.084401, loss_ce: 0.039018
2021-12-02 22:43:13,249 iteration 385 : loss : 0.089333, loss_ce: 0.038053
2021-12-02 22:43:14,728 iteration 386 : loss : 0.128717, loss_ce: 0.046006
2021-12-02 22:43:16,217 iteration 387 : loss : 0.147351, loss_ce: 0.052799
2021-12-02 22:43:17,717 iteration 388 : loss : 0.099753, loss_ce: 0.041460
2021-12-02 22:43:19,207 iteration 389 : loss : 0.190645, loss_ce: 0.083978
2021-12-02 22:43:20,656 iteration 390 : loss : 0.098790, loss_ce: 0.042550
2021-12-02 22:43:22,112 iteration 391 : loss : 0.139772, loss_ce: 0.079341
  6%|█▋                            | 23/400 [10:16<2:45:41, 26.37s/it]2021-12-02 22:43:23,646 iteration 392 : loss : 0.092021, loss_ce: 0.052087
2021-12-02 22:43:25,066 iteration 393 : loss : 0.085246, loss_ce: 0.032272
2021-12-02 22:43:26,577 iteration 394 : loss : 0.093364, loss_ce: 0.035171
2021-12-02 22:43:28,062 iteration 395 : loss : 0.116627, loss_ce: 0.059225
2021-12-02 22:43:29,505 iteration 396 : loss : 0.118456, loss_ce: 0.041561
2021-12-02 22:43:30,979 iteration 397 : loss : 0.103179, loss_ce: 0.044881
2021-12-02 22:43:32,466 iteration 398 : loss : 0.076710, loss_ce: 0.032260
2021-12-02 22:43:33,844 iteration 399 : loss : 0.100379, loss_ce: 0.041065
2021-12-02 22:43:35,316 iteration 400 : loss : 0.076710, loss_ce: 0.031463
2021-12-02 22:43:36,843 iteration 401 : loss : 0.121697, loss_ce: 0.061010
2021-12-02 22:43:38,298 iteration 402 : loss : 0.089437, loss_ce: 0.040305
2021-12-02 22:43:39,748 iteration 403 : loss : 0.079879, loss_ce: 0.032069
2021-12-02 22:43:41,241 iteration 404 : loss : 0.095266, loss_ce: 0.044686
2021-12-02 22:43:42,764 iteration 405 : loss : 0.113311, loss_ce: 0.042140
2021-12-02 22:43:44,193 iteration 406 : loss : 0.103927, loss_ce: 0.040408
2021-12-02 22:43:45,601 iteration 407 : loss : 0.088382, loss_ce: 0.032172
2021-12-02 22:43:47,056 iteration 408 : loss : 0.116605, loss_ce: 0.044374
  6%|█▊                            | 24/400 [10:41<2:42:35, 25.94s/it]2021-12-02 22:43:48,608 iteration 409 : loss : 0.100187, loss_ce: 0.045349
2021-12-02 22:43:50,080 iteration 410 : loss : 0.105115, loss_ce: 0.042691
2021-12-02 22:43:51,523 iteration 411 : loss : 0.140959, loss_ce: 0.042241
2021-12-02 22:43:52,897 iteration 412 : loss : 0.071207, loss_ce: 0.028144
2021-12-02 22:43:54,366 iteration 413 : loss : 0.101017, loss_ce: 0.035091
2021-12-02 22:43:55,777 iteration 414 : loss : 0.117840, loss_ce: 0.054319
2021-12-02 22:43:57,156 iteration 415 : loss : 0.066346, loss_ce: 0.027492
2021-12-02 22:43:58,621 iteration 416 : loss : 0.088776, loss_ce: 0.042628
2021-12-02 22:44:00,059 iteration 417 : loss : 0.118521, loss_ce: 0.047943
2021-12-02 22:44:01,570 iteration 418 : loss : 0.105137, loss_ce: 0.048492
2021-12-02 22:44:02,985 iteration 419 : loss : 0.081161, loss_ce: 0.041771
2021-12-02 22:44:04,445 iteration 420 : loss : 0.093971, loss_ce: 0.036031
2021-12-02 22:44:05,844 iteration 421 : loss : 0.106301, loss_ce: 0.039140
2021-12-02 22:44:07,269 iteration 422 : loss : 0.128775, loss_ce: 0.052749
2021-12-02 22:44:08,701 iteration 423 : loss : 0.095636, loss_ce: 0.033836
2021-12-02 22:44:10,182 iteration 424 : loss : 0.104524, loss_ce: 0.044585
2021-12-02 22:44:10,182 Training Data Eval:
2021-12-02 22:44:17,596   Average segmentation loss on training set: 0.0759
2021-12-02 22:44:17,596 Validation Data Eval:
2021-12-02 22:44:20,169   Average segmentation loss on validation set: 0.1275
2021-12-02 22:44:22,092 Found new lowest validation loss at iteration 424! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/UNET_RUNMC/1channel_best_val_loss.pth
2021-12-02 22:44:23,539 iteration 425 : loss : 0.084141, loss_ce: 0.033481
  6%|█▉                            | 25/400 [11:17<3:01:54, 29.11s/it]2021-12-02 22:44:24,942 iteration 426 : loss : 0.088116, loss_ce: 0.031647
2021-12-02 22:44:26,370 iteration 427 : loss : 0.078917, loss_ce: 0.035339
2021-12-02 22:44:27,761 iteration 428 : loss : 0.086066, loss_ce: 0.034940
2021-12-02 22:44:29,108 iteration 429 : loss : 0.120979, loss_ce: 0.070744
2021-12-02 22:44:30,470 iteration 430 : loss : 0.112387, loss_ce: 0.042240
2021-12-02 22:44:31,897 iteration 431 : loss : 0.157823, loss_ce: 0.058874
2021-12-02 22:44:33,398 iteration 432 : loss : 0.080646, loss_ce: 0.036839
2021-12-02 22:44:34,923 iteration 433 : loss : 0.069309, loss_ce: 0.029748
2021-12-02 22:44:36,384 iteration 434 : loss : 0.075324, loss_ce: 0.032544
2021-12-02 22:44:37,796 iteration 435 : loss : 0.077350, loss_ce: 0.034452
2021-12-02 22:44:39,239 iteration 436 : loss : 0.072575, loss_ce: 0.031460
2021-12-02 22:44:40,695 iteration 437 : loss : 0.100177, loss_ce: 0.054361
2021-12-02 22:44:42,104 iteration 438 : loss : 0.111908, loss_ce: 0.038124
2021-12-02 22:44:43,576 iteration 439 : loss : 0.106382, loss_ce: 0.033067
2021-12-02 22:44:45,006 iteration 440 : loss : 0.095554, loss_ce: 0.034859
2021-12-02 22:44:46,514 iteration 441 : loss : 0.092710, loss_ce: 0.035599
2021-12-02 22:44:48,000 iteration 442 : loss : 0.102427, loss_ce: 0.050297
  6%|█▉                            | 26/400 [11:42<2:52:44, 27.71s/it]2021-12-02 22:44:49,496 iteration 443 : loss : 0.126132, loss_ce: 0.064095
2021-12-02 22:44:50,900 iteration 444 : loss : 0.097566, loss_ce: 0.043128
2021-12-02 22:44:52,337 iteration 445 : loss : 0.127935, loss_ce: 0.044001
2021-12-02 22:44:53,905 iteration 446 : loss : 0.166598, loss_ce: 0.073475
2021-12-02 22:44:55,418 iteration 447 : loss : 0.112216, loss_ce: 0.062191
2021-12-02 22:44:56,917 iteration 448 : loss : 0.221613, loss_ce: 0.071518
2021-12-02 22:44:58,399 iteration 449 : loss : 0.105844, loss_ce: 0.050870
2021-12-02 22:44:59,841 iteration 450 : loss : 0.112028, loss_ce: 0.039690
2021-12-02 22:45:01,369 iteration 451 : loss : 0.072844, loss_ce: 0.033035
2021-12-02 22:45:02,852 iteration 452 : loss : 0.082813, loss_ce: 0.036143
2021-12-02 22:45:04,347 iteration 453 : loss : 0.103206, loss_ce: 0.042319
2021-12-02 22:45:05,833 iteration 454 : loss : 0.124141, loss_ce: 0.040546
2021-12-02 22:45:07,352 iteration 455 : loss : 0.094262, loss_ce: 0.034036
2021-12-02 22:45:08,838 iteration 456 : loss : 0.084424, loss_ce: 0.032553
2021-12-02 22:45:10,303 iteration 457 : loss : 0.119583, loss_ce: 0.048156
2021-12-02 22:45:11,833 iteration 458 : loss : 0.144904, loss_ce: 0.073792
2021-12-02 22:45:13,234 iteration 459 : loss : 0.074505, loss_ce: 0.028837
  7%|██                            | 27/400 [12:07<2:47:39, 26.97s/it]2021-12-02 22:45:14,794 iteration 460 : loss : 0.113857, loss_ce: 0.050933
2021-12-02 22:45:16,273 iteration 461 : loss : 0.090212, loss_ce: 0.037679
2021-12-02 22:45:17,722 iteration 462 : loss : 0.095422, loss_ce: 0.041553
2021-12-02 22:45:19,241 iteration 463 : loss : 0.098776, loss_ce: 0.042504
2021-12-02 22:45:20,728 iteration 464 : loss : 0.089464, loss_ce: 0.035907
2021-12-02 22:45:22,152 iteration 465 : loss : 0.101923, loss_ce: 0.033808
2021-12-02 22:45:23,622 iteration 466 : loss : 0.097267, loss_ce: 0.032412
2021-12-02 22:45:25,078 iteration 467 : loss : 0.119082, loss_ce: 0.040334
2021-12-02 22:45:26,628 iteration 468 : loss : 0.122258, loss_ce: 0.062592
2021-12-02 22:45:28,066 iteration 469 : loss : 0.067820, loss_ce: 0.026941
2021-12-02 22:45:29,511 iteration 470 : loss : 0.110046, loss_ce: 0.046288
2021-12-02 22:45:30,957 iteration 471 : loss : 0.096657, loss_ce: 0.035685
2021-12-02 22:45:32,458 iteration 472 : loss : 0.089613, loss_ce: 0.036514
2021-12-02 22:45:34,033 iteration 473 : loss : 0.100360, loss_ce: 0.043962
2021-12-02 22:45:35,557 iteration 474 : loss : 0.148291, loss_ce: 0.065863
2021-12-02 22:45:36,990 iteration 475 : loss : 0.072146, loss_ce: 0.028056
2021-12-02 22:45:38,505 iteration 476 : loss : 0.118862, loss_ce: 0.062160
  7%|██                            | 28/400 [12:32<2:44:02, 26.46s/it]2021-12-02 22:45:40,012 iteration 477 : loss : 0.092230, loss_ce: 0.029691
2021-12-02 22:45:41,507 iteration 478 : loss : 0.074446, loss_ce: 0.029264
2021-12-02 22:45:42,950 iteration 479 : loss : 0.096996, loss_ce: 0.038601
2021-12-02 22:45:44,428 iteration 480 : loss : 0.102083, loss_ce: 0.047529
2021-12-02 22:45:45,826 iteration 481 : loss : 0.126385, loss_ce: 0.052677
2021-12-02 22:45:47,321 iteration 482 : loss : 0.119271, loss_ce: 0.033021
2021-12-02 22:45:48,803 iteration 483 : loss : 0.107795, loss_ce: 0.036993
2021-12-02 22:45:50,305 iteration 484 : loss : 0.103536, loss_ce: 0.044253
2021-12-02 22:45:51,746 iteration 485 : loss : 0.065719, loss_ce: 0.031753
2021-12-02 22:45:53,186 iteration 486 : loss : 0.111476, loss_ce: 0.040499
2021-12-02 22:45:54,696 iteration 487 : loss : 0.066383, loss_ce: 0.031211
2021-12-02 22:45:56,105 iteration 488 : loss : 0.089185, loss_ce: 0.037225
2021-12-02 22:45:57,581 iteration 489 : loss : 0.121450, loss_ce: 0.059645
2021-12-02 22:45:58,969 iteration 490 : loss : 0.070651, loss_ce: 0.025817
2021-12-02 22:46:00,450 iteration 491 : loss : 0.079581, loss_ce: 0.038048
2021-12-02 22:46:01,911 iteration 492 : loss : 0.051313, loss_ce: 0.025956
2021-12-02 22:46:03,386 iteration 493 : loss : 0.096310, loss_ce: 0.042118
  7%|██▏                           | 29/400 [12:57<2:40:40, 25.99s/it]2021-12-02 22:46:04,892 iteration 494 : loss : 0.075687, loss_ce: 0.034656
2021-12-02 22:46:06,390 iteration 495 : loss : 0.078983, loss_ce: 0.026342
2021-12-02 22:46:07,846 iteration 496 : loss : 0.117470, loss_ce: 0.058141
2021-12-02 22:46:09,338 iteration 497 : loss : 0.108146, loss_ce: 0.050578
2021-12-02 22:46:10,847 iteration 498 : loss : 0.103338, loss_ce: 0.051183
2021-12-02 22:46:12,245 iteration 499 : loss : 0.074212, loss_ce: 0.032860
2021-12-02 22:46:13,674 iteration 500 : loss : 0.081499, loss_ce: 0.032457
2021-12-02 22:46:15,100 iteration 501 : loss : 0.092041, loss_ce: 0.043128
2021-12-02 22:46:16,612 iteration 502 : loss : 0.075919, loss_ce: 0.034179
2021-12-02 22:46:18,054 iteration 503 : loss : 0.113369, loss_ce: 0.042263
2021-12-02 22:46:19,538 iteration 504 : loss : 0.076759, loss_ce: 0.026892
2021-12-02 22:46:20,960 iteration 505 : loss : 0.069105, loss_ce: 0.029220
2021-12-02 22:46:22,506 iteration 506 : loss : 0.069691, loss_ce: 0.028315
2021-12-02 22:46:23,961 iteration 507 : loss : 0.105568, loss_ce: 0.035209
2021-12-02 22:46:25,438 iteration 508 : loss : 0.081662, loss_ce: 0.034798
2021-12-02 22:46:26,936 iteration 509 : loss : 0.068140, loss_ce: 0.026937
2021-12-02 22:46:26,936 Training Data Eval:
2021-12-02 22:46:34,305   Average segmentation loss on training set: 0.0690
2021-12-02 22:46:34,305 Validation Data Eval:
2021-12-02 22:46:36,860   Average segmentation loss on validation set: 0.1641
2021-12-02 22:46:38,403 iteration 510 : loss : 0.076086, loss_ce: 0.030031
  8%|██▎                           | 30/400 [13:32<2:56:56, 28.69s/it]2021-12-02 22:46:39,953 iteration 511 : loss : 0.093063, loss_ce: 0.041103
2021-12-02 22:46:41,364 iteration 512 : loss : 0.087136, loss_ce: 0.037260
2021-12-02 22:46:42,793 iteration 513 : loss : 0.055964, loss_ce: 0.019646
2021-12-02 22:46:44,267 iteration 514 : loss : 0.082020, loss_ce: 0.033018
2021-12-02 22:46:45,732 iteration 515 : loss : 0.095240, loss_ce: 0.042807
2021-12-02 22:46:47,211 iteration 516 : loss : 0.066432, loss_ce: 0.023107
2021-12-02 22:46:48,719 iteration 517 : loss : 0.103080, loss_ce: 0.052723
2021-12-02 22:46:50,135 iteration 518 : loss : 0.081317, loss_ce: 0.030802
2021-12-02 22:46:51,606 iteration 519 : loss : 0.078549, loss_ce: 0.035342
2021-12-02 22:46:53,031 iteration 520 : loss : 0.072121, loss_ce: 0.031762
2021-12-02 22:46:54,494 iteration 521 : loss : 0.079195, loss_ce: 0.027660
2021-12-02 22:46:55,986 iteration 522 : loss : 0.092086, loss_ce: 0.033516
2021-12-02 22:46:57,505 iteration 523 : loss : 0.099655, loss_ce: 0.044808
2021-12-02 22:46:59,058 iteration 524 : loss : 0.090906, loss_ce: 0.040102
2021-12-02 22:47:00,521 iteration 525 : loss : 0.112142, loss_ce: 0.054227
2021-12-02 22:47:01,971 iteration 526 : loss : 0.094845, loss_ce: 0.040923
2021-12-02 22:47:03,431 iteration 527 : loss : 0.074200, loss_ce: 0.024898
  8%|██▎                           | 31/400 [13:57<2:49:42, 27.59s/it]2021-12-02 22:47:04,929 iteration 528 : loss : 0.073212, loss_ce: 0.035131
2021-12-02 22:47:06,412 iteration 529 : loss : 0.090076, loss_ce: 0.032247
2021-12-02 22:47:07,845 iteration 530 : loss : 0.104607, loss_ce: 0.036259
2021-12-02 22:47:09,255 iteration 531 : loss : 0.104477, loss_ce: 0.030330
2021-12-02 22:47:10,677 iteration 532 : loss : 0.088850, loss_ce: 0.038679
2021-12-02 22:47:12,217 iteration 533 : loss : 0.048580, loss_ce: 0.019127
2021-12-02 22:47:13,637 iteration 534 : loss : 0.071192, loss_ce: 0.034904
2021-12-02 22:47:15,150 iteration 535 : loss : 0.072646, loss_ce: 0.029768
2021-12-02 22:47:16,677 iteration 536 : loss : 0.083609, loss_ce: 0.039055
2021-12-02 22:47:18,220 iteration 537 : loss : 0.092294, loss_ce: 0.033811
2021-12-02 22:47:19,700 iteration 538 : loss : 0.086580, loss_ce: 0.043285
2021-12-02 22:47:21,143 iteration 539 : loss : 0.074418, loss_ce: 0.029894
2021-12-02 22:47:22,617 iteration 540 : loss : 0.092177, loss_ce: 0.033011
2021-12-02 22:47:24,066 iteration 541 : loss : 0.070014, loss_ce: 0.033734
2021-12-02 22:47:25,556 iteration 542 : loss : 0.069262, loss_ce: 0.030809
2021-12-02 22:47:26,961 iteration 543 : loss : 0.049983, loss_ce: 0.021699
2021-12-02 22:47:28,396 iteration 544 : loss : 0.068543, loss_ce: 0.024082
  8%|██▍                           | 32/400 [14:22<2:44:24, 26.81s/it]2021-12-02 22:47:29,931 iteration 545 : loss : 0.079656, loss_ce: 0.041465
2021-12-02 22:47:31,388 iteration 546 : loss : 0.091507, loss_ce: 0.034874
2021-12-02 22:47:32,840 iteration 547 : loss : 0.075281, loss_ce: 0.035427
2021-12-02 22:47:34,296 iteration 548 : loss : 0.100541, loss_ce: 0.037921
2021-12-02 22:47:35,787 iteration 549 : loss : 0.072954, loss_ce: 0.032760
2021-12-02 22:47:37,213 iteration 550 : loss : 0.072339, loss_ce: 0.024757
2021-12-02 22:47:38,665 iteration 551 : loss : 0.086193, loss_ce: 0.034293
2021-12-02 22:47:40,095 iteration 552 : loss : 0.065104, loss_ce: 0.025533
2021-12-02 22:47:41,590 iteration 553 : loss : 0.083620, loss_ce: 0.037233
2021-12-02 22:47:42,995 iteration 554 : loss : 0.061507, loss_ce: 0.028799
2021-12-02 22:47:44,463 iteration 555 : loss : 0.105826, loss_ce: 0.031284
2021-12-02 22:47:45,974 iteration 556 : loss : 0.074469, loss_ce: 0.035574
2021-12-02 22:47:47,391 iteration 557 : loss : 0.069894, loss_ce: 0.026854
2021-12-02 22:47:48,903 iteration 558 : loss : 0.080954, loss_ce: 0.026383
2021-12-02 22:47:50,364 iteration 559 : loss : 0.084376, loss_ce: 0.034527
2021-12-02 22:47:51,852 iteration 560 : loss : 0.105512, loss_ce: 0.028681
2021-12-02 22:47:53,350 iteration 561 : loss : 0.136885, loss_ce: 0.072565
  8%|██▍                           | 33/400 [14:47<2:40:34, 26.25s/it]2021-12-02 22:47:54,964 iteration 562 : loss : 0.109242, loss_ce: 0.049426
2021-12-02 22:47:56,337 iteration 563 : loss : 0.087871, loss_ce: 0.039654
2021-12-02 22:47:57,821 iteration 564 : loss : 0.068537, loss_ce: 0.037901
2021-12-02 22:47:59,303 iteration 565 : loss : 0.089563, loss_ce: 0.041318
2021-12-02 22:48:00,811 iteration 566 : loss : 0.069946, loss_ce: 0.030838
2021-12-02 22:48:02,249 iteration 567 : loss : 0.078171, loss_ce: 0.026091
2021-12-02 22:48:03,687 iteration 568 : loss : 0.125947, loss_ce: 0.050919
2021-12-02 22:48:05,140 iteration 569 : loss : 0.087506, loss_ce: 0.036200
2021-12-02 22:48:06,623 iteration 570 : loss : 0.081514, loss_ce: 0.037536
2021-12-02 22:48:08,061 iteration 571 : loss : 0.114053, loss_ce: 0.042402
2021-12-02 22:48:09,557 iteration 572 : loss : 0.081506, loss_ce: 0.030781
2021-12-02 22:48:10,998 iteration 573 : loss : 0.081467, loss_ce: 0.034181
2021-12-02 22:48:12,462 iteration 574 : loss : 0.085725, loss_ce: 0.027207
2021-12-02 22:48:13,987 iteration 575 : loss : 0.086692, loss_ce: 0.028194
2021-12-02 22:48:15,486 iteration 576 : loss : 0.086611, loss_ce: 0.032451
2021-12-02 22:48:16,941 iteration 577 : loss : 0.065051, loss_ce: 0.035638
2021-12-02 22:48:18,362 iteration 578 : loss : 0.068930, loss_ce: 0.031265
  8%|██▌                           | 34/400 [15:12<2:37:51, 25.88s/it]2021-12-02 22:48:20,022 iteration 579 : loss : 0.080204, loss_ce: 0.041036
2021-12-02 22:48:21,492 iteration 580 : loss : 0.083642, loss_ce: 0.033963
2021-12-02 22:48:23,004 iteration 581 : loss : 0.097959, loss_ce: 0.030130
2021-12-02 22:48:24,456 iteration 582 : loss : 0.096024, loss_ce: 0.036695
2021-12-02 22:48:25,927 iteration 583 : loss : 0.093777, loss_ce: 0.023287
2021-12-02 22:48:27,361 iteration 584 : loss : 0.062580, loss_ce: 0.026015
2021-12-02 22:48:28,867 iteration 585 : loss : 0.068289, loss_ce: 0.028386
2021-12-02 22:48:30,276 iteration 586 : loss : 0.106652, loss_ce: 0.044626
2021-12-02 22:48:31,689 iteration 587 : loss : 0.068706, loss_ce: 0.030890
2021-12-02 22:48:33,181 iteration 588 : loss : 0.110649, loss_ce: 0.041297
2021-12-02 22:48:34,647 iteration 589 : loss : 0.093641, loss_ce: 0.037327
2021-12-02 22:48:36,124 iteration 590 : loss : 0.083247, loss_ce: 0.028063
2021-12-02 22:48:37,597 iteration 591 : loss : 0.080087, loss_ce: 0.032531
2021-12-02 22:48:39,061 iteration 592 : loss : 0.075146, loss_ce: 0.030603
2021-12-02 22:48:40,550 iteration 593 : loss : 0.066602, loss_ce: 0.026937
2021-12-02 22:48:42,029 iteration 594 : loss : 0.084774, loss_ce: 0.038759
2021-12-02 22:48:42,029 Training Data Eval:
2021-12-02 22:48:49,397   Average segmentation loss on training set: 0.0896
2021-12-02 22:48:49,398 Validation Data Eval:
2021-12-02 22:48:51,973   Average segmentation loss on validation set: 0.1342
2021-12-02 22:48:53,498 iteration 595 : loss : 0.098152, loss_ce: 0.050286
  9%|██▋                           | 35/400 [15:47<2:54:19, 28.66s/it]2021-12-02 22:48:55,010 iteration 596 : loss : 0.081469, loss_ce: 0.031223
2021-12-02 22:48:56,456 iteration 597 : loss : 0.106377, loss_ce: 0.034636
2021-12-02 22:48:57,894 iteration 598 : loss : 0.056188, loss_ce: 0.019455
2021-12-02 22:48:59,353 iteration 599 : loss : 0.077755, loss_ce: 0.033714
2021-12-02 22:49:00,794 iteration 600 : loss : 0.084691, loss_ce: 0.043787
2021-12-02 22:49:02,261 iteration 601 : loss : 0.071879, loss_ce: 0.031912
2021-12-02 22:49:03,765 iteration 602 : loss : 0.066302, loss_ce: 0.028504
2021-12-02 22:49:05,190 iteration 603 : loss : 0.071717, loss_ce: 0.024843
2021-12-02 22:49:06,618 iteration 604 : loss : 0.058525, loss_ce: 0.020467
2021-12-02 22:49:08,044 iteration 605 : loss : 0.072752, loss_ce: 0.026217
2021-12-02 22:49:09,626 iteration 606 : loss : 0.085807, loss_ce: 0.038472
2021-12-02 22:49:11,091 iteration 607 : loss : 0.074437, loss_ce: 0.030922
2021-12-02 22:49:12,557 iteration 608 : loss : 0.077005, loss_ce: 0.037332
2021-12-02 22:49:13,957 iteration 609 : loss : 0.054668, loss_ce: 0.022423
2021-12-02 22:49:15,473 iteration 610 : loss : 0.063648, loss_ce: 0.028540
2021-12-02 22:49:17,028 iteration 611 : loss : 0.070896, loss_ce: 0.033484
2021-12-02 22:49:18,498 iteration 612 : loss : 0.090220, loss_ce: 0.029903
  9%|██▋                           | 36/400 [16:12<2:47:12, 27.56s/it]2021-12-02 22:49:20,027 iteration 613 : loss : 0.072797, loss_ce: 0.031371
2021-12-02 22:49:21,451 iteration 614 : loss : 0.074104, loss_ce: 0.027152
2021-12-02 22:49:22,871 iteration 615 : loss : 0.099679, loss_ce: 0.043266
2021-12-02 22:49:24,403 iteration 616 : loss : 0.083858, loss_ce: 0.039432
2021-12-02 22:49:25,827 iteration 617 : loss : 0.082849, loss_ce: 0.038679
2021-12-02 22:49:27,312 iteration 618 : loss : 0.161750, loss_ce: 0.043681
2021-12-02 22:49:28,776 iteration 619 : loss : 0.176868, loss_ce: 0.078599
2021-12-02 22:49:30,325 iteration 620 : loss : 0.146074, loss_ce: 0.046228
2021-12-02 22:49:31,789 iteration 621 : loss : 0.059142, loss_ce: 0.021825
2021-12-02 22:49:33,363 iteration 622 : loss : 0.075250, loss_ce: 0.029584
2021-12-02 22:49:34,905 iteration 623 : loss : 0.131025, loss_ce: 0.075006
2021-12-02 22:49:36,350 iteration 624 : loss : 0.087617, loss_ce: 0.030286
2021-12-02 22:49:37,762 iteration 625 : loss : 0.077081, loss_ce: 0.034191
2021-12-02 22:49:39,260 iteration 626 : loss : 0.081836, loss_ce: 0.036347
2021-12-02 22:49:40,758 iteration 627 : loss : 0.095741, loss_ce: 0.034075
2021-12-02 22:49:42,312 iteration 628 : loss : 0.087583, loss_ce: 0.033561
2021-12-02 22:49:43,770 iteration 629 : loss : 0.082285, loss_ce: 0.035362
  9%|██▊                           | 37/400 [16:37<2:42:34, 26.87s/it]2021-12-02 22:49:45,326 iteration 630 : loss : 0.068536, loss_ce: 0.031994
2021-12-02 22:49:46,777 iteration 631 : loss : 0.045103, loss_ce: 0.020685
2021-12-02 22:49:48,215 iteration 632 : loss : 0.094062, loss_ce: 0.037080
2021-12-02 22:49:49,735 iteration 633 : loss : 0.074569, loss_ce: 0.029779
2021-12-02 22:49:51,181 iteration 634 : loss : 0.107756, loss_ce: 0.038956
2021-12-02 22:49:52,731 iteration 635 : loss : 0.075808, loss_ce: 0.032747
2021-12-02 22:49:54,220 iteration 636 : loss : 0.069689, loss_ce: 0.027999
2021-12-02 22:49:55,625 iteration 637 : loss : 0.086366, loss_ce: 0.036268
2021-12-02 22:49:57,167 iteration 638 : loss : 0.108745, loss_ce: 0.034261
2021-12-02 22:49:58,611 iteration 639 : loss : 0.063802, loss_ce: 0.031057
2021-12-02 22:50:00,028 iteration 640 : loss : 0.109564, loss_ce: 0.033153
2021-12-02 22:50:01,443 iteration 641 : loss : 0.080677, loss_ce: 0.032662
2021-12-02 22:50:02,874 iteration 642 : loss : 0.094964, loss_ce: 0.030047
2021-12-02 22:50:04,366 iteration 643 : loss : 0.081497, loss_ce: 0.035826
2021-12-02 22:50:05,835 iteration 644 : loss : 0.077843, loss_ce: 0.033661
2021-12-02 22:50:07,271 iteration 645 : loss : 0.070166, loss_ce: 0.021545
2021-12-02 22:50:08,802 iteration 646 : loss : 0.078439, loss_ce: 0.035784
 10%|██▊                           | 38/400 [17:02<2:38:47, 26.32s/it]2021-12-02 22:50:10,289 iteration 647 : loss : 0.097731, loss_ce: 0.038830
2021-12-02 22:50:11,760 iteration 648 : loss : 0.068407, loss_ce: 0.028737
2021-12-02 22:50:13,250 iteration 649 : loss : 0.084568, loss_ce: 0.032725
2021-12-02 22:50:14,783 iteration 650 : loss : 0.102553, loss_ce: 0.036933
2021-12-02 22:50:16,253 iteration 651 : loss : 0.056746, loss_ce: 0.023474
2021-12-02 22:50:17,616 iteration 652 : loss : 0.051015, loss_ce: 0.019640
2021-12-02 22:50:19,134 iteration 653 : loss : 0.100896, loss_ce: 0.033524
2021-12-02 22:50:20,554 iteration 654 : loss : 0.073101, loss_ce: 0.027214
2021-12-02 22:50:22,029 iteration 655 : loss : 0.076085, loss_ce: 0.027797
2021-12-02 22:50:23,500 iteration 656 : loss : 0.078376, loss_ce: 0.028952
2021-12-02 22:50:25,033 iteration 657 : loss : 0.054045, loss_ce: 0.021971
2021-12-02 22:50:26,519 iteration 658 : loss : 0.076734, loss_ce: 0.025252
2021-12-02 22:50:28,019 iteration 659 : loss : 0.080282, loss_ce: 0.031076
2021-12-02 22:50:29,461 iteration 660 : loss : 0.059100, loss_ce: 0.028370
2021-12-02 22:50:30,948 iteration 661 : loss : 0.084757, loss_ce: 0.036603
2021-12-02 22:50:32,498 iteration 662 : loss : 0.105644, loss_ce: 0.024502
2021-12-02 22:50:33,960 iteration 663 : loss : 0.079638, loss_ce: 0.031297
 10%|██▉                           | 39/400 [17:28<2:36:14, 25.97s/it]2021-12-02 22:50:35,494 iteration 664 : loss : 0.064929, loss_ce: 0.026800
2021-12-02 22:50:36,886 iteration 665 : loss : 0.066224, loss_ce: 0.030156
2021-12-02 22:50:38,351 iteration 666 : loss : 0.053638, loss_ce: 0.017798
2021-12-02 22:50:39,847 iteration 667 : loss : 0.065411, loss_ce: 0.028414
2021-12-02 22:50:41,318 iteration 668 : loss : 0.084992, loss_ce: 0.039789
2021-12-02 22:50:42,758 iteration 669 : loss : 0.057916, loss_ce: 0.022947
2021-12-02 22:50:44,336 iteration 670 : loss : 0.081707, loss_ce: 0.032659
2021-12-02 22:50:45,768 iteration 671 : loss : 0.090303, loss_ce: 0.035858
2021-12-02 22:50:47,284 iteration 672 : loss : 0.055957, loss_ce: 0.022977
2021-12-02 22:50:48,776 iteration 673 : loss : 0.086431, loss_ce: 0.036570
2021-12-02 22:50:50,279 iteration 674 : loss : 0.072460, loss_ce: 0.040885
2021-12-02 22:50:51,793 iteration 675 : loss : 0.099960, loss_ce: 0.040770
2021-12-02 22:50:53,234 iteration 676 : loss : 0.088345, loss_ce: 0.035847
2021-12-02 22:50:54,706 iteration 677 : loss : 0.048941, loss_ce: 0.023409
2021-12-02 22:50:56,210 iteration 678 : loss : 0.084131, loss_ce: 0.034540
2021-12-02 22:50:57,682 iteration 679 : loss : 0.086217, loss_ce: 0.037448
2021-12-02 22:50:57,682 Training Data Eval:
2021-12-02 22:51:05,019   Average segmentation loss on training set: 0.0745
2021-12-02 22:51:05,019 Validation Data Eval:
2021-12-02 22:51:07,585   Average segmentation loss on validation set: 0.1415
2021-12-02 22:51:09,080 iteration 680 : loss : 0.097602, loss_ce: 0.037114
 10%|███                           | 40/400 [18:03<2:52:18, 28.72s/it]2021-12-02 22:51:10,627 iteration 681 : loss : 0.054204, loss_ce: 0.020340
2021-12-02 22:51:12,033 iteration 682 : loss : 0.112679, loss_ce: 0.033639
2021-12-02 22:51:13,517 iteration 683 : loss : 0.079556, loss_ce: 0.035232
2021-12-02 22:51:14,959 iteration 684 : loss : 0.069134, loss_ce: 0.024614
2021-12-02 22:51:16,496 iteration 685 : loss : 0.064943, loss_ce: 0.025541
2021-12-02 22:51:17,978 iteration 686 : loss : 0.088338, loss_ce: 0.037247
2021-12-02 22:51:19,440 iteration 687 : loss : 0.065943, loss_ce: 0.029733
2021-12-02 22:51:20,879 iteration 688 : loss : 0.078842, loss_ce: 0.025312
2021-12-02 22:51:22,380 iteration 689 : loss : 0.060693, loss_ce: 0.021144
2021-12-02 22:51:23,896 iteration 690 : loss : 0.073601, loss_ce: 0.023497
2021-12-02 22:51:25,366 iteration 691 : loss : 0.098576, loss_ce: 0.033261
2021-12-02 22:51:26,880 iteration 692 : loss : 0.065088, loss_ce: 0.023909
2021-12-02 22:51:28,285 iteration 693 : loss : 0.107043, loss_ce: 0.049552
2021-12-02 22:51:29,766 iteration 694 : loss : 0.073341, loss_ce: 0.030585
2021-12-02 22:51:31,209 iteration 695 : loss : 0.068619, loss_ce: 0.026343
2021-12-02 22:51:32,733 iteration 696 : loss : 0.050102, loss_ce: 0.021496
2021-12-02 22:51:34,188 iteration 697 : loss : 0.064004, loss_ce: 0.024677
 10%|███                           | 41/400 [18:28<2:45:21, 27.64s/it]2021-12-02 22:51:35,667 iteration 698 : loss : 0.075535, loss_ce: 0.026227
2021-12-02 22:51:37,170 iteration 699 : loss : 0.073423, loss_ce: 0.033450
2021-12-02 22:51:38,611 iteration 700 : loss : 0.082065, loss_ce: 0.038068
2021-12-02 22:51:40,056 iteration 701 : loss : 0.082937, loss_ce: 0.041956
2021-12-02 22:51:41,556 iteration 702 : loss : 0.097799, loss_ce: 0.036696
2021-12-02 22:51:43,099 iteration 703 : loss : 0.047380, loss_ce: 0.022398
2021-12-02 22:51:44,514 iteration 704 : loss : 0.047133, loss_ce: 0.020224
2021-12-02 22:51:45,972 iteration 705 : loss : 0.081708, loss_ce: 0.032222
2021-12-02 22:51:47,443 iteration 706 : loss : 0.069604, loss_ce: 0.026602
2021-12-02 22:51:48,866 iteration 707 : loss : 0.046056, loss_ce: 0.019334
2021-12-02 22:51:50,343 iteration 708 : loss : 0.046112, loss_ce: 0.017519
2021-12-02 22:51:51,811 iteration 709 : loss : 0.085685, loss_ce: 0.035074
2021-12-02 22:51:53,303 iteration 710 : loss : 0.066101, loss_ce: 0.024942
2021-12-02 22:51:54,780 iteration 711 : loss : 0.075513, loss_ce: 0.031643
2021-12-02 22:51:56,324 iteration 712 : loss : 0.077344, loss_ce: 0.028183
2021-12-02 22:51:57,777 iteration 713 : loss : 0.059339, loss_ce: 0.025714
2021-12-02 22:51:59,303 iteration 714 : loss : 0.077603, loss_ce: 0.027124
 10%|███▏                          | 42/400 [18:53<2:40:23, 26.88s/it]2021-12-02 22:52:00,864 iteration 715 : loss : 0.061119, loss_ce: 0.024018
2021-12-02 22:52:02,364 iteration 716 : loss : 0.082069, loss_ce: 0.038597
2021-12-02 22:52:03,831 iteration 717 : loss : 0.073264, loss_ce: 0.027972
2021-12-02 22:52:05,317 iteration 718 : loss : 0.082389, loss_ce: 0.039846
2021-12-02 22:52:06,849 iteration 719 : loss : 0.075600, loss_ce: 0.026558
2021-12-02 22:52:08,312 iteration 720 : loss : 0.078868, loss_ce: 0.027722
2021-12-02 22:52:09,767 iteration 721 : loss : 0.071887, loss_ce: 0.028604
2021-12-02 22:52:11,214 iteration 722 : loss : 0.077494, loss_ce: 0.024114
2021-12-02 22:52:12,709 iteration 723 : loss : 0.088911, loss_ce: 0.047516
2021-12-02 22:52:14,149 iteration 724 : loss : 0.091199, loss_ce: 0.038318
2021-12-02 22:52:15,672 iteration 725 : loss : 0.081103, loss_ce: 0.028263
2021-12-02 22:52:17,142 iteration 726 : loss : 0.070391, loss_ce: 0.028420
2021-12-02 22:52:18,557 iteration 727 : loss : 0.054422, loss_ce: 0.021116
2021-12-02 22:52:20,058 iteration 728 : loss : 0.093386, loss_ce: 0.034204
2021-12-02 22:52:21,569 iteration 729 : loss : 0.075424, loss_ce: 0.030723
2021-12-02 22:52:23,050 iteration 730 : loss : 0.063166, loss_ce: 0.025320
2021-12-02 22:52:24,445 iteration 731 : loss : 0.056619, loss_ce: 0.023151
 11%|███▏                          | 43/400 [19:18<2:36:49, 26.36s/it]2021-12-02 22:52:25,920 iteration 732 : loss : 0.056620, loss_ce: 0.026936
2021-12-02 22:52:27,326 iteration 733 : loss : 0.069712, loss_ce: 0.033928
2021-12-02 22:52:28,838 iteration 734 : loss : 0.064035, loss_ce: 0.024690
2021-12-02 22:52:30,309 iteration 735 : loss : 0.082139, loss_ce: 0.028131
2021-12-02 22:52:31,779 iteration 736 : loss : 0.062663, loss_ce: 0.027392
2021-12-02 22:52:33,375 iteration 737 : loss : 0.056826, loss_ce: 0.027473
2021-12-02 22:52:34,766 iteration 738 : loss : 0.080693, loss_ce: 0.035547
2021-12-02 22:52:36,260 iteration 739 : loss : 0.065729, loss_ce: 0.026066
2021-12-02 22:52:37,731 iteration 740 : loss : 0.053685, loss_ce: 0.022915
2021-12-02 22:52:39,190 iteration 741 : loss : 0.059404, loss_ce: 0.022574
2021-12-02 22:52:40,596 iteration 742 : loss : 0.064479, loss_ce: 0.028643
2021-12-02 22:52:42,074 iteration 743 : loss : 0.066359, loss_ce: 0.026803
2021-12-02 22:52:43,580 iteration 744 : loss : 0.065369, loss_ce: 0.027895
2021-12-02 22:52:44,996 iteration 745 : loss : 0.126394, loss_ce: 0.027888
2021-12-02 22:52:46,433 iteration 746 : loss : 0.049339, loss_ce: 0.017130
2021-12-02 22:52:47,868 iteration 747 : loss : 0.057851, loss_ce: 0.024464
2021-12-02 22:52:49,292 iteration 748 : loss : 0.046586, loss_ce: 0.019443
 11%|███▎                          | 44/400 [19:43<2:33:42, 25.91s/it]2021-12-02 22:52:50,755 iteration 749 : loss : 0.148582, loss_ce: 0.026286
2021-12-02 22:52:52,191 iteration 750 : loss : 0.067212, loss_ce: 0.024774
2021-12-02 22:52:53,684 iteration 751 : loss : 0.075750, loss_ce: 0.023333
2021-12-02 22:52:55,146 iteration 752 : loss : 0.120827, loss_ce: 0.046974
2021-12-02 22:52:56,573 iteration 753 : loss : 0.084571, loss_ce: 0.034732
2021-12-02 22:52:58,022 iteration 754 : loss : 0.074920, loss_ce: 0.030617
2021-12-02 22:52:59,416 iteration 755 : loss : 0.073623, loss_ce: 0.038055
2021-12-02 22:53:00,808 iteration 756 : loss : 0.051915, loss_ce: 0.017644
2021-12-02 22:53:02,263 iteration 757 : loss : 0.099508, loss_ce: 0.047258
2021-12-02 22:53:03,818 iteration 758 : loss : 0.105714, loss_ce: 0.046714
2021-12-02 22:53:05,406 iteration 759 : loss : 0.107355, loss_ce: 0.039162
2021-12-02 22:53:06,856 iteration 760 : loss : 0.083822, loss_ce: 0.038928
2021-12-02 22:53:08,348 iteration 761 : loss : 0.062411, loss_ce: 0.028865
2021-12-02 22:53:09,854 iteration 762 : loss : 0.085951, loss_ce: 0.033016
2021-12-02 22:53:11,410 iteration 763 : loss : 0.084587, loss_ce: 0.033802
2021-12-02 22:53:12,880 iteration 764 : loss : 0.073282, loss_ce: 0.033466
2021-12-02 22:53:12,880 Training Data Eval:
2021-12-02 22:53:20,284   Average segmentation loss on training set: 0.3385
2021-12-02 22:53:20,285 Validation Data Eval:
2021-12-02 22:53:22,845   Average segmentation loss on validation set: 0.3619
2021-12-02 22:53:24,521 iteration 765 : loss : 0.081488, loss_ce: 0.034658
 11%|███▍                          | 45/400 [20:18<2:49:49, 28.70s/it]2021-12-02 22:53:26,110 iteration 766 : loss : 0.109708, loss_ce: 0.038609
2021-12-02 22:53:27,661 iteration 767 : loss : 0.102630, loss_ce: 0.035473
2021-12-02 22:53:29,186 iteration 768 : loss : 0.101789, loss_ce: 0.035733
2021-12-02 22:53:30,738 iteration 769 : loss : 0.067954, loss_ce: 0.029386
2021-12-02 22:53:32,134 iteration 770 : loss : 0.065073, loss_ce: 0.025876
2021-12-02 22:53:33,627 iteration 771 : loss : 0.088526, loss_ce: 0.024020
2021-12-02 22:53:35,113 iteration 772 : loss : 0.047621, loss_ce: 0.017217
2021-12-02 22:53:36,618 iteration 773 : loss : 0.093013, loss_ce: 0.022007
2021-12-02 22:53:38,256 iteration 774 : loss : 0.074482, loss_ce: 0.030492
2021-12-02 22:53:39,715 iteration 775 : loss : 0.096586, loss_ce: 0.056248
2021-12-02 22:53:41,161 iteration 776 : loss : 0.069101, loss_ce: 0.024153
2021-12-02 22:53:42,883 iteration 777 : loss : 0.103139, loss_ce: 0.056061
2021-12-02 22:53:44,304 iteration 778 : loss : 0.124735, loss_ce: 0.039562
2021-12-02 22:53:45,878 iteration 779 : loss : 0.087223, loss_ce: 0.037234
2021-12-02 22:53:47,454 iteration 780 : loss : 0.088061, loss_ce: 0.029125
2021-12-02 22:53:48,916 iteration 781 : loss : 0.111962, loss_ce: 0.065398
2021-12-02 22:53:50,324 iteration 782 : loss : 0.060878, loss_ce: 0.031441
 12%|███▍                          | 46/400 [20:44<2:44:13, 27.83s/it]2021-12-02 22:53:51,878 iteration 783 : loss : 0.067653, loss_ce: 0.034962
2021-12-02 22:53:53,357 iteration 784 : loss : 0.091830, loss_ce: 0.033401
2021-12-02 22:53:54,884 iteration 785 : loss : 0.074704, loss_ce: 0.033296
2021-12-02 22:53:56,360 iteration 786 : loss : 0.074234, loss_ce: 0.029483
2021-12-02 22:53:57,846 iteration 787 : loss : 0.063122, loss_ce: 0.020793
2021-12-02 22:53:59,423 iteration 788 : loss : 0.080689, loss_ce: 0.038699
2021-12-02 22:54:00,831 iteration 789 : loss : 0.086397, loss_ce: 0.028537
2021-12-02 22:54:02,388 iteration 790 : loss : 0.074800, loss_ce: 0.026186
2021-12-02 22:54:03,871 iteration 791 : loss : 0.050184, loss_ce: 0.020063
2021-12-02 22:54:05,306 iteration 792 : loss : 0.056542, loss_ce: 0.024229
2021-12-02 22:54:06,872 iteration 793 : loss : 0.084056, loss_ce: 0.040987
2021-12-02 22:54:08,279 iteration 794 : loss : 0.065621, loss_ce: 0.026512
2021-12-02 22:54:09,726 iteration 795 : loss : 0.063951, loss_ce: 0.025513
2021-12-02 22:54:11,175 iteration 796 : loss : 0.073851, loss_ce: 0.037311
2021-12-02 22:54:12,737 iteration 797 : loss : 0.079361, loss_ce: 0.030615
2021-12-02 22:54:14,219 iteration 798 : loss : 0.052225, loss_ce: 0.018993
2021-12-02 22:54:15,634 iteration 799 : loss : 0.048356, loss_ce: 0.023279
 12%|███▌                          | 47/400 [21:09<2:39:18, 27.08s/it]2021-12-02 22:54:17,319 iteration 800 : loss : 0.061008, loss_ce: 0.021111
2021-12-02 22:54:18,843 iteration 801 : loss : 0.060951, loss_ce: 0.025869
2021-12-02 22:54:20,344 iteration 802 : loss : 0.064460, loss_ce: 0.023378
2021-12-02 22:54:21,877 iteration 803 : loss : 0.081533, loss_ce: 0.042921
2021-12-02 22:54:23,484 iteration 804 : loss : 0.126589, loss_ce: 0.061279
2021-12-02 22:54:25,137 iteration 805 : loss : 0.060892, loss_ce: 0.021580
2021-12-02 22:54:26,603 iteration 806 : loss : 0.056006, loss_ce: 0.027307
2021-12-02 22:54:28,038 iteration 807 : loss : 0.059761, loss_ce: 0.024106
2021-12-02 22:54:29,589 iteration 808 : loss : 0.077122, loss_ce: 0.040045
2021-12-02 22:54:31,107 iteration 809 : loss : 0.068660, loss_ce: 0.025372
2021-12-02 22:54:32,556 iteration 810 : loss : 0.076662, loss_ce: 0.024562
2021-12-02 22:54:33,974 iteration 811 : loss : 0.077442, loss_ce: 0.043631
2021-12-02 22:54:35,441 iteration 812 : loss : 0.063307, loss_ce: 0.028490
2021-12-02 22:54:36,942 iteration 813 : loss : 0.085678, loss_ce: 0.024302
2021-12-02 22:54:38,562 iteration 814 : loss : 0.085460, loss_ce: 0.032775
2021-12-02 22:54:40,116 iteration 815 : loss : 0.094924, loss_ce: 0.042176
2021-12-02 22:54:41,616 iteration 816 : loss : 0.051303, loss_ce: 0.020117
 12%|███▌                          | 48/400 [21:35<2:36:54, 26.75s/it]2021-12-02 22:54:43,179 iteration 817 : loss : 0.061029, loss_ce: 0.026049
2021-12-02 22:54:44,624 iteration 818 : loss : 0.056069, loss_ce: 0.023270
2021-12-02 22:54:46,123 iteration 819 : loss : 0.050770, loss_ce: 0.019461
2021-12-02 22:54:47,541 iteration 820 : loss : 0.056354, loss_ce: 0.022339
2021-12-02 22:54:49,122 iteration 821 : loss : 0.068461, loss_ce: 0.025564
2021-12-02 22:54:50,658 iteration 822 : loss : 0.071641, loss_ce: 0.028289
2021-12-02 22:54:52,097 iteration 823 : loss : 0.043257, loss_ce: 0.017152
2021-12-02 22:54:53,532 iteration 824 : loss : 0.066967, loss_ce: 0.029865
2021-12-02 22:54:55,031 iteration 825 : loss : 0.059607, loss_ce: 0.023287
2021-12-02 22:54:56,519 iteration 826 : loss : 0.085747, loss_ce: 0.026435
2021-12-02 22:54:58,006 iteration 827 : loss : 0.081392, loss_ce: 0.025572
2021-12-02 22:54:59,503 iteration 828 : loss : 0.058707, loss_ce: 0.021476
2021-12-02 22:55:01,039 iteration 829 : loss : 0.069040, loss_ce: 0.025702
2021-12-02 22:55:02,596 iteration 830 : loss : 0.047599, loss_ce: 0.016550
2021-12-02 22:55:04,089 iteration 831 : loss : 0.080853, loss_ce: 0.035677
2021-12-02 22:55:05,554 iteration 832 : loss : 0.054851, loss_ce: 0.020649
2021-12-02 22:55:07,125 iteration 833 : loss : 0.084745, loss_ce: 0.044062
 12%|███▋                          | 49/400 [22:01<2:34:18, 26.38s/it]2021-12-02 22:55:08,700 iteration 834 : loss : 0.061890, loss_ce: 0.027225
2021-12-02 22:55:10,093 iteration 835 : loss : 0.054129, loss_ce: 0.016202
2021-12-02 22:55:11,607 iteration 836 : loss : 0.069886, loss_ce: 0.030204
2021-12-02 22:55:13,054 iteration 837 : loss : 0.047804, loss_ce: 0.026122
2021-12-02 22:55:14,487 iteration 838 : loss : 0.053853, loss_ce: 0.020942
2021-12-02 22:55:16,025 iteration 839 : loss : 0.052697, loss_ce: 0.020790
2021-12-02 22:55:17,523 iteration 840 : loss : 0.061415, loss_ce: 0.019997
2021-12-02 22:55:18,981 iteration 841 : loss : 0.059512, loss_ce: 0.026435
2021-12-02 22:55:20,471 iteration 842 : loss : 0.069852, loss_ce: 0.028200
2021-12-02 22:55:22,081 iteration 843 : loss : 0.081301, loss_ce: 0.030825
2021-12-02 22:55:23,570 iteration 844 : loss : 0.053915, loss_ce: 0.018789
2021-12-02 22:55:25,110 iteration 845 : loss : 0.069561, loss_ce: 0.023771
2021-12-02 22:55:26,771 iteration 846 : loss : 0.061225, loss_ce: 0.029647
2021-12-02 22:55:28,281 iteration 847 : loss : 0.048010, loss_ce: 0.020277
2021-12-02 22:55:29,668 iteration 848 : loss : 0.062609, loss_ce: 0.027550
2021-12-02 22:55:31,202 iteration 849 : loss : 0.055211, loss_ce: 0.023696
2021-12-02 22:55:31,203 Training Data Eval:
2021-12-02 22:55:38,685   Average segmentation loss on training set: 0.0578
2021-12-02 22:55:38,685 Validation Data Eval:
2021-12-02 22:55:41,274   Average segmentation loss on validation set: 0.1459
2021-12-02 22:55:42,839 iteration 850 : loss : 0.080601, loss_ce: 0.027617
 12%|███▊                          | 50/400 [22:37<2:50:12, 29.18s/it]2021-12-02 22:55:44,432 iteration 851 : loss : 0.041295, loss_ce: 0.017490
2021-12-02 22:55:45,901 iteration 852 : loss : 0.045075, loss_ce: 0.017546
2021-12-02 22:55:47,473 iteration 853 : loss : 0.071489, loss_ce: 0.029178
2021-12-02 22:55:48,983 iteration 854 : loss : 0.059478, loss_ce: 0.019018
2021-12-02 22:55:50,504 iteration 855 : loss : 0.052745, loss_ce: 0.022974
2021-12-02 22:55:52,033 iteration 856 : loss : 0.060000, loss_ce: 0.020615
2021-12-02 22:55:53,488 iteration 857 : loss : 0.053292, loss_ce: 0.023561
2021-12-02 22:55:54,904 iteration 858 : loss : 0.051760, loss_ce: 0.024282
2021-12-02 22:55:56,359 iteration 859 : loss : 0.063632, loss_ce: 0.024384
2021-12-02 22:55:57,809 iteration 860 : loss : 0.066940, loss_ce: 0.018630
2021-12-02 22:55:59,376 iteration 861 : loss : 0.055484, loss_ce: 0.023056
2021-12-02 22:56:00,779 iteration 862 : loss : 0.063606, loss_ce: 0.020317
2021-12-02 22:56:02,330 iteration 863 : loss : 0.072543, loss_ce: 0.030776
2021-12-02 22:56:03,824 iteration 864 : loss : 0.066377, loss_ce: 0.027755
2021-12-02 22:56:05,233 iteration 865 : loss : 0.046962, loss_ce: 0.019759
2021-12-02 22:56:06,812 iteration 866 : loss : 0.088791, loss_ce: 0.042215
2021-12-02 22:56:08,231 iteration 867 : loss : 0.034787, loss_ce: 0.013001
 13%|███▊                          | 51/400 [23:02<2:43:06, 28.04s/it]2021-12-02 22:56:09,843 iteration 868 : loss : 0.083163, loss_ce: 0.024318
2021-12-02 22:56:11,313 iteration 869 : loss : 0.072226, loss_ce: 0.026105
2021-12-02 22:56:12,690 iteration 870 : loss : 0.039523, loss_ce: 0.014678
2021-12-02 22:56:14,122 iteration 871 : loss : 0.053532, loss_ce: 0.020014
2021-12-02 22:56:15,575 iteration 872 : loss : 0.056135, loss_ce: 0.030205
2021-12-02 22:56:17,156 iteration 873 : loss : 0.050707, loss_ce: 0.018928
2021-12-02 22:56:18,560 iteration 874 : loss : 0.048424, loss_ce: 0.020283
2021-12-02 22:56:20,199 iteration 875 : loss : 0.079439, loss_ce: 0.030630
2021-12-02 22:56:21,677 iteration 876 : loss : 0.040338, loss_ce: 0.019675
2021-12-02 22:56:23,035 iteration 877 : loss : 0.049982, loss_ce: 0.018785
2021-12-02 22:56:24,581 iteration 878 : loss : 0.057942, loss_ce: 0.026706
2021-12-02 22:56:26,033 iteration 879 : loss : 0.048074, loss_ce: 0.020703
2021-12-02 22:56:27,563 iteration 880 : loss : 0.054911, loss_ce: 0.018154
2021-12-02 22:56:29,023 iteration 881 : loss : 0.067703, loss_ce: 0.029145
2021-12-02 22:56:30,547 iteration 882 : loss : 0.060064, loss_ce: 0.023581
2021-12-02 22:56:32,041 iteration 883 : loss : 0.066075, loss_ce: 0.028292
2021-12-02 22:56:33,640 iteration 884 : loss : 0.067618, loss_ce: 0.031842
 13%|███▉                          | 52/400 [23:27<2:38:03, 27.25s/it]2021-12-02 22:56:35,230 iteration 885 : loss : 0.073537, loss_ce: 0.025978
2021-12-02 22:56:36,752 iteration 886 : loss : 0.047940, loss_ce: 0.021268
2021-12-02 22:56:38,279 iteration 887 : loss : 0.087923, loss_ce: 0.037198
2021-12-02 22:56:39,777 iteration 888 : loss : 0.070953, loss_ce: 0.030619
2021-12-02 22:56:41,333 iteration 889 : loss : 0.071318, loss_ce: 0.025532
2021-12-02 22:56:42,945 iteration 890 : loss : 0.080470, loss_ce: 0.030180
2021-12-02 22:56:44,455 iteration 891 : loss : 0.046847, loss_ce: 0.016718
2021-12-02 22:56:45,954 iteration 892 : loss : 0.066898, loss_ce: 0.031046
2021-12-02 22:56:47,420 iteration 893 : loss : 0.051034, loss_ce: 0.018514
2021-12-02 22:56:49,039 iteration 894 : loss : 0.056167, loss_ce: 0.022249
2021-12-02 22:56:50,508 iteration 895 : loss : 0.072774, loss_ce: 0.020871
2021-12-02 22:56:52,086 iteration 896 : loss : 0.071533, loss_ce: 0.032598
2021-12-02 22:56:53,671 iteration 897 : loss : 0.073765, loss_ce: 0.034178
2021-12-02 22:56:55,135 iteration 898 : loss : 0.060548, loss_ce: 0.030729
2021-12-02 22:56:56,612 iteration 899 : loss : 0.079251, loss_ce: 0.039741
2021-12-02 22:56:58,045 iteration 900 : loss : 0.050171, loss_ce: 0.021882
2021-12-02 22:56:59,523 iteration 901 : loss : 0.063916, loss_ce: 0.020241
 13%|███▉                          | 53/400 [23:53<2:35:13, 26.84s/it]2021-12-02 22:57:01,124 iteration 902 : loss : 0.053624, loss_ce: 0.021612
2021-12-02 22:57:02,724 iteration 903 : loss : 0.046803, loss_ce: 0.018346
2021-12-02 22:57:04,259 iteration 904 : loss : 0.076986, loss_ce: 0.029412
2021-12-02 22:57:05,769 iteration 905 : loss : 0.089003, loss_ce: 0.038521
2021-12-02 22:57:07,259 iteration 906 : loss : 0.052881, loss_ce: 0.024097
2021-12-02 22:57:08,831 iteration 907 : loss : 0.070418, loss_ce: 0.027055
2021-12-02 22:57:10,215 iteration 908 : loss : 0.051939, loss_ce: 0.020516
2021-12-02 22:57:11,749 iteration 909 : loss : 0.057807, loss_ce: 0.025951
2021-12-02 22:57:13,184 iteration 910 : loss : 0.065671, loss_ce: 0.027841
2021-12-02 22:57:14,659 iteration 911 : loss : 0.046383, loss_ce: 0.017459
2021-12-02 22:57:16,140 iteration 912 : loss : 0.051667, loss_ce: 0.017749
2021-12-02 22:57:17,625 iteration 913 : loss : 0.055235, loss_ce: 0.019502
2021-12-02 22:57:19,114 iteration 914 : loss : 0.066685, loss_ce: 0.033036
2021-12-02 22:57:20,579 iteration 915 : loss : 0.085001, loss_ce: 0.025582
2021-12-02 22:57:22,045 iteration 916 : loss : 0.058426, loss_ce: 0.020561
2021-12-02 22:57:23,561 iteration 917 : loss : 0.070442, loss_ce: 0.030816
2021-12-02 22:57:25,100 iteration 918 : loss : 0.075090, loss_ce: 0.027202
 14%|████                          | 54/400 [24:19<2:32:34, 26.46s/it]2021-12-02 22:57:26,704 iteration 919 : loss : 0.048583, loss_ce: 0.021479
2021-12-02 22:57:28,226 iteration 920 : loss : 0.066145, loss_ce: 0.028305
2021-12-02 22:57:29,785 iteration 921 : loss : 0.065801, loss_ce: 0.024368
2021-12-02 22:57:31,351 iteration 922 : loss : 0.066466, loss_ce: 0.027991
2021-12-02 22:57:32,813 iteration 923 : loss : 0.057601, loss_ce: 0.026784
2021-12-02 22:57:34,363 iteration 924 : loss : 0.118493, loss_ce: 0.029881
2021-12-02 22:57:35,826 iteration 925 : loss : 0.040845, loss_ce: 0.015566
2021-12-02 22:57:37,394 iteration 926 : loss : 0.055286, loss_ce: 0.023788
2021-12-02 22:57:38,816 iteration 927 : loss : 0.070128, loss_ce: 0.025723
2021-12-02 22:57:40,324 iteration 928 : loss : 0.054254, loss_ce: 0.022247
2021-12-02 22:57:41,891 iteration 929 : loss : 0.069761, loss_ce: 0.023874
2021-12-02 22:57:43,408 iteration 930 : loss : 0.055338, loss_ce: 0.023369
2021-12-02 22:57:44,936 iteration 931 : loss : 0.099012, loss_ce: 0.026848
2021-12-02 22:57:46,448 iteration 932 : loss : 0.055756, loss_ce: 0.019680
2021-12-02 22:57:47,900 iteration 933 : loss : 0.093803, loss_ce: 0.035745
2021-12-02 22:57:49,392 iteration 934 : loss : 0.045175, loss_ce: 0.017229
2021-12-02 22:57:49,393 Training Data Eval:
2021-12-02 22:57:56,955   Average segmentation loss on training set: 0.0506
2021-12-02 22:57:56,955 Validation Data Eval:
2021-12-02 22:57:59,578   Average segmentation loss on validation set: 0.1175
2021-12-02 22:58:01,536 Found new lowest validation loss at iteration 934! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/UNET_RUNMC/1channel_best_val_loss.pth
2021-12-02 22:58:03,125 iteration 935 : loss : 0.093823, loss_ce: 0.028775
 14%|████▏                         | 55/400 [24:57<2:52:05, 29.93s/it]2021-12-02 22:58:04,622 iteration 936 : loss : 0.057163, loss_ce: 0.020072
2021-12-02 22:58:06,087 iteration 937 : loss : 0.056563, loss_ce: 0.016998
2021-12-02 22:58:07,584 iteration 938 : loss : 0.071102, loss_ce: 0.023080
2021-12-02 22:58:08,966 iteration 939 : loss : 0.056234, loss_ce: 0.017115
2021-12-02 22:58:10,444 iteration 940 : loss : 0.081213, loss_ce: 0.030065
2021-12-02 22:58:12,056 iteration 941 : loss : 0.053484, loss_ce: 0.020665
2021-12-02 22:58:13,511 iteration 942 : loss : 0.045150, loss_ce: 0.017661
2021-12-02 22:58:15,001 iteration 943 : loss : 0.063872, loss_ce: 0.030702
2021-12-02 22:58:16,481 iteration 944 : loss : 0.050106, loss_ce: 0.019812
2021-12-02 22:58:17,968 iteration 945 : loss : 0.056392, loss_ce: 0.021854
2021-12-02 22:58:19,457 iteration 946 : loss : 0.045665, loss_ce: 0.020089
2021-12-02 22:58:20,917 iteration 947 : loss : 0.053386, loss_ce: 0.019796
2021-12-02 22:58:22,395 iteration 948 : loss : 0.079072, loss_ce: 0.025349
2021-12-02 22:58:23,885 iteration 949 : loss : 0.054904, loss_ce: 0.022014
2021-12-02 22:58:25,386 iteration 950 : loss : 0.062602, loss_ce: 0.030157
2021-12-02 22:58:26,960 iteration 951 : loss : 0.052161, loss_ce: 0.025142
2021-12-02 22:58:28,418 iteration 952 : loss : 0.058688, loss_ce: 0.024331
 14%|████▏                         | 56/400 [25:22<2:43:37, 28.54s/it]2021-12-02 22:58:30,025 iteration 953 : loss : 0.057700, loss_ce: 0.020190
2021-12-02 22:58:31,593 iteration 954 : loss : 0.049043, loss_ce: 0.019607
2021-12-02 22:58:33,029 iteration 955 : loss : 0.034979, loss_ce: 0.015157
2021-12-02 22:58:34,598 iteration 956 : loss : 0.070636, loss_ce: 0.030554
2021-12-02 22:58:36,145 iteration 957 : loss : 0.056831, loss_ce: 0.021128
2021-12-02 22:58:37,687 iteration 958 : loss : 0.068962, loss_ce: 0.021578
2021-12-02 22:58:39,291 iteration 959 : loss : 0.072366, loss_ce: 0.038299
2021-12-02 22:58:40,965 iteration 960 : loss : 0.068638, loss_ce: 0.030788
2021-12-02 22:58:42,414 iteration 961 : loss : 0.078650, loss_ce: 0.024301
2021-12-02 22:58:43,844 iteration 962 : loss : 0.047421, loss_ce: 0.015117
2021-12-02 22:58:45,449 iteration 963 : loss : 0.048339, loss_ce: 0.017677
2021-12-02 22:58:46,999 iteration 964 : loss : 0.063862, loss_ce: 0.035356
2021-12-02 22:58:48,484 iteration 965 : loss : 0.052687, loss_ce: 0.024386
2021-12-02 22:58:49,998 iteration 966 : loss : 0.056496, loss_ce: 0.023615
2021-12-02 22:58:51,530 iteration 967 : loss : 0.048645, loss_ce: 0.019379
2021-12-02 22:58:53,006 iteration 968 : loss : 0.090070, loss_ce: 0.028545
2021-12-02 22:58:54,550 iteration 969 : loss : 0.047138, loss_ce: 0.020280
 14%|████▎                         | 57/400 [25:48<2:39:01, 27.82s/it]2021-12-02 22:58:56,126 iteration 970 : loss : 0.067349, loss_ce: 0.032858
2021-12-02 22:58:57,666 iteration 971 : loss : 0.052278, loss_ce: 0.015882
2021-12-02 22:58:59,113 iteration 972 : loss : 0.050614, loss_ce: 0.022854
2021-12-02 22:59:00,669 iteration 973 : loss : 0.066075, loss_ce: 0.022161
2021-12-02 22:59:02,136 iteration 974 : loss : 0.045031, loss_ce: 0.016663
2021-12-02 22:59:03,711 iteration 975 : loss : 0.068744, loss_ce: 0.022533
2021-12-02 22:59:05,190 iteration 976 : loss : 0.047078, loss_ce: 0.019044
2021-12-02 22:59:06,718 iteration 977 : loss : 0.042836, loss_ce: 0.014813
2021-12-02 22:59:08,274 iteration 978 : loss : 0.037956, loss_ce: 0.015052
2021-12-02 22:59:09,782 iteration 979 : loss : 0.081520, loss_ce: 0.041442
2021-12-02 22:59:11,280 iteration 980 : loss : 0.040431, loss_ce: 0.013535
2021-12-02 22:59:12,900 iteration 981 : loss : 0.055514, loss_ce: 0.024659
2021-12-02 22:59:14,386 iteration 982 : loss : 0.055428, loss_ce: 0.029405
2021-12-02 22:59:15,981 iteration 983 : loss : 0.091795, loss_ce: 0.026145
2021-12-02 22:59:17,430 iteration 984 : loss : 0.053312, loss_ce: 0.026596
2021-12-02 22:59:18,958 iteration 985 : loss : 0.044410, loss_ce: 0.014182
2021-12-02 22:59:20,553 iteration 986 : loss : 0.066733, loss_ce: 0.023780
 14%|████▎                         | 58/400 [26:14<2:35:28, 27.28s/it]2021-12-02 22:59:22,221 iteration 987 : loss : 0.044446, loss_ce: 0.020257
2021-12-02 22:59:23,759 iteration 988 : loss : 0.056753, loss_ce: 0.026131
2021-12-02 22:59:25,270 iteration 989 : loss : 0.047770, loss_ce: 0.019243
2021-12-02 22:59:26,794 iteration 990 : loss : 0.063334, loss_ce: 0.026276
2021-12-02 22:59:28,334 iteration 991 : loss : 0.049473, loss_ce: 0.020631
2021-12-02 22:59:29,959 iteration 992 : loss : 0.058789, loss_ce: 0.027912
2021-12-02 22:59:31,501 iteration 993 : loss : 0.050542, loss_ce: 0.019581
2021-12-02 22:59:33,152 iteration 994 : loss : 0.051636, loss_ce: 0.019672
2021-12-02 22:59:34,680 iteration 995 : loss : 0.104089, loss_ce: 0.031553
2021-12-02 22:59:36,267 iteration 996 : loss : 0.035459, loss_ce: 0.015588
2021-12-02 22:59:37,842 iteration 997 : loss : 0.061787, loss_ce: 0.022320
2021-12-02 22:59:39,324 iteration 998 : loss : 0.048022, loss_ce: 0.014996
2021-12-02 22:59:40,907 iteration 999 : loss : 0.055780, loss_ce: 0.022533
2021-12-02 22:59:42,390 iteration 1000 : loss : 0.057262, loss_ce: 0.017847
2021-12-02 22:59:43,874 iteration 1001 : loss : 0.078447, loss_ce: 0.020825
2021-12-02 22:59:45,522 iteration 1002 : loss : 0.049310, loss_ce: 0.019896
2021-12-02 22:59:47,153 iteration 1003 : loss : 0.066240, loss_ce: 0.027549
 15%|████▍                         | 59/400 [26:41<2:33:51, 27.07s/it]2021-12-02 22:59:48,765 iteration 1004 : loss : 0.106336, loss_ce: 0.045460
2021-12-02 22:59:50,279 iteration 1005 : loss : 0.071462, loss_ce: 0.031238
2021-12-02 22:59:51,917 iteration 1006 : loss : 0.065948, loss_ce: 0.026826
2021-12-02 22:59:53,395 iteration 1007 : loss : 0.062080, loss_ce: 0.029993
2021-12-02 22:59:54,869 iteration 1008 : loss : 0.106056, loss_ce: 0.038875
2021-12-02 22:59:56,353 iteration 1009 : loss : 0.068461, loss_ce: 0.023135
2021-12-02 22:59:57,841 iteration 1010 : loss : 0.057452, loss_ce: 0.022236
2021-12-02 22:59:59,444 iteration 1011 : loss : 0.052808, loss_ce: 0.023494
2021-12-02 23:00:00,974 iteration 1012 : loss : 0.043878, loss_ce: 0.017470
2021-12-02 23:00:02,448 iteration 1013 : loss : 0.046441, loss_ce: 0.015811
2021-12-02 23:00:04,008 iteration 1014 : loss : 0.067063, loss_ce: 0.029638
2021-12-02 23:00:05,483 iteration 1015 : loss : 0.061925, loss_ce: 0.021742
2021-12-02 23:00:07,037 iteration 1016 : loss : 0.050935, loss_ce: 0.022196
2021-12-02 23:00:08,476 iteration 1017 : loss : 0.042250, loss_ce: 0.015721
2021-12-02 23:00:09,905 iteration 1018 : loss : 0.062733, loss_ce: 0.022885
2021-12-02 23:00:11,446 iteration 1019 : loss : 0.060362, loss_ce: 0.023912
2021-12-02 23:00:11,446 Training Data Eval:
2021-12-02 23:00:19,083   Average segmentation loss on training set: 0.0425
2021-12-02 23:00:19,083 Validation Data Eval:
2021-12-02 23:00:21,715   Average segmentation loss on validation set: 0.1035
2021-12-02 23:00:23,641 Found new lowest validation loss at iteration 1019! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/UNET_RUNMC/1channel_best_val_loss.pth
2021-12-02 23:00:25,040 iteration 1020 : loss : 0.044015, loss_ce: 0.016960
 15%|████▌                         | 60/400 [27:19<2:51:47, 30.32s/it]2021-12-02 23:00:26,633 iteration 1021 : loss : 0.080541, loss_ce: 0.021834
2021-12-02 23:00:28,089 iteration 1022 : loss : 0.060425, loss_ce: 0.028100
2021-12-02 23:00:29,527 iteration 1023 : loss : 0.110801, loss_ce: 0.031297
2021-12-02 23:00:31,088 iteration 1024 : loss : 0.054572, loss_ce: 0.022101
2021-12-02 23:00:32,635 iteration 1025 : loss : 0.047930, loss_ce: 0.020086
2021-12-02 23:00:34,068 iteration 1026 : loss : 0.053950, loss_ce: 0.018267
2021-12-02 23:00:35,681 iteration 1027 : loss : 0.062691, loss_ce: 0.020412
2021-12-02 23:00:37,273 iteration 1028 : loss : 0.082321, loss_ce: 0.035198
2021-12-02 23:00:38,811 iteration 1029 : loss : 0.053232, loss_ce: 0.022473
2021-12-02 23:00:40,332 iteration 1030 : loss : 0.043008, loss_ce: 0.014721
2021-12-02 23:00:41,922 iteration 1031 : loss : 0.083551, loss_ce: 0.038301
2021-12-02 23:00:43,490 iteration 1032 : loss : 0.056120, loss_ce: 0.027172
2021-12-02 23:00:44,999 iteration 1033 : loss : 0.068417, loss_ce: 0.022362
2021-12-02 23:00:46,605 iteration 1034 : loss : 0.064997, loss_ce: 0.021762
2021-12-02 23:00:48,164 iteration 1035 : loss : 0.046841, loss_ce: 0.020436
2021-12-02 23:00:49,723 iteration 1036 : loss : 0.051335, loss_ce: 0.020193
2021-12-02 23:00:51,205 iteration 1037 : loss : 0.053348, loss_ce: 0.017874
 15%|████▌                         | 61/400 [27:45<2:44:13, 29.07s/it]2021-12-02 23:00:52,801 iteration 1038 : loss : 0.048302, loss_ce: 0.018756
2021-12-02 23:00:54,292 iteration 1039 : loss : 0.057388, loss_ce: 0.028343
2021-12-02 23:00:55,797 iteration 1040 : loss : 0.060748, loss_ce: 0.024394
2021-12-02 23:00:57,283 iteration 1041 : loss : 0.052822, loss_ce: 0.023098
2021-12-02 23:00:58,769 iteration 1042 : loss : 0.054198, loss_ce: 0.021673
2021-12-02 23:01:00,227 iteration 1043 : loss : 0.079141, loss_ce: 0.028575
2021-12-02 23:01:01,714 iteration 1044 : loss : 0.047328, loss_ce: 0.017429
2021-12-02 23:01:03,115 iteration 1045 : loss : 0.042187, loss_ce: 0.018801
2021-12-02 23:01:04,578 iteration 1046 : loss : 0.061846, loss_ce: 0.016903
2021-12-02 23:01:06,095 iteration 1047 : loss : 0.066200, loss_ce: 0.022555
2021-12-02 23:01:07,675 iteration 1048 : loss : 0.055652, loss_ce: 0.018449
2021-12-02 23:01:09,209 iteration 1049 : loss : 0.060625, loss_ce: 0.017042
2021-12-02 23:01:10,780 iteration 1050 : loss : 0.072241, loss_ce: 0.021835
2021-12-02 23:01:12,303 iteration 1051 : loss : 0.052480, loss_ce: 0.021236
2021-12-02 23:01:13,817 iteration 1052 : loss : 0.056503, loss_ce: 0.027035
2021-12-02 23:01:15,268 iteration 1053 : loss : 0.053854, loss_ce: 0.017132
2021-12-02 23:01:16,851 iteration 1054 : loss : 0.055853, loss_ce: 0.028556
 16%|████▋                         | 62/400 [28:11<2:37:58, 28.04s/it]2021-12-02 23:01:18,434 iteration 1055 : loss : 0.033438, loss_ce: 0.011808
2021-12-02 23:01:19,917 iteration 1056 : loss : 0.059302, loss_ce: 0.030194
2021-12-02 23:01:21,408 iteration 1057 : loss : 0.081319, loss_ce: 0.042632
2021-12-02 23:01:22,925 iteration 1058 : loss : 0.068882, loss_ce: 0.034881
2021-12-02 23:01:24,366 iteration 1059 : loss : 0.052135, loss_ce: 0.019673
2021-12-02 23:01:25,863 iteration 1060 : loss : 0.043227, loss_ce: 0.015602
2021-12-02 23:01:27,396 iteration 1061 : loss : 0.042477, loss_ce: 0.015741
2021-12-02 23:01:28,922 iteration 1062 : loss : 0.055122, loss_ce: 0.022894
2021-12-02 23:01:30,494 iteration 1063 : loss : 0.085293, loss_ce: 0.027142
2021-12-02 23:01:32,001 iteration 1064 : loss : 0.054674, loss_ce: 0.017212
2021-12-02 23:01:33,443 iteration 1065 : loss : 0.040223, loss_ce: 0.015250
2021-12-02 23:01:34,978 iteration 1066 : loss : 0.046475, loss_ce: 0.019266
2021-12-02 23:01:36,460 iteration 1067 : loss : 0.120773, loss_ce: 0.025984
2021-12-02 23:01:38,021 iteration 1068 : loss : 0.062235, loss_ce: 0.029730
2021-12-02 23:01:39,548 iteration 1069 : loss : 0.067639, loss_ce: 0.031284
2021-12-02 23:01:41,053 iteration 1070 : loss : 0.042965, loss_ce: 0.019409
2021-12-02 23:01:42,553 iteration 1071 : loss : 0.048114, loss_ce: 0.022943
 16%|████▋                         | 63/400 [28:36<2:33:33, 27.34s/it]2021-12-02 23:01:44,204 iteration 1072 : loss : 0.067547, loss_ce: 0.023138
2021-12-02 23:01:45,675 iteration 1073 : loss : 0.106471, loss_ce: 0.023643
2021-12-02 23:01:47,152 iteration 1074 : loss : 0.044689, loss_ce: 0.017812
2021-12-02 23:01:48,675 iteration 1075 : loss : 0.072075, loss_ce: 0.028305
2021-12-02 23:01:50,134 iteration 1076 : loss : 0.044525, loss_ce: 0.015635
2021-12-02 23:01:51,623 iteration 1077 : loss : 0.047212, loss_ce: 0.016660
2021-12-02 23:01:53,191 iteration 1078 : loss : 0.072794, loss_ce: 0.041604
2021-12-02 23:01:54,659 iteration 1079 : loss : 0.037580, loss_ce: 0.014610
2021-12-02 23:01:56,126 iteration 1080 : loss : 0.042721, loss_ce: 0.018311
2021-12-02 23:01:57,659 iteration 1081 : loss : 0.060027, loss_ce: 0.019383
2021-12-02 23:01:59,193 iteration 1082 : loss : 0.057697, loss_ce: 0.031417
2021-12-02 23:02:00,748 iteration 1083 : loss : 0.061020, loss_ce: 0.026481
2021-12-02 23:02:02,216 iteration 1084 : loss : 0.055342, loss_ce: 0.027850
2021-12-02 23:02:03,794 iteration 1085 : loss : 0.054232, loss_ce: 0.020199
2021-12-02 23:02:05,279 iteration 1086 : loss : 0.061434, loss_ce: 0.025638
2021-12-02 23:02:06,768 iteration 1087 : loss : 0.054788, loss_ce: 0.021478
2021-12-02 23:02:08,318 iteration 1088 : loss : 0.052427, loss_ce: 0.021763
 16%|████▊                         | 64/400 [29:02<2:30:28, 26.87s/it]2021-12-02 23:02:09,889 iteration 1089 : loss : 0.079687, loss_ce: 0.029499
2021-12-02 23:02:11,366 iteration 1090 : loss : 0.040705, loss_ce: 0.019591
2021-12-02 23:02:12,867 iteration 1091 : loss : 0.043077, loss_ce: 0.019505
2021-12-02 23:02:14,360 iteration 1092 : loss : 0.047572, loss_ce: 0.020102
2021-12-02 23:02:15,874 iteration 1093 : loss : 0.066171, loss_ce: 0.022406
2021-12-02 23:02:17,436 iteration 1094 : loss : 0.043256, loss_ce: 0.016785
2021-12-02 23:02:18,896 iteration 1095 : loss : 0.042710, loss_ce: 0.018602
2021-12-02 23:02:20,483 iteration 1096 : loss : 0.057018, loss_ce: 0.022503
2021-12-02 23:02:21,990 iteration 1097 : loss : 0.065591, loss_ce: 0.027143
2021-12-02 23:02:23,452 iteration 1098 : loss : 0.048435, loss_ce: 0.021735
2021-12-02 23:02:24,965 iteration 1099 : loss : 0.056988, loss_ce: 0.019697
2021-12-02 23:02:26,527 iteration 1100 : loss : 0.056847, loss_ce: 0.020014
2021-12-02 23:02:28,019 iteration 1101 : loss : 0.041755, loss_ce: 0.018278
2021-12-02 23:02:29,583 iteration 1102 : loss : 0.072618, loss_ce: 0.021717
2021-12-02 23:02:31,060 iteration 1103 : loss : 0.060096, loss_ce: 0.021335
2021-12-02 23:02:32,545 iteration 1104 : loss : 0.054821, loss_ce: 0.024736
2021-12-02 23:02:32,545 Training Data Eval:
2021-12-02 23:02:40,061   Average segmentation loss on training set: 0.0501
2021-12-02 23:02:40,061 Validation Data Eval:
2021-12-02 23:02:42,675   Average segmentation loss on validation set: 0.1392
2021-12-02 23:02:44,241 iteration 1105 : loss : 0.048064, loss_ce: 0.013517
 16%|████▉                         | 65/400 [29:38<2:45:10, 29.58s/it]2021-12-02 23:02:45,735 iteration 1106 : loss : 0.054287, loss_ce: 0.019029
2021-12-02 23:02:47,221 iteration 1107 : loss : 0.058782, loss_ce: 0.029858
2021-12-02 23:02:48,737 iteration 1108 : loss : 0.049018, loss_ce: 0.012680
2021-12-02 23:02:50,198 iteration 1109 : loss : 0.040139, loss_ce: 0.016385
2021-12-02 23:02:51,697 iteration 1110 : loss : 0.059078, loss_ce: 0.027750
2021-12-02 23:02:53,165 iteration 1111 : loss : 0.043283, loss_ce: 0.017802
2021-12-02 23:02:54,661 iteration 1112 : loss : 0.048052, loss_ce: 0.018831
2021-12-02 23:02:56,148 iteration 1113 : loss : 0.048592, loss_ce: 0.016886
2021-12-02 23:02:57,708 iteration 1114 : loss : 0.048342, loss_ce: 0.021530
2021-12-02 23:02:59,301 iteration 1115 : loss : 0.052522, loss_ce: 0.024978
2021-12-02 23:03:00,819 iteration 1116 : loss : 0.066466, loss_ce: 0.020519
2021-12-02 23:03:02,418 iteration 1117 : loss : 0.046890, loss_ce: 0.015742
2021-12-02 23:03:03,943 iteration 1118 : loss : 0.065825, loss_ce: 0.018697
2021-12-02 23:03:05,393 iteration 1119 : loss : 0.042370, loss_ce: 0.020532
2021-12-02 23:03:06,843 iteration 1120 : loss : 0.049230, loss_ce: 0.016487
2021-12-02 23:03:08,353 iteration 1121 : loss : 0.063310, loss_ce: 0.022771
2021-12-02 23:03:09,843 iteration 1122 : loss : 0.059678, loss_ce: 0.028780
 16%|████▉                         | 66/400 [30:03<2:38:01, 28.39s/it]2021-12-02 23:03:11,351 iteration 1123 : loss : 0.080156, loss_ce: 0.023822
2021-12-02 23:03:12,878 iteration 1124 : loss : 0.051817, loss_ce: 0.024920
2021-12-02 23:03:14,375 iteration 1125 : loss : 0.033644, loss_ce: 0.010996
2021-12-02 23:03:15,856 iteration 1126 : loss : 0.047075, loss_ce: 0.016187
2021-12-02 23:03:17,336 iteration 1127 : loss : 0.052193, loss_ce: 0.023377
2021-12-02 23:03:18,890 iteration 1128 : loss : 0.074820, loss_ce: 0.032144
2021-12-02 23:03:20,432 iteration 1129 : loss : 0.069503, loss_ce: 0.024561
2021-12-02 23:03:21,903 iteration 1130 : loss : 0.048508, loss_ce: 0.023330
2021-12-02 23:03:23,383 iteration 1131 : loss : 0.044036, loss_ce: 0.018165
2021-12-02 23:03:24,907 iteration 1132 : loss : 0.051817, loss_ce: 0.020936
2021-12-02 23:03:26,351 iteration 1133 : loss : 0.038996, loss_ce: 0.017332
2021-12-02 23:03:27,846 iteration 1134 : loss : 0.059839, loss_ce: 0.021066
2021-12-02 23:03:29,304 iteration 1135 : loss : 0.056398, loss_ce: 0.023405
2021-12-02 23:03:30,769 iteration 1136 : loss : 0.039947, loss_ce: 0.014280
2021-12-02 23:03:32,221 iteration 1137 : loss : 0.056982, loss_ce: 0.024566
2021-12-02 23:03:33,743 iteration 1138 : loss : 0.043416, loss_ce: 0.019925
2021-12-02 23:03:35,246 iteration 1139 : loss : 0.063489, loss_ce: 0.020116
 17%|█████                         | 67/400 [30:29<2:32:35, 27.49s/it]2021-12-02 23:03:36,776 iteration 1140 : loss : 0.061807, loss_ce: 0.022131
2021-12-02 23:03:38,216 iteration 1141 : loss : 0.045860, loss_ce: 0.016033
2021-12-02 23:03:39,766 iteration 1142 : loss : 0.045275, loss_ce: 0.018349
2021-12-02 23:03:41,246 iteration 1143 : loss : 0.048697, loss_ce: 0.019211
2021-12-02 23:03:42,773 iteration 1144 : loss : 0.059089, loss_ce: 0.028503
2021-12-02 23:03:44,218 iteration 1145 : loss : 0.045788, loss_ce: 0.017874
2021-12-02 23:03:45,724 iteration 1146 : loss : 0.058897, loss_ce: 0.030796
2021-12-02 23:03:47,145 iteration 1147 : loss : 0.041961, loss_ce: 0.015891
2021-12-02 23:03:48,684 iteration 1148 : loss : 0.045587, loss_ce: 0.017000
2021-12-02 23:03:50,125 iteration 1149 : loss : 0.043149, loss_ce: 0.020914
2021-12-02 23:03:51,615 iteration 1150 : loss : 0.047557, loss_ce: 0.019520
2021-12-02 23:03:53,121 iteration 1151 : loss : 0.052994, loss_ce: 0.020508
2021-12-02 23:03:54,720 iteration 1152 : loss : 0.063323, loss_ce: 0.026325
2021-12-02 23:03:56,130 iteration 1153 : loss : 0.046451, loss_ce: 0.016100
2021-12-02 23:03:57,639 iteration 1154 : loss : 0.058889, loss_ce: 0.021980
2021-12-02 23:03:59,091 iteration 1155 : loss : 0.053086, loss_ce: 0.017718
2021-12-02 23:04:00,640 iteration 1156 : loss : 0.061663, loss_ce: 0.032645
 17%|█████                         | 68/400 [30:54<2:28:38, 26.86s/it]2021-12-02 23:04:02,167 iteration 1157 : loss : 0.081680, loss_ce: 0.021470
2021-12-02 23:04:03,670 iteration 1158 : loss : 0.050273, loss_ce: 0.017234
2021-12-02 23:04:05,218 iteration 1159 : loss : 0.043920, loss_ce: 0.014552
2021-12-02 23:04:06,804 iteration 1160 : loss : 0.053737, loss_ce: 0.022953
2021-12-02 23:04:08,337 iteration 1161 : loss : 0.043915, loss_ce: 0.018389
2021-12-02 23:04:09,845 iteration 1162 : loss : 0.045642, loss_ce: 0.015938
2021-12-02 23:04:11,297 iteration 1163 : loss : 0.059461, loss_ce: 0.028712
2021-12-02 23:04:12,767 iteration 1164 : loss : 0.058888, loss_ce: 0.022277
2021-12-02 23:04:14,256 iteration 1165 : loss : 0.047204, loss_ce: 0.019311
2021-12-02 23:04:15,792 iteration 1166 : loss : 0.037664, loss_ce: 0.013090
2021-12-02 23:04:17,238 iteration 1167 : loss : 0.037543, loss_ce: 0.019177
2021-12-02 23:04:18,698 iteration 1168 : loss : 0.046065, loss_ce: 0.019819
2021-12-02 23:04:20,145 iteration 1169 : loss : 0.043108, loss_ce: 0.017425
2021-12-02 23:04:21,608 iteration 1170 : loss : 0.068548, loss_ce: 0.025626
2021-12-02 23:04:23,131 iteration 1171 : loss : 0.040338, loss_ce: 0.013853
2021-12-02 23:04:24,628 iteration 1172 : loss : 0.039605, loss_ce: 0.018238
2021-12-02 23:04:26,130 iteration 1173 : loss : 0.060325, loss_ce: 0.021480
 17%|█████▏                        | 69/400 [31:20<2:25:54, 26.45s/it]2021-12-02 23:04:27,654 iteration 1174 : loss : 0.059416, loss_ce: 0.020544
2021-12-02 23:04:29,155 iteration 1175 : loss : 0.040558, loss_ce: 0.016745
2021-12-02 23:04:30,639 iteration 1176 : loss : 0.042822, loss_ce: 0.016112
2021-12-02 23:04:32,095 iteration 1177 : loss : 0.046492, loss_ce: 0.021092
2021-12-02 23:04:33,610 iteration 1178 : loss : 0.050935, loss_ce: 0.016274
2021-12-02 23:04:35,148 iteration 1179 : loss : 0.046972, loss_ce: 0.021620
2021-12-02 23:04:36,599 iteration 1180 : loss : 0.044071, loss_ce: 0.020295
2021-12-02 23:04:38,085 iteration 1181 : loss : 0.039801, loss_ce: 0.013510
2021-12-02 23:04:39,580 iteration 1182 : loss : 0.049488, loss_ce: 0.019379
2021-12-02 23:04:41,015 iteration 1183 : loss : 0.060494, loss_ce: 0.027532
2021-12-02 23:04:42,473 iteration 1184 : loss : 0.034338, loss_ce: 0.015166
2021-12-02 23:04:43,993 iteration 1185 : loss : 0.045101, loss_ce: 0.017294
2021-12-02 23:04:45,442 iteration 1186 : loss : 0.044070, loss_ce: 0.022459
2021-12-02 23:04:46,976 iteration 1187 : loss : 0.046672, loss_ce: 0.016087
2021-12-02 23:04:48,429 iteration 1188 : loss : 0.047674, loss_ce: 0.018489
2021-12-02 23:04:49,982 iteration 1189 : loss : 0.049146, loss_ce: 0.020253
2021-12-02 23:04:49,983 Training Data Eval:
2021-12-02 23:04:57,470   Average segmentation loss on training set: 0.0323
2021-12-02 23:04:57,471 Validation Data Eval:
2021-12-02 23:05:00,079   Average segmentation loss on validation set: 0.0776
2021-12-02 23:05:02,037 Found new lowest validation loss at iteration 1189! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/UNET_RUNMC/1channel_best_val_loss.pth
2021-12-02 23:05:03,518 iteration 1190 : loss : 0.053176, loss_ce: 0.025955
 18%|█████▎                        | 70/400 [31:57<2:43:32, 29.74s/it]2021-12-02 23:05:05,036 iteration 1191 : loss : 0.049733, loss_ce: 0.020394
2021-12-02 23:05:06,391 iteration 1192 : loss : 0.034493, loss_ce: 0.015653
2021-12-02 23:05:07,861 iteration 1193 : loss : 0.081777, loss_ce: 0.023956
2021-12-02 23:05:09,272 iteration 1194 : loss : 0.040335, loss_ce: 0.013009
2021-12-02 23:05:10,696 iteration 1195 : loss : 0.043314, loss_ce: 0.019001
2021-12-02 23:05:12,136 iteration 1196 : loss : 0.044051, loss_ce: 0.016892
2021-12-02 23:05:13,554 iteration 1197 : loss : 0.037032, loss_ce: 0.014477
2021-12-02 23:05:15,076 iteration 1198 : loss : 0.047059, loss_ce: 0.022026
2021-12-02 23:05:16,567 iteration 1199 : loss : 0.045689, loss_ce: 0.017477
2021-12-02 23:05:18,017 iteration 1200 : loss : 0.060833, loss_ce: 0.019089
2021-12-02 23:05:19,440 iteration 1201 : loss : 0.042204, loss_ce: 0.017895
2021-12-02 23:05:20,945 iteration 1202 : loss : 0.047503, loss_ce: 0.016096
2021-12-02 23:05:22,435 iteration 1203 : loss : 0.060907, loss_ce: 0.019216
2021-12-02 23:05:23,916 iteration 1204 : loss : 0.044205, loss_ce: 0.016142
2021-12-02 23:05:25,410 iteration 1205 : loss : 0.060750, loss_ce: 0.024190
2021-12-02 23:05:26,904 iteration 1206 : loss : 0.045464, loss_ce: 0.018199
2021-12-02 23:05:28,440 iteration 1207 : loss : 0.056824, loss_ce: 0.018445
 18%|█████▎                        | 71/400 [32:22<2:35:08, 28.29s/it]2021-12-02 23:05:30,036 iteration 1208 : loss : 0.056394, loss_ce: 0.026038
2021-12-02 23:05:31,511 iteration 1209 : loss : 0.048024, loss_ce: 0.018022
2021-12-02 23:05:32,991 iteration 1210 : loss : 0.047547, loss_ce: 0.016908
2021-12-02 23:05:34,431 iteration 1211 : loss : 0.037934, loss_ce: 0.014520
2021-12-02 23:05:35,853 iteration 1212 : loss : 0.058464, loss_ce: 0.019652
2021-12-02 23:05:37,445 iteration 1213 : loss : 0.067032, loss_ce: 0.029089
2021-12-02 23:05:38,914 iteration 1214 : loss : 0.036491, loss_ce: 0.013577
2021-12-02 23:05:40,404 iteration 1215 : loss : 0.042000, loss_ce: 0.016063
2021-12-02 23:05:41,998 iteration 1216 : loss : 0.060051, loss_ce: 0.021974
2021-12-02 23:05:43,489 iteration 1217 : loss : 0.034776, loss_ce: 0.011666
2021-12-02 23:05:44,932 iteration 1218 : loss : 0.038040, loss_ce: 0.014301
2021-12-02 23:05:46,339 iteration 1219 : loss : 0.048431, loss_ce: 0.015307
2021-12-02 23:05:47,795 iteration 1220 : loss : 0.042997, loss_ce: 0.017365
2021-12-02 23:05:49,230 iteration 1221 : loss : 0.076365, loss_ce: 0.026911
2021-12-02 23:05:50,757 iteration 1222 : loss : 0.066863, loss_ce: 0.025454
2021-12-02 23:05:52,201 iteration 1223 : loss : 0.056248, loss_ce: 0.024862
2021-12-02 23:05:53,705 iteration 1224 : loss : 0.071006, loss_ce: 0.027044
 18%|█████▍                        | 72/400 [32:47<2:29:41, 27.38s/it]2021-12-02 23:05:55,194 iteration 1225 : loss : 0.038077, loss_ce: 0.013998
2021-12-02 23:05:56,703 iteration 1226 : loss : 0.065826, loss_ce: 0.030052
2021-12-02 23:05:58,140 iteration 1227 : loss : 0.045310, loss_ce: 0.015588
2021-12-02 23:05:59,606 iteration 1228 : loss : 0.047047, loss_ce: 0.019407
2021-12-02 23:06:01,024 iteration 1229 : loss : 0.045311, loss_ce: 0.014463
2021-12-02 23:06:02,467 iteration 1230 : loss : 0.045551, loss_ce: 0.018265
2021-12-02 23:06:03,973 iteration 1231 : loss : 0.051323, loss_ce: 0.022364
2021-12-02 23:06:05,400 iteration 1232 : loss : 0.050489, loss_ce: 0.020999
2021-12-02 23:06:06,838 iteration 1233 : loss : 0.040058, loss_ce: 0.014998
2021-12-02 23:06:08,347 iteration 1234 : loss : 0.052806, loss_ce: 0.021987
2021-12-02 23:06:09,858 iteration 1235 : loss : 0.085725, loss_ce: 0.032253
2021-12-02 23:06:11,296 iteration 1236 : loss : 0.045094, loss_ce: 0.016234
2021-12-02 23:06:12,705 iteration 1237 : loss : 0.047764, loss_ce: 0.020666
2021-12-02 23:06:14,236 iteration 1238 : loss : 0.049719, loss_ce: 0.018389
2021-12-02 23:06:15,666 iteration 1239 : loss : 0.037340, loss_ce: 0.013998
2021-12-02 23:06:17,110 iteration 1240 : loss : 0.041647, loss_ce: 0.016144
2021-12-02 23:06:18,543 iteration 1241 : loss : 0.051348, loss_ce: 0.025803
 18%|█████▍                        | 73/400 [33:12<2:25:04, 26.62s/it]2021-12-02 23:06:20,076 iteration 1242 : loss : 0.067835, loss_ce: 0.041832
2021-12-02 23:06:21,515 iteration 1243 : loss : 0.055993, loss_ce: 0.017807
2021-12-02 23:06:22,979 iteration 1244 : loss : 0.040689, loss_ce: 0.016658
2021-12-02 23:06:24,474 iteration 1245 : loss : 0.071522, loss_ce: 0.026600
2021-12-02 23:06:25,949 iteration 1246 : loss : 0.045887, loss_ce: 0.016102
2021-12-02 23:06:27,391 iteration 1247 : loss : 0.041816, loss_ce: 0.017230
2021-12-02 23:06:28,899 iteration 1248 : loss : 0.063895, loss_ce: 0.018001
2021-12-02 23:06:30,339 iteration 1249 : loss : 0.037009, loss_ce: 0.012099
2021-12-02 23:06:31,907 iteration 1250 : loss : 0.077054, loss_ce: 0.032806
2021-12-02 23:06:33,480 iteration 1251 : loss : 0.055217, loss_ce: 0.026195
2021-12-02 23:06:34,960 iteration 1252 : loss : 0.044435, loss_ce: 0.018202
2021-12-02 23:06:36,354 iteration 1253 : loss : 0.038104, loss_ce: 0.013017
2021-12-02 23:06:37,813 iteration 1254 : loss : 0.042208, loss_ce: 0.022111
2021-12-02 23:06:39,303 iteration 1255 : loss : 0.044603, loss_ce: 0.017762
2021-12-02 23:06:40,766 iteration 1256 : loss : 0.054432, loss_ce: 0.024416
2021-12-02 23:06:42,226 iteration 1257 : loss : 0.061575, loss_ce: 0.016937
2021-12-02 23:06:43,694 iteration 1258 : loss : 0.038809, loss_ce: 0.017162
 18%|█████▌                        | 74/400 [33:37<2:22:13, 26.18s/it]2021-12-02 23:06:45,157 iteration 1259 : loss : 0.042680, loss_ce: 0.020272
2021-12-02 23:06:46,666 iteration 1260 : loss : 0.044905, loss_ce: 0.017487
2021-12-02 23:06:48,132 iteration 1261 : loss : 0.038468, loss_ce: 0.010933
2021-12-02 23:06:49,680 iteration 1262 : loss : 0.047428, loss_ce: 0.017308
2021-12-02 23:06:51,262 iteration 1263 : loss : 0.067241, loss_ce: 0.026614
2021-12-02 23:06:52,714 iteration 1264 : loss : 0.041616, loss_ce: 0.019559
2021-12-02 23:06:54,226 iteration 1265 : loss : 0.047397, loss_ce: 0.025813
2021-12-02 23:06:55,735 iteration 1266 : loss : 0.055856, loss_ce: 0.023017
2021-12-02 23:06:57,204 iteration 1267 : loss : 0.046642, loss_ce: 0.016800
2021-12-02 23:06:58,639 iteration 1268 : loss : 0.052493, loss_ce: 0.018876
2021-12-02 23:07:00,185 iteration 1269 : loss : 0.088063, loss_ce: 0.023281
2021-12-02 23:07:01,697 iteration 1270 : loss : 0.041051, loss_ce: 0.015482
2021-12-02 23:07:03,162 iteration 1271 : loss : 0.051111, loss_ce: 0.023121
2021-12-02 23:07:04,558 iteration 1272 : loss : 0.047366, loss_ce: 0.017666
2021-12-02 23:07:06,022 iteration 1273 : loss : 0.040224, loss_ce: 0.015243
2021-12-02 23:07:07,493 iteration 1274 : loss : 0.055954, loss_ce: 0.016639
2021-12-02 23:07:07,493 Training Data Eval:
2021-12-02 23:07:14,941   Average segmentation loss on training set: 0.0317
2021-12-02 23:07:14,941 Validation Data Eval:
2021-12-02 23:07:17,538   Average segmentation loss on validation set: 0.1046
2021-12-02 23:07:19,014 iteration 1275 : loss : 0.048449, loss_ce: 0.017254
 19%|█████▋                        | 75/400 [34:13<2:36:38, 28.92s/it]2021-12-02 23:07:20,466 iteration 1276 : loss : 0.042546, loss_ce: 0.017013
2021-12-02 23:07:22,019 iteration 1277 : loss : 0.044422, loss_ce: 0.014992
2021-12-02 23:07:23,439 iteration 1278 : loss : 0.032662, loss_ce: 0.011752
2021-12-02 23:07:24,998 iteration 1279 : loss : 0.039172, loss_ce: 0.015005
2021-12-02 23:07:26,499 iteration 1280 : loss : 0.057988, loss_ce: 0.023987
2021-12-02 23:07:27,981 iteration 1281 : loss : 0.071991, loss_ce: 0.029321
2021-12-02 23:07:29,401 iteration 1282 : loss : 0.030927, loss_ce: 0.013904
2021-12-02 23:07:30,954 iteration 1283 : loss : 0.041701, loss_ce: 0.012371
2021-12-02 23:07:32,397 iteration 1284 : loss : 0.044444, loss_ce: 0.018323
2021-12-02 23:07:33,933 iteration 1285 : loss : 0.049901, loss_ce: 0.017779
2021-12-02 23:07:35,482 iteration 1286 : loss : 0.121033, loss_ce: 0.035139
2021-12-02 23:07:36,918 iteration 1287 : loss : 0.035543, loss_ce: 0.017646
2021-12-02 23:07:38,358 iteration 1288 : loss : 0.050885, loss_ce: 0.023738
2021-12-02 23:07:39,831 iteration 1289 : loss : 0.073203, loss_ce: 0.034354
2021-12-02 23:07:41,343 iteration 1290 : loss : 0.063062, loss_ce: 0.027248
2021-12-02 23:07:42,844 iteration 1291 : loss : 0.086963, loss_ce: 0.040958
2021-12-02 23:07:44,365 iteration 1292 : loss : 0.058697, loss_ce: 0.020919
 19%|█████▋                        | 76/400 [34:38<2:30:23, 27.85s/it]2021-12-02 23:07:45,914 iteration 1293 : loss : 0.045944, loss_ce: 0.016367
2021-12-02 23:07:47,402 iteration 1294 : loss : 0.056023, loss_ce: 0.020314
2021-12-02 23:07:48,952 iteration 1295 : loss : 0.073253, loss_ce: 0.019551
2021-12-02 23:07:50,441 iteration 1296 : loss : 0.056214, loss_ce: 0.016773
2021-12-02 23:07:51,870 iteration 1297 : loss : 0.055036, loss_ce: 0.027048
2021-12-02 23:07:53,259 iteration 1298 : loss : 0.042085, loss_ce: 0.015398
2021-12-02 23:07:54,740 iteration 1299 : loss : 0.053690, loss_ce: 0.025646
2021-12-02 23:07:56,191 iteration 1300 : loss : 0.080017, loss_ce: 0.022440
2021-12-02 23:07:57,680 iteration 1301 : loss : 0.054403, loss_ce: 0.019476
2021-12-02 23:07:59,127 iteration 1302 : loss : 0.065173, loss_ce: 0.029014
2021-12-02 23:08:00,583 iteration 1303 : loss : 0.050822, loss_ce: 0.019310
2021-12-02 23:08:02,068 iteration 1304 : loss : 0.052436, loss_ce: 0.021098
2021-12-02 23:08:03,541 iteration 1305 : loss : 0.062327, loss_ce: 0.027926
2021-12-02 23:08:05,036 iteration 1306 : loss : 0.073603, loss_ce: 0.026988
2021-12-02 23:08:06,542 iteration 1307 : loss : 0.047153, loss_ce: 0.022684
2021-12-02 23:08:08,015 iteration 1308 : loss : 0.062786, loss_ce: 0.016475
2021-12-02 23:08:09,439 iteration 1309 : loss : 0.047615, loss_ce: 0.016361
 19%|█████▊                        | 77/400 [35:03<2:25:27, 27.02s/it]2021-12-02 23:08:11,030 iteration 1310 : loss : 0.056481, loss_ce: 0.019572
2021-12-02 23:08:12,518 iteration 1311 : loss : 0.055256, loss_ce: 0.025652
2021-12-02 23:08:13,970 iteration 1312 : loss : 0.039633, loss_ce: 0.015931
2021-12-02 23:08:15,411 iteration 1313 : loss : 0.063551, loss_ce: 0.017919
2021-12-02 23:08:16,866 iteration 1314 : loss : 0.051181, loss_ce: 0.021819
2021-12-02 23:08:18,347 iteration 1315 : loss : 0.084952, loss_ce: 0.042693
2021-12-02 23:08:19,914 iteration 1316 : loss : 0.057738, loss_ce: 0.023426
2021-12-02 23:08:21,369 iteration 1317 : loss : 0.056422, loss_ce: 0.030099
2021-12-02 23:08:22,902 iteration 1318 : loss : 0.151051, loss_ce: 0.033082
2021-12-02 23:08:24,396 iteration 1319 : loss : 0.066212, loss_ce: 0.032562
2021-12-02 23:08:25,852 iteration 1320 : loss : 0.044723, loss_ce: 0.017686
2021-12-02 23:08:27,332 iteration 1321 : loss : 0.069199, loss_ce: 0.020610
2021-12-02 23:08:28,731 iteration 1322 : loss : 0.062908, loss_ce: 0.027314
2021-12-02 23:08:30,178 iteration 1323 : loss : 0.070043, loss_ce: 0.023655
2021-12-02 23:08:31,658 iteration 1324 : loss : 0.057505, loss_ce: 0.024381
2021-12-02 23:08:33,182 iteration 1325 : loss : 0.084433, loss_ce: 0.031078
2021-12-02 23:08:34,579 iteration 1326 : loss : 0.049210, loss_ce: 0.018167
 20%|█████▊                        | 78/400 [35:28<2:21:58, 26.45s/it]2021-12-02 23:08:36,069 iteration 1327 : loss : 0.081523, loss_ce: 0.027827
2021-12-02 23:08:37,544 iteration 1328 : loss : 0.102390, loss_ce: 0.049678
2021-12-02 23:08:38,997 iteration 1329 : loss : 0.048895, loss_ce: 0.022237
2021-12-02 23:08:40,439 iteration 1330 : loss : 0.101890, loss_ce: 0.029437
2021-12-02 23:08:41,864 iteration 1331 : loss : 0.047661, loss_ce: 0.024721
2021-12-02 23:08:43,302 iteration 1332 : loss : 0.049807, loss_ce: 0.017717
2021-12-02 23:08:44,753 iteration 1333 : loss : 0.053783, loss_ce: 0.015389
2021-12-02 23:08:46,230 iteration 1334 : loss : 0.057694, loss_ce: 0.022224
2021-12-02 23:08:47,688 iteration 1335 : loss : 0.050376, loss_ce: 0.017896
2021-12-02 23:08:49,139 iteration 1336 : loss : 0.036449, loss_ce: 0.013979
2021-12-02 23:08:50,662 iteration 1337 : loss : 0.071701, loss_ce: 0.034553
2021-12-02 23:08:52,147 iteration 1338 : loss : 0.044507, loss_ce: 0.016075
2021-12-02 23:08:53,648 iteration 1339 : loss : 0.050157, loss_ce: 0.024439
2021-12-02 23:08:55,141 iteration 1340 : loss : 0.059846, loss_ce: 0.030817
2021-12-02 23:08:56,608 iteration 1341 : loss : 0.050938, loss_ce: 0.018627
2021-12-02 23:08:58,053 iteration 1342 : loss : 0.066492, loss_ce: 0.025856
2021-12-02 23:08:59,459 iteration 1343 : loss : 0.040078, loss_ce: 0.015716
 20%|█████▉                        | 79/400 [35:53<2:19:00, 25.98s/it]2021-12-02 23:09:00,994 iteration 1344 : loss : 0.045356, loss_ce: 0.017727
2021-12-02 23:09:02,517 iteration 1345 : loss : 0.072403, loss_ce: 0.025929
2021-12-02 23:09:03,948 iteration 1346 : loss : 0.053368, loss_ce: 0.024679
2021-12-02 23:09:05,470 iteration 1347 : loss : 0.048954, loss_ce: 0.024617
2021-12-02 23:09:07,027 iteration 1348 : loss : 0.076883, loss_ce: 0.029979
2021-12-02 23:09:08,490 iteration 1349 : loss : 0.052691, loss_ce: 0.020289
2021-12-02 23:09:09,949 iteration 1350 : loss : 0.049465, loss_ce: 0.022010
2021-12-02 23:09:11,409 iteration 1351 : loss : 0.048904, loss_ce: 0.022143
2021-12-02 23:09:12,928 iteration 1352 : loss : 0.048227, loss_ce: 0.022211
2021-12-02 23:09:14,416 iteration 1353 : loss : 0.055802, loss_ce: 0.020263
2021-12-02 23:09:15,920 iteration 1354 : loss : 0.059606, loss_ce: 0.023661
2021-12-02 23:09:17,477 iteration 1355 : loss : 0.163737, loss_ce: 0.049446
2021-12-02 23:09:18,932 iteration 1356 : loss : 0.050788, loss_ce: 0.017940
2021-12-02 23:09:20,410 iteration 1357 : loss : 0.045148, loss_ce: 0.018930
2021-12-02 23:09:21,927 iteration 1358 : loss : 0.060560, loss_ce: 0.024231
2021-12-02 23:09:23,405 iteration 1359 : loss : 0.058626, loss_ce: 0.026581
2021-12-02 23:09:23,405 Training Data Eval:
2021-12-02 23:09:30,838   Average segmentation loss on training set: 0.0405
2021-12-02 23:09:30,838 Validation Data Eval:
2021-12-02 23:09:33,424   Average segmentation loss on validation set: 0.0986
2021-12-02 23:09:34,951 iteration 1360 : loss : 0.048720, loss_ce: 0.013772
 20%|██████                        | 80/400 [36:29<2:33:46, 28.83s/it]2021-12-02 23:09:36,560 iteration 1361 : loss : 0.088813, loss_ce: 0.046943
2021-12-02 23:09:38,035 iteration 1362 : loss : 0.056356, loss_ce: 0.018918
2021-12-02 23:09:39,652 iteration 1363 : loss : 0.108821, loss_ce: 0.048628
2021-12-02 23:09:41,012 iteration 1364 : loss : 0.054094, loss_ce: 0.015181
2021-12-02 23:09:42,556 iteration 1365 : loss : 0.060145, loss_ce: 0.025510
2021-12-02 23:09:44,049 iteration 1366 : loss : 0.074460, loss_ce: 0.032682
2021-12-02 23:09:45,501 iteration 1367 : loss : 0.047045, loss_ce: 0.017953
2021-12-02 23:09:46,968 iteration 1368 : loss : 0.057879, loss_ce: 0.026961
2021-12-02 23:09:48,395 iteration 1369 : loss : 0.060336, loss_ce: 0.023232
2021-12-02 23:09:49,900 iteration 1370 : loss : 0.048954, loss_ce: 0.024434
2021-12-02 23:09:51,363 iteration 1371 : loss : 0.042572, loss_ce: 0.016426
2021-12-02 23:09:52,815 iteration 1372 : loss : 0.051036, loss_ce: 0.019190
2021-12-02 23:09:54,243 iteration 1373 : loss : 0.058762, loss_ce: 0.022013
2021-12-02 23:09:55,727 iteration 1374 : loss : 0.050717, loss_ce: 0.016768
2021-12-02 23:09:57,218 iteration 1375 : loss : 0.049347, loss_ce: 0.023371
2021-12-02 23:09:58,681 iteration 1376 : loss : 0.064006, loss_ce: 0.022059
2021-12-02 23:10:00,151 iteration 1377 : loss : 0.028741, loss_ce: 0.011512
 20%|██████                        | 81/400 [36:54<2:27:30, 27.75s/it]2021-12-02 23:10:01,635 iteration 1378 : loss : 0.057562, loss_ce: 0.022795
2021-12-02 23:10:03,135 iteration 1379 : loss : 0.038525, loss_ce: 0.014625
2021-12-02 23:10:04,605 iteration 1380 : loss : 0.044926, loss_ce: 0.018365
2021-12-02 23:10:06,155 iteration 1381 : loss : 0.061676, loss_ce: 0.026404
2021-12-02 23:10:07,559 iteration 1382 : loss : 0.035953, loss_ce: 0.013656
2021-12-02 23:10:09,088 iteration 1383 : loss : 0.053375, loss_ce: 0.020748
2021-12-02 23:10:10,564 iteration 1384 : loss : 0.056111, loss_ce: 0.021027
2021-12-02 23:10:11,960 iteration 1385 : loss : 0.051647, loss_ce: 0.018625
2021-12-02 23:10:13,403 iteration 1386 : loss : 0.039170, loss_ce: 0.015249
2021-12-02 23:10:14,850 iteration 1387 : loss : 0.037945, loss_ce: 0.014775
2021-12-02 23:10:16,304 iteration 1388 : loss : 0.047948, loss_ce: 0.015285
2021-12-02 23:10:17,784 iteration 1389 : loss : 0.052428, loss_ce: 0.022596
2021-12-02 23:10:19,310 iteration 1390 : loss : 0.038296, loss_ce: 0.017080
2021-12-02 23:10:20,831 iteration 1391 : loss : 0.052302, loss_ce: 0.019841
2021-12-02 23:10:22,340 iteration 1392 : loss : 0.042273, loss_ce: 0.021546
2021-12-02 23:10:23,788 iteration 1393 : loss : 0.040011, loss_ce: 0.014224
2021-12-02 23:10:25,324 iteration 1394 : loss : 0.036405, loss_ce: 0.016312
 20%|██████▏                       | 82/400 [37:19<2:22:56, 26.97s/it]2021-12-02 23:10:26,836 iteration 1395 : loss : 0.053352, loss_ce: 0.020334
2021-12-02 23:10:28,290 iteration 1396 : loss : 0.046329, loss_ce: 0.021206
2021-12-02 23:10:29,807 iteration 1397 : loss : 0.066978, loss_ce: 0.025049
2021-12-02 23:10:31,323 iteration 1398 : loss : 0.055198, loss_ce: 0.024777
2021-12-02 23:10:32,714 iteration 1399 : loss : 0.044719, loss_ce: 0.019842
2021-12-02 23:10:34,116 iteration 1400 : loss : 0.040624, loss_ce: 0.014570
2021-12-02 23:10:35,666 iteration 1401 : loss : 0.054824, loss_ce: 0.017838
2021-12-02 23:10:37,135 iteration 1402 : loss : 0.073445, loss_ce: 0.027062
2021-12-02 23:10:38,560 iteration 1403 : loss : 0.046059, loss_ce: 0.014615
2021-12-02 23:10:39,994 iteration 1404 : loss : 0.030800, loss_ce: 0.013217
2021-12-02 23:10:41,478 iteration 1405 : loss : 0.059507, loss_ce: 0.021187
2021-12-02 23:10:42,946 iteration 1406 : loss : 0.054011, loss_ce: 0.017782
2021-12-02 23:10:44,452 iteration 1407 : loss : 0.030554, loss_ce: 0.012347
2021-12-02 23:10:45,927 iteration 1408 : loss : 0.040421, loss_ce: 0.014214
2021-12-02 23:10:47,402 iteration 1409 : loss : 0.057863, loss_ce: 0.019038
2021-12-02 23:10:48,924 iteration 1410 : loss : 0.045224, loss_ce: 0.019083
2021-12-02 23:10:50,359 iteration 1411 : loss : 0.043396, loss_ce: 0.014121
 21%|██████▏                       | 83/400 [37:44<2:19:26, 26.39s/it]2021-12-02 23:10:51,848 iteration 1412 : loss : 0.047975, loss_ce: 0.018031
2021-12-02 23:10:53,359 iteration 1413 : loss : 0.060710, loss_ce: 0.020177
2021-12-02 23:10:54,795 iteration 1414 : loss : 0.038085, loss_ce: 0.013905
2021-12-02 23:10:56,298 iteration 1415 : loss : 0.045913, loss_ce: 0.012396
2021-12-02 23:10:57,769 iteration 1416 : loss : 0.037222, loss_ce: 0.015438
2021-12-02 23:10:59,258 iteration 1417 : loss : 0.055119, loss_ce: 0.019657
2021-12-02 23:11:00,709 iteration 1418 : loss : 0.045999, loss_ce: 0.020968
2021-12-02 23:11:02,119 iteration 1419 : loss : 0.040114, loss_ce: 0.014224
2021-12-02 23:11:03,628 iteration 1420 : loss : 0.050062, loss_ce: 0.017335
2021-12-02 23:11:05,167 iteration 1421 : loss : 0.063274, loss_ce: 0.027000
2021-12-02 23:11:06,655 iteration 1422 : loss : 0.042988, loss_ce: 0.015158
2021-12-02 23:11:08,075 iteration 1423 : loss : 0.054744, loss_ce: 0.021803
2021-12-02 23:11:09,570 iteration 1424 : loss : 0.042704, loss_ce: 0.018439
2021-12-02 23:11:11,069 iteration 1425 : loss : 0.032127, loss_ce: 0.011863
2021-12-02 23:11:12,500 iteration 1426 : loss : 0.047079, loss_ce: 0.019876
2021-12-02 23:11:13,962 iteration 1427 : loss : 0.049449, loss_ce: 0.022226
2021-12-02 23:11:15,348 iteration 1428 : loss : 0.049789, loss_ce: 0.017939
 21%|██████▎                       | 84/400 [38:09<2:16:51, 25.99s/it]2021-12-02 23:11:16,978 iteration 1429 : loss : 0.046264, loss_ce: 0.021083
2021-12-02 23:11:18,400 iteration 1430 : loss : 0.109522, loss_ce: 0.027502
2021-12-02 23:11:19,871 iteration 1431 : loss : 0.049655, loss_ce: 0.023567
2021-12-02 23:11:21,349 iteration 1432 : loss : 0.051691, loss_ce: 0.023027
2021-12-02 23:11:22,860 iteration 1433 : loss : 0.048886, loss_ce: 0.017369
2021-12-02 23:11:24,317 iteration 1434 : loss : 0.047990, loss_ce: 0.018861
2021-12-02 23:11:25,814 iteration 1435 : loss : 0.046414, loss_ce: 0.019075
2021-12-02 23:11:27,320 iteration 1436 : loss : 0.066785, loss_ce: 0.026770
2021-12-02 23:11:28,831 iteration 1437 : loss : 0.051384, loss_ce: 0.017131
2021-12-02 23:11:30,308 iteration 1438 : loss : 0.053828, loss_ce: 0.027596
2021-12-02 23:11:31,820 iteration 1439 : loss : 0.044087, loss_ce: 0.017970
2021-12-02 23:11:33,325 iteration 1440 : loss : 0.046606, loss_ce: 0.023452
2021-12-02 23:11:34,776 iteration 1441 : loss : 0.037189, loss_ce: 0.016024
2021-12-02 23:11:36,265 iteration 1442 : loss : 0.041354, loss_ce: 0.016297
2021-12-02 23:11:37,764 iteration 1443 : loss : 0.059393, loss_ce: 0.021201
2021-12-02 23:11:39,235 iteration 1444 : loss : 0.090684, loss_ce: 0.024731
2021-12-02 23:11:39,235 Training Data Eval:
2021-12-02 23:11:46,664   Average segmentation loss on training set: 0.0373
2021-12-02 23:11:46,664 Validation Data Eval:
2021-12-02 23:11:49,255   Average segmentation loss on validation set: 0.0931
2021-12-02 23:11:50,740 iteration 1445 : loss : 0.045668, loss_ce: 0.014081
 21%|██████▍                       | 85/400 [38:44<2:31:09, 28.79s/it]2021-12-02 23:11:52,344 iteration 1446 : loss : 0.044630, loss_ce: 0.015807
2021-12-02 23:11:53,808 iteration 1447 : loss : 0.046451, loss_ce: 0.015186
2021-12-02 23:11:55,225 iteration 1448 : loss : 0.047321, loss_ce: 0.025820
2021-12-02 23:11:56,727 iteration 1449 : loss : 0.046342, loss_ce: 0.014702
2021-12-02 23:11:58,283 iteration 1450 : loss : 0.055977, loss_ce: 0.027798
2021-12-02 23:11:59,839 iteration 1451 : loss : 0.051004, loss_ce: 0.019793
2021-12-02 23:12:01,273 iteration 1452 : loss : 0.044348, loss_ce: 0.013635
2021-12-02 23:12:02,718 iteration 1453 : loss : 0.047348, loss_ce: 0.018290
2021-12-02 23:12:04,209 iteration 1454 : loss : 0.051177, loss_ce: 0.015080
2021-12-02 23:12:05,661 iteration 1455 : loss : 0.038730, loss_ce: 0.017224
2021-12-02 23:12:07,214 iteration 1456 : loss : 0.086253, loss_ce: 0.029655
2021-12-02 23:12:08,680 iteration 1457 : loss : 0.046712, loss_ce: 0.019296
2021-12-02 23:12:10,124 iteration 1458 : loss : 0.046900, loss_ce: 0.015511
2021-12-02 23:12:11,550 iteration 1459 : loss : 0.039118, loss_ce: 0.010182
2021-12-02 23:12:13,084 iteration 1460 : loss : 0.075075, loss_ce: 0.031946
2021-12-02 23:12:14,577 iteration 1461 : loss : 0.051989, loss_ce: 0.020815
2021-12-02 23:12:16,110 iteration 1462 : loss : 0.042833, loss_ce: 0.018341
 22%|██████▍                       | 86/400 [39:10<2:25:18, 27.77s/it]2021-12-02 23:12:17,623 iteration 1463 : loss : 0.041485, loss_ce: 0.017576
2021-12-02 23:12:19,061 iteration 1464 : loss : 0.045540, loss_ce: 0.019209
2021-12-02 23:12:20,552 iteration 1465 : loss : 0.059150, loss_ce: 0.015776
2021-12-02 23:12:22,049 iteration 1466 : loss : 0.038426, loss_ce: 0.014708
2021-12-02 23:12:23,534 iteration 1467 : loss : 0.047721, loss_ce: 0.021807
2021-12-02 23:12:24,986 iteration 1468 : loss : 0.039591, loss_ce: 0.019746
2021-12-02 23:12:26,448 iteration 1469 : loss : 0.043247, loss_ce: 0.016464
2021-12-02 23:12:27,955 iteration 1470 : loss : 0.051597, loss_ce: 0.018191
2021-12-02 23:12:29,457 iteration 1471 : loss : 0.065091, loss_ce: 0.040346
2021-12-02 23:12:30,850 iteration 1472 : loss : 0.030860, loss_ce: 0.011021
2021-12-02 23:12:32,406 iteration 1473 : loss : 0.040107, loss_ce: 0.015249
2021-12-02 23:12:33,910 iteration 1474 : loss : 0.057690, loss_ce: 0.020064
2021-12-02 23:12:35,372 iteration 1475 : loss : 0.044754, loss_ce: 0.021910
2021-12-02 23:12:36,920 iteration 1476 : loss : 0.070078, loss_ce: 0.022969
2021-12-02 23:12:38,422 iteration 1477 : loss : 0.039747, loss_ce: 0.012570
2021-12-02 23:12:39,951 iteration 1478 : loss : 0.050408, loss_ce: 0.020682
2021-12-02 23:12:41,366 iteration 1479 : loss : 0.054737, loss_ce: 0.018815
 22%|██████▌                       | 87/400 [39:35<2:20:55, 27.01s/it]2021-12-02 23:12:42,886 iteration 1480 : loss : 0.043808, loss_ce: 0.015342
2021-12-02 23:12:44,336 iteration 1481 : loss : 0.035951, loss_ce: 0.014144
2021-12-02 23:12:45,797 iteration 1482 : loss : 0.040269, loss_ce: 0.015064
2021-12-02 23:12:47,332 iteration 1483 : loss : 0.051994, loss_ce: 0.018192
2021-12-02 23:12:48,919 iteration 1484 : loss : 0.061720, loss_ce: 0.025798
2021-12-02 23:12:50,439 iteration 1485 : loss : 0.040468, loss_ce: 0.016641
2021-12-02 23:12:51,896 iteration 1486 : loss : 0.038905, loss_ce: 0.017274
2021-12-02 23:12:53,368 iteration 1487 : loss : 0.037492, loss_ce: 0.016710
2021-12-02 23:12:54,852 iteration 1488 : loss : 0.034429, loss_ce: 0.014800
2021-12-02 23:12:56,347 iteration 1489 : loss : 0.028457, loss_ce: 0.011110
2021-12-02 23:12:57,854 iteration 1490 : loss : 0.069678, loss_ce: 0.026801
2021-12-02 23:12:59,389 iteration 1491 : loss : 0.064652, loss_ce: 0.027494
2021-12-02 23:13:00,829 iteration 1492 : loss : 0.040829, loss_ce: 0.015342
2021-12-02 23:13:02,339 iteration 1493 : loss : 0.059968, loss_ce: 0.022559
2021-12-02 23:13:03,772 iteration 1494 : loss : 0.044739, loss_ce: 0.016198
2021-12-02 23:13:05,218 iteration 1495 : loss : 0.047901, loss_ce: 0.020082
2021-12-02 23:13:06,686 iteration 1496 : loss : 0.070435, loss_ce: 0.020315
 22%|██████▌                       | 88/400 [40:00<2:17:49, 26.50s/it]2021-12-02 23:13:08,167 iteration 1497 : loss : 0.051798, loss_ce: 0.025404
2021-12-02 23:13:09,622 iteration 1498 : loss : 0.052491, loss_ce: 0.016702
2021-12-02 23:13:11,111 iteration 1499 : loss : 0.049838, loss_ce: 0.023137
2021-12-02 23:13:12,523 iteration 1500 : loss : 0.051650, loss_ce: 0.021336
2021-12-02 23:13:13,981 iteration 1501 : loss : 0.047584, loss_ce: 0.017373
2021-12-02 23:13:15,478 iteration 1502 : loss : 0.054320, loss_ce: 0.018335
2021-12-02 23:13:16,929 iteration 1503 : loss : 0.035943, loss_ce: 0.015345
2021-12-02 23:13:18,382 iteration 1504 : loss : 0.040554, loss_ce: 0.012207
2021-12-02 23:13:19,806 iteration 1505 : loss : 0.052025, loss_ce: 0.021759
2021-12-02 23:13:21,284 iteration 1506 : loss : 0.044749, loss_ce: 0.016600
2021-12-02 23:13:22,762 iteration 1507 : loss : 0.051909, loss_ce: 0.016349
2021-12-02 23:13:24,211 iteration 1508 : loss : 0.058018, loss_ce: 0.023867
2021-12-02 23:13:25,669 iteration 1509 : loss : 0.046012, loss_ce: 0.015427
2021-12-02 23:13:27,102 iteration 1510 : loss : 0.027808, loss_ce: 0.010246
2021-12-02 23:13:28,599 iteration 1511 : loss : 0.043743, loss_ce: 0.019876
2021-12-02 23:13:30,041 iteration 1512 : loss : 0.042985, loss_ce: 0.018818
2021-12-02 23:13:31,520 iteration 1513 : loss : 0.051206, loss_ce: 0.028503
 22%|██████▋                       | 89/400 [40:25<2:14:46, 26.00s/it]2021-12-02 23:13:33,018 iteration 1514 : loss : 0.049614, loss_ce: 0.017255
2021-12-02 23:13:34,492 iteration 1515 : loss : 0.049340, loss_ce: 0.020009
2021-12-02 23:13:35,971 iteration 1516 : loss : 0.042048, loss_ce: 0.015860
2021-12-02 23:13:37,408 iteration 1517 : loss : 0.036107, loss_ce: 0.016139
2021-12-02 23:13:38,887 iteration 1518 : loss : 0.044172, loss_ce: 0.014815
2021-12-02 23:13:40,325 iteration 1519 : loss : 0.041388, loss_ce: 0.013883
2021-12-02 23:13:41,780 iteration 1520 : loss : 0.037884, loss_ce: 0.011826
2021-12-02 23:13:43,244 iteration 1521 : loss : 0.042795, loss_ce: 0.014061
2021-12-02 23:13:44,818 iteration 1522 : loss : 0.045888, loss_ce: 0.014233
2021-12-02 23:13:46,240 iteration 1523 : loss : 0.037524, loss_ce: 0.016465
2021-12-02 23:13:47,714 iteration 1524 : loss : 0.046409, loss_ce: 0.017639
2021-12-02 23:13:49,125 iteration 1525 : loss : 0.035275, loss_ce: 0.015065
2021-12-02 23:13:50,646 iteration 1526 : loss : 0.040270, loss_ce: 0.017609
2021-12-02 23:13:52,172 iteration 1527 : loss : 0.052506, loss_ce: 0.021704
2021-12-02 23:13:53,677 iteration 1528 : loss : 0.046233, loss_ce: 0.016724
2021-12-02 23:13:55,129 iteration 1529 : loss : 0.045724, loss_ce: 0.017611
2021-12-02 23:13:55,129 Training Data Eval:
2021-12-02 23:14:02,538   Average segmentation loss on training set: 0.0301
2021-12-02 23:14:02,539 Validation Data Eval:
2021-12-02 23:14:05,098   Average segmentation loss on validation set: 0.1011
2021-12-02 23:14:06,570 iteration 1530 : loss : 0.048085, loss_ce: 0.022915
 22%|██████▊                       | 90/400 [41:00<2:28:23, 28.72s/it]2021-12-02 23:14:08,212 iteration 1531 : loss : 0.047497, loss_ce: 0.016495
2021-12-02 23:14:09,719 iteration 1532 : loss : 0.042355, loss_ce: 0.015506
2021-12-02 23:14:11,152 iteration 1533 : loss : 0.033456, loss_ce: 0.015198
2021-12-02 23:14:12,657 iteration 1534 : loss : 0.054302, loss_ce: 0.020675
2021-12-02 23:14:14,105 iteration 1535 : loss : 0.045977, loss_ce: 0.017350
2021-12-02 23:14:15,558 iteration 1536 : loss : 0.062559, loss_ce: 0.031813
2021-12-02 23:14:17,017 iteration 1537 : loss : 0.052783, loss_ce: 0.016710
2021-12-02 23:14:18,456 iteration 1538 : loss : 0.125332, loss_ce: 0.026684
2021-12-02 23:14:19,939 iteration 1539 : loss : 0.044159, loss_ce: 0.016449
2021-12-02 23:14:21,420 iteration 1540 : loss : 0.052278, loss_ce: 0.023273
2021-12-02 23:14:22,831 iteration 1541 : loss : 0.034623, loss_ce: 0.011629
2021-12-02 23:14:24,317 iteration 1542 : loss : 0.049517, loss_ce: 0.022998
2021-12-02 23:14:25,785 iteration 1543 : loss : 0.041350, loss_ce: 0.014485
2021-12-02 23:14:27,208 iteration 1544 : loss : 0.042020, loss_ce: 0.016107
2021-12-02 23:14:28,666 iteration 1545 : loss : 0.053672, loss_ce: 0.022647
2021-12-02 23:14:30,121 iteration 1546 : loss : 0.044785, loss_ce: 0.018245
2021-12-02 23:14:31,556 iteration 1547 : loss : 0.062399, loss_ce: 0.022676
 23%|██████▊                       | 91/400 [41:25<2:22:07, 27.60s/it]2021-12-02 23:14:33,083 iteration 1548 : loss : 0.037176, loss_ce: 0.013310
2021-12-02 23:14:34,493 iteration 1549 : loss : 0.034899, loss_ce: 0.015182
2021-12-02 23:14:36,050 iteration 1550 : loss : 0.055748, loss_ce: 0.024655
2021-12-02 23:14:37,504 iteration 1551 : loss : 0.039642, loss_ce: 0.014598
2021-12-02 23:14:38,975 iteration 1552 : loss : 0.033483, loss_ce: 0.014987
2021-12-02 23:14:40,384 iteration 1553 : loss : 0.032740, loss_ce: 0.016676
2021-12-02 23:14:41,819 iteration 1554 : loss : 0.055203, loss_ce: 0.022302
2021-12-02 23:14:43,329 iteration 1555 : loss : 0.044578, loss_ce: 0.015981
2021-12-02 23:14:44,881 iteration 1556 : loss : 0.055390, loss_ce: 0.019651
2021-12-02 23:14:46,398 iteration 1557 : loss : 0.073292, loss_ce: 0.017479
2021-12-02 23:14:47,856 iteration 1558 : loss : 0.052667, loss_ce: 0.014286
2021-12-02 23:14:49,394 iteration 1559 : loss : 0.054011, loss_ce: 0.026328
2021-12-02 23:14:50,835 iteration 1560 : loss : 0.041093, loss_ce: 0.012377
2021-12-02 23:14:52,289 iteration 1561 : loss : 0.050263, loss_ce: 0.018919
2021-12-02 23:14:53,774 iteration 1562 : loss : 0.041777, loss_ce: 0.018251
2021-12-02 23:14:55,238 iteration 1563 : loss : 0.053541, loss_ce: 0.026063
2021-12-02 23:14:56,707 iteration 1564 : loss : 0.048489, loss_ce: 0.019386
 23%|██████▉                       | 92/400 [41:50<2:17:54, 26.86s/it]2021-12-02 23:14:58,248 iteration 1565 : loss : 0.038213, loss_ce: 0.015406
2021-12-02 23:14:59,693 iteration 1566 : loss : 0.054127, loss_ce: 0.026600
2021-12-02 23:15:01,227 iteration 1567 : loss : 0.059943, loss_ce: 0.019962
2021-12-02 23:15:02,792 iteration 1568 : loss : 0.049771, loss_ce: 0.022311
2021-12-02 23:15:04,244 iteration 1569 : loss : 0.039015, loss_ce: 0.015122
2021-12-02 23:15:05,719 iteration 1570 : loss : 0.032215, loss_ce: 0.012442
2021-12-02 23:15:07,176 iteration 1571 : loss : 0.050156, loss_ce: 0.020761
2021-12-02 23:15:08,631 iteration 1572 : loss : 0.065175, loss_ce: 0.028750
2021-12-02 23:15:10,108 iteration 1573 : loss : 0.055961, loss_ce: 0.016803
2021-12-02 23:15:11,574 iteration 1574 : loss : 0.048689, loss_ce: 0.022829
2021-12-02 23:15:13,053 iteration 1575 : loss : 0.058794, loss_ce: 0.026595
2021-12-02 23:15:14,498 iteration 1576 : loss : 0.037979, loss_ce: 0.012694
2021-12-02 23:15:15,917 iteration 1577 : loss : 0.083231, loss_ce: 0.028152
2021-12-02 23:15:17,308 iteration 1578 : loss : 0.036865, loss_ce: 0.015610
2021-12-02 23:15:18,771 iteration 1579 : loss : 0.036063, loss_ce: 0.013301
2021-12-02 23:15:20,248 iteration 1580 : loss : 0.047652, loss_ce: 0.016122
2021-12-02 23:15:21,743 iteration 1581 : loss : 0.035352, loss_ce: 0.015118
 23%|██████▉                       | 93/400 [42:15<2:14:39, 26.32s/it]2021-12-02 23:15:23,296 iteration 1582 : loss : 0.046119, loss_ce: 0.020628
2021-12-02 23:15:24,758 iteration 1583 : loss : 0.059296, loss_ce: 0.016416
2021-12-02 23:15:26,182 iteration 1584 : loss : 0.044290, loss_ce: 0.015841
2021-12-02 23:15:27,640 iteration 1585 : loss : 0.034984, loss_ce: 0.016040
2021-12-02 23:15:29,059 iteration 1586 : loss : 0.030552, loss_ce: 0.013884
2021-12-02 23:15:30,523 iteration 1587 : loss : 0.042274, loss_ce: 0.014917
2021-12-02 23:15:31,983 iteration 1588 : loss : 0.040317, loss_ce: 0.011797
2021-12-02 23:15:33,465 iteration 1589 : loss : 0.054095, loss_ce: 0.024094
2021-12-02 23:15:35,001 iteration 1590 : loss : 0.053653, loss_ce: 0.018275
2021-12-02 23:15:36,433 iteration 1591 : loss : 0.049508, loss_ce: 0.025334
2021-12-02 23:15:37,825 iteration 1592 : loss : 0.035581, loss_ce: 0.015521
2021-12-02 23:15:39,286 iteration 1593 : loss : 0.051902, loss_ce: 0.017026
2021-12-02 23:15:40,737 iteration 1594 : loss : 0.045897, loss_ce: 0.016089
2021-12-02 23:15:42,161 iteration 1595 : loss : 0.045472, loss_ce: 0.024399
2021-12-02 23:15:43,572 iteration 1596 : loss : 0.040619, loss_ce: 0.012526
2021-12-02 23:15:45,059 iteration 1597 : loss : 0.081860, loss_ce: 0.021727
2021-12-02 23:15:46,555 iteration 1598 : loss : 0.050031, loss_ce: 0.017953
 24%|███████                       | 94/400 [42:40<2:11:54, 25.86s/it]2021-12-02 23:15:48,110 iteration 1599 : loss : 0.043918, loss_ce: 0.020566
2021-12-02 23:15:49,556 iteration 1600 : loss : 0.036070, loss_ce: 0.017043
2021-12-02 23:15:51,037 iteration 1601 : loss : 0.041418, loss_ce: 0.015639
2021-12-02 23:15:52,505 iteration 1602 : loss : 0.051639, loss_ce: 0.017938
2021-12-02 23:15:53,950 iteration 1603 : loss : 0.039866, loss_ce: 0.015580
2021-12-02 23:15:55,382 iteration 1604 : loss : 0.045650, loss_ce: 0.012136
2021-12-02 23:15:56,837 iteration 1605 : loss : 0.042647, loss_ce: 0.014285
2021-12-02 23:15:58,309 iteration 1606 : loss : 0.031793, loss_ce: 0.012240
2021-12-02 23:15:59,760 iteration 1607 : loss : 0.047908, loss_ce: 0.020086
2021-12-02 23:16:01,279 iteration 1608 : loss : 0.053954, loss_ce: 0.026761
2021-12-02 23:16:02,722 iteration 1609 : loss : 0.040047, loss_ce: 0.016539
2021-12-02 23:16:04,263 iteration 1610 : loss : 0.041954, loss_ce: 0.017780
2021-12-02 23:16:05,803 iteration 1611 : loss : 0.042162, loss_ce: 0.022095
2021-12-02 23:16:07,354 iteration 1612 : loss : 0.035787, loss_ce: 0.012882
2021-12-02 23:16:08,815 iteration 1613 : loss : 0.038794, loss_ce: 0.013695
2021-12-02 23:16:10,330 iteration 1614 : loss : 0.045492, loss_ce: 0.020523
2021-12-02 23:16:10,330 Training Data Eval:
2021-12-02 23:16:17,737   Average segmentation loss on training set: 0.0311
2021-12-02 23:16:17,738 Validation Data Eval:
2021-12-02 23:16:20,302   Average segmentation loss on validation set: 0.0930
2021-12-02 23:16:21,832 iteration 1615 : loss : 0.050839, loss_ce: 0.017182
 24%|███████▏                      | 95/400 [43:15<2:25:50, 28.69s/it]2021-12-02 23:16:23,369 iteration 1616 : loss : 0.049718, loss_ce: 0.018953
2021-12-02 23:16:24,832 iteration 1617 : loss : 0.050796, loss_ce: 0.021096
2021-12-02 23:16:26,255 iteration 1618 : loss : 0.037381, loss_ce: 0.013879
2021-12-02 23:16:27,717 iteration 1619 : loss : 0.049289, loss_ce: 0.030004
2021-12-02 23:16:29,298 iteration 1620 : loss : 0.045114, loss_ce: 0.014563
2021-12-02 23:16:30,872 iteration 1621 : loss : 0.054172, loss_ce: 0.023163
2021-12-02 23:16:32,340 iteration 1622 : loss : 0.041305, loss_ce: 0.016871
2021-12-02 23:16:33,774 iteration 1623 : loss : 0.038580, loss_ce: 0.014448
2021-12-02 23:16:35,253 iteration 1624 : loss : 0.035486, loss_ce: 0.013737
2021-12-02 23:16:36,643 iteration 1625 : loss : 0.026678, loss_ce: 0.009432
2021-12-02 23:16:38,095 iteration 1626 : loss : 0.037509, loss_ce: 0.015403
2021-12-02 23:16:39,653 iteration 1627 : loss : 0.046363, loss_ce: 0.018287
2021-12-02 23:16:41,183 iteration 1628 : loss : 0.043566, loss_ce: 0.017661
2021-12-02 23:16:42,617 iteration 1629 : loss : 0.039841, loss_ce: 0.015524
2021-12-02 23:16:44,029 iteration 1630 : loss : 0.028219, loss_ce: 0.012017
2021-12-02 23:16:45,466 iteration 1631 : loss : 0.046099, loss_ce: 0.015591
2021-12-02 23:16:46,924 iteration 1632 : loss : 0.033989, loss_ce: 0.013630
 24%|███████▏                      | 96/400 [43:41<2:19:53, 27.61s/it]2021-12-02 23:16:48,454 iteration 1633 : loss : 0.052346, loss_ce: 0.017889
2021-12-02 23:16:49,939 iteration 1634 : loss : 0.051909, loss_ce: 0.021369
2021-12-02 23:16:51,392 iteration 1635 : loss : 0.055517, loss_ce: 0.015826
2021-12-02 23:16:52,806 iteration 1636 : loss : 0.037108, loss_ce: 0.018793
2021-12-02 23:16:54,298 iteration 1637 : loss : 0.048519, loss_ce: 0.016599
2021-12-02 23:16:55,765 iteration 1638 : loss : 0.038634, loss_ce: 0.018051
2021-12-02 23:16:57,274 iteration 1639 : loss : 0.043551, loss_ce: 0.020541
2021-12-02 23:16:58,695 iteration 1640 : loss : 0.050402, loss_ce: 0.017169
2021-12-02 23:17:00,233 iteration 1641 : loss : 0.062114, loss_ce: 0.023384
2021-12-02 23:17:01,650 iteration 1642 : loss : 0.035655, loss_ce: 0.012012
2021-12-02 23:17:03,063 iteration 1643 : loss : 0.042829, loss_ce: 0.014370
2021-12-02 23:17:04,578 iteration 1644 : loss : 0.043661, loss_ce: 0.016974
2021-12-02 23:17:06,107 iteration 1645 : loss : 0.049711, loss_ce: 0.020756
2021-12-02 23:17:07,530 iteration 1646 : loss : 0.048597, loss_ce: 0.016715
2021-12-02 23:17:08,963 iteration 1647 : loss : 0.060873, loss_ce: 0.018684
2021-12-02 23:17:10,366 iteration 1648 : loss : 0.034595, loss_ce: 0.014480
2021-12-02 23:17:11,793 iteration 1649 : loss : 0.036150, loss_ce: 0.014072
 24%|███████▎                      | 97/400 [44:05<2:15:17, 26.79s/it]2021-12-02 23:17:13,422 iteration 1650 : loss : 0.043318, loss_ce: 0.020491
2021-12-02 23:17:14,861 iteration 1651 : loss : 0.063052, loss_ce: 0.021265
2021-12-02 23:17:16,345 iteration 1652 : loss : 0.053682, loss_ce: 0.017957
2021-12-02 23:17:17,781 iteration 1653 : loss : 0.046122, loss_ce: 0.014664
2021-12-02 23:17:19,246 iteration 1654 : loss : 0.039419, loss_ce: 0.013853
2021-12-02 23:17:20,682 iteration 1655 : loss : 0.043681, loss_ce: 0.014852
2021-12-02 23:17:22,211 iteration 1656 : loss : 0.061167, loss_ce: 0.022909
2021-12-02 23:17:23,652 iteration 1657 : loss : 0.044132, loss_ce: 0.018680
2021-12-02 23:17:25,152 iteration 1658 : loss : 0.056299, loss_ce: 0.031002
2021-12-02 23:17:26,685 iteration 1659 : loss : 0.047154, loss_ce: 0.021119
2021-12-02 23:17:28,152 iteration 1660 : loss : 0.029669, loss_ce: 0.011086
2021-12-02 23:17:29,580 iteration 1661 : loss : 0.035361, loss_ce: 0.010974
2021-12-02 23:17:31,074 iteration 1662 : loss : 0.043216, loss_ce: 0.014409
2021-12-02 23:17:32,593 iteration 1663 : loss : 0.032617, loss_ce: 0.013983
2021-12-02 23:17:34,080 iteration 1664 : loss : 0.066717, loss_ce: 0.024020
2021-12-02 23:17:35,524 iteration 1665 : loss : 0.055106, loss_ce: 0.025705
2021-12-02 23:17:37,003 iteration 1666 : loss : 0.041021, loss_ce: 0.011843
 24%|███████▎                      | 98/400 [44:31<2:12:25, 26.31s/it]2021-12-02 23:17:38,464 iteration 1667 : loss : 0.040186, loss_ce: 0.020231
2021-12-02 23:17:39,984 iteration 1668 : loss : 0.054689, loss_ce: 0.017720
2021-12-02 23:17:41,490 iteration 1669 : loss : 0.039511, loss_ce: 0.013470
2021-12-02 23:17:42,899 iteration 1670 : loss : 0.031939, loss_ce: 0.010250
2021-12-02 23:17:44,319 iteration 1671 : loss : 0.036670, loss_ce: 0.015858
2021-12-02 23:17:45,833 iteration 1672 : loss : 0.044434, loss_ce: 0.015345
2021-12-02 23:17:47,321 iteration 1673 : loss : 0.035981, loss_ce: 0.010830
2021-12-02 23:17:48,874 iteration 1674 : loss : 0.047125, loss_ce: 0.018472
2021-12-02 23:17:50,308 iteration 1675 : loss : 0.065024, loss_ce: 0.018627
2021-12-02 23:17:51,828 iteration 1676 : loss : 0.051246, loss_ce: 0.025417
2021-12-02 23:17:53,330 iteration 1677 : loss : 0.073608, loss_ce: 0.016176
2021-12-02 23:17:54,832 iteration 1678 : loss : 0.046971, loss_ce: 0.020862
2021-12-02 23:17:56,281 iteration 1679 : loss : 0.053992, loss_ce: 0.019339
2021-12-02 23:17:57,785 iteration 1680 : loss : 0.046814, loss_ce: 0.022455
2021-12-02 23:17:59,250 iteration 1681 : loss : 0.062322, loss_ce: 0.023371
2021-12-02 23:18:00,716 iteration 1682 : loss : 0.052475, loss_ce: 0.022261
2021-12-02 23:18:02,162 iteration 1683 : loss : 0.036716, loss_ce: 0.017609
 25%|███████▍                      | 99/400 [44:56<2:10:16, 25.97s/it]2021-12-02 23:18:03,709 iteration 1684 : loss : 0.059629, loss_ce: 0.021147
2021-12-02 23:18:05,140 iteration 1685 : loss : 0.037135, loss_ce: 0.017775
2021-12-02 23:18:06,548 iteration 1686 : loss : 0.040094, loss_ce: 0.014181
2021-12-02 23:18:07,986 iteration 1687 : loss : 0.034645, loss_ce: 0.013446
2021-12-02 23:18:09,460 iteration 1688 : loss : 0.042588, loss_ce: 0.018488
2021-12-02 23:18:10,883 iteration 1689 : loss : 0.037189, loss_ce: 0.013419
2021-12-02 23:18:12,368 iteration 1690 : loss : 0.058658, loss_ce: 0.024675
2021-12-02 23:18:13,812 iteration 1691 : loss : 0.037708, loss_ce: 0.015921
2021-12-02 23:18:15,321 iteration 1692 : loss : 0.069474, loss_ce: 0.022985
2021-12-02 23:18:16,841 iteration 1693 : loss : 0.044369, loss_ce: 0.022255
2021-12-02 23:18:18,331 iteration 1694 : loss : 0.042549, loss_ce: 0.013719
2021-12-02 23:18:19,734 iteration 1695 : loss : 0.034583, loss_ce: 0.010553
2021-12-02 23:18:21,195 iteration 1696 : loss : 0.055388, loss_ce: 0.018619
2021-12-02 23:18:22,698 iteration 1697 : loss : 0.049169, loss_ce: 0.016726
2021-12-02 23:18:24,152 iteration 1698 : loss : 0.029510, loss_ce: 0.009497
2021-12-02 23:18:25,530 iteration 1699 : loss : 0.038857, loss_ce: 0.017450
2021-12-02 23:18:25,530 Training Data Eval:
2021-12-02 23:18:32,972   Average segmentation loss on training set: 0.0272
2021-12-02 23:18:32,972 Validation Data Eval:
2021-12-02 23:18:35,543   Average segmentation loss on validation set: 0.0914
2021-12-02 23:18:37,042 iteration 1700 : loss : 0.037408, loss_ce: 0.011116
 25%|███████▎                     | 100/400 [45:31<2:23:11, 28.64s/it]2021-12-02 23:18:38,592 iteration 1701 : loss : 0.047143, loss_ce: 0.018918
2021-12-02 23:18:40,064 iteration 1702 : loss : 0.040801, loss_ce: 0.015975
2021-12-02 23:18:41,493 iteration 1703 : loss : 0.042564, loss_ce: 0.017041
2021-12-02 23:18:43,039 iteration 1704 : loss : 0.033828, loss_ce: 0.012937
2021-12-02 23:18:44,513 iteration 1705 : loss : 0.039974, loss_ce: 0.017310
2021-12-02 23:18:45,990 iteration 1706 : loss : 0.035458, loss_ce: 0.015219
2021-12-02 23:18:47,442 iteration 1707 : loss : 0.040871, loss_ce: 0.015539
2021-12-02 23:18:48,941 iteration 1708 : loss : 0.044442, loss_ce: 0.014283
2021-12-02 23:18:50,346 iteration 1709 : loss : 0.038986, loss_ce: 0.015153
2021-12-02 23:18:51,738 iteration 1710 : loss : 0.027041, loss_ce: 0.011712
2021-12-02 23:18:53,224 iteration 1711 : loss : 0.037822, loss_ce: 0.014124
2021-12-02 23:18:54,647 iteration 1712 : loss : 0.029824, loss_ce: 0.009733
2021-12-02 23:18:56,047 iteration 1713 : loss : 0.033113, loss_ce: 0.011638
2021-12-02 23:18:57,583 iteration 1714 : loss : 0.058933, loss_ce: 0.017032
2021-12-02 23:18:59,070 iteration 1715 : loss : 0.064522, loss_ce: 0.018343
2021-12-02 23:19:00,600 iteration 1716 : loss : 0.054583, loss_ce: 0.018024
2021-12-02 23:19:02,061 iteration 1717 : loss : 0.055301, loss_ce: 0.023789
 25%|███████▎                     | 101/400 [45:56<2:17:19, 27.56s/it]2021-12-02 23:19:03,550 iteration 1718 : loss : 0.039114, loss_ce: 0.013172
2021-12-02 23:19:05,034 iteration 1719 : loss : 0.049191, loss_ce: 0.019189
2021-12-02 23:19:06,425 iteration 1720 : loss : 0.033835, loss_ce: 0.010091
2021-12-02 23:19:07,899 iteration 1721 : loss : 0.037129, loss_ce: 0.016220
2021-12-02 23:19:09,406 iteration 1722 : loss : 0.037925, loss_ce: 0.012539
2021-12-02 23:19:10,862 iteration 1723 : loss : 0.047142, loss_ce: 0.018858
2021-12-02 23:19:12,374 iteration 1724 : loss : 0.043679, loss_ce: 0.013905
2021-12-02 23:19:13,953 iteration 1725 : loss : 0.071347, loss_ce: 0.023036
2021-12-02 23:19:15,460 iteration 1726 : loss : 0.051595, loss_ce: 0.013928
2021-12-02 23:19:16,902 iteration 1727 : loss : 0.042032, loss_ce: 0.018107
2021-12-02 23:19:18,338 iteration 1728 : loss : 0.051264, loss_ce: 0.017899
2021-12-02 23:19:19,794 iteration 1729 : loss : 0.042983, loss_ce: 0.017651
2021-12-02 23:19:21,291 iteration 1730 : loss : 0.036496, loss_ce: 0.013195
2021-12-02 23:19:22,821 iteration 1731 : loss : 0.060296, loss_ce: 0.022781
2021-12-02 23:19:24,289 iteration 1732 : loss : 0.029089, loss_ce: 0.014020
2021-12-02 23:19:25,830 iteration 1733 : loss : 0.046074, loss_ce: 0.018945
2021-12-02 23:19:27,270 iteration 1734 : loss : 0.040625, loss_ce: 0.012752
 26%|███████▍                     | 102/400 [46:21<2:13:21, 26.85s/it]2021-12-02 23:19:28,750 iteration 1735 : loss : 0.048966, loss_ce: 0.019644
2021-12-02 23:19:30,205 iteration 1736 : loss : 0.036959, loss_ce: 0.015983
2021-12-02 23:19:31,660 iteration 1737 : loss : 0.029986, loss_ce: 0.011984
2021-12-02 23:19:33,099 iteration 1738 : loss : 0.040714, loss_ce: 0.014076
2021-12-02 23:19:34,646 iteration 1739 : loss : 0.043507, loss_ce: 0.020284
2021-12-02 23:19:36,154 iteration 1740 : loss : 0.059312, loss_ce: 0.023015
2021-12-02 23:19:37,614 iteration 1741 : loss : 0.046830, loss_ce: 0.015965
2021-12-02 23:19:39,167 iteration 1742 : loss : 0.042282, loss_ce: 0.019381
2021-12-02 23:19:40,607 iteration 1743 : loss : 0.038529, loss_ce: 0.010922
2021-12-02 23:19:42,087 iteration 1744 : loss : 0.032276, loss_ce: 0.012318
2021-12-02 23:19:43,682 iteration 1745 : loss : 0.058919, loss_ce: 0.032016
2021-12-02 23:19:45,134 iteration 1746 : loss : 0.027754, loss_ce: 0.011725
2021-12-02 23:19:46,590 iteration 1747 : loss : 0.034417, loss_ce: 0.014526
2021-12-02 23:19:48,053 iteration 1748 : loss : 0.037125, loss_ce: 0.015247
2021-12-02 23:19:49,504 iteration 1749 : loss : 0.036002, loss_ce: 0.012131
2021-12-02 23:19:50,915 iteration 1750 : loss : 0.029700, loss_ce: 0.012906
2021-12-02 23:19:52,482 iteration 1751 : loss : 0.045640, loss_ce: 0.016124
 26%|███████▍                     | 103/400 [46:46<2:10:27, 26.36s/it]2021-12-02 23:19:53,963 iteration 1752 : loss : 0.028401, loss_ce: 0.010152
2021-12-02 23:19:55,392 iteration 1753 : loss : 0.046826, loss_ce: 0.021522
2021-12-02 23:19:56,853 iteration 1754 : loss : 0.033921, loss_ce: 0.013436
2021-12-02 23:19:58,306 iteration 1755 : loss : 0.033685, loss_ce: 0.013145
2021-12-02 23:19:59,810 iteration 1756 : loss : 0.040920, loss_ce: 0.016693
2021-12-02 23:20:01,337 iteration 1757 : loss : 0.049440, loss_ce: 0.025617
2021-12-02 23:20:02,848 iteration 1758 : loss : 0.048253, loss_ce: 0.018439
2021-12-02 23:20:04,243 iteration 1759 : loss : 0.060985, loss_ce: 0.015915
2021-12-02 23:20:05,696 iteration 1760 : loss : 0.037698, loss_ce: 0.013438
2021-12-02 23:20:07,121 iteration 1761 : loss : 0.025974, loss_ce: 0.011382
2021-12-02 23:20:08,584 iteration 1762 : loss : 0.044457, loss_ce: 0.017632
2021-12-02 23:20:09,971 iteration 1763 : loss : 0.040421, loss_ce: 0.017001
2021-12-02 23:20:11,521 iteration 1764 : loss : 0.031236, loss_ce: 0.009077
2021-12-02 23:20:12,988 iteration 1765 : loss : 0.050048, loss_ce: 0.019110
2021-12-02 23:20:14,510 iteration 1766 : loss : 0.034204, loss_ce: 0.012830
2021-12-02 23:20:15,987 iteration 1767 : loss : 0.044664, loss_ce: 0.016381
2021-12-02 23:20:17,441 iteration 1768 : loss : 0.047944, loss_ce: 0.018526
 26%|███████▌                     | 104/400 [47:11<2:07:58, 25.94s/it]2021-12-02 23:20:18,993 iteration 1769 : loss : 0.041390, loss_ce: 0.016069
2021-12-02 23:20:20,452 iteration 1770 : loss : 0.028466, loss_ce: 0.009168
2021-12-02 23:20:21,873 iteration 1771 : loss : 0.027872, loss_ce: 0.008508
2021-12-02 23:20:23,386 iteration 1772 : loss : 0.052118, loss_ce: 0.022610
2021-12-02 23:20:24,865 iteration 1773 : loss : 0.039210, loss_ce: 0.016222
2021-12-02 23:20:26,307 iteration 1774 : loss : 0.042510, loss_ce: 0.013775
2021-12-02 23:20:27,765 iteration 1775 : loss : 0.035606, loss_ce: 0.011983
2021-12-02 23:20:29,211 iteration 1776 : loss : 0.045018, loss_ce: 0.014217
2021-12-02 23:20:30,638 iteration 1777 : loss : 0.036130, loss_ce: 0.014066
2021-12-02 23:20:32,130 iteration 1778 : loss : 0.040469, loss_ce: 0.016818
2021-12-02 23:20:33,585 iteration 1779 : loss : 0.051122, loss_ce: 0.024442
2021-12-02 23:20:35,086 iteration 1780 : loss : 0.064405, loss_ce: 0.015912
2021-12-02 23:20:36,578 iteration 1781 : loss : 0.059026, loss_ce: 0.020493
2021-12-02 23:20:37,985 iteration 1782 : loss : 0.043186, loss_ce: 0.013202
2021-12-02 23:20:39,427 iteration 1783 : loss : 0.036629, loss_ce: 0.016294
2021-12-02 23:20:40,929 iteration 1784 : loss : 0.043252, loss_ce: 0.021753
2021-12-02 23:20:40,930 Training Data Eval:
2021-12-02 23:20:48,342   Average segmentation loss on training set: 0.0337
2021-12-02 23:20:48,342 Validation Data Eval:
2021-12-02 23:20:50,911   Average segmentation loss on validation set: 0.0777
2021-12-02 23:20:52,385 iteration 1785 : loss : 0.032451, loss_ce: 0.017429
 26%|███████▌                     | 105/400 [47:46<2:20:49, 28.64s/it]2021-12-02 23:20:53,945 iteration 1786 : loss : 0.052062, loss_ce: 0.017659
2021-12-02 23:20:55,358 iteration 1787 : loss : 0.037974, loss_ce: 0.010641
2021-12-02 23:20:56,849 iteration 1788 : loss : 0.032277, loss_ce: 0.012451
2021-12-02 23:20:58,329 iteration 1789 : loss : 0.039478, loss_ce: 0.016766
2021-12-02 23:20:59,927 iteration 1790 : loss : 0.038745, loss_ce: 0.013437
2021-12-02 23:21:01,402 iteration 1791 : loss : 0.045919, loss_ce: 0.024312
2021-12-02 23:21:02,886 iteration 1792 : loss : 0.031180, loss_ce: 0.011635
2021-12-02 23:21:04,383 iteration 1793 : loss : 0.052654, loss_ce: 0.021911
2021-12-02 23:21:05,837 iteration 1794 : loss : 0.046765, loss_ce: 0.025619
2021-12-02 23:21:07,229 iteration 1795 : loss : 0.029708, loss_ce: 0.011338
2021-12-02 23:21:08,768 iteration 1796 : loss : 0.037749, loss_ce: 0.016619
2021-12-02 23:21:10,182 iteration 1797 : loss : 0.047654, loss_ce: 0.021602
2021-12-02 23:21:11,646 iteration 1798 : loss : 0.038682, loss_ce: 0.015159
2021-12-02 23:21:13,177 iteration 1799 : loss : 0.034406, loss_ce: 0.013546
2021-12-02 23:21:14,601 iteration 1800 : loss : 0.044491, loss_ce: 0.015184
2021-12-02 23:21:16,066 iteration 1801 : loss : 0.048322, loss_ce: 0.019281
2021-12-02 23:21:17,574 iteration 1802 : loss : 0.046073, loss_ce: 0.015897
 26%|███████▋                     | 106/400 [48:11<2:15:15, 27.60s/it]2021-12-02 23:21:19,164 iteration 1803 : loss : 0.045840, loss_ce: 0.015903
2021-12-02 23:21:20,570 iteration 1804 : loss : 0.036711, loss_ce: 0.011704
2021-12-02 23:21:22,150 iteration 1805 : loss : 0.049381, loss_ce: 0.014803
2021-12-02 23:21:23,685 iteration 1806 : loss : 0.049980, loss_ce: 0.022705
2021-12-02 23:21:25,135 iteration 1807 : loss : 0.035353, loss_ce: 0.014994
2021-12-02 23:21:26,603 iteration 1808 : loss : 0.031769, loss_ce: 0.013530
2021-12-02 23:21:28,035 iteration 1809 : loss : 0.040225, loss_ce: 0.018059
2021-12-02 23:21:29,537 iteration 1810 : loss : 0.050182, loss_ce: 0.024228
2021-12-02 23:21:30,998 iteration 1811 : loss : 0.039076, loss_ce: 0.013479
2021-12-02 23:21:32,464 iteration 1812 : loss : 0.037866, loss_ce: 0.012203
2021-12-02 23:21:33,906 iteration 1813 : loss : 0.049039, loss_ce: 0.023752
2021-12-02 23:21:35,349 iteration 1814 : loss : 0.026859, loss_ce: 0.009982
2021-12-02 23:21:36,893 iteration 1815 : loss : 0.054462, loss_ce: 0.016706
2021-12-02 23:21:38,379 iteration 1816 : loss : 0.036666, loss_ce: 0.014984
2021-12-02 23:21:39,905 iteration 1817 : loss : 0.053105, loss_ce: 0.020207
2021-12-02 23:21:41,322 iteration 1818 : loss : 0.028242, loss_ce: 0.009729
2021-12-02 23:21:42,842 iteration 1819 : loss : 0.047586, loss_ce: 0.020392
 27%|███████▊                     | 107/400 [48:37<2:11:23, 26.91s/it]2021-12-02 23:21:44,284 iteration 1820 : loss : 0.032543, loss_ce: 0.013976
2021-12-02 23:21:45,844 iteration 1821 : loss : 0.043124, loss_ce: 0.014953
2021-12-02 23:21:47,347 iteration 1822 : loss : 0.050693, loss_ce: 0.025479
2021-12-02 23:21:48,877 iteration 1823 : loss : 0.051602, loss_ce: 0.017550
2021-12-02 23:21:50,363 iteration 1824 : loss : 0.045508, loss_ce: 0.013319
2021-12-02 23:21:51,765 iteration 1825 : loss : 0.040527, loss_ce: 0.015005
2021-12-02 23:21:53,289 iteration 1826 : loss : 0.040980, loss_ce: 0.013566
2021-12-02 23:21:54,714 iteration 1827 : loss : 0.030986, loss_ce: 0.011479
2021-12-02 23:21:56,189 iteration 1828 : loss : 0.039666, loss_ce: 0.014785
2021-12-02 23:21:57,620 iteration 1829 : loss : 0.047108, loss_ce: 0.022242
2021-12-02 23:21:59,152 iteration 1830 : loss : 0.048319, loss_ce: 0.017645
2021-12-02 23:22:00,616 iteration 1831 : loss : 0.036282, loss_ce: 0.014944
2021-12-02 23:22:02,056 iteration 1832 : loss : 0.034179, loss_ce: 0.014197
2021-12-02 23:22:03,475 iteration 1833 : loss : 0.039485, loss_ce: 0.016362
2021-12-02 23:22:04,955 iteration 1834 : loss : 0.041595, loss_ce: 0.014002
2021-12-02 23:22:06,433 iteration 1835 : loss : 0.030210, loss_ce: 0.011604
2021-12-02 23:22:07,877 iteration 1836 : loss : 0.051707, loss_ce: 0.018297
 27%|███████▊                     | 108/400 [49:02<2:08:12, 26.34s/it]2021-12-02 23:22:09,419 iteration 1837 : loss : 0.044956, loss_ce: 0.016155
2021-12-02 23:22:10,801 iteration 1838 : loss : 0.034425, loss_ce: 0.013177
2021-12-02 23:22:12,235 iteration 1839 : loss : 0.041185, loss_ce: 0.016082
2021-12-02 23:22:13,733 iteration 1840 : loss : 0.028978, loss_ce: 0.011772
2021-12-02 23:22:15,163 iteration 1841 : loss : 0.035008, loss_ce: 0.014098
2021-12-02 23:22:16,608 iteration 1842 : loss : 0.030567, loss_ce: 0.009031
2021-12-02 23:22:18,072 iteration 1843 : loss : 0.030618, loss_ce: 0.013830
2021-12-02 23:22:19,530 iteration 1844 : loss : 0.033023, loss_ce: 0.010482
2021-12-02 23:22:20,968 iteration 1845 : loss : 0.035034, loss_ce: 0.010661
2021-12-02 23:22:22,508 iteration 1846 : loss : 0.036709, loss_ce: 0.014069
2021-12-02 23:22:23,940 iteration 1847 : loss : 0.036657, loss_ce: 0.012238
2021-12-02 23:22:25,391 iteration 1848 : loss : 0.046179, loss_ce: 0.018403
2021-12-02 23:22:26,827 iteration 1849 : loss : 0.045987, loss_ce: 0.019754
2021-12-02 23:22:28,409 iteration 1850 : loss : 0.047290, loss_ce: 0.019400
2021-12-02 23:22:29,876 iteration 1851 : loss : 0.099763, loss_ce: 0.031496
2021-12-02 23:22:31,352 iteration 1852 : loss : 0.036961, loss_ce: 0.014658
2021-12-02 23:22:32,792 iteration 1853 : loss : 0.031330, loss_ce: 0.013183
 27%|███████▉                     | 109/400 [49:26<2:05:41, 25.92s/it]2021-12-02 23:22:34,290 iteration 1854 : loss : 0.034193, loss_ce: 0.012024
2021-12-02 23:22:35,801 iteration 1855 : loss : 0.033144, loss_ce: 0.012994
2021-12-02 23:22:37,314 iteration 1856 : loss : 0.036951, loss_ce: 0.012101
2021-12-02 23:22:38,840 iteration 1857 : loss : 0.030942, loss_ce: 0.012641
2021-12-02 23:22:40,315 iteration 1858 : loss : 0.042489, loss_ce: 0.017493
2021-12-02 23:22:41,796 iteration 1859 : loss : 0.042561, loss_ce: 0.017680
2021-12-02 23:22:43,224 iteration 1860 : loss : 0.037656, loss_ce: 0.012463
2021-12-02 23:22:44,765 iteration 1861 : loss : 0.033146, loss_ce: 0.013075
2021-12-02 23:22:46,216 iteration 1862 : loss : 0.029625, loss_ce: 0.012760
2021-12-02 23:22:47,700 iteration 1863 : loss : 0.061504, loss_ce: 0.034818
2021-12-02 23:22:49,189 iteration 1864 : loss : 0.054703, loss_ce: 0.013126
2021-12-02 23:22:50,567 iteration 1865 : loss : 0.028948, loss_ce: 0.012967
2021-12-02 23:22:52,098 iteration 1866 : loss : 0.029379, loss_ce: 0.013857
2021-12-02 23:22:53,562 iteration 1867 : loss : 0.027715, loss_ce: 0.012384
2021-12-02 23:22:54,984 iteration 1868 : loss : 0.040762, loss_ce: 0.015863
2021-12-02 23:22:56,410 iteration 1869 : loss : 0.063390, loss_ce: 0.020602
2021-12-02 23:22:56,410 Training Data Eval:
2021-12-02 23:23:03,832   Average segmentation loss on training set: 0.0286
2021-12-02 23:23:03,832 Validation Data Eval:
2021-12-02 23:23:06,408   Average segmentation loss on validation set: 0.0651
2021-12-02 23:23:08,352 Found new lowest validation loss at iteration 1869! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/UNET_RUNMC/1channel_best_val_loss.pth
2021-12-02 23:23:09,864 iteration 1870 : loss : 0.033508, loss_ce: 0.012604
 28%|███████▉                     | 110/400 [50:04<2:21:26, 29.26s/it]2021-12-02 23:23:11,368 iteration 1871 : loss : 0.053127, loss_ce: 0.019049
2021-12-02 23:23:12,869 iteration 1872 : loss : 0.050126, loss_ce: 0.014451
2021-12-02 23:23:14,224 iteration 1873 : loss : 0.033803, loss_ce: 0.012453
2021-12-02 23:23:15,687 iteration 1874 : loss : 0.051015, loss_ce: 0.023584
2021-12-02 23:23:17,046 iteration 1875 : loss : 0.039704, loss_ce: 0.013705
2021-12-02 23:23:18,560 iteration 1876 : loss : 0.037271, loss_ce: 0.009961
2021-12-02 23:23:20,059 iteration 1877 : loss : 0.072458, loss_ce: 0.028969
2021-12-02 23:23:21,495 iteration 1878 : loss : 0.030851, loss_ce: 0.013453
2021-12-02 23:23:22,926 iteration 1879 : loss : 0.032042, loss_ce: 0.012607
2021-12-02 23:23:24,411 iteration 1880 : loss : 0.040214, loss_ce: 0.021236
2021-12-02 23:23:25,884 iteration 1881 : loss : 0.048256, loss_ce: 0.017633
2021-12-02 23:23:27,317 iteration 1882 : loss : 0.035336, loss_ce: 0.012509
2021-12-02 23:23:28,721 iteration 1883 : loss : 0.036777, loss_ce: 0.011983
2021-12-02 23:23:30,234 iteration 1884 : loss : 0.038062, loss_ce: 0.015368
2021-12-02 23:23:31,631 iteration 1885 : loss : 0.032082, loss_ce: 0.012827
2021-12-02 23:23:33,177 iteration 1886 : loss : 0.032527, loss_ce: 0.014028
2021-12-02 23:23:34,724 iteration 1887 : loss : 0.036626, loss_ce: 0.016158
 28%|████████                     | 111/400 [50:28<2:14:34, 27.94s/it]2021-12-02 23:23:36,232 iteration 1888 : loss : 0.038107, loss_ce: 0.015336
2021-12-02 23:23:37,746 iteration 1889 : loss : 0.035946, loss_ce: 0.014520
2021-12-02 23:23:39,243 iteration 1890 : loss : 0.043138, loss_ce: 0.014233
2021-12-02 23:23:40,760 iteration 1891 : loss : 0.030182, loss_ce: 0.011560
2021-12-02 23:23:42,247 iteration 1892 : loss : 0.036826, loss_ce: 0.016251
2021-12-02 23:23:43,722 iteration 1893 : loss : 0.049326, loss_ce: 0.025267
2021-12-02 23:23:45,178 iteration 1894 : loss : 0.041087, loss_ce: 0.017369
2021-12-02 23:23:46,636 iteration 1895 : loss : 0.048704, loss_ce: 0.014531
2021-12-02 23:23:48,220 iteration 1896 : loss : 0.041729, loss_ce: 0.018845
2021-12-02 23:23:49,677 iteration 1897 : loss : 0.061605, loss_ce: 0.018429
2021-12-02 23:23:51,196 iteration 1898 : loss : 0.039781, loss_ce: 0.013351
2021-12-02 23:23:52,662 iteration 1899 : loss : 0.040750, loss_ce: 0.020985
2021-12-02 23:23:54,065 iteration 1900 : loss : 0.031761, loss_ce: 0.012596
2021-12-02 23:23:55,529 iteration 1901 : loss : 0.036407, loss_ce: 0.013156
2021-12-02 23:23:57,023 iteration 1902 : loss : 0.029307, loss_ce: 0.011772
2021-12-02 23:23:58,540 iteration 1903 : loss : 0.041550, loss_ce: 0.011461
2021-12-02 23:24:00,097 iteration 1904 : loss : 0.043888, loss_ce: 0.014254
 28%|████████                     | 112/400 [50:54<2:10:24, 27.17s/it]2021-12-02 23:24:01,568 iteration 1905 : loss : 0.030647, loss_ce: 0.012747
2021-12-02 23:24:03,083 iteration 1906 : loss : 0.046058, loss_ce: 0.016519
2021-12-02 23:24:04,637 iteration 1907 : loss : 0.036517, loss_ce: 0.013953
2021-12-02 23:24:06,131 iteration 1908 : loss : 0.034606, loss_ce: 0.013969
2021-12-02 23:24:07,651 iteration 1909 : loss : 0.049946, loss_ce: 0.027119
2021-12-02 23:24:09,169 iteration 1910 : loss : 0.028907, loss_ce: 0.012970
2021-12-02 23:24:10,735 iteration 1911 : loss : 0.038165, loss_ce: 0.012484
2021-12-02 23:24:12,224 iteration 1912 : loss : 0.057430, loss_ce: 0.020538
2021-12-02 23:24:13,684 iteration 1913 : loss : 0.032216, loss_ce: 0.011548
2021-12-02 23:24:15,120 iteration 1914 : loss : 0.031722, loss_ce: 0.013379
2021-12-02 23:24:16,612 iteration 1915 : loss : 0.055179, loss_ce: 0.018469
2021-12-02 23:24:18,075 iteration 1916 : loss : 0.042817, loss_ce: 0.015781
2021-12-02 23:24:19,559 iteration 1917 : loss : 0.045330, loss_ce: 0.016694
2021-12-02 23:24:20,990 iteration 1918 : loss : 0.037823, loss_ce: 0.015574
2021-12-02 23:24:22,447 iteration 1919 : loss : 0.032542, loss_ce: 0.013596
2021-12-02 23:24:23,927 iteration 1920 : loss : 0.032586, loss_ce: 0.011839
2021-12-02 23:24:25,441 iteration 1921 : loss : 0.053293, loss_ce: 0.017286
 28%|████████▏                    | 113/400 [51:19<2:07:20, 26.62s/it]2021-12-02 23:24:26,932 iteration 1922 : loss : 0.039630, loss_ce: 0.014306
2021-12-02 23:24:28,338 iteration 1923 : loss : 0.026359, loss_ce: 0.010181
2021-12-02 23:24:29,830 iteration 1924 : loss : 0.059457, loss_ce: 0.030474
2021-12-02 23:24:31,257 iteration 1925 : loss : 0.038685, loss_ce: 0.015226
2021-12-02 23:24:32,718 iteration 1926 : loss : 0.031405, loss_ce: 0.012954
2021-12-02 23:24:34,235 iteration 1927 : loss : 0.063697, loss_ce: 0.024275
2021-12-02 23:24:35,745 iteration 1928 : loss : 0.027299, loss_ce: 0.010509
2021-12-02 23:24:37,179 iteration 1929 : loss : 0.032342, loss_ce: 0.013395
2021-12-02 23:24:38,639 iteration 1930 : loss : 0.035183, loss_ce: 0.009803
2021-12-02 23:24:40,078 iteration 1931 : loss : 0.053892, loss_ce: 0.014956
2021-12-02 23:24:41,554 iteration 1932 : loss : 0.048319, loss_ce: 0.013677
2021-12-02 23:24:43,035 iteration 1933 : loss : 0.041213, loss_ce: 0.014563
2021-12-02 23:24:44,404 iteration 1934 : loss : 0.026790, loss_ce: 0.012177
2021-12-02 23:24:45,852 iteration 1935 : loss : 0.034901, loss_ce: 0.015671
2021-12-02 23:24:47,354 iteration 1936 : loss : 0.027051, loss_ce: 0.010428
2021-12-02 23:24:48,848 iteration 1937 : loss : 0.032046, loss_ce: 0.012054
2021-12-02 23:24:50,353 iteration 1938 : loss : 0.034369, loss_ce: 0.009328
 28%|████████▎                    | 114/400 [51:44<2:04:28, 26.11s/it]2021-12-02 23:24:51,816 iteration 1939 : loss : 0.034143, loss_ce: 0.015154
2021-12-02 23:24:53,249 iteration 1940 : loss : 0.028831, loss_ce: 0.011051
2021-12-02 23:24:54,753 iteration 1941 : loss : 0.040988, loss_ce: 0.019146
2021-12-02 23:24:56,228 iteration 1942 : loss : 0.044760, loss_ce: 0.012805
2021-12-02 23:24:57,640 iteration 1943 : loss : 0.028038, loss_ce: 0.011081
2021-12-02 23:24:59,091 iteration 1944 : loss : 0.032765, loss_ce: 0.012169
2021-12-02 23:25:00,559 iteration 1945 : loss : 0.030451, loss_ce: 0.014176
2021-12-02 23:25:02,015 iteration 1946 : loss : 0.039949, loss_ce: 0.014725
2021-12-02 23:25:03,461 iteration 1947 : loss : 0.034539, loss_ce: 0.012475
2021-12-02 23:25:04,894 iteration 1948 : loss : 0.036216, loss_ce: 0.014700
2021-12-02 23:25:06,305 iteration 1949 : loss : 0.033427, loss_ce: 0.017182
2021-12-02 23:25:07,818 iteration 1950 : loss : 0.043703, loss_ce: 0.016909
2021-12-02 23:25:09,367 iteration 1951 : loss : 0.056700, loss_ce: 0.024290
2021-12-02 23:25:10,779 iteration 1952 : loss : 0.043289, loss_ce: 0.013079
2021-12-02 23:25:12,253 iteration 1953 : loss : 0.044101, loss_ce: 0.022997
2021-12-02 23:25:13,778 iteration 1954 : loss : 0.047737, loss_ce: 0.016518
2021-12-02 23:25:13,778 Training Data Eval:
2021-12-02 23:25:21,174   Average segmentation loss on training set: 0.0319
2021-12-02 23:25:21,174 Validation Data Eval:
2021-12-02 23:25:23,757   Average segmentation loss on validation set: 0.0962
2021-12-02 23:25:25,232 iteration 1955 : loss : 0.030789, loss_ce: 0.011145
 29%|████████▎                    | 115/400 [52:19<2:16:31, 28.74s/it]2021-12-02 23:25:26,801 iteration 1956 : loss : 0.039061, loss_ce: 0.017106
2021-12-02 23:25:28,210 iteration 1957 : loss : 0.035506, loss_ce: 0.014245
2021-12-02 23:25:29,655 iteration 1958 : loss : 0.031678, loss_ce: 0.015384
2021-12-02 23:25:31,201 iteration 1959 : loss : 0.062185, loss_ce: 0.016102
2021-12-02 23:25:32,655 iteration 1960 : loss : 0.062248, loss_ce: 0.022676
2021-12-02 23:25:34,124 iteration 1961 : loss : 0.052509, loss_ce: 0.017662
2021-12-02 23:25:35,581 iteration 1962 : loss : 0.033151, loss_ce: 0.012115
2021-12-02 23:25:37,056 iteration 1963 : loss : 0.035750, loss_ce: 0.014616
2021-12-02 23:25:38,508 iteration 1964 : loss : 0.041027, loss_ce: 0.011724
2021-12-02 23:25:39,931 iteration 1965 : loss : 0.040146, loss_ce: 0.018707
2021-12-02 23:25:41,346 iteration 1966 : loss : 0.038820, loss_ce: 0.017328
2021-12-02 23:25:42,771 iteration 1967 : loss : 0.040109, loss_ce: 0.013077
2021-12-02 23:25:44,190 iteration 1968 : loss : 0.035235, loss_ce: 0.016606
2021-12-02 23:25:45,710 iteration 1969 : loss : 0.034538, loss_ce: 0.012270
2021-12-02 23:25:47,306 iteration 1970 : loss : 0.042065, loss_ce: 0.015299
2021-12-02 23:25:48,694 iteration 1971 : loss : 0.030476, loss_ce: 0.009410
2021-12-02 23:25:50,259 iteration 1972 : loss : 0.046634, loss_ce: 0.016889
 29%|████████▍                    | 116/400 [52:44<2:10:45, 27.63s/it]2021-12-02 23:25:51,703 iteration 1973 : loss : 0.032150, loss_ce: 0.012080
2021-12-02 23:25:53,117 iteration 1974 : loss : 0.046412, loss_ce: 0.021337
2021-12-02 23:25:54,638 iteration 1975 : loss : 0.047266, loss_ce: 0.018034
2021-12-02 23:25:56,029 iteration 1976 : loss : 0.038479, loss_ce: 0.015844
2021-12-02 23:25:57,565 iteration 1977 : loss : 0.045054, loss_ce: 0.019559
2021-12-02 23:25:58,960 iteration 1978 : loss : 0.043555, loss_ce: 0.015298
2021-12-02 23:26:00,371 iteration 1979 : loss : 0.038901, loss_ce: 0.018732
2021-12-02 23:26:01,868 iteration 1980 : loss : 0.050451, loss_ce: 0.016045
2021-12-02 23:26:03,307 iteration 1981 : loss : 0.037466, loss_ce: 0.013606
2021-12-02 23:26:04,851 iteration 1982 : loss : 0.047844, loss_ce: 0.014664
2021-12-02 23:26:06,397 iteration 1983 : loss : 0.048278, loss_ce: 0.023071
2021-12-02 23:26:07,815 iteration 1984 : loss : 0.036283, loss_ce: 0.011516
2021-12-02 23:26:09,249 iteration 1985 : loss : 0.034638, loss_ce: 0.010947
2021-12-02 23:26:10,688 iteration 1986 : loss : 0.035764, loss_ce: 0.011873
2021-12-02 23:26:12,129 iteration 1987 : loss : 0.025434, loss_ce: 0.009096
2021-12-02 23:26:13,674 iteration 1988 : loss : 0.037037, loss_ce: 0.016500
2021-12-02 23:26:15,116 iteration 1989 : loss : 0.038590, loss_ce: 0.017045
 29%|████████▍                    | 117/400 [53:09<2:06:22, 26.79s/it]2021-12-02 23:26:16,623 iteration 1990 : loss : 0.061483, loss_ce: 0.031693
2021-12-02 23:26:18,017 iteration 1991 : loss : 0.029394, loss_ce: 0.012330
2021-12-02 23:26:19,525 iteration 1992 : loss : 0.039452, loss_ce: 0.017244
2021-12-02 23:26:20,991 iteration 1993 : loss : 0.057973, loss_ce: 0.013492
2021-12-02 23:26:22,473 iteration 1994 : loss : 0.029563, loss_ce: 0.011352
2021-12-02 23:26:23,928 iteration 1995 : loss : 0.036029, loss_ce: 0.013761
2021-12-02 23:26:25,396 iteration 1996 : loss : 0.048443, loss_ce: 0.022635
2021-12-02 23:26:26,862 iteration 1997 : loss : 0.033668, loss_ce: 0.013198
2021-12-02 23:26:28,341 iteration 1998 : loss : 0.041722, loss_ce: 0.016226
2021-12-02 23:26:29,825 iteration 1999 : loss : 0.035472, loss_ce: 0.013770
2021-12-02 23:26:31,401 iteration 2000 : loss : 0.055730, loss_ce: 0.013937
2021-12-02 23:26:32,868 iteration 2001 : loss : 0.028953, loss_ce: 0.011526
2021-12-02 23:26:34,261 iteration 2002 : loss : 0.045206, loss_ce: 0.017419
2021-12-02 23:26:35,623 iteration 2003 : loss : 0.026240, loss_ce: 0.011856
2021-12-02 23:26:37,043 iteration 2004 : loss : 0.047328, loss_ce: 0.014323
2021-12-02 23:26:38,531 iteration 2005 : loss : 0.026532, loss_ce: 0.009716
2021-12-02 23:26:40,015 iteration 2006 : loss : 0.041922, loss_ce: 0.015947
 30%|████████▌                    | 118/400 [53:34<2:03:15, 26.23s/it]2021-12-02 23:26:41,584 iteration 2007 : loss : 0.032068, loss_ce: 0.012398
2021-12-02 23:26:43,165 iteration 2008 : loss : 0.046349, loss_ce: 0.014755
2021-12-02 23:26:44,636 iteration 2009 : loss : 0.037059, loss_ce: 0.016286
2021-12-02 23:26:46,094 iteration 2010 : loss : 0.042173, loss_ce: 0.016087
2021-12-02 23:26:47,645 iteration 2011 : loss : 0.039829, loss_ce: 0.014379
2021-12-02 23:26:49,121 iteration 2012 : loss : 0.030848, loss_ce: 0.015517
2021-12-02 23:26:50,519 iteration 2013 : loss : 0.031885, loss_ce: 0.012911
2021-12-02 23:26:51,976 iteration 2014 : loss : 0.050518, loss_ce: 0.017327
2021-12-02 23:26:53,488 iteration 2015 : loss : 0.040381, loss_ce: 0.015992
2021-12-02 23:26:54,961 iteration 2016 : loss : 0.046165, loss_ce: 0.017170
2021-12-02 23:26:56,466 iteration 2017 : loss : 0.037711, loss_ce: 0.013299
2021-12-02 23:26:58,021 iteration 2018 : loss : 0.039630, loss_ce: 0.016567
2021-12-02 23:26:59,465 iteration 2019 : loss : 0.038797, loss_ce: 0.012521
2021-12-02 23:27:00,900 iteration 2020 : loss : 0.033481, loss_ce: 0.011487
2021-12-02 23:27:02,390 iteration 2021 : loss : 0.039457, loss_ce: 0.014056
2021-12-02 23:27:03,880 iteration 2022 : loss : 0.040187, loss_ce: 0.020364
2021-12-02 23:27:05,383 iteration 2023 : loss : 0.047982, loss_ce: 0.015926
 30%|████████▋                    | 119/400 [53:59<2:01:36, 25.97s/it]2021-12-02 23:27:06,843 iteration 2024 : loss : 0.033293, loss_ce: 0.010462
2021-12-02 23:27:08,311 iteration 2025 : loss : 0.029906, loss_ce: 0.014424
2021-12-02 23:27:09,825 iteration 2026 : loss : 0.034075, loss_ce: 0.016194
2021-12-02 23:27:11,265 iteration 2027 : loss : 0.037012, loss_ce: 0.010494
2021-12-02 23:27:12,683 iteration 2028 : loss : 0.029607, loss_ce: 0.015227
2021-12-02 23:27:14,118 iteration 2029 : loss : 0.030539, loss_ce: 0.012594
2021-12-02 23:27:15,547 iteration 2030 : loss : 0.036467, loss_ce: 0.014536
2021-12-02 23:27:17,007 iteration 2031 : loss : 0.033867, loss_ce: 0.012502
2021-12-02 23:27:18,553 iteration 2032 : loss : 0.052846, loss_ce: 0.022724
2021-12-02 23:27:20,118 iteration 2033 : loss : 0.053130, loss_ce: 0.024312
2021-12-02 23:27:21,550 iteration 2034 : loss : 0.035983, loss_ce: 0.013766
2021-12-02 23:27:23,032 iteration 2035 : loss : 0.042596, loss_ce: 0.015007
2021-12-02 23:27:24,551 iteration 2036 : loss : 0.036408, loss_ce: 0.019746
2021-12-02 23:27:26,010 iteration 2037 : loss : 0.060260, loss_ce: 0.014379
2021-12-02 23:27:27,516 iteration 2038 : loss : 0.041653, loss_ce: 0.016526
2021-12-02 23:27:29,070 iteration 2039 : loss : 0.051824, loss_ce: 0.021353
2021-12-02 23:27:29,070 Training Data Eval:
2021-12-02 23:27:36,448   Average segmentation loss on training set: 0.0271
2021-12-02 23:27:36,448 Validation Data Eval:
2021-12-02 23:27:39,006   Average segmentation loss on validation set: 0.0817
2021-12-02 23:27:40,560 iteration 2040 : loss : 0.045739, loss_ce: 0.016020
 30%|████████▋                    | 120/400 [54:34<2:14:05, 28.73s/it]2021-12-02 23:27:42,126 iteration 2041 : loss : 0.045427, loss_ce: 0.011718
2021-12-02 23:27:43,581 iteration 2042 : loss : 0.031359, loss_ce: 0.012554
2021-12-02 23:27:45,032 iteration 2043 : loss : 0.029066, loss_ce: 0.009681
2021-12-02 23:27:46,491 iteration 2044 : loss : 0.042845, loss_ce: 0.015248
2021-12-02 23:27:47,918 iteration 2045 : loss : 0.033712, loss_ce: 0.011450
2021-12-02 23:27:49,384 iteration 2046 : loss : 0.044633, loss_ce: 0.022554
2021-12-02 23:27:50,837 iteration 2047 : loss : 0.036616, loss_ce: 0.014405
2021-12-02 23:27:52,320 iteration 2048 : loss : 0.037045, loss_ce: 0.012441
2021-12-02 23:27:53,778 iteration 2049 : loss : 0.037890, loss_ce: 0.009347
2021-12-02 23:27:55,259 iteration 2050 : loss : 0.051869, loss_ce: 0.020842
2021-12-02 23:27:56,745 iteration 2051 : loss : 0.034412, loss_ce: 0.016135
2021-12-02 23:27:58,149 iteration 2052 : loss : 0.026390, loss_ce: 0.010432
2021-12-02 23:27:59,620 iteration 2053 : loss : 0.055389, loss_ce: 0.015582
2021-12-02 23:28:01,049 iteration 2054 : loss : 0.029760, loss_ce: 0.012454
2021-12-02 23:28:02,486 iteration 2055 : loss : 0.038565, loss_ce: 0.011693
2021-12-02 23:28:03,987 iteration 2056 : loss : 0.035104, loss_ce: 0.014747
2021-12-02 23:28:05,408 iteration 2057 : loss : 0.035085, loss_ce: 0.014034
 30%|████████▊                    | 121/400 [54:59<2:08:10, 27.56s/it]2021-12-02 23:28:06,936 iteration 2058 : loss : 0.034386, loss_ce: 0.015744
2021-12-02 23:28:08,446 iteration 2059 : loss : 0.044618, loss_ce: 0.016538
2021-12-02 23:28:09,825 iteration 2060 : loss : 0.033816, loss_ce: 0.012608
2021-12-02 23:28:11,319 iteration 2061 : loss : 0.050540, loss_ce: 0.019578
2021-12-02 23:28:12,780 iteration 2062 : loss : 0.036776, loss_ce: 0.014100
2021-12-02 23:28:14,244 iteration 2063 : loss : 0.055159, loss_ce: 0.011733
2021-12-02 23:28:15,657 iteration 2064 : loss : 0.025069, loss_ce: 0.008581
2021-12-02 23:28:17,104 iteration 2065 : loss : 0.033432, loss_ce: 0.009532
2021-12-02 23:28:18,569 iteration 2066 : loss : 0.036850, loss_ce: 0.013754
2021-12-02 23:28:20,064 iteration 2067 : loss : 0.030453, loss_ce: 0.010978
2021-12-02 23:28:21,589 iteration 2068 : loss : 0.028549, loss_ce: 0.011895
2021-12-02 23:28:23,035 iteration 2069 : loss : 0.033767, loss_ce: 0.008791
2021-12-02 23:28:24,532 iteration 2070 : loss : 0.034947, loss_ce: 0.014099
2021-12-02 23:28:26,039 iteration 2071 : loss : 0.033859, loss_ce: 0.012749
2021-12-02 23:28:27,502 iteration 2072 : loss : 0.052537, loss_ce: 0.020488
2021-12-02 23:28:29,015 iteration 2073 : loss : 0.032294, loss_ce: 0.011769
2021-12-02 23:28:30,508 iteration 2074 : loss : 0.035331, loss_ce: 0.016556
 30%|████████▊                    | 122/400 [55:24<2:04:18, 26.83s/it]2021-12-02 23:28:31,994 iteration 2075 : loss : 0.025565, loss_ce: 0.008594
2021-12-02 23:28:33,466 iteration 2076 : loss : 0.035357, loss_ce: 0.010091
2021-12-02 23:28:34,960 iteration 2077 : loss : 0.032041, loss_ce: 0.012505
2021-12-02 23:28:36,538 iteration 2078 : loss : 0.041665, loss_ce: 0.012744
2021-12-02 23:28:37,979 iteration 2079 : loss : 0.032151, loss_ce: 0.011710
2021-12-02 23:28:39,493 iteration 2080 : loss : 0.040488, loss_ce: 0.015990
2021-12-02 23:28:40,874 iteration 2081 : loss : 0.029231, loss_ce: 0.010323
2021-12-02 23:28:42,252 iteration 2082 : loss : 0.023230, loss_ce: 0.008153
2021-12-02 23:28:43,723 iteration 2083 : loss : 0.038349, loss_ce: 0.019077
2021-12-02 23:28:45,178 iteration 2084 : loss : 0.045385, loss_ce: 0.020512
2021-12-02 23:28:46,605 iteration 2085 : loss : 0.033374, loss_ce: 0.009835
2021-12-02 23:28:48,056 iteration 2086 : loss : 0.040448, loss_ce: 0.016733
2021-12-02 23:28:49,479 iteration 2087 : loss : 0.035615, loss_ce: 0.013164
2021-12-02 23:28:51,001 iteration 2088 : loss : 0.027353, loss_ce: 0.010827
2021-12-02 23:28:52,504 iteration 2089 : loss : 0.031957, loss_ce: 0.014096
2021-12-02 23:28:53,920 iteration 2090 : loss : 0.029724, loss_ce: 0.012356
2021-12-02 23:28:55,425 iteration 2091 : loss : 0.038425, loss_ce: 0.018477
 31%|████████▉                    | 123/400 [55:49<2:01:12, 26.25s/it]2021-12-02 23:28:56,877 iteration 2092 : loss : 0.028097, loss_ce: 0.011810
2021-12-02 23:28:58,318 iteration 2093 : loss : 0.037550, loss_ce: 0.013868
2021-12-02 23:28:59,778 iteration 2094 : loss : 0.038758, loss_ce: 0.009823
2021-12-02 23:29:01,189 iteration 2095 : loss : 0.021631, loss_ce: 0.009271
2021-12-02 23:29:02,712 iteration 2096 : loss : 0.034224, loss_ce: 0.015719
2021-12-02 23:29:04,186 iteration 2097 : loss : 0.058658, loss_ce: 0.017953
2021-12-02 23:29:05,660 iteration 2098 : loss : 0.053955, loss_ce: 0.024344
2021-12-02 23:29:07,140 iteration 2099 : loss : 0.035529, loss_ce: 0.010666
2021-12-02 23:29:08,646 iteration 2100 : loss : 0.030965, loss_ce: 0.016050
2021-12-02 23:29:10,129 iteration 2101 : loss : 0.035274, loss_ce: 0.013039
2021-12-02 23:29:11,636 iteration 2102 : loss : 0.038579, loss_ce: 0.017792
2021-12-02 23:29:13,037 iteration 2103 : loss : 0.039893, loss_ce: 0.018445
2021-12-02 23:29:14,460 iteration 2104 : loss : 0.049378, loss_ce: 0.017209
2021-12-02 23:29:16,008 iteration 2105 : loss : 0.053658, loss_ce: 0.015321
2021-12-02 23:29:17,440 iteration 2106 : loss : 0.028887, loss_ce: 0.013823
2021-12-02 23:29:18,978 iteration 2107 : loss : 0.026968, loss_ce: 0.009245
2021-12-02 23:29:20,459 iteration 2108 : loss : 0.044626, loss_ce: 0.019167
 31%|████████▉                    | 124/400 [56:14<1:59:05, 25.89s/it]2021-12-02 23:29:21,984 iteration 2109 : loss : 0.047755, loss_ce: 0.019814
2021-12-02 23:29:23,478 iteration 2110 : loss : 0.048457, loss_ce: 0.017810
2021-12-02 23:29:25,022 iteration 2111 : loss : 0.091220, loss_ce: 0.027784
2021-12-02 23:29:26,489 iteration 2112 : loss : 0.065611, loss_ce: 0.032629
2021-12-02 23:29:27,919 iteration 2113 : loss : 0.034563, loss_ce: 0.016123
2021-12-02 23:29:29,430 iteration 2114 : loss : 0.044336, loss_ce: 0.022777
2021-12-02 23:29:30,908 iteration 2115 : loss : 0.049505, loss_ce: 0.015565
2021-12-02 23:29:32,381 iteration 2116 : loss : 0.052131, loss_ce: 0.018900
2021-12-02 23:29:33,843 iteration 2117 : loss : 0.050353, loss_ce: 0.020070
2021-12-02 23:29:35,343 iteration 2118 : loss : 0.052247, loss_ce: 0.016681
2021-12-02 23:29:36,846 iteration 2119 : loss : 0.042677, loss_ce: 0.016235
2021-12-02 23:29:38,312 iteration 2120 : loss : 0.035577, loss_ce: 0.010545
2021-12-02 23:29:39,708 iteration 2121 : loss : 0.027740, loss_ce: 0.011261
2021-12-02 23:29:41,158 iteration 2122 : loss : 0.033824, loss_ce: 0.012153
2021-12-02 23:29:42,669 iteration 2123 : loss : 0.074015, loss_ce: 0.034611
2021-12-02 23:29:44,204 iteration 2124 : loss : 0.048703, loss_ce: 0.018583
2021-12-02 23:29:44,204 Training Data Eval:
2021-12-02 23:29:51,610   Average segmentation loss on training set: 0.0287
2021-12-02 23:29:51,611 Validation Data Eval:
2021-12-02 23:29:54,175   Average segmentation loss on validation set: 0.0860
2021-12-02 23:29:55,685 iteration 2125 : loss : 0.067175, loss_ce: 0.034704
 31%|█████████                    | 125/400 [56:49<2:11:30, 28.69s/it]2021-12-02 23:29:57,275 iteration 2126 : loss : 0.036483, loss_ce: 0.015266
2021-12-02 23:29:58,765 iteration 2127 : loss : 0.050423, loss_ce: 0.024901
2021-12-02 23:30:00,236 iteration 2128 : loss : 0.050525, loss_ce: 0.016119
2021-12-02 23:30:01,664 iteration 2129 : loss : 0.045998, loss_ce: 0.015922
2021-12-02 23:30:03,169 iteration 2130 : loss : 0.066884, loss_ce: 0.020112
2021-12-02 23:30:04,621 iteration 2131 : loss : 0.048261, loss_ce: 0.013716
2021-12-02 23:30:06,083 iteration 2132 : loss : 0.027534, loss_ce: 0.010398
2021-12-02 23:30:07,613 iteration 2133 : loss : 0.051736, loss_ce: 0.016942
2021-12-02 23:30:09,003 iteration 2134 : loss : 0.038829, loss_ce: 0.018025
2021-12-02 23:30:10,472 iteration 2135 : loss : 0.044871, loss_ce: 0.014965
2021-12-02 23:30:11,929 iteration 2136 : loss : 0.045780, loss_ce: 0.018159
2021-12-02 23:30:13,399 iteration 2137 : loss : 0.058533, loss_ce: 0.024408
2021-12-02 23:30:14,837 iteration 2138 : loss : 0.048895, loss_ce: 0.018172
2021-12-02 23:30:16,340 iteration 2139 : loss : 0.041719, loss_ce: 0.021618
2021-12-02 23:30:17,806 iteration 2140 : loss : 0.045407, loss_ce: 0.022427
2021-12-02 23:30:19,332 iteration 2141 : loss : 0.069941, loss_ce: 0.022439
2021-12-02 23:30:20,758 iteration 2142 : loss : 0.045852, loss_ce: 0.014817
 32%|█████████▏                   | 126/400 [57:14<2:06:04, 27.61s/it]2021-12-02 23:30:22,217 iteration 2143 : loss : 0.034237, loss_ce: 0.012490
2021-12-02 23:30:23,717 iteration 2144 : loss : 0.040406, loss_ce: 0.011940
2021-12-02 23:30:25,210 iteration 2145 : loss : 0.047877, loss_ce: 0.014897
2021-12-02 23:30:26,631 iteration 2146 : loss : 0.025399, loss_ce: 0.009990
2021-12-02 23:30:28,111 iteration 2147 : loss : 0.050185, loss_ce: 0.017009
2021-12-02 23:30:29,567 iteration 2148 : loss : 0.036586, loss_ce: 0.013535
2021-12-02 23:30:31,054 iteration 2149 : loss : 0.044115, loss_ce: 0.016042
2021-12-02 23:30:32,503 iteration 2150 : loss : 0.029865, loss_ce: 0.013066
2021-12-02 23:30:34,020 iteration 2151 : loss : 0.046827, loss_ce: 0.019247
2021-12-02 23:30:35,442 iteration 2152 : loss : 0.027107, loss_ce: 0.010412
2021-12-02 23:30:36,854 iteration 2153 : loss : 0.033540, loss_ce: 0.012833
2021-12-02 23:30:38,434 iteration 2154 : loss : 0.052396, loss_ce: 0.021295
2021-12-02 23:30:39,895 iteration 2155 : loss : 0.041543, loss_ce: 0.014418
2021-12-02 23:30:41,310 iteration 2156 : loss : 0.052894, loss_ce: 0.024779
2021-12-02 23:30:42,895 iteration 2157 : loss : 0.060094, loss_ce: 0.019003
2021-12-02 23:30:44,438 iteration 2158 : loss : 0.048068, loss_ce: 0.024977
2021-12-02 23:30:45,900 iteration 2159 : loss : 0.048124, loss_ce: 0.013000
 32%|█████████▏                   | 127/400 [57:40<2:02:13, 26.86s/it]2021-12-02 23:30:47,374 iteration 2160 : loss : 0.032708, loss_ce: 0.012559
2021-12-02 23:30:48,784 iteration 2161 : loss : 0.029125, loss_ce: 0.009580
2021-12-02 23:30:50,219 iteration 2162 : loss : 0.041166, loss_ce: 0.016020
2021-12-02 23:30:51,642 iteration 2163 : loss : 0.030017, loss_ce: 0.011075
2021-12-02 23:30:53,136 iteration 2164 : loss : 0.034056, loss_ce: 0.015208
2021-12-02 23:30:54,621 iteration 2165 : loss : 0.056555, loss_ce: 0.022192
2021-12-02 23:30:56,047 iteration 2166 : loss : 0.037765, loss_ce: 0.016291
2021-12-02 23:30:57,432 iteration 2167 : loss : 0.033219, loss_ce: 0.011678
2021-12-02 23:30:58,884 iteration 2168 : loss : 0.028162, loss_ce: 0.012022
2021-12-02 23:31:00,381 iteration 2169 : loss : 0.048451, loss_ce: 0.017717
2021-12-02 23:31:01,755 iteration 2170 : loss : 0.028238, loss_ce: 0.009178
2021-12-02 23:31:03,204 iteration 2171 : loss : 0.033798, loss_ce: 0.013245
2021-12-02 23:31:04,645 iteration 2172 : loss : 0.044948, loss_ce: 0.014170
2021-12-02 23:31:06,085 iteration 2173 : loss : 0.035652, loss_ce: 0.008787
2021-12-02 23:31:07,558 iteration 2174 : loss : 0.038130, loss_ce: 0.015264
2021-12-02 23:31:09,088 iteration 2175 : loss : 0.026337, loss_ce: 0.010596
2021-12-02 23:31:10,458 iteration 2176 : loss : 0.033148, loss_ce: 0.015585
 32%|█████████▎                   | 128/400 [58:04<1:58:39, 26.18s/it]2021-12-02 23:31:11,911 iteration 2177 : loss : 0.047440, loss_ce: 0.023902
2021-12-02 23:31:13,371 iteration 2178 : loss : 0.028317, loss_ce: 0.010149
2021-12-02 23:31:14,923 iteration 2179 : loss : 0.032506, loss_ce: 0.009985
2021-12-02 23:31:16,435 iteration 2180 : loss : 0.038030, loss_ce: 0.014549
2021-12-02 23:31:17,821 iteration 2181 : loss : 0.029953, loss_ce: 0.010639
2021-12-02 23:31:19,279 iteration 2182 : loss : 0.036330, loss_ce: 0.012486
2021-12-02 23:31:20,759 iteration 2183 : loss : 0.049782, loss_ce: 0.013127
2021-12-02 23:31:22,160 iteration 2184 : loss : 0.037084, loss_ce: 0.017350
2021-12-02 23:31:23,579 iteration 2185 : loss : 0.031734, loss_ce: 0.011293
2021-12-02 23:31:25,109 iteration 2186 : loss : 0.037767, loss_ce: 0.015144
2021-12-02 23:31:26,645 iteration 2187 : loss : 0.040115, loss_ce: 0.013191
2021-12-02 23:31:28,226 iteration 2188 : loss : 0.038928, loss_ce: 0.020030
2021-12-02 23:31:29,797 iteration 2189 : loss : 0.053423, loss_ce: 0.017006
2021-12-02 23:31:31,272 iteration 2190 : loss : 0.032578, loss_ce: 0.015039
2021-12-02 23:31:32,758 iteration 2191 : loss : 0.037913, loss_ce: 0.013640
2021-12-02 23:31:34,201 iteration 2192 : loss : 0.040409, loss_ce: 0.015030
2021-12-02 23:31:35,684 iteration 2193 : loss : 0.036126, loss_ce: 0.011061
 32%|█████████▎                   | 129/400 [58:29<1:56:56, 25.89s/it]2021-12-02 23:31:37,213 iteration 2194 : loss : 0.040359, loss_ce: 0.015098
2021-12-02 23:31:38,674 iteration 2195 : loss : 0.036016, loss_ce: 0.018449
2021-12-02 23:31:40,192 iteration 2196 : loss : 0.028218, loss_ce: 0.012813
2021-12-02 23:31:41,737 iteration 2197 : loss : 0.035730, loss_ce: 0.013853
2021-12-02 23:31:43,205 iteration 2198 : loss : 0.054351, loss_ce: 0.017426
2021-12-02 23:31:44,680 iteration 2199 : loss : 0.043532, loss_ce: 0.019174
2021-12-02 23:31:46,218 iteration 2200 : loss : 0.094442, loss_ce: 0.018267
2021-12-02 23:31:47,634 iteration 2201 : loss : 0.029730, loss_ce: 0.011004
2021-12-02 23:31:49,203 iteration 2202 : loss : 0.050858, loss_ce: 0.022219
2021-12-02 23:31:50,684 iteration 2203 : loss : 0.039739, loss_ce: 0.015009
2021-12-02 23:31:52,090 iteration 2204 : loss : 0.034018, loss_ce: 0.009660
2021-12-02 23:31:53,588 iteration 2205 : loss : 0.056182, loss_ce: 0.029753
2021-12-02 23:31:55,133 iteration 2206 : loss : 0.055785, loss_ce: 0.022575
2021-12-02 23:31:56,617 iteration 2207 : loss : 0.039578, loss_ce: 0.011954
2021-12-02 23:31:58,135 iteration 2208 : loss : 0.061249, loss_ce: 0.017416
2021-12-02 23:31:59,601 iteration 2209 : loss : 0.065290, loss_ce: 0.026714
2021-12-02 23:31:59,601 Training Data Eval:
2021-12-02 23:32:06,982   Average segmentation loss on training set: 0.0301
2021-12-02 23:32:06,983 Validation Data Eval:
2021-12-02 23:32:09,553   Average segmentation loss on validation set: 0.0652
2021-12-02 23:32:11,077 iteration 2210 : loss : 0.042676, loss_ce: 0.021532
 32%|█████████▍                   | 130/400 [59:05<2:09:19, 28.74s/it]2021-12-02 23:32:12,615 iteration 2211 : loss : 0.031744, loss_ce: 0.009909
2021-12-02 23:32:14,046 iteration 2212 : loss : 0.036168, loss_ce: 0.017261
2021-12-02 23:32:15,533 iteration 2213 : loss : 0.047801, loss_ce: 0.012285
2021-12-02 23:32:16,947 iteration 2214 : loss : 0.030211, loss_ce: 0.010761
2021-12-02 23:32:18,349 iteration 2215 : loss : 0.028795, loss_ce: 0.010889
2021-12-02 23:32:19,776 iteration 2216 : loss : 0.040102, loss_ce: 0.017261
2021-12-02 23:32:21,198 iteration 2217 : loss : 0.032250, loss_ce: 0.015551
2021-12-02 23:32:22,651 iteration 2218 : loss : 0.029464, loss_ce: 0.010484
2021-12-02 23:32:24,145 iteration 2219 : loss : 0.037261, loss_ce: 0.016838
2021-12-02 23:32:25,680 iteration 2220 : loss : 0.041399, loss_ce: 0.020853
2021-12-02 23:32:27,212 iteration 2221 : loss : 0.037786, loss_ce: 0.012385
2021-12-02 23:32:28,609 iteration 2222 : loss : 0.028467, loss_ce: 0.010516
2021-12-02 23:32:30,032 iteration 2223 : loss : 0.043358, loss_ce: 0.014486
2021-12-02 23:32:31,558 iteration 2224 : loss : 0.054845, loss_ce: 0.024370
2021-12-02 23:32:33,029 iteration 2225 : loss : 0.037011, loss_ce: 0.012269
2021-12-02 23:32:34,541 iteration 2226 : loss : 0.035408, loss_ce: 0.015152
2021-12-02 23:32:36,039 iteration 2227 : loss : 0.053083, loss_ce: 0.017827
 33%|█████████▍                   | 131/400 [59:30<2:03:46, 27.61s/it]2021-12-02 23:32:37,625 iteration 2228 : loss : 0.040837, loss_ce: 0.018527
2021-12-02 23:32:39,094 iteration 2229 : loss : 0.034417, loss_ce: 0.012613
2021-12-02 23:32:40,669 iteration 2230 : loss : 0.045794, loss_ce: 0.017992
2021-12-02 23:32:42,115 iteration 2231 : loss : 0.043034, loss_ce: 0.023442
2021-12-02 23:32:43,573 iteration 2232 : loss : 0.028758, loss_ce: 0.013026
2021-12-02 23:32:45,215 iteration 2233 : loss : 0.062089, loss_ce: 0.021226
2021-12-02 23:32:46,690 iteration 2234 : loss : 0.041002, loss_ce: 0.011424
2021-12-02 23:32:48,137 iteration 2235 : loss : 0.039234, loss_ce: 0.016705
2021-12-02 23:32:49,579 iteration 2236 : loss : 0.031924, loss_ce: 0.012588
2021-12-02 23:32:51,050 iteration 2237 : loss : 0.037383, loss_ce: 0.015843
2021-12-02 23:32:52,468 iteration 2238 : loss : 0.028551, loss_ce: 0.009217
2021-12-02 23:32:53,919 iteration 2239 : loss : 0.020229, loss_ce: 0.005641
2021-12-02 23:32:55,313 iteration 2240 : loss : 0.044088, loss_ce: 0.011575
2021-12-02 23:32:56,778 iteration 2241 : loss : 0.025086, loss_ce: 0.009662
2021-12-02 23:32:58,311 iteration 2242 : loss : 0.036594, loss_ce: 0.012971
2021-12-02 23:32:59,813 iteration 2243 : loss : 0.042682, loss_ce: 0.022436
2021-12-02 23:33:01,263 iteration 2244 : loss : 0.025733, loss_ce: 0.009676
 33%|█████████▌                   | 132/400 [59:55<2:00:07, 26.89s/it]2021-12-02 23:33:02,776 iteration 2245 : loss : 0.032242, loss_ce: 0.009568
2021-12-02 23:33:04,168 iteration 2246 : loss : 0.027457, loss_ce: 0.007926
2021-12-02 23:33:05,652 iteration 2247 : loss : 0.030501, loss_ce: 0.013849
2021-12-02 23:33:07,180 iteration 2248 : loss : 0.051065, loss_ce: 0.025844
2021-12-02 23:33:08,641 iteration 2249 : loss : 0.026045, loss_ce: 0.011764
2021-12-02 23:33:10,105 iteration 2250 : loss : 0.032721, loss_ce: 0.010945
2021-12-02 23:33:11,590 iteration 2251 : loss : 0.032507, loss_ce: 0.014467
2021-12-02 23:33:13,059 iteration 2252 : loss : 0.041687, loss_ce: 0.015420
2021-12-02 23:33:14,614 iteration 2253 : loss : 0.039059, loss_ce: 0.015187
2021-12-02 23:33:16,124 iteration 2254 : loss : 0.034340, loss_ce: 0.014067
2021-12-02 23:33:17,587 iteration 2255 : loss : 0.035597, loss_ce: 0.013703
2021-12-02 23:33:19,046 iteration 2256 : loss : 0.024513, loss_ce: 0.009891
2021-12-02 23:33:20,479 iteration 2257 : loss : 0.040437, loss_ce: 0.012881
2021-12-02 23:33:21,909 iteration 2258 : loss : 0.039335, loss_ce: 0.013019
2021-12-02 23:33:23,420 iteration 2259 : loss : 0.028962, loss_ce: 0.011199
2021-12-02 23:33:24,815 iteration 2260 : loss : 0.031892, loss_ce: 0.011745
2021-12-02 23:33:26,304 iteration 2261 : loss : 0.046827, loss_ce: 0.019998
 33%|████████▉                  | 133/400 [1:00:20<1:57:12, 26.34s/it]2021-12-02 23:33:27,788 iteration 2262 : loss : 0.028441, loss_ce: 0.014287
2021-12-02 23:33:29,307 iteration 2263 : loss : 0.036346, loss_ce: 0.013292
2021-12-02 23:33:30,860 iteration 2264 : loss : 0.041760, loss_ce: 0.012001
2021-12-02 23:33:32,343 iteration 2265 : loss : 0.033505, loss_ce: 0.013820
2021-12-02 23:33:33,777 iteration 2266 : loss : 0.033945, loss_ce: 0.015421
2021-12-02 23:33:35,223 iteration 2267 : loss : 0.021716, loss_ce: 0.007399
2021-12-02 23:33:36,680 iteration 2268 : loss : 0.033538, loss_ce: 0.013293
2021-12-02 23:33:38,098 iteration 2269 : loss : 0.031323, loss_ce: 0.015812
2021-12-02 23:33:39,572 iteration 2270 : loss : 0.038797, loss_ce: 0.012266
2021-12-02 23:33:41,022 iteration 2271 : loss : 0.027434, loss_ce: 0.010552
2021-12-02 23:33:42,473 iteration 2272 : loss : 0.035700, loss_ce: 0.017839
2021-12-02 23:33:43,969 iteration 2273 : loss : 0.029984, loss_ce: 0.009285
2021-12-02 23:33:45,456 iteration 2274 : loss : 0.037360, loss_ce: 0.010704
2021-12-02 23:33:46,966 iteration 2275 : loss : 0.040561, loss_ce: 0.014343
2021-12-02 23:33:48,357 iteration 2276 : loss : 0.032393, loss_ce: 0.011704
2021-12-02 23:33:49,827 iteration 2277 : loss : 0.035643, loss_ce: 0.011375
2021-12-02 23:33:51,261 iteration 2278 : loss : 0.024721, loss_ce: 0.008963
 34%|█████████                  | 134/400 [1:00:45<1:54:55, 25.92s/it]2021-12-02 23:33:52,724 iteration 2279 : loss : 0.043752, loss_ce: 0.016383
2021-12-02 23:33:54,211 iteration 2280 : loss : 0.038338, loss_ce: 0.017640
2021-12-02 23:33:55,677 iteration 2281 : loss : 0.067647, loss_ce: 0.017390
2021-12-02 23:33:57,177 iteration 2282 : loss : 0.033316, loss_ce: 0.011465
2021-12-02 23:33:58,712 iteration 2283 : loss : 0.041099, loss_ce: 0.016158
2021-12-02 23:34:00,151 iteration 2284 : loss : 0.036708, loss_ce: 0.016331
2021-12-02 23:34:01,595 iteration 2285 : loss : 0.024560, loss_ce: 0.008712
2021-12-02 23:34:03,040 iteration 2286 : loss : 0.025603, loss_ce: 0.009196
2021-12-02 23:34:04,496 iteration 2287 : loss : 0.029675, loss_ce: 0.011119
2021-12-02 23:34:05,987 iteration 2288 : loss : 0.038214, loss_ce: 0.012753
2021-12-02 23:34:07,407 iteration 2289 : loss : 0.035431, loss_ce: 0.008453
2021-12-02 23:34:08,924 iteration 2290 : loss : 0.033305, loss_ce: 0.016239
2021-12-02 23:34:10,383 iteration 2291 : loss : 0.026780, loss_ce: 0.009675
2021-12-02 23:34:11,813 iteration 2292 : loss : 0.035643, loss_ce: 0.015346
2021-12-02 23:34:13,212 iteration 2293 : loss : 0.033334, loss_ce: 0.016799
2021-12-02 23:34:14,716 iteration 2294 : loss : 0.064514, loss_ce: 0.021971
2021-12-02 23:34:14,716 Training Data Eval:
2021-12-02 23:34:22,125   Average segmentation loss on training set: 0.0249
2021-12-02 23:34:22,126 Validation Data Eval:
2021-12-02 23:34:24,691   Average segmentation loss on validation set: 0.0832
2021-12-02 23:34:26,245 iteration 2295 : loss : 0.028203, loss_ce: 0.011633
 34%|█████████                  | 135/400 [1:01:20<2:06:30, 28.64s/it]2021-12-02 23:34:27,717 iteration 2296 : loss : 0.026075, loss_ce: 0.011083
2021-12-02 23:34:29,174 iteration 2297 : loss : 0.027297, loss_ce: 0.010414
2021-12-02 23:34:30,634 iteration 2298 : loss : 0.021781, loss_ce: 0.009703
2021-12-02 23:34:32,165 iteration 2299 : loss : 0.045272, loss_ce: 0.022070
2021-12-02 23:34:33,597 iteration 2300 : loss : 0.033979, loss_ce: 0.014056
2021-12-02 23:34:35,135 iteration 2301 : loss : 0.026884, loss_ce: 0.007872
2021-12-02 23:34:36,636 iteration 2302 : loss : 0.050992, loss_ce: 0.015987
2021-12-02 23:34:38,108 iteration 2303 : loss : 0.029071, loss_ce: 0.008581
2021-12-02 23:34:39,651 iteration 2304 : loss : 0.033208, loss_ce: 0.012048
2021-12-02 23:34:41,150 iteration 2305 : loss : 0.029688, loss_ce: 0.010993
2021-12-02 23:34:42,716 iteration 2306 : loss : 0.042190, loss_ce: 0.021885
2021-12-02 23:34:44,162 iteration 2307 : loss : 0.060739, loss_ce: 0.020045
2021-12-02 23:34:45,588 iteration 2308 : loss : 0.036985, loss_ce: 0.011163
2021-12-02 23:34:47,030 iteration 2309 : loss : 0.028586, loss_ce: 0.012539
2021-12-02 23:34:48,555 iteration 2310 : loss : 0.030108, loss_ce: 0.010061
2021-12-02 23:34:49,940 iteration 2311 : loss : 0.045046, loss_ce: 0.013841
2021-12-02 23:34:51,411 iteration 2312 : loss : 0.051595, loss_ce: 0.017300
 34%|█████████▏                 | 136/400 [1:01:45<2:01:24, 27.59s/it]2021-12-02 23:34:52,963 iteration 2313 : loss : 0.035925, loss_ce: 0.014176
2021-12-02 23:34:54,341 iteration 2314 : loss : 0.022446, loss_ce: 0.007261
2021-12-02 23:34:55,775 iteration 2315 : loss : 0.023370, loss_ce: 0.007959
2021-12-02 23:34:57,314 iteration 2316 : loss : 0.032931, loss_ce: 0.012445
2021-12-02 23:34:58,721 iteration 2317 : loss : 0.040190, loss_ce: 0.012112
2021-12-02 23:35:00,177 iteration 2318 : loss : 0.035170, loss_ce: 0.017035
2021-12-02 23:35:01,639 iteration 2319 : loss : 0.040442, loss_ce: 0.016492
2021-12-02 23:35:03,165 iteration 2320 : loss : 0.039538, loss_ce: 0.016851
2021-12-02 23:35:04,628 iteration 2321 : loss : 0.035936, loss_ce: 0.014047
2021-12-02 23:35:06,122 iteration 2322 : loss : 0.027017, loss_ce: 0.011397
2021-12-02 23:35:07,511 iteration 2323 : loss : 0.024904, loss_ce: 0.009379
2021-12-02 23:35:08,968 iteration 2324 : loss : 0.026698, loss_ce: 0.011427
2021-12-02 23:35:10,333 iteration 2325 : loss : 0.027266, loss_ce: 0.012344
2021-12-02 23:35:11,795 iteration 2326 : loss : 0.038532, loss_ce: 0.009383
2021-12-02 23:35:13,207 iteration 2327 : loss : 0.027945, loss_ce: 0.010629
2021-12-02 23:35:14,664 iteration 2328 : loss : 0.033738, loss_ce: 0.013708
2021-12-02 23:35:16,095 iteration 2329 : loss : 0.025317, loss_ce: 0.009917
 34%|█████████▏                 | 137/400 [1:02:10<1:57:09, 26.73s/it]2021-12-02 23:35:17,633 iteration 2330 : loss : 0.041780, loss_ce: 0.016817
2021-12-02 23:35:19,043 iteration 2331 : loss : 0.026516, loss_ce: 0.010129
2021-12-02 23:35:20,569 iteration 2332 : loss : 0.032648, loss_ce: 0.011347
2021-12-02 23:35:22,030 iteration 2333 : loss : 0.039834, loss_ce: 0.016669
2021-12-02 23:35:23,609 iteration 2334 : loss : 0.026799, loss_ce: 0.010581
2021-12-02 23:35:25,168 iteration 2335 : loss : 0.034195, loss_ce: 0.013327
2021-12-02 23:35:26,704 iteration 2336 : loss : 0.046990, loss_ce: 0.021460
2021-12-02 23:35:28,172 iteration 2337 : loss : 0.039615, loss_ce: 0.013755
2021-12-02 23:35:29,665 iteration 2338 : loss : 0.049144, loss_ce: 0.017188
2021-12-02 23:35:31,157 iteration 2339 : loss : 0.043713, loss_ce: 0.014541
2021-12-02 23:35:32,570 iteration 2340 : loss : 0.040390, loss_ce: 0.013507
2021-12-02 23:35:34,044 iteration 2341 : loss : 0.033042, loss_ce: 0.012514
2021-12-02 23:35:35,520 iteration 2342 : loss : 0.036031, loss_ce: 0.015865
2021-12-02 23:35:37,088 iteration 2343 : loss : 0.030320, loss_ce: 0.010675
2021-12-02 23:35:38,511 iteration 2344 : loss : 0.065696, loss_ce: 0.018709
2021-12-02 23:35:39,946 iteration 2345 : loss : 0.036050, loss_ce: 0.016773
2021-12-02 23:35:41,397 iteration 2346 : loss : 0.036882, loss_ce: 0.016756
 34%|█████████▎                 | 138/400 [1:02:35<1:54:50, 26.30s/it]2021-12-02 23:35:42,992 iteration 2347 : loss : 0.046439, loss_ce: 0.020036
2021-12-02 23:35:44,468 iteration 2348 : loss : 0.032177, loss_ce: 0.012315
2021-12-02 23:35:45,913 iteration 2349 : loss : 0.036089, loss_ce: 0.014092
2021-12-02 23:35:47,365 iteration 2350 : loss : 0.047533, loss_ce: 0.013808
2021-12-02 23:35:48,894 iteration 2351 : loss : 0.032902, loss_ce: 0.015567
2021-12-02 23:35:50,312 iteration 2352 : loss : 0.028067, loss_ce: 0.013643
2021-12-02 23:35:51,743 iteration 2353 : loss : 0.026647, loss_ce: 0.011212
2021-12-02 23:35:53,155 iteration 2354 : loss : 0.021766, loss_ce: 0.009982
2021-12-02 23:35:54,600 iteration 2355 : loss : 0.039253, loss_ce: 0.013310
2021-12-02 23:35:56,127 iteration 2356 : loss : 0.031209, loss_ce: 0.012153
2021-12-02 23:35:57,604 iteration 2357 : loss : 0.049837, loss_ce: 0.016890
2021-12-02 23:35:59,079 iteration 2358 : loss : 0.036095, loss_ce: 0.014304
2021-12-02 23:36:00,529 iteration 2359 : loss : 0.038665, loss_ce: 0.012941
2021-12-02 23:36:01,965 iteration 2360 : loss : 0.035345, loss_ce: 0.010796
2021-12-02 23:36:03,430 iteration 2361 : loss : 0.028523, loss_ce: 0.010315
2021-12-02 23:36:04,997 iteration 2362 : loss : 0.037225, loss_ce: 0.014465
2021-12-02 23:36:06,462 iteration 2363 : loss : 0.026175, loss_ce: 0.010662
 35%|█████████▍                 | 139/400 [1:03:00<1:52:47, 25.93s/it]2021-12-02 23:36:08,047 iteration 2364 : loss : 0.027182, loss_ce: 0.009391
2021-12-02 23:36:09,588 iteration 2365 : loss : 0.037729, loss_ce: 0.017450
2021-12-02 23:36:11,098 iteration 2366 : loss : 0.043269, loss_ce: 0.017464
2021-12-02 23:36:12,512 iteration 2367 : loss : 0.026003, loss_ce: 0.006104
2021-12-02 23:36:13,931 iteration 2368 : loss : 0.026407, loss_ce: 0.010499
2021-12-02 23:36:15,407 iteration 2369 : loss : 0.040702, loss_ce: 0.012442
2021-12-02 23:36:16,857 iteration 2370 : loss : 0.048449, loss_ce: 0.018480
2021-12-02 23:36:18,349 iteration 2371 : loss : 0.028467, loss_ce: 0.011203
2021-12-02 23:36:19,776 iteration 2372 : loss : 0.026439, loss_ce: 0.008266
2021-12-02 23:36:21,222 iteration 2373 : loss : 0.034623, loss_ce: 0.013903
2021-12-02 23:36:22,646 iteration 2374 : loss : 0.029854, loss_ce: 0.011372
2021-12-02 23:36:24,083 iteration 2375 : loss : 0.026017, loss_ce: 0.008656
2021-12-02 23:36:25,573 iteration 2376 : loss : 0.041415, loss_ce: 0.020454
2021-12-02 23:36:27,047 iteration 2377 : loss : 0.037103, loss_ce: 0.018264
2021-12-02 23:36:28,523 iteration 2378 : loss : 0.023686, loss_ce: 0.009497
2021-12-02 23:36:30,015 iteration 2379 : loss : 0.040488, loss_ce: 0.017140
2021-12-02 23:36:30,016 Training Data Eval:
2021-12-02 23:36:37,450   Average segmentation loss on training set: 0.0288
2021-12-02 23:36:37,451 Validation Data Eval:
2021-12-02 23:36:40,027   Average segmentation loss on validation set: 0.0751
2021-12-02 23:36:41,459 iteration 2380 : loss : 0.024477, loss_ce: 0.011654
 35%|█████████▍                 | 140/400 [1:03:35<2:04:07, 28.65s/it]2021-12-02 23:36:42,946 iteration 2381 : loss : 0.033785, loss_ce: 0.011097
2021-12-02 23:36:44,456 iteration 2382 : loss : 0.036113, loss_ce: 0.011550
2021-12-02 23:36:45,905 iteration 2383 : loss : 0.027047, loss_ce: 0.009161
2021-12-02 23:36:47,412 iteration 2384 : loss : 0.035060, loss_ce: 0.013301
2021-12-02 23:36:48,905 iteration 2385 : loss : 0.055256, loss_ce: 0.022120
2021-12-02 23:36:50,352 iteration 2386 : loss : 0.037772, loss_ce: 0.011581
2021-12-02 23:36:51,789 iteration 2387 : loss : 0.035505, loss_ce: 0.012851
2021-12-02 23:36:53,260 iteration 2388 : loss : 0.049184, loss_ce: 0.022860
2021-12-02 23:36:54,688 iteration 2389 : loss : 0.018226, loss_ce: 0.005723
2021-12-02 23:36:56,175 iteration 2390 : loss : 0.035305, loss_ce: 0.017857
2021-12-02 23:36:57,617 iteration 2391 : loss : 0.033363, loss_ce: 0.018233
2021-12-02 23:36:59,107 iteration 2392 : loss : 0.033417, loss_ce: 0.012871
2021-12-02 23:37:00,589 iteration 2393 : loss : 0.042707, loss_ce: 0.013692
2021-12-02 23:37:01,968 iteration 2394 : loss : 0.026956, loss_ce: 0.008920
2021-12-02 23:37:03,482 iteration 2395 : loss : 0.033278, loss_ce: 0.014983
2021-12-02 23:37:04,923 iteration 2396 : loss : 0.022365, loss_ce: 0.010081
2021-12-02 23:37:06,406 iteration 2397 : loss : 0.025786, loss_ce: 0.010402
 35%|█████████▌                 | 141/400 [1:04:00<1:58:52, 27.54s/it]2021-12-02 23:37:07,911 iteration 2398 : loss : 0.045069, loss_ce: 0.016007
2021-12-02 23:37:09,358 iteration 2399 : loss : 0.033608, loss_ce: 0.011497
2021-12-02 23:37:10,882 iteration 2400 : loss : 0.035831, loss_ce: 0.017031
2021-12-02 23:37:12,348 iteration 2401 : loss : 0.027050, loss_ce: 0.009167
2021-12-02 23:37:13,867 iteration 2402 : loss : 0.033177, loss_ce: 0.015515
2021-12-02 23:37:15,313 iteration 2403 : loss : 0.025579, loss_ce: 0.010422
2021-12-02 23:37:16,735 iteration 2404 : loss : 0.027246, loss_ce: 0.011757
2021-12-02 23:37:18,133 iteration 2405 : loss : 0.022045, loss_ce: 0.008074
2021-12-02 23:37:19,712 iteration 2406 : loss : 0.033039, loss_ce: 0.010815
2021-12-02 23:37:21,116 iteration 2407 : loss : 0.030156, loss_ce: 0.015520
2021-12-02 23:37:22,534 iteration 2408 : loss : 0.023064, loss_ce: 0.009969
2021-12-02 23:37:24,059 iteration 2409 : loss : 0.025512, loss_ce: 0.008036
2021-12-02 23:37:25,580 iteration 2410 : loss : 0.036023, loss_ce: 0.013043
2021-12-02 23:37:27,064 iteration 2411 : loss : 0.038886, loss_ce: 0.011809
2021-12-02 23:37:28,486 iteration 2412 : loss : 0.020681, loss_ce: 0.007821
2021-12-02 23:37:30,011 iteration 2413 : loss : 0.038383, loss_ce: 0.017992
2021-12-02 23:37:31,482 iteration 2414 : loss : 0.039946, loss_ce: 0.015093
 36%|█████████▌                 | 142/400 [1:04:25<1:55:13, 26.80s/it]2021-12-02 23:37:33,011 iteration 2415 : loss : 0.031357, loss_ce: 0.010144
2021-12-02 23:37:34,452 iteration 2416 : loss : 0.024347, loss_ce: 0.009109
2021-12-02 23:37:35,914 iteration 2417 : loss : 0.031201, loss_ce: 0.010126
2021-12-02 23:37:37,452 iteration 2418 : loss : 0.030055, loss_ce: 0.010406
2021-12-02 23:37:38,925 iteration 2419 : loss : 0.040191, loss_ce: 0.021440
2021-12-02 23:37:40,485 iteration 2420 : loss : 0.035059, loss_ce: 0.016404
2021-12-02 23:37:42,003 iteration 2421 : loss : 0.041138, loss_ce: 0.013523
2021-12-02 23:37:43,503 iteration 2422 : loss : 0.033100, loss_ce: 0.011423
2021-12-02 23:37:44,952 iteration 2423 : loss : 0.026282, loss_ce: 0.009279
2021-12-02 23:37:46,395 iteration 2424 : loss : 0.026273, loss_ce: 0.011180
2021-12-02 23:37:47,960 iteration 2425 : loss : 0.037609, loss_ce: 0.012337
2021-12-02 23:37:49,410 iteration 2426 : loss : 0.031642, loss_ce: 0.009622
2021-12-02 23:37:50,800 iteration 2427 : loss : 0.027501, loss_ce: 0.012040
2021-12-02 23:37:52,241 iteration 2428 : loss : 0.036186, loss_ce: 0.009742
2021-12-02 23:37:53,685 iteration 2429 : loss : 0.034152, loss_ce: 0.011754
2021-12-02 23:37:55,136 iteration 2430 : loss : 0.020136, loss_ce: 0.007709
2021-12-02 23:37:56,619 iteration 2431 : loss : 0.031780, loss_ce: 0.015909
 36%|█████████▋                 | 143/400 [1:04:50<1:52:38, 26.30s/it]2021-12-02 23:37:58,100 iteration 2432 : loss : 0.028666, loss_ce: 0.008250
2021-12-02 23:37:59,561 iteration 2433 : loss : 0.029752, loss_ce: 0.011708
2021-12-02 23:38:01,047 iteration 2434 : loss : 0.036135, loss_ce: 0.012161
2021-12-02 23:38:02,629 iteration 2435 : loss : 0.044138, loss_ce: 0.022885
2021-12-02 23:38:04,027 iteration 2436 : loss : 0.024782, loss_ce: 0.009973
2021-12-02 23:38:05,558 iteration 2437 : loss : 0.026465, loss_ce: 0.009724
2021-12-02 23:38:07,127 iteration 2438 : loss : 0.039132, loss_ce: 0.012990
2021-12-02 23:38:08,653 iteration 2439 : loss : 0.053192, loss_ce: 0.016162
2021-12-02 23:38:10,193 iteration 2440 : loss : 0.029479, loss_ce: 0.011942
2021-12-02 23:38:11,659 iteration 2441 : loss : 0.034359, loss_ce: 0.011043
2021-12-02 23:38:13,125 iteration 2442 : loss : 0.030449, loss_ce: 0.011135
2021-12-02 23:38:14,538 iteration 2443 : loss : 0.030221, loss_ce: 0.010413
2021-12-02 23:38:16,007 iteration 2444 : loss : 0.031521, loss_ce: 0.011732
2021-12-02 23:38:17,485 iteration 2445 : loss : 0.028739, loss_ce: 0.012415
2021-12-02 23:38:19,038 iteration 2446 : loss : 0.030900, loss_ce: 0.015234
2021-12-02 23:38:20,453 iteration 2447 : loss : 0.027390, loss_ce: 0.008311
2021-12-02 23:38:21,970 iteration 2448 : loss : 0.025540, loss_ce: 0.009139
 36%|█████████▋                 | 144/400 [1:05:16<1:50:59, 26.01s/it]2021-12-02 23:38:23,434 iteration 2449 : loss : 0.046805, loss_ce: 0.016352
2021-12-02 23:38:24,845 iteration 2450 : loss : 0.025976, loss_ce: 0.012762
2021-12-02 23:38:26,297 iteration 2451 : loss : 0.030719, loss_ce: 0.008884
2021-12-02 23:38:27,736 iteration 2452 : loss : 0.028332, loss_ce: 0.010180
2021-12-02 23:38:29,220 iteration 2453 : loss : 0.034698, loss_ce: 0.010954
2021-12-02 23:38:30,679 iteration 2454 : loss : 0.031316, loss_ce: 0.010729
2021-12-02 23:38:32,113 iteration 2455 : loss : 0.035558, loss_ce: 0.017044
2021-12-02 23:38:33,543 iteration 2456 : loss : 0.024736, loss_ce: 0.009882
2021-12-02 23:38:35,004 iteration 2457 : loss : 0.027579, loss_ce: 0.010428
2021-12-02 23:38:36,429 iteration 2458 : loss : 0.032210, loss_ce: 0.012130
2021-12-02 23:38:37,823 iteration 2459 : loss : 0.022668, loss_ce: 0.008919
2021-12-02 23:38:39,294 iteration 2460 : loss : 0.032963, loss_ce: 0.007974
2021-12-02 23:38:40,837 iteration 2461 : loss : 0.030365, loss_ce: 0.010226
2021-12-02 23:38:42,338 iteration 2462 : loss : 0.044480, loss_ce: 0.012953
2021-12-02 23:38:43,794 iteration 2463 : loss : 0.029774, loss_ce: 0.012882
2021-12-02 23:38:45,270 iteration 2464 : loss : 0.021529, loss_ce: 0.007905
2021-12-02 23:38:45,270 Training Data Eval:
2021-12-02 23:38:52,672   Average segmentation loss on training set: 0.0227
2021-12-02 23:38:52,672 Validation Data Eval:
2021-12-02 23:38:55,248   Average segmentation loss on validation set: 0.0969
2021-12-02 23:38:56,718 iteration 2465 : loss : 0.030768, loss_ce: 0.012924
 36%|█████████▊                 | 145/400 [1:05:50<2:01:42, 28.64s/it]2021-12-02 23:38:58,309 iteration 2466 : loss : 0.034252, loss_ce: 0.012049
2021-12-02 23:38:59,857 iteration 2467 : loss : 0.033501, loss_ce: 0.014191
2021-12-02 23:39:01,310 iteration 2468 : loss : 0.027682, loss_ce: 0.010181
2021-12-02 23:39:02,736 iteration 2469 : loss : 0.023349, loss_ce: 0.009978
2021-12-02 23:39:04,196 iteration 2470 : loss : 0.031461, loss_ce: 0.009772
2021-12-02 23:39:05,761 iteration 2471 : loss : 0.037979, loss_ce: 0.014297
2021-12-02 23:39:07,214 iteration 2472 : loss : 0.060456, loss_ce: 0.026417
2021-12-02 23:39:08,734 iteration 2473 : loss : 0.048147, loss_ce: 0.018092
2021-12-02 23:39:10,164 iteration 2474 : loss : 0.028499, loss_ce: 0.008846
2021-12-02 23:39:11,641 iteration 2475 : loss : 0.031364, loss_ce: 0.009857
2021-12-02 23:39:13,073 iteration 2476 : loss : 0.023046, loss_ce: 0.011597
2021-12-02 23:39:14,624 iteration 2477 : loss : 0.045850, loss_ce: 0.017971
2021-12-02 23:39:16,129 iteration 2478 : loss : 0.028994, loss_ce: 0.009825
2021-12-02 23:39:17,519 iteration 2479 : loss : 0.026845, loss_ce: 0.008220
2021-12-02 23:39:19,009 iteration 2480 : loss : 0.033647, loss_ce: 0.013203
2021-12-02 23:39:20,547 iteration 2481 : loss : 0.028856, loss_ce: 0.010756
2021-12-02 23:39:21,987 iteration 2482 : loss : 0.024291, loss_ce: 0.010832
 36%|█████████▊                 | 146/400 [1:06:16<1:56:56, 27.62s/it]2021-12-02 23:39:23,573 iteration 2483 : loss : 0.047303, loss_ce: 0.021984
2021-12-02 23:39:25,072 iteration 2484 : loss : 0.034258, loss_ce: 0.007171
2021-12-02 23:39:26,491 iteration 2485 : loss : 0.025346, loss_ce: 0.010924
2021-12-02 23:39:27,944 iteration 2486 : loss : 0.025877, loss_ce: 0.010631
2021-12-02 23:39:29,392 iteration 2487 : loss : 0.030969, loss_ce: 0.010278
2021-12-02 23:39:30,922 iteration 2488 : loss : 0.039173, loss_ce: 0.014505
2021-12-02 23:39:32,377 iteration 2489 : loss : 0.034756, loss_ce: 0.013354
2021-12-02 23:39:33,894 iteration 2490 : loss : 0.038664, loss_ce: 0.015569
2021-12-02 23:39:35,437 iteration 2491 : loss : 0.029125, loss_ce: 0.013039
2021-12-02 23:39:36,824 iteration 2492 : loss : 0.021403, loss_ce: 0.008071
2021-12-02 23:39:38,315 iteration 2493 : loss : 0.027735, loss_ce: 0.011106
2021-12-02 23:39:39,773 iteration 2494 : loss : 0.035809, loss_ce: 0.009878
2021-12-02 23:39:41,218 iteration 2495 : loss : 0.030314, loss_ce: 0.013467
2021-12-02 23:39:42,849 iteration 2496 : loss : 0.043137, loss_ce: 0.012355
2021-12-02 23:39:44,332 iteration 2497 : loss : 0.040390, loss_ce: 0.013532
2021-12-02 23:39:45,851 iteration 2498 : loss : 0.033920, loss_ce: 0.013457
2021-12-02 23:39:47,271 iteration 2499 : loss : 0.022988, loss_ce: 0.006173
 37%|█████████▉                 | 147/400 [1:06:41<1:53:31, 26.92s/it]2021-12-02 23:39:48,786 iteration 2500 : loss : 0.030261, loss_ce: 0.010402
2021-12-02 23:39:50,260 iteration 2501 : loss : 0.023610, loss_ce: 0.007533
2021-12-02 23:39:51,804 iteration 2502 : loss : 0.041446, loss_ce: 0.016329
2021-12-02 23:39:53,236 iteration 2503 : loss : 0.026810, loss_ce: 0.010474
2021-12-02 23:39:54,685 iteration 2504 : loss : 0.024200, loss_ce: 0.008688
2021-12-02 23:39:56,211 iteration 2505 : loss : 0.042826, loss_ce: 0.015164
2021-12-02 23:39:57,677 iteration 2506 : loss : 0.034814, loss_ce: 0.011146
2021-12-02 23:39:59,086 iteration 2507 : loss : 0.028205, loss_ce: 0.012016
2021-12-02 23:40:00,521 iteration 2508 : loss : 0.043318, loss_ce: 0.016301
2021-12-02 23:40:01,986 iteration 2509 : loss : 0.036509, loss_ce: 0.011818
2021-12-02 23:40:03,451 iteration 2510 : loss : 0.027368, loss_ce: 0.011206
2021-12-02 23:40:04,954 iteration 2511 : loss : 0.028397, loss_ce: 0.012561
2021-12-02 23:40:06,466 iteration 2512 : loss : 0.027941, loss_ce: 0.010651
2021-12-02 23:40:08,000 iteration 2513 : loss : 0.040495, loss_ce: 0.012976
2021-12-02 23:40:09,474 iteration 2514 : loss : 0.034329, loss_ce: 0.009614
2021-12-02 23:40:10,923 iteration 2515 : loss : 0.031035, loss_ce: 0.020779
2021-12-02 23:40:12,369 iteration 2516 : loss : 0.024233, loss_ce: 0.011002
 37%|█████████▉                 | 148/400 [1:07:06<1:50:46, 26.38s/it]2021-12-02 23:40:13,909 iteration 2517 : loss : 0.025918, loss_ce: 0.009421
2021-12-02 23:40:15,364 iteration 2518 : loss : 0.030074, loss_ce: 0.008818
2021-12-02 23:40:16,852 iteration 2519 : loss : 0.032377, loss_ce: 0.011499
2021-12-02 23:40:18,322 iteration 2520 : loss : 0.032747, loss_ce: 0.012924
2021-12-02 23:40:19,774 iteration 2521 : loss : 0.019573, loss_ce: 0.007226
2021-12-02 23:40:21,248 iteration 2522 : loss : 0.030338, loss_ce: 0.015404
2021-12-02 23:40:22,758 iteration 2523 : loss : 0.042515, loss_ce: 0.010581
2021-12-02 23:40:24,209 iteration 2524 : loss : 0.026747, loss_ce: 0.011832
2021-12-02 23:40:25,681 iteration 2525 : loss : 0.025421, loss_ce: 0.011380
2021-12-02 23:40:27,145 iteration 2526 : loss : 0.034057, loss_ce: 0.012300
2021-12-02 23:40:28,609 iteration 2527 : loss : 0.035023, loss_ce: 0.012591
2021-12-02 23:40:30,100 iteration 2528 : loss : 0.028222, loss_ce: 0.009238
2021-12-02 23:40:31,574 iteration 2529 : loss : 0.029432, loss_ce: 0.010907
2021-12-02 23:40:33,061 iteration 2530 : loss : 0.034583, loss_ce: 0.014449
2021-12-02 23:40:34,608 iteration 2531 : loss : 0.030104, loss_ce: 0.013865
2021-12-02 23:40:36,075 iteration 2532 : loss : 0.050076, loss_ce: 0.013694
2021-12-02 23:40:37,555 iteration 2533 : loss : 0.038353, loss_ce: 0.009308
 37%|██████████                 | 149/400 [1:07:31<1:48:50, 26.02s/it]2021-12-02 23:40:39,007 iteration 2534 : loss : 0.028550, loss_ce: 0.010570
2021-12-02 23:40:40,542 iteration 2535 : loss : 0.034725, loss_ce: 0.011055
2021-12-02 23:40:41,981 iteration 2536 : loss : 0.033045, loss_ce: 0.015009
2021-12-02 23:40:43,430 iteration 2537 : loss : 0.024455, loss_ce: 0.009059
2021-12-02 23:40:44,813 iteration 2538 : loss : 0.021216, loss_ce: 0.009124
2021-12-02 23:40:46,327 iteration 2539 : loss : 0.031693, loss_ce: 0.012188
2021-12-02 23:40:47,768 iteration 2540 : loss : 0.024350, loss_ce: 0.007328
2021-12-02 23:40:49,229 iteration 2541 : loss : 0.029250, loss_ce: 0.011832
2021-12-02 23:40:50,662 iteration 2542 : loss : 0.024481, loss_ce: 0.008030
2021-12-02 23:40:52,084 iteration 2543 : loss : 0.034780, loss_ce: 0.011886
2021-12-02 23:40:53,561 iteration 2544 : loss : 0.031573, loss_ce: 0.011407
2021-12-02 23:40:55,135 iteration 2545 : loss : 0.029198, loss_ce: 0.010655
2021-12-02 23:40:56,728 iteration 2546 : loss : 0.045289, loss_ce: 0.020025
2021-12-02 23:40:58,134 iteration 2547 : loss : 0.024362, loss_ce: 0.011235
2021-12-02 23:40:59,629 iteration 2548 : loss : 0.027108, loss_ce: 0.011576
2021-12-02 23:41:01,107 iteration 2549 : loss : 0.038519, loss_ce: 0.011342
2021-12-02 23:41:01,107 Training Data Eval:
2021-12-02 23:41:08,550   Average segmentation loss on training set: 0.0221
2021-12-02 23:41:08,550 Validation Data Eval:
2021-12-02 23:41:11,140   Average segmentation loss on validation set: 0.0707
2021-12-02 23:41:12,615 iteration 2550 : loss : 0.024336, loss_ce: 0.007591
 38%|██████████▏                | 150/400 [1:08:06<1:59:43, 28.73s/it]2021-12-02 23:41:14,146 iteration 2551 : loss : 0.026410, loss_ce: 0.012037
2021-12-02 23:41:15,688 iteration 2552 : loss : 0.030278, loss_ce: 0.012840
2021-12-02 23:41:17,110 iteration 2553 : loss : 0.022750, loss_ce: 0.007590
2021-12-02 23:41:18,613 iteration 2554 : loss : 0.024180, loss_ce: 0.008508
2021-12-02 23:41:20,080 iteration 2555 : loss : 0.035307, loss_ce: 0.009117
2021-12-02 23:41:21,630 iteration 2556 : loss : 0.027639, loss_ce: 0.012668
2021-12-02 23:41:23,093 iteration 2557 : loss : 0.030151, loss_ce: 0.014623
2021-12-02 23:41:24,592 iteration 2558 : loss : 0.038765, loss_ce: 0.018109
2021-12-02 23:41:26,151 iteration 2559 : loss : 0.035658, loss_ce: 0.013292
2021-12-02 23:41:27,614 iteration 2560 : loss : 0.027169, loss_ce: 0.015502
2021-12-02 23:41:29,177 iteration 2561 : loss : 0.030248, loss_ce: 0.010236
2021-12-02 23:41:30,683 iteration 2562 : loss : 0.029629, loss_ce: 0.011719
2021-12-02 23:41:32,218 iteration 2563 : loss : 0.039670, loss_ce: 0.017962
2021-12-02 23:41:33,648 iteration 2564 : loss : 0.026026, loss_ce: 0.010075
2021-12-02 23:41:35,099 iteration 2565 : loss : 0.026372, loss_ce: 0.009141
2021-12-02 23:41:36,573 iteration 2566 : loss : 0.027939, loss_ce: 0.009695
2021-12-02 23:41:38,094 iteration 2567 : loss : 0.034708, loss_ce: 0.009187
 38%|██████████▏                | 151/400 [1:08:32<1:55:10, 27.75s/it]2021-12-02 23:41:39,656 iteration 2568 : loss : 0.028324, loss_ce: 0.012394
2021-12-02 23:41:41,124 iteration 2569 : loss : 0.027875, loss_ce: 0.013889
2021-12-02 23:41:42,606 iteration 2570 : loss : 0.036649, loss_ce: 0.013736
2021-12-02 23:41:44,093 iteration 2571 : loss : 0.019471, loss_ce: 0.007514
2021-12-02 23:41:45,528 iteration 2572 : loss : 0.049309, loss_ce: 0.014394
2021-12-02 23:41:46,986 iteration 2573 : loss : 0.032968, loss_ce: 0.013231
2021-12-02 23:41:48,466 iteration 2574 : loss : 0.033044, loss_ce: 0.010070
2021-12-02 23:41:50,062 iteration 2575 : loss : 0.038221, loss_ce: 0.016296
2021-12-02 23:41:51,555 iteration 2576 : loss : 0.024541, loss_ce: 0.008402
2021-12-02 23:41:53,055 iteration 2577 : loss : 0.044256, loss_ce: 0.015418
2021-12-02 23:41:54,553 iteration 2578 : loss : 0.041923, loss_ce: 0.014517
2021-12-02 23:41:56,008 iteration 2579 : loss : 0.032853, loss_ce: 0.008744
2021-12-02 23:41:57,554 iteration 2580 : loss : 0.050024, loss_ce: 0.011525
2021-12-02 23:41:59,094 iteration 2581 : loss : 0.036988, loss_ce: 0.014611
2021-12-02 23:42:00,660 iteration 2582 : loss : 0.026447, loss_ce: 0.009023
2021-12-02 23:42:02,157 iteration 2583 : loss : 0.023068, loss_ce: 0.008400
2021-12-02 23:42:03,580 iteration 2584 : loss : 0.020259, loss_ce: 0.007819
 38%|██████████▎                | 152/400 [1:08:57<1:51:55, 27.08s/it]2021-12-02 23:42:05,140 iteration 2585 : loss : 0.021971, loss_ce: 0.006747
2021-12-02 23:42:06,627 iteration 2586 : loss : 0.027492, loss_ce: 0.012741
2021-12-02 23:42:08,061 iteration 2587 : loss : 0.032550, loss_ce: 0.012119
2021-12-02 23:42:09,533 iteration 2588 : loss : 0.029816, loss_ce: 0.013799
2021-12-02 23:42:11,059 iteration 2589 : loss : 0.030535, loss_ce: 0.010187
2021-12-02 23:42:12,579 iteration 2590 : loss : 0.031623, loss_ce: 0.013395
2021-12-02 23:42:14,025 iteration 2591 : loss : 0.023997, loss_ce: 0.008010
2021-12-02 23:42:15,475 iteration 2592 : loss : 0.029294, loss_ce: 0.009285
2021-12-02 23:42:16,939 iteration 2593 : loss : 0.025173, loss_ce: 0.011202
2021-12-02 23:42:18,555 iteration 2594 : loss : 0.038267, loss_ce: 0.016951
2021-12-02 23:42:20,067 iteration 2595 : loss : 0.026721, loss_ce: 0.009707
2021-12-02 23:42:21,532 iteration 2596 : loss : 0.022764, loss_ce: 0.009864
2021-12-02 23:42:22,988 iteration 2597 : loss : 0.028064, loss_ce: 0.010046
2021-12-02 23:42:24,461 iteration 2598 : loss : 0.022347, loss_ce: 0.008232
2021-12-02 23:42:25,942 iteration 2599 : loss : 0.026791, loss_ce: 0.006276
2021-12-02 23:42:27,440 iteration 2600 : loss : 0.027258, loss_ce: 0.008818
2021-12-02 23:42:28,895 iteration 2601 : loss : 0.024858, loss_ce: 0.010402
 38%|██████████▎                | 153/400 [1:09:23<1:49:17, 26.55s/it]2021-12-02 23:42:30,459 iteration 2602 : loss : 0.031147, loss_ce: 0.012611
2021-12-02 23:42:31,888 iteration 2603 : loss : 0.022374, loss_ce: 0.008319
2021-12-02 23:42:33,368 iteration 2604 : loss : 0.024589, loss_ce: 0.008881
2021-12-02 23:42:34,987 iteration 2605 : loss : 0.031504, loss_ce: 0.011370
2021-12-02 23:42:36,487 iteration 2606 : loss : 0.030503, loss_ce: 0.012478
2021-12-02 23:42:37,988 iteration 2607 : loss : 0.040050, loss_ce: 0.015743
2021-12-02 23:42:39,428 iteration 2608 : loss : 0.024804, loss_ce: 0.010823
2021-12-02 23:42:40,870 iteration 2609 : loss : 0.034982, loss_ce: 0.010547
2021-12-02 23:42:42,467 iteration 2610 : loss : 0.029453, loss_ce: 0.011406
2021-12-02 23:42:43,935 iteration 2611 : loss : 0.032455, loss_ce: 0.010486
2021-12-02 23:42:45,342 iteration 2612 : loss : 0.021702, loss_ce: 0.010663
2021-12-02 23:42:46,810 iteration 2613 : loss : 0.032210, loss_ce: 0.010365
2021-12-02 23:42:48,353 iteration 2614 : loss : 0.033315, loss_ce: 0.011207
2021-12-02 23:42:49,828 iteration 2615 : loss : 0.030335, loss_ce: 0.011890
2021-12-02 23:42:51,299 iteration 2616 : loss : 0.027883, loss_ce: 0.010736
2021-12-02 23:42:52,859 iteration 2617 : loss : 0.031588, loss_ce: 0.007869
2021-12-02 23:42:54,349 iteration 2618 : loss : 0.033869, loss_ce: 0.015956
 38%|██████████▍                | 154/400 [1:09:48<1:47:29, 26.22s/it]2021-12-02 23:42:55,926 iteration 2619 : loss : 0.037309, loss_ce: 0.009779
2021-12-02 23:42:57,389 iteration 2620 : loss : 0.027975, loss_ce: 0.010494
2021-12-02 23:42:58,911 iteration 2621 : loss : 0.032466, loss_ce: 0.010008
2021-12-02 23:43:00,434 iteration 2622 : loss : 0.028818, loss_ce: 0.014517
2021-12-02 23:43:01,944 iteration 2623 : loss : 0.036137, loss_ce: 0.015402
2021-12-02 23:43:03,387 iteration 2624 : loss : 0.024069, loss_ce: 0.007513
2021-12-02 23:43:04,865 iteration 2625 : loss : 0.021242, loss_ce: 0.008577
2021-12-02 23:43:06,427 iteration 2626 : loss : 0.035209, loss_ce: 0.015939
2021-12-02 23:43:07,936 iteration 2627 : loss : 0.047606, loss_ce: 0.011569
2021-12-02 23:43:09,374 iteration 2628 : loss : 0.028812, loss_ce: 0.009891
2021-12-02 23:43:10,921 iteration 2629 : loss : 0.032866, loss_ce: 0.010412
2021-12-02 23:43:12,371 iteration 2630 : loss : 0.024167, loss_ce: 0.007656
2021-12-02 23:43:13,876 iteration 2631 : loss : 0.031263, loss_ce: 0.014106
2021-12-02 23:43:15,393 iteration 2632 : loss : 0.033722, loss_ce: 0.012208
2021-12-02 23:43:16,850 iteration 2633 : loss : 0.027027, loss_ce: 0.013236
2021-12-02 23:43:18,344 iteration 2634 : loss : 0.032964, loss_ce: 0.010560
2021-12-02 23:43:18,344 Training Data Eval:
2021-12-02 23:43:25,897   Average segmentation loss on training set: 0.0205
2021-12-02 23:43:25,897 Validation Data Eval:
2021-12-02 23:43:28,500   Average segmentation loss on validation set: 0.0864
2021-12-02 23:43:30,059 iteration 2635 : loss : 0.032117, loss_ce: 0.012945
 39%|██████████▍                | 155/400 [1:10:24<1:58:40, 29.06s/it]2021-12-02 23:43:31,570 iteration 2636 : loss : 0.023128, loss_ce: 0.006858
2021-12-02 23:43:33,180 iteration 2637 : loss : 0.039881, loss_ce: 0.012220
2021-12-02 23:43:34,670 iteration 2638 : loss : 0.029092, loss_ce: 0.011409
2021-12-02 23:43:36,057 iteration 2639 : loss : 0.019268, loss_ce: 0.006838
2021-12-02 23:43:37,497 iteration 2640 : loss : 0.029661, loss_ce: 0.011281
2021-12-02 23:43:39,047 iteration 2641 : loss : 0.036864, loss_ce: 0.014358
2021-12-02 23:43:40,587 iteration 2642 : loss : 0.046409, loss_ce: 0.010944
2021-12-02 23:43:42,119 iteration 2643 : loss : 0.031902, loss_ce: 0.011489
2021-12-02 23:43:43,564 iteration 2644 : loss : 0.032774, loss_ce: 0.009079
2021-12-02 23:43:45,004 iteration 2645 : loss : 0.026985, loss_ce: 0.012948
2021-12-02 23:43:46,454 iteration 2646 : loss : 0.026342, loss_ce: 0.007599
2021-12-02 23:43:47,988 iteration 2647 : loss : 0.026289, loss_ce: 0.011459
2021-12-02 23:43:49,422 iteration 2648 : loss : 0.018054, loss_ce: 0.007962
2021-12-02 23:43:50,952 iteration 2649 : loss : 0.032665, loss_ce: 0.013426
2021-12-02 23:43:52,465 iteration 2650 : loss : 0.023165, loss_ce: 0.009541
2021-12-02 23:43:53,930 iteration 2651 : loss : 0.031233, loss_ce: 0.012153
2021-12-02 23:43:55,414 iteration 2652 : loss : 0.027219, loss_ce: 0.013011
 39%|██████████▌                | 156/400 [1:10:49<1:53:40, 27.95s/it]2021-12-02 23:43:57,037 iteration 2653 : loss : 0.048743, loss_ce: 0.016179
2021-12-02 23:43:58,512 iteration 2654 : loss : 0.022673, loss_ce: 0.008481
2021-12-02 23:43:59,948 iteration 2655 : loss : 0.020832, loss_ce: 0.007300
2021-12-02 23:44:01,365 iteration 2656 : loss : 0.025113, loss_ce: 0.010580
2021-12-02 23:44:02,812 iteration 2657 : loss : 0.024021, loss_ce: 0.008193
2021-12-02 23:44:04,282 iteration 2658 : loss : 0.022773, loss_ce: 0.009317
2021-12-02 23:44:05,881 iteration 2659 : loss : 0.034907, loss_ce: 0.014813
2021-12-02 23:44:07,352 iteration 2660 : loss : 0.029619, loss_ce: 0.009559
2021-12-02 23:44:08,758 iteration 2661 : loss : 0.024646, loss_ce: 0.009417
2021-12-02 23:44:10,256 iteration 2662 : loss : 0.031622, loss_ce: 0.011923
2021-12-02 23:44:11,686 iteration 2663 : loss : 0.028935, loss_ce: 0.009905
2021-12-02 23:44:13,213 iteration 2664 : loss : 0.021676, loss_ce: 0.006835
2021-12-02 23:44:14,669 iteration 2665 : loss : 0.027466, loss_ce: 0.010562
2021-12-02 23:44:16,149 iteration 2666 : loss : 0.033812, loss_ce: 0.012777
2021-12-02 23:44:17,668 iteration 2667 : loss : 0.025957, loss_ce: 0.008989
2021-12-02 23:44:19,182 iteration 2668 : loss : 0.032682, loss_ce: 0.011016
2021-12-02 23:44:20,716 iteration 2669 : loss : 0.028340, loss_ce: 0.009899
 39%|██████████▌                | 157/400 [1:11:14<1:49:59, 27.16s/it]2021-12-02 23:44:22,266 iteration 2670 : loss : 0.032434, loss_ce: 0.008761
2021-12-02 23:44:23,744 iteration 2671 : loss : 0.028169, loss_ce: 0.007869
2021-12-02 23:44:25,237 iteration 2672 : loss : 0.023632, loss_ce: 0.008763
2021-12-02 23:44:26,765 iteration 2673 : loss : 0.040750, loss_ce: 0.015432
2021-12-02 23:44:28,213 iteration 2674 : loss : 0.026562, loss_ce: 0.012244
2021-12-02 23:44:29,747 iteration 2675 : loss : 0.034105, loss_ce: 0.013235
2021-12-02 23:44:31,255 iteration 2676 : loss : 0.030359, loss_ce: 0.008571
2021-12-02 23:44:32,683 iteration 2677 : loss : 0.022627, loss_ce: 0.009640
2021-12-02 23:44:34,104 iteration 2678 : loss : 0.027604, loss_ce: 0.008859
2021-12-02 23:44:35,603 iteration 2679 : loss : 0.023805, loss_ce: 0.010451
2021-12-02 23:44:37,152 iteration 2680 : loss : 0.031692, loss_ce: 0.014183
2021-12-02 23:44:38,618 iteration 2681 : loss : 0.023160, loss_ce: 0.010041
2021-12-02 23:44:40,041 iteration 2682 : loss : 0.023406, loss_ce: 0.008943
2021-12-02 23:44:41,523 iteration 2683 : loss : 0.028653, loss_ce: 0.013588
2021-12-02 23:44:42,995 iteration 2684 : loss : 0.032782, loss_ce: 0.008194
2021-12-02 23:44:44,488 iteration 2685 : loss : 0.027045, loss_ce: 0.012243
2021-12-02 23:44:45,951 iteration 2686 : loss : 0.023298, loss_ce: 0.008111
 40%|██████████▋                | 158/400 [1:11:40<1:47:12, 26.58s/it]2021-12-02 23:44:47,466 iteration 2687 : loss : 0.018922, loss_ce: 0.008475
2021-12-02 23:44:48,918 iteration 2688 : loss : 0.026973, loss_ce: 0.010910
2021-12-02 23:44:50,309 iteration 2689 : loss : 0.020623, loss_ce: 0.007401
2021-12-02 23:44:51,779 iteration 2690 : loss : 0.031107, loss_ce: 0.016185
2021-12-02 23:44:53,275 iteration 2691 : loss : 0.020703, loss_ce: 0.006885
2021-12-02 23:44:54,765 iteration 2692 : loss : 0.022792, loss_ce: 0.006879
2021-12-02 23:44:56,223 iteration 2693 : loss : 0.024991, loss_ce: 0.009143
2021-12-02 23:44:57,636 iteration 2694 : loss : 0.024668, loss_ce: 0.008741
2021-12-02 23:44:59,161 iteration 2695 : loss : 0.039894, loss_ce: 0.014848
2021-12-02 23:45:00,736 iteration 2696 : loss : 0.047184, loss_ce: 0.018526
2021-12-02 23:45:02,266 iteration 2697 : loss : 0.037434, loss_ce: 0.019896
2021-12-02 23:45:03,689 iteration 2698 : loss : 0.019810, loss_ce: 0.007554
2021-12-02 23:45:05,125 iteration 2699 : loss : 0.025308, loss_ce: 0.008553
2021-12-02 23:45:06,574 iteration 2700 : loss : 0.033789, loss_ce: 0.009524
2021-12-02 23:45:08,062 iteration 2701 : loss : 0.040386, loss_ce: 0.018507
2021-12-02 23:45:09,547 iteration 2702 : loss : 0.058186, loss_ce: 0.013553
2021-12-02 23:45:11,038 iteration 2703 : loss : 0.031783, loss_ce: 0.010872
 40%|██████████▋                | 159/400 [1:12:05<1:44:57, 26.13s/it]2021-12-02 23:45:12,514 iteration 2704 : loss : 0.021813, loss_ce: 0.006651
2021-12-02 23:45:13,947 iteration 2705 : loss : 0.027320, loss_ce: 0.008310
2021-12-02 23:45:15,463 iteration 2706 : loss : 0.030436, loss_ce: 0.015173
2021-12-02 23:45:16,931 iteration 2707 : loss : 0.031055, loss_ce: 0.014453
2021-12-02 23:45:18,389 iteration 2708 : loss : 0.038976, loss_ce: 0.013843
2021-12-02 23:45:19,937 iteration 2709 : loss : 0.034155, loss_ce: 0.009875
2021-12-02 23:45:21,456 iteration 2710 : loss : 0.058075, loss_ce: 0.024919
2021-12-02 23:45:22,896 iteration 2711 : loss : 0.026536, loss_ce: 0.008702
2021-12-02 23:45:24,355 iteration 2712 : loss : 0.046588, loss_ce: 0.016746
2021-12-02 23:45:25,853 iteration 2713 : loss : 0.022436, loss_ce: 0.007795
2021-12-02 23:45:27,342 iteration 2714 : loss : 0.027818, loss_ce: 0.010165
2021-12-02 23:45:28,817 iteration 2715 : loss : 0.025825, loss_ce: 0.013535
2021-12-02 23:45:30,252 iteration 2716 : loss : 0.042485, loss_ce: 0.011339
2021-12-02 23:45:31,664 iteration 2717 : loss : 0.025937, loss_ce: 0.009956
2021-12-02 23:45:33,169 iteration 2718 : loss : 0.031985, loss_ce: 0.012693
2021-12-02 23:45:34,604 iteration 2719 : loss : 0.023206, loss_ce: 0.009655
2021-12-02 23:45:34,604 Training Data Eval:
2021-12-02 23:45:42,106   Average segmentation loss on training set: 0.0271
2021-12-02 23:45:42,106 Validation Data Eval:
2021-12-02 23:45:44,700   Average segmentation loss on validation set: 0.0860
2021-12-02 23:45:46,171 iteration 2720 : loss : 0.029771, loss_ce: 0.012837
 40%|██████████▊                | 160/400 [1:12:40<1:55:19, 28.83s/it]2021-12-02 23:45:47,700 iteration 2721 : loss : 0.036331, loss_ce: 0.013586
2021-12-02 23:45:49,199 iteration 2722 : loss : 0.024569, loss_ce: 0.012101
2021-12-02 23:45:50,748 iteration 2723 : loss : 0.029218, loss_ce: 0.012983
2021-12-02 23:45:52,160 iteration 2724 : loss : 0.025665, loss_ce: 0.008648
2021-12-02 23:45:53,620 iteration 2725 : loss : 0.045005, loss_ce: 0.012865
2021-12-02 23:45:55,169 iteration 2726 : loss : 0.022844, loss_ce: 0.007946
2021-12-02 23:45:56,637 iteration 2727 : loss : 0.027143, loss_ce: 0.009133
2021-12-02 23:45:58,147 iteration 2728 : loss : 0.029669, loss_ce: 0.010995
2021-12-02 23:45:59,656 iteration 2729 : loss : 0.041633, loss_ce: 0.020363
2021-12-02 23:46:01,199 iteration 2730 : loss : 0.046465, loss_ce: 0.017035
2021-12-02 23:46:02,664 iteration 2731 : loss : 0.033553, loss_ce: 0.012363
2021-12-02 23:46:04,066 iteration 2732 : loss : 0.024488, loss_ce: 0.009232
2021-12-02 23:46:05,530 iteration 2733 : loss : 0.024677, loss_ce: 0.010545
2021-12-02 23:46:07,004 iteration 2734 : loss : 0.048295, loss_ce: 0.011715
2021-12-02 23:46:08,470 iteration 2735 : loss : 0.032272, loss_ce: 0.016034
2021-12-02 23:46:09,903 iteration 2736 : loss : 0.032615, loss_ce: 0.010475
2021-12-02 23:46:11,349 iteration 2737 : loss : 0.024875, loss_ce: 0.006047
 40%|██████████▊                | 161/400 [1:13:05<1:50:28, 27.74s/it]2021-12-02 23:46:12,901 iteration 2738 : loss : 0.042587, loss_ce: 0.020284
2021-12-02 23:46:14,324 iteration 2739 : loss : 0.025715, loss_ce: 0.007905
2021-12-02 23:46:15,871 iteration 2740 : loss : 0.040714, loss_ce: 0.014552
2021-12-02 23:46:17,327 iteration 2741 : loss : 0.029159, loss_ce: 0.011748
2021-12-02 23:46:18,797 iteration 2742 : loss : 0.030844, loss_ce: 0.012085
2021-12-02 23:46:20,224 iteration 2743 : loss : 0.025558, loss_ce: 0.009145
2021-12-02 23:46:21,702 iteration 2744 : loss : 0.021628, loss_ce: 0.007110
2021-12-02 23:46:23,145 iteration 2745 : loss : 0.025758, loss_ce: 0.007738
2021-12-02 23:46:24,710 iteration 2746 : loss : 0.057995, loss_ce: 0.016175
2021-12-02 23:46:26,148 iteration 2747 : loss : 0.026554, loss_ce: 0.010845
2021-12-02 23:46:27,659 iteration 2748 : loss : 0.028090, loss_ce: 0.007620
2021-12-02 23:46:29,181 iteration 2749 : loss : 0.046197, loss_ce: 0.017829
2021-12-02 23:46:30,620 iteration 2750 : loss : 0.038181, loss_ce: 0.015514
2021-12-02 23:46:32,083 iteration 2751 : loss : 0.049150, loss_ce: 0.017343
2021-12-02 23:46:33,648 iteration 2752 : loss : 0.052340, loss_ce: 0.021267
2021-12-02 23:46:35,216 iteration 2753 : loss : 0.036046, loss_ce: 0.016241
2021-12-02 23:46:36,704 iteration 2754 : loss : 0.026114, loss_ce: 0.012953
 40%|██████████▉                | 162/400 [1:13:30<1:47:10, 27.02s/it]2021-12-02 23:46:38,119 iteration 2755 : loss : 0.027472, loss_ce: 0.008716
2021-12-02 23:46:39,606 iteration 2756 : loss : 0.033584, loss_ce: 0.012533
2021-12-02 23:46:41,073 iteration 2757 : loss : 0.027868, loss_ce: 0.011657
2021-12-02 23:46:42,530 iteration 2758 : loss : 0.029900, loss_ce: 0.011016
2021-12-02 23:46:44,002 iteration 2759 : loss : 0.037040, loss_ce: 0.013057
2021-12-02 23:46:45,489 iteration 2760 : loss : 0.037763, loss_ce: 0.017250
2021-12-02 23:46:46,985 iteration 2761 : loss : 0.053125, loss_ce: 0.015987
2021-12-02 23:46:48,440 iteration 2762 : loss : 0.032034, loss_ce: 0.014133
2021-12-02 23:46:49,924 iteration 2763 : loss : 0.062654, loss_ce: 0.018351
2021-12-02 23:46:51,327 iteration 2764 : loss : 0.026495, loss_ce: 0.009574
2021-12-02 23:46:52,891 iteration 2765 : loss : 0.025418, loss_ce: 0.007776
2021-12-02 23:46:54,297 iteration 2766 : loss : 0.032947, loss_ce: 0.010357
2021-12-02 23:46:55,769 iteration 2767 : loss : 0.034051, loss_ce: 0.012218
2021-12-02 23:46:57,220 iteration 2768 : loss : 0.032137, loss_ce: 0.010334
2021-12-02 23:46:58,638 iteration 2769 : loss : 0.028532, loss_ce: 0.012283
2021-12-02 23:47:00,092 iteration 2770 : loss : 0.029404, loss_ce: 0.012576
2021-12-02 23:47:01,556 iteration 2771 : loss : 0.029361, loss_ce: 0.012193
 41%|███████████                | 163/400 [1:13:55<1:44:09, 26.37s/it]2021-12-02 23:47:03,020 iteration 2772 : loss : 0.040519, loss_ce: 0.014191
2021-12-02 23:47:04,492 iteration 2773 : loss : 0.036572, loss_ce: 0.014141
2021-12-02 23:47:05,965 iteration 2774 : loss : 0.041366, loss_ce: 0.009423
2021-12-02 23:47:07,462 iteration 2775 : loss : 0.058842, loss_ce: 0.024956
2021-12-02 23:47:08,926 iteration 2776 : loss : 0.026877, loss_ce: 0.009454
2021-12-02 23:47:10,452 iteration 2777 : loss : 0.024059, loss_ce: 0.008746
2021-12-02 23:47:11,891 iteration 2778 : loss : 0.026224, loss_ce: 0.008852
2021-12-02 23:47:13,321 iteration 2779 : loss : 0.025201, loss_ce: 0.010369
2021-12-02 23:47:14,772 iteration 2780 : loss : 0.026243, loss_ce: 0.012027
2021-12-02 23:47:16,328 iteration 2781 : loss : 0.040616, loss_ce: 0.015692
2021-12-02 23:47:17,843 iteration 2782 : loss : 0.030066, loss_ce: 0.012858
2021-12-02 23:47:19,302 iteration 2783 : loss : 0.043022, loss_ce: 0.012057
2021-12-02 23:47:20,678 iteration 2784 : loss : 0.032083, loss_ce: 0.009070
2021-12-02 23:47:22,107 iteration 2785 : loss : 0.028791, loss_ce: 0.011941
2021-12-02 23:47:23,531 iteration 2786 : loss : 0.029037, loss_ce: 0.011633
2021-12-02 23:47:24,984 iteration 2787 : loss : 0.026888, loss_ce: 0.010241
2021-12-02 23:47:26,582 iteration 2788 : loss : 0.051165, loss_ce: 0.020883
 41%|███████████                | 164/400 [1:14:20<1:42:08, 25.97s/it]2021-12-02 23:47:28,099 iteration 2789 : loss : 0.023591, loss_ce: 0.007552
2021-12-02 23:47:29,621 iteration 2790 : loss : 0.041360, loss_ce: 0.016545
2021-12-02 23:47:31,027 iteration 2791 : loss : 0.021683, loss_ce: 0.006577
2021-12-02 23:47:32,474 iteration 2792 : loss : 0.026267, loss_ce: 0.009662
2021-12-02 23:47:33,934 iteration 2793 : loss : 0.027847, loss_ce: 0.009427
2021-12-02 23:47:35,464 iteration 2794 : loss : 0.029962, loss_ce: 0.013587
2021-12-02 23:47:36,928 iteration 2795 : loss : 0.031397, loss_ce: 0.011337
2021-12-02 23:47:38,370 iteration 2796 : loss : 0.029796, loss_ce: 0.010743
2021-12-02 23:47:39,882 iteration 2797 : loss : 0.028038, loss_ce: 0.012711
2021-12-02 23:47:41,377 iteration 2798 : loss : 0.037370, loss_ce: 0.011532
2021-12-02 23:47:42,922 iteration 2799 : loss : 0.031077, loss_ce: 0.011376
2021-12-02 23:47:44,397 iteration 2800 : loss : 0.037436, loss_ce: 0.017388
2021-12-02 23:47:45,793 iteration 2801 : loss : 0.029385, loss_ce: 0.008625
2021-12-02 23:47:47,222 iteration 2802 : loss : 0.023505, loss_ce: 0.007367
2021-12-02 23:47:48,706 iteration 2803 : loss : 0.033214, loss_ce: 0.012921
2021-12-02 23:47:50,118 iteration 2804 : loss : 0.037006, loss_ce: 0.013711
2021-12-02 23:47:50,118 Training Data Eval:
2021-12-02 23:47:57,561   Average segmentation loss on training set: 0.0202
2021-12-02 23:47:57,561 Validation Data Eval:
2021-12-02 23:48:00,134   Average segmentation loss on validation set: 0.0793
2021-12-02 23:48:01,713 iteration 2805 : loss : 0.030570, loss_ce: 0.012553
 41%|███████████▏               | 165/400 [1:14:55<1:52:29, 28.72s/it]2021-12-02 23:48:03,301 iteration 2806 : loss : 0.035982, loss_ce: 0.015108
2021-12-02 23:48:04,833 iteration 2807 : loss : 0.044505, loss_ce: 0.014186
2021-12-02 23:48:06,335 iteration 2808 : loss : 0.030926, loss_ce: 0.010843
2021-12-02 23:48:07,812 iteration 2809 : loss : 0.026369, loss_ce: 0.009490
2021-12-02 23:48:09,226 iteration 2810 : loss : 0.032585, loss_ce: 0.011095
2021-12-02 23:48:10,749 iteration 2811 : loss : 0.027488, loss_ce: 0.013195
2021-12-02 23:48:12,156 iteration 2812 : loss : 0.018113, loss_ce: 0.007317
2021-12-02 23:48:13,688 iteration 2813 : loss : 0.038146, loss_ce: 0.015254
2021-12-02 23:48:15,173 iteration 2814 : loss : 0.030842, loss_ce: 0.010500
2021-12-02 23:48:16,635 iteration 2815 : loss : 0.023938, loss_ce: 0.010067
2021-12-02 23:48:18,095 iteration 2816 : loss : 0.031146, loss_ce: 0.010549
2021-12-02 23:48:19,618 iteration 2817 : loss : 0.054551, loss_ce: 0.010826
2021-12-02 23:48:21,129 iteration 2818 : loss : 0.033805, loss_ce: 0.012961
2021-12-02 23:48:22,576 iteration 2819 : loss : 0.034725, loss_ce: 0.016153
2021-12-02 23:48:24,136 iteration 2820 : loss : 0.037027, loss_ce: 0.011727
2021-12-02 23:48:25,662 iteration 2821 : loss : 0.039942, loss_ce: 0.012312
2021-12-02 23:48:27,154 iteration 2822 : loss : 0.026130, loss_ce: 0.007816
 42%|███████████▏               | 166/400 [1:15:21<1:48:09, 27.73s/it]2021-12-02 23:48:28,771 iteration 2823 : loss : 0.034805, loss_ce: 0.014671
2021-12-02 23:48:30,208 iteration 2824 : loss : 0.029840, loss_ce: 0.012894
2021-12-02 23:48:31,688 iteration 2825 : loss : 0.027199, loss_ce: 0.010781
2021-12-02 23:48:33,243 iteration 2826 : loss : 0.052338, loss_ce: 0.017799
2021-12-02 23:48:34,820 iteration 2827 : loss : 0.067107, loss_ce: 0.021640
2021-12-02 23:48:36,299 iteration 2828 : loss : 0.052621, loss_ce: 0.018910
2021-12-02 23:48:37,759 iteration 2829 : loss : 0.030718, loss_ce: 0.014494
2021-12-02 23:48:39,220 iteration 2830 : loss : 0.037324, loss_ce: 0.012604
2021-12-02 23:48:40,607 iteration 2831 : loss : 0.026442, loss_ce: 0.011236
2021-12-02 23:48:42,196 iteration 2832 : loss : 0.035326, loss_ce: 0.015339
2021-12-02 23:48:43,657 iteration 2833 : loss : 0.029045, loss_ce: 0.009775
2021-12-02 23:48:45,182 iteration 2834 : loss : 0.035107, loss_ce: 0.013215
2021-12-02 23:48:46,672 iteration 2835 : loss : 0.053471, loss_ce: 0.016294
2021-12-02 23:48:48,136 iteration 2836 : loss : 0.039813, loss_ce: 0.014604
2021-12-02 23:48:49,660 iteration 2837 : loss : 0.036470, loss_ce: 0.011405
2021-12-02 23:48:51,079 iteration 2838 : loss : 0.027830, loss_ce: 0.009791
2021-12-02 23:48:52,572 iteration 2839 : loss : 0.028731, loss_ce: 0.010613
 42%|███████████▎               | 167/400 [1:15:46<1:45:00, 27.04s/it]2021-12-02 23:48:54,153 iteration 2840 : loss : 0.033294, loss_ce: 0.011822
2021-12-02 23:48:55,609 iteration 2841 : loss : 0.027670, loss_ce: 0.008381
2021-12-02 23:48:57,052 iteration 2842 : loss : 0.021727, loss_ce: 0.007611
2021-12-02 23:48:58,554 iteration 2843 : loss : 0.034112, loss_ce: 0.010001
2021-12-02 23:49:00,048 iteration 2844 : loss : 0.034188, loss_ce: 0.013528
2021-12-02 23:49:01,520 iteration 2845 : loss : 0.035961, loss_ce: 0.013392
2021-12-02 23:49:02,987 iteration 2846 : loss : 0.026506, loss_ce: 0.009582
2021-12-02 23:49:04,350 iteration 2847 : loss : 0.021271, loss_ce: 0.010122
2021-12-02 23:49:05,834 iteration 2848 : loss : 0.036892, loss_ce: 0.013448
2021-12-02 23:49:07,339 iteration 2849 : loss : 0.030262, loss_ce: 0.011203
2021-12-02 23:49:08,818 iteration 2850 : loss : 0.039525, loss_ce: 0.013497
2021-12-02 23:49:10,316 iteration 2851 : loss : 0.031259, loss_ce: 0.012206
2021-12-02 23:49:11,782 iteration 2852 : loss : 0.042568, loss_ce: 0.011566
2021-12-02 23:49:13,305 iteration 2853 : loss : 0.025395, loss_ce: 0.009445
2021-12-02 23:49:14,804 iteration 2854 : loss : 0.029416, loss_ce: 0.010493
2021-12-02 23:49:16,246 iteration 2855 : loss : 0.027800, loss_ce: 0.013473
2021-12-02 23:49:17,743 iteration 2856 : loss : 0.042045, loss_ce: 0.018781
 42%|███████████▎               | 168/400 [1:16:11<1:42:23, 26.48s/it]2021-12-02 23:49:19,184 iteration 2857 : loss : 0.021498, loss_ce: 0.006984
2021-12-02 23:49:20,657 iteration 2858 : loss : 0.026081, loss_ce: 0.010766
2021-12-02 23:49:22,085 iteration 2859 : loss : 0.023492, loss_ce: 0.009420
2021-12-02 23:49:23,581 iteration 2860 : loss : 0.033248, loss_ce: 0.009808
2021-12-02 23:49:24,978 iteration 2861 : loss : 0.027505, loss_ce: 0.012371
2021-12-02 23:49:26,539 iteration 2862 : loss : 0.060679, loss_ce: 0.018196
2021-12-02 23:49:27,964 iteration 2863 : loss : 0.027464, loss_ce: 0.007589
2021-12-02 23:49:29,471 iteration 2864 : loss : 0.030025, loss_ce: 0.011959
2021-12-02 23:49:30,974 iteration 2865 : loss : 0.032409, loss_ce: 0.013614
2021-12-02 23:49:32,419 iteration 2866 : loss : 0.031698, loss_ce: 0.012269
2021-12-02 23:49:33,970 iteration 2867 : loss : 0.031605, loss_ce: 0.012340
2021-12-02 23:49:35,385 iteration 2868 : loss : 0.024815, loss_ce: 0.009337
2021-12-02 23:49:36,928 iteration 2869 : loss : 0.032012, loss_ce: 0.012256
2021-12-02 23:49:38,417 iteration 2870 : loss : 0.025566, loss_ce: 0.008561
2021-12-02 23:49:39,868 iteration 2871 : loss : 0.021282, loss_ce: 0.008800
2021-12-02 23:49:41,289 iteration 2872 : loss : 0.028665, loss_ce: 0.010157
2021-12-02 23:49:42,813 iteration 2873 : loss : 0.033062, loss_ce: 0.009673
 42%|███████████▍               | 169/400 [1:16:36<1:40:19, 26.06s/it]2021-12-02 23:49:44,375 iteration 2874 : loss : 0.029568, loss_ce: 0.008611
2021-12-02 23:49:45,843 iteration 2875 : loss : 0.022657, loss_ce: 0.010563
2021-12-02 23:49:47,314 iteration 2876 : loss : 0.038858, loss_ce: 0.015626
2021-12-02 23:49:48,841 iteration 2877 : loss : 0.035189, loss_ce: 0.009518
2021-12-02 23:49:50,318 iteration 2878 : loss : 0.024699, loss_ce: 0.011276
2021-12-02 23:49:51,828 iteration 2879 : loss : 0.026510, loss_ce: 0.009153
2021-12-02 23:49:53,342 iteration 2880 : loss : 0.036029, loss_ce: 0.014312
2021-12-02 23:49:54,813 iteration 2881 : loss : 0.024806, loss_ce: 0.010198
2021-12-02 23:49:56,338 iteration 2882 : loss : 0.035884, loss_ce: 0.018319
2021-12-02 23:49:57,792 iteration 2883 : loss : 0.028906, loss_ce: 0.012609
2021-12-02 23:49:59,259 iteration 2884 : loss : 0.027702, loss_ce: 0.012863
2021-12-02 23:50:00,742 iteration 2885 : loss : 0.031113, loss_ce: 0.013907
2021-12-02 23:50:02,144 iteration 2886 : loss : 0.041727, loss_ce: 0.015902
2021-12-02 23:50:03,673 iteration 2887 : loss : 0.035384, loss_ce: 0.017600
2021-12-02 23:50:05,171 iteration 2888 : loss : 0.039001, loss_ce: 0.009484
2021-12-02 23:50:06,777 iteration 2889 : loss : 0.024488, loss_ce: 0.008261
2021-12-02 23:50:06,777 Training Data Eval:
2021-12-02 23:50:14,174   Average segmentation loss on training set: 0.0190
2021-12-02 23:50:14,174 Validation Data Eval:
2021-12-02 23:50:16,748   Average segmentation loss on validation set: 0.0981
2021-12-02 23:50:18,284 iteration 2890 : loss : 0.019955, loss_ce: 0.006777
 42%|███████████▍               | 170/400 [1:17:12<1:50:41, 28.88s/it]2021-12-02 23:50:19,830 iteration 2891 : loss : 0.026225, loss_ce: 0.010788
2021-12-02 23:50:21,375 iteration 2892 : loss : 0.028173, loss_ce: 0.007459
2021-12-02 23:50:22,817 iteration 2893 : loss : 0.026422, loss_ce: 0.007790
2021-12-02 23:50:24,354 iteration 2894 : loss : 0.041259, loss_ce: 0.011945
2021-12-02 23:50:25,857 iteration 2895 : loss : 0.026304, loss_ce: 0.010480
2021-12-02 23:50:27,297 iteration 2896 : loss : 0.024881, loss_ce: 0.007897
2021-12-02 23:50:28,782 iteration 2897 : loss : 0.033382, loss_ce: 0.015903
2021-12-02 23:50:30,215 iteration 2898 : loss : 0.024547, loss_ce: 0.011432
2021-12-02 23:50:31,719 iteration 2899 : loss : 0.037985, loss_ce: 0.014836
2021-12-02 23:50:33,177 iteration 2900 : loss : 0.020345, loss_ce: 0.007056
2021-12-02 23:50:34,663 iteration 2901 : loss : 0.033586, loss_ce: 0.008995
2021-12-02 23:50:36,072 iteration 2902 : loss : 0.030184, loss_ce: 0.009834
2021-12-02 23:50:37,509 iteration 2903 : loss : 0.025650, loss_ce: 0.011873
2021-12-02 23:50:38,940 iteration 2904 : loss : 0.025214, loss_ce: 0.009236
2021-12-02 23:50:40,361 iteration 2905 : loss : 0.026366, loss_ce: 0.012136
2021-12-02 23:50:41,859 iteration 2906 : loss : 0.028850, loss_ce: 0.013816
2021-12-02 23:50:43,296 iteration 2907 : loss : 0.024551, loss_ce: 0.008717
 43%|███████████▌               | 171/400 [1:17:37<1:45:48, 27.72s/it]2021-12-02 23:50:44,842 iteration 2908 : loss : 0.036602, loss_ce: 0.015612
2021-12-02 23:50:46,354 iteration 2909 : loss : 0.044937, loss_ce: 0.021608
2021-12-02 23:50:47,833 iteration 2910 : loss : 0.023189, loss_ce: 0.008520
2021-12-02 23:50:49,342 iteration 2911 : loss : 0.025311, loss_ce: 0.008413
2021-12-02 23:50:50,766 iteration 2912 : loss : 0.026244, loss_ce: 0.010921
2021-12-02 23:50:52,284 iteration 2913 : loss : 0.027407, loss_ce: 0.012258
2021-12-02 23:50:53,727 iteration 2914 : loss : 0.033562, loss_ce: 0.011497
2021-12-02 23:50:55,194 iteration 2915 : loss : 0.021669, loss_ce: 0.009214
2021-12-02 23:50:56,684 iteration 2916 : loss : 0.022410, loss_ce: 0.009166
2021-12-02 23:50:58,086 iteration 2917 : loss : 0.021991, loss_ce: 0.009805
2021-12-02 23:50:59,519 iteration 2918 : loss : 0.035598, loss_ce: 0.009068
2021-12-02 23:51:00,978 iteration 2919 : loss : 0.021959, loss_ce: 0.006798
2021-12-02 23:51:02,459 iteration 2920 : loss : 0.022516, loss_ce: 0.008547
2021-12-02 23:51:03,926 iteration 2921 : loss : 0.035543, loss_ce: 0.016262
2021-12-02 23:51:05,348 iteration 2922 : loss : 0.032783, loss_ce: 0.011474
2021-12-02 23:51:06,805 iteration 2923 : loss : 0.026457, loss_ce: 0.008463
2021-12-02 23:51:08,276 iteration 2924 : loss : 0.029124, loss_ce: 0.009539
 43%|███████████▌               | 172/400 [1:18:02<1:42:12, 26.90s/it]2021-12-02 23:51:09,710 iteration 2925 : loss : 0.023206, loss_ce: 0.011967
2021-12-02 23:51:11,249 iteration 2926 : loss : 0.031795, loss_ce: 0.013315
2021-12-02 23:51:12,712 iteration 2927 : loss : 0.028268, loss_ce: 0.012029
2021-12-02 23:51:14,095 iteration 2928 : loss : 0.028224, loss_ce: 0.008423
2021-12-02 23:51:15,551 iteration 2929 : loss : 0.026433, loss_ce: 0.010677
2021-12-02 23:51:17,093 iteration 2930 : loss : 0.031352, loss_ce: 0.013375
2021-12-02 23:51:18,543 iteration 2931 : loss : 0.026607, loss_ce: 0.009607
2021-12-02 23:51:19,976 iteration 2932 : loss : 0.026772, loss_ce: 0.010035
2021-12-02 23:51:21,511 iteration 2933 : loss : 0.032283, loss_ce: 0.010688
2021-12-02 23:51:22,970 iteration 2934 : loss : 0.039000, loss_ce: 0.016067
2021-12-02 23:51:24,463 iteration 2935 : loss : 0.028839, loss_ce: 0.008878
2021-12-02 23:51:25,924 iteration 2936 : loss : 0.023023, loss_ce: 0.006770
2021-12-02 23:51:27,411 iteration 2937 : loss : 0.027899, loss_ce: 0.012271
2021-12-02 23:51:28,916 iteration 2938 : loss : 0.036839, loss_ce: 0.011500
2021-12-02 23:51:30,420 iteration 2939 : loss : 0.024458, loss_ce: 0.007785
2021-12-02 23:51:31,982 iteration 2940 : loss : 0.049248, loss_ce: 0.026500
2021-12-02 23:51:33,441 iteration 2941 : loss : 0.022244, loss_ce: 0.007079
 43%|███████████▋               | 173/400 [1:18:27<1:39:48, 26.38s/it]2021-12-02 23:51:34,918 iteration 2942 : loss : 0.021733, loss_ce: 0.006680
2021-12-02 23:51:36,397 iteration 2943 : loss : 0.031237, loss_ce: 0.009966
2021-12-02 23:51:37,809 iteration 2944 : loss : 0.026387, loss_ce: 0.012678
2021-12-02 23:51:39,278 iteration 2945 : loss : 0.021288, loss_ce: 0.006584
2021-12-02 23:51:40,669 iteration 2946 : loss : 0.021621, loss_ce: 0.008561
2021-12-02 23:51:42,131 iteration 2947 : loss : 0.023392, loss_ce: 0.008913
2021-12-02 23:51:43,566 iteration 2948 : loss : 0.024642, loss_ce: 0.006967
2021-12-02 23:51:45,098 iteration 2949 : loss : 0.040876, loss_ce: 0.017515
2021-12-02 23:51:46,616 iteration 2950 : loss : 0.022565, loss_ce: 0.009203
2021-12-02 23:51:48,106 iteration 2951 : loss : 0.027729, loss_ce: 0.013001
2021-12-02 23:51:49,593 iteration 2952 : loss : 0.023144, loss_ce: 0.007303
2021-12-02 23:51:51,119 iteration 2953 : loss : 0.031813, loss_ce: 0.015987
2021-12-02 23:51:52,676 iteration 2954 : loss : 0.055723, loss_ce: 0.014124
2021-12-02 23:51:54,106 iteration 2955 : loss : 0.021918, loss_ce: 0.010163
2021-12-02 23:51:55,559 iteration 2956 : loss : 0.020862, loss_ce: 0.007283
2021-12-02 23:51:56,981 iteration 2957 : loss : 0.032093, loss_ce: 0.012218
2021-12-02 23:51:58,470 iteration 2958 : loss : 0.041292, loss_ce: 0.018214
 44%|███████████▋               | 174/400 [1:18:52<1:37:49, 25.97s/it]2021-12-02 23:52:00,011 iteration 2959 : loss : 0.022724, loss_ce: 0.007061
2021-12-02 23:52:01,471 iteration 2960 : loss : 0.030796, loss_ce: 0.012422
2021-12-02 23:52:02,969 iteration 2961 : loss : 0.032684, loss_ce: 0.011300
2021-12-02 23:52:04,566 iteration 2962 : loss : 0.030580, loss_ce: 0.012315
2021-12-02 23:52:06,039 iteration 2963 : loss : 0.034394, loss_ce: 0.013220
2021-12-02 23:52:07,417 iteration 2964 : loss : 0.022621, loss_ce: 0.008373
2021-12-02 23:52:08,881 iteration 2965 : loss : 0.023413, loss_ce: 0.011558
2021-12-02 23:52:10,374 iteration 2966 : loss : 0.032943, loss_ce: 0.010992
2021-12-02 23:52:11,829 iteration 2967 : loss : 0.036182, loss_ce: 0.011917
2021-12-02 23:52:13,293 iteration 2968 : loss : 0.023854, loss_ce: 0.009511
2021-12-02 23:52:14,736 iteration 2969 : loss : 0.032671, loss_ce: 0.013267
2021-12-02 23:52:16,217 iteration 2970 : loss : 0.026503, loss_ce: 0.010508
2021-12-02 23:52:17,678 iteration 2971 : loss : 0.022888, loss_ce: 0.007934
2021-12-02 23:52:19,143 iteration 2972 : loss : 0.037768, loss_ce: 0.016609
2021-12-02 23:52:20,567 iteration 2973 : loss : 0.022834, loss_ce: 0.005997
2021-12-02 23:52:22,126 iteration 2974 : loss : 0.040224, loss_ce: 0.014466
2021-12-02 23:52:22,127 Training Data Eval:
2021-12-02 23:52:29,552   Average segmentation loss on training set: 0.0175
2021-12-02 23:52:29,552 Validation Data Eval:
2021-12-02 23:52:32,135   Average segmentation loss on validation set: 0.0745
2021-12-02 23:52:33,586 iteration 2975 : loss : 0.019780, loss_ce: 0.007347
 44%|███████████▊               | 175/400 [1:19:27<1:47:40, 28.72s/it]2021-12-02 23:52:35,052 iteration 2976 : loss : 0.018109, loss_ce: 0.007535
2021-12-02 23:52:36,535 iteration 2977 : loss : 0.027932, loss_ce: 0.013326
2021-12-02 23:52:38,011 iteration 2978 : loss : 0.023095, loss_ce: 0.007138
2021-12-02 23:52:39,534 iteration 2979 : loss : 0.029215, loss_ce: 0.010755
2021-12-02 23:52:41,036 iteration 2980 : loss : 0.032386, loss_ce: 0.010407
2021-12-02 23:52:42,601 iteration 2981 : loss : 0.035345, loss_ce: 0.015384
2021-12-02 23:52:44,084 iteration 2982 : loss : 0.016582, loss_ce: 0.006488
2021-12-02 23:52:45,562 iteration 2983 : loss : 0.028934, loss_ce: 0.011453
2021-12-02 23:52:47,036 iteration 2984 : loss : 0.042584, loss_ce: 0.016608
2021-12-02 23:52:48,531 iteration 2985 : loss : 0.030694, loss_ce: 0.011088
2021-12-02 23:52:49,949 iteration 2986 : loss : 0.024002, loss_ce: 0.010278
2021-12-02 23:52:51,416 iteration 2987 : loss : 0.033599, loss_ce: 0.011126
2021-12-02 23:52:52,924 iteration 2988 : loss : 0.026114, loss_ce: 0.009877
2021-12-02 23:52:54,424 iteration 2989 : loss : 0.029524, loss_ce: 0.010797
2021-12-02 23:52:55,825 iteration 2990 : loss : 0.026043, loss_ce: 0.009894
2021-12-02 23:52:57,290 iteration 2991 : loss : 0.024677, loss_ce: 0.010339
2021-12-02 23:52:58,824 iteration 2992 : loss : 0.023793, loss_ce: 0.009914
 44%|███████████▉               | 176/400 [1:19:52<1:43:18, 27.67s/it]2021-12-02 23:53:00,286 iteration 2993 : loss : 0.035327, loss_ce: 0.017774
2021-12-02 23:53:01,768 iteration 2994 : loss : 0.057124, loss_ce: 0.013670
2021-12-02 23:53:03,228 iteration 2995 : loss : 0.020570, loss_ce: 0.007622
2021-12-02 23:53:04,698 iteration 2996 : loss : 0.022328, loss_ce: 0.010844
2021-12-02 23:53:06,159 iteration 2997 : loss : 0.031750, loss_ce: 0.009248
2021-12-02 23:53:07,650 iteration 2998 : loss : 0.021900, loss_ce: 0.008073
2021-12-02 23:53:09,170 iteration 2999 : loss : 0.049308, loss_ce: 0.008383
2021-12-02 23:53:10,698 iteration 3000 : loss : 0.034691, loss_ce: 0.014324
2021-12-02 23:53:12,213 iteration 3001 : loss : 0.029768, loss_ce: 0.008413
2021-12-02 23:53:13,638 iteration 3002 : loss : 0.026127, loss_ce: 0.009287
2021-12-02 23:53:15,091 iteration 3003 : loss : 0.030263, loss_ce: 0.011133
2021-12-02 23:53:16,544 iteration 3004 : loss : 0.024552, loss_ce: 0.009684
2021-12-02 23:53:18,006 iteration 3005 : loss : 0.027378, loss_ce: 0.012399
2021-12-02 23:53:19,498 iteration 3006 : loss : 0.031553, loss_ce: 0.012766
2021-12-02 23:53:21,046 iteration 3007 : loss : 0.026733, loss_ce: 0.011302
2021-12-02 23:53:22,535 iteration 3008 : loss : 0.053993, loss_ce: 0.019591
2021-12-02 23:53:23,936 iteration 3009 : loss : 0.028654, loss_ce: 0.011362
 44%|███████████▉               | 177/400 [1:20:18<1:39:59, 26.90s/it]2021-12-02 23:53:25,566 iteration 3010 : loss : 0.048621, loss_ce: 0.019138
2021-12-02 23:53:27,047 iteration 3011 : loss : 0.022914, loss_ce: 0.011781
2021-12-02 23:53:28,446 iteration 3012 : loss : 0.030761, loss_ce: 0.011591
2021-12-02 23:53:29,858 iteration 3013 : loss : 0.030994, loss_ce: 0.009520
2021-12-02 23:53:31,330 iteration 3014 : loss : 0.026519, loss_ce: 0.010047
2021-12-02 23:53:32,795 iteration 3015 : loss : 0.035712, loss_ce: 0.009062
2021-12-02 23:53:34,263 iteration 3016 : loss : 0.029839, loss_ce: 0.011167
2021-12-02 23:53:35,710 iteration 3017 : loss : 0.027762, loss_ce: 0.014084
2021-12-02 23:53:37,156 iteration 3018 : loss : 0.025537, loss_ce: 0.010252
2021-12-02 23:53:38,567 iteration 3019 : loss : 0.028482, loss_ce: 0.011832
2021-12-02 23:53:40,060 iteration 3020 : loss : 0.037396, loss_ce: 0.013589
2021-12-02 23:53:41,533 iteration 3021 : loss : 0.018421, loss_ce: 0.006394
2021-12-02 23:53:42,978 iteration 3022 : loss : 0.018371, loss_ce: 0.006093
2021-12-02 23:53:44,446 iteration 3023 : loss : 0.030633, loss_ce: 0.009988
2021-12-02 23:53:45,991 iteration 3024 : loss : 0.032289, loss_ce: 0.014730
2021-12-02 23:53:47,507 iteration 3025 : loss : 0.030411, loss_ce: 0.012161
2021-12-02 23:53:48,929 iteration 3026 : loss : 0.023243, loss_ce: 0.008855
 44%|████████████               | 178/400 [1:20:43<1:37:25, 26.33s/it]2021-12-02 23:53:50,496 iteration 3027 : loss : 0.040792, loss_ce: 0.014828
2021-12-02 23:53:51,926 iteration 3028 : loss : 0.023114, loss_ce: 0.008932
2021-12-02 23:53:53,407 iteration 3029 : loss : 0.029707, loss_ce: 0.013788
2021-12-02 23:53:54,850 iteration 3030 : loss : 0.021816, loss_ce: 0.009573
2021-12-02 23:53:56,327 iteration 3031 : loss : 0.035601, loss_ce: 0.012562
2021-12-02 23:53:57,748 iteration 3032 : loss : 0.024802, loss_ce: 0.008375
2021-12-02 23:53:59,248 iteration 3033 : loss : 0.045360, loss_ce: 0.014504
2021-12-02 23:54:00,756 iteration 3034 : loss : 0.044810, loss_ce: 0.014572
2021-12-02 23:54:02,226 iteration 3035 : loss : 0.025689, loss_ce: 0.010939
2021-12-02 23:54:03,663 iteration 3036 : loss : 0.038519, loss_ce: 0.020520
2021-12-02 23:54:05,125 iteration 3037 : loss : 0.034263, loss_ce: 0.012947
2021-12-02 23:54:06,618 iteration 3038 : loss : 0.023172, loss_ce: 0.007950
2021-12-02 23:54:08,033 iteration 3039 : loss : 0.029478, loss_ce: 0.008738
2021-12-02 23:54:09,515 iteration 3040 : loss : 0.050473, loss_ce: 0.014307
2021-12-02 23:54:11,023 iteration 3041 : loss : 0.024727, loss_ce: 0.009075
2021-12-02 23:54:12,478 iteration 3042 : loss : 0.028530, loss_ce: 0.012183
2021-12-02 23:54:14,097 iteration 3043 : loss : 0.044202, loss_ce: 0.014037
 45%|████████████               | 179/400 [1:21:08<1:35:42, 25.98s/it]2021-12-02 23:54:15,613 iteration 3044 : loss : 0.027110, loss_ce: 0.011546
2021-12-02 23:54:17,005 iteration 3045 : loss : 0.024895, loss_ce: 0.009120
2021-12-02 23:54:18,441 iteration 3046 : loss : 0.021744, loss_ce: 0.007323
2021-12-02 23:54:20,007 iteration 3047 : loss : 0.038654, loss_ce: 0.019969
2021-12-02 23:54:21,439 iteration 3048 : loss : 0.028985, loss_ce: 0.009923
2021-12-02 23:54:22,906 iteration 3049 : loss : 0.031956, loss_ce: 0.013531
2021-12-02 23:54:24,387 iteration 3050 : loss : 0.027102, loss_ce: 0.013633
2021-12-02 23:54:25,861 iteration 3051 : loss : 0.028752, loss_ce: 0.007803
2021-12-02 23:54:27,318 iteration 3052 : loss : 0.027882, loss_ce: 0.009856
2021-12-02 23:54:28,850 iteration 3053 : loss : 0.022527, loss_ce: 0.009783
2021-12-02 23:54:30,273 iteration 3054 : loss : 0.028959, loss_ce: 0.009037
2021-12-02 23:54:31,761 iteration 3055 : loss : 0.033393, loss_ce: 0.012584
2021-12-02 23:54:33,208 iteration 3056 : loss : 0.022243, loss_ce: 0.008780
2021-12-02 23:54:34,633 iteration 3057 : loss : 0.028227, loss_ce: 0.010933
2021-12-02 23:54:36,130 iteration 3058 : loss : 0.023796, loss_ce: 0.009104
2021-12-02 23:54:37,629 iteration 3059 : loss : 0.029908, loss_ce: 0.009080
2021-12-02 23:54:37,629 Training Data Eval:
2021-12-02 23:54:45,005   Average segmentation loss on training set: 0.0195
2021-12-02 23:54:45,006 Validation Data Eval:
2021-12-02 23:54:47,609   Average segmentation loss on validation set: 0.0613
2021-12-02 23:54:49,709 Found new lowest validation loss at iteration 3059! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/UNET_RUNMC/1channel_best_val_loss.pth
2021-12-02 23:54:51,140 iteration 3060 : loss : 0.023128, loss_ce: 0.010877
 45%|████████████▏              | 180/400 [1:21:45<1:47:26, 29.30s/it]2021-12-02 23:54:52,523 iteration 3061 : loss : 0.023348, loss_ce: 0.008666
2021-12-02 23:54:53,917 iteration 3062 : loss : 0.026905, loss_ce: 0.009396
2021-12-02 23:54:55,348 iteration 3063 : loss : 0.027960, loss_ce: 0.010700
2021-12-02 23:54:56,791 iteration 3064 : loss : 0.023896, loss_ce: 0.011212
2021-12-02 23:54:58,145 iteration 3065 : loss : 0.018641, loss_ce: 0.006187
2021-12-02 23:54:59,576 iteration 3066 : loss : 0.026431, loss_ce: 0.011755
2021-12-02 23:55:01,060 iteration 3067 : loss : 0.033693, loss_ce: 0.015292
2021-12-02 23:55:02,531 iteration 3068 : loss : 0.030246, loss_ce: 0.008805
2021-12-02 23:55:04,002 iteration 3069 : loss : 0.038687, loss_ce: 0.009252
2021-12-02 23:55:05,483 iteration 3070 : loss : 0.019763, loss_ce: 0.008268
2021-12-02 23:55:06,907 iteration 3071 : loss : 0.025080, loss_ce: 0.010910
2021-12-02 23:55:08,325 iteration 3072 : loss : 0.023512, loss_ce: 0.008207
2021-12-02 23:55:09,775 iteration 3073 : loss : 0.026120, loss_ce: 0.009919
2021-12-02 23:55:11,307 iteration 3074 : loss : 0.030298, loss_ce: 0.012330
2021-12-02 23:55:12,785 iteration 3075 : loss : 0.029160, loss_ce: 0.009627
2021-12-02 23:55:14,307 iteration 3076 : loss : 0.035416, loss_ce: 0.012483
2021-12-02 23:55:15,725 iteration 3077 : loss : 0.036880, loss_ce: 0.016692
 45%|████████████▏              | 181/400 [1:22:09<1:41:46, 27.88s/it]2021-12-02 23:55:17,193 iteration 3078 : loss : 0.028027, loss_ce: 0.011291
2021-12-02 23:55:18,756 iteration 3079 : loss : 0.021309, loss_ce: 0.007075
2021-12-02 23:55:20,145 iteration 3080 : loss : 0.046010, loss_ce: 0.013488
2021-12-02 23:55:21,640 iteration 3081 : loss : 0.027348, loss_ce: 0.008217
2021-12-02 23:55:23,098 iteration 3082 : loss : 0.032044, loss_ce: 0.007595
2021-12-02 23:55:24,622 iteration 3083 : loss : 0.031169, loss_ce: 0.011582
2021-12-02 23:55:25,995 iteration 3084 : loss : 0.024578, loss_ce: 0.010665
2021-12-02 23:55:27,494 iteration 3085 : loss : 0.024529, loss_ce: 0.009540
2021-12-02 23:55:29,058 iteration 3086 : loss : 0.029664, loss_ce: 0.015024
2021-12-02 23:55:30,502 iteration 3087 : loss : 0.022167, loss_ce: 0.008060
2021-12-02 23:55:31,980 iteration 3088 : loss : 0.019341, loss_ce: 0.006265
2021-12-02 23:55:33,528 iteration 3089 : loss : 0.035167, loss_ce: 0.011835
2021-12-02 23:55:34,932 iteration 3090 : loss : 0.024639, loss_ce: 0.011033
2021-12-02 23:55:36,405 iteration 3091 : loss : 0.026916, loss_ce: 0.013280
2021-12-02 23:55:37,999 iteration 3092 : loss : 0.034340, loss_ce: 0.013352
2021-12-02 23:55:39,426 iteration 3093 : loss : 0.022313, loss_ce: 0.008985
2021-12-02 23:55:40,899 iteration 3094 : loss : 0.024383, loss_ce: 0.009645
 46%|████████████▎              | 182/400 [1:22:35<1:38:22, 27.07s/it]2021-12-02 23:55:42,408 iteration 3095 : loss : 0.019765, loss_ce: 0.008321
2021-12-02 23:55:43,871 iteration 3096 : loss : 0.022791, loss_ce: 0.009126
2021-12-02 23:55:45,316 iteration 3097 : loss : 0.027330, loss_ce: 0.010637
2021-12-02 23:55:46,755 iteration 3098 : loss : 0.021883, loss_ce: 0.008935
2021-12-02 23:55:48,239 iteration 3099 : loss : 0.022021, loss_ce: 0.007232
2021-12-02 23:55:49,662 iteration 3100 : loss : 0.022068, loss_ce: 0.007488
2021-12-02 23:55:51,161 iteration 3101 : loss : 0.020436, loss_ce: 0.007412
2021-12-02 23:55:52,615 iteration 3102 : loss : 0.028383, loss_ce: 0.010447
2021-12-02 23:55:54,084 iteration 3103 : loss : 0.034533, loss_ce: 0.013830
2021-12-02 23:55:55,527 iteration 3104 : loss : 0.021595, loss_ce: 0.009484
2021-12-02 23:55:56,952 iteration 3105 : loss : 0.022148, loss_ce: 0.010463
2021-12-02 23:55:58,411 iteration 3106 : loss : 0.024569, loss_ce: 0.011127
2021-12-02 23:55:59,874 iteration 3107 : loss : 0.019259, loss_ce: 0.005989
2021-12-02 23:56:01,350 iteration 3108 : loss : 0.029116, loss_ce: 0.009444
2021-12-02 23:56:02,838 iteration 3109 : loss : 0.032789, loss_ce: 0.012267
2021-12-02 23:56:04,335 iteration 3110 : loss : 0.031024, loss_ce: 0.014032
2021-12-02 23:56:05,828 iteration 3111 : loss : 0.024270, loss_ce: 0.009582
 46%|████████████▎              | 183/400 [1:22:59<1:35:34, 26.43s/it]2021-12-02 23:56:07,379 iteration 3112 : loss : 0.026088, loss_ce: 0.009528
2021-12-02 23:56:08,810 iteration 3113 : loss : 0.020618, loss_ce: 0.008432
2021-12-02 23:56:10,305 iteration 3114 : loss : 0.025630, loss_ce: 0.010775
2021-12-02 23:56:11,771 iteration 3115 : loss : 0.027989, loss_ce: 0.010616
2021-12-02 23:56:13,237 iteration 3116 : loss : 0.025933, loss_ce: 0.011709
2021-12-02 23:56:14,762 iteration 3117 : loss : 0.024435, loss_ce: 0.008851
2021-12-02 23:56:16,203 iteration 3118 : loss : 0.037773, loss_ce: 0.013803
2021-12-02 23:56:17,753 iteration 3119 : loss : 0.034624, loss_ce: 0.011385
2021-12-02 23:56:19,176 iteration 3120 : loss : 0.021239, loss_ce: 0.008259
2021-12-02 23:56:20,716 iteration 3121 : loss : 0.025175, loss_ce: 0.011494
2021-12-02 23:56:22,164 iteration 3122 : loss : 0.029963, loss_ce: 0.007349
2021-12-02 23:56:23,686 iteration 3123 : loss : 0.027817, loss_ce: 0.011249
2021-12-02 23:56:25,090 iteration 3124 : loss : 0.019572, loss_ce: 0.006777
2021-12-02 23:56:26,557 iteration 3125 : loss : 0.032783, loss_ce: 0.009249
2021-12-02 23:56:28,070 iteration 3126 : loss : 0.020470, loss_ce: 0.009345
2021-12-02 23:56:29,588 iteration 3127 : loss : 0.023658, loss_ce: 0.007354
2021-12-02 23:56:31,104 iteration 3128 : loss : 0.029357, loss_ce: 0.009960
 46%|████████████▍              | 184/400 [1:23:25<1:33:54, 26.08s/it]2021-12-02 23:56:32,594 iteration 3129 : loss : 0.024901, loss_ce: 0.009068
2021-12-02 23:56:34,142 iteration 3130 : loss : 0.028465, loss_ce: 0.011833
2021-12-02 23:56:35,588 iteration 3131 : loss : 0.026560, loss_ce: 0.010156
2021-12-02 23:56:37,045 iteration 3132 : loss : 0.022258, loss_ce: 0.006577
2021-12-02 23:56:38,517 iteration 3133 : loss : 0.030100, loss_ce: 0.010950
2021-12-02 23:56:39,964 iteration 3134 : loss : 0.022927, loss_ce: 0.011625
2021-12-02 23:56:41,440 iteration 3135 : loss : 0.024260, loss_ce: 0.010191
2021-12-02 23:56:42,906 iteration 3136 : loss : 0.020716, loss_ce: 0.008576
2021-12-02 23:56:44,473 iteration 3137 : loss : 0.025179, loss_ce: 0.010317
2021-12-02 23:56:46,006 iteration 3138 : loss : 0.033707, loss_ce: 0.013378
2021-12-02 23:56:47,419 iteration 3139 : loss : 0.023179, loss_ce: 0.007833
2021-12-02 23:56:48,844 iteration 3140 : loss : 0.027455, loss_ce: 0.011893
2021-12-02 23:56:50,335 iteration 3141 : loss : 0.035926, loss_ce: 0.016815
2021-12-02 23:56:51,792 iteration 3142 : loss : 0.027317, loss_ce: 0.009448
2021-12-02 23:56:53,299 iteration 3143 : loss : 0.036526, loss_ce: 0.014097
2021-12-02 23:56:54,771 iteration 3144 : loss : 0.027084, loss_ce: 0.010222
2021-12-02 23:56:54,771 Training Data Eval:
2021-12-02 23:57:02,164   Average segmentation loss on training set: 0.0187
2021-12-02 23:57:02,164 Validation Data Eval:
2021-12-02 23:57:04,738   Average segmentation loss on validation set: 0.0754
2021-12-02 23:57:06,170 iteration 3145 : loss : 0.020256, loss_ce: 0.007896
 46%|████████████▍              | 185/400 [1:24:00<1:43:07, 28.78s/it]2021-12-02 23:57:07,844 iteration 3146 : loss : 0.062573, loss_ce: 0.017883
2021-12-02 23:57:09,367 iteration 3147 : loss : 0.025518, loss_ce: 0.011785
2021-12-02 23:57:10,781 iteration 3148 : loss : 0.026699, loss_ce: 0.010215
2021-12-02 23:57:12,287 iteration 3149 : loss : 0.033020, loss_ce: 0.009385
2021-12-02 23:57:13,786 iteration 3150 : loss : 0.028680, loss_ce: 0.008501
2021-12-02 23:57:15,279 iteration 3151 : loss : 0.035843, loss_ce: 0.011705
2021-12-02 23:57:16,779 iteration 3152 : loss : 0.032093, loss_ce: 0.010733
2021-12-02 23:57:18,256 iteration 3153 : loss : 0.033845, loss_ce: 0.017413
2021-12-02 23:57:19,791 iteration 3154 : loss : 0.029730, loss_ce: 0.010889
2021-12-02 23:57:21,287 iteration 3155 : loss : 0.023778, loss_ce: 0.008062
2021-12-02 23:57:22,701 iteration 3156 : loss : 0.027539, loss_ce: 0.008811
2021-12-02 23:57:24,177 iteration 3157 : loss : 0.026776, loss_ce: 0.012341
2021-12-02 23:57:25,602 iteration 3158 : loss : 0.037408, loss_ce: 0.009364
2021-12-02 23:57:27,103 iteration 3159 : loss : 0.030963, loss_ce: 0.015531
2021-12-02 23:57:28,611 iteration 3160 : loss : 0.024079, loss_ce: 0.008962
2021-12-02 23:57:30,155 iteration 3161 : loss : 0.023242, loss_ce: 0.008163
2021-12-02 23:57:31,637 iteration 3162 : loss : 0.034631, loss_ce: 0.011720
 46%|████████████▌              | 186/400 [1:24:25<1:39:06, 27.79s/it]2021-12-02 23:57:33,115 iteration 3163 : loss : 0.034747, loss_ce: 0.011440
2021-12-02 23:57:34,678 iteration 3164 : loss : 0.038674, loss_ce: 0.016598
2021-12-02 23:57:36,183 iteration 3165 : loss : 0.026381, loss_ce: 0.010452
2021-12-02 23:57:37,604 iteration 3166 : loss : 0.024726, loss_ce: 0.009699
2021-12-02 23:57:39,101 iteration 3167 : loss : 0.026763, loss_ce: 0.009278
2021-12-02 23:57:40,559 iteration 3168 : loss : 0.023553, loss_ce: 0.009753
2021-12-02 23:57:42,045 iteration 3169 : loss : 0.034571, loss_ce: 0.015208
2021-12-02 23:57:43,517 iteration 3170 : loss : 0.029875, loss_ce: 0.013025
2021-12-02 23:57:44,889 iteration 3171 : loss : 0.027732, loss_ce: 0.007628
2021-12-02 23:57:46,339 iteration 3172 : loss : 0.024313, loss_ce: 0.009008
2021-12-02 23:57:47,818 iteration 3173 : loss : 0.044824, loss_ce: 0.013840
2021-12-02 23:57:49,267 iteration 3174 : loss : 0.028804, loss_ce: 0.013518
2021-12-02 23:57:50,701 iteration 3175 : loss : 0.026674, loss_ce: 0.007602
2021-12-02 23:57:52,253 iteration 3176 : loss : 0.045689, loss_ce: 0.013722
2021-12-02 23:57:53,709 iteration 3177 : loss : 0.039634, loss_ce: 0.018441
2021-12-02 23:57:55,249 iteration 3178 : loss : 0.021930, loss_ce: 0.006215
2021-12-02 23:57:56,717 iteration 3179 : loss : 0.058428, loss_ce: 0.028824
 47%|████████████▌              | 187/400 [1:24:50<1:35:45, 26.97s/it]2021-12-02 23:57:58,243 iteration 3180 : loss : 0.065268, loss_ce: 0.028602
2021-12-02 23:57:59,685 iteration 3181 : loss : 0.022050, loss_ce: 0.010364
2021-12-02 23:58:01,111 iteration 3182 : loss : 0.021877, loss_ce: 0.009617
2021-12-02 23:58:02,661 iteration 3183 : loss : 0.032099, loss_ce: 0.012611
2021-12-02 23:58:04,123 iteration 3184 : loss : 0.027909, loss_ce: 0.009886
2021-12-02 23:58:05,595 iteration 3185 : loss : 0.038619, loss_ce: 0.012914
2021-12-02 23:58:07,101 iteration 3186 : loss : 0.021906, loss_ce: 0.009064
2021-12-02 23:58:08,609 iteration 3187 : loss : 0.024042, loss_ce: 0.009739
2021-12-02 23:58:10,127 iteration 3188 : loss : 0.031069, loss_ce: 0.011385
2021-12-02 23:58:11,590 iteration 3189 : loss : 0.025050, loss_ce: 0.009380
2021-12-02 23:58:13,149 iteration 3190 : loss : 0.030789, loss_ce: 0.010849
2021-12-02 23:58:14,655 iteration 3191 : loss : 0.025308, loss_ce: 0.008719
2021-12-02 23:58:16,067 iteration 3192 : loss : 0.028388, loss_ce: 0.005935
2021-12-02 23:58:17,546 iteration 3193 : loss : 0.024977, loss_ce: 0.010124
2021-12-02 23:58:19,121 iteration 3194 : loss : 0.034878, loss_ce: 0.013836
2021-12-02 23:58:20,591 iteration 3195 : loss : 0.026942, loss_ce: 0.012415
2021-12-02 23:58:22,056 iteration 3196 : loss : 0.027887, loss_ce: 0.014108
 47%|████████████▋              | 188/400 [1:25:16<1:33:34, 26.48s/it]2021-12-02 23:58:23,560 iteration 3197 : loss : 0.016220, loss_ce: 0.006761
2021-12-02 23:58:25,054 iteration 3198 : loss : 0.027920, loss_ce: 0.013447
2021-12-02 23:58:26,546 iteration 3199 : loss : 0.022314, loss_ce: 0.005728
2021-12-02 23:58:28,054 iteration 3200 : loss : 0.039641, loss_ce: 0.015125
2021-12-02 23:58:29,571 iteration 3201 : loss : 0.036954, loss_ce: 0.016171
2021-12-02 23:58:31,091 iteration 3202 : loss : 0.037393, loss_ce: 0.010732
2021-12-02 23:58:32,490 iteration 3203 : loss : 0.022958, loss_ce: 0.010700
2021-12-02 23:58:33,889 iteration 3204 : loss : 0.021316, loss_ce: 0.008968
2021-12-02 23:58:35,298 iteration 3205 : loss : 0.031110, loss_ce: 0.009192
2021-12-02 23:58:36,677 iteration 3206 : loss : 0.020574, loss_ce: 0.006379
2021-12-02 23:58:38,179 iteration 3207 : loss : 0.037197, loss_ce: 0.014100
2021-12-02 23:58:39,639 iteration 3208 : loss : 0.025178, loss_ce: 0.009592
2021-12-02 23:58:41,070 iteration 3209 : loss : 0.033402, loss_ce: 0.011744
2021-12-02 23:58:42,555 iteration 3210 : loss : 0.032670, loss_ce: 0.015655
2021-12-02 23:58:43,977 iteration 3211 : loss : 0.025300, loss_ce: 0.007244
2021-12-02 23:58:45,515 iteration 3212 : loss : 0.033970, loss_ce: 0.013882
2021-12-02 23:58:47,061 iteration 3213 : loss : 0.031457, loss_ce: 0.009562
 47%|████████████▊              | 189/400 [1:25:41<1:31:33, 26.04s/it]2021-12-02 23:58:48,524 iteration 3214 : loss : 0.021076, loss_ce: 0.008631
2021-12-02 23:58:49,973 iteration 3215 : loss : 0.026118, loss_ce: 0.011233
2021-12-02 23:58:51,431 iteration 3216 : loss : 0.038668, loss_ce: 0.017800
2021-12-02 23:58:52,928 iteration 3217 : loss : 0.029603, loss_ce: 0.012406
2021-12-02 23:58:54,401 iteration 3218 : loss : 0.029911, loss_ce: 0.010231
2021-12-02 23:58:55,869 iteration 3219 : loss : 0.027397, loss_ce: 0.010470
2021-12-02 23:58:57,301 iteration 3220 : loss : 0.019832, loss_ce: 0.007832
2021-12-02 23:58:58,859 iteration 3221 : loss : 0.047748, loss_ce: 0.021752
2021-12-02 23:59:00,308 iteration 3222 : loss : 0.025695, loss_ce: 0.007471
2021-12-02 23:59:01,805 iteration 3223 : loss : 0.025032, loss_ce: 0.007786
2021-12-02 23:59:03,372 iteration 3224 : loss : 0.030732, loss_ce: 0.008433
2021-12-02 23:59:04,841 iteration 3225 : loss : 0.033624, loss_ce: 0.016113
2021-12-02 23:59:06,316 iteration 3226 : loss : 0.030330, loss_ce: 0.014379
2021-12-02 23:59:07,790 iteration 3227 : loss : 0.028131, loss_ce: 0.010275
2021-12-02 23:59:09,221 iteration 3228 : loss : 0.027453, loss_ce: 0.007882
2021-12-02 23:59:10,622 iteration 3229 : loss : 0.030440, loss_ce: 0.009051
2021-12-02 23:59:10,622 Training Data Eval:
2021-12-02 23:59:18,027   Average segmentation loss on training set: 0.0210
2021-12-02 23:59:18,027 Validation Data Eval:
2021-12-02 23:59:20,609   Average segmentation loss on validation set: 0.0800
2021-12-02 23:59:22,037 iteration 3230 : loss : 0.028079, loss_ce: 0.010007
 48%|████████████▊              | 190/400 [1:26:16<1:40:31, 28.72s/it]2021-12-02 23:59:23,528 iteration 3231 : loss : 0.027502, loss_ce: 0.006246
2021-12-02 23:59:24,969 iteration 3232 : loss : 0.022867, loss_ce: 0.007013
2021-12-02 23:59:26,437 iteration 3233 : loss : 0.031226, loss_ce: 0.014603
2021-12-02 23:59:27,926 iteration 3234 : loss : 0.022500, loss_ce: 0.007491
2021-12-02 23:59:29,406 iteration 3235 : loss : 0.032664, loss_ce: 0.009609
2021-12-02 23:59:30,815 iteration 3236 : loss : 0.022261, loss_ce: 0.011423
2021-12-02 23:59:32,374 iteration 3237 : loss : 0.025895, loss_ce: 0.011161
2021-12-02 23:59:33,843 iteration 3238 : loss : 0.020806, loss_ce: 0.009698
2021-12-02 23:59:35,325 iteration 3239 : loss : 0.021955, loss_ce: 0.008448
2021-12-02 23:59:36,765 iteration 3240 : loss : 0.035807, loss_ce: 0.009903
2021-12-02 23:59:38,188 iteration 3241 : loss : 0.032880, loss_ce: 0.007483
2021-12-02 23:59:39,667 iteration 3242 : loss : 0.033184, loss_ce: 0.013917
2021-12-02 23:59:41,063 iteration 3243 : loss : 0.032259, loss_ce: 0.011379
2021-12-02 23:59:42,541 iteration 3244 : loss : 0.028759, loss_ce: 0.010473
2021-12-02 23:59:43,968 iteration 3245 : loss : 0.018977, loss_ce: 0.008745
2021-12-02 23:59:45,499 iteration 3246 : loss : 0.029213, loss_ce: 0.014049
2021-12-02 23:59:46,926 iteration 3247 : loss : 0.027440, loss_ce: 0.014778
 48%|████████████▉              | 191/400 [1:26:41<1:36:02, 27.57s/it]2021-12-02 23:59:48,406 iteration 3248 : loss : 0.019938, loss_ce: 0.007292
2021-12-02 23:59:49,826 iteration 3249 : loss : 0.027065, loss_ce: 0.009489
2021-12-02 23:59:51,280 iteration 3250 : loss : 0.028526, loss_ce: 0.008975
2021-12-02 23:59:52,735 iteration 3251 : loss : 0.021295, loss_ce: 0.008917
2021-12-02 23:59:54,220 iteration 3252 : loss : 0.022490, loss_ce: 0.007154
2021-12-02 23:59:55,677 iteration 3253 : loss : 0.019910, loss_ce: 0.008683
2021-12-02 23:59:57,122 iteration 3254 : loss : 0.023274, loss_ce: 0.008905
2021-12-02 23:59:58,517 iteration 3255 : loss : 0.027043, loss_ce: 0.010512
2021-12-03 00:00:00,009 iteration 3256 : loss : 0.024152, loss_ce: 0.009749
2021-12-03 00:00:01,426 iteration 3257 : loss : 0.023088, loss_ce: 0.009709
2021-12-03 00:00:02,881 iteration 3258 : loss : 0.029886, loss_ce: 0.012528
2021-12-03 00:00:04,292 iteration 3259 : loss : 0.024599, loss_ce: 0.010408
2021-12-03 00:00:05,761 iteration 3260 : loss : 0.021356, loss_ce: 0.008508
2021-12-03 00:00:07,208 iteration 3261 : loss : 0.040135, loss_ce: 0.011120
2021-12-03 00:00:08,700 iteration 3262 : loss : 0.030148, loss_ce: 0.011382
2021-12-03 00:00:10,258 iteration 3263 : loss : 0.025883, loss_ce: 0.009311
2021-12-03 00:00:11,732 iteration 3264 : loss : 0.027474, loss_ce: 0.011319
 48%|████████████▉              | 192/400 [1:27:05<1:32:42, 26.74s/it]2021-12-03 00:00:13,206 iteration 3265 : loss : 0.021002, loss_ce: 0.008433
2021-12-03 00:00:14,719 iteration 3266 : loss : 0.027185, loss_ce: 0.012116
2021-12-03 00:00:16,197 iteration 3267 : loss : 0.022208, loss_ce: 0.008862
2021-12-03 00:00:17,622 iteration 3268 : loss : 0.020502, loss_ce: 0.007986
2021-12-03 00:00:19,142 iteration 3269 : loss : 0.032117, loss_ce: 0.014106
2021-12-03 00:00:20,683 iteration 3270 : loss : 0.031003, loss_ce: 0.008763
2021-12-03 00:00:22,180 iteration 3271 : loss : 0.028370, loss_ce: 0.009581
2021-12-03 00:00:23,680 iteration 3272 : loss : 0.030867, loss_ce: 0.010629
2021-12-03 00:00:25,083 iteration 3273 : loss : 0.022170, loss_ce: 0.006561
2021-12-03 00:00:26,552 iteration 3274 : loss : 0.021874, loss_ce: 0.010419
2021-12-03 00:00:28,078 iteration 3275 : loss : 0.031207, loss_ce: 0.008754
2021-12-03 00:00:29,523 iteration 3276 : loss : 0.023296, loss_ce: 0.008497
2021-12-03 00:00:31,005 iteration 3277 : loss : 0.024842, loss_ce: 0.012961
2021-12-03 00:00:32,468 iteration 3278 : loss : 0.028359, loss_ce: 0.011139
2021-12-03 00:00:33,906 iteration 3279 : loss : 0.023533, loss_ce: 0.007834
2021-12-03 00:00:35,354 iteration 3280 : loss : 0.030345, loss_ce: 0.012238
2021-12-03 00:00:36,768 iteration 3281 : loss : 0.018608, loss_ce: 0.005700
 48%|█████████████              | 193/400 [1:27:30<1:30:29, 26.23s/it]2021-12-03 00:00:38,301 iteration 3282 : loss : 0.030262, loss_ce: 0.012477
2021-12-03 00:00:39,743 iteration 3283 : loss : 0.018974, loss_ce: 0.006044
2021-12-03 00:00:41,196 iteration 3284 : loss : 0.032870, loss_ce: 0.016040
2021-12-03 00:00:42,643 iteration 3285 : loss : 0.026378, loss_ce: 0.009260
2021-12-03 00:00:44,093 iteration 3286 : loss : 0.018600, loss_ce: 0.006879
2021-12-03 00:00:45,573 iteration 3287 : loss : 0.027225, loss_ce: 0.010836
2021-12-03 00:00:47,000 iteration 3288 : loss : 0.031443, loss_ce: 0.016915
2021-12-03 00:00:48,434 iteration 3289 : loss : 0.030393, loss_ce: 0.009559
2021-12-03 00:00:49,943 iteration 3290 : loss : 0.030114, loss_ce: 0.008248
2021-12-03 00:00:51,456 iteration 3291 : loss : 0.031839, loss_ce: 0.010899
2021-12-03 00:00:52,930 iteration 3292 : loss : 0.029237, loss_ce: 0.009148
2021-12-03 00:00:54,391 iteration 3293 : loss : 0.022868, loss_ce: 0.009892
2021-12-03 00:00:55,824 iteration 3294 : loss : 0.024160, loss_ce: 0.010026
2021-12-03 00:00:57,362 iteration 3295 : loss : 0.031900, loss_ce: 0.012882
2021-12-03 00:00:58,845 iteration 3296 : loss : 0.025382, loss_ce: 0.007100
2021-12-03 00:01:00,255 iteration 3297 : loss : 0.018072, loss_ce: 0.007543
2021-12-03 00:01:01,746 iteration 3298 : loss : 0.022047, loss_ce: 0.008883
 48%|█████████████              | 194/400 [1:27:55<1:28:46, 25.85s/it]2021-12-03 00:01:03,193 iteration 3299 : loss : 0.021337, loss_ce: 0.009146
2021-12-03 00:01:04,634 iteration 3300 : loss : 0.036330, loss_ce: 0.010448
2021-12-03 00:01:06,152 iteration 3301 : loss : 0.025453, loss_ce: 0.011215
2021-12-03 00:01:07,611 iteration 3302 : loss : 0.030676, loss_ce: 0.011571
2021-12-03 00:01:09,044 iteration 3303 : loss : 0.020669, loss_ce: 0.008253
2021-12-03 00:01:10,505 iteration 3304 : loss : 0.026365, loss_ce: 0.009575
2021-12-03 00:01:12,001 iteration 3305 : loss : 0.023657, loss_ce: 0.007308
2021-12-03 00:01:13,522 iteration 3306 : loss : 0.031725, loss_ce: 0.013520
2021-12-03 00:01:14,956 iteration 3307 : loss : 0.027605, loss_ce: 0.010627
2021-12-03 00:01:16,412 iteration 3308 : loss : 0.025464, loss_ce: 0.010840
2021-12-03 00:01:17,864 iteration 3309 : loss : 0.029329, loss_ce: 0.006301
2021-12-03 00:01:19,383 iteration 3310 : loss : 0.049132, loss_ce: 0.016998
2021-12-03 00:01:20,919 iteration 3311 : loss : 0.028414, loss_ce: 0.008950
2021-12-03 00:01:22,322 iteration 3312 : loss : 0.020590, loss_ce: 0.006162
2021-12-03 00:01:23,751 iteration 3313 : loss : 0.020750, loss_ce: 0.007196
2021-12-03 00:01:25,278 iteration 3314 : loss : 0.027675, loss_ce: 0.009462
2021-12-03 00:01:25,278 Training Data Eval:
2021-12-03 00:01:32,671   Average segmentation loss on training set: 0.0184
2021-12-03 00:01:32,671 Validation Data Eval:
2021-12-03 00:01:35,263   Average segmentation loss on validation set: 0.0637
2021-12-03 00:01:36,684 iteration 3315 : loss : 0.016609, loss_ce: 0.007803
 49%|█████████████▏             | 195/400 [1:28:30<1:37:38, 28.58s/it]2021-12-03 00:01:38,166 iteration 3316 : loss : 0.017730, loss_ce: 0.006739
2021-12-03 00:01:39,602 iteration 3317 : loss : 0.025757, loss_ce: 0.009919
2021-12-03 00:01:41,149 iteration 3318 : loss : 0.024534, loss_ce: 0.010607
2021-12-03 00:01:42,592 iteration 3319 : loss : 0.024136, loss_ce: 0.008719
2021-12-03 00:01:44,043 iteration 3320 : loss : 0.024035, loss_ce: 0.008404
2021-12-03 00:01:45,507 iteration 3321 : loss : 0.021288, loss_ce: 0.006527
2021-12-03 00:01:46,963 iteration 3322 : loss : 0.029703, loss_ce: 0.012278
2021-12-03 00:01:48,385 iteration 3323 : loss : 0.024913, loss_ce: 0.007419
2021-12-03 00:01:49,933 iteration 3324 : loss : 0.027816, loss_ce: 0.012129
2021-12-03 00:01:51,362 iteration 3325 : loss : 0.023412, loss_ce: 0.007586
2021-12-03 00:01:52,851 iteration 3326 : loss : 0.022603, loss_ce: 0.008566
2021-12-03 00:01:54,407 iteration 3327 : loss : 0.041747, loss_ce: 0.014010
2021-12-03 00:01:55,879 iteration 3328 : loss : 0.023835, loss_ce: 0.008508
2021-12-03 00:01:57,309 iteration 3329 : loss : 0.020729, loss_ce: 0.009866
2021-12-03 00:01:58,755 iteration 3330 : loss : 0.027204, loss_ce: 0.009570
2021-12-03 00:02:00,227 iteration 3331 : loss : 0.022327, loss_ce: 0.007493
2021-12-03 00:02:01,623 iteration 3332 : loss : 0.016621, loss_ce: 0.007362
 49%|█████████████▏             | 196/400 [1:28:55<1:33:27, 27.49s/it]2021-12-03 00:02:03,133 iteration 3333 : loss : 0.019877, loss_ce: 0.007633
2021-12-03 00:02:04,605 iteration 3334 : loss : 0.017833, loss_ce: 0.008074
2021-12-03 00:02:05,994 iteration 3335 : loss : 0.017386, loss_ce: 0.007286
2021-12-03 00:02:07,448 iteration 3336 : loss : 0.031594, loss_ce: 0.010852
2021-12-03 00:02:08,939 iteration 3337 : loss : 0.029047, loss_ce: 0.012145
2021-12-03 00:02:10,478 iteration 3338 : loss : 0.032108, loss_ce: 0.016603
2021-12-03 00:02:11,914 iteration 3339 : loss : 0.039880, loss_ce: 0.010139
2021-12-03 00:02:13,341 iteration 3340 : loss : 0.020450, loss_ce: 0.007270
2021-12-03 00:02:14,790 iteration 3341 : loss : 0.016954, loss_ce: 0.006299
2021-12-03 00:02:16,292 iteration 3342 : loss : 0.028540, loss_ce: 0.013851
2021-12-03 00:02:17,787 iteration 3343 : loss : 0.025660, loss_ce: 0.009257
2021-12-03 00:02:19,259 iteration 3344 : loss : 0.027974, loss_ce: 0.009265
2021-12-03 00:02:20,691 iteration 3345 : loss : 0.020734, loss_ce: 0.007288
2021-12-03 00:02:22,169 iteration 3346 : loss : 0.021900, loss_ce: 0.011244
2021-12-03 00:02:23,677 iteration 3347 : loss : 0.036789, loss_ce: 0.009149
2021-12-03 00:02:25,233 iteration 3348 : loss : 0.033486, loss_ce: 0.011827
2021-12-03 00:02:26,704 iteration 3349 : loss : 0.028646, loss_ce: 0.010500
 49%|█████████████▎             | 197/400 [1:29:20<1:30:33, 26.77s/it]2021-12-03 00:02:28,183 iteration 3350 : loss : 0.019297, loss_ce: 0.007405
2021-12-03 00:02:29,606 iteration 3351 : loss : 0.027979, loss_ce: 0.011820
2021-12-03 00:02:31,041 iteration 3352 : loss : 0.024205, loss_ce: 0.009386
2021-12-03 00:02:32,513 iteration 3353 : loss : 0.025433, loss_ce: 0.009366
2021-12-03 00:02:33,989 iteration 3354 : loss : 0.020920, loss_ce: 0.006777
2021-12-03 00:02:35,519 iteration 3355 : loss : 0.025914, loss_ce: 0.013679
2021-12-03 00:02:37,017 iteration 3356 : loss : 0.042584, loss_ce: 0.011009
2021-12-03 00:02:38,549 iteration 3357 : loss : 0.023519, loss_ce: 0.007652
2021-12-03 00:02:40,054 iteration 3358 : loss : 0.028925, loss_ce: 0.009216
2021-12-03 00:02:41,534 iteration 3359 : loss : 0.024923, loss_ce: 0.010078
2021-12-03 00:02:43,087 iteration 3360 : loss : 0.030838, loss_ce: 0.012870
2021-12-03 00:02:44,501 iteration 3361 : loss : 0.028820, loss_ce: 0.007526
2021-12-03 00:02:45,926 iteration 3362 : loss : 0.024720, loss_ce: 0.009955
2021-12-03 00:02:47,338 iteration 3363 : loss : 0.022343, loss_ce: 0.009662
2021-12-03 00:02:48,807 iteration 3364 : loss : 0.029877, loss_ce: 0.009692
2021-12-03 00:02:50,223 iteration 3365 : loss : 0.018863, loss_ce: 0.009560
2021-12-03 00:02:51,672 iteration 3366 : loss : 0.020615, loss_ce: 0.008214
 50%|█████████████▎             | 198/400 [1:29:45<1:28:17, 26.23s/it]2021-12-03 00:02:53,194 iteration 3367 : loss : 0.032524, loss_ce: 0.013233
2021-12-03 00:02:54,658 iteration 3368 : loss : 0.028135, loss_ce: 0.014322
2021-12-03 00:02:56,138 iteration 3369 : loss : 0.022139, loss_ce: 0.008360
2021-12-03 00:02:57,621 iteration 3370 : loss : 0.023814, loss_ce: 0.009909
2021-12-03 00:02:59,013 iteration 3371 : loss : 0.014505, loss_ce: 0.005576
2021-12-03 00:03:00,469 iteration 3372 : loss : 0.025886, loss_ce: 0.013221
2021-12-03 00:03:01,925 iteration 3373 : loss : 0.018496, loss_ce: 0.008739
2021-12-03 00:03:03,345 iteration 3374 : loss : 0.020316, loss_ce: 0.008129
2021-12-03 00:03:04,751 iteration 3375 : loss : 0.026361, loss_ce: 0.011644
2021-12-03 00:03:06,182 iteration 3376 : loss : 0.037252, loss_ce: 0.013727
2021-12-03 00:03:07,692 iteration 3377 : loss : 0.038681, loss_ce: 0.011664
2021-12-03 00:03:09,162 iteration 3378 : loss : 0.024567, loss_ce: 0.009233
2021-12-03 00:03:10,556 iteration 3379 : loss : 0.019219, loss_ce: 0.008681
2021-12-03 00:03:12,080 iteration 3380 : loss : 0.032017, loss_ce: 0.011967
2021-12-03 00:03:13,487 iteration 3381 : loss : 0.052219, loss_ce: 0.007922
2021-12-03 00:03:14,967 iteration 3382 : loss : 0.033456, loss_ce: 0.012027
2021-12-03 00:03:16,414 iteration 3383 : loss : 0.027732, loss_ce: 0.008836
 50%|█████████████▍             | 199/400 [1:30:10<1:26:22, 25.78s/it]2021-12-03 00:03:17,886 iteration 3384 : loss : 0.027950, loss_ce: 0.008474
2021-12-03 00:03:19,393 iteration 3385 : loss : 0.027212, loss_ce: 0.011573
2021-12-03 00:03:20,894 iteration 3386 : loss : 0.037441, loss_ce: 0.015646
2021-12-03 00:03:22,376 iteration 3387 : loss : 0.043416, loss_ce: 0.016001
2021-12-03 00:03:23,775 iteration 3388 : loss : 0.030517, loss_ce: 0.009883
2021-12-03 00:03:25,254 iteration 3389 : loss : 0.038119, loss_ce: 0.014678
2021-12-03 00:03:26,653 iteration 3390 : loss : 0.045181, loss_ce: 0.011999
2021-12-03 00:03:28,196 iteration 3391 : loss : 0.049106, loss_ce: 0.013709
2021-12-03 00:03:29,682 iteration 3392 : loss : 0.030583, loss_ce: 0.011175
2021-12-03 00:03:31,171 iteration 3393 : loss : 0.029536, loss_ce: 0.011522
2021-12-03 00:03:32,564 iteration 3394 : loss : 0.027935, loss_ce: 0.009999
2021-12-03 00:03:34,135 iteration 3395 : loss : 0.043838, loss_ce: 0.015200
2021-12-03 00:03:35,613 iteration 3396 : loss : 0.038243, loss_ce: 0.012908
2021-12-03 00:03:37,061 iteration 3397 : loss : 0.027591, loss_ce: 0.010865
2021-12-03 00:03:38,554 iteration 3398 : loss : 0.028724, loss_ce: 0.009982
2021-12-03 00:03:40,031 iteration 3399 : loss : 0.026731, loss_ce: 0.011648
2021-12-03 00:03:40,031 Training Data Eval:
2021-12-03 00:03:47,390   Average segmentation loss on training set: 0.0252
2021-12-03 00:03:47,390 Validation Data Eval:
2021-12-03 00:03:49,949   Average segmentation loss on validation set: 0.0752
2021-12-03 00:03:51,430 iteration 3400 : loss : 0.031645, loss_ce: 0.009161
 50%|█████████████▌             | 200/400 [1:30:45<1:35:10, 28.55s/it]2021-12-03 00:03:53,067 iteration 3401 : loss : 0.027094, loss_ce: 0.009812
2021-12-03 00:03:54,575 iteration 3402 : loss : 0.034243, loss_ce: 0.013110
2021-12-03 00:03:56,008 iteration 3403 : loss : 0.028693, loss_ce: 0.013525
2021-12-03 00:03:57,463 iteration 3404 : loss : 0.027828, loss_ce: 0.008275
2021-12-03 00:03:58,924 iteration 3405 : loss : 0.030764, loss_ce: 0.012984
2021-12-03 00:04:00,433 iteration 3406 : loss : 0.034122, loss_ce: 0.012066
2021-12-03 00:04:01,889 iteration 3407 : loss : 0.035675, loss_ce: 0.013733
2021-12-03 00:04:03,358 iteration 3408 : loss : 0.028208, loss_ce: 0.010166
2021-12-03 00:04:04,849 iteration 3409 : loss : 0.034301, loss_ce: 0.015096
2021-12-03 00:04:06,347 iteration 3410 : loss : 0.022401, loss_ce: 0.008102
2021-12-03 00:04:07,879 iteration 3411 : loss : 0.030501, loss_ce: 0.011663
2021-12-03 00:04:09,306 iteration 3412 : loss : 0.028536, loss_ce: 0.009463
2021-12-03 00:04:10,714 iteration 3413 : loss : 0.019756, loss_ce: 0.008306
2021-12-03 00:04:12,192 iteration 3414 : loss : 0.044756, loss_ce: 0.011698
2021-12-03 00:04:13,701 iteration 3415 : loss : 0.028247, loss_ce: 0.012795
2021-12-03 00:04:15,195 iteration 3416 : loss : 0.021611, loss_ce: 0.005841
2021-12-03 00:04:16,724 iteration 3417 : loss : 0.047297, loss_ce: 0.021488
 50%|█████████████▌             | 201/400 [1:31:10<1:31:27, 27.57s/it]2021-12-03 00:04:18,241 iteration 3418 : loss : 0.021782, loss_ce: 0.009675
2021-12-03 00:04:19,719 iteration 3419 : loss : 0.031442, loss_ce: 0.010865
2021-12-03 00:04:21,248 iteration 3420 : loss : 0.034370, loss_ce: 0.011546
2021-12-03 00:04:22,731 iteration 3421 : loss : 0.026257, loss_ce: 0.008785
2021-12-03 00:04:24,149 iteration 3422 : loss : 0.023313, loss_ce: 0.007027
2021-12-03 00:04:25,607 iteration 3423 : loss : 0.019678, loss_ce: 0.007699
2021-12-03 00:04:27,063 iteration 3424 : loss : 0.024459, loss_ce: 0.009797
2021-12-03 00:04:28,487 iteration 3425 : loss : 0.023259, loss_ce: 0.010355
2021-12-03 00:04:29,961 iteration 3426 : loss : 0.028252, loss_ce: 0.009479
2021-12-03 00:04:31,449 iteration 3427 : loss : 0.034723, loss_ce: 0.011253
2021-12-03 00:04:32,945 iteration 3428 : loss : 0.031546, loss_ce: 0.011409
2021-12-03 00:04:34,453 iteration 3429 : loss : 0.027941, loss_ce: 0.011656
2021-12-03 00:04:35,973 iteration 3430 : loss : 0.036807, loss_ce: 0.016255
2021-12-03 00:04:37,384 iteration 3431 : loss : 0.023901, loss_ce: 0.009829
2021-12-03 00:04:38,812 iteration 3432 : loss : 0.026193, loss_ce: 0.008417
2021-12-03 00:04:40,245 iteration 3433 : loss : 0.024235, loss_ce: 0.008186
2021-12-03 00:04:41,747 iteration 3434 : loss : 0.045344, loss_ce: 0.014127
 50%|█████████████▋             | 202/400 [1:31:35<1:28:28, 26.81s/it]2021-12-03 00:04:43,188 iteration 3435 : loss : 0.026058, loss_ce: 0.008172
2021-12-03 00:04:44,649 iteration 3436 : loss : 0.022557, loss_ce: 0.008896
2021-12-03 00:04:46,210 iteration 3437 : loss : 0.027589, loss_ce: 0.012097
2021-12-03 00:04:47,735 iteration 3438 : loss : 0.036742, loss_ce: 0.015282
2021-12-03 00:04:49,237 iteration 3439 : loss : 0.028228, loss_ce: 0.009143
2021-12-03 00:04:50,676 iteration 3440 : loss : 0.021344, loss_ce: 0.007401
2021-12-03 00:04:52,149 iteration 3441 : loss : 0.025956, loss_ce: 0.010619
2021-12-03 00:04:53,735 iteration 3442 : loss : 0.030006, loss_ce: 0.009938
2021-12-03 00:04:55,237 iteration 3443 : loss : 0.024950, loss_ce: 0.007703
2021-12-03 00:04:56,722 iteration 3444 : loss : 0.027268, loss_ce: 0.012410
2021-12-03 00:04:58,189 iteration 3445 : loss : 0.031278, loss_ce: 0.009159
2021-12-03 00:04:59,630 iteration 3446 : loss : 0.023176, loss_ce: 0.009508
2021-12-03 00:05:01,064 iteration 3447 : loss : 0.028260, loss_ce: 0.009607
2021-12-03 00:05:02,565 iteration 3448 : loss : 0.033502, loss_ce: 0.007513
2021-12-03 00:05:04,051 iteration 3449 : loss : 0.025300, loss_ce: 0.010446
2021-12-03 00:05:05,524 iteration 3450 : loss : 0.029122, loss_ce: 0.012660
2021-12-03 00:05:07,068 iteration 3451 : loss : 0.021772, loss_ce: 0.007835
 51%|█████████████▋             | 203/400 [1:32:01<1:26:33, 26.36s/it]2021-12-03 00:05:08,580 iteration 3452 : loss : 0.018949, loss_ce: 0.007306
2021-12-03 00:05:10,025 iteration 3453 : loss : 0.024197, loss_ce: 0.009032
2021-12-03 00:05:11,468 iteration 3454 : loss : 0.023263, loss_ce: 0.007375
2021-12-03 00:05:13,007 iteration 3455 : loss : 0.029766, loss_ce: 0.013372
2021-12-03 00:05:14,444 iteration 3456 : loss : 0.018709, loss_ce: 0.006573
2021-12-03 00:05:15,993 iteration 3457 : loss : 0.046621, loss_ce: 0.018213
2021-12-03 00:05:17,469 iteration 3458 : loss : 0.025045, loss_ce: 0.008616
2021-12-03 00:05:18,918 iteration 3459 : loss : 0.023843, loss_ce: 0.009992
2021-12-03 00:05:20,404 iteration 3460 : loss : 0.025011, loss_ce: 0.010391
2021-12-03 00:05:21,876 iteration 3461 : loss : 0.025442, loss_ce: 0.009712
2021-12-03 00:05:23,322 iteration 3462 : loss : 0.024104, loss_ce: 0.010360
2021-12-03 00:05:24,820 iteration 3463 : loss : 0.033506, loss_ce: 0.012783
2021-12-03 00:05:26,242 iteration 3464 : loss : 0.025194, loss_ce: 0.008281
2021-12-03 00:05:27,744 iteration 3465 : loss : 0.035402, loss_ce: 0.011973
2021-12-03 00:05:29,213 iteration 3466 : loss : 0.019402, loss_ce: 0.006851
2021-12-03 00:05:30,689 iteration 3467 : loss : 0.029316, loss_ce: 0.016666
2021-12-03 00:05:32,183 iteration 3468 : loss : 0.025757, loss_ce: 0.010351
 51%|█████████████▊             | 204/400 [1:32:26<1:24:53, 25.99s/it]2021-12-03 00:05:33,642 iteration 3469 : loss : 0.026600, loss_ce: 0.008312
2021-12-03 00:05:35,142 iteration 3470 : loss : 0.030038, loss_ce: 0.010396
2021-12-03 00:05:36,532 iteration 3471 : loss : 0.024238, loss_ce: 0.007637
2021-12-03 00:05:38,033 iteration 3472 : loss : 0.033180, loss_ce: 0.013531
2021-12-03 00:05:39,610 iteration 3473 : loss : 0.028373, loss_ce: 0.011802
2021-12-03 00:05:41,062 iteration 3474 : loss : 0.021689, loss_ce: 0.006536
2021-12-03 00:05:42,595 iteration 3475 : loss : 0.051574, loss_ce: 0.012894
2021-12-03 00:05:44,037 iteration 3476 : loss : 0.025285, loss_ce: 0.007930
2021-12-03 00:05:45,529 iteration 3477 : loss : 0.028538, loss_ce: 0.007891
2021-12-03 00:05:46,978 iteration 3478 : loss : 0.020453, loss_ce: 0.007471
2021-12-03 00:05:48,406 iteration 3479 : loss : 0.027227, loss_ce: 0.010889
2021-12-03 00:05:49,802 iteration 3480 : loss : 0.026735, loss_ce: 0.010102
2021-12-03 00:05:51,251 iteration 3481 : loss : 0.029886, loss_ce: 0.010876
2021-12-03 00:05:52,712 iteration 3482 : loss : 0.031709, loss_ce: 0.012635
2021-12-03 00:05:54,220 iteration 3483 : loss : 0.023101, loss_ce: 0.009580
2021-12-03 00:05:55,601 iteration 3484 : loss : 0.022506, loss_ce: 0.008651
2021-12-03 00:05:55,602 Training Data Eval:
2021-12-03 00:06:03,006   Average segmentation loss on training set: 0.0185
2021-12-03 00:06:03,006 Validation Data Eval:
2021-12-03 00:06:05,592   Average segmentation loss on validation set: 0.0837
2021-12-03 00:06:07,157 iteration 3485 : loss : 0.029830, loss_ce: 0.012520
 51%|█████████████▊             | 205/400 [1:33:01<1:33:13, 28.69s/it]2021-12-03 00:06:08,694 iteration 3486 : loss : 0.028567, loss_ce: 0.012456
2021-12-03 00:06:10,098 iteration 3487 : loss : 0.022509, loss_ce: 0.009132
2021-12-03 00:06:11,535 iteration 3488 : loss : 0.038582, loss_ce: 0.014516
2021-12-03 00:06:12,994 iteration 3489 : loss : 0.031159, loss_ce: 0.010663
2021-12-03 00:06:14,474 iteration 3490 : loss : 0.031339, loss_ce: 0.013942
2021-12-03 00:06:15,997 iteration 3491 : loss : 0.032063, loss_ce: 0.011817
2021-12-03 00:06:17,418 iteration 3492 : loss : 0.029694, loss_ce: 0.009837
2021-12-03 00:06:19,015 iteration 3493 : loss : 0.026404, loss_ce: 0.011188
2021-12-03 00:06:20,498 iteration 3494 : loss : 0.022699, loss_ce: 0.006422
2021-12-03 00:06:21,944 iteration 3495 : loss : 0.029195, loss_ce: 0.009473
2021-12-03 00:06:23,442 iteration 3496 : loss : 0.025516, loss_ce: 0.010812
2021-12-03 00:06:24,935 iteration 3497 : loss : 0.032786, loss_ce: 0.011302
2021-12-03 00:06:26,478 iteration 3498 : loss : 0.024021, loss_ce: 0.009803
2021-12-03 00:06:27,898 iteration 3499 : loss : 0.021724, loss_ce: 0.007670
2021-12-03 00:06:29,295 iteration 3500 : loss : 0.024753, loss_ce: 0.007010
2021-12-03 00:06:30,747 iteration 3501 : loss : 0.028582, loss_ce: 0.010352
2021-12-03 00:06:32,241 iteration 3502 : loss : 0.028288, loss_ce: 0.009908
 52%|█████████████▉             | 206/400 [1:33:26<1:29:15, 27.60s/it]2021-12-03 00:06:33,774 iteration 3503 : loss : 0.025326, loss_ce: 0.008885
2021-12-03 00:06:35,230 iteration 3504 : loss : 0.021184, loss_ce: 0.006017
2021-12-03 00:06:36,619 iteration 3505 : loss : 0.021451, loss_ce: 0.009304
2021-12-03 00:06:38,115 iteration 3506 : loss : 0.055989, loss_ce: 0.016497
2021-12-03 00:06:39,568 iteration 3507 : loss : 0.024726, loss_ce: 0.007561
2021-12-03 00:06:41,148 iteration 3508 : loss : 0.030664, loss_ce: 0.013389
2021-12-03 00:06:42,631 iteration 3509 : loss : 0.021331, loss_ce: 0.007579
2021-12-03 00:06:44,037 iteration 3510 : loss : 0.027371, loss_ce: 0.010661
2021-12-03 00:06:45,454 iteration 3511 : loss : 0.017691, loss_ce: 0.008103
2021-12-03 00:06:46,981 iteration 3512 : loss : 0.025997, loss_ce: 0.007599
2021-12-03 00:06:48,449 iteration 3513 : loss : 0.021084, loss_ce: 0.006482
2021-12-03 00:06:50,027 iteration 3514 : loss : 0.044633, loss_ce: 0.022575
2021-12-03 00:06:51,460 iteration 3515 : loss : 0.028132, loss_ce: 0.007461
2021-12-03 00:06:52,886 iteration 3516 : loss : 0.021637, loss_ce: 0.008689
2021-12-03 00:06:54,328 iteration 3517 : loss : 0.023774, loss_ce: 0.008130
2021-12-03 00:06:55,770 iteration 3518 : loss : 0.027425, loss_ce: 0.014541
2021-12-03 00:06:57,254 iteration 3519 : loss : 0.026269, loss_ce: 0.010882
 52%|█████████████▉             | 207/400 [1:33:51<1:26:17, 26.83s/it]2021-12-03 00:06:58,792 iteration 3520 : loss : 0.029853, loss_ce: 0.010085
2021-12-03 00:07:00,226 iteration 3521 : loss : 0.034421, loss_ce: 0.015756
2021-12-03 00:07:01,640 iteration 3522 : loss : 0.019892, loss_ce: 0.008336
2021-12-03 00:07:03,093 iteration 3523 : loss : 0.020564, loss_ce: 0.007344
2021-12-03 00:07:04,586 iteration 3524 : loss : 0.025118, loss_ce: 0.010083
2021-12-03 00:07:06,138 iteration 3525 : loss : 0.021831, loss_ce: 0.007722
2021-12-03 00:07:07,625 iteration 3526 : loss : 0.045417, loss_ce: 0.019405
2021-12-03 00:07:09,127 iteration 3527 : loss : 0.040520, loss_ce: 0.011119
2021-12-03 00:07:10,700 iteration 3528 : loss : 0.029059, loss_ce: 0.011123
2021-12-03 00:07:12,168 iteration 3529 : loss : 0.028194, loss_ce: 0.006733
2021-12-03 00:07:13,638 iteration 3530 : loss : 0.019571, loss_ce: 0.007452
2021-12-03 00:07:15,054 iteration 3531 : loss : 0.026083, loss_ce: 0.007561
2021-12-03 00:07:16,600 iteration 3532 : loss : 0.024131, loss_ce: 0.009675
2021-12-03 00:07:18,062 iteration 3533 : loss : 0.025267, loss_ce: 0.007814
2021-12-03 00:07:19,542 iteration 3534 : loss : 0.032183, loss_ce: 0.013404
2021-12-03 00:07:21,065 iteration 3535 : loss : 0.028421, loss_ce: 0.010963
2021-12-03 00:07:22,556 iteration 3536 : loss : 0.022850, loss_ce: 0.009205
 52%|██████████████             | 208/400 [1:34:16<1:24:22, 26.37s/it]2021-12-03 00:07:23,995 iteration 3537 : loss : 0.027692, loss_ce: 0.010949
2021-12-03 00:07:25,394 iteration 3538 : loss : 0.021311, loss_ce: 0.009925
2021-12-03 00:07:26,833 iteration 3539 : loss : 0.015982, loss_ce: 0.006731
2021-12-03 00:07:28,200 iteration 3540 : loss : 0.023908, loss_ce: 0.006236
2021-12-03 00:07:29,727 iteration 3541 : loss : 0.028170, loss_ce: 0.010772
2021-12-03 00:07:31,193 iteration 3542 : loss : 0.025028, loss_ce: 0.009964
2021-12-03 00:07:32,760 iteration 3543 : loss : 0.045849, loss_ce: 0.015562
2021-12-03 00:07:34,155 iteration 3544 : loss : 0.016801, loss_ce: 0.006441
2021-12-03 00:07:35,621 iteration 3545 : loss : 0.027741, loss_ce: 0.013175
2021-12-03 00:07:37,034 iteration 3546 : loss : 0.019199, loss_ce: 0.007196
2021-12-03 00:07:38,513 iteration 3547 : loss : 0.027122, loss_ce: 0.012621
2021-12-03 00:07:39,949 iteration 3548 : loss : 0.023079, loss_ce: 0.007406
2021-12-03 00:07:41,428 iteration 3549 : loss : 0.023203, loss_ce: 0.009109
2021-12-03 00:07:42,920 iteration 3550 : loss : 0.024397, loss_ce: 0.010172
2021-12-03 00:07:44,439 iteration 3551 : loss : 0.019809, loss_ce: 0.006735
2021-12-03 00:07:45,955 iteration 3552 : loss : 0.045308, loss_ce: 0.016247
2021-12-03 00:07:47,471 iteration 3553 : loss : 0.027322, loss_ce: 0.011491
 52%|██████████████             | 209/400 [1:34:41<1:22:33, 25.93s/it]2021-12-03 00:07:49,002 iteration 3554 : loss : 0.021182, loss_ce: 0.009142
2021-12-03 00:07:50,440 iteration 3555 : loss : 0.019472, loss_ce: 0.006387
2021-12-03 00:07:51,893 iteration 3556 : loss : 0.019978, loss_ce: 0.007786
2021-12-03 00:07:53,437 iteration 3557 : loss : 0.034381, loss_ce: 0.009286
2021-12-03 00:07:54,853 iteration 3558 : loss : 0.034786, loss_ce: 0.009796
2021-12-03 00:07:56,293 iteration 3559 : loss : 0.024023, loss_ce: 0.007808
2021-12-03 00:07:57,666 iteration 3560 : loss : 0.022067, loss_ce: 0.011181
2021-12-03 00:07:59,200 iteration 3561 : loss : 0.026664, loss_ce: 0.009745
2021-12-03 00:08:00,629 iteration 3562 : loss : 0.020434, loss_ce: 0.007269
2021-12-03 00:08:02,114 iteration 3563 : loss : 0.022231, loss_ce: 0.007314
2021-12-03 00:08:03,564 iteration 3564 : loss : 0.024653, loss_ce: 0.008399
2021-12-03 00:08:05,132 iteration 3565 : loss : 0.024739, loss_ce: 0.009966
2021-12-03 00:08:06,610 iteration 3566 : loss : 0.027886, loss_ce: 0.010722
2021-12-03 00:08:08,152 iteration 3567 : loss : 0.027635, loss_ce: 0.012005
2021-12-03 00:08:09,666 iteration 3568 : loss : 0.034701, loss_ce: 0.011884
2021-12-03 00:08:11,174 iteration 3569 : loss : 0.039340, loss_ce: 0.009211
2021-12-03 00:08:11,174 Training Data Eval:
2021-12-03 00:08:18,566   Average segmentation loss on training set: 0.0165
2021-12-03 00:08:18,567 Validation Data Eval:
2021-12-03 00:08:21,138   Average segmentation loss on validation set: 0.0753
2021-12-03 00:08:22,635 iteration 3570 : loss : 0.035575, loss_ce: 0.015319
 52%|██████████████▏            | 210/400 [1:35:16<1:30:53, 28.70s/it]2021-12-03 00:08:24,154 iteration 3571 : loss : 0.031101, loss_ce: 0.012527
2021-12-03 00:08:25,626 iteration 3572 : loss : 0.024905, loss_ce: 0.008373
2021-12-03 00:08:27,099 iteration 3573 : loss : 0.032004, loss_ce: 0.011940
2021-12-03 00:08:28,534 iteration 3574 : loss : 0.019459, loss_ce: 0.008038
2021-12-03 00:08:29,976 iteration 3575 : loss : 0.021708, loss_ce: 0.009178
2021-12-03 00:08:31,446 iteration 3576 : loss : 0.035449, loss_ce: 0.012386
2021-12-03 00:08:32,969 iteration 3577 : loss : 0.022303, loss_ce: 0.009366
2021-12-03 00:08:34,481 iteration 3578 : loss : 0.035721, loss_ce: 0.014315
2021-12-03 00:08:35,923 iteration 3579 : loss : 0.023452, loss_ce: 0.008542
2021-12-03 00:08:37,421 iteration 3580 : loss : 0.025650, loss_ce: 0.008273
2021-12-03 00:08:38,860 iteration 3581 : loss : 0.042722, loss_ce: 0.007544
2021-12-03 00:08:40,334 iteration 3582 : loss : 0.023211, loss_ce: 0.008636
2021-12-03 00:08:41,830 iteration 3583 : loss : 0.026598, loss_ce: 0.010152
2021-12-03 00:08:43,277 iteration 3584 : loss : 0.027112, loss_ce: 0.010498
2021-12-03 00:08:44,736 iteration 3585 : loss : 0.023201, loss_ce: 0.007399
2021-12-03 00:08:46,150 iteration 3586 : loss : 0.030987, loss_ce: 0.012135
2021-12-03 00:08:47,583 iteration 3587 : loss : 0.029761, loss_ce: 0.011305
 53%|██████████████▏            | 211/400 [1:35:41<1:26:51, 27.58s/it]2021-12-03 00:08:49,023 iteration 3588 : loss : 0.020801, loss_ce: 0.007762
2021-12-03 00:08:50,528 iteration 3589 : loss : 0.035019, loss_ce: 0.012847
2021-12-03 00:08:51,988 iteration 3590 : loss : 0.029469, loss_ce: 0.012398
2021-12-03 00:08:53,470 iteration 3591 : loss : 0.023883, loss_ce: 0.007100
2021-12-03 00:08:54,982 iteration 3592 : loss : 0.025745, loss_ce: 0.009907
2021-12-03 00:08:56,444 iteration 3593 : loss : 0.042684, loss_ce: 0.010603
2021-12-03 00:08:57,921 iteration 3594 : loss : 0.022410, loss_ce: 0.006601
2021-12-03 00:08:59,493 iteration 3595 : loss : 0.067595, loss_ce: 0.015875
2021-12-03 00:09:00,877 iteration 3596 : loss : 0.023675, loss_ce: 0.010055
2021-12-03 00:09:02,414 iteration 3597 : loss : 0.037312, loss_ce: 0.013773
2021-12-03 00:09:03,881 iteration 3598 : loss : 0.028246, loss_ce: 0.013453
2021-12-03 00:09:05,355 iteration 3599 : loss : 0.029322, loss_ce: 0.011871
2021-12-03 00:09:06,805 iteration 3600 : loss : 0.027875, loss_ce: 0.011694
2021-12-03 00:09:08,279 iteration 3601 : loss : 0.039349, loss_ce: 0.015955
2021-12-03 00:09:09,730 iteration 3602 : loss : 0.034735, loss_ce: 0.016345
2021-12-03 00:09:11,177 iteration 3603 : loss : 0.018198, loss_ce: 0.005872
2021-12-03 00:09:12,605 iteration 3604 : loss : 0.023383, loss_ce: 0.008782
 53%|██████████████▎            | 212/400 [1:36:06<1:24:00, 26.81s/it]2021-12-03 00:09:14,117 iteration 3605 : loss : 0.022480, loss_ce: 0.007870
2021-12-03 00:09:15,577 iteration 3606 : loss : 0.030139, loss_ce: 0.009871
2021-12-03 00:09:16,988 iteration 3607 : loss : 0.023037, loss_ce: 0.007892
2021-12-03 00:09:18,402 iteration 3608 : loss : 0.024092, loss_ce: 0.010586
2021-12-03 00:09:19,895 iteration 3609 : loss : 0.036294, loss_ce: 0.013874
2021-12-03 00:09:21,320 iteration 3610 : loss : 0.028609, loss_ce: 0.011610
2021-12-03 00:09:22,830 iteration 3611 : loss : 0.028951, loss_ce: 0.012588
2021-12-03 00:09:24,322 iteration 3612 : loss : 0.031008, loss_ce: 0.011492
2021-12-03 00:09:25,776 iteration 3613 : loss : 0.046269, loss_ce: 0.013666
2021-12-03 00:09:27,283 iteration 3614 : loss : 0.020814, loss_ce: 0.006162
2021-12-03 00:09:28,716 iteration 3615 : loss : 0.043518, loss_ce: 0.012019
2021-12-03 00:09:30,236 iteration 3616 : loss : 0.026879, loss_ce: 0.009419
2021-12-03 00:09:31,678 iteration 3617 : loss : 0.027453, loss_ce: 0.010176
2021-12-03 00:09:33,146 iteration 3618 : loss : 0.036840, loss_ce: 0.016704
2021-12-03 00:09:34,613 iteration 3619 : loss : 0.023125, loss_ce: 0.010198
2021-12-03 00:09:36,103 iteration 3620 : loss : 0.027442, loss_ce: 0.010533
2021-12-03 00:09:37,548 iteration 3621 : loss : 0.024251, loss_ce: 0.009423
 53%|██████████████▍            | 213/400 [1:36:31<1:21:50, 26.26s/it]2021-12-03 00:09:39,134 iteration 3622 : loss : 0.028874, loss_ce: 0.010549
2021-12-03 00:09:40,592 iteration 3623 : loss : 0.023068, loss_ce: 0.009043
2021-12-03 00:09:42,124 iteration 3624 : loss : 0.024520, loss_ce: 0.007763
2021-12-03 00:09:43,650 iteration 3625 : loss : 0.030627, loss_ce: 0.014060
2021-12-03 00:09:45,111 iteration 3626 : loss : 0.023291, loss_ce: 0.009336
2021-12-03 00:09:46,609 iteration 3627 : loss : 0.021631, loss_ce: 0.010451
2021-12-03 00:09:48,089 iteration 3628 : loss : 0.022641, loss_ce: 0.006972
2021-12-03 00:09:49,615 iteration 3629 : loss : 0.033365, loss_ce: 0.012872
2021-12-03 00:09:51,063 iteration 3630 : loss : 0.025010, loss_ce: 0.010321
2021-12-03 00:09:52,460 iteration 3631 : loss : 0.020551, loss_ce: 0.008854
2021-12-03 00:09:53,877 iteration 3632 : loss : 0.019497, loss_ce: 0.008721
2021-12-03 00:09:55,388 iteration 3633 : loss : 0.036572, loss_ce: 0.013788
2021-12-03 00:09:56,846 iteration 3634 : loss : 0.025336, loss_ce: 0.009088
2021-12-03 00:09:58,280 iteration 3635 : loss : 0.020804, loss_ce: 0.007098
2021-12-03 00:09:59,712 iteration 3636 : loss : 0.021958, loss_ce: 0.007918
2021-12-03 00:10:01,232 iteration 3637 : loss : 0.030374, loss_ce: 0.009191
2021-12-03 00:10:02,633 iteration 3638 : loss : 0.022179, loss_ce: 0.007034
 54%|██████████████▍            | 214/400 [1:36:56<1:20:17, 25.90s/it]2021-12-03 00:10:04,124 iteration 3639 : loss : 0.019702, loss_ce: 0.008794
2021-12-03 00:10:05,626 iteration 3640 : loss : 0.026914, loss_ce: 0.009786
2021-12-03 00:10:07,088 iteration 3641 : loss : 0.024003, loss_ce: 0.007815
2021-12-03 00:10:08,605 iteration 3642 : loss : 0.030631, loss_ce: 0.013456
2021-12-03 00:10:10,086 iteration 3643 : loss : 0.032085, loss_ce: 0.014470
2021-12-03 00:10:11,533 iteration 3644 : loss : 0.020516, loss_ce: 0.009725
2021-12-03 00:10:12,952 iteration 3645 : loss : 0.018741, loss_ce: 0.006728
2021-12-03 00:10:14,418 iteration 3646 : loss : 0.021145, loss_ce: 0.007013
2021-12-03 00:10:15,925 iteration 3647 : loss : 0.028297, loss_ce: 0.011047
2021-12-03 00:10:17,493 iteration 3648 : loss : 0.039834, loss_ce: 0.015339
2021-12-03 00:10:18,968 iteration 3649 : loss : 0.028327, loss_ce: 0.009174
2021-12-03 00:10:20,437 iteration 3650 : loss : 0.026706, loss_ce: 0.007621
2021-12-03 00:10:21,921 iteration 3651 : loss : 0.023335, loss_ce: 0.008619
2021-12-03 00:10:23,390 iteration 3652 : loss : 0.021432, loss_ce: 0.009002
2021-12-03 00:10:24,895 iteration 3653 : loss : 0.036489, loss_ce: 0.010864
2021-12-03 00:10:26,352 iteration 3654 : loss : 0.018695, loss_ce: 0.005512
2021-12-03 00:10:26,353 Training Data Eval:
2021-12-03 00:10:33,730   Average segmentation loss on training set: 0.0173
2021-12-03 00:10:33,730 Validation Data Eval:
2021-12-03 00:10:36,275   Average segmentation loss on validation set: 0.0739
2021-12-03 00:10:37,675 iteration 3655 : loss : 0.022523, loss_ce: 0.008443
 54%|██████████████▌            | 215/400 [1:37:31<1:28:18, 28.64s/it]2021-12-03 00:10:39,263 iteration 3656 : loss : 0.040230, loss_ce: 0.009474
2021-12-03 00:10:40,715 iteration 3657 : loss : 0.021143, loss_ce: 0.009765
2021-12-03 00:10:42,197 iteration 3658 : loss : 0.034960, loss_ce: 0.014464
2021-12-03 00:10:43,694 iteration 3659 : loss : 0.022287, loss_ce: 0.007331
2021-12-03 00:10:45,241 iteration 3660 : loss : 0.030430, loss_ce: 0.009160
2021-12-03 00:10:46,790 iteration 3661 : loss : 0.027064, loss_ce: 0.011919
2021-12-03 00:10:48,181 iteration 3662 : loss : 0.022634, loss_ce: 0.008510
2021-12-03 00:10:49,613 iteration 3663 : loss : 0.019543, loss_ce: 0.006092
2021-12-03 00:10:51,071 iteration 3664 : loss : 0.029179, loss_ce: 0.008581
2021-12-03 00:10:52,539 iteration 3665 : loss : 0.017085, loss_ce: 0.006993
2021-12-03 00:10:54,101 iteration 3666 : loss : 0.031827, loss_ce: 0.015755
2021-12-03 00:10:55,601 iteration 3667 : loss : 0.029817, loss_ce: 0.012497
2021-12-03 00:10:57,095 iteration 3668 : loss : 0.019924, loss_ce: 0.008122
2021-12-03 00:10:58,566 iteration 3669 : loss : 0.029822, loss_ce: 0.014807
2021-12-03 00:11:00,023 iteration 3670 : loss : 0.031485, loss_ce: 0.009985
2021-12-03 00:11:01,525 iteration 3671 : loss : 0.028197, loss_ce: 0.010455
2021-12-03 00:11:02,941 iteration 3672 : loss : 0.022848, loss_ce: 0.009672
 54%|██████████████▌            | 216/400 [1:37:57<1:24:43, 27.63s/it]2021-12-03 00:11:04,433 iteration 3673 : loss : 0.022547, loss_ce: 0.011508
2021-12-03 00:11:05,900 iteration 3674 : loss : 0.028064, loss_ce: 0.011020
2021-12-03 00:11:07,359 iteration 3675 : loss : 0.019801, loss_ce: 0.010535
2021-12-03 00:11:08,820 iteration 3676 : loss : 0.020358, loss_ce: 0.006960
2021-12-03 00:11:10,283 iteration 3677 : loss : 0.024400, loss_ce: 0.012321
2021-12-03 00:11:11,809 iteration 3678 : loss : 0.050040, loss_ce: 0.018898
2021-12-03 00:11:13,257 iteration 3679 : loss : 0.022942, loss_ce: 0.008385
2021-12-03 00:11:14,710 iteration 3680 : loss : 0.029363, loss_ce: 0.010541
2021-12-03 00:11:16,231 iteration 3681 : loss : 0.027261, loss_ce: 0.010583
2021-12-03 00:11:17,669 iteration 3682 : loss : 0.030011, loss_ce: 0.010640
2021-12-03 00:11:19,159 iteration 3683 : loss : 0.075122, loss_ce: 0.010260
2021-12-03 00:11:20,582 iteration 3684 : loss : 0.014822, loss_ce: 0.004120
2021-12-03 00:11:22,018 iteration 3685 : loss : 0.033403, loss_ce: 0.016733
2021-12-03 00:11:23,497 iteration 3686 : loss : 0.024700, loss_ce: 0.008952
2021-12-03 00:11:24,974 iteration 3687 : loss : 0.029816, loss_ce: 0.010855
2021-12-03 00:11:26,430 iteration 3688 : loss : 0.043936, loss_ce: 0.021754
2021-12-03 00:11:27,845 iteration 3689 : loss : 0.026352, loss_ce: 0.009663
 54%|██████████████▋            | 217/400 [1:38:22<1:21:46, 26.81s/it]2021-12-03 00:11:29,349 iteration 3690 : loss : 0.017856, loss_ce: 0.004509
2021-12-03 00:11:30,885 iteration 3691 : loss : 0.033256, loss_ce: 0.008320
2021-12-03 00:11:32,359 iteration 3692 : loss : 0.023430, loss_ce: 0.010069
2021-12-03 00:11:33,886 iteration 3693 : loss : 0.036472, loss_ce: 0.014589
2021-12-03 00:11:35,350 iteration 3694 : loss : 0.019208, loss_ce: 0.008306
2021-12-03 00:11:36,759 iteration 3695 : loss : 0.023027, loss_ce: 0.009207
2021-12-03 00:11:38,255 iteration 3696 : loss : 0.036807, loss_ce: 0.020073
2021-12-03 00:11:39,705 iteration 3697 : loss : 0.027805, loss_ce: 0.007696
2021-12-03 00:11:41,180 iteration 3698 : loss : 0.028940, loss_ce: 0.009656
2021-12-03 00:11:42,707 iteration 3699 : loss : 0.040279, loss_ce: 0.019337
2021-12-03 00:11:44,158 iteration 3700 : loss : 0.026734, loss_ce: 0.011936
2021-12-03 00:11:45,580 iteration 3701 : loss : 0.023025, loss_ce: 0.008286
2021-12-03 00:11:47,001 iteration 3702 : loss : 0.029030, loss_ce: 0.010522
2021-12-03 00:11:48,557 iteration 3703 : loss : 0.028009, loss_ce: 0.012525
2021-12-03 00:11:49,983 iteration 3704 : loss : 0.026266, loss_ce: 0.007813
2021-12-03 00:11:51,416 iteration 3705 : loss : 0.026742, loss_ce: 0.008209
2021-12-03 00:11:52,842 iteration 3706 : loss : 0.016706, loss_ce: 0.004628
 55%|██████████████▋            | 218/400 [1:38:46<1:19:40, 26.26s/it]2021-12-03 00:11:54,369 iteration 3707 : loss : 0.033557, loss_ce: 0.010585
2021-12-03 00:11:55,831 iteration 3708 : loss : 0.024042, loss_ce: 0.009670
2021-12-03 00:11:57,281 iteration 3709 : loss : 0.038669, loss_ce: 0.014273
2021-12-03 00:11:58,789 iteration 3710 : loss : 0.025528, loss_ce: 0.008215
2021-12-03 00:12:00,240 iteration 3711 : loss : 0.019576, loss_ce: 0.007131
2021-12-03 00:12:01,725 iteration 3712 : loss : 0.037691, loss_ce: 0.011099
2021-12-03 00:12:03,140 iteration 3713 : loss : 0.020836, loss_ce: 0.007862
2021-12-03 00:12:04,577 iteration 3714 : loss : 0.018105, loss_ce: 0.006543
2021-12-03 00:12:06,049 iteration 3715 : loss : 0.030143, loss_ce: 0.011076
2021-12-03 00:12:07,483 iteration 3716 : loss : 0.025232, loss_ce: 0.008846
2021-12-03 00:12:08,978 iteration 3717 : loss : 0.025807, loss_ce: 0.009743
2021-12-03 00:12:10,502 iteration 3718 : loss : 0.025626, loss_ce: 0.010827
2021-12-03 00:12:11,925 iteration 3719 : loss : 0.023356, loss_ce: 0.006380
2021-12-03 00:12:13,422 iteration 3720 : loss : 0.020617, loss_ce: 0.010409
2021-12-03 00:12:14,891 iteration 3721 : loss : 0.020107, loss_ce: 0.008911
2021-12-03 00:12:16,337 iteration 3722 : loss : 0.023421, loss_ce: 0.008963
2021-12-03 00:12:17,779 iteration 3723 : loss : 0.025211, loss_ce: 0.007045
 55%|██████████████▊            | 219/400 [1:39:11<1:18:01, 25.87s/it]2021-12-03 00:12:19,238 iteration 3724 : loss : 0.016117, loss_ce: 0.007204
2021-12-03 00:12:20,672 iteration 3725 : loss : 0.034247, loss_ce: 0.014409
2021-12-03 00:12:22,188 iteration 3726 : loss : 0.024012, loss_ce: 0.009965
2021-12-03 00:12:23,658 iteration 3727 : loss : 0.019588, loss_ce: 0.007563
2021-12-03 00:12:25,140 iteration 3728 : loss : 0.025850, loss_ce: 0.006958
2021-12-03 00:12:26,565 iteration 3729 : loss : 0.019525, loss_ce: 0.005126
2021-12-03 00:12:28,004 iteration 3730 : loss : 0.021331, loss_ce: 0.008346
2021-12-03 00:12:29,439 iteration 3731 : loss : 0.020729, loss_ce: 0.007206
2021-12-03 00:12:30,938 iteration 3732 : loss : 0.022577, loss_ce: 0.007494
2021-12-03 00:12:32,363 iteration 3733 : loss : 0.020290, loss_ce: 0.007731
2021-12-03 00:12:33,837 iteration 3734 : loss : 0.022196, loss_ce: 0.009758
2021-12-03 00:12:35,294 iteration 3735 : loss : 0.025754, loss_ce: 0.007313
2021-12-03 00:12:36,799 iteration 3736 : loss : 0.032037, loss_ce: 0.016999
2021-12-03 00:12:38,218 iteration 3737 : loss : 0.019602, loss_ce: 0.005942
2021-12-03 00:12:39,667 iteration 3738 : loss : 0.018815, loss_ce: 0.006271
2021-12-03 00:12:41,097 iteration 3739 : loss : 0.020380, loss_ce: 0.007234
2021-12-03 00:12:41,097 Training Data Eval:
2021-12-03 00:12:48,495   Average segmentation loss on training set: 0.0147
2021-12-03 00:12:48,495 Validation Data Eval:
2021-12-03 00:12:51,066   Average segmentation loss on validation set: 0.0719
2021-12-03 00:12:52,688 iteration 3740 : loss : 0.033413, loss_ce: 0.018863
 55%|██████████████▊            | 220/400 [1:39:46<1:25:44, 28.58s/it]2021-12-03 00:12:54,317 iteration 3741 : loss : 0.025074, loss_ce: 0.006801
2021-12-03 00:12:55,764 iteration 3742 : loss : 0.027818, loss_ce: 0.013620
2021-12-03 00:12:57,219 iteration 3743 : loss : 0.023611, loss_ce: 0.008938
2021-12-03 00:12:58,726 iteration 3744 : loss : 0.029617, loss_ce: 0.010881
2021-12-03 00:13:00,243 iteration 3745 : loss : 0.028674, loss_ce: 0.009503
2021-12-03 00:13:01,773 iteration 3746 : loss : 0.034284, loss_ce: 0.013062
2021-12-03 00:13:03,220 iteration 3747 : loss : 0.023925, loss_ce: 0.007723
2021-12-03 00:13:04,663 iteration 3748 : loss : 0.017978, loss_ce: 0.008275
2021-12-03 00:13:06,176 iteration 3749 : loss : 0.022979, loss_ce: 0.007581
2021-12-03 00:13:07,709 iteration 3750 : loss : 0.022916, loss_ce: 0.008462
2021-12-03 00:13:09,187 iteration 3751 : loss : 0.029170, loss_ce: 0.008512
2021-12-03 00:13:10,631 iteration 3752 : loss : 0.030742, loss_ce: 0.007761
2021-12-03 00:13:12,062 iteration 3753 : loss : 0.023310, loss_ce: 0.006601
2021-12-03 00:13:13,533 iteration 3754 : loss : 0.019811, loss_ce: 0.006732
2021-12-03 00:13:15,047 iteration 3755 : loss : 0.024414, loss_ce: 0.011665
2021-12-03 00:13:16,454 iteration 3756 : loss : 0.027211, loss_ce: 0.011283
2021-12-03 00:13:17,887 iteration 3757 : loss : 0.025500, loss_ce: 0.010450
 55%|██████████████▉            | 221/400 [1:40:12<1:22:14, 27.57s/it]2021-12-03 00:13:19,474 iteration 3758 : loss : 0.019709, loss_ce: 0.006347
2021-12-03 00:13:20,897 iteration 3759 : loss : 0.020097, loss_ce: 0.006052
2021-12-03 00:13:22,340 iteration 3760 : loss : 0.019490, loss_ce: 0.007815
2021-12-03 00:13:23,814 iteration 3761 : loss : 0.023320, loss_ce: 0.008835
2021-12-03 00:13:25,316 iteration 3762 : loss : 0.021506, loss_ce: 0.010414
2021-12-03 00:13:26,867 iteration 3763 : loss : 0.022747, loss_ce: 0.008031
2021-12-03 00:13:28,320 iteration 3764 : loss : 0.029230, loss_ce: 0.009948
2021-12-03 00:13:29,729 iteration 3765 : loss : 0.021307, loss_ce: 0.008629
2021-12-03 00:13:31,228 iteration 3766 : loss : 0.030866, loss_ce: 0.011824
2021-12-03 00:13:32,674 iteration 3767 : loss : 0.018426, loss_ce: 0.007136
2021-12-03 00:13:34,096 iteration 3768 : loss : 0.029805, loss_ce: 0.009620
2021-12-03 00:13:35,535 iteration 3769 : loss : 0.018826, loss_ce: 0.008006
2021-12-03 00:13:37,041 iteration 3770 : loss : 0.035589, loss_ce: 0.010680
2021-12-03 00:13:38,622 iteration 3771 : loss : 0.028691, loss_ce: 0.010062
2021-12-03 00:13:40,127 iteration 3772 : loss : 0.024628, loss_ce: 0.006682
2021-12-03 00:13:41,591 iteration 3773 : loss : 0.015788, loss_ce: 0.005675
2021-12-03 00:13:43,095 iteration 3774 : loss : 0.046455, loss_ce: 0.022285
 56%|██████████████▉            | 222/400 [1:40:37<1:19:40, 26.86s/it]2021-12-03 00:13:44,563 iteration 3775 : loss : 0.022915, loss_ce: 0.008813
2021-12-03 00:13:45,963 iteration 3776 : loss : 0.036314, loss_ce: 0.015527
2021-12-03 00:13:47,431 iteration 3777 : loss : 0.021586, loss_ce: 0.005485
2021-12-03 00:13:48,863 iteration 3778 : loss : 0.019942, loss_ce: 0.007373
2021-12-03 00:13:50,305 iteration 3779 : loss : 0.018772, loss_ce: 0.008036
2021-12-03 00:13:51,790 iteration 3780 : loss : 0.027470, loss_ce: 0.009045
2021-12-03 00:13:53,271 iteration 3781 : loss : 0.027866, loss_ce: 0.012873
2021-12-03 00:13:54,747 iteration 3782 : loss : 0.068056, loss_ce: 0.012081
2021-12-03 00:13:56,225 iteration 3783 : loss : 0.018279, loss_ce: 0.008605
2021-12-03 00:13:57,713 iteration 3784 : loss : 0.025131, loss_ce: 0.010983
2021-12-03 00:13:59,159 iteration 3785 : loss : 0.019402, loss_ce: 0.008389
2021-12-03 00:14:00,608 iteration 3786 : loss : 0.018144, loss_ce: 0.006652
2021-12-03 00:14:02,055 iteration 3787 : loss : 0.021423, loss_ce: 0.007248
2021-12-03 00:14:03,571 iteration 3788 : loss : 0.040177, loss_ce: 0.009122
2021-12-03 00:14:05,021 iteration 3789 : loss : 0.021919, loss_ce: 0.006484
2021-12-03 00:14:06,502 iteration 3790 : loss : 0.026707, loss_ce: 0.009415
2021-12-03 00:14:07,989 iteration 3791 : loss : 0.026408, loss_ce: 0.010050
 56%|███████████████            | 223/400 [1:41:02<1:17:29, 26.27s/it]2021-12-03 00:14:09,473 iteration 3792 : loss : 0.014677, loss_ce: 0.005116
2021-12-03 00:14:10,973 iteration 3793 : loss : 0.021731, loss_ce: 0.006507
2021-12-03 00:14:12,452 iteration 3794 : loss : 0.025847, loss_ce: 0.009786
2021-12-03 00:14:13,917 iteration 3795 : loss : 0.019653, loss_ce: 0.006219
2021-12-03 00:14:15,308 iteration 3796 : loss : 0.017426, loss_ce: 0.005520
2021-12-03 00:14:16,769 iteration 3797 : loss : 0.026678, loss_ce: 0.009653
2021-12-03 00:14:18,187 iteration 3798 : loss : 0.019665, loss_ce: 0.007179
2021-12-03 00:14:19,634 iteration 3799 : loss : 0.029094, loss_ce: 0.010160
2021-12-03 00:14:21,089 iteration 3800 : loss : 0.018513, loss_ce: 0.005047
2021-12-03 00:14:22,542 iteration 3801 : loss : 0.051091, loss_ce: 0.010517
2021-12-03 00:14:23,972 iteration 3802 : loss : 0.020982, loss_ce: 0.009529
2021-12-03 00:14:25,438 iteration 3803 : loss : 0.018707, loss_ce: 0.005498
2021-12-03 00:14:26,903 iteration 3804 : loss : 0.028781, loss_ce: 0.012086
2021-12-03 00:14:28,350 iteration 3805 : loss : 0.033640, loss_ce: 0.013860
2021-12-03 00:14:29,794 iteration 3806 : loss : 0.032374, loss_ce: 0.014566
2021-12-03 00:14:31,283 iteration 3807 : loss : 0.025085, loss_ce: 0.008817
2021-12-03 00:14:32,755 iteration 3808 : loss : 0.023939, loss_ce: 0.009350
 56%|███████████████            | 224/400 [1:41:26<1:15:43, 25.82s/it]2021-12-03 00:14:34,221 iteration 3809 : loss : 0.016776, loss_ce: 0.005505
2021-12-03 00:14:35,664 iteration 3810 : loss : 0.026709, loss_ce: 0.010751
2021-12-03 00:14:37,127 iteration 3811 : loss : 0.025359, loss_ce: 0.007803
2021-12-03 00:14:38,581 iteration 3812 : loss : 0.023203, loss_ce: 0.011235
2021-12-03 00:14:40,027 iteration 3813 : loss : 0.022143, loss_ce: 0.010040
2021-12-03 00:14:41,523 iteration 3814 : loss : 0.025681, loss_ce: 0.009883
2021-12-03 00:14:42,986 iteration 3815 : loss : 0.029461, loss_ce: 0.010497
2021-12-03 00:14:44,453 iteration 3816 : loss : 0.022319, loss_ce: 0.009231
2021-12-03 00:14:45,863 iteration 3817 : loss : 0.020793, loss_ce: 0.008110
2021-12-03 00:14:47,362 iteration 3818 : loss : 0.019237, loss_ce: 0.008905
2021-12-03 00:14:48,863 iteration 3819 : loss : 0.019777, loss_ce: 0.009321
2021-12-03 00:14:50,341 iteration 3820 : loss : 0.036483, loss_ce: 0.013114
2021-12-03 00:14:51,840 iteration 3821 : loss : 0.027340, loss_ce: 0.010927
2021-12-03 00:14:53,280 iteration 3822 : loss : 0.034868, loss_ce: 0.010963
2021-12-03 00:14:54,812 iteration 3823 : loss : 0.036817, loss_ce: 0.009127
2021-12-03 00:14:56,289 iteration 3824 : loss : 0.023363, loss_ce: 0.008029
2021-12-03 00:14:56,289 Training Data Eval:
2021-12-03 00:15:03,692   Average segmentation loss on training set: 0.0159
2021-12-03 00:15:03,693 Validation Data Eval:
2021-12-03 00:15:06,276   Average segmentation loss on validation set: 0.0785
2021-12-03 00:15:07,812 iteration 3825 : loss : 0.028091, loss_ce: 0.010176
 56%|███████████████▏           | 225/400 [1:42:01<1:23:22, 28.59s/it]2021-12-03 00:15:09,343 iteration 3826 : loss : 0.027072, loss_ce: 0.012669
2021-12-03 00:15:10,773 iteration 3827 : loss : 0.023721, loss_ce: 0.007721
2021-12-03 00:15:12,262 iteration 3828 : loss : 0.023429, loss_ce: 0.008724
2021-12-03 00:15:13,756 iteration 3829 : loss : 0.025228, loss_ce: 0.007279
2021-12-03 00:15:15,198 iteration 3830 : loss : 0.014862, loss_ce: 0.005336
2021-12-03 00:15:16,627 iteration 3831 : loss : 0.020054, loss_ce: 0.006521
2021-12-03 00:15:18,053 iteration 3832 : loss : 0.031810, loss_ce: 0.008938
2021-12-03 00:15:19,525 iteration 3833 : loss : 0.017764, loss_ce: 0.008033
2021-12-03 00:15:21,031 iteration 3834 : loss : 0.029075, loss_ce: 0.012987
2021-12-03 00:15:22,518 iteration 3835 : loss : 0.026276, loss_ce: 0.008711
2021-12-03 00:15:23,987 iteration 3836 : loss : 0.021644, loss_ce: 0.008234
2021-12-03 00:15:25,457 iteration 3837 : loss : 0.029434, loss_ce: 0.008746
2021-12-03 00:15:26,981 iteration 3838 : loss : 0.028840, loss_ce: 0.010410
2021-12-03 00:15:28,421 iteration 3839 : loss : 0.020986, loss_ce: 0.008762
2021-12-03 00:15:29,889 iteration 3840 : loss : 0.024842, loss_ce: 0.006383
2021-12-03 00:15:31,328 iteration 3841 : loss : 0.022198, loss_ce: 0.008011
2021-12-03 00:15:32,811 iteration 3842 : loss : 0.032494, loss_ce: 0.015859
 56%|███████████████▎           | 226/400 [1:42:26<1:19:47, 27.51s/it]2021-12-03 00:15:34,289 iteration 3843 : loss : 0.021267, loss_ce: 0.008808
2021-12-03 00:15:35,775 iteration 3844 : loss : 0.030951, loss_ce: 0.008886
2021-12-03 00:15:37,249 iteration 3845 : loss : 0.018712, loss_ce: 0.008012
2021-12-03 00:15:38,674 iteration 3846 : loss : 0.016706, loss_ce: 0.005994
2021-12-03 00:15:40,118 iteration 3847 : loss : 0.024852, loss_ce: 0.008810
2021-12-03 00:15:41,636 iteration 3848 : loss : 0.018024, loss_ce: 0.007777
2021-12-03 00:15:43,198 iteration 3849 : loss : 0.026326, loss_ce: 0.011072
2021-12-03 00:15:44,728 iteration 3850 : loss : 0.039512, loss_ce: 0.009189
2021-12-03 00:15:46,194 iteration 3851 : loss : 0.019085, loss_ce: 0.007827
2021-12-03 00:15:47,681 iteration 3852 : loss : 0.027875, loss_ce: 0.007987
2021-12-03 00:15:49,124 iteration 3853 : loss : 0.018450, loss_ce: 0.005287
2021-12-03 00:15:50,621 iteration 3854 : loss : 0.022018, loss_ce: 0.006391
2021-12-03 00:15:52,198 iteration 3855 : loss : 0.037551, loss_ce: 0.013213
2021-12-03 00:15:53,551 iteration 3856 : loss : 0.019590, loss_ce: 0.008961
2021-12-03 00:15:54,995 iteration 3857 : loss : 0.028089, loss_ce: 0.012827
2021-12-03 00:15:56,380 iteration 3858 : loss : 0.022049, loss_ce: 0.008491
2021-12-03 00:15:57,853 iteration 3859 : loss : 0.020792, loss_ce: 0.009321
 57%|███████████████▎           | 227/400 [1:42:52<1:17:11, 26.77s/it]2021-12-03 00:15:59,381 iteration 3860 : loss : 0.018701, loss_ce: 0.006804
2021-12-03 00:16:00,911 iteration 3861 : loss : 0.034004, loss_ce: 0.015425
2021-12-03 00:16:02,399 iteration 3862 : loss : 0.022497, loss_ce: 0.007998
2021-12-03 00:16:03,884 iteration 3863 : loss : 0.028744, loss_ce: 0.011542
2021-12-03 00:16:05,385 iteration 3864 : loss : 0.024362, loss_ce: 0.007969
2021-12-03 00:16:06,849 iteration 3865 : loss : 0.023034, loss_ce: 0.008077
2021-12-03 00:16:08,408 iteration 3866 : loss : 0.028480, loss_ce: 0.009391
2021-12-03 00:16:09,851 iteration 3867 : loss : 0.030075, loss_ce: 0.010218
2021-12-03 00:16:11,363 iteration 3868 : loss : 0.036038, loss_ce: 0.011007
2021-12-03 00:16:12,850 iteration 3869 : loss : 0.021330, loss_ce: 0.010121
2021-12-03 00:16:14,356 iteration 3870 : loss : 0.021728, loss_ce: 0.009283
2021-12-03 00:16:15,845 iteration 3871 : loss : 0.025517, loss_ce: 0.007324
2021-12-03 00:16:17,279 iteration 3872 : loss : 0.026023, loss_ce: 0.008654
2021-12-03 00:16:18,720 iteration 3873 : loss : 0.020308, loss_ce: 0.009745
2021-12-03 00:16:20,223 iteration 3874 : loss : 0.030925, loss_ce: 0.011877
2021-12-03 00:16:21,706 iteration 3875 : loss : 0.032729, loss_ce: 0.013511
2021-12-03 00:16:23,194 iteration 3876 : loss : 0.028171, loss_ce: 0.008250
 57%|███████████████▍           | 228/400 [1:43:17<1:15:31, 26.34s/it]2021-12-03 00:16:24,687 iteration 3877 : loss : 0.022777, loss_ce: 0.008285
2021-12-03 00:16:26,171 iteration 3878 : loss : 0.028244, loss_ce: 0.010430
2021-12-03 00:16:27,608 iteration 3879 : loss : 0.017895, loss_ce: 0.006656
2021-12-03 00:16:29,120 iteration 3880 : loss : 0.021290, loss_ce: 0.008415
2021-12-03 00:16:30,556 iteration 3881 : loss : 0.029611, loss_ce: 0.013127
2021-12-03 00:16:32,090 iteration 3882 : loss : 0.039678, loss_ce: 0.009693
2021-12-03 00:16:33,597 iteration 3883 : loss : 0.026005, loss_ce: 0.008696
2021-12-03 00:16:35,076 iteration 3884 : loss : 0.021160, loss_ce: 0.008361
2021-12-03 00:16:36,588 iteration 3885 : loss : 0.040021, loss_ce: 0.012883
2021-12-03 00:16:38,096 iteration 3886 : loss : 0.027480, loss_ce: 0.010454
2021-12-03 00:16:39,516 iteration 3887 : loss : 0.021417, loss_ce: 0.007231
2021-12-03 00:16:41,021 iteration 3888 : loss : 0.025210, loss_ce: 0.012286
2021-12-03 00:16:42,490 iteration 3889 : loss : 0.020076, loss_ce: 0.007269
2021-12-03 00:16:44,057 iteration 3890 : loss : 0.031143, loss_ce: 0.009958
2021-12-03 00:16:45,496 iteration 3891 : loss : 0.031586, loss_ce: 0.012404
2021-12-03 00:16:46,973 iteration 3892 : loss : 0.025852, loss_ce: 0.011294
2021-12-03 00:16:48,474 iteration 3893 : loss : 0.038976, loss_ce: 0.013330
 57%|███████████████▍           | 229/400 [1:43:42<1:14:10, 26.02s/it]2021-12-03 00:16:49,984 iteration 3894 : loss : 0.019284, loss_ce: 0.005503
2021-12-03 00:16:51,410 iteration 3895 : loss : 0.022529, loss_ce: 0.007777
2021-12-03 00:16:52,899 iteration 3896 : loss : 0.043426, loss_ce: 0.017928
2021-12-03 00:16:54,409 iteration 3897 : loss : 0.023487, loss_ce: 0.009610
2021-12-03 00:16:55,905 iteration 3898 : loss : 0.030155, loss_ce: 0.009505
2021-12-03 00:16:57,309 iteration 3899 : loss : 0.026720, loss_ce: 0.010730
2021-12-03 00:16:58,736 iteration 3900 : loss : 0.023400, loss_ce: 0.009228
2021-12-03 00:17:00,147 iteration 3901 : loss : 0.023760, loss_ce: 0.009218
2021-12-03 00:17:01,578 iteration 3902 : loss : 0.021675, loss_ce: 0.007739
2021-12-03 00:17:02,988 iteration 3903 : loss : 0.028038, loss_ce: 0.008103
2021-12-03 00:17:04,453 iteration 3904 : loss : 0.022368, loss_ce: 0.007123
2021-12-03 00:17:05,894 iteration 3905 : loss : 0.023858, loss_ce: 0.006838
2021-12-03 00:17:07,284 iteration 3906 : loss : 0.015755, loss_ce: 0.006497
2021-12-03 00:17:08,670 iteration 3907 : loss : 0.020387, loss_ce: 0.007791
2021-12-03 00:17:10,089 iteration 3908 : loss : 0.019692, loss_ce: 0.007462
2021-12-03 00:17:11,566 iteration 3909 : loss : 0.027654, loss_ce: 0.013819
2021-12-03 00:17:11,566 Training Data Eval:
2021-12-03 00:17:18,958   Average segmentation loss on training set: 0.0182
2021-12-03 00:17:18,959 Validation Data Eval:
2021-12-03 00:17:21,523   Average segmentation loss on validation set: 0.0880
2021-12-03 00:17:23,065 iteration 3910 : loss : 0.019758, loss_ce: 0.006684
 57%|███████████████▌           | 230/400 [1:44:17<1:21:01, 28.60s/it]2021-12-03 00:17:24,537 iteration 3911 : loss : 0.024290, loss_ce: 0.009647
2021-12-03 00:17:26,029 iteration 3912 : loss : 0.023932, loss_ce: 0.009089
2021-12-03 00:17:27,498 iteration 3913 : loss : 0.018407, loss_ce: 0.006569
2021-12-03 00:17:28,950 iteration 3914 : loss : 0.018718, loss_ce: 0.008852
2021-12-03 00:17:30,400 iteration 3915 : loss : 0.023805, loss_ce: 0.009431
2021-12-03 00:17:31,840 iteration 3916 : loss : 0.021275, loss_ce: 0.006845
2021-12-03 00:17:33,341 iteration 3917 : loss : 0.026153, loss_ce: 0.009413
2021-12-03 00:17:34,844 iteration 3918 : loss : 0.031197, loss_ce: 0.008561
2021-12-03 00:17:36,423 iteration 3919 : loss : 0.049734, loss_ce: 0.013303
2021-12-03 00:17:37,846 iteration 3920 : loss : 0.017511, loss_ce: 0.006496
2021-12-03 00:17:39,308 iteration 3921 : loss : 0.025516, loss_ce: 0.011147
2021-12-03 00:17:40,824 iteration 3922 : loss : 0.026692, loss_ce: 0.009884
2021-12-03 00:17:42,266 iteration 3923 : loss : 0.016999, loss_ce: 0.008079
2021-12-03 00:17:43,689 iteration 3924 : loss : 0.024421, loss_ce: 0.006798
2021-12-03 00:17:45,213 iteration 3925 : loss : 0.029607, loss_ce: 0.010311
2021-12-03 00:17:46,713 iteration 3926 : loss : 0.017113, loss_ce: 0.006008
2021-12-03 00:17:48,170 iteration 3927 : loss : 0.027106, loss_ce: 0.009989
 58%|███████████████▌           | 231/400 [1:44:42<1:17:35, 27.55s/it]2021-12-03 00:17:49,733 iteration 3928 : loss : 0.039755, loss_ce: 0.023657
2021-12-03 00:17:51,197 iteration 3929 : loss : 0.017233, loss_ce: 0.007790
2021-12-03 00:17:52,708 iteration 3930 : loss : 0.027933, loss_ce: 0.010742
2021-12-03 00:17:54,188 iteration 3931 : loss : 0.019061, loss_ce: 0.006870
2021-12-03 00:17:55,661 iteration 3932 : loss : 0.025738, loss_ce: 0.008884
2021-12-03 00:17:57,188 iteration 3933 : loss : 0.022590, loss_ce: 0.008091
2021-12-03 00:17:58,687 iteration 3934 : loss : 0.035967, loss_ce: 0.016247
2021-12-03 00:18:00,097 iteration 3935 : loss : 0.016836, loss_ce: 0.006893
2021-12-03 00:18:01,682 iteration 3936 : loss : 0.031237, loss_ce: 0.012309
2021-12-03 00:18:03,097 iteration 3937 : loss : 0.026935, loss_ce: 0.012806
2021-12-03 00:18:04,603 iteration 3938 : loss : 0.079869, loss_ce: 0.017407
2021-12-03 00:18:06,006 iteration 3939 : loss : 0.030656, loss_ce: 0.009062
2021-12-03 00:18:07,451 iteration 3940 : loss : 0.026855, loss_ce: 0.008966
2021-12-03 00:18:08,920 iteration 3941 : loss : 0.026805, loss_ce: 0.010984
2021-12-03 00:18:10,439 iteration 3942 : loss : 0.045860, loss_ce: 0.019151
2021-12-03 00:18:11,862 iteration 3943 : loss : 0.037808, loss_ce: 0.015837
2021-12-03 00:18:13,378 iteration 3944 : loss : 0.031620, loss_ce: 0.010912
 58%|███████████████▋           | 232/400 [1:45:07<1:15:09, 26.84s/it]2021-12-03 00:18:14,901 iteration 3945 : loss : 0.024648, loss_ce: 0.010567
2021-12-03 00:18:16,287 iteration 3946 : loss : 0.018119, loss_ce: 0.008836
2021-12-03 00:18:17,754 iteration 3947 : loss : 0.025499, loss_ce: 0.007750
2021-12-03 00:18:19,343 iteration 3948 : loss : 0.034310, loss_ce: 0.012723
2021-12-03 00:18:20,845 iteration 3949 : loss : 0.029391, loss_ce: 0.010237
2021-12-03 00:18:22,374 iteration 3950 : loss : 0.027065, loss_ce: 0.007394
2021-12-03 00:18:23,782 iteration 3951 : loss : 0.022265, loss_ce: 0.009964
2021-12-03 00:18:25,282 iteration 3952 : loss : 0.020640, loss_ce: 0.007752
2021-12-03 00:18:26,801 iteration 3953 : loss : 0.051676, loss_ce: 0.016935
2021-12-03 00:18:28,244 iteration 3954 : loss : 0.030079, loss_ce: 0.011553
2021-12-03 00:18:29,687 iteration 3955 : loss : 0.017185, loss_ce: 0.006283
2021-12-03 00:18:31,255 iteration 3956 : loss : 0.033111, loss_ce: 0.013333
2021-12-03 00:18:32,684 iteration 3957 : loss : 0.028927, loss_ce: 0.012926
2021-12-03 00:18:34,125 iteration 3958 : loss : 0.023347, loss_ce: 0.008674
2021-12-03 00:18:35,670 iteration 3959 : loss : 0.027836, loss_ce: 0.007539
2021-12-03 00:18:37,116 iteration 3960 : loss : 0.024078, loss_ce: 0.011115
2021-12-03 00:18:38,578 iteration 3961 : loss : 0.025811, loss_ce: 0.009723
 58%|███████████████▋           | 233/400 [1:45:32<1:13:20, 26.35s/it]2021-12-03 00:18:40,121 iteration 3962 : loss : 0.030301, loss_ce: 0.010298
2021-12-03 00:18:41,581 iteration 3963 : loss : 0.027228, loss_ce: 0.010848
2021-12-03 00:18:43,134 iteration 3964 : loss : 0.029209, loss_ce: 0.013997
2021-12-03 00:18:44,550 iteration 3965 : loss : 0.022064, loss_ce: 0.006167
2021-12-03 00:18:46,053 iteration 3966 : loss : 0.029975, loss_ce: 0.012031
2021-12-03 00:18:47,526 iteration 3967 : loss : 0.025234, loss_ce: 0.008276
2021-12-03 00:18:48,918 iteration 3968 : loss : 0.022803, loss_ce: 0.008519
2021-12-03 00:18:50,421 iteration 3969 : loss : 0.025203, loss_ce: 0.006571
2021-12-03 00:18:51,885 iteration 3970 : loss : 0.023781, loss_ce: 0.007003
2021-12-03 00:18:53,277 iteration 3971 : loss : 0.019394, loss_ce: 0.007326
2021-12-03 00:18:54,780 iteration 3972 : loss : 0.036921, loss_ce: 0.009670
2021-12-03 00:18:56,203 iteration 3973 : loss : 0.026981, loss_ce: 0.014228
2021-12-03 00:18:57,592 iteration 3974 : loss : 0.020471, loss_ce: 0.005660
2021-12-03 00:18:59,081 iteration 3975 : loss : 0.022305, loss_ce: 0.008715
2021-12-03 00:19:00,614 iteration 3976 : loss : 0.033445, loss_ce: 0.012602
2021-12-03 00:19:02,139 iteration 3977 : loss : 0.022107, loss_ce: 0.009914
2021-12-03 00:19:03,670 iteration 3978 : loss : 0.038456, loss_ce: 0.013415
 58%|███████████████▊           | 234/400 [1:45:57<1:11:51, 25.97s/it]2021-12-03 00:19:05,168 iteration 3979 : loss : 0.029172, loss_ce: 0.010127
2021-12-03 00:19:06,646 iteration 3980 : loss : 0.027605, loss_ce: 0.009065
2021-12-03 00:19:08,094 iteration 3981 : loss : 0.022575, loss_ce: 0.008115
2021-12-03 00:19:09,480 iteration 3982 : loss : 0.020508, loss_ce: 0.007010
2021-12-03 00:19:10,886 iteration 3983 : loss : 0.021663, loss_ce: 0.009745
2021-12-03 00:19:12,340 iteration 3984 : loss : 0.021157, loss_ce: 0.007851
2021-12-03 00:19:13,813 iteration 3985 : loss : 0.034324, loss_ce: 0.018768
2021-12-03 00:19:15,348 iteration 3986 : loss : 0.027261, loss_ce: 0.011817
2021-12-03 00:19:16,843 iteration 3987 : loss : 0.025749, loss_ce: 0.010154
2021-12-03 00:19:18,307 iteration 3988 : loss : 0.025542, loss_ce: 0.010333
2021-12-03 00:19:19,745 iteration 3989 : loss : 0.025472, loss_ce: 0.005764
2021-12-03 00:19:21,191 iteration 3990 : loss : 0.033985, loss_ce: 0.009030
2021-12-03 00:19:22,703 iteration 3991 : loss : 0.029458, loss_ce: 0.006812
2021-12-03 00:19:24,195 iteration 3992 : loss : 0.028196, loss_ce: 0.008325
2021-12-03 00:19:25,707 iteration 3993 : loss : 0.025523, loss_ce: 0.009547
2021-12-03 00:19:27,148 iteration 3994 : loss : 0.025157, loss_ce: 0.010818
2021-12-03 00:19:27,148 Training Data Eval:
2021-12-03 00:19:34,548   Average segmentation loss on training set: 0.0175
2021-12-03 00:19:34,549 Validation Data Eval:
2021-12-03 00:19:37,116   Average segmentation loss on validation set: 0.0967
2021-12-03 00:19:38,552 iteration 3995 : loss : 0.022886, loss_ce: 0.009494
 59%|███████████████▊           | 235/400 [1:46:32<1:18:46, 28.65s/it]2021-12-03 00:19:40,139 iteration 3996 : loss : 0.022649, loss_ce: 0.006568
2021-12-03 00:19:41,564 iteration 3997 : loss : 0.030798, loss_ce: 0.008391
2021-12-03 00:19:43,071 iteration 3998 : loss : 0.036169, loss_ce: 0.018916
2021-12-03 00:19:44,518 iteration 3999 : loss : 0.024226, loss_ce: 0.005582
2021-12-03 00:19:46,027 iteration 4000 : loss : 0.019067, loss_ce: 0.008664
2021-12-03 00:19:47,432 iteration 4001 : loss : 0.019979, loss_ce: 0.007097
2021-12-03 00:19:48,896 iteration 4002 : loss : 0.024489, loss_ce: 0.009626
2021-12-03 00:19:50,369 iteration 4003 : loss : 0.025353, loss_ce: 0.011038
2021-12-03 00:19:51,875 iteration 4004 : loss : 0.030669, loss_ce: 0.007642
2021-12-03 00:19:53,338 iteration 4005 : loss : 0.028194, loss_ce: 0.012543
2021-12-03 00:19:54,759 iteration 4006 : loss : 0.019739, loss_ce: 0.008338
2021-12-03 00:19:56,262 iteration 4007 : loss : 0.025774, loss_ce: 0.007381
2021-12-03 00:19:57,683 iteration 4008 : loss : 0.021698, loss_ce: 0.008123
2021-12-03 00:19:59,123 iteration 4009 : loss : 0.025233, loss_ce: 0.010074
2021-12-03 00:20:00,644 iteration 4010 : loss : 0.026469, loss_ce: 0.011041
2021-12-03 00:20:02,056 iteration 4011 : loss : 0.019043, loss_ce: 0.005119
2021-12-03 00:20:03,586 iteration 4012 : loss : 0.026085, loss_ce: 0.011687
 59%|███████████████▉           | 236/400 [1:46:57<1:15:20, 27.56s/it]2021-12-03 00:20:05,171 iteration 4013 : loss : 0.038721, loss_ce: 0.010313
2021-12-03 00:20:06,583 iteration 4014 : loss : 0.020998, loss_ce: 0.006638
2021-12-03 00:20:08,087 iteration 4015 : loss : 0.040060, loss_ce: 0.015784
2021-12-03 00:20:09,585 iteration 4016 : loss : 0.020478, loss_ce: 0.007062
2021-12-03 00:20:11,105 iteration 4017 : loss : 0.022227, loss_ce: 0.007155
2021-12-03 00:20:12,543 iteration 4018 : loss : 0.019309, loss_ce: 0.006666
2021-12-03 00:20:14,012 iteration 4019 : loss : 0.024168, loss_ce: 0.012818
2021-12-03 00:20:15,438 iteration 4020 : loss : 0.026702, loss_ce: 0.015679
2021-12-03 00:20:16,876 iteration 4021 : loss : 0.021280, loss_ce: 0.010375
2021-12-03 00:20:18,372 iteration 4022 : loss : 0.027807, loss_ce: 0.014154
2021-12-03 00:20:19,803 iteration 4023 : loss : 0.018009, loss_ce: 0.006068
2021-12-03 00:20:21,213 iteration 4024 : loss : 0.022240, loss_ce: 0.006765
2021-12-03 00:20:22,645 iteration 4025 : loss : 0.019715, loss_ce: 0.006499
2021-12-03 00:20:24,145 iteration 4026 : loss : 0.019492, loss_ce: 0.007914
2021-12-03 00:20:25,630 iteration 4027 : loss : 0.025607, loss_ce: 0.008435
2021-12-03 00:20:27,143 iteration 4028 : loss : 0.027697, loss_ce: 0.008199
2021-12-03 00:20:28,574 iteration 4029 : loss : 0.017017, loss_ce: 0.007082
 59%|███████████████▉           | 237/400 [1:47:22<1:12:46, 26.79s/it]2021-12-03 00:20:30,161 iteration 4030 : loss : 0.021600, loss_ce: 0.008792
2021-12-03 00:20:31,640 iteration 4031 : loss : 0.034226, loss_ce: 0.011068
2021-12-03 00:20:33,094 iteration 4032 : loss : 0.033643, loss_ce: 0.015076
2021-12-03 00:20:34,550 iteration 4033 : loss : 0.031034, loss_ce: 0.009474
2021-12-03 00:20:35,953 iteration 4034 : loss : 0.024494, loss_ce: 0.007820
2021-12-03 00:20:37,395 iteration 4035 : loss : 0.019905, loss_ce: 0.006119
2021-12-03 00:20:38,893 iteration 4036 : loss : 0.029704, loss_ce: 0.009621
2021-12-03 00:20:40,315 iteration 4037 : loss : 0.017268, loss_ce: 0.008359
2021-12-03 00:20:41,836 iteration 4038 : loss : 0.024022, loss_ce: 0.007974
2021-12-03 00:20:43,382 iteration 4039 : loss : 0.023445, loss_ce: 0.008689
2021-12-03 00:20:44,920 iteration 4040 : loss : 0.025672, loss_ce: 0.011274
2021-12-03 00:20:46,423 iteration 4041 : loss : 0.021542, loss_ce: 0.006251
2021-12-03 00:20:47,856 iteration 4042 : loss : 0.031409, loss_ce: 0.012405
2021-12-03 00:20:49,336 iteration 4043 : loss : 0.175527, loss_ce: 0.005157
2021-12-03 00:20:50,769 iteration 4044 : loss : 0.019866, loss_ce: 0.007852
2021-12-03 00:20:52,218 iteration 4045 : loss : 0.021945, loss_ce: 0.010029
2021-12-03 00:20:53,721 iteration 4046 : loss : 0.023979, loss_ce: 0.010627
 60%|████████████████           | 238/400 [1:47:47<1:10:59, 26.30s/it]2021-12-03 00:20:55,307 iteration 4047 : loss : 0.021358, loss_ce: 0.009600
2021-12-03 00:20:56,807 iteration 4048 : loss : 0.023546, loss_ce: 0.008848
2021-12-03 00:20:58,241 iteration 4049 : loss : 0.016879, loss_ce: 0.006276
2021-12-03 00:20:59,729 iteration 4050 : loss : 0.023011, loss_ce: 0.008705
2021-12-03 00:21:01,288 iteration 4051 : loss : 0.051493, loss_ce: 0.008354
2021-12-03 00:21:02,694 iteration 4052 : loss : 0.023125, loss_ce: 0.009061
2021-12-03 00:21:04,087 iteration 4053 : loss : 0.018371, loss_ce: 0.006001
2021-12-03 00:21:05,506 iteration 4054 : loss : 0.039383, loss_ce: 0.011444
2021-12-03 00:21:06,954 iteration 4055 : loss : 0.022737, loss_ce: 0.010270
2021-12-03 00:21:08,434 iteration 4056 : loss : 0.036177, loss_ce: 0.017887
2021-12-03 00:21:09,869 iteration 4057 : loss : 0.021037, loss_ce: 0.004656
2021-12-03 00:21:11,333 iteration 4058 : loss : 0.015119, loss_ce: 0.005387
2021-12-03 00:21:12,885 iteration 4059 : loss : 0.038433, loss_ce: 0.017756
2021-12-03 00:21:14,357 iteration 4060 : loss : 0.024426, loss_ce: 0.012660
2021-12-03 00:21:15,838 iteration 4061 : loss : 0.024947, loss_ce: 0.010957
2021-12-03 00:21:17,337 iteration 4062 : loss : 0.029662, loss_ce: 0.012558
2021-12-03 00:21:18,813 iteration 4063 : loss : 0.027023, loss_ce: 0.008718
 60%|████████████████▏          | 239/400 [1:48:12<1:09:35, 25.93s/it]2021-12-03 00:21:20,309 iteration 4064 : loss : 0.026753, loss_ce: 0.006503
2021-12-03 00:21:21,757 iteration 4065 : loss : 0.018845, loss_ce: 0.006283
2021-12-03 00:21:23,277 iteration 4066 : loss : 0.026938, loss_ce: 0.009798
2021-12-03 00:21:24,699 iteration 4067 : loss : 0.018768, loss_ce: 0.007354
2021-12-03 00:21:26,162 iteration 4068 : loss : 0.022172, loss_ce: 0.007955
2021-12-03 00:21:27,649 iteration 4069 : loss : 0.020835, loss_ce: 0.008713
2021-12-03 00:21:29,134 iteration 4070 : loss : 0.032101, loss_ce: 0.012867
2021-12-03 00:21:30,661 iteration 4071 : loss : 0.026736, loss_ce: 0.008180
2021-12-03 00:21:32,106 iteration 4072 : loss : 0.018192, loss_ce: 0.005816
2021-12-03 00:21:33,530 iteration 4073 : loss : 0.014839, loss_ce: 0.004874
2021-12-03 00:21:34,987 iteration 4074 : loss : 0.026183, loss_ce: 0.011975
2021-12-03 00:21:36,492 iteration 4075 : loss : 0.021076, loss_ce: 0.006677
2021-12-03 00:21:37,926 iteration 4076 : loss : 0.027312, loss_ce: 0.010633
2021-12-03 00:21:39,383 iteration 4077 : loss : 0.020329, loss_ce: 0.006845
2021-12-03 00:21:40,894 iteration 4078 : loss : 0.028017, loss_ce: 0.011333
2021-12-03 00:21:42,380 iteration 4079 : loss : 0.018602, loss_ce: 0.008052
2021-12-03 00:21:42,380 Training Data Eval:
2021-12-03 00:21:49,798   Average segmentation loss on training set: 0.0157
2021-12-03 00:21:49,798 Validation Data Eval:
2021-12-03 00:21:52,370   Average segmentation loss on validation set: 0.0642
2021-12-03 00:21:53,912 iteration 4080 : loss : 0.024616, loss_ce: 0.011281
 60%|████████████████▏          | 240/400 [1:48:48<1:16:29, 28.69s/it]2021-12-03 00:21:55,465 iteration 4081 : loss : 0.027522, loss_ce: 0.009950
2021-12-03 00:21:56,933 iteration 4082 : loss : 0.021337, loss_ce: 0.009171
2021-12-03 00:21:58,350 iteration 4083 : loss : 0.017416, loss_ce: 0.007366
2021-12-03 00:21:59,810 iteration 4084 : loss : 0.020199, loss_ce: 0.007206
2021-12-03 00:22:01,245 iteration 4085 : loss : 0.024940, loss_ce: 0.007914
2021-12-03 00:22:02,826 iteration 4086 : loss : 0.032725, loss_ce: 0.011248
2021-12-03 00:22:04,294 iteration 4087 : loss : 0.016495, loss_ce: 0.004871
2021-12-03 00:22:05,690 iteration 4088 : loss : 0.023703, loss_ce: 0.010941
2021-12-03 00:22:07,157 iteration 4089 : loss : 0.029553, loss_ce: 0.011232
2021-12-03 00:22:08,537 iteration 4090 : loss : 0.022985, loss_ce: 0.007259
2021-12-03 00:22:09,989 iteration 4091 : loss : 0.035138, loss_ce: 0.015380
2021-12-03 00:22:11,466 iteration 4092 : loss : 0.017379, loss_ce: 0.005977
2021-12-03 00:22:12,942 iteration 4093 : loss : 0.047977, loss_ce: 0.020708
2021-12-03 00:22:14,394 iteration 4094 : loss : 0.018744, loss_ce: 0.007345
2021-12-03 00:22:15,883 iteration 4095 : loss : 0.020216, loss_ce: 0.008740
2021-12-03 00:22:17,323 iteration 4096 : loss : 0.020881, loss_ce: 0.011565
2021-12-03 00:22:18,777 iteration 4097 : loss : 0.018328, loss_ce: 0.006765
 60%|████████████████▎          | 241/400 [1:49:12<1:12:58, 27.54s/it]2021-12-03 00:22:20,269 iteration 4098 : loss : 0.021759, loss_ce: 0.008038
2021-12-03 00:22:21,695 iteration 4099 : loss : 0.024166, loss_ce: 0.006288
2021-12-03 00:22:23,173 iteration 4100 : loss : 0.020472, loss_ce: 0.006740
2021-12-03 00:22:24,673 iteration 4101 : loss : 0.031332, loss_ce: 0.010712
2021-12-03 00:22:26,170 iteration 4102 : loss : 0.029389, loss_ce: 0.012875
2021-12-03 00:22:27,649 iteration 4103 : loss : 0.031640, loss_ce: 0.013756
2021-12-03 00:22:29,118 iteration 4104 : loss : 0.029840, loss_ce: 0.012477
2021-12-03 00:22:30,611 iteration 4105 : loss : 0.026970, loss_ce: 0.011884
2021-12-03 00:22:32,062 iteration 4106 : loss : 0.026454, loss_ce: 0.010097
2021-12-03 00:22:33,518 iteration 4107 : loss : 0.017985, loss_ce: 0.007731
2021-12-03 00:22:34,974 iteration 4108 : loss : 0.019774, loss_ce: 0.007904
2021-12-03 00:22:36,396 iteration 4109 : loss : 0.018062, loss_ce: 0.006437
2021-12-03 00:22:37,882 iteration 4110 : loss : 0.028176, loss_ce: 0.010113
2021-12-03 00:22:39,468 iteration 4111 : loss : 0.034911, loss_ce: 0.016377
2021-12-03 00:22:40,899 iteration 4112 : loss : 0.020564, loss_ce: 0.007398
2021-12-03 00:22:42,415 iteration 4113 : loss : 0.034775, loss_ce: 0.009911
2021-12-03 00:22:43,879 iteration 4114 : loss : 0.024836, loss_ce: 0.011721
 60%|████████████████▎          | 242/400 [1:49:38<1:10:35, 26.81s/it]2021-12-03 00:22:45,348 iteration 4115 : loss : 0.018839, loss_ce: 0.009037
2021-12-03 00:22:46,850 iteration 4116 : loss : 0.016525, loss_ce: 0.005121
2021-12-03 00:22:48,250 iteration 4117 : loss : 0.016799, loss_ce: 0.005927
2021-12-03 00:22:49,773 iteration 4118 : loss : 0.029837, loss_ce: 0.010165
2021-12-03 00:22:51,355 iteration 4119 : loss : 0.028231, loss_ce: 0.008662
2021-12-03 00:22:52,841 iteration 4120 : loss : 0.023297, loss_ce: 0.006659
2021-12-03 00:22:54,272 iteration 4121 : loss : 0.018150, loss_ce: 0.005959
2021-12-03 00:22:55,731 iteration 4122 : loss : 0.025175, loss_ce: 0.007537
2021-12-03 00:22:57,154 iteration 4123 : loss : 0.013025, loss_ce: 0.005546
2021-12-03 00:22:58,661 iteration 4124 : loss : 0.022700, loss_ce: 0.010051
2021-12-03 00:23:00,162 iteration 4125 : loss : 0.026471, loss_ce: 0.011065
2021-12-03 00:23:01,637 iteration 4126 : loss : 0.025126, loss_ce: 0.009270
2021-12-03 00:23:03,053 iteration 4127 : loss : 0.014186, loss_ce: 0.006426
2021-12-03 00:23:04,590 iteration 4128 : loss : 0.030525, loss_ce: 0.008780
2021-12-03 00:23:05,990 iteration 4129 : loss : 0.030014, loss_ce: 0.007066
2021-12-03 00:23:07,398 iteration 4130 : loss : 0.017818, loss_ce: 0.005349
2021-12-03 00:23:08,858 iteration 4131 : loss : 0.018434, loss_ce: 0.008291
 61%|████████████████▍          | 243/400 [1:50:03<1:08:42, 26.26s/it]2021-12-03 00:23:10,408 iteration 4132 : loss : 0.023565, loss_ce: 0.006955
2021-12-03 00:23:11,873 iteration 4133 : loss : 0.028952, loss_ce: 0.009818
2021-12-03 00:23:13,361 iteration 4134 : loss : 0.034137, loss_ce: 0.016623
2021-12-03 00:23:14,745 iteration 4135 : loss : 0.027593, loss_ce: 0.013692
2021-12-03 00:23:16,213 iteration 4136 : loss : 0.022368, loss_ce: 0.009735
2021-12-03 00:23:17,629 iteration 4137 : loss : 0.015879, loss_ce: 0.006160
2021-12-03 00:23:19,137 iteration 4138 : loss : 0.019888, loss_ce: 0.008623
2021-12-03 00:23:20,616 iteration 4139 : loss : 0.020086, loss_ce: 0.007873
2021-12-03 00:23:22,082 iteration 4140 : loss : 0.016116, loss_ce: 0.007193
2021-12-03 00:23:23,557 iteration 4141 : loss : 0.023204, loss_ce: 0.008139
2021-12-03 00:23:25,083 iteration 4142 : loss : 0.040495, loss_ce: 0.016985
2021-12-03 00:23:26,474 iteration 4143 : loss : 0.025379, loss_ce: 0.007880
2021-12-03 00:23:27,887 iteration 4144 : loss : 0.019345, loss_ce: 0.004393
2021-12-03 00:23:29,414 iteration 4145 : loss : 0.022741, loss_ce: 0.008488
2021-12-03 00:23:30,855 iteration 4146 : loss : 0.018615, loss_ce: 0.007917
2021-12-03 00:23:32,330 iteration 4147 : loss : 0.018887, loss_ce: 0.006695
2021-12-03 00:23:33,763 iteration 4148 : loss : 0.022815, loss_ce: 0.010226
 61%|████████████████▍          | 244/400 [1:50:27<1:07:13, 25.85s/it]2021-12-03 00:23:35,204 iteration 4149 : loss : 0.018731, loss_ce: 0.006104
2021-12-03 00:23:36,673 iteration 4150 : loss : 0.016175, loss_ce: 0.004726
2021-12-03 00:23:38,185 iteration 4151 : loss : 0.029097, loss_ce: 0.012518
2021-12-03 00:23:39,657 iteration 4152 : loss : 0.023660, loss_ce: 0.009032
2021-12-03 00:23:41,064 iteration 4153 : loss : 0.016501, loss_ce: 0.005553
2021-12-03 00:23:42,557 iteration 4154 : loss : 0.016085, loss_ce: 0.005419
2021-12-03 00:23:44,017 iteration 4155 : loss : 0.024681, loss_ce: 0.007621
2021-12-03 00:23:45,418 iteration 4156 : loss : 0.015901, loss_ce: 0.005488
2021-12-03 00:23:46,941 iteration 4157 : loss : 0.020238, loss_ce: 0.009456
2021-12-03 00:23:48,384 iteration 4158 : loss : 0.020988, loss_ce: 0.007698
2021-12-03 00:23:49,836 iteration 4159 : loss : 0.014708, loss_ce: 0.006018
2021-12-03 00:23:51,385 iteration 4160 : loss : 0.044122, loss_ce: 0.016607
2021-12-03 00:23:52,912 iteration 4161 : loss : 0.023725, loss_ce: 0.007556
2021-12-03 00:23:54,437 iteration 4162 : loss : 0.033715, loss_ce: 0.013914
2021-12-03 00:23:55,937 iteration 4163 : loss : 0.035953, loss_ce: 0.012665
2021-12-03 00:23:57,397 iteration 4164 : loss : 0.019303, loss_ce: 0.007197
2021-12-03 00:23:57,397 Training Data Eval:
2021-12-03 00:24:04,809   Average segmentation loss on training set: 0.0154
2021-12-03 00:24:04,809 Validation Data Eval:
2021-12-03 00:24:07,363   Average segmentation loss on validation set: 0.0757
2021-12-03 00:24:08,867 iteration 4165 : loss : 0.025689, loss_ce: 0.007960
 61%|████████████████▌          | 245/400 [1:51:03<1:13:57, 28.63s/it]2021-12-03 00:24:10,375 iteration 4166 : loss : 0.017039, loss_ce: 0.006794
2021-12-03 00:24:11,782 iteration 4167 : loss : 0.017590, loss_ce: 0.006118
2021-12-03 00:24:13,227 iteration 4168 : loss : 0.015471, loss_ce: 0.006048
2021-12-03 00:24:14,654 iteration 4169 : loss : 0.018309, loss_ce: 0.008728
2021-12-03 00:24:16,229 iteration 4170 : loss : 0.029005, loss_ce: 0.012335
2021-12-03 00:24:17,638 iteration 4171 : loss : 0.020694, loss_ce: 0.005845
2021-12-03 00:24:19,099 iteration 4172 : loss : 0.018576, loss_ce: 0.008161
2021-12-03 00:24:20,582 iteration 4173 : loss : 0.024710, loss_ce: 0.007145
2021-12-03 00:24:22,022 iteration 4174 : loss : 0.018527, loss_ce: 0.005022
2021-12-03 00:24:23,459 iteration 4175 : loss : 0.016846, loss_ce: 0.006785
2021-12-03 00:24:24,910 iteration 4176 : loss : 0.028519, loss_ce: 0.012031
2021-12-03 00:24:26,412 iteration 4177 : loss : 0.026142, loss_ce: 0.006434
2021-12-03 00:24:27,827 iteration 4178 : loss : 0.019068, loss_ce: 0.007184
2021-12-03 00:24:29,266 iteration 4179 : loss : 0.021926, loss_ce: 0.009759
2021-12-03 00:24:30,703 iteration 4180 : loss : 0.018528, loss_ce: 0.005483
2021-12-03 00:24:32,161 iteration 4181 : loss : 0.016992, loss_ce: 0.007303
2021-12-03 00:24:33,630 iteration 4182 : loss : 0.019450, loss_ce: 0.004915
 62%|████████████████▌          | 246/400 [1:51:27<1:10:30, 27.47s/it]2021-12-03 00:24:35,177 iteration 4183 : loss : 0.026160, loss_ce: 0.007875
2021-12-03 00:24:36,667 iteration 4184 : loss : 0.018436, loss_ce: 0.007360
2021-12-03 00:24:38,142 iteration 4185 : loss : 0.020223, loss_ce: 0.008698
2021-12-03 00:24:39,597 iteration 4186 : loss : 0.018300, loss_ce: 0.005063
2021-12-03 00:24:41,097 iteration 4187 : loss : 0.030222, loss_ce: 0.008358
2021-12-03 00:24:42,525 iteration 4188 : loss : 0.026062, loss_ce: 0.008106
2021-12-03 00:24:44,087 iteration 4189 : loss : 0.020579, loss_ce: 0.008902
2021-12-03 00:24:45,590 iteration 4190 : loss : 0.040739, loss_ce: 0.018126
2021-12-03 00:24:47,109 iteration 4191 : loss : 0.028718, loss_ce: 0.011510
2021-12-03 00:24:48,494 iteration 4192 : loss : 0.018303, loss_ce: 0.005820
2021-12-03 00:24:49,973 iteration 4193 : loss : 0.026286, loss_ce: 0.012210
2021-12-03 00:24:51,476 iteration 4194 : loss : 0.025905, loss_ce: 0.010330
2021-12-03 00:24:52,912 iteration 4195 : loss : 0.029800, loss_ce: 0.009073
2021-12-03 00:24:54,407 iteration 4196 : loss : 0.019768, loss_ce: 0.008078
2021-12-03 00:24:55,844 iteration 4197 : loss : 0.026115, loss_ce: 0.007942
2021-12-03 00:24:57,292 iteration 4198 : loss : 0.018276, loss_ce: 0.006904
2021-12-03 00:24:58,705 iteration 4199 : loss : 0.016623, loss_ce: 0.006348
 62%|████████████████▋          | 247/400 [1:51:52<1:08:13, 26.75s/it]2021-12-03 00:25:00,226 iteration 4200 : loss : 0.032883, loss_ce: 0.013961
2021-12-03 00:25:01,724 iteration 4201 : loss : 0.019226, loss_ce: 0.007903
2021-12-03 00:25:03,205 iteration 4202 : loss : 0.023670, loss_ce: 0.009881
2021-12-03 00:25:04,761 iteration 4203 : loss : 0.024324, loss_ce: 0.010149
2021-12-03 00:25:06,210 iteration 4204 : loss : 0.020333, loss_ce: 0.008590
2021-12-03 00:25:07,659 iteration 4205 : loss : 0.020839, loss_ce: 0.008708
2021-12-03 00:25:09,228 iteration 4206 : loss : 0.028330, loss_ce: 0.009830
2021-12-03 00:25:10,719 iteration 4207 : loss : 0.023920, loss_ce: 0.009164
2021-12-03 00:25:12,091 iteration 4208 : loss : 0.014623, loss_ce: 0.005506
2021-12-03 00:25:13,529 iteration 4209 : loss : 0.020401, loss_ce: 0.009089
2021-12-03 00:25:14,978 iteration 4210 : loss : 0.019548, loss_ce: 0.008540
2021-12-03 00:25:16,453 iteration 4211 : loss : 0.020788, loss_ce: 0.008235
2021-12-03 00:25:17,962 iteration 4212 : loss : 0.021154, loss_ce: 0.007953
2021-12-03 00:25:19,393 iteration 4213 : loss : 0.029506, loss_ce: 0.007861
2021-12-03 00:25:20,892 iteration 4214 : loss : 0.029417, loss_ce: 0.008825
2021-12-03 00:25:22,348 iteration 4215 : loss : 0.022231, loss_ce: 0.007316
2021-12-03 00:25:23,791 iteration 4216 : loss : 0.025452, loss_ce: 0.009338
 62%|████████████████▋          | 248/400 [1:52:17<1:06:30, 26.25s/it]2021-12-03 00:25:25,342 iteration 4217 : loss : 0.029480, loss_ce: 0.010084
2021-12-03 00:25:26,779 iteration 4218 : loss : 0.022361, loss_ce: 0.007270
2021-12-03 00:25:28,217 iteration 4219 : loss : 0.020398, loss_ce: 0.007510
2021-12-03 00:25:29,607 iteration 4220 : loss : 0.020617, loss_ce: 0.004983
2021-12-03 00:25:31,161 iteration 4221 : loss : 0.019761, loss_ce: 0.008643
2021-12-03 00:25:32,710 iteration 4222 : loss : 0.023205, loss_ce: 0.007959
2021-12-03 00:25:34,144 iteration 4223 : loss : 0.020904, loss_ce: 0.006919
2021-12-03 00:25:35,668 iteration 4224 : loss : 0.036375, loss_ce: 0.009500
2021-12-03 00:25:37,156 iteration 4225 : loss : 0.024808, loss_ce: 0.007000
2021-12-03 00:25:38,667 iteration 4226 : loss : 0.020648, loss_ce: 0.009488
2021-12-03 00:25:40,153 iteration 4227 : loss : 0.019470, loss_ce: 0.007508
2021-12-03 00:25:41,567 iteration 4228 : loss : 0.020351, loss_ce: 0.010411
2021-12-03 00:25:43,012 iteration 4229 : loss : 0.024131, loss_ce: 0.009689
2021-12-03 00:25:44,451 iteration 4230 : loss : 0.022248, loss_ce: 0.010788
2021-12-03 00:25:45,951 iteration 4231 : loss : 0.022136, loss_ce: 0.007550
2021-12-03 00:25:47,451 iteration 4232 : loss : 0.026407, loss_ce: 0.008139
2021-12-03 00:25:48,910 iteration 4233 : loss : 0.025286, loss_ce: 0.013178
 62%|████████████████▊          | 249/400 [1:52:43<1:05:12, 25.91s/it]2021-12-03 00:25:50,340 iteration 4234 : loss : 0.025656, loss_ce: 0.005892
2021-12-03 00:25:51,750 iteration 4235 : loss : 0.013295, loss_ce: 0.004754
2021-12-03 00:25:53,256 iteration 4236 : loss : 0.022117, loss_ce: 0.010061
2021-12-03 00:25:54,686 iteration 4237 : loss : 0.021816, loss_ce: 0.008476
2021-12-03 00:25:56,143 iteration 4238 : loss : 0.030162, loss_ce: 0.016198
2021-12-03 00:25:57,720 iteration 4239 : loss : 0.029032, loss_ce: 0.011156
2021-12-03 00:25:59,196 iteration 4240 : loss : 0.021943, loss_ce: 0.006598
2021-12-03 00:26:00,576 iteration 4241 : loss : 0.017738, loss_ce: 0.008289
2021-12-03 00:26:02,037 iteration 4242 : loss : 0.020589, loss_ce: 0.006318
2021-12-03 00:26:03,469 iteration 4243 : loss : 0.021639, loss_ce: 0.008412
2021-12-03 00:26:04,868 iteration 4244 : loss : 0.016105, loss_ce: 0.007201
2021-12-03 00:26:06,377 iteration 4245 : loss : 0.022215, loss_ce: 0.009754
2021-12-03 00:26:07,919 iteration 4246 : loss : 0.026236, loss_ce: 0.007699
2021-12-03 00:26:09,410 iteration 4247 : loss : 0.020225, loss_ce: 0.008195
2021-12-03 00:26:10,819 iteration 4248 : loss : 0.028445, loss_ce: 0.011208
2021-12-03 00:26:12,332 iteration 4249 : loss : 0.024342, loss_ce: 0.006784
2021-12-03 00:26:12,333 Training Data Eval:
2021-12-03 00:26:19,736   Average segmentation loss on training set: 0.0136
2021-12-03 00:26:19,737 Validation Data Eval:
2021-12-03 00:26:22,304   Average segmentation loss on validation set: 0.0837
2021-12-03 00:26:23,795 iteration 4250 : loss : 0.025450, loss_ce: 0.009416
2021-12-03 00:26:25,744 save model to ../model/TU_RUNMC256/TU_pretrain_R50-ViT-B_16_skip3_bs16_256/1channelepoch_249.pth
 62%|████████████████▉          | 250/400 [1:53:19<1:12:55, 29.17s/it]2021-12-03 00:26:27,268 iteration 4251 : loss : 0.023596, loss_ce: 0.006318
2021-12-03 00:26:28,706 iteration 4252 : loss : 0.023991, loss_ce: 0.010985
2021-12-03 00:26:30,099 iteration 4253 : loss : 0.022247, loss_ce: 0.006210
2021-12-03 00:26:31,539 iteration 4254 : loss : 0.017770, loss_ce: 0.006666
2021-12-03 00:26:32,985 iteration 4255 : loss : 0.021178, loss_ce: 0.007731
2021-12-03 00:26:34,301 iteration 4256 : loss : 0.018371, loss_ce: 0.007649
2021-12-03 00:26:35,727 iteration 4257 : loss : 0.022600, loss_ce: 0.008142
2021-12-03 00:26:37,108 iteration 4258 : loss : 0.022047, loss_ce: 0.006501
2021-12-03 00:26:38,605 iteration 4259 : loss : 0.026074, loss_ce: 0.011844
2021-12-03 00:26:40,098 iteration 4260 : loss : 0.024280, loss_ce: 0.007247
2021-12-03 00:26:41,605 iteration 4261 : loss : 0.025846, loss_ce: 0.010366
2021-12-03 00:26:43,060 iteration 4262 : loss : 0.022376, loss_ce: 0.010322
2021-12-03 00:26:44,571 iteration 4263 : loss : 0.022536, loss_ce: 0.009027
2021-12-03 00:26:46,077 iteration 4264 : loss : 0.024924, loss_ce: 0.009927
2021-12-03 00:26:47,531 iteration 4265 : loss : 0.032219, loss_ce: 0.007308
2021-12-03 00:26:49,017 iteration 4266 : loss : 0.020787, loss_ce: 0.006472
2021-12-03 00:26:50,528 iteration 4267 : loss : 0.019594, loss_ce: 0.007149
 63%|████████████████▉          | 251/400 [1:53:44<1:09:12, 27.87s/it]2021-12-03 00:26:52,045 iteration 4268 : loss : 0.016939, loss_ce: 0.004009
2021-12-03 00:26:53,496 iteration 4269 : loss : 0.018846, loss_ce: 0.005783
2021-12-03 00:26:54,939 iteration 4270 : loss : 0.019704, loss_ce: 0.010530
2021-12-03 00:26:56,347 iteration 4271 : loss : 0.020447, loss_ce: 0.007909
2021-12-03 00:26:57,814 iteration 4272 : loss : 0.019880, loss_ce: 0.009261
2021-12-03 00:26:59,217 iteration 4273 : loss : 0.017519, loss_ce: 0.007037
2021-12-03 00:27:00,759 iteration 4274 : loss : 0.020374, loss_ce: 0.008938
2021-12-03 00:27:02,195 iteration 4275 : loss : 0.017903, loss_ce: 0.006309
2021-12-03 00:27:03,700 iteration 4276 : loss : 0.029594, loss_ce: 0.008058
2021-12-03 00:27:05,196 iteration 4277 : loss : 0.025948, loss_ce: 0.008099
2021-12-03 00:27:06,673 iteration 4278 : loss : 0.023314, loss_ce: 0.007243
2021-12-03 00:27:08,102 iteration 4279 : loss : 0.022668, loss_ce: 0.011097
2021-12-03 00:27:09,584 iteration 4280 : loss : 0.020846, loss_ce: 0.006836
2021-12-03 00:27:11,058 iteration 4281 : loss : 0.026855, loss_ce: 0.007614
2021-12-03 00:27:12,474 iteration 4282 : loss : 0.016921, loss_ce: 0.006475
2021-12-03 00:27:13,937 iteration 4283 : loss : 0.025524, loss_ce: 0.007420
2021-12-03 00:27:15,384 iteration 4284 : loss : 0.017651, loss_ce: 0.006406
 63%|█████████████████          | 252/400 [1:54:09<1:06:30, 26.97s/it]2021-12-03 00:27:16,843 iteration 4285 : loss : 0.021592, loss_ce: 0.006765
2021-12-03 00:27:18,363 iteration 4286 : loss : 0.026178, loss_ce: 0.009104
2021-12-03 00:27:19,799 iteration 4287 : loss : 0.021388, loss_ce: 0.008781
2021-12-03 00:27:21,224 iteration 4288 : loss : 0.020556, loss_ce: 0.008940
2021-12-03 00:27:22,685 iteration 4289 : loss : 0.022305, loss_ce: 0.007775
2021-12-03 00:27:24,138 iteration 4290 : loss : 0.021828, loss_ce: 0.005610
2021-12-03 00:27:25,628 iteration 4291 : loss : 0.018832, loss_ce: 0.006712
2021-12-03 00:27:27,117 iteration 4292 : loss : 0.024761, loss_ce: 0.011833
2021-12-03 00:27:28,589 iteration 4293 : loss : 0.022562, loss_ce: 0.007509
2021-12-03 00:27:30,014 iteration 4294 : loss : 0.018668, loss_ce: 0.004618
2021-12-03 00:27:31,563 iteration 4295 : loss : 0.027808, loss_ce: 0.009451
2021-12-03 00:27:33,025 iteration 4296 : loss : 0.014374, loss_ce: 0.004455
2021-12-03 00:27:34,503 iteration 4297 : loss : 0.022848, loss_ce: 0.008545
2021-12-03 00:27:35,938 iteration 4298 : loss : 0.015002, loss_ce: 0.006975
2021-12-03 00:27:37,451 iteration 4299 : loss : 0.016765, loss_ce: 0.006897
2021-12-03 00:27:38,987 iteration 4300 : loss : 0.024803, loss_ce: 0.009620
2021-12-03 00:27:40,512 iteration 4301 : loss : 0.018075, loss_ce: 0.007357
 63%|█████████████████          | 253/400 [1:54:34<1:04:43, 26.42s/it]2021-12-03 00:27:42,061 iteration 4302 : loss : 0.031904, loss_ce: 0.011134
2021-12-03 00:27:43,562 iteration 4303 : loss : 0.044672, loss_ce: 0.007621
2021-12-03 00:27:44,985 iteration 4304 : loss : 0.018578, loss_ce: 0.006917
2021-12-03 00:27:46,422 iteration 4305 : loss : 0.034542, loss_ce: 0.011919
2021-12-03 00:27:47,875 iteration 4306 : loss : 0.023250, loss_ce: 0.008969
2021-12-03 00:27:49,301 iteration 4307 : loss : 0.017488, loss_ce: 0.007134
2021-12-03 00:27:50,803 iteration 4308 : loss : 0.019319, loss_ce: 0.006890
2021-12-03 00:27:52,331 iteration 4309 : loss : 0.034063, loss_ce: 0.012686
2021-12-03 00:27:53,795 iteration 4310 : loss : 0.018281, loss_ce: 0.007735
2021-12-03 00:27:55,237 iteration 4311 : loss : 0.018815, loss_ce: 0.006635
2021-12-03 00:27:56,665 iteration 4312 : loss : 0.027305, loss_ce: 0.009896
2021-12-03 00:27:58,114 iteration 4313 : loss : 0.018091, loss_ce: 0.008425
2021-12-03 00:27:59,550 iteration 4314 : loss : 0.021035, loss_ce: 0.006804
2021-12-03 00:28:01,057 iteration 4315 : loss : 0.017081, loss_ce: 0.005858
2021-12-03 00:28:02,479 iteration 4316 : loss : 0.021794, loss_ce: 0.006747
2021-12-03 00:28:03,977 iteration 4317 : loss : 0.026627, loss_ce: 0.010168
2021-12-03 00:28:05,395 iteration 4318 : loss : 0.019840, loss_ce: 0.008318
 64%|█████████████████▏         | 254/400 [1:54:59<1:03:09, 25.95s/it]2021-12-03 00:28:06,942 iteration 4319 : loss : 0.027456, loss_ce: 0.009985
2021-12-03 00:28:08,412 iteration 4320 : loss : 0.024591, loss_ce: 0.009767
2021-12-03 00:28:09,794 iteration 4321 : loss : 0.021856, loss_ce: 0.006548
2021-12-03 00:28:11,264 iteration 4322 : loss : 0.019672, loss_ce: 0.006586
2021-12-03 00:28:12,690 iteration 4323 : loss : 0.018955, loss_ce: 0.008645
2021-12-03 00:28:14,260 iteration 4324 : loss : 0.028242, loss_ce: 0.012689
2021-12-03 00:28:15,734 iteration 4325 : loss : 0.022612, loss_ce: 0.009777
2021-12-03 00:28:17,175 iteration 4326 : loss : 0.026492, loss_ce: 0.013121
2021-12-03 00:28:18,652 iteration 4327 : loss : 0.020802, loss_ce: 0.006279
2021-12-03 00:28:20,062 iteration 4328 : loss : 0.037197, loss_ce: 0.013477
2021-12-03 00:28:21,578 iteration 4329 : loss : 0.048137, loss_ce: 0.011561
2021-12-03 00:28:23,084 iteration 4330 : loss : 0.022986, loss_ce: 0.010262
2021-12-03 00:28:24,625 iteration 4331 : loss : 0.037703, loss_ce: 0.010812
2021-12-03 00:28:26,127 iteration 4332 : loss : 0.027250, loss_ce: 0.008254
2021-12-03 00:28:27,648 iteration 4333 : loss : 0.033007, loss_ce: 0.014055
2021-12-03 00:28:29,115 iteration 4334 : loss : 0.019156, loss_ce: 0.009188
2021-12-03 00:28:29,115 Training Data Eval:
2021-12-03 00:28:36,537   Average segmentation loss on training set: 0.0148
2021-12-03 00:28:36,537 Validation Data Eval:
2021-12-03 00:28:39,122   Average segmentation loss on validation set: 0.0999
2021-12-03 00:28:40,641 iteration 4335 : loss : 0.035376, loss_ce: 0.010445
 64%|█████████████████▏         | 255/400 [1:55:34<1:09:27, 28.74s/it]2021-12-03 00:28:42,074 iteration 4336 : loss : 0.016243, loss_ce: 0.008395
2021-12-03 00:28:43,605 iteration 4337 : loss : 0.024760, loss_ce: 0.010420
2021-12-03 00:28:45,055 iteration 4338 : loss : 0.027212, loss_ce: 0.009584
2021-12-03 00:28:46,469 iteration 4339 : loss : 0.023281, loss_ce: 0.007293
2021-12-03 00:28:47,965 iteration 4340 : loss : 0.026031, loss_ce: 0.011102
2021-12-03 00:28:49,385 iteration 4341 : loss : 0.016898, loss_ce: 0.005240
2021-12-03 00:28:50,887 iteration 4342 : loss : 0.024466, loss_ce: 0.007221
2021-12-03 00:28:52,386 iteration 4343 : loss : 0.019794, loss_ce: 0.006467
2021-12-03 00:28:53,879 iteration 4344 : loss : 0.024621, loss_ce: 0.012229
2021-12-03 00:28:55,425 iteration 4345 : loss : 0.025539, loss_ce: 0.011339
2021-12-03 00:28:56,843 iteration 4346 : loss : 0.023451, loss_ce: 0.006507
2021-12-03 00:28:58,307 iteration 4347 : loss : 0.021296, loss_ce: 0.009688
2021-12-03 00:28:59,733 iteration 4348 : loss : 0.016361, loss_ce: 0.007916
2021-12-03 00:29:01,120 iteration 4349 : loss : 0.019489, loss_ce: 0.005823
2021-12-03 00:29:02,513 iteration 4350 : loss : 0.021620, loss_ce: 0.007430
2021-12-03 00:29:04,043 iteration 4351 : loss : 0.031867, loss_ce: 0.010469
2021-12-03 00:29:05,503 iteration 4352 : loss : 0.022493, loss_ce: 0.010128
 64%|█████████████████▎         | 256/400 [1:55:59<1:06:11, 27.58s/it]2021-12-03 00:29:06,965 iteration 4353 : loss : 0.019188, loss_ce: 0.005745
2021-12-03 00:29:08,495 iteration 4354 : loss : 0.025341, loss_ce: 0.010923
2021-12-03 00:29:09,998 iteration 4355 : loss : 0.022066, loss_ce: 0.009756
2021-12-03 00:29:11,539 iteration 4356 : loss : 0.028081, loss_ce: 0.007018
2021-12-03 00:29:13,052 iteration 4357 : loss : 0.017754, loss_ce: 0.008016
2021-12-03 00:29:14,593 iteration 4358 : loss : 0.026400, loss_ce: 0.008883
2021-12-03 00:29:16,076 iteration 4359 : loss : 0.020316, loss_ce: 0.006525
2021-12-03 00:29:17,524 iteration 4360 : loss : 0.025902, loss_ce: 0.011202
2021-12-03 00:29:19,033 iteration 4361 : loss : 0.020483, loss_ce: 0.007507
2021-12-03 00:29:20,493 iteration 4362 : loss : 0.018468, loss_ce: 0.007722
2021-12-03 00:29:21,950 iteration 4363 : loss : 0.016715, loss_ce: 0.007004
2021-12-03 00:29:23,440 iteration 4364 : loss : 0.018849, loss_ce: 0.007100
2021-12-03 00:29:24,984 iteration 4365 : loss : 0.026802, loss_ce: 0.011291
2021-12-03 00:29:26,398 iteration 4366 : loss : 0.019322, loss_ce: 0.005248
2021-12-03 00:29:27,771 iteration 4367 : loss : 0.016941, loss_ce: 0.006883
2021-12-03 00:29:29,178 iteration 4368 : loss : 0.021344, loss_ce: 0.006844
2021-12-03 00:29:30,663 iteration 4369 : loss : 0.030000, loss_ce: 0.010561
 64%|█████████████████▎         | 257/400 [1:56:24<1:03:59, 26.85s/it]2021-12-03 00:29:32,195 iteration 4370 : loss : 0.020326, loss_ce: 0.007193
2021-12-03 00:29:33,678 iteration 4371 : loss : 0.022665, loss_ce: 0.011847
2021-12-03 00:29:35,172 iteration 4372 : loss : 0.028136, loss_ce: 0.011008
2021-12-03 00:29:36,658 iteration 4373 : loss : 0.018697, loss_ce: 0.008882
2021-12-03 00:29:38,152 iteration 4374 : loss : 0.018057, loss_ce: 0.006277
2021-12-03 00:29:39,653 iteration 4375 : loss : 0.025405, loss_ce: 0.011462
2021-12-03 00:29:41,114 iteration 4376 : loss : 0.020781, loss_ce: 0.006910
2021-12-03 00:29:42,572 iteration 4377 : loss : 0.018511, loss_ce: 0.004947
2021-12-03 00:29:43,985 iteration 4378 : loss : 0.016003, loss_ce: 0.005494
2021-12-03 00:29:45,402 iteration 4379 : loss : 0.016961, loss_ce: 0.005530
2021-12-03 00:29:46,796 iteration 4380 : loss : 0.017795, loss_ce: 0.005943
2021-12-03 00:29:48,296 iteration 4381 : loss : 0.028002, loss_ce: 0.009901
2021-12-03 00:29:49,752 iteration 4382 : loss : 0.020345, loss_ce: 0.004421
2021-12-03 00:29:51,188 iteration 4383 : loss : 0.019831, loss_ce: 0.005706
2021-12-03 00:29:52,701 iteration 4384 : loss : 0.019845, loss_ce: 0.008316
2021-12-03 00:29:54,201 iteration 4385 : loss : 0.031575, loss_ce: 0.010867
2021-12-03 00:29:55,622 iteration 4386 : loss : 0.019618, loss_ce: 0.008959
 64%|█████████████████▍         | 258/400 [1:56:49<1:02:12, 26.29s/it]2021-12-03 00:29:57,098 iteration 4387 : loss : 0.020999, loss_ce: 0.006618
2021-12-03 00:29:58,574 iteration 4388 : loss : 0.025008, loss_ce: 0.010697
2021-12-03 00:30:00,039 iteration 4389 : loss : 0.022777, loss_ce: 0.007370
2021-12-03 00:30:01,449 iteration 4390 : loss : 0.017759, loss_ce: 0.005612
2021-12-03 00:30:02,919 iteration 4391 : loss : 0.027380, loss_ce: 0.008057
2021-12-03 00:30:04,374 iteration 4392 : loss : 0.020801, loss_ce: 0.006095
2021-12-03 00:30:05,905 iteration 4393 : loss : 0.024701, loss_ce: 0.012094
2021-12-03 00:30:07,395 iteration 4394 : loss : 0.020932, loss_ce: 0.007798
2021-12-03 00:30:08,949 iteration 4395 : loss : 0.023948, loss_ce: 0.009341
2021-12-03 00:30:10,392 iteration 4396 : loss : 0.019309, loss_ce: 0.006587
2021-12-03 00:30:11,954 iteration 4397 : loss : 0.025595, loss_ce: 0.013273
2021-12-03 00:30:13,364 iteration 4398 : loss : 0.019831, loss_ce: 0.008643
2021-12-03 00:30:14,867 iteration 4399 : loss : 0.022882, loss_ce: 0.008739
2021-12-03 00:30:16,343 iteration 4400 : loss : 0.028405, loss_ce: 0.008922
2021-12-03 00:30:17,934 iteration 4401 : loss : 0.029036, loss_ce: 0.011342
2021-12-03 00:30:19,404 iteration 4402 : loss : 0.022295, loss_ce: 0.007014
2021-12-03 00:30:20,894 iteration 4403 : loss : 0.023063, loss_ce: 0.008057
 65%|█████████████████▍         | 259/400 [1:57:15<1:01:03, 25.98s/it]2021-12-03 00:30:22,375 iteration 4404 : loss : 0.021547, loss_ce: 0.008801
2021-12-03 00:30:23,885 iteration 4405 : loss : 0.020622, loss_ce: 0.008516
2021-12-03 00:30:25,369 iteration 4406 : loss : 0.019303, loss_ce: 0.007779
2021-12-03 00:30:26,900 iteration 4407 : loss : 0.028047, loss_ce: 0.010902
2021-12-03 00:30:28,335 iteration 4408 : loss : 0.018312, loss_ce: 0.007471
2021-12-03 00:30:29,829 iteration 4409 : loss : 0.021797, loss_ce: 0.007708
2021-12-03 00:30:31,430 iteration 4410 : loss : 0.022908, loss_ce: 0.008004
2021-12-03 00:30:32,932 iteration 4411 : loss : 0.025819, loss_ce: 0.013381
2021-12-03 00:30:34,402 iteration 4412 : loss : 0.023103, loss_ce: 0.008800
2021-12-03 00:30:35,884 iteration 4413 : loss : 0.017036, loss_ce: 0.005461
2021-12-03 00:30:37,290 iteration 4414 : loss : 0.017973, loss_ce: 0.005507
2021-12-03 00:30:38,798 iteration 4415 : loss : 0.018825, loss_ce: 0.007022
2021-12-03 00:30:40,322 iteration 4416 : loss : 0.029023, loss_ce: 0.009423
2021-12-03 00:30:41,786 iteration 4417 : loss : 0.014871, loss_ce: 0.004619
2021-12-03 00:30:43,264 iteration 4418 : loss : 0.018569, loss_ce: 0.007965
2021-12-03 00:30:44,774 iteration 4419 : loss : 0.018312, loss_ce: 0.005303
2021-12-03 00:30:44,774 Training Data Eval:
2021-12-03 00:30:52,213   Average segmentation loss on training set: 0.0163
2021-12-03 00:30:52,214 Validation Data Eval:
2021-12-03 00:30:54,772   Average segmentation loss on validation set: 0.0761
2021-12-03 00:30:56,226 iteration 4420 : loss : 0.016011, loss_ce: 0.006197
 65%|█████████████████▌         | 260/400 [1:57:50<1:07:10, 28.79s/it]2021-12-03 00:30:57,751 iteration 4421 : loss : 0.017872, loss_ce: 0.005581
2021-12-03 00:30:59,248 iteration 4422 : loss : 0.026798, loss_ce: 0.012111
2021-12-03 00:31:00,789 iteration 4423 : loss : 0.029736, loss_ce: 0.011022
2021-12-03 00:31:02,211 iteration 4424 : loss : 0.017238, loss_ce: 0.005387
2021-12-03 00:31:03,630 iteration 4425 : loss : 0.016769, loss_ce: 0.005716
2021-12-03 00:31:05,166 iteration 4426 : loss : 0.016753, loss_ce: 0.006749
2021-12-03 00:31:06,578 iteration 4427 : loss : 0.016279, loss_ce: 0.007786
2021-12-03 00:31:07,958 iteration 4428 : loss : 0.013727, loss_ce: 0.006331
2021-12-03 00:31:09,362 iteration 4429 : loss : 0.019221, loss_ce: 0.006289
2021-12-03 00:31:10,779 iteration 4430 : loss : 0.019793, loss_ce: 0.009686
2021-12-03 00:31:12,260 iteration 4431 : loss : 0.026775, loss_ce: 0.012877
2021-12-03 00:31:13,763 iteration 4432 : loss : 0.022125, loss_ce: 0.007613
2021-12-03 00:31:15,207 iteration 4433 : loss : 0.020315, loss_ce: 0.005397
2021-12-03 00:31:16,625 iteration 4434 : loss : 0.014230, loss_ce: 0.005776
2021-12-03 00:31:18,098 iteration 4435 : loss : 0.021785, loss_ce: 0.004362
2021-12-03 00:31:19,558 iteration 4436 : loss : 0.019884, loss_ce: 0.008997
2021-12-03 00:31:21,077 iteration 4437 : loss : 0.022638, loss_ce: 0.009088
 65%|█████████████████▌         | 261/400 [1:58:15<1:03:57, 27.61s/it]2021-12-03 00:31:22,648 iteration 4438 : loss : 0.030384, loss_ce: 0.007261
2021-12-03 00:31:24,129 iteration 4439 : loss : 0.017966, loss_ce: 0.006866
2021-12-03 00:31:25,604 iteration 4440 : loss : 0.018931, loss_ce: 0.006277
2021-12-03 00:31:27,166 iteration 4441 : loss : 0.018998, loss_ce: 0.005187
2021-12-03 00:31:28,681 iteration 4442 : loss : 0.018617, loss_ce: 0.008350
2021-12-03 00:31:30,142 iteration 4443 : loss : 0.050564, loss_ce: 0.015831
2021-12-03 00:31:31,533 iteration 4444 : loss : 0.019932, loss_ce: 0.005815
2021-12-03 00:31:32,987 iteration 4445 : loss : 0.023623, loss_ce: 0.010090
2021-12-03 00:31:34,489 iteration 4446 : loss : 0.020495, loss_ce: 0.008140
2021-12-03 00:31:35,951 iteration 4447 : loss : 0.021655, loss_ce: 0.007374
2021-12-03 00:31:37,443 iteration 4448 : loss : 0.028970, loss_ce: 0.010492
2021-12-03 00:31:38,901 iteration 4449 : loss : 0.023068, loss_ce: 0.010808
2021-12-03 00:31:40,427 iteration 4450 : loss : 0.019286, loss_ce: 0.005820
2021-12-03 00:31:41,882 iteration 4451 : loss : 0.019695, loss_ce: 0.006975
2021-12-03 00:31:43,380 iteration 4452 : loss : 0.020625, loss_ce: 0.008675
2021-12-03 00:31:44,825 iteration 4453 : loss : 0.018243, loss_ce: 0.006286
2021-12-03 00:31:46,260 iteration 4454 : loss : 0.023065, loss_ce: 0.008723
 66%|█████████████████▋         | 262/400 [1:58:40<1:01:49, 26.88s/it]2021-12-03 00:31:47,795 iteration 4455 : loss : 0.015251, loss_ce: 0.004097
2021-12-03 00:31:49,199 iteration 4456 : loss : 0.019903, loss_ce: 0.007680
2021-12-03 00:31:50,696 iteration 4457 : loss : 0.020651, loss_ce: 0.007541
2021-12-03 00:31:52,255 iteration 4458 : loss : 0.036685, loss_ce: 0.015440
2021-12-03 00:31:53,871 iteration 4459 : loss : 0.022252, loss_ce: 0.009636
2021-12-03 00:31:55,301 iteration 4460 : loss : 0.022044, loss_ce: 0.007420
2021-12-03 00:31:56,772 iteration 4461 : loss : 0.029263, loss_ce: 0.010546
2021-12-03 00:31:58,336 iteration 4462 : loss : 0.026437, loss_ce: 0.011816
2021-12-03 00:31:59,828 iteration 4463 : loss : 0.024642, loss_ce: 0.010130
2021-12-03 00:32:01,293 iteration 4464 : loss : 0.018418, loss_ce: 0.006144
2021-12-03 00:32:02,702 iteration 4465 : loss : 0.024245, loss_ce: 0.005489
2021-12-03 00:32:04,154 iteration 4466 : loss : 0.017526, loss_ce: 0.004564
2021-12-03 00:32:05,651 iteration 4467 : loss : 0.050004, loss_ce: 0.024723
2021-12-03 00:32:07,198 iteration 4468 : loss : 0.026170, loss_ce: 0.011807
2021-12-03 00:32:08,785 iteration 4469 : loss : 0.022981, loss_ce: 0.010343
2021-12-03 00:32:10,343 iteration 4470 : loss : 0.021158, loss_ce: 0.008646
2021-12-03 00:32:11,937 iteration 4471 : loss : 0.031825, loss_ce: 0.012425
 66%|█████████████████▊         | 263/400 [1:59:06<1:00:32, 26.52s/it]2021-12-03 00:32:13,451 iteration 4472 : loss : 0.018572, loss_ce: 0.006954
2021-12-03 00:32:14,911 iteration 4473 : loss : 0.022194, loss_ce: 0.008812
2021-12-03 00:32:16,420 iteration 4474 : loss : 0.015769, loss_ce: 0.007275
2021-12-03 00:32:17,873 iteration 4475 : loss : 0.021908, loss_ce: 0.006235
2021-12-03 00:32:19,303 iteration 4476 : loss : 0.020484, loss_ce: 0.005869
2021-12-03 00:32:20,784 iteration 4477 : loss : 0.019997, loss_ce: 0.008828
2021-12-03 00:32:22,420 iteration 4478 : loss : 0.022816, loss_ce: 0.011085
2021-12-03 00:32:23,917 iteration 4479 : loss : 0.022639, loss_ce: 0.006319
2021-12-03 00:32:25,442 iteration 4480 : loss : 0.021571, loss_ce: 0.007560
2021-12-03 00:32:26,888 iteration 4481 : loss : 0.019219, loss_ce: 0.006771
2021-12-03 00:32:28,316 iteration 4482 : loss : 0.019441, loss_ce: 0.005612
2021-12-03 00:32:29,776 iteration 4483 : loss : 0.018678, loss_ce: 0.006789
2021-12-03 00:32:31,281 iteration 4484 : loss : 0.014416, loss_ce: 0.004544
2021-12-03 00:32:32,711 iteration 4485 : loss : 0.018447, loss_ce: 0.008319
2021-12-03 00:32:34,269 iteration 4486 : loss : 0.017432, loss_ce: 0.006862
2021-12-03 00:32:35,805 iteration 4487 : loss : 0.028094, loss_ce: 0.014681
2021-12-03 00:32:37,252 iteration 4488 : loss : 0.017991, loss_ce: 0.007045
 66%|███████████████████▏         | 264/400 [1:59:31<59:17, 26.16s/it]2021-12-03 00:32:38,853 iteration 4489 : loss : 0.020251, loss_ce: 0.009189
2021-12-03 00:32:40,305 iteration 4490 : loss : 0.021958, loss_ce: 0.010430
2021-12-03 00:32:41,890 iteration 4491 : loss : 0.027631, loss_ce: 0.011146
2021-12-03 00:32:43,356 iteration 4492 : loss : 0.020952, loss_ce: 0.005691
2021-12-03 00:32:44,956 iteration 4493 : loss : 0.027533, loss_ce: 0.018776
2021-12-03 00:32:46,423 iteration 4494 : loss : 0.022451, loss_ce: 0.007202
2021-12-03 00:32:47,946 iteration 4495 : loss : 0.027413, loss_ce: 0.006721
2021-12-03 00:32:49,456 iteration 4496 : loss : 0.022357, loss_ce: 0.005923
2021-12-03 00:32:50,836 iteration 4497 : loss : 0.021837, loss_ce: 0.009636
2021-12-03 00:32:52,333 iteration 4498 : loss : 0.020422, loss_ce: 0.006681
2021-12-03 00:32:53,797 iteration 4499 : loss : 0.017854, loss_ce: 0.007133
2021-12-03 00:32:55,286 iteration 4500 : loss : 0.024006, loss_ce: 0.008301
2021-12-03 00:32:56,741 iteration 4501 : loss : 0.017377, loss_ce: 0.006828
2021-12-03 00:32:58,225 iteration 4502 : loss : 0.019922, loss_ce: 0.006822
2021-12-03 00:32:59,803 iteration 4503 : loss : 0.021110, loss_ce: 0.007484
2021-12-03 00:33:01,203 iteration 4504 : loss : 0.017635, loss_ce: 0.006891
2021-12-03 00:33:01,203 Training Data Eval:
2021-12-03 00:33:08,647   Average segmentation loss on training set: 0.0137
2021-12-03 00:33:08,647 Validation Data Eval:
2021-12-03 00:33:11,229   Average segmentation loss on validation set: 0.0647
2021-12-03 00:33:12,760 iteration 4505 : loss : 0.019011, loss_ce: 0.006755
 66%|█████████████████▉         | 265/400 [2:00:06<1:05:10, 28.96s/it]2021-12-03 00:33:14,346 iteration 4506 : loss : 0.022333, loss_ce: 0.008499
2021-12-03 00:33:15,912 iteration 4507 : loss : 0.029131, loss_ce: 0.011407
2021-12-03 00:33:17,432 iteration 4508 : loss : 0.018773, loss_ce: 0.006062
2021-12-03 00:33:18,863 iteration 4509 : loss : 0.015084, loss_ce: 0.005086
2021-12-03 00:33:20,385 iteration 4510 : loss : 0.017309, loss_ce: 0.005757
2021-12-03 00:33:22,010 iteration 4511 : loss : 0.027625, loss_ce: 0.013412
2021-12-03 00:33:23,417 iteration 4512 : loss : 0.017279, loss_ce: 0.005856
2021-12-03 00:33:24,870 iteration 4513 : loss : 0.017689, loss_ce: 0.005928
2021-12-03 00:33:26,319 iteration 4514 : loss : 0.020067, loss_ce: 0.007460
2021-12-03 00:33:27,817 iteration 4515 : loss : 0.021154, loss_ce: 0.007900
2021-12-03 00:33:29,334 iteration 4516 : loss : 0.019994, loss_ce: 0.009322
2021-12-03 00:33:30,877 iteration 4517 : loss : 0.019057, loss_ce: 0.006962
2021-12-03 00:33:32,365 iteration 4518 : loss : 0.021330, loss_ce: 0.009587
2021-12-03 00:33:33,789 iteration 4519 : loss : 0.031261, loss_ce: 0.009375
2021-12-03 00:33:35,312 iteration 4520 : loss : 0.021738, loss_ce: 0.007457
2021-12-03 00:33:36,828 iteration 4521 : loss : 0.016759, loss_ce: 0.006959
2021-12-03 00:33:38,382 iteration 4522 : loss : 0.026036, loss_ce: 0.007985
 66%|█████████████████▉         | 266/400 [2:00:32<1:02:27, 27.96s/it]2021-12-03 00:33:40,010 iteration 4523 : loss : 0.023165, loss_ce: 0.010424
2021-12-03 00:33:41,530 iteration 4524 : loss : 0.024986, loss_ce: 0.008738
2021-12-03 00:33:43,081 iteration 4525 : loss : 0.022989, loss_ce: 0.010161
2021-12-03 00:33:44,602 iteration 4526 : loss : 0.021878, loss_ce: 0.005942
2021-12-03 00:33:46,045 iteration 4527 : loss : 0.018376, loss_ce: 0.006058
2021-12-03 00:33:47,489 iteration 4528 : loss : 0.018540, loss_ce: 0.005733
2021-12-03 00:33:48,980 iteration 4529 : loss : 0.020135, loss_ce: 0.007996
2021-12-03 00:33:50,433 iteration 4530 : loss : 0.023055, loss_ce: 0.006242
2021-12-03 00:33:51,945 iteration 4531 : loss : 0.023033, loss_ce: 0.008158
2021-12-03 00:33:53,491 iteration 4532 : loss : 0.016279, loss_ce: 0.005283
2021-12-03 00:33:54,971 iteration 4533 : loss : 0.016684, loss_ce: 0.007164
2021-12-03 00:33:56,468 iteration 4534 : loss : 0.018196, loss_ce: 0.005224
2021-12-03 00:33:58,015 iteration 4535 : loss : 0.019262, loss_ce: 0.006541
2021-12-03 00:33:59,535 iteration 4536 : loss : 0.015409, loss_ce: 0.006216
2021-12-03 00:34:01,044 iteration 4537 : loss : 0.021808, loss_ce: 0.009519
2021-12-03 00:34:02,554 iteration 4538 : loss : 0.021790, loss_ce: 0.008043
2021-12-03 00:34:04,065 iteration 4539 : loss : 0.018652, loss_ce: 0.006963
 67%|██████████████████         | 267/400 [2:00:58<1:00:28, 27.28s/it]2021-12-03 00:34:05,593 iteration 4540 : loss : 0.014126, loss_ce: 0.005024
2021-12-03 00:34:07,155 iteration 4541 : loss : 0.023107, loss_ce: 0.013542
2021-12-03 00:34:08,619 iteration 4542 : loss : 0.019749, loss_ce: 0.006731
2021-12-03 00:34:10,099 iteration 4543 : loss : 0.018734, loss_ce: 0.006232
2021-12-03 00:34:11,537 iteration 4544 : loss : 0.018933, loss_ce: 0.005986
2021-12-03 00:34:13,084 iteration 4545 : loss : 0.021613, loss_ce: 0.008404
2021-12-03 00:34:14,733 iteration 4546 : loss : 0.025360, loss_ce: 0.010366
2021-12-03 00:34:16,366 iteration 4547 : loss : 0.022828, loss_ce: 0.008902
2021-12-03 00:34:17,833 iteration 4548 : loss : 0.017287, loss_ce: 0.006132
2021-12-03 00:34:19,321 iteration 4549 : loss : 0.017200, loss_ce: 0.004762
2021-12-03 00:34:20,866 iteration 4550 : loss : 0.019491, loss_ce: 0.006930
2021-12-03 00:34:22,428 iteration 4551 : loss : 0.024691, loss_ce: 0.010092
2021-12-03 00:34:24,065 iteration 4552 : loss : 0.034957, loss_ce: 0.011906
2021-12-03 00:34:25,629 iteration 4553 : loss : 0.021610, loss_ce: 0.007014
2021-12-03 00:34:27,096 iteration 4554 : loss : 0.017453, loss_ce: 0.007537
2021-12-03 00:34:28,586 iteration 4555 : loss : 0.016359, loss_ce: 0.006528
2021-12-03 00:34:30,090 iteration 4556 : loss : 0.023159, loss_ce: 0.006270
 67%|███████████████████▍         | 268/400 [2:01:24<59:10, 26.90s/it]2021-12-03 00:34:31,632 iteration 4557 : loss : 0.014811, loss_ce: 0.005583
2021-12-03 00:34:33,183 iteration 4558 : loss : 0.023021, loss_ce: 0.008750
2021-12-03 00:34:34,758 iteration 4559 : loss : 0.020799, loss_ce: 0.008463
2021-12-03 00:34:36,289 iteration 4560 : loss : 0.016190, loss_ce: 0.008002
2021-12-03 00:34:37,757 iteration 4561 : loss : 0.015327, loss_ce: 0.004746
2021-12-03 00:34:39,282 iteration 4562 : loss : 0.020672, loss_ce: 0.008298
2021-12-03 00:34:40,780 iteration 4563 : loss : 0.019154, loss_ce: 0.006154
2021-12-03 00:34:42,286 iteration 4564 : loss : 0.014666, loss_ce: 0.006068
2021-12-03 00:34:43,811 iteration 4565 : loss : 0.027379, loss_ce: 0.010286
2021-12-03 00:34:45,363 iteration 4566 : loss : 0.019271, loss_ce: 0.007659
2021-12-03 00:34:46,894 iteration 4567 : loss : 0.019485, loss_ce: 0.007014
2021-12-03 00:34:48,361 iteration 4568 : loss : 0.014856, loss_ce: 0.004637
2021-12-03 00:34:49,848 iteration 4569 : loss : 0.023923, loss_ce: 0.008993
2021-12-03 00:34:51,354 iteration 4570 : loss : 0.016134, loss_ce: 0.005406
2021-12-03 00:34:52,922 iteration 4571 : loss : 0.026479, loss_ce: 0.011542
2021-12-03 00:34:54,481 iteration 4572 : loss : 0.023510, loss_ce: 0.007753
2021-12-03 00:34:56,043 iteration 4573 : loss : 0.023262, loss_ce: 0.006978
 67%|███████████████████▌         | 269/400 [2:01:50<58:06, 26.61s/it]2021-12-03 00:34:57,551 iteration 4574 : loss : 0.014450, loss_ce: 0.004561
2021-12-03 00:34:59,060 iteration 4575 : loss : 0.019855, loss_ce: 0.004644
2021-12-03 00:35:00,502 iteration 4576 : loss : 0.016670, loss_ce: 0.006450
2021-12-03 00:35:02,004 iteration 4577 : loss : 0.016632, loss_ce: 0.007730
2021-12-03 00:35:03,556 iteration 4578 : loss : 0.017462, loss_ce: 0.006430
2021-12-03 00:35:05,045 iteration 4579 : loss : 0.013994, loss_ce: 0.005971
2021-12-03 00:35:06,561 iteration 4580 : loss : 0.015601, loss_ce: 0.005788
2021-12-03 00:35:08,079 iteration 4581 : loss : 0.018689, loss_ce: 0.007393
2021-12-03 00:35:09,590 iteration 4582 : loss : 0.020600, loss_ce: 0.007091
2021-12-03 00:35:11,098 iteration 4583 : loss : 0.016969, loss_ce: 0.006733
2021-12-03 00:35:12,604 iteration 4584 : loss : 0.023744, loss_ce: 0.008213
2021-12-03 00:35:14,163 iteration 4585 : loss : 0.022336, loss_ce: 0.006889
2021-12-03 00:35:15,626 iteration 4586 : loss : 0.015549, loss_ce: 0.006327
2021-12-03 00:35:17,128 iteration 4587 : loss : 0.016863, loss_ce: 0.005033
2021-12-03 00:35:18,635 iteration 4588 : loss : 0.020058, loss_ce: 0.006884
2021-12-03 00:35:20,204 iteration 4589 : loss : 0.025382, loss_ce: 0.009002
2021-12-03 00:35:20,204 Training Data Eval:
2021-12-03 00:35:27,784   Average segmentation loss on training set: 0.0134
2021-12-03 00:35:27,784 Validation Data Eval:
2021-12-03 00:35:30,421   Average segmentation loss on validation set: 0.0697
2021-12-03 00:35:31,966 iteration 4590 : loss : 0.016728, loss_ce: 0.006834
 68%|██████████████████▏        | 270/400 [2:02:26<1:03:43, 29.41s/it]2021-12-03 00:35:33,567 iteration 4591 : loss : 0.029129, loss_ce: 0.007043
2021-12-03 00:35:35,142 iteration 4592 : loss : 0.023127, loss_ce: 0.007662
2021-12-03 00:35:36,698 iteration 4593 : loss : 0.019027, loss_ce: 0.008445
2021-12-03 00:35:38,293 iteration 4594 : loss : 0.034163, loss_ce: 0.009892
2021-12-03 00:35:39,803 iteration 4595 : loss : 0.020049, loss_ce: 0.006560
2021-12-03 00:35:41,321 iteration 4596 : loss : 0.019523, loss_ce: 0.005859
2021-12-03 00:35:42,891 iteration 4597 : loss : 0.015237, loss_ce: 0.006524
2021-12-03 00:35:44,488 iteration 4598 : loss : 0.025811, loss_ce: 0.008523
2021-12-03 00:35:46,026 iteration 4599 : loss : 0.017549, loss_ce: 0.007896
2021-12-03 00:35:47,548 iteration 4600 : loss : 0.019719, loss_ce: 0.006432
2021-12-03 00:35:49,097 iteration 4601 : loss : 0.021189, loss_ce: 0.009045
2021-12-03 00:35:50,756 iteration 4602 : loss : 0.042850, loss_ce: 0.012047
2021-12-03 00:35:52,311 iteration 4603 : loss : 0.019088, loss_ce: 0.006421
2021-12-03 00:35:53,869 iteration 4604 : loss : 0.023792, loss_ce: 0.011858
2021-12-03 00:35:55,467 iteration 4605 : loss : 0.055434, loss_ce: 0.012353
2021-12-03 00:35:57,049 iteration 4606 : loss : 0.019235, loss_ce: 0.007322
2021-12-03 00:35:58,643 iteration 4607 : loss : 0.018406, loss_ce: 0.009933
 68%|██████████████████▎        | 271/400 [2:02:52<1:01:28, 28.59s/it]2021-12-03 00:36:00,176 iteration 4608 : loss : 0.017524, loss_ce: 0.006552
2021-12-03 00:36:01,735 iteration 4609 : loss : 0.028516, loss_ce: 0.012664
2021-12-03 00:36:03,216 iteration 4610 : loss : 0.025532, loss_ce: 0.009080
2021-12-03 00:36:04,699 iteration 4611 : loss : 0.024441, loss_ce: 0.010625
2021-12-03 00:36:06,156 iteration 4612 : loss : 0.018813, loss_ce: 0.005878
2021-12-03 00:36:07,688 iteration 4613 : loss : 0.021728, loss_ce: 0.007717
2021-12-03 00:36:09,178 iteration 4614 : loss : 0.022166, loss_ce: 0.011948
2021-12-03 00:36:10,701 iteration 4615 : loss : 0.022276, loss_ce: 0.008141
2021-12-03 00:36:12,350 iteration 4616 : loss : 0.026974, loss_ce: 0.010002
2021-12-03 00:36:13,887 iteration 4617 : loss : 0.028984, loss_ce: 0.012593
2021-12-03 00:36:15,363 iteration 4618 : loss : 0.017811, loss_ce: 0.005373
2021-12-03 00:36:16,871 iteration 4619 : loss : 0.016052, loss_ce: 0.006911
2021-12-03 00:36:18,485 iteration 4620 : loss : 0.024075, loss_ce: 0.007945
2021-12-03 00:36:20,022 iteration 4621 : loss : 0.026811, loss_ce: 0.017346
2021-12-03 00:36:21,567 iteration 4622 : loss : 0.029351, loss_ce: 0.012216
2021-12-03 00:36:23,102 iteration 4623 : loss : 0.017397, loss_ce: 0.005610
2021-12-03 00:36:24,666 iteration 4624 : loss : 0.016628, loss_ce: 0.007352
 68%|███████████████████▋         | 272/400 [2:03:18<59:20, 27.82s/it]2021-12-03 00:36:26,307 iteration 4625 : loss : 0.027223, loss_ce: 0.011983
2021-12-03 00:36:27,894 iteration 4626 : loss : 0.020881, loss_ce: 0.009310
2021-12-03 00:36:29,533 iteration 4627 : loss : 0.021501, loss_ce: 0.008847
2021-12-03 00:36:31,031 iteration 4628 : loss : 0.017668, loss_ce: 0.006300
2021-12-03 00:36:32,475 iteration 4629 : loss : 0.020308, loss_ce: 0.006754
2021-12-03 00:36:33,983 iteration 4630 : loss : 0.017639, loss_ce: 0.006486
2021-12-03 00:36:35,549 iteration 4631 : loss : 0.019145, loss_ce: 0.006721
2021-12-03 00:36:37,101 iteration 4632 : loss : 0.024828, loss_ce: 0.007990
2021-12-03 00:36:38,607 iteration 4633 : loss : 0.017227, loss_ce: 0.005840
2021-12-03 00:36:40,097 iteration 4634 : loss : 0.014862, loss_ce: 0.006566
2021-12-03 00:36:41,552 iteration 4635 : loss : 0.013378, loss_ce: 0.005105
2021-12-03 00:36:43,175 iteration 4636 : loss : 0.035041, loss_ce: 0.013377
2021-12-03 00:36:44,679 iteration 4637 : loss : 0.019737, loss_ce: 0.006046
2021-12-03 00:36:46,334 iteration 4638 : loss : 0.024406, loss_ce: 0.011622
2021-12-03 00:36:47,914 iteration 4639 : loss : 0.024237, loss_ce: 0.008676
2021-12-03 00:36:49,575 iteration 4640 : loss : 0.023102, loss_ce: 0.008228
2021-12-03 00:36:51,153 iteration 4641 : loss : 0.022282, loss_ce: 0.008031
 68%|███████████████████▊         | 273/400 [2:03:45<58:02, 27.42s/it]2021-12-03 00:36:52,708 iteration 4642 : loss : 0.034257, loss_ce: 0.007123
2021-12-03 00:36:54,206 iteration 4643 : loss : 0.025088, loss_ce: 0.008696
2021-12-03 00:36:55,747 iteration 4644 : loss : 0.021569, loss_ce: 0.006907
2021-12-03 00:36:57,322 iteration 4645 : loss : 0.028997, loss_ce: 0.013709
2021-12-03 00:36:58,908 iteration 4646 : loss : 0.022082, loss_ce: 0.006567
2021-12-03 00:37:00,385 iteration 4647 : loss : 0.020564, loss_ce: 0.006200
2021-12-03 00:37:01,899 iteration 4648 : loss : 0.039480, loss_ce: 0.012632
2021-12-03 00:37:03,459 iteration 4649 : loss : 0.019513, loss_ce: 0.008273
2021-12-03 00:37:05,073 iteration 4650 : loss : 0.026646, loss_ce: 0.007846
2021-12-03 00:37:06,568 iteration 4651 : loss : 0.016110, loss_ce: 0.006944
2021-12-03 00:37:08,195 iteration 4652 : loss : 0.025086, loss_ce: 0.008174
2021-12-03 00:37:09,711 iteration 4653 : loss : 0.024792, loss_ce: 0.011763
2021-12-03 00:37:11,242 iteration 4654 : loss : 0.019877, loss_ce: 0.005131
2021-12-03 00:37:12,848 iteration 4655 : loss : 0.026306, loss_ce: 0.010451
2021-12-03 00:37:14,499 iteration 4656 : loss : 0.028224, loss_ce: 0.012780
2021-12-03 00:37:16,130 iteration 4657 : loss : 0.029161, loss_ce: 0.012848
2021-12-03 00:37:17,722 iteration 4658 : loss : 0.028065, loss_ce: 0.009751
 68%|███████████████████▊         | 274/400 [2:04:11<57:02, 27.16s/it]2021-12-03 00:37:19,318 iteration 4659 : loss : 0.027011, loss_ce: 0.011590
2021-12-03 00:37:20,885 iteration 4660 : loss : 0.023580, loss_ce: 0.009659
2021-12-03 00:37:22,469 iteration 4661 : loss : 0.026343, loss_ce: 0.009362
2021-12-03 00:37:23,953 iteration 4662 : loss : 0.013954, loss_ce: 0.005173
2021-12-03 00:37:25,534 iteration 4663 : loss : 0.023005, loss_ce: 0.009037
2021-12-03 00:37:27,043 iteration 4664 : loss : 0.015015, loss_ce: 0.005486
2021-12-03 00:37:28,588 iteration 4665 : loss : 0.026742, loss_ce: 0.009425
2021-12-03 00:37:30,030 iteration 4666 : loss : 0.017854, loss_ce: 0.006739
2021-12-03 00:37:31,550 iteration 4667 : loss : 0.017563, loss_ce: 0.007040
2021-12-03 00:37:33,226 iteration 4668 : loss : 0.025857, loss_ce: 0.011923
2021-12-03 00:37:34,700 iteration 4669 : loss : 0.019552, loss_ce: 0.008590
2021-12-03 00:37:36,208 iteration 4670 : loss : 0.026441, loss_ce: 0.010112
2021-12-03 00:37:37,701 iteration 4671 : loss : 0.022814, loss_ce: 0.007065
2021-12-03 00:37:39,357 iteration 4672 : loss : 0.025548, loss_ce: 0.010421
2021-12-03 00:37:40,966 iteration 4673 : loss : 0.017945, loss_ce: 0.007220
2021-12-03 00:37:42,413 iteration 4674 : loss : 0.017535, loss_ce: 0.005023
2021-12-03 00:37:42,414 Training Data Eval:
2021-12-03 00:37:50,071   Average segmentation loss on training set: 0.0147
2021-12-03 00:37:50,072 Validation Data Eval:
2021-12-03 00:37:52,713   Average segmentation loss on validation set: 0.0687
2021-12-03 00:37:54,335 iteration 4675 : loss : 0.018653, loss_ce: 0.007036
 69%|██████████████████▌        | 275/400 [2:04:48<1:02:30, 30.00s/it]2021-12-03 00:37:56,080 iteration 4676 : loss : 0.035596, loss_ce: 0.011752
2021-12-03 00:37:57,615 iteration 4677 : loss : 0.020600, loss_ce: 0.007256
2021-12-03 00:37:59,178 iteration 4678 : loss : 0.023722, loss_ce: 0.006593
2021-12-03 00:38:00,806 iteration 4679 : loss : 0.036835, loss_ce: 0.008837
2021-12-03 00:38:02,338 iteration 4680 : loss : 0.019318, loss_ce: 0.007511
2021-12-03 00:38:03,868 iteration 4681 : loss : 0.032897, loss_ce: 0.009881
2021-12-03 00:38:05,363 iteration 4682 : loss : 0.020572, loss_ce: 0.007347
2021-12-03 00:38:06,800 iteration 4683 : loss : 0.020880, loss_ce: 0.006039
2021-12-03 00:38:08,414 iteration 4684 : loss : 0.027495, loss_ce: 0.012036
2021-12-03 00:38:10,002 iteration 4685 : loss : 0.028401, loss_ce: 0.008883
2021-12-03 00:38:11,546 iteration 4686 : loss : 0.026176, loss_ce: 0.007999
2021-12-03 00:38:13,060 iteration 4687 : loss : 0.018337, loss_ce: 0.007785
2021-12-03 00:38:14,529 iteration 4688 : loss : 0.016169, loss_ce: 0.007420
2021-12-03 00:38:16,014 iteration 4689 : loss : 0.012753, loss_ce: 0.005536
2021-12-03 00:38:17,519 iteration 4690 : loss : 0.023991, loss_ce: 0.008606
2021-12-03 00:38:19,113 iteration 4691 : loss : 0.032807, loss_ce: 0.017349
2021-12-03 00:38:20,620 iteration 4692 : loss : 0.021805, loss_ce: 0.006469
 69%|████████████████████         | 276/400 [2:05:14<59:41, 28.88s/it]2021-12-03 00:38:22,285 iteration 4693 : loss : 0.028346, loss_ce: 0.010067
2021-12-03 00:38:23,850 iteration 4694 : loss : 0.029972, loss_ce: 0.011092
2021-12-03 00:38:25,237 iteration 4695 : loss : 0.014624, loss_ce: 0.004758
2021-12-03 00:38:26,879 iteration 4696 : loss : 0.024624, loss_ce: 0.008476
2021-12-03 00:38:28,357 iteration 4697 : loss : 0.023195, loss_ce: 0.008222
2021-12-03 00:38:29,870 iteration 4698 : loss : 0.019880, loss_ce: 0.008734
2021-12-03 00:38:31,487 iteration 4699 : loss : 0.018790, loss_ce: 0.008743
2021-12-03 00:38:32,992 iteration 4700 : loss : 0.020583, loss_ce: 0.009277
2021-12-03 00:38:34,663 iteration 4701 : loss : 0.020918, loss_ce: 0.008654
2021-12-03 00:38:36,173 iteration 4702 : loss : 0.018688, loss_ce: 0.007740
2021-12-03 00:38:37,667 iteration 4703 : loss : 0.018217, loss_ce: 0.005022
2021-12-03 00:38:39,210 iteration 4704 : loss : 0.023058, loss_ce: 0.007818
2021-12-03 00:38:40,622 iteration 4705 : loss : 0.013566, loss_ce: 0.005703
2021-12-03 00:38:42,171 iteration 4706 : loss : 0.018700, loss_ce: 0.005228
2021-12-03 00:38:43,794 iteration 4707 : loss : 0.019370, loss_ce: 0.007588
2021-12-03 00:38:45,430 iteration 4708 : loss : 0.019774, loss_ce: 0.006323
2021-12-03 00:38:47,018 iteration 4709 : loss : 0.026472, loss_ce: 0.008369
 69%|████████████████████         | 277/400 [2:05:41<57:41, 28.14s/it]2021-12-03 00:38:48,641 iteration 4710 : loss : 0.021464, loss_ce: 0.004814
2021-12-03 00:38:50,328 iteration 4711 : loss : 0.028013, loss_ce: 0.010612
2021-12-03 00:38:51,815 iteration 4712 : loss : 0.023700, loss_ce: 0.009311
2021-12-03 00:38:53,315 iteration 4713 : loss : 0.016819, loss_ce: 0.006214
2021-12-03 00:38:54,862 iteration 4714 : loss : 0.019344, loss_ce: 0.006227
2021-12-03 00:38:56,473 iteration 4715 : loss : 0.027894, loss_ce: 0.009161
2021-12-03 00:38:58,057 iteration 4716 : loss : 0.021269, loss_ce: 0.008210
2021-12-03 00:38:59,607 iteration 4717 : loss : 0.018590, loss_ce: 0.006327
2021-12-03 00:39:01,090 iteration 4718 : loss : 0.015985, loss_ce: 0.005776
2021-12-03 00:39:02,572 iteration 4719 : loss : 0.018876, loss_ce: 0.008277
2021-12-03 00:39:04,078 iteration 4720 : loss : 0.017329, loss_ce: 0.006881
2021-12-03 00:39:05,607 iteration 4721 : loss : 0.017249, loss_ce: 0.006592
2021-12-03 00:39:07,207 iteration 4722 : loss : 0.021967, loss_ce: 0.007324
2021-12-03 00:39:08,743 iteration 4723 : loss : 0.014739, loss_ce: 0.005496
2021-12-03 00:39:10,225 iteration 4724 : loss : 0.013100, loss_ce: 0.004957
2021-12-03 00:39:11,712 iteration 4725 : loss : 0.018260, loss_ce: 0.007399
2021-12-03 00:39:13,256 iteration 4726 : loss : 0.019523, loss_ce: 0.007277
 70%|████████████████████▏        | 278/400 [2:06:07<56:03, 27.57s/it]2021-12-03 00:39:14,876 iteration 4727 : loss : 0.020359, loss_ce: 0.007201
2021-12-03 00:39:16,343 iteration 4728 : loss : 0.015243, loss_ce: 0.005652
2021-12-03 00:39:17,859 iteration 4729 : loss : 0.016291, loss_ce: 0.005596
2021-12-03 00:39:19,364 iteration 4730 : loss : 0.012810, loss_ce: 0.004233
2021-12-03 00:39:20,990 iteration 4731 : loss : 0.024830, loss_ce: 0.009305
2021-12-03 00:39:22,579 iteration 4732 : loss : 0.027679, loss_ce: 0.008956
2021-12-03 00:39:24,101 iteration 4733 : loss : 0.016932, loss_ce: 0.006474
2021-12-03 00:39:25,618 iteration 4734 : loss : 0.020654, loss_ce: 0.007759
2021-12-03 00:39:27,270 iteration 4735 : loss : 0.024103, loss_ce: 0.008147
2021-12-03 00:39:28,756 iteration 4736 : loss : 0.024112, loss_ce: 0.011133
2021-12-03 00:39:30,382 iteration 4737 : loss : 0.023364, loss_ce: 0.008709
2021-12-03 00:39:31,927 iteration 4738 : loss : 0.026018, loss_ce: 0.010505
2021-12-03 00:39:33,474 iteration 4739 : loss : 0.017809, loss_ce: 0.006680
2021-12-03 00:39:35,057 iteration 4740 : loss : 0.024867, loss_ce: 0.011612
2021-12-03 00:39:36,578 iteration 4741 : loss : 0.018989, loss_ce: 0.006177
2021-12-03 00:39:38,113 iteration 4742 : loss : 0.019118, loss_ce: 0.008704
2021-12-03 00:39:39,707 iteration 4743 : loss : 0.032817, loss_ce: 0.010809
 70%|████████████████████▏        | 279/400 [2:06:33<54:55, 27.24s/it]2021-12-03 00:39:41,352 iteration 4744 : loss : 0.025035, loss_ce: 0.009616
2021-12-03 00:39:42,874 iteration 4745 : loss : 0.023976, loss_ce: 0.007558
2021-12-03 00:39:44,351 iteration 4746 : loss : 0.018648, loss_ce: 0.009302
2021-12-03 00:39:45,862 iteration 4747 : loss : 0.020490, loss_ce: 0.006874
2021-12-03 00:39:47,414 iteration 4748 : loss : 0.017860, loss_ce: 0.006446
2021-12-03 00:39:48,976 iteration 4749 : loss : 0.033632, loss_ce: 0.012207
2021-12-03 00:39:50,597 iteration 4750 : loss : 0.021074, loss_ce: 0.007938
2021-12-03 00:39:52,123 iteration 4751 : loss : 0.028719, loss_ce: 0.011116
2021-12-03 00:39:53,700 iteration 4752 : loss : 0.015910, loss_ce: 0.005814
2021-12-03 00:39:55,291 iteration 4753 : loss : 0.017089, loss_ce: 0.005555
2021-12-03 00:39:56,843 iteration 4754 : loss : 0.017265, loss_ce: 0.005429
2021-12-03 00:39:58,502 iteration 4755 : loss : 0.017125, loss_ce: 0.005193
2021-12-03 00:40:00,026 iteration 4756 : loss : 0.017667, loss_ce: 0.008251
2021-12-03 00:40:01,574 iteration 4757 : loss : 0.026712, loss_ce: 0.010759
2021-12-03 00:40:03,088 iteration 4758 : loss : 0.019473, loss_ce: 0.006261
2021-12-03 00:40:04,640 iteration 4759 : loss : 0.016524, loss_ce: 0.005633
2021-12-03 00:40:04,641 Training Data Eval:
2021-12-03 00:40:12,300   Average segmentation loss on training set: 0.0128
2021-12-03 00:40:12,301 Validation Data Eval:
2021-12-03 00:40:14,936   Average segmentation loss on validation set: 0.0834
2021-12-03 00:40:16,458 iteration 4760 : loss : 0.017749, loss_ce: 0.007537
 70%|██████████████████▉        | 280/400 [2:07:10<1:00:10, 30.09s/it]2021-12-03 00:40:18,055 iteration 4761 : loss : 0.017466, loss_ce: 0.006402
2021-12-03 00:40:19,643 iteration 4762 : loss : 0.025614, loss_ce: 0.011846
2021-12-03 00:40:21,144 iteration 4763 : loss : 0.014471, loss_ce: 0.005816
2021-12-03 00:40:22,741 iteration 4764 : loss : 0.023601, loss_ce: 0.007688
2021-12-03 00:40:24,272 iteration 4765 : loss : 0.020457, loss_ce: 0.009241
2021-12-03 00:40:25,894 iteration 4766 : loss : 0.024557, loss_ce: 0.008942
2021-12-03 00:40:27,479 iteration 4767 : loss : 0.021639, loss_ce: 0.008080
2021-12-03 00:40:28,975 iteration 4768 : loss : 0.016848, loss_ce: 0.005329
2021-12-03 00:40:30,533 iteration 4769 : loss : 0.030853, loss_ce: 0.012822
2021-12-03 00:40:32,118 iteration 4770 : loss : 0.019545, loss_ce: 0.008027
2021-12-03 00:40:33,614 iteration 4771 : loss : 0.015527, loss_ce: 0.005110
2021-12-03 00:40:35,224 iteration 4772 : loss : 0.019466, loss_ce: 0.008091
2021-12-03 00:40:36,818 iteration 4773 : loss : 0.020927, loss_ce: 0.007377
2021-12-03 00:40:38,408 iteration 4774 : loss : 0.017735, loss_ce: 0.007127
2021-12-03 00:40:39,914 iteration 4775 : loss : 0.018804, loss_ce: 0.005745
2021-12-03 00:40:41,451 iteration 4776 : loss : 0.017293, loss_ce: 0.009439
2021-12-03 00:40:43,141 iteration 4777 : loss : 0.025838, loss_ce: 0.011973
 70%|████████████████████▎        | 281/400 [2:07:37<57:38, 29.07s/it]2021-12-03 00:40:44,661 iteration 4778 : loss : 0.014902, loss_ce: 0.004094
2021-12-03 00:40:46,186 iteration 4779 : loss : 0.022521, loss_ce: 0.007380
2021-12-03 00:40:47,652 iteration 4780 : loss : 0.014859, loss_ce: 0.005066
2021-12-03 00:40:49,185 iteration 4781 : loss : 0.020030, loss_ce: 0.006642
2021-12-03 00:40:50,798 iteration 4782 : loss : 0.021486, loss_ce: 0.009333
2021-12-03 00:40:52,323 iteration 4783 : loss : 0.014640, loss_ce: 0.006314
2021-12-03 00:40:53,773 iteration 4784 : loss : 0.014531, loss_ce: 0.005827
2021-12-03 00:40:55,352 iteration 4785 : loss : 0.020896, loss_ce: 0.007605
2021-12-03 00:40:56,936 iteration 4786 : loss : 0.024076, loss_ce: 0.011120
2021-12-03 00:40:58,527 iteration 4787 : loss : 0.021404, loss_ce: 0.006492
2021-12-03 00:41:00,127 iteration 4788 : loss : 0.019927, loss_ce: 0.006940
2021-12-03 00:41:01,612 iteration 4789 : loss : 0.015086, loss_ce: 0.007053
2021-12-03 00:41:03,270 iteration 4790 : loss : 0.028776, loss_ce: 0.010205
2021-12-03 00:41:04,800 iteration 4791 : loss : 0.029050, loss_ce: 0.014503
2021-12-03 00:41:06,412 iteration 4792 : loss : 0.037529, loss_ce: 0.009057
2021-12-03 00:41:07,908 iteration 4793 : loss : 0.015357, loss_ce: 0.005401
2021-12-03 00:41:09,362 iteration 4794 : loss : 0.016456, loss_ce: 0.004674
 70%|████████████████████▍        | 282/400 [2:08:03<55:28, 28.21s/it]2021-12-03 00:41:10,992 iteration 4795 : loss : 0.022685, loss_ce: 0.007332
2021-12-03 00:41:12,569 iteration 4796 : loss : 0.013748, loss_ce: 0.004527
2021-12-03 00:41:14,146 iteration 4797 : loss : 0.025304, loss_ce: 0.010364
2021-12-03 00:41:15,780 iteration 4798 : loss : 0.030108, loss_ce: 0.008076
2021-12-03 00:41:17,304 iteration 4799 : loss : 0.015375, loss_ce: 0.004795
2021-12-03 00:41:18,832 iteration 4800 : loss : 0.021865, loss_ce: 0.006780
2021-12-03 00:41:20,486 iteration 4801 : loss : 0.019658, loss_ce: 0.007246
2021-12-03 00:41:21,961 iteration 4802 : loss : 0.016175, loss_ce: 0.006561
2021-12-03 00:41:23,483 iteration 4803 : loss : 0.019654, loss_ce: 0.009189
2021-12-03 00:41:25,131 iteration 4804 : loss : 0.058488, loss_ce: 0.010939
2021-12-03 00:41:26,759 iteration 4805 : loss : 0.024580, loss_ce: 0.008928
2021-12-03 00:41:28,402 iteration 4806 : loss : 0.022206, loss_ce: 0.009167
2021-12-03 00:41:29,898 iteration 4807 : loss : 0.027758, loss_ce: 0.012495
2021-12-03 00:41:31,372 iteration 4808 : loss : 0.018165, loss_ce: 0.007441
2021-12-03 00:41:32,946 iteration 4809 : loss : 0.027429, loss_ce: 0.013452
2021-12-03 00:41:34,504 iteration 4810 : loss : 0.022069, loss_ce: 0.005211
2021-12-03 00:41:36,077 iteration 4811 : loss : 0.019468, loss_ce: 0.008100
 71%|████████████████████▌        | 283/400 [2:08:30<54:08, 27.76s/it]2021-12-03 00:41:37,640 iteration 4812 : loss : 0.017378, loss_ce: 0.007010
2021-12-03 00:41:39,219 iteration 4813 : loss : 0.020855, loss_ce: 0.005843
2021-12-03 00:41:40,767 iteration 4814 : loss : 0.056784, loss_ce: 0.013712
2021-12-03 00:41:42,252 iteration 4815 : loss : 0.018575, loss_ce: 0.007647
2021-12-03 00:41:43,933 iteration 4816 : loss : 0.021201, loss_ce: 0.009160
2021-12-03 00:41:45,470 iteration 4817 : loss : 0.025909, loss_ce: 0.010521
2021-12-03 00:41:46,986 iteration 4818 : loss : 0.019036, loss_ce: 0.006233
2021-12-03 00:41:48,440 iteration 4819 : loss : 0.022082, loss_ce: 0.007753
2021-12-03 00:41:49,962 iteration 4820 : loss : 0.022055, loss_ce: 0.008525
2021-12-03 00:41:51,629 iteration 4821 : loss : 0.024541, loss_ce: 0.011044
2021-12-03 00:41:53,263 iteration 4822 : loss : 0.020344, loss_ce: 0.006684
2021-12-03 00:41:54,807 iteration 4823 : loss : 0.021010, loss_ce: 0.009094
2021-12-03 00:41:56,356 iteration 4824 : loss : 0.028265, loss_ce: 0.011250
2021-12-03 00:41:57,855 iteration 4825 : loss : 0.023330, loss_ce: 0.008309
2021-12-03 00:41:59,374 iteration 4826 : loss : 0.020017, loss_ce: 0.006021
2021-12-03 00:42:00,913 iteration 4827 : loss : 0.016463, loss_ce: 0.006133
2021-12-03 00:42:02,433 iteration 4828 : loss : 0.017725, loss_ce: 0.006810
 71%|████████████████████▌        | 284/400 [2:08:56<52:51, 27.34s/it]2021-12-03 00:42:03,991 iteration 4829 : loss : 0.019746, loss_ce: 0.006490
2021-12-03 00:42:05,590 iteration 4830 : loss : 0.020125, loss_ce: 0.009559
2021-12-03 00:42:07,157 iteration 4831 : loss : 0.020934, loss_ce: 0.007843
2021-12-03 00:42:08,678 iteration 4832 : loss : 0.028199, loss_ce: 0.008265
2021-12-03 00:42:10,239 iteration 4833 : loss : 0.024805, loss_ce: 0.008969
2021-12-03 00:42:11,732 iteration 4834 : loss : 0.015803, loss_ce: 0.005319
2021-12-03 00:42:13,402 iteration 4835 : loss : 0.024202, loss_ce: 0.011446
2021-12-03 00:42:14,961 iteration 4836 : loss : 0.018575, loss_ce: 0.005671
2021-12-03 00:42:16,602 iteration 4837 : loss : 0.021361, loss_ce: 0.006220
2021-12-03 00:42:18,112 iteration 4838 : loss : 0.015034, loss_ce: 0.004535
2021-12-03 00:42:19,685 iteration 4839 : loss : 0.032771, loss_ce: 0.014086
2021-12-03 00:42:21,233 iteration 4840 : loss : 0.021586, loss_ce: 0.009786
2021-12-03 00:42:22,708 iteration 4841 : loss : 0.015247, loss_ce: 0.004670
2021-12-03 00:42:24,282 iteration 4842 : loss : 0.015624, loss_ce: 0.005359
2021-12-03 00:42:25,930 iteration 4843 : loss : 0.019992, loss_ce: 0.006736
2021-12-03 00:42:27,486 iteration 4844 : loss : 0.020661, loss_ce: 0.007624
2021-12-03 00:42:27,487 Training Data Eval:
2021-12-03 00:42:35,133   Average segmentation loss on training set: 0.0120
2021-12-03 00:42:35,134 Validation Data Eval:
2021-12-03 00:42:37,777   Average segmentation loss on validation set: 0.0595
2021-12-03 00:42:39,928 Found new lowest validation loss at iteration 4844! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/UNET_RUNMC/1channel_best_val_loss.pth
2021-12-03 00:42:41,482 iteration 4845 : loss : 0.027543, loss_ce: 0.012691
 71%|████████████████████▋        | 285/400 [2:09:35<59:08, 30.86s/it]2021-12-03 00:42:42,952 iteration 4846 : loss : 0.020452, loss_ce: 0.008778
2021-12-03 00:42:44,351 iteration 4847 : loss : 0.017228, loss_ce: 0.005872
2021-12-03 00:42:45,889 iteration 4848 : loss : 0.025183, loss_ce: 0.012245
2021-12-03 00:42:47,454 iteration 4849 : loss : 0.018527, loss_ce: 0.004540
2021-12-03 00:42:48,974 iteration 4850 : loss : 0.017276, loss_ce: 0.004792
2021-12-03 00:42:50,689 iteration 4851 : loss : 0.019436, loss_ce: 0.007981
2021-12-03 00:42:52,225 iteration 4852 : loss : 0.019973, loss_ce: 0.007113
2021-12-03 00:42:53,764 iteration 4853 : loss : 0.018074, loss_ce: 0.007889
2021-12-03 00:42:55,296 iteration 4854 : loss : 0.018289, loss_ce: 0.006939
2021-12-03 00:42:56,802 iteration 4855 : loss : 0.024961, loss_ce: 0.006644
2021-12-03 00:42:58,471 iteration 4856 : loss : 0.027233, loss_ce: 0.010836
2021-12-03 00:42:59,973 iteration 4857 : loss : 0.015154, loss_ce: 0.005510
2021-12-03 00:43:01,607 iteration 4858 : loss : 0.016038, loss_ce: 0.005243
2021-12-03 00:43:03,092 iteration 4859 : loss : 0.012408, loss_ce: 0.004823
2021-12-03 00:43:04,700 iteration 4860 : loss : 0.024543, loss_ce: 0.010732
2021-12-03 00:43:06,234 iteration 4861 : loss : 0.017918, loss_ce: 0.006026
2021-12-03 00:43:07,841 iteration 4862 : loss : 0.019862, loss_ce: 0.008814
 72%|████████████████████▋        | 286/400 [2:10:01<56:03, 29.50s/it]2021-12-03 00:43:09,528 iteration 4863 : loss : 0.026500, loss_ce: 0.007139
2021-12-03 00:43:11,071 iteration 4864 : loss : 0.015675, loss_ce: 0.005588
2021-12-03 00:43:12,605 iteration 4865 : loss : 0.019064, loss_ce: 0.010667
2021-12-03 00:43:14,230 iteration 4866 : loss : 0.019395, loss_ce: 0.006418
2021-12-03 00:43:15,805 iteration 4867 : loss : 0.023892, loss_ce: 0.009069
2021-12-03 00:43:17,238 iteration 4868 : loss : 0.015035, loss_ce: 0.006324
2021-12-03 00:43:18,857 iteration 4869 : loss : 0.020587, loss_ce: 0.009507
2021-12-03 00:43:20,404 iteration 4870 : loss : 0.021980, loss_ce: 0.006936
2021-12-03 00:43:22,081 iteration 4871 : loss : 0.021682, loss_ce: 0.008782
2021-12-03 00:43:23,562 iteration 4872 : loss : 0.012860, loss_ce: 0.003805
2021-12-03 00:43:25,233 iteration 4873 : loss : 0.020643, loss_ce: 0.008776
2021-12-03 00:43:26,841 iteration 4874 : loss : 0.025247, loss_ce: 0.008469
2021-12-03 00:43:28,376 iteration 4875 : loss : 0.022384, loss_ce: 0.008477
2021-12-03 00:43:29,831 iteration 4876 : loss : 0.021118, loss_ce: 0.006065
2021-12-03 00:43:31,429 iteration 4877 : loss : 0.024031, loss_ce: 0.013206
2021-12-03 00:43:33,046 iteration 4878 : loss : 0.037639, loss_ce: 0.011134
2021-12-03 00:43:34,585 iteration 4879 : loss : 0.013737, loss_ce: 0.004671
 72%|████████████████████▊        | 287/400 [2:10:28<54:00, 28.67s/it]2021-12-03 00:43:36,175 iteration 4880 : loss : 0.029356, loss_ce: 0.014148
2021-12-03 00:43:37,670 iteration 4881 : loss : 0.018621, loss_ce: 0.007408
2021-12-03 00:43:39,138 iteration 4882 : loss : 0.014505, loss_ce: 0.006219
2021-12-03 00:43:40,686 iteration 4883 : loss : 0.018216, loss_ce: 0.007217
2021-12-03 00:43:42,258 iteration 4884 : loss : 0.019679, loss_ce: 0.005871
2021-12-03 00:43:43,692 iteration 4885 : loss : 0.016779, loss_ce: 0.006501
2021-12-03 00:43:45,242 iteration 4886 : loss : 0.019226, loss_ce: 0.005199
2021-12-03 00:43:46,733 iteration 4887 : loss : 0.017250, loss_ce: 0.006407
2021-12-03 00:43:48,305 iteration 4888 : loss : 0.029306, loss_ce: 0.008325
2021-12-03 00:43:49,883 iteration 4889 : loss : 0.032758, loss_ce: 0.015515
2021-12-03 00:43:51,383 iteration 4890 : loss : 0.017699, loss_ce: 0.008799
2021-12-03 00:43:52,817 iteration 4891 : loss : 0.013500, loss_ce: 0.004973
2021-12-03 00:43:54,423 iteration 4892 : loss : 0.016321, loss_ce: 0.006295
2021-12-03 00:43:55,994 iteration 4893 : loss : 0.021263, loss_ce: 0.008899
2021-12-03 00:43:57,538 iteration 4894 : loss : 0.016793, loss_ce: 0.007043
2021-12-03 00:43:59,073 iteration 4895 : loss : 0.019776, loss_ce: 0.004415
2021-12-03 00:44:00,580 iteration 4896 : loss : 0.017393, loss_ce: 0.004783
 72%|████████████████████▉        | 288/400 [2:10:54<52:01, 27.87s/it]2021-12-03 00:44:02,165 iteration 4897 : loss : 0.018273, loss_ce: 0.006844
2021-12-03 00:44:03,780 iteration 4898 : loss : 0.022055, loss_ce: 0.010619
2021-12-03 00:44:05,293 iteration 4899 : loss : 0.016832, loss_ce: 0.004811
2021-12-03 00:44:06,773 iteration 4900 : loss : 0.023895, loss_ce: 0.008364
2021-12-03 00:44:08,295 iteration 4901 : loss : 0.025975, loss_ce: 0.007465
2021-12-03 00:44:09,819 iteration 4902 : loss : 0.013191, loss_ce: 0.004549
2021-12-03 00:44:11,399 iteration 4903 : loss : 0.022107, loss_ce: 0.009205
2021-12-03 00:44:12,842 iteration 4904 : loss : 0.016756, loss_ce: 0.004675
2021-12-03 00:44:14,341 iteration 4905 : loss : 0.017476, loss_ce: 0.004756
2021-12-03 00:44:15,933 iteration 4906 : loss : 0.018259, loss_ce: 0.006482
2021-12-03 00:44:17,447 iteration 4907 : loss : 0.017460, loss_ce: 0.006227
2021-12-03 00:44:19,080 iteration 4908 : loss : 0.022014, loss_ce: 0.008726
2021-12-03 00:44:20,662 iteration 4909 : loss : 0.018536, loss_ce: 0.005894
2021-12-03 00:44:22,174 iteration 4910 : loss : 0.017973, loss_ce: 0.007892
2021-12-03 00:44:23,700 iteration 4911 : loss : 0.012919, loss_ce: 0.004528
2021-12-03 00:44:25,273 iteration 4912 : loss : 0.016021, loss_ce: 0.006889
2021-12-03 00:44:26,811 iteration 4913 : loss : 0.025542, loss_ce: 0.009089
 72%|████████████████████▉        | 289/400 [2:11:20<50:38, 27.38s/it]2021-12-03 00:44:28,421 iteration 4914 : loss : 0.023077, loss_ce: 0.009017
2021-12-03 00:44:29,912 iteration 4915 : loss : 0.019193, loss_ce: 0.006690
2021-12-03 00:44:31,443 iteration 4916 : loss : 0.015351, loss_ce: 0.004005
2021-12-03 00:44:32,996 iteration 4917 : loss : 0.017785, loss_ce: 0.005169
2021-12-03 00:44:34,575 iteration 4918 : loss : 0.017106, loss_ce: 0.006194
2021-12-03 00:44:36,292 iteration 4919 : loss : 0.029300, loss_ce: 0.012815
2021-12-03 00:44:37,810 iteration 4920 : loss : 0.014156, loss_ce: 0.005402
2021-12-03 00:44:39,317 iteration 4921 : loss : 0.017997, loss_ce: 0.009112
2021-12-03 00:44:40,795 iteration 4922 : loss : 0.015284, loss_ce: 0.003914
2021-12-03 00:44:42,401 iteration 4923 : loss : 0.025388, loss_ce: 0.010249
2021-12-03 00:44:44,031 iteration 4924 : loss : 0.026241, loss_ce: 0.015500
2021-12-03 00:44:45,601 iteration 4925 : loss : 0.016499, loss_ce: 0.005708
2021-12-03 00:44:47,207 iteration 4926 : loss : 0.020501, loss_ce: 0.010403
2021-12-03 00:44:48,728 iteration 4927 : loss : 0.015247, loss_ce: 0.004304
2021-12-03 00:44:50,349 iteration 4928 : loss : 0.030029, loss_ce: 0.011466
2021-12-03 00:44:51,937 iteration 4929 : loss : 0.018092, loss_ce: 0.007691
2021-12-03 00:44:51,938 Training Data Eval:
2021-12-03 00:44:59,614   Average segmentation loss on training set: 0.0114
2021-12-03 00:44:59,614 Validation Data Eval:
2021-12-03 00:45:02,267   Average segmentation loss on validation set: 0.0701
2021-12-03 00:45:03,835 iteration 4930 : loss : 0.025122, loss_ce: 0.007290
 72%|█████████████████████        | 290/400 [2:11:57<55:29, 30.27s/it]2021-12-03 00:45:05,446 iteration 4931 : loss : 0.016795, loss_ce: 0.007398
2021-12-03 00:45:07,034 iteration 4932 : loss : 0.022203, loss_ce: 0.010921
2021-12-03 00:45:08,528 iteration 4933 : loss : 0.015184, loss_ce: 0.007521
2021-12-03 00:45:10,157 iteration 4934 : loss : 0.021371, loss_ce: 0.007402
2021-12-03 00:45:11,718 iteration 4935 : loss : 0.020703, loss_ce: 0.006895
2021-12-03 00:45:13,297 iteration 4936 : loss : 0.023785, loss_ce: 0.009145
2021-12-03 00:45:14,846 iteration 4937 : loss : 0.017910, loss_ce: 0.008645
2021-12-03 00:45:16,431 iteration 4938 : loss : 0.034319, loss_ce: 0.012104
2021-12-03 00:45:18,060 iteration 4939 : loss : 0.023916, loss_ce: 0.009744
2021-12-03 00:45:19,597 iteration 4940 : loss : 0.021026, loss_ce: 0.008269
2021-12-03 00:45:21,179 iteration 4941 : loss : 0.023447, loss_ce: 0.010612
2021-12-03 00:45:22,762 iteration 4942 : loss : 0.019966, loss_ce: 0.006669
2021-12-03 00:45:24,442 iteration 4943 : loss : 0.033606, loss_ce: 0.007759
2021-12-03 00:45:26,010 iteration 4944 : loss : 0.023471, loss_ce: 0.007404
2021-12-03 00:45:27,621 iteration 4945 : loss : 0.020707, loss_ce: 0.008006
2021-12-03 00:45:29,260 iteration 4946 : loss : 0.026493, loss_ce: 0.008164
2021-12-03 00:45:30,814 iteration 4947 : loss : 0.023084, loss_ce: 0.007810
 73%|█████████████████████        | 291/400 [2:12:24<53:12, 29.29s/it]2021-12-03 00:45:32,461 iteration 4948 : loss : 0.022408, loss_ce: 0.008140
2021-12-03 00:45:33,990 iteration 4949 : loss : 0.030964, loss_ce: 0.012713
2021-12-03 00:45:35,587 iteration 4950 : loss : 0.031760, loss_ce: 0.013408
2021-12-03 00:45:37,136 iteration 4951 : loss : 0.021781, loss_ce: 0.006364
2021-12-03 00:45:38,685 iteration 4952 : loss : 0.015699, loss_ce: 0.008201
2021-12-03 00:45:40,278 iteration 4953 : loss : 0.021849, loss_ce: 0.008480
2021-12-03 00:45:41,813 iteration 4954 : loss : 0.014148, loss_ce: 0.004538
2021-12-03 00:45:43,308 iteration 4955 : loss : 0.023045, loss_ce: 0.006149
2021-12-03 00:45:44,855 iteration 4956 : loss : 0.022913, loss_ce: 0.006650
2021-12-03 00:45:46,319 iteration 4957 : loss : 0.016487, loss_ce: 0.006047
2021-12-03 00:45:47,888 iteration 4958 : loss : 0.025963, loss_ce: 0.012018
2021-12-03 00:45:49,467 iteration 4959 : loss : 0.020764, loss_ce: 0.007143
2021-12-03 00:45:50,940 iteration 4960 : loss : 0.016789, loss_ce: 0.005939
2021-12-03 00:45:52,524 iteration 4961 : loss : 0.017339, loss_ce: 0.006822
2021-12-03 00:45:54,010 iteration 4962 : loss : 0.024790, loss_ce: 0.006066
2021-12-03 00:45:55,535 iteration 4963 : loss : 0.016741, loss_ce: 0.005958
2021-12-03 00:45:57,147 iteration 4964 : loss : 0.019524, loss_ce: 0.006712
 73%|█████████████████████▏       | 292/400 [2:12:51<51:07, 28.40s/it]2021-12-03 00:45:58,830 iteration 4965 : loss : 0.027976, loss_ce: 0.011117
2021-12-03 00:46:00,450 iteration 4966 : loss : 0.020896, loss_ce: 0.009385
2021-12-03 00:46:01,978 iteration 4967 : loss : 0.023198, loss_ce: 0.009691
2021-12-03 00:46:03,531 iteration 4968 : loss : 0.019201, loss_ce: 0.009061
2021-12-03 00:46:05,210 iteration 4969 : loss : 0.027479, loss_ce: 0.008197
2021-12-03 00:46:06,707 iteration 4970 : loss : 0.015757, loss_ce: 0.006418
2021-12-03 00:46:08,244 iteration 4971 : loss : 0.017174, loss_ce: 0.008333
2021-12-03 00:46:09,847 iteration 4972 : loss : 0.024882, loss_ce: 0.009598
2021-12-03 00:46:11,409 iteration 4973 : loss : 0.021490, loss_ce: 0.007501
2021-12-03 00:46:13,101 iteration 4974 : loss : 0.023561, loss_ce: 0.007931
2021-12-03 00:46:14,656 iteration 4975 : loss : 0.016227, loss_ce: 0.005011
2021-12-03 00:46:16,146 iteration 4976 : loss : 0.017708, loss_ce: 0.006166
2021-12-03 00:46:17,744 iteration 4977 : loss : 0.024819, loss_ce: 0.005462
2021-12-03 00:46:19,287 iteration 4978 : loss : 0.022749, loss_ce: 0.005165
2021-12-03 00:46:20,850 iteration 4979 : loss : 0.019932, loss_ce: 0.007197
2021-12-03 00:46:22,430 iteration 4980 : loss : 0.022608, loss_ce: 0.006722
2021-12-03 00:46:23,979 iteration 4981 : loss : 0.022309, loss_ce: 0.007941
 73%|█████████████████████▏       | 293/400 [2:13:18<49:48, 27.93s/it]2021-12-03 00:46:25,544 iteration 4982 : loss : 0.016878, loss_ce: 0.007557
2021-12-03 00:46:27,067 iteration 4983 : loss : 0.018370, loss_ce: 0.007023
2021-12-03 00:46:28,740 iteration 4984 : loss : 0.019583, loss_ce: 0.006434
2021-12-03 00:46:30,223 iteration 4985 : loss : 0.014007, loss_ce: 0.003834
2021-12-03 00:46:31,870 iteration 4986 : loss : 0.022146, loss_ce: 0.009394
2021-12-03 00:46:33,357 iteration 4987 : loss : 0.016899, loss_ce: 0.004987
2021-12-03 00:46:34,930 iteration 4988 : loss : 0.021981, loss_ce: 0.006631
2021-12-03 00:46:36,556 iteration 4989 : loss : 0.022504, loss_ce: 0.008225
2021-12-03 00:46:38,204 iteration 4990 : loss : 0.017975, loss_ce: 0.007569
2021-12-03 00:46:39,782 iteration 4991 : loss : 0.026329, loss_ce: 0.007168
2021-12-03 00:46:41,238 iteration 4992 : loss : 0.014258, loss_ce: 0.006723
2021-12-03 00:46:42,768 iteration 4993 : loss : 0.019251, loss_ce: 0.006482
2021-12-03 00:46:44,263 iteration 4994 : loss : 0.016839, loss_ce: 0.005340
2021-12-03 00:46:45,791 iteration 4995 : loss : 0.019608, loss_ce: 0.008173
2021-12-03 00:46:47,376 iteration 4996 : loss : 0.025809, loss_ce: 0.007121
2021-12-03 00:46:48,829 iteration 4997 : loss : 0.016825, loss_ce: 0.005047
2021-12-03 00:46:50,300 iteration 4998 : loss : 0.016988, loss_ce: 0.006566
 74%|█████████████████████▎       | 294/400 [2:13:44<48:29, 27.45s/it]2021-12-03 00:46:51,843 iteration 4999 : loss : 0.014883, loss_ce: 0.005142
2021-12-03 00:46:53,377 iteration 5000 : loss : 0.022047, loss_ce: 0.008255
2021-12-03 00:46:54,916 iteration 5001 : loss : 0.016156, loss_ce: 0.007127
2021-12-03 00:46:56,445 iteration 5002 : loss : 0.012551, loss_ce: 0.004310
2021-12-03 00:46:58,033 iteration 5003 : loss : 0.033980, loss_ce: 0.006672
2021-12-03 00:46:59,578 iteration 5004 : loss : 0.019910, loss_ce: 0.007880
2021-12-03 00:47:01,139 iteration 5005 : loss : 0.017768, loss_ce: 0.007292
2021-12-03 00:47:02,762 iteration 5006 : loss : 0.023521, loss_ce: 0.010341
2021-12-03 00:47:04,359 iteration 5007 : loss : 0.024508, loss_ce: 0.009979
2021-12-03 00:47:05,963 iteration 5008 : loss : 0.023687, loss_ce: 0.009636
2021-12-03 00:47:07,557 iteration 5009 : loss : 0.022883, loss_ce: 0.006195
2021-12-03 00:47:09,137 iteration 5010 : loss : 0.021227, loss_ce: 0.008461
2021-12-03 00:47:10,669 iteration 5011 : loss : 0.016875, loss_ce: 0.007643
2021-12-03 00:47:12,235 iteration 5012 : loss : 0.024440, loss_ce: 0.010741
2021-12-03 00:47:13,691 iteration 5013 : loss : 0.018293, loss_ce: 0.006623
2021-12-03 00:47:15,212 iteration 5014 : loss : 0.023361, loss_ce: 0.008453
2021-12-03 00:47:15,212 Training Data Eval:
2021-12-03 00:47:22,869   Average segmentation loss on training set: 0.0133
2021-12-03 00:47:22,869 Validation Data Eval:
2021-12-03 00:47:25,513   Average segmentation loss on validation set: 0.0655
2021-12-03 00:47:27,074 iteration 5015 : loss : 0.028723, loss_ce: 0.010197
 74%|█████████████████████▍       | 295/400 [2:14:21<52:55, 30.24s/it]2021-12-03 00:47:28,683 iteration 5016 : loss : 0.017987, loss_ce: 0.007708
2021-12-03 00:47:30,223 iteration 5017 : loss : 0.015635, loss_ce: 0.005394
2021-12-03 00:47:31,775 iteration 5018 : loss : 0.017903, loss_ce: 0.007213
2021-12-03 00:47:33,353 iteration 5019 : loss : 0.020139, loss_ce: 0.007174
2021-12-03 00:47:34,954 iteration 5020 : loss : 0.023293, loss_ce: 0.007068
2021-12-03 00:47:36,527 iteration 5021 : loss : 0.020999, loss_ce: 0.010312
2021-12-03 00:47:38,009 iteration 5022 : loss : 0.019718, loss_ce: 0.005910
2021-12-03 00:47:39,612 iteration 5023 : loss : 0.027624, loss_ce: 0.006910
2021-12-03 00:47:41,281 iteration 5024 : loss : 0.027909, loss_ce: 0.006255
2021-12-03 00:47:42,909 iteration 5025 : loss : 0.031361, loss_ce: 0.006410
2021-12-03 00:47:44,472 iteration 5026 : loss : 0.017892, loss_ce: 0.006660
2021-12-03 00:47:45,996 iteration 5027 : loss : 0.018576, loss_ce: 0.007605
2021-12-03 00:47:47,528 iteration 5028 : loss : 0.025228, loss_ce: 0.009700
2021-12-03 00:47:49,192 iteration 5029 : loss : 0.034166, loss_ce: 0.008860
2021-12-03 00:47:50,761 iteration 5030 : loss : 0.017625, loss_ce: 0.008238
2021-12-03 00:47:52,405 iteration 5031 : loss : 0.020640, loss_ce: 0.008865
2021-12-03 00:47:53,984 iteration 5032 : loss : 0.021932, loss_ce: 0.010203
 74%|█████████████████████▍       | 296/400 [2:14:48<50:41, 29.25s/it]2021-12-03 00:47:55,728 iteration 5033 : loss : 0.030568, loss_ce: 0.009588
2021-12-03 00:47:57,271 iteration 5034 : loss : 0.026103, loss_ce: 0.007584
2021-12-03 00:47:58,801 iteration 5035 : loss : 0.022916, loss_ce: 0.008196
2021-12-03 00:48:00,319 iteration 5036 : loss : 0.019029, loss_ce: 0.007141
2021-12-03 00:48:01,839 iteration 5037 : loss : 0.022081, loss_ce: 0.007466
2021-12-03 00:48:03,386 iteration 5038 : loss : 0.022331, loss_ce: 0.004798
2021-12-03 00:48:05,047 iteration 5039 : loss : 0.017808, loss_ce: 0.008434
2021-12-03 00:48:06,606 iteration 5040 : loss : 0.016060, loss_ce: 0.004490
2021-12-03 00:48:08,258 iteration 5041 : loss : 0.018987, loss_ce: 0.006819
2021-12-03 00:48:09,785 iteration 5042 : loss : 0.017965, loss_ce: 0.007328
2021-12-03 00:48:11,345 iteration 5043 : loss : 0.018104, loss_ce: 0.008259
2021-12-03 00:48:12,920 iteration 5044 : loss : 0.020107, loss_ce: 0.008315
2021-12-03 00:48:14,538 iteration 5045 : loss : 0.022971, loss_ce: 0.010243
2021-12-03 00:48:16,112 iteration 5046 : loss : 0.039675, loss_ce: 0.010496
2021-12-03 00:48:17,645 iteration 5047 : loss : 0.026475, loss_ce: 0.006691
2021-12-03 00:48:19,180 iteration 5048 : loss : 0.015825, loss_ce: 0.006060
2021-12-03 00:48:20,712 iteration 5049 : loss : 0.014865, loss_ce: 0.005494
 74%|█████████████████████▌       | 297/400 [2:15:14<48:54, 28.49s/it]2021-12-03 00:48:22,335 iteration 5050 : loss : 0.021614, loss_ce: 0.006410
2021-12-03 00:48:23,857 iteration 5051 : loss : 0.026036, loss_ce: 0.010774
2021-12-03 00:48:25,378 iteration 5052 : loss : 0.017855, loss_ce: 0.007099
2021-12-03 00:48:26,925 iteration 5053 : loss : 0.016257, loss_ce: 0.006631
2021-12-03 00:48:28,490 iteration 5054 : loss : 0.014323, loss_ce: 0.004441
2021-12-03 00:48:30,035 iteration 5055 : loss : 0.019599, loss_ce: 0.006224
2021-12-03 00:48:31,561 iteration 5056 : loss : 0.022989, loss_ce: 0.005481
2021-12-03 00:48:33,185 iteration 5057 : loss : 0.021373, loss_ce: 0.010376
2021-12-03 00:48:34,818 iteration 5058 : loss : 0.027932, loss_ce: 0.011949
2021-12-03 00:48:36,246 iteration 5059 : loss : 0.027220, loss_ce: 0.006086
2021-12-03 00:48:37,819 iteration 5060 : loss : 0.026762, loss_ce: 0.007320
2021-12-03 00:48:39,400 iteration 5061 : loss : 0.016057, loss_ce: 0.006044
2021-12-03 00:48:40,968 iteration 5062 : loss : 0.025028, loss_ce: 0.007284
2021-12-03 00:48:42,594 iteration 5063 : loss : 0.023713, loss_ce: 0.009845
2021-12-03 00:48:44,120 iteration 5064 : loss : 0.020895, loss_ce: 0.007232
2021-12-03 00:48:45,615 iteration 5065 : loss : 0.021962, loss_ce: 0.008446
2021-12-03 00:48:47,151 iteration 5066 : loss : 0.017961, loss_ce: 0.008023
 74%|█████████████████████▌       | 298/400 [2:15:41<47:22, 27.87s/it]2021-12-03 00:48:48,826 iteration 5067 : loss : 0.018339, loss_ce: 0.006845
2021-12-03 00:48:50,422 iteration 5068 : loss : 0.031829, loss_ce: 0.012603
2021-12-03 00:48:51,999 iteration 5069 : loss : 0.022380, loss_ce: 0.006783
2021-12-03 00:48:53,547 iteration 5070 : loss : 0.016477, loss_ce: 0.004499
2021-12-03 00:48:55,183 iteration 5071 : loss : 0.021479, loss_ce: 0.007972
2021-12-03 00:48:56,614 iteration 5072 : loss : 0.019047, loss_ce: 0.006125
2021-12-03 00:48:58,166 iteration 5073 : loss : 0.017651, loss_ce: 0.008067
2021-12-03 00:48:59,771 iteration 5074 : loss : 0.027625, loss_ce: 0.007451
2021-12-03 00:49:01,340 iteration 5075 : loss : 0.020619, loss_ce: 0.007032
2021-12-03 00:49:02,968 iteration 5076 : loss : 0.019446, loss_ce: 0.008772
2021-12-03 00:49:04,490 iteration 5077 : loss : 0.017648, loss_ce: 0.005895
2021-12-03 00:49:06,060 iteration 5078 : loss : 0.014579, loss_ce: 0.003941
2021-12-03 00:49:07,591 iteration 5079 : loss : 0.016752, loss_ce: 0.006488
2021-12-03 00:49:09,122 iteration 5080 : loss : 0.021262, loss_ce: 0.007412
2021-12-03 00:49:10,679 iteration 5081 : loss : 0.021679, loss_ce: 0.010264
2021-12-03 00:49:12,309 iteration 5082 : loss : 0.030784, loss_ce: 0.014729
2021-12-03 00:49:13,891 iteration 5083 : loss : 0.018043, loss_ce: 0.005570
 75%|█████████████████████▋       | 299/400 [2:16:08<46:20, 27.53s/it]2021-12-03 00:49:15,471 iteration 5084 : loss : 0.016057, loss_ce: 0.005660
2021-12-03 00:49:17,036 iteration 5085 : loss : 0.021774, loss_ce: 0.007685
2021-12-03 00:49:18,576 iteration 5086 : loss : 0.019109, loss_ce: 0.007300
2021-12-03 00:49:20,196 iteration 5087 : loss : 0.026993, loss_ce: 0.009428
2021-12-03 00:49:21,772 iteration 5088 : loss : 0.016828, loss_ce: 0.005790
2021-12-03 00:49:23,293 iteration 5089 : loss : 0.018103, loss_ce: 0.005466
2021-12-03 00:49:24,813 iteration 5090 : loss : 0.016238, loss_ce: 0.004966
2021-12-03 00:49:26,480 iteration 5091 : loss : 0.022165, loss_ce: 0.007775
2021-12-03 00:49:28,031 iteration 5092 : loss : 0.012742, loss_ce: 0.005812
2021-12-03 00:49:29,547 iteration 5093 : loss : 0.018798, loss_ce: 0.008255
2021-12-03 00:49:31,043 iteration 5094 : loss : 0.014828, loss_ce: 0.005186
2021-12-03 00:49:32,609 iteration 5095 : loss : 0.028532, loss_ce: 0.009036
2021-12-03 00:49:34,097 iteration 5096 : loss : 0.014167, loss_ce: 0.005220
2021-12-03 00:49:35,605 iteration 5097 : loss : 0.017098, loss_ce: 0.007166
2021-12-03 00:49:37,138 iteration 5098 : loss : 0.023501, loss_ce: 0.007530
2021-12-03 00:49:38,674 iteration 5099 : loss : 0.016207, loss_ce: 0.005342
2021-12-03 00:49:38,675 Training Data Eval:
2021-12-03 00:49:46,326   Average segmentation loss on training set: 0.0118
2021-12-03 00:49:46,327 Validation Data Eval:
2021-12-03 00:49:48,960   Average segmentation loss on validation set: 0.0718
2021-12-03 00:49:50,529 iteration 5100 : loss : 0.014835, loss_ce: 0.006687
2021-12-03 00:49:52,512 save model to ../model/TU_RUNMC256/TU_pretrain_R50-ViT-B_16_skip3_bs16_256/1channelepoch_299.pth
 75%|█████████████████████▊       | 300/400 [2:16:46<51:24, 30.84s/it]2021-12-03 00:49:54,033 iteration 5101 : loss : 0.015847, loss_ce: 0.006491
2021-12-03 00:49:55,441 iteration 5102 : loss : 0.012979, loss_ce: 0.004605
2021-12-03 00:49:56,908 iteration 5103 : loss : 0.017936, loss_ce: 0.007450
2021-12-03 00:49:58,504 iteration 5104 : loss : 0.025932, loss_ce: 0.010477
2021-12-03 00:49:59,973 iteration 5105 : loss : 0.019309, loss_ce: 0.007441
2021-12-03 00:50:01,565 iteration 5106 : loss : 0.019771, loss_ce: 0.006884
2021-12-03 00:50:03,064 iteration 5107 : loss : 0.016751, loss_ce: 0.006096
2021-12-03 00:50:04,675 iteration 5108 : loss : 0.027459, loss_ce: 0.008727
2021-12-03 00:50:06,242 iteration 5109 : loss : 0.025215, loss_ce: 0.007296
2021-12-03 00:50:07,797 iteration 5110 : loss : 0.020867, loss_ce: 0.009639
2021-12-03 00:50:09,393 iteration 5111 : loss : 0.017709, loss_ce: 0.005473
2021-12-03 00:50:10,887 iteration 5112 : loss : 0.019804, loss_ce: 0.004905
2021-12-03 00:50:12,507 iteration 5113 : loss : 0.031650, loss_ce: 0.004982
2021-12-03 00:50:14,046 iteration 5114 : loss : 0.016503, loss_ce: 0.007999
2021-12-03 00:50:15,551 iteration 5115 : loss : 0.023167, loss_ce: 0.006592
2021-12-03 00:50:17,090 iteration 5116 : loss : 0.017114, loss_ce: 0.006388
2021-12-03 00:50:18,722 iteration 5117 : loss : 0.018740, loss_ce: 0.008943
 75%|█████████████████████▊       | 301/400 [2:17:12<48:37, 29.47s/it]2021-12-03 00:50:20,354 iteration 5118 : loss : 0.014164, loss_ce: 0.005456
2021-12-03 00:50:21,908 iteration 5119 : loss : 0.019606, loss_ce: 0.006836
2021-12-03 00:50:23,395 iteration 5120 : loss : 0.022177, loss_ce: 0.005959
2021-12-03 00:50:24,925 iteration 5121 : loss : 0.018175, loss_ce: 0.008203
2021-12-03 00:50:26,437 iteration 5122 : loss : 0.020222, loss_ce: 0.007494
2021-12-03 00:50:27,998 iteration 5123 : loss : 0.023066, loss_ce: 0.006335
2021-12-03 00:50:29,586 iteration 5124 : loss : 0.016436, loss_ce: 0.006220
2021-12-03 00:50:31,044 iteration 5125 : loss : 0.018929, loss_ce: 0.009044
2021-12-03 00:50:32,547 iteration 5126 : loss : 0.022715, loss_ce: 0.007561
2021-12-03 00:50:34,150 iteration 5127 : loss : 0.023188, loss_ce: 0.008579
2021-12-03 00:50:35,673 iteration 5128 : loss : 0.013395, loss_ce: 0.005210
2021-12-03 00:50:37,237 iteration 5129 : loss : 0.019110, loss_ce: 0.006004
2021-12-03 00:50:38,768 iteration 5130 : loss : 0.016892, loss_ce: 0.005106
2021-12-03 00:50:40,230 iteration 5131 : loss : 0.013072, loss_ce: 0.004626
2021-12-03 00:50:41,777 iteration 5132 : loss : 0.017845, loss_ce: 0.006594
2021-12-03 00:50:43,294 iteration 5133 : loss : 0.016867, loss_ce: 0.004923
2021-12-03 00:50:44,794 iteration 5134 : loss : 0.017698, loss_ce: 0.006996
 76%|█████████████████████▉       | 302/400 [2:17:38<46:28, 28.45s/it]2021-12-03 00:50:46,511 iteration 5135 : loss : 0.023882, loss_ce: 0.009113
2021-12-03 00:50:48,034 iteration 5136 : loss : 0.020055, loss_ce: 0.006139
2021-12-03 00:50:49,651 iteration 5137 : loss : 0.019298, loss_ce: 0.006266
2021-12-03 00:50:51,172 iteration 5138 : loss : 0.021278, loss_ce: 0.008099
2021-12-03 00:50:52,732 iteration 5139 : loss : 0.012750, loss_ce: 0.004523
2021-12-03 00:50:54,385 iteration 5140 : loss : 0.015067, loss_ce: 0.006265
2021-12-03 00:50:55,900 iteration 5141 : loss : 0.024287, loss_ce: 0.008174
2021-12-03 00:50:57,481 iteration 5142 : loss : 0.023551, loss_ce: 0.008808
2021-12-03 00:50:58,956 iteration 5143 : loss : 0.014804, loss_ce: 0.005688
2021-12-03 00:51:00,553 iteration 5144 : loss : 0.018254, loss_ce: 0.008893
2021-12-03 00:51:02,024 iteration 5145 : loss : 0.012767, loss_ce: 0.004032
2021-12-03 00:51:03,659 iteration 5146 : loss : 0.033582, loss_ce: 0.017547
2021-12-03 00:51:05,293 iteration 5147 : loss : 0.019132, loss_ce: 0.006395
2021-12-03 00:51:06,814 iteration 5148 : loss : 0.015880, loss_ce: 0.006226
2021-12-03 00:51:08,347 iteration 5149 : loss : 0.021979, loss_ce: 0.006253
2021-12-03 00:51:09,851 iteration 5150 : loss : 0.013165, loss_ce: 0.005066
2021-12-03 00:51:11,396 iteration 5151 : loss : 0.020571, loss_ce: 0.004198
 76%|█████████████████████▉       | 303/400 [2:18:05<45:06, 27.90s/it]2021-12-03 00:51:12,961 iteration 5152 : loss : 0.015024, loss_ce: 0.003116
2021-12-03 00:51:14,416 iteration 5153 : loss : 0.012307, loss_ce: 0.004767
2021-12-03 00:51:16,047 iteration 5154 : loss : 0.018916, loss_ce: 0.007470
2021-12-03 00:51:17,539 iteration 5155 : loss : 0.013594, loss_ce: 0.004719
2021-12-03 00:51:19,070 iteration 5156 : loss : 0.020747, loss_ce: 0.008802
2021-12-03 00:51:20,557 iteration 5157 : loss : 0.012698, loss_ce: 0.003864
2021-12-03 00:51:22,083 iteration 5158 : loss : 0.019330, loss_ce: 0.006414
2021-12-03 00:51:23,713 iteration 5159 : loss : 0.020394, loss_ce: 0.007359
2021-12-03 00:51:25,188 iteration 5160 : loss : 0.014254, loss_ce: 0.004767
2021-12-03 00:51:26,723 iteration 5161 : loss : 0.015541, loss_ce: 0.005711
2021-12-03 00:51:28,212 iteration 5162 : loss : 0.015446, loss_ce: 0.006267
2021-12-03 00:51:29,795 iteration 5163 : loss : 0.021251, loss_ce: 0.008120
2021-12-03 00:51:31,363 iteration 5164 : loss : 0.015776, loss_ce: 0.007235
2021-12-03 00:51:32,830 iteration 5165 : loss : 0.016746, loss_ce: 0.005052
2021-12-03 00:51:34,371 iteration 5166 : loss : 0.015519, loss_ce: 0.006751
2021-12-03 00:51:35,923 iteration 5167 : loss : 0.020412, loss_ce: 0.005927
2021-12-03 00:51:37,542 iteration 5168 : loss : 0.017107, loss_ce: 0.006371
 76%|██████████████████████       | 304/400 [2:18:31<43:47, 27.37s/it]2021-12-03 00:51:39,285 iteration 5169 : loss : 0.028817, loss_ce: 0.011385
2021-12-03 00:51:40,772 iteration 5170 : loss : 0.019554, loss_ce: 0.005285
2021-12-03 00:51:42,397 iteration 5171 : loss : 0.019581, loss_ce: 0.008251
2021-12-03 00:51:43,878 iteration 5172 : loss : 0.029222, loss_ce: 0.011956
2021-12-03 00:51:45,288 iteration 5173 : loss : 0.013262, loss_ce: 0.005528
2021-12-03 00:51:46,920 iteration 5174 : loss : 0.018666, loss_ce: 0.006590
2021-12-03 00:51:48,442 iteration 5175 : loss : 0.016435, loss_ce: 0.007474
2021-12-03 00:51:50,120 iteration 5176 : loss : 0.025318, loss_ce: 0.009873
2021-12-03 00:51:51,604 iteration 5177 : loss : 0.019251, loss_ce: 0.007951
2021-12-03 00:51:53,093 iteration 5178 : loss : 0.014230, loss_ce: 0.004235
2021-12-03 00:51:54,675 iteration 5179 : loss : 0.023933, loss_ce: 0.008081
2021-12-03 00:51:56,229 iteration 5180 : loss : 0.019508, loss_ce: 0.008786
2021-12-03 00:51:57,737 iteration 5181 : loss : 0.017049, loss_ce: 0.004918
2021-12-03 00:51:59,265 iteration 5182 : loss : 0.014492, loss_ce: 0.005602
2021-12-03 00:52:00,761 iteration 5183 : loss : 0.019157, loss_ce: 0.009987
2021-12-03 00:52:02,268 iteration 5184 : loss : 0.020332, loss_ce: 0.007020
2021-12-03 00:52:02,268 Training Data Eval:
2021-12-03 00:52:09,936   Average segmentation loss on training set: 0.0116
2021-12-03 00:52:09,937 Validation Data Eval:
2021-12-03 00:52:12,572   Average segmentation loss on validation set: 0.0711
2021-12-03 00:52:14,121 iteration 5185 : loss : 0.021520, loss_ce: 0.007524
 76%|██████████████████████       | 305/400 [2:19:08<47:42, 30.13s/it]2021-12-03 00:52:15,769 iteration 5186 : loss : 0.018193, loss_ce: 0.008832
2021-12-03 00:52:17,262 iteration 5187 : loss : 0.018242, loss_ce: 0.006950
2021-12-03 00:52:18,779 iteration 5188 : loss : 0.013095, loss_ce: 0.005319
2021-12-03 00:52:20,286 iteration 5189 : loss : 0.017061, loss_ce: 0.007353
2021-12-03 00:52:21,758 iteration 5190 : loss : 0.017653, loss_ce: 0.007396
2021-12-03 00:52:23,336 iteration 5191 : loss : 0.015351, loss_ce: 0.004350
2021-12-03 00:52:24,942 iteration 5192 : loss : 0.019119, loss_ce: 0.006238
2021-12-03 00:52:26,435 iteration 5193 : loss : 0.011888, loss_ce: 0.003833
2021-12-03 00:52:28,027 iteration 5194 : loss : 0.021617, loss_ce: 0.007693
2021-12-03 00:52:29,540 iteration 5195 : loss : 0.015905, loss_ce: 0.005153
2021-12-03 00:52:30,983 iteration 5196 : loss : 0.010581, loss_ce: 0.002796
2021-12-03 00:52:32,468 iteration 5197 : loss : 0.015450, loss_ce: 0.004895
2021-12-03 00:52:33,978 iteration 5198 : loss : 0.017102, loss_ce: 0.007849
2021-12-03 00:52:35,557 iteration 5199 : loss : 0.013544, loss_ce: 0.004919
2021-12-03 00:52:37,099 iteration 5200 : loss : 0.027158, loss_ce: 0.008343
2021-12-03 00:52:38,675 iteration 5201 : loss : 0.021299, loss_ce: 0.007081
2021-12-03 00:52:40,312 iteration 5202 : loss : 0.023487, loss_ce: 0.010678
 76%|██████████████████████▏      | 306/400 [2:19:34<45:21, 28.95s/it]2021-12-03 00:52:41,887 iteration 5203 : loss : 0.013647, loss_ce: 0.004970
2021-12-03 00:52:43,416 iteration 5204 : loss : 0.019613, loss_ce: 0.007766
2021-12-03 00:52:45,049 iteration 5205 : loss : 0.022942, loss_ce: 0.009536
2021-12-03 00:52:46,566 iteration 5206 : loss : 0.021056, loss_ce: 0.007016
2021-12-03 00:52:48,134 iteration 5207 : loss : 0.018819, loss_ce: 0.007542
2021-12-03 00:52:49,778 iteration 5208 : loss : 0.018141, loss_ce: 0.006909
2021-12-03 00:52:51,285 iteration 5209 : loss : 0.016800, loss_ce: 0.006659
2021-12-03 00:52:52,888 iteration 5210 : loss : 0.017070, loss_ce: 0.006320
2021-12-03 00:52:54,466 iteration 5211 : loss : 0.015692, loss_ce: 0.006266
2021-12-03 00:52:56,030 iteration 5212 : loss : 0.017845, loss_ce: 0.006222
2021-12-03 00:52:57,469 iteration 5213 : loss : 0.014143, loss_ce: 0.005082
2021-12-03 00:52:59,119 iteration 5214 : loss : 0.023891, loss_ce: 0.011359
2021-12-03 00:53:00,710 iteration 5215 : loss : 0.023310, loss_ce: 0.006935
2021-12-03 00:53:02,330 iteration 5216 : loss : 0.020316, loss_ce: 0.006430
2021-12-03 00:53:04,007 iteration 5217 : loss : 0.022836, loss_ce: 0.008995
2021-12-03 00:53:05,509 iteration 5218 : loss : 0.021236, loss_ce: 0.004354
2021-12-03 00:53:07,136 iteration 5219 : loss : 0.020388, loss_ce: 0.006894
 77%|██████████████████████▎      | 307/400 [2:20:01<43:53, 28.31s/it]2021-12-03 00:53:08,698 iteration 5220 : loss : 0.015310, loss_ce: 0.004734
2021-12-03 00:53:10,235 iteration 5221 : loss : 0.021516, loss_ce: 0.006145
2021-12-03 00:53:11,724 iteration 5222 : loss : 0.013009, loss_ce: 0.004760
2021-12-03 00:53:13,338 iteration 5223 : loss : 0.022275, loss_ce: 0.009376
2021-12-03 00:53:14,889 iteration 5224 : loss : 0.018638, loss_ce: 0.006294
2021-12-03 00:53:16,512 iteration 5225 : loss : 0.014489, loss_ce: 0.004603
2021-12-03 00:53:18,045 iteration 5226 : loss : 0.018525, loss_ce: 0.007541
2021-12-03 00:53:19,685 iteration 5227 : loss : 0.017358, loss_ce: 0.007326
2021-12-03 00:53:21,202 iteration 5228 : loss : 0.015709, loss_ce: 0.004703
2021-12-03 00:53:22,892 iteration 5229 : loss : 0.018391, loss_ce: 0.007555
2021-12-03 00:53:24,318 iteration 5230 : loss : 0.014072, loss_ce: 0.005887
2021-12-03 00:53:25,903 iteration 5231 : loss : 0.018268, loss_ce: 0.006913
2021-12-03 00:53:27,468 iteration 5232 : loss : 0.021028, loss_ce: 0.006347
2021-12-03 00:53:29,065 iteration 5233 : loss : 0.019137, loss_ce: 0.007223
2021-12-03 00:53:30,554 iteration 5234 : loss : 0.014257, loss_ce: 0.005723
2021-12-03 00:53:32,095 iteration 5235 : loss : 0.018614, loss_ce: 0.006343
2021-12-03 00:53:33,710 iteration 5236 : loss : 0.026327, loss_ce: 0.008836
 77%|██████████████████████▎      | 308/400 [2:20:27<42:36, 27.79s/it]2021-12-03 00:53:35,179 iteration 5237 : loss : 0.012965, loss_ce: 0.005354
2021-12-03 00:53:36,777 iteration 5238 : loss : 0.013976, loss_ce: 0.005583
2021-12-03 00:53:38,355 iteration 5239 : loss : 0.017550, loss_ce: 0.006013
2021-12-03 00:53:39,960 iteration 5240 : loss : 0.171097, loss_ce: 0.002789
2021-12-03 00:53:41,480 iteration 5241 : loss : 0.014428, loss_ce: 0.005293
2021-12-03 00:53:43,025 iteration 5242 : loss : 0.023418, loss_ce: 0.010116
2021-12-03 00:53:44,672 iteration 5243 : loss : 0.030425, loss_ce: 0.009552
2021-12-03 00:53:46,272 iteration 5244 : loss : 0.018430, loss_ce: 0.007817
2021-12-03 00:53:47,843 iteration 5245 : loss : 0.018832, loss_ce: 0.006363
2021-12-03 00:53:49,441 iteration 5246 : loss : 0.020950, loss_ce: 0.006655
2021-12-03 00:53:50,916 iteration 5247 : loss : 0.013914, loss_ce: 0.005417
2021-12-03 00:53:52,515 iteration 5248 : loss : 0.014464, loss_ce: 0.004298
2021-12-03 00:53:54,170 iteration 5249 : loss : 0.017182, loss_ce: 0.005549
2021-12-03 00:53:55,712 iteration 5250 : loss : 0.018762, loss_ce: 0.008924
2021-12-03 00:53:57,144 iteration 5251 : loss : 0.014329, loss_ce: 0.004659
2021-12-03 00:53:58,699 iteration 5252 : loss : 0.016548, loss_ce: 0.006523
2021-12-03 00:54:00,291 iteration 5253 : loss : 0.029660, loss_ce: 0.009444
 77%|██████████████████████▍      | 309/400 [2:20:54<41:36, 27.43s/it]2021-12-03 00:54:01,904 iteration 5254 : loss : 0.014864, loss_ce: 0.004981
2021-12-03 00:54:03,438 iteration 5255 : loss : 0.021829, loss_ce: 0.011792
2021-12-03 00:54:04,910 iteration 5256 : loss : 0.014698, loss_ce: 0.005911
2021-12-03 00:54:06,484 iteration 5257 : loss : 0.015433, loss_ce: 0.006241
2021-12-03 00:54:08,091 iteration 5258 : loss : 0.016433, loss_ce: 0.004584
2021-12-03 00:54:09,598 iteration 5259 : loss : 0.017017, loss_ce: 0.004512
2021-12-03 00:54:11,173 iteration 5260 : loss : 0.014587, loss_ce: 0.004770
2021-12-03 00:54:12,753 iteration 5261 : loss : 0.021517, loss_ce: 0.008707
2021-12-03 00:54:14,323 iteration 5262 : loss : 0.010903, loss_ce: 0.004038
2021-12-03 00:54:15,893 iteration 5263 : loss : 0.023318, loss_ce: 0.010492
2021-12-03 00:54:17,393 iteration 5264 : loss : 0.015163, loss_ce: 0.007055
2021-12-03 00:54:18,950 iteration 5265 : loss : 0.023928, loss_ce: 0.011957
2021-12-03 00:54:20,544 iteration 5266 : loss : 0.018990, loss_ce: 0.006090
2021-12-03 00:54:22,087 iteration 5267 : loss : 0.022007, loss_ce: 0.006345
2021-12-03 00:54:23,674 iteration 5268 : loss : 0.031928, loss_ce: 0.010132
2021-12-03 00:54:25,358 iteration 5269 : loss : 0.024840, loss_ce: 0.008902
2021-12-03 00:54:25,358 Training Data Eval:
2021-12-03 00:54:33,010   Average segmentation loss on training set: 0.0114
2021-12-03 00:54:33,011 Validation Data Eval:
2021-12-03 00:54:35,652   Average segmentation loss on validation set: 0.0862
2021-12-03 00:54:37,216 iteration 5270 : loss : 0.014462, loss_ce: 0.005830
 78%|██████████████████████▍      | 310/400 [2:21:31<45:24, 30.28s/it]2021-12-03 00:54:38,795 iteration 5271 : loss : 0.016953, loss_ce: 0.006954
2021-12-03 00:54:40,384 iteration 5272 : loss : 0.021973, loss_ce: 0.012134
2021-12-03 00:54:41,916 iteration 5273 : loss : 0.014432, loss_ce: 0.003742
2021-12-03 00:54:43,428 iteration 5274 : loss : 0.022216, loss_ce: 0.008044
2021-12-03 00:54:44,879 iteration 5275 : loss : 0.014716, loss_ce: 0.006178
2021-12-03 00:54:46,479 iteration 5276 : loss : 0.018971, loss_ce: 0.007477
2021-12-03 00:54:48,055 iteration 5277 : loss : 0.016975, loss_ce: 0.006024
2021-12-03 00:54:49,522 iteration 5278 : loss : 0.015110, loss_ce: 0.006179
2021-12-03 00:54:51,076 iteration 5279 : loss : 0.018588, loss_ce: 0.007471
2021-12-03 00:54:52,789 iteration 5280 : loss : 0.028984, loss_ce: 0.011286
2021-12-03 00:54:54,328 iteration 5281 : loss : 0.016062, loss_ce: 0.005602
2021-12-03 00:54:55,821 iteration 5282 : loss : 0.014349, loss_ce: 0.004298
2021-12-03 00:54:57,381 iteration 5283 : loss : 0.025497, loss_ce: 0.009306
2021-12-03 00:54:58,974 iteration 5284 : loss : 0.031929, loss_ce: 0.012030
2021-12-03 00:55:00,531 iteration 5285 : loss : 0.016068, loss_ce: 0.006703
2021-12-03 00:55:01,999 iteration 5286 : loss : 0.014798, loss_ce: 0.006406
2021-12-03 00:55:03,540 iteration 5287 : loss : 0.015608, loss_ce: 0.003517
 78%|██████████████████████▌      | 311/400 [2:21:57<43:08, 29.09s/it]2021-12-03 00:55:05,155 iteration 5288 : loss : 0.017495, loss_ce: 0.006861
2021-12-03 00:55:06,721 iteration 5289 : loss : 0.023032, loss_ce: 0.007881
2021-12-03 00:55:08,249 iteration 5290 : loss : 0.020619, loss_ce: 0.005253
2021-12-03 00:55:09,786 iteration 5291 : loss : 0.020521, loss_ce: 0.006690
2021-12-03 00:55:11,379 iteration 5292 : loss : 0.017148, loss_ce: 0.006092
2021-12-03 00:55:12,938 iteration 5293 : loss : 0.020961, loss_ce: 0.008540
2021-12-03 00:55:14,553 iteration 5294 : loss : 0.027722, loss_ce: 0.010388
2021-12-03 00:55:16,216 iteration 5295 : loss : 0.025544, loss_ce: 0.008322
2021-12-03 00:55:17,827 iteration 5296 : loss : 0.025486, loss_ce: 0.006413
2021-12-03 00:55:19,429 iteration 5297 : loss : 0.018052, loss_ce: 0.005747
2021-12-03 00:55:21,037 iteration 5298 : loss : 0.020960, loss_ce: 0.007750
2021-12-03 00:55:22,644 iteration 5299 : loss : 0.016269, loss_ce: 0.005311
2021-12-03 00:55:24,276 iteration 5300 : loss : 0.021545, loss_ce: 0.007429
2021-12-03 00:55:25,771 iteration 5301 : loss : 0.015828, loss_ce: 0.005838
2021-12-03 00:55:27,251 iteration 5302 : loss : 0.014913, loss_ce: 0.007104
2021-12-03 00:55:28,729 iteration 5303 : loss : 0.014201, loss_ce: 0.005298
2021-12-03 00:55:30,185 iteration 5304 : loss : 0.014859, loss_ce: 0.005170
 78%|██████████████████████▌      | 312/400 [2:22:24<41:35, 28.36s/it]2021-12-03 00:55:31,821 iteration 5305 : loss : 0.019674, loss_ce: 0.006615
2021-12-03 00:55:33,523 iteration 5306 : loss : 0.018950, loss_ce: 0.007957
2021-12-03 00:55:35,213 iteration 5307 : loss : 0.021103, loss_ce: 0.008144
2021-12-03 00:55:36,840 iteration 5308 : loss : 0.034405, loss_ce: 0.009771
2021-12-03 00:55:38,436 iteration 5309 : loss : 0.027500, loss_ce: 0.007776
2021-12-03 00:55:39,936 iteration 5310 : loss : 0.014427, loss_ce: 0.006772
2021-12-03 00:55:41,431 iteration 5311 : loss : 0.020971, loss_ce: 0.005292
2021-12-03 00:55:43,063 iteration 5312 : loss : 0.018725, loss_ce: 0.008407
2021-12-03 00:55:44,749 iteration 5313 : loss : 0.021001, loss_ce: 0.006415
2021-12-03 00:55:46,323 iteration 5314 : loss : 0.019399, loss_ce: 0.005841
2021-12-03 00:55:47,947 iteration 5315 : loss : 0.032804, loss_ce: 0.007283
2021-12-03 00:55:49,547 iteration 5316 : loss : 0.014671, loss_ce: 0.005453
2021-12-03 00:55:51,075 iteration 5317 : loss : 0.018376, loss_ce: 0.007781
2021-12-03 00:55:52,585 iteration 5318 : loss : 0.015575, loss_ce: 0.005866
2021-12-03 00:55:54,200 iteration 5319 : loss : 0.021049, loss_ce: 0.008314
2021-12-03 00:55:55,785 iteration 5320 : loss : 0.021822, loss_ce: 0.010211
2021-12-03 00:55:57,427 iteration 5321 : loss : 0.023606, loss_ce: 0.010628
 78%|██████████████████████▋      | 313/400 [2:22:51<40:37, 28.02s/it]2021-12-03 00:55:58,974 iteration 5322 : loss : 0.014565, loss_ce: 0.006347
2021-12-03 00:56:00,547 iteration 5323 : loss : 0.023951, loss_ce: 0.009458
2021-12-03 00:56:02,042 iteration 5324 : loss : 0.020219, loss_ce: 0.006872
2021-12-03 00:56:03,562 iteration 5325 : loss : 0.016932, loss_ce: 0.004045
2021-12-03 00:56:05,188 iteration 5326 : loss : 0.021082, loss_ce: 0.007481
2021-12-03 00:56:06,716 iteration 5327 : loss : 0.018626, loss_ce: 0.005944
2021-12-03 00:56:08,250 iteration 5328 : loss : 0.018636, loss_ce: 0.009660
2021-12-03 00:56:09,865 iteration 5329 : loss : 0.026167, loss_ce: 0.008864
2021-12-03 00:56:11,461 iteration 5330 : loss : 0.019207, loss_ce: 0.006900
2021-12-03 00:56:13,009 iteration 5331 : loss : 0.017269, loss_ce: 0.005515
2021-12-03 00:56:14,567 iteration 5332 : loss : 0.017651, loss_ce: 0.005180
2021-12-03 00:56:16,130 iteration 5333 : loss : 0.019371, loss_ce: 0.009563
2021-12-03 00:56:17,667 iteration 5334 : loss : 0.019703, loss_ce: 0.007683
2021-12-03 00:56:19,282 iteration 5335 : loss : 0.021795, loss_ce: 0.006492
2021-12-03 00:56:20,880 iteration 5336 : loss : 0.016406, loss_ce: 0.005878
2021-12-03 00:56:22,413 iteration 5337 : loss : 0.021369, loss_ce: 0.007672
2021-12-03 00:56:23,955 iteration 5338 : loss : 0.016376, loss_ce: 0.006660
 78%|██████████████████████▊      | 314/400 [2:23:18<39:31, 27.57s/it]2021-12-03 00:56:25,748 iteration 5339 : loss : 0.018381, loss_ce: 0.006960
2021-12-03 00:56:27,377 iteration 5340 : loss : 0.024711, loss_ce: 0.012562
2021-12-03 00:56:28,971 iteration 5341 : loss : 0.021979, loss_ce: 0.004096
2021-12-03 00:56:30,558 iteration 5342 : loss : 0.017034, loss_ce: 0.008683
2021-12-03 00:56:32,100 iteration 5343 : loss : 0.014613, loss_ce: 0.004646
2021-12-03 00:56:33,684 iteration 5344 : loss : 0.020196, loss_ce: 0.006910
2021-12-03 00:56:35,227 iteration 5345 : loss : 0.015369, loss_ce: 0.005168
2021-12-03 00:56:36,844 iteration 5346 : loss : 0.016355, loss_ce: 0.005107
2021-12-03 00:56:38,445 iteration 5347 : loss : 0.013682, loss_ce: 0.003826
2021-12-03 00:56:40,003 iteration 5348 : loss : 0.015661, loss_ce: 0.003937
2021-12-03 00:56:41,575 iteration 5349 : loss : 0.023167, loss_ce: 0.008860
2021-12-03 00:56:43,060 iteration 5350 : loss : 0.015652, loss_ce: 0.006231
2021-12-03 00:56:44,569 iteration 5351 : loss : 0.023758, loss_ce: 0.009274
2021-12-03 00:56:46,192 iteration 5352 : loss : 0.018387, loss_ce: 0.007106
2021-12-03 00:56:47,809 iteration 5353 : loss : 0.014710, loss_ce: 0.004729
2021-12-03 00:56:49,354 iteration 5354 : loss : 0.014023, loss_ce: 0.006330
2021-12-03 00:56:49,354 Training Data Eval:
2021-12-03 00:56:57,062   Average segmentation loss on training set: 0.0110
2021-12-03 00:56:57,062 Validation Data Eval:
2021-12-03 00:56:59,718   Average segmentation loss on validation set: 0.0671
2021-12-03 00:57:01,217 iteration 5355 : loss : 0.016544, loss_ce: 0.005919
 79%|██████████████████████▊      | 315/400 [2:23:55<43:11, 30.48s/it]2021-12-03 00:57:02,823 iteration 5356 : loss : 0.023311, loss_ce: 0.010357
2021-12-03 00:57:04,302 iteration 5357 : loss : 0.024237, loss_ce: 0.005448
2021-12-03 00:57:06,022 iteration 5358 : loss : 0.026281, loss_ce: 0.011725
2021-12-03 00:57:07,522 iteration 5359 : loss : 0.013459, loss_ce: 0.004913
2021-12-03 00:57:09,110 iteration 5360 : loss : 0.023051, loss_ce: 0.009638
2021-12-03 00:57:10,692 iteration 5361 : loss : 0.018219, loss_ce: 0.006166
2021-12-03 00:57:12,313 iteration 5362 : loss : 0.019890, loss_ce: 0.006940
2021-12-03 00:57:13,885 iteration 5363 : loss : 0.026489, loss_ce: 0.009359
2021-12-03 00:57:15,454 iteration 5364 : loss : 0.025184, loss_ce: 0.006000
2021-12-03 00:57:17,004 iteration 5365 : loss : 0.015583, loss_ce: 0.005894
2021-12-03 00:57:18,594 iteration 5366 : loss : 0.016703, loss_ce: 0.005455
2021-12-03 00:57:20,216 iteration 5367 : loss : 0.017104, loss_ce: 0.007044
2021-12-03 00:57:21,764 iteration 5368 : loss : 0.013587, loss_ce: 0.005825
2021-12-03 00:57:23,358 iteration 5369 : loss : 0.017622, loss_ce: 0.007094
2021-12-03 00:57:24,892 iteration 5370 : loss : 0.012148, loss_ce: 0.004628
2021-12-03 00:57:26,439 iteration 5371 : loss : 0.018957, loss_ce: 0.009988
2021-12-03 00:57:27,999 iteration 5372 : loss : 0.019193, loss_ce: 0.005761
 79%|██████████████████████▉      | 316/400 [2:24:22<41:07, 29.37s/it]2021-12-03 00:57:29,661 iteration 5373 : loss : 0.015969, loss_ce: 0.007073
2021-12-03 00:57:31,185 iteration 5374 : loss : 0.016741, loss_ce: 0.007849
2021-12-03 00:57:32,784 iteration 5375 : loss : 0.015563, loss_ce: 0.004130
2021-12-03 00:57:34,333 iteration 5376 : loss : 0.013836, loss_ce: 0.004886
2021-12-03 00:57:35,866 iteration 5377 : loss : 0.014106, loss_ce: 0.004581
2021-12-03 00:57:37,442 iteration 5378 : loss : 0.019335, loss_ce: 0.007266
2021-12-03 00:57:38,937 iteration 5379 : loss : 0.011535, loss_ce: 0.004291
2021-12-03 00:57:40,502 iteration 5380 : loss : 0.017306, loss_ce: 0.006930
2021-12-03 00:57:42,029 iteration 5381 : loss : 0.019938, loss_ce: 0.008312
2021-12-03 00:57:43,624 iteration 5382 : loss : 0.016309, loss_ce: 0.004921
2021-12-03 00:57:45,277 iteration 5383 : loss : 0.026098, loss_ce: 0.012572
2021-12-03 00:57:47,014 iteration 5384 : loss : 0.018526, loss_ce: 0.006372
2021-12-03 00:57:48,510 iteration 5385 : loss : 0.015133, loss_ce: 0.005789
2021-12-03 00:57:49,960 iteration 5386 : loss : 0.013728, loss_ce: 0.004547
2021-12-03 00:57:51,460 iteration 5387 : loss : 0.018184, loss_ce: 0.007206
2021-12-03 00:57:53,029 iteration 5388 : loss : 0.029162, loss_ce: 0.007623
2021-12-03 00:57:54,725 iteration 5389 : loss : 0.028887, loss_ce: 0.009413
 79%|██████████████████████▉      | 317/400 [2:24:48<39:32, 28.58s/it]2021-12-03 00:57:56,328 iteration 5390 : loss : 0.025610, loss_ce: 0.006196
2021-12-03 00:57:57,945 iteration 5391 : loss : 0.018961, loss_ce: 0.006091
2021-12-03 00:57:59,544 iteration 5392 : loss : 0.018711, loss_ce: 0.009636
2021-12-03 00:58:01,101 iteration 5393 : loss : 0.024671, loss_ce: 0.007716
2021-12-03 00:58:02,635 iteration 5394 : loss : 0.019195, loss_ce: 0.008710
2021-12-03 00:58:04,227 iteration 5395 : loss : 0.018355, loss_ce: 0.005236
2021-12-03 00:58:05,740 iteration 5396 : loss : 0.017132, loss_ce: 0.008304
2021-12-03 00:58:07,380 iteration 5397 : loss : 0.018276, loss_ce: 0.005814
2021-12-03 00:58:08,969 iteration 5398 : loss : 0.019697, loss_ce: 0.007011
2021-12-03 00:58:10,457 iteration 5399 : loss : 0.018001, loss_ce: 0.005357
2021-12-03 00:58:12,110 iteration 5400 : loss : 0.024251, loss_ce: 0.006501
2021-12-03 00:58:13,703 iteration 5401 : loss : 0.023944, loss_ce: 0.010718
2021-12-03 00:58:15,242 iteration 5402 : loss : 0.019225, loss_ce: 0.006741
2021-12-03 00:58:16,756 iteration 5403 : loss : 0.020902, loss_ce: 0.007868
2021-12-03 00:58:18,264 iteration 5404 : loss : 0.015812, loss_ce: 0.004158
2021-12-03 00:58:19,812 iteration 5405 : loss : 0.018761, loss_ce: 0.007033
2021-12-03 00:58:21,425 iteration 5406 : loss : 0.018125, loss_ce: 0.005235
 80%|███████████████████████      | 318/400 [2:25:15<38:16, 28.01s/it]2021-12-03 00:58:23,082 iteration 5407 : loss : 0.021500, loss_ce: 0.008408
2021-12-03 00:58:24,647 iteration 5408 : loss : 0.022175, loss_ce: 0.006754
2021-12-03 00:58:26,323 iteration 5409 : loss : 0.023879, loss_ce: 0.011145
2021-12-03 00:58:27,844 iteration 5410 : loss : 0.017754, loss_ce: 0.007660
2021-12-03 00:58:29,407 iteration 5411 : loss : 0.016293, loss_ce: 0.005976
2021-12-03 00:58:30,966 iteration 5412 : loss : 0.017796, loss_ce: 0.007465
2021-12-03 00:58:32,503 iteration 5413 : loss : 0.017371, loss_ce: 0.007821
2021-12-03 00:58:34,086 iteration 5414 : loss : 0.017928, loss_ce: 0.006755
2021-12-03 00:58:35,753 iteration 5415 : loss : 0.024725, loss_ce: 0.010246
2021-12-03 00:58:37,226 iteration 5416 : loss : 0.012760, loss_ce: 0.004111
2021-12-03 00:58:38,784 iteration 5417 : loss : 0.016778, loss_ce: 0.005028
2021-12-03 00:58:40,340 iteration 5418 : loss : 0.021460, loss_ce: 0.008553
2021-12-03 00:58:41,935 iteration 5419 : loss : 0.017632, loss_ce: 0.006117
2021-12-03 00:58:43,571 iteration 5420 : loss : 0.017945, loss_ce: 0.006425
2021-12-03 00:58:45,166 iteration 5421 : loss : 0.014880, loss_ce: 0.006703
2021-12-03 00:58:46,604 iteration 5422 : loss : 0.011304, loss_ce: 0.004655
2021-12-03 00:58:48,209 iteration 5423 : loss : 0.024456, loss_ce: 0.005279
 80%|███████████████████████▏     | 319/400 [2:25:42<37:19, 27.64s/it]2021-12-03 00:58:49,904 iteration 5424 : loss : 0.016715, loss_ce: 0.005915
2021-12-03 00:58:51,422 iteration 5425 : loss : 0.013269, loss_ce: 0.004062
2021-12-03 00:58:52,975 iteration 5426 : loss : 0.017759, loss_ce: 0.004259
2021-12-03 00:58:54,442 iteration 5427 : loss : 0.018583, loss_ce: 0.007168
2021-12-03 00:58:55,956 iteration 5428 : loss : 0.022508, loss_ce: 0.009379
2021-12-03 00:58:57,541 iteration 5429 : loss : 0.014760, loss_ce: 0.005469
2021-12-03 00:58:59,105 iteration 5430 : loss : 0.017711, loss_ce: 0.007805
2021-12-03 00:59:00,571 iteration 5431 : loss : 0.015472, loss_ce: 0.005728
2021-12-03 00:59:02,162 iteration 5432 : loss : 0.018646, loss_ce: 0.008311
2021-12-03 00:59:03,767 iteration 5433 : loss : 0.022596, loss_ce: 0.009218
2021-12-03 00:59:05,266 iteration 5434 : loss : 0.016347, loss_ce: 0.006873
2021-12-03 00:59:06,918 iteration 5435 : loss : 0.023234, loss_ce: 0.009389
2021-12-03 00:59:08,515 iteration 5436 : loss : 0.015676, loss_ce: 0.005644
2021-12-03 00:59:10,138 iteration 5437 : loss : 0.028084, loss_ce: 0.007079
2021-12-03 00:59:11,756 iteration 5438 : loss : 0.015425, loss_ce: 0.006224
2021-12-03 00:59:13,306 iteration 5439 : loss : 0.015850, loss_ce: 0.006674
2021-12-03 00:59:13,306 Training Data Eval:
2021-12-03 00:59:20,989   Average segmentation loss on training set: 0.0107
2021-12-03 00:59:20,989 Validation Data Eval:
2021-12-03 00:59:23,624   Average segmentation loss on validation set: 0.0773
2021-12-03 00:59:25,122 iteration 5440 : loss : 0.017014, loss_ce: 0.005466
 80%|███████████████████████▏     | 320/400 [2:26:19<40:34, 30.43s/it]2021-12-03 00:59:26,721 iteration 5441 : loss : 0.014579, loss_ce: 0.004957
2021-12-03 00:59:28,197 iteration 5442 : loss : 0.018168, loss_ce: 0.006711
2021-12-03 00:59:29,729 iteration 5443 : loss : 0.015008, loss_ce: 0.004993
2021-12-03 00:59:31,202 iteration 5444 : loss : 0.015460, loss_ce: 0.004604
2021-12-03 00:59:32,806 iteration 5445 : loss : 0.017166, loss_ce: 0.006067
2021-12-03 00:59:34,324 iteration 5446 : loss : 0.014467, loss_ce: 0.006810
2021-12-03 00:59:35,982 iteration 5447 : loss : 0.025273, loss_ce: 0.007864
2021-12-03 00:59:37,508 iteration 5448 : loss : 0.014902, loss_ce: 0.005089
2021-12-03 00:59:39,078 iteration 5449 : loss : 0.024084, loss_ce: 0.013667
2021-12-03 00:59:40,636 iteration 5450 : loss : 0.019694, loss_ce: 0.007808
2021-12-03 00:59:42,131 iteration 5451 : loss : 0.022716, loss_ce: 0.007331
2021-12-03 00:59:43,702 iteration 5452 : loss : 0.028947, loss_ce: 0.011208
2021-12-03 00:59:45,215 iteration 5453 : loss : 0.014485, loss_ce: 0.005573
2021-12-03 00:59:46,832 iteration 5454 : loss : 0.017272, loss_ce: 0.008646
2021-12-03 00:59:48,422 iteration 5455 : loss : 0.023617, loss_ce: 0.008604
2021-12-03 00:59:49,988 iteration 5456 : loss : 0.014849, loss_ce: 0.003963
2021-12-03 00:59:51,462 iteration 5457 : loss : 0.014710, loss_ce: 0.004563
 80%|███████████████████████▎     | 321/400 [2:26:45<38:26, 29.20s/it]2021-12-03 00:59:53,035 iteration 5458 : loss : 0.019207, loss_ce: 0.006239
2021-12-03 00:59:54,521 iteration 5459 : loss : 0.016206, loss_ce: 0.006724
2021-12-03 00:59:56,082 iteration 5460 : loss : 0.014700, loss_ce: 0.005255
2021-12-03 00:59:57,626 iteration 5461 : loss : 0.029527, loss_ce: 0.010069
2021-12-03 00:59:59,170 iteration 5462 : loss : 0.018640, loss_ce: 0.006324
2021-12-03 01:00:00,743 iteration 5463 : loss : 0.025551, loss_ce: 0.007345
2021-12-03 01:00:02,308 iteration 5464 : loss : 0.015967, loss_ce: 0.007024
2021-12-03 01:00:03,946 iteration 5465 : loss : 0.023311, loss_ce: 0.008702
2021-12-03 01:00:05,564 iteration 5466 : loss : 0.016664, loss_ce: 0.006173
2021-12-03 01:00:07,155 iteration 5467 : loss : 0.029619, loss_ce: 0.012338
2021-12-03 01:00:08,734 iteration 5468 : loss : 0.015155, loss_ce: 0.006055
2021-12-03 01:00:10,212 iteration 5469 : loss : 0.016175, loss_ce: 0.005815
2021-12-03 01:00:11,750 iteration 5470 : loss : 0.010310, loss_ce: 0.003537
2021-12-03 01:00:13,298 iteration 5471 : loss : 0.021264, loss_ce: 0.006021
2021-12-03 01:00:14,847 iteration 5472 : loss : 0.021832, loss_ce: 0.007400
2021-12-03 01:00:16,319 iteration 5473 : loss : 0.014678, loss_ce: 0.005125
2021-12-03 01:00:17,823 iteration 5474 : loss : 0.016276, loss_ce: 0.004950
 80%|███████████████████████▎     | 322/400 [2:27:11<36:51, 28.35s/it]2021-12-03 01:00:19,452 iteration 5475 : loss : 0.022861, loss_ce: 0.006311
2021-12-03 01:00:21,094 iteration 5476 : loss : 0.022248, loss_ce: 0.009706
2021-12-03 01:00:22,646 iteration 5477 : loss : 0.046936, loss_ce: 0.009986
2021-12-03 01:00:24,124 iteration 5478 : loss : 0.014587, loss_ce: 0.004867
2021-12-03 01:00:25,678 iteration 5479 : loss : 0.013363, loss_ce: 0.005466
2021-12-03 01:00:27,231 iteration 5480 : loss : 0.019389, loss_ce: 0.006134
2021-12-03 01:00:28,734 iteration 5481 : loss : 0.016232, loss_ce: 0.005744
2021-12-03 01:00:30,399 iteration 5482 : loss : 0.042767, loss_ce: 0.009747
2021-12-03 01:00:31,873 iteration 5483 : loss : 0.015979, loss_ce: 0.006332
2021-12-03 01:00:33,440 iteration 5484 : loss : 0.024406, loss_ce: 0.008698
2021-12-03 01:00:34,997 iteration 5485 : loss : 0.019703, loss_ce: 0.009690
2021-12-03 01:00:36,541 iteration 5486 : loss : 0.024754, loss_ce: 0.010975
2021-12-03 01:00:38,085 iteration 5487 : loss : 0.021150, loss_ce: 0.007254
2021-12-03 01:00:39,571 iteration 5488 : loss : 0.016941, loss_ce: 0.007705
2021-12-03 01:00:41,089 iteration 5489 : loss : 0.015151, loss_ce: 0.008183
2021-12-03 01:00:42,731 iteration 5490 : loss : 0.025641, loss_ce: 0.010213
2021-12-03 01:00:44,269 iteration 5491 : loss : 0.017628, loss_ce: 0.005429
 81%|███████████████████████▍     | 323/400 [2:27:38<35:38, 27.78s/it]2021-12-03 01:00:45,779 iteration 5492 : loss : 0.017883, loss_ce: 0.006172
2021-12-03 01:00:47,360 iteration 5493 : loss : 0.022468, loss_ce: 0.006978
2021-12-03 01:00:48,871 iteration 5494 : loss : 0.020384, loss_ce: 0.006481
2021-12-03 01:00:50,428 iteration 5495 : loss : 0.013613, loss_ce: 0.004149
2021-12-03 01:00:51,999 iteration 5496 : loss : 0.020301, loss_ce: 0.005259
2021-12-03 01:00:53,606 iteration 5497 : loss : 0.015027, loss_ce: 0.005812
2021-12-03 01:00:55,230 iteration 5498 : loss : 0.030006, loss_ce: 0.011739
2021-12-03 01:00:56,829 iteration 5499 : loss : 0.023434, loss_ce: 0.011876
2021-12-03 01:00:58,325 iteration 5500 : loss : 0.015319, loss_ce: 0.006359
2021-12-03 01:00:59,854 iteration 5501 : loss : 0.021695, loss_ce: 0.009210
2021-12-03 01:01:01,338 iteration 5502 : loss : 0.012054, loss_ce: 0.005001
2021-12-03 01:01:02,907 iteration 5503 : loss : 0.018444, loss_ce: 0.004932
2021-12-03 01:01:04,409 iteration 5504 : loss : 0.018652, loss_ce: 0.007305
2021-12-03 01:01:05,966 iteration 5505 : loss : 0.018523, loss_ce: 0.007094
2021-12-03 01:01:07,554 iteration 5506 : loss : 0.014077, loss_ce: 0.004915
2021-12-03 01:01:09,093 iteration 5507 : loss : 0.017242, loss_ce: 0.007197
2021-12-03 01:01:10,663 iteration 5508 : loss : 0.022249, loss_ce: 0.007457
 81%|███████████████████████▍     | 324/400 [2:28:04<34:39, 27.37s/it]2021-12-03 01:01:12,296 iteration 5509 : loss : 0.025457, loss_ce: 0.007422
2021-12-03 01:01:13,942 iteration 5510 : loss : 0.015403, loss_ce: 0.004907
2021-12-03 01:01:15,484 iteration 5511 : loss : 0.015928, loss_ce: 0.005718
2021-12-03 01:01:17,099 iteration 5512 : loss : 0.019477, loss_ce: 0.008815
2021-12-03 01:01:18,644 iteration 5513 : loss : 0.015504, loss_ce: 0.006930
2021-12-03 01:01:20,132 iteration 5514 : loss : 0.012639, loss_ce: 0.004017
2021-12-03 01:01:21,758 iteration 5515 : loss : 0.037585, loss_ce: 0.008815
2021-12-03 01:01:23,266 iteration 5516 : loss : 0.016239, loss_ce: 0.006364
2021-12-03 01:01:24,802 iteration 5517 : loss : 0.018972, loss_ce: 0.007724
2021-12-03 01:01:26,343 iteration 5518 : loss : 0.019805, loss_ce: 0.006594
2021-12-03 01:01:27,939 iteration 5519 : loss : 0.017752, loss_ce: 0.006260
2021-12-03 01:01:29,519 iteration 5520 : loss : 0.016870, loss_ce: 0.007389
2021-12-03 01:01:31,100 iteration 5521 : loss : 0.016035, loss_ce: 0.006101
2021-12-03 01:01:32,657 iteration 5522 : loss : 0.019392, loss_ce: 0.006171
2021-12-03 01:01:34,192 iteration 5523 : loss : 0.011726, loss_ce: 0.003921
2021-12-03 01:01:35,726 iteration 5524 : loss : 0.016976, loss_ce: 0.007167
2021-12-03 01:01:35,727 Training Data Eval:
2021-12-03 01:01:43,401   Average segmentation loss on training set: 0.0114
2021-12-03 01:01:43,401 Validation Data Eval:
2021-12-03 01:01:46,038   Average segmentation loss on validation set: 0.0594
2021-12-03 01:01:47,987 Found new lowest validation loss at iteration 5524! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/UNET_RUNMC/1channel_best_val_loss.pth
2021-12-03 01:01:49,435 iteration 5525 : loss : 0.020682, loss_ce: 0.009822
 81%|███████████████████████▌     | 325/400 [2:28:43<38:28, 30.78s/it]2021-12-03 01:01:50,939 iteration 5526 : loss : 0.031919, loss_ce: 0.008550
2021-12-03 01:01:52,388 iteration 5527 : loss : 0.016549, loss_ce: 0.006868
2021-12-03 01:01:53,877 iteration 5528 : loss : 0.024741, loss_ce: 0.009048
2021-12-03 01:01:55,470 iteration 5529 : loss : 0.019486, loss_ce: 0.007991
2021-12-03 01:01:56,940 iteration 5530 : loss : 0.016832, loss_ce: 0.007512
2021-12-03 01:01:58,458 iteration 5531 : loss : 0.018418, loss_ce: 0.007706
2021-12-03 01:01:59,968 iteration 5532 : loss : 0.012505, loss_ce: 0.005079
2021-12-03 01:02:01,588 iteration 5533 : loss : 0.017498, loss_ce: 0.004875
2021-12-03 01:02:03,138 iteration 5534 : loss : 0.015922, loss_ce: 0.005418
2021-12-03 01:02:04,760 iteration 5535 : loss : 0.022854, loss_ce: 0.009825
2021-12-03 01:02:06,422 iteration 5536 : loss : 0.018089, loss_ce: 0.007742
2021-12-03 01:02:08,015 iteration 5537 : loss : 0.026026, loss_ce: 0.008327
2021-12-03 01:02:09,587 iteration 5538 : loss : 0.017660, loss_ce: 0.007017
2021-12-03 01:02:11,261 iteration 5539 : loss : 0.021659, loss_ce: 0.005351
2021-12-03 01:02:12,783 iteration 5540 : loss : 0.016063, loss_ce: 0.007386
2021-12-03 01:02:14,387 iteration 5541 : loss : 0.025272, loss_ce: 0.007783
2021-12-03 01:02:15,919 iteration 5542 : loss : 0.015630, loss_ce: 0.005888
 82%|███████████████████████▋     | 326/400 [2:29:10<36:22, 29.49s/it]2021-12-03 01:02:17,528 iteration 5543 : loss : 0.023418, loss_ce: 0.008602
2021-12-03 01:02:19,066 iteration 5544 : loss : 0.018318, loss_ce: 0.008534
2021-12-03 01:02:20,586 iteration 5545 : loss : 0.016182, loss_ce: 0.006751
2021-12-03 01:02:22,088 iteration 5546 : loss : 0.018349, loss_ce: 0.006968
2021-12-03 01:02:23,645 iteration 5547 : loss : 0.019737, loss_ce: 0.008904
2021-12-03 01:02:25,275 iteration 5548 : loss : 0.015288, loss_ce: 0.005068
2021-12-03 01:02:26,774 iteration 5549 : loss : 0.015943, loss_ce: 0.006237
2021-12-03 01:02:28,306 iteration 5550 : loss : 0.018533, loss_ce: 0.006717
2021-12-03 01:02:29,863 iteration 5551 : loss : 0.017207, loss_ce: 0.007158
2021-12-03 01:02:31,357 iteration 5552 : loss : 0.013487, loss_ce: 0.005005
2021-12-03 01:02:32,956 iteration 5553 : loss : 0.021953, loss_ce: 0.010324
2021-12-03 01:02:34,577 iteration 5554 : loss : 0.015435, loss_ce: 0.005095
2021-12-03 01:02:36,184 iteration 5555 : loss : 0.020163, loss_ce: 0.005166
2021-12-03 01:02:37,656 iteration 5556 : loss : 0.016153, loss_ce: 0.005928
2021-12-03 01:02:39,284 iteration 5557 : loss : 0.036776, loss_ce: 0.009337
2021-12-03 01:02:40,815 iteration 5558 : loss : 0.015164, loss_ce: 0.004922
2021-12-03 01:02:42,264 iteration 5559 : loss : 0.012823, loss_ce: 0.004864
 82%|███████████████████████▋     | 327/400 [2:29:36<34:44, 28.55s/it]2021-12-03 01:02:44,077 iteration 5560 : loss : 0.026487, loss_ce: 0.009497
2021-12-03 01:02:45,625 iteration 5561 : loss : 0.016829, loss_ce: 0.005517
2021-12-03 01:02:47,174 iteration 5562 : loss : 0.021733, loss_ce: 0.006310
2021-12-03 01:02:48,739 iteration 5563 : loss : 0.013105, loss_ce: 0.005114
2021-12-03 01:02:50,392 iteration 5564 : loss : 0.025989, loss_ce: 0.007748
2021-12-03 01:02:51,945 iteration 5565 : loss : 0.016890, loss_ce: 0.006388
2021-12-03 01:02:53,541 iteration 5566 : loss : 0.014099, loss_ce: 0.005967
2021-12-03 01:02:55,214 iteration 5567 : loss : 0.017925, loss_ce: 0.008273
2021-12-03 01:02:56,776 iteration 5568 : loss : 0.023191, loss_ce: 0.008323
2021-12-03 01:02:58,383 iteration 5569 : loss : 0.016225, loss_ce: 0.006790
2021-12-03 01:02:59,968 iteration 5570 : loss : 0.014021, loss_ce: 0.004651
2021-12-03 01:03:01,583 iteration 5571 : loss : 0.019730, loss_ce: 0.007915
2021-12-03 01:03:03,110 iteration 5572 : loss : 0.015441, loss_ce: 0.005964
2021-12-03 01:03:04,624 iteration 5573 : loss : 0.015173, loss_ce: 0.004548
2021-12-03 01:03:06,313 iteration 5574 : loss : 0.017618, loss_ce: 0.005892
2021-12-03 01:03:07,758 iteration 5575 : loss : 0.011158, loss_ce: 0.004667
2021-12-03 01:03:09,181 iteration 5576 : loss : 0.012593, loss_ce: 0.003858
 82%|███████████████████████▊     | 328/400 [2:30:03<33:40, 28.06s/it]2021-12-03 01:03:10,795 iteration 5577 : loss : 0.014308, loss_ce: 0.004812
2021-12-03 01:03:12,333 iteration 5578 : loss : 0.017311, loss_ce: 0.004852
2021-12-03 01:03:13,877 iteration 5579 : loss : 0.014874, loss_ce: 0.004443
2021-12-03 01:03:15,492 iteration 5580 : loss : 0.013579, loss_ce: 0.004787
2021-12-03 01:03:17,035 iteration 5581 : loss : 0.014748, loss_ce: 0.005430
2021-12-03 01:03:18,636 iteration 5582 : loss : 0.017643, loss_ce: 0.005446
2021-12-03 01:03:20,172 iteration 5583 : loss : 0.020106, loss_ce: 0.005297
2021-12-03 01:03:21,837 iteration 5584 : loss : 0.017597, loss_ce: 0.007464
2021-12-03 01:03:23,371 iteration 5585 : loss : 0.022101, loss_ce: 0.009286
2021-12-03 01:03:24,926 iteration 5586 : loss : 0.029463, loss_ce: 0.014044
2021-12-03 01:03:26,462 iteration 5587 : loss : 0.016852, loss_ce: 0.008837
2021-12-03 01:03:28,068 iteration 5588 : loss : 0.016483, loss_ce: 0.005829
2021-12-03 01:03:29,679 iteration 5589 : loss : 0.019936, loss_ce: 0.007393
2021-12-03 01:03:31,258 iteration 5590 : loss : 0.017961, loss_ce: 0.006866
2021-12-03 01:03:32,833 iteration 5591 : loss : 0.017918, loss_ce: 0.007768
2021-12-03 01:03:34,379 iteration 5592 : loss : 0.018691, loss_ce: 0.006463
2021-12-03 01:03:35,924 iteration 5593 : loss : 0.014355, loss_ce: 0.008014
 82%|███████████████████████▊     | 329/400 [2:30:30<32:44, 27.66s/it]2021-12-03 01:03:37,588 iteration 5594 : loss : 0.014782, loss_ce: 0.005311
2021-12-03 01:03:39,112 iteration 5595 : loss : 0.014896, loss_ce: 0.006235
2021-12-03 01:03:40,647 iteration 5596 : loss : 0.010210, loss_ce: 0.002797
2021-12-03 01:03:42,232 iteration 5597 : loss : 0.013772, loss_ce: 0.004301
2021-12-03 01:03:43,873 iteration 5598 : loss : 0.017341, loss_ce: 0.007495
2021-12-03 01:03:45,473 iteration 5599 : loss : 0.016661, loss_ce: 0.005892
2021-12-03 01:03:47,077 iteration 5600 : loss : 0.014857, loss_ce: 0.006017
2021-12-03 01:03:48,692 iteration 5601 : loss : 0.016166, loss_ce: 0.005389
2021-12-03 01:03:50,190 iteration 5602 : loss : 0.020498, loss_ce: 0.005152
2021-12-03 01:03:51,769 iteration 5603 : loss : 0.022799, loss_ce: 0.009996
2021-12-03 01:03:53,283 iteration 5604 : loss : 0.015562, loss_ce: 0.006882
2021-12-03 01:03:54,811 iteration 5605 : loss : 0.015220, loss_ce: 0.004890
2021-12-03 01:03:56,458 iteration 5606 : loss : 0.019387, loss_ce: 0.005626
2021-12-03 01:03:58,025 iteration 5607 : loss : 0.026096, loss_ce: 0.009052
2021-12-03 01:03:59,742 iteration 5608 : loss : 0.018728, loss_ce: 0.009402
2021-12-03 01:04:01,278 iteration 5609 : loss : 0.015833, loss_ce: 0.007539
2021-12-03 01:04:01,278 Training Data Eval:
2021-12-03 01:04:08,960   Average segmentation loss on training set: 0.0103
2021-12-03 01:04:08,960 Validation Data Eval:
2021-12-03 01:04:11,602   Average segmentation loss on validation set: 0.0712
2021-12-03 01:04:13,203 iteration 5610 : loss : 0.022369, loss_ce: 0.009034
 82%|███████████████████████▉     | 330/400 [2:31:07<35:38, 30.55s/it]2021-12-03 01:04:14,832 iteration 5611 : loss : 0.018503, loss_ce: 0.007772
2021-12-03 01:04:16,398 iteration 5612 : loss : 0.016614, loss_ce: 0.005284
2021-12-03 01:04:17,948 iteration 5613 : loss : 0.020061, loss_ce: 0.007239
2021-12-03 01:04:19,507 iteration 5614 : loss : 0.023750, loss_ce: 0.007859
2021-12-03 01:04:21,096 iteration 5615 : loss : 0.016966, loss_ce: 0.005691
2021-12-03 01:04:22,718 iteration 5616 : loss : 0.017443, loss_ce: 0.006368
2021-12-03 01:04:24,272 iteration 5617 : loss : 0.012426, loss_ce: 0.004190
2021-12-03 01:04:25,783 iteration 5618 : loss : 0.018184, loss_ce: 0.007817
2021-12-03 01:04:27,386 iteration 5619 : loss : 0.018452, loss_ce: 0.005900
2021-12-03 01:04:29,012 iteration 5620 : loss : 0.019389, loss_ce: 0.005608
2021-12-03 01:04:30,540 iteration 5621 : loss : 0.020685, loss_ce: 0.008211
2021-12-03 01:04:32,197 iteration 5622 : loss : 0.018228, loss_ce: 0.006965
2021-12-03 01:04:33,717 iteration 5623 : loss : 0.019344, loss_ce: 0.005328
2021-12-03 01:04:35,305 iteration 5624 : loss : 0.013979, loss_ce: 0.005794
2021-12-03 01:04:36,883 iteration 5625 : loss : 0.020160, loss_ce: 0.008979
2021-12-03 01:04:38,417 iteration 5626 : loss : 0.018852, loss_ce: 0.006574
2021-12-03 01:04:39,977 iteration 5627 : loss : 0.018426, loss_ce: 0.006133
 83%|███████████████████████▉     | 331/400 [2:31:34<33:49, 29.42s/it]2021-12-03 01:04:41,481 iteration 5628 : loss : 0.014373, loss_ce: 0.005032
2021-12-03 01:04:43,067 iteration 5629 : loss : 0.015122, loss_ce: 0.006384
2021-12-03 01:04:44,620 iteration 5630 : loss : 0.012829, loss_ce: 0.003710
2021-12-03 01:04:46,312 iteration 5631 : loss : 0.021208, loss_ce: 0.009522
2021-12-03 01:04:47,790 iteration 5632 : loss : 0.015883, loss_ce: 0.006426
2021-12-03 01:04:49,402 iteration 5633 : loss : 0.022980, loss_ce: 0.008984
2021-12-03 01:04:50,895 iteration 5634 : loss : 0.018434, loss_ce: 0.005920
2021-12-03 01:04:52,487 iteration 5635 : loss : 0.018107, loss_ce: 0.005317
2021-12-03 01:04:53,981 iteration 5636 : loss : 0.012185, loss_ce: 0.004978
2021-12-03 01:04:55,564 iteration 5637 : loss : 0.017384, loss_ce: 0.007430
2021-12-03 01:04:57,003 iteration 5638 : loss : 0.013477, loss_ce: 0.004089
2021-12-03 01:04:58,509 iteration 5639 : loss : 0.018554, loss_ce: 0.005202
2021-12-03 01:05:00,025 iteration 5640 : loss : 0.015169, loss_ce: 0.007061
2021-12-03 01:05:01,587 iteration 5641 : loss : 0.014150, loss_ce: 0.007911
2021-12-03 01:05:03,131 iteration 5642 : loss : 0.018607, loss_ce: 0.003533
2021-12-03 01:05:04,742 iteration 5643 : loss : 0.016756, loss_ce: 0.005153
2021-12-03 01:05:06,347 iteration 5644 : loss : 0.018153, loss_ce: 0.006393
 83%|████████████████████████     | 332/400 [2:32:00<32:18, 28.51s/it]2021-12-03 01:05:08,106 iteration 5645 : loss : 0.020118, loss_ce: 0.008389
2021-12-03 01:05:09,632 iteration 5646 : loss : 0.018546, loss_ce: 0.007333
2021-12-03 01:05:11,196 iteration 5647 : loss : 0.019950, loss_ce: 0.008961
2021-12-03 01:05:12,798 iteration 5648 : loss : 0.023951, loss_ce: 0.007864
2021-12-03 01:05:14,405 iteration 5649 : loss : 0.017578, loss_ce: 0.007765
2021-12-03 01:05:15,983 iteration 5650 : loss : 0.014485, loss_ce: 0.005870
2021-12-03 01:05:17,537 iteration 5651 : loss : 0.020438, loss_ce: 0.010869
2021-12-03 01:05:19,008 iteration 5652 : loss : 0.014683, loss_ce: 0.005771
2021-12-03 01:05:20,555 iteration 5653 : loss : 0.014324, loss_ce: 0.005194
2021-12-03 01:05:22,019 iteration 5654 : loss : 0.014282, loss_ce: 0.003697
2021-12-03 01:05:23,574 iteration 5655 : loss : 0.018304, loss_ce: 0.007547
2021-12-03 01:05:25,116 iteration 5656 : loss : 0.012532, loss_ce: 0.004198
2021-12-03 01:05:26,670 iteration 5657 : loss : 0.019526, loss_ce: 0.008495
2021-12-03 01:05:28,242 iteration 5658 : loss : 0.020908, loss_ce: 0.012055
2021-12-03 01:05:29,778 iteration 5659 : loss : 0.018964, loss_ce: 0.004912
2021-12-03 01:05:31,273 iteration 5660 : loss : 0.012237, loss_ce: 0.004440
2021-12-03 01:05:32,952 iteration 5661 : loss : 0.018939, loss_ce: 0.006103
 83%|████████████████████████▏    | 333/400 [2:32:27<31:11, 27.94s/it]2021-12-03 01:05:34,576 iteration 5662 : loss : 0.015864, loss_ce: 0.004266
2021-12-03 01:05:36,129 iteration 5663 : loss : 0.015791, loss_ce: 0.005773
2021-12-03 01:05:37,726 iteration 5664 : loss : 0.025806, loss_ce: 0.007520
2021-12-03 01:05:39,195 iteration 5665 : loss : 0.013212, loss_ce: 0.004847
2021-12-03 01:05:40,778 iteration 5666 : loss : 0.014925, loss_ce: 0.005745
2021-12-03 01:05:42,388 iteration 5667 : loss : 0.015039, loss_ce: 0.006031
2021-12-03 01:05:43,940 iteration 5668 : loss : 0.022805, loss_ce: 0.014267
2021-12-03 01:05:45,554 iteration 5669 : loss : 0.023640, loss_ce: 0.011022
2021-12-03 01:05:47,095 iteration 5670 : loss : 0.014237, loss_ce: 0.004767
2021-12-03 01:05:48,632 iteration 5671 : loss : 0.015058, loss_ce: 0.005068
2021-12-03 01:05:50,193 iteration 5672 : loss : 0.022434, loss_ce: 0.007079
2021-12-03 01:05:51,712 iteration 5673 : loss : 0.015036, loss_ce: 0.004465
2021-12-03 01:05:53,357 iteration 5674 : loss : 0.019691, loss_ce: 0.010625
2021-12-03 01:05:54,879 iteration 5675 : loss : 0.015292, loss_ce: 0.006405
2021-12-03 01:05:56,520 iteration 5676 : loss : 0.018982, loss_ce: 0.006240
2021-12-03 01:05:58,122 iteration 5677 : loss : 0.013235, loss_ce: 0.006205
2021-12-03 01:05:59,682 iteration 5678 : loss : 0.022279, loss_ce: 0.007323
 84%|████████████████████████▏    | 334/400 [2:32:53<30:19, 27.57s/it]2021-12-03 01:06:01,300 iteration 5679 : loss : 0.021733, loss_ce: 0.008978
2021-12-03 01:06:02,748 iteration 5680 : loss : 0.013016, loss_ce: 0.003239
2021-12-03 01:06:04,369 iteration 5681 : loss : 0.021423, loss_ce: 0.007454
2021-12-03 01:06:05,977 iteration 5682 : loss : 0.022798, loss_ce: 0.010243
2021-12-03 01:06:07,486 iteration 5683 : loss : 0.012939, loss_ce: 0.004157
2021-12-03 01:06:09,006 iteration 5684 : loss : 0.011805, loss_ce: 0.006086
2021-12-03 01:06:10,555 iteration 5685 : loss : 0.016666, loss_ce: 0.007573
2021-12-03 01:06:12,069 iteration 5686 : loss : 0.016848, loss_ce: 0.006522
2021-12-03 01:06:13,633 iteration 5687 : loss : 0.012931, loss_ce: 0.005066
2021-12-03 01:06:15,306 iteration 5688 : loss : 0.036827, loss_ce: 0.015179
2021-12-03 01:06:16,878 iteration 5689 : loss : 0.034208, loss_ce: 0.007683
2021-12-03 01:06:18,457 iteration 5690 : loss : 0.017858, loss_ce: 0.007209
2021-12-03 01:06:20,060 iteration 5691 : loss : 0.020513, loss_ce: 0.008414
2021-12-03 01:06:21,640 iteration 5692 : loss : 0.020349, loss_ce: 0.009335
2021-12-03 01:06:23,203 iteration 5693 : loss : 0.030472, loss_ce: 0.006948
2021-12-03 01:06:24,744 iteration 5694 : loss : 0.016689, loss_ce: 0.007487
2021-12-03 01:06:24,745 Training Data Eval:
2021-12-03 01:06:32,404   Average segmentation loss on training set: 0.0108
2021-12-03 01:06:32,404 Validation Data Eval:
2021-12-03 01:06:35,031   Average segmentation loss on validation set: 0.0681
2021-12-03 01:06:36,541 iteration 5695 : loss : 0.014215, loss_ce: 0.004941
 84%|████████████████████████▎    | 335/400 [2:33:30<32:53, 30.36s/it]2021-12-03 01:06:38,115 iteration 5696 : loss : 0.012233, loss_ce: 0.006008
2021-12-03 01:06:39,615 iteration 5697 : loss : 0.015093, loss_ce: 0.006622
2021-12-03 01:06:41,235 iteration 5698 : loss : 0.017513, loss_ce: 0.005656
2021-12-03 01:06:42,708 iteration 5699 : loss : 0.014909, loss_ce: 0.006351
2021-12-03 01:06:44,242 iteration 5700 : loss : 0.014507, loss_ce: 0.004916
2021-12-03 01:06:45,739 iteration 5701 : loss : 0.016402, loss_ce: 0.006843
2021-12-03 01:06:47,403 iteration 5702 : loss : 0.021630, loss_ce: 0.008534
2021-12-03 01:06:49,008 iteration 5703 : loss : 0.020584, loss_ce: 0.008377
2021-12-03 01:06:50,582 iteration 5704 : loss : 0.018988, loss_ce: 0.006343
2021-12-03 01:06:52,195 iteration 5705 : loss : 0.016870, loss_ce: 0.005280
2021-12-03 01:06:53,660 iteration 5706 : loss : 0.013116, loss_ce: 0.004879
2021-12-03 01:06:55,201 iteration 5707 : loss : 0.014624, loss_ce: 0.004897
2021-12-03 01:06:56,703 iteration 5708 : loss : 0.014299, loss_ce: 0.005043
2021-12-03 01:06:58,238 iteration 5709 : loss : 0.015252, loss_ce: 0.004937
2021-12-03 01:06:59,779 iteration 5710 : loss : 0.019996, loss_ce: 0.005989
2021-12-03 01:07:01,268 iteration 5711 : loss : 0.015226, loss_ce: 0.004562
2021-12-03 01:07:02,842 iteration 5712 : loss : 0.021436, loss_ce: 0.008962
 84%|████████████████████████▎    | 336/400 [2:33:57<31:05, 29.14s/it]2021-12-03 01:07:04,517 iteration 5713 : loss : 0.020358, loss_ce: 0.006508
2021-12-03 01:07:06,126 iteration 5714 : loss : 0.019543, loss_ce: 0.006073
2021-12-03 01:07:07,750 iteration 5715 : loss : 0.014052, loss_ce: 0.005128
2021-12-03 01:07:09,289 iteration 5716 : loss : 0.017229, loss_ce: 0.006322
2021-12-03 01:07:10,947 iteration 5717 : loss : 0.020667, loss_ce: 0.009430
2021-12-03 01:07:12,452 iteration 5718 : loss : 0.016532, loss_ce: 0.005077
2021-12-03 01:07:13,958 iteration 5719 : loss : 0.015903, loss_ce: 0.007560
2021-12-03 01:07:15,569 iteration 5720 : loss : 0.015834, loss_ce: 0.006316
2021-12-03 01:07:17,140 iteration 5721 : loss : 0.021990, loss_ce: 0.011418
2021-12-03 01:07:18,699 iteration 5722 : loss : 0.019092, loss_ce: 0.008004
2021-12-03 01:07:20,234 iteration 5723 : loss : 0.017240, loss_ce: 0.006668
2021-12-03 01:07:21,801 iteration 5724 : loss : 0.018283, loss_ce: 0.005938
2021-12-03 01:07:23,357 iteration 5725 : loss : 0.016409, loss_ce: 0.006173
2021-12-03 01:07:24,844 iteration 5726 : loss : 0.018064, loss_ce: 0.004071
2021-12-03 01:07:26,384 iteration 5727 : loss : 0.015461, loss_ce: 0.004468
2021-12-03 01:07:27,888 iteration 5728 : loss : 0.016645, loss_ce: 0.005977
2021-12-03 01:07:29,472 iteration 5729 : loss : 0.017310, loss_ce: 0.006908
 84%|████████████████████████▍    | 337/400 [2:34:23<29:48, 28.39s/it]2021-12-03 01:07:31,002 iteration 5730 : loss : 0.015135, loss_ce: 0.006236
2021-12-03 01:07:32,570 iteration 5731 : loss : 0.018312, loss_ce: 0.007717
2021-12-03 01:07:34,051 iteration 5732 : loss : 0.014452, loss_ce: 0.005618
2021-12-03 01:07:35,626 iteration 5733 : loss : 0.025890, loss_ce: 0.006455
2021-12-03 01:07:37,219 iteration 5734 : loss : 0.020552, loss_ce: 0.008668
2021-12-03 01:07:38,714 iteration 5735 : loss : 0.015824, loss_ce: 0.004442
2021-12-03 01:07:40,206 iteration 5736 : loss : 0.020996, loss_ce: 0.007758
2021-12-03 01:07:41,781 iteration 5737 : loss : 0.020404, loss_ce: 0.006525
2021-12-03 01:07:43,275 iteration 5738 : loss : 0.015216, loss_ce: 0.005341
2021-12-03 01:07:44,755 iteration 5739 : loss : 0.021332, loss_ce: 0.009492
2021-12-03 01:07:46,275 iteration 5740 : loss : 0.026859, loss_ce: 0.008303
2021-12-03 01:07:47,803 iteration 5741 : loss : 0.017693, loss_ce: 0.008269
2021-12-03 01:07:49,324 iteration 5742 : loss : 0.016241, loss_ce: 0.003494
2021-12-03 01:07:50,869 iteration 5743 : loss : 0.014428, loss_ce: 0.005618
2021-12-03 01:07:52,450 iteration 5744 : loss : 0.023010, loss_ce: 0.008876
2021-12-03 01:07:54,018 iteration 5745 : loss : 0.019494, loss_ce: 0.008110
2021-12-03 01:07:55,509 iteration 5746 : loss : 0.014993, loss_ce: 0.003760
 84%|████████████████████████▌    | 338/400 [2:34:49<28:36, 27.68s/it]2021-12-03 01:07:57,082 iteration 5747 : loss : 0.016430, loss_ce: 0.006226
2021-12-03 01:07:58,628 iteration 5748 : loss : 0.022152, loss_ce: 0.008843
2021-12-03 01:08:00,150 iteration 5749 : loss : 0.021258, loss_ce: 0.008008
2021-12-03 01:08:01,679 iteration 5750 : loss : 0.016618, loss_ce: 0.005436
2021-12-03 01:08:03,152 iteration 5751 : loss : 0.015658, loss_ce: 0.004981
2021-12-03 01:08:04,643 iteration 5752 : loss : 0.015747, loss_ce: 0.004683
2021-12-03 01:08:06,211 iteration 5753 : loss : 0.015154, loss_ce: 0.006017
2021-12-03 01:08:07,784 iteration 5754 : loss : 0.022029, loss_ce: 0.006453
2021-12-03 01:08:09,317 iteration 5755 : loss : 0.011668, loss_ce: 0.003806
2021-12-03 01:08:10,824 iteration 5756 : loss : 0.016618, loss_ce: 0.006032
2021-12-03 01:08:12,250 iteration 5757 : loss : 0.012428, loss_ce: 0.004957
2021-12-03 01:08:13,817 iteration 5758 : loss : 0.024894, loss_ce: 0.009341
2021-12-03 01:08:15,385 iteration 5759 : loss : 0.015745, loss_ce: 0.006948
2021-12-03 01:08:16,985 iteration 5760 : loss : 0.017344, loss_ce: 0.008451
2021-12-03 01:08:18,582 iteration 5761 : loss : 0.018369, loss_ce: 0.006678
2021-12-03 01:08:20,041 iteration 5762 : loss : 0.016950, loss_ce: 0.007999
2021-12-03 01:08:21,590 iteration 5763 : loss : 0.013269, loss_ce: 0.005280
 85%|████████████████████████▌    | 339/400 [2:35:15<27:39, 27.20s/it]2021-12-03 01:08:23,166 iteration 5764 : loss : 0.016092, loss_ce: 0.005628
2021-12-03 01:08:24,740 iteration 5765 : loss : 0.036016, loss_ce: 0.008489
2021-12-03 01:08:26,288 iteration 5766 : loss : 0.022514, loss_ce: 0.013252
2021-12-03 01:08:27,802 iteration 5767 : loss : 0.015978, loss_ce: 0.008805
2021-12-03 01:08:29,405 iteration 5768 : loss : 0.019705, loss_ce: 0.006685
2021-12-03 01:08:30,955 iteration 5769 : loss : 0.017667, loss_ce: 0.004911
2021-12-03 01:08:32,445 iteration 5770 : loss : 0.014905, loss_ce: 0.005025
2021-12-03 01:08:33,993 iteration 5771 : loss : 0.018363, loss_ce: 0.007423
2021-12-03 01:08:35,489 iteration 5772 : loss : 0.013912, loss_ce: 0.004568
2021-12-03 01:08:36,932 iteration 5773 : loss : 0.014044, loss_ce: 0.004627
2021-12-03 01:08:38,377 iteration 5774 : loss : 0.015974, loss_ce: 0.004386
2021-12-03 01:08:39,902 iteration 5775 : loss : 0.015418, loss_ce: 0.005874
2021-12-03 01:08:41,485 iteration 5776 : loss : 0.021487, loss_ce: 0.009909
2021-12-03 01:08:42,920 iteration 5777 : loss : 0.016067, loss_ce: 0.006437
2021-12-03 01:08:44,422 iteration 5778 : loss : 0.018934, loss_ce: 0.005840
2021-12-03 01:08:45,921 iteration 5779 : loss : 0.013937, loss_ce: 0.004559
2021-12-03 01:08:45,921 Training Data Eval:
2021-12-03 01:08:53,527   Average segmentation loss on training set: 0.0101
2021-12-03 01:08:53,528 Validation Data Eval:
2021-12-03 01:08:56,149   Average segmentation loss on validation set: 0.0685
2021-12-03 01:08:57,650 iteration 5780 : loss : 0.018916, loss_ce: 0.006922
 85%|████████████████████████▋    | 340/400 [2:35:51<29:51, 29.86s/it]2021-12-03 01:08:59,204 iteration 5781 : loss : 0.017848, loss_ce: 0.004743
2021-12-03 01:09:00,767 iteration 5782 : loss : 0.020692, loss_ce: 0.008851
2021-12-03 01:09:02,267 iteration 5783 : loss : 0.017364, loss_ce: 0.006445
2021-12-03 01:09:03,827 iteration 5784 : loss : 0.017383, loss_ce: 0.009674
2021-12-03 01:09:05,312 iteration 5785 : loss : 0.013469, loss_ce: 0.005043
2021-12-03 01:09:06,803 iteration 5786 : loss : 0.017547, loss_ce: 0.009826
2021-12-03 01:09:08,296 iteration 5787 : loss : 0.018307, loss_ce: 0.006340
2021-12-03 01:09:09,913 iteration 5788 : loss : 0.022929, loss_ce: 0.008877
2021-12-03 01:09:11,435 iteration 5789 : loss : 0.013211, loss_ce: 0.004578
2021-12-03 01:09:12,955 iteration 5790 : loss : 0.014876, loss_ce: 0.004876
2021-12-03 01:09:14,441 iteration 5791 : loss : 0.015223, loss_ce: 0.005435
2021-12-03 01:09:15,980 iteration 5792 : loss : 0.019459, loss_ce: 0.006527
2021-12-03 01:09:17,588 iteration 5793 : loss : 0.017686, loss_ce: 0.006389
2021-12-03 01:09:19,108 iteration 5794 : loss : 0.016949, loss_ce: 0.006475
2021-12-03 01:09:20,604 iteration 5795 : loss : 0.015214, loss_ce: 0.005035
2021-12-03 01:09:22,072 iteration 5796 : loss : 0.011735, loss_ce: 0.003371
2021-12-03 01:09:23,607 iteration 5797 : loss : 0.018392, loss_ce: 0.006787
 85%|████████████████████████▋    | 341/400 [2:36:17<28:12, 28.69s/it]2021-12-03 01:09:25,189 iteration 5798 : loss : 0.019597, loss_ce: 0.007514
2021-12-03 01:09:26,687 iteration 5799 : loss : 0.018695, loss_ce: 0.007848
2021-12-03 01:09:28,181 iteration 5800 : loss : 0.019938, loss_ce: 0.007218
2021-12-03 01:09:29,688 iteration 5801 : loss : 0.018311, loss_ce: 0.006461
2021-12-03 01:09:31,146 iteration 5802 : loss : 0.017337, loss_ce: 0.006018
2021-12-03 01:09:32,625 iteration 5803 : loss : 0.014623, loss_ce: 0.006560
2021-12-03 01:09:34,118 iteration 5804 : loss : 0.019580, loss_ce: 0.006565
2021-12-03 01:09:35,708 iteration 5805 : loss : 0.018251, loss_ce: 0.007050
2021-12-03 01:09:37,202 iteration 5806 : loss : 0.018218, loss_ce: 0.005242
2021-12-03 01:09:38,779 iteration 5807 : loss : 0.026487, loss_ce: 0.009707
2021-12-03 01:09:40,299 iteration 5808 : loss : 0.019722, loss_ce: 0.008536
2021-12-03 01:09:41,753 iteration 5809 : loss : 0.013756, loss_ce: 0.003351
2021-12-03 01:09:43,234 iteration 5810 : loss : 0.018689, loss_ce: 0.006403
2021-12-03 01:09:44,673 iteration 5811 : loss : 0.012022, loss_ce: 0.003565
2021-12-03 01:09:46,181 iteration 5812 : loss : 0.018123, loss_ce: 0.005846
2021-12-03 01:09:47,622 iteration 5813 : loss : 0.015146, loss_ce: 0.006432
2021-12-03 01:09:49,136 iteration 5814 : loss : 0.018511, loss_ce: 0.008089
 86%|████████████████████████▊    | 342/400 [2:36:43<26:49, 27.74s/it]2021-12-03 01:09:50,647 iteration 5815 : loss : 0.012952, loss_ce: 0.004660
2021-12-03 01:09:52,131 iteration 5816 : loss : 0.014878, loss_ce: 0.006758
2021-12-03 01:09:53,609 iteration 5817 : loss : 0.013056, loss_ce: 0.004520
2021-12-03 01:09:55,027 iteration 5818 : loss : 0.015439, loss_ce: 0.006460
2021-12-03 01:09:56,615 iteration 5819 : loss : 0.017742, loss_ce: 0.006374
2021-12-03 01:09:58,170 iteration 5820 : loss : 0.020972, loss_ce: 0.010213
2021-12-03 01:09:59,603 iteration 5821 : loss : 0.014941, loss_ce: 0.004849
2021-12-03 01:10:01,077 iteration 5822 : loss : 0.012261, loss_ce: 0.005209
2021-12-03 01:10:02,677 iteration 5823 : loss : 0.018034, loss_ce: 0.007683
2021-12-03 01:10:04,180 iteration 5824 : loss : 0.018744, loss_ce: 0.005472
2021-12-03 01:10:05,720 iteration 5825 : loss : 0.017998, loss_ce: 0.006543
2021-12-03 01:10:07,251 iteration 5826 : loss : 0.021681, loss_ce: 0.005748
2021-12-03 01:10:08,755 iteration 5827 : loss : 0.020946, loss_ce: 0.006141
2021-12-03 01:10:10,345 iteration 5828 : loss : 0.024282, loss_ce: 0.007717
2021-12-03 01:10:11,825 iteration 5829 : loss : 0.013802, loss_ce: 0.005212
2021-12-03 01:10:13,292 iteration 5830 : loss : 0.017228, loss_ce: 0.006486
2021-12-03 01:10:14,775 iteration 5831 : loss : 0.016354, loss_ce: 0.005340
 86%|████████████████████████▊    | 343/400 [2:37:08<25:45, 27.11s/it]2021-12-03 01:10:16,330 iteration 5832 : loss : 0.014352, loss_ce: 0.003924
2021-12-03 01:10:17,865 iteration 5833 : loss : 0.015388, loss_ce: 0.006556
2021-12-03 01:10:19,307 iteration 5834 : loss : 0.019884, loss_ce: 0.006394
2021-12-03 01:10:20,761 iteration 5835 : loss : 0.019233, loss_ce: 0.005513
2021-12-03 01:10:22,305 iteration 5836 : loss : 0.020135, loss_ce: 0.009927
2021-12-03 01:10:23,819 iteration 5837 : loss : 0.015929, loss_ce: 0.003609
2021-12-03 01:10:25,239 iteration 5838 : loss : 0.010142, loss_ce: 0.002956
2021-12-03 01:10:26,729 iteration 5839 : loss : 0.012423, loss_ce: 0.004293
2021-12-03 01:10:28,259 iteration 5840 : loss : 0.024778, loss_ce: 0.009396
2021-12-03 01:10:29,736 iteration 5841 : loss : 0.015092, loss_ce: 0.006102
2021-12-03 01:10:31,247 iteration 5842 : loss : 0.009237, loss_ce: 0.003417
2021-12-03 01:10:32,708 iteration 5843 : loss : 0.016381, loss_ce: 0.006532
2021-12-03 01:10:34,319 iteration 5844 : loss : 0.024958, loss_ce: 0.007182
2021-12-03 01:10:35,802 iteration 5845 : loss : 0.020495, loss_ce: 0.007839
2021-12-03 01:10:37,316 iteration 5846 : loss : 0.028532, loss_ce: 0.010724
2021-12-03 01:10:38,822 iteration 5847 : loss : 0.015589, loss_ce: 0.006236
2021-12-03 01:10:40,317 iteration 5848 : loss : 0.017002, loss_ce: 0.006092
 86%|████████████████████████▉    | 344/400 [2:37:34<24:51, 26.64s/it]2021-12-03 01:10:41,902 iteration 5849 : loss : 0.015095, loss_ce: 0.005936
2021-12-03 01:10:43,317 iteration 5850 : loss : 0.013730, loss_ce: 0.005584
2021-12-03 01:10:44,812 iteration 5851 : loss : 0.016005, loss_ce: 0.006461
2021-12-03 01:10:46,295 iteration 5852 : loss : 0.017078, loss_ce: 0.006038
2021-12-03 01:10:47,722 iteration 5853 : loss : 0.013998, loss_ce: 0.004368
2021-12-03 01:10:49,193 iteration 5854 : loss : 0.022849, loss_ce: 0.007262
2021-12-03 01:10:50,750 iteration 5855 : loss : 0.018593, loss_ce: 0.007999
2021-12-03 01:10:52,252 iteration 5856 : loss : 0.013942, loss_ce: 0.005854
2021-12-03 01:10:53,759 iteration 5857 : loss : 0.015416, loss_ce: 0.005211
2021-12-03 01:10:55,185 iteration 5858 : loss : 0.014372, loss_ce: 0.005449
2021-12-03 01:10:56,708 iteration 5859 : loss : 0.020799, loss_ce: 0.008207
2021-12-03 01:10:58,230 iteration 5860 : loss : 0.014254, loss_ce: 0.003660
2021-12-03 01:10:59,693 iteration 5861 : loss : 0.013750, loss_ce: 0.004142
2021-12-03 01:11:01,195 iteration 5862 : loss : 0.014579, loss_ce: 0.006279
2021-12-03 01:11:02,609 iteration 5863 : loss : 0.014517, loss_ce: 0.005994
2021-12-03 01:11:04,122 iteration 5864 : loss : 0.018610, loss_ce: 0.005342
2021-12-03 01:11:04,122 Training Data Eval:
2021-12-03 01:11:11,699   Average segmentation loss on training set: 0.0094
2021-12-03 01:11:11,699 Validation Data Eval:
2021-12-03 01:11:14,320   Average segmentation loss on validation set: 0.0681
2021-12-03 01:11:15,774 iteration 5865 : loss : 0.024588, loss_ce: 0.007454
 86%|█████████████████████████    | 345/400 [2:38:09<26:50, 29.29s/it]2021-12-03 01:11:17,396 iteration 5866 : loss : 0.014560, loss_ce: 0.006247
2021-12-03 01:11:18,931 iteration 5867 : loss : 0.022057, loss_ce: 0.005880
2021-12-03 01:11:20,433 iteration 5868 : loss : 0.020402, loss_ce: 0.007095
2021-12-03 01:11:21,849 iteration 5869 : loss : 0.014951, loss_ce: 0.006346
2021-12-03 01:11:23,425 iteration 5870 : loss : 0.020187, loss_ce: 0.004774
2021-12-03 01:11:24,942 iteration 5871 : loss : 0.013701, loss_ce: 0.004635
2021-12-03 01:11:26,467 iteration 5872 : loss : 0.021081, loss_ce: 0.007374
2021-12-03 01:11:28,050 iteration 5873 : loss : 0.020641, loss_ce: 0.006959
2021-12-03 01:11:29,496 iteration 5874 : loss : 0.014996, loss_ce: 0.004991
2021-12-03 01:11:30,992 iteration 5875 : loss : 0.014924, loss_ce: 0.007331
2021-12-03 01:11:32,480 iteration 5876 : loss : 0.018275, loss_ce: 0.006633
2021-12-03 01:11:33,958 iteration 5877 : loss : 0.018834, loss_ce: 0.006365
2021-12-03 01:11:35,469 iteration 5878 : loss : 0.015784, loss_ce: 0.006805
2021-12-03 01:11:36,928 iteration 5879 : loss : 0.013992, loss_ce: 0.006058
2021-12-03 01:11:38,508 iteration 5880 : loss : 0.018624, loss_ce: 0.004732
2021-12-03 01:11:39,952 iteration 5881 : loss : 0.011139, loss_ce: 0.003737
2021-12-03 01:11:41,422 iteration 5882 : loss : 0.016247, loss_ce: 0.006682
 86%|█████████████████████████    | 346/400 [2:38:35<25:22, 28.20s/it]2021-12-03 01:11:42,963 iteration 5883 : loss : 0.014065, loss_ce: 0.004412
2021-12-03 01:11:44,432 iteration 5884 : loss : 0.014498, loss_ce: 0.005986
2021-12-03 01:11:46,028 iteration 5885 : loss : 0.023466, loss_ce: 0.009099
2021-12-03 01:11:47,466 iteration 5886 : loss : 0.016480, loss_ce: 0.005712
2021-12-03 01:11:48,936 iteration 5887 : loss : 0.013613, loss_ce: 0.005331
2021-12-03 01:11:50,500 iteration 5888 : loss : 0.017656, loss_ce: 0.005946
2021-12-03 01:11:52,049 iteration 5889 : loss : 0.019576, loss_ce: 0.008389
2021-12-03 01:11:53,537 iteration 5890 : loss : 0.012180, loss_ce: 0.003903
2021-12-03 01:11:55,081 iteration 5891 : loss : 0.020320, loss_ce: 0.006538
2021-12-03 01:11:56,647 iteration 5892 : loss : 0.017263, loss_ce: 0.006709
2021-12-03 01:11:58,098 iteration 5893 : loss : 0.012342, loss_ce: 0.003906
2021-12-03 01:11:59,662 iteration 5894 : loss : 0.023568, loss_ce: 0.010288
2021-12-03 01:12:01,160 iteration 5895 : loss : 0.019180, loss_ce: 0.007120
2021-12-03 01:12:02,640 iteration 5896 : loss : 0.013634, loss_ce: 0.006698
2021-12-03 01:12:04,182 iteration 5897 : loss : 0.022342, loss_ce: 0.008366
2021-12-03 01:12:05,699 iteration 5898 : loss : 0.012955, loss_ce: 0.004264
2021-12-03 01:12:07,156 iteration 5899 : loss : 0.016710, loss_ce: 0.006072
 87%|█████████████████████████▏   | 347/400 [2:39:01<24:15, 27.45s/it]2021-12-03 01:12:08,707 iteration 5900 : loss : 0.016744, loss_ce: 0.005250
2021-12-03 01:12:10,243 iteration 5901 : loss : 0.019072, loss_ce: 0.006433
2021-12-03 01:12:11,739 iteration 5902 : loss : 0.015306, loss_ce: 0.005959
2021-12-03 01:12:13,292 iteration 5903 : loss : 0.022833, loss_ce: 0.009466
2021-12-03 01:12:14,784 iteration 5904 : loss : 0.021568, loss_ce: 0.007637
2021-12-03 01:12:16,320 iteration 5905 : loss : 0.019480, loss_ce: 0.004887
2021-12-03 01:12:17,767 iteration 5906 : loss : 0.015717, loss_ce: 0.006014
2021-12-03 01:12:19,288 iteration 5907 : loss : 0.013104, loss_ce: 0.004401
2021-12-03 01:12:20,784 iteration 5908 : loss : 0.013216, loss_ce: 0.004524
2021-12-03 01:12:22,194 iteration 5909 : loss : 0.023152, loss_ce: 0.005958
2021-12-03 01:12:23,723 iteration 5910 : loss : 0.023014, loss_ce: 0.007994
2021-12-03 01:12:25,252 iteration 5911 : loss : 0.020151, loss_ce: 0.009778
2021-12-03 01:12:26,690 iteration 5912 : loss : 0.016866, loss_ce: 0.005086
2021-12-03 01:12:28,149 iteration 5913 : loss : 0.018968, loss_ce: 0.009980
2021-12-03 01:12:29,643 iteration 5914 : loss : 0.016150, loss_ce: 0.005787
2021-12-03 01:12:31,050 iteration 5915 : loss : 0.013626, loss_ce: 0.005225
2021-12-03 01:12:32,576 iteration 5916 : loss : 0.032307, loss_ce: 0.011260
 87%|█████████████████████████▏   | 348/400 [2:39:26<23:15, 26.84s/it]2021-12-03 01:12:34,098 iteration 5917 : loss : 0.014832, loss_ce: 0.005651
2021-12-03 01:12:35,526 iteration 5918 : loss : 0.016597, loss_ce: 0.006479
2021-12-03 01:12:37,041 iteration 5919 : loss : 0.019457, loss_ce: 0.008492
2021-12-03 01:12:38,579 iteration 5920 : loss : 0.021836, loss_ce: 0.011396
2021-12-03 01:12:40,189 iteration 5921 : loss : 0.032755, loss_ce: 0.008918
2021-12-03 01:12:41,648 iteration 5922 : loss : 0.013783, loss_ce: 0.003462
2021-12-03 01:12:43,136 iteration 5923 : loss : 0.017692, loss_ce: 0.005415
2021-12-03 01:12:44,702 iteration 5924 : loss : 0.023939, loss_ce: 0.004490
2021-12-03 01:12:46,192 iteration 5925 : loss : 0.015919, loss_ce: 0.005206
2021-12-03 01:12:47,678 iteration 5926 : loss : 0.017270, loss_ce: 0.006808
2021-12-03 01:12:49,204 iteration 5927 : loss : 0.013017, loss_ce: 0.004913
2021-12-03 01:12:50,658 iteration 5928 : loss : 0.019141, loss_ce: 0.004830
2021-12-03 01:12:52,108 iteration 5929 : loss : 0.013750, loss_ce: 0.006226
2021-12-03 01:12:53,559 iteration 5930 : loss : 0.017095, loss_ce: 0.007133
2021-12-03 01:12:55,060 iteration 5931 : loss : 0.022249, loss_ce: 0.005491
2021-12-03 01:12:56,590 iteration 5932 : loss : 0.015952, loss_ce: 0.005381
2021-12-03 01:12:58,049 iteration 5933 : loss : 0.017643, loss_ce: 0.007180
 87%|█████████████████████████▎   | 349/400 [2:39:52<22:27, 26.43s/it]2021-12-03 01:12:59,527 iteration 5934 : loss : 0.019467, loss_ce: 0.006464
2021-12-03 01:13:01,116 iteration 5935 : loss : 0.020135, loss_ce: 0.007708
2021-12-03 01:13:02,592 iteration 5936 : loss : 0.012084, loss_ce: 0.004725
2021-12-03 01:13:04,051 iteration 5937 : loss : 0.017665, loss_ce: 0.006102
2021-12-03 01:13:05,477 iteration 5938 : loss : 0.010570, loss_ce: 0.003909
2021-12-03 01:13:07,002 iteration 5939 : loss : 0.015881, loss_ce: 0.006697
2021-12-03 01:13:08,422 iteration 5940 : loss : 0.013711, loss_ce: 0.005456
2021-12-03 01:13:09,872 iteration 5941 : loss : 0.016714, loss_ce: 0.006720
2021-12-03 01:13:11,336 iteration 5942 : loss : 0.019584, loss_ce: 0.010226
2021-12-03 01:13:12,822 iteration 5943 : loss : 0.017313, loss_ce: 0.004900
2021-12-03 01:13:14,310 iteration 5944 : loss : 0.013447, loss_ce: 0.006670
2021-12-03 01:13:15,783 iteration 5945 : loss : 0.013809, loss_ce: 0.003244
2021-12-03 01:13:17,377 iteration 5946 : loss : 0.020410, loss_ce: 0.007787
2021-12-03 01:13:18,876 iteration 5947 : loss : 0.021706, loss_ce: 0.008115
2021-12-03 01:13:20,329 iteration 5948 : loss : 0.019913, loss_ce: 0.007108
2021-12-03 01:13:21,877 iteration 5949 : loss : 0.016819, loss_ce: 0.006124
2021-12-03 01:13:21,878 Training Data Eval:
2021-12-03 01:13:29,361   Average segmentation loss on training set: 0.0097
2021-12-03 01:13:29,362 Validation Data Eval:
2021-12-03 01:13:31,983   Average segmentation loss on validation set: 0.0740
2021-12-03 01:13:33,503 iteration 5950 : loss : 0.022046, loss_ce: 0.006680
2021-12-03 01:13:35,495 save model to ../model/TU_RUNMC256/TU_pretrain_R50-ViT-B_16_skip3_bs16_256/1channelepoch_349.pth
 88%|█████████████████████████▍   | 350/400 [2:40:29<24:46, 29.72s/it]2021-12-03 01:13:36,900 iteration 5951 : loss : 0.015624, loss_ce: 0.005507
2021-12-03 01:13:38,303 iteration 5952 : loss : 0.017312, loss_ce: 0.006501
2021-12-03 01:13:39,709 iteration 5953 : loss : 0.019020, loss_ce: 0.007649
2021-12-03 01:13:41,080 iteration 5954 : loss : 0.017633, loss_ce: 0.006416
2021-12-03 01:13:42,477 iteration 5955 : loss : 0.016139, loss_ce: 0.005447
2021-12-03 01:13:43,938 iteration 5956 : loss : 0.025096, loss_ce: 0.013465
2021-12-03 01:13:45,406 iteration 5957 : loss : 0.014158, loss_ce: 0.005809
2021-12-03 01:13:46,861 iteration 5958 : loss : 0.013369, loss_ce: 0.004709
2021-12-03 01:13:48,359 iteration 5959 : loss : 0.017760, loss_ce: 0.006909
2021-12-03 01:13:49,819 iteration 5960 : loss : 0.015310, loss_ce: 0.004521
2021-12-03 01:13:51,277 iteration 5961 : loss : 0.023113, loss_ce: 0.005520
2021-12-03 01:13:52,761 iteration 5962 : loss : 0.016321, loss_ce: 0.003462
2021-12-03 01:13:54,255 iteration 5963 : loss : 0.020107, loss_ce: 0.008339
2021-12-03 01:13:55,709 iteration 5964 : loss : 0.013160, loss_ce: 0.005586
2021-12-03 01:13:57,145 iteration 5965 : loss : 0.012707, loss_ce: 0.005632
2021-12-03 01:13:58,687 iteration 5966 : loss : 0.022858, loss_ce: 0.006220
2021-12-03 01:14:00,184 iteration 5967 : loss : 0.016681, loss_ce: 0.006705
 88%|█████████████████████████▍   | 351/400 [2:40:54<23:03, 28.23s/it]2021-12-03 01:14:01,793 iteration 5968 : loss : 0.017947, loss_ce: 0.006721
2021-12-03 01:14:03,250 iteration 5969 : loss : 0.017482, loss_ce: 0.007206
2021-12-03 01:14:04,776 iteration 5970 : loss : 0.018816, loss_ce: 0.007714
2021-12-03 01:14:06,187 iteration 5971 : loss : 0.013237, loss_ce: 0.003717
2021-12-03 01:14:07,585 iteration 5972 : loss : 0.012449, loss_ce: 0.003896
2021-12-03 01:14:09,086 iteration 5973 : loss : 0.020828, loss_ce: 0.010316
2021-12-03 01:14:10,655 iteration 5974 : loss : 0.027676, loss_ce: 0.010210
2021-12-03 01:14:12,072 iteration 5975 : loss : 0.015500, loss_ce: 0.005591
2021-12-03 01:14:13,529 iteration 5976 : loss : 0.016879, loss_ce: 0.004876
2021-12-03 01:14:14,961 iteration 5977 : loss : 0.016220, loss_ce: 0.004615
2021-12-03 01:14:16,397 iteration 5978 : loss : 0.013291, loss_ce: 0.005776
2021-12-03 01:14:17,863 iteration 5979 : loss : 0.013358, loss_ce: 0.006877
2021-12-03 01:14:19,374 iteration 5980 : loss : 0.013230, loss_ce: 0.004398
2021-12-03 01:14:20,806 iteration 5981 : loss : 0.018248, loss_ce: 0.007767
2021-12-03 01:14:22,277 iteration 5982 : loss : 0.019229, loss_ce: 0.007878
2021-12-03 01:14:23,799 iteration 5983 : loss : 0.016943, loss_ce: 0.005089
2021-12-03 01:14:25,257 iteration 5984 : loss : 0.017989, loss_ce: 0.006697
 88%|█████████████████████████▌   | 352/400 [2:41:19<21:49, 27.28s/it]2021-12-03 01:14:26,797 iteration 5985 : loss : 0.013773, loss_ce: 0.003698
2021-12-03 01:14:28,205 iteration 5986 : loss : 0.012512, loss_ce: 0.004026
2021-12-03 01:14:29,716 iteration 5987 : loss : 0.020095, loss_ce: 0.007563
2021-12-03 01:14:31,241 iteration 5988 : loss : 0.020210, loss_ce: 0.009125
2021-12-03 01:14:32,732 iteration 5989 : loss : 0.013825, loss_ce: 0.005337
2021-12-03 01:14:34,202 iteration 5990 : loss : 0.013749, loss_ce: 0.004648
2021-12-03 01:14:35,718 iteration 5991 : loss : 0.022436, loss_ce: 0.007656
2021-12-03 01:14:37,206 iteration 5992 : loss : 0.021355, loss_ce: 0.006905
2021-12-03 01:14:38,670 iteration 5993 : loss : 0.014260, loss_ce: 0.006478
2021-12-03 01:14:40,183 iteration 5994 : loss : 0.017694, loss_ce: 0.007597
2021-12-03 01:14:41,649 iteration 5995 : loss : 0.014628, loss_ce: 0.005385
2021-12-03 01:14:43,080 iteration 5996 : loss : 0.012130, loss_ce: 0.003581
2021-12-03 01:14:44,566 iteration 5997 : loss : 0.019426, loss_ce: 0.007476
2021-12-03 01:14:46,112 iteration 5998 : loss : 0.016888, loss_ce: 0.005662
2021-12-03 01:14:47,678 iteration 5999 : loss : 0.019706, loss_ce: 0.007993
2021-12-03 01:14:49,170 iteration 6000 : loss : 0.015504, loss_ce: 0.006307
2021-12-03 01:14:50,573 iteration 6001 : loss : 0.014395, loss_ce: 0.007014
 88%|█████████████████████████▌   | 353/400 [2:41:44<20:54, 26.69s/it]2021-12-03 01:14:52,116 iteration 6002 : loss : 0.019363, loss_ce: 0.006596
2021-12-03 01:14:53,564 iteration 6003 : loss : 0.014967, loss_ce: 0.005525
2021-12-03 01:14:55,073 iteration 6004 : loss : 0.019186, loss_ce: 0.008380
2021-12-03 01:14:56,584 iteration 6005 : loss : 0.019298, loss_ce: 0.006834
2021-12-03 01:14:58,153 iteration 6006 : loss : 0.018369, loss_ce: 0.007229
2021-12-03 01:14:59,664 iteration 6007 : loss : 0.012787, loss_ce: 0.004933
2021-12-03 01:15:01,159 iteration 6008 : loss : 0.016849, loss_ce: 0.005860
2021-12-03 01:15:02,564 iteration 6009 : loss : 0.016439, loss_ce: 0.007452
2021-12-03 01:15:04,000 iteration 6010 : loss : 0.012772, loss_ce: 0.005191
2021-12-03 01:15:05,515 iteration 6011 : loss : 0.017439, loss_ce: 0.006069
2021-12-03 01:15:07,063 iteration 6012 : loss : 0.023732, loss_ce: 0.004830
2021-12-03 01:15:08,572 iteration 6013 : loss : 0.020593, loss_ce: 0.006316
2021-12-03 01:15:10,072 iteration 6014 : loss : 0.025432, loss_ce: 0.006638
2021-12-03 01:15:11,538 iteration 6015 : loss : 0.016192, loss_ce: 0.006290
2021-12-03 01:15:13,038 iteration 6016 : loss : 0.014973, loss_ce: 0.005547
2021-12-03 01:15:14,518 iteration 6017 : loss : 0.016726, loss_ce: 0.007285
2021-12-03 01:15:16,016 iteration 6018 : loss : 0.019367, loss_ce: 0.007169
 88%|█████████████████████████▋   | 354/400 [2:42:10<20:10, 26.32s/it]2021-12-03 01:15:17,546 iteration 6019 : loss : 0.022003, loss_ce: 0.009573
2021-12-03 01:15:19,007 iteration 6020 : loss : 0.012318, loss_ce: 0.005406
2021-12-03 01:15:20,506 iteration 6021 : loss : 0.020696, loss_ce: 0.004850
2021-12-03 01:15:21,949 iteration 6022 : loss : 0.011685, loss_ce: 0.004797
2021-12-03 01:15:23,467 iteration 6023 : loss : 0.015285, loss_ce: 0.006002
2021-12-03 01:15:24,928 iteration 6024 : loss : 0.016833, loss_ce: 0.005481
2021-12-03 01:15:26,384 iteration 6025 : loss : 0.014420, loss_ce: 0.005343
2021-12-03 01:15:27,887 iteration 6026 : loss : 0.015564, loss_ce: 0.005022
2021-12-03 01:15:29,361 iteration 6027 : loss : 0.014898, loss_ce: 0.005394
2021-12-03 01:15:30,871 iteration 6028 : loss : 0.017328, loss_ce: 0.008393
2021-12-03 01:15:32,345 iteration 6029 : loss : 0.017060, loss_ce: 0.004509
2021-12-03 01:15:33,751 iteration 6030 : loss : 0.014808, loss_ce: 0.006590
2021-12-03 01:15:35,260 iteration 6031 : loss : 0.014041, loss_ce: 0.006611
2021-12-03 01:15:36,703 iteration 6032 : loss : 0.016185, loss_ce: 0.004921
2021-12-03 01:15:38,228 iteration 6033 : loss : 0.017444, loss_ce: 0.006606
2021-12-03 01:15:39,710 iteration 6034 : loss : 0.020579, loss_ce: 0.007264
2021-12-03 01:15:39,711 Training Data Eval:
2021-12-03 01:15:47,193   Average segmentation loss on training set: 0.0089
2021-12-03 01:15:47,194 Validation Data Eval:
2021-12-03 01:15:49,783   Average segmentation loss on validation set: 0.0701
2021-12-03 01:15:51,181 iteration 6035 : loss : 0.012667, loss_ce: 0.004562
 89%|█████████████████████████▋   | 355/400 [2:42:45<21:43, 28.97s/it]2021-12-03 01:15:52,827 iteration 6036 : loss : 0.017442, loss_ce: 0.004371
2021-12-03 01:15:54,352 iteration 6037 : loss : 0.016352, loss_ce: 0.005118
2021-12-03 01:15:55,819 iteration 6038 : loss : 0.016240, loss_ce: 0.005988
2021-12-03 01:15:57,275 iteration 6039 : loss : 0.016187, loss_ce: 0.005266
2021-12-03 01:15:58,773 iteration 6040 : loss : 0.016011, loss_ce: 0.005956
2021-12-03 01:16:00,224 iteration 6041 : loss : 0.013900, loss_ce: 0.004630
2021-12-03 01:16:01,708 iteration 6042 : loss : 0.012762, loss_ce: 0.005704
2021-12-03 01:16:03,143 iteration 6043 : loss : 0.011564, loss_ce: 0.005071
2021-12-03 01:16:04,589 iteration 6044 : loss : 0.012158, loss_ce: 0.004942
2021-12-03 01:16:06,147 iteration 6045 : loss : 0.019617, loss_ce: 0.007551
2021-12-03 01:16:07,574 iteration 6046 : loss : 0.014322, loss_ce: 0.005986
2021-12-03 01:16:08,995 iteration 6047 : loss : 0.011276, loss_ce: 0.004552
2021-12-03 01:16:10,535 iteration 6048 : loss : 0.019773, loss_ce: 0.005816
2021-12-03 01:16:11,958 iteration 6049 : loss : 0.015186, loss_ce: 0.004849
2021-12-03 01:16:13,399 iteration 6050 : loss : 0.015900, loss_ce: 0.004187
2021-12-03 01:16:14,831 iteration 6051 : loss : 0.011313, loss_ce: 0.004488
2021-12-03 01:16:16,333 iteration 6052 : loss : 0.011006, loss_ce: 0.003772
 89%|█████████████████████████▊   | 356/400 [2:43:10<20:24, 27.82s/it]2021-12-03 01:16:17,837 iteration 6053 : loss : 0.013856, loss_ce: 0.003905
2021-12-03 01:16:19,287 iteration 6054 : loss : 0.015259, loss_ce: 0.004962
2021-12-03 01:16:20,768 iteration 6055 : loss : 0.021118, loss_ce: 0.009187
2021-12-03 01:16:22,224 iteration 6056 : loss : 0.015344, loss_ce: 0.005148
2021-12-03 01:16:23,628 iteration 6057 : loss : 0.016864, loss_ce: 0.005981
2021-12-03 01:16:25,080 iteration 6058 : loss : 0.011106, loss_ce: 0.005764
2021-12-03 01:16:26,622 iteration 6059 : loss : 0.015730, loss_ce: 0.004713
2021-12-03 01:16:28,120 iteration 6060 : loss : 0.018442, loss_ce: 0.004941
2021-12-03 01:16:29,586 iteration 6061 : loss : 0.016704, loss_ce: 0.008033
2021-12-03 01:16:31,180 iteration 6062 : loss : 0.020054, loss_ce: 0.007364
2021-12-03 01:16:32,615 iteration 6063 : loss : 0.014186, loss_ce: 0.006056
2021-12-03 01:16:34,063 iteration 6064 : loss : 0.010455, loss_ce: 0.003447
2021-12-03 01:16:35,557 iteration 6065 : loss : 0.024542, loss_ce: 0.010262
2021-12-03 01:16:36,978 iteration 6066 : loss : 0.022969, loss_ce: 0.008978
2021-12-03 01:16:38,470 iteration 6067 : loss : 0.023771, loss_ce: 0.008187
2021-12-03 01:16:39,940 iteration 6068 : loss : 0.015754, loss_ce: 0.002729
2021-12-03 01:16:41,459 iteration 6069 : loss : 0.017571, loss_ce: 0.007829
 89%|█████████████████████████▉   | 357/400 [2:43:35<19:21, 27.02s/it]2021-12-03 01:16:42,977 iteration 6070 : loss : 0.018431, loss_ce: 0.007739
2021-12-03 01:16:44,441 iteration 6071 : loss : 0.015244, loss_ce: 0.005986
2021-12-03 01:16:45,902 iteration 6072 : loss : 0.016909, loss_ce: 0.005659
2021-12-03 01:16:47,379 iteration 6073 : loss : 0.024352, loss_ce: 0.006817
2021-12-03 01:16:48,785 iteration 6074 : loss : 0.014465, loss_ce: 0.006619
2021-12-03 01:16:50,289 iteration 6075 : loss : 0.021053, loss_ce: 0.009039
2021-12-03 01:16:51,762 iteration 6076 : loss : 0.013907, loss_ce: 0.005467
2021-12-03 01:16:53,151 iteration 6077 : loss : 0.011781, loss_ce: 0.004085
2021-12-03 01:16:54,618 iteration 6078 : loss : 0.016613, loss_ce: 0.008579
2021-12-03 01:16:56,139 iteration 6079 : loss : 0.013487, loss_ce: 0.005030
2021-12-03 01:16:57,543 iteration 6080 : loss : 0.013564, loss_ce: 0.004598
2021-12-03 01:16:59,086 iteration 6081 : loss : 0.018415, loss_ce: 0.007767
2021-12-03 01:17:00,529 iteration 6082 : loss : 0.017525, loss_ce: 0.004630
2021-12-03 01:17:02,074 iteration 6083 : loss : 0.010828, loss_ce: 0.003066
2021-12-03 01:17:03,497 iteration 6084 : loss : 0.014685, loss_ce: 0.004032
2021-12-03 01:17:04,933 iteration 6085 : loss : 0.022092, loss_ce: 0.008517
2021-12-03 01:17:06,538 iteration 6086 : loss : 0.024953, loss_ce: 0.005891
 90%|█████████████████████████▉   | 358/400 [2:44:00<18:30, 26.43s/it]2021-12-03 01:17:08,008 iteration 6087 : loss : 0.015342, loss_ce: 0.006053
2021-12-03 01:17:09,488 iteration 6088 : loss : 0.014619, loss_ce: 0.006486
2021-12-03 01:17:10,945 iteration 6089 : loss : 0.018287, loss_ce: 0.008751
2021-12-03 01:17:12,414 iteration 6090 : loss : 0.014535, loss_ce: 0.003621
2021-12-03 01:17:13,895 iteration 6091 : loss : 0.017235, loss_ce: 0.007069
2021-12-03 01:17:15,378 iteration 6092 : loss : 0.010780, loss_ce: 0.004148
2021-12-03 01:17:16,787 iteration 6093 : loss : 0.013461, loss_ce: 0.004296
2021-12-03 01:17:18,213 iteration 6094 : loss : 0.013390, loss_ce: 0.004624
2021-12-03 01:17:19,707 iteration 6095 : loss : 0.016421, loss_ce: 0.006648
2021-12-03 01:17:21,185 iteration 6096 : loss : 0.016407, loss_ce: 0.005201
2021-12-03 01:17:22,605 iteration 6097 : loss : 0.011814, loss_ce: 0.005153
2021-12-03 01:17:24,084 iteration 6098 : loss : 0.020889, loss_ce: 0.008242
2021-12-03 01:17:25,601 iteration 6099 : loss : 0.020082, loss_ce: 0.004493
2021-12-03 01:17:27,134 iteration 6100 : loss : 0.022306, loss_ce: 0.007621
2021-12-03 01:17:28,635 iteration 6101 : loss : 0.011691, loss_ce: 0.004215
2021-12-03 01:17:30,082 iteration 6102 : loss : 0.015058, loss_ce: 0.004818
2021-12-03 01:17:31,477 iteration 6103 : loss : 0.009936, loss_ce: 0.003558
 90%|██████████████████████████   | 359/400 [2:44:25<17:45, 25.99s/it]2021-12-03 01:17:33,033 iteration 6104 : loss : 0.018835, loss_ce: 0.005356
2021-12-03 01:17:34,454 iteration 6105 : loss : 0.017377, loss_ce: 0.006134
2021-12-03 01:17:35,842 iteration 6106 : loss : 0.017274, loss_ce: 0.005259
2021-12-03 01:17:37,271 iteration 6107 : loss : 0.016070, loss_ce: 0.005200
2021-12-03 01:17:38,792 iteration 6108 : loss : 0.016454, loss_ce: 0.004887
2021-12-03 01:17:40,234 iteration 6109 : loss : 0.013523, loss_ce: 0.004693
2021-12-03 01:17:41,718 iteration 6110 : loss : 0.011187, loss_ce: 0.004386
2021-12-03 01:17:43,238 iteration 6111 : loss : 0.019280, loss_ce: 0.007011
2021-12-03 01:17:44,732 iteration 6112 : loss : 0.016276, loss_ce: 0.005851
2021-12-03 01:17:46,248 iteration 6113 : loss : 0.018135, loss_ce: 0.005945
2021-12-03 01:17:47,704 iteration 6114 : loss : 0.021239, loss_ce: 0.009483
2021-12-03 01:17:49,258 iteration 6115 : loss : 0.019205, loss_ce: 0.006493
2021-12-03 01:17:50,742 iteration 6116 : loss : 0.015043, loss_ce: 0.006660
2021-12-03 01:17:52,175 iteration 6117 : loss : 0.017322, loss_ce: 0.007068
2021-12-03 01:17:53,678 iteration 6118 : loss : 0.015653, loss_ce: 0.006811
2021-12-03 01:17:55,138 iteration 6119 : loss : 0.020307, loss_ce: 0.007318
2021-12-03 01:17:55,138 Training Data Eval:
2021-12-03 01:18:02,580   Average segmentation loss on training set: 0.0090
2021-12-03 01:18:02,580 Validation Data Eval:
2021-12-03 01:18:05,155   Average segmentation loss on validation set: 0.0741
2021-12-03 01:18:06,625 iteration 6120 : loss : 0.016185, loss_ce: 0.007448
 90%|██████████████████████████   | 360/400 [2:45:00<19:09, 28.74s/it]2021-12-03 01:18:08,177 iteration 6121 : loss : 0.016695, loss_ce: 0.007716
2021-12-03 01:18:09,701 iteration 6122 : loss : 0.016923, loss_ce: 0.005662
2021-12-03 01:18:11,244 iteration 6123 : loss : 0.017410, loss_ce: 0.006732
2021-12-03 01:18:12,727 iteration 6124 : loss : 0.015543, loss_ce: 0.004368
2021-12-03 01:18:14,281 iteration 6125 : loss : 0.017976, loss_ce: 0.005939
2021-12-03 01:18:15,734 iteration 6126 : loss : 0.025920, loss_ce: 0.005519
2021-12-03 01:18:17,155 iteration 6127 : loss : 0.013000, loss_ce: 0.005090
2021-12-03 01:18:18,686 iteration 6128 : loss : 0.018984, loss_ce: 0.005720
2021-12-03 01:18:20,159 iteration 6129 : loss : 0.013335, loss_ce: 0.005723
2021-12-03 01:18:21,716 iteration 6130 : loss : 0.017628, loss_ce: 0.007972
2021-12-03 01:18:23,203 iteration 6131 : loss : 0.019881, loss_ce: 0.009734
2021-12-03 01:18:24,684 iteration 6132 : loss : 0.019773, loss_ce: 0.004398
2021-12-03 01:18:26,119 iteration 6133 : loss : 0.012609, loss_ce: 0.006292
2021-12-03 01:18:27,511 iteration 6134 : loss : 0.010911, loss_ce: 0.004484
2021-12-03 01:18:28,938 iteration 6135 : loss : 0.012503, loss_ce: 0.004953
2021-12-03 01:18:30,428 iteration 6136 : loss : 0.018911, loss_ce: 0.005490
2021-12-03 01:18:31,890 iteration 6137 : loss : 0.015405, loss_ce: 0.005265
 90%|██████████████████████████▏  | 361/400 [2:45:26<18:00, 27.70s/it]2021-12-03 01:18:33,376 iteration 6138 : loss : 0.013693, loss_ce: 0.005454
2021-12-03 01:18:34,881 iteration 6139 : loss : 0.015389, loss_ce: 0.006350
2021-12-03 01:18:36,331 iteration 6140 : loss : 0.011522, loss_ce: 0.003985
2021-12-03 01:18:37,832 iteration 6141 : loss : 0.013481, loss_ce: 0.004840
2021-12-03 01:18:39,426 iteration 6142 : loss : 0.017797, loss_ce: 0.006462
2021-12-03 01:18:40,820 iteration 6143 : loss : 0.015101, loss_ce: 0.006840
2021-12-03 01:18:42,313 iteration 6144 : loss : 0.014770, loss_ce: 0.006972
2021-12-03 01:18:43,802 iteration 6145 : loss : 0.017481, loss_ce: 0.006502
2021-12-03 01:18:45,259 iteration 6146 : loss : 0.015582, loss_ce: 0.006578
2021-12-03 01:18:46,720 iteration 6147 : loss : 0.015589, loss_ce: 0.003857
2021-12-03 01:18:48,149 iteration 6148 : loss : 0.010579, loss_ce: 0.003529
2021-12-03 01:18:49,580 iteration 6149 : loss : 0.016809, loss_ce: 0.005747
2021-12-03 01:18:51,005 iteration 6150 : loss : 0.018394, loss_ce: 0.005663
2021-12-03 01:18:52,475 iteration 6151 : loss : 0.024152, loss_ce: 0.005338
2021-12-03 01:18:53,910 iteration 6152 : loss : 0.016263, loss_ce: 0.006008
2021-12-03 01:18:55,418 iteration 6153 : loss : 0.018988, loss_ce: 0.009152
2021-12-03 01:18:56,966 iteration 6154 : loss : 0.019339, loss_ce: 0.007899
 90%|██████████████████████████▏  | 362/400 [2:45:51<17:02, 26.91s/it]2021-12-03 01:18:58,468 iteration 6155 : loss : 0.021828, loss_ce: 0.009138
2021-12-03 01:18:59,915 iteration 6156 : loss : 0.012191, loss_ce: 0.005001
2021-12-03 01:19:01,417 iteration 6157 : loss : 0.016886, loss_ce: 0.005760
2021-12-03 01:19:02,865 iteration 6158 : loss : 0.014907, loss_ce: 0.004648
2021-12-03 01:19:04,256 iteration 6159 : loss : 0.010512, loss_ce: 0.004099
2021-12-03 01:19:05,909 iteration 6160 : loss : 0.017207, loss_ce: 0.007753
2021-12-03 01:19:07,295 iteration 6161 : loss : 0.016265, loss_ce: 0.005072
2021-12-03 01:19:08,777 iteration 6162 : loss : 0.011686, loss_ce: 0.004202
2021-12-03 01:19:10,238 iteration 6163 : loss : 0.012132, loss_ce: 0.004435
2021-12-03 01:19:11,672 iteration 6164 : loss : 0.014186, loss_ce: 0.003982
2021-12-03 01:19:13,145 iteration 6165 : loss : 0.013258, loss_ce: 0.004838
2021-12-03 01:19:14,636 iteration 6166 : loss : 0.018356, loss_ce: 0.007536
2021-12-03 01:19:16,046 iteration 6167 : loss : 0.011521, loss_ce: 0.003457
2021-12-03 01:19:17,609 iteration 6168 : loss : 0.026122, loss_ce: 0.008207
2021-12-03 01:19:19,070 iteration 6169 : loss : 0.014226, loss_ce: 0.005720
2021-12-03 01:19:20,562 iteration 6170 : loss : 0.014125, loss_ce: 0.006228
2021-12-03 01:19:22,006 iteration 6171 : loss : 0.016062, loss_ce: 0.004235
 91%|██████████████████████████▎  | 363/400 [2:46:16<16:14, 26.35s/it]2021-12-03 01:19:23,516 iteration 6172 : loss : 0.016876, loss_ce: 0.006674
2021-12-03 01:19:24,895 iteration 6173 : loss : 0.011406, loss_ce: 0.003800
2021-12-03 01:19:26,352 iteration 6174 : loss : 0.015956, loss_ce: 0.007813
2021-12-03 01:19:27,773 iteration 6175 : loss : 0.013026, loss_ce: 0.003723
2021-12-03 01:19:29,256 iteration 6176 : loss : 0.015437, loss_ce: 0.007863
2021-12-03 01:19:30,809 iteration 6177 : loss : 0.016891, loss_ce: 0.008233
2021-12-03 01:19:32,321 iteration 6178 : loss : 0.019051, loss_ce: 0.006986
2021-12-03 01:19:33,808 iteration 6179 : loss : 0.017522, loss_ce: 0.005473
2021-12-03 01:19:35,307 iteration 6180 : loss : 0.022906, loss_ce: 0.003187
2021-12-03 01:19:36,749 iteration 6181 : loss : 0.017633, loss_ce: 0.006787
2021-12-03 01:19:38,219 iteration 6182 : loss : 0.011825, loss_ce: 0.004634
2021-12-03 01:19:39,651 iteration 6183 : loss : 0.016195, loss_ce: 0.005800
2021-12-03 01:19:41,094 iteration 6184 : loss : 0.012560, loss_ce: 0.004577
2021-12-03 01:19:42,594 iteration 6185 : loss : 0.017008, loss_ce: 0.005120
2021-12-03 01:19:44,003 iteration 6186 : loss : 0.012307, loss_ce: 0.004401
2021-12-03 01:19:45,408 iteration 6187 : loss : 0.016664, loss_ce: 0.004986
2021-12-03 01:19:46,821 iteration 6188 : loss : 0.017713, loss_ce: 0.007827
 91%|██████████████████████████▍  | 364/400 [2:46:40<15:31, 25.89s/it]2021-12-03 01:19:48,412 iteration 6189 : loss : 0.019449, loss_ce: 0.007753
2021-12-03 01:19:49,864 iteration 6190 : loss : 0.013806, loss_ce: 0.005355
2021-12-03 01:19:51,373 iteration 6191 : loss : 0.011513, loss_ce: 0.003307
2021-12-03 01:19:52,869 iteration 6192 : loss : 0.013638, loss_ce: 0.004787
2021-12-03 01:19:54,303 iteration 6193 : loss : 0.012129, loss_ce: 0.003652
2021-12-03 01:19:55,837 iteration 6194 : loss : 0.019103, loss_ce: 0.007659
2021-12-03 01:19:57,364 iteration 6195 : loss : 0.017403, loss_ce: 0.005977
2021-12-03 01:19:58,792 iteration 6196 : loss : 0.020967, loss_ce: 0.006600
2021-12-03 01:20:00,341 iteration 6197 : loss : 0.019723, loss_ce: 0.007201
2021-12-03 01:20:01,882 iteration 6198 : loss : 0.020401, loss_ce: 0.008939
2021-12-03 01:20:03,315 iteration 6199 : loss : 0.014932, loss_ce: 0.005547
2021-12-03 01:20:04,811 iteration 6200 : loss : 0.021242, loss_ce: 0.009640
2021-12-03 01:20:06,280 iteration 6201 : loss : 0.015504, loss_ce: 0.006224
2021-12-03 01:20:07,728 iteration 6202 : loss : 0.013764, loss_ce: 0.004089
2021-12-03 01:20:09,187 iteration 6203 : loss : 0.017035, loss_ce: 0.005302
2021-12-03 01:20:10,705 iteration 6204 : loss : 0.014251, loss_ce: 0.006781
2021-12-03 01:20:10,706 Training Data Eval:
2021-12-03 01:20:18,154   Average segmentation loss on training set: 0.0089
2021-12-03 01:20:18,154 Validation Data Eval:
2021-12-03 01:20:20,758   Average segmentation loss on validation set: 0.0679
2021-12-03 01:20:22,326 iteration 6205 : loss : 0.021293, loss_ce: 0.009087
 91%|██████████████████████████▍  | 365/400 [2:47:16<16:46, 28.77s/it]2021-12-03 01:20:23,870 iteration 6206 : loss : 0.018268, loss_ce: 0.007907
2021-12-03 01:20:25,336 iteration 6207 : loss : 0.017117, loss_ce: 0.008554
2021-12-03 01:20:26,809 iteration 6208 : loss : 0.018899, loss_ce: 0.006310
2021-12-03 01:20:28,289 iteration 6209 : loss : 0.020681, loss_ce: 0.007179
2021-12-03 01:20:29,748 iteration 6210 : loss : 0.015903, loss_ce: 0.005747
2021-12-03 01:20:31,162 iteration 6211 : loss : 0.011711, loss_ce: 0.004015
2021-12-03 01:20:32,623 iteration 6212 : loss : 0.017319, loss_ce: 0.006976
2021-12-03 01:20:34,100 iteration 6213 : loss : 0.011904, loss_ce: 0.004374
2021-12-03 01:20:35,554 iteration 6214 : loss : 0.011228, loss_ce: 0.004533
2021-12-03 01:20:37,065 iteration 6215 : loss : 0.017361, loss_ce: 0.005488
2021-12-03 01:20:38,526 iteration 6216 : loss : 0.011379, loss_ce: 0.004542
2021-12-03 01:20:39,932 iteration 6217 : loss : 0.018442, loss_ce: 0.005644
2021-12-03 01:20:41,418 iteration 6218 : loss : 0.014320, loss_ce: 0.005593
2021-12-03 01:20:42,888 iteration 6219 : loss : 0.015004, loss_ce: 0.004994
2021-12-03 01:20:44,322 iteration 6220 : loss : 0.012426, loss_ce: 0.002770
2021-12-03 01:20:45,801 iteration 6221 : loss : 0.014429, loss_ce: 0.003950
2021-12-03 01:20:47,227 iteration 6222 : loss : 0.013381, loss_ce: 0.006378
 92%|██████████████████████████▌  | 366/400 [2:47:41<15:38, 27.61s/it]2021-12-03 01:20:48,783 iteration 6223 : loss : 0.015148, loss_ce: 0.006201
2021-12-03 01:20:50,241 iteration 6224 : loss : 0.015974, loss_ce: 0.006417
2021-12-03 01:20:51,719 iteration 6225 : loss : 0.021545, loss_ce: 0.007721
2021-12-03 01:20:53,157 iteration 6226 : loss : 0.012594, loss_ce: 0.004226
2021-12-03 01:20:54,588 iteration 6227 : loss : 0.013312, loss_ce: 0.005159
2021-12-03 01:20:56,083 iteration 6228 : loss : 0.014897, loss_ce: 0.006119
2021-12-03 01:20:57,550 iteration 6229 : loss : 0.011305, loss_ce: 0.005013
2021-12-03 01:20:59,053 iteration 6230 : loss : 0.017389, loss_ce: 0.004929
2021-12-03 01:21:00,559 iteration 6231 : loss : 0.022217, loss_ce: 0.008809
2021-12-03 01:21:02,025 iteration 6232 : loss : 0.016909, loss_ce: 0.007749
2021-12-03 01:21:03,482 iteration 6233 : loss : 0.017115, loss_ce: 0.007005
2021-12-03 01:21:04,934 iteration 6234 : loss : 0.013800, loss_ce: 0.002929
2021-12-03 01:21:06,363 iteration 6235 : loss : 0.016436, loss_ce: 0.008509
2021-12-03 01:21:07,827 iteration 6236 : loss : 0.012397, loss_ce: 0.005976
2021-12-03 01:21:09,306 iteration 6237 : loss : 0.019560, loss_ce: 0.008917
2021-12-03 01:21:10,832 iteration 6238 : loss : 0.017596, loss_ce: 0.004669
2021-12-03 01:21:12,296 iteration 6239 : loss : 0.016306, loss_ce: 0.005362
 92%|██████████████████████████▌  | 367/400 [2:48:06<14:46, 26.85s/it]2021-12-03 01:21:13,795 iteration 6240 : loss : 0.012667, loss_ce: 0.004320
2021-12-03 01:21:15,217 iteration 6241 : loss : 0.011035, loss_ce: 0.005134
2021-12-03 01:21:16,752 iteration 6242 : loss : 0.016500, loss_ce: 0.006116
2021-12-03 01:21:18,195 iteration 6243 : loss : 0.011573, loss_ce: 0.004513
2021-12-03 01:21:19,724 iteration 6244 : loss : 0.015490, loss_ce: 0.006517
2021-12-03 01:21:21,179 iteration 6245 : loss : 0.014490, loss_ce: 0.005269
2021-12-03 01:21:22,644 iteration 6246 : loss : 0.014022, loss_ce: 0.005742
2021-12-03 01:21:24,126 iteration 6247 : loss : 0.015399, loss_ce: 0.003845
2021-12-03 01:21:25,571 iteration 6248 : loss : 0.013156, loss_ce: 0.005235
2021-12-03 01:21:27,023 iteration 6249 : loss : 0.015739, loss_ce: 0.004550
2021-12-03 01:21:28,524 iteration 6250 : loss : 0.015798, loss_ce: 0.005884
2021-12-03 01:21:30,069 iteration 6251 : loss : 0.016568, loss_ce: 0.006111
2021-12-03 01:21:31,487 iteration 6252 : loss : 0.014624, loss_ce: 0.006335
2021-12-03 01:21:32,999 iteration 6253 : loss : 0.015260, loss_ce: 0.005333
2021-12-03 01:21:34,452 iteration 6254 : loss : 0.013083, loss_ce: 0.005636
2021-12-03 01:21:35,934 iteration 6255 : loss : 0.019305, loss_ce: 0.007765
2021-12-03 01:21:37,465 iteration 6256 : loss : 0.020392, loss_ce: 0.008603
 92%|██████████████████████████▋  | 368/400 [2:48:31<14:02, 26.34s/it]2021-12-03 01:21:39,020 iteration 6257 : loss : 0.030101, loss_ce: 0.009263
2021-12-03 01:21:40,520 iteration 6258 : loss : 0.018610, loss_ce: 0.007035
2021-12-03 01:21:42,027 iteration 6259 : loss : 0.017980, loss_ce: 0.007148
2021-12-03 01:21:43,467 iteration 6260 : loss : 0.017474, loss_ce: 0.007060
2021-12-03 01:21:44,911 iteration 6261 : loss : 0.018236, loss_ce: 0.006252
2021-12-03 01:21:46,396 iteration 6262 : loss : 0.016613, loss_ce: 0.004265
2021-12-03 01:21:47,892 iteration 6263 : loss : 0.018756, loss_ce: 0.004023
2021-12-03 01:21:49,376 iteration 6264 : loss : 0.013533, loss_ce: 0.005175
2021-12-03 01:21:50,859 iteration 6265 : loss : 0.014936, loss_ce: 0.005677
2021-12-03 01:21:52,316 iteration 6266 : loss : 0.014814, loss_ce: 0.007053
2021-12-03 01:21:53,753 iteration 6267 : loss : 0.015021, loss_ce: 0.007564
2021-12-03 01:21:55,217 iteration 6268 : loss : 0.011679, loss_ce: 0.004506
2021-12-03 01:21:56,569 iteration 6269 : loss : 0.010780, loss_ce: 0.003704
2021-12-03 01:21:58,023 iteration 6270 : loss : 0.013271, loss_ce: 0.006084
2021-12-03 01:21:59,492 iteration 6271 : loss : 0.020648, loss_ce: 0.006649
2021-12-03 01:22:00,989 iteration 6272 : loss : 0.020702, loss_ce: 0.007700
2021-12-03 01:22:02,475 iteration 6273 : loss : 0.018117, loss_ce: 0.006798
 92%|██████████████████████████▊  | 369/400 [2:48:56<13:24, 25.95s/it]2021-12-03 01:22:04,119 iteration 6274 : loss : 0.021348, loss_ce: 0.007116
2021-12-03 01:22:05,605 iteration 6275 : loss : 0.015414, loss_ce: 0.007897
2021-12-03 01:22:07,082 iteration 6276 : loss : 0.014853, loss_ce: 0.005220
2021-12-03 01:22:08,508 iteration 6277 : loss : 0.012077, loss_ce: 0.003203
2021-12-03 01:22:09,976 iteration 6278 : loss : 0.024615, loss_ce: 0.007256
2021-12-03 01:22:11,432 iteration 6279 : loss : 0.015933, loss_ce: 0.007343
2021-12-03 01:22:12,855 iteration 6280 : loss : 0.020716, loss_ce: 0.007301
2021-12-03 01:22:14,420 iteration 6281 : loss : 0.023147, loss_ce: 0.005543
2021-12-03 01:22:15,860 iteration 6282 : loss : 0.012820, loss_ce: 0.004742
2021-12-03 01:22:17,285 iteration 6283 : loss : 0.011447, loss_ce: 0.004905
2021-12-03 01:22:18,760 iteration 6284 : loss : 0.020329, loss_ce: 0.008348
2021-12-03 01:22:20,268 iteration 6285 : loss : 0.015741, loss_ce: 0.005290
2021-12-03 01:22:21,700 iteration 6286 : loss : 0.015821, loss_ce: 0.005704
2021-12-03 01:22:23,134 iteration 6287 : loss : 0.019386, loss_ce: 0.005178
2021-12-03 01:22:24,526 iteration 6288 : loss : 0.011269, loss_ce: 0.003610
2021-12-03 01:22:26,014 iteration 6289 : loss : 0.018383, loss_ce: 0.009050
2021-12-03 01:22:26,014 Training Data Eval:
2021-12-03 01:22:33,443   Average segmentation loss on training set: 0.0086
2021-12-03 01:22:33,443 Validation Data Eval:
2021-12-03 01:22:36,032   Average segmentation loss on validation set: 0.0685
2021-12-03 01:22:37,550 iteration 6290 : loss : 0.017347, loss_ce: 0.008098
 92%|██████████████████████████▊  | 370/400 [2:49:31<14:20, 28.68s/it]2021-12-03 01:22:39,067 iteration 6291 : loss : 0.010890, loss_ce: 0.004200
2021-12-03 01:22:40,553 iteration 6292 : loss : 0.014770, loss_ce: 0.004670
2021-12-03 01:22:42,054 iteration 6293 : loss : 0.017360, loss_ce: 0.007545
2021-12-03 01:22:43,560 iteration 6294 : loss : 0.021129, loss_ce: 0.006101
2021-12-03 01:22:45,017 iteration 6295 : loss : 0.016489, loss_ce: 0.006587
2021-12-03 01:22:46,546 iteration 6296 : loss : 0.018598, loss_ce: 0.006318
2021-12-03 01:22:48,027 iteration 6297 : loss : 0.020674, loss_ce: 0.007285
2021-12-03 01:22:49,534 iteration 6298 : loss : 0.024039, loss_ce: 0.008569
2021-12-03 01:22:50,984 iteration 6299 : loss : 0.013736, loss_ce: 0.004362
2021-12-03 01:22:52,409 iteration 6300 : loss : 0.020545, loss_ce: 0.006142
2021-12-03 01:22:53,849 iteration 6301 : loss : 0.016838, loss_ce: 0.011360
2021-12-03 01:22:55,358 iteration 6302 : loss : 0.016583, loss_ce: 0.005660
2021-12-03 01:22:56,758 iteration 6303 : loss : 0.012885, loss_ce: 0.002848
2021-12-03 01:22:58,181 iteration 6304 : loss : 0.012767, loss_ce: 0.003521
2021-12-03 01:22:59,684 iteration 6305 : loss : 0.017836, loss_ce: 0.007901
2021-12-03 01:23:01,123 iteration 6306 : loss : 0.020070, loss_ce: 0.005408
2021-12-03 01:23:02,563 iteration 6307 : loss : 0.013695, loss_ce: 0.006299
 93%|██████████████████████████▉  | 371/400 [2:49:56<13:19, 27.58s/it]2021-12-03 01:23:04,032 iteration 6308 : loss : 0.015002, loss_ce: 0.003281
2021-12-03 01:23:05,493 iteration 6309 : loss : 0.021735, loss_ce: 0.008107
2021-12-03 01:23:06,941 iteration 6310 : loss : 0.017777, loss_ce: 0.007966
2021-12-03 01:23:08,415 iteration 6311 : loss : 0.012578, loss_ce: 0.004917
2021-12-03 01:23:09,915 iteration 6312 : loss : 0.020364, loss_ce: 0.006131
2021-12-03 01:23:11,428 iteration 6313 : loss : 0.018540, loss_ce: 0.007935
2021-12-03 01:23:12,875 iteration 6314 : loss : 0.012996, loss_ce: 0.004158
2021-12-03 01:23:14,308 iteration 6315 : loss : 0.013627, loss_ce: 0.004756
2021-12-03 01:23:15,777 iteration 6316 : loss : 0.014693, loss_ce: 0.005315
2021-12-03 01:23:17,241 iteration 6317 : loss : 0.012899, loss_ce: 0.003449
2021-12-03 01:23:18,773 iteration 6318 : loss : 0.023046, loss_ce: 0.008820
2021-12-03 01:23:20,253 iteration 6319 : loss : 0.016281, loss_ce: 0.005745
2021-12-03 01:23:21,700 iteration 6320 : loss : 0.015454, loss_ce: 0.005283
2021-12-03 01:23:23,208 iteration 6321 : loss : 0.019443, loss_ce: 0.009793
2021-12-03 01:23:24,719 iteration 6322 : loss : 0.014468, loss_ce: 0.006179
2021-12-03 01:23:26,295 iteration 6323 : loss : 0.018514, loss_ce: 0.006255
2021-12-03 01:23:27,811 iteration 6324 : loss : 0.016637, loss_ce: 0.007666
 93%|██████████████████████████▉  | 372/400 [2:50:21<12:32, 26.88s/it]2021-12-03 01:23:29,350 iteration 6325 : loss : 0.015212, loss_ce: 0.003962
2021-12-03 01:23:30,781 iteration 6326 : loss : 0.018133, loss_ce: 0.008434
2021-12-03 01:23:32,238 iteration 6327 : loss : 0.018548, loss_ce: 0.005579
2021-12-03 01:23:33,742 iteration 6328 : loss : 0.013941, loss_ce: 0.006396
2021-12-03 01:23:35,152 iteration 6329 : loss : 0.013791, loss_ce: 0.006927
2021-12-03 01:23:36,611 iteration 6330 : loss : 0.016704, loss_ce: 0.006113
2021-12-03 01:23:38,133 iteration 6331 : loss : 0.015367, loss_ce: 0.005924
2021-12-03 01:23:39,623 iteration 6332 : loss : 0.012948, loss_ce: 0.003516
2021-12-03 01:23:41,093 iteration 6333 : loss : 0.013097, loss_ce: 0.005948
2021-12-03 01:23:42,556 iteration 6334 : loss : 0.015630, loss_ce: 0.004333
2021-12-03 01:23:44,096 iteration 6335 : loss : 0.018438, loss_ce: 0.008500
2021-12-03 01:23:45,533 iteration 6336 : loss : 0.013711, loss_ce: 0.005533
2021-12-03 01:23:47,015 iteration 6337 : loss : 0.016524, loss_ce: 0.005024
2021-12-03 01:23:48,481 iteration 6338 : loss : 0.015504, loss_ce: 0.004452
2021-12-03 01:23:49,924 iteration 6339 : loss : 0.014179, loss_ce: 0.004735
2021-12-03 01:23:51,371 iteration 6340 : loss : 0.017330, loss_ce: 0.007795
2021-12-03 01:23:52,782 iteration 6341 : loss : 0.011465, loss_ce: 0.003671
 93%|███████████████████████████  | 373/400 [2:50:46<11:50, 26.31s/it]2021-12-03 01:23:54,363 iteration 6342 : loss : 0.023601, loss_ce: 0.006738
2021-12-03 01:23:55,809 iteration 6343 : loss : 0.014920, loss_ce: 0.006253
2021-12-03 01:23:57,263 iteration 6344 : loss : 0.018092, loss_ce: 0.004826
2021-12-03 01:23:58,698 iteration 6345 : loss : 0.020510, loss_ce: 0.003623
2021-12-03 01:24:00,169 iteration 6346 : loss : 0.021131, loss_ce: 0.006268
2021-12-03 01:24:01,637 iteration 6347 : loss : 0.015815, loss_ce: 0.005976
2021-12-03 01:24:03,015 iteration 6348 : loss : 0.010098, loss_ce: 0.004143
2021-12-03 01:24:04,499 iteration 6349 : loss : 0.014904, loss_ce: 0.006297
2021-12-03 01:24:06,064 iteration 6350 : loss : 0.025292, loss_ce: 0.008876
2021-12-03 01:24:07,569 iteration 6351 : loss : 0.015983, loss_ce: 0.006946
2021-12-03 01:24:09,028 iteration 6352 : loss : 0.019258, loss_ce: 0.005759
2021-12-03 01:24:10,506 iteration 6353 : loss : 0.017182, loss_ce: 0.006719
2021-12-03 01:24:11,981 iteration 6354 : loss : 0.016293, loss_ce: 0.007335
2021-12-03 01:24:13,433 iteration 6355 : loss : 0.016831, loss_ce: 0.005534
2021-12-03 01:24:14,950 iteration 6356 : loss : 0.022237, loss_ce: 0.005380
2021-12-03 01:24:16,387 iteration 6357 : loss : 0.018110, loss_ce: 0.006384
2021-12-03 01:24:17,951 iteration 6358 : loss : 0.019210, loss_ce: 0.007204
 94%|███████████████████████████  | 374/400 [2:51:12<11:15, 25.97s/it]2021-12-03 01:24:19,543 iteration 6359 : loss : 0.021733, loss_ce: 0.005413
2021-12-03 01:24:20,958 iteration 6360 : loss : 0.017183, loss_ce: 0.007693
2021-12-03 01:24:22,445 iteration 6361 : loss : 0.012281, loss_ce: 0.003800
2021-12-03 01:24:23,937 iteration 6362 : loss : 0.020098, loss_ce: 0.008701
2021-12-03 01:24:25,448 iteration 6363 : loss : 0.019562, loss_ce: 0.007750
2021-12-03 01:24:26,872 iteration 6364 : loss : 0.011905, loss_ce: 0.003004
2021-12-03 01:24:28,363 iteration 6365 : loss : 0.016960, loss_ce: 0.008297
2021-12-03 01:24:29,911 iteration 6366 : loss : 0.016189, loss_ce: 0.006404
2021-12-03 01:24:31,480 iteration 6367 : loss : 0.032359, loss_ce: 0.015489
2021-12-03 01:24:32,969 iteration 6368 : loss : 0.020382, loss_ce: 0.008303
2021-12-03 01:24:34,448 iteration 6369 : loss : 0.013148, loss_ce: 0.005173
2021-12-03 01:24:35,911 iteration 6370 : loss : 0.015117, loss_ce: 0.005073
2021-12-03 01:24:37,457 iteration 6371 : loss : 0.021460, loss_ce: 0.006281
2021-12-03 01:24:38,883 iteration 6372 : loss : 0.010476, loss_ce: 0.003949
2021-12-03 01:24:40,305 iteration 6373 : loss : 0.012580, loss_ce: 0.004755
2021-12-03 01:24:41,775 iteration 6374 : loss : 0.023687, loss_ce: 0.010265
2021-12-03 01:24:41,775 Training Data Eval:
2021-12-03 01:24:49,179   Average segmentation loss on training set: 0.0088
2021-12-03 01:24:49,180 Validation Data Eval:
2021-12-03 01:24:51,758   Average segmentation loss on validation set: 0.0641
2021-12-03 01:24:53,243 iteration 6375 : loss : 0.023481, loss_ce: 0.007084
 94%|███████████████████████████▏ | 375/400 [2:51:47<11:59, 28.76s/it]2021-12-03 01:24:54,788 iteration 6376 : loss : 0.023027, loss_ce: 0.006944
2021-12-03 01:24:56,257 iteration 6377 : loss : 0.015056, loss_ce: 0.005823
2021-12-03 01:24:57,646 iteration 6378 : loss : 0.016056, loss_ce: 0.008467
2021-12-03 01:24:59,137 iteration 6379 : loss : 0.016474, loss_ce: 0.004487
2021-12-03 01:25:00,587 iteration 6380 : loss : 0.016270, loss_ce: 0.005396
2021-12-03 01:25:02,028 iteration 6381 : loss : 0.010841, loss_ce: 0.003096
2021-12-03 01:25:03,425 iteration 6382 : loss : 0.014701, loss_ce: 0.005469
2021-12-03 01:25:04,938 iteration 6383 : loss : 0.024074, loss_ce: 0.008594
2021-12-03 01:25:06,375 iteration 6384 : loss : 0.013307, loss_ce: 0.004991
2021-12-03 01:25:07,871 iteration 6385 : loss : 0.021962, loss_ce: 0.006889
2021-12-03 01:25:09,380 iteration 6386 : loss : 0.016233, loss_ce: 0.005264
2021-12-03 01:25:10,929 iteration 6387 : loss : 0.016172, loss_ce: 0.007123
2021-12-03 01:25:12,421 iteration 6388 : loss : 0.014931, loss_ce: 0.006226
2021-12-03 01:25:13,793 iteration 6389 : loss : 0.011714, loss_ce: 0.003926
2021-12-03 01:25:15,260 iteration 6390 : loss : 0.015921, loss_ce: 0.007055
2021-12-03 01:25:16,692 iteration 6391 : loss : 0.013549, loss_ce: 0.007229
2021-12-03 01:25:18,224 iteration 6392 : loss : 0.019118, loss_ce: 0.005293
 94%|███████████████████████████▎ | 376/400 [2:52:12<11:03, 27.63s/it]2021-12-03 01:25:19,731 iteration 6393 : loss : 0.013976, loss_ce: 0.005114
2021-12-03 01:25:21,230 iteration 6394 : loss : 0.016309, loss_ce: 0.005366
2021-12-03 01:25:22,673 iteration 6395 : loss : 0.013924, loss_ce: 0.004087
2021-12-03 01:25:24,126 iteration 6396 : loss : 0.013808, loss_ce: 0.004909
2021-12-03 01:25:25,609 iteration 6397 : loss : 0.012973, loss_ce: 0.005057
2021-12-03 01:25:27,089 iteration 6398 : loss : 0.015064, loss_ce: 0.005359
2021-12-03 01:25:28,539 iteration 6399 : loss : 0.017935, loss_ce: 0.005617
2021-12-03 01:25:29,987 iteration 6400 : loss : 0.011612, loss_ce: 0.004632
2021-12-03 01:25:31,477 iteration 6401 : loss : 0.013703, loss_ce: 0.005352
2021-12-03 01:25:32,922 iteration 6402 : loss : 0.014133, loss_ce: 0.007124
2021-12-03 01:25:34,449 iteration 6403 : loss : 0.019768, loss_ce: 0.008244
2021-12-03 01:25:35,902 iteration 6404 : loss : 0.012109, loss_ce: 0.004895
2021-12-03 01:25:37,347 iteration 6405 : loss : 0.020248, loss_ce: 0.006127
2021-12-03 01:25:38,945 iteration 6406 : loss : 0.027113, loss_ce: 0.007028
2021-12-03 01:25:40,448 iteration 6407 : loss : 0.033255, loss_ce: 0.010347
2021-12-03 01:25:41,826 iteration 6408 : loss : 0.010494, loss_ce: 0.003571
2021-12-03 01:25:43,282 iteration 6409 : loss : 0.016460, loss_ce: 0.007766
 94%|███████████████████████████▎ | 377/400 [2:52:37<10:17, 26.86s/it]2021-12-03 01:25:44,781 iteration 6410 : loss : 0.013624, loss_ce: 0.005451
2021-12-03 01:25:46,281 iteration 6411 : loss : 0.014413, loss_ce: 0.005463
2021-12-03 01:25:47,780 iteration 6412 : loss : 0.014726, loss_ce: 0.005998
2021-12-03 01:25:49,223 iteration 6413 : loss : 0.014178, loss_ce: 0.005967
2021-12-03 01:25:50,642 iteration 6414 : loss : 0.012774, loss_ce: 0.004883
2021-12-03 01:25:52,048 iteration 6415 : loss : 0.011616, loss_ce: 0.003826
2021-12-03 01:25:53,531 iteration 6416 : loss : 0.012054, loss_ce: 0.004845
2021-12-03 01:25:54,943 iteration 6417 : loss : 0.013831, loss_ce: 0.005029
2021-12-03 01:25:56,391 iteration 6418 : loss : 0.012396, loss_ce: 0.005358
2021-12-03 01:25:57,940 iteration 6419 : loss : 0.020079, loss_ce: 0.008569
2021-12-03 01:25:59,457 iteration 6420 : loss : 0.021596, loss_ce: 0.005182
2021-12-03 01:26:00,933 iteration 6421 : loss : 0.015727, loss_ce: 0.005728
2021-12-03 01:26:02,399 iteration 6422 : loss : 0.019392, loss_ce: 0.005805
2021-12-03 01:26:03,902 iteration 6423 : loss : 0.013512, loss_ce: 0.005366
2021-12-03 01:26:05,436 iteration 6424 : loss : 0.020422, loss_ce: 0.011610
2021-12-03 01:26:06,881 iteration 6425 : loss : 0.017807, loss_ce: 0.005424
2021-12-03 01:26:08,408 iteration 6426 : loss : 0.017657, loss_ce: 0.005721
 94%|███████████████████████████▍ | 378/400 [2:53:02<09:39, 26.34s/it]2021-12-03 01:26:09,975 iteration 6427 : loss : 0.013505, loss_ce: 0.004195
2021-12-03 01:26:11,444 iteration 6428 : loss : 0.014701, loss_ce: 0.004476
2021-12-03 01:26:12,921 iteration 6429 : loss : 0.017040, loss_ce: 0.005080
2021-12-03 01:26:14,429 iteration 6430 : loss : 0.018061, loss_ce: 0.007979
2021-12-03 01:26:15,842 iteration 6431 : loss : 0.012958, loss_ce: 0.004651
2021-12-03 01:26:17,329 iteration 6432 : loss : 0.015749, loss_ce: 0.006044
2021-12-03 01:26:18,785 iteration 6433 : loss : 0.013303, loss_ce: 0.004167
2021-12-03 01:26:20,223 iteration 6434 : loss : 0.014500, loss_ce: 0.005525
2021-12-03 01:26:21,669 iteration 6435 : loss : 0.014808, loss_ce: 0.005046
2021-12-03 01:26:23,106 iteration 6436 : loss : 0.012848, loss_ce: 0.005152
2021-12-03 01:26:24,575 iteration 6437 : loss : 0.011922, loss_ce: 0.003982
2021-12-03 01:26:26,079 iteration 6438 : loss : 0.016081, loss_ce: 0.005301
2021-12-03 01:26:27,483 iteration 6439 : loss : 0.012148, loss_ce: 0.005203
2021-12-03 01:26:28,987 iteration 6440 : loss : 0.016732, loss_ce: 0.007440
2021-12-03 01:26:30,394 iteration 6441 : loss : 0.010898, loss_ce: 0.004828
2021-12-03 01:26:31,862 iteration 6442 : loss : 0.019195, loss_ce: 0.006054
2021-12-03 01:26:33,250 iteration 6443 : loss : 0.011263, loss_ce: 0.003716
 95%|███████████████████████████▍ | 379/400 [2:53:27<09:03, 25.89s/it]2021-12-03 01:26:34,779 iteration 6444 : loss : 0.015311, loss_ce: 0.007271
2021-12-03 01:26:36,239 iteration 6445 : loss : 0.015261, loss_ce: 0.005939
2021-12-03 01:26:37,715 iteration 6446 : loss : 0.015509, loss_ce: 0.006289
2021-12-03 01:26:39,215 iteration 6447 : loss : 0.026583, loss_ce: 0.004899
2021-12-03 01:26:40,711 iteration 6448 : loss : 0.015417, loss_ce: 0.005672
2021-12-03 01:26:42,139 iteration 6449 : loss : 0.013616, loss_ce: 0.003203
2021-12-03 01:26:43,551 iteration 6450 : loss : 0.014573, loss_ce: 0.006454
2021-12-03 01:26:45,041 iteration 6451 : loss : 0.014386, loss_ce: 0.004985
2021-12-03 01:26:46,574 iteration 6452 : loss : 0.016892, loss_ce: 0.005594
2021-12-03 01:26:48,022 iteration 6453 : loss : 0.014928, loss_ce: 0.005459
2021-12-03 01:26:49,431 iteration 6454 : loss : 0.018112, loss_ce: 0.006480
2021-12-03 01:26:50,926 iteration 6455 : loss : 0.013149, loss_ce: 0.005909
2021-12-03 01:26:52,379 iteration 6456 : loss : 0.023369, loss_ce: 0.007951
2021-12-03 01:26:53,853 iteration 6457 : loss : 0.018570, loss_ce: 0.006238
2021-12-03 01:26:55,292 iteration 6458 : loss : 0.015187, loss_ce: 0.005393
2021-12-03 01:26:56,755 iteration 6459 : loss : 0.014626, loss_ce: 0.004211
2021-12-03 01:26:56,755 Training Data Eval:
2021-12-03 01:27:04,158   Average segmentation loss on training set: 0.0085
2021-12-03 01:27:04,158 Validation Data Eval:
2021-12-03 01:27:06,718   Average segmentation loss on validation set: 0.0720
2021-12-03 01:27:08,229 iteration 6460 : loss : 0.013832, loss_ce: 0.006094
 95%|███████████████████████████▌ | 380/400 [2:54:02<09:32, 28.62s/it]2021-12-03 01:27:09,800 iteration 6461 : loss : 0.017560, loss_ce: 0.007052
2021-12-03 01:27:11,241 iteration 6462 : loss : 0.012111, loss_ce: 0.005373
2021-12-03 01:27:12,753 iteration 6463 : loss : 0.019540, loss_ce: 0.008458
2021-12-03 01:27:14,216 iteration 6464 : loss : 0.014754, loss_ce: 0.004076
2021-12-03 01:27:15,718 iteration 6465 : loss : 0.017922, loss_ce: 0.006555
2021-12-03 01:27:17,153 iteration 6466 : loss : 0.012572, loss_ce: 0.003904
2021-12-03 01:27:18,596 iteration 6467 : loss : 0.014116, loss_ce: 0.004706
2021-12-03 01:27:20,107 iteration 6468 : loss : 0.017460, loss_ce: 0.006317
2021-12-03 01:27:21,544 iteration 6469 : loss : 0.013532, loss_ce: 0.005551
2021-12-03 01:27:22,974 iteration 6470 : loss : 0.013230, loss_ce: 0.003549
2021-12-03 01:27:24,453 iteration 6471 : loss : 0.011869, loss_ce: 0.003861
2021-12-03 01:27:25,950 iteration 6472 : loss : 0.021081, loss_ce: 0.006507
2021-12-03 01:27:27,383 iteration 6473 : loss : 0.015173, loss_ce: 0.005657
2021-12-03 01:27:28,907 iteration 6474 : loss : 0.013382, loss_ce: 0.006516
2021-12-03 01:27:30,399 iteration 6475 : loss : 0.022245, loss_ce: 0.011645
2021-12-03 01:27:31,757 iteration 6476 : loss : 0.019726, loss_ce: 0.006952
2021-12-03 01:27:33,324 iteration 6477 : loss : 0.018574, loss_ce: 0.007256
 95%|███████████████████████████▌ | 381/400 [2:54:27<08:43, 27.56s/it]2021-12-03 01:27:34,896 iteration 6478 : loss : 0.018680, loss_ce: 0.005638
2021-12-03 01:27:36,332 iteration 6479 : loss : 0.016212, loss_ce: 0.005244
2021-12-03 01:27:37,785 iteration 6480 : loss : 0.013505, loss_ce: 0.005754
2021-12-03 01:27:39,274 iteration 6481 : loss : 0.015413, loss_ce: 0.007407
2021-12-03 01:27:40,685 iteration 6482 : loss : 0.016813, loss_ce: 0.005746
2021-12-03 01:27:42,168 iteration 6483 : loss : 0.027444, loss_ce: 0.007100
2021-12-03 01:27:43,586 iteration 6484 : loss : 0.012287, loss_ce: 0.004666
2021-12-03 01:27:45,044 iteration 6485 : loss : 0.015139, loss_ce: 0.006577
2021-12-03 01:27:46,557 iteration 6486 : loss : 0.013725, loss_ce: 0.004857
2021-12-03 01:27:48,110 iteration 6487 : loss : 0.020610, loss_ce: 0.008483
2021-12-03 01:27:49,595 iteration 6488 : loss : 0.037834, loss_ce: 0.015215
2021-12-03 01:27:51,016 iteration 6489 : loss : 0.010866, loss_ce: 0.005462
2021-12-03 01:27:52,490 iteration 6490 : loss : 0.015249, loss_ce: 0.004211
2021-12-03 01:27:53,931 iteration 6491 : loss : 0.013369, loss_ce: 0.004554
2021-12-03 01:27:55,475 iteration 6492 : loss : 0.015647, loss_ce: 0.005957
2021-12-03 01:27:56,964 iteration 6493 : loss : 0.032969, loss_ce: 0.011504
2021-12-03 01:27:58,355 iteration 6494 : loss : 0.008599, loss_ce: 0.003419
 96%|███████████████████████████▋ | 382/400 [2:54:52<08:02, 26.80s/it]2021-12-03 01:27:59,855 iteration 6495 : loss : 0.013711, loss_ce: 0.005174
2021-12-03 01:28:01,311 iteration 6496 : loss : 0.021223, loss_ce: 0.005856
2021-12-03 01:28:02,812 iteration 6497 : loss : 0.019590, loss_ce: 0.008436
2021-12-03 01:28:04,309 iteration 6498 : loss : 0.025171, loss_ce: 0.009575
2021-12-03 01:28:05,804 iteration 6499 : loss : 0.017508, loss_ce: 0.006627
2021-12-03 01:28:07,269 iteration 6500 : loss : 0.012792, loss_ce: 0.004772
2021-12-03 01:28:08,749 iteration 6501 : loss : 0.017476, loss_ce: 0.007871
2021-12-03 01:28:10,253 iteration 6502 : loss : 0.016935, loss_ce: 0.009476
2021-12-03 01:28:11,685 iteration 6503 : loss : 0.009353, loss_ce: 0.002430
2021-12-03 01:28:13,104 iteration 6504 : loss : 0.011663, loss_ce: 0.003782
2021-12-03 01:28:14,464 iteration 6505 : loss : 0.012355, loss_ce: 0.005571
2021-12-03 01:28:15,929 iteration 6506 : loss : 0.020948, loss_ce: 0.006171
2021-12-03 01:28:17,458 iteration 6507 : loss : 0.019584, loss_ce: 0.009621
2021-12-03 01:28:18,953 iteration 6508 : loss : 0.019039, loss_ce: 0.008346
2021-12-03 01:28:20,420 iteration 6509 : loss : 0.016795, loss_ce: 0.006365
2021-12-03 01:28:21,897 iteration 6510 : loss : 0.012197, loss_ce: 0.004046
2021-12-03 01:28:23,304 iteration 6511 : loss : 0.014255, loss_ce: 0.005221
 96%|███████████████████████████▊ | 383/400 [2:55:17<07:26, 26.25s/it]2021-12-03 01:28:24,806 iteration 6512 : loss : 0.015480, loss_ce: 0.004643
2021-12-03 01:28:26,272 iteration 6513 : loss : 0.017049, loss_ce: 0.006108
2021-12-03 01:28:27,826 iteration 6514 : loss : 0.013280, loss_ce: 0.003879
2021-12-03 01:28:29,334 iteration 6515 : loss : 0.018347, loss_ce: 0.006118
2021-12-03 01:28:30,812 iteration 6516 : loss : 0.018574, loss_ce: 0.008099
2021-12-03 01:28:32,266 iteration 6517 : loss : 0.019030, loss_ce: 0.004052
2021-12-03 01:28:33,744 iteration 6518 : loss : 0.012555, loss_ce: 0.004433
2021-12-03 01:28:35,208 iteration 6519 : loss : 0.020798, loss_ce: 0.005776
2021-12-03 01:28:36,716 iteration 6520 : loss : 0.015467, loss_ce: 0.005148
2021-12-03 01:28:38,151 iteration 6521 : loss : 0.022426, loss_ce: 0.009636
2021-12-03 01:28:39,641 iteration 6522 : loss : 0.013017, loss_ce: 0.004915
2021-12-03 01:28:41,052 iteration 6523 : loss : 0.014527, loss_ce: 0.006759
2021-12-03 01:28:42,553 iteration 6524 : loss : 0.019093, loss_ce: 0.008181
2021-12-03 01:28:44,033 iteration 6525 : loss : 0.019384, loss_ce: 0.006965
2021-12-03 01:28:45,497 iteration 6526 : loss : 0.014811, loss_ce: 0.005650
2021-12-03 01:28:46,889 iteration 6527 : loss : 0.013762, loss_ce: 0.006031
2021-12-03 01:28:48,310 iteration 6528 : loss : 0.013788, loss_ce: 0.003990
 96%|███████████████████████████▊ | 384/400 [2:55:42<06:53, 25.87s/it]2021-12-03 01:28:49,882 iteration 6529 : loss : 0.028058, loss_ce: 0.008088
2021-12-03 01:28:51,370 iteration 6530 : loss : 0.012793, loss_ce: 0.004634
2021-12-03 01:28:52,787 iteration 6531 : loss : 0.012126, loss_ce: 0.003411
2021-12-03 01:28:54,274 iteration 6532 : loss : 0.016318, loss_ce: 0.006300
2021-12-03 01:28:55,690 iteration 6533 : loss : 0.009016, loss_ce: 0.003474
2021-12-03 01:28:57,168 iteration 6534 : loss : 0.015094, loss_ce: 0.006501
2021-12-03 01:28:58,643 iteration 6535 : loss : 0.018948, loss_ce: 0.008683
2021-12-03 01:29:00,143 iteration 6536 : loss : 0.013667, loss_ce: 0.004491
2021-12-03 01:29:01,615 iteration 6537 : loss : 0.020858, loss_ce: 0.008104
2021-12-03 01:29:03,091 iteration 6538 : loss : 0.013517, loss_ce: 0.004029
2021-12-03 01:29:04,587 iteration 6539 : loss : 0.020480, loss_ce: 0.008253
2021-12-03 01:29:05,984 iteration 6540 : loss : 0.012721, loss_ce: 0.005172
2021-12-03 01:29:07,430 iteration 6541 : loss : 0.017482, loss_ce: 0.010719
2021-12-03 01:29:08,996 iteration 6542 : loss : 0.013128, loss_ce: 0.004085
2021-12-03 01:29:10,430 iteration 6543 : loss : 0.013211, loss_ce: 0.005007
2021-12-03 01:29:11,917 iteration 6544 : loss : 0.019362, loss_ce: 0.008406
2021-12-03 01:29:11,917 Training Data Eval:
2021-12-03 01:29:19,350   Average segmentation loss on training set: 0.0082
2021-12-03 01:29:19,350 Validation Data Eval:
2021-12-03 01:29:21,952   Average segmentation loss on validation set: 0.0743
2021-12-03 01:29:23,519 iteration 6545 : loss : 0.016678, loss_ce: 0.006461
 96%|███████████████████████████▉ | 385/400 [2:56:17<07:10, 28.67s/it]2021-12-03 01:29:25,173 iteration 6546 : loss : 0.015624, loss_ce: 0.006223
2021-12-03 01:29:26,630 iteration 6547 : loss : 0.015011, loss_ce: 0.006192
2021-12-03 01:29:28,125 iteration 6548 : loss : 0.011493, loss_ce: 0.004486
2021-12-03 01:29:29,568 iteration 6549 : loss : 0.014238, loss_ce: 0.005258
2021-12-03 01:29:31,081 iteration 6550 : loss : 0.016446, loss_ce: 0.005836
2021-12-03 01:29:32,645 iteration 6551 : loss : 0.020231, loss_ce: 0.008418
2021-12-03 01:29:34,194 iteration 6552 : loss : 0.021598, loss_ce: 0.009056
2021-12-03 01:29:35,748 iteration 6553 : loss : 0.018559, loss_ce: 0.005419
2021-12-03 01:29:37,215 iteration 6554 : loss : 0.013848, loss_ce: 0.004961
2021-12-03 01:29:38,683 iteration 6555 : loss : 0.010735, loss_ce: 0.004129
2021-12-03 01:29:40,140 iteration 6556 : loss : 0.014370, loss_ce: 0.003537
2021-12-03 01:29:41,525 iteration 6557 : loss : 0.009597, loss_ce: 0.003787
2021-12-03 01:29:43,002 iteration 6558 : loss : 0.015353, loss_ce: 0.004697
2021-12-03 01:29:44,415 iteration 6559 : loss : 0.011984, loss_ce: 0.004230
2021-12-03 01:29:45,891 iteration 6560 : loss : 0.014865, loss_ce: 0.006588
2021-12-03 01:29:47,390 iteration 6561 : loss : 0.016413, loss_ce: 0.004686
2021-12-03 01:29:48,826 iteration 6562 : loss : 0.013328, loss_ce: 0.005015
 96%|███████████████████████████▉ | 386/400 [2:56:42<06:27, 27.67s/it]2021-12-03 01:29:50,459 iteration 6563 : loss : 0.019287, loss_ce: 0.008319
2021-12-03 01:29:51,888 iteration 6564 : loss : 0.021043, loss_ce: 0.008043
2021-12-03 01:29:53,304 iteration 6565 : loss : 0.022602, loss_ce: 0.004883
2021-12-03 01:29:54,716 iteration 6566 : loss : 0.012508, loss_ce: 0.004864
2021-12-03 01:29:56,108 iteration 6567 : loss : 0.013329, loss_ce: 0.004921
2021-12-03 01:29:57,549 iteration 6568 : loss : 0.013554, loss_ce: 0.005326
2021-12-03 01:29:59,011 iteration 6569 : loss : 0.015309, loss_ce: 0.006390
2021-12-03 01:30:00,424 iteration 6570 : loss : 0.011585, loss_ce: 0.005448
2021-12-03 01:30:01,885 iteration 6571 : loss : 0.017862, loss_ce: 0.005735
2021-12-03 01:30:03,296 iteration 6572 : loss : 0.012233, loss_ce: 0.005168
2021-12-03 01:30:04,830 iteration 6573 : loss : 0.013503, loss_ce: 0.004180
2021-12-03 01:30:06,365 iteration 6574 : loss : 0.012301, loss_ce: 0.005553
2021-12-03 01:30:07,898 iteration 6575 : loss : 0.034567, loss_ce: 0.011313
2021-12-03 01:30:09,326 iteration 6576 : loss : 0.014795, loss_ce: 0.006096
2021-12-03 01:30:10,821 iteration 6577 : loss : 0.021403, loss_ce: 0.004485
2021-12-03 01:30:12,253 iteration 6578 : loss : 0.013238, loss_ce: 0.004999
2021-12-03 01:30:13,743 iteration 6579 : loss : 0.021461, loss_ce: 0.007312
 97%|████████████████████████████ | 387/400 [2:57:07<05:48, 26.84s/it]2021-12-03 01:30:15,259 iteration 6580 : loss : 0.015276, loss_ce: 0.004385
2021-12-03 01:30:16,700 iteration 6581 : loss : 0.015744, loss_ce: 0.005394
2021-12-03 01:30:18,238 iteration 6582 : loss : 0.013908, loss_ce: 0.004669
2021-12-03 01:30:19,695 iteration 6583 : loss : 0.015974, loss_ce: 0.006321
2021-12-03 01:30:21,169 iteration 6584 : loss : 0.022180, loss_ce: 0.008215
2021-12-03 01:30:22,678 iteration 6585 : loss : 0.020259, loss_ce: 0.006893
2021-12-03 01:30:24,170 iteration 6586 : loss : 0.015484, loss_ce: 0.004295
2021-12-03 01:30:25,621 iteration 6587 : loss : 0.010898, loss_ce: 0.004617
2021-12-03 01:30:27,084 iteration 6588 : loss : 0.014977, loss_ce: 0.006357
2021-12-03 01:30:28,482 iteration 6589 : loss : 0.014682, loss_ce: 0.005146
2021-12-03 01:30:29,993 iteration 6590 : loss : 0.028338, loss_ce: 0.013435
2021-12-03 01:30:31,507 iteration 6591 : loss : 0.017096, loss_ce: 0.006888
2021-12-03 01:30:32,943 iteration 6592 : loss : 0.013402, loss_ce: 0.004910
2021-12-03 01:30:34,475 iteration 6593 : loss : 0.026156, loss_ce: 0.004955
2021-12-03 01:30:35,932 iteration 6594 : loss : 0.014340, loss_ce: 0.006700
2021-12-03 01:30:37,387 iteration 6595 : loss : 0.012798, loss_ce: 0.004610
2021-12-03 01:30:38,907 iteration 6596 : loss : 0.031769, loss_ce: 0.012657
 97%|████████████████████████████▏| 388/400 [2:57:33<05:16, 26.34s/it]2021-12-03 01:30:40,421 iteration 6597 : loss : 0.014702, loss_ce: 0.005988
2021-12-03 01:30:41,847 iteration 6598 : loss : 0.018990, loss_ce: 0.003977
2021-12-03 01:30:43,358 iteration 6599 : loss : 0.014232, loss_ce: 0.005550
2021-12-03 01:30:44,758 iteration 6600 : loss : 0.009575, loss_ce: 0.003969
2021-12-03 01:30:46,216 iteration 6601 : loss : 0.015758, loss_ce: 0.005574
2021-12-03 01:30:47,648 iteration 6602 : loss : 0.021390, loss_ce: 0.006043
2021-12-03 01:30:49,115 iteration 6603 : loss : 0.015749, loss_ce: 0.004838
2021-12-03 01:30:50,509 iteration 6604 : loss : 0.009353, loss_ce: 0.003807
2021-12-03 01:30:51,972 iteration 6605 : loss : 0.014804, loss_ce: 0.005365
2021-12-03 01:30:53,461 iteration 6606 : loss : 0.015066, loss_ce: 0.007538
2021-12-03 01:30:54,950 iteration 6607 : loss : 0.017367, loss_ce: 0.007209
2021-12-03 01:30:56,432 iteration 6608 : loss : 0.012439, loss_ce: 0.005011
2021-12-03 01:30:57,849 iteration 6609 : loss : 0.015452, loss_ce: 0.005086
2021-12-03 01:30:59,293 iteration 6610 : loss : 0.012731, loss_ce: 0.004880
2021-12-03 01:31:00,745 iteration 6611 : loss : 0.012321, loss_ce: 0.002884
2021-12-03 01:31:02,252 iteration 6612 : loss : 0.027065, loss_ce: 0.009195
2021-12-03 01:31:03,613 iteration 6613 : loss : 0.011723, loss_ce: 0.004380
 97%|████████████████████████████▏| 389/400 [2:57:57<04:44, 25.85s/it]2021-12-03 01:31:05,134 iteration 6614 : loss : 0.018558, loss_ce: 0.007059
2021-12-03 01:31:06,605 iteration 6615 : loss : 0.013715, loss_ce: 0.005784
2021-12-03 01:31:08,051 iteration 6616 : loss : 0.015876, loss_ce: 0.004783
2021-12-03 01:31:09,611 iteration 6617 : loss : 0.016624, loss_ce: 0.005751
2021-12-03 01:31:11,084 iteration 6618 : loss : 0.016709, loss_ce: 0.004218
2021-12-03 01:31:12,625 iteration 6619 : loss : 0.021202, loss_ce: 0.008766
2021-12-03 01:31:14,131 iteration 6620 : loss : 0.022368, loss_ce: 0.009958
2021-12-03 01:31:15,591 iteration 6621 : loss : 0.022143, loss_ce: 0.006406
2021-12-03 01:31:17,057 iteration 6622 : loss : 0.020021, loss_ce: 0.010743
2021-12-03 01:31:18,534 iteration 6623 : loss : 0.017803, loss_ce: 0.006091
2021-12-03 01:31:20,032 iteration 6624 : loss : 0.028931, loss_ce: 0.013270
2021-12-03 01:31:21,543 iteration 6625 : loss : 0.018525, loss_ce: 0.009482
2021-12-03 01:31:22,989 iteration 6626 : loss : 0.015464, loss_ce: 0.004228
2021-12-03 01:31:24,377 iteration 6627 : loss : 0.014048, loss_ce: 0.004523
2021-12-03 01:31:25,833 iteration 6628 : loss : 0.013107, loss_ce: 0.006003
2021-12-03 01:31:27,277 iteration 6629 : loss : 0.013948, loss_ce: 0.006385
2021-12-03 01:31:27,277 Training Data Eval:
2021-12-03 01:31:34,689   Average segmentation loss on training set: 0.0083
2021-12-03 01:31:34,689 Validation Data Eval:
2021-12-03 01:31:37,277   Average segmentation loss on validation set: 0.0717
2021-12-03 01:31:38,797 iteration 6630 : loss : 0.017795, loss_ce: 0.005196
 98%|████████████████████████████▎| 390/400 [2:58:32<04:46, 28.65s/it]2021-12-03 01:31:40,401 iteration 6631 : loss : 0.017475, loss_ce: 0.006881
2021-12-03 01:31:41,860 iteration 6632 : loss : 0.015333, loss_ce: 0.006255
2021-12-03 01:31:43,329 iteration 6633 : loss : 0.018018, loss_ce: 0.004851
2021-12-03 01:31:44,703 iteration 6634 : loss : 0.010325, loss_ce: 0.003233
2021-12-03 01:31:46,141 iteration 6635 : loss : 0.023744, loss_ce: 0.006418
2021-12-03 01:31:47,653 iteration 6636 : loss : 0.017406, loss_ce: 0.006326
2021-12-03 01:31:49,144 iteration 6637 : loss : 0.017144, loss_ce: 0.009175
2021-12-03 01:31:50,642 iteration 6638 : loss : 0.018333, loss_ce: 0.006393
2021-12-03 01:31:52,164 iteration 6639 : loss : 0.021987, loss_ce: 0.006543
2021-12-03 01:31:53,624 iteration 6640 : loss : 0.018815, loss_ce: 0.005915
2021-12-03 01:31:55,065 iteration 6641 : loss : 0.015260, loss_ce: 0.007947
2021-12-03 01:31:56,603 iteration 6642 : loss : 0.018401, loss_ce: 0.007304
2021-12-03 01:31:58,098 iteration 6643 : loss : 0.014332, loss_ce: 0.005848
2021-12-03 01:31:59,565 iteration 6644 : loss : 0.023800, loss_ce: 0.008128
2021-12-03 01:32:00,963 iteration 6645 : loss : 0.009323, loss_ce: 0.004165
2021-12-03 01:32:02,405 iteration 6646 : loss : 0.013787, loss_ce: 0.005691
2021-12-03 01:32:03,808 iteration 6647 : loss : 0.010779, loss_ce: 0.003484
 98%|████████████████████████████▎| 391/400 [2:58:57<04:07, 27.55s/it]2021-12-03 01:32:05,318 iteration 6648 : loss : 0.012456, loss_ce: 0.004031
2021-12-03 01:32:06,827 iteration 6649 : loss : 0.017794, loss_ce: 0.007966
2021-12-03 01:32:08,221 iteration 6650 : loss : 0.014373, loss_ce: 0.005115
2021-12-03 01:32:09,644 iteration 6651 : loss : 0.012023, loss_ce: 0.003982
2021-12-03 01:32:11,163 iteration 6652 : loss : 0.018624, loss_ce: 0.006384
2021-12-03 01:32:12,674 iteration 6653 : loss : 0.017663, loss_ce: 0.007961
2021-12-03 01:32:14,113 iteration 6654 : loss : 0.013535, loss_ce: 0.005375
2021-12-03 01:32:15,603 iteration 6655 : loss : 0.013544, loss_ce: 0.005149
2021-12-03 01:32:17,102 iteration 6656 : loss : 0.012957, loss_ce: 0.005109
2021-12-03 01:32:18,656 iteration 6657 : loss : 0.023293, loss_ce: 0.008268
2021-12-03 01:32:20,122 iteration 6658 : loss : 0.023304, loss_ce: 0.007812
2021-12-03 01:32:21,631 iteration 6659 : loss : 0.016366, loss_ce: 0.006581
2021-12-03 01:32:23,068 iteration 6660 : loss : 0.014076, loss_ce: 0.004671
2021-12-03 01:32:24,459 iteration 6661 : loss : 0.010471, loss_ce: 0.003812
2021-12-03 01:32:25,946 iteration 6662 : loss : 0.013976, loss_ce: 0.004780
2021-12-03 01:32:27,465 iteration 6663 : loss : 0.014675, loss_ce: 0.005486
2021-12-03 01:32:28,919 iteration 6664 : loss : 0.015387, loss_ce: 0.004721
 98%|████████████████████████████▍| 392/400 [2:59:23<03:34, 26.83s/it]2021-12-03 01:32:30,457 iteration 6665 : loss : 0.016396, loss_ce: 0.005731
2021-12-03 01:32:31,934 iteration 6666 : loss : 0.015555, loss_ce: 0.008304
2021-12-03 01:32:33,359 iteration 6667 : loss : 0.012580, loss_ce: 0.004374
2021-12-03 01:32:34,734 iteration 6668 : loss : 0.010385, loss_ce: 0.004259
2021-12-03 01:32:36,214 iteration 6669 : loss : 0.022500, loss_ce: 0.008817
2021-12-03 01:32:37,623 iteration 6670 : loss : 0.012609, loss_ce: 0.004305
2021-12-03 01:32:39,153 iteration 6671 : loss : 0.018719, loss_ce: 0.006863
2021-12-03 01:32:40,618 iteration 6672 : loss : 0.014625, loss_ce: 0.008341
2021-12-03 01:32:42,154 iteration 6673 : loss : 0.014999, loss_ce: 0.006393
2021-12-03 01:32:43,666 iteration 6674 : loss : 0.015621, loss_ce: 0.005490
2021-12-03 01:32:45,094 iteration 6675 : loss : 0.016739, loss_ce: 0.005366
2021-12-03 01:32:46,483 iteration 6676 : loss : 0.010312, loss_ce: 0.004056
2021-12-03 01:32:47,961 iteration 6677 : loss : 0.013062, loss_ce: 0.002946
2021-12-03 01:32:49,523 iteration 6678 : loss : 0.014584, loss_ce: 0.006774
2021-12-03 01:32:51,033 iteration 6679 : loss : 0.013316, loss_ce: 0.004310
2021-12-03 01:32:52,476 iteration 6680 : loss : 0.026635, loss_ce: 0.012984
2021-12-03 01:32:53,891 iteration 6681 : loss : 0.011832, loss_ce: 0.004207
 98%|████████████████████████████▍| 393/400 [2:59:48<03:03, 26.27s/it]2021-12-03 01:32:55,404 iteration 6682 : loss : 0.014270, loss_ce: 0.004539
2021-12-03 01:32:56,909 iteration 6683 : loss : 0.018459, loss_ce: 0.006156
2021-12-03 01:32:58,388 iteration 6684 : loss : 0.026403, loss_ce: 0.004946
2021-12-03 01:32:59,829 iteration 6685 : loss : 0.012500, loss_ce: 0.004486
2021-12-03 01:33:01,303 iteration 6686 : loss : 0.014720, loss_ce: 0.004720
2021-12-03 01:33:02,777 iteration 6687 : loss : 0.019366, loss_ce: 0.007410
2021-12-03 01:33:04,263 iteration 6688 : loss : 0.017707, loss_ce: 0.005865
2021-12-03 01:33:05,717 iteration 6689 : loss : 0.012959, loss_ce: 0.005029
2021-12-03 01:33:07,257 iteration 6690 : loss : 0.017970, loss_ce: 0.006316
2021-12-03 01:33:08,657 iteration 6691 : loss : 0.013900, loss_ce: 0.005360
2021-12-03 01:33:10,062 iteration 6692 : loss : 0.012681, loss_ce: 0.007392
2021-12-03 01:33:11,531 iteration 6693 : loss : 0.014624, loss_ce: 0.006168
2021-12-03 01:33:12,932 iteration 6694 : loss : 0.010119, loss_ce: 0.004096
2021-12-03 01:33:14,361 iteration 6695 : loss : 0.015316, loss_ce: 0.004581
2021-12-03 01:33:15,819 iteration 6696 : loss : 0.017558, loss_ce: 0.009702
2021-12-03 01:33:17,294 iteration 6697 : loss : 0.016866, loss_ce: 0.006271
2021-12-03 01:33:18,692 iteration 6698 : loss : 0.018778, loss_ce: 0.006832
 98%|████████████████████████████▌| 394/400 [3:00:12<02:34, 25.83s/it]2021-12-03 01:33:20,220 iteration 6699 : loss : 0.015148, loss_ce: 0.004069
2021-12-03 01:33:21,728 iteration 6700 : loss : 0.015402, loss_ce: 0.005932
2021-12-03 01:33:23,268 iteration 6701 : loss : 0.027510, loss_ce: 0.007820
2021-12-03 01:33:24,694 iteration 6702 : loss : 0.014730, loss_ce: 0.005112
2021-12-03 01:33:26,241 iteration 6703 : loss : 0.015918, loss_ce: 0.005033
2021-12-03 01:33:27,701 iteration 6704 : loss : 0.016942, loss_ce: 0.007986
2021-12-03 01:33:29,098 iteration 6705 : loss : 0.012650, loss_ce: 0.003641
2021-12-03 01:33:30,525 iteration 6706 : loss : 0.012926, loss_ce: 0.004243
2021-12-03 01:33:31,986 iteration 6707 : loss : 0.014531, loss_ce: 0.004995
2021-12-03 01:33:33,395 iteration 6708 : loss : 0.010498, loss_ce: 0.003265
2021-12-03 01:33:34,835 iteration 6709 : loss : 0.013940, loss_ce: 0.003833
2021-12-03 01:33:36,309 iteration 6710 : loss : 0.014303, loss_ce: 0.005521
2021-12-03 01:33:37,754 iteration 6711 : loss : 0.014038, loss_ce: 0.006045
2021-12-03 01:33:39,248 iteration 6712 : loss : 0.014035, loss_ce: 0.005658
2021-12-03 01:33:40,695 iteration 6713 : loss : 0.013261, loss_ce: 0.004154
2021-12-03 01:33:42,167 iteration 6714 : loss : 0.013269, loss_ce: 0.005214
2021-12-03 01:33:42,167 Training Data Eval:
2021-12-03 01:33:49,567   Average segmentation loss on training set: 0.0082
2021-12-03 01:33:49,568 Validation Data Eval:
2021-12-03 01:33:52,137   Average segmentation loss on validation set: 0.0724
2021-12-03 01:33:53,587 iteration 6715 : loss : 0.009225, loss_ce: 0.002658
 99%|████████████████████████████▋| 395/400 [3:00:47<02:22, 28.55s/it]2021-12-03 01:33:55,055 iteration 6716 : loss : 0.010911, loss_ce: 0.003602
2021-12-03 01:33:56,538 iteration 6717 : loss : 0.016034, loss_ce: 0.004403
2021-12-03 01:33:58,056 iteration 6718 : loss : 0.023106, loss_ce: 0.010560
2021-12-03 01:33:59,557 iteration 6719 : loss : 0.030898, loss_ce: 0.010965
2021-12-03 01:34:01,038 iteration 6720 : loss : 0.051886, loss_ce: 0.009084
2021-12-03 01:34:02,542 iteration 6721 : loss : 0.015129, loss_ce: 0.006593
2021-12-03 01:34:03,992 iteration 6722 : loss : 0.011847, loss_ce: 0.004806
2021-12-03 01:34:05,465 iteration 6723 : loss : 0.016753, loss_ce: 0.006758
2021-12-03 01:34:06,888 iteration 6724 : loss : 0.013735, loss_ce: 0.006044
2021-12-03 01:34:08,337 iteration 6725 : loss : 0.010563, loss_ce: 0.003733
2021-12-03 01:34:09,716 iteration 6726 : loss : 0.009674, loss_ce: 0.003264
2021-12-03 01:34:11,262 iteration 6727 : loss : 0.022842, loss_ce: 0.007855
2021-12-03 01:34:12,692 iteration 6728 : loss : 0.016153, loss_ce: 0.006679
2021-12-03 01:34:14,194 iteration 6729 : loss : 0.021049, loss_ce: 0.007149
2021-12-03 01:34:15,740 iteration 6730 : loss : 0.018477, loss_ce: 0.007336
2021-12-03 01:34:17,234 iteration 6731 : loss : 0.019862, loss_ce: 0.006922
2021-12-03 01:34:18,681 iteration 6732 : loss : 0.011506, loss_ce: 0.005136
 99%|████████████████████████████▋| 396/400 [3:01:12<01:50, 27.51s/it]2021-12-03 01:34:20,149 iteration 6733 : loss : 0.010106, loss_ce: 0.004144
2021-12-03 01:34:21,610 iteration 6734 : loss : 0.014227, loss_ce: 0.003990
2021-12-03 01:34:23,113 iteration 6735 : loss : 0.022228, loss_ce: 0.006924
2021-12-03 01:34:24,576 iteration 6736 : loss : 0.011961, loss_ce: 0.005341
2021-12-03 01:34:25,995 iteration 6737 : loss : 0.013051, loss_ce: 0.006424
2021-12-03 01:34:27,395 iteration 6738 : loss : 0.012342, loss_ce: 0.003770
2021-12-03 01:34:28,845 iteration 6739 : loss : 0.017783, loss_ce: 0.007164
2021-12-03 01:34:30,346 iteration 6740 : loss : 0.017894, loss_ce: 0.006138
2021-12-03 01:34:31,831 iteration 6741 : loss : 0.019010, loss_ce: 0.008012
2021-12-03 01:34:33,284 iteration 6742 : loss : 0.013590, loss_ce: 0.006417
2021-12-03 01:34:34,683 iteration 6743 : loss : 0.011972, loss_ce: 0.002852
2021-12-03 01:34:36,173 iteration 6744 : loss : 0.020284, loss_ce: 0.007499
2021-12-03 01:34:37,628 iteration 6745 : loss : 0.015015, loss_ce: 0.007120
2021-12-03 01:34:39,035 iteration 6746 : loss : 0.011937, loss_ce: 0.003800
2021-12-03 01:34:40,480 iteration 6747 : loss : 0.010525, loss_ce: 0.003318
2021-12-03 01:34:41,957 iteration 6748 : loss : 0.012498, loss_ce: 0.005887
2021-12-03 01:34:43,403 iteration 6749 : loss : 0.011860, loss_ce: 0.003278
 99%|████████████████████████████▊| 397/400 [3:01:37<01:20, 26.67s/it]2021-12-03 01:34:44,914 iteration 6750 : loss : 0.011779, loss_ce: 0.005182
2021-12-03 01:34:46,429 iteration 6751 : loss : 0.011980, loss_ce: 0.004505
2021-12-03 01:34:47,813 iteration 6752 : loss : 0.011470, loss_ce: 0.003437
2021-12-03 01:34:49,287 iteration 6753 : loss : 0.018116, loss_ce: 0.007368
2021-12-03 01:34:50,760 iteration 6754 : loss : 0.012615, loss_ce: 0.004285
2021-12-03 01:34:52,186 iteration 6755 : loss : 0.012800, loss_ce: 0.003940
2021-12-03 01:34:53,621 iteration 6756 : loss : 0.014657, loss_ce: 0.005957
2021-12-03 01:34:55,140 iteration 6757 : loss : 0.013440, loss_ce: 0.004251
2021-12-03 01:34:56,569 iteration 6758 : loss : 0.013944, loss_ce: 0.005823
2021-12-03 01:34:58,033 iteration 6759 : loss : 0.012228, loss_ce: 0.005028
2021-12-03 01:34:59,571 iteration 6760 : loss : 0.026171, loss_ce: 0.005817
2021-12-03 01:35:01,042 iteration 6761 : loss : 0.013172, loss_ce: 0.005166
2021-12-03 01:35:02,480 iteration 6762 : loss : 0.016581, loss_ce: 0.004948
2021-12-03 01:35:04,023 iteration 6763 : loss : 0.022559, loss_ce: 0.008223
2021-12-03 01:35:05,446 iteration 6764 : loss : 0.020041, loss_ce: 0.007630
2021-12-03 01:35:06,951 iteration 6765 : loss : 0.017038, loss_ce: 0.006246
2021-12-03 01:35:08,374 iteration 6766 : loss : 0.011785, loss_ce: 0.005378
100%|████████████████████████████▊| 398/400 [3:02:02<00:52, 26.16s/it]2021-12-03 01:35:09,879 iteration 6767 : loss : 0.019970, loss_ce: 0.007099
2021-12-03 01:35:11,443 iteration 6768 : loss : 0.017814, loss_ce: 0.006747
2021-12-03 01:35:12,910 iteration 6769 : loss : 0.014567, loss_ce: 0.005951
2021-12-03 01:35:14,340 iteration 6770 : loss : 0.018667, loss_ce: 0.009645
2021-12-03 01:35:15,895 iteration 6771 : loss : 0.040442, loss_ce: 0.008375
2021-12-03 01:35:17,327 iteration 6772 : loss : 0.013823, loss_ce: 0.004998
2021-12-03 01:35:18,684 iteration 6773 : loss : 0.011533, loss_ce: 0.003509
2021-12-03 01:35:20,164 iteration 6774 : loss : 0.027057, loss_ce: 0.005620
2021-12-03 01:35:21,633 iteration 6775 : loss : 0.019341, loss_ce: 0.007042
2021-12-03 01:35:23,084 iteration 6776 : loss : 0.019935, loss_ce: 0.006795
2021-12-03 01:35:24,609 iteration 6777 : loss : 0.016277, loss_ce: 0.008251
2021-12-03 01:35:26,055 iteration 6778 : loss : 0.011082, loss_ce: 0.003669
2021-12-03 01:35:27,586 iteration 6779 : loss : 0.017164, loss_ce: 0.006969
2021-12-03 01:35:29,063 iteration 6780 : loss : 0.012367, loss_ce: 0.005788
2021-12-03 01:35:30,570 iteration 6781 : loss : 0.017177, loss_ce: 0.008085
2021-12-03 01:35:32,086 iteration 6782 : loss : 0.012426, loss_ce: 0.004598
2021-12-03 01:35:33,536 iteration 6783 : loss : 0.014389, loss_ce: 0.004592
100%|████████████████████████████▉| 399/400 [3:02:27<00:25, 25.86s/it]2021-12-03 01:35:35,115 iteration 6784 : loss : 0.017947, loss_ce: 0.005496
2021-12-03 01:35:36,598 iteration 6785 : loss : 0.021745, loss_ce: 0.007237
2021-12-03 01:35:38,014 iteration 6786 : loss : 0.011024, loss_ce: 0.004193
2021-12-03 01:35:39,456 iteration 6787 : loss : 0.013921, loss_ce: 0.004992
2021-12-03 01:35:40,935 iteration 6788 : loss : 0.013194, loss_ce: 0.005463
2021-12-03 01:35:42,403 iteration 6789 : loss : 0.014319, loss_ce: 0.004312
2021-12-03 01:35:43,840 iteration 6790 : loss : 0.012189, loss_ce: 0.004927
2021-12-03 01:35:45,320 iteration 6791 : loss : 0.013852, loss_ce: 0.005705
2021-12-03 01:35:46,732 iteration 6792 : loss : 0.011976, loss_ce: 0.005051
2021-12-03 01:35:48,245 iteration 6793 : loss : 0.018034, loss_ce: 0.006018
2021-12-03 01:35:49,723 iteration 6794 : loss : 0.020730, loss_ce: 0.007088
2021-12-03 01:35:51,229 iteration 6795 : loss : 0.015313, loss_ce: 0.005055
2021-12-03 01:35:52,743 iteration 6796 : loss : 0.013606, loss_ce: 0.006769
2021-12-03 01:35:54,127 iteration 6797 : loss : 0.010960, loss_ce: 0.003381
2021-12-03 01:35:55,624 iteration 6798 : loss : 0.014724, loss_ce: 0.004527
2021-12-03 01:35:57,174 iteration 6799 : loss : 0.016619, loss_ce: 0.006923
2021-12-03 01:35:57,174 Training Data Eval:
2021-12-03 01:36:04,562   Average segmentation loss on training set: 0.0080
2021-12-03 01:36:04,562 Validation Data Eval:
2021-12-03 01:36:07,150   Average segmentation loss on validation set: 0.0665
2021-12-03 01:36:08,593 iteration 6800 : loss : 0.011258, loss_ce: 0.002917
2021-12-03 01:36:10,564 save model to ../model/TU_RUNMC256/TU_pretrain_R50-ViT-B_16_skip3_bs16_256/1channelepoch_399.pth
2021-12-03 01:36:12,489 save model to ../model/TU_RUNMC256/TU_pretrain_R50-ViT-B_16_skip3_bs16_256/1channelepoch_399.pth
100%|████████████████████████████▉| 399/400 [3:03:06<00:27, 27.54s/it]
