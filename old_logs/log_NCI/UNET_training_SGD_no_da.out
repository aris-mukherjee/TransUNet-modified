2021-11-30 12:27:21,381 Logging directory: /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/TransUNet/log_dir/trRUNMC_cv1_no_da_r3/i2i2l/
2021-11-30 12:27:21,381 Tensorboard directory: /scratch_net/biwidl217_second/arismu/Tensorboard/trRUNMC_cv1_no_da_r3/i2i2l/
2021-11-30 12:27:21,381 ============================================================
2021-11-30 12:27:21,381 EXPERIMENT NAME: trRUNMC_cv1_no_da_r3/i2i2l/
2021-11-30 12:27:21,381 ============================================================
2021-11-30 12:27:21,381 Loading data...
2021-11-30 12:27:21,381 Reading NCI - RUNMC images...
2021-11-30 12:27:21,381 Data root directory: /itet-stor/arismu/bmicdatasets-originals/Originals/Challenge_Datasets/NCI_Prostate/
2021-11-30 12:27:21,385 Already preprocessed this configuration. Loading now!
2021-11-30 12:27:21,406 Training Images: (256, 256, 286)
2021-11-30 12:27:21,407 Training Labels: (256, 256, 286)
2021-11-30 12:27:21,407 Validation Images: (256, 256, 98)
2021-11-30 12:27:21,407 Validation Labels: (256, 256, 98)
2021-11-30 12:27:21,407 ============================================================
2021-11-30 12:27:21,449 17 iterations per epoch. 6800 max iterations 
  0%|                                         | 0/400 [00:00<?, ?it/s]2021-11-30 12:27:24,250 iteration 1 : loss : 1.062713, loss_ce: 1.355345
2021-11-30 12:27:25,453 iteration 2 : loss : 1.061149, loss_ce: 1.350731
2021-11-30 12:27:26,662 iteration 3 : loss : 1.055027, loss_ce: 1.339831
2021-11-30 12:27:27,876 iteration 4 : loss : 1.053834, loss_ce: 1.329420
2021-11-30 12:27:29,094 iteration 5 : loss : 1.036813, loss_ce: 1.309276
2021-11-30 12:27:30,308 iteration 6 : loss : 1.032398, loss_ce: 1.293601
2021-11-30 12:27:31,514 iteration 7 : loss : 1.014551, loss_ce: 1.271083
2021-11-30 12:27:32,731 iteration 8 : loss : 1.013722, loss_ce: 1.246221
2021-11-30 12:27:33,942 iteration 9 : loss : 0.970607, loss_ce: 1.217323
2021-11-30 12:27:35,171 iteration 10 : loss : 0.981360, loss_ce: 1.188650
2021-11-30 12:27:36,390 iteration 11 : loss : 0.949360, loss_ce: 1.159872
2021-11-30 12:27:37,606 iteration 12 : loss : 0.935218, loss_ce: 1.128901
2021-11-30 12:27:38,821 iteration 13 : loss : 0.920011, loss_ce: 1.098437
2021-11-30 12:27:40,041 iteration 14 : loss : 0.900968, loss_ce: 1.066976
2021-11-30 12:27:41,304 iteration 15 : loss : 0.880522, loss_ce: 1.035910
2021-11-30 12:27:42,632 iteration 16 : loss : 0.866621, loss_ce: 1.007284
2021-11-30 12:27:43,969 iteration 17 : loss : 0.839952, loss_ce: 0.977238
  0%|                               | 1/400 [00:22<2:30:30, 22.63s/it]2021-11-30 12:27:45,379 iteration 18 : loss : 0.823261, loss_ce: 0.947505
2021-11-30 12:27:46,682 iteration 19 : loss : 0.814602, loss_ce: 0.914078
2021-11-30 12:27:48,005 iteration 20 : loss : 0.794558, loss_ce: 0.886904
2021-11-30 12:27:49,321 iteration 21 : loss : 0.776118, loss_ce: 0.857902
2021-11-30 12:27:50,647 iteration 22 : loss : 0.752400, loss_ce: 0.839326
2021-11-30 12:27:51,982 iteration 23 : loss : 0.742277, loss_ce: 0.806043
2021-11-30 12:27:53,313 iteration 24 : loss : 0.728215, loss_ce: 0.785925
2021-11-30 12:27:54,648 iteration 25 : loss : 0.713232, loss_ce: 0.752130
2021-11-30 12:27:55,992 iteration 26 : loss : 0.691424, loss_ce: 0.738571
2021-11-30 12:27:57,329 iteration 27 : loss : 0.683392, loss_ce: 0.719648
2021-11-30 12:27:58,665 iteration 28 : loss : 0.673511, loss_ce: 0.681579
2021-11-30 12:27:59,995 iteration 29 : loss : 0.652929, loss_ce: 0.668373
2021-11-30 12:28:01,326 iteration 30 : loss : 0.641396, loss_ce: 0.645621
2021-11-30 12:28:02,670 iteration 31 : loss : 0.633595, loss_ce: 0.613623
2021-11-30 12:28:04,018 iteration 32 : loss : 0.624042, loss_ce: 0.615002
2021-11-30 12:28:05,362 iteration 33 : loss : 0.610794, loss_ce: 0.580444
2021-11-30 12:28:06,700 iteration 34 : loss : 0.603242, loss_ce: 0.571265
  0%|▏                              | 2/400 [00:45<2:30:22, 22.67s/it]2021-11-30 12:28:08,107 iteration 35 : loss : 0.586781, loss_ce: 0.551643
2021-11-30 12:28:09,452 iteration 36 : loss : 0.580553, loss_ce: 0.537913
2021-11-30 12:28:10,809 iteration 37 : loss : 0.570669, loss_ce: 0.519482
2021-11-30 12:28:12,158 iteration 38 : loss : 0.556530, loss_ce: 0.509627
2021-11-30 12:28:13,504 iteration 39 : loss : 0.546850, loss_ce: 0.482455
2021-11-30 12:28:14,859 iteration 40 : loss : 0.538036, loss_ce: 0.479652
2021-11-30 12:28:16,202 iteration 41 : loss : 0.541451, loss_ce: 0.480081
2021-11-30 12:28:17,549 iteration 42 : loss : 0.524953, loss_ce: 0.459841
2021-11-30 12:28:18,900 iteration 43 : loss : 0.522855, loss_ce: 0.433536
2021-11-30 12:28:20,245 iteration 44 : loss : 0.517023, loss_ce: 0.431708
2021-11-30 12:28:21,608 iteration 45 : loss : 0.510392, loss_ce: 0.420266
2021-11-30 12:28:22,961 iteration 46 : loss : 0.500533, loss_ce: 0.404493
2021-11-30 12:28:24,319 iteration 47 : loss : 0.495270, loss_ce: 0.409195
2021-11-30 12:28:25,677 iteration 48 : loss : 0.493418, loss_ce: 0.399622
2021-11-30 12:28:27,038 iteration 49 : loss : 0.486537, loss_ce: 0.382619
2021-11-30 12:28:28,399 iteration 50 : loss : 0.478258, loss_ce: 0.394006
2021-11-30 12:28:29,759 iteration 51 : loss : 0.475893, loss_ce: 0.382742
  1%|▏                              | 3/400 [01:08<2:31:09, 22.85s/it]2021-11-30 12:28:31,194 iteration 52 : loss : 0.473611, loss_ce: 0.387870
2021-11-30 12:28:32,556 iteration 53 : loss : 0.466747, loss_ce: 0.366228
2021-11-30 12:28:33,911 iteration 54 : loss : 0.471056, loss_ce: 0.341148
2021-11-30 12:28:35,270 iteration 55 : loss : 0.453511, loss_ce: 0.349032
2021-11-30 12:28:36,634 iteration 56 : loss : 0.458347, loss_ce: 0.328629
2021-11-30 12:28:37,995 iteration 57 : loss : 0.458370, loss_ce: 0.316588
2021-11-30 12:28:39,348 iteration 58 : loss : 0.450274, loss_ce: 0.331008
2021-11-30 12:28:40,708 iteration 59 : loss : 0.447813, loss_ce: 0.324592
2021-11-30 12:28:42,067 iteration 60 : loss : 0.446242, loss_ce: 0.325842
2021-11-30 12:28:43,432 iteration 61 : loss : 0.435144, loss_ce: 0.312161
2021-11-30 12:28:44,797 iteration 62 : loss : 0.433707, loss_ce: 0.306346
2021-11-30 12:28:46,160 iteration 63 : loss : 0.441819, loss_ce: 0.325570
2021-11-30 12:28:47,520 iteration 64 : loss : 0.431676, loss_ce: 0.294607
2021-11-30 12:28:48,886 iteration 65 : loss : 0.434106, loss_ce: 0.319066
2021-11-30 12:28:50,243 iteration 66 : loss : 0.429106, loss_ce: 0.265244
2021-11-30 12:28:51,602 iteration 67 : loss : 0.427318, loss_ce: 0.289824
2021-11-30 12:28:52,963 iteration 68 : loss : 0.423633, loss_ce: 0.272489
  1%|▎                              | 4/400 [01:31<2:31:42, 22.99s/it]2021-11-30 12:28:54,376 iteration 69 : loss : 0.418817, loss_ce: 0.282555
2021-11-30 12:28:55,726 iteration 70 : loss : 0.421383, loss_ce: 0.273816
2021-11-30 12:28:57,095 iteration 71 : loss : 0.420150, loss_ce: 0.288407
2021-11-30 12:28:58,451 iteration 72 : loss : 0.423522, loss_ce: 0.289283
2021-11-30 12:28:59,814 iteration 73 : loss : 0.421122, loss_ce: 0.274858
2021-11-30 12:29:01,180 iteration 74 : loss : 0.408057, loss_ce: 0.266620
2021-11-30 12:29:02,573 iteration 75 : loss : 0.414327, loss_ce: 0.273510
2021-11-30 12:29:03,930 iteration 76 : loss : 0.405106, loss_ce: 0.260596
2021-11-30 12:29:05,290 iteration 77 : loss : 0.402091, loss_ce: 0.258299
2021-11-30 12:29:06,649 iteration 78 : loss : 0.409914, loss_ce: 0.236435
2021-11-30 12:29:08,004 iteration 79 : loss : 0.395784, loss_ce: 0.242714
2021-11-30 12:29:09,362 iteration 80 : loss : 0.403315, loss_ce: 0.242862
2021-11-30 12:29:10,723 iteration 81 : loss : 0.402008, loss_ce: 0.260758
2021-11-30 12:29:12,085 iteration 82 : loss : 0.398342, loss_ce: 0.230606
2021-11-30 12:29:13,446 iteration 83 : loss : 0.406552, loss_ce: 0.270954
2021-11-30 12:29:14,802 iteration 84 : loss : 0.398879, loss_ce: 0.252515
2021-11-30 12:29:14,802 Training Data Eval:
2021-11-30 12:29:22,480   Average segmentation loss on training set: 0.4022
2021-11-30 12:29:22,481 Validation Data Eval:
2021-11-30 12:29:25,292   Average segmentation loss on validation set: 0.4221
2021-11-30 12:29:30,300 Found new lowest validation loss at iteration 84! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/UNET_RUNMC/best_val_loss_no_da.pth
2021-11-30 12:29:31,557 iteration 85 : loss : 0.397565, loss_ce: 0.243901
  1%|▍                              | 5/400 [02:10<3:08:23, 28.62s/it]2021-11-30 12:29:32,857 iteration 86 : loss : 0.396938, loss_ce: 0.249847
2021-11-30 12:29:34,087 iteration 87 : loss : 0.403187, loss_ce: 0.273634
2021-11-30 12:29:35,310 iteration 88 : loss : 0.395277, loss_ce: 0.238497
2021-11-30 12:29:36,527 iteration 89 : loss : 0.388852, loss_ce: 0.250755
2021-11-30 12:29:37,793 iteration 90 : loss : 0.386916, loss_ce: 0.221772
2021-11-30 12:29:39,126 iteration 91 : loss : 0.394178, loss_ce: 0.235364
2021-11-30 12:29:40,479 iteration 92 : loss : 0.387166, loss_ce: 0.215361
2021-11-30 12:29:41,828 iteration 93 : loss : 0.387737, loss_ce: 0.215911
2021-11-30 12:29:43,177 iteration 94 : loss : 0.382131, loss_ce: 0.218572
2021-11-30 12:29:44,534 iteration 95 : loss : 0.384925, loss_ce: 0.232595
2021-11-30 12:29:45,881 iteration 96 : loss : 0.382944, loss_ce: 0.233169
2021-11-30 12:29:47,241 iteration 97 : loss : 0.383653, loss_ce: 0.229356
2021-11-30 12:29:48,581 iteration 98 : loss : 0.385791, loss_ce: 0.222868
2021-11-30 12:29:49,927 iteration 99 : loss : 0.378735, loss_ce: 0.220080
2021-11-30 12:29:51,284 iteration 100 : loss : 0.381542, loss_ce: 0.235224
2021-11-30 12:29:52,639 iteration 101 : loss : 0.380437, loss_ce: 0.199713
2021-11-30 12:29:54,002 iteration 102 : loss : 0.395681, loss_ce: 0.248883
  2%|▍                              | 6/400 [02:32<2:54:07, 26.52s/it]2021-11-30 12:29:55,410 iteration 103 : loss : 0.382971, loss_ce: 0.222737
2021-11-30 12:29:56,757 iteration 104 : loss : 0.375742, loss_ce: 0.217765
2021-11-30 12:29:58,109 iteration 105 : loss : 0.385314, loss_ce: 0.230885
2021-11-30 12:29:59,463 iteration 106 : loss : 0.374421, loss_ce: 0.218326
2021-11-30 12:30:00,819 iteration 107 : loss : 0.373960, loss_ce: 0.207728
2021-11-30 12:30:02,182 iteration 108 : loss : 0.386119, loss_ce: 0.241223
2021-11-30 12:30:03,526 iteration 109 : loss : 0.374151, loss_ce: 0.204175
2021-11-30 12:30:04,877 iteration 110 : loss : 0.368985, loss_ce: 0.199265
2021-11-30 12:30:06,218 iteration 111 : loss : 0.380597, loss_ce: 0.216367
2021-11-30 12:30:07,568 iteration 112 : loss : 0.377665, loss_ce: 0.219995
2021-11-30 12:30:08,922 iteration 113 : loss : 0.369657, loss_ce: 0.193712
2021-11-30 12:30:10,271 iteration 114 : loss : 0.382709, loss_ce: 0.231264
2021-11-30 12:30:11,620 iteration 115 : loss : 0.363420, loss_ce: 0.201476
2021-11-30 12:30:12,971 iteration 116 : loss : 0.370228, loss_ce: 0.190679
2021-11-30 12:30:14,322 iteration 117 : loss : 0.363722, loss_ce: 0.188612
2021-11-30 12:30:15,677 iteration 118 : loss : 0.379660, loss_ce: 0.224461
2021-11-30 12:30:17,028 iteration 119 : loss : 0.363035, loss_ce: 0.192481
  2%|▌                              | 7/400 [02:55<2:46:11, 25.37s/it]2021-11-30 12:30:18,437 iteration 120 : loss : 0.361338, loss_ce: 0.170301
2021-11-30 12:30:19,796 iteration 121 : loss : 0.370075, loss_ce: 0.188775
2021-11-30 12:30:21,149 iteration 122 : loss : 0.369088, loss_ce: 0.206904
2021-11-30 12:30:22,495 iteration 123 : loss : 0.388398, loss_ce: 0.237221
2021-11-30 12:30:23,853 iteration 124 : loss : 0.360628, loss_ce: 0.191481
2021-11-30 12:30:25,201 iteration 125 : loss : 0.389435, loss_ce: 0.227662
2021-11-30 12:30:26,557 iteration 126 : loss : 0.364472, loss_ce: 0.201881
2021-11-30 12:30:27,906 iteration 127 : loss : 0.366477, loss_ce: 0.171604
2021-11-30 12:30:29,258 iteration 128 : loss : 0.360188, loss_ce: 0.183299
2021-11-30 12:30:30,614 iteration 129 : loss : 0.358600, loss_ce: 0.195362
2021-11-30 12:30:31,961 iteration 130 : loss : 0.356835, loss_ce: 0.191797
2021-11-30 12:30:33,321 iteration 131 : loss : 0.355691, loss_ce: 0.193722
2021-11-30 12:30:34,670 iteration 132 : loss : 0.372428, loss_ce: 0.217911
2021-11-30 12:30:36,017 iteration 133 : loss : 0.361680, loss_ce: 0.192088
2021-11-30 12:30:37,381 iteration 134 : loss : 0.369129, loss_ce: 0.200333
2021-11-30 12:30:38,737 iteration 135 : loss : 0.377725, loss_ce: 0.226422
2021-11-30 12:30:40,096 iteration 136 : loss : 0.340894, loss_ce: 0.173318
  2%|▌                              | 8/400 [03:18<2:40:58, 24.64s/it]2021-11-30 12:30:41,504 iteration 137 : loss : 0.358143, loss_ce: 0.186374
2021-11-30 12:30:42,847 iteration 138 : loss : 0.363027, loss_ce: 0.181875
2021-11-30 12:30:44,191 iteration 139 : loss : 0.353617, loss_ce: 0.195493
2021-11-30 12:30:45,543 iteration 140 : loss : 0.355698, loss_ce: 0.187640
2021-11-30 12:30:46,904 iteration 141 : loss : 0.353342, loss_ce: 0.180185
2021-11-30 12:30:48,264 iteration 142 : loss : 0.353602, loss_ce: 0.199952
2021-11-30 12:30:49,619 iteration 143 : loss : 0.385628, loss_ce: 0.222909
2021-11-30 12:30:50,982 iteration 144 : loss : 0.363201, loss_ce: 0.166522
2021-11-30 12:30:52,344 iteration 145 : loss : 0.380207, loss_ce: 0.209404
2021-11-30 12:30:53,700 iteration 146 : loss : 0.358342, loss_ce: 0.174842
2021-11-30 12:30:55,060 iteration 147 : loss : 0.352807, loss_ce: 0.168903
2021-11-30 12:30:56,421 iteration 148 : loss : 0.362121, loss_ce: 0.199999
2021-11-30 12:30:57,776 iteration 149 : loss : 0.352075, loss_ce: 0.179743
2021-11-30 12:30:59,137 iteration 150 : loss : 0.374475, loss_ce: 0.213582
2021-11-30 12:31:00,492 iteration 151 : loss : 0.358523, loss_ce: 0.175113
2021-11-30 12:31:01,855 iteration 152 : loss : 0.357286, loss_ce: 0.201023
2021-11-30 12:31:03,214 iteration 153 : loss : 0.351997, loss_ce: 0.183312
  2%|▋                              | 9/400 [03:41<2:37:28, 24.17s/it]2021-11-30 12:31:04,636 iteration 154 : loss : 0.352517, loss_ce: 0.182523
2021-11-30 12:31:05,984 iteration 155 : loss : 0.353963, loss_ce: 0.172050
2021-11-30 12:31:07,335 iteration 156 : loss : 0.363975, loss_ce: 0.199961
2021-11-30 12:31:08,692 iteration 157 : loss : 0.358122, loss_ce: 0.186248
2021-11-30 12:31:10,049 iteration 158 : loss : 0.350114, loss_ce: 0.184528
2021-11-30 12:31:11,412 iteration 159 : loss : 0.350669, loss_ce: 0.189334
2021-11-30 12:31:12,768 iteration 160 : loss : 0.355566, loss_ce: 0.185670
2021-11-30 12:31:14,112 iteration 161 : loss : 0.349277, loss_ce: 0.154847
2021-11-30 12:31:15,467 iteration 162 : loss : 0.339096, loss_ce: 0.159723
2021-11-30 12:31:16,825 iteration 163 : loss : 0.363810, loss_ce: 0.199824
2021-11-30 12:31:18,182 iteration 164 : loss : 0.363369, loss_ce: 0.190484
2021-11-30 12:31:19,527 iteration 165 : loss : 0.365244, loss_ce: 0.208072
2021-11-30 12:31:20,879 iteration 166 : loss : 0.350971, loss_ce: 0.166376
2021-11-30 12:31:22,241 iteration 167 : loss : 0.353836, loss_ce: 0.180980
2021-11-30 12:31:23,590 iteration 168 : loss : 0.351659, loss_ce: 0.162375
2021-11-30 12:31:24,931 iteration 169 : loss : 0.359817, loss_ce: 0.196837
2021-11-30 12:31:24,931 Training Data Eval:
2021-11-30 12:31:32,606   Average segmentation loss on training set: 0.3503
2021-11-30 12:31:32,606 Validation Data Eval:
2021-11-30 12:31:35,273   Average segmentation loss on validation set: 0.3720
2021-11-30 12:31:37,460 Found new lowest validation loss at iteration 169! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/UNET_RUNMC/best_val_loss_no_da.pth
2021-11-30 12:31:38,709 iteration 170 : loss : 0.344334, loss_ce: 0.174263
  2%|▊                             | 10/400 [04:17<2:59:48, 27.66s/it]2021-11-30 12:31:40,003 iteration 171 : loss : 0.355105, loss_ce: 0.183781
2021-11-30 12:31:41,316 iteration 172 : loss : 0.363621, loss_ce: 0.193119
2021-11-30 12:31:42,669 iteration 173 : loss : 0.356568, loss_ce: 0.181714
2021-11-30 12:31:44,029 iteration 174 : loss : 0.350937, loss_ce: 0.174283
2021-11-30 12:31:45,385 iteration 175 : loss : 0.344714, loss_ce: 0.196190
2021-11-30 12:31:46,745 iteration 176 : loss : 0.332817, loss_ce: 0.168635
2021-11-30 12:31:48,106 iteration 177 : loss : 0.359672, loss_ce: 0.179682
2021-11-30 12:31:49,464 iteration 178 : loss : 0.348689, loss_ce: 0.180765
2021-11-30 12:31:50,818 iteration 179 : loss : 0.348693, loss_ce: 0.166154
2021-11-30 12:31:52,170 iteration 180 : loss : 0.337089, loss_ce: 0.150209
2021-11-30 12:31:53,527 iteration 181 : loss : 0.388992, loss_ce: 0.242273
2021-11-30 12:31:54,883 iteration 182 : loss : 0.351676, loss_ce: 0.155092
2021-11-30 12:31:56,243 iteration 183 : loss : 0.351679, loss_ce: 0.171493
2021-11-30 12:31:57,600 iteration 184 : loss : 0.353917, loss_ce: 0.170656
2021-11-30 12:31:58,964 iteration 185 : loss : 0.351678, loss_ce: 0.177416
2021-11-30 12:32:00,320 iteration 186 : loss : 0.340019, loss_ce: 0.158364
2021-11-30 12:32:01,679 iteration 187 : loss : 0.338302, loss_ce: 0.172247
  3%|▊                             | 11/400 [04:40<2:50:02, 26.23s/it]2021-11-30 12:32:03,106 iteration 188 : loss : 0.346305, loss_ce: 0.157691
2021-11-30 12:32:04,461 iteration 189 : loss : 0.355360, loss_ce: 0.184596
2021-11-30 12:32:05,815 iteration 190 : loss : 0.351019, loss_ce: 0.176976
2021-11-30 12:32:07,177 iteration 191 : loss : 0.335000, loss_ce: 0.163719
2021-11-30 12:32:08,535 iteration 192 : loss : 0.343132, loss_ce: 0.186795
2021-11-30 12:32:09,889 iteration 193 : loss : 0.364171, loss_ce: 0.198662
2021-11-30 12:32:11,251 iteration 194 : loss : 0.365238, loss_ce: 0.203790
2021-11-30 12:32:12,612 iteration 195 : loss : 0.349951, loss_ce: 0.174747
2021-11-30 12:32:13,971 iteration 196 : loss : 0.348240, loss_ce: 0.180769
2021-11-30 12:32:15,329 iteration 197 : loss : 0.328766, loss_ce: 0.150252
2021-11-30 12:32:16,685 iteration 198 : loss : 0.346984, loss_ce: 0.166507
2021-11-30 12:32:18,041 iteration 199 : loss : 0.331673, loss_ce: 0.161314
2021-11-30 12:32:19,401 iteration 200 : loss : 0.350329, loss_ce: 0.165754
2021-11-30 12:32:20,766 iteration 201 : loss : 0.332609, loss_ce: 0.148697
2021-11-30 12:32:22,124 iteration 202 : loss : 0.344451, loss_ce: 0.180504
2021-11-30 12:32:23,479 iteration 203 : loss : 0.358647, loss_ce: 0.179393
2021-11-30 12:32:24,839 iteration 204 : loss : 0.355404, loss_ce: 0.162400
  3%|▉                             | 12/400 [05:03<2:43:33, 25.29s/it]2021-11-30 12:32:26,270 iteration 205 : loss : 0.337094, loss_ce: 0.155204
2021-11-30 12:32:27,630 iteration 206 : loss : 0.335428, loss_ce: 0.157659
2021-11-30 12:32:28,990 iteration 207 : loss : 0.346643, loss_ce: 0.174256
2021-11-30 12:32:30,349 iteration 208 : loss : 0.340847, loss_ce: 0.157129
2021-11-30 12:32:31,716 iteration 209 : loss : 0.343101, loss_ce: 0.182714
2021-11-30 12:32:33,075 iteration 210 : loss : 0.343845, loss_ce: 0.153932
2021-11-30 12:32:34,428 iteration 211 : loss : 0.338883, loss_ce: 0.164576
2021-11-30 12:32:35,793 iteration 212 : loss : 0.334206, loss_ce: 0.167448
2021-11-30 12:32:37,152 iteration 213 : loss : 0.358457, loss_ce: 0.180071
2021-11-30 12:32:38,513 iteration 214 : loss : 0.335579, loss_ce: 0.155875
2021-11-30 12:32:39,873 iteration 215 : loss : 0.357614, loss_ce: 0.196048
2021-11-30 12:32:41,226 iteration 216 : loss : 0.348722, loss_ce: 0.188599
2021-11-30 12:32:42,581 iteration 217 : loss : 0.338689, loss_ce: 0.149572
2021-11-30 12:32:43,924 iteration 218 : loss : 0.330316, loss_ce: 0.144509
2021-11-30 12:32:45,280 iteration 219 : loss : 0.361889, loss_ce: 0.173275
2021-11-30 12:32:46,641 iteration 220 : loss : 0.339728, loss_ce: 0.178783
2021-11-30 12:32:47,993 iteration 221 : loss : 0.344032, loss_ce: 0.165582
  3%|▉                             | 13/400 [05:26<2:38:58, 24.65s/it]2021-11-30 12:32:49,407 iteration 222 : loss : 0.342111, loss_ce: 0.177951
2021-11-30 12:32:50,762 iteration 223 : loss : 0.352698, loss_ce: 0.168444
2021-11-30 12:32:52,119 iteration 224 : loss : 0.333878, loss_ce: 0.148562
2021-11-30 12:32:53,472 iteration 225 : loss : 0.325296, loss_ce: 0.143495
2021-11-30 12:32:54,828 iteration 226 : loss : 0.359958, loss_ce: 0.193502
2021-11-30 12:32:56,187 iteration 227 : loss : 0.359120, loss_ce: 0.185683
2021-11-30 12:32:57,538 iteration 228 : loss : 0.357369, loss_ce: 0.186235
2021-11-30 12:32:58,889 iteration 229 : loss : 0.327776, loss_ce: 0.145358
2021-11-30 12:33:00,251 iteration 230 : loss : 0.329110, loss_ce: 0.180163
2021-11-30 12:33:01,603 iteration 231 : loss : 0.330038, loss_ce: 0.148817
2021-11-30 12:33:02,960 iteration 232 : loss : 0.324610, loss_ce: 0.151973
2021-11-30 12:33:04,313 iteration 233 : loss : 0.342407, loss_ce: 0.159320
2021-11-30 12:33:05,666 iteration 234 : loss : 0.330429, loss_ce: 0.153946
2021-11-30 12:33:07,020 iteration 235 : loss : 0.349940, loss_ce: 0.183786
2021-11-30 12:33:08,360 iteration 236 : loss : 0.352611, loss_ce: 0.170285
2021-11-30 12:33:09,708 iteration 237 : loss : 0.326001, loss_ce: 0.149613
2021-11-30 12:33:11,062 iteration 238 : loss : 0.343512, loss_ce: 0.129456
  4%|█                             | 14/400 [05:49<2:35:32, 24.18s/it]2021-11-30 12:33:12,496 iteration 239 : loss : 0.331597, loss_ce: 0.159887
2021-11-30 12:33:13,850 iteration 240 : loss : 0.342318, loss_ce: 0.160609
2021-11-30 12:33:15,212 iteration 241 : loss : 0.337018, loss_ce: 0.158281
2021-11-30 12:33:16,572 iteration 242 : loss : 0.344789, loss_ce: 0.182445
2021-11-30 12:33:17,916 iteration 243 : loss : 0.352874, loss_ce: 0.180994
2021-11-30 12:33:19,276 iteration 244 : loss : 0.325459, loss_ce: 0.139743
2021-11-30 12:33:20,633 iteration 245 : loss : 0.346573, loss_ce: 0.157354
2021-11-30 12:33:21,982 iteration 246 : loss : 0.341828, loss_ce: 0.176695
2021-11-30 12:33:23,346 iteration 247 : loss : 0.330564, loss_ce: 0.146152
2021-11-30 12:33:24,715 iteration 248 : loss : 0.344786, loss_ce: 0.170113
2021-11-30 12:33:26,070 iteration 249 : loss : 0.315999, loss_ce: 0.148786
2021-11-30 12:33:27,426 iteration 250 : loss : 0.340713, loss_ce: 0.171761
2021-11-30 12:33:28,784 iteration 251 : loss : 0.352699, loss_ce: 0.179261
2021-11-30 12:33:30,146 iteration 252 : loss : 0.345430, loss_ce: 0.169571
2021-11-30 12:33:31,503 iteration 253 : loss : 0.342863, loss_ce: 0.175246
2021-11-30 12:33:32,855 iteration 254 : loss : 0.335383, loss_ce: 0.156545
2021-11-30 12:33:32,855 Training Data Eval:
2021-11-30 12:33:40,504   Average segmentation loss on training set: 0.3346
2021-11-30 12:33:40,505 Validation Data Eval:
2021-11-30 12:33:43,139   Average segmentation loss on validation set: 0.3521
2021-11-30 12:33:45,104 Found new lowest validation loss at iteration 254! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/UNET_RUNMC/best_val_loss_no_da.pth
2021-11-30 12:33:46,362 iteration 255 : loss : 0.323400, loss_ce: 0.131572
  4%|█▏                            | 15/400 [06:24<2:56:36, 27.52s/it]2021-11-30 12:33:47,650 iteration 256 : loss : 0.329632, loss_ce: 0.155523
2021-11-30 12:33:48,913 iteration 257 : loss : 0.326065, loss_ce: 0.155084
2021-11-30 12:33:50,246 iteration 258 : loss : 0.312542, loss_ce: 0.131021
2021-11-30 12:33:51,603 iteration 259 : loss : 0.334762, loss_ce: 0.135278
2021-11-30 12:33:52,947 iteration 260 : loss : 0.322324, loss_ce: 0.153558
2021-11-30 12:33:54,299 iteration 261 : loss : 0.344006, loss_ce: 0.179250
2021-11-30 12:33:55,653 iteration 262 : loss : 0.323869, loss_ce: 0.156294
2021-11-30 12:33:56,997 iteration 263 : loss : 0.338336, loss_ce: 0.169888
2021-11-30 12:33:58,340 iteration 264 : loss : 0.333114, loss_ce: 0.157438
2021-11-30 12:33:59,693 iteration 265 : loss : 0.323640, loss_ce: 0.133656
2021-11-30 12:34:01,050 iteration 266 : loss : 0.330354, loss_ce: 0.149917
2021-11-30 12:34:02,406 iteration 267 : loss : 0.343368, loss_ce: 0.157441
2021-11-30 12:34:03,757 iteration 268 : loss : 0.335467, loss_ce: 0.160681
2021-11-30 12:34:05,104 iteration 269 : loss : 0.323569, loss_ce: 0.142583
2021-11-30 12:34:06,467 iteration 270 : loss : 0.323467, loss_ce: 0.145504
2021-11-30 12:34:07,829 iteration 271 : loss : 0.325427, loss_ce: 0.170779
2021-11-30 12:34:09,186 iteration 272 : loss : 0.351511, loss_ce: 0.185974
  4%|█▏                            | 16/400 [06:47<2:47:05, 26.11s/it]2021-11-30 12:34:10,614 iteration 273 : loss : 0.314601, loss_ce: 0.133380
2021-11-30 12:34:11,979 iteration 274 : loss : 0.327440, loss_ce: 0.159353
2021-11-30 12:34:13,340 iteration 275 : loss : 0.320586, loss_ce: 0.128651
2021-11-30 12:34:14,704 iteration 276 : loss : 0.322833, loss_ce: 0.145173
2021-11-30 12:34:16,069 iteration 277 : loss : 0.342748, loss_ce: 0.160610
2021-11-30 12:34:17,435 iteration 278 : loss : 0.315318, loss_ce: 0.142942
2021-11-30 12:34:18,799 iteration 279 : loss : 0.320770, loss_ce: 0.171195
2021-11-30 12:34:20,168 iteration 280 : loss : 0.317720, loss_ce: 0.141151
2021-11-30 12:34:21,530 iteration 281 : loss : 0.326968, loss_ce: 0.139885
2021-11-30 12:34:22,891 iteration 282 : loss : 0.347008, loss_ce: 0.191995
2021-11-30 12:34:24,254 iteration 283 : loss : 0.327477, loss_ce: 0.150789
2021-11-30 12:34:25,613 iteration 284 : loss : 0.318335, loss_ce: 0.146342
2021-11-30 12:34:26,975 iteration 285 : loss : 0.334781, loss_ce: 0.180803
2021-11-30 12:34:28,338 iteration 286 : loss : 0.328086, loss_ce: 0.156942
2021-11-30 12:34:29,699 iteration 287 : loss : 0.332981, loss_ce: 0.166617
2021-11-30 12:34:31,063 iteration 288 : loss : 0.351804, loss_ce: 0.165871
2021-11-30 12:34:32,418 iteration 289 : loss : 0.340801, loss_ce: 0.171139
  4%|█▎                            | 17/400 [07:11<2:41:08, 25.24s/it]2021-11-30 12:34:33,843 iteration 290 : loss : 0.322357, loss_ce: 0.169048
2021-11-30 12:34:35,200 iteration 291 : loss : 0.312707, loss_ce: 0.155214
2021-11-30 12:34:36,556 iteration 292 : loss : 0.343909, loss_ce: 0.177474
2021-11-30 12:34:37,917 iteration 293 : loss : 0.323345, loss_ce: 0.127047
2021-11-30 12:34:39,278 iteration 294 : loss : 0.333076, loss_ce: 0.177560
2021-11-30 12:34:40,637 iteration 295 : loss : 0.312169, loss_ce: 0.146469
2021-11-30 12:34:41,995 iteration 296 : loss : 0.310340, loss_ce: 0.141210
2021-11-30 12:34:43,358 iteration 297 : loss : 0.324417, loss_ce: 0.142672
2021-11-30 12:34:44,722 iteration 298 : loss : 0.321439, loss_ce: 0.139341
2021-11-30 12:34:46,080 iteration 299 : loss : 0.331282, loss_ce: 0.144488
2021-11-30 12:34:47,444 iteration 300 : loss : 0.319744, loss_ce: 0.149543
2021-11-30 12:34:48,807 iteration 301 : loss : 0.314006, loss_ce: 0.140102
2021-11-30 12:34:50,174 iteration 302 : loss : 0.315054, loss_ce: 0.133037
2021-11-30 12:34:51,537 iteration 303 : loss : 0.330949, loss_ce: 0.166718
2021-11-30 12:34:52,899 iteration 304 : loss : 0.339379, loss_ce: 0.154953
2021-11-30 12:34:54,261 iteration 305 : loss : 0.304686, loss_ce: 0.123454
2021-11-30 12:34:55,621 iteration 306 : loss : 0.336968, loss_ce: 0.179511
  4%|█▎                            | 18/400 [07:34<2:36:48, 24.63s/it]2021-11-30 12:34:57,047 iteration 307 : loss : 0.329085, loss_ce: 0.150548
2021-11-30 12:34:58,407 iteration 308 : loss : 0.320224, loss_ce: 0.166155
2021-11-30 12:34:59,765 iteration 309 : loss : 0.342449, loss_ce: 0.185485
2021-11-30 12:35:01,117 iteration 310 : loss : 0.321729, loss_ce: 0.150948
2021-11-30 12:35:02,471 iteration 311 : loss : 0.310883, loss_ce: 0.121437
2021-11-30 12:35:03,832 iteration 312 : loss : 0.300439, loss_ce: 0.126794
2021-11-30 12:35:05,189 iteration 313 : loss : 0.329187, loss_ce: 0.125301
2021-11-30 12:35:06,550 iteration 314 : loss : 0.325056, loss_ce: 0.155180
2021-11-30 12:35:07,908 iteration 315 : loss : 0.307551, loss_ce: 0.140042
2021-11-30 12:35:09,267 iteration 316 : loss : 0.312717, loss_ce: 0.154482
2021-11-30 12:35:10,621 iteration 317 : loss : 0.316401, loss_ce: 0.151160
2021-11-30 12:35:11,979 iteration 318 : loss : 0.318657, loss_ce: 0.130547
2021-11-30 12:35:13,337 iteration 319 : loss : 0.317733, loss_ce: 0.142187
2021-11-30 12:35:14,697 iteration 320 : loss : 0.320791, loss_ce: 0.163759
2021-11-30 12:35:16,065 iteration 321 : loss : 0.311065, loss_ce: 0.140079
2021-11-30 12:35:17,423 iteration 322 : loss : 0.320592, loss_ce: 0.145928
2021-11-30 12:35:18,784 iteration 323 : loss : 0.314497, loss_ce: 0.143617
  5%|█▍                            | 19/400 [07:57<2:33:35, 24.19s/it]2021-11-30 12:35:20,193 iteration 324 : loss : 0.327967, loss_ce: 0.143322
2021-11-30 12:35:21,543 iteration 325 : loss : 0.311591, loss_ce: 0.125826
2021-11-30 12:35:22,898 iteration 326 : loss : 0.324054, loss_ce: 0.161830
2021-11-30 12:35:24,248 iteration 327 : loss : 0.327379, loss_ce: 0.170942
2021-11-30 12:35:25,608 iteration 328 : loss : 0.303583, loss_ce: 0.140511
2021-11-30 12:35:26,958 iteration 329 : loss : 0.303119, loss_ce: 0.131209
2021-11-30 12:35:28,309 iteration 330 : loss : 0.318187, loss_ce: 0.164886
2021-11-30 12:35:29,661 iteration 331 : loss : 0.298628, loss_ce: 0.123456
2021-11-30 12:35:31,011 iteration 332 : loss : 0.323280, loss_ce: 0.147100
2021-11-30 12:35:32,360 iteration 333 : loss : 0.315817, loss_ce: 0.155955
2021-11-30 12:35:33,720 iteration 334 : loss : 0.296919, loss_ce: 0.126514
2021-11-30 12:35:35,064 iteration 335 : loss : 0.320115, loss_ce: 0.161232
2021-11-30 12:35:36,423 iteration 336 : loss : 0.325185, loss_ce: 0.165837
2021-11-30 12:35:37,782 iteration 337 : loss : 0.303251, loss_ce: 0.128320
2021-11-30 12:35:39,146 iteration 338 : loss : 0.322944, loss_ce: 0.131188
2021-11-30 12:35:40,501 iteration 339 : loss : 0.332112, loss_ce: 0.173037
2021-11-30 12:35:40,501 Training Data Eval:
2021-11-30 12:35:48,290   Average segmentation loss on training set: 0.3089
2021-11-30 12:35:48,290 Validation Data Eval:
2021-11-30 12:35:50,962   Average segmentation loss on validation set: 0.3208
2021-11-30 12:35:52,912 Found new lowest validation loss at iteration 339! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/UNET_RUNMC/best_val_loss_no_da.pth
2021-11-30 12:35:54,171 iteration 340 : loss : 0.305266, loss_ce: 0.133347
  5%|█▌                            | 20/400 [08:32<2:54:28, 27.55s/it]2021-11-30 12:35:55,463 iteration 341 : loss : 0.306662, loss_ce: 0.140211
2021-11-30 12:35:56,747 iteration 342 : loss : 0.313182, loss_ce: 0.151412
2021-11-30 12:35:58,093 iteration 343 : loss : 0.314276, loss_ce: 0.149909
2021-11-30 12:35:59,452 iteration 344 : loss : 0.318300, loss_ce: 0.160320
2021-11-30 12:36:00,813 iteration 345 : loss : 0.308094, loss_ce: 0.147724
2021-11-30 12:36:02,171 iteration 346 : loss : 0.303226, loss_ce: 0.124655
2021-11-30 12:36:03,522 iteration 347 : loss : 0.302757, loss_ce: 0.133484
2021-11-30 12:36:04,883 iteration 348 : loss : 0.323638, loss_ce: 0.155641
2021-11-30 12:36:06,236 iteration 349 : loss : 0.322614, loss_ce: 0.153571
2021-11-30 12:36:07,599 iteration 350 : loss : 0.315283, loss_ce: 0.151865
2021-11-30 12:36:08,960 iteration 351 : loss : 0.313589, loss_ce: 0.138082
2021-11-30 12:36:10,322 iteration 352 : loss : 0.313153, loss_ce: 0.138043
2021-11-30 12:36:11,685 iteration 353 : loss : 0.296495, loss_ce: 0.142043
2021-11-30 12:36:13,041 iteration 354 : loss : 0.289326, loss_ce: 0.138171
2021-11-30 12:36:14,395 iteration 355 : loss : 0.307324, loss_ce: 0.112055
2021-11-30 12:36:15,755 iteration 356 : loss : 0.285383, loss_ce: 0.121952
2021-11-30 12:36:17,114 iteration 357 : loss : 0.303383, loss_ce: 0.146272
  5%|█▌                            | 21/400 [08:55<2:45:18, 26.17s/it]2021-11-30 12:36:18,542 iteration 358 : loss : 0.295193, loss_ce: 0.121139
2021-11-30 12:36:19,902 iteration 359 : loss : 0.293812, loss_ce: 0.132837
2021-11-30 12:36:21,261 iteration 360 : loss : 0.285031, loss_ce: 0.124665
2021-11-30 12:36:22,618 iteration 361 : loss : 0.299100, loss_ce: 0.136373
2021-11-30 12:36:23,984 iteration 362 : loss : 0.331492, loss_ce: 0.170718
2021-11-30 12:36:25,342 iteration 363 : loss : 0.285587, loss_ce: 0.124424
2021-11-30 12:36:26,701 iteration 364 : loss : 0.275807, loss_ce: 0.124414
2021-11-30 12:36:28,056 iteration 365 : loss : 0.315891, loss_ce: 0.133985
2021-11-30 12:36:29,409 iteration 366 : loss : 0.298674, loss_ce: 0.142270
2021-11-30 12:36:30,765 iteration 367 : loss : 0.317656, loss_ce: 0.147574
2021-11-30 12:36:32,125 iteration 368 : loss : 0.299901, loss_ce: 0.151446
2021-11-30 12:36:33,479 iteration 369 : loss : 0.314747, loss_ce: 0.137612
2021-11-30 12:36:34,836 iteration 370 : loss : 0.286764, loss_ce: 0.112693
2021-11-30 12:36:36,188 iteration 371 : loss : 0.306587, loss_ce: 0.151453
2021-11-30 12:36:37,546 iteration 372 : loss : 0.285608, loss_ce: 0.127417
2021-11-30 12:36:38,900 iteration 373 : loss : 0.292442, loss_ce: 0.125582
2021-11-30 12:36:40,251 iteration 374 : loss : 0.292472, loss_ce: 0.123849
  6%|█▋                            | 22/400 [09:18<2:39:08, 25.26s/it]2021-11-30 12:36:41,669 iteration 375 : loss : 0.308449, loss_ce: 0.136510
2021-11-30 12:36:43,027 iteration 376 : loss : 0.284686, loss_ce: 0.125980
2021-11-30 12:36:44,380 iteration 377 : loss : 0.302086, loss_ce: 0.128555
2021-11-30 12:36:45,737 iteration 378 : loss : 0.286750, loss_ce: 0.142519
2021-11-30 12:36:47,095 iteration 379 : loss : 0.298740, loss_ce: 0.133851
2021-11-30 12:36:48,452 iteration 380 : loss : 0.280356, loss_ce: 0.125456
2021-11-30 12:36:49,802 iteration 381 : loss : 0.300906, loss_ce: 0.141198
2021-11-30 12:36:51,161 iteration 382 : loss : 0.304110, loss_ce: 0.120840
2021-11-30 12:36:52,517 iteration 383 : loss : 0.294116, loss_ce: 0.126549
2021-11-30 12:36:53,868 iteration 384 : loss : 0.289025, loss_ce: 0.135971
2021-11-30 12:36:55,223 iteration 385 : loss : 0.281138, loss_ce: 0.126070
2021-11-30 12:36:56,573 iteration 386 : loss : 0.292507, loss_ce: 0.131462
2021-11-30 12:36:57,927 iteration 387 : loss : 0.285170, loss_ce: 0.122783
2021-11-30 12:36:59,278 iteration 388 : loss : 0.288696, loss_ce: 0.142945
2021-11-30 12:37:00,633 iteration 389 : loss : 0.276438, loss_ce: 0.101905
2021-11-30 12:37:01,988 iteration 390 : loss : 0.284770, loss_ce: 0.134952
2021-11-30 12:37:03,343 iteration 391 : loss : 0.297397, loss_ce: 0.156416
  6%|█▋                            | 23/400 [09:41<2:34:36, 24.61s/it]2021-11-30 12:37:04,755 iteration 392 : loss : 0.271851, loss_ce: 0.128976
2021-11-30 12:37:06,097 iteration 393 : loss : 0.284943, loss_ce: 0.127469
2021-11-30 12:37:07,438 iteration 394 : loss : 0.287051, loss_ce: 0.116221
2021-11-30 12:37:08,792 iteration 395 : loss : 0.285941, loss_ce: 0.134676
2021-11-30 12:37:10,142 iteration 396 : loss : 0.273737, loss_ce: 0.111809
2021-11-30 12:37:11,490 iteration 397 : loss : 0.294951, loss_ce: 0.142447
2021-11-30 12:37:12,847 iteration 398 : loss : 0.289949, loss_ce: 0.139225
2021-11-30 12:37:14,196 iteration 399 : loss : 0.283682, loss_ce: 0.134835
2021-11-30 12:37:15,545 iteration 400 : loss : 0.282698, loss_ce: 0.126165
2021-11-30 12:37:16,884 iteration 401 : loss : 0.281689, loss_ce: 0.130498
2021-11-30 12:37:18,233 iteration 402 : loss : 0.283832, loss_ce: 0.133796
2021-11-30 12:37:19,585 iteration 403 : loss : 0.274247, loss_ce: 0.127699
2021-11-30 12:37:20,936 iteration 404 : loss : 0.258647, loss_ce: 0.102550
2021-11-30 12:37:22,296 iteration 405 : loss : 0.283177, loss_ce: 0.134189
2021-11-30 12:37:23,638 iteration 406 : loss : 0.275931, loss_ce: 0.114606
2021-11-30 12:37:24,993 iteration 407 : loss : 0.274694, loss_ce: 0.123968
2021-11-30 12:37:26,354 iteration 408 : loss : 0.286664, loss_ce: 0.122066
  6%|█▊                            | 24/400 [10:04<2:31:12, 24.13s/it]2021-11-30 12:37:27,768 iteration 409 : loss : 0.263161, loss_ce: 0.129558
2021-11-30 12:37:29,112 iteration 410 : loss : 0.276882, loss_ce: 0.117193
2021-11-30 12:37:30,474 iteration 411 : loss : 0.268668, loss_ce: 0.120350
2021-11-30 12:37:31,828 iteration 412 : loss : 0.249828, loss_ce: 0.100686
2021-11-30 12:37:33,172 iteration 413 : loss : 0.281279, loss_ce: 0.122203
2021-11-30 12:37:34,528 iteration 414 : loss : 0.265510, loss_ce: 0.110310
2021-11-30 12:37:35,883 iteration 415 : loss : 0.290863, loss_ce: 0.142864
2021-11-30 12:37:37,241 iteration 416 : loss : 0.285643, loss_ce: 0.138910
2021-11-30 12:37:38,598 iteration 417 : loss : 0.267833, loss_ce: 0.116417
2021-11-30 12:37:39,954 iteration 418 : loss : 0.258315, loss_ce: 0.112697
2021-11-30 12:37:41,313 iteration 419 : loss : 0.263687, loss_ce: 0.121017
2021-11-30 12:37:42,669 iteration 420 : loss : 0.258267, loss_ce: 0.118731
2021-11-30 12:37:44,021 iteration 421 : loss : 0.260798, loss_ce: 0.115151
2021-11-30 12:37:45,369 iteration 422 : loss : 0.249878, loss_ce: 0.102870
2021-11-30 12:37:46,717 iteration 423 : loss : 0.270841, loss_ce: 0.124119
2021-11-30 12:37:48,076 iteration 424 : loss : 0.274762, loss_ce: 0.122017
2021-11-30 12:37:48,076 Training Data Eval:
2021-11-30 12:37:55,705   Average segmentation loss on training set: 0.2608
2021-11-30 12:37:55,705 Validation Data Eval:
2021-11-30 12:37:58,349   Average segmentation loss on validation set: 0.2676
2021-11-30 12:38:00,312 Found new lowest validation loss at iteration 424! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/UNET_RUNMC/best_val_loss_no_da.pth
2021-11-30 12:38:01,561 iteration 425 : loss : 0.260081, loss_ce: 0.119590
  6%|█▉                            | 25/400 [10:40<2:51:35, 27.45s/it]2021-11-30 12:38:02,853 iteration 426 : loss : 0.252640, loss_ce: 0.110578
2021-11-30 12:38:04,110 iteration 427 : loss : 0.248424, loss_ce: 0.115914
2021-11-30 12:38:05,427 iteration 428 : loss : 0.259156, loss_ce: 0.103694
2021-11-30 12:38:06,782 iteration 429 : loss : 0.269899, loss_ce: 0.115162
2021-11-30 12:38:08,137 iteration 430 : loss : 0.282726, loss_ce: 0.096431
2021-11-30 12:38:09,486 iteration 431 : loss : 0.261166, loss_ce: 0.115221
2021-11-30 12:38:10,827 iteration 432 : loss : 0.268028, loss_ce: 0.112833
2021-11-30 12:38:12,176 iteration 433 : loss : 0.264518, loss_ce: 0.117158
2021-11-30 12:38:13,524 iteration 434 : loss : 0.255037, loss_ce: 0.094986
2021-11-30 12:38:14,875 iteration 435 : loss : 0.241262, loss_ce: 0.101872
2021-11-30 12:38:16,221 iteration 436 : loss : 0.236561, loss_ce: 0.108908
2021-11-30 12:38:17,572 iteration 437 : loss : 0.252667, loss_ce: 0.108672
2021-11-30 12:38:18,919 iteration 438 : loss : 0.269782, loss_ce: 0.139895
2021-11-30 12:38:20,271 iteration 439 : loss : 0.254532, loss_ce: 0.110295
2021-11-30 12:38:21,613 iteration 440 : loss : 0.265681, loss_ce: 0.107975
2021-11-30 12:38:22,965 iteration 441 : loss : 0.250662, loss_ce: 0.124844
2021-11-30 12:38:24,318 iteration 442 : loss : 0.239411, loss_ce: 0.111429
  6%|█▉                            | 26/400 [11:02<2:42:20, 26.04s/it]2021-11-30 12:38:25,732 iteration 443 : loss : 0.244855, loss_ce: 0.109703
2021-11-30 12:38:27,085 iteration 444 : loss : 0.241292, loss_ce: 0.106286
2021-11-30 12:38:28,441 iteration 445 : loss : 0.264353, loss_ce: 0.104415
2021-11-30 12:38:29,785 iteration 446 : loss : 0.226971, loss_ce: 0.101829
2021-11-30 12:38:31,133 iteration 447 : loss : 0.235180, loss_ce: 0.103465
2021-11-30 12:38:32,475 iteration 448 : loss : 0.234237, loss_ce: 0.098499
2021-11-30 12:38:33,820 iteration 449 : loss : 0.236821, loss_ce: 0.108260
2021-11-30 12:38:35,170 iteration 450 : loss : 0.270393, loss_ce: 0.108349
2021-11-30 12:38:36,519 iteration 451 : loss : 0.255227, loss_ce: 0.121071
2021-11-30 12:38:37,881 iteration 452 : loss : 0.267224, loss_ce: 0.118948
2021-11-30 12:38:39,214 iteration 453 : loss : 0.272090, loss_ce: 0.102141
2021-11-30 12:38:40,552 iteration 454 : loss : 0.231124, loss_ce: 0.098149
2021-11-30 12:38:41,911 iteration 455 : loss : 0.237145, loss_ce: 0.094906
2021-11-30 12:38:43,262 iteration 456 : loss : 0.263863, loss_ce: 0.106844
2021-11-30 12:38:44,627 iteration 457 : loss : 0.229339, loss_ce: 0.097732
2021-11-30 12:38:45,978 iteration 458 : loss : 0.245661, loss_ce: 0.106114
2021-11-30 12:38:47,330 iteration 459 : loss : 0.241321, loss_ce: 0.104552
  7%|██                            | 27/400 [11:25<2:36:14, 25.13s/it]2021-11-30 12:38:48,735 iteration 460 : loss : 0.235659, loss_ce: 0.100152
2021-11-30 12:38:50,080 iteration 461 : loss : 0.245544, loss_ce: 0.103045
2021-11-30 12:38:51,435 iteration 462 : loss : 0.235751, loss_ce: 0.094944
2021-11-30 12:38:52,802 iteration 463 : loss : 0.252294, loss_ce: 0.103068
2021-11-30 12:38:54,154 iteration 464 : loss : 0.228099, loss_ce: 0.090419
2021-11-30 12:38:55,509 iteration 465 : loss : 0.230622, loss_ce: 0.099979
2021-11-30 12:38:56,856 iteration 466 : loss : 0.237125, loss_ce: 0.100828
2021-11-30 12:38:58,214 iteration 467 : loss : 0.237021, loss_ce: 0.099739
2021-11-30 12:38:59,569 iteration 468 : loss : 0.228747, loss_ce: 0.095728
2021-11-30 12:39:00,917 iteration 469 : loss : 0.248925, loss_ce: 0.126168
2021-11-30 12:39:02,259 iteration 470 : loss : 0.228200, loss_ce: 0.096870
2021-11-30 12:39:03,609 iteration 471 : loss : 0.225062, loss_ce: 0.103662
2021-11-30 12:39:04,962 iteration 472 : loss : 0.229612, loss_ce: 0.095746
2021-11-30 12:39:06,320 iteration 473 : loss : 0.248892, loss_ce: 0.113573
2021-11-30 12:39:07,674 iteration 474 : loss : 0.224466, loss_ce: 0.090579
2021-11-30 12:39:09,027 iteration 475 : loss : 0.218281, loss_ce: 0.081529
2021-11-30 12:39:10,374 iteration 476 : loss : 0.256956, loss_ce: 0.113812
  7%|██                            | 28/400 [11:48<2:31:56, 24.51s/it]2021-11-30 12:39:11,788 iteration 477 : loss : 0.250114, loss_ce: 0.114443
2021-11-30 12:39:13,144 iteration 478 : loss : 0.230745, loss_ce: 0.097924
2021-11-30 12:39:14,500 iteration 479 : loss : 0.224646, loss_ce: 0.093676
2021-11-30 12:39:15,851 iteration 480 : loss : 0.230174, loss_ce: 0.083647
2021-11-30 12:39:17,213 iteration 481 : loss : 0.211875, loss_ce: 0.085635
2021-11-30 12:39:18,563 iteration 482 : loss : 0.227155, loss_ce: 0.089409
2021-11-30 12:39:19,911 iteration 483 : loss : 0.234536, loss_ce: 0.079492
2021-11-30 12:39:21,275 iteration 484 : loss : 0.253181, loss_ce: 0.126501
2021-11-30 12:39:22,630 iteration 485 : loss : 0.244599, loss_ce: 0.100578
2021-11-30 12:39:23,984 iteration 486 : loss : 0.217540, loss_ce: 0.087697
2021-11-30 12:39:25,328 iteration 487 : loss : 0.231958, loss_ce: 0.093010
2021-11-30 12:39:26,677 iteration 488 : loss : 0.211734, loss_ce: 0.094487
2021-11-30 12:39:28,038 iteration 489 : loss : 0.229735, loss_ce: 0.102823
2021-11-30 12:39:29,393 iteration 490 : loss : 0.219125, loss_ce: 0.095019
2021-11-30 12:39:30,742 iteration 491 : loss : 0.220207, loss_ce: 0.099559
2021-11-30 12:39:32,097 iteration 492 : loss : 0.218892, loss_ce: 0.100947
2021-11-30 12:39:33,453 iteration 493 : loss : 0.231750, loss_ce: 0.102044
  7%|██▏                           | 29/400 [12:12<2:28:53, 24.08s/it]2021-11-30 12:39:34,878 iteration 494 : loss : 0.234832, loss_ce: 0.094935
2021-11-30 12:39:36,237 iteration 495 : loss : 0.223945, loss_ce: 0.094442
2021-11-30 12:39:37,598 iteration 496 : loss : 0.214865, loss_ce: 0.090878
2021-11-30 12:39:38,960 iteration 497 : loss : 0.240045, loss_ce: 0.110499
2021-11-30 12:39:40,315 iteration 498 : loss : 0.238066, loss_ce: 0.105408
2021-11-30 12:39:41,679 iteration 499 : loss : 0.204450, loss_ce: 0.087447
2021-11-30 12:39:43,036 iteration 500 : loss : 0.206208, loss_ce: 0.087085
2021-11-30 12:39:44,399 iteration 501 : loss : 0.216823, loss_ce: 0.096004
2021-11-30 12:39:45,753 iteration 502 : loss : 0.230220, loss_ce: 0.110991
2021-11-30 12:39:47,111 iteration 503 : loss : 0.212967, loss_ce: 0.098714
2021-11-30 12:39:48,467 iteration 504 : loss : 0.225223, loss_ce: 0.100375
2021-11-30 12:39:49,833 iteration 505 : loss : 0.240288, loss_ce: 0.113607
2021-11-30 12:39:51,192 iteration 506 : loss : 0.207208, loss_ce: 0.087685
2021-11-30 12:39:52,551 iteration 507 : loss : 0.208480, loss_ce: 0.084973
2021-11-30 12:39:53,907 iteration 508 : loss : 0.196234, loss_ce: 0.083563
2021-11-30 12:39:55,268 iteration 509 : loss : 0.199026, loss_ce: 0.086856
2021-11-30 12:39:55,268 Training Data Eval:
2021-11-30 12:40:02,946   Average segmentation loss on training set: 0.2127
2021-11-30 12:40:02,946 Validation Data Eval:
2021-11-30 12:40:05,585   Average segmentation loss on validation set: 0.2115
2021-11-30 12:40:07,519 Found new lowest validation loss at iteration 509! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/UNET_RUNMC/best_val_loss_no_da.pth
2021-11-30 12:40:08,762 iteration 510 : loss : 0.213610, loss_ce: 0.079616
  8%|██▎                           | 30/400 [12:47<2:49:15, 27.45s/it]2021-11-30 12:40:10,059 iteration 511 : loss : 0.224955, loss_ce: 0.098102
2021-11-30 12:40:11,350 iteration 512 : loss : 0.220551, loss_ce: 0.106651
2021-11-30 12:40:12,694 iteration 513 : loss : 0.221792, loss_ce: 0.091966
2021-11-30 12:40:14,046 iteration 514 : loss : 0.194253, loss_ce: 0.081166
2021-11-30 12:40:15,391 iteration 515 : loss : 0.239041, loss_ce: 0.083378
2021-11-30 12:40:16,736 iteration 516 : loss : 0.220121, loss_ce: 0.097845
2021-11-30 12:40:18,076 iteration 517 : loss : 0.221857, loss_ce: 0.096894
2021-11-30 12:40:19,417 iteration 518 : loss : 0.219751, loss_ce: 0.098703
2021-11-30 12:40:20,766 iteration 519 : loss : 0.206649, loss_ce: 0.090290
2021-11-30 12:40:22,123 iteration 520 : loss : 0.199836, loss_ce: 0.086900
2021-11-30 12:40:23,462 iteration 521 : loss : 0.222204, loss_ce: 0.089042
2021-11-30 12:40:24,799 iteration 522 : loss : 0.224171, loss_ce: 0.102296
2021-11-30 12:40:26,140 iteration 523 : loss : 0.198991, loss_ce: 0.088291
2021-11-30 12:40:27,485 iteration 524 : loss : 0.233831, loss_ce: 0.099178
2021-11-30 12:40:28,839 iteration 525 : loss : 0.195447, loss_ce: 0.080090
2021-11-30 12:40:30,190 iteration 526 : loss : 0.228496, loss_ce: 0.103609
2021-11-30 12:40:31,551 iteration 527 : loss : 0.208910, loss_ce: 0.076938
  8%|██▎                           | 31/400 [13:10<2:40:12, 26.05s/it]2021-11-30 12:40:32,953 iteration 528 : loss : 0.191007, loss_ce: 0.079330
2021-11-30 12:40:34,296 iteration 529 : loss : 0.215186, loss_ce: 0.087579
2021-11-30 12:40:35,646 iteration 530 : loss : 0.194497, loss_ce: 0.068964
2021-11-30 12:40:37,006 iteration 531 : loss : 0.210670, loss_ce: 0.096503
2021-11-30 12:40:38,366 iteration 532 : loss : 0.195898, loss_ce: 0.094570
2021-11-30 12:40:39,732 iteration 533 : loss : 0.189074, loss_ce: 0.082296
2021-11-30 12:40:41,091 iteration 534 : loss : 0.217445, loss_ce: 0.084660
2021-11-30 12:40:42,448 iteration 535 : loss : 0.200028, loss_ce: 0.082890
2021-11-30 12:40:43,806 iteration 536 : loss : 0.189512, loss_ce: 0.080297
2021-11-30 12:40:45,163 iteration 537 : loss : 0.209271, loss_ce: 0.100171
2021-11-30 12:40:46,522 iteration 538 : loss : 0.217700, loss_ce: 0.093991
2021-11-30 12:40:47,870 iteration 539 : loss : 0.186276, loss_ce: 0.078197
2021-11-30 12:40:49,226 iteration 540 : loss : 0.216598, loss_ce: 0.103271
2021-11-30 12:40:50,589 iteration 541 : loss : 0.182801, loss_ce: 0.086848
2021-11-30 12:40:51,944 iteration 542 : loss : 0.204540, loss_ce: 0.079680
2021-11-30 12:40:53,293 iteration 543 : loss : 0.238651, loss_ce: 0.083187
2021-11-30 12:40:54,652 iteration 544 : loss : 0.194264, loss_ce: 0.077407
  8%|██▍                           | 32/400 [13:33<2:34:21, 25.17s/it]2021-11-30 12:40:56,075 iteration 545 : loss : 0.209609, loss_ce: 0.081474
2021-11-30 12:40:57,421 iteration 546 : loss : 0.226123, loss_ce: 0.079338
2021-11-30 12:40:58,780 iteration 547 : loss : 0.221221, loss_ce: 0.089622
2021-11-30 12:41:00,134 iteration 548 : loss : 0.174871, loss_ce: 0.076304
2021-11-30 12:41:01,484 iteration 549 : loss : 0.193000, loss_ce: 0.070437
2021-11-30 12:41:02,843 iteration 550 : loss : 0.188963, loss_ce: 0.075064
2021-11-30 12:41:04,198 iteration 551 : loss : 0.211438, loss_ce: 0.084067
2021-11-30 12:41:05,558 iteration 552 : loss : 0.200528, loss_ce: 0.088519
2021-11-30 12:41:06,910 iteration 553 : loss : 0.175876, loss_ce: 0.072599
2021-11-30 12:41:08,267 iteration 554 : loss : 0.234379, loss_ce: 0.110274
2021-11-30 12:41:09,625 iteration 555 : loss : 0.178442, loss_ce: 0.075122
2021-11-30 12:41:10,988 iteration 556 : loss : 0.196085, loss_ce: 0.081563
2021-11-30 12:41:12,353 iteration 557 : loss : 0.226434, loss_ce: 0.096046
2021-11-30 12:41:13,717 iteration 558 : loss : 0.179471, loss_ce: 0.077283
2021-11-30 12:41:15,074 iteration 559 : loss : 0.193074, loss_ce: 0.081199
2021-11-30 12:41:16,436 iteration 560 : loss : 0.195313, loss_ce: 0.086588
2021-11-30 12:41:17,797 iteration 561 : loss : 0.196491, loss_ce: 0.091385
  8%|██▍                           | 33/400 [13:56<2:30:12, 24.56s/it]2021-11-30 12:41:19,212 iteration 562 : loss : 0.180824, loss_ce: 0.084144
2021-11-30 12:41:20,574 iteration 563 : loss : 0.213795, loss_ce: 0.081363
2021-11-30 12:41:21,937 iteration 564 : loss : 0.185243, loss_ce: 0.073775
2021-11-30 12:41:23,300 iteration 565 : loss : 0.185032, loss_ce: 0.090359
2021-11-30 12:41:24,662 iteration 566 : loss : 0.207561, loss_ce: 0.089361
2021-11-30 12:41:26,023 iteration 567 : loss : 0.172655, loss_ce: 0.080580
2021-11-30 12:41:27,380 iteration 568 : loss : 0.188197, loss_ce: 0.077464
2021-11-30 12:41:28,737 iteration 569 : loss : 0.198530, loss_ce: 0.081010
2021-11-30 12:41:30,097 iteration 570 : loss : 0.182633, loss_ce: 0.077019
2021-11-30 12:41:31,455 iteration 571 : loss : 0.182185, loss_ce: 0.073461
2021-11-30 12:41:32,819 iteration 572 : loss : 0.184957, loss_ce: 0.075566
2021-11-30 12:41:34,175 iteration 573 : loss : 0.173309, loss_ce: 0.072560
2021-11-30 12:41:35,527 iteration 574 : loss : 0.180845, loss_ce: 0.069878
2021-11-30 12:41:36,887 iteration 575 : loss : 0.193267, loss_ce: 0.075753
2021-11-30 12:41:38,239 iteration 576 : loss : 0.204345, loss_ce: 0.087647
2021-11-30 12:41:39,596 iteration 577 : loss : 0.182785, loss_ce: 0.076539
2021-11-30 12:41:40,955 iteration 578 : loss : 0.202642, loss_ce: 0.081027
  8%|██▌                           | 34/400 [14:19<2:27:14, 24.14s/it]2021-11-30 12:41:42,373 iteration 579 : loss : 0.195046, loss_ce: 0.079057
2021-11-30 12:41:43,728 iteration 580 : loss : 0.175509, loss_ce: 0.069523
2021-11-30 12:41:45,085 iteration 581 : loss : 0.185039, loss_ce: 0.080287
2021-11-30 12:41:46,443 iteration 582 : loss : 0.179792, loss_ce: 0.072967
2021-11-30 12:41:47,805 iteration 583 : loss : 0.187952, loss_ce: 0.073942
2021-11-30 12:41:49,167 iteration 584 : loss : 0.182644, loss_ce: 0.069427
2021-11-30 12:41:50,523 iteration 585 : loss : 0.179008, loss_ce: 0.079409
2021-11-30 12:41:51,883 iteration 586 : loss : 0.166660, loss_ce: 0.063453
2021-11-30 12:41:53,242 iteration 587 : loss : 0.174582, loss_ce: 0.072790
2021-11-30 12:41:54,601 iteration 588 : loss : 0.181509, loss_ce: 0.078823
2021-11-30 12:41:55,958 iteration 589 : loss : 0.211243, loss_ce: 0.084067
2021-11-30 12:41:57,318 iteration 590 : loss : 0.183313, loss_ce: 0.066549
2021-11-30 12:41:58,676 iteration 591 : loss : 0.194103, loss_ce: 0.084530
2021-11-30 12:42:00,033 iteration 592 : loss : 0.182547, loss_ce: 0.077011
2021-11-30 12:42:01,389 iteration 593 : loss : 0.186852, loss_ce: 0.087851
2021-11-30 12:42:02,750 iteration 594 : loss : 0.171924, loss_ce: 0.073013
2021-11-30 12:42:02,750 Training Data Eval:
2021-11-30 12:42:10,390   Average segmentation loss on training set: 0.1750
2021-11-30 12:42:10,391 Validation Data Eval:
2021-11-30 12:42:13,031   Average segmentation loss on validation set: 0.2092
2021-11-30 12:42:14,981 Found new lowest validation loss at iteration 594! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/UNET_RUNMC/best_val_loss_no_da.pth
2021-11-30 12:42:16,223 iteration 595 : loss : 0.183497, loss_ce: 0.073370
  9%|██▋                           | 35/400 [14:54<2:47:09, 27.48s/it]2021-11-30 12:42:17,510 iteration 596 : loss : 0.171769, loss_ce: 0.067809
2021-11-30 12:42:18,775 iteration 597 : loss : 0.177944, loss_ce: 0.081450
2021-11-30 12:42:20,118 iteration 598 : loss : 0.175912, loss_ce: 0.066893
2021-11-30 12:42:21,475 iteration 599 : loss : 0.160511, loss_ce: 0.063339
2021-11-30 12:42:22,821 iteration 600 : loss : 0.167929, loss_ce: 0.072923
2021-11-30 12:42:24,174 iteration 601 : loss : 0.205352, loss_ce: 0.086269
2021-11-30 12:42:25,518 iteration 602 : loss : 0.161147, loss_ce: 0.073794
2021-11-30 12:42:26,883 iteration 603 : loss : 0.165711, loss_ce: 0.077200
2021-11-30 12:42:28,246 iteration 604 : loss : 0.162829, loss_ce: 0.070259
2021-11-30 12:42:29,601 iteration 605 : loss : 0.178436, loss_ce: 0.076692
2021-11-30 12:42:30,964 iteration 606 : loss : 0.183977, loss_ce: 0.073366
2021-11-30 12:42:32,324 iteration 607 : loss : 0.176948, loss_ce: 0.068509
2021-11-30 12:42:33,684 iteration 608 : loss : 0.163513, loss_ce: 0.064288
2021-11-30 12:42:35,039 iteration 609 : loss : 0.195812, loss_ce: 0.074930
2021-11-30 12:42:36,399 iteration 610 : loss : 0.182769, loss_ce: 0.069016
2021-11-30 12:42:37,759 iteration 611 : loss : 0.170474, loss_ce: 0.071543
2021-11-30 12:42:39,113 iteration 612 : loss : 0.152145, loss_ce: 0.053643
  9%|██▋                           | 36/400 [15:17<2:38:20, 26.10s/it]2021-11-30 12:42:40,528 iteration 613 : loss : 0.179233, loss_ce: 0.079094
2021-11-30 12:42:41,882 iteration 614 : loss : 0.165848, loss_ce: 0.059177
2021-11-30 12:42:43,244 iteration 615 : loss : 0.161735, loss_ce: 0.073043
2021-11-30 12:42:44,591 iteration 616 : loss : 0.142743, loss_ce: 0.057735
2021-11-30 12:42:45,938 iteration 617 : loss : 0.170939, loss_ce: 0.068657
2021-11-30 12:42:47,293 iteration 618 : loss : 0.151540, loss_ce: 0.060028
2021-11-30 12:42:48,644 iteration 619 : loss : 0.162716, loss_ce: 0.070052
2021-11-30 12:42:49,997 iteration 620 : loss : 0.150862, loss_ce: 0.066989
2021-11-30 12:42:51,350 iteration 621 : loss : 0.150516, loss_ce: 0.064471
2021-11-30 12:42:52,695 iteration 622 : loss : 0.182628, loss_ce: 0.067144
2021-11-30 12:42:54,044 iteration 623 : loss : 0.179451, loss_ce: 0.070500
2021-11-30 12:42:55,396 iteration 624 : loss : 0.192421, loss_ce: 0.081474
2021-11-30 12:42:56,747 iteration 625 : loss : 0.171083, loss_ce: 0.066781
2021-11-30 12:42:58,093 iteration 626 : loss : 0.186537, loss_ce: 0.086234
2021-11-30 12:42:59,447 iteration 627 : loss : 0.154549, loss_ce: 0.062854
2021-11-30 12:43:00,805 iteration 628 : loss : 0.152623, loss_ce: 0.057596
2021-11-30 12:43:02,140 iteration 629 : loss : 0.181963, loss_ce: 0.065752
  9%|██▊                           | 37/400 [15:40<2:32:20, 25.18s/it]2021-11-30 12:43:03,557 iteration 630 : loss : 0.161268, loss_ce: 0.067626
2021-11-30 12:43:04,917 iteration 631 : loss : 0.227825, loss_ce: 0.071108
2021-11-30 12:43:06,267 iteration 632 : loss : 0.152846, loss_ce: 0.060015
2021-11-30 12:43:07,611 iteration 633 : loss : 0.150104, loss_ce: 0.065519
2021-11-30 12:43:08,965 iteration 634 : loss : 0.164518, loss_ce: 0.061452
2021-11-30 12:43:10,317 iteration 635 : loss : 0.175079, loss_ce: 0.068379
2021-11-30 12:43:11,677 iteration 636 : loss : 0.149461, loss_ce: 0.065814
2021-11-30 12:43:13,029 iteration 637 : loss : 0.141854, loss_ce: 0.067001
2021-11-30 12:43:14,387 iteration 638 : loss : 0.166318, loss_ce: 0.065303
2021-11-30 12:43:15,751 iteration 639 : loss : 0.155985, loss_ce: 0.059182
2021-11-30 12:43:17,104 iteration 640 : loss : 0.176438, loss_ce: 0.083773
2021-11-30 12:43:18,470 iteration 641 : loss : 0.162465, loss_ce: 0.069649
2021-11-30 12:43:19,823 iteration 642 : loss : 0.145933, loss_ce: 0.062699
2021-11-30 12:43:21,171 iteration 643 : loss : 0.150427, loss_ce: 0.062445
2021-11-30 12:43:22,531 iteration 644 : loss : 0.166569, loss_ce: 0.068496
2021-11-30 12:43:23,889 iteration 645 : loss : 0.151801, loss_ce: 0.058441
2021-11-30 12:43:25,242 iteration 646 : loss : 0.189311, loss_ce: 0.066896
 10%|██▊                           | 38/400 [16:03<2:28:08, 24.56s/it]2021-11-30 12:43:26,656 iteration 647 : loss : 0.181504, loss_ce: 0.062823
2021-11-30 12:43:28,007 iteration 648 : loss : 0.169114, loss_ce: 0.065912
2021-11-30 12:43:29,350 iteration 649 : loss : 0.137633, loss_ce: 0.058578
2021-11-30 12:43:30,710 iteration 650 : loss : 0.188887, loss_ce: 0.082062
2021-11-30 12:43:32,072 iteration 651 : loss : 0.155397, loss_ce: 0.055316
2021-11-30 12:43:33,424 iteration 652 : loss : 0.145788, loss_ce: 0.061048
2021-11-30 12:43:34,777 iteration 653 : loss : 0.136559, loss_ce: 0.056067
2021-11-30 12:43:36,139 iteration 654 : loss : 0.149858, loss_ce: 0.068725
2021-11-30 12:43:37,492 iteration 655 : loss : 0.157573, loss_ce: 0.064725
2021-11-30 12:43:38,840 iteration 656 : loss : 0.150494, loss_ce: 0.068347
2021-11-30 12:43:40,190 iteration 657 : loss : 0.162734, loss_ce: 0.066403
2021-11-30 12:43:41,538 iteration 658 : loss : 0.160429, loss_ce: 0.070322
2021-11-30 12:43:42,884 iteration 659 : loss : 0.140234, loss_ce: 0.065127
2021-11-30 12:43:44,235 iteration 660 : loss : 0.178698, loss_ce: 0.069497
2021-11-30 12:43:45,584 iteration 661 : loss : 0.138778, loss_ce: 0.057043
2021-11-30 12:43:46,942 iteration 662 : loss : 0.134559, loss_ce: 0.057932
2021-11-30 12:43:48,293 iteration 663 : loss : 0.197139, loss_ce: 0.077316
 10%|██▉                           | 39/400 [16:26<2:25:02, 24.11s/it]2021-11-30 12:43:49,704 iteration 664 : loss : 0.158956, loss_ce: 0.063004
2021-11-30 12:43:51,056 iteration 665 : loss : 0.150346, loss_ce: 0.069664
2021-11-30 12:43:52,400 iteration 666 : loss : 0.154643, loss_ce: 0.056643
2021-11-30 12:43:53,759 iteration 667 : loss : 0.139673, loss_ce: 0.060368
2021-11-30 12:43:55,122 iteration 668 : loss : 0.134764, loss_ce: 0.048732
2021-11-30 12:43:56,471 iteration 669 : loss : 0.134034, loss_ce: 0.055134
2021-11-30 12:43:57,816 iteration 670 : loss : 0.151036, loss_ce: 0.055992
2021-11-30 12:43:59,175 iteration 671 : loss : 0.117353, loss_ce: 0.054605
2021-11-30 12:44:00,526 iteration 672 : loss : 0.146598, loss_ce: 0.063543
2021-11-30 12:44:01,876 iteration 673 : loss : 0.139167, loss_ce: 0.053540
2021-11-30 12:44:03,226 iteration 674 : loss : 0.139966, loss_ce: 0.058366
2021-11-30 12:44:04,575 iteration 675 : loss : 0.138579, loss_ce: 0.054295
2021-11-30 12:44:05,939 iteration 676 : loss : 0.126743, loss_ce: 0.052485
2021-11-30 12:44:07,286 iteration 677 : loss : 0.172192, loss_ce: 0.068176
2021-11-30 12:44:08,641 iteration 678 : loss : 0.144038, loss_ce: 0.056790
2021-11-30 12:44:09,994 iteration 679 : loss : 0.140617, loss_ce: 0.057665
2021-11-30 12:44:09,994 Training Data Eval:
2021-11-30 12:44:17,655   Average segmentation loss on training set: 0.1456
2021-11-30 12:44:17,656 Validation Data Eval:
2021-11-30 12:44:20,312   Average segmentation loss on validation set: 0.1670
2021-11-30 12:44:22,256 Found new lowest validation loss at iteration 679! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/UNET_RUNMC/best_val_loss_no_da.pth
2021-11-30 12:44:23,509 iteration 680 : loss : 0.130294, loss_ce: 0.054085
 10%|███                           | 40/400 [17:02<2:44:38, 27.44s/it]2021-11-30 12:44:24,808 iteration 681 : loss : 0.126437, loss_ce: 0.051131
2021-11-30 12:44:26,114 iteration 682 : loss : 0.125372, loss_ce: 0.056574
2021-11-30 12:44:27,471 iteration 683 : loss : 0.140844, loss_ce: 0.056693
2021-11-30 12:44:28,823 iteration 684 : loss : 0.112411, loss_ce: 0.053635
2021-11-30 12:44:30,166 iteration 685 : loss : 0.131044, loss_ce: 0.050296
2021-11-30 12:44:31,522 iteration 686 : loss : 0.093404, loss_ce: 0.044356
2021-11-30 12:44:32,871 iteration 687 : loss : 0.129703, loss_ce: 0.052958
2021-11-30 12:44:34,225 iteration 688 : loss : 0.147084, loss_ce: 0.058725
2021-11-30 12:44:35,576 iteration 689 : loss : 0.131859, loss_ce: 0.053216
2021-11-30 12:44:36,918 iteration 690 : loss : 0.151065, loss_ce: 0.067128
2021-11-30 12:44:38,276 iteration 691 : loss : 0.160207, loss_ce: 0.064974
2021-11-30 12:44:39,634 iteration 692 : loss : 0.113656, loss_ce: 0.048946
2021-11-30 12:44:40,988 iteration 693 : loss : 0.148461, loss_ce: 0.061593
2021-11-30 12:44:42,344 iteration 694 : loss : 0.143973, loss_ce: 0.064051
2021-11-30 12:44:43,706 iteration 695 : loss : 0.144400, loss_ce: 0.055017
2021-11-30 12:44:45,057 iteration 696 : loss : 0.148451, loss_ce: 0.054622
2021-11-30 12:44:46,411 iteration 697 : loss : 0.142375, loss_ce: 0.057547
 10%|███                           | 41/400 [17:25<2:36:01, 26.08s/it]2021-11-30 12:44:47,823 iteration 698 : loss : 0.176134, loss_ce: 0.072506
2021-11-30 12:44:49,181 iteration 699 : loss : 0.147444, loss_ce: 0.054805
2021-11-30 12:44:50,525 iteration 700 : loss : 0.150938, loss_ce: 0.056614
2021-11-30 12:44:51,877 iteration 701 : loss : 0.119354, loss_ce: 0.056643
2021-11-30 12:44:53,227 iteration 702 : loss : 0.127216, loss_ce: 0.052487
2021-11-30 12:44:54,580 iteration 703 : loss : 0.145337, loss_ce: 0.062178
2021-11-30 12:44:55,934 iteration 704 : loss : 0.143168, loss_ce: 0.058153
2021-11-30 12:44:57,290 iteration 705 : loss : 0.132301, loss_ce: 0.050064
2021-11-30 12:44:58,642 iteration 706 : loss : 0.138407, loss_ce: 0.050929
2021-11-30 12:44:59,995 iteration 707 : loss : 0.116585, loss_ce: 0.046605
2021-11-30 12:45:01,348 iteration 708 : loss : 0.135360, loss_ce: 0.055402
2021-11-30 12:45:02,704 iteration 709 : loss : 0.161410, loss_ce: 0.076521
2021-11-30 12:45:04,055 iteration 710 : loss : 0.135090, loss_ce: 0.051375
2021-11-30 12:45:05,403 iteration 711 : loss : 0.118413, loss_ce: 0.057435
2021-11-30 12:45:06,758 iteration 712 : loss : 0.140413, loss_ce: 0.061359
2021-11-30 12:45:08,109 iteration 713 : loss : 0.152019, loss_ce: 0.055098
2021-11-30 12:45:09,457 iteration 714 : loss : 0.148026, loss_ce: 0.056592
 10%|███▏                          | 42/400 [17:48<2:30:10, 25.17s/it]2021-11-30 12:45:10,870 iteration 715 : loss : 0.144408, loss_ce: 0.061052
2021-11-30 12:45:12,218 iteration 716 : loss : 0.130941, loss_ce: 0.048512
2021-11-30 12:45:13,573 iteration 717 : loss : 0.132891, loss_ce: 0.053945
2021-11-30 12:45:14,925 iteration 718 : loss : 0.126212, loss_ce: 0.055927
2021-11-30 12:45:16,286 iteration 719 : loss : 0.113461, loss_ce: 0.049995
2021-11-30 12:45:17,642 iteration 720 : loss : 0.117090, loss_ce: 0.053546
2021-11-30 12:45:18,992 iteration 721 : loss : 0.125015, loss_ce: 0.046920
2021-11-30 12:45:20,342 iteration 722 : loss : 0.118344, loss_ce: 0.043456
2021-11-30 12:45:21,693 iteration 723 : loss : 0.115439, loss_ce: 0.049804
2021-11-30 12:45:23,039 iteration 724 : loss : 0.141435, loss_ce: 0.062405
2021-11-30 12:45:24,393 iteration 725 : loss : 0.121239, loss_ce: 0.053622
2021-11-30 12:45:25,746 iteration 726 : loss : 0.125070, loss_ce: 0.047685
2021-11-30 12:45:27,098 iteration 727 : loss : 0.109024, loss_ce: 0.050261
2021-11-30 12:45:28,440 iteration 728 : loss : 0.134531, loss_ce: 0.066688
2021-11-30 12:45:29,788 iteration 729 : loss : 0.182622, loss_ce: 0.064016
2021-11-30 12:45:31,141 iteration 730 : loss : 0.146776, loss_ce: 0.054686
2021-11-30 12:45:32,487 iteration 731 : loss : 0.119807, loss_ce: 0.050915
 11%|███▏                          | 43/400 [18:11<2:25:55, 24.53s/it]2021-11-30 12:45:33,902 iteration 732 : loss : 0.124546, loss_ce: 0.049795
2021-11-30 12:45:35,252 iteration 733 : loss : 0.103611, loss_ce: 0.045341
2021-11-30 12:45:36,594 iteration 734 : loss : 0.095321, loss_ce: 0.046957
2021-11-30 12:45:37,946 iteration 735 : loss : 0.139603, loss_ce: 0.059110
2021-11-30 12:45:39,302 iteration 736 : loss : 0.107338, loss_ce: 0.044495
2021-11-30 12:45:40,643 iteration 737 : loss : 0.111935, loss_ce: 0.049643
2021-11-30 12:45:42,001 iteration 738 : loss : 0.093919, loss_ce: 0.043280
2021-11-30 12:45:43,356 iteration 739 : loss : 0.143132, loss_ce: 0.052941
2021-11-30 12:45:44,709 iteration 740 : loss : 0.136888, loss_ce: 0.043980
2021-11-30 12:45:46,063 iteration 741 : loss : 0.087786, loss_ce: 0.039124
2021-11-30 12:45:47,418 iteration 742 : loss : 0.156769, loss_ce: 0.052414
2021-11-30 12:45:48,772 iteration 743 : loss : 0.112682, loss_ce: 0.049995
2021-11-30 12:45:50,121 iteration 744 : loss : 0.150519, loss_ce: 0.060854
2021-11-30 12:45:51,471 iteration 745 : loss : 0.117409, loss_ce: 0.052246
2021-11-30 12:45:52,832 iteration 746 : loss : 0.115373, loss_ce: 0.047402
2021-11-30 12:45:54,186 iteration 747 : loss : 0.105686, loss_ce: 0.046374
2021-11-30 12:45:55,535 iteration 748 : loss : 0.165302, loss_ce: 0.066162
 11%|███▎                          | 44/400 [18:34<2:22:53, 24.08s/it]2021-11-30 12:45:56,954 iteration 749 : loss : 0.116982, loss_ce: 0.047222
2021-11-30 12:45:58,305 iteration 750 : loss : 0.137220, loss_ce: 0.044935
2021-11-30 12:45:59,658 iteration 751 : loss : 0.116777, loss_ce: 0.043294
2021-11-30 12:46:01,012 iteration 752 : loss : 0.089895, loss_ce: 0.043986
2021-11-30 12:46:02,366 iteration 753 : loss : 0.118937, loss_ce: 0.050414
2021-11-30 12:46:03,725 iteration 754 : loss : 0.091950, loss_ce: 0.040371
2021-11-30 12:46:05,078 iteration 755 : loss : 0.091966, loss_ce: 0.045353
2021-11-30 12:46:06,444 iteration 756 : loss : 0.127012, loss_ce: 0.045865
2021-11-30 12:46:07,808 iteration 757 : loss : 0.128209, loss_ce: 0.055313
2021-11-30 12:46:09,157 iteration 758 : loss : 0.108331, loss_ce: 0.039577
2021-11-30 12:46:10,513 iteration 759 : loss : 0.148818, loss_ce: 0.058632
2021-11-30 12:46:11,867 iteration 760 : loss : 0.119139, loss_ce: 0.055155
2021-11-30 12:46:13,220 iteration 761 : loss : 0.094942, loss_ce: 0.040685
2021-11-30 12:46:14,578 iteration 762 : loss : 0.114346, loss_ce: 0.047409
2021-11-30 12:46:15,923 iteration 763 : loss : 0.123243, loss_ce: 0.050603
2021-11-30 12:46:17,278 iteration 764 : loss : 0.106633, loss_ce: 0.045650
2021-11-30 12:46:17,278 Training Data Eval:
2021-11-30 12:46:24,910   Average segmentation loss on training set: 0.1145
2021-11-30 12:46:24,911 Validation Data Eval:
2021-11-30 12:46:27,557   Average segmentation loss on validation set: 0.1524
2021-11-30 12:46:29,500 Found new lowest validation loss at iteration 764! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/UNET_RUNMC/best_val_loss_no_da.pth
2021-11-30 12:46:30,741 iteration 765 : loss : 0.109144, loss_ce: 0.051073
 11%|███▍                          | 45/400 [19:09<2:42:14, 27.42s/it]2021-11-30 12:46:32,031 iteration 766 : loss : 0.139087, loss_ce: 0.055747
2021-11-30 12:46:33,310 iteration 767 : loss : 0.099622, loss_ce: 0.038151
2021-11-30 12:46:34,652 iteration 768 : loss : 0.104953, loss_ce: 0.045057
2021-11-30 12:46:36,004 iteration 769 : loss : 0.093863, loss_ce: 0.041622
2021-11-30 12:46:37,352 iteration 770 : loss : 0.107540, loss_ce: 0.044026
2021-11-30 12:46:38,692 iteration 771 : loss : 0.117377, loss_ce: 0.044053
2021-11-30 12:46:40,046 iteration 772 : loss : 0.134474, loss_ce: 0.050159
2021-11-30 12:46:41,398 iteration 773 : loss : 0.116295, loss_ce: 0.056329
2021-11-30 12:46:42,741 iteration 774 : loss : 0.094805, loss_ce: 0.043409
2021-11-30 12:46:44,102 iteration 775 : loss : 0.081034, loss_ce: 0.037819
2021-11-30 12:46:45,443 iteration 776 : loss : 0.096856, loss_ce: 0.040554
2021-11-30 12:46:46,789 iteration 777 : loss : 0.092228, loss_ce: 0.038763
2021-11-30 12:46:48,146 iteration 778 : loss : 0.126604, loss_ce: 0.045202
2021-11-30 12:46:49,498 iteration 779 : loss : 0.104359, loss_ce: 0.051848
2021-11-30 12:46:50,853 iteration 780 : loss : 0.108006, loss_ce: 0.046485
2021-11-30 12:46:52,204 iteration 781 : loss : 0.119543, loss_ce: 0.053687
2021-11-30 12:46:53,548 iteration 782 : loss : 0.083992, loss_ce: 0.039984
 12%|███▍                          | 46/400 [19:32<2:33:36, 26.04s/it]2021-11-30 12:46:54,961 iteration 783 : loss : 0.087315, loss_ce: 0.039152
2021-11-30 12:46:56,309 iteration 784 : loss : 0.104550, loss_ce: 0.042842
2021-11-30 12:46:57,668 iteration 785 : loss : 0.112169, loss_ce: 0.039970
2021-11-30 12:46:59,024 iteration 786 : loss : 0.087874, loss_ce: 0.038055
2021-11-30 12:47:00,382 iteration 787 : loss : 0.114357, loss_ce: 0.050009
2021-11-30 12:47:01,725 iteration 788 : loss : 0.092649, loss_ce: 0.044226
2021-11-30 12:47:03,083 iteration 789 : loss : 0.108720, loss_ce: 0.042297
2021-11-30 12:47:04,435 iteration 790 : loss : 0.098054, loss_ce: 0.044159
2021-11-30 12:47:05,789 iteration 791 : loss : 0.092817, loss_ce: 0.037736
2021-11-30 12:47:07,129 iteration 792 : loss : 0.126292, loss_ce: 0.050705
2021-11-30 12:47:08,476 iteration 793 : loss : 0.093936, loss_ce: 0.046846
2021-11-30 12:47:09,825 iteration 794 : loss : 0.108135, loss_ce: 0.041825
2021-11-30 12:47:11,171 iteration 795 : loss : 0.102953, loss_ce: 0.051174
2021-11-30 12:47:12,528 iteration 796 : loss : 0.100382, loss_ce: 0.045230
2021-11-30 12:47:13,874 iteration 797 : loss : 0.112588, loss_ce: 0.046432
2021-11-30 12:47:15,228 iteration 798 : loss : 0.096976, loss_ce: 0.046333
2021-11-30 12:47:16,560 iteration 799 : loss : 0.103981, loss_ce: 0.048405
 12%|███▌                          | 47/400 [19:55<2:27:50, 25.13s/it]2021-11-30 12:47:17,971 iteration 800 : loss : 0.133147, loss_ce: 0.048280
2021-11-30 12:47:19,320 iteration 801 : loss : 0.089997, loss_ce: 0.045343
2021-11-30 12:47:20,669 iteration 802 : loss : 0.084910, loss_ce: 0.035648
2021-11-30 12:47:22,018 iteration 803 : loss : 0.077492, loss_ce: 0.038938
2021-11-30 12:47:23,367 iteration 804 : loss : 0.097947, loss_ce: 0.043648
2021-11-30 12:47:24,723 iteration 805 : loss : 0.104113, loss_ce: 0.041372
2021-11-30 12:47:26,076 iteration 806 : loss : 0.086964, loss_ce: 0.042742
2021-11-30 12:47:27,432 iteration 807 : loss : 0.104525, loss_ce: 0.045368
2021-11-30 12:47:28,784 iteration 808 : loss : 0.098127, loss_ce: 0.040582
2021-11-30 12:47:30,142 iteration 809 : loss : 0.084849, loss_ce: 0.042381
2021-11-30 12:47:31,495 iteration 810 : loss : 0.144555, loss_ce: 0.050409
2021-11-30 12:47:32,852 iteration 811 : loss : 0.108139, loss_ce: 0.042808
2021-11-30 12:47:34,214 iteration 812 : loss : 0.099195, loss_ce: 0.040429
2021-11-30 12:47:35,564 iteration 813 : loss : 0.108505, loss_ce: 0.046471
2021-11-30 12:47:36,923 iteration 814 : loss : 0.091616, loss_ce: 0.045632
2021-11-30 12:47:38,276 iteration 815 : loss : 0.111450, loss_ce: 0.048639
2021-11-30 12:47:39,643 iteration 816 : loss : 0.095240, loss_ce: 0.046048
 12%|███▌                          | 48/400 [20:18<2:23:49, 24.51s/it]2021-11-30 12:47:41,080 iteration 817 : loss : 0.111844, loss_ce: 0.048375
2021-11-30 12:47:42,439 iteration 818 : loss : 0.082886, loss_ce: 0.039812
2021-11-30 12:47:43,798 iteration 819 : loss : 0.101988, loss_ce: 0.050497
2021-11-30 12:47:45,155 iteration 820 : loss : 0.114189, loss_ce: 0.048410
2021-11-30 12:47:46,512 iteration 821 : loss : 0.072823, loss_ce: 0.038948
2021-11-30 12:47:47,866 iteration 822 : loss : 0.079550, loss_ce: 0.039460
2021-11-30 12:47:49,224 iteration 823 : loss : 0.087901, loss_ce: 0.038377
2021-11-30 12:47:50,583 iteration 824 : loss : 0.102279, loss_ce: 0.042786
2021-11-30 12:47:51,939 iteration 825 : loss : 0.097013, loss_ce: 0.042236
2021-11-30 12:47:53,295 iteration 826 : loss : 0.071921, loss_ce: 0.037710
2021-11-30 12:47:54,652 iteration 827 : loss : 0.118580, loss_ce: 0.043302
2021-11-30 12:47:56,007 iteration 828 : loss : 0.087574, loss_ce: 0.040661
2021-11-30 12:47:57,361 iteration 829 : loss : 0.089859, loss_ce: 0.045004
2021-11-30 12:47:58,715 iteration 830 : loss : 0.130576, loss_ce: 0.038376
2021-11-30 12:48:00,070 iteration 831 : loss : 0.104576, loss_ce: 0.038321
2021-11-30 12:48:01,418 iteration 832 : loss : 0.099410, loss_ce: 0.040786
2021-11-30 12:48:02,774 iteration 833 : loss : 0.095676, loss_ce: 0.038162
 12%|███▋                          | 49/400 [20:41<2:20:58, 24.10s/it]2021-11-30 12:48:04,198 iteration 834 : loss : 0.110898, loss_ce: 0.050377
2021-11-30 12:48:05,546 iteration 835 : loss : 0.093484, loss_ce: 0.037186
2021-11-30 12:48:06,900 iteration 836 : loss : 0.097459, loss_ce: 0.041789
2021-11-30 12:48:08,258 iteration 837 : loss : 0.095637, loss_ce: 0.035065
2021-11-30 12:48:09,611 iteration 838 : loss : 0.084399, loss_ce: 0.039496
2021-11-30 12:48:10,955 iteration 839 : loss : 0.102410, loss_ce: 0.035217
2021-11-30 12:48:12,310 iteration 840 : loss : 0.086876, loss_ce: 0.042114
2021-11-30 12:48:13,659 iteration 841 : loss : 0.111050, loss_ce: 0.040832
2021-11-30 12:48:15,019 iteration 842 : loss : 0.082189, loss_ce: 0.038707
2021-11-30 12:48:16,365 iteration 843 : loss : 0.082047, loss_ce: 0.037807
2021-11-30 12:48:17,719 iteration 844 : loss : 0.115141, loss_ce: 0.048484
2021-11-30 12:48:19,073 iteration 845 : loss : 0.080412, loss_ce: 0.038116
2021-11-30 12:48:20,432 iteration 846 : loss : 0.100903, loss_ce: 0.042686
2021-11-30 12:48:21,792 iteration 847 : loss : 0.087886, loss_ce: 0.039469
2021-11-30 12:48:23,143 iteration 848 : loss : 0.083236, loss_ce: 0.035219
2021-11-30 12:48:24,504 iteration 849 : loss : 0.086640, loss_ce: 0.041619
2021-11-30 12:48:24,504 Training Data Eval:
2021-11-30 12:48:32,129   Average segmentation loss on training set: 0.0838
2021-11-30 12:48:32,130 Validation Data Eval:
2021-11-30 12:48:34,762   Average segmentation loss on validation set: 0.1414
2021-11-30 12:48:38,870 Found new lowest validation loss at iteration 849! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/UNET_RUNMC/best_val_loss_no_da.pth
2021-11-30 12:48:40,121 iteration 850 : loss : 0.077168, loss_ce: 0.033902
 12%|███▊                          | 50/400 [21:18<2:43:45, 28.07s/it]2021-11-30 12:48:41,416 iteration 851 : loss : 0.092655, loss_ce: 0.038557
2021-11-30 12:48:42,633 iteration 852 : loss : 0.074323, loss_ce: 0.032442
2021-11-30 12:48:43,857 iteration 853 : loss : 0.105688, loss_ce: 0.035111
2021-11-30 12:48:45,108 iteration 854 : loss : 0.089289, loss_ce: 0.047350
2021-11-30 12:48:46,437 iteration 855 : loss : 0.080276, loss_ce: 0.040987
2021-11-30 12:48:47,789 iteration 856 : loss : 0.099474, loss_ce: 0.039490
2021-11-30 12:48:49,143 iteration 857 : loss : 0.091425, loss_ce: 0.039254
2021-11-30 12:48:50,486 iteration 858 : loss : 0.090169, loss_ce: 0.036033
2021-11-30 12:48:51,836 iteration 859 : loss : 0.074398, loss_ce: 0.036981
2021-11-30 12:48:53,179 iteration 860 : loss : 0.105155, loss_ce: 0.043710
2021-11-30 12:48:54,544 iteration 861 : loss : 0.079118, loss_ce: 0.038302
2021-11-30 12:48:55,897 iteration 862 : loss : 0.084214, loss_ce: 0.037622
2021-11-30 12:48:57,248 iteration 863 : loss : 0.073553, loss_ce: 0.034531
2021-11-30 12:48:58,613 iteration 864 : loss : 0.091366, loss_ce: 0.040357
2021-11-30 12:48:59,967 iteration 865 : loss : 0.104393, loss_ce: 0.036354
2021-11-30 12:49:01,327 iteration 866 : loss : 0.071333, loss_ce: 0.033381
2021-11-30 12:49:02,677 iteration 867 : loss : 0.078504, loss_ce: 0.035057
 13%|███▊                          | 51/400 [21:41<2:33:40, 26.42s/it]2021-11-30 12:49:04,100 iteration 868 : loss : 0.068410, loss_ce: 0.031899
2021-11-30 12:49:05,453 iteration 869 : loss : 0.108536, loss_ce: 0.051901
2021-11-30 12:49:06,816 iteration 870 : loss : 0.081657, loss_ce: 0.033105
2021-11-30 12:49:08,171 iteration 871 : loss : 0.062552, loss_ce: 0.029900
2021-11-30 12:49:09,513 iteration 872 : loss : 0.095275, loss_ce: 0.041308
2021-11-30 12:49:10,857 iteration 873 : loss : 0.102717, loss_ce: 0.035666
2021-11-30 12:49:12,216 iteration 874 : loss : 0.079220, loss_ce: 0.035591
2021-11-30 12:49:13,575 iteration 875 : loss : 0.084971, loss_ce: 0.035486
2021-11-30 12:49:14,928 iteration 876 : loss : 0.070571, loss_ce: 0.032924
2021-11-30 12:49:16,282 iteration 877 : loss : 0.091270, loss_ce: 0.035419
2021-11-30 12:49:17,638 iteration 878 : loss : 0.071574, loss_ce: 0.033645
2021-11-30 12:49:18,980 iteration 879 : loss : 0.062792, loss_ce: 0.031761
2021-11-30 12:49:20,326 iteration 880 : loss : 0.107554, loss_ce: 0.053073
2021-11-30 12:49:21,680 iteration 881 : loss : 0.076454, loss_ce: 0.035278
2021-11-30 12:49:23,031 iteration 882 : loss : 0.079921, loss_ce: 0.035966
2021-11-30 12:49:24,382 iteration 883 : loss : 0.101767, loss_ce: 0.035623
2021-11-30 12:49:25,745 iteration 884 : loss : 0.072347, loss_ce: 0.036543
 13%|███▉                          | 52/400 [22:04<2:27:23, 25.41s/it]2021-11-30 12:49:27,172 iteration 885 : loss : 0.087814, loss_ce: 0.036720
2021-11-30 12:49:28,530 iteration 886 : loss : 0.081097, loss_ce: 0.039482
2021-11-30 12:49:29,884 iteration 887 : loss : 0.083826, loss_ce: 0.040565
2021-11-30 12:49:31,236 iteration 888 : loss : 0.078207, loss_ce: 0.030894
2021-11-30 12:49:32,581 iteration 889 : loss : 0.071253, loss_ce: 0.032579
2021-11-30 12:49:33,939 iteration 890 : loss : 0.089173, loss_ce: 0.037649
2021-11-30 12:49:35,293 iteration 891 : loss : 0.089388, loss_ce: 0.035962
2021-11-30 12:49:36,648 iteration 892 : loss : 0.094913, loss_ce: 0.035751
2021-11-30 12:49:37,999 iteration 893 : loss : 0.083634, loss_ce: 0.036043
2021-11-30 12:49:39,342 iteration 894 : loss : 0.067752, loss_ce: 0.034498
2021-11-30 12:49:40,694 iteration 895 : loss : 0.091927, loss_ce: 0.032501
2021-11-30 12:49:42,048 iteration 896 : loss : 0.064110, loss_ce: 0.030771
2021-11-30 12:49:43,399 iteration 897 : loss : 0.098388, loss_ce: 0.041444
2021-11-30 12:49:44,748 iteration 898 : loss : 0.067785, loss_ce: 0.033955
2021-11-30 12:49:46,109 iteration 899 : loss : 0.070490, loss_ce: 0.038649
2021-11-30 12:49:47,454 iteration 900 : loss : 0.062889, loss_ce: 0.031536
2021-11-30 12:49:48,820 iteration 901 : loss : 0.083441, loss_ce: 0.033775
 13%|███▉                          | 53/400 [22:27<2:22:54, 24.71s/it]2021-11-30 12:49:50,228 iteration 902 : loss : 0.067613, loss_ce: 0.032086
2021-11-30 12:49:51,569 iteration 903 : loss : 0.104658, loss_ce: 0.038205
2021-11-30 12:49:52,930 iteration 904 : loss : 0.109273, loss_ce: 0.044191
2021-11-30 12:49:54,284 iteration 905 : loss : 0.064576, loss_ce: 0.032024
2021-11-30 12:49:55,646 iteration 906 : loss : 0.074711, loss_ce: 0.036367
2021-11-30 12:49:57,001 iteration 907 : loss : 0.060006, loss_ce: 0.029742
2021-11-30 12:49:58,351 iteration 908 : loss : 0.110151, loss_ce: 0.038165
2021-11-30 12:49:59,698 iteration 909 : loss : 0.102539, loss_ce: 0.044637
2021-11-30 12:50:01,098 iteration 910 : loss : 0.061409, loss_ce: 0.033043
2021-11-30 12:50:02,436 iteration 911 : loss : 0.139163, loss_ce: 0.037558
2021-11-30 12:50:03,786 iteration 912 : loss : 0.106806, loss_ce: 0.037241
2021-11-30 12:50:05,137 iteration 913 : loss : 0.076893, loss_ce: 0.038968
2021-11-30 12:50:06,484 iteration 914 : loss : 0.081361, loss_ce: 0.039894
2021-11-30 12:50:07,845 iteration 915 : loss : 0.119401, loss_ce: 0.045933
2021-11-30 12:50:09,203 iteration 916 : loss : 0.081307, loss_ce: 0.034772
2021-11-30 12:50:10,555 iteration 917 : loss : 0.054941, loss_ce: 0.026281
2021-11-30 12:50:11,895 iteration 918 : loss : 0.059895, loss_ce: 0.031523
 14%|████                          | 54/400 [22:50<2:19:40, 24.22s/it]2021-11-30 12:50:13,312 iteration 919 : loss : 0.078210, loss_ce: 0.033738
2021-11-30 12:50:14,656 iteration 920 : loss : 0.069471, loss_ce: 0.034596
2021-11-30 12:50:16,012 iteration 921 : loss : 0.069572, loss_ce: 0.031786
2021-11-30 12:50:17,360 iteration 922 : loss : 0.128013, loss_ce: 0.044553
2021-11-30 12:50:18,717 iteration 923 : loss : 0.070949, loss_ce: 0.033833
2021-11-30 12:50:20,067 iteration 924 : loss : 0.092632, loss_ce: 0.037220
2021-11-30 12:50:21,428 iteration 925 : loss : 0.075899, loss_ce: 0.036784
2021-11-30 12:50:22,783 iteration 926 : loss : 0.066391, loss_ce: 0.035522
2021-11-30 12:50:24,133 iteration 927 : loss : 0.054961, loss_ce: 0.030420
2021-11-30 12:50:25,482 iteration 928 : loss : 0.107918, loss_ce: 0.039907
2021-11-30 12:50:26,829 iteration 929 : loss : 0.058622, loss_ce: 0.029962
2021-11-30 12:50:28,174 iteration 930 : loss : 0.073999, loss_ce: 0.032871
2021-11-30 12:50:29,529 iteration 931 : loss : 0.073175, loss_ce: 0.031059
2021-11-30 12:50:30,874 iteration 932 : loss : 0.083082, loss_ce: 0.033381
2021-11-30 12:50:32,236 iteration 933 : loss : 0.070532, loss_ce: 0.031286
2021-11-30 12:50:33,589 iteration 934 : loss : 0.084034, loss_ce: 0.037041
2021-11-30 12:50:33,589 Training Data Eval:
2021-11-30 12:50:41,271   Average segmentation loss on training set: 0.0885
2021-11-30 12:50:41,271 Validation Data Eval:
2021-11-30 12:50:43,941   Average segmentation loss on validation set: 0.1426
2021-11-30 12:50:45,295 iteration 935 : loss : 0.090853, loss_ce: 0.037114
 14%|████▏                         | 55/400 [23:23<2:35:06, 26.97s/it]2021-11-30 12:50:46,722 iteration 936 : loss : 0.085852, loss_ce: 0.035208
2021-11-30 12:50:48,079 iteration 937 : loss : 0.071512, loss_ce: 0.037526
2021-11-30 12:50:49,443 iteration 938 : loss : 0.103726, loss_ce: 0.030942
2021-11-30 12:50:50,793 iteration 939 : loss : 0.068122, loss_ce: 0.034909
2021-11-30 12:50:52,139 iteration 940 : loss : 0.080357, loss_ce: 0.032587
2021-11-30 12:50:53,497 iteration 941 : loss : 0.079736, loss_ce: 0.034779
2021-11-30 12:50:54,846 iteration 942 : loss : 0.077754, loss_ce: 0.033499
2021-11-30 12:50:56,207 iteration 943 : loss : 0.090785, loss_ce: 0.039748
2021-11-30 12:50:57,560 iteration 944 : loss : 0.068892, loss_ce: 0.035505
2021-11-30 12:50:58,904 iteration 945 : loss : 0.086556, loss_ce: 0.033075
2021-11-30 12:51:00,263 iteration 946 : loss : 0.093693, loss_ce: 0.034722
2021-11-30 12:51:01,620 iteration 947 : loss : 0.064379, loss_ce: 0.031272
2021-11-30 12:51:02,974 iteration 948 : loss : 0.059163, loss_ce: 0.031843
2021-11-30 12:51:04,326 iteration 949 : loss : 0.121985, loss_ce: 0.034832
2021-11-30 12:51:05,686 iteration 950 : loss : 0.090941, loss_ce: 0.041965
2021-11-30 12:51:07,052 iteration 951 : loss : 0.058190, loss_ce: 0.030558
2021-11-30 12:51:08,408 iteration 952 : loss : 0.070907, loss_ce: 0.034341
 14%|████▏                         | 56/400 [23:47<2:28:00, 25.82s/it]2021-11-30 12:51:09,835 iteration 953 : loss : 0.086473, loss_ce: 0.046200
2021-11-30 12:51:11,191 iteration 954 : loss : 0.072429, loss_ce: 0.030168
2021-11-30 12:51:12,554 iteration 955 : loss : 0.080879, loss_ce: 0.033000
2021-11-30 12:51:13,909 iteration 956 : loss : 0.066349, loss_ce: 0.028610
2021-11-30 12:51:15,256 iteration 957 : loss : 0.085590, loss_ce: 0.035312
2021-11-30 12:51:16,611 iteration 958 : loss : 0.064758, loss_ce: 0.032944
2021-11-30 12:51:17,962 iteration 959 : loss : 0.061424, loss_ce: 0.030880
2021-11-30 12:51:19,321 iteration 960 : loss : 0.093773, loss_ce: 0.038715
2021-11-30 12:51:20,671 iteration 961 : loss : 0.062633, loss_ce: 0.033143
2021-11-30 12:51:22,007 iteration 962 : loss : 0.093404, loss_ce: 0.035389
2021-11-30 12:51:23,358 iteration 963 : loss : 0.067873, loss_ce: 0.027725
2021-11-30 12:51:24,718 iteration 964 : loss : 0.065340, loss_ce: 0.031637
2021-11-30 12:51:26,077 iteration 965 : loss : 0.084080, loss_ce: 0.036066
2021-11-30 12:51:27,415 iteration 966 : loss : 0.077754, loss_ce: 0.032369
2021-11-30 12:51:28,754 iteration 967 : loss : 0.065107, loss_ce: 0.032732
2021-11-30 12:51:30,108 iteration 968 : loss : 0.091116, loss_ce: 0.038263
2021-11-30 12:51:31,455 iteration 969 : loss : 0.075336, loss_ce: 0.026735
 14%|████▎                         | 57/400 [24:10<2:22:49, 24.98s/it]2021-11-30 12:51:32,864 iteration 970 : loss : 0.064147, loss_ce: 0.029050
2021-11-30 12:51:34,208 iteration 971 : loss : 0.055540, loss_ce: 0.030386
2021-11-30 12:51:35,559 iteration 972 : loss : 0.085214, loss_ce: 0.032944
2021-11-30 12:51:36,918 iteration 973 : loss : 0.084059, loss_ce: 0.030752
2021-11-30 12:51:38,269 iteration 974 : loss : 0.080776, loss_ce: 0.030063
2021-11-30 12:51:39,616 iteration 975 : loss : 0.064745, loss_ce: 0.027548
2021-11-30 12:51:40,963 iteration 976 : loss : 0.064415, loss_ce: 0.029673
2021-11-30 12:51:42,316 iteration 977 : loss : 0.067002, loss_ce: 0.030728
2021-11-30 12:51:43,674 iteration 978 : loss : 0.061218, loss_ce: 0.029119
2021-11-30 12:51:45,022 iteration 979 : loss : 0.064617, loss_ce: 0.029309
2021-11-30 12:51:46,378 iteration 980 : loss : 0.073923, loss_ce: 0.027227
2021-11-30 12:51:47,718 iteration 981 : loss : 0.099437, loss_ce: 0.033696
2021-11-30 12:51:49,073 iteration 982 : loss : 0.069372, loss_ce: 0.031540
2021-11-30 12:51:50,411 iteration 983 : loss : 0.069270, loss_ce: 0.033294
2021-11-30 12:51:51,765 iteration 984 : loss : 0.055803, loss_ce: 0.029976
2021-11-30 12:51:53,129 iteration 985 : loss : 0.059896, loss_ce: 0.032805
2021-11-30 12:51:54,481 iteration 986 : loss : 0.081037, loss_ce: 0.035065
 14%|████▎                         | 58/400 [24:33<2:19:04, 24.40s/it]2021-11-30 12:51:55,895 iteration 987 : loss : 0.078501, loss_ce: 0.027440
2021-11-30 12:51:57,244 iteration 988 : loss : 0.059500, loss_ce: 0.028103
2021-11-30 12:51:58,605 iteration 989 : loss : 0.098986, loss_ce: 0.038243
2021-11-30 12:51:59,967 iteration 990 : loss : 0.055973, loss_ce: 0.025149
2021-11-30 12:52:01,327 iteration 991 : loss : 0.064518, loss_ce: 0.028243
2021-11-30 12:52:02,685 iteration 992 : loss : 0.067500, loss_ce: 0.032502
2021-11-30 12:52:04,041 iteration 993 : loss : 0.048240, loss_ce: 0.025201
2021-11-30 12:52:05,395 iteration 994 : loss : 0.059870, loss_ce: 0.032595
2021-11-30 12:52:06,752 iteration 995 : loss : 0.067041, loss_ce: 0.027176
2021-11-30 12:52:08,108 iteration 996 : loss : 0.055069, loss_ce: 0.028551
2021-11-30 12:52:09,457 iteration 997 : loss : 0.069213, loss_ce: 0.028604
2021-11-30 12:52:10,810 iteration 998 : loss : 0.068634, loss_ce: 0.032043
2021-11-30 12:52:12,169 iteration 999 : loss : 0.056439, loss_ce: 0.027136
2021-11-30 12:52:13,523 iteration 1000 : loss : 0.057196, loss_ce: 0.028261
2021-11-30 12:52:14,880 iteration 1001 : loss : 0.077361, loss_ce: 0.035616
2021-11-30 12:52:16,236 iteration 1002 : loss : 0.054422, loss_ce: 0.031129
2021-11-30 12:52:17,588 iteration 1003 : loss : 0.072894, loss_ce: 0.033156
 15%|████▍                         | 59/400 [24:56<2:16:27, 24.01s/it]2021-11-30 12:52:18,999 iteration 1004 : loss : 0.078125, loss_ce: 0.027465
2021-11-30 12:52:20,344 iteration 1005 : loss : 0.058314, loss_ce: 0.026631
2021-11-30 12:52:21,681 iteration 1006 : loss : 0.065062, loss_ce: 0.028080
2021-11-30 12:52:23,046 iteration 1007 : loss : 0.053104, loss_ce: 0.026361
2021-11-30 12:52:24,399 iteration 1008 : loss : 0.056314, loss_ce: 0.029350
2021-11-30 12:52:25,754 iteration 1009 : loss : 0.055219, loss_ce: 0.025353
2021-11-30 12:52:27,111 iteration 1010 : loss : 0.062769, loss_ce: 0.031370
2021-11-30 12:52:28,456 iteration 1011 : loss : 0.062539, loss_ce: 0.028515
2021-11-30 12:52:29,802 iteration 1012 : loss : 0.057635, loss_ce: 0.027845
2021-11-30 12:52:31,146 iteration 1013 : loss : 0.061755, loss_ce: 0.027939
2021-11-30 12:52:32,489 iteration 1014 : loss : 0.046940, loss_ce: 0.023860
2021-11-30 12:52:33,839 iteration 1015 : loss : 0.074000, loss_ce: 0.029485
2021-11-30 12:52:35,190 iteration 1016 : loss : 0.070621, loss_ce: 0.026787
2021-11-30 12:52:36,545 iteration 1017 : loss : 0.079186, loss_ce: 0.035601
2021-11-30 12:52:37,890 iteration 1018 : loss : 0.045310, loss_ce: 0.026449
2021-11-30 12:52:39,233 iteration 1019 : loss : 0.058661, loss_ce: 0.033986
2021-11-30 12:52:39,234 Training Data Eval:
2021-11-30 12:52:46,869   Average segmentation loss on training set: 0.0629
2021-11-30 12:52:46,869 Validation Data Eval:
2021-11-30 12:52:49,491   Average segmentation loss on validation set: 0.1914
2021-11-30 12:52:50,822 iteration 1020 : loss : 0.062871, loss_ce: 0.027233
 15%|████▌                         | 60/400 [25:29<2:31:44, 26.78s/it]2021-11-30 12:52:52,237 iteration 1021 : loss : 0.066014, loss_ce: 0.026556
2021-11-30 12:52:53,590 iteration 1022 : loss : 0.061217, loss_ce: 0.030476
2021-11-30 12:52:54,948 iteration 1023 : loss : 0.058450, loss_ce: 0.029586
2021-11-30 12:52:56,305 iteration 1024 : loss : 0.056914, loss_ce: 0.027631
2021-11-30 12:52:57,655 iteration 1025 : loss : 0.058768, loss_ce: 0.028787
2021-11-30 12:52:59,007 iteration 1026 : loss : 0.058624, loss_ce: 0.030163
2021-11-30 12:53:00,364 iteration 1027 : loss : 0.060681, loss_ce: 0.028225
2021-11-30 12:53:01,728 iteration 1028 : loss : 0.086441, loss_ce: 0.039856
2021-11-30 12:53:03,076 iteration 1029 : loss : 0.060889, loss_ce: 0.029460
2021-11-30 12:53:04,424 iteration 1030 : loss : 0.052653, loss_ce: 0.029120
2021-11-30 12:53:05,775 iteration 1031 : loss : 0.063659, loss_ce: 0.029326
2021-11-30 12:53:07,119 iteration 1032 : loss : 0.096575, loss_ce: 0.041589
2021-11-30 12:53:08,482 iteration 1033 : loss : 0.058157, loss_ce: 0.028792
2021-11-30 12:53:09,832 iteration 1034 : loss : 0.046527, loss_ce: 0.022935
2021-11-30 12:53:11,184 iteration 1035 : loss : 0.127661, loss_ce: 0.039280
2021-11-30 12:53:12,540 iteration 1036 : loss : 0.062335, loss_ce: 0.031661
2021-11-30 12:53:13,886 iteration 1037 : loss : 0.093598, loss_ce: 0.033702
 15%|████▌                         | 61/400 [25:52<2:25:00, 25.66s/it]2021-11-30 12:53:15,296 iteration 1038 : loss : 0.058946, loss_ce: 0.029956
2021-11-30 12:53:16,638 iteration 1039 : loss : 0.064347, loss_ce: 0.033377
2021-11-30 12:53:17,989 iteration 1040 : loss : 0.155981, loss_ce: 0.024759
2021-11-30 12:53:19,342 iteration 1041 : loss : 0.096313, loss_ce: 0.039782
2021-11-30 12:53:20,686 iteration 1042 : loss : 0.107183, loss_ce: 0.033097
2021-11-30 12:53:22,030 iteration 1043 : loss : 0.079981, loss_ce: 0.029573
2021-11-30 12:53:23,378 iteration 1044 : loss : 0.066770, loss_ce: 0.036272
2021-11-30 12:53:24,724 iteration 1045 : loss : 0.076848, loss_ce: 0.037627
2021-11-30 12:53:26,067 iteration 1046 : loss : 0.074179, loss_ce: 0.032101
2021-11-30 12:53:27,411 iteration 1047 : loss : 0.060561, loss_ce: 0.027753
2021-11-30 12:53:28,766 iteration 1048 : loss : 0.061552, loss_ce: 0.027663
2021-11-30 12:53:30,110 iteration 1049 : loss : 0.081212, loss_ce: 0.033359
2021-11-30 12:53:31,467 iteration 1050 : loss : 0.065514, loss_ce: 0.031201
2021-11-30 12:53:32,820 iteration 1051 : loss : 0.055477, loss_ce: 0.028564
2021-11-30 12:53:34,163 iteration 1052 : loss : 0.066176, loss_ce: 0.033259
2021-11-30 12:53:35,523 iteration 1053 : loss : 0.092259, loss_ce: 0.035074
2021-11-30 12:53:36,877 iteration 1054 : loss : 0.106645, loss_ce: 0.045882
 16%|████▋                         | 62/400 [26:15<2:20:03, 24.86s/it]2021-11-30 12:53:38,284 iteration 1055 : loss : 0.102987, loss_ce: 0.031112
2021-11-30 12:53:39,616 iteration 1056 : loss : 0.058579, loss_ce: 0.032077
2021-11-30 12:53:40,971 iteration 1057 : loss : 0.052510, loss_ce: 0.026345
2021-11-30 12:53:42,318 iteration 1058 : loss : 0.064642, loss_ce: 0.031099
2021-11-30 12:53:43,667 iteration 1059 : loss : 0.080657, loss_ce: 0.035038
2021-11-30 12:53:45,008 iteration 1060 : loss : 0.101541, loss_ce: 0.045058
2021-11-30 12:53:46,366 iteration 1061 : loss : 0.057379, loss_ce: 0.030576
2021-11-30 12:53:47,717 iteration 1062 : loss : 0.070585, loss_ce: 0.036898
2021-11-30 12:53:49,059 iteration 1063 : loss : 0.057145, loss_ce: 0.029994
2021-11-30 12:53:50,409 iteration 1064 : loss : 0.063839, loss_ce: 0.028362
2021-11-30 12:53:51,750 iteration 1065 : loss : 0.071739, loss_ce: 0.027196
2021-11-30 12:53:53,091 iteration 1066 : loss : 0.065857, loss_ce: 0.028275
2021-11-30 12:53:54,436 iteration 1067 : loss : 0.134613, loss_ce: 0.036091
2021-11-30 12:53:55,788 iteration 1068 : loss : 0.085703, loss_ce: 0.031642
2021-11-30 12:53:57,138 iteration 1069 : loss : 0.064583, loss_ce: 0.027417
2021-11-30 12:53:58,493 iteration 1070 : loss : 0.064863, loss_ce: 0.027041
2021-11-30 12:53:59,854 iteration 1071 : loss : 0.053785, loss_ce: 0.025716
 16%|████▋                         | 63/400 [26:38<2:16:27, 24.30s/it]2021-11-30 12:54:01,275 iteration 1072 : loss : 0.089297, loss_ce: 0.032968
2021-11-30 12:54:02,612 iteration 1073 : loss : 0.081890, loss_ce: 0.025938
2021-11-30 12:54:03,973 iteration 1074 : loss : 0.049547, loss_ce: 0.024567
2021-11-30 12:54:05,335 iteration 1075 : loss : 0.083201, loss_ce: 0.035817
2021-11-30 12:54:06,685 iteration 1076 : loss : 0.065526, loss_ce: 0.035713
2021-11-30 12:54:08,038 iteration 1077 : loss : 0.198267, loss_ce: 0.045023
2021-11-30 12:54:09,399 iteration 1078 : loss : 0.061716, loss_ce: 0.028304
2021-11-30 12:54:10,758 iteration 1079 : loss : 0.077826, loss_ce: 0.038817
2021-11-30 12:54:12,096 iteration 1080 : loss : 0.062940, loss_ce: 0.030012
2021-11-30 12:54:13,454 iteration 1081 : loss : 0.057265, loss_ce: 0.024217
2021-11-30 12:54:14,813 iteration 1082 : loss : 0.075364, loss_ce: 0.038615
2021-11-30 12:54:16,172 iteration 1083 : loss : 0.066308, loss_ce: 0.026716
2021-11-30 12:54:17,524 iteration 1084 : loss : 0.062567, loss_ce: 0.028529
2021-11-30 12:54:18,875 iteration 1085 : loss : 0.057078, loss_ce: 0.024482
2021-11-30 12:54:20,234 iteration 1086 : loss : 0.062947, loss_ce: 0.030720
2021-11-30 12:54:21,592 iteration 1087 : loss : 0.045100, loss_ce: 0.024683
2021-11-30 12:54:22,941 iteration 1088 : loss : 0.063245, loss_ce: 0.032515
 16%|████▊                         | 64/400 [27:01<2:14:01, 23.93s/it]2021-11-30 12:54:24,347 iteration 1089 : loss : 0.056535, loss_ce: 0.029358
2021-11-30 12:54:25,702 iteration 1090 : loss : 0.080330, loss_ce: 0.035017
2021-11-30 12:54:27,057 iteration 1091 : loss : 0.086318, loss_ce: 0.033313
2021-11-30 12:54:28,403 iteration 1092 : loss : 0.070448, loss_ce: 0.026444
2021-11-30 12:54:29,753 iteration 1093 : loss : 0.062199, loss_ce: 0.030029
2021-11-30 12:54:31,115 iteration 1094 : loss : 0.062589, loss_ce: 0.035469
2021-11-30 12:54:32,467 iteration 1095 : loss : 0.047702, loss_ce: 0.024905
2021-11-30 12:54:33,813 iteration 1096 : loss : 0.043214, loss_ce: 0.022219
2021-11-30 12:54:35,163 iteration 1097 : loss : 0.063164, loss_ce: 0.023409
2021-11-30 12:54:36,505 iteration 1098 : loss : 0.067676, loss_ce: 0.026564
2021-11-30 12:54:37,851 iteration 1099 : loss : 0.057315, loss_ce: 0.024895
2021-11-30 12:54:39,207 iteration 1100 : loss : 0.056389, loss_ce: 0.025964
2021-11-30 12:54:40,551 iteration 1101 : loss : 0.052511, loss_ce: 0.027699
2021-11-30 12:54:41,905 iteration 1102 : loss : 0.077742, loss_ce: 0.033998
2021-11-30 12:54:43,258 iteration 1103 : loss : 0.086713, loss_ce: 0.033208
2021-11-30 12:54:44,611 iteration 1104 : loss : 0.079454, loss_ce: 0.029962
2021-11-30 12:54:44,611 Training Data Eval:
2021-11-30 12:54:52,264   Average segmentation loss on training set: 0.0596
2021-11-30 12:54:52,265 Validation Data Eval:
2021-11-30 12:54:54,894   Average segmentation loss on validation set: 0.1386
2021-11-30 12:54:56,864 Found new lowest validation loss at iteration 1104! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/UNET_RUNMC/best_val_loss_no_da.pth
2021-11-30 12:54:58,103 iteration 1105 : loss : 0.057099, loss_ce: 0.027604
 16%|████▉                         | 65/400 [27:36<2:32:26, 27.30s/it]2021-11-30 12:54:59,396 iteration 1106 : loss : 0.051814, loss_ce: 0.027209
2021-11-30 12:55:00,666 iteration 1107 : loss : 0.064401, loss_ce: 0.030018
2021-11-30 12:55:02,014 iteration 1108 : loss : 0.059488, loss_ce: 0.026419
2021-11-30 12:55:03,373 iteration 1109 : loss : 0.104328, loss_ce: 0.029544
2021-11-30 12:55:04,729 iteration 1110 : loss : 0.078303, loss_ce: 0.022673
2021-11-30 12:55:06,075 iteration 1111 : loss : 0.059199, loss_ce: 0.028994
2021-11-30 12:55:07,433 iteration 1112 : loss : 0.085412, loss_ce: 0.037175
2021-11-30 12:55:08,790 iteration 1113 : loss : 0.089690, loss_ce: 0.034169
2021-11-30 12:55:10,151 iteration 1114 : loss : 0.053089, loss_ce: 0.025849
2021-11-30 12:55:11,504 iteration 1115 : loss : 0.082198, loss_ce: 0.044355
2021-11-30 12:55:12,867 iteration 1116 : loss : 0.077650, loss_ce: 0.030208
2021-11-30 12:55:14,225 iteration 1117 : loss : 0.074173, loss_ce: 0.026063
2021-11-30 12:55:15,571 iteration 1118 : loss : 0.055379, loss_ce: 0.025736
2021-11-30 12:55:16,921 iteration 1119 : loss : 0.047964, loss_ce: 0.025295
2021-11-30 12:55:18,267 iteration 1120 : loss : 0.050155, loss_ce: 0.027409
2021-11-30 12:55:19,613 iteration 1121 : loss : 0.058081, loss_ce: 0.025175
2021-11-30 12:55:20,969 iteration 1122 : loss : 0.078030, loss_ce: 0.031354
 16%|████▉                         | 66/400 [27:59<2:24:34, 25.97s/it]2021-11-30 12:55:22,380 iteration 1123 : loss : 0.068243, loss_ce: 0.027869
2021-11-30 12:55:23,733 iteration 1124 : loss : 0.050250, loss_ce: 0.023738
2021-11-30 12:55:25,089 iteration 1125 : loss : 0.070987, loss_ce: 0.032133
2021-11-30 12:55:26,441 iteration 1126 : loss : 0.056578, loss_ce: 0.027362
2021-11-30 12:55:27,794 iteration 1127 : loss : 0.057653, loss_ce: 0.023010
2021-11-30 12:55:29,154 iteration 1128 : loss : 0.048432, loss_ce: 0.025353
2021-11-30 12:55:30,512 iteration 1129 : loss : 0.061352, loss_ce: 0.025671
2021-11-30 12:55:31,875 iteration 1130 : loss : 0.050672, loss_ce: 0.026399
2021-11-30 12:55:33,230 iteration 1131 : loss : 0.053499, loss_ce: 0.028897
2021-11-30 12:55:34,589 iteration 1132 : loss : 0.052196, loss_ce: 0.027505
2021-11-30 12:55:35,942 iteration 1133 : loss : 0.048245, loss_ce: 0.026515
2021-11-30 12:55:37,296 iteration 1134 : loss : 0.055014, loss_ce: 0.028197
2021-11-30 12:55:38,660 iteration 1135 : loss : 0.075380, loss_ce: 0.029126
2021-11-30 12:55:40,024 iteration 1136 : loss : 0.072657, loss_ce: 0.027195
2021-11-30 12:55:41,384 iteration 1137 : loss : 0.089694, loss_ce: 0.028303
2021-11-30 12:55:42,734 iteration 1138 : loss : 0.065140, loss_ce: 0.029429
2021-11-30 12:55:44,092 iteration 1139 : loss : 0.068056, loss_ce: 0.030018
 17%|█████                         | 67/400 [28:22<2:19:23, 25.12s/it]2021-11-30 12:55:45,518 iteration 1140 : loss : 0.062199, loss_ce: 0.027601
2021-11-30 12:55:46,880 iteration 1141 : loss : 0.066675, loss_ce: 0.030303
2021-11-30 12:55:48,236 iteration 1142 : loss : 0.081454, loss_ce: 0.030166
2021-11-30 12:55:49,589 iteration 1143 : loss : 0.070565, loss_ce: 0.029311
2021-11-30 12:55:50,942 iteration 1144 : loss : 0.063758, loss_ce: 0.024819
2021-11-30 12:55:52,300 iteration 1145 : loss : 0.054346, loss_ce: 0.026098
2021-11-30 12:55:53,658 iteration 1146 : loss : 0.061147, loss_ce: 0.029782
2021-11-30 12:55:55,007 iteration 1147 : loss : 0.079368, loss_ce: 0.036540
2021-11-30 12:55:56,362 iteration 1148 : loss : 0.057329, loss_ce: 0.024581
2021-11-30 12:55:57,714 iteration 1149 : loss : 0.045452, loss_ce: 0.023821
2021-11-30 12:55:59,069 iteration 1150 : loss : 0.054862, loss_ce: 0.024892
2021-11-30 12:56:00,429 iteration 1151 : loss : 0.054334, loss_ce: 0.025371
2021-11-30 12:56:01,790 iteration 1152 : loss : 0.075606, loss_ce: 0.027179
2021-11-30 12:56:03,139 iteration 1153 : loss : 0.056912, loss_ce: 0.024815
2021-11-30 12:56:04,497 iteration 1154 : loss : 0.049416, loss_ce: 0.025204
2021-11-30 12:56:05,863 iteration 1155 : loss : 0.049311, loss_ce: 0.026005
2021-11-30 12:56:07,216 iteration 1156 : loss : 0.037178, loss_ce: 0.021695
 17%|█████                         | 68/400 [28:45<2:15:40, 24.52s/it]2021-11-30 12:56:08,627 iteration 1157 : loss : 0.053656, loss_ce: 0.025091
2021-11-30 12:56:09,973 iteration 1158 : loss : 0.046298, loss_ce: 0.022738
2021-11-30 12:56:11,330 iteration 1159 : loss : 0.059354, loss_ce: 0.029205
2021-11-30 12:56:12,673 iteration 1160 : loss : 0.063874, loss_ce: 0.028902
2021-11-30 12:56:14,030 iteration 1161 : loss : 0.036790, loss_ce: 0.021849
2021-11-30 12:56:15,382 iteration 1162 : loss : 0.062847, loss_ce: 0.028506
2021-11-30 12:56:16,728 iteration 1163 : loss : 0.057075, loss_ce: 0.025366
2021-11-30 12:56:18,084 iteration 1164 : loss : 0.054140, loss_ce: 0.024824
2021-11-30 12:56:19,445 iteration 1165 : loss : 0.063295, loss_ce: 0.031292
2021-11-30 12:56:20,808 iteration 1166 : loss : 0.069013, loss_ce: 0.026014
2021-11-30 12:56:22,169 iteration 1167 : loss : 0.041727, loss_ce: 0.022012
2021-11-30 12:56:23,526 iteration 1168 : loss : 0.064944, loss_ce: 0.033711
2021-11-30 12:56:24,886 iteration 1169 : loss : 0.057043, loss_ce: 0.028619
2021-11-30 12:56:26,247 iteration 1170 : loss : 0.086734, loss_ce: 0.027872
2021-11-30 12:56:27,604 iteration 1171 : loss : 0.093031, loss_ce: 0.028443
2021-11-30 12:56:28,960 iteration 1172 : loss : 0.051405, loss_ce: 0.024325
2021-11-30 12:56:30,322 iteration 1173 : loss : 0.051733, loss_ce: 0.024157
 17%|█████▏                        | 69/400 [29:08<2:12:55, 24.09s/it]2021-11-30 12:56:31,752 iteration 1174 : loss : 0.061037, loss_ce: 0.029177
2021-11-30 12:56:33,114 iteration 1175 : loss : 0.076276, loss_ce: 0.034088
2021-11-30 12:56:34,474 iteration 1176 : loss : 0.060124, loss_ce: 0.033520
2021-11-30 12:56:35,832 iteration 1177 : loss : 0.072945, loss_ce: 0.029579
2021-11-30 12:56:37,188 iteration 1178 : loss : 0.084552, loss_ce: 0.029627
2021-11-30 12:56:38,551 iteration 1179 : loss : 0.053307, loss_ce: 0.026678
2021-11-30 12:56:39,910 iteration 1180 : loss : 0.053220, loss_ce: 0.025273
2021-11-30 12:56:41,268 iteration 1181 : loss : 0.052566, loss_ce: 0.022478
2021-11-30 12:56:42,625 iteration 1182 : loss : 0.079565, loss_ce: 0.030684
2021-11-30 12:56:43,983 iteration 1183 : loss : 0.060179, loss_ce: 0.021691
2021-11-30 12:56:45,342 iteration 1184 : loss : 0.062349, loss_ce: 0.028301
2021-11-30 12:56:46,696 iteration 1185 : loss : 0.047743, loss_ce: 0.021073
2021-11-30 12:56:48,059 iteration 1186 : loss : 0.044617, loss_ce: 0.023569
2021-11-30 12:56:49,405 iteration 1187 : loss : 0.052982, loss_ce: 0.024609
2021-11-30 12:56:50,758 iteration 1188 : loss : 0.041672, loss_ce: 0.021514
2021-11-30 12:56:52,117 iteration 1189 : loss : 0.049448, loss_ce: 0.024383
2021-11-30 12:56:52,118 Training Data Eval:
2021-11-30 12:56:59,760   Average segmentation loss on training set: 0.0770
2021-11-30 12:56:59,760 Validation Data Eval:
2021-11-30 12:57:02,417   Average segmentation loss on validation set: 0.2431
2021-11-30 12:57:03,757 iteration 1190 : loss : 0.056455, loss_ce: 0.024097
 18%|█████▎                        | 70/400 [29:42<2:27:56, 26.90s/it]2021-11-30 12:57:05,183 iteration 1191 : loss : 0.054407, loss_ce: 0.027157
2021-11-30 12:57:06,525 iteration 1192 : loss : 0.049168, loss_ce: 0.023788
2021-11-30 12:57:07,886 iteration 1193 : loss : 0.049097, loss_ce: 0.025905
2021-11-30 12:57:09,237 iteration 1194 : loss : 0.047151, loss_ce: 0.024540
2021-11-30 12:57:10,580 iteration 1195 : loss : 0.040721, loss_ce: 0.021409
2021-11-30 12:57:11,932 iteration 1196 : loss : 0.056471, loss_ce: 0.023372
2021-11-30 12:57:13,277 iteration 1197 : loss : 0.047528, loss_ce: 0.021015
2021-11-30 12:57:14,643 iteration 1198 : loss : 0.044171, loss_ce: 0.019580
2021-11-30 12:57:15,994 iteration 1199 : loss : 0.048970, loss_ce: 0.025169
2021-11-30 12:57:17,346 iteration 1200 : loss : 0.043532, loss_ce: 0.022844
2021-11-30 12:57:18,705 iteration 1201 : loss : 0.038842, loss_ce: 0.021449
2021-11-30 12:57:20,061 iteration 1202 : loss : 0.058334, loss_ce: 0.020339
2021-11-30 12:57:21,425 iteration 1203 : loss : 0.061098, loss_ce: 0.026997
2021-11-30 12:57:22,778 iteration 1204 : loss : 0.053097, loss_ce: 0.026682
2021-11-30 12:57:24,116 iteration 1205 : loss : 0.051208, loss_ce: 0.021851
2021-11-30 12:57:25,460 iteration 1206 : loss : 0.052603, loss_ce: 0.022201
2021-11-30 12:57:26,812 iteration 1207 : loss : 0.047103, loss_ce: 0.022299
 18%|█████▎                        | 71/400 [30:05<2:21:10, 25.75s/it]2021-11-30 12:57:28,224 iteration 1208 : loss : 0.041344, loss_ce: 0.019685
2021-11-30 12:57:29,562 iteration 1209 : loss : 0.070957, loss_ce: 0.026701
2021-11-30 12:57:30,917 iteration 1210 : loss : 0.035568, loss_ce: 0.020698
2021-11-30 12:57:32,274 iteration 1211 : loss : 0.047732, loss_ce: 0.019933
2021-11-30 12:57:33,623 iteration 1212 : loss : 0.049722, loss_ce: 0.026106
2021-11-30 12:57:34,961 iteration 1213 : loss : 0.062366, loss_ce: 0.025705
2021-11-30 12:57:36,311 iteration 1214 : loss : 0.033328, loss_ce: 0.020839
2021-11-30 12:57:37,668 iteration 1215 : loss : 0.044795, loss_ce: 0.023336
2021-11-30 12:57:39,030 iteration 1216 : loss : 0.053790, loss_ce: 0.025152
2021-11-30 12:57:40,382 iteration 1217 : loss : 0.035599, loss_ce: 0.019960
2021-11-30 12:57:41,721 iteration 1218 : loss : 0.061376, loss_ce: 0.026042
2021-11-30 12:57:43,075 iteration 1219 : loss : 0.048464, loss_ce: 0.022607
2021-11-30 12:57:44,417 iteration 1220 : loss : 0.054621, loss_ce: 0.022051
2021-11-30 12:57:45,763 iteration 1221 : loss : 0.047108, loss_ce: 0.023503
2021-11-30 12:57:47,112 iteration 1222 : loss : 0.048067, loss_ce: 0.025769
2021-11-30 12:57:48,467 iteration 1223 : loss : 0.049490, loss_ce: 0.022609
2021-11-30 12:57:49,812 iteration 1224 : loss : 0.052192, loss_ce: 0.023771
 18%|█████▍                        | 72/400 [30:28<2:16:13, 24.92s/it]2021-11-30 12:57:51,221 iteration 1225 : loss : 0.059855, loss_ce: 0.026375
2021-11-30 12:57:52,570 iteration 1226 : loss : 0.049262, loss_ce: 0.022366
2021-11-30 12:57:53,921 iteration 1227 : loss : 0.038132, loss_ce: 0.020573
2021-11-30 12:57:55,263 iteration 1228 : loss : 0.049572, loss_ce: 0.020171
2021-11-30 12:57:56,620 iteration 1229 : loss : 0.046455, loss_ce: 0.022378
2021-11-30 12:57:57,967 iteration 1230 : loss : 0.040591, loss_ce: 0.020001
2021-11-30 12:57:59,321 iteration 1231 : loss : 0.051674, loss_ce: 0.023477
2021-11-30 12:58:00,675 iteration 1232 : loss : 0.043848, loss_ce: 0.022581
2021-11-30 12:58:02,027 iteration 1233 : loss : 0.044587, loss_ce: 0.025493
2021-11-30 12:58:03,385 iteration 1234 : loss : 0.053525, loss_ce: 0.024148
2021-11-30 12:58:04,723 iteration 1235 : loss : 0.036363, loss_ce: 0.019862
2021-11-30 12:58:06,074 iteration 1236 : loss : 0.052705, loss_ce: 0.026841
2021-11-30 12:58:07,416 iteration 1237 : loss : 0.040877, loss_ce: 0.020365
2021-11-30 12:58:08,770 iteration 1238 : loss : 0.047461, loss_ce: 0.021489
2021-11-30 12:58:10,126 iteration 1239 : loss : 0.051492, loss_ce: 0.024336
2021-11-30 12:58:11,470 iteration 1240 : loss : 0.050022, loss_ce: 0.022518
2021-11-30 12:58:12,833 iteration 1241 : loss : 0.038373, loss_ce: 0.022123
 18%|█████▍                        | 73/400 [30:51<2:12:42, 24.35s/it]2021-11-30 12:58:14,244 iteration 1242 : loss : 0.040123, loss_ce: 0.018014
2021-11-30 12:58:15,581 iteration 1243 : loss : 0.071218, loss_ce: 0.030455
2021-11-30 12:58:16,938 iteration 1244 : loss : 0.039863, loss_ce: 0.022661
2021-11-30 12:58:18,289 iteration 1245 : loss : 0.040416, loss_ce: 0.021867
2021-11-30 12:58:19,638 iteration 1246 : loss : 0.046702, loss_ce: 0.022724
2021-11-30 12:58:20,997 iteration 1247 : loss : 0.043907, loss_ce: 0.020591
2021-11-30 12:58:22,355 iteration 1248 : loss : 0.049668, loss_ce: 0.023472
2021-11-30 12:58:23,709 iteration 1249 : loss : 0.058074, loss_ce: 0.023193
2021-11-30 12:58:25,063 iteration 1250 : loss : 0.052763, loss_ce: 0.024697
2021-11-30 12:58:26,412 iteration 1251 : loss : 0.054314, loss_ce: 0.023125
2021-11-30 12:58:27,777 iteration 1252 : loss : 0.045839, loss_ce: 0.018754
2021-11-30 12:58:29,130 iteration 1253 : loss : 0.043023, loss_ce: 0.023052
2021-11-30 12:58:30,472 iteration 1254 : loss : 0.044802, loss_ce: 0.026927
2021-11-30 12:58:31,825 iteration 1255 : loss : 0.049248, loss_ce: 0.025537
2021-11-30 12:58:33,162 iteration 1256 : loss : 0.048118, loss_ce: 0.022020
2021-11-30 12:58:34,512 iteration 1257 : loss : 0.056226, loss_ce: 0.024703
2021-11-30 12:58:35,860 iteration 1258 : loss : 0.041224, loss_ce: 0.018922
 18%|█████▌                        | 74/400 [31:14<2:10:09, 23.96s/it]2021-11-30 12:58:37,276 iteration 1259 : loss : 0.052881, loss_ce: 0.022845
2021-11-30 12:58:38,630 iteration 1260 : loss : 0.046383, loss_ce: 0.022731
2021-11-30 12:58:39,986 iteration 1261 : loss : 0.039509, loss_ce: 0.017973
2021-11-30 12:58:41,340 iteration 1262 : loss : 0.043318, loss_ce: 0.021095
2021-11-30 12:58:42,687 iteration 1263 : loss : 0.047958, loss_ce: 0.021581
2021-11-30 12:58:44,039 iteration 1264 : loss : 0.052873, loss_ce: 0.026869
2021-11-30 12:58:45,394 iteration 1265 : loss : 0.043642, loss_ce: 0.019596
2021-11-30 12:58:46,748 iteration 1266 : loss : 0.038634, loss_ce: 0.022541
2021-11-30 12:58:48,091 iteration 1267 : loss : 0.047193, loss_ce: 0.021971
2021-11-30 12:58:49,449 iteration 1268 : loss : 0.034415, loss_ce: 0.020156
2021-11-30 12:58:50,797 iteration 1269 : loss : 0.059206, loss_ce: 0.027069
2021-11-30 12:58:52,159 iteration 1270 : loss : 0.040356, loss_ce: 0.020757
2021-11-30 12:58:53,510 iteration 1271 : loss : 0.049130, loss_ce: 0.025385
2021-11-30 12:58:54,853 iteration 1272 : loss : 0.052737, loss_ce: 0.019193
2021-11-30 12:58:56,204 iteration 1273 : loss : 0.047987, loss_ce: 0.021045
2021-11-30 12:58:57,545 iteration 1274 : loss : 0.034512, loss_ce: 0.020290
2021-11-30 12:58:57,545 Training Data Eval:
2021-11-30 12:59:05,182   Average segmentation loss on training set: 0.0424
2021-11-30 12:59:05,182 Validation Data Eval:
2021-11-30 12:59:07,814   Average segmentation loss on validation set: 0.1972
2021-11-30 12:59:09,158 iteration 1275 : loss : 0.037480, loss_ce: 0.018995
 19%|█████▋                        | 75/400 [31:47<2:24:56, 26.76s/it]2021-11-30 12:59:10,574 iteration 1276 : loss : 0.037916, loss_ce: 0.021329
2021-11-30 12:59:11,914 iteration 1277 : loss : 0.052133, loss_ce: 0.021649
2021-11-30 12:59:13,270 iteration 1278 : loss : 0.043147, loss_ce: 0.020858
2021-11-30 12:59:14,613 iteration 1279 : loss : 0.043213, loss_ce: 0.023173
2021-11-30 12:59:15,965 iteration 1280 : loss : 0.034880, loss_ce: 0.019776
2021-11-30 12:59:17,321 iteration 1281 : loss : 0.030561, loss_ce: 0.017778
2021-11-30 12:59:18,668 iteration 1282 : loss : 0.044020, loss_ce: 0.018191
2021-11-30 12:59:20,004 iteration 1283 : loss : 0.060094, loss_ce: 0.026408
2021-11-30 12:59:21,351 iteration 1284 : loss : 0.042629, loss_ce: 0.021666
2021-11-30 12:59:22,708 iteration 1285 : loss : 0.052397, loss_ce: 0.023282
2021-11-30 12:59:24,052 iteration 1286 : loss : 0.050387, loss_ce: 0.023809
2021-11-30 12:59:25,403 iteration 1287 : loss : 0.049995, loss_ce: 0.027355
2021-11-30 12:59:26,759 iteration 1288 : loss : 0.040426, loss_ce: 0.020328
2021-11-30 12:59:28,100 iteration 1289 : loss : 0.049139, loss_ce: 0.022285
2021-11-30 12:59:29,443 iteration 1290 : loss : 0.038943, loss_ce: 0.020595
2021-11-30 12:59:30,792 iteration 1291 : loss : 0.051835, loss_ce: 0.019746
2021-11-30 12:59:32,129 iteration 1292 : loss : 0.036344, loss_ce: 0.018017
 19%|█████▋                        | 76/400 [32:10<2:18:20, 25.62s/it]2021-11-30 12:59:33,535 iteration 1293 : loss : 0.044194, loss_ce: 0.019498
2021-11-30 12:59:34,875 iteration 1294 : loss : 0.039184, loss_ce: 0.018494
2021-11-30 12:59:36,230 iteration 1295 : loss : 0.051025, loss_ce: 0.021969
2021-11-30 12:59:37,588 iteration 1296 : loss : 0.040676, loss_ce: 0.019289
2021-11-30 12:59:38,939 iteration 1297 : loss : 0.050443, loss_ce: 0.026790
2021-11-30 12:59:40,294 iteration 1298 : loss : 0.059660, loss_ce: 0.029430
2021-11-30 12:59:41,645 iteration 1299 : loss : 0.037040, loss_ce: 0.019348
2021-11-30 12:59:42,992 iteration 1300 : loss : 0.055460, loss_ce: 0.021769
2021-11-30 12:59:44,351 iteration 1301 : loss : 0.040264, loss_ce: 0.023432
2021-11-30 12:59:45,701 iteration 1302 : loss : 0.044762, loss_ce: 0.019799
2021-11-30 12:59:47,056 iteration 1303 : loss : 0.038202, loss_ce: 0.020914
2021-11-30 12:59:48,404 iteration 1304 : loss : 0.040994, loss_ce: 0.020679
2021-11-30 12:59:49,754 iteration 1305 : loss : 0.056548, loss_ce: 0.023701
2021-11-30 12:59:51,110 iteration 1306 : loss : 0.036615, loss_ce: 0.017680
2021-11-30 12:59:52,452 iteration 1307 : loss : 0.044426, loss_ce: 0.023965
2021-11-30 12:59:53,795 iteration 1308 : loss : 0.034718, loss_ce: 0.017524
2021-11-30 12:59:55,147 iteration 1309 : loss : 0.053503, loss_ce: 0.024922
 19%|█████▊                        | 77/400 [32:33<2:13:43, 24.84s/it]2021-11-30 12:59:56,569 iteration 1310 : loss : 0.060165, loss_ce: 0.029656
2021-11-30 12:59:57,920 iteration 1311 : loss : 0.036543, loss_ce: 0.019132
2021-11-30 12:59:59,274 iteration 1312 : loss : 0.041030, loss_ce: 0.020407
2021-11-30 13:00:00,627 iteration 1313 : loss : 0.043224, loss_ce: 0.021040
2021-11-30 13:00:01,981 iteration 1314 : loss : 0.040693, loss_ce: 0.021443
2021-11-30 13:00:03,327 iteration 1315 : loss : 0.038177, loss_ce: 0.021636
2021-11-30 13:00:04,692 iteration 1316 : loss : 0.047821, loss_ce: 0.021067
2021-11-30 13:00:06,043 iteration 1317 : loss : 0.044378, loss_ce: 0.019488
2021-11-30 13:00:07,386 iteration 1318 : loss : 0.064781, loss_ce: 0.025351
2021-11-30 13:00:08,738 iteration 1319 : loss : 0.056067, loss_ce: 0.023276
2021-11-30 13:00:10,097 iteration 1320 : loss : 0.040754, loss_ce: 0.021574
2021-11-30 13:00:11,453 iteration 1321 : loss : 0.042690, loss_ce: 0.019338
2021-11-30 13:00:12,809 iteration 1322 : loss : 0.062239, loss_ce: 0.022953
2021-11-30 13:00:14,166 iteration 1323 : loss : 0.047487, loss_ce: 0.019539
2021-11-30 13:00:15,523 iteration 1324 : loss : 0.056915, loss_ce: 0.025360
2021-11-30 13:00:16,880 iteration 1325 : loss : 0.045486, loss_ce: 0.020064
2021-11-30 13:00:18,236 iteration 1326 : loss : 0.046128, loss_ce: 0.024451
 20%|█████▊                        | 78/400 [32:56<2:10:29, 24.31s/it]2021-11-30 13:00:19,668 iteration 1327 : loss : 0.039285, loss_ce: 0.022049
2021-11-30 13:00:21,021 iteration 1328 : loss : 0.052577, loss_ce: 0.024509
2021-11-30 13:00:22,374 iteration 1329 : loss : 0.043836, loss_ce: 0.018734
2021-11-30 13:00:23,736 iteration 1330 : loss : 0.037558, loss_ce: 0.019212
2021-11-30 13:00:25,092 iteration 1331 : loss : 0.038657, loss_ce: 0.018386
2021-11-30 13:00:26,448 iteration 1332 : loss : 0.041544, loss_ce: 0.018130
2021-11-30 13:00:27,800 iteration 1333 : loss : 0.037199, loss_ce: 0.021722
2021-11-30 13:00:29,169 iteration 1334 : loss : 0.034676, loss_ce: 0.019232
2021-11-30 13:00:30,523 iteration 1335 : loss : 0.045145, loss_ce: 0.022398
2021-11-30 13:00:31,885 iteration 1336 : loss : 0.052416, loss_ce: 0.020541
2021-11-30 13:00:33,251 iteration 1337 : loss : 0.038379, loss_ce: 0.019645
2021-11-30 13:00:34,611 iteration 1338 : loss : 0.042654, loss_ce: 0.020732
2021-11-30 13:00:35,969 iteration 1339 : loss : 0.043383, loss_ce: 0.021825
2021-11-30 13:00:37,329 iteration 1340 : loss : 0.036006, loss_ce: 0.020467
2021-11-30 13:00:38,681 iteration 1341 : loss : 0.052004, loss_ce: 0.024207
2021-11-30 13:00:40,043 iteration 1342 : loss : 0.048642, loss_ce: 0.019559
2021-11-30 13:00:41,402 iteration 1343 : loss : 0.049397, loss_ce: 0.023726
 20%|█████▉                        | 79/400 [33:20<2:08:14, 23.97s/it]2021-11-30 13:00:42,834 iteration 1344 : loss : 0.039327, loss_ce: 0.018923
2021-11-30 13:00:44,187 iteration 1345 : loss : 0.044099, loss_ce: 0.022880
2021-11-30 13:00:45,544 iteration 1346 : loss : 0.037996, loss_ce: 0.019569
2021-11-30 13:00:46,911 iteration 1347 : loss : 0.038341, loss_ce: 0.018259
2021-11-30 13:00:48,270 iteration 1348 : loss : 0.054266, loss_ce: 0.021879
2021-11-30 13:00:49,626 iteration 1349 : loss : 0.049892, loss_ce: 0.018836
2021-11-30 13:00:50,983 iteration 1350 : loss : 0.030822, loss_ce: 0.016561
2021-11-30 13:00:52,344 iteration 1351 : loss : 0.052574, loss_ce: 0.018617
2021-11-30 13:00:53,703 iteration 1352 : loss : 0.041731, loss_ce: 0.020660
2021-11-30 13:00:55,060 iteration 1353 : loss : 0.035505, loss_ce: 0.015692
2021-11-30 13:00:56,415 iteration 1354 : loss : 0.036016, loss_ce: 0.019118
2021-11-30 13:00:57,782 iteration 1355 : loss : 0.047364, loss_ce: 0.024983
2021-11-30 13:00:59,133 iteration 1356 : loss : 0.040957, loss_ce: 0.023989
2021-11-30 13:01:00,484 iteration 1357 : loss : 0.049221, loss_ce: 0.024872
2021-11-30 13:01:01,841 iteration 1358 : loss : 0.042388, loss_ce: 0.019065
2021-11-30 13:01:03,197 iteration 1359 : loss : 0.038029, loss_ce: 0.019503
2021-11-30 13:01:03,197 Training Data Eval:
2021-11-30 13:01:10,849   Average segmentation loss on training set: 0.0396
2021-11-30 13:01:10,849 Validation Data Eval:
2021-11-30 13:01:13,481   Average segmentation loss on validation set: 0.1458
2021-11-30 13:01:14,822 iteration 1360 : loss : 0.040735, loss_ce: 0.021314
 20%|██████                        | 80/400 [33:53<2:22:57, 26.81s/it]2021-11-30 13:01:16,237 iteration 1361 : loss : 0.044503, loss_ce: 0.019260
2021-11-30 13:01:17,589 iteration 1362 : loss : 0.054383, loss_ce: 0.021719
2021-11-30 13:01:18,948 iteration 1363 : loss : 0.036918, loss_ce: 0.017017
2021-11-30 13:01:20,292 iteration 1364 : loss : 0.035157, loss_ce: 0.018227
2021-11-30 13:01:21,651 iteration 1365 : loss : 0.030596, loss_ce: 0.017886
2021-11-30 13:01:22,991 iteration 1366 : loss : 0.037331, loss_ce: 0.019818
2021-11-30 13:01:24,340 iteration 1367 : loss : 0.098733, loss_ce: 0.040554
2021-11-30 13:01:25,691 iteration 1368 : loss : 0.042630, loss_ce: 0.021137
2021-11-30 13:01:27,036 iteration 1369 : loss : 0.055525, loss_ce: 0.020147
2021-11-30 13:01:28,397 iteration 1370 : loss : 0.032282, loss_ce: 0.017110
2021-11-30 13:01:29,763 iteration 1371 : loss : 0.038714, loss_ce: 0.019559
2021-11-30 13:01:31,103 iteration 1372 : loss : 0.043848, loss_ce: 0.022062
2021-11-30 13:01:32,445 iteration 1373 : loss : 0.044150, loss_ce: 0.021060
2021-11-30 13:01:33,800 iteration 1374 : loss : 0.046321, loss_ce: 0.022944
2021-11-30 13:01:35,152 iteration 1375 : loss : 0.037434, loss_ce: 0.021296
2021-11-30 13:01:36,498 iteration 1376 : loss : 0.051873, loss_ce: 0.025446
2021-11-30 13:01:37,854 iteration 1377 : loss : 0.041427, loss_ce: 0.021374
 20%|██████                        | 81/400 [34:16<2:16:29, 25.67s/it]2021-11-30 13:01:39,252 iteration 1378 : loss : 0.040639, loss_ce: 0.020338
2021-11-30 13:01:40,590 iteration 1379 : loss : 0.037737, loss_ce: 0.019943
2021-11-30 13:01:41,951 iteration 1380 : loss : 0.047382, loss_ce: 0.024382
2021-11-30 13:01:43,298 iteration 1381 : loss : 0.038671, loss_ce: 0.018087
2021-11-30 13:01:44,639 iteration 1382 : loss : 0.027489, loss_ce: 0.016559
2021-11-30 13:01:45,991 iteration 1383 : loss : 0.039527, loss_ce: 0.021956
2021-11-30 13:01:47,333 iteration 1384 : loss : 0.056316, loss_ce: 0.019216
2021-11-30 13:01:48,687 iteration 1385 : loss : 0.028360, loss_ce: 0.015493
2021-11-30 13:01:50,035 iteration 1386 : loss : 0.057234, loss_ce: 0.022269
2021-11-30 13:01:51,374 iteration 1387 : loss : 0.031238, loss_ce: 0.019747
2021-11-30 13:01:52,728 iteration 1388 : loss : 0.033384, loss_ce: 0.018808
2021-11-30 13:01:54,076 iteration 1389 : loss : 0.037921, loss_ce: 0.015227
2021-11-30 13:01:55,437 iteration 1390 : loss : 0.037689, loss_ce: 0.019274
2021-11-30 13:01:56,784 iteration 1391 : loss : 0.058153, loss_ce: 0.021196
2021-11-30 13:01:58,138 iteration 1392 : loss : 0.034387, loss_ce: 0.019720
2021-11-30 13:01:59,497 iteration 1393 : loss : 0.042419, loss_ce: 0.020026
2021-11-30 13:02:00,853 iteration 1394 : loss : 0.041682, loss_ce: 0.022376
 20%|██████▏                       | 82/400 [34:39<2:11:49, 24.87s/it]2021-11-30 13:02:02,281 iteration 1395 : loss : 0.046081, loss_ce: 0.020625
2021-11-30 13:02:03,636 iteration 1396 : loss : 0.035002, loss_ce: 0.018540
2021-11-30 13:02:04,993 iteration 1397 : loss : 0.041637, loss_ce: 0.021457
2021-11-30 13:02:06,342 iteration 1398 : loss : 0.035347, loss_ce: 0.019104
2021-11-30 13:02:07,696 iteration 1399 : loss : 0.052664, loss_ce: 0.022780
2021-11-30 13:02:09,055 iteration 1400 : loss : 0.039955, loss_ce: 0.020446
2021-11-30 13:02:10,409 iteration 1401 : loss : 0.039640, loss_ce: 0.019442
2021-11-30 13:02:11,753 iteration 1402 : loss : 0.044365, loss_ce: 0.021396
2021-11-30 13:02:13,099 iteration 1403 : loss : 0.059860, loss_ce: 0.019702
2021-11-30 13:02:14,437 iteration 1404 : loss : 0.034663, loss_ce: 0.017834
2021-11-30 13:02:15,783 iteration 1405 : loss : 0.037188, loss_ce: 0.020080
2021-11-30 13:02:17,146 iteration 1406 : loss : 0.036246, loss_ce: 0.018995
2021-11-30 13:02:18,499 iteration 1407 : loss : 0.050178, loss_ce: 0.021377
2021-11-30 13:02:19,850 iteration 1408 : loss : 0.036239, loss_ce: 0.017860
2021-11-30 13:02:21,197 iteration 1409 : loss : 0.031845, loss_ce: 0.017052
2021-11-30 13:02:22,547 iteration 1410 : loss : 0.033199, loss_ce: 0.018692
2021-11-30 13:02:23,906 iteration 1411 : loss : 0.039803, loss_ce: 0.018313
 21%|██████▏                       | 83/400 [35:02<2:08:30, 24.32s/it]2021-11-30 13:02:25,312 iteration 1412 : loss : 0.041209, loss_ce: 0.018121
2021-11-30 13:02:26,666 iteration 1413 : loss : 0.036874, loss_ce: 0.021377
2021-11-30 13:02:28,020 iteration 1414 : loss : 0.039226, loss_ce: 0.017174
2021-11-30 13:02:29,366 iteration 1415 : loss : 0.034467, loss_ce: 0.018258
2021-11-30 13:02:30,705 iteration 1416 : loss : 0.036329, loss_ce: 0.018310
2021-11-30 13:02:32,058 iteration 1417 : loss : 0.027194, loss_ce: 0.016061
2021-11-30 13:02:33,409 iteration 1418 : loss : 0.035233, loss_ce: 0.019581
2021-11-30 13:02:34,770 iteration 1419 : loss : 0.033458, loss_ce: 0.018311
2021-11-30 13:02:36,116 iteration 1420 : loss : 0.030695, loss_ce: 0.017870
2021-11-30 13:02:37,468 iteration 1421 : loss : 0.037169, loss_ce: 0.021074
2021-11-30 13:02:38,818 iteration 1422 : loss : 0.037671, loss_ce: 0.022177
2021-11-30 13:02:40,171 iteration 1423 : loss : 0.034435, loss_ce: 0.017915
2021-11-30 13:02:41,529 iteration 1424 : loss : 0.042783, loss_ce: 0.020196
2021-11-30 13:02:42,869 iteration 1425 : loss : 0.061176, loss_ce: 0.027969
2021-11-30 13:02:44,209 iteration 1426 : loss : 0.042975, loss_ce: 0.018048
2021-11-30 13:02:45,565 iteration 1427 : loss : 0.141210, loss_ce: 0.023774
2021-11-30 13:02:46,915 iteration 1428 : loss : 0.036397, loss_ce: 0.020725
 21%|██████▎                       | 84/400 [35:25<2:06:01, 23.93s/it]2021-11-30 13:02:48,339 iteration 1429 : loss : 0.035456, loss_ce: 0.019926
2021-11-30 13:02:49,691 iteration 1430 : loss : 0.069743, loss_ce: 0.034059
2021-11-30 13:02:51,040 iteration 1431 : loss : 0.052725, loss_ce: 0.021488
2021-11-30 13:02:52,385 iteration 1432 : loss : 0.040618, loss_ce: 0.018446
2021-11-30 13:02:53,723 iteration 1433 : loss : 0.032914, loss_ce: 0.017884
2021-11-30 13:02:55,076 iteration 1434 : loss : 0.041642, loss_ce: 0.018087
2021-11-30 13:02:56,433 iteration 1435 : loss : 0.038428, loss_ce: 0.018196
2021-11-30 13:02:57,779 iteration 1436 : loss : 0.045764, loss_ce: 0.023114
2021-11-30 13:02:59,147 iteration 1437 : loss : 0.037805, loss_ce: 0.017328
2021-11-30 13:03:00,504 iteration 1438 : loss : 0.042374, loss_ce: 0.018841
2021-11-30 13:03:01,847 iteration 1439 : loss : 0.033181, loss_ce: 0.018504
2021-11-30 13:03:03,205 iteration 1440 : loss : 0.029739, loss_ce: 0.016495
2021-11-30 13:03:04,549 iteration 1441 : loss : 0.034233, loss_ce: 0.015680
2021-11-30 13:03:05,912 iteration 1442 : loss : 0.039995, loss_ce: 0.023057
2021-11-30 13:03:07,265 iteration 1443 : loss : 0.052930, loss_ce: 0.019409
2021-11-30 13:03:08,612 iteration 1444 : loss : 0.030820, loss_ce: 0.016821
2021-11-30 13:03:08,612 Training Data Eval:
2021-11-30 13:03:16,241   Average segmentation loss on training set: 0.0384
2021-11-30 13:03:16,241 Validation Data Eval:
2021-11-30 13:03:18,863   Average segmentation loss on validation set: 0.2022
2021-11-30 13:03:20,208 iteration 1445 : loss : 0.043130, loss_ce: 0.018358
 21%|██████▍                       | 85/400 [35:58<2:20:22, 26.74s/it]2021-11-30 13:03:21,637 iteration 1446 : loss : 0.029282, loss_ce: 0.016710
2021-11-30 13:03:22,982 iteration 1447 : loss : 0.048761, loss_ce: 0.017403
2021-11-30 13:03:24,341 iteration 1448 : loss : 0.050262, loss_ce: 0.019752
2021-11-30 13:03:25,701 iteration 1449 : loss : 0.026932, loss_ce: 0.015352
2021-11-30 13:03:27,045 iteration 1450 : loss : 0.037426, loss_ce: 0.020274
2021-11-30 13:03:28,402 iteration 1451 : loss : 0.041458, loss_ce: 0.016065
2021-11-30 13:03:29,747 iteration 1452 : loss : 0.031791, loss_ce: 0.015796
2021-11-30 13:03:31,104 iteration 1453 : loss : 0.035856, loss_ce: 0.019869
2021-11-30 13:03:32,439 iteration 1454 : loss : 0.034865, loss_ce: 0.017310
2021-11-30 13:03:33,782 iteration 1455 : loss : 0.036852, loss_ce: 0.022725
2021-11-30 13:03:35,135 iteration 1456 : loss : 0.043653, loss_ce: 0.017677
2021-11-30 13:03:36,481 iteration 1457 : loss : 0.047887, loss_ce: 0.020499
2021-11-30 13:03:37,835 iteration 1458 : loss : 0.037419, loss_ce: 0.020545
2021-11-30 13:03:39,192 iteration 1459 : loss : 0.035882, loss_ce: 0.021485
2021-11-30 13:03:40,548 iteration 1460 : loss : 0.038224, loss_ce: 0.018952
2021-11-30 13:03:41,906 iteration 1461 : loss : 0.045547, loss_ce: 0.021990
2021-11-30 13:03:43,258 iteration 1462 : loss : 0.034689, loss_ce: 0.016893
 22%|██████▍                       | 86/400 [36:21<2:14:08, 25.63s/it]2021-11-30 13:03:44,676 iteration 1463 : loss : 0.034130, loss_ce: 0.016009
2021-11-30 13:03:46,034 iteration 1464 : loss : 0.033572, loss_ce: 0.018830
2021-11-30 13:03:47,383 iteration 1465 : loss : 0.038064, loss_ce: 0.019330
2021-11-30 13:03:48,739 iteration 1466 : loss : 0.032204, loss_ce: 0.016450
2021-11-30 13:03:50,093 iteration 1467 : loss : 0.049262, loss_ce: 0.020254
2021-11-30 13:03:51,435 iteration 1468 : loss : 0.035605, loss_ce: 0.019269
2021-11-30 13:03:52,793 iteration 1469 : loss : 0.052449, loss_ce: 0.025871
2021-11-30 13:03:54,149 iteration 1470 : loss : 0.042746, loss_ce: 0.019963
2021-11-30 13:03:55,504 iteration 1471 : loss : 0.034043, loss_ce: 0.017982
2021-11-30 13:03:56,864 iteration 1472 : loss : 0.025610, loss_ce: 0.015813
2021-11-30 13:03:58,223 iteration 1473 : loss : 0.037292, loss_ce: 0.019142
2021-11-30 13:03:59,577 iteration 1474 : loss : 0.030176, loss_ce: 0.015911
2021-11-30 13:04:00,938 iteration 1475 : loss : 0.036873, loss_ce: 0.021300
2021-11-30 13:04:02,296 iteration 1476 : loss : 0.044113, loss_ce: 0.018803
2021-11-30 13:04:03,656 iteration 1477 : loss : 0.041172, loss_ce: 0.016657
2021-11-30 13:04:05,012 iteration 1478 : loss : 0.032139, loss_ce: 0.016339
2021-11-30 13:04:06,373 iteration 1479 : loss : 0.035159, loss_ce: 0.017460
 22%|██████▌                       | 87/400 [36:44<2:09:46, 24.88s/it]2021-11-30 13:04:07,801 iteration 1480 : loss : 0.033082, loss_ce: 0.017720
2021-11-30 13:04:09,165 iteration 1481 : loss : 0.028651, loss_ce: 0.014827
2021-11-30 13:04:10,525 iteration 1482 : loss : 0.033794, loss_ce: 0.018755
2021-11-30 13:04:11,883 iteration 1483 : loss : 0.035690, loss_ce: 0.018882
2021-11-30 13:04:13,243 iteration 1484 : loss : 0.041660, loss_ce: 0.022910
2021-11-30 13:04:14,603 iteration 1485 : loss : 0.030530, loss_ce: 0.018443
2021-11-30 13:04:15,960 iteration 1486 : loss : 0.041097, loss_ce: 0.023580
2021-11-30 13:04:17,324 iteration 1487 : loss : 0.035577, loss_ce: 0.016023
2021-11-30 13:04:18,691 iteration 1488 : loss : 0.036411, loss_ce: 0.017150
2021-11-30 13:04:20,047 iteration 1489 : loss : 0.052425, loss_ce: 0.020741
2021-11-30 13:04:21,412 iteration 1490 : loss : 0.036619, loss_ce: 0.017158
2021-11-30 13:04:22,774 iteration 1491 : loss : 0.036762, loss_ce: 0.021053
2021-11-30 13:04:24,131 iteration 1492 : loss : 0.042754, loss_ce: 0.018796
2021-11-30 13:04:25,491 iteration 1493 : loss : 0.047837, loss_ce: 0.019996
2021-11-30 13:04:26,850 iteration 1494 : loss : 0.042618, loss_ce: 0.019497
2021-11-30 13:04:28,213 iteration 1495 : loss : 0.034015, loss_ce: 0.017002
2021-11-30 13:04:29,568 iteration 1496 : loss : 0.116989, loss_ce: 0.027618
 22%|██████▌                       | 88/400 [37:08<2:06:44, 24.37s/it]2021-11-30 13:04:30,994 iteration 1497 : loss : 0.054994, loss_ce: 0.018924
2021-11-30 13:04:32,349 iteration 1498 : loss : 0.034280, loss_ce: 0.015913
2021-11-30 13:04:33,705 iteration 1499 : loss : 0.046703, loss_ce: 0.022007
2021-11-30 13:04:35,061 iteration 1500 : loss : 0.036432, loss_ce: 0.019940
2021-11-30 13:04:36,419 iteration 1501 : loss : 0.031701, loss_ce: 0.017224
2021-11-30 13:04:37,775 iteration 1502 : loss : 0.050300, loss_ce: 0.016232
2021-11-30 13:04:39,131 iteration 1503 : loss : 0.035077, loss_ce: 0.015170
2021-11-30 13:04:40,489 iteration 1504 : loss : 0.044507, loss_ce: 0.020795
2021-11-30 13:04:41,844 iteration 1505 : loss : 0.032784, loss_ce: 0.015821
2021-11-30 13:04:43,203 iteration 1506 : loss : 0.030408, loss_ce: 0.017393
2021-11-30 13:04:44,561 iteration 1507 : loss : 0.037662, loss_ce: 0.024035
2021-11-30 13:04:45,923 iteration 1508 : loss : 0.031628, loss_ce: 0.015390
2021-11-30 13:04:47,287 iteration 1509 : loss : 0.028852, loss_ce: 0.015284
2021-11-30 13:04:48,641 iteration 1510 : loss : 0.034003, loss_ce: 0.016822
2021-11-30 13:04:49,995 iteration 1511 : loss : 0.036930, loss_ce: 0.019374
2021-11-30 13:04:51,353 iteration 1512 : loss : 0.038025, loss_ce: 0.022578
2021-11-30 13:04:52,703 iteration 1513 : loss : 0.039365, loss_ce: 0.017384
 22%|██████▋                       | 89/400 [37:31<2:04:24, 24.00s/it]2021-11-30 13:04:54,124 iteration 1514 : loss : 0.046060, loss_ce: 0.019856
2021-11-30 13:04:55,468 iteration 1515 : loss : 0.035474, loss_ce: 0.019291
2021-11-30 13:04:56,828 iteration 1516 : loss : 0.041860, loss_ce: 0.019580
2021-11-30 13:04:58,180 iteration 1517 : loss : 0.045063, loss_ce: 0.019768
2021-11-30 13:04:59,541 iteration 1518 : loss : 0.048728, loss_ce: 0.020973
2021-11-30 13:05:00,892 iteration 1519 : loss : 0.043693, loss_ce: 0.020961
2021-11-30 13:05:02,239 iteration 1520 : loss : 0.040320, loss_ce: 0.019438
2021-11-30 13:05:03,577 iteration 1521 : loss : 0.034786, loss_ce: 0.019765
2021-11-30 13:05:04,921 iteration 1522 : loss : 0.035349, loss_ce: 0.017971
2021-11-30 13:05:06,272 iteration 1523 : loss : 0.035742, loss_ce: 0.017392
2021-11-30 13:05:07,634 iteration 1524 : loss : 0.041707, loss_ce: 0.020425
2021-11-30 13:05:08,993 iteration 1525 : loss : 0.038401, loss_ce: 0.021641
2021-11-30 13:05:10,342 iteration 1526 : loss : 0.036104, loss_ce: 0.019040
2021-11-30 13:05:11,705 iteration 1527 : loss : 0.034716, loss_ce: 0.016971
2021-11-30 13:05:13,065 iteration 1528 : loss : 0.032536, loss_ce: 0.015619
2021-11-30 13:05:14,418 iteration 1529 : loss : 0.035351, loss_ce: 0.019167
2021-11-30 13:05:14,418 Training Data Eval:
2021-11-30 13:05:22,072   Average segmentation loss on training set: 0.0333
2021-11-30 13:05:22,072 Validation Data Eval:
2021-11-30 13:05:24,721   Average segmentation loss on validation set: 0.1609
2021-11-30 13:05:26,071 iteration 1530 : loss : 0.039449, loss_ce: 0.017751
 22%|██████▊                       | 90/400 [38:04<2:18:31, 26.81s/it]2021-11-30 13:05:27,503 iteration 1531 : loss : 0.032587, loss_ce: 0.018092
2021-11-30 13:05:28,859 iteration 1532 : loss : 0.027107, loss_ce: 0.014885
2021-11-30 13:05:30,219 iteration 1533 : loss : 0.030225, loss_ce: 0.016304
2021-11-30 13:05:31,577 iteration 1534 : loss : 0.031416, loss_ce: 0.018020
2021-11-30 13:05:32,931 iteration 1535 : loss : 0.030629, loss_ce: 0.017598
2021-11-30 13:05:34,287 iteration 1536 : loss : 0.036774, loss_ce: 0.019590
2021-11-30 13:05:35,643 iteration 1537 : loss : 0.046521, loss_ce: 0.020755
2021-11-30 13:05:37,001 iteration 1538 : loss : 0.032473, loss_ce: 0.016878
2021-11-30 13:05:38,358 iteration 1539 : loss : 0.025444, loss_ce: 0.015213
2021-11-30 13:05:39,722 iteration 1540 : loss : 0.029408, loss_ce: 0.016259
2021-11-30 13:05:41,075 iteration 1541 : loss : 0.037286, loss_ce: 0.020026
2021-11-30 13:05:42,421 iteration 1542 : loss : 0.034341, loss_ce: 0.016311
2021-11-30 13:05:43,779 iteration 1543 : loss : 0.039313, loss_ce: 0.017982
2021-11-30 13:05:45,132 iteration 1544 : loss : 0.033252, loss_ce: 0.015699
2021-11-30 13:05:46,490 iteration 1545 : loss : 0.038156, loss_ce: 0.017367
2021-11-30 13:05:47,838 iteration 1546 : loss : 0.047347, loss_ce: 0.021559
2021-11-30 13:05:49,181 iteration 1547 : loss : 0.031564, loss_ce: 0.015201
 23%|██████▊                       | 91/400 [38:27<2:12:21, 25.70s/it]2021-11-30 13:05:50,592 iteration 1548 : loss : 0.031328, loss_ce: 0.013028
2021-11-30 13:05:51,936 iteration 1549 : loss : 0.025801, loss_ce: 0.012942
2021-11-30 13:05:53,281 iteration 1550 : loss : 0.039482, loss_ce: 0.016451
2021-11-30 13:05:54,638 iteration 1551 : loss : 0.029860, loss_ce: 0.018602
2021-11-30 13:05:55,988 iteration 1552 : loss : 0.031168, loss_ce: 0.015353
2021-11-30 13:05:57,341 iteration 1553 : loss : 0.038830, loss_ce: 0.017507
2021-11-30 13:05:58,679 iteration 1554 : loss : 0.045558, loss_ce: 0.020658
2021-11-30 13:06:00,023 iteration 1555 : loss : 0.036553, loss_ce: 0.017496
2021-11-30 13:06:01,365 iteration 1556 : loss : 0.023899, loss_ce: 0.013975
2021-11-30 13:06:02,713 iteration 1557 : loss : 0.034770, loss_ce: 0.017179
2021-11-30 13:06:04,069 iteration 1558 : loss : 0.031461, loss_ce: 0.017297
2021-11-30 13:06:05,411 iteration 1559 : loss : 0.048444, loss_ce: 0.021536
2021-11-30 13:06:06,761 iteration 1560 : loss : 0.027991, loss_ce: 0.013937
2021-11-30 13:06:08,110 iteration 1561 : loss : 0.032340, loss_ce: 0.018381
2021-11-30 13:06:09,458 iteration 1562 : loss : 0.039457, loss_ce: 0.021985
2021-11-30 13:06:10,814 iteration 1563 : loss : 0.028485, loss_ce: 0.017230
2021-11-30 13:06:12,158 iteration 1564 : loss : 0.043651, loss_ce: 0.021976
 23%|██████▉                       | 92/400 [38:50<2:07:43, 24.88s/it]2021-11-30 13:06:13,576 iteration 1565 : loss : 0.028575, loss_ce: 0.015615
2021-11-30 13:06:14,934 iteration 1566 : loss : 0.037155, loss_ce: 0.020938
2021-11-30 13:06:16,277 iteration 1567 : loss : 0.028747, loss_ce: 0.015480
2021-11-30 13:06:17,620 iteration 1568 : loss : 0.033856, loss_ce: 0.019647
2021-11-30 13:06:18,970 iteration 1569 : loss : 0.046702, loss_ce: 0.021131
2021-11-30 13:06:20,324 iteration 1570 : loss : 0.045844, loss_ce: 0.018639
2021-11-30 13:06:21,679 iteration 1571 : loss : 0.026045, loss_ce: 0.015910
2021-11-30 13:06:23,021 iteration 1572 : loss : 0.025177, loss_ce: 0.015736
2021-11-30 13:06:24,373 iteration 1573 : loss : 0.050146, loss_ce: 0.017248
2021-11-30 13:06:25,719 iteration 1574 : loss : 0.029311, loss_ce: 0.015538
2021-11-30 13:06:27,077 iteration 1575 : loss : 0.032045, loss_ce: 0.014770
2021-11-30 13:06:28,417 iteration 1576 : loss : 0.029923, loss_ce: 0.016514
2021-11-30 13:06:29,764 iteration 1577 : loss : 0.034437, loss_ce: 0.018526
2021-11-30 13:06:31,121 iteration 1578 : loss : 0.029941, loss_ce: 0.016456
2021-11-30 13:06:32,469 iteration 1579 : loss : 0.029215, loss_ce: 0.016760
2021-11-30 13:06:33,797 iteration 1580 : loss : 0.034996, loss_ce: 0.016093
2021-11-30 13:06:35,141 iteration 1581 : loss : 0.051133, loss_ce: 0.016201
 23%|██████▉                       | 93/400 [39:13<2:04:24, 24.31s/it]2021-11-30 13:06:36,547 iteration 1582 : loss : 0.038545, loss_ce: 0.018294
2021-11-30 13:06:37,880 iteration 1583 : loss : 0.028994, loss_ce: 0.015571
2021-11-30 13:06:39,227 iteration 1584 : loss : 0.026761, loss_ce: 0.014725
2021-11-30 13:06:40,576 iteration 1585 : loss : 0.044595, loss_ce: 0.020049
2021-11-30 13:06:41,914 iteration 1586 : loss : 0.055002, loss_ce: 0.025002
2021-11-30 13:06:43,256 iteration 1587 : loss : 0.046116, loss_ce: 0.027322
2021-11-30 13:06:44,595 iteration 1588 : loss : 0.033262, loss_ce: 0.015183
2021-11-30 13:06:45,936 iteration 1589 : loss : 0.031818, loss_ce: 0.016858
2021-11-30 13:06:47,294 iteration 1590 : loss : 0.030994, loss_ce: 0.015469
2021-11-30 13:06:48,646 iteration 1591 : loss : 0.067958, loss_ce: 0.020486
2021-11-30 13:06:49,983 iteration 1592 : loss : 0.039539, loss_ce: 0.020469
2021-11-30 13:06:51,329 iteration 1593 : loss : 0.042483, loss_ce: 0.018776
2021-11-30 13:06:52,695 iteration 1594 : loss : 0.026880, loss_ce: 0.015832
2021-11-30 13:06:54,056 iteration 1595 : loss : 0.031235, loss_ce: 0.017445
2021-11-30 13:06:55,409 iteration 1596 : loss : 0.029991, loss_ce: 0.017568
2021-11-30 13:06:56,750 iteration 1597 : loss : 0.038531, loss_ce: 0.019400
2021-11-30 13:06:58,088 iteration 1598 : loss : 0.043587, loss_ce: 0.018364
 24%|███████                       | 94/400 [39:36<2:01:54, 23.90s/it]2021-11-30 13:06:59,502 iteration 1599 : loss : 0.048365, loss_ce: 0.020088
2021-11-30 13:07:00,861 iteration 1600 : loss : 0.027684, loss_ce: 0.016376
2021-11-30 13:07:02,202 iteration 1601 : loss : 0.026904, loss_ce: 0.014779
2021-11-30 13:07:03,559 iteration 1602 : loss : 0.042274, loss_ce: 0.018432
2021-11-30 13:07:04,915 iteration 1603 : loss : 0.034012, loss_ce: 0.018001
2021-11-30 13:07:06,270 iteration 1604 : loss : 0.037669, loss_ce: 0.018421
2021-11-30 13:07:07,621 iteration 1605 : loss : 0.027625, loss_ce: 0.017492
2021-11-30 13:07:08,979 iteration 1606 : loss : 0.026448, loss_ce: 0.015442
2021-11-30 13:07:10,341 iteration 1607 : loss : 0.035100, loss_ce: 0.017074
2021-11-30 13:07:11,686 iteration 1608 : loss : 0.027986, loss_ce: 0.015224
2021-11-30 13:07:13,036 iteration 1609 : loss : 0.036259, loss_ce: 0.017305
2021-11-30 13:07:14,384 iteration 1610 : loss : 0.032291, loss_ce: 0.015034
2021-11-30 13:07:15,741 iteration 1611 : loss : 0.037670, loss_ce: 0.017419
2021-11-30 13:07:17,092 iteration 1612 : loss : 0.042681, loss_ce: 0.016213
2021-11-30 13:07:18,441 iteration 1613 : loss : 0.038796, loss_ce: 0.019732
2021-11-30 13:07:19,792 iteration 1614 : loss : 0.039129, loss_ce: 0.015644
2021-11-30 13:07:19,792 Training Data Eval:
2021-11-30 13:07:27,390   Average segmentation loss on training set: 0.0452
2021-11-30 13:07:27,391 Validation Data Eval:
2021-11-30 13:07:30,042   Average segmentation loss on validation set: 0.2240
2021-11-30 13:07:31,386 iteration 1615 : loss : 0.030322, loss_ce: 0.016065
 24%|███████▏                      | 95/400 [40:10<2:15:50, 26.72s/it]2021-11-30 13:07:32,803 iteration 1616 : loss : 0.033376, loss_ce: 0.015593
2021-11-30 13:07:34,167 iteration 1617 : loss : 0.048265, loss_ce: 0.022751
2021-11-30 13:07:35,522 iteration 1618 : loss : 0.031441, loss_ce: 0.017101
2021-11-30 13:07:36,881 iteration 1619 : loss : 0.035510, loss_ce: 0.015228
2021-11-30 13:07:38,228 iteration 1620 : loss : 0.032049, loss_ce: 0.016280
2021-11-30 13:07:39,570 iteration 1621 : loss : 0.028201, loss_ce: 0.015148
2021-11-30 13:07:40,933 iteration 1622 : loss : 0.025777, loss_ce: 0.014369
2021-11-30 13:07:42,284 iteration 1623 : loss : 0.027227, loss_ce: 0.016167
2021-11-30 13:07:43,634 iteration 1624 : loss : 0.029539, loss_ce: 0.016831
2021-11-30 13:07:44,981 iteration 1625 : loss : 0.068758, loss_ce: 0.019222
2021-11-30 13:07:46,324 iteration 1626 : loss : 0.029374, loss_ce: 0.017258
2021-11-30 13:07:47,683 iteration 1627 : loss : 0.034016, loss_ce: 0.017538
2021-11-30 13:07:49,032 iteration 1628 : loss : 0.026096, loss_ce: 0.015056
2021-11-30 13:07:50,395 iteration 1629 : loss : 0.028939, loss_ce: 0.015294
2021-11-30 13:07:51,742 iteration 1630 : loss : 0.029791, loss_ce: 0.015341
2021-11-30 13:07:53,075 iteration 1631 : loss : 0.028622, loss_ce: 0.016240
2021-11-30 13:07:54,433 iteration 1632 : loss : 0.041033, loss_ce: 0.021637
 24%|███████▏                      | 96/400 [40:33<2:09:48, 25.62s/it]2021-11-30 13:07:55,847 iteration 1633 : loss : 0.031136, loss_ce: 0.014655
2021-11-30 13:07:57,181 iteration 1634 : loss : 0.026184, loss_ce: 0.015670
2021-11-30 13:07:58,534 iteration 1635 : loss : 0.024662, loss_ce: 0.012826
2021-11-30 13:07:59,884 iteration 1636 : loss : 0.030103, loss_ce: 0.016103
2021-11-30 13:08:01,240 iteration 1637 : loss : 0.035685, loss_ce: 0.014569
2021-11-30 13:08:02,595 iteration 1638 : loss : 0.029691, loss_ce: 0.017149
2021-11-30 13:08:03,951 iteration 1639 : loss : 0.031623, loss_ce: 0.017961
2021-11-30 13:08:05,301 iteration 1640 : loss : 0.027858, loss_ce: 0.015813
2021-11-30 13:08:06,642 iteration 1641 : loss : 0.041065, loss_ce: 0.024238
2021-11-30 13:08:07,994 iteration 1642 : loss : 0.031042, loss_ce: 0.015809
2021-11-30 13:08:09,333 iteration 1643 : loss : 0.027548, loss_ce: 0.014483
2021-11-30 13:08:10,681 iteration 1644 : loss : 0.032475, loss_ce: 0.017938
2021-11-30 13:08:12,035 iteration 1645 : loss : 0.032544, loss_ce: 0.016641
2021-11-30 13:08:13,377 iteration 1646 : loss : 0.026859, loss_ce: 0.015562
2021-11-30 13:08:14,739 iteration 1647 : loss : 0.038777, loss_ce: 0.016641
2021-11-30 13:08:16,099 iteration 1648 : loss : 0.037928, loss_ce: 0.019409
2021-11-30 13:08:17,447 iteration 1649 : loss : 0.024959, loss_ce: 0.014286
 24%|███████▎                      | 97/400 [40:56<2:05:26, 24.84s/it]2021-11-30 13:08:18,870 iteration 1650 : loss : 0.035600, loss_ce: 0.015691
2021-11-30 13:08:20,226 iteration 1651 : loss : 0.032745, loss_ce: 0.017079
2021-11-30 13:08:21,569 iteration 1652 : loss : 0.031740, loss_ce: 0.016528
2021-11-30 13:08:22,922 iteration 1653 : loss : 0.026897, loss_ce: 0.015717
2021-11-30 13:08:24,272 iteration 1654 : loss : 0.029765, loss_ce: 0.016167
2021-11-30 13:08:25,625 iteration 1655 : loss : 0.027505, loss_ce: 0.014562
2021-11-30 13:08:26,975 iteration 1656 : loss : 0.036093, loss_ce: 0.018167
2021-11-30 13:08:28,319 iteration 1657 : loss : 0.024426, loss_ce: 0.013631
2021-11-30 13:08:29,675 iteration 1658 : loss : 0.025247, loss_ce: 0.014450
2021-11-30 13:08:31,017 iteration 1659 : loss : 0.034555, loss_ce: 0.016024
2021-11-30 13:08:32,374 iteration 1660 : loss : 0.032110, loss_ce: 0.015522
2021-11-30 13:08:33,724 iteration 1661 : loss : 0.028228, loss_ce: 0.014573
2021-11-30 13:08:35,072 iteration 1662 : loss : 0.028279, loss_ce: 0.019088
2021-11-30 13:08:36,413 iteration 1663 : loss : 0.024100, loss_ce: 0.013289
2021-11-30 13:08:37,759 iteration 1664 : loss : 0.034149, loss_ce: 0.019876
2021-11-30 13:08:39,110 iteration 1665 : loss : 0.029149, loss_ce: 0.013402
2021-11-30 13:08:40,458 iteration 1666 : loss : 0.033155, loss_ce: 0.018683
 24%|███████▎                      | 98/400 [41:19<2:02:15, 24.29s/it]2021-11-30 13:08:41,865 iteration 1667 : loss : 0.026257, loss_ce: 0.014030
2021-11-30 13:08:43,216 iteration 1668 : loss : 0.028132, loss_ce: 0.015013
2021-11-30 13:08:44,561 iteration 1669 : loss : 0.025534, loss_ce: 0.014537
2021-11-30 13:08:45,900 iteration 1670 : loss : 0.033265, loss_ce: 0.015735
2021-11-30 13:08:47,236 iteration 1671 : loss : 0.024334, loss_ce: 0.013487
2021-11-30 13:08:48,579 iteration 1672 : loss : 0.030814, loss_ce: 0.014914
2021-11-30 13:08:49,932 iteration 1673 : loss : 0.035977, loss_ce: 0.020544
2021-11-30 13:08:51,276 iteration 1674 : loss : 0.025571, loss_ce: 0.015065
2021-11-30 13:08:52,640 iteration 1675 : loss : 0.032348, loss_ce: 0.013802
2021-11-30 13:08:53,994 iteration 1676 : loss : 0.024599, loss_ce: 0.014447
2021-11-30 13:08:55,343 iteration 1677 : loss : 0.034388, loss_ce: 0.016754
2021-11-30 13:08:56,698 iteration 1678 : loss : 0.033807, loss_ce: 0.015832
2021-11-30 13:08:58,057 iteration 1679 : loss : 0.019786, loss_ce: 0.012295
2021-11-30 13:08:59,409 iteration 1680 : loss : 0.041628, loss_ce: 0.018647
2021-11-30 13:09:00,763 iteration 1681 : loss : 0.034398, loss_ce: 0.017919
2021-11-30 13:09:02,117 iteration 1682 : loss : 0.027750, loss_ce: 0.017758
2021-11-30 13:09:03,474 iteration 1683 : loss : 0.032663, loss_ce: 0.017975
 25%|███████▍                      | 99/400 [41:42<1:59:56, 23.91s/it]2021-11-30 13:09:04,887 iteration 1684 : loss : 0.032900, loss_ce: 0.015707
2021-11-30 13:09:06,238 iteration 1685 : loss : 0.027437, loss_ce: 0.014914
2021-11-30 13:09:07,587 iteration 1686 : loss : 0.027339, loss_ce: 0.014192
2021-11-30 13:09:08,931 iteration 1687 : loss : 0.043713, loss_ce: 0.017383
2021-11-30 13:09:10,273 iteration 1688 : loss : 0.028494, loss_ce: 0.014317
2021-11-30 13:09:11,619 iteration 1689 : loss : 0.023146, loss_ce: 0.014668
2021-11-30 13:09:12,976 iteration 1690 : loss : 0.038680, loss_ce: 0.015703
2021-11-30 13:09:14,328 iteration 1691 : loss : 0.044927, loss_ce: 0.021882
2021-11-30 13:09:15,669 iteration 1692 : loss : 0.023133, loss_ce: 0.013473
2021-11-30 13:09:17,022 iteration 1693 : loss : 0.026966, loss_ce: 0.014297
2021-11-30 13:09:18,368 iteration 1694 : loss : 0.025822, loss_ce: 0.015325
2021-11-30 13:09:19,724 iteration 1695 : loss : 0.040974, loss_ce: 0.017844
2021-11-30 13:09:21,062 iteration 1696 : loss : 0.029338, loss_ce: 0.015094
2021-11-30 13:09:22,412 iteration 1697 : loss : 0.024087, loss_ce: 0.014303
2021-11-30 13:09:23,775 iteration 1698 : loss : 0.033067, loss_ce: 0.017428
2021-11-30 13:09:25,128 iteration 1699 : loss : 0.023167, loss_ce: 0.015014
2021-11-30 13:09:25,128 Training Data Eval:
2021-11-30 13:09:32,760   Average segmentation loss on training set: 0.0305
2021-11-30 13:09:32,760 Validation Data Eval:
2021-11-30 13:09:35,387   Average segmentation loss on validation set: 0.1426
2021-11-30 13:09:36,746 iteration 1700 : loss : 0.029343, loss_ce: 0.015459
 25%|███████▎                     | 100/400 [42:15<2:13:35, 26.72s/it]2021-11-30 13:09:38,176 iteration 1701 : loss : 0.031685, loss_ce: 0.016018
2021-11-30 13:09:39,532 iteration 1702 : loss : 0.025885, loss_ce: 0.015124
2021-11-30 13:09:40,887 iteration 1703 : loss : 0.029628, loss_ce: 0.015728
2021-11-30 13:09:42,242 iteration 1704 : loss : 0.024576, loss_ce: 0.014128
2021-11-30 13:09:43,597 iteration 1705 : loss : 0.024865, loss_ce: 0.014113
2021-11-30 13:09:44,951 iteration 1706 : loss : 0.039900, loss_ce: 0.019338
2021-11-30 13:09:46,305 iteration 1707 : loss : 0.033411, loss_ce: 0.015446
2021-11-30 13:09:47,649 iteration 1708 : loss : 0.030855, loss_ce: 0.015655
2021-11-30 13:09:48,998 iteration 1709 : loss : 0.026048, loss_ce: 0.016303
2021-11-30 13:09:50,356 iteration 1710 : loss : 0.031370, loss_ce: 0.015407
2021-11-30 13:09:51,699 iteration 1711 : loss : 0.056667, loss_ce: 0.022000
2021-11-30 13:09:53,059 iteration 1712 : loss : 0.019579, loss_ce: 0.013107
2021-11-30 13:09:54,410 iteration 1713 : loss : 0.034443, loss_ce: 0.016502
2021-11-30 13:09:55,756 iteration 1714 : loss : 0.040756, loss_ce: 0.015401
2021-11-30 13:09:57,114 iteration 1715 : loss : 0.030255, loss_ce: 0.015791
2021-11-30 13:09:58,468 iteration 1716 : loss : 0.029142, loss_ce: 0.014977
2021-11-30 13:09:59,826 iteration 1717 : loss : 0.032967, loss_ce: 0.015812
 25%|███████▎                     | 101/400 [42:38<2:07:42, 25.63s/it]2021-11-30 13:10:01,237 iteration 1718 : loss : 0.028948, loss_ce: 0.015862
2021-11-30 13:10:02,582 iteration 1719 : loss : 0.026360, loss_ce: 0.012576
2021-11-30 13:10:03,935 iteration 1720 : loss : 0.019471, loss_ce: 0.012512
2021-11-30 13:10:05,289 iteration 1721 : loss : 0.036864, loss_ce: 0.018690
2021-11-30 13:10:06,639 iteration 1722 : loss : 0.034836, loss_ce: 0.018063
2021-11-30 13:10:07,990 iteration 1723 : loss : 0.036467, loss_ce: 0.017021
2021-11-30 13:10:09,346 iteration 1724 : loss : 0.021455, loss_ce: 0.012378
2021-11-30 13:10:10,695 iteration 1725 : loss : 0.019185, loss_ce: 0.012441
2021-11-30 13:10:12,055 iteration 1726 : loss : 0.021559, loss_ce: 0.013741
2021-11-30 13:10:13,406 iteration 1727 : loss : 0.027988, loss_ce: 0.016031
2021-11-30 13:10:14,762 iteration 1728 : loss : 0.029953, loss_ce: 0.015636
2021-11-30 13:10:16,119 iteration 1729 : loss : 0.047487, loss_ce: 0.016764
2021-11-30 13:10:17,463 iteration 1730 : loss : 0.049993, loss_ce: 0.019657
2021-11-30 13:10:18,813 iteration 1731 : loss : 0.029599, loss_ce: 0.015543
2021-11-30 13:10:20,165 iteration 1732 : loss : 0.028202, loss_ce: 0.016622
2021-11-30 13:10:21,516 iteration 1733 : loss : 0.020031, loss_ce: 0.011669
2021-11-30 13:10:22,872 iteration 1734 : loss : 0.032107, loss_ce: 0.016727
 26%|███████▍                     | 102/400 [43:01<2:03:26, 24.85s/it]2021-11-30 13:10:24,302 iteration 1735 : loss : 0.029001, loss_ce: 0.013998
2021-11-30 13:10:25,659 iteration 1736 : loss : 0.025498, loss_ce: 0.013431
2021-11-30 13:10:27,014 iteration 1737 : loss : 0.033555, loss_ce: 0.016161
2021-11-30 13:10:28,371 iteration 1738 : loss : 0.024302, loss_ce: 0.014619
2021-11-30 13:10:29,727 iteration 1739 : loss : 0.031214, loss_ce: 0.014733
2021-11-30 13:10:31,083 iteration 1740 : loss : 0.034474, loss_ce: 0.018384
2021-11-30 13:10:32,436 iteration 1741 : loss : 0.027339, loss_ce: 0.015252
2021-11-30 13:10:33,793 iteration 1742 : loss : 0.026414, loss_ce: 0.015683
2021-11-30 13:10:35,149 iteration 1743 : loss : 0.025055, loss_ce: 0.014854
2021-11-30 13:10:36,502 iteration 1744 : loss : 0.034148, loss_ce: 0.015355
2021-11-30 13:10:37,860 iteration 1745 : loss : 0.024836, loss_ce: 0.014102
2021-11-30 13:10:39,220 iteration 1746 : loss : 0.022702, loss_ce: 0.013878
2021-11-30 13:10:40,578 iteration 1747 : loss : 0.024228, loss_ce: 0.012070
2021-11-30 13:10:41,928 iteration 1748 : loss : 0.029573, loss_ce: 0.016946
2021-11-30 13:10:43,288 iteration 1749 : loss : 0.028288, loss_ce: 0.016761
2021-11-30 13:10:44,638 iteration 1750 : loss : 0.037314, loss_ce: 0.014656
2021-11-30 13:10:45,991 iteration 1751 : loss : 0.025942, loss_ce: 0.013453
 26%|███████▍                     | 103/400 [43:24<2:00:26, 24.33s/it]2021-11-30 13:10:47,412 iteration 1752 : loss : 0.030516, loss_ce: 0.013439
2021-11-30 13:10:48,772 iteration 1753 : loss : 0.027917, loss_ce: 0.015529
2021-11-30 13:10:50,127 iteration 1754 : loss : 0.028060, loss_ce: 0.013630
2021-11-30 13:10:51,485 iteration 1755 : loss : 0.031666, loss_ce: 0.015144
2021-11-30 13:10:52,840 iteration 1756 : loss : 0.026525, loss_ce: 0.017392
2021-11-30 13:10:54,195 iteration 1757 : loss : 0.033068, loss_ce: 0.017469
2021-11-30 13:10:55,550 iteration 1758 : loss : 0.037283, loss_ce: 0.014787
2021-11-30 13:10:56,901 iteration 1759 : loss : 0.024619, loss_ce: 0.012912
2021-11-30 13:10:58,255 iteration 1760 : loss : 0.029400, loss_ce: 0.014965
2021-11-30 13:10:59,610 iteration 1761 : loss : 0.042437, loss_ce: 0.016060
2021-11-30 13:11:00,965 iteration 1762 : loss : 0.029932, loss_ce: 0.017269
2021-11-30 13:11:02,317 iteration 1763 : loss : 0.022410, loss_ce: 0.011876
2021-11-30 13:11:03,670 iteration 1764 : loss : 0.024121, loss_ce: 0.015886
2021-11-30 13:11:05,023 iteration 1765 : loss : 0.038040, loss_ce: 0.020666
2021-11-30 13:11:06,379 iteration 1766 : loss : 0.023604, loss_ce: 0.013177
2021-11-30 13:11:07,726 iteration 1767 : loss : 0.034104, loss_ce: 0.020758
2021-11-30 13:11:09,076 iteration 1768 : loss : 0.024908, loss_ce: 0.013440
 26%|███████▌                     | 104/400 [43:47<1:58:11, 23.96s/it]2021-11-30 13:11:10,485 iteration 1769 : loss : 0.020906, loss_ce: 0.012237
2021-11-30 13:11:11,832 iteration 1770 : loss : 0.023922, loss_ce: 0.013337
2021-11-30 13:11:13,191 iteration 1771 : loss : 0.024505, loss_ce: 0.014014
2021-11-30 13:11:14,545 iteration 1772 : loss : 0.021597, loss_ce: 0.013160
2021-11-30 13:11:15,894 iteration 1773 : loss : 0.036571, loss_ce: 0.016175
2021-11-30 13:11:17,239 iteration 1774 : loss : 0.019456, loss_ce: 0.013341
2021-11-30 13:11:18,589 iteration 1775 : loss : 0.026522, loss_ce: 0.013109
2021-11-30 13:11:19,930 iteration 1776 : loss : 0.031387, loss_ce: 0.016066
2021-11-30 13:11:21,282 iteration 1777 : loss : 0.031500, loss_ce: 0.016629
2021-11-30 13:11:22,637 iteration 1778 : loss : 0.031339, loss_ce: 0.015203
2021-11-30 13:11:23,992 iteration 1779 : loss : 0.022833, loss_ce: 0.014594
2021-11-30 13:11:25,344 iteration 1780 : loss : 0.024550, loss_ce: 0.014148
2021-11-30 13:11:26,715 iteration 1781 : loss : 0.032052, loss_ce: 0.014653
2021-11-30 13:11:28,062 iteration 1782 : loss : 0.024689, loss_ce: 0.014356
2021-11-30 13:11:29,406 iteration 1783 : loss : 0.028066, loss_ce: 0.013129
2021-11-30 13:11:30,755 iteration 1784 : loss : 0.021103, loss_ce: 0.012374
2021-11-30 13:11:30,755 Training Data Eval:
2021-11-30 13:11:38,361   Average segmentation loss on training set: 0.0231
2021-11-30 13:11:38,362 Validation Data Eval:
2021-11-30 13:11:41,005   Average segmentation loss on validation set: 0.1640
2021-11-30 13:11:42,344 iteration 1785 : loss : 0.025568, loss_ce: 0.014065
 26%|███████▌                     | 105/400 [44:20<2:11:31, 26.75s/it]2021-11-30 13:11:43,758 iteration 1786 : loss : 0.021080, loss_ce: 0.012951
2021-11-30 13:11:45,112 iteration 1787 : loss : 0.026257, loss_ce: 0.014876
2021-11-30 13:11:46,466 iteration 1788 : loss : 0.020974, loss_ce: 0.012469
2021-11-30 13:11:47,821 iteration 1789 : loss : 0.021626, loss_ce: 0.012401
2021-11-30 13:11:49,175 iteration 1790 : loss : 0.023794, loss_ce: 0.013138
2021-11-30 13:11:50,530 iteration 1791 : loss : 0.030131, loss_ce: 0.017742
2021-11-30 13:11:51,883 iteration 1792 : loss : 0.025954, loss_ce: 0.013893
2021-11-30 13:11:53,226 iteration 1793 : loss : 0.028145, loss_ce: 0.015829
2021-11-30 13:11:54,582 iteration 1794 : loss : 0.022257, loss_ce: 0.014346
2021-11-30 13:11:55,929 iteration 1795 : loss : 0.021439, loss_ce: 0.011100
2021-11-30 13:11:57,279 iteration 1796 : loss : 0.024687, loss_ce: 0.013988
2021-11-30 13:11:58,632 iteration 1797 : loss : 0.037629, loss_ce: 0.014720
2021-11-30 13:11:59,984 iteration 1798 : loss : 0.029364, loss_ce: 0.015451
2021-11-30 13:12:01,327 iteration 1799 : loss : 0.023730, loss_ce: 0.013021
2021-11-30 13:12:02,686 iteration 1800 : loss : 0.028004, loss_ce: 0.012868
2021-11-30 13:12:04,033 iteration 1801 : loss : 0.026729, loss_ce: 0.013587
2021-11-30 13:12:05,379 iteration 1802 : loss : 0.031571, loss_ce: 0.017464
 26%|███████▋                     | 106/400 [44:43<2:05:36, 25.64s/it]2021-11-30 13:12:06,793 iteration 1803 : loss : 0.024857, loss_ce: 0.015681
2021-11-30 13:12:08,142 iteration 1804 : loss : 0.032255, loss_ce: 0.014162
2021-11-30 13:12:09,497 iteration 1805 : loss : 0.024978, loss_ce: 0.012274
2021-11-30 13:12:10,847 iteration 1806 : loss : 0.026250, loss_ce: 0.016690
2021-11-30 13:12:12,197 iteration 1807 : loss : 0.024435, loss_ce: 0.012662
2021-11-30 13:12:13,552 iteration 1808 : loss : 0.027015, loss_ce: 0.016318
2021-11-30 13:12:14,905 iteration 1809 : loss : 0.023590, loss_ce: 0.013144
2021-11-30 13:12:16,264 iteration 1810 : loss : 0.024344, loss_ce: 0.013234
2021-11-30 13:12:17,624 iteration 1811 : loss : 0.020790, loss_ce: 0.013324
2021-11-30 13:12:18,975 iteration 1812 : loss : 0.019330, loss_ce: 0.012371
2021-11-30 13:12:20,327 iteration 1813 : loss : 0.024483, loss_ce: 0.013533
2021-11-30 13:12:21,683 iteration 1814 : loss : 0.029567, loss_ce: 0.016750
2021-11-30 13:12:23,041 iteration 1815 : loss : 0.024894, loss_ce: 0.011851
2021-11-30 13:12:24,394 iteration 1816 : loss : 0.032073, loss_ce: 0.016461
2021-11-30 13:12:25,751 iteration 1817 : loss : 0.025165, loss_ce: 0.012877
2021-11-30 13:12:27,100 iteration 1818 : loss : 0.021741, loss_ce: 0.012863
2021-11-30 13:12:28,452 iteration 1819 : loss : 0.034159, loss_ce: 0.016244
 27%|███████▊                     | 107/400 [45:07<2:01:25, 24.87s/it]2021-11-30 13:12:29,859 iteration 1820 : loss : 0.033537, loss_ce: 0.013786
2021-11-30 13:12:31,199 iteration 1821 : loss : 0.022597, loss_ce: 0.013442
2021-11-30 13:12:32,543 iteration 1822 : loss : 0.033997, loss_ce: 0.013621
2021-11-30 13:12:33,897 iteration 1823 : loss : 0.033152, loss_ce: 0.014812
2021-11-30 13:12:35,250 iteration 1824 : loss : 0.019009, loss_ce: 0.012395
2021-11-30 13:12:36,590 iteration 1825 : loss : 0.033632, loss_ce: 0.016415
2021-11-30 13:12:37,945 iteration 1826 : loss : 0.031716, loss_ce: 0.017020
2021-11-30 13:12:39,296 iteration 1827 : loss : 0.021320, loss_ce: 0.012682
2021-11-30 13:12:40,642 iteration 1828 : loss : 0.023418, loss_ce: 0.012560
2021-11-30 13:12:41,997 iteration 1829 : loss : 0.022754, loss_ce: 0.015418
2021-11-30 13:12:43,354 iteration 1830 : loss : 0.023851, loss_ce: 0.014520
2021-11-30 13:12:44,693 iteration 1831 : loss : 0.027973, loss_ce: 0.013709
2021-11-30 13:12:46,052 iteration 1832 : loss : 0.021864, loss_ce: 0.014182
2021-11-30 13:12:47,400 iteration 1833 : loss : 0.026592, loss_ce: 0.013585
2021-11-30 13:12:48,748 iteration 1834 : loss : 0.020730, loss_ce: 0.011773
2021-11-30 13:12:50,092 iteration 1835 : loss : 0.029508, loss_ce: 0.013979
2021-11-30 13:12:51,453 iteration 1836 : loss : 0.025582, loss_ce: 0.014332
 27%|███████▊                     | 108/400 [45:30<1:58:17, 24.31s/it]2021-11-30 13:12:52,868 iteration 1837 : loss : 0.022883, loss_ce: 0.013885
2021-11-30 13:12:54,213 iteration 1838 : loss : 0.022333, loss_ce: 0.013400
2021-11-30 13:12:55,569 iteration 1839 : loss : 0.037278, loss_ce: 0.019732
2021-11-30 13:12:56,927 iteration 1840 : loss : 0.024361, loss_ce: 0.012852
2021-11-30 13:12:58,280 iteration 1841 : loss : 0.024818, loss_ce: 0.014703
2021-11-30 13:12:59,638 iteration 1842 : loss : 0.028517, loss_ce: 0.012030
2021-11-30 13:13:00,994 iteration 1843 : loss : 0.026765, loss_ce: 0.015941
2021-11-30 13:13:02,350 iteration 1844 : loss : 0.025098, loss_ce: 0.014202
2021-11-30 13:13:03,693 iteration 1845 : loss : 0.024416, loss_ce: 0.014315
2021-11-30 13:13:05,041 iteration 1846 : loss : 0.026768, loss_ce: 0.014824
2021-11-30 13:13:06,391 iteration 1847 : loss : 0.027413, loss_ce: 0.012379
2021-11-30 13:13:07,741 iteration 1848 : loss : 0.028835, loss_ce: 0.013653
2021-11-30 13:13:09,083 iteration 1849 : loss : 0.024089, loss_ce: 0.013225
2021-11-30 13:13:10,436 iteration 1850 : loss : 0.018643, loss_ce: 0.011935
2021-11-30 13:13:11,784 iteration 1851 : loss : 0.019984, loss_ce: 0.012110
2021-11-30 13:13:13,129 iteration 1852 : loss : 0.029984, loss_ce: 0.015618
2021-11-30 13:13:14,482 iteration 1853 : loss : 0.023040, loss_ce: 0.012635
 27%|███████▉                     | 109/400 [45:53<1:56:01, 23.92s/it]2021-11-30 13:13:15,890 iteration 1854 : loss : 0.027633, loss_ce: 0.014000
2021-11-30 13:13:17,223 iteration 1855 : loss : 0.025487, loss_ce: 0.014870
2021-11-30 13:13:18,564 iteration 1856 : loss : 0.028415, loss_ce: 0.012614
2021-11-30 13:13:19,921 iteration 1857 : loss : 0.032101, loss_ce: 0.017075
2021-11-30 13:13:21,274 iteration 1858 : loss : 0.021548, loss_ce: 0.013137
2021-11-30 13:13:22,616 iteration 1859 : loss : 0.023217, loss_ce: 0.012289
2021-11-30 13:13:23,964 iteration 1860 : loss : 0.025017, loss_ce: 0.013159
2021-11-30 13:13:25,318 iteration 1861 : loss : 0.034117, loss_ce: 0.013685
2021-11-30 13:13:26,674 iteration 1862 : loss : 0.020253, loss_ce: 0.011208
2021-11-30 13:13:28,023 iteration 1863 : loss : 0.024119, loss_ce: 0.014447
2021-11-30 13:13:29,379 iteration 1864 : loss : 0.020694, loss_ce: 0.012287
2021-11-30 13:13:30,723 iteration 1865 : loss : 0.025220, loss_ce: 0.015308
2021-11-30 13:13:32,069 iteration 1866 : loss : 0.028383, loss_ce: 0.015829
2021-11-30 13:13:33,425 iteration 1867 : loss : 0.025022, loss_ce: 0.015352
2021-11-30 13:13:34,775 iteration 1868 : loss : 0.026219, loss_ce: 0.013292
2021-11-30 13:13:36,110 iteration 1869 : loss : 0.024940, loss_ce: 0.013288
2021-11-30 13:13:36,110 Training Data Eval:
2021-11-30 13:13:43,744   Average segmentation loss on training set: 0.0246
2021-11-30 13:13:43,745 Validation Data Eval:
2021-11-30 13:13:46,379   Average segmentation loss on validation set: 0.1548
2021-11-30 13:13:47,730 iteration 1870 : loss : 0.027782, loss_ce: 0.013080
 28%|███████▉                     | 110/400 [46:26<2:09:09, 26.72s/it]2021-11-30 13:13:49,156 iteration 1871 : loss : 0.024562, loss_ce: 0.014631
2021-11-30 13:13:50,519 iteration 1872 : loss : 0.026029, loss_ce: 0.016791
2021-11-30 13:13:51,876 iteration 1873 : loss : 0.019657, loss_ce: 0.011213
2021-11-30 13:13:53,233 iteration 1874 : loss : 0.019624, loss_ce: 0.012713
2021-11-30 13:13:54,591 iteration 1875 : loss : 0.029586, loss_ce: 0.016971
2021-11-30 13:13:55,949 iteration 1876 : loss : 0.034956, loss_ce: 0.013762
2021-11-30 13:13:57,314 iteration 1877 : loss : 0.023917, loss_ce: 0.014389
2021-11-30 13:13:58,670 iteration 1878 : loss : 0.027313, loss_ce: 0.014448
2021-11-30 13:14:00,029 iteration 1879 : loss : 0.018931, loss_ce: 0.011954
2021-11-30 13:14:01,382 iteration 1880 : loss : 0.030573, loss_ce: 0.017161
2021-11-30 13:14:02,739 iteration 1881 : loss : 0.022897, loss_ce: 0.012708
2021-11-30 13:14:04,100 iteration 1882 : loss : 0.022783, loss_ce: 0.012341
2021-11-30 13:14:05,457 iteration 1883 : loss : 0.031374, loss_ce: 0.014458
2021-11-30 13:14:06,822 iteration 1884 : loss : 0.022130, loss_ce: 0.011522
2021-11-30 13:14:08,171 iteration 1885 : loss : 0.022480, loss_ce: 0.011897
2021-11-30 13:14:09,530 iteration 1886 : loss : 0.023351, loss_ce: 0.012896
2021-11-30 13:14:10,892 iteration 1887 : loss : 0.021532, loss_ce: 0.012646
 28%|████████                     | 111/400 [46:49<2:03:33, 25.65s/it]2021-11-30 13:14:12,302 iteration 1888 : loss : 0.029620, loss_ce: 0.014632
2021-11-30 13:14:13,645 iteration 1889 : loss : 0.034282, loss_ce: 0.019781
2021-11-30 13:14:14,996 iteration 1890 : loss : 0.021404, loss_ce: 0.011101
2021-11-30 13:14:16,343 iteration 1891 : loss : 0.023343, loss_ce: 0.013403
2021-11-30 13:14:17,694 iteration 1892 : loss : 0.025044, loss_ce: 0.013507
2021-11-30 13:14:19,037 iteration 1893 : loss : 0.026276, loss_ce: 0.015334
2021-11-30 13:14:20,393 iteration 1894 : loss : 0.023698, loss_ce: 0.012659
2021-11-30 13:14:21,750 iteration 1895 : loss : 0.037900, loss_ce: 0.015537
2021-11-30 13:14:23,105 iteration 1896 : loss : 0.023054, loss_ce: 0.011510
2021-11-30 13:14:24,451 iteration 1897 : loss : 0.028011, loss_ce: 0.015067
2021-11-30 13:14:25,809 iteration 1898 : loss : 0.024499, loss_ce: 0.013457
2021-11-30 13:14:27,170 iteration 1899 : loss : 0.021600, loss_ce: 0.012091
2021-11-30 13:14:28,528 iteration 1900 : loss : 0.026323, loss_ce: 0.013609
2021-11-30 13:14:29,884 iteration 1901 : loss : 0.022371, loss_ce: 0.011916
2021-11-30 13:14:31,242 iteration 1902 : loss : 0.018260, loss_ce: 0.010836
2021-11-30 13:14:32,602 iteration 1903 : loss : 0.020242, loss_ce: 0.013426
2021-11-30 13:14:33,963 iteration 1904 : loss : 0.027842, loss_ce: 0.014895
 28%|████████                     | 112/400 [47:12<1:59:25, 24.88s/it]2021-11-30 13:14:35,381 iteration 1905 : loss : 0.022942, loss_ce: 0.013761
2021-11-30 13:14:36,727 iteration 1906 : loss : 0.018716, loss_ce: 0.011772
2021-11-30 13:14:38,083 iteration 1907 : loss : 0.018635, loss_ce: 0.012140
2021-11-30 13:14:39,442 iteration 1908 : loss : 0.024727, loss_ce: 0.013860
2021-11-30 13:14:40,804 iteration 1909 : loss : 0.030416, loss_ce: 0.016423
2021-11-30 13:14:42,156 iteration 1910 : loss : 0.027246, loss_ce: 0.012574
2021-11-30 13:14:43,491 iteration 1911 : loss : 0.028095, loss_ce: 0.012950
2021-11-30 13:14:44,836 iteration 1912 : loss : 0.022110, loss_ce: 0.013042
2021-11-30 13:14:46,196 iteration 1913 : loss : 0.022989, loss_ce: 0.013536
2021-11-30 13:14:47,553 iteration 1914 : loss : 0.022793, loss_ce: 0.013384
2021-11-30 13:14:48,900 iteration 1915 : loss : 0.029088, loss_ce: 0.015231
2021-11-30 13:14:50,248 iteration 1916 : loss : 0.024905, loss_ce: 0.011883
2021-11-30 13:14:51,599 iteration 1917 : loss : 0.017680, loss_ce: 0.010521
2021-11-30 13:14:52,944 iteration 1918 : loss : 0.034975, loss_ce: 0.018564
2021-11-30 13:14:54,300 iteration 1919 : loss : 0.030760, loss_ce: 0.015626
2021-11-30 13:14:55,651 iteration 1920 : loss : 0.019620, loss_ce: 0.011693
2021-11-30 13:14:56,995 iteration 1921 : loss : 0.022879, loss_ce: 0.011842
 28%|████████▏                    | 113/400 [47:35<1:56:21, 24.32s/it]2021-11-30 13:14:58,411 iteration 1922 : loss : 0.026482, loss_ce: 0.014978
2021-11-30 13:14:59,754 iteration 1923 : loss : 0.022283, loss_ce: 0.012060
2021-11-30 13:15:01,107 iteration 1924 : loss : 0.021075, loss_ce: 0.011637
2021-11-30 13:15:02,440 iteration 1925 : loss : 0.020187, loss_ce: 0.012504
2021-11-30 13:15:03,781 iteration 1926 : loss : 0.023148, loss_ce: 0.013556
2021-11-30 13:15:05,125 iteration 1927 : loss : 0.032239, loss_ce: 0.013865
2021-11-30 13:15:06,477 iteration 1928 : loss : 0.024599, loss_ce: 0.012114
2021-11-30 13:15:07,830 iteration 1929 : loss : 0.016805, loss_ce: 0.011055
2021-11-30 13:15:09,172 iteration 1930 : loss : 0.030514, loss_ce: 0.012088
2021-11-30 13:15:10,525 iteration 1931 : loss : 0.021001, loss_ce: 0.013645
2021-11-30 13:15:11,876 iteration 1932 : loss : 0.027799, loss_ce: 0.015214
2021-11-30 13:15:13,211 iteration 1933 : loss : 0.027567, loss_ce: 0.013227
2021-11-30 13:15:14,568 iteration 1934 : loss : 0.029774, loss_ce: 0.015010
2021-11-30 13:15:15,898 iteration 1935 : loss : 0.021670, loss_ce: 0.013118
2021-11-30 13:15:17,245 iteration 1936 : loss : 0.019412, loss_ce: 0.011884
2021-11-30 13:15:18,580 iteration 1937 : loss : 0.019367, loss_ce: 0.012382
2021-11-30 13:15:19,939 iteration 1938 : loss : 0.026156, loss_ce: 0.012817
 28%|████████▎                    | 114/400 [47:58<1:53:58, 23.91s/it]2021-11-30 13:15:21,353 iteration 1939 : loss : 0.032177, loss_ce: 0.013622
2021-11-30 13:15:22,690 iteration 1940 : loss : 0.024026, loss_ce: 0.012855
2021-11-30 13:15:24,030 iteration 1941 : loss : 0.019418, loss_ce: 0.012495
2021-11-30 13:15:25,380 iteration 1942 : loss : 0.019418, loss_ce: 0.012553
2021-11-30 13:15:26,735 iteration 1943 : loss : 0.017978, loss_ce: 0.011601
2021-11-30 13:15:28,075 iteration 1944 : loss : 0.027315, loss_ce: 0.012706
2021-11-30 13:15:29,417 iteration 1945 : loss : 0.023298, loss_ce: 0.012747
2021-11-30 13:15:30,775 iteration 1946 : loss : 0.020103, loss_ce: 0.012000
2021-11-30 13:15:32,124 iteration 1947 : loss : 0.018209, loss_ce: 0.010270
2021-11-30 13:15:33,463 iteration 1948 : loss : 0.022075, loss_ce: 0.010940
2021-11-30 13:15:34,803 iteration 1949 : loss : 0.020956, loss_ce: 0.012445
2021-11-30 13:15:36,150 iteration 1950 : loss : 0.028502, loss_ce: 0.015311
2021-11-30 13:15:37,499 iteration 1951 : loss : 0.028380, loss_ce: 0.015530
2021-11-30 13:15:38,846 iteration 1952 : loss : 0.021542, loss_ce: 0.012444
2021-11-30 13:15:40,209 iteration 1953 : loss : 0.021110, loss_ce: 0.014262
2021-11-30 13:15:41,561 iteration 1954 : loss : 0.020965, loss_ce: 0.010877
2021-11-30 13:15:41,561 Training Data Eval:
2021-11-30 13:15:49,162   Average segmentation loss on training set: 0.0204
2021-11-30 13:15:49,163 Validation Data Eval:
2021-11-30 13:15:51,786   Average segmentation loss on validation set: 0.1769
2021-11-30 13:15:53,125 iteration 1955 : loss : 0.022142, loss_ce: 0.013005
 29%|████████▎                    | 115/400 [48:31<2:06:47, 26.69s/it]2021-11-30 13:15:54,541 iteration 1956 : loss : 0.020955, loss_ce: 0.011554
2021-11-30 13:15:55,885 iteration 1957 : loss : 0.021843, loss_ce: 0.011750
2021-11-30 13:15:57,238 iteration 1958 : loss : 0.022313, loss_ce: 0.013041
2021-11-30 13:15:58,596 iteration 1959 : loss : 0.036125, loss_ce: 0.013932
2021-11-30 13:15:59,939 iteration 1960 : loss : 0.021800, loss_ce: 0.012532
2021-11-30 13:16:01,295 iteration 1961 : loss : 0.019399, loss_ce: 0.010700
2021-11-30 13:16:02,638 iteration 1962 : loss : 0.026150, loss_ce: 0.014827
2021-11-30 13:16:03,980 iteration 1963 : loss : 0.028120, loss_ce: 0.015020
2021-11-30 13:16:05,322 iteration 1964 : loss : 0.022038, loss_ce: 0.013070
2021-11-30 13:16:06,668 iteration 1965 : loss : 0.019218, loss_ce: 0.012168
2021-11-30 13:16:08,030 iteration 1966 : loss : 0.025915, loss_ce: 0.012726
2021-11-30 13:16:09,370 iteration 1967 : loss : 0.021150, loss_ce: 0.012345
2021-11-30 13:16:10,730 iteration 1968 : loss : 0.020362, loss_ce: 0.013286
2021-11-30 13:16:12,073 iteration 1969 : loss : 0.020641, loss_ce: 0.010733
2021-11-30 13:16:13,428 iteration 1970 : loss : 0.024911, loss_ce: 0.014676
2021-11-30 13:16:14,764 iteration 1971 : loss : 0.027289, loss_ce: 0.016531
2021-11-30 13:16:16,109 iteration 1972 : loss : 0.024973, loss_ce: 0.013490
 29%|████████▍                    | 116/400 [48:54<2:01:04, 25.58s/it]2021-11-30 13:16:17,532 iteration 1973 : loss : 0.019947, loss_ce: 0.012791
2021-11-30 13:16:18,883 iteration 1974 : loss : 0.021701, loss_ce: 0.012325
2021-11-30 13:16:20,226 iteration 1975 : loss : 0.022168, loss_ce: 0.012511
2021-11-30 13:16:21,578 iteration 1976 : loss : 0.024987, loss_ce: 0.013422
2021-11-30 13:16:22,913 iteration 1977 : loss : 0.018032, loss_ce: 0.011782
2021-11-30 13:16:24,269 iteration 1978 : loss : 0.030529, loss_ce: 0.014699
2021-11-30 13:16:25,619 iteration 1979 : loss : 0.029082, loss_ce: 0.013470
2021-11-30 13:16:26,964 iteration 1980 : loss : 0.027668, loss_ce: 0.012282
2021-11-30 13:16:28,323 iteration 1981 : loss : 0.018136, loss_ce: 0.011157
2021-11-30 13:16:29,673 iteration 1982 : loss : 0.019898, loss_ce: 0.012625
2021-11-30 13:16:31,019 iteration 1983 : loss : 0.026784, loss_ce: 0.012112
2021-11-30 13:16:32,360 iteration 1984 : loss : 0.020020, loss_ce: 0.012423
2021-11-30 13:16:33,706 iteration 1985 : loss : 0.020618, loss_ce: 0.012418
2021-11-30 13:16:35,067 iteration 1986 : loss : 0.026488, loss_ce: 0.014089
2021-11-30 13:16:36,420 iteration 1987 : loss : 0.023427, loss_ce: 0.011217
2021-11-30 13:16:37,767 iteration 1988 : loss : 0.021708, loss_ce: 0.012627
2021-11-30 13:16:39,103 iteration 1989 : loss : 0.018609, loss_ce: 0.012648
 29%|████████▍                    | 117/400 [49:17<1:56:59, 24.80s/it]2021-11-30 13:16:40,510 iteration 1990 : loss : 0.025988, loss_ce: 0.013249
2021-11-30 13:16:41,840 iteration 1991 : loss : 0.019434, loss_ce: 0.011068
2021-11-30 13:16:43,185 iteration 1992 : loss : 0.020125, loss_ce: 0.012887
2021-11-30 13:16:44,543 iteration 1993 : loss : 0.018901, loss_ce: 0.011823
2021-11-30 13:16:45,895 iteration 1994 : loss : 0.042902, loss_ce: 0.012909
2021-11-30 13:16:47,235 iteration 1995 : loss : 0.021098, loss_ce: 0.011828
2021-11-30 13:16:48,592 iteration 1996 : loss : 0.017512, loss_ce: 0.009960
2021-11-30 13:16:49,945 iteration 1997 : loss : 0.016806, loss_ce: 0.010108
2021-11-30 13:16:51,293 iteration 1998 : loss : 0.029828, loss_ce: 0.018738
2021-11-30 13:16:52,653 iteration 1999 : loss : 0.041985, loss_ce: 0.024102
2021-11-30 13:16:54,015 iteration 2000 : loss : 0.042765, loss_ce: 0.020762
2021-11-30 13:16:55,377 iteration 2001 : loss : 0.017327, loss_ce: 0.011436
2021-11-30 13:16:56,733 iteration 2002 : loss : 0.018054, loss_ce: 0.010845
2021-11-30 13:16:58,092 iteration 2003 : loss : 0.020113, loss_ce: 0.012327
2021-11-30 13:16:59,451 iteration 2004 : loss : 0.037421, loss_ce: 0.013330
2021-11-30 13:17:00,797 iteration 2005 : loss : 0.025308, loss_ce: 0.014266
2021-11-30 13:17:02,146 iteration 2006 : loss : 0.023264, loss_ce: 0.013063
 30%|████████▌                    | 118/400 [49:40<1:54:05, 24.28s/it]2021-11-30 13:17:03,555 iteration 2007 : loss : 0.020779, loss_ce: 0.012171
2021-11-30 13:17:04,898 iteration 2008 : loss : 0.020137, loss_ce: 0.010931
2021-11-30 13:17:06,255 iteration 2009 : loss : 0.033749, loss_ce: 0.014179
2021-11-30 13:17:07,608 iteration 2010 : loss : 0.024769, loss_ce: 0.013102
2021-11-30 13:17:08,958 iteration 2011 : loss : 0.032873, loss_ce: 0.015273
2021-11-30 13:17:10,322 iteration 2012 : loss : 0.020616, loss_ce: 0.014135
2021-11-30 13:17:11,677 iteration 2013 : loss : 0.023680, loss_ce: 0.012214
2021-11-30 13:17:13,029 iteration 2014 : loss : 0.021628, loss_ce: 0.011811
2021-11-30 13:17:14,388 iteration 2015 : loss : 0.035797, loss_ce: 0.014242
2021-11-30 13:17:15,745 iteration 2016 : loss : 0.019219, loss_ce: 0.012277
2021-11-30 13:17:17,111 iteration 2017 : loss : 0.021750, loss_ce: 0.013735
2021-11-30 13:17:18,468 iteration 2018 : loss : 0.033691, loss_ce: 0.016166
2021-11-30 13:17:19,822 iteration 2019 : loss : 0.030775, loss_ce: 0.017591
2021-11-30 13:17:21,175 iteration 2020 : loss : 0.037899, loss_ce: 0.017865
2021-11-30 13:17:22,529 iteration 2021 : loss : 0.020529, loss_ce: 0.012379
2021-11-30 13:17:23,887 iteration 2022 : loss : 0.026114, loss_ce: 0.012473
2021-11-30 13:17:25,248 iteration 2023 : loss : 0.022330, loss_ce: 0.013767
 30%|████████▋                    | 119/400 [50:03<1:52:02, 23.93s/it]2021-11-30 13:17:26,664 iteration 2024 : loss : 0.028762, loss_ce: 0.013882
2021-11-30 13:17:28,010 iteration 2025 : loss : 0.016429, loss_ce: 0.010004
2021-11-30 13:17:29,367 iteration 2026 : loss : 0.021727, loss_ce: 0.011631
2021-11-30 13:17:30,720 iteration 2027 : loss : 0.020113, loss_ce: 0.013158
2021-11-30 13:17:32,076 iteration 2028 : loss : 0.028549, loss_ce: 0.016178
2021-11-30 13:17:33,427 iteration 2029 : loss : 0.034822, loss_ce: 0.015983
2021-11-30 13:17:34,775 iteration 2030 : loss : 0.023343, loss_ce: 0.011510
2021-11-30 13:17:36,126 iteration 2031 : loss : 0.028815, loss_ce: 0.013953
2021-11-30 13:17:37,476 iteration 2032 : loss : 0.020049, loss_ce: 0.013187
2021-11-30 13:17:38,815 iteration 2033 : loss : 0.022567, loss_ce: 0.012069
2021-11-30 13:17:40,158 iteration 2034 : loss : 0.020038, loss_ce: 0.011714
2021-11-30 13:17:41,509 iteration 2035 : loss : 0.022181, loss_ce: 0.012154
2021-11-30 13:17:42,864 iteration 2036 : loss : 0.022810, loss_ce: 0.013475
2021-11-30 13:17:44,216 iteration 2037 : loss : 0.025208, loss_ce: 0.012586
2021-11-30 13:17:45,559 iteration 2038 : loss : 0.022785, loss_ce: 0.010613
2021-11-30 13:17:46,911 iteration 2039 : loss : 0.020154, loss_ce: 0.012412
2021-11-30 13:17:46,911 Training Data Eval:
2021-11-30 13:17:54,530   Average segmentation loss on training set: 0.0397
2021-11-30 13:17:54,530 Validation Data Eval:
2021-11-30 13:17:57,145   Average segmentation loss on validation set: 0.2379
2021-11-30 13:17:58,492 iteration 2040 : loss : 0.019346, loss_ce: 0.011825
 30%|████████▋                    | 120/400 [50:37<2:04:41, 26.72s/it]2021-11-30 13:17:59,918 iteration 2041 : loss : 0.038872, loss_ce: 0.015734
2021-11-30 13:18:01,267 iteration 2042 : loss : 0.022162, loss_ce: 0.013356
2021-11-30 13:18:02,623 iteration 2043 : loss : 0.023392, loss_ce: 0.012316
2021-11-30 13:18:03,979 iteration 2044 : loss : 0.021438, loss_ce: 0.011675
2021-11-30 13:18:05,333 iteration 2045 : loss : 0.020419, loss_ce: 0.011282
2021-11-30 13:18:06,677 iteration 2046 : loss : 0.027772, loss_ce: 0.013519
2021-11-30 13:18:08,018 iteration 2047 : loss : 0.020905, loss_ce: 0.012183
2021-11-30 13:18:09,371 iteration 2048 : loss : 0.022232, loss_ce: 0.013922
2021-11-30 13:18:10,729 iteration 2049 : loss : 0.025880, loss_ce: 0.014535
2021-11-30 13:18:12,084 iteration 2050 : loss : 0.019298, loss_ce: 0.011417
2021-11-30 13:18:13,429 iteration 2051 : loss : 0.023953, loss_ce: 0.013592
2021-11-30 13:18:14,783 iteration 2052 : loss : 0.026061, loss_ce: 0.014036
2021-11-30 13:18:16,144 iteration 2053 : loss : 0.025890, loss_ce: 0.014047
2021-11-30 13:18:17,501 iteration 2054 : loss : 0.028528, loss_ce: 0.011942
2021-11-30 13:18:18,846 iteration 2055 : loss : 0.023533, loss_ce: 0.013067
2021-11-30 13:18:20,194 iteration 2056 : loss : 0.015276, loss_ce: 0.009968
2021-11-30 13:18:21,547 iteration 2057 : loss : 0.021364, loss_ce: 0.011705
 30%|████████▊                    | 121/400 [51:00<1:59:07, 25.62s/it]2021-11-30 13:18:22,955 iteration 2058 : loss : 0.018732, loss_ce: 0.010785
2021-11-30 13:18:24,297 iteration 2059 : loss : 0.021948, loss_ce: 0.013380
2021-11-30 13:18:25,657 iteration 2060 : loss : 0.020366, loss_ce: 0.013061
2021-11-30 13:18:27,012 iteration 2061 : loss : 0.022425, loss_ce: 0.013439
2021-11-30 13:18:28,365 iteration 2062 : loss : 0.022270, loss_ce: 0.011595
2021-11-30 13:18:29,717 iteration 2063 : loss : 0.020669, loss_ce: 0.013302
2021-11-30 13:18:31,075 iteration 2064 : loss : 0.017666, loss_ce: 0.011212
2021-11-30 13:18:32,438 iteration 2065 : loss : 0.020677, loss_ce: 0.011635
2021-11-30 13:18:33,799 iteration 2066 : loss : 0.021173, loss_ce: 0.012683
2021-11-30 13:18:35,166 iteration 2067 : loss : 0.022349, loss_ce: 0.012596
2021-11-30 13:18:36,531 iteration 2068 : loss : 0.023003, loss_ce: 0.013592
2021-11-30 13:18:37,886 iteration 2069 : loss : 0.022644, loss_ce: 0.011255
2021-11-30 13:18:39,234 iteration 2070 : loss : 0.025144, loss_ce: 0.011257
2021-11-30 13:18:40,594 iteration 2071 : loss : 0.032218, loss_ce: 0.015126
2021-11-30 13:18:41,951 iteration 2072 : loss : 0.025245, loss_ce: 0.013616
2021-11-30 13:18:43,309 iteration 2073 : loss : 0.022844, loss_ce: 0.011601
2021-11-30 13:18:44,669 iteration 2074 : loss : 0.019373, loss_ce: 0.011370
 30%|████████▊                    | 122/400 [51:23<1:55:14, 24.87s/it]2021-11-30 13:18:46,090 iteration 2075 : loss : 0.019106, loss_ce: 0.012646
2021-11-30 13:18:47,448 iteration 2076 : loss : 0.019699, loss_ce: 0.010856
2021-11-30 13:18:48,804 iteration 2077 : loss : 0.024777, loss_ce: 0.010329
2021-11-30 13:18:50,163 iteration 2078 : loss : 0.015818, loss_ce: 0.009965
2021-11-30 13:18:51,518 iteration 2079 : loss : 0.019523, loss_ce: 0.012471
2021-11-30 13:18:52,876 iteration 2080 : loss : 0.020487, loss_ce: 0.012209
2021-11-30 13:18:54,216 iteration 2081 : loss : 0.028376, loss_ce: 0.012806
2021-11-30 13:18:55,577 iteration 2082 : loss : 0.028735, loss_ce: 0.017100
2021-11-30 13:18:56,930 iteration 2083 : loss : 0.023323, loss_ce: 0.010427
2021-11-30 13:18:58,279 iteration 2084 : loss : 0.018042, loss_ce: 0.010551
2021-11-30 13:18:59,635 iteration 2085 : loss : 0.021213, loss_ce: 0.012103
2021-11-30 13:19:00,981 iteration 2086 : loss : 0.021179, loss_ce: 0.013503
2021-11-30 13:19:02,341 iteration 2087 : loss : 0.023253, loss_ce: 0.011842
2021-11-30 13:19:03,683 iteration 2088 : loss : 0.019579, loss_ce: 0.012875
2021-11-30 13:19:05,037 iteration 2089 : loss : 0.026226, loss_ce: 0.016739
2021-11-30 13:19:06,393 iteration 2090 : loss : 0.020268, loss_ce: 0.011002
2021-11-30 13:19:07,742 iteration 2091 : loss : 0.021128, loss_ce: 0.011295
 31%|████████▉                    | 123/400 [51:46<1:52:19, 24.33s/it]2021-11-30 13:19:09,161 iteration 2092 : loss : 0.020477, loss_ce: 0.010820
2021-11-30 13:19:10,513 iteration 2093 : loss : 0.030677, loss_ce: 0.015359
2021-11-30 13:19:11,867 iteration 2094 : loss : 0.019392, loss_ce: 0.011370
2021-11-30 13:19:13,219 iteration 2095 : loss : 0.026279, loss_ce: 0.013208
2021-11-30 13:19:14,564 iteration 2096 : loss : 0.016816, loss_ce: 0.010404
2021-11-30 13:19:15,922 iteration 2097 : loss : 0.028819, loss_ce: 0.012203
2021-11-30 13:19:17,281 iteration 2098 : loss : 0.027714, loss_ce: 0.014518
2021-11-30 13:19:18,623 iteration 2099 : loss : 0.021712, loss_ce: 0.013391
2021-11-30 13:19:19,979 iteration 2100 : loss : 0.018301, loss_ce: 0.009719
2021-11-30 13:19:21,335 iteration 2101 : loss : 0.019697, loss_ce: 0.011455
2021-11-30 13:19:22,679 iteration 2102 : loss : 0.025491, loss_ce: 0.016475
2021-11-30 13:19:24,045 iteration 2103 : loss : 0.021722, loss_ce: 0.012184
2021-11-30 13:19:25,399 iteration 2104 : loss : 0.019836, loss_ce: 0.011095
2021-11-30 13:19:26,738 iteration 2105 : loss : 0.028762, loss_ce: 0.013750
2021-11-30 13:19:28,077 iteration 2106 : loss : 0.020168, loss_ce: 0.012243
2021-11-30 13:19:29,423 iteration 2107 : loss : 0.017792, loss_ce: 0.011974
2021-11-30 13:19:30,780 iteration 2108 : loss : 0.020165, loss_ce: 0.012381
 31%|████████▉                    | 124/400 [52:09<1:50:08, 23.94s/it]2021-11-30 13:19:32,182 iteration 2109 : loss : 0.020640, loss_ce: 0.013094
2021-11-30 13:19:33,518 iteration 2110 : loss : 0.019359, loss_ce: 0.012786
2021-11-30 13:19:34,867 iteration 2111 : loss : 0.017166, loss_ce: 0.010628
2021-11-30 13:19:36,228 iteration 2112 : loss : 0.024064, loss_ce: 0.012756
2021-11-30 13:19:37,580 iteration 2113 : loss : 0.021190, loss_ce: 0.010325
2021-11-30 13:19:38,932 iteration 2114 : loss : 0.019282, loss_ce: 0.011558
2021-11-30 13:19:40,288 iteration 2115 : loss : 0.025706, loss_ce: 0.012427
2021-11-30 13:19:41,648 iteration 2116 : loss : 0.022993, loss_ce: 0.011761
2021-11-30 13:19:43,003 iteration 2117 : loss : 0.028038, loss_ce: 0.013306
2021-11-30 13:19:44,365 iteration 2118 : loss : 0.014173, loss_ce: 0.009872
2021-11-30 13:19:45,727 iteration 2119 : loss : 0.022166, loss_ce: 0.011164
2021-11-30 13:19:47,084 iteration 2120 : loss : 0.025135, loss_ce: 0.015237
2021-11-30 13:19:48,441 iteration 2121 : loss : 0.024955, loss_ce: 0.016452
2021-11-30 13:19:49,800 iteration 2122 : loss : 0.018734, loss_ce: 0.011093
2021-11-30 13:19:51,161 iteration 2123 : loss : 0.014865, loss_ce: 0.009474
2021-11-30 13:19:52,522 iteration 2124 : loss : 0.019971, loss_ce: 0.010697
2021-11-30 13:19:52,523 Training Data Eval:
2021-11-30 13:20:00,240   Average segmentation loss on training set: 0.0216
2021-11-30 13:20:00,240 Validation Data Eval:
2021-11-30 13:20:02,896   Average segmentation loss on validation set: 0.1903
2021-11-30 13:20:04,243 iteration 2125 : loss : 0.019429, loss_ce: 0.012870
 31%|█████████                    | 125/400 [52:42<2:02:49, 26.80s/it]2021-11-30 13:20:05,662 iteration 2126 : loss : 0.019454, loss_ce: 0.012587
2021-11-30 13:20:07,016 iteration 2127 : loss : 0.020009, loss_ce: 0.012494
2021-11-30 13:20:08,374 iteration 2128 : loss : 0.025352, loss_ce: 0.013702
2021-11-30 13:20:09,731 iteration 2129 : loss : 0.016075, loss_ce: 0.009431
2021-11-30 13:20:11,087 iteration 2130 : loss : 0.020461, loss_ce: 0.011472
2021-11-30 13:20:12,436 iteration 2131 : loss : 0.017681, loss_ce: 0.010192
2021-11-30 13:20:13,798 iteration 2132 : loss : 0.055236, loss_ce: 0.011311
2021-11-30 13:20:15,145 iteration 2133 : loss : 0.019581, loss_ce: 0.011347
2021-11-30 13:20:16,501 iteration 2134 : loss : 0.023445, loss_ce: 0.012989
2021-11-30 13:20:17,849 iteration 2135 : loss : 0.018534, loss_ce: 0.011456
2021-11-30 13:20:19,210 iteration 2136 : loss : 0.027865, loss_ce: 0.014649
2021-11-30 13:20:20,566 iteration 2137 : loss : 0.018755, loss_ce: 0.011715
2021-11-30 13:20:21,919 iteration 2138 : loss : 0.017659, loss_ce: 0.010845
2021-11-30 13:20:23,271 iteration 2139 : loss : 0.019582, loss_ce: 0.011470
2021-11-30 13:20:24,628 iteration 2140 : loss : 0.022636, loss_ce: 0.013068
2021-11-30 13:20:25,986 iteration 2141 : loss : 0.016420, loss_ce: 0.010154
2021-11-30 13:20:27,345 iteration 2142 : loss : 0.022996, loss_ce: 0.012094
 32%|█████████▏                   | 126/400 [53:05<1:57:18, 25.69s/it]2021-11-30 13:20:28,757 iteration 2143 : loss : 0.020249, loss_ce: 0.010405
2021-11-30 13:20:30,108 iteration 2144 : loss : 0.025226, loss_ce: 0.016328
2021-11-30 13:20:31,465 iteration 2145 : loss : 0.019657, loss_ce: 0.010541
2021-11-30 13:20:32,822 iteration 2146 : loss : 0.019324, loss_ce: 0.010347
2021-11-30 13:20:34,171 iteration 2147 : loss : 0.019859, loss_ce: 0.011843
2021-11-30 13:20:35,520 iteration 2148 : loss : 0.019693, loss_ce: 0.013629
2021-11-30 13:20:36,868 iteration 2149 : loss : 0.022365, loss_ce: 0.012535
2021-11-30 13:20:38,218 iteration 2150 : loss : 0.019818, loss_ce: 0.012046
2021-11-30 13:20:39,578 iteration 2151 : loss : 0.020439, loss_ce: 0.011134
2021-11-30 13:20:40,928 iteration 2152 : loss : 0.021919, loss_ce: 0.010013
2021-11-30 13:20:42,291 iteration 2153 : loss : 0.019838, loss_ce: 0.011621
2021-11-30 13:20:43,646 iteration 2154 : loss : 0.018715, loss_ce: 0.011422
2021-11-30 13:20:44,999 iteration 2155 : loss : 0.018272, loss_ce: 0.010980
2021-11-30 13:20:46,355 iteration 2156 : loss : 0.029419, loss_ce: 0.013062
2021-11-30 13:20:47,702 iteration 2157 : loss : 0.016090, loss_ce: 0.010714
2021-11-30 13:20:49,066 iteration 2158 : loss : 0.020024, loss_ce: 0.010715
2021-11-30 13:20:50,416 iteration 2159 : loss : 0.020909, loss_ce: 0.012313
 32%|█████████▏                   | 127/400 [53:29<1:53:18, 24.90s/it]2021-11-30 13:20:51,814 iteration 2160 : loss : 0.018683, loss_ce: 0.010217
2021-11-30 13:20:53,152 iteration 2161 : loss : 0.019642, loss_ce: 0.010779
2021-11-30 13:20:54,493 iteration 2162 : loss : 0.016040, loss_ce: 0.009364
2021-11-30 13:20:55,850 iteration 2163 : loss : 0.019384, loss_ce: 0.010948
2021-11-30 13:20:57,202 iteration 2164 : loss : 0.021814, loss_ce: 0.010324
2021-11-30 13:20:58,543 iteration 2165 : loss : 0.019817, loss_ce: 0.011469
2021-11-30 13:20:59,893 iteration 2166 : loss : 0.027449, loss_ce: 0.017182
2021-11-30 13:21:01,248 iteration 2167 : loss : 0.019187, loss_ce: 0.011981
2021-11-30 13:21:02,592 iteration 2168 : loss : 0.019254, loss_ce: 0.011996
2021-11-30 13:21:03,945 iteration 2169 : loss : 0.025901, loss_ce: 0.010993
2021-11-30 13:21:05,303 iteration 2170 : loss : 0.018030, loss_ce: 0.011652
2021-11-30 13:21:06,657 iteration 2171 : loss : 0.023992, loss_ce: 0.014784
2021-11-30 13:21:08,009 iteration 2172 : loss : 0.018475, loss_ce: 0.011437
2021-11-30 13:21:09,356 iteration 2173 : loss : 0.019637, loss_ce: 0.011432
2021-11-30 13:21:10,704 iteration 2174 : loss : 0.021732, loss_ce: 0.011013
2021-11-30 13:21:12,060 iteration 2175 : loss : 0.024772, loss_ce: 0.012381
2021-11-30 13:21:13,414 iteration 2176 : loss : 0.021006, loss_ce: 0.012341
 32%|█████████▎                   | 128/400 [53:52<1:50:18, 24.33s/it]2021-11-30 13:21:14,820 iteration 2177 : loss : 0.015751, loss_ce: 0.009351
2021-11-30 13:21:16,162 iteration 2178 : loss : 0.023633, loss_ce: 0.012381
2021-11-30 13:21:17,518 iteration 2179 : loss : 0.016181, loss_ce: 0.010099
2021-11-30 13:21:18,869 iteration 2180 : loss : 0.020520, loss_ce: 0.010961
2021-11-30 13:21:20,210 iteration 2181 : loss : 0.018590, loss_ce: 0.010480
2021-11-30 13:21:21,569 iteration 2182 : loss : 0.020261, loss_ce: 0.011367
2021-11-30 13:21:22,928 iteration 2183 : loss : 0.016433, loss_ce: 0.010993
2021-11-30 13:21:24,285 iteration 2184 : loss : 0.013705, loss_ce: 0.009524
2021-11-30 13:21:25,644 iteration 2185 : loss : 0.017304, loss_ce: 0.011034
2021-11-30 13:21:26,995 iteration 2186 : loss : 0.026143, loss_ce: 0.014987
2021-11-30 13:21:28,350 iteration 2187 : loss : 0.017634, loss_ce: 0.010862
2021-11-30 13:21:29,703 iteration 2188 : loss : 0.020940, loss_ce: 0.010436
2021-11-30 13:21:31,058 iteration 2189 : loss : 0.022297, loss_ce: 0.012314
2021-11-30 13:21:32,413 iteration 2190 : loss : 0.019056, loss_ce: 0.011947
2021-11-30 13:21:33,773 iteration 2191 : loss : 0.016561, loss_ce: 0.009529
2021-11-30 13:21:35,127 iteration 2192 : loss : 0.015263, loss_ce: 0.010026
2021-11-30 13:21:36,481 iteration 2193 : loss : 0.018823, loss_ce: 0.010553
 32%|█████████▎                   | 129/400 [54:15<1:48:11, 23.95s/it]2021-11-30 13:21:37,909 iteration 2194 : loss : 0.017449, loss_ce: 0.011311
2021-11-30 13:21:39,272 iteration 2195 : loss : 0.017131, loss_ce: 0.010803
2021-11-30 13:21:40,629 iteration 2196 : loss : 0.018531, loss_ce: 0.011603
2021-11-30 13:21:41,988 iteration 2197 : loss : 0.016400, loss_ce: 0.010078
2021-11-30 13:21:43,345 iteration 2198 : loss : 0.027015, loss_ce: 0.012587
2021-11-30 13:21:44,701 iteration 2199 : loss : 0.017470, loss_ce: 0.011801
2021-11-30 13:21:46,055 iteration 2200 : loss : 0.018789, loss_ce: 0.009906
2021-11-30 13:21:47,413 iteration 2201 : loss : 0.019512, loss_ce: 0.011455
2021-11-30 13:21:48,767 iteration 2202 : loss : 0.017893, loss_ce: 0.011370
2021-11-30 13:21:50,124 iteration 2203 : loss : 0.015446, loss_ce: 0.009930
2021-11-30 13:21:51,489 iteration 2204 : loss : 0.016911, loss_ce: 0.009783
2021-11-30 13:21:52,846 iteration 2205 : loss : 0.017979, loss_ce: 0.010524
2021-11-30 13:21:54,203 iteration 2206 : loss : 0.016690, loss_ce: 0.009759
2021-11-30 13:21:55,559 iteration 2207 : loss : 0.019677, loss_ce: 0.011533
2021-11-30 13:21:56,916 iteration 2208 : loss : 0.018870, loss_ce: 0.011737
2021-11-30 13:21:58,272 iteration 2209 : loss : 0.026461, loss_ce: 0.015425
2021-11-30 13:21:58,272 Training Data Eval:
2021-11-30 13:22:06,009   Average segmentation loss on training set: 0.0169
2021-11-30 13:22:06,009 Validation Data Eval:
2021-11-30 13:22:08,659   Average segmentation loss on validation set: 0.1767
2021-11-30 13:22:10,011 iteration 2210 : loss : 0.018127, loss_ce: 0.009973
 32%|█████████▍                   | 130/400 [54:48<2:00:42, 26.83s/it]2021-11-30 13:22:11,434 iteration 2211 : loss : 0.019808, loss_ce: 0.012813
2021-11-30 13:22:12,789 iteration 2212 : loss : 0.015904, loss_ce: 0.010812
2021-11-30 13:22:14,148 iteration 2213 : loss : 0.017895, loss_ce: 0.011731
2021-11-30 13:22:15,502 iteration 2214 : loss : 0.019307, loss_ce: 0.012383
2021-11-30 13:22:16,859 iteration 2215 : loss : 0.014858, loss_ce: 0.009648
2021-11-30 13:22:18,211 iteration 2216 : loss : 0.017872, loss_ce: 0.011002
2021-11-30 13:22:19,569 iteration 2217 : loss : 0.025432, loss_ce: 0.011794
2021-11-30 13:22:20,917 iteration 2218 : loss : 0.022594, loss_ce: 0.010242
2021-11-30 13:22:22,263 iteration 2219 : loss : 0.018692, loss_ce: 0.010562
2021-11-30 13:22:23,620 iteration 2220 : loss : 0.016408, loss_ce: 0.010068
2021-11-30 13:22:24,980 iteration 2221 : loss : 0.024251, loss_ce: 0.010978
2021-11-30 13:22:26,338 iteration 2222 : loss : 0.021263, loss_ce: 0.012704
2021-11-30 13:22:27,685 iteration 2223 : loss : 0.028601, loss_ce: 0.015817
2021-11-30 13:22:29,043 iteration 2224 : loss : 0.018897, loss_ce: 0.010260
2021-11-30 13:22:30,405 iteration 2225 : loss : 0.027545, loss_ce: 0.015153
2021-11-30 13:22:31,754 iteration 2226 : loss : 0.018577, loss_ce: 0.009390
2021-11-30 13:22:33,107 iteration 2227 : loss : 0.015523, loss_ce: 0.009914
 33%|█████████▍                   | 131/400 [55:11<1:55:14, 25.71s/it]2021-11-30 13:22:34,521 iteration 2228 : loss : 0.019573, loss_ce: 0.012222
2021-11-30 13:22:35,858 iteration 2229 : loss : 0.026659, loss_ce: 0.013120
2021-11-30 13:22:37,207 iteration 2230 : loss : 0.014998, loss_ce: 0.010260
2021-11-30 13:22:38,548 iteration 2231 : loss : 0.014692, loss_ce: 0.009546
2021-11-30 13:22:39,899 iteration 2232 : loss : 0.018033, loss_ce: 0.010253
2021-11-30 13:22:41,251 iteration 2233 : loss : 0.020215, loss_ce: 0.010914
2021-11-30 13:22:42,596 iteration 2234 : loss : 0.018892, loss_ce: 0.011266
2021-11-30 13:22:43,952 iteration 2235 : loss : 0.016351, loss_ce: 0.011580
2021-11-30 13:22:45,300 iteration 2236 : loss : 0.019638, loss_ce: 0.012686
2021-11-30 13:22:46,639 iteration 2237 : loss : 0.018976, loss_ce: 0.011071
2021-11-30 13:22:47,986 iteration 2238 : loss : 0.021282, loss_ce: 0.011898
2021-11-30 13:22:49,338 iteration 2239 : loss : 0.016251, loss_ce: 0.009447
2021-11-30 13:22:50,691 iteration 2240 : loss : 0.014701, loss_ce: 0.009451
2021-11-30 13:22:52,043 iteration 2241 : loss : 0.015449, loss_ce: 0.009952
2021-11-30 13:22:53,389 iteration 2242 : loss : 0.014563, loss_ce: 0.008557
2021-11-30 13:22:54,751 iteration 2243 : loss : 0.013949, loss_ce: 0.009452
2021-11-30 13:22:56,106 iteration 2244 : loss : 0.019693, loss_ce: 0.010531
 33%|█████████▌                   | 132/400 [55:34<1:51:11, 24.89s/it]2021-11-30 13:22:57,528 iteration 2245 : loss : 0.020216, loss_ce: 0.010685
2021-11-30 13:22:58,892 iteration 2246 : loss : 0.014983, loss_ce: 0.010047
2021-11-30 13:23:00,235 iteration 2247 : loss : 0.015363, loss_ce: 0.009598
2021-11-30 13:23:01,587 iteration 2248 : loss : 0.015752, loss_ce: 0.009702
2021-11-30 13:23:02,937 iteration 2249 : loss : 0.030140, loss_ce: 0.013338
2021-11-30 13:23:04,284 iteration 2250 : loss : 0.019028, loss_ce: 0.010372
2021-11-30 13:23:05,632 iteration 2251 : loss : 0.017833, loss_ce: 0.012322
2021-11-30 13:23:06,977 iteration 2252 : loss : 0.021937, loss_ce: 0.011017
2021-11-30 13:23:08,333 iteration 2253 : loss : 0.021990, loss_ce: 0.012083
2021-11-30 13:23:09,681 iteration 2254 : loss : 0.014922, loss_ce: 0.009764
2021-11-30 13:23:11,048 iteration 2255 : loss : 0.017676, loss_ce: 0.010059
2021-11-30 13:23:12,412 iteration 2256 : loss : 0.023679, loss_ce: 0.011843
2021-11-30 13:23:13,769 iteration 2257 : loss : 0.022245, loss_ce: 0.009251
2021-11-30 13:23:15,120 iteration 2258 : loss : 0.020051, loss_ce: 0.012606
2021-11-30 13:23:16,472 iteration 2259 : loss : 0.017159, loss_ce: 0.011694
2021-11-30 13:23:17,821 iteration 2260 : loss : 0.016447, loss_ce: 0.009450
2021-11-30 13:23:19,176 iteration 2261 : loss : 0.021946, loss_ce: 0.013570
 33%|█████████▋                   | 133/400 [55:57<1:48:20, 24.35s/it]2021-11-30 13:23:20,581 iteration 2262 : loss : 0.016576, loss_ce: 0.009461
2021-11-30 13:23:21,918 iteration 2263 : loss : 0.017579, loss_ce: 0.010718
2021-11-30 13:23:23,274 iteration 2264 : loss : 0.016556, loss_ce: 0.010641
2021-11-30 13:23:24,621 iteration 2265 : loss : 0.019840, loss_ce: 0.010742
2021-11-30 13:23:25,973 iteration 2266 : loss : 0.017106, loss_ce: 0.010593
2021-11-30 13:23:27,331 iteration 2267 : loss : 0.018542, loss_ce: 0.010309
2021-11-30 13:23:28,700 iteration 2268 : loss : 0.016015, loss_ce: 0.009906
2021-11-30 13:23:30,057 iteration 2269 : loss : 0.015384, loss_ce: 0.010591
2021-11-30 13:23:31,413 iteration 2270 : loss : 0.014277, loss_ce: 0.009307
2021-11-30 13:23:32,772 iteration 2271 : loss : 0.017883, loss_ce: 0.010165
2021-11-30 13:23:34,133 iteration 2272 : loss : 0.025020, loss_ce: 0.014771
2021-11-30 13:23:35,486 iteration 2273 : loss : 0.018173, loss_ce: 0.011825
2021-11-30 13:23:36,838 iteration 2274 : loss : 0.020991, loss_ce: 0.010744
2021-11-30 13:23:38,192 iteration 2275 : loss : 0.022664, loss_ce: 0.012468
2021-11-30 13:23:39,543 iteration 2276 : loss : 0.018952, loss_ce: 0.011656
2021-11-30 13:23:40,896 iteration 2277 : loss : 0.015467, loss_ce: 0.008871
2021-11-30 13:23:42,254 iteration 2278 : loss : 0.016093, loss_ce: 0.010537
 34%|█████████▋                   | 134/400 [56:20<1:46:15, 23.97s/it]2021-11-30 13:23:43,666 iteration 2279 : loss : 0.016403, loss_ce: 0.010411
2021-11-30 13:23:45,011 iteration 2280 : loss : 0.019999, loss_ce: 0.013326
2021-11-30 13:23:46,369 iteration 2281 : loss : 0.037738, loss_ce: 0.012075
2021-11-30 13:23:47,720 iteration 2282 : loss : 0.015657, loss_ce: 0.010212
2021-11-30 13:23:49,078 iteration 2283 : loss : 0.020892, loss_ce: 0.012886
2021-11-30 13:23:50,428 iteration 2284 : loss : 0.021690, loss_ce: 0.011789
2021-11-30 13:23:51,787 iteration 2285 : loss : 0.024747, loss_ce: 0.013030
2021-11-30 13:23:53,141 iteration 2286 : loss : 0.017646, loss_ce: 0.009830
2021-11-30 13:23:54,503 iteration 2287 : loss : 0.016394, loss_ce: 0.010671
2021-11-30 13:23:55,859 iteration 2288 : loss : 0.018274, loss_ce: 0.011279
2021-11-30 13:23:57,215 iteration 2289 : loss : 0.014466, loss_ce: 0.008996
2021-11-30 13:23:58,576 iteration 2290 : loss : 0.015107, loss_ce: 0.010206
2021-11-30 13:23:59,936 iteration 2291 : loss : 0.024936, loss_ce: 0.013403
2021-11-30 13:24:01,292 iteration 2292 : loss : 0.021066, loss_ce: 0.012732
2021-11-30 13:24:02,675 iteration 2293 : loss : 0.016455, loss_ce: 0.009622
2021-11-30 13:24:04,034 iteration 2294 : loss : 0.016757, loss_ce: 0.010211
2021-11-30 13:24:04,034 Training Data Eval:
2021-11-30 13:24:11,762   Average segmentation loss on training set: 0.0165
2021-11-30 13:24:11,762 Validation Data Eval:
2021-11-30 13:24:14,409   Average segmentation loss on validation set: 0.1516
2021-11-30 13:24:15,758 iteration 2295 : loss : 0.017630, loss_ce: 0.009992
 34%|█████████▊                   | 135/400 [56:54<1:58:29, 26.83s/it]2021-11-30 13:24:17,183 iteration 2296 : loss : 0.019178, loss_ce: 0.012162
2021-11-30 13:24:18,543 iteration 2297 : loss : 0.014216, loss_ce: 0.009211
2021-11-30 13:24:19,895 iteration 2298 : loss : 0.013075, loss_ce: 0.008678
2021-11-30 13:24:21,246 iteration 2299 : loss : 0.022280, loss_ce: 0.009594
2021-11-30 13:24:22,606 iteration 2300 : loss : 0.016956, loss_ce: 0.009550
2021-11-30 13:24:23,959 iteration 2301 : loss : 0.019406, loss_ce: 0.011024
2021-11-30 13:24:25,320 iteration 2302 : loss : 0.021667, loss_ce: 0.013920
2021-11-30 13:24:26,675 iteration 2303 : loss : 0.018043, loss_ce: 0.010535
2021-11-30 13:24:28,026 iteration 2304 : loss : 0.022673, loss_ce: 0.011393
2021-11-30 13:24:29,387 iteration 2305 : loss : 0.015878, loss_ce: 0.010232
2021-11-30 13:24:30,739 iteration 2306 : loss : 0.018419, loss_ce: 0.011114
2021-11-30 13:24:32,093 iteration 2307 : loss : 0.017673, loss_ce: 0.011602
2021-11-30 13:24:33,450 iteration 2308 : loss : 0.014750, loss_ce: 0.009353
2021-11-30 13:24:34,798 iteration 2309 : loss : 0.016246, loss_ce: 0.009610
2021-11-30 13:24:36,155 iteration 2310 : loss : 0.021116, loss_ce: 0.012721
2021-11-30 13:24:37,503 iteration 2311 : loss : 0.018060, loss_ce: 0.011107
2021-11-30 13:24:38,854 iteration 2312 : loss : 0.026777, loss_ce: 0.011224
 34%|█████████▊                   | 136/400 [57:17<1:53:07, 25.71s/it]2021-11-30 13:24:40,267 iteration 2313 : loss : 0.016912, loss_ce: 0.009880
2021-11-30 13:24:41,604 iteration 2314 : loss : 0.016758, loss_ce: 0.011822
2021-11-30 13:24:42,953 iteration 2315 : loss : 0.015284, loss_ce: 0.009605
2021-11-30 13:24:44,312 iteration 2316 : loss : 0.021725, loss_ce: 0.012524
2021-11-30 13:24:45,657 iteration 2317 : loss : 0.025180, loss_ce: 0.009977
2021-11-30 13:24:47,017 iteration 2318 : loss : 0.014745, loss_ce: 0.009415
2021-11-30 13:24:48,368 iteration 2319 : loss : 0.023358, loss_ce: 0.012738
2021-11-30 13:24:49,724 iteration 2320 : loss : 0.017360, loss_ce: 0.010518
2021-11-30 13:24:51,081 iteration 2321 : loss : 0.018441, loss_ce: 0.010485
2021-11-30 13:24:52,445 iteration 2322 : loss : 0.017450, loss_ce: 0.010827
2021-11-30 13:24:53,802 iteration 2323 : loss : 0.017919, loss_ce: 0.010107
2021-11-30 13:24:55,155 iteration 2324 : loss : 0.017231, loss_ce: 0.009790
2021-11-30 13:24:56,508 iteration 2325 : loss : 0.015759, loss_ce: 0.008719
2021-11-30 13:24:57,864 iteration 2326 : loss : 0.026173, loss_ce: 0.014329
2021-11-30 13:24:59,210 iteration 2327 : loss : 0.020625, loss_ce: 0.013406
2021-11-30 13:25:00,571 iteration 2328 : loss : 0.014401, loss_ce: 0.009347
2021-11-30 13:25:01,914 iteration 2329 : loss : 0.017335, loss_ce: 0.011549
 34%|█████████▉                   | 137/400 [57:40<1:49:12, 24.92s/it]2021-11-30 13:25:03,330 iteration 2330 : loss : 0.017440, loss_ce: 0.010039
2021-11-30 13:25:04,676 iteration 2331 : loss : 0.017450, loss_ce: 0.009452
2021-11-30 13:25:06,039 iteration 2332 : loss : 0.015673, loss_ce: 0.010438
2021-11-30 13:25:07,400 iteration 2333 : loss : 0.020724, loss_ce: 0.012972
2021-11-30 13:25:08,766 iteration 2334 : loss : 0.020585, loss_ce: 0.011343
2021-11-30 13:25:10,126 iteration 2335 : loss : 0.015961, loss_ce: 0.009959
2021-11-30 13:25:11,486 iteration 2336 : loss : 0.017143, loss_ce: 0.010158
2021-11-30 13:25:12,844 iteration 2337 : loss : 0.020928, loss_ce: 0.010955
2021-11-30 13:25:14,208 iteration 2338 : loss : 0.018025, loss_ce: 0.009520
2021-11-30 13:25:15,564 iteration 2339 : loss : 0.016655, loss_ce: 0.010772
2021-11-30 13:25:16,923 iteration 2340 : loss : 0.018295, loss_ce: 0.011527
2021-11-30 13:25:18,278 iteration 2341 : loss : 0.022468, loss_ce: 0.010595
2021-11-30 13:25:19,630 iteration 2342 : loss : 0.017148, loss_ce: 0.011022
2021-11-30 13:25:20,987 iteration 2343 : loss : 0.013541, loss_ce: 0.008972
2021-11-30 13:25:22,342 iteration 2344 : loss : 0.013965, loss_ce: 0.009387
2021-11-30 13:25:23,703 iteration 2345 : loss : 0.016647, loss_ce: 0.010061
2021-11-30 13:25:25,047 iteration 2346 : loss : 0.022122, loss_ce: 0.010544
 34%|██████████                   | 138/400 [58:03<1:46:27, 24.38s/it]2021-11-30 13:25:26,468 iteration 2347 : loss : 0.016018, loss_ce: 0.009458
2021-11-30 13:25:27,807 iteration 2348 : loss : 0.013420, loss_ce: 0.009108
2021-11-30 13:25:29,165 iteration 2349 : loss : 0.014627, loss_ce: 0.008695
2021-11-30 13:25:30,521 iteration 2350 : loss : 0.017692, loss_ce: 0.009866
2021-11-30 13:25:31,883 iteration 2351 : loss : 0.014820, loss_ce: 0.009778
2021-11-30 13:25:33,242 iteration 2352 : loss : 0.019209, loss_ce: 0.012189
2021-11-30 13:25:34,601 iteration 2353 : loss : 0.017182, loss_ce: 0.010356
2021-11-30 13:25:35,958 iteration 2354 : loss : 0.018660, loss_ce: 0.011240
2021-11-30 13:25:37,318 iteration 2355 : loss : 0.016523, loss_ce: 0.010989
2021-11-30 13:25:38,679 iteration 2356 : loss : 0.019040, loss_ce: 0.010576
2021-11-30 13:25:40,036 iteration 2357 : loss : 0.018096, loss_ce: 0.010140
2021-11-30 13:25:41,392 iteration 2358 : loss : 0.022433, loss_ce: 0.011683
2021-11-30 13:25:42,747 iteration 2359 : loss : 0.035697, loss_ce: 0.012694
2021-11-30 13:25:44,106 iteration 2360 : loss : 0.016045, loss_ce: 0.010650
2021-11-30 13:25:45,470 iteration 2361 : loss : 0.014783, loss_ce: 0.009159
2021-11-30 13:25:46,830 iteration 2362 : loss : 0.021485, loss_ce: 0.011984
2021-11-30 13:25:48,187 iteration 2363 : loss : 0.018011, loss_ce: 0.011771
 35%|██████████                   | 139/400 [58:26<1:44:26, 24.01s/it]2021-11-30 13:25:49,621 iteration 2364 : loss : 0.017457, loss_ce: 0.010186
2021-11-30 13:25:50,986 iteration 2365 : loss : 0.024981, loss_ce: 0.011927
2021-11-30 13:25:52,346 iteration 2366 : loss : 0.016570, loss_ce: 0.010842
2021-11-30 13:25:53,702 iteration 2367 : loss : 0.015005, loss_ce: 0.009921
2021-11-30 13:25:55,060 iteration 2368 : loss : 0.017952, loss_ce: 0.010018
2021-11-30 13:25:56,421 iteration 2369 : loss : 0.016463, loss_ce: 0.009085
2021-11-30 13:25:57,779 iteration 2370 : loss : 0.019624, loss_ce: 0.009812
2021-11-30 13:25:59,135 iteration 2371 : loss : 0.014479, loss_ce: 0.009627
2021-11-30 13:26:00,495 iteration 2372 : loss : 0.017418, loss_ce: 0.010537
2021-11-30 13:26:01,855 iteration 2373 : loss : 0.017589, loss_ce: 0.009550
2021-11-30 13:26:03,214 iteration 2374 : loss : 0.016727, loss_ce: 0.010173
2021-11-30 13:26:04,566 iteration 2375 : loss : 0.014164, loss_ce: 0.009159
2021-11-30 13:26:05,923 iteration 2376 : loss : 0.018679, loss_ce: 0.011813
2021-11-30 13:26:07,281 iteration 2377 : loss : 0.019228, loss_ce: 0.010202
2021-11-30 13:26:08,635 iteration 2378 : loss : 0.017824, loss_ce: 0.009723
2021-11-30 13:26:09,996 iteration 2379 : loss : 0.018944, loss_ce: 0.011280
2021-11-30 13:26:09,997 Training Data Eval:
2021-11-30 13:26:17,789   Average segmentation loss on training set: 0.0164
2021-11-30 13:26:17,789 Validation Data Eval:
2021-11-30 13:26:20,458   Average segmentation loss on validation set: 0.1749
2021-11-30 13:26:21,816 iteration 2380 : loss : 0.017025, loss_ce: 0.011387
 35%|██████████▏                  | 140/400 [59:00<1:56:32, 26.89s/it]2021-11-30 13:26:23,245 iteration 2381 : loss : 0.020730, loss_ce: 0.012922
2021-11-30 13:26:24,605 iteration 2382 : loss : 0.015782, loss_ce: 0.009737
2021-11-30 13:26:25,968 iteration 2383 : loss : 0.017066, loss_ce: 0.011440
2021-11-30 13:26:27,329 iteration 2384 : loss : 0.019946, loss_ce: 0.010374
2021-11-30 13:26:28,688 iteration 2385 : loss : 0.016057, loss_ce: 0.009070
2021-11-30 13:26:30,048 iteration 2386 : loss : 0.015695, loss_ce: 0.009012
2021-11-30 13:26:31,407 iteration 2387 : loss : 0.013496, loss_ce: 0.008624
2021-11-30 13:26:32,761 iteration 2388 : loss : 0.016674, loss_ce: 0.009611
2021-11-30 13:26:34,115 iteration 2389 : loss : 0.015138, loss_ce: 0.010176
2021-11-30 13:26:35,469 iteration 2390 : loss : 0.015169, loss_ce: 0.010483
2021-11-30 13:26:36,829 iteration 2391 : loss : 0.015881, loss_ce: 0.009635
2021-11-30 13:26:38,191 iteration 2392 : loss : 0.017967, loss_ce: 0.010913
2021-11-30 13:26:39,548 iteration 2393 : loss : 0.013456, loss_ce: 0.008631
2021-11-30 13:26:40,905 iteration 2394 : loss : 0.017817, loss_ce: 0.010320
2021-11-30 13:26:42,265 iteration 2395 : loss : 0.017507, loss_ce: 0.009741
2021-11-30 13:26:43,622 iteration 2396 : loss : 0.016744, loss_ce: 0.010786
2021-11-30 13:26:44,980 iteration 2397 : loss : 0.013596, loss_ce: 0.009160
 35%|██████████▏                  | 141/400 [59:23<1:51:15, 25.78s/it]2021-11-30 13:26:46,405 iteration 2398 : loss : 0.013347, loss_ce: 0.008825
2021-11-30 13:26:47,766 iteration 2399 : loss : 0.016393, loss_ce: 0.011179
2021-11-30 13:26:49,122 iteration 2400 : loss : 0.016074, loss_ce: 0.010471
2021-11-30 13:26:50,487 iteration 2401 : loss : 0.012443, loss_ce: 0.008614
2021-11-30 13:26:51,843 iteration 2402 : loss : 0.014842, loss_ce: 0.010123
2021-11-30 13:26:53,201 iteration 2403 : loss : 0.013382, loss_ce: 0.008905
2021-11-30 13:26:54,559 iteration 2404 : loss : 0.028863, loss_ce: 0.012219
2021-11-30 13:26:55,920 iteration 2405 : loss : 0.015813, loss_ce: 0.009740
2021-11-30 13:26:57,281 iteration 2406 : loss : 0.014318, loss_ce: 0.009433
2021-11-30 13:26:58,640 iteration 2407 : loss : 0.017709, loss_ce: 0.010148
2021-11-30 13:27:00,000 iteration 2408 : loss : 0.015007, loss_ce: 0.008271
2021-11-30 13:27:01,357 iteration 2409 : loss : 0.022124, loss_ce: 0.010223
2021-11-30 13:27:02,715 iteration 2410 : loss : 0.016551, loss_ce: 0.009332
2021-11-30 13:27:04,076 iteration 2411 : loss : 0.015293, loss_ce: 0.008787
2021-11-30 13:27:05,434 iteration 2412 : loss : 0.014134, loss_ce: 0.009907
2021-11-30 13:27:06,794 iteration 2413 : loss : 0.016963, loss_ce: 0.010882
2021-11-30 13:27:08,154 iteration 2414 : loss : 0.017142, loss_ce: 0.011580
 36%|██████████▎                  | 142/400 [59:46<1:47:28, 24.99s/it]2021-11-30 13:27:09,586 iteration 2415 : loss : 0.017718, loss_ce: 0.011114
2021-11-30 13:27:10,946 iteration 2416 : loss : 0.014795, loss_ce: 0.009757
2021-11-30 13:27:12,302 iteration 2417 : loss : 0.023735, loss_ce: 0.014768
2021-11-30 13:27:13,667 iteration 2418 : loss : 0.016174, loss_ce: 0.009691
2021-11-30 13:27:15,029 iteration 2419 : loss : 0.019345, loss_ce: 0.012613
2021-11-30 13:27:16,397 iteration 2420 : loss : 0.034711, loss_ce: 0.009978
2021-11-30 13:27:17,750 iteration 2421 : loss : 0.015104, loss_ce: 0.010000
2021-11-30 13:27:19,113 iteration 2422 : loss : 0.016513, loss_ce: 0.008689
2021-11-30 13:27:20,468 iteration 2423 : loss : 0.014895, loss_ce: 0.009177
2021-11-30 13:27:21,828 iteration 2424 : loss : 0.014889, loss_ce: 0.009467
2021-11-30 13:27:23,182 iteration 2425 : loss : 0.017276, loss_ce: 0.010408
2021-11-30 13:27:24,538 iteration 2426 : loss : 0.016964, loss_ce: 0.010160
2021-11-30 13:27:25,900 iteration 2427 : loss : 0.013250, loss_ce: 0.008675
2021-11-30 13:27:27,261 iteration 2428 : loss : 0.014765, loss_ce: 0.009570
2021-11-30 13:27:28,623 iteration 2429 : loss : 0.016044, loss_ce: 0.009842
2021-11-30 13:27:29,978 iteration 2430 : loss : 0.026241, loss_ce: 0.010601
2021-11-30 13:27:31,339 iteration 2431 : loss : 0.023645, loss_ce: 0.011554
 36%|█████████▋                 | 143/400 [1:00:09<1:44:43, 24.45s/it]2021-11-30 13:27:32,756 iteration 2432 : loss : 0.022288, loss_ce: 0.011836
2021-11-30 13:27:34,109 iteration 2433 : loss : 0.015040, loss_ce: 0.009451
2021-11-30 13:27:35,462 iteration 2434 : loss : 0.014824, loss_ce: 0.008829
2021-11-30 13:27:36,814 iteration 2435 : loss : 0.018965, loss_ce: 0.009577
2021-11-30 13:27:38,162 iteration 2436 : loss : 0.014043, loss_ce: 0.008304
2021-11-30 13:27:39,511 iteration 2437 : loss : 0.019465, loss_ce: 0.012378
2021-11-30 13:27:40,865 iteration 2438 : loss : 0.015186, loss_ce: 0.009389
2021-11-30 13:27:42,219 iteration 2439 : loss : 0.013835, loss_ce: 0.009209
2021-11-30 13:27:43,569 iteration 2440 : loss : 0.016094, loss_ce: 0.009175
2021-11-30 13:27:44,918 iteration 2441 : loss : 0.018025, loss_ce: 0.011494
2021-11-30 13:27:46,266 iteration 2442 : loss : 0.019828, loss_ce: 0.011884
2021-11-30 13:27:47,619 iteration 2443 : loss : 0.017642, loss_ce: 0.008983
2021-11-30 13:27:48,962 iteration 2444 : loss : 0.017970, loss_ce: 0.011232
2021-11-30 13:27:50,321 iteration 2445 : loss : 0.022756, loss_ce: 0.012755
2021-11-30 13:27:51,671 iteration 2446 : loss : 0.017412, loss_ce: 0.010882
2021-11-30 13:27:53,027 iteration 2447 : loss : 0.013142, loss_ce: 0.008403
2021-11-30 13:27:54,386 iteration 2448 : loss : 0.016484, loss_ce: 0.010914
 36%|█████████▋                 | 144/400 [1:00:33<1:42:31, 24.03s/it]2021-11-30 13:27:55,798 iteration 2449 : loss : 0.018298, loss_ce: 0.009753
2021-11-30 13:27:57,138 iteration 2450 : loss : 0.017517, loss_ce: 0.010831
2021-11-30 13:27:58,496 iteration 2451 : loss : 0.019647, loss_ce: 0.009806
2021-11-30 13:27:59,847 iteration 2452 : loss : 0.017472, loss_ce: 0.010628
2021-11-30 13:28:01,193 iteration 2453 : loss : 0.019689, loss_ce: 0.010087
2021-11-30 13:28:02,540 iteration 2454 : loss : 0.016144, loss_ce: 0.011080
2021-11-30 13:28:03,893 iteration 2455 : loss : 0.014395, loss_ce: 0.009067
2021-11-30 13:28:05,251 iteration 2456 : loss : 0.015069, loss_ce: 0.009392
2021-11-30 13:28:06,596 iteration 2457 : loss : 0.014441, loss_ce: 0.008854
2021-11-30 13:28:07,948 iteration 2458 : loss : 0.015517, loss_ce: 0.009678
2021-11-30 13:28:09,299 iteration 2459 : loss : 0.017580, loss_ce: 0.009027
2021-11-30 13:28:10,646 iteration 2460 : loss : 0.014918, loss_ce: 0.008976
2021-11-30 13:28:12,004 iteration 2461 : loss : 0.021810, loss_ce: 0.012479
2021-11-30 13:28:13,355 iteration 2462 : loss : 0.015043, loss_ce: 0.009466
2021-11-30 13:28:14,713 iteration 2463 : loss : 0.014620, loss_ce: 0.009044
2021-11-30 13:28:16,068 iteration 2464 : loss : 0.016585, loss_ce: 0.011361
2021-11-30 13:28:16,068 Training Data Eval:
2021-11-30 13:28:23,823   Average segmentation loss on training set: 0.0142
2021-11-30 13:28:23,823 Validation Data Eval:
2021-11-30 13:28:27,708   Average segmentation loss on validation set: 0.1615
2021-11-30 13:28:28,970 iteration 2465 : loss : 0.013844, loss_ce: 0.008350
 36%|█████████▊                 | 145/400 [1:01:07<1:55:34, 27.20s/it]2021-11-30 13:28:30,326 iteration 2466 : loss : 0.014981, loss_ce: 0.009960
2021-11-30 13:28:31,674 iteration 2467 : loss : 0.018403, loss_ce: 0.010573
2021-11-30 13:28:33,034 iteration 2468 : loss : 0.020341, loss_ce: 0.013118
2021-11-30 13:28:34,397 iteration 2469 : loss : 0.019739, loss_ce: 0.010525
2021-11-30 13:28:35,761 iteration 2470 : loss : 0.019232, loss_ce: 0.009998
2021-11-30 13:28:37,121 iteration 2471 : loss : 0.013941, loss_ce: 0.009669
2021-11-30 13:28:38,479 iteration 2472 : loss : 0.015696, loss_ce: 0.010253
2021-11-30 13:28:39,837 iteration 2473 : loss : 0.015825, loss_ce: 0.008834
2021-11-30 13:28:41,179 iteration 2474 : loss : 0.014752, loss_ce: 0.009666
2021-11-30 13:28:42,540 iteration 2475 : loss : 0.016627, loss_ce: 0.008755
2021-11-30 13:28:43,890 iteration 2476 : loss : 0.019352, loss_ce: 0.009396
2021-11-30 13:28:45,237 iteration 2477 : loss : 0.014612, loss_ce: 0.009856
2021-11-30 13:28:46,591 iteration 2478 : loss : 0.015165, loss_ce: 0.009911
2021-11-30 13:28:47,938 iteration 2479 : loss : 0.015647, loss_ce: 0.009802
2021-11-30 13:28:49,299 iteration 2480 : loss : 0.015221, loss_ce: 0.009347
2021-11-30 13:28:50,645 iteration 2481 : loss : 0.014671, loss_ce: 0.008849
2021-11-30 13:28:51,992 iteration 2482 : loss : 0.018403, loss_ce: 0.010896
 36%|█████████▊                 | 146/400 [1:01:30<1:49:49, 25.94s/it]2021-11-30 13:28:53,406 iteration 2483 : loss : 0.013923, loss_ce: 0.008184
2021-11-30 13:28:54,754 iteration 2484 : loss : 0.015910, loss_ce: 0.010533
2021-11-30 13:28:56,113 iteration 2485 : loss : 0.021054, loss_ce: 0.009736
2021-11-30 13:28:57,456 iteration 2486 : loss : 0.014517, loss_ce: 0.008855
2021-11-30 13:28:58,799 iteration 2487 : loss : 0.018175, loss_ce: 0.009264
2021-11-30 13:29:00,160 iteration 2488 : loss : 0.018125, loss_ce: 0.009906
2021-11-30 13:29:01,512 iteration 2489 : loss : 0.016098, loss_ce: 0.010428
2021-11-30 13:29:02,847 iteration 2490 : loss : 0.017213, loss_ce: 0.010729
2021-11-30 13:29:04,199 iteration 2491 : loss : 0.016487, loss_ce: 0.009170
2021-11-30 13:29:05,542 iteration 2492 : loss : 0.016276, loss_ce: 0.010169
2021-11-30 13:29:06,895 iteration 2493 : loss : 0.014367, loss_ce: 0.008904
2021-11-30 13:29:08,252 iteration 2494 : loss : 0.015326, loss_ce: 0.008938
2021-11-30 13:29:09,609 iteration 2495 : loss : 0.015078, loss_ce: 0.010092
2021-11-30 13:29:10,960 iteration 2496 : loss : 0.017312, loss_ce: 0.010640
2021-11-30 13:29:12,308 iteration 2497 : loss : 0.016310, loss_ce: 0.011185
2021-11-30 13:29:13,662 iteration 2498 : loss : 0.017047, loss_ce: 0.011110
2021-11-30 13:29:15,012 iteration 2499 : loss : 0.017242, loss_ce: 0.010787
 37%|█████████▉                 | 147/400 [1:01:53<1:45:42, 25.07s/it]2021-11-30 13:29:16,439 iteration 2500 : loss : 0.014413, loss_ce: 0.009314
2021-11-30 13:29:17,790 iteration 2501 : loss : 0.014854, loss_ce: 0.009174
2021-11-30 13:29:19,139 iteration 2502 : loss : 0.018166, loss_ce: 0.011393
2021-11-30 13:29:20,494 iteration 2503 : loss : 0.014627, loss_ce: 0.009204
2021-11-30 13:29:21,846 iteration 2504 : loss : 0.014123, loss_ce: 0.009063
2021-11-30 13:29:23,195 iteration 2505 : loss : 0.012454, loss_ce: 0.008360
2021-11-30 13:29:24,547 iteration 2506 : loss : 0.014486, loss_ce: 0.010023
2021-11-30 13:29:25,899 iteration 2507 : loss : 0.014719, loss_ce: 0.009506
2021-11-30 13:29:27,259 iteration 2508 : loss : 0.016137, loss_ce: 0.010035
2021-11-30 13:29:28,618 iteration 2509 : loss : 0.013341, loss_ce: 0.009039
2021-11-30 13:29:29,974 iteration 2510 : loss : 0.012282, loss_ce: 0.008417
2021-11-30 13:29:31,332 iteration 2511 : loss : 0.014703, loss_ce: 0.008900
2021-11-30 13:29:32,688 iteration 2512 : loss : 0.013309, loss_ce: 0.009081
2021-11-30 13:29:34,038 iteration 2513 : loss : 0.014347, loss_ce: 0.009301
2021-11-30 13:29:35,392 iteration 2514 : loss : 0.014520, loss_ce: 0.008679
2021-11-30 13:29:36,745 iteration 2515 : loss : 0.013075, loss_ce: 0.008413
2021-11-30 13:29:38,098 iteration 2516 : loss : 0.014598, loss_ce: 0.008703
 37%|█████████▉                 | 148/400 [1:02:16<1:42:47, 24.47s/it]2021-11-30 13:29:39,508 iteration 2517 : loss : 0.013616, loss_ce: 0.008687
2021-11-30 13:29:40,842 iteration 2518 : loss : 0.013162, loss_ce: 0.008980
2021-11-30 13:29:42,190 iteration 2519 : loss : 0.013118, loss_ce: 0.008635
2021-11-30 13:29:43,547 iteration 2520 : loss : 0.014438, loss_ce: 0.008860
2021-11-30 13:29:44,895 iteration 2521 : loss : 0.017204, loss_ce: 0.010664
2021-11-30 13:29:46,255 iteration 2522 : loss : 0.014004, loss_ce: 0.008846
2021-11-30 13:29:47,612 iteration 2523 : loss : 0.014094, loss_ce: 0.009471
2021-11-30 13:29:48,969 iteration 2524 : loss : 0.018413, loss_ce: 0.009441
2021-11-30 13:29:50,319 iteration 2525 : loss : 0.017191, loss_ce: 0.011273
2021-11-30 13:29:51,669 iteration 2526 : loss : 0.015193, loss_ce: 0.009650
2021-11-30 13:29:53,019 iteration 2527 : loss : 0.012831, loss_ce: 0.008689
2021-11-30 13:29:54,363 iteration 2528 : loss : 0.015550, loss_ce: 0.008724
2021-11-30 13:29:55,706 iteration 2529 : loss : 0.015459, loss_ce: 0.009029
2021-11-30 13:29:57,063 iteration 2530 : loss : 0.021409, loss_ce: 0.013389
2021-11-30 13:29:58,418 iteration 2531 : loss : 0.015368, loss_ce: 0.008983
2021-11-30 13:29:59,765 iteration 2532 : loss : 0.019896, loss_ce: 0.011619
2021-11-30 13:30:01,096 iteration 2533 : loss : 0.014215, loss_ce: 0.008838
 37%|██████████                 | 149/400 [1:02:39<1:40:31, 24.03s/it]2021-11-30 13:30:02,507 iteration 2534 : loss : 0.019706, loss_ce: 0.009352
2021-11-30 13:30:03,859 iteration 2535 : loss : 0.018629, loss_ce: 0.009986
2021-11-30 13:30:05,222 iteration 2536 : loss : 0.011811, loss_ce: 0.008288
2021-11-30 13:30:06,566 iteration 2537 : loss : 0.020745, loss_ce: 0.011148
2021-11-30 13:30:07,917 iteration 2538 : loss : 0.015059, loss_ce: 0.008918
2021-11-30 13:30:09,263 iteration 2539 : loss : 0.014770, loss_ce: 0.010524
2021-11-30 13:30:10,620 iteration 2540 : loss : 0.024681, loss_ce: 0.013843
2021-11-30 13:30:11,968 iteration 2541 : loss : 0.013708, loss_ce: 0.008507
2021-11-30 13:30:13,318 iteration 2542 : loss : 0.013274, loss_ce: 0.008807
2021-11-30 13:30:14,665 iteration 2543 : loss : 0.014078, loss_ce: 0.009616
2021-11-30 13:30:16,014 iteration 2544 : loss : 0.014467, loss_ce: 0.009265
2021-11-30 13:30:17,368 iteration 2545 : loss : 0.017628, loss_ce: 0.010402
2021-11-30 13:30:18,720 iteration 2546 : loss : 0.012920, loss_ce: 0.009184
2021-11-30 13:30:20,058 iteration 2547 : loss : 0.016848, loss_ce: 0.008390
2021-11-30 13:30:21,407 iteration 2548 : loss : 0.016658, loss_ce: 0.009095
2021-11-30 13:30:22,768 iteration 2549 : loss : 0.020133, loss_ce: 0.009125
2021-11-30 13:30:22,769 Training Data Eval:
2021-11-30 13:30:30,479   Average segmentation loss on training set: 0.0130
2021-11-30 13:30:30,479 Validation Data Eval:
2021-11-30 13:30:33,141   Average segmentation loss on validation set: 0.1622
2021-11-30 13:30:34,504 iteration 2550 : loss : 0.013013, loss_ce: 0.008522
 38%|██████████▏                | 150/400 [1:03:13<1:51:51, 26.84s/it]2021-11-30 13:30:35,940 iteration 2551 : loss : 0.013932, loss_ce: 0.008997
2021-11-30 13:30:37,301 iteration 2552 : loss : 0.015691, loss_ce: 0.010071
2021-11-30 13:30:38,661 iteration 2553 : loss : 0.022423, loss_ce: 0.014789
2021-11-30 13:30:40,027 iteration 2554 : loss : 0.017006, loss_ce: 0.008999
2021-11-30 13:30:41,389 iteration 2555 : loss : 0.013433, loss_ce: 0.008837
2021-11-30 13:30:42,752 iteration 2556 : loss : 0.015099, loss_ce: 0.010233
2021-11-30 13:30:44,112 iteration 2557 : loss : 0.017200, loss_ce: 0.010172
2021-11-30 13:30:45,475 iteration 2558 : loss : 0.012073, loss_ce: 0.008266
2021-11-30 13:30:46,837 iteration 2559 : loss : 0.015308, loss_ce: 0.009654
2021-11-30 13:30:48,197 iteration 2560 : loss : 0.018454, loss_ce: 0.009307
2021-11-30 13:30:49,562 iteration 2561 : loss : 0.015673, loss_ce: 0.008626
2021-11-30 13:30:50,918 iteration 2562 : loss : 0.015207, loss_ce: 0.009586
2021-11-30 13:30:52,278 iteration 2563 : loss : 0.014584, loss_ce: 0.010130
2021-11-30 13:30:53,635 iteration 2564 : loss : 0.015079, loss_ce: 0.008765
2021-11-30 13:30:54,994 iteration 2565 : loss : 0.014234, loss_ce: 0.008738
2021-11-30 13:30:56,360 iteration 2566 : loss : 0.015170, loss_ce: 0.009391
2021-11-30 13:30:57,717 iteration 2567 : loss : 0.019827, loss_ce: 0.009598
 38%|██████████▏                | 151/400 [1:03:36<1:46:52, 25.75s/it]2021-11-30 13:30:59,131 iteration 2568 : loss : 0.013020, loss_ce: 0.008868
2021-11-30 13:31:00,494 iteration 2569 : loss : 0.016271, loss_ce: 0.010391
2021-11-30 13:31:01,856 iteration 2570 : loss : 0.011398, loss_ce: 0.007759
2021-11-30 13:31:03,219 iteration 2571 : loss : 0.012208, loss_ce: 0.008510
2021-11-30 13:31:04,582 iteration 2572 : loss : 0.018319, loss_ce: 0.008871
2021-11-30 13:31:05,938 iteration 2573 : loss : 0.018129, loss_ce: 0.010686
2021-11-30 13:31:07,294 iteration 2574 : loss : 0.017854, loss_ce: 0.010161
2021-11-30 13:31:08,652 iteration 2575 : loss : 0.018887, loss_ce: 0.011035
2021-11-30 13:31:10,013 iteration 2576 : loss : 0.016760, loss_ce: 0.010795
2021-11-30 13:31:11,371 iteration 2577 : loss : 0.014725, loss_ce: 0.009663
2021-11-30 13:31:12,729 iteration 2578 : loss : 0.013503, loss_ce: 0.009624
2021-11-30 13:31:14,084 iteration 2579 : loss : 0.015720, loss_ce: 0.009607
2021-11-30 13:31:15,443 iteration 2580 : loss : 0.018418, loss_ce: 0.008525
2021-11-30 13:31:16,803 iteration 2581 : loss : 0.013310, loss_ce: 0.008122
2021-11-30 13:31:18,159 iteration 2582 : loss : 0.016446, loss_ce: 0.009414
2021-11-30 13:31:19,513 iteration 2583 : loss : 0.014794, loss_ce: 0.008893
2021-11-30 13:31:20,872 iteration 2584 : loss : 0.017851, loss_ce: 0.010851
 38%|██████████▎                | 152/400 [1:03:59<1:43:13, 24.97s/it]2021-11-30 13:31:22,276 iteration 2585 : loss : 0.015781, loss_ce: 0.009410
2021-11-30 13:31:23,615 iteration 2586 : loss : 0.012754, loss_ce: 0.008427
2021-11-30 13:31:24,978 iteration 2587 : loss : 0.014500, loss_ce: 0.009115
2021-11-30 13:31:26,333 iteration 2588 : loss : 0.014116, loss_ce: 0.008861
2021-11-30 13:31:27,694 iteration 2589 : loss : 0.021417, loss_ce: 0.010827
2021-11-30 13:31:29,053 iteration 2590 : loss : 0.019046, loss_ce: 0.011463
2021-11-30 13:31:30,407 iteration 2591 : loss : 0.013351, loss_ce: 0.008701
2021-11-30 13:31:31,755 iteration 2592 : loss : 0.014031, loss_ce: 0.008928
2021-11-30 13:31:33,115 iteration 2593 : loss : 0.015363, loss_ce: 0.008373
2021-11-30 13:31:34,462 iteration 2594 : loss : 0.014005, loss_ce: 0.008698
2021-11-30 13:31:35,818 iteration 2595 : loss : 0.012661, loss_ce: 0.009054
2021-11-30 13:31:37,169 iteration 2596 : loss : 0.019915, loss_ce: 0.013230
2021-11-30 13:31:38,509 iteration 2597 : loss : 0.023727, loss_ce: 0.009578
2021-11-30 13:31:39,851 iteration 2598 : loss : 0.012514, loss_ce: 0.008698
2021-11-30 13:31:41,205 iteration 2599 : loss : 0.012687, loss_ce: 0.008354
2021-11-30 13:31:42,562 iteration 2600 : loss : 0.012366, loss_ce: 0.008779
2021-11-30 13:31:43,914 iteration 2601 : loss : 0.013491, loss_ce: 0.008478
 38%|██████████▎                | 153/400 [1:04:22<1:40:25, 24.40s/it]2021-11-30 13:31:45,324 iteration 2602 : loss : 0.017785, loss_ce: 0.011091
2021-11-30 13:31:46,677 iteration 2603 : loss : 0.016515, loss_ce: 0.009355
2021-11-30 13:31:48,018 iteration 2604 : loss : 0.015697, loss_ce: 0.009462
2021-11-30 13:31:49,372 iteration 2605 : loss : 0.021550, loss_ce: 0.013719
2021-11-30 13:31:50,732 iteration 2606 : loss : 0.019017, loss_ce: 0.011535
2021-11-30 13:31:52,084 iteration 2607 : loss : 0.014779, loss_ce: 0.008017
2021-11-30 13:31:53,438 iteration 2608 : loss : 0.025913, loss_ce: 0.010072
2021-11-30 13:31:54,786 iteration 2609 : loss : 0.015725, loss_ce: 0.009990
2021-11-30 13:31:56,129 iteration 2610 : loss : 0.014226, loss_ce: 0.008256
2021-11-30 13:31:57,488 iteration 2611 : loss : 0.014545, loss_ce: 0.009883
2021-11-30 13:31:58,830 iteration 2612 : loss : 0.017203, loss_ce: 0.008770
2021-11-30 13:32:00,187 iteration 2613 : loss : 0.015630, loss_ce: 0.009566
2021-11-30 13:32:01,533 iteration 2614 : loss : 0.019372, loss_ce: 0.013849
2021-11-30 13:32:02,881 iteration 2615 : loss : 0.020909, loss_ce: 0.009659
2021-11-30 13:32:04,231 iteration 2616 : loss : 0.016573, loss_ce: 0.008777
2021-11-30 13:32:05,578 iteration 2617 : loss : 0.012907, loss_ce: 0.008771
2021-11-30 13:32:06,934 iteration 2618 : loss : 0.017854, loss_ce: 0.010645
 38%|██████████▍                | 154/400 [1:04:45<1:38:19, 23.98s/it]2021-11-30 13:32:08,346 iteration 2619 : loss : 0.018893, loss_ce: 0.008954
2021-11-30 13:32:09,683 iteration 2620 : loss : 0.011433, loss_ce: 0.007633
2021-11-30 13:32:11,037 iteration 2621 : loss : 0.020374, loss_ce: 0.010931
2021-11-30 13:32:12,391 iteration 2622 : loss : 0.014692, loss_ce: 0.009746
2021-11-30 13:32:13,739 iteration 2623 : loss : 0.016780, loss_ce: 0.010294
2021-11-30 13:32:15,092 iteration 2624 : loss : 0.016921, loss_ce: 0.009511
2021-11-30 13:32:16,447 iteration 2625 : loss : 0.014593, loss_ce: 0.008830
2021-11-30 13:32:17,805 iteration 2626 : loss : 0.014780, loss_ce: 0.010310
2021-11-30 13:32:19,156 iteration 2627 : loss : 0.015421, loss_ce: 0.008858
2021-11-30 13:32:20,503 iteration 2628 : loss : 0.015080, loss_ce: 0.008827
2021-11-30 13:32:21,859 iteration 2629 : loss : 0.014720, loss_ce: 0.009440
2021-11-30 13:32:23,209 iteration 2630 : loss : 0.014666, loss_ce: 0.008943
2021-11-30 13:32:24,559 iteration 2631 : loss : 0.015221, loss_ce: 0.009066
2021-11-30 13:32:25,908 iteration 2632 : loss : 0.012710, loss_ce: 0.008695
2021-11-30 13:32:27,257 iteration 2633 : loss : 0.017385, loss_ce: 0.010378
2021-11-30 13:32:28,614 iteration 2634 : loss : 0.013753, loss_ce: 0.009366
2021-11-30 13:32:28,614 Training Data Eval:
2021-11-30 13:32:36,233   Average segmentation loss on training set: 0.0139
2021-11-30 13:32:36,233 Validation Data Eval:
2021-11-30 13:32:38,839   Average segmentation loss on validation set: 0.1734
2021-11-30 13:32:40,193 iteration 2635 : loss : 0.017466, loss_ce: 0.009473
 39%|██████████▍                | 155/400 [1:05:18<1:49:17, 26.77s/it]2021-11-30 13:32:41,618 iteration 2636 : loss : 0.013674, loss_ce: 0.009144
2021-11-30 13:32:42,977 iteration 2637 : loss : 0.015877, loss_ce: 0.010655
2021-11-30 13:32:44,321 iteration 2638 : loss : 0.012634, loss_ce: 0.008439
2021-11-30 13:32:45,677 iteration 2639 : loss : 0.015013, loss_ce: 0.009021
2021-11-30 13:32:47,036 iteration 2640 : loss : 0.014392, loss_ce: 0.008592
2021-11-30 13:32:48,388 iteration 2641 : loss : 0.019744, loss_ce: 0.009317
2021-11-30 13:32:49,750 iteration 2642 : loss : 0.012131, loss_ce: 0.008510
2021-11-30 13:32:51,101 iteration 2643 : loss : 0.018971, loss_ce: 0.009555
2021-11-30 13:32:52,458 iteration 2644 : loss : 0.011974, loss_ce: 0.008125
2021-11-30 13:32:53,812 iteration 2645 : loss : 0.011643, loss_ce: 0.007726
2021-11-30 13:32:55,170 iteration 2646 : loss : 0.016574, loss_ce: 0.010529
2021-11-30 13:32:56,530 iteration 2647 : loss : 0.017652, loss_ce: 0.009960
2021-11-30 13:32:57,888 iteration 2648 : loss : 0.011995, loss_ce: 0.008175
2021-11-30 13:32:59,244 iteration 2649 : loss : 0.012398, loss_ce: 0.008160
2021-11-30 13:33:00,602 iteration 2650 : loss : 0.014200, loss_ce: 0.009121
2021-11-30 13:33:01,959 iteration 2651 : loss : 0.011217, loss_ce: 0.007815
2021-11-30 13:33:03,321 iteration 2652 : loss : 0.015851, loss_ce: 0.010705
 39%|██████████▌                | 156/400 [1:05:41<1:44:24, 25.67s/it]2021-11-30 13:33:04,745 iteration 2653 : loss : 0.015663, loss_ce: 0.008386
2021-11-30 13:33:06,093 iteration 2654 : loss : 0.019201, loss_ce: 0.009739
2021-11-30 13:33:07,444 iteration 2655 : loss : 0.020038, loss_ce: 0.011490
2021-11-30 13:33:08,798 iteration 2656 : loss : 0.012724, loss_ce: 0.007687
2021-11-30 13:33:10,145 iteration 2657 : loss : 0.014967, loss_ce: 0.009586
2021-11-30 13:33:11,500 iteration 2658 : loss : 0.012581, loss_ce: 0.007781
2021-11-30 13:33:12,855 iteration 2659 : loss : 0.013239, loss_ce: 0.008469
2021-11-30 13:33:14,209 iteration 2660 : loss : 0.015436, loss_ce: 0.010556
2021-11-30 13:33:15,572 iteration 2661 : loss : 0.017301, loss_ce: 0.011668
2021-11-30 13:33:16,926 iteration 2662 : loss : 0.013730, loss_ce: 0.008367
2021-11-30 13:33:18,275 iteration 2663 : loss : 0.016780, loss_ce: 0.010343
2021-11-30 13:33:19,632 iteration 2664 : loss : 0.014030, loss_ce: 0.008496
2021-11-30 13:33:20,980 iteration 2665 : loss : 0.013020, loss_ce: 0.008558
2021-11-30 13:33:22,323 iteration 2666 : loss : 0.016392, loss_ce: 0.010749
2021-11-30 13:33:23,673 iteration 2667 : loss : 0.014457, loss_ce: 0.008795
2021-11-30 13:33:25,031 iteration 2668 : loss : 0.012642, loss_ce: 0.008331
2021-11-30 13:33:26,382 iteration 2669 : loss : 0.012162, loss_ce: 0.007858
 39%|██████████▌                | 157/400 [1:06:05<1:40:48, 24.89s/it]2021-11-30 13:33:27,801 iteration 2670 : loss : 0.013311, loss_ce: 0.009136
2021-11-30 13:33:29,143 iteration 2671 : loss : 0.021393, loss_ce: 0.009188
2021-11-30 13:33:30,502 iteration 2672 : loss : 0.014001, loss_ce: 0.009938
2021-11-30 13:33:31,852 iteration 2673 : loss : 0.015269, loss_ce: 0.008875
2021-11-30 13:33:33,201 iteration 2674 : loss : 0.012552, loss_ce: 0.008345
2021-11-30 13:33:34,554 iteration 2675 : loss : 0.014629, loss_ce: 0.009691
2021-11-30 13:33:35,910 iteration 2676 : loss : 0.013434, loss_ce: 0.009934
2021-11-30 13:33:37,265 iteration 2677 : loss : 0.012601, loss_ce: 0.008141
2021-11-30 13:33:38,609 iteration 2678 : loss : 0.014518, loss_ce: 0.008421
2021-11-30 13:33:39,945 iteration 2679 : loss : 0.012811, loss_ce: 0.007858
2021-11-30 13:33:41,299 iteration 2680 : loss : 0.015875, loss_ce: 0.008403
2021-11-30 13:33:42,661 iteration 2681 : loss : 0.014239, loss_ce: 0.009571
2021-11-30 13:33:44,015 iteration 2682 : loss : 0.013223, loss_ce: 0.008129
2021-11-30 13:33:45,371 iteration 2683 : loss : 0.013950, loss_ce: 0.008390
2021-11-30 13:33:46,732 iteration 2684 : loss : 0.011576, loss_ce: 0.007643
2021-11-30 13:33:48,090 iteration 2685 : loss : 0.017001, loss_ce: 0.008314
2021-11-30 13:33:49,443 iteration 2686 : loss : 0.020300, loss_ce: 0.012717
 40%|██████████▋                | 158/400 [1:06:28<1:38:10, 24.34s/it]2021-11-30 13:33:50,860 iteration 2687 : loss : 0.016172, loss_ce: 0.008155
2021-11-30 13:33:52,219 iteration 2688 : loss : 0.013337, loss_ce: 0.008826
2021-11-30 13:33:53,574 iteration 2689 : loss : 0.012835, loss_ce: 0.007901
2021-11-30 13:33:54,929 iteration 2690 : loss : 0.012841, loss_ce: 0.008448
2021-11-30 13:33:56,287 iteration 2691 : loss : 0.013529, loss_ce: 0.008121
2021-11-30 13:33:57,634 iteration 2692 : loss : 0.019180, loss_ce: 0.011528
2021-11-30 13:33:58,991 iteration 2693 : loss : 0.012598, loss_ce: 0.008187
2021-11-30 13:34:00,339 iteration 2694 : loss : 0.013523, loss_ce: 0.009306
2021-11-30 13:34:01,697 iteration 2695 : loss : 0.015435, loss_ce: 0.010242
2021-11-30 13:34:03,056 iteration 2696 : loss : 0.019392, loss_ce: 0.011177
2021-11-30 13:34:04,411 iteration 2697 : loss : 0.013324, loss_ce: 0.008409
2021-11-30 13:34:05,762 iteration 2698 : loss : 0.017020, loss_ce: 0.011114
2021-11-30 13:34:07,107 iteration 2699 : loss : 0.013833, loss_ce: 0.008004
2021-11-30 13:34:08,460 iteration 2700 : loss : 0.011783, loss_ce: 0.007808
2021-11-30 13:34:09,819 iteration 2701 : loss : 0.011367, loss_ce: 0.008008
2021-11-30 13:34:11,165 iteration 2702 : loss : 0.013501, loss_ce: 0.008120
2021-11-30 13:34:12,507 iteration 2703 : loss : 0.013673, loss_ce: 0.008148
 40%|██████████▋                | 159/400 [1:06:51<1:36:13, 23.96s/it]2021-11-30 13:34:13,927 iteration 2704 : loss : 0.011194, loss_ce: 0.007764
2021-11-30 13:34:15,283 iteration 2705 : loss : 0.014657, loss_ce: 0.009404
2021-11-30 13:34:16,638 iteration 2706 : loss : 0.014523, loss_ce: 0.010542
2021-11-30 13:34:17,998 iteration 2707 : loss : 0.014912, loss_ce: 0.009515
2021-11-30 13:34:19,342 iteration 2708 : loss : 0.013162, loss_ce: 0.008606
2021-11-30 13:34:20,690 iteration 2709 : loss : 0.011197, loss_ce: 0.008176
2021-11-30 13:34:22,033 iteration 2710 : loss : 0.015768, loss_ce: 0.008472
2021-11-30 13:34:23,373 iteration 2711 : loss : 0.012752, loss_ce: 0.008107
2021-11-30 13:34:24,722 iteration 2712 : loss : 0.018228, loss_ce: 0.010491
2021-11-30 13:34:26,080 iteration 2713 : loss : 0.016800, loss_ce: 0.009755
2021-11-30 13:34:27,432 iteration 2714 : loss : 0.016665, loss_ce: 0.009809
2021-11-30 13:34:28,782 iteration 2715 : loss : 0.010723, loss_ce: 0.007086
2021-11-30 13:34:30,135 iteration 2716 : loss : 0.012738, loss_ce: 0.007734
2021-11-30 13:34:31,477 iteration 2717 : loss : 0.011629, loss_ce: 0.007489
2021-11-30 13:34:32,825 iteration 2718 : loss : 0.016622, loss_ce: 0.011144
2021-11-30 13:34:34,184 iteration 2719 : loss : 0.013425, loss_ce: 0.008858
2021-11-30 13:34:34,185 Training Data Eval:
2021-11-30 13:34:41,796   Average segmentation loss on training set: 0.0152
2021-11-30 13:34:41,796 Validation Data Eval:
2021-11-30 13:34:44,432   Average segmentation loss on validation set: 0.1364
2021-11-30 13:34:46,369 Found new lowest validation loss at iteration 2719! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/UNET_RUNMC/best_val_loss_no_da.pth
2021-11-30 13:34:47,614 iteration 2720 : loss : 0.014314, loss_ce: 0.007663
 40%|██████████▊                | 160/400 [1:07:26<1:49:13, 27.30s/it]2021-11-30 13:34:48,911 iteration 2721 : loss : 0.014166, loss_ce: 0.008890
2021-11-30 13:34:50,150 iteration 2722 : loss : 0.018882, loss_ce: 0.008333
2021-11-30 13:34:51,465 iteration 2723 : loss : 0.013871, loss_ce: 0.009422
2021-11-30 13:34:52,815 iteration 2724 : loss : 0.013508, loss_ce: 0.009464
2021-11-30 13:34:54,162 iteration 2725 : loss : 0.012169, loss_ce: 0.007840
2021-11-30 13:34:55,508 iteration 2726 : loss : 0.019544, loss_ce: 0.009187
2021-11-30 13:34:56,861 iteration 2727 : loss : 0.012380, loss_ce: 0.007790
2021-11-30 13:34:58,204 iteration 2728 : loss : 0.017238, loss_ce: 0.008444
2021-11-30 13:34:59,561 iteration 2729 : loss : 0.021291, loss_ce: 0.011343
2021-11-30 13:35:00,899 iteration 2730 : loss : 0.015665, loss_ce: 0.009241
2021-11-30 13:35:02,256 iteration 2731 : loss : 0.017205, loss_ce: 0.009756
2021-11-30 13:35:03,607 iteration 2732 : loss : 0.019684, loss_ce: 0.013493
2021-11-30 13:35:04,959 iteration 2733 : loss : 0.022597, loss_ce: 0.013308
2021-11-30 13:35:06,315 iteration 2734 : loss : 0.013171, loss_ce: 0.008710
2021-11-30 13:35:07,668 iteration 2735 : loss : 0.017771, loss_ce: 0.010833
2021-11-30 13:35:09,019 iteration 2736 : loss : 0.012606, loss_ce: 0.008314
2021-11-30 13:35:10,369 iteration 2737 : loss : 0.015092, loss_ce: 0.008703
 40%|██████████▊                | 161/400 [1:07:48<1:43:18, 25.94s/it]2021-11-30 13:35:11,777 iteration 2738 : loss : 0.018141, loss_ce: 0.009070
2021-11-30 13:35:13,127 iteration 2739 : loss : 0.011243, loss_ce: 0.007333
2021-11-30 13:35:14,488 iteration 2740 : loss : 0.015074, loss_ce: 0.008754
2021-11-30 13:35:15,845 iteration 2741 : loss : 0.017483, loss_ce: 0.009941
2021-11-30 13:35:17,192 iteration 2742 : loss : 0.013991, loss_ce: 0.008869
2021-11-30 13:35:18,544 iteration 2743 : loss : 0.014289, loss_ce: 0.009690
2021-11-30 13:35:19,891 iteration 2744 : loss : 0.019333, loss_ce: 0.009924
2021-11-30 13:35:21,247 iteration 2745 : loss : 0.015864, loss_ce: 0.009197
2021-11-30 13:35:22,602 iteration 2746 : loss : 0.014001, loss_ce: 0.008432
2021-11-30 13:35:23,952 iteration 2747 : loss : 0.014796, loss_ce: 0.008246
2021-11-30 13:35:25,301 iteration 2748 : loss : 0.016941, loss_ce: 0.008720
2021-11-30 13:35:26,650 iteration 2749 : loss : 0.016288, loss_ce: 0.009167
2021-11-30 13:35:27,998 iteration 2750 : loss : 0.016116, loss_ce: 0.011048
2021-11-30 13:35:29,348 iteration 2751 : loss : 0.011459, loss_ce: 0.007849
2021-11-30 13:35:30,705 iteration 2752 : loss : 0.014287, loss_ce: 0.008838
2021-11-30 13:35:32,056 iteration 2753 : loss : 0.016574, loss_ce: 0.009459
2021-11-30 13:35:33,416 iteration 2754 : loss : 0.016938, loss_ce: 0.011037
 40%|██████████▉                | 162/400 [1:08:12<1:39:26, 25.07s/it]2021-11-30 13:35:34,826 iteration 2755 : loss : 0.013356, loss_ce: 0.007970
2021-11-30 13:35:36,167 iteration 2756 : loss : 0.011983, loss_ce: 0.007769
2021-11-30 13:35:37,522 iteration 2757 : loss : 0.014172, loss_ce: 0.008392
2021-11-30 13:35:38,877 iteration 2758 : loss : 0.015688, loss_ce: 0.008692
2021-11-30 13:35:40,225 iteration 2759 : loss : 0.011344, loss_ce: 0.008566
2021-11-30 13:35:41,589 iteration 2760 : loss : 0.013872, loss_ce: 0.008610
2021-11-30 13:35:42,942 iteration 2761 : loss : 0.012342, loss_ce: 0.008651
2021-11-30 13:35:44,286 iteration 2762 : loss : 0.017982, loss_ce: 0.009942
2021-11-30 13:35:45,640 iteration 2763 : loss : 0.020010, loss_ce: 0.009572
2021-11-30 13:35:46,988 iteration 2764 : loss : 0.015886, loss_ce: 0.008455
2021-11-30 13:35:48,341 iteration 2765 : loss : 0.014274, loss_ce: 0.009749
2021-11-30 13:35:49,684 iteration 2766 : loss : 0.012283, loss_ce: 0.008009
2021-11-30 13:35:51,036 iteration 2767 : loss : 0.011583, loss_ce: 0.008012
2021-11-30 13:35:52,392 iteration 2768 : loss : 0.011855, loss_ce: 0.007672
2021-11-30 13:35:53,746 iteration 2769 : loss : 0.016190, loss_ce: 0.009274
2021-11-30 13:35:55,110 iteration 2770 : loss : 0.017043, loss_ce: 0.010178
2021-11-30 13:35:56,468 iteration 2771 : loss : 0.010875, loss_ce: 0.008148
 41%|███████████                | 163/400 [1:08:35<1:36:38, 24.47s/it]2021-11-30 13:35:57,892 iteration 2772 : loss : 0.016257, loss_ce: 0.007703
2021-11-30 13:35:59,256 iteration 2773 : loss : 0.013435, loss_ce: 0.009492
2021-11-30 13:36:00,618 iteration 2774 : loss : 0.013554, loss_ce: 0.008859
2021-11-30 13:36:01,977 iteration 2775 : loss : 0.014013, loss_ce: 0.009103
2021-11-30 13:36:03,338 iteration 2776 : loss : 0.013946, loss_ce: 0.008189
2021-11-30 13:36:04,690 iteration 2777 : loss : 0.016602, loss_ce: 0.008594
2021-11-30 13:36:06,047 iteration 2778 : loss : 0.013666, loss_ce: 0.008142
2021-11-30 13:36:07,405 iteration 2779 : loss : 0.015377, loss_ce: 0.009647
2021-11-30 13:36:08,771 iteration 2780 : loss : 0.011239, loss_ce: 0.008004
2021-11-30 13:36:10,128 iteration 2781 : loss : 0.012416, loss_ce: 0.009013
2021-11-30 13:36:11,519 iteration 2782 : loss : 0.012213, loss_ce: 0.007482
2021-11-30 13:36:12,877 iteration 2783 : loss : 0.014105, loss_ce: 0.009628
2021-11-30 13:36:14,234 iteration 2784 : loss : 0.014084, loss_ce: 0.008729
2021-11-30 13:36:15,595 iteration 2785 : loss : 0.014958, loss_ce: 0.008842
2021-11-30 13:36:16,956 iteration 2786 : loss : 0.012125, loss_ce: 0.009034
2021-11-30 13:36:18,313 iteration 2787 : loss : 0.013416, loss_ce: 0.007608
2021-11-30 13:36:19,676 iteration 2788 : loss : 0.017004, loss_ce: 0.008332
 41%|███████████                | 164/400 [1:08:58<1:34:44, 24.09s/it]2021-11-30 13:36:21,091 iteration 2789 : loss : 0.012863, loss_ce: 0.008654
2021-11-30 13:36:22,440 iteration 2790 : loss : 0.013347, loss_ce: 0.008361
2021-11-30 13:36:23,800 iteration 2791 : loss : 0.015634, loss_ce: 0.008055
2021-11-30 13:36:25,152 iteration 2792 : loss : 0.013266, loss_ce: 0.008861
2021-11-30 13:36:26,512 iteration 2793 : loss : 0.011311, loss_ce: 0.007869
2021-11-30 13:36:27,866 iteration 2794 : loss : 0.011205, loss_ce: 0.007775
2021-11-30 13:36:29,223 iteration 2795 : loss : 0.014888, loss_ce: 0.008444
2021-11-30 13:36:30,578 iteration 2796 : loss : 0.015032, loss_ce: 0.009038
2021-11-30 13:36:31,938 iteration 2797 : loss : 0.013797, loss_ce: 0.008745
2021-11-30 13:36:33,293 iteration 2798 : loss : 0.017737, loss_ce: 0.011133
2021-11-30 13:36:34,648 iteration 2799 : loss : 0.012958, loss_ce: 0.008025
2021-11-30 13:36:36,007 iteration 2800 : loss : 0.013583, loss_ce: 0.008070
2021-11-30 13:36:37,359 iteration 2801 : loss : 0.011659, loss_ce: 0.008313
2021-11-30 13:36:38,717 iteration 2802 : loss : 0.014941, loss_ce: 0.008301
2021-11-30 13:36:40,074 iteration 2803 : loss : 0.017221, loss_ce: 0.008492
2021-11-30 13:36:41,430 iteration 2804 : loss : 0.015920, loss_ce: 0.009453
2021-11-30 13:36:41,430 Training Data Eval:
2021-11-30 13:36:49,134   Average segmentation loss on training set: 0.0127
2021-11-30 13:36:49,134 Validation Data Eval:
2021-11-30 13:36:51,788   Average segmentation loss on validation set: 0.1492
2021-11-30 13:36:53,130 iteration 2805 : loss : 0.015331, loss_ce: 0.009804
 41%|███████████▏               | 165/400 [1:09:31<1:45:20, 26.90s/it]2021-11-30 13:36:54,552 iteration 2806 : loss : 0.013796, loss_ce: 0.008390
2021-11-30 13:36:55,904 iteration 2807 : loss : 0.016171, loss_ce: 0.009654
2021-11-30 13:36:57,262 iteration 2808 : loss : 0.012774, loss_ce: 0.008606
2021-11-30 13:36:58,608 iteration 2809 : loss : 0.014403, loss_ce: 0.009331
2021-11-30 13:36:59,960 iteration 2810 : loss : 0.013323, loss_ce: 0.007789
2021-11-30 13:37:01,309 iteration 2811 : loss : 0.011443, loss_ce: 0.007640
2021-11-30 13:37:02,659 iteration 2812 : loss : 0.014309, loss_ce: 0.009476
2021-11-30 13:37:04,003 iteration 2813 : loss : 0.019042, loss_ce: 0.008470
2021-11-30 13:37:05,355 iteration 2814 : loss : 0.013931, loss_ce: 0.008974
2021-11-30 13:37:06,705 iteration 2815 : loss : 0.014109, loss_ce: 0.007636
2021-11-30 13:37:08,047 iteration 2816 : loss : 0.020382, loss_ce: 0.012729
2021-11-30 13:37:09,403 iteration 2817 : loss : 0.013450, loss_ce: 0.008745
2021-11-30 13:37:10,756 iteration 2818 : loss : 0.013938, loss_ce: 0.008103
2021-11-30 13:37:12,103 iteration 2819 : loss : 0.015757, loss_ce: 0.010324
2021-11-30 13:37:13,441 iteration 2820 : loss : 0.013568, loss_ce: 0.007672
2021-11-30 13:37:14,790 iteration 2821 : loss : 0.011696, loss_ce: 0.007508
2021-11-30 13:37:16,140 iteration 2822 : loss : 0.013289, loss_ce: 0.008740
 42%|███████████▏               | 166/400 [1:09:54<1:40:21, 25.73s/it]2021-11-30 13:37:17,551 iteration 2823 : loss : 0.013288, loss_ce: 0.008597
2021-11-30 13:37:18,905 iteration 2824 : loss : 0.017560, loss_ce: 0.008926
2021-11-30 13:37:20,253 iteration 2825 : loss : 0.012483, loss_ce: 0.008021
2021-11-30 13:37:21,606 iteration 2826 : loss : 0.013115, loss_ce: 0.008158
2021-11-30 13:37:22,956 iteration 2827 : loss : 0.011713, loss_ce: 0.008305
2021-11-30 13:37:24,308 iteration 2828 : loss : 0.016396, loss_ce: 0.009599
2021-11-30 13:37:25,655 iteration 2829 : loss : 0.011883, loss_ce: 0.007899
2021-11-30 13:37:27,009 iteration 2830 : loss : 0.013174, loss_ce: 0.008543
2021-11-30 13:37:28,359 iteration 2831 : loss : 0.013793, loss_ce: 0.008307
2021-11-30 13:37:29,716 iteration 2832 : loss : 0.012889, loss_ce: 0.008022
2021-11-30 13:37:31,062 iteration 2833 : loss : 0.012550, loss_ce: 0.008972
2021-11-30 13:37:32,408 iteration 2834 : loss : 0.017373, loss_ce: 0.009604
2021-11-30 13:37:33,762 iteration 2835 : loss : 0.012284, loss_ce: 0.007916
2021-11-30 13:37:35,114 iteration 2836 : loss : 0.014193, loss_ce: 0.008544
2021-11-30 13:37:36,468 iteration 2837 : loss : 0.019748, loss_ce: 0.008114
2021-11-30 13:37:37,826 iteration 2838 : loss : 0.014027, loss_ce: 0.009531
2021-11-30 13:37:39,178 iteration 2839 : loss : 0.013235, loss_ce: 0.007835
 42%|███████████▎               | 167/400 [1:10:17<1:36:46, 24.92s/it]2021-11-30 13:37:40,592 iteration 2840 : loss : 0.015120, loss_ce: 0.010683
2021-11-30 13:37:41,947 iteration 2841 : loss : 0.010991, loss_ce: 0.007878
2021-11-30 13:37:43,292 iteration 2842 : loss : 0.018356, loss_ce: 0.009148
2021-11-30 13:37:44,657 iteration 2843 : loss : 0.019413, loss_ce: 0.010178
2021-11-30 13:37:46,017 iteration 2844 : loss : 0.011820, loss_ce: 0.008046
2021-11-30 13:37:47,372 iteration 2845 : loss : 0.022469, loss_ce: 0.012205
2021-11-30 13:37:48,713 iteration 2846 : loss : 0.011404, loss_ce: 0.007692
2021-11-30 13:37:50,067 iteration 2847 : loss : 0.014393, loss_ce: 0.009084
2021-11-30 13:37:51,430 iteration 2848 : loss : 0.011394, loss_ce: 0.007764
2021-11-30 13:37:52,784 iteration 2849 : loss : 0.012514, loss_ce: 0.007878
2021-11-30 13:37:54,141 iteration 2850 : loss : 0.012792, loss_ce: 0.008433
2021-11-30 13:37:55,496 iteration 2851 : loss : 0.013412, loss_ce: 0.008218
2021-11-30 13:37:56,833 iteration 2852 : loss : 0.013630, loss_ce: 0.008289
2021-11-30 13:37:58,183 iteration 2853 : loss : 0.011136, loss_ce: 0.007183
2021-11-30 13:37:59,526 iteration 2854 : loss : 0.012796, loss_ce: 0.008320
2021-11-30 13:38:00,884 iteration 2855 : loss : 0.010902, loss_ce: 0.007489
2021-11-30 13:38:02,239 iteration 2856 : loss : 0.013997, loss_ce: 0.008481
 42%|███████████▎               | 168/400 [1:10:40<1:34:12, 24.37s/it]2021-11-30 13:38:03,643 iteration 2857 : loss : 0.012340, loss_ce: 0.008079
2021-11-30 13:38:04,983 iteration 2858 : loss : 0.017349, loss_ce: 0.008854
2021-11-30 13:38:06,341 iteration 2859 : loss : 0.013766, loss_ce: 0.009810
2021-11-30 13:38:07,692 iteration 2860 : loss : 0.014847, loss_ce: 0.010097
2021-11-30 13:38:09,051 iteration 2861 : loss : 0.012781, loss_ce: 0.008228
2021-11-30 13:38:10,395 iteration 2862 : loss : 0.015983, loss_ce: 0.009904
2021-11-30 13:38:11,746 iteration 2863 : loss : 0.017594, loss_ce: 0.007701
2021-11-30 13:38:13,104 iteration 2864 : loss : 0.014890, loss_ce: 0.008246
2021-11-30 13:38:14,446 iteration 2865 : loss : 0.012123, loss_ce: 0.008172
2021-11-30 13:38:15,800 iteration 2866 : loss : 0.012764, loss_ce: 0.007463
2021-11-30 13:38:17,149 iteration 2867 : loss : 0.015103, loss_ce: 0.009698
2021-11-30 13:38:18,495 iteration 2868 : loss : 0.011650, loss_ce: 0.007869
2021-11-30 13:38:19,852 iteration 2869 : loss : 0.013429, loss_ce: 0.008710
2021-11-30 13:38:21,211 iteration 2870 : loss : 0.014054, loss_ce: 0.008810
2021-11-30 13:38:22,566 iteration 2871 : loss : 0.014272, loss_ce: 0.008019
2021-11-30 13:38:23,919 iteration 2872 : loss : 0.013202, loss_ce: 0.007880
2021-11-30 13:38:25,266 iteration 2873 : loss : 0.014179, loss_ce: 0.008433
 42%|███████████▍               | 169/400 [1:11:03<1:32:15, 23.96s/it]2021-11-30 13:38:26,672 iteration 2874 : loss : 0.012361, loss_ce: 0.008398
2021-11-30 13:38:28,010 iteration 2875 : loss : 0.016693, loss_ce: 0.007983
2021-11-30 13:38:29,356 iteration 2876 : loss : 0.014102, loss_ce: 0.009495
2021-11-30 13:38:30,712 iteration 2877 : loss : 0.013693, loss_ce: 0.008415
2021-11-30 13:38:32,065 iteration 2878 : loss : 0.019080, loss_ce: 0.011491
2021-11-30 13:38:33,419 iteration 2879 : loss : 0.011461, loss_ce: 0.007764
2021-11-30 13:38:34,769 iteration 2880 : loss : 0.011769, loss_ce: 0.007379
2021-11-30 13:38:36,128 iteration 2881 : loss : 0.012680, loss_ce: 0.007841
2021-11-30 13:38:37,486 iteration 2882 : loss : 0.013817, loss_ce: 0.008172
2021-11-30 13:38:38,838 iteration 2883 : loss : 0.011852, loss_ce: 0.007732
2021-11-30 13:38:40,193 iteration 2884 : loss : 0.015294, loss_ce: 0.008934
2021-11-30 13:38:41,550 iteration 2885 : loss : 0.011313, loss_ce: 0.007515
2021-11-30 13:38:42,902 iteration 2886 : loss : 0.015133, loss_ce: 0.009600
2021-11-30 13:38:44,258 iteration 2887 : loss : 0.014307, loss_ce: 0.008536
2021-11-30 13:38:45,610 iteration 2888 : loss : 0.015790, loss_ce: 0.008585
2021-11-30 13:38:46,948 iteration 2889 : loss : 0.010485, loss_ce: 0.007105
2021-11-30 13:38:46,948 Training Data Eval:
2021-11-30 13:38:54,567   Average segmentation loss on training set: 0.0114
2021-11-30 13:38:54,567 Validation Data Eval:
2021-11-30 13:38:57,196   Average segmentation loss on validation set: 0.1602
2021-11-30 13:38:58,540 iteration 2890 : loss : 0.013346, loss_ce: 0.009080
 42%|███████████▍               | 170/400 [1:11:37<1:42:34, 26.76s/it]2021-11-30 13:38:59,959 iteration 2891 : loss : 0.013871, loss_ce: 0.009215
2021-11-30 13:39:01,309 iteration 2892 : loss : 0.012480, loss_ce: 0.007424
2021-11-30 13:39:02,663 iteration 2893 : loss : 0.015543, loss_ce: 0.009259
2021-11-30 13:39:04,010 iteration 2894 : loss : 0.014600, loss_ce: 0.007879
2021-11-30 13:39:05,364 iteration 2895 : loss : 0.012442, loss_ce: 0.008811
2021-11-30 13:39:06,704 iteration 2896 : loss : 0.010959, loss_ce: 0.006766
2021-11-30 13:39:08,063 iteration 2897 : loss : 0.012503, loss_ce: 0.007487
2021-11-30 13:39:09,408 iteration 2898 : loss : 0.012292, loss_ce: 0.008276
2021-11-30 13:39:10,743 iteration 2899 : loss : 0.013980, loss_ce: 0.008093
2021-11-30 13:39:12,093 iteration 2900 : loss : 0.019642, loss_ce: 0.013079
2021-11-30 13:39:13,440 iteration 2901 : loss : 0.014319, loss_ce: 0.008603
2021-11-30 13:39:14,789 iteration 2902 : loss : 0.014991, loss_ce: 0.008040
2021-11-30 13:39:16,142 iteration 2903 : loss : 0.014002, loss_ce: 0.009024
2021-11-30 13:39:17,500 iteration 2904 : loss : 0.013868, loss_ce: 0.008094
2021-11-30 13:39:18,861 iteration 2905 : loss : 0.012540, loss_ce: 0.007819
2021-11-30 13:39:20,209 iteration 2906 : loss : 0.014410, loss_ce: 0.009221
2021-11-30 13:39:21,551 iteration 2907 : loss : 0.017627, loss_ce: 0.011272
 43%|███████████▌               | 171/400 [1:12:00<1:37:49, 25.63s/it]2021-11-30 13:39:22,952 iteration 2908 : loss : 0.014639, loss_ce: 0.009932
2021-11-30 13:39:24,299 iteration 2909 : loss : 0.029741, loss_ce: 0.010194
2021-11-30 13:39:25,661 iteration 2910 : loss : 0.010226, loss_ce: 0.007328
2021-11-30 13:39:27,008 iteration 2911 : loss : 0.012580, loss_ce: 0.008153
2021-11-30 13:39:28,353 iteration 2912 : loss : 0.012062, loss_ce: 0.008296
2021-11-30 13:39:29,712 iteration 2913 : loss : 0.011972, loss_ce: 0.007300
2021-11-30 13:39:31,066 iteration 2914 : loss : 0.016145, loss_ce: 0.009007
2021-11-30 13:39:32,420 iteration 2915 : loss : 0.021237, loss_ce: 0.012649
2021-11-30 13:39:33,765 iteration 2916 : loss : 0.011236, loss_ce: 0.007620
2021-11-30 13:39:35,112 iteration 2917 : loss : 0.011341, loss_ce: 0.008271
2021-11-30 13:39:36,472 iteration 2918 : loss : 0.013035, loss_ce: 0.007921
2021-11-30 13:39:37,819 iteration 2919 : loss : 0.016857, loss_ce: 0.007906
2021-11-30 13:39:39,180 iteration 2920 : loss : 0.013313, loss_ce: 0.008824
2021-11-30 13:39:40,531 iteration 2921 : loss : 0.021386, loss_ce: 0.011026
2021-11-30 13:39:41,878 iteration 2922 : loss : 0.012656, loss_ce: 0.007902
2021-11-30 13:39:43,238 iteration 2923 : loss : 0.013613, loss_ce: 0.007967
2021-11-30 13:39:44,600 iteration 2924 : loss : 0.012163, loss_ce: 0.008328
 43%|███████████▌               | 172/400 [1:12:23<1:34:27, 24.86s/it]2021-11-30 13:39:46,025 iteration 2925 : loss : 0.011648, loss_ce: 0.007012
2021-11-30 13:39:47,382 iteration 2926 : loss : 0.012151, loss_ce: 0.008170
2021-11-30 13:39:48,737 iteration 2927 : loss : 0.016817, loss_ce: 0.008682
2021-11-30 13:39:50,098 iteration 2928 : loss : 0.012367, loss_ce: 0.008242
2021-11-30 13:39:51,463 iteration 2929 : loss : 0.012091, loss_ce: 0.008340
2021-11-30 13:39:52,815 iteration 2930 : loss : 0.011840, loss_ce: 0.008506
2021-11-30 13:39:54,172 iteration 2931 : loss : 0.013772, loss_ce: 0.009330
2021-11-30 13:39:55,531 iteration 2932 : loss : 0.014299, loss_ce: 0.008542
2021-11-30 13:39:56,889 iteration 2933 : loss : 0.013997, loss_ce: 0.008263
2021-11-30 13:39:58,248 iteration 2934 : loss : 0.015095, loss_ce: 0.009637
2021-11-30 13:39:59,610 iteration 2935 : loss : 0.022534, loss_ce: 0.009872
2021-11-30 13:40:00,970 iteration 2936 : loss : 0.017827, loss_ce: 0.008275
2021-11-30 13:40:02,323 iteration 2937 : loss : 0.016846, loss_ce: 0.008536
2021-11-30 13:40:03,683 iteration 2938 : loss : 0.014464, loss_ce: 0.008548
2021-11-30 13:40:05,036 iteration 2939 : loss : 0.011018, loss_ce: 0.007467
2021-11-30 13:40:06,397 iteration 2940 : loss : 0.016537, loss_ce: 0.009582
2021-11-30 13:40:07,760 iteration 2941 : loss : 0.018438, loss_ce: 0.010251
 43%|███████████▋               | 173/400 [1:12:46<1:32:06, 24.35s/it]2021-11-30 13:40:09,184 iteration 2942 : loss : 0.017887, loss_ce: 0.011006
2021-11-30 13:40:10,548 iteration 2943 : loss : 0.015080, loss_ce: 0.007819
2021-11-30 13:40:11,911 iteration 2944 : loss : 0.011741, loss_ce: 0.007618
2021-11-30 13:40:13,271 iteration 2945 : loss : 0.012456, loss_ce: 0.007638
2021-11-30 13:40:14,625 iteration 2946 : loss : 0.011746, loss_ce: 0.007890
2021-11-30 13:40:15,985 iteration 2947 : loss : 0.012029, loss_ce: 0.007990
2021-11-30 13:40:17,347 iteration 2948 : loss : 0.011666, loss_ce: 0.007234
2021-11-30 13:40:18,704 iteration 2949 : loss : 0.013250, loss_ce: 0.008710
2021-11-30 13:40:20,060 iteration 2950 : loss : 0.011556, loss_ce: 0.007515
2021-11-30 13:40:21,420 iteration 2951 : loss : 0.015784, loss_ce: 0.009706
2021-11-30 13:40:22,783 iteration 2952 : loss : 0.011451, loss_ce: 0.007699
2021-11-30 13:40:24,143 iteration 2953 : loss : 0.020357, loss_ce: 0.008767
2021-11-30 13:40:25,507 iteration 2954 : loss : 0.013201, loss_ce: 0.008063
2021-11-30 13:40:26,869 iteration 2955 : loss : 0.012156, loss_ce: 0.007869
2021-11-30 13:40:28,227 iteration 2956 : loss : 0.012401, loss_ce: 0.007933
2021-11-30 13:40:29,587 iteration 2957 : loss : 0.016435, loss_ce: 0.010515
2021-11-30 13:40:30,952 iteration 2958 : loss : 0.013048, loss_ce: 0.007835
 44%|███████████▋               | 174/400 [1:13:09<1:30:24, 24.00s/it]2021-11-30 13:40:32,377 iteration 2959 : loss : 0.011115, loss_ce: 0.007180
2021-11-30 13:40:33,736 iteration 2960 : loss : 0.016147, loss_ce: 0.010067
2021-11-30 13:40:35,096 iteration 2961 : loss : 0.013797, loss_ce: 0.008212
2021-11-30 13:40:36,457 iteration 2962 : loss : 0.013149, loss_ce: 0.007519
2021-11-30 13:40:37,817 iteration 2963 : loss : 0.011940, loss_ce: 0.007361
2021-11-30 13:40:39,173 iteration 2964 : loss : 0.014234, loss_ce: 0.009319
2021-11-30 13:40:40,532 iteration 2965 : loss : 0.015820, loss_ce: 0.008838
2021-11-30 13:40:41,896 iteration 2966 : loss : 0.012563, loss_ce: 0.007904
2021-11-30 13:40:43,259 iteration 2967 : loss : 0.011765, loss_ce: 0.007923
2021-11-30 13:40:44,616 iteration 2968 : loss : 0.011741, loss_ce: 0.007210
2021-11-30 13:40:45,975 iteration 2969 : loss : 0.010724, loss_ce: 0.007536
2021-11-30 13:40:47,328 iteration 2970 : loss : 0.013595, loss_ce: 0.008418
2021-11-30 13:40:48,689 iteration 2971 : loss : 0.011173, loss_ce: 0.007004
2021-11-30 13:40:50,054 iteration 2972 : loss : 0.014151, loss_ce: 0.008245
2021-11-30 13:40:51,413 iteration 2973 : loss : 0.014441, loss_ce: 0.009199
2021-11-30 13:40:52,784 iteration 2974 : loss : 0.012216, loss_ce: 0.008473
2021-11-30 13:40:52,784 Training Data Eval:
2021-11-30 13:41:00,479   Average segmentation loss on training set: 0.0132
2021-11-30 13:41:00,480 Validation Data Eval:
2021-11-30 13:41:03,133   Average segmentation loss on validation set: 0.1423
2021-11-30 13:41:04,471 iteration 2975 : loss : 0.009098, loss_ce: 0.006785
 44%|███████████▊               | 175/400 [1:13:43<1:40:42, 26.86s/it]2021-11-30 13:41:05,888 iteration 2976 : loss : 0.011111, loss_ce: 0.007617
2021-11-30 13:41:07,243 iteration 2977 : loss : 0.014145, loss_ce: 0.007417
2021-11-30 13:41:08,609 iteration 2978 : loss : 0.011360, loss_ce: 0.007044
2021-11-30 13:41:09,962 iteration 2979 : loss : 0.011431, loss_ce: 0.008138
2021-11-30 13:41:11,317 iteration 2980 : loss : 0.016191, loss_ce: 0.010256
2021-11-30 13:41:12,674 iteration 2981 : loss : 0.019015, loss_ce: 0.010091
2021-11-30 13:41:14,035 iteration 2982 : loss : 0.010153, loss_ce: 0.007488
2021-11-30 13:41:15,392 iteration 2983 : loss : 0.012999, loss_ce: 0.008968
2021-11-30 13:41:16,742 iteration 2984 : loss : 0.017812, loss_ce: 0.009321
2021-11-30 13:41:18,101 iteration 2985 : loss : 0.010989, loss_ce: 0.007473
2021-11-30 13:41:19,461 iteration 2986 : loss : 0.011446, loss_ce: 0.007955
2021-11-30 13:41:20,821 iteration 2987 : loss : 0.016347, loss_ce: 0.008799
2021-11-30 13:41:22,179 iteration 2988 : loss : 0.011472, loss_ce: 0.007412
2021-11-30 13:41:23,526 iteration 2989 : loss : 0.016215, loss_ce: 0.008143
2021-11-30 13:41:24,880 iteration 2990 : loss : 0.015113, loss_ce: 0.010311
2021-11-30 13:41:26,238 iteration 2991 : loss : 0.012678, loss_ce: 0.007205
2021-11-30 13:41:27,582 iteration 2992 : loss : 0.010159, loss_ce: 0.006634
 44%|███████████▉               | 176/400 [1:14:06<1:36:06, 25.74s/it]2021-11-30 13:41:29,029 iteration 2993 : loss : 0.017526, loss_ce: 0.008500
2021-11-30 13:41:30,375 iteration 2994 : loss : 0.016003, loss_ce: 0.010271
2021-11-30 13:41:31,725 iteration 2995 : loss : 0.014637, loss_ce: 0.008862
2021-11-30 13:41:33,083 iteration 2996 : loss : 0.016134, loss_ce: 0.007916
2021-11-30 13:41:34,438 iteration 2997 : loss : 0.016892, loss_ce: 0.010401
2021-11-30 13:41:35,795 iteration 2998 : loss : 0.014242, loss_ce: 0.008653
2021-11-30 13:41:37,158 iteration 2999 : loss : 0.015114, loss_ce: 0.008027
2021-11-30 13:41:38,523 iteration 3000 : loss : 0.012262, loss_ce: 0.008160
2021-11-30 13:41:39,887 iteration 3001 : loss : 0.012201, loss_ce: 0.008444
2021-11-30 13:41:41,242 iteration 3002 : loss : 0.011389, loss_ce: 0.007621
2021-11-30 13:41:42,601 iteration 3003 : loss : 0.030622, loss_ce: 0.008205
2021-11-30 13:41:43,961 iteration 3004 : loss : 0.012173, loss_ce: 0.008572
2021-11-30 13:41:45,313 iteration 3005 : loss : 0.013431, loss_ce: 0.007903
2021-11-30 13:41:46,670 iteration 3006 : loss : 0.014191, loss_ce: 0.007867
2021-11-30 13:41:48,030 iteration 3007 : loss : 0.014041, loss_ce: 0.008489
2021-11-30 13:41:49,389 iteration 3008 : loss : 0.014249, loss_ce: 0.008723
2021-11-30 13:41:50,749 iteration 3009 : loss : 0.015320, loss_ce: 0.009219
 44%|███████████▉               | 177/400 [1:14:29<1:32:46, 24.96s/it]2021-11-30 13:41:52,185 iteration 3010 : loss : 0.011975, loss_ce: 0.007327
2021-11-30 13:41:53,539 iteration 3011 : loss : 0.017804, loss_ce: 0.012563
2021-11-30 13:41:54,900 iteration 3012 : loss : 0.010677, loss_ce: 0.007162
2021-11-30 13:41:56,260 iteration 3013 : loss : 0.014992, loss_ce: 0.009406
2021-11-30 13:41:57,624 iteration 3014 : loss : 0.022280, loss_ce: 0.009135
2021-11-30 13:41:58,984 iteration 3015 : loss : 0.013097, loss_ce: 0.008239
2021-11-30 13:42:00,339 iteration 3016 : loss : 0.012580, loss_ce: 0.007508
2021-11-30 13:42:01,704 iteration 3017 : loss : 0.013084, loss_ce: 0.008155
2021-11-30 13:42:03,064 iteration 3018 : loss : 0.014184, loss_ce: 0.008125
2021-11-30 13:42:04,419 iteration 3019 : loss : 0.019850, loss_ce: 0.008267
2021-11-30 13:42:05,785 iteration 3020 : loss : 0.011390, loss_ce: 0.007887
2021-11-30 13:42:07,139 iteration 3021 : loss : 0.014596, loss_ce: 0.008216
2021-11-30 13:42:08,500 iteration 3022 : loss : 0.013368, loss_ce: 0.007686
2021-11-30 13:42:09,859 iteration 3023 : loss : 0.011916, loss_ce: 0.007471
2021-11-30 13:42:11,217 iteration 3024 : loss : 0.013187, loss_ce: 0.008604
2021-11-30 13:42:12,570 iteration 3025 : loss : 0.011532, loss_ce: 0.007394
2021-11-30 13:42:13,919 iteration 3026 : loss : 0.012679, loss_ce: 0.008298
 44%|████████████               | 178/400 [1:14:52<1:30:21, 24.42s/it]2021-11-30 13:42:15,331 iteration 3027 : loss : 0.011070, loss_ce: 0.007204
2021-11-30 13:42:16,676 iteration 3028 : loss : 0.013369, loss_ce: 0.007771
2021-11-30 13:42:18,014 iteration 3029 : loss : 0.012141, loss_ce: 0.007192
2021-11-30 13:42:19,368 iteration 3030 : loss : 0.013777, loss_ce: 0.008159
2021-11-30 13:42:20,728 iteration 3031 : loss : 0.013308, loss_ce: 0.008751
2021-11-30 13:42:22,074 iteration 3032 : loss : 0.011663, loss_ce: 0.008009
2021-11-30 13:42:23,423 iteration 3033 : loss : 0.011451, loss_ce: 0.007186
2021-11-30 13:42:24,779 iteration 3034 : loss : 0.011222, loss_ce: 0.007061
2021-11-30 13:42:26,134 iteration 3035 : loss : 0.012903, loss_ce: 0.007740
2021-11-30 13:42:27,485 iteration 3036 : loss : 0.010742, loss_ce: 0.007241
2021-11-30 13:42:28,833 iteration 3037 : loss : 0.028924, loss_ce: 0.008260
2021-11-30 13:42:30,185 iteration 3038 : loss : 0.013011, loss_ce: 0.007886
2021-11-30 13:42:31,530 iteration 3039 : loss : 0.011869, loss_ce: 0.007826
2021-11-30 13:42:32,874 iteration 3040 : loss : 0.013175, loss_ce: 0.008189
2021-11-30 13:42:34,227 iteration 3041 : loss : 0.015260, loss_ce: 0.010029
2021-11-30 13:42:35,571 iteration 3042 : loss : 0.017077, loss_ce: 0.008997
2021-11-30 13:42:36,925 iteration 3043 : loss : 0.014453, loss_ce: 0.009227
 45%|████████████               | 179/400 [1:15:15<1:28:23, 24.00s/it]2021-11-30 13:42:38,342 iteration 3044 : loss : 0.012281, loss_ce: 0.007296
2021-11-30 13:42:39,676 iteration 3045 : loss : 0.017592, loss_ce: 0.008299
2021-11-30 13:42:41,022 iteration 3046 : loss : 0.011818, loss_ce: 0.008141
2021-11-30 13:42:42,373 iteration 3047 : loss : 0.012963, loss_ce: 0.007543
2021-11-30 13:42:43,731 iteration 3048 : loss : 0.010417, loss_ce: 0.006922
2021-11-30 13:42:45,075 iteration 3049 : loss : 0.017623, loss_ce: 0.010490
2021-11-30 13:42:46,422 iteration 3050 : loss : 0.015875, loss_ce: 0.008922
2021-11-30 13:42:47,788 iteration 3051 : loss : 0.019678, loss_ce: 0.009921
2021-11-30 13:42:49,127 iteration 3052 : loss : 0.017274, loss_ce: 0.009035
2021-11-30 13:42:50,478 iteration 3053 : loss : 0.011689, loss_ce: 0.007470
2021-11-30 13:42:51,835 iteration 3054 : loss : 0.012052, loss_ce: 0.007179
2021-11-30 13:42:53,173 iteration 3055 : loss : 0.014010, loss_ce: 0.009249
2021-11-30 13:42:54,526 iteration 3056 : loss : 0.013206, loss_ce: 0.008133
2021-11-30 13:42:55,878 iteration 3057 : loss : 0.013085, loss_ce: 0.007412
2021-11-30 13:42:57,229 iteration 3058 : loss : 0.014892, loss_ce: 0.010341
2021-11-30 13:42:58,584 iteration 3059 : loss : 0.019160, loss_ce: 0.009267
2021-11-30 13:42:58,584 Training Data Eval:
2021-11-30 13:43:06,222   Average segmentation loss on training set: 0.0122
2021-11-30 13:43:06,222 Validation Data Eval:
2021-11-30 13:43:08,871   Average segmentation loss on validation set: 0.1477
2021-11-30 13:43:10,203 iteration 3060 : loss : 0.014618, loss_ce: 0.008369
 45%|████████████▏              | 180/400 [1:15:48<1:38:11, 26.78s/it]2021-11-30 13:43:11,620 iteration 3061 : loss : 0.011532, loss_ce: 0.007562
2021-11-30 13:43:12,973 iteration 3062 : loss : 0.012910, loss_ce: 0.008076
2021-11-30 13:43:14,315 iteration 3063 : loss : 0.011391, loss_ce: 0.007316
2021-11-30 13:43:15,656 iteration 3064 : loss : 0.012362, loss_ce: 0.007561
2021-11-30 13:43:17,007 iteration 3065 : loss : 0.011032, loss_ce: 0.007051
2021-11-30 13:43:18,357 iteration 3066 : loss : 0.012303, loss_ce: 0.008292
2021-11-30 13:43:19,703 iteration 3067 : loss : 0.017523, loss_ce: 0.009788
2021-11-30 13:43:21,054 iteration 3068 : loss : 0.013179, loss_ce: 0.008270
2021-11-30 13:43:22,401 iteration 3069 : loss : 0.014677, loss_ce: 0.008417
2021-11-30 13:43:23,744 iteration 3070 : loss : 0.011964, loss_ce: 0.008034
2021-11-30 13:43:25,096 iteration 3071 : loss : 0.012336, loss_ce: 0.007618
2021-11-30 13:43:26,454 iteration 3072 : loss : 0.012459, loss_ce: 0.008146
2021-11-30 13:43:27,788 iteration 3073 : loss : 0.015749, loss_ce: 0.010511
2021-11-30 13:43:29,138 iteration 3074 : loss : 0.011684, loss_ce: 0.007330
2021-11-30 13:43:30,486 iteration 3075 : loss : 0.010838, loss_ce: 0.006984
2021-11-30 13:43:31,838 iteration 3076 : loss : 0.012495, loss_ce: 0.008312
2021-11-30 13:43:33,190 iteration 3077 : loss : 0.016003, loss_ce: 0.007568
 45%|████████████▏              | 181/400 [1:16:11<1:33:36, 25.64s/it]2021-11-30 13:43:34,603 iteration 3078 : loss : 0.014363, loss_ce: 0.008231
2021-11-30 13:43:35,946 iteration 3079 : loss : 0.013103, loss_ce: 0.007541
2021-11-30 13:43:37,302 iteration 3080 : loss : 0.013586, loss_ce: 0.007555
2021-11-30 13:43:38,644 iteration 3081 : loss : 0.013797, loss_ce: 0.007598
2021-11-30 13:43:40,001 iteration 3082 : loss : 0.010320, loss_ce: 0.006922
2021-11-30 13:43:41,352 iteration 3083 : loss : 0.012399, loss_ce: 0.008366
2021-11-30 13:43:42,705 iteration 3084 : loss : 0.014904, loss_ce: 0.010341
2021-11-30 13:43:44,054 iteration 3085 : loss : 0.012864, loss_ce: 0.008567
2021-11-30 13:43:45,401 iteration 3086 : loss : 0.013106, loss_ce: 0.008677
2021-11-30 13:43:46,758 iteration 3087 : loss : 0.011182, loss_ce: 0.006854
2021-11-30 13:43:48,100 iteration 3088 : loss : 0.011301, loss_ce: 0.007474
2021-11-30 13:43:49,449 iteration 3089 : loss : 0.012749, loss_ce: 0.007238
2021-11-30 13:43:50,786 iteration 3090 : loss : 0.011023, loss_ce: 0.007570
2021-11-30 13:43:52,139 iteration 3091 : loss : 0.013240, loss_ce: 0.007828
2021-11-30 13:43:53,492 iteration 3092 : loss : 0.010588, loss_ce: 0.007345
2021-11-30 13:43:54,833 iteration 3093 : loss : 0.012912, loss_ce: 0.008588
2021-11-30 13:43:56,184 iteration 3094 : loss : 0.015269, loss_ce: 0.008996
 46%|████████████▎              | 182/400 [1:16:34<1:30:17, 24.85s/it]2021-11-30 13:43:57,592 iteration 3095 : loss : 0.012963, loss_ce: 0.008464
2021-11-30 13:43:58,934 iteration 3096 : loss : 0.015244, loss_ce: 0.009115
2021-11-30 13:44:00,292 iteration 3097 : loss : 0.011108, loss_ce: 0.007875
2021-11-30 13:44:01,643 iteration 3098 : loss : 0.018508, loss_ce: 0.008074
2021-11-30 13:44:02,984 iteration 3099 : loss : 0.014018, loss_ce: 0.008625
2021-11-30 13:44:04,340 iteration 3100 : loss : 0.017066, loss_ce: 0.006893
2021-11-30 13:44:05,689 iteration 3101 : loss : 0.018123, loss_ce: 0.009937
2021-11-30 13:44:07,043 iteration 3102 : loss : 0.012716, loss_ce: 0.007920
2021-11-30 13:44:08,393 iteration 3103 : loss : 0.014314, loss_ce: 0.009703
2021-11-30 13:44:09,738 iteration 3104 : loss : 0.015445, loss_ce: 0.010173
2021-11-30 13:44:11,097 iteration 3105 : loss : 0.013274, loss_ce: 0.007132
2021-11-30 13:44:12,449 iteration 3106 : loss : 0.012781, loss_ce: 0.008141
2021-11-30 13:44:13,805 iteration 3107 : loss : 0.012423, loss_ce: 0.007615
2021-11-30 13:44:15,156 iteration 3108 : loss : 0.015158, loss_ce: 0.010424
2021-11-30 13:44:16,494 iteration 3109 : loss : 0.017024, loss_ce: 0.009073
2021-11-30 13:44:17,835 iteration 3110 : loss : 0.013262, loss_ce: 0.007933
2021-11-30 13:44:19,181 iteration 3111 : loss : 0.010961, loss_ce: 0.007502
 46%|████████████▎              | 183/400 [1:16:57<1:27:51, 24.29s/it]2021-11-30 13:44:20,600 iteration 3112 : loss : 0.010358, loss_ce: 0.007141
2021-11-30 13:44:21,938 iteration 3113 : loss : 0.012196, loss_ce: 0.007426
2021-11-30 13:44:23,291 iteration 3114 : loss : 0.012624, loss_ce: 0.007827
2021-11-30 13:44:24,647 iteration 3115 : loss : 0.025243, loss_ce: 0.014356
2021-11-30 13:44:25,989 iteration 3116 : loss : 0.016499, loss_ce: 0.009082
2021-11-30 13:44:27,332 iteration 3117 : loss : 0.014145, loss_ce: 0.008260
2021-11-30 13:44:28,688 iteration 3118 : loss : 0.016455, loss_ce: 0.008326
2021-11-30 13:44:30,033 iteration 3119 : loss : 0.012980, loss_ce: 0.009236
2021-11-30 13:44:31,389 iteration 3120 : loss : 0.013163, loss_ce: 0.007789
2021-11-30 13:44:32,736 iteration 3121 : loss : 0.011661, loss_ce: 0.007088
2021-11-30 13:44:34,089 iteration 3122 : loss : 0.013369, loss_ce: 0.008465
2021-11-30 13:44:35,427 iteration 3123 : loss : 0.012111, loss_ce: 0.007425
2021-11-30 13:44:36,759 iteration 3124 : loss : 0.014766, loss_ce: 0.008973
2021-11-30 13:44:38,099 iteration 3125 : loss : 0.012796, loss_ce: 0.008583
2021-11-30 13:44:39,445 iteration 3126 : loss : 0.012915, loss_ce: 0.008649
2021-11-30 13:44:40,806 iteration 3127 : loss : 0.014686, loss_ce: 0.007168
2021-11-30 13:44:42,158 iteration 3128 : loss : 0.010344, loss_ce: 0.007804
 46%|████████████▍              | 184/400 [1:17:20<1:26:02, 23.90s/it]2021-11-30 13:44:43,559 iteration 3129 : loss : 0.010345, loss_ce: 0.007201
2021-11-30 13:44:44,901 iteration 3130 : loss : 0.016136, loss_ce: 0.009404
2021-11-30 13:44:46,251 iteration 3131 : loss : 0.011637, loss_ce: 0.007870
2021-11-30 13:44:47,607 iteration 3132 : loss : 0.012532, loss_ce: 0.008240
2021-11-30 13:44:48,959 iteration 3133 : loss : 0.012208, loss_ce: 0.007377
2021-11-30 13:44:50,303 iteration 3134 : loss : 0.011206, loss_ce: 0.007906
2021-11-30 13:44:51,663 iteration 3135 : loss : 0.010985, loss_ce: 0.007093
2021-11-30 13:44:53,003 iteration 3136 : loss : 0.010806, loss_ce: 0.007011
2021-11-30 13:44:54,357 iteration 3137 : loss : 0.010948, loss_ce: 0.007042
2021-11-30 13:44:55,708 iteration 3138 : loss : 0.014011, loss_ce: 0.009600
2021-11-30 13:44:57,050 iteration 3139 : loss : 0.010335, loss_ce: 0.007009
2021-11-30 13:44:58,386 iteration 3140 : loss : 0.010444, loss_ce: 0.007208
2021-11-30 13:44:59,731 iteration 3141 : loss : 0.014406, loss_ce: 0.007773
2021-11-30 13:45:01,089 iteration 3142 : loss : 0.012587, loss_ce: 0.008100
2021-11-30 13:45:02,435 iteration 3143 : loss : 0.015329, loss_ce: 0.007823
2021-11-30 13:45:03,782 iteration 3144 : loss : 0.014493, loss_ce: 0.008390
2021-11-30 13:45:03,782 Training Data Eval:
2021-11-30 13:45:11,377   Average segmentation loss on training set: 0.0115
2021-11-30 13:45:11,377 Validation Data Eval:
2021-11-30 13:45:13,991   Average segmentation loss on validation set: 0.1791
2021-11-30 13:45:15,333 iteration 3145 : loss : 0.010762, loss_ce: 0.006954
 46%|████████████▍              | 185/400 [1:17:53<1:35:36, 26.68s/it]2021-11-30 13:45:16,733 iteration 3146 : loss : 0.015750, loss_ce: 0.010723
2021-11-30 13:45:18,074 iteration 3147 : loss : 0.012209, loss_ce: 0.007110
2021-11-30 13:45:19,420 iteration 3148 : loss : 0.010935, loss_ce: 0.006901
2021-11-30 13:45:20,768 iteration 3149 : loss : 0.010694, loss_ce: 0.006593
2021-11-30 13:45:22,102 iteration 3150 : loss : 0.011331, loss_ce: 0.007487
2021-11-30 13:45:23,456 iteration 3151 : loss : 0.011962, loss_ce: 0.007205
2021-11-30 13:45:24,809 iteration 3152 : loss : 0.011948, loss_ce: 0.007956
2021-11-30 13:45:26,154 iteration 3153 : loss : 0.010094, loss_ce: 0.006776
2021-11-30 13:45:27,514 iteration 3154 : loss : 0.014131, loss_ce: 0.007428
2021-11-30 13:45:28,860 iteration 3155 : loss : 0.012727, loss_ce: 0.007918
2021-11-30 13:45:30,202 iteration 3156 : loss : 0.012873, loss_ce: 0.008692
2021-11-30 13:45:31,547 iteration 3157 : loss : 0.011125, loss_ce: 0.007260
2021-11-30 13:45:32,890 iteration 3158 : loss : 0.010161, loss_ce: 0.006883
2021-11-30 13:45:34,243 iteration 3159 : loss : 0.017005, loss_ce: 0.010067
2021-11-30 13:45:35,594 iteration 3160 : loss : 0.011986, loss_ce: 0.006939
2021-11-30 13:45:36,949 iteration 3161 : loss : 0.016015, loss_ce: 0.011138
2021-11-30 13:45:38,295 iteration 3162 : loss : 0.010092, loss_ce: 0.007334
 46%|████████████▌              | 186/400 [1:18:16<1:31:11, 25.57s/it]2021-11-30 13:45:39,703 iteration 3163 : loss : 0.012748, loss_ce: 0.007715
2021-11-30 13:45:41,041 iteration 3164 : loss : 0.012813, loss_ce: 0.007476
2021-11-30 13:45:42,391 iteration 3165 : loss : 0.017087, loss_ce: 0.012000
2021-11-30 13:45:43,742 iteration 3166 : loss : 0.013751, loss_ce: 0.008118
2021-11-30 13:45:45,104 iteration 3167 : loss : 0.013706, loss_ce: 0.009168
2021-11-30 13:45:46,450 iteration 3168 : loss : 0.012935, loss_ce: 0.006986
2021-11-30 13:45:47,811 iteration 3169 : loss : 0.011856, loss_ce: 0.006945
2021-11-30 13:45:49,151 iteration 3170 : loss : 0.012351, loss_ce: 0.008231
2021-11-30 13:45:50,490 iteration 3171 : loss : 0.010896, loss_ce: 0.007617
2021-11-30 13:45:51,843 iteration 3172 : loss : 0.011989, loss_ce: 0.007421
2021-11-30 13:45:53,195 iteration 3173 : loss : 0.009861, loss_ce: 0.006876
2021-11-30 13:45:54,546 iteration 3174 : loss : 0.011008, loss_ce: 0.006593
2021-11-30 13:45:55,893 iteration 3175 : loss : 0.010902, loss_ce: 0.006834
2021-11-30 13:45:57,237 iteration 3176 : loss : 0.011144, loss_ce: 0.007288
2021-11-30 13:45:58,586 iteration 3177 : loss : 0.016677, loss_ce: 0.009179
2021-11-30 13:45:59,937 iteration 3178 : loss : 0.013494, loss_ce: 0.008066
2021-11-30 13:46:01,294 iteration 3179 : loss : 0.012099, loss_ce: 0.007885
 47%|████████████▌              | 187/400 [1:18:39<1:28:01, 24.79s/it]2021-11-30 13:46:02,699 iteration 3180 : loss : 0.012177, loss_ce: 0.007705
2021-11-30 13:46:04,033 iteration 3181 : loss : 0.012451, loss_ce: 0.006608
2021-11-30 13:46:05,397 iteration 3182 : loss : 0.011600, loss_ce: 0.007271
2021-11-30 13:46:06,748 iteration 3183 : loss : 0.011703, loss_ce: 0.006852
2021-11-30 13:46:08,108 iteration 3184 : loss : 0.012930, loss_ce: 0.008483
2021-11-30 13:46:09,462 iteration 3185 : loss : 0.012659, loss_ce: 0.008147
2021-11-30 13:46:10,811 iteration 3186 : loss : 0.010908, loss_ce: 0.006677
2021-11-30 13:46:12,171 iteration 3187 : loss : 0.012188, loss_ce: 0.006924
2021-11-30 13:46:13,520 iteration 3188 : loss : 0.012156, loss_ce: 0.007623
2021-11-30 13:46:14,870 iteration 3189 : loss : 0.012075, loss_ce: 0.008530
2021-11-30 13:46:16,224 iteration 3190 : loss : 0.010897, loss_ce: 0.007344
2021-11-30 13:46:17,580 iteration 3191 : loss : 0.010090, loss_ce: 0.006816
2021-11-30 13:46:18,938 iteration 3192 : loss : 0.011051, loss_ce: 0.008183
2021-11-30 13:46:20,290 iteration 3193 : loss : 0.014386, loss_ce: 0.009272
2021-11-30 13:46:21,631 iteration 3194 : loss : 0.012294, loss_ce: 0.007140
2021-11-30 13:46:22,980 iteration 3195 : loss : 0.012515, loss_ce: 0.007941
2021-11-30 13:46:24,328 iteration 3196 : loss : 0.011118, loss_ce: 0.007104
 47%|████████████▋              | 188/400 [1:19:02<1:25:44, 24.27s/it]2021-11-30 13:46:25,747 iteration 3197 : loss : 0.009721, loss_ce: 0.006506
2021-11-30 13:46:27,092 iteration 3198 : loss : 0.011438, loss_ce: 0.007676
2021-11-30 13:46:28,445 iteration 3199 : loss : 0.018425, loss_ce: 0.012496
2021-11-30 13:46:29,803 iteration 3200 : loss : 0.011596, loss_ce: 0.007903
2021-11-30 13:46:31,159 iteration 3201 : loss : 0.018537, loss_ce: 0.009212
2021-11-30 13:46:32,503 iteration 3202 : loss : 0.018636, loss_ce: 0.008255
2021-11-30 13:46:33,868 iteration 3203 : loss : 0.008804, loss_ce: 0.006074
2021-11-30 13:46:35,218 iteration 3204 : loss : 0.011265, loss_ce: 0.007690
2021-11-30 13:46:36,569 iteration 3205 : loss : 0.012078, loss_ce: 0.007838
2021-11-30 13:46:37,904 iteration 3206 : loss : 0.012561, loss_ce: 0.007925
2021-11-30 13:46:39,256 iteration 3207 : loss : 0.012392, loss_ce: 0.007352
2021-11-30 13:46:40,614 iteration 3208 : loss : 0.016613, loss_ce: 0.011984
2021-11-30 13:46:41,956 iteration 3209 : loss : 0.012620, loss_ce: 0.007462
2021-11-30 13:46:43,314 iteration 3210 : loss : 0.010381, loss_ce: 0.007014
2021-11-30 13:46:44,666 iteration 3211 : loss : 0.013372, loss_ce: 0.007661
2021-11-30 13:46:46,010 iteration 3212 : loss : 0.010983, loss_ce: 0.007194
2021-11-30 13:46:47,355 iteration 3213 : loss : 0.009549, loss_ce: 0.006329
 47%|████████████▊              | 189/400 [1:19:25<1:24:01, 23.90s/it]2021-11-30 13:46:48,764 iteration 3214 : loss : 0.016570, loss_ce: 0.008144
2021-11-30 13:46:50,105 iteration 3215 : loss : 0.013203, loss_ce: 0.008635
2021-11-30 13:46:51,462 iteration 3216 : loss : 0.016314, loss_ce: 0.007814
2021-11-30 13:46:52,804 iteration 3217 : loss : 0.010198, loss_ce: 0.006784
2021-11-30 13:46:54,170 iteration 3218 : loss : 0.010740, loss_ce: 0.007103
2021-11-30 13:46:55,517 iteration 3219 : loss : 0.018480, loss_ce: 0.011024
2021-11-30 13:46:56,850 iteration 3220 : loss : 0.010958, loss_ce: 0.007185
2021-11-30 13:46:58,191 iteration 3221 : loss : 0.014554, loss_ce: 0.007642
2021-11-30 13:46:59,542 iteration 3222 : loss : 0.011218, loss_ce: 0.007164
2021-11-30 13:47:00,907 iteration 3223 : loss : 0.011787, loss_ce: 0.006662
2021-11-30 13:47:02,259 iteration 3224 : loss : 0.014065, loss_ce: 0.009278
2021-11-30 13:47:03,599 iteration 3225 : loss : 0.009725, loss_ce: 0.006784
2021-11-30 13:47:04,959 iteration 3226 : loss : 0.010248, loss_ce: 0.007165
2021-11-30 13:47:06,318 iteration 3227 : loss : 0.012289, loss_ce: 0.007422
2021-11-30 13:47:07,674 iteration 3228 : loss : 0.013010, loss_ce: 0.009613
2021-11-30 13:47:09,018 iteration 3229 : loss : 0.010814, loss_ce: 0.006859
2021-11-30 13:47:09,018 Training Data Eval:
2021-11-30 13:47:16,634   Average segmentation loss on training set: 0.0144
2021-11-30 13:47:16,634 Validation Data Eval:
2021-11-30 13:47:19,258   Average segmentation loss on validation set: 0.1378
2021-11-30 13:47:20,608 iteration 3230 : loss : 0.013009, loss_ce: 0.008080
 48%|████████████▊              | 190/400 [1:19:59<1:33:27, 26.70s/it]2021-11-30 13:47:22,025 iteration 3231 : loss : 0.014893, loss_ce: 0.008771
2021-11-30 13:47:23,377 iteration 3232 : loss : 0.013300, loss_ce: 0.007570
2021-11-30 13:47:24,716 iteration 3233 : loss : 0.009897, loss_ce: 0.006779
2021-11-30 13:47:26,071 iteration 3234 : loss : 0.010813, loss_ce: 0.007510
2021-11-30 13:47:27,428 iteration 3235 : loss : 0.012970, loss_ce: 0.007767
2021-11-30 13:47:28,773 iteration 3236 : loss : 0.009866, loss_ce: 0.007259
2021-11-30 13:47:30,113 iteration 3237 : loss : 0.012176, loss_ce: 0.008136
2021-11-30 13:47:31,467 iteration 3238 : loss : 0.013049, loss_ce: 0.006701
2021-11-30 13:47:32,814 iteration 3239 : loss : 0.014056, loss_ce: 0.007829
2021-11-30 13:47:34,163 iteration 3240 : loss : 0.011886, loss_ce: 0.007463
2021-11-30 13:47:35,501 iteration 3241 : loss : 0.011540, loss_ce: 0.008029
2021-11-30 13:47:36,848 iteration 3242 : loss : 0.010550, loss_ce: 0.006578
2021-11-30 13:47:38,208 iteration 3243 : loss : 0.018962, loss_ce: 0.008420
2021-11-30 13:47:39,562 iteration 3244 : loss : 0.013732, loss_ce: 0.009203
2021-11-30 13:47:40,914 iteration 3245 : loss : 0.013749, loss_ce: 0.009242
2021-11-30 13:47:42,272 iteration 3246 : loss : 0.012075, loss_ce: 0.007141
2021-11-30 13:47:43,625 iteration 3247 : loss : 0.009798, loss_ce: 0.007082
 48%|████████████▉              | 191/400 [1:20:22<1:29:09, 25.60s/it]2021-11-30 13:47:45,037 iteration 3248 : loss : 0.011994, loss_ce: 0.007477
2021-11-30 13:47:46,389 iteration 3249 : loss : 0.010267, loss_ce: 0.007233
2021-11-30 13:47:47,736 iteration 3250 : loss : 0.009367, loss_ce: 0.006746
2021-11-30 13:47:49,089 iteration 3251 : loss : 0.011667, loss_ce: 0.007492
2021-11-30 13:47:50,446 iteration 3252 : loss : 0.010796, loss_ce: 0.006849
2021-11-30 13:47:51,798 iteration 3253 : loss : 0.009799, loss_ce: 0.006691
2021-11-30 13:47:53,154 iteration 3254 : loss : 0.011036, loss_ce: 0.007510
2021-11-30 13:47:54,497 iteration 3255 : loss : 0.013938, loss_ce: 0.007930
2021-11-30 13:47:55,843 iteration 3256 : loss : 0.011861, loss_ce: 0.007214
2021-11-30 13:47:57,196 iteration 3257 : loss : 0.014639, loss_ce: 0.007307
2021-11-30 13:47:58,546 iteration 3258 : loss : 0.012830, loss_ce: 0.008937
2021-11-30 13:47:59,902 iteration 3259 : loss : 0.012146, loss_ce: 0.007440
2021-11-30 13:48:01,246 iteration 3260 : loss : 0.010627, loss_ce: 0.007175
2021-11-30 13:48:02,601 iteration 3261 : loss : 0.012823, loss_ce: 0.007080
2021-11-30 13:48:03,956 iteration 3262 : loss : 0.011725, loss_ce: 0.006902
2021-11-30 13:48:05,311 iteration 3263 : loss : 0.013400, loss_ce: 0.009618
2021-11-30 13:48:06,663 iteration 3264 : loss : 0.011138, loss_ce: 0.006407
 48%|████████████▉              | 192/400 [1:20:45<1:26:04, 24.83s/it]2021-11-30 13:48:08,096 iteration 3265 : loss : 0.012149, loss_ce: 0.006933
2021-11-30 13:48:09,450 iteration 3266 : loss : 0.012594, loss_ce: 0.008371
2021-11-30 13:48:10,804 iteration 3267 : loss : 0.012166, loss_ce: 0.008722
2021-11-30 13:48:12,167 iteration 3268 : loss : 0.011048, loss_ce: 0.006515
2021-11-30 13:48:13,529 iteration 3269 : loss : 0.009755, loss_ce: 0.006602
2021-11-30 13:48:14,889 iteration 3270 : loss : 0.017770, loss_ce: 0.009068
2021-11-30 13:48:16,249 iteration 3271 : loss : 0.012389, loss_ce: 0.007350
2021-11-30 13:48:17,604 iteration 3272 : loss : 0.011249, loss_ce: 0.007218
2021-11-30 13:48:18,960 iteration 3273 : loss : 0.009325, loss_ce: 0.006516
2021-11-30 13:48:20,322 iteration 3274 : loss : 0.011428, loss_ce: 0.006703
2021-11-30 13:48:21,681 iteration 3275 : loss : 0.010249, loss_ce: 0.006646
2021-11-30 13:48:23,046 iteration 3276 : loss : 0.012397, loss_ce: 0.008629
2021-11-30 13:48:24,400 iteration 3277 : loss : 0.012858, loss_ce: 0.008730
2021-11-30 13:48:25,760 iteration 3278 : loss : 0.013105, loss_ce: 0.007612
2021-11-30 13:48:27,120 iteration 3279 : loss : 0.010945, loss_ce: 0.007215
2021-11-30 13:48:28,482 iteration 3280 : loss : 0.010939, loss_ce: 0.007443
2021-11-30 13:48:29,834 iteration 3281 : loss : 0.010747, loss_ce: 0.006569
 48%|█████████████              | 193/400 [1:21:08<1:23:56, 24.33s/it]2021-11-30 13:48:31,259 iteration 3282 : loss : 0.011451, loss_ce: 0.007865
2021-11-30 13:48:32,596 iteration 3283 : loss : 0.011401, loss_ce: 0.007870
2021-11-30 13:48:33,951 iteration 3284 : loss : 0.011649, loss_ce: 0.008071
2021-11-30 13:48:35,310 iteration 3285 : loss : 0.009820, loss_ce: 0.006550
2021-11-30 13:48:36,661 iteration 3286 : loss : 0.011908, loss_ce: 0.007158
2021-11-30 13:48:38,010 iteration 3287 : loss : 0.011695, loss_ce: 0.006867
2021-11-30 13:48:39,369 iteration 3288 : loss : 0.009651, loss_ce: 0.006569
2021-11-30 13:48:40,708 iteration 3289 : loss : 0.010251, loss_ce: 0.007517
2021-11-30 13:48:42,063 iteration 3290 : loss : 0.009554, loss_ce: 0.006259
2021-11-30 13:48:43,416 iteration 3291 : loss : 0.014055, loss_ce: 0.007520
2021-11-30 13:48:44,767 iteration 3292 : loss : 0.014003, loss_ce: 0.008540
2021-11-30 13:48:46,119 iteration 3293 : loss : 0.008932, loss_ce: 0.006473
2021-11-30 13:48:47,471 iteration 3294 : loss : 0.013490, loss_ce: 0.009003
2021-11-30 13:48:48,830 iteration 3295 : loss : 0.011228, loss_ce: 0.007769
2021-11-30 13:48:50,183 iteration 3296 : loss : 0.010346, loss_ce: 0.006720
2021-11-30 13:48:51,543 iteration 3297 : loss : 0.011837, loss_ce: 0.006711
2021-11-30 13:48:52,898 iteration 3298 : loss : 0.009941, loss_ce: 0.006623
 48%|█████████████              | 194/400 [1:21:31<1:22:13, 23.95s/it]2021-11-30 13:48:54,311 iteration 3299 : loss : 0.017171, loss_ce: 0.008245
2021-11-30 13:48:55,675 iteration 3300 : loss : 0.012964, loss_ce: 0.008007
2021-11-30 13:48:57,031 iteration 3301 : loss : 0.012387, loss_ce: 0.007142
2021-11-30 13:48:58,383 iteration 3302 : loss : 0.010472, loss_ce: 0.007137
2021-11-30 13:48:59,732 iteration 3303 : loss : 0.008079, loss_ce: 0.006209
2021-11-30 13:49:01,091 iteration 3304 : loss : 0.008696, loss_ce: 0.006651
2021-11-30 13:49:02,442 iteration 3305 : loss : 0.017350, loss_ce: 0.009637
2021-11-30 13:49:03,800 iteration 3306 : loss : 0.009907, loss_ce: 0.006513
2021-11-30 13:49:05,149 iteration 3307 : loss : 0.010319, loss_ce: 0.007274
2021-11-30 13:49:06,503 iteration 3308 : loss : 0.010599, loss_ce: 0.006856
2021-11-30 13:49:07,848 iteration 3309 : loss : 0.012775, loss_ce: 0.008218
2021-11-30 13:49:09,199 iteration 3310 : loss : 0.011903, loss_ce: 0.008917
2021-11-30 13:49:10,553 iteration 3311 : loss : 0.011816, loss_ce: 0.007501
2021-11-30 13:49:11,891 iteration 3312 : loss : 0.011783, loss_ce: 0.006997
2021-11-30 13:49:13,238 iteration 3313 : loss : 0.010616, loss_ce: 0.006517
2021-11-30 13:49:14,582 iteration 3314 : loss : 0.011451, loss_ce: 0.008182
2021-11-30 13:49:14,582 Training Data Eval:
2021-11-30 13:49:22,176   Average segmentation loss on training set: 0.0112
2021-11-30 13:49:22,176 Validation Data Eval:
2021-11-30 13:49:24,815   Average segmentation loss on validation set: 0.1468
2021-11-30 13:49:26,154 iteration 3315 : loss : 0.010473, loss_ce: 0.006867
 49%|█████████████▏             | 195/400 [1:22:04<1:31:22, 26.74s/it]2021-11-30 13:49:27,565 iteration 3316 : loss : 0.010860, loss_ce: 0.006701
2021-11-30 13:49:28,905 iteration 3317 : loss : 0.012678, loss_ce: 0.007380
2021-11-30 13:49:30,255 iteration 3318 : loss : 0.012091, loss_ce: 0.008004
2021-11-30 13:49:31,602 iteration 3319 : loss : 0.009251, loss_ce: 0.006781
2021-11-30 13:49:32,957 iteration 3320 : loss : 0.013201, loss_ce: 0.007245
2021-11-30 13:49:34,313 iteration 3321 : loss : 0.012383, loss_ce: 0.008226
2021-11-30 13:49:35,662 iteration 3322 : loss : 0.013603, loss_ce: 0.010585
2021-11-30 13:49:37,006 iteration 3323 : loss : 0.014979, loss_ce: 0.007697
2021-11-30 13:49:38,358 iteration 3324 : loss : 0.012182, loss_ce: 0.007687
2021-11-30 13:49:39,703 iteration 3325 : loss : 0.011384, loss_ce: 0.007112
2021-11-30 13:49:41,050 iteration 3326 : loss : 0.012008, loss_ce: 0.007780
2021-11-30 13:49:42,393 iteration 3327 : loss : 0.009418, loss_ce: 0.006244
2021-11-30 13:49:43,740 iteration 3328 : loss : 0.012519, loss_ce: 0.006896
2021-11-30 13:49:45,085 iteration 3329 : loss : 0.011331, loss_ce: 0.007073
2021-11-30 13:49:46,423 iteration 3330 : loss : 0.009345, loss_ce: 0.006517
2021-11-30 13:49:47,778 iteration 3331 : loss : 0.013744, loss_ce: 0.009270
2021-11-30 13:49:49,122 iteration 3332 : loss : 0.011357, loss_ce: 0.007736
 49%|█████████████▏             | 196/400 [1:22:27<1:27:04, 25.61s/it]2021-11-30 13:49:50,535 iteration 3333 : loss : 0.010630, loss_ce: 0.007902
2021-11-30 13:49:51,883 iteration 3334 : loss : 0.011710, loss_ce: 0.007365
2021-11-30 13:49:53,220 iteration 3335 : loss : 0.009354, loss_ce: 0.006871
2021-11-30 13:49:54,571 iteration 3336 : loss : 0.010980, loss_ce: 0.007122
2021-11-30 13:49:55,917 iteration 3337 : loss : 0.011843, loss_ce: 0.008246
2021-11-30 13:49:57,277 iteration 3338 : loss : 0.014362, loss_ce: 0.008351
2021-11-30 13:49:58,623 iteration 3339 : loss : 0.011194, loss_ce: 0.007007
2021-11-30 13:49:59,973 iteration 3340 : loss : 0.011075, loss_ce: 0.006919
2021-11-30 13:50:01,333 iteration 3341 : loss : 0.011897, loss_ce: 0.006905
2021-11-30 13:50:02,685 iteration 3342 : loss : 0.008722, loss_ce: 0.006257
2021-11-30 13:50:04,027 iteration 3343 : loss : 0.009644, loss_ce: 0.007049
2021-11-30 13:50:05,379 iteration 3344 : loss : 0.010594, loss_ce: 0.007083
2021-11-30 13:50:06,723 iteration 3345 : loss : 0.012253, loss_ce: 0.007419
2021-11-30 13:50:08,079 iteration 3346 : loss : 0.009669, loss_ce: 0.006469
2021-11-30 13:50:09,431 iteration 3347 : loss : 0.015600, loss_ce: 0.007986
2021-11-30 13:50:10,788 iteration 3348 : loss : 0.014037, loss_ce: 0.007486
2021-11-30 13:50:12,141 iteration 3349 : loss : 0.010782, loss_ce: 0.006633
 49%|█████████████▎             | 197/400 [1:22:50<1:24:01, 24.83s/it]2021-11-30 13:50:13,543 iteration 3350 : loss : 0.012041, loss_ce: 0.006919
2021-11-30 13:50:14,893 iteration 3351 : loss : 0.014149, loss_ce: 0.009315
2021-11-30 13:50:16,249 iteration 3352 : loss : 0.011019, loss_ce: 0.006862
2021-11-30 13:50:17,594 iteration 3353 : loss : 0.015437, loss_ce: 0.008755
2021-11-30 13:50:18,946 iteration 3354 : loss : 0.013107, loss_ce: 0.006817
2021-11-30 13:50:20,299 iteration 3355 : loss : 0.009709, loss_ce: 0.006553
2021-11-30 13:50:21,655 iteration 3356 : loss : 0.010316, loss_ce: 0.006895
2021-11-30 13:50:23,011 iteration 3357 : loss : 0.009991, loss_ce: 0.007558
2021-11-30 13:50:24,359 iteration 3358 : loss : 0.015722, loss_ce: 0.008823
2021-11-30 13:50:25,716 iteration 3359 : loss : 0.011521, loss_ce: 0.006775
2021-11-30 13:50:27,057 iteration 3360 : loss : 0.012409, loss_ce: 0.008559
2021-11-30 13:50:28,406 iteration 3361 : loss : 0.013640, loss_ce: 0.007723
2021-11-30 13:50:29,760 iteration 3362 : loss : 0.012338, loss_ce: 0.007941
2021-11-30 13:50:31,108 iteration 3363 : loss : 0.009687, loss_ce: 0.006386
2021-11-30 13:50:32,470 iteration 3364 : loss : 0.014191, loss_ce: 0.009120
2021-11-30 13:50:33,824 iteration 3365 : loss : 0.010489, loss_ce: 0.006435
2021-11-30 13:50:35,177 iteration 3366 : loss : 0.013214, loss_ce: 0.008783
 50%|█████████████▎             | 198/400 [1:23:13<1:21:47, 24.29s/it]2021-11-30 13:50:36,594 iteration 3367 : loss : 0.027548, loss_ce: 0.012427
2021-11-30 13:50:37,946 iteration 3368 : loss : 0.011275, loss_ce: 0.006965
2021-11-30 13:50:39,306 iteration 3369 : loss : 0.013413, loss_ce: 0.008103
2021-11-30 13:50:40,664 iteration 3370 : loss : 0.012396, loss_ce: 0.007350
2021-11-30 13:50:42,022 iteration 3371 : loss : 0.010172, loss_ce: 0.007047
2021-11-30 13:50:43,374 iteration 3372 : loss : 0.011218, loss_ce: 0.007075
2021-11-30 13:50:44,729 iteration 3373 : loss : 0.012865, loss_ce: 0.007885
2021-11-30 13:50:46,069 iteration 3374 : loss : 0.010135, loss_ce: 0.006514
2021-11-30 13:50:47,427 iteration 3375 : loss : 0.013075, loss_ce: 0.008971
2021-11-30 13:50:48,774 iteration 3376 : loss : 0.013765, loss_ce: 0.007295
2021-11-30 13:50:50,120 iteration 3377 : loss : 0.010454, loss_ce: 0.006522
2021-11-30 13:50:51,465 iteration 3378 : loss : 0.013525, loss_ce: 0.008654
2021-11-30 13:50:52,816 iteration 3379 : loss : 0.013408, loss_ce: 0.009029
2021-11-30 13:50:54,176 iteration 3380 : loss : 0.010464, loss_ce: 0.007106
2021-11-30 13:50:55,522 iteration 3381 : loss : 0.014600, loss_ce: 0.007934
2021-11-30 13:50:56,873 iteration 3382 : loss : 0.010354, loss_ce: 0.006481
2021-11-30 13:50:58,226 iteration 3383 : loss : 0.009212, loss_ce: 0.006319
 50%|█████████████▍             | 199/400 [1:23:36<1:20:07, 23.92s/it]2021-11-30 13:50:59,648 iteration 3384 : loss : 0.009671, loss_ce: 0.006990
2021-11-30 13:51:00,991 iteration 3385 : loss : 0.011480, loss_ce: 0.007463
2021-11-30 13:51:02,349 iteration 3386 : loss : 0.009529, loss_ce: 0.006650
2021-11-30 13:51:03,693 iteration 3387 : loss : 0.010412, loss_ce: 0.007693
2021-11-30 13:51:05,044 iteration 3388 : loss : 0.009273, loss_ce: 0.006898
2021-11-30 13:51:06,392 iteration 3389 : loss : 0.009037, loss_ce: 0.006279
2021-11-30 13:51:07,740 iteration 3390 : loss : 0.008693, loss_ce: 0.006325
2021-11-30 13:51:09,095 iteration 3391 : loss : 0.017082, loss_ce: 0.008960
2021-11-30 13:51:10,439 iteration 3392 : loss : 0.011149, loss_ce: 0.006402
2021-11-30 13:51:11,790 iteration 3393 : loss : 0.009687, loss_ce: 0.006377
2021-11-30 13:51:13,140 iteration 3394 : loss : 0.009757, loss_ce: 0.006430
2021-11-30 13:51:14,485 iteration 3395 : loss : 0.010484, loss_ce: 0.006725
2021-11-30 13:51:15,844 iteration 3396 : loss : 0.011471, loss_ce: 0.007133
2021-11-30 13:51:17,193 iteration 3397 : loss : 0.009973, loss_ce: 0.006826
2021-11-30 13:51:18,547 iteration 3398 : loss : 0.012770, loss_ce: 0.007344
2021-11-30 13:51:19,901 iteration 3399 : loss : 0.012513, loss_ce: 0.008411
2021-11-30 13:51:19,901 Training Data Eval:
2021-11-30 13:51:27,524   Average segmentation loss on training set: 0.0093
2021-11-30 13:51:27,524 Validation Data Eval:
2021-11-30 13:51:30,164   Average segmentation loss on validation set: 0.1659
2021-11-30 13:51:31,511 iteration 3400 : loss : 0.011185, loss_ce: 0.007162
 50%|█████████████▌             | 200/400 [1:24:10<1:29:06, 26.73s/it]2021-11-30 13:51:32,929 iteration 3401 : loss : 0.010492, loss_ce: 0.006718
2021-11-30 13:51:34,263 iteration 3402 : loss : 0.011353, loss_ce: 0.007581
2021-11-30 13:51:35,618 iteration 3403 : loss : 0.013155, loss_ce: 0.008840
2021-11-30 13:51:36,972 iteration 3404 : loss : 0.009567, loss_ce: 0.006298
2021-11-30 13:51:38,321 iteration 3405 : loss : 0.010278, loss_ce: 0.007110
2021-11-30 13:51:39,670 iteration 3406 : loss : 0.011437, loss_ce: 0.007975
2021-11-30 13:51:41,025 iteration 3407 : loss : 0.010937, loss_ce: 0.006322
2021-11-30 13:51:42,378 iteration 3408 : loss : 0.010009, loss_ce: 0.006290
2021-11-30 13:51:43,731 iteration 3409 : loss : 0.011422, loss_ce: 0.006594
2021-11-30 13:51:45,086 iteration 3410 : loss : 0.012726, loss_ce: 0.006613
2021-11-30 13:51:46,429 iteration 3411 : loss : 0.009304, loss_ce: 0.006743
2021-11-30 13:51:47,779 iteration 3412 : loss : 0.010173, loss_ce: 0.007230
2021-11-30 13:51:49,139 iteration 3413 : loss : 0.010396, loss_ce: 0.007033
2021-11-30 13:51:50,498 iteration 3414 : loss : 0.012195, loss_ce: 0.007692
2021-11-30 13:51:51,841 iteration 3415 : loss : 0.009828, loss_ce: 0.006988
2021-11-30 13:51:53,195 iteration 3416 : loss : 0.011295, loss_ce: 0.006493
2021-11-30 13:51:54,550 iteration 3417 : loss : 0.011951, loss_ce: 0.007213
 50%|█████████████▌             | 201/400 [1:24:33<1:24:58, 25.62s/it]2021-11-30 13:51:55,958 iteration 3418 : loss : 0.011779, loss_ce: 0.008282
2021-11-30 13:51:57,310 iteration 3419 : loss : 0.010182, loss_ce: 0.006482
2021-11-30 13:51:58,659 iteration 3420 : loss : 0.010979, loss_ce: 0.007613
2021-11-30 13:52:00,004 iteration 3421 : loss : 0.009369, loss_ce: 0.006618
2021-11-30 13:52:01,362 iteration 3422 : loss : 0.011066, loss_ce: 0.007263
2021-11-30 13:52:02,711 iteration 3423 : loss : 0.009300, loss_ce: 0.006299
2021-11-30 13:52:04,044 iteration 3424 : loss : 0.010643, loss_ce: 0.007414
2021-11-30 13:52:05,383 iteration 3425 : loss : 0.010935, loss_ce: 0.007182
2021-11-30 13:52:06,736 iteration 3426 : loss : 0.010680, loss_ce: 0.006578
2021-11-30 13:52:08,094 iteration 3427 : loss : 0.010123, loss_ce: 0.006543
2021-11-30 13:52:09,438 iteration 3428 : loss : 0.014011, loss_ce: 0.006891
2021-11-30 13:52:10,789 iteration 3429 : loss : 0.012105, loss_ce: 0.006989
2021-11-30 13:52:12,136 iteration 3430 : loss : 0.009919, loss_ce: 0.006388
2021-11-30 13:52:13,470 iteration 3431 : loss : 0.010758, loss_ce: 0.007037
2021-11-30 13:52:14,819 iteration 3432 : loss : 0.010471, loss_ce: 0.006922
2021-11-30 13:52:16,164 iteration 3433 : loss : 0.011724, loss_ce: 0.007567
2021-11-30 13:52:17,521 iteration 3434 : loss : 0.011427, loss_ce: 0.007491
 50%|█████████████▋             | 202/400 [1:24:56<1:21:56, 24.83s/it]2021-11-30 13:52:18,937 iteration 3435 : loss : 0.008980, loss_ce: 0.006517
2021-11-30 13:52:20,269 iteration 3436 : loss : 0.010376, loss_ce: 0.006829
2021-11-30 13:52:21,626 iteration 3437 : loss : 0.010703, loss_ce: 0.006625
2021-11-30 13:52:22,975 iteration 3438 : loss : 0.013147, loss_ce: 0.007851
2021-11-30 13:52:24,320 iteration 3439 : loss : 0.012693, loss_ce: 0.007204
2021-11-30 13:52:25,674 iteration 3440 : loss : 0.010330, loss_ce: 0.006803
2021-11-30 13:52:27,021 iteration 3441 : loss : 0.011575, loss_ce: 0.007197
2021-11-30 13:52:28,384 iteration 3442 : loss : 0.010802, loss_ce: 0.007218
2021-11-30 13:52:29,724 iteration 3443 : loss : 0.009885, loss_ce: 0.006661
2021-11-30 13:52:31,085 iteration 3444 : loss : 0.009202, loss_ce: 0.006478
2021-11-30 13:52:32,442 iteration 3445 : loss : 0.009920, loss_ce: 0.006268
2021-11-30 13:52:33,795 iteration 3446 : loss : 0.010165, loss_ce: 0.007061
2021-11-30 13:52:35,148 iteration 3447 : loss : 0.010345, loss_ce: 0.006389
2021-11-30 13:52:36,494 iteration 3448 : loss : 0.009591, loss_ce: 0.006661
2021-11-30 13:52:37,847 iteration 3449 : loss : 0.010258, loss_ce: 0.007398
2021-11-30 13:52:39,199 iteration 3450 : loss : 0.012340, loss_ce: 0.008250
2021-11-30 13:52:40,556 iteration 3451 : loss : 0.009585, loss_ce: 0.006702
 51%|█████████████▋             | 203/400 [1:25:19<1:19:44, 24.29s/it]2021-11-30 13:52:41,974 iteration 3452 : loss : 0.011112, loss_ce: 0.006710
2021-11-30 13:52:43,312 iteration 3453 : loss : 0.009114, loss_ce: 0.006360
2021-11-30 13:52:44,662 iteration 3454 : loss : 0.012429, loss_ce: 0.006808
2021-11-30 13:52:46,015 iteration 3455 : loss : 0.011088, loss_ce: 0.007033
2021-11-30 13:52:47,363 iteration 3456 : loss : 0.012371, loss_ce: 0.006551
2021-11-30 13:52:48,707 iteration 3457 : loss : 0.009247, loss_ce: 0.006383
2021-11-30 13:52:50,047 iteration 3458 : loss : 0.011036, loss_ce: 0.006639
2021-11-30 13:52:51,401 iteration 3459 : loss : 0.010685, loss_ce: 0.007253
2021-11-30 13:52:52,755 iteration 3460 : loss : 0.014197, loss_ce: 0.009405
2021-11-30 13:52:54,104 iteration 3461 : loss : 0.011588, loss_ce: 0.008197
2021-11-30 13:52:55,451 iteration 3462 : loss : 0.010599, loss_ce: 0.007526
2021-11-30 13:52:56,801 iteration 3463 : loss : 0.013536, loss_ce: 0.007561
2021-11-30 13:52:58,148 iteration 3464 : loss : 0.013980, loss_ce: 0.008135
2021-11-30 13:52:59,507 iteration 3465 : loss : 0.009213, loss_ce: 0.006444
2021-11-30 13:53:00,867 iteration 3466 : loss : 0.010805, loss_ce: 0.007298
2021-11-30 13:53:02,221 iteration 3467 : loss : 0.017471, loss_ce: 0.011366
2021-11-30 13:53:03,576 iteration 3468 : loss : 0.012241, loss_ce: 0.007011
 51%|█████████████▊             | 204/400 [1:25:42<1:18:06, 23.91s/it]2021-11-30 13:53:04,999 iteration 3469 : loss : 0.014933, loss_ce: 0.008696
2021-11-30 13:53:06,344 iteration 3470 : loss : 0.010226, loss_ce: 0.006294
2021-11-30 13:53:07,694 iteration 3471 : loss : 0.011063, loss_ce: 0.007767
2021-11-30 13:53:09,036 iteration 3472 : loss : 0.012479, loss_ce: 0.007393
2021-11-30 13:53:10,391 iteration 3473 : loss : 0.011315, loss_ce: 0.007174
2021-11-30 13:53:11,730 iteration 3474 : loss : 0.011257, loss_ce: 0.006976
2021-11-30 13:53:13,088 iteration 3475 : loss : 0.027203, loss_ce: 0.008415
2021-11-30 13:53:14,445 iteration 3476 : loss : 0.012881, loss_ce: 0.006784
2021-11-30 13:53:15,808 iteration 3477 : loss : 0.011194, loss_ce: 0.007825
2021-11-30 13:53:17,166 iteration 3478 : loss : 0.019988, loss_ce: 0.010295
2021-11-30 13:53:18,530 iteration 3479 : loss : 0.012686, loss_ce: 0.007438
2021-11-30 13:53:19,889 iteration 3480 : loss : 0.014644, loss_ce: 0.008603
2021-11-30 13:53:21,243 iteration 3481 : loss : 0.014674, loss_ce: 0.009260
2021-11-30 13:53:22,602 iteration 3482 : loss : 0.011650, loss_ce: 0.007196
2021-11-30 13:53:23,964 iteration 3483 : loss : 0.009135, loss_ce: 0.006121
2021-11-30 13:53:25,324 iteration 3484 : loss : 0.011850, loss_ce: 0.007781
2021-11-30 13:53:25,325 Training Data Eval:
2021-11-30 13:53:33,111   Average segmentation loss on training set: 0.0114
2021-11-30 13:53:33,111 Validation Data Eval:
2021-11-30 13:53:35,777   Average segmentation loss on validation set: 0.1396
2021-11-30 13:53:37,133 iteration 3485 : loss : 0.011885, loss_ce: 0.007676
 51%|█████████████▊             | 205/400 [1:26:15<1:27:06, 26.80s/it]2021-11-30 13:53:38,557 iteration 3486 : loss : 0.010094, loss_ce: 0.006763
2021-11-30 13:53:39,916 iteration 3487 : loss : 0.009985, loss_ce: 0.006470
2021-11-30 13:53:41,273 iteration 3488 : loss : 0.016169, loss_ce: 0.007508
2021-11-30 13:53:42,629 iteration 3489 : loss : 0.010523, loss_ce: 0.006410
2021-11-30 13:53:43,988 iteration 3490 : loss : 0.014301, loss_ce: 0.007263
2021-11-30 13:53:45,344 iteration 3491 : loss : 0.020638, loss_ce: 0.008548
2021-11-30 13:53:46,693 iteration 3492 : loss : 0.010331, loss_ce: 0.006857
2021-11-30 13:53:48,046 iteration 3493 : loss : 0.009488, loss_ce: 0.006806
2021-11-30 13:53:49,389 iteration 3494 : loss : 0.012554, loss_ce: 0.007957
2021-11-30 13:53:50,737 iteration 3495 : loss : 0.013089, loss_ce: 0.007853
2021-11-30 13:53:52,091 iteration 3496 : loss : 0.012134, loss_ce: 0.007753
2021-11-30 13:53:53,450 iteration 3497 : loss : 0.011305, loss_ce: 0.006519
2021-11-30 13:53:54,806 iteration 3498 : loss : 0.014277, loss_ce: 0.010336
2021-11-30 13:53:56,158 iteration 3499 : loss : 0.009798, loss_ce: 0.007255
2021-11-30 13:53:57,499 iteration 3500 : loss : 0.010636, loss_ce: 0.006923
2021-11-30 13:53:58,854 iteration 3501 : loss : 0.010841, loss_ce: 0.006171
2021-11-30 13:54:00,215 iteration 3502 : loss : 0.011453, loss_ce: 0.007753
 52%|█████████████▉             | 206/400 [1:26:38<1:23:03, 25.69s/it]2021-11-30 13:54:01,641 iteration 3503 : loss : 0.009585, loss_ce: 0.006314
2021-11-30 13:54:02,988 iteration 3504 : loss : 0.009825, loss_ce: 0.006297
2021-11-30 13:54:04,334 iteration 3505 : loss : 0.013424, loss_ce: 0.007304
2021-11-30 13:54:05,691 iteration 3506 : loss : 0.011126, loss_ce: 0.007515
2021-11-30 13:54:07,047 iteration 3507 : loss : 0.010686, loss_ce: 0.006399
2021-11-30 13:54:08,394 iteration 3508 : loss : 0.016736, loss_ce: 0.007359
2021-11-30 13:54:09,747 iteration 3509 : loss : 0.022372, loss_ce: 0.012055
2021-11-30 13:54:11,084 iteration 3510 : loss : 0.010185, loss_ce: 0.006963
2021-11-30 13:54:12,440 iteration 3511 : loss : 0.013371, loss_ce: 0.009469
2021-11-30 13:54:13,793 iteration 3512 : loss : 0.015357, loss_ce: 0.007039
2021-11-30 13:54:15,151 iteration 3513 : loss : 0.011533, loss_ce: 0.007689
2021-11-30 13:54:16,512 iteration 3514 : loss : 0.010324, loss_ce: 0.006868
2021-11-30 13:54:17,859 iteration 3515 : loss : 0.011458, loss_ce: 0.006326
2021-11-30 13:54:19,213 iteration 3516 : loss : 0.010290, loss_ce: 0.007023
2021-11-30 13:54:20,572 iteration 3517 : loss : 0.009609, loss_ce: 0.006531
2021-11-30 13:54:21,921 iteration 3518 : loss : 0.011445, loss_ce: 0.007252
2021-11-30 13:54:23,281 iteration 3519 : loss : 0.010489, loss_ce: 0.006536
 52%|█████████████▉             | 207/400 [1:27:01<1:20:05, 24.90s/it]2021-11-30 13:54:24,685 iteration 3520 : loss : 0.009592, loss_ce: 0.005908
2021-11-30 13:54:26,033 iteration 3521 : loss : 0.010374, loss_ce: 0.006500
2021-11-30 13:54:27,392 iteration 3522 : loss : 0.010336, loss_ce: 0.006339
2021-11-30 13:54:28,744 iteration 3523 : loss : 0.009343, loss_ce: 0.006289
2021-11-30 13:54:30,086 iteration 3524 : loss : 0.010383, loss_ce: 0.006999
2021-11-30 13:54:31,442 iteration 3525 : loss : 0.012874, loss_ce: 0.007350
2021-11-30 13:54:32,787 iteration 3526 : loss : 0.009725, loss_ce: 0.006149
2021-11-30 13:54:34,139 iteration 3527 : loss : 0.011724, loss_ce: 0.008670
2021-11-30 13:54:35,492 iteration 3528 : loss : 0.010344, loss_ce: 0.006249
2021-11-30 13:54:36,831 iteration 3529 : loss : 0.009937, loss_ce: 0.007003
2021-11-30 13:54:38,178 iteration 3530 : loss : 0.011786, loss_ce: 0.008156
2021-11-30 13:54:39,527 iteration 3531 : loss : 0.015523, loss_ce: 0.009285
2021-11-30 13:54:40,883 iteration 3532 : loss : 0.009908, loss_ce: 0.006993
2021-11-30 13:54:42,229 iteration 3533 : loss : 0.014773, loss_ce: 0.009398
2021-11-30 13:54:43,583 iteration 3534 : loss : 0.015694, loss_ce: 0.007996
2021-11-30 13:54:44,925 iteration 3535 : loss : 0.012354, loss_ce: 0.007345
2021-11-30 13:54:46,284 iteration 3536 : loss : 0.013717, loss_ce: 0.008143
 52%|██████████████             | 208/400 [1:27:24<1:17:51, 24.33s/it]2021-11-30 13:54:47,704 iteration 3537 : loss : 0.010355, loss_ce: 0.006382
2021-11-30 13:54:49,050 iteration 3538 : loss : 0.010380, loss_ce: 0.007054
2021-11-30 13:54:50,403 iteration 3539 : loss : 0.011023, loss_ce: 0.007003
2021-11-30 13:54:51,760 iteration 3540 : loss : 0.010279, loss_ce: 0.006384
2021-11-30 13:54:53,095 iteration 3541 : loss : 0.009454, loss_ce: 0.006810
2021-11-30 13:54:54,447 iteration 3542 : loss : 0.010129, loss_ce: 0.006846
2021-11-30 13:54:55,802 iteration 3543 : loss : 0.011004, loss_ce: 0.006408
2021-11-30 13:54:57,148 iteration 3544 : loss : 0.009849, loss_ce: 0.007073
2021-11-30 13:54:58,498 iteration 3545 : loss : 0.011004, loss_ce: 0.006562
2021-11-30 13:54:59,845 iteration 3546 : loss : 0.010581, loss_ce: 0.007368
2021-11-30 13:55:01,201 iteration 3547 : loss : 0.023044, loss_ce: 0.012957
2021-11-30 13:55:02,538 iteration 3548 : loss : 0.010132, loss_ce: 0.006954
2021-11-30 13:55:03,889 iteration 3549 : loss : 0.009707, loss_ce: 0.006145
2021-11-30 13:55:05,224 iteration 3550 : loss : 0.008584, loss_ce: 0.005922
2021-11-30 13:55:06,581 iteration 3551 : loss : 0.011481, loss_ce: 0.007773
2021-11-30 13:55:07,940 iteration 3552 : loss : 0.013831, loss_ce: 0.007398
2021-11-30 13:55:09,275 iteration 3553 : loss : 0.009732, loss_ce: 0.006394
 52%|██████████████             | 209/400 [1:27:47<1:16:10, 23.93s/it]2021-11-30 13:55:10,669 iteration 3554 : loss : 0.010300, loss_ce: 0.006311
2021-11-30 13:55:12,007 iteration 3555 : loss : 0.015762, loss_ce: 0.007014
2021-11-30 13:55:13,350 iteration 3556 : loss : 0.010465, loss_ce: 0.006896
2021-11-30 13:55:14,699 iteration 3557 : loss : 0.010699, loss_ce: 0.006626
2021-11-30 13:55:16,045 iteration 3558 : loss : 0.013796, loss_ce: 0.008983
2021-11-30 13:55:17,384 iteration 3559 : loss : 0.009640, loss_ce: 0.006784
2021-11-30 13:55:18,728 iteration 3560 : loss : 0.011356, loss_ce: 0.007004
2021-11-30 13:55:20,082 iteration 3561 : loss : 0.009594, loss_ce: 0.006319
2021-11-30 13:55:21,437 iteration 3562 : loss : 0.010829, loss_ce: 0.007819
2021-11-30 13:55:22,788 iteration 3563 : loss : 0.010030, loss_ce: 0.006499
2021-11-30 13:55:24,149 iteration 3564 : loss : 0.008798, loss_ce: 0.006513
2021-11-30 13:55:25,495 iteration 3565 : loss : 0.013037, loss_ce: 0.009210
2021-11-30 13:55:26,841 iteration 3566 : loss : 0.016182, loss_ce: 0.007932
2021-11-30 13:55:28,189 iteration 3567 : loss : 0.008926, loss_ce: 0.006190
2021-11-30 13:55:29,528 iteration 3568 : loss : 0.010895, loss_ce: 0.006867
2021-11-30 13:55:30,881 iteration 3569 : loss : 0.009204, loss_ce: 0.006285
2021-11-30 13:55:30,882 Training Data Eval:
2021-11-30 13:55:38,484   Average segmentation loss on training set: 0.0094
2021-11-30 13:55:38,484 Validation Data Eval:
2021-11-30 13:55:41,103   Average segmentation loss on validation set: 0.1703
2021-11-30 13:55:42,436 iteration 3570 : loss : 0.009849, loss_ce: 0.006939
 52%|██████████████▏            | 210/400 [1:28:21<1:24:32, 26.70s/it]2021-11-30 13:55:43,851 iteration 3571 : loss : 0.010295, loss_ce: 0.007013
2021-11-30 13:55:45,210 iteration 3572 : loss : 0.010960, loss_ce: 0.006254
2021-11-30 13:55:46,556 iteration 3573 : loss : 0.009559, loss_ce: 0.006254
2021-11-30 13:55:47,914 iteration 3574 : loss : 0.016067, loss_ce: 0.007521
2021-11-30 13:55:49,271 iteration 3575 : loss : 0.012339, loss_ce: 0.007589
2021-11-30 13:55:50,629 iteration 3576 : loss : 0.010492, loss_ce: 0.006605
2021-11-30 13:55:51,986 iteration 3577 : loss : 0.009634, loss_ce: 0.006445
2021-11-30 13:55:53,336 iteration 3578 : loss : 0.010877, loss_ce: 0.006978
2021-11-30 13:55:54,680 iteration 3579 : loss : 0.010947, loss_ce: 0.007587
2021-11-30 13:55:56,043 iteration 3580 : loss : 0.009467, loss_ce: 0.006048
2021-11-30 13:55:57,394 iteration 3581 : loss : 0.010841, loss_ce: 0.007684
2021-11-30 13:55:58,735 iteration 3582 : loss : 0.010171, loss_ce: 0.006909
2021-11-30 13:56:00,088 iteration 3583 : loss : 0.011803, loss_ce: 0.007891
2021-11-30 13:56:01,445 iteration 3584 : loss : 0.010868, loss_ce: 0.006895
2021-11-30 13:56:02,797 iteration 3585 : loss : 0.010804, loss_ce: 0.007162
2021-11-30 13:56:04,144 iteration 3586 : loss : 0.009081, loss_ce: 0.006706
2021-11-30 13:56:05,502 iteration 3587 : loss : 0.012181, loss_ce: 0.006808
 53%|██████████████▏            | 211/400 [1:28:44<1:20:39, 25.61s/it]2021-11-30 13:56:06,910 iteration 3588 : loss : 0.011711, loss_ce: 0.007257
2021-11-30 13:56:08,252 iteration 3589 : loss : 0.010318, loss_ce: 0.006590
2021-11-30 13:56:09,604 iteration 3590 : loss : 0.009341, loss_ce: 0.006535
2021-11-30 13:56:10,960 iteration 3591 : loss : 0.014560, loss_ce: 0.007172
2021-11-30 13:56:12,314 iteration 3592 : loss : 0.013464, loss_ce: 0.008855
2021-11-30 13:56:13,674 iteration 3593 : loss : 0.010768, loss_ce: 0.006136
2021-11-30 13:56:15,030 iteration 3594 : loss : 0.010068, loss_ce: 0.006106
2021-11-30 13:56:16,391 iteration 3595 : loss : 0.013096, loss_ce: 0.009813
2021-11-30 13:56:17,749 iteration 3596 : loss : 0.009492, loss_ce: 0.006034
2021-11-30 13:56:19,102 iteration 3597 : loss : 0.012806, loss_ce: 0.006553
2021-11-30 13:56:20,461 iteration 3598 : loss : 0.009135, loss_ce: 0.006716
2021-11-30 13:56:21,807 iteration 3599 : loss : 0.009330, loss_ce: 0.006510
2021-11-30 13:56:23,165 iteration 3600 : loss : 0.009980, loss_ce: 0.006704
2021-11-30 13:56:24,521 iteration 3601 : loss : 0.010889, loss_ce: 0.007636
2021-11-30 13:56:25,865 iteration 3602 : loss : 0.010026, loss_ce: 0.006676
2021-11-30 13:56:27,224 iteration 3603 : loss : 0.011009, loss_ce: 0.006737
2021-11-30 13:56:28,577 iteration 3604 : loss : 0.010403, loss_ce: 0.007157
 53%|██████████████▎            | 212/400 [1:29:07<1:17:51, 24.85s/it]2021-11-30 13:56:29,988 iteration 3605 : loss : 0.008741, loss_ce: 0.006024
2021-11-30 13:56:31,322 iteration 3606 : loss : 0.009934, loss_ce: 0.006339
2021-11-30 13:56:32,676 iteration 3607 : loss : 0.011862, loss_ce: 0.006780
2021-11-30 13:56:34,031 iteration 3608 : loss : 0.011737, loss_ce: 0.007662
2021-11-30 13:56:35,385 iteration 3609 : loss : 0.010596, loss_ce: 0.007357
2021-11-30 13:56:36,727 iteration 3610 : loss : 0.009223, loss_ce: 0.006439
2021-11-30 13:56:38,082 iteration 3611 : loss : 0.012208, loss_ce: 0.007296
2021-11-30 13:56:39,424 iteration 3612 : loss : 0.009269, loss_ce: 0.006588
2021-11-30 13:56:40,757 iteration 3613 : loss : 0.013509, loss_ce: 0.009547
2021-11-30 13:56:42,112 iteration 3614 : loss : 0.009994, loss_ce: 0.006369
2021-11-30 13:56:43,465 iteration 3615 : loss : 0.012865, loss_ce: 0.007042
2021-11-30 13:56:44,810 iteration 3616 : loss : 0.009125, loss_ce: 0.006036
2021-11-30 13:56:46,152 iteration 3617 : loss : 0.010311, loss_ce: 0.006617
2021-11-30 13:56:47,498 iteration 3618 : loss : 0.008885, loss_ce: 0.006052
2021-11-30 13:56:48,841 iteration 3619 : loss : 0.015887, loss_ce: 0.010650
2021-11-30 13:56:50,200 iteration 3620 : loss : 0.009781, loss_ce: 0.006689
2021-11-30 13:56:51,559 iteration 3621 : loss : 0.010013, loss_ce: 0.006358
 53%|██████████████▍            | 213/400 [1:29:30<1:15:41, 24.29s/it]2021-11-30 13:56:52,963 iteration 3622 : loss : 0.010667, loss_ce: 0.006957
2021-11-30 13:56:54,323 iteration 3623 : loss : 0.009390, loss_ce: 0.006639
2021-11-30 13:56:55,680 iteration 3624 : loss : 0.015818, loss_ce: 0.008709
2021-11-30 13:56:57,041 iteration 3625 : loss : 0.010842, loss_ce: 0.006945
2021-11-30 13:56:58,394 iteration 3626 : loss : 0.013217, loss_ce: 0.006993
2021-11-30 13:56:59,751 iteration 3627 : loss : 0.008979, loss_ce: 0.006111
2021-11-30 13:57:01,116 iteration 3628 : loss : 0.009484, loss_ce: 0.006161
2021-11-30 13:57:02,479 iteration 3629 : loss : 0.013827, loss_ce: 0.007273
2021-11-30 13:57:03,838 iteration 3630 : loss : 0.011704, loss_ce: 0.007672
2021-11-30 13:57:05,195 iteration 3631 : loss : 0.009479, loss_ce: 0.006332
2021-11-30 13:57:06,540 iteration 3632 : loss : 0.010167, loss_ce: 0.006021
2021-11-30 13:57:07,891 iteration 3633 : loss : 0.015353, loss_ce: 0.007566
2021-11-30 13:57:09,235 iteration 3634 : loss : 0.011913, loss_ce: 0.008510
2021-11-30 13:57:10,591 iteration 3635 : loss : 0.010970, loss_ce: 0.006458
2021-11-30 13:57:11,948 iteration 3636 : loss : 0.009418, loss_ce: 0.005954
2021-11-30 13:57:13,308 iteration 3637 : loss : 0.010174, loss_ce: 0.007053
2021-11-30 13:57:14,660 iteration 3638 : loss : 0.011541, loss_ce: 0.007737
 54%|██████████████▍            | 214/400 [1:29:53<1:14:11, 23.93s/it]2021-11-30 13:57:16,071 iteration 3639 : loss : 0.010228, loss_ce: 0.006196
2021-11-30 13:57:17,414 iteration 3640 : loss : 0.013902, loss_ce: 0.008126
2021-11-30 13:57:18,765 iteration 3641 : loss : 0.013000, loss_ce: 0.007520
2021-11-30 13:57:20,118 iteration 3642 : loss : 0.014619, loss_ce: 0.010323
2021-11-30 13:57:21,475 iteration 3643 : loss : 0.012552, loss_ce: 0.008017
2021-11-30 13:57:22,832 iteration 3644 : loss : 0.009943, loss_ce: 0.006517
2021-11-30 13:57:24,186 iteration 3645 : loss : 0.010908, loss_ce: 0.007511
2021-11-30 13:57:25,543 iteration 3646 : loss : 0.008361, loss_ce: 0.005889
2021-11-30 13:57:26,902 iteration 3647 : loss : 0.009762, loss_ce: 0.006451
2021-11-30 13:57:28,256 iteration 3648 : loss : 0.009566, loss_ce: 0.006238
2021-11-30 13:57:29,608 iteration 3649 : loss : 0.008269, loss_ce: 0.006041
2021-11-30 13:57:30,957 iteration 3650 : loss : 0.008746, loss_ce: 0.006472
2021-11-30 13:57:32,316 iteration 3651 : loss : 0.013724, loss_ce: 0.007259
2021-11-30 13:57:33,663 iteration 3652 : loss : 0.008410, loss_ce: 0.006042
2021-11-30 13:57:35,011 iteration 3653 : loss : 0.010271, loss_ce: 0.006531
2021-11-30 13:57:36,371 iteration 3654 : loss : 0.011121, loss_ce: 0.006436
2021-11-30 13:57:36,371 Training Data Eval:
2021-11-30 13:57:43,975   Average segmentation loss on training set: 0.0105
2021-11-30 13:57:43,975 Validation Data Eval:
2021-11-30 13:57:46,596   Average segmentation loss on validation set: 0.1865
2021-11-30 13:57:47,956 iteration 3655 : loss : 0.010443, loss_ce: 0.006246
 54%|██████████████▌            | 215/400 [1:30:26<1:22:27, 26.74s/it]2021-11-30 13:57:49,369 iteration 3656 : loss : 0.010595, loss_ce: 0.006252
2021-11-30 13:57:50,711 iteration 3657 : loss : 0.011939, loss_ce: 0.007250
2021-11-30 13:57:52,067 iteration 3658 : loss : 0.009006, loss_ce: 0.006214
2021-11-30 13:57:53,426 iteration 3659 : loss : 0.010441, loss_ce: 0.007060
2021-11-30 13:57:54,768 iteration 3660 : loss : 0.009478, loss_ce: 0.006118
2021-11-30 13:57:56,116 iteration 3661 : loss : 0.011757, loss_ce: 0.008029
2021-11-30 13:57:57,464 iteration 3662 : loss : 0.011438, loss_ce: 0.007222
2021-11-30 13:57:58,808 iteration 3663 : loss : 0.012688, loss_ce: 0.007955
2021-11-30 13:58:00,173 iteration 3664 : loss : 0.010272, loss_ce: 0.006026
2021-11-30 13:58:01,529 iteration 3665 : loss : 0.009002, loss_ce: 0.006079
2021-11-30 13:58:02,885 iteration 3666 : loss : 0.009554, loss_ce: 0.006403
2021-11-30 13:58:04,237 iteration 3667 : loss : 0.009982, loss_ce: 0.006078
2021-11-30 13:58:05,592 iteration 3668 : loss : 0.014079, loss_ce: 0.008368
2021-11-30 13:58:06,949 iteration 3669 : loss : 0.008975, loss_ce: 0.006930
2021-11-30 13:58:08,299 iteration 3670 : loss : 0.009244, loss_ce: 0.006570
2021-11-30 13:58:09,645 iteration 3671 : loss : 0.008852, loss_ce: 0.006174
2021-11-30 13:58:11,005 iteration 3672 : loss : 0.009250, loss_ce: 0.006548
 54%|██████████████▌            | 216/400 [1:30:49<1:18:36, 25.63s/it]2021-11-30 13:58:12,408 iteration 3673 : loss : 0.008665, loss_ce: 0.006018
2021-11-30 13:58:13,754 iteration 3674 : loss : 0.012206, loss_ce: 0.008400
2021-11-30 13:58:15,107 iteration 3675 : loss : 0.011174, loss_ce: 0.006262
2021-11-30 13:58:16,443 iteration 3676 : loss : 0.011056, loss_ce: 0.006544
2021-11-30 13:58:17,797 iteration 3677 : loss : 0.009977, loss_ce: 0.007215
2021-11-30 13:58:19,153 iteration 3678 : loss : 0.009272, loss_ce: 0.005791
2021-11-30 13:58:20,490 iteration 3679 : loss : 0.009272, loss_ce: 0.006033
2021-11-30 13:58:21,833 iteration 3680 : loss : 0.014910, loss_ce: 0.007797
2021-11-30 13:58:23,186 iteration 3681 : loss : 0.011713, loss_ce: 0.008486
2021-11-30 13:58:24,548 iteration 3682 : loss : 0.010141, loss_ce: 0.006795
2021-11-30 13:58:25,895 iteration 3683 : loss : 0.010319, loss_ce: 0.006371
2021-11-30 13:58:27,242 iteration 3684 : loss : 0.011850, loss_ce: 0.006359
2021-11-30 13:58:28,596 iteration 3685 : loss : 0.012866, loss_ce: 0.007675
2021-11-30 13:58:29,935 iteration 3686 : loss : 0.010261, loss_ce: 0.006645
2021-11-30 13:58:31,297 iteration 3687 : loss : 0.009815, loss_ce: 0.006562
2021-11-30 13:58:32,641 iteration 3688 : loss : 0.010714, loss_ce: 0.007530
2021-11-30 13:58:33,992 iteration 3689 : loss : 0.016263, loss_ce: 0.007276
 54%|██████████████▋            | 217/400 [1:31:12<1:15:45, 24.84s/it]2021-11-30 13:58:35,406 iteration 3690 : loss : 0.010182, loss_ce: 0.006846
2021-11-30 13:58:36,756 iteration 3691 : loss : 0.010409, loss_ce: 0.006536
2021-11-30 13:58:38,108 iteration 3692 : loss : 0.009057, loss_ce: 0.005926
2021-11-30 13:58:39,462 iteration 3693 : loss : 0.012858, loss_ce: 0.007549
2021-11-30 13:58:40,818 iteration 3694 : loss : 0.016907, loss_ce: 0.010419
2021-11-30 13:58:42,178 iteration 3695 : loss : 0.019649, loss_ce: 0.009148
2021-11-30 13:58:43,541 iteration 3696 : loss : 0.011983, loss_ce: 0.007716
2021-11-30 13:58:44,904 iteration 3697 : loss : 0.015532, loss_ce: 0.007559
2021-11-30 13:58:46,266 iteration 3698 : loss : 0.011371, loss_ce: 0.007231
2021-11-30 13:58:47,621 iteration 3699 : loss : 0.009439, loss_ce: 0.005989
2021-11-30 13:58:48,975 iteration 3700 : loss : 0.010884, loss_ce: 0.007106
2021-11-30 13:58:50,329 iteration 3701 : loss : 0.009024, loss_ce: 0.005920
2021-11-30 13:58:51,689 iteration 3702 : loss : 0.009758, loss_ce: 0.006209
2021-11-30 13:58:53,047 iteration 3703 : loss : 0.010518, loss_ce: 0.007091
2021-11-30 13:58:54,404 iteration 3704 : loss : 0.009820, loss_ce: 0.007051
2021-11-30 13:58:55,756 iteration 3705 : loss : 0.010573, loss_ce: 0.006501
2021-11-30 13:58:57,113 iteration 3706 : loss : 0.015116, loss_ce: 0.008346
 55%|██████████████▋            | 218/400 [1:31:35<1:13:47, 24.33s/it]2021-11-30 13:58:58,549 iteration 3707 : loss : 0.008613, loss_ce: 0.005949
2021-11-30 13:58:59,911 iteration 3708 : loss : 0.010040, loss_ce: 0.007077
2021-11-30 13:59:01,266 iteration 3709 : loss : 0.009925, loss_ce: 0.006694
2021-11-30 13:59:02,625 iteration 3710 : loss : 0.010290, loss_ce: 0.006269
2021-11-30 13:59:03,978 iteration 3711 : loss : 0.010395, loss_ce: 0.007061
2021-11-30 13:59:05,337 iteration 3712 : loss : 0.013450, loss_ce: 0.006129
2021-11-30 13:59:06,694 iteration 3713 : loss : 0.009124, loss_ce: 0.006202
2021-11-30 13:59:08,050 iteration 3714 : loss : 0.012087, loss_ce: 0.008850
2021-11-30 13:59:09,406 iteration 3715 : loss : 0.011642, loss_ce: 0.007022
2021-11-30 13:59:10,764 iteration 3716 : loss : 0.011500, loss_ce: 0.007842
2021-11-30 13:59:12,124 iteration 3717 : loss : 0.009054, loss_ce: 0.005873
2021-11-30 13:59:13,483 iteration 3718 : loss : 0.010207, loss_ce: 0.006323
2021-11-30 13:59:14,832 iteration 3719 : loss : 0.009618, loss_ce: 0.006872
2021-11-30 13:59:16,180 iteration 3720 : loss : 0.009571, loss_ce: 0.005921
2021-11-30 13:59:17,528 iteration 3721 : loss : 0.010992, loss_ce: 0.006943
2021-11-30 13:59:18,878 iteration 3722 : loss : 0.009575, loss_ce: 0.005997
2021-11-30 13:59:20,233 iteration 3723 : loss : 0.012342, loss_ce: 0.007425
 55%|██████████████▊            | 219/400 [1:31:58<1:12:17, 23.96s/it]2021-11-30 13:59:21,645 iteration 3724 : loss : 0.012579, loss_ce: 0.006487
2021-11-30 13:59:22,996 iteration 3725 : loss : 0.009879, loss_ce: 0.006364
2021-11-30 13:59:24,348 iteration 3726 : loss : 0.009916, loss_ce: 0.006117
2021-11-30 13:59:25,697 iteration 3727 : loss : 0.015834, loss_ce: 0.010853
2021-11-30 13:59:27,043 iteration 3728 : loss : 0.012208, loss_ce: 0.008029
2021-11-30 13:59:28,387 iteration 3729 : loss : 0.008261, loss_ce: 0.005648
2021-11-30 13:59:29,727 iteration 3730 : loss : 0.009950, loss_ce: 0.006181
2021-11-30 13:59:31,079 iteration 3731 : loss : 0.012940, loss_ce: 0.007718
2021-11-30 13:59:32,413 iteration 3732 : loss : 0.008971, loss_ce: 0.006025
2021-11-30 13:59:33,761 iteration 3733 : loss : 0.010894, loss_ce: 0.006263
2021-11-30 13:59:35,110 iteration 3734 : loss : 0.010514, loss_ce: 0.007038
2021-11-30 13:59:36,456 iteration 3735 : loss : 0.008859, loss_ce: 0.006206
2021-11-30 13:59:37,811 iteration 3736 : loss : 0.011565, loss_ce: 0.007543
2021-11-30 13:59:39,157 iteration 3737 : loss : 0.009647, loss_ce: 0.006355
2021-11-30 13:59:40,505 iteration 3738 : loss : 0.017007, loss_ce: 0.012347
2021-11-30 13:59:41,854 iteration 3739 : loss : 0.012660, loss_ce: 0.006576
2021-11-30 13:59:41,854 Training Data Eval:
2021-11-30 13:59:49,443   Average segmentation loss on training set: 0.0100
2021-11-30 13:59:49,444 Validation Data Eval:
2021-11-30 13:59:52,076   Average segmentation loss on validation set: 0.1475
2021-11-30 13:59:53,414 iteration 3740 : loss : 0.010558, loss_ce: 0.007144
 55%|██████████████▊            | 220/400 [1:32:32<1:20:10, 26.73s/it]2021-11-30 13:59:54,826 iteration 3741 : loss : 0.011777, loss_ce: 0.008271
2021-11-30 13:59:56,170 iteration 3742 : loss : 0.010190, loss_ce: 0.006279
2021-11-30 13:59:57,526 iteration 3743 : loss : 0.010502, loss_ce: 0.006630
2021-11-30 13:59:58,871 iteration 3744 : loss : 0.008659, loss_ce: 0.006515
2021-11-30 14:00:00,224 iteration 3745 : loss : 0.010562, loss_ce: 0.006305
2021-11-30 14:00:01,584 iteration 3746 : loss : 0.009333, loss_ce: 0.005926
2021-11-30 14:00:02,936 iteration 3747 : loss : 0.010021, loss_ce: 0.007066
2021-11-30 14:00:04,284 iteration 3748 : loss : 0.010434, loss_ce: 0.006536
2021-11-30 14:00:05,633 iteration 3749 : loss : 0.013585, loss_ce: 0.008156
2021-11-30 14:00:06,976 iteration 3750 : loss : 0.008556, loss_ce: 0.005903
2021-11-30 14:00:08,325 iteration 3751 : loss : 0.008393, loss_ce: 0.005740
2021-11-30 14:00:09,661 iteration 3752 : loss : 0.011749, loss_ce: 0.006301
2021-11-30 14:00:11,020 iteration 3753 : loss : 0.008300, loss_ce: 0.005848
2021-11-30 14:00:12,367 iteration 3754 : loss : 0.008902, loss_ce: 0.006297
2021-11-30 14:00:13,719 iteration 3755 : loss : 0.010639, loss_ce: 0.007083
2021-11-30 14:00:15,075 iteration 3756 : loss : 0.010785, loss_ce: 0.006847
2021-11-30 14:00:16,422 iteration 3757 : loss : 0.010160, loss_ce: 0.006956
 55%|██████████████▉            | 221/400 [1:32:55<1:16:24, 25.61s/it]2021-11-30 14:00:17,830 iteration 3758 : loss : 0.010734, loss_ce: 0.006169
2021-11-30 14:00:19,165 iteration 3759 : loss : 0.008368, loss_ce: 0.005956
2021-11-30 14:00:20,511 iteration 3760 : loss : 0.011943, loss_ce: 0.008255
2021-11-30 14:00:21,854 iteration 3761 : loss : 0.009093, loss_ce: 0.006200
2021-11-30 14:00:23,208 iteration 3762 : loss : 0.008869, loss_ce: 0.005876
2021-11-30 14:00:24,559 iteration 3763 : loss : 0.012349, loss_ce: 0.006499
2021-11-30 14:00:25,901 iteration 3764 : loss : 0.011668, loss_ce: 0.008149
2021-11-30 14:00:27,250 iteration 3765 : loss : 0.009981, loss_ce: 0.006257
2021-11-30 14:00:28,591 iteration 3766 : loss : 0.009767, loss_ce: 0.006292
2021-11-30 14:00:29,947 iteration 3767 : loss : 0.010218, loss_ce: 0.006812
2021-11-30 14:00:31,300 iteration 3768 : loss : 0.008978, loss_ce: 0.006657
2021-11-30 14:00:32,648 iteration 3769 : loss : 0.009895, loss_ce: 0.006132
2021-11-30 14:00:34,003 iteration 3770 : loss : 0.010193, loss_ce: 0.006592
2021-11-30 14:00:35,346 iteration 3771 : loss : 0.011657, loss_ce: 0.007196
2021-11-30 14:00:36,699 iteration 3772 : loss : 0.011913, loss_ce: 0.007591
2021-11-30 14:00:38,057 iteration 3773 : loss : 0.010388, loss_ce: 0.006497
2021-11-30 14:00:39,416 iteration 3774 : loss : 0.008938, loss_ce: 0.006455
 56%|██████████████▉            | 222/400 [1:33:18<1:13:38, 24.83s/it]2021-11-30 14:00:40,831 iteration 3775 : loss : 0.013917, loss_ce: 0.009396
2021-11-30 14:00:42,185 iteration 3776 : loss : 0.008461, loss_ce: 0.006049
2021-11-30 14:00:43,535 iteration 3777 : loss : 0.008976, loss_ce: 0.006285
2021-11-30 14:00:44,887 iteration 3778 : loss : 0.011690, loss_ce: 0.006541
2021-11-30 14:00:46,247 iteration 3779 : loss : 0.011875, loss_ce: 0.006733
2021-11-30 14:00:47,596 iteration 3780 : loss : 0.011411, loss_ce: 0.006806
2021-11-30 14:00:48,957 iteration 3781 : loss : 0.012042, loss_ce: 0.006484
2021-11-30 14:00:50,309 iteration 3782 : loss : 0.010354, loss_ce: 0.006907
2021-11-30 14:00:51,669 iteration 3783 : loss : 0.009094, loss_ce: 0.006398
2021-11-30 14:00:53,027 iteration 3784 : loss : 0.011030, loss_ce: 0.007383
2021-11-30 14:00:54,372 iteration 3785 : loss : 0.010863, loss_ce: 0.007277
2021-11-30 14:00:55,729 iteration 3786 : loss : 0.009443, loss_ce: 0.006028
2021-11-30 14:00:57,088 iteration 3787 : loss : 0.008385, loss_ce: 0.005847
2021-11-30 14:00:58,437 iteration 3788 : loss : 0.009740, loss_ce: 0.006327
2021-11-30 14:00:59,793 iteration 3789 : loss : 0.010221, loss_ce: 0.006266
2021-11-30 14:01:01,158 iteration 3790 : loss : 0.010301, loss_ce: 0.006785
2021-11-30 14:01:02,514 iteration 3791 : loss : 0.009059, loss_ce: 0.006214
 56%|███████████████            | 223/400 [1:33:41<1:11:42, 24.31s/it]2021-11-30 14:01:03,947 iteration 3792 : loss : 0.009514, loss_ce: 0.006137
2021-11-30 14:01:05,303 iteration 3793 : loss : 0.010596, loss_ce: 0.007225
2021-11-30 14:01:06,665 iteration 3794 : loss : 0.009164, loss_ce: 0.006168
2021-11-30 14:01:08,022 iteration 3795 : loss : 0.012081, loss_ce: 0.008831
2021-11-30 14:01:09,377 iteration 3796 : loss : 0.015783, loss_ce: 0.007873
2021-11-30 14:01:10,735 iteration 3797 : loss : 0.011059, loss_ce: 0.006816
2021-11-30 14:01:12,092 iteration 3798 : loss : 0.011672, loss_ce: 0.006707
2021-11-30 14:01:13,451 iteration 3799 : loss : 0.009682, loss_ce: 0.006525
2021-11-30 14:01:14,808 iteration 3800 : loss : 0.008457, loss_ce: 0.005776
2021-11-30 14:01:16,172 iteration 3801 : loss : 0.015959, loss_ce: 0.006828
2021-11-30 14:01:17,524 iteration 3802 : loss : 0.009460, loss_ce: 0.006113
2021-11-30 14:01:18,873 iteration 3803 : loss : 0.008266, loss_ce: 0.006355
2021-11-30 14:01:20,235 iteration 3804 : loss : 0.008404, loss_ce: 0.005826
2021-11-30 14:01:21,590 iteration 3805 : loss : 0.010778, loss_ce: 0.007104
2021-11-30 14:01:22,955 iteration 3806 : loss : 0.010112, loss_ce: 0.006522
2021-11-30 14:01:24,307 iteration 3807 : loss : 0.009221, loss_ce: 0.005873
2021-11-30 14:01:25,662 iteration 3808 : loss : 0.008871, loss_ce: 0.006306
 56%|███████████████            | 224/400 [1:34:04<1:10:18, 23.97s/it]2021-11-30 14:01:27,104 iteration 3809 : loss : 0.007919, loss_ce: 0.005756
2021-11-30 14:01:28,458 iteration 3810 : loss : 0.009215, loss_ce: 0.006614
2021-11-30 14:01:29,810 iteration 3811 : loss : 0.009767, loss_ce: 0.006061
2021-11-30 14:01:31,167 iteration 3812 : loss : 0.008967, loss_ce: 0.005841
2021-11-30 14:01:32,524 iteration 3813 : loss : 0.010425, loss_ce: 0.007239
2021-11-30 14:01:33,871 iteration 3814 : loss : 0.012843, loss_ce: 0.006559
2021-11-30 14:01:35,227 iteration 3815 : loss : 0.011504, loss_ce: 0.006951
2021-11-30 14:01:36,582 iteration 3816 : loss : 0.008868, loss_ce: 0.005837
2021-11-30 14:01:37,930 iteration 3817 : loss : 0.010719, loss_ce: 0.006967
2021-11-30 14:01:39,287 iteration 3818 : loss : 0.009622, loss_ce: 0.006143
2021-11-30 14:01:40,633 iteration 3819 : loss : 0.011747, loss_ce: 0.007193
2021-11-30 14:01:41,988 iteration 3820 : loss : 0.008129, loss_ce: 0.005980
2021-11-30 14:01:43,342 iteration 3821 : loss : 0.009856, loss_ce: 0.006384
2021-11-30 14:01:44,694 iteration 3822 : loss : 0.010557, loss_ce: 0.006873
2021-11-30 14:01:46,049 iteration 3823 : loss : 0.011514, loss_ce: 0.006359
2021-11-30 14:01:47,393 iteration 3824 : loss : 0.012049, loss_ce: 0.006881
2021-11-30 14:01:47,393 Training Data Eval:
2021-11-30 14:01:54,993   Average segmentation loss on training set: 0.0090
2021-11-30 14:01:54,994 Validation Data Eval:
2021-11-30 14:01:57,633   Average segmentation loss on validation set: 0.1580
2021-11-30 14:01:58,976 iteration 3825 : loss : 0.010000, loss_ce: 0.006599
 56%|███████████████▏           | 225/400 [1:34:37<1:18:03, 26.76s/it]2021-11-30 14:02:00,390 iteration 3826 : loss : 0.007921, loss_ce: 0.005873
2021-11-30 14:02:01,726 iteration 3827 : loss : 0.008997, loss_ce: 0.006583
2021-11-30 14:02:03,085 iteration 3828 : loss : 0.016481, loss_ce: 0.007585
2021-11-30 14:02:04,430 iteration 3829 : loss : 0.011546, loss_ce: 0.007121
2021-11-30 14:02:05,779 iteration 3830 : loss : 0.010271, loss_ce: 0.007015
2021-11-30 14:02:07,128 iteration 3831 : loss : 0.010896, loss_ce: 0.006904
2021-11-30 14:02:08,463 iteration 3832 : loss : 0.009577, loss_ce: 0.005898
2021-11-30 14:02:09,820 iteration 3833 : loss : 0.011159, loss_ce: 0.007296
2021-11-30 14:02:11,168 iteration 3834 : loss : 0.009966, loss_ce: 0.007102
2021-11-30 14:02:12,519 iteration 3835 : loss : 0.008749, loss_ce: 0.005963
2021-11-30 14:02:13,873 iteration 3836 : loss : 0.011071, loss_ce: 0.007084
2021-11-30 14:02:15,220 iteration 3837 : loss : 0.009699, loss_ce: 0.006502
2021-11-30 14:02:16,579 iteration 3838 : loss : 0.009667, loss_ce: 0.005906
2021-11-30 14:02:17,925 iteration 3839 : loss : 0.009645, loss_ce: 0.006306
2021-11-30 14:02:19,276 iteration 3840 : loss : 0.008647, loss_ce: 0.005688
2021-11-30 14:02:20,629 iteration 3841 : loss : 0.010570, loss_ce: 0.007213
2021-11-30 14:02:21,974 iteration 3842 : loss : 0.011411, loss_ce: 0.007558
 56%|███████████████▎           | 226/400 [1:35:00<1:14:21, 25.64s/it]2021-11-30 14:02:23,407 iteration 3843 : loss : 0.010457, loss_ce: 0.006145
2021-11-30 14:02:24,763 iteration 3844 : loss : 0.010844, loss_ce: 0.007744
2021-11-30 14:02:26,099 iteration 3845 : loss : 0.010457, loss_ce: 0.006174
2021-11-30 14:02:27,460 iteration 3846 : loss : 0.011050, loss_ce: 0.007820
2021-11-30 14:02:28,803 iteration 3847 : loss : 0.008315, loss_ce: 0.006033
2021-11-30 14:02:30,154 iteration 3848 : loss : 0.010452, loss_ce: 0.006091
2021-11-30 14:02:31,500 iteration 3849 : loss : 0.012204, loss_ce: 0.006870
2021-11-30 14:02:32,846 iteration 3850 : loss : 0.016595, loss_ce: 0.009296
2021-11-30 14:02:34,184 iteration 3851 : loss : 0.010380, loss_ce: 0.006547
2021-11-30 14:02:35,541 iteration 3852 : loss : 0.009609, loss_ce: 0.006185
2021-11-30 14:02:36,897 iteration 3853 : loss : 0.009445, loss_ce: 0.006388
2021-11-30 14:02:38,242 iteration 3854 : loss : 0.009051, loss_ce: 0.005831
2021-11-30 14:02:39,597 iteration 3855 : loss : 0.010322, loss_ce: 0.006162
2021-11-30 14:02:40,953 iteration 3856 : loss : 0.009849, loss_ce: 0.006519
2021-11-30 14:02:42,299 iteration 3857 : loss : 0.009034, loss_ce: 0.006429
2021-11-30 14:02:43,648 iteration 3858 : loss : 0.009468, loss_ce: 0.006455
2021-11-30 14:02:44,995 iteration 3859 : loss : 0.008252, loss_ce: 0.006054
 57%|███████████████▎           | 227/400 [1:35:23<1:11:38, 24.85s/it]2021-11-30 14:02:46,400 iteration 3860 : loss : 0.008902, loss_ce: 0.005875
2021-11-30 14:02:47,737 iteration 3861 : loss : 0.010371, loss_ce: 0.007546
2021-11-30 14:02:49,092 iteration 3862 : loss : 0.010260, loss_ce: 0.005683
2021-11-30 14:02:50,436 iteration 3863 : loss : 0.011643, loss_ce: 0.007373
2021-11-30 14:02:51,791 iteration 3864 : loss : 0.008765, loss_ce: 0.006009
2021-11-30 14:02:53,136 iteration 3865 : loss : 0.007865, loss_ce: 0.005460
2021-11-30 14:02:54,478 iteration 3866 : loss : 0.009436, loss_ce: 0.005825
2021-11-30 14:02:55,826 iteration 3867 : loss : 0.011037, loss_ce: 0.007021
2021-11-30 14:02:57,168 iteration 3868 : loss : 0.008127, loss_ce: 0.005671
2021-11-30 14:02:58,516 iteration 3869 : loss : 0.009787, loss_ce: 0.007045
2021-11-30 14:02:59,874 iteration 3870 : loss : 0.009807, loss_ce: 0.006484
2021-11-30 14:03:01,230 iteration 3871 : loss : 0.008709, loss_ce: 0.006133
2021-11-30 14:03:02,585 iteration 3872 : loss : 0.010057, loss_ce: 0.006612
2021-11-30 14:03:03,936 iteration 3873 : loss : 0.008132, loss_ce: 0.006028
2021-11-30 14:03:05,295 iteration 3874 : loss : 0.009930, loss_ce: 0.006015
2021-11-30 14:03:06,654 iteration 3875 : loss : 0.009439, loss_ce: 0.006871
2021-11-30 14:03:08,013 iteration 3876 : loss : 0.010121, loss_ce: 0.006912
 57%|███████████████▍           | 228/400 [1:35:46<1:09:39, 24.30s/it]2021-11-30 14:03:09,429 iteration 3877 : loss : 0.011615, loss_ce: 0.007493
2021-11-30 14:03:10,782 iteration 3878 : loss : 0.010142, loss_ce: 0.006830
2021-11-30 14:03:12,141 iteration 3879 : loss : 0.014474, loss_ce: 0.006680
2021-11-30 14:03:13,502 iteration 3880 : loss : 0.011454, loss_ce: 0.006701
2021-11-30 14:03:14,855 iteration 3881 : loss : 0.007551, loss_ce: 0.005519
2021-11-30 14:03:16,219 iteration 3882 : loss : 0.009836, loss_ce: 0.006725
2021-11-30 14:03:17,577 iteration 3883 : loss : 0.009699, loss_ce: 0.006519
2021-11-30 14:03:18,937 iteration 3884 : loss : 0.011432, loss_ce: 0.008164
2021-11-30 14:03:20,293 iteration 3885 : loss : 0.009734, loss_ce: 0.006529
2021-11-30 14:03:21,643 iteration 3886 : loss : 0.009417, loss_ce: 0.006715
2021-11-30 14:03:22,989 iteration 3887 : loss : 0.010197, loss_ce: 0.006844
2021-11-30 14:03:24,346 iteration 3888 : loss : 0.008821, loss_ce: 0.005973
2021-11-30 14:03:25,700 iteration 3889 : loss : 0.010393, loss_ce: 0.005996
2021-11-30 14:03:27,055 iteration 3890 : loss : 0.010706, loss_ce: 0.006363
2021-11-30 14:03:28,393 iteration 3891 : loss : 0.009399, loss_ce: 0.006154
2021-11-30 14:03:29,751 iteration 3892 : loss : 0.009367, loss_ce: 0.006103
2021-11-30 14:03:31,106 iteration 3893 : loss : 0.008232, loss_ce: 0.005838
 57%|███████████████▍           | 229/400 [1:36:09<1:08:13, 23.94s/it]2021-11-30 14:03:32,511 iteration 3894 : loss : 0.008419, loss_ce: 0.005995
2021-11-30 14:03:33,858 iteration 3895 : loss : 0.010372, loss_ce: 0.006166
2021-11-30 14:03:35,211 iteration 3896 : loss : 0.009191, loss_ce: 0.006284
2021-11-30 14:03:36,565 iteration 3897 : loss : 0.008901, loss_ce: 0.005763
2021-11-30 14:03:37,911 iteration 3898 : loss : 0.009209, loss_ce: 0.006497
2021-11-30 14:03:39,258 iteration 3899 : loss : 0.009263, loss_ce: 0.006465
2021-11-30 14:03:40,604 iteration 3900 : loss : 0.008719, loss_ce: 0.006222
2021-11-30 14:03:41,957 iteration 3901 : loss : 0.010313, loss_ce: 0.007009
2021-11-30 14:03:43,311 iteration 3902 : loss : 0.013243, loss_ce: 0.007361
2021-11-30 14:03:44,659 iteration 3903 : loss : 0.011860, loss_ce: 0.007643
2021-11-30 14:03:46,006 iteration 3904 : loss : 0.011857, loss_ce: 0.006695
2021-11-30 14:03:47,347 iteration 3905 : loss : 0.008673, loss_ce: 0.005699
2021-11-30 14:03:48,700 iteration 3906 : loss : 0.010338, loss_ce: 0.006016
2021-11-30 14:03:50,053 iteration 3907 : loss : 0.012129, loss_ce: 0.008652
2021-11-30 14:03:51,405 iteration 3908 : loss : 0.010365, loss_ce: 0.006708
2021-11-30 14:03:52,750 iteration 3909 : loss : 0.009321, loss_ce: 0.006016
2021-11-30 14:03:52,750 Training Data Eval:
2021-11-30 14:04:00,360   Average segmentation loss on training set: 0.0126
2021-11-30 14:04:00,360 Validation Data Eval:
2021-11-30 14:04:02,996   Average segmentation loss on validation set: 0.1402
2021-11-30 14:04:04,347 iteration 3910 : loss : 0.009693, loss_ce: 0.006125
 57%|███████████████▌           | 230/400 [1:36:42<1:15:43, 26.73s/it]2021-11-30 14:04:05,765 iteration 3911 : loss : 0.010612, loss_ce: 0.006436
2021-11-30 14:04:07,113 iteration 3912 : loss : 0.014401, loss_ce: 0.007052
2021-11-30 14:04:08,465 iteration 3913 : loss : 0.009652, loss_ce: 0.006620
2021-11-30 14:04:09,831 iteration 3914 : loss : 0.009168, loss_ce: 0.006190
2021-11-30 14:04:11,179 iteration 3915 : loss : 0.008597, loss_ce: 0.005934
2021-11-30 14:04:12,531 iteration 3916 : loss : 0.008948, loss_ce: 0.005929
2021-11-30 14:04:13,879 iteration 3917 : loss : 0.011914, loss_ce: 0.008352
2021-11-30 14:04:15,235 iteration 3918 : loss : 0.010878, loss_ce: 0.006329
2021-11-30 14:04:16,592 iteration 3919 : loss : 0.010529, loss_ce: 0.007011
2021-11-30 14:04:17,934 iteration 3920 : loss : 0.009633, loss_ce: 0.006921
2021-11-30 14:04:19,288 iteration 3921 : loss : 0.009595, loss_ce: 0.006706
2021-11-30 14:04:20,642 iteration 3922 : loss : 0.009546, loss_ce: 0.005631
2021-11-30 14:04:21,991 iteration 3923 : loss : 0.009409, loss_ce: 0.006235
2021-11-30 14:04:23,351 iteration 3924 : loss : 0.015683, loss_ce: 0.009721
2021-11-30 14:04:24,701 iteration 3925 : loss : 0.008691, loss_ce: 0.006342
2021-11-30 14:04:26,052 iteration 3926 : loss : 0.020311, loss_ce: 0.006998
2021-11-30 14:04:27,401 iteration 3927 : loss : 0.012316, loss_ce: 0.006574
 58%|███████████████▌           | 231/400 [1:37:06<1:12:10, 25.63s/it]2021-11-30 14:04:28,829 iteration 3928 : loss : 0.011252, loss_ce: 0.006108
2021-11-30 14:04:30,176 iteration 3929 : loss : 0.013854, loss_ce: 0.007725
2021-11-30 14:04:31,538 iteration 3930 : loss : 0.008314, loss_ce: 0.005987
2021-11-30 14:04:32,899 iteration 3931 : loss : 0.011719, loss_ce: 0.007298
2021-11-30 14:04:34,256 iteration 3932 : loss : 0.009569, loss_ce: 0.006012
2021-11-30 14:04:35,614 iteration 3933 : loss : 0.012164, loss_ce: 0.008001
2021-11-30 14:04:36,964 iteration 3934 : loss : 0.010337, loss_ce: 0.006275
2021-11-30 14:04:38,329 iteration 3935 : loss : 0.008403, loss_ce: 0.005613
2021-11-30 14:04:39,681 iteration 3936 : loss : 0.015325, loss_ce: 0.008729
2021-11-30 14:04:41,033 iteration 3937 : loss : 0.009311, loss_ce: 0.005848
2021-11-30 14:04:42,388 iteration 3938 : loss : 0.011232, loss_ce: 0.007565
2021-11-30 14:04:43,743 iteration 3939 : loss : 0.012509, loss_ce: 0.006735
2021-11-30 14:04:45,100 iteration 3940 : loss : 0.009637, loss_ce: 0.006560
2021-11-30 14:04:46,462 iteration 3941 : loss : 0.008863, loss_ce: 0.006334
2021-11-30 14:04:47,813 iteration 3942 : loss : 0.012437, loss_ce: 0.006347
2021-11-30 14:04:49,176 iteration 3943 : loss : 0.009149, loss_ce: 0.006385
2021-11-30 14:04:50,532 iteration 3944 : loss : 0.010688, loss_ce: 0.006954
 58%|███████████████▋           | 232/400 [1:37:29<1:09:38, 24.87s/it]2021-11-30 14:04:51,943 iteration 3945 : loss : 0.009019, loss_ce: 0.005719
2021-11-30 14:04:53,294 iteration 3946 : loss : 0.010561, loss_ce: 0.006620
2021-11-30 14:04:54,644 iteration 3947 : loss : 0.010169, loss_ce: 0.006481
2021-11-30 14:04:56,004 iteration 3948 : loss : 0.008639, loss_ce: 0.006189
2021-11-30 14:04:57,364 iteration 3949 : loss : 0.011306, loss_ce: 0.007335
2021-11-30 14:04:58,725 iteration 3950 : loss : 0.009224, loss_ce: 0.006522
2021-11-30 14:05:00,073 iteration 3951 : loss : 0.009948, loss_ce: 0.005951
2021-11-30 14:05:01,427 iteration 3952 : loss : 0.010812, loss_ce: 0.007550
2021-11-30 14:05:02,773 iteration 3953 : loss : 0.010451, loss_ce: 0.006881
2021-11-30 14:05:04,131 iteration 3954 : loss : 0.009286, loss_ce: 0.006349
2021-11-30 14:05:05,474 iteration 3955 : loss : 0.008676, loss_ce: 0.006055
2021-11-30 14:05:06,814 iteration 3956 : loss : 0.014280, loss_ce: 0.008995
2021-11-30 14:05:08,162 iteration 3957 : loss : 0.010360, loss_ce: 0.006334
2021-11-30 14:05:09,518 iteration 3958 : loss : 0.012901, loss_ce: 0.006490
2021-11-30 14:05:10,872 iteration 3959 : loss : 0.009431, loss_ce: 0.005970
2021-11-30 14:05:12,213 iteration 3960 : loss : 0.012085, loss_ce: 0.006760
2021-11-30 14:05:13,562 iteration 3961 : loss : 0.009220, loss_ce: 0.006159
 58%|███████████████▋           | 233/400 [1:37:52<1:07:41, 24.32s/it]2021-11-30 14:05:14,970 iteration 3962 : loss : 0.010099, loss_ce: 0.005931
2021-11-30 14:05:16,315 iteration 3963 : loss : 0.011459, loss_ce: 0.007776
2021-11-30 14:05:17,676 iteration 3964 : loss : 0.008981, loss_ce: 0.006430
2021-11-30 14:05:19,012 iteration 3965 : loss : 0.009040, loss_ce: 0.006539
2021-11-30 14:05:20,352 iteration 3966 : loss : 0.010554, loss_ce: 0.006595
2021-11-30 14:05:21,711 iteration 3967 : loss : 0.008915, loss_ce: 0.006111
2021-11-30 14:05:23,061 iteration 3968 : loss : 0.009166, loss_ce: 0.005593
2021-11-30 14:05:24,412 iteration 3969 : loss : 0.009728, loss_ce: 0.006417
2021-11-30 14:05:25,765 iteration 3970 : loss : 0.009175, loss_ce: 0.006776
2021-11-30 14:05:27,115 iteration 3971 : loss : 0.012469, loss_ce: 0.006683
2021-11-30 14:05:28,472 iteration 3972 : loss : 0.008914, loss_ce: 0.006302
2021-11-30 14:05:29,829 iteration 3973 : loss : 0.010055, loss_ce: 0.006600
2021-11-30 14:05:31,180 iteration 3974 : loss : 0.015419, loss_ce: 0.006969
2021-11-30 14:05:32,532 iteration 3975 : loss : 0.008168, loss_ce: 0.005594
2021-11-30 14:05:33,877 iteration 3976 : loss : 0.012653, loss_ce: 0.006905
2021-11-30 14:05:35,233 iteration 3977 : loss : 0.007639, loss_ce: 0.005487
2021-11-30 14:05:36,582 iteration 3978 : loss : 0.010410, loss_ce: 0.006778
 58%|███████████████▊           | 234/400 [1:38:15<1:06:12, 23.93s/it]2021-11-30 14:05:37,989 iteration 3979 : loss : 0.010893, loss_ce: 0.005937
2021-11-30 14:05:39,346 iteration 3980 : loss : 0.008780, loss_ce: 0.006077
2021-11-30 14:05:40,688 iteration 3981 : loss : 0.010374, loss_ce: 0.007181
2021-11-30 14:05:42,044 iteration 3982 : loss : 0.009150, loss_ce: 0.005750
2021-11-30 14:05:43,382 iteration 3983 : loss : 0.008806, loss_ce: 0.005951
2021-11-30 14:05:44,731 iteration 3984 : loss : 0.011354, loss_ce: 0.006463
2021-11-30 14:05:46,088 iteration 3985 : loss : 0.011500, loss_ce: 0.008452
2021-11-30 14:05:47,442 iteration 3986 : loss : 0.009627, loss_ce: 0.006461
2021-11-30 14:05:48,777 iteration 3987 : loss : 0.010674, loss_ce: 0.006999
2021-11-30 14:05:50,117 iteration 3988 : loss : 0.012937, loss_ce: 0.008023
2021-11-30 14:05:51,467 iteration 3989 : loss : 0.009787, loss_ce: 0.006065
2021-11-30 14:05:52,819 iteration 3990 : loss : 0.010448, loss_ce: 0.007183
2021-11-30 14:05:54,170 iteration 3991 : loss : 0.011178, loss_ce: 0.006278
2021-11-30 14:05:55,528 iteration 3992 : loss : 0.010354, loss_ce: 0.006636
2021-11-30 14:05:56,869 iteration 3993 : loss : 0.009815, loss_ce: 0.006398
2021-11-30 14:05:58,207 iteration 3994 : loss : 0.007042, loss_ce: 0.005389
2021-11-30 14:05:58,208 Training Data Eval:
2021-11-30 14:06:05,790   Average segmentation loss on training set: 0.0105
2021-11-30 14:06:05,790 Validation Data Eval:
2021-11-30 14:06:08,406   Average segmentation loss on validation set: 0.1439
2021-11-30 14:06:09,754 iteration 3995 : loss : 0.010965, loss_ce: 0.006375
 59%|███████████████▊           | 235/400 [1:38:48<1:13:26, 26.70s/it]2021-11-30 14:06:11,171 iteration 3996 : loss : 0.013633, loss_ce: 0.007216
2021-11-30 14:06:12,509 iteration 3997 : loss : 0.009145, loss_ce: 0.006764
2021-11-30 14:06:13,855 iteration 3998 : loss : 0.009548, loss_ce: 0.005735
2021-11-30 14:06:15,207 iteration 3999 : loss : 0.009881, loss_ce: 0.005815
2021-11-30 14:06:16,555 iteration 4000 : loss : 0.009409, loss_ce: 0.006578
2021-11-30 14:06:17,897 iteration 4001 : loss : 0.010390, loss_ce: 0.006801
2021-11-30 14:06:19,256 iteration 4002 : loss : 0.008966, loss_ce: 0.005850
2021-11-30 14:06:20,600 iteration 4003 : loss : 0.009520, loss_ce: 0.006742
2021-11-30 14:06:21,950 iteration 4004 : loss : 0.009988, loss_ce: 0.007027
2021-11-30 14:06:23,290 iteration 4005 : loss : 0.009172, loss_ce: 0.006096
2021-11-30 14:06:24,634 iteration 4006 : loss : 0.010444, loss_ce: 0.006388
2021-11-30 14:06:25,980 iteration 4007 : loss : 0.008635, loss_ce: 0.006347
2021-11-30 14:06:27,337 iteration 4008 : loss : 0.010811, loss_ce: 0.006979
2021-11-30 14:06:28,693 iteration 4009 : loss : 0.008404, loss_ce: 0.005891
2021-11-30 14:06:30,042 iteration 4010 : loss : 0.011496, loss_ce: 0.006037
2021-11-30 14:06:31,389 iteration 4011 : loss : 0.008820, loss_ce: 0.005643
2021-11-30 14:06:32,735 iteration 4012 : loss : 0.010619, loss_ce: 0.006493
 59%|███████████████▉           | 236/400 [1:39:11<1:09:56, 25.59s/it]2021-11-30 14:06:34,141 iteration 4013 : loss : 0.008667, loss_ce: 0.006081
2021-11-30 14:06:35,487 iteration 4014 : loss : 0.010152, loss_ce: 0.007132
2021-11-30 14:06:36,836 iteration 4015 : loss : 0.010893, loss_ce: 0.007577
2021-11-30 14:06:38,176 iteration 4016 : loss : 0.008189, loss_ce: 0.005671
2021-11-30 14:06:39,533 iteration 4017 : loss : 0.009007, loss_ce: 0.005673
2021-11-30 14:06:40,888 iteration 4018 : loss : 0.008752, loss_ce: 0.006229
2021-11-30 14:06:42,236 iteration 4019 : loss : 0.010268, loss_ce: 0.006058
2021-11-30 14:06:43,585 iteration 4020 : loss : 0.011570, loss_ce: 0.005975
2021-11-30 14:06:44,941 iteration 4021 : loss : 0.011194, loss_ce: 0.006664
2021-11-30 14:06:46,290 iteration 4022 : loss : 0.010090, loss_ce: 0.006236
2021-11-30 14:06:47,649 iteration 4023 : loss : 0.009909, loss_ce: 0.006666
2021-11-30 14:06:49,008 iteration 4024 : loss : 0.010734, loss_ce: 0.006208
2021-11-30 14:06:50,359 iteration 4025 : loss : 0.008868, loss_ce: 0.005784
2021-11-30 14:06:51,705 iteration 4026 : loss : 0.009531, loss_ce: 0.006002
2021-11-30 14:06:53,067 iteration 4027 : loss : 0.009534, loss_ce: 0.006543
2021-11-30 14:06:54,416 iteration 4028 : loss : 0.013147, loss_ce: 0.007262
2021-11-30 14:06:55,765 iteration 4029 : loss : 0.010174, loss_ce: 0.006624
 59%|███████████████▉           | 237/400 [1:39:34<1:07:25, 24.82s/it]2021-11-30 14:06:57,179 iteration 4030 : loss : 0.008025, loss_ce: 0.005647
2021-11-30 14:06:58,524 iteration 4031 : loss : 0.013409, loss_ce: 0.006906
2021-11-30 14:06:59,873 iteration 4032 : loss : 0.010076, loss_ce: 0.005967
2021-11-30 14:07:01,217 iteration 4033 : loss : 0.009367, loss_ce: 0.006130
2021-11-30 14:07:02,576 iteration 4034 : loss : 0.007691, loss_ce: 0.005362
2021-11-30 14:07:03,928 iteration 4035 : loss : 0.009617, loss_ce: 0.006604
2021-11-30 14:07:05,281 iteration 4036 : loss : 0.010504, loss_ce: 0.007296
2021-11-30 14:07:06,626 iteration 4037 : loss : 0.011090, loss_ce: 0.006790
2021-11-30 14:07:07,979 iteration 4038 : loss : 0.008431, loss_ce: 0.005519
2021-11-30 14:07:09,328 iteration 4039 : loss : 0.010012, loss_ce: 0.006409
2021-11-30 14:07:10,680 iteration 4040 : loss : 0.011060, loss_ce: 0.007336
2021-11-30 14:07:12,024 iteration 4041 : loss : 0.013783, loss_ce: 0.008977
2021-11-30 14:07:13,374 iteration 4042 : loss : 0.009326, loss_ce: 0.005907
2021-11-30 14:07:14,728 iteration 4043 : loss : 0.010592, loss_ce: 0.006868
2021-11-30 14:07:16,074 iteration 4044 : loss : 0.010092, loss_ce: 0.005899
2021-11-30 14:07:17,437 iteration 4045 : loss : 0.009082, loss_ce: 0.006200
2021-11-30 14:07:18,784 iteration 4046 : loss : 0.008360, loss_ce: 0.005398
 60%|████████████████           | 238/400 [1:39:57<1:05:33, 24.28s/it]2021-11-30 14:07:20,188 iteration 4047 : loss : 0.011210, loss_ce: 0.007550
2021-11-30 14:07:21,519 iteration 4048 : loss : 0.008498, loss_ce: 0.005907
2021-11-30 14:07:22,876 iteration 4049 : loss : 0.007891, loss_ce: 0.005258
2021-11-30 14:07:24,229 iteration 4050 : loss : 0.009119, loss_ce: 0.006316
2021-11-30 14:07:25,571 iteration 4051 : loss : 0.010387, loss_ce: 0.006678
2021-11-30 14:07:26,928 iteration 4052 : loss : 0.008769, loss_ce: 0.006140
2021-11-30 14:07:28,282 iteration 4053 : loss : 0.009831, loss_ce: 0.006844
2021-11-30 14:07:29,635 iteration 4054 : loss : 0.009351, loss_ce: 0.005788
2021-11-30 14:07:30,994 iteration 4055 : loss : 0.009196, loss_ce: 0.006734
2021-11-30 14:07:32,349 iteration 4056 : loss : 0.008695, loss_ce: 0.005710
2021-11-30 14:07:33,704 iteration 4057 : loss : 0.009173, loss_ce: 0.006215
2021-11-30 14:07:35,058 iteration 4058 : loss : 0.009499, loss_ce: 0.005749
2021-11-30 14:07:36,407 iteration 4059 : loss : 0.014578, loss_ce: 0.007340
2021-11-30 14:07:37,752 iteration 4060 : loss : 0.008323, loss_ce: 0.005727
2021-11-30 14:07:39,096 iteration 4061 : loss : 0.009399, loss_ce: 0.006422
2021-11-30 14:07:40,439 iteration 4062 : loss : 0.013127, loss_ce: 0.008488
2021-11-30 14:07:41,794 iteration 4063 : loss : 0.009711, loss_ce: 0.006296
 60%|████████████████▏          | 239/400 [1:40:20<1:04:07, 23.90s/it]2021-11-30 14:07:43,198 iteration 4064 : loss : 0.010607, loss_ce: 0.006797
2021-11-30 14:07:44,538 iteration 4065 : loss : 0.011648, loss_ce: 0.008112
2021-11-30 14:07:45,894 iteration 4066 : loss : 0.009556, loss_ce: 0.005895
2021-11-30 14:07:47,235 iteration 4067 : loss : 0.010167, loss_ce: 0.006986
2021-11-30 14:07:48,593 iteration 4068 : loss : 0.008248, loss_ce: 0.005648
2021-11-30 14:07:49,937 iteration 4069 : loss : 0.011762, loss_ce: 0.005556
2021-11-30 14:07:51,286 iteration 4070 : loss : 0.010814, loss_ce: 0.007007
2021-11-30 14:07:52,642 iteration 4071 : loss : 0.009403, loss_ce: 0.006322
2021-11-30 14:07:53,981 iteration 4072 : loss : 0.013953, loss_ce: 0.008846
2021-11-30 14:07:55,334 iteration 4073 : loss : 0.007417, loss_ce: 0.005300
2021-11-30 14:07:56,676 iteration 4074 : loss : 0.011618, loss_ce: 0.006206
2021-11-30 14:07:58,032 iteration 4075 : loss : 0.011567, loss_ce: 0.006906
2021-11-30 14:07:59,377 iteration 4076 : loss : 0.007722, loss_ce: 0.005503
2021-11-30 14:08:00,729 iteration 4077 : loss : 0.010169, loss_ce: 0.006980
2021-11-30 14:08:02,092 iteration 4078 : loss : 0.008571, loss_ce: 0.006190
2021-11-30 14:08:03,445 iteration 4079 : loss : 0.010394, loss_ce: 0.005877
2021-11-30 14:08:03,445 Training Data Eval:
2021-11-30 14:08:11,070   Average segmentation loss on training set: 0.0084
2021-11-30 14:08:11,070 Validation Data Eval:
2021-11-30 14:08:13,694   Average segmentation loss on validation set: 0.1577
2021-11-30 14:08:15,032 iteration 4080 : loss : 0.009643, loss_ce: 0.007215
 60%|████████████████▏          | 240/400 [1:40:53<1:11:12, 26.70s/it]2021-11-30 14:08:16,445 iteration 4081 : loss : 0.010385, loss_ce: 0.006446
2021-11-30 14:08:17,797 iteration 4082 : loss : 0.008328, loss_ce: 0.005945
2021-11-30 14:08:19,141 iteration 4083 : loss : 0.009533, loss_ce: 0.006103
2021-11-30 14:08:20,502 iteration 4084 : loss : 0.008436, loss_ce: 0.005677
2021-11-30 14:08:21,850 iteration 4085 : loss : 0.009217, loss_ce: 0.006124
2021-11-30 14:08:23,196 iteration 4086 : loss : 0.010131, loss_ce: 0.007008
2021-11-30 14:08:24,537 iteration 4087 : loss : 0.008976, loss_ce: 0.006194
2021-11-30 14:08:25,885 iteration 4088 : loss : 0.009088, loss_ce: 0.006337
2021-11-30 14:08:27,240 iteration 4089 : loss : 0.007822, loss_ce: 0.005676
2021-11-30 14:08:28,582 iteration 4090 : loss : 0.010447, loss_ce: 0.006034
2021-11-30 14:08:29,937 iteration 4091 : loss : 0.007918, loss_ce: 0.005639
2021-11-30 14:08:31,285 iteration 4092 : loss : 0.007998, loss_ce: 0.005465
2021-11-30 14:08:32,625 iteration 4093 : loss : 0.011045, loss_ce: 0.007462
2021-11-30 14:08:33,964 iteration 4094 : loss : 0.009681, loss_ce: 0.006736
2021-11-30 14:08:35,309 iteration 4095 : loss : 0.010301, loss_ce: 0.006152
2021-11-30 14:08:36,660 iteration 4096 : loss : 0.014154, loss_ce: 0.008422
2021-11-30 14:08:38,013 iteration 4097 : loss : 0.008431, loss_ce: 0.005563
 60%|████████████████▎          | 241/400 [1:41:16<1:07:47, 25.58s/it]2021-11-30 14:08:39,419 iteration 4098 : loss : 0.011035, loss_ce: 0.006758
2021-11-30 14:08:40,756 iteration 4099 : loss : 0.010917, loss_ce: 0.005864
2021-11-30 14:08:42,102 iteration 4100 : loss : 0.010939, loss_ce: 0.005602
2021-11-30 14:08:43,460 iteration 4101 : loss : 0.010248, loss_ce: 0.005798
2021-11-30 14:08:44,805 iteration 4102 : loss : 0.008802, loss_ce: 0.006492
2021-11-30 14:08:46,141 iteration 4103 : loss : 0.010225, loss_ce: 0.006084
2021-11-30 14:08:47,494 iteration 4104 : loss : 0.009440, loss_ce: 0.006983
2021-11-30 14:08:48,845 iteration 4105 : loss : 0.009199, loss_ce: 0.005734
2021-11-30 14:08:50,200 iteration 4106 : loss : 0.009644, loss_ce: 0.006557
2021-11-30 14:08:51,539 iteration 4107 : loss : 0.009508, loss_ce: 0.005728
2021-11-30 14:08:52,895 iteration 4108 : loss : 0.009396, loss_ce: 0.006509
2021-11-30 14:08:54,240 iteration 4109 : loss : 0.010268, loss_ce: 0.006836
2021-11-30 14:08:55,583 iteration 4110 : loss : 0.011330, loss_ce: 0.006694
2021-11-30 14:08:56,926 iteration 4111 : loss : 0.010378, loss_ce: 0.005969
2021-11-30 14:08:58,276 iteration 4112 : loss : 0.009574, loss_ce: 0.006697
2021-11-30 14:08:59,630 iteration 4113 : loss : 0.008486, loss_ce: 0.005754
2021-11-30 14:09:00,984 iteration 4114 : loss : 0.010557, loss_ce: 0.006690
 60%|████████████████▎          | 242/400 [1:41:39<1:05:18, 24.80s/it]2021-11-30 14:09:02,387 iteration 4115 : loss : 0.011734, loss_ce: 0.007606
2021-11-30 14:09:03,725 iteration 4116 : loss : 0.008926, loss_ce: 0.005867
2021-11-30 14:09:05,066 iteration 4117 : loss : 0.009076, loss_ce: 0.005755
2021-11-30 14:09:06,416 iteration 4118 : loss : 0.009278, loss_ce: 0.005820
2021-11-30 14:09:07,755 iteration 4119 : loss : 0.011658, loss_ce: 0.006749
2021-11-30 14:09:09,107 iteration 4120 : loss : 0.008098, loss_ce: 0.005482
2021-11-30 14:09:10,465 iteration 4121 : loss : 0.013701, loss_ce: 0.008299
2021-11-30 14:09:11,809 iteration 4122 : loss : 0.009225, loss_ce: 0.006838
2021-11-30 14:09:13,161 iteration 4123 : loss : 0.009795, loss_ce: 0.006049
2021-11-30 14:09:14,512 iteration 4124 : loss : 0.009636, loss_ce: 0.005631
2021-11-30 14:09:15,848 iteration 4125 : loss : 0.008879, loss_ce: 0.005805
2021-11-30 14:09:17,189 iteration 4126 : loss : 0.009916, loss_ce: 0.006242
2021-11-30 14:09:18,538 iteration 4127 : loss : 0.008922, loss_ce: 0.006690
2021-11-30 14:09:19,911 iteration 4128 : loss : 0.008606, loss_ce: 0.006285
2021-11-30 14:09:21,253 iteration 4129 : loss : 0.009266, loss_ce: 0.005843
2021-11-30 14:09:22,602 iteration 4130 : loss : 0.007665, loss_ce: 0.005540
2021-11-30 14:09:23,945 iteration 4131 : loss : 0.010268, loss_ce: 0.006614
 61%|████████████████▍          | 243/400 [1:42:02<1:03:27, 24.25s/it]2021-11-30 14:09:25,343 iteration 4132 : loss : 0.009756, loss_ce: 0.006789
2021-11-30 14:09:26,678 iteration 4133 : loss : 0.011537, loss_ce: 0.006985
2021-11-30 14:09:28,021 iteration 4134 : loss : 0.009050, loss_ce: 0.006222
2021-11-30 14:09:29,374 iteration 4135 : loss : 0.008277, loss_ce: 0.005697
2021-11-30 14:09:30,713 iteration 4136 : loss : 0.010956, loss_ce: 0.007585
2021-11-30 14:09:32,060 iteration 4137 : loss : 0.008252, loss_ce: 0.005079
2021-11-30 14:09:33,414 iteration 4138 : loss : 0.009835, loss_ce: 0.006065
2021-11-30 14:09:34,765 iteration 4139 : loss : 0.008631, loss_ce: 0.006010
2021-11-30 14:09:36,118 iteration 4140 : loss : 0.008778, loss_ce: 0.005852
2021-11-30 14:09:37,458 iteration 4141 : loss : 0.013712, loss_ce: 0.006933
2021-11-30 14:09:38,800 iteration 4142 : loss : 0.009359, loss_ce: 0.006395
2021-11-30 14:09:40,141 iteration 4143 : loss : 0.008217, loss_ce: 0.005449
2021-11-30 14:09:41,498 iteration 4144 : loss : 0.010814, loss_ce: 0.007328
2021-11-30 14:09:42,858 iteration 4145 : loss : 0.009489, loss_ce: 0.006709
2021-11-30 14:09:44,202 iteration 4146 : loss : 0.008981, loss_ce: 0.006463
2021-11-30 14:09:45,548 iteration 4147 : loss : 0.008551, loss_ce: 0.006138
2021-11-30 14:09:46,901 iteration 4148 : loss : 0.011910, loss_ce: 0.005990
 61%|████████████████▍          | 244/400 [1:42:25<1:02:02, 23.86s/it]2021-11-30 14:09:48,306 iteration 4149 : loss : 0.007765, loss_ce: 0.005539
2021-11-30 14:09:49,665 iteration 4150 : loss : 0.008337, loss_ce: 0.005990
2021-11-30 14:09:51,017 iteration 4151 : loss : 0.008133, loss_ce: 0.005939
2021-11-30 14:09:52,370 iteration 4152 : loss : 0.007372, loss_ce: 0.005327
2021-11-30 14:09:53,723 iteration 4153 : loss : 0.008597, loss_ce: 0.005789
2021-11-30 14:09:55,072 iteration 4154 : loss : 0.009690, loss_ce: 0.005894
2021-11-30 14:09:56,416 iteration 4155 : loss : 0.009193, loss_ce: 0.006005
2021-11-30 14:09:57,772 iteration 4156 : loss : 0.009678, loss_ce: 0.005585
2021-11-30 14:09:59,128 iteration 4157 : loss : 0.007124, loss_ce: 0.005369
2021-11-30 14:10:00,487 iteration 4158 : loss : 0.009583, loss_ce: 0.006332
2021-11-30 14:10:01,832 iteration 4159 : loss : 0.010264, loss_ce: 0.007255
2021-11-30 14:10:03,182 iteration 4160 : loss : 0.008692, loss_ce: 0.006067
2021-11-30 14:10:04,538 iteration 4161 : loss : 0.009723, loss_ce: 0.005872
2021-11-30 14:10:05,883 iteration 4162 : loss : 0.008550, loss_ce: 0.005716
2021-11-30 14:10:07,226 iteration 4163 : loss : 0.017827, loss_ce: 0.009691
2021-11-30 14:10:08,569 iteration 4164 : loss : 0.017789, loss_ce: 0.008944
2021-11-30 14:10:08,569 Training Data Eval:
2021-11-30 14:10:16,175   Average segmentation loss on training set: 0.0086
2021-11-30 14:10:16,176 Validation Data Eval:
2021-11-30 14:10:18,800   Average segmentation loss on validation set: 0.1647
2021-11-30 14:10:20,144 iteration 4165 : loss : 0.009602, loss_ce: 0.006253
 61%|████████████████▌          | 245/400 [1:42:58<1:08:54, 26.68s/it]2021-11-30 14:10:21,559 iteration 4166 : loss : 0.007923, loss_ce: 0.005818
2021-11-30 14:10:22,897 iteration 4167 : loss : 0.012702, loss_ce: 0.006073
2021-11-30 14:10:24,250 iteration 4168 : loss : 0.012124, loss_ce: 0.007034
2021-11-30 14:10:25,598 iteration 4169 : loss : 0.008608, loss_ce: 0.006327
2021-11-30 14:10:26,946 iteration 4170 : loss : 0.010366, loss_ce: 0.007347
2021-11-30 14:10:28,303 iteration 4171 : loss : 0.011104, loss_ce: 0.006052
2021-11-30 14:10:29,657 iteration 4172 : loss : 0.010869, loss_ce: 0.007509
2021-11-30 14:10:31,004 iteration 4173 : loss : 0.007860, loss_ce: 0.005624
2021-11-30 14:10:32,355 iteration 4174 : loss : 0.008783, loss_ce: 0.005809
2021-11-30 14:10:33,707 iteration 4175 : loss : 0.010033, loss_ce: 0.005536
2021-11-30 14:10:35,044 iteration 4176 : loss : 0.008014, loss_ce: 0.005848
2021-11-30 14:10:36,398 iteration 4177 : loss : 0.008449, loss_ce: 0.005640
2021-11-30 14:10:37,754 iteration 4178 : loss : 0.009276, loss_ce: 0.006097
2021-11-30 14:10:39,095 iteration 4179 : loss : 0.008967, loss_ce: 0.006318
2021-11-30 14:10:40,435 iteration 4180 : loss : 0.010147, loss_ce: 0.005715
2021-11-30 14:10:41,780 iteration 4181 : loss : 0.007972, loss_ce: 0.005490
2021-11-30 14:10:43,134 iteration 4182 : loss : 0.012282, loss_ce: 0.007827
 62%|████████████████▌          | 246/400 [1:43:21<1:05:37, 25.57s/it]2021-11-30 14:10:44,544 iteration 4183 : loss : 0.007961, loss_ce: 0.005516
2021-11-30 14:10:45,888 iteration 4184 : loss : 0.008609, loss_ce: 0.005734
2021-11-30 14:10:47,221 iteration 4185 : loss : 0.008234, loss_ce: 0.005874
2021-11-30 14:10:48,577 iteration 4186 : loss : 0.010032, loss_ce: 0.007473
2021-11-30 14:10:49,927 iteration 4187 : loss : 0.008616, loss_ce: 0.005427
2021-11-30 14:10:51,278 iteration 4188 : loss : 0.007702, loss_ce: 0.005536
2021-11-30 14:10:52,625 iteration 4189 : loss : 0.010142, loss_ce: 0.006028
2021-11-30 14:10:53,969 iteration 4190 : loss : 0.009366, loss_ce: 0.005907
2021-11-30 14:10:55,360 iteration 4191 : loss : 0.008828, loss_ce: 0.005320
2021-11-30 14:10:56,715 iteration 4192 : loss : 0.018349, loss_ce: 0.010481
2021-11-30 14:10:58,074 iteration 4193 : loss : 0.008657, loss_ce: 0.005480
2021-11-30 14:10:59,435 iteration 4194 : loss : 0.009566, loss_ce: 0.006926
2021-11-30 14:11:00,786 iteration 4195 : loss : 0.011613, loss_ce: 0.008081
2021-11-30 14:11:02,141 iteration 4196 : loss : 0.008643, loss_ce: 0.005732
2021-11-30 14:11:03,496 iteration 4197 : loss : 0.008080, loss_ce: 0.005447
2021-11-30 14:11:04,846 iteration 4198 : loss : 0.009034, loss_ce: 0.006003
2021-11-30 14:11:06,200 iteration 4199 : loss : 0.010099, loss_ce: 0.006111
 62%|████████████████▋          | 247/400 [1:43:44<1:03:17, 24.82s/it]2021-11-30 14:11:07,617 iteration 4200 : loss : 0.009289, loss_ce: 0.006396
2021-11-30 14:11:08,971 iteration 4201 : loss : 0.010107, loss_ce: 0.007228
2021-11-30 14:11:10,330 iteration 4202 : loss : 0.011786, loss_ce: 0.007104
2021-11-30 14:11:11,684 iteration 4203 : loss : 0.008396, loss_ce: 0.005258
2021-11-30 14:11:13,034 iteration 4204 : loss : 0.008224, loss_ce: 0.005608
2021-11-30 14:11:14,392 iteration 4205 : loss : 0.008568, loss_ce: 0.006066
2021-11-30 14:11:15,749 iteration 4206 : loss : 0.009459, loss_ce: 0.006325
2021-11-30 14:11:17,100 iteration 4207 : loss : 0.007535, loss_ce: 0.005619
2021-11-30 14:11:18,451 iteration 4208 : loss : 0.008551, loss_ce: 0.005599
2021-11-30 14:11:19,808 iteration 4209 : loss : 0.008549, loss_ce: 0.005639
2021-11-30 14:11:21,166 iteration 4210 : loss : 0.008096, loss_ce: 0.005743
2021-11-30 14:11:22,515 iteration 4211 : loss : 0.010208, loss_ce: 0.005684
2021-11-30 14:11:23,871 iteration 4212 : loss : 0.007845, loss_ce: 0.005550
2021-11-30 14:11:25,229 iteration 4213 : loss : 0.008328, loss_ce: 0.005665
2021-11-30 14:11:26,586 iteration 4214 : loss : 0.012667, loss_ce: 0.008255
2021-11-30 14:11:27,941 iteration 4215 : loss : 0.008249, loss_ce: 0.005766
2021-11-30 14:11:29,297 iteration 4216 : loss : 0.007304, loss_ce: 0.005292
 62%|████████████████▋          | 248/400 [1:44:07<1:01:33, 24.30s/it]2021-11-30 14:11:30,705 iteration 4217 : loss : 0.008396, loss_ce: 0.006147
2021-11-30 14:11:32,055 iteration 4218 : loss : 0.009229, loss_ce: 0.006063
2021-11-30 14:11:33,408 iteration 4219 : loss : 0.007921, loss_ce: 0.005458
2021-11-30 14:11:34,763 iteration 4220 : loss : 0.011920, loss_ce: 0.007650
2021-11-30 14:11:36,115 iteration 4221 : loss : 0.010060, loss_ce: 0.006774
2021-11-30 14:11:37,470 iteration 4222 : loss : 0.009218, loss_ce: 0.006011
2021-11-30 14:11:38,814 iteration 4223 : loss : 0.008971, loss_ce: 0.006013
2021-11-30 14:11:40,169 iteration 4224 : loss : 0.008328, loss_ce: 0.005868
2021-11-30 14:11:41,516 iteration 4225 : loss : 0.007454, loss_ce: 0.005575
2021-11-30 14:11:42,876 iteration 4226 : loss : 0.010415, loss_ce: 0.006426
2021-11-30 14:11:44,211 iteration 4227 : loss : 0.007687, loss_ce: 0.005492
2021-11-30 14:11:45,560 iteration 4228 : loss : 0.008835, loss_ce: 0.005456
2021-11-30 14:11:46,905 iteration 4229 : loss : 0.009010, loss_ce: 0.006788
2021-11-30 14:11:48,245 iteration 4230 : loss : 0.010288, loss_ce: 0.005525
2021-11-30 14:11:49,602 iteration 4231 : loss : 0.010686, loss_ce: 0.005823
2021-11-30 14:11:50,952 iteration 4232 : loss : 0.009845, loss_ce: 0.006024
2021-11-30 14:11:52,311 iteration 4233 : loss : 0.008218, loss_ce: 0.005822
 62%|████████████████▊          | 249/400 [1:44:30<1:00:11, 23.92s/it]2021-11-30 14:11:53,720 iteration 4234 : loss : 0.008461, loss_ce: 0.005547
2021-11-30 14:11:55,067 iteration 4235 : loss : 0.009530, loss_ce: 0.005950
2021-11-30 14:11:56,429 iteration 4236 : loss : 0.008558, loss_ce: 0.006001
2021-11-30 14:11:57,789 iteration 4237 : loss : 0.009498, loss_ce: 0.005699
2021-11-30 14:11:59,148 iteration 4238 : loss : 0.008562, loss_ce: 0.005953
2021-11-30 14:12:00,504 iteration 4239 : loss : 0.008786, loss_ce: 0.005473
2021-11-30 14:12:01,846 iteration 4240 : loss : 0.011672, loss_ce: 0.007428
2021-11-30 14:12:03,199 iteration 4241 : loss : 0.010220, loss_ce: 0.006728
2021-11-30 14:12:04,554 iteration 4242 : loss : 0.008321, loss_ce: 0.005475
2021-11-30 14:12:05,899 iteration 4243 : loss : 0.011972, loss_ce: 0.007170
2021-11-30 14:12:07,263 iteration 4244 : loss : 0.008306, loss_ce: 0.005768
2021-11-30 14:12:08,617 iteration 4245 : loss : 0.008872, loss_ce: 0.006527
2021-11-30 14:12:09,969 iteration 4246 : loss : 0.010631, loss_ce: 0.005580
2021-11-30 14:12:11,321 iteration 4247 : loss : 0.008781, loss_ce: 0.005554
2021-11-30 14:12:12,671 iteration 4248 : loss : 0.009798, loss_ce: 0.006584
2021-11-30 14:12:14,024 iteration 4249 : loss : 0.009135, loss_ce: 0.006457
2021-11-30 14:12:14,025 Training Data Eval:
2021-11-30 14:12:21,656   Average segmentation loss on training set: 0.0093
2021-11-30 14:12:21,657 Validation Data Eval:
2021-11-30 14:12:24,299   Average segmentation loss on validation set: 0.1489
2021-11-30 14:12:25,638 iteration 4250 : loss : 0.008149, loss_ce: 0.006025
 62%|████████████████▉          | 250/400 [1:45:04<1:06:51, 26.74s/it]2021-11-30 14:12:27,062 iteration 4251 : loss : 0.008503, loss_ce: 0.006001
2021-11-30 14:12:28,404 iteration 4252 : loss : 0.010900, loss_ce: 0.006020
2021-11-30 14:12:29,760 iteration 4253 : loss : 0.008685, loss_ce: 0.006084
2021-11-30 14:12:31,112 iteration 4254 : loss : 0.008252, loss_ce: 0.006013
2021-11-30 14:12:32,454 iteration 4255 : loss : 0.011972, loss_ce: 0.007054
2021-11-30 14:12:33,806 iteration 4256 : loss : 0.008274, loss_ce: 0.005529
2021-11-30 14:12:35,153 iteration 4257 : loss : 0.009520, loss_ce: 0.005979
2021-11-30 14:12:36,504 iteration 4258 : loss : 0.010682, loss_ce: 0.006668
2021-11-30 14:12:37,851 iteration 4259 : loss : 0.008059, loss_ce: 0.005652
2021-11-30 14:12:39,205 iteration 4260 : loss : 0.011149, loss_ce: 0.006868
2021-11-30 14:12:40,552 iteration 4261 : loss : 0.009275, loss_ce: 0.005675
2021-11-30 14:12:41,909 iteration 4262 : loss : 0.008992, loss_ce: 0.006270
2021-11-30 14:12:43,271 iteration 4263 : loss : 0.007907, loss_ce: 0.005521
2021-11-30 14:12:44,628 iteration 4264 : loss : 0.009894, loss_ce: 0.006604
2021-11-30 14:12:45,984 iteration 4265 : loss : 0.007681, loss_ce: 0.005316
2021-11-30 14:12:47,331 iteration 4266 : loss : 0.010708, loss_ce: 0.006222
2021-11-30 14:12:48,685 iteration 4267 : loss : 0.009918, loss_ce: 0.006375
 63%|████████████████▉          | 251/400 [1:45:27<1:03:38, 25.63s/it]2021-11-30 14:12:50,093 iteration 4268 : loss : 0.008880, loss_ce: 0.005989
2021-11-30 14:12:51,441 iteration 4269 : loss : 0.015041, loss_ce: 0.006759
2021-11-30 14:12:52,797 iteration 4270 : loss : 0.009259, loss_ce: 0.006125
2021-11-30 14:12:54,157 iteration 4271 : loss : 0.011069, loss_ce: 0.006415
2021-11-30 14:12:55,496 iteration 4272 : loss : 0.009618, loss_ce: 0.006966
2021-11-30 14:12:56,840 iteration 4273 : loss : 0.012945, loss_ce: 0.006144
2021-11-30 14:12:58,224 iteration 4274 : loss : 0.009298, loss_ce: 0.006443
2021-11-30 14:12:59,576 iteration 4275 : loss : 0.008623, loss_ce: 0.005949
2021-11-30 14:13:00,924 iteration 4276 : loss : 0.008127, loss_ce: 0.006019
2021-11-30 14:13:02,264 iteration 4277 : loss : 0.009418, loss_ce: 0.006066
2021-11-30 14:13:03,615 iteration 4278 : loss : 0.010098, loss_ce: 0.006920
2021-11-30 14:13:04,960 iteration 4279 : loss : 0.010353, loss_ce: 0.006563
2021-11-30 14:13:06,308 iteration 4280 : loss : 0.011934, loss_ce: 0.007153
2021-11-30 14:13:07,662 iteration 4281 : loss : 0.008758, loss_ce: 0.005853
2021-11-30 14:13:08,996 iteration 4282 : loss : 0.010363, loss_ce: 0.005672
2021-11-30 14:13:10,345 iteration 4283 : loss : 0.008757, loss_ce: 0.005734
2021-11-30 14:13:11,682 iteration 4284 : loss : 0.008784, loss_ce: 0.006249
 63%|█████████████████          | 252/400 [1:45:50<1:01:16, 24.84s/it]2021-11-30 14:13:13,086 iteration 4285 : loss : 0.009711, loss_ce: 0.006936
2021-11-30 14:13:14,435 iteration 4286 : loss : 0.008644, loss_ce: 0.006190
2021-11-30 14:13:15,781 iteration 4287 : loss : 0.008649, loss_ce: 0.006279
2021-11-30 14:13:17,122 iteration 4288 : loss : 0.007115, loss_ce: 0.005152
2021-11-30 14:13:18,463 iteration 4289 : loss : 0.008962, loss_ce: 0.006108
2021-11-30 14:13:19,806 iteration 4290 : loss : 0.011727, loss_ce: 0.007675
2021-11-30 14:13:21,156 iteration 4291 : loss : 0.009453, loss_ce: 0.005843
2021-11-30 14:13:22,505 iteration 4292 : loss : 0.011247, loss_ce: 0.005827
2021-11-30 14:13:23,853 iteration 4293 : loss : 0.008685, loss_ce: 0.005924
2021-11-30 14:13:25,201 iteration 4294 : loss : 0.010067, loss_ce: 0.006560
2021-11-30 14:13:26,539 iteration 4295 : loss : 0.009747, loss_ce: 0.006336
2021-11-30 14:13:27,887 iteration 4296 : loss : 0.008949, loss_ce: 0.005951
2021-11-30 14:13:29,228 iteration 4297 : loss : 0.010225, loss_ce: 0.006664
2021-11-30 14:13:30,585 iteration 4298 : loss : 0.007676, loss_ce: 0.005394
2021-11-30 14:13:31,934 iteration 4299 : loss : 0.011860, loss_ce: 0.006115
2021-11-30 14:13:33,286 iteration 4300 : loss : 0.007644, loss_ce: 0.005280
2021-11-30 14:13:34,626 iteration 4301 : loss : 0.013118, loss_ce: 0.007542
 63%|██████████████████▎          | 253/400 [1:46:13<59:27, 24.27s/it]2021-11-30 14:13:36,023 iteration 4302 : loss : 0.008621, loss_ce: 0.005773
2021-11-30 14:13:37,378 iteration 4303 : loss : 0.008747, loss_ce: 0.005995
2021-11-30 14:13:38,732 iteration 4304 : loss : 0.012520, loss_ce: 0.007817
2021-11-30 14:13:40,075 iteration 4305 : loss : 0.008491, loss_ce: 0.005908
2021-11-30 14:13:41,439 iteration 4306 : loss : 0.009156, loss_ce: 0.006231
2021-11-30 14:13:42,779 iteration 4307 : loss : 0.008743, loss_ce: 0.005314
2021-11-30 14:13:44,131 iteration 4308 : loss : 0.011170, loss_ce: 0.006397
2021-11-30 14:13:45,471 iteration 4309 : loss : 0.008706, loss_ce: 0.005618
2021-11-30 14:13:46,816 iteration 4310 : loss : 0.010582, loss_ce: 0.006834
2021-11-30 14:13:48,170 iteration 4311 : loss : 0.009017, loss_ce: 0.005849
2021-11-30 14:13:49,519 iteration 4312 : loss : 0.011007, loss_ce: 0.006301
2021-11-30 14:13:50,876 iteration 4313 : loss : 0.008597, loss_ce: 0.005142
2021-11-30 14:13:52,216 iteration 4314 : loss : 0.009000, loss_ce: 0.006049
2021-11-30 14:13:53,565 iteration 4315 : loss : 0.009159, loss_ce: 0.006470
2021-11-30 14:13:54,907 iteration 4316 : loss : 0.008536, loss_ce: 0.005532
2021-11-30 14:13:56,253 iteration 4317 : loss : 0.010976, loss_ce: 0.006841
2021-11-30 14:13:57,621 iteration 4318 : loss : 0.010018, loss_ce: 0.006873
 64%|██████████████████▍          | 254/400 [1:46:36<58:07, 23.89s/it]2021-11-30 14:13:59,029 iteration 4319 : loss : 0.009677, loss_ce: 0.006543
2021-11-30 14:14:00,366 iteration 4320 : loss : 0.008532, loss_ce: 0.005531
2021-11-30 14:14:01,719 iteration 4321 : loss : 0.010649, loss_ce: 0.006207
2021-11-30 14:14:03,069 iteration 4322 : loss : 0.009185, loss_ce: 0.005972
2021-11-30 14:14:04,412 iteration 4323 : loss : 0.009151, loss_ce: 0.005912
2021-11-30 14:14:05,763 iteration 4324 : loss : 0.007743, loss_ce: 0.005246
2021-11-30 14:14:07,106 iteration 4325 : loss : 0.008818, loss_ce: 0.006410
2021-11-30 14:14:08,464 iteration 4326 : loss : 0.007938, loss_ce: 0.005679
2021-11-30 14:14:09,806 iteration 4327 : loss : 0.009250, loss_ce: 0.006202
2021-11-30 14:14:11,156 iteration 4328 : loss : 0.009101, loss_ce: 0.006121
2021-11-30 14:14:12,497 iteration 4329 : loss : 0.009798, loss_ce: 0.006464
2021-11-30 14:14:13,844 iteration 4330 : loss : 0.008899, loss_ce: 0.006872
2021-11-30 14:14:15,202 iteration 4331 : loss : 0.007601, loss_ce: 0.005282
2021-11-30 14:14:16,551 iteration 4332 : loss : 0.008230, loss_ce: 0.005592
2021-11-30 14:14:17,902 iteration 4333 : loss : 0.008488, loss_ce: 0.005271
2021-11-30 14:14:19,245 iteration 4334 : loss : 0.008352, loss_ce: 0.005883
2021-11-30 14:14:19,245 Training Data Eval:
2021-11-30 14:14:26,827   Average segmentation loss on training set: 0.0083
2021-11-30 14:14:26,828 Validation Data Eval:
2021-11-30 14:14:29,461   Average segmentation loss on validation set: 0.1574
2021-11-30 14:14:30,800 iteration 4335 : loss : 0.010584, loss_ce: 0.006932
 64%|█████████████████▏         | 255/400 [1:47:09<1:04:28, 26.68s/it]2021-11-30 14:14:32,217 iteration 4336 : loss : 0.009201, loss_ce: 0.005907
2021-11-30 14:14:33,563 iteration 4337 : loss : 0.011742, loss_ce: 0.008396
2021-11-30 14:14:34,916 iteration 4338 : loss : 0.007987, loss_ce: 0.005112
2021-11-30 14:14:36,257 iteration 4339 : loss : 0.009490, loss_ce: 0.005848
2021-11-30 14:14:37,606 iteration 4340 : loss : 0.009881, loss_ce: 0.006198
2021-11-30 14:14:38,943 iteration 4341 : loss : 0.008130, loss_ce: 0.005599
2021-11-30 14:14:40,297 iteration 4342 : loss : 0.008803, loss_ce: 0.006019
2021-11-30 14:14:41,656 iteration 4343 : loss : 0.008304, loss_ce: 0.005547
2021-11-30 14:14:43,005 iteration 4344 : loss : 0.007663, loss_ce: 0.005451
2021-11-30 14:14:44,353 iteration 4345 : loss : 0.008238, loss_ce: 0.005506
2021-11-30 14:14:45,703 iteration 4346 : loss : 0.009666, loss_ce: 0.006931
2021-11-30 14:14:47,057 iteration 4347 : loss : 0.008181, loss_ce: 0.005755
2021-11-30 14:14:48,414 iteration 4348 : loss : 0.008763, loss_ce: 0.005828
2021-11-30 14:14:49,762 iteration 4349 : loss : 0.012253, loss_ce: 0.006430
2021-11-30 14:14:51,099 iteration 4350 : loss : 0.007432, loss_ce: 0.005341
2021-11-30 14:14:52,445 iteration 4351 : loss : 0.007994, loss_ce: 0.005590
2021-11-30 14:14:53,800 iteration 4352 : loss : 0.010262, loss_ce: 0.006642
 64%|█████████████████▎         | 256/400 [1:47:32<1:01:22, 25.57s/it]2021-11-30 14:14:55,204 iteration 4353 : loss : 0.023294, loss_ce: 0.010638
2021-11-30 14:14:56,560 iteration 4354 : loss : 0.009098, loss_ce: 0.005861
2021-11-30 14:14:57,903 iteration 4355 : loss : 0.011421, loss_ce: 0.007369
2021-11-30 14:14:59,257 iteration 4356 : loss : 0.009942, loss_ce: 0.006638
2021-11-30 14:15:00,605 iteration 4357 : loss : 0.009045, loss_ce: 0.006149
2021-11-30 14:15:01,955 iteration 4358 : loss : 0.008281, loss_ce: 0.005732
2021-11-30 14:15:03,306 iteration 4359 : loss : 0.008763, loss_ce: 0.005887
2021-11-30 14:15:04,642 iteration 4360 : loss : 0.008525, loss_ce: 0.005524
2021-11-30 14:15:05,997 iteration 4361 : loss : 0.009734, loss_ce: 0.005986
2021-11-30 14:15:07,333 iteration 4362 : loss : 0.006799, loss_ce: 0.004910
2021-11-30 14:15:08,686 iteration 4363 : loss : 0.008313, loss_ce: 0.005264
2021-11-30 14:15:10,030 iteration 4364 : loss : 0.008539, loss_ce: 0.005950
2021-11-30 14:15:11,378 iteration 4365 : loss : 0.010189, loss_ce: 0.007415
2021-11-30 14:15:12,719 iteration 4366 : loss : 0.009595, loss_ce: 0.005456
2021-11-30 14:15:14,060 iteration 4367 : loss : 0.015008, loss_ce: 0.008785
2021-11-30 14:15:15,402 iteration 4368 : loss : 0.008553, loss_ce: 0.006005
2021-11-30 14:15:16,754 iteration 4369 : loss : 0.010378, loss_ce: 0.006052
 64%|██████████████████▋          | 257/400 [1:47:55<59:04, 24.79s/it]2021-11-30 14:15:18,163 iteration 4370 : loss : 0.008304, loss_ce: 0.005608
2021-11-30 14:15:19,506 iteration 4371 : loss : 0.008053, loss_ce: 0.005323
2021-11-30 14:15:20,862 iteration 4372 : loss : 0.008308, loss_ce: 0.005913
2021-11-30 14:15:22,212 iteration 4373 : loss : 0.008515, loss_ce: 0.005716
2021-11-30 14:15:23,554 iteration 4374 : loss : 0.008126, loss_ce: 0.005931
2021-11-30 14:15:24,903 iteration 4375 : loss : 0.009212, loss_ce: 0.006095
2021-11-30 14:15:26,248 iteration 4376 : loss : 0.009318, loss_ce: 0.006582
2021-11-30 14:15:27,597 iteration 4377 : loss : 0.008102, loss_ce: 0.005436
2021-11-30 14:15:28,950 iteration 4378 : loss : 0.007423, loss_ce: 0.005211
2021-11-30 14:15:30,286 iteration 4379 : loss : 0.008238, loss_ce: 0.005552
2021-11-30 14:15:31,638 iteration 4380 : loss : 0.008382, loss_ce: 0.005754
2021-11-30 14:15:32,987 iteration 4381 : loss : 0.009334, loss_ce: 0.005307
2021-11-30 14:15:34,334 iteration 4382 : loss : 0.012023, loss_ce: 0.006566
2021-11-30 14:15:35,684 iteration 4383 : loss : 0.008592, loss_ce: 0.006472
2021-11-30 14:15:37,016 iteration 4384 : loss : 0.007210, loss_ce: 0.005214
2021-11-30 14:15:38,366 iteration 4385 : loss : 0.008748, loss_ce: 0.005993
2021-11-30 14:15:39,713 iteration 4386 : loss : 0.009317, loss_ce: 0.006051
 64%|██████████████████▋          | 258/400 [1:48:18<57:21, 24.24s/it]2021-11-30 14:15:41,117 iteration 4387 : loss : 0.008267, loss_ce: 0.005777
2021-11-30 14:15:42,450 iteration 4388 : loss : 0.008653, loss_ce: 0.005602
2021-11-30 14:15:43,795 iteration 4389 : loss : 0.010305, loss_ce: 0.006268
2021-11-30 14:15:45,140 iteration 4390 : loss : 0.013161, loss_ce: 0.007610
2021-11-30 14:15:46,480 iteration 4391 : loss : 0.007317, loss_ce: 0.005133
2021-11-30 14:15:47,828 iteration 4392 : loss : 0.010763, loss_ce: 0.005779
2021-11-30 14:15:49,172 iteration 4393 : loss : 0.008116, loss_ce: 0.005283
2021-11-30 14:15:50,515 iteration 4394 : loss : 0.008902, loss_ce: 0.006387
2021-11-30 14:15:51,852 iteration 4395 : loss : 0.007942, loss_ce: 0.005597
2021-11-30 14:15:53,197 iteration 4396 : loss : 0.009062, loss_ce: 0.006460
2021-11-30 14:15:54,554 iteration 4397 : loss : 0.008980, loss_ce: 0.005634
2021-11-30 14:15:55,904 iteration 4398 : loss : 0.008054, loss_ce: 0.005630
2021-11-30 14:15:57,265 iteration 4399 : loss : 0.009133, loss_ce: 0.006033
2021-11-30 14:15:58,623 iteration 4400 : loss : 0.009563, loss_ce: 0.006128
2021-11-30 14:15:59,970 iteration 4401 : loss : 0.007280, loss_ce: 0.005193
2021-11-30 14:16:01,329 iteration 4402 : loss : 0.010037, loss_ce: 0.007293
2021-11-30 14:16:02,680 iteration 4403 : loss : 0.009176, loss_ce: 0.006039
 65%|██████████████████▊          | 259/400 [1:48:41<56:04, 23.86s/it]2021-11-30 14:16:04,098 iteration 4404 : loss : 0.010980, loss_ce: 0.006212
2021-11-30 14:16:05,440 iteration 4405 : loss : 0.009185, loss_ce: 0.005625
2021-11-30 14:16:06,796 iteration 4406 : loss : 0.008657, loss_ce: 0.005470
2021-11-30 14:16:08,151 iteration 4407 : loss : 0.010014, loss_ce: 0.005911
2021-11-30 14:16:09,510 iteration 4408 : loss : 0.008022, loss_ce: 0.005458
2021-11-30 14:16:10,855 iteration 4409 : loss : 0.009085, loss_ce: 0.005689
2021-11-30 14:16:12,212 iteration 4410 : loss : 0.007825, loss_ce: 0.005507
2021-11-30 14:16:13,560 iteration 4411 : loss : 0.009241, loss_ce: 0.006670
2021-11-30 14:16:14,916 iteration 4412 : loss : 0.008351, loss_ce: 0.006270
2021-11-30 14:16:16,275 iteration 4413 : loss : 0.012806, loss_ce: 0.007612
2021-11-30 14:16:17,634 iteration 4414 : loss : 0.010147, loss_ce: 0.006042
2021-11-30 14:16:18,994 iteration 4415 : loss : 0.008570, loss_ce: 0.005589
2021-11-30 14:16:20,349 iteration 4416 : loss : 0.008166, loss_ce: 0.005962
2021-11-30 14:16:21,709 iteration 4417 : loss : 0.010108, loss_ce: 0.006173
2021-11-30 14:16:23,066 iteration 4418 : loss : 0.008566, loss_ce: 0.006397
2021-11-30 14:16:24,424 iteration 4419 : loss : 0.010393, loss_ce: 0.006606
2021-11-30 14:16:24,424 Training Data Eval:
2021-11-30 14:16:32,101   Average segmentation loss on training set: 0.0083
2021-11-30 14:16:32,102 Validation Data Eval:
2021-11-30 14:16:34,757   Average segmentation loss on validation set: 0.1667
2021-11-30 14:16:36,116 iteration 4420 : loss : 0.010411, loss_ce: 0.006424
 65%|█████████████████▌         | 260/400 [1:49:14<1:02:22, 26.73s/it]2021-11-30 14:16:37,534 iteration 4421 : loss : 0.007438, loss_ce: 0.004974
2021-11-30 14:16:38,893 iteration 4422 : loss : 0.008539, loss_ce: 0.005851
2021-11-30 14:16:40,255 iteration 4423 : loss : 0.009773, loss_ce: 0.006610
2021-11-30 14:16:41,607 iteration 4424 : loss : 0.008454, loss_ce: 0.006238
2021-11-30 14:16:42,962 iteration 4425 : loss : 0.009063, loss_ce: 0.005568
2021-11-30 14:16:44,314 iteration 4426 : loss : 0.009041, loss_ce: 0.006203
2021-11-30 14:16:45,674 iteration 4427 : loss : 0.010279, loss_ce: 0.005639
2021-11-30 14:16:47,025 iteration 4428 : loss : 0.007674, loss_ce: 0.005522
2021-11-30 14:16:48,378 iteration 4429 : loss : 0.010547, loss_ce: 0.006348
2021-11-30 14:16:49,726 iteration 4430 : loss : 0.008267, loss_ce: 0.005683
2021-11-30 14:16:51,081 iteration 4431 : loss : 0.008143, loss_ce: 0.005668
2021-11-30 14:16:52,433 iteration 4432 : loss : 0.008532, loss_ce: 0.005606
2021-11-30 14:16:53,788 iteration 4433 : loss : 0.008616, loss_ce: 0.005865
2021-11-30 14:16:55,140 iteration 4434 : loss : 0.009432, loss_ce: 0.005817
2021-11-30 14:16:56,496 iteration 4435 : loss : 0.008612, loss_ce: 0.005878
2021-11-30 14:16:57,849 iteration 4436 : loss : 0.007591, loss_ce: 0.005068
2021-11-30 14:16:59,207 iteration 4437 : loss : 0.011952, loss_ce: 0.007676
 65%|██████████████████▉          | 261/400 [1:49:37<59:23, 25.64s/it]2021-11-30 14:17:00,634 iteration 4438 : loss : 0.008210, loss_ce: 0.005877
2021-11-30 14:17:01,982 iteration 4439 : loss : 0.009203, loss_ce: 0.006535
2021-11-30 14:17:03,331 iteration 4440 : loss : 0.012898, loss_ce: 0.005688
2021-11-30 14:17:04,689 iteration 4441 : loss : 0.010602, loss_ce: 0.007766
2021-11-30 14:17:06,043 iteration 4442 : loss : 0.008558, loss_ce: 0.005670
2021-11-30 14:17:07,389 iteration 4443 : loss : 0.007580, loss_ce: 0.005583
2021-11-30 14:17:08,742 iteration 4444 : loss : 0.007394, loss_ce: 0.005161
2021-11-30 14:17:10,092 iteration 4445 : loss : 0.008428, loss_ce: 0.005494
2021-11-30 14:17:11,435 iteration 4446 : loss : 0.010072, loss_ce: 0.006949
2021-11-30 14:17:12,785 iteration 4447 : loss : 0.009548, loss_ce: 0.005726
2021-11-30 14:17:14,123 iteration 4448 : loss : 0.016876, loss_ce: 0.007197
2021-11-30 14:17:15,482 iteration 4449 : loss : 0.009015, loss_ce: 0.006040
2021-11-30 14:17:16,843 iteration 4450 : loss : 0.008775, loss_ce: 0.005325
2021-11-30 14:17:18,186 iteration 4451 : loss : 0.009440, loss_ce: 0.006437
2021-11-30 14:17:19,542 iteration 4452 : loss : 0.008593, loss_ce: 0.005461
2021-11-30 14:17:20,892 iteration 4453 : loss : 0.008140, loss_ce: 0.005370
2021-11-30 14:17:22,241 iteration 4454 : loss : 0.010822, loss_ce: 0.007307
 66%|██████████████████▉          | 262/400 [1:50:00<57:10, 24.86s/it]2021-11-30 14:17:23,650 iteration 4455 : loss : 0.008465, loss_ce: 0.005357
2021-11-30 14:17:24,993 iteration 4456 : loss : 0.008917, loss_ce: 0.005853
2021-11-30 14:17:26,344 iteration 4457 : loss : 0.010740, loss_ce: 0.006777
2021-11-30 14:17:27,694 iteration 4458 : loss : 0.011859, loss_ce: 0.006970
2021-11-30 14:17:29,044 iteration 4459 : loss : 0.010981, loss_ce: 0.006373
2021-11-30 14:17:30,397 iteration 4460 : loss : 0.008689, loss_ce: 0.005906
2021-11-30 14:17:31,750 iteration 4461 : loss : 0.008308, loss_ce: 0.005839
2021-11-30 14:17:33,114 iteration 4462 : loss : 0.007720, loss_ce: 0.005401
2021-11-30 14:17:34,454 iteration 4463 : loss : 0.008345, loss_ce: 0.005331
2021-11-30 14:17:35,787 iteration 4464 : loss : 0.008100, loss_ce: 0.005793
2021-11-30 14:17:37,123 iteration 4465 : loss : 0.010412, loss_ce: 0.006617
2021-11-30 14:17:38,476 iteration 4466 : loss : 0.007610, loss_ce: 0.005741
2021-11-30 14:17:39,831 iteration 4467 : loss : 0.012067, loss_ce: 0.006083
2021-11-30 14:17:41,175 iteration 4468 : loss : 0.007925, loss_ce: 0.005260
2021-11-30 14:17:42,529 iteration 4469 : loss : 0.008414, loss_ce: 0.005891
2021-11-30 14:17:43,857 iteration 4470 : loss : 0.007667, loss_ce: 0.005535
2021-11-30 14:17:45,198 iteration 4471 : loss : 0.009406, loss_ce: 0.006380
 66%|███████████████████          | 263/400 [1:50:23<55:27, 24.29s/it]2021-11-30 14:17:46,616 iteration 4472 : loss : 0.007857, loss_ce: 0.005131
2021-11-30 14:17:47,950 iteration 4473 : loss : 0.007807, loss_ce: 0.005307
2021-11-30 14:17:49,291 iteration 4474 : loss : 0.007483, loss_ce: 0.005392
2021-11-30 14:17:50,633 iteration 4475 : loss : 0.008129, loss_ce: 0.005548
2021-11-30 14:17:51,983 iteration 4476 : loss : 0.008558, loss_ce: 0.005813
2021-11-30 14:17:53,335 iteration 4477 : loss : 0.007553, loss_ce: 0.005620
2021-11-30 14:17:54,674 iteration 4478 : loss : 0.010021, loss_ce: 0.005690
2021-11-30 14:17:56,028 iteration 4479 : loss : 0.010138, loss_ce: 0.005858
2021-11-30 14:17:57,386 iteration 4480 : loss : 0.008472, loss_ce: 0.005436
2021-11-30 14:17:58,732 iteration 4481 : loss : 0.007840, loss_ce: 0.005337
2021-11-30 14:18:00,070 iteration 4482 : loss : 0.009123, loss_ce: 0.006240
2021-11-30 14:18:01,410 iteration 4483 : loss : 0.010671, loss_ce: 0.006826
2021-11-30 14:18:02,744 iteration 4484 : loss : 0.008757, loss_ce: 0.006694
2021-11-30 14:18:04,086 iteration 4485 : loss : 0.008316, loss_ce: 0.005726
2021-11-30 14:18:05,438 iteration 4486 : loss : 0.009088, loss_ce: 0.005871
2021-11-30 14:18:06,780 iteration 4487 : loss : 0.009235, loss_ce: 0.006464
2021-11-30 14:18:08,125 iteration 4488 : loss : 0.009858, loss_ce: 0.005805
 66%|███████████████████▏         | 264/400 [1:50:46<54:07, 23.88s/it]2021-11-30 14:18:09,536 iteration 4489 : loss : 0.007731, loss_ce: 0.005385
2021-11-30 14:18:10,874 iteration 4490 : loss : 0.007091, loss_ce: 0.005132
2021-11-30 14:18:12,222 iteration 4491 : loss : 0.008190, loss_ce: 0.005917
2021-11-30 14:18:13,559 iteration 4492 : loss : 0.008794, loss_ce: 0.005492
2021-11-30 14:18:14,902 iteration 4493 : loss : 0.008888, loss_ce: 0.006166
2021-11-30 14:18:16,256 iteration 4494 : loss : 0.008431, loss_ce: 0.005604
2021-11-30 14:18:17,595 iteration 4495 : loss : 0.010000, loss_ce: 0.006249
2021-11-30 14:18:18,948 iteration 4496 : loss : 0.007900, loss_ce: 0.005232
2021-11-30 14:18:20,300 iteration 4497 : loss : 0.009522, loss_ce: 0.005471
2021-11-30 14:18:21,641 iteration 4498 : loss : 0.007799, loss_ce: 0.005550
2021-11-30 14:18:22,983 iteration 4499 : loss : 0.010914, loss_ce: 0.007321
2021-11-30 14:18:24,331 iteration 4500 : loss : 0.010954, loss_ce: 0.007292
2021-11-30 14:18:25,680 iteration 4501 : loss : 0.008160, loss_ce: 0.005194
2021-11-30 14:18:27,027 iteration 4502 : loss : 0.009075, loss_ce: 0.006642
2021-11-30 14:18:28,377 iteration 4503 : loss : 0.008085, loss_ce: 0.005133
2021-11-30 14:18:29,716 iteration 4504 : loss : 0.009619, loss_ce: 0.005930
2021-11-30 14:18:29,717 Training Data Eval:
2021-11-30 14:18:37,282   Average segmentation loss on training set: 0.0074
2021-11-30 14:18:37,283 Validation Data Eval:
2021-11-30 14:18:39,907   Average segmentation loss on validation set: 0.1694
2021-11-30 14:18:41,243 iteration 4505 : loss : 0.010100, loss_ce: 0.006402
 66%|███████████████████▏         | 265/400 [1:51:19<59:57, 26.65s/it]2021-11-30 14:18:42,648 iteration 4506 : loss : 0.008018, loss_ce: 0.005817
2021-11-30 14:18:44,001 iteration 4507 : loss : 0.007757, loss_ce: 0.005487
2021-11-30 14:18:45,346 iteration 4508 : loss : 0.007715, loss_ce: 0.005198
2021-11-30 14:18:46,693 iteration 4509 : loss : 0.008276, loss_ce: 0.005115
2021-11-30 14:18:48,039 iteration 4510 : loss : 0.008442, loss_ce: 0.005477
2021-11-30 14:18:49,392 iteration 4511 : loss : 0.008519, loss_ce: 0.005617
2021-11-30 14:18:50,725 iteration 4512 : loss : 0.008761, loss_ce: 0.005398
2021-11-30 14:18:52,068 iteration 4513 : loss : 0.009327, loss_ce: 0.005896
2021-11-30 14:18:53,421 iteration 4514 : loss : 0.009179, loss_ce: 0.005749
2021-11-30 14:18:54,771 iteration 4515 : loss : 0.010794, loss_ce: 0.007266
2021-11-30 14:18:56,105 iteration 4516 : loss : 0.008261, loss_ce: 0.005836
2021-11-30 14:18:57,456 iteration 4517 : loss : 0.023185, loss_ce: 0.005461
2021-11-30 14:18:58,796 iteration 4518 : loss : 0.009144, loss_ce: 0.005712
2021-11-30 14:19:00,145 iteration 4519 : loss : 0.010962, loss_ce: 0.007535
2021-11-30 14:19:01,489 iteration 4520 : loss : 0.011579, loss_ce: 0.006249
2021-11-30 14:19:02,838 iteration 4521 : loss : 0.010146, loss_ce: 0.006874
2021-11-30 14:19:04,191 iteration 4522 : loss : 0.009935, loss_ce: 0.006195
 66%|███████████████████▎         | 266/400 [1:51:42<57:02, 25.54s/it]2021-11-30 14:19:05,606 iteration 4523 : loss : 0.008474, loss_ce: 0.005469
2021-11-30 14:19:06,957 iteration 4524 : loss : 0.007418, loss_ce: 0.004960
2021-11-30 14:19:08,313 iteration 4525 : loss : 0.010102, loss_ce: 0.006803
2021-11-30 14:19:09,671 iteration 4526 : loss : 0.008633, loss_ce: 0.005679
2021-11-30 14:19:11,016 iteration 4527 : loss : 0.009361, loss_ce: 0.005278
2021-11-30 14:19:12,368 iteration 4528 : loss : 0.010626, loss_ce: 0.006880
2021-11-30 14:19:13,721 iteration 4529 : loss : 0.008887, loss_ce: 0.005151
2021-11-30 14:19:15,079 iteration 4530 : loss : 0.008951, loss_ce: 0.005708
2021-11-30 14:19:16,432 iteration 4531 : loss : 0.008517, loss_ce: 0.005511
2021-11-30 14:19:17,781 iteration 4532 : loss : 0.008352, loss_ce: 0.005593
2021-11-30 14:19:19,132 iteration 4533 : loss : 0.008930, loss_ce: 0.005852
2021-11-30 14:19:20,488 iteration 4534 : loss : 0.011608, loss_ce: 0.006504
2021-11-30 14:19:21,846 iteration 4535 : loss : 0.009714, loss_ce: 0.006797
2021-11-30 14:19:23,198 iteration 4536 : loss : 0.010023, loss_ce: 0.005683
2021-11-30 14:19:24,553 iteration 4537 : loss : 0.009903, loss_ce: 0.005609
2021-11-30 14:19:25,904 iteration 4538 : loss : 0.010298, loss_ce: 0.006429
2021-11-30 14:19:27,252 iteration 4539 : loss : 0.007475, loss_ce: 0.005464
 67%|███████████████████▎         | 267/400 [1:52:05<54:57, 24.80s/it]2021-11-30 14:19:28,676 iteration 4540 : loss : 0.012902, loss_ce: 0.006953
2021-11-30 14:19:30,031 iteration 4541 : loss : 0.008725, loss_ce: 0.006258
2021-11-30 14:19:31,387 iteration 4542 : loss : 0.008397, loss_ce: 0.005897
2021-11-30 14:19:32,745 iteration 4543 : loss : 0.008571, loss_ce: 0.005533
2021-11-30 14:19:34,101 iteration 4544 : loss : 0.009225, loss_ce: 0.006337
2021-11-30 14:19:35,457 iteration 4545 : loss : 0.009834, loss_ce: 0.006006
2021-11-30 14:19:36,808 iteration 4546 : loss : 0.007914, loss_ce: 0.005210
2021-11-30 14:19:38,164 iteration 4547 : loss : 0.008487, loss_ce: 0.005548
2021-11-30 14:19:39,526 iteration 4548 : loss : 0.011137, loss_ce: 0.006414
2021-11-30 14:19:40,878 iteration 4549 : loss : 0.012024, loss_ce: 0.006419
2021-11-30 14:19:42,232 iteration 4550 : loss : 0.007172, loss_ce: 0.005401
2021-11-30 14:19:43,582 iteration 4551 : loss : 0.008286, loss_ce: 0.005701
2021-11-30 14:19:44,931 iteration 4552 : loss : 0.008957, loss_ce: 0.005845
2021-11-30 14:19:46,287 iteration 4553 : loss : 0.010421, loss_ce: 0.007222
2021-11-30 14:19:47,640 iteration 4554 : loss : 0.009378, loss_ce: 0.005706
2021-11-30 14:19:48,983 iteration 4555 : loss : 0.008383, loss_ce: 0.005662
2021-11-30 14:19:50,335 iteration 4556 : loss : 0.008619, loss_ce: 0.005823
 67%|███████████████████▍         | 268/400 [1:52:28<53:25, 24.28s/it]2021-11-30 14:19:51,758 iteration 4557 : loss : 0.007438, loss_ce: 0.005170
2021-11-30 14:19:53,101 iteration 4558 : loss : 0.010156, loss_ce: 0.005695
2021-11-30 14:19:54,443 iteration 4559 : loss : 0.009761, loss_ce: 0.006216
2021-11-30 14:19:55,799 iteration 4560 : loss : 0.007777, loss_ce: 0.005596
2021-11-30 14:19:57,146 iteration 4561 : loss : 0.008365, loss_ce: 0.005004
2021-11-30 14:19:58,501 iteration 4562 : loss : 0.011361, loss_ce: 0.005632
2021-11-30 14:19:59,841 iteration 4563 : loss : 0.010909, loss_ce: 0.006845
2021-11-30 14:20:01,188 iteration 4564 : loss : 0.008408, loss_ce: 0.005677
2021-11-30 14:20:02,530 iteration 4565 : loss : 0.009851, loss_ce: 0.005594
2021-11-30 14:20:03,874 iteration 4566 : loss : 0.008183, loss_ce: 0.005699
2021-11-30 14:20:05,227 iteration 4567 : loss : 0.011557, loss_ce: 0.007965
2021-11-30 14:20:06,578 iteration 4568 : loss : 0.009024, loss_ce: 0.006419
2021-11-30 14:20:07,933 iteration 4569 : loss : 0.007986, loss_ce: 0.005336
2021-11-30 14:20:09,273 iteration 4570 : loss : 0.009266, loss_ce: 0.006352
2021-11-30 14:20:10,612 iteration 4571 : loss : 0.007472, loss_ce: 0.005150
2021-11-30 14:20:11,963 iteration 4572 : loss : 0.008953, loss_ce: 0.005965
2021-11-30 14:20:13,323 iteration 4573 : loss : 0.007518, loss_ce: 0.005632
 67%|███████████████████▌         | 269/400 [1:52:51<52:10, 23.90s/it]2021-11-30 14:20:14,744 iteration 4574 : loss : 0.010406, loss_ce: 0.005771
2021-11-30 14:20:16,100 iteration 4575 : loss : 0.009455, loss_ce: 0.006922
2021-11-30 14:20:17,456 iteration 4576 : loss : 0.008514, loss_ce: 0.005324
2021-11-30 14:20:18,815 iteration 4577 : loss : 0.009570, loss_ce: 0.005371
2021-11-30 14:20:20,165 iteration 4578 : loss : 0.007698, loss_ce: 0.005750
2021-11-30 14:20:21,503 iteration 4579 : loss : 0.009589, loss_ce: 0.005720
2021-11-30 14:20:22,853 iteration 4580 : loss : 0.010547, loss_ce: 0.007319
2021-11-30 14:20:24,195 iteration 4581 : loss : 0.007528, loss_ce: 0.005418
2021-11-30 14:20:25,552 iteration 4582 : loss : 0.009607, loss_ce: 0.006060
2021-11-30 14:20:26,910 iteration 4583 : loss : 0.010396, loss_ce: 0.006376
2021-11-30 14:20:28,256 iteration 4584 : loss : 0.009013, loss_ce: 0.006391
2021-11-30 14:20:29,613 iteration 4585 : loss : 0.016175, loss_ce: 0.006403
2021-11-30 14:20:30,961 iteration 4586 : loss : 0.008444, loss_ce: 0.005752
2021-11-30 14:20:32,313 iteration 4587 : loss : 0.007403, loss_ce: 0.005274
2021-11-30 14:20:33,652 iteration 4588 : loss : 0.009130, loss_ce: 0.006157
2021-11-30 14:20:35,007 iteration 4589 : loss : 0.010659, loss_ce: 0.007213
2021-11-30 14:20:35,007 Training Data Eval:
2021-11-30 14:20:42,596   Average segmentation loss on training set: 0.0086
2021-11-30 14:20:42,596 Validation Data Eval:
2021-11-30 14:20:45,220   Average segmentation loss on validation set: 0.2060
2021-11-30 14:20:46,552 iteration 4590 : loss : 0.012589, loss_ce: 0.007956
 68%|███████████████████▌         | 270/400 [1:53:25<57:49, 26.69s/it]2021-11-30 14:20:47,955 iteration 4591 : loss : 0.010846, loss_ce: 0.006668
2021-11-30 14:20:49,305 iteration 4592 : loss : 0.008539, loss_ce: 0.005178
2021-11-30 14:20:50,654 iteration 4593 : loss : 0.008594, loss_ce: 0.005824
2021-11-30 14:20:52,000 iteration 4594 : loss : 0.008200, loss_ce: 0.005341
2021-11-30 14:20:53,352 iteration 4595 : loss : 0.007552, loss_ce: 0.005403
2021-11-30 14:20:54,698 iteration 4596 : loss : 0.009566, loss_ce: 0.006548
2021-11-30 14:20:56,057 iteration 4597 : loss : 0.008283, loss_ce: 0.006061
2021-11-30 14:20:57,409 iteration 4598 : loss : 0.016985, loss_ce: 0.006663
2021-11-30 14:20:58,761 iteration 4599 : loss : 0.011555, loss_ce: 0.005984
2021-11-30 14:21:00,122 iteration 4600 : loss : 0.008869, loss_ce: 0.006045
2021-11-30 14:21:01,476 iteration 4601 : loss : 0.010700, loss_ce: 0.007649
2021-11-30 14:21:02,830 iteration 4602 : loss : 0.008480, loss_ce: 0.005056
2021-11-30 14:21:04,190 iteration 4603 : loss : 0.008816, loss_ce: 0.005646
2021-11-30 14:21:05,546 iteration 4604 : loss : 0.007511, loss_ce: 0.005587
2021-11-30 14:21:06,906 iteration 4605 : loss : 0.012957, loss_ce: 0.007605
2021-11-30 14:21:08,260 iteration 4606 : loss : 0.008661, loss_ce: 0.005814
2021-11-30 14:21:09,609 iteration 4607 : loss : 0.008838, loss_ce: 0.006295
 68%|███████████████████▋         | 271/400 [1:53:48<55:02, 25.60s/it]2021-11-30 14:21:11,023 iteration 4608 : loss : 0.008067, loss_ce: 0.005648
2021-11-30 14:21:12,372 iteration 4609 : loss : 0.009284, loss_ce: 0.006221
2021-11-30 14:21:13,734 iteration 4610 : loss : 0.008420, loss_ce: 0.005381
2021-11-30 14:21:15,089 iteration 4611 : loss : 0.008090, loss_ce: 0.005373
2021-11-30 14:21:16,427 iteration 4612 : loss : 0.008223, loss_ce: 0.006253
2021-11-30 14:21:17,778 iteration 4613 : loss : 0.008143, loss_ce: 0.005940
2021-11-30 14:21:19,127 iteration 4614 : loss : 0.011489, loss_ce: 0.006623
2021-11-30 14:21:20,470 iteration 4615 : loss : 0.008463, loss_ce: 0.005558
2021-11-30 14:21:21,814 iteration 4616 : loss : 0.007165, loss_ce: 0.005105
2021-11-30 14:21:23,160 iteration 4617 : loss : 0.009707, loss_ce: 0.005281
2021-11-30 14:21:24,514 iteration 4618 : loss : 0.008501, loss_ce: 0.005513
2021-11-30 14:21:25,863 iteration 4619 : loss : 0.008349, loss_ce: 0.005727
2021-11-30 14:21:27,203 iteration 4620 : loss : 0.008188, loss_ce: 0.005883
2021-11-30 14:21:28,555 iteration 4621 : loss : 0.008064, loss_ce: 0.005212
2021-11-30 14:21:29,897 iteration 4622 : loss : 0.008139, loss_ce: 0.006199
2021-11-30 14:21:31,251 iteration 4623 : loss : 0.009283, loss_ce: 0.006321
2021-11-30 14:21:32,598 iteration 4624 : loss : 0.007096, loss_ce: 0.004947
 68%|███████████████████▋         | 272/400 [1:54:11<52:57, 24.82s/it]2021-11-30 14:21:34,016 iteration 4625 : loss : 0.010090, loss_ce: 0.006636
2021-11-30 14:21:35,369 iteration 4626 : loss : 0.009423, loss_ce: 0.005714
2021-11-30 14:21:36,712 iteration 4627 : loss : 0.007923, loss_ce: 0.005577
2021-11-30 14:21:38,062 iteration 4628 : loss : 0.008667, loss_ce: 0.005841
2021-11-30 14:21:39,417 iteration 4629 : loss : 0.011681, loss_ce: 0.006086
2021-11-30 14:21:40,763 iteration 4630 : loss : 0.008056, loss_ce: 0.005533
2021-11-30 14:21:42,119 iteration 4631 : loss : 0.008331, loss_ce: 0.005729
2021-11-30 14:21:43,471 iteration 4632 : loss : 0.008284, loss_ce: 0.005205
2021-11-30 14:21:44,818 iteration 4633 : loss : 0.009300, loss_ce: 0.006543
2021-11-30 14:21:46,170 iteration 4634 : loss : 0.010690, loss_ce: 0.007071
2021-11-30 14:21:47,515 iteration 4635 : loss : 0.008519, loss_ce: 0.006053
2021-11-30 14:21:48,871 iteration 4636 : loss : 0.008087, loss_ce: 0.005355
2021-11-30 14:21:50,207 iteration 4637 : loss : 0.007171, loss_ce: 0.004856
2021-11-30 14:21:51,555 iteration 4638 : loss : 0.010447, loss_ce: 0.005633
2021-11-30 14:21:52,894 iteration 4639 : loss : 0.008191, loss_ce: 0.005603
2021-11-30 14:21:54,253 iteration 4640 : loss : 0.008184, loss_ce: 0.005716
2021-11-30 14:21:55,608 iteration 4641 : loss : 0.007622, loss_ce: 0.005418
 68%|███████████████████▊         | 273/400 [1:54:34<51:23, 24.28s/it]2021-11-30 14:21:57,020 iteration 4642 : loss : 0.008835, loss_ce: 0.006394
2021-11-30 14:21:58,367 iteration 4643 : loss : 0.007046, loss_ce: 0.004884
2021-11-30 14:21:59,726 iteration 4644 : loss : 0.008425, loss_ce: 0.006214
2021-11-30 14:22:01,079 iteration 4645 : loss : 0.009496, loss_ce: 0.005553
2021-11-30 14:22:02,436 iteration 4646 : loss : 0.008277, loss_ce: 0.005375
2021-11-30 14:22:03,793 iteration 4647 : loss : 0.012026, loss_ce: 0.005928
2021-11-30 14:22:05,151 iteration 4648 : loss : 0.007938, loss_ce: 0.005144
2021-11-30 14:22:06,511 iteration 4649 : loss : 0.008106, loss_ce: 0.005496
2021-11-30 14:22:07,863 iteration 4650 : loss : 0.007638, loss_ce: 0.005371
2021-11-30 14:22:09,210 iteration 4651 : loss : 0.007498, loss_ce: 0.005402
2021-11-30 14:22:10,571 iteration 4652 : loss : 0.007379, loss_ce: 0.005272
2021-11-30 14:22:11,925 iteration 4653 : loss : 0.011311, loss_ce: 0.006431
2021-11-30 14:22:13,283 iteration 4654 : loss : 0.011518, loss_ce: 0.007254
2021-11-30 14:22:14,633 iteration 4655 : loss : 0.008102, loss_ce: 0.005576
2021-11-30 14:22:15,976 iteration 4656 : loss : 0.009470, loss_ce: 0.005667
2021-11-30 14:22:17,341 iteration 4657 : loss : 0.011553, loss_ce: 0.008497
2021-11-30 14:22:18,701 iteration 4658 : loss : 0.008865, loss_ce: 0.006163
 68%|███████████████████▊         | 274/400 [1:54:57<50:14, 23.92s/it]2021-11-30 14:22:20,100 iteration 4659 : loss : 0.007819, loss_ce: 0.005708
2021-11-30 14:22:21,456 iteration 4660 : loss : 0.007296, loss_ce: 0.004760
2021-11-30 14:22:22,801 iteration 4661 : loss : 0.010117, loss_ce: 0.007340
2021-11-30 14:22:24,148 iteration 4662 : loss : 0.007246, loss_ce: 0.005320
2021-11-30 14:22:25,506 iteration 4663 : loss : 0.011733, loss_ce: 0.006583
2021-11-30 14:22:26,844 iteration 4664 : loss : 0.008765, loss_ce: 0.005365
2021-11-30 14:22:28,195 iteration 4665 : loss : 0.007436, loss_ce: 0.005222
2021-11-30 14:22:29,540 iteration 4666 : loss : 0.007823, loss_ce: 0.005771
2021-11-30 14:22:30,888 iteration 4667 : loss : 0.009059, loss_ce: 0.006459
2021-11-30 14:22:32,241 iteration 4668 : loss : 0.012235, loss_ce: 0.006300
2021-11-30 14:22:33,592 iteration 4669 : loss : 0.007834, loss_ce: 0.005552
2021-11-30 14:22:34,950 iteration 4670 : loss : 0.008900, loss_ce: 0.006157
2021-11-30 14:22:36,299 iteration 4671 : loss : 0.008326, loss_ce: 0.005583
2021-11-30 14:22:37,647 iteration 4672 : loss : 0.008357, loss_ce: 0.005504
2021-11-30 14:22:38,995 iteration 4673 : loss : 0.007969, loss_ce: 0.005809
2021-11-30 14:22:40,345 iteration 4674 : loss : 0.008945, loss_ce: 0.005420
2021-11-30 14:22:40,346 Training Data Eval:
2021-11-30 14:22:47,973   Average segmentation loss on training set: 0.0073
2021-11-30 14:22:47,973 Validation Data Eval:
2021-11-30 14:22:50,592   Average segmentation loss on validation set: 0.1725
2021-11-30 14:22:51,928 iteration 4675 : loss : 0.008667, loss_ce: 0.005807
 69%|███████████████████▉         | 275/400 [1:55:30<55:39, 26.71s/it]2021-11-30 14:22:53,354 iteration 4676 : loss : 0.008264, loss_ce: 0.005623
2021-11-30 14:22:54,701 iteration 4677 : loss : 0.008262, loss_ce: 0.005423
2021-11-30 14:22:56,055 iteration 4678 : loss : 0.007689, loss_ce: 0.005527
2021-11-30 14:22:57,389 iteration 4679 : loss : 0.008774, loss_ce: 0.005428
2021-11-30 14:22:58,734 iteration 4680 : loss : 0.009139, loss_ce: 0.005251
2021-11-30 14:23:00,085 iteration 4681 : loss : 0.008566, loss_ce: 0.005410
2021-11-30 14:23:01,432 iteration 4682 : loss : 0.006843, loss_ce: 0.004765
2021-11-30 14:23:02,775 iteration 4683 : loss : 0.009111, loss_ce: 0.006705
2021-11-30 14:23:04,119 iteration 4684 : loss : 0.012689, loss_ce: 0.006060
2021-11-30 14:23:05,471 iteration 4685 : loss : 0.008878, loss_ce: 0.006211
2021-11-30 14:23:06,805 iteration 4686 : loss : 0.007558, loss_ce: 0.005205
2021-11-30 14:23:08,162 iteration 4687 : loss : 0.008319, loss_ce: 0.005475
2021-11-30 14:23:09,506 iteration 4688 : loss : 0.008000, loss_ce: 0.005710
2021-11-30 14:23:10,841 iteration 4689 : loss : 0.007736, loss_ce: 0.005683
2021-11-30 14:23:12,184 iteration 4690 : loss : 0.008882, loss_ce: 0.006480
2021-11-30 14:23:13,531 iteration 4691 : loss : 0.007694, loss_ce: 0.005652
2021-11-30 14:23:14,877 iteration 4692 : loss : 0.008963, loss_ce: 0.006146
 69%|████████████████████         | 276/400 [1:55:53<52:52, 25.58s/it]2021-11-30 14:23:16,281 iteration 4693 : loss : 0.007930, loss_ce: 0.005796
2021-11-30 14:23:17,614 iteration 4694 : loss : 0.009064, loss_ce: 0.005739
2021-11-30 14:23:18,954 iteration 4695 : loss : 0.009126, loss_ce: 0.005465
2021-11-30 14:23:20,308 iteration 4696 : loss : 0.008643, loss_ce: 0.005800
2021-11-30 14:23:21,661 iteration 4697 : loss : 0.007815, loss_ce: 0.005812
2021-11-30 14:23:23,005 iteration 4698 : loss : 0.010904, loss_ce: 0.005910
2021-11-30 14:23:24,344 iteration 4699 : loss : 0.009522, loss_ce: 0.005885
2021-11-30 14:23:25,685 iteration 4700 : loss : 0.010923, loss_ce: 0.006128
2021-11-30 14:23:27,037 iteration 4701 : loss : 0.009052, loss_ce: 0.006507
2021-11-30 14:23:28,382 iteration 4702 : loss : 0.008765, loss_ce: 0.005721
2021-11-30 14:23:29,725 iteration 4703 : loss : 0.009060, loss_ce: 0.006723
2021-11-30 14:23:31,076 iteration 4704 : loss : 0.008318, loss_ce: 0.006253
2021-11-30 14:23:32,410 iteration 4705 : loss : 0.008782, loss_ce: 0.006003
2021-11-30 14:23:33,758 iteration 4706 : loss : 0.008136, loss_ce: 0.005474
2021-11-30 14:23:35,097 iteration 4707 : loss : 0.011976, loss_ce: 0.006119
2021-11-30 14:23:36,429 iteration 4708 : loss : 0.013907, loss_ce: 0.006459
2021-11-30 14:23:37,773 iteration 4709 : loss : 0.007576, loss_ce: 0.004822
 69%|████████████████████         | 277/400 [1:56:16<50:47, 24.78s/it]2021-11-30 14:23:39,183 iteration 4710 : loss : 0.007489, loss_ce: 0.005537
2021-11-30 14:23:40,524 iteration 4711 : loss : 0.011627, loss_ce: 0.007641
2021-11-30 14:23:41,873 iteration 4712 : loss : 0.007904, loss_ce: 0.005271
2021-11-30 14:23:43,209 iteration 4713 : loss : 0.007086, loss_ce: 0.005059
2021-11-30 14:23:44,547 iteration 4714 : loss : 0.008581, loss_ce: 0.005304
2021-11-30 14:23:45,893 iteration 4715 : loss : 0.007870, loss_ce: 0.005474
2021-11-30 14:23:47,255 iteration 4716 : loss : 0.008269, loss_ce: 0.005153
2021-11-30 14:23:48,609 iteration 4717 : loss : 0.008083, loss_ce: 0.005293
2021-11-30 14:23:49,949 iteration 4718 : loss : 0.006803, loss_ce: 0.004699
2021-11-30 14:23:51,290 iteration 4719 : loss : 0.011037, loss_ce: 0.005430
2021-11-30 14:23:52,632 iteration 4720 : loss : 0.007395, loss_ce: 0.005348
2021-11-30 14:23:53,989 iteration 4721 : loss : 0.007667, loss_ce: 0.005452
2021-11-30 14:23:55,329 iteration 4722 : loss : 0.009022, loss_ce: 0.005921
2021-11-30 14:23:56,683 iteration 4723 : loss : 0.008909, loss_ce: 0.006291
2021-11-30 14:23:58,026 iteration 4724 : loss : 0.009103, loss_ce: 0.006287
2021-11-30 14:23:59,365 iteration 4725 : loss : 0.010430, loss_ce: 0.006818
2021-11-30 14:24:00,719 iteration 4726 : loss : 0.007201, loss_ce: 0.005144
 70%|████████████████████▏        | 278/400 [1:56:39<49:15, 24.23s/it]2021-11-30 14:24:02,131 iteration 4727 : loss : 0.009824, loss_ce: 0.006913
2021-11-30 14:24:03,473 iteration 4728 : loss : 0.008859, loss_ce: 0.005574
2021-11-30 14:24:04,828 iteration 4729 : loss : 0.008059, loss_ce: 0.005426
2021-11-30 14:24:06,177 iteration 4730 : loss : 0.008453, loss_ce: 0.004919
2021-11-30 14:24:07,535 iteration 4731 : loss : 0.008822, loss_ce: 0.006730
2021-11-30 14:24:08,880 iteration 4732 : loss : 0.011181, loss_ce: 0.006825
2021-11-30 14:24:10,217 iteration 4733 : loss : 0.008717, loss_ce: 0.006077
2021-11-30 14:24:11,560 iteration 4734 : loss : 0.007613, loss_ce: 0.005372
2021-11-30 14:24:12,913 iteration 4735 : loss : 0.007853, loss_ce: 0.005702
2021-11-30 14:24:14,276 iteration 4736 : loss : 0.008918, loss_ce: 0.005913
2021-11-30 14:24:15,630 iteration 4737 : loss : 0.015738, loss_ce: 0.006149
2021-11-30 14:24:16,976 iteration 4738 : loss : 0.009540, loss_ce: 0.005981
2021-11-30 14:24:18,315 iteration 4739 : loss : 0.008127, loss_ce: 0.005129
2021-11-30 14:24:19,655 iteration 4740 : loss : 0.008413, loss_ce: 0.005025
2021-11-30 14:24:21,008 iteration 4741 : loss : 0.009239, loss_ce: 0.005976
2021-11-30 14:24:22,358 iteration 4742 : loss : 0.007538, loss_ce: 0.005147
2021-11-30 14:24:23,717 iteration 4743 : loss : 0.009914, loss_ce: 0.005911
 70%|████████████████████▏        | 279/400 [1:57:02<48:06, 23.86s/it]2021-11-30 14:24:25,125 iteration 4744 : loss : 0.007842, loss_ce: 0.005224
2021-11-30 14:24:26,476 iteration 4745 : loss : 0.007694, loss_ce: 0.005349
2021-11-30 14:24:27,836 iteration 4746 : loss : 0.009992, loss_ce: 0.006216
2021-11-30 14:24:29,178 iteration 4747 : loss : 0.006750, loss_ce: 0.004966
2021-11-30 14:24:30,527 iteration 4748 : loss : 0.009428, loss_ce: 0.006525
2021-11-30 14:24:31,890 iteration 4749 : loss : 0.007824, loss_ce: 0.005438
2021-11-30 14:24:33,238 iteration 4750 : loss : 0.007313, loss_ce: 0.004784
2021-11-30 14:24:34,592 iteration 4751 : loss : 0.008819, loss_ce: 0.006004
2021-11-30 14:24:35,951 iteration 4752 : loss : 0.009163, loss_ce: 0.006202
2021-11-30 14:24:37,304 iteration 4753 : loss : 0.007652, loss_ce: 0.005197
2021-11-30 14:24:38,659 iteration 4754 : loss : 0.008314, loss_ce: 0.005730
2021-11-30 14:24:40,008 iteration 4755 : loss : 0.008375, loss_ce: 0.005617
2021-11-30 14:24:41,373 iteration 4756 : loss : 0.008729, loss_ce: 0.005625
2021-11-30 14:24:42,722 iteration 4757 : loss : 0.012122, loss_ce: 0.007941
2021-11-30 14:24:44,068 iteration 4758 : loss : 0.008819, loss_ce: 0.005260
2021-11-30 14:24:45,429 iteration 4759 : loss : 0.009926, loss_ce: 0.005854
2021-11-30 14:24:45,429 Training Data Eval:
2021-11-30 14:24:53,047   Average segmentation loss on training set: 0.0079
2021-11-30 14:24:53,047 Validation Data Eval:
2021-11-30 14:24:55,693   Average segmentation loss on validation set: 0.1580
2021-11-30 14:24:57,033 iteration 4760 : loss : 0.008802, loss_ce: 0.006208
 70%|████████████████████▎        | 280/400 [1:57:35<53:23, 26.69s/it]2021-11-30 14:24:58,443 iteration 4761 : loss : 0.008594, loss_ce: 0.005418
2021-11-30 14:24:59,797 iteration 4762 : loss : 0.007451, loss_ce: 0.005300
2021-11-30 14:25:01,145 iteration 4763 : loss : 0.009023, loss_ce: 0.005659
2021-11-30 14:25:02,485 iteration 4764 : loss : 0.009164, loss_ce: 0.005365
2021-11-30 14:25:03,845 iteration 4765 : loss : 0.007449, loss_ce: 0.005074
2021-11-30 14:25:05,200 iteration 4766 : loss : 0.007565, loss_ce: 0.004962
2021-11-30 14:25:06,552 iteration 4767 : loss : 0.007853, loss_ce: 0.005965
2021-11-30 14:25:07,907 iteration 4768 : loss : 0.009348, loss_ce: 0.006062
2021-11-30 14:25:09,271 iteration 4769 : loss : 0.011876, loss_ce: 0.006906
2021-11-30 14:25:10,629 iteration 4770 : loss : 0.007644, loss_ce: 0.005608
2021-11-30 14:25:11,980 iteration 4771 : loss : 0.007744, loss_ce: 0.005075
2021-11-30 14:25:13,335 iteration 4772 : loss : 0.007728, loss_ce: 0.005478
2021-11-30 14:25:14,695 iteration 4773 : loss : 0.007629, loss_ce: 0.005722
2021-11-30 14:25:16,039 iteration 4774 : loss : 0.010354, loss_ce: 0.006035
2021-11-30 14:25:17,393 iteration 4775 : loss : 0.008385, loss_ce: 0.005305
2021-11-30 14:25:18,742 iteration 4776 : loss : 0.010502, loss_ce: 0.007217
2021-11-30 14:25:20,095 iteration 4777 : loss : 0.009337, loss_ce: 0.006492
 70%|████████████████████▎        | 281/400 [1:57:58<50:47, 25.61s/it]2021-11-30 14:25:21,507 iteration 4778 : loss : 0.006875, loss_ce: 0.005295
2021-11-30 14:25:22,847 iteration 4779 : loss : 0.008308, loss_ce: 0.005905
2021-11-30 14:25:24,198 iteration 4780 : loss : 0.009349, loss_ce: 0.005775
2021-11-30 14:25:25,561 iteration 4781 : loss : 0.016941, loss_ce: 0.006796
2021-11-30 14:25:26,915 iteration 4782 : loss : 0.008354, loss_ce: 0.005776
2021-11-30 14:25:28,259 iteration 4783 : loss : 0.009603, loss_ce: 0.005295
2021-11-30 14:25:29,603 iteration 4784 : loss : 0.010926, loss_ce: 0.006322
2021-11-30 14:25:30,960 iteration 4785 : loss : 0.008271, loss_ce: 0.005886
2021-11-30 14:25:32,301 iteration 4786 : loss : 0.009123, loss_ce: 0.006316
2021-11-30 14:25:33,645 iteration 4787 : loss : 0.010180, loss_ce: 0.006103
2021-11-30 14:25:34,995 iteration 4788 : loss : 0.006889, loss_ce: 0.005062
2021-11-30 14:25:36,346 iteration 4789 : loss : 0.008888, loss_ce: 0.005546
2021-11-30 14:25:37,693 iteration 4790 : loss : 0.007403, loss_ce: 0.005291
2021-11-30 14:25:39,062 iteration 4791 : loss : 0.009874, loss_ce: 0.006139
2021-11-30 14:25:40,409 iteration 4792 : loss : 0.007561, loss_ce: 0.005502
2021-11-30 14:25:41,758 iteration 4793 : loss : 0.007692, loss_ce: 0.005517
2021-11-30 14:25:43,094 iteration 4794 : loss : 0.008484, loss_ce: 0.005332
 70%|████████████████████▍        | 282/400 [1:58:21<48:49, 24.82s/it]2021-11-30 14:25:44,509 iteration 4795 : loss : 0.008229, loss_ce: 0.005256
2021-11-30 14:25:45,843 iteration 4796 : loss : 0.010613, loss_ce: 0.007162
2021-11-30 14:25:47,197 iteration 4797 : loss : 0.008604, loss_ce: 0.005170
2021-11-30 14:25:48,537 iteration 4798 : loss : 0.010591, loss_ce: 0.005903
2021-11-30 14:25:49,872 iteration 4799 : loss : 0.007782, loss_ce: 0.005340
2021-11-30 14:25:51,205 iteration 4800 : loss : 0.008383, loss_ce: 0.005249
2021-11-30 14:25:52,540 iteration 4801 : loss : 0.014689, loss_ce: 0.010041
2021-11-30 14:25:53,888 iteration 4802 : loss : 0.010454, loss_ce: 0.007695
2021-11-30 14:25:55,238 iteration 4803 : loss : 0.007548, loss_ce: 0.005327
2021-11-30 14:25:56,575 iteration 4804 : loss : 0.009190, loss_ce: 0.006309
2021-11-30 14:25:57,930 iteration 4805 : loss : 0.008445, loss_ce: 0.005297
2021-11-30 14:25:59,264 iteration 4806 : loss : 0.007536, loss_ce: 0.005299
2021-11-30 14:26:00,602 iteration 4807 : loss : 0.007559, loss_ce: 0.005033
2021-11-30 14:26:01,947 iteration 4808 : loss : 0.009147, loss_ce: 0.005514
2021-11-30 14:26:03,296 iteration 4809 : loss : 0.008481, loss_ce: 0.005347
2021-11-30 14:26:04,646 iteration 4810 : loss : 0.007856, loss_ce: 0.005018
2021-11-30 14:26:05,991 iteration 4811 : loss : 0.008293, loss_ce: 0.005585
 71%|████████████████████▌        | 283/400 [1:58:44<47:16, 24.25s/it]2021-11-30 14:26:07,409 iteration 4812 : loss : 0.010655, loss_ce: 0.005353
2021-11-30 14:26:08,757 iteration 4813 : loss : 0.009425, loss_ce: 0.006484
2021-11-30 14:26:10,099 iteration 4814 : loss : 0.007890, loss_ce: 0.005281
2021-11-30 14:26:11,451 iteration 4815 : loss : 0.008334, loss_ce: 0.005838
2021-11-30 14:26:12,793 iteration 4816 : loss : 0.007798, loss_ce: 0.005613
2021-11-30 14:26:14,133 iteration 4817 : loss : 0.007971, loss_ce: 0.005145
2021-11-30 14:26:15,488 iteration 4818 : loss : 0.010238, loss_ce: 0.007128
2021-11-30 14:26:16,835 iteration 4819 : loss : 0.009789, loss_ce: 0.005707
2021-11-30 14:26:18,193 iteration 4820 : loss : 0.009319, loss_ce: 0.005634
2021-11-30 14:26:19,533 iteration 4821 : loss : 0.011062, loss_ce: 0.006523
2021-11-30 14:26:20,875 iteration 4822 : loss : 0.007302, loss_ce: 0.005446
2021-11-30 14:26:22,216 iteration 4823 : loss : 0.009139, loss_ce: 0.005212
2021-11-30 14:26:23,568 iteration 4824 : loss : 0.008432, loss_ce: 0.005557
2021-11-30 14:26:24,926 iteration 4825 : loss : 0.010260, loss_ce: 0.005653
2021-11-30 14:26:26,263 iteration 4826 : loss : 0.010145, loss_ce: 0.007201
2021-11-30 14:26:27,614 iteration 4827 : loss : 0.009191, loss_ce: 0.006252
2021-11-30 14:26:28,955 iteration 4828 : loss : 0.008088, loss_ce: 0.005521
 71%|████████████████████▌        | 284/400 [1:59:07<46:07, 23.86s/it]2021-11-30 14:26:30,375 iteration 4829 : loss : 0.008241, loss_ce: 0.005321
2021-11-30 14:26:31,730 iteration 4830 : loss : 0.009718, loss_ce: 0.006053
2021-11-30 14:26:33,084 iteration 4831 : loss : 0.009512, loss_ce: 0.006666
2021-11-30 14:26:34,437 iteration 4832 : loss : 0.008390, loss_ce: 0.005758
2021-11-30 14:26:35,803 iteration 4833 : loss : 0.011881, loss_ce: 0.006021
2021-11-30 14:26:37,162 iteration 4834 : loss : 0.007033, loss_ce: 0.005011
2021-11-30 14:26:38,526 iteration 4835 : loss : 0.009466, loss_ce: 0.005474
2021-11-30 14:26:39,889 iteration 4836 : loss : 0.008369, loss_ce: 0.006047
2021-11-30 14:26:41,247 iteration 4837 : loss : 0.006926, loss_ce: 0.005331
2021-11-30 14:26:42,611 iteration 4838 : loss : 0.008900, loss_ce: 0.005143
2021-11-30 14:26:43,972 iteration 4839 : loss : 0.009227, loss_ce: 0.006247
2021-11-30 14:26:45,340 iteration 4840 : loss : 0.010502, loss_ce: 0.005239
2021-11-30 14:26:46,698 iteration 4841 : loss : 0.010518, loss_ce: 0.006027
2021-11-30 14:26:48,051 iteration 4842 : loss : 0.007405, loss_ce: 0.005075
2021-11-30 14:26:49,410 iteration 4843 : loss : 0.007614, loss_ce: 0.005556
2021-11-30 14:26:50,768 iteration 4844 : loss : 0.008380, loss_ce: 0.005527
2021-11-30 14:26:50,768 Training Data Eval:
2021-11-30 14:26:58,405   Average segmentation loss on training set: 0.0079
2021-11-30 14:26:58,406 Validation Data Eval:
2021-11-30 14:27:01,037   Average segmentation loss on validation set: 0.1901
2021-11-30 14:27:02,373 iteration 4845 : loss : 0.007506, loss_ce: 0.005550
 71%|████████████████████▋        | 285/400 [1:59:40<51:13, 26.73s/it]2021-11-30 14:27:03,780 iteration 4846 : loss : 0.009199, loss_ce: 0.006982
2021-11-30 14:27:05,129 iteration 4847 : loss : 0.010893, loss_ce: 0.006530
2021-11-30 14:27:06,485 iteration 4848 : loss : 0.007917, loss_ce: 0.005697
2021-11-30 14:27:07,844 iteration 4849 : loss : 0.015723, loss_ce: 0.008704
2021-11-30 14:27:09,202 iteration 4850 : loss : 0.012023, loss_ce: 0.005956
2021-11-30 14:27:10,552 iteration 4851 : loss : 0.008143, loss_ce: 0.005317
2021-11-30 14:27:11,908 iteration 4852 : loss : 0.007044, loss_ce: 0.005104
2021-11-30 14:27:13,262 iteration 4853 : loss : 0.007924, loss_ce: 0.005421
2021-11-30 14:27:14,623 iteration 4854 : loss : 0.009639, loss_ce: 0.005440
2021-11-30 14:27:15,984 iteration 4855 : loss : 0.008886, loss_ce: 0.006141
2021-11-30 14:27:17,346 iteration 4856 : loss : 0.009197, loss_ce: 0.005649
2021-11-30 14:27:18,706 iteration 4857 : loss : 0.008582, loss_ce: 0.005707
2021-11-30 14:27:20,062 iteration 4858 : loss : 0.007941, loss_ce: 0.005849
2021-11-30 14:27:21,419 iteration 4859 : loss : 0.011322, loss_ce: 0.005608
2021-11-30 14:27:22,768 iteration 4860 : loss : 0.010217, loss_ce: 0.006897
2021-11-30 14:27:24,127 iteration 4861 : loss : 0.028081, loss_ce: 0.010221
2021-11-30 14:27:25,481 iteration 4862 : loss : 0.007143, loss_ce: 0.004974
 72%|████████████████████▋        | 286/400 [2:00:04<48:43, 25.64s/it]2021-11-30 14:27:26,894 iteration 4863 : loss : 0.010155, loss_ce: 0.006234
2021-11-30 14:27:28,232 iteration 4864 : loss : 0.009874, loss_ce: 0.005672
2021-11-30 14:27:29,581 iteration 4865 : loss : 0.008883, loss_ce: 0.005981
2021-11-30 14:27:30,938 iteration 4866 : loss : 0.014708, loss_ce: 0.007585
2021-11-30 14:27:32,293 iteration 4867 : loss : 0.008105, loss_ce: 0.005355
2021-11-30 14:27:33,649 iteration 4868 : loss : 0.009707, loss_ce: 0.005496
2021-11-30 14:27:34,999 iteration 4869 : loss : 0.008420, loss_ce: 0.005153
2021-11-30 14:27:36,340 iteration 4870 : loss : 0.008068, loss_ce: 0.005492
2021-11-30 14:27:37,693 iteration 4871 : loss : 0.007548, loss_ce: 0.005542
2021-11-30 14:27:39,037 iteration 4872 : loss : 0.012307, loss_ce: 0.007312
2021-11-30 14:27:40,392 iteration 4873 : loss : 0.009629, loss_ce: 0.006358
2021-11-30 14:27:41,759 iteration 4874 : loss : 0.008209, loss_ce: 0.004917
2021-11-30 14:27:43,102 iteration 4875 : loss : 0.008632, loss_ce: 0.005745
2021-11-30 14:27:44,457 iteration 4876 : loss : 0.008340, loss_ce: 0.005107
2021-11-30 14:27:45,812 iteration 4877 : loss : 0.007822, loss_ce: 0.005488
2021-11-30 14:27:47,159 iteration 4878 : loss : 0.006730, loss_ce: 0.005040
2021-11-30 14:27:48,516 iteration 4879 : loss : 0.008477, loss_ce: 0.006072
 72%|████████████████████▊        | 287/400 [2:00:27<46:49, 24.86s/it]2021-11-30 14:27:49,930 iteration 4880 : loss : 0.008417, loss_ce: 0.005956
2021-11-30 14:27:51,268 iteration 4881 : loss : 0.007250, loss_ce: 0.005253
2021-11-30 14:27:52,620 iteration 4882 : loss : 0.007923, loss_ce: 0.005568
2021-11-30 14:27:53,968 iteration 4883 : loss : 0.008017, loss_ce: 0.005677
2021-11-30 14:27:55,317 iteration 4884 : loss : 0.011905, loss_ce: 0.005754
2021-11-30 14:27:56,671 iteration 4885 : loss : 0.007512, loss_ce: 0.005269
2021-11-30 14:27:58,020 iteration 4886 : loss : 0.008228, loss_ce: 0.005183
2021-11-30 14:27:59,377 iteration 4887 : loss : 0.010778, loss_ce: 0.007283
2021-11-30 14:28:00,726 iteration 4888 : loss : 0.007411, loss_ce: 0.005417
2021-11-30 14:28:02,078 iteration 4889 : loss : 0.020116, loss_ce: 0.006903
2021-11-30 14:28:03,425 iteration 4890 : loss : 0.008898, loss_ce: 0.006312
2021-11-30 14:28:04,788 iteration 4891 : loss : 0.008201, loss_ce: 0.005375
2021-11-30 14:28:06,140 iteration 4892 : loss : 0.008317, loss_ce: 0.005490
2021-11-30 14:28:07,497 iteration 4893 : loss : 0.009201, loss_ce: 0.005828
2021-11-30 14:28:08,844 iteration 4894 : loss : 0.008026, loss_ce: 0.004892
2021-11-30 14:28:10,202 iteration 4895 : loss : 0.009156, loss_ce: 0.006535
2021-11-30 14:28:11,559 iteration 4896 : loss : 0.007884, loss_ce: 0.005234
 72%|████████████████████▉        | 288/400 [2:00:50<45:23, 24.31s/it]2021-11-30 14:28:12,988 iteration 4897 : loss : 0.007627, loss_ce: 0.005571
2021-11-30 14:28:14,345 iteration 4898 : loss : 0.008417, loss_ce: 0.005201
2021-11-30 14:28:15,701 iteration 4899 : loss : 0.007470, loss_ce: 0.004973
2021-11-30 14:28:17,056 iteration 4900 : loss : 0.009235, loss_ce: 0.005752
2021-11-30 14:28:18,416 iteration 4901 : loss : 0.008392, loss_ce: 0.005280
2021-11-30 14:28:19,770 iteration 4902 : loss : 0.008839, loss_ce: 0.005180
2021-11-30 14:28:21,126 iteration 4903 : loss : 0.007947, loss_ce: 0.005792
2021-11-30 14:28:22,498 iteration 4904 : loss : 0.008703, loss_ce: 0.005394
2021-11-30 14:28:23,858 iteration 4905 : loss : 0.007589, loss_ce: 0.005114
2021-11-30 14:28:25,212 iteration 4906 : loss : 0.013344, loss_ce: 0.008728
2021-11-30 14:28:26,574 iteration 4907 : loss : 0.015804, loss_ce: 0.006917
2021-11-30 14:28:27,927 iteration 4908 : loss : 0.007591, loss_ce: 0.005587
2021-11-30 14:28:29,299 iteration 4909 : loss : 0.008838, loss_ce: 0.005718
2021-11-30 14:28:30,654 iteration 4910 : loss : 0.008530, loss_ce: 0.005703
2021-11-30 14:28:32,007 iteration 4911 : loss : 0.007080, loss_ce: 0.004776
2021-11-30 14:28:33,367 iteration 4912 : loss : 0.011359, loss_ce: 0.007976
2021-11-30 14:28:34,722 iteration 4913 : loss : 0.008410, loss_ce: 0.005331
 72%|████████████████████▉        | 289/400 [2:01:13<44:20, 23.97s/it]2021-11-30 14:28:36,131 iteration 4914 : loss : 0.007894, loss_ce: 0.005052
2021-11-30 14:28:37,486 iteration 4915 : loss : 0.007250, loss_ce: 0.005074
2021-11-30 14:28:38,833 iteration 4916 : loss : 0.007914, loss_ce: 0.005615
2021-11-30 14:28:40,175 iteration 4917 : loss : 0.010098, loss_ce: 0.005503
2021-11-30 14:28:41,516 iteration 4918 : loss : 0.010418, loss_ce: 0.006527
2021-11-30 14:28:42,874 iteration 4919 : loss : 0.009716, loss_ce: 0.006673
2021-11-30 14:28:44,227 iteration 4920 : loss : 0.008058, loss_ce: 0.005385
2021-11-30 14:28:45,568 iteration 4921 : loss : 0.009565, loss_ce: 0.006240
2021-11-30 14:28:46,925 iteration 4922 : loss : 0.009094, loss_ce: 0.006406
2021-11-30 14:28:48,280 iteration 4923 : loss : 0.007435, loss_ce: 0.005028
2021-11-30 14:28:49,619 iteration 4924 : loss : 0.006904, loss_ce: 0.004988
2021-11-30 14:28:50,993 iteration 4925 : loss : 0.009508, loss_ce: 0.005331
2021-11-30 14:28:52,348 iteration 4926 : loss : 0.008898, loss_ce: 0.005380
2021-11-30 14:28:53,692 iteration 4927 : loss : 0.011530, loss_ce: 0.006212
2021-11-30 14:28:55,042 iteration 4928 : loss : 0.007075, loss_ce: 0.005659
2021-11-30 14:28:56,400 iteration 4929 : loss : 0.008812, loss_ce: 0.005920
2021-11-30 14:28:56,401 Training Data Eval:
2021-11-30 14:29:04,019   Average segmentation loss on training set: 0.0071
2021-11-30 14:29:04,019 Validation Data Eval:
2021-11-30 14:29:06,645   Average segmentation loss on validation set: 0.1764
2021-11-30 14:29:07,990 iteration 4930 : loss : 0.007277, loss_ce: 0.005281
 72%|█████████████████████        | 290/400 [2:01:46<49:03, 26.76s/it]2021-11-30 14:29:09,394 iteration 4931 : loss : 0.007944, loss_ce: 0.005056
2021-11-30 14:29:10,740 iteration 4932 : loss : 0.008057, loss_ce: 0.006002
2021-11-30 14:29:12,089 iteration 4933 : loss : 0.009004, loss_ce: 0.006450
2021-11-30 14:29:13,442 iteration 4934 : loss : 0.008498, loss_ce: 0.005121
2021-11-30 14:29:14,783 iteration 4935 : loss : 0.009366, loss_ce: 0.005073
2021-11-30 14:29:16,136 iteration 4936 : loss : 0.011438, loss_ce: 0.008198
2021-11-30 14:29:17,482 iteration 4937 : loss : 0.011806, loss_ce: 0.007634
2021-11-30 14:29:18,826 iteration 4938 : loss : 0.009283, loss_ce: 0.005121
2021-11-30 14:29:20,164 iteration 4939 : loss : 0.009937, loss_ce: 0.005896
2021-11-30 14:29:21,518 iteration 4940 : loss : 0.011296, loss_ce: 0.006695
2021-11-30 14:29:22,871 iteration 4941 : loss : 0.008768, loss_ce: 0.006117
2021-11-30 14:29:24,223 iteration 4942 : loss : 0.009095, loss_ce: 0.006365
2021-11-30 14:29:25,582 iteration 4943 : loss : 0.007480, loss_ce: 0.005052
2021-11-30 14:29:26,932 iteration 4944 : loss : 0.007807, loss_ce: 0.005277
2021-11-30 14:29:28,294 iteration 4945 : loss : 0.007275, loss_ce: 0.004832
2021-11-30 14:29:29,640 iteration 4946 : loss : 0.013670, loss_ce: 0.006564
2021-11-30 14:29:30,991 iteration 4947 : loss : 0.007766, loss_ce: 0.005667
 73%|█████████████████████        | 291/400 [2:02:09<46:33, 25.63s/it]2021-11-30 14:29:32,406 iteration 4948 : loss : 0.008249, loss_ce: 0.005219
2021-11-30 14:29:33,748 iteration 4949 : loss : 0.006984, loss_ce: 0.005130
2021-11-30 14:29:35,096 iteration 4950 : loss : 0.007443, loss_ce: 0.005160
2021-11-30 14:29:36,451 iteration 4951 : loss : 0.008164, loss_ce: 0.005609
2021-11-30 14:29:37,798 iteration 4952 : loss : 0.010245, loss_ce: 0.006011
2021-11-30 14:29:39,144 iteration 4953 : loss : 0.008536, loss_ce: 0.005706
2021-11-30 14:29:40,499 iteration 4954 : loss : 0.007315, loss_ce: 0.005367
2021-11-30 14:29:41,847 iteration 4955 : loss : 0.008028, loss_ce: 0.005363
2021-11-30 14:29:43,203 iteration 4956 : loss : 0.007715, loss_ce: 0.004782
2021-11-30 14:29:44,560 iteration 4957 : loss : 0.007875, loss_ce: 0.005706
2021-11-30 14:29:45,900 iteration 4958 : loss : 0.007077, loss_ce: 0.004999
2021-11-30 14:29:47,248 iteration 4959 : loss : 0.010302, loss_ce: 0.006285
2021-11-30 14:29:48,604 iteration 4960 : loss : 0.007862, loss_ce: 0.005622
2021-11-30 14:29:49,960 iteration 4961 : loss : 0.008076, loss_ce: 0.005053
2021-11-30 14:29:51,301 iteration 4962 : loss : 0.008052, loss_ce: 0.005181
2021-11-30 14:29:52,638 iteration 4963 : loss : 0.007819, loss_ce: 0.005566
2021-11-30 14:29:53,986 iteration 4964 : loss : 0.009253, loss_ce: 0.006027
 73%|█████████████████████▏       | 292/400 [2:02:32<44:42, 24.84s/it]2021-11-30 14:29:55,407 iteration 4965 : loss : 0.009948, loss_ce: 0.006777
2021-11-30 14:29:56,765 iteration 4966 : loss : 0.009167, loss_ce: 0.005882
2021-11-30 14:29:58,123 iteration 4967 : loss : 0.008626, loss_ce: 0.005454
2021-11-30 14:29:59,469 iteration 4968 : loss : 0.007879, loss_ce: 0.005329
2021-11-30 14:30:00,822 iteration 4969 : loss : 0.008647, loss_ce: 0.005169
2021-11-30 14:30:02,173 iteration 4970 : loss : 0.006648, loss_ce: 0.004930
2021-11-30 14:30:03,525 iteration 4971 : loss : 0.008223, loss_ce: 0.005376
2021-11-30 14:30:04,883 iteration 4972 : loss : 0.008212, loss_ce: 0.005508
2021-11-30 14:30:06,223 iteration 4973 : loss : 0.007564, loss_ce: 0.005642
2021-11-30 14:30:07,579 iteration 4974 : loss : 0.008422, loss_ce: 0.005607
2021-11-30 14:30:08,933 iteration 4975 : loss : 0.009522, loss_ce: 0.005758
2021-11-30 14:30:10,286 iteration 4976 : loss : 0.006906, loss_ce: 0.004869
2021-11-30 14:30:11,632 iteration 4977 : loss : 0.008894, loss_ce: 0.006538
2021-11-30 14:30:12,980 iteration 4978 : loss : 0.007170, loss_ce: 0.004829
2021-11-30 14:30:14,338 iteration 4979 : loss : 0.011923, loss_ce: 0.006835
2021-11-30 14:30:15,687 iteration 4980 : loss : 0.007139, loss_ce: 0.005207
2021-11-30 14:30:17,042 iteration 4981 : loss : 0.008178, loss_ce: 0.005398
 73%|█████████████████████▏       | 293/400 [2:02:55<43:20, 24.31s/it]2021-11-30 14:30:18,446 iteration 4982 : loss : 0.008453, loss_ce: 0.005100
2021-11-30 14:30:19,790 iteration 4983 : loss : 0.006758, loss_ce: 0.005071
2021-11-30 14:30:21,146 iteration 4984 : loss : 0.008098, loss_ce: 0.005684
2021-11-30 14:30:22,491 iteration 4985 : loss : 0.007243, loss_ce: 0.004820
2021-11-30 14:30:23,851 iteration 4986 : loss : 0.011285, loss_ce: 0.007487
2021-11-30 14:30:25,209 iteration 4987 : loss : 0.008861, loss_ce: 0.005760
2021-11-30 14:30:26,561 iteration 4988 : loss : 0.008625, loss_ce: 0.005281
2021-11-30 14:30:27,909 iteration 4989 : loss : 0.010240, loss_ce: 0.005058
2021-11-30 14:30:29,267 iteration 4990 : loss : 0.007399, loss_ce: 0.005134
2021-11-30 14:30:30,618 iteration 4991 : loss : 0.007759, loss_ce: 0.004890
2021-11-30 14:30:31,978 iteration 4992 : loss : 0.009349, loss_ce: 0.005681
2021-11-30 14:30:33,323 iteration 4993 : loss : 0.008663, loss_ce: 0.005429
2021-11-30 14:30:34,677 iteration 4994 : loss : 0.008814, loss_ce: 0.006624
2021-11-30 14:30:36,041 iteration 4995 : loss : 0.007751, loss_ce: 0.005715
2021-11-30 14:30:37,398 iteration 4996 : loss : 0.007826, loss_ce: 0.005278
2021-11-30 14:30:38,752 iteration 4997 : loss : 0.008558, loss_ce: 0.006231
2021-11-30 14:30:40,103 iteration 4998 : loss : 0.010403, loss_ce: 0.005893
 74%|█████████████████████▎       | 294/400 [2:03:18<42:16, 23.93s/it]2021-11-30 14:30:41,510 iteration 4999 : loss : 0.007689, loss_ce: 0.005210
2021-11-30 14:30:42,867 iteration 5000 : loss : 0.008745, loss_ce: 0.005774
2021-11-30 14:30:44,220 iteration 5001 : loss : 0.010061, loss_ce: 0.006889
2021-11-30 14:30:45,567 iteration 5002 : loss : 0.007338, loss_ce: 0.005143
2021-11-30 14:30:46,912 iteration 5003 : loss : 0.009036, loss_ce: 0.005312
2021-11-30 14:30:48,263 iteration 5004 : loss : 0.008211, loss_ce: 0.005596
2021-11-30 14:30:49,613 iteration 5005 : loss : 0.006787, loss_ce: 0.005040
2021-11-30 14:30:50,977 iteration 5006 : loss : 0.008302, loss_ce: 0.005598
2021-11-30 14:30:52,323 iteration 5007 : loss : 0.007695, loss_ce: 0.005307
2021-11-30 14:30:53,673 iteration 5008 : loss : 0.009813, loss_ce: 0.006640
2021-11-30 14:30:55,021 iteration 5009 : loss : 0.009150, loss_ce: 0.005744
2021-11-30 14:30:56,373 iteration 5010 : loss : 0.011965, loss_ce: 0.006155
2021-11-30 14:30:57,716 iteration 5011 : loss : 0.009184, loss_ce: 0.005842
2021-11-30 14:30:59,074 iteration 5012 : loss : 0.010592, loss_ce: 0.005828
2021-11-30 14:31:00,434 iteration 5013 : loss : 0.008253, loss_ce: 0.005163
2021-11-30 14:31:01,776 iteration 5014 : loss : 0.007197, loss_ce: 0.004971
2021-11-30 14:31:01,777 Training Data Eval:
2021-11-30 14:31:09,451   Average segmentation loss on training set: 0.0071
2021-11-30 14:31:09,451 Validation Data Eval:
2021-11-30 14:31:12,106   Average segmentation loss on validation set: 0.1798
2021-11-30 14:31:13,452 iteration 5015 : loss : 0.008136, loss_ce: 0.005771
 74%|█████████████████████▍       | 295/400 [2:03:52<46:49, 26.76s/it]2021-11-30 14:31:14,871 iteration 5016 : loss : 0.007651, loss_ce: 0.005137
2021-11-30 14:31:16,224 iteration 5017 : loss : 0.008113, loss_ce: 0.005279
2021-11-30 14:31:17,573 iteration 5018 : loss : 0.007446, loss_ce: 0.004831
2021-11-30 14:31:18,914 iteration 5019 : loss : 0.008894, loss_ce: 0.006354
2021-11-30 14:31:20,269 iteration 5020 : loss : 0.014769, loss_ce: 0.006599
2021-11-30 14:31:21,616 iteration 5021 : loss : 0.011501, loss_ce: 0.006478
2021-11-30 14:31:22,973 iteration 5022 : loss : 0.007292, loss_ce: 0.004812
2021-11-30 14:31:24,331 iteration 5023 : loss : 0.010195, loss_ce: 0.005634
2021-11-30 14:31:25,685 iteration 5024 : loss : 0.012783, loss_ce: 0.008469
2021-11-30 14:31:27,044 iteration 5025 : loss : 0.010819, loss_ce: 0.006946
2021-11-30 14:31:28,397 iteration 5026 : loss : 0.008877, loss_ce: 0.006075
2021-11-30 14:31:29,742 iteration 5027 : loss : 0.006701, loss_ce: 0.004794
2021-11-30 14:31:31,095 iteration 5028 : loss : 0.007086, loss_ce: 0.004798
2021-11-30 14:31:32,439 iteration 5029 : loss : 0.007958, loss_ce: 0.005152
2021-11-30 14:31:33,802 iteration 5030 : loss : 0.007545, loss_ce: 0.005473
2021-11-30 14:31:35,151 iteration 5031 : loss : 0.008520, loss_ce: 0.006097
2021-11-30 14:31:36,494 iteration 5032 : loss : 0.008433, loss_ce: 0.005933
 74%|█████████████████████▍       | 296/400 [2:04:15<44:26, 25.64s/it]2021-11-30 14:31:37,906 iteration 5033 : loss : 0.007813, loss_ce: 0.005303
2021-11-30 14:31:39,256 iteration 5034 : loss : 0.011135, loss_ce: 0.007395
2021-11-30 14:31:40,595 iteration 5035 : loss : 0.008892, loss_ce: 0.005434
2021-11-30 14:31:41,953 iteration 5036 : loss : 0.007519, loss_ce: 0.005699
2021-11-30 14:31:43,313 iteration 5037 : loss : 0.009300, loss_ce: 0.005595
2021-11-30 14:31:44,673 iteration 5038 : loss : 0.008466, loss_ce: 0.005995
2021-11-30 14:31:46,011 iteration 5039 : loss : 0.018284, loss_ce: 0.006804
2021-11-30 14:31:47,361 iteration 5040 : loss : 0.011296, loss_ce: 0.006274
2021-11-30 14:31:48,720 iteration 5041 : loss : 0.006978, loss_ce: 0.004970
2021-11-30 14:31:50,062 iteration 5042 : loss : 0.008468, loss_ce: 0.005264
2021-11-30 14:31:51,419 iteration 5043 : loss : 0.008830, loss_ce: 0.005823
2021-11-30 14:31:52,770 iteration 5044 : loss : 0.007695, loss_ce: 0.005273
2021-11-30 14:31:54,112 iteration 5045 : loss : 0.008077, loss_ce: 0.005388
2021-11-30 14:31:55,456 iteration 5046 : loss : 0.007826, loss_ce: 0.005166
2021-11-30 14:31:56,811 iteration 5047 : loss : 0.010950, loss_ce: 0.006543
2021-11-30 14:31:58,167 iteration 5048 : loss : 0.009204, loss_ce: 0.005780
2021-11-30 14:31:59,513 iteration 5049 : loss : 0.010458, loss_ce: 0.005528
 74%|█████████████████████▌       | 297/400 [2:04:38<42:40, 24.86s/it]2021-11-30 14:32:00,918 iteration 5050 : loss : 0.007853, loss_ce: 0.004880
2021-11-30 14:32:02,257 iteration 5051 : loss : 0.008551, loss_ce: 0.005136
2021-11-30 14:32:03,609 iteration 5052 : loss : 0.007860, loss_ce: 0.005797
2021-11-30 14:32:04,965 iteration 5053 : loss : 0.006922, loss_ce: 0.004795
2021-11-30 14:32:06,309 iteration 5054 : loss : 0.007988, loss_ce: 0.005203
2021-11-30 14:32:07,665 iteration 5055 : loss : 0.008093, loss_ce: 0.005956
2021-11-30 14:32:09,015 iteration 5056 : loss : 0.008676, loss_ce: 0.005352
2021-11-30 14:32:10,369 iteration 5057 : loss : 0.009721, loss_ce: 0.006199
2021-11-30 14:32:11,714 iteration 5058 : loss : 0.008169, loss_ce: 0.005329
2021-11-30 14:32:13,068 iteration 5059 : loss : 0.008621, loss_ce: 0.006062
2021-11-30 14:32:14,428 iteration 5060 : loss : 0.008995, loss_ce: 0.005871
2021-11-30 14:32:15,787 iteration 5061 : loss : 0.012167, loss_ce: 0.006749
2021-11-30 14:32:17,143 iteration 5062 : loss : 0.008539, loss_ce: 0.005552
2021-11-30 14:32:18,495 iteration 5063 : loss : 0.007551, loss_ce: 0.005707
2021-11-30 14:32:19,850 iteration 5064 : loss : 0.010378, loss_ce: 0.005717
2021-11-30 14:32:21,203 iteration 5065 : loss : 0.009964, loss_ce: 0.005274
2021-11-30 14:32:22,569 iteration 5066 : loss : 0.007599, loss_ce: 0.005227
 74%|█████████████████████▌       | 298/400 [2:05:01<41:20, 24.32s/it]2021-11-30 14:32:23,980 iteration 5067 : loss : 0.012829, loss_ce: 0.008254
2021-11-30 14:32:25,326 iteration 5068 : loss : 0.007418, loss_ce: 0.005246
2021-11-30 14:32:26,684 iteration 5069 : loss : 0.007057, loss_ce: 0.005304
2021-11-30 14:32:28,031 iteration 5070 : loss : 0.008599, loss_ce: 0.005215
2021-11-30 14:32:29,387 iteration 5071 : loss : 0.007678, loss_ce: 0.005020
2021-11-30 14:32:30,747 iteration 5072 : loss : 0.006691, loss_ce: 0.004923
2021-11-30 14:32:32,098 iteration 5073 : loss : 0.007638, loss_ce: 0.004883
2021-11-30 14:32:33,440 iteration 5074 : loss : 0.007408, loss_ce: 0.004829
2021-11-30 14:32:34,782 iteration 5075 : loss : 0.007842, loss_ce: 0.005059
2021-11-30 14:32:36,141 iteration 5076 : loss : 0.007641, loss_ce: 0.005386
2021-11-30 14:32:37,497 iteration 5077 : loss : 0.008630, loss_ce: 0.006069
2021-11-30 14:32:38,848 iteration 5078 : loss : 0.007740, loss_ce: 0.005514
2021-11-30 14:32:40,199 iteration 5079 : loss : 0.007670, loss_ce: 0.004913
2021-11-30 14:32:41,550 iteration 5080 : loss : 0.006561, loss_ce: 0.005161
2021-11-30 14:32:42,915 iteration 5081 : loss : 0.007787, loss_ce: 0.005047
2021-11-30 14:32:44,284 iteration 5082 : loss : 0.009911, loss_ce: 0.006674
2021-11-30 14:32:45,637 iteration 5083 : loss : 0.007634, loss_ce: 0.005121
 75%|█████████████████████▋       | 299/400 [2:05:24<40:18, 23.94s/it]2021-11-30 14:32:47,050 iteration 5084 : loss : 0.010142, loss_ce: 0.006360
2021-11-30 14:32:48,396 iteration 5085 : loss : 0.006803, loss_ce: 0.004559
2021-11-30 14:32:49,755 iteration 5086 : loss : 0.007876, loss_ce: 0.005805
2021-11-30 14:32:51,119 iteration 5087 : loss : 0.009626, loss_ce: 0.005173
2021-11-30 14:32:52,475 iteration 5088 : loss : 0.007877, loss_ce: 0.005139
2021-11-30 14:32:53,838 iteration 5089 : loss : 0.007664, loss_ce: 0.005173
2021-11-30 14:32:55,183 iteration 5090 : loss : 0.007081, loss_ce: 0.005289
2021-11-30 14:32:56,535 iteration 5091 : loss : 0.008501, loss_ce: 0.005034
2021-11-30 14:32:57,884 iteration 5092 : loss : 0.009024, loss_ce: 0.005736
2021-11-30 14:32:59,237 iteration 5093 : loss : 0.007407, loss_ce: 0.005330
2021-11-30 14:33:00,579 iteration 5094 : loss : 0.009049, loss_ce: 0.005218
2021-11-30 14:33:01,922 iteration 5095 : loss : 0.009215, loss_ce: 0.006600
2021-11-30 14:33:03,279 iteration 5096 : loss : 0.009003, loss_ce: 0.006299
2021-11-30 14:33:04,625 iteration 5097 : loss : 0.010873, loss_ce: 0.006166
2021-11-30 14:33:05,980 iteration 5098 : loss : 0.007454, loss_ce: 0.005188
2021-11-30 14:33:07,337 iteration 5099 : loss : 0.007278, loss_ce: 0.004672
2021-11-30 14:33:07,337 Training Data Eval:
2021-11-30 14:33:15,027   Average segmentation loss on training set: 0.0072
2021-11-30 14:33:15,027 Validation Data Eval:
2021-11-30 14:33:17,671   Average segmentation loss on validation set: 0.1830
2021-11-30 14:33:19,016 iteration 5100 : loss : 0.008523, loss_ce: 0.006193
 75%|█████████████████████▊       | 300/400 [2:05:57<44:37, 26.77s/it]2021-11-30 14:33:20,443 iteration 5101 : loss : 0.008610, loss_ce: 0.005758
2021-11-30 14:33:21,791 iteration 5102 : loss : 0.007903, loss_ce: 0.005338
2021-11-30 14:33:23,150 iteration 5103 : loss : 0.008838, loss_ce: 0.004879
2021-11-30 14:33:24,498 iteration 5104 : loss : 0.007638, loss_ce: 0.005103
2021-11-30 14:33:25,854 iteration 5105 : loss : 0.010500, loss_ce: 0.007047
2021-11-30 14:33:27,210 iteration 5106 : loss : 0.007675, loss_ce: 0.004731
2021-11-30 14:33:28,557 iteration 5107 : loss : 0.008488, loss_ce: 0.006005
2021-11-30 14:33:29,912 iteration 5108 : loss : 0.007984, loss_ce: 0.005811
2021-11-30 14:33:31,263 iteration 5109 : loss : 0.008283, loss_ce: 0.005315
2021-11-30 14:33:32,609 iteration 5110 : loss : 0.007418, loss_ce: 0.005347
2021-11-30 14:33:33,964 iteration 5111 : loss : 0.007146, loss_ce: 0.005349
2021-11-30 14:33:35,314 iteration 5112 : loss : 0.008183, loss_ce: 0.006043
2021-11-30 14:33:36,667 iteration 5113 : loss : 0.009831, loss_ce: 0.005847
2021-11-30 14:33:38,012 iteration 5114 : loss : 0.009430, loss_ce: 0.005062
2021-11-30 14:33:39,372 iteration 5115 : loss : 0.009328, loss_ce: 0.006134
2021-11-30 14:33:40,714 iteration 5116 : loss : 0.006738, loss_ce: 0.004876
2021-11-30 14:33:42,058 iteration 5117 : loss : 0.007430, loss_ce: 0.005270
 75%|█████████████████████▊       | 301/400 [2:06:20<42:19, 25.65s/it]2021-11-30 14:33:43,462 iteration 5118 : loss : 0.009004, loss_ce: 0.006413
2021-11-30 14:33:44,806 iteration 5119 : loss : 0.007615, loss_ce: 0.005495
2021-11-30 14:33:46,146 iteration 5120 : loss : 0.012788, loss_ce: 0.006941
2021-11-30 14:33:47,507 iteration 5121 : loss : 0.008981, loss_ce: 0.006116
2021-11-30 14:33:48,852 iteration 5122 : loss : 0.008970, loss_ce: 0.005257
2021-11-30 14:33:50,211 iteration 5123 : loss : 0.008815, loss_ce: 0.005645
2021-11-30 14:33:51,562 iteration 5124 : loss : 0.007074, loss_ce: 0.004962
2021-11-30 14:33:52,899 iteration 5125 : loss : 0.008234, loss_ce: 0.005713
2021-11-30 14:33:54,245 iteration 5126 : loss : 0.008513, loss_ce: 0.005752
2021-11-30 14:33:55,603 iteration 5127 : loss : 0.009898, loss_ce: 0.006355
2021-11-30 14:33:56,961 iteration 5128 : loss : 0.008271, loss_ce: 0.006303
2021-11-30 14:33:58,309 iteration 5129 : loss : 0.007832, loss_ce: 0.005318
2021-11-30 14:33:59,664 iteration 5130 : loss : 0.007480, loss_ce: 0.005409
2021-11-30 14:34:01,009 iteration 5131 : loss : 0.007933, loss_ce: 0.004954
2021-11-30 14:34:02,360 iteration 5132 : loss : 0.008143, loss_ce: 0.005259
2021-11-30 14:34:03,717 iteration 5133 : loss : 0.008750, loss_ce: 0.005063
2021-11-30 14:34:05,069 iteration 5134 : loss : 0.012469, loss_ce: 0.005741
 76%|█████████████████████▉       | 302/400 [2:06:43<40:36, 24.86s/it]2021-11-30 14:34:06,481 iteration 5135 : loss : 0.007752, loss_ce: 0.005298
2021-11-30 14:34:07,836 iteration 5136 : loss : 0.007965, loss_ce: 0.005985
2021-11-30 14:34:09,193 iteration 5137 : loss : 0.006522, loss_ce: 0.004565
2021-11-30 14:34:10,537 iteration 5138 : loss : 0.007027, loss_ce: 0.005250
2021-11-30 14:34:11,890 iteration 5139 : loss : 0.007783, loss_ce: 0.005610
2021-11-30 14:34:13,233 iteration 5140 : loss : 0.007046, loss_ce: 0.004806
2021-11-30 14:34:14,594 iteration 5141 : loss : 0.007363, loss_ce: 0.005362
2021-11-30 14:34:15,950 iteration 5142 : loss : 0.008485, loss_ce: 0.005295
2021-11-30 14:34:17,315 iteration 5143 : loss : 0.008855, loss_ce: 0.005107
2021-11-30 14:34:18,677 iteration 5144 : loss : 0.007748, loss_ce: 0.005462
2021-11-30 14:34:20,038 iteration 5145 : loss : 0.007531, loss_ce: 0.005065
2021-11-30 14:34:21,402 iteration 5146 : loss : 0.008772, loss_ce: 0.005632
2021-11-30 14:34:22,769 iteration 5147 : loss : 0.008546, loss_ce: 0.005725
2021-11-30 14:34:24,137 iteration 5148 : loss : 0.008642, loss_ce: 0.005510
2021-11-30 14:34:25,501 iteration 5149 : loss : 0.007613, loss_ce: 0.005178
2021-11-30 14:34:26,865 iteration 5150 : loss : 0.008823, loss_ce: 0.005917
2021-11-30 14:34:28,230 iteration 5151 : loss : 0.007071, loss_ce: 0.004871
 76%|█████████████████████▉       | 303/400 [2:07:06<39:21, 24.35s/it]2021-11-30 14:34:29,662 iteration 5152 : loss : 0.007716, loss_ce: 0.005406
2021-11-30 14:34:31,026 iteration 5153 : loss : 0.008076, loss_ce: 0.005117
2021-11-30 14:34:32,394 iteration 5154 : loss : 0.007724, loss_ce: 0.005279
2021-11-30 14:34:33,764 iteration 5155 : loss : 0.007724, loss_ce: 0.005123
2021-11-30 14:34:35,127 iteration 5156 : loss : 0.007210, loss_ce: 0.005364
2021-11-30 14:34:36,490 iteration 5157 : loss : 0.014132, loss_ce: 0.005043
2021-11-30 14:34:37,852 iteration 5158 : loss : 0.009151, loss_ce: 0.005619
2021-11-30 14:34:39,215 iteration 5159 : loss : 0.007701, loss_ce: 0.005493
2021-11-30 14:34:40,577 iteration 5160 : loss : 0.007841, loss_ce: 0.005187
2021-11-30 14:34:41,935 iteration 5161 : loss : 0.010231, loss_ce: 0.006693
2021-11-30 14:34:43,297 iteration 5162 : loss : 0.013264, loss_ce: 0.005634
2021-11-30 14:34:44,654 iteration 5163 : loss : 0.008479, loss_ce: 0.005415
2021-11-30 14:34:46,004 iteration 5164 : loss : 0.007834, loss_ce: 0.005637
2021-11-30 14:34:47,358 iteration 5165 : loss : 0.008460, loss_ce: 0.004984
2021-11-30 14:34:48,715 iteration 5166 : loss : 0.011092, loss_ce: 0.007990
2021-11-30 14:34:50,077 iteration 5167 : loss : 0.007983, loss_ce: 0.005236
2021-11-30 14:34:51,439 iteration 5168 : loss : 0.008785, loss_ce: 0.005828
 76%|██████████████████████       | 304/400 [2:07:30<38:24, 24.01s/it]2021-11-30 14:34:52,854 iteration 5169 : loss : 0.008383, loss_ce: 0.005417
2021-11-30 14:34:54,221 iteration 5170 : loss : 0.007598, loss_ce: 0.005111
2021-11-30 14:34:55,563 iteration 5171 : loss : 0.008554, loss_ce: 0.006376
2021-11-30 14:34:56,913 iteration 5172 : loss : 0.018279, loss_ce: 0.007986
2021-11-30 14:34:58,267 iteration 5173 : loss : 0.007403, loss_ce: 0.005153
2021-11-30 14:34:59,628 iteration 5174 : loss : 0.008250, loss_ce: 0.005352
2021-11-30 14:35:00,979 iteration 5175 : loss : 0.009018, loss_ce: 0.005016
2021-11-30 14:35:02,334 iteration 5176 : loss : 0.008146, loss_ce: 0.004864
2021-11-30 14:35:03,668 iteration 5177 : loss : 0.010163, loss_ce: 0.005167
2021-11-30 14:35:05,028 iteration 5178 : loss : 0.008992, loss_ce: 0.006000
2021-11-30 14:35:06,385 iteration 5179 : loss : 0.006993, loss_ce: 0.005304
2021-11-30 14:35:07,726 iteration 5180 : loss : 0.007573, loss_ce: 0.004736
2021-11-30 14:35:09,073 iteration 5181 : loss : 0.008256, loss_ce: 0.005230
2021-11-30 14:35:10,429 iteration 5182 : loss : 0.008620, loss_ce: 0.005596
2021-11-30 14:35:11,778 iteration 5183 : loss : 0.007295, loss_ce: 0.005291
2021-11-30 14:35:13,122 iteration 5184 : loss : 0.007734, loss_ce: 0.005239
2021-11-30 14:35:13,122 Training Data Eval:
2021-11-30 14:35:20,758   Average segmentation loss on training set: 0.0072
2021-11-30 14:35:20,758 Validation Data Eval:
2021-11-30 14:35:23,385   Average segmentation loss on validation set: 0.1694
2021-11-30 14:35:24,723 iteration 5185 : loss : 0.008104, loss_ce: 0.005823
 76%|██████████████████████       | 305/400 [2:08:03<42:25, 26.79s/it]2021-11-30 14:35:26,138 iteration 5186 : loss : 0.006898, loss_ce: 0.004779
2021-11-30 14:35:27,498 iteration 5187 : loss : 0.008152, loss_ce: 0.005379
2021-11-30 14:35:28,845 iteration 5188 : loss : 0.008766, loss_ce: 0.006301
2021-11-30 14:35:30,191 iteration 5189 : loss : 0.006817, loss_ce: 0.004854
2021-11-30 14:35:31,535 iteration 5190 : loss : 0.007693, loss_ce: 0.005229
2021-11-30 14:35:32,877 iteration 5191 : loss : 0.009045, loss_ce: 0.006020
2021-11-30 14:35:34,233 iteration 5192 : loss : 0.007420, loss_ce: 0.005260
2021-11-30 14:35:35,584 iteration 5193 : loss : 0.009615, loss_ce: 0.006704
2021-11-30 14:35:36,942 iteration 5194 : loss : 0.008214, loss_ce: 0.005625
2021-11-30 14:35:38,293 iteration 5195 : loss : 0.008827, loss_ce: 0.005720
2021-11-30 14:35:39,634 iteration 5196 : loss : 0.009166, loss_ce: 0.006433
2021-11-30 14:35:40,968 iteration 5197 : loss : 0.008697, loss_ce: 0.005602
2021-11-30 14:35:42,328 iteration 5198 : loss : 0.006942, loss_ce: 0.004764
2021-11-30 14:35:43,686 iteration 5199 : loss : 0.007959, loss_ce: 0.005031
2021-11-30 14:35:45,034 iteration 5200 : loss : 0.009900, loss_ce: 0.005683
2021-11-30 14:35:46,382 iteration 5201 : loss : 0.010247, loss_ce: 0.005374
2021-11-30 14:35:47,739 iteration 5202 : loss : 0.007408, loss_ce: 0.005062
 76%|██████████████████████▏      | 306/400 [2:08:26<40:11, 25.66s/it]2021-11-30 14:35:49,143 iteration 5203 : loss : 0.008482, loss_ce: 0.005735
2021-11-30 14:35:50,490 iteration 5204 : loss : 0.008446, loss_ce: 0.006751
2021-11-30 14:35:51,839 iteration 5205 : loss : 0.007891, loss_ce: 0.005843
2021-11-30 14:35:53,182 iteration 5206 : loss : 0.009726, loss_ce: 0.005274
2021-11-30 14:35:54,534 iteration 5207 : loss : 0.008003, loss_ce: 0.005549
2021-11-30 14:35:55,878 iteration 5208 : loss : 0.009446, loss_ce: 0.006284
2021-11-30 14:35:57,232 iteration 5209 : loss : 0.007910, loss_ce: 0.004662
2021-11-30 14:35:58,590 iteration 5210 : loss : 0.008713, loss_ce: 0.005739
2021-11-30 14:35:59,939 iteration 5211 : loss : 0.007806, loss_ce: 0.005249
2021-11-30 14:36:01,296 iteration 5212 : loss : 0.007531, loss_ce: 0.005242
2021-11-30 14:36:02,648 iteration 5213 : loss : 0.008110, loss_ce: 0.005654
2021-11-30 14:36:04,002 iteration 5214 : loss : 0.009702, loss_ce: 0.005272
2021-11-30 14:36:05,364 iteration 5215 : loss : 0.007142, loss_ce: 0.004862
2021-11-30 14:36:06,713 iteration 5216 : loss : 0.007006, loss_ce: 0.005076
2021-11-30 14:36:08,071 iteration 5217 : loss : 0.008443, loss_ce: 0.005730
2021-11-30 14:36:09,432 iteration 5218 : loss : 0.008158, loss_ce: 0.005467
2021-11-30 14:36:10,779 iteration 5219 : loss : 0.008364, loss_ce: 0.004993
 77%|██████████████████████▎      | 307/400 [2:08:49<38:33, 24.87s/it]2021-11-30 14:36:12,198 iteration 5220 : loss : 0.009603, loss_ce: 0.006432
2021-11-30 14:36:13,544 iteration 5221 : loss : 0.009616, loss_ce: 0.005497
2021-11-30 14:36:14,898 iteration 5222 : loss : 0.010032, loss_ce: 0.006895
2021-11-30 14:36:16,256 iteration 5223 : loss : 0.010686, loss_ce: 0.005203
2021-11-30 14:36:17,604 iteration 5224 : loss : 0.006458, loss_ce: 0.004878
2021-11-30 14:36:18,945 iteration 5225 : loss : 0.007152, loss_ce: 0.005002
2021-11-30 14:36:20,305 iteration 5226 : loss : 0.009283, loss_ce: 0.006564
2021-11-30 14:36:21,652 iteration 5227 : loss : 0.007225, loss_ce: 0.004893
2021-11-30 14:36:23,006 iteration 5228 : loss : 0.008589, loss_ce: 0.005665
2021-11-30 14:36:24,358 iteration 5229 : loss : 0.006935, loss_ce: 0.004931
2021-11-30 14:36:25,717 iteration 5230 : loss : 0.011563, loss_ce: 0.005585
2021-11-30 14:36:27,082 iteration 5231 : loss : 0.009239, loss_ce: 0.005407
2021-11-30 14:36:28,431 iteration 5232 : loss : 0.007750, loss_ce: 0.005463
2021-11-30 14:36:29,787 iteration 5233 : loss : 0.007450, loss_ce: 0.005161
2021-11-30 14:36:31,149 iteration 5234 : loss : 0.007570, loss_ce: 0.005104
2021-11-30 14:36:32,505 iteration 5235 : loss : 0.006576, loss_ce: 0.004715
2021-11-30 14:36:33,862 iteration 5236 : loss : 0.006999, loss_ce: 0.004860
 77%|██████████████████████▎      | 308/400 [2:09:12<37:18, 24.34s/it]2021-11-30 14:36:35,285 iteration 5237 : loss : 0.008181, loss_ce: 0.005618
2021-11-30 14:36:36,644 iteration 5238 : loss : 0.008761, loss_ce: 0.005337
2021-11-30 14:36:38,005 iteration 5239 : loss : 0.007783, loss_ce: 0.005477
2021-11-30 14:36:39,365 iteration 5240 : loss : 0.007115, loss_ce: 0.005133
2021-11-30 14:36:40,722 iteration 5241 : loss : 0.008673, loss_ce: 0.005872
2021-11-30 14:36:42,082 iteration 5242 : loss : 0.007513, loss_ce: 0.005276
2021-11-30 14:36:43,435 iteration 5243 : loss : 0.008087, loss_ce: 0.005294
2021-11-30 14:36:44,789 iteration 5244 : loss : 0.011184, loss_ce: 0.005500
2021-11-30 14:36:46,152 iteration 5245 : loss : 0.008293, loss_ce: 0.005409
2021-11-30 14:36:47,501 iteration 5246 : loss : 0.010278, loss_ce: 0.007553
2021-11-30 14:36:48,853 iteration 5247 : loss : 0.011282, loss_ce: 0.005606
2021-11-30 14:36:50,212 iteration 5248 : loss : 0.006836, loss_ce: 0.005111
2021-11-30 14:36:51,561 iteration 5249 : loss : 0.007768, loss_ce: 0.005595
2021-11-30 14:36:52,916 iteration 5250 : loss : 0.006855, loss_ce: 0.004621
2021-11-30 14:36:54,267 iteration 5251 : loss : 0.008528, loss_ce: 0.005372
2021-11-30 14:36:55,610 iteration 5252 : loss : 0.006871, loss_ce: 0.004981
2021-11-30 14:36:56,962 iteration 5253 : loss : 0.007471, loss_ce: 0.005134
 77%|██████████████████████▍      | 309/400 [2:09:35<36:20, 23.96s/it]2021-11-30 14:36:58,368 iteration 5254 : loss : 0.011548, loss_ce: 0.006421
2021-11-30 14:36:59,709 iteration 5255 : loss : 0.008367, loss_ce: 0.005236
2021-11-30 14:37:01,059 iteration 5256 : loss : 0.009332, loss_ce: 0.005439
2021-11-30 14:37:02,407 iteration 5257 : loss : 0.007459, loss_ce: 0.005242
2021-11-30 14:37:03,754 iteration 5258 : loss : 0.007067, loss_ce: 0.004772
2021-11-30 14:37:05,108 iteration 5259 : loss : 0.008451, loss_ce: 0.005800
2021-11-30 14:37:06,456 iteration 5260 : loss : 0.008380, loss_ce: 0.006135
2021-11-30 14:37:07,813 iteration 5261 : loss : 0.006701, loss_ce: 0.004628
2021-11-30 14:37:09,160 iteration 5262 : loss : 0.007476, loss_ce: 0.004968
2021-11-30 14:37:10,512 iteration 5263 : loss : 0.007513, loss_ce: 0.005152
2021-11-30 14:37:11,847 iteration 5264 : loss : 0.007960, loss_ce: 0.005063
2021-11-30 14:37:13,190 iteration 5265 : loss : 0.008272, loss_ce: 0.005550
2021-11-30 14:37:14,539 iteration 5266 : loss : 0.011760, loss_ce: 0.008644
2021-11-30 14:37:15,878 iteration 5267 : loss : 0.007001, loss_ce: 0.005070
2021-11-30 14:37:17,228 iteration 5268 : loss : 0.012459, loss_ce: 0.007379
2021-11-30 14:37:18,565 iteration 5269 : loss : 0.007469, loss_ce: 0.005185
2021-11-30 14:37:18,565 Training Data Eval:
2021-11-30 14:37:26,164   Average segmentation loss on training set: 0.0072
2021-11-30 14:37:26,164 Validation Data Eval:
2021-11-30 14:37:28,790   Average segmentation loss on validation set: 0.1638
2021-11-30 14:37:30,143 iteration 5270 : loss : 0.008424, loss_ce: 0.005567
 78%|██████████████████████▍      | 310/400 [2:10:08<40:05, 26.73s/it]2021-11-30 14:37:31,559 iteration 5271 : loss : 0.007554, loss_ce: 0.004870
2021-11-30 14:37:32,900 iteration 5272 : loss : 0.008373, loss_ce: 0.005118
2021-11-30 14:37:34,255 iteration 5273 : loss : 0.007024, loss_ce: 0.004752
2021-11-30 14:37:35,606 iteration 5274 : loss : 0.010184, loss_ce: 0.006844
2021-11-30 14:37:36,944 iteration 5275 : loss : 0.008312, loss_ce: 0.005140
2021-11-30 14:37:38,289 iteration 5276 : loss : 0.007482, loss_ce: 0.005206
2021-11-30 14:37:39,645 iteration 5277 : loss : 0.007638, loss_ce: 0.005235
2021-11-30 14:37:40,995 iteration 5278 : loss : 0.007718, loss_ce: 0.005287
2021-11-30 14:37:42,344 iteration 5279 : loss : 0.008217, loss_ce: 0.005115
2021-11-30 14:37:43,698 iteration 5280 : loss : 0.007667, loss_ce: 0.005530
2021-11-30 14:37:45,048 iteration 5281 : loss : 0.008806, loss_ce: 0.005237
2021-11-30 14:37:46,397 iteration 5282 : loss : 0.008337, loss_ce: 0.005939
2021-11-30 14:37:47,751 iteration 5283 : loss : 0.008093, loss_ce: 0.006290
2021-11-30 14:37:49,111 iteration 5284 : loss : 0.009528, loss_ce: 0.004987
2021-11-30 14:37:50,469 iteration 5285 : loss : 0.007780, loss_ce: 0.005327
2021-11-30 14:37:51,828 iteration 5286 : loss : 0.011047, loss_ce: 0.008143
2021-11-30 14:37:53,178 iteration 5287 : loss : 0.009847, loss_ce: 0.006067
 78%|██████████████████████▌      | 311/400 [2:10:31<38:00, 25.62s/it]2021-11-30 14:37:54,604 iteration 5288 : loss : 0.007956, loss_ce: 0.005932
2021-11-30 14:37:55,961 iteration 5289 : loss : 0.011697, loss_ce: 0.007435
2021-11-30 14:37:57,324 iteration 5290 : loss : 0.007940, loss_ce: 0.005208
2021-11-30 14:37:58,680 iteration 5291 : loss : 0.009150, loss_ce: 0.006177
2021-11-30 14:38:00,038 iteration 5292 : loss : 0.006733, loss_ce: 0.005050
2021-11-30 14:38:01,399 iteration 5293 : loss : 0.006968, loss_ce: 0.004902
2021-11-30 14:38:02,751 iteration 5294 : loss : 0.010007, loss_ce: 0.005517
2021-11-30 14:38:04,107 iteration 5295 : loss : 0.009854, loss_ce: 0.006945
2021-11-30 14:38:05,471 iteration 5296 : loss : 0.007966, loss_ce: 0.005143
2021-11-30 14:38:06,830 iteration 5297 : loss : 0.007323, loss_ce: 0.004948
2021-11-30 14:38:08,178 iteration 5298 : loss : 0.009653, loss_ce: 0.005496
2021-11-30 14:38:09,536 iteration 5299 : loss : 0.007076, loss_ce: 0.005151
2021-11-30 14:38:10,895 iteration 5300 : loss : 0.007027, loss_ce: 0.004836
2021-11-30 14:38:12,249 iteration 5301 : loss : 0.007334, loss_ce: 0.004894
2021-11-30 14:38:13,605 iteration 5302 : loss : 0.009110, loss_ce: 0.005959
2021-11-30 14:38:14,956 iteration 5303 : loss : 0.007784, loss_ce: 0.005153
2021-11-30 14:38:16,292 iteration 5304 : loss : 0.008025, loss_ce: 0.005075
 78%|██████████████████████▌      | 312/400 [2:10:54<36:28, 24.87s/it]2021-11-30 14:38:17,702 iteration 5305 : loss : 0.011875, loss_ce: 0.005765
2021-11-30 14:38:19,041 iteration 5306 : loss : 0.008277, loss_ce: 0.005526
2021-11-30 14:38:20,401 iteration 5307 : loss : 0.007071, loss_ce: 0.004822
2021-11-30 14:38:21,762 iteration 5308 : loss : 0.009153, loss_ce: 0.006067
2021-11-30 14:38:23,103 iteration 5309 : loss : 0.009013, loss_ce: 0.006286
2021-11-30 14:38:24,449 iteration 5310 : loss : 0.009307, loss_ce: 0.005671
2021-11-30 14:38:25,801 iteration 5311 : loss : 0.008052, loss_ce: 0.005397
2021-11-30 14:38:27,162 iteration 5312 : loss : 0.008682, loss_ce: 0.005103
2021-11-30 14:38:28,518 iteration 5313 : loss : 0.010816, loss_ce: 0.006975
2021-11-30 14:38:29,867 iteration 5314 : loss : 0.009440, loss_ce: 0.005741
2021-11-30 14:38:31,224 iteration 5315 : loss : 0.008491, loss_ce: 0.005394
2021-11-30 14:38:32,574 iteration 5316 : loss : 0.008764, loss_ce: 0.006657
2021-11-30 14:38:33,925 iteration 5317 : loss : 0.007015, loss_ce: 0.004935
2021-11-30 14:38:35,281 iteration 5318 : loss : 0.016852, loss_ce: 0.006175
2021-11-30 14:38:36,646 iteration 5319 : loss : 0.008106, loss_ce: 0.005830
2021-11-30 14:38:37,987 iteration 5320 : loss : 0.008729, loss_ce: 0.004938
2021-11-30 14:38:39,329 iteration 5321 : loss : 0.011948, loss_ce: 0.005638
 78%|██████████████████████▋      | 313/400 [2:11:17<35:15, 24.32s/it]2021-11-30 14:38:40,742 iteration 5322 : loss : 0.010794, loss_ce: 0.005091
2021-11-30 14:38:42,083 iteration 5323 : loss : 0.009765, loss_ce: 0.005276
2021-11-30 14:38:43,438 iteration 5324 : loss : 0.008727, loss_ce: 0.006447
2021-11-30 14:38:44,778 iteration 5325 : loss : 0.008281, loss_ce: 0.005312
2021-11-30 14:38:46,139 iteration 5326 : loss : 0.007197, loss_ce: 0.005124
2021-11-30 14:38:47,492 iteration 5327 : loss : 0.008159, loss_ce: 0.005106
2021-11-30 14:38:48,833 iteration 5328 : loss : 0.009154, loss_ce: 0.005630
2021-11-30 14:38:50,177 iteration 5329 : loss : 0.009380, loss_ce: 0.005914
2021-11-30 14:38:51,532 iteration 5330 : loss : 0.007292, loss_ce: 0.005395
2021-11-30 14:38:52,894 iteration 5331 : loss : 0.007665, loss_ce: 0.004897
2021-11-30 14:38:54,231 iteration 5332 : loss : 0.007977, loss_ce: 0.005372
2021-11-30 14:38:55,581 iteration 5333 : loss : 0.009711, loss_ce: 0.006445
2021-11-30 14:38:56,925 iteration 5334 : loss : 0.006941, loss_ce: 0.005172
2021-11-30 14:38:58,277 iteration 5335 : loss : 0.008194, loss_ce: 0.005326
2021-11-30 14:38:59,628 iteration 5336 : loss : 0.010091, loss_ce: 0.005630
2021-11-30 14:39:00,972 iteration 5337 : loss : 0.008420, loss_ce: 0.005698
2021-11-30 14:39:02,326 iteration 5338 : loss : 0.008736, loss_ce: 0.005328
 78%|██████████████████████▊      | 314/400 [2:11:40<34:17, 23.92s/it]2021-11-30 14:39:03,737 iteration 5339 : loss : 0.008593, loss_ce: 0.004852
2021-11-30 14:39:05,080 iteration 5340 : loss : 0.009005, loss_ce: 0.004874
2021-11-30 14:39:06,435 iteration 5341 : loss : 0.006767, loss_ce: 0.004868
2021-11-30 14:39:07,768 iteration 5342 : loss : 0.009489, loss_ce: 0.006755
2021-11-30 14:39:09,112 iteration 5343 : loss : 0.012162, loss_ce: 0.008453
2021-11-30 14:39:10,464 iteration 5344 : loss : 0.009815, loss_ce: 0.005241
2021-11-30 14:39:11,808 iteration 5345 : loss : 0.007816, loss_ce: 0.005208
2021-11-30 14:39:13,159 iteration 5346 : loss : 0.008253, loss_ce: 0.005443
2021-11-30 14:39:14,493 iteration 5347 : loss : 0.008745, loss_ce: 0.005833
2021-11-30 14:39:15,854 iteration 5348 : loss : 0.008481, loss_ce: 0.005554
2021-11-30 14:39:17,208 iteration 5349 : loss : 0.007631, loss_ce: 0.005124
2021-11-30 14:39:18,537 iteration 5350 : loss : 0.008281, loss_ce: 0.005221
2021-11-30 14:39:19,886 iteration 5351 : loss : 0.009001, loss_ce: 0.005939
2021-11-30 14:39:21,236 iteration 5352 : loss : 0.008236, loss_ce: 0.005721
2021-11-30 14:39:22,587 iteration 5353 : loss : 0.007052, loss_ce: 0.004888
2021-11-30 14:39:23,932 iteration 5354 : loss : 0.008711, loss_ce: 0.006204
2021-11-30 14:39:23,932 Training Data Eval:
2021-11-30 14:39:31,516   Average segmentation loss on training set: 0.0069
2021-11-30 14:39:31,517 Validation Data Eval:
2021-11-30 14:39:34,143   Average segmentation loss on validation set: 0.1735
2021-11-30 14:39:35,482 iteration 5355 : loss : 0.010690, loss_ce: 0.005635
 79%|██████████████████████▊      | 315/400 [2:12:14<37:48, 26.69s/it]2021-11-30 14:39:36,901 iteration 5356 : loss : 0.007212, loss_ce: 0.005023
2021-11-30 14:39:38,243 iteration 5357 : loss : 0.007393, loss_ce: 0.004888
2021-11-30 14:39:39,598 iteration 5358 : loss : 0.007127, loss_ce: 0.005175
2021-11-30 14:39:40,945 iteration 5359 : loss : 0.007498, loss_ce: 0.005172
2021-11-30 14:39:42,297 iteration 5360 : loss : 0.008784, loss_ce: 0.005694
2021-11-30 14:39:43,647 iteration 5361 : loss : 0.006661, loss_ce: 0.004895
2021-11-30 14:39:45,001 iteration 5362 : loss : 0.008207, loss_ce: 0.004957
2021-11-30 14:39:46,361 iteration 5363 : loss : 0.007513, loss_ce: 0.005069
2021-11-30 14:39:47,712 iteration 5364 : loss : 0.007121, loss_ce: 0.004965
2021-11-30 14:39:49,066 iteration 5365 : loss : 0.007228, loss_ce: 0.005370
2021-11-30 14:39:50,411 iteration 5366 : loss : 0.007904, loss_ce: 0.005023
2021-11-30 14:39:51,778 iteration 5367 : loss : 0.007811, loss_ce: 0.005308
2021-11-30 14:39:53,131 iteration 5368 : loss : 0.006680, loss_ce: 0.004826
2021-11-30 14:39:54,479 iteration 5369 : loss : 0.009540, loss_ce: 0.006625
2021-11-30 14:39:55,833 iteration 5370 : loss : 0.006669, loss_ce: 0.005009
2021-11-30 14:39:57,191 iteration 5371 : loss : 0.008184, loss_ce: 0.005115
2021-11-30 14:39:58,534 iteration 5372 : loss : 0.007522, loss_ce: 0.004935
 79%|██████████████████████▉      | 316/400 [2:12:37<35:50, 25.60s/it]2021-11-30 14:39:59,947 iteration 5373 : loss : 0.008287, loss_ce: 0.005846
2021-11-30 14:40:01,295 iteration 5374 : loss : 0.011332, loss_ce: 0.005669
2021-11-30 14:40:02,643 iteration 5375 : loss : 0.007195, loss_ce: 0.004871
2021-11-30 14:40:03,994 iteration 5376 : loss : 0.010588, loss_ce: 0.005834
2021-11-30 14:40:05,345 iteration 5377 : loss : 0.016294, loss_ce: 0.006491
2021-11-30 14:40:06,689 iteration 5378 : loss : 0.007971, loss_ce: 0.004803
2021-11-30 14:40:08,049 iteration 5379 : loss : 0.008491, loss_ce: 0.005588
2021-11-30 14:40:09,413 iteration 5380 : loss : 0.017211, loss_ce: 0.006566
2021-11-30 14:40:10,772 iteration 5381 : loss : 0.013420, loss_ce: 0.009749
2021-11-30 14:40:12,131 iteration 5382 : loss : 0.008569, loss_ce: 0.006004
2021-11-30 14:40:13,499 iteration 5383 : loss : 0.009883, loss_ce: 0.006355
2021-11-30 14:40:14,855 iteration 5384 : loss : 0.011771, loss_ce: 0.007620
2021-11-30 14:40:16,213 iteration 5385 : loss : 0.007787, loss_ce: 0.005432
2021-11-30 14:40:17,575 iteration 5386 : loss : 0.008875, loss_ce: 0.005537
2021-11-30 14:40:18,933 iteration 5387 : loss : 0.009575, loss_ce: 0.006871
2021-11-30 14:40:20,293 iteration 5388 : loss : 0.007675, loss_ce: 0.004913
2021-11-30 14:40:21,647 iteration 5389 : loss : 0.008313, loss_ce: 0.005503
 79%|██████████████████████▉      | 317/400 [2:13:00<34:22, 24.86s/it]2021-11-30 14:40:23,075 iteration 5390 : loss : 0.008750, loss_ce: 0.005438
2021-11-30 14:40:24,423 iteration 5391 : loss : 0.007455, loss_ce: 0.004975
2021-11-30 14:40:25,778 iteration 5392 : loss : 0.008892, loss_ce: 0.006287
2021-11-30 14:40:27,132 iteration 5393 : loss : 0.011029, loss_ce: 0.006322
2021-11-30 14:40:28,489 iteration 5394 : loss : 0.012952, loss_ce: 0.007250
2021-11-30 14:40:29,831 iteration 5395 : loss : 0.007662, loss_ce: 0.005108
2021-11-30 14:40:31,192 iteration 5396 : loss : 0.007928, loss_ce: 0.005121
2021-11-30 14:40:32,546 iteration 5397 : loss : 0.007444, loss_ce: 0.004805
2021-11-30 14:40:33,902 iteration 5398 : loss : 0.006827, loss_ce: 0.005086
2021-11-30 14:40:35,255 iteration 5399 : loss : 0.008760, loss_ce: 0.005543
2021-11-30 14:40:36,601 iteration 5400 : loss : 0.009109, loss_ce: 0.006091
2021-11-30 14:40:37,957 iteration 5401 : loss : 0.008349, loss_ce: 0.004768
2021-11-30 14:40:39,310 iteration 5402 : loss : 0.008187, loss_ce: 0.005686
2021-11-30 14:40:40,658 iteration 5403 : loss : 0.007510, loss_ce: 0.005007
2021-11-30 14:40:42,009 iteration 5404 : loss : 0.006979, loss_ce: 0.004862
2021-11-30 14:40:43,363 iteration 5405 : loss : 0.008162, loss_ce: 0.005512
2021-11-30 14:40:44,717 iteration 5406 : loss : 0.008964, loss_ce: 0.006329
 80%|███████████████████████      | 318/400 [2:13:23<33:14, 24.32s/it]2021-11-30 14:40:46,129 iteration 5407 : loss : 0.012222, loss_ce: 0.008114
2021-11-30 14:40:47,478 iteration 5408 : loss : 0.009559, loss_ce: 0.005308
2021-11-30 14:40:48,839 iteration 5409 : loss : 0.007940, loss_ce: 0.005315
2021-11-30 14:40:50,189 iteration 5410 : loss : 0.007604, loss_ce: 0.005327
2021-11-30 14:40:51,538 iteration 5411 : loss : 0.008210, loss_ce: 0.004882
2021-11-30 14:40:52,882 iteration 5412 : loss : 0.008138, loss_ce: 0.005659
2021-11-30 14:40:54,238 iteration 5413 : loss : 0.007258, loss_ce: 0.005334
2021-11-30 14:40:55,596 iteration 5414 : loss : 0.007433, loss_ce: 0.005484
2021-11-30 14:40:56,929 iteration 5415 : loss : 0.007080, loss_ce: 0.004840
2021-11-30 14:40:58,271 iteration 5416 : loss : 0.007675, loss_ce: 0.005117
2021-11-30 14:40:59,626 iteration 5417 : loss : 0.010143, loss_ce: 0.005905
2021-11-30 14:41:00,975 iteration 5418 : loss : 0.009676, loss_ce: 0.005719
2021-11-30 14:41:02,326 iteration 5419 : loss : 0.007778, loss_ce: 0.005358
2021-11-30 14:41:03,674 iteration 5420 : loss : 0.008599, loss_ce: 0.005607
2021-11-30 14:41:05,026 iteration 5421 : loss : 0.007855, loss_ce: 0.005032
2021-11-30 14:41:06,369 iteration 5422 : loss : 0.007643, loss_ce: 0.005146
2021-11-30 14:41:07,714 iteration 5423 : loss : 0.007763, loss_ce: 0.005111
 80%|███████████████████████▏     | 319/400 [2:13:46<32:17, 23.92s/it]2021-11-30 14:41:09,131 iteration 5424 : loss : 0.007873, loss_ce: 0.005634
2021-11-30 14:41:10,473 iteration 5425 : loss : 0.009915, loss_ce: 0.005957
2021-11-30 14:41:11,838 iteration 5426 : loss : 0.007231, loss_ce: 0.005196
2021-11-30 14:41:13,190 iteration 5427 : loss : 0.007271, loss_ce: 0.005046
2021-11-30 14:41:14,533 iteration 5428 : loss : 0.011402, loss_ce: 0.005448
2021-11-30 14:41:15,873 iteration 5429 : loss : 0.009773, loss_ce: 0.006707
2021-11-30 14:41:17,221 iteration 5430 : loss : 0.007978, loss_ce: 0.005462
2021-11-30 14:41:18,580 iteration 5431 : loss : 0.007881, loss_ce: 0.005443
2021-11-30 14:41:19,940 iteration 5432 : loss : 0.008212, loss_ce: 0.005150
2021-11-30 14:41:21,287 iteration 5433 : loss : 0.007799, loss_ce: 0.005148
2021-11-30 14:41:22,634 iteration 5434 : loss : 0.007143, loss_ce: 0.005063
2021-11-30 14:41:23,981 iteration 5435 : loss : 0.007971, loss_ce: 0.005408
2021-11-30 14:41:25,328 iteration 5436 : loss : 0.006859, loss_ce: 0.005065
2021-11-30 14:41:26,689 iteration 5437 : loss : 0.007900, loss_ce: 0.005007
2021-11-30 14:41:28,030 iteration 5438 : loss : 0.007048, loss_ce: 0.004954
2021-11-30 14:41:29,384 iteration 5439 : loss : 0.008911, loss_ce: 0.005909
2021-11-30 14:41:29,384 Training Data Eval:
2021-11-30 14:41:37,029   Average segmentation loss on training set: 0.0067
2021-11-30 14:41:37,030 Validation Data Eval:
2021-11-30 14:41:39,656   Average segmentation loss on validation set: 0.1801
2021-11-30 14:41:40,999 iteration 5440 : loss : 0.007394, loss_ce: 0.005356
 80%|███████████████████████▏     | 320/400 [2:14:19<35:38, 26.73s/it]2021-11-30 14:41:42,409 iteration 5441 : loss : 0.007423, loss_ce: 0.004897
2021-11-30 14:41:43,749 iteration 5442 : loss : 0.006667, loss_ce: 0.004967
2021-11-30 14:41:45,104 iteration 5443 : loss : 0.008363, loss_ce: 0.005931
2021-11-30 14:41:46,452 iteration 5444 : loss : 0.006514, loss_ce: 0.004501
2021-11-30 14:41:47,810 iteration 5445 : loss : 0.007862, loss_ce: 0.005286
2021-11-30 14:41:49,161 iteration 5446 : loss : 0.009063, loss_ce: 0.005989
2021-11-30 14:41:50,502 iteration 5447 : loss : 0.008714, loss_ce: 0.005422
2021-11-30 14:41:51,844 iteration 5448 : loss : 0.009066, loss_ce: 0.005643
2021-11-30 14:41:53,188 iteration 5449 : loss : 0.010035, loss_ce: 0.007252
2021-11-30 14:41:54,546 iteration 5450 : loss : 0.010494, loss_ce: 0.006964
2021-11-30 14:41:55,896 iteration 5451 : loss : 0.009102, loss_ce: 0.005351
2021-11-30 14:41:57,252 iteration 5452 : loss : 0.010920, loss_ce: 0.005523
2021-11-30 14:41:58,597 iteration 5453 : loss : 0.007117, loss_ce: 0.005061
2021-11-30 14:41:59,937 iteration 5454 : loss : 0.010549, loss_ce: 0.005420
2021-11-30 14:42:01,280 iteration 5455 : loss : 0.008225, loss_ce: 0.005123
2021-11-30 14:42:02,635 iteration 5456 : loss : 0.006785, loss_ce: 0.005156
2021-11-30 14:42:03,996 iteration 5457 : loss : 0.007804, loss_ce: 0.005511
 80%|███████████████████████▎     | 321/400 [2:14:42<33:43, 25.61s/it]2021-11-30 14:42:05,416 iteration 5458 : loss : 0.008371, loss_ce: 0.004897
2021-11-30 14:42:06,772 iteration 5459 : loss : 0.010867, loss_ce: 0.007200
2021-11-30 14:42:08,116 iteration 5460 : loss : 0.007448, loss_ce: 0.005263
2021-11-30 14:42:09,465 iteration 5461 : loss : 0.007898, loss_ce: 0.005041
2021-11-30 14:42:10,821 iteration 5462 : loss : 0.007790, loss_ce: 0.005373
2021-11-30 14:42:12,174 iteration 5463 : loss : 0.007857, loss_ce: 0.005655
2021-11-30 14:42:13,519 iteration 5464 : loss : 0.007624, loss_ce: 0.005449
2021-11-30 14:42:14,869 iteration 5465 : loss : 0.007651, loss_ce: 0.005098
2021-11-30 14:42:16,207 iteration 5466 : loss : 0.008261, loss_ce: 0.005036
2021-11-30 14:42:17,558 iteration 5467 : loss : 0.010410, loss_ce: 0.006946
2021-11-30 14:42:18,902 iteration 5468 : loss : 0.006672, loss_ce: 0.005010
2021-11-30 14:42:20,258 iteration 5469 : loss : 0.007744, loss_ce: 0.005418
2021-11-30 14:42:21,616 iteration 5470 : loss : 0.007265, loss_ce: 0.005044
2021-11-30 14:42:22,968 iteration 5471 : loss : 0.007963, loss_ce: 0.004772
2021-11-30 14:42:24,322 iteration 5472 : loss : 0.008618, loss_ce: 0.006088
2021-11-30 14:42:25,668 iteration 5473 : loss : 0.007656, loss_ce: 0.004858
2021-11-30 14:42:27,013 iteration 5474 : loss : 0.008365, loss_ce: 0.005584
 80%|███████████████████████▎     | 322/400 [2:15:05<32:16, 24.83s/it]2021-11-30 14:42:28,435 iteration 5475 : loss : 0.007618, loss_ce: 0.005127
2021-11-30 14:42:29,785 iteration 5476 : loss : 0.008170, loss_ce: 0.005298
2021-11-30 14:42:31,132 iteration 5477 : loss : 0.006947, loss_ce: 0.004723
2021-11-30 14:42:32,493 iteration 5478 : loss : 0.006248, loss_ce: 0.004590
2021-11-30 14:42:33,852 iteration 5479 : loss : 0.007579, loss_ce: 0.005310
2021-11-30 14:42:35,210 iteration 5480 : loss : 0.006950, loss_ce: 0.004951
2021-11-30 14:42:36,572 iteration 5481 : loss : 0.007891, loss_ce: 0.005403
2021-11-30 14:42:37,928 iteration 5482 : loss : 0.009043, loss_ce: 0.006054
2021-11-30 14:42:39,284 iteration 5483 : loss : 0.008997, loss_ce: 0.006580
2021-11-30 14:42:40,650 iteration 5484 : loss : 0.007466, loss_ce: 0.004951
2021-11-30 14:42:42,010 iteration 5485 : loss : 0.007928, loss_ce: 0.005121
2021-11-30 14:42:43,361 iteration 5486 : loss : 0.007665, loss_ce: 0.005731
2021-11-30 14:42:44,723 iteration 5487 : loss : 0.006847, loss_ce: 0.005261
2021-11-30 14:42:46,082 iteration 5488 : loss : 0.008788, loss_ce: 0.005131
2021-11-30 14:42:47,447 iteration 5489 : loss : 0.010579, loss_ce: 0.005699
2021-11-30 14:42:48,798 iteration 5490 : loss : 0.009450, loss_ce: 0.006071
2021-11-30 14:42:50,159 iteration 5491 : loss : 0.007088, loss_ce: 0.004672
 81%|███████████████████████▍     | 323/400 [2:15:28<31:13, 24.33s/it]2021-11-30 14:42:51,575 iteration 5492 : loss : 0.009169, loss_ce: 0.005305
2021-11-30 14:42:52,931 iteration 5493 : loss : 0.007909, loss_ce: 0.005183
2021-11-30 14:42:54,283 iteration 5494 : loss : 0.007401, loss_ce: 0.004838
2021-11-30 14:42:55,642 iteration 5495 : loss : 0.006408, loss_ce: 0.004601
2021-11-30 14:42:57,003 iteration 5496 : loss : 0.007552, loss_ce: 0.004881
2021-11-30 14:42:58,358 iteration 5497 : loss : 0.007547, loss_ce: 0.005523
2021-11-30 14:42:59,718 iteration 5498 : loss : 0.008660, loss_ce: 0.005897
2021-11-30 14:43:01,075 iteration 5499 : loss : 0.007777, loss_ce: 0.005707
2021-11-30 14:43:02,435 iteration 5500 : loss : 0.008659, loss_ce: 0.006178
2021-11-30 14:43:03,795 iteration 5501 : loss : 0.012126, loss_ce: 0.008106
2021-11-30 14:43:05,164 iteration 5502 : loss : 0.006699, loss_ce: 0.004742
2021-11-30 14:43:06,517 iteration 5503 : loss : 0.006475, loss_ce: 0.004910
2021-11-30 14:43:07,874 iteration 5504 : loss : 0.008340, loss_ce: 0.005360
2021-11-30 14:43:09,219 iteration 5505 : loss : 0.010884, loss_ce: 0.005320
2021-11-30 14:43:10,573 iteration 5506 : loss : 0.006702, loss_ce: 0.004978
2021-11-30 14:43:11,923 iteration 5507 : loss : 0.008195, loss_ce: 0.005022
2021-11-30 14:43:13,272 iteration 5508 : loss : 0.008460, loss_ce: 0.006114
 81%|███████████████████████▍     | 324/400 [2:15:51<30:21, 23.96s/it]2021-11-30 14:43:14,686 iteration 5509 : loss : 0.009771, loss_ce: 0.006520
2021-11-30 14:43:16,042 iteration 5510 : loss : 0.007190, loss_ce: 0.004968
2021-11-30 14:43:17,396 iteration 5511 : loss : 0.007115, loss_ce: 0.004788
2021-11-30 14:43:18,755 iteration 5512 : loss : 0.009777, loss_ce: 0.005059
2021-11-30 14:43:20,108 iteration 5513 : loss : 0.007562, loss_ce: 0.005158
2021-11-30 14:43:21,467 iteration 5514 : loss : 0.008890, loss_ce: 0.005975
2021-11-30 14:43:22,827 iteration 5515 : loss : 0.006614, loss_ce: 0.004901
2021-11-30 14:43:24,187 iteration 5516 : loss : 0.016550, loss_ce: 0.007322
2021-11-30 14:43:25,546 iteration 5517 : loss : 0.008329, loss_ce: 0.005442
2021-11-30 14:43:26,908 iteration 5518 : loss : 0.007273, loss_ce: 0.005155
2021-11-30 14:43:28,265 iteration 5519 : loss : 0.009725, loss_ce: 0.005805
2021-11-30 14:43:29,627 iteration 5520 : loss : 0.007297, loss_ce: 0.005411
2021-11-30 14:43:30,988 iteration 5521 : loss : 0.013600, loss_ce: 0.006829
2021-11-30 14:43:32,339 iteration 5522 : loss : 0.008526, loss_ce: 0.005331
2021-11-30 14:43:33,697 iteration 5523 : loss : 0.006371, loss_ce: 0.004816
2021-11-30 14:43:35,053 iteration 5524 : loss : 0.008227, loss_ce: 0.006065
2021-11-30 14:43:35,053 Training Data Eval:
2021-11-30 14:43:42,740   Average segmentation loss on training set: 0.0068
2021-11-30 14:43:42,740 Validation Data Eval:
2021-11-30 14:43:45,398   Average segmentation loss on validation set: 0.1840
2021-11-30 14:43:46,740 iteration 5525 : loss : 0.007527, loss_ce: 0.005102
 81%|███████████████████████▌     | 325/400 [2:16:25<33:31, 26.82s/it]2021-11-30 14:43:48,164 iteration 5526 : loss : 0.007337, loss_ce: 0.004989
2021-11-30 14:43:49,519 iteration 5527 : loss : 0.008741, loss_ce: 0.004932
2021-11-30 14:43:50,880 iteration 5528 : loss : 0.007212, loss_ce: 0.004856
2021-11-30 14:43:52,229 iteration 5529 : loss : 0.012881, loss_ce: 0.005589
2021-11-30 14:43:53,587 iteration 5530 : loss : 0.009037, loss_ce: 0.005745
2021-11-30 14:43:54,941 iteration 5531 : loss : 0.009639, loss_ce: 0.006997
2021-11-30 14:43:56,286 iteration 5532 : loss : 0.018053, loss_ce: 0.005862
2021-11-30 14:43:57,642 iteration 5533 : loss : 0.008476, loss_ce: 0.005568
2021-11-30 14:43:58,998 iteration 5534 : loss : 0.010406, loss_ce: 0.006883
2021-11-30 14:44:00,336 iteration 5535 : loss : 0.010469, loss_ce: 0.006441
2021-11-30 14:44:01,677 iteration 5536 : loss : 0.008120, loss_ce: 0.005324
2021-11-30 14:44:03,038 iteration 5537 : loss : 0.009485, loss_ce: 0.006142
2021-11-30 14:44:04,395 iteration 5538 : loss : 0.017146, loss_ce: 0.011834
2021-11-30 14:44:05,737 iteration 5539 : loss : 0.006862, loss_ce: 0.004535
2021-11-30 14:44:07,087 iteration 5540 : loss : 0.008911, loss_ce: 0.006566
2021-11-30 14:44:08,439 iteration 5541 : loss : 0.010021, loss_ce: 0.005171
2021-11-30 14:44:09,781 iteration 5542 : loss : 0.007076, loss_ce: 0.004632
 82%|███████████████████████▋     | 326/400 [2:16:48<31:40, 25.68s/it]2021-11-30 14:44:11,202 iteration 5543 : loss : 0.006784, loss_ce: 0.004818
2021-11-30 14:44:12,560 iteration 5544 : loss : 0.007736, loss_ce: 0.005326
2021-11-30 14:44:13,903 iteration 5545 : loss : 0.008232, loss_ce: 0.005203
2021-11-30 14:44:15,265 iteration 5546 : loss : 0.007688, loss_ce: 0.005210
2021-11-30 14:44:16,617 iteration 5547 : loss : 0.007366, loss_ce: 0.004956
2021-11-30 14:44:17,959 iteration 5548 : loss : 0.009530, loss_ce: 0.006542
2021-11-30 14:44:19,320 iteration 5549 : loss : 0.009389, loss_ce: 0.006364
2021-11-30 14:44:20,676 iteration 5550 : loss : 0.011298, loss_ce: 0.005312
2021-11-30 14:44:22,037 iteration 5551 : loss : 0.008590, loss_ce: 0.005515
2021-11-30 14:44:23,393 iteration 5552 : loss : 0.007310, loss_ce: 0.005585
2021-11-30 14:44:24,752 iteration 5553 : loss : 0.009123, loss_ce: 0.005946
2021-11-30 14:44:26,109 iteration 5554 : loss : 0.007281, loss_ce: 0.004992
2021-11-30 14:44:27,448 iteration 5555 : loss : 0.009094, loss_ce: 0.005818
2021-11-30 14:44:28,802 iteration 5556 : loss : 0.006584, loss_ce: 0.004647
2021-11-30 14:44:30,154 iteration 5557 : loss : 0.007484, loss_ce: 0.005135
2021-11-30 14:44:31,520 iteration 5558 : loss : 0.008923, loss_ce: 0.005949
2021-11-30 14:44:32,885 iteration 5559 : loss : 0.007218, loss_ce: 0.005149
 82%|███████████████████████▋     | 327/400 [2:17:11<30:18, 24.91s/it]2021-11-30 14:44:34,300 iteration 5560 : loss : 0.006163, loss_ce: 0.004771
2021-11-30 14:44:35,642 iteration 5561 : loss : 0.009261, loss_ce: 0.005305
2021-11-30 14:44:36,990 iteration 5562 : loss : 0.011758, loss_ce: 0.005860
2021-11-30 14:44:38,339 iteration 5563 : loss : 0.007446, loss_ce: 0.004942
2021-11-30 14:44:39,681 iteration 5564 : loss : 0.008246, loss_ce: 0.005658
2021-11-30 14:44:41,038 iteration 5565 : loss : 0.007162, loss_ce: 0.005253
2021-11-30 14:44:42,376 iteration 5566 : loss : 0.007696, loss_ce: 0.005423
2021-11-30 14:44:43,735 iteration 5567 : loss : 0.008006, loss_ce: 0.005658
2021-11-30 14:44:45,081 iteration 5568 : loss : 0.009816, loss_ce: 0.006187
2021-11-30 14:44:46,422 iteration 5569 : loss : 0.007111, loss_ce: 0.004886
2021-11-30 14:44:47,778 iteration 5570 : loss : 0.007697, loss_ce: 0.004955
2021-11-30 14:44:49,120 iteration 5571 : loss : 0.008262, loss_ce: 0.004901
2021-11-30 14:44:50,465 iteration 5572 : loss : 0.007108, loss_ce: 0.005035
2021-11-30 14:44:51,825 iteration 5573 : loss : 0.007516, loss_ce: 0.005545
2021-11-30 14:44:53,187 iteration 5574 : loss : 0.007656, loss_ce: 0.005192
2021-11-30 14:44:54,548 iteration 5575 : loss : 0.009582, loss_ce: 0.005299
2021-11-30 14:44:55,910 iteration 5576 : loss : 0.010068, loss_ce: 0.006445
 82%|███████████████████████▊     | 328/400 [2:17:34<29:12, 24.34s/it]2021-11-30 14:44:57,330 iteration 5577 : loss : 0.008553, loss_ce: 0.006375
2021-11-30 14:44:58,694 iteration 5578 : loss : 0.007957, loss_ce: 0.004892
2021-11-30 14:45:00,043 iteration 5579 : loss : 0.007464, loss_ce: 0.004576
2021-11-30 14:45:01,396 iteration 5580 : loss : 0.006648, loss_ce: 0.004718
2021-11-30 14:45:02,743 iteration 5581 : loss : 0.006659, loss_ce: 0.004763
2021-11-30 14:45:04,100 iteration 5582 : loss : 0.007687, loss_ce: 0.005306
2021-11-30 14:45:05,461 iteration 5583 : loss : 0.009085, loss_ce: 0.005436
2021-11-30 14:45:06,796 iteration 5584 : loss : 0.006764, loss_ce: 0.004985
2021-11-30 14:45:08,154 iteration 5585 : loss : 0.010082, loss_ce: 0.006774
2021-11-30 14:45:09,516 iteration 5586 : loss : 0.007041, loss_ce: 0.004977
2021-11-30 14:45:10,864 iteration 5587 : loss : 0.006194, loss_ce: 0.004591
2021-11-30 14:45:12,214 iteration 5588 : loss : 0.007568, loss_ce: 0.005233
2021-11-30 14:45:13,558 iteration 5589 : loss : 0.009429, loss_ce: 0.005016
2021-11-30 14:45:14,903 iteration 5590 : loss : 0.008187, loss_ce: 0.005471
2021-11-30 14:45:16,245 iteration 5591 : loss : 0.009752, loss_ce: 0.007059
2021-11-30 14:45:17,592 iteration 5592 : loss : 0.007576, loss_ce: 0.005024
2021-11-30 14:45:18,954 iteration 5593 : loss : 0.007113, loss_ce: 0.004862
 82%|███████████████████████▊     | 329/400 [2:17:57<28:20, 23.95s/it]2021-11-30 14:45:20,355 iteration 5594 : loss : 0.008192, loss_ce: 0.005739
2021-11-30 14:45:21,687 iteration 5595 : loss : 0.008218, loss_ce: 0.005141
2021-11-30 14:45:23,041 iteration 5596 : loss : 0.007019, loss_ce: 0.004867
2021-11-30 14:45:24,387 iteration 5597 : loss : 0.008719, loss_ce: 0.006358
2021-11-30 14:45:25,736 iteration 5598 : loss : 0.008356, loss_ce: 0.005053
2021-11-30 14:45:27,083 iteration 5599 : loss : 0.008696, loss_ce: 0.005776
2021-11-30 14:45:28,434 iteration 5600 : loss : 0.007773, loss_ce: 0.004956
2021-11-30 14:45:29,774 iteration 5601 : loss : 0.008615, loss_ce: 0.005360
2021-11-30 14:45:31,116 iteration 5602 : loss : 0.008129, loss_ce: 0.006118
2021-11-30 14:45:32,481 iteration 5603 : loss : 0.009364, loss_ce: 0.006532
2021-11-30 14:45:33,839 iteration 5604 : loss : 0.007419, loss_ce: 0.005273
2021-11-30 14:45:35,191 iteration 5605 : loss : 0.008461, loss_ce: 0.005010
2021-11-30 14:45:36,544 iteration 5606 : loss : 0.008638, loss_ce: 0.005084
2021-11-30 14:45:37,902 iteration 5607 : loss : 0.007034, loss_ce: 0.004785
2021-11-30 14:45:39,254 iteration 5608 : loss : 0.008605, loss_ce: 0.005690
2021-11-30 14:45:40,607 iteration 5609 : loss : 0.008915, loss_ce: 0.006007
2021-11-30 14:45:40,607 Training Data Eval:
2021-11-30 14:45:48,227   Average segmentation loss on training set: 0.0066
2021-11-30 14:45:48,227 Validation Data Eval:
2021-11-30 14:45:50,840   Average segmentation loss on validation set: 0.1803
2021-11-30 14:45:52,185 iteration 5610 : loss : 0.007195, loss_ce: 0.004847
 82%|███████████████████████▉     | 330/400 [2:18:30<31:11, 26.74s/it]2021-11-30 14:45:53,595 iteration 5611 : loss : 0.007154, loss_ce: 0.004764
2021-11-30 14:45:54,939 iteration 5612 : loss : 0.008775, loss_ce: 0.004879
2021-11-30 14:45:56,292 iteration 5613 : loss : 0.006812, loss_ce: 0.005217
2021-11-30 14:45:57,652 iteration 5614 : loss : 0.007282, loss_ce: 0.005236
2021-11-30 14:45:59,005 iteration 5615 : loss : 0.011963, loss_ce: 0.005635
2021-11-30 14:46:00,348 iteration 5616 : loss : 0.011964, loss_ce: 0.007013
2021-11-30 14:46:01,698 iteration 5617 : loss : 0.007608, loss_ce: 0.004898
2021-11-30 14:46:03,052 iteration 5618 : loss : 0.006375, loss_ce: 0.004905
2021-11-30 14:46:04,403 iteration 5619 : loss : 0.008899, loss_ce: 0.006375
2021-11-30 14:46:05,754 iteration 5620 : loss : 0.007338, loss_ce: 0.004952
2021-11-30 14:46:07,112 iteration 5621 : loss : 0.006167, loss_ce: 0.004775
2021-11-30 14:46:08,473 iteration 5622 : loss : 0.006830, loss_ce: 0.005129
2021-11-30 14:46:09,834 iteration 5623 : loss : 0.009748, loss_ce: 0.006512
2021-11-30 14:46:11,200 iteration 5624 : loss : 0.009428, loss_ce: 0.004984
2021-11-30 14:46:12,554 iteration 5625 : loss : 0.007430, loss_ce: 0.004878
2021-11-30 14:46:13,911 iteration 5626 : loss : 0.009053, loss_ce: 0.006466
2021-11-30 14:46:15,269 iteration 5627 : loss : 0.010164, loss_ce: 0.006643
 83%|███████████████████████▉     | 331/400 [2:18:53<29:29, 25.64s/it]2021-11-30 14:46:16,682 iteration 5628 : loss : 0.006784, loss_ce: 0.004669
2021-11-30 14:46:18,033 iteration 5629 : loss : 0.007156, loss_ce: 0.005058
2021-11-30 14:46:19,392 iteration 5630 : loss : 0.007259, loss_ce: 0.004980
2021-11-30 14:46:20,743 iteration 5631 : loss : 0.006219, loss_ce: 0.004661
2021-11-30 14:46:22,092 iteration 5632 : loss : 0.007624, loss_ce: 0.005535
2021-11-30 14:46:23,445 iteration 5633 : loss : 0.009409, loss_ce: 0.007086
2021-11-30 14:46:24,799 iteration 5634 : loss : 0.007873, loss_ce: 0.005116
2021-11-30 14:46:26,151 iteration 5635 : loss : 0.008489, loss_ce: 0.006156
2021-11-30 14:46:27,489 iteration 5636 : loss : 0.006773, loss_ce: 0.004903
2021-11-30 14:46:28,845 iteration 5637 : loss : 0.010491, loss_ce: 0.005375
2021-11-30 14:46:30,198 iteration 5638 : loss : 0.007191, loss_ce: 0.005318
2021-11-30 14:46:31,536 iteration 5639 : loss : 0.007716, loss_ce: 0.005625
2021-11-30 14:46:32,900 iteration 5640 : loss : 0.007955, loss_ce: 0.004796
2021-11-30 14:46:34,246 iteration 5641 : loss : 0.007995, loss_ce: 0.004920
2021-11-30 14:46:35,581 iteration 5642 : loss : 0.008389, loss_ce: 0.005074
2021-11-30 14:46:36,926 iteration 5643 : loss : 0.008778, loss_ce: 0.005139
2021-11-30 14:46:38,283 iteration 5644 : loss : 0.007895, loss_ce: 0.005407
 83%|████████████████████████     | 332/400 [2:19:16<28:10, 24.85s/it]2021-11-30 14:46:39,689 iteration 5645 : loss : 0.008773, loss_ce: 0.005629
2021-11-30 14:46:41,022 iteration 5646 : loss : 0.007510, loss_ce: 0.005290
2021-11-30 14:46:42,374 iteration 5647 : loss : 0.008089, loss_ce: 0.006021
2021-11-30 14:46:43,729 iteration 5648 : loss : 0.006928, loss_ce: 0.004879
2021-11-30 14:46:45,072 iteration 5649 : loss : 0.008343, loss_ce: 0.006174
2021-11-30 14:46:46,417 iteration 5650 : loss : 0.008906, loss_ce: 0.006136
2021-11-30 14:46:47,759 iteration 5651 : loss : 0.007292, loss_ce: 0.004690
2021-11-30 14:46:49,107 iteration 5652 : loss : 0.007699, loss_ce: 0.005116
2021-11-30 14:46:50,456 iteration 5653 : loss : 0.006857, loss_ce: 0.004907
2021-11-30 14:46:51,801 iteration 5654 : loss : 0.008974, loss_ce: 0.005110
2021-11-30 14:46:53,159 iteration 5655 : loss : 0.007871, loss_ce: 0.004861
2021-11-30 14:46:54,498 iteration 5656 : loss : 0.009292, loss_ce: 0.006624
2021-11-30 14:46:55,841 iteration 5657 : loss : 0.006749, loss_ce: 0.004622
2021-11-30 14:46:57,192 iteration 5658 : loss : 0.008818, loss_ce: 0.004929
2021-11-30 14:46:58,542 iteration 5659 : loss : 0.007123, loss_ce: 0.004682
2021-11-30 14:46:59,893 iteration 5660 : loss : 0.008297, loss_ce: 0.005747
2021-11-30 14:47:01,250 iteration 5661 : loss : 0.007810, loss_ce: 0.005668
 83%|████████████████████████▏    | 333/400 [2:19:39<27:07, 24.29s/it]2021-11-30 14:47:02,658 iteration 5662 : loss : 0.008375, loss_ce: 0.005963
2021-11-30 14:47:03,995 iteration 5663 : loss : 0.009238, loss_ce: 0.006514
2021-11-30 14:47:05,351 iteration 5664 : loss : 0.007536, loss_ce: 0.005595
2021-11-30 14:47:06,705 iteration 5665 : loss : 0.006995, loss_ce: 0.004833
2021-11-30 14:47:08,051 iteration 5666 : loss : 0.007230, loss_ce: 0.004978
2021-11-30 14:47:09,394 iteration 5667 : loss : 0.007655, loss_ce: 0.004754
2021-11-30 14:47:10,746 iteration 5668 : loss : 0.008694, loss_ce: 0.005057
2021-11-30 14:47:12,102 iteration 5669 : loss : 0.010809, loss_ce: 0.006870
2021-11-30 14:47:13,455 iteration 5670 : loss : 0.007108, loss_ce: 0.004686
2021-11-30 14:47:14,804 iteration 5671 : loss : 0.009739, loss_ce: 0.006446
2021-11-30 14:47:16,160 iteration 5672 : loss : 0.010343, loss_ce: 0.005868
2021-11-30 14:47:17,515 iteration 5673 : loss : 0.010091, loss_ce: 0.005583
2021-11-30 14:47:18,870 iteration 5674 : loss : 0.006647, loss_ce: 0.004443
2021-11-30 14:47:20,224 iteration 5675 : loss : 0.007045, loss_ce: 0.005113
2021-11-30 14:47:21,562 iteration 5676 : loss : 0.007654, loss_ce: 0.005681
2021-11-30 14:47:22,922 iteration 5677 : loss : 0.007106, loss_ce: 0.004972
2021-11-30 14:47:24,280 iteration 5678 : loss : 0.007093, loss_ce: 0.005077
 84%|████████████████████████▏    | 334/400 [2:20:02<26:18, 23.91s/it]2021-11-30 14:47:25,689 iteration 5679 : loss : 0.007182, loss_ce: 0.004378
2021-11-30 14:47:27,033 iteration 5680 : loss : 0.008223, loss_ce: 0.005948
2021-11-30 14:47:28,389 iteration 5681 : loss : 0.009681, loss_ce: 0.005649
2021-11-30 14:47:29,740 iteration 5682 : loss : 0.008323, loss_ce: 0.005484
2021-11-30 14:47:31,089 iteration 5683 : loss : 0.007342, loss_ce: 0.005114
2021-11-30 14:47:32,433 iteration 5684 : loss : 0.006909, loss_ce: 0.004891
2021-11-30 14:47:33,780 iteration 5685 : loss : 0.006965, loss_ce: 0.004559
2021-11-30 14:47:35,135 iteration 5686 : loss : 0.007853, loss_ce: 0.005644
2021-11-30 14:47:36,487 iteration 5687 : loss : 0.009422, loss_ce: 0.005654
2021-11-30 14:47:37,838 iteration 5688 : loss : 0.009490, loss_ce: 0.006693
2021-11-30 14:47:39,183 iteration 5689 : loss : 0.008570, loss_ce: 0.005093
2021-11-30 14:47:40,525 iteration 5690 : loss : 0.008162, loss_ce: 0.004863
2021-11-30 14:47:41,881 iteration 5691 : loss : 0.007113, loss_ce: 0.004909
2021-11-30 14:47:43,231 iteration 5692 : loss : 0.008201, loss_ce: 0.005192
2021-11-30 14:47:44,594 iteration 5693 : loss : 0.009448, loss_ce: 0.006605
2021-11-30 14:47:45,949 iteration 5694 : loss : 0.007924, loss_ce: 0.005672
2021-11-30 14:47:45,949 Training Data Eval:
2021-11-30 14:47:53,611   Average segmentation loss on training set: 0.0070
2021-11-30 14:47:53,612 Validation Data Eval:
2021-11-30 14:47:56,261   Average segmentation loss on validation set: 0.1761
2021-11-30 14:47:57,620 iteration 5695 : loss : 0.008194, loss_ce: 0.005333
 84%|████████████████████████▎    | 335/400 [2:20:36<28:57, 26.74s/it]2021-11-30 14:47:59,042 iteration 5696 : loss : 0.009638, loss_ce: 0.005504
2021-11-30 14:48:00,402 iteration 5697 : loss : 0.010801, loss_ce: 0.005593
2021-11-30 14:48:01,765 iteration 5698 : loss : 0.007600, loss_ce: 0.004981
2021-11-30 14:48:03,123 iteration 5699 : loss : 0.008952, loss_ce: 0.005842
2021-11-30 14:48:04,482 iteration 5700 : loss : 0.006814, loss_ce: 0.004830
2021-11-30 14:48:05,841 iteration 5701 : loss : 0.007868, loss_ce: 0.006013
2021-11-30 14:48:07,202 iteration 5702 : loss : 0.007887, loss_ce: 0.005052
2021-11-30 14:48:08,559 iteration 5703 : loss : 0.006635, loss_ce: 0.004406
2021-11-30 14:48:09,920 iteration 5704 : loss : 0.007743, loss_ce: 0.005719
2021-11-30 14:48:11,282 iteration 5705 : loss : 0.007768, loss_ce: 0.004964
2021-11-30 14:48:12,632 iteration 5706 : loss : 0.007880, loss_ce: 0.005050
2021-11-30 14:48:13,994 iteration 5707 : loss : 0.007380, loss_ce: 0.005113
2021-11-30 14:48:15,354 iteration 5708 : loss : 0.009288, loss_ce: 0.005381
2021-11-30 14:48:16,705 iteration 5709 : loss : 0.012708, loss_ce: 0.007678
2021-11-30 14:48:18,065 iteration 5710 : loss : 0.006688, loss_ce: 0.005098
2021-11-30 14:48:19,422 iteration 5711 : loss : 0.008783, loss_ce: 0.006086
2021-11-30 14:48:20,780 iteration 5712 : loss : 0.007054, loss_ce: 0.005529
 84%|████████████████████████▎    | 336/400 [2:20:59<27:22, 25.67s/it]2021-11-30 14:48:22,210 iteration 5713 : loss : 0.008245, loss_ce: 0.005100
2021-11-30 14:48:23,571 iteration 5714 : loss : 0.010663, loss_ce: 0.006060
2021-11-30 14:48:24,927 iteration 5715 : loss : 0.007661, loss_ce: 0.005380
2021-11-30 14:48:26,281 iteration 5716 : loss : 0.010167, loss_ce: 0.005671
2021-11-30 14:48:27,641 iteration 5717 : loss : 0.009169, loss_ce: 0.006298
2021-11-30 14:48:29,002 iteration 5718 : loss : 0.006480, loss_ce: 0.004829
2021-11-30 14:48:30,364 iteration 5719 : loss : 0.007337, loss_ce: 0.005063
2021-11-30 14:48:31,725 iteration 5720 : loss : 0.007882, loss_ce: 0.005490
2021-11-30 14:48:33,079 iteration 5721 : loss : 0.008078, loss_ce: 0.005152
2021-11-30 14:48:34,437 iteration 5722 : loss : 0.007911, loss_ce: 0.005102
2021-11-30 14:48:35,793 iteration 5723 : loss : 0.007542, loss_ce: 0.005366
2021-11-30 14:48:37,151 iteration 5724 : loss : 0.009122, loss_ce: 0.004937
2021-11-30 14:48:38,502 iteration 5725 : loss : 0.006232, loss_ce: 0.004964
2021-11-30 14:48:39,863 iteration 5726 : loss : 0.005674, loss_ce: 0.004415
2021-11-30 14:48:41,220 iteration 5727 : loss : 0.007688, loss_ce: 0.005020
2021-11-30 14:48:42,578 iteration 5728 : loss : 0.008169, loss_ce: 0.005276
2021-11-30 14:48:43,934 iteration 5729 : loss : 0.007574, loss_ce: 0.005412
 84%|████████████████████████▍    | 337/400 [2:21:22<26:09, 24.91s/it]2021-11-30 14:48:45,343 iteration 5730 : loss : 0.007660, loss_ce: 0.004844
2021-11-30 14:48:46,698 iteration 5731 : loss : 0.008663, loss_ce: 0.005956
2021-11-30 14:48:48,059 iteration 5732 : loss : 0.006845, loss_ce: 0.004881
2021-11-30 14:48:49,411 iteration 5733 : loss : 0.008248, loss_ce: 0.005433
2021-11-30 14:48:50,762 iteration 5734 : loss : 0.006820, loss_ce: 0.004893
2021-11-30 14:48:52,112 iteration 5735 : loss : 0.009551, loss_ce: 0.006429
2021-11-30 14:48:53,471 iteration 5736 : loss : 0.013679, loss_ce: 0.005786
2021-11-30 14:48:54,828 iteration 5737 : loss : 0.007622, loss_ce: 0.005078
2021-11-30 14:48:56,165 iteration 5738 : loss : 0.006858, loss_ce: 0.004795
2021-11-30 14:48:57,509 iteration 5739 : loss : 0.007832, loss_ce: 0.005566
2021-11-30 14:48:58,864 iteration 5740 : loss : 0.008792, loss_ce: 0.006042
2021-11-30 14:49:00,219 iteration 5741 : loss : 0.008036, loss_ce: 0.004967
2021-11-30 14:49:01,581 iteration 5742 : loss : 0.011441, loss_ce: 0.008658
2021-11-30 14:49:02,926 iteration 5743 : loss : 0.007407, loss_ce: 0.004968
2021-11-30 14:49:04,268 iteration 5744 : loss : 0.009422, loss_ce: 0.006533
2021-11-30 14:49:05,612 iteration 5745 : loss : 0.006877, loss_ce: 0.004786
2021-11-30 14:49:06,964 iteration 5746 : loss : 0.008749, loss_ce: 0.004977
 84%|████████████████████████▌    | 338/400 [2:21:45<25:09, 24.35s/it]2021-11-30 14:49:08,385 iteration 5747 : loss : 0.009485, loss_ce: 0.005597
2021-11-30 14:49:09,732 iteration 5748 : loss : 0.007781, loss_ce: 0.004690
2021-11-30 14:49:11,084 iteration 5749 : loss : 0.008944, loss_ce: 0.005430
2021-11-30 14:49:12,434 iteration 5750 : loss : 0.007546, loss_ce: 0.005241
2021-11-30 14:49:13,773 iteration 5751 : loss : 0.007245, loss_ce: 0.004810
2021-11-30 14:49:15,114 iteration 5752 : loss : 0.007476, loss_ce: 0.004950
2021-11-30 14:49:16,463 iteration 5753 : loss : 0.008821, loss_ce: 0.006532
2021-11-30 14:49:17,814 iteration 5754 : loss : 0.006307, loss_ce: 0.004516
2021-11-30 14:49:19,170 iteration 5755 : loss : 0.007519, loss_ce: 0.005107
2021-11-30 14:49:20,519 iteration 5756 : loss : 0.008462, loss_ce: 0.005721
2021-11-30 14:49:21,858 iteration 5757 : loss : 0.006095, loss_ce: 0.004813
2021-11-30 14:49:23,209 iteration 5758 : loss : 0.009554, loss_ce: 0.006859
2021-11-30 14:49:24,557 iteration 5759 : loss : 0.006842, loss_ce: 0.004856
2021-11-30 14:49:25,910 iteration 5760 : loss : 0.007787, loss_ce: 0.005029
2021-11-30 14:49:27,266 iteration 5761 : loss : 0.009792, loss_ce: 0.005290
2021-11-30 14:49:28,618 iteration 5762 : loss : 0.008816, loss_ce: 0.005164
2021-11-30 14:49:29,968 iteration 5763 : loss : 0.009781, loss_ce: 0.005093
 85%|████████████████████████▌    | 339/400 [2:22:08<24:20, 23.94s/it]2021-11-30 14:49:31,384 iteration 5764 : loss : 0.006436, loss_ce: 0.004680
2021-11-30 14:49:32,742 iteration 5765 : loss : 0.007335, loss_ce: 0.004488
2021-11-30 14:49:34,097 iteration 5766 : loss : 0.007368, loss_ce: 0.005088
2021-11-30 14:49:35,449 iteration 5767 : loss : 0.008487, loss_ce: 0.005729
2021-11-30 14:49:36,804 iteration 5768 : loss : 0.008609, loss_ce: 0.006322
2021-11-30 14:49:38,171 iteration 5769 : loss : 0.007209, loss_ce: 0.005069
2021-11-30 14:49:39,529 iteration 5770 : loss : 0.009678, loss_ce: 0.007188
2021-11-30 14:49:40,888 iteration 5771 : loss : 0.006896, loss_ce: 0.005030
2021-11-30 14:49:42,247 iteration 5772 : loss : 0.006547, loss_ce: 0.004700
2021-11-30 14:49:43,606 iteration 5773 : loss : 0.008166, loss_ce: 0.005044
2021-11-30 14:49:44,967 iteration 5774 : loss : 0.006643, loss_ce: 0.004525
2021-11-30 14:49:46,326 iteration 5775 : loss : 0.006487, loss_ce: 0.004626
2021-11-30 14:49:47,693 iteration 5776 : loss : 0.007383, loss_ce: 0.005064
2021-11-30 14:49:49,048 iteration 5777 : loss : 0.007782, loss_ce: 0.005402
2021-11-30 14:49:50,407 iteration 5778 : loss : 0.007118, loss_ce: 0.005027
2021-11-30 14:49:51,762 iteration 5779 : loss : 0.007026, loss_ce: 0.004677
2021-11-30 14:49:51,762 Training Data Eval:
2021-11-30 14:49:59,482   Average segmentation loss on training set: 0.0067
2021-11-30 14:49:59,483 Validation Data Eval:
2021-11-30 14:50:02,124   Average segmentation loss on validation set: 0.1690
2021-11-30 14:50:03,475 iteration 5780 : loss : 0.006945, loss_ce: 0.004998
 85%|████████████████████████▋    | 340/400 [2:22:42<26:48, 26.81s/it]2021-11-30 14:50:04,901 iteration 5781 : loss : 0.007705, loss_ce: 0.005420
2021-11-30 14:50:06,259 iteration 5782 : loss : 0.007795, loss_ce: 0.005558
2021-11-30 14:50:07,614 iteration 5783 : loss : 0.007383, loss_ce: 0.005059
2021-11-30 14:50:08,970 iteration 5784 : loss : 0.007985, loss_ce: 0.004975
2021-11-30 14:50:10,322 iteration 5785 : loss : 0.007690, loss_ce: 0.005134
2021-11-30 14:50:11,677 iteration 5786 : loss : 0.008342, loss_ce: 0.005748
2021-11-30 14:50:13,040 iteration 5787 : loss : 0.006776, loss_ce: 0.004799
2021-11-30 14:50:14,395 iteration 5788 : loss : 0.008013, loss_ce: 0.004939
2021-11-30 14:50:15,752 iteration 5789 : loss : 0.006950, loss_ce: 0.004768
2021-11-30 14:50:17,102 iteration 5790 : loss : 0.008963, loss_ce: 0.005980
2021-11-30 14:50:18,460 iteration 5791 : loss : 0.006975, loss_ce: 0.005023
2021-11-30 14:50:19,820 iteration 5792 : loss : 0.007253, loss_ce: 0.005492
2021-11-30 14:50:21,174 iteration 5793 : loss : 0.006346, loss_ce: 0.004715
2021-11-30 14:50:22,534 iteration 5794 : loss : 0.007326, loss_ce: 0.004894
2021-11-30 14:50:23,894 iteration 5795 : loss : 0.007246, loss_ce: 0.005150
2021-11-30 14:50:25,249 iteration 5796 : loss : 0.006409, loss_ce: 0.004632
2021-11-30 14:50:26,607 iteration 5797 : loss : 0.007265, loss_ce: 0.004808
 85%|████████████████████████▋    | 341/400 [2:23:05<25:16, 25.71s/it]2021-11-30 14:50:28,027 iteration 5798 : loss : 0.007238, loss_ce: 0.004923
2021-11-30 14:50:29,385 iteration 5799 : loss : 0.007041, loss_ce: 0.004963
2021-11-30 14:50:30,742 iteration 5800 : loss : 0.008098, loss_ce: 0.004965
2021-11-30 14:50:32,099 iteration 5801 : loss : 0.007613, loss_ce: 0.004616
2021-11-30 14:50:33,459 iteration 5802 : loss : 0.006153, loss_ce: 0.004547
2021-11-30 14:50:34,817 iteration 5803 : loss : 0.008130, loss_ce: 0.005915
2021-11-30 14:50:36,174 iteration 5804 : loss : 0.006395, loss_ce: 0.004818
2021-11-30 14:50:37,532 iteration 5805 : loss : 0.007014, loss_ce: 0.004735
2021-11-30 14:50:38,895 iteration 5806 : loss : 0.007444, loss_ce: 0.004713
2021-11-30 14:50:40,247 iteration 5807 : loss : 0.007072, loss_ce: 0.005062
2021-11-30 14:50:41,611 iteration 5808 : loss : 0.006739, loss_ce: 0.005123
2021-11-30 14:50:42,971 iteration 5809 : loss : 0.008749, loss_ce: 0.005356
2021-11-30 14:50:44,325 iteration 5810 : loss : 0.007968, loss_ce: 0.005483
2021-11-30 14:50:45,679 iteration 5811 : loss : 0.007935, loss_ce: 0.005704
2021-11-30 14:50:47,036 iteration 5812 : loss : 0.009385, loss_ce: 0.005724
2021-11-30 14:50:48,396 iteration 5813 : loss : 0.007904, loss_ce: 0.005375
2021-11-30 14:50:49,757 iteration 5814 : loss : 0.006570, loss_ce: 0.004983
 86%|████████████████████████▊    | 342/400 [2:23:28<24:06, 24.94s/it]2021-11-30 14:50:51,176 iteration 5815 : loss : 0.009421, loss_ce: 0.005281
2021-11-30 14:50:52,539 iteration 5816 : loss : 0.008510, loss_ce: 0.005036
2021-11-30 14:50:53,895 iteration 5817 : loss : 0.010023, loss_ce: 0.006855
2021-11-30 14:50:55,255 iteration 5818 : loss : 0.007417, loss_ce: 0.005065
2021-11-30 14:50:56,607 iteration 5819 : loss : 0.007349, loss_ce: 0.005274
2021-11-30 14:50:57,962 iteration 5820 : loss : 0.008315, loss_ce: 0.005122
2021-11-30 14:50:59,319 iteration 5821 : loss : 0.009414, loss_ce: 0.005894
2021-11-30 14:51:00,670 iteration 5822 : loss : 0.007888, loss_ce: 0.004816
2021-11-30 14:51:02,026 iteration 5823 : loss : 0.007993, loss_ce: 0.005000
2021-11-30 14:51:03,378 iteration 5824 : loss : 0.007610, loss_ce: 0.005237
2021-11-30 14:51:04,732 iteration 5825 : loss : 0.006455, loss_ce: 0.004685
2021-11-30 14:51:06,086 iteration 5826 : loss : 0.008444, loss_ce: 0.004813
2021-11-30 14:51:07,444 iteration 5827 : loss : 0.009948, loss_ce: 0.005169
2021-11-30 14:51:08,790 iteration 5828 : loss : 0.008073, loss_ce: 0.005382
2021-11-30 14:51:10,140 iteration 5829 : loss : 0.007722, loss_ce: 0.005732
2021-11-30 14:51:11,495 iteration 5830 : loss : 0.007756, loss_ce: 0.006306
2021-11-30 14:51:12,838 iteration 5831 : loss : 0.007774, loss_ce: 0.005663
 86%|████████████████████████▊    | 343/400 [2:23:51<23:09, 24.38s/it]2021-11-30 14:51:14,253 iteration 5832 : loss : 0.007623, loss_ce: 0.005392
2021-11-30 14:51:15,614 iteration 5833 : loss : 0.014348, loss_ce: 0.006486
2021-11-30 14:51:16,968 iteration 5834 : loss : 0.009459, loss_ce: 0.005576
2021-11-30 14:51:18,326 iteration 5835 : loss : 0.010347, loss_ce: 0.005048
2021-11-30 14:51:19,684 iteration 5836 : loss : 0.006384, loss_ce: 0.004635
2021-11-30 14:51:21,042 iteration 5837 : loss : 0.009119, loss_ce: 0.006018
2021-11-30 14:51:22,394 iteration 5838 : loss : 0.007836, loss_ce: 0.005172
2021-11-30 14:51:23,755 iteration 5839 : loss : 0.007427, loss_ce: 0.005019
2021-11-30 14:51:25,115 iteration 5840 : loss : 0.008614, loss_ce: 0.005904
2021-11-30 14:51:26,475 iteration 5841 : loss : 0.012005, loss_ce: 0.009402
2021-11-30 14:51:27,831 iteration 5842 : loss : 0.008514, loss_ce: 0.004910
2021-11-30 14:51:29,190 iteration 5843 : loss : 0.006967, loss_ce: 0.004970
2021-11-30 14:51:30,547 iteration 5844 : loss : 0.007437, loss_ce: 0.005315
2021-11-30 14:51:31,902 iteration 5845 : loss : 0.007501, loss_ce: 0.004938
2021-11-30 14:51:33,266 iteration 5846 : loss : 0.007059, loss_ce: 0.004911
2021-11-30 14:51:34,621 iteration 5847 : loss : 0.007011, loss_ce: 0.004701
2021-11-30 14:51:35,973 iteration 5848 : loss : 0.006996, loss_ce: 0.005008
 86%|████████████████████████▉    | 344/400 [2:24:14<22:24, 24.01s/it]2021-11-30 14:51:37,392 iteration 5849 : loss : 0.007052, loss_ce: 0.005151
2021-11-30 14:51:38,747 iteration 5850 : loss : 0.007480, loss_ce: 0.005431
2021-11-30 14:51:40,107 iteration 5851 : loss : 0.013706, loss_ce: 0.006140
2021-11-30 14:51:41,461 iteration 5852 : loss : 0.007821, loss_ce: 0.005093
2021-11-30 14:51:42,816 iteration 5853 : loss : 0.007861, loss_ce: 0.004761
2021-11-30 14:51:44,177 iteration 5854 : loss : 0.007559, loss_ce: 0.004784
2021-11-30 14:51:45,534 iteration 5855 : loss : 0.006649, loss_ce: 0.004996
2021-11-30 14:51:46,893 iteration 5856 : loss : 0.008760, loss_ce: 0.006104
2021-11-30 14:51:48,245 iteration 5857 : loss : 0.008476, loss_ce: 0.005700
2021-11-30 14:51:49,594 iteration 5858 : loss : 0.008298, loss_ce: 0.005572
2021-11-30 14:51:50,961 iteration 5859 : loss : 0.010710, loss_ce: 0.004925
2021-11-30 14:51:52,315 iteration 5860 : loss : 0.007249, loss_ce: 0.005244
2021-11-30 14:51:53,660 iteration 5861 : loss : 0.009303, loss_ce: 0.006350
2021-11-30 14:51:55,011 iteration 5862 : loss : 0.007443, loss_ce: 0.005280
2021-11-30 14:51:56,378 iteration 5863 : loss : 0.008362, loss_ce: 0.005878
2021-11-30 14:51:57,735 iteration 5864 : loss : 0.006794, loss_ce: 0.004557
2021-11-30 14:51:57,736 Training Data Eval:
2021-11-30 14:52:05,434   Average segmentation loss on training set: 0.0067
2021-11-30 14:52:05,435 Validation Data Eval:
2021-11-30 14:52:08,092   Average segmentation loss on validation set: 0.1894
2021-11-30 14:52:09,453 iteration 5865 : loss : 0.006947, loss_ce: 0.004739
 86%|█████████████████████████    | 345/400 [2:24:48<24:36, 26.85s/it]2021-11-30 14:52:10,887 iteration 5866 : loss : 0.007409, loss_ce: 0.004614
2021-11-30 14:52:12,247 iteration 5867 : loss : 0.006817, loss_ce: 0.005081
2021-11-30 14:52:13,605 iteration 5868 : loss : 0.007815, loss_ce: 0.005263
2021-11-30 14:52:14,963 iteration 5869 : loss : 0.012624, loss_ce: 0.006817
2021-11-30 14:52:16,323 iteration 5870 : loss : 0.006291, loss_ce: 0.004468
2021-11-30 14:52:17,679 iteration 5871 : loss : 0.006392, loss_ce: 0.004650
2021-11-30 14:52:19,042 iteration 5872 : loss : 0.008650, loss_ce: 0.005493
2021-11-30 14:52:20,401 iteration 5873 : loss : 0.007799, loss_ce: 0.005701
2021-11-30 14:52:21,762 iteration 5874 : loss : 0.006462, loss_ce: 0.004663
2021-11-30 14:52:23,117 iteration 5875 : loss : 0.009300, loss_ce: 0.005301
2021-11-30 14:52:24,469 iteration 5876 : loss : 0.006983, loss_ce: 0.004794
2021-11-30 14:52:25,823 iteration 5877 : loss : 0.008538, loss_ce: 0.005946
2021-11-30 14:52:27,182 iteration 5878 : loss : 0.008034, loss_ce: 0.005829
2021-11-30 14:52:28,537 iteration 5879 : loss : 0.006450, loss_ce: 0.004736
2021-11-30 14:52:29,896 iteration 5880 : loss : 0.009598, loss_ce: 0.005174
2021-11-30 14:52:31,251 iteration 5881 : loss : 0.007685, loss_ce: 0.004676
2021-11-30 14:52:32,601 iteration 5882 : loss : 0.008527, loss_ce: 0.005852
 86%|█████████████████████████    | 346/400 [2:25:11<23:09, 25.74s/it]2021-11-30 14:52:34,020 iteration 5883 : loss : 0.007403, loss_ce: 0.004702
2021-11-30 14:52:35,378 iteration 5884 : loss : 0.006695, loss_ce: 0.004925
2021-11-30 14:52:36,734 iteration 5885 : loss : 0.007826, loss_ce: 0.004855
2021-11-30 14:52:38,093 iteration 5886 : loss : 0.007161, loss_ce: 0.005272
2021-11-30 14:52:39,446 iteration 5887 : loss : 0.007593, loss_ce: 0.004817
2021-11-30 14:52:40,798 iteration 5888 : loss : 0.006774, loss_ce: 0.005037
2021-11-30 14:52:42,159 iteration 5889 : loss : 0.007179, loss_ce: 0.005102
2021-11-30 14:52:43,513 iteration 5890 : loss : 0.010035, loss_ce: 0.006141
2021-11-30 14:52:44,862 iteration 5891 : loss : 0.014625, loss_ce: 0.007027
2021-11-30 14:52:46,209 iteration 5892 : loss : 0.008617, loss_ce: 0.005843
2021-11-30 14:52:47,570 iteration 5893 : loss : 0.008251, loss_ce: 0.005620
2021-11-30 14:52:48,925 iteration 5894 : loss : 0.007255, loss_ce: 0.004943
2021-11-30 14:52:50,279 iteration 5895 : loss : 0.008546, loss_ce: 0.005187
2021-11-30 14:52:51,636 iteration 5896 : loss : 0.007653, loss_ce: 0.005259
2021-11-30 14:52:52,993 iteration 5897 : loss : 0.008042, loss_ce: 0.005632
2021-11-30 14:52:54,344 iteration 5898 : loss : 0.007058, loss_ce: 0.005132
2021-11-30 14:52:55,701 iteration 5899 : loss : 0.009869, loss_ce: 0.005729
 87%|█████████████████████████▏   | 347/400 [2:25:34<22:02, 24.95s/it]2021-11-30 14:52:57,113 iteration 5900 : loss : 0.007847, loss_ce: 0.004788
2021-11-30 14:52:58,458 iteration 5901 : loss : 0.007181, loss_ce: 0.005345
2021-11-30 14:52:59,806 iteration 5902 : loss : 0.007415, loss_ce: 0.004630
2021-11-30 14:53:01,160 iteration 5903 : loss : 0.006701, loss_ce: 0.004725
2021-11-30 14:53:02,502 iteration 5904 : loss : 0.008836, loss_ce: 0.005450
2021-11-30 14:53:03,855 iteration 5905 : loss : 0.006736, loss_ce: 0.004787
2021-11-30 14:53:05,195 iteration 5906 : loss : 0.007793, loss_ce: 0.005035
2021-11-30 14:53:06,548 iteration 5907 : loss : 0.010645, loss_ce: 0.005831
2021-11-30 14:53:07,888 iteration 5908 : loss : 0.010588, loss_ce: 0.005409
2021-11-30 14:53:09,241 iteration 5909 : loss : 0.008165, loss_ce: 0.004840
2021-11-30 14:53:10,587 iteration 5910 : loss : 0.012332, loss_ce: 0.008819
2021-11-30 14:53:11,936 iteration 5911 : loss : 0.007611, loss_ce: 0.005162
2021-11-30 14:53:13,293 iteration 5912 : loss : 0.006192, loss_ce: 0.004636
2021-11-30 14:53:14,640 iteration 5913 : loss : 0.006221, loss_ce: 0.004527
2021-11-30 14:53:15,997 iteration 5914 : loss : 0.010275, loss_ce: 0.006980
2021-11-30 14:53:17,352 iteration 5915 : loss : 0.009843, loss_ce: 0.007312
2021-11-30 14:53:18,698 iteration 5916 : loss : 0.008946, loss_ce: 0.006266
 87%|█████████████████████████▏   | 348/400 [2:25:57<21:06, 24.36s/it]2021-11-30 14:53:20,110 iteration 5917 : loss : 0.009092, loss_ce: 0.006496
2021-11-30 14:53:21,461 iteration 5918 : loss : 0.007928, loss_ce: 0.005475
2021-11-30 14:53:22,809 iteration 5919 : loss : 0.007475, loss_ce: 0.005006
2021-11-30 14:53:24,153 iteration 5920 : loss : 0.006832, loss_ce: 0.004869
2021-11-30 14:53:25,489 iteration 5921 : loss : 0.008357, loss_ce: 0.005987
2021-11-30 14:53:26,838 iteration 5922 : loss : 0.007196, loss_ce: 0.004592
2021-11-30 14:53:28,189 iteration 5923 : loss : 0.006608, loss_ce: 0.004803
2021-11-30 14:53:29,543 iteration 5924 : loss : 0.007097, loss_ce: 0.005347
2021-11-30 14:53:30,902 iteration 5925 : loss : 0.006658, loss_ce: 0.004668
2021-11-30 14:53:32,254 iteration 5926 : loss : 0.008007, loss_ce: 0.005045
2021-11-30 14:53:33,605 iteration 5927 : loss : 0.007829, loss_ce: 0.004856
2021-11-30 14:53:34,963 iteration 5928 : loss : 0.007465, loss_ce: 0.004771
2021-11-30 14:53:36,322 iteration 5929 : loss : 0.006808, loss_ce: 0.004925
2021-11-30 14:53:37,681 iteration 5930 : loss : 0.007264, loss_ce: 0.005217
2021-11-30 14:53:39,027 iteration 5931 : loss : 0.008979, loss_ce: 0.005091
2021-11-30 14:53:40,369 iteration 5932 : loss : 0.007245, loss_ce: 0.005003
2021-11-30 14:53:41,726 iteration 5933 : loss : 0.006590, loss_ce: 0.004565
 87%|█████████████████████████▎   | 349/400 [2:26:20<20:22, 23.96s/it]2021-11-30 14:53:43,140 iteration 5934 : loss : 0.008583, loss_ce: 0.005768
2021-11-30 14:53:44,497 iteration 5935 : loss : 0.006686, loss_ce: 0.004882
2021-11-30 14:53:45,857 iteration 5936 : loss : 0.007033, loss_ce: 0.005035
2021-11-30 14:53:47,211 iteration 5937 : loss : 0.007029, loss_ce: 0.004497
2021-11-30 14:53:48,552 iteration 5938 : loss : 0.007647, loss_ce: 0.005077
2021-11-30 14:53:49,907 iteration 5939 : loss : 0.007830, loss_ce: 0.005767
2021-11-30 14:53:51,252 iteration 5940 : loss : 0.006314, loss_ce: 0.004711
2021-11-30 14:53:52,607 iteration 5941 : loss : 0.008844, loss_ce: 0.006286
2021-11-30 14:53:53,951 iteration 5942 : loss : 0.007568, loss_ce: 0.005232
2021-11-30 14:53:55,297 iteration 5943 : loss : 0.007114, loss_ce: 0.005136
2021-11-30 14:53:56,647 iteration 5944 : loss : 0.009169, loss_ce: 0.005365
2021-11-30 14:53:57,997 iteration 5945 : loss : 0.007782, loss_ce: 0.004758
2021-11-30 14:53:59,350 iteration 5946 : loss : 0.006896, loss_ce: 0.005034
2021-11-30 14:54:00,688 iteration 5947 : loss : 0.017692, loss_ce: 0.009438
2021-11-30 14:54:02,032 iteration 5948 : loss : 0.008679, loss_ce: 0.005513
2021-11-30 14:54:03,379 iteration 5949 : loss : 0.008375, loss_ce: 0.005164
2021-11-30 14:54:03,380 Training Data Eval:
2021-11-30 14:54:10,982   Average segmentation loss on training set: 0.0065
2021-11-30 14:54:10,983 Validation Data Eval:
2021-11-30 14:54:13,611   Average segmentation loss on validation set: 0.1735
2021-11-30 14:54:14,951 iteration 5950 : loss : 0.007250, loss_ce: 0.004981
 88%|█████████████████████████▍   | 350/400 [2:26:53<22:17, 26.74s/it]2021-11-30 14:54:16,369 iteration 5951 : loss : 0.008481, loss_ce: 0.004968
2021-11-30 14:54:17,734 iteration 5952 : loss : 0.009442, loss_ce: 0.006346
2021-11-30 14:54:19,074 iteration 5953 : loss : 0.007686, loss_ce: 0.004842
2021-11-30 14:54:20,435 iteration 5954 : loss : 0.008455, loss_ce: 0.005763
2021-11-30 14:54:21,792 iteration 5955 : loss : 0.008555, loss_ce: 0.006489
2021-11-30 14:54:23,155 iteration 5956 : loss : 0.006675, loss_ce: 0.004915
2021-11-30 14:54:24,505 iteration 5957 : loss : 0.009329, loss_ce: 0.005883
2021-11-30 14:54:25,860 iteration 5958 : loss : 0.006382, loss_ce: 0.004792
2021-11-30 14:54:27,225 iteration 5959 : loss : 0.006991, loss_ce: 0.005082
2021-11-30 14:54:28,576 iteration 5960 : loss : 0.006091, loss_ce: 0.004844
2021-11-30 14:54:29,909 iteration 5961 : loss : 0.009030, loss_ce: 0.004751
2021-11-30 14:54:31,247 iteration 5962 : loss : 0.008112, loss_ce: 0.005569
2021-11-30 14:54:32,596 iteration 5963 : loss : 0.007728, loss_ce: 0.004749
2021-11-30 14:54:33,950 iteration 5964 : loss : 0.008515, loss_ce: 0.005340
2021-11-30 14:54:35,302 iteration 5965 : loss : 0.006375, loss_ce: 0.004697
2021-11-30 14:54:36,656 iteration 5966 : loss : 0.006759, loss_ce: 0.004555
2021-11-30 14:54:37,992 iteration 5967 : loss : 0.010933, loss_ce: 0.005080
 88%|█████████████████████████▍   | 351/400 [2:27:16<20:55, 25.63s/it]2021-11-30 14:54:39,395 iteration 5968 : loss : 0.006411, loss_ce: 0.004765
2021-11-30 14:54:40,736 iteration 5969 : loss : 0.008593, loss_ce: 0.005029
2021-11-30 14:54:42,077 iteration 5970 : loss : 0.010702, loss_ce: 0.005973
2021-11-30 14:54:43,430 iteration 5971 : loss : 0.008012, loss_ce: 0.004915
2021-11-30 14:54:44,776 iteration 5972 : loss : 0.008955, loss_ce: 0.005854
2021-11-30 14:54:46,130 iteration 5973 : loss : 0.006488, loss_ce: 0.004564
2021-11-30 14:54:47,482 iteration 5974 : loss : 0.007705, loss_ce: 0.005652
2021-11-30 14:54:48,817 iteration 5975 : loss : 0.008391, loss_ce: 0.005357
2021-11-30 14:54:50,167 iteration 5976 : loss : 0.006885, loss_ce: 0.004732
2021-11-30 14:54:51,526 iteration 5977 : loss : 0.006492, loss_ce: 0.004657
2021-11-30 14:54:52,865 iteration 5978 : loss : 0.006683, loss_ce: 0.004672
2021-11-30 14:54:54,202 iteration 5979 : loss : 0.006420, loss_ce: 0.004662
2021-11-30 14:54:55,546 iteration 5980 : loss : 0.008840, loss_ce: 0.005403
2021-11-30 14:54:56,896 iteration 5981 : loss : 0.007283, loss_ce: 0.005327
2021-11-30 14:54:58,242 iteration 5982 : loss : 0.008422, loss_ce: 0.006093
2021-11-30 14:54:59,591 iteration 5983 : loss : 0.006361, loss_ce: 0.004646
2021-11-30 14:55:00,939 iteration 5984 : loss : 0.006515, loss_ce: 0.004763
 88%|█████████████████████████▌   | 352/400 [2:27:39<19:51, 24.83s/it]2021-11-30 14:55:02,340 iteration 5985 : loss : 0.007129, loss_ce: 0.005264
2021-11-30 14:55:03,676 iteration 5986 : loss : 0.007814, loss_ce: 0.005218
2021-11-30 14:55:05,029 iteration 5987 : loss : 0.008098, loss_ce: 0.005834
2021-11-30 14:55:06,367 iteration 5988 : loss : 0.009255, loss_ce: 0.005544
2021-11-30 14:55:07,707 iteration 5989 : loss : 0.007654, loss_ce: 0.004617
2021-11-30 14:55:09,065 iteration 5990 : loss : 0.007614, loss_ce: 0.005655
2021-11-30 14:55:10,419 iteration 5991 : loss : 0.008228, loss_ce: 0.005796
2021-11-30 14:55:11,763 iteration 5992 : loss : 0.008190, loss_ce: 0.004972
2021-11-30 14:55:13,116 iteration 5993 : loss : 0.007065, loss_ce: 0.005172
2021-11-30 14:55:14,452 iteration 5994 : loss : 0.007030, loss_ce: 0.004560
2021-11-30 14:55:15,787 iteration 5995 : loss : 0.007914, loss_ce: 0.005402
2021-11-30 14:55:17,137 iteration 5996 : loss : 0.008073, loss_ce: 0.005089
2021-11-30 14:55:18,483 iteration 5997 : loss : 0.007463, loss_ce: 0.004969
2021-11-30 14:55:19,837 iteration 5998 : loss : 0.011633, loss_ce: 0.007822
2021-11-30 14:55:21,190 iteration 5999 : loss : 0.006906, loss_ce: 0.004869
2021-11-30 14:55:22,529 iteration 6000 : loss : 0.006237, loss_ce: 0.004537
2021-11-30 14:55:23,876 iteration 6001 : loss : 0.006502, loss_ce: 0.004542
 88%|█████████████████████████▌   | 353/400 [2:28:02<19:00, 24.26s/it]2021-11-30 14:55:25,285 iteration 6002 : loss : 0.008521, loss_ce: 0.005863
2021-11-30 14:55:26,640 iteration 6003 : loss : 0.008335, loss_ce: 0.005061
2021-11-30 14:55:28,000 iteration 6004 : loss : 0.007636, loss_ce: 0.005124
2021-11-30 14:55:29,347 iteration 6005 : loss : 0.007630, loss_ce: 0.005195
2021-11-30 14:55:30,702 iteration 6006 : loss : 0.008069, loss_ce: 0.004913
2021-11-30 14:55:32,049 iteration 6007 : loss : 0.006436, loss_ce: 0.004574
2021-11-30 14:55:33,397 iteration 6008 : loss : 0.007196, loss_ce: 0.004845
2021-11-30 14:55:34,756 iteration 6009 : loss : 0.006454, loss_ce: 0.004507
2021-11-30 14:55:36,118 iteration 6010 : loss : 0.008290, loss_ce: 0.006146
2021-11-30 14:55:37,473 iteration 6011 : loss : 0.007880, loss_ce: 0.005110
2021-11-30 14:55:38,828 iteration 6012 : loss : 0.006711, loss_ce: 0.004933
2021-11-30 14:55:40,174 iteration 6013 : loss : 0.007369, loss_ce: 0.005496
2021-11-30 14:55:41,525 iteration 6014 : loss : 0.007728, loss_ce: 0.004849
2021-11-30 14:55:42,867 iteration 6015 : loss : 0.007482, loss_ce: 0.005156
2021-11-30 14:55:44,223 iteration 6016 : loss : 0.006066, loss_ce: 0.004406
2021-11-30 14:55:45,580 iteration 6017 : loss : 0.007876, loss_ce: 0.004764
2021-11-30 14:55:46,929 iteration 6018 : loss : 0.010112, loss_ce: 0.007063
 88%|█████████████████████████▋   | 354/400 [2:28:25<18:19, 23.90s/it]2021-11-30 14:55:48,335 iteration 6019 : loss : 0.009576, loss_ce: 0.006347
2021-11-30 14:55:49,685 iteration 6020 : loss : 0.008351, loss_ce: 0.004708
2021-11-30 14:55:51,035 iteration 6021 : loss : 0.006685, loss_ce: 0.004812
2021-11-30 14:55:52,376 iteration 6022 : loss : 0.008822, loss_ce: 0.005289
2021-11-30 14:55:53,721 iteration 6023 : loss : 0.006902, loss_ce: 0.004844
2021-11-30 14:55:55,080 iteration 6024 : loss : 0.010031, loss_ce: 0.006841
2021-11-30 14:55:56,426 iteration 6025 : loss : 0.006042, loss_ce: 0.004409
2021-11-30 14:55:57,786 iteration 6026 : loss : 0.007937, loss_ce: 0.005870
2021-11-30 14:55:59,142 iteration 6027 : loss : 0.007053, loss_ce: 0.005272
2021-11-30 14:56:00,485 iteration 6028 : loss : 0.006921, loss_ce: 0.004625
2021-11-30 14:56:01,839 iteration 6029 : loss : 0.007546, loss_ce: 0.005060
2021-11-30 14:56:03,192 iteration 6030 : loss : 0.007287, loss_ce: 0.004966
2021-11-30 14:56:04,536 iteration 6031 : loss : 0.006920, loss_ce: 0.004654
2021-11-30 14:56:05,880 iteration 6032 : loss : 0.007692, loss_ce: 0.005288
2021-11-30 14:56:07,231 iteration 6033 : loss : 0.006536, loss_ce: 0.004519
2021-11-30 14:56:08,587 iteration 6034 : loss : 0.007249, loss_ce: 0.004857
2021-11-30 14:56:08,587 Training Data Eval:
2021-11-30 14:56:16,241   Average segmentation loss on training set: 0.0064
2021-11-30 14:56:16,241 Validation Data Eval:
2021-11-30 14:56:18,898   Average segmentation loss on validation set: 0.1754
2021-11-30 14:56:20,253 iteration 6035 : loss : 0.008086, loss_ce: 0.005012
 89%|█████████████████████████▋   | 355/400 [2:28:58<20:02, 26.73s/it]2021-11-30 14:56:21,686 iteration 6036 : loss : 0.008524, loss_ce: 0.005269
2021-11-30 14:56:23,048 iteration 6037 : loss : 0.006744, loss_ce: 0.004687
2021-11-30 14:56:24,406 iteration 6038 : loss : 0.008176, loss_ce: 0.005196
2021-11-30 14:56:25,777 iteration 6039 : loss : 0.009895, loss_ce: 0.005549
2021-11-30 14:56:27,134 iteration 6040 : loss : 0.006704, loss_ce: 0.004970
2021-11-30 14:56:28,486 iteration 6041 : loss : 0.007947, loss_ce: 0.005480
2021-11-30 14:56:29,833 iteration 6042 : loss : 0.008304, loss_ce: 0.005955
2021-11-30 14:56:31,190 iteration 6043 : loss : 0.007468, loss_ce: 0.005230
2021-11-30 14:56:32,549 iteration 6044 : loss : 0.007503, loss_ce: 0.004993
2021-11-30 14:56:33,891 iteration 6045 : loss : 0.009089, loss_ce: 0.005457
2021-11-30 14:56:35,235 iteration 6046 : loss : 0.009058, loss_ce: 0.004695
2021-11-30 14:56:36,586 iteration 6047 : loss : 0.007639, loss_ce: 0.005022
2021-11-30 14:56:37,942 iteration 6048 : loss : 0.008714, loss_ce: 0.006539
2021-11-30 14:56:39,302 iteration 6049 : loss : 0.008009, loss_ce: 0.005057
2021-11-30 14:56:40,646 iteration 6050 : loss : 0.007488, loss_ce: 0.004609
2021-11-30 14:56:42,002 iteration 6051 : loss : 0.007741, loss_ce: 0.005151
2021-11-30 14:56:43,352 iteration 6052 : loss : 0.008767, loss_ce: 0.005206
 89%|█████████████████████████▊   | 356/400 [2:29:21<18:48, 25.64s/it]2021-11-30 14:56:44,756 iteration 6053 : loss : 0.006996, loss_ce: 0.004885
2021-11-30 14:56:46,107 iteration 6054 : loss : 0.008979, loss_ce: 0.006730
2021-11-30 14:56:47,462 iteration 6055 : loss : 0.006777, loss_ce: 0.004938
2021-11-30 14:56:48,811 iteration 6056 : loss : 0.008293, loss_ce: 0.005468
2021-11-30 14:56:50,160 iteration 6057 : loss : 0.008753, loss_ce: 0.004976
2021-11-30 14:56:51,504 iteration 6058 : loss : 0.008864, loss_ce: 0.005813
2021-11-30 14:56:52,844 iteration 6059 : loss : 0.006915, loss_ce: 0.005252
2021-11-30 14:56:54,190 iteration 6060 : loss : 0.006572, loss_ce: 0.004683
2021-11-30 14:56:55,546 iteration 6061 : loss : 0.008372, loss_ce: 0.004676
2021-11-30 14:56:56,898 iteration 6062 : loss : 0.006228, loss_ce: 0.004367
2021-11-30 14:56:58,249 iteration 6063 : loss : 0.007168, loss_ce: 0.004824
2021-11-30 14:56:59,608 iteration 6064 : loss : 0.007213, loss_ce: 0.004748
2021-11-30 14:57:00,958 iteration 6065 : loss : 0.007807, loss_ce: 0.005456
2021-11-30 14:57:02,308 iteration 6066 : loss : 0.006738, loss_ce: 0.004782
2021-11-30 14:57:03,667 iteration 6067 : loss : 0.007896, loss_ce: 0.006089
2021-11-30 14:57:05,019 iteration 6068 : loss : 0.007867, loss_ce: 0.005073
2021-11-30 14:57:06,373 iteration 6069 : loss : 0.008533, loss_ce: 0.005174
 89%|█████████████████████████▉   | 357/400 [2:29:44<17:48, 24.85s/it]2021-11-30 14:57:07,779 iteration 6070 : loss : 0.007285, loss_ce: 0.005287
2021-11-30 14:57:09,116 iteration 6071 : loss : 0.010423, loss_ce: 0.006088
2021-11-30 14:57:10,471 iteration 6072 : loss : 0.006712, loss_ce: 0.005010
2021-11-30 14:57:11,820 iteration 6073 : loss : 0.006855, loss_ce: 0.004864
2021-11-30 14:57:13,176 iteration 6074 : loss : 0.006756, loss_ce: 0.005199
2021-11-30 14:57:14,533 iteration 6075 : loss : 0.008128, loss_ce: 0.004736
2021-11-30 14:57:15,885 iteration 6076 : loss : 0.006850, loss_ce: 0.004852
2021-11-30 14:57:17,244 iteration 6077 : loss : 0.007459, loss_ce: 0.005187
2021-11-30 14:57:18,604 iteration 6078 : loss : 0.008241, loss_ce: 0.005545
2021-11-30 14:57:19,966 iteration 6079 : loss : 0.008743, loss_ce: 0.005671
2021-11-30 14:57:21,325 iteration 6080 : loss : 0.008037, loss_ce: 0.005300
2021-11-30 14:57:22,677 iteration 6081 : loss : 0.006427, loss_ce: 0.004553
2021-11-30 14:57:24,024 iteration 6082 : loss : 0.007480, loss_ce: 0.005451
2021-11-30 14:57:25,387 iteration 6083 : loss : 0.006689, loss_ce: 0.004818
2021-11-30 14:57:26,741 iteration 6084 : loss : 0.008434, loss_ce: 0.005800
2021-11-30 14:57:28,091 iteration 6085 : loss : 0.006587, loss_ce: 0.004290
2021-11-30 14:57:29,440 iteration 6086 : loss : 0.007103, loss_ce: 0.004830
 90%|█████████████████████████▉   | 358/400 [2:30:08<17:01, 24.32s/it]2021-11-30 14:57:30,857 iteration 6087 : loss : 0.007650, loss_ce: 0.005481
2021-11-30 14:57:32,204 iteration 6088 : loss : 0.007458, loss_ce: 0.004981
2021-11-30 14:57:33,562 iteration 6089 : loss : 0.006696, loss_ce: 0.004655
2021-11-30 14:57:34,917 iteration 6090 : loss : 0.006659, loss_ce: 0.004806
2021-11-30 14:57:36,272 iteration 6091 : loss : 0.007137, loss_ce: 0.004971
2021-11-30 14:57:37,623 iteration 6092 : loss : 0.007036, loss_ce: 0.005220
2021-11-30 14:57:38,977 iteration 6093 : loss : 0.007777, loss_ce: 0.005363
2021-11-30 14:57:40,338 iteration 6094 : loss : 0.006621, loss_ce: 0.004539
2021-11-30 14:57:41,691 iteration 6095 : loss : 0.007085, loss_ce: 0.004619
2021-11-30 14:57:43,033 iteration 6096 : loss : 0.008273, loss_ce: 0.004971
2021-11-30 14:57:44,387 iteration 6097 : loss : 0.007394, loss_ce: 0.005172
2021-11-30 14:57:45,736 iteration 6098 : loss : 0.007599, loss_ce: 0.005402
2021-11-30 14:57:47,103 iteration 6099 : loss : 0.007722, loss_ce: 0.004905
2021-11-30 14:57:48,454 iteration 6100 : loss : 0.006653, loss_ce: 0.004445
2021-11-30 14:57:49,802 iteration 6101 : loss : 0.009106, loss_ce: 0.006261
2021-11-30 14:57:51,156 iteration 6102 : loss : 0.007402, loss_ce: 0.005042
2021-11-30 14:57:52,505 iteration 6103 : loss : 0.006095, loss_ce: 0.004340
 90%|██████████████████████████   | 359/400 [2:30:31<16:21, 23.94s/it]2021-11-30 14:57:53,930 iteration 6104 : loss : 0.006682, loss_ce: 0.004732
2021-11-30 14:57:55,284 iteration 6105 : loss : 0.008544, loss_ce: 0.004888
2021-11-30 14:57:56,623 iteration 6106 : loss : 0.010403, loss_ce: 0.006673
2021-11-30 14:57:57,983 iteration 6107 : loss : 0.008970, loss_ce: 0.005017
2021-11-30 14:57:59,331 iteration 6108 : loss : 0.007280, loss_ce: 0.005048
2021-11-30 14:58:00,676 iteration 6109 : loss : 0.009295, loss_ce: 0.005207
2021-11-30 14:58:02,025 iteration 6110 : loss : 0.006923, loss_ce: 0.005162
2021-11-30 14:58:03,375 iteration 6111 : loss : 0.009139, loss_ce: 0.005918
2021-11-30 14:58:04,736 iteration 6112 : loss : 0.008437, loss_ce: 0.006206
2021-11-30 14:58:06,091 iteration 6113 : loss : 0.006988, loss_ce: 0.004723
2021-11-30 14:58:07,441 iteration 6114 : loss : 0.006598, loss_ce: 0.004803
2021-11-30 14:58:08,798 iteration 6115 : loss : 0.008338, loss_ce: 0.005578
2021-11-30 14:58:10,159 iteration 6116 : loss : 0.007411, loss_ce: 0.004683
2021-11-30 14:58:11,517 iteration 6117 : loss : 0.007351, loss_ce: 0.004765
2021-11-30 14:58:12,873 iteration 6118 : loss : 0.007014, loss_ce: 0.005005
2021-11-30 14:58:14,233 iteration 6119 : loss : 0.009498, loss_ce: 0.006502
2021-11-30 14:58:14,233 Training Data Eval:
2021-11-30 14:58:21,849   Average segmentation loss on training set: 0.0064
2021-11-30 14:58:21,850 Validation Data Eval:
2021-11-30 14:58:24,477   Average segmentation loss on validation set: 0.1773
2021-11-30 14:58:25,827 iteration 6120 : loss : 0.009047, loss_ce: 0.006298
 90%|██████████████████████████   | 360/400 [2:31:04<17:50, 26.76s/it]2021-11-30 14:58:27,246 iteration 6121 : loss : 0.006503, loss_ce: 0.004617
2021-11-30 14:58:28,590 iteration 6122 : loss : 0.007870, loss_ce: 0.005253
2021-11-30 14:58:29,944 iteration 6123 : loss : 0.007073, loss_ce: 0.005045
2021-11-30 14:58:31,301 iteration 6124 : loss : 0.007817, loss_ce: 0.004773
2021-11-30 14:58:32,661 iteration 6125 : loss : 0.006947, loss_ce: 0.005432
2021-11-30 14:58:34,017 iteration 6126 : loss : 0.009646, loss_ce: 0.006433
2021-11-30 14:58:35,375 iteration 6127 : loss : 0.007169, loss_ce: 0.005140
2021-11-30 14:58:36,738 iteration 6128 : loss : 0.006803, loss_ce: 0.004518
2021-11-30 14:58:38,099 iteration 6129 : loss : 0.013819, loss_ce: 0.006488
2021-11-30 14:58:39,464 iteration 6130 : loss : 0.007520, loss_ce: 0.005560
2021-11-30 14:58:40,824 iteration 6131 : loss : 0.008745, loss_ce: 0.005442
2021-11-30 14:58:42,180 iteration 6132 : loss : 0.006640, loss_ce: 0.004758
2021-11-30 14:58:43,533 iteration 6133 : loss : 0.007296, loss_ce: 0.004842
2021-11-30 14:58:44,888 iteration 6134 : loss : 0.006335, loss_ce: 0.004581
2021-11-30 14:58:46,239 iteration 6135 : loss : 0.006552, loss_ce: 0.004441
2021-11-30 14:58:47,601 iteration 6136 : loss : 0.007340, loss_ce: 0.005171
2021-11-30 14:58:48,958 iteration 6137 : loss : 0.007624, loss_ce: 0.005404
 90%|██████████████████████████▏  | 361/400 [2:31:27<16:41, 25.67s/it]2021-11-30 14:58:50,373 iteration 6138 : loss : 0.006119, loss_ce: 0.004331
2021-11-30 14:58:51,730 iteration 6139 : loss : 0.007398, loss_ce: 0.004960
2021-11-30 14:58:53,082 iteration 6140 : loss : 0.007153, loss_ce: 0.005112
2021-11-30 14:58:54,440 iteration 6141 : loss : 0.007365, loss_ce: 0.005269
2021-11-30 14:58:55,797 iteration 6142 : loss : 0.006391, loss_ce: 0.004737
2021-11-30 14:58:57,155 iteration 6143 : loss : 0.007886, loss_ce: 0.005667
2021-11-30 14:58:58,519 iteration 6144 : loss : 0.006312, loss_ce: 0.004520
2021-11-30 14:58:59,876 iteration 6145 : loss : 0.006349, loss_ce: 0.004714
2021-11-30 14:59:01,231 iteration 6146 : loss : 0.007480, loss_ce: 0.005053
2021-11-30 14:59:02,587 iteration 6147 : loss : 0.007539, loss_ce: 0.005263
2021-11-30 14:59:03,947 iteration 6148 : loss : 0.008671, loss_ce: 0.006302
2021-11-30 14:59:05,302 iteration 6149 : loss : 0.007530, loss_ce: 0.004931
2021-11-30 14:59:06,660 iteration 6150 : loss : 0.008729, loss_ce: 0.006168
2021-11-30 14:59:08,015 iteration 6151 : loss : 0.006604, loss_ce: 0.005076
2021-11-30 14:59:09,370 iteration 6152 : loss : 0.005999, loss_ce: 0.004523
2021-11-30 14:59:10,728 iteration 6153 : loss : 0.007849, loss_ce: 0.004871
2021-11-30 14:59:12,093 iteration 6154 : loss : 0.006617, loss_ce: 0.004812
 90%|██████████████████████████▏  | 362/400 [2:31:50<15:46, 24.91s/it]2021-11-30 14:59:13,526 iteration 6155 : loss : 0.007639, loss_ce: 0.005525
2021-11-30 14:59:14,879 iteration 6156 : loss : 0.007017, loss_ce: 0.005116
2021-11-30 14:59:16,229 iteration 6157 : loss : 0.008419, loss_ce: 0.004726
2021-11-30 14:59:17,583 iteration 6158 : loss : 0.008348, loss_ce: 0.006160
2021-11-30 14:59:18,936 iteration 6159 : loss : 0.010174, loss_ce: 0.005358
2021-11-30 14:59:20,294 iteration 6160 : loss : 0.007651, loss_ce: 0.004689
2021-11-30 14:59:21,651 iteration 6161 : loss : 0.008021, loss_ce: 0.005746
2021-11-30 14:59:23,012 iteration 6162 : loss : 0.007445, loss_ce: 0.004965
2021-11-30 14:59:24,375 iteration 6163 : loss : 0.006804, loss_ce: 0.004975
2021-11-30 14:59:25,731 iteration 6164 : loss : 0.006329, loss_ce: 0.004926
2021-11-30 14:59:27,085 iteration 6165 : loss : 0.007329, loss_ce: 0.004991
2021-11-30 14:59:28,444 iteration 6166 : loss : 0.006403, loss_ce: 0.004668
2021-11-30 14:59:29,804 iteration 6167 : loss : 0.008305, loss_ce: 0.004520
2021-11-30 14:59:31,155 iteration 6168 : loss : 0.007634, loss_ce: 0.005138
2021-11-30 14:59:32,508 iteration 6169 : loss : 0.010399, loss_ce: 0.006658
2021-11-30 14:59:33,849 iteration 6170 : loss : 0.009729, loss_ce: 0.005704
2021-11-30 14:59:35,200 iteration 6171 : loss : 0.010086, loss_ce: 0.005647
 91%|██████████████████████████▎  | 363/400 [2:32:13<15:01, 24.37s/it]2021-11-30 14:59:36,599 iteration 6172 : loss : 0.006730, loss_ce: 0.005269
2021-11-30 14:59:37,953 iteration 6173 : loss : 0.006718, loss_ce: 0.004700
2021-11-30 14:59:39,308 iteration 6174 : loss : 0.007566, loss_ce: 0.004629
2021-11-30 14:59:40,656 iteration 6175 : loss : 0.007952, loss_ce: 0.004893
2021-11-30 14:59:42,010 iteration 6176 : loss : 0.007282, loss_ce: 0.005478
2021-11-30 14:59:43,351 iteration 6177 : loss : 0.007082, loss_ce: 0.005309
2021-11-30 14:59:44,698 iteration 6178 : loss : 0.008662, loss_ce: 0.005504
2021-11-30 14:59:46,044 iteration 6179 : loss : 0.009672, loss_ce: 0.005974
2021-11-30 14:59:47,387 iteration 6180 : loss : 0.006637, loss_ce: 0.004462
2021-11-30 14:59:48,749 iteration 6181 : loss : 0.006996, loss_ce: 0.004521
2021-11-30 14:59:50,098 iteration 6182 : loss : 0.007300, loss_ce: 0.004829
2021-11-30 14:59:51,451 iteration 6183 : loss : 0.007455, loss_ce: 0.005084
2021-11-30 14:59:52,805 iteration 6184 : loss : 0.010494, loss_ce: 0.005700
2021-11-30 14:59:54,154 iteration 6185 : loss : 0.008348, loss_ce: 0.005674
2021-11-30 14:59:55,515 iteration 6186 : loss : 0.010409, loss_ce: 0.005892
2021-11-30 14:59:56,869 iteration 6187 : loss : 0.007817, loss_ce: 0.005674
2021-11-30 14:59:58,220 iteration 6188 : loss : 0.007179, loss_ce: 0.004958
 91%|██████████████████████████▍  | 364/400 [2:32:36<14:22, 23.97s/it]2021-11-30 14:59:59,626 iteration 6189 : loss : 0.007331, loss_ce: 0.004581
2021-11-30 15:00:00,963 iteration 6190 : loss : 0.008768, loss_ce: 0.006064
2021-11-30 15:00:02,315 iteration 6191 : loss : 0.006344, loss_ce: 0.004463
2021-11-30 15:00:03,666 iteration 6192 : loss : 0.006983, loss_ce: 0.005210
2021-11-30 15:00:05,014 iteration 6193 : loss : 0.007354, loss_ce: 0.005128
2021-11-30 15:00:06,371 iteration 6194 : loss : 0.006554, loss_ce: 0.004887
2021-11-30 15:00:07,720 iteration 6195 : loss : 0.007298, loss_ce: 0.004659
2021-11-30 15:00:09,060 iteration 6196 : loss : 0.007031, loss_ce: 0.005007
2021-11-30 15:00:10,405 iteration 6197 : loss : 0.008253, loss_ce: 0.005282
2021-11-30 15:00:11,762 iteration 6198 : loss : 0.007639, loss_ce: 0.005285
2021-11-30 15:00:13,119 iteration 6199 : loss : 0.008218, loss_ce: 0.005840
2021-11-30 15:00:14,472 iteration 6200 : loss : 0.010316, loss_ce: 0.006137
2021-11-30 15:00:15,827 iteration 6201 : loss : 0.006276, loss_ce: 0.004440
2021-11-30 15:00:17,184 iteration 6202 : loss : 0.008137, loss_ce: 0.006099
2021-11-30 15:00:18,532 iteration 6203 : loss : 0.007464, loss_ce: 0.004808
2021-11-30 15:00:19,895 iteration 6204 : loss : 0.007713, loss_ce: 0.005658
2021-11-30 15:00:19,896 Training Data Eval:
2021-11-30 15:00:27,544   Average segmentation loss on training set: 0.0064
2021-11-30 15:00:27,544 Validation Data Eval:
2021-11-30 15:00:30,215   Average segmentation loss on validation set: 0.1769
2021-11-30 15:00:31,572 iteration 6205 : loss : 0.009230, loss_ce: 0.005463
 91%|██████████████████████████▍  | 365/400 [2:33:10<15:37, 26.78s/it]2021-11-30 15:00:32,996 iteration 6206 : loss : 0.006907, loss_ce: 0.005032
2021-11-30 15:00:34,349 iteration 6207 : loss : 0.006299, loss_ce: 0.004769
2021-11-30 15:00:35,711 iteration 6208 : loss : 0.007384, loss_ce: 0.004736
2021-11-30 15:00:37,067 iteration 6209 : loss : 0.008309, loss_ce: 0.005511
2021-11-30 15:00:38,425 iteration 6210 : loss : 0.010620, loss_ce: 0.005650
2021-11-30 15:00:39,781 iteration 6211 : loss : 0.008156, loss_ce: 0.005239
2021-11-30 15:00:41,144 iteration 6212 : loss : 0.007815, loss_ce: 0.005520
2021-11-30 15:00:42,506 iteration 6213 : loss : 0.006842, loss_ce: 0.004559
2021-11-30 15:00:43,862 iteration 6214 : loss : 0.009594, loss_ce: 0.007045
2021-11-30 15:00:45,219 iteration 6215 : loss : 0.009253, loss_ce: 0.005709
2021-11-30 15:00:46,579 iteration 6216 : loss : 0.007404, loss_ce: 0.004693
2021-11-30 15:00:47,935 iteration 6217 : loss : 0.007558, loss_ce: 0.005478
2021-11-30 15:00:49,289 iteration 6218 : loss : 0.007471, loss_ce: 0.005575
2021-11-30 15:00:50,642 iteration 6219 : loss : 0.006778, loss_ce: 0.004493
2021-11-30 15:00:51,992 iteration 6220 : loss : 0.007236, loss_ce: 0.004868
2021-11-30 15:00:53,337 iteration 6221 : loss : 0.006270, loss_ce: 0.004382
2021-11-30 15:00:54,688 iteration 6222 : loss : 0.007218, loss_ce: 0.005134
 92%|██████████████████████████▌  | 366/400 [2:33:33<14:33, 25.68s/it]2021-11-30 15:00:56,094 iteration 6223 : loss : 0.007021, loss_ce: 0.004450
2021-11-30 15:00:57,438 iteration 6224 : loss : 0.006957, loss_ce: 0.004576
2021-11-30 15:00:58,795 iteration 6225 : loss : 0.007994, loss_ce: 0.006220
2021-11-30 15:01:00,151 iteration 6226 : loss : 0.007529, loss_ce: 0.004975
2021-11-30 15:01:01,487 iteration 6227 : loss : 0.006725, loss_ce: 0.004575
2021-11-30 15:01:02,831 iteration 6228 : loss : 0.010239, loss_ce: 0.006674
2021-11-30 15:01:04,168 iteration 6229 : loss : 0.007082, loss_ce: 0.005141
2021-11-30 15:01:05,519 iteration 6230 : loss : 0.008869, loss_ce: 0.006449
2021-11-30 15:01:06,864 iteration 6231 : loss : 0.007716, loss_ce: 0.005403
2021-11-30 15:01:08,214 iteration 6232 : loss : 0.006632, loss_ce: 0.004671
2021-11-30 15:01:09,561 iteration 6233 : loss : 0.007275, loss_ce: 0.004738
2021-11-30 15:01:10,907 iteration 6234 : loss : 0.006728, loss_ce: 0.004721
2021-11-30 15:01:12,254 iteration 6235 : loss : 0.006900, loss_ce: 0.004923
2021-11-30 15:01:13,594 iteration 6236 : loss : 0.006489, loss_ce: 0.004745
2021-11-30 15:01:14,939 iteration 6237 : loss : 0.005804, loss_ce: 0.004332
2021-11-30 15:01:16,280 iteration 6238 : loss : 0.007551, loss_ce: 0.004849
2021-11-30 15:01:17,637 iteration 6239 : loss : 0.008656, loss_ce: 0.006041
 92%|██████████████████████████▌  | 367/400 [2:33:56<13:40, 24.86s/it]2021-11-30 15:01:19,054 iteration 6240 : loss : 0.006262, loss_ce: 0.004535
2021-11-30 15:01:20,394 iteration 6241 : loss : 0.008933, loss_ce: 0.005196
2021-11-30 15:01:21,743 iteration 6242 : loss : 0.007692, loss_ce: 0.004933
2021-11-30 15:01:23,080 iteration 6243 : loss : 0.007320, loss_ce: 0.005583
2021-11-30 15:01:24,430 iteration 6244 : loss : 0.006178, loss_ce: 0.004513
2021-11-30 15:01:25,776 iteration 6245 : loss : 0.007526, loss_ce: 0.004437
2021-11-30 15:01:27,117 iteration 6246 : loss : 0.006797, loss_ce: 0.005214
2021-11-30 15:01:28,476 iteration 6247 : loss : 0.007623, loss_ce: 0.005202
2021-11-30 15:01:29,814 iteration 6248 : loss : 0.006059, loss_ce: 0.004462
2021-11-30 15:01:31,168 iteration 6249 : loss : 0.007567, loss_ce: 0.005138
2021-11-30 15:01:32,508 iteration 6250 : loss : 0.006753, loss_ce: 0.004974
2021-11-30 15:01:33,848 iteration 6251 : loss : 0.006797, loss_ce: 0.004893
2021-11-30 15:01:35,192 iteration 6252 : loss : 0.007372, loss_ce: 0.005235
2021-11-30 15:01:36,527 iteration 6253 : loss : 0.009076, loss_ce: 0.006310
2021-11-30 15:01:37,886 iteration 6254 : loss : 0.008212, loss_ce: 0.004775
2021-11-30 15:01:39,237 iteration 6255 : loss : 0.007940, loss_ce: 0.005880
2021-11-30 15:01:40,593 iteration 6256 : loss : 0.008469, loss_ce: 0.005627
 92%|██████████████████████████▋  | 368/400 [2:34:19<12:57, 24.29s/it]2021-11-30 15:01:41,997 iteration 6257 : loss : 0.006723, loss_ce: 0.005183
2021-11-30 15:01:43,340 iteration 6258 : loss : 0.008960, loss_ce: 0.006370
2021-11-30 15:01:44,695 iteration 6259 : loss : 0.007362, loss_ce: 0.004766
2021-11-30 15:01:46,038 iteration 6260 : loss : 0.008666, loss_ce: 0.005990
2021-11-30 15:01:47,393 iteration 6261 : loss : 0.006674, loss_ce: 0.004602
2021-11-30 15:01:48,735 iteration 6262 : loss : 0.006479, loss_ce: 0.004746
2021-11-30 15:01:50,089 iteration 6263 : loss : 0.006297, loss_ce: 0.004567
2021-11-30 15:01:51,457 iteration 6264 : loss : 0.007235, loss_ce: 0.004804
2021-11-30 15:01:52,806 iteration 6265 : loss : 0.008430, loss_ce: 0.005613
2021-11-30 15:01:54,159 iteration 6266 : loss : 0.008737, loss_ce: 0.005769
2021-11-30 15:01:55,514 iteration 6267 : loss : 0.007427, loss_ce: 0.004732
2021-11-30 15:01:56,865 iteration 6268 : loss : 0.006381, loss_ce: 0.004773
2021-11-30 15:01:58,227 iteration 6269 : loss : 0.007149, loss_ce: 0.004444
2021-11-30 15:01:59,572 iteration 6270 : loss : 0.007266, loss_ce: 0.004865
2021-11-30 15:02:00,930 iteration 6271 : loss : 0.006937, loss_ce: 0.005057
2021-11-30 15:02:02,289 iteration 6272 : loss : 0.006493, loss_ce: 0.004910
2021-11-30 15:02:03,647 iteration 6273 : loss : 0.007964, loss_ce: 0.005158
 92%|██████████████████████████▊  | 369/400 [2:34:42<12:21, 23.92s/it]2021-11-30 15:02:05,078 iteration 6274 : loss : 0.010253, loss_ce: 0.006465
2021-11-30 15:02:06,443 iteration 6275 : loss : 0.007317, loss_ce: 0.005038
2021-11-30 15:02:07,807 iteration 6276 : loss : 0.007552, loss_ce: 0.005275
2021-11-30 15:02:09,169 iteration 6277 : loss : 0.010477, loss_ce: 0.005330
2021-11-30 15:02:10,532 iteration 6278 : loss : 0.007431, loss_ce: 0.004771
2021-11-30 15:02:11,891 iteration 6279 : loss : 0.006268, loss_ce: 0.004651
2021-11-30 15:02:13,244 iteration 6280 : loss : 0.008844, loss_ce: 0.005749
2021-11-30 15:02:14,608 iteration 6281 : loss : 0.007254, loss_ce: 0.005545
2021-11-30 15:02:15,976 iteration 6282 : loss : 0.007231, loss_ce: 0.004649
2021-11-30 15:02:17,336 iteration 6283 : loss : 0.008820, loss_ce: 0.005962
2021-11-30 15:02:18,703 iteration 6284 : loss : 0.008336, loss_ce: 0.005854
2021-11-30 15:02:20,052 iteration 6285 : loss : 0.007833, loss_ce: 0.004647
2021-11-30 15:02:21,412 iteration 6286 : loss : 0.009793, loss_ce: 0.006201
2021-11-30 15:02:22,775 iteration 6287 : loss : 0.007443, loss_ce: 0.004883
2021-11-30 15:02:24,133 iteration 6288 : loss : 0.008449, loss_ce: 0.005610
2021-11-30 15:02:25,484 iteration 6289 : loss : 0.008223, loss_ce: 0.004891
2021-11-30 15:02:25,485 Training Data Eval:
2021-11-30 15:02:33,119   Average segmentation loss on training set: 0.0065
2021-11-30 15:02:33,120 Validation Data Eval:
2021-11-30 15:02:35,748   Average segmentation loss on validation set: 0.1760
2021-11-30 15:02:37,092 iteration 6290 : loss : 0.006572, loss_ce: 0.004853
 92%|██████████████████████████▊  | 370/400 [2:35:15<13:23, 26.78s/it]2021-11-30 15:02:38,503 iteration 6291 : loss : 0.007067, loss_ce: 0.004964
2021-11-30 15:02:39,845 iteration 6292 : loss : 0.006813, loss_ce: 0.005015
2021-11-30 15:02:41,203 iteration 6293 : loss : 0.006890, loss_ce: 0.005220
2021-11-30 15:02:42,546 iteration 6294 : loss : 0.011283, loss_ce: 0.006092
2021-11-30 15:02:43,896 iteration 6295 : loss : 0.008249, loss_ce: 0.005631
2021-11-30 15:02:45,248 iteration 6296 : loss : 0.006741, loss_ce: 0.004820
2021-11-30 15:02:46,581 iteration 6297 : loss : 0.007574, loss_ce: 0.004905
2021-11-30 15:02:47,932 iteration 6298 : loss : 0.007037, loss_ce: 0.004739
2021-11-30 15:02:49,277 iteration 6299 : loss : 0.008687, loss_ce: 0.005763
2021-11-30 15:02:50,630 iteration 6300 : loss : 0.006564, loss_ce: 0.004867
2021-11-30 15:02:51,985 iteration 6301 : loss : 0.006906, loss_ce: 0.005289
2021-11-30 15:02:53,330 iteration 6302 : loss : 0.008172, loss_ce: 0.004971
2021-11-30 15:02:54,677 iteration 6303 : loss : 0.009741, loss_ce: 0.006014
2021-11-30 15:02:56,034 iteration 6304 : loss : 0.008675, loss_ce: 0.005060
2021-11-30 15:02:57,389 iteration 6305 : loss : 0.007317, loss_ce: 0.004722
2021-11-30 15:02:58,736 iteration 6306 : loss : 0.007737, loss_ce: 0.004994
2021-11-30 15:03:00,074 iteration 6307 : loss : 0.006976, loss_ce: 0.004653
 93%|██████████████████████████▉  | 371/400 [2:35:38<12:23, 25.64s/it]2021-11-30 15:03:01,486 iteration 6308 : loss : 0.011500, loss_ce: 0.005720
2021-11-30 15:03:02,820 iteration 6309 : loss : 0.006976, loss_ce: 0.004917
2021-11-30 15:03:04,171 iteration 6310 : loss : 0.007551, loss_ce: 0.004946
2021-11-30 15:03:05,524 iteration 6311 : loss : 0.007384, loss_ce: 0.004729
2021-11-30 15:03:06,860 iteration 6312 : loss : 0.006767, loss_ce: 0.004739
2021-11-30 15:03:08,217 iteration 6313 : loss : 0.008447, loss_ce: 0.005867
2021-11-30 15:03:09,568 iteration 6314 : loss : 0.007675, loss_ce: 0.004839
2021-11-30 15:03:10,922 iteration 6315 : loss : 0.006636, loss_ce: 0.004845
2021-11-30 15:03:12,258 iteration 6316 : loss : 0.008023, loss_ce: 0.005391
2021-11-30 15:03:13,599 iteration 6317 : loss : 0.008488, loss_ce: 0.006336
2021-11-30 15:03:14,947 iteration 6318 : loss : 0.007325, loss_ce: 0.005738
2021-11-30 15:03:16,287 iteration 6319 : loss : 0.010381, loss_ce: 0.005170
2021-11-30 15:03:17,639 iteration 6320 : loss : 0.007008, loss_ce: 0.004879
2021-11-30 15:03:18,992 iteration 6321 : loss : 0.007118, loss_ce: 0.004767
2021-11-30 15:03:20,342 iteration 6322 : loss : 0.006709, loss_ce: 0.004844
2021-11-30 15:03:21,695 iteration 6323 : loss : 0.007986, loss_ce: 0.005374
2021-11-30 15:03:23,045 iteration 6324 : loss : 0.006162, loss_ce: 0.004465
 93%|██████████████████████████▉  | 372/400 [2:36:01<11:35, 24.84s/it]2021-11-30 15:03:24,464 iteration 6325 : loss : 0.006759, loss_ce: 0.005032
2021-11-30 15:03:25,820 iteration 6326 : loss : 0.006965, loss_ce: 0.005011
2021-11-30 15:03:27,177 iteration 6327 : loss : 0.006344, loss_ce: 0.004490
2021-11-30 15:03:28,530 iteration 6328 : loss : 0.006893, loss_ce: 0.005348
2021-11-30 15:03:29,874 iteration 6329 : loss : 0.007332, loss_ce: 0.004645
2021-11-30 15:03:31,229 iteration 6330 : loss : 0.008459, loss_ce: 0.005673
2021-11-30 15:03:32,584 iteration 6331 : loss : 0.006772, loss_ce: 0.004594
2021-11-30 15:03:33,942 iteration 6332 : loss : 0.006635, loss_ce: 0.004698
2021-11-30 15:03:35,304 iteration 6333 : loss : 0.007669, loss_ce: 0.005301
2021-11-30 15:03:36,661 iteration 6334 : loss : 0.009141, loss_ce: 0.006166
2021-11-30 15:03:38,019 iteration 6335 : loss : 0.008490, loss_ce: 0.005324
2021-11-30 15:03:39,379 iteration 6336 : loss : 0.006863, loss_ce: 0.004803
2021-11-30 15:03:40,736 iteration 6337 : loss : 0.007957, loss_ce: 0.005667
2021-11-30 15:03:42,093 iteration 6338 : loss : 0.011137, loss_ce: 0.005597
2021-11-30 15:03:43,450 iteration 6339 : loss : 0.006515, loss_ce: 0.004670
2021-11-30 15:03:44,804 iteration 6340 : loss : 0.006546, loss_ce: 0.004496
2021-11-30 15:03:46,165 iteration 6341 : loss : 0.006574, loss_ce: 0.004816
 93%|███████████████████████████  | 373/400 [2:36:24<10:56, 24.32s/it]2021-11-30 15:03:47,575 iteration 6342 : loss : 0.008276, loss_ce: 0.005756
2021-11-30 15:03:48,928 iteration 6343 : loss : 0.006904, loss_ce: 0.004488
2021-11-30 15:03:50,286 iteration 6344 : loss : 0.007089, loss_ce: 0.004623
2021-11-30 15:03:51,646 iteration 6345 : loss : 0.007492, loss_ce: 0.004971
2021-11-30 15:03:52,999 iteration 6346 : loss : 0.009100, loss_ce: 0.005352
2021-11-30 15:03:54,354 iteration 6347 : loss : 0.006966, loss_ce: 0.004921
2021-11-30 15:03:55,709 iteration 6348 : loss : 0.006730, loss_ce: 0.005018
2021-11-30 15:03:57,069 iteration 6349 : loss : 0.006684, loss_ce: 0.004604
2021-11-30 15:03:58,429 iteration 6350 : loss : 0.006735, loss_ce: 0.005024
2021-11-30 15:03:59,788 iteration 6351 : loss : 0.006603, loss_ce: 0.004806
2021-11-30 15:04:01,151 iteration 6352 : loss : 0.008428, loss_ce: 0.005264
2021-11-30 15:04:02,506 iteration 6353 : loss : 0.007369, loss_ce: 0.005328
2021-11-30 15:04:03,855 iteration 6354 : loss : 0.009271, loss_ce: 0.004851
2021-11-30 15:04:05,206 iteration 6355 : loss : 0.008704, loss_ce: 0.006084
2021-11-30 15:04:06,559 iteration 6356 : loss : 0.007362, loss_ce: 0.005150
2021-11-30 15:04:07,907 iteration 6357 : loss : 0.012064, loss_ce: 0.007875
2021-11-30 15:04:09,270 iteration 6358 : loss : 0.007710, loss_ce: 0.004898
 94%|███████████████████████████  | 374/400 [2:36:47<10:22, 23.96s/it]2021-11-30 15:04:10,673 iteration 6359 : loss : 0.009437, loss_ce: 0.005490
2021-11-30 15:04:12,012 iteration 6360 : loss : 0.007436, loss_ce: 0.005363
2021-11-30 15:04:13,368 iteration 6361 : loss : 0.006386, loss_ce: 0.004562
2021-11-30 15:04:14,724 iteration 6362 : loss : 0.009575, loss_ce: 0.005945
2021-11-30 15:04:16,073 iteration 6363 : loss : 0.007486, loss_ce: 0.005274
2021-11-30 15:04:17,427 iteration 6364 : loss : 0.008760, loss_ce: 0.006002
2021-11-30 15:04:18,784 iteration 6365 : loss : 0.008960, loss_ce: 0.005743
2021-11-30 15:04:20,145 iteration 6366 : loss : 0.006966, loss_ce: 0.004915
2021-11-30 15:04:21,499 iteration 6367 : loss : 0.008419, loss_ce: 0.004803
2021-11-30 15:04:22,845 iteration 6368 : loss : 0.008792, loss_ce: 0.004887
2021-11-30 15:04:24,202 iteration 6369 : loss : 0.006438, loss_ce: 0.004725
2021-11-30 15:04:25,548 iteration 6370 : loss : 0.007750, loss_ce: 0.005806
2021-11-30 15:04:26,910 iteration 6371 : loss : 0.008468, loss_ce: 0.005352
2021-11-30 15:04:28,270 iteration 6372 : loss : 0.007683, loss_ce: 0.004823
2021-11-30 15:04:29,610 iteration 6373 : loss : 0.007853, loss_ce: 0.005534
2021-11-30 15:04:30,970 iteration 6374 : loss : 0.006331, loss_ce: 0.004471
2021-11-30 15:04:30,970 Training Data Eval:
2021-11-30 15:04:38,604   Average segmentation loss on training set: 0.0063
2021-11-30 15:04:38,604 Validation Data Eval:
2021-11-30 15:04:41,224   Average segmentation loss on validation set: 0.1748
2021-11-30 15:04:42,569 iteration 6375 : loss : 0.009061, loss_ce: 0.005870
 94%|███████████████████████████▏ | 375/400 [2:37:21<11:08, 26.76s/it]2021-11-30 15:04:43,972 iteration 6376 : loss : 0.007589, loss_ce: 0.005722
2021-11-30 15:04:45,325 iteration 6377 : loss : 0.008126, loss_ce: 0.004531
2021-11-30 15:04:46,675 iteration 6378 : loss : 0.005916, loss_ce: 0.004278
2021-11-30 15:04:48,024 iteration 6379 : loss : 0.007267, loss_ce: 0.005200
2021-11-30 15:04:49,357 iteration 6380 : loss : 0.006296, loss_ce: 0.004764
2021-11-30 15:04:50,704 iteration 6381 : loss : 0.008857, loss_ce: 0.005998
2021-11-30 15:04:52,066 iteration 6382 : loss : 0.007829, loss_ce: 0.005455
2021-11-30 15:04:53,415 iteration 6383 : loss : 0.007533, loss_ce: 0.004774
2021-11-30 15:04:54,772 iteration 6384 : loss : 0.006638, loss_ce: 0.004796
2021-11-30 15:04:56,117 iteration 6385 : loss : 0.008240, loss_ce: 0.005817
2021-11-30 15:04:57,458 iteration 6386 : loss : 0.009103, loss_ce: 0.005247
2021-11-30 15:04:58,815 iteration 6387 : loss : 0.006627, loss_ce: 0.004605
2021-11-30 15:05:00,169 iteration 6388 : loss : 0.007093, loss_ce: 0.004955
2021-11-30 15:05:01,523 iteration 6389 : loss : 0.007711, loss_ce: 0.004945
2021-11-30 15:05:02,854 iteration 6390 : loss : 0.007731, loss_ce: 0.004677
2021-11-30 15:05:04,196 iteration 6391 : loss : 0.007057, loss_ce: 0.005235
2021-11-30 15:05:05,540 iteration 6392 : loss : 0.007466, loss_ce: 0.005624
 94%|███████████████████████████▎ | 376/400 [2:37:44<10:14, 25.62s/it]2021-11-30 15:05:06,954 iteration 6393 : loss : 0.008088, loss_ce: 0.005377
2021-11-30 15:05:08,300 iteration 6394 : loss : 0.006933, loss_ce: 0.004784
2021-11-30 15:05:09,661 iteration 6395 : loss : 0.008745, loss_ce: 0.006031
2021-11-30 15:05:11,018 iteration 6396 : loss : 0.007368, loss_ce: 0.004976
2021-11-30 15:05:12,380 iteration 6397 : loss : 0.006975, loss_ce: 0.005027
2021-11-30 15:05:13,738 iteration 6398 : loss : 0.007055, loss_ce: 0.004686
2021-11-30 15:05:15,098 iteration 6399 : loss : 0.009716, loss_ce: 0.006738
2021-11-30 15:05:16,458 iteration 6400 : loss : 0.005975, loss_ce: 0.004554
2021-11-30 15:05:17,801 iteration 6401 : loss : 0.007976, loss_ce: 0.005571
2021-11-30 15:05:19,153 iteration 6402 : loss : 0.007723, loss_ce: 0.004812
2021-11-30 15:05:20,515 iteration 6403 : loss : 0.007332, loss_ce: 0.005070
2021-11-30 15:05:21,868 iteration 6404 : loss : 0.007034, loss_ce: 0.004844
2021-11-30 15:05:23,231 iteration 6405 : loss : 0.008802, loss_ce: 0.005134
2021-11-30 15:05:24,586 iteration 6406 : loss : 0.009343, loss_ce: 0.005123
2021-11-30 15:05:25,931 iteration 6407 : loss : 0.007975, loss_ce: 0.005070
2021-11-30 15:05:27,289 iteration 6408 : loss : 0.007611, loss_ce: 0.004868
2021-11-30 15:05:28,634 iteration 6409 : loss : 0.009154, loss_ce: 0.005865
 94%|███████████████████████████▎ | 377/400 [2:38:07<09:31, 24.87s/it]2021-11-30 15:05:30,062 iteration 6410 : loss : 0.010981, loss_ce: 0.004840
2021-11-30 15:05:31,421 iteration 6411 : loss : 0.006055, loss_ce: 0.004602
2021-11-30 15:05:32,763 iteration 6412 : loss : 0.006750, loss_ce: 0.004904
2021-11-30 15:05:34,115 iteration 6413 : loss : 0.007525, loss_ce: 0.005440
2021-11-30 15:05:35,477 iteration 6414 : loss : 0.007467, loss_ce: 0.005049
2021-11-30 15:05:36,840 iteration 6415 : loss : 0.006459, loss_ce: 0.004716
2021-11-30 15:05:38,196 iteration 6416 : loss : 0.006566, loss_ce: 0.004637
2021-11-30 15:05:39,542 iteration 6417 : loss : 0.007337, loss_ce: 0.005251
2021-11-30 15:05:40,888 iteration 6418 : loss : 0.007712, loss_ce: 0.005722
2021-11-30 15:05:42,245 iteration 6419 : loss : 0.006570, loss_ce: 0.004509
2021-11-30 15:05:43,598 iteration 6420 : loss : 0.007947, loss_ce: 0.004948
2021-11-30 15:05:44,952 iteration 6421 : loss : 0.007641, loss_ce: 0.005378
2021-11-30 15:05:46,307 iteration 6422 : loss : 0.008389, loss_ce: 0.005075
2021-11-30 15:05:47,650 iteration 6423 : loss : 0.006736, loss_ce: 0.004884
2021-11-30 15:05:49,008 iteration 6424 : loss : 0.007915, loss_ce: 0.004983
2021-11-30 15:05:50,360 iteration 6425 : loss : 0.007192, loss_ce: 0.004773
2021-11-30 15:05:51,701 iteration 6426 : loss : 0.006767, loss_ce: 0.004743
 94%|███████████████████████████▍ | 378/400 [2:38:30<08:55, 24.33s/it]2021-11-30 15:05:53,113 iteration 6427 : loss : 0.006473, loss_ce: 0.004827
2021-11-30 15:05:54,460 iteration 6428 : loss : 0.009401, loss_ce: 0.005811
2021-11-30 15:05:55,819 iteration 6429 : loss : 0.008646, loss_ce: 0.005993
2021-11-30 15:05:57,180 iteration 6430 : loss : 0.007861, loss_ce: 0.005127
2021-11-30 15:05:58,538 iteration 6431 : loss : 0.008925, loss_ce: 0.005077
2021-11-30 15:05:59,890 iteration 6432 : loss : 0.008025, loss_ce: 0.005312
2021-11-30 15:06:01,245 iteration 6433 : loss : 0.006199, loss_ce: 0.004470
2021-11-30 15:06:02,607 iteration 6434 : loss : 0.007364, loss_ce: 0.004892
2021-11-30 15:06:03,963 iteration 6435 : loss : 0.006364, loss_ce: 0.004571
2021-11-30 15:06:05,299 iteration 6436 : loss : 0.008384, loss_ce: 0.005364
2021-11-30 15:06:06,659 iteration 6437 : loss : 0.006769, loss_ce: 0.005174
2021-11-30 15:06:08,011 iteration 6438 : loss : 0.006317, loss_ce: 0.004572
2021-11-30 15:06:09,363 iteration 6439 : loss : 0.008421, loss_ce: 0.005058
2021-11-30 15:06:10,711 iteration 6440 : loss : 0.009266, loss_ce: 0.005858
2021-11-30 15:06:12,074 iteration 6441 : loss : 0.007257, loss_ce: 0.005336
2021-11-30 15:06:13,425 iteration 6442 : loss : 0.006598, loss_ce: 0.005054
2021-11-30 15:06:14,776 iteration 6443 : loss : 0.007753, loss_ce: 0.005312
 95%|███████████████████████████▍ | 379/400 [2:38:53<08:22, 23.95s/it]2021-11-30 15:06:16,204 iteration 6444 : loss : 0.006577, loss_ce: 0.004425
2021-11-30 15:06:17,549 iteration 6445 : loss : 0.008165, loss_ce: 0.005722
2021-11-30 15:06:18,907 iteration 6446 : loss : 0.007485, loss_ce: 0.004508
2021-11-30 15:06:20,258 iteration 6447 : loss : 0.009119, loss_ce: 0.005670
2021-11-30 15:06:21,615 iteration 6448 : loss : 0.007504, loss_ce: 0.005484
2021-11-30 15:06:22,973 iteration 6449 : loss : 0.007170, loss_ce: 0.005027
2021-11-30 15:06:24,319 iteration 6450 : loss : 0.008657, loss_ce: 0.005300
2021-11-30 15:06:25,678 iteration 6451 : loss : 0.006494, loss_ce: 0.004669
2021-11-30 15:06:27,030 iteration 6452 : loss : 0.007659, loss_ce: 0.005262
2021-11-30 15:06:28,389 iteration 6453 : loss : 0.006732, loss_ce: 0.004531
2021-11-30 15:06:29,756 iteration 6454 : loss : 0.006658, loss_ce: 0.004936
2021-11-30 15:06:31,106 iteration 6455 : loss : 0.007842, loss_ce: 0.005015
2021-11-30 15:06:32,450 iteration 6456 : loss : 0.006953, loss_ce: 0.005208
2021-11-30 15:06:33,804 iteration 6457 : loss : 0.006577, loss_ce: 0.004604
2021-11-30 15:06:35,160 iteration 6458 : loss : 0.010970, loss_ce: 0.005695
2021-11-30 15:06:36,519 iteration 6459 : loss : 0.006677, loss_ce: 0.004874
2021-11-30 15:06:36,519 Training Data Eval:
2021-11-30 15:06:44,100   Average segmentation loss on training set: 0.0066
2021-11-30 15:06:44,101 Validation Data Eval:
2021-11-30 15:06:46,737   Average segmentation loss on validation set: 0.1712
2021-11-30 15:06:48,073 iteration 6460 : loss : 0.007215, loss_ce: 0.005053
 95%|███████████████████████████▌ | 380/400 [2:39:26<08:55, 26.75s/it]2021-11-30 15:06:49,485 iteration 6461 : loss : 0.007259, loss_ce: 0.004859
2021-11-30 15:06:50,831 iteration 6462 : loss : 0.008881, loss_ce: 0.006222
2021-11-30 15:06:52,173 iteration 6463 : loss : 0.008108, loss_ce: 0.004912
2021-11-30 15:06:53,526 iteration 6464 : loss : 0.006922, loss_ce: 0.005261
2021-11-30 15:06:54,872 iteration 6465 : loss : 0.006525, loss_ce: 0.004599
2021-11-30 15:06:56,207 iteration 6466 : loss : 0.008788, loss_ce: 0.005062
2021-11-30 15:06:57,542 iteration 6467 : loss : 0.007373, loss_ce: 0.004960
2021-11-30 15:06:58,897 iteration 6468 : loss : 0.007017, loss_ce: 0.005128
2021-11-30 15:07:00,249 iteration 6469 : loss : 0.008572, loss_ce: 0.005756
2021-11-30 15:07:01,591 iteration 6470 : loss : 0.006535, loss_ce: 0.004584
2021-11-30 15:07:02,946 iteration 6471 : loss : 0.007309, loss_ce: 0.005128
2021-11-30 15:07:04,287 iteration 6472 : loss : 0.006913, loss_ce: 0.004947
2021-11-30 15:07:05,641 iteration 6473 : loss : 0.007092, loss_ce: 0.005146
2021-11-30 15:07:06,977 iteration 6474 : loss : 0.006346, loss_ce: 0.004434
2021-11-30 15:07:08,316 iteration 6475 : loss : 0.006925, loss_ce: 0.004788
2021-11-30 15:07:09,650 iteration 6476 : loss : 0.008139, loss_ce: 0.004899
2021-11-30 15:07:10,992 iteration 6477 : loss : 0.007890, loss_ce: 0.005374
 95%|███████████████████████████▌ | 381/400 [2:39:49<08:06, 25.60s/it]2021-11-30 15:07:12,406 iteration 6478 : loss : 0.007296, loss_ce: 0.004851
2021-11-30 15:07:13,748 iteration 6479 : loss : 0.008577, loss_ce: 0.005019
2021-11-30 15:07:15,089 iteration 6480 : loss : 0.008122, loss_ce: 0.005464
2021-11-30 15:07:16,442 iteration 6481 : loss : 0.007311, loss_ce: 0.005170
2021-11-30 15:07:17,794 iteration 6482 : loss : 0.006788, loss_ce: 0.004938
2021-11-30 15:07:19,139 iteration 6483 : loss : 0.006718, loss_ce: 0.004775
2021-11-30 15:07:20,483 iteration 6484 : loss : 0.007215, loss_ce: 0.005156
2021-11-30 15:07:21,819 iteration 6485 : loss : 0.007092, loss_ce: 0.005430
2021-11-30 15:07:23,159 iteration 6486 : loss : 0.008334, loss_ce: 0.004413
2021-11-30 15:07:24,500 iteration 6487 : loss : 0.008975, loss_ce: 0.005249
2021-11-30 15:07:25,853 iteration 6488 : loss : 0.007552, loss_ce: 0.004650
2021-11-30 15:07:27,193 iteration 6489 : loss : 0.010444, loss_ce: 0.007212
2021-11-30 15:07:28,553 iteration 6490 : loss : 0.006683, loss_ce: 0.004853
2021-11-30 15:07:29,902 iteration 6491 : loss : 0.010090, loss_ce: 0.005228
2021-11-30 15:07:31,266 iteration 6492 : loss : 0.010251, loss_ce: 0.006798
2021-11-30 15:07:32,621 iteration 6493 : loss : 0.005846, loss_ce: 0.004343
2021-11-30 15:07:33,977 iteration 6494 : loss : 0.007708, loss_ce: 0.004791
 96%|███████████████████████████▋ | 382/400 [2:40:12<07:26, 24.82s/it]2021-11-30 15:07:35,393 iteration 6495 : loss : 0.006875, loss_ce: 0.004857
2021-11-30 15:07:36,734 iteration 6496 : loss : 0.006858, loss_ce: 0.005368
2021-11-30 15:07:38,087 iteration 6497 : loss : 0.007989, loss_ce: 0.005037
2021-11-30 15:07:39,432 iteration 6498 : loss : 0.007902, loss_ce: 0.004943
2021-11-30 15:07:40,777 iteration 6499 : loss : 0.007438, loss_ce: 0.005627
2021-11-30 15:07:42,136 iteration 6500 : loss : 0.007738, loss_ce: 0.004914
2021-11-30 15:07:43,491 iteration 6501 : loss : 0.005955, loss_ce: 0.004437
2021-11-30 15:07:44,827 iteration 6502 : loss : 0.006274, loss_ce: 0.004614
2021-11-30 15:07:46,179 iteration 6503 : loss : 0.006696, loss_ce: 0.004734
2021-11-30 15:07:47,534 iteration 6504 : loss : 0.007029, loss_ce: 0.004490
2021-11-30 15:07:48,884 iteration 6505 : loss : 0.008364, loss_ce: 0.005279
2021-11-30 15:07:50,241 iteration 6506 : loss : 0.010608, loss_ce: 0.006836
2021-11-30 15:07:51,592 iteration 6507 : loss : 0.007484, loss_ce: 0.004771
2021-11-30 15:07:52,941 iteration 6508 : loss : 0.008803, loss_ce: 0.005729
2021-11-30 15:07:54,293 iteration 6509 : loss : 0.007072, loss_ce: 0.004756
2021-11-30 15:07:55,649 iteration 6510 : loss : 0.009233, loss_ce: 0.006382
2021-11-30 15:07:57,010 iteration 6511 : loss : 0.008624, loss_ce: 0.005458
 96%|███████████████████████████▊ | 383/400 [2:40:35<06:52, 24.28s/it]2021-11-30 15:07:58,424 iteration 6512 : loss : 0.007313, loss_ce: 0.005258
2021-11-30 15:07:59,771 iteration 6513 : loss : 0.008032, loss_ce: 0.005854
2021-11-30 15:08:01,137 iteration 6514 : loss : 0.007287, loss_ce: 0.004759
2021-11-30 15:08:02,497 iteration 6515 : loss : 0.007707, loss_ce: 0.005521
2021-11-30 15:08:03,844 iteration 6516 : loss : 0.007941, loss_ce: 0.005376
2021-11-30 15:08:05,203 iteration 6517 : loss : 0.007653, loss_ce: 0.004852
2021-11-30 15:08:06,556 iteration 6518 : loss : 0.008226, loss_ce: 0.004903
2021-11-30 15:08:07,912 iteration 6519 : loss : 0.008173, loss_ce: 0.005161
2021-11-30 15:08:09,267 iteration 6520 : loss : 0.007974, loss_ce: 0.005956
2021-11-30 15:08:10,622 iteration 6521 : loss : 0.006145, loss_ce: 0.004573
2021-11-30 15:08:11,985 iteration 6522 : loss : 0.010318, loss_ce: 0.005709
2021-11-30 15:08:13,339 iteration 6523 : loss : 0.009263, loss_ce: 0.006155
2021-11-30 15:08:14,701 iteration 6524 : loss : 0.009457, loss_ce: 0.006208
2021-11-30 15:08:16,062 iteration 6525 : loss : 0.006316, loss_ce: 0.004604
2021-11-30 15:08:17,418 iteration 6526 : loss : 0.010099, loss_ce: 0.005900
2021-11-30 15:08:18,773 iteration 6527 : loss : 0.006051, loss_ce: 0.004440
2021-11-30 15:08:20,140 iteration 6528 : loss : 0.005596, loss_ce: 0.004162
 96%|███████████████████████████▊ | 384/400 [2:40:58<06:22, 23.94s/it]2021-11-30 15:08:21,552 iteration 6529 : loss : 0.007542, loss_ce: 0.004517
2021-11-30 15:08:22,901 iteration 6530 : loss : 0.006728, loss_ce: 0.004698
2021-11-30 15:08:24,258 iteration 6531 : loss : 0.007131, loss_ce: 0.005275
2021-11-30 15:08:25,612 iteration 6532 : loss : 0.008695, loss_ce: 0.005586
2021-11-30 15:08:26,980 iteration 6533 : loss : 0.006285, loss_ce: 0.004686
2021-11-30 15:08:28,339 iteration 6534 : loss : 0.008750, loss_ce: 0.006102
2021-11-30 15:08:29,692 iteration 6535 : loss : 0.009215, loss_ce: 0.005337
2021-11-30 15:08:31,039 iteration 6536 : loss : 0.007511, loss_ce: 0.004808
2021-11-30 15:08:32,383 iteration 6537 : loss : 0.008368, loss_ce: 0.005938
2021-11-30 15:08:33,747 iteration 6538 : loss : 0.008483, loss_ce: 0.005889
2021-11-30 15:08:35,105 iteration 6539 : loss : 0.006478, loss_ce: 0.004555
2021-11-30 15:08:36,451 iteration 6540 : loss : 0.009942, loss_ce: 0.005100
2021-11-30 15:08:37,799 iteration 6541 : loss : 0.007269, loss_ce: 0.005148
2021-11-30 15:08:39,155 iteration 6542 : loss : 0.006972, loss_ce: 0.004934
2021-11-30 15:08:40,497 iteration 6543 : loss : 0.007108, loss_ce: 0.005113
2021-11-30 15:08:41,862 iteration 6544 : loss : 0.007554, loss_ce: 0.004506
2021-11-30 15:08:41,862 Training Data Eval:
2021-11-30 15:08:49,467   Average segmentation loss on training set: 0.0065
2021-11-30 15:08:49,468 Validation Data Eval:
2021-11-30 15:08:52,094   Average segmentation loss on validation set: 0.1787
2021-11-30 15:08:53,439 iteration 6545 : loss : 0.006523, loss_ce: 0.004590
 96%|███████████████████████████▉ | 385/400 [2:41:32<06:41, 26.75s/it]2021-11-30 15:08:54,851 iteration 6546 : loss : 0.006515, loss_ce: 0.004581
2021-11-30 15:08:56,191 iteration 6547 : loss : 0.008260, loss_ce: 0.005289
2021-11-30 15:08:57,527 iteration 6548 : loss : 0.007088, loss_ce: 0.004615
2021-11-30 15:08:58,876 iteration 6549 : loss : 0.014084, loss_ce: 0.007497
2021-11-30 15:09:00,226 iteration 6550 : loss : 0.007423, loss_ce: 0.005157
2021-11-30 15:09:01,550 iteration 6551 : loss : 0.015463, loss_ce: 0.008347
2021-11-30 15:09:02,886 iteration 6552 : loss : 0.007394, loss_ce: 0.004494
2021-11-30 15:09:04,234 iteration 6553 : loss : 0.006731, loss_ce: 0.004879
2021-11-30 15:09:05,589 iteration 6554 : loss : 0.006192, loss_ce: 0.004684
2021-11-30 15:09:06,934 iteration 6555 : loss : 0.008380, loss_ce: 0.005828
2021-11-30 15:09:08,288 iteration 6556 : loss : 0.006315, loss_ce: 0.004572
2021-11-30 15:09:09,626 iteration 6557 : loss : 0.006567, loss_ce: 0.004501
2021-11-30 15:09:10,968 iteration 6558 : loss : 0.007241, loss_ce: 0.004760
2021-11-30 15:09:12,321 iteration 6559 : loss : 0.009404, loss_ce: 0.006259
2021-11-30 15:09:13,665 iteration 6560 : loss : 0.006054, loss_ce: 0.004516
2021-11-30 15:09:15,017 iteration 6561 : loss : 0.006646, loss_ce: 0.004450
2021-11-30 15:09:16,348 iteration 6562 : loss : 0.007233, loss_ce: 0.005529
 96%|███████████████████████████▉ | 386/400 [2:41:54<05:58, 25.59s/it]2021-11-30 15:09:17,746 iteration 6563 : loss : 0.008198, loss_ce: 0.005580
2021-11-30 15:09:19,094 iteration 6564 : loss : 0.008437, loss_ce: 0.005798
2021-11-30 15:09:20,448 iteration 6565 : loss : 0.006484, loss_ce: 0.004857
2021-11-30 15:09:21,803 iteration 6566 : loss : 0.006317, loss_ce: 0.004665
2021-11-30 15:09:23,141 iteration 6567 : loss : 0.008398, loss_ce: 0.004487
2021-11-30 15:09:24,491 iteration 6568 : loss : 0.005951, loss_ce: 0.004368
2021-11-30 15:09:25,849 iteration 6569 : loss : 0.007421, loss_ce: 0.005435
2021-11-30 15:09:27,194 iteration 6570 : loss : 0.007208, loss_ce: 0.005579
2021-11-30 15:09:28,536 iteration 6571 : loss : 0.006572, loss_ce: 0.004633
2021-11-30 15:09:29,882 iteration 6572 : loss : 0.007435, loss_ce: 0.005090
2021-11-30 15:09:31,229 iteration 6573 : loss : 0.006285, loss_ce: 0.004558
2021-11-30 15:09:32,572 iteration 6574 : loss : 0.006952, loss_ce: 0.004877
2021-11-30 15:09:33,911 iteration 6575 : loss : 0.006406, loss_ce: 0.004587
2021-11-30 15:09:35,252 iteration 6576 : loss : 0.007426, loss_ce: 0.004833
2021-11-30 15:09:36,602 iteration 6577 : loss : 0.008888, loss_ce: 0.006021
2021-11-30 15:09:37,953 iteration 6578 : loss : 0.007112, loss_ce: 0.005124
2021-11-30 15:09:39,308 iteration 6579 : loss : 0.006568, loss_ce: 0.004540
 97%|████████████████████████████ | 387/400 [2:42:17<05:22, 24.80s/it]2021-11-30 15:09:40,712 iteration 6580 : loss : 0.006394, loss_ce: 0.004629
2021-11-30 15:09:42,058 iteration 6581 : loss : 0.011560, loss_ce: 0.004689
2021-11-30 15:09:43,410 iteration 6582 : loss : 0.006861, loss_ce: 0.004967
2021-11-30 15:09:44,766 iteration 6583 : loss : 0.007648, loss_ce: 0.004861
2021-11-30 15:09:46,122 iteration 6584 : loss : 0.006787, loss_ce: 0.004647
2021-11-30 15:09:47,478 iteration 6585 : loss : 0.006442, loss_ce: 0.004779
2021-11-30 15:09:48,838 iteration 6586 : loss : 0.009781, loss_ce: 0.005500
2021-11-30 15:09:50,194 iteration 6587 : loss : 0.008293, loss_ce: 0.005417
2021-11-30 15:09:51,541 iteration 6588 : loss : 0.008744, loss_ce: 0.006331
2021-11-30 15:09:52,900 iteration 6589 : loss : 0.006965, loss_ce: 0.004847
2021-11-30 15:09:54,250 iteration 6590 : loss : 0.007637, loss_ce: 0.004936
2021-11-30 15:09:55,600 iteration 6591 : loss : 0.008102, loss_ce: 0.006010
2021-11-30 15:09:56,955 iteration 6592 : loss : 0.007549, loss_ce: 0.004585
2021-11-30 15:09:58,299 iteration 6593 : loss : 0.006471, loss_ce: 0.004713
2021-11-30 15:09:59,655 iteration 6594 : loss : 0.009669, loss_ce: 0.007127
2021-11-30 15:10:01,011 iteration 6595 : loss : 0.008135, loss_ce: 0.005649
2021-11-30 15:10:02,363 iteration 6596 : loss : 0.007866, loss_ce: 0.004828
 97%|████████████████████████████▏| 388/400 [2:42:40<04:51, 24.28s/it]2021-11-30 15:10:03,768 iteration 6597 : loss : 0.007792, loss_ce: 0.005047
2021-11-30 15:10:05,114 iteration 6598 : loss : 0.007713, loss_ce: 0.005685
2021-11-30 15:10:06,472 iteration 6599 : loss : 0.005993, loss_ce: 0.004585
2021-11-30 15:10:07,825 iteration 6600 : loss : 0.005992, loss_ce: 0.004693
2021-11-30 15:10:09,174 iteration 6601 : loss : 0.008758, loss_ce: 0.006133
2021-11-30 15:10:10,537 iteration 6602 : loss : 0.007179, loss_ce: 0.005221
2021-11-30 15:10:11,884 iteration 6603 : loss : 0.008411, loss_ce: 0.005943
2021-11-30 15:10:13,234 iteration 6604 : loss : 0.006250, loss_ce: 0.004624
2021-11-30 15:10:14,601 iteration 6605 : loss : 0.006352, loss_ce: 0.004464
2021-11-30 15:10:15,957 iteration 6606 : loss : 0.006702, loss_ce: 0.004469
2021-11-30 15:10:17,316 iteration 6607 : loss : 0.007212, loss_ce: 0.004913
2021-11-30 15:10:18,670 iteration 6608 : loss : 0.006828, loss_ce: 0.004818
2021-11-30 15:10:20,010 iteration 6609 : loss : 0.007625, loss_ce: 0.004829
2021-11-30 15:10:21,372 iteration 6610 : loss : 0.007593, loss_ce: 0.005012
2021-11-30 15:10:22,727 iteration 6611 : loss : 0.007470, loss_ce: 0.004664
2021-11-30 15:10:24,081 iteration 6612 : loss : 0.008072, loss_ce: 0.005748
2021-11-30 15:10:25,418 iteration 6613 : loss : 0.007426, loss_ce: 0.005250
 97%|████████████████████████████▏| 389/400 [2:43:04<04:23, 23.91s/it]2021-11-30 15:10:26,824 iteration 6614 : loss : 0.007487, loss_ce: 0.004446
2021-11-30 15:10:28,178 iteration 6615 : loss : 0.008597, loss_ce: 0.005898
2021-11-30 15:10:29,526 iteration 6616 : loss : 0.010790, loss_ce: 0.006598
2021-11-30 15:10:30,869 iteration 6617 : loss : 0.008089, loss_ce: 0.005230
2021-11-30 15:10:32,229 iteration 6618 : loss : 0.006990, loss_ce: 0.004972
2021-11-30 15:10:33,583 iteration 6619 : loss : 0.007573, loss_ce: 0.005581
2021-11-30 15:10:34,945 iteration 6620 : loss : 0.008263, loss_ce: 0.006171
2021-11-30 15:10:36,298 iteration 6621 : loss : 0.010514, loss_ce: 0.006384
2021-11-30 15:10:37,643 iteration 6622 : loss : 0.007025, loss_ce: 0.004447
2021-11-30 15:10:39,003 iteration 6623 : loss : 0.007278, loss_ce: 0.004833
2021-11-30 15:10:40,357 iteration 6624 : loss : 0.007152, loss_ce: 0.005209
2021-11-30 15:10:41,703 iteration 6625 : loss : 0.006133, loss_ce: 0.004351
2021-11-30 15:10:43,046 iteration 6626 : loss : 0.008547, loss_ce: 0.005737
2021-11-30 15:10:44,398 iteration 6627 : loss : 0.010067, loss_ce: 0.005610
2021-11-30 15:10:45,754 iteration 6628 : loss : 0.007064, loss_ce: 0.004952
2021-11-30 15:10:47,092 iteration 6629 : loss : 0.006454, loss_ce: 0.004461
2021-11-30 15:10:47,093 Training Data Eval:
2021-11-30 15:10:54,693   Average segmentation loss on training set: 0.0064
2021-11-30 15:10:54,694 Validation Data Eval:
2021-11-30 15:10:57,327   Average segmentation loss on validation set: 0.1732
2021-11-30 15:10:58,671 iteration 6630 : loss : 0.007150, loss_ce: 0.004554
 98%|████████████████████████████▎| 390/400 [2:43:37<04:27, 26.72s/it]2021-11-30 15:11:00,091 iteration 6631 : loss : 0.006855, loss_ce: 0.004839
2021-11-30 15:11:01,438 iteration 6632 : loss : 0.008773, loss_ce: 0.005686
2021-11-30 15:11:02,803 iteration 6633 : loss : 0.006413, loss_ce: 0.004680
2021-11-30 15:11:04,158 iteration 6634 : loss : 0.006976, loss_ce: 0.004306
2021-11-30 15:11:05,505 iteration 6635 : loss : 0.007463, loss_ce: 0.005402
2021-11-30 15:11:06,863 iteration 6636 : loss : 0.007000, loss_ce: 0.005206
2021-11-30 15:11:08,203 iteration 6637 : loss : 0.007468, loss_ce: 0.005044
2021-11-30 15:11:09,556 iteration 6638 : loss : 0.008078, loss_ce: 0.006203
2021-11-30 15:11:10,909 iteration 6639 : loss : 0.006267, loss_ce: 0.004520
2021-11-30 15:11:12,246 iteration 6640 : loss : 0.008730, loss_ce: 0.004957
2021-11-30 15:11:13,600 iteration 6641 : loss : 0.006490, loss_ce: 0.004867
2021-11-30 15:11:14,953 iteration 6642 : loss : 0.006915, loss_ce: 0.004375
2021-11-30 15:11:16,307 iteration 6643 : loss : 0.007640, loss_ce: 0.005075
2021-11-30 15:11:17,656 iteration 6644 : loss : 0.006735, loss_ce: 0.004802
2021-11-30 15:11:19,003 iteration 6645 : loss : 0.007453, loss_ce: 0.004757
2021-11-30 15:11:20,357 iteration 6646 : loss : 0.006038, loss_ce: 0.004384
2021-11-30 15:11:21,707 iteration 6647 : loss : 0.007097, loss_ce: 0.005207
 98%|████████████████████████████▎| 391/400 [2:44:00<03:50, 25.61s/it]2021-11-30 15:11:23,122 iteration 6648 : loss : 0.007411, loss_ce: 0.005027
2021-11-30 15:11:24,464 iteration 6649 : loss : 0.010626, loss_ce: 0.005773
2021-11-30 15:11:25,818 iteration 6650 : loss : 0.008884, loss_ce: 0.006728
2021-11-30 15:11:27,171 iteration 6651 : loss : 0.007389, loss_ce: 0.004330
2021-11-30 15:11:28,526 iteration 6652 : loss : 0.006669, loss_ce: 0.004852
2021-11-30 15:11:29,866 iteration 6653 : loss : 0.011181, loss_ce: 0.006676
2021-11-30 15:11:31,222 iteration 6654 : loss : 0.007513, loss_ce: 0.004973
2021-11-30 15:11:32,568 iteration 6655 : loss : 0.014440, loss_ce: 0.007207
2021-11-30 15:11:33,929 iteration 6656 : loss : 0.006569, loss_ce: 0.004590
2021-11-30 15:11:35,279 iteration 6657 : loss : 0.008797, loss_ce: 0.006240
2021-11-30 15:11:36,627 iteration 6658 : loss : 0.007053, loss_ce: 0.004763
2021-11-30 15:11:37,990 iteration 6659 : loss : 0.006318, loss_ce: 0.004434
2021-11-30 15:11:39,329 iteration 6660 : loss : 0.007420, loss_ce: 0.005384
2021-11-30 15:11:40,685 iteration 6661 : loss : 0.008308, loss_ce: 0.005043
2021-11-30 15:11:42,027 iteration 6662 : loss : 0.007267, loss_ce: 0.004731
2021-11-30 15:11:43,385 iteration 6663 : loss : 0.007057, loss_ce: 0.005314
2021-11-30 15:11:44,751 iteration 6664 : loss : 0.007041, loss_ce: 0.004599
 98%|████████████████████████████▍| 392/400 [2:44:23<03:18, 24.84s/it]2021-11-30 15:11:46,163 iteration 6665 : loss : 0.006206, loss_ce: 0.004430
2021-11-30 15:11:47,508 iteration 6666 : loss : 0.007149, loss_ce: 0.005259
2021-11-30 15:11:48,863 iteration 6667 : loss : 0.007224, loss_ce: 0.005247
2021-11-30 15:11:50,204 iteration 6668 : loss : 0.006406, loss_ce: 0.004820
2021-11-30 15:11:51,556 iteration 6669 : loss : 0.007285, loss_ce: 0.004955
2021-11-30 15:11:52,899 iteration 6670 : loss : 0.008732, loss_ce: 0.004873
2021-11-30 15:11:54,238 iteration 6671 : loss : 0.007499, loss_ce: 0.004981
2021-11-30 15:11:55,598 iteration 6672 : loss : 0.006201, loss_ce: 0.004485
2021-11-30 15:11:56,946 iteration 6673 : loss : 0.008409, loss_ce: 0.005050
2021-11-30 15:11:58,305 iteration 6674 : loss : 0.007814, loss_ce: 0.005933
2021-11-30 15:11:59,653 iteration 6675 : loss : 0.006818, loss_ce: 0.004654
2021-11-30 15:12:01,001 iteration 6676 : loss : 0.006775, loss_ce: 0.004956
2021-11-30 15:12:02,359 iteration 6677 : loss : 0.009062, loss_ce: 0.005965
2021-11-30 15:12:03,711 iteration 6678 : loss : 0.007042, loss_ce: 0.004831
2021-11-30 15:12:05,065 iteration 6679 : loss : 0.009852, loss_ce: 0.005028
2021-11-30 15:12:06,402 iteration 6680 : loss : 0.006584, loss_ce: 0.004868
2021-11-30 15:12:07,748 iteration 6681 : loss : 0.006608, loss_ce: 0.004952
 98%|████████████████████████████▍| 393/400 [2:44:46<02:50, 24.29s/it]2021-11-30 15:12:09,177 iteration 6682 : loss : 0.006193, loss_ce: 0.004737
2021-11-30 15:12:10,539 iteration 6683 : loss : 0.007460, loss_ce: 0.004708
2021-11-30 15:12:11,893 iteration 6684 : loss : 0.007875, loss_ce: 0.005772
2021-11-30 15:12:13,261 iteration 6685 : loss : 0.006337, loss_ce: 0.004608
2021-11-30 15:12:14,628 iteration 6686 : loss : 0.006756, loss_ce: 0.004402
2021-11-30 15:12:15,989 iteration 6687 : loss : 0.007866, loss_ce: 0.005283
2021-11-30 15:12:17,353 iteration 6688 : loss : 0.008180, loss_ce: 0.005756
2021-11-30 15:12:18,714 iteration 6689 : loss : 0.007817, loss_ce: 0.005119
2021-11-30 15:12:20,070 iteration 6690 : loss : 0.007055, loss_ce: 0.005128
2021-11-30 15:12:21,424 iteration 6691 : loss : 0.007764, loss_ce: 0.005437
2021-11-30 15:12:22,787 iteration 6692 : loss : 0.006376, loss_ce: 0.004745
2021-11-30 15:12:24,143 iteration 6693 : loss : 0.006256, loss_ce: 0.004587
2021-11-30 15:12:25,511 iteration 6694 : loss : 0.006970, loss_ce: 0.004876
2021-11-30 15:12:26,879 iteration 6695 : loss : 0.008288, loss_ce: 0.005151
2021-11-30 15:12:28,244 iteration 6696 : loss : 0.007179, loss_ce: 0.004746
2021-11-30 15:12:29,609 iteration 6697 : loss : 0.006461, loss_ce: 0.004646
2021-11-30 15:12:30,965 iteration 6698 : loss : 0.006849, loss_ce: 0.004542
 98%|████████████████████████████▌| 394/400 [2:45:09<02:23, 23.96s/it]2021-11-30 15:12:32,380 iteration 6699 : loss : 0.006961, loss_ce: 0.004910
2021-11-30 15:12:33,741 iteration 6700 : loss : 0.007916, loss_ce: 0.005796
2021-11-30 15:12:35,101 iteration 6701 : loss : 0.007555, loss_ce: 0.004985
2021-11-30 15:12:36,459 iteration 6702 : loss : 0.008089, loss_ce: 0.005413
2021-11-30 15:12:37,817 iteration 6703 : loss : 0.007815, loss_ce: 0.005033
2021-11-30 15:12:39,173 iteration 6704 : loss : 0.007971, loss_ce: 0.005762
2021-11-30 15:12:40,527 iteration 6705 : loss : 0.007867, loss_ce: 0.005227
2021-11-30 15:12:41,889 iteration 6706 : loss : 0.006841, loss_ce: 0.004875
2021-11-30 15:12:43,246 iteration 6707 : loss : 0.008186, loss_ce: 0.004907
2021-11-30 15:12:44,607 iteration 6708 : loss : 0.008548, loss_ce: 0.005475
2021-11-30 15:12:45,970 iteration 6709 : loss : 0.008861, loss_ce: 0.005045
2021-11-30 15:12:47,330 iteration 6710 : loss : 0.007217, loss_ce: 0.004594
2021-11-30 15:12:48,688 iteration 6711 : loss : 0.006683, loss_ce: 0.004721
2021-11-30 15:12:50,047 iteration 6712 : loss : 0.008388, loss_ce: 0.006388
2021-11-30 15:12:51,404 iteration 6713 : loss : 0.007810, loss_ce: 0.004696
2021-11-30 15:12:52,767 iteration 6714 : loss : 0.007664, loss_ce: 0.004949
2021-11-30 15:12:52,767 Training Data Eval:
2021-11-30 15:13:00,488   Average segmentation loss on training set: 0.0063
2021-11-30 15:13:00,488 Validation Data Eval:
2021-11-30 15:13:03,154   Average segmentation loss on validation set: 0.1776
2021-11-30 15:13:04,511 iteration 6715 : loss : 0.007592, loss_ce: 0.005695
 99%|████████████████████████████▋| 395/400 [2:45:43<02:14, 26.84s/it]2021-11-30 15:13:05,938 iteration 6716 : loss : 0.008694, loss_ce: 0.005903
2021-11-30 15:13:07,295 iteration 6717 : loss : 0.006806, loss_ce: 0.004701
2021-11-30 15:13:08,652 iteration 6718 : loss : 0.007844, loss_ce: 0.005866
2021-11-30 15:13:10,010 iteration 6719 : loss : 0.006740, loss_ce: 0.004722
2021-11-30 15:13:11,376 iteration 6720 : loss : 0.006414, loss_ce: 0.004618
2021-11-30 15:13:12,733 iteration 6721 : loss : 0.007715, loss_ce: 0.004751
2021-11-30 15:13:14,095 iteration 6722 : loss : 0.006508, loss_ce: 0.005181
2021-11-30 15:13:15,454 iteration 6723 : loss : 0.007910, loss_ce: 0.004997
2021-11-30 15:13:16,817 iteration 6724 : loss : 0.008080, loss_ce: 0.005237
2021-11-30 15:13:18,177 iteration 6725 : loss : 0.008437, loss_ce: 0.005519
2021-11-30 15:13:19,536 iteration 6726 : loss : 0.007115, loss_ce: 0.005092
2021-11-30 15:13:20,894 iteration 6727 : loss : 0.008828, loss_ce: 0.005610
2021-11-30 15:13:22,257 iteration 6728 : loss : 0.007238, loss_ce: 0.005202
2021-11-30 15:13:23,618 iteration 6729 : loss : 0.006791, loss_ce: 0.004435
2021-11-30 15:13:24,978 iteration 6730 : loss : 0.009477, loss_ce: 0.006451
2021-11-30 15:13:26,333 iteration 6731 : loss : 0.007741, loss_ce: 0.004937
2021-11-30 15:13:27,687 iteration 6732 : loss : 0.007882, loss_ce: 0.004942
 99%|████████████████████████████▋| 396/400 [2:46:06<01:42, 25.74s/it]2021-11-30 15:13:29,111 iteration 6733 : loss : 0.009876, loss_ce: 0.005229
2021-11-30 15:13:30,469 iteration 6734 : loss : 0.007316, loss_ce: 0.004656
2021-11-30 15:13:31,830 iteration 6735 : loss : 0.007340, loss_ce: 0.004575
2021-11-30 15:13:33,200 iteration 6736 : loss : 0.007446, loss_ce: 0.005280
2021-11-30 15:13:34,558 iteration 6737 : loss : 0.006459, loss_ce: 0.004966
2021-11-30 15:13:35,917 iteration 6738 : loss : 0.007840, loss_ce: 0.004869
2021-11-30 15:13:37,278 iteration 6739 : loss : 0.006874, loss_ce: 0.004793
2021-11-30 15:13:38,635 iteration 6740 : loss : 0.007308, loss_ce: 0.004800
2021-11-30 15:13:39,990 iteration 6741 : loss : 0.007000, loss_ce: 0.005253
2021-11-30 15:13:41,347 iteration 6742 : loss : 0.007025, loss_ce: 0.004533
2021-11-30 15:13:42,702 iteration 6743 : loss : 0.006842, loss_ce: 0.005058
2021-11-30 15:13:44,052 iteration 6744 : loss : 0.008788, loss_ce: 0.005893
2021-11-30 15:13:45,413 iteration 6745 : loss : 0.007300, loss_ce: 0.005467
2021-11-30 15:13:46,777 iteration 6746 : loss : 0.006670, loss_ce: 0.005080
2021-11-30 15:13:48,147 iteration 6747 : loss : 0.006951, loss_ce: 0.005008
2021-11-30 15:13:49,508 iteration 6748 : loss : 0.008896, loss_ce: 0.006084
2021-11-30 15:13:50,855 iteration 6749 : loss : 0.006388, loss_ce: 0.004314
 99%|████████████████████████████▊| 397/400 [2:46:29<01:14, 24.97s/it]2021-11-30 15:13:52,265 iteration 6750 : loss : 0.006733, loss_ce: 0.004998
2021-11-30 15:13:53,606 iteration 6751 : loss : 0.010318, loss_ce: 0.006820
2021-11-30 15:13:54,960 iteration 6752 : loss : 0.008417, loss_ce: 0.005575
2021-11-30 15:13:56,315 iteration 6753 : loss : 0.007028, loss_ce: 0.004572
2021-11-30 15:13:57,671 iteration 6754 : loss : 0.007640, loss_ce: 0.004911
2021-11-30 15:13:59,030 iteration 6755 : loss : 0.007263, loss_ce: 0.004751
2021-11-30 15:14:00,393 iteration 6756 : loss : 0.008526, loss_ce: 0.004538
2021-11-30 15:14:01,748 iteration 6757 : loss : 0.006864, loss_ce: 0.005094
2021-11-30 15:14:03,107 iteration 6758 : loss : 0.007295, loss_ce: 0.004761
2021-11-30 15:14:04,465 iteration 6759 : loss : 0.005981, loss_ce: 0.004218
2021-11-30 15:14:05,818 iteration 6760 : loss : 0.007224, loss_ce: 0.004847
2021-11-30 15:14:07,173 iteration 6761 : loss : 0.006424, loss_ce: 0.004830
2021-11-30 15:14:08,534 iteration 6762 : loss : 0.007044, loss_ce: 0.004812
2021-11-30 15:14:09,877 iteration 6763 : loss : 0.007554, loss_ce: 0.005066
2021-11-30 15:14:11,223 iteration 6764 : loss : 0.007913, loss_ce: 0.005779
2021-11-30 15:14:12,575 iteration 6765 : loss : 0.007049, loss_ce: 0.005241
2021-11-30 15:14:13,926 iteration 6766 : loss : 0.005776, loss_ce: 0.004677
100%|████████████████████████████▊| 398/400 [2:46:52<00:48, 24.40s/it]2021-11-30 15:14:15,353 iteration 6767 : loss : 0.009815, loss_ce: 0.006872
2021-11-30 15:14:16,699 iteration 6768 : loss : 0.007340, loss_ce: 0.004708
2021-11-30 15:14:18,044 iteration 6769 : loss : 0.006921, loss_ce: 0.004836
2021-11-30 15:14:19,402 iteration 6770 : loss : 0.007237, loss_ce: 0.005627
2021-11-30 15:14:20,753 iteration 6771 : loss : 0.006723, loss_ce: 0.004559
2021-11-30 15:14:22,100 iteration 6772 : loss : 0.007473, loss_ce: 0.005654
2021-11-30 15:14:23,452 iteration 6773 : loss : 0.006427, loss_ce: 0.004603
2021-11-30 15:14:24,791 iteration 6774 : loss : 0.008371, loss_ce: 0.005222
2021-11-30 15:14:26,141 iteration 6775 : loss : 0.006844, loss_ce: 0.004873
2021-11-30 15:14:27,488 iteration 6776 : loss : 0.007452, loss_ce: 0.005168
2021-11-30 15:14:28,844 iteration 6777 : loss : 0.006787, loss_ce: 0.004759
2021-11-30 15:14:30,188 iteration 6778 : loss : 0.007256, loss_ce: 0.004465
2021-11-30 15:14:31,533 iteration 6779 : loss : 0.007319, loss_ce: 0.004688
2021-11-30 15:14:32,894 iteration 6780 : loss : 0.006400, loss_ce: 0.004383
2021-11-30 15:14:34,242 iteration 6781 : loss : 0.007799, loss_ce: 0.005192
2021-11-30 15:14:35,595 iteration 6782 : loss : 0.007725, loss_ce: 0.005509
2021-11-30 15:14:36,952 iteration 6783 : loss : 0.006930, loss_ce: 0.004871
100%|████████████████████████████▉| 399/400 [2:47:15<00:23, 23.99s/it]2021-11-30 15:14:38,377 iteration 6784 : loss : 0.008510, loss_ce: 0.004795
2021-11-30 15:14:39,733 iteration 6785 : loss : 0.006743, loss_ce: 0.004564
2021-11-30 15:14:41,094 iteration 6786 : loss : 0.007653, loss_ce: 0.005412
2021-11-30 15:14:42,449 iteration 6787 : loss : 0.009863, loss_ce: 0.004906
2021-11-30 15:14:43,810 iteration 6788 : loss : 0.007511, loss_ce: 0.004961
2021-11-30 15:14:45,170 iteration 6789 : loss : 0.008027, loss_ce: 0.005698
2021-11-30 15:14:46,524 iteration 6790 : loss : 0.009656, loss_ce: 0.007148
2021-11-30 15:14:47,876 iteration 6791 : loss : 0.007516, loss_ce: 0.005619
2021-11-30 15:14:49,224 iteration 6792 : loss : 0.007102, loss_ce: 0.004695
2021-11-30 15:14:50,569 iteration 6793 : loss : 0.006867, loss_ce: 0.004621
2021-11-30 15:14:51,934 iteration 6794 : loss : 0.006400, loss_ce: 0.004583
2021-11-30 15:14:53,280 iteration 6795 : loss : 0.008555, loss_ce: 0.004977
2021-11-30 15:14:54,634 iteration 6796 : loss : 0.009084, loss_ce: 0.005470
2021-11-30 15:14:55,988 iteration 6797 : loss : 0.006346, loss_ce: 0.004401
2021-11-30 15:14:57,331 iteration 6798 : loss : 0.007735, loss_ce: 0.005725
2021-11-30 15:14:58,687 iteration 6799 : loss : 0.006801, loss_ce: 0.004842
2021-11-30 15:14:58,687 Training Data Eval:
2021-11-30 15:15:06,303   Average segmentation loss on training set: 0.0062
2021-11-30 15:15:06,304 Validation Data Eval:
2021-11-30 15:15:08,930   Average segmentation loss on validation set: 0.1772
2021-11-30 15:15:10,273 iteration 6800 : loss : 0.008144, loss_ce: 0.005951
100%|█████████████████████████████| 400/400 [2:47:48<00:00, 26.79s/it]100%|█████████████████████████████| 400/400 [2:47:48<00:00, 25.17s/it]
