2021-11-30 13:15:09,433 Logging directory: /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/TransUNet/log_dir/trRUNMC_cv1_r3/i2i2l/
2021-11-30 13:15:09,434 Tensorboard directory: /scratch_net/biwidl217_second/arismu/Tensorboard/trRUNMC_cv1_r3/i2i2l/
2021-11-30 13:15:09,434 ============================================================
2021-11-30 13:15:09,434 EXPERIMENT NAME: trRUNMC_cv1_r3/i2i2l/
2021-11-30 13:15:09,434 ============================================================
2021-11-30 13:15:09,434 Loading data...
2021-11-30 13:15:09,434 Reading NCI - RUNMC images...
2021-11-30 13:15:09,434 Data root directory: /itet-stor/arismu/bmicdatasets-originals/Originals/Challenge_Datasets/NCI_Prostate/
2021-11-30 13:15:09,437 Already preprocessed this configuration. Loading now!
2021-11-30 13:15:09,456 Training Images: (256, 256, 286)
2021-11-30 13:15:09,456 Training Labels: (256, 256, 286)
2021-11-30 13:15:09,456 Validation Images: (256, 256, 98)
2021-11-30 13:15:09,456 Validation Labels: (256, 256, 98)
2021-11-30 13:15:09,456 ============================================================
2021-11-30 13:15:09,512 17 iterations per epoch. 6800 max iterations 
  0%|                                         | 0/400 [00:00<?, ?it/s]2021-11-30 13:15:12,323 iteration 1 : loss : 1.062713, loss_ce: 1.354821
2021-11-30 13:15:13,702 iteration 2 : loss : 1.033840, loss_ce: 1.305527
2021-11-30 13:15:15,200 iteration 3 : loss : 0.948568, loss_ce: 1.166062
2021-11-30 13:15:16,588 iteration 4 : loss : 0.865582, loss_ce: 1.017044
2021-11-30 13:15:17,989 iteration 5 : loss : 0.790496, loss_ce: 0.901195
2021-11-30 13:15:19,397 iteration 6 : loss : 0.727345, loss_ce: 0.782201
2021-11-30 13:15:20,865 iteration 7 : loss : 0.668314, loss_ce: 0.696404
2021-11-30 13:15:22,269 iteration 8 : loss : 0.649367, loss_ce: 0.635099
2021-11-30 13:15:23,698 iteration 9 : loss : 0.702393, loss_ce: 0.771711
2021-11-30 13:15:25,153 iteration 10 : loss : 0.657770, loss_ce: 0.649016
2021-11-30 13:15:26,676 iteration 11 : loss : 0.630953, loss_ce: 0.627479
2021-11-30 13:15:28,071 iteration 12 : loss : 0.610269, loss_ce: 0.587443
2021-11-30 13:15:29,450 iteration 13 : loss : 0.596743, loss_ce: 0.554109
2021-11-30 13:15:30,806 iteration 14 : loss : 0.580782, loss_ce: 0.532286
2021-11-30 13:15:32,229 iteration 15 : loss : 0.576279, loss_ce: 0.531041
2021-11-30 13:15:33,650 iteration 16 : loss : 0.572950, loss_ce: 0.512674
2021-11-30 13:15:35,054 iteration 17 : loss : 0.543344, loss_ce: 0.486590
  0%|                               | 1/400 [00:25<2:50:18, 25.61s/it]2021-11-30 13:15:36,560 iteration 18 : loss : 0.546115, loss_ce: 0.447656
2021-11-30 13:15:37,903 iteration 19 : loss : 0.530356, loss_ce: 0.451095
2021-11-30 13:15:39,381 iteration 20 : loss : 0.519899, loss_ce: 0.429922
2021-11-30 13:15:40,759 iteration 21 : loss : 0.516121, loss_ce: 0.403113
2021-11-30 13:15:42,171 iteration 22 : loss : 0.511076, loss_ce: 0.431756
2021-11-30 13:15:43,653 iteration 23 : loss : 0.503479, loss_ce: 0.386074
2021-11-30 13:15:45,053 iteration 24 : loss : 0.496118, loss_ce: 0.385098
2021-11-30 13:15:46,508 iteration 25 : loss : 0.493844, loss_ce: 0.408363
2021-11-30 13:15:47,897 iteration 26 : loss : 0.484970, loss_ce: 0.371264
2021-11-30 13:15:49,231 iteration 27 : loss : 0.481433, loss_ce: 0.374250
2021-11-30 13:15:50,580 iteration 28 : loss : 0.474752, loss_ce: 0.350997
2021-11-30 13:15:52,045 iteration 29 : loss : 0.467408, loss_ce: 0.338201
2021-11-30 13:15:53,476 iteration 30 : loss : 0.455065, loss_ce: 0.333207
2021-11-30 13:15:54,831 iteration 31 : loss : 0.454839, loss_ce: 0.336800
2021-11-30 13:15:56,296 iteration 32 : loss : 0.454868, loss_ce: 0.342265
2021-11-30 13:15:57,742 iteration 33 : loss : 0.446447, loss_ce: 0.325421
2021-11-30 13:15:59,185 iteration 34 : loss : 0.444398, loss_ce: 0.332976
  0%|▏                              | 2/400 [00:49<2:44:01, 24.73s/it]2021-11-30 13:16:00,686 iteration 35 : loss : 0.430957, loss_ce: 0.293320
2021-11-30 13:16:02,149 iteration 36 : loss : 0.434260, loss_ce: 0.303356
2021-11-30 13:16:03,639 iteration 37 : loss : 0.425189, loss_ce: 0.279086
2021-11-30 13:16:05,112 iteration 38 : loss : 0.418407, loss_ce: 0.296238
2021-11-30 13:16:06,634 iteration 39 : loss : 0.415037, loss_ce: 0.292143
2021-11-30 13:16:08,229 iteration 40 : loss : 0.416502, loss_ce: 0.291322
2021-11-30 13:16:09,794 iteration 41 : loss : 0.431509, loss_ce: 0.296882
2021-11-30 13:16:11,330 iteration 42 : loss : 0.415946, loss_ce: 0.276701
2021-11-30 13:16:12,795 iteration 43 : loss : 0.408113, loss_ce: 0.258896
2021-11-30 13:16:14,398 iteration 44 : loss : 0.395097, loss_ce: 0.261203
2021-11-30 13:16:15,916 iteration 45 : loss : 0.393352, loss_ce: 0.260550
2021-11-30 13:16:17,454 iteration 46 : loss : 0.384478, loss_ce: 0.234117
2021-11-30 13:16:19,034 iteration 47 : loss : 0.367623, loss_ce: 0.227110
2021-11-30 13:16:20,577 iteration 48 : loss : 0.372648, loss_ce: 0.232117
2021-11-30 13:16:22,162 iteration 49 : loss : 0.388586, loss_ce: 0.247392
2021-11-30 13:16:23,643 iteration 50 : loss : 0.406578, loss_ce: 0.247147
2021-11-30 13:16:25,112 iteration 51 : loss : 0.376530, loss_ce: 0.232337
  1%|▏                              | 3/400 [01:15<2:47:14, 25.27s/it]2021-11-30 13:16:26,719 iteration 52 : loss : 0.392991, loss_ce: 0.252432
2021-11-30 13:16:28,268 iteration 53 : loss : 0.386622, loss_ce: 0.234884
2021-11-30 13:16:29,793 iteration 54 : loss : 0.366925, loss_ce: 0.211335
2021-11-30 13:16:31,345 iteration 55 : loss : 0.388521, loss_ce: 0.247798
2021-11-30 13:16:32,857 iteration 56 : loss : 0.355856, loss_ce: 0.215528
2021-11-30 13:16:34,402 iteration 57 : loss : 0.349368, loss_ce: 0.207859
2021-11-30 13:16:35,946 iteration 58 : loss : 0.364367, loss_ce: 0.211443
2021-11-30 13:16:37,471 iteration 59 : loss : 0.348866, loss_ce: 0.217477
2021-11-30 13:16:39,014 iteration 60 : loss : 0.379803, loss_ce: 0.217857
2021-11-30 13:16:40,560 iteration 61 : loss : 0.363172, loss_ce: 0.219490
2021-11-30 13:16:42,082 iteration 62 : loss : 0.383757, loss_ce: 0.185365
2021-11-30 13:16:43,533 iteration 63 : loss : 0.359991, loss_ce: 0.206576
2021-11-30 13:16:45,036 iteration 64 : loss : 0.383459, loss_ce: 0.197230
2021-11-30 13:16:46,513 iteration 65 : loss : 0.350173, loss_ce: 0.172011
2021-11-30 13:16:48,024 iteration 66 : loss : 0.320824, loss_ce: 0.184745
2021-11-30 13:16:49,603 iteration 67 : loss : 0.353978, loss_ce: 0.194168
2021-11-30 13:16:51,122 iteration 68 : loss : 0.308156, loss_ce: 0.186369
  1%|▎                              | 4/400 [01:41<2:48:43, 25.56s/it]2021-11-30 13:16:52,711 iteration 69 : loss : 0.313077, loss_ce: 0.182955
2021-11-30 13:16:54,304 iteration 70 : loss : 0.325450, loss_ce: 0.194472
2021-11-30 13:16:55,807 iteration 71 : loss : 0.309795, loss_ce: 0.175480
2021-11-30 13:16:57,349 iteration 72 : loss : 0.305108, loss_ce: 0.169781
2021-11-30 13:16:58,842 iteration 73 : loss : 0.302923, loss_ce: 0.177560
2021-11-30 13:17:00,305 iteration 74 : loss : 0.271485, loss_ce: 0.150752
2021-11-30 13:17:01,788 iteration 75 : loss : 0.286932, loss_ce: 0.155484
2021-11-30 13:17:03,289 iteration 76 : loss : 0.315525, loss_ce: 0.179632
2021-11-30 13:17:04,699 iteration 77 : loss : 0.294656, loss_ce: 0.175001
2021-11-30 13:17:06,211 iteration 78 : loss : 0.304500, loss_ce: 0.179391
2021-11-30 13:17:07,696 iteration 79 : loss : 0.328233, loss_ce: 0.168151
2021-11-30 13:17:09,157 iteration 80 : loss : 0.294595, loss_ce: 0.167028
2021-11-30 13:17:10,630 iteration 81 : loss : 0.309405, loss_ce: 0.168439
2021-11-30 13:17:12,116 iteration 82 : loss : 0.316489, loss_ce: 0.164736
2021-11-30 13:17:13,597 iteration 83 : loss : 0.306241, loss_ce: 0.147388
2021-11-30 13:17:15,157 iteration 84 : loss : 0.334995, loss_ce: 0.198772
2021-11-30 13:17:15,157 Training Data Eval:
2021-11-30 13:17:22,740   Average segmentation loss on training set: 2.0359
2021-11-30 13:17:22,741 Validation Data Eval:
2021-11-30 13:17:25,502   Average segmentation loss on validation set: 2.1077
2021-11-30 13:17:26,992 iteration 85 : loss : 0.313827, loss_ce: 0.162037
  1%|▍                              | 5/400 [02:17<3:12:44, 29.28s/it]2021-11-30 13:17:28,558 iteration 86 : loss : 0.323651, loss_ce: 0.146407
2021-11-30 13:17:30,204 iteration 87 : loss : 0.280222, loss_ce: 0.146375
2021-11-30 13:17:31,675 iteration 88 : loss : 0.282919, loss_ce: 0.148154
2021-11-30 13:17:33,227 iteration 89 : loss : 0.339242, loss_ce: 0.171089
2021-11-30 13:17:34,753 iteration 90 : loss : 0.271584, loss_ce: 0.144207
2021-11-30 13:17:36,357 iteration 91 : loss : 0.271325, loss_ce: 0.162130
2021-11-30 13:17:37,819 iteration 92 : loss : 0.277571, loss_ce: 0.154434
2021-11-30 13:17:39,324 iteration 93 : loss : 0.298500, loss_ce: 0.152041
2021-11-30 13:17:40,834 iteration 94 : loss : 0.248949, loss_ce: 0.137418
2021-11-30 13:17:42,475 iteration 95 : loss : 0.286331, loss_ce: 0.156350
2021-11-30 13:17:43,954 iteration 96 : loss : 0.275156, loss_ce: 0.145624
2021-11-30 13:17:45,447 iteration 97 : loss : 0.293276, loss_ce: 0.144743
2021-11-30 13:17:46,966 iteration 98 : loss : 0.294578, loss_ce: 0.147746
2021-11-30 13:17:48,554 iteration 99 : loss : 0.277984, loss_ce: 0.146963
2021-11-30 13:17:50,091 iteration 100 : loss : 0.277717, loss_ce: 0.141240
2021-11-30 13:17:51,606 iteration 101 : loss : 0.214896, loss_ce: 0.107775
2021-11-30 13:17:53,061 iteration 102 : loss : 0.241069, loss_ce: 0.120102
  2%|▍                              | 6/400 [02:43<3:05:07, 28.19s/it]2021-11-30 13:17:54,711 iteration 103 : loss : 0.269808, loss_ce: 0.140128
2021-11-30 13:17:56,302 iteration 104 : loss : 0.305308, loss_ce: 0.154480
2021-11-30 13:17:57,935 iteration 105 : loss : 0.295116, loss_ce: 0.141381
2021-11-30 13:17:59,421 iteration 106 : loss : 0.293917, loss_ce: 0.141425
2021-11-30 13:18:01,087 iteration 107 : loss : 0.244171, loss_ce: 0.129091
2021-11-30 13:18:02,548 iteration 108 : loss : 0.268005, loss_ce: 0.133969
2021-11-30 13:18:04,035 iteration 109 : loss : 0.258369, loss_ce: 0.138090
2021-11-30 13:18:05,483 iteration 110 : loss : 0.230151, loss_ce: 0.117275
2021-11-30 13:18:07,036 iteration 111 : loss : 0.331612, loss_ce: 0.181046
2021-11-30 13:18:08,489 iteration 112 : loss : 0.228119, loss_ce: 0.118209
2021-11-30 13:18:10,008 iteration 113 : loss : 0.272609, loss_ce: 0.165003
2021-11-30 13:18:11,499 iteration 114 : loss : 0.260422, loss_ce: 0.122013
2021-11-30 13:18:13,006 iteration 115 : loss : 0.263471, loss_ce: 0.136630
2021-11-30 13:18:14,563 iteration 116 : loss : 0.286337, loss_ce: 0.155214
2021-11-30 13:18:16,114 iteration 117 : loss : 0.264852, loss_ce: 0.136761
2021-11-30 13:18:17,639 iteration 118 : loss : 0.298615, loss_ce: 0.148579
2021-11-30 13:18:19,177 iteration 119 : loss : 0.254798, loss_ce: 0.111990
  2%|▌                              | 7/400 [03:09<3:00:12, 27.51s/it]2021-11-30 13:18:20,710 iteration 120 : loss : 0.382063, loss_ce: 0.190761
2021-11-30 13:18:22,175 iteration 121 : loss : 0.256105, loss_ce: 0.124275
2021-11-30 13:18:23,733 iteration 122 : loss : 0.306185, loss_ce: 0.134749
2021-11-30 13:18:25,272 iteration 123 : loss : 0.257586, loss_ce: 0.116141
2021-11-30 13:18:26,772 iteration 124 : loss : 0.247325, loss_ce: 0.110137
2021-11-30 13:18:28,239 iteration 125 : loss : 0.250156, loss_ce: 0.130713
2021-11-30 13:18:29,778 iteration 126 : loss : 0.252028, loss_ce: 0.114787
2021-11-30 13:18:31,249 iteration 127 : loss : 0.242932, loss_ce: 0.126493
2021-11-30 13:18:32,751 iteration 128 : loss : 0.245343, loss_ce: 0.122940
2021-11-30 13:18:34,316 iteration 129 : loss : 0.258291, loss_ce: 0.118120
2021-11-30 13:18:35,809 iteration 130 : loss : 0.225800, loss_ce: 0.104732
2021-11-30 13:18:37,396 iteration 131 : loss : 0.248269, loss_ce: 0.132730
2021-11-30 13:18:39,013 iteration 132 : loss : 0.243724, loss_ce: 0.097363
2021-11-30 13:18:40,495 iteration 133 : loss : 0.234210, loss_ce: 0.104757
2021-11-30 13:18:42,085 iteration 134 : loss : 0.234152, loss_ce: 0.105557
2021-11-30 13:18:43,672 iteration 135 : loss : 0.248898, loss_ce: 0.123432
2021-11-30 13:18:45,187 iteration 136 : loss : 0.197293, loss_ce: 0.096849
  2%|▌                              | 8/400 [03:35<2:56:36, 27.03s/it]2021-11-30 13:18:46,805 iteration 137 : loss : 0.230833, loss_ce: 0.097362
2021-11-30 13:18:48,276 iteration 138 : loss : 0.253201, loss_ce: 0.140774
2021-11-30 13:18:49,830 iteration 139 : loss : 0.299591, loss_ce: 0.151286
2021-11-30 13:18:51,347 iteration 140 : loss : 0.238422, loss_ce: 0.110962
2021-11-30 13:18:52,910 iteration 141 : loss : 0.231413, loss_ce: 0.117318
2021-11-30 13:18:54,480 iteration 142 : loss : 0.245743, loss_ce: 0.118797
2021-11-30 13:18:56,068 iteration 143 : loss : 0.234720, loss_ce: 0.113072
2021-11-30 13:18:57,617 iteration 144 : loss : 0.246745, loss_ce: 0.113832
2021-11-30 13:18:59,132 iteration 145 : loss : 0.223940, loss_ce: 0.101364
2021-11-30 13:19:00,697 iteration 146 : loss : 0.242332, loss_ce: 0.127968
2021-11-30 13:19:02,268 iteration 147 : loss : 0.242474, loss_ce: 0.118559
2021-11-30 13:19:03,700 iteration 148 : loss : 0.252176, loss_ce: 0.128395
2021-11-30 13:19:05,215 iteration 149 : loss : 0.342843, loss_ce: 0.172048
2021-11-30 13:19:06,689 iteration 150 : loss : 0.311918, loss_ce: 0.129803
2021-11-30 13:19:08,184 iteration 151 : loss : 0.281038, loss_ce: 0.144107
2021-11-30 13:19:09,704 iteration 152 : loss : 0.248636, loss_ce: 0.097859
2021-11-30 13:19:11,235 iteration 153 : loss : 0.285987, loss_ce: 0.133922
  2%|▋                              | 9/400 [04:01<2:54:09, 26.73s/it]2021-11-30 13:19:12,732 iteration 154 : loss : 0.276693, loss_ce: 0.119381
2021-11-30 13:19:14,260 iteration 155 : loss : 0.242788, loss_ce: 0.096073
2021-11-30 13:19:15,869 iteration 156 : loss : 0.252561, loss_ce: 0.102651
2021-11-30 13:19:17,408 iteration 157 : loss : 0.287755, loss_ce: 0.122195
2021-11-30 13:19:19,043 iteration 158 : loss : 0.241467, loss_ce: 0.116789
2021-11-30 13:19:20,463 iteration 159 : loss : 0.218528, loss_ce: 0.098660
2021-11-30 13:19:22,064 iteration 160 : loss : 0.206106, loss_ce: 0.086034
2021-11-30 13:19:23,637 iteration 161 : loss : 0.281133, loss_ce: 0.126657
2021-11-30 13:19:25,210 iteration 162 : loss : 0.235073, loss_ce: 0.116618
2021-11-30 13:19:26,726 iteration 163 : loss : 0.292541, loss_ce: 0.135171
2021-11-30 13:19:28,259 iteration 164 : loss : 0.208498, loss_ce: 0.081198
2021-11-30 13:19:29,781 iteration 165 : loss : 0.244698, loss_ce: 0.112252
2021-11-30 13:19:31,262 iteration 166 : loss : 0.247670, loss_ce: 0.110120
2021-11-30 13:19:32,780 iteration 167 : loss : 0.217685, loss_ce: 0.098843
2021-11-30 13:19:34,336 iteration 168 : loss : 0.239906, loss_ce: 0.133617
2021-11-30 13:19:35,866 iteration 169 : loss : 0.254284, loss_ce: 0.137346
2021-11-30 13:19:35,867 Training Data Eval:
2021-11-30 13:19:43,451   Average segmentation loss on training set: 0.3208
2021-11-30 13:19:43,459 Validation Data Eval:
2021-11-30 13:19:46,081   Average segmentation loss on validation set: 0.3045
2021-11-30 13:19:47,994 Found new lowest validation loss at iteration 169! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/UNET_RUNMC/ADAM/ADAM_best_val_loss.pth
2021-11-30 13:19:49,461 iteration 170 : loss : 0.180732, loss_ce: 0.090114
  2%|▊                             | 10/400 [04:39<3:16:46, 30.27s/it]2021-11-30 13:19:50,927 iteration 171 : loss : 0.200396, loss_ce: 0.093018
2021-11-30 13:19:52,383 iteration 172 : loss : 0.227774, loss_ce: 0.109281
2021-11-30 13:19:53,931 iteration 173 : loss : 0.182052, loss_ce: 0.085505
2021-11-30 13:19:55,409 iteration 174 : loss : 0.224593, loss_ce: 0.106286
2021-11-30 13:19:56,891 iteration 175 : loss : 0.265910, loss_ce: 0.116812
2021-11-30 13:19:58,436 iteration 176 : loss : 0.202700, loss_ce: 0.104428
2021-11-30 13:19:59,949 iteration 177 : loss : 0.244318, loss_ce: 0.109145
2021-11-30 13:20:01,474 iteration 178 : loss : 0.170262, loss_ce: 0.091840
2021-11-30 13:20:02,996 iteration 179 : loss : 0.219954, loss_ce: 0.102580
2021-11-30 13:20:04,482 iteration 180 : loss : 0.197069, loss_ce: 0.086813
2021-11-30 13:20:06,046 iteration 181 : loss : 0.254374, loss_ce: 0.124210
2021-11-30 13:20:07,528 iteration 182 : loss : 0.158664, loss_ce: 0.070494
2021-11-30 13:20:08,998 iteration 183 : loss : 0.218997, loss_ce: 0.091961
2021-11-30 13:20:10,431 iteration 184 : loss : 0.216848, loss_ce: 0.084447
2021-11-30 13:20:11,985 iteration 185 : loss : 0.242045, loss_ce: 0.092978
2021-11-30 13:20:13,548 iteration 186 : loss : 0.262636, loss_ce: 0.123580
2021-11-30 13:20:15,129 iteration 187 : loss : 0.248469, loss_ce: 0.103496
  3%|▊                             | 11/400 [05:05<3:07:08, 28.86s/it]2021-11-30 13:20:16,709 iteration 188 : loss : 0.228361, loss_ce: 0.097800
2021-11-30 13:20:18,243 iteration 189 : loss : 0.210291, loss_ce: 0.089904
2021-11-30 13:20:19,783 iteration 190 : loss : 0.235278, loss_ce: 0.094278
2021-11-30 13:20:21,279 iteration 191 : loss : 0.174493, loss_ce: 0.077383
2021-11-30 13:20:22,737 iteration 192 : loss : 0.211540, loss_ce: 0.109272
2021-11-30 13:20:24,301 iteration 193 : loss : 0.226622, loss_ce: 0.102173
2021-11-30 13:20:25,812 iteration 194 : loss : 0.265721, loss_ce: 0.093343
2021-11-30 13:20:27,306 iteration 195 : loss : 0.215469, loss_ce: 0.099895
2021-11-30 13:20:28,743 iteration 196 : loss : 0.215266, loss_ce: 0.083421
2021-11-30 13:20:30,261 iteration 197 : loss : 0.241768, loss_ce: 0.105064
2021-11-30 13:20:31,819 iteration 198 : loss : 0.202152, loss_ce: 0.096433
2021-11-30 13:20:33,308 iteration 199 : loss : 0.201635, loss_ce: 0.088404
2021-11-30 13:20:34,795 iteration 200 : loss : 0.184418, loss_ce: 0.084249
2021-11-30 13:20:36,327 iteration 201 : loss : 0.143525, loss_ce: 0.065934
2021-11-30 13:20:37,877 iteration 202 : loss : 0.225693, loss_ce: 0.101678
2021-11-30 13:20:39,368 iteration 203 : loss : 0.178378, loss_ce: 0.076737
2021-11-30 13:20:40,969 iteration 204 : loss : 0.235296, loss_ce: 0.100783
  3%|▉                             | 12/400 [05:31<3:00:42, 27.94s/it]2021-11-30 13:20:42,502 iteration 205 : loss : 0.199234, loss_ce: 0.087680
2021-11-30 13:20:44,003 iteration 206 : loss : 0.182462, loss_ce: 0.068808
2021-11-30 13:20:45,559 iteration 207 : loss : 0.175382, loss_ce: 0.074678
2021-11-30 13:20:47,048 iteration 208 : loss : 0.254359, loss_ce: 0.086505
2021-11-30 13:20:48,624 iteration 209 : loss : 0.264519, loss_ce: 0.131249
2021-11-30 13:20:50,056 iteration 210 : loss : 0.173947, loss_ce: 0.070221
2021-11-30 13:20:51,611 iteration 211 : loss : 0.202366, loss_ce: 0.097559
2021-11-30 13:20:53,145 iteration 212 : loss : 0.217084, loss_ce: 0.088581
2021-11-30 13:20:54,760 iteration 213 : loss : 0.159092, loss_ce: 0.084111
2021-11-30 13:20:56,281 iteration 214 : loss : 0.187408, loss_ce: 0.070801
2021-11-30 13:20:57,816 iteration 215 : loss : 0.234893, loss_ce: 0.105139
2021-11-30 13:20:59,480 iteration 216 : loss : 0.205031, loss_ce: 0.080342
2021-11-30 13:21:01,079 iteration 217 : loss : 0.167924, loss_ce: 0.068362
2021-11-30 13:21:02,620 iteration 218 : loss : 0.196387, loss_ce: 0.104250
2021-11-30 13:21:04,034 iteration 219 : loss : 0.181430, loss_ce: 0.084129
2021-11-30 13:21:05,581 iteration 220 : loss : 0.156449, loss_ce: 0.072371
2021-11-30 13:21:07,101 iteration 221 : loss : 0.208323, loss_ce: 0.080686
  3%|▉                             | 13/400 [05:57<2:56:42, 27.40s/it]2021-11-30 13:21:08,670 iteration 222 : loss : 0.222367, loss_ce: 0.117914
2021-11-30 13:21:10,227 iteration 223 : loss : 0.154801, loss_ce: 0.071674
2021-11-30 13:21:11,741 iteration 224 : loss : 0.268604, loss_ce: 0.133119
2021-11-30 13:21:13,346 iteration 225 : loss : 0.289467, loss_ce: 0.090482
2021-11-30 13:21:14,862 iteration 226 : loss : 0.171050, loss_ce: 0.066295
2021-11-30 13:21:16,419 iteration 227 : loss : 0.220199, loss_ce: 0.094916
2021-11-30 13:21:17,936 iteration 228 : loss : 0.214451, loss_ce: 0.094365
2021-11-30 13:21:19,411 iteration 229 : loss : 0.206213, loss_ce: 0.076107
2021-11-30 13:21:20,936 iteration 230 : loss : 0.174333, loss_ce: 0.073484
2021-11-30 13:21:22,507 iteration 231 : loss : 0.231066, loss_ce: 0.100884
2021-11-30 13:21:24,063 iteration 232 : loss : 0.167015, loss_ce: 0.074910
2021-11-30 13:21:25,536 iteration 233 : loss : 0.230259, loss_ce: 0.102962
2021-11-30 13:21:27,117 iteration 234 : loss : 0.186958, loss_ce: 0.078603
2021-11-30 13:21:28,620 iteration 235 : loss : 0.180869, loss_ce: 0.075269
2021-11-30 13:21:30,165 iteration 236 : loss : 0.171664, loss_ce: 0.076049
2021-11-30 13:21:31,662 iteration 237 : loss : 0.145605, loss_ce: 0.067509
2021-11-30 13:21:33,168 iteration 238 : loss : 0.179355, loss_ce: 0.094176
  4%|█                             | 14/400 [06:23<2:53:40, 27.00s/it]2021-11-30 13:21:34,673 iteration 239 : loss : 0.208698, loss_ce: 0.079952
2021-11-30 13:21:36,220 iteration 240 : loss : 0.173980, loss_ce: 0.085919
2021-11-30 13:21:37,787 iteration 241 : loss : 0.220790, loss_ce: 0.085484
2021-11-30 13:21:39,318 iteration 242 : loss : 0.207994, loss_ce: 0.110347
2021-11-30 13:21:40,984 iteration 243 : loss : 0.194727, loss_ce: 0.085884
2021-11-30 13:21:42,439 iteration 244 : loss : 0.187444, loss_ce: 0.055964
2021-11-30 13:21:43,966 iteration 245 : loss : 0.199095, loss_ce: 0.096071
2021-11-30 13:21:45,541 iteration 246 : loss : 0.178695, loss_ce: 0.078621
2021-11-30 13:21:47,058 iteration 247 : loss : 0.223578, loss_ce: 0.086596
2021-11-30 13:21:48,581 iteration 248 : loss : 0.154470, loss_ce: 0.056359
2021-11-30 13:21:50,077 iteration 249 : loss : 0.208103, loss_ce: 0.111272
2021-11-30 13:21:51,578 iteration 250 : loss : 0.197186, loss_ce: 0.083139
2021-11-30 13:21:53,045 iteration 251 : loss : 0.206390, loss_ce: 0.071783
2021-11-30 13:21:54,557 iteration 252 : loss : 0.127807, loss_ce: 0.059919
2021-11-30 13:21:56,096 iteration 253 : loss : 0.170519, loss_ce: 0.071365
2021-11-30 13:21:57,691 iteration 254 : loss : 0.297691, loss_ce: 0.107576
2021-11-30 13:21:57,691 Training Data Eval:
2021-11-30 13:22:05,258   Average segmentation loss on training set: 0.1631
2021-11-30 13:22:05,259 Validation Data Eval:
2021-11-30 13:22:07,877   Average segmentation loss on validation set: 0.2059
2021-11-30 13:22:09,900 Found new lowest validation loss at iteration 254! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/UNET_RUNMC/ADAM/ADAM_best_val_loss.pth
2021-11-30 13:22:11,321 iteration 255 : loss : 0.171579, loss_ce: 0.076161
  4%|█▏                            | 15/400 [07:01<3:14:48, 30.36s/it]2021-11-30 13:22:12,800 iteration 256 : loss : 0.197644, loss_ce: 0.079336
2021-11-30 13:22:14,273 iteration 257 : loss : 0.176270, loss_ce: 0.076125
2021-11-30 13:22:15,806 iteration 258 : loss : 0.171465, loss_ce: 0.075956
2021-11-30 13:22:17,223 iteration 259 : loss : 0.155870, loss_ce: 0.076394
2021-11-30 13:22:18,825 iteration 260 : loss : 0.150453, loss_ce: 0.068050
2021-11-30 13:22:20,369 iteration 261 : loss : 0.220698, loss_ce: 0.086996
2021-11-30 13:22:21,996 iteration 262 : loss : 0.183434, loss_ce: 0.094185
2021-11-30 13:22:23,524 iteration 263 : loss : 0.165720, loss_ce: 0.074535
2021-11-30 13:22:25,082 iteration 264 : loss : 0.237309, loss_ce: 0.116496
2021-11-30 13:22:26,563 iteration 265 : loss : 0.120101, loss_ce: 0.056262
2021-11-30 13:22:28,112 iteration 266 : loss : 0.149857, loss_ce: 0.077830
2021-11-30 13:22:29,633 iteration 267 : loss : 0.173906, loss_ce: 0.065508
2021-11-30 13:22:31,168 iteration 268 : loss : 0.186115, loss_ce: 0.087819
2021-11-30 13:22:32,876 iteration 269 : loss : 0.171476, loss_ce: 0.069823
2021-11-30 13:22:34,487 iteration 270 : loss : 0.174969, loss_ce: 0.070157
2021-11-30 13:22:35,896 iteration 271 : loss : 0.173535, loss_ce: 0.053673
2021-11-30 13:22:37,420 iteration 272 : loss : 0.199542, loss_ce: 0.086936
  4%|█▏                            | 16/400 [07:27<3:06:05, 29.08s/it]2021-11-30 13:22:38,938 iteration 273 : loss : 0.135383, loss_ce: 0.056087
2021-11-30 13:22:40,411 iteration 274 : loss : 0.120215, loss_ce: 0.051151
2021-11-30 13:22:41,894 iteration 275 : loss : 0.145924, loss_ce: 0.063185
2021-11-30 13:22:43,429 iteration 276 : loss : 0.143348, loss_ce: 0.069327
2021-11-30 13:22:44,980 iteration 277 : loss : 0.157603, loss_ce: 0.067494
2021-11-30 13:22:46,371 iteration 278 : loss : 0.180802, loss_ce: 0.066679
2021-11-30 13:22:47,845 iteration 279 : loss : 0.200798, loss_ce: 0.079384
2021-11-30 13:22:49,315 iteration 280 : loss : 0.175584, loss_ce: 0.078945
2021-11-30 13:22:50,830 iteration 281 : loss : 0.150623, loss_ce: 0.065846
2021-11-30 13:22:52,337 iteration 282 : loss : 0.195159, loss_ce: 0.080840
2021-11-30 13:22:53,813 iteration 283 : loss : 0.174962, loss_ce: 0.094668
2021-11-30 13:22:55,401 iteration 284 : loss : 0.190421, loss_ce: 0.088637
2021-11-30 13:22:56,867 iteration 285 : loss : 0.180049, loss_ce: 0.063283
2021-11-30 13:22:58,338 iteration 286 : loss : 0.157636, loss_ce: 0.077891
2021-11-30 13:22:59,930 iteration 287 : loss : 0.174013, loss_ce: 0.083884
2021-11-30 13:23:01,498 iteration 288 : loss : 0.231757, loss_ce: 0.110893
2021-11-30 13:23:03,009 iteration 289 : loss : 0.168022, loss_ce: 0.074317
  4%|█▎                            | 17/400 [07:53<2:58:54, 28.03s/it]2021-11-30 13:23:04,574 iteration 290 : loss : 0.122158, loss_ce: 0.053008
2021-11-30 13:23:06,064 iteration 291 : loss : 0.160946, loss_ce: 0.069592
2021-11-30 13:23:07,541 iteration 292 : loss : 0.114568, loss_ce: 0.051729
2021-11-30 13:23:09,057 iteration 293 : loss : 0.198425, loss_ce: 0.096785
2021-11-30 13:23:10,586 iteration 294 : loss : 0.176616, loss_ce: 0.076318
2021-11-30 13:23:12,195 iteration 295 : loss : 0.172123, loss_ce: 0.062110
2021-11-30 13:23:13,673 iteration 296 : loss : 0.162296, loss_ce: 0.062063
2021-11-30 13:23:15,199 iteration 297 : loss : 0.136726, loss_ce: 0.052472
2021-11-30 13:23:16,692 iteration 298 : loss : 0.137894, loss_ce: 0.055675
2021-11-30 13:23:18,198 iteration 299 : loss : 0.146633, loss_ce: 0.060322
2021-11-30 13:23:19,715 iteration 300 : loss : 0.176351, loss_ce: 0.073155
2021-11-30 13:23:21,241 iteration 301 : loss : 0.202487, loss_ce: 0.110448
2021-11-30 13:23:22,813 iteration 302 : loss : 0.120179, loss_ce: 0.054782
2021-11-30 13:23:24,364 iteration 303 : loss : 0.181600, loss_ce: 0.075446
2021-11-30 13:23:25,911 iteration 304 : loss : 0.169508, loss_ce: 0.070762
2021-11-30 13:23:27,484 iteration 305 : loss : 0.232309, loss_ce: 0.105000
2021-11-30 13:23:29,014 iteration 306 : loss : 0.186092, loss_ce: 0.094710
  4%|█▎                            | 18/400 [08:19<2:54:34, 27.42s/it]2021-11-30 13:23:30,565 iteration 307 : loss : 0.161506, loss_ce: 0.063839
2021-11-30 13:23:32,045 iteration 308 : loss : 0.140732, loss_ce: 0.072187
2021-11-30 13:23:33,593 iteration 309 : loss : 0.240515, loss_ce: 0.113616
2021-11-30 13:23:35,138 iteration 310 : loss : 0.179056, loss_ce: 0.082128
2021-11-30 13:23:36,611 iteration 311 : loss : 0.192429, loss_ce: 0.064692
2021-11-30 13:23:38,121 iteration 312 : loss : 0.164766, loss_ce: 0.073668
2021-11-30 13:23:39,656 iteration 313 : loss : 0.191957, loss_ce: 0.098515
2021-11-30 13:23:41,114 iteration 314 : loss : 0.119590, loss_ce: 0.056707
2021-11-30 13:23:42,617 iteration 315 : loss : 0.176088, loss_ce: 0.062030
2021-11-30 13:23:44,143 iteration 316 : loss : 0.191279, loss_ce: 0.075883
2021-11-30 13:23:45,658 iteration 317 : loss : 0.178505, loss_ce: 0.077445
2021-11-30 13:23:47,212 iteration 318 : loss : 0.129242, loss_ce: 0.058796
2021-11-30 13:23:48,684 iteration 319 : loss : 0.109087, loss_ce: 0.049363
2021-11-30 13:23:50,261 iteration 320 : loss : 0.118896, loss_ce: 0.046252
2021-11-30 13:23:51,810 iteration 321 : loss : 0.127233, loss_ce: 0.045387
2021-11-30 13:23:53,329 iteration 322 : loss : 0.207347, loss_ce: 0.092494
2021-11-30 13:23:54,899 iteration 323 : loss : 0.174334, loss_ce: 0.060387
  5%|█▍                            | 19/400 [08:45<2:51:11, 26.96s/it]2021-11-30 13:23:56,443 iteration 324 : loss : 0.161552, loss_ce: 0.065718
2021-11-30 13:23:57,960 iteration 325 : loss : 0.151347, loss_ce: 0.055879
2021-11-30 13:23:59,511 iteration 326 : loss : 0.136129, loss_ce: 0.059047
2021-11-30 13:24:01,108 iteration 327 : loss : 0.164755, loss_ce: 0.081758
2021-11-30 13:24:02,606 iteration 328 : loss : 0.128475, loss_ce: 0.057147
2021-11-30 13:24:04,154 iteration 329 : loss : 0.157726, loss_ce: 0.084494
2021-11-30 13:24:05,712 iteration 330 : loss : 0.155028, loss_ce: 0.066007
2021-11-30 13:24:07,181 iteration 331 : loss : 0.130154, loss_ce: 0.064918
2021-11-30 13:24:08,689 iteration 332 : loss : 0.132773, loss_ce: 0.049963
2021-11-30 13:24:10,230 iteration 333 : loss : 0.122322, loss_ce: 0.058058
2021-11-30 13:24:11,765 iteration 334 : loss : 0.141271, loss_ce: 0.064961
2021-11-30 13:24:13,262 iteration 335 : loss : 0.195759, loss_ce: 0.068453
2021-11-30 13:24:14,826 iteration 336 : loss : 0.123137, loss_ce: 0.050528
2021-11-30 13:24:16,330 iteration 337 : loss : 0.116179, loss_ce: 0.040413
2021-11-30 13:24:17,815 iteration 338 : loss : 0.196305, loss_ce: 0.093084
2021-11-30 13:24:19,306 iteration 339 : loss : 0.157776, loss_ce: 0.053212
2021-11-30 13:24:19,306 Training Data Eval:
2021-11-30 13:24:26,887   Average segmentation loss on training set: 0.1354
2021-11-30 13:24:26,887 Validation Data Eval:
2021-11-30 13:24:29,508   Average segmentation loss on validation set: 0.2361
2021-11-30 13:24:31,087 iteration 340 : loss : 0.150101, loss_ce: 0.065731
  5%|█▌                            | 20/400 [09:21<3:08:16, 29.73s/it]2021-11-30 13:24:32,694 iteration 341 : loss : 0.091440, loss_ce: 0.040905
2021-11-30 13:24:34,234 iteration 342 : loss : 0.125864, loss_ce: 0.044352
2021-11-30 13:24:35,774 iteration 343 : loss : 0.130106, loss_ce: 0.055720
2021-11-30 13:24:37,327 iteration 344 : loss : 0.168895, loss_ce: 0.079155
2021-11-30 13:24:38,838 iteration 345 : loss : 0.106905, loss_ce: 0.042144
2021-11-30 13:24:40,422 iteration 346 : loss : 0.166415, loss_ce: 0.076788
2021-11-30 13:24:41,903 iteration 347 : loss : 0.168884, loss_ce: 0.090148
2021-11-30 13:24:43,446 iteration 348 : loss : 0.152346, loss_ce: 0.063173
2021-11-30 13:24:45,082 iteration 349 : loss : 0.176555, loss_ce: 0.096617
2021-11-30 13:24:46,585 iteration 350 : loss : 0.162915, loss_ce: 0.066943
2021-11-30 13:24:48,157 iteration 351 : loss : 0.136838, loss_ce: 0.062194
2021-11-30 13:24:49,713 iteration 352 : loss : 0.162313, loss_ce: 0.076458
2021-11-30 13:24:51,176 iteration 353 : loss : 0.136674, loss_ce: 0.059940
2021-11-30 13:24:52,701 iteration 354 : loss : 0.158882, loss_ce: 0.062138
2021-11-30 13:24:54,272 iteration 355 : loss : 0.128438, loss_ce: 0.059611
2021-11-30 13:24:55,919 iteration 356 : loss : 0.141667, loss_ce: 0.068252
2021-11-30 13:24:57,368 iteration 357 : loss : 0.134777, loss_ce: 0.054859
  5%|█▌                            | 21/400 [09:47<3:01:14, 28.69s/it]2021-11-30 13:24:58,955 iteration 358 : loss : 0.112337, loss_ce: 0.052196
2021-11-30 13:25:00,541 iteration 359 : loss : 0.150219, loss_ce: 0.063492
2021-11-30 13:25:02,022 iteration 360 : loss : 0.104385, loss_ce: 0.039496
2021-11-30 13:25:03,579 iteration 361 : loss : 0.152618, loss_ce: 0.058355
2021-11-30 13:25:05,175 iteration 362 : loss : 0.116373, loss_ce: 0.037974
2021-11-30 13:25:06,775 iteration 363 : loss : 0.156499, loss_ce: 0.059598
2021-11-30 13:25:08,321 iteration 364 : loss : 0.147101, loss_ce: 0.052289
2021-11-30 13:25:09,763 iteration 365 : loss : 0.152508, loss_ce: 0.069772
2021-11-30 13:25:11,317 iteration 366 : loss : 0.133448, loss_ce: 0.058435
2021-11-30 13:25:12,782 iteration 367 : loss : 0.116927, loss_ce: 0.051297
2021-11-30 13:25:14,356 iteration 368 : loss : 0.122132, loss_ce: 0.048234
2021-11-30 13:25:15,956 iteration 369 : loss : 0.191772, loss_ce: 0.072616
2021-11-30 13:25:17,525 iteration 370 : loss : 0.132162, loss_ce: 0.070741
2021-11-30 13:25:19,051 iteration 371 : loss : 0.183224, loss_ce: 0.056614
2021-11-30 13:25:20,594 iteration 372 : loss : 0.218497, loss_ce: 0.107621
2021-11-30 13:25:22,075 iteration 373 : loss : 0.148811, loss_ce: 0.053713
2021-11-30 13:25:23,559 iteration 374 : loss : 0.167214, loss_ce: 0.069822
  6%|█▋                            | 22/400 [10:14<2:56:03, 27.94s/it]2021-11-30 13:25:25,167 iteration 375 : loss : 0.231792, loss_ce: 0.108083
2021-11-30 13:25:26,632 iteration 376 : loss : 0.086900, loss_ce: 0.033186
2021-11-30 13:25:28,141 iteration 377 : loss : 0.145727, loss_ce: 0.052121
2021-11-30 13:25:29,734 iteration 378 : loss : 0.140379, loss_ce: 0.049919
2021-11-30 13:25:31,189 iteration 379 : loss : 0.119418, loss_ce: 0.053490
2021-11-30 13:25:32,749 iteration 380 : loss : 0.116037, loss_ce: 0.048822
2021-11-30 13:25:34,278 iteration 381 : loss : 0.103369, loss_ce: 0.041679
2021-11-30 13:25:35,730 iteration 382 : loss : 0.133444, loss_ce: 0.068482
2021-11-30 13:25:37,244 iteration 383 : loss : 0.172892, loss_ce: 0.072405
2021-11-30 13:25:38,795 iteration 384 : loss : 0.105263, loss_ce: 0.046982
2021-11-30 13:25:40,299 iteration 385 : loss : 0.091094, loss_ce: 0.041536
2021-11-30 13:25:41,828 iteration 386 : loss : 0.144670, loss_ce: 0.051683
2021-11-30 13:25:43,370 iteration 387 : loss : 0.226003, loss_ce: 0.083212
2021-11-30 13:25:44,937 iteration 388 : loss : 0.148852, loss_ce: 0.067463
2021-11-30 13:25:46,481 iteration 389 : loss : 0.208628, loss_ce: 0.105816
2021-11-30 13:25:47,992 iteration 390 : loss : 0.107130, loss_ce: 0.046661
2021-11-30 13:25:49,487 iteration 391 : loss : 0.184637, loss_ce: 0.115692
  6%|█▋                            | 23/400 [10:40<2:51:45, 27.34s/it]2021-11-30 13:25:51,078 iteration 392 : loss : 0.140479, loss_ce: 0.084733
2021-11-30 13:25:52,558 iteration 393 : loss : 0.096733, loss_ce: 0.037043
2021-11-30 13:25:54,129 iteration 394 : loss : 0.110036, loss_ce: 0.041145
2021-11-30 13:25:55,673 iteration 395 : loss : 0.140143, loss_ce: 0.064772
2021-11-30 13:25:57,163 iteration 396 : loss : 0.123678, loss_ce: 0.048201
2021-11-30 13:25:58,678 iteration 397 : loss : 0.115425, loss_ce: 0.054815
2021-11-30 13:26:00,215 iteration 398 : loss : 0.094967, loss_ce: 0.042028
2021-11-30 13:26:01,630 iteration 399 : loss : 0.128946, loss_ce: 0.054512
2021-11-30 13:26:03,167 iteration 400 : loss : 0.102010, loss_ce: 0.042949
2021-11-30 13:26:04,738 iteration 401 : loss : 0.132379, loss_ce: 0.054552
2021-11-30 13:26:06,238 iteration 402 : loss : 0.101811, loss_ce: 0.050857
2021-11-30 13:26:07,742 iteration 403 : loss : 0.086386, loss_ce: 0.038335
2021-11-30 13:26:09,290 iteration 404 : loss : 0.115859, loss_ce: 0.052409
2021-11-30 13:26:10,881 iteration 405 : loss : 0.127185, loss_ce: 0.053374
2021-11-30 13:26:12,373 iteration 406 : loss : 0.125988, loss_ce: 0.048737
2021-11-30 13:26:13,833 iteration 407 : loss : 0.106000, loss_ce: 0.040460
2021-11-30 13:26:15,341 iteration 408 : loss : 0.168873, loss_ce: 0.071185
  6%|█▊                            | 24/400 [11:05<2:48:32, 26.89s/it]2021-11-30 13:26:16,941 iteration 409 : loss : 0.109175, loss_ce: 0.053121
2021-11-30 13:26:18,479 iteration 410 : loss : 0.116856, loss_ce: 0.045199
2021-11-30 13:26:19,992 iteration 411 : loss : 0.167617, loss_ce: 0.048223
2021-11-30 13:26:21,427 iteration 412 : loss : 0.074730, loss_ce: 0.031740
2021-11-30 13:26:22,957 iteration 413 : loss : 0.134581, loss_ce: 0.049896
2021-11-30 13:26:24,427 iteration 414 : loss : 0.175125, loss_ce: 0.097817
2021-11-30 13:26:25,854 iteration 415 : loss : 0.109337, loss_ce: 0.044658
2021-11-30 13:26:27,358 iteration 416 : loss : 0.138143, loss_ce: 0.069127
2021-11-30 13:26:28,833 iteration 417 : loss : 0.164393, loss_ce: 0.065380
2021-11-30 13:26:30,416 iteration 418 : loss : 0.129497, loss_ce: 0.057916
2021-11-30 13:26:31,907 iteration 419 : loss : 0.127149, loss_ce: 0.071856
2021-11-30 13:26:33,423 iteration 420 : loss : 0.099465, loss_ce: 0.042708
2021-11-30 13:26:34,882 iteration 421 : loss : 0.131312, loss_ce: 0.057740
2021-11-30 13:26:36,352 iteration 422 : loss : 0.146364, loss_ce: 0.065873
2021-11-30 13:26:37,835 iteration 423 : loss : 0.120370, loss_ce: 0.038442
2021-11-30 13:26:39,363 iteration 424 : loss : 0.142923, loss_ce: 0.060261
2021-11-30 13:26:39,363 Training Data Eval:
2021-11-30 13:26:46,944   Average segmentation loss on training set: 0.1456
2021-11-30 13:26:46,944 Validation Data Eval:
2021-11-30 13:26:49,565   Average segmentation loss on validation set: 0.1697
2021-11-30 13:26:51,476 Found new lowest validation loss at iteration 424! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/UNET_RUNMC/ADAM/ADAM_best_val_loss.pth
2021-11-30 13:26:52,890 iteration 425 : loss : 0.171780, loss_ce: 0.062668
  6%|█▉                            | 25/400 [11:43<3:08:03, 30.09s/it]2021-11-30 13:26:54,288 iteration 426 : loss : 0.104742, loss_ce: 0.038260
2021-11-30 13:26:55,747 iteration 427 : loss : 0.099286, loss_ce: 0.040037
2021-11-30 13:26:57,231 iteration 428 : loss : 0.122869, loss_ce: 0.045916
2021-11-30 13:26:58,693 iteration 429 : loss : 0.174310, loss_ce: 0.098170
2021-11-30 13:27:00,161 iteration 430 : loss : 0.135353, loss_ce: 0.048543
2021-11-30 13:27:01,639 iteration 431 : loss : 0.186828, loss_ce: 0.073951
2021-11-30 13:27:03,195 iteration 432 : loss : 0.088820, loss_ce: 0.042684
2021-11-30 13:27:04,787 iteration 433 : loss : 0.100584, loss_ce: 0.041500
2021-11-30 13:27:06,295 iteration 434 : loss : 0.085333, loss_ce: 0.035126
2021-11-30 13:27:07,754 iteration 435 : loss : 0.109327, loss_ce: 0.046888
2021-11-30 13:27:09,247 iteration 436 : loss : 0.092936, loss_ce: 0.042147
2021-11-30 13:27:10,756 iteration 437 : loss : 0.145268, loss_ce: 0.069061
2021-11-30 13:27:12,219 iteration 438 : loss : 0.134843, loss_ce: 0.046461
2021-11-30 13:27:13,733 iteration 439 : loss : 0.148686, loss_ce: 0.049613
2021-11-30 13:27:15,233 iteration 440 : loss : 0.113615, loss_ce: 0.043182
2021-11-30 13:27:16,788 iteration 441 : loss : 0.134139, loss_ce: 0.053043
2021-11-30 13:27:18,338 iteration 442 : loss : 0.129718, loss_ce: 0.063501
  6%|█▉                            | 26/400 [12:08<2:58:53, 28.70s/it]2021-11-30 13:27:19,867 iteration 443 : loss : 0.110494, loss_ce: 0.051489
2021-11-30 13:27:21,326 iteration 444 : loss : 0.105712, loss_ce: 0.042083
2021-11-30 13:27:22,834 iteration 445 : loss : 0.158359, loss_ce: 0.056464
2021-11-30 13:27:24,478 iteration 446 : loss : 0.141848, loss_ce: 0.059348
2021-11-30 13:27:26,046 iteration 447 : loss : 0.145397, loss_ce: 0.093987
2021-11-30 13:27:27,587 iteration 448 : loss : 0.215836, loss_ce: 0.063240
2021-11-30 13:27:29,085 iteration 449 : loss : 0.124933, loss_ce: 0.060807
2021-11-30 13:27:30,584 iteration 450 : loss : 0.111067, loss_ce: 0.039955
2021-11-30 13:27:32,170 iteration 451 : loss : 0.080148, loss_ce: 0.036851
2021-11-30 13:27:33,713 iteration 452 : loss : 0.115472, loss_ce: 0.043594
2021-11-30 13:27:35,255 iteration 453 : loss : 0.127770, loss_ce: 0.054600
2021-11-30 13:27:36,812 iteration 454 : loss : 0.136058, loss_ce: 0.047733
2021-11-30 13:27:38,382 iteration 455 : loss : 0.078949, loss_ce: 0.032437
2021-11-30 13:27:39,908 iteration 456 : loss : 0.122324, loss_ce: 0.042414
2021-11-30 13:27:41,419 iteration 457 : loss : 0.125509, loss_ce: 0.055538
2021-11-30 13:27:43,009 iteration 458 : loss : 0.112902, loss_ce: 0.058284
2021-11-30 13:27:44,470 iteration 459 : loss : 0.077293, loss_ce: 0.031889
  7%|██                            | 27/400 [12:34<2:53:36, 27.93s/it]2021-11-30 13:27:46,049 iteration 460 : loss : 0.105917, loss_ce: 0.056666
2021-11-30 13:27:47,580 iteration 461 : loss : 0.098664, loss_ce: 0.046660
2021-11-30 13:27:49,101 iteration 462 : loss : 0.135612, loss_ce: 0.064245
2021-11-30 13:27:50,683 iteration 463 : loss : 0.124492, loss_ce: 0.051925
2021-11-30 13:27:52,200 iteration 464 : loss : 0.098329, loss_ce: 0.039199
2021-11-30 13:27:53,662 iteration 465 : loss : 0.090882, loss_ce: 0.031802
2021-11-30 13:27:55,169 iteration 466 : loss : 0.102504, loss_ce: 0.034131
2021-11-30 13:27:56,678 iteration 467 : loss : 0.116556, loss_ce: 0.039160
2021-11-30 13:27:58,293 iteration 468 : loss : 0.116279, loss_ce: 0.056811
2021-11-30 13:27:59,784 iteration 469 : loss : 0.098435, loss_ce: 0.037296
2021-11-30 13:28:01,307 iteration 470 : loss : 0.134984, loss_ce: 0.052671
2021-11-30 13:28:02,814 iteration 471 : loss : 0.122825, loss_ce: 0.042850
2021-11-30 13:28:04,363 iteration 472 : loss : 0.120207, loss_ce: 0.047427
2021-11-30 13:28:06,009 iteration 473 : loss : 0.137186, loss_ce: 0.057140
2021-11-30 13:28:07,601 iteration 474 : loss : 0.174810, loss_ce: 0.081565
2021-11-30 13:28:09,095 iteration 475 : loss : 0.078352, loss_ce: 0.032687
2021-11-30 13:28:10,671 iteration 476 : loss : 0.136791, loss_ce: 0.077184
  7%|██                            | 28/400 [13:01<2:49:56, 27.41s/it]2021-11-30 13:28:12,244 iteration 477 : loss : 0.118494, loss_ce: 0.040628
2021-11-30 13:28:13,797 iteration 478 : loss : 0.088595, loss_ce: 0.034811
2021-11-30 13:28:15,306 iteration 479 : loss : 0.127807, loss_ce: 0.055705
2021-11-30 13:28:16,842 iteration 480 : loss : 0.095829, loss_ce: 0.051226
2021-11-30 13:28:18,288 iteration 481 : loss : 0.132515, loss_ce: 0.051623
2021-11-30 13:28:19,822 iteration 482 : loss : 0.148282, loss_ce: 0.044147
2021-11-30 13:28:21,362 iteration 483 : loss : 0.140746, loss_ce: 0.055043
2021-11-30 13:28:22,910 iteration 484 : loss : 0.168047, loss_ce: 0.074149
2021-11-30 13:28:24,399 iteration 485 : loss : 0.110220, loss_ce: 0.045666
2021-11-30 13:28:25,897 iteration 486 : loss : 0.115665, loss_ce: 0.038109
2021-11-30 13:28:27,475 iteration 487 : loss : 0.087358, loss_ce: 0.037097
2021-11-30 13:28:28,948 iteration 488 : loss : 0.111527, loss_ce: 0.044551
2021-11-30 13:28:30,468 iteration 489 : loss : 0.150064, loss_ce: 0.081345
2021-11-30 13:28:31,910 iteration 490 : loss : 0.117263, loss_ce: 0.045717
2021-11-30 13:28:33,431 iteration 491 : loss : 0.113103, loss_ce: 0.054702
2021-11-30 13:28:34,930 iteration 492 : loss : 0.069119, loss_ce: 0.035626
2021-11-30 13:28:36,472 iteration 493 : loss : 0.111623, loss_ce: 0.051426
  7%|██▏                           | 29/400 [13:26<2:46:29, 26.93s/it]2021-11-30 13:28:38,042 iteration 494 : loss : 0.100074, loss_ce: 0.045303
2021-11-30 13:28:39,582 iteration 495 : loss : 0.103963, loss_ce: 0.034813
2021-11-30 13:28:41,091 iteration 496 : loss : 0.133971, loss_ce: 0.069064
2021-11-30 13:28:42,624 iteration 497 : loss : 0.110616, loss_ce: 0.046913
2021-11-30 13:28:44,213 iteration 498 : loss : 0.121267, loss_ce: 0.056029
2021-11-30 13:28:45,657 iteration 499 : loss : 0.090630, loss_ce: 0.042966
2021-11-30 13:28:47,124 iteration 500 : loss : 0.090208, loss_ce: 0.032230
2021-11-30 13:28:48,597 iteration 501 : loss : 0.099947, loss_ce: 0.044494
2021-11-30 13:28:50,177 iteration 502 : loss : 0.084969, loss_ce: 0.034083
2021-11-30 13:28:51,642 iteration 503 : loss : 0.149741, loss_ce: 0.054250
2021-11-30 13:28:53,181 iteration 504 : loss : 0.087198, loss_ce: 0.032424
2021-11-30 13:28:54,664 iteration 505 : loss : 0.070767, loss_ce: 0.029296
2021-11-30 13:28:56,267 iteration 506 : loss : 0.067019, loss_ce: 0.028944
2021-11-30 13:28:57,783 iteration 507 : loss : 0.113045, loss_ce: 0.040413
2021-11-30 13:28:59,300 iteration 508 : loss : 0.126379, loss_ce: 0.051833
2021-11-30 13:29:00,865 iteration 509 : loss : 0.081881, loss_ce: 0.030691
2021-11-30 13:29:00,865 Training Data Eval:
2021-11-30 13:29:08,441   Average segmentation loss on training set: 0.0820
2021-11-30 13:29:08,441 Validation Data Eval:
2021-11-30 13:29:11,066   Average segmentation loss on validation set: 0.1095
2021-11-30 13:29:13,058 Found new lowest validation loss at iteration 509! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/UNET_RUNMC/ADAM/ADAM_best_val_loss.pth
2021-11-30 13:29:14,560 iteration 510 : loss : 0.089780, loss_ce: 0.042930
  8%|██▎                           | 30/400 [14:05<3:06:41, 30.27s/it]2021-11-30 13:29:16,038 iteration 511 : loss : 0.118134, loss_ce: 0.055709
2021-11-30 13:29:17,422 iteration 512 : loss : 0.102226, loss_ce: 0.047402
2021-11-30 13:29:18,841 iteration 513 : loss : 0.084351, loss_ce: 0.028089
2021-11-30 13:29:20,336 iteration 514 : loss : 0.079240, loss_ce: 0.036020
2021-11-30 13:29:21,826 iteration 515 : loss : 0.113353, loss_ce: 0.053782
2021-11-30 13:29:23,385 iteration 516 : loss : 0.107608, loss_ce: 0.046751
2021-11-30 13:29:24,963 iteration 517 : loss : 0.111722, loss_ce: 0.056969
2021-11-30 13:29:26,429 iteration 518 : loss : 0.088565, loss_ce: 0.033572
2021-11-30 13:29:27,948 iteration 519 : loss : 0.122385, loss_ce: 0.056016
2021-11-30 13:29:29,428 iteration 520 : loss : 0.103668, loss_ce: 0.045484
2021-11-30 13:29:30,940 iteration 521 : loss : 0.112815, loss_ce: 0.044826
2021-11-30 13:29:32,498 iteration 522 : loss : 0.108016, loss_ce: 0.045644
2021-11-30 13:29:34,079 iteration 523 : loss : 0.109805, loss_ce: 0.046780
2021-11-30 13:29:35,673 iteration 524 : loss : 0.117263, loss_ce: 0.046739
2021-11-30 13:29:37,172 iteration 525 : loss : 0.142624, loss_ce: 0.070652
2021-11-30 13:29:38,673 iteration 526 : loss : 0.115160, loss_ce: 0.049738
2021-11-30 13:29:40,192 iteration 527 : loss : 0.087662, loss_ce: 0.034387
  8%|██▎                           | 31/400 [14:30<2:57:37, 28.88s/it]2021-11-30 13:29:41,735 iteration 528 : loss : 0.095906, loss_ce: 0.049205
2021-11-30 13:29:43,244 iteration 529 : loss : 0.113323, loss_ce: 0.042093
2021-11-30 13:29:44,713 iteration 530 : loss : 0.104282, loss_ce: 0.042834
2021-11-30 13:29:46,177 iteration 531 : loss : 0.099583, loss_ce: 0.032310
2021-11-30 13:29:47,676 iteration 532 : loss : 0.096363, loss_ce: 0.044430
2021-11-30 13:29:49,279 iteration 533 : loss : 0.067752, loss_ce: 0.029720
2021-11-30 13:29:50,753 iteration 534 : loss : 0.077405, loss_ce: 0.037055
2021-11-30 13:29:52,310 iteration 535 : loss : 0.078218, loss_ce: 0.029793
2021-11-30 13:29:53,917 iteration 536 : loss : 0.120076, loss_ce: 0.061971
2021-11-30 13:29:55,516 iteration 537 : loss : 0.105619, loss_ce: 0.039969
2021-11-30 13:29:57,043 iteration 538 : loss : 0.096519, loss_ce: 0.045184
2021-11-30 13:29:58,539 iteration 539 : loss : 0.098811, loss_ce: 0.040611
2021-11-30 13:30:00,094 iteration 540 : loss : 0.096736, loss_ce: 0.035774
2021-11-30 13:30:01,602 iteration 541 : loss : 0.078242, loss_ce: 0.033885
2021-11-30 13:30:03,121 iteration 542 : loss : 0.096680, loss_ce: 0.040811
2021-11-30 13:30:04,601 iteration 543 : loss : 0.056184, loss_ce: 0.023780
2021-11-30 13:30:06,109 iteration 544 : loss : 0.082285, loss_ce: 0.031778
  8%|██▍                           | 32/400 [14:56<2:51:41, 27.99s/it]2021-11-30 13:30:07,680 iteration 545 : loss : 0.090187, loss_ce: 0.047516
2021-11-30 13:30:09,189 iteration 546 : loss : 0.078763, loss_ce: 0.030138
2021-11-30 13:30:10,707 iteration 547 : loss : 0.103673, loss_ce: 0.045742
2021-11-30 13:30:12,236 iteration 548 : loss : 0.165416, loss_ce: 0.061412
2021-11-30 13:30:13,761 iteration 549 : loss : 0.084568, loss_ce: 0.038514
2021-11-30 13:30:15,251 iteration 550 : loss : 0.078405, loss_ce: 0.033455
2021-11-30 13:30:16,760 iteration 551 : loss : 0.086539, loss_ce: 0.035510
2021-11-30 13:30:18,234 iteration 552 : loss : 0.083633, loss_ce: 0.033765
2021-11-30 13:30:19,775 iteration 553 : loss : 0.096329, loss_ce: 0.039751
2021-11-30 13:30:21,235 iteration 554 : loss : 0.084254, loss_ce: 0.040821
2021-11-30 13:30:22,747 iteration 555 : loss : 0.143781, loss_ce: 0.044136
2021-11-30 13:30:24,314 iteration 556 : loss : 0.090518, loss_ce: 0.042856
2021-11-30 13:30:25,755 iteration 557 : loss : 0.081544, loss_ce: 0.030580
2021-11-30 13:30:27,299 iteration 558 : loss : 0.093824, loss_ce: 0.034799
2021-11-30 13:30:28,801 iteration 559 : loss : 0.097833, loss_ce: 0.038015
2021-11-30 13:30:30,332 iteration 560 : loss : 0.085161, loss_ce: 0.023925
2021-11-30 13:30:31,920 iteration 561 : loss : 0.111219, loss_ce: 0.057802
  8%|██▍                           | 33/400 [15:22<2:47:13, 27.34s/it]2021-11-30 13:30:33,576 iteration 562 : loss : 0.131112, loss_ce: 0.060908
2021-11-30 13:30:35,005 iteration 563 : loss : 0.080889, loss_ce: 0.035963
2021-11-30 13:30:36,544 iteration 564 : loss : 0.092477, loss_ce: 0.043115
2021-11-30 13:30:38,104 iteration 565 : loss : 0.089290, loss_ce: 0.037268
2021-11-30 13:30:39,666 iteration 566 : loss : 0.079199, loss_ce: 0.033906
2021-11-30 13:30:41,155 iteration 567 : loss : 0.084018, loss_ce: 0.031052
2021-11-30 13:30:42,637 iteration 568 : loss : 0.149436, loss_ce: 0.049256
2021-11-30 13:30:44,172 iteration 569 : loss : 0.096526, loss_ce: 0.036662
2021-11-30 13:30:45,719 iteration 570 : loss : 0.084669, loss_ce: 0.042803
2021-11-30 13:30:47,228 iteration 571 : loss : 0.161726, loss_ce: 0.065135
2021-11-30 13:30:48,752 iteration 572 : loss : 0.118231, loss_ce: 0.036014
2021-11-30 13:30:50,256 iteration 573 : loss : 0.091320, loss_ce: 0.031573
2021-11-30 13:30:51,774 iteration 574 : loss : 0.112335, loss_ce: 0.037217
2021-11-30 13:30:53,347 iteration 575 : loss : 0.095102, loss_ce: 0.031500
2021-11-30 13:30:54,902 iteration 576 : loss : 0.098946, loss_ce: 0.041947
2021-11-30 13:30:56,424 iteration 577 : loss : 0.087082, loss_ce: 0.036992
2021-11-30 13:30:57,895 iteration 578 : loss : 0.106656, loss_ce: 0.044770
  8%|██▌                           | 34/400 [15:48<2:44:15, 26.93s/it]2021-11-30 13:30:59,593 iteration 579 : loss : 0.100630, loss_ce: 0.047673
2021-11-30 13:31:01,118 iteration 580 : loss : 0.099394, loss_ce: 0.039542
2021-11-30 13:31:02,678 iteration 581 : loss : 0.126235, loss_ce: 0.046161
2021-11-30 13:31:04,180 iteration 582 : loss : 0.100772, loss_ce: 0.043906
2021-11-30 13:31:05,706 iteration 583 : loss : 0.164894, loss_ce: 0.050520
2021-11-30 13:31:07,198 iteration 584 : loss : 0.067408, loss_ce: 0.030740
2021-11-30 13:31:08,779 iteration 585 : loss : 0.072996, loss_ce: 0.030896
2021-11-30 13:31:10,247 iteration 586 : loss : 0.112494, loss_ce: 0.045352
2021-11-30 13:31:11,712 iteration 587 : loss : 0.068638, loss_ce: 0.030674
2021-11-30 13:31:13,251 iteration 588 : loss : 0.100235, loss_ce: 0.038127
2021-11-30 13:31:14,758 iteration 589 : loss : 0.081570, loss_ce: 0.032139
2021-11-30 13:31:16,275 iteration 590 : loss : 0.087145, loss_ce: 0.033672
2021-11-30 13:31:17,812 iteration 591 : loss : 0.086730, loss_ce: 0.040442
2021-11-30 13:31:19,334 iteration 592 : loss : 0.084054, loss_ce: 0.035365
2021-11-30 13:31:20,895 iteration 593 : loss : 0.066120, loss_ce: 0.025636
2021-11-30 13:31:22,421 iteration 594 : loss : 0.093794, loss_ce: 0.041206
2021-11-30 13:31:22,421 Training Data Eval:
2021-11-30 13:31:29,976   Average segmentation loss on training set: 0.0984
2021-11-30 13:31:29,976 Validation Data Eval:
2021-11-30 13:31:32,597   Average segmentation loss on validation set: 0.1162
2021-11-30 13:31:34,195 iteration 595 : loss : 0.130007, loss_ce: 0.068645
  9%|██▋                           | 35/400 [16:24<3:00:55, 29.74s/it]2021-11-30 13:31:35,761 iteration 596 : loss : 0.087209, loss_ce: 0.036088
2021-11-30 13:31:37,255 iteration 597 : loss : 0.118807, loss_ce: 0.041659
2021-11-30 13:31:38,735 iteration 598 : loss : 0.060576, loss_ce: 0.024087
2021-11-30 13:31:40,245 iteration 599 : loss : 0.087451, loss_ce: 0.034509
2021-11-30 13:31:41,749 iteration 600 : loss : 0.085892, loss_ce: 0.038010
2021-11-30 13:31:43,279 iteration 601 : loss : 0.085130, loss_ce: 0.036377
2021-11-30 13:31:44,835 iteration 602 : loss : 0.072781, loss_ce: 0.031521
2021-11-30 13:31:46,293 iteration 603 : loss : 0.078548, loss_ce: 0.031926
2021-11-30 13:31:47,771 iteration 604 : loss : 0.092300, loss_ce: 0.037055
2021-11-30 13:31:49,236 iteration 605 : loss : 0.080045, loss_ce: 0.030574
2021-11-30 13:31:50,869 iteration 606 : loss : 0.074608, loss_ce: 0.034049
2021-11-30 13:31:52,374 iteration 607 : loss : 0.091956, loss_ce: 0.039595
2021-11-30 13:31:53,898 iteration 608 : loss : 0.091249, loss_ce: 0.048853
2021-11-30 13:31:55,347 iteration 609 : loss : 0.083218, loss_ce: 0.038152
2021-11-30 13:31:56,899 iteration 610 : loss : 0.077757, loss_ce: 0.031784
2021-11-30 13:31:58,516 iteration 611 : loss : 0.096853, loss_ce: 0.042861
2021-11-30 13:32:00,072 iteration 612 : loss : 0.087128, loss_ce: 0.031852
  9%|██▋                           | 36/400 [16:50<2:53:24, 28.58s/it]2021-11-30 13:32:01,658 iteration 613 : loss : 0.086856, loss_ce: 0.038295
2021-11-30 13:32:03,127 iteration 614 : loss : 0.085976, loss_ce: 0.032002
2021-11-30 13:32:04,601 iteration 615 : loss : 0.125808, loss_ce: 0.063619
2021-11-30 13:32:06,201 iteration 616 : loss : 0.086424, loss_ce: 0.039156
2021-11-30 13:32:07,689 iteration 617 : loss : 0.096280, loss_ce: 0.045437
2021-11-30 13:32:09,214 iteration 618 : loss : 0.116053, loss_ce: 0.030258
2021-11-30 13:32:10,737 iteration 619 : loss : 0.118425, loss_ce: 0.055501
2021-11-30 13:32:12,347 iteration 620 : loss : 0.181369, loss_ce: 0.063228
2021-11-30 13:32:13,861 iteration 621 : loss : 0.071372, loss_ce: 0.027584
2021-11-30 13:32:15,501 iteration 622 : loss : 0.113400, loss_ce: 0.042280
2021-11-30 13:32:17,122 iteration 623 : loss : 0.146637, loss_ce: 0.070395
2021-11-30 13:32:18,618 iteration 624 : loss : 0.111941, loss_ce: 0.032212
2021-11-30 13:32:20,085 iteration 625 : loss : 0.079569, loss_ce: 0.034858
2021-11-30 13:32:21,640 iteration 626 : loss : 0.085659, loss_ce: 0.034852
2021-11-30 13:32:23,217 iteration 627 : loss : 0.134842, loss_ce: 0.053505
2021-11-30 13:32:24,825 iteration 628 : loss : 0.119576, loss_ce: 0.048984
2021-11-30 13:32:26,326 iteration 629 : loss : 0.088121, loss_ce: 0.040271
  9%|██▊                           | 37/400 [17:16<2:48:41, 27.88s/it]2021-11-30 13:32:27,916 iteration 630 : loss : 0.084385, loss_ce: 0.039258
2021-11-30 13:32:29,426 iteration 631 : loss : 0.053870, loss_ce: 0.025583
2021-11-30 13:32:30,927 iteration 632 : loss : 0.114278, loss_ce: 0.046795
2021-11-30 13:32:32,513 iteration 633 : loss : 0.102793, loss_ce: 0.041766
2021-11-30 13:32:34,039 iteration 634 : loss : 0.116525, loss_ce: 0.038428
2021-11-30 13:32:35,671 iteration 635 : loss : 0.097913, loss_ce: 0.037714
2021-11-30 13:32:37,204 iteration 636 : loss : 0.096847, loss_ce: 0.037283
2021-11-30 13:32:38,657 iteration 637 : loss : 0.095566, loss_ce: 0.040354
2021-11-30 13:32:40,254 iteration 638 : loss : 0.138863, loss_ce: 0.048224
2021-11-30 13:32:41,748 iteration 639 : loss : 0.098089, loss_ce: 0.044721
2021-11-30 13:32:43,212 iteration 640 : loss : 0.132964, loss_ce: 0.040621
2021-11-30 13:32:44,683 iteration 641 : loss : 0.100826, loss_ce: 0.043975
2021-11-30 13:32:46,153 iteration 642 : loss : 0.091641, loss_ce: 0.025067
2021-11-30 13:32:47,670 iteration 643 : loss : 0.099851, loss_ce: 0.034708
2021-11-30 13:32:49,183 iteration 644 : loss : 0.105611, loss_ce: 0.043088
2021-11-30 13:32:50,651 iteration 645 : loss : 0.093779, loss_ce: 0.027822
2021-11-30 13:32:52,229 iteration 646 : loss : 0.099551, loss_ce: 0.048305
 10%|██▊                           | 38/400 [17:42<2:44:38, 27.29s/it]2021-11-30 13:32:53,759 iteration 647 : loss : 0.101757, loss_ce: 0.042404
2021-11-30 13:32:55,283 iteration 648 : loss : 0.074346, loss_ce: 0.033036
2021-11-30 13:32:56,828 iteration 649 : loss : 0.079588, loss_ce: 0.033818
2021-11-30 13:32:58,403 iteration 650 : loss : 0.110139, loss_ce: 0.043290
2021-11-30 13:32:59,914 iteration 651 : loss : 0.076490, loss_ce: 0.028649
2021-11-30 13:33:01,324 iteration 652 : loss : 0.064256, loss_ce: 0.024106
2021-11-30 13:33:02,909 iteration 653 : loss : 0.107857, loss_ce: 0.041251
2021-11-30 13:33:04,389 iteration 654 : loss : 0.083251, loss_ce: 0.028847
2021-11-30 13:33:05,905 iteration 655 : loss : 0.115830, loss_ce: 0.040345
2021-11-30 13:33:07,442 iteration 656 : loss : 0.072408, loss_ce: 0.028133
2021-11-30 13:33:09,023 iteration 657 : loss : 0.055694, loss_ce: 0.020728
2021-11-30 13:33:10,552 iteration 658 : loss : 0.078909, loss_ce: 0.027001
2021-11-30 13:33:12,085 iteration 659 : loss : 0.115082, loss_ce: 0.041141
2021-11-30 13:33:13,564 iteration 660 : loss : 0.070907, loss_ce: 0.037604
2021-11-30 13:33:15,112 iteration 661 : loss : 0.091898, loss_ce: 0.037513
2021-11-30 13:33:16,733 iteration 662 : loss : 0.146824, loss_ce: 0.035101
2021-11-30 13:33:18,257 iteration 663 : loss : 0.090385, loss_ce: 0.036823
 10%|██▉                           | 39/400 [18:08<2:41:54, 26.91s/it]2021-11-30 13:33:19,846 iteration 664 : loss : 0.080138, loss_ce: 0.037940
2021-11-30 13:33:21,308 iteration 665 : loss : 0.063398, loss_ce: 0.030955
2021-11-30 13:33:22,805 iteration 666 : loss : 0.061085, loss_ce: 0.022444
2021-11-30 13:33:24,355 iteration 667 : loss : 0.055659, loss_ce: 0.023866
2021-11-30 13:33:25,875 iteration 668 : loss : 0.081802, loss_ce: 0.034715
2021-11-30 13:33:27,373 iteration 669 : loss : 0.078754, loss_ce: 0.030723
2021-11-30 13:33:29,013 iteration 670 : loss : 0.101179, loss_ce: 0.039172
2021-11-30 13:33:30,517 iteration 671 : loss : 0.089448, loss_ce: 0.030244
2021-11-30 13:33:32,086 iteration 672 : loss : 0.062172, loss_ce: 0.022670
2021-11-30 13:33:33,636 iteration 673 : loss : 0.085333, loss_ce: 0.035050
2021-11-30 13:33:35,179 iteration 674 : loss : 0.093708, loss_ce: 0.051093
2021-11-30 13:33:36,769 iteration 675 : loss : 0.129109, loss_ce: 0.056100
2021-11-30 13:33:38,284 iteration 676 : loss : 0.094991, loss_ce: 0.035759
2021-11-30 13:33:39,803 iteration 677 : loss : 0.057933, loss_ce: 0.026324
2021-11-30 13:33:41,354 iteration 678 : loss : 0.098175, loss_ce: 0.036370
2021-11-30 13:33:42,895 iteration 679 : loss : 0.114581, loss_ce: 0.050457
2021-11-30 13:33:42,895 Training Data Eval:
2021-11-30 13:33:50,441   Average segmentation loss on training set: 0.0930
2021-11-30 13:33:50,441 Validation Data Eval:
2021-11-30 13:33:53,057   Average segmentation loss on validation set: 0.1832
2021-11-30 13:33:54,579 iteration 680 : loss : 0.070220, loss_ce: 0.024918
 10%|███                           | 40/400 [18:45<2:58:24, 29.73s/it]2021-11-30 13:33:56,174 iteration 681 : loss : 0.065563, loss_ce: 0.023671
2021-11-30 13:33:57,633 iteration 682 : loss : 0.074553, loss_ce: 0.027564
2021-11-30 13:33:59,161 iteration 683 : loss : 0.096263, loss_ce: 0.041438
2021-11-30 13:34:00,646 iteration 684 : loss : 0.098691, loss_ce: 0.037757
2021-11-30 13:34:02,224 iteration 685 : loss : 0.075552, loss_ce: 0.033156
2021-11-30 13:34:03,740 iteration 686 : loss : 0.109454, loss_ce: 0.043146
2021-11-30 13:34:05,263 iteration 687 : loss : 0.077897, loss_ce: 0.035417
2021-11-30 13:34:06,757 iteration 688 : loss : 0.116171, loss_ce: 0.036705
2021-11-30 13:34:08,298 iteration 689 : loss : 0.067696, loss_ce: 0.028351
2021-11-30 13:34:09,831 iteration 690 : loss : 0.083635, loss_ce: 0.028567
2021-11-30 13:34:11,354 iteration 691 : loss : 0.078351, loss_ce: 0.032785
2021-11-30 13:34:12,923 iteration 692 : loss : 0.078592, loss_ce: 0.030598
2021-11-30 13:34:14,379 iteration 693 : loss : 0.069832, loss_ce: 0.035448
2021-11-30 13:34:15,923 iteration 694 : loss : 0.087476, loss_ce: 0.037770
2021-11-30 13:34:17,407 iteration 695 : loss : 0.083012, loss_ce: 0.037249
2021-11-30 13:34:18,989 iteration 696 : loss : 0.071215, loss_ce: 0.031780
2021-11-30 13:34:20,504 iteration 697 : loss : 0.069222, loss_ce: 0.029128
 10%|███                           | 41/400 [19:11<2:51:05, 28.59s/it]2021-11-30 13:34:22,032 iteration 698 : loss : 0.120761, loss_ce: 0.042484
2021-11-30 13:34:23,593 iteration 699 : loss : 0.088386, loss_ce: 0.041850
2021-11-30 13:34:25,093 iteration 700 : loss : 0.094509, loss_ce: 0.038117
2021-11-30 13:34:26,593 iteration 701 : loss : 0.101714, loss_ce: 0.053573
2021-11-30 13:34:28,166 iteration 702 : loss : 0.098761, loss_ce: 0.034211
2021-11-30 13:34:29,778 iteration 703 : loss : 0.059425, loss_ce: 0.024511
2021-11-30 13:34:31,243 iteration 704 : loss : 0.078591, loss_ce: 0.031998
2021-11-30 13:34:32,760 iteration 705 : loss : 0.078980, loss_ce: 0.030808
2021-11-30 13:34:34,295 iteration 706 : loss : 0.066250, loss_ce: 0.025678
2021-11-30 13:34:35,746 iteration 707 : loss : 0.058050, loss_ce: 0.025379
2021-11-30 13:34:37,271 iteration 708 : loss : 0.058575, loss_ce: 0.020881
2021-11-30 13:34:38,789 iteration 709 : loss : 0.093475, loss_ce: 0.038576
2021-11-30 13:34:40,353 iteration 710 : loss : 0.093525, loss_ce: 0.040807
2021-11-30 13:34:41,890 iteration 711 : loss : 0.077756, loss_ce: 0.031884
2021-11-30 13:34:43,488 iteration 712 : loss : 0.097740, loss_ce: 0.036724
2021-11-30 13:34:44,993 iteration 713 : loss : 0.067942, loss_ce: 0.031232
2021-11-30 13:34:46,583 iteration 714 : loss : 0.104793, loss_ce: 0.038506
 10%|███▏                          | 42/400 [19:37<2:46:06, 27.84s/it]2021-11-30 13:34:48,187 iteration 715 : loss : 0.066084, loss_ce: 0.024175
2021-11-30 13:34:49,750 iteration 716 : loss : 0.054574, loss_ce: 0.024210
2021-11-30 13:34:51,268 iteration 717 : loss : 0.069259, loss_ce: 0.027162
2021-11-30 13:34:52,796 iteration 718 : loss : 0.085404, loss_ce: 0.041110
2021-11-30 13:34:54,363 iteration 719 : loss : 0.085630, loss_ce: 0.031885
2021-11-30 13:34:55,879 iteration 720 : loss : 0.074427, loss_ce: 0.026880
2021-11-30 13:34:57,397 iteration 721 : loss : 0.110376, loss_ce: 0.035252
2021-11-30 13:34:58,899 iteration 722 : loss : 0.080251, loss_ce: 0.027181
2021-11-30 13:35:00,454 iteration 723 : loss : 0.081958, loss_ce: 0.040688
2021-11-30 13:35:01,942 iteration 724 : loss : 0.112755, loss_ce: 0.046149
2021-11-30 13:35:03,523 iteration 725 : loss : 0.083544, loss_ce: 0.030956
2021-11-30 13:35:05,028 iteration 726 : loss : 0.087930, loss_ce: 0.035463
2021-11-30 13:35:06,479 iteration 727 : loss : 0.055622, loss_ce: 0.022581
2021-11-30 13:35:08,032 iteration 728 : loss : 0.067641, loss_ce: 0.029451
2021-11-30 13:35:09,594 iteration 729 : loss : 0.063452, loss_ce: 0.026245
2021-11-30 13:35:11,121 iteration 730 : loss : 0.063992, loss_ce: 0.025179
2021-11-30 13:35:12,576 iteration 731 : loss : 0.056541, loss_ce: 0.020622
 11%|███▏                          | 43/400 [20:03<2:42:20, 27.28s/it]2021-11-30 13:35:14,080 iteration 732 : loss : 0.067555, loss_ce: 0.030945
2021-11-30 13:35:15,540 iteration 733 : loss : 0.069306, loss_ce: 0.034772
2021-11-30 13:35:17,100 iteration 734 : loss : 0.072879, loss_ce: 0.031424
2021-11-30 13:35:18,617 iteration 735 : loss : 0.106259, loss_ce: 0.042724
2021-11-30 13:35:20,106 iteration 736 : loss : 0.069139, loss_ce: 0.031158
2021-11-30 13:35:21,739 iteration 737 : loss : 0.084625, loss_ce: 0.037450
2021-11-30 13:35:23,189 iteration 738 : loss : 0.076509, loss_ce: 0.033288
2021-11-30 13:35:24,737 iteration 739 : loss : 0.095525, loss_ce: 0.038334
2021-11-30 13:35:26,242 iteration 740 : loss : 0.071557, loss_ce: 0.027262
2021-11-30 13:35:27,722 iteration 741 : loss : 0.084080, loss_ce: 0.031795
2021-11-30 13:35:29,182 iteration 742 : loss : 0.068044, loss_ce: 0.032535
2021-11-30 13:35:30,725 iteration 743 : loss : 0.075342, loss_ce: 0.028485
2021-11-30 13:35:32,268 iteration 744 : loss : 0.083305, loss_ce: 0.035431
2021-11-30 13:35:33,755 iteration 745 : loss : 0.103231, loss_ce: 0.024260
2021-11-30 13:35:35,249 iteration 746 : loss : 0.081444, loss_ce: 0.032269
2021-11-30 13:35:36,730 iteration 747 : loss : 0.082360, loss_ce: 0.033445
2021-11-30 13:35:38,206 iteration 748 : loss : 0.064688, loss_ce: 0.028259
 11%|███▎                          | 44/400 [20:28<2:38:56, 26.79s/it]2021-11-30 13:35:39,716 iteration 749 : loss : 0.157967, loss_ce: 0.033951
2021-11-30 13:35:41,216 iteration 750 : loss : 0.071726, loss_ce: 0.028674
2021-11-30 13:35:42,742 iteration 751 : loss : 0.058079, loss_ce: 0.017748
2021-11-30 13:35:44,231 iteration 752 : loss : 0.138442, loss_ce: 0.069777
2021-11-30 13:35:45,698 iteration 753 : loss : 0.082959, loss_ce: 0.036940
2021-11-30 13:35:47,179 iteration 754 : loss : 0.099548, loss_ce: 0.036363
2021-11-30 13:35:48,616 iteration 755 : loss : 0.080189, loss_ce: 0.040525
2021-11-30 13:35:50,065 iteration 756 : loss : 0.050409, loss_ce: 0.017771
2021-11-30 13:35:51,576 iteration 757 : loss : 0.103422, loss_ce: 0.055202
2021-11-30 13:35:53,169 iteration 758 : loss : 0.111661, loss_ce: 0.049940
2021-11-30 13:35:54,804 iteration 759 : loss : 0.095575, loss_ce: 0.038741
2021-11-30 13:35:56,291 iteration 760 : loss : 0.102436, loss_ce: 0.061908
2021-11-30 13:35:57,817 iteration 761 : loss : 0.067093, loss_ce: 0.028677
2021-11-30 13:35:59,380 iteration 762 : loss : 0.088056, loss_ce: 0.035420
2021-11-30 13:36:00,943 iteration 763 : loss : 0.086340, loss_ce: 0.040758
2021-11-30 13:36:02,443 iteration 764 : loss : 0.079441, loss_ce: 0.035776
2021-11-30 13:36:02,443 Training Data Eval:
2021-11-30 13:36:10,011   Average segmentation loss on training set: 0.0949
2021-11-30 13:36:10,012 Validation Data Eval:
2021-11-30 13:36:12,626   Average segmentation loss on validation set: 0.1417
2021-11-30 13:36:14,323 iteration 765 : loss : 0.087677, loss_ce: 0.036739
 11%|███▍                          | 45/400 [21:04<2:55:03, 29.59s/it]2021-11-30 13:36:15,926 iteration 766 : loss : 0.087932, loss_ce: 0.032268
2021-11-30 13:36:17,478 iteration 767 : loss : 0.080317, loss_ce: 0.028999
2021-11-30 13:36:19,025 iteration 768 : loss : 0.081454, loss_ce: 0.027532
2021-11-30 13:36:20,597 iteration 769 : loss : 0.077758, loss_ce: 0.034306
2021-11-30 13:36:22,054 iteration 770 : loss : 0.072136, loss_ce: 0.030265
2021-11-30 13:36:23,581 iteration 771 : loss : 0.121832, loss_ce: 0.037524
2021-11-30 13:36:25,101 iteration 772 : loss : 0.069833, loss_ce: 0.028252
2021-11-30 13:36:26,660 iteration 773 : loss : 0.104175, loss_ce: 0.028413
2021-11-30 13:36:28,299 iteration 774 : loss : 0.080354, loss_ce: 0.036811
2021-11-30 13:36:29,794 iteration 775 : loss : 0.088244, loss_ce: 0.046534
2021-11-30 13:36:31,281 iteration 776 : loss : 0.085741, loss_ce: 0.033254
2021-11-30 13:36:32,986 iteration 777 : loss : 0.132910, loss_ce: 0.066907
2021-11-30 13:36:34,438 iteration 778 : loss : 0.094023, loss_ce: 0.033299
2021-11-30 13:36:36,015 iteration 779 : loss : 0.088468, loss_ce: 0.038819
2021-11-30 13:36:37,593 iteration 780 : loss : 0.088693, loss_ce: 0.033193
2021-11-30 13:36:39,079 iteration 781 : loss : 0.082067, loss_ce: 0.049036
2021-11-30 13:36:40,540 iteration 782 : loss : 0.064702, loss_ce: 0.032750
 12%|███▍                          | 46/400 [21:31<2:48:36, 28.58s/it]2021-11-30 13:36:42,104 iteration 783 : loss : 0.074983, loss_ce: 0.033329
2021-11-30 13:36:43,603 iteration 784 : loss : 0.094707, loss_ce: 0.033209
2021-11-30 13:36:45,140 iteration 785 : loss : 0.087059, loss_ce: 0.038539
2021-11-30 13:36:46,654 iteration 786 : loss : 0.078775, loss_ce: 0.028648
2021-11-30 13:36:48,166 iteration 787 : loss : 0.067413, loss_ce: 0.026409
2021-11-30 13:36:49,739 iteration 788 : loss : 0.084600, loss_ce: 0.036541
2021-11-30 13:36:51,171 iteration 789 : loss : 0.084572, loss_ce: 0.029304
2021-11-30 13:36:52,742 iteration 790 : loss : 0.064914, loss_ce: 0.026053
2021-11-30 13:36:54,260 iteration 791 : loss : 0.055138, loss_ce: 0.024147
2021-11-30 13:36:55,737 iteration 792 : loss : 0.058592, loss_ce: 0.026241
2021-11-30 13:36:57,318 iteration 793 : loss : 0.083706, loss_ce: 0.042739
2021-11-30 13:36:58,747 iteration 794 : loss : 0.056665, loss_ce: 0.024907
2021-11-30 13:37:00,220 iteration 795 : loss : 0.071965, loss_ce: 0.027956
2021-11-30 13:37:01,691 iteration 796 : loss : 0.064385, loss_ce: 0.030086
2021-11-30 13:37:03,247 iteration 797 : loss : 0.101515, loss_ce: 0.040939
2021-11-30 13:37:04,747 iteration 798 : loss : 0.068584, loss_ce: 0.025345
2021-11-30 13:37:06,200 iteration 799 : loss : 0.052268, loss_ce: 0.023912
 12%|███▌                          | 47/400 [21:56<2:42:58, 27.70s/it]2021-11-30 13:37:07,867 iteration 800 : loss : 0.098021, loss_ce: 0.034801
2021-11-30 13:37:09,411 iteration 801 : loss : 0.081786, loss_ce: 0.035296
2021-11-30 13:37:10,936 iteration 802 : loss : 0.068958, loss_ce: 0.023639
2021-11-30 13:37:12,471 iteration 803 : loss : 0.075460, loss_ce: 0.037070
2021-11-30 13:37:14,080 iteration 804 : loss : 0.124873, loss_ce: 0.055478
2021-11-30 13:37:15,744 iteration 805 : loss : 0.066655, loss_ce: 0.023567
2021-11-30 13:37:17,244 iteration 806 : loss : 0.087308, loss_ce: 0.039006
2021-11-30 13:37:18,699 iteration 807 : loss : 0.067593, loss_ce: 0.026301
2021-11-30 13:37:20,255 iteration 808 : loss : 0.082140, loss_ce: 0.037576
2021-11-30 13:37:21,795 iteration 809 : loss : 0.068011, loss_ce: 0.023239
2021-11-30 13:37:23,293 iteration 810 : loss : 0.092597, loss_ce: 0.034688
2021-11-30 13:37:24,749 iteration 811 : loss : 0.110901, loss_ce: 0.062112
2021-11-30 13:37:26,244 iteration 812 : loss : 0.087590, loss_ce: 0.041390
2021-11-30 13:37:27,762 iteration 813 : loss : 0.092252, loss_ce: 0.029799
2021-11-30 13:37:29,405 iteration 814 : loss : 0.099833, loss_ce: 0.034961
2021-11-30 13:37:30,999 iteration 815 : loss : 0.083874, loss_ce: 0.034578
2021-11-30 13:37:32,535 iteration 816 : loss : 0.052457, loss_ce: 0.020861
 12%|███▌                          | 48/400 [22:23<2:40:06, 27.29s/it]2021-11-30 13:37:34,078 iteration 817 : loss : 0.093818, loss_ce: 0.042189
2021-11-30 13:37:35,537 iteration 818 : loss : 0.058266, loss_ce: 0.025568
2021-11-30 13:37:37,065 iteration 819 : loss : 0.067265, loss_ce: 0.023886
2021-11-30 13:37:38,517 iteration 820 : loss : 0.054598, loss_ce: 0.022958
2021-11-30 13:37:40,084 iteration 821 : loss : 0.077856, loss_ce: 0.029057
2021-11-30 13:37:41,642 iteration 822 : loss : 0.086020, loss_ce: 0.030104
2021-11-30 13:37:43,104 iteration 823 : loss : 0.044054, loss_ce: 0.018203
2021-11-30 13:37:44,564 iteration 824 : loss : 0.076461, loss_ce: 0.035200
2021-11-30 13:37:46,092 iteration 825 : loss : 0.058222, loss_ce: 0.022793
2021-11-30 13:37:47,582 iteration 826 : loss : 0.107034, loss_ce: 0.030638
2021-11-30 13:37:49,081 iteration 827 : loss : 0.100596, loss_ce: 0.034649
2021-11-30 13:37:50,600 iteration 828 : loss : 0.063678, loss_ce: 0.024820
2021-11-30 13:37:52,122 iteration 829 : loss : 0.103919, loss_ce: 0.038934
2021-11-30 13:37:53,689 iteration 830 : loss : 0.070146, loss_ce: 0.024771
2021-11-30 13:37:55,222 iteration 831 : loss : 0.075171, loss_ce: 0.034843
2021-11-30 13:37:56,727 iteration 832 : loss : 0.056391, loss_ce: 0.022317
2021-11-30 13:37:58,282 iteration 833 : loss : 0.074457, loss_ce: 0.036884
 12%|███▋                          | 49/400 [22:48<2:36:56, 26.83s/it]2021-11-30 13:37:59,831 iteration 834 : loss : 0.056482, loss_ce: 0.023655
2021-11-30 13:38:01,258 iteration 835 : loss : 0.072336, loss_ce: 0.021999
2021-11-30 13:38:02,775 iteration 836 : loss : 0.057301, loss_ce: 0.027351
2021-11-30 13:38:04,258 iteration 837 : loss : 0.061590, loss_ce: 0.033905
2021-11-30 13:38:05,713 iteration 838 : loss : 0.066597, loss_ce: 0.025052
2021-11-30 13:38:07,236 iteration 839 : loss : 0.090960, loss_ce: 0.037108
2021-11-30 13:38:08,731 iteration 840 : loss : 0.070633, loss_ce: 0.025629
2021-11-30 13:38:10,202 iteration 841 : loss : 0.067019, loss_ce: 0.027377
2021-11-30 13:38:11,714 iteration 842 : loss : 0.075064, loss_ce: 0.030021
2021-11-30 13:38:13,307 iteration 843 : loss : 0.084183, loss_ce: 0.030835
2021-11-30 13:38:14,797 iteration 844 : loss : 0.065404, loss_ce: 0.022606
2021-11-30 13:38:16,332 iteration 845 : loss : 0.083572, loss_ce: 0.029499
2021-11-30 13:38:17,950 iteration 846 : loss : 0.054837, loss_ce: 0.024487
2021-11-30 13:38:19,466 iteration 847 : loss : 0.060075, loss_ce: 0.027849
2021-11-30 13:38:20,889 iteration 848 : loss : 0.061429, loss_ce: 0.024914
2021-11-30 13:38:22,417 iteration 849 : loss : 0.060016, loss_ce: 0.025277
2021-11-30 13:38:22,417 Training Data Eval:
2021-11-30 13:38:30,023   Average segmentation loss on training set: 0.0483
2021-11-30 13:38:30,024 Validation Data Eval:
2021-11-30 13:38:32,649   Average segmentation loss on validation set: 0.0950
2021-11-30 13:38:34,576 Found new lowest validation loss at iteration 849! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/UNET_RUNMC/ADAM/ADAM_best_val_loss.pth
2021-11-30 13:38:36,068 iteration 850 : loss : 0.082219, loss_ce: 0.030537
 12%|███▊                          | 50/400 [23:26<2:55:40, 30.11s/it]2021-11-30 13:38:37,548 iteration 851 : loss : 0.058965, loss_ce: 0.025127
2021-11-30 13:38:38,947 iteration 852 : loss : 0.050836, loss_ce: 0.020662
2021-11-30 13:38:40,469 iteration 853 : loss : 0.065769, loss_ce: 0.027844
2021-11-30 13:38:41,995 iteration 854 : loss : 0.053774, loss_ce: 0.016639
2021-11-30 13:38:43,539 iteration 855 : loss : 0.073111, loss_ce: 0.029054
2021-11-30 13:38:45,093 iteration 856 : loss : 0.058882, loss_ce: 0.020764
2021-11-30 13:38:46,567 iteration 857 : loss : 0.061224, loss_ce: 0.027472
2021-11-30 13:38:47,996 iteration 858 : loss : 0.053526, loss_ce: 0.025833
2021-11-30 13:38:49,482 iteration 859 : loss : 0.063058, loss_ce: 0.027512
2021-11-30 13:38:50,949 iteration 860 : loss : 0.081550, loss_ce: 0.020729
2021-11-30 13:38:52,517 iteration 861 : loss : 0.073773, loss_ce: 0.031736
2021-11-30 13:38:53,954 iteration 862 : loss : 0.070850, loss_ce: 0.022425
2021-11-30 13:38:55,533 iteration 863 : loss : 0.076274, loss_ce: 0.031692
2021-11-30 13:38:57,080 iteration 864 : loss : 0.076914, loss_ce: 0.033731
2021-11-30 13:38:58,510 iteration 865 : loss : 0.050253, loss_ce: 0.021612
2021-11-30 13:39:00,075 iteration 866 : loss : 0.086355, loss_ce: 0.041865
2021-11-30 13:39:01,525 iteration 867 : loss : 0.039135, loss_ce: 0.015901
 13%|███▊                          | 51/400 [23:52<2:47:02, 28.72s/it]2021-11-30 13:39:03,130 iteration 868 : loss : 0.089066, loss_ce: 0.031536
2021-11-30 13:39:04,625 iteration 869 : loss : 0.064588, loss_ce: 0.024707
2021-11-30 13:39:06,046 iteration 870 : loss : 0.056612, loss_ce: 0.020356
2021-11-30 13:39:07,513 iteration 871 : loss : 0.063307, loss_ce: 0.027173
2021-11-30 13:39:09,001 iteration 872 : loss : 0.066370, loss_ce: 0.039001
2021-11-30 13:39:10,595 iteration 873 : loss : 0.074019, loss_ce: 0.026572
2021-11-30 13:39:12,026 iteration 874 : loss : 0.049954, loss_ce: 0.021760
2021-11-30 13:39:13,671 iteration 875 : loss : 0.098111, loss_ce: 0.036185
2021-11-30 13:39:15,178 iteration 876 : loss : 0.043959, loss_ce: 0.020022
2021-11-30 13:39:16,614 iteration 877 : loss : 0.054742, loss_ce: 0.019474
2021-11-30 13:39:18,159 iteration 878 : loss : 0.077072, loss_ce: 0.032148
2021-11-30 13:39:19,641 iteration 879 : loss : 0.080797, loss_ce: 0.038857
2021-11-30 13:39:21,178 iteration 880 : loss : 0.053003, loss_ce: 0.018048
2021-11-30 13:39:22,666 iteration 881 : loss : 0.072475, loss_ce: 0.029548
2021-11-30 13:39:24,217 iteration 882 : loss : 0.075912, loss_ce: 0.030269
2021-11-30 13:39:25,723 iteration 883 : loss : 0.072101, loss_ce: 0.034961
2021-11-30 13:39:27,325 iteration 884 : loss : 0.086542, loss_ce: 0.041719
 13%|███▉                          | 52/400 [24:17<2:41:29, 27.84s/it]2021-11-30 13:39:28,914 iteration 885 : loss : 0.078459, loss_ce: 0.031151
2021-11-30 13:39:30,452 iteration 886 : loss : 0.074187, loss_ce: 0.029807
2021-11-30 13:39:32,004 iteration 887 : loss : 0.074022, loss_ce: 0.031540
2021-11-30 13:39:33,513 iteration 888 : loss : 0.058645, loss_ce: 0.022301
2021-11-30 13:39:35,099 iteration 889 : loss : 0.090592, loss_ce: 0.029681
2021-11-30 13:39:36,715 iteration 890 : loss : 0.077079, loss_ce: 0.027151
2021-11-30 13:39:38,223 iteration 891 : loss : 0.053179, loss_ce: 0.020170
2021-11-30 13:39:39,749 iteration 892 : loss : 0.059920, loss_ce: 0.029230
2021-11-30 13:39:41,252 iteration 893 : loss : 0.049834, loss_ce: 0.018584
2021-11-30 13:39:42,868 iteration 894 : loss : 0.064014, loss_ce: 0.025367
2021-11-30 13:39:44,353 iteration 895 : loss : 0.095081, loss_ce: 0.027803
2021-11-30 13:39:45,925 iteration 896 : loss : 0.074026, loss_ce: 0.030894
2021-11-30 13:39:47,515 iteration 897 : loss : 0.075889, loss_ce: 0.040542
2021-11-30 13:39:49,006 iteration 898 : loss : 0.081442, loss_ce: 0.040621
2021-11-30 13:39:50,507 iteration 899 : loss : 0.083797, loss_ce: 0.043410
2021-11-30 13:39:51,983 iteration 900 : loss : 0.060513, loss_ce: 0.028086
2021-11-30 13:39:53,491 iteration 901 : loss : 0.068420, loss_ce: 0.024251
 13%|███▉                          | 53/400 [24:44<2:38:06, 27.34s/it]2021-11-30 13:39:55,066 iteration 902 : loss : 0.061583, loss_ce: 0.024680
2021-11-30 13:39:56,659 iteration 903 : loss : 0.057244, loss_ce: 0.021897
2021-11-30 13:39:58,198 iteration 904 : loss : 0.067686, loss_ce: 0.022329
2021-11-30 13:39:59,734 iteration 905 : loss : 0.076852, loss_ce: 0.034517
2021-11-30 13:40:01,253 iteration 906 : loss : 0.056099, loss_ce: 0.024893
2021-11-30 13:40:02,833 iteration 907 : loss : 0.052035, loss_ce: 0.019511
2021-11-30 13:40:04,263 iteration 908 : loss : 0.050225, loss_ce: 0.021071
2021-11-30 13:40:05,819 iteration 909 : loss : 0.062154, loss_ce: 0.027145
2021-11-30 13:40:07,261 iteration 910 : loss : 0.094657, loss_ce: 0.039674
2021-11-30 13:40:08,770 iteration 911 : loss : 0.050938, loss_ce: 0.021029
2021-11-30 13:40:10,271 iteration 912 : loss : 0.059039, loss_ce: 0.022175
2021-11-30 13:40:11,761 iteration 913 : loss : 0.068763, loss_ce: 0.025042
2021-11-30 13:40:13,274 iteration 914 : loss : 0.080846, loss_ce: 0.034774
2021-11-30 13:40:14,747 iteration 915 : loss : 0.118309, loss_ce: 0.036093
2021-11-30 13:40:16,239 iteration 916 : loss : 0.050915, loss_ce: 0.019131
2021-11-30 13:40:17,770 iteration 917 : loss : 0.089077, loss_ce: 0.033634
2021-11-30 13:40:19,340 iteration 918 : loss : 0.104365, loss_ce: 0.035584
 14%|████                          | 54/400 [25:09<2:35:04, 26.89s/it]2021-11-30 13:40:20,930 iteration 919 : loss : 0.058795, loss_ce: 0.025665
2021-11-30 13:40:22,458 iteration 920 : loss : 0.076058, loss_ce: 0.031749
2021-11-30 13:40:24,011 iteration 921 : loss : 0.066999, loss_ce: 0.024455
2021-11-30 13:40:25,570 iteration 922 : loss : 0.066527, loss_ce: 0.033444
2021-11-30 13:40:27,062 iteration 923 : loss : 0.055209, loss_ce: 0.025970
2021-11-30 13:40:28,621 iteration 924 : loss : 0.083547, loss_ce: 0.029860
2021-11-30 13:40:30,098 iteration 925 : loss : 0.051512, loss_ce: 0.020049
2021-11-30 13:40:31,678 iteration 926 : loss : 0.050083, loss_ce: 0.022444
2021-11-30 13:40:33,121 iteration 927 : loss : 0.088401, loss_ce: 0.034471
2021-11-30 13:40:34,636 iteration 928 : loss : 0.081828, loss_ce: 0.036883
2021-11-30 13:40:36,203 iteration 929 : loss : 0.072031, loss_ce: 0.026371
2021-11-30 13:40:37,743 iteration 930 : loss : 0.070324, loss_ce: 0.029801
2021-11-30 13:40:39,264 iteration 931 : loss : 0.097682, loss_ce: 0.025786
2021-11-30 13:40:40,799 iteration 932 : loss : 0.062728, loss_ce: 0.022274
2021-11-30 13:40:42,281 iteration 933 : loss : 0.093577, loss_ce: 0.033700
2021-11-30 13:40:43,819 iteration 934 : loss : 0.055641, loss_ce: 0.023875
2021-11-30 13:40:43,819 Training Data Eval:
2021-11-30 13:40:51,405   Average segmentation loss on training set: 0.0660
2021-11-30 13:40:51,405 Validation Data Eval:
2021-11-30 13:40:54,028   Average segmentation loss on validation set: 0.1720
2021-11-30 13:40:55,625 iteration 935 : loss : 0.077608, loss_ce: 0.024377
 14%|████▏                         | 55/400 [25:46<2:50:49, 29.71s/it]2021-11-30 13:40:57,152 iteration 936 : loss : 0.057435, loss_ce: 0.019468
2021-11-30 13:40:58,686 iteration 937 : loss : 0.058392, loss_ce: 0.018167
2021-11-30 13:41:00,264 iteration 938 : loss : 0.058470, loss_ce: 0.020180
2021-11-30 13:41:01,741 iteration 939 : loss : 0.060558, loss_ce: 0.020154
2021-11-30 13:41:03,280 iteration 940 : loss : 0.058971, loss_ce: 0.024433
2021-11-30 13:41:04,898 iteration 941 : loss : 0.062102, loss_ce: 0.026564
2021-11-30 13:41:06,393 iteration 942 : loss : 0.054441, loss_ce: 0.020817
2021-11-30 13:41:07,890 iteration 943 : loss : 0.065592, loss_ce: 0.032478
2021-11-30 13:41:09,370 iteration 944 : loss : 0.058321, loss_ce: 0.023388
2021-11-30 13:41:10,875 iteration 945 : loss : 0.073207, loss_ce: 0.031468
2021-11-30 13:41:12,358 iteration 946 : loss : 0.044536, loss_ce: 0.019998
2021-11-30 13:41:13,828 iteration 947 : loss : 0.075109, loss_ce: 0.027014
2021-11-30 13:41:15,305 iteration 948 : loss : 0.078922, loss_ce: 0.027528
2021-11-30 13:41:16,813 iteration 949 : loss : 0.056187, loss_ce: 0.020251
2021-11-30 13:41:18,309 iteration 950 : loss : 0.089999, loss_ce: 0.044328
2021-11-30 13:41:19,859 iteration 951 : loss : 0.069539, loss_ce: 0.042423
2021-11-30 13:41:21,337 iteration 952 : loss : 0.067938, loss_ce: 0.032258
 14%|████▏                         | 56/400 [26:11<2:43:27, 28.51s/it]2021-11-30 13:41:22,912 iteration 953 : loss : 0.071166, loss_ce: 0.026014
2021-11-30 13:41:24,464 iteration 954 : loss : 0.070021, loss_ce: 0.026938
2021-11-30 13:41:25,900 iteration 955 : loss : 0.038673, loss_ce: 0.017580
2021-11-30 13:41:27,440 iteration 956 : loss : 0.056079, loss_ce: 0.020469
2021-11-30 13:41:28,964 iteration 957 : loss : 0.052377, loss_ce: 0.020004
2021-11-30 13:41:30,521 iteration 958 : loss : 0.068706, loss_ce: 0.022967
2021-11-30 13:41:32,124 iteration 959 : loss : 0.065094, loss_ce: 0.032928
2021-11-30 13:41:33,772 iteration 960 : loss : 0.061548, loss_ce: 0.027694
2021-11-30 13:41:35,257 iteration 961 : loss : 0.091666, loss_ce: 0.030622
2021-11-30 13:41:36,717 iteration 962 : loss : 0.064618, loss_ce: 0.019509
2021-11-30 13:41:38,299 iteration 963 : loss : 0.062910, loss_ce: 0.024264
2021-11-30 13:41:39,836 iteration 964 : loss : 0.064456, loss_ce: 0.033560
2021-11-30 13:41:41,328 iteration 965 : loss : 0.057088, loss_ce: 0.027631
2021-11-30 13:41:42,855 iteration 966 : loss : 0.060025, loss_ce: 0.025787
2021-11-30 13:41:44,383 iteration 967 : loss : 0.043244, loss_ce: 0.018223
2021-11-30 13:41:45,880 iteration 968 : loss : 0.118562, loss_ce: 0.036554
2021-11-30 13:41:47,408 iteration 969 : loss : 0.059242, loss_ce: 0.024191
 14%|████▎                         | 57/400 [26:37<2:38:48, 27.78s/it]2021-11-30 13:41:48,951 iteration 970 : loss : 0.060970, loss_ce: 0.030506
2021-11-30 13:41:50,485 iteration 971 : loss : 0.083429, loss_ce: 0.024926
2021-11-30 13:41:51,929 iteration 972 : loss : 0.058340, loss_ce: 0.028223
2021-11-30 13:41:53,456 iteration 973 : loss : 0.050179, loss_ce: 0.017435
2021-11-30 13:41:54,938 iteration 974 : loss : 0.070366, loss_ce: 0.026589
2021-11-30 13:41:56,502 iteration 975 : loss : 0.072036, loss_ce: 0.028009
2021-11-30 13:41:57,997 iteration 976 : loss : 0.060601, loss_ce: 0.025365
2021-11-30 13:41:59,498 iteration 977 : loss : 0.043803, loss_ce: 0.016042
2021-11-30 13:42:01,058 iteration 978 : loss : 0.044211, loss_ce: 0.016510
2021-11-30 13:42:02,554 iteration 979 : loss : 0.067836, loss_ce: 0.037073
2021-11-30 13:42:04,059 iteration 980 : loss : 0.041125, loss_ce: 0.014546
2021-11-30 13:42:05,668 iteration 981 : loss : 0.071676, loss_ce: 0.036201
2021-11-30 13:42:07,169 iteration 982 : loss : 0.059081, loss_ce: 0.030048
2021-11-30 13:42:08,725 iteration 983 : loss : 0.087515, loss_ce: 0.028475
2021-11-30 13:42:10,162 iteration 984 : loss : 0.057701, loss_ce: 0.030397
2021-11-30 13:42:11,685 iteration 985 : loss : 0.055868, loss_ce: 0.017978
2021-11-30 13:42:13,259 iteration 986 : loss : 0.067947, loss_ce: 0.027608
 14%|████▎                         | 58/400 [27:03<2:35:03, 27.20s/it]2021-11-30 13:42:14,878 iteration 987 : loss : 0.058999, loss_ce: 0.028311
2021-11-30 13:42:16,407 iteration 988 : loss : 0.068310, loss_ce: 0.030880
2021-11-30 13:42:17,928 iteration 989 : loss : 0.056863, loss_ce: 0.020848
2021-11-30 13:42:19,454 iteration 990 : loss : 0.055734, loss_ce: 0.024559
2021-11-30 13:42:20,959 iteration 991 : loss : 0.049246, loss_ce: 0.022259
2021-11-30 13:42:22,535 iteration 992 : loss : 0.060487, loss_ce: 0.028287
2021-11-30 13:42:24,070 iteration 993 : loss : 0.047217, loss_ce: 0.018016
2021-11-30 13:42:25,711 iteration 994 : loss : 0.061938, loss_ce: 0.024885
2021-11-30 13:42:27,238 iteration 995 : loss : 0.095925, loss_ce: 0.033155
2021-11-30 13:42:28,811 iteration 996 : loss : 0.040697, loss_ce: 0.018015
2021-11-30 13:42:30,383 iteration 997 : loss : 0.077019, loss_ce: 0.026377
2021-11-30 13:42:31,850 iteration 998 : loss : 0.057016, loss_ce: 0.018290
2021-11-30 13:42:33,415 iteration 999 : loss : 0.061524, loss_ce: 0.022107
2021-11-30 13:42:34,899 iteration 1000 : loss : 0.071377, loss_ce: 0.023018
2021-11-30 13:42:36,384 iteration 1001 : loss : 0.075121, loss_ce: 0.018846
2021-11-30 13:42:38,019 iteration 1002 : loss : 0.057102, loss_ce: 0.020951
2021-11-30 13:42:39,623 iteration 1003 : loss : 0.081094, loss_ce: 0.032047
 15%|████▍                         | 59/400 [27:30<2:33:10, 26.95s/it]2021-11-30 13:42:41,185 iteration 1004 : loss : 0.120316, loss_ce: 0.048575
2021-11-30 13:42:42,691 iteration 1005 : loss : 0.054406, loss_ce: 0.023892
2021-11-30 13:42:44,287 iteration 1006 : loss : 0.071714, loss_ce: 0.027588
2021-11-30 13:42:45,773 iteration 1007 : loss : 0.059478, loss_ce: 0.032051
2021-11-30 13:42:47,256 iteration 1008 : loss : 0.103836, loss_ce: 0.040585
2021-11-30 13:42:48,749 iteration 1009 : loss : 0.072484, loss_ce: 0.027833
2021-11-30 13:42:50,239 iteration 1010 : loss : 0.069906, loss_ce: 0.026639
2021-11-30 13:42:51,811 iteration 1011 : loss : 0.065122, loss_ce: 0.028469
2021-11-30 13:42:53,330 iteration 1012 : loss : 0.050862, loss_ce: 0.019084
2021-11-30 13:42:54,784 iteration 1013 : loss : 0.066366, loss_ce: 0.021855
2021-11-30 13:42:56,310 iteration 1014 : loss : 0.065443, loss_ce: 0.026858
2021-11-30 13:42:57,754 iteration 1015 : loss : 0.065642, loss_ce: 0.025718
2021-11-30 13:42:59,286 iteration 1016 : loss : 0.065187, loss_ce: 0.028896
2021-11-30 13:43:00,725 iteration 1017 : loss : 0.040828, loss_ce: 0.015159
2021-11-30 13:43:02,164 iteration 1018 : loss : 0.066610, loss_ce: 0.025545
2021-11-30 13:43:03,692 iteration 1019 : loss : 0.095066, loss_ce: 0.042626
2021-11-30 13:43:03,692 Training Data Eval:
2021-11-30 13:43:11,274   Average segmentation loss on training set: 0.0463
2021-11-30 13:43:11,275 Validation Data Eval:
2021-11-30 13:43:13,899   Average segmentation loss on validation set: 0.1007
2021-11-30 13:43:15,372 iteration 1020 : loss : 0.046745, loss_ce: 0.017708
 15%|████▌                         | 60/400 [28:05<2:47:40, 29.59s/it]2021-11-30 13:43:17,006 iteration 1021 : loss : 0.112742, loss_ce: 0.036174
2021-11-30 13:43:18,528 iteration 1022 : loss : 0.074897, loss_ce: 0.031251
2021-11-30 13:43:20,047 iteration 1023 : loss : 0.119911, loss_ce: 0.038410
2021-11-30 13:43:21,618 iteration 1024 : loss : 0.058140, loss_ce: 0.021900
2021-11-30 13:43:23,181 iteration 1025 : loss : 0.049453, loss_ce: 0.023495
2021-11-30 13:43:24,621 iteration 1026 : loss : 0.051512, loss_ce: 0.018317
2021-11-30 13:43:26,180 iteration 1027 : loss : 0.104973, loss_ce: 0.039977
2021-11-30 13:43:27,742 iteration 1028 : loss : 0.063642, loss_ce: 0.028350
2021-11-30 13:43:29,243 iteration 1029 : loss : 0.047318, loss_ce: 0.021181
2021-11-30 13:43:30,772 iteration 1030 : loss : 0.047344, loss_ce: 0.017074
2021-11-30 13:43:32,351 iteration 1031 : loss : 0.088232, loss_ce: 0.042469
2021-11-30 13:43:33,895 iteration 1032 : loss : 0.060175, loss_ce: 0.026785
2021-11-30 13:43:35,385 iteration 1033 : loss : 0.067322, loss_ce: 0.023088
2021-11-30 13:43:36,986 iteration 1034 : loss : 0.088740, loss_ce: 0.040508
2021-11-30 13:43:38,518 iteration 1035 : loss : 0.056531, loss_ce: 0.024243
2021-11-30 13:43:40,050 iteration 1036 : loss : 0.060401, loss_ce: 0.025068
2021-11-30 13:43:41,536 iteration 1037 : loss : 0.061744, loss_ce: 0.020221
 15%|████▌                         | 61/400 [28:32<2:41:21, 28.56s/it]2021-11-30 13:43:43,120 iteration 1038 : loss : 0.063745, loss_ce: 0.028162
2021-11-30 13:43:44,629 iteration 1039 : loss : 0.057739, loss_ce: 0.029208
2021-11-30 13:43:46,177 iteration 1040 : loss : 0.077116, loss_ce: 0.037221
2021-11-30 13:43:47,704 iteration 1041 : loss : 0.054713, loss_ce: 0.024830
2021-11-30 13:43:49,244 iteration 1042 : loss : 0.076254, loss_ce: 0.033470
2021-11-30 13:43:50,762 iteration 1043 : loss : 0.071651, loss_ce: 0.024455
2021-11-30 13:43:52,311 iteration 1044 : loss : 0.061020, loss_ce: 0.023267
2021-11-30 13:43:53,755 iteration 1045 : loss : 0.052888, loss_ce: 0.024559
2021-11-30 13:43:55,234 iteration 1046 : loss : 0.100040, loss_ce: 0.028332
2021-11-30 13:43:56,800 iteration 1047 : loss : 0.085435, loss_ce: 0.029502
2021-11-30 13:43:58,300 iteration 1048 : loss : 0.060159, loss_ce: 0.024161
2021-11-30 13:43:59,813 iteration 1049 : loss : 0.060916, loss_ce: 0.023924
2021-11-30 13:44:01,384 iteration 1050 : loss : 0.085485, loss_ce: 0.026361
2021-11-30 13:44:02,899 iteration 1051 : loss : 0.063048, loss_ce: 0.026156
2021-11-30 13:44:04,426 iteration 1052 : loss : 0.079022, loss_ce: 0.035053
2021-11-30 13:44:05,879 iteration 1053 : loss : 0.070454, loss_ce: 0.020616
2021-11-30 13:44:07,474 iteration 1054 : loss : 0.061205, loss_ce: 0.026796
 16%|████▋                         | 62/400 [28:58<2:36:28, 27.78s/it]2021-11-30 13:44:09,032 iteration 1055 : loss : 0.045216, loss_ce: 0.018054
2021-11-30 13:44:10,520 iteration 1056 : loss : 0.064159, loss_ce: 0.032594
2021-11-30 13:44:12,007 iteration 1057 : loss : 0.100078, loss_ce: 0.050610
2021-11-30 13:44:13,530 iteration 1058 : loss : 0.063105, loss_ce: 0.029307
2021-11-30 13:44:14,976 iteration 1059 : loss : 0.069645, loss_ce: 0.025995
2021-11-30 13:44:16,483 iteration 1060 : loss : 0.051135, loss_ce: 0.019127
2021-11-30 13:44:18,023 iteration 1061 : loss : 0.048383, loss_ce: 0.018629
2021-11-30 13:44:19,554 iteration 1062 : loss : 0.069775, loss_ce: 0.027736
2021-11-30 13:44:21,143 iteration 1063 : loss : 0.083456, loss_ce: 0.025534
2021-11-30 13:44:22,641 iteration 1064 : loss : 0.072612, loss_ce: 0.021873
2021-11-30 13:44:24,092 iteration 1065 : loss : 0.054592, loss_ce: 0.021796
2021-11-30 13:44:25,655 iteration 1066 : loss : 0.048733, loss_ce: 0.019536
2021-11-30 13:44:27,163 iteration 1067 : loss : 0.124042, loss_ce: 0.025651
2021-11-30 13:44:28,727 iteration 1068 : loss : 0.089519, loss_ce: 0.041076
2021-11-30 13:44:30,260 iteration 1069 : loss : 0.070479, loss_ce: 0.027704
2021-11-30 13:44:31,770 iteration 1070 : loss : 0.055485, loss_ce: 0.021005
2021-11-30 13:44:33,279 iteration 1071 : loss : 0.057285, loss_ce: 0.026939
 16%|████▋                         | 63/400 [29:23<2:32:41, 27.18s/it]2021-11-30 13:44:34,917 iteration 1072 : loss : 0.066002, loss_ce: 0.022131
2021-11-30 13:44:36,398 iteration 1073 : loss : 0.090615, loss_ce: 0.024742
2021-11-30 13:44:37,905 iteration 1074 : loss : 0.049881, loss_ce: 0.018694
2021-11-30 13:44:39,464 iteration 1075 : loss : 0.076915, loss_ce: 0.025061
2021-11-30 13:44:40,938 iteration 1076 : loss : 0.051016, loss_ce: 0.018228
2021-11-30 13:44:42,443 iteration 1077 : loss : 0.051265, loss_ce: 0.017626
2021-11-30 13:44:44,013 iteration 1078 : loss : 0.068146, loss_ce: 0.039487
2021-11-30 13:44:45,501 iteration 1079 : loss : 0.039682, loss_ce: 0.016581
2021-11-30 13:44:46,978 iteration 1080 : loss : 0.050423, loss_ce: 0.021372
2021-11-30 13:44:48,516 iteration 1081 : loss : 0.071302, loss_ce: 0.025285
2021-11-30 13:44:50,050 iteration 1082 : loss : 0.064341, loss_ce: 0.033868
2021-11-30 13:44:51,608 iteration 1083 : loss : 0.056358, loss_ce: 0.025736
2021-11-30 13:44:53,101 iteration 1084 : loss : 0.069894, loss_ce: 0.036388
2021-11-30 13:44:54,690 iteration 1085 : loss : 0.058098, loss_ce: 0.022051
2021-11-30 13:44:56,185 iteration 1086 : loss : 0.059433, loss_ce: 0.023003
2021-11-30 13:44:57,700 iteration 1087 : loss : 0.047371, loss_ce: 0.019239
2021-11-30 13:44:59,270 iteration 1088 : loss : 0.052963, loss_ce: 0.023329
 16%|████▊                         | 64/400 [29:49<2:30:14, 26.83s/it]2021-11-30 13:45:00,795 iteration 1089 : loss : 0.065060, loss_ce: 0.024567
2021-11-30 13:45:02,284 iteration 1090 : loss : 0.060292, loss_ce: 0.029132
2021-11-30 13:45:03,800 iteration 1091 : loss : 0.058944, loss_ce: 0.027308
2021-11-30 13:45:05,314 iteration 1092 : loss : 0.060320, loss_ce: 0.025617
2021-11-30 13:45:06,863 iteration 1093 : loss : 0.060378, loss_ce: 0.021637
2021-11-30 13:45:08,444 iteration 1094 : loss : 0.059069, loss_ce: 0.026314
2021-11-30 13:45:09,934 iteration 1095 : loss : 0.045912, loss_ce: 0.019571
2021-11-30 13:45:11,544 iteration 1096 : loss : 0.066076, loss_ce: 0.028336
2021-11-30 13:45:13,061 iteration 1097 : loss : 0.073649, loss_ce: 0.030164
2021-11-30 13:45:14,529 iteration 1098 : loss : 0.040908, loss_ce: 0.019143
2021-11-30 13:45:16,091 iteration 1099 : loss : 0.053199, loss_ce: 0.018553
2021-11-30 13:45:17,693 iteration 1100 : loss : 0.043755, loss_ce: 0.016208
2021-11-30 13:45:19,196 iteration 1101 : loss : 0.052531, loss_ce: 0.024226
2021-11-30 13:45:20,776 iteration 1102 : loss : 0.074729, loss_ce: 0.021038
2021-11-30 13:45:22,275 iteration 1103 : loss : 0.064789, loss_ce: 0.021775
2021-11-30 13:45:23,774 iteration 1104 : loss : 0.061641, loss_ce: 0.026670
2021-11-30 13:45:23,774 Training Data Eval:
2021-11-30 13:45:31,354   Average segmentation loss on training set: 0.0468
2021-11-30 13:45:31,355 Validation Data Eval:
2021-11-30 13:45:33,980   Average segmentation loss on validation set: 0.0941
2021-11-30 13:45:36,276 Found new lowest validation loss at iteration 1104! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/UNET_RUNMC/ADAM/ADAM_best_val_loss.pth
2021-11-30 13:45:37,774 iteration 1105 : loss : 0.058251, loss_ce: 0.017295
 16%|████▉                         | 65/400 [30:28<2:49:19, 30.33s/it]2021-11-30 13:45:39,157 iteration 1106 : loss : 0.060327, loss_ce: 0.020109
2021-11-30 13:45:40,556 iteration 1107 : loss : 0.060333, loss_ce: 0.032589
2021-11-30 13:45:42,004 iteration 1108 : loss : 0.070722, loss_ce: 0.015060
2021-11-30 13:45:43,435 iteration 1109 : loss : 0.043936, loss_ce: 0.018331
2021-11-30 13:45:44,970 iteration 1110 : loss : 0.045959, loss_ce: 0.019346
2021-11-30 13:45:46,458 iteration 1111 : loss : 0.045821, loss_ce: 0.019898
2021-11-30 13:45:47,964 iteration 1112 : loss : 0.050134, loss_ce: 0.019592
2021-11-30 13:45:49,464 iteration 1113 : loss : 0.059424, loss_ce: 0.019498
2021-11-30 13:45:51,034 iteration 1114 : loss : 0.060341, loss_ce: 0.028555
2021-11-30 13:45:52,669 iteration 1115 : loss : 0.058499, loss_ce: 0.028333
2021-11-30 13:45:54,218 iteration 1116 : loss : 0.062547, loss_ce: 0.020737
2021-11-30 13:45:55,835 iteration 1117 : loss : 0.055756, loss_ce: 0.021484
2021-11-30 13:45:57,396 iteration 1118 : loss : 0.076621, loss_ce: 0.025166
2021-11-30 13:45:58,887 iteration 1119 : loss : 0.044772, loss_ce: 0.021941
2021-11-30 13:46:00,378 iteration 1120 : loss : 0.069922, loss_ce: 0.024445
2021-11-30 13:46:01,919 iteration 1121 : loss : 0.066389, loss_ce: 0.020597
2021-11-30 13:46:03,444 iteration 1122 : loss : 0.072406, loss_ce: 0.034601
 16%|████▉                         | 66/400 [30:53<2:41:02, 28.93s/it]2021-11-30 13:46:04,972 iteration 1123 : loss : 0.105877, loss_ce: 0.030607
2021-11-30 13:46:06,536 iteration 1124 : loss : 0.051269, loss_ce: 0.022044
2021-11-30 13:46:08,049 iteration 1125 : loss : 0.042364, loss_ce: 0.014051
2021-11-30 13:46:09,545 iteration 1126 : loss : 0.076692, loss_ce: 0.028964
2021-11-30 13:46:11,042 iteration 1127 : loss : 0.071450, loss_ce: 0.028141
2021-11-30 13:46:12,615 iteration 1128 : loss : 0.083709, loss_ce: 0.031628
2021-11-30 13:46:14,184 iteration 1129 : loss : 0.070765, loss_ce: 0.023550
2021-11-30 13:46:15,680 iteration 1130 : loss : 0.051696, loss_ce: 0.023153
2021-11-30 13:46:17,175 iteration 1131 : loss : 0.055351, loss_ce: 0.023775
2021-11-30 13:46:18,728 iteration 1132 : loss : 0.068414, loss_ce: 0.025950
2021-11-30 13:46:20,194 iteration 1133 : loss : 0.042939, loss_ce: 0.020670
2021-11-30 13:46:21,710 iteration 1134 : loss : 0.084490, loss_ce: 0.028612
2021-11-30 13:46:23,202 iteration 1135 : loss : 0.059902, loss_ce: 0.025403
2021-11-30 13:46:24,707 iteration 1136 : loss : 0.039165, loss_ce: 0.014213
2021-11-30 13:46:26,208 iteration 1137 : loss : 0.081011, loss_ce: 0.033937
2021-11-30 13:46:27,757 iteration 1138 : loss : 0.058005, loss_ce: 0.026686
2021-11-30 13:46:29,284 iteration 1139 : loss : 0.061478, loss_ce: 0.023768
 17%|█████                         | 67/400 [31:19<2:35:25, 28.00s/it]2021-11-30 13:46:30,835 iteration 1140 : loss : 0.065348, loss_ce: 0.026160
2021-11-30 13:46:32,310 iteration 1141 : loss : 0.053585, loss_ce: 0.020343
2021-11-30 13:46:33,890 iteration 1142 : loss : 0.066167, loss_ce: 0.030447
2021-11-30 13:46:35,404 iteration 1143 : loss : 0.059242, loss_ce: 0.022758
2021-11-30 13:46:36,948 iteration 1144 : loss : 0.075958, loss_ce: 0.040482
2021-11-30 13:46:38,419 iteration 1145 : loss : 0.055185, loss_ce: 0.020122
2021-11-30 13:46:39,946 iteration 1146 : loss : 0.095647, loss_ce: 0.050412
2021-11-30 13:46:41,388 iteration 1147 : loss : 0.056383, loss_ce: 0.022562
2021-11-30 13:46:42,948 iteration 1148 : loss : 0.080361, loss_ce: 0.032596
2021-11-30 13:46:44,421 iteration 1149 : loss : 0.061478, loss_ce: 0.029767
2021-11-30 13:46:45,948 iteration 1150 : loss : 0.050174, loss_ce: 0.020230
2021-11-30 13:46:47,495 iteration 1151 : loss : 0.063094, loss_ce: 0.022737
2021-11-30 13:46:49,116 iteration 1152 : loss : 0.062947, loss_ce: 0.025362
2021-11-30 13:46:50,538 iteration 1153 : loss : 0.045541, loss_ce: 0.017453
2021-11-30 13:46:52,098 iteration 1154 : loss : 0.077362, loss_ce: 0.028709
2021-11-30 13:46:53,576 iteration 1155 : loss : 0.055207, loss_ce: 0.020018
2021-11-30 13:46:55,130 iteration 1156 : loss : 0.063046, loss_ce: 0.031821
 17%|█████                         | 68/400 [31:45<2:31:22, 27.36s/it]2021-11-30 13:46:56,649 iteration 1157 : loss : 0.127959, loss_ce: 0.035573
2021-11-30 13:46:58,197 iteration 1158 : loss : 0.061095, loss_ce: 0.021663
2021-11-30 13:46:59,789 iteration 1159 : loss : 0.048993, loss_ce: 0.015977
2021-11-30 13:47:01,416 iteration 1160 : loss : 0.063084, loss_ce: 0.026909
2021-11-30 13:47:02,981 iteration 1161 : loss : 0.042475, loss_ce: 0.019455
2021-11-30 13:47:04,518 iteration 1162 : loss : 0.056963, loss_ce: 0.020706
2021-11-30 13:47:06,000 iteration 1163 : loss : 0.065681, loss_ce: 0.032655
2021-11-30 13:47:07,505 iteration 1164 : loss : 0.075767, loss_ce: 0.026134
2021-11-30 13:47:09,016 iteration 1165 : loss : 0.048565, loss_ce: 0.025042
2021-11-30 13:47:10,617 iteration 1166 : loss : 0.037454, loss_ce: 0.012978
2021-11-30 13:47:12,102 iteration 1167 : loss : 0.050834, loss_ce: 0.025096
2021-11-30 13:47:13,609 iteration 1168 : loss : 0.062697, loss_ce: 0.029508
2021-11-30 13:47:15,089 iteration 1169 : loss : 0.062258, loss_ce: 0.026495
2021-11-30 13:47:16,579 iteration 1170 : loss : 0.072588, loss_ce: 0.028702
2021-11-30 13:47:18,104 iteration 1171 : loss : 0.063416, loss_ce: 0.019317
2021-11-30 13:47:19,628 iteration 1172 : loss : 0.050312, loss_ce: 0.024746
2021-11-30 13:47:21,185 iteration 1173 : loss : 0.061898, loss_ce: 0.025176
 17%|█████▏                        | 69/400 [32:11<2:28:45, 26.96s/it]2021-11-30 13:47:22,733 iteration 1174 : loss : 0.057258, loss_ce: 0.017817
2021-11-30 13:47:24,249 iteration 1175 : loss : 0.041690, loss_ce: 0.016820
2021-11-30 13:47:25,746 iteration 1176 : loss : 0.046573, loss_ce: 0.018423
2021-11-30 13:47:27,225 iteration 1177 : loss : 0.044496, loss_ce: 0.017030
2021-11-30 13:47:28,785 iteration 1178 : loss : 0.051033, loss_ce: 0.016913
2021-11-30 13:47:30,367 iteration 1179 : loss : 0.071383, loss_ce: 0.029092
2021-11-30 13:47:31,853 iteration 1180 : loss : 0.043656, loss_ce: 0.019383
2021-11-30 13:47:33,363 iteration 1181 : loss : 0.047467, loss_ce: 0.017356
2021-11-30 13:47:34,910 iteration 1182 : loss : 0.051964, loss_ce: 0.019682
2021-11-30 13:47:36,379 iteration 1183 : loss : 0.059137, loss_ce: 0.022297
2021-11-30 13:47:37,856 iteration 1184 : loss : 0.041011, loss_ce: 0.018406
2021-11-30 13:47:39,406 iteration 1185 : loss : 0.051893, loss_ce: 0.020583
2021-11-30 13:47:40,883 iteration 1186 : loss : 0.042544, loss_ce: 0.020333
2021-11-30 13:47:42,466 iteration 1187 : loss : 0.046768, loss_ce: 0.014828
2021-11-30 13:47:43,944 iteration 1188 : loss : 0.047995, loss_ce: 0.017981
2021-11-30 13:47:45,525 iteration 1189 : loss : 0.055372, loss_ce: 0.024364
2021-11-30 13:47:45,525 Training Data Eval:
2021-11-30 13:47:53,112   Average segmentation loss on training set: 0.0374
2021-11-30 13:47:53,113 Validation Data Eval:
2021-11-30 13:47:55,737   Average segmentation loss on validation set: 0.0802
2021-11-30 13:47:57,692 Found new lowest validation loss at iteration 1189! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/UNET_RUNMC/ADAM/ADAM_best_val_loss.pth
2021-11-30 13:47:59,135 iteration 1190 : loss : 0.069536, loss_ce: 0.031209
 18%|█████▎                        | 70/400 [32:49<2:46:26, 30.26s/it]2021-11-30 13:48:00,677 iteration 1191 : loss : 0.054706, loss_ce: 0.022049
2021-11-30 13:48:02,053 iteration 1192 : loss : 0.044076, loss_ce: 0.021267
2021-11-30 13:48:03,584 iteration 1193 : loss : 0.074383, loss_ce: 0.026153
2021-11-30 13:48:05,056 iteration 1194 : loss : 0.043675, loss_ce: 0.013227
2021-11-30 13:48:06,516 iteration 1195 : loss : 0.040456, loss_ce: 0.017822
2021-11-30 13:48:07,998 iteration 1196 : loss : 0.053828, loss_ce: 0.019555
2021-11-30 13:48:09,436 iteration 1197 : loss : 0.045508, loss_ce: 0.016816
2021-11-30 13:48:10,987 iteration 1198 : loss : 0.053801, loss_ce: 0.024633
2021-11-30 13:48:12,504 iteration 1199 : loss : 0.055873, loss_ce: 0.021475
2021-11-30 13:48:14,007 iteration 1200 : loss : 0.057533, loss_ce: 0.020088
2021-11-30 13:48:15,482 iteration 1201 : loss : 0.041828, loss_ce: 0.019123
2021-11-30 13:48:17,016 iteration 1202 : loss : 0.052892, loss_ce: 0.019387
2021-11-30 13:48:18,549 iteration 1203 : loss : 0.062581, loss_ce: 0.020182
2021-11-30 13:48:20,061 iteration 1204 : loss : 0.056051, loss_ce: 0.020100
2021-11-30 13:48:21,606 iteration 1205 : loss : 0.059837, loss_ce: 0.022888
2021-11-30 13:48:23,113 iteration 1206 : loss : 0.044811, loss_ce: 0.018319
2021-11-30 13:48:24,664 iteration 1207 : loss : 0.041253, loss_ce: 0.013366
 18%|█████▎                        | 71/400 [33:15<2:38:09, 28.84s/it]2021-11-30 13:48:26,251 iteration 1208 : loss : 0.060306, loss_ce: 0.029434
2021-11-30 13:48:27,788 iteration 1209 : loss : 0.040511, loss_ce: 0.015714
2021-11-30 13:48:29,295 iteration 1210 : loss : 0.052188, loss_ce: 0.019157
2021-11-30 13:48:30,760 iteration 1211 : loss : 0.032108, loss_ce: 0.012028
2021-11-30 13:48:32,221 iteration 1212 : loss : 0.054737, loss_ce: 0.019122
2021-11-30 13:48:33,855 iteration 1213 : loss : 0.058536, loss_ce: 0.029568
2021-11-30 13:48:35,368 iteration 1214 : loss : 0.040003, loss_ce: 0.016648
2021-11-30 13:48:36,889 iteration 1215 : loss : 0.082467, loss_ce: 0.036860
2021-11-30 13:48:38,516 iteration 1216 : loss : 0.048080, loss_ce: 0.018203
2021-11-30 13:48:40,051 iteration 1217 : loss : 0.032406, loss_ce: 0.011680
2021-11-30 13:48:41,514 iteration 1218 : loss : 0.041731, loss_ce: 0.014706
2021-11-30 13:48:42,955 iteration 1219 : loss : 0.041671, loss_ce: 0.013437
2021-11-30 13:48:44,465 iteration 1220 : loss : 0.040008, loss_ce: 0.014868
2021-11-30 13:48:45,957 iteration 1221 : loss : 0.075660, loss_ce: 0.028806
2021-11-30 13:48:47,543 iteration 1222 : loss : 0.063078, loss_ce: 0.021980
2021-11-30 13:48:49,036 iteration 1223 : loss : 0.044261, loss_ce: 0.019816
2021-11-30 13:48:50,582 iteration 1224 : loss : 0.076298, loss_ce: 0.029107
 18%|█████▍                        | 72/400 [33:41<2:32:52, 27.96s/it]2021-11-30 13:48:52,106 iteration 1225 : loss : 0.042610, loss_ce: 0.015291
2021-11-30 13:48:53,660 iteration 1226 : loss : 0.061020, loss_ce: 0.028920
2021-11-30 13:48:55,123 iteration 1227 : loss : 0.048055, loss_ce: 0.017071
2021-11-30 13:48:56,632 iteration 1228 : loss : 0.046359, loss_ce: 0.016545
2021-11-30 13:48:58,074 iteration 1229 : loss : 0.051332, loss_ce: 0.017806
2021-11-30 13:48:59,540 iteration 1230 : loss : 0.042203, loss_ce: 0.017147
2021-11-30 13:49:01,088 iteration 1231 : loss : 0.048002, loss_ce: 0.021489
2021-11-30 13:49:02,562 iteration 1232 : loss : 0.056152, loss_ce: 0.021415
2021-11-30 13:49:04,040 iteration 1233 : loss : 0.039620, loss_ce: 0.015760
2021-11-30 13:49:05,591 iteration 1234 : loss : 0.056857, loss_ce: 0.023751
2021-11-30 13:49:07,135 iteration 1235 : loss : 0.100559, loss_ce: 0.037045
2021-11-30 13:49:08,604 iteration 1236 : loss : 0.061922, loss_ce: 0.023046
2021-11-30 13:49:10,039 iteration 1237 : loss : 0.058508, loss_ce: 0.022989
2021-11-30 13:49:11,603 iteration 1238 : loss : 0.069942, loss_ce: 0.020452
2021-11-30 13:49:13,073 iteration 1239 : loss : 0.039602, loss_ce: 0.015117
2021-11-30 13:49:14,547 iteration 1240 : loss : 0.046629, loss_ce: 0.018098
2021-11-30 13:49:16,023 iteration 1241 : loss : 0.053542, loss_ce: 0.029795
 18%|█████▍                        | 73/400 [34:06<2:28:16, 27.21s/it]2021-11-30 13:49:17,587 iteration 1242 : loss : 0.078640, loss_ce: 0.046460
2021-11-30 13:49:19,068 iteration 1243 : loss : 0.059877, loss_ce: 0.018993
2021-11-30 13:49:20,572 iteration 1244 : loss : 0.065592, loss_ce: 0.032356
2021-11-30 13:49:22,089 iteration 1245 : loss : 0.087155, loss_ce: 0.037028
2021-11-30 13:49:23,611 iteration 1246 : loss : 0.045968, loss_ce: 0.015567
2021-11-30 13:49:25,095 iteration 1247 : loss : 0.054958, loss_ce: 0.022732
2021-11-30 13:49:26,629 iteration 1248 : loss : 0.059984, loss_ce: 0.019626
2021-11-30 13:49:28,100 iteration 1249 : loss : 0.037325, loss_ce: 0.012598
2021-11-30 13:49:29,699 iteration 1250 : loss : 0.062762, loss_ce: 0.023288
2021-11-30 13:49:31,321 iteration 1251 : loss : 0.090868, loss_ce: 0.045294
2021-11-30 13:49:32,873 iteration 1252 : loss : 0.048329, loss_ce: 0.021150
2021-11-30 13:49:34,304 iteration 1253 : loss : 0.045455, loss_ce: 0.016881
2021-11-30 13:49:35,816 iteration 1254 : loss : 0.060117, loss_ce: 0.032229
2021-11-30 13:49:37,349 iteration 1255 : loss : 0.043940, loss_ce: 0.016577
2021-11-30 13:49:38,838 iteration 1256 : loss : 0.057681, loss_ce: 0.026076
2021-11-30 13:49:40,329 iteration 1257 : loss : 0.070846, loss_ce: 0.024097
2021-11-30 13:49:41,858 iteration 1258 : loss : 0.062852, loss_ce: 0.034566
 18%|█████▌                        | 74/400 [34:32<2:25:34, 26.79s/it]2021-11-30 13:49:43,365 iteration 1259 : loss : 0.045994, loss_ce: 0.020765
2021-11-30 13:49:44,930 iteration 1260 : loss : 0.041042, loss_ce: 0.018073
2021-11-30 13:49:46,436 iteration 1261 : loss : 0.043881, loss_ce: 0.014897
2021-11-30 13:49:48,017 iteration 1262 : loss : 0.050806, loss_ce: 0.022003
2021-11-30 13:49:49,623 iteration 1263 : loss : 0.089489, loss_ce: 0.030828
2021-11-30 13:49:51,121 iteration 1264 : loss : 0.051714, loss_ce: 0.020790
2021-11-30 13:49:52,696 iteration 1265 : loss : 0.054195, loss_ce: 0.029937
2021-11-30 13:49:54,256 iteration 1266 : loss : 0.060894, loss_ce: 0.023049
2021-11-30 13:49:55,803 iteration 1267 : loss : 0.057315, loss_ce: 0.021232
2021-11-30 13:49:57,281 iteration 1268 : loss : 0.071007, loss_ce: 0.027151
2021-11-30 13:49:58,856 iteration 1269 : loss : 0.086882, loss_ce: 0.022473
2021-11-30 13:50:00,398 iteration 1270 : loss : 0.071047, loss_ce: 0.027270
2021-11-30 13:50:01,911 iteration 1271 : loss : 0.060561, loss_ce: 0.030082
2021-11-30 13:50:03,361 iteration 1272 : loss : 0.046575, loss_ce: 0.016423
2021-11-30 13:50:04,847 iteration 1273 : loss : 0.053782, loss_ce: 0.019023
2021-11-30 13:50:06,356 iteration 1274 : loss : 0.051460, loss_ce: 0.015701
2021-11-30 13:50:06,356 Training Data Eval:
2021-11-30 13:50:13,942   Average segmentation loss on training set: 0.0376
2021-11-30 13:50:13,943 Validation Data Eval:
2021-11-30 13:50:16,571   Average segmentation loss on validation set: 0.1037
2021-11-30 13:50:18,082 iteration 1275 : loss : 0.051336, loss_ce: 0.019295
 19%|█████▋                        | 75/400 [35:08<2:40:27, 29.62s/it]2021-11-30 13:50:19,575 iteration 1276 : loss : 0.037396, loss_ce: 0.015226
2021-11-30 13:50:21,189 iteration 1277 : loss : 0.055652, loss_ce: 0.021205
2021-11-30 13:50:22,678 iteration 1278 : loss : 0.041640, loss_ce: 0.015122
2021-11-30 13:50:24,276 iteration 1279 : loss : 0.052140, loss_ce: 0.020340
2021-11-30 13:50:25,812 iteration 1280 : loss : 0.061062, loss_ce: 0.026255
2021-11-30 13:50:27,355 iteration 1281 : loss : 0.060589, loss_ce: 0.026337
2021-11-30 13:50:28,821 iteration 1282 : loss : 0.032728, loss_ce: 0.014934
2021-11-30 13:50:30,384 iteration 1283 : loss : 0.062280, loss_ce: 0.018797
2021-11-30 13:50:31,878 iteration 1284 : loss : 0.040814, loss_ce: 0.015937
2021-11-30 13:50:33,458 iteration 1285 : loss : 0.059956, loss_ce: 0.021881
2021-11-30 13:50:35,066 iteration 1286 : loss : 0.117169, loss_ce: 0.030554
2021-11-30 13:50:36,566 iteration 1287 : loss : 0.043375, loss_ce: 0.021678
2021-11-30 13:50:38,037 iteration 1288 : loss : 0.054713, loss_ce: 0.024819
2021-11-30 13:50:39,547 iteration 1289 : loss : 0.050311, loss_ce: 0.019593
2021-11-30 13:50:41,098 iteration 1290 : loss : 0.068597, loss_ce: 0.025556
2021-11-30 13:50:42,652 iteration 1291 : loss : 0.059903, loss_ce: 0.023343
2021-11-30 13:50:44,219 iteration 1292 : loss : 0.064581, loss_ce: 0.025476
 19%|█████▋                        | 76/400 [35:34<2:34:19, 28.58s/it]2021-11-30 13:50:45,793 iteration 1293 : loss : 0.049427, loss_ce: 0.017584
2021-11-30 13:50:47,331 iteration 1294 : loss : 0.074224, loss_ce: 0.025806
2021-11-30 13:50:48,929 iteration 1295 : loss : 0.056478, loss_ce: 0.018972
2021-11-30 13:50:50,471 iteration 1296 : loss : 0.074782, loss_ce: 0.024389
2021-11-30 13:50:51,955 iteration 1297 : loss : 0.062503, loss_ce: 0.035518
2021-11-30 13:50:53,401 iteration 1298 : loss : 0.041852, loss_ce: 0.016684
2021-11-30 13:50:54,925 iteration 1299 : loss : 0.051242, loss_ce: 0.024475
2021-11-30 13:50:56,455 iteration 1300 : loss : 0.057566, loss_ce: 0.016613
2021-11-30 13:50:58,000 iteration 1301 : loss : 0.035541, loss_ce: 0.014230
2021-11-30 13:50:59,486 iteration 1302 : loss : 0.055353, loss_ce: 0.025565
2021-11-30 13:51:00,977 iteration 1303 : loss : 0.055563, loss_ce: 0.022853
2021-11-30 13:51:02,506 iteration 1304 : loss : 0.052517, loss_ce: 0.021598
2021-11-30 13:51:04,036 iteration 1305 : loss : 0.055966, loss_ce: 0.022360
2021-11-30 13:51:05,594 iteration 1306 : loss : 0.063456, loss_ce: 0.020802
2021-11-30 13:51:07,148 iteration 1307 : loss : 0.042362, loss_ce: 0.021857
2021-11-30 13:51:08,692 iteration 1308 : loss : 0.054667, loss_ce: 0.015064
2021-11-30 13:51:10,159 iteration 1309 : loss : 0.051781, loss_ce: 0.018602
 19%|█████▊                        | 77/400 [36:00<2:29:35, 27.79s/it]2021-11-30 13:51:11,776 iteration 1310 : loss : 0.048536, loss_ce: 0.017382
2021-11-30 13:51:13,254 iteration 1311 : loss : 0.046985, loss_ce: 0.020680
2021-11-30 13:51:14,740 iteration 1312 : loss : 0.039891, loss_ce: 0.016195
2021-11-30 13:51:16,225 iteration 1313 : loss : 0.069161, loss_ce: 0.018515
2021-11-30 13:51:17,749 iteration 1314 : loss : 0.042120, loss_ce: 0.018373
2021-11-30 13:51:19,287 iteration 1315 : loss : 0.087570, loss_ce: 0.043771
2021-11-30 13:51:20,917 iteration 1316 : loss : 0.053062, loss_ce: 0.020474
2021-11-30 13:51:22,426 iteration 1317 : loss : 0.050489, loss_ce: 0.026373
2021-11-30 13:51:24,011 iteration 1318 : loss : 0.138461, loss_ce: 0.026587
2021-11-30 13:51:25,562 iteration 1319 : loss : 0.057989, loss_ce: 0.026932
2021-11-30 13:51:27,068 iteration 1320 : loss : 0.038648, loss_ce: 0.014330
2021-11-30 13:51:28,601 iteration 1321 : loss : 0.070706, loss_ce: 0.022028
2021-11-30 13:51:30,068 iteration 1322 : loss : 0.055710, loss_ce: 0.024586
2021-11-30 13:51:31,589 iteration 1323 : loss : 0.096930, loss_ce: 0.034931
2021-11-30 13:51:33,141 iteration 1324 : loss : 0.060888, loss_ce: 0.027515
2021-11-30 13:51:34,708 iteration 1325 : loss : 0.075810, loss_ce: 0.030618
2021-11-30 13:51:36,150 iteration 1326 : loss : 0.052191, loss_ce: 0.019532
 20%|█████▊                        | 78/400 [36:26<2:26:13, 27.25s/it]2021-11-30 13:51:37,675 iteration 1327 : loss : 0.079933, loss_ce: 0.024290
2021-11-30 13:51:39,226 iteration 1328 : loss : 0.055332, loss_ce: 0.026536
2021-11-30 13:51:40,739 iteration 1329 : loss : 0.048873, loss_ce: 0.022512
2021-11-30 13:51:42,235 iteration 1330 : loss : 0.088331, loss_ce: 0.023741
2021-11-30 13:51:43,694 iteration 1331 : loss : 0.052598, loss_ce: 0.025754
2021-11-30 13:51:45,176 iteration 1332 : loss : 0.047035, loss_ce: 0.017574
2021-11-30 13:51:46,684 iteration 1333 : loss : 0.046441, loss_ce: 0.012260
2021-11-30 13:51:48,211 iteration 1334 : loss : 0.054884, loss_ce: 0.022205
2021-11-30 13:51:49,702 iteration 1335 : loss : 0.060860, loss_ce: 0.019509
2021-11-30 13:51:51,196 iteration 1336 : loss : 0.050279, loss_ce: 0.020551
2021-11-30 13:51:52,768 iteration 1337 : loss : 0.065627, loss_ce: 0.029101
2021-11-30 13:51:54,310 iteration 1338 : loss : 0.050017, loss_ce: 0.016680
2021-11-30 13:51:55,854 iteration 1339 : loss : 0.050445, loss_ce: 0.025656
2021-11-30 13:51:57,391 iteration 1340 : loss : 0.057061, loss_ce: 0.025926
2021-11-30 13:51:58,925 iteration 1341 : loss : 0.053618, loss_ce: 0.019507
2021-11-30 13:52:00,423 iteration 1342 : loss : 0.062418, loss_ce: 0.023905
2021-11-30 13:52:01,887 iteration 1343 : loss : 0.045468, loss_ce: 0.018724
 20%|█████▉                        | 79/400 [36:52<2:23:20, 26.79s/it]2021-11-30 13:52:03,447 iteration 1344 : loss : 0.054423, loss_ce: 0.023366
2021-11-30 13:52:05,030 iteration 1345 : loss : 0.052032, loss_ce: 0.020150
2021-11-30 13:52:06,521 iteration 1346 : loss : 0.050745, loss_ce: 0.022572
2021-11-30 13:52:08,090 iteration 1347 : loss : 0.042271, loss_ce: 0.020074
2021-11-30 13:52:09,709 iteration 1348 : loss : 0.081628, loss_ce: 0.032787
2021-11-30 13:52:11,246 iteration 1349 : loss : 0.056423, loss_ce: 0.021806
2021-11-30 13:52:12,752 iteration 1350 : loss : 0.051949, loss_ce: 0.024283
2021-11-30 13:52:14,268 iteration 1351 : loss : 0.048495, loss_ce: 0.021421
2021-11-30 13:52:15,831 iteration 1352 : loss : 0.043747, loss_ce: 0.020320
2021-11-30 13:52:17,376 iteration 1353 : loss : 0.060258, loss_ce: 0.020245
2021-11-30 13:52:18,921 iteration 1354 : loss : 0.078840, loss_ce: 0.026680
2021-11-30 13:52:20,533 iteration 1355 : loss : 0.162473, loss_ce: 0.043485
2021-11-30 13:52:22,056 iteration 1356 : loss : 0.054269, loss_ce: 0.022784
2021-11-30 13:52:23,623 iteration 1357 : loss : 0.040941, loss_ce: 0.017044
2021-11-30 13:52:25,184 iteration 1358 : loss : 0.048108, loss_ce: 0.018569
2021-11-30 13:52:26,703 iteration 1359 : loss : 0.067705, loss_ce: 0.031874
2021-11-30 13:52:26,704 Training Data Eval:
2021-11-30 13:52:34,286   Average segmentation loss on training set: 0.0489
2021-11-30 13:52:34,286 Validation Data Eval:
2021-11-30 13:52:36,903   Average segmentation loss on validation set: 0.1132
2021-11-30 13:52:38,484 iteration 1360 : loss : 0.041664, loss_ce: 0.011328
 20%|██████                        | 80/400 [37:29<2:38:35, 29.74s/it]2021-11-30 13:52:40,138 iteration 1361 : loss : 0.063915, loss_ce: 0.026732
2021-11-30 13:52:41,679 iteration 1362 : loss : 0.058744, loss_ce: 0.020327
2021-11-30 13:52:43,365 iteration 1363 : loss : 0.074843, loss_ce: 0.030228
2021-11-30 13:52:44,765 iteration 1364 : loss : 0.066648, loss_ce: 0.019196
2021-11-30 13:52:46,352 iteration 1365 : loss : 0.057479, loss_ce: 0.026880
2021-11-30 13:52:47,886 iteration 1366 : loss : 0.061670, loss_ce: 0.029136
2021-11-30 13:52:49,401 iteration 1367 : loss : 0.052172, loss_ce: 0.018693
2021-11-30 13:52:50,932 iteration 1368 : loss : 0.041998, loss_ce: 0.017610
2021-11-30 13:52:52,424 iteration 1369 : loss : 0.050085, loss_ce: 0.018997
2021-11-30 13:52:53,993 iteration 1370 : loss : 0.062305, loss_ce: 0.028357
2021-11-30 13:52:55,494 iteration 1371 : loss : 0.043681, loss_ce: 0.016843
2021-11-30 13:52:56,977 iteration 1372 : loss : 0.052197, loss_ce: 0.020423
2021-11-30 13:52:58,461 iteration 1373 : loss : 0.057420, loss_ce: 0.021267
2021-11-30 13:52:59,995 iteration 1374 : loss : 0.044575, loss_ce: 0.015070
2021-11-30 13:53:01,553 iteration 1375 : loss : 0.050247, loss_ce: 0.022291
2021-11-30 13:53:03,078 iteration 1376 : loss : 0.062736, loss_ce: 0.020567
2021-11-30 13:53:04,582 iteration 1377 : loss : 0.030212, loss_ce: 0.011501
 20%|██████                        | 81/400 [37:55<2:32:17, 28.65s/it]2021-11-30 13:53:06,072 iteration 1378 : loss : 0.056218, loss_ce: 0.022211
2021-11-30 13:53:07,627 iteration 1379 : loss : 0.039873, loss_ce: 0.015330
2021-11-30 13:53:09,159 iteration 1380 : loss : 0.044576, loss_ce: 0.017982
2021-11-30 13:53:10,746 iteration 1381 : loss : 0.047804, loss_ce: 0.020094
2021-11-30 13:53:12,195 iteration 1382 : loss : 0.042779, loss_ce: 0.016303
2021-11-30 13:53:13,782 iteration 1383 : loss : 0.037174, loss_ce: 0.014647
2021-11-30 13:53:15,313 iteration 1384 : loss : 0.056303, loss_ce: 0.021165
2021-11-30 13:53:16,770 iteration 1385 : loss : 0.060801, loss_ce: 0.019065
2021-11-30 13:53:18,250 iteration 1386 : loss : 0.037590, loss_ce: 0.013577
2021-11-30 13:53:19,750 iteration 1387 : loss : 0.044071, loss_ce: 0.018275
2021-11-30 13:53:21,279 iteration 1388 : loss : 0.046559, loss_ce: 0.013641
2021-11-30 13:53:22,793 iteration 1389 : loss : 0.061964, loss_ce: 0.024767
2021-11-30 13:53:24,343 iteration 1390 : loss : 0.044335, loss_ce: 0.018412
2021-11-30 13:53:25,915 iteration 1391 : loss : 0.043782, loss_ce: 0.017873
2021-11-30 13:53:27,483 iteration 1392 : loss : 0.052307, loss_ce: 0.027434
2021-11-30 13:53:28,985 iteration 1393 : loss : 0.051967, loss_ce: 0.020358
2021-11-30 13:53:30,560 iteration 1394 : loss : 0.046525, loss_ce: 0.021535
 20%|██████▏                       | 82/400 [38:21<2:27:34, 27.84s/it]2021-11-30 13:53:32,099 iteration 1395 : loss : 0.046152, loss_ce: 0.018922
2021-11-30 13:53:33,594 iteration 1396 : loss : 0.040029, loss_ce: 0.018189
2021-11-30 13:53:35,160 iteration 1397 : loss : 0.055410, loss_ce: 0.022007
2021-11-30 13:53:36,741 iteration 1398 : loss : 0.047129, loss_ce: 0.020531
2021-11-30 13:53:38,195 iteration 1399 : loss : 0.048286, loss_ce: 0.021682
2021-11-30 13:53:39,659 iteration 1400 : loss : 0.046129, loss_ce: 0.015117
2021-11-30 13:53:41,235 iteration 1401 : loss : 0.063080, loss_ce: 0.022079
2021-11-30 13:53:42,762 iteration 1402 : loss : 0.061350, loss_ce: 0.024023
2021-11-30 13:53:44,234 iteration 1403 : loss : 0.055877, loss_ce: 0.018839
2021-11-30 13:53:45,710 iteration 1404 : loss : 0.035172, loss_ce: 0.015533
2021-11-30 13:53:47,239 iteration 1405 : loss : 0.069979, loss_ce: 0.024953
2021-11-30 13:53:48,764 iteration 1406 : loss : 0.050223, loss_ce: 0.017907
2021-11-30 13:53:50,330 iteration 1407 : loss : 0.035838, loss_ce: 0.014459
2021-11-30 13:53:51,845 iteration 1408 : loss : 0.048025, loss_ce: 0.016814
2021-11-30 13:53:53,388 iteration 1409 : loss : 0.068936, loss_ce: 0.023549
2021-11-30 13:53:54,967 iteration 1410 : loss : 0.040832, loss_ce: 0.016006
2021-11-30 13:53:56,453 iteration 1411 : loss : 0.045968, loss_ce: 0.015521
 21%|██████▏                       | 83/400 [38:46<2:24:01, 27.26s/it]2021-11-30 13:53:57,981 iteration 1412 : loss : 0.059589, loss_ce: 0.021308
2021-11-30 13:53:59,566 iteration 1413 : loss : 0.090752, loss_ce: 0.027684
2021-11-30 13:54:01,062 iteration 1414 : loss : 0.038307, loss_ce: 0.015151
2021-11-30 13:54:02,623 iteration 1415 : loss : 0.058529, loss_ce: 0.015635
2021-11-30 13:54:04,116 iteration 1416 : loss : 0.050117, loss_ce: 0.020008
2021-11-30 13:54:05,605 iteration 1417 : loss : 0.047706, loss_ce: 0.016196
2021-11-30 13:54:07,088 iteration 1418 : loss : 0.055634, loss_ce: 0.023019
2021-11-30 13:54:08,558 iteration 1419 : loss : 0.042719, loss_ce: 0.016216
2021-11-30 13:54:10,117 iteration 1420 : loss : 0.047529, loss_ce: 0.018193
2021-11-30 13:54:11,723 iteration 1421 : loss : 0.072426, loss_ce: 0.029303
2021-11-30 13:54:13,260 iteration 1422 : loss : 0.039966, loss_ce: 0.011790
2021-11-30 13:54:14,709 iteration 1423 : loss : 0.054702, loss_ce: 0.021078
2021-11-30 13:54:16,258 iteration 1424 : loss : 0.040732, loss_ce: 0.018537
2021-11-30 13:54:17,813 iteration 1425 : loss : 0.032091, loss_ce: 0.012660
2021-11-30 13:54:19,296 iteration 1426 : loss : 0.047868, loss_ce: 0.020585
2021-11-30 13:54:20,801 iteration 1427 : loss : 0.066608, loss_ce: 0.026884
2021-11-30 13:54:22,232 iteration 1428 : loss : 0.054175, loss_ce: 0.019768
 21%|██████▎                       | 84/400 [39:12<2:21:13, 26.82s/it]2021-11-30 13:54:23,869 iteration 1429 : loss : 0.047829, loss_ce: 0.021049
2021-11-30 13:54:25,347 iteration 1430 : loss : 0.125600, loss_ce: 0.027910
2021-11-30 13:54:26,857 iteration 1431 : loss : 0.068218, loss_ce: 0.033365
2021-11-30 13:54:28,393 iteration 1432 : loss : 0.060410, loss_ce: 0.027404
2021-11-30 13:54:29,963 iteration 1433 : loss : 0.044938, loss_ce: 0.016526
2021-11-30 13:54:31,458 iteration 1434 : loss : 0.048519, loss_ce: 0.020029
2021-11-30 13:54:33,001 iteration 1435 : loss : 0.052605, loss_ce: 0.023667
2021-11-30 13:54:34,542 iteration 1436 : loss : 0.064055, loss_ce: 0.027564
2021-11-30 13:54:36,085 iteration 1437 : loss : 0.062147, loss_ce: 0.020735
2021-11-30 13:54:37,612 iteration 1438 : loss : 0.057851, loss_ce: 0.028598
2021-11-30 13:54:39,187 iteration 1439 : loss : 0.049842, loss_ce: 0.022298
2021-11-30 13:54:40,738 iteration 1440 : loss : 0.043978, loss_ce: 0.019436
2021-11-30 13:54:42,252 iteration 1441 : loss : 0.033163, loss_ce: 0.014248
2021-11-30 13:54:43,776 iteration 1442 : loss : 0.041506, loss_ce: 0.016842
2021-11-30 13:54:45,322 iteration 1443 : loss : 0.061395, loss_ce: 0.024674
2021-11-30 13:54:46,835 iteration 1444 : loss : 0.082969, loss_ce: 0.025349
2021-11-30 13:54:46,836 Training Data Eval:
2021-11-30 13:54:54,411   Average segmentation loss on training set: 0.0387
2021-11-30 13:54:54,412 Validation Data Eval:
2021-11-30 13:54:57,027   Average segmentation loss on validation set: 0.0911
2021-11-30 13:54:58,552 iteration 1445 : loss : 0.048178, loss_ce: 0.015867
 21%|██████▍                       | 85/400 [39:49<2:35:44, 29.67s/it]2021-11-30 13:55:00,187 iteration 1446 : loss : 0.062344, loss_ce: 0.021079
2021-11-30 13:55:01,697 iteration 1447 : loss : 0.059104, loss_ce: 0.020399
2021-11-30 13:55:03,178 iteration 1448 : loss : 0.055409, loss_ce: 0.028765
2021-11-30 13:55:04,724 iteration 1449 : loss : 0.054116, loss_ce: 0.019732
2021-11-30 13:55:06,336 iteration 1450 : loss : 0.042452, loss_ce: 0.019503
2021-11-30 13:55:07,953 iteration 1451 : loss : 0.053450, loss_ce: 0.021699
2021-11-30 13:55:09,447 iteration 1452 : loss : 0.047725, loss_ce: 0.016213
2021-11-30 13:55:10,960 iteration 1453 : loss : 0.056099, loss_ce: 0.028419
2021-11-30 13:55:12,502 iteration 1454 : loss : 0.077170, loss_ce: 0.025152
2021-11-30 13:55:13,996 iteration 1455 : loss : 0.039504, loss_ce: 0.017800
2021-11-30 13:55:15,611 iteration 1456 : loss : 0.098176, loss_ce: 0.025027
2021-11-30 13:55:17,124 iteration 1457 : loss : 0.069869, loss_ce: 0.032608
2021-11-30 13:55:18,640 iteration 1458 : loss : 0.051935, loss_ce: 0.017769
2021-11-30 13:55:20,124 iteration 1459 : loss : 0.068575, loss_ce: 0.023112
2021-11-30 13:55:21,725 iteration 1460 : loss : 0.095027, loss_ce: 0.038595
2021-11-30 13:55:23,249 iteration 1461 : loss : 0.063334, loss_ce: 0.026414
2021-11-30 13:55:24,805 iteration 1462 : loss : 0.072601, loss_ce: 0.030450
 22%|██████▍                       | 86/400 [40:15<2:29:53, 28.64s/it]2021-11-30 13:55:26,355 iteration 1463 : loss : 0.054911, loss_ce: 0.022969
2021-11-30 13:55:27,851 iteration 1464 : loss : 0.065804, loss_ce: 0.023751
2021-11-30 13:55:29,396 iteration 1465 : loss : 0.078564, loss_ce: 0.018872
2021-11-30 13:55:30,946 iteration 1466 : loss : 0.043954, loss_ce: 0.017470
2021-11-30 13:55:32,473 iteration 1467 : loss : 0.046565, loss_ce: 0.022475
2021-11-30 13:55:33,985 iteration 1468 : loss : 0.043866, loss_ce: 0.020967
2021-11-30 13:55:35,493 iteration 1469 : loss : 0.060941, loss_ce: 0.023651
2021-11-30 13:55:37,033 iteration 1470 : loss : 0.079143, loss_ce: 0.026163
2021-11-30 13:55:38,565 iteration 1471 : loss : 0.067681, loss_ce: 0.036291
2021-11-30 13:55:39,994 iteration 1472 : loss : 0.040628, loss_ce: 0.014052
2021-11-30 13:55:41,582 iteration 1473 : loss : 0.040420, loss_ce: 0.017236
2021-11-30 13:55:43,142 iteration 1474 : loss : 0.064109, loss_ce: 0.024730
2021-11-30 13:55:44,655 iteration 1475 : loss : 0.042695, loss_ce: 0.018077
2021-11-30 13:55:46,267 iteration 1476 : loss : 0.061985, loss_ce: 0.021395
2021-11-30 13:55:47,830 iteration 1477 : loss : 0.052956, loss_ce: 0.017265
2021-11-30 13:55:49,419 iteration 1478 : loss : 0.067574, loss_ce: 0.026973
2021-11-30 13:55:50,915 iteration 1479 : loss : 0.047186, loss_ce: 0.017137
 22%|██████▌                       | 87/400 [40:41<2:25:27, 27.88s/it]2021-11-30 13:55:52,493 iteration 1480 : loss : 0.049076, loss_ce: 0.016168
2021-11-30 13:55:54,009 iteration 1481 : loss : 0.038811, loss_ce: 0.015856
2021-11-30 13:55:55,525 iteration 1482 : loss : 0.043426, loss_ce: 0.017638
2021-11-30 13:55:57,126 iteration 1483 : loss : 0.047806, loss_ce: 0.018366
2021-11-30 13:55:58,756 iteration 1484 : loss : 0.067383, loss_ce: 0.020444
2021-11-30 13:56:00,317 iteration 1485 : loss : 0.038128, loss_ce: 0.015592
2021-11-30 13:56:01,805 iteration 1486 : loss : 0.045910, loss_ce: 0.019029
2021-11-30 13:56:03,330 iteration 1487 : loss : 0.046034, loss_ce: 0.020977
2021-11-30 13:56:04,859 iteration 1488 : loss : 0.056911, loss_ce: 0.023873
2021-11-30 13:56:06,397 iteration 1489 : loss : 0.041441, loss_ce: 0.016788
2021-11-30 13:56:07,948 iteration 1490 : loss : 0.059457, loss_ce: 0.024161
2021-11-30 13:56:09,551 iteration 1491 : loss : 0.058378, loss_ce: 0.023525
2021-11-30 13:56:11,039 iteration 1492 : loss : 0.040376, loss_ce: 0.015514
2021-11-30 13:56:12,602 iteration 1493 : loss : 0.051702, loss_ce: 0.021440
2021-11-30 13:56:14,100 iteration 1494 : loss : 0.047036, loss_ce: 0.019878
2021-11-30 13:56:15,616 iteration 1495 : loss : 0.048437, loss_ce: 0.018939
2021-11-30 13:56:17,150 iteration 1496 : loss : 0.077213, loss_ce: 0.021901
 22%|██████▌                       | 88/400 [41:07<2:22:25, 27.39s/it]2021-11-30 13:56:18,667 iteration 1497 : loss : 0.048122, loss_ce: 0.020540
2021-11-30 13:56:20,161 iteration 1498 : loss : 0.047587, loss_ce: 0.015525
2021-11-30 13:56:21,715 iteration 1499 : loss : 0.055404, loss_ce: 0.023993
2021-11-30 13:56:23,167 iteration 1500 : loss : 0.076087, loss_ce: 0.026381
2021-11-30 13:56:24,682 iteration 1501 : loss : 0.034741, loss_ce: 0.011449
2021-11-30 13:56:26,222 iteration 1502 : loss : 0.048168, loss_ce: 0.016119
2021-11-30 13:56:27,717 iteration 1503 : loss : 0.031761, loss_ce: 0.014124
2021-11-30 13:56:29,240 iteration 1504 : loss : 0.044528, loss_ce: 0.014168
2021-11-30 13:56:30,716 iteration 1505 : loss : 0.045419, loss_ce: 0.016681
2021-11-30 13:56:32,228 iteration 1506 : loss : 0.046267, loss_ce: 0.017690
2021-11-30 13:56:33,753 iteration 1507 : loss : 0.064101, loss_ce: 0.022025
2021-11-30 13:56:35,249 iteration 1508 : loss : 0.041968, loss_ce: 0.017864
2021-11-30 13:56:36,764 iteration 1509 : loss : 0.049832, loss_ce: 0.016347
2021-11-30 13:56:38,249 iteration 1510 : loss : 0.027298, loss_ce: 0.010374
2021-11-30 13:56:39,782 iteration 1511 : loss : 0.043484, loss_ce: 0.020991
2021-11-30 13:56:41,265 iteration 1512 : loss : 0.043609, loss_ce: 0.017541
2021-11-30 13:56:42,811 iteration 1513 : loss : 0.046399, loss_ce: 0.023300
 22%|██████▋                       | 89/400 [41:33<2:19:16, 26.87s/it]2021-11-30 13:56:44,353 iteration 1514 : loss : 0.052044, loss_ce: 0.016586
2021-11-30 13:56:45,868 iteration 1515 : loss : 0.048981, loss_ce: 0.018960
2021-11-30 13:56:47,401 iteration 1516 : loss : 0.079669, loss_ce: 0.035243
2021-11-30 13:56:48,926 iteration 1517 : loss : 0.038360, loss_ce: 0.018587
2021-11-30 13:56:50,474 iteration 1518 : loss : 0.042524, loss_ce: 0.012129
2021-11-30 13:56:51,984 iteration 1519 : loss : 0.038627, loss_ce: 0.013651
2021-11-30 13:56:53,473 iteration 1520 : loss : 0.038929, loss_ce: 0.012824
2021-11-30 13:56:54,985 iteration 1521 : loss : 0.042799, loss_ce: 0.017482
2021-11-30 13:56:56,593 iteration 1522 : loss : 0.045926, loss_ce: 0.016629
2021-11-30 13:56:58,060 iteration 1523 : loss : 0.046536, loss_ce: 0.022242
2021-11-30 13:56:59,600 iteration 1524 : loss : 0.062261, loss_ce: 0.023704
2021-11-30 13:57:01,117 iteration 1525 : loss : 0.037687, loss_ce: 0.015536
2021-11-30 13:57:02,693 iteration 1526 : loss : 0.051468, loss_ce: 0.021286
2021-11-30 13:57:04,274 iteration 1527 : loss : 0.067014, loss_ce: 0.032874
2021-11-30 13:57:05,830 iteration 1528 : loss : 0.049863, loss_ce: 0.017693
2021-11-30 13:57:07,345 iteration 1529 : loss : 0.060564, loss_ce: 0.021303
2021-11-30 13:57:07,345 Training Data Eval:
2021-11-30 13:57:14,952   Average segmentation loss on training set: 0.0328
2021-11-30 13:57:14,953 Validation Data Eval:
2021-11-30 13:57:17,575   Average segmentation loss on validation set: 0.1156
2021-11-30 13:57:19,074 iteration 1530 : loss : 0.050878, loss_ce: 0.022049
 22%|██████▊                       | 90/400 [42:09<2:33:23, 29.69s/it]2021-11-30 13:57:20,770 iteration 1531 : loss : 0.050244, loss_ce: 0.022275
2021-11-30 13:57:22,316 iteration 1532 : loss : 0.042808, loss_ce: 0.013737
2021-11-30 13:57:23,797 iteration 1533 : loss : 0.035704, loss_ce: 0.016229
2021-11-30 13:57:25,375 iteration 1534 : loss : 0.056430, loss_ce: 0.022902
2021-11-30 13:57:26,895 iteration 1535 : loss : 0.049185, loss_ce: 0.019596
2021-11-30 13:57:28,390 iteration 1536 : loss : 0.069915, loss_ce: 0.032859
2021-11-30 13:57:29,879 iteration 1537 : loss : 0.062118, loss_ce: 0.021578
2021-11-30 13:57:31,337 iteration 1538 : loss : 0.133811, loss_ce: 0.030679
2021-11-30 13:57:32,844 iteration 1539 : loss : 0.047138, loss_ce: 0.017736
2021-11-30 13:57:34,383 iteration 1540 : loss : 0.062557, loss_ce: 0.029768
2021-11-30 13:57:35,822 iteration 1541 : loss : 0.043924, loss_ce: 0.013691
2021-11-30 13:57:37,335 iteration 1542 : loss : 0.056458, loss_ce: 0.025758
2021-11-30 13:57:38,832 iteration 1543 : loss : 0.054846, loss_ce: 0.015630
2021-11-30 13:57:40,299 iteration 1544 : loss : 0.051600, loss_ce: 0.018621
2021-11-30 13:57:41,799 iteration 1545 : loss : 0.057519, loss_ce: 0.021427
2021-11-30 13:57:43,304 iteration 1546 : loss : 0.043243, loss_ce: 0.018715
2021-11-30 13:57:44,810 iteration 1547 : loss : 0.057078, loss_ce: 0.020582
 23%|██████▊                       | 91/400 [42:35<2:26:47, 28.50s/it]2021-11-30 13:57:46,356 iteration 1548 : loss : 0.046398, loss_ce: 0.017713
2021-11-30 13:57:47,833 iteration 1549 : loss : 0.047893, loss_ce: 0.021585
2021-11-30 13:57:49,441 iteration 1550 : loss : 0.050521, loss_ce: 0.021959
2021-11-30 13:57:50,964 iteration 1551 : loss : 0.060352, loss_ce: 0.025888
2021-11-30 13:57:52,483 iteration 1552 : loss : 0.041040, loss_ce: 0.016614
2021-11-30 13:57:53,939 iteration 1553 : loss : 0.036594, loss_ce: 0.018765
2021-11-30 13:57:55,419 iteration 1554 : loss : 0.061466, loss_ce: 0.021841
2021-11-30 13:57:56,982 iteration 1555 : loss : 0.041653, loss_ce: 0.015569
2021-11-30 13:57:58,615 iteration 1556 : loss : 0.057699, loss_ce: 0.021058
2021-11-30 13:58:00,191 iteration 1557 : loss : 0.096576, loss_ce: 0.025491
2021-11-30 13:58:01,715 iteration 1558 : loss : 0.053182, loss_ce: 0.017197
2021-11-30 13:58:03,320 iteration 1559 : loss : 0.054053, loss_ce: 0.025787
2021-11-30 13:58:04,809 iteration 1560 : loss : 0.044635, loss_ce: 0.015016
2021-11-30 13:58:06,324 iteration 1561 : loss : 0.056288, loss_ce: 0.022823
2021-11-30 13:58:07,851 iteration 1562 : loss : 0.045943, loss_ce: 0.020389
2021-11-30 13:58:09,358 iteration 1563 : loss : 0.043640, loss_ce: 0.021730
2021-11-30 13:58:10,872 iteration 1564 : loss : 0.065808, loss_ce: 0.022943
 23%|██████▉                       | 92/400 [43:01<2:22:33, 27.77s/it]2021-11-30 13:58:12,443 iteration 1565 : loss : 0.038154, loss_ce: 0.014317
2021-11-30 13:58:13,940 iteration 1566 : loss : 0.070058, loss_ce: 0.029988
2021-11-30 13:58:15,488 iteration 1567 : loss : 0.067716, loss_ce: 0.022280
2021-11-30 13:58:17,097 iteration 1568 : loss : 0.045094, loss_ce: 0.019419
2021-11-30 13:58:18,594 iteration 1569 : loss : 0.053169, loss_ce: 0.021898
2021-11-30 13:58:20,130 iteration 1570 : loss : 0.041233, loss_ce: 0.015225
2021-11-30 13:58:21,644 iteration 1571 : loss : 0.047027, loss_ce: 0.019709
2021-11-30 13:58:23,148 iteration 1572 : loss : 0.059540, loss_ce: 0.028423
2021-11-30 13:58:24,665 iteration 1573 : loss : 0.067069, loss_ce: 0.020985
2021-11-30 13:58:26,195 iteration 1574 : loss : 0.044007, loss_ce: 0.021155
2021-11-30 13:58:27,740 iteration 1575 : loss : 0.052795, loss_ce: 0.022243
2021-11-30 13:58:29,264 iteration 1576 : loss : 0.047491, loss_ce: 0.015029
2021-11-30 13:58:30,740 iteration 1577 : loss : 0.071918, loss_ce: 0.028358
2021-11-30 13:58:32,174 iteration 1578 : loss : 0.040197, loss_ce: 0.016643
2021-11-30 13:58:33,680 iteration 1579 : loss : 0.040273, loss_ce: 0.015278
2021-11-30 13:58:35,214 iteration 1580 : loss : 0.045676, loss_ce: 0.015601
2021-11-30 13:58:36,755 iteration 1581 : loss : 0.047335, loss_ce: 0.017713
 23%|██████▉                       | 93/400 [43:27<2:19:12, 27.21s/it]2021-11-30 13:58:38,350 iteration 1582 : loss : 0.036923, loss_ce: 0.017563
2021-11-30 13:58:39,875 iteration 1583 : loss : 0.047295, loss_ce: 0.014386
2021-11-30 13:58:41,348 iteration 1584 : loss : 0.042770, loss_ce: 0.014386
2021-11-30 13:58:42,845 iteration 1585 : loss : 0.043451, loss_ce: 0.018861
2021-11-30 13:58:44,293 iteration 1586 : loss : 0.036345, loss_ce: 0.017538
2021-11-30 13:58:45,792 iteration 1587 : loss : 0.053550, loss_ce: 0.019162
2021-11-30 13:58:47,291 iteration 1588 : loss : 0.040224, loss_ce: 0.012625
2021-11-30 13:58:48,795 iteration 1589 : loss : 0.048908, loss_ce: 0.023009
2021-11-30 13:58:50,379 iteration 1590 : loss : 0.063527, loss_ce: 0.022733
2021-11-30 13:58:51,861 iteration 1591 : loss : 0.039702, loss_ce: 0.019086
2021-11-30 13:58:53,298 iteration 1592 : loss : 0.030553, loss_ce: 0.013482
2021-11-30 13:58:54,828 iteration 1593 : loss : 0.055210, loss_ce: 0.020165
2021-11-30 13:58:56,323 iteration 1594 : loss : 0.048052, loss_ce: 0.015744
2021-11-30 13:58:57,782 iteration 1595 : loss : 0.044570, loss_ce: 0.023268
2021-11-30 13:58:59,227 iteration 1596 : loss : 0.051220, loss_ce: 0.019247
2021-11-30 13:59:00,765 iteration 1597 : loss : 0.064047, loss_ce: 0.019799
2021-11-30 13:59:02,312 iteration 1598 : loss : 0.066081, loss_ce: 0.026037
 24%|███████                       | 94/400 [43:52<2:16:13, 26.71s/it]2021-11-30 13:59:03,925 iteration 1599 : loss : 0.055322, loss_ce: 0.025961
2021-11-30 13:59:05,427 iteration 1600 : loss : 0.056439, loss_ce: 0.022918
2021-11-30 13:59:06,986 iteration 1601 : loss : 0.046659, loss_ce: 0.019012
2021-11-30 13:59:08,516 iteration 1602 : loss : 0.074886, loss_ce: 0.023559
2021-11-30 13:59:10,043 iteration 1603 : loss : 0.046650, loss_ce: 0.018927
2021-11-30 13:59:11,545 iteration 1604 : loss : 0.065637, loss_ce: 0.019421
2021-11-30 13:59:13,072 iteration 1605 : loss : 0.049146, loss_ce: 0.021003
2021-11-30 13:59:14,608 iteration 1606 : loss : 0.034156, loss_ce: 0.013235
2021-11-30 13:59:16,146 iteration 1607 : loss : 0.052747, loss_ce: 0.019018
2021-11-30 13:59:17,749 iteration 1608 : loss : 0.078424, loss_ce: 0.031862
2021-11-30 13:59:19,249 iteration 1609 : loss : 0.042484, loss_ce: 0.016364
2021-11-30 13:59:20,851 iteration 1610 : loss : 0.046734, loss_ce: 0.018530
2021-11-30 13:59:22,448 iteration 1611 : loss : 0.055798, loss_ce: 0.028684
2021-11-30 13:59:24,071 iteration 1612 : loss : 0.046357, loss_ce: 0.017410
2021-11-30 13:59:25,604 iteration 1613 : loss : 0.041916, loss_ce: 0.013804
2021-11-30 13:59:27,198 iteration 1614 : loss : 0.049483, loss_ce: 0.021294
2021-11-30 13:59:27,198 Training Data Eval:
2021-11-30 13:59:34,806   Average segmentation loss on training set: 0.0325
2021-11-30 13:59:34,806 Validation Data Eval:
2021-11-30 13:59:37,439   Average segmentation loss on validation set: 0.0968
2021-11-30 13:59:39,019 iteration 1615 : loss : 0.043903, loss_ce: 0.016801
 24%|███████▏                      | 95/400 [44:29<2:31:01, 29.71s/it]2021-11-30 13:59:40,592 iteration 1616 : loss : 0.034393, loss_ce: 0.012531
2021-11-30 13:59:42,113 iteration 1617 : loss : 0.042155, loss_ce: 0.020012
2021-11-30 13:59:43,599 iteration 1618 : loss : 0.041259, loss_ce: 0.014881
2021-11-30 13:59:45,122 iteration 1619 : loss : 0.056062, loss_ce: 0.031303
2021-11-30 13:59:46,763 iteration 1620 : loss : 0.045434, loss_ce: 0.016236
2021-11-30 13:59:48,396 iteration 1621 : loss : 0.068682, loss_ce: 0.023567
2021-11-30 13:59:49,913 iteration 1622 : loss : 0.047520, loss_ce: 0.018352
2021-11-30 13:59:51,407 iteration 1623 : loss : 0.043455, loss_ce: 0.014553
2021-11-30 13:59:52,964 iteration 1624 : loss : 0.042311, loss_ce: 0.017053
2021-11-30 13:59:54,437 iteration 1625 : loss : 0.047615, loss_ce: 0.018204
2021-11-30 13:59:55,939 iteration 1626 : loss : 0.037801, loss_ce: 0.015402
2021-11-30 13:59:57,576 iteration 1627 : loss : 0.068665, loss_ce: 0.027220
2021-11-30 13:59:59,182 iteration 1628 : loss : 0.045024, loss_ce: 0.017902
2021-11-30 14:00:00,672 iteration 1629 : loss : 0.035722, loss_ce: 0.013123
2021-11-30 14:00:02,152 iteration 1630 : loss : 0.028164, loss_ce: 0.011370
2021-11-30 14:00:03,645 iteration 1631 : loss : 0.050775, loss_ce: 0.016968
2021-11-30 14:00:05,150 iteration 1632 : loss : 0.036500, loss_ce: 0.014099
 24%|███████▏                      | 96/400 [44:55<2:25:05, 28.64s/it]2021-11-30 14:00:06,721 iteration 1633 : loss : 0.069999, loss_ce: 0.019791
2021-11-30 14:00:08,269 iteration 1634 : loss : 0.056106, loss_ce: 0.020416
2021-11-30 14:00:09,769 iteration 1635 : loss : 0.053548, loss_ce: 0.015389
2021-11-30 14:00:11,241 iteration 1636 : loss : 0.042081, loss_ce: 0.021715
2021-11-30 14:00:12,783 iteration 1637 : loss : 0.058102, loss_ce: 0.019403
2021-11-30 14:00:14,309 iteration 1638 : loss : 0.039186, loss_ce: 0.018363
2021-11-30 14:00:15,897 iteration 1639 : loss : 0.041774, loss_ce: 0.019273
2021-11-30 14:00:17,382 iteration 1640 : loss : 0.048611, loss_ce: 0.015624
2021-11-30 14:00:18,968 iteration 1641 : loss : 0.049982, loss_ce: 0.017189
2021-11-30 14:00:20,446 iteration 1642 : loss : 0.033964, loss_ce: 0.012694
2021-11-30 14:00:21,913 iteration 1643 : loss : 0.048556, loss_ce: 0.017073
2021-11-30 14:00:23,475 iteration 1644 : loss : 0.041886, loss_ce: 0.017190
2021-11-30 14:00:25,075 iteration 1645 : loss : 0.042927, loss_ce: 0.017302
2021-11-30 14:00:26,552 iteration 1646 : loss : 0.051422, loss_ce: 0.016533
2021-11-30 14:00:28,050 iteration 1647 : loss : 0.072370, loss_ce: 0.023344
2021-11-30 14:00:29,481 iteration 1648 : loss : 0.036706, loss_ce: 0.015315
2021-11-30 14:00:30,944 iteration 1649 : loss : 0.039683, loss_ce: 0.014634
 24%|███████▎                      | 97/400 [45:21<2:20:18, 27.78s/it]2021-11-30 14:00:32,606 iteration 1650 : loss : 0.077606, loss_ce: 0.048941
2021-11-30 14:00:34,104 iteration 1651 : loss : 0.069916, loss_ce: 0.019302
2021-11-30 14:00:35,634 iteration 1652 : loss : 0.063292, loss_ce: 0.017133
2021-11-30 14:00:37,129 iteration 1653 : loss : 0.040065, loss_ce: 0.012561
2021-11-30 14:00:38,638 iteration 1654 : loss : 0.042248, loss_ce: 0.014361
2021-11-30 14:00:40,121 iteration 1655 : loss : 0.059593, loss_ce: 0.025065
2021-11-30 14:00:41,673 iteration 1656 : loss : 0.053582, loss_ce: 0.020470
2021-11-30 14:00:43,181 iteration 1657 : loss : 0.051614, loss_ce: 0.024368
2021-11-30 14:00:44,746 iteration 1658 : loss : 0.061199, loss_ce: 0.039243
2021-11-30 14:00:46,350 iteration 1659 : loss : 0.061710, loss_ce: 0.025961
2021-11-30 14:00:47,872 iteration 1660 : loss : 0.032939, loss_ce: 0.013029
2021-11-30 14:00:49,330 iteration 1661 : loss : 0.051500, loss_ce: 0.017334
2021-11-30 14:00:50,883 iteration 1662 : loss : 0.054473, loss_ce: 0.017067
2021-11-30 14:00:52,478 iteration 1663 : loss : 0.042402, loss_ce: 0.018932
2021-11-30 14:00:53,986 iteration 1664 : loss : 0.053920, loss_ce: 0.019506
2021-11-30 14:00:55,488 iteration 1665 : loss : 0.054378, loss_ce: 0.025120
2021-11-30 14:00:57,012 iteration 1666 : loss : 0.055700, loss_ce: 0.015413
 24%|███████▎                      | 98/400 [45:47<2:17:14, 27.27s/it]2021-11-30 14:00:58,536 iteration 1667 : loss : 0.053981, loss_ce: 0.024636
2021-11-30 14:01:00,124 iteration 1668 : loss : 0.063014, loss_ce: 0.021617
2021-11-30 14:01:01,672 iteration 1669 : loss : 0.048812, loss_ce: 0.019020
2021-11-30 14:01:03,118 iteration 1670 : loss : 0.030949, loss_ce: 0.010696
2021-11-30 14:01:04,588 iteration 1671 : loss : 0.036470, loss_ce: 0.016233
2021-11-30 14:01:06,169 iteration 1672 : loss : 0.052211, loss_ce: 0.020998
2021-11-30 14:01:07,727 iteration 1673 : loss : 0.043397, loss_ce: 0.014373
2021-11-30 14:01:09,342 iteration 1674 : loss : 0.054215, loss_ce: 0.019185
2021-11-30 14:01:10,847 iteration 1675 : loss : 0.065588, loss_ce: 0.019440
2021-11-30 14:01:12,411 iteration 1676 : loss : 0.040076, loss_ce: 0.016252
2021-11-30 14:01:13,950 iteration 1677 : loss : 0.066505, loss_ce: 0.019541
2021-11-30 14:01:15,508 iteration 1678 : loss : 0.033122, loss_ce: 0.014677
2021-11-30 14:01:17,015 iteration 1679 : loss : 0.048311, loss_ce: 0.018390
2021-11-30 14:01:18,541 iteration 1680 : loss : 0.056088, loss_ce: 0.027776
2021-11-30 14:01:20,048 iteration 1681 : loss : 0.038256, loss_ce: 0.015399
2021-11-30 14:01:21,570 iteration 1682 : loss : 0.049748, loss_ce: 0.020257
2021-11-30 14:01:23,073 iteration 1683 : loss : 0.040753, loss_ce: 0.019333
 25%|███████▍                      | 99/400 [46:13<2:14:59, 26.91s/it]2021-11-30 14:01:24,659 iteration 1684 : loss : 0.052030, loss_ce: 0.023017
2021-11-30 14:01:26,152 iteration 1685 : loss : 0.043259, loss_ce: 0.021673
2021-11-30 14:01:27,599 iteration 1686 : loss : 0.031396, loss_ce: 0.012274
2021-11-30 14:01:29,081 iteration 1687 : loss : 0.034373, loss_ce: 0.014351
2021-11-30 14:01:30,611 iteration 1688 : loss : 0.051215, loss_ce: 0.026024
2021-11-30 14:01:32,105 iteration 1689 : loss : 0.040624, loss_ce: 0.014648
2021-11-30 14:01:33,644 iteration 1690 : loss : 0.102694, loss_ce: 0.039449
2021-11-30 14:01:35,156 iteration 1691 : loss : 0.028904, loss_ce: 0.011824
2021-11-30 14:01:36,734 iteration 1692 : loss : 0.056997, loss_ce: 0.021518
2021-11-30 14:01:38,309 iteration 1693 : loss : 0.038792, loss_ce: 0.018817
2021-11-30 14:01:39,856 iteration 1694 : loss : 0.041372, loss_ce: 0.015566
2021-11-30 14:01:41,300 iteration 1695 : loss : 0.027446, loss_ce: 0.008863
2021-11-30 14:01:42,825 iteration 1696 : loss : 0.041199, loss_ce: 0.015845
2021-11-30 14:01:44,380 iteration 1697 : loss : 0.046904, loss_ce: 0.016332
2021-11-30 14:01:45,897 iteration 1698 : loss : 0.035684, loss_ce: 0.010993
2021-11-30 14:01:47,326 iteration 1699 : loss : 0.038451, loss_ce: 0.018002
2021-11-30 14:01:47,326 Training Data Eval:
2021-11-30 14:01:54,916   Average segmentation loss on training set: 0.0332
2021-11-30 14:01:54,916 Validation Data Eval:
2021-11-30 14:01:57,540   Average segmentation loss on validation set: 0.0912
2021-11-30 14:01:59,071 iteration 1700 : loss : 0.042600, loss_ce: 0.012473
 25%|███████▎                     | 100/400 [46:49<2:28:09, 29.63s/it]2021-11-30 14:02:00,661 iteration 1701 : loss : 0.040665, loss_ce: 0.016765
2021-11-30 14:02:02,195 iteration 1702 : loss : 0.043283, loss_ce: 0.018114
2021-11-30 14:02:03,679 iteration 1703 : loss : 0.047494, loss_ce: 0.019402
2021-11-30 14:02:05,266 iteration 1704 : loss : 0.037460, loss_ce: 0.013761
2021-11-30 14:02:06,799 iteration 1705 : loss : 0.051739, loss_ce: 0.025686
2021-11-30 14:02:08,330 iteration 1706 : loss : 0.048433, loss_ce: 0.022597
2021-11-30 14:02:09,851 iteration 1707 : loss : 0.047777, loss_ce: 0.018098
2021-11-30 14:02:11,394 iteration 1708 : loss : 0.047020, loss_ce: 0.015597
2021-11-30 14:02:12,858 iteration 1709 : loss : 0.035830, loss_ce: 0.014981
2021-11-30 14:02:14,302 iteration 1710 : loss : 0.035991, loss_ce: 0.015048
2021-11-30 14:02:15,830 iteration 1711 : loss : 0.043756, loss_ce: 0.015551
2021-11-30 14:02:17,303 iteration 1712 : loss : 0.047700, loss_ce: 0.015773
2021-11-30 14:02:18,766 iteration 1713 : loss : 0.039415, loss_ce: 0.013458
2021-11-30 14:02:20,348 iteration 1714 : loss : 0.090228, loss_ce: 0.027465
2021-11-30 14:02:21,894 iteration 1715 : loss : 0.076232, loss_ce: 0.020319
2021-11-30 14:02:23,495 iteration 1716 : loss : 0.064821, loss_ce: 0.021804
2021-11-30 14:02:25,016 iteration 1717 : loss : 0.053129, loss_ce: 0.020058
 25%|███████▎                     | 101/400 [47:15<2:22:09, 28.53s/it]2021-11-30 14:02:26,549 iteration 1718 : loss : 0.048534, loss_ce: 0.014770
2021-11-30 14:02:28,097 iteration 1719 : loss : 0.054143, loss_ce: 0.021263
2021-11-30 14:02:29,536 iteration 1720 : loss : 0.041887, loss_ce: 0.013669
2021-11-30 14:02:31,043 iteration 1721 : loss : 0.064214, loss_ce: 0.027000
2021-11-30 14:02:32,602 iteration 1722 : loss : 0.050620, loss_ce: 0.015739
2021-11-30 14:02:34,113 iteration 1723 : loss : 0.058482, loss_ce: 0.022996
2021-11-30 14:02:35,682 iteration 1724 : loss : 0.040096, loss_ce: 0.012392
2021-11-30 14:02:37,303 iteration 1725 : loss : 0.080835, loss_ce: 0.026395
2021-11-30 14:02:38,876 iteration 1726 : loss : 0.072770, loss_ce: 0.017328
2021-11-30 14:02:40,402 iteration 1727 : loss : 0.035094, loss_ce: 0.017735
2021-11-30 14:02:41,906 iteration 1728 : loss : 0.042972, loss_ce: 0.015341
2021-11-30 14:02:43,413 iteration 1729 : loss : 0.038072, loss_ce: 0.015869
2021-11-30 14:02:44,942 iteration 1730 : loss : 0.038217, loss_ce: 0.014825
2021-11-30 14:02:46,523 iteration 1731 : loss : 0.048806, loss_ce: 0.016447
2021-11-30 14:02:48,040 iteration 1732 : loss : 0.029463, loss_ce: 0.013492
2021-11-30 14:02:49,627 iteration 1733 : loss : 0.052141, loss_ce: 0.021004
2021-11-30 14:02:51,106 iteration 1734 : loss : 0.035389, loss_ce: 0.012234
 26%|███████▍                     | 102/400 [47:41<2:18:02, 27.79s/it]2021-11-30 14:02:52,634 iteration 1735 : loss : 0.050863, loss_ce: 0.018245
2021-11-30 14:02:54,139 iteration 1736 : loss : 0.034762, loss_ce: 0.014325
2021-11-30 14:02:55,655 iteration 1737 : loss : 0.035810, loss_ce: 0.013360
2021-11-30 14:02:57,153 iteration 1738 : loss : 0.052822, loss_ce: 0.016840
2021-11-30 14:02:58,756 iteration 1739 : loss : 0.053114, loss_ce: 0.024469
2021-11-30 14:03:00,303 iteration 1740 : loss : 0.053326, loss_ce: 0.018097
2021-11-30 14:03:01,817 iteration 1741 : loss : 0.039825, loss_ce: 0.014086
2021-11-30 14:03:03,430 iteration 1742 : loss : 0.039604, loss_ce: 0.016965
2021-11-30 14:03:04,927 iteration 1743 : loss : 0.053651, loss_ce: 0.018046
2021-11-30 14:03:06,469 iteration 1744 : loss : 0.046107, loss_ce: 0.017704
2021-11-30 14:03:08,118 iteration 1745 : loss : 0.055125, loss_ce: 0.029619
2021-11-30 14:03:09,616 iteration 1746 : loss : 0.028845, loss_ce: 0.011348
2021-11-30 14:03:11,119 iteration 1747 : loss : 0.034858, loss_ce: 0.015240
2021-11-30 14:03:12,646 iteration 1748 : loss : 0.036624, loss_ce: 0.014432
2021-11-30 14:03:14,164 iteration 1749 : loss : 0.048149, loss_ce: 0.018587
2021-11-30 14:03:15,632 iteration 1750 : loss : 0.034483, loss_ce: 0.015507
2021-11-30 14:03:17,254 iteration 1751 : loss : 0.055216, loss_ce: 0.022097
 26%|███████▍                     | 103/400 [48:07<2:15:08, 27.30s/it]2021-11-30 14:03:18,777 iteration 1752 : loss : 0.030878, loss_ce: 0.010506
2021-11-30 14:03:20,248 iteration 1753 : loss : 0.042361, loss_ce: 0.019608
2021-11-30 14:03:21,764 iteration 1754 : loss : 0.036084, loss_ce: 0.014250
2021-11-30 14:03:23,292 iteration 1755 : loss : 0.033719, loss_ce: 0.013228
2021-11-30 14:03:24,832 iteration 1756 : loss : 0.045165, loss_ce: 0.020540
2021-11-30 14:03:26,412 iteration 1757 : loss : 0.043996, loss_ce: 0.026324
2021-11-30 14:03:27,955 iteration 1758 : loss : 0.050455, loss_ce: 0.018220
2021-11-30 14:03:29,403 iteration 1759 : loss : 0.051821, loss_ce: 0.015249
2021-11-30 14:03:30,927 iteration 1760 : loss : 0.049138, loss_ce: 0.020631
2021-11-30 14:03:32,418 iteration 1761 : loss : 0.029816, loss_ce: 0.011247
2021-11-30 14:03:33,928 iteration 1762 : loss : 0.040480, loss_ce: 0.014710
2021-11-30 14:03:35,375 iteration 1763 : loss : 0.039532, loss_ce: 0.016033
2021-11-30 14:03:36,987 iteration 1764 : loss : 0.026255, loss_ce: 0.006930
2021-11-30 14:03:38,501 iteration 1765 : loss : 0.043418, loss_ce: 0.014362
2021-11-30 14:03:40,073 iteration 1766 : loss : 0.034975, loss_ce: 0.014082
2021-11-30 14:03:41,607 iteration 1767 : loss : 0.051133, loss_ce: 0.020893
2021-11-30 14:03:43,119 iteration 1768 : loss : 0.052768, loss_ce: 0.017885
 26%|███████▌                     | 104/400 [48:33<2:12:34, 26.87s/it]2021-11-30 14:03:44,702 iteration 1769 : loss : 0.033433, loss_ce: 0.013257
2021-11-30 14:03:46,200 iteration 1770 : loss : 0.032234, loss_ce: 0.010853
2021-11-30 14:03:47,688 iteration 1771 : loss : 0.025205, loss_ce: 0.008343
2021-11-30 14:03:49,275 iteration 1772 : loss : 0.053829, loss_ce: 0.027138
2021-11-30 14:03:50,817 iteration 1773 : loss : 0.040789, loss_ce: 0.018369
2021-11-30 14:03:52,304 iteration 1774 : loss : 0.050221, loss_ce: 0.016181
2021-11-30 14:03:53,812 iteration 1775 : loss : 0.038854, loss_ce: 0.013117
2021-11-30 14:03:55,301 iteration 1776 : loss : 0.049904, loss_ce: 0.017008
2021-11-30 14:03:56,776 iteration 1777 : loss : 0.038192, loss_ce: 0.014786
2021-11-30 14:03:58,330 iteration 1778 : loss : 0.044729, loss_ce: 0.021280
2021-11-30 14:03:59,839 iteration 1779 : loss : 0.049472, loss_ce: 0.021451
2021-11-30 14:04:01,371 iteration 1780 : loss : 0.049667, loss_ce: 0.014957
2021-11-30 14:04:02,914 iteration 1781 : loss : 0.057430, loss_ce: 0.018482
2021-11-30 14:04:04,377 iteration 1782 : loss : 0.059736, loss_ce: 0.013158
2021-11-30 14:04:05,872 iteration 1783 : loss : 0.040903, loss_ce: 0.017347
2021-11-30 14:04:07,407 iteration 1784 : loss : 0.044208, loss_ce: 0.023487
2021-11-30 14:04:07,408 Training Data Eval:
2021-11-30 14:04:14,990   Average segmentation loss on training set: 0.0379
2021-11-30 14:04:14,990 Validation Data Eval:
2021-11-30 14:04:17,605   Average segmentation loss on validation set: 0.1189
2021-11-30 14:04:19,125 iteration 1785 : loss : 0.035013, loss_ce: 0.015495
 26%|███████▌                     | 105/400 [49:09<2:25:35, 29.61s/it]2021-11-30 14:04:20,725 iteration 1786 : loss : 0.074488, loss_ce: 0.027440
2021-11-30 14:04:22,193 iteration 1787 : loss : 0.058384, loss_ce: 0.011046
2021-11-30 14:04:23,739 iteration 1788 : loss : 0.037541, loss_ce: 0.013910
2021-11-30 14:04:25,275 iteration 1789 : loss : 0.040585, loss_ce: 0.020015
2021-11-30 14:04:26,925 iteration 1790 : loss : 0.049856, loss_ce: 0.017695
2021-11-30 14:04:28,477 iteration 1791 : loss : 0.044773, loss_ce: 0.020032
2021-11-30 14:04:30,003 iteration 1792 : loss : 0.042973, loss_ce: 0.014637
2021-11-30 14:04:31,559 iteration 1793 : loss : 0.048146, loss_ce: 0.019457
2021-11-30 14:04:33,063 iteration 1794 : loss : 0.057090, loss_ce: 0.032997
2021-11-30 14:04:34,499 iteration 1795 : loss : 0.031322, loss_ce: 0.012340
2021-11-30 14:04:36,095 iteration 1796 : loss : 0.053594, loss_ce: 0.023475
2021-11-30 14:04:37,570 iteration 1797 : loss : 0.046622, loss_ce: 0.021154
2021-11-30 14:04:39,115 iteration 1798 : loss : 0.036312, loss_ce: 0.013017
2021-11-30 14:04:40,693 iteration 1799 : loss : 0.052565, loss_ce: 0.020145
2021-11-30 14:04:42,151 iteration 1800 : loss : 0.049920, loss_ce: 0.017982
2021-11-30 14:04:43,669 iteration 1801 : loss : 0.054862, loss_ce: 0.022478
2021-11-30 14:04:45,231 iteration 1802 : loss : 0.044257, loss_ce: 0.015790
 26%|███████▋                     | 106/400 [49:35<2:19:55, 28.56s/it]2021-11-30 14:04:46,835 iteration 1803 : loss : 0.071824, loss_ce: 0.028894
2021-11-30 14:04:48,282 iteration 1804 : loss : 0.041176, loss_ce: 0.013256
2021-11-30 14:04:49,914 iteration 1805 : loss : 0.038616, loss_ce: 0.013271
2021-11-30 14:04:51,493 iteration 1806 : loss : 0.047972, loss_ce: 0.022750
2021-11-30 14:04:53,017 iteration 1807 : loss : 0.036979, loss_ce: 0.015138
2021-11-30 14:04:54,579 iteration 1808 : loss : 0.032174, loss_ce: 0.013627
2021-11-30 14:04:56,085 iteration 1809 : loss : 0.038621, loss_ce: 0.016532
2021-11-30 14:04:57,634 iteration 1810 : loss : 0.045106, loss_ce: 0.021833
2021-11-30 14:04:59,148 iteration 1811 : loss : 0.047029, loss_ce: 0.016698
2021-11-30 14:05:00,640 iteration 1812 : loss : 0.042894, loss_ce: 0.012623
2021-11-30 14:05:02,145 iteration 1813 : loss : 0.057264, loss_ce: 0.028302
2021-11-30 14:05:03,638 iteration 1814 : loss : 0.026354, loss_ce: 0.009932
2021-11-30 14:05:05,233 iteration 1815 : loss : 0.064123, loss_ce: 0.020295
2021-11-30 14:05:06,782 iteration 1816 : loss : 0.040033, loss_ce: 0.017107
2021-11-30 14:05:08,367 iteration 1817 : loss : 0.039921, loss_ce: 0.015310
2021-11-30 14:05:09,831 iteration 1818 : loss : 0.032390, loss_ce: 0.011188
2021-11-30 14:05:11,408 iteration 1819 : loss : 0.042301, loss_ce: 0.014967
 27%|███████▊                     | 107/400 [50:01<2:15:58, 27.85s/it]2021-11-30 14:05:12,877 iteration 1820 : loss : 0.030152, loss_ce: 0.013281
2021-11-30 14:05:14,544 iteration 1821 : loss : 0.049375, loss_ce: 0.016629
2021-11-30 14:05:16,098 iteration 1822 : loss : 0.045850, loss_ce: 0.022233
2021-11-30 14:05:17,688 iteration 1823 : loss : 0.051802, loss_ce: 0.017893
2021-11-30 14:05:19,235 iteration 1824 : loss : 0.067983, loss_ce: 0.023563
2021-11-30 14:05:20,728 iteration 1825 : loss : 0.045933, loss_ce: 0.016863
2021-11-30 14:05:22,305 iteration 1826 : loss : 0.030369, loss_ce: 0.009546
2021-11-30 14:05:23,793 iteration 1827 : loss : 0.031990, loss_ce: 0.011554
2021-11-30 14:05:25,330 iteration 1828 : loss : 0.046553, loss_ce: 0.019425
2021-11-30 14:05:26,831 iteration 1829 : loss : 0.046836, loss_ce: 0.021607
2021-11-30 14:05:28,421 iteration 1830 : loss : 0.070783, loss_ce: 0.027783
2021-11-30 14:05:29,956 iteration 1831 : loss : 0.036220, loss_ce: 0.014252
2021-11-30 14:05:31,447 iteration 1832 : loss : 0.038836, loss_ce: 0.015825
2021-11-30 14:05:32,911 iteration 1833 : loss : 0.045304, loss_ce: 0.019039
2021-11-30 14:05:34,439 iteration 1834 : loss : 0.037657, loss_ce: 0.012596
2021-11-30 14:05:35,976 iteration 1835 : loss : 0.036187, loss_ce: 0.014705
2021-11-30 14:05:37,477 iteration 1836 : loss : 0.060978, loss_ce: 0.021409
 27%|███████▊                     | 108/400 [50:28<2:12:55, 27.31s/it]2021-11-30 14:05:39,077 iteration 1837 : loss : 0.051027, loss_ce: 0.020548
2021-11-30 14:05:40,525 iteration 1838 : loss : 0.036212, loss_ce: 0.014779
2021-11-30 14:05:42,020 iteration 1839 : loss : 0.046053, loss_ce: 0.020348
2021-11-30 14:05:43,566 iteration 1840 : loss : 0.033719, loss_ce: 0.013634
2021-11-30 14:05:45,032 iteration 1841 : loss : 0.043867, loss_ce: 0.016204
2021-11-30 14:05:46,532 iteration 1842 : loss : 0.038587, loss_ce: 0.013902
2021-11-30 14:05:48,073 iteration 1843 : loss : 0.036854, loss_ce: 0.016936
2021-11-30 14:05:49,584 iteration 1844 : loss : 0.043106, loss_ce: 0.014252
2021-11-30 14:05:51,070 iteration 1845 : loss : 0.033918, loss_ce: 0.012085
2021-11-30 14:05:52,653 iteration 1846 : loss : 0.044736, loss_ce: 0.020672
2021-11-30 14:05:54,131 iteration 1847 : loss : 0.038717, loss_ce: 0.012374
2021-11-30 14:05:55,665 iteration 1848 : loss : 0.047408, loss_ce: 0.018440
2021-11-30 14:05:57,162 iteration 1849 : loss : 0.046123, loss_ce: 0.020302
2021-11-30 14:05:58,785 iteration 1850 : loss : 0.052879, loss_ce: 0.019071
2021-11-30 14:06:00,295 iteration 1851 : loss : 0.070060, loss_ce: 0.020139
2021-11-30 14:06:01,849 iteration 1852 : loss : 0.040149, loss_ce: 0.016027
2021-11-30 14:06:03,344 iteration 1853 : loss : 0.054172, loss_ce: 0.022886
 27%|███████▉                     | 109/400 [50:53<2:10:21, 26.88s/it]2021-11-30 14:06:04,868 iteration 1854 : loss : 0.034310, loss_ce: 0.013474
2021-11-30 14:06:06,428 iteration 1855 : loss : 0.047019, loss_ce: 0.024054
2021-11-30 14:06:08,009 iteration 1856 : loss : 0.047268, loss_ce: 0.016038
2021-11-30 14:06:09,591 iteration 1857 : loss : 0.039397, loss_ce: 0.018183
2021-11-30 14:06:11,123 iteration 1858 : loss : 0.036497, loss_ce: 0.014354
2021-11-30 14:06:12,652 iteration 1859 : loss : 0.045820, loss_ce: 0.017778
2021-11-30 14:06:14,144 iteration 1860 : loss : 0.033055, loss_ce: 0.011672
2021-11-30 14:06:15,718 iteration 1861 : loss : 0.049429, loss_ce: 0.020543
2021-11-30 14:06:17,181 iteration 1862 : loss : 0.037524, loss_ce: 0.019854
2021-11-30 14:06:18,700 iteration 1863 : loss : 0.046185, loss_ce: 0.020394
2021-11-30 14:06:20,257 iteration 1864 : loss : 0.069642, loss_ce: 0.018213
2021-11-30 14:06:21,689 iteration 1865 : loss : 0.031746, loss_ce: 0.014220
2021-11-30 14:06:23,277 iteration 1866 : loss : 0.029592, loss_ce: 0.013428
2021-11-30 14:06:24,795 iteration 1867 : loss : 0.032065, loss_ce: 0.013848
2021-11-30 14:06:26,292 iteration 1868 : loss : 0.038641, loss_ce: 0.015799
2021-11-30 14:06:27,768 iteration 1869 : loss : 0.044232, loss_ce: 0.013310
2021-11-30 14:06:27,768 Training Data Eval:
2021-11-30 14:06:35,356   Average segmentation loss on training set: 0.0296
2021-11-30 14:06:35,356 Validation Data Eval:
2021-11-30 14:06:37,981   Average segmentation loss on validation set: 0.0957
2021-11-30 14:06:39,551 iteration 1870 : loss : 0.038399, loss_ce: 0.013898
 28%|███████▉                     | 110/400 [51:30<2:23:26, 29.68s/it]2021-11-30 14:06:41,176 iteration 1871 : loss : 0.030405, loss_ce: 0.011890
2021-11-30 14:06:42,796 iteration 1872 : loss : 0.063897, loss_ce: 0.019201
2021-11-30 14:06:44,265 iteration 1873 : loss : 0.040391, loss_ce: 0.015245
2021-11-30 14:06:45,855 iteration 1874 : loss : 0.048924, loss_ce: 0.022911
2021-11-30 14:06:47,308 iteration 1875 : loss : 0.035226, loss_ce: 0.013925
2021-11-30 14:06:48,895 iteration 1876 : loss : 0.047851, loss_ce: 0.013969
2021-11-30 14:06:50,446 iteration 1877 : loss : 0.051021, loss_ce: 0.021717
2021-11-30 14:06:51,932 iteration 1878 : loss : 0.031561, loss_ce: 0.013001
2021-11-30 14:06:53,428 iteration 1879 : loss : 0.041347, loss_ce: 0.015218
2021-11-30 14:06:54,923 iteration 1880 : loss : 0.040686, loss_ce: 0.021640
2021-11-30 14:06:56,442 iteration 1881 : loss : 0.056370, loss_ce: 0.018635
2021-11-30 14:06:57,924 iteration 1882 : loss : 0.042592, loss_ce: 0.015308
2021-11-30 14:06:59,375 iteration 1883 : loss : 0.036625, loss_ce: 0.011541
2021-11-30 14:07:00,926 iteration 1884 : loss : 0.041462, loss_ce: 0.016152
2021-11-30 14:07:02,370 iteration 1885 : loss : 0.031803, loss_ce: 0.013556
2021-11-30 14:07:03,962 iteration 1886 : loss : 0.041333, loss_ce: 0.016343
2021-11-30 14:07:05,554 iteration 1887 : loss : 0.051235, loss_ce: 0.023431
 28%|████████                     | 111/400 [51:56<2:17:37, 28.57s/it]2021-11-30 14:07:07,086 iteration 1888 : loss : 0.040878, loss_ce: 0.017876
2021-11-30 14:07:08,657 iteration 1889 : loss : 0.045490, loss_ce: 0.018177
2021-11-30 14:07:10,195 iteration 1890 : loss : 0.034926, loss_ce: 0.010796
2021-11-30 14:07:11,760 iteration 1891 : loss : 0.054554, loss_ce: 0.018166
2021-11-30 14:07:13,283 iteration 1892 : loss : 0.038126, loss_ce: 0.015242
2021-11-30 14:07:14,818 iteration 1893 : loss : 0.042436, loss_ce: 0.022290
2021-11-30 14:07:16,328 iteration 1894 : loss : 0.049241, loss_ce: 0.022364
2021-11-30 14:07:17,861 iteration 1895 : loss : 0.037624, loss_ce: 0.013216
2021-11-30 14:07:19,490 iteration 1896 : loss : 0.080503, loss_ce: 0.039911
2021-11-30 14:07:20,987 iteration 1897 : loss : 0.041625, loss_ce: 0.014740
2021-11-30 14:07:22,562 iteration 1898 : loss : 0.037899, loss_ce: 0.012986
2021-11-30 14:07:24,085 iteration 1899 : loss : 0.055431, loss_ce: 0.027872
2021-11-30 14:07:25,525 iteration 1900 : loss : 0.039415, loss_ce: 0.016321
2021-11-30 14:07:27,055 iteration 1901 : loss : 0.033701, loss_ce: 0.012564
2021-11-30 14:07:28,585 iteration 1902 : loss : 0.049027, loss_ce: 0.020450
2021-11-30 14:07:30,168 iteration 1903 : loss : 0.066592, loss_ce: 0.018749
2021-11-30 14:07:31,777 iteration 1904 : loss : 0.052708, loss_ce: 0.017996
 28%|████████                     | 112/400 [52:22<2:13:45, 27.87s/it]2021-11-30 14:07:33,269 iteration 1905 : loss : 0.029417, loss_ce: 0.012836
2021-11-30 14:07:34,840 iteration 1906 : loss : 0.044183, loss_ce: 0.016301
2021-11-30 14:07:36,468 iteration 1907 : loss : 0.047177, loss_ce: 0.018458
2021-11-30 14:07:38,029 iteration 1908 : loss : 0.042988, loss_ce: 0.018144
2021-11-30 14:07:39,612 iteration 1909 : loss : 0.043706, loss_ce: 0.022075
2021-11-30 14:07:41,189 iteration 1910 : loss : 0.036270, loss_ce: 0.016372
2021-11-30 14:07:42,820 iteration 1911 : loss : 0.032576, loss_ce: 0.012017
2021-11-30 14:07:44,373 iteration 1912 : loss : 0.030785, loss_ce: 0.010330
2021-11-30 14:07:45,883 iteration 1913 : loss : 0.029992, loss_ce: 0.010455
2021-11-30 14:07:47,383 iteration 1914 : loss : 0.032523, loss_ce: 0.013496
2021-11-30 14:07:48,907 iteration 1915 : loss : 0.074091, loss_ce: 0.024282
2021-11-30 14:07:50,433 iteration 1916 : loss : 0.031725, loss_ce: 0.011622
2021-11-30 14:07:51,989 iteration 1917 : loss : 0.046153, loss_ce: 0.017478
2021-11-30 14:07:53,477 iteration 1918 : loss : 0.044362, loss_ce: 0.017503
2021-11-30 14:07:54,988 iteration 1919 : loss : 0.037180, loss_ce: 0.016434
2021-11-30 14:07:56,515 iteration 1920 : loss : 0.030366, loss_ce: 0.010037
2021-11-30 14:07:58,077 iteration 1921 : loss : 0.042566, loss_ce: 0.013728
 28%|████████▏                    | 113/400 [52:48<2:11:02, 27.40s/it]2021-11-30 14:07:59,613 iteration 1922 : loss : 0.035134, loss_ce: 0.012807
2021-11-30 14:08:01,074 iteration 1923 : loss : 0.029173, loss_ce: 0.012236
2021-11-30 14:08:02,618 iteration 1924 : loss : 0.062241, loss_ce: 0.030168
2021-11-30 14:08:04,082 iteration 1925 : loss : 0.043404, loss_ce: 0.019538
2021-11-30 14:08:05,570 iteration 1926 : loss : 0.039582, loss_ce: 0.018783
2021-11-30 14:08:07,151 iteration 1927 : loss : 0.062477, loss_ce: 0.023968
2021-11-30 14:08:08,719 iteration 1928 : loss : 0.029071, loss_ce: 0.011373
2021-11-30 14:08:10,212 iteration 1929 : loss : 0.041867, loss_ce: 0.018404
2021-11-30 14:08:11,728 iteration 1930 : loss : 0.046579, loss_ce: 0.014250
2021-11-30 14:08:13,238 iteration 1931 : loss : 0.052495, loss_ce: 0.014039
2021-11-30 14:08:14,765 iteration 1932 : loss : 0.058967, loss_ce: 0.022448
2021-11-30 14:08:16,280 iteration 1933 : loss : 0.040446, loss_ce: 0.014623
2021-11-30 14:08:17,692 iteration 1934 : loss : 0.028020, loss_ce: 0.011889
2021-11-30 14:08:19,180 iteration 1935 : loss : 0.049247, loss_ce: 0.023267
2021-11-30 14:08:20,739 iteration 1936 : loss : 0.030070, loss_ce: 0.010804
2021-11-30 14:08:22,291 iteration 1937 : loss : 0.035037, loss_ce: 0.013787
2021-11-30 14:08:23,848 iteration 1938 : loss : 0.037480, loss_ce: 0.012025
 28%|████████▎                    | 114/400 [53:14<2:08:16, 26.91s/it]2021-11-30 14:08:25,351 iteration 1939 : loss : 0.033064, loss_ce: 0.014166
2021-11-30 14:08:26,852 iteration 1940 : loss : 0.032739, loss_ce: 0.013113
2021-11-30 14:08:28,417 iteration 1941 : loss : 0.052402, loss_ce: 0.023509
2021-11-30 14:08:29,924 iteration 1942 : loss : 0.051123, loss_ce: 0.017507
2021-11-30 14:08:31,381 iteration 1943 : loss : 0.033350, loss_ce: 0.011486
2021-11-30 14:08:32,883 iteration 1944 : loss : 0.031684, loss_ce: 0.012366
2021-11-30 14:08:34,397 iteration 1945 : loss : 0.031119, loss_ce: 0.013940
2021-11-30 14:08:35,908 iteration 1946 : loss : 0.038848, loss_ce: 0.013462
2021-11-30 14:08:37,399 iteration 1947 : loss : 0.045789, loss_ce: 0.016636
2021-11-30 14:08:38,897 iteration 1948 : loss : 0.034519, loss_ce: 0.014019
2021-11-30 14:08:40,351 iteration 1949 : loss : 0.031761, loss_ce: 0.015808
2021-11-30 14:08:41,904 iteration 1950 : loss : 0.042557, loss_ce: 0.018667
2021-11-30 14:08:43,520 iteration 1951 : loss : 0.052176, loss_ce: 0.017145
2021-11-30 14:08:44,991 iteration 1952 : loss : 0.033209, loss_ce: 0.009819
2021-11-30 14:08:46,537 iteration 1953 : loss : 0.042559, loss_ce: 0.022611
2021-11-30 14:08:48,117 iteration 1954 : loss : 0.046892, loss_ce: 0.015135
2021-11-30 14:08:48,117 Training Data Eval:
2021-11-30 14:08:55,698   Average segmentation loss on training set: 0.0319
2021-11-30 14:08:55,698 Validation Data Eval:
2021-11-30 14:08:58,316   Average segmentation loss on validation set: 0.1212
2021-11-30 14:08:59,841 iteration 1955 : loss : 0.029639, loss_ce: 0.011711
 29%|████████▎                    | 115/400 [53:50<2:20:46, 29.64s/it]2021-11-30 14:09:01,455 iteration 1956 : loss : 0.040161, loss_ce: 0.015223
2021-11-30 14:09:02,929 iteration 1957 : loss : 0.029426, loss_ce: 0.011913
2021-11-30 14:09:04,422 iteration 1958 : loss : 0.034390, loss_ce: 0.016435
2021-11-30 14:09:06,032 iteration 1959 : loss : 0.069378, loss_ce: 0.015899
2021-11-30 14:09:07,529 iteration 1960 : loss : 0.041939, loss_ce: 0.014705
2021-11-30 14:09:09,058 iteration 1961 : loss : 0.035752, loss_ce: 0.012184
2021-11-30 14:09:10,565 iteration 1962 : loss : 0.031820, loss_ce: 0.011580
2021-11-30 14:09:12,127 iteration 1963 : loss : 0.045539, loss_ce: 0.019472
2021-11-30 14:09:13,627 iteration 1964 : loss : 0.036566, loss_ce: 0.010333
2021-11-30 14:09:15,114 iteration 1965 : loss : 0.041790, loss_ce: 0.019614
2021-11-30 14:09:16,603 iteration 1966 : loss : 0.033247, loss_ce: 0.016195
2021-11-30 14:09:18,080 iteration 1967 : loss : 0.034114, loss_ce: 0.009811
2021-11-30 14:09:19,542 iteration 1968 : loss : 0.040659, loss_ce: 0.020358
2021-11-30 14:09:21,086 iteration 1969 : loss : 0.039467, loss_ce: 0.014387
2021-11-30 14:09:22,723 iteration 1970 : loss : 0.046974, loss_ce: 0.015217
2021-11-30 14:09:24,154 iteration 1971 : loss : 0.036184, loss_ce: 0.011395
2021-11-30 14:09:25,779 iteration 1972 : loss : 0.044998, loss_ce: 0.016564
 29%|████████▍                    | 116/400 [54:16<2:15:01, 28.53s/it]2021-11-30 14:09:27,255 iteration 1973 : loss : 0.031667, loss_ce: 0.013439
2021-11-30 14:09:28,713 iteration 1974 : loss : 0.036281, loss_ce: 0.014226
2021-11-30 14:09:30,301 iteration 1975 : loss : 0.051087, loss_ce: 0.020001
2021-11-30 14:09:31,734 iteration 1976 : loss : 0.040075, loss_ce: 0.018241
2021-11-30 14:09:33,330 iteration 1977 : loss : 0.048811, loss_ce: 0.021252
2021-11-30 14:09:34,825 iteration 1978 : loss : 0.051547, loss_ce: 0.021422
2021-11-30 14:09:36,314 iteration 1979 : loss : 0.035215, loss_ce: 0.017053
2021-11-30 14:09:37,878 iteration 1980 : loss : 0.035014, loss_ce: 0.010947
2021-11-30 14:09:39,340 iteration 1981 : loss : 0.036990, loss_ce: 0.014072
2021-11-30 14:09:40,898 iteration 1982 : loss : 0.034064, loss_ce: 0.012586
2021-11-30 14:09:42,481 iteration 1983 : loss : 0.032618, loss_ce: 0.013642
2021-11-30 14:09:43,968 iteration 1984 : loss : 0.036623, loss_ce: 0.011542
2021-11-30 14:09:45,466 iteration 1985 : loss : 0.035400, loss_ce: 0.013896
2021-11-30 14:09:46,955 iteration 1986 : loss : 0.048401, loss_ce: 0.014699
2021-11-30 14:09:48,438 iteration 1987 : loss : 0.024904, loss_ce: 0.009886
2021-11-30 14:09:50,044 iteration 1988 : loss : 0.031517, loss_ce: 0.013814
2021-11-30 14:09:51,540 iteration 1989 : loss : 0.036012, loss_ce: 0.017696
 29%|████████▍                    | 117/400 [54:42<2:10:37, 27.69s/it]2021-11-30 14:09:53,095 iteration 1990 : loss : 0.050139, loss_ce: 0.023328
2021-11-30 14:09:54,537 iteration 1991 : loss : 0.037293, loss_ce: 0.016307
2021-11-30 14:09:56,089 iteration 1992 : loss : 0.033023, loss_ce: 0.014363
2021-11-30 14:09:57,608 iteration 1993 : loss : 0.048007, loss_ce: 0.012509
2021-11-30 14:09:59,145 iteration 1994 : loss : 0.034943, loss_ce: 0.013303
2021-11-30 14:10:00,652 iteration 1995 : loss : 0.040824, loss_ce: 0.015023
2021-11-30 14:10:02,178 iteration 1996 : loss : 0.044828, loss_ce: 0.019862
2021-11-30 14:10:03,708 iteration 1997 : loss : 0.034097, loss_ce: 0.014465
2021-11-30 14:10:05,251 iteration 1998 : loss : 0.048779, loss_ce: 0.020479
2021-11-30 14:10:06,791 iteration 1999 : loss : 0.042673, loss_ce: 0.019762
2021-11-30 14:10:08,425 iteration 2000 : loss : 0.058239, loss_ce: 0.012937
2021-11-30 14:10:09,930 iteration 2001 : loss : 0.039589, loss_ce: 0.018454
2021-11-30 14:10:11,375 iteration 2002 : loss : 0.036761, loss_ce: 0.014679
2021-11-30 14:10:12,783 iteration 2003 : loss : 0.025502, loss_ce: 0.012006
2021-11-30 14:10:14,255 iteration 2004 : loss : 0.045438, loss_ce: 0.012996
2021-11-30 14:10:15,824 iteration 2005 : loss : 0.032704, loss_ce: 0.012977
2021-11-30 14:10:17,362 iteration 2006 : loss : 0.032327, loss_ce: 0.011058
 30%|████████▌                    | 118/400 [55:07<2:07:31, 27.13s/it]2021-11-30 14:10:18,975 iteration 2007 : loss : 0.035637, loss_ce: 0.013075
2021-11-30 14:10:20,601 iteration 2008 : loss : 0.034371, loss_ce: 0.012029
2021-11-30 14:10:22,124 iteration 2009 : loss : 0.046226, loss_ce: 0.020099
2021-11-30 14:10:23,635 iteration 2010 : loss : 0.042970, loss_ce: 0.017550
2021-11-30 14:10:25,234 iteration 2011 : loss : 0.043178, loss_ce: 0.016024
2021-11-30 14:10:26,756 iteration 2012 : loss : 0.036640, loss_ce: 0.016193
2021-11-30 14:10:28,205 iteration 2013 : loss : 0.026240, loss_ce: 0.011611
2021-11-30 14:10:29,711 iteration 2014 : loss : 0.040565, loss_ce: 0.013071
2021-11-30 14:10:31,270 iteration 2015 : loss : 0.034627, loss_ce: 0.013597
2021-11-30 14:10:32,772 iteration 2016 : loss : 0.049811, loss_ce: 0.015892
2021-11-30 14:10:34,347 iteration 2017 : loss : 0.032074, loss_ce: 0.008678
2021-11-30 14:10:35,968 iteration 2018 : loss : 0.039487, loss_ce: 0.017488
2021-11-30 14:10:37,475 iteration 2019 : loss : 0.048869, loss_ce: 0.016808
2021-11-30 14:10:38,979 iteration 2020 : loss : 0.030845, loss_ce: 0.010261
2021-11-30 14:10:40,532 iteration 2021 : loss : 0.040383, loss_ce: 0.013270
2021-11-30 14:10:42,065 iteration 2022 : loss : 0.043261, loss_ce: 0.017702
2021-11-30 14:10:43,635 iteration 2023 : loss : 0.052834, loss_ce: 0.018915
 30%|████████▋                    | 119/400 [55:34<2:05:51, 26.87s/it]2021-11-30 14:10:45,139 iteration 2024 : loss : 0.028880, loss_ce: 0.008417
2021-11-30 14:10:46,671 iteration 2025 : loss : 0.029308, loss_ce: 0.013666
2021-11-30 14:10:48,234 iteration 2026 : loss : 0.035920, loss_ce: 0.015618
2021-11-30 14:10:49,729 iteration 2027 : loss : 0.039550, loss_ce: 0.010921
2021-11-30 14:10:51,199 iteration 2028 : loss : 0.028893, loss_ce: 0.014798
2021-11-30 14:10:52,711 iteration 2029 : loss : 0.034390, loss_ce: 0.013002
2021-11-30 14:10:54,192 iteration 2030 : loss : 0.049885, loss_ce: 0.019489
2021-11-30 14:10:55,712 iteration 2031 : loss : 0.042539, loss_ce: 0.015389
2021-11-30 14:10:57,305 iteration 2032 : loss : 0.052983, loss_ce: 0.023060
2021-11-30 14:10:58,939 iteration 2033 : loss : 0.048401, loss_ce: 0.020963
2021-11-30 14:11:00,422 iteration 2034 : loss : 0.035569, loss_ce: 0.014499
2021-11-30 14:11:01,938 iteration 2035 : loss : 0.039133, loss_ce: 0.013949
2021-11-30 14:11:03,502 iteration 2036 : loss : 0.035109, loss_ce: 0.016418
2021-11-30 14:11:05,032 iteration 2037 : loss : 0.056513, loss_ce: 0.014264
2021-11-30 14:11:06,597 iteration 2038 : loss : 0.066493, loss_ce: 0.023950
2021-11-30 14:11:08,200 iteration 2039 : loss : 0.038578, loss_ce: 0.014048
2021-11-30 14:11:08,200 Training Data Eval:
2021-11-30 14:11:15,784   Average segmentation loss on training set: 0.0297
2021-11-30 14:11:15,785 Validation Data Eval:
2021-11-30 14:11:18,402   Average segmentation loss on validation set: 0.1082
2021-11-30 14:11:19,986 iteration 2040 : loss : 0.045970, loss_ce: 0.018524
 30%|████████▋                    | 120/400 [56:10<2:18:41, 29.72s/it]2021-11-30 14:11:21,585 iteration 2041 : loss : 0.051600, loss_ce: 0.014421
2021-11-30 14:11:23,072 iteration 2042 : loss : 0.038666, loss_ce: 0.014386
2021-11-30 14:11:24,582 iteration 2043 : loss : 0.027841, loss_ce: 0.008852
2021-11-30 14:11:26,106 iteration 2044 : loss : 0.044067, loss_ce: 0.017829
2021-11-30 14:11:27,595 iteration 2045 : loss : 0.032654, loss_ce: 0.010407
2021-11-30 14:11:29,132 iteration 2046 : loss : 0.049932, loss_ce: 0.024259
2021-11-30 14:11:30,626 iteration 2047 : loss : 0.034841, loss_ce: 0.013913
2021-11-30 14:11:32,163 iteration 2048 : loss : 0.038077, loss_ce: 0.012314
2021-11-30 14:11:33,671 iteration 2049 : loss : 0.039521, loss_ce: 0.009432
2021-11-30 14:11:35,197 iteration 2050 : loss : 0.058318, loss_ce: 0.025325
2021-11-30 14:11:36,736 iteration 2051 : loss : 0.041944, loss_ce: 0.021395
2021-11-30 14:11:38,207 iteration 2052 : loss : 0.031323, loss_ce: 0.012709
2021-11-30 14:11:39,737 iteration 2053 : loss : 0.043924, loss_ce: 0.013112
2021-11-30 14:11:41,247 iteration 2054 : loss : 0.034802, loss_ce: 0.014383
2021-11-30 14:11:42,751 iteration 2055 : loss : 0.055256, loss_ce: 0.017501
2021-11-30 14:11:44,330 iteration 2056 : loss : 0.051168, loss_ce: 0.022453
2021-11-30 14:11:45,795 iteration 2057 : loss : 0.035753, loss_ce: 0.014580
 30%|████████▊                    | 121/400 [56:36<2:12:43, 28.54s/it]2021-11-30 14:11:47,361 iteration 2058 : loss : 0.045035, loss_ce: 0.022478
2021-11-30 14:11:48,932 iteration 2059 : loss : 0.047010, loss_ce: 0.017481
2021-11-30 14:11:50,378 iteration 2060 : loss : 0.038913, loss_ce: 0.014135
2021-11-30 14:11:51,921 iteration 2061 : loss : 0.047150, loss_ce: 0.018238
2021-11-30 14:11:53,419 iteration 2062 : loss : 0.061807, loss_ce: 0.023980
2021-11-30 14:11:54,938 iteration 2063 : loss : 0.084576, loss_ce: 0.019506
2021-11-30 14:11:56,413 iteration 2064 : loss : 0.034169, loss_ce: 0.012087
2021-11-30 14:11:57,904 iteration 2065 : loss : 0.046765, loss_ce: 0.014353
2021-11-30 14:11:59,429 iteration 2066 : loss : 0.038456, loss_ce: 0.013400
2021-11-30 14:12:00,973 iteration 2067 : loss : 0.031234, loss_ce: 0.011588
2021-11-30 14:12:02,558 iteration 2068 : loss : 0.030330, loss_ce: 0.013487
2021-11-30 14:12:04,044 iteration 2069 : loss : 0.049810, loss_ce: 0.015617
2021-11-30 14:12:05,608 iteration 2070 : loss : 0.041321, loss_ce: 0.016402
2021-11-30 14:12:07,187 iteration 2071 : loss : 0.050357, loss_ce: 0.018058
2021-11-30 14:12:08,719 iteration 2072 : loss : 0.051402, loss_ce: 0.020989
2021-11-30 14:12:10,285 iteration 2073 : loss : 0.040506, loss_ce: 0.013223
2021-11-30 14:12:11,834 iteration 2074 : loss : 0.039490, loss_ce: 0.020693
 30%|████████▊                    | 122/400 [57:02<2:08:47, 27.80s/it]2021-11-30 14:12:13,364 iteration 2075 : loss : 0.029573, loss_ce: 0.010649
2021-11-30 14:12:14,889 iteration 2076 : loss : 0.028252, loss_ce: 0.009044
2021-11-30 14:12:16,429 iteration 2077 : loss : 0.045520, loss_ce: 0.021351
2021-11-30 14:12:18,061 iteration 2078 : loss : 0.033783, loss_ce: 0.011544
2021-11-30 14:12:19,540 iteration 2079 : loss : 0.052403, loss_ce: 0.017879
2021-11-30 14:12:21,116 iteration 2080 : loss : 0.066772, loss_ce: 0.026587
2021-11-30 14:12:22,548 iteration 2081 : loss : 0.042003, loss_ce: 0.015629
2021-11-30 14:12:23,979 iteration 2082 : loss : 0.025842, loss_ce: 0.008922
2021-11-30 14:12:25,496 iteration 2083 : loss : 0.039807, loss_ce: 0.021642
2021-11-30 14:12:26,998 iteration 2084 : loss : 0.051765, loss_ce: 0.024483
2021-11-30 14:12:28,491 iteration 2085 : loss : 0.053715, loss_ce: 0.018736
2021-11-30 14:12:30,005 iteration 2086 : loss : 0.046658, loss_ce: 0.018340
2021-11-30 14:12:31,478 iteration 2087 : loss : 0.037603, loss_ce: 0.014780
2021-11-30 14:12:33,061 iteration 2088 : loss : 0.031733, loss_ce: 0.012832
2021-11-30 14:12:34,641 iteration 2089 : loss : 0.035386, loss_ce: 0.015898
2021-11-30 14:12:36,102 iteration 2090 : loss : 0.038465, loss_ce: 0.017808
2021-11-30 14:12:37,650 iteration 2091 : loss : 0.037048, loss_ce: 0.015769
 31%|████████▉                    | 123/400 [57:28<2:05:34, 27.20s/it]2021-11-30 14:12:39,132 iteration 2092 : loss : 0.036800, loss_ce: 0.016996
2021-11-30 14:12:40,636 iteration 2093 : loss : 0.043116, loss_ce: 0.016516
2021-11-30 14:12:42,147 iteration 2094 : loss : 0.044801, loss_ce: 0.010918
2021-11-30 14:12:43,608 iteration 2095 : loss : 0.025076, loss_ce: 0.011022
2021-11-30 14:12:45,207 iteration 2096 : loss : 0.044427, loss_ce: 0.022547
2021-11-30 14:12:46,734 iteration 2097 : loss : 0.058118, loss_ce: 0.020438
2021-11-30 14:12:48,260 iteration 2098 : loss : 0.069587, loss_ce: 0.028702
2021-11-30 14:12:49,796 iteration 2099 : loss : 0.032754, loss_ce: 0.010057
2021-11-30 14:12:51,357 iteration 2100 : loss : 0.045099, loss_ce: 0.024003
2021-11-30 14:12:52,907 iteration 2101 : loss : 0.033827, loss_ce: 0.011530
2021-11-30 14:12:54,455 iteration 2102 : loss : 0.042192, loss_ce: 0.020063
2021-11-30 14:12:55,899 iteration 2103 : loss : 0.045077, loss_ce: 0.020327
2021-11-30 14:12:57,363 iteration 2104 : loss : 0.053149, loss_ce: 0.016510
2021-11-30 14:12:58,968 iteration 2105 : loss : 0.056271, loss_ce: 0.016438
2021-11-30 14:13:00,465 iteration 2106 : loss : 0.026470, loss_ce: 0.011540
2021-11-30 14:13:02,053 iteration 2107 : loss : 0.037375, loss_ce: 0.013241
2021-11-30 14:13:03,577 iteration 2108 : loss : 0.037566, loss_ce: 0.016143
 31%|████████▉                    | 124/400 [57:54<2:03:21, 26.82s/it]2021-11-30 14:13:05,121 iteration 2109 : loss : 0.045587, loss_ce: 0.017789
2021-11-30 14:13:06,680 iteration 2110 : loss : 0.047149, loss_ce: 0.015119
2021-11-30 14:13:08,284 iteration 2111 : loss : 0.039403, loss_ce: 0.010573
2021-11-30 14:13:09,813 iteration 2112 : loss : 0.045904, loss_ce: 0.018259
2021-11-30 14:13:11,296 iteration 2113 : loss : 0.050508, loss_ce: 0.024514
2021-11-30 14:13:12,854 iteration 2114 : loss : 0.053109, loss_ce: 0.026501
2021-11-30 14:13:14,404 iteration 2115 : loss : 0.031135, loss_ce: 0.010295
2021-11-30 14:13:15,951 iteration 2116 : loss : 0.040232, loss_ce: 0.013034
2021-11-30 14:13:17,497 iteration 2117 : loss : 0.036487, loss_ce: 0.012465
2021-11-30 14:13:19,047 iteration 2118 : loss : 0.064607, loss_ce: 0.022830
2021-11-30 14:13:20,612 iteration 2119 : loss : 0.053383, loss_ce: 0.016915
2021-11-30 14:13:22,138 iteration 2120 : loss : 0.052616, loss_ce: 0.014475
2021-11-30 14:13:23,576 iteration 2121 : loss : 0.034049, loss_ce: 0.011394
2021-11-30 14:13:25,083 iteration 2122 : loss : 0.040508, loss_ce: 0.018257
2021-11-30 14:13:26,658 iteration 2123 : loss : 0.059368, loss_ce: 0.028492
2021-11-30 14:13:28,242 iteration 2124 : loss : 0.062426, loss_ce: 0.024670
2021-11-30 14:13:28,242 Training Data Eval:
2021-11-30 14:13:35,813   Average segmentation loss on training set: 0.0305
2021-11-30 14:13:35,813 Validation Data Eval:
2021-11-30 14:13:38,437   Average segmentation loss on validation set: 0.1299
2021-11-30 14:13:39,983 iteration 2125 : loss : 0.052186, loss_ce: 0.029801
 31%|█████████                    | 125/400 [58:30<2:16:06, 29.70s/it]2021-11-30 14:13:41,593 iteration 2126 : loss : 0.034681, loss_ce: 0.014162
2021-11-30 14:13:43,143 iteration 2127 : loss : 0.036738, loss_ce: 0.014879
2021-11-30 14:13:44,709 iteration 2128 : loss : 0.038814, loss_ce: 0.011737
2021-11-30 14:13:46,196 iteration 2129 : loss : 0.048546, loss_ce: 0.018502
2021-11-30 14:13:47,756 iteration 2130 : loss : 0.041779, loss_ce: 0.015225
2021-11-30 14:13:49,272 iteration 2131 : loss : 0.034613, loss_ce: 0.010117
2021-11-30 14:13:50,808 iteration 2132 : loss : 0.033713, loss_ce: 0.011906
2021-11-30 14:13:52,403 iteration 2133 : loss : 0.051676, loss_ce: 0.017307
2021-11-30 14:13:53,865 iteration 2134 : loss : 0.031230, loss_ce: 0.014827
2021-11-30 14:13:55,402 iteration 2135 : loss : 0.037093, loss_ce: 0.014493
2021-11-30 14:13:56,919 iteration 2136 : loss : 0.037595, loss_ce: 0.015122
2021-11-30 14:13:58,455 iteration 2137 : loss : 0.052900, loss_ce: 0.021884
2021-11-30 14:13:59,944 iteration 2138 : loss : 0.041942, loss_ce: 0.016402
2021-11-30 14:14:01,518 iteration 2139 : loss : 0.035543, loss_ce: 0.015194
2021-11-30 14:14:03,052 iteration 2140 : loss : 0.041201, loss_ce: 0.017590
2021-11-30 14:14:04,629 iteration 2141 : loss : 0.038492, loss_ce: 0.013214
2021-11-30 14:14:06,108 iteration 2142 : loss : 0.034276, loss_ce: 0.010601
 32%|█████████▏                   | 126/400 [58:56<2:10:43, 28.62s/it]2021-11-30 14:14:07,603 iteration 2143 : loss : 0.030675, loss_ce: 0.011012
2021-11-30 14:14:09,158 iteration 2144 : loss : 0.038190, loss_ce: 0.013027
2021-11-30 14:14:10,721 iteration 2145 : loss : 0.048584, loss_ce: 0.014086
2021-11-30 14:14:12,186 iteration 2146 : loss : 0.022054, loss_ce: 0.009574
2021-11-30 14:14:13,725 iteration 2147 : loss : 0.039767, loss_ce: 0.014910
2021-11-30 14:14:15,241 iteration 2148 : loss : 0.032900, loss_ce: 0.013013
2021-11-30 14:14:16,761 iteration 2149 : loss : 0.047495, loss_ce: 0.018720
2021-11-30 14:14:18,260 iteration 2150 : loss : 0.025454, loss_ce: 0.009994
2021-11-30 14:14:19,836 iteration 2151 : loss : 0.045141, loss_ce: 0.019206
2021-11-30 14:14:21,326 iteration 2152 : loss : 0.028139, loss_ce: 0.010320
2021-11-30 14:14:22,805 iteration 2153 : loss : 0.033346, loss_ce: 0.013622
2021-11-30 14:14:24,444 iteration 2154 : loss : 0.050770, loss_ce: 0.017001
2021-11-30 14:14:25,963 iteration 2155 : loss : 0.032791, loss_ce: 0.012518
2021-11-30 14:14:27,434 iteration 2156 : loss : 0.054014, loss_ce: 0.023894
2021-11-30 14:14:29,090 iteration 2157 : loss : 0.085896, loss_ce: 0.025153
2021-11-30 14:14:30,699 iteration 2158 : loss : 0.052284, loss_ce: 0.023029
2021-11-30 14:14:32,244 iteration 2159 : loss : 0.054184, loss_ce: 0.015572
 32%|█████████▏                   | 127/400 [59:22<2:06:50, 27.88s/it]2021-11-30 14:14:33,764 iteration 2160 : loss : 0.038548, loss_ce: 0.012621
2021-11-30 14:14:35,228 iteration 2161 : loss : 0.025795, loss_ce: 0.008247
2021-11-30 14:14:36,741 iteration 2162 : loss : 0.033028, loss_ce: 0.013760
2021-11-30 14:14:38,230 iteration 2163 : loss : 0.030464, loss_ce: 0.011165
2021-11-30 14:14:39,800 iteration 2164 : loss : 0.030679, loss_ce: 0.013494
2021-11-30 14:14:41,340 iteration 2165 : loss : 0.052458, loss_ce: 0.018400
2021-11-30 14:14:42,823 iteration 2166 : loss : 0.032910, loss_ce: 0.014596
2021-11-30 14:14:44,274 iteration 2167 : loss : 0.031494, loss_ce: 0.011351
2021-11-30 14:14:45,776 iteration 2168 : loss : 0.032715, loss_ce: 0.013890
2021-11-30 14:14:47,323 iteration 2169 : loss : 0.063439, loss_ce: 0.034335
2021-11-30 14:14:48,746 iteration 2170 : loss : 0.029283, loss_ce: 0.009358
2021-11-30 14:14:50,258 iteration 2171 : loss : 0.032755, loss_ce: 0.013636
2021-11-30 14:14:51,744 iteration 2172 : loss : 0.041776, loss_ce: 0.012409
2021-11-30 14:14:53,219 iteration 2173 : loss : 0.035424, loss_ce: 0.009341
2021-11-30 14:14:54,745 iteration 2174 : loss : 0.035315, loss_ce: 0.014649
2021-11-30 14:14:56,341 iteration 2175 : loss : 0.032554, loss_ce: 0.013449
2021-11-30 14:14:57,750 iteration 2176 : loss : 0.031846, loss_ce: 0.015824
 32%|█████████▎                   | 128/400 [59:48<2:03:09, 27.17s/it]2021-11-30 14:14:59,241 iteration 2177 : loss : 0.050266, loss_ce: 0.027618
2021-11-30 14:15:00,758 iteration 2178 : loss : 0.033075, loss_ce: 0.011632
2021-11-30 14:15:02,344 iteration 2179 : loss : 0.030051, loss_ce: 0.010013
2021-11-30 14:15:03,898 iteration 2180 : loss : 0.041100, loss_ce: 0.015129
2021-11-30 14:15:05,346 iteration 2181 : loss : 0.034941, loss_ce: 0.013119
2021-11-30 14:15:06,877 iteration 2182 : loss : 0.037967, loss_ce: 0.013256
2021-11-30 14:15:08,407 iteration 2183 : loss : 0.065524, loss_ce: 0.020892
2021-11-30 14:15:09,872 iteration 2184 : loss : 0.044070, loss_ce: 0.022037
2021-11-30 14:15:11,353 iteration 2185 : loss : 0.030973, loss_ce: 0.011755
2021-11-30 14:15:12,967 iteration 2186 : loss : 0.030416, loss_ce: 0.012313
2021-11-30 14:15:14,571 iteration 2187 : loss : 0.037810, loss_ce: 0.010892
2021-11-30 14:15:16,220 iteration 2188 : loss : 0.041773, loss_ce: 0.020479
2021-11-30 14:15:17,859 iteration 2189 : loss : 0.049661, loss_ce: 0.017890
2021-11-30 14:15:19,380 iteration 2190 : loss : 0.041494, loss_ce: 0.016982
2021-11-30 14:15:20,916 iteration 2191 : loss : 0.033877, loss_ce: 0.013231
2021-11-30 14:15:22,409 iteration 2192 : loss : 0.047500, loss_ce: 0.020010
2021-11-30 14:15:23,952 iteration 2193 : loss : 0.031284, loss_ce: 0.009925
 32%|████████▋                  | 129/400 [1:00:14<2:01:24, 26.88s/it]2021-11-30 14:15:25,541 iteration 2194 : loss : 0.039868, loss_ce: 0.015963
2021-11-30 14:15:27,094 iteration 2195 : loss : 0.041946, loss_ce: 0.021882
2021-11-30 14:15:28,662 iteration 2196 : loss : 0.037432, loss_ce: 0.017528
2021-11-30 14:15:30,277 iteration 2197 : loss : 0.030676, loss_ce: 0.010834
2021-11-30 14:15:31,793 iteration 2198 : loss : 0.052481, loss_ce: 0.018006
2021-11-30 14:15:33,312 iteration 2199 : loss : 0.030947, loss_ce: 0.013486
2021-11-30 14:15:34,898 iteration 2200 : loss : 0.062571, loss_ce: 0.012947
2021-11-30 14:15:36,371 iteration 2201 : loss : 0.032386, loss_ce: 0.012432
2021-11-30 14:15:37,981 iteration 2202 : loss : 0.051175, loss_ce: 0.023951
2021-11-30 14:15:39,519 iteration 2203 : loss : 0.031946, loss_ce: 0.009969
2021-11-30 14:15:40,979 iteration 2204 : loss : 0.026162, loss_ce: 0.008890
2021-11-30 14:15:42,532 iteration 2205 : loss : 0.040513, loss_ce: 0.021158
2021-11-30 14:15:44,128 iteration 2206 : loss : 0.044279, loss_ce: 0.019620
2021-11-30 14:15:45,676 iteration 2207 : loss : 0.040889, loss_ce: 0.010416
2021-11-30 14:15:47,255 iteration 2208 : loss : 0.048056, loss_ce: 0.014653
2021-11-30 14:15:48,778 iteration 2209 : loss : 0.048687, loss_ce: 0.017957
2021-11-30 14:15:48,778 Training Data Eval:
2021-11-30 14:15:56,357   Average segmentation loss on training set: 0.0342
2021-11-30 14:15:56,358 Validation Data Eval:
2021-11-30 14:15:58,985   Average segmentation loss on validation set: 0.0941
2021-11-30 14:16:00,548 iteration 2210 : loss : 0.045362, loss_ce: 0.024273
 32%|████████▊                  | 130/400 [1:00:51<2:14:04, 29.79s/it]2021-11-30 14:16:02,130 iteration 2211 : loss : 0.038209, loss_ce: 0.010574
2021-11-30 14:16:03,615 iteration 2212 : loss : 0.049896, loss_ce: 0.020893
2021-11-30 14:16:05,133 iteration 2213 : loss : 0.047264, loss_ce: 0.012300
2021-11-30 14:16:06,587 iteration 2214 : loss : 0.032500, loss_ce: 0.010808
2021-11-30 14:16:08,040 iteration 2215 : loss : 0.026817, loss_ce: 0.010306
2021-11-30 14:16:09,548 iteration 2216 : loss : 0.034171, loss_ce: 0.013360
2021-11-30 14:16:11,020 iteration 2217 : loss : 0.038498, loss_ce: 0.019752
2021-11-30 14:16:12,521 iteration 2218 : loss : 0.034720, loss_ce: 0.011266
2021-11-30 14:16:14,071 iteration 2219 : loss : 0.028910, loss_ce: 0.012312
2021-11-30 14:16:15,680 iteration 2220 : loss : 0.039663, loss_ce: 0.018760
2021-11-30 14:16:17,261 iteration 2221 : loss : 0.041255, loss_ce: 0.013589
2021-11-30 14:16:18,697 iteration 2222 : loss : 0.031789, loss_ce: 0.012283
2021-11-30 14:16:20,179 iteration 2223 : loss : 0.032701, loss_ce: 0.012401
2021-11-30 14:16:21,782 iteration 2224 : loss : 0.039193, loss_ce: 0.016400
2021-11-30 14:16:23,322 iteration 2225 : loss : 0.040840, loss_ce: 0.014605
2021-11-30 14:16:24,899 iteration 2226 : loss : 0.040022, loss_ce: 0.017444
2021-11-30 14:16:26,456 iteration 2227 : loss : 0.044057, loss_ce: 0.013935
 33%|████████▊                  | 131/400 [1:01:16<2:08:20, 28.63s/it]2021-11-30 14:16:28,088 iteration 2228 : loss : 0.041753, loss_ce: 0.017016
2021-11-30 14:16:29,616 iteration 2229 : loss : 0.047384, loss_ce: 0.017479
2021-11-30 14:16:31,257 iteration 2230 : loss : 0.047147, loss_ce: 0.019631
2021-11-30 14:16:32,782 iteration 2231 : loss : 0.036376, loss_ce: 0.018556
2021-11-30 14:16:34,298 iteration 2232 : loss : 0.039270, loss_ce: 0.018697
2021-11-30 14:16:36,002 iteration 2233 : loss : 0.060813, loss_ce: 0.018808
2021-11-30 14:16:37,558 iteration 2234 : loss : 0.047469, loss_ce: 0.015663
2021-11-30 14:16:39,079 iteration 2235 : loss : 0.039615, loss_ce: 0.015027
2021-11-30 14:16:40,591 iteration 2236 : loss : 0.030912, loss_ce: 0.012061
2021-11-30 14:16:42,126 iteration 2237 : loss : 0.031387, loss_ce: 0.013810
2021-11-30 14:16:43,594 iteration 2238 : loss : 0.039516, loss_ce: 0.011618
2021-11-30 14:16:45,104 iteration 2239 : loss : 0.026217, loss_ce: 0.007800
2021-11-30 14:16:46,546 iteration 2240 : loss : 0.039866, loss_ce: 0.010217
2021-11-30 14:16:48,054 iteration 2241 : loss : 0.029966, loss_ce: 0.011500
2021-11-30 14:16:49,624 iteration 2242 : loss : 0.038389, loss_ce: 0.012846
2021-11-30 14:16:51,183 iteration 2243 : loss : 0.049618, loss_ce: 0.026624
2021-11-30 14:16:52,676 iteration 2244 : loss : 0.025166, loss_ce: 0.008210
 33%|████████▉                  | 132/400 [1:01:43<2:04:38, 27.91s/it]2021-11-30 14:16:54,214 iteration 2245 : loss : 0.032019, loss_ce: 0.009995
2021-11-30 14:16:55,646 iteration 2246 : loss : 0.029430, loss_ce: 0.008687
2021-11-30 14:16:57,171 iteration 2247 : loss : 0.035946, loss_ce: 0.016549
2021-11-30 14:16:58,772 iteration 2248 : loss : 0.038362, loss_ce: 0.015955
2021-11-30 14:17:00,294 iteration 2249 : loss : 0.025121, loss_ce: 0.011689
2021-11-30 14:17:01,814 iteration 2250 : loss : 0.028888, loss_ce: 0.009829
2021-11-30 14:17:03,380 iteration 2251 : loss : 0.030703, loss_ce: 0.013858
2021-11-30 14:17:04,909 iteration 2252 : loss : 0.033171, loss_ce: 0.011824
2021-11-30 14:17:06,528 iteration 2253 : loss : 0.052299, loss_ce: 0.018887
2021-11-30 14:17:08,100 iteration 2254 : loss : 0.030318, loss_ce: 0.012281
2021-11-30 14:17:09,638 iteration 2255 : loss : 0.025465, loss_ce: 0.009074
2021-11-30 14:17:11,144 iteration 2256 : loss : 0.028545, loss_ce: 0.012209
2021-11-30 14:17:12,614 iteration 2257 : loss : 0.035870, loss_ce: 0.010461
2021-11-30 14:17:14,086 iteration 2258 : loss : 0.036774, loss_ce: 0.013699
2021-11-30 14:17:15,666 iteration 2259 : loss : 0.041732, loss_ce: 0.016629
2021-11-30 14:17:17,114 iteration 2260 : loss : 0.032124, loss_ce: 0.012208
2021-11-30 14:17:18,643 iteration 2261 : loss : 0.044879, loss_ce: 0.017358
 33%|████████▉                  | 133/400 [1:02:09<2:01:35, 27.32s/it]2021-11-30 14:17:20,148 iteration 2262 : loss : 0.031201, loss_ce: 0.016389
2021-11-30 14:17:21,736 iteration 2263 : loss : 0.042137, loss_ce: 0.014443
2021-11-30 14:17:23,344 iteration 2264 : loss : 0.036376, loss_ce: 0.010208
2021-11-30 14:17:24,896 iteration 2265 : loss : 0.034563, loss_ce: 0.012767
2021-11-30 14:17:26,389 iteration 2266 : loss : 0.034259, loss_ce: 0.014151
2021-11-30 14:17:27,902 iteration 2267 : loss : 0.022550, loss_ce: 0.007503
2021-11-30 14:17:29,438 iteration 2268 : loss : 0.034454, loss_ce: 0.013146
2021-11-30 14:17:30,913 iteration 2269 : loss : 0.033593, loss_ce: 0.016816
2021-11-30 14:17:32,428 iteration 2270 : loss : 0.036048, loss_ce: 0.010361
2021-11-30 14:17:33,928 iteration 2271 : loss : 0.031527, loss_ce: 0.011441
2021-11-30 14:17:35,453 iteration 2272 : loss : 0.046923, loss_ce: 0.023863
2021-11-30 14:17:37,001 iteration 2273 : loss : 0.027295, loss_ce: 0.008647
2021-11-30 14:17:38,539 iteration 2274 : loss : 0.038743, loss_ce: 0.013777
2021-11-30 14:17:40,118 iteration 2275 : loss : 0.036974, loss_ce: 0.014298
2021-11-30 14:17:41,606 iteration 2276 : loss : 0.029980, loss_ce: 0.011824
2021-11-30 14:17:43,151 iteration 2277 : loss : 0.040085, loss_ce: 0.013186
2021-11-30 14:17:44,620 iteration 2278 : loss : 0.025177, loss_ce: 0.009474
 34%|█████████                  | 134/400 [1:02:35<1:59:20, 26.92s/it]2021-11-30 14:17:46,116 iteration 2279 : loss : 0.051553, loss_ce: 0.018120
2021-11-30 14:17:47,651 iteration 2280 : loss : 0.034228, loss_ce: 0.015892
2021-11-30 14:17:49,156 iteration 2281 : loss : 0.047737, loss_ce: 0.012335
2021-11-30 14:17:50,710 iteration 2282 : loss : 0.023622, loss_ce: 0.008052
2021-11-30 14:17:52,302 iteration 2283 : loss : 0.033380, loss_ce: 0.014206
2021-11-30 14:17:53,809 iteration 2284 : loss : 0.047578, loss_ce: 0.021832
2021-11-30 14:17:55,301 iteration 2285 : loss : 0.026828, loss_ce: 0.009094
2021-11-30 14:17:56,807 iteration 2286 : loss : 0.074295, loss_ce: 0.034304
2021-11-30 14:17:58,319 iteration 2287 : loss : 0.034841, loss_ce: 0.014617
2021-11-30 14:17:59,880 iteration 2288 : loss : 0.028055, loss_ce: 0.009735
2021-11-30 14:18:01,364 iteration 2289 : loss : 0.036858, loss_ce: 0.010386
2021-11-30 14:18:02,931 iteration 2290 : loss : 0.035005, loss_ce: 0.017397
2021-11-30 14:18:04,432 iteration 2291 : loss : 0.028968, loss_ce: 0.012299
2021-11-30 14:18:05,926 iteration 2292 : loss : 0.041348, loss_ce: 0.018909
2021-11-30 14:18:07,369 iteration 2293 : loss : 0.031523, loss_ce: 0.015879
2021-11-30 14:18:08,931 iteration 2294 : loss : 0.055212, loss_ce: 0.019435
2021-11-30 14:18:08,932 Training Data Eval:
2021-11-30 14:18:16,530   Average segmentation loss on training set: 0.0291
2021-11-30 14:18:16,530 Validation Data Eval:
2021-11-30 14:18:19,152   Average segmentation loss on validation set: 0.1268
2021-11-30 14:18:20,756 iteration 2295 : loss : 0.027614, loss_ce: 0.012286
 34%|█████████                  | 135/400 [1:03:11<2:11:06, 29.68s/it]2021-11-30 14:18:22,251 iteration 2296 : loss : 0.024632, loss_ce: 0.011016
2021-11-30 14:18:23,757 iteration 2297 : loss : 0.026726, loss_ce: 0.011764
2021-11-30 14:18:25,270 iteration 2298 : loss : 0.029778, loss_ce: 0.014097
2021-11-30 14:18:26,862 iteration 2299 : loss : 0.041623, loss_ce: 0.021098
2021-11-30 14:18:28,359 iteration 2300 : loss : 0.027261, loss_ce: 0.011337
2021-11-30 14:18:29,952 iteration 2301 : loss : 0.028675, loss_ce: 0.008780
2021-11-30 14:18:31,510 iteration 2302 : loss : 0.057084, loss_ce: 0.020247
2021-11-30 14:18:33,068 iteration 2303 : loss : 0.033842, loss_ce: 0.012011
2021-11-30 14:18:34,663 iteration 2304 : loss : 0.034079, loss_ce: 0.013633
2021-11-30 14:18:36,220 iteration 2305 : loss : 0.039977, loss_ce: 0.017527
2021-11-30 14:18:37,837 iteration 2306 : loss : 0.052944, loss_ce: 0.024212
2021-11-30 14:18:39,346 iteration 2307 : loss : 0.050508, loss_ce: 0.016197
2021-11-30 14:18:40,829 iteration 2308 : loss : 0.035525, loss_ce: 0.012819
2021-11-30 14:18:42,320 iteration 2309 : loss : 0.034235, loss_ce: 0.015351
2021-11-30 14:18:43,901 iteration 2310 : loss : 0.032609, loss_ce: 0.013178
2021-11-30 14:18:45,360 iteration 2311 : loss : 0.039144, loss_ce: 0.011848
2021-11-30 14:18:46,883 iteration 2312 : loss : 0.038770, loss_ce: 0.016588
 34%|█████████▏                 | 136/400 [1:03:37<2:05:53, 28.61s/it]2021-11-30 14:18:48,474 iteration 2313 : loss : 0.036711, loss_ce: 0.013754
2021-11-30 14:18:49,892 iteration 2314 : loss : 0.026543, loss_ce: 0.008926
2021-11-30 14:18:51,377 iteration 2315 : loss : 0.022977, loss_ce: 0.008233
2021-11-30 14:18:52,979 iteration 2316 : loss : 0.029784, loss_ce: 0.012947
2021-11-30 14:18:54,430 iteration 2317 : loss : 0.029061, loss_ce: 0.008886
2021-11-30 14:18:55,923 iteration 2318 : loss : 0.036919, loss_ce: 0.019377
2021-11-30 14:18:57,453 iteration 2319 : loss : 0.027465, loss_ce: 0.010777
2021-11-30 14:18:59,052 iteration 2320 : loss : 0.032324, loss_ce: 0.013565
2021-11-30 14:19:00,560 iteration 2321 : loss : 0.031948, loss_ce: 0.013114
2021-11-30 14:19:02,082 iteration 2322 : loss : 0.032733, loss_ce: 0.014045
2021-11-30 14:19:03,516 iteration 2323 : loss : 0.033390, loss_ce: 0.012391
2021-11-30 14:19:05,045 iteration 2324 : loss : 0.027621, loss_ce: 0.011832
2021-11-30 14:19:06,459 iteration 2325 : loss : 0.027277, loss_ce: 0.011747
2021-11-30 14:19:07,961 iteration 2326 : loss : 0.046226, loss_ce: 0.013830
2021-11-30 14:19:09,424 iteration 2327 : loss : 0.030199, loss_ce: 0.012022
2021-11-30 14:19:10,945 iteration 2328 : loss : 0.035980, loss_ce: 0.015466
2021-11-30 14:19:12,430 iteration 2329 : loss : 0.028838, loss_ce: 0.010769
 34%|█████████▏                 | 137/400 [1:04:02<2:01:24, 27.70s/it]2021-11-30 14:19:14,003 iteration 2330 : loss : 0.040535, loss_ce: 0.014946
2021-11-30 14:19:15,487 iteration 2331 : loss : 0.025566, loss_ce: 0.010056
2021-11-30 14:19:17,082 iteration 2332 : loss : 0.045273, loss_ce: 0.018814
2021-11-30 14:19:18,602 iteration 2333 : loss : 0.060876, loss_ce: 0.035587
2021-11-30 14:19:20,229 iteration 2334 : loss : 0.035251, loss_ce: 0.015646
2021-11-30 14:19:21,829 iteration 2335 : loss : 0.073046, loss_ce: 0.034447
2021-11-30 14:19:23,419 iteration 2336 : loss : 0.035057, loss_ce: 0.016508
2021-11-30 14:19:24,934 iteration 2337 : loss : 0.065434, loss_ce: 0.025312
2021-11-30 14:19:26,477 iteration 2338 : loss : 0.053348, loss_ce: 0.020359
2021-11-30 14:19:28,020 iteration 2339 : loss : 0.037353, loss_ce: 0.013250
2021-11-30 14:19:29,484 iteration 2340 : loss : 0.026849, loss_ce: 0.010687
2021-11-30 14:19:31,028 iteration 2341 : loss : 0.032954, loss_ce: 0.012329
2021-11-30 14:19:32,569 iteration 2342 : loss : 0.031748, loss_ce: 0.012905
2021-11-30 14:19:34,214 iteration 2343 : loss : 0.042297, loss_ce: 0.014275
2021-11-30 14:19:35,710 iteration 2344 : loss : 0.051674, loss_ce: 0.016695
2021-11-30 14:19:37,212 iteration 2345 : loss : 0.039194, loss_ce: 0.018365
2021-11-30 14:19:38,724 iteration 2346 : loss : 0.045324, loss_ce: 0.017352
 34%|█████████▎                 | 138/400 [1:04:29<1:59:06, 27.28s/it]2021-11-30 14:19:40,369 iteration 2347 : loss : 0.055652, loss_ce: 0.024102
2021-11-30 14:19:41,917 iteration 2348 : loss : 0.029478, loss_ce: 0.011120
2021-11-30 14:19:43,393 iteration 2349 : loss : 0.033005, loss_ce: 0.012044
2021-11-30 14:19:44,891 iteration 2350 : loss : 0.052898, loss_ce: 0.018186
2021-11-30 14:19:46,489 iteration 2351 : loss : 0.035597, loss_ce: 0.016053
2021-11-30 14:19:47,991 iteration 2352 : loss : 0.027969, loss_ce: 0.014634
2021-11-30 14:19:49,486 iteration 2353 : loss : 0.025363, loss_ce: 0.010858
2021-11-30 14:19:50,963 iteration 2354 : loss : 0.025236, loss_ce: 0.011659
2021-11-30 14:19:52,444 iteration 2355 : loss : 0.039346, loss_ce: 0.012747
2021-11-30 14:19:54,009 iteration 2356 : loss : 0.045629, loss_ce: 0.015023
2021-11-30 14:19:55,524 iteration 2357 : loss : 0.055740, loss_ce: 0.014552
2021-11-30 14:19:57,068 iteration 2358 : loss : 0.033042, loss_ce: 0.012796
2021-11-30 14:19:58,563 iteration 2359 : loss : 0.047854, loss_ce: 0.017078
2021-11-30 14:20:00,036 iteration 2360 : loss : 0.056858, loss_ce: 0.018587
2021-11-30 14:20:01,568 iteration 2361 : loss : 0.040421, loss_ce: 0.014647
2021-11-30 14:20:03,200 iteration 2362 : loss : 0.038196, loss_ce: 0.016068
2021-11-30 14:20:04,716 iteration 2363 : loss : 0.028190, loss_ce: 0.012294
 35%|█████████▍                 | 139/400 [1:04:55<1:56:58, 26.89s/it]2021-11-30 14:20:06,351 iteration 2364 : loss : 0.032653, loss_ce: 0.011848
2021-11-30 14:20:07,946 iteration 2365 : loss : 0.029482, loss_ce: 0.011079
2021-11-30 14:20:09,513 iteration 2366 : loss : 0.037291, loss_ce: 0.015022
2021-11-30 14:20:10,979 iteration 2367 : loss : 0.036043, loss_ce: 0.008519
2021-11-30 14:20:12,464 iteration 2368 : loss : 0.031649, loss_ce: 0.013922
2021-11-30 14:20:13,998 iteration 2369 : loss : 0.039238, loss_ce: 0.011140
2021-11-30 14:20:15,529 iteration 2370 : loss : 0.040470, loss_ce: 0.014961
2021-11-30 14:20:17,075 iteration 2371 : loss : 0.031648, loss_ce: 0.012829
2021-11-30 14:20:18,579 iteration 2372 : loss : 0.032580, loss_ce: 0.010868
2021-11-30 14:20:20,077 iteration 2373 : loss : 0.052171, loss_ce: 0.018172
2021-11-30 14:20:21,550 iteration 2374 : loss : 0.035523, loss_ce: 0.013752
2021-11-30 14:20:23,043 iteration 2375 : loss : 0.031433, loss_ce: 0.011363
2021-11-30 14:20:24,579 iteration 2376 : loss : 0.036432, loss_ce: 0.018588
2021-11-30 14:20:26,128 iteration 2377 : loss : 0.033396, loss_ce: 0.015101
2021-11-30 14:20:27,657 iteration 2378 : loss : 0.024305, loss_ce: 0.009351
2021-11-30 14:20:29,220 iteration 2379 : loss : 0.047866, loss_ce: 0.019458
2021-11-30 14:20:29,220 Training Data Eval:
2021-11-30 14:20:36,806   Average segmentation loss on training set: 0.0225
2021-11-30 14:20:36,806 Validation Data Eval:
2021-11-30 14:20:39,433   Average segmentation loss on validation set: 0.0840
2021-11-30 14:20:40,924 iteration 2380 : loss : 0.025046, loss_ce: 0.011873
 35%|█████████▍                 | 140/400 [1:05:31<2:08:37, 29.68s/it]2021-11-30 14:20:42,432 iteration 2381 : loss : 0.032116, loss_ce: 0.011104
2021-11-30 14:20:43,991 iteration 2382 : loss : 0.039021, loss_ce: 0.012211
2021-11-30 14:20:45,473 iteration 2383 : loss : 0.023683, loss_ce: 0.007847
2021-11-30 14:20:47,038 iteration 2384 : loss : 0.044685, loss_ce: 0.014901
2021-11-30 14:20:48,622 iteration 2385 : loss : 0.038196, loss_ce: 0.014332
2021-11-30 14:20:50,150 iteration 2386 : loss : 0.029490, loss_ce: 0.009490
2021-11-30 14:20:51,634 iteration 2387 : loss : 0.030467, loss_ce: 0.010684
2021-11-30 14:20:53,166 iteration 2388 : loss : 0.037754, loss_ce: 0.015127
2021-11-30 14:20:54,622 iteration 2389 : loss : 0.019605, loss_ce: 0.006220
2021-11-30 14:20:56,150 iteration 2390 : loss : 0.033843, loss_ce: 0.017356
2021-11-30 14:20:57,646 iteration 2391 : loss : 0.036038, loss_ce: 0.020515
2021-11-30 14:20:59,187 iteration 2392 : loss : 0.041449, loss_ce: 0.018108
2021-11-30 14:21:00,733 iteration 2393 : loss : 0.045364, loss_ce: 0.013989
2021-11-30 14:21:02,174 iteration 2394 : loss : 0.029344, loss_ce: 0.009203
2021-11-30 14:21:03,752 iteration 2395 : loss : 0.035855, loss_ce: 0.013621
2021-11-30 14:21:05,223 iteration 2396 : loss : 0.024080, loss_ce: 0.011119
2021-11-30 14:21:06,773 iteration 2397 : loss : 0.033717, loss_ce: 0.012349
 35%|█████████▌                 | 141/400 [1:05:57<2:03:11, 28.54s/it]2021-11-30 14:21:08,343 iteration 2398 : loss : 0.037962, loss_ce: 0.013274
2021-11-30 14:21:09,826 iteration 2399 : loss : 0.053527, loss_ce: 0.015047
2021-11-30 14:21:11,416 iteration 2400 : loss : 0.031581, loss_ce: 0.013530
2021-11-30 14:21:12,936 iteration 2401 : loss : 0.029668, loss_ce: 0.008839
2021-11-30 14:21:14,505 iteration 2402 : loss : 0.032562, loss_ce: 0.016182
2021-11-30 14:21:15,985 iteration 2403 : loss : 0.031426, loss_ce: 0.012280
2021-11-30 14:21:17,443 iteration 2404 : loss : 0.023160, loss_ce: 0.010125
2021-11-30 14:21:18,891 iteration 2405 : loss : 0.025895, loss_ce: 0.009471
2021-11-30 14:21:20,530 iteration 2406 : loss : 0.056452, loss_ce: 0.015740
2021-11-30 14:21:21,998 iteration 2407 : loss : 0.030444, loss_ce: 0.014580
2021-11-30 14:21:23,473 iteration 2408 : loss : 0.027065, loss_ce: 0.010887
2021-11-30 14:21:25,026 iteration 2409 : loss : 0.034920, loss_ce: 0.011054
2021-11-30 14:21:26,599 iteration 2410 : loss : 0.042662, loss_ce: 0.017888
2021-11-30 14:21:28,144 iteration 2411 : loss : 0.043968, loss_ce: 0.013620
2021-11-30 14:21:29,625 iteration 2412 : loss : 0.022914, loss_ce: 0.008518
2021-11-30 14:21:31,203 iteration 2413 : loss : 0.067094, loss_ce: 0.034301
2021-11-30 14:21:32,715 iteration 2414 : loss : 0.035206, loss_ce: 0.015012
 36%|█████████▌                 | 142/400 [1:06:23<1:59:20, 27.76s/it]2021-11-30 14:21:34,293 iteration 2415 : loss : 0.036942, loss_ce: 0.012408
2021-11-30 14:21:35,806 iteration 2416 : loss : 0.028996, loss_ce: 0.010594
2021-11-30 14:21:37,325 iteration 2417 : loss : 0.043310, loss_ce: 0.013819
2021-11-30 14:21:38,923 iteration 2418 : loss : 0.033196, loss_ce: 0.011510
2021-11-30 14:21:40,473 iteration 2419 : loss : 0.036994, loss_ce: 0.019283
2021-11-30 14:21:42,085 iteration 2420 : loss : 0.037581, loss_ce: 0.015962
2021-11-30 14:21:43,682 iteration 2421 : loss : 0.041466, loss_ce: 0.013516
2021-11-30 14:21:45,256 iteration 2422 : loss : 0.033245, loss_ce: 0.011930
2021-11-30 14:21:46,782 iteration 2423 : loss : 0.034446, loss_ce: 0.012703
2021-11-30 14:21:48,288 iteration 2424 : loss : 0.026411, loss_ce: 0.010890
2021-11-30 14:21:49,903 iteration 2425 : loss : 0.044964, loss_ce: 0.015136
2021-11-30 14:21:51,410 iteration 2426 : loss : 0.036493, loss_ce: 0.010952
2021-11-30 14:21:52,840 iteration 2427 : loss : 0.029335, loss_ce: 0.012760
2021-11-30 14:21:54,325 iteration 2428 : loss : 0.036186, loss_ce: 0.009437
2021-11-30 14:21:55,826 iteration 2429 : loss : 0.040383, loss_ce: 0.015042
2021-11-30 14:21:57,314 iteration 2430 : loss : 0.019060, loss_ce: 0.007506
2021-11-30 14:21:58,844 iteration 2431 : loss : 0.038265, loss_ce: 0.019430
 36%|█████████▋                 | 143/400 [1:06:49<1:56:47, 27.27s/it]2021-11-30 14:22:00,362 iteration 2432 : loss : 0.028902, loss_ce: 0.008475
2021-11-30 14:22:01,869 iteration 2433 : loss : 0.026517, loss_ce: 0.010846
2021-11-30 14:22:03,394 iteration 2434 : loss : 0.033577, loss_ce: 0.011285
2021-11-30 14:22:05,012 iteration 2435 : loss : 0.036409, loss_ce: 0.018757
2021-11-30 14:22:06,465 iteration 2436 : loss : 0.027045, loss_ce: 0.011125
2021-11-30 14:22:08,041 iteration 2437 : loss : 0.025310, loss_ce: 0.009723
2021-11-30 14:22:09,620 iteration 2438 : loss : 0.047459, loss_ce: 0.017070
2021-11-30 14:22:11,177 iteration 2439 : loss : 0.031345, loss_ce: 0.010582
2021-11-30 14:22:12,744 iteration 2440 : loss : 0.036398, loss_ce: 0.014560
2021-11-30 14:22:14,267 iteration 2441 : loss : 0.033747, loss_ce: 0.012611
2021-11-30 14:22:15,791 iteration 2442 : loss : 0.028526, loss_ce: 0.010872
2021-11-30 14:22:17,258 iteration 2443 : loss : 0.031831, loss_ce: 0.012081
2021-11-30 14:22:18,790 iteration 2444 : loss : 0.031132, loss_ce: 0.011953
2021-11-30 14:22:20,317 iteration 2445 : loss : 0.027151, loss_ce: 0.011134
2021-11-30 14:22:21,921 iteration 2446 : loss : 0.036822, loss_ce: 0.017776
2021-11-30 14:22:23,385 iteration 2447 : loss : 0.026772, loss_ce: 0.008670
2021-11-30 14:22:24,964 iteration 2448 : loss : 0.029664, loss_ce: 0.010980
 36%|█████████▋                 | 144/400 [1:07:15<1:54:52, 26.92s/it]2021-11-30 14:22:26,461 iteration 2449 : loss : 0.047646, loss_ce: 0.015217
2021-11-30 14:22:27,919 iteration 2450 : loss : 0.026420, loss_ce: 0.013578
2021-11-30 14:22:29,438 iteration 2451 : loss : 0.027139, loss_ce: 0.008650
2021-11-30 14:22:30,922 iteration 2452 : loss : 0.033325, loss_ce: 0.012073
2021-11-30 14:22:32,467 iteration 2453 : loss : 0.031619, loss_ce: 0.011602
2021-11-30 14:22:33,967 iteration 2454 : loss : 0.031152, loss_ce: 0.010411
2021-11-30 14:22:35,441 iteration 2455 : loss : 0.037290, loss_ce: 0.016408
2021-11-30 14:22:36,909 iteration 2456 : loss : 0.025316, loss_ce: 0.009803
2021-11-30 14:22:38,417 iteration 2457 : loss : 0.027910, loss_ce: 0.010359
2021-11-30 14:22:39,892 iteration 2458 : loss : 0.028118, loss_ce: 0.010452
2021-11-30 14:22:41,323 iteration 2459 : loss : 0.023537, loss_ce: 0.009303
2021-11-30 14:22:42,817 iteration 2460 : loss : 0.034448, loss_ce: 0.008955
2021-11-30 14:22:44,401 iteration 2461 : loss : 0.032153, loss_ce: 0.010496
2021-11-30 14:22:45,946 iteration 2462 : loss : 0.037785, loss_ce: 0.012694
2021-11-30 14:22:47,450 iteration 2463 : loss : 0.026470, loss_ce: 0.011386
2021-11-30 14:22:48,994 iteration 2464 : loss : 0.030454, loss_ce: 0.012541
2021-11-30 14:22:48,994 Training Data Eval:
2021-11-30 14:22:56,618   Average segmentation loss on training set: 0.0228
2021-11-30 14:22:56,619 Validation Data Eval:
2021-11-30 14:22:59,251   Average segmentation loss on validation set: 0.1049
2021-11-30 14:23:00,760 iteration 2465 : loss : 0.028559, loss_ce: 0.010471
 36%|█████████▊                 | 145/400 [1:07:51<2:05:44, 29.58s/it]2021-11-30 14:23:02,378 iteration 2466 : loss : 0.031604, loss_ce: 0.012584
2021-11-30 14:23:03,975 iteration 2467 : loss : 0.029934, loss_ce: 0.011577
2021-11-30 14:23:05,485 iteration 2468 : loss : 0.043989, loss_ce: 0.025070
2021-11-30 14:23:06,960 iteration 2469 : loss : 0.036924, loss_ce: 0.016574
2021-11-30 14:23:08,469 iteration 2470 : loss : 0.039935, loss_ce: 0.012451
2021-11-30 14:23:10,059 iteration 2471 : loss : 0.036627, loss_ce: 0.012950
2021-11-30 14:23:11,547 iteration 2472 : loss : 0.051961, loss_ce: 0.024127
2021-11-30 14:23:13,111 iteration 2473 : loss : 0.032233, loss_ce: 0.013093
2021-11-30 14:23:14,603 iteration 2474 : loss : 0.028033, loss_ce: 0.009427
2021-11-30 14:23:16,141 iteration 2475 : loss : 0.036004, loss_ce: 0.011626
2021-11-30 14:23:17,618 iteration 2476 : loss : 0.029495, loss_ce: 0.014555
2021-11-30 14:23:19,220 iteration 2477 : loss : 0.043102, loss_ce: 0.018125
2021-11-30 14:23:20,775 iteration 2478 : loss : 0.026319, loss_ce: 0.009681
2021-11-30 14:23:22,222 iteration 2479 : loss : 0.024909, loss_ce: 0.009029
2021-11-30 14:23:23,744 iteration 2480 : loss : 0.044867, loss_ce: 0.016616
2021-11-30 14:23:25,326 iteration 2481 : loss : 0.025228, loss_ce: 0.008961
2021-11-30 14:23:26,810 iteration 2482 : loss : 0.025281, loss_ce: 0.010784
 36%|█████████▊                 | 146/400 [1:08:17<2:00:45, 28.52s/it]2021-11-30 14:23:28,438 iteration 2483 : loss : 0.031246, loss_ce: 0.013066
2021-11-30 14:23:29,975 iteration 2484 : loss : 0.030716, loss_ce: 0.006648
2021-11-30 14:23:31,463 iteration 2485 : loss : 0.029354, loss_ce: 0.012385
2021-11-30 14:23:32,971 iteration 2486 : loss : 0.029040, loss_ce: 0.011291
2021-11-30 14:23:34,486 iteration 2487 : loss : 0.032818, loss_ce: 0.011071
2021-11-30 14:23:36,057 iteration 2488 : loss : 0.039616, loss_ce: 0.014600
2021-11-30 14:23:37,571 iteration 2489 : loss : 0.029495, loss_ce: 0.012349
2021-11-30 14:23:39,119 iteration 2490 : loss : 0.031265, loss_ce: 0.013757
2021-11-30 14:23:40,721 iteration 2491 : loss : 0.031028, loss_ce: 0.012553
2021-11-30 14:23:42,135 iteration 2492 : loss : 0.022792, loss_ce: 0.008443
2021-11-30 14:23:43,669 iteration 2493 : loss : 0.029193, loss_ce: 0.012188
2021-11-30 14:23:45,183 iteration 2494 : loss : 0.032850, loss_ce: 0.008491
2021-11-30 14:23:46,680 iteration 2495 : loss : 0.029084, loss_ce: 0.013617
2021-11-30 14:23:48,358 iteration 2496 : loss : 0.044870, loss_ce: 0.012483
2021-11-30 14:23:49,909 iteration 2497 : loss : 0.037128, loss_ce: 0.012377
2021-11-30 14:23:51,472 iteration 2498 : loss : 0.035833, loss_ce: 0.014044
2021-11-30 14:23:52,943 iteration 2499 : loss : 0.028606, loss_ce: 0.007771
 37%|█████████▉                 | 147/400 [1:08:43<1:57:15, 27.81s/it]2021-11-30 14:23:54,486 iteration 2500 : loss : 0.029361, loss_ce: 0.010492
2021-11-30 14:23:55,990 iteration 2501 : loss : 0.028608, loss_ce: 0.008271
2021-11-30 14:23:57,571 iteration 2502 : loss : 0.050444, loss_ce: 0.021056
2021-11-30 14:23:59,038 iteration 2503 : loss : 0.030061, loss_ce: 0.011246
2021-11-30 14:24:00,516 iteration 2504 : loss : 0.027246, loss_ce: 0.009387
2021-11-30 14:24:02,069 iteration 2505 : loss : 0.044740, loss_ce: 0.019164
2021-11-30 14:24:03,588 iteration 2506 : loss : 0.030742, loss_ce: 0.009431
2021-11-30 14:24:05,057 iteration 2507 : loss : 0.027658, loss_ce: 0.012208
2021-11-30 14:24:06,554 iteration 2508 : loss : 0.029311, loss_ce: 0.011021
2021-11-30 14:24:08,052 iteration 2509 : loss : 0.046927, loss_ce: 0.016405
2021-11-30 14:24:09,542 iteration 2510 : loss : 0.020938, loss_ce: 0.009297
2021-11-30 14:24:11,073 iteration 2511 : loss : 0.023906, loss_ce: 0.009826
2021-11-30 14:24:12,633 iteration 2512 : loss : 0.031230, loss_ce: 0.012726
2021-11-30 14:24:14,202 iteration 2513 : loss : 0.033845, loss_ce: 0.011417
2021-11-30 14:24:15,725 iteration 2514 : loss : 0.028643, loss_ce: 0.008167
2021-11-30 14:24:17,229 iteration 2515 : loss : 0.026169, loss_ce: 0.012807
2021-11-30 14:24:18,735 iteration 2516 : loss : 0.021752, loss_ce: 0.009749
 37%|█████████▉                 | 148/400 [1:09:09<1:54:15, 27.20s/it]2021-11-30 14:24:20,281 iteration 2517 : loss : 0.027154, loss_ce: 0.010271
2021-11-30 14:24:21,804 iteration 2518 : loss : 0.032630, loss_ce: 0.009598
2021-11-30 14:24:23,330 iteration 2519 : loss : 0.030632, loss_ce: 0.011533
2021-11-30 14:24:24,848 iteration 2520 : loss : 0.053221, loss_ce: 0.025444
2021-11-30 14:24:26,357 iteration 2521 : loss : 0.028178, loss_ce: 0.010611
2021-11-30 14:24:27,873 iteration 2522 : loss : 0.028755, loss_ce: 0.014100
2021-11-30 14:24:29,438 iteration 2523 : loss : 0.066896, loss_ce: 0.019044
2021-11-30 14:24:30,960 iteration 2524 : loss : 0.024386, loss_ce: 0.010671
2021-11-30 14:24:32,496 iteration 2525 : loss : 0.037649, loss_ce: 0.014062
2021-11-30 14:24:34,037 iteration 2526 : loss : 0.030621, loss_ce: 0.011225
2021-11-30 14:24:35,570 iteration 2527 : loss : 0.028355, loss_ce: 0.010106
2021-11-30 14:24:37,129 iteration 2528 : loss : 0.035762, loss_ce: 0.011902
2021-11-30 14:24:38,658 iteration 2529 : loss : 0.042555, loss_ce: 0.015093
2021-11-30 14:24:40,181 iteration 2530 : loss : 0.030675, loss_ce: 0.014820
2021-11-30 14:24:41,766 iteration 2531 : loss : 0.030288, loss_ce: 0.012017
2021-11-30 14:24:43,282 iteration 2532 : loss : 0.036586, loss_ce: 0.013219
2021-11-30 14:24:44,816 iteration 2533 : loss : 0.042093, loss_ce: 0.011389
 37%|██████████                 | 149/400 [1:09:35<1:52:22, 26.86s/it]2021-11-30 14:24:46,299 iteration 2534 : loss : 0.035146, loss_ce: 0.016713
2021-11-30 14:24:47,887 iteration 2535 : loss : 0.032169, loss_ce: 0.010832
2021-11-30 14:24:49,384 iteration 2536 : loss : 0.034085, loss_ce: 0.015771
2021-11-30 14:24:50,885 iteration 2537 : loss : 0.030322, loss_ce: 0.012434
2021-11-30 14:24:52,305 iteration 2538 : loss : 0.024084, loss_ce: 0.009796
2021-11-30 14:24:53,840 iteration 2539 : loss : 0.036913, loss_ce: 0.014857
2021-11-30 14:24:55,306 iteration 2540 : loss : 0.024842, loss_ce: 0.007528
2021-11-30 14:24:56,816 iteration 2541 : loss : 0.027634, loss_ce: 0.011490
2021-11-30 14:24:58,282 iteration 2542 : loss : 0.027161, loss_ce: 0.009488
2021-11-30 14:24:59,749 iteration 2543 : loss : 0.036198, loss_ce: 0.012508
2021-11-30 14:25:01,259 iteration 2544 : loss : 0.039620, loss_ce: 0.013856
2021-11-30 14:25:02,901 iteration 2545 : loss : 0.023049, loss_ce: 0.009558
2021-11-30 14:25:04,534 iteration 2546 : loss : 0.037398, loss_ce: 0.015347
2021-11-30 14:25:05,998 iteration 2547 : loss : 0.022565, loss_ce: 0.011139
2021-11-30 14:25:07,549 iteration 2548 : loss : 0.036412, loss_ce: 0.019164
2021-11-30 14:25:09,086 iteration 2549 : loss : 0.041085, loss_ce: 0.011796
2021-11-30 14:25:09,087 Training Data Eval:
2021-11-30 14:25:16,652   Average segmentation loss on training set: 0.0214
2021-11-30 14:25:16,653 Validation Data Eval:
2021-11-30 14:25:19,267   Average segmentation loss on validation set: 0.0786
2021-11-30 14:25:21,196 Found new lowest validation loss at iteration 2549! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/UNET_RUNMC/ADAM/ADAM_best_val_loss.pth
2021-11-30 14:25:22,584 iteration 2550 : loss : 0.039778, loss_ce: 0.015501
 38%|██████████▏                | 150/400 [1:10:13<2:05:34, 30.14s/it]2021-11-30 14:25:24,015 iteration 2551 : loss : 0.025146, loss_ce: 0.011458
2021-11-30 14:25:25,503 iteration 2552 : loss : 0.023657, loss_ce: 0.008977
2021-11-30 14:25:26,914 iteration 2553 : loss : 0.021038, loss_ce: 0.006851
2021-11-30 14:25:28,415 iteration 2554 : loss : 0.023376, loss_ce: 0.009287
2021-11-30 14:25:29,915 iteration 2555 : loss : 0.033045, loss_ce: 0.009147
2021-11-30 14:25:31,477 iteration 2556 : loss : 0.044121, loss_ce: 0.024271
2021-11-30 14:25:32,989 iteration 2557 : loss : 0.033454, loss_ce: 0.016119
2021-11-30 14:25:34,504 iteration 2558 : loss : 0.030775, loss_ce: 0.014561
2021-11-30 14:25:36,104 iteration 2559 : loss : 0.028450, loss_ce: 0.010633
2021-11-30 14:25:37,626 iteration 2560 : loss : 0.024938, loss_ce: 0.012560
2021-11-30 14:25:39,228 iteration 2561 : loss : 0.040170, loss_ce: 0.014320
2021-11-30 14:25:40,761 iteration 2562 : loss : 0.035727, loss_ce: 0.014840
2021-11-30 14:25:42,313 iteration 2563 : loss : 0.040388, loss_ce: 0.017507
2021-11-30 14:25:43,798 iteration 2564 : loss : 0.040241, loss_ce: 0.018195
2021-11-30 14:25:45,277 iteration 2565 : loss : 0.039446, loss_ce: 0.016442
2021-11-30 14:25:46,775 iteration 2566 : loss : 0.030200, loss_ce: 0.010888
2021-11-30 14:25:48,314 iteration 2567 : loss : 0.040416, loss_ce: 0.012915
 38%|██████████▏                | 151/400 [1:10:38<1:59:34, 28.81s/it]2021-11-30 14:25:49,881 iteration 2568 : loss : 0.044293, loss_ce: 0.019565
2021-11-30 14:25:51,381 iteration 2569 : loss : 0.036318, loss_ce: 0.018541
2021-11-30 14:25:52,877 iteration 2570 : loss : 0.040727, loss_ce: 0.013889
2021-11-30 14:25:54,401 iteration 2571 : loss : 0.025060, loss_ce: 0.009125
2021-11-30 14:25:55,865 iteration 2572 : loss : 0.035584, loss_ce: 0.010050
2021-11-30 14:25:57,322 iteration 2573 : loss : 0.038934, loss_ce: 0.015407
2021-11-30 14:25:58,813 iteration 2574 : loss : 0.043838, loss_ce: 0.013294
2021-11-30 14:26:00,433 iteration 2575 : loss : 0.057537, loss_ce: 0.027535
2021-11-30 14:26:01,965 iteration 2576 : loss : 0.042222, loss_ce: 0.016027
2021-11-30 14:26:03,478 iteration 2577 : loss : 0.034333, loss_ce: 0.014568
2021-11-30 14:26:04,994 iteration 2578 : loss : 0.041556, loss_ce: 0.014007
2021-11-30 14:26:06,453 iteration 2579 : loss : 0.038734, loss_ce: 0.010529
2021-11-30 14:26:08,038 iteration 2580 : loss : 0.057220, loss_ce: 0.014841
2021-11-30 14:26:09,592 iteration 2581 : loss : 0.044360, loss_ce: 0.017464
2021-11-30 14:26:11,182 iteration 2582 : loss : 0.032102, loss_ce: 0.012184
2021-11-30 14:26:12,690 iteration 2583 : loss : 0.029853, loss_ce: 0.011148
2021-11-30 14:26:14,140 iteration 2584 : loss : 0.035226, loss_ce: 0.013167
 38%|██████████▎                | 152/400 [1:11:04<1:55:24, 27.92s/it]2021-11-30 14:26:15,697 iteration 2585 : loss : 0.025104, loss_ce: 0.007627
2021-11-30 14:26:17,218 iteration 2586 : loss : 0.032647, loss_ce: 0.015346
2021-11-30 14:26:18,679 iteration 2587 : loss : 0.031353, loss_ce: 0.011696
2021-11-30 14:26:20,194 iteration 2588 : loss : 0.036096, loss_ce: 0.016969
2021-11-30 14:26:21,746 iteration 2589 : loss : 0.041828, loss_ce: 0.013841
2021-11-30 14:26:23,307 iteration 2590 : loss : 0.036099, loss_ce: 0.015695
2021-11-30 14:26:24,783 iteration 2591 : loss : 0.030315, loss_ce: 0.009375
2021-11-30 14:26:26,265 iteration 2592 : loss : 0.033842, loss_ce: 0.011426
2021-11-30 14:26:27,770 iteration 2593 : loss : 0.027699, loss_ce: 0.012225
2021-11-30 14:26:29,400 iteration 2594 : loss : 0.046344, loss_ce: 0.021570
2021-11-30 14:26:30,934 iteration 2595 : loss : 0.030687, loss_ce: 0.011578
2021-11-30 14:26:32,405 iteration 2596 : loss : 0.025560, loss_ce: 0.011229
2021-11-30 14:26:33,877 iteration 2597 : loss : 0.027843, loss_ce: 0.009954
2021-11-30 14:26:35,380 iteration 2598 : loss : 0.024509, loss_ce: 0.009692
2021-11-30 14:26:36,884 iteration 2599 : loss : 0.032621, loss_ce: 0.007443
2021-11-30 14:26:38,376 iteration 2600 : loss : 0.035554, loss_ce: 0.012659
2021-11-30 14:26:39,857 iteration 2601 : loss : 0.028696, loss_ce: 0.011852
 38%|██████████▎                | 153/400 [1:11:30<1:52:13, 27.26s/it]2021-11-30 14:26:41,435 iteration 2602 : loss : 0.029917, loss_ce: 0.012387
2021-11-30 14:26:42,886 iteration 2603 : loss : 0.023621, loss_ce: 0.008263
2021-11-30 14:26:44,387 iteration 2604 : loss : 0.027628, loss_ce: 0.010450
2021-11-30 14:26:46,029 iteration 2605 : loss : 0.027782, loss_ce: 0.008482
2021-11-30 14:26:47,540 iteration 2606 : loss : 0.029688, loss_ce: 0.011317
2021-11-30 14:26:49,068 iteration 2607 : loss : 0.031180, loss_ce: 0.014763
2021-11-30 14:26:50,525 iteration 2608 : loss : 0.026595, loss_ce: 0.012532
2021-11-30 14:26:52,005 iteration 2609 : loss : 0.034918, loss_ce: 0.010919
2021-11-30 14:26:53,635 iteration 2610 : loss : 0.038905, loss_ce: 0.015622
2021-11-30 14:26:55,111 iteration 2611 : loss : 0.033148, loss_ce: 0.011187
2021-11-30 14:26:56,540 iteration 2612 : loss : 0.024514, loss_ce: 0.011932
2021-11-30 14:26:58,034 iteration 2613 : loss : 0.032297, loss_ce: 0.009619
2021-11-30 14:26:59,610 iteration 2614 : loss : 0.056500, loss_ce: 0.017303
2021-11-30 14:27:01,077 iteration 2615 : loss : 0.036191, loss_ce: 0.013983
2021-11-30 14:27:02,560 iteration 2616 : loss : 0.025916, loss_ce: 0.009857
2021-11-30 14:27:04,144 iteration 2617 : loss : 0.033665, loss_ce: 0.008916
2021-11-30 14:27:05,696 iteration 2618 : loss : 0.045273, loss_ce: 0.022274
 38%|██████████▍                | 154/400 [1:11:56<1:50:00, 26.83s/it]2021-11-30 14:27:07,300 iteration 2619 : loss : 0.041446, loss_ce: 0.012509
2021-11-30 14:27:08,789 iteration 2620 : loss : 0.033162, loss_ce: 0.012215
2021-11-30 14:27:10,328 iteration 2621 : loss : 0.036398, loss_ce: 0.012178
2021-11-30 14:27:11,888 iteration 2622 : loss : 0.035370, loss_ce: 0.017280
2021-11-30 14:27:13,439 iteration 2623 : loss : 0.056519, loss_ce: 0.029853
2021-11-30 14:27:14,915 iteration 2624 : loss : 0.025994, loss_ce: 0.008117
2021-11-30 14:27:16,407 iteration 2625 : loss : 0.026675, loss_ce: 0.010626
2021-11-30 14:27:17,993 iteration 2626 : loss : 0.047677, loss_ce: 0.021166
2021-11-30 14:27:19,518 iteration 2627 : loss : 0.044643, loss_ce: 0.012165
2021-11-30 14:27:20,988 iteration 2628 : loss : 0.029478, loss_ce: 0.011534
2021-11-30 14:27:22,552 iteration 2629 : loss : 0.051599, loss_ce: 0.016267
2021-11-30 14:27:24,016 iteration 2630 : loss : 0.032619, loss_ce: 0.012172
2021-11-30 14:27:25,551 iteration 2631 : loss : 0.039942, loss_ce: 0.016320
2021-11-30 14:27:27,092 iteration 2632 : loss : 0.034730, loss_ce: 0.013046
2021-11-30 14:27:28,582 iteration 2633 : loss : 0.034207, loss_ce: 0.014145
2021-11-30 14:27:30,116 iteration 2634 : loss : 0.026834, loss_ce: 0.008980
2021-11-30 14:27:30,116 Training Data Eval:
2021-11-30 14:27:37,696   Average segmentation loss on training set: 0.0246
2021-11-30 14:27:37,696 Validation Data Eval:
2021-11-30 14:27:40,319   Average segmentation loss on validation set: 0.1272
2021-11-30 14:27:41,904 iteration 2635 : loss : 0.036652, loss_ce: 0.015570
 39%|██████████▍                | 155/400 [1:12:32<2:01:02, 29.64s/it]2021-11-30 14:27:43,431 iteration 2636 : loss : 0.032103, loss_ce: 0.008787
2021-11-30 14:27:45,073 iteration 2637 : loss : 0.042297, loss_ce: 0.013610
2021-11-30 14:27:46,594 iteration 2638 : loss : 0.031261, loss_ce: 0.011442
2021-11-30 14:27:48,007 iteration 2639 : loss : 0.022925, loss_ce: 0.007953
2021-11-30 14:27:49,483 iteration 2640 : loss : 0.030331, loss_ce: 0.011223
2021-11-30 14:27:51,094 iteration 2641 : loss : 0.042490, loss_ce: 0.018206
2021-11-30 14:27:52,660 iteration 2642 : loss : 0.038195, loss_ce: 0.011809
2021-11-30 14:27:54,207 iteration 2643 : loss : 0.037773, loss_ce: 0.011921
2021-11-30 14:27:55,702 iteration 2644 : loss : 0.040709, loss_ce: 0.010898
2021-11-30 14:27:57,186 iteration 2645 : loss : 0.033025, loss_ce: 0.017006
2021-11-30 14:27:58,683 iteration 2646 : loss : 0.032608, loss_ce: 0.009868
2021-11-30 14:28:00,241 iteration 2647 : loss : 0.046854, loss_ce: 0.018838
2021-11-30 14:28:01,685 iteration 2648 : loss : 0.018760, loss_ce: 0.008451
2021-11-30 14:28:03,224 iteration 2649 : loss : 0.035089, loss_ce: 0.015112
2021-11-30 14:28:04,774 iteration 2650 : loss : 0.031133, loss_ce: 0.015103
2021-11-30 14:28:06,261 iteration 2651 : loss : 0.035310, loss_ce: 0.013258
2021-11-30 14:28:07,791 iteration 2652 : loss : 0.033169, loss_ce: 0.015028
 39%|██████████▌                | 156/400 [1:12:58<1:55:58, 28.52s/it]2021-11-30 14:28:09,430 iteration 2653 : loss : 0.041768, loss_ce: 0.018212
2021-11-30 14:28:10,917 iteration 2654 : loss : 0.024195, loss_ce: 0.009441
2021-11-30 14:28:12,372 iteration 2655 : loss : 0.023111, loss_ce: 0.008177
2021-11-30 14:28:13,824 iteration 2656 : loss : 0.022872, loss_ce: 0.010574
2021-11-30 14:28:15,295 iteration 2657 : loss : 0.022449, loss_ce: 0.008069
2021-11-30 14:28:16,794 iteration 2658 : loss : 0.024413, loss_ce: 0.010055
2021-11-30 14:28:18,415 iteration 2659 : loss : 0.034579, loss_ce: 0.015571
2021-11-30 14:28:19,911 iteration 2660 : loss : 0.029970, loss_ce: 0.010718
2021-11-30 14:28:21,351 iteration 2661 : loss : 0.026398, loss_ce: 0.009836
2021-11-30 14:28:22,926 iteration 2662 : loss : 0.032206, loss_ce: 0.013101
2021-11-30 14:28:24,398 iteration 2663 : loss : 0.028637, loss_ce: 0.011451
2021-11-30 14:28:25,969 iteration 2664 : loss : 0.024072, loss_ce: 0.008073
2021-11-30 14:28:27,468 iteration 2665 : loss : 0.026255, loss_ce: 0.009668
2021-11-30 14:28:28,985 iteration 2666 : loss : 0.041595, loss_ce: 0.014825
2021-11-30 14:28:30,535 iteration 2667 : loss : 0.021578, loss_ce: 0.007934
2021-11-30 14:28:32,074 iteration 2668 : loss : 0.061883, loss_ce: 0.021271
2021-11-30 14:28:33,625 iteration 2669 : loss : 0.033027, loss_ce: 0.012165
 39%|██████████▌                | 157/400 [1:13:24<1:52:14, 27.71s/it]2021-11-30 14:28:35,220 iteration 2670 : loss : 0.037682, loss_ce: 0.010671
2021-11-30 14:28:36,740 iteration 2671 : loss : 0.033337, loss_ce: 0.009810
2021-11-30 14:28:38,284 iteration 2672 : loss : 0.023056, loss_ce: 0.008932
2021-11-30 14:28:39,852 iteration 2673 : loss : 0.039982, loss_ce: 0.014558
2021-11-30 14:28:41,348 iteration 2674 : loss : 0.029414, loss_ce: 0.013566
2021-11-30 14:28:42,913 iteration 2675 : loss : 0.032516, loss_ce: 0.011928
2021-11-30 14:28:44,434 iteration 2676 : loss : 0.033047, loss_ce: 0.009832
2021-11-30 14:28:45,897 iteration 2677 : loss : 0.023492, loss_ce: 0.010278
2021-11-30 14:28:47,346 iteration 2678 : loss : 0.029982, loss_ce: 0.009230
2021-11-30 14:28:48,902 iteration 2679 : loss : 0.033553, loss_ce: 0.015665
2021-11-30 14:28:50,471 iteration 2680 : loss : 0.030908, loss_ce: 0.014208
2021-11-30 14:28:51,982 iteration 2681 : loss : 0.026651, loss_ce: 0.012469
2021-11-30 14:28:53,455 iteration 2682 : loss : 0.027078, loss_ce: 0.012006
2021-11-30 14:28:55,001 iteration 2683 : loss : 0.041856, loss_ce: 0.021720
2021-11-30 14:28:56,511 iteration 2684 : loss : 0.034886, loss_ce: 0.009080
2021-11-30 14:28:58,034 iteration 2685 : loss : 0.027435, loss_ce: 0.012350
2021-11-30 14:28:59,551 iteration 2686 : loss : 0.020868, loss_ce: 0.007598
 40%|██████████▋                | 158/400 [1:13:50<1:49:36, 27.18s/it]2021-11-30 14:29:01,084 iteration 2687 : loss : 0.020843, loss_ce: 0.009131
2021-11-30 14:29:02,572 iteration 2688 : loss : 0.043016, loss_ce: 0.014979
2021-11-30 14:29:03,990 iteration 2689 : loss : 0.021286, loss_ce: 0.008069
2021-11-30 14:29:05,495 iteration 2690 : loss : 0.024857, loss_ce: 0.010664
2021-11-30 14:29:07,024 iteration 2691 : loss : 0.019354, loss_ce: 0.006957
2021-11-30 14:29:08,539 iteration 2692 : loss : 0.029456, loss_ce: 0.010656
2021-11-30 14:29:10,008 iteration 2693 : loss : 0.035644, loss_ce: 0.016311
2021-11-30 14:29:11,436 iteration 2694 : loss : 0.025701, loss_ce: 0.009818
2021-11-30 14:29:12,991 iteration 2695 : loss : 0.042374, loss_ce: 0.015659
2021-11-30 14:29:14,624 iteration 2696 : loss : 0.041880, loss_ce: 0.016000
2021-11-30 14:29:16,192 iteration 2697 : loss : 0.029415, loss_ce: 0.015169
2021-11-30 14:29:17,638 iteration 2698 : loss : 0.021149, loss_ce: 0.008115
2021-11-30 14:29:19,112 iteration 2699 : loss : 0.031625, loss_ce: 0.010495
2021-11-30 14:29:20,606 iteration 2700 : loss : 0.032833, loss_ce: 0.009804
2021-11-30 14:29:22,130 iteration 2701 : loss : 0.032967, loss_ce: 0.015283
2021-11-30 14:29:23,672 iteration 2702 : loss : 0.052961, loss_ce: 0.010004
2021-11-30 14:29:25,213 iteration 2703 : loss : 0.036435, loss_ce: 0.013239
 40%|██████████▋                | 159/400 [1:14:15<1:47:19, 26.72s/it]2021-11-30 14:29:26,704 iteration 2704 : loss : 0.020990, loss_ce: 0.006069
2021-11-30 14:29:28,161 iteration 2705 : loss : 0.030420, loss_ce: 0.012588
2021-11-30 14:29:29,717 iteration 2706 : loss : 0.042602, loss_ce: 0.020584
2021-11-30 14:29:31,225 iteration 2707 : loss : 0.025765, loss_ce: 0.008484
2021-11-30 14:29:32,722 iteration 2708 : loss : 0.038156, loss_ce: 0.012661
2021-11-30 14:29:34,311 iteration 2709 : loss : 0.038681, loss_ce: 0.012262
2021-11-30 14:29:35,860 iteration 2710 : loss : 0.039909, loss_ce: 0.016789
2021-11-30 14:29:37,337 iteration 2711 : loss : 0.026087, loss_ce: 0.008802
2021-11-30 14:29:38,835 iteration 2712 : loss : 0.031873, loss_ce: 0.011858
2021-11-30 14:29:40,374 iteration 2713 : loss : 0.023700, loss_ce: 0.008588
2021-11-30 14:29:41,897 iteration 2714 : loss : 0.030492, loss_ce: 0.012932
2021-11-30 14:29:43,413 iteration 2715 : loss : 0.036398, loss_ce: 0.018265
2021-11-30 14:29:44,911 iteration 2716 : loss : 0.040232, loss_ce: 0.010747
2021-11-30 14:29:46,377 iteration 2717 : loss : 0.026798, loss_ce: 0.009247
2021-11-30 14:29:47,933 iteration 2718 : loss : 0.026465, loss_ce: 0.010130
2021-11-30 14:29:49,416 iteration 2719 : loss : 0.020512, loss_ce: 0.008656
2021-11-30 14:29:49,417 Training Data Eval:
2021-11-30 14:29:57,032   Average segmentation loss on training set: 0.0205
2021-11-30 14:29:57,032 Validation Data Eval:
2021-11-30 14:29:59,662   Average segmentation loss on validation set: 0.0737
2021-11-30 14:30:01,598 Found new lowest validation loss at iteration 2719! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/UNET_RUNMC/ADAM/ADAM_best_val_loss.pth
2021-11-30 14:30:03,009 iteration 2720 : loss : 0.026941, loss_ce: 0.010733
 40%|██████████▊                | 160/400 [1:14:53<2:00:09, 30.04s/it]2021-11-30 14:30:04,474 iteration 2721 : loss : 0.036540, loss_ce: 0.011948
2021-11-30 14:30:05,918 iteration 2722 : loss : 0.026152, loss_ce: 0.011238
2021-11-30 14:30:07,464 iteration 2723 : loss : 0.037709, loss_ce: 0.015354
2021-11-30 14:30:08,902 iteration 2724 : loss : 0.028006, loss_ce: 0.008988
2021-11-30 14:30:10,406 iteration 2725 : loss : 0.037681, loss_ce: 0.011488
2021-11-30 14:30:11,990 iteration 2726 : loss : 0.026999, loss_ce: 0.009407
2021-11-30 14:30:13,528 iteration 2727 : loss : 0.029220, loss_ce: 0.010100
2021-11-30 14:30:15,069 iteration 2728 : loss : 0.027234, loss_ce: 0.010171
2021-11-30 14:30:16,616 iteration 2729 : loss : 0.041712, loss_ce: 0.020090
2021-11-30 14:30:18,191 iteration 2730 : loss : 0.027884, loss_ce: 0.010189
2021-11-30 14:30:19,711 iteration 2731 : loss : 0.027955, loss_ce: 0.010161
2021-11-30 14:30:21,144 iteration 2732 : loss : 0.024405, loss_ce: 0.009287
2021-11-30 14:30:22,636 iteration 2733 : loss : 0.022249, loss_ce: 0.010045
2021-11-30 14:30:24,169 iteration 2734 : loss : 0.046155, loss_ce: 0.012937
2021-11-30 14:30:25,686 iteration 2735 : loss : 0.027373, loss_ce: 0.013186
2021-11-30 14:30:27,199 iteration 2736 : loss : 0.026810, loss_ce: 0.008342
2021-11-30 14:30:28,699 iteration 2737 : loss : 0.034035, loss_ce: 0.009450
 40%|██████████▊                | 161/400 [1:15:19<1:54:28, 28.74s/it]2021-11-30 14:30:30,290 iteration 2738 : loss : 0.042133, loss_ce: 0.020582
2021-11-30 14:30:31,762 iteration 2739 : loss : 0.024736, loss_ce: 0.007007
2021-11-30 14:30:33,356 iteration 2740 : loss : 0.053106, loss_ce: 0.019304
2021-11-30 14:30:34,857 iteration 2741 : loss : 0.033577, loss_ce: 0.014008
2021-11-30 14:30:36,370 iteration 2742 : loss : 0.046172, loss_ce: 0.019582
2021-11-30 14:30:37,826 iteration 2743 : loss : 0.034865, loss_ce: 0.012505
2021-11-30 14:30:39,346 iteration 2744 : loss : 0.021568, loss_ce: 0.007108
2021-11-30 14:30:40,811 iteration 2745 : loss : 0.026732, loss_ce: 0.007999
2021-11-30 14:30:42,416 iteration 2746 : loss : 0.071770, loss_ce: 0.016962
2021-11-30 14:30:43,897 iteration 2747 : loss : 0.024088, loss_ce: 0.009649
2021-11-30 14:30:45,471 iteration 2748 : loss : 0.027499, loss_ce: 0.007512
2021-11-30 14:30:47,044 iteration 2749 : loss : 0.033912, loss_ce: 0.012258
2021-11-30 14:30:48,543 iteration 2750 : loss : 0.034512, loss_ce: 0.013937
2021-11-30 14:30:50,054 iteration 2751 : loss : 0.046378, loss_ce: 0.012225
2021-11-30 14:30:51,674 iteration 2752 : loss : 0.030507, loss_ce: 0.011502
2021-11-30 14:30:53,279 iteration 2753 : loss : 0.056832, loss_ce: 0.028693
2021-11-30 14:30:54,802 iteration 2754 : loss : 0.031321, loss_ce: 0.015455
 40%|██████████▉                | 162/400 [1:15:45<1:50:50, 27.95s/it]2021-11-30 14:30:56,231 iteration 2755 : loss : 0.023161, loss_ce: 0.006882
2021-11-30 14:30:57,767 iteration 2756 : loss : 0.034607, loss_ce: 0.014236
2021-11-30 14:30:59,276 iteration 2757 : loss : 0.024501, loss_ce: 0.009794
2021-11-30 14:31:00,800 iteration 2758 : loss : 0.032225, loss_ce: 0.011347
2021-11-30 14:31:02,309 iteration 2759 : loss : 0.043948, loss_ce: 0.017061
2021-11-30 14:31:03,835 iteration 2760 : loss : 0.028522, loss_ce: 0.013735
2021-11-30 14:31:05,371 iteration 2761 : loss : 0.036876, loss_ce: 0.012134
2021-11-30 14:31:06,863 iteration 2762 : loss : 0.038081, loss_ce: 0.016780
2021-11-30 14:31:08,393 iteration 2763 : loss : 0.044574, loss_ce: 0.013527
2021-11-30 14:31:09,855 iteration 2764 : loss : 0.021568, loss_ce: 0.007591
2021-11-30 14:31:11,467 iteration 2765 : loss : 0.024051, loss_ce: 0.008273
2021-11-30 14:31:12,901 iteration 2766 : loss : 0.034535, loss_ce: 0.011555
2021-11-30 14:31:14,420 iteration 2767 : loss : 0.036067, loss_ce: 0.014234
2021-11-30 14:31:15,923 iteration 2768 : loss : 0.032389, loss_ce: 0.011338
2021-11-30 14:31:17,392 iteration 2769 : loss : 0.026909, loss_ce: 0.011102
2021-11-30 14:31:18,873 iteration 2770 : loss : 0.046448, loss_ce: 0.022777
2021-11-30 14:31:20,375 iteration 2771 : loss : 0.022032, loss_ce: 0.009611
 41%|███████████                | 163/400 [1:16:10<1:47:34, 27.23s/it]2021-11-30 14:31:21,865 iteration 2772 : loss : 0.024665, loss_ce: 0.008560
2021-11-30 14:31:23,391 iteration 2773 : loss : 0.023756, loss_ce: 0.009109
2021-11-30 14:31:24,913 iteration 2774 : loss : 0.057454, loss_ce: 0.013357
2021-11-30 14:31:26,436 iteration 2775 : loss : 0.037004, loss_ce: 0.014122
2021-11-30 14:31:27,925 iteration 2776 : loss : 0.028240, loss_ce: 0.010955
2021-11-30 14:31:29,500 iteration 2777 : loss : 0.025391, loss_ce: 0.009848
2021-11-30 14:31:30,983 iteration 2778 : loss : 0.023566, loss_ce: 0.007948
2021-11-30 14:31:32,452 iteration 2779 : loss : 0.030420, loss_ce: 0.012569
2021-11-30 14:31:33,956 iteration 2780 : loss : 0.028856, loss_ce: 0.014076
2021-11-30 14:31:35,578 iteration 2781 : loss : 0.037596, loss_ce: 0.014900
2021-11-30 14:31:37,168 iteration 2782 : loss : 0.027047, loss_ce: 0.011823
2021-11-30 14:31:38,654 iteration 2783 : loss : 0.033276, loss_ce: 0.010930
2021-11-30 14:31:40,056 iteration 2784 : loss : 0.029088, loss_ce: 0.008203
2021-11-30 14:31:41,523 iteration 2785 : loss : 0.025847, loss_ce: 0.011801
2021-11-30 14:31:42,986 iteration 2786 : loss : 0.031241, loss_ce: 0.012860
2021-11-30 14:31:44,479 iteration 2787 : loss : 0.026146, loss_ce: 0.010155
2021-11-30 14:31:46,101 iteration 2788 : loss : 0.036595, loss_ce: 0.015657
 41%|███████████                | 164/400 [1:16:36<1:45:20, 26.78s/it]2021-11-30 14:31:47,656 iteration 2789 : loss : 0.022824, loss_ce: 0.007372
2021-11-30 14:31:49,240 iteration 2790 : loss : 0.035838, loss_ce: 0.013787
2021-11-30 14:31:50,695 iteration 2791 : loss : 0.021147, loss_ce: 0.006269
2021-11-30 14:31:52,202 iteration 2792 : loss : 0.027472, loss_ce: 0.011136
2021-11-30 14:31:53,709 iteration 2793 : loss : 0.025763, loss_ce: 0.008671
2021-11-30 14:31:55,269 iteration 2794 : loss : 0.033606, loss_ce: 0.017074
2021-11-30 14:31:56,779 iteration 2795 : loss : 0.034670, loss_ce: 0.013597
2021-11-30 14:31:58,247 iteration 2796 : loss : 0.030503, loss_ce: 0.009765
2021-11-30 14:31:59,793 iteration 2797 : loss : 0.036252, loss_ce: 0.014923
2021-11-30 14:32:01,321 iteration 2798 : loss : 0.039972, loss_ce: 0.011139
2021-11-30 14:32:02,941 iteration 2799 : loss : 0.035419, loss_ce: 0.012806
2021-11-30 14:32:04,480 iteration 2800 : loss : 0.032515, loss_ce: 0.015872
2021-11-30 14:32:05,905 iteration 2801 : loss : 0.035885, loss_ce: 0.010068
2021-11-30 14:32:07,365 iteration 2802 : loss : 0.022300, loss_ce: 0.007468
2021-11-30 14:32:08,908 iteration 2803 : loss : 0.038846, loss_ce: 0.017804
2021-11-30 14:32:10,335 iteration 2804 : loss : 0.031259, loss_ce: 0.011746
2021-11-30 14:32:10,336 Training Data Eval:
2021-11-30 14:32:17,932   Average segmentation loss on training set: 0.0206
2021-11-30 14:32:17,933 Validation Data Eval:
2021-11-30 14:32:20,548   Average segmentation loss on validation set: 0.0767
2021-11-30 14:32:22,155 iteration 2805 : loss : 0.031135, loss_ce: 0.012237
 41%|███████████▏               | 165/400 [1:17:12<1:55:47, 29.57s/it]2021-11-30 14:32:23,785 iteration 2806 : loss : 0.026538, loss_ce: 0.010693
2021-11-30 14:32:25,372 iteration 2807 : loss : 0.056288, loss_ce: 0.016838
2021-11-30 14:32:26,924 iteration 2808 : loss : 0.037775, loss_ce: 0.011844
2021-11-30 14:32:28,464 iteration 2809 : loss : 0.035120, loss_ce: 0.013043
2021-11-30 14:32:29,935 iteration 2810 : loss : 0.035398, loss_ce: 0.012036
2021-11-30 14:32:31,495 iteration 2811 : loss : 0.033482, loss_ce: 0.017290
2021-11-30 14:32:32,956 iteration 2812 : loss : 0.018793, loss_ce: 0.007414
2021-11-30 14:32:34,531 iteration 2813 : loss : 0.047978, loss_ce: 0.022217
2021-11-30 14:32:36,082 iteration 2814 : loss : 0.029417, loss_ce: 0.010207
2021-11-30 14:32:37,594 iteration 2815 : loss : 0.028762, loss_ce: 0.013034
2021-11-30 14:32:39,117 iteration 2816 : loss : 0.023447, loss_ce: 0.008449
2021-11-30 14:32:40,696 iteration 2817 : loss : 0.040174, loss_ce: 0.008449
2021-11-30 14:32:42,281 iteration 2818 : loss : 0.036894, loss_ce: 0.015111
2021-11-30 14:32:43,778 iteration 2819 : loss : 0.030878, loss_ce: 0.013766
2021-11-30 14:32:45,385 iteration 2820 : loss : 0.047243, loss_ce: 0.018018
2021-11-30 14:32:46,978 iteration 2821 : loss : 0.038860, loss_ce: 0.013992
2021-11-30 14:32:48,522 iteration 2822 : loss : 0.022804, loss_ce: 0.007491
 42%|███████████▏               | 166/400 [1:17:39<1:51:33, 28.61s/it]2021-11-30 14:32:50,169 iteration 2823 : loss : 0.041901, loss_ce: 0.018331
2021-11-30 14:32:51,650 iteration 2824 : loss : 0.026512, loss_ce: 0.012154
2021-11-30 14:32:53,187 iteration 2825 : loss : 0.034286, loss_ce: 0.014449
2021-11-30 14:32:54,787 iteration 2826 : loss : 0.055832, loss_ce: 0.021669
2021-11-30 14:32:56,408 iteration 2827 : loss : 0.048246, loss_ce: 0.014403
2021-11-30 14:32:57,945 iteration 2828 : loss : 0.036928, loss_ce: 0.012163
2021-11-30 14:32:59,468 iteration 2829 : loss : 0.031433, loss_ce: 0.015067
2021-11-30 14:33:00,975 iteration 2830 : loss : 0.043687, loss_ce: 0.015782
2021-11-30 14:33:02,406 iteration 2831 : loss : 0.030950, loss_ce: 0.014218
2021-11-30 14:33:04,050 iteration 2832 : loss : 0.040469, loss_ce: 0.018040
2021-11-30 14:33:05,557 iteration 2833 : loss : 0.032354, loss_ce: 0.012499
2021-11-30 14:33:07,123 iteration 2834 : loss : 0.028355, loss_ce: 0.010184
2021-11-30 14:33:08,657 iteration 2835 : loss : 0.049588, loss_ce: 0.015882
2021-11-30 14:33:10,166 iteration 2836 : loss : 0.032297, loss_ce: 0.011185
2021-11-30 14:33:11,743 iteration 2837 : loss : 0.034086, loss_ce: 0.012442
2021-11-30 14:33:13,191 iteration 2838 : loss : 0.029458, loss_ce: 0.012359
2021-11-30 14:33:14,735 iteration 2839 : loss : 0.032867, loss_ce: 0.012171
 42%|███████████▎               | 167/400 [1:18:05<1:48:17, 27.89s/it]2021-11-30 14:33:16,351 iteration 2840 : loss : 0.045295, loss_ce: 0.016390
2021-11-30 14:33:17,876 iteration 2841 : loss : 0.029720, loss_ce: 0.010499
2021-11-30 14:33:19,386 iteration 2842 : loss : 0.024208, loss_ce: 0.007857
2021-11-30 14:33:20,948 iteration 2843 : loss : 0.034382, loss_ce: 0.009385
2021-11-30 14:33:22,476 iteration 2844 : loss : 0.031830, loss_ce: 0.012139
2021-11-30 14:33:23,997 iteration 2845 : loss : 0.025523, loss_ce: 0.008537
2021-11-30 14:33:25,522 iteration 2846 : loss : 0.022808, loss_ce: 0.007625
2021-11-30 14:33:26,936 iteration 2847 : loss : 0.019016, loss_ce: 0.009711
2021-11-30 14:33:28,470 iteration 2848 : loss : 0.029182, loss_ce: 0.009658
2021-11-30 14:33:30,054 iteration 2849 : loss : 0.040564, loss_ce: 0.012723
2021-11-30 14:33:31,604 iteration 2850 : loss : 0.024100, loss_ce: 0.008786
2021-11-30 14:33:33,162 iteration 2851 : loss : 0.030462, loss_ce: 0.010949
2021-11-30 14:33:34,697 iteration 2852 : loss : 0.067396, loss_ce: 0.017740
2021-11-30 14:33:36,278 iteration 2853 : loss : 0.029624, loss_ce: 0.010019
2021-11-30 14:33:37,818 iteration 2854 : loss : 0.027759, loss_ce: 0.009325
2021-11-30 14:33:39,298 iteration 2855 : loss : 0.023051, loss_ce: 0.010351
2021-11-30 14:33:40,854 iteration 2856 : loss : 0.037157, loss_ce: 0.016146
 42%|███████████▎               | 168/400 [1:18:31<1:45:46, 27.36s/it]2021-11-30 14:33:42,330 iteration 2857 : loss : 0.024234, loss_ce: 0.007550
2021-11-30 14:33:43,869 iteration 2858 : loss : 0.028565, loss_ce: 0.012427
2021-11-30 14:33:45,351 iteration 2859 : loss : 0.028820, loss_ce: 0.011013
2021-11-30 14:33:46,908 iteration 2860 : loss : 0.034440, loss_ce: 0.011084
2021-11-30 14:33:48,348 iteration 2861 : loss : 0.027699, loss_ce: 0.011865
2021-11-30 14:33:49,949 iteration 2862 : loss : 0.042455, loss_ce: 0.011683
2021-11-30 14:33:51,425 iteration 2863 : loss : 0.041120, loss_ce: 0.011085
2021-11-30 14:33:52,964 iteration 2864 : loss : 0.027806, loss_ce: 0.010907
2021-11-30 14:33:54,533 iteration 2865 : loss : 0.032114, loss_ce: 0.011004
2021-11-30 14:33:56,035 iteration 2866 : loss : 0.030663, loss_ce: 0.011262
2021-11-30 14:33:57,656 iteration 2867 : loss : 0.032526, loss_ce: 0.015446
2021-11-30 14:33:59,141 iteration 2868 : loss : 0.032780, loss_ce: 0.011486
2021-11-30 14:34:00,743 iteration 2869 : loss : 0.041517, loss_ce: 0.015534
2021-11-30 14:34:02,278 iteration 2870 : loss : 0.026965, loss_ce: 0.008753
2021-11-30 14:34:03,765 iteration 2871 : loss : 0.022490, loss_ce: 0.008764
2021-11-30 14:34:05,206 iteration 2872 : loss : 0.028447, loss_ce: 0.011662
2021-11-30 14:34:06,786 iteration 2873 : loss : 0.030189, loss_ce: 0.009344
 42%|███████████▍               | 169/400 [1:18:57<1:43:41, 26.93s/it]2021-11-30 14:34:08,386 iteration 2874 : loss : 0.039525, loss_ce: 0.011718
2021-11-30 14:34:09,917 iteration 2875 : loss : 0.039730, loss_ce: 0.012675
2021-11-30 14:34:11,438 iteration 2876 : loss : 0.033550, loss_ce: 0.014085
2021-11-30 14:34:13,018 iteration 2877 : loss : 0.040648, loss_ce: 0.012088
2021-11-30 14:34:14,543 iteration 2878 : loss : 0.028025, loss_ce: 0.013008
2021-11-30 14:34:16,110 iteration 2879 : loss : 0.031697, loss_ce: 0.010623
2021-11-30 14:34:17,694 iteration 2880 : loss : 0.035818, loss_ce: 0.011317
2021-11-30 14:34:19,219 iteration 2881 : loss : 0.029229, loss_ce: 0.011510
2021-11-30 14:34:20,793 iteration 2882 : loss : 0.025668, loss_ce: 0.012355
2021-11-30 14:34:22,284 iteration 2883 : loss : 0.030303, loss_ce: 0.013845
2021-11-30 14:34:23,784 iteration 2884 : loss : 0.030760, loss_ce: 0.012640
2021-11-30 14:34:25,332 iteration 2885 : loss : 0.027448, loss_ce: 0.010807
2021-11-30 14:34:26,770 iteration 2886 : loss : 0.030388, loss_ce: 0.009481
2021-11-30 14:34:28,366 iteration 2887 : loss : 0.040257, loss_ce: 0.020061
2021-11-30 14:34:29,913 iteration 2888 : loss : 0.051134, loss_ce: 0.013884
2021-11-30 14:34:31,542 iteration 2889 : loss : 0.030063, loss_ce: 0.010452
2021-11-30 14:34:31,543 Training Data Eval:
2021-11-30 14:34:39,101   Average segmentation loss on training set: 0.0196
2021-11-30 14:34:39,101 Validation Data Eval:
2021-11-30 14:34:41,717   Average segmentation loss on validation set: 0.1044
2021-11-30 14:34:43,289 iteration 2890 : loss : 0.026051, loss_ce: 0.008659
 42%|███████████▍               | 170/400 [1:19:33<1:54:13, 29.80s/it]2021-11-30 14:34:44,896 iteration 2891 : loss : 0.026720, loss_ce: 0.011343
2021-11-30 14:34:46,494 iteration 2892 : loss : 0.032241, loss_ce: 0.008004
2021-11-30 14:34:47,973 iteration 2893 : loss : 0.020365, loss_ce: 0.006630
2021-11-30 14:34:49,566 iteration 2894 : loss : 0.037138, loss_ce: 0.011354
2021-11-30 14:34:51,157 iteration 2895 : loss : 0.032152, loss_ce: 0.014558
2021-11-30 14:34:52,647 iteration 2896 : loss : 0.025923, loss_ce: 0.009444
2021-11-30 14:34:54,167 iteration 2897 : loss : 0.039094, loss_ce: 0.015708
2021-11-30 14:34:55,632 iteration 2898 : loss : 0.026506, loss_ce: 0.011722
2021-11-30 14:34:57,204 iteration 2899 : loss : 0.031995, loss_ce: 0.012013
2021-11-30 14:34:58,712 iteration 2900 : loss : 0.029909, loss_ce: 0.010227
2021-11-30 14:35:00,242 iteration 2901 : loss : 0.026963, loss_ce: 0.008733
2021-11-30 14:35:01,706 iteration 2902 : loss : 0.029499, loss_ce: 0.010402
2021-11-30 14:35:03,192 iteration 2903 : loss : 0.025694, loss_ce: 0.011496
2021-11-30 14:35:04,684 iteration 2904 : loss : 0.044567, loss_ce: 0.021921
2021-11-30 14:35:06,143 iteration 2905 : loss : 0.030401, loss_ce: 0.018544
2021-11-30 14:35:07,692 iteration 2906 : loss : 0.036633, loss_ce: 0.018562
2021-11-30 14:35:09,183 iteration 2907 : loss : 0.031927, loss_ce: 0.011495
 43%|███████████▌               | 171/400 [1:19:59<1:49:16, 28.63s/it]2021-11-30 14:35:10,788 iteration 2908 : loss : 0.040481, loss_ce: 0.020266
2021-11-30 14:35:12,348 iteration 2909 : loss : 0.041567, loss_ce: 0.016651
2021-11-30 14:35:13,864 iteration 2910 : loss : 0.028007, loss_ce: 0.012072
2021-11-30 14:35:15,428 iteration 2911 : loss : 0.029250, loss_ce: 0.011015
2021-11-30 14:35:16,921 iteration 2912 : loss : 0.031211, loss_ce: 0.011158
2021-11-30 14:35:18,504 iteration 2913 : loss : 0.028554, loss_ce: 0.012295
2021-11-30 14:35:20,002 iteration 2914 : loss : 0.033159, loss_ce: 0.012101
2021-11-30 14:35:21,515 iteration 2915 : loss : 0.023505, loss_ce: 0.010672
2021-11-30 14:35:23,061 iteration 2916 : loss : 0.028807, loss_ce: 0.012775
2021-11-30 14:35:24,524 iteration 2917 : loss : 0.023984, loss_ce: 0.010672
2021-11-30 14:35:26,016 iteration 2918 : loss : 0.042848, loss_ce: 0.010625
2021-11-30 14:35:27,537 iteration 2919 : loss : 0.025271, loss_ce: 0.007605
2021-11-30 14:35:29,100 iteration 2920 : loss : 0.027725, loss_ce: 0.011002
2021-11-30 14:35:30,604 iteration 2921 : loss : 0.027901, loss_ce: 0.012394
2021-11-30 14:35:32,061 iteration 2922 : loss : 0.029935, loss_ce: 0.010360
2021-11-30 14:35:33,562 iteration 2923 : loss : 0.032364, loss_ce: 0.010878
2021-11-30 14:35:35,085 iteration 2924 : loss : 0.038892, loss_ce: 0.015183
 43%|███████████▌               | 172/400 [1:20:25<1:45:40, 27.81s/it]2021-11-30 14:35:36,544 iteration 2925 : loss : 0.026600, loss_ce: 0.013186
2021-11-30 14:35:38,136 iteration 2926 : loss : 0.033459, loss_ce: 0.015222
2021-11-30 14:35:39,643 iteration 2927 : loss : 0.031691, loss_ce: 0.013787
2021-11-30 14:35:41,058 iteration 2928 : loss : 0.026834, loss_ce: 0.008056
2021-11-30 14:35:42,563 iteration 2929 : loss : 0.025022, loss_ce: 0.010483
2021-11-30 14:35:44,158 iteration 2930 : loss : 0.031960, loss_ce: 0.014098
2021-11-30 14:35:45,648 iteration 2931 : loss : 0.034461, loss_ce: 0.011965
2021-11-30 14:35:47,111 iteration 2932 : loss : 0.026404, loss_ce: 0.009749
2021-11-30 14:35:48,703 iteration 2933 : loss : 0.030296, loss_ce: 0.010977
2021-11-30 14:35:50,214 iteration 2934 : loss : 0.029550, loss_ce: 0.010226
2021-11-30 14:35:51,730 iteration 2935 : loss : 0.029345, loss_ce: 0.010031
2021-11-30 14:35:53,239 iteration 2936 : loss : 0.024266, loss_ce: 0.006668
2021-11-30 14:35:54,776 iteration 2937 : loss : 0.034926, loss_ce: 0.016696
2021-11-30 14:35:56,329 iteration 2938 : loss : 0.036239, loss_ce: 0.012318
2021-11-30 14:35:57,885 iteration 2939 : loss : 0.031872, loss_ce: 0.011273
2021-11-30 14:35:59,505 iteration 2940 : loss : 0.041899, loss_ce: 0.020901
2021-11-30 14:36:00,978 iteration 2941 : loss : 0.023549, loss_ce: 0.006947
 43%|███████████▋               | 173/400 [1:20:51<1:43:02, 27.24s/it]2021-11-30 14:36:02,495 iteration 2942 : loss : 0.025227, loss_ce: 0.007516
2021-11-30 14:36:04,042 iteration 2943 : loss : 0.040505, loss_ce: 0.011737
2021-11-30 14:36:05,521 iteration 2944 : loss : 0.025814, loss_ce: 0.012802
2021-11-30 14:36:07,042 iteration 2945 : loss : 0.024542, loss_ce: 0.006597
2021-11-30 14:36:08,475 iteration 2946 : loss : 0.024499, loss_ce: 0.009525
2021-11-30 14:36:09,966 iteration 2947 : loss : 0.027781, loss_ce: 0.010095
2021-11-30 14:36:11,454 iteration 2948 : loss : 0.027767, loss_ce: 0.007913
2021-11-30 14:36:13,028 iteration 2949 : loss : 0.031926, loss_ce: 0.012819
2021-11-30 14:36:14,597 iteration 2950 : loss : 0.024215, loss_ce: 0.010854
2021-11-30 14:36:16,145 iteration 2951 : loss : 0.030668, loss_ce: 0.013959
2021-11-30 14:36:17,686 iteration 2952 : loss : 0.022833, loss_ce: 0.008043
2021-11-30 14:36:19,257 iteration 2953 : loss : 0.028184, loss_ce: 0.013630
2021-11-30 14:36:20,876 iteration 2954 : loss : 0.045981, loss_ce: 0.011840
2021-11-30 14:36:22,353 iteration 2955 : loss : 0.023947, loss_ce: 0.011336
2021-11-30 14:36:23,852 iteration 2956 : loss : 0.029228, loss_ce: 0.011755
2021-11-30 14:36:25,329 iteration 2957 : loss : 0.033427, loss_ce: 0.011097
2021-11-30 14:36:26,875 iteration 2958 : loss : 0.033576, loss_ce: 0.015788
 44%|███████████▋               | 174/400 [1:21:17<1:41:04, 26.83s/it]2021-11-30 14:36:28,400 iteration 2959 : loss : 0.024588, loss_ce: 0.008564
2021-11-30 14:36:29,899 iteration 2960 : loss : 0.026699, loss_ce: 0.011801
2021-11-30 14:36:31,423 iteration 2961 : loss : 0.026665, loss_ce: 0.010220
2021-11-30 14:36:33,094 iteration 2962 : loss : 0.023739, loss_ce: 0.007898
2021-11-30 14:36:34,635 iteration 2963 : loss : 0.057586, loss_ce: 0.022056
2021-11-30 14:36:36,077 iteration 2964 : loss : 0.021543, loss_ce: 0.008040
2021-11-30 14:36:37,603 iteration 2965 : loss : 0.025563, loss_ce: 0.012153
2021-11-30 14:36:39,168 iteration 2966 : loss : 0.050205, loss_ce: 0.018237
2021-11-30 14:36:40,663 iteration 2967 : loss : 0.038965, loss_ce: 0.016368
2021-11-30 14:36:42,183 iteration 2968 : loss : 0.031948, loss_ce: 0.014283
2021-11-30 14:36:43,692 iteration 2969 : loss : 0.040052, loss_ce: 0.018486
2021-11-30 14:36:45,237 iteration 2970 : loss : 0.030197, loss_ce: 0.012314
2021-11-30 14:36:46,740 iteration 2971 : loss : 0.022840, loss_ce: 0.008768
2021-11-30 14:36:48,247 iteration 2972 : loss : 0.025582, loss_ce: 0.011271
2021-11-30 14:36:49,718 iteration 2973 : loss : 0.025214, loss_ce: 0.006864
2021-11-30 14:36:51,297 iteration 2974 : loss : 0.033326, loss_ce: 0.012331
2021-11-30 14:36:51,298 Training Data Eval:
2021-11-30 14:36:58,882   Average segmentation loss on training set: 0.0190
2021-11-30 14:36:58,883 Validation Data Eval:
2021-11-30 14:37:01,511   Average segmentation loss on validation set: 0.0757
2021-11-30 14:37:03,010 iteration 2975 : loss : 0.021646, loss_ce: 0.008121
 44%|███████████▊               | 175/400 [1:21:53<1:51:05, 29.62s/it]2021-11-30 14:37:04,494 iteration 2976 : loss : 0.021887, loss_ce: 0.008715
2021-11-30 14:37:06,051 iteration 2977 : loss : 0.026795, loss_ce: 0.012338
2021-11-30 14:37:07,593 iteration 2978 : loss : 0.038513, loss_ce: 0.012167
2021-11-30 14:37:09,165 iteration 2979 : loss : 0.027349, loss_ce: 0.008528
2021-11-30 14:37:10,736 iteration 2980 : loss : 0.033361, loss_ce: 0.010097
2021-11-30 14:37:12,362 iteration 2981 : loss : 0.033896, loss_ce: 0.014750
2021-11-30 14:37:13,873 iteration 2982 : loss : 0.019944, loss_ce: 0.007525
2021-11-30 14:37:15,401 iteration 2983 : loss : 0.025633, loss_ce: 0.009330
2021-11-30 14:37:16,933 iteration 2984 : loss : 0.033058, loss_ce: 0.010986
2021-11-30 14:37:18,498 iteration 2985 : loss : 0.035669, loss_ce: 0.013725
2021-11-30 14:37:19,972 iteration 2986 : loss : 0.029385, loss_ce: 0.013834
2021-11-30 14:37:21,506 iteration 2987 : loss : 0.029111, loss_ce: 0.009288
2021-11-30 14:37:23,067 iteration 2988 : loss : 0.027890, loss_ce: 0.010915
2021-11-30 14:37:24,638 iteration 2989 : loss : 0.043360, loss_ce: 0.017309
2021-11-30 14:37:26,100 iteration 2990 : loss : 0.020631, loss_ce: 0.008316
2021-11-30 14:37:27,607 iteration 2991 : loss : 0.022299, loss_ce: 0.008758
2021-11-30 14:37:29,191 iteration 2992 : loss : 0.027494, loss_ce: 0.011895
 44%|███████████▉               | 176/400 [1:22:19<1:46:44, 28.59s/it]2021-11-30 14:37:30,701 iteration 2993 : loss : 0.025969, loss_ce: 0.013361
2021-11-30 14:37:32,227 iteration 2994 : loss : 0.045650, loss_ce: 0.011038
2021-11-30 14:37:33,722 iteration 2995 : loss : 0.022564, loss_ce: 0.008032
2021-11-30 14:37:35,247 iteration 2996 : loss : 0.020485, loss_ce: 0.009192
2021-11-30 14:37:36,774 iteration 2997 : loss : 0.024868, loss_ce: 0.009107
2021-11-30 14:37:38,314 iteration 2998 : loss : 0.025813, loss_ce: 0.010115
2021-11-30 14:37:39,888 iteration 2999 : loss : 0.054801, loss_ce: 0.010104
2021-11-30 14:37:41,467 iteration 3000 : loss : 0.069348, loss_ce: 0.030226
2021-11-30 14:37:43,054 iteration 3001 : loss : 0.049704, loss_ce: 0.011057
2021-11-30 14:37:44,523 iteration 3002 : loss : 0.024284, loss_ce: 0.008628
2021-11-30 14:37:46,009 iteration 3003 : loss : 0.026956, loss_ce: 0.008925
2021-11-30 14:37:47,521 iteration 3004 : loss : 0.022770, loss_ce: 0.009100
2021-11-30 14:37:49,048 iteration 3005 : loss : 0.031661, loss_ce: 0.015198
2021-11-30 14:37:50,601 iteration 3006 : loss : 0.027918, loss_ce: 0.010841
2021-11-30 14:37:52,149 iteration 3007 : loss : 0.036238, loss_ce: 0.015653
2021-11-30 14:37:53,702 iteration 3008 : loss : 0.028949, loss_ce: 0.010120
2021-11-30 14:37:55,174 iteration 3009 : loss : 0.035031, loss_ce: 0.013464
 44%|███████████▉               | 177/400 [1:22:45<1:43:21, 27.81s/it]2021-11-30 14:37:56,844 iteration 3010 : loss : 0.037915, loss_ce: 0.012491
2021-11-30 14:37:58,390 iteration 3011 : loss : 0.028170, loss_ce: 0.012657
2021-11-30 14:37:59,862 iteration 3012 : loss : 0.023178, loss_ce: 0.009781
2021-11-30 14:38:01,336 iteration 3013 : loss : 0.035881, loss_ce: 0.009880
2021-11-30 14:38:02,863 iteration 3014 : loss : 0.031890, loss_ce: 0.011321
2021-11-30 14:38:04,382 iteration 3015 : loss : 0.036103, loss_ce: 0.008644
2021-11-30 14:38:05,893 iteration 3016 : loss : 0.039760, loss_ce: 0.013340
2021-11-30 14:38:07,392 iteration 3017 : loss : 0.030720, loss_ce: 0.014783
2021-11-30 14:38:08,889 iteration 3018 : loss : 0.023954, loss_ce: 0.009409
2021-11-30 14:38:10,348 iteration 3019 : loss : 0.023493, loss_ce: 0.008121
2021-11-30 14:38:11,883 iteration 3020 : loss : 0.042183, loss_ce: 0.014099
2021-11-30 14:38:13,407 iteration 3021 : loss : 0.017921, loss_ce: 0.006664
2021-11-30 14:38:14,914 iteration 3022 : loss : 0.019032, loss_ce: 0.006153
2021-11-30 14:38:16,453 iteration 3023 : loss : 0.037169, loss_ce: 0.012118
2021-11-30 14:38:18,052 iteration 3024 : loss : 0.033981, loss_ce: 0.012406
2021-11-30 14:38:19,627 iteration 3025 : loss : 0.033621, loss_ce: 0.013651
2021-11-30 14:38:21,099 iteration 3026 : loss : 0.029446, loss_ce: 0.013393
 44%|████████████               | 178/400 [1:23:11<1:40:47, 27.24s/it]2021-11-30 14:38:22,712 iteration 3027 : loss : 0.040231, loss_ce: 0.014962
2021-11-30 14:38:24,182 iteration 3028 : loss : 0.026965, loss_ce: 0.010662
2021-11-30 14:38:25,702 iteration 3029 : loss : 0.030730, loss_ce: 0.012041
2021-11-30 14:38:27,192 iteration 3030 : loss : 0.023854, loss_ce: 0.010295
2021-11-30 14:38:28,708 iteration 3031 : loss : 0.039657, loss_ce: 0.015727
2021-11-30 14:38:30,186 iteration 3032 : loss : 0.027905, loss_ce: 0.009844
2021-11-30 14:38:31,732 iteration 3033 : loss : 0.038814, loss_ce: 0.012648
2021-11-30 14:38:33,317 iteration 3034 : loss : 0.033178, loss_ce: 0.011536
2021-11-30 14:38:34,866 iteration 3035 : loss : 0.031812, loss_ce: 0.015397
2021-11-30 14:38:36,366 iteration 3036 : loss : 0.034530, loss_ce: 0.017263
2021-11-30 14:38:37,892 iteration 3037 : loss : 0.036969, loss_ce: 0.014930
2021-11-30 14:38:39,459 iteration 3038 : loss : 0.023104, loss_ce: 0.008062
2021-11-30 14:38:40,928 iteration 3039 : loss : 0.024779, loss_ce: 0.007503
2021-11-30 14:38:42,471 iteration 3040 : loss : 0.035187, loss_ce: 0.009147
2021-11-30 14:38:44,036 iteration 3041 : loss : 0.029457, loss_ce: 0.012212
2021-11-30 14:38:45,558 iteration 3042 : loss : 0.033574, loss_ce: 0.014498
2021-11-30 14:38:47,231 iteration 3043 : loss : 0.041722, loss_ce: 0.014321
 45%|████████████               | 179/400 [1:23:37<1:39:07, 26.91s/it]2021-11-30 14:38:48,784 iteration 3044 : loss : 0.031697, loss_ce: 0.012883
2021-11-30 14:38:50,248 iteration 3045 : loss : 0.023149, loss_ce: 0.008481
2021-11-30 14:38:51,755 iteration 3046 : loss : 0.022195, loss_ce: 0.007335
2021-11-30 14:38:53,372 iteration 3047 : loss : 0.037856, loss_ce: 0.019549
2021-11-30 14:38:54,836 iteration 3048 : loss : 0.035689, loss_ce: 0.011554
2021-11-30 14:38:56,351 iteration 3049 : loss : 0.028979, loss_ce: 0.011590
2021-11-30 14:38:57,900 iteration 3050 : loss : 0.026870, loss_ce: 0.012900
2021-11-30 14:38:59,425 iteration 3051 : loss : 0.038203, loss_ce: 0.010464
2021-11-30 14:39:00,931 iteration 3052 : loss : 0.027185, loss_ce: 0.008912
2021-11-30 14:39:02,522 iteration 3053 : loss : 0.024160, loss_ce: 0.010380
2021-11-30 14:39:03,996 iteration 3054 : loss : 0.031937, loss_ce: 0.009178
2021-11-30 14:39:05,534 iteration 3055 : loss : 0.035498, loss_ce: 0.012904
2021-11-30 14:39:07,041 iteration 3056 : loss : 0.027721, loss_ce: 0.010229
2021-11-30 14:39:08,510 iteration 3057 : loss : 0.023968, loss_ce: 0.008854
2021-11-30 14:39:10,056 iteration 3058 : loss : 0.022414, loss_ce: 0.008477
2021-11-30 14:39:11,607 iteration 3059 : loss : 0.026001, loss_ce: 0.008987
2021-11-30 14:39:11,607 Training Data Eval:
2021-11-30 14:39:19,187   Average segmentation loss on training set: 0.0185
2021-11-30 14:39:19,187 Validation Data Eval:
2021-11-30 14:39:21,815   Average segmentation loss on validation set: 0.0661
2021-11-30 14:39:23,838 Found new lowest validation loss at iteration 3059! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/UNET_RUNMC/ADAM/ADAM_best_val_loss.pth
2021-11-30 14:39:25,234 iteration 3060 : loss : 0.026467, loss_ce: 0.012682
 45%|████████████▏              | 180/400 [1:24:15<1:50:52, 30.24s/it]2021-11-30 14:39:26,607 iteration 3061 : loss : 0.022409, loss_ce: 0.008221
2021-11-30 14:39:28,024 iteration 3062 : loss : 0.030083, loss_ce: 0.011023
2021-11-30 14:39:29,529 iteration 3063 : loss : 0.024121, loss_ce: 0.009043
2021-11-30 14:39:31,077 iteration 3064 : loss : 0.046125, loss_ce: 0.018337
2021-11-30 14:39:32,497 iteration 3065 : loss : 0.019647, loss_ce: 0.006447
2021-11-30 14:39:33,995 iteration 3066 : loss : 0.024749, loss_ce: 0.011465
2021-11-30 14:39:35,533 iteration 3067 : loss : 0.033674, loss_ce: 0.014192
2021-11-30 14:39:37,073 iteration 3068 : loss : 0.031253, loss_ce: 0.010046
2021-11-30 14:39:38,601 iteration 3069 : loss : 0.029511, loss_ce: 0.008100
2021-11-30 14:39:40,121 iteration 3070 : loss : 0.030614, loss_ce: 0.012033
2021-11-30 14:39:41,583 iteration 3071 : loss : 0.024205, loss_ce: 0.009803
2021-11-30 14:39:43,050 iteration 3072 : loss : 0.026552, loss_ce: 0.009783
2021-11-30 14:39:44,554 iteration 3073 : loss : 0.021913, loss_ce: 0.007947
2021-11-30 14:39:46,144 iteration 3074 : loss : 0.028251, loss_ce: 0.011732
2021-11-30 14:39:47,687 iteration 3075 : loss : 0.029673, loss_ce: 0.009556
2021-11-30 14:39:49,268 iteration 3076 : loss : 0.029175, loss_ce: 0.011615
2021-11-30 14:39:50,731 iteration 3077 : loss : 0.032145, loss_ce: 0.011163
 45%|████████████▏              | 181/400 [1:24:41<1:45:10, 28.81s/it]2021-11-30 14:39:52,236 iteration 3078 : loss : 0.025956, loss_ce: 0.008988
2021-11-30 14:39:53,862 iteration 3079 : loss : 0.021273, loss_ce: 0.006874
2021-11-30 14:39:55,328 iteration 3080 : loss : 0.023237, loss_ce: 0.006858
2021-11-30 14:39:56,884 iteration 3081 : loss : 0.022118, loss_ce: 0.007945
2021-11-30 14:39:58,398 iteration 3082 : loss : 0.036517, loss_ce: 0.008659
2021-11-30 14:39:59,951 iteration 3083 : loss : 0.027624, loss_ce: 0.010716
2021-11-30 14:40:01,368 iteration 3084 : loss : 0.022873, loss_ce: 0.009557
2021-11-30 14:40:02,936 iteration 3085 : loss : 0.027475, loss_ce: 0.010518
2021-11-30 14:40:04,542 iteration 3086 : loss : 0.032170, loss_ce: 0.016474
2021-11-30 14:40:06,039 iteration 3087 : loss : 0.026621, loss_ce: 0.010155
2021-11-30 14:40:07,571 iteration 3088 : loss : 0.025798, loss_ce: 0.007562
2021-11-30 14:40:09,191 iteration 3089 : loss : 0.037021, loss_ce: 0.011162
2021-11-30 14:40:10,650 iteration 3090 : loss : 0.022132, loss_ce: 0.009817
2021-11-30 14:40:12,164 iteration 3091 : loss : 0.027804, loss_ce: 0.013856
2021-11-30 14:40:13,820 iteration 3092 : loss : 0.037080, loss_ce: 0.013788
2021-11-30 14:40:15,294 iteration 3093 : loss : 0.023871, loss_ce: 0.010054
2021-11-30 14:40:16,823 iteration 3094 : loss : 0.020663, loss_ce: 0.008308
 46%|████████████▎              | 182/400 [1:25:07<1:41:44, 28.00s/it]2021-11-30 14:40:18,375 iteration 3095 : loss : 0.030631, loss_ce: 0.013588
2021-11-30 14:40:19,915 iteration 3096 : loss : 0.027711, loss_ce: 0.013439
2021-11-30 14:40:21,417 iteration 3097 : loss : 0.019059, loss_ce: 0.006541
2021-11-30 14:40:22,880 iteration 3098 : loss : 0.024892, loss_ce: 0.009370
2021-11-30 14:40:24,393 iteration 3099 : loss : 0.019490, loss_ce: 0.006177
2021-11-30 14:40:25,865 iteration 3100 : loss : 0.029068, loss_ce: 0.009569
2021-11-30 14:40:27,437 iteration 3101 : loss : 0.022124, loss_ce: 0.007868
2021-11-30 14:40:28,968 iteration 3102 : loss : 0.028091, loss_ce: 0.010498
2021-11-30 14:40:30,492 iteration 3103 : loss : 0.029506, loss_ce: 0.010740
2021-11-30 14:40:31,965 iteration 3104 : loss : 0.023650, loss_ce: 0.009973
2021-11-30 14:40:33,430 iteration 3105 : loss : 0.021086, loss_ce: 0.009368
2021-11-30 14:40:34,933 iteration 3106 : loss : 0.025451, loss_ce: 0.011950
2021-11-30 14:40:36,422 iteration 3107 : loss : 0.020258, loss_ce: 0.006185
2021-11-30 14:40:37,965 iteration 3108 : loss : 0.031668, loss_ce: 0.010258
2021-11-30 14:40:39,509 iteration 3109 : loss : 0.026460, loss_ce: 0.008674
2021-11-30 14:40:41,072 iteration 3110 : loss : 0.039514, loss_ce: 0.016125
2021-11-30 14:40:42,609 iteration 3111 : loss : 0.019680, loss_ce: 0.007885
 46%|████████████▎              | 183/400 [1:25:33<1:38:51, 27.33s/it]2021-11-30 14:40:44,181 iteration 3112 : loss : 0.023656, loss_ce: 0.008320
2021-11-30 14:40:45,667 iteration 3113 : loss : 0.027179, loss_ce: 0.011519
2021-11-30 14:40:47,233 iteration 3114 : loss : 0.030721, loss_ce: 0.010662
2021-11-30 14:40:48,759 iteration 3115 : loss : 0.024340, loss_ce: 0.010080
2021-11-30 14:40:50,274 iteration 3116 : loss : 0.027342, loss_ce: 0.011397
2021-11-30 14:40:51,844 iteration 3117 : loss : 0.022684, loss_ce: 0.008582
2021-11-30 14:40:53,341 iteration 3118 : loss : 0.028200, loss_ce: 0.011520
2021-11-30 14:40:54,947 iteration 3119 : loss : 0.032882, loss_ce: 0.010990
2021-11-30 14:40:56,409 iteration 3120 : loss : 0.021429, loss_ce: 0.008636
2021-11-30 14:40:57,987 iteration 3121 : loss : 0.023149, loss_ce: 0.010205
2021-11-30 14:40:59,499 iteration 3122 : loss : 0.032530, loss_ce: 0.008773
2021-11-30 14:41:01,068 iteration 3123 : loss : 0.028068, loss_ce: 0.011632
2021-11-30 14:41:02,517 iteration 3124 : loss : 0.027969, loss_ce: 0.009162
2021-11-30 14:41:04,027 iteration 3125 : loss : 0.029560, loss_ce: 0.008270
2021-11-30 14:41:05,608 iteration 3126 : loss : 0.024131, loss_ce: 0.010930
2021-11-30 14:41:07,179 iteration 3127 : loss : 0.022820, loss_ce: 0.007213
2021-11-30 14:41:08,745 iteration 3128 : loss : 0.027587, loss_ce: 0.009230
 46%|████████████▍              | 184/400 [1:25:59<1:37:06, 26.98s/it]2021-11-30 14:41:10,266 iteration 3129 : loss : 0.026785, loss_ce: 0.009726
2021-11-30 14:41:11,868 iteration 3130 : loss : 0.028931, loss_ce: 0.012143
2021-11-30 14:41:13,372 iteration 3131 : loss : 0.031445, loss_ce: 0.011146
2021-11-30 14:41:14,883 iteration 3132 : loss : 0.021272, loss_ce: 0.006073
2021-11-30 14:41:16,389 iteration 3133 : loss : 0.032502, loss_ce: 0.013471
2021-11-30 14:41:17,879 iteration 3134 : loss : 0.021399, loss_ce: 0.009150
2021-11-30 14:41:19,391 iteration 3135 : loss : 0.026622, loss_ce: 0.011083
2021-11-30 14:41:20,888 iteration 3136 : loss : 0.025083, loss_ce: 0.011618
2021-11-30 14:41:22,511 iteration 3137 : loss : 0.027801, loss_ce: 0.012197
2021-11-30 14:41:24,094 iteration 3138 : loss : 0.047424, loss_ce: 0.022676
2021-11-30 14:41:25,557 iteration 3139 : loss : 0.023367, loss_ce: 0.007799
2021-11-30 14:41:27,024 iteration 3140 : loss : 0.026458, loss_ce: 0.010544
2021-11-30 14:41:28,567 iteration 3141 : loss : 0.033704, loss_ce: 0.014687
2021-11-30 14:41:30,073 iteration 3142 : loss : 0.033449, loss_ce: 0.011175
2021-11-30 14:41:31,619 iteration 3143 : loss : 0.034745, loss_ce: 0.013414
2021-11-30 14:41:33,115 iteration 3144 : loss : 0.024934, loss_ce: 0.008749
2021-11-30 14:41:33,115 Training Data Eval:
2021-11-30 14:41:40,710   Average segmentation loss on training set: 0.0173
2021-11-30 14:41:40,711 Validation Data Eval:
2021-11-30 14:41:43,333   Average segmentation loss on validation set: 0.0649
2021-11-30 14:41:45,337 Found new lowest validation loss at iteration 3144! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/UNET_RUNMC/ADAM/ADAM_best_val_loss.pth
2021-11-30 14:41:46,733 iteration 3145 : loss : 0.019234, loss_ce: 0.008391
 46%|████████████▍              | 185/400 [1:26:37<1:48:29, 30.28s/it]2021-11-30 14:41:48,319 iteration 3146 : loss : 0.035928, loss_ce: 0.011919
2021-11-30 14:41:49,804 iteration 3147 : loss : 0.027976, loss_ce: 0.012030
2021-11-30 14:41:51,229 iteration 3148 : loss : 0.020770, loss_ce: 0.007332
2021-11-30 14:41:52,775 iteration 3149 : loss : 0.022713, loss_ce: 0.007014
2021-11-30 14:41:54,328 iteration 3150 : loss : 0.033587, loss_ce: 0.009837
2021-11-30 14:41:55,891 iteration 3151 : loss : 0.028756, loss_ce: 0.009976
2021-11-30 14:41:57,440 iteration 3152 : loss : 0.028345, loss_ce: 0.009753
2021-11-30 14:41:58,969 iteration 3153 : loss : 0.032372, loss_ce: 0.014147
2021-11-30 14:42:00,563 iteration 3154 : loss : 0.030999, loss_ce: 0.011671
2021-11-30 14:42:02,129 iteration 3155 : loss : 0.023633, loss_ce: 0.007965
2021-11-30 14:42:03,601 iteration 3156 : loss : 0.022944, loss_ce: 0.007810
2021-11-30 14:42:05,130 iteration 3157 : loss : 0.025086, loss_ce: 0.011363
2021-11-30 14:42:06,605 iteration 3158 : loss : 0.039457, loss_ce: 0.010117
2021-11-30 14:42:08,159 iteration 3159 : loss : 0.037487, loss_ce: 0.019520
2021-11-30 14:42:09,697 iteration 3160 : loss : 0.022938, loss_ce: 0.008992
2021-11-30 14:42:11,287 iteration 3161 : loss : 0.021341, loss_ce: 0.007331
2021-11-30 14:42:12,808 iteration 3162 : loss : 0.025439, loss_ce: 0.008510
 46%|████████████▌              | 186/400 [1:27:03<1:43:30, 29.02s/it]2021-11-30 14:42:14,331 iteration 3163 : loss : 0.030571, loss_ce: 0.009636
2021-11-30 14:42:15,944 iteration 3164 : loss : 0.044133, loss_ce: 0.017418
2021-11-30 14:42:17,503 iteration 3165 : loss : 0.036671, loss_ce: 0.017021
2021-11-30 14:42:18,978 iteration 3166 : loss : 0.028544, loss_ce: 0.011427
2021-11-30 14:42:20,542 iteration 3167 : loss : 0.023511, loss_ce: 0.007703
2021-11-30 14:42:22,052 iteration 3168 : loss : 0.038002, loss_ce: 0.015072
2021-11-30 14:42:23,612 iteration 3169 : loss : 0.027093, loss_ce: 0.012117
2021-11-30 14:42:25,138 iteration 3170 : loss : 0.021492, loss_ce: 0.009902
2021-11-30 14:42:26,564 iteration 3171 : loss : 0.023786, loss_ce: 0.006493
2021-11-30 14:42:28,048 iteration 3172 : loss : 0.019728, loss_ce: 0.007453
2021-11-30 14:42:29,574 iteration 3173 : loss : 0.040489, loss_ce: 0.011085
2021-11-30 14:42:31,060 iteration 3174 : loss : 0.022054, loss_ce: 0.009846
2021-11-30 14:42:32,522 iteration 3175 : loss : 0.045055, loss_ce: 0.015760
2021-11-30 14:42:34,127 iteration 3176 : loss : 0.051334, loss_ce: 0.015734
2021-11-30 14:42:35,650 iteration 3177 : loss : 0.030135, loss_ce: 0.010926
2021-11-30 14:42:37,255 iteration 3178 : loss : 0.038745, loss_ce: 0.012283
2021-11-30 14:42:38,798 iteration 3179 : loss : 0.033319, loss_ce: 0.017083
 47%|████████████▌              | 187/400 [1:27:29<1:39:47, 28.11s/it]2021-11-30 14:42:40,377 iteration 3180 : loss : 0.078994, loss_ce: 0.038198
2021-11-30 14:42:41,887 iteration 3181 : loss : 0.023689, loss_ce: 0.011372
2021-11-30 14:42:43,356 iteration 3182 : loss : 0.027013, loss_ce: 0.013476
2021-11-30 14:42:44,940 iteration 3183 : loss : 0.038773, loss_ce: 0.013740
2021-11-30 14:42:46,452 iteration 3184 : loss : 0.036101, loss_ce: 0.012890
2021-11-30 14:42:47,985 iteration 3185 : loss : 0.034424, loss_ce: 0.011094
2021-11-30 14:42:49,543 iteration 3186 : loss : 0.024080, loss_ce: 0.009720
2021-11-30 14:42:51,120 iteration 3187 : loss : 0.030341, loss_ce: 0.011700
2021-11-30 14:42:52,683 iteration 3188 : loss : 0.037150, loss_ce: 0.016301
2021-11-30 14:42:54,185 iteration 3189 : loss : 0.027909, loss_ce: 0.009699
2021-11-30 14:42:55,801 iteration 3190 : loss : 0.041402, loss_ce: 0.015932
2021-11-30 14:42:57,384 iteration 3191 : loss : 0.026563, loss_ce: 0.010392
2021-11-30 14:42:58,839 iteration 3192 : loss : 0.039015, loss_ce: 0.008638
2021-11-30 14:43:00,357 iteration 3193 : loss : 0.027682, loss_ce: 0.010375
2021-11-30 14:43:01,993 iteration 3194 : loss : 0.041099, loss_ce: 0.014862
2021-11-30 14:43:03,534 iteration 3195 : loss : 0.032893, loss_ce: 0.014175
2021-11-30 14:43:05,057 iteration 3196 : loss : 0.034117, loss_ce: 0.017589
 47%|████████████▋              | 188/400 [1:27:55<1:37:21, 27.55s/it]2021-11-30 14:43:06,602 iteration 3197 : loss : 0.020650, loss_ce: 0.008520
2021-11-30 14:43:08,153 iteration 3198 : loss : 0.042978, loss_ce: 0.020652
2021-11-30 14:43:09,711 iteration 3199 : loss : 0.037635, loss_ce: 0.010404
2021-11-30 14:43:11,289 iteration 3200 : loss : 0.035792, loss_ce: 0.010332
2021-11-30 14:43:12,895 iteration 3201 : loss : 0.032863, loss_ce: 0.011621
2021-11-30 14:43:14,475 iteration 3202 : loss : 0.035636, loss_ce: 0.011517
2021-11-30 14:43:15,924 iteration 3203 : loss : 0.022947, loss_ce: 0.009882
2021-11-30 14:43:17,373 iteration 3204 : loss : 0.020709, loss_ce: 0.008376
2021-11-30 14:43:18,826 iteration 3205 : loss : 0.027805, loss_ce: 0.008443
2021-11-30 14:43:20,244 iteration 3206 : loss : 0.019499, loss_ce: 0.005888
2021-11-30 14:43:21,810 iteration 3207 : loss : 0.030162, loss_ce: 0.011974
2021-11-30 14:43:23,326 iteration 3208 : loss : 0.031609, loss_ce: 0.012193
2021-11-30 14:43:24,828 iteration 3209 : loss : 0.041834, loss_ce: 0.012997
2021-11-30 14:43:26,371 iteration 3210 : loss : 0.023740, loss_ce: 0.010739
2021-11-30 14:43:27,853 iteration 3211 : loss : 0.024213, loss_ce: 0.007712
2021-11-30 14:43:29,441 iteration 3212 : loss : 0.033278, loss_ce: 0.014860
2021-11-30 14:43:31,034 iteration 3213 : loss : 0.032576, loss_ce: 0.009730
 47%|████████████▊              | 189/400 [1:28:21<1:35:13, 27.08s/it]2021-11-30 14:43:32,527 iteration 3214 : loss : 0.020675, loss_ce: 0.008744
2021-11-30 14:43:34,048 iteration 3215 : loss : 0.021949, loss_ce: 0.009294
2021-11-30 14:43:35,571 iteration 3216 : loss : 0.035972, loss_ce: 0.013083
2021-11-30 14:43:37,122 iteration 3217 : loss : 0.026936, loss_ce: 0.011621
2021-11-30 14:43:38,652 iteration 3218 : loss : 0.040551, loss_ce: 0.011910
2021-11-30 14:43:40,166 iteration 3219 : loss : 0.028582, loss_ce: 0.010638
2021-11-30 14:43:41,653 iteration 3220 : loss : 0.024750, loss_ce: 0.011126
2021-11-30 14:43:43,266 iteration 3221 : loss : 0.034625, loss_ce: 0.013888
2021-11-30 14:43:44,749 iteration 3222 : loss : 0.020434, loss_ce: 0.005273
2021-11-30 14:43:46,306 iteration 3223 : loss : 0.032129, loss_ce: 0.009613
2021-11-30 14:43:47,907 iteration 3224 : loss : 0.032983, loss_ce: 0.009747
2021-11-30 14:43:49,428 iteration 3225 : loss : 0.040918, loss_ce: 0.022072
2021-11-30 14:43:50,950 iteration 3226 : loss : 0.034242, loss_ce: 0.012295
2021-11-30 14:43:52,501 iteration 3227 : loss : 0.033510, loss_ce: 0.013408
2021-11-30 14:43:53,997 iteration 3228 : loss : 0.024614, loss_ce: 0.007756
2021-11-30 14:43:55,460 iteration 3229 : loss : 0.025352, loss_ce: 0.007519
2021-11-30 14:43:55,461 Training Data Eval:
2021-11-30 14:44:03,049   Average segmentation loss on training set: 0.0180
2021-11-30 14:44:03,050 Validation Data Eval:
2021-11-30 14:44:05,672   Average segmentation loss on validation set: 0.0930
2021-11-30 14:44:07,136 iteration 3230 : loss : 0.025601, loss_ce: 0.009357
 48%|████████████▊              | 190/400 [1:28:57<1:44:15, 29.79s/it]2021-11-30 14:44:08,672 iteration 3231 : loss : 0.029152, loss_ce: 0.007277
2021-11-30 14:44:10,183 iteration 3232 : loss : 0.022035, loss_ce: 0.006785
2021-11-30 14:44:11,705 iteration 3233 : loss : 0.032752, loss_ce: 0.015990
2021-11-30 14:44:13,248 iteration 3234 : loss : 0.021380, loss_ce: 0.007848
2021-11-30 14:44:14,785 iteration 3235 : loss : 0.033319, loss_ce: 0.010879
2021-11-30 14:44:16,260 iteration 3236 : loss : 0.019141, loss_ce: 0.008359
2021-11-30 14:44:17,873 iteration 3237 : loss : 0.026993, loss_ce: 0.012044
2021-11-30 14:44:19,401 iteration 3238 : loss : 0.027309, loss_ce: 0.015690
2021-11-30 14:44:20,942 iteration 3239 : loss : 0.037568, loss_ce: 0.017619
2021-11-30 14:44:22,418 iteration 3240 : loss : 0.037663, loss_ce: 0.010496
2021-11-30 14:44:23,884 iteration 3241 : loss : 0.038488, loss_ce: 0.008660
2021-11-30 14:44:25,407 iteration 3242 : loss : 0.028098, loss_ce: 0.011078
2021-11-30 14:44:26,870 iteration 3243 : loss : 0.030180, loss_ce: 0.010453
2021-11-30 14:44:28,407 iteration 3244 : loss : 0.031975, loss_ce: 0.012122
2021-11-30 14:44:29,894 iteration 3245 : loss : 0.020074, loss_ce: 0.008739
2021-11-30 14:44:31,474 iteration 3246 : loss : 0.034008, loss_ce: 0.014948
2021-11-30 14:44:32,957 iteration 3247 : loss : 0.026225, loss_ce: 0.010409
 48%|████████████▉              | 191/400 [1:29:23<1:39:36, 28.60s/it]2021-11-30 14:44:34,472 iteration 3248 : loss : 0.023940, loss_ce: 0.008015
2021-11-30 14:44:35,964 iteration 3249 : loss : 0.020594, loss_ce: 0.006969
2021-11-30 14:44:37,474 iteration 3250 : loss : 0.027580, loss_ce: 0.009506
2021-11-30 14:44:39,001 iteration 3251 : loss : 0.022496, loss_ce: 0.009323
2021-11-30 14:44:40,532 iteration 3252 : loss : 0.029361, loss_ce: 0.011357
2021-11-30 14:44:42,052 iteration 3253 : loss : 0.020744, loss_ce: 0.008504
2021-11-30 14:44:43,556 iteration 3254 : loss : 0.027308, loss_ce: 0.010909
2021-11-30 14:44:45,003 iteration 3255 : loss : 0.025472, loss_ce: 0.010056
2021-11-30 14:44:46,509 iteration 3256 : loss : 0.020467, loss_ce: 0.007544
2021-11-30 14:44:48,010 iteration 3257 : loss : 0.022357, loss_ce: 0.009643
2021-11-30 14:44:49,542 iteration 3258 : loss : 0.030064, loss_ce: 0.011858
2021-11-30 14:44:51,003 iteration 3259 : loss : 0.025541, loss_ce: 0.009690
2021-11-30 14:44:52,555 iteration 3260 : loss : 0.021264, loss_ce: 0.008185
2021-11-30 14:44:54,049 iteration 3261 : loss : 0.042407, loss_ce: 0.011211
2021-11-30 14:44:55,622 iteration 3262 : loss : 0.035241, loss_ce: 0.012971
2021-11-30 14:44:57,246 iteration 3263 : loss : 0.032126, loss_ce: 0.008492
2021-11-30 14:44:58,779 iteration 3264 : loss : 0.032783, loss_ce: 0.013160
 48%|████████████▉              | 192/400 [1:29:49<1:36:15, 27.77s/it]2021-11-30 14:45:00,297 iteration 3265 : loss : 0.021216, loss_ce: 0.008489
2021-11-30 14:45:01,878 iteration 3266 : loss : 0.029629, loss_ce: 0.012516
2021-11-30 14:45:03,427 iteration 3267 : loss : 0.023974, loss_ce: 0.009378
2021-11-30 14:45:04,910 iteration 3268 : loss : 0.023099, loss_ce: 0.008073
2021-11-30 14:45:06,483 iteration 3269 : loss : 0.029633, loss_ce: 0.012544
2021-11-30 14:45:08,087 iteration 3270 : loss : 0.036478, loss_ce: 0.011784
2021-11-30 14:45:09,649 iteration 3271 : loss : 0.027634, loss_ce: 0.009099
2021-11-30 14:45:11,222 iteration 3272 : loss : 0.023567, loss_ce: 0.009609
2021-11-30 14:45:12,688 iteration 3273 : loss : 0.021219, loss_ce: 0.006525
2021-11-30 14:45:14,214 iteration 3274 : loss : 0.020893, loss_ce: 0.010072
2021-11-30 14:45:15,790 iteration 3275 : loss : 0.031049, loss_ce: 0.008628
2021-11-30 14:45:17,284 iteration 3276 : loss : 0.022389, loss_ce: 0.009046
2021-11-30 14:45:18,837 iteration 3277 : loss : 0.027061, loss_ce: 0.012620
2021-11-30 14:45:20,363 iteration 3278 : loss : 0.025241, loss_ce: 0.009123
2021-11-30 14:45:21,866 iteration 3279 : loss : 0.022602, loss_ce: 0.008358
2021-11-30 14:45:23,374 iteration 3280 : loss : 0.024177, loss_ce: 0.008346
2021-11-30 14:45:24,849 iteration 3281 : loss : 0.020573, loss_ce: 0.006193
 48%|█████████████              | 193/400 [1:30:15<1:34:01, 27.26s/it]2021-11-30 14:45:26,453 iteration 3282 : loss : 0.024072, loss_ce: 0.009958
2021-11-30 14:45:27,980 iteration 3283 : loss : 0.021240, loss_ce: 0.007310
2021-11-30 14:45:29,516 iteration 3284 : loss : 0.033978, loss_ce: 0.014056
2021-11-30 14:45:31,060 iteration 3285 : loss : 0.026781, loss_ce: 0.010386
2021-11-30 14:45:32,572 iteration 3286 : loss : 0.020033, loss_ce: 0.007170
2021-11-30 14:45:34,113 iteration 3287 : loss : 0.024519, loss_ce: 0.009554
2021-11-30 14:45:35,581 iteration 3288 : loss : 0.028050, loss_ce: 0.015185
2021-11-30 14:45:37,067 iteration 3289 : loss : 0.027795, loss_ce: 0.008084
2021-11-30 14:45:38,656 iteration 3290 : loss : 0.043884, loss_ce: 0.013797
2021-11-30 14:45:40,236 iteration 3291 : loss : 0.032864, loss_ce: 0.012118
2021-11-30 14:45:41,755 iteration 3292 : loss : 0.028341, loss_ce: 0.007899
2021-11-30 14:45:43,268 iteration 3293 : loss : 0.021830, loss_ce: 0.010065
2021-11-30 14:45:44,776 iteration 3294 : loss : 0.029729, loss_ce: 0.015191
2021-11-30 14:45:46,376 iteration 3295 : loss : 0.037569, loss_ce: 0.014294
2021-11-30 14:45:47,917 iteration 3296 : loss : 0.025889, loss_ce: 0.006596
2021-11-30 14:45:49,371 iteration 3297 : loss : 0.018234, loss_ce: 0.006467
2021-11-30 14:45:50,928 iteration 3298 : loss : 0.030483, loss_ce: 0.011977
 48%|█████████████              | 194/400 [1:30:41<1:32:21, 26.90s/it]2021-11-30 14:45:52,422 iteration 3299 : loss : 0.021981, loss_ce: 0.008593
2021-11-30 14:45:53,912 iteration 3300 : loss : 0.035779, loss_ce: 0.011295
2021-11-30 14:45:55,478 iteration 3301 : loss : 0.041202, loss_ce: 0.020292
2021-11-30 14:45:57,012 iteration 3302 : loss : 0.023750, loss_ce: 0.008498
2021-11-30 14:45:58,508 iteration 3303 : loss : 0.024113, loss_ce: 0.009841
2021-11-30 14:46:00,029 iteration 3304 : loss : 0.033333, loss_ce: 0.012106
2021-11-30 14:46:01,587 iteration 3305 : loss : 0.024065, loss_ce: 0.007871
2021-11-30 14:46:03,149 iteration 3306 : loss : 0.024227, loss_ce: 0.009191
2021-11-30 14:46:04,638 iteration 3307 : loss : 0.025240, loss_ce: 0.009735
2021-11-30 14:46:06,166 iteration 3308 : loss : 0.042714, loss_ce: 0.018303
2021-11-30 14:46:07,686 iteration 3309 : loss : 0.029066, loss_ce: 0.007121
2021-11-30 14:46:09,265 iteration 3310 : loss : 0.042721, loss_ce: 0.014399
2021-11-30 14:46:10,844 iteration 3311 : loss : 0.020255, loss_ce: 0.006965
2021-11-30 14:46:12,298 iteration 3312 : loss : 0.026750, loss_ce: 0.008130
2021-11-30 14:46:13,796 iteration 3313 : loss : 0.021145, loss_ce: 0.007621
2021-11-30 14:46:15,379 iteration 3314 : loss : 0.025114, loss_ce: 0.008527
2021-11-30 14:46:15,379 Training Data Eval:
2021-11-30 14:46:22,964   Average segmentation loss on training set: 0.0184
2021-11-30 14:46:22,965 Validation Data Eval:
2021-11-30 14:46:25,594   Average segmentation loss on validation set: 0.0668
2021-11-30 14:46:27,076 iteration 3315 : loss : 0.017110, loss_ce: 0.008106
 49%|█████████████▏             | 195/400 [1:31:17<1:41:23, 29.68s/it]2021-11-30 14:46:28,607 iteration 3316 : loss : 0.017545, loss_ce: 0.006343
2021-11-30 14:46:30,089 iteration 3317 : loss : 0.034485, loss_ce: 0.013383
2021-11-30 14:46:31,696 iteration 3318 : loss : 0.021687, loss_ce: 0.008574
2021-11-30 14:46:33,179 iteration 3319 : loss : 0.024399, loss_ce: 0.008280
2021-11-30 14:46:34,701 iteration 3320 : loss : 0.020340, loss_ce: 0.007852
2021-11-30 14:46:36,224 iteration 3321 : loss : 0.021060, loss_ce: 0.006391
2021-11-30 14:46:37,755 iteration 3322 : loss : 0.029275, loss_ce: 0.012095
2021-11-30 14:46:39,237 iteration 3323 : loss : 0.023804, loss_ce: 0.007717
2021-11-30 14:46:40,851 iteration 3324 : loss : 0.033885, loss_ce: 0.013956
2021-11-30 14:46:42,329 iteration 3325 : loss : 0.031141, loss_ce: 0.010036
2021-11-30 14:46:43,861 iteration 3326 : loss : 0.026959, loss_ce: 0.011011
2021-11-30 14:46:45,456 iteration 3327 : loss : 0.037201, loss_ce: 0.012863
2021-11-30 14:46:46,972 iteration 3328 : loss : 0.023970, loss_ce: 0.007802
2021-11-30 14:46:48,457 iteration 3329 : loss : 0.021088, loss_ce: 0.009203
2021-11-30 14:46:49,952 iteration 3330 : loss : 0.035550, loss_ce: 0.013645
2021-11-30 14:46:51,493 iteration 3331 : loss : 0.019593, loss_ce: 0.006876
2021-11-30 14:46:52,937 iteration 3332 : loss : 0.018829, loss_ce: 0.008615
 49%|█████████████▏             | 196/400 [1:31:43<1:37:00, 28.53s/it]2021-11-30 14:46:54,463 iteration 3333 : loss : 0.030173, loss_ce: 0.013824
2021-11-30 14:46:56,003 iteration 3334 : loss : 0.019452, loss_ce: 0.008294
2021-11-30 14:46:57,453 iteration 3335 : loss : 0.017739, loss_ce: 0.007255
2021-11-30 14:46:58,969 iteration 3336 : loss : 0.025737, loss_ce: 0.008473
2021-11-30 14:47:00,549 iteration 3337 : loss : 0.037001, loss_ce: 0.018477
2021-11-30 14:47:02,152 iteration 3338 : loss : 0.027919, loss_ce: 0.012796
2021-11-30 14:47:03,663 iteration 3339 : loss : 0.031717, loss_ce: 0.009493
2021-11-30 14:47:05,162 iteration 3340 : loss : 0.018273, loss_ce: 0.007084
2021-11-30 14:47:06,682 iteration 3341 : loss : 0.019130, loss_ce: 0.007206
2021-11-30 14:47:08,233 iteration 3342 : loss : 0.031525, loss_ce: 0.014991
2021-11-30 14:47:09,766 iteration 3343 : loss : 0.026794, loss_ce: 0.009417
2021-11-30 14:47:11,293 iteration 3344 : loss : 0.028294, loss_ce: 0.009020
2021-11-30 14:47:12,788 iteration 3345 : loss : 0.020342, loss_ce: 0.007024
2021-11-30 14:47:14,311 iteration 3346 : loss : 0.018112, loss_ce: 0.007910
2021-11-30 14:47:15,868 iteration 3347 : loss : 0.027882, loss_ce: 0.009411
2021-11-30 14:47:17,486 iteration 3348 : loss : 0.036010, loss_ce: 0.011042
2021-11-30 14:47:19,011 iteration 3349 : loss : 0.029097, loss_ce: 0.011072
 49%|█████████████▎             | 197/400 [1:32:09<1:34:02, 27.79s/it]2021-11-30 14:47:20,514 iteration 3350 : loss : 0.018806, loss_ce: 0.007701
2021-11-30 14:47:21,982 iteration 3351 : loss : 0.019940, loss_ce: 0.007271
2021-11-30 14:47:23,486 iteration 3352 : loss : 0.019792, loss_ce: 0.006920
2021-11-30 14:47:25,026 iteration 3353 : loss : 0.022253, loss_ce: 0.009379
2021-11-30 14:47:26,575 iteration 3354 : loss : 0.019505, loss_ce: 0.006375
2021-11-30 14:47:28,159 iteration 3355 : loss : 0.027272, loss_ce: 0.014597
2021-11-30 14:47:29,725 iteration 3356 : loss : 0.025937, loss_ce: 0.006513
2021-11-30 14:47:31,286 iteration 3357 : loss : 0.028382, loss_ce: 0.008454
2021-11-30 14:47:32,862 iteration 3358 : loss : 0.023507, loss_ce: 0.007978
2021-11-30 14:47:34,405 iteration 3359 : loss : 0.021402, loss_ce: 0.008374
2021-11-30 14:47:36,021 iteration 3360 : loss : 0.026897, loss_ce: 0.010524
2021-11-30 14:47:37,481 iteration 3361 : loss : 0.034780, loss_ce: 0.009375
2021-11-30 14:47:38,964 iteration 3362 : loss : 0.025342, loss_ce: 0.008930
2021-11-30 14:47:40,442 iteration 3363 : loss : 0.019770, loss_ce: 0.009244
2021-11-30 14:47:41,987 iteration 3364 : loss : 0.025130, loss_ce: 0.008802
2021-11-30 14:47:43,459 iteration 3365 : loss : 0.021930, loss_ce: 0.011196
2021-11-30 14:47:44,976 iteration 3366 : loss : 0.023348, loss_ce: 0.009500
 50%|█████████████▎             | 198/400 [1:32:35<1:31:43, 27.25s/it]2021-11-30 14:47:46,536 iteration 3367 : loss : 0.030224, loss_ce: 0.011115
2021-11-30 14:47:48,068 iteration 3368 : loss : 0.024748, loss_ce: 0.011512
2021-11-30 14:47:49,606 iteration 3369 : loss : 0.022696, loss_ce: 0.008077
2021-11-30 14:47:51,133 iteration 3370 : loss : 0.025190, loss_ce: 0.010747
2021-11-30 14:47:52,569 iteration 3371 : loss : 0.016255, loss_ce: 0.006318
2021-11-30 14:47:54,065 iteration 3372 : loss : 0.025091, loss_ce: 0.012945
2021-11-30 14:47:55,583 iteration 3373 : loss : 0.018452, loss_ce: 0.008342
2021-11-30 14:47:57,055 iteration 3374 : loss : 0.017922, loss_ce: 0.007716
2021-11-30 14:47:58,533 iteration 3375 : loss : 0.019281, loss_ce: 0.008198
2021-11-30 14:48:00,010 iteration 3376 : loss : 0.025032, loss_ce: 0.010302
2021-11-30 14:48:01,580 iteration 3377 : loss : 0.029922, loss_ce: 0.009458
2021-11-30 14:48:03,090 iteration 3378 : loss : 0.031994, loss_ce: 0.011208
2021-11-30 14:48:04,540 iteration 3379 : loss : 0.019681, loss_ce: 0.008546
2021-11-30 14:48:06,120 iteration 3380 : loss : 0.029176, loss_ce: 0.010247
2021-11-30 14:48:07,566 iteration 3381 : loss : 0.032000, loss_ce: 0.006979
2021-11-30 14:48:09,092 iteration 3382 : loss : 0.031032, loss_ce: 0.011629
2021-11-30 14:48:10,603 iteration 3383 : loss : 0.021840, loss_ce: 0.007566
 50%|█████████████▍             | 199/400 [1:33:01<1:29:38, 26.76s/it]2021-11-30 14:48:12,094 iteration 3384 : loss : 0.020565, loss_ce: 0.007363
2021-11-30 14:48:13,655 iteration 3385 : loss : 0.019132, loss_ce: 0.007646
2021-11-30 14:48:15,233 iteration 3386 : loss : 0.028644, loss_ce: 0.014245
2021-11-30 14:48:16,784 iteration 3387 : loss : 0.025887, loss_ce: 0.010382
2021-11-30 14:48:18,242 iteration 3388 : loss : 0.020170, loss_ce: 0.007271
2021-11-30 14:48:19,786 iteration 3389 : loss : 0.026904, loss_ce: 0.011603
2021-11-30 14:48:21,247 iteration 3390 : loss : 0.023431, loss_ce: 0.006365
2021-11-30 14:48:22,852 iteration 3391 : loss : 0.044152, loss_ce: 0.010722
2021-11-30 14:48:24,394 iteration 3392 : loss : 0.033683, loss_ce: 0.013023
2021-11-30 14:48:25,943 iteration 3393 : loss : 0.023845, loss_ce: 0.008537
2021-11-30 14:48:27,392 iteration 3394 : loss : 0.026501, loss_ce: 0.009168
2021-11-30 14:48:29,010 iteration 3395 : loss : 0.027085, loss_ce: 0.009885
2021-11-30 14:48:30,530 iteration 3396 : loss : 0.032415, loss_ce: 0.012542
2021-11-30 14:48:32,017 iteration 3397 : loss : 0.030330, loss_ce: 0.012394
2021-11-30 14:48:33,572 iteration 3398 : loss : 0.024953, loss_ce: 0.008197
2021-11-30 14:48:35,093 iteration 3399 : loss : 0.019819, loss_ce: 0.007810
2021-11-30 14:48:35,093 Training Data Eval:
2021-11-30 14:48:42,677   Average segmentation loss on training set: 0.0172
2021-11-30 14:48:42,678 Validation Data Eval:
2021-11-30 14:48:45,297   Average segmentation loss on validation set: 0.0778
2021-11-30 14:48:46,834 iteration 3400 : loss : 0.027261, loss_ce: 0.008699
 50%|█████████████▌             | 200/400 [1:33:37<1:38:40, 29.60s/it]2021-11-30 14:48:48,516 iteration 3401 : loss : 0.026183, loss_ce: 0.010813
2021-11-30 14:48:50,083 iteration 3402 : loss : 0.025320, loss_ce: 0.009304
2021-11-30 14:48:51,592 iteration 3403 : loss : 0.022359, loss_ce: 0.010887
2021-11-30 14:48:53,097 iteration 3404 : loss : 0.021318, loss_ce: 0.006281
2021-11-30 14:48:54,612 iteration 3405 : loss : 0.030118, loss_ce: 0.013006
2021-11-30 14:48:56,174 iteration 3406 : loss : 0.033270, loss_ce: 0.011930
2021-11-30 14:48:57,696 iteration 3407 : loss : 0.032139, loss_ce: 0.012338
2021-11-30 14:48:59,237 iteration 3408 : loss : 0.024532, loss_ce: 0.008426
2021-11-30 14:49:00,782 iteration 3409 : loss : 0.026560, loss_ce: 0.011858
2021-11-30 14:49:02,315 iteration 3410 : loss : 0.024486, loss_ce: 0.007865
2021-11-30 14:49:03,883 iteration 3411 : loss : 0.025252, loss_ce: 0.009553
2021-11-30 14:49:05,349 iteration 3412 : loss : 0.026636, loss_ce: 0.008767
2021-11-30 14:49:06,807 iteration 3413 : loss : 0.023003, loss_ce: 0.008986
2021-11-30 14:49:08,358 iteration 3414 : loss : 0.031833, loss_ce: 0.007846
2021-11-30 14:49:09,919 iteration 3415 : loss : 0.020915, loss_ce: 0.007245
2021-11-30 14:49:11,478 iteration 3416 : loss : 0.017399, loss_ce: 0.005313
2021-11-30 14:49:13,069 iteration 3417 : loss : 0.037632, loss_ce: 0.014697
 50%|█████████████▌             | 201/400 [1:34:03<1:34:49, 28.59s/it]2021-11-30 14:49:14,630 iteration 3418 : loss : 0.021957, loss_ce: 0.010180
2021-11-30 14:49:16,195 iteration 3419 : loss : 0.034944, loss_ce: 0.011780
2021-11-30 14:49:17,813 iteration 3420 : loss : 0.028484, loss_ce: 0.009143
2021-11-30 14:49:19,354 iteration 3421 : loss : 0.030905, loss_ce: 0.010612
2021-11-30 14:49:20,843 iteration 3422 : loss : 0.023660, loss_ce: 0.006791
2021-11-30 14:49:22,382 iteration 3423 : loss : 0.020056, loss_ce: 0.007723
2021-11-30 14:49:23,898 iteration 3424 : loss : 0.048463, loss_ce: 0.019961
2021-11-30 14:49:25,368 iteration 3425 : loss : 0.028318, loss_ce: 0.013763
2021-11-30 14:49:26,893 iteration 3426 : loss : 0.025164, loss_ce: 0.008096
2021-11-30 14:49:28,431 iteration 3427 : loss : 0.027566, loss_ce: 0.008200
2021-11-30 14:49:29,964 iteration 3428 : loss : 0.031254, loss_ce: 0.011127
2021-11-30 14:49:31,521 iteration 3429 : loss : 0.026234, loss_ce: 0.009472
2021-11-30 14:49:33,070 iteration 3430 : loss : 0.035771, loss_ce: 0.014242
2021-11-30 14:49:34,526 iteration 3431 : loss : 0.024825, loss_ce: 0.010287
2021-11-30 14:49:36,024 iteration 3432 : loss : 0.025498, loss_ce: 0.007743
2021-11-30 14:49:37,506 iteration 3433 : loss : 0.023401, loss_ce: 0.007669
2021-11-30 14:49:39,070 iteration 3434 : loss : 0.040197, loss_ce: 0.014422
 50%|█████████████▋             | 202/400 [1:34:29<1:31:47, 27.82s/it]2021-11-30 14:49:40,575 iteration 3435 : loss : 0.025689, loss_ce: 0.008003
2021-11-30 14:49:42,066 iteration 3436 : loss : 0.017480, loss_ce: 0.006275
2021-11-30 14:49:43,679 iteration 3437 : loss : 0.026930, loss_ce: 0.011540
2021-11-30 14:49:45,254 iteration 3438 : loss : 0.020082, loss_ce: 0.008904
2021-11-30 14:49:46,834 iteration 3439 : loss : 0.028389, loss_ce: 0.010879
2021-11-30 14:49:48,312 iteration 3440 : loss : 0.020184, loss_ce: 0.007366
2021-11-30 14:49:49,817 iteration 3441 : loss : 0.026625, loss_ce: 0.011708
2021-11-30 14:49:51,433 iteration 3442 : loss : 0.038386, loss_ce: 0.013043
2021-11-30 14:49:53,014 iteration 3443 : loss : 0.027058, loss_ce: 0.009640
2021-11-30 14:49:54,583 iteration 3444 : loss : 0.027493, loss_ce: 0.010381
2021-11-30 14:49:56,103 iteration 3445 : loss : 0.028436, loss_ce: 0.006851
2021-11-30 14:49:57,624 iteration 3446 : loss : 0.025078, loss_ce: 0.010165
2021-11-30 14:49:59,149 iteration 3447 : loss : 0.024984, loss_ce: 0.008114
2021-11-30 14:50:00,727 iteration 3448 : loss : 0.031777, loss_ce: 0.008647
2021-11-30 14:50:02,268 iteration 3449 : loss : 0.029944, loss_ce: 0.011050
2021-11-30 14:50:03,775 iteration 3450 : loss : 0.033416, loss_ce: 0.015071
2021-11-30 14:50:05,386 iteration 3451 : loss : 0.021522, loss_ce: 0.008048
 51%|█████████████▋             | 203/400 [1:34:55<1:29:50, 27.36s/it]2021-11-30 14:50:06,929 iteration 3452 : loss : 0.024246, loss_ce: 0.009668
2021-11-30 14:50:08,413 iteration 3453 : loss : 0.023436, loss_ce: 0.009484
2021-11-30 14:50:09,885 iteration 3454 : loss : 0.020288, loss_ce: 0.006750
2021-11-30 14:50:11,473 iteration 3455 : loss : 0.030990, loss_ce: 0.012935
2021-11-30 14:50:12,953 iteration 3456 : loss : 0.018203, loss_ce: 0.005603
2021-11-30 14:50:14,566 iteration 3457 : loss : 0.024535, loss_ce: 0.009223
2021-11-30 14:50:16,118 iteration 3458 : loss : 0.028293, loss_ce: 0.009523
2021-11-30 14:50:17,640 iteration 3459 : loss : 0.026300, loss_ce: 0.011150
2021-11-30 14:50:19,156 iteration 3460 : loss : 0.023964, loss_ce: 0.009804
2021-11-30 14:50:20,667 iteration 3461 : loss : 0.024524, loss_ce: 0.008868
2021-11-30 14:50:22,167 iteration 3462 : loss : 0.022730, loss_ce: 0.009792
2021-11-30 14:50:23,730 iteration 3463 : loss : 0.020496, loss_ce: 0.007109
2021-11-30 14:50:25,189 iteration 3464 : loss : 0.020818, loss_ce: 0.007270
2021-11-30 14:50:26,794 iteration 3465 : loss : 0.026787, loss_ce: 0.008334
2021-11-30 14:50:28,333 iteration 3466 : loss : 0.017936, loss_ce: 0.006044
2021-11-30 14:50:29,877 iteration 3467 : loss : 0.020902, loss_ce: 0.010168
2021-11-30 14:50:31,386 iteration 3468 : loss : 0.024208, loss_ce: 0.009901
 51%|█████████████▊             | 204/400 [1:35:21<1:28:02, 26.95s/it]2021-11-30 14:50:32,906 iteration 3469 : loss : 0.019362, loss_ce: 0.005851
2021-11-30 14:50:34,477 iteration 3470 : loss : 0.033120, loss_ce: 0.010052
2021-11-30 14:50:35,932 iteration 3471 : loss : 0.018973, loss_ce: 0.006381
2021-11-30 14:50:37,468 iteration 3472 : loss : 0.037419, loss_ce: 0.017420
2021-11-30 14:50:39,085 iteration 3473 : loss : 0.032864, loss_ce: 0.012809
2021-11-30 14:50:40,595 iteration 3474 : loss : 0.023298, loss_ce: 0.007033
2021-11-30 14:50:42,198 iteration 3475 : loss : 0.040829, loss_ce: 0.011128
2021-11-30 14:50:43,688 iteration 3476 : loss : 0.051202, loss_ce: 0.016348
2021-11-30 14:50:45,232 iteration 3477 : loss : 0.031453, loss_ce: 0.008909
2021-11-30 14:50:46,741 iteration 3478 : loss : 0.034493, loss_ce: 0.016385
2021-11-30 14:50:48,239 iteration 3479 : loss : 0.022460, loss_ce: 0.009129
2021-11-30 14:50:49,674 iteration 3480 : loss : 0.021431, loss_ce: 0.009016
2021-11-30 14:50:51,177 iteration 3481 : loss : 0.027014, loss_ce: 0.010715
2021-11-30 14:50:52,685 iteration 3482 : loss : 0.020798, loss_ce: 0.008074
2021-11-30 14:50:54,280 iteration 3483 : loss : 0.035471, loss_ce: 0.016070
2021-11-30 14:50:55,730 iteration 3484 : loss : 0.024381, loss_ce: 0.009717
2021-11-30 14:50:55,730 Training Data Eval:
2021-11-30 14:51:03,322   Average segmentation loss on training set: 0.0180
2021-11-30 14:51:03,322 Validation Data Eval:
2021-11-30 14:51:05,952   Average segmentation loss on validation set: 0.0749
2021-11-30 14:51:07,557 iteration 3485 : loss : 0.035400, loss_ce: 0.017771
 51%|█████████████▊             | 205/400 [1:35:58<1:36:35, 29.72s/it]2021-11-30 14:51:09,114 iteration 3486 : loss : 0.028590, loss_ce: 0.013329
2021-11-30 14:51:10,593 iteration 3487 : loss : 0.022071, loss_ce: 0.009051
2021-11-30 14:51:12,093 iteration 3488 : loss : 0.029132, loss_ce: 0.010297
2021-11-30 14:51:13,611 iteration 3489 : loss : 0.028587, loss_ce: 0.009902
2021-11-30 14:51:15,174 iteration 3490 : loss : 0.033022, loss_ce: 0.013456
2021-11-30 14:51:16,766 iteration 3491 : loss : 0.033233, loss_ce: 0.012946
2021-11-30 14:51:18,220 iteration 3492 : loss : 0.028985, loss_ce: 0.009971
2021-11-30 14:51:19,836 iteration 3493 : loss : 0.030493, loss_ce: 0.011997
2021-11-30 14:51:21,379 iteration 3494 : loss : 0.026968, loss_ce: 0.008534
2021-11-30 14:51:22,888 iteration 3495 : loss : 0.028095, loss_ce: 0.009618
2021-11-30 14:51:24,440 iteration 3496 : loss : 0.020457, loss_ce: 0.007984
2021-11-30 14:51:26,000 iteration 3497 : loss : 0.030635, loss_ce: 0.012493
2021-11-30 14:51:27,618 iteration 3498 : loss : 0.023346, loss_ce: 0.009381
2021-11-30 14:51:29,089 iteration 3499 : loss : 0.022095, loss_ce: 0.007994
2021-11-30 14:51:30,527 iteration 3500 : loss : 0.019461, loss_ce: 0.005976
2021-11-30 14:51:31,992 iteration 3501 : loss : 0.024017, loss_ce: 0.007978
2021-11-30 14:51:33,545 iteration 3502 : loss : 0.027697, loss_ce: 0.009295
 52%|█████████████▉             | 206/400 [1:36:24<1:32:28, 28.60s/it]2021-11-30 14:51:35,125 iteration 3503 : loss : 0.026715, loss_ce: 0.009463
2021-11-30 14:51:36,619 iteration 3504 : loss : 0.019938, loss_ce: 0.006137
2021-11-30 14:51:38,048 iteration 3505 : loss : 0.024419, loss_ce: 0.009830
2021-11-30 14:51:39,597 iteration 3506 : loss : 0.021357, loss_ce: 0.006353
2021-11-30 14:51:41,116 iteration 3507 : loss : 0.023480, loss_ce: 0.006536
2021-11-30 14:51:42,742 iteration 3508 : loss : 0.038049, loss_ce: 0.018244
2021-11-30 14:51:44,273 iteration 3509 : loss : 0.023252, loss_ce: 0.009655
2021-11-30 14:51:45,749 iteration 3510 : loss : 0.021883, loss_ce: 0.008671
2021-11-30 14:51:47,216 iteration 3511 : loss : 0.026817, loss_ce: 0.012073
2021-11-30 14:51:48,800 iteration 3512 : loss : 0.038433, loss_ce: 0.010917
2021-11-30 14:51:50,322 iteration 3513 : loss : 0.020213, loss_ce: 0.006130
2021-11-30 14:51:51,969 iteration 3514 : loss : 0.036601, loss_ce: 0.019005
2021-11-30 14:51:53,473 iteration 3515 : loss : 0.025282, loss_ce: 0.007987
2021-11-30 14:51:54,966 iteration 3516 : loss : 0.025915, loss_ce: 0.009552
2021-11-30 14:51:56,477 iteration 3517 : loss : 0.022966, loss_ce: 0.008677
2021-11-30 14:51:57,989 iteration 3518 : loss : 0.026368, loss_ce: 0.014437
2021-11-30 14:51:59,525 iteration 3519 : loss : 0.021396, loss_ce: 0.007943
 52%|█████████████▉             | 207/400 [1:36:50<1:29:27, 27.81s/it]2021-11-30 14:52:01,090 iteration 3520 : loss : 0.035981, loss_ce: 0.012932
2021-11-30 14:52:02,573 iteration 3521 : loss : 0.031283, loss_ce: 0.013934
2021-11-30 14:52:04,039 iteration 3522 : loss : 0.018826, loss_ce: 0.008402
2021-11-30 14:52:05,537 iteration 3523 : loss : 0.025268, loss_ce: 0.008455
2021-11-30 14:52:07,076 iteration 3524 : loss : 0.020897, loss_ce: 0.008645
2021-11-30 14:52:08,666 iteration 3525 : loss : 0.026251, loss_ce: 0.010650
2021-11-30 14:52:10,217 iteration 3526 : loss : 0.021069, loss_ce: 0.007606
2021-11-30 14:52:11,777 iteration 3527 : loss : 0.034950, loss_ce: 0.010714
2021-11-30 14:52:13,405 iteration 3528 : loss : 0.057608, loss_ce: 0.026856
2021-11-30 14:52:14,943 iteration 3529 : loss : 0.030911, loss_ce: 0.008805
2021-11-30 14:52:16,487 iteration 3530 : loss : 0.017429, loss_ce: 0.006452
2021-11-30 14:52:17,959 iteration 3531 : loss : 0.022812, loss_ce: 0.006049
2021-11-30 14:52:19,547 iteration 3532 : loss : 0.035234, loss_ce: 0.016140
2021-11-30 14:52:21,052 iteration 3533 : loss : 0.021330, loss_ce: 0.006584
2021-11-30 14:52:22,598 iteration 3534 : loss : 0.026153, loss_ce: 0.010120
2021-11-30 14:52:24,187 iteration 3535 : loss : 0.026993, loss_ce: 0.010131
2021-11-30 14:52:25,749 iteration 3536 : loss : 0.025493, loss_ce: 0.009825
 52%|██████████████             | 208/400 [1:37:16<1:27:28, 27.34s/it]2021-11-30 14:52:27,236 iteration 3537 : loss : 0.020081, loss_ce: 0.007760
2021-11-30 14:52:28,688 iteration 3538 : loss : 0.017830, loss_ce: 0.007462
2021-11-30 14:52:30,174 iteration 3539 : loss : 0.017013, loss_ce: 0.007299
2021-11-30 14:52:31,600 iteration 3540 : loss : 0.020766, loss_ce: 0.005986
2021-11-30 14:52:33,187 iteration 3541 : loss : 0.028395, loss_ce: 0.010488
2021-11-30 14:52:34,710 iteration 3542 : loss : 0.022975, loss_ce: 0.009274
2021-11-30 14:52:36,340 iteration 3543 : loss : 0.040393, loss_ce: 0.014158
2021-11-30 14:52:37,790 iteration 3544 : loss : 0.017682, loss_ce: 0.007269
2021-11-30 14:52:39,304 iteration 3545 : loss : 0.018776, loss_ce: 0.007805
2021-11-30 14:52:40,762 iteration 3546 : loss : 0.020440, loss_ce: 0.007369
2021-11-30 14:52:42,274 iteration 3547 : loss : 0.024447, loss_ce: 0.010180
2021-11-30 14:52:43,741 iteration 3548 : loss : 0.027068, loss_ce: 0.008404
2021-11-30 14:52:45,264 iteration 3549 : loss : 0.027731, loss_ce: 0.010074
2021-11-30 14:52:46,833 iteration 3550 : loss : 0.020863, loss_ce: 0.009022
2021-11-30 14:52:48,417 iteration 3551 : loss : 0.031061, loss_ce: 0.010908
2021-11-30 14:52:49,982 iteration 3552 : loss : 0.068427, loss_ce: 0.026515
2021-11-30 14:52:51,550 iteration 3553 : loss : 0.025284, loss_ce: 0.010736
 52%|██████████████             | 209/400 [1:37:42<1:25:33, 26.88s/it]2021-11-30 14:52:53,115 iteration 3554 : loss : 0.022854, loss_ce: 0.009878
2021-11-30 14:52:54,618 iteration 3555 : loss : 0.019749, loss_ce: 0.006262
2021-11-30 14:52:56,112 iteration 3556 : loss : 0.025038, loss_ce: 0.010282
2021-11-30 14:52:57,710 iteration 3557 : loss : 0.027662, loss_ce: 0.007559
2021-11-30 14:52:59,185 iteration 3558 : loss : 0.031683, loss_ce: 0.008463
2021-11-30 14:53:00,682 iteration 3559 : loss : 0.022128, loss_ce: 0.007167
2021-11-30 14:53:02,107 iteration 3560 : loss : 0.023690, loss_ce: 0.012978
2021-11-30 14:53:03,695 iteration 3561 : loss : 0.028383, loss_ce: 0.010554
2021-11-30 14:53:05,187 iteration 3562 : loss : 0.025657, loss_ce: 0.010141
2021-11-30 14:53:06,737 iteration 3563 : loss : 0.027894, loss_ce: 0.009205
2021-11-30 14:53:08,264 iteration 3564 : loss : 0.033667, loss_ce: 0.012137
2021-11-30 14:53:09,881 iteration 3565 : loss : 0.033762, loss_ce: 0.011374
2021-11-30 14:53:11,428 iteration 3566 : loss : 0.035149, loss_ce: 0.014007
2021-11-30 14:53:13,027 iteration 3567 : loss : 0.026896, loss_ce: 0.012912
2021-11-30 14:53:14,613 iteration 3568 : loss : 0.042113, loss_ce: 0.015341
2021-11-30 14:53:16,188 iteration 3569 : loss : 0.038695, loss_ce: 0.008133
2021-11-30 14:53:16,188 Training Data Eval:
2021-11-30 14:53:23,766   Average segmentation loss on training set: 0.0165
2021-11-30 14:53:23,767 Validation Data Eval:
2021-11-30 14:53:26,396   Average segmentation loss on validation set: 0.0770
2021-11-30 14:53:27,931 iteration 3570 : loss : 0.023871, loss_ce: 0.008466
 52%|██████████████▏            | 210/400 [1:38:18<1:34:08, 29.73s/it]2021-11-30 14:53:29,490 iteration 3571 : loss : 0.028179, loss_ce: 0.010982
2021-11-30 14:53:31,033 iteration 3572 : loss : 0.022420, loss_ce: 0.006139
2021-11-30 14:53:32,561 iteration 3573 : loss : 0.041040, loss_ce: 0.019599
2021-11-30 14:53:34,054 iteration 3574 : loss : 0.016212, loss_ce: 0.006894
2021-11-30 14:53:35,564 iteration 3575 : loss : 0.023761, loss_ce: 0.009816
2021-11-30 14:53:37,113 iteration 3576 : loss : 0.033454, loss_ce: 0.012427
2021-11-30 14:53:38,678 iteration 3577 : loss : 0.020233, loss_ce: 0.008668
2021-11-30 14:53:40,239 iteration 3578 : loss : 0.029128, loss_ce: 0.012490
2021-11-30 14:53:41,734 iteration 3579 : loss : 0.030348, loss_ce: 0.009903
2021-11-30 14:53:43,301 iteration 3580 : loss : 0.026799, loss_ce: 0.008677
2021-11-30 14:53:44,790 iteration 3581 : loss : 0.030266, loss_ce: 0.006011
2021-11-30 14:53:46,301 iteration 3582 : loss : 0.021255, loss_ce: 0.008155
2021-11-30 14:53:47,855 iteration 3583 : loss : 0.036977, loss_ce: 0.015210
2021-11-30 14:53:49,360 iteration 3584 : loss : 0.032860, loss_ce: 0.012270
2021-11-30 14:53:50,857 iteration 3585 : loss : 0.019321, loss_ce: 0.007245
2021-11-30 14:53:52,311 iteration 3586 : loss : 0.026415, loss_ce: 0.009783
2021-11-30 14:53:53,823 iteration 3587 : loss : 0.021239, loss_ce: 0.008123
 53%|██████████████▏            | 211/400 [1:38:44<1:30:00, 28.58s/it]2021-11-30 14:53:55,304 iteration 3588 : loss : 0.019443, loss_ce: 0.007248
2021-11-30 14:53:56,865 iteration 3589 : loss : 0.030518, loss_ce: 0.010702
2021-11-30 14:53:58,382 iteration 3590 : loss : 0.028419, loss_ce: 0.013298
2021-11-30 14:53:59,876 iteration 3591 : loss : 0.022902, loss_ce: 0.007396
2021-11-30 14:54:01,443 iteration 3592 : loss : 0.031681, loss_ce: 0.011758
2021-11-30 14:54:02,977 iteration 3593 : loss : 0.028046, loss_ce: 0.007556
2021-11-30 14:54:04,507 iteration 3594 : loss : 0.021722, loss_ce: 0.006774
2021-11-30 14:54:06,151 iteration 3595 : loss : 0.065801, loss_ce: 0.014720
2021-11-30 14:54:07,605 iteration 3596 : loss : 0.022382, loss_ce: 0.008422
2021-11-30 14:54:09,191 iteration 3597 : loss : 0.043030, loss_ce: 0.013395
2021-11-30 14:54:10,699 iteration 3598 : loss : 0.031357, loss_ce: 0.017833
2021-11-30 14:54:12,221 iteration 3599 : loss : 0.029422, loss_ce: 0.010860
2021-11-30 14:54:13,730 iteration 3600 : loss : 0.025014, loss_ce: 0.011806
2021-11-30 14:54:15,251 iteration 3601 : loss : 0.025043, loss_ce: 0.010787
2021-11-30 14:54:16,747 iteration 3602 : loss : 0.027750, loss_ce: 0.012627
2021-11-30 14:54:18,237 iteration 3603 : loss : 0.026847, loss_ce: 0.012588
2021-11-30 14:54:19,699 iteration 3604 : loss : 0.023243, loss_ce: 0.008862
 53%|██████████████▎            | 212/400 [1:39:10<1:27:00, 27.77s/it]2021-11-30 14:54:21,254 iteration 3605 : loss : 0.023651, loss_ce: 0.008518
2021-11-30 14:54:22,771 iteration 3606 : loss : 0.036240, loss_ce: 0.015236
2021-11-30 14:54:24,223 iteration 3607 : loss : 0.019893, loss_ce: 0.006751
2021-11-30 14:54:25,692 iteration 3608 : loss : 0.024392, loss_ce: 0.011224
2021-11-30 14:54:27,244 iteration 3609 : loss : 0.033651, loss_ce: 0.011220
2021-11-30 14:54:28,718 iteration 3610 : loss : 0.026008, loss_ce: 0.011562
2021-11-30 14:54:30,280 iteration 3611 : loss : 0.033353, loss_ce: 0.016847
2021-11-30 14:54:31,848 iteration 3612 : loss : 0.022407, loss_ce: 0.008292
2021-11-30 14:54:33,387 iteration 3613 : loss : 0.027412, loss_ce: 0.008908
2021-11-30 14:54:34,939 iteration 3614 : loss : 0.018540, loss_ce: 0.005591
2021-11-30 14:54:36,445 iteration 3615 : loss : 0.028348, loss_ce: 0.009590
2021-11-30 14:54:38,026 iteration 3616 : loss : 0.033738, loss_ce: 0.009145
2021-11-30 14:54:39,537 iteration 3617 : loss : 0.028471, loss_ce: 0.010490
2021-11-30 14:54:41,028 iteration 3618 : loss : 0.024749, loss_ce: 0.009766
2021-11-30 14:54:42,538 iteration 3619 : loss : 0.025803, loss_ce: 0.010781
2021-11-30 14:54:44,082 iteration 3620 : loss : 0.036703, loss_ce: 0.017046
2021-11-30 14:54:45,602 iteration 3621 : loss : 0.030659, loss_ce: 0.012247
 53%|██████████████▍            | 213/400 [1:39:36<1:24:47, 27.21s/it]2021-11-30 14:54:47,210 iteration 3622 : loss : 0.033197, loss_ce: 0.012576
2021-11-30 14:54:48,733 iteration 3623 : loss : 0.021978, loss_ce: 0.008489
2021-11-30 14:54:50,308 iteration 3624 : loss : 0.023458, loss_ce: 0.007764
2021-11-30 14:54:51,879 iteration 3625 : loss : 0.035708, loss_ce: 0.014775
2021-11-30 14:54:53,391 iteration 3626 : loss : 0.022226, loss_ce: 0.008239
2021-11-30 14:54:54,949 iteration 3627 : loss : 0.025346, loss_ce: 0.012022
2021-11-30 14:54:56,495 iteration 3628 : loss : 0.025042, loss_ce: 0.007223
2021-11-30 14:54:58,074 iteration 3629 : loss : 0.024105, loss_ce: 0.009856
2021-11-30 14:54:59,588 iteration 3630 : loss : 0.030048, loss_ce: 0.010982
2021-11-30 14:55:01,037 iteration 3631 : loss : 0.021679, loss_ce: 0.008823
2021-11-30 14:55:02,494 iteration 3632 : loss : 0.020674, loss_ce: 0.008950
2021-11-30 14:55:04,080 iteration 3633 : loss : 0.037224, loss_ce: 0.015811
2021-11-30 14:55:05,585 iteration 3634 : loss : 0.026700, loss_ce: 0.009269
2021-11-30 14:55:07,062 iteration 3635 : loss : 0.022923, loss_ce: 0.008132
2021-11-30 14:55:08,543 iteration 3636 : loss : 0.021462, loss_ce: 0.008808
2021-11-30 14:55:10,130 iteration 3637 : loss : 0.025798, loss_ce: 0.007796
2021-11-30 14:55:11,600 iteration 3638 : loss : 0.022607, loss_ce: 0.007077
 54%|██████████████▍            | 214/400 [1:40:02<1:23:13, 26.85s/it]2021-11-30 14:55:13,128 iteration 3639 : loss : 0.021801, loss_ce: 0.010071
2021-11-30 14:55:14,680 iteration 3640 : loss : 0.019674, loss_ce: 0.006834
2021-11-30 14:55:16,209 iteration 3641 : loss : 0.020727, loss_ce: 0.006406
2021-11-30 14:55:17,754 iteration 3642 : loss : 0.031090, loss_ce: 0.013249
2021-11-30 14:55:19,257 iteration 3643 : loss : 0.029013, loss_ce: 0.013142
2021-11-30 14:55:20,751 iteration 3644 : loss : 0.035043, loss_ce: 0.015971
2021-11-30 14:55:22,243 iteration 3645 : loss : 0.018432, loss_ce: 0.006728
2021-11-30 14:55:23,770 iteration 3646 : loss : 0.020789, loss_ce: 0.007112
2021-11-30 14:55:25,319 iteration 3647 : loss : 0.023269, loss_ce: 0.009368
2021-11-30 14:55:26,938 iteration 3648 : loss : 0.031687, loss_ce: 0.012421
2021-11-30 14:55:28,484 iteration 3649 : loss : 0.027229, loss_ce: 0.008658
2021-11-30 14:55:29,991 iteration 3650 : loss : 0.027402, loss_ce: 0.009830
2021-11-30 14:55:31,526 iteration 3651 : loss : 0.024255, loss_ce: 0.009484
2021-11-30 14:55:33,011 iteration 3652 : loss : 0.022639, loss_ce: 0.009502
2021-11-30 14:55:34,601 iteration 3653 : loss : 0.037928, loss_ce: 0.009185
2021-11-30 14:55:36,120 iteration 3654 : loss : 0.021992, loss_ce: 0.007132
2021-11-30 14:55:36,120 Training Data Eval:
2021-11-30 14:55:43,699   Average segmentation loss on training set: 0.0162
2021-11-30 14:55:43,700 Validation Data Eval:
2021-11-30 14:55:46,318   Average segmentation loss on validation set: 0.0903
2021-11-30 14:55:47,751 iteration 3655 : loss : 0.020817, loss_ce: 0.007427
 54%|██████████████▌            | 215/400 [1:40:38<1:31:22, 29.64s/it]2021-11-30 14:55:49,369 iteration 3656 : loss : 0.041354, loss_ce: 0.009498
2021-11-30 14:55:50,858 iteration 3657 : loss : 0.020471, loss_ce: 0.010159
2021-11-30 14:55:52,385 iteration 3658 : loss : 0.021999, loss_ce: 0.008512
2021-11-30 14:55:53,936 iteration 3659 : loss : 0.020824, loss_ce: 0.006369
2021-11-30 14:55:55,565 iteration 3660 : loss : 0.037392, loss_ce: 0.011404
2021-11-30 14:55:57,181 iteration 3661 : loss : 0.028887, loss_ce: 0.012708
2021-11-30 14:55:58,621 iteration 3662 : loss : 0.019048, loss_ce: 0.006966
2021-11-30 14:56:00,106 iteration 3663 : loss : 0.019441, loss_ce: 0.006128
2021-11-30 14:56:01,623 iteration 3664 : loss : 0.025462, loss_ce: 0.007203
2021-11-30 14:56:03,125 iteration 3665 : loss : 0.017764, loss_ce: 0.007453
2021-11-30 14:56:04,742 iteration 3666 : loss : 0.034809, loss_ce: 0.016650
2021-11-30 14:56:06,295 iteration 3667 : loss : 0.029903, loss_ce: 0.011501
2021-11-30 14:56:07,854 iteration 3668 : loss : 0.024068, loss_ce: 0.009014
2021-11-30 14:56:09,374 iteration 3669 : loss : 0.033486, loss_ce: 0.013976
2021-11-30 14:56:10,884 iteration 3670 : loss : 0.034877, loss_ce: 0.010488
2021-11-30 14:56:12,446 iteration 3671 : loss : 0.025020, loss_ce: 0.009505
2021-11-30 14:56:13,921 iteration 3672 : loss : 0.024646, loss_ce: 0.009719
 54%|██████████████▌            | 216/400 [1:41:04<1:27:41, 28.60s/it]2021-11-30 14:56:15,459 iteration 3673 : loss : 0.024061, loss_ce: 0.011111
2021-11-30 14:56:16,986 iteration 3674 : loss : 0.032831, loss_ce: 0.013115
2021-11-30 14:56:18,487 iteration 3675 : loss : 0.021909, loss_ce: 0.011525
2021-11-30 14:56:19,996 iteration 3676 : loss : 0.017875, loss_ce: 0.005768
2021-11-30 14:56:21,495 iteration 3677 : loss : 0.025808, loss_ce: 0.013092
2021-11-30 14:56:23,087 iteration 3678 : loss : 0.029842, loss_ce: 0.009895
2021-11-30 14:56:24,588 iteration 3679 : loss : 0.026207, loss_ce: 0.009875
2021-11-30 14:56:26,079 iteration 3680 : loss : 0.034743, loss_ce: 0.009695
2021-11-30 14:56:27,638 iteration 3681 : loss : 0.026263, loss_ce: 0.008267
2021-11-30 14:56:29,138 iteration 3682 : loss : 0.022321, loss_ce: 0.008467
2021-11-30 14:56:30,708 iteration 3683 : loss : 0.074997, loss_ce: 0.006447
2021-11-30 14:56:32,207 iteration 3684 : loss : 0.013165, loss_ce: 0.004294
2021-11-30 14:56:33,716 iteration 3685 : loss : 0.027992, loss_ce: 0.012297
2021-11-30 14:56:35,256 iteration 3686 : loss : 0.022564, loss_ce: 0.008521
2021-11-30 14:56:36,777 iteration 3687 : loss : 0.024457, loss_ce: 0.007705
2021-11-30 14:56:38,302 iteration 3688 : loss : 0.030751, loss_ce: 0.014204
2021-11-30 14:56:39,752 iteration 3689 : loss : 0.030460, loss_ce: 0.010482
 54%|██████████████▋            | 217/400 [1:41:30<1:24:41, 27.77s/it]2021-11-30 14:56:41,268 iteration 3690 : loss : 0.023030, loss_ce: 0.005608
2021-11-30 14:56:42,856 iteration 3691 : loss : 0.061887, loss_ce: 0.015995
2021-11-30 14:56:44,407 iteration 3692 : loss : 0.023289, loss_ce: 0.009681
2021-11-30 14:56:45,986 iteration 3693 : loss : 0.038811, loss_ce: 0.014024
2021-11-30 14:56:47,496 iteration 3694 : loss : 0.020213, loss_ce: 0.008241
2021-11-30 14:56:48,975 iteration 3695 : loss : 0.024132, loss_ce: 0.009671
2021-11-30 14:56:50,547 iteration 3696 : loss : 0.031901, loss_ce: 0.015569
2021-11-30 14:56:52,048 iteration 3697 : loss : 0.030215, loss_ce: 0.009285
2021-11-30 14:56:53,575 iteration 3698 : loss : 0.027897, loss_ce: 0.008815
2021-11-30 14:56:55,159 iteration 3699 : loss : 0.028904, loss_ce: 0.009460
2021-11-30 14:56:56,694 iteration 3700 : loss : 0.025764, loss_ce: 0.010993
2021-11-30 14:56:58,184 iteration 3701 : loss : 0.026906, loss_ce: 0.008666
2021-11-30 14:56:59,667 iteration 3702 : loss : 0.030010, loss_ce: 0.011260
2021-11-30 14:57:01,289 iteration 3703 : loss : 0.044866, loss_ce: 0.022725
2021-11-30 14:57:02,798 iteration 3704 : loss : 0.027698, loss_ce: 0.007122
2021-11-30 14:57:04,279 iteration 3705 : loss : 0.020117, loss_ce: 0.006586
2021-11-30 14:57:05,758 iteration 3706 : loss : 0.022930, loss_ce: 0.005381
 55%|██████████████▋            | 218/400 [1:41:56<1:22:36, 27.24s/it]2021-11-30 14:57:07,302 iteration 3707 : loss : 0.036085, loss_ce: 0.012723
2021-11-30 14:57:08,835 iteration 3708 : loss : 0.023082, loss_ce: 0.009178
2021-11-30 14:57:10,360 iteration 3709 : loss : 0.022180, loss_ce: 0.007203
2021-11-30 14:57:11,919 iteration 3710 : loss : 0.031420, loss_ce: 0.010005
2021-11-30 14:57:13,406 iteration 3711 : loss : 0.019549, loss_ce: 0.006991
2021-11-30 14:57:14,956 iteration 3712 : loss : 0.026574, loss_ce: 0.007770
2021-11-30 14:57:16,435 iteration 3713 : loss : 0.020101, loss_ce: 0.007585
2021-11-30 14:57:17,930 iteration 3714 : loss : 0.019942, loss_ce: 0.007222
2021-11-30 14:57:19,472 iteration 3715 : loss : 0.028667, loss_ce: 0.013078
2021-11-30 14:57:20,957 iteration 3716 : loss : 0.035684, loss_ce: 0.011338
2021-11-30 14:57:22,498 iteration 3717 : loss : 0.032649, loss_ce: 0.013121
2021-11-30 14:57:24,065 iteration 3718 : loss : 0.027036, loss_ce: 0.011204
2021-11-30 14:57:25,529 iteration 3719 : loss : 0.022924, loss_ce: 0.006252
2021-11-30 14:57:27,058 iteration 3720 : loss : 0.019198, loss_ce: 0.009170
2021-11-30 14:57:28,577 iteration 3721 : loss : 0.024098, loss_ce: 0.010435
2021-11-30 14:57:30,094 iteration 3722 : loss : 0.021410, loss_ce: 0.008314
2021-11-30 14:57:31,575 iteration 3723 : loss : 0.028053, loss_ce: 0.008506
 55%|██████████████▊            | 219/400 [1:42:22<1:20:52, 26.81s/it]2021-11-30 14:57:33,054 iteration 3724 : loss : 0.021420, loss_ce: 0.010532
2021-11-30 14:57:34,540 iteration 3725 : loss : 0.031277, loss_ce: 0.013269
2021-11-30 14:57:36,119 iteration 3726 : loss : 0.032268, loss_ce: 0.013285
2021-11-30 14:57:37,642 iteration 3727 : loss : 0.023631, loss_ce: 0.009151
2021-11-30 14:57:39,171 iteration 3728 : loss : 0.027255, loss_ce: 0.006545
2021-11-30 14:57:40,678 iteration 3729 : loss : 0.021120, loss_ce: 0.005975
2021-11-30 14:57:42,194 iteration 3730 : loss : 0.022520, loss_ce: 0.008843
2021-11-30 14:57:43,691 iteration 3731 : loss : 0.024177, loss_ce: 0.007964
2021-11-30 14:57:45,242 iteration 3732 : loss : 0.026849, loss_ce: 0.007941
2021-11-30 14:57:46,722 iteration 3733 : loss : 0.021837, loss_ce: 0.008208
2021-11-30 14:57:48,249 iteration 3734 : loss : 0.056351, loss_ce: 0.024637
2021-11-30 14:57:49,776 iteration 3735 : loss : 0.030769, loss_ce: 0.007227
2021-11-30 14:57:51,343 iteration 3736 : loss : 0.026226, loss_ce: 0.011994
2021-11-30 14:57:52,834 iteration 3737 : loss : 0.020671, loss_ce: 0.006508
2021-11-30 14:57:54,345 iteration 3738 : loss : 0.022452, loss_ce: 0.007905
2021-11-30 14:57:55,820 iteration 3739 : loss : 0.023042, loss_ce: 0.008935
2021-11-30 14:57:55,820 Training Data Eval:
2021-11-30 14:58:03,400   Average segmentation loss on training set: 0.0184
2021-11-30 14:58:03,400 Validation Data Eval:
2021-11-30 14:58:06,024   Average segmentation loss on validation set: 0.0898
2021-11-30 14:58:07,701 iteration 3740 : loss : 0.033096, loss_ce: 0.015170
 55%|██████████████▊            | 220/400 [1:42:58<1:28:48, 29.60s/it]2021-11-30 14:58:09,381 iteration 3741 : loss : 0.031697, loss_ce: 0.010692
2021-11-30 14:58:10,899 iteration 3742 : loss : 0.028567, loss_ce: 0.014272
2021-11-30 14:58:12,425 iteration 3743 : loss : 0.030552, loss_ce: 0.012998
2021-11-30 14:58:13,986 iteration 3744 : loss : 0.042195, loss_ce: 0.014546
2021-11-30 14:58:15,567 iteration 3745 : loss : 0.028248, loss_ce: 0.009850
2021-11-30 14:58:17,153 iteration 3746 : loss : 0.026726, loss_ce: 0.010711
2021-11-30 14:58:18,685 iteration 3747 : loss : 0.024727, loss_ce: 0.008332
2021-11-30 14:58:20,183 iteration 3748 : loss : 0.020325, loss_ce: 0.008858
2021-11-30 14:58:21,741 iteration 3749 : loss : 0.026841, loss_ce: 0.008041
2021-11-30 14:58:23,325 iteration 3750 : loss : 0.025978, loss_ce: 0.011105
2021-11-30 14:58:24,864 iteration 3751 : loss : 0.029969, loss_ce: 0.008586
2021-11-30 14:58:26,370 iteration 3752 : loss : 0.028990, loss_ce: 0.007993
2021-11-30 14:58:27,856 iteration 3753 : loss : 0.027364, loss_ce: 0.008332
2021-11-30 14:58:29,383 iteration 3754 : loss : 0.019904, loss_ce: 0.007930
2021-11-30 14:58:30,959 iteration 3755 : loss : 0.024045, loss_ce: 0.010674
2021-11-30 14:58:32,418 iteration 3756 : loss : 0.020897, loss_ce: 0.008806
2021-11-30 14:58:33,887 iteration 3757 : loss : 0.022425, loss_ce: 0.009698
 55%|██████████████▉            | 221/400 [1:43:24<1:25:16, 28.58s/it]2021-11-30 14:58:35,510 iteration 3758 : loss : 0.027624, loss_ce: 0.009941
2021-11-30 14:58:37,006 iteration 3759 : loss : 0.024079, loss_ce: 0.007694
2021-11-30 14:58:38,509 iteration 3760 : loss : 0.020166, loss_ce: 0.008299
2021-11-30 14:58:40,065 iteration 3761 : loss : 0.031072, loss_ce: 0.012859
2021-11-30 14:58:41,643 iteration 3762 : loss : 0.023825, loss_ce: 0.011886
2021-11-30 14:58:43,270 iteration 3763 : loss : 0.025657, loss_ce: 0.008704
2021-11-30 14:58:44,784 iteration 3764 : loss : 0.030269, loss_ce: 0.010882
2021-11-30 14:58:46,270 iteration 3765 : loss : 0.018616, loss_ce: 0.007599
2021-11-30 14:58:47,836 iteration 3766 : loss : 0.032763, loss_ce: 0.010158
2021-11-30 14:58:49,349 iteration 3767 : loss : 0.020351, loss_ce: 0.006791
2021-11-30 14:58:50,836 iteration 3768 : loss : 0.028151, loss_ce: 0.008890
2021-11-30 14:58:52,325 iteration 3769 : loss : 0.020107, loss_ce: 0.008185
2021-11-30 14:58:53,883 iteration 3770 : loss : 0.032252, loss_ce: 0.008226
2021-11-30 14:58:55,528 iteration 3771 : loss : 0.030741, loss_ce: 0.012035
2021-11-30 14:58:57,094 iteration 3772 : loss : 0.035542, loss_ce: 0.009223
2021-11-30 14:58:58,617 iteration 3773 : loss : 0.017826, loss_ce: 0.006405
2021-11-30 14:59:00,211 iteration 3774 : loss : 0.059313, loss_ce: 0.032796
 56%|██████████████▉            | 222/400 [1:43:50<1:22:46, 27.90s/it]2021-11-30 14:59:01,732 iteration 3775 : loss : 0.023033, loss_ce: 0.008707
2021-11-30 14:59:03,190 iteration 3776 : loss : 0.027066, loss_ce: 0.010901
2021-11-30 14:59:04,693 iteration 3777 : loss : 0.021957, loss_ce: 0.006538
2021-11-30 14:59:06,189 iteration 3778 : loss : 0.018998, loss_ce: 0.007850
2021-11-30 14:59:07,668 iteration 3779 : loss : 0.022439, loss_ce: 0.009887
2021-11-30 14:59:09,210 iteration 3780 : loss : 0.029819, loss_ce: 0.009608
2021-11-30 14:59:10,734 iteration 3781 : loss : 0.034339, loss_ce: 0.015692
2021-11-30 14:59:12,280 iteration 3782 : loss : 0.072769, loss_ce: 0.013674
2021-11-30 14:59:13,826 iteration 3783 : loss : 0.019304, loss_ce: 0.009195
2021-11-30 14:59:15,376 iteration 3784 : loss : 0.030901, loss_ce: 0.013882
2021-11-30 14:59:16,854 iteration 3785 : loss : 0.021257, loss_ce: 0.008919
2021-11-30 14:59:18,332 iteration 3786 : loss : 0.020738, loss_ce: 0.008111
2021-11-30 14:59:19,831 iteration 3787 : loss : 0.024662, loss_ce: 0.008256
2021-11-30 14:59:21,410 iteration 3788 : loss : 0.025548, loss_ce: 0.007494
2021-11-30 14:59:22,931 iteration 3789 : loss : 0.020478, loss_ce: 0.005879
2021-11-30 14:59:24,465 iteration 3790 : loss : 0.025890, loss_ce: 0.008731
2021-11-30 14:59:26,018 iteration 3791 : loss : 0.027655, loss_ce: 0.010760
 56%|███████████████            | 223/400 [1:44:16<1:20:27, 27.28s/it]2021-11-30 14:59:27,532 iteration 3792 : loss : 0.022607, loss_ce: 0.007269
2021-11-30 14:59:29,089 iteration 3793 : loss : 0.026719, loss_ce: 0.007867
2021-11-30 14:59:30,632 iteration 3794 : loss : 0.028623, loss_ce: 0.010720
2021-11-30 14:59:32,152 iteration 3795 : loss : 0.020891, loss_ce: 0.006690
2021-11-30 14:59:33,594 iteration 3796 : loss : 0.018828, loss_ce: 0.006170
2021-11-30 14:59:35,091 iteration 3797 : loss : 0.021431, loss_ce: 0.007899
2021-11-30 14:59:36,556 iteration 3798 : loss : 0.022889, loss_ce: 0.008194
2021-11-30 14:59:38,059 iteration 3799 : loss : 0.021224, loss_ce: 0.007349
2021-11-30 14:59:39,567 iteration 3800 : loss : 0.019512, loss_ce: 0.005799
2021-11-30 14:59:41,067 iteration 3801 : loss : 0.041185, loss_ce: 0.008629
2021-11-30 14:59:42,570 iteration 3802 : loss : 0.023041, loss_ce: 0.011204
2021-11-30 14:59:44,080 iteration 3803 : loss : 0.017403, loss_ce: 0.005394
2021-11-30 14:59:45,597 iteration 3804 : loss : 0.029533, loss_ce: 0.011426
2021-11-30 14:59:47,100 iteration 3805 : loss : 0.022066, loss_ce: 0.008613
2021-11-30 14:59:48,595 iteration 3806 : loss : 0.024132, loss_ce: 0.011754
2021-11-30 14:59:50,143 iteration 3807 : loss : 0.024567, loss_ce: 0.008679
2021-11-30 14:59:51,673 iteration 3808 : loss : 0.021285, loss_ce: 0.008195
 56%|███████████████            | 224/400 [1:44:42<1:18:34, 26.79s/it]2021-11-30 14:59:53,169 iteration 3809 : loss : 0.019579, loss_ce: 0.006459
2021-11-30 14:59:54,676 iteration 3810 : loss : 0.020111, loss_ce: 0.007555
2021-11-30 14:59:56,180 iteration 3811 : loss : 0.025923, loss_ce: 0.009688
2021-11-30 14:59:57,723 iteration 3812 : loss : 0.027378, loss_ce: 0.013737
2021-11-30 14:59:59,225 iteration 3813 : loss : 0.022811, loss_ce: 0.009849
2021-11-30 15:00:00,762 iteration 3814 : loss : 0.021876, loss_ce: 0.007934
2021-11-30 15:00:02,278 iteration 3815 : loss : 0.021750, loss_ce: 0.008114
2021-11-30 15:00:03,822 iteration 3816 : loss : 0.020065, loss_ce: 0.007533
2021-11-30 15:00:05,292 iteration 3817 : loss : 0.018312, loss_ce: 0.007176
2021-11-30 15:00:06,834 iteration 3818 : loss : 0.018808, loss_ce: 0.008155
2021-11-30 15:00:08,407 iteration 3819 : loss : 0.023120, loss_ce: 0.010845
2021-11-30 15:00:09,960 iteration 3820 : loss : 0.023788, loss_ce: 0.008751
2021-11-30 15:00:11,494 iteration 3821 : loss : 0.028761, loss_ce: 0.010985
2021-11-30 15:00:12,968 iteration 3822 : loss : 0.028546, loss_ce: 0.009778
2021-11-30 15:00:14,576 iteration 3823 : loss : 0.028033, loss_ce: 0.007274
2021-11-30 15:00:16,118 iteration 3824 : loss : 0.025392, loss_ce: 0.008060
2021-11-30 15:00:16,118 Training Data Eval:
2021-11-30 15:00:23,693   Average segmentation loss on training set: 0.0157
2021-11-30 15:00:23,694 Validation Data Eval:
2021-11-30 15:00:26,319   Average segmentation loss on validation set: 0.0771
2021-11-30 15:00:27,903 iteration 3825 : loss : 0.025890, loss_ce: 0.008529
 56%|███████████████▏           | 225/400 [1:45:18<1:26:23, 29.62s/it]2021-11-30 15:00:29,486 iteration 3826 : loss : 0.024390, loss_ce: 0.011166
2021-11-30 15:00:30,971 iteration 3827 : loss : 0.022063, loss_ce: 0.007336
2021-11-30 15:00:32,497 iteration 3828 : loss : 0.021531, loss_ce: 0.009242
2021-11-30 15:00:34,034 iteration 3829 : loss : 0.021916, loss_ce: 0.006840
2021-11-30 15:00:35,521 iteration 3830 : loss : 0.017840, loss_ce: 0.007285
2021-11-30 15:00:37,006 iteration 3831 : loss : 0.022945, loss_ce: 0.007435
2021-11-30 15:00:38,487 iteration 3832 : loss : 0.020829, loss_ce: 0.004930
2021-11-30 15:00:39,994 iteration 3833 : loss : 0.016801, loss_ce: 0.007643
2021-11-30 15:00:41,542 iteration 3834 : loss : 0.025137, loss_ce: 0.011644
2021-11-30 15:00:43,085 iteration 3835 : loss : 0.027293, loss_ce: 0.009720
2021-11-30 15:00:44,613 iteration 3836 : loss : 0.021153, loss_ce: 0.008151
2021-11-30 15:00:46,152 iteration 3837 : loss : 0.021542, loss_ce: 0.007471
2021-11-30 15:00:47,737 iteration 3838 : loss : 0.021988, loss_ce: 0.007843
2021-11-30 15:00:49,248 iteration 3839 : loss : 0.024055, loss_ce: 0.012079
2021-11-30 15:00:50,770 iteration 3840 : loss : 0.026895, loss_ce: 0.006231
2021-11-30 15:00:52,263 iteration 3841 : loss : 0.021340, loss_ce: 0.007955
2021-11-30 15:00:53,805 iteration 3842 : loss : 0.026864, loss_ce: 0.013782
 56%|███████████████▎           | 226/400 [1:45:44<1:22:39, 28.51s/it]2021-11-30 15:00:55,344 iteration 3843 : loss : 0.018772, loss_ce: 0.007377
2021-11-30 15:00:56,901 iteration 3844 : loss : 0.026303, loss_ce: 0.007390
2021-11-30 15:00:58,439 iteration 3845 : loss : 0.018677, loss_ce: 0.008049
2021-11-30 15:00:59,917 iteration 3846 : loss : 0.016788, loss_ce: 0.006325
2021-11-30 15:01:01,448 iteration 3847 : loss : 0.023260, loss_ce: 0.008862
2021-11-30 15:01:03,005 iteration 3848 : loss : 0.021943, loss_ce: 0.010014
2021-11-30 15:01:04,616 iteration 3849 : loss : 0.028063, loss_ce: 0.013534
2021-11-30 15:01:06,218 iteration 3850 : loss : 0.039489, loss_ce: 0.010428
2021-11-30 15:01:07,740 iteration 3851 : loss : 0.021895, loss_ce: 0.008800
2021-11-30 15:01:09,272 iteration 3852 : loss : 0.023276, loss_ce: 0.006730
2021-11-30 15:01:10,747 iteration 3853 : loss : 0.018323, loss_ce: 0.005642
2021-11-30 15:01:12,293 iteration 3854 : loss : 0.022743, loss_ce: 0.006961
2021-11-30 15:01:13,935 iteration 3855 : loss : 0.023556, loss_ce: 0.008312
2021-11-30 15:01:15,336 iteration 3856 : loss : 0.020614, loss_ce: 0.009127
2021-11-30 15:01:16,850 iteration 3857 : loss : 0.025360, loss_ce: 0.010826
2021-11-30 15:01:18,287 iteration 3858 : loss : 0.021001, loss_ce: 0.008604
2021-11-30 15:01:19,810 iteration 3859 : loss : 0.028184, loss_ce: 0.010429
 57%|███████████████▎           | 227/400 [1:46:10<1:20:01, 27.75s/it]2021-11-30 15:01:21,367 iteration 3860 : loss : 0.018136, loss_ce: 0.006896
2021-11-30 15:01:22,945 iteration 3861 : loss : 0.030111, loss_ce: 0.012973
2021-11-30 15:01:24,475 iteration 3862 : loss : 0.030933, loss_ce: 0.011205
2021-11-30 15:01:26,002 iteration 3863 : loss : 0.028062, loss_ce: 0.010219
2021-11-30 15:01:27,547 iteration 3864 : loss : 0.040218, loss_ce: 0.013108
2021-11-30 15:01:29,057 iteration 3865 : loss : 0.025140, loss_ce: 0.007651
2021-11-30 15:01:30,685 iteration 3866 : loss : 0.025252, loss_ce: 0.008945
2021-11-30 15:01:32,175 iteration 3867 : loss : 0.031200, loss_ce: 0.010482
2021-11-30 15:01:33,730 iteration 3868 : loss : 0.036003, loss_ce: 0.012004
2021-11-30 15:01:35,275 iteration 3869 : loss : 0.027107, loss_ce: 0.014330
2021-11-30 15:01:36,851 iteration 3870 : loss : 0.022606, loss_ce: 0.009508
2021-11-30 15:01:38,387 iteration 3871 : loss : 0.036337, loss_ce: 0.010184
2021-11-30 15:01:39,866 iteration 3872 : loss : 0.025802, loss_ce: 0.008581
2021-11-30 15:01:41,353 iteration 3873 : loss : 0.020033, loss_ce: 0.009996
2021-11-30 15:01:42,897 iteration 3874 : loss : 0.025808, loss_ce: 0.009878
2021-11-30 15:01:44,439 iteration 3875 : loss : 0.028585, loss_ce: 0.011198
2021-11-30 15:01:45,981 iteration 3876 : loss : 0.031277, loss_ce: 0.010115
 57%|███████████████▍           | 228/400 [1:46:36<1:18:12, 27.28s/it]2021-11-30 15:01:47,526 iteration 3877 : loss : 0.025661, loss_ce: 0.009426
2021-11-30 15:01:49,084 iteration 3878 : loss : 0.024784, loss_ce: 0.009348
2021-11-30 15:01:50,581 iteration 3879 : loss : 0.023643, loss_ce: 0.009698
2021-11-30 15:01:52,130 iteration 3880 : loss : 0.019586, loss_ce: 0.008725
2021-11-30 15:01:53,622 iteration 3881 : loss : 0.025651, loss_ce: 0.011677
2021-11-30 15:01:55,245 iteration 3882 : loss : 0.044468, loss_ce: 0.008829
2021-11-30 15:01:56,822 iteration 3883 : loss : 0.048492, loss_ce: 0.014762
2021-11-30 15:01:58,368 iteration 3884 : loss : 0.034576, loss_ce: 0.013756
2021-11-30 15:01:59,918 iteration 3885 : loss : 0.072396, loss_ce: 0.015381
2021-11-30 15:02:01,483 iteration 3886 : loss : 0.032972, loss_ce: 0.012260
2021-11-30 15:02:02,949 iteration 3887 : loss : 0.023211, loss_ce: 0.008041
2021-11-30 15:02:04,498 iteration 3888 : loss : 0.030603, loss_ce: 0.013770
2021-11-30 15:02:06,021 iteration 3889 : loss : 0.023281, loss_ce: 0.007592
2021-11-30 15:02:07,651 iteration 3890 : loss : 0.065533, loss_ce: 0.014324
2021-11-30 15:02:09,142 iteration 3891 : loss : 0.044612, loss_ce: 0.015747
2021-11-30 15:02:10,668 iteration 3892 : loss : 0.028209, loss_ce: 0.011876
2021-11-30 15:02:12,224 iteration 3893 : loss : 0.038957, loss_ce: 0.013695
 57%|███████████████▍           | 229/400 [1:47:02<1:16:51, 26.97s/it]2021-11-30 15:02:13,783 iteration 3894 : loss : 0.022617, loss_ce: 0.006545
2021-11-30 15:02:15,257 iteration 3895 : loss : 0.023969, loss_ce: 0.008332
2021-11-30 15:02:16,779 iteration 3896 : loss : 0.030559, loss_ce: 0.011759
2021-11-30 15:02:18,330 iteration 3897 : loss : 0.027824, loss_ce: 0.011471
2021-11-30 15:02:19,887 iteration 3898 : loss : 0.038037, loss_ce: 0.010806
2021-11-30 15:02:21,349 iteration 3899 : loss : 0.033031, loss_ce: 0.010846
2021-11-30 15:02:22,838 iteration 3900 : loss : 0.036251, loss_ce: 0.011143
2021-11-30 15:02:24,319 iteration 3901 : loss : 0.030674, loss_ce: 0.012936
2021-11-30 15:02:25,821 iteration 3902 : loss : 0.025582, loss_ce: 0.008713
2021-11-30 15:02:27,280 iteration 3903 : loss : 0.027011, loss_ce: 0.007551
2021-11-30 15:02:28,784 iteration 3904 : loss : 0.031500, loss_ce: 0.009229
2021-11-30 15:02:30,297 iteration 3905 : loss : 0.023217, loss_ce: 0.007045
2021-11-30 15:02:31,747 iteration 3906 : loss : 0.021784, loss_ce: 0.008184
2021-11-30 15:02:33,198 iteration 3907 : loss : 0.020563, loss_ce: 0.007485
2021-11-30 15:02:34,656 iteration 3908 : loss : 0.022747, loss_ce: 0.008069
2021-11-30 15:02:36,162 iteration 3909 : loss : 0.037872, loss_ce: 0.018694
2021-11-30 15:02:36,163 Training Data Eval:
2021-11-30 15:02:43,765   Average segmentation loss on training set: 0.0165
2021-11-30 15:02:43,765 Validation Data Eval:
2021-11-30 15:02:46,387   Average segmentation loss on validation set: 0.0789
2021-11-30 15:02:47,988 iteration 3910 : loss : 0.026148, loss_ce: 0.008433
 57%|███████████████▌           | 230/400 [1:47:38<1:23:53, 29.61s/it]2021-11-30 15:02:49,500 iteration 3911 : loss : 0.019109, loss_ce: 0.007488
2021-11-30 15:02:51,052 iteration 3912 : loss : 0.021307, loss_ce: 0.007622
2021-11-30 15:02:52,554 iteration 3913 : loss : 0.018551, loss_ce: 0.007386
2021-11-30 15:02:54,064 iteration 3914 : loss : 0.020783, loss_ce: 0.009735
2021-11-30 15:02:55,568 iteration 3915 : loss : 0.025964, loss_ce: 0.010918
2021-11-30 15:02:57,039 iteration 3916 : loss : 0.022212, loss_ce: 0.007715
2021-11-30 15:02:58,598 iteration 3917 : loss : 0.028779, loss_ce: 0.009191
2021-11-30 15:03:00,155 iteration 3918 : loss : 0.048209, loss_ce: 0.011817
2021-11-30 15:03:01,779 iteration 3919 : loss : 0.037314, loss_ce: 0.010425
2021-11-30 15:03:03,264 iteration 3920 : loss : 0.023526, loss_ce: 0.008816
2021-11-30 15:03:04,782 iteration 3921 : loss : 0.021065, loss_ce: 0.007739
2021-11-30 15:03:06,351 iteration 3922 : loss : 0.037434, loss_ce: 0.013646
2021-11-30 15:03:07,860 iteration 3923 : loss : 0.031748, loss_ce: 0.013814
2021-11-30 15:03:09,329 iteration 3924 : loss : 0.036895, loss_ce: 0.008726
2021-11-30 15:03:10,914 iteration 3925 : loss : 0.038820, loss_ce: 0.013754
2021-11-30 15:03:12,489 iteration 3926 : loss : 0.020553, loss_ce: 0.008156
2021-11-30 15:03:13,996 iteration 3927 : loss : 0.026722, loss_ce: 0.010223
 58%|███████████████▌           | 231/400 [1:48:04<1:20:21, 28.53s/it]2021-11-30 15:03:15,593 iteration 3928 : loss : 0.030473, loss_ce: 0.011977
2021-11-30 15:03:17,105 iteration 3929 : loss : 0.023714, loss_ce: 0.010869
2021-11-30 15:03:18,680 iteration 3930 : loss : 0.035549, loss_ce: 0.017836
2021-11-30 15:03:20,223 iteration 3931 : loss : 0.023430, loss_ce: 0.010338
2021-11-30 15:03:21,777 iteration 3932 : loss : 0.034938, loss_ce: 0.010659
2021-11-30 15:03:23,361 iteration 3933 : loss : 0.022092, loss_ce: 0.008746
2021-11-30 15:03:24,903 iteration 3934 : loss : 0.020310, loss_ce: 0.007655
2021-11-30 15:03:26,353 iteration 3935 : loss : 0.018409, loss_ce: 0.007674
2021-11-30 15:03:27,995 iteration 3936 : loss : 0.027823, loss_ce: 0.012473
2021-11-30 15:03:29,471 iteration 3937 : loss : 0.026133, loss_ce: 0.011454
2021-11-30 15:03:31,030 iteration 3938 : loss : 0.074702, loss_ce: 0.012924
2021-11-30 15:03:32,475 iteration 3939 : loss : 0.030999, loss_ce: 0.008945
2021-11-30 15:03:33,977 iteration 3940 : loss : 0.029298, loss_ce: 0.009999
2021-11-30 15:03:35,498 iteration 3941 : loss : 0.026817, loss_ce: 0.011201
2021-11-30 15:03:37,075 iteration 3942 : loss : 0.063089, loss_ce: 0.029773
2021-11-30 15:03:38,553 iteration 3943 : loss : 0.023491, loss_ce: 0.005946
2021-11-30 15:03:40,123 iteration 3944 : loss : 0.041825, loss_ce: 0.016092
 58%|███████████████▋           | 232/400 [1:48:30<1:17:51, 27.81s/it]2021-11-30 15:03:41,694 iteration 3945 : loss : 0.026517, loss_ce: 0.010670
2021-11-30 15:03:43,131 iteration 3946 : loss : 0.021118, loss_ce: 0.010362
2021-11-30 15:03:44,650 iteration 3947 : loss : 0.020391, loss_ce: 0.006587
2021-11-30 15:03:46,286 iteration 3948 : loss : 0.035318, loss_ce: 0.011401
2021-11-30 15:03:47,835 iteration 3949 : loss : 0.038877, loss_ce: 0.015291
2021-11-30 15:03:49,419 iteration 3950 : loss : 0.026035, loss_ce: 0.008071
2021-11-30 15:03:50,872 iteration 3951 : loss : 0.020511, loss_ce: 0.009111
2021-11-30 15:03:52,428 iteration 3952 : loss : 0.023283, loss_ce: 0.007895
2021-11-30 15:03:54,018 iteration 3953 : loss : 0.035667, loss_ce: 0.011715
2021-11-30 15:03:55,517 iteration 3954 : loss : 0.020439, loss_ce: 0.006692
2021-11-30 15:03:57,024 iteration 3955 : loss : 0.017919, loss_ce: 0.006584
2021-11-30 15:03:58,650 iteration 3956 : loss : 0.030395, loss_ce: 0.013349
2021-11-30 15:04:00,134 iteration 3957 : loss : 0.023764, loss_ce: 0.008842
2021-11-30 15:04:01,629 iteration 3958 : loss : 0.019377, loss_ce: 0.007492
2021-11-30 15:04:03,231 iteration 3959 : loss : 0.025809, loss_ce: 0.007071
2021-11-30 15:04:04,734 iteration 3960 : loss : 0.023735, loss_ce: 0.010536
2021-11-30 15:04:06,256 iteration 3961 : loss : 0.028756, loss_ce: 0.013360
 58%|███████████████▋           | 233/400 [1:48:56<1:15:59, 27.30s/it]2021-11-30 15:04:07,839 iteration 3962 : loss : 0.026727, loss_ce: 0.009294
2021-11-30 15:04:09,354 iteration 3963 : loss : 0.026412, loss_ce: 0.010197
2021-11-30 15:04:10,955 iteration 3964 : loss : 0.028773, loss_ce: 0.012881
2021-11-30 15:04:12,435 iteration 3965 : loss : 0.021567, loss_ce: 0.005900
2021-11-30 15:04:13,994 iteration 3966 : loss : 0.030410, loss_ce: 0.010366
2021-11-30 15:04:15,523 iteration 3967 : loss : 0.025491, loss_ce: 0.008819
2021-11-30 15:04:16,954 iteration 3968 : loss : 0.022723, loss_ce: 0.008694
2021-11-30 15:04:18,510 iteration 3969 : loss : 0.023735, loss_ce: 0.006750
2021-11-30 15:04:20,014 iteration 3970 : loss : 0.041211, loss_ce: 0.016023
2021-11-30 15:04:21,446 iteration 3971 : loss : 0.019151, loss_ce: 0.007434
2021-11-30 15:04:23,001 iteration 3972 : loss : 0.022495, loss_ce: 0.006171
2021-11-30 15:04:24,467 iteration 3973 : loss : 0.025412, loss_ce: 0.012947
2021-11-30 15:04:25,916 iteration 3974 : loss : 0.018296, loss_ce: 0.005631
2021-11-30 15:04:27,459 iteration 3975 : loss : 0.026512, loss_ce: 0.011346
2021-11-30 15:04:29,040 iteration 3976 : loss : 0.027943, loss_ce: 0.011451
2021-11-30 15:04:30,608 iteration 3977 : loss : 0.021774, loss_ce: 0.009150
2021-11-30 15:04:32,200 iteration 3978 : loss : 0.029244, loss_ce: 0.011066
 58%|███████████████▊           | 234/400 [1:49:22<1:14:25, 26.90s/it]2021-11-30 15:04:33,761 iteration 3979 : loss : 0.021933, loss_ce: 0.007408
2021-11-30 15:04:35,311 iteration 3980 : loss : 0.025095, loss_ce: 0.007962
2021-11-30 15:04:36,809 iteration 3981 : loss : 0.028353, loss_ce: 0.012837
2021-11-30 15:04:38,224 iteration 3982 : loss : 0.019314, loss_ce: 0.007565
2021-11-30 15:04:39,667 iteration 3983 : loss : 0.020312, loss_ce: 0.009399
2021-11-30 15:04:41,157 iteration 3984 : loss : 0.019466, loss_ce: 0.007915
2021-11-30 15:04:42,692 iteration 3985 : loss : 0.032119, loss_ce: 0.017640
2021-11-30 15:04:44,309 iteration 3986 : loss : 0.033235, loss_ce: 0.015343
2021-11-30 15:04:45,842 iteration 3987 : loss : 0.028926, loss_ce: 0.012273
2021-11-30 15:04:47,356 iteration 3988 : loss : 0.020251, loss_ce: 0.009163
2021-11-30 15:04:48,840 iteration 3989 : loss : 0.027160, loss_ce: 0.006470
2021-11-30 15:04:50,335 iteration 3990 : loss : 0.031814, loss_ce: 0.009239
2021-11-30 15:04:51,908 iteration 3991 : loss : 0.037059, loss_ce: 0.007878
2021-11-30 15:04:53,445 iteration 3992 : loss : 0.034789, loss_ce: 0.011684
2021-11-30 15:04:55,013 iteration 3993 : loss : 0.021336, loss_ce: 0.008086
2021-11-30 15:04:56,531 iteration 3994 : loss : 0.018551, loss_ce: 0.008554
2021-11-30 15:04:56,531 Training Data Eval:
2021-11-30 15:05:04,126   Average segmentation loss on training set: 0.0154
2021-11-30 15:05:04,127 Validation Data Eval:
2021-11-30 15:05:06,755   Average segmentation loss on validation set: 0.0800
2021-11-30 15:05:08,232 iteration 3995 : loss : 0.018897, loss_ce: 0.007468
 59%|███████████████▊           | 235/400 [1:49:58<1:21:30, 29.64s/it]2021-11-30 15:05:09,848 iteration 3996 : loss : 0.020208, loss_ce: 0.006379
2021-11-30 15:05:11,318 iteration 3997 : loss : 0.030711, loss_ce: 0.009040
2021-11-30 15:05:12,844 iteration 3998 : loss : 0.021211, loss_ce: 0.009808
2021-11-30 15:05:14,354 iteration 3999 : loss : 0.024017, loss_ce: 0.005932
2021-11-30 15:05:15,922 iteration 4000 : loss : 0.020448, loss_ce: 0.010078
2021-11-30 15:05:17,391 iteration 4001 : loss : 0.019573, loss_ce: 0.006815
2021-11-30 15:05:18,914 iteration 4002 : loss : 0.022670, loss_ce: 0.008353
2021-11-30 15:05:20,439 iteration 4003 : loss : 0.021955, loss_ce: 0.009551
2021-11-30 15:05:21,987 iteration 4004 : loss : 0.040024, loss_ce: 0.010186
2021-11-30 15:05:23,519 iteration 4005 : loss : 0.024317, loss_ce: 0.011537
2021-11-30 15:05:24,983 iteration 4006 : loss : 0.020254, loss_ce: 0.008608
2021-11-30 15:05:26,545 iteration 4007 : loss : 0.026733, loss_ce: 0.007660
2021-11-30 15:05:28,023 iteration 4008 : loss : 0.018230, loss_ce: 0.006259
2021-11-30 15:05:29,556 iteration 4009 : loss : 0.021004, loss_ce: 0.008873
2021-11-30 15:05:31,125 iteration 4010 : loss : 0.029425, loss_ce: 0.011869
2021-11-30 15:05:32,591 iteration 4011 : loss : 0.020843, loss_ce: 0.005899
2021-11-30 15:05:34,172 iteration 4012 : loss : 0.021709, loss_ce: 0.009160
 59%|███████████████▉           | 236/400 [1:50:24<1:17:58, 28.53s/it]2021-11-30 15:05:35,815 iteration 4013 : loss : 0.045639, loss_ce: 0.015598
2021-11-30 15:05:37,277 iteration 4014 : loss : 0.020284, loss_ce: 0.006392
2021-11-30 15:05:38,848 iteration 4015 : loss : 0.028814, loss_ce: 0.011101
2021-11-30 15:05:40,421 iteration 4016 : loss : 0.021440, loss_ce: 0.008032
2021-11-30 15:05:41,984 iteration 4017 : loss : 0.025098, loss_ce: 0.008907
2021-11-30 15:05:43,465 iteration 4018 : loss : 0.021627, loss_ce: 0.007231
2021-11-30 15:05:44,974 iteration 4019 : loss : 0.024631, loss_ce: 0.013084
2021-11-30 15:05:46,448 iteration 4020 : loss : 0.021891, loss_ce: 0.011922
2021-11-30 15:05:47,962 iteration 4021 : loss : 0.022465, loss_ce: 0.010049
2021-11-30 15:05:49,504 iteration 4022 : loss : 0.023807, loss_ce: 0.012062
2021-11-30 15:05:51,031 iteration 4023 : loss : 0.020169, loss_ce: 0.006530
2021-11-30 15:05:52,489 iteration 4024 : loss : 0.021948, loss_ce: 0.006799
2021-11-30 15:05:53,966 iteration 4025 : loss : 0.018391, loss_ce: 0.006411
2021-11-30 15:05:55,499 iteration 4026 : loss : 0.020714, loss_ce: 0.008239
2021-11-30 15:05:57,031 iteration 4027 : loss : 0.025807, loss_ce: 0.008810
2021-11-30 15:05:58,603 iteration 4028 : loss : 0.028213, loss_ce: 0.010341
2021-11-30 15:06:00,092 iteration 4029 : loss : 0.018157, loss_ce: 0.007141
 59%|███████████████▉           | 237/400 [1:50:50<1:15:22, 27.75s/it]2021-11-30 15:06:01,707 iteration 4030 : loss : 0.029446, loss_ce: 0.012696
2021-11-30 15:06:03,241 iteration 4031 : loss : 0.033623, loss_ce: 0.011339
2021-11-30 15:06:04,749 iteration 4032 : loss : 0.025891, loss_ce: 0.010701
2021-11-30 15:06:06,257 iteration 4033 : loss : 0.025177, loss_ce: 0.008315
2021-11-30 15:06:07,698 iteration 4034 : loss : 0.021603, loss_ce: 0.006871
2021-11-30 15:06:09,197 iteration 4035 : loss : 0.019258, loss_ce: 0.005862
2021-11-30 15:06:10,758 iteration 4036 : loss : 0.034113, loss_ce: 0.009510
2021-11-30 15:06:12,229 iteration 4037 : loss : 0.016404, loss_ce: 0.007540
2021-11-30 15:06:13,817 iteration 4038 : loss : 0.039692, loss_ce: 0.013620
2021-11-30 15:06:15,424 iteration 4039 : loss : 0.029880, loss_ce: 0.011481
2021-11-30 15:06:17,013 iteration 4040 : loss : 0.027831, loss_ce: 0.011495
2021-11-30 15:06:18,599 iteration 4041 : loss : 0.027076, loss_ce: 0.008469
2021-11-30 15:06:20,081 iteration 4042 : loss : 0.020473, loss_ce: 0.007312
2021-11-30 15:06:21,611 iteration 4043 : loss : 0.177199, loss_ce: 0.006464
2021-11-30 15:06:23,101 iteration 4044 : loss : 0.023217, loss_ce: 0.009126
2021-11-30 15:06:24,625 iteration 4045 : loss : 0.025301, loss_ce: 0.011500
2021-11-30 15:06:26,191 iteration 4046 : loss : 0.023801, loss_ce: 0.010248
 60%|████████████████           | 238/400 [1:51:16<1:13:34, 27.25s/it]2021-11-30 15:06:27,838 iteration 4047 : loss : 0.026566, loss_ce: 0.013180
2021-11-30 15:06:29,391 iteration 4048 : loss : 0.023517, loss_ce: 0.009054
2021-11-30 15:06:30,866 iteration 4049 : loss : 0.021168, loss_ce: 0.007699
2021-11-30 15:06:32,410 iteration 4050 : loss : 0.031146, loss_ce: 0.013023
2021-11-30 15:06:34,017 iteration 4051 : loss : 0.063503, loss_ce: 0.009686
2021-11-30 15:06:35,484 iteration 4052 : loss : 0.025207, loss_ce: 0.008704
2021-11-30 15:06:36,929 iteration 4053 : loss : 0.022164, loss_ce: 0.006951
2021-11-30 15:06:38,401 iteration 4054 : loss : 0.027429, loss_ce: 0.007645
2021-11-30 15:06:39,885 iteration 4055 : loss : 0.021651, loss_ce: 0.009373
2021-11-30 15:06:41,410 iteration 4056 : loss : 0.030388, loss_ce: 0.015441
2021-11-30 15:06:42,897 iteration 4057 : loss : 0.017878, loss_ce: 0.005071
2021-11-30 15:06:44,403 iteration 4058 : loss : 0.019217, loss_ce: 0.006538
2021-11-30 15:06:46,019 iteration 4059 : loss : 0.051183, loss_ce: 0.026228
2021-11-30 15:06:47,541 iteration 4060 : loss : 0.023804, loss_ce: 0.009784
2021-11-30 15:06:49,066 iteration 4061 : loss : 0.036857, loss_ce: 0.019371
2021-11-30 15:06:50,624 iteration 4062 : loss : 0.036602, loss_ce: 0.014336
2021-11-30 15:06:52,153 iteration 4063 : loss : 0.038644, loss_ce: 0.011432
 60%|████████████████▏          | 239/400 [1:51:42<1:12:04, 26.86s/it]2021-11-30 15:06:53,698 iteration 4064 : loss : 0.033422, loss_ce: 0.008055
2021-11-30 15:06:55,176 iteration 4065 : loss : 0.018622, loss_ce: 0.006207
2021-11-30 15:06:56,752 iteration 4066 : loss : 0.037933, loss_ce: 0.013030
2021-11-30 15:06:58,241 iteration 4067 : loss : 0.020580, loss_ce: 0.008454
2021-11-30 15:06:59,748 iteration 4068 : loss : 0.026433, loss_ce: 0.011159
2021-11-30 15:07:01,296 iteration 4069 : loss : 0.021335, loss_ce: 0.009162
2021-11-30 15:07:02,827 iteration 4070 : loss : 0.033214, loss_ce: 0.011455
2021-11-30 15:07:04,424 iteration 4071 : loss : 0.023714, loss_ce: 0.007524
2021-11-30 15:07:05,935 iteration 4072 : loss : 0.021861, loss_ce: 0.006700
2021-11-30 15:07:07,421 iteration 4073 : loss : 0.021105, loss_ce: 0.007002
2021-11-30 15:07:08,939 iteration 4074 : loss : 0.025216, loss_ce: 0.011119
2021-11-30 15:07:10,524 iteration 4075 : loss : 0.019969, loss_ce: 0.006417
2021-11-30 15:07:12,006 iteration 4076 : loss : 0.034384, loss_ce: 0.013657
2021-11-30 15:07:13,524 iteration 4077 : loss : 0.018156, loss_ce: 0.006192
2021-11-30 15:07:15,107 iteration 4078 : loss : 0.026385, loss_ce: 0.010449
2021-11-30 15:07:16,670 iteration 4079 : loss : 0.028975, loss_ce: 0.011621
2021-11-30 15:07:16,670 Training Data Eval:
2021-11-30 15:07:24,278   Average segmentation loss on training set: 0.0160
2021-11-30 15:07:24,279 Validation Data Eval:
2021-11-30 15:07:26,911   Average segmentation loss on validation set: 0.0770
2021-11-30 15:07:28,504 iteration 4080 : loss : 0.024238, loss_ce: 0.010860
 60%|████████████████▏          | 240/400 [1:52:19<1:19:14, 29.71s/it]2021-11-30 15:07:30,119 iteration 4081 : loss : 0.039724, loss_ce: 0.016617
2021-11-30 15:07:31,661 iteration 4082 : loss : 0.020522, loss_ce: 0.007563
2021-11-30 15:07:33,148 iteration 4083 : loss : 0.021124, loss_ce: 0.008090
2021-11-30 15:07:34,691 iteration 4084 : loss : 0.021870, loss_ce: 0.007004
2021-11-30 15:07:36,174 iteration 4085 : loss : 0.028892, loss_ce: 0.008022
2021-11-30 15:07:37,820 iteration 4086 : loss : 0.035345, loss_ce: 0.013501
2021-11-30 15:07:39,370 iteration 4087 : loss : 0.041716, loss_ce: 0.008015
2021-11-30 15:07:40,841 iteration 4088 : loss : 0.020569, loss_ce: 0.009345
2021-11-30 15:07:42,362 iteration 4089 : loss : 0.031416, loss_ce: 0.010967
2021-11-30 15:07:43,805 iteration 4090 : loss : 0.024526, loss_ce: 0.007588
2021-11-30 15:07:45,329 iteration 4091 : loss : 0.027291, loss_ce: 0.010564
2021-11-30 15:07:46,860 iteration 4092 : loss : 0.023531, loss_ce: 0.008156
2021-11-30 15:07:48,397 iteration 4093 : loss : 0.034665, loss_ce: 0.012265
2021-11-30 15:07:49,895 iteration 4094 : loss : 0.026035, loss_ce: 0.009958
2021-11-30 15:07:51,440 iteration 4095 : loss : 0.027535, loss_ce: 0.013005
2021-11-30 15:07:52,944 iteration 4096 : loss : 0.024448, loss_ce: 0.015840
2021-11-30 15:07:54,447 iteration 4097 : loss : 0.023244, loss_ce: 0.007359
 60%|████████████████▎          | 241/400 [1:52:44<1:15:44, 28.58s/it]2021-11-30 15:07:55,986 iteration 4098 : loss : 0.020428, loss_ce: 0.007363
2021-11-30 15:07:57,470 iteration 4099 : loss : 0.030266, loss_ce: 0.007175
2021-11-30 15:07:59,005 iteration 4100 : loss : 0.024302, loss_ce: 0.008252
2021-11-30 15:08:00,580 iteration 4101 : loss : 0.026274, loss_ce: 0.008559
2021-11-30 15:08:02,150 iteration 4102 : loss : 0.030709, loss_ce: 0.013103
2021-11-30 15:08:03,694 iteration 4103 : loss : 0.030218, loss_ce: 0.012980
2021-11-30 15:08:05,221 iteration 4104 : loss : 0.037708, loss_ce: 0.014850
2021-11-30 15:08:06,767 iteration 4105 : loss : 0.020263, loss_ce: 0.009407
2021-11-30 15:08:08,279 iteration 4106 : loss : 0.022519, loss_ce: 0.009280
2021-11-30 15:08:09,790 iteration 4107 : loss : 0.016348, loss_ce: 0.005791
2021-11-30 15:08:11,319 iteration 4108 : loss : 0.018741, loss_ce: 0.007461
2021-11-30 15:08:12,785 iteration 4109 : loss : 0.018760, loss_ce: 0.006668
2021-11-30 15:08:14,337 iteration 4110 : loss : 0.026925, loss_ce: 0.009866
2021-11-30 15:08:16,011 iteration 4111 : loss : 0.037429, loss_ce: 0.019440
2021-11-30 15:08:17,499 iteration 4112 : loss : 0.023372, loss_ce: 0.007961
2021-11-30 15:08:19,065 iteration 4113 : loss : 0.029040, loss_ce: 0.008926
2021-11-30 15:08:20,584 iteration 4114 : loss : 0.024379, loss_ce: 0.010815
 60%|████████████████▎          | 242/400 [1:53:11<1:13:19, 27.85s/it]2021-11-30 15:08:22,107 iteration 4115 : loss : 0.022539, loss_ce: 0.011282
2021-11-30 15:08:23,671 iteration 4116 : loss : 0.020301, loss_ce: 0.006828
2021-11-30 15:08:25,128 iteration 4117 : loss : 0.018092, loss_ce: 0.005922
2021-11-30 15:08:26,724 iteration 4118 : loss : 0.025661, loss_ce: 0.012184
2021-11-30 15:08:28,353 iteration 4119 : loss : 0.032958, loss_ce: 0.010208
2021-11-30 15:08:29,891 iteration 4120 : loss : 0.029652, loss_ce: 0.007385
2021-11-30 15:08:31,382 iteration 4121 : loss : 0.020126, loss_ce: 0.006385
2021-11-30 15:08:32,890 iteration 4122 : loss : 0.020096, loss_ce: 0.006428
2021-11-30 15:08:34,356 iteration 4123 : loss : 0.014484, loss_ce: 0.006021
2021-11-30 15:08:35,929 iteration 4124 : loss : 0.025024, loss_ce: 0.011617
2021-11-30 15:08:37,462 iteration 4125 : loss : 0.037351, loss_ce: 0.014307
2021-11-30 15:08:38,992 iteration 4126 : loss : 0.023478, loss_ce: 0.008768
2021-11-30 15:08:40,472 iteration 4127 : loss : 0.015694, loss_ce: 0.007452
2021-11-30 15:08:42,086 iteration 4128 : loss : 0.040983, loss_ce: 0.011480
2021-11-30 15:08:43,537 iteration 4129 : loss : 0.031864, loss_ce: 0.007116
2021-11-30 15:08:45,002 iteration 4130 : loss : 0.022603, loss_ce: 0.007009
2021-11-30 15:08:46,514 iteration 4131 : loss : 0.019145, loss_ce: 0.008313
 61%|████████████████▍          | 243/400 [1:53:37<1:11:21, 27.27s/it]2021-11-30 15:08:48,115 iteration 4132 : loss : 0.034529, loss_ce: 0.011437
2021-11-30 15:08:49,645 iteration 4133 : loss : 0.022204, loss_ce: 0.006724
2021-11-30 15:08:51,186 iteration 4134 : loss : 0.032330, loss_ce: 0.012158
2021-11-30 15:08:52,632 iteration 4135 : loss : 0.024034, loss_ce: 0.010588
2021-11-30 15:08:54,149 iteration 4136 : loss : 0.025908, loss_ce: 0.011908
2021-11-30 15:08:55,608 iteration 4137 : loss : 0.019015, loss_ce: 0.006657
2021-11-30 15:08:57,150 iteration 4138 : loss : 0.020322, loss_ce: 0.008496
2021-11-30 15:08:58,701 iteration 4139 : loss : 0.020620, loss_ce: 0.008298
2021-11-30 15:09:00,229 iteration 4140 : loss : 0.029825, loss_ce: 0.012158
2021-11-30 15:09:01,752 iteration 4141 : loss : 0.022705, loss_ce: 0.008067
2021-11-30 15:09:03,332 iteration 4142 : loss : 0.028594, loss_ce: 0.010153
2021-11-30 15:09:04,761 iteration 4143 : loss : 0.029326, loss_ce: 0.008768
2021-11-30 15:09:06,230 iteration 4144 : loss : 0.022307, loss_ce: 0.005335
2021-11-30 15:09:07,801 iteration 4145 : loss : 0.018704, loss_ce: 0.007973
2021-11-30 15:09:09,310 iteration 4146 : loss : 0.019308, loss_ce: 0.008772
2021-11-30 15:09:10,844 iteration 4147 : loss : 0.021619, loss_ce: 0.007709
2021-11-30 15:09:12,348 iteration 4148 : loss : 0.026835, loss_ce: 0.009315
 61%|████████████████▍          | 244/400 [1:54:02<1:09:47, 26.84s/it]2021-11-30 15:09:13,838 iteration 4149 : loss : 0.022216, loss_ce: 0.008796
2021-11-30 15:09:15,372 iteration 4150 : loss : 0.020519, loss_ce: 0.006415
2021-11-30 15:09:16,928 iteration 4151 : loss : 0.031258, loss_ce: 0.008880
2021-11-30 15:09:18,457 iteration 4152 : loss : 0.021697, loss_ce: 0.007848
2021-11-30 15:09:19,910 iteration 4153 : loss : 0.020414, loss_ce: 0.006912
2021-11-30 15:09:21,440 iteration 4154 : loss : 0.021401, loss_ce: 0.007416
2021-11-30 15:09:22,954 iteration 4155 : loss : 0.025268, loss_ce: 0.007426
2021-11-30 15:09:24,428 iteration 4156 : loss : 0.017777, loss_ce: 0.005828
2021-11-30 15:09:25,993 iteration 4157 : loss : 0.039583, loss_ce: 0.022717
2021-11-30 15:09:27,486 iteration 4158 : loss : 0.019552, loss_ce: 0.007119
2021-11-30 15:09:28,986 iteration 4159 : loss : 0.024813, loss_ce: 0.011251
2021-11-30 15:09:30,605 iteration 4160 : loss : 0.034736, loss_ce: 0.012259
2021-11-30 15:09:32,178 iteration 4161 : loss : 0.033870, loss_ce: 0.013261
2021-11-30 15:09:33,752 iteration 4162 : loss : 0.028111, loss_ce: 0.009880
2021-11-30 15:09:35,318 iteration 4163 : loss : 0.033326, loss_ce: 0.017213
2021-11-30 15:09:36,860 iteration 4164 : loss : 0.022547, loss_ce: 0.007998
2021-11-30 15:09:36,860 Training Data Eval:
2021-11-30 15:09:44,426   Average segmentation loss on training set: 0.0168
2021-11-30 15:09:44,427 Validation Data Eval:
2021-11-30 15:09:47,046   Average segmentation loss on validation set: 0.0835
2021-11-30 15:09:48,605 iteration 4165 : loss : 0.031228, loss_ce: 0.009916
 61%|████████████████▌          | 245/400 [1:54:39<1:16:37, 29.66s/it]2021-11-30 15:09:50,153 iteration 4166 : loss : 0.018490, loss_ce: 0.007178
2021-11-30 15:09:51,614 iteration 4167 : loss : 0.021320, loss_ce: 0.007212
2021-11-30 15:09:53,101 iteration 4168 : loss : 0.015829, loss_ce: 0.006556
2021-11-30 15:09:54,582 iteration 4169 : loss : 0.020032, loss_ce: 0.010168
2021-11-30 15:09:56,196 iteration 4170 : loss : 0.023419, loss_ce: 0.009807
2021-11-30 15:09:57,667 iteration 4171 : loss : 0.020046, loss_ce: 0.005976
2021-11-30 15:09:59,172 iteration 4172 : loss : 0.019934, loss_ce: 0.009221
2021-11-30 15:10:00,735 iteration 4173 : loss : 0.025948, loss_ce: 0.007045
2021-11-30 15:10:02,229 iteration 4174 : loss : 0.020514, loss_ce: 0.005711
2021-11-30 15:10:03,718 iteration 4175 : loss : 0.018340, loss_ce: 0.006970
2021-11-30 15:10:05,229 iteration 4176 : loss : 0.024263, loss_ce: 0.010820
2021-11-30 15:10:06,784 iteration 4177 : loss : 0.017609, loss_ce: 0.004927
2021-11-30 15:10:08,266 iteration 4178 : loss : 0.024842, loss_ce: 0.009278
2021-11-30 15:10:09,769 iteration 4179 : loss : 0.022479, loss_ce: 0.009383
2021-11-30 15:10:11,274 iteration 4180 : loss : 0.017704, loss_ce: 0.005644
2021-11-30 15:10:12,787 iteration 4181 : loss : 0.020170, loss_ce: 0.008618
2021-11-30 15:10:14,295 iteration 4182 : loss : 0.020665, loss_ce: 0.005481
 62%|████████████████▌          | 246/400 [1:55:04<1:13:04, 28.47s/it]2021-11-30 15:10:15,860 iteration 4183 : loss : 0.020285, loss_ce: 0.006353
2021-11-30 15:10:17,411 iteration 4184 : loss : 0.021162, loss_ce: 0.008873
2021-11-30 15:10:18,926 iteration 4185 : loss : 0.019925, loss_ce: 0.008257
2021-11-30 15:10:20,416 iteration 4186 : loss : 0.017777, loss_ce: 0.004962
2021-11-30 15:10:21,971 iteration 4187 : loss : 0.030688, loss_ce: 0.009935
2021-11-30 15:10:23,454 iteration 4188 : loss : 0.025492, loss_ce: 0.008041
2021-11-30 15:10:25,050 iteration 4189 : loss : 0.026358, loss_ce: 0.011998
2021-11-30 15:10:26,609 iteration 4190 : loss : 0.028600, loss_ce: 0.012502
2021-11-30 15:10:28,182 iteration 4191 : loss : 0.024756, loss_ce: 0.010469
2021-11-30 15:10:29,613 iteration 4192 : loss : 0.014640, loss_ce: 0.004453
2021-11-30 15:10:31,143 iteration 4193 : loss : 0.023430, loss_ce: 0.012292
2021-11-30 15:10:32,700 iteration 4194 : loss : 0.019776, loss_ce: 0.006844
2021-11-30 15:10:34,204 iteration 4195 : loss : 0.025902, loss_ce: 0.008472
2021-11-30 15:10:35,770 iteration 4196 : loss : 0.016740, loss_ce: 0.007335
2021-11-30 15:10:37,258 iteration 4197 : loss : 0.022036, loss_ce: 0.006249
2021-11-30 15:10:38,780 iteration 4198 : loss : 0.020201, loss_ce: 0.007388
2021-11-30 15:10:40,253 iteration 4199 : loss : 0.018326, loss_ce: 0.007419
 62%|████████████████▋          | 247/400 [1:55:30<1:10:41, 27.72s/it]2021-11-30 15:10:41,826 iteration 4200 : loss : 0.018106, loss_ce: 0.006245
2021-11-30 15:10:43,362 iteration 4201 : loss : 0.019221, loss_ce: 0.008041
2021-11-30 15:10:44,910 iteration 4202 : loss : 0.021796, loss_ce: 0.008931
2021-11-30 15:10:46,518 iteration 4203 : loss : 0.026869, loss_ce: 0.011797
2021-11-30 15:10:48,031 iteration 4204 : loss : 0.022498, loss_ce: 0.009416
2021-11-30 15:10:49,529 iteration 4205 : loss : 0.021524, loss_ce: 0.008906
2021-11-30 15:10:51,152 iteration 4206 : loss : 0.030979, loss_ce: 0.010487
2021-11-30 15:10:52,700 iteration 4207 : loss : 0.027413, loss_ce: 0.011231
2021-11-30 15:10:54,144 iteration 4208 : loss : 0.013997, loss_ce: 0.005259
2021-11-30 15:10:55,622 iteration 4209 : loss : 0.018890, loss_ce: 0.008204
2021-11-30 15:10:57,100 iteration 4210 : loss : 0.018810, loss_ce: 0.007753
2021-11-30 15:10:58,632 iteration 4211 : loss : 0.021115, loss_ce: 0.008295
2021-11-30 15:11:00,205 iteration 4212 : loss : 0.018124, loss_ce: 0.006540
2021-11-30 15:11:01,682 iteration 4213 : loss : 0.022943, loss_ce: 0.006173
2021-11-30 15:11:03,238 iteration 4214 : loss : 0.024672, loss_ce: 0.008293
2021-11-30 15:11:04,754 iteration 4215 : loss : 0.021829, loss_ce: 0.007513
2021-11-30 15:11:06,271 iteration 4216 : loss : 0.019397, loss_ce: 0.005824
 62%|████████████████▋          | 248/400 [1:55:56<1:08:55, 27.21s/it]2021-11-30 15:11:07,861 iteration 4217 : loss : 0.022295, loss_ce: 0.008136
2021-11-30 15:11:09,356 iteration 4218 : loss : 0.021596, loss_ce: 0.007114
2021-11-30 15:11:10,835 iteration 4219 : loss : 0.017714, loss_ce: 0.007353
2021-11-30 15:11:12,276 iteration 4220 : loss : 0.024203, loss_ce: 0.005539
2021-11-30 15:11:13,893 iteration 4221 : loss : 0.021307, loss_ce: 0.009477
2021-11-30 15:11:15,499 iteration 4222 : loss : 0.025551, loss_ce: 0.007403
2021-11-30 15:11:16,994 iteration 4223 : loss : 0.018416, loss_ce: 0.005942
2021-11-30 15:11:18,570 iteration 4224 : loss : 0.037902, loss_ce: 0.008467
2021-11-30 15:11:20,110 iteration 4225 : loss : 0.025141, loss_ce: 0.007549
2021-11-30 15:11:21,662 iteration 4226 : loss : 0.020707, loss_ce: 0.008598
2021-11-30 15:11:23,190 iteration 4227 : loss : 0.018264, loss_ce: 0.006858
2021-11-30 15:11:24,666 iteration 4228 : loss : 0.024329, loss_ce: 0.011127
2021-11-30 15:11:26,182 iteration 4229 : loss : 0.022160, loss_ce: 0.008184
2021-11-30 15:11:27,686 iteration 4230 : loss : 0.026695, loss_ce: 0.014050
2021-11-30 15:11:29,246 iteration 4231 : loss : 0.035306, loss_ce: 0.012489
2021-11-30 15:11:30,793 iteration 4232 : loss : 0.032820, loss_ce: 0.010241
2021-11-30 15:11:32,291 iteration 4233 : loss : 0.029407, loss_ce: 0.015312
 62%|████████████████▊          | 249/400 [1:56:22<1:07:34, 26.85s/it]2021-11-30 15:11:33,755 iteration 4234 : loss : 0.025681, loss_ce: 0.005914
2021-11-30 15:11:35,207 iteration 4235 : loss : 0.013749, loss_ce: 0.005090
2021-11-30 15:11:36,761 iteration 4236 : loss : 0.022476, loss_ce: 0.008601
2021-11-30 15:11:38,240 iteration 4237 : loss : 0.024655, loss_ce: 0.009746
2021-11-30 15:11:39,745 iteration 4238 : loss : 0.039094, loss_ce: 0.021762
2021-11-30 15:11:41,387 iteration 4239 : loss : 0.038068, loss_ce: 0.015640
2021-11-30 15:11:42,929 iteration 4240 : loss : 0.025019, loss_ce: 0.008088
2021-11-30 15:11:44,376 iteration 4241 : loss : 0.018187, loss_ce: 0.008312
2021-11-30 15:11:45,896 iteration 4242 : loss : 0.028626, loss_ce: 0.009345
2021-11-30 15:11:47,401 iteration 4243 : loss : 0.019858, loss_ce: 0.007433
2021-11-30 15:11:48,852 iteration 4244 : loss : 0.015932, loss_ce: 0.007529
2021-11-30 15:11:50,407 iteration 4245 : loss : 0.025892, loss_ce: 0.010983
2021-11-30 15:11:52,005 iteration 4246 : loss : 0.021510, loss_ce: 0.006005
2021-11-30 15:11:53,557 iteration 4247 : loss : 0.021769, loss_ce: 0.009515
2021-11-30 15:11:55,017 iteration 4248 : loss : 0.024936, loss_ce: 0.010975
2021-11-30 15:11:56,602 iteration 4249 : loss : 0.030355, loss_ce: 0.009421
2021-11-30 15:11:56,603 Training Data Eval:
2021-11-30 15:12:04,188   Average segmentation loss on training set: 0.0147
2021-11-30 15:12:04,188 Validation Data Eval:
2021-11-30 15:12:06,808   Average segmentation loss on validation set: 0.0776
2021-11-30 15:12:08,324 iteration 4250 : loss : 0.026148, loss_ce: 0.009239
 62%|████████████████▉          | 250/400 [1:56:58<1:14:00, 29.60s/it]2021-11-30 15:12:09,930 iteration 4251 : loss : 0.024725, loss_ce: 0.006374
2021-11-30 15:12:11,497 iteration 4252 : loss : 0.029328, loss_ce: 0.015164
2021-11-30 15:12:13,014 iteration 4253 : loss : 0.027703, loss_ce: 0.010016
2021-11-30 15:12:14,577 iteration 4254 : loss : 0.016474, loss_ce: 0.005896
2021-11-30 15:12:16,145 iteration 4255 : loss : 0.021850, loss_ce: 0.008455
2021-11-30 15:12:17,599 iteration 4256 : loss : 0.016719, loss_ce: 0.007381
2021-11-30 15:12:19,114 iteration 4257 : loss : 0.022820, loss_ce: 0.009084
2021-11-30 15:12:20,573 iteration 4258 : loss : 0.025476, loss_ce: 0.007489
2021-11-30 15:12:22,108 iteration 4259 : loss : 0.022561, loss_ce: 0.009758
2021-11-30 15:12:23,665 iteration 4260 : loss : 0.025364, loss_ce: 0.007671
2021-11-30 15:12:25,206 iteration 4261 : loss : 0.022949, loss_ce: 0.008467
2021-11-30 15:12:26,696 iteration 4262 : loss : 0.018332, loss_ce: 0.008062
2021-11-30 15:12:28,238 iteration 4263 : loss : 0.022347, loss_ce: 0.009137
2021-11-30 15:12:29,815 iteration 4264 : loss : 0.027414, loss_ce: 0.011039
2021-11-30 15:12:31,327 iteration 4265 : loss : 0.029288, loss_ce: 0.007817
2021-11-30 15:12:32,869 iteration 4266 : loss : 0.027150, loss_ce: 0.008233
2021-11-30 15:12:34,437 iteration 4267 : loss : 0.026825, loss_ce: 0.010073
 63%|████████████████▉          | 251/400 [1:57:24<1:10:55, 28.56s/it]2021-11-30 15:12:36,014 iteration 4268 : loss : 0.019716, loss_ce: 0.004587
2021-11-30 15:12:37,518 iteration 4269 : loss : 0.032354, loss_ce: 0.013107
2021-11-30 15:12:39,014 iteration 4270 : loss : 0.021372, loss_ce: 0.011404
2021-11-30 15:12:40,468 iteration 4271 : loss : 0.020283, loss_ce: 0.007394
2021-11-30 15:12:41,972 iteration 4272 : loss : 0.020565, loss_ce: 0.009892
2021-11-30 15:12:43,426 iteration 4273 : loss : 0.018458, loss_ce: 0.007955
2021-11-30 15:12:45,026 iteration 4274 : loss : 0.019051, loss_ce: 0.008905
2021-11-30 15:12:46,519 iteration 4275 : loss : 0.024197, loss_ce: 0.008564
2021-11-30 15:12:48,091 iteration 4276 : loss : 0.028309, loss_ce: 0.008321
2021-11-30 15:12:49,655 iteration 4277 : loss : 0.025204, loss_ce: 0.007390
2021-11-30 15:12:51,197 iteration 4278 : loss : 0.023778, loss_ce: 0.007480
2021-11-30 15:12:52,686 iteration 4279 : loss : 0.025421, loss_ce: 0.013749
2021-11-30 15:12:54,211 iteration 4280 : loss : 0.029807, loss_ce: 0.010013
2021-11-30 15:12:55,747 iteration 4281 : loss : 0.025068, loss_ce: 0.007935
2021-11-30 15:12:57,215 iteration 4282 : loss : 0.019365, loss_ce: 0.008153
2021-11-30 15:12:58,722 iteration 4283 : loss : 0.029266, loss_ce: 0.008627
2021-11-30 15:13:00,203 iteration 4284 : loss : 0.018015, loss_ce: 0.007101
 63%|█████████████████          | 252/400 [1:57:50<1:08:22, 27.72s/it]2021-11-30 15:13:01,717 iteration 4285 : loss : 0.022121, loss_ce: 0.007299
2021-11-30 15:13:03,274 iteration 4286 : loss : 0.029261, loss_ce: 0.010693
2021-11-30 15:13:04,758 iteration 4287 : loss : 0.022159, loss_ce: 0.009197
2021-11-30 15:13:06,232 iteration 4288 : loss : 0.022293, loss_ce: 0.010013
2021-11-30 15:13:07,746 iteration 4289 : loss : 0.027191, loss_ce: 0.009766
2021-11-30 15:13:09,262 iteration 4290 : loss : 0.022530, loss_ce: 0.005661
2021-11-30 15:13:10,805 iteration 4291 : loss : 0.035354, loss_ce: 0.012188
2021-11-30 15:13:12,345 iteration 4292 : loss : 0.024980, loss_ce: 0.013357
2021-11-30 15:13:13,866 iteration 4293 : loss : 0.040045, loss_ce: 0.009426
2021-11-30 15:13:15,368 iteration 4294 : loss : 0.021655, loss_ce: 0.005216
2021-11-30 15:13:16,984 iteration 4295 : loss : 0.022105, loss_ce: 0.007573
2021-11-30 15:13:18,512 iteration 4296 : loss : 0.022784, loss_ce: 0.007940
2021-11-30 15:13:20,037 iteration 4297 : loss : 0.028144, loss_ce: 0.008825
2021-11-30 15:13:21,536 iteration 4298 : loss : 0.020741, loss_ce: 0.011186
2021-11-30 15:13:23,101 iteration 4299 : loss : 0.020271, loss_ce: 0.008697
2021-11-30 15:13:24,683 iteration 4300 : loss : 0.027716, loss_ce: 0.009943
2021-11-30 15:13:26,262 iteration 4301 : loss : 0.017859, loss_ce: 0.007470
 63%|█████████████████          | 253/400 [1:58:16<1:06:41, 27.22s/it]2021-11-30 15:13:27,864 iteration 4302 : loss : 0.022886, loss_ce: 0.008712
2021-11-30 15:13:29,438 iteration 4303 : loss : 0.042144, loss_ce: 0.008272
2021-11-30 15:13:30,918 iteration 4304 : loss : 0.021104, loss_ce: 0.007815
2021-11-30 15:13:32,413 iteration 4305 : loss : 0.019453, loss_ce: 0.007974
2021-11-30 15:13:33,910 iteration 4306 : loss : 0.016824, loss_ce: 0.004853
2021-11-30 15:13:35,365 iteration 4307 : loss : 0.019419, loss_ce: 0.008665
2021-11-30 15:13:36,905 iteration 4308 : loss : 0.025106, loss_ce: 0.008479
2021-11-30 15:13:38,481 iteration 4309 : loss : 0.027396, loss_ce: 0.010469
2021-11-30 15:13:40,009 iteration 4310 : loss : 0.016721, loss_ce: 0.006391
2021-11-30 15:13:41,493 iteration 4311 : loss : 0.029453, loss_ce: 0.011125
2021-11-30 15:13:42,973 iteration 4312 : loss : 0.021574, loss_ce: 0.007094
2021-11-30 15:13:44,471 iteration 4313 : loss : 0.018547, loss_ce: 0.008704
2021-11-30 15:13:45,976 iteration 4314 : loss : 0.019563, loss_ce: 0.007195
2021-11-30 15:13:47,516 iteration 4315 : loss : 0.021416, loss_ce: 0.007948
2021-11-30 15:13:48,998 iteration 4316 : loss : 0.021138, loss_ce: 0.006550
2021-11-30 15:13:50,566 iteration 4317 : loss : 0.023309, loss_ce: 0.009066
2021-11-30 15:13:52,057 iteration 4318 : loss : 0.019544, loss_ce: 0.007994
 64%|█████████████████▏         | 254/400 [1:58:42<1:05:11, 26.79s/it]2021-11-30 15:13:53,661 iteration 4319 : loss : 0.024433, loss_ce: 0.008951
2021-11-30 15:13:55,218 iteration 4320 : loss : 0.025667, loss_ce: 0.009818
2021-11-30 15:13:56,651 iteration 4321 : loss : 0.017283, loss_ce: 0.005240
2021-11-30 15:13:58,179 iteration 4322 : loss : 0.016429, loss_ce: 0.005396
2021-11-30 15:13:59,652 iteration 4323 : loss : 0.020108, loss_ce: 0.009615
2021-11-30 15:14:01,271 iteration 4324 : loss : 0.027130, loss_ce: 0.011343
2021-11-30 15:14:02,788 iteration 4325 : loss : 0.021154, loss_ce: 0.008866
2021-11-30 15:14:04,286 iteration 4326 : loss : 0.019778, loss_ce: 0.009055
2021-11-30 15:14:05,834 iteration 4327 : loss : 0.022605, loss_ce: 0.005826
2021-11-30 15:14:07,306 iteration 4328 : loss : 0.027160, loss_ce: 0.009120
2021-11-30 15:14:08,873 iteration 4329 : loss : 0.027792, loss_ce: 0.007223
2021-11-30 15:14:10,418 iteration 4330 : loss : 0.018090, loss_ce: 0.007576
2021-11-30 15:14:12,000 iteration 4331 : loss : 0.031487, loss_ce: 0.008887
2021-11-30 15:14:13,535 iteration 4332 : loss : 0.024547, loss_ce: 0.008108
2021-11-30 15:14:15,109 iteration 4333 : loss : 0.038056, loss_ce: 0.016773
2021-11-30 15:14:16,640 iteration 4334 : loss : 0.024432, loss_ce: 0.010836
2021-11-30 15:14:16,641 Training Data Eval:
2021-11-30 15:14:24,254   Average segmentation loss on training set: 0.0138
2021-11-30 15:14:24,254 Validation Data Eval:
2021-11-30 15:14:26,883   Average segmentation loss on validation set: 0.0783
2021-11-30 15:14:28,445 iteration 4335 : loss : 0.023873, loss_ce: 0.006837
 64%|█████████████████▏         | 255/400 [1:59:18<1:11:42, 29.67s/it]2021-11-30 15:14:29,912 iteration 4336 : loss : 0.014654, loss_ce: 0.007207
2021-11-30 15:14:31,527 iteration 4337 : loss : 0.026699, loss_ce: 0.011002
2021-11-30 15:14:33,054 iteration 4338 : loss : 0.023525, loss_ce: 0.007579
2021-11-30 15:14:34,540 iteration 4339 : loss : 0.018076, loss_ce: 0.005846
2021-11-30 15:14:36,091 iteration 4340 : loss : 0.022680, loss_ce: 0.009747
2021-11-30 15:14:37,584 iteration 4341 : loss : 0.016789, loss_ce: 0.005345
2021-11-30 15:14:39,142 iteration 4342 : loss : 0.023674, loss_ce: 0.007294
2021-11-30 15:14:40,704 iteration 4343 : loss : 0.021333, loss_ce: 0.006534
2021-11-30 15:14:42,257 iteration 4344 : loss : 0.021460, loss_ce: 0.010446
2021-11-30 15:14:43,874 iteration 4345 : loss : 0.022833, loss_ce: 0.009778
2021-11-30 15:14:45,333 iteration 4346 : loss : 0.024595, loss_ce: 0.006493
2021-11-30 15:14:46,854 iteration 4347 : loss : 0.018624, loss_ce: 0.008302
2021-11-30 15:14:48,318 iteration 4348 : loss : 0.016341, loss_ce: 0.007956
2021-11-30 15:14:49,765 iteration 4349 : loss : 0.016559, loss_ce: 0.004888
2021-11-30 15:14:51,204 iteration 4350 : loss : 0.020190, loss_ce: 0.008472
2021-11-30 15:14:52,745 iteration 4351 : loss : 0.026402, loss_ce: 0.008190
2021-11-30 15:14:54,263 iteration 4352 : loss : 0.024408, loss_ce: 0.011341
 64%|█████████████████▎         | 256/400 [1:59:44<1:08:26, 28.52s/it]2021-11-30 15:14:55,784 iteration 4353 : loss : 0.021956, loss_ce: 0.006688
2021-11-30 15:14:57,371 iteration 4354 : loss : 0.022615, loss_ce: 0.011549
2021-11-30 15:14:58,931 iteration 4355 : loss : 0.020808, loss_ce: 0.008216
2021-11-30 15:15:00,519 iteration 4356 : loss : 0.025629, loss_ce: 0.006482
2021-11-30 15:15:02,089 iteration 4357 : loss : 0.019964, loss_ce: 0.009974
2021-11-30 15:15:03,661 iteration 4358 : loss : 0.029229, loss_ce: 0.009373
2021-11-30 15:15:05,195 iteration 4359 : loss : 0.019633, loss_ce: 0.006432
2021-11-30 15:15:06,705 iteration 4360 : loss : 0.028305, loss_ce: 0.013837
2021-11-30 15:15:08,288 iteration 4361 : loss : 0.023583, loss_ce: 0.008327
2021-11-30 15:15:09,809 iteration 4362 : loss : 0.018835, loss_ce: 0.007803
2021-11-30 15:15:11,314 iteration 4363 : loss : 0.015272, loss_ce: 0.005974
2021-11-30 15:15:12,849 iteration 4364 : loss : 0.018823, loss_ce: 0.007075
2021-11-30 15:15:14,461 iteration 4365 : loss : 0.023071, loss_ce: 0.010566
2021-11-30 15:15:15,928 iteration 4366 : loss : 0.019289, loss_ce: 0.005417
2021-11-30 15:15:17,360 iteration 4367 : loss : 0.018260, loss_ce: 0.007630
2021-11-30 15:15:18,826 iteration 4368 : loss : 0.022082, loss_ce: 0.007052
2021-11-30 15:15:20,363 iteration 4369 : loss : 0.024611, loss_ce: 0.009161
 64%|█████████████████▎         | 257/400 [2:00:10<1:06:14, 27.79s/it]2021-11-30 15:15:21,922 iteration 4370 : loss : 0.019105, loss_ce: 0.006584
2021-11-30 15:15:23,460 iteration 4371 : loss : 0.019672, loss_ce: 0.009692
2021-11-30 15:15:25,001 iteration 4372 : loss : 0.018682, loss_ce: 0.007457
2021-11-30 15:15:26,548 iteration 4373 : loss : 0.017947, loss_ce: 0.008206
2021-11-30 15:15:28,088 iteration 4374 : loss : 0.041778, loss_ce: 0.014702
2021-11-30 15:15:29,620 iteration 4375 : loss : 0.022292, loss_ce: 0.009711
2021-11-30 15:15:31,110 iteration 4376 : loss : 0.022394, loss_ce: 0.007877
2021-11-30 15:15:32,609 iteration 4377 : loss : 0.017770, loss_ce: 0.005115
2021-11-30 15:15:34,084 iteration 4378 : loss : 0.016392, loss_ce: 0.005664
2021-11-30 15:15:35,560 iteration 4379 : loss : 0.017129, loss_ce: 0.005440
2021-11-30 15:15:37,003 iteration 4380 : loss : 0.018482, loss_ce: 0.006189
2021-11-30 15:15:38,548 iteration 4381 : loss : 0.027074, loss_ce: 0.010422
2021-11-30 15:15:40,076 iteration 4382 : loss : 0.036105, loss_ce: 0.006507
2021-11-30 15:15:41,557 iteration 4383 : loss : 0.020808, loss_ce: 0.005956
2021-11-30 15:15:43,128 iteration 4384 : loss : 0.028285, loss_ce: 0.010955
2021-11-30 15:15:44,699 iteration 4385 : loss : 0.028980, loss_ce: 0.009353
2021-11-30 15:15:46,182 iteration 4386 : loss : 0.017611, loss_ce: 0.007638
 64%|█████████████████▍         | 258/400 [2:00:36<1:04:22, 27.20s/it]2021-11-30 15:15:47,673 iteration 4387 : loss : 0.025669, loss_ce: 0.007072
2021-11-30 15:15:49,183 iteration 4388 : loss : 0.022745, loss_ce: 0.009977
2021-11-30 15:15:50,697 iteration 4389 : loss : 0.040541, loss_ce: 0.013451
2021-11-30 15:15:52,168 iteration 4390 : loss : 0.017128, loss_ce: 0.005796
2021-11-30 15:15:53,710 iteration 4391 : loss : 0.024014, loss_ce: 0.007275
2021-11-30 15:15:55,213 iteration 4392 : loss : 0.023044, loss_ce: 0.006236
2021-11-30 15:15:56,789 iteration 4393 : loss : 0.026518, loss_ce: 0.010739
2021-11-30 15:15:58,335 iteration 4394 : loss : 0.021004, loss_ce: 0.008754
2021-11-30 15:15:59,948 iteration 4395 : loss : 0.027632, loss_ce: 0.009643
2021-11-30 15:16:01,417 iteration 4396 : loss : 0.027226, loss_ce: 0.008363
2021-11-30 15:16:03,036 iteration 4397 : loss : 0.028164, loss_ce: 0.014656
2021-11-30 15:16:04,495 iteration 4398 : loss : 0.018790, loss_ce: 0.008464
2021-11-30 15:16:06,059 iteration 4399 : loss : 0.019642, loss_ce: 0.007465
2021-11-30 15:16:07,586 iteration 4400 : loss : 0.033511, loss_ce: 0.010966
2021-11-30 15:16:09,239 iteration 4401 : loss : 0.044565, loss_ce: 0.018160
2021-11-30 15:16:10,787 iteration 4402 : loss : 0.029279, loss_ce: 0.009191
2021-11-30 15:16:12,323 iteration 4403 : loss : 0.024080, loss_ce: 0.008993
 65%|█████████████████▍         | 259/400 [2:01:02<1:03:10, 26.88s/it]2021-11-30 15:16:13,853 iteration 4404 : loss : 0.021814, loss_ce: 0.009761
2021-11-30 15:16:15,417 iteration 4405 : loss : 0.022889, loss_ce: 0.009413
2021-11-30 15:16:16,969 iteration 4406 : loss : 0.023686, loss_ce: 0.009249
2021-11-30 15:16:18,537 iteration 4407 : loss : 0.026743, loss_ce: 0.008428
2021-11-30 15:16:20,045 iteration 4408 : loss : 0.022153, loss_ce: 0.008901
2021-11-30 15:16:21,589 iteration 4409 : loss : 0.022007, loss_ce: 0.007528
2021-11-30 15:16:23,247 iteration 4410 : loss : 0.029365, loss_ce: 0.010033
2021-11-30 15:16:24,804 iteration 4411 : loss : 0.022392, loss_ce: 0.009245
2021-11-30 15:16:26,322 iteration 4412 : loss : 0.021489, loss_ce: 0.008270
2021-11-30 15:16:27,866 iteration 4413 : loss : 0.018887, loss_ce: 0.006252
2021-11-30 15:16:29,344 iteration 4414 : loss : 0.020161, loss_ce: 0.006648
2021-11-30 15:16:30,901 iteration 4415 : loss : 0.025459, loss_ce: 0.010825
2021-11-30 15:16:32,472 iteration 4416 : loss : 0.034044, loss_ce: 0.009941
2021-11-30 15:16:33,977 iteration 4417 : loss : 0.018691, loss_ce: 0.005863
2021-11-30 15:16:35,531 iteration 4418 : loss : 0.020468, loss_ce: 0.009091
2021-11-30 15:16:37,104 iteration 4419 : loss : 0.019527, loss_ce: 0.006126
2021-11-30 15:16:37,104 Training Data Eval:
2021-11-30 15:16:44,696   Average segmentation loss on training set: 0.0142
2021-11-30 15:16:44,696 Validation Data Eval:
2021-11-30 15:16:47,319   Average segmentation loss on validation set: 0.0706
2021-11-30 15:16:48,801 iteration 4420 : loss : 0.016000, loss_ce: 0.006970
 65%|█████████████████▌         | 260/400 [2:01:39<1:09:26, 29.76s/it]2021-11-30 15:16:50,347 iteration 4421 : loss : 0.018715, loss_ce: 0.006268
2021-11-30 15:16:51,887 iteration 4422 : loss : 0.027827, loss_ce: 0.011500
2021-11-30 15:16:53,502 iteration 4423 : loss : 0.027237, loss_ce: 0.010281
2021-11-30 15:16:54,979 iteration 4424 : loss : 0.019964, loss_ce: 0.006458
2021-11-30 15:16:56,450 iteration 4425 : loss : 0.017420, loss_ce: 0.005984
2021-11-30 15:16:58,024 iteration 4426 : loss : 0.020322, loss_ce: 0.008071
2021-11-30 15:16:59,498 iteration 4427 : loss : 0.017058, loss_ce: 0.008460
2021-11-30 15:17:00,931 iteration 4428 : loss : 0.014975, loss_ce: 0.006843
2021-11-30 15:17:02,402 iteration 4429 : loss : 0.017571, loss_ce: 0.005921
2021-11-30 15:17:03,865 iteration 4430 : loss : 0.015462, loss_ce: 0.006350
2021-11-30 15:17:05,392 iteration 4431 : loss : 0.027433, loss_ce: 0.013437
2021-11-30 15:17:06,949 iteration 4432 : loss : 0.022193, loss_ce: 0.008281
2021-11-30 15:17:08,459 iteration 4433 : loss : 0.022743, loss_ce: 0.005741
2021-11-30 15:17:09,906 iteration 4434 : loss : 0.014745, loss_ce: 0.006166
2021-11-30 15:17:11,425 iteration 4435 : loss : 0.022893, loss_ce: 0.005138
2021-11-30 15:17:12,933 iteration 4436 : loss : 0.016527, loss_ce: 0.006578
2021-11-30 15:17:14,503 iteration 4437 : loss : 0.021861, loss_ce: 0.007773
 65%|█████████████████▌         | 261/400 [2:02:05<1:06:07, 28.54s/it]2021-11-30 15:17:16,105 iteration 4438 : loss : 0.038677, loss_ce: 0.009154
2021-11-30 15:17:17,654 iteration 4439 : loss : 0.019338, loss_ce: 0.007008
2021-11-30 15:17:19,182 iteration 4440 : loss : 0.022352, loss_ce: 0.007133
2021-11-30 15:17:20,816 iteration 4441 : loss : 0.036948, loss_ce: 0.016008
2021-11-30 15:17:22,393 iteration 4442 : loss : 0.019465, loss_ce: 0.010001
2021-11-30 15:17:23,929 iteration 4443 : loss : 0.028650, loss_ce: 0.011144
2021-11-30 15:17:25,382 iteration 4444 : loss : 0.020148, loss_ce: 0.006782
2021-11-30 15:17:26,900 iteration 4445 : loss : 0.026943, loss_ce: 0.012229
2021-11-30 15:17:28,450 iteration 4446 : loss : 0.020305, loss_ce: 0.008381
2021-11-30 15:17:29,953 iteration 4447 : loss : 0.018941, loss_ce: 0.006507
2021-11-30 15:17:31,502 iteration 4448 : loss : 0.028275, loss_ce: 0.010952
2021-11-30 15:17:33,049 iteration 4449 : loss : 0.023340, loss_ce: 0.010113
2021-11-30 15:17:34,620 iteration 4450 : loss : 0.026671, loss_ce: 0.008640
2021-11-30 15:17:36,107 iteration 4451 : loss : 0.024353, loss_ce: 0.008848
2021-11-30 15:17:37,645 iteration 4452 : loss : 0.021986, loss_ce: 0.009299
2021-11-30 15:17:39,151 iteration 4453 : loss : 0.021592, loss_ce: 0.007193
2021-11-30 15:17:40,654 iteration 4454 : loss : 0.023896, loss_ce: 0.010035
 66%|█████████████████▋         | 262/400 [2:02:31<1:04:00, 27.83s/it]2021-11-30 15:17:42,226 iteration 4455 : loss : 0.019289, loss_ce: 0.004992
2021-11-30 15:17:43,645 iteration 4456 : loss : 0.015816, loss_ce: 0.005915
2021-11-30 15:17:45,177 iteration 4457 : loss : 0.033902, loss_ce: 0.015778
2021-11-30 15:17:46,796 iteration 4458 : loss : 0.023910, loss_ce: 0.009788
2021-11-30 15:17:48,460 iteration 4459 : loss : 0.021875, loss_ce: 0.010489
2021-11-30 15:17:49,936 iteration 4460 : loss : 0.022741, loss_ce: 0.007434
2021-11-30 15:17:51,477 iteration 4461 : loss : 0.032017, loss_ce: 0.008951
2021-11-30 15:17:53,045 iteration 4462 : loss : 0.028411, loss_ce: 0.012009
2021-11-30 15:17:54,555 iteration 4463 : loss : 0.021507, loss_ce: 0.007777
2021-11-30 15:17:56,053 iteration 4464 : loss : 0.016815, loss_ce: 0.005663
2021-11-30 15:17:57,505 iteration 4465 : loss : 0.023987, loss_ce: 0.005705
2021-11-30 15:17:58,980 iteration 4466 : loss : 0.018613, loss_ce: 0.005862
2021-11-30 15:18:00,509 iteration 4467 : loss : 0.042794, loss_ce: 0.016066
2021-11-30 15:18:02,064 iteration 4468 : loss : 0.023458, loss_ce: 0.010016
2021-11-30 15:18:03,653 iteration 4469 : loss : 0.023454, loss_ce: 0.011397
2021-11-30 15:18:05,221 iteration 4470 : loss : 0.021202, loss_ce: 0.008914
2021-11-30 15:18:06,819 iteration 4471 : loss : 0.027012, loss_ce: 0.009311
 66%|█████████████████▊         | 263/400 [2:02:57<1:02:23, 27.32s/it]2021-11-30 15:18:08,345 iteration 4472 : loss : 0.019068, loss_ce: 0.008560
2021-11-30 15:18:09,833 iteration 4473 : loss : 0.023703, loss_ce: 0.009162
2021-11-30 15:18:11,361 iteration 4474 : loss : 0.022718, loss_ce: 0.011442
2021-11-30 15:18:12,868 iteration 4475 : loss : 0.019917, loss_ce: 0.005760
2021-11-30 15:18:14,339 iteration 4476 : loss : 0.020180, loss_ce: 0.005930
2021-11-30 15:18:15,825 iteration 4477 : loss : 0.019263, loss_ce: 0.007987
2021-11-30 15:18:17,449 iteration 4478 : loss : 0.025212, loss_ce: 0.014300
2021-11-30 15:18:18,975 iteration 4479 : loss : 0.021023, loss_ce: 0.006381
2021-11-30 15:18:20,518 iteration 4480 : loss : 0.021221, loss_ce: 0.007860
2021-11-30 15:18:22,003 iteration 4481 : loss : 0.019955, loss_ce: 0.007357
2021-11-30 15:18:23,468 iteration 4482 : loss : 0.016273, loss_ce: 0.004731
2021-11-30 15:18:24,967 iteration 4483 : loss : 0.023745, loss_ce: 0.007175
2021-11-30 15:18:26,486 iteration 4484 : loss : 0.017109, loss_ce: 0.005681
2021-11-30 15:18:27,939 iteration 4485 : loss : 0.017182, loss_ce: 0.006726
2021-11-30 15:18:29,528 iteration 4486 : loss : 0.022591, loss_ce: 0.009223
2021-11-30 15:18:31,079 iteration 4487 : loss : 0.020904, loss_ce: 0.009097
2021-11-30 15:18:32,545 iteration 4488 : loss : 0.019618, loss_ce: 0.007153
 66%|█████████████████▊         | 264/400 [2:03:23<1:00:50, 26.84s/it]2021-11-30 15:18:34,131 iteration 4489 : loss : 0.023577, loss_ce: 0.012094
2021-11-30 15:18:35,650 iteration 4490 : loss : 0.022157, loss_ce: 0.009462
2021-11-30 15:18:37,253 iteration 4491 : loss : 0.027535, loss_ce: 0.009705
2021-11-30 15:18:38,741 iteration 4492 : loss : 0.024454, loss_ce: 0.005386
2021-11-30 15:18:40,335 iteration 4493 : loss : 0.022654, loss_ce: 0.012903
2021-11-30 15:18:41,829 iteration 4494 : loss : 0.029175, loss_ce: 0.009358
2021-11-30 15:18:43,359 iteration 4495 : loss : 0.024212, loss_ce: 0.006906
2021-11-30 15:18:44,892 iteration 4496 : loss : 0.021390, loss_ce: 0.005814
2021-11-30 15:18:46,319 iteration 4497 : loss : 0.023413, loss_ce: 0.010610
2021-11-30 15:18:47,853 iteration 4498 : loss : 0.023844, loss_ce: 0.007682
2021-11-30 15:18:49,331 iteration 4499 : loss : 0.023635, loss_ce: 0.011054
2021-11-30 15:18:50,835 iteration 4500 : loss : 0.021603, loss_ce: 0.007864
2021-11-30 15:18:52,322 iteration 4501 : loss : 0.017636, loss_ce: 0.007538
2021-11-30 15:18:53,832 iteration 4502 : loss : 0.024743, loss_ce: 0.010024
2021-11-30 15:18:55,437 iteration 4503 : loss : 0.021789, loss_ce: 0.008471
2021-11-30 15:18:56,876 iteration 4504 : loss : 0.016596, loss_ce: 0.006578
2021-11-30 15:18:56,877 Training Data Eval:
2021-11-30 15:19:04,459   Average segmentation loss on training set: 0.0134
2021-11-30 15:19:04,459 Validation Data Eval:
2021-11-30 15:19:07,089   Average segmentation loss on validation set: 0.0672
2021-11-30 15:19:08,625 iteration 4505 : loss : 0.019230, loss_ce: 0.006871
 66%|█████████████████▉         | 265/400 [2:03:59<1:06:38, 29.62s/it]2021-11-30 15:19:10,213 iteration 4506 : loss : 0.022413, loss_ce: 0.007612
2021-11-30 15:19:11,805 iteration 4507 : loss : 0.028173, loss_ce: 0.012035
2021-11-30 15:19:13,335 iteration 4508 : loss : 0.024948, loss_ce: 0.008764
2021-11-30 15:19:14,803 iteration 4509 : loss : 0.016329, loss_ce: 0.005580
2021-11-30 15:19:16,339 iteration 4510 : loss : 0.015690, loss_ce: 0.004861
2021-11-30 15:19:17,942 iteration 4511 : loss : 0.023937, loss_ce: 0.010690
2021-11-30 15:19:19,380 iteration 4512 : loss : 0.019592, loss_ce: 0.007123
2021-11-30 15:19:20,881 iteration 4513 : loss : 0.021111, loss_ce: 0.007336
2021-11-30 15:19:22,377 iteration 4514 : loss : 0.021919, loss_ce: 0.008772
2021-11-30 15:19:23,893 iteration 4515 : loss : 0.018455, loss_ce: 0.006949
2021-11-30 15:19:25,417 iteration 4516 : loss : 0.020180, loss_ce: 0.008892
2021-11-30 15:19:26,965 iteration 4517 : loss : 0.019689, loss_ce: 0.006940
2021-11-30 15:19:28,472 iteration 4518 : loss : 0.022098, loss_ce: 0.011056
2021-11-30 15:19:29,911 iteration 4519 : loss : 0.030197, loss_ce: 0.008849
2021-11-30 15:19:31,445 iteration 4520 : loss : 0.020598, loss_ce: 0.006347
2021-11-30 15:19:32,965 iteration 4521 : loss : 0.024238, loss_ce: 0.013834
2021-11-30 15:19:34,547 iteration 4522 : loss : 0.026466, loss_ce: 0.008724
 66%|█████████████████▉         | 266/400 [2:04:25<1:03:40, 28.51s/it]2021-11-30 15:19:36,175 iteration 4523 : loss : 0.032165, loss_ce: 0.016118
2021-11-30 15:19:37,702 iteration 4524 : loss : 0.020787, loss_ce: 0.007226
2021-11-30 15:19:39,243 iteration 4525 : loss : 0.025285, loss_ce: 0.011399
2021-11-30 15:19:40,758 iteration 4526 : loss : 0.017492, loss_ce: 0.005115
2021-11-30 15:19:42,202 iteration 4527 : loss : 0.016746, loss_ce: 0.006875
2021-11-30 15:19:43,694 iteration 4528 : loss : 0.025692, loss_ce: 0.008489
2021-11-30 15:19:45,236 iteration 4529 : loss : 0.017980, loss_ce: 0.007801
2021-11-30 15:19:46,721 iteration 4530 : loss : 0.025568, loss_ce: 0.006359
2021-11-30 15:19:48,244 iteration 4531 : loss : 0.021449, loss_ce: 0.006992
2021-11-30 15:19:49,793 iteration 4532 : loss : 0.017472, loss_ce: 0.005829
2021-11-30 15:19:51,294 iteration 4533 : loss : 0.020521, loss_ce: 0.008788
2021-11-30 15:19:52,808 iteration 4534 : loss : 0.021942, loss_ce: 0.006546
2021-11-30 15:19:54,357 iteration 4535 : loss : 0.016862, loss_ce: 0.006159
2021-11-30 15:19:55,893 iteration 4536 : loss : 0.018517, loss_ce: 0.007224
2021-11-30 15:19:57,410 iteration 4537 : loss : 0.022094, loss_ce: 0.009276
2021-11-30 15:19:58,927 iteration 4538 : loss : 0.026114, loss_ce: 0.010542
2021-11-30 15:20:00,452 iteration 4539 : loss : 0.021244, loss_ce: 0.007976
 67%|██████████████████         | 267/400 [2:04:50<1:01:27, 27.73s/it]2021-11-30 15:20:01,994 iteration 4540 : loss : 0.017642, loss_ce: 0.006370
2021-11-30 15:20:03,537 iteration 4541 : loss : 0.026032, loss_ce: 0.013132
2021-11-30 15:20:05,009 iteration 4542 : loss : 0.020599, loss_ce: 0.007348
2021-11-30 15:20:06,523 iteration 4543 : loss : 0.019546, loss_ce: 0.006345
2021-11-30 15:20:07,995 iteration 4544 : loss : 0.017636, loss_ce: 0.006192
2021-11-30 15:20:09,570 iteration 4545 : loss : 0.018555, loss_ce: 0.007119
2021-11-30 15:20:11,198 iteration 4546 : loss : 0.027918, loss_ce: 0.012874
2021-11-30 15:20:12,811 iteration 4547 : loss : 0.021735, loss_ce: 0.007662
2021-11-30 15:20:14,262 iteration 4548 : loss : 0.018162, loss_ce: 0.006867
2021-11-30 15:20:15,730 iteration 4549 : loss : 0.024790, loss_ce: 0.005885
2021-11-30 15:20:17,251 iteration 4550 : loss : 0.021900, loss_ce: 0.008483
2021-11-30 15:20:18,807 iteration 4551 : loss : 0.020077, loss_ce: 0.007374
2021-11-30 15:20:20,401 iteration 4552 : loss : 0.024226, loss_ce: 0.007567
2021-11-30 15:20:21,920 iteration 4553 : loss : 0.021789, loss_ce: 0.007391
2021-11-30 15:20:23,384 iteration 4554 : loss : 0.020100, loss_ce: 0.008337
2021-11-30 15:20:24,903 iteration 4555 : loss : 0.017866, loss_ce: 0.006655
2021-11-30 15:20:26,412 iteration 4556 : loss : 0.022115, loss_ce: 0.006415
 67%|███████████████████▍         | 268/400 [2:05:16<59:49, 27.19s/it]2021-11-30 15:20:27,932 iteration 4557 : loss : 0.019692, loss_ce: 0.007790
2021-11-30 15:20:29,476 iteration 4558 : loss : 0.028991, loss_ce: 0.007965
2021-11-30 15:20:31,064 iteration 4559 : loss : 0.023812, loss_ce: 0.008538
2021-11-30 15:20:32,609 iteration 4560 : loss : 0.017648, loss_ce: 0.008973
2021-11-30 15:20:34,105 iteration 4561 : loss : 0.016339, loss_ce: 0.005080
2021-11-30 15:20:35,635 iteration 4562 : loss : 0.024443, loss_ce: 0.008617
2021-11-30 15:20:37,149 iteration 4563 : loss : 0.019909, loss_ce: 0.006758
2021-11-30 15:20:38,640 iteration 4564 : loss : 0.018425, loss_ce: 0.007034
2021-11-30 15:20:40,150 iteration 4565 : loss : 0.022409, loss_ce: 0.008723
2021-11-30 15:20:41,687 iteration 4566 : loss : 0.017849, loss_ce: 0.006290
2021-11-30 15:20:43,201 iteration 4567 : loss : 0.018012, loss_ce: 0.007185
2021-11-30 15:20:44,645 iteration 4568 : loss : 0.016390, loss_ce: 0.005276
2021-11-30 15:20:46,112 iteration 4569 : loss : 0.017694, loss_ce: 0.006695
2021-11-30 15:20:47,598 iteration 4570 : loss : 0.018577, loss_ce: 0.006400
2021-11-30 15:20:49,145 iteration 4571 : loss : 0.025767, loss_ce: 0.012058
2021-11-30 15:20:50,711 iteration 4572 : loss : 0.028190, loss_ce: 0.010388
2021-11-30 15:20:52,270 iteration 4573 : loss : 0.026080, loss_ce: 0.008402
 67%|███████████████████▌         | 269/400 [2:05:42<58:29, 26.79s/it]2021-11-30 15:20:53,761 iteration 4574 : loss : 0.014633, loss_ce: 0.004590
2021-11-30 15:20:55,295 iteration 4575 : loss : 0.014454, loss_ce: 0.003590
2021-11-30 15:20:56,738 iteration 4576 : loss : 0.019381, loss_ce: 0.007856
2021-11-30 15:20:58,216 iteration 4577 : loss : 0.016275, loss_ce: 0.007437
2021-11-30 15:20:59,733 iteration 4578 : loss : 0.014642, loss_ce: 0.005588
2021-11-30 15:21:01,203 iteration 4579 : loss : 0.017702, loss_ce: 0.007858
2021-11-30 15:21:02,693 iteration 4580 : loss : 0.019985, loss_ce: 0.007410
2021-11-30 15:21:04,233 iteration 4581 : loss : 0.033998, loss_ce: 0.012479
2021-11-30 15:21:05,734 iteration 4582 : loss : 0.022410, loss_ce: 0.007624
2021-11-30 15:21:07,238 iteration 4583 : loss : 0.020275, loss_ce: 0.007516
2021-11-30 15:21:08,741 iteration 4584 : loss : 0.017172, loss_ce: 0.005553
2021-11-30 15:21:10,289 iteration 4585 : loss : 0.020392, loss_ce: 0.006144
2021-11-30 15:21:11,744 iteration 4586 : loss : 0.016780, loss_ce: 0.006733
2021-11-30 15:21:13,231 iteration 4587 : loss : 0.015079, loss_ce: 0.004511
2021-11-30 15:21:14,722 iteration 4588 : loss : 0.019901, loss_ce: 0.007038
2021-11-30 15:21:16,233 iteration 4589 : loss : 0.021741, loss_ce: 0.008001
2021-11-30 15:21:16,234 Training Data Eval:
2021-11-30 15:21:23,797   Average segmentation loss on training set: 0.0135
2021-11-30 15:21:23,798 Validation Data Eval:
2021-11-30 15:21:26,414   Average segmentation loss on validation set: 0.0727
2021-11-30 15:21:27,921 iteration 4590 : loss : 0.021889, loss_ce: 0.010617
 68%|██████████████████▏        | 270/400 [2:06:18<1:03:48, 29.45s/it]2021-11-30 15:21:29,484 iteration 4591 : loss : 0.029616, loss_ce: 0.007243
2021-11-30 15:21:31,051 iteration 4592 : loss : 0.020407, loss_ce: 0.006505
2021-11-30 15:21:32,590 iteration 4593 : loss : 0.021070, loss_ce: 0.009197
2021-11-30 15:21:34,159 iteration 4594 : loss : 0.036390, loss_ce: 0.010741
2021-11-30 15:21:35,667 iteration 4595 : loss : 0.021558, loss_ce: 0.006610
2021-11-30 15:21:37,173 iteration 4596 : loss : 0.021474, loss_ce: 0.005057
2021-11-30 15:21:38,707 iteration 4597 : loss : 0.016880, loss_ce: 0.007358
2021-11-30 15:21:40,272 iteration 4598 : loss : 0.030548, loss_ce: 0.010874
2021-11-30 15:21:41,817 iteration 4599 : loss : 0.019553, loss_ce: 0.009531
2021-11-30 15:21:43,323 iteration 4600 : loss : 0.020069, loss_ce: 0.006392
2021-11-30 15:21:44,870 iteration 4601 : loss : 0.017488, loss_ce: 0.008106
2021-11-30 15:21:46,482 iteration 4602 : loss : 0.024939, loss_ce: 0.006193
2021-11-30 15:21:48,007 iteration 4603 : loss : 0.024294, loss_ce: 0.008808
2021-11-30 15:21:49,581 iteration 4604 : loss : 0.020729, loss_ce: 0.008381
2021-11-30 15:21:51,146 iteration 4605 : loss : 0.049044, loss_ce: 0.010337
2021-11-30 15:21:52,703 iteration 4606 : loss : 0.022848, loss_ce: 0.008761
2021-11-30 15:21:54,256 iteration 4607 : loss : 0.017991, loss_ce: 0.009337
 68%|██████████████████▎        | 271/400 [2:06:44<1:01:18, 28.52s/it]2021-11-30 15:21:55,768 iteration 4608 : loss : 0.016017, loss_ce: 0.005769
2021-11-30 15:21:57,296 iteration 4609 : loss : 0.025865, loss_ce: 0.009780
2021-11-30 15:21:58,772 iteration 4610 : loss : 0.021116, loss_ce: 0.006481
2021-11-30 15:22:00,232 iteration 4611 : loss : 0.021017, loss_ce: 0.008109
2021-11-30 15:22:01,683 iteration 4612 : loss : 0.023285, loss_ce: 0.006454
2021-11-30 15:22:03,215 iteration 4613 : loss : 0.026620, loss_ce: 0.009556
2021-11-30 15:22:04,725 iteration 4614 : loss : 0.019258, loss_ce: 0.009778
2021-11-30 15:22:06,276 iteration 4615 : loss : 0.016072, loss_ce: 0.005350
2021-11-30 15:22:07,909 iteration 4616 : loss : 0.026516, loss_ce: 0.012449
2021-11-30 15:22:09,436 iteration 4617 : loss : 0.025460, loss_ce: 0.011190
2021-11-30 15:22:10,901 iteration 4618 : loss : 0.026403, loss_ce: 0.008544
2021-11-30 15:22:12,382 iteration 4619 : loss : 0.013817, loss_ce: 0.006078
2021-11-30 15:22:13,954 iteration 4620 : loss : 0.020740, loss_ce: 0.006010
2021-11-30 15:22:15,478 iteration 4621 : loss : 0.022892, loss_ce: 0.012524
2021-11-30 15:22:17,004 iteration 4622 : loss : 0.032772, loss_ce: 0.013202
2021-11-30 15:22:18,512 iteration 4623 : loss : 0.036710, loss_ce: 0.020865
2021-11-30 15:22:20,039 iteration 4624 : loss : 0.019431, loss_ce: 0.008903
 68%|███████████████████▋         | 272/400 [2:07:10<59:05, 27.70s/it]2021-11-30 15:22:21,649 iteration 4625 : loss : 0.016849, loss_ce: 0.006655
2021-11-30 15:22:23,231 iteration 4626 : loss : 0.023802, loss_ce: 0.011108
2021-11-30 15:22:24,849 iteration 4627 : loss : 0.023948, loss_ce: 0.010309
2021-11-30 15:22:26,349 iteration 4628 : loss : 0.019062, loss_ce: 0.007149
2021-11-30 15:22:27,803 iteration 4629 : loss : 0.017474, loss_ce: 0.006226
2021-11-30 15:22:29,321 iteration 4630 : loss : 0.022650, loss_ce: 0.009469
2021-11-30 15:22:30,849 iteration 4631 : loss : 0.025080, loss_ce: 0.008820
2021-11-30 15:22:32,368 iteration 4632 : loss : 0.021111, loss_ce: 0.006974
2021-11-30 15:22:33,874 iteration 4633 : loss : 0.019495, loss_ce: 0.006173
2021-11-30 15:22:35,364 iteration 4634 : loss : 0.022349, loss_ce: 0.013171
2021-11-30 15:22:36,799 iteration 4635 : loss : 0.014414, loss_ce: 0.005848
2021-11-30 15:22:38,397 iteration 4636 : loss : 0.025779, loss_ce: 0.010067
2021-11-30 15:22:39,921 iteration 4637 : loss : 0.029407, loss_ce: 0.010290
2021-11-30 15:22:41,543 iteration 4638 : loss : 0.031071, loss_ce: 0.013193
2021-11-30 15:22:43,096 iteration 4639 : loss : 0.023939, loss_ce: 0.008474
2021-11-30 15:22:44,722 iteration 4640 : loss : 0.034641, loss_ce: 0.012786
2021-11-30 15:22:46,268 iteration 4641 : loss : 0.021411, loss_ce: 0.008196
 68%|███████████████████▊         | 273/400 [2:07:36<57:41, 27.26s/it]2021-11-30 15:22:47,817 iteration 4642 : loss : 0.026652, loss_ce: 0.005383
2021-11-30 15:22:49,330 iteration 4643 : loss : 0.019503, loss_ce: 0.007169
2021-11-30 15:22:50,904 iteration 4644 : loss : 0.024197, loss_ce: 0.007797
2021-11-30 15:22:52,485 iteration 4645 : loss : 0.030156, loss_ce: 0.013829
2021-11-30 15:22:54,023 iteration 4646 : loss : 0.028514, loss_ce: 0.006735
2021-11-30 15:22:55,461 iteration 4647 : loss : 0.017559, loss_ce: 0.005573
2021-11-30 15:22:56,958 iteration 4648 : loss : 0.017029, loss_ce: 0.005987
2021-11-30 15:22:58,497 iteration 4649 : loss : 0.023357, loss_ce: 0.009172
2021-11-30 15:23:00,072 iteration 4650 : loss : 0.032467, loss_ce: 0.009714
2021-11-30 15:23:01,544 iteration 4651 : loss : 0.026956, loss_ce: 0.012062
2021-11-30 15:23:03,159 iteration 4652 : loss : 0.026748, loss_ce: 0.010906
2021-11-30 15:23:04,671 iteration 4653 : loss : 0.020589, loss_ce: 0.007930
2021-11-30 15:23:06,172 iteration 4654 : loss : 0.038784, loss_ce: 0.010245
2021-11-30 15:23:07,754 iteration 4655 : loss : 0.023731, loss_ce: 0.009159
2021-11-30 15:23:09,355 iteration 4656 : loss : 0.028092, loss_ce: 0.013179
2021-11-30 15:23:10,897 iteration 4657 : loss : 0.032003, loss_ce: 0.015416
2021-11-30 15:23:12,436 iteration 4658 : loss : 0.025059, loss_ce: 0.009682
 68%|███████████████████▊         | 274/400 [2:08:02<56:32, 26.93s/it]2021-11-30 15:23:14,022 iteration 4659 : loss : 0.028647, loss_ce: 0.011901
2021-11-30 15:23:15,606 iteration 4660 : loss : 0.027917, loss_ce: 0.011096
2021-11-30 15:23:17,158 iteration 4661 : loss : 0.033585, loss_ce: 0.011491
2021-11-30 15:23:18,648 iteration 4662 : loss : 0.015596, loss_ce: 0.006062
2021-11-30 15:23:20,193 iteration 4663 : loss : 0.024324, loss_ce: 0.010149
2021-11-30 15:23:21,704 iteration 4664 : loss : 0.018330, loss_ce: 0.007486
2021-11-30 15:23:23,217 iteration 4665 : loss : 0.023953, loss_ce: 0.008759
2021-11-30 15:23:24,654 iteration 4666 : loss : 0.016939, loss_ce: 0.005791
2021-11-30 15:23:26,145 iteration 4667 : loss : 0.029583, loss_ce: 0.012434
2021-11-30 15:23:27,796 iteration 4668 : loss : 0.025677, loss_ce: 0.011216
2021-11-30 15:23:29,266 iteration 4669 : loss : 0.017527, loss_ce: 0.006829
2021-11-30 15:23:30,756 iteration 4670 : loss : 0.024684, loss_ce: 0.008654
2021-11-30 15:23:32,227 iteration 4671 : loss : 0.020146, loss_ce: 0.006511
2021-11-30 15:23:33,844 iteration 4672 : loss : 0.030819, loss_ce: 0.010731
2021-11-30 15:23:35,425 iteration 4673 : loss : 0.017933, loss_ce: 0.007878
2021-11-30 15:23:36,881 iteration 4674 : loss : 0.018299, loss_ce: 0.005240
2021-11-30 15:23:36,881 Training Data Eval:
2021-11-30 15:23:44,452   Average segmentation loss on training set: 0.0149
2021-11-30 15:23:44,452 Validation Data Eval:
2021-11-30 15:23:47,069   Average segmentation loss on validation set: 0.0699
2021-11-30 15:23:48,650 iteration 4675 : loss : 0.019949, loss_ce: 0.007072
 69%|██████████████████▌        | 275/400 [2:08:39<1:01:54, 29.72s/it]2021-11-30 15:23:50,315 iteration 4676 : loss : 0.024350, loss_ce: 0.008456
2021-11-30 15:23:51,828 iteration 4677 : loss : 0.020646, loss_ce: 0.006958
2021-11-30 15:23:53,375 iteration 4678 : loss : 0.023570, loss_ce: 0.006836
2021-11-30 15:23:54,980 iteration 4679 : loss : 0.036949, loss_ce: 0.009564
2021-11-30 15:23:56,500 iteration 4680 : loss : 0.017667, loss_ce: 0.006911
2021-11-30 15:23:58,012 iteration 4681 : loss : 0.033679, loss_ce: 0.009733
2021-11-30 15:23:59,520 iteration 4682 : loss : 0.021355, loss_ce: 0.007649
2021-11-30 15:24:00,953 iteration 4683 : loss : 0.024760, loss_ce: 0.006654
2021-11-30 15:24:02,529 iteration 4684 : loss : 0.021265, loss_ce: 0.010108
2021-11-30 15:24:04,087 iteration 4685 : loss : 0.042889, loss_ce: 0.018287
2021-11-30 15:24:05,606 iteration 4686 : loss : 0.025843, loss_ce: 0.006563
2021-11-30 15:24:07,128 iteration 4687 : loss : 0.018276, loss_ce: 0.008045
2021-11-30 15:24:08,583 iteration 4688 : loss : 0.014317, loss_ce: 0.006482
2021-11-30 15:24:10,041 iteration 4689 : loss : 0.012774, loss_ce: 0.005408
2021-11-30 15:24:11,515 iteration 4690 : loss : 0.023627, loss_ce: 0.009544
2021-11-30 15:24:13,072 iteration 4691 : loss : 0.024488, loss_ce: 0.011953
2021-11-30 15:24:14,571 iteration 4692 : loss : 0.026901, loss_ce: 0.007308
 69%|████████████████████         | 276/400 [2:09:05<59:03, 28.58s/it]2021-11-30 15:24:16,184 iteration 4693 : loss : 0.026478, loss_ce: 0.008794
2021-11-30 15:24:17,721 iteration 4694 : loss : 0.030551, loss_ce: 0.012239
2021-11-30 15:24:19,118 iteration 4695 : loss : 0.017104, loss_ce: 0.005802
2021-11-30 15:24:20,721 iteration 4696 : loss : 0.025517, loss_ce: 0.010205
2021-11-30 15:24:22,199 iteration 4697 : loss : 0.018776, loss_ce: 0.006715
2021-11-30 15:24:23,719 iteration 4698 : loss : 0.026240, loss_ce: 0.011778
2021-11-30 15:24:25,297 iteration 4699 : loss : 0.018870, loss_ce: 0.008498
2021-11-30 15:24:26,801 iteration 4700 : loss : 0.021252, loss_ce: 0.009625
2021-11-30 15:24:28,415 iteration 4701 : loss : 0.021463, loss_ce: 0.008411
2021-11-30 15:24:29,906 iteration 4702 : loss : 0.017664, loss_ce: 0.008013
2021-11-30 15:24:31,389 iteration 4703 : loss : 0.018234, loss_ce: 0.004800
2021-11-30 15:24:32,936 iteration 4704 : loss : 0.023784, loss_ce: 0.007516
2021-11-30 15:24:34,327 iteration 4705 : loss : 0.014438, loss_ce: 0.006050
2021-11-30 15:24:35,854 iteration 4706 : loss : 0.021178, loss_ce: 0.005592
2021-11-30 15:24:37,435 iteration 4707 : loss : 0.020943, loss_ce: 0.007919
2021-11-30 15:24:39,027 iteration 4708 : loss : 0.029392, loss_ce: 0.009382
2021-11-30 15:24:40,570 iteration 4709 : loss : 0.027246, loss_ce: 0.009827
 69%|████████████████████         | 277/400 [2:09:31<56:59, 27.80s/it]2021-11-30 15:24:42,149 iteration 4710 : loss : 0.036108, loss_ce: 0.007111
2021-11-30 15:24:43,808 iteration 4711 : loss : 0.022981, loss_ce: 0.009403
2021-11-30 15:24:45,302 iteration 4712 : loss : 0.020733, loss_ce: 0.008643
2021-11-30 15:24:46,806 iteration 4713 : loss : 0.021232, loss_ce: 0.007767
2021-11-30 15:24:48,339 iteration 4714 : loss : 0.023982, loss_ce: 0.007880
2021-11-30 15:24:49,924 iteration 4715 : loss : 0.022561, loss_ce: 0.007122
2021-11-30 15:24:51,475 iteration 4716 : loss : 0.019833, loss_ce: 0.007433
2021-11-30 15:24:52,987 iteration 4717 : loss : 0.023200, loss_ce: 0.007407
2021-11-30 15:24:54,459 iteration 4718 : loss : 0.015671, loss_ce: 0.005536
2021-11-30 15:24:55,920 iteration 4719 : loss : 0.020699, loss_ce: 0.008552
2021-11-30 15:24:57,413 iteration 4720 : loss : 0.018005, loss_ce: 0.006663
2021-11-30 15:24:58,909 iteration 4721 : loss : 0.019593, loss_ce: 0.007865
2021-11-30 15:25:00,456 iteration 4722 : loss : 0.028822, loss_ce: 0.009132
2021-11-30 15:25:01,964 iteration 4723 : loss : 0.015461, loss_ce: 0.005490
2021-11-30 15:25:03,431 iteration 4724 : loss : 0.015596, loss_ce: 0.005984
2021-11-30 15:25:04,897 iteration 4725 : loss : 0.019915, loss_ce: 0.007669
2021-11-30 15:25:06,413 iteration 4726 : loss : 0.020898, loss_ce: 0.007920
 70%|████████████████████▏        | 278/400 [2:09:56<55:20, 27.22s/it]2021-11-30 15:25:08,023 iteration 4727 : loss : 0.024951, loss_ce: 0.008036
2021-11-30 15:25:09,480 iteration 4728 : loss : 0.016845, loss_ce: 0.006344
2021-11-30 15:25:10,960 iteration 4729 : loss : 0.017527, loss_ce: 0.005924
2021-11-30 15:25:12,439 iteration 4730 : loss : 0.014910, loss_ce: 0.004870
2021-11-30 15:25:14,010 iteration 4731 : loss : 0.028411, loss_ce: 0.011988
2021-11-30 15:25:15,554 iteration 4732 : loss : 0.031405, loss_ce: 0.011680
2021-11-30 15:25:17,094 iteration 4733 : loss : 0.017475, loss_ce: 0.005834
2021-11-30 15:25:18,600 iteration 4734 : loss : 0.017851, loss_ce: 0.006407
2021-11-30 15:25:20,205 iteration 4735 : loss : 0.020982, loss_ce: 0.006883
2021-11-30 15:25:21,660 iteration 4736 : loss : 0.023167, loss_ce: 0.010331
2021-11-30 15:25:23,268 iteration 4737 : loss : 0.026126, loss_ce: 0.008406
2021-11-30 15:25:24,795 iteration 4738 : loss : 0.018975, loss_ce: 0.006143
2021-11-30 15:25:26,312 iteration 4739 : loss : 0.023181, loss_ce: 0.008958
2021-11-30 15:25:27,870 iteration 4740 : loss : 0.027165, loss_ce: 0.012002
2021-11-30 15:25:29,378 iteration 4741 : loss : 0.017328, loss_ce: 0.005599
2021-11-30 15:25:30,887 iteration 4742 : loss : 0.017717, loss_ce: 0.008320
2021-11-30 15:25:32,483 iteration 4743 : loss : 0.026120, loss_ce: 0.008064
 70%|████████████████████▏        | 279/400 [2:10:23<54:11, 26.87s/it]2021-11-30 15:25:34,093 iteration 4744 : loss : 0.021708, loss_ce: 0.007319
2021-11-30 15:25:35,613 iteration 4745 : loss : 0.021669, loss_ce: 0.006465
2021-11-30 15:25:37,088 iteration 4746 : loss : 0.015593, loss_ce: 0.007790
2021-11-30 15:25:38,575 iteration 4747 : loss : 0.027907, loss_ce: 0.008860
2021-11-30 15:25:40,107 iteration 4748 : loss : 0.020577, loss_ce: 0.007080
2021-11-30 15:25:41,654 iteration 4749 : loss : 0.024710, loss_ce: 0.008427
2021-11-30 15:25:43,228 iteration 4750 : loss : 0.020529, loss_ce: 0.008180
2021-11-30 15:25:44,727 iteration 4751 : loss : 0.022965, loss_ce: 0.008585
2021-11-30 15:25:46,267 iteration 4752 : loss : 0.020087, loss_ce: 0.007310
2021-11-30 15:25:47,842 iteration 4753 : loss : 0.021136, loss_ce: 0.006892
2021-11-30 15:25:49,382 iteration 4754 : loss : 0.016502, loss_ce: 0.005406
2021-11-30 15:25:50,990 iteration 4755 : loss : 0.019411, loss_ce: 0.005495
2021-11-30 15:25:52,476 iteration 4756 : loss : 0.019804, loss_ce: 0.009311
2021-11-30 15:25:53,994 iteration 4757 : loss : 0.023786, loss_ce: 0.008833
2021-11-30 15:25:55,488 iteration 4758 : loss : 0.018816, loss_ce: 0.005659
2021-11-30 15:25:57,009 iteration 4759 : loss : 0.013902, loss_ce: 0.004635
2021-11-30 15:25:57,010 Training Data Eval:
2021-11-30 15:26:04,604   Average segmentation loss on training set: 0.0131
2021-11-30 15:26:04,604 Validation Data Eval:
2021-11-30 15:26:07,219   Average segmentation loss on validation set: 0.0834
2021-11-30 15:26:08,733 iteration 4760 : loss : 0.021708, loss_ce: 0.010535
 70%|████████████████████▎        | 280/400 [2:10:59<59:22, 29.69s/it]2021-11-30 15:26:10,285 iteration 4761 : loss : 0.018334, loss_ce: 0.006445
2021-11-30 15:26:11,834 iteration 4762 : loss : 0.027107, loss_ce: 0.008063
2021-11-30 15:26:13,311 iteration 4763 : loss : 0.015948, loss_ce: 0.006215
2021-11-30 15:26:14,865 iteration 4764 : loss : 0.029070, loss_ce: 0.010581
2021-11-30 15:26:16,365 iteration 4765 : loss : 0.017904, loss_ce: 0.008237
2021-11-30 15:26:17,946 iteration 4766 : loss : 0.021339, loss_ce: 0.006951
2021-11-30 15:26:19,488 iteration 4767 : loss : 0.017693, loss_ce: 0.007062
2021-11-30 15:26:20,977 iteration 4768 : loss : 0.022521, loss_ce: 0.006949
2021-11-30 15:26:22,539 iteration 4769 : loss : 0.026083, loss_ce: 0.009948
2021-11-30 15:26:24,101 iteration 4770 : loss : 0.025804, loss_ce: 0.010547
2021-11-30 15:26:25,555 iteration 4771 : loss : 0.017102, loss_ce: 0.005554
2021-11-30 15:26:27,128 iteration 4772 : loss : 0.020604, loss_ce: 0.008093
2021-11-30 15:26:28,667 iteration 4773 : loss : 0.025780, loss_ce: 0.010436
2021-11-30 15:26:30,202 iteration 4774 : loss : 0.018045, loss_ce: 0.007007
2021-11-30 15:26:31,689 iteration 4775 : loss : 0.032975, loss_ce: 0.009096
2021-11-30 15:26:33,214 iteration 4776 : loss : 0.021884, loss_ce: 0.011348
2021-11-30 15:26:34,861 iteration 4777 : loss : 0.027357, loss_ce: 0.011625
 70%|████████████████████▎        | 281/400 [2:11:25<56:45, 28.62s/it]2021-11-30 15:26:36,334 iteration 4778 : loss : 0.013957, loss_ce: 0.003912
2021-11-30 15:26:37,821 iteration 4779 : loss : 0.023193, loss_ce: 0.008008
2021-11-30 15:26:39,272 iteration 4780 : loss : 0.017264, loss_ce: 0.005994
2021-11-30 15:26:40,772 iteration 4781 : loss : 0.022878, loss_ce: 0.007137
2021-11-30 15:26:42,342 iteration 4782 : loss : 0.024114, loss_ce: 0.010872
2021-11-30 15:26:43,856 iteration 4783 : loss : 0.022493, loss_ce: 0.010238
2021-11-30 15:26:45,315 iteration 4784 : loss : 0.015035, loss_ce: 0.006154
2021-11-30 15:26:46,901 iteration 4785 : loss : 0.026332, loss_ce: 0.009719
2021-11-30 15:26:48,444 iteration 4786 : loss : 0.021211, loss_ce: 0.005953
2021-11-30 15:26:49,994 iteration 4787 : loss : 0.021001, loss_ce: 0.006755
2021-11-30 15:26:51,555 iteration 4788 : loss : 0.018981, loss_ce: 0.006242
2021-11-30 15:26:53,021 iteration 4789 : loss : 0.017702, loss_ce: 0.007668
2021-11-30 15:26:54,632 iteration 4790 : loss : 0.021749, loss_ce: 0.007554
2021-11-30 15:26:56,132 iteration 4791 : loss : 0.026777, loss_ce: 0.011023
2021-11-30 15:26:57,716 iteration 4792 : loss : 0.029843, loss_ce: 0.009624
2021-11-30 15:26:59,201 iteration 4793 : loss : 0.018974, loss_ce: 0.006532
2021-11-30 15:27:00,630 iteration 4794 : loss : 0.020129, loss_ce: 0.005617
 70%|████████████████████▍        | 282/400 [2:11:51<54:35, 27.76s/it]2021-11-30 15:27:02,202 iteration 4795 : loss : 0.021670, loss_ce: 0.006617
2021-11-30 15:27:03,734 iteration 4796 : loss : 0.013736, loss_ce: 0.004472
2021-11-30 15:27:05,275 iteration 4797 : loss : 0.023686, loss_ce: 0.010763
2021-11-30 15:27:06,845 iteration 4798 : loss : 0.027936, loss_ce: 0.009398
2021-11-30 15:27:08,362 iteration 4799 : loss : 0.017905, loss_ce: 0.005152
2021-11-30 15:27:09,882 iteration 4800 : loss : 0.022835, loss_ce: 0.007022
2021-11-30 15:27:11,474 iteration 4801 : loss : 0.022030, loss_ce: 0.008110
2021-11-30 15:27:12,925 iteration 4802 : loss : 0.021981, loss_ce: 0.012316
2021-11-30 15:27:14,416 iteration 4803 : loss : 0.017037, loss_ce: 0.007415
2021-11-30 15:27:16,004 iteration 4804 : loss : 0.054978, loss_ce: 0.011546
2021-11-30 15:27:17,582 iteration 4805 : loss : 0.040936, loss_ce: 0.018261
2021-11-30 15:27:19,167 iteration 4806 : loss : 0.022122, loss_ce: 0.008377
2021-11-30 15:27:20,630 iteration 4807 : loss : 0.021669, loss_ce: 0.009010
2021-11-30 15:27:22,080 iteration 4808 : loss : 0.016924, loss_ce: 0.006885
2021-11-30 15:27:23,623 iteration 4809 : loss : 0.026408, loss_ce: 0.011970
2021-11-30 15:27:25,147 iteration 4810 : loss : 0.021604, loss_ce: 0.005768
2021-11-30 15:27:26,683 iteration 4811 : loss : 0.016797, loss_ce: 0.007273
 71%|████████████████████▌        | 283/400 [2:12:17<53:08, 27.25s/it]2021-11-30 15:27:28,186 iteration 4812 : loss : 0.023853, loss_ce: 0.008359
2021-11-30 15:27:29,734 iteration 4813 : loss : 0.014988, loss_ce: 0.003922
2021-11-30 15:27:31,289 iteration 4814 : loss : 0.021303, loss_ce: 0.004759
2021-11-30 15:27:32,742 iteration 4815 : loss : 0.016869, loss_ce: 0.007107
2021-11-30 15:27:34,358 iteration 4816 : loss : 0.022149, loss_ce: 0.009297
2021-11-30 15:27:35,858 iteration 4817 : loss : 0.023651, loss_ce: 0.008902
2021-11-30 15:27:37,347 iteration 4818 : loss : 0.016145, loss_ce: 0.005809
2021-11-30 15:27:38,778 iteration 4819 : loss : 0.018952, loss_ce: 0.007319
2021-11-30 15:27:40,270 iteration 4820 : loss : 0.019041, loss_ce: 0.007586
2021-11-30 15:27:41,887 iteration 4821 : loss : 0.025701, loss_ce: 0.012026
2021-11-30 15:27:43,485 iteration 4822 : loss : 0.026599, loss_ce: 0.008454
2021-11-30 15:27:44,997 iteration 4823 : loss : 0.024375, loss_ce: 0.010289
2021-11-30 15:27:46,538 iteration 4824 : loss : 0.025236, loss_ce: 0.009280
2021-11-30 15:27:48,034 iteration 4825 : loss : 0.024088, loss_ce: 0.008875
2021-11-30 15:27:49,518 iteration 4826 : loss : 0.021603, loss_ce: 0.006215
2021-11-30 15:27:51,019 iteration 4827 : loss : 0.015872, loss_ce: 0.006563
2021-11-30 15:27:52,488 iteration 4828 : loss : 0.018963, loss_ce: 0.008049
 71%|████████████████████▌        | 284/400 [2:12:43<51:50, 26.82s/it]2021-11-30 15:27:53,985 iteration 4829 : loss : 0.022447, loss_ce: 0.007415
2021-11-30 15:27:55,541 iteration 4830 : loss : 0.017247, loss_ce: 0.007596
2021-11-30 15:27:57,070 iteration 4831 : loss : 0.018388, loss_ce: 0.007103
2021-11-30 15:27:58,583 iteration 4832 : loss : 0.021095, loss_ce: 0.006752
2021-11-30 15:28:00,136 iteration 4833 : loss : 0.024723, loss_ce: 0.008465
2021-11-30 15:28:01,598 iteration 4834 : loss : 0.016883, loss_ce: 0.005767
2021-11-30 15:28:03,217 iteration 4835 : loss : 0.022340, loss_ce: 0.010256
2021-11-30 15:28:04,745 iteration 4836 : loss : 0.024616, loss_ce: 0.007311
2021-11-30 15:28:06,310 iteration 4837 : loss : 0.021992, loss_ce: 0.006223
2021-11-30 15:28:07,805 iteration 4838 : loss : 0.016813, loss_ce: 0.005085
2021-11-30 15:28:09,339 iteration 4839 : loss : 0.022020, loss_ce: 0.008384
2021-11-30 15:28:10,873 iteration 4840 : loss : 0.019826, loss_ce: 0.008566
2021-11-30 15:28:12,335 iteration 4841 : loss : 0.014345, loss_ce: 0.004376
2021-11-30 15:28:13,878 iteration 4842 : loss : 0.017772, loss_ce: 0.006277
2021-11-30 15:28:15,475 iteration 4843 : loss : 0.019487, loss_ce: 0.006176
2021-11-30 15:28:16,984 iteration 4844 : loss : 0.024490, loss_ce: 0.008735
2021-11-30 15:28:16,985 Training Data Eval:
2021-11-30 15:28:25,938   Average segmentation loss on training set: 0.0119
2021-11-30 15:28:25,938 Validation Data Eval:
2021-11-30 15:28:28,558   Average segmentation loss on validation set: 0.0662
2021-11-30 15:28:30,119 iteration 4845 : loss : 0.019734, loss_ce: 0.009034
 71%|████████████████████▋        | 285/400 [2:13:20<57:37, 30.06s/it]2021-11-30 15:28:31,642 iteration 4846 : loss : 0.016179, loss_ce: 0.006493
2021-11-30 15:28:33,127 iteration 4847 : loss : 0.017947, loss_ce: 0.006593
2021-11-30 15:28:34,697 iteration 4848 : loss : 0.026247, loss_ce: 0.012793
2021-11-30 15:28:36,231 iteration 4849 : loss : 0.016613, loss_ce: 0.003817
2021-11-30 15:28:37,719 iteration 4850 : loss : 0.017807, loss_ce: 0.004975
2021-11-30 15:28:39,330 iteration 4851 : loss : 0.015129, loss_ce: 0.005927
2021-11-30 15:28:40,838 iteration 4852 : loss : 0.017938, loss_ce: 0.006364
2021-11-30 15:28:42,363 iteration 4853 : loss : 0.017672, loss_ce: 0.007347
2021-11-30 15:28:43,897 iteration 4854 : loss : 0.018628, loss_ce: 0.006788
2021-11-30 15:28:45,387 iteration 4855 : loss : 0.022501, loss_ce: 0.006088
2021-11-30 15:28:47,007 iteration 4856 : loss : 0.023255, loss_ce: 0.008793
2021-11-30 15:28:48,502 iteration 4857 : loss : 0.014279, loss_ce: 0.005346
2021-11-30 15:28:50,109 iteration 4858 : loss : 0.017657, loss_ce: 0.006437
2021-11-30 15:28:51,579 iteration 4859 : loss : 0.012790, loss_ce: 0.005049
2021-11-30 15:28:53,143 iteration 4860 : loss : 0.019803, loss_ce: 0.008281
2021-11-30 15:28:54,637 iteration 4861 : loss : 0.022175, loss_ce: 0.007985
2021-11-30 15:28:56,192 iteration 4862 : loss : 0.015825, loss_ce: 0.007796
 72%|████████████████████▋        | 286/400 [2:13:46<54:50, 28.86s/it]2021-11-30 15:28:57,830 iteration 4863 : loss : 0.021164, loss_ce: 0.007855
2021-11-30 15:28:59,330 iteration 4864 : loss : 0.016590, loss_ce: 0.005900
2021-11-30 15:29:00,821 iteration 4865 : loss : 0.015836, loss_ce: 0.007060
2021-11-30 15:29:02,399 iteration 4866 : loss : 0.020867, loss_ce: 0.007161
2021-11-30 15:29:03,911 iteration 4867 : loss : 0.016653, loss_ce: 0.005796
2021-11-30 15:29:05,335 iteration 4868 : loss : 0.015741, loss_ce: 0.006697
2021-11-30 15:29:06,953 iteration 4869 : loss : 0.020211, loss_ce: 0.009101
2021-11-30 15:29:08,470 iteration 4870 : loss : 0.014940, loss_ce: 0.005756
2021-11-30 15:29:10,081 iteration 4871 : loss : 0.022240, loss_ce: 0.008433
2021-11-30 15:29:11,536 iteration 4872 : loss : 0.013221, loss_ce: 0.004178
2021-11-30 15:29:13,149 iteration 4873 : loss : 0.018095, loss_ce: 0.007135
2021-11-30 15:29:14,681 iteration 4874 : loss : 0.038818, loss_ce: 0.013242
2021-11-30 15:29:16,192 iteration 4875 : loss : 0.022391, loss_ce: 0.008184
2021-11-30 15:29:17,631 iteration 4876 : loss : 0.020026, loss_ce: 0.005950
2021-11-30 15:29:19,206 iteration 4877 : loss : 0.021258, loss_ce: 0.010673
2021-11-30 15:29:20,814 iteration 4878 : loss : 0.026428, loss_ce: 0.008708
2021-11-30 15:29:22,345 iteration 4879 : loss : 0.015439, loss_ce: 0.005499
 72%|████████████████████▊        | 287/400 [2:14:12<52:49, 28.05s/it]2021-11-30 15:29:23,885 iteration 4880 : loss : 0.018553, loss_ce: 0.007289
2021-11-30 15:29:25,361 iteration 4881 : loss : 0.015118, loss_ce: 0.006149
2021-11-30 15:29:26,807 iteration 4882 : loss : 0.015127, loss_ce: 0.006620
2021-11-30 15:29:28,347 iteration 4883 : loss : 0.019154, loss_ce: 0.007556
2021-11-30 15:29:29,907 iteration 4884 : loss : 0.016152, loss_ce: 0.004866
2021-11-30 15:29:31,338 iteration 4885 : loss : 0.015158, loss_ce: 0.005908
2021-11-30 15:29:32,848 iteration 4886 : loss : 0.023711, loss_ce: 0.005522
2021-11-30 15:29:34,295 iteration 4887 : loss : 0.014549, loss_ce: 0.004318
2021-11-30 15:29:35,839 iteration 4888 : loss : 0.027621, loss_ce: 0.007719
2021-11-30 15:29:37,360 iteration 4889 : loss : 0.027765, loss_ce: 0.014090
2021-11-30 15:29:38,835 iteration 4890 : loss : 0.016800, loss_ce: 0.008445
2021-11-30 15:29:40,253 iteration 4891 : loss : 0.012902, loss_ce: 0.004670
2021-11-30 15:29:41,832 iteration 4892 : loss : 0.016558, loss_ce: 0.006436
2021-11-30 15:29:43,341 iteration 4893 : loss : 0.023537, loss_ce: 0.011516
2021-11-30 15:29:44,848 iteration 4894 : loss : 0.016201, loss_ce: 0.006810
2021-11-30 15:29:46,338 iteration 4895 : loss : 0.018555, loss_ce: 0.004264
2021-11-30 15:29:47,825 iteration 4896 : loss : 0.018954, loss_ce: 0.005270
 72%|████████████████████▉        | 288/400 [2:14:38<50:55, 27.28s/it]2021-11-30 15:29:49,349 iteration 4897 : loss : 0.016383, loss_ce: 0.006453
2021-11-30 15:29:50,909 iteration 4898 : loss : 0.031770, loss_ce: 0.014838
2021-11-30 15:29:52,415 iteration 4899 : loss : 0.011837, loss_ce: 0.003326
2021-11-30 15:29:53,915 iteration 4900 : loss : 0.017312, loss_ce: 0.006500
2021-11-30 15:29:55,419 iteration 4901 : loss : 0.020820, loss_ce: 0.005352
2021-11-30 15:29:56,942 iteration 4902 : loss : 0.011877, loss_ce: 0.003866
2021-11-30 15:29:58,495 iteration 4903 : loss : 0.017207, loss_ce: 0.008242
2021-11-30 15:29:59,927 iteration 4904 : loss : 0.015730, loss_ce: 0.004678
2021-11-30 15:30:01,416 iteration 4905 : loss : 0.017243, loss_ce: 0.004859
2021-11-30 15:30:02,981 iteration 4906 : loss : 0.018260, loss_ce: 0.006264
2021-11-30 15:30:04,467 iteration 4907 : loss : 0.017147, loss_ce: 0.006110
2021-11-30 15:30:06,059 iteration 4908 : loss : 0.024292, loss_ce: 0.010523
2021-11-30 15:30:07,613 iteration 4909 : loss : 0.014757, loss_ce: 0.004691
2021-11-30 15:30:09,087 iteration 4910 : loss : 0.015752, loss_ce: 0.007428
2021-11-30 15:30:10,584 iteration 4911 : loss : 0.015725, loss_ce: 0.005560
2021-11-30 15:30:12,125 iteration 4912 : loss : 0.023953, loss_ce: 0.011382
2021-11-30 15:30:13,647 iteration 4913 : loss : 0.022227, loss_ce: 0.008945
 72%|████████████████████▉        | 289/400 [2:15:04<49:39, 26.84s/it]2021-11-30 15:30:15,262 iteration 4914 : loss : 0.020396, loss_ce: 0.007341
2021-11-30 15:30:16,759 iteration 4915 : loss : 0.017197, loss_ce: 0.006172
2021-11-30 15:30:18,272 iteration 4916 : loss : 0.015522, loss_ce: 0.004148
2021-11-30 15:30:19,784 iteration 4917 : loss : 0.013929, loss_ce: 0.004279
2021-11-30 15:30:21,327 iteration 4918 : loss : 0.019954, loss_ce: 0.007682
2021-11-30 15:30:23,023 iteration 4919 : loss : 0.023696, loss_ce: 0.010356
2021-11-30 15:30:24,518 iteration 4920 : loss : 0.014650, loss_ce: 0.005432
2021-11-30 15:30:25,993 iteration 4921 : loss : 0.019033, loss_ce: 0.010075
2021-11-30 15:30:27,447 iteration 4922 : loss : 0.018428, loss_ce: 0.005015
2021-11-30 15:30:29,016 iteration 4923 : loss : 0.020333, loss_ce: 0.007222
2021-11-30 15:30:30,617 iteration 4924 : loss : 0.024632, loss_ce: 0.013984
2021-11-30 15:30:32,173 iteration 4925 : loss : 0.015424, loss_ce: 0.005880
2021-11-30 15:30:33,759 iteration 4926 : loss : 0.022567, loss_ce: 0.010256
2021-11-30 15:30:35,263 iteration 4927 : loss : 0.016095, loss_ce: 0.004838
2021-11-30 15:30:36,845 iteration 4928 : loss : 0.026200, loss_ce: 0.010104
2021-11-30 15:30:38,448 iteration 4929 : loss : 0.022383, loss_ce: 0.009138
2021-11-30 15:30:38,449 Training Data Eval:
2021-11-30 15:30:46,118   Average segmentation loss on training set: 0.0115
2021-11-30 15:30:46,119 Validation Data Eval:
2021-11-30 15:30:48,761   Average segmentation loss on validation set: 0.0617
2021-11-30 15:30:50,734 Found new lowest validation loss at iteration 4929! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/UNET_RUNMC/ADAM/ADAM_best_val_loss.pth
2021-11-30 15:30:52,185 iteration 4930 : loss : 0.021536, loss_ce: 0.006534
 72%|█████████████████████        | 290/400 [2:15:42<55:38, 30.35s/it]2021-11-30 15:30:53,648 iteration 4931 : loss : 0.019884, loss_ce: 0.009718
2021-11-30 15:30:55,106 iteration 4932 : loss : 0.019412, loss_ce: 0.009439
2021-11-30 15:30:56,516 iteration 4933 : loss : 0.015040, loss_ce: 0.006980
2021-11-30 15:30:58,086 iteration 4934 : loss : 0.026137, loss_ce: 0.007920
2021-11-30 15:30:59,616 iteration 4935 : loss : 0.018713, loss_ce: 0.005942
2021-11-30 15:31:01,176 iteration 4936 : loss : 0.022322, loss_ce: 0.008026
2021-11-30 15:31:02,745 iteration 4937 : loss : 0.020167, loss_ce: 0.010287
2021-11-30 15:31:04,332 iteration 4938 : loss : 0.028163, loss_ce: 0.009606
2021-11-30 15:31:05,918 iteration 4939 : loss : 0.022402, loss_ce: 0.008608
2021-11-30 15:31:07,435 iteration 4940 : loss : 0.020284, loss_ce: 0.008408
2021-11-30 15:31:08,975 iteration 4941 : loss : 0.019133, loss_ce: 0.008368
2021-11-30 15:31:10,503 iteration 4942 : loss : 0.019662, loss_ce: 0.006637
2021-11-30 15:31:12,113 iteration 4943 : loss : 0.038182, loss_ce: 0.009592
2021-11-30 15:31:13,637 iteration 4944 : loss : 0.019476, loss_ce: 0.005951
2021-11-30 15:31:15,212 iteration 4945 : loss : 0.022267, loss_ce: 0.008163
2021-11-30 15:31:16,787 iteration 4946 : loss : 0.029210, loss_ce: 0.008482
2021-11-30 15:31:18,281 iteration 4947 : loss : 0.030028, loss_ce: 0.010901
 73%|█████████████████████        | 291/400 [2:16:08<52:49, 29.07s/it]2021-11-30 15:31:19,857 iteration 4948 : loss : 0.025229, loss_ce: 0.009932
2021-11-30 15:31:21,354 iteration 4949 : loss : 0.022062, loss_ce: 0.009656
2021-11-30 15:31:22,912 iteration 4950 : loss : 0.025379, loss_ce: 0.010654
2021-11-30 15:31:24,465 iteration 4951 : loss : 0.023167, loss_ce: 0.007651
2021-11-30 15:31:26,009 iteration 4952 : loss : 0.016876, loss_ce: 0.008802
2021-11-30 15:31:27,584 iteration 4953 : loss : 0.023504, loss_ce: 0.009869
2021-11-30 15:31:29,088 iteration 4954 : loss : 0.014822, loss_ce: 0.004682
2021-11-30 15:31:30,568 iteration 4955 : loss : 0.019837, loss_ce: 0.005564
2021-11-30 15:31:32,091 iteration 4956 : loss : 0.019216, loss_ce: 0.005373
2021-11-30 15:31:33,541 iteration 4957 : loss : 0.015016, loss_ce: 0.005961
2021-11-30 15:31:35,087 iteration 4958 : loss : 0.026456, loss_ce: 0.014454
2021-11-30 15:31:36,629 iteration 4959 : loss : 0.018541, loss_ce: 0.006296
2021-11-30 15:31:38,086 iteration 4960 : loss : 0.017576, loss_ce: 0.006479
2021-11-30 15:31:39,621 iteration 4961 : loss : 0.019238, loss_ce: 0.008164
2021-11-30 15:31:41,102 iteration 4962 : loss : 0.032481, loss_ce: 0.007040
2021-11-30 15:31:42,617 iteration 4963 : loss : 0.018420, loss_ce: 0.007088
2021-11-30 15:31:44,189 iteration 4964 : loss : 0.022635, loss_ce: 0.007387
 73%|█████████████████████▏       | 292/400 [2:16:34<50:37, 28.12s/it]2021-11-30 15:31:45,801 iteration 4965 : loss : 0.022884, loss_ce: 0.009447
2021-11-30 15:31:47,378 iteration 4966 : loss : 0.022863, loss_ce: 0.009551
2021-11-30 15:31:48,924 iteration 4967 : loss : 0.025707, loss_ce: 0.014942
2021-11-30 15:31:50,472 iteration 4968 : loss : 0.017043, loss_ce: 0.007827
2021-11-30 15:31:52,095 iteration 4969 : loss : 0.033871, loss_ce: 0.013924
2021-11-30 15:31:53,569 iteration 4970 : loss : 0.014745, loss_ce: 0.005872
2021-11-30 15:31:55,081 iteration 4971 : loss : 0.016917, loss_ce: 0.008584
2021-11-30 15:31:56,645 iteration 4972 : loss : 0.021926, loss_ce: 0.009940
2021-11-30 15:31:58,190 iteration 4973 : loss : 0.023200, loss_ce: 0.008709
2021-11-30 15:31:59,849 iteration 4974 : loss : 0.024629, loss_ce: 0.007937
2021-11-30 15:32:01,352 iteration 4975 : loss : 0.016513, loss_ce: 0.005000
2021-11-30 15:32:02,818 iteration 4976 : loss : 0.014595, loss_ce: 0.005452
2021-11-30 15:32:04,369 iteration 4977 : loss : 0.022142, loss_ce: 0.005173
2021-11-30 15:32:05,869 iteration 4978 : loss : 0.014597, loss_ce: 0.004353
2021-11-30 15:32:07,394 iteration 4979 : loss : 0.022121, loss_ce: 0.009326
2021-11-30 15:32:08,930 iteration 4980 : loss : 0.019518, loss_ce: 0.005390
2021-11-30 15:32:10,453 iteration 4981 : loss : 0.024492, loss_ce: 0.008690
 73%|█████████████████████▏       | 293/400 [2:17:00<49:09, 27.57s/it]2021-11-30 15:32:11,996 iteration 4982 : loss : 0.014547, loss_ce: 0.006789
2021-11-30 15:32:13,507 iteration 4983 : loss : 0.017588, loss_ce: 0.006732
2021-11-30 15:32:15,121 iteration 4984 : loss : 0.021691, loss_ce: 0.008365
2021-11-30 15:32:16,580 iteration 4985 : loss : 0.014978, loss_ce: 0.004021
2021-11-30 15:32:18,195 iteration 4986 : loss : 0.020554, loss_ce: 0.009101
2021-11-30 15:32:19,684 iteration 4987 : loss : 0.020397, loss_ce: 0.006737
2021-11-30 15:32:21,223 iteration 4988 : loss : 0.021364, loss_ce: 0.006288
2021-11-30 15:32:22,799 iteration 4989 : loss : 0.020464, loss_ce: 0.007704
2021-11-30 15:32:24,415 iteration 4990 : loss : 0.020367, loss_ce: 0.009313
2021-11-30 15:32:25,947 iteration 4991 : loss : 0.020643, loss_ce: 0.005921
2021-11-30 15:32:27,379 iteration 4992 : loss : 0.014604, loss_ce: 0.006596
2021-11-30 15:32:28,897 iteration 4993 : loss : 0.018625, loss_ce: 0.006324
2021-11-30 15:32:30,379 iteration 4994 : loss : 0.016453, loss_ce: 0.005572
2021-11-30 15:32:31,869 iteration 4995 : loss : 0.017994, loss_ce: 0.008471
2021-11-30 15:32:33,433 iteration 4996 : loss : 0.021322, loss_ce: 0.005840
2021-11-30 15:32:34,887 iteration 4997 : loss : 0.015680, loss_ce: 0.004836
2021-11-30 15:32:36,360 iteration 4998 : loss : 0.016509, loss_ce: 0.006182
 74%|█████████████████████▎       | 294/400 [2:17:26<47:49, 27.07s/it]2021-11-30 15:32:37,911 iteration 4999 : loss : 0.015383, loss_ce: 0.006000
2021-11-30 15:32:39,425 iteration 5000 : loss : 0.016108, loss_ce: 0.006217
2021-11-30 15:32:40,920 iteration 5001 : loss : 0.017863, loss_ce: 0.008792
2021-11-30 15:32:42,413 iteration 5002 : loss : 0.013784, loss_ce: 0.005092
2021-11-30 15:32:43,961 iteration 5003 : loss : 0.033351, loss_ce: 0.008036
2021-11-30 15:32:45,470 iteration 5004 : loss : 0.019711, loss_ce: 0.006359
2021-11-30 15:32:46,993 iteration 5005 : loss : 0.018880, loss_ce: 0.008099
2021-11-30 15:32:48,571 iteration 5006 : loss : 0.020475, loss_ce: 0.008047
2021-11-30 15:32:50,134 iteration 5007 : loss : 0.034169, loss_ce: 0.014454
2021-11-30 15:32:51,695 iteration 5008 : loss : 0.025880, loss_ce: 0.010428
2021-11-30 15:32:53,270 iteration 5009 : loss : 0.018117, loss_ce: 0.004886
2021-11-30 15:32:54,823 iteration 5010 : loss : 0.023643, loss_ce: 0.008932
2021-11-30 15:32:56,340 iteration 5011 : loss : 0.017986, loss_ce: 0.008150
2021-11-30 15:32:57,877 iteration 5012 : loss : 0.015960, loss_ce: 0.006166
2021-11-30 15:32:59,355 iteration 5013 : loss : 0.016936, loss_ce: 0.006290
2021-11-30 15:33:00,886 iteration 5014 : loss : 0.021925, loss_ce: 0.007241
2021-11-30 15:33:00,886 Training Data Eval:
2021-11-30 15:33:08,548   Average segmentation loss on training set: 0.0113
2021-11-30 15:33:08,548 Validation Data Eval:
2021-11-30 15:33:11,185   Average segmentation loss on validation set: 0.0786
2021-11-30 15:33:12,717 iteration 5015 : loss : 0.015607, loss_ce: 0.004979
 74%|█████████████████████▍       | 295/400 [2:18:03<52:14, 29.85s/it]2021-11-30 15:33:14,275 iteration 5016 : loss : 0.017996, loss_ce: 0.008421
2021-11-30 15:33:15,781 iteration 5017 : loss : 0.023507, loss_ce: 0.011378
2021-11-30 15:33:17,303 iteration 5018 : loss : 0.017511, loss_ce: 0.007142
2021-11-30 15:33:18,846 iteration 5019 : loss : 0.016097, loss_ce: 0.005160
2021-11-30 15:33:20,395 iteration 5020 : loss : 0.024771, loss_ce: 0.007516
2021-11-30 15:33:21,974 iteration 5021 : loss : 0.019282, loss_ce: 0.010584
2021-11-30 15:33:23,450 iteration 5022 : loss : 0.018054, loss_ce: 0.006038
2021-11-30 15:33:24,974 iteration 5023 : loss : 0.033592, loss_ce: 0.009560
2021-11-30 15:33:26,593 iteration 5024 : loss : 0.026231, loss_ce: 0.006105
2021-11-30 15:33:28,199 iteration 5025 : loss : 0.045595, loss_ce: 0.008931
2021-11-30 15:33:29,748 iteration 5026 : loss : 0.018167, loss_ce: 0.006321
2021-11-30 15:33:31,227 iteration 5027 : loss : 0.015905, loss_ce: 0.006664
2021-11-30 15:33:32,726 iteration 5028 : loss : 0.025540, loss_ce: 0.009152
2021-11-30 15:33:34,334 iteration 5029 : loss : 0.018174, loss_ce: 0.003959
2021-11-30 15:33:35,859 iteration 5030 : loss : 0.019498, loss_ce: 0.009180
2021-11-30 15:33:37,448 iteration 5031 : loss : 0.022597, loss_ce: 0.009581
2021-11-30 15:33:38,984 iteration 5032 : loss : 0.021657, loss_ce: 0.010117
 74%|█████████████████████▍       | 296/400 [2:18:29<49:52, 28.78s/it]2021-11-30 15:33:40,656 iteration 5033 : loss : 0.027167, loss_ce: 0.009748
2021-11-30 15:33:42,160 iteration 5034 : loss : 0.021625, loss_ce: 0.006151
2021-11-30 15:33:43,659 iteration 5035 : loss : 0.021364, loss_ce: 0.009102
2021-11-30 15:33:45,162 iteration 5036 : loss : 0.020950, loss_ce: 0.007568
2021-11-30 15:33:46,709 iteration 5037 : loss : 0.024850, loss_ce: 0.009876
2021-11-30 15:33:48,204 iteration 5038 : loss : 0.025314, loss_ce: 0.005434
2021-11-30 15:33:49,809 iteration 5039 : loss : 0.026411, loss_ce: 0.013307
2021-11-30 15:33:51,335 iteration 5040 : loss : 0.032507, loss_ce: 0.011320
2021-11-30 15:33:52,933 iteration 5041 : loss : 0.018567, loss_ce: 0.006130
2021-11-30 15:33:54,410 iteration 5042 : loss : 0.014842, loss_ce: 0.005894
2021-11-30 15:33:55,940 iteration 5043 : loss : 0.016666, loss_ce: 0.007495
2021-11-30 15:33:57,473 iteration 5044 : loss : 0.031830, loss_ce: 0.016284
2021-11-30 15:33:59,054 iteration 5045 : loss : 0.023654, loss_ce: 0.009397
2021-11-30 15:34:00,583 iteration 5046 : loss : 0.020352, loss_ce: 0.005552
2021-11-30 15:34:02,099 iteration 5047 : loss : 0.029438, loss_ce: 0.007880
2021-11-30 15:34:03,607 iteration 5048 : loss : 0.018184, loss_ce: 0.006858
2021-11-30 15:34:05,141 iteration 5049 : loss : 0.015417, loss_ce: 0.005882
 74%|█████████████████████▌       | 297/400 [2:18:55<48:03, 27.99s/it]2021-11-30 15:34:06,717 iteration 5050 : loss : 0.025147, loss_ce: 0.008165
2021-11-30 15:34:08,229 iteration 5051 : loss : 0.023877, loss_ce: 0.008907
2021-11-30 15:34:09,753 iteration 5052 : loss : 0.017637, loss_ce: 0.007275
2021-11-30 15:34:11,280 iteration 5053 : loss : 0.014157, loss_ce: 0.005416
2021-11-30 15:34:12,806 iteration 5054 : loss : 0.015459, loss_ce: 0.005065
2021-11-30 15:34:14,314 iteration 5055 : loss : 0.017928, loss_ce: 0.006067
2021-11-30 15:34:15,819 iteration 5056 : loss : 0.033528, loss_ce: 0.008829
2021-11-30 15:34:17,407 iteration 5057 : loss : 0.016091, loss_ce: 0.007878
2021-11-30 15:34:18,979 iteration 5058 : loss : 0.025504, loss_ce: 0.010224
2021-11-30 15:34:20,403 iteration 5059 : loss : 0.021140, loss_ce: 0.005584
2021-11-30 15:34:21,939 iteration 5060 : loss : 0.020212, loss_ce: 0.005901
2021-11-30 15:34:23,503 iteration 5061 : loss : 0.019862, loss_ce: 0.008185
2021-11-30 15:34:25,058 iteration 5062 : loss : 0.027404, loss_ce: 0.008452
2021-11-30 15:34:26,639 iteration 5063 : loss : 0.019964, loss_ce: 0.007677
2021-11-30 15:34:28,120 iteration 5064 : loss : 0.019198, loss_ce: 0.006910
2021-11-30 15:34:29,627 iteration 5065 : loss : 0.031663, loss_ce: 0.011415
2021-11-30 15:34:31,155 iteration 5066 : loss : 0.013317, loss_ce: 0.006441
 74%|█████████████████████▌       | 298/400 [2:19:21<46:34, 27.40s/it]2021-11-30 15:34:32,794 iteration 5067 : loss : 0.021329, loss_ce: 0.008983
2021-11-30 15:34:34,347 iteration 5068 : loss : 0.023191, loss_ce: 0.010210
2021-11-30 15:34:35,898 iteration 5069 : loss : 0.025098, loss_ce: 0.009154
2021-11-30 15:34:37,419 iteration 5070 : loss : 0.018416, loss_ce: 0.005115
2021-11-30 15:34:39,017 iteration 5071 : loss : 0.029653, loss_ce: 0.011748
2021-11-30 15:34:40,435 iteration 5072 : loss : 0.018548, loss_ce: 0.006013
2021-11-30 15:34:41,963 iteration 5073 : loss : 0.018056, loss_ce: 0.008440
2021-11-30 15:34:43,553 iteration 5074 : loss : 0.018713, loss_ce: 0.005931
2021-11-30 15:34:45,073 iteration 5075 : loss : 0.018915, loss_ce: 0.007851
2021-11-30 15:34:46,655 iteration 5076 : loss : 0.022388, loss_ce: 0.008815
2021-11-30 15:34:48,168 iteration 5077 : loss : 0.022665, loss_ce: 0.007861
2021-11-30 15:34:49,694 iteration 5078 : loss : 0.017311, loss_ce: 0.004845
2021-11-30 15:34:51,204 iteration 5079 : loss : 0.014745, loss_ce: 0.005725
2021-11-30 15:34:52,744 iteration 5080 : loss : 0.018663, loss_ce: 0.007017
2021-11-30 15:34:54,308 iteration 5081 : loss : 0.020549, loss_ce: 0.009018
2021-11-30 15:34:55,890 iteration 5082 : loss : 0.027036, loss_ce: 0.014550
2021-11-30 15:34:57,434 iteration 5083 : loss : 0.019369, loss_ce: 0.005829
 75%|█████████████████████▋       | 299/400 [2:19:47<45:33, 27.06s/it]2021-11-30 15:34:58,980 iteration 5084 : loss : 0.016069, loss_ce: 0.005367
2021-11-30 15:35:00,503 iteration 5085 : loss : 0.024011, loss_ce: 0.008527
2021-11-30 15:35:01,998 iteration 5086 : loss : 0.016046, loss_ce: 0.005638
2021-11-30 15:35:03,573 iteration 5087 : loss : 0.023144, loss_ce: 0.007927
2021-11-30 15:35:05,124 iteration 5088 : loss : 0.018478, loss_ce: 0.006512
2021-11-30 15:35:06,599 iteration 5089 : loss : 0.019952, loss_ce: 0.006482
2021-11-30 15:35:08,105 iteration 5090 : loss : 0.013535, loss_ce: 0.004405
2021-11-30 15:35:09,723 iteration 5091 : loss : 0.025139, loss_ce: 0.010212
2021-11-30 15:35:11,250 iteration 5092 : loss : 0.014401, loss_ce: 0.006845
2021-11-30 15:35:12,745 iteration 5093 : loss : 0.018077, loss_ce: 0.007968
2021-11-30 15:35:14,223 iteration 5094 : loss : 0.015872, loss_ce: 0.005830
2021-11-30 15:35:15,785 iteration 5095 : loss : 0.027227, loss_ce: 0.009197
2021-11-30 15:35:17,261 iteration 5096 : loss : 0.014628, loss_ce: 0.005493
2021-11-30 15:35:18,775 iteration 5097 : loss : 0.015334, loss_ce: 0.006345
2021-11-30 15:35:20,314 iteration 5098 : loss : 0.027974, loss_ce: 0.009174
2021-11-30 15:35:21,834 iteration 5099 : loss : 0.019982, loss_ce: 0.006473
2021-11-30 15:35:21,834 Training Data Eval:
2021-11-30 15:35:29,509   Average segmentation loss on training set: 0.0115
2021-11-30 15:35:29,509 Validation Data Eval:
2021-11-30 15:35:32,140   Average segmentation loss on validation set: 0.0620
2021-11-30 15:35:33,673 iteration 5100 : loss : 0.017228, loss_ce: 0.008294
 75%|█████████████████████▊       | 300/400 [2:20:24<49:41, 29.82s/it]2021-11-30 15:35:35,259 iteration 5101 : loss : 0.018968, loss_ce: 0.008601
2021-11-30 15:35:36,762 iteration 5102 : loss : 0.014927, loss_ce: 0.005940
2021-11-30 15:35:38,287 iteration 5103 : loss : 0.018460, loss_ce: 0.007432
2021-11-30 15:35:39,873 iteration 5104 : loss : 0.024249, loss_ce: 0.009036
2021-11-30 15:35:41,350 iteration 5105 : loss : 0.017155, loss_ce: 0.005999
2021-11-30 15:35:42,935 iteration 5106 : loss : 0.018918, loss_ce: 0.006464
2021-11-30 15:35:44,424 iteration 5107 : loss : 0.014623, loss_ce: 0.005736
2021-11-30 15:35:45,976 iteration 5108 : loss : 0.020346, loss_ce: 0.007213
2021-11-30 15:35:47,505 iteration 5109 : loss : 0.026676, loss_ce: 0.007612
2021-11-30 15:35:49,033 iteration 5110 : loss : 0.022960, loss_ce: 0.009994
2021-11-30 15:35:50,596 iteration 5111 : loss : 0.017537, loss_ce: 0.006213
2021-11-30 15:35:52,070 iteration 5112 : loss : 0.018001, loss_ce: 0.005273
2021-11-30 15:35:53,651 iteration 5113 : loss : 0.069182, loss_ce: 0.014180
2021-11-30 15:35:55,157 iteration 5114 : loss : 0.019218, loss_ce: 0.009093
2021-11-30 15:35:56,648 iteration 5115 : loss : 0.019969, loss_ce: 0.005274
2021-11-30 15:35:58,132 iteration 5116 : loss : 0.016060, loss_ce: 0.006154
2021-11-30 15:35:59,710 iteration 5117 : loss : 0.022523, loss_ce: 0.010327
 75%|█████████████████████▊       | 301/400 [2:20:50<47:19, 28.68s/it]2021-11-30 15:36:01,290 iteration 5118 : loss : 0.012326, loss_ce: 0.004418
2021-11-30 15:36:02,833 iteration 5119 : loss : 0.024293, loss_ce: 0.007735
2021-11-30 15:36:04,318 iteration 5120 : loss : 0.017907, loss_ce: 0.004526
2021-11-30 15:36:05,847 iteration 5121 : loss : 0.018902, loss_ce: 0.008759
2021-11-30 15:36:07,330 iteration 5122 : loss : 0.018723, loss_ce: 0.006699
2021-11-30 15:36:08,861 iteration 5123 : loss : 0.018841, loss_ce: 0.005197
2021-11-30 15:36:10,408 iteration 5124 : loss : 0.016122, loss_ce: 0.006704
2021-11-30 15:36:11,856 iteration 5125 : loss : 0.018049, loss_ce: 0.008936
2021-11-30 15:36:13,334 iteration 5126 : loss : 0.023595, loss_ce: 0.007926
2021-11-30 15:36:14,899 iteration 5127 : loss : 0.025335, loss_ce: 0.009170
2021-11-30 15:36:16,420 iteration 5128 : loss : 0.012906, loss_ce: 0.005032
2021-11-30 15:36:17,958 iteration 5129 : loss : 0.020114, loss_ce: 0.005871
2021-11-30 15:36:19,470 iteration 5130 : loss : 0.019633, loss_ce: 0.005992
2021-11-30 15:36:20,911 iteration 5131 : loss : 0.011911, loss_ce: 0.004310
2021-11-30 15:36:22,435 iteration 5132 : loss : 0.019543, loss_ce: 0.008473
2021-11-30 15:36:23,912 iteration 5133 : loss : 0.019521, loss_ce: 0.005123
2021-11-30 15:36:25,386 iteration 5134 : loss : 0.019146, loss_ce: 0.008084
 76%|█████████████████████▉       | 302/400 [2:21:15<45:22, 27.78s/it]2021-11-30 15:36:27,083 iteration 5135 : loss : 0.022483, loss_ce: 0.008528
2021-11-30 15:36:28,591 iteration 5136 : loss : 0.025550, loss_ce: 0.008049
2021-11-30 15:36:30,160 iteration 5137 : loss : 0.023032, loss_ce: 0.007219
2021-11-30 15:36:31,652 iteration 5138 : loss : 0.017444, loss_ce: 0.006945
2021-11-30 15:36:33,177 iteration 5139 : loss : 0.014554, loss_ce: 0.005023
2021-11-30 15:36:34,805 iteration 5140 : loss : 0.015889, loss_ce: 0.006183
2021-11-30 15:36:36,286 iteration 5141 : loss : 0.021660, loss_ce: 0.006833
2021-11-30 15:36:37,815 iteration 5142 : loss : 0.037675, loss_ce: 0.013185
2021-11-30 15:36:39,253 iteration 5143 : loss : 0.015431, loss_ce: 0.005908
2021-11-30 15:36:40,796 iteration 5144 : loss : 0.019813, loss_ce: 0.010556
2021-11-30 15:36:42,244 iteration 5145 : loss : 0.016241, loss_ce: 0.005335
2021-11-30 15:36:43,834 iteration 5146 : loss : 0.028717, loss_ce: 0.012608
2021-11-30 15:36:45,423 iteration 5147 : loss : 0.025060, loss_ce: 0.009113
2021-11-30 15:36:46,935 iteration 5148 : loss : 0.017056, loss_ce: 0.006961
2021-11-30 15:36:48,428 iteration 5149 : loss : 0.024592, loss_ce: 0.006096
2021-11-30 15:36:49,926 iteration 5150 : loss : 0.013024, loss_ce: 0.004937
2021-11-30 15:36:51,468 iteration 5151 : loss : 0.036248, loss_ce: 0.006989
 76%|█████████████████████▉       | 303/400 [2:21:41<44:05, 27.27s/it]2021-11-30 15:36:52,981 iteration 5152 : loss : 0.016244, loss_ce: 0.003545
2021-11-30 15:36:54,435 iteration 5153 : loss : 0.013835, loss_ce: 0.005498
2021-11-30 15:36:56,016 iteration 5154 : loss : 0.022283, loss_ce: 0.009359
2021-11-30 15:36:57,469 iteration 5155 : loss : 0.014896, loss_ce: 0.004705
2021-11-30 15:36:58,971 iteration 5156 : loss : 0.028295, loss_ce: 0.010857
2021-11-30 15:37:00,436 iteration 5157 : loss : 0.016009, loss_ce: 0.004718
2021-11-30 15:37:01,944 iteration 5158 : loss : 0.021571, loss_ce: 0.007708
2021-11-30 15:37:03,508 iteration 5159 : loss : 0.020930, loss_ce: 0.006802
2021-11-30 15:37:04,958 iteration 5160 : loss : 0.013615, loss_ce: 0.004798
2021-11-30 15:37:06,470 iteration 5161 : loss : 0.015303, loss_ce: 0.006102
2021-11-30 15:37:07,953 iteration 5162 : loss : 0.017786, loss_ce: 0.008058
2021-11-30 15:37:09,497 iteration 5163 : loss : 0.017554, loss_ce: 0.007863
2021-11-30 15:37:11,033 iteration 5164 : loss : 0.018566, loss_ce: 0.008910
2021-11-30 15:37:12,498 iteration 5165 : loss : 0.018992, loss_ce: 0.006115
2021-11-30 15:37:14,046 iteration 5166 : loss : 0.016598, loss_ce: 0.007071
2021-11-30 15:37:15,574 iteration 5167 : loss : 0.024681, loss_ce: 0.008455
2021-11-30 15:37:17,145 iteration 5168 : loss : 0.017941, loss_ce: 0.006363
 76%|██████████████████████       | 304/400 [2:22:07<42:52, 26.79s/it]2021-11-30 15:37:18,804 iteration 5169 : loss : 0.028530, loss_ce: 0.013712
2021-11-30 15:37:20,279 iteration 5170 : loss : 0.016128, loss_ce: 0.005097
2021-11-30 15:37:21,839 iteration 5171 : loss : 0.016394, loss_ce: 0.006177
2021-11-30 15:37:23,278 iteration 5172 : loss : 0.014967, loss_ce: 0.004905
2021-11-30 15:37:24,685 iteration 5173 : loss : 0.013566, loss_ce: 0.005618
2021-11-30 15:37:26,277 iteration 5174 : loss : 0.018588, loss_ce: 0.006869
2021-11-30 15:37:27,764 iteration 5175 : loss : 0.016476, loss_ce: 0.007446
2021-11-30 15:37:29,400 iteration 5176 : loss : 0.025697, loss_ce: 0.008773
2021-11-30 15:37:30,868 iteration 5177 : loss : 0.019769, loss_ce: 0.008507
2021-11-30 15:37:32,371 iteration 5178 : loss : 0.014640, loss_ce: 0.004579
2021-11-30 15:37:33,949 iteration 5179 : loss : 0.018141, loss_ce: 0.005489
2021-11-30 15:37:35,480 iteration 5180 : loss : 0.016318, loss_ce: 0.005510
2021-11-30 15:37:36,953 iteration 5181 : loss : 0.016815, loss_ce: 0.003926
2021-11-30 15:37:38,467 iteration 5182 : loss : 0.017506, loss_ce: 0.006602
2021-11-30 15:37:39,989 iteration 5183 : loss : 0.020757, loss_ce: 0.009602
2021-11-30 15:37:41,486 iteration 5184 : loss : 0.034164, loss_ce: 0.012154
2021-11-30 15:37:41,487 Training Data Eval:
2021-11-30 15:37:49,167   Average segmentation loss on training set: 0.0116
2021-11-30 15:37:49,167 Validation Data Eval:
2021-11-30 15:37:51,803   Average segmentation loss on validation set: 0.0742
2021-11-30 15:37:53,334 iteration 5185 : loss : 0.018355, loss_ce: 0.006498
 76%|██████████████████████       | 305/400 [2:22:43<46:53, 29.61s/it]2021-11-30 15:37:54,916 iteration 5186 : loss : 0.016485, loss_ce: 0.008112
2021-11-30 15:37:56,398 iteration 5187 : loss : 0.018327, loss_ce: 0.007092
2021-11-30 15:37:57,885 iteration 5188 : loss : 0.013984, loss_ce: 0.005673
2021-11-30 15:37:59,378 iteration 5189 : loss : 0.016873, loss_ce: 0.007383
2021-11-30 15:38:00,859 iteration 5190 : loss : 0.019651, loss_ce: 0.008051
2021-11-30 15:38:02,425 iteration 5191 : loss : 0.017672, loss_ce: 0.005392
2021-11-30 15:38:03,986 iteration 5192 : loss : 0.020629, loss_ce: 0.007251
2021-11-30 15:38:05,465 iteration 5193 : loss : 0.011974, loss_ce: 0.003864
2021-11-30 15:38:07,026 iteration 5194 : loss : 0.023063, loss_ce: 0.008879
2021-11-30 15:38:08,520 iteration 5195 : loss : 0.014782, loss_ce: 0.004748
2021-11-30 15:38:09,949 iteration 5196 : loss : 0.012035, loss_ce: 0.003178
2021-11-30 15:38:11,416 iteration 5197 : loss : 0.015566, loss_ce: 0.004832
2021-11-30 15:38:12,891 iteration 5198 : loss : 0.015091, loss_ce: 0.006535
2021-11-30 15:38:14,444 iteration 5199 : loss : 0.013407, loss_ce: 0.004509
2021-11-30 15:38:15,960 iteration 5200 : loss : 0.033499, loss_ce: 0.009158
2021-11-30 15:38:17,504 iteration 5201 : loss : 0.019242, loss_ce: 0.005851
2021-11-30 15:38:19,114 iteration 5202 : loss : 0.027019, loss_ce: 0.011629
 76%|██████████████████████▏      | 306/400 [2:23:09<44:35, 28.46s/it]2021-11-30 15:38:20,634 iteration 5203 : loss : 0.015861, loss_ce: 0.006166
2021-11-30 15:38:22,123 iteration 5204 : loss : 0.017604, loss_ce: 0.007515
2021-11-30 15:38:23,759 iteration 5205 : loss : 0.022725, loss_ce: 0.010792
2021-11-30 15:38:25,290 iteration 5206 : loss : 0.034697, loss_ce: 0.012445
2021-11-30 15:38:26,808 iteration 5207 : loss : 0.018197, loss_ce: 0.008028
2021-11-30 15:38:28,393 iteration 5208 : loss : 0.026468, loss_ce: 0.009521
2021-11-30 15:38:29,855 iteration 5209 : loss : 0.017473, loss_ce: 0.006862
2021-11-30 15:38:31,430 iteration 5210 : loss : 0.020237, loss_ce: 0.007682
2021-11-30 15:38:32,962 iteration 5211 : loss : 0.017625, loss_ce: 0.007716
2021-11-30 15:38:34,479 iteration 5212 : loss : 0.017861, loss_ce: 0.006196
2021-11-30 15:38:35,909 iteration 5213 : loss : 0.015205, loss_ce: 0.005559
2021-11-30 15:38:37,520 iteration 5214 : loss : 0.025485, loss_ce: 0.012017
2021-11-30 15:38:39,067 iteration 5215 : loss : 0.020381, loss_ce: 0.006295
2021-11-30 15:38:40,630 iteration 5216 : loss : 0.019596, loss_ce: 0.006204
2021-11-30 15:38:42,232 iteration 5217 : loss : 0.023457, loss_ce: 0.007837
2021-11-30 15:38:43,731 iteration 5218 : loss : 0.025140, loss_ce: 0.004238
2021-11-30 15:38:45,343 iteration 5219 : loss : 0.019856, loss_ce: 0.006281
 77%|██████████████████████▎      | 307/400 [2:23:35<43:04, 27.79s/it]2021-11-30 15:38:46,882 iteration 5220 : loss : 0.026739, loss_ce: 0.007251
2021-11-30 15:38:48,388 iteration 5221 : loss : 0.022957, loss_ce: 0.008168
2021-11-30 15:38:49,868 iteration 5222 : loss : 0.015460, loss_ce: 0.005725
2021-11-30 15:38:51,422 iteration 5223 : loss : 0.022210, loss_ce: 0.008310
2021-11-30 15:38:52,926 iteration 5224 : loss : 0.018585, loss_ce: 0.006249
2021-11-30 15:38:54,494 iteration 5225 : loss : 0.017740, loss_ce: 0.005691
2021-11-30 15:38:56,012 iteration 5226 : loss : 0.019196, loss_ce: 0.007915
2021-11-30 15:38:57,601 iteration 5227 : loss : 0.035948, loss_ce: 0.013242
2021-11-30 15:38:59,089 iteration 5228 : loss : 0.016320, loss_ce: 0.004600
2021-11-30 15:39:00,721 iteration 5229 : loss : 0.021448, loss_ce: 0.008803
2021-11-30 15:39:02,133 iteration 5230 : loss : 0.013065, loss_ce: 0.005562
2021-11-30 15:39:03,671 iteration 5231 : loss : 0.017389, loss_ce: 0.006339
2021-11-30 15:39:05,204 iteration 5232 : loss : 0.018650, loss_ce: 0.005549
2021-11-30 15:39:06,760 iteration 5233 : loss : 0.018985, loss_ce: 0.006812
2021-11-30 15:39:08,262 iteration 5234 : loss : 0.017363, loss_ce: 0.007351
2021-11-30 15:39:09,785 iteration 5235 : loss : 0.022376, loss_ce: 0.007051
2021-11-30 15:39:11,344 iteration 5236 : loss : 0.024791, loss_ce: 0.008985
 77%|██████████████████████▎      | 308/400 [2:24:01<41:47, 27.25s/it]2021-11-30 15:39:12,791 iteration 5237 : loss : 0.013407, loss_ce: 0.005321
2021-11-30 15:39:14,362 iteration 5238 : loss : 0.017968, loss_ce: 0.007423
2021-11-30 15:39:15,900 iteration 5239 : loss : 0.016216, loss_ce: 0.005673
2021-11-30 15:39:17,458 iteration 5240 : loss : 0.171339, loss_ce: 0.002912
2021-11-30 15:39:18,946 iteration 5241 : loss : 0.016237, loss_ce: 0.006247
2021-11-30 15:39:20,463 iteration 5242 : loss : 0.018501, loss_ce: 0.007880
2021-11-30 15:39:22,061 iteration 5243 : loss : 0.029396, loss_ce: 0.010309
2021-11-30 15:39:23,611 iteration 5244 : loss : 0.017415, loss_ce: 0.006937
2021-11-30 15:39:25,148 iteration 5245 : loss : 0.019857, loss_ce: 0.006601
2021-11-30 15:39:26,706 iteration 5246 : loss : 0.025568, loss_ce: 0.006441
2021-11-30 15:39:28,166 iteration 5247 : loss : 0.012753, loss_ce: 0.005061
2021-11-30 15:39:29,724 iteration 5248 : loss : 0.039610, loss_ce: 0.015472
2021-11-30 15:39:31,318 iteration 5249 : loss : 0.020220, loss_ce: 0.006823
2021-11-30 15:39:32,878 iteration 5250 : loss : 0.019055, loss_ce: 0.008479
2021-11-30 15:39:34,325 iteration 5251 : loss : 0.013891, loss_ce: 0.004724
2021-11-30 15:39:35,856 iteration 5252 : loss : 0.016940, loss_ce: 0.006856
2021-11-30 15:39:37,402 iteration 5253 : loss : 0.028807, loss_ce: 0.006645
 77%|██████████████████████▍      | 309/400 [2:24:27<40:47, 26.90s/it]2021-11-30 15:39:38,956 iteration 5254 : loss : 0.011424, loss_ce: 0.004102
2021-11-30 15:39:40,479 iteration 5255 : loss : 0.023807, loss_ce: 0.012066
2021-11-30 15:39:41,931 iteration 5256 : loss : 0.018498, loss_ce: 0.006907
2021-11-30 15:39:43,462 iteration 5257 : loss : 0.017437, loss_ce: 0.007050
2021-11-30 15:39:45,042 iteration 5258 : loss : 0.014729, loss_ce: 0.004003
2021-11-30 15:39:46,513 iteration 5259 : loss : 0.019954, loss_ce: 0.004927
2021-11-30 15:39:48,049 iteration 5260 : loss : 0.016551, loss_ce: 0.005747
2021-11-30 15:39:49,589 iteration 5261 : loss : 0.020488, loss_ce: 0.008217
2021-11-30 15:39:51,132 iteration 5262 : loss : 0.012235, loss_ce: 0.004640
2021-11-30 15:39:52,653 iteration 5263 : loss : 0.018160, loss_ce: 0.007492
2021-11-30 15:39:54,125 iteration 5264 : loss : 0.015020, loss_ce: 0.007150
2021-11-30 15:39:55,682 iteration 5265 : loss : 0.020054, loss_ce: 0.007401
2021-11-30 15:39:57,305 iteration 5266 : loss : 0.024156, loss_ce: 0.008240
2021-11-30 15:39:58,820 iteration 5267 : loss : 0.028392, loss_ce: 0.006552
2021-11-30 15:40:00,350 iteration 5268 : loss : 0.022495, loss_ce: 0.005512
2021-11-30 15:40:01,964 iteration 5269 : loss : 0.022848, loss_ce: 0.006364
2021-11-30 15:40:01,965 Training Data Eval:
2021-11-30 15:40:09,636   Average segmentation loss on training set: 0.0116
2021-11-30 15:40:09,637 Validation Data Eval:
2021-11-30 15:40:12,272   Average segmentation loss on validation set: 0.0769
2021-11-30 15:40:13,803 iteration 5270 : loss : 0.014907, loss_ce: 0.006319
 78%|██████████████████████▍      | 310/400 [2:25:04<44:37, 29.75s/it]2021-11-30 15:40:15,338 iteration 5271 : loss : 0.017127, loss_ce: 0.008344
2021-11-30 15:40:16,915 iteration 5272 : loss : 0.016873, loss_ce: 0.007691
2021-11-30 15:40:18,404 iteration 5273 : loss : 0.015834, loss_ce: 0.004524
2021-11-30 15:40:19,911 iteration 5274 : loss : 0.017652, loss_ce: 0.006344
2021-11-30 15:40:21,372 iteration 5275 : loss : 0.015118, loss_ce: 0.006592
2021-11-30 15:40:22,925 iteration 5276 : loss : 0.018015, loss_ce: 0.006830
2021-11-30 15:40:24,463 iteration 5277 : loss : 0.021625, loss_ce: 0.007132
2021-11-30 15:40:25,917 iteration 5278 : loss : 0.014646, loss_ce: 0.005745
2021-11-30 15:40:27,442 iteration 5279 : loss : 0.016421, loss_ce: 0.007322
2021-11-30 15:40:29,099 iteration 5280 : loss : 0.023436, loss_ce: 0.008176
2021-11-30 15:40:30,604 iteration 5281 : loss : 0.016441, loss_ce: 0.005747
2021-11-30 15:40:32,065 iteration 5282 : loss : 0.012645, loss_ce: 0.003809
2021-11-30 15:40:33,590 iteration 5283 : loss : 0.021799, loss_ce: 0.007705
2021-11-30 15:40:35,144 iteration 5284 : loss : 0.024910, loss_ce: 0.007153
2021-11-30 15:40:36,651 iteration 5285 : loss : 0.020795, loss_ce: 0.009564
2021-11-30 15:40:38,084 iteration 5286 : loss : 0.013781, loss_ce: 0.005762
2021-11-30 15:40:39,594 iteration 5287 : loss : 0.016651, loss_ce: 0.003450
 78%|██████████████████████▌      | 311/400 [2:25:30<42:21, 28.56s/it]2021-11-30 15:40:41,175 iteration 5288 : loss : 0.019569, loss_ce: 0.007665
2021-11-30 15:40:42,731 iteration 5289 : loss : 0.020698, loss_ce: 0.005991
2021-11-30 15:40:44,238 iteration 5290 : loss : 0.025159, loss_ce: 0.005680
2021-11-30 15:40:45,742 iteration 5291 : loss : 0.021094, loss_ce: 0.006813
2021-11-30 15:40:47,298 iteration 5292 : loss : 0.017783, loss_ce: 0.006767
2021-11-30 15:40:48,861 iteration 5293 : loss : 0.018697, loss_ce: 0.008036
2021-11-30 15:40:50,420 iteration 5294 : loss : 0.021548, loss_ce: 0.007587
2021-11-30 15:40:52,016 iteration 5295 : loss : 0.024891, loss_ce: 0.009043
2021-11-30 15:40:53,568 iteration 5296 : loss : 0.020443, loss_ce: 0.005449
2021-11-30 15:40:55,133 iteration 5297 : loss : 0.015026, loss_ce: 0.004399
2021-11-30 15:40:56,696 iteration 5298 : loss : 0.019383, loss_ce: 0.007307
2021-11-30 15:40:58,248 iteration 5299 : loss : 0.017084, loss_ce: 0.005566
2021-11-30 15:40:59,839 iteration 5300 : loss : 0.025218, loss_ce: 0.010085
2021-11-30 15:41:01,299 iteration 5301 : loss : 0.017644, loss_ce: 0.006488
2021-11-30 15:41:02,785 iteration 5302 : loss : 0.015804, loss_ce: 0.007549
2021-11-30 15:41:04,263 iteration 5303 : loss : 0.018029, loss_ce: 0.006609
2021-11-30 15:41:05,717 iteration 5304 : loss : 0.017918, loss_ce: 0.006675
 78%|██████████████████████▌      | 312/400 [2:25:56<40:49, 27.83s/it]2021-11-30 15:41:07,311 iteration 5305 : loss : 0.019697, loss_ce: 0.006688
2021-11-30 15:41:08,928 iteration 5306 : loss : 0.020967, loss_ce: 0.009471
2021-11-30 15:41:10,538 iteration 5307 : loss : 0.022154, loss_ce: 0.008344
2021-11-30 15:41:12,137 iteration 5308 : loss : 0.028956, loss_ce: 0.008567
2021-11-30 15:41:13,719 iteration 5309 : loss : 0.026456, loss_ce: 0.007454
2021-11-30 15:41:15,219 iteration 5310 : loss : 0.016632, loss_ce: 0.007813
2021-11-30 15:41:16,716 iteration 5311 : loss : 0.022907, loss_ce: 0.005851
2021-11-30 15:41:18,307 iteration 5312 : loss : 0.019584, loss_ce: 0.008381
2021-11-30 15:41:19,929 iteration 5313 : loss : 0.020877, loss_ce: 0.005235
2021-11-30 15:41:21,451 iteration 5314 : loss : 0.019718, loss_ce: 0.007165
2021-11-30 15:41:23,036 iteration 5315 : loss : 0.040325, loss_ce: 0.009820
2021-11-30 15:41:24,608 iteration 5316 : loss : 0.023458, loss_ce: 0.008622
2021-11-30 15:41:26,131 iteration 5317 : loss : 0.017355, loss_ce: 0.007776
2021-11-30 15:41:27,612 iteration 5318 : loss : 0.016177, loss_ce: 0.006647
2021-11-30 15:41:29,206 iteration 5319 : loss : 0.020276, loss_ce: 0.008391
2021-11-30 15:41:30,764 iteration 5320 : loss : 0.021292, loss_ce: 0.009234
2021-11-30 15:41:32,355 iteration 5321 : loss : 0.021373, loss_ce: 0.008178
 78%|██████████████████████▋      | 313/400 [2:26:22<39:49, 27.47s/it]2021-11-30 15:41:33,847 iteration 5322 : loss : 0.017657, loss_ce: 0.008522
2021-11-30 15:41:35,390 iteration 5323 : loss : 0.021739, loss_ce: 0.008757
2021-11-30 15:41:36,840 iteration 5324 : loss : 0.020161, loss_ce: 0.006639
2021-11-30 15:41:38,326 iteration 5325 : loss : 0.031449, loss_ce: 0.007398
2021-11-30 15:41:39,887 iteration 5326 : loss : 0.020132, loss_ce: 0.006860
2021-11-30 15:41:41,371 iteration 5327 : loss : 0.016429, loss_ce: 0.005844
2021-11-30 15:41:42,882 iteration 5328 : loss : 0.014453, loss_ce: 0.006308
2021-11-30 15:41:44,445 iteration 5329 : loss : 0.030729, loss_ce: 0.009703
2021-11-30 15:41:45,987 iteration 5330 : loss : 0.017752, loss_ce: 0.006520
2021-11-30 15:41:47,516 iteration 5331 : loss : 0.019850, loss_ce: 0.006719
2021-11-30 15:41:49,062 iteration 5332 : loss : 0.019884, loss_ce: 0.007284
2021-11-30 15:41:50,617 iteration 5333 : loss : 0.015344, loss_ce: 0.006552
2021-11-30 15:41:52,152 iteration 5334 : loss : 0.022062, loss_ce: 0.008979
2021-11-30 15:41:53,717 iteration 5335 : loss : 0.031418, loss_ce: 0.009906
2021-11-30 15:41:55,253 iteration 5336 : loss : 0.016534, loss_ce: 0.005900
2021-11-30 15:41:56,746 iteration 5337 : loss : 0.016112, loss_ce: 0.005730
2021-11-30 15:41:58,234 iteration 5338 : loss : 0.016101, loss_ce: 0.006110
 78%|██████████████████████▊      | 314/400 [2:26:48<38:41, 26.99s/it]2021-11-30 15:41:59,952 iteration 5339 : loss : 0.021788, loss_ce: 0.008763
2021-11-30 15:42:01,515 iteration 5340 : loss : 0.019910, loss_ce: 0.010406
2021-11-30 15:42:03,057 iteration 5341 : loss : 0.020173, loss_ce: 0.003571
2021-11-30 15:42:04,607 iteration 5342 : loss : 0.017194, loss_ce: 0.008888
2021-11-30 15:42:06,124 iteration 5343 : loss : 0.014886, loss_ce: 0.004289
2021-11-30 15:42:07,664 iteration 5344 : loss : 0.019408, loss_ce: 0.008014
2021-11-30 15:42:09,186 iteration 5345 : loss : 0.015082, loss_ce: 0.005005
2021-11-30 15:42:10,742 iteration 5346 : loss : 0.021100, loss_ce: 0.007316
2021-11-30 15:42:12,324 iteration 5347 : loss : 0.015560, loss_ce: 0.004265
2021-11-30 15:42:13,899 iteration 5348 : loss : 0.016305, loss_ce: 0.004447
2021-11-30 15:42:15,439 iteration 5349 : loss : 0.018914, loss_ce: 0.007439
2021-11-30 15:42:16,908 iteration 5350 : loss : 0.013298, loss_ce: 0.004999
2021-11-30 15:42:18,402 iteration 5351 : loss : 0.025505, loss_ce: 0.009302
2021-11-30 15:42:19,974 iteration 5352 : loss : 0.020007, loss_ce: 0.008730
2021-11-30 15:42:21,547 iteration 5353 : loss : 0.014668, loss_ce: 0.005015
2021-11-30 15:42:23,040 iteration 5354 : loss : 0.015375, loss_ce: 0.006808
2021-11-30 15:42:23,040 Training Data Eval:
2021-11-30 15:42:30,672   Average segmentation loss on training set: 0.0114
2021-11-30 15:42:30,672 Validation Data Eval:
2021-11-30 15:42:33,300   Average segmentation loss on validation set: 0.0715
2021-11-30 15:42:34,779 iteration 5355 : loss : 0.016164, loss_ce: 0.005742
 79%|██████████████████████▊      | 315/400 [2:27:25<42:18, 29.86s/it]2021-11-30 15:42:36,351 iteration 5356 : loss : 0.016099, loss_ce: 0.007489
2021-11-30 15:42:37,819 iteration 5357 : loss : 0.021901, loss_ce: 0.004831
2021-11-30 15:42:39,474 iteration 5358 : loss : 0.025008, loss_ce: 0.010565
2021-11-30 15:42:40,947 iteration 5359 : loss : 0.013162, loss_ce: 0.004712
2021-11-30 15:42:42,502 iteration 5360 : loss : 0.019440, loss_ce: 0.007731
2021-11-30 15:42:44,066 iteration 5361 : loss : 0.020575, loss_ce: 0.006566
2021-11-30 15:42:45,621 iteration 5362 : loss : 0.021731, loss_ce: 0.006414
2021-11-30 15:42:47,147 iteration 5363 : loss : 0.019867, loss_ce: 0.007493
2021-11-30 15:42:48,677 iteration 5364 : loss : 0.027935, loss_ce: 0.005748
2021-11-30 15:42:50,199 iteration 5365 : loss : 0.014146, loss_ce: 0.005529
2021-11-30 15:42:51,745 iteration 5366 : loss : 0.017124, loss_ce: 0.006148
2021-11-30 15:42:53,327 iteration 5367 : loss : 0.017257, loss_ce: 0.006886
2021-11-30 15:42:54,840 iteration 5368 : loss : 0.014335, loss_ce: 0.006591
2021-11-30 15:42:56,395 iteration 5369 : loss : 0.013764, loss_ce: 0.004729
2021-11-30 15:42:57,898 iteration 5370 : loss : 0.012233, loss_ce: 0.004712
2021-11-30 15:42:59,434 iteration 5371 : loss : 0.015641, loss_ce: 0.007327
2021-11-30 15:43:00,939 iteration 5372 : loss : 0.015215, loss_ce: 0.005161
 79%|██████████████████████▉      | 316/400 [2:27:51<40:15, 28.75s/it]2021-11-30 15:43:02,522 iteration 5373 : loss : 0.017483, loss_ce: 0.008320
2021-11-30 15:43:04,009 iteration 5374 : loss : 0.018151, loss_ce: 0.008437
2021-11-30 15:43:05,557 iteration 5375 : loss : 0.019555, loss_ce: 0.008046
2021-11-30 15:43:07,060 iteration 5376 : loss : 0.016664, loss_ce: 0.006392
2021-11-30 15:43:08,561 iteration 5377 : loss : 0.015568, loss_ce: 0.004687
2021-11-30 15:43:10,093 iteration 5378 : loss : 0.019469, loss_ce: 0.006899
2021-11-30 15:43:11,555 iteration 5379 : loss : 0.015331, loss_ce: 0.006208
2021-11-30 15:43:13,080 iteration 5380 : loss : 0.017470, loss_ce: 0.007464
2021-11-30 15:43:14,569 iteration 5381 : loss : 0.019401, loss_ce: 0.007659
2021-11-30 15:43:16,125 iteration 5382 : loss : 0.014637, loss_ce: 0.004166
2021-11-30 15:43:17,729 iteration 5383 : loss : 0.024073, loss_ce: 0.010503
2021-11-30 15:43:19,398 iteration 5384 : loss : 0.021593, loss_ce: 0.007529
2021-11-30 15:43:20,913 iteration 5385 : loss : 0.016051, loss_ce: 0.005657
2021-11-30 15:43:22,353 iteration 5386 : loss : 0.014701, loss_ce: 0.004798
2021-11-30 15:43:23,855 iteration 5387 : loss : 0.020647, loss_ce: 0.009928
2021-11-30 15:43:25,414 iteration 5388 : loss : 0.018370, loss_ce: 0.005848
2021-11-30 15:43:27,051 iteration 5389 : loss : 0.025187, loss_ce: 0.008518
 79%|██████████████████████▉      | 317/400 [2:28:17<38:40, 27.96s/it]2021-11-30 15:43:28,598 iteration 5390 : loss : 0.025332, loss_ce: 0.012919
2021-11-30 15:43:30,170 iteration 5391 : loss : 0.023857, loss_ce: 0.008097
2021-11-30 15:43:31,739 iteration 5392 : loss : 0.019890, loss_ce: 0.010945
2021-11-30 15:43:33,278 iteration 5393 : loss : 0.022823, loss_ce: 0.006833
2021-11-30 15:43:34,774 iteration 5394 : loss : 0.018276, loss_ce: 0.007795
2021-11-30 15:43:36,317 iteration 5395 : loss : 0.017930, loss_ce: 0.005163
2021-11-30 15:43:37,789 iteration 5396 : loss : 0.023840, loss_ce: 0.014660
2021-11-30 15:43:39,388 iteration 5397 : loss : 0.022715, loss_ce: 0.007866
2021-11-30 15:43:40,924 iteration 5398 : loss : 0.018548, loss_ce: 0.006821
2021-11-30 15:43:42,388 iteration 5399 : loss : 0.021407, loss_ce: 0.006215
2021-11-30 15:43:44,001 iteration 5400 : loss : 0.037761, loss_ce: 0.011433
2021-11-30 15:43:45,575 iteration 5401 : loss : 0.018168, loss_ce: 0.008307
2021-11-30 15:43:47,103 iteration 5402 : loss : 0.018536, loss_ce: 0.005685
2021-11-30 15:43:48,587 iteration 5403 : loss : 0.025811, loss_ce: 0.010591
2021-11-30 15:43:50,075 iteration 5404 : loss : 0.015940, loss_ce: 0.004557
2021-11-30 15:43:51,584 iteration 5405 : loss : 0.018517, loss_ce: 0.007736
2021-11-30 15:43:53,153 iteration 5406 : loss : 0.018823, loss_ce: 0.006131
 80%|███████████████████████      | 318/400 [2:28:43<37:26, 27.40s/it]2021-11-30 15:43:54,750 iteration 5407 : loss : 0.024123, loss_ce: 0.009553
2021-11-30 15:43:56,253 iteration 5408 : loss : 0.028919, loss_ce: 0.009181
2021-11-30 15:43:57,870 iteration 5409 : loss : 0.019832, loss_ce: 0.008576
2021-11-30 15:43:59,359 iteration 5410 : loss : 0.021141, loss_ce: 0.008731
2021-11-30 15:44:00,880 iteration 5411 : loss : 0.022983, loss_ce: 0.010848
2021-11-30 15:44:02,408 iteration 5412 : loss : 0.018097, loss_ce: 0.007773
2021-11-30 15:44:03,920 iteration 5413 : loss : 0.019730, loss_ce: 0.008552
2021-11-30 15:44:05,452 iteration 5414 : loss : 0.018610, loss_ce: 0.007189
2021-11-30 15:44:07,064 iteration 5415 : loss : 0.022678, loss_ce: 0.009235
2021-11-30 15:44:08,532 iteration 5416 : loss : 0.012796, loss_ce: 0.004230
2021-11-30 15:44:10,113 iteration 5417 : loss : 0.014054, loss_ce: 0.004342
2021-11-30 15:44:11,628 iteration 5418 : loss : 0.020019, loss_ce: 0.007728
2021-11-30 15:44:13,171 iteration 5419 : loss : 0.025102, loss_ce: 0.006259
2021-11-30 15:44:14,754 iteration 5420 : loss : 0.020419, loss_ce: 0.007359
2021-11-30 15:44:16,307 iteration 5421 : loss : 0.021164, loss_ce: 0.010503
2021-11-30 15:44:17,718 iteration 5422 : loss : 0.013097, loss_ce: 0.005618
2021-11-30 15:44:19,277 iteration 5423 : loss : 0.027320, loss_ce: 0.006492
 80%|███████████████████████▏     | 319/400 [2:29:09<36:28, 27.02s/it]2021-11-30 15:44:20,900 iteration 5424 : loss : 0.019891, loss_ce: 0.006582
2021-11-30 15:44:22,387 iteration 5425 : loss : 0.016737, loss_ce: 0.005708
2021-11-30 15:44:23,902 iteration 5426 : loss : 0.022481, loss_ce: 0.006362
2021-11-30 15:44:25,351 iteration 5427 : loss : 0.016983, loss_ce: 0.006843
2021-11-30 15:44:26,839 iteration 5428 : loss : 0.023804, loss_ce: 0.010128
2021-11-30 15:44:28,397 iteration 5429 : loss : 0.014114, loss_ce: 0.004764
2021-11-30 15:44:29,916 iteration 5430 : loss : 0.025328, loss_ce: 0.012440
2021-11-30 15:44:31,368 iteration 5431 : loss : 0.022522, loss_ce: 0.007563
2021-11-30 15:44:32,955 iteration 5432 : loss : 0.015346, loss_ce: 0.006486
2021-11-30 15:44:34,536 iteration 5433 : loss : 0.022648, loss_ce: 0.009269
2021-11-30 15:44:36,009 iteration 5434 : loss : 0.017059, loss_ce: 0.007219
2021-11-30 15:44:37,608 iteration 5435 : loss : 0.025276, loss_ce: 0.011263
2021-11-30 15:44:39,146 iteration 5436 : loss : 0.017264, loss_ce: 0.006331
2021-11-30 15:44:40,724 iteration 5437 : loss : 0.036766, loss_ce: 0.008312
2021-11-30 15:44:42,279 iteration 5438 : loss : 0.015565, loss_ce: 0.006254
2021-11-30 15:44:43,795 iteration 5439 : loss : 0.019102, loss_ce: 0.007930
2021-11-30 15:44:43,795 Training Data Eval:
2021-11-30 15:44:51,433   Average segmentation loss on training set: 0.0116
2021-11-30 15:44:51,434 Validation Data Eval:
2021-11-30 15:44:54,062   Average segmentation loss on validation set: 0.0771
2021-11-30 15:44:55,539 iteration 5440 : loss : 0.018167, loss_ce: 0.005576
 80%|███████████████████████▏     | 320/400 [2:29:46<39:43, 29.79s/it]2021-11-30 15:44:57,096 iteration 5441 : loss : 0.017709, loss_ce: 0.006379
2021-11-30 15:44:58,568 iteration 5442 : loss : 0.020169, loss_ce: 0.007412
2021-11-30 15:45:00,084 iteration 5443 : loss : 0.015663, loss_ce: 0.005528
2021-11-30 15:45:01,551 iteration 5444 : loss : 0.015439, loss_ce: 0.004926
2021-11-30 15:45:03,081 iteration 5445 : loss : 0.017450, loss_ce: 0.006374
2021-11-30 15:45:04,563 iteration 5446 : loss : 0.016823, loss_ce: 0.008016
2021-11-30 15:45:06,159 iteration 5447 : loss : 0.024261, loss_ce: 0.008633
2021-11-30 15:45:07,634 iteration 5448 : loss : 0.015126, loss_ce: 0.006534
2021-11-30 15:45:09,166 iteration 5449 : loss : 0.025042, loss_ce: 0.013897
2021-11-30 15:45:10,685 iteration 5450 : loss : 0.018599, loss_ce: 0.007746
2021-11-30 15:45:12,156 iteration 5451 : loss : 0.013803, loss_ce: 0.004611
2021-11-30 15:45:13,697 iteration 5452 : loss : 0.016793, loss_ce: 0.006371
2021-11-30 15:45:15,171 iteration 5453 : loss : 0.014874, loss_ce: 0.006105
2021-11-30 15:45:16,748 iteration 5454 : loss : 0.017205, loss_ce: 0.008310
2021-11-30 15:45:18,284 iteration 5455 : loss : 0.024632, loss_ce: 0.007610
2021-11-30 15:45:19,814 iteration 5456 : loss : 0.015398, loss_ce: 0.003240
2021-11-30 15:45:21,293 iteration 5457 : loss : 0.012976, loss_ce: 0.003807
 80%|███████████████████████▎     | 321/400 [2:30:11<37:38, 28.58s/it]2021-11-30 15:45:22,839 iteration 5458 : loss : 0.019128, loss_ce: 0.006069
2021-11-30 15:45:24,303 iteration 5459 : loss : 0.019590, loss_ce: 0.008646
2021-11-30 15:45:25,816 iteration 5460 : loss : 0.016471, loss_ce: 0.006304
2021-11-30 15:45:27,360 iteration 5461 : loss : 0.019608, loss_ce: 0.006704
2021-11-30 15:45:28,864 iteration 5462 : loss : 0.017274, loss_ce: 0.005762
2021-11-30 15:45:30,402 iteration 5463 : loss : 0.020549, loss_ce: 0.005712
2021-11-30 15:45:31,925 iteration 5464 : loss : 0.021021, loss_ce: 0.009270
2021-11-30 15:45:33,516 iteration 5465 : loss : 0.026743, loss_ce: 0.009584
2021-11-30 15:45:35,085 iteration 5466 : loss : 0.015244, loss_ce: 0.005681
2021-11-30 15:45:36,614 iteration 5467 : loss : 0.022240, loss_ce: 0.010432
2021-11-30 15:45:38,140 iteration 5468 : loss : 0.017479, loss_ce: 0.007004
2021-11-30 15:45:39,605 iteration 5469 : loss : 0.024508, loss_ce: 0.008194
2021-11-30 15:45:41,110 iteration 5470 : loss : 0.010839, loss_ce: 0.003833
2021-11-30 15:45:42,612 iteration 5471 : loss : 0.017835, loss_ce: 0.004418
2021-11-30 15:45:44,155 iteration 5472 : loss : 0.020814, loss_ce: 0.006912
2021-11-30 15:45:45,640 iteration 5473 : loss : 0.013632, loss_ce: 0.004803
2021-11-30 15:45:47,117 iteration 5474 : loss : 0.016192, loss_ce: 0.005057
 80%|███████████████████████▎     | 322/400 [2:30:37<36:04, 27.75s/it]2021-11-30 15:45:48,699 iteration 5475 : loss : 0.029169, loss_ce: 0.007580
2021-11-30 15:45:50,257 iteration 5476 : loss : 0.019871, loss_ce: 0.009135
2021-11-30 15:45:51,766 iteration 5477 : loss : 0.044027, loss_ce: 0.007035
2021-11-30 15:45:53,213 iteration 5478 : loss : 0.016169, loss_ce: 0.005152
2021-11-30 15:45:54,715 iteration 5479 : loss : 0.014651, loss_ce: 0.006085
2021-11-30 15:45:56,219 iteration 5480 : loss : 0.032951, loss_ce: 0.011673
2021-11-30 15:45:57,715 iteration 5481 : loss : 0.019241, loss_ce: 0.006882
2021-11-30 15:45:59,330 iteration 5482 : loss : 0.030783, loss_ce: 0.006972
2021-11-30 15:46:00,769 iteration 5483 : loss : 0.015278, loss_ce: 0.005560
2021-11-30 15:46:02,301 iteration 5484 : loss : 0.024872, loss_ce: 0.010308
2021-11-30 15:46:03,820 iteration 5485 : loss : 0.014566, loss_ce: 0.005962
2021-11-30 15:46:05,349 iteration 5486 : loss : 0.022443, loss_ce: 0.011226
2021-11-30 15:46:06,878 iteration 5487 : loss : 0.017144, loss_ce: 0.006656
2021-11-30 15:46:08,361 iteration 5488 : loss : 0.016351, loss_ce: 0.007395
2021-11-30 15:46:09,833 iteration 5489 : loss : 0.015194, loss_ce: 0.007987
2021-11-30 15:46:11,434 iteration 5490 : loss : 0.019946, loss_ce: 0.007495
2021-11-30 15:46:12,916 iteration 5491 : loss : 0.013355, loss_ce: 0.003929
 81%|███████████████████████▍     | 323/400 [2:31:03<34:51, 27.17s/it]2021-11-30 15:46:14,387 iteration 5492 : loss : 0.017564, loss_ce: 0.006359
2021-11-30 15:46:15,928 iteration 5493 : loss : 0.020759, loss_ce: 0.006204
2021-11-30 15:46:17,395 iteration 5494 : loss : 0.016662, loss_ce: 0.005162
2021-11-30 15:46:18,921 iteration 5495 : loss : 0.013816, loss_ce: 0.004152
2021-11-30 15:46:20,460 iteration 5496 : loss : 0.016763, loss_ce: 0.004821
2021-11-30 15:46:21,995 iteration 5497 : loss : 0.013746, loss_ce: 0.004952
2021-11-30 15:46:23,563 iteration 5498 : loss : 0.025474, loss_ce: 0.009281
2021-11-30 15:46:25,118 iteration 5499 : loss : 0.020250, loss_ce: 0.011159
2021-11-30 15:46:26,572 iteration 5500 : loss : 0.022669, loss_ce: 0.009207
2021-11-30 15:46:28,079 iteration 5501 : loss : 0.021039, loss_ce: 0.009382
2021-11-30 15:46:29,552 iteration 5502 : loss : 0.011804, loss_ce: 0.004995
2021-11-30 15:46:31,078 iteration 5503 : loss : 0.018813, loss_ce: 0.005016
2021-11-30 15:46:32,551 iteration 5504 : loss : 0.015671, loss_ce: 0.005829
2021-11-30 15:46:34,057 iteration 5505 : loss : 0.015406, loss_ce: 0.006181
2021-11-30 15:46:35,599 iteration 5506 : loss : 0.016290, loss_ce: 0.005977
2021-11-30 15:46:37,099 iteration 5507 : loss : 0.017966, loss_ce: 0.007931
2021-11-30 15:46:38,624 iteration 5508 : loss : 0.023585, loss_ce: 0.007583
 81%|███████████████████████▍     | 324/400 [2:31:29<33:51, 26.73s/it]2021-11-30 15:46:40,181 iteration 5509 : loss : 0.020784, loss_ce: 0.006238
2021-11-30 15:46:41,770 iteration 5510 : loss : 0.022612, loss_ce: 0.008273
2021-11-30 15:46:43,259 iteration 5511 : loss : 0.015171, loss_ce: 0.005316
2021-11-30 15:46:44,819 iteration 5512 : loss : 0.018745, loss_ce: 0.007075
2021-11-30 15:46:46,306 iteration 5513 : loss : 0.012647, loss_ce: 0.005268
2021-11-30 15:46:47,756 iteration 5514 : loss : 0.011436, loss_ce: 0.003831
2021-11-30 15:46:49,335 iteration 5515 : loss : 0.027175, loss_ce: 0.006266
2021-11-30 15:46:50,836 iteration 5516 : loss : 0.018490, loss_ce: 0.007203
2021-11-30 15:46:52,376 iteration 5517 : loss : 0.016203, loss_ce: 0.007152
2021-11-30 15:46:53,899 iteration 5518 : loss : 0.020462, loss_ce: 0.006848
2021-11-30 15:46:55,433 iteration 5519 : loss : 0.020779, loss_ce: 0.007531
2021-11-30 15:46:56,960 iteration 5520 : loss : 0.014323, loss_ce: 0.006125
2021-11-30 15:46:58,497 iteration 5521 : loss : 0.021126, loss_ce: 0.008263
2021-11-30 15:47:00,008 iteration 5522 : loss : 0.019115, loss_ce: 0.006590
2021-11-30 15:47:01,482 iteration 5523 : loss : 0.012162, loss_ce: 0.004028
2021-11-30 15:47:02,998 iteration 5524 : loss : 0.018386, loss_ce: 0.007467
2021-11-30 15:47:02,998 Training Data Eval:
2021-11-30 15:47:10,641   Average segmentation loss on training set: 0.0104
2021-11-30 15:47:10,641 Validation Data Eval:
2021-11-30 15:47:13,269   Average segmentation loss on validation set: 0.0711
2021-11-30 15:47:14,777 iteration 5525 : loss : 0.016704, loss_ce: 0.007480
 81%|███████████████████████▌     | 325/400 [2:32:05<36:56, 29.56s/it]2021-11-30 15:47:16,385 iteration 5526 : loss : 0.014848, loss_ce: 0.005003
2021-11-30 15:47:17,908 iteration 5527 : loss : 0.017584, loss_ce: 0.008342
2021-11-30 15:47:19,433 iteration 5528 : loss : 0.019888, loss_ce: 0.007434
2021-11-30 15:47:20,959 iteration 5529 : loss : 0.024084, loss_ce: 0.010309
2021-11-30 15:47:22,424 iteration 5530 : loss : 0.015523, loss_ce: 0.006827
2021-11-30 15:47:23,938 iteration 5531 : loss : 0.016619, loss_ce: 0.007067
2021-11-30 15:47:25,414 iteration 5532 : loss : 0.011424, loss_ce: 0.004560
2021-11-30 15:47:26,986 iteration 5533 : loss : 0.018966, loss_ce: 0.005819
2021-11-30 15:47:28,498 iteration 5534 : loss : 0.018240, loss_ce: 0.006258
2021-11-30 15:47:30,088 iteration 5535 : loss : 0.017581, loss_ce: 0.006545
2021-11-30 15:47:31,687 iteration 5536 : loss : 0.014540, loss_ce: 0.005912
2021-11-30 15:47:33,220 iteration 5537 : loss : 0.022476, loss_ce: 0.008629
2021-11-30 15:47:34,749 iteration 5538 : loss : 0.015846, loss_ce: 0.006130
2021-11-30 15:47:36,358 iteration 5539 : loss : 0.026667, loss_ce: 0.006789
2021-11-30 15:47:37,844 iteration 5540 : loss : 0.015650, loss_ce: 0.007382
2021-11-30 15:47:39,378 iteration 5541 : loss : 0.019416, loss_ce: 0.007567
2021-11-30 15:47:40,891 iteration 5542 : loss : 0.014922, loss_ce: 0.006119
 82%|███████████████████████▋     | 326/400 [2:32:31<35:10, 28.52s/it]2021-11-30 15:47:42,472 iteration 5543 : loss : 0.024794, loss_ce: 0.008591
2021-11-30 15:47:43,994 iteration 5544 : loss : 0.017192, loss_ce: 0.007925
2021-11-30 15:47:45,481 iteration 5545 : loss : 0.015071, loss_ce: 0.005606
2021-11-30 15:47:46,950 iteration 5546 : loss : 0.015974, loss_ce: 0.005405
2021-11-30 15:47:48,475 iteration 5547 : loss : 0.017241, loss_ce: 0.006165
2021-11-30 15:47:50,042 iteration 5548 : loss : 0.041635, loss_ce: 0.014123
2021-11-30 15:47:51,494 iteration 5549 : loss : 0.017856, loss_ce: 0.007065
2021-11-30 15:47:52,987 iteration 5550 : loss : 0.014766, loss_ce: 0.005390
2021-11-30 15:47:54,521 iteration 5551 : loss : 0.021349, loss_ce: 0.008287
2021-11-30 15:47:55,973 iteration 5552 : loss : 0.012739, loss_ce: 0.004921
2021-11-30 15:47:57,504 iteration 5553 : loss : 0.026532, loss_ce: 0.010462
2021-11-30 15:47:59,058 iteration 5554 : loss : 0.022476, loss_ce: 0.007854
2021-11-30 15:48:00,631 iteration 5555 : loss : 0.024739, loss_ce: 0.006841
2021-11-30 15:48:02,082 iteration 5556 : loss : 0.016086, loss_ce: 0.006415
2021-11-30 15:48:03,651 iteration 5557 : loss : 0.026966, loss_ce: 0.007503
2021-11-30 15:48:05,161 iteration 5558 : loss : 0.016763, loss_ce: 0.005509
2021-11-30 15:48:06,592 iteration 5559 : loss : 0.013888, loss_ce: 0.005696
 82%|███████████████████████▋     | 327/400 [2:32:57<33:40, 27.68s/it]2021-11-30 15:48:08,302 iteration 5560 : loss : 0.034194, loss_ce: 0.012865
2021-11-30 15:48:09,798 iteration 5561 : loss : 0.019118, loss_ce: 0.006884
2021-11-30 15:48:11,308 iteration 5562 : loss : 0.021787, loss_ce: 0.006271
2021-11-30 15:48:12,834 iteration 5563 : loss : 0.016711, loss_ce: 0.006718
2021-11-30 15:48:14,436 iteration 5564 : loss : 0.017010, loss_ce: 0.005303
2021-11-30 15:48:15,940 iteration 5565 : loss : 0.014955, loss_ce: 0.006102
2021-11-30 15:48:17,485 iteration 5566 : loss : 0.014731, loss_ce: 0.006276
2021-11-30 15:48:19,092 iteration 5567 : loss : 0.017417, loss_ce: 0.007373
2021-11-30 15:48:20,602 iteration 5568 : loss : 0.021625, loss_ce: 0.008047
2021-11-30 15:48:22,143 iteration 5569 : loss : 0.017966, loss_ce: 0.007683
2021-11-30 15:48:23,673 iteration 5570 : loss : 0.015061, loss_ce: 0.005083
2021-11-30 15:48:25,251 iteration 5571 : loss : 0.023544, loss_ce: 0.010018
2021-11-30 15:48:26,774 iteration 5572 : loss : 0.014559, loss_ce: 0.005256
2021-11-30 15:48:28,284 iteration 5573 : loss : 0.043171, loss_ce: 0.013757
2021-11-30 15:48:29,897 iteration 5574 : loss : 0.020566, loss_ce: 0.007221
2021-11-30 15:48:31,309 iteration 5575 : loss : 0.012630, loss_ce: 0.005409
2021-11-30 15:48:32,720 iteration 5576 : loss : 0.014359, loss_ce: 0.004375
 82%|███████████████████████▊     | 328/400 [2:33:23<32:39, 27.21s/it]2021-11-30 15:48:34,272 iteration 5577 : loss : 0.015329, loss_ce: 0.005043
2021-11-30 15:48:35,760 iteration 5578 : loss : 0.017486, loss_ce: 0.004284
2021-11-30 15:48:37,259 iteration 5579 : loss : 0.013945, loss_ce: 0.004244
2021-11-30 15:48:38,806 iteration 5580 : loss : 0.014989, loss_ce: 0.006303
2021-11-30 15:48:40,308 iteration 5581 : loss : 0.015586, loss_ce: 0.005470
2021-11-30 15:48:41,860 iteration 5582 : loss : 0.018597, loss_ce: 0.005448
2021-11-30 15:48:43,369 iteration 5583 : loss : 0.035531, loss_ce: 0.010419
2021-11-30 15:48:44,975 iteration 5584 : loss : 0.022121, loss_ce: 0.009963
2021-11-30 15:48:46,470 iteration 5585 : loss : 0.019606, loss_ce: 0.006812
2021-11-30 15:48:47,980 iteration 5586 : loss : 0.019002, loss_ce: 0.008745
2021-11-30 15:48:49,500 iteration 5587 : loss : 0.021556, loss_ce: 0.010299
2021-11-30 15:48:51,088 iteration 5588 : loss : 0.020828, loss_ce: 0.007463
2021-11-30 15:48:52,643 iteration 5589 : loss : 0.021672, loss_ce: 0.008351
2021-11-30 15:48:54,152 iteration 5590 : loss : 0.019172, loss_ce: 0.007071
2021-11-30 15:48:55,681 iteration 5591 : loss : 0.016740, loss_ce: 0.007298
2021-11-30 15:48:57,181 iteration 5592 : loss : 0.015844, loss_ce: 0.005152
2021-11-30 15:48:58,696 iteration 5593 : loss : 0.015186, loss_ce: 0.008902
 82%|███████████████████████▊     | 329/400 [2:33:49<31:45, 26.84s/it]2021-11-30 15:49:00,282 iteration 5594 : loss : 0.017188, loss_ce: 0.006434
2021-11-30 15:49:01,788 iteration 5595 : loss : 0.017562, loss_ce: 0.008226
2021-11-30 15:49:03,278 iteration 5596 : loss : 0.011112, loss_ce: 0.003328
2021-11-30 15:49:04,814 iteration 5597 : loss : 0.016218, loss_ce: 0.005434
2021-11-30 15:49:06,399 iteration 5598 : loss : 0.021585, loss_ce: 0.008856
2021-11-30 15:49:07,960 iteration 5599 : loss : 0.013840, loss_ce: 0.004723
2021-11-30 15:49:09,491 iteration 5600 : loss : 0.015662, loss_ce: 0.006556
2021-11-30 15:49:11,041 iteration 5601 : loss : 0.015674, loss_ce: 0.004374
2021-11-30 15:49:12,518 iteration 5602 : loss : 0.016494, loss_ce: 0.004505
2021-11-30 15:49:14,093 iteration 5603 : loss : 0.026685, loss_ce: 0.012190
2021-11-30 15:49:15,575 iteration 5604 : loss : 0.016732, loss_ce: 0.007334
2021-11-30 15:49:17,062 iteration 5605 : loss : 0.014754, loss_ce: 0.004489
2021-11-30 15:49:18,643 iteration 5606 : loss : 0.017294, loss_ce: 0.005554
2021-11-30 15:49:20,172 iteration 5607 : loss : 0.018031, loss_ce: 0.006280
2021-11-30 15:49:21,813 iteration 5608 : loss : 0.024062, loss_ce: 0.012008
2021-11-30 15:49:23,295 iteration 5609 : loss : 0.018107, loss_ce: 0.007500
2021-11-30 15:49:23,295 Training Data Eval:
2021-11-30 15:49:30,934   Average segmentation loss on training set: 0.0106
2021-11-30 15:49:30,934 Validation Data Eval:
2021-11-30 15:49:33,561   Average segmentation loss on validation set: 0.0670
2021-11-30 15:49:35,126 iteration 5610 : loss : 0.018885, loss_ce: 0.007718
 82%|███████████████████████▉     | 330/400 [2:34:25<34:40, 29.72s/it]2021-11-30 15:49:36,735 iteration 5611 : loss : 0.018740, loss_ce: 0.007517
2021-11-30 15:49:38,264 iteration 5612 : loss : 0.018307, loss_ce: 0.005700
2021-11-30 15:49:39,771 iteration 5613 : loss : 0.024457, loss_ce: 0.011573
2021-11-30 15:49:41,292 iteration 5614 : loss : 0.019293, loss_ce: 0.006364
2021-11-30 15:49:42,841 iteration 5615 : loss : 0.018985, loss_ce: 0.006836
2021-11-30 15:49:44,400 iteration 5616 : loss : 0.016589, loss_ce: 0.005974
2021-11-30 15:49:45,915 iteration 5617 : loss : 0.012892, loss_ce: 0.004362
2021-11-30 15:49:47,379 iteration 5618 : loss : 0.016923, loss_ce: 0.007336
2021-11-30 15:49:48,940 iteration 5619 : loss : 0.024853, loss_ce: 0.008366
2021-11-30 15:49:50,510 iteration 5620 : loss : 0.015552, loss_ce: 0.004971
2021-11-30 15:49:51,998 iteration 5621 : loss : 0.018413, loss_ce: 0.006965
2021-11-30 15:49:53,594 iteration 5622 : loss : 0.019804, loss_ce: 0.007652
2021-11-30 15:49:55,071 iteration 5623 : loss : 0.020496, loss_ce: 0.005988
2021-11-30 15:49:56,600 iteration 5624 : loss : 0.015974, loss_ce: 0.007087
2021-11-30 15:49:58,149 iteration 5625 : loss : 0.024378, loss_ce: 0.010472
2021-11-30 15:49:59,683 iteration 5626 : loss : 0.016431, loss_ce: 0.006264
2021-11-30 15:50:01,216 iteration 5627 : loss : 0.020320, loss_ce: 0.006231
 83%|███████████████████████▉     | 331/400 [2:34:51<32:55, 28.63s/it]2021-11-30 15:50:02,669 iteration 5628 : loss : 0.014959, loss_ce: 0.005310
2021-11-30 15:50:04,210 iteration 5629 : loss : 0.016923, loss_ce: 0.007859
2021-11-30 15:50:05,737 iteration 5630 : loss : 0.013716, loss_ce: 0.004406
2021-11-30 15:50:07,344 iteration 5631 : loss : 0.019053, loss_ce: 0.008203
2021-11-30 15:50:08,796 iteration 5632 : loss : 0.016155, loss_ce: 0.006658
2021-11-30 15:50:10,355 iteration 5633 : loss : 0.026219, loss_ce: 0.009710
2021-11-30 15:50:11,840 iteration 5634 : loss : 0.014768, loss_ce: 0.005128
2021-11-30 15:50:13,393 iteration 5635 : loss : 0.017488, loss_ce: 0.005283
2021-11-30 15:50:14,867 iteration 5636 : loss : 0.012747, loss_ce: 0.005643
2021-11-30 15:50:16,410 iteration 5637 : loss : 0.019273, loss_ce: 0.008072
2021-11-30 15:50:17,833 iteration 5638 : loss : 0.013106, loss_ce: 0.004079
2021-11-30 15:50:19,303 iteration 5639 : loss : 0.016039, loss_ce: 0.004693
2021-11-30 15:50:20,802 iteration 5640 : loss : 0.015350, loss_ce: 0.007725
2021-11-30 15:50:22,348 iteration 5641 : loss : 0.015462, loss_ce: 0.008184
2021-11-30 15:50:23,847 iteration 5642 : loss : 0.017598, loss_ce: 0.003441
2021-11-30 15:50:25,428 iteration 5643 : loss : 0.012565, loss_ce: 0.003358
2021-11-30 15:50:26,972 iteration 5644 : loss : 0.017278, loss_ce: 0.006469
 83%|████████████████████████     | 332/400 [2:35:17<31:28, 27.77s/it]2021-11-30 15:50:28,621 iteration 5645 : loss : 0.021676, loss_ce: 0.008670
2021-11-30 15:50:30,111 iteration 5646 : loss : 0.017264, loss_ce: 0.005856
2021-11-30 15:50:31,628 iteration 5647 : loss : 0.016398, loss_ce: 0.008354
2021-11-30 15:50:33,184 iteration 5648 : loss : 0.019538, loss_ce: 0.006828
2021-11-30 15:50:34,731 iteration 5649 : loss : 0.016964, loss_ce: 0.007734
2021-11-30 15:50:36,256 iteration 5650 : loss : 0.015152, loss_ce: 0.005585
2021-11-30 15:50:37,763 iteration 5651 : loss : 0.018815, loss_ce: 0.009104
2021-11-30 15:50:39,212 iteration 5652 : loss : 0.017061, loss_ce: 0.007435
2021-11-30 15:50:40,713 iteration 5653 : loss : 0.015981, loss_ce: 0.005153
2021-11-30 15:50:42,177 iteration 5654 : loss : 0.015330, loss_ce: 0.004200
2021-11-30 15:50:43,735 iteration 5655 : loss : 0.020162, loss_ce: 0.007315
2021-11-30 15:50:45,252 iteration 5656 : loss : 0.014100, loss_ce: 0.004726
2021-11-30 15:50:46,753 iteration 5657 : loss : 0.013864, loss_ce: 0.005360
2021-11-30 15:50:48,262 iteration 5658 : loss : 0.016057, loss_ce: 0.008781
2021-11-30 15:50:49,766 iteration 5659 : loss : 0.018976, loss_ce: 0.004917
2021-11-30 15:50:51,222 iteration 5660 : loss : 0.014075, loss_ce: 0.005454
2021-11-30 15:50:52,820 iteration 5661 : loss : 0.016783, loss_ce: 0.005214
 83%|████████████████████████▏    | 333/400 [2:35:43<30:21, 27.19s/it]2021-11-30 15:50:54,361 iteration 5662 : loss : 0.019691, loss_ce: 0.004479
2021-11-30 15:50:55,884 iteration 5663 : loss : 0.019658, loss_ce: 0.007817
2021-11-30 15:50:57,420 iteration 5664 : loss : 0.022021, loss_ce: 0.006748
2021-11-30 15:50:58,860 iteration 5665 : loss : 0.014591, loss_ce: 0.005249
2021-11-30 15:51:00,406 iteration 5666 : loss : 0.014654, loss_ce: 0.005237
2021-11-30 15:51:01,965 iteration 5667 : loss : 0.017064, loss_ce: 0.006647
2021-11-30 15:51:03,478 iteration 5668 : loss : 0.016520, loss_ce: 0.007283
2021-11-30 15:51:05,030 iteration 5669 : loss : 0.022025, loss_ce: 0.010128
2021-11-30 15:51:06,560 iteration 5670 : loss : 0.014495, loss_ce: 0.005275
2021-11-30 15:51:08,082 iteration 5671 : loss : 0.016486, loss_ce: 0.005425
2021-11-30 15:51:09,604 iteration 5672 : loss : 0.020341, loss_ce: 0.005424
2021-11-30 15:51:11,091 iteration 5673 : loss : 0.016564, loss_ce: 0.005001
2021-11-30 15:51:12,667 iteration 5674 : loss : 0.018197, loss_ce: 0.008522
2021-11-30 15:51:14,163 iteration 5675 : loss : 0.016185, loss_ce: 0.006714
2021-11-30 15:51:15,744 iteration 5676 : loss : 0.019547, loss_ce: 0.006982
2021-11-30 15:51:17,301 iteration 5677 : loss : 0.012315, loss_ce: 0.005665
2021-11-30 15:51:18,820 iteration 5678 : loss : 0.020548, loss_ce: 0.006635
 84%|████████████████████████▏    | 334/400 [2:36:09<29:30, 26.83s/it]2021-11-30 15:51:20,376 iteration 5679 : loss : 0.022953, loss_ce: 0.009585
2021-11-30 15:51:21,792 iteration 5680 : loss : 0.013783, loss_ce: 0.003294
2021-11-30 15:51:23,356 iteration 5681 : loss : 0.026882, loss_ce: 0.009300
2021-11-30 15:51:24,916 iteration 5682 : loss : 0.023088, loss_ce: 0.009607
2021-11-30 15:51:26,397 iteration 5683 : loss : 0.013955, loss_ce: 0.004364
2021-11-30 15:51:27,888 iteration 5684 : loss : 0.011770, loss_ce: 0.005727
2021-11-30 15:51:29,429 iteration 5685 : loss : 0.023174, loss_ce: 0.010222
2021-11-30 15:51:30,927 iteration 5686 : loss : 0.015058, loss_ce: 0.005724
2021-11-30 15:51:32,441 iteration 5687 : loss : 0.014348, loss_ce: 0.005749
2021-11-30 15:51:34,035 iteration 5688 : loss : 0.021214, loss_ce: 0.008001
2021-11-30 15:51:35,553 iteration 5689 : loss : 0.026451, loss_ce: 0.006399
2021-11-30 15:51:37,096 iteration 5690 : loss : 0.017721, loss_ce: 0.007539
2021-11-30 15:51:38,648 iteration 5691 : loss : 0.019071, loss_ce: 0.007896
2021-11-30 15:51:40,198 iteration 5692 : loss : 0.017754, loss_ce: 0.007070
2021-11-30 15:51:41,739 iteration 5693 : loss : 0.021645, loss_ce: 0.005946
2021-11-30 15:51:43,236 iteration 5694 : loss : 0.017356, loss_ce: 0.007522
2021-11-30 15:51:43,236 Training Data Eval:
2021-11-30 15:51:50,888   Average segmentation loss on training set: 0.0103
2021-11-30 15:51:50,889 Validation Data Eval:
2021-11-30 15:51:53,523   Average segmentation loss on validation set: 0.0718
2021-11-30 15:51:55,009 iteration 5695 : loss : 0.019981, loss_ce: 0.005550
 84%|████████████████████████▎    | 335/400 [2:36:45<32:06, 29.64s/it]2021-11-30 15:51:56,532 iteration 5696 : loss : 0.013109, loss_ce: 0.006308
2021-11-30 15:51:58,005 iteration 5697 : loss : 0.014752, loss_ce: 0.006325
2021-11-30 15:51:59,558 iteration 5698 : loss : 0.019802, loss_ce: 0.006517
2021-11-30 15:52:01,008 iteration 5699 : loss : 0.015382, loss_ce: 0.006446
2021-11-30 15:52:02,500 iteration 5700 : loss : 0.017003, loss_ce: 0.005938
2021-11-30 15:52:03,967 iteration 5701 : loss : 0.013265, loss_ce: 0.006067
2021-11-30 15:52:05,585 iteration 5702 : loss : 0.017934, loss_ce: 0.006060
2021-11-30 15:52:07,134 iteration 5703 : loss : 0.017596, loss_ce: 0.007532
2021-11-30 15:52:08,662 iteration 5704 : loss : 0.018874, loss_ce: 0.007153
2021-11-30 15:52:10,195 iteration 5705 : loss : 0.017684, loss_ce: 0.006113
2021-11-30 15:52:11,625 iteration 5706 : loss : 0.015936, loss_ce: 0.006033
2021-11-30 15:52:13,129 iteration 5707 : loss : 0.014295, loss_ce: 0.005505
2021-11-30 15:52:14,600 iteration 5708 : loss : 0.017010, loss_ce: 0.005802
2021-11-30 15:52:16,128 iteration 5709 : loss : 0.012885, loss_ce: 0.004282
2021-11-30 15:52:17,634 iteration 5710 : loss : 0.017454, loss_ce: 0.005082
2021-11-30 15:52:19,095 iteration 5711 : loss : 0.016262, loss_ce: 0.005126
2021-11-30 15:52:20,620 iteration 5712 : loss : 0.020310, loss_ce: 0.008273
 84%|████████████████████████▎    | 336/400 [2:37:11<30:19, 28.43s/it]2021-11-30 15:52:22,214 iteration 5713 : loss : 0.019688, loss_ce: 0.006605
2021-11-30 15:52:23,764 iteration 5714 : loss : 0.018279, loss_ce: 0.006294
2021-11-30 15:52:25,335 iteration 5715 : loss : 0.012950, loss_ce: 0.005091
2021-11-30 15:52:26,833 iteration 5716 : loss : 0.017741, loss_ce: 0.006663
2021-11-30 15:52:28,432 iteration 5717 : loss : 0.018068, loss_ce: 0.007914
2021-11-30 15:52:29,926 iteration 5718 : loss : 0.011678, loss_ce: 0.003913
2021-11-30 15:52:31,384 iteration 5719 : loss : 0.016941, loss_ce: 0.007458
2021-11-30 15:52:32,937 iteration 5720 : loss : 0.023821, loss_ce: 0.009768
2021-11-30 15:52:34,457 iteration 5721 : loss : 0.019044, loss_ce: 0.009986
2021-11-30 15:52:35,977 iteration 5722 : loss : 0.015112, loss_ce: 0.006090
2021-11-30 15:52:37,511 iteration 5723 : loss : 0.021847, loss_ce: 0.006900
2021-11-30 15:52:39,072 iteration 5724 : loss : 0.017556, loss_ce: 0.006805
2021-11-30 15:52:40,603 iteration 5725 : loss : 0.018493, loss_ce: 0.006968
2021-11-30 15:52:42,086 iteration 5726 : loss : 0.018420, loss_ce: 0.004427
2021-11-30 15:52:43,631 iteration 5727 : loss : 0.022271, loss_ce: 0.006417
2021-11-30 15:52:45,135 iteration 5728 : loss : 0.021384, loss_ce: 0.006608
2021-11-30 15:52:46,732 iteration 5729 : loss : 0.020520, loss_ce: 0.008617
 84%|████████████████████████▍    | 337/400 [2:37:37<29:07, 27.74s/it]2021-11-30 15:52:48,242 iteration 5730 : loss : 0.016196, loss_ce: 0.007787
2021-11-30 15:52:49,815 iteration 5731 : loss : 0.018155, loss_ce: 0.008114
2021-11-30 15:52:51,305 iteration 5732 : loss : 0.013972, loss_ce: 0.005185
2021-11-30 15:52:52,900 iteration 5733 : loss : 0.023668, loss_ce: 0.006000
2021-11-30 15:52:54,469 iteration 5734 : loss : 0.018150, loss_ce: 0.006820
2021-11-30 15:52:55,972 iteration 5735 : loss : 0.014817, loss_ce: 0.004272
2021-11-30 15:52:57,483 iteration 5736 : loss : 0.023791, loss_ce: 0.009171
2021-11-30 15:52:59,083 iteration 5737 : loss : 0.033749, loss_ce: 0.014622
2021-11-30 15:53:00,570 iteration 5738 : loss : 0.013695, loss_ce: 0.004419
2021-11-30 15:53:02,046 iteration 5739 : loss : 0.016001, loss_ce: 0.005624
2021-11-30 15:53:03,559 iteration 5740 : loss : 0.021572, loss_ce: 0.007582
2021-11-30 15:53:05,088 iteration 5741 : loss : 0.016463, loss_ce: 0.007748
2021-11-30 15:53:06,625 iteration 5742 : loss : 0.016904, loss_ce: 0.003650
2021-11-30 15:53:08,183 iteration 5743 : loss : 0.014599, loss_ce: 0.006320
2021-11-30 15:53:09,770 iteration 5744 : loss : 0.026428, loss_ce: 0.011568
2021-11-30 15:53:11,360 iteration 5745 : loss : 0.019808, loss_ce: 0.009323
2021-11-30 15:53:12,841 iteration 5746 : loss : 0.015259, loss_ce: 0.004023
 84%|████████████████████████▌    | 338/400 [2:38:03<28:09, 27.25s/it]2021-11-30 15:53:14,404 iteration 5747 : loss : 0.019085, loss_ce: 0.007065
2021-11-30 15:53:15,953 iteration 5748 : loss : 0.018959, loss_ce: 0.007809
2021-11-30 15:53:17,487 iteration 5749 : loss : 0.023066, loss_ce: 0.008643
2021-11-30 15:53:19,018 iteration 5750 : loss : 0.018505, loss_ce: 0.006591
2021-11-30 15:53:20,491 iteration 5751 : loss : 0.016425, loss_ce: 0.005390
2021-11-30 15:53:21,997 iteration 5752 : loss : 0.018271, loss_ce: 0.005737
2021-11-30 15:53:23,570 iteration 5753 : loss : 0.013947, loss_ce: 0.005022
2021-11-30 15:53:25,160 iteration 5754 : loss : 0.014480, loss_ce: 0.004240
2021-11-30 15:53:26,689 iteration 5755 : loss : 0.012392, loss_ce: 0.004247
2021-11-30 15:53:28,173 iteration 5756 : loss : 0.014474, loss_ce: 0.004535
2021-11-30 15:53:29,588 iteration 5757 : loss : 0.014141, loss_ce: 0.005669
2021-11-30 15:53:31,167 iteration 5758 : loss : 0.021280, loss_ce: 0.009186
2021-11-30 15:53:32,740 iteration 5759 : loss : 0.015400, loss_ce: 0.006320
2021-11-30 15:53:34,355 iteration 5760 : loss : 0.017366, loss_ce: 0.007889
2021-11-30 15:53:35,981 iteration 5761 : loss : 0.020863, loss_ce: 0.008503
2021-11-30 15:53:37,455 iteration 5762 : loss : 0.016350, loss_ce: 0.007272
2021-11-30 15:53:39,018 iteration 5763 : loss : 0.013443, loss_ce: 0.005481
 85%|████████████████████████▌    | 339/400 [2:38:29<27:22, 26.93s/it]2021-11-30 15:53:40,568 iteration 5764 : loss : 0.017389, loss_ce: 0.006816
2021-11-30 15:53:42,157 iteration 5765 : loss : 0.029904, loss_ce: 0.007204
2021-11-30 15:53:43,712 iteration 5766 : loss : 0.022767, loss_ce: 0.012604
2021-11-30 15:53:45,243 iteration 5767 : loss : 0.014564, loss_ce: 0.007166
2021-11-30 15:53:46,887 iteration 5768 : loss : 0.018507, loss_ce: 0.007530
2021-11-30 15:53:48,463 iteration 5769 : loss : 0.019913, loss_ce: 0.006078
2021-11-30 15:53:49,939 iteration 5770 : loss : 0.014922, loss_ce: 0.005385
2021-11-30 15:53:51,478 iteration 5771 : loss : 0.017745, loss_ce: 0.006985
2021-11-30 15:53:52,994 iteration 5772 : loss : 0.013383, loss_ce: 0.004043
2021-11-30 15:53:54,458 iteration 5773 : loss : 0.012772, loss_ce: 0.004535
2021-11-30 15:53:55,923 iteration 5774 : loss : 0.013847, loss_ce: 0.003603
2021-11-30 15:53:57,469 iteration 5775 : loss : 0.015880, loss_ce: 0.006063
2021-11-30 15:53:59,062 iteration 5776 : loss : 0.019205, loss_ce: 0.009205
2021-11-30 15:54:00,498 iteration 5777 : loss : 0.014610, loss_ce: 0.006173
2021-11-30 15:54:01,986 iteration 5778 : loss : 0.018373, loss_ce: 0.004932
2021-11-30 15:54:03,506 iteration 5779 : loss : 0.012890, loss_ce: 0.004363
2021-11-30 15:54:03,506 Training Data Eval:
2021-11-30 15:54:11,144   Average segmentation loss on training set: 0.0097
2021-11-30 15:54:11,145 Validation Data Eval:
2021-11-30 15:54:13,772   Average segmentation loss on validation set: 0.0660
2021-11-30 15:54:15,285 iteration 5780 : loss : 0.025459, loss_ce: 0.008017
 85%|████████████████████████▋    | 340/400 [2:39:05<29:43, 29.73s/it]2021-11-30 15:54:16,826 iteration 5781 : loss : 0.020330, loss_ce: 0.005356
2021-11-30 15:54:18,419 iteration 5782 : loss : 0.023064, loss_ce: 0.009208
2021-11-30 15:54:19,930 iteration 5783 : loss : 0.015712, loss_ce: 0.005836
2021-11-30 15:54:21,469 iteration 5784 : loss : 0.019106, loss_ce: 0.008440
2021-11-30 15:54:22,945 iteration 5785 : loss : 0.012190, loss_ce: 0.004299
2021-11-30 15:54:24,447 iteration 5786 : loss : 0.013739, loss_ce: 0.005896
2021-11-30 15:54:25,937 iteration 5787 : loss : 0.014314, loss_ce: 0.005183
2021-11-30 15:54:27,578 iteration 5788 : loss : 0.026494, loss_ce: 0.012637
2021-11-30 15:54:29,106 iteration 5789 : loss : 0.015132, loss_ce: 0.005496
2021-11-30 15:54:30,615 iteration 5790 : loss : 0.015014, loss_ce: 0.004950
2021-11-30 15:54:32,091 iteration 5791 : loss : 0.013929, loss_ce: 0.004991
2021-11-30 15:54:33,638 iteration 5792 : loss : 0.019220, loss_ce: 0.007826
2021-11-30 15:54:35,267 iteration 5793 : loss : 0.020921, loss_ce: 0.006932
2021-11-30 15:54:36,784 iteration 5794 : loss : 0.016827, loss_ce: 0.007288
2021-11-30 15:54:38,300 iteration 5795 : loss : 0.016391, loss_ce: 0.005293
2021-11-30 15:54:39,781 iteration 5796 : loss : 0.014377, loss_ce: 0.003942
2021-11-30 15:54:41,336 iteration 5797 : loss : 0.018205, loss_ce: 0.006757
 85%|████████████████████████▋    | 341/400 [2:39:31<28:08, 28.62s/it]2021-11-30 15:54:42,933 iteration 5798 : loss : 0.018603, loss_ce: 0.006924
2021-11-30 15:54:44,461 iteration 5799 : loss : 0.017906, loss_ce: 0.006037
2021-11-30 15:54:45,968 iteration 5800 : loss : 0.014125, loss_ce: 0.006093
2021-11-30 15:54:47,491 iteration 5801 : loss : 0.029734, loss_ce: 0.013057
2021-11-30 15:54:48,965 iteration 5802 : loss : 0.013708, loss_ce: 0.006150
2021-11-30 15:54:50,454 iteration 5803 : loss : 0.015186, loss_ce: 0.007443
2021-11-30 15:54:51,976 iteration 5804 : loss : 0.017876, loss_ce: 0.006117
2021-11-30 15:54:53,576 iteration 5805 : loss : 0.013888, loss_ce: 0.004390
2021-11-30 15:54:55,086 iteration 5806 : loss : 0.025984, loss_ce: 0.008192
2021-11-30 15:54:56,679 iteration 5807 : loss : 0.025011, loss_ce: 0.009715
2021-11-30 15:54:58,203 iteration 5808 : loss : 0.018429, loss_ce: 0.008690
2021-11-30 15:54:59,657 iteration 5809 : loss : 0.012816, loss_ce: 0.003199
2021-11-30 15:55:01,165 iteration 5810 : loss : 0.015720, loss_ce: 0.005158
2021-11-30 15:55:02,617 iteration 5811 : loss : 0.011902, loss_ce: 0.003638
2021-11-30 15:55:04,152 iteration 5812 : loss : 0.017881, loss_ce: 0.006085
2021-11-30 15:55:05,611 iteration 5813 : loss : 0.019988, loss_ce: 0.007707
2021-11-30 15:55:07,144 iteration 5814 : loss : 0.016902, loss_ce: 0.007154
 86%|████████████████████████▊    | 342/400 [2:39:57<26:51, 27.78s/it]2021-11-30 15:55:08,649 iteration 5815 : loss : 0.012766, loss_ce: 0.004083
2021-11-30 15:55:10,143 iteration 5816 : loss : 0.012413, loss_ce: 0.005872
2021-11-30 15:55:11,631 iteration 5817 : loss : 0.012655, loss_ce: 0.004723
2021-11-30 15:55:13,066 iteration 5818 : loss : 0.014401, loss_ce: 0.005723
2021-11-30 15:55:14,650 iteration 5819 : loss : 0.023229, loss_ce: 0.008623
2021-11-30 15:55:16,231 iteration 5820 : loss : 0.023928, loss_ce: 0.012611
2021-11-30 15:55:17,675 iteration 5821 : loss : 0.016756, loss_ce: 0.005589
2021-11-30 15:55:19,150 iteration 5822 : loss : 0.011346, loss_ce: 0.004753
2021-11-30 15:55:20,780 iteration 5823 : loss : 0.020776, loss_ce: 0.008478
2021-11-30 15:55:22,302 iteration 5824 : loss : 0.016223, loss_ce: 0.004805
2021-11-30 15:55:23,867 iteration 5825 : loss : 0.016953, loss_ce: 0.006367
2021-11-30 15:55:25,420 iteration 5826 : loss : 0.020085, loss_ce: 0.004999
2021-11-30 15:55:26,941 iteration 5827 : loss : 0.018819, loss_ce: 0.006026
2021-11-30 15:55:28,545 iteration 5828 : loss : 0.021837, loss_ce: 0.008830
2021-11-30 15:55:30,062 iteration 5829 : loss : 0.014814, loss_ce: 0.005902
2021-11-30 15:55:31,551 iteration 5830 : loss : 0.021655, loss_ce: 0.008338
2021-11-30 15:55:33,068 iteration 5831 : loss : 0.015693, loss_ce: 0.005356
 86%|████████████████████████▊    | 343/400 [2:40:23<25:51, 27.22s/it]2021-11-30 15:55:34,628 iteration 5832 : loss : 0.016055, loss_ce: 0.004493
2021-11-30 15:55:36,188 iteration 5833 : loss : 0.018263, loss_ce: 0.008450
2021-11-30 15:55:37,664 iteration 5834 : loss : 0.014274, loss_ce: 0.004883
2021-11-30 15:55:39,160 iteration 5835 : loss : 0.023930, loss_ce: 0.006939
2021-11-30 15:55:40,722 iteration 5836 : loss : 0.020491, loss_ce: 0.010577
2021-11-30 15:55:42,236 iteration 5837 : loss : 0.016797, loss_ce: 0.003762
2021-11-30 15:55:43,666 iteration 5838 : loss : 0.011937, loss_ce: 0.003269
2021-11-30 15:55:45,177 iteration 5839 : loss : 0.017222, loss_ce: 0.005589
2021-11-30 15:55:46,750 iteration 5840 : loss : 0.018384, loss_ce: 0.006989
2021-11-30 15:55:48,234 iteration 5841 : loss : 0.017104, loss_ce: 0.007686
2021-11-30 15:55:49,720 iteration 5842 : loss : 0.011627, loss_ce: 0.004168
2021-11-30 15:55:51,226 iteration 5843 : loss : 0.026340, loss_ce: 0.008552
2021-11-30 15:55:52,880 iteration 5844 : loss : 0.035054, loss_ce: 0.012451
2021-11-30 15:55:54,396 iteration 5845 : loss : 0.019001, loss_ce: 0.006885
2021-11-30 15:55:55,921 iteration 5846 : loss : 0.017594, loss_ce: 0.007211
2021-11-30 15:55:57,455 iteration 5847 : loss : 0.019596, loss_ce: 0.007538
2021-11-30 15:55:58,980 iteration 5848 : loss : 0.017217, loss_ce: 0.006211
 86%|████████████████████████▉    | 344/400 [2:40:49<25:02, 26.83s/it]2021-11-30 15:56:00,530 iteration 5849 : loss : 0.016496, loss_ce: 0.006581
2021-11-30 15:56:01,988 iteration 5850 : loss : 0.012467, loss_ce: 0.005150
2021-11-30 15:56:03,521 iteration 5851 : loss : 0.015112, loss_ce: 0.005762
2021-11-30 15:56:05,017 iteration 5852 : loss : 0.015746, loss_ce: 0.005813
2021-11-30 15:56:06,454 iteration 5853 : loss : 0.015772, loss_ce: 0.005947
2021-11-30 15:56:07,960 iteration 5854 : loss : 0.021253, loss_ce: 0.007259
2021-11-30 15:56:09,539 iteration 5855 : loss : 0.019970, loss_ce: 0.008476
2021-11-30 15:56:11,071 iteration 5856 : loss : 0.016525, loss_ce: 0.007068
2021-11-30 15:56:12,598 iteration 5857 : loss : 0.013824, loss_ce: 0.004725
2021-11-30 15:56:14,052 iteration 5858 : loss : 0.014024, loss_ce: 0.005319
2021-11-30 15:56:15,615 iteration 5859 : loss : 0.017282, loss_ce: 0.006370
2021-11-30 15:56:17,181 iteration 5860 : loss : 0.015558, loss_ce: 0.004133
2021-11-30 15:56:18,677 iteration 5861 : loss : 0.015486, loss_ce: 0.004603
2021-11-30 15:56:20,211 iteration 5862 : loss : 0.019462, loss_ce: 0.009765
2021-11-30 15:56:21,640 iteration 5863 : loss : 0.009629, loss_ce: 0.003147
2021-11-30 15:56:23,161 iteration 5864 : loss : 0.020404, loss_ce: 0.006513
2021-11-30 15:56:23,161 Training Data Eval:
2021-11-30 15:56:30,832   Average segmentation loss on training set: 0.0096
2021-11-30 15:56:30,833 Validation Data Eval:
2021-11-30 15:56:33,467   Average segmentation loss on validation set: 0.0668
2021-11-30 15:56:34,937 iteration 5865 : loss : 0.017053, loss_ce: 0.005135
 86%|█████████████████████████    | 345/400 [2:41:25<27:06, 29.57s/it]2021-11-30 15:56:36,573 iteration 5866 : loss : 0.014261, loss_ce: 0.005923
2021-11-30 15:56:38,171 iteration 5867 : loss : 0.027477, loss_ce: 0.007481
2021-11-30 15:56:39,732 iteration 5868 : loss : 0.021515, loss_ce: 0.008078
2021-11-30 15:56:41,173 iteration 5869 : loss : 0.013780, loss_ce: 0.005511
2021-11-30 15:56:42,779 iteration 5870 : loss : 0.020721, loss_ce: 0.004693
2021-11-30 15:56:44,349 iteration 5871 : loss : 0.013528, loss_ce: 0.004490
2021-11-30 15:56:45,907 iteration 5872 : loss : 0.023224, loss_ce: 0.008432
2021-11-30 15:56:47,533 iteration 5873 : loss : 0.023953, loss_ce: 0.008042
2021-11-30 15:56:49,005 iteration 5874 : loss : 0.019155, loss_ce: 0.006581
2021-11-30 15:56:50,497 iteration 5875 : loss : 0.015075, loss_ce: 0.007775
2021-11-30 15:56:52,022 iteration 5876 : loss : 0.017890, loss_ce: 0.006302
2021-11-30 15:56:53,542 iteration 5877 : loss : 0.018820, loss_ce: 0.006659
2021-11-30 15:56:55,101 iteration 5878 : loss : 0.016800, loss_ce: 0.007195
2021-11-30 15:56:56,598 iteration 5879 : loss : 0.013284, loss_ce: 0.005792
2021-11-30 15:56:58,208 iteration 5880 : loss : 0.015998, loss_ce: 0.004278
2021-11-30 15:56:59,663 iteration 5881 : loss : 0.010669, loss_ce: 0.004041
2021-11-30 15:57:01,167 iteration 5882 : loss : 0.016972, loss_ce: 0.007213
 86%|█████████████████████████    | 346/400 [2:41:51<25:42, 28.57s/it]2021-11-30 15:57:02,720 iteration 5883 : loss : 0.012165, loss_ce: 0.004210
2021-11-30 15:57:04,204 iteration 5884 : loss : 0.014792, loss_ce: 0.005952
2021-11-30 15:57:05,829 iteration 5885 : loss : 0.024391, loss_ce: 0.009249
2021-11-30 15:57:07,289 iteration 5886 : loss : 0.017493, loss_ce: 0.005544
2021-11-30 15:57:08,802 iteration 5887 : loss : 0.014121, loss_ce: 0.005556
2021-11-30 15:57:10,403 iteration 5888 : loss : 0.031650, loss_ce: 0.012202
2021-11-30 15:57:11,989 iteration 5889 : loss : 0.015636, loss_ce: 0.006170
2021-11-30 15:57:13,522 iteration 5890 : loss : 0.012801, loss_ce: 0.004158
2021-11-30 15:57:15,110 iteration 5891 : loss : 0.017932, loss_ce: 0.005980
2021-11-30 15:57:16,706 iteration 5892 : loss : 0.020318, loss_ce: 0.008711
2021-11-30 15:57:18,181 iteration 5893 : loss : 0.012057, loss_ce: 0.003973
2021-11-30 15:57:19,787 iteration 5894 : loss : 0.014754, loss_ce: 0.006259
2021-11-30 15:57:21,344 iteration 5895 : loss : 0.021633, loss_ce: 0.007406
2021-11-30 15:57:22,855 iteration 5896 : loss : 0.015583, loss_ce: 0.007122
2021-11-30 15:57:24,433 iteration 5897 : loss : 0.027885, loss_ce: 0.010142
2021-11-30 15:57:26,003 iteration 5898 : loss : 0.013287, loss_ce: 0.004751
2021-11-30 15:57:27,503 iteration 5899 : loss : 0.023088, loss_ce: 0.008449
 87%|█████████████████████████▏   | 347/400 [2:42:18<24:38, 27.90s/it]2021-11-30 15:57:29,069 iteration 5900 : loss : 0.015200, loss_ce: 0.004974
2021-11-30 15:57:30,661 iteration 5901 : loss : 0.025619, loss_ce: 0.008413
2021-11-30 15:57:32,201 iteration 5902 : loss : 0.016876, loss_ce: 0.006580
2021-11-30 15:57:33,797 iteration 5903 : loss : 0.013218, loss_ce: 0.005661
2021-11-30 15:57:35,298 iteration 5904 : loss : 0.013700, loss_ce: 0.005005
2021-11-30 15:57:36,859 iteration 5905 : loss : 0.027107, loss_ce: 0.007006
2021-11-30 15:57:38,332 iteration 5906 : loss : 0.015991, loss_ce: 0.006251
2021-11-30 15:57:39,893 iteration 5907 : loss : 0.010462, loss_ce: 0.003363
2021-11-30 15:57:41,429 iteration 5908 : loss : 0.012431, loss_ce: 0.004417
2021-11-30 15:57:42,880 iteration 5909 : loss : 0.023617, loss_ce: 0.005796
2021-11-30 15:57:44,423 iteration 5910 : loss : 0.020084, loss_ce: 0.007269
2021-11-30 15:57:45,976 iteration 5911 : loss : 0.022793, loss_ce: 0.009112
2021-11-30 15:57:47,444 iteration 5912 : loss : 0.018840, loss_ce: 0.006151
2021-11-30 15:57:48,961 iteration 5913 : loss : 0.018115, loss_ce: 0.008974
2021-11-30 15:57:50,501 iteration 5914 : loss : 0.026640, loss_ce: 0.008594
2021-11-30 15:57:51,943 iteration 5915 : loss : 0.014807, loss_ce: 0.005833
2021-11-30 15:57:53,507 iteration 5916 : loss : 0.021149, loss_ce: 0.007774
 87%|█████████████████████████▏   | 348/400 [2:42:44<23:41, 27.33s/it]2021-11-30 15:57:55,036 iteration 5917 : loss : 0.014723, loss_ce: 0.005175
2021-11-30 15:57:56,497 iteration 5918 : loss : 0.014162, loss_ce: 0.005424
2021-11-30 15:57:58,061 iteration 5919 : loss : 0.018944, loss_ce: 0.008169
2021-11-30 15:57:59,632 iteration 5920 : loss : 0.019321, loss_ce: 0.010344
2021-11-30 15:58:01,276 iteration 5921 : loss : 0.031873, loss_ce: 0.010948
2021-11-30 15:58:02,777 iteration 5922 : loss : 0.015774, loss_ce: 0.004135
2021-11-30 15:58:04,314 iteration 5923 : loss : 0.017599, loss_ce: 0.005388
2021-11-30 15:58:05,931 iteration 5924 : loss : 0.018973, loss_ce: 0.004636
2021-11-30 15:58:07,458 iteration 5925 : loss : 0.015047, loss_ce: 0.005492
2021-11-30 15:58:08,991 iteration 5926 : loss : 0.023292, loss_ce: 0.008718
2021-11-30 15:58:10,526 iteration 5927 : loss : 0.016311, loss_ce: 0.005971
2021-11-30 15:58:11,981 iteration 5928 : loss : 0.016713, loss_ce: 0.004102
2021-11-30 15:58:13,452 iteration 5929 : loss : 0.014857, loss_ce: 0.006907
2021-11-30 15:58:14,932 iteration 5930 : loss : 0.017726, loss_ce: 0.007882
2021-11-30 15:58:16,476 iteration 5931 : loss : 0.026184, loss_ce: 0.006867
2021-11-30 15:58:18,056 iteration 5932 : loss : 0.015990, loss_ce: 0.005433
2021-11-30 15:58:19,571 iteration 5933 : loss : 0.017523, loss_ce: 0.006345
 87%|█████████████████████████▎   | 349/400 [2:43:10<22:54, 26.95s/it]2021-11-30 15:58:21,103 iteration 5934 : loss : 0.016642, loss_ce: 0.005124
2021-11-30 15:58:22,754 iteration 5935 : loss : 0.015949, loss_ce: 0.005234
2021-11-30 15:58:24,281 iteration 5936 : loss : 0.015195, loss_ce: 0.006420
2021-11-30 15:58:25,776 iteration 5937 : loss : 0.015183, loss_ce: 0.005122
2021-11-30 15:58:27,225 iteration 5938 : loss : 0.010990, loss_ce: 0.003992
2021-11-30 15:58:28,792 iteration 5939 : loss : 0.013767, loss_ce: 0.006028
2021-11-30 15:58:30,270 iteration 5940 : loss : 0.014006, loss_ce: 0.005512
2021-11-30 15:58:31,761 iteration 5941 : loss : 0.018687, loss_ce: 0.008235
2021-11-30 15:58:33,255 iteration 5942 : loss : 0.013450, loss_ce: 0.005581
2021-11-30 15:58:34,804 iteration 5943 : loss : 0.019363, loss_ce: 0.005894
2021-11-30 15:58:36,335 iteration 5944 : loss : 0.014068, loss_ce: 0.007112
2021-11-30 15:58:37,833 iteration 5945 : loss : 0.017773, loss_ce: 0.004824
2021-11-30 15:58:39,444 iteration 5946 : loss : 0.016921, loss_ce: 0.005732
2021-11-30 15:58:40,998 iteration 5947 : loss : 0.019657, loss_ce: 0.007812
2021-11-30 15:58:42,495 iteration 5948 : loss : 0.019164, loss_ce: 0.006638
2021-11-30 15:58:44,067 iteration 5949 : loss : 0.015870, loss_ce: 0.005502
2021-11-30 15:58:44,067 Training Data Eval:
2021-11-30 15:58:51,710   Average segmentation loss on training set: 0.0095
2021-11-30 15:58:51,710 Validation Data Eval:
2021-11-30 15:58:54,354   Average segmentation loss on validation set: 0.0721
2021-11-30 15:58:55,905 iteration 5950 : loss : 0.017637, loss_ce: 0.005270
 88%|█████████████████████████▍   | 350/400 [2:43:46<24:48, 29.77s/it]2021-11-30 15:58:57,421 iteration 5951 : loss : 0.014282, loss_ce: 0.004822
2021-11-30 15:58:58,953 iteration 5952 : loss : 0.026654, loss_ce: 0.009079
2021-11-30 15:59:00,499 iteration 5953 : loss : 0.021668, loss_ce: 0.009779
2021-11-30 15:59:01,991 iteration 5954 : loss : 0.015765, loss_ce: 0.006297
2021-11-30 15:59:03,523 iteration 5955 : loss : 0.017814, loss_ce: 0.005597
2021-11-30 15:59:05,073 iteration 5956 : loss : 0.019112, loss_ce: 0.009933
2021-11-30 15:59:06,621 iteration 5957 : loss : 0.013240, loss_ce: 0.005193
2021-11-30 15:59:08,099 iteration 5958 : loss : 0.013170, loss_ce: 0.004777
2021-11-30 15:59:09,621 iteration 5959 : loss : 0.017778, loss_ce: 0.007346
2021-11-30 15:59:11,106 iteration 5960 : loss : 0.016967, loss_ce: 0.005346
2021-11-30 15:59:12,577 iteration 5961 : loss : 0.016834, loss_ce: 0.003993
2021-11-30 15:59:14,094 iteration 5962 : loss : 0.020926, loss_ce: 0.005437
2021-11-30 15:59:15,651 iteration 5963 : loss : 0.017202, loss_ce: 0.007244
2021-11-30 15:59:17,146 iteration 5964 : loss : 0.012337, loss_ce: 0.005168
2021-11-30 15:59:18,598 iteration 5965 : loss : 0.012582, loss_ce: 0.005788
2021-11-30 15:59:20,174 iteration 5966 : loss : 0.015531, loss_ce: 0.004250
2021-11-30 15:59:21,705 iteration 5967 : loss : 0.016132, loss_ce: 0.006644
 88%|█████████████████████████▍   | 351/400 [2:44:12<23:20, 28.57s/it]2021-11-30 15:59:23,327 iteration 5968 : loss : 0.025062, loss_ce: 0.009894
2021-11-30 15:59:24,819 iteration 5969 : loss : 0.016065, loss_ce: 0.006563
2021-11-30 15:59:26,385 iteration 5970 : loss : 0.018439, loss_ce: 0.006934
2021-11-30 15:59:27,850 iteration 5971 : loss : 0.013027, loss_ce: 0.004088
2021-11-30 15:59:29,280 iteration 5972 : loss : 0.012062, loss_ce: 0.003889
2021-11-30 15:59:30,797 iteration 5973 : loss : 0.016324, loss_ce: 0.007194
2021-11-30 15:59:32,413 iteration 5974 : loss : 0.026141, loss_ce: 0.010289
2021-11-30 15:59:33,866 iteration 5975 : loss : 0.015598, loss_ce: 0.005307
2021-11-30 15:59:35,351 iteration 5976 : loss : 0.018046, loss_ce: 0.005378
2021-11-30 15:59:36,822 iteration 5977 : loss : 0.023656, loss_ce: 0.005190
2021-11-30 15:59:38,303 iteration 5978 : loss : 0.013065, loss_ce: 0.005944
2021-11-30 15:59:39,829 iteration 5979 : loss : 0.012932, loss_ce: 0.006113
2021-11-30 15:59:41,388 iteration 5980 : loss : 0.011643, loss_ce: 0.003800
2021-11-30 15:59:42,877 iteration 5981 : loss : 0.018358, loss_ce: 0.008065
2021-11-30 15:59:44,402 iteration 5982 : loss : 0.022917, loss_ce: 0.009591
2021-11-30 15:59:45,999 iteration 5983 : loss : 0.020306, loss_ce: 0.006088
2021-11-30 15:59:47,499 iteration 5984 : loss : 0.016199, loss_ce: 0.005505
 88%|█████████████████████████▌   | 352/400 [2:44:38<22:11, 27.74s/it]2021-11-30 15:59:49,046 iteration 5985 : loss : 0.015919, loss_ce: 0.004358
2021-11-30 15:59:50,470 iteration 5986 : loss : 0.015246, loss_ce: 0.004884
2021-11-30 15:59:52,033 iteration 5987 : loss : 0.017578, loss_ce: 0.007118
2021-11-30 15:59:53,596 iteration 5988 : loss : 0.018544, loss_ce: 0.007434
2021-11-30 15:59:55,131 iteration 5989 : loss : 0.011876, loss_ce: 0.004545
2021-11-30 15:59:56,618 iteration 5990 : loss : 0.015257, loss_ce: 0.005318
2021-11-30 15:59:58,171 iteration 5991 : loss : 0.019451, loss_ce: 0.006646
2021-11-30 15:59:59,698 iteration 5992 : loss : 0.015418, loss_ce: 0.005107
2021-11-30 16:00:01,209 iteration 5993 : loss : 0.013186, loss_ce: 0.005204
2021-11-30 16:00:02,774 iteration 5994 : loss : 0.017686, loss_ce: 0.007326
2021-11-30 16:00:04,292 iteration 5995 : loss : 0.016744, loss_ce: 0.005455
2021-11-30 16:00:05,763 iteration 5996 : loss : 0.012381, loss_ce: 0.003621
2021-11-30 16:00:07,300 iteration 5997 : loss : 0.018970, loss_ce: 0.007141
2021-11-30 16:00:08,897 iteration 5998 : loss : 0.019220, loss_ce: 0.007096
2021-11-30 16:00:10,526 iteration 5999 : loss : 0.022771, loss_ce: 0.008349
2021-11-30 16:00:12,045 iteration 6000 : loss : 0.017111, loss_ce: 0.007554
2021-11-30 16:00:13,487 iteration 6001 : loss : 0.014796, loss_ce: 0.006791
 88%|█████████████████████████▌   | 353/400 [2:45:04<21:19, 27.21s/it]2021-11-30 16:00:15,059 iteration 6002 : loss : 0.015654, loss_ce: 0.006107
2021-11-30 16:00:16,544 iteration 6003 : loss : 0.015890, loss_ce: 0.005433
2021-11-30 16:00:18,118 iteration 6004 : loss : 0.018341, loss_ce: 0.009048
2021-11-30 16:00:19,668 iteration 6005 : loss : 0.021943, loss_ce: 0.007973
2021-11-30 16:00:21,285 iteration 6006 : loss : 0.015438, loss_ce: 0.006165
2021-11-30 16:00:22,824 iteration 6007 : loss : 0.012512, loss_ce: 0.004769
2021-11-30 16:00:24,338 iteration 6008 : loss : 0.016096, loss_ce: 0.005330
2021-11-30 16:00:25,776 iteration 6009 : loss : 0.013407, loss_ce: 0.006390
2021-11-30 16:00:27,251 iteration 6010 : loss : 0.012699, loss_ce: 0.005200
2021-11-30 16:00:28,816 iteration 6011 : loss : 0.016344, loss_ce: 0.005336
2021-11-30 16:00:30,387 iteration 6012 : loss : 0.021995, loss_ce: 0.004893
2021-11-30 16:00:31,947 iteration 6013 : loss : 0.015397, loss_ce: 0.004909
2021-11-30 16:00:33,497 iteration 6014 : loss : 0.028192, loss_ce: 0.006935
2021-11-30 16:00:34,997 iteration 6015 : loss : 0.023070, loss_ce: 0.008352
2021-11-30 16:00:36,512 iteration 6016 : loss : 0.014825, loss_ce: 0.005207
2021-11-30 16:00:38,014 iteration 6017 : loss : 0.019805, loss_ce: 0.008033
2021-11-30 16:00:39,550 iteration 6018 : loss : 0.021427, loss_ce: 0.007845
 88%|█████████████████████████▋   | 354/400 [2:45:30<20:35, 26.87s/it]2021-11-30 16:00:41,138 iteration 6019 : loss : 0.019668, loss_ce: 0.011347
2021-11-30 16:00:42,650 iteration 6020 : loss : 0.013987, loss_ce: 0.006030
2021-11-30 16:00:44,182 iteration 6021 : loss : 0.021051, loss_ce: 0.005719
2021-11-30 16:00:45,647 iteration 6022 : loss : 0.015149, loss_ce: 0.006268
2021-11-30 16:00:47,201 iteration 6023 : loss : 0.016410, loss_ce: 0.005915
2021-11-30 16:00:48,691 iteration 6024 : loss : 0.017669, loss_ce: 0.005489
2021-11-30 16:00:50,188 iteration 6025 : loss : 0.016630, loss_ce: 0.005831
2021-11-30 16:00:51,724 iteration 6026 : loss : 0.014389, loss_ce: 0.004827
2021-11-30 16:00:53,251 iteration 6027 : loss : 0.014740, loss_ce: 0.005821
2021-11-30 16:00:54,811 iteration 6028 : loss : 0.014468, loss_ce: 0.005781
2021-11-30 16:00:56,303 iteration 6029 : loss : 0.015540, loss_ce: 0.004129
2021-11-30 16:00:57,761 iteration 6030 : loss : 0.014536, loss_ce: 0.006761
2021-11-30 16:00:59,293 iteration 6031 : loss : 0.014442, loss_ce: 0.007025
2021-11-30 16:01:00,758 iteration 6032 : loss : 0.016290, loss_ce: 0.004987
2021-11-30 16:01:02,318 iteration 6033 : loss : 0.025475, loss_ce: 0.008591
2021-11-30 16:01:03,839 iteration 6034 : loss : 0.014708, loss_ce: 0.005593
2021-11-30 16:01:03,839 Training Data Eval:
2021-11-30 16:01:11,501   Average segmentation loss on training set: 0.0090
2021-11-30 16:01:11,501 Validation Data Eval:
2021-11-30 16:01:14,129   Average segmentation loss on validation set: 0.0680
2021-11-30 16:01:15,562 iteration 6035 : loss : 0.011203, loss_ce: 0.004178
 89%|█████████████████████████▋   | 355/400 [2:46:06<22:12, 29.62s/it]2021-11-30 16:01:17,221 iteration 6036 : loss : 0.032332, loss_ce: 0.010603
2021-11-30 16:01:18,785 iteration 6037 : loss : 0.016945, loss_ce: 0.005136
2021-11-30 16:01:20,299 iteration 6038 : loss : 0.016331, loss_ce: 0.005526
2021-11-30 16:01:21,802 iteration 6039 : loss : 0.016019, loss_ce: 0.004876
2021-11-30 16:01:23,327 iteration 6040 : loss : 0.016624, loss_ce: 0.005733
2021-11-30 16:01:24,799 iteration 6041 : loss : 0.012634, loss_ce: 0.004286
2021-11-30 16:01:26,324 iteration 6042 : loss : 0.012487, loss_ce: 0.005625
2021-11-30 16:01:27,801 iteration 6043 : loss : 0.012249, loss_ce: 0.005370
2021-11-30 16:01:29,267 iteration 6044 : loss : 0.013174, loss_ce: 0.006175
2021-11-30 16:01:30,853 iteration 6045 : loss : 0.022208, loss_ce: 0.009766
2021-11-30 16:01:32,324 iteration 6046 : loss : 0.016459, loss_ce: 0.007094
2021-11-30 16:01:33,794 iteration 6047 : loss : 0.011112, loss_ce: 0.004765
2021-11-30 16:01:35,377 iteration 6048 : loss : 0.018846, loss_ce: 0.005474
2021-11-30 16:01:36,814 iteration 6049 : loss : 0.014652, loss_ce: 0.005229
2021-11-30 16:01:38,257 iteration 6050 : loss : 0.015155, loss_ce: 0.004203
2021-11-30 16:01:39,713 iteration 6051 : loss : 0.011889, loss_ce: 0.004879
2021-11-30 16:01:41,252 iteration 6052 : loss : 0.013738, loss_ce: 0.004881
 89%|█████████████████████████▊   | 356/400 [2:46:31<20:51, 28.44s/it]2021-11-30 16:01:42,778 iteration 6053 : loss : 0.015268, loss_ce: 0.004764
2021-11-30 16:01:44,259 iteration 6054 : loss : 0.013831, loss_ce: 0.004562
2021-11-30 16:01:45,795 iteration 6055 : loss : 0.016089, loss_ce: 0.006684
2021-11-30 16:01:47,292 iteration 6056 : loss : 0.013456, loss_ce: 0.004734
2021-11-30 16:01:48,735 iteration 6057 : loss : 0.015031, loss_ce: 0.005751
2021-11-30 16:01:50,206 iteration 6058 : loss : 0.011469, loss_ce: 0.005916
2021-11-30 16:01:51,773 iteration 6059 : loss : 0.016159, loss_ce: 0.004867
2021-11-30 16:01:53,289 iteration 6060 : loss : 0.015739, loss_ce: 0.004880
2021-11-30 16:01:54,763 iteration 6061 : loss : 0.017654, loss_ce: 0.007927
2021-11-30 16:01:56,393 iteration 6062 : loss : 0.019927, loss_ce: 0.006985
2021-11-30 16:01:57,856 iteration 6063 : loss : 0.012766, loss_ce: 0.005765
2021-11-30 16:01:59,331 iteration 6064 : loss : 0.017205, loss_ce: 0.005529
2021-11-30 16:02:00,892 iteration 6065 : loss : 0.017315, loss_ce: 0.006358
2021-11-30 16:02:02,364 iteration 6066 : loss : 0.013469, loss_ce: 0.005353
2021-11-30 16:02:03,903 iteration 6067 : loss : 0.020453, loss_ce: 0.008314
2021-11-30 16:02:05,425 iteration 6068 : loss : 0.013367, loss_ce: 0.002387
2021-11-30 16:02:07,014 iteration 6069 : loss : 0.022031, loss_ce: 0.010640
 89%|█████████████████████████▉   | 357/400 [2:46:57<19:48, 27.63s/it]2021-11-30 16:02:08,572 iteration 6070 : loss : 0.018286, loss_ce: 0.008780
2021-11-30 16:02:10,088 iteration 6071 : loss : 0.012770, loss_ce: 0.005130
2021-11-30 16:02:11,586 iteration 6072 : loss : 0.014452, loss_ce: 0.005061
2021-11-30 16:02:13,099 iteration 6073 : loss : 0.021946, loss_ce: 0.005958
2021-11-30 16:02:14,539 iteration 6074 : loss : 0.013591, loss_ce: 0.005607
2021-11-30 16:02:16,088 iteration 6075 : loss : 0.017400, loss_ce: 0.007675
2021-11-30 16:02:17,600 iteration 6076 : loss : 0.012818, loss_ce: 0.004958
2021-11-30 16:02:19,007 iteration 6077 : loss : 0.011049, loss_ce: 0.003987
2021-11-30 16:02:20,521 iteration 6078 : loss : 0.016221, loss_ce: 0.007656
2021-11-30 16:02:22,103 iteration 6079 : loss : 0.023757, loss_ce: 0.010884
2021-11-30 16:02:23,561 iteration 6080 : loss : 0.011988, loss_ce: 0.004061
2021-11-30 16:02:25,146 iteration 6081 : loss : 0.024478, loss_ce: 0.009550
2021-11-30 16:02:26,652 iteration 6082 : loss : 0.017626, loss_ce: 0.004197
2021-11-30 16:02:28,205 iteration 6083 : loss : 0.014181, loss_ce: 0.005094
2021-11-30 16:02:29,672 iteration 6084 : loss : 0.014682, loss_ce: 0.003981
2021-11-30 16:02:31,145 iteration 6085 : loss : 0.016331, loss_ce: 0.006803
2021-11-30 16:02:32,813 iteration 6086 : loss : 0.024690, loss_ce: 0.005780
 90%|█████████████████████████▉   | 358/400 [2:47:23<18:57, 27.08s/it]2021-11-30 16:02:34,309 iteration 6087 : loss : 0.014067, loss_ce: 0.005497
2021-11-30 16:02:35,841 iteration 6088 : loss : 0.018291, loss_ce: 0.007620
2021-11-30 16:02:37,340 iteration 6089 : loss : 0.015139, loss_ce: 0.006745
2021-11-30 16:02:38,833 iteration 6090 : loss : 0.018776, loss_ce: 0.004687
2021-11-30 16:02:40,358 iteration 6091 : loss : 0.012571, loss_ce: 0.004707
2021-11-30 16:02:41,877 iteration 6092 : loss : 0.012729, loss_ce: 0.004974
2021-11-30 16:02:43,323 iteration 6093 : loss : 0.015413, loss_ce: 0.004956
2021-11-30 16:02:44,787 iteration 6094 : loss : 0.020812, loss_ce: 0.005811
2021-11-30 16:02:46,338 iteration 6095 : loss : 0.019899, loss_ce: 0.009312
2021-11-30 16:02:47,879 iteration 6096 : loss : 0.017724, loss_ce: 0.005936
2021-11-30 16:02:49,338 iteration 6097 : loss : 0.013729, loss_ce: 0.006067
2021-11-30 16:02:50,880 iteration 6098 : loss : 0.018347, loss_ce: 0.007157
2021-11-30 16:02:52,441 iteration 6099 : loss : 0.019506, loss_ce: 0.004360
2021-11-30 16:02:54,026 iteration 6100 : loss : 0.025297, loss_ce: 0.008055
2021-11-30 16:02:55,578 iteration 6101 : loss : 0.012377, loss_ce: 0.004351
2021-11-30 16:02:57,040 iteration 6102 : loss : 0.014876, loss_ce: 0.004539
2021-11-30 16:02:58,446 iteration 6103 : loss : 0.010135, loss_ce: 0.003651
 90%|██████████████████████████   | 359/400 [2:47:48<18:12, 26.65s/it]2021-11-30 16:03:00,048 iteration 6104 : loss : 0.018931, loss_ce: 0.005462
2021-11-30 16:03:01,510 iteration 6105 : loss : 0.015456, loss_ce: 0.005381
2021-11-30 16:03:02,939 iteration 6106 : loss : 0.012822, loss_ce: 0.004174
2021-11-30 16:03:04,406 iteration 6107 : loss : 0.013373, loss_ce: 0.004158
2021-11-30 16:03:05,966 iteration 6108 : loss : 0.012874, loss_ce: 0.003877
2021-11-30 16:03:07,452 iteration 6109 : loss : 0.012832, loss_ce: 0.004684
2021-11-30 16:03:08,978 iteration 6110 : loss : 0.013365, loss_ce: 0.005872
2021-11-30 16:03:10,542 iteration 6111 : loss : 0.019286, loss_ce: 0.007240
2021-11-30 16:03:12,085 iteration 6112 : loss : 0.014093, loss_ce: 0.005496
2021-11-30 16:03:13,649 iteration 6113 : loss : 0.015789, loss_ce: 0.005033
2021-11-30 16:03:15,138 iteration 6114 : loss : 0.023542, loss_ce: 0.010089
2021-11-30 16:03:16,738 iteration 6115 : loss : 0.020419, loss_ce: 0.005775
2021-11-30 16:03:18,294 iteration 6116 : loss : 0.015205, loss_ce: 0.006195
2021-11-30 16:03:19,768 iteration 6117 : loss : 0.017885, loss_ce: 0.007103
2021-11-30 16:03:21,309 iteration 6118 : loss : 0.017309, loss_ce: 0.007183
2021-11-30 16:03:22,809 iteration 6119 : loss : 0.015495, loss_ce: 0.004872
2021-11-30 16:03:22,809 Training Data Eval:
2021-11-30 16:03:30,491   Average segmentation loss on training set: 0.0093
2021-11-30 16:03:30,492 Validation Data Eval:
2021-11-30 16:03:33,117   Average segmentation loss on validation set: 0.0719
2021-11-30 16:03:34,634 iteration 6120 : loss : 0.013249, loss_ce: 0.005680
 90%|██████████████████████████   | 360/400 [2:48:25<19:40, 29.51s/it]2021-11-30 16:03:36,201 iteration 6121 : loss : 0.015382, loss_ce: 0.006769
2021-11-30 16:03:37,760 iteration 6122 : loss : 0.018916, loss_ce: 0.006503
2021-11-30 16:03:39,354 iteration 6123 : loss : 0.016674, loss_ce: 0.006598
2021-11-30 16:03:40,882 iteration 6124 : loss : 0.017761, loss_ce: 0.005421
2021-11-30 16:03:42,475 iteration 6125 : loss : 0.019178, loss_ce: 0.006200
2021-11-30 16:03:43,989 iteration 6126 : loss : 0.022094, loss_ce: 0.004556
2021-11-30 16:03:45,486 iteration 6127 : loss : 0.016263, loss_ce: 0.005867
2021-11-30 16:03:47,075 iteration 6128 : loss : 0.019125, loss_ce: 0.005888
2021-11-30 16:03:48,588 iteration 6129 : loss : 0.012651, loss_ce: 0.006135
2021-11-30 16:03:50,167 iteration 6130 : loss : 0.016457, loss_ce: 0.006036
2021-11-30 16:03:51,684 iteration 6131 : loss : 0.017247, loss_ce: 0.008963
2021-11-30 16:03:53,196 iteration 6132 : loss : 0.020980, loss_ce: 0.004692
2021-11-30 16:03:54,659 iteration 6133 : loss : 0.013804, loss_ce: 0.006946
2021-11-30 16:03:56,109 iteration 6134 : loss : 0.010598, loss_ce: 0.004378
2021-11-30 16:03:57,574 iteration 6135 : loss : 0.011558, loss_ce: 0.004350
2021-11-30 16:03:59,104 iteration 6136 : loss : 0.013969, loss_ce: 0.004442
2021-11-30 16:04:00,588 iteration 6137 : loss : 0.013553, loss_ce: 0.005354
 90%|██████████████████████████▏  | 361/400 [2:48:51<18:29, 28.44s/it]2021-11-30 16:04:02,097 iteration 6138 : loss : 0.013362, loss_ce: 0.004948
2021-11-30 16:04:03,660 iteration 6139 : loss : 0.017691, loss_ce: 0.009025
2021-11-30 16:04:05,163 iteration 6140 : loss : 0.010846, loss_ce: 0.003758
2021-11-30 16:04:06,710 iteration 6141 : loss : 0.016073, loss_ce: 0.006181
2021-11-30 16:04:08,374 iteration 6142 : loss : 0.018544, loss_ce: 0.007241
2021-11-30 16:04:09,844 iteration 6143 : loss : 0.013154, loss_ce: 0.005913
2021-11-30 16:04:11,364 iteration 6144 : loss : 0.012587, loss_ce: 0.005343
2021-11-30 16:04:12,892 iteration 6145 : loss : 0.033025, loss_ce: 0.009171
2021-11-30 16:04:14,414 iteration 6146 : loss : 0.013562, loss_ce: 0.005963
2021-11-30 16:04:15,930 iteration 6147 : loss : 0.012676, loss_ce: 0.003259
2021-11-30 16:04:17,395 iteration 6148 : loss : 0.011178, loss_ce: 0.003608
2021-11-30 16:04:18,866 iteration 6149 : loss : 0.018470, loss_ce: 0.006240
2021-11-30 16:04:20,347 iteration 6150 : loss : 0.019603, loss_ce: 0.006246
2021-11-30 16:04:21,849 iteration 6151 : loss : 0.016306, loss_ce: 0.003871
2021-11-30 16:04:23,336 iteration 6152 : loss : 0.015606, loss_ce: 0.005857
2021-11-30 16:04:24,904 iteration 6153 : loss : 0.023466, loss_ce: 0.010901
2021-11-30 16:04:26,487 iteration 6154 : loss : 0.021061, loss_ce: 0.009091
 90%|██████████████████████████▏  | 362/400 [2:49:17<17:31, 27.68s/it]2021-11-30 16:04:27,994 iteration 6155 : loss : 0.015441, loss_ce: 0.006674
2021-11-30 16:04:29,503 iteration 6156 : loss : 0.012047, loss_ce: 0.004890
2021-11-30 16:04:31,059 iteration 6157 : loss : 0.018937, loss_ce: 0.006497
2021-11-30 16:04:32,544 iteration 6158 : loss : 0.019154, loss_ce: 0.007965
2021-11-30 16:04:33,974 iteration 6159 : loss : 0.010440, loss_ce: 0.004050
2021-11-30 16:04:35,679 iteration 6160 : loss : 0.021822, loss_ce: 0.009776
2021-11-30 16:04:37,120 iteration 6161 : loss : 0.014126, loss_ce: 0.004580
2021-11-30 16:04:38,660 iteration 6162 : loss : 0.012896, loss_ce: 0.004572
2021-11-30 16:04:40,180 iteration 6163 : loss : 0.013053, loss_ce: 0.004809
2021-11-30 16:04:41,656 iteration 6164 : loss : 0.013085, loss_ce: 0.003837
2021-11-30 16:04:43,184 iteration 6165 : loss : 0.015836, loss_ce: 0.005513
2021-11-30 16:04:44,722 iteration 6166 : loss : 0.017249, loss_ce: 0.007528
2021-11-30 16:04:46,154 iteration 6167 : loss : 0.012946, loss_ce: 0.004500
2021-11-30 16:04:47,766 iteration 6168 : loss : 0.023124, loss_ce: 0.007324
2021-11-30 16:04:49,268 iteration 6169 : loss : 0.013064, loss_ce: 0.005287
2021-11-30 16:04:50,809 iteration 6170 : loss : 0.016508, loss_ce: 0.007188
2021-11-30 16:04:52,322 iteration 6171 : loss : 0.018726, loss_ce: 0.005159
 91%|██████████████████████████▎  | 363/400 [2:49:42<16:43, 27.13s/it]2021-11-30 16:04:53,863 iteration 6172 : loss : 0.017144, loss_ce: 0.005898
2021-11-30 16:04:55,288 iteration 6173 : loss : 0.011980, loss_ce: 0.004287
2021-11-30 16:04:56,790 iteration 6174 : loss : 0.015915, loss_ce: 0.007827
2021-11-30 16:04:58,257 iteration 6175 : loss : 0.011900, loss_ce: 0.003377
2021-11-30 16:04:59,788 iteration 6176 : loss : 0.014902, loss_ce: 0.007239
2021-11-30 16:05:01,409 iteration 6177 : loss : 0.016426, loss_ce: 0.007853
2021-11-30 16:05:02,963 iteration 6178 : loss : 0.016115, loss_ce: 0.004730
2021-11-30 16:05:04,496 iteration 6179 : loss : 0.018186, loss_ce: 0.006252
2021-11-30 16:05:06,039 iteration 6180 : loss : 0.023797, loss_ce: 0.003905
2021-11-30 16:05:07,530 iteration 6181 : loss : 0.015607, loss_ce: 0.005847
2021-11-30 16:05:09,056 iteration 6182 : loss : 0.012252, loss_ce: 0.004892
2021-11-30 16:05:10,535 iteration 6183 : loss : 0.016093, loss_ce: 0.006184
2021-11-30 16:05:12,029 iteration 6184 : loss : 0.016540, loss_ce: 0.007011
2021-11-30 16:05:13,592 iteration 6185 : loss : 0.025741, loss_ce: 0.006463
2021-11-30 16:05:15,045 iteration 6186 : loss : 0.013668, loss_ce: 0.005115
2021-11-30 16:05:16,517 iteration 6187 : loss : 0.020689, loss_ce: 0.005964
2021-11-30 16:05:17,979 iteration 6188 : loss : 0.014918, loss_ce: 0.005303
 91%|██████████████████████████▍  | 364/400 [2:50:08<16:00, 26.69s/it]2021-11-30 16:05:19,593 iteration 6189 : loss : 0.021429, loss_ce: 0.008240
2021-11-30 16:05:21,116 iteration 6190 : loss : 0.013500, loss_ce: 0.005177
2021-11-30 16:05:22,698 iteration 6191 : loss : 0.021189, loss_ce: 0.005351
2021-11-30 16:05:24,242 iteration 6192 : loss : 0.012552, loss_ce: 0.004248
2021-11-30 16:05:25,705 iteration 6193 : loss : 0.013232, loss_ce: 0.004126
2021-11-30 16:05:27,271 iteration 6194 : loss : 0.012292, loss_ce: 0.004611
2021-11-30 16:05:28,841 iteration 6195 : loss : 0.018328, loss_ce: 0.006008
2021-11-30 16:05:30,312 iteration 6196 : loss : 0.019774, loss_ce: 0.006690
2021-11-30 16:05:31,906 iteration 6197 : loss : 0.036739, loss_ce: 0.013917
2021-11-30 16:05:33,501 iteration 6198 : loss : 0.017235, loss_ce: 0.007075
2021-11-30 16:05:34,965 iteration 6199 : loss : 0.013042, loss_ce: 0.004669
2021-11-30 16:05:36,504 iteration 6200 : loss : 0.018663, loss_ce: 0.007451
2021-11-30 16:05:38,023 iteration 6201 : loss : 0.013576, loss_ce: 0.005038
2021-11-30 16:05:39,528 iteration 6202 : loss : 0.012519, loss_ce: 0.003923
2021-11-30 16:05:41,030 iteration 6203 : loss : 0.019618, loss_ce: 0.006574
2021-11-30 16:05:42,586 iteration 6204 : loss : 0.014424, loss_ce: 0.005698
2021-11-30 16:05:42,586 Training Data Eval:
2021-11-30 16:05:50,243   Average segmentation loss on training set: 0.0093
2021-11-30 16:05:50,244 Validation Data Eval:
2021-11-30 16:05:52,883   Average segmentation loss on validation set: 0.0704
2021-11-30 16:05:54,483 iteration 6205 : loss : 0.021310, loss_ce: 0.010100
 91%|██████████████████████████▍  | 365/400 [2:50:45<17:17, 29.63s/it]2021-11-30 16:05:56,052 iteration 6206 : loss : 0.015181, loss_ce: 0.006598
2021-11-30 16:05:57,561 iteration 6207 : loss : 0.017006, loss_ce: 0.009124
2021-11-30 16:05:59,113 iteration 6208 : loss : 0.013566, loss_ce: 0.004766
2021-11-30 16:06:00,651 iteration 6209 : loss : 0.025867, loss_ce: 0.008640
2021-11-30 16:06:02,146 iteration 6210 : loss : 0.017405, loss_ce: 0.006489
2021-11-30 16:06:03,610 iteration 6211 : loss : 0.013306, loss_ce: 0.004799
2021-11-30 16:06:05,097 iteration 6212 : loss : 0.016943, loss_ce: 0.006716
2021-11-30 16:06:06,611 iteration 6213 : loss : 0.020881, loss_ce: 0.007706
2021-11-30 16:06:08,112 iteration 6214 : loss : 0.011025, loss_ce: 0.004075
2021-11-30 16:06:09,680 iteration 6215 : loss : 0.016102, loss_ce: 0.005029
2021-11-30 16:06:11,179 iteration 6216 : loss : 0.011272, loss_ce: 0.004266
2021-11-30 16:06:12,626 iteration 6217 : loss : 0.017198, loss_ce: 0.005530
2021-11-30 16:06:14,152 iteration 6218 : loss : 0.016726, loss_ce: 0.006875
2021-11-30 16:06:15,658 iteration 6219 : loss : 0.014237, loss_ce: 0.005317
2021-11-30 16:06:17,125 iteration 6220 : loss : 0.012222, loss_ce: 0.002739
2021-11-30 16:06:18,667 iteration 6221 : loss : 0.014314, loss_ce: 0.004184
2021-11-30 16:06:20,127 iteration 6222 : loss : 0.013217, loss_ce: 0.006243
 92%|██████████████████████████▌  | 366/400 [2:51:10<16:06, 28.44s/it]2021-11-30 16:06:21,720 iteration 6223 : loss : 0.018015, loss_ce: 0.008160
2021-11-30 16:06:23,241 iteration 6224 : loss : 0.017221, loss_ce: 0.006641
2021-11-30 16:06:24,778 iteration 6225 : loss : 0.016944, loss_ce: 0.004930
2021-11-30 16:06:26,262 iteration 6226 : loss : 0.012010, loss_ce: 0.003880
2021-11-30 16:06:27,707 iteration 6227 : loss : 0.013031, loss_ce: 0.005177
2021-11-30 16:06:29,213 iteration 6228 : loss : 0.013097, loss_ce: 0.004532
2021-11-30 16:06:31,447 iteration 6229 : loss : 0.010964, loss_ce: 0.004601
2021-11-30 16:06:32,929 iteration 6230 : loss : 0.017569, loss_ce: 0.005291
2021-11-30 16:06:34,450 iteration 6231 : loss : 0.019551, loss_ce: 0.008386
2021-11-30 16:06:35,970 iteration 6232 : loss : 0.014339, loss_ce: 0.005904
2021-11-30 16:06:37,468 iteration 6233 : loss : 0.013907, loss_ce: 0.005988
2021-11-30 16:06:38,967 iteration 6234 : loss : 0.016783, loss_ce: 0.003703
2021-11-30 16:06:40,452 iteration 6235 : loss : 0.013934, loss_ce: 0.006793
2021-11-30 16:06:41,980 iteration 6236 : loss : 0.013787, loss_ce: 0.006509
2021-11-30 16:06:43,524 iteration 6237 : loss : 0.016508, loss_ce: 0.006876
2021-11-30 16:06:45,103 iteration 6238 : loss : 0.015594, loss_ce: 0.005052
2021-11-30 16:06:46,615 iteration 6239 : loss : 0.012269, loss_ce: 0.003557
 92%|██████████████████████████▌  | 367/400 [2:51:37<15:19, 27.85s/it]2021-11-30 16:06:48,170 iteration 6240 : loss : 0.015905, loss_ce: 0.006433
2021-11-30 16:06:49,632 iteration 6241 : loss : 0.010953, loss_ce: 0.005136
2021-11-30 16:06:51,220 iteration 6242 : loss : 0.026347, loss_ce: 0.011138
2021-11-30 16:06:52,732 iteration 6243 : loss : 0.011104, loss_ce: 0.004214
2021-11-30 16:06:54,335 iteration 6244 : loss : 0.016194, loss_ce: 0.006557
2021-11-30 16:06:55,830 iteration 6245 : loss : 0.014865, loss_ce: 0.004946
2021-11-30 16:06:57,308 iteration 6246 : loss : 0.013366, loss_ce: 0.005561
2021-11-30 16:06:58,841 iteration 6247 : loss : 0.017105, loss_ce: 0.004112
2021-11-30 16:07:00,355 iteration 6248 : loss : 0.014654, loss_ce: 0.005896
2021-11-30 16:07:01,858 iteration 6249 : loss : 0.013999, loss_ce: 0.004265
2021-11-30 16:07:03,396 iteration 6250 : loss : 0.016569, loss_ce: 0.006344
2021-11-30 16:07:05,000 iteration 6251 : loss : 0.017409, loss_ce: 0.006534
2021-11-30 16:07:06,485 iteration 6252 : loss : 0.014227, loss_ce: 0.006018
2021-11-30 16:07:08,045 iteration 6253 : loss : 0.019781, loss_ce: 0.007456
2021-11-30 16:07:09,540 iteration 6254 : loss : 0.014341, loss_ce: 0.006385
2021-11-30 16:07:11,058 iteration 6255 : loss : 0.015133, loss_ce: 0.006304
2021-11-30 16:07:12,643 iteration 6256 : loss : 0.021801, loss_ce: 0.009154
 92%|██████████████████████████▋  | 368/400 [2:52:03<14:33, 27.30s/it]2021-11-30 16:07:14,257 iteration 6257 : loss : 0.023824, loss_ce: 0.007675
2021-11-30 16:07:15,799 iteration 6258 : loss : 0.019071, loss_ce: 0.006846
2021-11-30 16:07:17,366 iteration 6259 : loss : 0.015498, loss_ce: 0.005768
2021-11-30 16:07:18,883 iteration 6260 : loss : 0.014072, loss_ce: 0.005767
2021-11-30 16:07:20,381 iteration 6261 : loss : 0.014533, loss_ce: 0.004753
2021-11-30 16:07:21,916 iteration 6262 : loss : 0.020698, loss_ce: 0.005416
2021-11-30 16:07:23,446 iteration 6263 : loss : 0.020807, loss_ce: 0.003883
2021-11-30 16:07:24,985 iteration 6264 : loss : 0.021408, loss_ce: 0.007147
2021-11-30 16:07:26,517 iteration 6265 : loss : 0.015680, loss_ce: 0.005773
2021-11-30 16:07:28,016 iteration 6266 : loss : 0.018573, loss_ce: 0.009491
2021-11-30 16:07:29,501 iteration 6267 : loss : 0.016204, loss_ce: 0.007244
2021-11-30 16:07:31,040 iteration 6268 : loss : 0.016417, loss_ce: 0.006257
2021-11-30 16:07:32,423 iteration 6269 : loss : 0.011152, loss_ce: 0.003755
2021-11-30 16:07:33,920 iteration 6270 : loss : 0.012801, loss_ce: 0.005346
2021-11-30 16:07:35,424 iteration 6271 : loss : 0.016099, loss_ce: 0.004444
2021-11-30 16:07:36,985 iteration 6272 : loss : 0.025101, loss_ce: 0.009230
2021-11-30 16:07:38,540 iteration 6273 : loss : 0.012788, loss_ce: 0.004393
 92%|██████████████████████████▊  | 369/400 [2:52:29<13:53, 26.88s/it]2021-11-30 16:07:40,201 iteration 6274 : loss : 0.026930, loss_ce: 0.009101
2021-11-30 16:07:41,728 iteration 6275 : loss : 0.014184, loss_ce: 0.006829
2021-11-30 16:07:43,253 iteration 6276 : loss : 0.015489, loss_ce: 0.005697
2021-11-30 16:07:44,737 iteration 6277 : loss : 0.012189, loss_ce: 0.003258
2021-11-30 16:07:46,254 iteration 6278 : loss : 0.022071, loss_ce: 0.007368
2021-11-30 16:07:47,758 iteration 6279 : loss : 0.018471, loss_ce: 0.007400
2021-11-30 16:07:49,239 iteration 6280 : loss : 0.020688, loss_ce: 0.007249
2021-11-30 16:07:50,875 iteration 6281 : loss : 0.028226, loss_ce: 0.007149
2021-11-30 16:07:52,363 iteration 6282 : loss : 0.013103, loss_ce: 0.004927
2021-11-30 16:07:53,826 iteration 6283 : loss : 0.010883, loss_ce: 0.004461
2021-11-30 16:07:55,349 iteration 6284 : loss : 0.016985, loss_ce: 0.007293
2021-11-30 16:07:56,930 iteration 6285 : loss : 0.015173, loss_ce: 0.004572
2021-11-30 16:07:58,425 iteration 6286 : loss : 0.013569, loss_ce: 0.004443
2021-11-30 16:07:59,917 iteration 6287 : loss : 0.016899, loss_ce: 0.004513
2021-11-30 16:08:01,365 iteration 6288 : loss : 0.011768, loss_ce: 0.003857
2021-11-30 16:08:02,908 iteration 6289 : loss : 0.014895, loss_ce: 0.006492
2021-11-30 16:08:02,908 Training Data Eval:
2021-11-30 16:08:10,554   Average segmentation loss on training set: 0.0087
2021-11-30 16:08:10,555 Validation Data Eval:
2021-11-30 16:08:13,295   Average segmentation loss on validation set: 0.0661
2021-11-30 16:08:14,862 iteration 6290 : loss : 0.020384, loss_ce: 0.008402
 92%|██████████████████████████▊  | 370/400 [2:53:05<14:51, 29.71s/it]2021-11-30 16:08:16,422 iteration 6291 : loss : 0.010882, loss_ce: 0.004396
2021-11-30 16:08:17,952 iteration 6292 : loss : 0.014451, loss_ce: 0.004522
2021-11-30 16:08:19,493 iteration 6293 : loss : 0.017413, loss_ce: 0.007671
2021-11-30 16:08:21,034 iteration 6294 : loss : 0.022962, loss_ce: 0.006224
2021-11-30 16:08:22,549 iteration 6295 : loss : 0.020528, loss_ce: 0.012277
2021-11-30 16:08:24,132 iteration 6296 : loss : 0.021864, loss_ce: 0.007001
2021-11-30 16:08:25,657 iteration 6297 : loss : 0.020173, loss_ce: 0.006726
2021-11-30 16:08:27,212 iteration 6298 : loss : 0.019557, loss_ce: 0.007300
2021-11-30 16:08:28,738 iteration 6299 : loss : 0.014747, loss_ce: 0.004682
2021-11-30 16:08:30,226 iteration 6300 : loss : 0.023525, loss_ce: 0.007717
2021-11-30 16:08:31,706 iteration 6301 : loss : 0.016177, loss_ce: 0.010883
2021-11-30 16:08:33,238 iteration 6302 : loss : 0.014265, loss_ce: 0.004873
2021-11-30 16:08:34,675 iteration 6303 : loss : 0.012602, loss_ce: 0.002862
2021-11-30 16:08:36,145 iteration 6304 : loss : 0.016453, loss_ce: 0.005147
2021-11-30 16:08:37,714 iteration 6305 : loss : 0.020108, loss_ce: 0.007960
2021-11-30 16:08:39,210 iteration 6306 : loss : 0.021801, loss_ce: 0.005733
2021-11-30 16:08:40,715 iteration 6307 : loss : 0.011793, loss_ce: 0.005169
 93%|██████████████████████████▉  | 371/400 [2:53:31<13:48, 28.56s/it]2021-11-30 16:08:42,227 iteration 6308 : loss : 0.022824, loss_ce: 0.004942
2021-11-30 16:08:43,765 iteration 6309 : loss : 0.018138, loss_ce: 0.007335
2021-11-30 16:08:45,256 iteration 6310 : loss : 0.015967, loss_ce: 0.006987
2021-11-30 16:08:46,779 iteration 6311 : loss : 0.011763, loss_ce: 0.004688
2021-11-30 16:08:48,312 iteration 6312 : loss : 0.027754, loss_ce: 0.011172
2021-11-30 16:08:49,893 iteration 6313 : loss : 0.021282, loss_ce: 0.011275
2021-11-30 16:08:51,383 iteration 6314 : loss : 0.013908, loss_ce: 0.004529
2021-11-30 16:08:52,859 iteration 6315 : loss : 0.012487, loss_ce: 0.004229
2021-11-30 16:08:54,371 iteration 6316 : loss : 0.014094, loss_ce: 0.004922
2021-11-30 16:08:55,876 iteration 6317 : loss : 0.011838, loss_ce: 0.003198
2021-11-30 16:08:57,457 iteration 6318 : loss : 0.022019, loss_ce: 0.008973
2021-11-30 16:08:58,994 iteration 6319 : loss : 0.013560, loss_ce: 0.004919
2021-11-30 16:09:00,499 iteration 6320 : loss : 0.014039, loss_ce: 0.005116
2021-11-30 16:09:02,069 iteration 6321 : loss : 0.016715, loss_ce: 0.007561
2021-11-30 16:09:03,627 iteration 6322 : loss : 0.018398, loss_ce: 0.009165
2021-11-30 16:09:05,250 iteration 6323 : loss : 0.017801, loss_ce: 0.005704
2021-11-30 16:09:06,834 iteration 6324 : loss : 0.018994, loss_ce: 0.009241
 93%|██████████████████████████▉  | 372/400 [2:53:57<12:59, 27.83s/it]2021-11-30 16:09:08,408 iteration 6325 : loss : 0.018105, loss_ce: 0.005558
2021-11-30 16:09:09,877 iteration 6326 : loss : 0.019140, loss_ce: 0.008855
2021-11-30 16:09:11,380 iteration 6327 : loss : 0.017014, loss_ce: 0.005781
2021-11-30 16:09:12,962 iteration 6328 : loss : 0.012891, loss_ce: 0.005743
2021-11-30 16:09:14,420 iteration 6329 : loss : 0.014115, loss_ce: 0.007116
2021-11-30 16:09:15,927 iteration 6330 : loss : 0.015428, loss_ce: 0.005828
2021-11-30 16:09:17,494 iteration 6331 : loss : 0.014143, loss_ce: 0.005378
2021-11-30 16:09:19,026 iteration 6332 : loss : 0.013073, loss_ce: 0.003647
2021-11-30 16:09:20,525 iteration 6333 : loss : 0.011633, loss_ce: 0.005121
2021-11-30 16:09:22,043 iteration 6334 : loss : 0.020338, loss_ce: 0.005015
2021-11-30 16:09:23,625 iteration 6335 : loss : 0.014599, loss_ce: 0.005794
2021-11-30 16:09:25,118 iteration 6336 : loss : 0.014310, loss_ce: 0.005875
2021-11-30 16:09:26,652 iteration 6337 : loss : 0.015098, loss_ce: 0.005021
2021-11-30 16:09:28,160 iteration 6338 : loss : 0.017252, loss_ce: 0.005470
2021-11-30 16:09:29,656 iteration 6339 : loss : 0.020366, loss_ce: 0.010504
2021-11-30 16:09:31,148 iteration 6340 : loss : 0.015439, loss_ce: 0.006848
2021-11-30 16:09:32,599 iteration 6341 : loss : 0.010541, loss_ce: 0.003620
 93%|███████████████████████████  | 373/400 [2:54:23<12:14, 27.21s/it]2021-11-30 16:09:34,206 iteration 6342 : loss : 0.020618, loss_ce: 0.007157
2021-11-30 16:09:35,714 iteration 6343 : loss : 0.012176, loss_ce: 0.004225
2021-11-30 16:09:37,203 iteration 6344 : loss : 0.017461, loss_ce: 0.005439
2021-11-30 16:09:38,701 iteration 6345 : loss : 0.019326, loss_ce: 0.002772
2021-11-30 16:09:40,228 iteration 6346 : loss : 0.018003, loss_ce: 0.005772
2021-11-30 16:09:41,750 iteration 6347 : loss : 0.022432, loss_ce: 0.007803
2021-11-30 16:09:43,174 iteration 6348 : loss : 0.009938, loss_ce: 0.004171
2021-11-30 16:09:44,704 iteration 6349 : loss : 0.017688, loss_ce: 0.007722
2021-11-30 16:09:46,335 iteration 6350 : loss : 0.019500, loss_ce: 0.006500
2021-11-30 16:09:47,894 iteration 6351 : loss : 0.013840, loss_ce: 0.006453
2021-11-30 16:09:49,399 iteration 6352 : loss : 0.018669, loss_ce: 0.005281
2021-11-30 16:09:50,931 iteration 6353 : loss : 0.024151, loss_ce: 0.010784
2021-11-30 16:09:52,438 iteration 6354 : loss : 0.017840, loss_ce: 0.009442
2021-11-30 16:09:53,935 iteration 6355 : loss : 0.016188, loss_ce: 0.005647
2021-11-30 16:09:55,512 iteration 6356 : loss : 0.029351, loss_ce: 0.007594
2021-11-30 16:09:57,008 iteration 6357 : loss : 0.014198, loss_ce: 0.005133
2021-11-30 16:09:58,634 iteration 6358 : loss : 0.016913, loss_ce: 0.007693
 94%|███████████████████████████  | 374/400 [2:54:49<11:38, 26.86s/it]2021-11-30 16:10:00,234 iteration 6359 : loss : 0.023009, loss_ce: 0.006511
2021-11-30 16:10:01,701 iteration 6360 : loss : 0.018827, loss_ce: 0.007301
2021-11-30 16:10:03,265 iteration 6361 : loss : 0.015774, loss_ce: 0.005637
2021-11-30 16:10:04,805 iteration 6362 : loss : 0.015712, loss_ce: 0.006598
2021-11-30 16:10:06,371 iteration 6363 : loss : 0.027101, loss_ce: 0.010270
2021-11-30 16:10:07,841 iteration 6364 : loss : 0.011129, loss_ce: 0.002938
2021-11-30 16:10:09,359 iteration 6365 : loss : 0.018612, loss_ce: 0.009387
2021-11-30 16:10:10,946 iteration 6366 : loss : 0.016602, loss_ce: 0.006097
2021-11-30 16:10:12,560 iteration 6367 : loss : 0.019797, loss_ce: 0.007756
2021-11-30 16:10:14,114 iteration 6368 : loss : 0.021155, loss_ce: 0.008293
2021-11-30 16:10:15,648 iteration 6369 : loss : 0.011070, loss_ce: 0.004523
2021-11-30 16:10:17,168 iteration 6370 : loss : 0.017405, loss_ce: 0.006011
2021-11-30 16:10:18,762 iteration 6371 : loss : 0.021842, loss_ce: 0.007480
2021-11-30 16:10:20,238 iteration 6372 : loss : 0.010066, loss_ce: 0.004222
2021-11-30 16:10:21,718 iteration 6373 : loss : 0.012924, loss_ce: 0.004775
2021-11-30 16:10:23,242 iteration 6374 : loss : 0.019114, loss_ce: 0.008210
2021-11-30 16:10:23,242 Training Data Eval:
2021-11-30 16:10:30,895   Average segmentation loss on training set: 0.0087
2021-11-30 16:10:30,895 Validation Data Eval:
2021-11-30 16:10:33,526   Average segmentation loss on validation set: 0.0653
2021-11-30 16:10:35,064 iteration 6375 : loss : 0.024252, loss_ce: 0.006881
 94%|███████████████████████████▏ | 375/400 [2:55:25<12:23, 29.73s/it]2021-11-30 16:10:36,669 iteration 6376 : loss : 0.018432, loss_ce: 0.005817
2021-11-30 16:10:38,203 iteration 6377 : loss : 0.015619, loss_ce: 0.005126
2021-11-30 16:10:39,634 iteration 6378 : loss : 0.014202, loss_ce: 0.006509
2021-11-30 16:10:41,154 iteration 6379 : loss : 0.018926, loss_ce: 0.004490
2021-11-30 16:10:42,639 iteration 6380 : loss : 0.015542, loss_ce: 0.005910
2021-11-30 16:10:44,131 iteration 6381 : loss : 0.010551, loss_ce: 0.003190
2021-11-30 16:10:45,563 iteration 6382 : loss : 0.013643, loss_ce: 0.004673
2021-11-30 16:10:47,126 iteration 6383 : loss : 0.018300, loss_ce: 0.006444
2021-11-30 16:10:48,638 iteration 6384 : loss : 0.013867, loss_ce: 0.005739
2021-11-30 16:10:50,174 iteration 6385 : loss : 0.015293, loss_ce: 0.004683
2021-11-30 16:10:51,734 iteration 6386 : loss : 0.015473, loss_ce: 0.005034
2021-11-30 16:10:53,331 iteration 6387 : loss : 0.019328, loss_ce: 0.008648
2021-11-30 16:10:54,868 iteration 6388 : loss : 0.017126, loss_ce: 0.007088
2021-11-30 16:10:56,279 iteration 6389 : loss : 0.012402, loss_ce: 0.004216
2021-11-30 16:10:57,789 iteration 6390 : loss : 0.019951, loss_ce: 0.010025
2021-11-30 16:10:59,258 iteration 6391 : loss : 0.012797, loss_ce: 0.006550
2021-11-30 16:11:00,843 iteration 6392 : loss : 0.018515, loss_ce: 0.004778
 94%|███████████████████████████▎ | 376/400 [2:55:51<11:25, 28.54s/it]2021-11-30 16:11:02,384 iteration 6393 : loss : 0.013600, loss_ce: 0.004906
2021-11-30 16:11:03,947 iteration 6394 : loss : 0.016103, loss_ce: 0.005836
2021-11-30 16:11:05,441 iteration 6395 : loss : 0.011542, loss_ce: 0.003313
2021-11-30 16:11:06,962 iteration 6396 : loss : 0.015178, loss_ce: 0.005573
2021-11-30 16:11:08,493 iteration 6397 : loss : 0.014096, loss_ce: 0.005568
2021-11-30 16:11:10,020 iteration 6398 : loss : 0.014655, loss_ce: 0.004944
2021-11-30 16:11:11,514 iteration 6399 : loss : 0.015413, loss_ce: 0.005264
2021-11-30 16:11:13,007 iteration 6400 : loss : 0.013109, loss_ce: 0.005384
2021-11-30 16:11:15,394 iteration 6401 : loss : 0.016302, loss_ce: 0.005917
2021-11-30 16:11:16,827 iteration 6402 : loss : 0.015765, loss_ce: 0.008129
2021-11-30 16:11:18,364 iteration 6403 : loss : 0.026427, loss_ce: 0.010361
2021-11-30 16:11:19,825 iteration 6404 : loss : 0.014692, loss_ce: 0.006488
2021-11-30 16:11:21,290 iteration 6405 : loss : 0.018790, loss_ce: 0.005573
2021-11-30 16:11:22,948 iteration 6406 : loss : 0.034726, loss_ce: 0.008793
2021-11-30 16:11:24,494 iteration 6407 : loss : 0.020478, loss_ce: 0.005241
2021-11-30 16:11:25,927 iteration 6408 : loss : 0.011005, loss_ce: 0.003760
2021-11-30 16:11:27,428 iteration 6409 : loss : 0.015857, loss_ce: 0.007969
 94%|███████████████████████████▎ | 377/400 [2:56:17<10:42, 27.96s/it]2021-11-30 16:11:28,940 iteration 6410 : loss : 0.012027, loss_ce: 0.004059
2021-11-30 16:11:30,481 iteration 6411 : loss : 0.014835, loss_ce: 0.005750
2021-11-30 16:11:32,020 iteration 6412 : loss : 0.013180, loss_ce: 0.004836
2021-11-30 16:11:33,529 iteration 6413 : loss : 0.016312, loss_ce: 0.007317
2021-11-30 16:11:35,020 iteration 6414 : loss : 0.013483, loss_ce: 0.005569
2021-11-30 16:11:36,501 iteration 6415 : loss : 0.011328, loss_ce: 0.003787
2021-11-30 16:11:38,040 iteration 6416 : loss : 0.011482, loss_ce: 0.004720
2021-11-30 16:11:39,492 iteration 6417 : loss : 0.013805, loss_ce: 0.005441
2021-11-30 16:11:40,984 iteration 6418 : loss : 0.011012, loss_ce: 0.004888
2021-11-30 16:11:42,599 iteration 6419 : loss : 0.021378, loss_ce: 0.008385
2021-11-30 16:11:44,177 iteration 6420 : loss : 0.019516, loss_ce: 0.005418
2021-11-30 16:11:45,723 iteration 6421 : loss : 0.013282, loss_ce: 0.004922
2021-11-30 16:11:47,241 iteration 6422 : loss : 0.019140, loss_ce: 0.005360
2021-11-30 16:11:48,789 iteration 6423 : loss : 0.015783, loss_ce: 0.007065
2021-11-30 16:11:50,380 iteration 6424 : loss : 0.018046, loss_ce: 0.009415
2021-11-30 16:11:51,877 iteration 6425 : loss : 0.013393, loss_ce: 0.003726
2021-11-30 16:11:53,464 iteration 6426 : loss : 0.019707, loss_ce: 0.006846
 94%|███████████████████████████▍ | 378/400 [2:56:43<10:02, 27.38s/it]2021-11-30 16:11:55,052 iteration 6427 : loss : 0.013830, loss_ce: 0.004126
2021-11-30 16:11:56,555 iteration 6428 : loss : 0.016853, loss_ce: 0.004737
2021-11-30 16:11:58,068 iteration 6429 : loss : 0.013082, loss_ce: 0.003905
2021-11-30 16:11:59,636 iteration 6430 : loss : 0.017237, loss_ce: 0.007306
2021-11-30 16:12:01,099 iteration 6431 : loss : 0.012229, loss_ce: 0.004571
2021-11-30 16:12:02,637 iteration 6432 : loss : 0.013323, loss_ce: 0.005164
2021-11-30 16:12:04,150 iteration 6433 : loss : 0.012763, loss_ce: 0.004006
2021-11-30 16:12:05,632 iteration 6434 : loss : 0.015155, loss_ce: 0.005992
2021-11-30 16:12:07,162 iteration 6435 : loss : 0.014357, loss_ce: 0.005071
2021-11-30 16:12:08,658 iteration 6436 : loss : 0.012241, loss_ce: 0.005165
2021-11-30 16:12:10,179 iteration 6437 : loss : 0.016522, loss_ce: 0.005163
2021-11-30 16:12:11,717 iteration 6438 : loss : 0.017703, loss_ce: 0.005252
2021-11-30 16:12:13,201 iteration 6439 : loss : 0.012710, loss_ce: 0.005458
2021-11-30 16:12:14,752 iteration 6440 : loss : 0.017686, loss_ce: 0.008618
2021-11-30 16:12:16,210 iteration 6441 : loss : 0.010947, loss_ce: 0.004963
2021-11-30 16:12:17,746 iteration 6442 : loss : 0.015040, loss_ce: 0.004849
2021-11-30 16:12:19,205 iteration 6443 : loss : 0.010827, loss_ce: 0.003605
 95%|███████████████████████████▍ | 379/400 [2:57:09<09:24, 26.89s/it]2021-11-30 16:12:20,778 iteration 6444 : loss : 0.012938, loss_ce: 0.005577
2021-11-30 16:12:22,280 iteration 6445 : loss : 0.018591, loss_ce: 0.006526
2021-11-30 16:12:23,798 iteration 6446 : loss : 0.014622, loss_ce: 0.005683
2021-11-30 16:12:25,334 iteration 6447 : loss : 0.027938, loss_ce: 0.004175
2021-11-30 16:12:26,893 iteration 6448 : loss : 0.018276, loss_ce: 0.007144
2021-11-30 16:12:28,390 iteration 6449 : loss : 0.013496, loss_ce: 0.003292
2021-11-30 16:12:29,870 iteration 6450 : loss : 0.014267, loss_ce: 0.006085
2021-11-30 16:12:31,394 iteration 6451 : loss : 0.013504, loss_ce: 0.004997
2021-11-30 16:12:32,983 iteration 6452 : loss : 0.022655, loss_ce: 0.007369
2021-11-30 16:12:34,472 iteration 6453 : loss : 0.018563, loss_ce: 0.006819
2021-11-30 16:12:35,918 iteration 6454 : loss : 0.017696, loss_ce: 0.006982
2021-11-30 16:12:37,466 iteration 6455 : loss : 0.014315, loss_ce: 0.006094
2021-11-30 16:12:38,992 iteration 6456 : loss : 0.016054, loss_ce: 0.006277
2021-11-30 16:12:40,523 iteration 6457 : loss : 0.022437, loss_ce: 0.006566
2021-11-30 16:12:41,983 iteration 6458 : loss : 0.014628, loss_ce: 0.005383
2021-11-30 16:12:43,483 iteration 6459 : loss : 0.010643, loss_ce: 0.002734
2021-11-30 16:12:43,483 Training Data Eval:
2021-11-30 16:12:51,140   Average segmentation loss on training set: 0.0086
2021-11-30 16:12:51,141 Validation Data Eval:
2021-11-30 16:12:53,883   Average segmentation loss on validation set: 0.0740
2021-11-30 16:12:55,441 iteration 6460 : loss : 0.017627, loss_ce: 0.007698
 95%|███████████████████████████▌ | 380/400 [2:57:45<09:53, 29.69s/it]2021-11-30 16:12:57,034 iteration 6461 : loss : 0.018724, loss_ce: 0.007870
2021-11-30 16:12:58,528 iteration 6462 : loss : 0.010732, loss_ce: 0.004404
2021-11-30 16:13:00,099 iteration 6463 : loss : 0.020133, loss_ce: 0.009572
2021-11-30 16:13:01,621 iteration 6464 : loss : 0.013977, loss_ce: 0.003640
2021-11-30 16:13:03,184 iteration 6465 : loss : 0.014665, loss_ce: 0.005675
2021-11-30 16:13:04,647 iteration 6466 : loss : 0.013972, loss_ce: 0.004342
2021-11-30 16:13:06,143 iteration 6467 : loss : 0.018004, loss_ce: 0.006793
2021-11-30 16:13:07,721 iteration 6468 : loss : 0.015420, loss_ce: 0.005617
2021-11-30 16:13:09,226 iteration 6469 : loss : 0.011513, loss_ce: 0.004623
2021-11-30 16:13:10,704 iteration 6470 : loss : 0.015552, loss_ce: 0.004444
2021-11-30 16:13:12,235 iteration 6471 : loss : 0.011637, loss_ce: 0.003786
2021-11-30 16:13:13,772 iteration 6472 : loss : 0.018672, loss_ce: 0.006070
2021-11-30 16:13:15,263 iteration 6473 : loss : 0.013889, loss_ce: 0.004373
2021-11-30 16:13:16,825 iteration 6474 : loss : 0.010848, loss_ce: 0.004341
2021-11-30 16:13:18,367 iteration 6475 : loss : 0.019568, loss_ce: 0.011738
2021-11-30 16:13:19,792 iteration 6476 : loss : 0.015952, loss_ce: 0.005616
2021-11-30 16:13:21,393 iteration 6477 : loss : 0.017138, loss_ce: 0.006715
 95%|███████████████████████████▌ | 381/400 [2:58:11<09:02, 28.57s/it]2021-11-30 16:13:23,000 iteration 6478 : loss : 0.021358, loss_ce: 0.007151
2021-11-30 16:13:24,501 iteration 6479 : loss : 0.018835, loss_ce: 0.006247
2021-11-30 16:13:25,995 iteration 6480 : loss : 0.014061, loss_ce: 0.006764
2021-11-30 16:13:27,549 iteration 6481 : loss : 0.016818, loss_ce: 0.007772
2021-11-30 16:13:29,005 iteration 6482 : loss : 0.013405, loss_ce: 0.004776
2021-11-30 16:13:30,562 iteration 6483 : loss : 0.021439, loss_ce: 0.006041
2021-11-30 16:13:32,039 iteration 6484 : loss : 0.014766, loss_ce: 0.006149
2021-11-30 16:13:33,557 iteration 6485 : loss : 0.017167, loss_ce: 0.007270
2021-11-30 16:13:35,128 iteration 6486 : loss : 0.021793, loss_ce: 0.008988
2021-11-30 16:13:36,753 iteration 6487 : loss : 0.018156, loss_ce: 0.007172
2021-11-30 16:13:38,286 iteration 6488 : loss : 0.014069, loss_ce: 0.005146
2021-11-30 16:13:39,759 iteration 6489 : loss : 0.012059, loss_ce: 0.005885
2021-11-30 16:13:41,299 iteration 6490 : loss : 0.015045, loss_ce: 0.004022
2021-11-30 16:13:42,814 iteration 6491 : loss : 0.014773, loss_ce: 0.005398
2021-11-30 16:13:44,391 iteration 6492 : loss : 0.016229, loss_ce: 0.006950
2021-11-30 16:13:45,909 iteration 6493 : loss : 0.018686, loss_ce: 0.006472
2021-11-30 16:13:47,323 iteration 6494 : loss : 0.009066, loss_ce: 0.003602
 96%|███████████████████████████▋ | 382/400 [2:58:37<08:20, 27.78s/it]2021-11-30 16:13:48,858 iteration 6495 : loss : 0.015466, loss_ce: 0.005996
2021-11-30 16:13:50,380 iteration 6496 : loss : 0.017443, loss_ce: 0.004061
2021-11-30 16:13:51,930 iteration 6497 : loss : 0.012731, loss_ce: 0.004400
2021-11-30 16:13:53,463 iteration 6498 : loss : 0.025093, loss_ce: 0.008890
2021-11-30 16:13:55,021 iteration 6499 : loss : 0.020709, loss_ce: 0.009250
2021-11-30 16:13:56,519 iteration 6500 : loss : 0.012711, loss_ce: 0.004571
2021-11-30 16:13:58,048 iteration 6501 : loss : 0.020015, loss_ce: 0.008339
2021-11-30 16:13:59,613 iteration 6502 : loss : 0.017429, loss_ce: 0.010149
2021-11-30 16:14:01,098 iteration 6503 : loss : 0.009817, loss_ce: 0.002645
2021-11-30 16:14:02,565 iteration 6504 : loss : 0.012575, loss_ce: 0.004365
2021-11-30 16:14:03,970 iteration 6505 : loss : 0.012225, loss_ce: 0.005553
2021-11-30 16:14:05,481 iteration 6506 : loss : 0.015745, loss_ce: 0.004397
2021-11-30 16:14:07,059 iteration 6507 : loss : 0.017311, loss_ce: 0.008618
2021-11-30 16:14:08,619 iteration 6508 : loss : 0.016228, loss_ce: 0.005565
2021-11-30 16:14:10,150 iteration 6509 : loss : 0.015377, loss_ce: 0.006076
2021-11-30 16:14:11,685 iteration 6510 : loss : 0.014734, loss_ce: 0.005778
2021-11-30 16:14:13,127 iteration 6511 : loss : 0.013659, loss_ce: 0.004861
 96%|███████████████████████████▊ | 383/400 [2:59:03<07:42, 27.19s/it]2021-11-30 16:14:14,646 iteration 6512 : loss : 0.014433, loss_ce: 0.004455
2021-11-30 16:14:16,165 iteration 6513 : loss : 0.015406, loss_ce: 0.005298
2021-11-30 16:14:17,761 iteration 6514 : loss : 0.013954, loss_ce: 0.004095
2021-11-30 16:14:19,321 iteration 6515 : loss : 0.017010, loss_ce: 0.005602
2021-11-30 16:14:20,856 iteration 6516 : loss : 0.020784, loss_ce: 0.009279
2021-11-30 16:14:22,339 iteration 6517 : loss : 0.015651, loss_ce: 0.003649
2021-11-30 16:14:23,857 iteration 6518 : loss : 0.012633, loss_ce: 0.004748
2021-11-30 16:14:25,379 iteration 6519 : loss : 0.016591, loss_ce: 0.004870
2021-11-30 16:14:26,945 iteration 6520 : loss : 0.017481, loss_ce: 0.006168
2021-11-30 16:14:28,422 iteration 6521 : loss : 0.018016, loss_ce: 0.007689
2021-11-30 16:14:29,954 iteration 6522 : loss : 0.011710, loss_ce: 0.004453
2021-11-30 16:14:31,406 iteration 6523 : loss : 0.011144, loss_ce: 0.004419
2021-11-30 16:14:32,972 iteration 6524 : loss : 0.016757, loss_ce: 0.007399
2021-11-30 16:14:34,498 iteration 6525 : loss : 0.017748, loss_ce: 0.007405
2021-11-30 16:14:36,007 iteration 6526 : loss : 0.015845, loss_ce: 0.006225
2021-11-30 16:14:37,450 iteration 6527 : loss : 0.014715, loss_ce: 0.006352
2021-11-30 16:14:38,923 iteration 6528 : loss : 0.016791, loss_ce: 0.005161
 96%|███████████████████████████▊ | 384/400 [2:59:29<07:08, 26.77s/it]2021-11-30 16:14:40,530 iteration 6529 : loss : 0.021226, loss_ce: 0.006517
2021-11-30 16:14:42,083 iteration 6530 : loss : 0.017673, loss_ce: 0.006242
2021-11-30 16:14:43,545 iteration 6531 : loss : 0.012323, loss_ce: 0.003329
2021-11-30 16:14:45,094 iteration 6532 : loss : 0.029784, loss_ce: 0.015101
2021-11-30 16:14:46,537 iteration 6533 : loss : 0.009519, loss_ce: 0.003644
2021-11-30 16:14:48,071 iteration 6534 : loss : 0.015791, loss_ce: 0.007063
2021-11-30 16:14:49,601 iteration 6535 : loss : 0.015193, loss_ce: 0.005935
2021-11-30 16:14:51,136 iteration 6536 : loss : 0.014238, loss_ce: 0.004806
2021-11-30 16:14:52,674 iteration 6537 : loss : 0.021861, loss_ce: 0.007616
2021-11-30 16:14:54,222 iteration 6538 : loss : 0.014545, loss_ce: 0.004916
2021-11-30 16:14:55,786 iteration 6539 : loss : 0.016228, loss_ce: 0.007042
2021-11-30 16:14:57,216 iteration 6540 : loss : 0.011590, loss_ce: 0.004838
2021-11-30 16:14:58,695 iteration 6541 : loss : 0.016131, loss_ce: 0.008598
2021-11-30 16:15:00,306 iteration 6542 : loss : 0.012924, loss_ce: 0.004098
2021-11-30 16:15:01,781 iteration 6543 : loss : 0.012659, loss_ce: 0.003576
2021-11-30 16:15:03,337 iteration 6544 : loss : 0.016338, loss_ce: 0.006445
2021-11-30 16:15:03,337 Training Data Eval:
2021-11-30 16:15:10,939   Average segmentation loss on training set: 0.0083
2021-11-30 16:15:10,939 Validation Data Eval:
2021-11-30 16:15:13,577   Average segmentation loss on validation set: 0.0748
2021-11-30 16:15:15,174 iteration 6545 : loss : 0.016863, loss_ce: 0.006498
 96%|███████████████████████████▉ | 385/400 [3:00:05<07:24, 29.61s/it]2021-11-30 16:15:16,860 iteration 6546 : loss : 0.013587, loss_ce: 0.005732
2021-11-30 16:15:18,379 iteration 6547 : loss : 0.012933, loss_ce: 0.005384
2021-11-30 16:15:19,931 iteration 6548 : loss : 0.016360, loss_ce: 0.007648
2021-11-30 16:15:21,410 iteration 6549 : loss : 0.017508, loss_ce: 0.006353
2021-11-30 16:15:22,963 iteration 6550 : loss : 0.018263, loss_ce: 0.006586
2021-11-30 16:15:24,564 iteration 6551 : loss : 0.019268, loss_ce: 0.008014
2021-11-30 16:15:26,192 iteration 6552 : loss : 0.022294, loss_ce: 0.009403
2021-11-30 16:15:27,827 iteration 6553 : loss : 0.025147, loss_ce: 0.008255
2021-11-30 16:15:29,363 iteration 6554 : loss : 0.025869, loss_ce: 0.008015
2021-11-30 16:15:30,900 iteration 6555 : loss : 0.013657, loss_ce: 0.005925
2021-11-30 16:15:32,437 iteration 6556 : loss : 0.017591, loss_ce: 0.004151
2021-11-30 16:15:33,867 iteration 6557 : loss : 0.009628, loss_ce: 0.003847
2021-11-30 16:15:35,387 iteration 6558 : loss : 0.019169, loss_ce: 0.005974
2021-11-30 16:15:36,851 iteration 6559 : loss : 0.011807, loss_ce: 0.004218
2021-11-30 16:15:38,378 iteration 6560 : loss : 0.014078, loss_ce: 0.006427
2021-11-30 16:15:39,924 iteration 6561 : loss : 0.015050, loss_ce: 0.004207
2021-11-30 16:15:41,389 iteration 6562 : loss : 0.013589, loss_ce: 0.005273
 96%|███████████████████████████▉ | 386/400 [3:00:31<06:40, 28.60s/it]2021-11-30 16:15:43,075 iteration 6563 : loss : 0.019557, loss_ce: 0.008701
2021-11-30 16:15:44,581 iteration 6564 : loss : 0.015810, loss_ce: 0.006681
2021-11-30 16:15:46,056 iteration 6565 : loss : 0.023307, loss_ce: 0.005489
2021-11-30 16:15:47,526 iteration 6566 : loss : 0.013250, loss_ce: 0.005415
2021-11-30 16:15:48,965 iteration 6567 : loss : 0.013753, loss_ce: 0.005283
2021-11-30 16:15:50,459 iteration 6568 : loss : 0.013100, loss_ce: 0.005703
2021-11-30 16:15:51,996 iteration 6569 : loss : 0.014979, loss_ce: 0.005597
2021-11-30 16:15:53,468 iteration 6570 : loss : 0.010774, loss_ce: 0.004936
2021-11-30 16:15:54,963 iteration 6571 : loss : 0.014631, loss_ce: 0.004383
2021-11-30 16:15:56,405 iteration 6572 : loss : 0.012018, loss_ce: 0.005200
2021-11-30 16:15:57,994 iteration 6573 : loss : 0.021896, loss_ce: 0.007757
2021-11-30 16:15:59,593 iteration 6574 : loss : 0.010706, loss_ce: 0.003990
2021-11-30 16:16:01,184 iteration 6575 : loss : 0.039126, loss_ce: 0.008608
2021-11-30 16:16:02,672 iteration 6576 : loss : 0.013300, loss_ce: 0.005608
2021-11-30 16:16:04,215 iteration 6577 : loss : 0.019169, loss_ce: 0.004408
2021-11-30 16:16:05,690 iteration 6578 : loss : 0.014334, loss_ce: 0.005992
2021-11-30 16:16:07,230 iteration 6579 : loss : 0.014146, loss_ce: 0.004973
 97%|████████████████████████████ | 387/400 [3:00:57<06:00, 27.77s/it]2021-11-30 16:16:08,820 iteration 6580 : loss : 0.014954, loss_ce: 0.004233
2021-11-30 16:16:10,315 iteration 6581 : loss : 0.013101, loss_ce: 0.004244
2021-11-30 16:16:11,909 iteration 6582 : loss : 0.014887, loss_ce: 0.004733
2021-11-30 16:16:13,429 iteration 6583 : loss : 0.018752, loss_ce: 0.006277
2021-11-30 16:16:14,961 iteration 6584 : loss : 0.017119, loss_ce: 0.007290
2021-11-30 16:16:16,527 iteration 6585 : loss : 0.020990, loss_ce: 0.006591
2021-11-30 16:16:18,068 iteration 6586 : loss : 0.020250, loss_ce: 0.005806
2021-11-30 16:16:19,581 iteration 6587 : loss : 0.010203, loss_ce: 0.004416
2021-11-30 16:16:21,122 iteration 6588 : loss : 0.014299, loss_ce: 0.005793
2021-11-30 16:16:22,581 iteration 6589 : loss : 0.011602, loss_ce: 0.004385
2021-11-30 16:16:24,177 iteration 6590 : loss : 0.017586, loss_ce: 0.008444
2021-11-30 16:16:25,754 iteration 6591 : loss : 0.016312, loss_ce: 0.005981
2021-11-30 16:16:27,248 iteration 6592 : loss : 0.015085, loss_ce: 0.005705
2021-11-30 16:16:28,848 iteration 6593 : loss : 0.031056, loss_ce: 0.006753
2021-11-30 16:16:30,360 iteration 6594 : loss : 0.011515, loss_ce: 0.005154
2021-11-30 16:16:31,877 iteration 6595 : loss : 0.016286, loss_ce: 0.006823
2021-11-30 16:16:33,459 iteration 6596 : loss : 0.016141, loss_ce: 0.005813
 97%|████████████████████████████▏| 388/400 [3:01:23<05:27, 27.31s/it]2021-11-30 16:16:35,007 iteration 6597 : loss : 0.016592, loss_ce: 0.007002
2021-11-30 16:16:36,473 iteration 6598 : loss : 0.012483, loss_ce: 0.003270
2021-11-30 16:16:38,023 iteration 6599 : loss : 0.018384, loss_ce: 0.007964
2021-11-30 16:16:39,437 iteration 6600 : loss : 0.009424, loss_ce: 0.003876
2021-11-30 16:16:40,935 iteration 6601 : loss : 0.015440, loss_ce: 0.005387
2021-11-30 16:16:42,413 iteration 6602 : loss : 0.016401, loss_ce: 0.005675
2021-11-30 16:16:43,942 iteration 6603 : loss : 0.015170, loss_ce: 0.005191
2021-11-30 16:16:45,379 iteration 6604 : loss : 0.009275, loss_ce: 0.003751
2021-11-30 16:16:46,899 iteration 6605 : loss : 0.014350, loss_ce: 0.004796
2021-11-30 16:16:48,458 iteration 6606 : loss : 0.014511, loss_ce: 0.006549
2021-11-30 16:16:50,000 iteration 6607 : loss : 0.016793, loss_ce: 0.006921
2021-11-30 16:16:51,544 iteration 6608 : loss : 0.011997, loss_ce: 0.004989
2021-11-30 16:16:53,012 iteration 6609 : loss : 0.014617, loss_ce: 0.005276
2021-11-30 16:16:54,506 iteration 6610 : loss : 0.011388, loss_ce: 0.004621
2021-11-30 16:16:55,997 iteration 6611 : loss : 0.011826, loss_ce: 0.002773
2021-11-30 16:16:57,566 iteration 6612 : loss : 0.017951, loss_ce: 0.006399
2021-11-30 16:16:58,973 iteration 6613 : loss : 0.010873, loss_ce: 0.004081
 97%|████████████████████████████▏| 389/400 [3:01:49<04:54, 26.77s/it]2021-11-30 16:17:00,529 iteration 6614 : loss : 0.015394, loss_ce: 0.005792
2021-11-30 16:17:02,076 iteration 6615 : loss : 0.012990, loss_ce: 0.005713
2021-11-30 16:17:03,578 iteration 6616 : loss : 0.013589, loss_ce: 0.003819
2021-11-30 16:17:05,214 iteration 6617 : loss : 0.020940, loss_ce: 0.009251
2021-11-30 16:17:06,744 iteration 6618 : loss : 0.017076, loss_ce: 0.005442
2021-11-30 16:17:08,326 iteration 6619 : loss : 0.023096, loss_ce: 0.008671
2021-11-30 16:17:09,877 iteration 6620 : loss : 0.015569, loss_ce: 0.006544
2021-11-30 16:17:11,369 iteration 6621 : loss : 0.022858, loss_ce: 0.006829
2021-11-30 16:17:12,885 iteration 6622 : loss : 0.017574, loss_ce: 0.008864
2021-11-30 16:17:14,388 iteration 6623 : loss : 0.015818, loss_ce: 0.005156
2021-11-30 16:17:15,948 iteration 6624 : loss : 0.047557, loss_ce: 0.025146
2021-11-30 16:17:17,511 iteration 6625 : loss : 0.014268, loss_ce: 0.005550
2021-11-30 16:17:19,023 iteration 6626 : loss : 0.014782, loss_ce: 0.003873
2021-11-30 16:17:20,461 iteration 6627 : loss : 0.014332, loss_ce: 0.004493
2021-11-30 16:17:21,962 iteration 6628 : loss : 0.012177, loss_ce: 0.005678
2021-11-30 16:17:23,471 iteration 6629 : loss : 0.013046, loss_ce: 0.006221
2021-11-30 16:17:23,471 Training Data Eval:
2021-11-30 16:17:31,121   Average segmentation loss on training set: 0.0083
2021-11-30 16:17:31,122 Validation Data Eval:
2021-11-30 16:17:33,754   Average segmentation loss on validation set: 0.0706
2021-11-30 16:17:35,304 iteration 6630 : loss : 0.017290, loss_ce: 0.005244
 98%|████████████████████████████▎| 390/400 [3:02:25<04:56, 29.64s/it]2021-11-30 16:17:36,934 iteration 6631 : loss : 0.015163, loss_ce: 0.005491
2021-11-30 16:17:38,462 iteration 6632 : loss : 0.014569, loss_ce: 0.005883
2021-11-30 16:17:39,993 iteration 6633 : loss : 0.017735, loss_ce: 0.005294
2021-11-30 16:17:41,401 iteration 6634 : loss : 0.011958, loss_ce: 0.003652
2021-11-30 16:17:42,878 iteration 6635 : loss : 0.018587, loss_ce: 0.004619
2021-11-30 16:17:44,437 iteration 6636 : loss : 0.017001, loss_ce: 0.005997
2021-11-30 16:17:45,994 iteration 6637 : loss : 0.011965, loss_ce: 0.005454
2021-11-30 16:17:47,551 iteration 6638 : loss : 0.016421, loss_ce: 0.006412
2021-11-30 16:17:49,136 iteration 6639 : loss : 0.022763, loss_ce: 0.007322
2021-11-30 16:17:50,642 iteration 6640 : loss : 0.015572, loss_ce: 0.004606
2021-11-30 16:17:52,144 iteration 6641 : loss : 0.014301, loss_ce: 0.007462
2021-11-30 16:17:53,720 iteration 6642 : loss : 0.012075, loss_ce: 0.004998
2021-11-30 16:17:55,259 iteration 6643 : loss : 0.020504, loss_ce: 0.007676
2021-11-30 16:17:56,774 iteration 6644 : loss : 0.014548, loss_ce: 0.004925
2021-11-30 16:17:58,249 iteration 6645 : loss : 0.009059, loss_ce: 0.003871
2021-11-30 16:17:59,756 iteration 6646 : loss : 0.012556, loss_ce: 0.005327
2021-11-30 16:18:01,200 iteration 6647 : loss : 0.010531, loss_ce: 0.003464
 98%|████████████████████████████▎| 391/400 [3:02:51<04:16, 28.51s/it]2021-11-30 16:18:02,721 iteration 6648 : loss : 0.014543, loss_ce: 0.004519
2021-11-30 16:18:04,300 iteration 6649 : loss : 0.018595, loss_ce: 0.006886
2021-11-30 16:18:05,751 iteration 6650 : loss : 0.014501, loss_ce: 0.005109
2021-11-30 16:18:07,226 iteration 6651 : loss : 0.014274, loss_ce: 0.004380
2021-11-30 16:18:08,814 iteration 6652 : loss : 0.016235, loss_ce: 0.006064
2021-11-30 16:18:10,389 iteration 6653 : loss : 0.013993, loss_ce: 0.005652
2021-11-30 16:18:11,871 iteration 6654 : loss : 0.012534, loss_ce: 0.004856
2021-11-30 16:18:13,410 iteration 6655 : loss : 0.015432, loss_ce: 0.005844
2021-11-30 16:18:14,940 iteration 6656 : loss : 0.013495, loss_ce: 0.005266
2021-11-30 16:18:16,545 iteration 6657 : loss : 0.017427, loss_ce: 0.006244
2021-11-30 16:18:18,079 iteration 6658 : loss : 0.021043, loss_ce: 0.007671
2021-11-30 16:18:19,643 iteration 6659 : loss : 0.025250, loss_ce: 0.007420
2021-11-30 16:18:21,115 iteration 6660 : loss : 0.012404, loss_ce: 0.004313
2021-11-30 16:18:22,562 iteration 6661 : loss : 0.010310, loss_ce: 0.003724
2021-11-30 16:18:24,108 iteration 6662 : loss : 0.012854, loss_ce: 0.004856
2021-11-30 16:18:25,667 iteration 6663 : loss : 0.024444, loss_ce: 0.009292
2021-11-30 16:18:27,156 iteration 6664 : loss : 0.013733, loss_ce: 0.004419
 98%|████████████████████████████▍| 392/400 [3:03:17<03:41, 27.75s/it]2021-11-30 16:18:28,720 iteration 6665 : loss : 0.014315, loss_ce: 0.004996
2021-11-30 16:18:30,263 iteration 6666 : loss : 0.013820, loss_ce: 0.005501
2021-11-30 16:18:31,762 iteration 6667 : loss : 0.015707, loss_ce: 0.005570
2021-11-30 16:18:33,185 iteration 6668 : loss : 0.010021, loss_ce: 0.004069
2021-11-30 16:18:34,705 iteration 6669 : loss : 0.019462, loss_ce: 0.006220
2021-11-30 16:18:36,173 iteration 6670 : loss : 0.015110, loss_ce: 0.005484
2021-11-30 16:18:37,763 iteration 6671 : loss : 0.013641, loss_ce: 0.005615
2021-11-30 16:18:39,271 iteration 6672 : loss : 0.013425, loss_ce: 0.006680
2021-11-30 16:18:40,859 iteration 6673 : loss : 0.018414, loss_ce: 0.009322
2021-11-30 16:18:42,452 iteration 6674 : loss : 0.021117, loss_ce: 0.008141
2021-11-30 16:18:43,936 iteration 6675 : loss : 0.016718, loss_ce: 0.005295
2021-11-30 16:18:45,372 iteration 6676 : loss : 0.010704, loss_ce: 0.004194
2021-11-30 16:18:46,904 iteration 6677 : loss : 0.011352, loss_ce: 0.002904
2021-11-30 16:18:48,510 iteration 6678 : loss : 0.014462, loss_ce: 0.006153
2021-11-30 16:18:50,048 iteration 6679 : loss : 0.017339, loss_ce: 0.007060
2021-11-30 16:18:51,554 iteration 6680 : loss : 0.021060, loss_ce: 0.008529
2021-11-30 16:18:53,038 iteration 6681 : loss : 0.024241, loss_ce: 0.007861
 98%|████████████████████████████▍| 393/400 [3:03:43<03:10, 27.19s/it]2021-11-30 16:18:54,606 iteration 6682 : loss : 0.020711, loss_ce: 0.007368
2021-11-30 16:18:56,164 iteration 6683 : loss : 0.017503, loss_ce: 0.005957
2021-11-30 16:18:57,699 iteration 6684 : loss : 0.038295, loss_ce: 0.008287
2021-11-30 16:18:59,197 iteration 6685 : loss : 0.013414, loss_ce: 0.004728
2021-11-30 16:19:00,738 iteration 6686 : loss : 0.014375, loss_ce: 0.004283
2021-11-30 16:19:02,260 iteration 6687 : loss : 0.017332, loss_ce: 0.007014
2021-11-30 16:19:03,789 iteration 6688 : loss : 0.014794, loss_ce: 0.005003
2021-11-30 16:19:05,283 iteration 6689 : loss : 0.016081, loss_ce: 0.007307
2021-11-30 16:19:06,866 iteration 6690 : loss : 0.016215, loss_ce: 0.005773
2021-11-30 16:19:08,325 iteration 6691 : loss : 0.012204, loss_ce: 0.004282
2021-11-30 16:19:09,787 iteration 6692 : loss : 0.012434, loss_ce: 0.006713
2021-11-30 16:19:11,321 iteration 6693 : loss : 0.013479, loss_ce: 0.005658
2021-11-30 16:19:12,769 iteration 6694 : loss : 0.010718, loss_ce: 0.004393
2021-11-30 16:19:14,276 iteration 6695 : loss : 0.013469, loss_ce: 0.003650
2021-11-30 16:19:15,777 iteration 6696 : loss : 0.017171, loss_ce: 0.009438
2021-11-30 16:19:17,284 iteration 6697 : loss : 0.015923, loss_ce: 0.005863
2021-11-30 16:19:18,719 iteration 6698 : loss : 0.015467, loss_ce: 0.004758
 98%|████████████████████████████▌| 394/400 [3:04:09<02:40, 26.74s/it]2021-11-30 16:19:20,285 iteration 6699 : loss : 0.014355, loss_ce: 0.004438
2021-11-30 16:19:21,853 iteration 6700 : loss : 0.016106, loss_ce: 0.006203
2021-11-30 16:19:23,438 iteration 6701 : loss : 0.022958, loss_ce: 0.007128
2021-11-30 16:19:24,912 iteration 6702 : loss : 0.012909, loss_ce: 0.003904
2021-11-30 16:19:26,538 iteration 6703 : loss : 0.015709, loss_ce: 0.004414
2021-11-30 16:19:28,067 iteration 6704 : loss : 0.015599, loss_ce: 0.007869
2021-11-30 16:19:29,524 iteration 6705 : loss : 0.011978, loss_ce: 0.003617
2021-11-30 16:19:31,004 iteration 6706 : loss : 0.013886, loss_ce: 0.004991
2021-11-30 16:19:32,516 iteration 6707 : loss : 0.013653, loss_ce: 0.004884
2021-11-30 16:19:33,961 iteration 6708 : loss : 0.009976, loss_ce: 0.003104
2021-11-30 16:19:35,448 iteration 6709 : loss : 0.015471, loss_ce: 0.004307
2021-11-30 16:19:36,972 iteration 6710 : loss : 0.015745, loss_ce: 0.006534
2021-11-30 16:19:38,503 iteration 6711 : loss : 0.014512, loss_ce: 0.006247
2021-11-30 16:19:40,069 iteration 6712 : loss : 0.013774, loss_ce: 0.005499
2021-11-30 16:19:41,568 iteration 6713 : loss : 0.014629, loss_ce: 0.005085
2021-11-30 16:19:43,059 iteration 6714 : loss : 0.013143, loss_ce: 0.005461
2021-11-30 16:19:43,059 Training Data Eval:
2021-11-30 16:19:50,695   Average segmentation loss on training set: 0.0084
2021-11-30 16:19:50,695 Validation Data Eval:
2021-11-30 16:19:53,330   Average segmentation loss on validation set: 0.0720
2021-11-30 16:19:54,836 iteration 6715 : loss : 0.009149, loss_ce: 0.002760
 99%|████████████████████████████▋| 395/400 [3:04:45<02:27, 29.55s/it]2021-11-30 16:19:56,326 iteration 6716 : loss : 0.010085, loss_ce: 0.003377
2021-11-30 16:19:57,864 iteration 6717 : loss : 0.015635, loss_ce: 0.004550
2021-11-30 16:19:59,443 iteration 6718 : loss : 0.020303, loss_ce: 0.009089
2021-11-30 16:20:01,018 iteration 6719 : loss : 0.019190, loss_ce: 0.006925
2021-11-30 16:20:02,552 iteration 6720 : loss : 0.022534, loss_ce: 0.004114
2021-11-30 16:20:04,097 iteration 6721 : loss : 0.015546, loss_ce: 0.006908
2021-11-30 16:20:05,599 iteration 6722 : loss : 0.013920, loss_ce: 0.006072
2021-11-30 16:20:07,146 iteration 6723 : loss : 0.018885, loss_ce: 0.007136
2021-11-30 16:20:08,611 iteration 6724 : loss : 0.013550, loss_ce: 0.005202
2021-11-30 16:20:10,111 iteration 6725 : loss : 0.010900, loss_ce: 0.003555
2021-11-30 16:20:11,541 iteration 6726 : loss : 0.010510, loss_ce: 0.003796
2021-11-30 16:20:13,160 iteration 6727 : loss : 0.019267, loss_ce: 0.006529
2021-11-30 16:20:14,631 iteration 6728 : loss : 0.017346, loss_ce: 0.006240
2021-11-30 16:20:16,192 iteration 6729 : loss : 0.016710, loss_ce: 0.005199
2021-11-30 16:20:17,790 iteration 6730 : loss : 0.018946, loss_ce: 0.007925
2021-11-30 16:20:19,349 iteration 6731 : loss : 0.018320, loss_ce: 0.006134
2021-11-30 16:20:20,852 iteration 6732 : loss : 0.010736, loss_ce: 0.004667
 99%|████████████████████████████▋| 396/400 [3:05:11<01:53, 28.49s/it]2021-11-30 16:20:22,351 iteration 6733 : loss : 0.010098, loss_ce: 0.004453
2021-11-30 16:20:23,837 iteration 6734 : loss : 0.013648, loss_ce: 0.003862
2021-11-30 16:20:25,390 iteration 6735 : loss : 0.015492, loss_ce: 0.005669
2021-11-30 16:20:26,886 iteration 6736 : loss : 0.013059, loss_ce: 0.005895
2021-11-30 16:20:28,358 iteration 6737 : loss : 0.015029, loss_ce: 0.007718
2021-11-30 16:20:29,817 iteration 6738 : loss : 0.012245, loss_ce: 0.003692
2021-11-30 16:20:31,352 iteration 6739 : loss : 0.014190, loss_ce: 0.006141
2021-11-30 16:20:32,907 iteration 6740 : loss : 0.020964, loss_ce: 0.007477
2021-11-30 16:20:34,419 iteration 6741 : loss : 0.018577, loss_ce: 0.007639
2021-11-30 16:20:35,904 iteration 6742 : loss : 0.017435, loss_ce: 0.007612
2021-11-30 16:20:37,382 iteration 6743 : loss : 0.011975, loss_ce: 0.002834
2021-11-30 16:20:38,944 iteration 6744 : loss : 0.015641, loss_ce: 0.006087
2021-11-30 16:20:40,438 iteration 6745 : loss : 0.011064, loss_ce: 0.004941
2021-11-30 16:20:41,887 iteration 6746 : loss : 0.009496, loss_ce: 0.002700
2021-11-30 16:20:43,357 iteration 6747 : loss : 0.011149, loss_ce: 0.003533
2021-11-30 16:20:44,889 iteration 6748 : loss : 0.009592, loss_ce: 0.003972
2021-11-30 16:20:46,388 iteration 6749 : loss : 0.013515, loss_ce: 0.003751
 99%|████████████████████████████▊| 397/400 [3:05:36<01:22, 27.60s/it]2021-11-30 16:20:47,933 iteration 6750 : loss : 0.011494, loss_ce: 0.005001
2021-11-30 16:20:49,503 iteration 6751 : loss : 0.011950, loss_ce: 0.004833
2021-11-30 16:20:50,945 iteration 6752 : loss : 0.010876, loss_ce: 0.003377
2021-11-30 16:20:52,469 iteration 6753 : loss : 0.014920, loss_ce: 0.006450
2021-11-30 16:20:54,002 iteration 6754 : loss : 0.012416, loss_ce: 0.004400
2021-11-30 16:20:55,475 iteration 6755 : loss : 0.013349, loss_ce: 0.004444
2021-11-30 16:20:56,975 iteration 6756 : loss : 0.016859, loss_ce: 0.008136
2021-11-30 16:20:58,548 iteration 6757 : loss : 0.015168, loss_ce: 0.004748
2021-11-30 16:21:00,021 iteration 6758 : loss : 0.014799, loss_ce: 0.006579
2021-11-30 16:21:01,553 iteration 6759 : loss : 0.012279, loss_ce: 0.005328
2021-11-30 16:21:03,141 iteration 6760 : loss : 0.042280, loss_ce: 0.008285
2021-11-30 16:21:04,652 iteration 6761 : loss : 0.015009, loss_ce: 0.006336
2021-11-30 16:21:06,147 iteration 6762 : loss : 0.017117, loss_ce: 0.005370
2021-11-30 16:21:07,706 iteration 6763 : loss : 0.016187, loss_ce: 0.006621
2021-11-30 16:21:09,177 iteration 6764 : loss : 0.016368, loss_ce: 0.006547
2021-11-30 16:21:10,746 iteration 6765 : loss : 0.014148, loss_ce: 0.005108
2021-11-30 16:21:12,239 iteration 6766 : loss : 0.011334, loss_ce: 0.005109
100%|████████████████████████████▊| 398/400 [3:06:02<00:54, 27.08s/it]2021-11-30 16:21:13,799 iteration 6767 : loss : 0.015085, loss_ce: 0.005070
2021-11-30 16:21:15,390 iteration 6768 : loss : 0.017278, loss_ce: 0.006549
2021-11-30 16:21:16,909 iteration 6769 : loss : 0.016188, loss_ce: 0.006893
2021-11-30 16:21:18,408 iteration 6770 : loss : 0.015547, loss_ce: 0.007386
2021-11-30 16:21:20,007 iteration 6771 : loss : 0.021996, loss_ce: 0.005152
2021-11-30 16:21:21,490 iteration 6772 : loss : 0.013032, loss_ce: 0.004632
2021-11-30 16:21:22,879 iteration 6773 : loss : 0.012379, loss_ce: 0.003694
2021-11-30 16:21:24,433 iteration 6774 : loss : 0.044399, loss_ce: 0.010594
2021-11-30 16:21:25,970 iteration 6775 : loss : 0.016283, loss_ce: 0.005587
2021-11-30 16:21:27,471 iteration 6776 : loss : 0.017569, loss_ce: 0.005809
2021-11-30 16:21:29,052 iteration 6777 : loss : 0.018771, loss_ce: 0.010493
2021-11-30 16:21:30,554 iteration 6778 : loss : 0.010070, loss_ce: 0.003286
2021-11-30 16:21:32,143 iteration 6779 : loss : 0.020957, loss_ce: 0.008220
2021-11-30 16:21:33,673 iteration 6780 : loss : 0.013521, loss_ce: 0.006170
2021-11-30 16:21:35,230 iteration 6781 : loss : 0.015551, loss_ce: 0.006353
2021-11-30 16:21:36,805 iteration 6782 : loss : 0.012077, loss_ce: 0.004470
2021-11-30 16:21:38,290 iteration 6783 : loss : 0.013661, loss_ce: 0.004581
100%|████████████████████████████▉| 399/400 [3:06:28<00:26, 26.77s/it]2021-11-30 16:21:39,889 iteration 6784 : loss : 0.016688, loss_ce: 0.005213
2021-11-30 16:21:41,422 iteration 6785 : loss : 0.017520, loss_ce: 0.005719
2021-11-30 16:21:42,892 iteration 6786 : loss : 0.014948, loss_ce: 0.007080
2021-11-30 16:21:44,376 iteration 6787 : loss : 0.012240, loss_ce: 0.004024
2021-11-30 16:21:45,908 iteration 6788 : loss : 0.013037, loss_ce: 0.005195
2021-11-30 16:21:47,417 iteration 6789 : loss : 0.016773, loss_ce: 0.005035
2021-11-30 16:21:48,918 iteration 6790 : loss : 0.011149, loss_ce: 0.004553
2021-11-30 16:21:50,447 iteration 6791 : loss : 0.017698, loss_ce: 0.007928
2021-11-30 16:21:51,911 iteration 6792 : loss : 0.012212, loss_ce: 0.005285
2021-11-30 16:21:53,485 iteration 6793 : loss : 0.017993, loss_ce: 0.005465
2021-11-30 16:21:54,991 iteration 6794 : loss : 0.019384, loss_ce: 0.006587
2021-11-30 16:21:56,547 iteration 6795 : loss : 0.015123, loss_ce: 0.005540
2021-11-30 16:21:58,120 iteration 6796 : loss : 0.013749, loss_ce: 0.006939
2021-11-30 16:21:59,560 iteration 6797 : loss : 0.015813, loss_ce: 0.004586
2021-11-30 16:22:01,112 iteration 6798 : loss : 0.016509, loss_ce: 0.005429
2021-11-30 16:22:02,708 iteration 6799 : loss : 0.018461, loss_ce: 0.008227
2021-11-30 16:22:02,709 Training Data Eval:
2021-11-30 16:22:10,355   Average segmentation loss on training set: 0.0081
2021-11-30 16:22:10,355 Validation Data Eval:
2021-11-30 16:22:12,997   Average segmentation loss on validation set: 0.0678
2021-11-30 16:22:14,475 iteration 6800 : loss : 0.012679, loss_ce: 0.003277
100%|█████████████████████████████| 400/400 [3:07:05<00:00, 29.60s/it]100%|█████████████████████████████| 400/400 [3:07:05<00:00, 28.06s/it]
