2021-12-10 10:26:37,170 Logging directory: /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/TransUNet/log_dir/trRUNMC_cv1_no_da_r3/i2i2l/
2021-12-10 10:26:37,170 Tensorboard directory: /scratch_net/biwidl217_second/arismu/Tensorboard/trRUNMC_cv1_no_da_r3/i2i2l/
2021-12-10 10:26:37,171 ============================================================
2021-12-10 10:26:37,171 EXPERIMENT NAME: trRUNMC_cv1_no_da_r3/i2i2l/
2021-12-10 10:26:37,171 ============================================================
2021-12-10 10:26:37,171 Loading data...
2021-12-10 10:26:37,171 Reading NCI - RUNMC images...
2021-12-10 10:26:37,171 Data root directory: /itet-stor/arismu/bmicdatasets-originals/Originals/Challenge_Datasets/NCI_Prostate/
2021-12-10 10:26:37,172 Already preprocessed this configuration. Loading now!
2021-12-10 10:26:37,191 Training Images: (256, 256, 286)
2021-12-10 10:26:37,191 Training Labels: (256, 256, 286)
2021-12-10 10:26:37,191 Validation Images: (256, 256, 98)
2021-12-10 10:26:37,191 Validation Labels: (256, 256, 98)
2021-12-10 10:26:37,191 ============================================================
2021-12-10 10:26:37,229 17 iterations per epoch. 6800 max iterations 
  0%|                                         | 0/400 [00:00<?, ?it/s]2021-12-10 10:26:39,671 iteration 1 : loss : 0.901086, loss_ce: 1.071506
2021-12-10 10:26:41,013 iteration 2 : loss : 0.846292, loss_ce: 0.986390
2021-12-10 10:26:42,360 iteration 3 : loss : 0.788706, loss_ce: 0.889212
2021-12-10 10:26:43,708 iteration 4 : loss : 0.740257, loss_ce: 0.803017
2021-12-10 10:26:45,057 iteration 5 : loss : 0.683195, loss_ce: 0.723338
2021-12-10 10:26:46,414 iteration 6 : loss : 0.643330, loss_ce: 0.651627
2021-12-10 10:26:47,789 iteration 7 : loss : 0.599617, loss_ce: 0.598962
2021-12-10 10:26:49,257 iteration 8 : loss : 0.576497, loss_ce: 0.534317
2021-12-10 10:26:50,723 iteration 9 : loss : 0.538089, loss_ce: 0.529011
2021-12-10 10:26:52,201 iteration 10 : loss : 0.536909, loss_ce: 0.467313
2021-12-10 10:26:53,681 iteration 11 : loss : 0.473762, loss_ce: 0.426598
2021-12-10 10:26:55,167 iteration 12 : loss : 0.462266, loss_ce: 0.389430
2021-12-10 10:26:56,654 iteration 13 : loss : 0.448126, loss_ce: 0.359611
2021-12-10 10:26:58,144 iteration 14 : loss : 0.430084, loss_ce: 0.332325
2021-12-10 10:26:59,634 iteration 15 : loss : 0.386723, loss_ce: 0.295321
2021-12-10 10:27:01,124 iteration 16 : loss : 0.399731, loss_ce: 0.287012
2021-12-10 10:27:02,612 iteration 17 : loss : 0.363977, loss_ce: 0.264169
  0%|                               | 1/400 [00:25<2:49:13, 25.45s/it]2021-12-10 10:27:04,168 iteration 18 : loss : 0.339313, loss_ce: 0.239889
2021-12-10 10:27:05,656 iteration 19 : loss : 0.324458, loss_ce: 0.205610
2021-12-10 10:27:07,148 iteration 20 : loss : 0.344826, loss_ce: 0.209378
2021-12-10 10:27:08,637 iteration 21 : loss : 0.312646, loss_ce: 0.184966
2021-12-10 10:27:10,123 iteration 22 : loss : 0.298837, loss_ce: 0.191533
2021-12-10 10:27:11,613 iteration 23 : loss : 0.291834, loss_ce: 0.173613
2021-12-10 10:27:13,108 iteration 24 : loss : 0.305339, loss_ce: 0.184002
2021-12-10 10:27:14,601 iteration 25 : loss : 0.277977, loss_ce: 0.152151
2021-12-10 10:27:16,093 iteration 26 : loss : 0.261238, loss_ce: 0.152223
2021-12-10 10:27:17,587 iteration 27 : loss : 0.284071, loss_ce: 0.155478
2021-12-10 10:27:19,083 iteration 28 : loss : 0.266525, loss_ce: 0.129301
2021-12-10 10:27:20,576 iteration 29 : loss : 0.282347, loss_ce: 0.146980
2021-12-10 10:27:22,069 iteration 30 : loss : 0.236458, loss_ce: 0.127100
2021-12-10 10:27:23,564 iteration 31 : loss : 0.244449, loss_ce: 0.121448
2021-12-10 10:27:25,055 iteration 32 : loss : 0.277694, loss_ce: 0.145398
2021-12-10 10:27:26,548 iteration 33 : loss : 0.233399, loss_ce: 0.111664
2021-12-10 10:27:28,040 iteration 34 : loss : 0.210765, loss_ce: 0.101454
  0%|▏                              | 2/400 [00:50<2:48:42, 25.43s/it]2021-12-10 10:27:29,601 iteration 35 : loss : 0.249891, loss_ce: 0.115188
2021-12-10 10:27:31,106 iteration 36 : loss : 0.258587, loss_ce: 0.111880
2021-12-10 10:27:32,613 iteration 37 : loss : 0.201943, loss_ce: 0.090516
2021-12-10 10:27:34,142 iteration 38 : loss : 0.260074, loss_ce: 0.122195
2021-12-10 10:27:35,763 iteration 39 : loss : 0.249047, loss_ce: 0.102035
2021-12-10 10:27:37,454 iteration 40 : loss : 0.206661, loss_ce: 0.093448
2021-12-10 10:27:39,132 iteration 41 : loss : 0.274225, loss_ce: 0.129017
2021-12-10 10:27:40,858 iteration 42 : loss : 0.241396, loss_ce: 0.114872
2021-12-10 10:27:42,576 iteration 43 : loss : 0.245887, loss_ce: 0.105766
2021-12-10 10:27:44,353 iteration 44 : loss : 0.227545, loss_ce: 0.094085
2021-12-10 10:27:46,172 iteration 45 : loss : 0.217795, loss_ce: 0.092428
2021-12-10 10:27:48,055 iteration 46 : loss : 0.236568, loss_ce: 0.105129
2021-12-10 10:27:49,986 iteration 47 : loss : 0.203644, loss_ce: 0.091418
2021-12-10 10:27:52,015 iteration 48 : loss : 0.213078, loss_ce: 0.087479
2021-12-10 10:27:54,094 iteration 49 : loss : 0.181178, loss_ce: 0.071790
2021-12-10 10:27:56,222 iteration 50 : loss : 0.195122, loss_ce: 0.093391
2021-12-10 10:27:58,460 iteration 51 : loss : 0.221188, loss_ce: 0.103914
  1%|▏                              | 3/400 [01:21<3:03:21, 27.71s/it]2021-12-10 10:28:00,751 iteration 52 : loss : 0.202468, loss_ce: 0.094227
2021-12-10 10:28:03,024 iteration 53 : loss : 0.202381, loss_ce: 0.094201
2021-12-10 10:28:05,356 iteration 54 : loss : 0.221694, loss_ce: 0.089022
2021-12-10 10:28:07,780 iteration 55 : loss : 0.170924, loss_ce: 0.069784
2021-12-10 10:28:10,352 iteration 56 : loss : 0.219802, loss_ce: 0.081712
2021-12-10 10:28:12,886 iteration 57 : loss : 0.256597, loss_ce: 0.086203
2021-12-10 10:28:15,452 iteration 58 : loss : 0.259928, loss_ce: 0.099603
2021-12-10 10:28:18,015 iteration 59 : loss : 0.222383, loss_ce: 0.081663
2021-12-10 10:28:20,452 iteration 60 : loss : 0.222194, loss_ce: 0.092366
2021-12-10 10:28:23,110 iteration 61 : loss : 0.193184, loss_ce: 0.079874
2021-12-10 10:28:25,741 iteration 62 : loss : 0.230975, loss_ce: 0.099962
2021-12-10 10:28:28,371 iteration 63 : loss : 0.230572, loss_ce: 0.114434
2021-12-10 10:28:31,077 iteration 64 : loss : 0.274488, loss_ce: 0.119884
2021-12-10 10:28:33,670 iteration 65 : loss : 0.184189, loss_ce: 0.086489
2021-12-10 10:28:36,285 iteration 66 : loss : 0.254294, loss_ce: 0.093370
2021-12-10 10:28:39,031 iteration 67 : loss : 0.248242, loss_ce: 0.101306
2021-12-10 10:28:41,757 iteration 68 : loss : 0.245681, loss_ce: 0.089029
  1%|▎                              | 4/400 [02:04<3:43:28, 33.86s/it]2021-12-10 10:28:44,562 iteration 69 : loss : 0.224076, loss_ce: 0.080392
2021-12-10 10:28:47,292 iteration 70 : loss : 0.231752, loss_ce: 0.087117
2021-12-10 10:28:50,054 iteration 71 : loss : 0.198318, loss_ce: 0.084808
2021-12-10 10:28:52,773 iteration 72 : loss : 0.193908, loss_ce: 0.081160
2021-12-10 10:28:55,630 iteration 73 : loss : 0.217893, loss_ce: 0.094196
2021-12-10 10:28:58,491 iteration 74 : loss : 0.211454, loss_ce: 0.091602
2021-12-10 10:29:01,215 iteration 75 : loss : 0.225667, loss_ce: 0.093124
2021-12-10 10:29:04,073 iteration 76 : loss : 0.207297, loss_ce: 0.081526
2021-12-10 10:29:06,788 iteration 77 : loss : 0.178631, loss_ce: 0.071493
2021-12-10 10:29:09,553 iteration 78 : loss : 0.214135, loss_ce: 0.072730
2021-12-10 10:29:12,406 iteration 79 : loss : 0.221193, loss_ce: 0.078669
2021-12-10 10:29:15,139 iteration 80 : loss : 0.212921, loss_ce: 0.077691
2021-12-10 10:29:17,985 iteration 81 : loss : 0.188210, loss_ce: 0.074711
2021-12-10 10:29:20,875 iteration 82 : loss : 0.227324, loss_ce: 0.076187
2021-12-10 10:29:23,598 iteration 83 : loss : 0.234799, loss_ce: 0.110430
2021-12-10 10:29:26,435 iteration 84 : loss : 0.178152, loss_ce: 0.070487
2021-12-10 10:29:26,436 Training Data Eval:
2021-12-10 10:29:42,211   Average segmentation loss on training set: 0.4134
2021-12-10 10:29:42,212 Validation Data Eval:
2021-12-10 10:29:47,773   Average segmentation loss on validation set: 0.3516
2021-12-10 10:29:53,708 Found new lowest validation loss at iteration 84! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/NEW_TU/NEW_TU_ADAM_best_val_loss_seed1234_no_da.pth
2021-12-10 10:29:55,589 iteration 85 : loss : 0.191419, loss_ce: 0.074693
  1%|▍                              | 5/400 [03:18<5:17:48, 48.27s/it]2021-12-10 10:29:58,223 iteration 86 : loss : 0.186612, loss_ce: 0.073808
2021-12-10 10:30:00,960 iteration 87 : loss : 0.171450, loss_ce: 0.076078
2021-12-10 10:30:03,747 iteration 88 : loss : 0.203779, loss_ce: 0.079218
2021-12-10 10:30:06,371 iteration 89 : loss : 0.180354, loss_ce: 0.072575
2021-12-10 10:30:09,223 iteration 90 : loss : 0.214174, loss_ce: 0.083776
2021-12-10 10:30:11,933 iteration 91 : loss : 0.183191, loss_ce: 0.076143
2021-12-10 10:30:14,803 iteration 92 : loss : 0.221342, loss_ce: 0.071415
2021-12-10 10:30:17,671 iteration 93 : loss : 0.207289, loss_ce: 0.064100
2021-12-10 10:30:20,548 iteration 94 : loss : 0.196331, loss_ce: 0.064884
2021-12-10 10:30:23,381 iteration 95 : loss : 0.172994, loss_ce: 0.057314
2021-12-10 10:30:26,232 iteration 96 : loss : 0.199807, loss_ce: 0.078549
2021-12-10 10:30:28,981 iteration 97 : loss : 0.187510, loss_ce: 0.072413
2021-12-10 10:30:31,848 iteration 98 : loss : 0.212760, loss_ce: 0.077857
2021-12-10 10:30:34,840 iteration 99 : loss : 0.203116, loss_ce: 0.077969
2021-12-10 10:30:37,750 iteration 100 : loss : 0.188077, loss_ce: 0.077917
2021-12-10 10:30:40,772 iteration 101 : loss : 0.206869, loss_ce: 0.072859
2021-12-10 10:30:43,669 iteration 102 : loss : 0.235877, loss_ce: 0.107151
  2%|▍                              | 6/400 [04:06<5:16:35, 48.21s/it]2021-12-10 10:30:46,770 iteration 103 : loss : 0.195694, loss_ce: 0.075459
2021-12-10 10:30:49,629 iteration 104 : loss : 0.191089, loss_ce: 0.072145
2021-12-10 10:30:52,461 iteration 105 : loss : 0.163883, loss_ce: 0.066116
2021-12-10 10:30:55,293 iteration 106 : loss : 0.154881, loss_ce: 0.057935
2021-12-10 10:30:58,175 iteration 107 : loss : 0.207316, loss_ce: 0.077794
2021-12-10 10:31:01,096 iteration 108 : loss : 0.161688, loss_ce: 0.069093
2021-12-10 10:31:03,998 iteration 109 : loss : 0.174302, loss_ce: 0.060142
2021-12-10 10:31:06,925 iteration 110 : loss : 0.195361, loss_ce: 0.066891
2021-12-10 10:31:09,849 iteration 111 : loss : 0.186624, loss_ce: 0.067518
2021-12-10 10:31:12,794 iteration 112 : loss : 0.176398, loss_ce: 0.063650
2021-12-10 10:31:15,769 iteration 113 : loss : 0.154995, loss_ce: 0.046311
2021-12-10 10:31:18,666 iteration 114 : loss : 0.203118, loss_ce: 0.088774
2021-12-10 10:31:21,689 iteration 115 : loss : 0.182434, loss_ce: 0.059065
2021-12-10 10:31:24,581 iteration 116 : loss : 0.221827, loss_ce: 0.083205
2021-12-10 10:31:27,506 iteration 117 : loss : 0.163177, loss_ce: 0.049222
2021-12-10 10:31:30,231 iteration 118 : loss : 0.144939, loss_ce: 0.054881
2021-12-10 10:31:33,302 iteration 119 : loss : 0.194829, loss_ce: 0.068498
  2%|▌                              | 7/400 [04:56<5:18:47, 48.67s/it]2021-12-10 10:31:36,208 iteration 120 : loss : 0.210054, loss_ce: 0.055465
2021-12-10 10:31:39,114 iteration 121 : loss : 0.182794, loss_ce: 0.059345
2021-12-10 10:31:41,835 iteration 122 : loss : 0.170818, loss_ce: 0.063737
2021-12-10 10:31:44,676 iteration 123 : loss : 0.198477, loss_ce: 0.090069
2021-12-10 10:31:47,512 iteration 124 : loss : 0.179906, loss_ce: 0.060465
2021-12-10 10:31:50,398 iteration 125 : loss : 0.174267, loss_ce: 0.077780
2021-12-10 10:31:53,322 iteration 126 : loss : 0.161635, loss_ce: 0.057856
2021-12-10 10:31:56,228 iteration 127 : loss : 0.219495, loss_ce: 0.058294
2021-12-10 10:31:59,104 iteration 128 : loss : 0.193499, loss_ce: 0.069630
2021-12-10 10:32:02,122 iteration 129 : loss : 0.189478, loss_ce: 0.066500
2021-12-10 10:32:05,144 iteration 130 : loss : 0.180029, loss_ce: 0.059097
2021-12-10 10:32:07,980 iteration 131 : loss : 0.211835, loss_ce: 0.077210
2021-12-10 10:32:11,158 iteration 132 : loss : 0.189320, loss_ce: 0.074388
2021-12-10 10:32:14,050 iteration 133 : loss : 0.159993, loss_ce: 0.056217
2021-12-10 10:32:17,018 iteration 134 : loss : 0.210625, loss_ce: 0.086737
2021-12-10 10:32:19,925 iteration 135 : loss : 0.168599, loss_ce: 0.074194
2021-12-10 10:32:22,926 iteration 136 : loss : 0.164525, loss_ce: 0.056137
  2%|▌                              | 8/400 [05:45<5:19:59, 48.98s/it]2021-12-10 10:32:25,903 iteration 137 : loss : 0.175090, loss_ce: 0.062522
2021-12-10 10:32:28,634 iteration 138 : loss : 0.160152, loss_ce: 0.055891
2021-12-10 10:32:31,481 iteration 139 : loss : 0.171998, loss_ce: 0.060520
2021-12-10 10:32:34,482 iteration 140 : loss : 0.191472, loss_ce: 0.068024
2021-12-10 10:32:37,519 iteration 141 : loss : 0.186420, loss_ce: 0.061549
2021-12-10 10:32:40,364 iteration 142 : loss : 0.173884, loss_ce: 0.068097
2021-12-10 10:32:43,367 iteration 143 : loss : 0.177420, loss_ce: 0.074177
2021-12-10 10:32:46,247 iteration 144 : loss : 0.201693, loss_ce: 0.058086
2021-12-10 10:32:49,102 iteration 145 : loss : 0.179944, loss_ce: 0.070247
2021-12-10 10:32:51,971 iteration 146 : loss : 0.172468, loss_ce: 0.059733
2021-12-10 10:32:54,983 iteration 147 : loss : 0.181550, loss_ce: 0.052300
2021-12-10 10:32:57,772 iteration 148 : loss : 0.169749, loss_ce: 0.065890
2021-12-10 10:33:00,688 iteration 149 : loss : 0.141001, loss_ce: 0.043785
2021-12-10 10:33:03,419 iteration 150 : loss : 0.194858, loss_ce: 0.081394
2021-12-10 10:33:06,430 iteration 151 : loss : 0.179190, loss_ce: 0.059822
2021-12-10 10:33:09,367 iteration 152 : loss : 0.152782, loss_ce: 0.057519
2021-12-10 10:33:12,375 iteration 153 : loss : 0.178608, loss_ce: 0.062787
  2%|▋                              | 9/400 [06:35<5:20:07, 49.12s/it]2021-12-10 10:33:15,377 iteration 154 : loss : 0.145762, loss_ce: 0.047677
2021-12-10 10:33:18,138 iteration 155 : loss : 0.164002, loss_ce: 0.057875
2021-12-10 10:33:21,055 iteration 156 : loss : 0.167668, loss_ce: 0.063489
2021-12-10 10:33:23,991 iteration 157 : loss : 0.153390, loss_ce: 0.050751
2021-12-10 10:33:26,885 iteration 158 : loss : 0.153101, loss_ce: 0.049680
2021-12-10 10:33:29,836 iteration 159 : loss : 0.151695, loss_ce: 0.050110
2021-12-10 10:33:32,853 iteration 160 : loss : 0.163953, loss_ce: 0.053961
2021-12-10 10:33:35,885 iteration 161 : loss : 0.171999, loss_ce: 0.048349
2021-12-10 10:33:38,809 iteration 162 : loss : 0.159022, loss_ce: 0.048044
2021-12-10 10:33:41,545 iteration 163 : loss : 0.146588, loss_ce: 0.057990
2021-12-10 10:33:44,545 iteration 164 : loss : 0.126606, loss_ce: 0.045836
2021-12-10 10:33:47,576 iteration 165 : loss : 0.181323, loss_ce: 0.082994
2021-12-10 10:33:50,493 iteration 166 : loss : 0.163541, loss_ce: 0.055497
2021-12-10 10:33:53,518 iteration 167 : loss : 0.151505, loss_ce: 0.056367
2021-12-10 10:33:56,251 iteration 168 : loss : 0.156040, loss_ce: 0.048131
2021-12-10 10:33:59,257 iteration 169 : loss : 0.154155, loss_ce: 0.059748
2021-12-10 10:33:59,257 Training Data Eval:
2021-12-10 10:34:15,300   Average segmentation loss on training set: 0.1567
2021-12-10 10:34:15,301 Validation Data Eval:
2021-12-10 10:34:20,864   Average segmentation loss on validation set: 0.1957
2021-12-10 10:34:26,588 Found new lowest validation loss at iteration 169! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/NEW_TU/NEW_TU_ADAM_best_val_loss_seed1234_no_da.pth
2021-12-10 10:34:28,438 iteration 170 : loss : 0.163908, loss_ce: 0.052347
  2%|▊                             | 10/400 [07:51<6:13:22, 57.44s/it]2021-12-10 10:34:31,035 iteration 171 : loss : 0.131504, loss_ce: 0.046135
2021-12-10 10:34:33,906 iteration 172 : loss : 0.125702, loss_ce: 0.048543
2021-12-10 10:34:36,616 iteration 173 : loss : 0.153297, loss_ce: 0.053708
2021-12-10 10:34:39,347 iteration 174 : loss : 0.148223, loss_ce: 0.056597
2021-12-10 10:34:42,072 iteration 175 : loss : 0.146631, loss_ce: 0.058887
2021-12-10 10:34:45,096 iteration 176 : loss : 0.105298, loss_ce: 0.041951
2021-12-10 10:34:47,932 iteration 177 : loss : 0.170076, loss_ce: 0.067712
2021-12-10 10:34:50,832 iteration 178 : loss : 0.153181, loss_ce: 0.061451
2021-12-10 10:34:53,799 iteration 179 : loss : 0.135689, loss_ce: 0.049688
2021-12-10 10:34:56,717 iteration 180 : loss : 0.147707, loss_ce: 0.045269
2021-12-10 10:34:59,447 iteration 181 : loss : 0.214580, loss_ce: 0.129454
2021-12-10 10:35:02,482 iteration 182 : loss : 0.202187, loss_ce: 0.056147
2021-12-10 10:35:05,330 iteration 183 : loss : 0.119750, loss_ce: 0.042566
2021-12-10 10:35:08,318 iteration 184 : loss : 0.133725, loss_ce: 0.046241
2021-12-10 10:35:11,344 iteration 185 : loss : 0.124957, loss_ce: 0.050031
2021-12-10 10:35:14,341 iteration 186 : loss : 0.129003, loss_ce: 0.039012
2021-12-10 10:35:17,212 iteration 187 : loss : 0.133964, loss_ce: 0.052004
  3%|▊                             | 11/400 [08:40<5:55:11, 54.79s/it]2021-12-10 10:35:20,263 iteration 188 : loss : 0.190355, loss_ce: 0.066203
2021-12-10 10:35:23,461 iteration 189 : loss : 0.117354, loss_ce: 0.049945
2021-12-10 10:35:26,356 iteration 190 : loss : 0.115932, loss_ce: 0.047848
2021-12-10 10:35:29,347 iteration 191 : loss : 0.100287, loss_ce: 0.038895
2021-12-10 10:35:32,258 iteration 192 : loss : 0.126021, loss_ce: 0.062524
2021-12-10 10:35:35,279 iteration 193 : loss : 0.145574, loss_ce: 0.061301
2021-12-10 10:35:38,127 iteration 194 : loss : 0.118398, loss_ce: 0.054012
2021-12-10 10:35:41,097 iteration 195 : loss : 0.140739, loss_ce: 0.053137
2021-12-10 10:35:44,094 iteration 196 : loss : 0.121506, loss_ce: 0.044949
2021-12-10 10:35:47,126 iteration 197 : loss : 0.143679, loss_ce: 0.053481
2021-12-10 10:35:50,019 iteration 198 : loss : 0.159595, loss_ce: 0.061053
2021-12-10 10:35:52,950 iteration 199 : loss : 0.126825, loss_ce: 0.054163
2021-12-10 10:35:55,678 iteration 200 : loss : 0.159747, loss_ce: 0.052919
2021-12-10 10:35:58,530 iteration 201 : loss : 0.200418, loss_ce: 0.065209
2021-12-10 10:36:01,543 iteration 202 : loss : 0.137175, loss_ce: 0.058404
2021-12-10 10:36:04,574 iteration 203 : loss : 0.118482, loss_ce: 0.052580
2021-12-10 10:36:07,573 iteration 204 : loss : 0.141461, loss_ce: 0.054121
  3%|▉                             | 12/400 [09:30<5:45:34, 53.44s/it]2021-12-10 10:36:10,585 iteration 205 : loss : 0.191156, loss_ce: 0.070649
2021-12-10 10:36:13,606 iteration 206 : loss : 0.130539, loss_ce: 0.045345
2021-12-10 10:36:16,479 iteration 207 : loss : 0.132349, loss_ce: 0.054153
2021-12-10 10:36:19,424 iteration 208 : loss : 0.154807, loss_ce: 0.046193
2021-12-10 10:36:22,294 iteration 209 : loss : 0.122500, loss_ce: 0.054505
2021-12-10 10:36:25,025 iteration 210 : loss : 0.144961, loss_ce: 0.047184
2021-12-10 10:36:28,039 iteration 211 : loss : 0.107007, loss_ce: 0.043689
2021-12-10 10:36:30,905 iteration 212 : loss : 0.103426, loss_ce: 0.045896
2021-12-10 10:36:33,914 iteration 213 : loss : 0.104504, loss_ce: 0.048657
2021-12-10 10:36:36,814 iteration 214 : loss : 0.144761, loss_ce: 0.057920
2021-12-10 10:36:39,794 iteration 215 : loss : 0.124799, loss_ce: 0.062081
2021-12-10 10:36:42,843 iteration 216 : loss : 0.138014, loss_ce: 0.060950
2021-12-10 10:36:45,763 iteration 217 : loss : 0.173027, loss_ce: 0.060106
2021-12-10 10:36:48,799 iteration 218 : loss : 0.159424, loss_ce: 0.049804
2021-12-10 10:36:51,634 iteration 219 : loss : 0.140708, loss_ce: 0.054907
2021-12-10 10:36:54,627 iteration 220 : loss : 0.169045, loss_ce: 0.065742
2021-12-10 10:36:57,535 iteration 221 : loss : 0.151506, loss_ce: 0.049624
  3%|▉                             | 13/400 [10:20<5:37:54, 52.39s/it]2021-12-10 10:37:00,514 iteration 222 : loss : 0.144643, loss_ce: 0.059048
2021-12-10 10:37:03,506 iteration 223 : loss : 0.136718, loss_ce: 0.051040
2021-12-10 10:37:06,398 iteration 224 : loss : 0.114963, loss_ce: 0.045785
2021-12-10 10:37:09,282 iteration 225 : loss : 0.143140, loss_ce: 0.049204
2021-12-10 10:37:12,053 iteration 226 : loss : 0.160502, loss_ce: 0.075016
2021-12-10 10:37:15,068 iteration 227 : loss : 0.141663, loss_ce: 0.059178
2021-12-10 10:37:18,057 iteration 228 : loss : 0.082446, loss_ce: 0.039451
2021-12-10 10:37:21,148 iteration 229 : loss : 0.098333, loss_ce: 0.036111
2021-12-10 10:37:24,000 iteration 230 : loss : 0.164816, loss_ce: 0.073838
2021-12-10 10:37:27,004 iteration 231 : loss : 0.135295, loss_ce: 0.045176
2021-12-10 10:37:29,923 iteration 232 : loss : 0.147126, loss_ce: 0.049294
2021-12-10 10:37:32,652 iteration 233 : loss : 0.143317, loss_ce: 0.056648
2021-12-10 10:37:35,614 iteration 234 : loss : 0.117742, loss_ce: 0.043605
2021-12-10 10:37:38,599 iteration 235 : loss : 0.190623, loss_ce: 0.097122
2021-12-10 10:37:41,515 iteration 236 : loss : 0.149239, loss_ce: 0.065116
2021-12-10 10:37:44,491 iteration 237 : loss : 0.123066, loss_ce: 0.042882
2021-12-10 10:37:47,609 iteration 238 : loss : 0.192599, loss_ce: 0.058990
  4%|█                             | 14/400 [11:10<5:32:32, 51.69s/it]2021-12-10 10:37:50,623 iteration 239 : loss : 0.196107, loss_ce: 0.073846
2021-12-10 10:37:53,550 iteration 240 : loss : 0.158905, loss_ce: 0.058897
2021-12-10 10:37:56,391 iteration 241 : loss : 0.097678, loss_ce: 0.041053
2021-12-10 10:37:59,446 iteration 242 : loss : 0.100768, loss_ce: 0.048688
2021-12-10 10:38:02,282 iteration 243 : loss : 0.156321, loss_ce: 0.069810
2021-12-10 10:38:05,233 iteration 244 : loss : 0.126729, loss_ce: 0.044909
2021-12-10 10:38:08,217 iteration 245 : loss : 0.133577, loss_ce: 0.053296
2021-12-10 10:38:11,169 iteration 246 : loss : 0.149699, loss_ce: 0.062795
2021-12-10 10:38:14,215 iteration 247 : loss : 0.113663, loss_ce: 0.037366
2021-12-10 10:38:17,121 iteration 248 : loss : 0.101900, loss_ce: 0.041993
2021-12-10 10:38:19,915 iteration 249 : loss : 0.100708, loss_ce: 0.038990
2021-12-10 10:38:22,814 iteration 250 : loss : 0.101827, loss_ce: 0.040463
2021-12-10 10:38:25,769 iteration 251 : loss : 0.108985, loss_ce: 0.041689
2021-12-10 10:38:28,747 iteration 252 : loss : 0.124614, loss_ce: 0.054571
2021-12-10 10:38:31,643 iteration 253 : loss : 0.086323, loss_ce: 0.042290
2021-12-10 10:38:34,571 iteration 254 : loss : 0.139770, loss_ce: 0.051237
2021-12-10 10:38:34,571 Training Data Eval:
2021-12-10 10:38:50,353   Average segmentation loss on training set: 0.1860
2021-12-10 10:38:50,353 Validation Data Eval:
2021-12-10 10:38:55,835   Average segmentation loss on validation set: 0.1817
2021-12-10 10:39:01,639 Found new lowest validation loss at iteration 254! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/NEW_TU/NEW_TU_ADAM_best_val_loss_seed1234_no_da.pth
2021-12-10 10:39:03,629 iteration 255 : loss : 0.165108, loss_ce: 0.050467
  4%|█▏                            | 15/400 [12:26<6:18:44, 59.02s/it]2021-12-10 10:39:06,588 iteration 256 : loss : 0.123395, loss_ce: 0.045262
2021-12-10 10:39:09,474 iteration 257 : loss : 0.124152, loss_ce: 0.045607
2021-12-10 10:39:12,198 iteration 258 : loss : 0.106291, loss_ce: 0.037461
2021-12-10 10:39:15,073 iteration 259 : loss : 0.137022, loss_ce: 0.042954
2021-12-10 10:39:18,002 iteration 260 : loss : 0.124612, loss_ce: 0.046416
2021-12-10 10:39:20,904 iteration 261 : loss : 0.137379, loss_ce: 0.055575
2021-12-10 10:39:23,883 iteration 262 : loss : 0.129649, loss_ce: 0.046931
2021-12-10 10:39:26,879 iteration 263 : loss : 0.103043, loss_ce: 0.048526
2021-12-10 10:39:29,868 iteration 264 : loss : 0.108704, loss_ce: 0.045405
2021-12-10 10:39:32,855 iteration 265 : loss : 0.109916, loss_ce: 0.033260
2021-12-10 10:39:35,602 iteration 266 : loss : 0.095435, loss_ce: 0.039577
2021-12-10 10:39:38,469 iteration 267 : loss : 0.113544, loss_ce: 0.049353
2021-12-10 10:39:41,491 iteration 268 : loss : 0.100021, loss_ce: 0.035142
2021-12-10 10:39:44,515 iteration 269 : loss : 0.105077, loss_ce: 0.042580
2021-12-10 10:39:47,511 iteration 270 : loss : 0.116446, loss_ce: 0.039198
2021-12-10 10:39:50,400 iteration 271 : loss : 0.120579, loss_ce: 0.052841
2021-12-10 10:39:53,415 iteration 272 : loss : 0.101283, loss_ce: 0.046731
  4%|█▏                            | 16/400 [13:16<5:59:57, 56.24s/it]2021-12-10 10:39:56,377 iteration 273 : loss : 0.088380, loss_ce: 0.034305
2021-12-10 10:39:59,266 iteration 274 : loss : 0.119516, loss_ce: 0.044067
2021-12-10 10:40:02,231 iteration 275 : loss : 0.103662, loss_ce: 0.037565
2021-12-10 10:40:05,153 iteration 276 : loss : 0.080860, loss_ce: 0.032016
2021-12-10 10:40:08,053 iteration 277 : loss : 0.106737, loss_ce: 0.042377
2021-12-10 10:40:10,956 iteration 278 : loss : 0.113753, loss_ce: 0.037930
2021-12-10 10:40:13,854 iteration 279 : loss : 0.110219, loss_ce: 0.046258
2021-12-10 10:40:16,849 iteration 280 : loss : 0.093572, loss_ce: 0.034590
2021-12-10 10:40:19,782 iteration 281 : loss : 0.153410, loss_ce: 0.040781
2021-12-10 10:40:22,625 iteration 282 : loss : 0.117383, loss_ce: 0.051121
2021-12-10 10:40:25,660 iteration 283 : loss : 0.098034, loss_ce: 0.039294
2021-12-10 10:40:28,392 iteration 284 : loss : 0.097202, loss_ce: 0.035948
2021-12-10 10:40:31,359 iteration 285 : loss : 0.086548, loss_ce: 0.044149
2021-12-10 10:40:34,256 iteration 286 : loss : 0.072771, loss_ce: 0.032913
2021-12-10 10:40:37,232 iteration 287 : loss : 0.087564, loss_ce: 0.039289
2021-12-10 10:40:40,263 iteration 288 : loss : 0.098644, loss_ce: 0.044605
2021-12-10 10:40:43,102 iteration 289 : loss : 0.113113, loss_ce: 0.054896
  4%|█▎                            | 17/400 [14:05<5:46:26, 54.27s/it]2021-12-10 10:40:46,181 iteration 290 : loss : 0.083015, loss_ce: 0.038210
2021-12-10 10:40:49,079 iteration 291 : loss : 0.096127, loss_ce: 0.039780
2021-12-10 10:40:52,072 iteration 292 : loss : 0.083519, loss_ce: 0.035629
2021-12-10 10:40:55,130 iteration 293 : loss : 0.123312, loss_ce: 0.042572
2021-12-10 10:40:58,162 iteration 294 : loss : 0.093493, loss_ce: 0.037778
2021-12-10 10:41:01,085 iteration 295 : loss : 0.073441, loss_ce: 0.025740
2021-12-10 10:41:04,126 iteration 296 : loss : 0.063239, loss_ce: 0.027915
2021-12-10 10:41:07,079 iteration 297 : loss : 0.090061, loss_ce: 0.030769
2021-12-10 10:41:10,071 iteration 298 : loss : 0.064113, loss_ce: 0.029274
2021-12-10 10:41:12,996 iteration 299 : loss : 0.098031, loss_ce: 0.037065
2021-12-10 10:41:15,897 iteration 300 : loss : 0.102776, loss_ce: 0.041995
2021-12-10 10:41:18,838 iteration 301 : loss : 0.098687, loss_ce: 0.036353
2021-12-10 10:41:21,760 iteration 302 : loss : 0.113057, loss_ce: 0.036764
2021-12-10 10:41:24,664 iteration 303 : loss : 0.093741, loss_ce: 0.044927
2021-12-10 10:41:27,665 iteration 304 : loss : 0.080594, loss_ce: 0.030291
2021-12-10 10:41:30,686 iteration 305 : loss : 0.088035, loss_ce: 0.025411
2021-12-10 10:41:33,654 iteration 306 : loss : 0.121543, loss_ce: 0.054553
  4%|█▎                            | 18/400 [14:56<5:38:24, 53.15s/it]2021-12-10 10:41:36,656 iteration 307 : loss : 0.086164, loss_ce: 0.031588
2021-12-10 10:41:39,380 iteration 308 : loss : 0.096348, loss_ce: 0.046493
2021-12-10 10:41:42,272 iteration 309 : loss : 0.099971, loss_ce: 0.049720
2021-12-10 10:41:45,200 iteration 310 : loss : 0.077767, loss_ce: 0.033341
2021-12-10 10:41:48,194 iteration 311 : loss : 0.153436, loss_ce: 0.053151
2021-12-10 10:41:51,288 iteration 312 : loss : 0.103954, loss_ce: 0.041125
2021-12-10 10:41:54,282 iteration 313 : loss : 0.134359, loss_ce: 0.051890
2021-12-10 10:41:57,174 iteration 314 : loss : 0.079232, loss_ce: 0.032423
2021-12-10 10:42:00,370 iteration 315 : loss : 0.107443, loss_ce: 0.039058
2021-12-10 10:42:03,291 iteration 316 : loss : 0.103679, loss_ce: 0.049092
2021-12-10 10:42:06,205 iteration 317 : loss : 0.067210, loss_ce: 0.027929
2021-12-10 10:42:08,928 iteration 318 : loss : 0.134679, loss_ce: 0.032861
2021-12-10 10:42:11,758 iteration 319 : loss : 0.107839, loss_ce: 0.037059
2021-12-10 10:42:14,642 iteration 320 : loss : 0.089019, loss_ce: 0.043765
2021-12-10 10:42:17,625 iteration 321 : loss : 0.079699, loss_ce: 0.035295
2021-12-10 10:42:20,521 iteration 322 : loss : 0.078208, loss_ce: 0.030675
2021-12-10 10:42:23,541 iteration 323 : loss : 0.080425, loss_ce: 0.039320
  5%|█▍                            | 19/400 [15:46<5:31:17, 52.17s/it]2021-12-10 10:42:26,506 iteration 324 : loss : 0.067682, loss_ce: 0.030486
2021-12-10 10:42:29,398 iteration 325 : loss : 0.108444, loss_ce: 0.042288
2021-12-10 10:42:32,322 iteration 326 : loss : 0.104703, loss_ce: 0.044432
2021-12-10 10:42:35,240 iteration 327 : loss : 0.120695, loss_ce: 0.052691
2021-12-10 10:42:38,169 iteration 328 : loss : 0.096918, loss_ce: 0.034249
2021-12-10 10:42:41,018 iteration 329 : loss : 0.094445, loss_ce: 0.035391
2021-12-10 10:42:44,205 iteration 330 : loss : 0.081130, loss_ce: 0.041711
2021-12-10 10:42:47,117 iteration 331 : loss : 0.070522, loss_ce: 0.025023
2021-12-10 10:42:50,157 iteration 332 : loss : 0.106408, loss_ce: 0.038117
2021-12-10 10:42:52,992 iteration 333 : loss : 0.086752, loss_ce: 0.037542
2021-12-10 10:42:56,017 iteration 334 : loss : 0.070143, loss_ce: 0.027323
2021-12-10 10:42:58,859 iteration 335 : loss : 0.092084, loss_ce: 0.038433
2021-12-10 10:43:01,861 iteration 336 : loss : 0.085677, loss_ce: 0.042777
2021-12-10 10:43:04,863 iteration 337 : loss : 0.127376, loss_ce: 0.033533
2021-12-10 10:43:07,798 iteration 338 : loss : 0.118081, loss_ce: 0.045401
2021-12-10 10:43:10,715 iteration 339 : loss : 0.090441, loss_ce: 0.041552
2021-12-10 10:43:10,715 Training Data Eval:
2021-12-10 10:43:27,078   Average segmentation loss on training set: 0.1100
2021-12-10 10:43:27,079 Validation Data Eval:
2021-12-10 10:43:32,762   Average segmentation loss on validation set: 0.1432
2021-12-10 10:43:38,575 Found new lowest validation loss at iteration 339! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/NEW_TU/NEW_TU_ADAM_best_val_loss_seed1234_no_da.pth
2021-12-10 10:43:40,594 iteration 340 : loss : 0.069173, loss_ce: 0.029858
  5%|█▌                            | 20/400 [17:03<6:17:43, 59.64s/it]2021-12-10 10:43:43,574 iteration 341 : loss : 0.087261, loss_ce: 0.035912
2021-12-10 10:43:46,372 iteration 342 : loss : 0.054906, loss_ce: 0.025860
2021-12-10 10:43:49,100 iteration 343 : loss : 0.084401, loss_ce: 0.034571
2021-12-10 10:43:51,932 iteration 344 : loss : 0.093816, loss_ce: 0.039633
2021-12-10 10:43:54,772 iteration 345 : loss : 0.085098, loss_ce: 0.033376
2021-12-10 10:43:57,684 iteration 346 : loss : 0.071573, loss_ce: 0.025895
2021-12-10 10:44:00,644 iteration 347 : loss : 0.072068, loss_ce: 0.029070
2021-12-10 10:44:03,554 iteration 348 : loss : 0.073085, loss_ce: 0.032745
2021-12-10 10:44:06,438 iteration 349 : loss : 0.065095, loss_ce: 0.022853
2021-12-10 10:44:09,220 iteration 350 : loss : 0.069291, loss_ce: 0.026058
2021-12-10 10:44:12,191 iteration 351 : loss : 0.081183, loss_ce: 0.030628
2021-12-10 10:44:15,274 iteration 352 : loss : 0.072201, loss_ce: 0.031534
2021-12-10 10:44:18,275 iteration 353 : loss : 0.074677, loss_ce: 0.035826
2021-12-10 10:44:21,157 iteration 354 : loss : 0.083595, loss_ce: 0.034315
2021-12-10 10:44:24,390 iteration 355 : loss : 0.143505, loss_ce: 0.032064
2021-12-10 10:44:27,263 iteration 356 : loss : 0.064418, loss_ce: 0.027120
2021-12-10 10:44:30,327 iteration 357 : loss : 0.088929, loss_ce: 0.036988
  5%|█▌                            | 21/400 [17:53<5:57:57, 56.67s/it]2021-12-10 10:44:33,272 iteration 358 : loss : 0.104720, loss_ce: 0.025458
2021-12-10 10:44:36,147 iteration 359 : loss : 0.112648, loss_ce: 0.041898
2021-12-10 10:44:39,232 iteration 360 : loss : 0.083232, loss_ce: 0.030511
2021-12-10 10:44:42,235 iteration 361 : loss : 0.076768, loss_ce: 0.029890
2021-12-10 10:44:45,135 iteration 362 : loss : 0.093848, loss_ce: 0.039533
2021-12-10 10:44:48,146 iteration 363 : loss : 0.068194, loss_ce: 0.024537
2021-12-10 10:44:51,192 iteration 364 : loss : 0.065416, loss_ce: 0.025461
2021-12-10 10:44:54,199 iteration 365 : loss : 0.083420, loss_ce: 0.035879
2021-12-10 10:44:57,112 iteration 366 : loss : 0.090214, loss_ce: 0.038585
2021-12-10 10:44:59,986 iteration 367 : loss : 0.082970, loss_ce: 0.034948
2021-12-10 10:45:02,861 iteration 368 : loss : 0.093408, loss_ce: 0.042521
2021-12-10 10:45:05,694 iteration 369 : loss : 0.067428, loss_ce: 0.027054
2021-12-10 10:45:08,699 iteration 370 : loss : 0.054320, loss_ce: 0.022863
2021-12-10 10:45:11,479 iteration 371 : loss : 0.075502, loss_ce: 0.032397
2021-12-10 10:45:14,338 iteration 372 : loss : 0.055631, loss_ce: 0.020640
2021-12-10 10:45:17,172 iteration 373 : loss : 0.080238, loss_ce: 0.030820
2021-12-10 10:45:20,153 iteration 374 : loss : 0.046802, loss_ce: 0.019820
  6%|█▋                            | 22/400 [18:42<5:44:04, 54.61s/it]2021-12-10 10:45:23,161 iteration 375 : loss : 0.071772, loss_ce: 0.027725
2021-12-10 10:45:26,240 iteration 376 : loss : 0.064198, loss_ce: 0.025438
2021-12-10 10:45:29,289 iteration 377 : loss : 0.074131, loss_ce: 0.027814
2021-12-10 10:45:32,187 iteration 378 : loss : 0.069955, loss_ce: 0.033551
2021-12-10 10:45:35,393 iteration 379 : loss : 0.072918, loss_ce: 0.028124
2021-12-10 10:45:38,429 iteration 380 : loss : 0.066504, loss_ce: 0.028603
2021-12-10 10:45:41,327 iteration 381 : loss : 0.055596, loss_ce: 0.022863
2021-12-10 10:45:44,234 iteration 382 : loss : 0.095693, loss_ce: 0.036541
2021-12-10 10:45:47,071 iteration 383 : loss : 0.094265, loss_ce: 0.027312
2021-12-10 10:45:50,067 iteration 384 : loss : 0.059357, loss_ce: 0.026037
2021-12-10 10:45:53,093 iteration 385 : loss : 0.060315, loss_ce: 0.023079
2021-12-10 10:45:56,080 iteration 386 : loss : 0.070688, loss_ce: 0.030072
2021-12-10 10:45:58,919 iteration 387 : loss : 0.090079, loss_ce: 0.032729
2021-12-10 10:46:01,948 iteration 388 : loss : 0.072860, loss_ce: 0.032327
2021-12-10 10:46:04,795 iteration 389 : loss : 0.113891, loss_ce: 0.034454
2021-12-10 10:46:07,792 iteration 390 : loss : 0.068043, loss_ce: 0.029046
2021-12-10 10:46:10,726 iteration 391 : loss : 0.076473, loss_ce: 0.037232
  6%|█▋                            | 23/400 [19:33<5:35:31, 53.40s/it]2021-12-10 10:46:13,735 iteration 392 : loss : 0.076911, loss_ce: 0.037408
2021-12-10 10:46:16,472 iteration 393 : loss : 0.048154, loss_ce: 0.021044
2021-12-10 10:46:19,397 iteration 394 : loss : 0.121425, loss_ce: 0.032214
2021-12-10 10:46:22,319 iteration 395 : loss : 0.069296, loss_ce: 0.029773
2021-12-10 10:46:25,330 iteration 396 : loss : 0.062780, loss_ce: 0.021873
2021-12-10 10:46:28,324 iteration 397 : loss : 0.079419, loss_ce: 0.033640
2021-12-10 10:46:31,235 iteration 398 : loss : 0.075788, loss_ce: 0.034101
2021-12-10 10:46:34,122 iteration 399 : loss : 0.048684, loss_ce: 0.021266
2021-12-10 10:46:37,023 iteration 400 : loss : 0.081751, loss_ce: 0.034271
2021-12-10 10:46:39,955 iteration 401 : loss : 0.090997, loss_ce: 0.030832
2021-12-10 10:46:42,838 iteration 402 : loss : 0.061776, loss_ce: 0.026040
2021-12-10 10:46:45,757 iteration 403 : loss : 0.060314, loss_ce: 0.027383
2021-12-10 10:46:48,661 iteration 404 : loss : 0.093781, loss_ce: 0.026448
2021-12-10 10:46:51,695 iteration 405 : loss : 0.082172, loss_ce: 0.033706
2021-12-10 10:46:54,723 iteration 406 : loss : 0.093082, loss_ce: 0.032947
2021-12-10 10:46:57,637 iteration 407 : loss : 0.058085, loss_ce: 0.026013
2021-12-10 10:47:00,363 iteration 408 : loss : 0.078887, loss_ce: 0.030258
  6%|█▊                            | 24/400 [20:23<5:27:34, 52.27s/it]2021-12-10 10:47:03,422 iteration 409 : loss : 0.081271, loss_ce: 0.039748
2021-12-10 10:47:06,335 iteration 410 : loss : 0.065392, loss_ce: 0.022462
2021-12-10 10:47:09,311 iteration 411 : loss : 0.054673, loss_ce: 0.023319
2021-12-10 10:47:12,182 iteration 412 : loss : 0.070865, loss_ce: 0.025904
2021-12-10 10:47:15,368 iteration 413 : loss : 0.080833, loss_ce: 0.032250
2021-12-10 10:47:18,345 iteration 414 : loss : 0.075188, loss_ce: 0.029315
2021-12-10 10:47:21,278 iteration 415 : loss : 0.072678, loss_ce: 0.035718
2021-12-10 10:47:24,274 iteration 416 : loss : 0.072709, loss_ce: 0.033348
2021-12-10 10:47:27,232 iteration 417 : loss : 0.108737, loss_ce: 0.032539
2021-12-10 10:47:30,223 iteration 418 : loss : 0.075380, loss_ce: 0.024107
2021-12-10 10:47:33,237 iteration 419 : loss : 0.060267, loss_ce: 0.023360
2021-12-10 10:47:36,106 iteration 420 : loss : 0.062233, loss_ce: 0.023724
2021-12-10 10:47:38,972 iteration 421 : loss : 0.067234, loss_ce: 0.025172
2021-12-10 10:47:41,840 iteration 422 : loss : 0.076290, loss_ce: 0.026498
2021-12-10 10:47:44,699 iteration 423 : loss : 0.063407, loss_ce: 0.028839
2021-12-10 10:47:47,554 iteration 424 : loss : 0.067157, loss_ce: 0.025128
2021-12-10 10:47:47,555 Training Data Eval:
2021-12-10 10:48:03,732   Average segmentation loss on training set: 0.1818
2021-12-10 10:48:03,732 Validation Data Eval:
2021-12-10 10:48:09,594   Average segmentation loss on validation set: 0.2904
2021-12-10 10:48:12,598 iteration 425 : loss : 0.071776, loss_ce: 0.031451
  6%|█▉                            | 25/400 [21:35<6:04:08, 58.26s/it]2021-12-10 10:48:15,569 iteration 426 : loss : 0.056307, loss_ce: 0.023711
2021-12-10 10:48:18,404 iteration 427 : loss : 0.067046, loss_ce: 0.031113
2021-12-10 10:48:21,439 iteration 428 : loss : 0.081384, loss_ce: 0.027844
2021-12-10 10:48:24,272 iteration 429 : loss : 0.060205, loss_ce: 0.022986
2021-12-10 10:48:27,217 iteration 430 : loss : 0.142528, loss_ce: 0.031498
2021-12-10 10:48:30,227 iteration 431 : loss : 0.067375, loss_ce: 0.028112
2021-12-10 10:48:33,166 iteration 432 : loss : 0.054811, loss_ce: 0.020278
2021-12-10 10:48:36,000 iteration 433 : loss : 0.089599, loss_ce: 0.036451
2021-12-10 10:48:38,836 iteration 434 : loss : 0.145117, loss_ce: 0.033440
2021-12-10 10:48:41,732 iteration 435 : loss : 0.074990, loss_ce: 0.027450
2021-12-10 10:48:44,719 iteration 436 : loss : 0.093790, loss_ce: 0.041146
2021-12-10 10:48:47,585 iteration 437 : loss : 0.085573, loss_ce: 0.032228
2021-12-10 10:48:50,447 iteration 438 : loss : 0.078330, loss_ce: 0.044784
2021-12-10 10:48:53,307 iteration 439 : loss : 0.107125, loss_ce: 0.037714
2021-12-10 10:48:56,163 iteration 440 : loss : 0.100601, loss_ce: 0.029216
2021-12-10 10:48:59,174 iteration 441 : loss : 0.070973, loss_ce: 0.037932
2021-12-10 10:49:02,173 iteration 442 : loss : 0.057213, loss_ce: 0.028749
  6%|█▉                            | 26/400 [22:25<5:46:55, 55.66s/it]2021-12-10 10:49:05,186 iteration 443 : loss : 0.066150, loss_ce: 0.029892
2021-12-10 10:49:08,098 iteration 444 : loss : 0.060955, loss_ce: 0.026044
2021-12-10 10:49:10,989 iteration 445 : loss : 0.091809, loss_ce: 0.031869
2021-12-10 10:49:13,713 iteration 446 : loss : 0.060856, loss_ce: 0.024204
2021-12-10 10:49:16,714 iteration 447 : loss : 0.077239, loss_ce: 0.031893
2021-12-10 10:49:19,615 iteration 448 : loss : 0.070698, loss_ce: 0.026537
2021-12-10 10:49:22,635 iteration 449 : loss : 0.077207, loss_ce: 0.031577
2021-12-10 10:49:25,529 iteration 450 : loss : 0.092174, loss_ce: 0.033462
2021-12-10 10:49:28,448 iteration 451 : loss : 0.089594, loss_ce: 0.038068
2021-12-10 10:49:31,182 iteration 452 : loss : 0.079061, loss_ce: 0.037105
2021-12-10 10:49:34,182 iteration 453 : loss : 0.086292, loss_ce: 0.028277
2021-12-10 10:49:37,021 iteration 454 : loss : 0.074045, loss_ce: 0.030796
2021-12-10 10:49:40,030 iteration 455 : loss : 0.072215, loss_ce: 0.027248
2021-12-10 10:49:43,022 iteration 456 : loss : 0.073320, loss_ce: 0.028256
2021-12-10 10:49:45,759 iteration 457 : loss : 0.050480, loss_ce: 0.018619
2021-12-10 10:49:48,614 iteration 458 : loss : 0.087045, loss_ce: 0.036235
2021-12-10 10:49:51,612 iteration 459 : loss : 0.062508, loss_ce: 0.021882
  7%|██                            | 27/400 [23:14<5:34:23, 53.79s/it]2021-12-10 10:49:54,492 iteration 460 : loss : 0.072019, loss_ce: 0.031079
2021-12-10 10:49:57,485 iteration 461 : loss : 0.069159, loss_ce: 0.026447
2021-12-10 10:50:00,415 iteration 462 : loss : 0.066596, loss_ce: 0.024030
2021-12-10 10:50:03,156 iteration 463 : loss : 0.093915, loss_ce: 0.032030
2021-12-10 10:50:06,066 iteration 464 : loss : 0.085648, loss_ce: 0.028969
2021-12-10 10:50:08,784 iteration 465 : loss : 0.075382, loss_ce: 0.031274
2021-12-10 10:50:11,788 iteration 466 : loss : 0.079761, loss_ce: 0.032754
2021-12-10 10:50:14,682 iteration 467 : loss : 0.049991, loss_ce: 0.020258
2021-12-10 10:50:17,562 iteration 468 : loss : 0.061856, loss_ce: 0.021497
2021-12-10 10:50:20,463 iteration 469 : loss : 0.104338, loss_ce: 0.062528
2021-12-10 10:50:23,465 iteration 470 : loss : 0.061976, loss_ce: 0.025689
2021-12-10 10:50:26,366 iteration 471 : loss : 0.061614, loss_ce: 0.029964
2021-12-10 10:50:29,269 iteration 472 : loss : 0.062087, loss_ce: 0.025110
2021-12-10 10:50:32,192 iteration 473 : loss : 0.077422, loss_ce: 0.036472
2021-12-10 10:50:34,920 iteration 474 : loss : 0.058656, loss_ce: 0.022555
2021-12-10 10:50:37,813 iteration 475 : loss : 0.136584, loss_ce: 0.037098
2021-12-10 10:50:40,619 iteration 476 : loss : 0.083813, loss_ce: 0.033598
  7%|██                            | 28/400 [24:03<5:24:36, 52.36s/it]2021-12-10 10:50:43,610 iteration 477 : loss : 0.055350, loss_ce: 0.024668
2021-12-10 10:50:46,353 iteration 478 : loss : 0.058083, loss_ce: 0.025784
2021-12-10 10:50:49,187 iteration 479 : loss : 0.084337, loss_ce: 0.029742
2021-12-10 10:50:52,020 iteration 480 : loss : 0.076342, loss_ce: 0.024561
2021-12-10 10:50:54,842 iteration 481 : loss : 0.063810, loss_ce: 0.024144
2021-12-10 10:50:57,670 iteration 482 : loss : 0.079347, loss_ce: 0.025924
2021-12-10 10:51:00,697 iteration 483 : loss : 0.091623, loss_ce: 0.030536
2021-12-10 10:51:03,423 iteration 484 : loss : 0.130893, loss_ce: 0.070016
2021-12-10 10:51:06,260 iteration 485 : loss : 0.077242, loss_ce: 0.032312
2021-12-10 10:51:09,255 iteration 486 : loss : 0.070805, loss_ce: 0.022917
2021-12-10 10:51:12,170 iteration 487 : loss : 0.076296, loss_ce: 0.022368
2021-12-10 10:51:15,098 iteration 488 : loss : 0.091536, loss_ce: 0.039521
2021-12-10 10:51:17,940 iteration 489 : loss : 0.068157, loss_ce: 0.028689
2021-12-10 10:51:20,831 iteration 490 : loss : 0.083346, loss_ce: 0.036205
2021-12-10 10:51:23,550 iteration 491 : loss : 0.083825, loss_ce: 0.042002
2021-12-10 10:51:26,382 iteration 492 : loss : 0.061616, loss_ce: 0.028858
2021-12-10 10:51:29,216 iteration 493 : loss : 0.085516, loss_ce: 0.037502
  7%|██▏                           | 29/400 [24:52<5:16:45, 51.23s/it]2021-12-10 10:51:32,122 iteration 494 : loss : 0.105308, loss_ce: 0.036770
2021-12-10 10:51:34,964 iteration 495 : loss : 0.077095, loss_ce: 0.028516
2021-12-10 10:51:37,858 iteration 496 : loss : 0.071009, loss_ce: 0.027032
2021-12-10 10:51:40,602 iteration 497 : loss : 0.065668, loss_ce: 0.030933
2021-12-10 10:51:43,442 iteration 498 : loss : 0.072331, loss_ce: 0.030368
2021-12-10 10:51:46,281 iteration 499 : loss : 0.069631, loss_ce: 0.026274
2021-12-10 10:51:49,052 iteration 500 : loss : 0.052080, loss_ce: 0.021244
2021-12-10 10:51:51,907 iteration 501 : loss : 0.059194, loss_ce: 0.022430
2021-12-10 10:51:54,679 iteration 502 : loss : 0.071909, loss_ce: 0.034961
2021-12-10 10:51:57,508 iteration 503 : loss : 0.062922, loss_ce: 0.031186
2021-12-10 10:52:00,437 iteration 504 : loss : 0.050185, loss_ce: 0.019330
2021-12-10 10:52:03,174 iteration 505 : loss : 0.067292, loss_ce: 0.037995
2021-12-10 10:52:06,086 iteration 506 : loss : 0.048177, loss_ce: 0.020668
2021-12-10 10:52:08,846 iteration 507 : loss : 0.066058, loss_ce: 0.024798
2021-12-10 10:52:11,604 iteration 508 : loss : 0.064638, loss_ce: 0.026124
2021-12-10 10:52:14,350 iteration 509 : loss : 0.048346, loss_ce: 0.019176
2021-12-10 10:52:14,350 Training Data Eval:
2021-12-10 10:52:29,877   Average segmentation loss on training set: 0.0801
2021-12-10 10:52:29,877 Validation Data Eval:
2021-12-10 10:52:35,357   Average segmentation loss on validation set: 0.1496
2021-12-10 10:52:38,074 iteration 510 : loss : 0.075351, loss_ce: 0.023053
  8%|██▎                           | 30/400 [26:00<5:48:31, 56.52s/it]2021-12-10 10:52:41,013 iteration 511 : loss : 0.051751, loss_ce: 0.022041
2021-12-10 10:52:43,773 iteration 512 : loss : 0.055797, loss_ce: 0.028779
2021-12-10 10:52:46,551 iteration 513 : loss : 0.055677, loss_ce: 0.021404
2021-12-10 10:52:49,295 iteration 514 : loss : 0.042645, loss_ce: 0.015512
2021-12-10 10:52:52,070 iteration 515 : loss : 0.104599, loss_ce: 0.027715
2021-12-10 10:52:54,829 iteration 516 : loss : 0.057284, loss_ce: 0.020533
2021-12-10 10:52:57,588 iteration 517 : loss : 0.068027, loss_ce: 0.025485
2021-12-10 10:53:00,473 iteration 518 : loss : 0.060584, loss_ce: 0.023461
2021-12-10 10:53:03,280 iteration 519 : loss : 0.060606, loss_ce: 0.025686
2021-12-10 10:53:06,035 iteration 520 : loss : 0.067554, loss_ce: 0.030486
2021-12-10 10:53:08,837 iteration 521 : loss : 0.069313, loss_ce: 0.023876
2021-12-10 10:53:11,588 iteration 522 : loss : 0.058869, loss_ce: 0.030482
2021-12-10 10:53:14,345 iteration 523 : loss : 0.063726, loss_ce: 0.024829
2021-12-10 10:53:17,092 iteration 524 : loss : 0.061644, loss_ce: 0.025937
2021-12-10 10:53:19,833 iteration 525 : loss : 0.049506, loss_ce: 0.021193
2021-12-10 10:53:22,611 iteration 526 : loss : 0.068450, loss_ce: 0.027831
2021-12-10 10:53:25,347 iteration 527 : loss : 0.102727, loss_ce: 0.035592
  8%|██▎                           | 31/400 [26:48<5:30:31, 53.74s/it]2021-12-10 10:53:28,118 iteration 528 : loss : 0.046011, loss_ce: 0.018512
2021-12-10 10:53:30,875 iteration 529 : loss : 0.050297, loss_ce: 0.020486
2021-12-10 10:53:33,656 iteration 530 : loss : 0.075267, loss_ce: 0.022555
2021-12-10 10:53:36,404 iteration 531 : loss : 0.043063, loss_ce: 0.020634
2021-12-10 10:53:39,184 iteration 532 : loss : 0.056891, loss_ce: 0.025571
2021-12-10 10:53:41,970 iteration 533 : loss : 0.051744, loss_ce: 0.021218
2021-12-10 10:53:44,633 iteration 534 : loss : 0.070723, loss_ce: 0.020221
2021-12-10 10:53:47,403 iteration 535 : loss : 0.046598, loss_ce: 0.017519
2021-12-10 10:53:50,204 iteration 536 : loss : 0.033531, loss_ce: 0.013652
2021-12-10 10:53:52,834 iteration 537 : loss : 0.069746, loss_ce: 0.036408
2021-12-10 10:53:55,595 iteration 538 : loss : 0.070807, loss_ce: 0.025040
2021-12-10 10:53:58,357 iteration 539 : loss : 0.057198, loss_ce: 0.020254
2021-12-10 10:54:01,031 iteration 540 : loss : 0.073874, loss_ce: 0.034509
2021-12-10 10:54:03,677 iteration 541 : loss : 0.043078, loss_ce: 0.022231
2021-12-10 10:54:06,447 iteration 542 : loss : 0.048104, loss_ce: 0.016688
2021-12-10 10:54:09,055 iteration 543 : loss : 0.134312, loss_ce: 0.034852
2021-12-10 10:54:11,924 iteration 544 : loss : 0.068844, loss_ce: 0.025135
  8%|██▍                           | 32/400 [27:34<5:16:26, 51.59s/it]2021-12-10 10:54:14,704 iteration 545 : loss : 0.044068, loss_ce: 0.015124
2021-12-10 10:54:17,428 iteration 546 : loss : 0.066232, loss_ce: 0.016471
2021-12-10 10:54:20,190 iteration 547 : loss : 0.070356, loss_ce: 0.023462
2021-12-10 10:54:22,861 iteration 548 : loss : 0.065895, loss_ce: 0.026082
2021-12-10 10:54:25,644 iteration 549 : loss : 0.054061, loss_ce: 0.015286
2021-12-10 10:54:28,451 iteration 550 : loss : 0.059279, loss_ce: 0.022062
2021-12-10 10:54:31,053 iteration 551 : loss : 0.067533, loss_ce: 0.027811
2021-12-10 10:54:33,781 iteration 552 : loss : 0.088262, loss_ce: 0.043369
2021-12-10 10:54:36,551 iteration 553 : loss : 0.054650, loss_ce: 0.020543
2021-12-10 10:54:39,207 iteration 554 : loss : 0.066186, loss_ce: 0.035409
2021-12-10 10:54:41,942 iteration 555 : loss : 0.049682, loss_ce: 0.019439
2021-12-10 10:54:44,611 iteration 556 : loss : 0.060527, loss_ce: 0.025767
2021-12-10 10:54:47,331 iteration 557 : loss : 0.092675, loss_ce: 0.033341
2021-12-10 10:54:50,033 iteration 558 : loss : 0.046751, loss_ce: 0.019470
2021-12-10 10:54:52,795 iteration 559 : loss : 0.054359, loss_ce: 0.021669
2021-12-10 10:54:55,580 iteration 560 : loss : 0.061251, loss_ce: 0.024355
2021-12-10 10:54:58,215 iteration 561 : loss : 0.048068, loss_ce: 0.020939
  8%|██▍                           | 33/400 [28:21<5:05:50, 50.00s/it]2021-12-10 10:55:01,022 iteration 562 : loss : 0.039791, loss_ce: 0.018343
2021-12-10 10:55:03,787 iteration 563 : loss : 0.069949, loss_ce: 0.024122
2021-12-10 10:55:06,422 iteration 564 : loss : 0.050173, loss_ce: 0.018250
2021-12-10 10:55:09,179 iteration 565 : loss : 0.049099, loss_ce: 0.024791
2021-12-10 10:55:11,856 iteration 566 : loss : 0.060207, loss_ce: 0.022838
2021-12-10 10:55:14,635 iteration 567 : loss : 0.046582, loss_ce: 0.021212
2021-12-10 10:55:17,262 iteration 568 : loss : 0.054807, loss_ce: 0.020276
2021-12-10 10:55:20,031 iteration 569 : loss : 0.063896, loss_ce: 0.023994
2021-12-10 10:55:22,701 iteration 570 : loss : 0.052710, loss_ce: 0.019911
2021-12-10 10:55:25,483 iteration 571 : loss : 0.050677, loss_ce: 0.019345
2021-12-10 10:55:28,124 iteration 572 : loss : 0.047484, loss_ce: 0.022029
2021-12-10 10:55:30,840 iteration 573 : loss : 0.051628, loss_ce: 0.022563
2021-12-10 10:55:33,584 iteration 574 : loss : 0.075100, loss_ce: 0.026922
2021-12-10 10:55:36,235 iteration 575 : loss : 0.060251, loss_ce: 0.024294
2021-12-10 10:55:38,950 iteration 576 : loss : 0.060673, loss_ce: 0.027466
2021-12-10 10:55:41,663 iteration 577 : loss : 0.049793, loss_ce: 0.021139
2021-12-10 10:55:44,413 iteration 578 : loss : 0.071826, loss_ce: 0.024692
  8%|██▌                           | 34/400 [29:07<4:58:03, 48.86s/it]2021-12-10 10:55:47,179 iteration 579 : loss : 0.060177, loss_ce: 0.022301
2021-12-10 10:55:49,904 iteration 580 : loss : 0.043912, loss_ce: 0.014974
2021-12-10 10:55:52,688 iteration 581 : loss : 0.054208, loss_ce: 0.021604
2021-12-10 10:55:55,356 iteration 582 : loss : 0.044332, loss_ce: 0.015805
2021-12-10 10:55:58,156 iteration 583 : loss : 0.049599, loss_ce: 0.017085
2021-12-10 10:56:00,754 iteration 584 : loss : 0.051087, loss_ce: 0.018828
2021-12-10 10:56:03,413 iteration 585 : loss : 0.041385, loss_ce: 0.015673
2021-12-10 10:56:06,199 iteration 586 : loss : 0.049282, loss_ce: 0.016189
2021-12-10 10:56:08,805 iteration 587 : loss : 0.036124, loss_ce: 0.014944
2021-12-10 10:56:11,429 iteration 588 : loss : 0.056568, loss_ce: 0.025471
2021-12-10 10:56:14,154 iteration 589 : loss : 0.053119, loss_ce: 0.018319
2021-12-10 10:56:16,777 iteration 590 : loss : 0.048584, loss_ce: 0.018213
2021-12-10 10:56:19,552 iteration 591 : loss : 0.054371, loss_ce: 0.025757
2021-12-10 10:56:22,152 iteration 592 : loss : 0.039430, loss_ce: 0.017248
2021-12-10 10:56:24,901 iteration 593 : loss : 0.057002, loss_ce: 0.027661
2021-12-10 10:56:27,545 iteration 594 : loss : 0.040575, loss_ce: 0.017133
2021-12-10 10:56:27,545 Training Data Eval:
2021-12-10 10:56:42,512   Average segmentation loss on training set: 0.0507
2021-12-10 10:56:42,513 Validation Data Eval:
2021-12-10 10:56:47,770   Average segmentation loss on validation set: 0.1140
2021-12-10 10:56:53,493 Found new lowest validation loss at iteration 594! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/NEW_TU/NEW_TU_ADAM_best_val_loss_seed1234_no_da.pth
2021-12-10 10:56:55,149 iteration 595 : loss : 0.067888, loss_ce: 0.025055
  9%|██▋                           | 35/400 [30:17<5:37:09, 55.42s/it]2021-12-10 10:56:57,203 iteration 596 : loss : 0.049546, loss_ce: 0.021206
2021-12-10 10:56:59,652 iteration 597 : loss : 0.046641, loss_ce: 0.021697
2021-12-10 10:57:02,053 iteration 598 : loss : 0.043512, loss_ce: 0.015962
2021-12-10 10:57:04,390 iteration 599 : loss : 0.052315, loss_ce: 0.020048
2021-12-10 10:57:06,949 iteration 600 : loss : 0.041454, loss_ce: 0.018485
2021-12-10 10:57:09,517 iteration 601 : loss : 0.056481, loss_ce: 0.020459
2021-12-10 10:57:12,059 iteration 602 : loss : 0.045073, loss_ce: 0.022044
2021-12-10 10:57:14,626 iteration 603 : loss : 0.044885, loss_ce: 0.022192
2021-12-10 10:57:17,224 iteration 604 : loss : 0.041557, loss_ce: 0.016998
2021-12-10 10:57:19,799 iteration 605 : loss : 0.063102, loss_ce: 0.025849
2021-12-10 10:57:22,413 iteration 606 : loss : 0.041316, loss_ce: 0.015907
2021-12-10 10:57:25,028 iteration 607 : loss : 0.052914, loss_ce: 0.016797
2021-12-10 10:57:27,654 iteration 608 : loss : 0.052493, loss_ce: 0.020509
2021-12-10 10:57:30,283 iteration 609 : loss : 0.092994, loss_ce: 0.034561
2021-12-10 10:57:33,009 iteration 610 : loss : 0.053951, loss_ce: 0.017789
2021-12-10 10:57:35,701 iteration 611 : loss : 0.046428, loss_ce: 0.019127
2021-12-10 10:57:38,315 iteration 612 : loss : 0.058977, loss_ce: 0.014516
  9%|██▋                           | 36/400 [31:01<5:13:55, 51.75s/it]2021-12-10 10:57:41,002 iteration 613 : loss : 0.045138, loss_ce: 0.019785
2021-12-10 10:57:43,769 iteration 614 : loss : 0.053314, loss_ce: 0.017778
2021-12-10 10:57:46,408 iteration 615 : loss : 0.039595, loss_ce: 0.016641
2021-12-10 10:57:49,200 iteration 616 : loss : 0.045439, loss_ce: 0.016091
2021-12-10 10:57:51,809 iteration 617 : loss : 0.053819, loss_ce: 0.023813
2021-12-10 10:57:54,591 iteration 618 : loss : 0.047033, loss_ce: 0.016893
2021-12-10 10:57:57,222 iteration 619 : loss : 0.044946, loss_ce: 0.018009
2021-12-10 10:57:59,987 iteration 620 : loss : 0.048628, loss_ce: 0.021601
2021-12-10 10:58:02,654 iteration 621 : loss : 0.036278, loss_ce: 0.015222
2021-12-10 10:58:05,278 iteration 622 : loss : 0.066821, loss_ce: 0.018887
2021-12-10 10:58:08,065 iteration 623 : loss : 0.087788, loss_ce: 0.022830
2021-12-10 10:58:10,659 iteration 624 : loss : 0.051836, loss_ce: 0.018938
2021-12-10 10:58:13,299 iteration 625 : loss : 0.081641, loss_ce: 0.030130
2021-12-10 10:58:15,893 iteration 626 : loss : 0.059077, loss_ce: 0.032502
2021-12-10 10:58:18,631 iteration 627 : loss : 0.049555, loss_ce: 0.016710
2021-12-10 10:58:21,297 iteration 628 : loss : 0.059406, loss_ce: 0.020722
2021-12-10 10:58:23,964 iteration 629 : loss : 0.047236, loss_ce: 0.018702
  9%|██▊                           | 37/400 [31:46<5:01:58, 49.91s/it]2021-12-10 10:58:26,712 iteration 630 : loss : 0.052232, loss_ce: 0.019737
2021-12-10 10:58:29,317 iteration 631 : loss : 0.125750, loss_ce: 0.028850
2021-12-10 10:58:32,079 iteration 632 : loss : 0.037710, loss_ce: 0.015463
2021-12-10 10:58:34,672 iteration 633 : loss : 0.034384, loss_ce: 0.015563
2021-12-10 10:58:37,294 iteration 634 : loss : 0.062837, loss_ce: 0.021640
2021-12-10 10:58:40,065 iteration 635 : loss : 0.054229, loss_ce: 0.020433
2021-12-10 10:58:42,702 iteration 636 : loss : 0.053497, loss_ce: 0.024196
2021-12-10 10:58:45,461 iteration 637 : loss : 0.046533, loss_ce: 0.022869
2021-12-10 10:58:48,123 iteration 638 : loss : 0.068875, loss_ce: 0.024373
2021-12-10 10:58:50,745 iteration 639 : loss : 0.055929, loss_ce: 0.019789
2021-12-10 10:58:53,530 iteration 640 : loss : 0.059159, loss_ce: 0.028520
2021-12-10 10:58:56,139 iteration 641 : loss : 0.043565, loss_ce: 0.019970
2021-12-10 10:58:58,816 iteration 642 : loss : 0.043076, loss_ce: 0.018124
2021-12-10 10:59:01,503 iteration 643 : loss : 0.061425, loss_ce: 0.022049
2021-12-10 10:59:04,187 iteration 644 : loss : 0.062286, loss_ce: 0.020792
2021-12-10 10:59:06,796 iteration 645 : loss : 0.045520, loss_ce: 0.017283
2021-12-10 10:59:09,423 iteration 646 : loss : 0.070955, loss_ce: 0.022244
 10%|██▊                           | 38/400 [32:32<4:53:04, 48.58s/it]2021-12-10 10:59:12,179 iteration 647 : loss : 0.050037, loss_ce: 0.012949
2021-12-10 10:59:14,807 iteration 648 : loss : 0.050062, loss_ce: 0.018665
2021-12-10 10:59:17,626 iteration 649 : loss : 0.047209, loss_ce: 0.018027
2021-12-10 10:59:20,240 iteration 650 : loss : 0.060941, loss_ce: 0.029629
2021-12-10 10:59:22,850 iteration 651 : loss : 0.052312, loss_ce: 0.015977
2021-12-10 10:59:25,454 iteration 652 : loss : 0.040428, loss_ce: 0.018306
2021-12-10 10:59:28,224 iteration 653 : loss : 0.044945, loss_ce: 0.014610
2021-12-10 10:59:30,821 iteration 654 : loss : 0.053552, loss_ce: 0.029991
2021-12-10 10:59:33,555 iteration 655 : loss : 0.054223, loss_ce: 0.019645
2021-12-10 10:59:36,220 iteration 656 : loss : 0.043666, loss_ce: 0.016926
2021-12-10 10:59:38,849 iteration 657 : loss : 0.051686, loss_ce: 0.020267
2021-12-10 10:59:41,504 iteration 658 : loss : 0.049430, loss_ce: 0.022739
2021-12-10 10:59:44,163 iteration 659 : loss : 0.042680, loss_ce: 0.023495
2021-12-10 10:59:46,795 iteration 660 : loss : 0.051139, loss_ce: 0.019366
2021-12-10 10:59:49,406 iteration 661 : loss : 0.038306, loss_ce: 0.016809
2021-12-10 10:59:52,054 iteration 662 : loss : 0.035335, loss_ce: 0.015591
2021-12-10 10:59:54,675 iteration 663 : loss : 0.060454, loss_ce: 0.019589
 10%|██▉                           | 39/400 [33:17<4:46:15, 47.58s/it]2021-12-10 10:59:57,427 iteration 664 : loss : 0.042626, loss_ce: 0.020315
2021-12-10 11:00:00,072 iteration 665 : loss : 0.042042, loss_ce: 0.021228
2021-12-10 11:00:02,768 iteration 666 : loss : 0.068336, loss_ce: 0.022328
2021-12-10 11:00:05,470 iteration 667 : loss : 0.039888, loss_ce: 0.016073
2021-12-10 11:00:08,062 iteration 668 : loss : 0.041917, loss_ce: 0.012437
2021-12-10 11:00:10,760 iteration 669 : loss : 0.044713, loss_ce: 0.016425
2021-12-10 11:00:13,364 iteration 670 : loss : 0.043593, loss_ce: 0.014731
2021-12-10 11:00:16,021 iteration 671 : loss : 0.046243, loss_ce: 0.019568
2021-12-10 11:00:18,659 iteration 672 : loss : 0.048292, loss_ce: 0.021585
2021-12-10 11:00:21,262 iteration 673 : loss : 0.038555, loss_ce: 0.015923
2021-12-10 11:00:23,874 iteration 674 : loss : 0.043188, loss_ce: 0.017795
2021-12-10 11:00:26,498 iteration 675 : loss : 0.041572, loss_ce: 0.017337
2021-12-10 11:00:29,126 iteration 676 : loss : 0.043267, loss_ce: 0.016160
2021-12-10 11:00:31,739 iteration 677 : loss : 0.063008, loss_ce: 0.023824
2021-12-10 11:00:34,398 iteration 678 : loss : 0.035231, loss_ce: 0.013833
2021-12-10 11:00:37,000 iteration 679 : loss : 0.041879, loss_ce: 0.016956
2021-12-10 11:00:37,000 Training Data Eval:
2021-12-10 11:00:51,582   Average segmentation loss on training set: 0.0541
2021-12-10 11:00:51,582 Validation Data Eval:
2021-12-10 11:00:56,691   Average segmentation loss on validation set: 0.1038
2021-12-10 11:01:02,610 Found new lowest validation loss at iteration 679! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/NEW_TU/NEW_TU_ADAM_best_val_loss_seed1234_no_da.pth
2021-12-10 11:01:04,232 iteration 680 : loss : 0.040204, loss_ce: 0.015763
 10%|███                           | 40/400 [34:27<5:25:03, 54.18s/it]2021-12-10 11:01:06,235 iteration 681 : loss : 0.058520, loss_ce: 0.020105
2021-12-10 11:01:08,602 iteration 682 : loss : 0.045796, loss_ce: 0.021849
2021-12-10 11:01:10,962 iteration 683 : loss : 0.061934, loss_ce: 0.022265
2021-12-10 11:01:13,275 iteration 684 : loss : 0.040123, loss_ce: 0.016123
2021-12-10 11:01:15,618 iteration 685 : loss : 0.041438, loss_ce: 0.013711
2021-12-10 11:01:18,025 iteration 686 : loss : 0.031718, loss_ce: 0.011021
2021-12-10 11:01:20,531 iteration 687 : loss : 0.042919, loss_ce: 0.015905
2021-12-10 11:01:23,061 iteration 688 : loss : 0.046260, loss_ce: 0.019001
2021-12-10 11:01:25,628 iteration 689 : loss : 0.037736, loss_ce: 0.015934
2021-12-10 11:01:28,204 iteration 690 : loss : 0.058135, loss_ce: 0.025473
2021-12-10 11:01:30,813 iteration 691 : loss : 0.050592, loss_ce: 0.021193
2021-12-10 11:01:33,421 iteration 692 : loss : 0.036684, loss_ce: 0.015700
2021-12-10 11:01:36,001 iteration 693 : loss : 0.042301, loss_ce: 0.017097
2021-12-10 11:01:38,622 iteration 694 : loss : 0.044618, loss_ce: 0.018001
2021-12-10 11:01:41,227 iteration 695 : loss : 0.046111, loss_ce: 0.017881
2021-12-10 11:01:43,941 iteration 696 : loss : 0.048239, loss_ce: 0.017953
2021-12-10 11:01:46,566 iteration 697 : loss : 0.044537, loss_ce: 0.017200
 10%|███                           | 41/400 [35:09<5:02:53, 50.62s/it]2021-12-10 11:01:49,240 iteration 698 : loss : 0.040730, loss_ce: 0.019505
2021-12-10 11:01:51,861 iteration 699 : loss : 0.053068, loss_ce: 0.020635
2021-12-10 11:01:54,483 iteration 700 : loss : 0.043871, loss_ce: 0.016716
2021-12-10 11:01:57,207 iteration 701 : loss : 0.042333, loss_ce: 0.018980
2021-12-10 11:01:59,815 iteration 702 : loss : 0.046793, loss_ce: 0.016196
2021-12-10 11:02:02,433 iteration 703 : loss : 0.049179, loss_ce: 0.021151
2021-12-10 11:02:05,219 iteration 704 : loss : 0.031271, loss_ce: 0.012180
2021-12-10 11:02:07,825 iteration 705 : loss : 0.041552, loss_ce: 0.013212
2021-12-10 11:02:10,463 iteration 706 : loss : 0.050421, loss_ce: 0.017827
2021-12-10 11:02:13,072 iteration 707 : loss : 0.039402, loss_ce: 0.011849
2021-12-10 11:02:15,598 iteration 708 : loss : 0.046196, loss_ce: 0.020782
2021-12-10 11:02:18,222 iteration 709 : loss : 0.060278, loss_ce: 0.036386
2021-12-10 11:02:20,887 iteration 710 : loss : 0.039578, loss_ce: 0.017227
2021-12-10 11:02:23,554 iteration 711 : loss : 0.032213, loss_ce: 0.013103
2021-12-10 11:02:26,220 iteration 712 : loss : 0.030502, loss_ce: 0.014539
2021-12-10 11:02:28,847 iteration 713 : loss : 0.062271, loss_ce: 0.019751
2021-12-10 11:02:31,609 iteration 714 : loss : 0.055662, loss_ce: 0.021569
 10%|███▏                          | 42/400 [35:54<4:52:04, 48.95s/it]2021-12-10 11:02:34,301 iteration 715 : loss : 0.054866, loss_ce: 0.020921
2021-12-10 11:02:36,919 iteration 716 : loss : 0.048983, loss_ce: 0.015231
2021-12-10 11:02:39,684 iteration 717 : loss : 0.047758, loss_ce: 0.019252
2021-12-10 11:02:42,279 iteration 718 : loss : 0.040571, loss_ce: 0.018727
2021-12-10 11:02:44,857 iteration 719 : loss : 0.031948, loss_ce: 0.014119
2021-12-10 11:02:47,623 iteration 720 : loss : 0.039566, loss_ce: 0.019158
2021-12-10 11:02:50,235 iteration 721 : loss : 0.053704, loss_ce: 0.016432
2021-12-10 11:02:52,850 iteration 722 : loss : 0.035938, loss_ce: 0.012492
2021-12-10 11:02:55,448 iteration 723 : loss : 0.044975, loss_ce: 0.015518
2021-12-10 11:02:58,072 iteration 724 : loss : 0.048267, loss_ce: 0.022232
2021-12-10 11:03:00,812 iteration 725 : loss : 0.052796, loss_ce: 0.027617
2021-12-10 11:03:03,532 iteration 726 : loss : 0.039508, loss_ce: 0.015389
2021-12-10 11:03:06,156 iteration 727 : loss : 0.041817, loss_ce: 0.017641
2021-12-10 11:03:08,925 iteration 728 : loss : 0.047329, loss_ce: 0.021133
2021-12-10 11:03:11,495 iteration 729 : loss : 0.053097, loss_ce: 0.017862
2021-12-10 11:03:14,088 iteration 730 : loss : 0.050465, loss_ce: 0.017686
2021-12-10 11:03:16,710 iteration 731 : loss : 0.026556, loss_ce: 0.010062
 11%|███▏                          | 43/400 [36:39<4:44:22, 47.79s/it]2021-12-10 11:03:19,394 iteration 732 : loss : 0.040910, loss_ce: 0.013988
2021-12-10 11:03:22,011 iteration 733 : loss : 0.040304, loss_ce: 0.014846
2021-12-10 11:03:24,779 iteration 734 : loss : 0.039735, loss_ce: 0.016894
2021-12-10 11:03:27,401 iteration 735 : loss : 0.044305, loss_ce: 0.019873
2021-12-10 11:03:30,010 iteration 736 : loss : 0.038037, loss_ce: 0.011822
2021-12-10 11:03:32,609 iteration 737 : loss : 0.034090, loss_ce: 0.014000
2021-12-10 11:03:35,243 iteration 738 : loss : 0.045032, loss_ce: 0.015891
2021-12-10 11:03:37,995 iteration 739 : loss : 0.054343, loss_ce: 0.020439
2021-12-10 11:03:40,600 iteration 740 : loss : 0.066262, loss_ce: 0.017235
2021-12-10 11:03:43,225 iteration 741 : loss : 0.031433, loss_ce: 0.009183
2021-12-10 11:03:45,833 iteration 742 : loss : 0.066936, loss_ce: 0.025659
2021-12-10 11:03:48,578 iteration 743 : loss : 0.046133, loss_ce: 0.014910
2021-12-10 11:03:51,204 iteration 744 : loss : 0.051907, loss_ce: 0.023175
2021-12-10 11:03:53,984 iteration 745 : loss : 0.063936, loss_ce: 0.022458
2021-12-10 11:03:56,580 iteration 746 : loss : 0.038613, loss_ce: 0.015682
2021-12-10 11:03:59,175 iteration 747 : loss : 0.057376, loss_ce: 0.018966
2021-12-10 11:04:01,809 iteration 748 : loss : 0.057430, loss_ce: 0.025274
 11%|███▎                          | 44/400 [37:24<4:38:47, 46.99s/it]2021-12-10 11:04:04,448 iteration 749 : loss : 0.051953, loss_ce: 0.022191
2021-12-10 11:04:07,060 iteration 750 : loss : 0.049960, loss_ce: 0.018784
2021-12-10 11:04:09,822 iteration 751 : loss : 0.055078, loss_ce: 0.017332
2021-12-10 11:04:12,422 iteration 752 : loss : 0.045440, loss_ce: 0.018789
2021-12-10 11:04:15,026 iteration 753 : loss : 0.049289, loss_ce: 0.019526
2021-12-10 11:04:17,785 iteration 754 : loss : 0.041021, loss_ce: 0.014829
2021-12-10 11:04:20,390 iteration 755 : loss : 0.034320, loss_ce: 0.014722
2021-12-10 11:04:23,039 iteration 756 : loss : 0.046013, loss_ce: 0.013050
2021-12-10 11:04:25,716 iteration 757 : loss : 0.047922, loss_ce: 0.021319
2021-12-10 11:04:28,354 iteration 758 : loss : 0.044312, loss_ce: 0.012257
2021-12-10 11:04:30,962 iteration 759 : loss : 0.053536, loss_ce: 0.019850
2021-12-10 11:04:33,593 iteration 760 : loss : 0.039893, loss_ce: 0.017373
2021-12-10 11:04:36,203 iteration 761 : loss : 0.028498, loss_ce: 0.011429
2021-12-10 11:04:38,826 iteration 762 : loss : 0.040153, loss_ce: 0.015911
2021-12-10 11:04:41,591 iteration 763 : loss : 0.041074, loss_ce: 0.018614
2021-12-10 11:04:44,206 iteration 764 : loss : 0.034596, loss_ce: 0.013275
2021-12-10 11:04:44,206 Training Data Eval:
2021-12-10 11:04:58,975   Average segmentation loss on training set: 0.0421
2021-12-10 11:04:58,976 Validation Data Eval:
2021-12-10 11:05:04,215   Average segmentation loss on validation set: 0.0888
2021-12-10 11:05:10,028 Found new lowest validation loss at iteration 764! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/NEW_TU/NEW_TU_ADAM_best_val_loss_seed1234_no_da.pth
2021-12-10 11:05:11,666 iteration 765 : loss : 0.047218, loss_ce: 0.022313
 11%|███▍                          | 45/400 [38:34<5:18:36, 53.85s/it]2021-12-10 11:05:13,701 iteration 766 : loss : 0.037698, loss_ce: 0.016525
2021-12-10 11:05:16,218 iteration 767 : loss : 0.032664, loss_ce: 0.013305
2021-12-10 11:05:18,551 iteration 768 : loss : 0.048493, loss_ce: 0.018275
2021-12-10 11:05:20,843 iteration 769 : loss : 0.037684, loss_ce: 0.015624
2021-12-10 11:05:23,180 iteration 770 : loss : 0.031048, loss_ce: 0.012675
2021-12-10 11:05:25,648 iteration 771 : loss : 0.054526, loss_ce: 0.017850
2021-12-10 11:05:28,146 iteration 772 : loss : 0.058182, loss_ce: 0.022335
2021-12-10 11:05:30,734 iteration 773 : loss : 0.052125, loss_ce: 0.027524
2021-12-10 11:05:33,322 iteration 774 : loss : 0.036634, loss_ce: 0.014591
2021-12-10 11:05:35,941 iteration 775 : loss : 0.028903, loss_ce: 0.010000
2021-12-10 11:05:38,542 iteration 776 : loss : 0.037002, loss_ce: 0.012413
2021-12-10 11:05:41,172 iteration 777 : loss : 0.036591, loss_ce: 0.014007
2021-12-10 11:05:43,839 iteration 778 : loss : 0.041342, loss_ce: 0.013904
2021-12-10 11:05:46,441 iteration 779 : loss : 0.050128, loss_ce: 0.026664
2021-12-10 11:05:49,058 iteration 780 : loss : 0.034895, loss_ce: 0.013651
2021-12-10 11:05:51,821 iteration 781 : loss : 0.045691, loss_ce: 0.022891
2021-12-10 11:05:54,421 iteration 782 : loss : 0.038154, loss_ce: 0.016420
 12%|███▍                          | 46/400 [39:17<4:58:04, 50.52s/it]2021-12-10 11:05:57,120 iteration 783 : loss : 0.038048, loss_ce: 0.014167
2021-12-10 11:05:59,912 iteration 784 : loss : 0.035773, loss_ce: 0.014650
2021-12-10 11:06:02,541 iteration 785 : loss : 0.050962, loss_ce: 0.014410
2021-12-10 11:06:05,306 iteration 786 : loss : 0.045208, loss_ce: 0.014981
2021-12-10 11:06:07,904 iteration 787 : loss : 0.031123, loss_ce: 0.014776
2021-12-10 11:06:10,522 iteration 788 : loss : 0.036939, loss_ce: 0.016704
2021-12-10 11:06:13,180 iteration 789 : loss : 0.036203, loss_ce: 0.012859
2021-12-10 11:06:15,804 iteration 790 : loss : 0.039866, loss_ce: 0.014388
2021-12-10 11:06:18,418 iteration 791 : loss : 0.031941, loss_ce: 0.011445
2021-12-10 11:06:21,350 iteration 792 : loss : 0.042303, loss_ce: 0.018225
2021-12-10 11:06:23,981 iteration 793 : loss : 0.037769, loss_ce: 0.017834
2021-12-10 11:06:26,755 iteration 794 : loss : 0.036743, loss_ce: 0.012745
2021-12-10 11:06:29,360 iteration 795 : loss : 0.038238, loss_ce: 0.017803
2021-12-10 11:06:31,985 iteration 796 : loss : 0.040738, loss_ce: 0.016078
2021-12-10 11:06:34,751 iteration 797 : loss : 0.037307, loss_ce: 0.017702
2021-12-10 11:06:37,420 iteration 798 : loss : 0.037665, loss_ce: 0.015679
2021-12-10 11:06:40,036 iteration 799 : loss : 0.035782, loss_ce: 0.016946
 12%|███▌                          | 47/400 [40:02<4:48:34, 49.05s/it]2021-12-10 11:06:42,901 iteration 800 : loss : 0.039897, loss_ce: 0.015084
2021-12-10 11:06:45,499 iteration 801 : loss : 0.031208, loss_ce: 0.014257
2021-12-10 11:06:48,206 iteration 802 : loss : 0.047693, loss_ce: 0.015300
2021-12-10 11:06:50,831 iteration 803 : loss : 0.027636, loss_ce: 0.010915
2021-12-10 11:06:53,604 iteration 804 : loss : 0.036060, loss_ce: 0.013582
2021-12-10 11:06:56,210 iteration 805 : loss : 0.040709, loss_ce: 0.014024
2021-12-10 11:06:58,831 iteration 806 : loss : 0.031622, loss_ce: 0.014595
2021-12-10 11:07:01,615 iteration 807 : loss : 0.039469, loss_ce: 0.015581
2021-12-10 11:07:04,214 iteration 808 : loss : 0.038441, loss_ce: 0.013180
2021-12-10 11:07:06,959 iteration 809 : loss : 0.041194, loss_ce: 0.016912
2021-12-10 11:07:09,603 iteration 810 : loss : 0.043389, loss_ce: 0.011979
2021-12-10 11:07:12,225 iteration 811 : loss : 0.037988, loss_ce: 0.016209
2021-12-10 11:07:14,991 iteration 812 : loss : 0.045749, loss_ce: 0.018877
2021-12-10 11:07:17,656 iteration 813 : loss : 0.040376, loss_ce: 0.017596
2021-12-10 11:07:20,326 iteration 814 : loss : 0.038016, loss_ce: 0.015761
2021-12-10 11:07:22,992 iteration 815 : loss : 0.049716, loss_ce: 0.017780
2021-12-10 11:07:25,655 iteration 816 : loss : 0.035890, loss_ce: 0.014837
 12%|███▌                          | 48/400 [40:48<4:41:42, 48.02s/it]2021-12-10 11:07:28,452 iteration 817 : loss : 0.034669, loss_ce: 0.014082
2021-12-10 11:07:31,087 iteration 818 : loss : 0.028603, loss_ce: 0.011578
2021-12-10 11:07:33,845 iteration 819 : loss : 0.027435, loss_ce: 0.013619
2021-12-10 11:07:36,471 iteration 820 : loss : 0.049442, loss_ce: 0.018976
2021-12-10 11:07:39,180 iteration 821 : loss : 0.030273, loss_ce: 0.013869
2021-12-10 11:07:41,850 iteration 822 : loss : 0.035492, loss_ce: 0.015306
2021-12-10 11:07:44,462 iteration 823 : loss : 0.036619, loss_ce: 0.015222
2021-12-10 11:07:47,243 iteration 824 : loss : 0.036684, loss_ce: 0.014744
2021-12-10 11:07:49,872 iteration 825 : loss : 0.037234, loss_ce: 0.014912
2021-12-10 11:07:52,523 iteration 826 : loss : 0.031550, loss_ce: 0.014611
2021-12-10 11:07:55,142 iteration 827 : loss : 0.046741, loss_ce: 0.020112
2021-12-10 11:07:57,924 iteration 828 : loss : 0.038022, loss_ce: 0.015613
2021-12-10 11:08:00,530 iteration 829 : loss : 0.039899, loss_ce: 0.016603
2021-12-10 11:08:03,121 iteration 830 : loss : 0.039843, loss_ce: 0.010206
2021-12-10 11:08:05,896 iteration 831 : loss : 0.040113, loss_ce: 0.010881
2021-12-10 11:08:08,515 iteration 832 : loss : 0.046650, loss_ce: 0.014167
2021-12-10 11:08:11,206 iteration 833 : loss : 0.033712, loss_ce: 0.013127
 12%|███▋                          | 49/400 [41:34<4:36:34, 47.28s/it]2021-12-10 11:08:13,967 iteration 834 : loss : 0.047066, loss_ce: 0.024936
2021-12-10 11:08:16,598 iteration 835 : loss : 0.037219, loss_ce: 0.013011
2021-12-10 11:08:19,203 iteration 836 : loss : 0.033460, loss_ce: 0.014712
2021-12-10 11:08:21,969 iteration 837 : loss : 0.038110, loss_ce: 0.011810
2021-12-10 11:08:24,597 iteration 838 : loss : 0.030665, loss_ce: 0.012726
2021-12-10 11:08:27,202 iteration 839 : loss : 0.059818, loss_ce: 0.015263
2021-12-10 11:08:29,936 iteration 840 : loss : 0.040075, loss_ce: 0.014938
2021-12-10 11:08:32,711 iteration 841 : loss : 0.052895, loss_ce: 0.020303
2021-12-10 11:08:35,340 iteration 842 : loss : 0.036322, loss_ce: 0.012569
2021-12-10 11:08:38,109 iteration 843 : loss : 0.040012, loss_ce: 0.015425
2021-12-10 11:08:40,742 iteration 844 : loss : 0.036524, loss_ce: 0.016596
2021-12-10 11:08:43,346 iteration 845 : loss : 0.037581, loss_ce: 0.015465
2021-12-10 11:08:46,115 iteration 846 : loss : 0.044602, loss_ce: 0.016260
2021-12-10 11:08:48,709 iteration 847 : loss : 0.041960, loss_ce: 0.015983
2021-12-10 11:08:51,314 iteration 848 : loss : 0.037235, loss_ce: 0.013125
2021-12-10 11:08:54,078 iteration 849 : loss : 0.034360, loss_ce: 0.017683
2021-12-10 11:08:54,078 Training Data Eval:
2021-12-10 11:09:08,863   Average segmentation loss on training set: 0.0386
2021-12-10 11:09:08,863 Validation Data Eval:
2021-12-10 11:09:14,009   Average segmentation loss on validation set: 0.1157
2021-12-10 11:09:16,653 iteration 850 : loss : 0.036903, loss_ce: 0.013873
 12%|███▊                          | 50/400 [42:39<5:07:35, 52.73s/it]2021-12-10 11:09:19,289 iteration 851 : loss : 0.049960, loss_ce: 0.019649
2021-12-10 11:09:22,065 iteration 852 : loss : 0.034936, loss_ce: 0.012735
2021-12-10 11:09:24,670 iteration 853 : loss : 0.033198, loss_ce: 0.010560
2021-12-10 11:09:27,327 iteration 854 : loss : 0.030390, loss_ce: 0.016108
2021-12-10 11:09:29,973 iteration 855 : loss : 0.027621, loss_ce: 0.012990
2021-12-10 11:09:32,637 iteration 856 : loss : 0.044625, loss_ce: 0.015261
2021-12-10 11:09:35,300 iteration 857 : loss : 0.038976, loss_ce: 0.015641
2021-12-10 11:09:37,960 iteration 858 : loss : 0.029566, loss_ce: 0.011063
2021-12-10 11:09:40,585 iteration 859 : loss : 0.032721, loss_ce: 0.013601
2021-12-10 11:09:43,369 iteration 860 : loss : 0.043728, loss_ce: 0.016358
2021-12-10 11:09:45,967 iteration 861 : loss : 0.038595, loss_ce: 0.014887
2021-12-10 11:09:48,619 iteration 862 : loss : 0.034092, loss_ce: 0.015044
2021-12-10 11:09:51,397 iteration 863 : loss : 0.031155, loss_ce: 0.012550
2021-12-10 11:09:53,996 iteration 864 : loss : 0.035403, loss_ce: 0.013143
2021-12-10 11:09:56,663 iteration 865 : loss : 0.040436, loss_ce: 0.013203
2021-12-10 11:09:59,264 iteration 866 : loss : 0.039643, loss_ce: 0.013934
2021-12-10 11:10:01,922 iteration 867 : loss : 0.035917, loss_ce: 0.014163
 13%|███▊                          | 51/400 [43:24<4:53:41, 50.49s/it]2021-12-10 11:10:04,595 iteration 868 : loss : 0.029894, loss_ce: 0.011892
2021-12-10 11:10:07,250 iteration 869 : loss : 0.046349, loss_ce: 0.020331
2021-12-10 11:10:09,877 iteration 870 : loss : 0.037519, loss_ce: 0.014184
2021-12-10 11:10:12,545 iteration 871 : loss : 0.022840, loss_ce: 0.007456
2021-12-10 11:10:15,154 iteration 872 : loss : 0.032031, loss_ce: 0.014448
2021-12-10 11:10:17,775 iteration 873 : loss : 0.037850, loss_ce: 0.012000
2021-12-10 11:10:20,542 iteration 874 : loss : 0.031438, loss_ce: 0.013608
2021-12-10 11:10:23,137 iteration 875 : loss : 0.036993, loss_ce: 0.014979
2021-12-10 11:10:25,885 iteration 876 : loss : 0.033536, loss_ce: 0.012422
2021-12-10 11:10:28,507 iteration 877 : loss : 0.039405, loss_ce: 0.013362
2021-12-10 11:10:31,176 iteration 878 : loss : 0.033938, loss_ce: 0.014350
2021-12-10 11:10:33,955 iteration 879 : loss : 0.024433, loss_ce: 0.009467
2021-12-10 11:10:36,554 iteration 880 : loss : 0.045775, loss_ce: 0.025655
2021-12-10 11:10:39,180 iteration 881 : loss : 0.043272, loss_ce: 0.018471
2021-12-10 11:10:41,890 iteration 882 : loss : 0.036515, loss_ce: 0.012329
2021-12-10 11:10:44,546 iteration 883 : loss : 0.047651, loss_ce: 0.015175
2021-12-10 11:10:47,315 iteration 884 : loss : 0.026514, loss_ce: 0.011697
 13%|███▉                          | 52/400 [44:10<4:43:58, 48.96s/it]2021-12-10 11:10:49,946 iteration 885 : loss : 0.035570, loss_ce: 0.013434
2021-12-10 11:10:52,555 iteration 886 : loss : 0.032066, loss_ce: 0.014944
2021-12-10 11:10:55,310 iteration 887 : loss : 0.035882, loss_ce: 0.013332
2021-12-10 11:10:57,955 iteration 888 : loss : 0.034019, loss_ce: 0.011457
2021-12-10 11:11:00,594 iteration 889 : loss : 0.033602, loss_ce: 0.013517
2021-12-10 11:11:03,215 iteration 890 : loss : 0.031968, loss_ce: 0.013423
2021-12-10 11:11:05,980 iteration 891 : loss : 0.042918, loss_ce: 0.013531
2021-12-10 11:11:08,603 iteration 892 : loss : 0.042995, loss_ce: 0.014320
2021-12-10 11:11:11,223 iteration 893 : loss : 0.035018, loss_ce: 0.013511
2021-12-10 11:11:14,033 iteration 894 : loss : 0.035489, loss_ce: 0.015329
2021-12-10 11:11:16,647 iteration 895 : loss : 0.040249, loss_ce: 0.010626
2021-12-10 11:11:19,318 iteration 896 : loss : 0.029915, loss_ce: 0.010439
2021-12-10 11:11:21,982 iteration 897 : loss : 0.037991, loss_ce: 0.018011
2021-12-10 11:11:24,644 iteration 898 : loss : 0.028003, loss_ce: 0.012312
2021-12-10 11:11:27,275 iteration 899 : loss : 0.035722, loss_ce: 0.018694
2021-12-10 11:11:30,062 iteration 900 : loss : 0.034869, loss_ce: 0.013017
2021-12-10 11:11:32,659 iteration 901 : loss : 0.034716, loss_ce: 0.010849
 13%|███▉                          | 53/400 [44:55<4:36:53, 47.88s/it]2021-12-10 11:11:35,322 iteration 902 : loss : 0.029618, loss_ce: 0.012458
2021-12-10 11:11:37,944 iteration 903 : loss : 0.035217, loss_ce: 0.015376
2021-12-10 11:11:40,558 iteration 904 : loss : 0.030907, loss_ce: 0.014233
2021-12-10 11:11:43,288 iteration 905 : loss : 0.029208, loss_ce: 0.011780
2021-12-10 11:11:45,957 iteration 906 : loss : 0.032703, loss_ce: 0.014953
2021-12-10 11:11:48,582 iteration 907 : loss : 0.032729, loss_ce: 0.010428
2021-12-10 11:11:51,364 iteration 908 : loss : 0.047586, loss_ce: 0.015345
2021-12-10 11:11:53,963 iteration 909 : loss : 0.038594, loss_ce: 0.018573
2021-12-10 11:11:56,587 iteration 910 : loss : 0.035392, loss_ce: 0.014102
2021-12-10 11:11:59,364 iteration 911 : loss : 0.049671, loss_ce: 0.012746
2021-12-10 11:12:01,961 iteration 912 : loss : 0.030785, loss_ce: 0.010816
2021-12-10 11:12:04,582 iteration 913 : loss : 0.036683, loss_ce: 0.017147
2021-12-10 11:12:07,186 iteration 914 : loss : 0.033631, loss_ce: 0.013495
2021-12-10 11:12:09,984 iteration 915 : loss : 0.037685, loss_ce: 0.015938
2021-12-10 11:12:12,587 iteration 916 : loss : 0.026774, loss_ce: 0.010217
2021-12-10 11:12:15,248 iteration 917 : loss : 0.032935, loss_ce: 0.010587
2021-12-10 11:12:17,869 iteration 918 : loss : 0.034279, loss_ce: 0.013123
 14%|████                          | 54/400 [45:40<4:31:28, 47.08s/it]2021-12-10 11:12:20,562 iteration 919 : loss : 0.025781, loss_ce: 0.010310
2021-12-10 11:12:23,163 iteration 920 : loss : 0.025766, loss_ce: 0.011022
2021-12-10 11:12:25,899 iteration 921 : loss : 0.023109, loss_ce: 0.009439
2021-12-10 11:12:28,549 iteration 922 : loss : 0.034037, loss_ce: 0.009861
2021-12-10 11:12:31,218 iteration 923 : loss : 0.031872, loss_ce: 0.013062
2021-12-10 11:12:33,884 iteration 924 : loss : 0.028455, loss_ce: 0.010630
2021-12-10 11:12:36,506 iteration 925 : loss : 0.044512, loss_ce: 0.016941
2021-12-10 11:12:39,145 iteration 926 : loss : 0.031311, loss_ce: 0.014042
2021-12-10 11:12:41,764 iteration 927 : loss : 0.029344, loss_ce: 0.012287
2021-12-10 11:12:44,420 iteration 928 : loss : 0.036350, loss_ce: 0.013753
2021-12-10 11:12:47,036 iteration 929 : loss : 0.026497, loss_ce: 0.009831
2021-12-10 11:12:49,809 iteration 930 : loss : 0.027418, loss_ce: 0.010451
2021-12-10 11:12:52,413 iteration 931 : loss : 0.032645, loss_ce: 0.010245
2021-12-10 11:12:55,106 iteration 932 : loss : 0.039599, loss_ce: 0.012787
2021-12-10 11:12:57,824 iteration 933 : loss : 0.027791, loss_ce: 0.011185
2021-12-10 11:13:00,420 iteration 934 : loss : 0.037167, loss_ce: 0.016581
2021-12-10 11:13:00,420 Training Data Eval:
2021-12-10 11:13:15,121   Average segmentation loss on training set: 0.0417
2021-12-10 11:13:15,121 Validation Data Eval:
2021-12-10 11:13:20,379   Average segmentation loss on validation set: 0.1522
2021-12-10 11:13:22,999 iteration 935 : loss : 0.049563, loss_ce: 0.019290
 14%|████▏                         | 55/400 [46:45<5:01:49, 52.49s/it]2021-12-10 11:13:25,688 iteration 936 : loss : 0.040429, loss_ce: 0.015394
2021-12-10 11:13:28,413 iteration 937 : loss : 0.032803, loss_ce: 0.015709
2021-12-10 11:13:31,014 iteration 938 : loss : 0.039863, loss_ce: 0.012013
2021-12-10 11:13:33,795 iteration 939 : loss : 0.025216, loss_ce: 0.011144
2021-12-10 11:13:36,429 iteration 940 : loss : 0.034992, loss_ce: 0.011592
2021-12-10 11:13:39,195 iteration 941 : loss : 0.031126, loss_ce: 0.012906
2021-12-10 11:13:41,831 iteration 942 : loss : 0.022706, loss_ce: 0.010853
2021-12-10 11:13:44,614 iteration 943 : loss : 0.027888, loss_ce: 0.011743
2021-12-10 11:13:47,291 iteration 944 : loss : 0.029634, loss_ce: 0.013359
2021-12-10 11:13:50,039 iteration 945 : loss : 0.031343, loss_ce: 0.010453
2021-12-10 11:13:52,713 iteration 946 : loss : 0.029595, loss_ce: 0.011679
2021-12-10 11:13:55,489 iteration 947 : loss : 0.038864, loss_ce: 0.014827
2021-12-10 11:13:58,127 iteration 948 : loss : 0.028382, loss_ce: 0.012859
2021-12-10 11:14:00,878 iteration 949 : loss : 0.041944, loss_ce: 0.010826
2021-12-10 11:14:03,485 iteration 950 : loss : 0.037135, loss_ce: 0.013158
2021-12-10 11:14:06,111 iteration 951 : loss : 0.031023, loss_ce: 0.010231
2021-12-10 11:14:08,885 iteration 952 : loss : 0.031769, loss_ce: 0.012076
 14%|████▏                         | 56/400 [47:31<4:49:34, 50.51s/it]2021-12-10 11:14:11,648 iteration 953 : loss : 0.037320, loss_ce: 0.019210
2021-12-10 11:14:14,360 iteration 954 : loss : 0.030463, loss_ce: 0.009754
2021-12-10 11:14:17,110 iteration 955 : loss : 0.032224, loss_ce: 0.012672
2021-12-10 11:14:19,888 iteration 956 : loss : 0.028003, loss_ce: 0.009643
2021-12-10 11:14:22,625 iteration 957 : loss : 0.037683, loss_ce: 0.013159
2021-12-10 11:14:25,410 iteration 958 : loss : 0.027535, loss_ce: 0.010075
2021-12-10 11:14:28,047 iteration 959 : loss : 0.029271, loss_ce: 0.011174
2021-12-10 11:14:30,802 iteration 960 : loss : 0.037139, loss_ce: 0.014559
2021-12-10 11:14:33,524 iteration 961 : loss : 0.029809, loss_ce: 0.013026
2021-12-10 11:14:36,269 iteration 962 : loss : 0.062728, loss_ce: 0.020090
2021-12-10 11:14:39,010 iteration 963 : loss : 0.042635, loss_ce: 0.012162
2021-12-10 11:14:41,730 iteration 964 : loss : 0.033352, loss_ce: 0.013262
2021-12-10 11:14:44,482 iteration 965 : loss : 0.044278, loss_ce: 0.016181
2021-12-10 11:14:47,273 iteration 966 : loss : 0.027872, loss_ce: 0.010522
2021-12-10 11:14:49,912 iteration 967 : loss : 0.042982, loss_ce: 0.017916
2021-12-10 11:14:52,674 iteration 968 : loss : 0.051655, loss_ce: 0.023281
2021-12-10 11:14:55,398 iteration 969 : loss : 0.040855, loss_ce: 0.009877
 14%|████▎                         | 57/400 [48:18<4:41:52, 49.31s/it]2021-12-10 11:14:58,153 iteration 970 : loss : 0.034080, loss_ce: 0.012917
2021-12-10 11:15:00,911 iteration 971 : loss : 0.035261, loss_ce: 0.015138
2021-12-10 11:15:03,658 iteration 972 : loss : 0.033007, loss_ce: 0.013195
2021-12-10 11:15:06,417 iteration 973 : loss : 0.041005, loss_ce: 0.011612
2021-12-10 11:15:09,136 iteration 974 : loss : 0.038789, loss_ce: 0.011913
2021-12-10 11:15:11,862 iteration 975 : loss : 0.032531, loss_ce: 0.011047
2021-12-10 11:15:14,615 iteration 976 : loss : 0.026485, loss_ce: 0.010598
2021-12-10 11:15:17,483 iteration 977 : loss : 0.026445, loss_ce: 0.011214
2021-12-10 11:15:20,268 iteration 978 : loss : 0.033514, loss_ce: 0.012562
2021-12-10 11:15:23,021 iteration 979 : loss : 0.036024, loss_ce: 0.013454
2021-12-10 11:15:25,776 iteration 980 : loss : 0.036362, loss_ce: 0.010279
2021-12-10 11:15:28,521 iteration 981 : loss : 0.038594, loss_ce: 0.012801
2021-12-10 11:15:31,249 iteration 982 : loss : 0.028917, loss_ce: 0.010839
2021-12-10 11:15:33,975 iteration 983 : loss : 0.045529, loss_ce: 0.018465
2021-12-10 11:15:36,845 iteration 984 : loss : 0.028470, loss_ce: 0.011360
2021-12-10 11:15:39,583 iteration 985 : loss : 0.035036, loss_ce: 0.016299
2021-12-10 11:15:42,453 iteration 986 : loss : 0.031858, loss_ce: 0.014449
 14%|████▎                         | 58/400 [49:05<4:37:12, 48.63s/it]2021-12-10 11:15:45,284 iteration 987 : loss : 0.035898, loss_ce: 0.011745
2021-12-10 11:15:48,015 iteration 988 : loss : 0.031840, loss_ce: 0.012896
2021-12-10 11:15:50,861 iteration 989 : loss : 0.045347, loss_ce: 0.015019
2021-12-10 11:15:53,588 iteration 990 : loss : 0.038299, loss_ce: 0.012431
2021-12-10 11:15:56,446 iteration 991 : loss : 0.022473, loss_ce: 0.009080
2021-12-10 11:15:59,198 iteration 992 : loss : 0.030478, loss_ce: 0.012558
2021-12-10 11:16:02,086 iteration 993 : loss : 0.023165, loss_ce: 0.007974
2021-12-10 11:16:04,811 iteration 994 : loss : 0.024498, loss_ce: 0.011120
2021-12-10 11:16:07,538 iteration 995 : loss : 0.032937, loss_ce: 0.010765
2021-12-10 11:16:10,412 iteration 996 : loss : 0.026805, loss_ce: 0.010743
2021-12-10 11:16:13,151 iteration 997 : loss : 0.028427, loss_ce: 0.009267
2021-12-10 11:16:16,026 iteration 998 : loss : 0.028904, loss_ce: 0.010484
2021-12-10 11:16:18,756 iteration 999 : loss : 0.027276, loss_ce: 0.010577
2021-12-10 11:16:21,642 iteration 1000 : loss : 0.030143, loss_ce: 0.011959
2021-12-10 11:16:24,390 iteration 1001 : loss : 0.031546, loss_ce: 0.013923
2021-12-10 11:16:27,252 iteration 1002 : loss : 0.025951, loss_ce: 0.012255
2021-12-10 11:16:30,121 iteration 1003 : loss : 0.031503, loss_ce: 0.011396
 15%|████▍                         | 59/400 [49:52<4:34:44, 48.34s/it]2021-12-10 11:16:32,895 iteration 1004 : loss : 0.046484, loss_ce: 0.012452
2021-12-10 11:16:35,784 iteration 1005 : loss : 0.028528, loss_ce: 0.010303
2021-12-10 11:16:38,509 iteration 1006 : loss : 0.023608, loss_ce: 0.008413
2021-12-10 11:16:41,386 iteration 1007 : loss : 0.026641, loss_ce: 0.009788
2021-12-10 11:16:44,218 iteration 1008 : loss : 0.026669, loss_ce: 0.011276
2021-12-10 11:16:47,084 iteration 1009 : loss : 0.025628, loss_ce: 0.009123
2021-12-10 11:16:49,815 iteration 1010 : loss : 0.027529, loss_ce: 0.010401
2021-12-10 11:16:52,667 iteration 1011 : loss : 0.029492, loss_ce: 0.009454
2021-12-10 11:16:55,525 iteration 1012 : loss : 0.028570, loss_ce: 0.010485
2021-12-10 11:16:58,388 iteration 1013 : loss : 0.032999, loss_ce: 0.012867
2021-12-10 11:17:01,362 iteration 1014 : loss : 0.028734, loss_ce: 0.010137
2021-12-10 11:17:04,117 iteration 1015 : loss : 0.025595, loss_ce: 0.010311
2021-12-10 11:17:06,957 iteration 1016 : loss : 0.033831, loss_ce: 0.011130
2021-12-10 11:17:09,792 iteration 1017 : loss : 0.029376, loss_ce: 0.013279
2021-12-10 11:17:12,647 iteration 1018 : loss : 0.026215, loss_ce: 0.010687
2021-12-10 11:17:15,373 iteration 1019 : loss : 0.024374, loss_ce: 0.012756
2021-12-10 11:17:15,373 Training Data Eval:
2021-12-10 11:17:31,157   Average segmentation loss on training set: 0.0278
2021-12-10 11:17:31,157 Validation Data Eval:
2021-12-10 11:17:36,725   Average segmentation loss on validation set: 0.1081
2021-12-10 11:17:39,578 iteration 1020 : loss : 0.027821, loss_ce: 0.009505
 15%|████▌                         | 60/400 [51:02<5:09:50, 54.68s/it]2021-12-10 11:17:42,523 iteration 1021 : loss : 0.038764, loss_ce: 0.012847
2021-12-10 11:17:45,243 iteration 1022 : loss : 0.021352, loss_ce: 0.010889
2021-12-10 11:17:48,209 iteration 1023 : loss : 0.024388, loss_ce: 0.010038
2021-12-10 11:17:50,942 iteration 1024 : loss : 0.030075, loss_ce: 0.011253
2021-12-10 11:17:53,781 iteration 1025 : loss : 0.024561, loss_ce: 0.009727
2021-12-10 11:17:56,669 iteration 1026 : loss : 0.029326, loss_ce: 0.009480
2021-12-10 11:17:59,398 iteration 1027 : loss : 0.020028, loss_ce: 0.007733
2021-12-10 11:18:02,237 iteration 1028 : loss : 0.038718, loss_ce: 0.020224
2021-12-10 11:18:05,108 iteration 1029 : loss : 0.025399, loss_ce: 0.010710
2021-12-10 11:18:07,749 iteration 1030 : loss : 0.027414, loss_ce: 0.012925
2021-12-10 11:18:10,495 iteration 1031 : loss : 0.037390, loss_ce: 0.014155
2021-12-10 11:18:13,223 iteration 1032 : loss : 0.036917, loss_ce: 0.017776
2021-12-10 11:18:16,086 iteration 1033 : loss : 0.029315, loss_ce: 0.012118
2021-12-10 11:18:18,846 iteration 1034 : loss : 0.029341, loss_ce: 0.008708
2021-12-10 11:18:21,773 iteration 1035 : loss : 0.046275, loss_ce: 0.012805
2021-12-10 11:18:24,505 iteration 1036 : loss : 0.028372, loss_ce: 0.010982
2021-12-10 11:18:27,393 iteration 1037 : loss : 0.027193, loss_ce: 0.010765
 15%|████▌                         | 61/400 [51:50<4:57:18, 52.62s/it]2021-12-10 11:18:30,192 iteration 1038 : loss : 0.025895, loss_ce: 0.010827
2021-12-10 11:18:33,048 iteration 1039 : loss : 0.030217, loss_ce: 0.014233
2021-12-10 11:18:35,900 iteration 1040 : loss : 0.071764, loss_ce: 0.009374
2021-12-10 11:18:38,758 iteration 1041 : loss : 0.038368, loss_ce: 0.016591
2021-12-10 11:18:41,618 iteration 1042 : loss : 0.097596, loss_ce: 0.029407
2021-12-10 11:18:44,479 iteration 1043 : loss : 0.036174, loss_ce: 0.010817
2021-12-10 11:18:47,322 iteration 1044 : loss : 0.045430, loss_ce: 0.021390
2021-12-10 11:18:50,208 iteration 1045 : loss : 0.050135, loss_ce: 0.024782
2021-12-10 11:18:53,176 iteration 1046 : loss : 0.028874, loss_ce: 0.011316
2021-12-10 11:18:56,098 iteration 1047 : loss : 0.030267, loss_ce: 0.012830
2021-12-10 11:18:59,040 iteration 1048 : loss : 0.035189, loss_ce: 0.012947
2021-12-10 11:19:02,000 iteration 1049 : loss : 0.046880, loss_ce: 0.016111
2021-12-10 11:19:04,782 iteration 1050 : loss : 0.045949, loss_ce: 0.018618
2021-12-10 11:19:07,792 iteration 1051 : loss : 0.045205, loss_ce: 0.021573
2021-12-10 11:19:10,694 iteration 1052 : loss : 0.054784, loss_ce: 0.024522
2021-12-10 11:19:13,562 iteration 1053 : loss : 0.042286, loss_ce: 0.013729
2021-12-10 11:19:16,565 iteration 1054 : loss : 0.054299, loss_ce: 0.023269
 16%|████▋                         | 62/400 [52:39<4:50:35, 51.58s/it]2021-12-10 11:19:19,612 iteration 1055 : loss : 0.048739, loss_ce: 0.014089
2021-12-10 11:19:22,361 iteration 1056 : loss : 0.027571, loss_ce: 0.013502
2021-12-10 11:19:25,227 iteration 1057 : loss : 0.035465, loss_ce: 0.014692
2021-12-10 11:19:28,062 iteration 1058 : loss : 0.035949, loss_ce: 0.014424
2021-12-10 11:19:30,912 iteration 1059 : loss : 0.051376, loss_ce: 0.017563
2021-12-10 11:19:33,782 iteration 1060 : loss : 0.036110, loss_ce: 0.014496
2021-12-10 11:19:36,530 iteration 1061 : loss : 0.034591, loss_ce: 0.016273
2021-12-10 11:19:39,304 iteration 1062 : loss : 0.031875, loss_ce: 0.015791
2021-12-10 11:19:42,045 iteration 1063 : loss : 0.045705, loss_ce: 0.021005
2021-12-10 11:19:44,801 iteration 1064 : loss : 0.043336, loss_ce: 0.015086
2021-12-10 11:19:47,704 iteration 1065 : loss : 0.058064, loss_ce: 0.016374
2021-12-10 11:19:50,448 iteration 1066 : loss : 0.036190, loss_ce: 0.012168
2021-12-10 11:19:53,305 iteration 1067 : loss : 0.077500, loss_ce: 0.021922
2021-12-10 11:19:56,163 iteration 1068 : loss : 0.042659, loss_ce: 0.017526
2021-12-10 11:19:59,025 iteration 1069 : loss : 0.055539, loss_ce: 0.019758
2021-12-10 11:20:01,867 iteration 1070 : loss : 0.040997, loss_ce: 0.013485
2021-12-10 11:20:04,709 iteration 1071 : loss : 0.053996, loss_ce: 0.018246
 16%|████▋                         | 63/400 [53:27<4:43:55, 50.55s/it]2021-12-10 11:20:07,593 iteration 1072 : loss : 0.048286, loss_ce: 0.017650
2021-12-10 11:20:10,620 iteration 1073 : loss : 0.050174, loss_ce: 0.011252
2021-12-10 11:20:13,513 iteration 1074 : loss : 0.042053, loss_ce: 0.018016
2021-12-10 11:20:16,427 iteration 1075 : loss : 0.054296, loss_ce: 0.022336
2021-12-10 11:20:19,268 iteration 1076 : loss : 0.039030, loss_ce: 0.018784
2021-12-10 11:20:22,288 iteration 1077 : loss : 0.107076, loss_ce: 0.029925
2021-12-10 11:20:25,132 iteration 1078 : loss : 0.031233, loss_ce: 0.012423
2021-12-10 11:20:28,017 iteration 1079 : loss : 0.041114, loss_ce: 0.020267
2021-12-10 11:20:30,918 iteration 1080 : loss : 0.042576, loss_ce: 0.018469
2021-12-10 11:20:33,851 iteration 1081 : loss : 0.037597, loss_ce: 0.013298
2021-12-10 11:20:36,756 iteration 1082 : loss : 0.040310, loss_ce: 0.021334
2021-12-10 11:20:39,626 iteration 1083 : loss : 0.040152, loss_ce: 0.012460
2021-12-10 11:20:42,536 iteration 1084 : loss : 0.039420, loss_ce: 0.016532
2021-12-10 11:20:45,262 iteration 1085 : loss : 0.040148, loss_ce: 0.012454
2021-12-10 11:20:48,287 iteration 1086 : loss : 0.038080, loss_ce: 0.015496
2021-12-10 11:20:51,126 iteration 1087 : loss : 0.034188, loss_ce: 0.014007
2021-12-10 11:20:54,021 iteration 1088 : loss : 0.050989, loss_ce: 0.024616
 16%|████▊                         | 64/400 [54:16<4:41:01, 50.18s/it]2021-12-10 11:20:57,012 iteration 1089 : loss : 0.039271, loss_ce: 0.016543
2021-12-10 11:20:59,745 iteration 1090 : loss : 0.033021, loss_ce: 0.014395
2021-12-10 11:21:02,632 iteration 1091 : loss : 0.048472, loss_ce: 0.013169
2021-12-10 11:21:05,539 iteration 1092 : loss : 0.047837, loss_ce: 0.013566
2021-12-10 11:21:08,472 iteration 1093 : loss : 0.030033, loss_ce: 0.013968
2021-12-10 11:21:11,390 iteration 1094 : loss : 0.034183, loss_ce: 0.017922
2021-12-10 11:21:14,287 iteration 1095 : loss : 0.029715, loss_ce: 0.011726
2021-12-10 11:21:17,172 iteration 1096 : loss : 0.037185, loss_ce: 0.011708
2021-12-10 11:21:19,945 iteration 1097 : loss : 0.044686, loss_ce: 0.010871
2021-12-10 11:21:22,783 iteration 1098 : loss : 0.040116, loss_ce: 0.012894
2021-12-10 11:21:25,805 iteration 1099 : loss : 0.036635, loss_ce: 0.012361
2021-12-10 11:21:28,750 iteration 1100 : loss : 0.026711, loss_ce: 0.009770
2021-12-10 11:21:31,485 iteration 1101 : loss : 0.037423, loss_ce: 0.016217
2021-12-10 11:21:34,267 iteration 1102 : loss : 0.052962, loss_ce: 0.022436
2021-12-10 11:21:36,997 iteration 1103 : loss : 0.037277, loss_ce: 0.014692
2021-12-10 11:21:39,745 iteration 1104 : loss : 0.040522, loss_ce: 0.012509
2021-12-10 11:21:39,745 Training Data Eval:
2021-12-10 11:21:55,333   Average segmentation loss on training set: 0.0417
2021-12-10 11:21:55,333 Validation Data Eval:
2021-12-10 11:22:00,813   Average segmentation loss on validation set: 0.1235
2021-12-10 11:22:03,768 iteration 1105 : loss : 0.036487, loss_ce: 0.014483
 16%|████▉                         | 65/400 [55:26<5:12:58, 56.05s/it]2021-12-10 11:22:06,609 iteration 1106 : loss : 0.028230, loss_ce: 0.012861
2021-12-10 11:22:09,476 iteration 1107 : loss : 0.036738, loss_ce: 0.015402
2021-12-10 11:22:12,345 iteration 1108 : loss : 0.036394, loss_ce: 0.011861
2021-12-10 11:22:15,214 iteration 1109 : loss : 0.047911, loss_ce: 0.015770
2021-12-10 11:22:18,050 iteration 1110 : loss : 0.044948, loss_ce: 0.009262
2021-12-10 11:22:20,894 iteration 1111 : loss : 0.028424, loss_ce: 0.011417
2021-12-10 11:22:23,770 iteration 1112 : loss : 0.031964, loss_ce: 0.015762
2021-12-10 11:22:26,527 iteration 1113 : loss : 0.036723, loss_ce: 0.015857
2021-12-10 11:22:29,254 iteration 1114 : loss : 0.029302, loss_ce: 0.011303
2021-12-10 11:22:31,980 iteration 1115 : loss : 0.035143, loss_ce: 0.021884
2021-12-10 11:22:34,855 iteration 1116 : loss : 0.031179, loss_ce: 0.011965
2021-12-10 11:22:37,728 iteration 1117 : loss : 0.038843, loss_ce: 0.009891
2021-12-10 11:22:40,566 iteration 1118 : loss : 0.037879, loss_ce: 0.013378
2021-12-10 11:22:43,395 iteration 1119 : loss : 0.028676, loss_ce: 0.011427
2021-12-10 11:22:46,418 iteration 1120 : loss : 0.039534, loss_ce: 0.018680
2021-12-10 11:22:49,275 iteration 1121 : loss : 0.036115, loss_ce: 0.011595
2021-12-10 11:22:52,133 iteration 1122 : loss : 0.029547, loss_ce: 0.011102
 16%|████▉                         | 66/400 [56:14<4:59:11, 53.75s/it]2021-12-10 11:22:55,130 iteration 1123 : loss : 0.034502, loss_ce: 0.013272
2021-12-10 11:22:58,051 iteration 1124 : loss : 0.029689, loss_ce: 0.010987
2021-12-10 11:23:00,783 iteration 1125 : loss : 0.034666, loss_ce: 0.013576
2021-12-10 11:23:03,779 iteration 1126 : loss : 0.028819, loss_ce: 0.013330
2021-12-10 11:23:06,592 iteration 1127 : loss : 0.038965, loss_ce: 0.010905
2021-12-10 11:23:09,432 iteration 1128 : loss : 0.028975, loss_ce: 0.011683
2021-12-10 11:23:12,273 iteration 1129 : loss : 0.025957, loss_ce: 0.010938
2021-12-10 11:23:15,001 iteration 1130 : loss : 0.029026, loss_ce: 0.011797
2021-12-10 11:23:17,874 iteration 1131 : loss : 0.031077, loss_ce: 0.014063
2021-12-10 11:23:20,748 iteration 1132 : loss : 0.030092, loss_ce: 0.012941
2021-12-10 11:23:23,615 iteration 1133 : loss : 0.029682, loss_ce: 0.013928
2021-12-10 11:23:26,453 iteration 1134 : loss : 0.030905, loss_ce: 0.012419
2021-12-10 11:23:29,292 iteration 1135 : loss : 0.031481, loss_ce: 0.009308
2021-12-10 11:23:32,120 iteration 1136 : loss : 0.027218, loss_ce: 0.007943
2021-12-10 11:23:35,007 iteration 1137 : loss : 0.023408, loss_ce: 0.006049
2021-12-10 11:23:37,781 iteration 1138 : loss : 0.032412, loss_ce: 0.016219
2021-12-10 11:23:40,637 iteration 1139 : loss : 0.026564, loss_ce: 0.012298
 17%|█████                         | 67/400 [57:03<4:49:33, 52.17s/it]2021-12-10 11:23:43,590 iteration 1140 : loss : 0.028024, loss_ce: 0.009458
2021-12-10 11:23:46,524 iteration 1141 : loss : 0.021605, loss_ce: 0.008786
2021-12-10 11:23:49,456 iteration 1142 : loss : 0.027339, loss_ce: 0.010404
2021-12-10 11:23:52,186 iteration 1143 : loss : 0.027992, loss_ce: 0.009639
2021-12-10 11:23:55,076 iteration 1144 : loss : 0.030434, loss_ce: 0.010564
2021-12-10 11:23:57,850 iteration 1145 : loss : 0.025768, loss_ce: 0.011739
2021-12-10 11:24:00,720 iteration 1146 : loss : 0.028690, loss_ce: 0.013091
2021-12-10 11:24:03,570 iteration 1147 : loss : 0.037627, loss_ce: 0.019002
2021-12-10 11:24:06,455 iteration 1148 : loss : 0.024960, loss_ce: 0.007585
2021-12-10 11:24:09,190 iteration 1149 : loss : 0.023916, loss_ce: 0.008759
2021-12-10 11:24:12,119 iteration 1150 : loss : 0.029447, loss_ce: 0.010152
2021-12-10 11:24:14,854 iteration 1151 : loss : 0.025342, loss_ce: 0.008748
2021-12-10 11:24:17,705 iteration 1152 : loss : 0.029691, loss_ce: 0.010043
2021-12-10 11:24:20,565 iteration 1153 : loss : 0.025771, loss_ce: 0.008676
2021-12-10 11:24:23,426 iteration 1154 : loss : 0.028500, loss_ce: 0.010232
2021-12-10 11:24:26,294 iteration 1155 : loss : 0.027059, loss_ce: 0.010995
2021-12-10 11:24:29,128 iteration 1156 : loss : 0.022564, loss_ce: 0.008621
 17%|█████                         | 68/400 [57:51<4:42:34, 51.07s/it]2021-12-10 11:24:32,207 iteration 1157 : loss : 0.026379, loss_ce: 0.009543
2021-12-10 11:24:35,013 iteration 1158 : loss : 0.022198, loss_ce: 0.007325
2021-12-10 11:24:38,036 iteration 1159 : loss : 0.024217, loss_ce: 0.010384
2021-12-10 11:24:40,893 iteration 1160 : loss : 0.028516, loss_ce: 0.012186
2021-12-10 11:24:43,903 iteration 1161 : loss : 0.020169, loss_ce: 0.008458
2021-12-10 11:24:46,783 iteration 1162 : loss : 0.026416, loss_ce: 0.011345
2021-12-10 11:24:49,774 iteration 1163 : loss : 0.026378, loss_ce: 0.010246
2021-12-10 11:24:52,691 iteration 1164 : loss : 0.027145, loss_ce: 0.009661
2021-12-10 11:24:55,566 iteration 1165 : loss : 0.027981, loss_ce: 0.011915
2021-12-10 11:24:58,400 iteration 1166 : loss : 0.028459, loss_ce: 0.009067
2021-12-10 11:25:01,422 iteration 1167 : loss : 0.022348, loss_ce: 0.007856
2021-12-10 11:25:04,259 iteration 1168 : loss : 0.032870, loss_ce: 0.017574
2021-12-10 11:25:07,150 iteration 1169 : loss : 0.024325, loss_ce: 0.010238
2021-12-10 11:25:10,049 iteration 1170 : loss : 0.028024, loss_ce: 0.009404
2021-12-10 11:25:12,968 iteration 1171 : loss : 0.022814, loss_ce: 0.007859
2021-12-10 11:25:15,888 iteration 1172 : loss : 0.017096, loss_ce: 0.006643
2021-12-10 11:25:18,619 iteration 1173 : loss : 0.025583, loss_ce: 0.007811
 17%|█████▏                        | 69/400 [58:41<4:39:06, 50.59s/it]2021-12-10 11:25:21,521 iteration 1174 : loss : 0.026748, loss_ce: 0.010321
2021-12-10 11:25:24,354 iteration 1175 : loss : 0.023110, loss_ce: 0.009897
2021-12-10 11:25:27,365 iteration 1176 : loss : 0.024605, loss_ce: 0.013526
2021-12-10 11:25:30,232 iteration 1177 : loss : 0.029157, loss_ce: 0.011224
2021-12-10 11:25:33,081 iteration 1178 : loss : 0.032501, loss_ce: 0.010707
2021-12-10 11:25:35,942 iteration 1179 : loss : 0.022936, loss_ce: 0.009731
2021-12-10 11:25:38,799 iteration 1180 : loss : 0.035041, loss_ce: 0.012120
2021-12-10 11:25:41,686 iteration 1181 : loss : 0.022357, loss_ce: 0.007921
2021-12-10 11:25:44,421 iteration 1182 : loss : 0.028612, loss_ce: 0.011857
2021-12-10 11:25:47,147 iteration 1183 : loss : 0.022901, loss_ce: 0.007215
2021-12-10 11:25:49,893 iteration 1184 : loss : 0.031166, loss_ce: 0.012949
2021-12-10 11:25:52,811 iteration 1185 : loss : 0.022124, loss_ce: 0.006367
2021-12-10 11:25:55,539 iteration 1186 : loss : 0.028641, loss_ce: 0.013227
2021-12-10 11:25:58,367 iteration 1187 : loss : 0.028122, loss_ce: 0.010207
2021-12-10 11:26:01,201 iteration 1188 : loss : 0.019947, loss_ce: 0.007785
2021-12-10 11:26:04,096 iteration 1189 : loss : 0.026815, loss_ce: 0.009976
2021-12-10 11:26:04,096 Training Data Eval:
2021-12-10 11:26:19,791   Average segmentation loss on training set: 0.0260
2021-12-10 11:26:19,792 Validation Data Eval:
2021-12-10 11:26:25,164   Average segmentation loss on validation set: 0.0872
2021-12-10 11:26:31,043 Found new lowest validation loss at iteration 1189! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/NEW_TU/NEW_TU_ADAM_best_val_loss_seed1234_no_da.pth
2021-12-10 11:26:32,828 iteration 1190 : loss : 0.029085, loss_ce: 0.011184
 18%|█████▎                        | 70/400 [59:55<5:17:14, 57.68s/it]2021-12-10 11:26:35,420 iteration 1191 : loss : 0.028426, loss_ce: 0.011881
2021-12-10 11:26:38,083 iteration 1192 : loss : 0.021271, loss_ce: 0.008588
2021-12-10 11:26:40,715 iteration 1193 : loss : 0.021147, loss_ce: 0.009182
2021-12-10 11:26:43,331 iteration 1194 : loss : 0.025248, loss_ce: 0.012139
2021-12-10 11:26:46,088 iteration 1195 : loss : 0.019012, loss_ce: 0.007249
2021-12-10 11:26:48,860 iteration 1196 : loss : 0.032343, loss_ce: 0.010203
2021-12-10 11:26:51,592 iteration 1197 : loss : 0.027756, loss_ce: 0.007955
2021-12-10 11:26:54,316 iteration 1198 : loss : 0.025933, loss_ce: 0.008398
2021-12-10 11:26:57,070 iteration 1199 : loss : 0.026103, loss_ce: 0.010853
2021-12-10 11:26:59,934 iteration 1200 : loss : 0.024650, loss_ce: 0.010255
2021-12-10 11:27:02,791 iteration 1201 : loss : 0.024177, loss_ce: 0.008682
2021-12-10 11:27:05,644 iteration 1202 : loss : 0.026689, loss_ce: 0.006846
2021-12-10 11:27:08,501 iteration 1203 : loss : 0.025871, loss_ce: 0.008939
2021-12-10 11:27:11,364 iteration 1204 : loss : 0.024559, loss_ce: 0.010955
2021-12-10 11:27:14,201 iteration 1205 : loss : 0.029983, loss_ce: 0.009307
2021-12-10 11:27:17,040 iteration 1206 : loss : 0.018049, loss_ce: 0.006818
2021-12-10 11:27:19,877 iteration 1207 : loss : 0.022434, loss_ce: 0.007477
 18%|████▉                       | 71/400 [1:00:42<4:58:47, 54.49s/it]2021-12-10 11:27:22,777 iteration 1208 : loss : 0.022455, loss_ce: 0.008418
2021-12-10 11:27:25,613 iteration 1209 : loss : 0.029264, loss_ce: 0.009720
2021-12-10 11:27:28,517 iteration 1210 : loss : 0.019128, loss_ce: 0.008603
2021-12-10 11:27:31,456 iteration 1211 : loss : 0.024049, loss_ce: 0.007199
2021-12-10 11:27:34,390 iteration 1212 : loss : 0.022399, loss_ce: 0.010122
2021-12-10 11:27:37,119 iteration 1213 : loss : 0.022734, loss_ce: 0.009234
2021-12-10 11:27:39,952 iteration 1214 : loss : 0.020845, loss_ce: 0.008882
2021-12-10 11:27:42,796 iteration 1215 : loss : 0.018486, loss_ce: 0.007839
2021-12-10 11:27:45,638 iteration 1216 : loss : 0.020710, loss_ce: 0.007984
2021-12-10 11:27:48,638 iteration 1217 : loss : 0.024857, loss_ce: 0.009513
2021-12-10 11:27:51,548 iteration 1218 : loss : 0.032945, loss_ce: 0.012202
2021-12-10 11:27:54,419 iteration 1219 : loss : 0.024362, loss_ce: 0.009274
2021-12-10 11:27:57,281 iteration 1220 : loss : 0.020854, loss_ce: 0.005524
2021-12-10 11:28:00,198 iteration 1221 : loss : 0.025606, loss_ce: 0.010152
2021-12-10 11:28:02,919 iteration 1222 : loss : 0.034476, loss_ce: 0.016683
2021-12-10 11:28:05,753 iteration 1223 : loss : 0.026275, loss_ce: 0.009450
2021-12-10 11:28:08,780 iteration 1224 : loss : 0.030076, loss_ce: 0.010612
 18%|█████                       | 72/400 [1:01:31<4:48:43, 52.81s/it]2021-12-10 11:28:11,585 iteration 1225 : loss : 0.021857, loss_ce: 0.009921
2021-12-10 11:28:14,592 iteration 1226 : loss : 0.027702, loss_ce: 0.009559
2021-12-10 11:28:17,511 iteration 1227 : loss : 0.022637, loss_ce: 0.008648
2021-12-10 11:28:20,351 iteration 1228 : loss : 0.027754, loss_ce: 0.007597
2021-12-10 11:28:23,190 iteration 1229 : loss : 0.027122, loss_ce: 0.010068
2021-12-10 11:28:26,216 iteration 1230 : loss : 0.020555, loss_ce: 0.007159
2021-12-10 11:28:29,147 iteration 1231 : loss : 0.024598, loss_ce: 0.008807
2021-12-10 11:28:31,883 iteration 1232 : loss : 0.024250, loss_ce: 0.009298
2021-12-10 11:28:34,736 iteration 1233 : loss : 0.021481, loss_ce: 0.011031
2021-12-10 11:28:37,576 iteration 1234 : loss : 0.022196, loss_ce: 0.008619
2021-12-10 11:28:40,414 iteration 1235 : loss : 0.019897, loss_ce: 0.006331
2021-12-10 11:28:43,433 iteration 1236 : loss : 0.024127, loss_ce: 0.011943
2021-12-10 11:28:46,276 iteration 1237 : loss : 0.021897, loss_ce: 0.007388
2021-12-10 11:28:49,170 iteration 1238 : loss : 0.023780, loss_ce: 0.009195
2021-12-10 11:28:52,102 iteration 1239 : loss : 0.025494, loss_ce: 0.010566
2021-12-10 11:28:55,021 iteration 1240 : loss : 0.023902, loss_ce: 0.007778
2021-12-10 11:28:57,923 iteration 1241 : loss : 0.019433, loss_ce: 0.009014
 18%|█████                       | 73/400 [1:02:20<4:41:50, 51.71s/it]2021-12-10 11:29:00,716 iteration 1242 : loss : 0.020748, loss_ce: 0.006401
2021-12-10 11:29:03,550 iteration 1243 : loss : 0.026394, loss_ce: 0.012490
2021-12-10 11:29:06,378 iteration 1244 : loss : 0.020176, loss_ce: 0.008967
2021-12-10 11:29:09,413 iteration 1245 : loss : 0.020827, loss_ce: 0.009596
2021-12-10 11:29:12,266 iteration 1246 : loss : 0.021421, loss_ce: 0.008966
2021-12-10 11:29:15,164 iteration 1247 : loss : 0.023251, loss_ce: 0.007507
2021-12-10 11:29:18,093 iteration 1248 : loss : 0.023933, loss_ce: 0.009243
2021-12-10 11:29:20,827 iteration 1249 : loss : 0.024630, loss_ce: 0.007813
2021-12-10 11:29:23,691 iteration 1250 : loss : 0.027466, loss_ce: 0.011222
2021-12-10 11:29:26,543 iteration 1251 : loss : 0.021189, loss_ce: 0.007974
2021-12-10 11:29:29,296 iteration 1252 : loss : 0.016489, loss_ce: 0.004412
2021-12-10 11:29:32,083 iteration 1253 : loss : 0.024452, loss_ce: 0.010942
2021-12-10 11:29:34,817 iteration 1254 : loss : 0.023537, loss_ce: 0.011807
2021-12-10 11:29:37,542 iteration 1255 : loss : 0.021217, loss_ce: 0.009562
2021-12-10 11:29:40,488 iteration 1256 : loss : 0.019053, loss_ce: 0.007754
2021-12-10 11:29:43,391 iteration 1257 : loss : 0.026267, loss_ce: 0.008122
2021-12-10 11:29:46,121 iteration 1258 : loss : 0.021581, loss_ce: 0.005991
 18%|█████▏                      | 74/400 [1:03:08<4:35:14, 50.66s/it]2021-12-10 11:29:49,058 iteration 1259 : loss : 0.023588, loss_ce: 0.008320
2021-12-10 11:29:51,897 iteration 1260 : loss : 0.029027, loss_ce: 0.009193
2021-12-10 11:29:54,775 iteration 1261 : loss : 0.022493, loss_ce: 0.006945
2021-12-10 11:29:57,615 iteration 1262 : loss : 0.021566, loss_ce: 0.007430
2021-12-10 11:30:00,446 iteration 1263 : loss : 0.023218, loss_ce: 0.007791
2021-12-10 11:30:03,289 iteration 1264 : loss : 0.027259, loss_ce: 0.011531
2021-12-10 11:30:06,177 iteration 1265 : loss : 0.019569, loss_ce: 0.007090
2021-12-10 11:30:09,085 iteration 1266 : loss : 0.020586, loss_ce: 0.009592
2021-12-10 11:30:12,018 iteration 1267 : loss : 0.023116, loss_ce: 0.007100
2021-12-10 11:30:14,820 iteration 1268 : loss : 0.022151, loss_ce: 0.007967
2021-12-10 11:30:17,661 iteration 1269 : loss : 0.024611, loss_ce: 0.010571
2021-12-10 11:30:20,502 iteration 1270 : loss : 0.021252, loss_ce: 0.008008
2021-12-10 11:30:23,342 iteration 1271 : loss : 0.022997, loss_ce: 0.010626
2021-12-10 11:30:26,340 iteration 1272 : loss : 0.023413, loss_ce: 0.006262
2021-12-10 11:30:29,055 iteration 1273 : loss : 0.027343, loss_ce: 0.009461
2021-12-10 11:30:32,073 iteration 1274 : loss : 0.019364, loss_ce: 0.008678
2021-12-10 11:30:32,074 Training Data Eval:
2021-12-10 11:30:48,089   Average segmentation loss on training set: 0.0237
2021-12-10 11:30:48,089 Validation Data Eval:
2021-12-10 11:30:53,437   Average segmentation loss on validation set: 0.1307
2021-12-10 11:30:56,192 iteration 1275 : loss : 0.019607, loss_ce: 0.007284
 19%|█████▎                      | 75/400 [1:04:19<5:05:56, 56.48s/it]2021-12-10 11:30:59,132 iteration 1276 : loss : 0.021559, loss_ce: 0.008888
2021-12-10 11:31:01,866 iteration 1277 : loss : 0.019524, loss_ce: 0.006588
2021-12-10 11:31:04,748 iteration 1278 : loss : 0.023891, loss_ce: 0.008271
2021-12-10 11:31:07,476 iteration 1279 : loss : 0.023422, loss_ce: 0.010772
2021-12-10 11:31:10,319 iteration 1280 : loss : 0.018969, loss_ce: 0.008064
2021-12-10 11:31:13,161 iteration 1281 : loss : 0.017901, loss_ce: 0.006597
2021-12-10 11:31:15,998 iteration 1282 : loss : 0.023993, loss_ce: 0.006859
2021-12-10 11:31:18,889 iteration 1283 : loss : 0.027043, loss_ce: 0.010564
2021-12-10 11:31:21,816 iteration 1284 : loss : 0.021683, loss_ce: 0.008894
2021-12-10 11:31:24,744 iteration 1285 : loss : 0.020706, loss_ce: 0.008111
2021-12-10 11:31:27,613 iteration 1286 : loss : 0.023030, loss_ce: 0.009265
2021-12-10 11:31:30,480 iteration 1287 : loss : 0.024470, loss_ce: 0.010377
2021-12-10 11:31:33,350 iteration 1288 : loss : 0.023855, loss_ce: 0.008628
2021-12-10 11:31:36,210 iteration 1289 : loss : 0.021536, loss_ce: 0.009152
2021-12-10 11:31:38,954 iteration 1290 : loss : 0.017712, loss_ce: 0.006987
2021-12-10 11:31:41,730 iteration 1291 : loss : 0.019884, loss_ce: 0.004924
2021-12-10 11:31:44,462 iteration 1292 : loss : 0.018564, loss_ce: 0.006347
 19%|█████▎                      | 76/400 [1:05:07<4:51:41, 54.02s/it]2021-12-10 11:31:47,303 iteration 1293 : loss : 0.020702, loss_ce: 0.006176
2021-12-10 11:31:50,198 iteration 1294 : loss : 0.019974, loss_ce: 0.006229
2021-12-10 11:31:52,923 iteration 1295 : loss : 0.022555, loss_ce: 0.007166
2021-12-10 11:31:55,750 iteration 1296 : loss : 0.017699, loss_ce: 0.006478
2021-12-10 11:31:58,778 iteration 1297 : loss : 0.019206, loss_ce: 0.009473
2021-12-10 11:32:01,661 iteration 1298 : loss : 0.025434, loss_ce: 0.012030
2021-12-10 11:32:04,589 iteration 1299 : loss : 0.021143, loss_ce: 0.006449
2021-12-10 11:32:07,326 iteration 1300 : loss : 0.018857, loss_ce: 0.007856
2021-12-10 11:32:10,194 iteration 1301 : loss : 0.020835, loss_ce: 0.009770
2021-12-10 11:32:13,051 iteration 1302 : loss : 0.020569, loss_ce: 0.007070
2021-12-10 11:32:15,932 iteration 1303 : loss : 0.020878, loss_ce: 0.009100
2021-12-10 11:32:18,695 iteration 1304 : loss : 0.018806, loss_ce: 0.007637
2021-12-10 11:32:21,462 iteration 1305 : loss : 0.021863, loss_ce: 0.007915
2021-12-10 11:32:24,194 iteration 1306 : loss : 0.015448, loss_ce: 0.005209
2021-12-10 11:32:27,116 iteration 1307 : loss : 0.018565, loss_ce: 0.008399
2021-12-10 11:32:29,852 iteration 1308 : loss : 0.021967, loss_ce: 0.006799
2021-12-10 11:32:32,691 iteration 1309 : loss : 0.025002, loss_ce: 0.009377
 19%|█████▍                      | 77/400 [1:05:55<4:41:27, 52.28s/it]2021-12-10 11:32:35,661 iteration 1310 : loss : 0.019024, loss_ce: 0.009463
2021-12-10 11:32:38,548 iteration 1311 : loss : 0.016488, loss_ce: 0.006238
2021-12-10 11:32:41,479 iteration 1312 : loss : 0.017549, loss_ce: 0.006040
2021-12-10 11:32:44,402 iteration 1313 : loss : 0.015931, loss_ce: 0.005965
2021-12-10 11:32:47,334 iteration 1314 : loss : 0.019161, loss_ce: 0.007366
2021-12-10 11:32:50,182 iteration 1315 : loss : 0.020484, loss_ce: 0.008195
2021-12-10 11:32:53,078 iteration 1316 : loss : 0.022310, loss_ce: 0.007913
2021-12-10 11:32:55,855 iteration 1317 : loss : 0.021350, loss_ce: 0.006407
2021-12-10 11:32:58,721 iteration 1318 : loss : 0.022741, loss_ce: 0.006689
2021-12-10 11:33:01,581 iteration 1319 : loss : 0.020187, loss_ce: 0.008867
2021-12-10 11:33:04,472 iteration 1320 : loss : 0.018244, loss_ce: 0.007857
2021-12-10 11:33:07,203 iteration 1321 : loss : 0.019587, loss_ce: 0.005359
2021-12-10 11:33:09,923 iteration 1322 : loss : 0.019991, loss_ce: 0.007720
2021-12-10 11:33:12,796 iteration 1323 : loss : 0.017651, loss_ce: 0.005539
2021-12-10 11:33:15,727 iteration 1324 : loss : 0.024164, loss_ce: 0.009030
2021-12-10 11:33:18,451 iteration 1325 : loss : 0.018241, loss_ce: 0.006226
2021-12-10 11:33:21,341 iteration 1326 : loss : 0.019491, loss_ce: 0.008593
 20%|█████▍                      | 78/400 [1:06:44<4:34:44, 51.19s/it]2021-12-10 11:33:24,339 iteration 1327 : loss : 0.019105, loss_ce: 0.008596
2021-12-10 11:33:27,071 iteration 1328 : loss : 0.018868, loss_ce: 0.008985
2021-12-10 11:33:30,088 iteration 1329 : loss : 0.023435, loss_ce: 0.007668
2021-12-10 11:33:33,054 iteration 1330 : loss : 0.018943, loss_ce: 0.007073
2021-12-10 11:33:35,971 iteration 1331 : loss : 0.016470, loss_ce: 0.005831
2021-12-10 11:33:38,853 iteration 1332 : loss : 0.017734, loss_ce: 0.005128
2021-12-10 11:33:41,730 iteration 1333 : loss : 0.020908, loss_ce: 0.010348
2021-12-10 11:33:44,605 iteration 1334 : loss : 0.017418, loss_ce: 0.006863
2021-12-10 11:33:47,483 iteration 1335 : loss : 0.020093, loss_ce: 0.008595
2021-12-10 11:33:50,353 iteration 1336 : loss : 0.019186, loss_ce: 0.005907
2021-12-10 11:33:53,148 iteration 1337 : loss : 0.018301, loss_ce: 0.007570
2021-12-10 11:33:56,087 iteration 1338 : loss : 0.020490, loss_ce: 0.007318
2021-12-10 11:33:59,002 iteration 1339 : loss : 0.019933, loss_ce: 0.008769
2021-12-10 11:34:01,714 iteration 1340 : loss : 0.018968, loss_ce: 0.009346
2021-12-10 11:34:04,431 iteration 1341 : loss : 0.020280, loss_ce: 0.008185
2021-12-10 11:34:07,300 iteration 1342 : loss : 0.026047, loss_ce: 0.007253
2021-12-10 11:34:10,162 iteration 1343 : loss : 0.020694, loss_ce: 0.009292
 20%|█████▌                      | 79/400 [1:07:32<4:30:02, 50.48s/it]2021-12-10 11:34:12,934 iteration 1344 : loss : 0.017726, loss_ce: 0.006702
2021-12-10 11:34:15,827 iteration 1345 : loss : 0.017644, loss_ce: 0.007105
2021-12-10 11:34:18,674 iteration 1346 : loss : 0.018080, loss_ce: 0.007176
2021-12-10 11:34:21,483 iteration 1347 : loss : 0.017992, loss_ce: 0.005926
2021-12-10 11:34:24,335 iteration 1348 : loss : 0.023982, loss_ce: 0.008521
2021-12-10 11:34:27,190 iteration 1349 : loss : 0.022960, loss_ce: 0.006294
2021-12-10 11:34:30,054 iteration 1350 : loss : 0.017189, loss_ce: 0.005866
2021-12-10 11:34:32,888 iteration 1351 : loss : 0.018509, loss_ce: 0.005217
2021-12-10 11:34:35,714 iteration 1352 : loss : 0.019809, loss_ce: 0.007193
2021-12-10 11:34:38,550 iteration 1353 : loss : 0.017806, loss_ce: 0.005649
2021-12-10 11:34:41,395 iteration 1354 : loss : 0.018651, loss_ce: 0.007135
2021-12-10 11:34:44,285 iteration 1355 : loss : 0.019857, loss_ce: 0.009504
2021-12-10 11:34:47,212 iteration 1356 : loss : 0.018676, loss_ce: 0.009240
2021-12-10 11:34:49,940 iteration 1357 : loss : 0.017727, loss_ce: 0.008205
2021-12-10 11:34:52,798 iteration 1358 : loss : 0.020838, loss_ce: 0.006977
2021-12-10 11:34:55,655 iteration 1359 : loss : 0.018771, loss_ce: 0.007771
2021-12-10 11:34:55,655 Training Data Eval:
2021-12-10 11:35:11,329   Average segmentation loss on training set: 0.0176
2021-12-10 11:35:11,329 Validation Data Eval:
2021-12-10 11:35:16,895   Average segmentation loss on validation set: 0.0938
2021-12-10 11:35:19,776 iteration 1360 : loss : 0.016453, loss_ce: 0.007212
 20%|█████▌                      | 80/400 [1:08:42<4:59:49, 56.22s/it]2021-12-10 11:35:22,709 iteration 1361 : loss : 0.020930, loss_ce: 0.006926
2021-12-10 11:35:25,433 iteration 1362 : loss : 0.018859, loss_ce: 0.005998
2021-12-10 11:35:28,366 iteration 1363 : loss : 0.021295, loss_ce: 0.006998
2021-12-10 11:35:31,099 iteration 1364 : loss : 0.016382, loss_ce: 0.005265
2021-12-10 11:35:33,978 iteration 1365 : loss : 0.015702, loss_ce: 0.006474
2021-12-10 11:35:36,706 iteration 1366 : loss : 0.017725, loss_ce: 0.005792
2021-12-10 11:35:39,629 iteration 1367 : loss : 0.027701, loss_ce: 0.015426
2021-12-10 11:35:42,379 iteration 1368 : loss : 0.017504, loss_ce: 0.008309
2021-12-10 11:35:45,107 iteration 1369 : loss : 0.020704, loss_ce: 0.007344
2021-12-10 11:35:47,828 iteration 1370 : loss : 0.019552, loss_ce: 0.008116
2021-12-10 11:35:50,582 iteration 1371 : loss : 0.029171, loss_ce: 0.010474
2021-12-10 11:35:53,302 iteration 1372 : loss : 0.020065, loss_ce: 0.007836
2021-12-10 11:35:56,021 iteration 1373 : loss : 0.018767, loss_ce: 0.007662
2021-12-10 11:35:58,772 iteration 1374 : loss : 0.017956, loss_ce: 0.006943
2021-12-10 11:36:01,626 iteration 1375 : loss : 0.029368, loss_ce: 0.013680
2021-12-10 11:36:04,494 iteration 1376 : loss : 0.034030, loss_ce: 0.016297
2021-12-10 11:36:07,226 iteration 1377 : loss : 0.019150, loss_ce: 0.008224
 20%|█████▋                      | 81/400 [1:09:30<4:44:54, 53.59s/it]2021-12-10 11:36:10,026 iteration 1378 : loss : 0.021846, loss_ce: 0.008636
2021-12-10 11:36:12,755 iteration 1379 : loss : 0.025049, loss_ce: 0.008263
2021-12-10 11:36:15,476 iteration 1380 : loss : 0.022399, loss_ce: 0.009975
2021-12-10 11:36:18,219 iteration 1381 : loss : 0.023862, loss_ce: 0.007984
2021-12-10 11:36:20,948 iteration 1382 : loss : 0.020993, loss_ce: 0.008406
2021-12-10 11:36:23,746 iteration 1383 : loss : 0.022375, loss_ce: 0.009017
2021-12-10 11:36:26,493 iteration 1384 : loss : 0.032035, loss_ce: 0.008801
2021-12-10 11:36:29,270 iteration 1385 : loss : 0.017215, loss_ce: 0.005086
2021-12-10 11:36:32,000 iteration 1386 : loss : 0.021012, loss_ce: 0.006662
2021-12-10 11:36:34,761 iteration 1387 : loss : 0.023658, loss_ce: 0.012093
2021-12-10 11:36:37,480 iteration 1388 : loss : 0.022312, loss_ce: 0.008914
2021-12-10 11:36:40,339 iteration 1389 : loss : 0.019604, loss_ce: 0.004296
2021-12-10 11:36:43,140 iteration 1390 : loss : 0.020003, loss_ce: 0.007147
2021-12-10 11:36:45,901 iteration 1391 : loss : 0.021623, loss_ce: 0.007420
2021-12-10 11:36:48,662 iteration 1392 : loss : 0.018838, loss_ce: 0.007895
2021-12-10 11:36:51,375 iteration 1393 : loss : 0.021626, loss_ce: 0.007433
2021-12-10 11:36:54,126 iteration 1394 : loss : 0.025972, loss_ce: 0.011961
 20%|█████▋                      | 82/400 [1:10:16<4:33:23, 51.58s/it]2021-12-10 11:36:56,822 iteration 1395 : loss : 0.025051, loss_ce: 0.009051
2021-12-10 11:36:59,587 iteration 1396 : loss : 0.016371, loss_ce: 0.006437
2021-12-10 11:37:02,341 iteration 1397 : loss : 0.022099, loss_ce: 0.009823
2021-12-10 11:37:05,109 iteration 1398 : loss : 0.018334, loss_ce: 0.008020
2021-12-10 11:37:07,900 iteration 1399 : loss : 0.026316, loss_ce: 0.011369
2021-12-10 11:37:10,536 iteration 1400 : loss : 0.017297, loss_ce: 0.007520
2021-12-10 11:37:13,307 iteration 1401 : loss : 0.022101, loss_ce: 0.007299
2021-12-10 11:37:16,103 iteration 1402 : loss : 0.018525, loss_ce: 0.007138
2021-12-10 11:37:18,732 iteration 1403 : loss : 0.023708, loss_ce: 0.007589
2021-12-10 11:37:21,498 iteration 1404 : loss : 0.019476, loss_ce: 0.007631
2021-12-10 11:37:24,290 iteration 1405 : loss : 0.019398, loss_ce: 0.007847
2021-12-10 11:37:26,922 iteration 1406 : loss : 0.022134, loss_ce: 0.008999
2021-12-10 11:37:29,573 iteration 1407 : loss : 0.019946, loss_ce: 0.007631
2021-12-10 11:37:32,343 iteration 1408 : loss : 0.021534, loss_ce: 0.006746
2021-12-10 11:37:34,962 iteration 1409 : loss : 0.016689, loss_ce: 0.006491
2021-12-10 11:37:37,713 iteration 1410 : loss : 0.014973, loss_ce: 0.006436
2021-12-10 11:37:40,491 iteration 1411 : loss : 0.019592, loss_ce: 0.006937
 21%|█████▊                      | 83/400 [1:11:03<4:24:14, 50.02s/it]2021-12-10 11:37:43,201 iteration 1412 : loss : 0.029502, loss_ce: 0.009473
2021-12-10 11:37:45,931 iteration 1413 : loss : 0.020485, loss_ce: 0.008340
2021-12-10 11:37:48,600 iteration 1414 : loss : 0.018966, loss_ce: 0.005542
2021-12-10 11:37:51,378 iteration 1415 : loss : 0.018545, loss_ce: 0.007919
2021-12-10 11:37:54,011 iteration 1416 : loss : 0.018728, loss_ce: 0.007030
2021-12-10 11:37:56,774 iteration 1417 : loss : 0.019977, loss_ce: 0.006582
2021-12-10 11:37:59,440 iteration 1418 : loss : 0.018191, loss_ce: 0.007628
2021-12-10 11:38:02,216 iteration 1419 : loss : 0.017506, loss_ce: 0.007098
2021-12-10 11:38:04,846 iteration 1420 : loss : 0.017732, loss_ce: 0.007317
2021-12-10 11:38:07,603 iteration 1421 : loss : 0.018712, loss_ce: 0.007818
2021-12-10 11:38:10,393 iteration 1422 : loss : 0.017216, loss_ce: 0.008583
2021-12-10 11:38:12,991 iteration 1423 : loss : 0.016926, loss_ce: 0.006366
2021-12-10 11:38:15,760 iteration 1424 : loss : 0.017880, loss_ce: 0.006975
2021-12-10 11:38:18,349 iteration 1425 : loss : 0.021543, loss_ce: 0.010814
2021-12-10 11:38:21,172 iteration 1426 : loss : 0.024043, loss_ce: 0.007772
2021-12-10 11:38:23,771 iteration 1427 : loss : 0.052194, loss_ce: 0.012666
2021-12-10 11:38:26,485 iteration 1428 : loss : 0.017268, loss_ce: 0.007919
 21%|█████▉                      | 84/400 [1:11:49<4:17:03, 48.81s/it]2021-12-10 11:38:29,203 iteration 1429 : loss : 0.020006, loss_ce: 0.009217
2021-12-10 11:38:31,824 iteration 1430 : loss : 0.040126, loss_ce: 0.021043
2021-12-10 11:38:34,599 iteration 1431 : loss : 0.032849, loss_ce: 0.010980
2021-12-10 11:38:37,399 iteration 1432 : loss : 0.027327, loss_ce: 0.012677
2021-12-10 11:38:40,003 iteration 1433 : loss : 0.019387, loss_ce: 0.007244
2021-12-10 11:38:42,709 iteration 1434 : loss : 0.020418, loss_ce: 0.007004
2021-12-10 11:38:45,331 iteration 1435 : loss : 0.028096, loss_ce: 0.007428
2021-12-10 11:38:48,082 iteration 1436 : loss : 0.027381, loss_ce: 0.012082
2021-12-10 11:38:50,642 iteration 1437 : loss : 0.018416, loss_ce: 0.006938
2021-12-10 11:38:53,410 iteration 1438 : loss : 0.023174, loss_ce: 0.008407
2021-12-10 11:38:56,007 iteration 1439 : loss : 0.038536, loss_ce: 0.015234
2021-12-10 11:38:58,624 iteration 1440 : loss : 0.020948, loss_ce: 0.007424
2021-12-10 11:39:01,398 iteration 1441 : loss : 0.021103, loss_ce: 0.007719
2021-12-10 11:39:04,025 iteration 1442 : loss : 0.023467, loss_ce: 0.010268
2021-12-10 11:39:06,847 iteration 1443 : loss : 0.038400, loss_ce: 0.012400
2021-12-10 11:39:09,447 iteration 1444 : loss : 0.028501, loss_ce: 0.010323
2021-12-10 11:39:09,447 Training Data Eval:
2021-12-10 11:39:24,223   Average segmentation loss on training set: 0.0298
2021-12-10 11:39:24,224 Validation Data Eval:
2021-12-10 11:39:29,434   Average segmentation loss on validation set: 0.0924
2021-12-10 11:39:32,251 iteration 1445 : loss : 0.031682, loss_ce: 0.008657
 21%|█████▉                      | 85/400 [1:12:55<4:42:57, 53.90s/it]2021-12-10 11:39:34,901 iteration 1446 : loss : 0.022245, loss_ce: 0.007459
2021-12-10 11:39:37,567 iteration 1447 : loss : 0.022756, loss_ce: 0.007172
2021-12-10 11:39:40,191 iteration 1448 : loss : 0.031314, loss_ce: 0.013461
2021-12-10 11:39:42,964 iteration 1449 : loss : 0.019560, loss_ce: 0.007166
2021-12-10 11:39:45,571 iteration 1450 : loss : 0.025691, loss_ce: 0.010150
2021-12-10 11:39:48,268 iteration 1451 : loss : 0.030933, loss_ce: 0.008610
2021-12-10 11:39:50,898 iteration 1452 : loss : 0.023877, loss_ce: 0.008125
2021-12-10 11:39:53,521 iteration 1453 : loss : 0.021914, loss_ce: 0.008293
2021-12-10 11:39:56,124 iteration 1454 : loss : 0.019012, loss_ce: 0.007275
2021-12-10 11:39:58,863 iteration 1455 : loss : 0.023282, loss_ce: 0.012541
2021-12-10 11:40:01,464 iteration 1456 : loss : 0.024979, loss_ce: 0.007068
2021-12-10 11:40:04,260 iteration 1457 : loss : 0.024689, loss_ce: 0.007961
2021-12-10 11:40:06,873 iteration 1458 : loss : 0.031553, loss_ce: 0.013704
2021-12-10 11:40:09,639 iteration 1459 : loss : 0.027354, loss_ce: 0.013634
2021-12-10 11:40:12,231 iteration 1460 : loss : 0.025749, loss_ce: 0.011279
2021-12-10 11:40:14,835 iteration 1461 : loss : 0.030511, loss_ce: 0.011973
2021-12-10 11:40:17,433 iteration 1462 : loss : 0.034238, loss_ce: 0.012828
 22%|██████                      | 86/400 [1:13:40<4:28:22, 51.28s/it]2021-12-10 11:40:20,252 iteration 1463 : loss : 0.032188, loss_ce: 0.011283
2021-12-10 11:40:22,843 iteration 1464 : loss : 0.022209, loss_ce: 0.010045
2021-12-10 11:40:25,494 iteration 1465 : loss : 0.027064, loss_ce: 0.011297
2021-12-10 11:40:28,120 iteration 1466 : loss : 0.023385, loss_ce: 0.007056
2021-12-10 11:40:30,785 iteration 1467 : loss : 0.032390, loss_ce: 0.008833
2021-12-10 11:40:33,563 iteration 1468 : loss : 0.023540, loss_ce: 0.010656
2021-12-10 11:40:36,165 iteration 1469 : loss : 0.036503, loss_ce: 0.021559
2021-12-10 11:40:38,785 iteration 1470 : loss : 0.026050, loss_ce: 0.009301
2021-12-10 11:40:41,474 iteration 1471 : loss : 0.023088, loss_ce: 0.009423
2021-12-10 11:40:44,071 iteration 1472 : loss : 0.017891, loss_ce: 0.007476
2021-12-10 11:40:46,737 iteration 1473 : loss : 0.022793, loss_ce: 0.009607
2021-12-10 11:40:49,394 iteration 1474 : loss : 0.022442, loss_ce: 0.008796
2021-12-10 11:40:52,027 iteration 1475 : loss : 0.018468, loss_ce: 0.008548
2021-12-10 11:40:54,821 iteration 1476 : loss : 0.027289, loss_ce: 0.009905
2021-12-10 11:40:57,427 iteration 1477 : loss : 0.022547, loss_ce: 0.007661
2021-12-10 11:41:00,050 iteration 1478 : loss : 0.022924, loss_ce: 0.007946
2021-12-10 11:41:02,673 iteration 1479 : loss : 0.025524, loss_ce: 0.007958
 22%|██████                      | 87/400 [1:14:25<4:18:03, 49.47s/it]2021-12-10 11:41:05,382 iteration 1480 : loss : 0.023015, loss_ce: 0.008974
2021-12-10 11:41:08,010 iteration 1481 : loss : 0.021733, loss_ce: 0.007720
2021-12-10 11:41:10,644 iteration 1482 : loss : 0.023640, loss_ce: 0.010250
2021-12-10 11:41:13,245 iteration 1483 : loss : 0.018776, loss_ce: 0.007673
2021-12-10 11:41:16,002 iteration 1484 : loss : 0.017991, loss_ce: 0.009633
2021-12-10 11:41:18,599 iteration 1485 : loss : 0.019439, loss_ce: 0.008624
2021-12-10 11:41:21,221 iteration 1486 : loss : 0.022358, loss_ce: 0.010346
2021-12-10 11:41:23,981 iteration 1487 : loss : 0.029516, loss_ce: 0.008959
2021-12-10 11:41:26,577 iteration 1488 : loss : 0.023249, loss_ce: 0.009307
2021-12-10 11:41:29,172 iteration 1489 : loss : 0.028252, loss_ce: 0.008405
2021-12-10 11:41:31,837 iteration 1490 : loss : 0.021819, loss_ce: 0.007281
2021-12-10 11:41:34,499 iteration 1491 : loss : 0.029286, loss_ce: 0.013546
2021-12-10 11:41:37,123 iteration 1492 : loss : 0.029377, loss_ce: 0.011203
2021-12-10 11:41:39,906 iteration 1493 : loss : 0.028963, loss_ce: 0.008397
2021-12-10 11:41:42,503 iteration 1494 : loss : 0.020927, loss_ce: 0.008143
2021-12-10 11:41:45,119 iteration 1495 : loss : 0.021502, loss_ce: 0.007862
2021-12-10 11:41:47,749 iteration 1496 : loss : 0.083453, loss_ce: 0.027062
 22%|██████▏                     | 88/400 [1:15:10<4:10:23, 48.15s/it]2021-12-10 11:41:50,398 iteration 1497 : loss : 0.033532, loss_ce: 0.009985
2021-12-10 11:41:52,997 iteration 1498 : loss : 0.031730, loss_ce: 0.011327
2021-12-10 11:41:55,809 iteration 1499 : loss : 0.048077, loss_ce: 0.028193
2021-12-10 11:41:58,420 iteration 1500 : loss : 0.021707, loss_ce: 0.008927
2021-12-10 11:42:01,016 iteration 1501 : loss : 0.028420, loss_ce: 0.012879
2021-12-10 11:42:03,601 iteration 1502 : loss : 0.055740, loss_ce: 0.021212
2021-12-10 11:42:06,258 iteration 1503 : loss : 0.025897, loss_ce: 0.010153
2021-12-10 11:42:08,913 iteration 1504 : loss : 0.032438, loss_ce: 0.011649
2021-12-10 11:42:11,535 iteration 1505 : loss : 0.030147, loss_ce: 0.009054
2021-12-10 11:42:14,139 iteration 1506 : loss : 0.030167, loss_ce: 0.011407
2021-12-10 11:42:16,774 iteration 1507 : loss : 0.038164, loss_ce: 0.023329
2021-12-10 11:42:19,370 iteration 1508 : loss : 0.028502, loss_ce: 0.009285
2021-12-10 11:42:22,000 iteration 1509 : loss : 0.025169, loss_ce: 0.009484
2021-12-10 11:42:24,764 iteration 1510 : loss : 0.027808, loss_ce: 0.009240
2021-12-10 11:42:27,363 iteration 1511 : loss : 0.025995, loss_ce: 0.011307
2021-12-10 11:42:29,935 iteration 1512 : loss : 0.030862, loss_ce: 0.015838
2021-12-10 11:42:32,554 iteration 1513 : loss : 0.026010, loss_ce: 0.009424
 22%|██████▏                     | 89/400 [1:15:55<4:04:22, 47.15s/it]2021-12-10 11:42:35,297 iteration 1514 : loss : 0.030134, loss_ce: 0.011642
2021-12-10 11:42:37,904 iteration 1515 : loss : 0.023554, loss_ce: 0.011184
2021-12-10 11:42:40,509 iteration 1516 : loss : 0.024669, loss_ce: 0.009768
2021-12-10 11:42:43,136 iteration 1517 : loss : 0.033733, loss_ce: 0.012289
2021-12-10 11:42:45,756 iteration 1518 : loss : 0.031119, loss_ce: 0.012402
2021-12-10 11:42:48,527 iteration 1519 : loss : 0.021416, loss_ce: 0.009904
2021-12-10 11:42:51,122 iteration 1520 : loss : 0.025243, loss_ce: 0.010436
2021-12-10 11:42:53,632 iteration 1521 : loss : 0.027367, loss_ce: 0.013399
2021-12-10 11:42:56,441 iteration 1522 : loss : 0.021567, loss_ce: 0.007607
2021-12-10 11:42:59,036 iteration 1523 : loss : 0.028928, loss_ce: 0.009410
2021-12-10 11:43:01,710 iteration 1524 : loss : 0.024775, loss_ce: 0.009903
2021-12-10 11:43:04,302 iteration 1525 : loss : 0.023617, loss_ce: 0.011114
2021-12-10 11:43:06,939 iteration 1526 : loss : 0.023839, loss_ce: 0.009562
2021-12-10 11:43:09,558 iteration 1527 : loss : 0.030060, loss_ce: 0.009463
2021-12-10 11:43:12,324 iteration 1528 : loss : 0.030521, loss_ce: 0.008760
2021-12-10 11:43:14,921 iteration 1529 : loss : 0.026170, loss_ce: 0.011668
2021-12-10 11:43:14,921 Training Data Eval:
2021-12-10 11:43:29,529   Average segmentation loss on training set: 0.0203
2021-12-10 11:43:29,530 Validation Data Eval:
2021-12-10 11:43:34,626   Average segmentation loss on validation set: 0.1039
2021-12-10 11:43:37,326 iteration 1530 : loss : 0.025201, loss_ce: 0.010065
 22%|██████▎                     | 90/400 [1:17:00<4:30:55, 52.44s/it]2021-12-10 11:43:40,111 iteration 1531 : loss : 0.022860, loss_ce: 0.008722
2021-12-10 11:43:42,717 iteration 1532 : loss : 0.018746, loss_ce: 0.006755
2021-12-10 11:43:45,323 iteration 1533 : loss : 0.025496, loss_ce: 0.011066
2021-12-10 11:43:47,956 iteration 1534 : loss : 0.022147, loss_ce: 0.010028
2021-12-10 11:43:50,576 iteration 1535 : loss : 0.021429, loss_ce: 0.006900
2021-12-10 11:43:53,170 iteration 1536 : loss : 0.017852, loss_ce: 0.007877
2021-12-10 11:43:55,791 iteration 1537 : loss : 0.021026, loss_ce: 0.009195
2021-12-10 11:43:58,390 iteration 1538 : loss : 0.023115, loss_ce: 0.007520
2021-12-10 11:44:01,007 iteration 1539 : loss : 0.018989, loss_ce: 0.007493
2021-12-10 11:44:03,817 iteration 1540 : loss : 0.019172, loss_ce: 0.006921
2021-12-10 11:44:06,386 iteration 1541 : loss : 0.020372, loss_ce: 0.008315
2021-12-10 11:44:09,005 iteration 1542 : loss : 0.021135, loss_ce: 0.007483
2021-12-10 11:44:11,633 iteration 1543 : loss : 0.020507, loss_ce: 0.007215
2021-12-10 11:44:14,386 iteration 1544 : loss : 0.019270, loss_ce: 0.005927
2021-12-10 11:44:16,976 iteration 1545 : loss : 0.021442, loss_ce: 0.007005
2021-12-10 11:44:19,700 iteration 1546 : loss : 0.025159, loss_ce: 0.011801
2021-12-10 11:44:22,326 iteration 1547 : loss : 0.016851, loss_ce: 0.006244
 23%|██████▎                     | 91/400 [1:17:45<4:18:33, 50.20s/it]2021-12-10 11:44:24,968 iteration 1548 : loss : 0.018348, loss_ce: 0.003609
2021-12-10 11:44:27,613 iteration 1549 : loss : 0.016704, loss_ce: 0.005228
2021-12-10 11:44:30,292 iteration 1550 : loss : 0.019150, loss_ce: 0.006010
2021-12-10 11:44:32,898 iteration 1551 : loss : 0.016808, loss_ce: 0.007897
2021-12-10 11:44:35,520 iteration 1552 : loss : 0.022018, loss_ce: 0.007432
2021-12-10 11:44:38,220 iteration 1553 : loss : 0.019725, loss_ce: 0.007038
2021-12-10 11:44:40,837 iteration 1554 : loss : 0.021777, loss_ce: 0.008481
2021-12-10 11:44:43,610 iteration 1555 : loss : 0.020886, loss_ce: 0.007708
2021-12-10 11:44:46,208 iteration 1556 : loss : 0.015820, loss_ce: 0.005977
2021-12-10 11:44:48,831 iteration 1557 : loss : 0.021386, loss_ce: 0.007936
2021-12-10 11:44:51,452 iteration 1558 : loss : 0.017637, loss_ce: 0.006914
2021-12-10 11:44:54,070 iteration 1559 : loss : 0.027161, loss_ce: 0.010419
2021-12-10 11:44:56,693 iteration 1560 : loss : 0.018765, loss_ce: 0.005863
2021-12-10 11:44:59,318 iteration 1561 : loss : 0.014008, loss_ce: 0.006228
2021-12-10 11:45:01,944 iteration 1562 : loss : 0.021901, loss_ce: 0.011315
2021-12-10 11:45:04,553 iteration 1563 : loss : 0.018117, loss_ce: 0.007408
2021-12-10 11:45:07,289 iteration 1564 : loss : 0.021086, loss_ce: 0.009885
 23%|██████▍                     | 92/400 [1:18:30<4:09:38, 48.63s/it]2021-12-10 11:45:09,956 iteration 1565 : loss : 0.019296, loss_ce: 0.007331
2021-12-10 11:45:12,654 iteration 1566 : loss : 0.019371, loss_ce: 0.010020
2021-12-10 11:45:15,269 iteration 1567 : loss : 0.018309, loss_ce: 0.006869
2021-12-10 11:45:17,869 iteration 1568 : loss : 0.019574, loss_ce: 0.009812
2021-12-10 11:45:20,490 iteration 1569 : loss : 0.019831, loss_ce: 0.009575
2021-12-10 11:45:23,252 iteration 1570 : loss : 0.017684, loss_ce: 0.006115
2021-12-10 11:45:25,840 iteration 1571 : loss : 0.016974, loss_ce: 0.005712
2021-12-10 11:45:28,543 iteration 1572 : loss : 0.016037, loss_ce: 0.007074
2021-12-10 11:45:31,148 iteration 1573 : loss : 0.020650, loss_ce: 0.005921
2021-12-10 11:45:33,908 iteration 1574 : loss : 0.016063, loss_ce: 0.006067
2021-12-10 11:45:36,511 iteration 1575 : loss : 0.021186, loss_ce: 0.005984
2021-12-10 11:45:39,110 iteration 1576 : loss : 0.017006, loss_ce: 0.006960
2021-12-10 11:45:41,675 iteration 1577 : loss : 0.020728, loss_ce: 0.010139
2021-12-10 11:45:44,379 iteration 1578 : loss : 0.016695, loss_ce: 0.006714
2021-12-10 11:45:47,106 iteration 1579 : loss : 0.014811, loss_ce: 0.005865
2021-12-10 11:45:49,701 iteration 1580 : loss : 0.024359, loss_ce: 0.007913
2021-12-10 11:45:52,322 iteration 1581 : loss : 0.025110, loss_ce: 0.006182
 23%|██████▌                     | 93/400 [1:19:15<4:03:18, 47.55s/it]2021-12-10 11:45:54,985 iteration 1582 : loss : 0.017134, loss_ce: 0.005589
2021-12-10 11:45:57,651 iteration 1583 : loss : 0.017125, loss_ce: 0.006386
2021-12-10 11:46:00,324 iteration 1584 : loss : 0.016535, loss_ce: 0.005319
2021-12-10 11:46:02,989 iteration 1585 : loss : 0.021937, loss_ce: 0.009276
2021-12-10 11:46:05,615 iteration 1586 : loss : 0.022996, loss_ce: 0.011235
2021-12-10 11:46:08,279 iteration 1587 : loss : 0.023746, loss_ce: 0.012146
2021-12-10 11:46:10,908 iteration 1588 : loss : 0.023134, loss_ce: 0.007079
2021-12-10 11:46:13,527 iteration 1589 : loss : 0.017089, loss_ce: 0.007194
2021-12-10 11:46:16,150 iteration 1590 : loss : 0.018108, loss_ce: 0.007167
2021-12-10 11:46:18,905 iteration 1591 : loss : 0.025528, loss_ce: 0.007925
2021-12-10 11:46:21,510 iteration 1592 : loss : 0.021260, loss_ce: 0.010175
2021-12-10 11:46:24,220 iteration 1593 : loss : 0.018297, loss_ce: 0.005567
2021-12-10 11:46:26,837 iteration 1594 : loss : 0.016284, loss_ce: 0.006560
2021-12-10 11:46:29,502 iteration 1595 : loss : 0.021106, loss_ce: 0.008891
2021-12-10 11:46:32,118 iteration 1596 : loss : 0.019928, loss_ce: 0.008581
2021-12-10 11:46:34,745 iteration 1597 : loss : 0.018647, loss_ce: 0.008194
2021-12-10 11:46:37,520 iteration 1598 : loss : 0.022067, loss_ce: 0.007376
 24%|██████▌                     | 94/400 [1:20:00<3:58:54, 46.85s/it]2021-12-10 11:46:40,159 iteration 1599 : loss : 0.022532, loss_ce: 0.008467
2021-12-10 11:46:42,864 iteration 1600 : loss : 0.015717, loss_ce: 0.006216
2021-12-10 11:46:45,466 iteration 1601 : loss : 0.017528, loss_ce: 0.006222
2021-12-10 11:46:48,133 iteration 1602 : loss : 0.017039, loss_ce: 0.006188
2021-12-10 11:46:50,724 iteration 1603 : loss : 0.017393, loss_ce: 0.007467
2021-12-10 11:46:53,332 iteration 1604 : loss : 0.020207, loss_ce: 0.007163
2021-12-10 11:46:55,954 iteration 1605 : loss : 0.018504, loss_ce: 0.008986
2021-12-10 11:46:58,583 iteration 1606 : loss : 0.015441, loss_ce: 0.006191
2021-12-10 11:47:01,387 iteration 1607 : loss : 0.018841, loss_ce: 0.007506
2021-12-10 11:47:04,006 iteration 1608 : loss : 0.017404, loss_ce: 0.006391
2021-12-10 11:47:06,670 iteration 1609 : loss : 0.019037, loss_ce: 0.007838
2021-12-10 11:47:09,296 iteration 1610 : loss : 0.016620, loss_ce: 0.005088
2021-12-10 11:47:12,018 iteration 1611 : loss : 0.016445, loss_ce: 0.005490
2021-12-10 11:47:14,620 iteration 1612 : loss : 0.015539, loss_ce: 0.004609
2021-12-10 11:47:17,334 iteration 1613 : loss : 0.021161, loss_ce: 0.010163
2021-12-10 11:47:19,960 iteration 1614 : loss : 0.021075, loss_ce: 0.005321
2021-12-10 11:47:19,960 Training Data Eval:
2021-12-10 11:47:34,578   Average segmentation loss on training set: 0.0174
2021-12-10 11:47:34,578 Validation Data Eval:
2021-12-10 11:47:39,794   Average segmentation loss on validation set: 0.1321
2021-12-10 11:47:42,460 iteration 1615 : loss : 0.014905, loss_ce: 0.006120
 24%|██████▋                     | 95/400 [1:21:05<4:25:43, 52.27s/it]2021-12-10 11:47:45,088 iteration 1616 : loss : 0.019676, loss_ce: 0.005385
2021-12-10 11:47:47,696 iteration 1617 : loss : 0.019216, loss_ce: 0.008533
2021-12-10 11:47:50,452 iteration 1618 : loss : 0.020124, loss_ce: 0.007519
2021-12-10 11:47:53,037 iteration 1619 : loss : 0.016907, loss_ce: 0.004813
2021-12-10 11:47:55,660 iteration 1620 : loss : 0.018268, loss_ce: 0.006675
2021-12-10 11:47:58,434 iteration 1621 : loss : 0.017867, loss_ce: 0.006687
2021-12-10 11:48:01,036 iteration 1622 : loss : 0.015953, loss_ce: 0.005768
2021-12-10 11:48:03,710 iteration 1623 : loss : 0.015445, loss_ce: 0.007226
2021-12-10 11:48:06,374 iteration 1624 : loss : 0.017868, loss_ce: 0.006827
2021-12-10 11:48:08,987 iteration 1625 : loss : 0.016243, loss_ce: 0.005129
2021-12-10 11:48:11,748 iteration 1626 : loss : 0.017472, loss_ce: 0.007595
2021-12-10 11:48:14,351 iteration 1627 : loss : 0.017770, loss_ce: 0.006744
2021-12-10 11:48:17,045 iteration 1628 : loss : 0.013330, loss_ce: 0.005533
2021-12-10 11:48:19,647 iteration 1629 : loss : 0.017739, loss_ce: 0.006873
2021-12-10 11:48:22,272 iteration 1630 : loss : 0.018319, loss_ce: 0.006189
2021-12-10 11:48:25,049 iteration 1631 : loss : 0.016965, loss_ce: 0.006300
2021-12-10 11:48:27,672 iteration 1632 : loss : 0.018533, loss_ce: 0.009360
 24%|██████▋                     | 96/400 [1:21:50<4:14:07, 50.15s/it]2021-12-10 11:48:30,309 iteration 1633 : loss : 0.020779, loss_ce: 0.005999
2021-12-10 11:48:33,064 iteration 1634 : loss : 0.014975, loss_ce: 0.005645
2021-12-10 11:48:35,667 iteration 1635 : loss : 0.014244, loss_ce: 0.004722
2021-12-10 11:48:38,352 iteration 1636 : loss : 0.013319, loss_ce: 0.004411
2021-12-10 11:48:41,056 iteration 1637 : loss : 0.018253, loss_ce: 0.004840
2021-12-10 11:48:43,655 iteration 1638 : loss : 0.015394, loss_ce: 0.006313
2021-12-10 11:48:46,368 iteration 1639 : loss : 0.019359, loss_ce: 0.008834
2021-12-10 11:48:49,038 iteration 1640 : loss : 0.022283, loss_ce: 0.010209
2021-12-10 11:48:51,683 iteration 1641 : loss : 0.020044, loss_ce: 0.009866
2021-12-10 11:48:54,330 iteration 1642 : loss : 0.014035, loss_ce: 0.005329
2021-12-10 11:48:56,960 iteration 1643 : loss : 0.014738, loss_ce: 0.004594
2021-12-10 11:48:59,725 iteration 1644 : loss : 0.017140, loss_ce: 0.008706
2021-12-10 11:49:02,305 iteration 1645 : loss : 0.020053, loss_ce: 0.007977
2021-12-10 11:49:04,907 iteration 1646 : loss : 0.013345, loss_ce: 0.006691
2021-12-10 11:49:07,725 iteration 1647 : loss : 0.017802, loss_ce: 0.006237
2021-12-10 11:49:10,334 iteration 1648 : loss : 0.019377, loss_ce: 0.007998
2021-12-10 11:49:13,072 iteration 1649 : loss : 0.018432, loss_ce: 0.006699
 24%|██████▊                     | 97/400 [1:22:35<4:06:05, 48.73s/it]2021-12-10 11:49:15,742 iteration 1650 : loss : 0.016947, loss_ce: 0.004940
2021-12-10 11:49:18,361 iteration 1651 : loss : 0.022313, loss_ce: 0.008810
2021-12-10 11:49:21,109 iteration 1652 : loss : 0.014953, loss_ce: 0.006350
2021-12-10 11:49:23,671 iteration 1653 : loss : 0.015012, loss_ce: 0.006467
2021-12-10 11:49:26,299 iteration 1654 : loss : 0.015930, loss_ce: 0.006076
2021-12-10 11:49:28,935 iteration 1655 : loss : 0.012758, loss_ce: 0.005112
2021-12-10 11:49:31,555 iteration 1656 : loss : 0.019340, loss_ce: 0.007935
2021-12-10 11:49:34,318 iteration 1657 : loss : 0.014218, loss_ce: 0.005176
2021-12-10 11:49:36,950 iteration 1658 : loss : 0.015161, loss_ce: 0.006465
2021-12-10 11:49:39,701 iteration 1659 : loss : 0.017679, loss_ce: 0.005312
2021-12-10 11:49:42,343 iteration 1660 : loss : 0.021121, loss_ce: 0.006943
2021-12-10 11:49:44,959 iteration 1661 : loss : 0.018823, loss_ce: 0.006512
2021-12-10 11:49:47,743 iteration 1662 : loss : 0.020382, loss_ce: 0.011901
2021-12-10 11:49:50,341 iteration 1663 : loss : 0.017914, loss_ce: 0.005730
2021-12-10 11:49:52,993 iteration 1664 : loss : 0.021193, loss_ce: 0.009506
2021-12-10 11:49:55,623 iteration 1665 : loss : 0.017034, loss_ce: 0.005366
2021-12-10 11:49:58,395 iteration 1666 : loss : 0.017472, loss_ce: 0.007550
 24%|██████▊                     | 98/400 [1:23:21<4:00:07, 47.71s/it]2021-12-10 11:50:01,038 iteration 1667 : loss : 0.015586, loss_ce: 0.005228
2021-12-10 11:50:03,649 iteration 1668 : loss : 0.016575, loss_ce: 0.006536
2021-12-10 11:50:06,425 iteration 1669 : loss : 0.017211, loss_ce: 0.007254
2021-12-10 11:50:09,021 iteration 1670 : loss : 0.016911, loss_ce: 0.005753
2021-12-10 11:50:11,634 iteration 1671 : loss : 0.016629, loss_ce: 0.006433
2021-12-10 11:50:14,293 iteration 1672 : loss : 0.017802, loss_ce: 0.006359
2021-12-10 11:50:16,953 iteration 1673 : loss : 0.018429, loss_ce: 0.009966
2021-12-10 11:50:19,576 iteration 1674 : loss : 0.017532, loss_ce: 0.006495
2021-12-10 11:50:22,362 iteration 1675 : loss : 0.015399, loss_ce: 0.004483
2021-12-10 11:50:24,985 iteration 1676 : loss : 0.016384, loss_ce: 0.006907
2021-12-10 11:50:27,632 iteration 1677 : loss : 0.016935, loss_ce: 0.005941
2021-12-10 11:50:30,254 iteration 1678 : loss : 0.018779, loss_ce: 0.005759
2021-12-10 11:50:32,999 iteration 1679 : loss : 0.014301, loss_ce: 0.004832
2021-12-10 11:50:35,659 iteration 1680 : loss : 0.020612, loss_ce: 0.006321
2021-12-10 11:50:38,217 iteration 1681 : loss : 0.015842, loss_ce: 0.006401
2021-12-10 11:50:40,999 iteration 1682 : loss : 0.015100, loss_ce: 0.007128
2021-12-10 11:50:43,600 iteration 1683 : loss : 0.015820, loss_ce: 0.007151
 25%|██████▉                     | 99/400 [1:24:06<3:55:34, 46.96s/it]2021-12-10 11:50:46,244 iteration 1684 : loss : 0.016342, loss_ce: 0.006221
2021-12-10 11:50:49,027 iteration 1685 : loss : 0.020894, loss_ce: 0.008974
2021-12-10 11:50:51,650 iteration 1686 : loss : 0.013268, loss_ce: 0.005436
2021-12-10 11:50:54,242 iteration 1687 : loss : 0.018945, loss_ce: 0.005961
2021-12-10 11:50:57,016 iteration 1688 : loss : 0.014102, loss_ce: 0.005436
2021-12-10 11:50:59,607 iteration 1689 : loss : 0.014430, loss_ce: 0.006025
2021-12-10 11:51:02,227 iteration 1690 : loss : 0.016447, loss_ce: 0.004767
2021-12-10 11:51:04,993 iteration 1691 : loss : 0.020130, loss_ce: 0.009678
2021-12-10 11:51:07,594 iteration 1692 : loss : 0.012646, loss_ce: 0.004946
2021-12-10 11:51:10,241 iteration 1693 : loss : 0.015375, loss_ce: 0.005325
2021-12-10 11:51:12,853 iteration 1694 : loss : 0.014601, loss_ce: 0.006002
2021-12-10 11:51:15,623 iteration 1695 : loss : 0.019497, loss_ce: 0.006555
2021-12-10 11:51:18,252 iteration 1696 : loss : 0.019069, loss_ce: 0.006787
2021-12-10 11:51:20,897 iteration 1697 : loss : 0.013224, loss_ce: 0.004942
2021-12-10 11:51:23,546 iteration 1698 : loss : 0.013312, loss_ce: 0.006402
2021-12-10 11:51:26,168 iteration 1699 : loss : 0.015328, loss_ce: 0.006451
2021-12-10 11:51:26,168 Training Data Eval:
2021-12-10 11:51:41,039   Average segmentation loss on training set: 0.0174
2021-12-10 11:51:41,040 Validation Data Eval:
2021-12-10 11:51:46,150   Average segmentation loss on validation set: 0.1152
2021-12-10 11:51:48,808 iteration 1700 : loss : 0.012981, loss_ce: 0.004610
 25%|██████▊                    | 100/400 [1:25:11<4:22:09, 52.43s/it]2021-12-10 11:51:51,513 iteration 1701 : loss : 0.014878, loss_ce: 0.005681
2021-12-10 11:51:54,155 iteration 1702 : loss : 0.014502, loss_ce: 0.006262
2021-12-10 11:51:56,897 iteration 1703 : loss : 0.013068, loss_ce: 0.004907
2021-12-10 11:51:59,518 iteration 1704 : loss : 0.014570, loss_ce: 0.005803
2021-12-10 11:52:02,300 iteration 1705 : loss : 0.017017, loss_ce: 0.006207
2021-12-10 11:52:04,922 iteration 1706 : loss : 0.022474, loss_ce: 0.008649
2021-12-10 11:52:07,545 iteration 1707 : loss : 0.017644, loss_ce: 0.005283
2021-12-10 11:52:10,206 iteration 1708 : loss : 0.014847, loss_ce: 0.005152
2021-12-10 11:52:12,869 iteration 1709 : loss : 0.020796, loss_ce: 0.010401
2021-12-10 11:52:15,532 iteration 1710 : loss : 0.017902, loss_ce: 0.006549
2021-12-10 11:52:18,155 iteration 1711 : loss : 0.020667, loss_ce: 0.009726
2021-12-10 11:52:20,779 iteration 1712 : loss : 0.011505, loss_ce: 0.004979
2021-12-10 11:52:23,423 iteration 1713 : loss : 0.015131, loss_ce: 0.005744
2021-12-10 11:52:26,045 iteration 1714 : loss : 0.019587, loss_ce: 0.005579
2021-12-10 11:52:28,809 iteration 1715 : loss : 0.015065, loss_ce: 0.006378
2021-12-10 11:52:31,442 iteration 1716 : loss : 0.018045, loss_ce: 0.005856
2021-12-10 11:52:34,051 iteration 1717 : loss : 0.014377, loss_ce: 0.005959
 25%|██████▊                    | 101/400 [1:25:56<4:10:32, 50.28s/it]2021-12-10 11:52:36,824 iteration 1718 : loss : 0.014768, loss_ce: 0.005910
2021-12-10 11:52:39,455 iteration 1719 : loss : 0.014901, loss_ce: 0.004738
2021-12-10 11:52:42,061 iteration 1720 : loss : 0.014941, loss_ce: 0.005796
2021-12-10 11:52:44,818 iteration 1721 : loss : 0.020914, loss_ce: 0.008953
2021-12-10 11:52:47,417 iteration 1722 : loss : 0.016337, loss_ce: 0.006700
2021-12-10 11:52:50,074 iteration 1723 : loss : 0.018363, loss_ce: 0.006474
2021-12-10 11:52:52,688 iteration 1724 : loss : 0.012280, loss_ce: 0.004235
2021-12-10 11:52:55,452 iteration 1725 : loss : 0.014612, loss_ce: 0.005536
2021-12-10 11:52:58,044 iteration 1726 : loss : 0.014372, loss_ce: 0.006550
2021-12-10 11:53:00,650 iteration 1727 : loss : 0.016138, loss_ce: 0.006707
2021-12-10 11:53:03,414 iteration 1728 : loss : 0.016510, loss_ce: 0.005715
2021-12-10 11:53:06,021 iteration 1729 : loss : 0.024052, loss_ce: 0.007314
2021-12-10 11:53:08,769 iteration 1730 : loss : 0.020862, loss_ce: 0.007929
2021-12-10 11:53:11,359 iteration 1731 : loss : 0.020194, loss_ce: 0.007311
2021-12-10 11:53:13,980 iteration 1732 : loss : 0.021418, loss_ce: 0.009723
2021-12-10 11:53:16,745 iteration 1733 : loss : 0.013504, loss_ce: 0.004045
2021-12-10 11:53:19,328 iteration 1734 : loss : 0.016913, loss_ce: 0.006375
 26%|██████▉                    | 102/400 [1:26:42<4:02:15, 48.78s/it]2021-12-10 11:53:21,946 iteration 1735 : loss : 0.019943, loss_ce: 0.006844
2021-12-10 11:53:24,558 iteration 1736 : loss : 0.020827, loss_ce: 0.007453
2021-12-10 11:53:27,339 iteration 1737 : loss : 0.015470, loss_ce: 0.005739
2021-12-10 11:53:29,963 iteration 1738 : loss : 0.013365, loss_ce: 0.005961
2021-12-10 11:53:32,586 iteration 1739 : loss : 0.017357, loss_ce: 0.005291
2021-12-10 11:53:35,210 iteration 1740 : loss : 0.015592, loss_ce: 0.007691
2021-12-10 11:53:37,832 iteration 1741 : loss : 0.015431, loss_ce: 0.005841
2021-12-10 11:53:40,498 iteration 1742 : loss : 0.015578, loss_ce: 0.007094
2021-12-10 11:53:43,151 iteration 1743 : loss : 0.014771, loss_ce: 0.006048
2021-12-10 11:53:45,746 iteration 1744 : loss : 0.016241, loss_ce: 0.004769
2021-12-10 11:53:48,366 iteration 1745 : loss : 0.014052, loss_ce: 0.005720
2021-12-10 11:53:51,136 iteration 1746 : loss : 0.013733, loss_ce: 0.005404
2021-12-10 11:53:53,736 iteration 1747 : loss : 0.012968, loss_ce: 0.003929
2021-12-10 11:53:56,351 iteration 1748 : loss : 0.015453, loss_ce: 0.007452
2021-12-10 11:53:59,116 iteration 1749 : loss : 0.016705, loss_ce: 0.006626
2021-12-10 11:54:01,718 iteration 1750 : loss : 0.020451, loss_ce: 0.005705
2021-12-10 11:54:04,335 iteration 1751 : loss : 0.017960, loss_ce: 0.006309
 26%|██████▉                    | 103/400 [1:27:27<3:55:50, 47.64s/it]2021-12-10 11:54:07,001 iteration 1752 : loss : 0.016558, loss_ce: 0.003988
2021-12-10 11:54:09,656 iteration 1753 : loss : 0.014190, loss_ce: 0.005464
2021-12-10 11:54:12,286 iteration 1754 : loss : 0.011541, loss_ce: 0.004093
2021-12-10 11:54:14,888 iteration 1755 : loss : 0.015340, loss_ce: 0.005144
2021-12-10 11:54:17,667 iteration 1756 : loss : 0.019066, loss_ce: 0.009332
2021-12-10 11:54:20,276 iteration 1757 : loss : 0.016014, loss_ce: 0.006838
2021-12-10 11:54:22,897 iteration 1758 : loss : 0.017472, loss_ce: 0.004067
2021-12-10 11:54:25,672 iteration 1759 : loss : 0.014715, loss_ce: 0.004262
2021-12-10 11:54:28,297 iteration 1760 : loss : 0.014768, loss_ce: 0.004674
2021-12-10 11:54:30,933 iteration 1761 : loss : 0.015335, loss_ce: 0.004858
2021-12-10 11:54:33,558 iteration 1762 : loss : 0.015647, loss_ce: 0.007334
2021-12-10 11:54:36,261 iteration 1763 : loss : 0.014171, loss_ce: 0.004572
2021-12-10 11:54:38,875 iteration 1764 : loss : 0.014288, loss_ce: 0.006530
2021-12-10 11:54:41,538 iteration 1765 : loss : 0.016074, loss_ce: 0.007632
2021-12-10 11:54:44,132 iteration 1766 : loss : 0.014928, loss_ce: 0.005586
2021-12-10 11:54:46,752 iteration 1767 : loss : 0.016084, loss_ce: 0.009281
2021-12-10 11:54:49,379 iteration 1768 : loss : 0.014678, loss_ce: 0.005338
 26%|███████                    | 104/400 [1:28:12<3:51:12, 46.87s/it]2021-12-10 11:54:52,037 iteration 1769 : loss : 0.013148, loss_ce: 0.004741
2021-12-10 11:54:54,801 iteration 1770 : loss : 0.014846, loss_ce: 0.005566
2021-12-10 11:54:57,424 iteration 1771 : loss : 0.014992, loss_ce: 0.006838
2021-12-10 11:55:00,056 iteration 1772 : loss : 0.015230, loss_ce: 0.005608
2021-12-10 11:55:02,673 iteration 1773 : loss : 0.015386, loss_ce: 0.005634
2021-12-10 11:55:05,299 iteration 1774 : loss : 0.011859, loss_ce: 0.005119
2021-12-10 11:55:08,066 iteration 1775 : loss : 0.014196, loss_ce: 0.004797
2021-12-10 11:55:10,661 iteration 1776 : loss : 0.015403, loss_ce: 0.006383
2021-12-10 11:55:13,222 iteration 1777 : loss : 0.015370, loss_ce: 0.006364
2021-12-10 11:55:16,014 iteration 1778 : loss : 0.013098, loss_ce: 0.004515
2021-12-10 11:55:18,621 iteration 1779 : loss : 0.015582, loss_ce: 0.006997
2021-12-10 11:55:21,224 iteration 1780 : loss : 0.016244, loss_ce: 0.006103
2021-12-10 11:55:23,828 iteration 1781 : loss : 0.013385, loss_ce: 0.004502
2021-12-10 11:55:26,444 iteration 1782 : loss : 0.011941, loss_ce: 0.005050
2021-12-10 11:55:29,067 iteration 1783 : loss : 0.012681, loss_ce: 0.004312
2021-12-10 11:55:31,665 iteration 1784 : loss : 0.015435, loss_ce: 0.005559
2021-12-10 11:55:31,665 Training Data Eval:
2021-12-10 11:55:46,344   Average segmentation loss on training set: 0.0139
2021-12-10 11:55:46,344 Validation Data Eval:
2021-12-10 11:55:51,469   Average segmentation loss on validation set: 0.0925
2021-12-10 11:55:54,236 iteration 1785 : loss : 0.014570, loss_ce: 0.005304
 26%|███████                    | 105/400 [1:29:17<4:16:57, 52.26s/it]2021-12-10 11:55:56,850 iteration 1786 : loss : 0.014359, loss_ce: 0.005965
2021-12-10 11:55:59,475 iteration 1787 : loss : 0.014546, loss_ce: 0.005524
2021-12-10 11:56:02,240 iteration 1788 : loss : 0.010502, loss_ce: 0.003722
2021-12-10 11:56:04,866 iteration 1789 : loss : 0.015051, loss_ce: 0.005677
2021-12-10 11:56:07,495 iteration 1790 : loss : 0.013220, loss_ce: 0.004809
2021-12-10 11:56:10,092 iteration 1791 : loss : 0.014758, loss_ce: 0.007131
2021-12-10 11:56:12,909 iteration 1792 : loss : 0.013576, loss_ce: 0.004929
2021-12-10 11:56:15,522 iteration 1793 : loss : 0.010960, loss_ce: 0.005062
2021-12-10 11:56:18,115 iteration 1794 : loss : 0.015547, loss_ce: 0.006669
2021-12-10 11:56:20,703 iteration 1795 : loss : 0.013836, loss_ce: 0.004630
2021-12-10 11:56:23,329 iteration 1796 : loss : 0.014847, loss_ce: 0.006083
2021-12-10 11:56:25,938 iteration 1797 : loss : 0.014640, loss_ce: 0.004055
2021-12-10 11:56:28,731 iteration 1798 : loss : 0.012192, loss_ce: 0.004833
2021-12-10 11:56:31,330 iteration 1799 : loss : 0.014294, loss_ce: 0.004936
2021-12-10 11:56:33,928 iteration 1800 : loss : 0.018145, loss_ce: 0.004740
2021-12-10 11:56:36,636 iteration 1801 : loss : 0.013544, loss_ce: 0.004022
2021-12-10 11:56:39,233 iteration 1802 : loss : 0.015973, loss_ce: 0.006856
 26%|███████▏                   | 106/400 [1:30:02<4:05:24, 50.08s/it]2021-12-10 11:56:41,917 iteration 1803 : loss : 0.013523, loss_ce: 0.006864
2021-12-10 11:56:44,507 iteration 1804 : loss : 0.015702, loss_ce: 0.004414
2021-12-10 11:56:47,083 iteration 1805 : loss : 0.013525, loss_ce: 0.004236
2021-12-10 11:56:49,685 iteration 1806 : loss : 0.015166, loss_ce: 0.006858
2021-12-10 11:56:52,290 iteration 1807 : loss : 0.014950, loss_ce: 0.004778
2021-12-10 11:56:54,920 iteration 1808 : loss : 0.015425, loss_ce: 0.006990
2021-12-10 11:56:57,542 iteration 1809 : loss : 0.014170, loss_ce: 0.004773
2021-12-10 11:57:00,207 iteration 1810 : loss : 0.012531, loss_ce: 0.004816
2021-12-10 11:57:02,807 iteration 1811 : loss : 0.013657, loss_ce: 0.005924
2021-12-10 11:57:05,427 iteration 1812 : loss : 0.011004, loss_ce: 0.004436
2021-12-10 11:57:08,046 iteration 1813 : loss : 0.012357, loss_ce: 0.004917
2021-12-10 11:57:10,726 iteration 1814 : loss : 0.015450, loss_ce: 0.007405
2021-12-10 11:57:13,327 iteration 1815 : loss : 0.015326, loss_ce: 0.004294
2021-12-10 11:57:15,953 iteration 1816 : loss : 0.014959, loss_ce: 0.005961
2021-12-10 11:57:18,566 iteration 1817 : loss : 0.018580, loss_ce: 0.007474
2021-12-10 11:57:21,365 iteration 1818 : loss : 0.014906, loss_ce: 0.005661
2021-12-10 11:57:23,965 iteration 1819 : loss : 0.019509, loss_ce: 0.007031
 27%|███████▏                   | 107/400 [1:30:46<3:56:44, 48.48s/it]2021-12-10 11:57:26,589 iteration 1820 : loss : 0.014380, loss_ce: 0.003775
2021-12-10 11:57:29,219 iteration 1821 : loss : 0.014747, loss_ce: 0.005937
2021-12-10 11:57:31,829 iteration 1822 : loss : 0.012838, loss_ce: 0.003106
2021-12-10 11:57:34,593 iteration 1823 : loss : 0.014932, loss_ce: 0.005549
2021-12-10 11:57:37,205 iteration 1824 : loss : 0.013510, loss_ce: 0.005693
2021-12-10 11:57:39,818 iteration 1825 : loss : 0.014923, loss_ce: 0.005711
2021-12-10 11:57:42,386 iteration 1826 : loss : 0.014447, loss_ce: 0.006161
2021-12-10 11:57:45,012 iteration 1827 : loss : 0.012388, loss_ce: 0.004835
2021-12-10 11:57:47,796 iteration 1828 : loss : 0.014615, loss_ce: 0.005101
2021-12-10 11:57:50,420 iteration 1829 : loss : 0.012924, loss_ce: 0.006432
2021-12-10 11:57:53,019 iteration 1830 : loss : 0.012091, loss_ce: 0.005659
2021-12-10 11:57:55,647 iteration 1831 : loss : 0.016834, loss_ce: 0.005632
2021-12-10 11:57:58,267 iteration 1832 : loss : 0.013913, loss_ce: 0.006616
2021-12-10 11:58:00,897 iteration 1833 : loss : 0.014977, loss_ce: 0.005240
2021-12-10 11:58:03,519 iteration 1834 : loss : 0.011521, loss_ce: 0.004098
2021-12-10 11:58:06,146 iteration 1835 : loss : 0.014423, loss_ce: 0.004568
2021-12-10 11:58:08,926 iteration 1836 : loss : 0.014363, loss_ce: 0.005579
 27%|███████▎                   | 108/400 [1:31:31<3:50:47, 47.42s/it]2021-12-10 11:58:11,547 iteration 1837 : loss : 0.011864, loss_ce: 0.004666
2021-12-10 11:58:14,318 iteration 1838 : loss : 0.013172, loss_ce: 0.004522
2021-12-10 11:58:16,939 iteration 1839 : loss : 0.016864, loss_ce: 0.008554
2021-12-10 11:58:19,533 iteration 1840 : loss : 0.011735, loss_ce: 0.003954
2021-12-10 11:58:22,260 iteration 1841 : loss : 0.012371, loss_ce: 0.005654
2021-12-10 11:58:24,897 iteration 1842 : loss : 0.013587, loss_ce: 0.003544
2021-12-10 11:58:27,502 iteration 1843 : loss : 0.011942, loss_ce: 0.005358
2021-12-10 11:58:30,266 iteration 1844 : loss : 0.011080, loss_ce: 0.004256
2021-12-10 11:58:32,793 iteration 1845 : loss : 0.015114, loss_ce: 0.006140
2021-12-10 11:58:35,414 iteration 1846 : loss : 0.012299, loss_ce: 0.005085
2021-12-10 11:58:38,174 iteration 1847 : loss : 0.011275, loss_ce: 0.003690
2021-12-10 11:58:40,770 iteration 1848 : loss : 0.011675, loss_ce: 0.003788
2021-12-10 11:58:43,386 iteration 1849 : loss : 0.012866, loss_ce: 0.005035
2021-12-10 11:58:46,044 iteration 1850 : loss : 0.012439, loss_ce: 0.005294
2021-12-10 11:58:48,646 iteration 1851 : loss : 0.012431, loss_ce: 0.004209
2021-12-10 11:58:51,446 iteration 1852 : loss : 0.014087, loss_ce: 0.005993
2021-12-10 11:58:54,060 iteration 1853 : loss : 0.014901, loss_ce: 0.004654
 27%|███████▎                   | 109/400 [1:32:16<3:46:40, 46.74s/it]2021-12-10 11:58:56,674 iteration 1854 : loss : 0.014342, loss_ce: 0.005540
2021-12-10 11:58:59,332 iteration 1855 : loss : 0.012684, loss_ce: 0.005851
2021-12-10 11:59:01,991 iteration 1856 : loss : 0.014944, loss_ce: 0.004417
2021-12-10 11:59:04,599 iteration 1857 : loss : 0.015597, loss_ce: 0.006233
2021-12-10 11:59:07,240 iteration 1858 : loss : 0.012169, loss_ce: 0.005080
2021-12-10 11:59:09,930 iteration 1859 : loss : 0.015105, loss_ce: 0.005385
2021-12-10 11:59:12,529 iteration 1860 : loss : 0.013504, loss_ce: 0.005188
2021-12-10 11:59:15,101 iteration 1861 : loss : 0.012578, loss_ce: 0.003777
2021-12-10 11:59:17,740 iteration 1862 : loss : 0.014651, loss_ce: 0.004243
2021-12-10 11:59:20,362 iteration 1863 : loss : 0.017534, loss_ce: 0.007722
2021-12-10 11:59:23,024 iteration 1864 : loss : 0.012876, loss_ce: 0.004236
2021-12-10 11:59:25,635 iteration 1865 : loss : 0.014486, loss_ce: 0.006314
2021-12-10 11:59:28,408 iteration 1866 : loss : 0.016161, loss_ce: 0.005774
2021-12-10 11:59:31,037 iteration 1867 : loss : 0.012911, loss_ce: 0.006076
2021-12-10 11:59:33,644 iteration 1868 : loss : 0.012573, loss_ce: 0.004365
2021-12-10 11:59:36,405 iteration 1869 : loss : 0.017878, loss_ce: 0.006071
2021-12-10 11:59:36,405 Training Data Eval:
2021-12-10 11:59:51,111   Average segmentation loss on training set: 0.0149
2021-12-10 11:59:51,112 Validation Data Eval:
2021-12-10 11:59:56,213   Average segmentation loss on validation set: 0.0965
2021-12-10 11:59:58,839 iteration 1870 : loss : 0.014428, loss_ce: 0.004830
 28%|███████▍                   | 110/400 [1:33:21<4:12:04, 52.15s/it]2021-12-10 12:00:01,527 iteration 1871 : loss : 0.014700, loss_ce: 0.006519
2021-12-10 12:00:04,182 iteration 1872 : loss : 0.015060, loss_ce: 0.007488
2021-12-10 12:00:06,828 iteration 1873 : loss : 0.015907, loss_ce: 0.004957
2021-12-10 12:00:09,451 iteration 1874 : loss : 0.012887, loss_ce: 0.005027
2021-12-10 12:00:12,231 iteration 1875 : loss : 0.016774, loss_ce: 0.007549
2021-12-10 12:00:14,840 iteration 1876 : loss : 0.017545, loss_ce: 0.004081
2021-12-10 12:00:17,538 iteration 1877 : loss : 0.012561, loss_ce: 0.005947
2021-12-10 12:00:20,141 iteration 1878 : loss : 0.013308, loss_ce: 0.004951
2021-12-10 12:00:22,772 iteration 1879 : loss : 0.010964, loss_ce: 0.004296
2021-12-10 12:00:25,545 iteration 1880 : loss : 0.014654, loss_ce: 0.006850
2021-12-10 12:00:28,145 iteration 1881 : loss : 0.017281, loss_ce: 0.005996
2021-12-10 12:00:30,768 iteration 1882 : loss : 0.016948, loss_ce: 0.006301
2021-12-10 12:00:33,369 iteration 1883 : loss : 0.017339, loss_ce: 0.004635
2021-12-10 12:00:36,153 iteration 1884 : loss : 0.012338, loss_ce: 0.004282
2021-12-10 12:00:38,763 iteration 1885 : loss : 0.014383, loss_ce: 0.003972
2021-12-10 12:00:41,417 iteration 1886 : loss : 0.015445, loss_ce: 0.006145
2021-12-10 12:00:44,047 iteration 1887 : loss : 0.016731, loss_ce: 0.006132
 28%|███████▍                   | 111/400 [1:34:06<4:01:08, 50.07s/it]2021-12-10 12:00:46,856 iteration 1888 : loss : 0.017538, loss_ce: 0.005783
2021-12-10 12:00:49,453 iteration 1889 : loss : 0.014273, loss_ce: 0.007488
2021-12-10 12:00:52,134 iteration 1890 : loss : 0.014553, loss_ce: 0.005485
2021-12-10 12:00:54,933 iteration 1891 : loss : 0.016074, loss_ce: 0.007293
2021-12-10 12:00:57,533 iteration 1892 : loss : 0.017044, loss_ce: 0.006046
2021-12-10 12:01:00,207 iteration 1893 : loss : 0.013268, loss_ce: 0.005628
2021-12-10 12:01:02,838 iteration 1894 : loss : 0.014437, loss_ce: 0.005419
2021-12-10 12:01:05,623 iteration 1895 : loss : 0.020027, loss_ce: 0.006156
2021-12-10 12:01:08,226 iteration 1896 : loss : 0.013439, loss_ce: 0.004556
2021-12-10 12:01:10,854 iteration 1897 : loss : 0.016329, loss_ce: 0.006228
2021-12-10 12:01:13,628 iteration 1898 : loss : 0.016347, loss_ce: 0.006010
2021-12-10 12:01:16,235 iteration 1899 : loss : 0.014956, loss_ce: 0.005344
2021-12-10 12:01:18,852 iteration 1900 : loss : 0.014513, loss_ce: 0.005645
2021-12-10 12:01:21,519 iteration 1901 : loss : 0.012597, loss_ce: 0.004167
2021-12-10 12:01:24,147 iteration 1902 : loss : 0.012816, loss_ce: 0.004305
2021-12-10 12:01:26,939 iteration 1903 : loss : 0.014326, loss_ce: 0.006227
2021-12-10 12:01:29,539 iteration 1904 : loss : 0.013980, loss_ce: 0.006203
 28%|███████▌                   | 112/400 [1:34:52<3:53:43, 48.69s/it]2021-12-10 12:01:32,189 iteration 1905 : loss : 0.011373, loss_ce: 0.005497
2021-12-10 12:01:34,972 iteration 1906 : loss : 0.016291, loss_ce: 0.006261
2021-12-10 12:01:37,545 iteration 1907 : loss : 0.013864, loss_ce: 0.005611
2021-12-10 12:01:40,307 iteration 1908 : loss : 0.016125, loss_ce: 0.006536
2021-12-10 12:01:42,946 iteration 1909 : loss : 0.016931, loss_ce: 0.005953
2021-12-10 12:01:45,565 iteration 1910 : loss : 0.013927, loss_ce: 0.003980
2021-12-10 12:01:48,227 iteration 1911 : loss : 0.014028, loss_ce: 0.004344
2021-12-10 12:01:50,989 iteration 1912 : loss : 0.016075, loss_ce: 0.006374
2021-12-10 12:01:53,584 iteration 1913 : loss : 0.015819, loss_ce: 0.007090
2021-12-10 12:01:56,282 iteration 1914 : loss : 0.016441, loss_ce: 0.006197
2021-12-10 12:01:58,905 iteration 1915 : loss : 0.016137, loss_ce: 0.006183
2021-12-10 12:02:01,713 iteration 1916 : loss : 0.013917, loss_ce: 0.004402
2021-12-10 12:02:04,329 iteration 1917 : loss : 0.013219, loss_ce: 0.003605
2021-12-10 12:02:07,111 iteration 1918 : loss : 0.018441, loss_ce: 0.007012
2021-12-10 12:02:09,720 iteration 1919 : loss : 0.016206, loss_ce: 0.006252
2021-12-10 12:02:12,353 iteration 1920 : loss : 0.014946, loss_ce: 0.004807
2021-12-10 12:02:14,976 iteration 1921 : loss : 0.010742, loss_ce: 0.003121
 28%|███████▋                   | 113/400 [1:35:37<3:48:14, 47.72s/it]2021-12-10 12:02:17,643 iteration 1922 : loss : 0.014340, loss_ce: 0.005712
2021-12-10 12:02:20,341 iteration 1923 : loss : 0.016560, loss_ce: 0.005740
2021-12-10 12:02:22,965 iteration 1924 : loss : 0.012470, loss_ce: 0.003783
2021-12-10 12:02:25,728 iteration 1925 : loss : 0.011668, loss_ce: 0.004932
2021-12-10 12:02:28,331 iteration 1926 : loss : 0.013586, loss_ce: 0.005130
2021-12-10 12:02:30,954 iteration 1927 : loss : 0.019326, loss_ce: 0.005690
2021-12-10 12:02:33,559 iteration 1928 : loss : 0.014580, loss_ce: 0.004266
2021-12-10 12:02:36,352 iteration 1929 : loss : 0.012962, loss_ce: 0.004988
2021-12-10 12:02:38,953 iteration 1930 : loss : 0.012965, loss_ce: 0.003116
2021-12-10 12:02:41,576 iteration 1931 : loss : 0.015686, loss_ce: 0.007093
2021-12-10 12:02:44,293 iteration 1932 : loss : 0.011968, loss_ce: 0.004378
2021-12-10 12:02:47,007 iteration 1933 : loss : 0.016803, loss_ce: 0.004967
2021-12-10 12:02:49,602 iteration 1934 : loss : 0.016101, loss_ce: 0.006368
2021-12-10 12:02:52,226 iteration 1935 : loss : 0.011719, loss_ce: 0.005327
2021-12-10 12:02:54,833 iteration 1936 : loss : 0.011664, loss_ce: 0.004608
2021-12-10 12:02:57,583 iteration 1937 : loss : 0.013653, loss_ce: 0.005313
2021-12-10 12:03:00,209 iteration 1938 : loss : 0.015478, loss_ce: 0.005409
 28%|███████▋                   | 114/400 [1:36:23<3:43:55, 46.98s/it]2021-12-10 12:03:02,971 iteration 1939 : loss : 0.019143, loss_ce: 0.005073
2021-12-10 12:03:05,640 iteration 1940 : loss : 0.013193, loss_ce: 0.004468
2021-12-10 12:03:08,309 iteration 1941 : loss : 0.014547, loss_ce: 0.006150
2021-12-10 12:03:10,934 iteration 1942 : loss : 0.012845, loss_ce: 0.005373
2021-12-10 12:03:13,562 iteration 1943 : loss : 0.013540, loss_ce: 0.005379
2021-12-10 12:03:16,285 iteration 1944 : loss : 0.014087, loss_ce: 0.004701
2021-12-10 12:03:18,886 iteration 1945 : loss : 0.016609, loss_ce: 0.005404
2021-12-10 12:03:21,673 iteration 1946 : loss : 0.013479, loss_ce: 0.004679
2021-12-10 12:03:24,272 iteration 1947 : loss : 0.009847, loss_ce: 0.003443
2021-12-10 12:03:26,968 iteration 1948 : loss : 0.011986, loss_ce: 0.003436
2021-12-10 12:03:29,676 iteration 1949 : loss : 0.013353, loss_ce: 0.005588
2021-12-10 12:03:32,270 iteration 1950 : loss : 0.017029, loss_ce: 0.006633
2021-12-10 12:03:34,881 iteration 1951 : loss : 0.013528, loss_ce: 0.005777
2021-12-10 12:03:37,536 iteration 1952 : loss : 0.013410, loss_ce: 0.004944
2021-12-10 12:03:40,157 iteration 1953 : loss : 0.012027, loss_ce: 0.005578
2021-12-10 12:03:42,931 iteration 1954 : loss : 0.012349, loss_ce: 0.003737
2021-12-10 12:03:42,931 Training Data Eval:
2021-12-10 12:03:57,721   Average segmentation loss on training set: 0.0122
2021-12-10 12:03:57,721 Validation Data Eval:
2021-12-10 12:04:02,941   Average segmentation loss on validation set: 0.1156
2021-12-10 12:04:05,563 iteration 1955 : loss : 0.013494, loss_ce: 0.005118
 29%|███████▊                   | 115/400 [1:37:28<4:09:19, 52.49s/it]2021-12-10 12:04:08,311 iteration 1956 : loss : 0.012413, loss_ce: 0.004574
2021-12-10 12:04:10,939 iteration 1957 : loss : 0.014617, loss_ce: 0.004451
2021-12-10 12:04:13,704 iteration 1958 : loss : 0.014044, loss_ce: 0.005081
2021-12-10 12:04:16,312 iteration 1959 : loss : 0.012531, loss_ce: 0.004339
2021-12-10 12:04:18,925 iteration 1960 : loss : 0.012214, loss_ce: 0.004021
2021-12-10 12:04:21,549 iteration 1961 : loss : 0.014529, loss_ce: 0.003839
2021-12-10 12:04:24,312 iteration 1962 : loss : 0.015192, loss_ce: 0.006662
2021-12-10 12:04:26,935 iteration 1963 : loss : 0.014913, loss_ce: 0.006441
2021-12-10 12:04:29,683 iteration 1964 : loss : 0.011773, loss_ce: 0.003796
2021-12-10 12:04:32,316 iteration 1965 : loss : 0.011420, loss_ce: 0.005088
2021-12-10 12:04:34,919 iteration 1966 : loss : 0.015489, loss_ce: 0.005096
2021-12-10 12:04:37,673 iteration 1967 : loss : 0.014257, loss_ce: 0.005414
2021-12-10 12:04:40,262 iteration 1968 : loss : 0.011713, loss_ce: 0.005533
2021-12-10 12:04:43,074 iteration 1969 : loss : 0.016772, loss_ce: 0.004472
2021-12-10 12:04:45,669 iteration 1970 : loss : 0.013002, loss_ce: 0.006328
2021-12-10 12:04:48,270 iteration 1971 : loss : 0.014966, loss_ce: 0.007443
2021-12-10 12:04:50,892 iteration 1972 : loss : 0.014219, loss_ce: 0.005535
 29%|███████▊                   | 116/400 [1:38:13<3:58:16, 50.34s/it]2021-12-10 12:04:53,576 iteration 1973 : loss : 0.014006, loss_ce: 0.005300
2021-12-10 12:04:56,327 iteration 1974 : loss : 0.012614, loss_ce: 0.004903
2021-12-10 12:04:58,993 iteration 1975 : loss : 0.012741, loss_ce: 0.005449
2021-12-10 12:05:01,623 iteration 1976 : loss : 0.014274, loss_ce: 0.005420
2021-12-10 12:05:04,412 iteration 1977 : loss : 0.011415, loss_ce: 0.004729
2021-12-10 12:05:07,015 iteration 1978 : loss : 0.016331, loss_ce: 0.006114
2021-12-10 12:05:09,615 iteration 1979 : loss : 0.017001, loss_ce: 0.005153
2021-12-10 12:05:12,412 iteration 1980 : loss : 0.013503, loss_ce: 0.003812
2021-12-10 12:05:15,084 iteration 1981 : loss : 0.012599, loss_ce: 0.005423
2021-12-10 12:05:17,693 iteration 1982 : loss : 0.013637, loss_ce: 0.006493
2021-12-10 12:05:20,322 iteration 1983 : loss : 0.017235, loss_ce: 0.005076
2021-12-10 12:05:22,984 iteration 1984 : loss : 0.011861, loss_ce: 0.005082
2021-12-10 12:05:25,617 iteration 1985 : loss : 0.011787, loss_ce: 0.004198
2021-12-10 12:05:28,395 iteration 1986 : loss : 0.014043, loss_ce: 0.005958
2021-12-10 12:05:31,004 iteration 1987 : loss : 0.014542, loss_ce: 0.004660
2021-12-10 12:05:33,673 iteration 1988 : loss : 0.016056, loss_ce: 0.005569
2021-12-10 12:05:36,334 iteration 1989 : loss : 0.016704, loss_ce: 0.007931
 29%|███████▉                   | 117/400 [1:38:59<3:50:30, 48.87s/it]2021-12-10 12:05:39,108 iteration 1990 : loss : 0.015063, loss_ce: 0.006210
2021-12-10 12:05:41,769 iteration 1991 : loss : 0.018286, loss_ce: 0.007049
2021-12-10 12:05:44,389 iteration 1992 : loss : 0.011631, loss_ce: 0.004958
2021-12-10 12:05:47,050 iteration 1993 : loss : 0.013193, loss_ce: 0.005924
2021-12-10 12:05:49,673 iteration 1994 : loss : 0.016312, loss_ce: 0.005017
2021-12-10 12:05:52,426 iteration 1995 : loss : 0.009826, loss_ce: 0.003661
2021-12-10 12:05:55,028 iteration 1996 : loss : 0.011790, loss_ce: 0.003159
2021-12-10 12:05:57,675 iteration 1997 : loss : 0.012204, loss_ce: 0.003636
2021-12-10 12:06:00,485 iteration 1998 : loss : 0.014197, loss_ce: 0.007789
2021-12-10 12:06:03,095 iteration 1999 : loss : 0.015276, loss_ce: 0.008797
2021-12-10 12:06:05,689 iteration 2000 : loss : 0.016597, loss_ce: 0.007580
2021-12-10 12:06:08,306 iteration 2001 : loss : 0.009618, loss_ce: 0.004481
2021-12-10 12:06:10,957 iteration 2002 : loss : 0.014443, loss_ce: 0.006044
2021-12-10 12:06:13,577 iteration 2003 : loss : 0.011686, loss_ce: 0.004456
2021-12-10 12:06:16,343 iteration 2004 : loss : 0.016571, loss_ce: 0.004440
2021-12-10 12:06:18,973 iteration 2005 : loss : 0.013919, loss_ce: 0.006337
2021-12-10 12:06:21,633 iteration 2006 : loss : 0.012761, loss_ce: 0.005419
 30%|███████▉                   | 118/400 [1:39:44<3:44:39, 47.80s/it]2021-12-10 12:06:24,321 iteration 2007 : loss : 0.012781, loss_ce: 0.004978
2021-12-10 12:06:27,073 iteration 2008 : loss : 0.011074, loss_ce: 0.003397
2021-12-10 12:06:29,700 iteration 2009 : loss : 0.011639, loss_ce: 0.003928
2021-12-10 12:06:32,433 iteration 2010 : loss : 0.010104, loss_ce: 0.003689
2021-12-10 12:06:35,207 iteration 2011 : loss : 0.013377, loss_ce: 0.003870
2021-12-10 12:06:37,808 iteration 2012 : loss : 0.013399, loss_ce: 0.007106
2021-12-10 12:06:40,397 iteration 2013 : loss : 0.012935, loss_ce: 0.003636
2021-12-10 12:06:43,168 iteration 2014 : loss : 0.010917, loss_ce: 0.004410
2021-12-10 12:06:45,791 iteration 2015 : loss : 0.016069, loss_ce: 0.004024
2021-12-10 12:06:48,498 iteration 2016 : loss : 0.011949, loss_ce: 0.004975
2021-12-10 12:06:51,201 iteration 2017 : loss : 0.014444, loss_ce: 0.006178
2021-12-10 12:06:53,802 iteration 2018 : loss : 0.015157, loss_ce: 0.005628
2021-12-10 12:06:56,417 iteration 2019 : loss : 0.012355, loss_ce: 0.005948
2021-12-10 12:06:59,110 iteration 2020 : loss : 0.012589, loss_ce: 0.004993
2021-12-10 12:07:01,796 iteration 2021 : loss : 0.015109, loss_ce: 0.005918
2021-12-10 12:07:04,511 iteration 2022 : loss : 0.017016, loss_ce: 0.005095
2021-12-10 12:07:07,147 iteration 2023 : loss : 0.012338, loss_ce: 0.005300
 30%|████████                   | 119/400 [1:40:29<3:40:38, 47.11s/it]2021-12-10 12:07:09,842 iteration 2024 : loss : 0.015315, loss_ce: 0.005175
2021-12-10 12:07:12,574 iteration 2025 : loss : 0.012636, loss_ce: 0.003953
2021-12-10 12:07:15,200 iteration 2026 : loss : 0.014970, loss_ce: 0.005378
2021-12-10 12:07:17,857 iteration 2027 : loss : 0.013314, loss_ce: 0.006842
2021-12-10 12:07:20,490 iteration 2028 : loss : 0.014551, loss_ce: 0.006797
2021-12-10 12:07:23,279 iteration 2029 : loss : 0.016120, loss_ce: 0.005118
2021-12-10 12:07:25,882 iteration 2030 : loss : 0.014627, loss_ce: 0.004458
2021-12-10 12:07:28,551 iteration 2031 : loss : 0.011459, loss_ce: 0.004150
2021-12-10 12:07:31,178 iteration 2032 : loss : 0.011843, loss_ce: 0.005371
2021-12-10 12:07:33,844 iteration 2033 : loss : 0.019931, loss_ce: 0.006179
2021-12-10 12:07:36,498 iteration 2034 : loss : 0.011687, loss_ce: 0.004657
2021-12-10 12:07:39,162 iteration 2035 : loss : 0.013534, loss_ce: 0.004850
2021-12-10 12:07:41,822 iteration 2036 : loss : 0.014480, loss_ce: 0.006416
2021-12-10 12:07:44,487 iteration 2037 : loss : 0.014064, loss_ce: 0.004679
2021-12-10 12:07:47,116 iteration 2038 : loss : 0.017160, loss_ce: 0.003385
2021-12-10 12:07:49,905 iteration 2039 : loss : 0.012615, loss_ce: 0.005013
2021-12-10 12:07:49,905 Training Data Eval:
2021-12-10 12:08:04,547   Average segmentation loss on training set: 0.0121
2021-12-10 12:08:04,547 Validation Data Eval:
2021-12-10 12:08:09,752   Average segmentation loss on validation set: 0.1173
2021-12-10 12:08:12,399 iteration 2040 : loss : 0.011109, loss_ce: 0.004703
 30%|████████                   | 120/400 [1:41:35<4:05:15, 52.56s/it]2021-12-10 12:08:15,168 iteration 2041 : loss : 0.019005, loss_ce: 0.007576
2021-12-10 12:08:17,794 iteration 2042 : loss : 0.012711, loss_ce: 0.005357
2021-12-10 12:08:20,395 iteration 2043 : loss : 0.010431, loss_ce: 0.003766
2021-12-10 12:08:23,158 iteration 2044 : loss : 0.012652, loss_ce: 0.004334
2021-12-10 12:08:25,762 iteration 2045 : loss : 0.015059, loss_ce: 0.004952
2021-12-10 12:08:28,387 iteration 2046 : loss : 0.013517, loss_ce: 0.004900
2021-12-10 12:08:31,124 iteration 2047 : loss : 0.015429, loss_ce: 0.005848
2021-12-10 12:08:33,827 iteration 2048 : loss : 0.015091, loss_ce: 0.006635
2021-12-10 12:08:36,522 iteration 2049 : loss : 0.017032, loss_ce: 0.007611
2021-12-10 12:08:39,120 iteration 2050 : loss : 0.011907, loss_ce: 0.004700
2021-12-10 12:08:41,738 iteration 2051 : loss : 0.013833, loss_ce: 0.005248
2021-12-10 12:08:44,371 iteration 2052 : loss : 0.018640, loss_ce: 0.006629
2021-12-10 12:08:47,127 iteration 2053 : loss : 0.013302, loss_ce: 0.005334
2021-12-10 12:08:49,766 iteration 2054 : loss : 0.015471, loss_ce: 0.004245
2021-12-10 12:08:52,390 iteration 2055 : loss : 0.012976, loss_ce: 0.004364
2021-12-10 12:08:55,198 iteration 2056 : loss : 0.012064, loss_ce: 0.004441
2021-12-10 12:08:57,812 iteration 2057 : loss : 0.015778, loss_ce: 0.005509
 30%|████████▏                  | 121/400 [1:42:20<3:54:25, 50.41s/it]2021-12-10 12:09:00,601 iteration 2058 : loss : 0.012058, loss_ce: 0.003881
2021-12-10 12:09:03,216 iteration 2059 : loss : 0.012306, loss_ce: 0.005376
2021-12-10 12:09:05,819 iteration 2060 : loss : 0.011738, loss_ce: 0.005216
2021-12-10 12:09:08,599 iteration 2061 : loss : 0.011629, loss_ce: 0.004985
2021-12-10 12:09:11,197 iteration 2062 : loss : 0.015452, loss_ce: 0.005055
2021-12-10 12:09:13,835 iteration 2063 : loss : 0.011303, loss_ce: 0.004912
2021-12-10 12:09:16,426 iteration 2064 : loss : 0.012147, loss_ce: 0.004934
2021-12-10 12:09:19,052 iteration 2065 : loss : 0.013357, loss_ce: 0.005434
2021-12-10 12:09:21,788 iteration 2066 : loss : 0.012791, loss_ce: 0.005623
2021-12-10 12:09:24,419 iteration 2067 : loss : 0.011456, loss_ce: 0.004772
2021-12-10 12:09:27,041 iteration 2068 : loss : 0.013519, loss_ce: 0.005142
2021-12-10 12:09:29,685 iteration 2069 : loss : 0.012299, loss_ce: 0.004314
2021-12-10 12:09:32,292 iteration 2070 : loss : 0.010146, loss_ce: 0.003020
2021-12-10 12:09:35,044 iteration 2071 : loss : 0.020750, loss_ce: 0.006578
2021-12-10 12:09:37,635 iteration 2072 : loss : 0.012538, loss_ce: 0.004926
2021-12-10 12:09:40,358 iteration 2073 : loss : 0.010938, loss_ce: 0.003385
2021-12-10 12:09:42,970 iteration 2074 : loss : 0.010821, loss_ce: 0.003984
 30%|████████▏                  | 122/400 [1:43:05<3:46:15, 48.83s/it]2021-12-10 12:09:45,745 iteration 2075 : loss : 0.011336, loss_ce: 0.004884
2021-12-10 12:09:48,327 iteration 2076 : loss : 0.013161, loss_ce: 0.003818
2021-12-10 12:09:51,031 iteration 2077 : loss : 0.013302, loss_ce: 0.003106
2021-12-10 12:09:53,740 iteration 2078 : loss : 0.010927, loss_ce: 0.003373
2021-12-10 12:09:56,459 iteration 2079 : loss : 0.012294, loss_ce: 0.005053
2021-12-10 12:09:59,064 iteration 2080 : loss : 0.011896, loss_ce: 0.004603
2021-12-10 12:10:01,693 iteration 2081 : loss : 0.012604, loss_ce: 0.003966
2021-12-10 12:10:04,398 iteration 2082 : loss : 0.013782, loss_ce: 0.006931
2021-12-10 12:10:07,135 iteration 2083 : loss : 0.016477, loss_ce: 0.003722
2021-12-10 12:10:09,731 iteration 2084 : loss : 0.014408, loss_ce: 0.004829
2021-12-10 12:10:12,343 iteration 2085 : loss : 0.012119, loss_ce: 0.004202
2021-12-10 12:10:15,007 iteration 2086 : loss : 0.011870, loss_ce: 0.005352
2021-12-10 12:10:17,639 iteration 2087 : loss : 0.013609, loss_ce: 0.004346
2021-12-10 12:10:20,259 iteration 2088 : loss : 0.012819, loss_ce: 0.006161
2021-12-10 12:10:23,056 iteration 2089 : loss : 0.013964, loss_ce: 0.006969
2021-12-10 12:10:25,675 iteration 2090 : loss : 0.012651, loss_ce: 0.003737
2021-12-10 12:10:28,279 iteration 2091 : loss : 0.011540, loss_ce: 0.004054
 31%|████████▎                  | 123/400 [1:43:51<3:40:34, 47.78s/it]2021-12-10 12:10:31,110 iteration 2092 : loss : 0.014800, loss_ce: 0.004638
2021-12-10 12:10:33,713 iteration 2093 : loss : 0.013252, loss_ce: 0.005874
2021-12-10 12:10:36,435 iteration 2094 : loss : 0.012063, loss_ce: 0.005244
2021-12-10 12:10:39,034 iteration 2095 : loss : 0.012134, loss_ce: 0.004058
2021-12-10 12:10:41,656 iteration 2096 : loss : 0.010483, loss_ce: 0.003693
2021-12-10 12:10:44,318 iteration 2097 : loss : 0.012990, loss_ce: 0.003340
2021-12-10 12:10:46,942 iteration 2098 : loss : 0.016386, loss_ce: 0.007167
2021-12-10 12:10:49,567 iteration 2099 : loss : 0.011078, loss_ce: 0.005016
2021-12-10 12:10:52,310 iteration 2100 : loss : 0.010001, loss_ce: 0.002561
2021-12-10 12:10:54,942 iteration 2101 : loss : 0.011891, loss_ce: 0.004273
2021-12-10 12:10:57,597 iteration 2102 : loss : 0.014286, loss_ce: 0.007116
2021-12-10 12:11:00,231 iteration 2103 : loss : 0.011430, loss_ce: 0.004302
2021-12-10 12:11:02,872 iteration 2104 : loss : 0.009910, loss_ce: 0.003475
2021-12-10 12:11:05,494 iteration 2105 : loss : 0.013434, loss_ce: 0.005203
2021-12-10 12:11:08,259 iteration 2106 : loss : 0.011525, loss_ce: 0.004966
2021-12-10 12:11:10,891 iteration 2107 : loss : 0.013722, loss_ce: 0.005389
2021-12-10 12:11:13,593 iteration 2108 : loss : 0.012183, loss_ce: 0.005399
 31%|████████▎                  | 124/400 [1:44:36<3:36:22, 47.04s/it]2021-12-10 12:11:16,264 iteration 2109 : loss : 0.012163, loss_ce: 0.005108
2021-12-10 12:11:18,928 iteration 2110 : loss : 0.011073, loss_ce: 0.005140
2021-12-10 12:11:21,591 iteration 2111 : loss : 0.009405, loss_ce: 0.003415
2021-12-10 12:11:24,219 iteration 2112 : loss : 0.011619, loss_ce: 0.004614
2021-12-10 12:11:26,825 iteration 2113 : loss : 0.013385, loss_ce: 0.004172
2021-12-10 12:11:29,586 iteration 2114 : loss : 0.010609, loss_ce: 0.004198
2021-12-10 12:11:32,180 iteration 2115 : loss : 0.012281, loss_ce: 0.003896
2021-12-10 12:11:34,800 iteration 2116 : loss : 0.012893, loss_ce: 0.004306
2021-12-10 12:11:37,467 iteration 2117 : loss : 0.014287, loss_ce: 0.004152
2021-12-10 12:11:40,124 iteration 2118 : loss : 0.010149, loss_ce: 0.003988
2021-12-10 12:11:42,730 iteration 2119 : loss : 0.013551, loss_ce: 0.004608
2021-12-10 12:11:45,359 iteration 2120 : loss : 0.014454, loss_ce: 0.006471
2021-12-10 12:11:48,079 iteration 2121 : loss : 0.011805, loss_ce: 0.006545
2021-12-10 12:11:50,702 iteration 2122 : loss : 0.011725, loss_ce: 0.004184
2021-12-10 12:11:53,470 iteration 2123 : loss : 0.010920, loss_ce: 0.003411
2021-12-10 12:11:56,075 iteration 2124 : loss : 0.015320, loss_ce: 0.005140
2021-12-10 12:11:56,075 Training Data Eval:
2021-12-10 12:12:10,793   Average segmentation loss on training set: 0.0119
2021-12-10 12:12:10,793 Validation Data Eval:
2021-12-10 12:12:15,966   Average segmentation loss on validation set: 0.1078
2021-12-10 12:12:18,561 iteration 2125 : loss : 0.011393, loss_ce: 0.005014
 31%|████████▍                  | 125/400 [1:45:41<4:00:14, 52.42s/it]2021-12-10 12:12:21,222 iteration 2126 : loss : 0.010415, loss_ce: 0.004695
2021-12-10 12:12:23,847 iteration 2127 : loss : 0.011530, loss_ce: 0.005448
2021-12-10 12:12:26,600 iteration 2128 : loss : 0.012445, loss_ce: 0.005331
2021-12-10 12:12:29,194 iteration 2129 : loss : 0.011024, loss_ce: 0.003640
2021-12-10 12:12:31,815 iteration 2130 : loss : 0.011853, loss_ce: 0.004321
2021-12-10 12:12:34,476 iteration 2131 : loss : 0.011240, loss_ce: 0.003808
2021-12-10 12:12:37,106 iteration 2132 : loss : 0.014824, loss_ce: 0.002479
2021-12-10 12:12:39,725 iteration 2133 : loss : 0.014714, loss_ce: 0.005634
2021-12-10 12:12:42,491 iteration 2134 : loss : 0.012764, loss_ce: 0.005772
2021-12-10 12:12:45,089 iteration 2135 : loss : 0.011139, loss_ce: 0.004819
2021-12-10 12:12:47,709 iteration 2136 : loss : 0.017634, loss_ce: 0.006001
2021-12-10 12:12:50,332 iteration 2137 : loss : 0.012388, loss_ce: 0.004984
2021-12-10 12:12:53,086 iteration 2138 : loss : 0.011434, loss_ce: 0.004685
2021-12-10 12:12:55,672 iteration 2139 : loss : 0.011418, loss_ce: 0.004729
2021-12-10 12:12:58,286 iteration 2140 : loss : 0.012447, loss_ce: 0.004582
2021-12-10 12:13:01,059 iteration 2141 : loss : 0.011180, loss_ce: 0.003873
2021-12-10 12:13:03,659 iteration 2142 : loss : 0.014726, loss_ce: 0.004666
 32%|████████▌                  | 126/400 [1:46:26<3:49:20, 50.22s/it]2021-12-10 12:13:06,333 iteration 2143 : loss : 0.011769, loss_ce: 0.003477
2021-12-10 12:13:08,937 iteration 2144 : loss : 0.011609, loss_ce: 0.006032
2021-12-10 12:13:11,709 iteration 2145 : loss : 0.011694, loss_ce: 0.003653
2021-12-10 12:13:14,306 iteration 2146 : loss : 0.014859, loss_ce: 0.004246
2021-12-10 12:13:16,925 iteration 2147 : loss : 0.013215, loss_ce: 0.004753
2021-12-10 12:13:19,547 iteration 2148 : loss : 0.012321, loss_ce: 0.007143
2021-12-10 12:13:22,254 iteration 2149 : loss : 0.011377, loss_ce: 0.005217
2021-12-10 12:13:24,984 iteration 2150 : loss : 0.011378, loss_ce: 0.004608
2021-12-10 12:13:27,577 iteration 2151 : loss : 0.015180, loss_ce: 0.004621
2021-12-10 12:13:30,196 iteration 2152 : loss : 0.013040, loss_ce: 0.003143
2021-12-10 12:13:32,907 iteration 2153 : loss : 0.011602, loss_ce: 0.004696
2021-12-10 12:13:35,507 iteration 2154 : loss : 0.010683, loss_ce: 0.004685
2021-12-10 12:13:38,169 iteration 2155 : loss : 0.010152, loss_ce: 0.003749
2021-12-10 12:13:40,818 iteration 2156 : loss : 0.014216, loss_ce: 0.004472
2021-12-10 12:13:43,446 iteration 2157 : loss : 0.009524, loss_ce: 0.004358
2021-12-10 12:13:46,049 iteration 2158 : loss : 0.009731, loss_ce: 0.002405
2021-12-10 12:13:48,815 iteration 2159 : loss : 0.012440, loss_ce: 0.004988
 32%|████████▌                  | 127/400 [1:47:11<3:41:35, 48.70s/it]2021-12-10 12:13:51,597 iteration 2160 : loss : 0.011477, loss_ce: 0.003750
2021-12-10 12:13:54,190 iteration 2161 : loss : 0.010662, loss_ce: 0.002927
2021-12-10 12:13:56,805 iteration 2162 : loss : 0.010087, loss_ce: 0.003316
2021-12-10 12:13:59,446 iteration 2163 : loss : 0.011883, loss_ce: 0.004321
2021-12-10 12:14:02,050 iteration 2164 : loss : 0.015743, loss_ce: 0.003845
2021-12-10 12:14:04,673 iteration 2165 : loss : 0.010771, loss_ce: 0.004008
2021-12-10 12:14:07,428 iteration 2166 : loss : 0.012789, loss_ce: 0.006338
2021-12-10 12:14:10,023 iteration 2167 : loss : 0.011111, loss_ce: 0.005022
2021-12-10 12:14:12,623 iteration 2168 : loss : 0.010221, loss_ce: 0.004427
2021-12-10 12:14:15,280 iteration 2169 : loss : 0.014955, loss_ce: 0.003084
2021-12-10 12:14:18,060 iteration 2170 : loss : 0.015452, loss_ce: 0.005785
2021-12-10 12:14:20,660 iteration 2171 : loss : 0.015758, loss_ce: 0.007504
2021-12-10 12:14:23,349 iteration 2172 : loss : 0.010450, loss_ce: 0.004370
2021-12-10 12:14:25,925 iteration 2173 : loss : 0.012429, loss_ce: 0.004614
2021-12-10 12:14:28,582 iteration 2174 : loss : 0.019279, loss_ce: 0.005000
2021-12-10 12:14:31,210 iteration 2175 : loss : 0.019006, loss_ce: 0.006955
2021-12-10 12:14:33,994 iteration 2176 : loss : 0.014421, loss_ce: 0.005721
 32%|████████▋                  | 128/400 [1:47:56<3:35:59, 47.65s/it]2021-12-10 12:14:36,659 iteration 2177 : loss : 0.012462, loss_ce: 0.004022
2021-12-10 12:14:39,281 iteration 2178 : loss : 0.018266, loss_ce: 0.005181
2021-12-10 12:14:41,888 iteration 2179 : loss : 0.011590, loss_ce: 0.004146
2021-12-10 12:14:44,657 iteration 2180 : loss : 0.012861, loss_ce: 0.003832
2021-12-10 12:14:47,248 iteration 2181 : loss : 0.016088, loss_ce: 0.005504
2021-12-10 12:14:49,978 iteration 2182 : loss : 0.016494, loss_ce: 0.005156
2021-12-10 12:14:52,569 iteration 2183 : loss : 0.012205, loss_ce: 0.005052
2021-12-10 12:14:55,186 iteration 2184 : loss : 0.010521, loss_ce: 0.004064
2021-12-10 12:14:57,930 iteration 2185 : loss : 0.012266, loss_ce: 0.004694
2021-12-10 12:15:00,655 iteration 2186 : loss : 0.015715, loss_ce: 0.006928
2021-12-10 12:15:03,250 iteration 2187 : loss : 0.013015, loss_ce: 0.004886
2021-12-10 12:15:05,936 iteration 2188 : loss : 0.014079, loss_ce: 0.004206
2021-12-10 12:15:08,507 iteration 2189 : loss : 0.013553, loss_ce: 0.004487
2021-12-10 12:15:11,166 iteration 2190 : loss : 0.013746, loss_ce: 0.005776
2021-12-10 12:15:13,837 iteration 2191 : loss : 0.012624, loss_ce: 0.003966
2021-12-10 12:15:16,470 iteration 2192 : loss : 0.010175, loss_ce: 0.003814
2021-12-10 12:15:19,071 iteration 2193 : loss : 0.018260, loss_ce: 0.008605
 32%|████████▋                  | 129/400 [1:48:41<3:31:43, 46.88s/it]2021-12-10 12:15:21,796 iteration 2194 : loss : 0.011743, loss_ce: 0.004942
2021-12-10 12:15:24,420 iteration 2195 : loss : 0.012535, loss_ce: 0.004870
2021-12-10 12:15:27,211 iteration 2196 : loss : 0.013181, loss_ce: 0.005455
2021-12-10 12:15:29,836 iteration 2197 : loss : 0.012476, loss_ce: 0.004937
2021-12-10 12:15:32,432 iteration 2198 : loss : 0.020467, loss_ce: 0.006849
2021-12-10 12:15:35,219 iteration 2199 : loss : 0.011277, loss_ce: 0.004898
2021-12-10 12:15:37,820 iteration 2200 : loss : 0.011960, loss_ce: 0.003838
2021-12-10 12:15:40,486 iteration 2201 : loss : 0.011082, loss_ce: 0.003999
2021-12-10 12:15:43,131 iteration 2202 : loss : 0.012871, loss_ce: 0.005272
2021-12-10 12:15:45,733 iteration 2203 : loss : 0.012782, loss_ce: 0.004533
2021-12-10 12:15:48,370 iteration 2204 : loss : 0.012443, loss_ce: 0.003851
2021-12-10 12:15:50,988 iteration 2205 : loss : 0.014179, loss_ce: 0.004821
2021-12-10 12:15:53,744 iteration 2206 : loss : 0.011856, loss_ce: 0.004077
2021-12-10 12:15:56,339 iteration 2207 : loss : 0.011608, loss_ce: 0.004061
2021-12-10 12:15:58,991 iteration 2208 : loss : 0.012112, loss_ce: 0.005571
2021-12-10 12:16:01,584 iteration 2209 : loss : 0.012986, loss_ce: 0.007058
2021-12-10 12:16:01,584 Training Data Eval:
2021-12-10 12:16:16,244   Average segmentation loss on training set: 0.0131
2021-12-10 12:16:16,245 Validation Data Eval:
2021-12-10 12:16:21,324   Average segmentation loss on validation set: 0.0953
2021-12-10 12:16:24,088 iteration 2210 : loss : 0.011994, loss_ce: 0.004050
 32%|████████▊                  | 130/400 [1:49:46<3:55:25, 52.32s/it]2021-12-10 12:16:26,852 iteration 2211 : loss : 0.011418, loss_ce: 0.005423
2021-12-10 12:16:29,438 iteration 2212 : loss : 0.009677, loss_ce: 0.004124
2021-12-10 12:16:32,060 iteration 2213 : loss : 0.011350, loss_ce: 0.005545
2021-12-10 12:16:34,673 iteration 2214 : loss : 0.011093, loss_ce: 0.005129
2021-12-10 12:16:37,402 iteration 2215 : loss : 0.009683, loss_ce: 0.003851
2021-12-10 12:16:40,022 iteration 2216 : loss : 0.010137, loss_ce: 0.004346
2021-12-10 12:16:42,805 iteration 2217 : loss : 0.012915, loss_ce: 0.004279
2021-12-10 12:16:45,403 iteration 2218 : loss : 0.013570, loss_ce: 0.004328
2021-12-10 12:16:48,115 iteration 2219 : loss : 0.013842, loss_ce: 0.004701
2021-12-10 12:16:50,714 iteration 2220 : loss : 0.013437, loss_ce: 0.005107
2021-12-10 12:16:53,319 iteration 2221 : loss : 0.011103, loss_ce: 0.002856
2021-12-10 12:16:56,048 iteration 2222 : loss : 0.015659, loss_ce: 0.006827
2021-12-10 12:16:58,709 iteration 2223 : loss : 0.018533, loss_ce: 0.009753
2021-12-10 12:17:01,371 iteration 2224 : loss : 0.014883, loss_ce: 0.004620
2021-12-10 12:17:03,995 iteration 2225 : loss : 0.015982, loss_ce: 0.007539
2021-12-10 12:17:06,700 iteration 2226 : loss : 0.017192, loss_ce: 0.004959
2021-12-10 12:17:09,398 iteration 2227 : loss : 0.014164, loss_ce: 0.005561
 33%|████████▊                  | 131/400 [1:50:32<3:45:07, 50.21s/it]2021-12-10 12:17:12,156 iteration 2228 : loss : 0.013180, loss_ce: 0.005855
2021-12-10 12:17:14,749 iteration 2229 : loss : 0.013574, loss_ce: 0.005424
2021-12-10 12:17:17,337 iteration 2230 : loss : 0.012427, loss_ce: 0.005356
2021-12-10 12:17:20,101 iteration 2231 : loss : 0.012660, loss_ce: 0.004407
2021-12-10 12:17:22,688 iteration 2232 : loss : 0.014367, loss_ce: 0.004065
2021-12-10 12:17:25,310 iteration 2233 : loss : 0.012024, loss_ce: 0.004094
2021-12-10 12:17:27,968 iteration 2234 : loss : 0.013829, loss_ce: 0.005690
2021-12-10 12:17:30,571 iteration 2235 : loss : 0.013671, loss_ce: 0.007016
2021-12-10 12:17:33,189 iteration 2236 : loss : 0.012307, loss_ce: 0.005433
2021-12-10 12:17:35,946 iteration 2237 : loss : 0.014440, loss_ce: 0.005978
2021-12-10 12:17:38,541 iteration 2238 : loss : 0.014299, loss_ce: 0.005449
2021-12-10 12:17:41,339 iteration 2239 : loss : 0.013146, loss_ce: 0.004139
2021-12-10 12:17:43,947 iteration 2240 : loss : 0.012600, loss_ce: 0.004826
2021-12-10 12:17:46,574 iteration 2241 : loss : 0.014173, loss_ce: 0.005798
2021-12-10 12:17:49,298 iteration 2242 : loss : 0.010619, loss_ce: 0.003356
2021-12-10 12:17:51,905 iteration 2243 : loss : 0.011069, loss_ce: 0.004115
2021-12-10 12:17:54,542 iteration 2244 : loss : 0.013929, loss_ce: 0.004857
 33%|████████▉                  | 132/400 [1:51:17<3:37:29, 48.69s/it]2021-12-10 12:17:57,375 iteration 2245 : loss : 0.013978, loss_ce: 0.004749
2021-12-10 12:17:59,969 iteration 2246 : loss : 0.010053, loss_ce: 0.004288
2021-12-10 12:18:02,537 iteration 2247 : loss : 0.012255, loss_ce: 0.004068
2021-12-10 12:18:05,154 iteration 2248 : loss : 0.010432, loss_ce: 0.003758
2021-12-10 12:18:07,917 iteration 2249 : loss : 0.013286, loss_ce: 0.004907
2021-12-10 12:18:10,509 iteration 2250 : loss : 0.011302, loss_ce: 0.003768
2021-12-10 12:18:13,128 iteration 2251 : loss : 0.013113, loss_ce: 0.006313
2021-12-10 12:18:15,887 iteration 2252 : loss : 0.015310, loss_ce: 0.004227
2021-12-10 12:18:18,483 iteration 2253 : loss : 0.011877, loss_ce: 0.004445
2021-12-10 12:18:21,099 iteration 2254 : loss : 0.011645, loss_ce: 0.004715
2021-12-10 12:18:23,855 iteration 2255 : loss : 0.010169, loss_ce: 0.003299
2021-12-10 12:18:26,517 iteration 2256 : loss : 0.013001, loss_ce: 0.004240
2021-12-10 12:18:29,165 iteration 2257 : loss : 0.015421, loss_ce: 0.003940
2021-12-10 12:18:31,757 iteration 2258 : loss : 0.012804, loss_ce: 0.005578
2021-12-10 12:18:34,419 iteration 2259 : loss : 0.012037, loss_ce: 0.005713
2021-12-10 12:18:37,113 iteration 2260 : loss : 0.011718, loss_ce: 0.003625
2021-12-10 12:18:39,814 iteration 2261 : loss : 0.010955, loss_ce: 0.005204
 33%|████████▉                  | 133/400 [1:52:02<3:32:06, 47.67s/it]2021-12-10 12:18:42,448 iteration 2262 : loss : 0.009311, loss_ce: 0.003341
2021-12-10 12:18:45,063 iteration 2263 : loss : 0.010981, loss_ce: 0.004164
2021-12-10 12:18:47,821 iteration 2264 : loss : 0.011483, loss_ce: 0.005157
2021-12-10 12:18:50,452 iteration 2265 : loss : 0.012133, loss_ce: 0.003860
2021-12-10 12:18:53,071 iteration 2266 : loss : 0.011273, loss_ce: 0.004693
2021-12-10 12:18:55,835 iteration 2267 : loss : 0.009141, loss_ce: 0.002484
2021-12-10 12:18:58,434 iteration 2268 : loss : 0.013133, loss_ce: 0.004938
2021-12-10 12:19:01,051 iteration 2269 : loss : 0.010649, loss_ce: 0.004830
2021-12-10 12:19:03,815 iteration 2270 : loss : 0.009302, loss_ce: 0.003574
2021-12-10 12:19:06,412 iteration 2271 : loss : 0.011366, loss_ce: 0.003418
2021-12-10 12:19:09,033 iteration 2272 : loss : 0.014609, loss_ce: 0.006269
2021-12-10 12:19:11,845 iteration 2273 : loss : 0.013337, loss_ce: 0.005514
2021-12-10 12:19:14,435 iteration 2274 : loss : 0.013268, loss_ce: 0.004326
2021-12-10 12:19:17,047 iteration 2275 : loss : 0.010685, loss_ce: 0.003895
2021-12-10 12:19:19,793 iteration 2276 : loss : 0.011122, loss_ce: 0.004071
2021-12-10 12:19:22,393 iteration 2277 : loss : 0.013595, loss_ce: 0.003437
2021-12-10 12:19:25,016 iteration 2278 : loss : 0.011173, loss_ce: 0.004400
 34%|█████████                  | 134/400 [1:52:47<3:28:02, 46.93s/it]2021-12-10 12:19:27,860 iteration 2279 : loss : 0.011330, loss_ce: 0.004436
2021-12-10 12:19:30,495 iteration 2280 : loss : 0.011536, loss_ce: 0.005366
2021-12-10 12:19:33,116 iteration 2281 : loss : 0.014535, loss_ce: 0.002602
2021-12-10 12:19:35,880 iteration 2282 : loss : 0.010249, loss_ce: 0.003910
2021-12-10 12:19:38,479 iteration 2283 : loss : 0.014474, loss_ce: 0.005470
2021-12-10 12:19:41,100 iteration 2284 : loss : 0.014534, loss_ce: 0.005567
2021-12-10 12:19:43,868 iteration 2285 : loss : 0.013652, loss_ce: 0.004909
2021-12-10 12:19:46,470 iteration 2286 : loss : 0.009969, loss_ce: 0.003152
2021-12-10 12:19:49,091 iteration 2287 : loss : 0.010373, loss_ce: 0.004297
2021-12-10 12:19:51,861 iteration 2288 : loss : 0.013366, loss_ce: 0.004593
2021-12-10 12:19:54,484 iteration 2289 : loss : 0.010071, loss_ce: 0.003484
2021-12-10 12:19:57,129 iteration 2290 : loss : 0.009654, loss_ce: 0.004159
2021-12-10 12:19:59,743 iteration 2291 : loss : 0.014503, loss_ce: 0.005856
2021-12-10 12:20:02,442 iteration 2292 : loss : 0.010342, loss_ce: 0.004553
2021-12-10 12:20:05,207 iteration 2293 : loss : 0.009112, loss_ce: 0.002484
2021-12-10 12:20:07,806 iteration 2294 : loss : 0.010946, loss_ce: 0.003699
2021-12-10 12:20:07,806 Training Data Eval:
2021-12-10 12:20:22,650   Average segmentation loss on training set: 0.0105
2021-12-10 12:20:22,650 Validation Data Eval:
2021-12-10 12:20:27,756   Average segmentation loss on validation set: 0.1152
2021-12-10 12:20:30,548 iteration 2295 : loss : 0.010054, loss_ce: 0.003307
 34%|█████████                  | 135/400 [1:53:53<3:51:54, 52.51s/it]2021-12-10 12:20:33,176 iteration 2296 : loss : 0.012043, loss_ce: 0.005684
2021-12-10 12:20:35,794 iteration 2297 : loss : 0.009010, loss_ce: 0.003516
2021-12-10 12:20:38,561 iteration 2298 : loss : 0.008053, loss_ce: 0.002705
2021-12-10 12:20:41,185 iteration 2299 : loss : 0.011643, loss_ce: 0.003298
2021-12-10 12:20:43,808 iteration 2300 : loss : 0.009855, loss_ce: 0.003267
2021-12-10 12:20:46,575 iteration 2301 : loss : 0.011400, loss_ce: 0.003923
2021-12-10 12:20:49,173 iteration 2302 : loss : 0.010431, loss_ce: 0.004745
2021-12-10 12:20:51,791 iteration 2303 : loss : 0.010672, loss_ce: 0.004314
2021-12-10 12:20:54,566 iteration 2304 : loss : 0.011159, loss_ce: 0.004192
2021-12-10 12:20:57,156 iteration 2305 : loss : 0.008855, loss_ce: 0.003666
2021-12-10 12:20:59,770 iteration 2306 : loss : 0.009519, loss_ce: 0.003746
2021-12-10 12:21:02,392 iteration 2307 : loss : 0.010591, loss_ce: 0.004865
2021-12-10 12:21:05,174 iteration 2308 : loss : 0.010234, loss_ce: 0.004051
2021-12-10 12:21:07,839 iteration 2309 : loss : 0.009773, loss_ce: 0.003288
2021-12-10 12:21:10,638 iteration 2310 : loss : 0.011546, loss_ce: 0.004329
2021-12-10 12:21:13,247 iteration 2311 : loss : 0.009989, loss_ce: 0.003799
2021-12-10 12:21:15,878 iteration 2312 : loss : 0.013259, loss_ce: 0.003501
 34%|█████████▏                 | 136/400 [1:54:38<3:41:33, 50.36s/it]2021-12-10 12:21:18,602 iteration 2313 : loss : 0.008647, loss_ce: 0.002729
2021-12-10 12:21:21,226 iteration 2314 : loss : 0.009634, loss_ce: 0.004808
2021-12-10 12:21:24,011 iteration 2315 : loss : 0.011952, loss_ce: 0.004612
2021-12-10 12:21:26,614 iteration 2316 : loss : 0.012608, loss_ce: 0.005462
2021-12-10 12:21:29,258 iteration 2317 : loss : 0.014762, loss_ce: 0.003470
2021-12-10 12:21:31,882 iteration 2318 : loss : 0.010287, loss_ce: 0.004139
2021-12-10 12:21:34,664 iteration 2319 : loss : 0.009383, loss_ce: 0.004237
2021-12-10 12:21:37,286 iteration 2320 : loss : 0.010764, loss_ce: 0.004080
2021-12-10 12:21:40,105 iteration 2321 : loss : 0.011535, loss_ce: 0.003884
2021-12-10 12:21:42,744 iteration 2322 : loss : 0.010930, loss_ce: 0.004396
2021-12-10 12:21:45,343 iteration 2323 : loss : 0.011753, loss_ce: 0.003896
2021-12-10 12:21:47,959 iteration 2324 : loss : 0.012228, loss_ce: 0.004547
2021-12-10 12:21:50,772 iteration 2325 : loss : 0.007935, loss_ce: 0.001756
2021-12-10 12:21:53,373 iteration 2326 : loss : 0.016067, loss_ce: 0.007539
2021-12-10 12:21:56,080 iteration 2327 : loss : 0.012541, loss_ce: 0.005259
2021-12-10 12:21:58,748 iteration 2328 : loss : 0.013289, loss_ce: 0.004806
2021-12-10 12:22:01,371 iteration 2329 : loss : 0.012444, loss_ce: 0.005733
 34%|█████████▏                 | 137/400 [1:55:24<3:34:20, 48.90s/it]2021-12-10 12:22:04,201 iteration 2330 : loss : 0.010866, loss_ce: 0.003999
2021-12-10 12:22:06,791 iteration 2331 : loss : 0.011803, loss_ce: 0.004124
2021-12-10 12:22:09,537 iteration 2332 : loss : 0.012431, loss_ce: 0.004624
2021-12-10 12:22:12,124 iteration 2333 : loss : 0.010773, loss_ce: 0.005008
2021-12-10 12:22:14,818 iteration 2334 : loss : 0.014183, loss_ce: 0.005164
2021-12-10 12:22:17,403 iteration 2335 : loss : 0.011282, loss_ce: 0.004537
2021-12-10 12:22:20,058 iteration 2336 : loss : 0.010732, loss_ce: 0.004128
2021-12-10 12:22:22,711 iteration 2337 : loss : 0.013333, loss_ce: 0.004289
2021-12-10 12:22:25,332 iteration 2338 : loss : 0.013309, loss_ce: 0.004101
2021-12-10 12:22:28,086 iteration 2339 : loss : 0.010903, loss_ce: 0.004927
2021-12-10 12:22:30,771 iteration 2340 : loss : 0.011832, loss_ce: 0.004901
2021-12-10 12:22:33,340 iteration 2341 : loss : 0.012151, loss_ce: 0.003235
2021-12-10 12:22:36,048 iteration 2342 : loss : 0.010649, loss_ce: 0.005004
2021-12-10 12:22:38,657 iteration 2343 : loss : 0.009828, loss_ce: 0.003724
2021-12-10 12:22:41,328 iteration 2344 : loss : 0.008954, loss_ce: 0.003410
2021-12-10 12:22:43,991 iteration 2345 : loss : 0.012030, loss_ce: 0.005129
2021-12-10 12:22:46,618 iteration 2346 : loss : 0.013730, loss_ce: 0.003145
 34%|█████████▎                 | 138/400 [1:56:09<3:28:43, 47.80s/it]2021-12-10 12:22:49,299 iteration 2347 : loss : 0.010459, loss_ce: 0.003621
2021-12-10 12:22:52,073 iteration 2348 : loss : 0.008820, loss_ce: 0.003458
2021-12-10 12:22:54,679 iteration 2349 : loss : 0.009824, loss_ce: 0.002918
2021-12-10 12:22:57,346 iteration 2350 : loss : 0.014501, loss_ce: 0.004117
2021-12-10 12:22:59,951 iteration 2351 : loss : 0.010206, loss_ce: 0.004024
2021-12-10 12:23:02,575 iteration 2352 : loss : 0.011665, loss_ce: 0.005285
2021-12-10 12:23:05,214 iteration 2353 : loss : 0.008543, loss_ce: 0.003344
2021-12-10 12:23:07,835 iteration 2354 : loss : 0.012218, loss_ce: 0.004657
2021-12-10 12:23:10,596 iteration 2355 : loss : 0.010475, loss_ce: 0.004622
2021-12-10 12:23:13,226 iteration 2356 : loss : 0.012987, loss_ce: 0.004550
2021-12-10 12:23:15,845 iteration 2357 : loss : 0.012733, loss_ce: 0.004553
2021-12-10 12:23:18,467 iteration 2358 : loss : 0.014929, loss_ce: 0.004945
2021-12-10 12:23:21,218 iteration 2359 : loss : 0.012842, loss_ce: 0.002620
2021-12-10 12:23:23,819 iteration 2360 : loss : 0.013960, loss_ce: 0.006343
2021-12-10 12:23:26,427 iteration 2361 : loss : 0.016547, loss_ce: 0.006201
2021-12-10 12:23:29,120 iteration 2362 : loss : 0.014992, loss_ce: 0.007073
2021-12-10 12:23:31,767 iteration 2363 : loss : 0.010439, loss_ce: 0.004613
 35%|█████████▍                 | 139/400 [1:56:54<3:24:28, 47.01s/it]2021-12-10 12:23:34,397 iteration 2364 : loss : 0.010087, loss_ce: 0.003874
2021-12-10 12:23:37,166 iteration 2365 : loss : 0.013725, loss_ce: 0.004708
2021-12-10 12:23:39,798 iteration 2366 : loss : 0.012643, loss_ce: 0.006489
2021-12-10 12:23:42,601 iteration 2367 : loss : 0.011956, loss_ce: 0.005599
2021-12-10 12:23:45,216 iteration 2368 : loss : 0.014987, loss_ce: 0.005534
2021-12-10 12:23:47,818 iteration 2369 : loss : 0.010255, loss_ce: 0.003140
2021-12-10 12:23:50,433 iteration 2370 : loss : 0.008901, loss_ce: 0.002436
2021-12-10 12:23:53,186 iteration 2371 : loss : 0.010708, loss_ce: 0.004421
2021-12-10 12:23:55,779 iteration 2372 : loss : 0.012493, loss_ce: 0.004377
2021-12-10 12:23:58,462 iteration 2373 : loss : 0.011066, loss_ce: 0.003698
2021-12-10 12:24:01,063 iteration 2374 : loss : 0.011352, loss_ce: 0.004592
2021-12-10 12:24:03,685 iteration 2375 : loss : 0.010760, loss_ce: 0.004216
2021-12-10 12:24:06,341 iteration 2376 : loss : 0.010790, loss_ce: 0.004714
2021-12-10 12:24:09,121 iteration 2377 : loss : 0.011129, loss_ce: 0.003915
2021-12-10 12:24:11,724 iteration 2378 : loss : 0.010552, loss_ce: 0.003428
2021-12-10 12:24:14,451 iteration 2379 : loss : 0.013137, loss_ce: 0.005651
2021-12-10 12:24:14,451 Training Data Eval:
2021-12-10 12:24:29,141   Average segmentation loss on training set: 0.0120
2021-12-10 12:24:29,141 Validation Data Eval:
2021-12-10 12:24:34,360   Average segmentation loss on validation set: 0.0992
2021-12-10 12:24:36,994 iteration 2380 : loss : 0.011362, loss_ce: 0.005856
 35%|█████████▍                 | 140/400 [1:57:59<3:47:23, 52.47s/it]2021-12-10 12:24:39,721 iteration 2381 : loss : 0.011524, loss_ce: 0.005553
2021-12-10 12:24:42,385 iteration 2382 : loss : 0.012992, loss_ce: 0.006092
2021-12-10 12:24:45,170 iteration 2383 : loss : 0.009647, loss_ce: 0.004733
2021-12-10 12:24:47,799 iteration 2384 : loss : 0.011414, loss_ce: 0.003308
2021-12-10 12:24:50,411 iteration 2385 : loss : 0.010561, loss_ce: 0.003343
2021-12-10 12:24:53,170 iteration 2386 : loss : 0.011600, loss_ce: 0.003323
2021-12-10 12:24:55,780 iteration 2387 : loss : 0.008431, loss_ce: 0.002990
2021-12-10 12:24:58,556 iteration 2388 : loss : 0.009964, loss_ce: 0.003561
2021-12-10 12:25:01,334 iteration 2389 : loss : 0.011258, loss_ce: 0.005158
2021-12-10 12:25:03,933 iteration 2390 : loss : 0.010057, loss_ce: 0.004621
2021-12-10 12:25:06,690 iteration 2391 : loss : 0.010201, loss_ce: 0.003833
2021-12-10 12:25:09,495 iteration 2392 : loss : 0.010927, loss_ce: 0.004006
2021-12-10 12:25:12,121 iteration 2393 : loss : 0.011350, loss_ce: 0.004434
2021-12-10 12:25:14,881 iteration 2394 : loss : 0.009695, loss_ce: 0.003912
2021-12-10 12:25:17,610 iteration 2395 : loss : 0.013423, loss_ce: 0.004396
2021-12-10 12:25:20,388 iteration 2396 : loss : 0.008724, loss_ce: 0.003822
2021-12-10 12:25:23,023 iteration 2397 : loss : 0.010151, loss_ce: 0.004244
 35%|█████████▌                 | 141/400 [1:58:45<3:38:09, 50.54s/it]2021-12-10 12:25:25,802 iteration 2398 : loss : 0.009063, loss_ce: 0.003461
2021-12-10 12:25:28,585 iteration 2399 : loss : 0.010357, loss_ce: 0.005181
2021-12-10 12:25:31,389 iteration 2400 : loss : 0.011666, loss_ce: 0.005318
2021-12-10 12:25:34,161 iteration 2401 : loss : 0.010592, loss_ce: 0.004121
2021-12-10 12:25:36,948 iteration 2402 : loss : 0.009187, loss_ce: 0.003571
2021-12-10 12:25:39,575 iteration 2403 : loss : 0.008320, loss_ce: 0.003393
2021-12-10 12:25:42,331 iteration 2404 : loss : 0.020451, loss_ce: 0.005997
2021-12-10 12:25:45,067 iteration 2405 : loss : 0.009019, loss_ce: 0.003709
2021-12-10 12:25:47,840 iteration 2406 : loss : 0.013189, loss_ce: 0.005111
2021-12-10 12:25:50,575 iteration 2407 : loss : 0.018553, loss_ce: 0.004930
2021-12-10 12:25:53,337 iteration 2408 : loss : 0.009117, loss_ce: 0.002523
2021-12-10 12:25:56,055 iteration 2409 : loss : 0.010900, loss_ce: 0.003018
2021-12-10 12:25:58,919 iteration 2410 : loss : 0.013121, loss_ce: 0.003897
2021-12-10 12:26:01,643 iteration 2411 : loss : 0.010653, loss_ce: 0.002993
2021-12-10 12:26:04,408 iteration 2412 : loss : 0.012643, loss_ce: 0.004997
2021-12-10 12:26:07,153 iteration 2413 : loss : 0.014638, loss_ce: 0.006309
2021-12-10 12:26:09,863 iteration 2414 : loss : 0.013364, loss_ce: 0.006648
 36%|█████████▌                 | 142/400 [1:59:32<3:32:33, 49.43s/it]2021-12-10 12:26:12,659 iteration 2415 : loss : 0.010232, loss_ce: 0.004593
2021-12-10 12:26:15,528 iteration 2416 : loss : 0.011817, loss_ce: 0.004694
2021-12-10 12:26:18,290 iteration 2417 : loss : 0.011580, loss_ce: 0.005685
2021-12-10 12:26:21,037 iteration 2418 : loss : 0.011758, loss_ce: 0.004087
2021-12-10 12:26:23,967 iteration 2419 : loss : 0.011253, loss_ce: 0.004947
2021-12-10 12:26:26,750 iteration 2420 : loss : 0.022088, loss_ce: 0.005726
2021-12-10 12:26:29,487 iteration 2421 : loss : 0.013344, loss_ce: 0.006099
2021-12-10 12:26:32,213 iteration 2422 : loss : 0.011252, loss_ce: 0.003647
2021-12-10 12:26:34,967 iteration 2423 : loss : 0.013128, loss_ce: 0.004420
2021-12-10 12:26:37,707 iteration 2424 : loss : 0.010405, loss_ce: 0.003730
2021-12-10 12:26:40,432 iteration 2425 : loss : 0.010363, loss_ce: 0.003622
2021-12-10 12:26:43,298 iteration 2426 : loss : 0.013110, loss_ce: 0.005188
2021-12-10 12:26:46,033 iteration 2427 : loss : 0.010920, loss_ce: 0.003977
2021-12-10 12:26:48,775 iteration 2428 : loss : 0.011116, loss_ce: 0.004298
2021-12-10 12:26:51,616 iteration 2429 : loss : 0.010965, loss_ce: 0.004213
2021-12-10 12:26:54,335 iteration 2430 : loss : 0.010647, loss_ce: 0.002539
2021-12-10 12:26:57,204 iteration 2431 : loss : 0.014759, loss_ce: 0.005137
 36%|█████████▋                 | 143/400 [2:00:20<3:29:02, 48.80s/it]2021-12-10 12:27:00,145 iteration 2432 : loss : 0.014316, loss_ce: 0.004784
2021-12-10 12:27:02,876 iteration 2433 : loss : 0.010656, loss_ce: 0.003894
2021-12-10 12:27:05,814 iteration 2434 : loss : 0.012968, loss_ce: 0.004231
2021-12-10 12:27:08,566 iteration 2435 : loss : 0.011985, loss_ce: 0.003421
2021-12-10 12:27:11,300 iteration 2436 : loss : 0.010414, loss_ce: 0.002873
2021-12-10 12:27:14,147 iteration 2437 : loss : 0.012712, loss_ce: 0.005466
2021-12-10 12:27:16,870 iteration 2438 : loss : 0.011905, loss_ce: 0.003852
2021-12-10 12:27:19,709 iteration 2439 : loss : 0.008608, loss_ce: 0.003209
2021-12-10 12:27:22,468 iteration 2440 : loss : 0.010690, loss_ce: 0.003518
2021-12-10 12:27:25,323 iteration 2441 : loss : 0.014006, loss_ce: 0.007117
2021-12-10 12:27:28,182 iteration 2442 : loss : 0.011770, loss_ce: 0.004909
2021-12-10 12:27:30,918 iteration 2443 : loss : 0.017395, loss_ce: 0.004642
2021-12-10 12:27:33,808 iteration 2444 : loss : 0.011397, loss_ce: 0.004861
2021-12-10 12:27:36,535 iteration 2445 : loss : 0.009743, loss_ce: 0.004182
2021-12-10 12:27:39,372 iteration 2446 : loss : 0.009847, loss_ce: 0.004069
2021-12-10 12:27:42,229 iteration 2447 : loss : 0.010810, loss_ce: 0.004016
2021-12-10 12:27:45,121 iteration 2448 : loss : 0.012457, loss_ce: 0.005362
 36%|█████████▋                 | 144/400 [2:01:07<3:27:05, 48.54s/it]2021-12-10 12:27:47,984 iteration 2449 : loss : 0.011892, loss_ce: 0.003760
2021-12-10 12:27:50,716 iteration 2450 : loss : 0.011334, loss_ce: 0.004785
2021-12-10 12:27:53,576 iteration 2451 : loss : 0.013326, loss_ce: 0.003749
2021-12-10 12:27:56,417 iteration 2452 : loss : 0.011326, loss_ce: 0.004529
2021-12-10 12:27:59,257 iteration 2453 : loss : 0.009852, loss_ce: 0.003108
2021-12-10 12:28:02,093 iteration 2454 : loss : 0.011688, loss_ce: 0.005257
2021-12-10 12:28:04,938 iteration 2455 : loss : 0.010028, loss_ce: 0.004126
2021-12-10 12:28:07,840 iteration 2456 : loss : 0.010056, loss_ce: 0.004131
2021-12-10 12:28:10,759 iteration 2457 : loss : 0.008862, loss_ce: 0.002775
2021-12-10 12:28:13,494 iteration 2458 : loss : 0.010529, loss_ce: 0.003826
2021-12-10 12:28:16,398 iteration 2459 : loss : 0.012024, loss_ce: 0.003689
2021-12-10 12:28:19,127 iteration 2460 : loss : 0.009070, loss_ce: 0.003123
2021-12-10 12:28:21,968 iteration 2461 : loss : 0.011106, loss_ce: 0.004828
2021-12-10 12:28:24,831 iteration 2462 : loss : 0.009270, loss_ce: 0.003412
2021-12-10 12:28:27,755 iteration 2463 : loss : 0.011260, loss_ce: 0.003389
2021-12-10 12:28:30,493 iteration 2464 : loss : 0.009569, loss_ce: 0.005021
2021-12-10 12:28:30,493 Training Data Eval:
2021-12-10 12:28:46,471   Average segmentation loss on training set: 0.0100
2021-12-10 12:28:46,472 Validation Data Eval:
2021-12-10 12:28:51,947   Average segmentation loss on validation set: 0.1052
2021-12-10 12:28:54,786 iteration 2465 : loss : 0.011311, loss_ce: 0.003287
 36%|█████████▊                 | 145/400 [2:02:17<3:53:13, 54.88s/it]2021-12-10 12:28:57,766 iteration 2466 : loss : 0.010371, loss_ce: 0.003869
2021-12-10 12:29:00,490 iteration 2467 : loss : 0.009049, loss_ce: 0.003692
2021-12-10 12:29:03,322 iteration 2468 : loss : 0.010319, loss_ce: 0.005384
2021-12-10 12:29:06,159 iteration 2469 : loss : 0.010505, loss_ce: 0.003647
2021-12-10 12:29:08,994 iteration 2470 : loss : 0.009534, loss_ce: 0.003117
2021-12-10 12:29:12,014 iteration 2471 : loss : 0.009750, loss_ce: 0.003715
2021-12-10 12:29:14,892 iteration 2472 : loss : 0.009772, loss_ce: 0.004010
2021-12-10 12:29:17,729 iteration 2473 : loss : 0.011690, loss_ce: 0.003382
2021-12-10 12:29:20,602 iteration 2474 : loss : 0.009029, loss_ce: 0.003919
2021-12-10 12:29:23,439 iteration 2475 : loss : 0.008187, loss_ce: 0.002208
2021-12-10 12:29:26,268 iteration 2476 : loss : 0.011247, loss_ce: 0.002733
2021-12-10 12:29:29,105 iteration 2477 : loss : 0.008308, loss_ce: 0.003655
2021-12-10 12:29:31,947 iteration 2478 : loss : 0.008858, loss_ce: 0.003793
2021-12-10 12:29:34,945 iteration 2479 : loss : 0.008942, loss_ce: 0.003019
2021-12-10 12:29:37,734 iteration 2480 : loss : 0.009871, loss_ce: 0.003711
2021-12-10 12:29:40,661 iteration 2481 : loss : 0.009055, loss_ce: 0.003285
2021-12-10 12:29:43,580 iteration 2482 : loss : 0.010079, loss_ce: 0.004047
 36%|█████████▊                 | 146/400 [2:03:06<3:44:35, 53.05s/it]2021-12-10 12:29:46,373 iteration 2483 : loss : 0.008790, loss_ce: 0.002514
2021-12-10 12:29:49,204 iteration 2484 : loss : 0.008307, loss_ce: 0.003893
2021-12-10 12:29:52,230 iteration 2485 : loss : 0.008708, loss_ce: 0.002382
2021-12-10 12:29:55,079 iteration 2486 : loss : 0.007960, loss_ce: 0.002669
2021-12-10 12:29:57,940 iteration 2487 : loss : 0.008721, loss_ce: 0.002808
2021-12-10 12:30:00,848 iteration 2488 : loss : 0.010897, loss_ce: 0.003573
2021-12-10 12:30:03,776 iteration 2489 : loss : 0.008304, loss_ce: 0.003310
2021-12-10 12:30:06,717 iteration 2490 : loss : 0.008463, loss_ce: 0.003900
2021-12-10 12:30:09,633 iteration 2491 : loss : 0.012120, loss_ce: 0.003236
2021-12-10 12:30:12,356 iteration 2492 : loss : 0.008308, loss_ce: 0.003475
2021-12-10 12:30:15,192 iteration 2493 : loss : 0.008671, loss_ce: 0.003118
2021-12-10 12:30:18,099 iteration 2494 : loss : 0.008745, loss_ce: 0.002768
2021-12-10 12:30:21,028 iteration 2495 : loss : 0.009979, loss_ce: 0.004472
2021-12-10 12:30:23,938 iteration 2496 : loss : 0.008054, loss_ce: 0.003333
2021-12-10 12:30:26,904 iteration 2497 : loss : 0.010114, loss_ce: 0.004225
2021-12-10 12:30:29,642 iteration 2498 : loss : 0.009551, loss_ce: 0.004352
2021-12-10 12:30:32,502 iteration 2499 : loss : 0.011186, loss_ce: 0.004272
 37%|█████████▉                 | 147/400 [2:03:55<3:38:27, 51.81s/it]2021-12-10 12:30:35,461 iteration 2500 : loss : 0.008500, loss_ce: 0.002867
2021-12-10 12:30:38,392 iteration 2501 : loss : 0.008092, loss_ce: 0.002771
2021-12-10 12:30:41,262 iteration 2502 : loss : 0.008131, loss_ce: 0.003971
2021-12-10 12:30:44,197 iteration 2503 : loss : 0.010510, loss_ce: 0.003536
2021-12-10 12:30:47,126 iteration 2504 : loss : 0.008366, loss_ce: 0.002903
2021-12-10 12:30:49,981 iteration 2505 : loss : 0.008629, loss_ce: 0.003064
2021-12-10 12:30:52,874 iteration 2506 : loss : 0.010858, loss_ce: 0.004339
2021-12-10 12:30:55,765 iteration 2507 : loss : 0.007617, loss_ce: 0.003345
2021-12-10 12:30:58,688 iteration 2508 : loss : 0.010258, loss_ce: 0.004256
2021-12-10 12:31:01,606 iteration 2509 : loss : 0.008145, loss_ce: 0.003773
2021-12-10 12:31:04,485 iteration 2510 : loss : 0.008619, loss_ce: 0.003224
2021-12-10 12:31:07,399 iteration 2511 : loss : 0.007952, loss_ce: 0.002711
2021-12-10 12:31:10,327 iteration 2512 : loss : 0.009343, loss_ce: 0.003805
2021-12-10 12:31:13,250 iteration 2513 : loss : 0.007588, loss_ce: 0.002766
2021-12-10 12:31:15,989 iteration 2514 : loss : 0.008536, loss_ce: 0.002834
2021-12-10 12:31:19,017 iteration 2515 : loss : 0.008685, loss_ce: 0.003043
2021-12-10 12:31:21,993 iteration 2516 : loss : 0.009188, loss_ce: 0.003253
 37%|█████████▉                 | 148/400 [2:04:44<3:34:41, 51.12s/it]2021-12-10 12:31:24,788 iteration 2517 : loss : 0.008557, loss_ce: 0.003218
2021-12-10 12:31:27,685 iteration 2518 : loss : 0.007878, loss_ce: 0.003258
2021-12-10 12:31:30,616 iteration 2519 : loss : 0.007173, loss_ce: 0.002830
2021-12-10 12:31:33,489 iteration 2520 : loss : 0.008587, loss_ce: 0.003045
2021-12-10 12:31:36,330 iteration 2521 : loss : 0.008915, loss_ce: 0.003842
2021-12-10 12:31:39,358 iteration 2522 : loss : 0.008471, loss_ce: 0.002405
2021-12-10 12:31:42,211 iteration 2523 : loss : 0.007321, loss_ce: 0.002796
2021-12-10 12:31:45,104 iteration 2524 : loss : 0.011914, loss_ce: 0.003792
2021-12-10 12:31:48,010 iteration 2525 : loss : 0.007902, loss_ce: 0.003373
2021-12-10 12:31:50,945 iteration 2526 : loss : 0.010951, loss_ce: 0.005113
2021-12-10 12:31:53,864 iteration 2527 : loss : 0.007969, loss_ce: 0.003282
2021-12-10 12:31:56,763 iteration 2528 : loss : 0.010391, loss_ce: 0.003206
2021-12-10 12:31:59,689 iteration 2529 : loss : 0.009226, loss_ce: 0.003097
2021-12-10 12:32:02,558 iteration 2530 : loss : 0.009435, loss_ce: 0.004914
2021-12-10 12:32:05,503 iteration 2531 : loss : 0.009757, loss_ce: 0.002862
2021-12-10 12:32:08,248 iteration 2532 : loss : 0.008508, loss_ce: 0.003697
2021-12-10 12:32:11,025 iteration 2533 : loss : 0.007608, loss_ce: 0.003053
 37%|██████████                 | 149/400 [2:05:33<3:31:13, 50.49s/it]2021-12-10 12:32:13,857 iteration 2534 : loss : 0.010251, loss_ce: 0.003458
2021-12-10 12:32:16,714 iteration 2535 : loss : 0.009327, loss_ce: 0.002750
2021-12-10 12:32:19,586 iteration 2536 : loss : 0.007176, loss_ce: 0.002665
2021-12-10 12:32:22,450 iteration 2537 : loss : 0.013032, loss_ce: 0.004526
2021-12-10 12:32:25,282 iteration 2538 : loss : 0.009950, loss_ce: 0.003700
2021-12-10 12:32:28,109 iteration 2539 : loss : 0.008966, loss_ce: 0.004706
2021-12-10 12:32:30,947 iteration 2540 : loss : 0.011317, loss_ce: 0.005363
2021-12-10 12:32:33,945 iteration 2541 : loss : 0.009791, loss_ce: 0.003273
2021-12-10 12:32:36,674 iteration 2542 : loss : 0.010669, loss_ce: 0.004396
2021-12-10 12:32:39,645 iteration 2543 : loss : 0.008868, loss_ce: 0.003920
2021-12-10 12:32:42,575 iteration 2544 : loss : 0.009434, loss_ce: 0.003929
2021-12-10 12:32:45,447 iteration 2545 : loss : 0.009120, loss_ce: 0.003254
2021-12-10 12:32:48,315 iteration 2546 : loss : 0.007981, loss_ce: 0.003683
2021-12-10 12:32:51,116 iteration 2547 : loss : 0.010239, loss_ce: 0.002440
2021-12-10 12:32:53,952 iteration 2548 : loss : 0.007560, loss_ce: 0.002836
2021-12-10 12:32:56,916 iteration 2549 : loss : 0.011047, loss_ce: 0.003193
2021-12-10 12:32:56,916 Training Data Eval:
2021-12-10 12:33:13,117   Average segmentation loss on training set: 0.0104
2021-12-10 12:33:13,117 Validation Data Eval:
2021-12-10 12:33:18,749   Average segmentation loss on validation set: 0.1217
2021-12-10 12:33:21,589 iteration 2550 : loss : 0.011311, loss_ce: 0.003751
2021-12-10 12:33:27,731 save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/NEW_TU/NEW_TU_ADAM_seed1234_no_daepoch_149.pth
 38%|██████████▏                | 150/400 [2:06:50<4:03:04, 58.34s/it]2021-12-10 12:33:29,545 iteration 2551 : loss : 0.010106, loss_ce: 0.003977
2021-12-10 12:33:32,056 iteration 2552 : loss : 0.009704, loss_ce: 0.003997
2021-12-10 12:33:34,808 iteration 2553 : loss : 0.011769, loss_ce: 0.005618
2021-12-10 12:33:37,433 iteration 2554 : loss : 0.010280, loss_ce: 0.003247
2021-12-10 12:33:40,175 iteration 2555 : loss : 0.012120, loss_ce: 0.004465
2021-12-10 12:33:42,949 iteration 2556 : loss : 0.009118, loss_ce: 0.004015
2021-12-10 12:33:45,699 iteration 2557 : loss : 0.011832, loss_ce: 0.004142
2021-12-10 12:33:48,426 iteration 2558 : loss : 0.007992, loss_ce: 0.003030
2021-12-10 12:33:51,271 iteration 2559 : loss : 0.011088, loss_ce: 0.004571
2021-12-10 12:33:54,114 iteration 2560 : loss : 0.010395, loss_ce: 0.002958
2021-12-10 12:33:57,006 iteration 2561 : loss : 0.010553, loss_ce: 0.003317
2021-12-10 12:33:59,935 iteration 2562 : loss : 0.011044, loss_ce: 0.004470
2021-12-10 12:34:02,675 iteration 2563 : loss : 0.008699, loss_ce: 0.004143
2021-12-10 12:34:05,536 iteration 2564 : loss : 0.007992, loss_ce: 0.002379
2021-12-10 12:34:08,397 iteration 2565 : loss : 0.008993, loss_ce: 0.003325
2021-12-10 12:34:11,250 iteration 2566 : loss : 0.010844, loss_ce: 0.004359
2021-12-10 12:34:14,254 iteration 2567 : loss : 0.013999, loss_ce: 0.004058
 38%|██████████▏                | 151/400 [2:07:37<3:47:28, 54.81s/it]2021-12-10 12:34:17,065 iteration 2568 : loss : 0.009685, loss_ce: 0.003976
2021-12-10 12:34:19,965 iteration 2569 : loss : 0.008884, loss_ce: 0.003778
2021-12-10 12:34:22,713 iteration 2570 : loss : 0.007913, loss_ce: 0.002524
2021-12-10 12:34:25,439 iteration 2571 : loss : 0.008058, loss_ce: 0.003512
2021-12-10 12:34:28,364 iteration 2572 : loss : 0.009457, loss_ce: 0.002309
2021-12-10 12:34:31,106 iteration 2573 : loss : 0.009799, loss_ce: 0.003982
2021-12-10 12:34:33,963 iteration 2574 : loss : 0.014107, loss_ce: 0.004294
2021-12-10 12:34:36,829 iteration 2575 : loss : 0.010260, loss_ce: 0.003891
2021-12-10 12:34:39,696 iteration 2576 : loss : 0.009209, loss_ce: 0.004046
2021-12-10 12:34:42,707 iteration 2577 : loss : 0.009154, loss_ce: 0.003405
2021-12-10 12:34:45,626 iteration 2578 : loss : 0.010099, loss_ce: 0.004067
2021-12-10 12:34:48,492 iteration 2579 : loss : 0.011659, loss_ce: 0.004348
2021-12-10 12:34:51,335 iteration 2580 : loss : 0.010500, loss_ce: 0.002627
2021-12-10 12:34:54,311 iteration 2581 : loss : 0.007713, loss_ce: 0.002558
2021-12-10 12:34:57,221 iteration 2582 : loss : 0.009125, loss_ce: 0.003342
2021-12-10 12:35:00,155 iteration 2583 : loss : 0.009613, loss_ce: 0.003261
2021-12-10 12:35:03,041 iteration 2584 : loss : 0.009311, loss_ce: 0.003701
 38%|██████████▎                | 152/400 [2:08:25<3:39:04, 53.00s/it]2021-12-10 12:35:05,823 iteration 2585 : loss : 0.010265, loss_ce: 0.004094
2021-12-10 12:35:08,848 iteration 2586 : loss : 0.007447, loss_ce: 0.002648
2021-12-10 12:35:11,746 iteration 2587 : loss : 0.008548, loss_ce: 0.002701
2021-12-10 12:35:14,633 iteration 2588 : loss : 0.010288, loss_ce: 0.003761
2021-12-10 12:35:17,564 iteration 2589 : loss : 0.009049, loss_ce: 0.003293
2021-12-10 12:35:20,448 iteration 2590 : loss : 0.008894, loss_ce: 0.003936
2021-12-10 12:35:23,347 iteration 2591 : loss : 0.008018, loss_ce: 0.002723
2021-12-10 12:35:26,225 iteration 2592 : loss : 0.008567, loss_ce: 0.003222
2021-12-10 12:35:29,095 iteration 2593 : loss : 0.010038, loss_ce: 0.003134
2021-12-10 12:35:31,958 iteration 2594 : loss : 0.008408, loss_ce: 0.002925
2021-12-10 12:35:34,820 iteration 2595 : loss : 0.007629, loss_ce: 0.003580
2021-12-10 12:35:37,547 iteration 2596 : loss : 0.011999, loss_ce: 0.006582
2021-12-10 12:35:40,268 iteration 2597 : loss : 0.009300, loss_ce: 0.001946
2021-12-10 12:35:43,138 iteration 2598 : loss : 0.008057, loss_ce: 0.003541
2021-12-10 12:35:46,038 iteration 2599 : loss : 0.007582, loss_ce: 0.002757
2021-12-10 12:35:48,828 iteration 2600 : loss : 0.007473, loss_ce: 0.003316
2021-12-10 12:35:51,661 iteration 2601 : loss : 0.008338, loss_ce: 0.002820
 38%|██████████▎                | 153/400 [2:09:14<3:32:47, 51.69s/it]2021-12-10 12:35:54,570 iteration 2602 : loss : 0.009737, loss_ce: 0.004620
2021-12-10 12:35:57,602 iteration 2603 : loss : 0.008245, loss_ce: 0.003127
2021-12-10 12:36:00,450 iteration 2604 : loss : 0.009334, loss_ce: 0.003336
2021-12-10 12:36:03,444 iteration 2605 : loss : 0.007900, loss_ce: 0.004068
2021-12-10 12:36:06,235 iteration 2606 : loss : 0.008314, loss_ce: 0.003757
2021-12-10 12:36:09,168 iteration 2607 : loss : 0.009347, loss_ce: 0.002974
2021-12-10 12:36:11,908 iteration 2608 : loss : 0.012175, loss_ce: 0.002994
2021-12-10 12:36:14,765 iteration 2609 : loss : 0.008396, loss_ce: 0.003587
2021-12-10 12:36:17,491 iteration 2610 : loss : 0.009707, loss_ce: 0.002913
2021-12-10 12:36:20,216 iteration 2611 : loss : 0.008306, loss_ce: 0.003682
2021-12-10 12:36:23,147 iteration 2612 : loss : 0.008215, loss_ce: 0.002627
2021-12-10 12:36:25,879 iteration 2613 : loss : 0.011664, loss_ce: 0.004865
2021-12-10 12:36:28,773 iteration 2614 : loss : 0.009850, loss_ce: 0.006084
2021-12-10 12:36:31,499 iteration 2615 : loss : 0.015442, loss_ce: 0.003814
2021-12-10 12:36:34,338 iteration 2616 : loss : 0.015007, loss_ce: 0.003941
2021-12-10 12:36:37,166 iteration 2617 : loss : 0.008209, loss_ce: 0.003403
2021-12-10 12:36:40,011 iteration 2618 : loss : 0.009165, loss_ce: 0.004307
 38%|██████████▍                | 154/400 [2:10:02<3:27:49, 50.69s/it]2021-12-10 12:36:42,912 iteration 2619 : loss : 0.016356, loss_ce: 0.003842
2021-12-10 12:36:45,884 iteration 2620 : loss : 0.008811, loss_ce: 0.003150
2021-12-10 12:36:48,754 iteration 2621 : loss : 0.009402, loss_ce: 0.003738
2021-12-10 12:36:51,641 iteration 2622 : loss : 0.011462, loss_ce: 0.004505
2021-12-10 12:36:54,543 iteration 2623 : loss : 0.011585, loss_ce: 0.005025
2021-12-10 12:36:57,433 iteration 2624 : loss : 0.009000, loss_ce: 0.003630
2021-12-10 12:37:00,209 iteration 2625 : loss : 0.018068, loss_ce: 0.007812
2021-12-10 12:37:03,219 iteration 2626 : loss : 0.010398, loss_ce: 0.005519
2021-12-10 12:37:06,127 iteration 2627 : loss : 0.010699, loss_ce: 0.004121
2021-12-10 12:37:09,010 iteration 2628 : loss : 0.009537, loss_ce: 0.003119
2021-12-10 12:37:12,014 iteration 2629 : loss : 0.009602, loss_ce: 0.003730
2021-12-10 12:37:14,924 iteration 2630 : loss : 0.013589, loss_ce: 0.006040
2021-12-10 12:37:17,762 iteration 2631 : loss : 0.008911, loss_ce: 0.003152
2021-12-10 12:37:20,600 iteration 2632 : loss : 0.009242, loss_ce: 0.003363
2021-12-10 12:37:23,569 iteration 2633 : loss : 0.012612, loss_ce: 0.005504
2021-12-10 12:37:26,487 iteration 2634 : loss : 0.011513, loss_ce: 0.004952
2021-12-10 12:37:26,487 Training Data Eval:
2021-12-10 12:37:42,031   Average segmentation loss on training set: 0.0105
2021-12-10 12:37:42,032 Validation Data Eval:
2021-12-10 12:37:47,546   Average segmentation loss on validation set: 0.1206
2021-12-10 12:37:50,476 iteration 2635 : loss : 0.014654, loss_ce: 0.004960
 39%|██████████▍                | 155/400 [2:11:13<3:51:12, 56.62s/it]2021-12-10 12:37:53,282 iteration 2636 : loss : 0.010930, loss_ce: 0.004089
2021-12-10 12:37:56,191 iteration 2637 : loss : 0.009581, loss_ce: 0.004139
2021-12-10 12:37:58,920 iteration 2638 : loss : 0.010088, loss_ce: 0.004169
2021-12-10 12:38:01,749 iteration 2639 : loss : 0.010997, loss_ce: 0.004525
2021-12-10 12:38:04,787 iteration 2640 : loss : 0.013008, loss_ce: 0.003788
2021-12-10 12:38:07,721 iteration 2641 : loss : 0.009852, loss_ce: 0.002527
2021-12-10 12:38:10,596 iteration 2642 : loss : 0.009684, loss_ce: 0.003821
2021-12-10 12:38:13,531 iteration 2643 : loss : 0.011340, loss_ce: 0.003367
2021-12-10 12:38:16,446 iteration 2644 : loss : 0.008666, loss_ce: 0.003242
2021-12-10 12:38:19,342 iteration 2645 : loss : 0.008951, loss_ce: 0.003198
2021-12-10 12:38:22,225 iteration 2646 : loss : 0.009906, loss_ce: 0.004028
2021-12-10 12:38:25,154 iteration 2647 : loss : 0.010780, loss_ce: 0.003565
2021-12-10 12:38:28,023 iteration 2648 : loss : 0.010051, loss_ce: 0.003660
2021-12-10 12:38:30,858 iteration 2649 : loss : 0.009139, loss_ce: 0.003484
2021-12-10 12:38:33,885 iteration 2650 : loss : 0.009611, loss_ce: 0.004019
2021-12-10 12:38:36,744 iteration 2651 : loss : 0.007332, loss_ce: 0.002783
2021-12-10 12:38:39,631 iteration 2652 : loss : 0.008978, loss_ce: 0.004376
 39%|██████████▌                | 156/400 [2:12:02<3:41:09, 54.38s/it]2021-12-10 12:38:42,576 iteration 2653 : loss : 0.007054, loss_ce: 0.001687
2021-12-10 12:38:45,449 iteration 2654 : loss : 0.012555, loss_ce: 0.003436
2021-12-10 12:38:48,170 iteration 2655 : loss : 0.011223, loss_ce: 0.004973
2021-12-10 12:38:51,043 iteration 2656 : loss : 0.007167, loss_ce: 0.002327
2021-12-10 12:38:53,770 iteration 2657 : loss : 0.009275, loss_ce: 0.003780
2021-12-10 12:38:56,629 iteration 2658 : loss : 0.009123, loss_ce: 0.002670
2021-12-10 12:38:59,565 iteration 2659 : loss : 0.008934, loss_ce: 0.003338
2021-12-10 12:39:02,301 iteration 2660 : loss : 0.008953, loss_ce: 0.004167
2021-12-10 12:39:05,157 iteration 2661 : loss : 0.009498, loss_ce: 0.004550
2021-12-10 12:39:08,008 iteration 2662 : loss : 0.009568, loss_ce: 0.003550
2021-12-10 12:39:10,862 iteration 2663 : loss : 0.009088, loss_ce: 0.004236
2021-12-10 12:39:13,873 iteration 2664 : loss : 0.010051, loss_ce: 0.003688
2021-12-10 12:39:16,787 iteration 2665 : loss : 0.009431, loss_ce: 0.003877
2021-12-10 12:39:19,654 iteration 2666 : loss : 0.008574, loss_ce: 0.003941
2021-12-10 12:39:22,524 iteration 2667 : loss : 0.008941, loss_ce: 0.003171
2021-12-10 12:39:25,513 iteration 2668 : loss : 0.007353, loss_ce: 0.002890
2021-12-10 12:39:28,430 iteration 2669 : loss : 0.007592, loss_ce: 0.002665
 39%|██████████▌                | 157/400 [2:12:51<3:33:26, 52.70s/it]2021-12-10 12:39:31,340 iteration 2670 : loss : 0.007488, loss_ce: 0.003081
2021-12-10 12:39:34,341 iteration 2671 : loss : 0.010324, loss_ce: 0.002773
2021-12-10 12:39:37,262 iteration 2672 : loss : 0.007878, loss_ce: 0.003688
2021-12-10 12:39:40,101 iteration 2673 : loss : 0.009777, loss_ce: 0.003551
2021-12-10 12:39:43,098 iteration 2674 : loss : 0.007406, loss_ce: 0.003143
2021-12-10 12:39:45,878 iteration 2675 : loss : 0.007889, loss_ce: 0.003338
2021-12-10 12:39:48,763 iteration 2676 : loss : 0.007718, loss_ce: 0.003983
2021-12-10 12:39:51,620 iteration 2677 : loss : 0.006994, loss_ce: 0.002718
2021-12-10 12:39:54,400 iteration 2678 : loss : 0.008375, loss_ce: 0.002945
2021-12-10 12:39:57,251 iteration 2679 : loss : 0.008022, loss_ce: 0.002619
2021-12-10 12:40:00,030 iteration 2680 : loss : 0.007832, loss_ce: 0.002531
2021-12-10 12:40:02,760 iteration 2681 : loss : 0.007919, loss_ce: 0.003191
2021-12-10 12:40:05,642 iteration 2682 : loss : 0.009594, loss_ce: 0.003010
2021-12-10 12:40:08,506 iteration 2683 : loss : 0.010095, loss_ce: 0.003086
2021-12-10 12:40:11,430 iteration 2684 : loss : 0.007216, loss_ce: 0.002613
2021-12-10 12:40:14,366 iteration 2685 : loss : 0.009319, loss_ce: 0.002474
2021-12-10 12:40:17,091 iteration 2686 : loss : 0.009092, loss_ce: 0.004151
 40%|██████████▋                | 158/400 [2:13:39<3:27:41, 51.49s/it]2021-12-10 12:40:20,095 iteration 2687 : loss : 0.010508, loss_ce: 0.002955
2021-12-10 12:40:23,029 iteration 2688 : loss : 0.007580, loss_ce: 0.002821
2021-12-10 12:40:25,902 iteration 2689 : loss : 0.008813, loss_ce: 0.002584
2021-12-10 12:40:28,779 iteration 2690 : loss : 0.008406, loss_ce: 0.003071
2021-12-10 12:40:31,499 iteration 2691 : loss : 0.008763, loss_ce: 0.002938
2021-12-10 12:40:34,466 iteration 2692 : loss : 0.009700, loss_ce: 0.004229
2021-12-10 12:40:37,371 iteration 2693 : loss : 0.007490, loss_ce: 0.002717
2021-12-10 12:40:40,296 iteration 2694 : loss : 0.008230, loss_ce: 0.003668
2021-12-10 12:40:43,225 iteration 2695 : loss : 0.007535, loss_ce: 0.003561
2021-12-10 12:40:46,127 iteration 2696 : loss : 0.012092, loss_ce: 0.005166
2021-12-10 12:40:48,995 iteration 2697 : loss : 0.006741, loss_ce: 0.002877
2021-12-10 12:40:51,857 iteration 2698 : loss : 0.009241, loss_ce: 0.004250
2021-12-10 12:40:54,721 iteration 2699 : loss : 0.007169, loss_ce: 0.002234
2021-12-10 12:40:57,576 iteration 2700 : loss : 0.007894, loss_ce: 0.002891
2021-12-10 12:41:00,452 iteration 2701 : loss : 0.007582, loss_ce: 0.003220
2021-12-10 12:41:03,184 iteration 2702 : loss : 0.007460, loss_ce: 0.002529
2021-12-10 12:41:06,044 iteration 2703 : loss : 0.007330, loss_ce: 0.002299
 40%|██████████▋                | 159/400 [2:14:28<3:23:46, 50.73s/it]2021-12-10 12:41:08,989 iteration 2704 : loss : 0.007141, loss_ce: 0.002627
2021-12-10 12:41:11,731 iteration 2705 : loss : 0.008801, loss_ce: 0.004001
2021-12-10 12:41:14,586 iteration 2706 : loss : 0.007694, loss_ce: 0.003757
2021-12-10 12:41:17,440 iteration 2707 : loss : 0.007619, loss_ce: 0.002963
2021-12-10 12:41:20,280 iteration 2708 : loss : 0.008768, loss_ce: 0.003275
2021-12-10 12:41:23,110 iteration 2709 : loss : 0.006667, loss_ce: 0.002797
2021-12-10 12:41:25,939 iteration 2710 : loss : 0.009885, loss_ce: 0.002627
2021-12-10 12:41:28,778 iteration 2711 : loss : 0.008390, loss_ce: 0.003164
2021-12-10 12:41:31,738 iteration 2712 : loss : 0.009580, loss_ce: 0.004497
2021-12-10 12:41:34,655 iteration 2713 : loss : 0.010118, loss_ce: 0.004400
2021-12-10 12:41:37,569 iteration 2714 : loss : 0.009390, loss_ce: 0.003589
2021-12-10 12:41:40,291 iteration 2715 : loss : 0.006241, loss_ce: 0.001858
2021-12-10 12:41:43,258 iteration 2716 : loss : 0.006542, loss_ce: 0.002356
2021-12-10 12:41:46,232 iteration 2717 : loss : 0.006981, loss_ce: 0.002291
2021-12-10 12:41:49,156 iteration 2718 : loss : 0.007711, loss_ce: 0.003374
2021-12-10 12:41:52,025 iteration 2719 : loss : 0.007190, loss_ce: 0.003042
2021-12-10 12:41:52,025 Training Data Eval:
2021-12-10 12:42:08,354   Average segmentation loss on training set: 0.0085
2021-12-10 12:42:08,354 Validation Data Eval:
2021-12-10 12:42:13,912   Average segmentation loss on validation set: 0.0938
2021-12-10 12:42:16,944 iteration 2720 : loss : 0.008876, loss_ce: 0.002381
 40%|██████████▊                | 160/400 [2:15:39<3:47:07, 56.78s/it]2021-12-10 12:42:19,740 iteration 2721 : loss : 0.007532, loss_ce: 0.002829
2021-12-10 12:42:22,736 iteration 2722 : loss : 0.010412, loss_ce: 0.002426
2021-12-10 12:42:25,651 iteration 2723 : loss : 0.007533, loss_ce: 0.003272
2021-12-10 12:42:28,451 iteration 2724 : loss : 0.008008, loss_ce: 0.003633
2021-12-10 12:42:31,287 iteration 2725 : loss : 0.007338, loss_ce: 0.002498
2021-12-10 12:42:34,256 iteration 2726 : loss : 0.008259, loss_ce: 0.002264
2021-12-10 12:42:37,170 iteration 2727 : loss : 0.009990, loss_ce: 0.003202
2021-12-10 12:42:40,100 iteration 2728 : loss : 0.009339, loss_ce: 0.002274
2021-12-10 12:42:42,945 iteration 2729 : loss : 0.009326, loss_ce: 0.004020
2021-12-10 12:42:45,981 iteration 2730 : loss : 0.008395, loss_ce: 0.003366
2021-12-10 12:42:48,830 iteration 2731 : loss : 0.007500, loss_ce: 0.002609
2021-12-10 12:42:51,729 iteration 2732 : loss : 0.008046, loss_ce: 0.004083
2021-12-10 12:42:54,615 iteration 2733 : loss : 0.009022, loss_ce: 0.004579
2021-12-10 12:42:57,545 iteration 2734 : loss : 0.008780, loss_ce: 0.003621
2021-12-10 12:43:00,420 iteration 2735 : loss : 0.011499, loss_ce: 0.005101
2021-12-10 12:43:03,310 iteration 2736 : loss : 0.007322, loss_ce: 0.002768
2021-12-10 12:43:06,042 iteration 2737 : loss : 0.010242, loss_ce: 0.004005
 40%|██████████▊                | 161/400 [2:16:28<3:36:59, 54.48s/it]2021-12-10 12:43:09,071 iteration 2738 : loss : 0.007866, loss_ce: 0.002643
2021-12-10 12:43:11,981 iteration 2739 : loss : 0.006552, loss_ce: 0.002425
2021-12-10 12:43:14,874 iteration 2740 : loss : 0.008134, loss_ce: 0.002614
2021-12-10 12:43:17,864 iteration 2741 : loss : 0.010014, loss_ce: 0.003455
2021-12-10 12:43:20,838 iteration 2742 : loss : 0.009642, loss_ce: 0.004179
2021-12-10 12:43:23,681 iteration 2743 : loss : 0.008513, loss_ce: 0.003700
2021-12-10 12:43:26,695 iteration 2744 : loss : 0.008244, loss_ce: 0.002741
2021-12-10 12:43:29,657 iteration 2745 : loss : 0.008743, loss_ce: 0.003093
2021-12-10 12:43:32,500 iteration 2746 : loss : 0.009189, loss_ce: 0.003115
2021-12-10 12:43:35,526 iteration 2747 : loss : 0.006955, loss_ce: 0.002523
2021-12-10 12:43:38,382 iteration 2748 : loss : 0.009410, loss_ce: 0.002791
2021-12-10 12:43:41,243 iteration 2749 : loss : 0.011284, loss_ce: 0.004010
2021-12-10 12:43:44,107 iteration 2750 : loss : 0.009168, loss_ce: 0.004748
2021-12-10 12:43:46,966 iteration 2751 : loss : 0.007759, loss_ce: 0.002787
2021-12-10 12:43:49,883 iteration 2752 : loss : 0.010916, loss_ce: 0.004792
2021-12-10 12:43:52,668 iteration 2753 : loss : 0.009799, loss_ce: 0.003495
2021-12-10 12:43:55,399 iteration 2754 : loss : 0.007962, loss_ce: 0.003853
 40%|██████████▉                | 162/400 [2:17:18<3:29:59, 52.94s/it]2021-12-10 12:43:58,199 iteration 2755 : loss : 0.007961, loss_ce: 0.002694
2021-12-10 12:44:01,063 iteration 2756 : loss : 0.009226, loss_ce: 0.003442
2021-12-10 12:44:03,904 iteration 2757 : loss : 0.008287, loss_ce: 0.002568
2021-12-10 12:44:06,741 iteration 2758 : loss : 0.007635, loss_ce: 0.002664
2021-12-10 12:44:09,766 iteration 2759 : loss : 0.006526, loss_ce: 0.003095
2021-12-10 12:44:12,603 iteration 2760 : loss : 0.008070, loss_ce: 0.003285
2021-12-10 12:44:15,598 iteration 2761 : loss : 0.007201, loss_ce: 0.003221
2021-12-10 12:44:18,316 iteration 2762 : loss : 0.009958, loss_ce: 0.003485
2021-12-10 12:44:21,359 iteration 2763 : loss : 0.009602, loss_ce: 0.002613
2021-12-10 12:44:24,091 iteration 2764 : loss : 0.008815, loss_ce: 0.002495
2021-12-10 12:44:27,047 iteration 2765 : loss : 0.007496, loss_ce: 0.003324
2021-12-10 12:44:29,963 iteration 2766 : loss : 0.006826, loss_ce: 0.002431
2021-12-10 12:44:32,883 iteration 2767 : loss : 0.007415, loss_ce: 0.003000
2021-12-10 12:44:35,779 iteration 2768 : loss : 0.008296, loss_ce: 0.002742
2021-12-10 12:44:38,555 iteration 2769 : loss : 0.008598, loss_ce: 0.003163
2021-12-10 12:44:41,635 iteration 2770 : loss : 0.006686, loss_ce: 0.002754
2021-12-10 12:44:44,410 iteration 2771 : loss : 0.006758, loss_ce: 0.003174
 41%|███████████                | 163/400 [2:18:07<3:24:26, 51.76s/it]2021-12-10 12:44:47,338 iteration 2772 : loss : 0.007927, loss_ce: 0.001573
2021-12-10 12:44:50,081 iteration 2773 : loss : 0.006924, loss_ce: 0.003220
2021-12-10 12:44:52,926 iteration 2774 : loss : 0.006669, loss_ce: 0.002998
2021-12-10 12:44:55,782 iteration 2775 : loss : 0.007249, loss_ce: 0.003234
2021-12-10 12:44:58,699 iteration 2776 : loss : 0.007964, loss_ce: 0.002625
2021-12-10 12:45:01,625 iteration 2777 : loss : 0.008727, loss_ce: 0.002982
2021-12-10 12:45:04,490 iteration 2778 : loss : 0.008288, loss_ce: 0.002722
2021-12-10 12:45:07,424 iteration 2779 : loss : 0.006994, loss_ce: 0.002803
2021-12-10 12:45:10,342 iteration 2780 : loss : 0.006580, loss_ce: 0.002786
2021-12-10 12:45:13,206 iteration 2781 : loss : 0.006579, loss_ce: 0.003170
2021-12-10 12:45:16,068 iteration 2782 : loss : 0.007099, loss_ce: 0.002330
2021-12-10 12:45:19,070 iteration 2783 : loss : 0.007886, loss_ce: 0.003601
2021-12-10 12:45:21,955 iteration 2784 : loss : 0.008197, loss_ce: 0.003062
2021-12-10 12:45:24,887 iteration 2785 : loss : 0.007310, loss_ce: 0.002607
2021-12-10 12:45:27,819 iteration 2786 : loss : 0.006131, loss_ce: 0.002923
2021-12-10 12:45:30,659 iteration 2787 : loss : 0.007732, loss_ce: 0.002514
2021-12-10 12:45:33,556 iteration 2788 : loss : 0.009104, loss_ce: 0.002026
 41%|███████████                | 164/400 [2:18:56<3:20:31, 50.98s/it]2021-12-10 12:45:36,546 iteration 2789 : loss : 0.006117, loss_ce: 0.002399
2021-12-10 12:45:39,456 iteration 2790 : loss : 0.007131, loss_ce: 0.002510
2021-12-10 12:45:42,348 iteration 2791 : loss : 0.008285, loss_ce: 0.001917
2021-12-10 12:45:45,280 iteration 2792 : loss : 0.008323, loss_ce: 0.003279
2021-12-10 12:45:48,199 iteration 2793 : loss : 0.005613, loss_ce: 0.002319
2021-12-10 12:45:51,069 iteration 2794 : loss : 0.006186, loss_ce: 0.002557
2021-12-10 12:45:53,993 iteration 2795 : loss : 0.006912, loss_ce: 0.002150
2021-12-10 12:45:56,851 iteration 2796 : loss : 0.007158, loss_ce: 0.002363
2021-12-10 12:45:59,744 iteration 2797 : loss : 0.007685, loss_ce: 0.002989
2021-12-10 12:46:02,523 iteration 2798 : loss : 0.008500, loss_ce: 0.003481
2021-12-10 12:46:05,533 iteration 2799 : loss : 0.007637, loss_ce: 0.002632
2021-12-10 12:46:08,412 iteration 2800 : loss : 0.009175, loss_ce: 0.003185
2021-12-10 12:46:11,246 iteration 2801 : loss : 0.009514, loss_ce: 0.003483
2021-12-10 12:46:14,276 iteration 2802 : loss : 0.009086, loss_ce: 0.002938
2021-12-10 12:46:17,123 iteration 2803 : loss : 0.010316, loss_ce: 0.003075
2021-12-10 12:46:20,015 iteration 2804 : loss : 0.012739, loss_ce: 0.004445
2021-12-10 12:46:20,016 Training Data Eval:
2021-12-10 12:46:36,177   Average segmentation loss on training set: 0.0081
2021-12-10 12:46:36,178 Validation Data Eval:
2021-12-10 12:46:41,791   Average segmentation loss on validation set: 0.1254
2021-12-10 12:46:44,634 iteration 2805 : loss : 0.007829, loss_ce: 0.003497
 41%|███████████▏               | 165/400 [2:20:07<3:43:17, 57.01s/it]2021-12-10 12:46:47,591 iteration 2806 : loss : 0.007620, loss_ce: 0.002672
2021-12-10 12:46:50,325 iteration 2807 : loss : 0.009650, loss_ce: 0.003739
2021-12-10 12:46:53,253 iteration 2808 : loss : 0.008648, loss_ce: 0.003287
2021-12-10 12:46:55,989 iteration 2809 : loss : 0.009999, loss_ce: 0.003861
2021-12-10 12:46:58,846 iteration 2810 : loss : 0.007755, loss_ce: 0.002662
2021-12-10 12:47:01,708 iteration 2811 : loss : 0.006351, loss_ce: 0.002451
2021-12-10 12:47:04,639 iteration 2812 : loss : 0.008522, loss_ce: 0.003750
2021-12-10 12:47:07,365 iteration 2813 : loss : 0.008994, loss_ce: 0.001852
2021-12-10 12:47:10,393 iteration 2814 : loss : 0.009193, loss_ce: 0.003215
2021-12-10 12:47:13,242 iteration 2815 : loss : 0.008029, loss_ce: 0.002102
2021-12-10 12:47:16,137 iteration 2816 : loss : 0.008734, loss_ce: 0.004228
2021-12-10 12:47:19,044 iteration 2817 : loss : 0.007352, loss_ce: 0.003181
2021-12-10 12:47:21,958 iteration 2818 : loss : 0.011260, loss_ce: 0.003544
2021-12-10 12:47:24,789 iteration 2819 : loss : 0.009517, loss_ce: 0.004329
2021-12-10 12:47:27,817 iteration 2820 : loss : 0.007925, loss_ce: 0.002667
2021-12-10 12:47:30,654 iteration 2821 : loss : 0.005823, loss_ce: 0.001897
2021-12-10 12:47:33,495 iteration 2822 : loss : 0.006891, loss_ce: 0.002672
 42%|███████████▏               | 166/400 [2:20:56<3:32:48, 54.57s/it]2021-12-10 12:47:36,470 iteration 2823 : loss : 0.007396, loss_ce: 0.003027
2021-12-10 12:47:39,305 iteration 2824 : loss : 0.008725, loss_ce: 0.002545
2021-12-10 12:47:42,341 iteration 2825 : loss : 0.008980, loss_ce: 0.003389
2021-12-10 12:47:45,187 iteration 2826 : loss : 0.008501, loss_ce: 0.003329
2021-12-10 12:47:48,082 iteration 2827 : loss : 0.007124, loss_ce: 0.003060
2021-12-10 12:47:50,862 iteration 2828 : loss : 0.007767, loss_ce: 0.003332
2021-12-10 12:47:53,871 iteration 2829 : loss : 0.008143, loss_ce: 0.003203
2021-12-10 12:47:56,779 iteration 2830 : loss : 0.007305, loss_ce: 0.003026
2021-12-10 12:47:59,620 iteration 2831 : loss : 0.007657, loss_ce: 0.002453
2021-12-10 12:48:02,449 iteration 2832 : loss : 0.006652, loss_ce: 0.002495
2021-12-10 12:48:05,481 iteration 2833 : loss : 0.007999, loss_ce: 0.003672
2021-12-10 12:48:08,328 iteration 2834 : loss : 0.007550, loss_ce: 0.003080
2021-12-10 12:48:11,327 iteration 2835 : loss : 0.007781, loss_ce: 0.002845
2021-12-10 12:48:14,046 iteration 2836 : loss : 0.009048, loss_ce: 0.003299
2021-12-10 12:48:17,047 iteration 2837 : loss : 0.009431, loss_ce: 0.001953
2021-12-10 12:48:19,927 iteration 2838 : loss : 0.008145, loss_ce: 0.003540
2021-12-10 12:48:22,802 iteration 2839 : loss : 0.008344, loss_ce: 0.002590
 42%|███████████▎               | 167/400 [2:21:45<3:25:45, 52.98s/it]2021-12-10 12:48:25,788 iteration 2840 : loss : 0.009271, loss_ce: 0.004313
2021-12-10 12:48:28,632 iteration 2841 : loss : 0.006935, loss_ce: 0.002843
2021-12-10 12:48:31,521 iteration 2842 : loss : 0.010876, loss_ce: 0.002901
2021-12-10 12:48:34,446 iteration 2843 : loss : 0.008515, loss_ce: 0.003207
2021-12-10 12:48:37,326 iteration 2844 : loss : 0.007187, loss_ce: 0.003093
2021-12-10 12:48:40,161 iteration 2845 : loss : 0.010539, loss_ce: 0.005117
2021-12-10 12:48:43,002 iteration 2846 : loss : 0.008827, loss_ce: 0.003314
2021-12-10 12:48:46,017 iteration 2847 : loss : 0.007902, loss_ce: 0.003693
2021-12-10 12:48:48,804 iteration 2848 : loss : 0.007365, loss_ce: 0.002782
2021-12-10 12:48:51,796 iteration 2849 : loss : 0.006652, loss_ce: 0.002684
2021-12-10 12:48:54,706 iteration 2850 : loss : 0.009016, loss_ce: 0.003534
2021-12-10 12:48:57,543 iteration 2851 : loss : 0.007760, loss_ce: 0.002490
2021-12-10 12:49:00,576 iteration 2852 : loss : 0.008901, loss_ce: 0.003143
2021-12-10 12:49:03,423 iteration 2853 : loss : 0.005805, loss_ce: 0.001873
2021-12-10 12:49:06,315 iteration 2854 : loss : 0.009477, loss_ce: 0.003541
2021-12-10 12:49:09,249 iteration 2855 : loss : 0.008030, loss_ce: 0.003034
2021-12-10 12:49:11,989 iteration 2856 : loss : 0.008850, loss_ce: 0.002525
 42%|███████████▎               | 168/400 [2:22:34<3:20:28, 51.85s/it]2021-12-10 12:49:14,963 iteration 2857 : loss : 0.006749, loss_ce: 0.002371
2021-12-10 12:49:17,805 iteration 2858 : loss : 0.008772, loss_ce: 0.002361
2021-12-10 12:49:20,841 iteration 2859 : loss : 0.008381, loss_ce: 0.004037
2021-12-10 12:49:23,574 iteration 2860 : loss : 0.008953, loss_ce: 0.004583
2021-12-10 12:49:26,402 iteration 2861 : loss : 0.008392, loss_ce: 0.003256
2021-12-10 12:49:29,443 iteration 2862 : loss : 0.007404, loss_ce: 0.003150
2021-12-10 12:49:32,297 iteration 2863 : loss : 0.010742, loss_ce: 0.002090
2021-12-10 12:49:35,193 iteration 2864 : loss : 0.008762, loss_ce: 0.002666
2021-12-10 12:49:37,977 iteration 2865 : loss : 0.006927, loss_ce: 0.002866
2021-12-10 12:49:40,847 iteration 2866 : loss : 0.007210, loss_ce: 0.002110
2021-12-10 12:49:43,705 iteration 2867 : loss : 0.008165, loss_ce: 0.003516
2021-12-10 12:49:46,589 iteration 2868 : loss : 0.007903, loss_ce: 0.003252
2021-12-10 12:49:49,321 iteration 2869 : loss : 0.008850, loss_ce: 0.003811
2021-12-10 12:49:52,044 iteration 2870 : loss : 0.009125, loss_ce: 0.003805
2021-12-10 12:49:54,914 iteration 2871 : loss : 0.007568, loss_ce: 0.002226
2021-12-10 12:49:57,851 iteration 2872 : loss : 0.009189, loss_ce: 0.003304
2021-12-10 12:50:00,583 iteration 2873 : loss : 0.008818, loss_ce: 0.002805
 42%|███████████▍               | 169/400 [2:23:23<3:15:50, 50.87s/it]2021-12-10 12:50:03,576 iteration 2874 : loss : 0.009307, loss_ce: 0.003392
2021-12-10 12:50:06,307 iteration 2875 : loss : 0.009929, loss_ce: 0.002202
2021-12-10 12:50:09,206 iteration 2876 : loss : 0.006594, loss_ce: 0.003153
2021-12-10 12:50:12,136 iteration 2877 : loss : 0.007144, loss_ce: 0.002650
2021-12-10 12:50:14,875 iteration 2878 : loss : 0.009739, loss_ce: 0.004461
2021-12-10 12:50:17,760 iteration 2879 : loss : 0.007038, loss_ce: 0.002547
2021-12-10 12:50:20,634 iteration 2880 : loss : 0.007769, loss_ce: 0.002725
2021-12-10 12:50:23,359 iteration 2881 : loss : 0.007830, loss_ce: 0.002785
2021-12-10 12:50:26,106 iteration 2882 : loss : 0.010502, loss_ce: 0.003555
2021-12-10 12:50:28,985 iteration 2883 : loss : 0.007047, loss_ce: 0.002412
2021-12-10 12:50:31,721 iteration 2884 : loss : 0.008248, loss_ce: 0.002949
2021-12-10 12:50:34,621 iteration 2885 : loss : 0.007202, loss_ce: 0.002720
2021-12-10 12:50:37,524 iteration 2886 : loss : 0.009336, loss_ce: 0.004544
2021-12-10 12:50:40,451 iteration 2887 : loss : 0.009375, loss_ce: 0.004020
2021-12-10 12:50:43,188 iteration 2888 : loss : 0.008760, loss_ce: 0.002227
2021-12-10 12:50:46,100 iteration 2889 : loss : 0.007720, loss_ce: 0.002410
2021-12-10 12:50:46,100 Training Data Eval:
2021-12-10 12:51:01,957   Average segmentation loss on training set: 0.0080
2021-12-10 12:51:01,958 Validation Data Eval:
2021-12-10 12:51:07,314   Average segmentation loss on validation set: 0.1131
2021-12-10 12:51:10,174 iteration 2890 : loss : 0.008286, loss_ce: 0.003837
 42%|███████████▍               | 170/400 [2:24:32<3:36:31, 56.49s/it]2021-12-10 12:51:13,107 iteration 2891 : loss : 0.008080, loss_ce: 0.003586
2021-12-10 12:51:16,022 iteration 2892 : loss : 0.006779, loss_ce: 0.002135
2021-12-10 12:51:18,910 iteration 2893 : loss : 0.009117, loss_ce: 0.003652
2021-12-10 12:51:21,646 iteration 2894 : loss : 0.007601, loss_ce: 0.002490
2021-12-10 12:51:24,548 iteration 2895 : loss : 0.007509, loss_ce: 0.003201
2021-12-10 12:51:27,484 iteration 2896 : loss : 0.006943, loss_ce: 0.001724
2021-12-10 12:51:30,268 iteration 2897 : loss : 0.008870, loss_ce: 0.002795
2021-12-10 12:51:33,269 iteration 2898 : loss : 0.006855, loss_ce: 0.002861
2021-12-10 12:51:35,997 iteration 2899 : loss : 0.007638, loss_ce: 0.002169
2021-12-10 12:51:38,856 iteration 2900 : loss : 0.009562, loss_ce: 0.004596
2021-12-10 12:51:41,728 iteration 2901 : loss : 0.008682, loss_ce: 0.003382
2021-12-10 12:51:44,489 iteration 2902 : loss : 0.010137, loss_ce: 0.003123
2021-12-10 12:51:47,244 iteration 2903 : loss : 0.009168, loss_ce: 0.003718
2021-12-10 12:51:50,008 iteration 2904 : loss : 0.008854, loss_ce: 0.003397
2021-12-10 12:51:52,836 iteration 2905 : loss : 0.008517, loss_ce: 0.003215
2021-12-10 12:51:55,741 iteration 2906 : loss : 0.008413, loss_ce: 0.003777
2021-12-10 12:51:58,588 iteration 2907 : loss : 0.008750, loss_ce: 0.004215
 43%|███████████▌               | 171/400 [2:25:21<3:26:20, 54.06s/it]2021-12-10 12:52:01,513 iteration 2908 : loss : 0.010946, loss_ce: 0.005192
2021-12-10 12:52:04,354 iteration 2909 : loss : 0.007878, loss_ce: 0.001712
2021-12-10 12:52:07,198 iteration 2910 : loss : 0.007684, loss_ce: 0.002787
2021-12-10 12:52:10,238 iteration 2911 : loss : 0.007153, loss_ce: 0.002723
2021-12-10 12:52:13,077 iteration 2912 : loss : 0.006687, loss_ce: 0.002719
2021-12-10 12:52:15,976 iteration 2913 : loss : 0.007350, loss_ce: 0.002631
2021-12-10 12:52:18,864 iteration 2914 : loss : 0.007821, loss_ce: 0.002771
2021-12-10 12:52:21,789 iteration 2915 : loss : 0.008128, loss_ce: 0.003940
2021-12-10 12:52:24,636 iteration 2916 : loss : 0.008410, loss_ce: 0.003132
2021-12-10 12:52:27,480 iteration 2917 : loss : 0.006884, loss_ce: 0.003195
2021-12-10 12:52:30,510 iteration 2918 : loss : 0.010091, loss_ce: 0.003418
2021-12-10 12:52:33,371 iteration 2919 : loss : 0.007768, loss_ce: 0.001553
2021-12-10 12:52:36,126 iteration 2920 : loss : 0.007978, loss_ce: 0.003648
2021-12-10 12:52:39,021 iteration 2921 : loss : 0.007948, loss_ce: 0.003133
2021-12-10 12:52:41,760 iteration 2922 : loss : 0.008056, loss_ce: 0.003031
2021-12-10 12:52:44,526 iteration 2923 : loss : 0.007829, loss_ce: 0.002538
2021-12-10 12:52:47,393 iteration 2924 : loss : 0.007307, loss_ce: 0.002995
 43%|███████████▌               | 172/400 [2:26:10<3:19:27, 52.49s/it]2021-12-10 12:52:50,187 iteration 2925 : loss : 0.005945, loss_ce: 0.001809
2021-12-10 12:52:53,030 iteration 2926 : loss : 0.007317, loss_ce: 0.003000
2021-12-10 12:52:55,929 iteration 2927 : loss : 0.011929, loss_ce: 0.003683
2021-12-10 12:52:58,852 iteration 2928 : loss : 0.007187, loss_ce: 0.003158
2021-12-10 12:53:01,590 iteration 2929 : loss : 0.007603, loss_ce: 0.003104
2021-12-10 12:53:04,626 iteration 2930 : loss : 0.006502, loss_ce: 0.002911
2021-12-10 12:53:07,402 iteration 2931 : loss : 0.008338, loss_ce: 0.003843
2021-12-10 12:53:10,253 iteration 2932 : loss : 0.008052, loss_ce: 0.002794
2021-12-10 12:53:13,112 iteration 2933 : loss : 0.008593, loss_ce: 0.003057
2021-12-10 12:53:15,896 iteration 2934 : loss : 0.007723, loss_ce: 0.003219
2021-12-10 12:53:18,630 iteration 2935 : loss : 0.010699, loss_ce: 0.003451
2021-12-10 12:53:21,360 iteration 2936 : loss : 0.008305, loss_ce: 0.001952
2021-12-10 12:53:24,228 iteration 2937 : loss : 0.010295, loss_ce: 0.003015
2021-12-10 12:53:27,098 iteration 2938 : loss : 0.008958, loss_ce: 0.002886
2021-12-10 12:53:29,933 iteration 2939 : loss : 0.008496, loss_ce: 0.003600
2021-12-10 12:53:32,765 iteration 2940 : loss : 0.008188, loss_ce: 0.003497
2021-12-10 12:53:35,776 iteration 2941 : loss : 0.007640, loss_ce: 0.003099
 43%|███████████▋               | 173/400 [2:26:58<3:13:55, 51.26s/it]2021-12-10 12:53:38,561 iteration 2942 : loss : 0.007503, loss_ce: 0.003396
2021-12-10 12:53:41,396 iteration 2943 : loss : 0.012495, loss_ce: 0.003053
2021-12-10 12:53:44,229 iteration 2944 : loss : 0.010195, loss_ce: 0.003358
2021-12-10 12:53:47,255 iteration 2945 : loss : 0.007501, loss_ce: 0.002293
2021-12-10 12:53:50,166 iteration 2946 : loss : 0.008414, loss_ce: 0.002984
2021-12-10 12:53:53,095 iteration 2947 : loss : 0.013137, loss_ce: 0.004411
2021-12-10 12:53:56,030 iteration 2948 : loss : 0.008933, loss_ce: 0.003530
2021-12-10 12:53:58,941 iteration 2949 : loss : 0.007581, loss_ce: 0.003389
2021-12-10 12:54:01,800 iteration 2950 : loss : 0.006216, loss_ce: 0.002395
2021-12-10 12:54:04,712 iteration 2951 : loss : 0.011291, loss_ce: 0.005096
2021-12-10 12:54:07,488 iteration 2952 : loss : 0.009042, loss_ce: 0.003174
2021-12-10 12:54:10,513 iteration 2953 : loss : 0.013381, loss_ce: 0.003423
2021-12-10 12:54:13,401 iteration 2954 : loss : 0.008660, loss_ce: 0.003603
2021-12-10 12:54:16,194 iteration 2955 : loss : 0.008313, loss_ce: 0.003440
2021-12-10 12:54:19,095 iteration 2956 : loss : 0.008837, loss_ce: 0.002646
2021-12-10 12:54:21,933 iteration 2957 : loss : 0.009792, loss_ce: 0.004533
2021-12-10 12:54:24,915 iteration 2958 : loss : 0.007388, loss_ce: 0.002698
 44%|███████████▋               | 174/400 [2:27:47<3:10:40, 50.62s/it]2021-12-10 12:54:27,706 iteration 2959 : loss : 0.008322, loss_ce: 0.002743
2021-12-10 12:54:30,728 iteration 2960 : loss : 0.010340, loss_ce: 0.005504
2021-12-10 12:54:33,570 iteration 2961 : loss : 0.010103, loss_ce: 0.003892
2021-12-10 12:54:36,466 iteration 2962 : loss : 0.010840, loss_ce: 0.003504
2021-12-10 12:54:39,367 iteration 2963 : loss : 0.008095, loss_ce: 0.003136
2021-12-10 12:54:42,298 iteration 2964 : loss : 0.008218, loss_ce: 0.003742
2021-12-10 12:54:45,164 iteration 2965 : loss : 0.009313, loss_ce: 0.002786
2021-12-10 12:54:48,190 iteration 2966 : loss : 0.009739, loss_ce: 0.003106
2021-12-10 12:54:51,060 iteration 2967 : loss : 0.007855, loss_ce: 0.003133
2021-12-10 12:54:53,900 iteration 2968 : loss : 0.009255, loss_ce: 0.003211
2021-12-10 12:54:56,866 iteration 2969 : loss : 0.007470, loss_ce: 0.002864
2021-12-10 12:54:59,780 iteration 2970 : loss : 0.008679, loss_ce: 0.003469
2021-12-10 12:55:02,672 iteration 2971 : loss : 0.008536, loss_ce: 0.002584
2021-12-10 12:55:05,451 iteration 2972 : loss : 0.009485, loss_ce: 0.003216
2021-12-10 12:55:08,455 iteration 2973 : loss : 0.008635, loss_ce: 0.003714
2021-12-10 12:55:11,370 iteration 2974 : loss : 0.008416, loss_ce: 0.003697
2021-12-10 12:55:11,370 Training Data Eval:
2021-12-10 12:55:27,524   Average segmentation loss on training set: 0.0094
2021-12-10 12:55:27,524 Validation Data Eval:
2021-12-10 12:55:33,118   Average segmentation loss on validation set: 0.1077
2021-12-10 12:55:35,972 iteration 2975 : loss : 0.007842, loss_ce: 0.003087
 44%|███████████▊               | 175/400 [2:28:58<3:32:49, 56.75s/it]2021-12-10 12:55:38,768 iteration 2976 : loss : 0.007399, loss_ce: 0.002997
2021-12-10 12:55:41,518 iteration 2977 : loss : 0.007182, loss_ce: 0.002395
2021-12-10 12:55:44,269 iteration 2978 : loss : 0.006314, loss_ce: 0.002038
2021-12-10 12:55:47,110 iteration 2979 : loss : 0.007254, loss_ce: 0.003159
2021-12-10 12:55:49,998 iteration 2980 : loss : 0.008293, loss_ce: 0.004158
2021-12-10 12:55:52,728 iteration 2981 : loss : 0.007186, loss_ce: 0.002721
2021-12-10 12:55:55,637 iteration 2982 : loss : 0.006683, loss_ce: 0.002820
2021-12-10 12:55:58,583 iteration 2983 : loss : 0.007501, loss_ce: 0.003487
2021-12-10 12:56:01,515 iteration 2984 : loss : 0.010592, loss_ce: 0.003652
2021-12-10 12:56:04,447 iteration 2985 : loss : 0.007005, loss_ce: 0.002646
2021-12-10 12:56:07,321 iteration 2986 : loss : 0.006482, loss_ce: 0.003001
2021-12-10 12:56:10,234 iteration 2987 : loss : 0.010467, loss_ce: 0.003279
2021-12-10 12:56:13,159 iteration 2988 : loss : 0.006555, loss_ce: 0.002171
2021-12-10 12:56:16,052 iteration 2989 : loss : 0.009430, loss_ce: 0.003004
2021-12-10 12:56:18,956 iteration 2990 : loss : 0.008147, loss_ce: 0.004133
2021-12-10 12:56:21,796 iteration 2991 : loss : 0.007683, loss_ce: 0.002196
2021-12-10 12:56:24,627 iteration 2992 : loss : 0.007157, loss_ce: 0.002524
 44%|███████████▉               | 176/400 [2:29:47<3:22:48, 54.32s/it]2021-12-10 12:56:27,570 iteration 2993 : loss : 0.007642, loss_ce: 0.002734
2021-12-10 12:56:30,435 iteration 2994 : loss : 0.008320, loss_ce: 0.003434
2021-12-10 12:56:33,322 iteration 2995 : loss : 0.008704, loss_ce: 0.003627
2021-12-10 12:56:36,054 iteration 2996 : loss : 0.009729, loss_ce: 0.003150
2021-12-10 12:56:38,781 iteration 2997 : loss : 0.008298, loss_ce: 0.003779
2021-12-10 12:56:41,650 iteration 2998 : loss : 0.007836, loss_ce: 0.002795
2021-12-10 12:56:44,375 iteration 2999 : loss : 0.007122, loss_ce: 0.002366
2021-12-10 12:56:47,387 iteration 3000 : loss : 0.008966, loss_ce: 0.003774
2021-12-10 12:56:50,293 iteration 3001 : loss : 0.008455, loss_ce: 0.004408
2021-12-10 12:56:53,159 iteration 3002 : loss : 0.007754, loss_ce: 0.003167
2021-12-10 12:56:56,124 iteration 3003 : loss : 0.006495, loss_ce: 0.000982
2021-12-10 12:56:59,048 iteration 3004 : loss : 0.007153, loss_ce: 0.003380
2021-12-10 12:57:01,822 iteration 3005 : loss : 0.007461, loss_ce: 0.002616
2021-12-10 12:57:04,856 iteration 3006 : loss : 0.010394, loss_ce: 0.002512
2021-12-10 12:57:07,730 iteration 3007 : loss : 0.007729, loss_ce: 0.003179
2021-12-10 12:57:10,593 iteration 3008 : loss : 0.007617, loss_ce: 0.003206
2021-12-10 12:57:13,448 iteration 3009 : loss : 0.009803, loss_ce: 0.003944
 44%|███████████▉               | 177/400 [2:30:36<3:15:45, 52.67s/it]2021-12-10 12:57:16,233 iteration 3010 : loss : 0.008302, loss_ce: 0.002520
2021-12-10 12:57:18,982 iteration 3011 : loss : 0.007770, loss_ce: 0.004334
2021-12-10 12:57:21,864 iteration 3012 : loss : 0.008364, loss_ce: 0.002616
2021-12-10 12:57:24,593 iteration 3013 : loss : 0.008453, loss_ce: 0.003982
2021-12-10 12:57:27,477 iteration 3014 : loss : 0.010039, loss_ce: 0.002779
2021-12-10 12:57:30,410 iteration 3015 : loss : 0.008399, loss_ce: 0.003358
2021-12-10 12:57:33,332 iteration 3016 : loss : 0.007806, loss_ce: 0.002678
2021-12-10 12:57:36,088 iteration 3017 : loss : 0.007425, loss_ce: 0.003077
2021-12-10 12:57:39,128 iteration 3018 : loss : 0.007683, loss_ce: 0.002751
2021-12-10 12:57:41,997 iteration 3019 : loss : 0.009423, loss_ce: 0.002182
2021-12-10 12:57:44,892 iteration 3020 : loss : 0.007958, loss_ce: 0.003355
2021-12-10 12:57:47,820 iteration 3021 : loss : 0.007572, loss_ce: 0.002747
2021-12-10 12:57:50,741 iteration 3022 : loss : 0.008825, loss_ce: 0.003559
2021-12-10 12:57:53,472 iteration 3023 : loss : 0.007646, loss_ce: 0.002566
2021-12-10 12:57:56,357 iteration 3024 : loss : 0.007762, loss_ce: 0.003467
2021-12-10 12:57:59,133 iteration 3025 : loss : 0.006755, loss_ce: 0.002511
2021-12-10 12:58:02,138 iteration 3026 : loss : 0.008797, loss_ce: 0.003421
 44%|████████████               | 178/400 [2:31:24<3:10:28, 51.48s/it]2021-12-10 12:58:04,945 iteration 3027 : loss : 0.007379, loss_ce: 0.002921
2021-12-10 12:58:07,841 iteration 3028 : loss : 0.006388, loss_ce: 0.002596
2021-12-10 12:58:10,617 iteration 3029 : loss : 0.008109, loss_ce: 0.002716
2021-12-10 12:58:13,617 iteration 3030 : loss : 0.006432, loss_ce: 0.002388
2021-12-10 12:58:16,454 iteration 3031 : loss : 0.007426, loss_ce: 0.003040
2021-12-10 12:58:19,418 iteration 3032 : loss : 0.007493, loss_ce: 0.003253
2021-12-10 12:58:22,332 iteration 3033 : loss : 0.008262, loss_ce: 0.002886
2021-12-10 12:58:25,220 iteration 3034 : loss : 0.008047, loss_ce: 0.002404
2021-12-10 12:58:28,113 iteration 3035 : loss : 0.007638, loss_ce: 0.002806
2021-12-10 12:58:31,044 iteration 3036 : loss : 0.005603, loss_ce: 0.002383
2021-12-10 12:58:33,877 iteration 3037 : loss : 0.009791, loss_ce: 0.001958
2021-12-10 12:58:36,744 iteration 3038 : loss : 0.007928, loss_ce: 0.003170
2021-12-10 12:58:39,489 iteration 3039 : loss : 0.006925, loss_ce: 0.002491
2021-12-10 12:58:42,224 iteration 3040 : loss : 0.008383, loss_ce: 0.002974
2021-12-10 12:58:45,117 iteration 3041 : loss : 0.008220, loss_ce: 0.003543
2021-12-10 12:58:48,038 iteration 3042 : loss : 0.012589, loss_ce: 0.003488
2021-12-10 12:58:50,774 iteration 3043 : loss : 0.006086, loss_ce: 0.002987
 45%|████████████               | 179/400 [2:32:13<3:06:28, 50.63s/it]2021-12-10 12:58:53,772 iteration 3044 : loss : 0.008232, loss_ce: 0.002502
2021-12-10 12:58:56,686 iteration 3045 : loss : 0.010724, loss_ce: 0.002994
2021-12-10 12:58:59,558 iteration 3046 : loss : 0.008484, loss_ce: 0.003373
2021-12-10 12:59:02,426 iteration 3047 : loss : 0.006628, loss_ce: 0.002313
2021-12-10 12:59:05,284 iteration 3048 : loss : 0.006281, loss_ce: 0.002162
2021-12-10 12:59:08,160 iteration 3049 : loss : 0.009340, loss_ce: 0.004481
2021-12-10 12:59:10,888 iteration 3050 : loss : 0.009711, loss_ce: 0.003855
2021-12-10 12:59:13,613 iteration 3051 : loss : 0.009233, loss_ce: 0.004004
2021-12-10 12:59:16,481 iteration 3052 : loss : 0.010612, loss_ce: 0.003177
2021-12-10 12:59:19,416 iteration 3053 : loss : 0.007694, loss_ce: 0.002905
2021-12-10 12:59:22,142 iteration 3054 : loss : 0.008399, loss_ce: 0.002761
2021-12-10 12:59:25,034 iteration 3055 : loss : 0.008317, loss_ce: 0.003851
2021-12-10 12:59:27,967 iteration 3056 : loss : 0.006681, loss_ce: 0.002741
2021-12-10 12:59:30,890 iteration 3057 : loss : 0.007703, loss_ce: 0.002455
2021-12-10 12:59:33,690 iteration 3058 : loss : 0.008241, loss_ce: 0.004084
2021-12-10 12:59:36,527 iteration 3059 : loss : 0.011636, loss_ce: 0.003797
2021-12-10 12:59:36,527 Training Data Eval:
2021-12-10 12:59:52,753   Average segmentation loss on training set: 0.0074
2021-12-10 12:59:52,754 Validation Data Eval:
2021-12-10 12:59:58,406   Average segmentation loss on validation set: 0.1204
2021-12-10 13:00:01,245 iteration 3060 : loss : 0.007964, loss_ce: 0.002852
 45%|████████████▏              | 180/400 [2:33:24<3:27:27, 56.58s/it]2021-12-10 13:00:04,085 iteration 3061 : loss : 0.006336, loss_ce: 0.002588
2021-12-10 13:00:06,955 iteration 3062 : loss : 0.008557, loss_ce: 0.003282
2021-12-10 13:00:09,814 iteration 3063 : loss : 0.007661, loss_ce: 0.002556
2021-12-10 13:00:12,675 iteration 3064 : loss : 0.007301, loss_ce: 0.002280
2021-12-10 13:00:15,408 iteration 3065 : loss : 0.007311, loss_ce: 0.002587
2021-12-10 13:00:18,163 iteration 3066 : loss : 0.006715, loss_ce: 0.002758
2021-12-10 13:00:21,035 iteration 3067 : loss : 0.009056, loss_ce: 0.003770
2021-12-10 13:00:23,903 iteration 3068 : loss : 0.009273, loss_ce: 0.003425
2021-12-10 13:00:26,744 iteration 3069 : loss : 0.007257, loss_ce: 0.002825
2021-12-10 13:00:29,585 iteration 3070 : loss : 0.006536, loss_ce: 0.002748
2021-12-10 13:00:32,422 iteration 3071 : loss : 0.007487, loss_ce: 0.002697
2021-12-10 13:00:35,451 iteration 3072 : loss : 0.007629, loss_ce: 0.003028
2021-12-10 13:00:38,299 iteration 3073 : loss : 0.007787, loss_ce: 0.004224
2021-12-10 13:00:41,298 iteration 3074 : loss : 0.007536, loss_ce: 0.002584
2021-12-10 13:00:44,083 iteration 3075 : loss : 0.005458, loss_ce: 0.002051
2021-12-10 13:00:47,011 iteration 3076 : loss : 0.007457, loss_ce: 0.003157
2021-12-10 13:00:49,942 iteration 3077 : loss : 0.007337, loss_ce: 0.002041
 45%|████████████▏              | 181/400 [2:34:12<3:17:52, 54.21s/it]2021-12-10 13:00:52,732 iteration 3078 : loss : 0.006753, loss_ce: 0.002471
2021-12-10 13:00:55,700 iteration 3079 : loss : 0.007285, loss_ce: 0.002414
2021-12-10 13:00:58,607 iteration 3080 : loss : 0.006188, loss_ce: 0.002156
2021-12-10 13:01:01,496 iteration 3081 : loss : 0.008679, loss_ce: 0.002264
2021-12-10 13:01:04,270 iteration 3082 : loss : 0.005843, loss_ce: 0.002112
2021-12-10 13:01:07,279 iteration 3083 : loss : 0.007202, loss_ce: 0.002999
2021-12-10 13:01:10,179 iteration 3084 : loss : 0.006651, loss_ce: 0.003351
2021-12-10 13:01:13,061 iteration 3085 : loss : 0.005934, loss_ce: 0.002522
2021-12-10 13:01:16,041 iteration 3086 : loss : 0.007286, loss_ce: 0.002947
2021-12-10 13:01:18,960 iteration 3087 : loss : 0.006503, loss_ce: 0.002063
2021-12-10 13:01:21,797 iteration 3088 : loss : 0.006090, loss_ce: 0.002679
2021-12-10 13:01:24,826 iteration 3089 : loss : 0.009143, loss_ce: 0.002596
2021-12-10 13:01:27,673 iteration 3090 : loss : 0.006720, loss_ce: 0.002462
2021-12-10 13:01:30,566 iteration 3091 : loss : 0.008924, loss_ce: 0.003018
2021-12-10 13:01:33,349 iteration 3092 : loss : 0.007015, loss_ce: 0.002829
2021-12-10 13:01:36,350 iteration 3093 : loss : 0.007103, loss_ce: 0.003261
2021-12-10 13:01:39,267 iteration 3094 : loss : 0.007218, loss_ce: 0.002789
 46%|████████████▎              | 182/400 [2:35:02<3:11:38, 52.74s/it]2021-12-10 13:01:42,230 iteration 3095 : loss : 0.006638, loss_ce: 0.002796
2021-12-10 13:01:45,105 iteration 3096 : loss : 0.006833, loss_ce: 0.003054
2021-12-10 13:01:48,036 iteration 3097 : loss : 0.005687, loss_ce: 0.002605
2021-12-10 13:01:50,918 iteration 3098 : loss : 0.007233, loss_ce: 0.001685
2021-12-10 13:01:53,707 iteration 3099 : loss : 0.008731, loss_ce: 0.003637
2021-12-10 13:01:56,489 iteration 3100 : loss : 0.005675, loss_ce: 0.001216
2021-12-10 13:01:59,496 iteration 3101 : loss : 0.008426, loss_ce: 0.003375
2021-12-10 13:02:02,409 iteration 3102 : loss : 0.006445, loss_ce: 0.002295
2021-12-10 13:02:05,276 iteration 3103 : loss : 0.006174, loss_ce: 0.002768
2021-12-10 13:02:08,113 iteration 3104 : loss : 0.007189, loss_ce: 0.002919
2021-12-10 13:02:11,131 iteration 3105 : loss : 0.006786, loss_ce: 0.001922
2021-12-10 13:02:14,006 iteration 3106 : loss : 0.006551, loss_ce: 0.002507
2021-12-10 13:02:16,919 iteration 3107 : loss : 0.010014, loss_ce: 0.003711
2021-12-10 13:02:19,759 iteration 3108 : loss : 0.007516, loss_ce: 0.003648
2021-12-10 13:02:22,784 iteration 3109 : loss : 0.008493, loss_ce: 0.002987
2021-12-10 13:02:25,636 iteration 3110 : loss : 0.007126, loss_ce: 0.002711
2021-12-10 13:02:28,526 iteration 3111 : loss : 0.006656, loss_ce: 0.002728
 46%|████████████▎              | 183/400 [2:35:51<3:06:59, 51.70s/it]2021-12-10 13:02:31,526 iteration 3112 : loss : 0.006566, loss_ce: 0.002191
2021-12-10 13:02:34,443 iteration 3113 : loss : 0.006383, loss_ce: 0.002547
2021-12-10 13:02:37,232 iteration 3114 : loss : 0.005550, loss_ce: 0.001936
2021-12-10 13:02:40,071 iteration 3115 : loss : 0.008578, loss_ce: 0.004103
2021-12-10 13:02:42,916 iteration 3116 : loss : 0.009858, loss_ce: 0.003436
2021-12-10 13:02:45,940 iteration 3117 : loss : 0.008372, loss_ce: 0.003025
2021-12-10 13:02:48,778 iteration 3118 : loss : 0.007284, loss_ce: 0.002012
2021-12-10 13:02:51,774 iteration 3119 : loss : 0.008329, loss_ce: 0.004208
2021-12-10 13:02:54,576 iteration 3120 : loss : 0.008058, loss_ce: 0.002431
2021-12-10 13:02:57,426 iteration 3121 : loss : 0.007625, loss_ce: 0.002365
2021-12-10 13:03:00,403 iteration 3122 : loss : 0.007065, loss_ce: 0.002978
2021-12-10 13:03:03,323 iteration 3123 : loss : 0.006662, loss_ce: 0.002161
2021-12-10 13:03:06,264 iteration 3124 : loss : 0.008557, loss_ce: 0.003922
2021-12-10 13:03:09,135 iteration 3125 : loss : 0.007031, loss_ce: 0.003162
2021-12-10 13:03:11,980 iteration 3126 : loss : 0.007813, loss_ce: 0.003452
2021-12-10 13:03:14,948 iteration 3127 : loss : 0.007323, loss_ce: 0.001534
2021-12-10 13:03:17,862 iteration 3128 : loss : 0.006884, loss_ce: 0.003278
 46%|████████████▍              | 184/400 [2:36:40<3:03:33, 50.99s/it]2021-12-10 13:03:20,837 iteration 3129 : loss : 0.007039, loss_ce: 0.002823
2021-12-10 13:03:23,757 iteration 3130 : loss : 0.007990, loss_ce: 0.002945
2021-12-10 13:03:26,672 iteration 3131 : loss : 0.007115, loss_ce: 0.002990
2021-12-10 13:03:29,553 iteration 3132 : loss : 0.008156, loss_ce: 0.003193
2021-12-10 13:03:32,485 iteration 3133 : loss : 0.008775, loss_ce: 0.002843
2021-12-10 13:03:35,254 iteration 3134 : loss : 0.007372, loss_ce: 0.003096
2021-12-10 13:03:38,259 iteration 3135 : loss : 0.006239, loss_ce: 0.002338
2021-12-10 13:03:40,996 iteration 3136 : loss : 0.007515, loss_ce: 0.002531
2021-12-10 13:03:44,004 iteration 3137 : loss : 0.006422, loss_ce: 0.002375
2021-12-10 13:03:46,738 iteration 3138 : loss : 0.007173, loss_ce: 0.003460
2021-12-10 13:03:49,733 iteration 3139 : loss : 0.006578, loss_ce: 0.002569
2021-12-10 13:03:52,652 iteration 3140 : loss : 0.005948, loss_ce: 0.002340
2021-12-10 13:03:55,561 iteration 3141 : loss : 0.006639, loss_ce: 0.002043
2021-12-10 13:03:58,488 iteration 3142 : loss : 0.007117, loss_ce: 0.002916
2021-12-10 13:04:01,429 iteration 3143 : loss : 0.006589, loss_ce: 0.001712
2021-12-10 13:04:04,157 iteration 3144 : loss : 0.007218, loss_ce: 0.003222
2021-12-10 13:04:04,157 Training Data Eval:
2021-12-10 13:04:20,236   Average segmentation loss on training set: 0.0062
2021-12-10 13:04:20,236 Validation Data Eval:
2021-12-10 13:04:25,955   Average segmentation loss on validation set: 0.1071
2021-12-10 13:04:28,795 iteration 3145 : loss : 0.005881, loss_ce: 0.002153
 46%|████████████▍              | 185/400 [2:37:51<3:24:09, 56.98s/it]2021-12-10 13:04:31,719 iteration 3146 : loss : 0.007000, loss_ce: 0.003433
2021-12-10 13:04:34,740 iteration 3147 : loss : 0.007207, loss_ce: 0.002237
2021-12-10 13:04:37,671 iteration 3148 : loss : 0.006841, loss_ce: 0.002218
2021-12-10 13:04:40,589 iteration 3149 : loss : 0.006691, loss_ce: 0.002235
2021-12-10 13:04:43,358 iteration 3150 : loss : 0.007496, loss_ce: 0.002723
2021-12-10 13:04:46,337 iteration 3151 : loss : 0.006030, loss_ce: 0.002103
2021-12-10 13:04:49,065 iteration 3152 : loss : 0.005621, loss_ce: 0.002467
2021-12-10 13:04:51,898 iteration 3153 : loss : 0.005198, loss_ce: 0.001842
2021-12-10 13:04:54,905 iteration 3154 : loss : 0.006582, loss_ce: 0.001636
2021-12-10 13:04:57,767 iteration 3155 : loss : 0.007083, loss_ce: 0.002727
2021-12-10 13:05:00,632 iteration 3156 : loss : 0.006603, loss_ce: 0.003043
2021-12-10 13:05:03,489 iteration 3157 : loss : 0.007028, loss_ce: 0.002708
2021-12-10 13:05:06,360 iteration 3158 : loss : 0.005268, loss_ce: 0.001959
2021-12-10 13:05:09,136 iteration 3159 : loss : 0.007437, loss_ce: 0.003546
2021-12-10 13:05:11,878 iteration 3160 : loss : 0.005737, loss_ce: 0.001531
2021-12-10 13:05:14,739 iteration 3161 : loss : 0.007525, loss_ce: 0.003782
2021-12-10 13:05:17,596 iteration 3162 : loss : 0.006018, loss_ce: 0.002673
 46%|████████████▌              | 186/400 [2:38:40<3:14:28, 54.52s/it]2021-12-10 13:05:20,396 iteration 3163 : loss : 0.007468, loss_ce: 0.002683
2021-12-10 13:05:23,222 iteration 3164 : loss : 0.007221, loss_ce: 0.002551
2021-12-10 13:05:26,067 iteration 3165 : loss : 0.006037, loss_ce: 0.003504
2021-12-10 13:05:28,960 iteration 3166 : loss : 0.008365, loss_ce: 0.002847
2021-12-10 13:05:31,892 iteration 3167 : loss : 0.009899, loss_ce: 0.004188
2021-12-10 13:05:34,681 iteration 3168 : loss : 0.007538, loss_ce: 0.002099
2021-12-10 13:05:37,571 iteration 3169 : loss : 0.006250, loss_ce: 0.001690
2021-12-10 13:05:40,472 iteration 3170 : loss : 0.007528, loss_ce: 0.002927
2021-12-10 13:05:43,406 iteration 3171 : loss : 0.008898, loss_ce: 0.003403
2021-12-10 13:05:46,326 iteration 3172 : loss : 0.008820, loss_ce: 0.003061
2021-12-10 13:05:49,225 iteration 3173 : loss : 0.006212, loss_ce: 0.002481
2021-12-10 13:05:52,156 iteration 3174 : loss : 0.006179, loss_ce: 0.001726
2021-12-10 13:05:55,048 iteration 3175 : loss : 0.008029, loss_ce: 0.002402
2021-12-10 13:05:57,784 iteration 3176 : loss : 0.006011, loss_ce: 0.002169
2021-12-10 13:06:00,643 iteration 3177 : loss : 0.008478, loss_ce: 0.002953
2021-12-10 13:06:03,510 iteration 3178 : loss : 0.009122, loss_ce: 0.003130
2021-12-10 13:06:06,365 iteration 3179 : loss : 0.006889, loss_ce: 0.002915
 47%|████████████▌              | 187/400 [2:39:29<3:07:25, 52.80s/it]2021-12-10 13:06:09,153 iteration 3180 : loss : 0.007340, loss_ce: 0.002854
2021-12-10 13:06:11,902 iteration 3181 : loss : 0.007893, loss_ce: 0.001936
2021-12-10 13:06:14,644 iteration 3182 : loss : 0.008542, loss_ce: 0.002753
2021-12-10 13:06:17,495 iteration 3183 : loss : 0.007207, loss_ce: 0.002173
2021-12-10 13:06:20,394 iteration 3184 : loss : 0.006394, loss_ce: 0.002796
2021-12-10 13:06:23,316 iteration 3185 : loss : 0.007274, loss_ce: 0.003109
2021-12-10 13:06:26,054 iteration 3186 : loss : 0.007379, loss_ce: 0.002224
2021-12-10 13:06:28,955 iteration 3187 : loss : 0.012057, loss_ce: 0.002925
2021-12-10 13:06:31,734 iteration 3188 : loss : 0.008154, loss_ce: 0.002797
2021-12-10 13:06:34,733 iteration 3189 : loss : 0.007174, loss_ce: 0.002912
2021-12-10 13:06:37,653 iteration 3190 : loss : 0.009199, loss_ce: 0.003157
2021-12-10 13:06:40,527 iteration 3191 : loss : 0.006370, loss_ce: 0.002146
2021-12-10 13:06:43,365 iteration 3192 : loss : 0.008373, loss_ce: 0.004152
2021-12-10 13:06:46,204 iteration 3193 : loss : 0.007696, loss_ce: 0.003409
2021-12-10 13:06:49,234 iteration 3194 : loss : 0.006657, loss_ce: 0.002381
2021-12-10 13:06:52,084 iteration 3195 : loss : 0.006205, loss_ce: 0.002310
2021-12-10 13:06:54,974 iteration 3196 : loss : 0.009921, loss_ce: 0.003499
 47%|████████████▋              | 188/400 [2:40:17<3:02:06, 51.54s/it]2021-12-10 13:06:57,971 iteration 3197 : loss : 0.005714, loss_ce: 0.001948
2021-12-10 13:07:00,888 iteration 3198 : loss : 0.007510, loss_ce: 0.003053
2021-12-10 13:07:03,797 iteration 3199 : loss : 0.005919, loss_ce: 0.003314
2021-12-10 13:07:06,661 iteration 3200 : loss : 0.006854, loss_ce: 0.002936
2021-12-10 13:07:09,580 iteration 3201 : loss : 0.007924, loss_ce: 0.002729
2021-12-10 13:07:12,450 iteration 3202 : loss : 0.006128, loss_ce: 0.001687
2021-12-10 13:07:15,283 iteration 3203 : loss : 0.005696, loss_ce: 0.001790
2021-12-10 13:07:18,117 iteration 3204 : loss : 0.007019, loss_ce: 0.003058
2021-12-10 13:07:21,130 iteration 3205 : loss : 0.006993, loss_ce: 0.002624
2021-12-10 13:07:23,996 iteration 3206 : loss : 0.007686, loss_ce: 0.003175
2021-12-10 13:07:27,012 iteration 3207 : loss : 0.007109, loss_ce: 0.002337
2021-12-10 13:07:29,897 iteration 3208 : loss : 0.008067, loss_ce: 0.004846
2021-12-10 13:07:32,899 iteration 3209 : loss : 0.006111, loss_ce: 0.002159
2021-12-10 13:07:35,822 iteration 3210 : loss : 0.006083, loss_ce: 0.002156
2021-12-10 13:07:38,695 iteration 3211 : loss : 0.007723, loss_ce: 0.002147
2021-12-10 13:07:41,656 iteration 3212 : loss : 0.006754, loss_ce: 0.002440
2021-12-10 13:07:44,584 iteration 3213 : loss : 0.006111, loss_ce: 0.001949
 47%|████████████▊              | 189/400 [2:41:07<2:59:12, 50.96s/it]2021-12-10 13:07:47,573 iteration 3214 : loss : 0.007605, loss_ce: 0.001980
2021-12-10 13:07:50,296 iteration 3215 : loss : 0.006313, loss_ce: 0.002751
2021-12-10 13:07:53,327 iteration 3216 : loss : 0.006193, loss_ce: 0.001532
2021-12-10 13:07:56,180 iteration 3217 : loss : 0.006628, loss_ce: 0.002536
2021-12-10 13:07:59,211 iteration 3218 : loss : 0.006892, loss_ce: 0.002674
2021-12-10 13:08:02,193 iteration 3219 : loss : 0.006967, loss_ce: 0.003328
2021-12-10 13:08:04,936 iteration 3220 : loss : 0.005282, loss_ce: 0.001783
2021-12-10 13:08:07,796 iteration 3221 : loss : 0.005388, loss_ce: 0.002013
2021-12-10 13:08:10,804 iteration 3222 : loss : 0.008124, loss_ce: 0.002840
2021-12-10 13:08:13,715 iteration 3223 : loss : 0.007388, loss_ce: 0.001750
2021-12-10 13:08:16,582 iteration 3224 : loss : 0.006421, loss_ce: 0.003027
2021-12-10 13:08:19,534 iteration 3225 : loss : 0.005675, loss_ce: 0.002317
2021-12-10 13:08:22,470 iteration 3226 : loss : 0.005821, loss_ce: 0.002298
2021-12-10 13:08:25,404 iteration 3227 : loss : 0.006433, loss_ce: 0.002482
2021-12-10 13:08:28,138 iteration 3228 : loss : 0.007434, loss_ce: 0.003775
2021-12-10 13:08:30,984 iteration 3229 : loss : 0.006236, loss_ce: 0.002187
2021-12-10 13:08:31,008 Training Data Eval:
2021-12-10 13:08:46,561   Average segmentation loss on training set: 0.0062
2021-12-10 13:08:46,562 Validation Data Eval:
2021-12-10 13:08:52,206   Average segmentation loss on validation set: 0.1190
2021-12-10 13:08:55,005 iteration 3230 : loss : 0.007725, loss_ce: 0.003308
 48%|████████████▊              | 190/400 [2:42:17<3:18:47, 56.80s/it]2021-12-10 13:08:57,903 iteration 3231 : loss : 0.007038, loss_ce: 0.002793
2021-12-10 13:09:00,746 iteration 3232 : loss : 0.007279, loss_ce: 0.002355
2021-12-10 13:09:03,590 iteration 3233 : loss : 0.006077, loss_ce: 0.002304
2021-12-10 13:09:06,602 iteration 3234 : loss : 0.005431, loss_ce: 0.002406
2021-12-10 13:09:09,471 iteration 3235 : loss : 0.006549, loss_ce: 0.002255
2021-12-10 13:09:12,334 iteration 3236 : loss : 0.005590, loss_ce: 0.002429
2021-12-10 13:09:15,197 iteration 3237 : loss : 0.006249, loss_ce: 0.003076
2021-12-10 13:09:18,054 iteration 3238 : loss : 0.006039, loss_ce: 0.001824
2021-12-10 13:09:20,913 iteration 3239 : loss : 0.006006, loss_ce: 0.002086
2021-12-10 13:09:23,924 iteration 3240 : loss : 0.006096, loss_ce: 0.001905
2021-12-10 13:09:26,831 iteration 3241 : loss : 0.005547, loss_ce: 0.002383
2021-12-10 13:09:29,672 iteration 3242 : loss : 0.006326, loss_ce: 0.001930
2021-12-10 13:09:32,660 iteration 3243 : loss : 0.009204, loss_ce: 0.002463
2021-12-10 13:09:35,385 iteration 3244 : loss : 0.006362, loss_ce: 0.003020
2021-12-10 13:09:38,355 iteration 3245 : loss : 0.006075, loss_ce: 0.002571
2021-12-10 13:09:41,163 iteration 3246 : loss : 0.006360, loss_ce: 0.002301
2021-12-10 13:09:44,081 iteration 3247 : loss : 0.005810, loss_ce: 0.002248
 48%|████████████▉              | 191/400 [2:43:06<3:09:46, 54.48s/it]2021-12-10 13:09:47,060 iteration 3248 : loss : 0.005659, loss_ce: 0.002408
2021-12-10 13:09:49,832 iteration 3249 : loss : 0.005477, loss_ce: 0.002356
2021-12-10 13:09:52,831 iteration 3250 : loss : 0.005299, loss_ce: 0.002183
2021-12-10 13:09:55,749 iteration 3251 : loss : 0.006166, loss_ce: 0.002351
2021-12-10 13:09:58,660 iteration 3252 : loss : 0.006674, loss_ce: 0.002119
2021-12-10 13:10:01,449 iteration 3253 : loss : 0.005187, loss_ce: 0.002040
2021-12-10 13:10:04,464 iteration 3254 : loss : 0.005016, loss_ce: 0.002234
2021-12-10 13:10:07,396 iteration 3255 : loss : 0.006466, loss_ce: 0.002177
2021-12-10 13:10:10,199 iteration 3256 : loss : 0.005428, loss_ce: 0.001993
2021-12-10 13:10:13,141 iteration 3257 : loss : 0.005479, loss_ce: 0.001758
2021-12-10 13:10:16,068 iteration 3258 : loss : 0.005937, loss_ce: 0.002887
2021-12-10 13:10:18,915 iteration 3259 : loss : 0.007524, loss_ce: 0.002318
2021-12-10 13:10:21,915 iteration 3260 : loss : 0.007126, loss_ce: 0.002849
2021-12-10 13:10:24,648 iteration 3261 : loss : 0.008298, loss_ce: 0.002799
2021-12-10 13:10:27,648 iteration 3262 : loss : 0.005250, loss_ce: 0.001744
2021-12-10 13:10:30,444 iteration 3263 : loss : 0.007175, loss_ce: 0.003549
2021-12-10 13:10:33,234 iteration 3264 : loss : 0.005404, loss_ce: 0.001594
 48%|████████████▉              | 192/400 [2:43:56<3:03:20, 52.89s/it]2021-12-10 13:10:36,230 iteration 3265 : loss : 0.008871, loss_ce: 0.002442
2021-12-10 13:10:38,985 iteration 3266 : loss : 0.005589, loss_ce: 0.002737
2021-12-10 13:10:41,739 iteration 3267 : loss : 0.005232, loss_ce: 0.002731
2021-12-10 13:10:44,488 iteration 3268 : loss : 0.006878, loss_ce: 0.001757
2021-12-10 13:10:47,419 iteration 3269 : loss : 0.005946, loss_ce: 0.002247
2021-12-10 13:10:50,186 iteration 3270 : loss : 0.006762, loss_ce: 0.002433
2021-12-10 13:10:53,053 iteration 3271 : loss : 0.007655, loss_ce: 0.002720
2021-12-10 13:10:55,892 iteration 3272 : loss : 0.006292, loss_ce: 0.002246
2021-12-10 13:10:58,729 iteration 3273 : loss : 0.004881, loss_ce: 0.001722
2021-12-10 13:11:01,564 iteration 3274 : loss : 0.005775, loss_ce: 0.001583
2021-12-10 13:11:04,400 iteration 3275 : loss : 0.005279, loss_ce: 0.001737
2021-12-10 13:11:07,399 iteration 3276 : loss : 0.005589, loss_ce: 0.002536
2021-12-10 13:11:10,322 iteration 3277 : loss : 0.006944, loss_ce: 0.002981
2021-12-10 13:11:13,222 iteration 3278 : loss : 0.007626, loss_ce: 0.002389
2021-12-10 13:11:16,113 iteration 3279 : loss : 0.006586, loss_ce: 0.002408
2021-12-10 13:11:19,046 iteration 3280 : loss : 0.006813, loss_ce: 0.002744
2021-12-10 13:11:21,970 iteration 3281 : loss : 0.004993, loss_ce: 0.001529
 48%|█████████████              | 193/400 [2:44:44<2:58:08, 51.64s/it]2021-12-10 13:11:24,926 iteration 3282 : loss : 0.006484, loss_ce: 0.002696
2021-12-10 13:11:27,815 iteration 3283 : loss : 0.006339, loss_ce: 0.002738
2021-12-10 13:11:30,739 iteration 3284 : loss : 0.007683, loss_ce: 0.003158
2021-12-10 13:11:33,739 iteration 3285 : loss : 0.005363, loss_ce: 0.001952
2021-12-10 13:11:36,661 iteration 3286 : loss : 0.005684, loss_ce: 0.001979
2021-12-10 13:11:39,500 iteration 3287 : loss : 0.007270, loss_ce: 0.002124
2021-12-10 13:11:42,469 iteration 3288 : loss : 0.005363, loss_ce: 0.001680
2021-12-10 13:11:45,271 iteration 3289 : loss : 0.005842, loss_ce: 0.002679
2021-12-10 13:11:48,106 iteration 3290 : loss : 0.005624, loss_ce: 0.001699
2021-12-10 13:11:51,107 iteration 3291 : loss : 0.006269, loss_ce: 0.001641
2021-12-10 13:11:54,003 iteration 3292 : loss : 0.005972, loss_ce: 0.002705
2021-12-10 13:11:56,933 iteration 3293 : loss : 0.005638, loss_ce: 0.002136
2021-12-10 13:11:59,853 iteration 3294 : loss : 0.006055, loss_ce: 0.002897
2021-12-10 13:12:02,725 iteration 3295 : loss : 0.005955, loss_ce: 0.002533
2021-12-10 13:12:05,663 iteration 3296 : loss : 0.005096, loss_ce: 0.001797
2021-12-10 13:12:08,499 iteration 3297 : loss : 0.006452, loss_ce: 0.001765
2021-12-10 13:12:11,395 iteration 3298 : loss : 0.005531, loss_ce: 0.001955
 48%|█████████████              | 194/400 [2:45:34<2:55:01, 50.98s/it]2021-12-10 13:12:14,389 iteration 3299 : loss : 0.009309, loss_ce: 0.002375
2021-12-10 13:12:17,315 iteration 3300 : loss : 0.005816, loss_ce: 0.002443
2021-12-10 13:12:20,213 iteration 3301 : loss : 0.007011, loss_ce: 0.002049
2021-12-10 13:12:22,936 iteration 3302 : loss : 0.006152, loss_ce: 0.002639
2021-12-10 13:12:25,689 iteration 3303 : loss : 0.005023, loss_ce: 0.002045
2021-12-10 13:12:28,608 iteration 3304 : loss : 0.004662, loss_ce: 0.002299
2021-12-10 13:12:31,358 iteration 3305 : loss : 0.007179, loss_ce: 0.003299
2021-12-10 13:12:34,196 iteration 3306 : loss : 0.005568, loss_ce: 0.001973
2021-12-10 13:12:37,062 iteration 3307 : loss : 0.005788, loss_ce: 0.002433
2021-12-10 13:12:39,900 iteration 3308 : loss : 0.007010, loss_ce: 0.002607
2021-12-10 13:12:42,731 iteration 3309 : loss : 0.006280, loss_ce: 0.002779
2021-12-10 13:12:45,626 iteration 3310 : loss : 0.005797, loss_ce: 0.003023
2021-12-10 13:12:48,404 iteration 3311 : loss : 0.006401, loss_ce: 0.002590
2021-12-10 13:12:51,265 iteration 3312 : loss : 0.007451, loss_ce: 0.002848
2021-12-10 13:12:54,136 iteration 3313 : loss : 0.007414, loss_ce: 0.002471
2021-12-10 13:12:56,997 iteration 3314 : loss : 0.005573, loss_ce: 0.002765
2021-12-10 13:12:56,997 Training Data Eval:
2021-12-10 13:13:12,357   Average segmentation loss on training set: 0.0067
2021-12-10 13:13:12,358 Validation Data Eval:
2021-12-10 13:13:17,939   Average segmentation loss on validation set: 0.1261
2021-12-10 13:13:20,835 iteration 3315 : loss : 0.006439, loss_ce: 0.002339
 49%|█████████████▏             | 195/400 [2:46:43<3:13:05, 56.51s/it]2021-12-10 13:13:23,822 iteration 3316 : loss : 0.005900, loss_ce: 0.002078
2021-12-10 13:13:26,741 iteration 3317 : loss : 0.005853, loss_ce: 0.002128
2021-12-10 13:13:29,638 iteration 3318 : loss : 0.006904, loss_ce: 0.003117
2021-12-10 13:13:32,540 iteration 3319 : loss : 0.005745, loss_ce: 0.002652
2021-12-10 13:13:35,588 iteration 3320 : loss : 0.007107, loss_ce: 0.002480
2021-12-10 13:13:38,436 iteration 3321 : loss : 0.006559, loss_ce: 0.003083
2021-12-10 13:13:41,449 iteration 3322 : loss : 0.006168, loss_ce: 0.003433
2021-12-10 13:13:44,317 iteration 3323 : loss : 0.009061, loss_ce: 0.003076
2021-12-10 13:13:47,187 iteration 3324 : loss : 0.006028, loss_ce: 0.002408
2021-12-10 13:13:50,099 iteration 3325 : loss : 0.008047, loss_ce: 0.003476
2021-12-10 13:13:52,826 iteration 3326 : loss : 0.007747, loss_ce: 0.003317
2021-12-10 13:13:55,579 iteration 3327 : loss : 0.006186, loss_ce: 0.002423
2021-12-10 13:13:58,498 iteration 3328 : loss : 0.009579, loss_ce: 0.003285
2021-12-10 13:14:01,228 iteration 3329 : loss : 0.007646, loss_ce: 0.002614
2021-12-10 13:14:04,072 iteration 3330 : loss : 0.007561, loss_ce: 0.003261
2021-12-10 13:14:06,904 iteration 3331 : loss : 0.007211, loss_ce: 0.003319
2021-12-10 13:14:09,812 iteration 3332 : loss : 0.006594, loss_ce: 0.002629
 49%|█████████████▏             | 196/400 [2:47:32<3:04:28, 54.26s/it]2021-12-10 13:14:12,735 iteration 3333 : loss : 0.006722, loss_ce: 0.003484
2021-12-10 13:14:15,604 iteration 3334 : loss : 0.007740, loss_ce: 0.003398
2021-12-10 13:14:18,565 iteration 3335 : loss : 0.007604, loss_ce: 0.003565
2021-12-10 13:14:21,494 iteration 3336 : loss : 0.008418, loss_ce: 0.003148
2021-12-10 13:14:24,436 iteration 3337 : loss : 0.007189, loss_ce: 0.003457
2021-12-10 13:14:27,310 iteration 3338 : loss : 0.007714, loss_ce: 0.003282
2021-12-10 13:14:30,160 iteration 3339 : loss : 0.006180, loss_ce: 0.002380
2021-12-10 13:14:33,173 iteration 3340 : loss : 0.006480, loss_ce: 0.002256
2021-12-10 13:14:36,078 iteration 3341 : loss : 0.007506, loss_ce: 0.002382
2021-12-10 13:14:38,915 iteration 3342 : loss : 0.006003, loss_ce: 0.002501
2021-12-10 13:14:41,915 iteration 3343 : loss : 0.007718, loss_ce: 0.003614
2021-12-10 13:14:44,845 iteration 3344 : loss : 0.008592, loss_ce: 0.003712
2021-12-10 13:14:47,720 iteration 3345 : loss : 0.008721, loss_ce: 0.004268
2021-12-10 13:14:50,566 iteration 3346 : loss : 0.005958, loss_ce: 0.002175
2021-12-10 13:14:53,610 iteration 3347 : loss : 0.007653, loss_ce: 0.003241
2021-12-10 13:14:56,449 iteration 3348 : loss : 0.008138, loss_ce: 0.003198
2021-12-10 13:14:59,177 iteration 3349 : loss : 0.005141, loss_ce: 0.002005
 49%|█████████████▎             | 197/400 [2:48:22<2:58:35, 52.79s/it]2021-12-10 13:15:01,968 iteration 3350 : loss : 0.008073, loss_ce: 0.002695
2021-12-10 13:15:04,863 iteration 3351 : loss : 0.007272, loss_ce: 0.003464
2021-12-10 13:15:07,588 iteration 3352 : loss : 0.006519, loss_ce: 0.002566
2021-12-10 13:15:10,457 iteration 3353 : loss : 0.007666, loss_ce: 0.003319
2021-12-10 13:15:13,391 iteration 3354 : loss : 0.006941, loss_ce: 0.002054
2021-12-10 13:15:16,307 iteration 3355 : loss : 0.007192, loss_ce: 0.003179
2021-12-10 13:15:19,197 iteration 3356 : loss : 0.005952, loss_ce: 0.002336
2021-12-10 13:15:22,127 iteration 3357 : loss : 0.006043, loss_ce: 0.002885
2021-12-10 13:15:25,059 iteration 3358 : loss : 0.006208, loss_ce: 0.002105
2021-12-10 13:15:27,798 iteration 3359 : loss : 0.005856, loss_ce: 0.001603
2021-12-10 13:15:30,791 iteration 3360 : loss : 0.006591, loss_ce: 0.003306
2021-12-10 13:15:33,666 iteration 3361 : loss : 0.008078, loss_ce: 0.002392
2021-12-10 13:15:36,539 iteration 3362 : loss : 0.007079, loss_ce: 0.002726
2021-12-10 13:15:39,270 iteration 3363 : loss : 0.006730, loss_ce: 0.002304
2021-12-10 13:15:42,261 iteration 3364 : loss : 0.006102, loss_ce: 0.002901
2021-12-10 13:15:45,183 iteration 3365 : loss : 0.005549, loss_ce: 0.002002
2021-12-10 13:15:48,077 iteration 3366 : loss : 0.008324, loss_ce: 0.003859
 50%|█████████████▎             | 198/400 [2:49:10<2:53:47, 51.62s/it]2021-12-10 13:15:51,009 iteration 3367 : loss : 0.009692, loss_ce: 0.003513
2021-12-10 13:15:53,882 iteration 3368 : loss : 0.005393, loss_ce: 0.001897
2021-12-10 13:15:56,644 iteration 3369 : loss : 0.007012, loss_ce: 0.002743
2021-12-10 13:15:59,356 iteration 3370 : loss : 0.006983, loss_ce: 0.002300
2021-12-10 13:16:02,086 iteration 3371 : loss : 0.006336, loss_ce: 0.002565
2021-12-10 13:16:04,921 iteration 3372 : loss : 0.007955, loss_ce: 0.003074
2021-12-10 13:16:07,791 iteration 3373 : loss : 0.006275, loss_ce: 0.002543
2021-12-10 13:16:10,725 iteration 3374 : loss : 0.007128, loss_ce: 0.002615
2021-12-10 13:16:13,456 iteration 3375 : loss : 0.006573, loss_ce: 0.003364
2021-12-10 13:16:16,345 iteration 3376 : loss : 0.008364, loss_ce: 0.002116
2021-12-10 13:16:19,275 iteration 3377 : loss : 0.005082, loss_ce: 0.001888
2021-12-10 13:16:22,204 iteration 3378 : loss : 0.006567, loss_ce: 0.002579
2021-12-10 13:16:25,123 iteration 3379 : loss : 0.006542, loss_ce: 0.003217
2021-12-10 13:16:27,857 iteration 3380 : loss : 0.005848, loss_ce: 0.002184
2021-12-10 13:16:30,820 iteration 3381 : loss : 0.006860, loss_ce: 0.002304
2021-12-10 13:16:33,623 iteration 3382 : loss : 0.005589, loss_ce: 0.001738
2021-12-10 13:16:36,518 iteration 3383 : loss : 0.004901, loss_ce: 0.001828
 50%|█████████████▍             | 199/400 [2:49:59<2:49:44, 50.67s/it]2021-12-10 13:16:39,528 iteration 3384 : loss : 0.005957, loss_ce: 0.002574
2021-12-10 13:16:42,465 iteration 3385 : loss : 0.007569, loss_ce: 0.003466
2021-12-10 13:16:45,383 iteration 3386 : loss : 0.005106, loss_ce: 0.001610
2021-12-10 13:16:48,283 iteration 3387 : loss : 0.005474, loss_ce: 0.002587
2021-12-10 13:16:51,174 iteration 3388 : loss : 0.005304, loss_ce: 0.002315
2021-12-10 13:16:53,962 iteration 3389 : loss : 0.005899, loss_ce: 0.002063
2021-12-10 13:16:56,820 iteration 3390 : loss : 0.004498, loss_ce: 0.001772
2021-12-10 13:16:59,557 iteration 3391 : loss : 0.008094, loss_ce: 0.002996
2021-12-10 13:17:02,287 iteration 3392 : loss : 0.005867, loss_ce: 0.001734
2021-12-10 13:17:05,152 iteration 3393 : loss : 0.005021, loss_ce: 0.001964
2021-12-10 13:17:07,890 iteration 3394 : loss : 0.006964, loss_ce: 0.002505
2021-12-10 13:17:10,752 iteration 3395 : loss : 0.005881, loss_ce: 0.001945
2021-12-10 13:17:13,608 iteration 3396 : loss : 0.005950, loss_ce: 0.002150
2021-12-10 13:17:16,458 iteration 3397 : loss : 0.005121, loss_ce: 0.001776
2021-12-10 13:17:19,464 iteration 3398 : loss : 0.006227, loss_ce: 0.002004
2021-12-10 13:17:22,404 iteration 3399 : loss : 0.005874, loss_ce: 0.002846
2021-12-10 13:17:22,404 Training Data Eval:
2021-12-10 13:17:38,383   Average segmentation loss on training set: 0.0059
2021-12-10 13:17:38,383 Validation Data Eval:
2021-12-10 13:17:43,838   Average segmentation loss on validation set: 0.1241
2021-12-10 13:17:46,698 iteration 3400 : loss : 0.006606, loss_ce: 0.002659
2021-12-10 13:17:52,569 save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/NEW_TU/NEW_TU_ADAM_seed1234_no_daepoch_199.pth
 50%|█████████████▌             | 200/400 [2:51:15<3:14:12, 58.26s/it]2021-12-10 13:17:54,331 iteration 3401 : loss : 0.007339, loss_ce: 0.002349
2021-12-10 13:17:56,773 iteration 3402 : loss : 0.006044, loss_ce: 0.002630
2021-12-10 13:17:59,531 iteration 3403 : loss : 0.005887, loss_ce: 0.003142
2021-12-10 13:18:02,137 iteration 3404 : loss : 0.004236, loss_ce: 0.001394
2021-12-10 13:18:04,874 iteration 3405 : loss : 0.005877, loss_ce: 0.002754
2021-12-10 13:18:07,655 iteration 3406 : loss : 0.005874, loss_ce: 0.002960
2021-12-10 13:18:10,462 iteration 3407 : loss : 0.005636, loss_ce: 0.001844
2021-12-10 13:18:13,200 iteration 3408 : loss : 0.004970, loss_ce: 0.001736
2021-12-10 13:18:15,941 iteration 3409 : loss : 0.006886, loss_ce: 0.002405
2021-12-10 13:18:18,783 iteration 3410 : loss : 0.007791, loss_ce: 0.002567
2021-12-10 13:18:21,634 iteration 3411 : loss : 0.005257, loss_ce: 0.002214
2021-12-10 13:18:24,498 iteration 3412 : loss : 0.005935, loss_ce: 0.002571
2021-12-10 13:18:27,348 iteration 3413 : loss : 0.007096, loss_ce: 0.002699
2021-12-10 13:18:30,366 iteration 3414 : loss : 0.006431, loss_ce: 0.002446
2021-12-10 13:18:33,257 iteration 3415 : loss : 0.005393, loss_ce: 0.002214
2021-12-10 13:18:36,261 iteration 3416 : loss : 0.008028, loss_ce: 0.002825
2021-12-10 13:18:39,177 iteration 3417 : loss : 0.006323, loss_ce: 0.002116
 50%|█████████████▌             | 201/400 [2:52:01<3:01:41, 54.78s/it]2021-12-10 13:18:42,097 iteration 3418 : loss : 0.006505, loss_ce: 0.002869
2021-12-10 13:18:45,013 iteration 3419 : loss : 0.005875, loss_ce: 0.002128
2021-12-10 13:18:47,894 iteration 3420 : loss : 0.005164, loss_ce: 0.002436
2021-12-10 13:18:50,825 iteration 3421 : loss : 0.005972, loss_ce: 0.002622
2021-12-10 13:18:53,687 iteration 3422 : loss : 0.006337, loss_ce: 0.002685
2021-12-10 13:18:56,524 iteration 3423 : loss : 0.005394, loss_ce: 0.001879
2021-12-10 13:18:59,562 iteration 3424 : loss : 0.005012, loss_ce: 0.002080
2021-12-10 13:19:02,407 iteration 3425 : loss : 0.005377, loss_ce: 0.002067
2021-12-10 13:19:05,405 iteration 3426 : loss : 0.005824, loss_ce: 0.001963
2021-12-10 13:19:08,210 iteration 3427 : loss : 0.004642, loss_ce: 0.001600
2021-12-10 13:19:11,148 iteration 3428 : loss : 0.007031, loss_ce: 0.002271
2021-12-10 13:19:14,069 iteration 3429 : loss : 0.005891, loss_ce: 0.002025
2021-12-10 13:19:16,967 iteration 3430 : loss : 0.005826, loss_ce: 0.001937
2021-12-10 13:19:19,894 iteration 3431 : loss : 0.006542, loss_ce: 0.002597
2021-12-10 13:19:22,765 iteration 3432 : loss : 0.005523, loss_ce: 0.002018
2021-12-10 13:19:25,604 iteration 3433 : loss : 0.006900, loss_ce: 0.002800
2021-12-10 13:19:28,579 iteration 3434 : loss : 0.005575, loss_ce: 0.002370
 50%|█████████████▋             | 202/400 [2:52:51<2:55:28, 53.17s/it]2021-12-10 13:19:31,382 iteration 3435 : loss : 0.005543, loss_ce: 0.002198
2021-12-10 13:19:34,409 iteration 3436 : loss : 0.005766, loss_ce: 0.002278
2021-12-10 13:19:37,154 iteration 3437 : loss : 0.005018, loss_ce: 0.001701
2021-12-10 13:19:39,888 iteration 3438 : loss : 0.005779, loss_ce: 0.001767
2021-12-10 13:19:42,639 iteration 3439 : loss : 0.006875, loss_ce: 0.002135
2021-12-10 13:19:45,380 iteration 3440 : loss : 0.005839, loss_ce: 0.002244
2021-12-10 13:19:48,294 iteration 3441 : loss : 0.008101, loss_ce: 0.003333
2021-12-10 13:19:51,025 iteration 3442 : loss : 0.005767, loss_ce: 0.002328
2021-12-10 13:19:53,866 iteration 3443 : loss : 0.004776, loss_ce: 0.001861
2021-12-10 13:19:56,702 iteration 3444 : loss : 0.005902, loss_ce: 0.002218
2021-12-10 13:19:59,588 iteration 3445 : loss : 0.007182, loss_ce: 0.002366
2021-12-10 13:20:02,516 iteration 3446 : loss : 0.005632, loss_ce: 0.002306
2021-12-10 13:20:05,351 iteration 3447 : loss : 0.007367, loss_ce: 0.002276
2021-12-10 13:20:08,178 iteration 3448 : loss : 0.006163, loss_ce: 0.002632
2021-12-10 13:20:11,189 iteration 3449 : loss : 0.006498, loss_ce: 0.003053
2021-12-10 13:20:14,056 iteration 3450 : loss : 0.006712, loss_ce: 0.002918
2021-12-10 13:20:16,916 iteration 3451 : loss : 0.005498, loss_ce: 0.002206
 51%|█████████████▋             | 203/400 [2:53:39<2:49:48, 51.72s/it]2021-12-10 13:20:19,860 iteration 3452 : loss : 0.006353, loss_ce: 0.002781
2021-12-10 13:20:22,636 iteration 3453 : loss : 0.006226, loss_ce: 0.002528
2021-12-10 13:20:25,372 iteration 3454 : loss : 0.006260, loss_ce: 0.001885
2021-12-10 13:20:28,095 iteration 3455 : loss : 0.005716, loss_ce: 0.002245
2021-12-10 13:20:30,967 iteration 3456 : loss : 0.005935, loss_ce: 0.001500
2021-12-10 13:20:33,844 iteration 3457 : loss : 0.007032, loss_ce: 0.002725
2021-12-10 13:20:36,681 iteration 3458 : loss : 0.007288, loss_ce: 0.002380
2021-12-10 13:20:39,512 iteration 3459 : loss : 0.005130, loss_ce: 0.001912
2021-12-10 13:20:42,416 iteration 3460 : loss : 0.005817, loss_ce: 0.002954
2021-12-10 13:20:45,347 iteration 3461 : loss : 0.005289, loss_ce: 0.002541
2021-12-10 13:20:48,273 iteration 3462 : loss : 0.004810, loss_ce: 0.002141
2021-12-10 13:20:50,998 iteration 3463 : loss : 0.005398, loss_ce: 0.002318
2021-12-10 13:20:54,024 iteration 3464 : loss : 0.006033, loss_ce: 0.002509
2021-12-10 13:20:56,881 iteration 3465 : loss : 0.005692, loss_ce: 0.002394
2021-12-10 13:20:59,876 iteration 3466 : loss : 0.006268, loss_ce: 0.002786
2021-12-10 13:21:02,662 iteration 3467 : loss : 0.007777, loss_ce: 0.003691
2021-12-10 13:21:05,438 iteration 3468 : loss : 0.005243, loss_ce: 0.001708
 51%|█████████████▊             | 204/400 [2:54:28<2:45:49, 50.76s/it]2021-12-10 13:21:08,402 iteration 3469 : loss : 0.005764, loss_ce: 0.002397
2021-12-10 13:21:11,306 iteration 3470 : loss : 0.004924, loss_ce: 0.001557
2021-12-10 13:21:14,143 iteration 3471 : loss : 0.005490, loss_ce: 0.002953
2021-12-10 13:21:17,171 iteration 3472 : loss : 0.005746, loss_ce: 0.002505
2021-12-10 13:21:20,020 iteration 3473 : loss : 0.005641, loss_ce: 0.002187
2021-12-10 13:21:22,921 iteration 3474 : loss : 0.006314, loss_ce: 0.002661
2021-12-10 13:21:25,809 iteration 3475 : loss : 0.015380, loss_ce: 0.002805
2021-12-10 13:21:28,741 iteration 3476 : loss : 0.006694, loss_ce: 0.001808
2021-12-10 13:21:31,629 iteration 3477 : loss : 0.007160, loss_ce: 0.003399
2021-12-10 13:21:34,350 iteration 3478 : loss : 0.009173, loss_ce: 0.003446
2021-12-10 13:21:37,390 iteration 3479 : loss : 0.009627, loss_ce: 0.003411
2021-12-10 13:21:40,184 iteration 3480 : loss : 0.007726, loss_ce: 0.003163
2021-12-10 13:21:42,947 iteration 3481 : loss : 0.009056, loss_ce: 0.004266
2021-12-10 13:21:45,708 iteration 3482 : loss : 0.006896, loss_ce: 0.002460
2021-12-10 13:21:48,452 iteration 3483 : loss : 0.006177, loss_ce: 0.002376
2021-12-10 13:21:51,305 iteration 3484 : loss : 0.007590, loss_ce: 0.003218
2021-12-10 13:21:51,305 Training Data Eval:
2021-12-10 13:22:07,265   Average segmentation loss on training set: 0.0084
2021-12-10 13:22:07,265 Validation Data Eval:
2021-12-10 13:22:12,954   Average segmentation loss on validation set: 0.1129
2021-12-10 13:22:15,865 iteration 3485 : loss : 0.007886, loss_ce: 0.003178
 51%|█████████████▊             | 205/400 [2:55:38<3:04:08, 56.66s/it]2021-12-10 13:22:18,830 iteration 3486 : loss : 0.008436, loss_ce: 0.003122
2021-12-10 13:22:21,753 iteration 3487 : loss : 0.008581, loss_ce: 0.003113
2021-12-10 13:22:24,491 iteration 3488 : loss : 0.009491, loss_ce: 0.002223
2021-12-10 13:22:27,349 iteration 3489 : loss : 0.007722, loss_ce: 0.002629
2021-12-10 13:22:30,346 iteration 3490 : loss : 0.007475, loss_ce: 0.002115
2021-12-10 13:22:33,266 iteration 3491 : loss : 0.007037, loss_ce: 0.001298
2021-12-10 13:22:36,102 iteration 3492 : loss : 0.007360, loss_ce: 0.002382
2021-12-10 13:22:39,118 iteration 3493 : loss : 0.006754, loss_ce: 0.002945
2021-12-10 13:22:41,975 iteration 3494 : loss : 0.007482, loss_ce: 0.003336
2021-12-10 13:22:44,903 iteration 3495 : loss : 0.007574, loss_ce: 0.002723
2021-12-10 13:22:47,665 iteration 3496 : loss : 0.007516, loss_ce: 0.003281
2021-12-10 13:22:50,697 iteration 3497 : loss : 0.007007, loss_ce: 0.002099
2021-12-10 13:22:53,570 iteration 3498 : loss : 0.006864, loss_ce: 0.003545
2021-12-10 13:22:56,423 iteration 3499 : loss : 0.006333, loss_ce: 0.002905
2021-12-10 13:22:59,255 iteration 3500 : loss : 0.006876, loss_ce: 0.002645
2021-12-10 13:23:02,081 iteration 3501 : loss : 0.007682, loss_ce: 0.002053
2021-12-10 13:23:05,116 iteration 3502 : loss : 0.006788, loss_ce: 0.003108
 52%|█████████████▉             | 206/400 [2:56:27<2:56:00, 54.43s/it]2021-12-10 13:23:07,925 iteration 3503 : loss : 0.005667, loss_ce: 0.001950
2021-12-10 13:23:10,779 iteration 3504 : loss : 0.005099, loss_ce: 0.001586
2021-12-10 13:23:13,655 iteration 3505 : loss : 0.005877, loss_ce: 0.001976
2021-12-10 13:23:16,400 iteration 3506 : loss : 0.006252, loss_ce: 0.002719
2021-12-10 13:23:19,126 iteration 3507 : loss : 0.006725, loss_ce: 0.002221
2021-12-10 13:23:21,998 iteration 3508 : loss : 0.013447, loss_ce: 0.003865
2021-12-10 13:23:24,869 iteration 3509 : loss : 0.006946, loss_ce: 0.003212
2021-12-10 13:23:27,788 iteration 3510 : loss : 0.006720, loss_ce: 0.002743
2021-12-10 13:23:30,516 iteration 3511 : loss : 0.007256, loss_ce: 0.003981
2021-12-10 13:23:33,407 iteration 3512 : loss : 0.007925, loss_ce: 0.001797
2021-12-10 13:23:36,338 iteration 3513 : loss : 0.006205, loss_ce: 0.002893
2021-12-10 13:23:39,258 iteration 3514 : loss : 0.005982, loss_ce: 0.002264
2021-12-10 13:23:41,986 iteration 3515 : loss : 0.005427, loss_ce: 0.001513
2021-12-10 13:23:44,882 iteration 3516 : loss : 0.006134, loss_ce: 0.002375
2021-12-10 13:23:47,808 iteration 3517 : loss : 0.006104, loss_ce: 0.002422
2021-12-10 13:23:50,729 iteration 3518 : loss : 0.009055, loss_ce: 0.002929
2021-12-10 13:23:53,526 iteration 3519 : loss : 0.007601, loss_ce: 0.002678
 52%|█████████████▉             | 207/400 [2:57:16<2:49:17, 52.63s/it]2021-12-10 13:23:56,431 iteration 3520 : loss : 0.005489, loss_ce: 0.001601
2021-12-10 13:23:59,270 iteration 3521 : loss : 0.006754, loss_ce: 0.002103
2021-12-10 13:24:02,294 iteration 3522 : loss : 0.005715, loss_ce: 0.001748
2021-12-10 13:24:05,150 iteration 3523 : loss : 0.004937, loss_ce: 0.001959
2021-12-10 13:24:08,081 iteration 3524 : loss : 0.005478, loss_ce: 0.002406
2021-12-10 13:24:11,002 iteration 3525 : loss : 0.006172, loss_ce: 0.002179
2021-12-10 13:24:13,732 iteration 3526 : loss : 0.005686, loss_ce: 0.001809
2021-12-10 13:24:16,613 iteration 3527 : loss : 0.005337, loss_ce: 0.002578
2021-12-10 13:24:19,513 iteration 3528 : loss : 0.005920, loss_ce: 0.001647
2021-12-10 13:24:22,446 iteration 3529 : loss : 0.005318, loss_ce: 0.002285
2021-12-10 13:24:25,368 iteration 3530 : loss : 0.008565, loss_ce: 0.003900
2021-12-10 13:24:28,098 iteration 3531 : loss : 0.007452, loss_ce: 0.003557
2021-12-10 13:24:31,133 iteration 3532 : loss : 0.005753, loss_ce: 0.002424
2021-12-10 13:24:33,979 iteration 3533 : loss : 0.007231, loss_ce: 0.003266
2021-12-10 13:24:37,005 iteration 3534 : loss : 0.008497, loss_ce: 0.002798
2021-12-10 13:24:39,883 iteration 3535 : loss : 0.006670, loss_ce: 0.002522
2021-12-10 13:24:42,734 iteration 3536 : loss : 0.006644, loss_ce: 0.002924
 52%|██████████████             | 208/400 [2:58:05<2:45:08, 51.61s/it]2021-12-10 13:24:45,582 iteration 3537 : loss : 0.004255, loss_ce: 0.001558
2021-12-10 13:24:48,583 iteration 3538 : loss : 0.009154, loss_ce: 0.003749
2021-12-10 13:24:51,504 iteration 3539 : loss : 0.005436, loss_ce: 0.002004
2021-12-10 13:24:54,339 iteration 3540 : loss : 0.005995, loss_ce: 0.002102
2021-12-10 13:24:57,361 iteration 3541 : loss : 0.004713, loss_ce: 0.002229
2021-12-10 13:25:00,197 iteration 3542 : loss : 0.005045, loss_ce: 0.002256
2021-12-10 13:25:03,092 iteration 3543 : loss : 0.006138, loss_ce: 0.002360
2021-12-10 13:25:06,021 iteration 3544 : loss : 0.005920, loss_ce: 0.002573
2021-12-10 13:25:08,763 iteration 3545 : loss : 0.007538, loss_ce: 0.002400
2021-12-10 13:25:11,622 iteration 3546 : loss : 0.004658, loss_ce: 0.002171
2021-12-10 13:25:14,672 iteration 3547 : loss : 0.006082, loss_ce: 0.002950
2021-12-10 13:25:17,597 iteration 3548 : loss : 0.008120, loss_ce: 0.003310
2021-12-10 13:25:20,498 iteration 3549 : loss : 0.005135, loss_ce: 0.001740
2021-12-10 13:25:23,427 iteration 3550 : loss : 0.004476, loss_ce: 0.001500
2021-12-10 13:25:26,171 iteration 3551 : loss : 0.005403, loss_ce: 0.002412
2021-12-10 13:25:29,030 iteration 3552 : loss : 0.005683, loss_ce: 0.001797
2021-12-10 13:25:31,767 iteration 3553 : loss : 0.004937, loss_ce: 0.001790
 52%|██████████████             | 209/400 [2:58:54<2:41:48, 50.83s/it]2021-12-10 13:25:34,572 iteration 3554 : loss : 0.006116, loss_ce: 0.001952
2021-12-10 13:25:37,310 iteration 3555 : loss : 0.005080, loss_ce: 0.001180
2021-12-10 13:25:40,168 iteration 3556 : loss : 0.005878, loss_ce: 0.002345
2021-12-10 13:25:43,104 iteration 3557 : loss : 0.007224, loss_ce: 0.002080
2021-12-10 13:25:45,839 iteration 3558 : loss : 0.007601, loss_ce: 0.003475
2021-12-10 13:25:48,749 iteration 3559 : loss : 0.005286, loss_ce: 0.002099
2021-12-10 13:25:51,678 iteration 3560 : loss : 0.006210, loss_ce: 0.002476
2021-12-10 13:25:54,425 iteration 3561 : loss : 0.005336, loss_ce: 0.001973
2021-12-10 13:25:57,278 iteration 3562 : loss : 0.005184, loss_ce: 0.002361
2021-12-10 13:26:00,112 iteration 3563 : loss : 0.006352, loss_ce: 0.002270
2021-12-10 13:26:02,968 iteration 3564 : loss : 0.005221, loss_ce: 0.002198
2021-12-10 13:26:05,795 iteration 3565 : loss : 0.005657, loss_ce: 0.002850
2021-12-10 13:26:08,542 iteration 3566 : loss : 0.006835, loss_ce: 0.002415
2021-12-10 13:26:11,275 iteration 3567 : loss : 0.004394, loss_ce: 0.001706
2021-12-10 13:26:14,149 iteration 3568 : loss : 0.006156, loss_ce: 0.002072
2021-12-10 13:26:16,874 iteration 3569 : loss : 0.005398, loss_ce: 0.001944
2021-12-10 13:26:16,874 Training Data Eval:
2021-12-10 13:26:32,387   Average segmentation loss on training set: 0.0045
2021-12-10 13:26:32,388 Validation Data Eval:
2021-12-10 13:26:38,012   Average segmentation loss on validation set: 0.1213
2021-12-10 13:26:40,880 iteration 3570 : loss : 0.004781, loss_ce: 0.002016
 52%|██████████████▏            | 210/400 [3:00:03<2:58:20, 56.32s/it]2021-12-10 13:26:43,846 iteration 3571 : loss : 0.005551, loss_ce: 0.002444
2021-12-10 13:26:46,571 iteration 3572 : loss : 0.005446, loss_ce: 0.001649
2021-12-10 13:26:49,577 iteration 3573 : loss : 0.004889, loss_ce: 0.001732
2021-12-10 13:26:52,509 iteration 3574 : loss : 0.005278, loss_ce: 0.001254
2021-12-10 13:26:55,449 iteration 3575 : loss : 0.005957, loss_ce: 0.002376
2021-12-10 13:26:58,172 iteration 3576 : loss : 0.005520, loss_ce: 0.001652
2021-12-10 13:27:01,189 iteration 3577 : loss : 0.005625, loss_ce: 0.002024
2021-12-10 13:27:04,068 iteration 3578 : loss : 0.005619, loss_ce: 0.002220
2021-12-10 13:27:06,934 iteration 3579 : loss : 0.005563, loss_ce: 0.002540
2021-12-10 13:27:09,795 iteration 3580 : loss : 0.004937, loss_ce: 0.001440
2021-12-10 13:27:12,663 iteration 3581 : loss : 0.005700, loss_ce: 0.002458
2021-12-10 13:27:15,388 iteration 3582 : loss : 0.005259, loss_ce: 0.002226
2021-12-10 13:27:18,113 iteration 3583 : loss : 0.005077, loss_ce: 0.002403
2021-12-10 13:27:20,953 iteration 3584 : loss : 0.004926, loss_ce: 0.001957
2021-12-10 13:27:23,800 iteration 3585 : loss : 0.005877, loss_ce: 0.002493
2021-12-10 13:27:26,706 iteration 3586 : loss : 0.004274, loss_ce: 0.001996
2021-12-10 13:27:29,643 iteration 3587 : loss : 0.005962, loss_ce: 0.001811
 53%|██████████████▏            | 211/400 [3:00:52<2:50:15, 54.05s/it]2021-12-10 13:27:32,430 iteration 3588 : loss : 0.005957, loss_ce: 0.002603
2021-12-10 13:27:35,476 iteration 3589 : loss : 0.005104, loss_ce: 0.002001
2021-12-10 13:27:38,322 iteration 3590 : loss : 0.004012, loss_ce: 0.001765
2021-12-10 13:27:41,170 iteration 3591 : loss : 0.006274, loss_ce: 0.001917
2021-12-10 13:27:44,204 iteration 3592 : loss : 0.006587, loss_ce: 0.002763
2021-12-10 13:27:47,120 iteration 3593 : loss : 0.005073, loss_ce: 0.001512
2021-12-10 13:27:50,029 iteration 3594 : loss : 0.005299, loss_ce: 0.001611
2021-12-10 13:27:52,940 iteration 3595 : loss : 0.005721, loss_ce: 0.003125
2021-12-10 13:27:55,870 iteration 3596 : loss : 0.005051, loss_ce: 0.001595
2021-12-10 13:27:58,809 iteration 3597 : loss : 0.004694, loss_ce: 0.001439
2021-12-10 13:28:01,651 iteration 3598 : loss : 0.005097, loss_ce: 0.002211
2021-12-10 13:28:04,551 iteration 3599 : loss : 0.004233, loss_ce: 0.001718
2021-12-10 13:28:07,444 iteration 3600 : loss : 0.005339, loss_ce: 0.002115
2021-12-10 13:28:10,366 iteration 3601 : loss : 0.004239, loss_ce: 0.001911
2021-12-10 13:28:13,251 iteration 3602 : loss : 0.005251, loss_ce: 0.001964
2021-12-10 13:28:16,177 iteration 3603 : loss : 0.004448, loss_ce: 0.001699
2021-12-10 13:28:19,099 iteration 3604 : loss : 0.004695, loss_ce: 0.002032
 53%|██████████████▎            | 212/400 [3:01:41<2:45:02, 52.67s/it]2021-12-10 13:28:21,907 iteration 3605 : loss : 0.005094, loss_ce: 0.002174
2021-12-10 13:28:24,775 iteration 3606 : loss : 0.005332, loss_ce: 0.001705
2021-12-10 13:28:27,631 iteration 3607 : loss : 0.005293, loss_ce: 0.001477
2021-12-10 13:28:30,365 iteration 3608 : loss : 0.005893, loss_ce: 0.002764
2021-12-10 13:28:33,122 iteration 3609 : loss : 0.006024, loss_ce: 0.002583
2021-12-10 13:28:35,988 iteration 3610 : loss : 0.005167, loss_ce: 0.001947
2021-12-10 13:28:38,851 iteration 3611 : loss : 0.006526, loss_ce: 0.002385
2021-12-10 13:28:41,717 iteration 3612 : loss : 0.004579, loss_ce: 0.001839
2021-12-10 13:28:44,584 iteration 3613 : loss : 0.006579, loss_ce: 0.003699
2021-12-10 13:28:47,445 iteration 3614 : loss : 0.005502, loss_ce: 0.001903
2021-12-10 13:28:50,394 iteration 3615 : loss : 0.005287, loss_ce: 0.001424
2021-12-10 13:28:53,334 iteration 3616 : loss : 0.004636, loss_ce: 0.001567
2021-12-10 13:28:56,276 iteration 3617 : loss : 0.004329, loss_ce: 0.001785
2021-12-10 13:28:59,198 iteration 3618 : loss : 0.004575, loss_ce: 0.001582
2021-12-10 13:29:02,094 iteration 3619 : loss : 0.006632, loss_ce: 0.003544
2021-12-10 13:29:04,870 iteration 3620 : loss : 0.005481, loss_ce: 0.002252
2021-12-10 13:29:07,874 iteration 3621 : loss : 0.006950, loss_ce: 0.002664
 53%|██████████████▍            | 213/400 [3:02:30<2:40:30, 51.50s/it]2021-12-10 13:29:10,812 iteration 3622 : loss : 0.004943, loss_ce: 0.001992
2021-12-10 13:29:13,670 iteration 3623 : loss : 0.004988, loss_ce: 0.002151
2021-12-10 13:29:16,652 iteration 3624 : loss : 0.004979, loss_ce: 0.002011
2021-12-10 13:29:19,572 iteration 3625 : loss : 0.005584, loss_ce: 0.002130
2021-12-10 13:29:22,405 iteration 3626 : loss : 0.005219, loss_ce: 0.001497
2021-12-10 13:29:25,374 iteration 3627 : loss : 0.006293, loss_ce: 0.002200
2021-12-10 13:29:28,287 iteration 3628 : loss : 0.005549, loss_ce: 0.001955
2021-12-10 13:29:31,179 iteration 3629 : loss : 0.006133, loss_ce: 0.002232
2021-12-10 13:29:33,958 iteration 3630 : loss : 0.005112, loss_ce: 0.002137
2021-12-10 13:29:36,961 iteration 3631 : loss : 0.005231, loss_ce: 0.002105
2021-12-10 13:29:39,876 iteration 3632 : loss : 0.004746, loss_ce: 0.001629
2021-12-10 13:29:42,901 iteration 3633 : loss : 0.008907, loss_ce: 0.002631
2021-12-10 13:29:45,743 iteration 3634 : loss : 0.006049, loss_ce: 0.003049
2021-12-10 13:29:48,781 iteration 3635 : loss : 0.005562, loss_ce: 0.001673
2021-12-10 13:29:51,631 iteration 3636 : loss : 0.005411, loss_ce: 0.001518
2021-12-10 13:29:54,528 iteration 3637 : loss : 0.005933, loss_ce: 0.002855
2021-12-10 13:29:57,417 iteration 3638 : loss : 0.007771, loss_ce: 0.003837
 54%|██████████████▍            | 214/400 [3:03:20<2:37:50, 50.92s/it]2021-12-10 13:30:00,398 iteration 3639 : loss : 0.005980, loss_ce: 0.001679
2021-12-10 13:30:03,311 iteration 3640 : loss : 0.006232, loss_ce: 0.002383
2021-12-10 13:30:06,205 iteration 3641 : loss : 0.007311, loss_ce: 0.002284
2021-12-10 13:30:09,113 iteration 3642 : loss : 0.006075, loss_ce: 0.003391
2021-12-10 13:30:11,959 iteration 3643 : loss : 0.007177, loss_ce: 0.002933
2021-12-10 13:30:14,994 iteration 3644 : loss : 0.006511, loss_ce: 0.002351
2021-12-10 13:30:17,844 iteration 3645 : loss : 0.006306, loss_ce: 0.002903
2021-12-10 13:30:20,738 iteration 3646 : loss : 0.005908, loss_ce: 0.002306
2021-12-10 13:30:23,631 iteration 3647 : loss : 0.005024, loss_ce: 0.001901
2021-12-10 13:30:26,413 iteration 3648 : loss : 0.004490, loss_ce: 0.001565
2021-12-10 13:30:29,427 iteration 3649 : loss : 0.004830, loss_ce: 0.001717
2021-12-10 13:30:32,338 iteration 3650 : loss : 0.005272, loss_ce: 0.002276
2021-12-10 13:30:35,257 iteration 3651 : loss : 0.007799, loss_ce: 0.002420
2021-12-10 13:30:38,147 iteration 3652 : loss : 0.004370, loss_ce: 0.001718
2021-12-10 13:30:41,135 iteration 3653 : loss : 0.005411, loss_ce: 0.002025
2021-12-10 13:30:44,011 iteration 3654 : loss : 0.006395, loss_ce: 0.002067
2021-12-10 13:30:44,011 Training Data Eval:
2021-12-10 13:31:00,105   Average segmentation loss on training set: 0.0059
2021-12-10 13:31:00,105 Validation Data Eval:
2021-12-10 13:31:05,661   Average segmentation loss on validation set: 0.1264
2021-12-10 13:31:08,682 iteration 3655 : loss : 0.006662, loss_ce: 0.002206
 54%|██████████████▌            | 215/400 [3:04:31<2:55:48, 57.02s/it]2021-12-10 13:31:11,483 iteration 3656 : loss : 0.005250, loss_ce: 0.001594
2021-12-10 13:31:14,215 iteration 3657 : loss : 0.005042, loss_ce: 0.002092
2021-12-10 13:31:16,969 iteration 3658 : loss : 0.005273, loss_ce: 0.001740
2021-12-10 13:31:19,832 iteration 3659 : loss : 0.006633, loss_ce: 0.002483
2021-12-10 13:31:22,696 iteration 3660 : loss : 0.005893, loss_ce: 0.001718
2021-12-10 13:31:25,563 iteration 3661 : loss : 0.005881, loss_ce: 0.002710
2021-12-10 13:31:28,430 iteration 3662 : loss : 0.006648, loss_ce: 0.002531
2021-12-10 13:31:31,302 iteration 3663 : loss : 0.006480, loss_ce: 0.002813
2021-12-10 13:31:34,167 iteration 3664 : loss : 0.004832, loss_ce: 0.001527
2021-12-10 13:31:36,899 iteration 3665 : loss : 0.004512, loss_ce: 0.001499
2021-12-10 13:31:39,615 iteration 3666 : loss : 0.005282, loss_ce: 0.002111
2021-12-10 13:31:42,366 iteration 3667 : loss : 0.004513, loss_ce: 0.001327
2021-12-10 13:31:45,227 iteration 3668 : loss : 0.005943, loss_ce: 0.002232
2021-12-10 13:31:48,093 iteration 3669 : loss : 0.005119, loss_ce: 0.002370
2021-12-10 13:31:50,960 iteration 3670 : loss : 0.004107, loss_ce: 0.001754
2021-12-10 13:31:53,824 iteration 3671 : loss : 0.005217, loss_ce: 0.001997
2021-12-10 13:31:56,692 iteration 3672 : loss : 0.005235, loss_ce: 0.001986
 54%|██████████████▌            | 216/400 [3:05:19<2:46:34, 54.32s/it]2021-12-10 13:31:59,488 iteration 3673 : loss : 0.004240, loss_ce: 0.001581
2021-12-10 13:32:02,525 iteration 3674 : loss : 0.004403, loss_ce: 0.002348
2021-12-10 13:32:05,372 iteration 3675 : loss : 0.004865, loss_ce: 0.001515
2021-12-10 13:32:08,265 iteration 3676 : loss : 0.006001, loss_ce: 0.002210
2021-12-10 13:32:11,195 iteration 3677 : loss : 0.005540, loss_ce: 0.002195
2021-12-10 13:32:14,116 iteration 3678 : loss : 0.004558, loss_ce: 0.001467
2021-12-10 13:32:16,989 iteration 3679 : loss : 0.004745, loss_ce: 0.001729
2021-12-10 13:32:19,825 iteration 3680 : loss : 0.005979, loss_ce: 0.002025
2021-12-10 13:32:22,842 iteration 3681 : loss : 0.005618, loss_ce: 0.002822
2021-12-10 13:32:25,787 iteration 3682 : loss : 0.005424, loss_ce: 0.002175
2021-12-10 13:32:28,526 iteration 3683 : loss : 0.004523, loss_ce: 0.001468
2021-12-10 13:32:31,253 iteration 3684 : loss : 0.006187, loss_ce: 0.001610
2021-12-10 13:32:34,007 iteration 3685 : loss : 0.005726, loss_ce: 0.002089
2021-12-10 13:32:36,866 iteration 3686 : loss : 0.004699, loss_ce: 0.001691
2021-12-10 13:32:39,716 iteration 3687 : loss : 0.005104, loss_ce: 0.001789
2021-12-10 13:32:42,551 iteration 3688 : loss : 0.005595, loss_ce: 0.002607
2021-12-10 13:32:45,386 iteration 3689 : loss : 0.007675, loss_ce: 0.002272
 54%|██████████████▋            | 217/400 [3:06:08<2:40:31, 52.63s/it]2021-12-10 13:32:48,313 iteration 3690 : loss : 0.004669, loss_ce: 0.002042
2021-12-10 13:32:51,315 iteration 3691 : loss : 0.005685, loss_ce: 0.001912
2021-12-10 13:32:54,232 iteration 3692 : loss : 0.004898, loss_ce: 0.001495
2021-12-10 13:32:57,069 iteration 3693 : loss : 0.005632, loss_ce: 0.002102
2021-12-10 13:33:00,089 iteration 3694 : loss : 0.007322, loss_ce: 0.004100
2021-12-10 13:33:02,966 iteration 3695 : loss : 0.007244, loss_ce: 0.002899
2021-12-10 13:33:05,880 iteration 3696 : loss : 0.006237, loss_ce: 0.002603
2021-12-10 13:33:08,717 iteration 3697 : loss : 0.007459, loss_ce: 0.002180
2021-12-10 13:33:11,740 iteration 3698 : loss : 0.005047, loss_ce: 0.002126
2021-12-10 13:33:14,588 iteration 3699 : loss : 0.006387, loss_ce: 0.002386
2021-12-10 13:33:17,482 iteration 3700 : loss : 0.006228, loss_ce: 0.002449
2021-12-10 13:33:20,262 iteration 3701 : loss : 0.004915, loss_ce: 0.001500
2021-12-10 13:33:23,133 iteration 3702 : loss : 0.005585, loss_ce: 0.002034
2021-12-10 13:33:25,995 iteration 3703 : loss : 0.005365, loss_ce: 0.002126
2021-12-10 13:33:28,879 iteration 3704 : loss : 0.005542, loss_ce: 0.002518
2021-12-10 13:33:31,598 iteration 3705 : loss : 0.006257, loss_ce: 0.002231
2021-12-10 13:33:34,457 iteration 3706 : loss : 0.006589, loss_ce: 0.003008
 55%|██████████████▋            | 218/400 [3:06:57<2:36:24, 51.56s/it]2021-12-10 13:33:37,418 iteration 3707 : loss : 0.005561, loss_ce: 0.001919
2021-12-10 13:33:40,157 iteration 3708 : loss : 0.005240, loss_ce: 0.002510
2021-12-10 13:33:43,015 iteration 3709 : loss : 0.005155, loss_ce: 0.002002
2021-12-10 13:33:45,870 iteration 3710 : loss : 0.006815, loss_ce: 0.002163
2021-12-10 13:33:48,725 iteration 3711 : loss : 0.005237, loss_ce: 0.001997
2021-12-10 13:33:51,732 iteration 3712 : loss : 0.007230, loss_ce: 0.001724
2021-12-10 13:33:54,648 iteration 3713 : loss : 0.004950, loss_ce: 0.001745
2021-12-10 13:33:57,493 iteration 3714 : loss : 0.006490, loss_ce: 0.003519
2021-12-10 13:34:00,324 iteration 3715 : loss : 0.006250, loss_ce: 0.002443
2021-12-10 13:34:03,355 iteration 3716 : loss : 0.005853, loss_ce: 0.002583
2021-12-10 13:34:06,204 iteration 3717 : loss : 0.005339, loss_ce: 0.001746
2021-12-10 13:34:09,097 iteration 3718 : loss : 0.005748, loss_ce: 0.002050
2021-12-10 13:34:12,030 iteration 3719 : loss : 0.005696, loss_ce: 0.002454
2021-12-10 13:34:14,960 iteration 3720 : loss : 0.005302, loss_ce: 0.001622
2021-12-10 13:34:17,892 iteration 3721 : loss : 0.006225, loss_ce: 0.002373
2021-12-10 13:34:20,742 iteration 3722 : loss : 0.005269, loss_ce: 0.001499
2021-12-10 13:34:23,637 iteration 3723 : loss : 0.005059, loss_ce: 0.002078
 55%|██████████████▊            | 219/400 [3:07:46<2:33:22, 50.85s/it]2021-12-10 13:34:26,626 iteration 3724 : loss : 0.006852, loss_ce: 0.001797
2021-12-10 13:34:29,559 iteration 3725 : loss : 0.005206, loss_ce: 0.001806
2021-12-10 13:34:32,414 iteration 3726 : loss : 0.005521, loss_ce: 0.001611
2021-12-10 13:34:35,308 iteration 3727 : loss : 0.008454, loss_ce: 0.005203
2021-12-10 13:34:38,189 iteration 3728 : loss : 0.005950, loss_ce: 0.002726
2021-12-10 13:34:41,120 iteration 3729 : loss : 0.005035, loss_ce: 0.001485
2021-12-10 13:34:44,043 iteration 3730 : loss : 0.006542, loss_ce: 0.002011
2021-12-10 13:34:46,956 iteration 3731 : loss : 0.006666, loss_ce: 0.002555
2021-12-10 13:34:49,850 iteration 3732 : loss : 0.003955, loss_ce: 0.001589
2021-12-10 13:34:52,747 iteration 3733 : loss : 0.005673, loss_ce: 0.001424
2021-12-10 13:34:55,669 iteration 3734 : loss : 0.005869, loss_ce: 0.002627
2021-12-10 13:34:58,588 iteration 3735 : loss : 0.004190, loss_ce: 0.001710
2021-12-10 13:35:01,388 iteration 3736 : loss : 0.007148, loss_ce: 0.002927
2021-12-10 13:35:04,222 iteration 3737 : loss : 0.005542, loss_ce: 0.001830
2021-12-10 13:35:07,052 iteration 3738 : loss : 0.006188, loss_ce: 0.003738
2021-12-10 13:35:09,949 iteration 3739 : loss : 0.007288, loss_ce: 0.001862
2021-12-10 13:35:09,949 Training Data Eval:
2021-12-10 13:35:26,013   Average segmentation loss on training set: 0.0051
2021-12-10 13:35:26,014 Validation Data Eval:
2021-12-10 13:35:31,671   Average segmentation loss on validation set: 0.1189
2021-12-10 13:35:34,541 iteration 3740 : loss : 0.004960, loss_ce: 0.002475
 55%|██████████████▊            | 220/400 [3:08:57<2:50:35, 56.87s/it]2021-12-10 13:35:37,529 iteration 3741 : loss : 0.005032, loss_ce: 0.002607
2021-12-10 13:35:40,254 iteration 3742 : loss : 0.004218, loss_ce: 0.001649
2021-12-10 13:35:43,287 iteration 3743 : loss : 0.005555, loss_ce: 0.001997
2021-12-10 13:35:46,142 iteration 3744 : loss : 0.004977, loss_ce: 0.002405
2021-12-10 13:35:48,988 iteration 3745 : loss : 0.004997, loss_ce: 0.001593
2021-12-10 13:35:51,721 iteration 3746 : loss : 0.004315, loss_ce: 0.001486
2021-12-10 13:35:54,495 iteration 3747 : loss : 0.005332, loss_ce: 0.002226
2021-12-10 13:35:57,224 iteration 3748 : loss : 0.004893, loss_ce: 0.001651
2021-12-10 13:35:59,945 iteration 3749 : loss : 0.005500, loss_ce: 0.002452
2021-12-10 13:36:02,819 iteration 3750 : loss : 0.004864, loss_ce: 0.001754
2021-12-10 13:36:05,565 iteration 3751 : loss : 0.004780, loss_ce: 0.001645
2021-12-10 13:36:08,419 iteration 3752 : loss : 0.006071, loss_ce: 0.001963
2021-12-10 13:36:11,272 iteration 3753 : loss : 0.004516, loss_ce: 0.001496
2021-12-10 13:36:14,110 iteration 3754 : loss : 0.004746, loss_ce: 0.001913
2021-12-10 13:36:16,947 iteration 3755 : loss : 0.005870, loss_ce: 0.002465
2021-12-10 13:36:19,788 iteration 3756 : loss : 0.005751, loss_ce: 0.002483
2021-12-10 13:36:22,823 iteration 3757 : loss : 0.005409, loss_ce: 0.002335
 55%|██████████████▉            | 221/400 [3:09:45<2:41:58, 54.29s/it]2021-12-10 13:36:25,633 iteration 3758 : loss : 0.004682, loss_ce: 0.001281
2021-12-10 13:36:28,498 iteration 3759 : loss : 0.003977, loss_ce: 0.001627
2021-12-10 13:36:31,353 iteration 3760 : loss : 0.004203, loss_ce: 0.002111
2021-12-10 13:36:34,120 iteration 3761 : loss : 0.004714, loss_ce: 0.001725
2021-12-10 13:36:36,889 iteration 3762 : loss : 0.003778, loss_ce: 0.001350
2021-12-10 13:36:39,620 iteration 3763 : loss : 0.003756, loss_ce: 0.001067
2021-12-10 13:36:42,348 iteration 3764 : loss : 0.005005, loss_ce: 0.002628
2021-12-10 13:36:45,218 iteration 3765 : loss : 0.004797, loss_ce: 0.001662
2021-12-10 13:36:47,945 iteration 3766 : loss : 0.005305, loss_ce: 0.001756
2021-12-10 13:36:50,783 iteration 3767 : loss : 0.003843, loss_ce: 0.001828
2021-12-10 13:36:53,776 iteration 3768 : loss : 0.003990, loss_ce: 0.001914
2021-12-10 13:36:56,693 iteration 3769 : loss : 0.004062, loss_ce: 0.001786
2021-12-10 13:36:59,574 iteration 3770 : loss : 0.005099, loss_ce: 0.001950
2021-12-10 13:37:02,414 iteration 3771 : loss : 0.005678, loss_ce: 0.002020
2021-12-10 13:37:05,243 iteration 3772 : loss : 0.004620, loss_ce: 0.002033
2021-12-10 13:37:08,087 iteration 3773 : loss : 0.004573, loss_ce: 0.001635
2021-12-10 13:37:10,972 iteration 3774 : loss : 0.004330, loss_ce: 0.001876
 56%|██████████████▉            | 222/400 [3:10:33<2:35:35, 52.45s/it]2021-12-10 13:37:13,959 iteration 3775 : loss : 0.005239, loss_ce: 0.002741
2021-12-10 13:37:16,872 iteration 3776 : loss : 0.004333, loss_ce: 0.001784
2021-12-10 13:37:19,762 iteration 3777 : loss : 0.005208, loss_ce: 0.002070
2021-12-10 13:37:22,585 iteration 3778 : loss : 0.004384, loss_ce: 0.001435
2021-12-10 13:37:25,529 iteration 3779 : loss : 0.005692, loss_ce: 0.001614
2021-12-10 13:37:28,453 iteration 3780 : loss : 0.004903, loss_ce: 0.001652
2021-12-10 13:37:31,372 iteration 3781 : loss : 0.003765, loss_ce: 0.001203
2021-12-10 13:37:34,284 iteration 3782 : loss : 0.005690, loss_ce: 0.003018
2021-12-10 13:37:37,070 iteration 3783 : loss : 0.004644, loss_ce: 0.002166
2021-12-10 13:37:39,908 iteration 3784 : loss : 0.004760, loss_ce: 0.002290
2021-12-10 13:37:42,745 iteration 3785 : loss : 0.006471, loss_ce: 0.002488
2021-12-10 13:37:45,789 iteration 3786 : loss : 0.004390, loss_ce: 0.001586
2021-12-10 13:37:48,641 iteration 3787 : loss : 0.004804, loss_ce: 0.001852
2021-12-10 13:37:51,367 iteration 3788 : loss : 0.004830, loss_ce: 0.001808
2021-12-10 13:37:54,078 iteration 3789 : loss : 0.005430, loss_ce: 0.002106
2021-12-10 13:37:56,939 iteration 3790 : loss : 0.005123, loss_ce: 0.002161
2021-12-10 13:37:59,675 iteration 3791 : loss : 0.004956, loss_ce: 0.001713
 56%|███████████████            | 223/400 [3:11:22<2:31:26, 51.34s/it]2021-12-10 13:38:02,766 iteration 3792 : loss : 0.004553, loss_ce: 0.001479
2021-12-10 13:38:05,534 iteration 3793 : loss : 0.006346, loss_ce: 0.002907
2021-12-10 13:38:08,375 iteration 3794 : loss : 0.005338, loss_ce: 0.002240
2021-12-10 13:38:11,213 iteration 3795 : loss : 0.004678, loss_ce: 0.002656
2021-12-10 13:38:14,050 iteration 3796 : loss : 0.007860, loss_ce: 0.002248
2021-12-10 13:38:17,056 iteration 3797 : loss : 0.004685, loss_ce: 0.001956
2021-12-10 13:38:19,919 iteration 3798 : loss : 0.004978, loss_ce: 0.001944
2021-12-10 13:38:22,784 iteration 3799 : loss : 0.004523, loss_ce: 0.001940
2021-12-10 13:38:25,647 iteration 3800 : loss : 0.005035, loss_ce: 0.001756
2021-12-10 13:38:28,518 iteration 3801 : loss : 0.007738, loss_ce: 0.002080
2021-12-10 13:38:31,381 iteration 3802 : loss : 0.004684, loss_ce: 0.001565
2021-12-10 13:38:34,244 iteration 3803 : loss : 0.004316, loss_ce: 0.002096
2021-12-10 13:38:36,974 iteration 3804 : loss : 0.004550, loss_ce: 0.001543
2021-12-10 13:38:39,734 iteration 3805 : loss : 0.006343, loss_ce: 0.002892
2021-12-10 13:38:42,473 iteration 3806 : loss : 0.005472, loss_ce: 0.002063
2021-12-10 13:38:45,370 iteration 3807 : loss : 0.004659, loss_ce: 0.001487
2021-12-10 13:38:48,094 iteration 3808 : loss : 0.004951, loss_ce: 0.002062
 56%|███████████████            | 224/400 [3:12:10<2:27:59, 50.45s/it]2021-12-10 13:38:51,021 iteration 3809 : loss : 0.003890, loss_ce: 0.001372
2021-12-10 13:38:53,876 iteration 3810 : loss : 0.004546, loss_ce: 0.001946
2021-12-10 13:38:56,623 iteration 3811 : loss : 0.005596, loss_ce: 0.001688
2021-12-10 13:38:59,348 iteration 3812 : loss : 0.005279, loss_ce: 0.001692
2021-12-10 13:39:02,091 iteration 3813 : loss : 0.005378, loss_ce: 0.002415
2021-12-10 13:39:04,949 iteration 3814 : loss : 0.005295, loss_ce: 0.002012
2021-12-10 13:39:07,804 iteration 3815 : loss : 0.005047, loss_ce: 0.002282
2021-12-10 13:39:10,668 iteration 3816 : loss : 0.004809, loss_ce: 0.001652
2021-12-10 13:39:13,533 iteration 3817 : loss : 0.006725, loss_ce: 0.002360
2021-12-10 13:39:16,402 iteration 3818 : loss : 0.005631, loss_ce: 0.001984
2021-12-10 13:39:19,244 iteration 3819 : loss : 0.005592, loss_ce: 0.002315
2021-12-10 13:39:22,066 iteration 3820 : loss : 0.004297, loss_ce: 0.001903
2021-12-10 13:39:25,097 iteration 3821 : loss : 0.006307, loss_ce: 0.002371
2021-12-10 13:39:27,945 iteration 3822 : loss : 0.005952, loss_ce: 0.002690
2021-12-10 13:39:30,839 iteration 3823 : loss : 0.005403, loss_ce: 0.001680
2021-12-10 13:39:33,721 iteration 3824 : loss : 0.005352, loss_ce: 0.001787
2021-12-10 13:39:33,722 Training Data Eval:
2021-12-10 13:39:49,806   Average segmentation loss on training set: 0.0046
2021-12-10 13:39:49,807 Validation Data Eval:
2021-12-10 13:39:55,382   Average segmentation loss on validation set: 0.1182
2021-12-10 13:39:58,412 iteration 3825 : loss : 0.005121, loss_ce: 0.002084
 56%|███████████████▏           | 225/400 [3:13:21<2:44:31, 56.41s/it]2021-12-10 13:40:01,205 iteration 3826 : loss : 0.004030, loss_ce: 0.001627
2021-12-10 13:40:04,169 iteration 3827 : loss : 0.004972, loss_ce: 0.002131
2021-12-10 13:40:06,899 iteration 3828 : loss : 0.006242, loss_ce: 0.001539
2021-12-10 13:40:09,882 iteration 3829 : loss : 0.005137, loss_ce: 0.001945
2021-12-10 13:40:12,684 iteration 3830 : loss : 0.005839, loss_ce: 0.002496
2021-12-10 13:40:15,521 iteration 3831 : loss : 0.005448, loss_ce: 0.002357
2021-12-10 13:40:18,491 iteration 3832 : loss : 0.004172, loss_ce: 0.001341
2021-12-10 13:40:21,405 iteration 3833 : loss : 0.004457, loss_ce: 0.001966
2021-12-10 13:40:24,295 iteration 3834 : loss : 0.004459, loss_ce: 0.002026
2021-12-10 13:40:27,208 iteration 3835 : loss : 0.004426, loss_ce: 0.001599
2021-12-10 13:40:30,082 iteration 3836 : loss : 0.005440, loss_ce: 0.002224
2021-12-10 13:40:33,008 iteration 3837 : loss : 0.004934, loss_ce: 0.001985
2021-12-10 13:40:35,929 iteration 3838 : loss : 0.004646, loss_ce: 0.001433
2021-12-10 13:40:38,825 iteration 3839 : loss : 0.004569, loss_ce: 0.001519
2021-12-10 13:40:41,714 iteration 3840 : loss : 0.003819, loss_ce: 0.001189
2021-12-10 13:40:44,620 iteration 3841 : loss : 0.005341, loss_ce: 0.002436
2021-12-10 13:40:47,558 iteration 3842 : loss : 0.004416, loss_ce: 0.002098
 56%|███████████████▎           | 226/400 [3:14:10<2:37:15, 54.23s/it]2021-12-10 13:40:50,500 iteration 3843 : loss : 0.005656, loss_ce: 0.002286
2021-12-10 13:40:53,424 iteration 3844 : loss : 0.005076, loss_ce: 0.002581
2021-12-10 13:40:56,265 iteration 3845 : loss : 0.005663, loss_ce: 0.002013
2021-12-10 13:40:59,304 iteration 3846 : loss : 0.004163, loss_ce: 0.002177
2021-12-10 13:41:02,153 iteration 3847 : loss : 0.004544, loss_ce: 0.001945
2021-12-10 13:41:05,047 iteration 3848 : loss : 0.005336, loss_ce: 0.001551
2021-12-10 13:41:07,944 iteration 3849 : loss : 0.005302, loss_ce: 0.001705
2021-12-10 13:41:10,844 iteration 3850 : loss : 0.005531, loss_ce: 0.002844
2021-12-10 13:41:13,771 iteration 3851 : loss : 0.005206, loss_ce: 0.002002
2021-12-10 13:41:16,648 iteration 3852 : loss : 0.004925, loss_ce: 0.001820
2021-12-10 13:41:19,583 iteration 3853 : loss : 0.004572, loss_ce: 0.001879
2021-12-10 13:41:22,429 iteration 3854 : loss : 0.004854, loss_ce: 0.001664
2021-12-10 13:41:25,325 iteration 3855 : loss : 0.004784, loss_ce: 0.001480
2021-12-10 13:41:28,234 iteration 3856 : loss : 0.004726, loss_ce: 0.002004
2021-12-10 13:41:31,080 iteration 3857 : loss : 0.004618, loss_ce: 0.001917
2021-12-10 13:41:34,054 iteration 3858 : loss : 0.004126, loss_ce: 0.001543
2021-12-10 13:41:36,926 iteration 3859 : loss : 0.004151, loss_ce: 0.001740
 57%|███████████████▎           | 227/400 [3:14:59<2:32:09, 52.77s/it]2021-12-10 13:41:39,864 iteration 3860 : loss : 0.004214, loss_ce: 0.001420
2021-12-10 13:41:42,760 iteration 3861 : loss : 0.005135, loss_ce: 0.002531
2021-12-10 13:41:45,684 iteration 3862 : loss : 0.005128, loss_ce: 0.001329
2021-12-10 13:41:48,603 iteration 3863 : loss : 0.004827, loss_ce: 0.002316
2021-12-10 13:41:51,469 iteration 3864 : loss : 0.003780, loss_ce: 0.001455
2021-12-10 13:41:54,198 iteration 3865 : loss : 0.003718, loss_ce: 0.001238
2021-12-10 13:41:57,083 iteration 3866 : loss : 0.004439, loss_ce: 0.001414
2021-12-10 13:41:59,890 iteration 3867 : loss : 0.005059, loss_ce: 0.002192
2021-12-10 13:42:02,738 iteration 3868 : loss : 0.004222, loss_ce: 0.001495
2021-12-10 13:42:05,601 iteration 3869 : loss : 0.004661, loss_ce: 0.002190
2021-12-10 13:42:08,335 iteration 3870 : loss : 0.004642, loss_ce: 0.002148
2021-12-10 13:42:11,064 iteration 3871 : loss : 0.003958, loss_ce: 0.001645
2021-12-10 13:42:13,900 iteration 3872 : loss : 0.005115, loss_ce: 0.002010
2021-12-10 13:42:16,745 iteration 3873 : loss : 0.003660, loss_ce: 0.001590
2021-12-10 13:42:19,585 iteration 3874 : loss : 0.004294, loss_ce: 0.001352
2021-12-10 13:42:22,480 iteration 3875 : loss : 0.004313, loss_ce: 0.002138
2021-12-10 13:42:25,411 iteration 3876 : loss : 0.004271, loss_ce: 0.001665
 57%|███████████████▍           | 228/400 [3:15:48<2:27:35, 51.49s/it]2021-12-10 13:42:28,200 iteration 3877 : loss : 0.004111, loss_ce: 0.001837
2021-12-10 13:42:31,194 iteration 3878 : loss : 0.004179, loss_ce: 0.001831
2021-12-10 13:42:34,111 iteration 3879 : loss : 0.005310, loss_ce: 0.001270
2021-12-10 13:42:37,005 iteration 3880 : loss : 0.005085, loss_ce: 0.001813
2021-12-10 13:42:39,896 iteration 3881 : loss : 0.003715, loss_ce: 0.001459
2021-12-10 13:42:42,823 iteration 3882 : loss : 0.005045, loss_ce: 0.002397
2021-12-10 13:42:45,742 iteration 3883 : loss : 0.005218, loss_ce: 0.002187
2021-12-10 13:42:48,654 iteration 3884 : loss : 0.004627, loss_ce: 0.002390
2021-12-10 13:42:51,592 iteration 3885 : loss : 0.004526, loss_ce: 0.001893
2021-12-10 13:42:54,329 iteration 3886 : loss : 0.005411, loss_ce: 0.002523
2021-12-10 13:42:57,209 iteration 3887 : loss : 0.004524, loss_ce: 0.001869
2021-12-10 13:42:59,941 iteration 3888 : loss : 0.003557, loss_ce: 0.001342
2021-12-10 13:43:02,671 iteration 3889 : loss : 0.004715, loss_ce: 0.001531
2021-12-10 13:43:05,535 iteration 3890 : loss : 0.004341, loss_ce: 0.001448
2021-12-10 13:43:08,376 iteration 3891 : loss : 0.004324, loss_ce: 0.001596
2021-12-10 13:43:11,208 iteration 3892 : loss : 0.005481, loss_ce: 0.001965
2021-12-10 13:43:14,108 iteration 3893 : loss : 0.004443, loss_ce: 0.001706
 57%|███████████████▍           | 229/400 [3:16:36<2:24:20, 50.65s/it]2021-12-10 13:43:17,082 iteration 3894 : loss : 0.004536, loss_ce: 0.001773
2021-12-10 13:43:20,000 iteration 3895 : loss : 0.004423, loss_ce: 0.001145
2021-12-10 13:43:22,891 iteration 3896 : loss : 0.003882, loss_ce: 0.001671
2021-12-10 13:43:25,667 iteration 3897 : loss : 0.004117, loss_ce: 0.001165
2021-12-10 13:43:28,742 iteration 3898 : loss : 0.003863, loss_ce: 0.001672
2021-12-10 13:43:31,522 iteration 3899 : loss : 0.004551, loss_ce: 0.001938
2021-12-10 13:43:34,395 iteration 3900 : loss : 0.004199, loss_ce: 0.001795
2021-12-10 13:43:37,131 iteration 3901 : loss : 0.004488, loss_ce: 0.001940
2021-12-10 13:43:39,866 iteration 3902 : loss : 0.005053, loss_ce: 0.001836
2021-12-10 13:43:42,761 iteration 3903 : loss : 0.004911, loss_ce: 0.002172
2021-12-10 13:43:45,692 iteration 3904 : loss : 0.005136, loss_ce: 0.001439
2021-12-10 13:43:48,433 iteration 3905 : loss : 0.003629, loss_ce: 0.001280
2021-12-10 13:43:51,453 iteration 3906 : loss : 0.004965, loss_ce: 0.001582
2021-12-10 13:43:54,432 iteration 3907 : loss : 0.004057, loss_ce: 0.002342
2021-12-10 13:43:57,314 iteration 3908 : loss : 0.004387, loss_ce: 0.001955
2021-12-10 13:44:00,233 iteration 3909 : loss : 0.004065, loss_ce: 0.001514
2021-12-10 13:44:00,233 Training Data Eval:
2021-12-10 13:44:16,411   Average segmentation loss on training set: 0.0039
2021-12-10 13:44:16,412 Validation Data Eval:
2021-12-10 13:44:21,940   Average segmentation loss on validation set: 0.1188
2021-12-10 13:44:24,810 iteration 3910 : loss : 0.004359, loss_ce: 0.001584
 57%|███████████████▌           | 230/400 [3:17:47<2:40:33, 56.67s/it]2021-12-10 13:44:27,809 iteration 3911 : loss : 0.003737, loss_ce: 0.001368
2021-12-10 13:44:30,593 iteration 3912 : loss : 0.006125, loss_ce: 0.001780
2021-12-10 13:44:33,328 iteration 3913 : loss : 0.005162, loss_ce: 0.002345
2021-12-10 13:44:36,054 iteration 3914 : loss : 0.004208, loss_ce: 0.001681
2021-12-10 13:44:38,814 iteration 3915 : loss : 0.005256, loss_ce: 0.001846
2021-12-10 13:44:41,570 iteration 3916 : loss : 0.004830, loss_ce: 0.001584
2021-12-10 13:44:44,360 iteration 3917 : loss : 0.004582, loss_ce: 0.002201
2021-12-10 13:44:47,210 iteration 3918 : loss : 0.005396, loss_ce: 0.001898
2021-12-10 13:44:50,065 iteration 3919 : loss : 0.004753, loss_ce: 0.001864
2021-12-10 13:44:52,924 iteration 3920 : loss : 0.004440, loss_ce: 0.002099
2021-12-10 13:44:55,990 iteration 3921 : loss : 0.004285, loss_ce: 0.001925
2021-12-10 13:44:58,773 iteration 3922 : loss : 0.003893, loss_ce: 0.000952
2021-12-10 13:45:01,801 iteration 3923 : loss : 0.004629, loss_ce: 0.001707
2021-12-10 13:45:04,642 iteration 3924 : loss : 0.004836, loss_ce: 0.002438
2021-12-10 13:45:07,545 iteration 3925 : loss : 0.003489, loss_ce: 0.001572
2021-12-10 13:45:10,486 iteration 3926 : loss : 0.006263, loss_ce: 0.001503
2021-12-10 13:45:13,403 iteration 3927 : loss : 0.005257, loss_ce: 0.001462
 58%|███████████████▌           | 231/400 [3:18:36<2:32:46, 54.24s/it]2021-12-10 13:45:16,244 iteration 3928 : loss : 0.003765, loss_ce: 0.001072
2021-12-10 13:45:19,242 iteration 3929 : loss : 0.005492, loss_ce: 0.001964
2021-12-10 13:45:22,167 iteration 3930 : loss : 0.004278, loss_ce: 0.001680
2021-12-10 13:45:25,007 iteration 3931 : loss : 0.004882, loss_ce: 0.002054
2021-12-10 13:45:27,986 iteration 3932 : loss : 0.005708, loss_ce: 0.001874
2021-12-10 13:45:30,714 iteration 3933 : loss : 0.004523, loss_ce: 0.002254
2021-12-10 13:45:33,728 iteration 3934 : loss : 0.005271, loss_ce: 0.001932
2021-12-10 13:45:36,622 iteration 3935 : loss : 0.004255, loss_ce: 0.001420
2021-12-10 13:45:39,553 iteration 3936 : loss : 0.004409, loss_ce: 0.001986
2021-12-10 13:45:42,389 iteration 3937 : loss : 0.005212, loss_ce: 0.001795
2021-12-10 13:45:45,355 iteration 3938 : loss : 0.004842, loss_ce: 0.002432
2021-12-10 13:45:48,251 iteration 3939 : loss : 0.005339, loss_ce: 0.001668
2021-12-10 13:45:50,982 iteration 3940 : loss : 0.004529, loss_ce: 0.001714
2021-12-10 13:45:53,819 iteration 3941 : loss : 0.004796, loss_ce: 0.002387
2021-12-10 13:45:56,855 iteration 3942 : loss : 0.004828, loss_ce: 0.001271
2021-12-10 13:45:59,754 iteration 3943 : loss : 0.004059, loss_ce: 0.001758
2021-12-10 13:46:02,637 iteration 3944 : loss : 0.004610, loss_ce: 0.002081
 58%|███████████████▋           | 232/400 [3:19:25<2:27:40, 52.74s/it]2021-12-10 13:46:05,625 iteration 3945 : loss : 0.003594, loss_ce: 0.001052
2021-12-10 13:46:08,555 iteration 3946 : loss : 0.005584, loss_ce: 0.002333
2021-12-10 13:46:11,407 iteration 3947 : loss : 0.004826, loss_ce: 0.001987
2021-12-10 13:46:14,301 iteration 3948 : loss : 0.004450, loss_ce: 0.001840
2021-12-10 13:46:17,086 iteration 3949 : loss : 0.006087, loss_ce: 0.002387
2021-12-10 13:46:20,092 iteration 3950 : loss : 0.004395, loss_ce: 0.002049
2021-12-10 13:46:22,983 iteration 3951 : loss : 0.004897, loss_ce: 0.001724
2021-12-10 13:46:25,847 iteration 3952 : loss : 0.005358, loss_ce: 0.002557
2021-12-10 13:46:28,715 iteration 3953 : loss : 0.004976, loss_ce: 0.002189
2021-12-10 13:46:31,600 iteration 3954 : loss : 0.005128, loss_ce: 0.001885
2021-12-10 13:46:34,362 iteration 3955 : loss : 0.004111, loss_ce: 0.001736
2021-12-10 13:46:37,088 iteration 3956 : loss : 0.004935, loss_ce: 0.002368
2021-12-10 13:46:39,958 iteration 3957 : loss : 0.005054, loss_ce: 0.001958
2021-12-10 13:46:42,683 iteration 3958 : loss : 0.004587, loss_ce: 0.001117
2021-12-10 13:46:45,535 iteration 3959 : loss : 0.004038, loss_ce: 0.001227
2021-12-10 13:46:48,396 iteration 3960 : loss : 0.004201, loss_ce: 0.001262
2021-12-10 13:46:51,258 iteration 3961 : loss : 0.003541, loss_ce: 0.001330
 58%|███████████████▋           | 233/400 [3:20:14<2:23:21, 51.51s/it]2021-12-10 13:46:54,049 iteration 3962 : loss : 0.003725, loss_ce: 0.001261
2021-12-10 13:46:56,877 iteration 3963 : loss : 0.004439, loss_ce: 0.002126
2021-12-10 13:46:59,766 iteration 3964 : loss : 0.004221, loss_ce: 0.001831
2021-12-10 13:47:02,692 iteration 3965 : loss : 0.004211, loss_ce: 0.001901
2021-12-10 13:47:05,431 iteration 3966 : loss : 0.005100, loss_ce: 0.001931
2021-12-10 13:47:08,278 iteration 3967 : loss : 0.004068, loss_ce: 0.001708
2021-12-10 13:47:11,136 iteration 3968 : loss : 0.004016, loss_ce: 0.001208
2021-12-10 13:47:14,000 iteration 3969 : loss : 0.005006, loss_ce: 0.002065
2021-12-10 13:47:16,974 iteration 3970 : loss : 0.003869, loss_ce: 0.001871
2021-12-10 13:47:19,755 iteration 3971 : loss : 0.005389, loss_ce: 0.001708
2021-12-10 13:47:22,484 iteration 3972 : loss : 0.004135, loss_ce: 0.001809
2021-12-10 13:47:25,324 iteration 3973 : loss : 0.004354, loss_ce: 0.001807
2021-12-10 13:47:28,068 iteration 3974 : loss : 0.004798, loss_ce: 0.001047
2021-12-10 13:47:30,896 iteration 3975 : loss : 0.004406, loss_ce: 0.001573
2021-12-10 13:47:33,783 iteration 3976 : loss : 0.006016, loss_ce: 0.001963
2021-12-10 13:47:36,553 iteration 3977 : loss : 0.003182, loss_ce: 0.001140
2021-12-10 13:47:39,276 iteration 3978 : loss : 0.004087, loss_ce: 0.001580
 58%|███████████████▊           | 234/400 [3:21:02<2:19:36, 50.46s/it]2021-12-10 13:47:42,075 iteration 3979 : loss : 0.003639, loss_ce: 0.001045
2021-12-10 13:47:44,952 iteration 3980 : loss : 0.003724, loss_ce: 0.001451
2021-12-10 13:47:47,674 iteration 3981 : loss : 0.005291, loss_ce: 0.001965
2021-12-10 13:47:50,397 iteration 3982 : loss : 0.004093, loss_ce: 0.001326
2021-12-10 13:47:53,259 iteration 3983 : loss : 0.004284, loss_ce: 0.001556
2021-12-10 13:47:56,017 iteration 3984 : loss : 0.004426, loss_ce: 0.001514
2021-12-10 13:47:58,746 iteration 3985 : loss : 0.003917, loss_ce: 0.002137
2021-12-10 13:48:01,507 iteration 3986 : loss : 0.004487, loss_ce: 0.001887
2021-12-10 13:48:04,399 iteration 3987 : loss : 0.005048, loss_ce: 0.002086
2021-12-10 13:48:07,134 iteration 3988 : loss : 0.005087, loss_ce: 0.002240
2021-12-10 13:48:09,861 iteration 3989 : loss : 0.004718, loss_ce: 0.001515
2021-12-10 13:48:12,610 iteration 3990 : loss : 0.004419, loss_ce: 0.002050
2021-12-10 13:48:15,337 iteration 3991 : loss : 0.005559, loss_ce: 0.001629
2021-12-10 13:48:18,094 iteration 3992 : loss : 0.005384, loss_ce: 0.002105
2021-12-10 13:48:20,806 iteration 3993 : loss : 0.004628, loss_ce: 0.001680
2021-12-10 13:48:23,667 iteration 3994 : loss : 0.003280, loss_ce: 0.001178
2021-12-10 13:48:23,667 Training Data Eval:
2021-12-10 13:48:38,845   Average segmentation loss on training set: 0.0040
2021-12-10 13:48:38,845 Validation Data Eval:
2021-12-10 13:48:44,099   Average segmentation loss on validation set: 0.1293
2021-12-10 13:48:46,873 iteration 3995 : loss : 0.004511, loss_ce: 0.001431
 59%|███████████████▊           | 235/400 [3:22:09<2:32:54, 55.60s/it]2021-12-10 13:48:49,644 iteration 3996 : loss : 0.005301, loss_ce: 0.002078
2021-12-10 13:48:52,404 iteration 3997 : loss : 0.004287, loss_ce: 0.002042
2021-12-10 13:48:55,127 iteration 3998 : loss : 0.003778, loss_ce: 0.001077
2021-12-10 13:48:57,869 iteration 3999 : loss : 0.004066, loss_ce: 0.001402
2021-12-10 13:49:00,606 iteration 4000 : loss : 0.004590, loss_ce: 0.001989
2021-12-10 13:49:03,385 iteration 4001 : loss : 0.004458, loss_ce: 0.001651
2021-12-10 13:49:06,017 iteration 4002 : loss : 0.004512, loss_ce: 0.001521
2021-12-10 13:49:08,912 iteration 4003 : loss : 0.004201, loss_ce: 0.001603
2021-12-10 13:49:11,539 iteration 4004 : loss : 0.004069, loss_ce: 0.001898
2021-12-10 13:49:14,296 iteration 4005 : loss : 0.004101, loss_ce: 0.001555
2021-12-10 13:49:17,023 iteration 4006 : loss : 0.004752, loss_ce: 0.001574
2021-12-10 13:49:19,780 iteration 4007 : loss : 0.003600, loss_ce: 0.001687
2021-12-10 13:49:22,581 iteration 4008 : loss : 0.004842, loss_ce: 0.002075
2021-12-10 13:49:25,187 iteration 4009 : loss : 0.003701, loss_ce: 0.001378
2021-12-10 13:49:27,965 iteration 4010 : loss : 0.006003, loss_ce: 0.001698
2021-12-10 13:49:30,756 iteration 4011 : loss : 0.003302, loss_ce: 0.001087
2021-12-10 13:49:33,359 iteration 4012 : loss : 0.003970, loss_ce: 0.001552
 59%|███████████████▉           | 236/400 [3:22:56<2:24:29, 52.87s/it]2021-12-10 13:49:36,166 iteration 4013 : loss : 0.004323, loss_ce: 0.001930
2021-12-10 13:49:38,773 iteration 4014 : loss : 0.004652, loss_ce: 0.002444
2021-12-10 13:49:41,542 iteration 4015 : loss : 0.004987, loss_ce: 0.002611
2021-12-10 13:49:44,206 iteration 4016 : loss : 0.003739, loss_ce: 0.001515
2021-12-10 13:49:46,979 iteration 4017 : loss : 0.004403, loss_ce: 0.001390
2021-12-10 13:49:49,641 iteration 4018 : loss : 0.004673, loss_ce: 0.001832
2021-12-10 13:49:52,389 iteration 4019 : loss : 0.004005, loss_ce: 0.001375
2021-12-10 13:49:55,167 iteration 4020 : loss : 0.005149, loss_ce: 0.001641
2021-12-10 13:49:57,766 iteration 4021 : loss : 0.004708, loss_ce: 0.001769
2021-12-10 13:50:00,526 iteration 4022 : loss : 0.004840, loss_ce: 0.001774
2021-12-10 13:50:03,156 iteration 4023 : loss : 0.004772, loss_ce: 0.002015
2021-12-10 13:50:05,918 iteration 4024 : loss : 0.004975, loss_ce: 0.001415
2021-12-10 13:50:08,549 iteration 4025 : loss : 0.004266, loss_ce: 0.001419
2021-12-10 13:50:11,335 iteration 4026 : loss : 0.004468, loss_ce: 0.001293
2021-12-10 13:50:13,941 iteration 4027 : loss : 0.004336, loss_ce: 0.001863
2021-12-10 13:50:16,711 iteration 4028 : loss : 0.005516, loss_ce: 0.001849
2021-12-10 13:50:19,379 iteration 4029 : loss : 0.004345, loss_ce: 0.001494
 59%|███████████████▉           | 237/400 [3:23:42<2:18:02, 50.81s/it]2021-12-10 13:50:22,071 iteration 4030 : loss : 0.004449, loss_ce: 0.001643
2021-12-10 13:50:24,784 iteration 4031 : loss : 0.004932, loss_ce: 0.001677
2021-12-10 13:50:27,407 iteration 4032 : loss : 0.004556, loss_ce: 0.001385
2021-12-10 13:50:30,183 iteration 4033 : loss : 0.004744, loss_ce: 0.001872
2021-12-10 13:50:32,808 iteration 4034 : loss : 0.004839, loss_ce: 0.001316
2021-12-10 13:50:35,461 iteration 4035 : loss : 0.004408, loss_ce: 0.002031
2021-12-10 13:50:38,221 iteration 4036 : loss : 0.004239, loss_ce: 0.002004
2021-12-10 13:50:40,883 iteration 4037 : loss : 0.004593, loss_ce: 0.001728
2021-12-10 13:50:43,517 iteration 4038 : loss : 0.005332, loss_ce: 0.001825
2021-12-10 13:50:46,276 iteration 4039 : loss : 0.004320, loss_ce: 0.001751
2021-12-10 13:50:48,937 iteration 4040 : loss : 0.003763, loss_ce: 0.001985
2021-12-10 13:50:51,603 iteration 4041 : loss : 0.005430, loss_ce: 0.002729
2021-12-10 13:50:54,231 iteration 4042 : loss : 0.004850, loss_ce: 0.001674
2021-12-10 13:50:57,014 iteration 4043 : loss : 0.005098, loss_ce: 0.002082
2021-12-10 13:50:59,764 iteration 4044 : loss : 0.004814, loss_ce: 0.001507
2021-12-10 13:51:02,389 iteration 4045 : loss : 0.003293, loss_ce: 0.001254
2021-12-10 13:51:05,180 iteration 4046 : loss : 0.004367, loss_ce: 0.001288
 60%|████████████████           | 238/400 [3:24:28<2:13:07, 49.31s/it]2021-12-10 13:51:07,838 iteration 4047 : loss : 0.006853, loss_ce: 0.003057
2021-12-10 13:51:10,479 iteration 4048 : loss : 0.004011, loss_ce: 0.001497
2021-12-10 13:51:13,099 iteration 4049 : loss : 0.003435, loss_ce: 0.001116
2021-12-10 13:51:15,826 iteration 4050 : loss : 0.005104, loss_ce: 0.002249
2021-12-10 13:51:18,491 iteration 4051 : loss : 0.005375, loss_ce: 0.002020
2021-12-10 13:51:21,257 iteration 4052 : loss : 0.005735, loss_ce: 0.002190
2021-12-10 13:51:23,890 iteration 4053 : loss : 0.004916, loss_ce: 0.002397
2021-12-10 13:51:26,639 iteration 4054 : loss : 0.004763, loss_ce: 0.001491
2021-12-10 13:51:29,259 iteration 4055 : loss : 0.005888, loss_ce: 0.002218
2021-12-10 13:51:32,027 iteration 4056 : loss : 0.005272, loss_ce: 0.001636
2021-12-10 13:51:34,651 iteration 4057 : loss : 0.005077, loss_ce: 0.002285
2021-12-10 13:51:37,409 iteration 4058 : loss : 0.005280, loss_ce: 0.001633
2021-12-10 13:51:40,003 iteration 4059 : loss : 0.004267, loss_ce: 0.000971
2021-12-10 13:51:42,641 iteration 4060 : loss : 0.003703, loss_ce: 0.001419
2021-12-10 13:51:45,279 iteration 4061 : loss : 0.004787, loss_ce: 0.001843
2021-12-10 13:51:47,905 iteration 4062 : loss : 0.005905, loss_ce: 0.002812
2021-12-10 13:51:50,625 iteration 4063 : loss : 0.004561, loss_ce: 0.001910
 60%|████████████████▏          | 239/400 [3:25:13<2:09:12, 48.15s/it]2021-12-10 13:51:53,263 iteration 4064 : loss : 0.005363, loss_ce: 0.002208
2021-12-10 13:51:56,038 iteration 4065 : loss : 0.004665, loss_ce: 0.002350
2021-12-10 13:51:58,644 iteration 4066 : loss : 0.004115, loss_ce: 0.001433
2021-12-10 13:52:01,401 iteration 4067 : loss : 0.004258, loss_ce: 0.001989
2021-12-10 13:52:04,034 iteration 4068 : loss : 0.005048, loss_ce: 0.001667
2021-12-10 13:52:06,824 iteration 4069 : loss : 0.003329, loss_ce: 0.000699
2021-12-10 13:52:09,425 iteration 4070 : loss : 0.005117, loss_ce: 0.002503
2021-12-10 13:52:12,088 iteration 4071 : loss : 0.004230, loss_ce: 0.001755
2021-12-10 13:52:14,710 iteration 4072 : loss : 0.004773, loss_ce: 0.002390
2021-12-10 13:52:17,495 iteration 4073 : loss : 0.004136, loss_ce: 0.001368
2021-12-10 13:52:20,105 iteration 4074 : loss : 0.004569, loss_ce: 0.001180
2021-12-10 13:52:22,727 iteration 4075 : loss : 0.005669, loss_ce: 0.002403
2021-12-10 13:52:25,340 iteration 4076 : loss : 0.004606, loss_ce: 0.001726
2021-12-10 13:52:28,140 iteration 4077 : loss : 0.004914, loss_ce: 0.002215
2021-12-10 13:52:30,759 iteration 4078 : loss : 0.004648, loss_ce: 0.002085
2021-12-10 13:52:33,523 iteration 4079 : loss : 0.004993, loss_ce: 0.001339
2021-12-10 13:52:33,523 Training Data Eval:
2021-12-10 13:52:48,324   Average segmentation loss on training set: 0.0051
2021-12-10 13:52:48,324 Validation Data Eval:
2021-12-10 13:52:53,555   Average segmentation loss on validation set: 0.1130
2021-12-10 13:52:56,312 iteration 4080 : loss : 0.004435, loss_ce: 0.002200
 60%|████████████████▏          | 240/400 [3:26:19<2:22:25, 53.41s/it]2021-12-10 13:52:58,947 iteration 4081 : loss : 0.005914, loss_ce: 0.002109
2021-12-10 13:53:01,607 iteration 4082 : loss : 0.003557, loss_ce: 0.001447
2021-12-10 13:53:04,284 iteration 4083 : loss : 0.004777, loss_ce: 0.001723
2021-12-10 13:53:07,062 iteration 4084 : loss : 0.004059, loss_ce: 0.001490
2021-12-10 13:53:09,658 iteration 4085 : loss : 0.004443, loss_ce: 0.001513
2021-12-10 13:53:12,312 iteration 4086 : loss : 0.006426, loss_ce: 0.002828
2021-12-10 13:53:14,935 iteration 4087 : loss : 0.005216, loss_ce: 0.002147
2021-12-10 13:53:17,704 iteration 4088 : loss : 0.003777, loss_ce: 0.001510
2021-12-10 13:53:20,310 iteration 4089 : loss : 0.003300, loss_ce: 0.001409
2021-12-10 13:53:22,938 iteration 4090 : loss : 0.005426, loss_ce: 0.001686
2021-12-10 13:53:25,688 iteration 4091 : loss : 0.004315, loss_ce: 0.001459
2021-12-10 13:53:28,396 iteration 4092 : loss : 0.003940, loss_ce: 0.001385
2021-12-10 13:53:31,019 iteration 4093 : loss : 0.004946, loss_ce: 0.002215
2021-12-10 13:53:33,650 iteration 4094 : loss : 0.004131, loss_ce: 0.001955
2021-12-10 13:53:36,468 iteration 4095 : loss : 0.004173, loss_ce: 0.001412
2021-12-10 13:53:39,070 iteration 4096 : loss : 0.005779, loss_ce: 0.002621
2021-12-10 13:53:41,684 iteration 4097 : loss : 0.004408, loss_ce: 0.001380
 60%|████████████████▎          | 241/400 [3:27:04<2:15:08, 51.00s/it]2021-12-10 13:53:44,531 iteration 4098 : loss : 0.004889, loss_ce: 0.001960
2021-12-10 13:53:47,135 iteration 4099 : loss : 0.004709, loss_ce: 0.001450
2021-12-10 13:53:49,788 iteration 4100 : loss : 0.003211, loss_ce: 0.000989
2021-12-10 13:53:52,441 iteration 4101 : loss : 0.004280, loss_ce: 0.001271
2021-12-10 13:53:55,104 iteration 4102 : loss : 0.003620, loss_ce: 0.001648
2021-12-10 13:53:57,764 iteration 4103 : loss : 0.005180, loss_ce: 0.002050
2021-12-10 13:54:00,425 iteration 4104 : loss : 0.003904, loss_ce: 0.001744
2021-12-10 13:54:03,210 iteration 4105 : loss : 0.004419, loss_ce: 0.001488
2021-12-10 13:54:05,813 iteration 4106 : loss : 0.004667, loss_ce: 0.002047
2021-12-10 13:54:08,434 iteration 4107 : loss : 0.003347, loss_ce: 0.001097
2021-12-10 13:54:11,034 iteration 4108 : loss : 0.003914, loss_ce: 0.001767
2021-12-10 13:54:13,765 iteration 4109 : loss : 0.004070, loss_ce: 0.001972
2021-12-10 13:54:16,389 iteration 4110 : loss : 0.004400, loss_ce: 0.001572
2021-12-10 13:54:19,164 iteration 4111 : loss : 0.004473, loss_ce: 0.001308
2021-12-10 13:54:21,795 iteration 4112 : loss : 0.003706, loss_ce: 0.001728
2021-12-10 13:54:24,561 iteration 4113 : loss : 0.004200, loss_ce: 0.001633
2021-12-10 13:54:27,163 iteration 4114 : loss : 0.004270, loss_ce: 0.001765
 60%|████████████████▎          | 242/400 [3:27:49<2:09:56, 49.34s/it]2021-12-10 13:54:29,857 iteration 4115 : loss : 0.004551, loss_ce: 0.002148
2021-12-10 13:54:32,602 iteration 4116 : loss : 0.004206, loss_ce: 0.001487
2021-12-10 13:54:35,227 iteration 4117 : loss : 0.004463, loss_ce: 0.001304
2021-12-10 13:54:37,834 iteration 4118 : loss : 0.005351, loss_ce: 0.001884
2021-12-10 13:54:40,631 iteration 4119 : loss : 0.004423, loss_ce: 0.001663
2021-12-10 13:54:43,236 iteration 4120 : loss : 0.003802, loss_ce: 0.001339
2021-12-10 13:54:45,862 iteration 4121 : loss : 0.004793, loss_ce: 0.002248
2021-12-10 13:54:48,635 iteration 4122 : loss : 0.004337, loss_ce: 0.002187
2021-12-10 13:54:51,232 iteration 4123 : loss : 0.003802, loss_ce: 0.001448
2021-12-10 13:54:54,007 iteration 4124 : loss : 0.003657, loss_ce: 0.001089
2021-12-10 13:54:56,578 iteration 4125 : loss : 0.004220, loss_ce: 0.001520
2021-12-10 13:54:59,344 iteration 4126 : loss : 0.004723, loss_ce: 0.001780
2021-12-10 13:55:01,969 iteration 4127 : loss : 0.003751, loss_ce: 0.001855
2021-12-10 13:55:04,610 iteration 4128 : loss : 0.003871, loss_ce: 0.001859
2021-12-10 13:55:07,325 iteration 4129 : loss : 0.004729, loss_ce: 0.001614
2021-12-10 13:55:09,995 iteration 4130 : loss : 0.003581, loss_ce: 0.001435
2021-12-10 13:55:12,598 iteration 4131 : loss : 0.004536, loss_ce: 0.001518
 61%|████████████████▍          | 243/400 [3:28:35<2:06:02, 48.17s/it]2021-12-10 13:55:15,274 iteration 4132 : loss : 0.004353, loss_ce: 0.002107
2021-12-10 13:55:17,900 iteration 4133 : loss : 0.004949, loss_ce: 0.001674
2021-12-10 13:55:20,664 iteration 4134 : loss : 0.004851, loss_ce: 0.002035
2021-12-10 13:55:23,295 iteration 4135 : loss : 0.003855, loss_ce: 0.001534
2021-12-10 13:55:25,896 iteration 4136 : loss : 0.004411, loss_ce: 0.002147
2021-12-10 13:55:28,668 iteration 4137 : loss : 0.005487, loss_ce: 0.001349
2021-12-10 13:55:31,302 iteration 4138 : loss : 0.003490, loss_ce: 0.001271
2021-12-10 13:55:33,965 iteration 4139 : loss : 0.004603, loss_ce: 0.001866
2021-12-10 13:55:36,637 iteration 4140 : loss : 0.003321, loss_ce: 0.001369
2021-12-10 13:55:39,268 iteration 4141 : loss : 0.004385, loss_ce: 0.001161
2021-12-10 13:55:41,911 iteration 4142 : loss : 0.004243, loss_ce: 0.001614
2021-12-10 13:55:44,636 iteration 4143 : loss : 0.004409, loss_ce: 0.001418
2021-12-10 13:55:47,418 iteration 4144 : loss : 0.005514, loss_ce: 0.002364
2021-12-10 13:55:50,016 iteration 4145 : loss : 0.004283, loss_ce: 0.001967
2021-12-10 13:55:52,633 iteration 4146 : loss : 0.004238, loss_ce: 0.001893
2021-12-10 13:55:55,409 iteration 4147 : loss : 0.004847, loss_ce: 0.002014
2021-12-10 13:55:58,007 iteration 4148 : loss : 0.006971, loss_ce: 0.001727
 61%|████████████████▍          | 244/400 [3:29:20<2:03:05, 47.34s/it]2021-12-10 13:56:00,672 iteration 4149 : loss : 0.004787, loss_ce: 0.001655
2021-12-10 13:56:03,299 iteration 4150 : loss : 0.003912, loss_ce: 0.001541
2021-12-10 13:56:06,011 iteration 4151 : loss : 0.003991, loss_ce: 0.001626
2021-12-10 13:56:08,633 iteration 4152 : loss : 0.003820, loss_ce: 0.001389
2021-12-10 13:56:11,418 iteration 4153 : loss : 0.004702, loss_ce: 0.001737
2021-12-10 13:56:14,022 iteration 4154 : loss : 0.004822, loss_ce: 0.001364
2021-12-10 13:56:16,766 iteration 4155 : loss : 0.004301, loss_ce: 0.001507
2021-12-10 13:56:19,366 iteration 4156 : loss : 0.004809, loss_ce: 0.001264
2021-12-10 13:56:22,055 iteration 4157 : loss : 0.003883, loss_ce: 0.001427
2021-12-10 13:56:24,753 iteration 4158 : loss : 0.004532, loss_ce: 0.001915
2021-12-10 13:56:27,554 iteration 4159 : loss : 0.005831, loss_ce: 0.002616
2021-12-10 13:56:30,165 iteration 4160 : loss : 0.005613, loss_ce: 0.002203
2021-12-10 13:56:32,788 iteration 4161 : loss : 0.004609, loss_ce: 0.001528
2021-12-10 13:56:35,397 iteration 4162 : loss : 0.003881, loss_ce: 0.001492
2021-12-10 13:56:38,146 iteration 4163 : loss : 0.008112, loss_ce: 0.003215
2021-12-10 13:56:40,742 iteration 4164 : loss : 0.005995, loss_ce: 0.002457
2021-12-10 13:56:40,742 Training Data Eval:
2021-12-10 13:56:55,485   Average segmentation loss on training set: 0.0048
2021-12-10 13:56:55,486 Validation Data Eval:
2021-12-10 13:57:00,678   Average segmentation loss on validation set: 0.1434
2021-12-10 13:57:03,328 iteration 4165 : loss : 0.004406, loss_ce: 0.001632
 61%|████████████████▌          | 245/400 [3:30:26<2:16:14, 52.74s/it]2021-12-10 13:57:05,959 iteration 4166 : loss : 0.004171, loss_ce: 0.001709
2021-12-10 13:57:08,669 iteration 4167 : loss : 0.004765, loss_ce: 0.001219
2021-12-10 13:57:11,291 iteration 4168 : loss : 0.005533, loss_ce: 0.001997
2021-12-10 13:57:13,910 iteration 4169 : loss : 0.004143, loss_ce: 0.001888
2021-12-10 13:57:16,679 iteration 4170 : loss : 0.004316, loss_ce: 0.002123
2021-12-10 13:57:19,304 iteration 4171 : loss : 0.004807, loss_ce: 0.001452
2021-12-10 13:57:22,022 iteration 4172 : loss : 0.005057, loss_ce: 0.002351
2021-12-10 13:57:24,648 iteration 4173 : loss : 0.005776, loss_ce: 0.001929
2021-12-10 13:57:27,412 iteration 4174 : loss : 0.004983, loss_ce: 0.001773
2021-12-10 13:57:30,079 iteration 4175 : loss : 0.005152, loss_ce: 0.001370
2021-12-10 13:57:32,750 iteration 4176 : loss : 0.004908, loss_ce: 0.001849
2021-12-10 13:57:35,378 iteration 4177 : loss : 0.005717, loss_ce: 0.001760
2021-12-10 13:57:37,996 iteration 4178 : loss : 0.005274, loss_ce: 0.002343
2021-12-10 13:57:40,762 iteration 4179 : loss : 0.004918, loss_ce: 0.001903
2021-12-10 13:57:43,363 iteration 4180 : loss : 0.005075, loss_ce: 0.001660
2021-12-10 13:57:46,120 iteration 4181 : loss : 0.004246, loss_ce: 0.001503
2021-12-10 13:57:48,730 iteration 4182 : loss : 0.006798, loss_ce: 0.002707
 62%|████████████████▌          | 246/400 [3:31:11<2:09:42, 50.54s/it]2021-12-10 13:57:51,407 iteration 4183 : loss : 0.004144, loss_ce: 0.001583
2021-12-10 13:57:54,008 iteration 4184 : loss : 0.005077, loss_ce: 0.001792
2021-12-10 13:57:56,631 iteration 4185 : loss : 0.004544, loss_ce: 0.001813
2021-12-10 13:57:59,397 iteration 4186 : loss : 0.004750, loss_ce: 0.002404
2021-12-10 13:58:02,067 iteration 4187 : loss : 0.004750, loss_ce: 0.001475
2021-12-10 13:58:04,843 iteration 4188 : loss : 0.004647, loss_ce: 0.001733
2021-12-10 13:58:07,449 iteration 4189 : loss : 0.004240, loss_ce: 0.001458
2021-12-10 13:58:10,051 iteration 4190 : loss : 0.003910, loss_ce: 0.001309
2021-12-10 13:58:12,832 iteration 4191 : loss : 0.004033, loss_ce: 0.001055
2021-12-10 13:58:15,441 iteration 4192 : loss : 0.006530, loss_ce: 0.003008
2021-12-10 13:58:18,205 iteration 4193 : loss : 0.004032, loss_ce: 0.001334
2021-12-10 13:58:20,809 iteration 4194 : loss : 0.004787, loss_ce: 0.002252
2021-12-10 13:58:23,499 iteration 4195 : loss : 0.004691, loss_ce: 0.002257
2021-12-10 13:58:26,100 iteration 4196 : loss : 0.005008, loss_ce: 0.001741
2021-12-10 13:58:28,924 iteration 4197 : loss : 0.004460, loss_ce: 0.001549
2021-12-10 13:58:31,528 iteration 4198 : loss : 0.003889, loss_ce: 0.001490
2021-12-10 13:58:34,235 iteration 4199 : loss : 0.005197, loss_ce: 0.001727
 62%|████████████████▋          | 247/400 [3:31:57<2:05:01, 49.03s/it]2021-12-10 13:58:36,854 iteration 4200 : loss : 0.004796, loss_ce: 0.002001
2021-12-10 13:58:39,507 iteration 4201 : loss : 0.005132, loss_ce: 0.002485
2021-12-10 13:58:42,215 iteration 4202 : loss : 0.005191, loss_ce: 0.001786
2021-12-10 13:58:44,898 iteration 4203 : loss : 0.003674, loss_ce: 0.001078
2021-12-10 13:58:47,512 iteration 4204 : loss : 0.004136, loss_ce: 0.001440
2021-12-10 13:58:50,113 iteration 4205 : loss : 0.003999, loss_ce: 0.001831
2021-12-10 13:58:52,803 iteration 4206 : loss : 0.004504, loss_ce: 0.001751
2021-12-10 13:58:55,406 iteration 4207 : loss : 0.003957, loss_ce: 0.001590
2021-12-10 13:58:58,223 iteration 4208 : loss : 0.004348, loss_ce: 0.001582
2021-12-10 13:59:00,837 iteration 4209 : loss : 0.004252, loss_ce: 0.001464
2021-12-10 13:59:03,470 iteration 4210 : loss : 0.003459, loss_ce: 0.001522
2021-12-10 13:59:06,077 iteration 4211 : loss : 0.004559, loss_ce: 0.001321
2021-12-10 13:59:08,845 iteration 4212 : loss : 0.003641, loss_ce: 0.001432
2021-12-10 13:59:11,584 iteration 4213 : loss : 0.003940, loss_ce: 0.001456
2021-12-10 13:59:14,185 iteration 4214 : loss : 0.004677, loss_ce: 0.002065
2021-12-10 13:59:16,809 iteration 4215 : loss : 0.004012, loss_ce: 0.001564
2021-12-10 13:59:19,476 iteration 4216 : loss : 0.003302, loss_ce: 0.001202
 62%|████████████████▋          | 248/400 [3:32:42<2:01:19, 47.89s/it]2021-12-10 13:59:22,161 iteration 4217 : loss : 0.004121, loss_ce: 0.001788
2021-12-10 13:59:24,867 iteration 4218 : loss : 0.004433, loss_ce: 0.001644
2021-12-10 13:59:27,486 iteration 4219 : loss : 0.003738, loss_ce: 0.001350
2021-12-10 13:59:30,193 iteration 4220 : loss : 0.003737, loss_ce: 0.001691
2021-12-10 13:59:32,818 iteration 4221 : loss : 0.004853, loss_ce: 0.002032
2021-12-10 13:59:35,483 iteration 4222 : loss : 0.003637, loss_ce: 0.001542
2021-12-10 13:59:38,146 iteration 4223 : loss : 0.004006, loss_ce: 0.001569
2021-12-10 13:59:40,810 iteration 4224 : loss : 0.004303, loss_ce: 0.001737
2021-12-10 13:59:43,471 iteration 4225 : loss : 0.003285, loss_ce: 0.001429
2021-12-10 13:59:46,097 iteration 4226 : loss : 0.003215, loss_ce: 0.001305
2021-12-10 13:59:48,801 iteration 4227 : loss : 0.003437, loss_ce: 0.001279
2021-12-10 13:59:51,538 iteration 4228 : loss : 0.003843, loss_ce: 0.001144
2021-12-10 13:59:54,144 iteration 4229 : loss : 0.003441, loss_ce: 0.001763
2021-12-10 13:59:56,797 iteration 4230 : loss : 0.004085, loss_ce: 0.001031
2021-12-10 13:59:59,422 iteration 4231 : loss : 0.003159, loss_ce: 0.000808
2021-12-10 14:00:02,199 iteration 4232 : loss : 0.004373, loss_ce: 0.001629
2021-12-10 14:00:04,791 iteration 4233 : loss : 0.003522, loss_ce: 0.001430
 62%|████████████████▊          | 249/400 [3:33:27<1:58:34, 47.12s/it]2021-12-10 14:00:07,570 iteration 4234 : loss : 0.003643, loss_ce: 0.001301
2021-12-10 14:00:10,178 iteration 4235 : loss : 0.003684, loss_ce: 0.001113
2021-12-10 14:00:12,842 iteration 4236 : loss : 0.003459, loss_ce: 0.001522
2021-12-10 14:00:15,462 iteration 4237 : loss : 0.004040, loss_ce: 0.001167
2021-12-10 14:00:18,115 iteration 4238 : loss : 0.003789, loss_ce: 0.001701
2021-12-10 14:00:20,735 iteration 4239 : loss : 0.004651, loss_ce: 0.001275
2021-12-10 14:00:23,341 iteration 4240 : loss : 0.004277, loss_ce: 0.002069
2021-12-10 14:00:25,959 iteration 4241 : loss : 0.003914, loss_ce: 0.001854
2021-12-10 14:00:28,725 iteration 4242 : loss : 0.003800, loss_ce: 0.001368
2021-12-10 14:00:31,320 iteration 4243 : loss : 0.005353, loss_ce: 0.002199
2021-12-10 14:00:33,928 iteration 4244 : loss : 0.003397, loss_ce: 0.001466
2021-12-10 14:00:36,697 iteration 4245 : loss : 0.004483, loss_ce: 0.002131
2021-12-10 14:00:39,300 iteration 4246 : loss : 0.003409, loss_ce: 0.000956
2021-12-10 14:00:41,979 iteration 4247 : loss : 0.003686, loss_ce: 0.001337
2021-12-10 14:00:44,776 iteration 4248 : loss : 0.003756, loss_ce: 0.001643
2021-12-10 14:00:47,373 iteration 4249 : loss : 0.004746, loss_ce: 0.002221
2021-12-10 14:00:47,373 Training Data Eval:
2021-12-10 14:01:01,895   Average segmentation loss on training set: 0.0038
2021-12-10 14:01:01,895 Validation Data Eval:
2021-12-10 14:01:07,191   Average segmentation loss on validation set: 0.1372
2021-12-10 14:01:09,797 iteration 4250 : loss : 0.003404, loss_ce: 0.001480
2021-12-10 14:01:15,897 save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/NEW_TU/NEW_TU_ADAM_seed1234_no_daepoch_249.pth
 62%|████████████████▉          | 250/400 [3:34:38<2:15:44, 54.30s/it]2021-12-10 14:01:17,493 iteration 4251 : loss : 0.003507, loss_ce: 0.001495
2021-12-10 14:01:19,419 iteration 4252 : loss : 0.004524, loss_ce: 0.001284
2021-12-10 14:01:21,752 iteration 4253 : loss : 0.003928, loss_ce: 0.001880
2021-12-10 14:01:24,110 iteration 4254 : loss : 0.003631, loss_ce: 0.001683
2021-12-10 14:01:26,469 iteration 4255 : loss : 0.004576, loss_ce: 0.002032
2021-12-10 14:01:28,816 iteration 4256 : loss : 0.003323, loss_ce: 0.001259
2021-12-10 14:01:31,291 iteration 4257 : loss : 0.004078, loss_ce: 0.001325
2021-12-10 14:01:33,855 iteration 4258 : loss : 0.004829, loss_ce: 0.002032
2021-12-10 14:01:36,423 iteration 4259 : loss : 0.004175, loss_ce: 0.001663
2021-12-10 14:01:39,036 iteration 4260 : loss : 0.004317, loss_ce: 0.001910
2021-12-10 14:01:41,616 iteration 4261 : loss : 0.003768, loss_ce: 0.001504
2021-12-10 14:01:44,230 iteration 4262 : loss : 0.003603, loss_ce: 0.001610
2021-12-10 14:01:46,850 iteration 4263 : loss : 0.003927, loss_ce: 0.001445
2021-12-10 14:01:49,473 iteration 4264 : loss : 0.003624, loss_ce: 0.001733
2021-12-10 14:01:52,126 iteration 4265 : loss : 0.003502, loss_ce: 0.001227
2021-12-10 14:01:54,744 iteration 4266 : loss : 0.003822, loss_ce: 0.001294
2021-12-10 14:01:57,351 iteration 4267 : loss : 0.004029, loss_ce: 0.001562
 63%|████████████████▉          | 251/400 [3:35:20<2:05:18, 50.46s/it]2021-12-10 14:02:00,033 iteration 4268 : loss : 0.003684, loss_ce: 0.001507
2021-12-10 14:02:02,696 iteration 4269 : loss : 0.004990, loss_ce: 0.001327
2021-12-10 14:02:05,330 iteration 4270 : loss : 0.004036, loss_ce: 0.001678
2021-12-10 14:02:07,942 iteration 4271 : loss : 0.003855, loss_ce: 0.001269
2021-12-10 14:02:10,753 iteration 4272 : loss : 0.004076, loss_ce: 0.001836
2021-12-10 14:02:13,361 iteration 4273 : loss : 0.004981, loss_ce: 0.001355
2021-12-10 14:02:15,989 iteration 4274 : loss : 0.003876, loss_ce: 0.001726
2021-12-10 14:02:18,647 iteration 4275 : loss : 0.004545, loss_ce: 0.001809
2021-12-10 14:02:21,279 iteration 4276 : loss : 0.003989, loss_ce: 0.001703
2021-12-10 14:02:23,904 iteration 4277 : loss : 0.004101, loss_ce: 0.001586
2021-12-10 14:02:26,664 iteration 4278 : loss : 0.004599, loss_ce: 0.001970
2021-12-10 14:02:29,290 iteration 4279 : loss : 0.003898, loss_ce: 0.001561
2021-12-10 14:02:31,922 iteration 4280 : loss : 0.004543, loss_ce: 0.002057
2021-12-10 14:02:34,540 iteration 4281 : loss : 0.003490, loss_ce: 0.001469
2021-12-10 14:02:37,291 iteration 4282 : loss : 0.003753, loss_ce: 0.000826
2021-12-10 14:02:39,890 iteration 4283 : loss : 0.004541, loss_ce: 0.001603
2021-12-10 14:02:42,579 iteration 4284 : loss : 0.003978, loss_ce: 0.001733
 63%|█████████████████          | 252/400 [3:36:05<2:00:36, 48.89s/it]2021-12-10 14:02:45,244 iteration 4285 : loss : 0.004040, loss_ce: 0.002020
2021-12-10 14:02:47,873 iteration 4286 : loss : 0.003910, loss_ce: 0.001577
2021-12-10 14:02:50,483 iteration 4287 : loss : 0.004221, loss_ce: 0.001669
2021-12-10 14:02:53,254 iteration 4288 : loss : 0.003157, loss_ce: 0.001285
2021-12-10 14:02:55,877 iteration 4289 : loss : 0.004206, loss_ce: 0.001781
2021-12-10 14:02:58,488 iteration 4290 : loss : 0.004284, loss_ce: 0.002019
2021-12-10 14:03:01,243 iteration 4291 : loss : 0.003919, loss_ce: 0.001177
2021-12-10 14:03:03,877 iteration 4292 : loss : 0.004655, loss_ce: 0.001037
2021-12-10 14:03:06,501 iteration 4293 : loss : 0.004117, loss_ce: 0.001627
2021-12-10 14:03:09,306 iteration 4294 : loss : 0.004319, loss_ce: 0.001871
2021-12-10 14:03:11,921 iteration 4295 : loss : 0.005124, loss_ce: 0.002040
2021-12-10 14:03:14,541 iteration 4296 : loss : 0.004145, loss_ce: 0.001578
2021-12-10 14:03:17,162 iteration 4297 : loss : 0.003535, loss_ce: 0.001428
2021-12-10 14:03:19,926 iteration 4298 : loss : 0.003222, loss_ce: 0.001181
2021-12-10 14:03:22,523 iteration 4299 : loss : 0.003087, loss_ce: 0.000911
2021-12-10 14:03:25,140 iteration 4300 : loss : 0.004733, loss_ce: 0.001601
2021-12-10 14:03:27,900 iteration 4301 : loss : 0.005278, loss_ce: 0.002020
 63%|█████████████████          | 253/400 [3:36:50<1:57:09, 47.82s/it]2021-12-10 14:03:30,533 iteration 4302 : loss : 0.003816, loss_ce: 0.001441
2021-12-10 14:03:33,324 iteration 4303 : loss : 0.003925, loss_ce: 0.001344
2021-12-10 14:03:35,924 iteration 4304 : loss : 0.003839, loss_ce: 0.001713
2021-12-10 14:03:38,547 iteration 4305 : loss : 0.004397, loss_ce: 0.001736
2021-12-10 14:03:41,200 iteration 4306 : loss : 0.003640, loss_ce: 0.001596
2021-12-10 14:03:43,802 iteration 4307 : loss : 0.003914, loss_ce: 0.001331
2021-12-10 14:03:46,602 iteration 4308 : loss : 0.005167, loss_ce: 0.001868
2021-12-10 14:03:49,215 iteration 4309 : loss : 0.004258, loss_ce: 0.001451
2021-12-10 14:03:51,853 iteration 4310 : loss : 0.004808, loss_ce: 0.002006
2021-12-10 14:03:54,457 iteration 4311 : loss : 0.004563, loss_ce: 0.001508
2021-12-10 14:03:57,085 iteration 4312 : loss : 0.004769, loss_ce: 0.001725
2021-12-10 14:03:59,856 iteration 4313 : loss : 0.005282, loss_ce: 0.001073
2021-12-10 14:04:02,454 iteration 4314 : loss : 0.004314, loss_ce: 0.001731
2021-12-10 14:04:05,070 iteration 4315 : loss : 0.004047, loss_ce: 0.001960
2021-12-10 14:04:07,698 iteration 4316 : loss : 0.003308, loss_ce: 0.001347
2021-12-10 14:04:10,462 iteration 4317 : loss : 0.005664, loss_ce: 0.002014
2021-12-10 14:04:13,063 iteration 4318 : loss : 0.004691, loss_ce: 0.002318
 64%|█████████████████▏         | 254/400 [3:37:35<1:54:25, 47.02s/it]2021-12-10 14:04:15,731 iteration 4319 : loss : 0.003905, loss_ce: 0.001739
2021-12-10 14:04:18,495 iteration 4320 : loss : 0.004024, loss_ce: 0.001507
2021-12-10 14:04:21,096 iteration 4321 : loss : 0.004631, loss_ce: 0.001514
2021-12-10 14:04:23,717 iteration 4322 : loss : 0.004544, loss_ce: 0.001609
2021-12-10 14:04:26,483 iteration 4323 : loss : 0.004958, loss_ce: 0.002172
2021-12-10 14:04:29,082 iteration 4324 : loss : 0.004610, loss_ce: 0.001983
2021-12-10 14:04:31,699 iteration 4325 : loss : 0.004825, loss_ce: 0.002263
2021-12-10 14:04:34,456 iteration 4326 : loss : 0.005034, loss_ce: 0.002171
2021-12-10 14:04:37,072 iteration 4327 : loss : 0.004785, loss_ce: 0.001848
2021-12-10 14:04:39,685 iteration 4328 : loss : 0.004717, loss_ce: 0.001965
2021-12-10 14:04:42,342 iteration 4329 : loss : 0.004072, loss_ce: 0.001682
2021-12-10 14:04:44,978 iteration 4330 : loss : 0.005086, loss_ce: 0.002668
2021-12-10 14:04:47,595 iteration 4331 : loss : 0.004149, loss_ce: 0.001220
2021-12-10 14:04:50,196 iteration 4332 : loss : 0.004969, loss_ce: 0.002137
2021-12-10 14:04:52,820 iteration 4333 : loss : 0.003771, loss_ce: 0.001049
2021-12-10 14:04:55,445 iteration 4334 : loss : 0.005226, loss_ce: 0.002074
2021-12-10 14:04:55,445 Training Data Eval:
2021-12-10 14:05:10,159   Average segmentation loss on training set: 0.0048
2021-12-10 14:05:10,160 Validation Data Eval:
2021-12-10 14:05:15,365   Average segmentation loss on validation set: 0.1254
2021-12-10 14:05:17,998 iteration 4335 : loss : 0.005929, loss_ce: 0.002363
 64%|█████████████████▏         | 255/400 [3:38:40<2:06:37, 52.40s/it]2021-12-10 14:05:20,709 iteration 4336 : loss : 0.004767, loss_ce: 0.002061
2021-12-10 14:05:23,342 iteration 4337 : loss : 0.005195, loss_ce: 0.003100
2021-12-10 14:05:25,963 iteration 4338 : loss : 0.004568, loss_ce: 0.001460
2021-12-10 14:05:28,730 iteration 4339 : loss : 0.005220, loss_ce: 0.001823
2021-12-10 14:05:31,322 iteration 4340 : loss : 0.004753, loss_ce: 0.001863
2021-12-10 14:05:33,913 iteration 4341 : loss : 0.003797, loss_ce: 0.001567
2021-12-10 14:05:36,537 iteration 4342 : loss : 0.003750, loss_ce: 0.001672
2021-12-10 14:05:39,310 iteration 4343 : loss : 0.004403, loss_ce: 0.001538
2021-12-10 14:05:41,940 iteration 4344 : loss : 0.003759, loss_ce: 0.001329
2021-12-10 14:05:44,653 iteration 4345 : loss : 0.004435, loss_ce: 0.001543
2021-12-10 14:05:47,267 iteration 4346 : loss : 0.004087, loss_ce: 0.001885
2021-12-10 14:05:50,033 iteration 4347 : loss : 0.003629, loss_ce: 0.001460
2021-12-10 14:05:52,630 iteration 4348 : loss : 0.003586, loss_ce: 0.001410
2021-12-10 14:05:55,249 iteration 4349 : loss : 0.003776, loss_ce: 0.001319
2021-12-10 14:05:58,060 iteration 4350 : loss : 0.003403, loss_ce: 0.001321
2021-12-10 14:06:00,671 iteration 4351 : loss : 0.003082, loss_ce: 0.001255
2021-12-10 14:06:03,271 iteration 4352 : loss : 0.004662, loss_ce: 0.001826
 64%|█████████████████▎         | 256/400 [3:39:26<2:00:37, 50.26s/it]2021-12-10 14:06:05,940 iteration 4353 : loss : 0.005187, loss_ce: 0.001947
2021-12-10 14:06:08,548 iteration 4354 : loss : 0.003796, loss_ce: 0.001440
2021-12-10 14:06:11,302 iteration 4355 : loss : 0.004878, loss_ce: 0.002345
2021-12-10 14:06:13,904 iteration 4356 : loss : 0.004060, loss_ce: 0.001775
2021-12-10 14:06:16,520 iteration 4357 : loss : 0.004264, loss_ce: 0.001673
2021-12-10 14:06:19,141 iteration 4358 : loss : 0.003785, loss_ce: 0.001574
2021-12-10 14:06:21,908 iteration 4359 : loss : 0.003710, loss_ce: 0.001411
2021-12-10 14:06:24,509 iteration 4360 : loss : 0.003505, loss_ce: 0.001304
2021-12-10 14:06:27,125 iteration 4361 : loss : 0.004059, loss_ce: 0.001306
2021-12-10 14:06:29,869 iteration 4362 : loss : 0.003097, loss_ce: 0.001052
2021-12-10 14:06:32,444 iteration 4363 : loss : 0.003817, loss_ce: 0.001205
2021-12-10 14:06:35,217 iteration 4364 : loss : 0.003702, loss_ce: 0.001534
2021-12-10 14:06:37,821 iteration 4365 : loss : 0.003924, loss_ce: 0.002157
2021-12-10 14:06:40,439 iteration 4366 : loss : 0.003828, loss_ce: 0.000957
2021-12-10 14:06:43,046 iteration 4367 : loss : 0.006808, loss_ce: 0.002957
2021-12-10 14:06:45,785 iteration 4368 : loss : 0.003581, loss_ce: 0.001538
2021-12-10 14:06:48,483 iteration 4369 : loss : 0.004022, loss_ce: 0.001387
 64%|█████████████████▎         | 257/400 [3:40:11<1:56:10, 48.74s/it]2021-12-10 14:06:51,153 iteration 4370 : loss : 0.004179, loss_ce: 0.001525
2021-12-10 14:06:53,799 iteration 4371 : loss : 0.003570, loss_ce: 0.001238
2021-12-10 14:06:56,442 iteration 4372 : loss : 0.003579, loss_ce: 0.001523
2021-12-10 14:06:59,059 iteration 4373 : loss : 0.003884, loss_ce: 0.001622
2021-12-10 14:07:01,679 iteration 4374 : loss : 0.003896, loss_ce: 0.001641
2021-12-10 14:07:04,473 iteration 4375 : loss : 0.003661, loss_ce: 0.001337
2021-12-10 14:07:07,078 iteration 4376 : loss : 0.003666, loss_ce: 0.001544
2021-12-10 14:07:09,813 iteration 4377 : loss : 0.003739, loss_ce: 0.001287
2021-12-10 14:07:12,419 iteration 4378 : loss : 0.003189, loss_ce: 0.001130
2021-12-10 14:07:15,080 iteration 4379 : loss : 0.003172, loss_ce: 0.001151
2021-12-10 14:07:17,692 iteration 4380 : loss : 0.003215, loss_ce: 0.001349
2021-12-10 14:07:20,354 iteration 4381 : loss : 0.003174, loss_ce: 0.001024
2021-12-10 14:07:23,069 iteration 4382 : loss : 0.003534, loss_ce: 0.001126
2021-12-10 14:07:25,666 iteration 4383 : loss : 0.003361, loss_ce: 0.001707
2021-12-10 14:07:28,273 iteration 4384 : loss : 0.002874, loss_ce: 0.001132
2021-12-10 14:07:31,031 iteration 4385 : loss : 0.004141, loss_ce: 0.001702
2021-12-10 14:07:33,651 iteration 4386 : loss : 0.003612, loss_ce: 0.001554
 64%|█████████████████▍         | 258/400 [3:40:56<1:52:49, 47.67s/it]2021-12-10 14:07:36,333 iteration 4387 : loss : 0.003300, loss_ce: 0.001437
2021-12-10 14:07:39,103 iteration 4388 : loss : 0.003113, loss_ce: 0.000991
2021-12-10 14:07:41,720 iteration 4389 : loss : 0.003334, loss_ce: 0.001467
2021-12-10 14:07:44,336 iteration 4390 : loss : 0.004433, loss_ce: 0.001878
2021-12-10 14:07:47,100 iteration 4391 : loss : 0.003105, loss_ce: 0.001153
2021-12-10 14:07:49,755 iteration 4392 : loss : 0.003867, loss_ce: 0.001071
2021-12-10 14:07:52,364 iteration 4393 : loss : 0.003372, loss_ce: 0.001400
2021-12-10 14:07:54,979 iteration 4394 : loss : 0.003526, loss_ce: 0.001864
2021-12-10 14:07:57,587 iteration 4395 : loss : 0.003714, loss_ce: 0.001531
2021-12-10 14:08:00,323 iteration 4396 : loss : 0.003577, loss_ce: 0.001585
2021-12-10 14:08:02,982 iteration 4397 : loss : 0.003173, loss_ce: 0.001053
2021-12-10 14:08:05,639 iteration 4398 : loss : 0.004046, loss_ce: 0.001718
2021-12-10 14:08:08,301 iteration 4399 : loss : 0.003525, loss_ce: 0.001481
2021-12-10 14:08:10,966 iteration 4400 : loss : 0.003575, loss_ce: 0.001468
2021-12-10 14:08:13,628 iteration 4401 : loss : 0.003041, loss_ce: 0.001106
2021-12-10 14:08:16,254 iteration 4402 : loss : 0.003941, loss_ce: 0.001997
2021-12-10 14:08:18,913 iteration 4403 : loss : 0.004884, loss_ce: 0.002082
 65%|█████████████████▍         | 259/400 [3:41:41<1:50:20, 46.95s/it]2021-12-10 14:08:21,641 iteration 4404 : loss : 0.003571, loss_ce: 0.001216
2021-12-10 14:08:24,320 iteration 4405 : loss : 0.003899, loss_ce: 0.001156
2021-12-10 14:08:26,922 iteration 4406 : loss : 0.003358, loss_ce: 0.001259
2021-12-10 14:08:29,602 iteration 4407 : loss : 0.004659, loss_ce: 0.001490
2021-12-10 14:08:32,230 iteration 4408 : loss : 0.002840, loss_ce: 0.001183
2021-12-10 14:08:34,882 iteration 4409 : loss : 0.003449, loss_ce: 0.001174
2021-12-10 14:08:37,532 iteration 4410 : loss : 0.003555, loss_ce: 0.001345
2021-12-10 14:08:40,152 iteration 4411 : loss : 0.003518, loss_ce: 0.001772
2021-12-10 14:08:42,802 iteration 4412 : loss : 0.002802, loss_ce: 0.001384
2021-12-10 14:08:45,419 iteration 4413 : loss : 0.004605, loss_ce: 0.002043
2021-12-10 14:08:48,178 iteration 4414 : loss : 0.004216, loss_ce: 0.001595
2021-12-10 14:08:50,783 iteration 4415 : loss : 0.003510, loss_ce: 0.001206
2021-12-10 14:08:53,529 iteration 4416 : loss : 0.003778, loss_ce: 0.001590
2021-12-10 14:08:56,132 iteration 4417 : loss : 0.003680, loss_ce: 0.001506
2021-12-10 14:08:58,748 iteration 4418 : loss : 0.003649, loss_ce: 0.001727
2021-12-10 14:09:01,374 iteration 4419 : loss : 0.004154, loss_ce: 0.001825
2021-12-10 14:09:01,374 Training Data Eval:
2021-12-10 14:09:16,234   Average segmentation loss on training set: 0.0035
2021-12-10 14:09:16,234 Validation Data Eval:
2021-12-10 14:09:21,336   Average segmentation loss on validation set: 0.1415
2021-12-10 14:09:24,087 iteration 4420 : loss : 0.004540, loss_ce: 0.001827
 65%|█████████████████▌         | 260/400 [3:42:46<2:02:18, 52.42s/it]2021-12-10 14:09:26,729 iteration 4421 : loss : 0.003064, loss_ce: 0.001045
2021-12-10 14:09:29,497 iteration 4422 : loss : 0.004001, loss_ce: 0.001566
2021-12-10 14:09:32,088 iteration 4423 : loss : 0.003112, loss_ce: 0.001511
2021-12-10 14:09:34,699 iteration 4424 : loss : 0.004219, loss_ce: 0.001894
2021-12-10 14:09:37,476 iteration 4425 : loss : 0.005728, loss_ce: 0.001990
2021-12-10 14:09:40,073 iteration 4426 : loss : 0.004393, loss_ce: 0.001782
2021-12-10 14:09:42,694 iteration 4427 : loss : 0.003468, loss_ce: 0.001210
2021-12-10 14:09:45,466 iteration 4428 : loss : 0.003411, loss_ce: 0.001396
2021-12-10 14:09:48,074 iteration 4429 : loss : 0.004825, loss_ce: 0.001544
2021-12-10 14:09:50,720 iteration 4430 : loss : 0.004860, loss_ce: 0.001979
2021-12-10 14:09:53,494 iteration 4431 : loss : 0.003738, loss_ce: 0.001522
2021-12-10 14:09:56,093 iteration 4432 : loss : 0.003524, loss_ce: 0.001301
2021-12-10 14:09:58,721 iteration 4433 : loss : 0.004499, loss_ce: 0.001732
2021-12-10 14:10:01,488 iteration 4434 : loss : 0.004645, loss_ce: 0.001554
2021-12-10 14:10:04,112 iteration 4435 : loss : 0.003448, loss_ce: 0.001429
2021-12-10 14:10:06,921 iteration 4436 : loss : 0.003034, loss_ce: 0.000828
2021-12-10 14:10:09,530 iteration 4437 : loss : 0.005524, loss_ce: 0.002641
 65%|█████████████████▌         | 261/400 [3:43:32<1:56:35, 50.32s/it]2021-12-10 14:10:12,304 iteration 4438 : loss : 0.003465, loss_ce: 0.001518
2021-12-10 14:10:14,894 iteration 4439 : loss : 0.003110, loss_ce: 0.001598
2021-12-10 14:10:17,510 iteration 4440 : loss : 0.004094, loss_ce: 0.000997
2021-12-10 14:10:20,232 iteration 4441 : loss : 0.003607, loss_ce: 0.002002
2021-12-10 14:10:22,996 iteration 4442 : loss : 0.003761, loss_ce: 0.001448
2021-12-10 14:10:25,595 iteration 4443 : loss : 0.003616, loss_ce: 0.001571
2021-12-10 14:10:28,288 iteration 4444 : loss : 0.002752, loss_ce: 0.001015
2021-12-10 14:10:30,889 iteration 4445 : loss : 0.003484, loss_ce: 0.001362
2021-12-10 14:10:33,518 iteration 4446 : loss : 0.004151, loss_ce: 0.001964
2021-12-10 14:10:36,123 iteration 4447 : loss : 0.003760, loss_ce: 0.001281
2021-12-10 14:10:38,847 iteration 4448 : loss : 0.005036, loss_ce: 0.001205
2021-12-10 14:10:41,472 iteration 4449 : loss : 0.003964, loss_ce: 0.001691
2021-12-10 14:10:44,081 iteration 4450 : loss : 0.003725, loss_ce: 0.001157
2021-12-10 14:10:46,819 iteration 4451 : loss : 0.003657, loss_ce: 0.001663
2021-12-10 14:10:49,526 iteration 4452 : loss : 0.003898, loss_ce: 0.001310
2021-12-10 14:10:52,144 iteration 4453 : loss : 0.003501, loss_ce: 0.001079
2021-12-10 14:10:54,892 iteration 4454 : loss : 0.003563, loss_ce: 0.001688
 66%|█████████████████▋         | 262/400 [3:44:17<1:52:19, 48.84s/it]2021-12-10 14:10:57,517 iteration 4455 : loss : 0.004010, loss_ce: 0.001359
2021-12-10 14:11:00,162 iteration 4456 : loss : 0.003473, loss_ce: 0.001391
2021-12-10 14:11:02,786 iteration 4457 : loss : 0.003966, loss_ce: 0.001607
2021-12-10 14:11:05,556 iteration 4458 : loss : 0.003709, loss_ce: 0.001352
2021-12-10 14:11:08,179 iteration 4459 : loss : 0.003366, loss_ce: 0.001224
2021-12-10 14:11:10,997 iteration 4460 : loss : 0.003595, loss_ce: 0.001626
2021-12-10 14:11:13,609 iteration 4461 : loss : 0.003252, loss_ce: 0.001352
2021-12-10 14:11:16,210 iteration 4462 : loss : 0.003109, loss_ce: 0.001238
2021-12-10 14:11:18,829 iteration 4463 : loss : 0.003686, loss_ce: 0.001300
2021-12-10 14:11:21,576 iteration 4464 : loss : 0.003255, loss_ce: 0.001348
2021-12-10 14:11:24,183 iteration 4465 : loss : 0.003994, loss_ce: 0.001845
2021-12-10 14:11:26,944 iteration 4466 : loss : 0.002903, loss_ce: 0.001296
2021-12-10 14:11:29,578 iteration 4467 : loss : 0.003041, loss_ce: 0.000948
2021-12-10 14:11:32,361 iteration 4468 : loss : 0.003509, loss_ce: 0.001243
2021-12-10 14:11:34,958 iteration 4469 : loss : 0.003218, loss_ce: 0.001411
2021-12-10 14:11:37,574 iteration 4470 : loss : 0.002686, loss_ce: 0.001120
2021-12-10 14:11:40,356 iteration 4471 : loss : 0.003978, loss_ce: 0.001646
 66%|█████████████████▊         | 263/400 [3:45:03<1:49:11, 47.82s/it]2021-12-10 14:11:43,168 iteration 4472 : loss : 0.003325, loss_ce: 0.001088
2021-12-10 14:11:45,780 iteration 4473 : loss : 0.003907, loss_ce: 0.001124
2021-12-10 14:11:48,410 iteration 4474 : loss : 0.002732, loss_ce: 0.001161
2021-12-10 14:11:51,196 iteration 4475 : loss : 0.003609, loss_ce: 0.001238
2021-12-10 14:11:53,795 iteration 4476 : loss : 0.003783, loss_ce: 0.001484
2021-12-10 14:11:56,403 iteration 4477 : loss : 0.003120, loss_ce: 0.001367
2021-12-10 14:11:59,133 iteration 4478 : loss : 0.004329, loss_ce: 0.001279
2021-12-10 14:12:01,835 iteration 4479 : loss : 0.004068, loss_ce: 0.001380
2021-12-10 14:12:04,519 iteration 4480 : loss : 0.004102, loss_ce: 0.001207
2021-12-10 14:12:07,097 iteration 4481 : loss : 0.003283, loss_ce: 0.001202
2021-12-10 14:12:09,717 iteration 4482 : loss : 0.003695, loss_ce: 0.001637
2021-12-10 14:12:12,505 iteration 4483 : loss : 0.003969, loss_ce: 0.001863
2021-12-10 14:12:15,097 iteration 4484 : loss : 0.003413, loss_ce: 0.001676
2021-12-10 14:12:17,718 iteration 4485 : loss : 0.003718, loss_ce: 0.001482
2021-12-10 14:12:20,371 iteration 4486 : loss : 0.004032, loss_ce: 0.001609
2021-12-10 14:12:22,994 iteration 4487 : loss : 0.002964, loss_ce: 0.001481
2021-12-10 14:12:25,735 iteration 4488 : loss : 0.003933, loss_ce: 0.001375
 66%|█████████████████▊         | 264/400 [3:45:48<1:46:44, 47.09s/it]2021-12-10 14:12:28,403 iteration 4489 : loss : 0.003127, loss_ce: 0.001213
2021-12-10 14:12:31,030 iteration 4490 : loss : 0.002587, loss_ce: 0.001001
2021-12-10 14:12:33,687 iteration 4491 : loss : 0.002980, loss_ce: 0.001369
2021-12-10 14:12:36,472 iteration 4492 : loss : 0.003129, loss_ce: 0.001131
2021-12-10 14:12:39,069 iteration 4493 : loss : 0.003505, loss_ce: 0.001873
2021-12-10 14:12:41,688 iteration 4494 : loss : 0.003745, loss_ce: 0.001429
2021-12-10 14:12:44,354 iteration 4495 : loss : 0.003997, loss_ce: 0.001530
2021-12-10 14:12:46,983 iteration 4496 : loss : 0.002895, loss_ce: 0.000928
2021-12-10 14:12:49,733 iteration 4497 : loss : 0.004506, loss_ce: 0.001271
2021-12-10 14:12:52,492 iteration 4498 : loss : 0.003029, loss_ce: 0.001179
2021-12-10 14:12:55,116 iteration 4499 : loss : 0.004090, loss_ce: 0.001886
2021-12-10 14:12:57,728 iteration 4500 : loss : 0.003243, loss_ce: 0.001547
2021-12-10 14:13:00,445 iteration 4501 : loss : 0.003271, loss_ce: 0.001160
2021-12-10 14:13:03,058 iteration 4502 : loss : 0.002884, loss_ce: 0.001425
2021-12-10 14:13:05,819 iteration 4503 : loss : 0.003691, loss_ce: 0.001073
2021-12-10 14:13:08,416 iteration 4504 : loss : 0.004738, loss_ce: 0.001735
2021-12-10 14:13:08,417 Training Data Eval:
2021-12-10 14:13:23,040   Average segmentation loss on training set: 0.0036
2021-12-10 14:13:23,040 Validation Data Eval:
2021-12-10 14:13:28,153   Average segmentation loss on validation set: 0.1257
2021-12-10 14:13:30,795 iteration 4505 : loss : 0.004448, loss_ce: 0.001869
 66%|█████████████████▉         | 265/400 [3:46:53<1:58:04, 52.48s/it]2021-12-10 14:13:33,518 iteration 4506 : loss : 0.003524, loss_ce: 0.001424
2021-12-10 14:13:36,151 iteration 4507 : loss : 0.003189, loss_ce: 0.001276
2021-12-10 14:13:38,937 iteration 4508 : loss : 0.003326, loss_ce: 0.001276
2021-12-10 14:13:41,546 iteration 4509 : loss : 0.003095, loss_ce: 0.000925
2021-12-10 14:13:44,163 iteration 4510 : loss : 0.002899, loss_ce: 0.000996
2021-12-10 14:13:46,788 iteration 4511 : loss : 0.003609, loss_ce: 0.001308
2021-12-10 14:13:49,580 iteration 4512 : loss : 0.003679, loss_ce: 0.001387
2021-12-10 14:13:52,176 iteration 4513 : loss : 0.003494, loss_ce: 0.001230
2021-12-10 14:13:54,833 iteration 4514 : loss : 0.003852, loss_ce: 0.001447
2021-12-10 14:13:57,459 iteration 4515 : loss : 0.003442, loss_ce: 0.001649
2021-12-10 14:14:00,061 iteration 4516 : loss : 0.003271, loss_ce: 0.001330
2021-12-10 14:14:02,818 iteration 4517 : loss : 0.007012, loss_ce: 0.000958
2021-12-10 14:14:05,441 iteration 4518 : loss : 0.003872, loss_ce: 0.001475
2021-12-10 14:14:08,076 iteration 4519 : loss : 0.005016, loss_ce: 0.002344
2021-12-10 14:14:10,803 iteration 4520 : loss : 0.005684, loss_ce: 0.001647
2021-12-10 14:14:13,407 iteration 4521 : loss : 0.004494, loss_ce: 0.002048
2021-12-10 14:14:16,030 iteration 4522 : loss : 0.003738, loss_ce: 0.001658
 66%|█████████████████▉         | 266/400 [3:47:38<1:52:21, 50.31s/it]2021-12-10 14:14:18,722 iteration 4523 : loss : 0.005065, loss_ce: 0.001449
2021-12-10 14:14:21,512 iteration 4524 : loss : 0.004272, loss_ce: 0.001199
2021-12-10 14:14:24,110 iteration 4525 : loss : 0.004245, loss_ce: 0.002054
2021-12-10 14:14:26,803 iteration 4526 : loss : 0.004819, loss_ce: 0.001740
2021-12-10 14:14:29,415 iteration 4527 : loss : 0.004439, loss_ce: 0.001320
2021-12-10 14:14:32,037 iteration 4528 : loss : 0.004325, loss_ce: 0.001760
2021-12-10 14:14:34,659 iteration 4529 : loss : 0.005494, loss_ce: 0.001814
2021-12-10 14:14:37,424 iteration 4530 : loss : 0.005518, loss_ce: 0.002085
2021-12-10 14:14:39,990 iteration 4531 : loss : 0.003564, loss_ce: 0.001320
2021-12-10 14:14:42,618 iteration 4532 : loss : 0.008741, loss_ce: 0.004033
2021-12-10 14:14:45,379 iteration 4533 : loss : 0.004591, loss_ce: 0.001642
2021-12-10 14:14:47,974 iteration 4534 : loss : 0.006243, loss_ce: 0.002446
2021-12-10 14:14:50,658 iteration 4535 : loss : 0.004305, loss_ce: 0.002168
2021-12-10 14:14:53,266 iteration 4536 : loss : 0.004423, loss_ce: 0.001457
2021-12-10 14:14:55,904 iteration 4537 : loss : 0.006898, loss_ce: 0.002165
2021-12-10 14:14:58,518 iteration 4538 : loss : 0.004020, loss_ce: 0.001596
2021-12-10 14:15:01,285 iteration 4539 : loss : 0.003417, loss_ce: 0.001379
 67%|██████████████████         | 267/400 [3:48:24<1:48:09, 48.79s/it]2021-12-10 14:15:03,911 iteration 4540 : loss : 0.005174, loss_ce: 0.001767
2021-12-10 14:15:06,533 iteration 4541 : loss : 0.004225, loss_ce: 0.001690
2021-12-10 14:15:09,152 iteration 4542 : loss : 0.003499, loss_ce: 0.001579
2021-12-10 14:15:11,868 iteration 4543 : loss : 0.004178, loss_ce: 0.001452
2021-12-10 14:15:14,488 iteration 4544 : loss : 0.003819, loss_ce: 0.001646
2021-12-10 14:15:17,090 iteration 4545 : loss : 0.005205, loss_ce: 0.001980
2021-12-10 14:15:19,711 iteration 4546 : loss : 0.003071, loss_ce: 0.001106
2021-12-10 14:15:22,481 iteration 4547 : loss : 0.003993, loss_ce: 0.001466
2021-12-10 14:15:25,112 iteration 4548 : loss : 0.004155, loss_ce: 0.001332
2021-12-10 14:15:27,817 iteration 4549 : loss : 0.004071, loss_ce: 0.001305
2021-12-10 14:15:30,555 iteration 4550 : loss : 0.002977, loss_ce: 0.001268
2021-12-10 14:15:33,146 iteration 4551 : loss : 0.003742, loss_ce: 0.001571
2021-12-10 14:15:35,759 iteration 4552 : loss : 0.004576, loss_ce: 0.001758
2021-12-10 14:15:38,359 iteration 4553 : loss : 0.004604, loss_ce: 0.002217
2021-12-10 14:15:40,980 iteration 4554 : loss : 0.004052, loss_ce: 0.001356
2021-12-10 14:15:43,741 iteration 4555 : loss : 0.004393, loss_ce: 0.001604
2021-12-10 14:15:46,372 iteration 4556 : loss : 0.004218, loss_ce: 0.001677
 67%|██████████████████         | 268/400 [3:49:09<1:44:53, 47.68s/it]2021-12-10 14:15:49,020 iteration 4557 : loss : 0.003130, loss_ce: 0.001004
2021-12-10 14:15:51,666 iteration 4558 : loss : 0.005379, loss_ce: 0.001288
2021-12-10 14:15:54,351 iteration 4559 : loss : 0.003809, loss_ce: 0.001631
2021-12-10 14:15:56,979 iteration 4560 : loss : 0.003928, loss_ce: 0.001496
2021-12-10 14:15:59,580 iteration 4561 : loss : 0.003570, loss_ce: 0.001103
2021-12-10 14:16:02,207 iteration 4562 : loss : 0.005633, loss_ce: 0.001498
2021-12-10 14:16:04,926 iteration 4563 : loss : 0.003345, loss_ce: 0.001494
2021-12-10 14:16:07,532 iteration 4564 : loss : 0.003893, loss_ce: 0.001566
2021-12-10 14:16:10,192 iteration 4565 : loss : 0.005573, loss_ce: 0.001609
2021-12-10 14:16:12,773 iteration 4566 : loss : 0.004439, loss_ce: 0.001807
2021-12-10 14:16:15,373 iteration 4567 : loss : 0.003970, loss_ce: 0.002251
2021-12-10 14:16:17,997 iteration 4568 : loss : 0.003456, loss_ce: 0.001442
2021-12-10 14:16:20,767 iteration 4569 : loss : 0.004464, loss_ce: 0.001506
2021-12-10 14:16:23,367 iteration 4570 : loss : 0.004325, loss_ce: 0.002057
2021-12-10 14:16:26,061 iteration 4571 : loss : 0.003571, loss_ce: 0.001278
2021-12-10 14:16:28,660 iteration 4572 : loss : 0.003368, loss_ce: 0.001427
2021-12-10 14:16:31,282 iteration 4573 : loss : 0.003053, loss_ce: 0.001398
 67%|██████████████████▏        | 269/400 [3:49:54<1:42:17, 46.85s/it]2021-12-10 14:16:34,020 iteration 4574 : loss : 0.004181, loss_ce: 0.001557
2021-12-10 14:16:36,624 iteration 4575 : loss : 0.003305, loss_ce: 0.001680
2021-12-10 14:16:39,295 iteration 4576 : loss : 0.004115, loss_ce: 0.001281
2021-12-10 14:16:41,898 iteration 4577 : loss : 0.004875, loss_ce: 0.001464
2021-12-10 14:16:44,503 iteration 4578 : loss : 0.004059, loss_ce: 0.001856
2021-12-10 14:16:47,110 iteration 4579 : loss : 0.005026, loss_ce: 0.001430
2021-12-10 14:16:49,734 iteration 4580 : loss : 0.003562, loss_ce: 0.001690
2021-12-10 14:16:52,365 iteration 4581 : loss : 0.003258, loss_ce: 0.001305
2021-12-10 14:16:55,085 iteration 4582 : loss : 0.004251, loss_ce: 0.001504
2021-12-10 14:16:57,708 iteration 4583 : loss : 0.004236, loss_ce: 0.001725
2021-12-10 14:17:00,477 iteration 4584 : loss : 0.004689, loss_ce: 0.002093
2021-12-10 14:17:03,070 iteration 4585 : loss : 0.004701, loss_ce: 0.001054
2021-12-10 14:17:05,666 iteration 4586 : loss : 0.003884, loss_ce: 0.001562
2021-12-10 14:17:08,288 iteration 4587 : loss : 0.003607, loss_ce: 0.001315
2021-12-10 14:17:10,932 iteration 4588 : loss : 0.004752, loss_ce: 0.001996
2021-12-10 14:17:13,562 iteration 4589 : loss : 0.004379, loss_ce: 0.002091
2021-12-10 14:17:13,563 Training Data Eval:
2021-12-10 14:17:28,322   Average segmentation loss on training set: 0.0038
2021-12-10 14:17:28,323 Validation Data Eval:
2021-12-10 14:17:33,401   Average segmentation loss on validation set: 0.1491
2021-12-10 14:17:36,023 iteration 4590 : loss : 0.004713, loss_ce: 0.002311
 68%|██████████████████▏        | 270/400 [3:50:58<1:53:07, 52.21s/it]2021-12-10 14:17:38,696 iteration 4591 : loss : 0.004478, loss_ce: 0.001700
2021-12-10 14:17:41,505 iteration 4592 : loss : 0.003982, loss_ce: 0.001173
2021-12-10 14:17:44,075 iteration 4593 : loss : 0.003660, loss_ce: 0.001412
2021-12-10 14:17:46,708 iteration 4594 : loss : 0.003772, loss_ce: 0.001326
2021-12-10 14:17:49,381 iteration 4595 : loss : 0.003289, loss_ce: 0.001305
2021-12-10 14:17:51,966 iteration 4596 : loss : 0.004927, loss_ce: 0.002139
2021-12-10 14:17:54,573 iteration 4597 : loss : 0.003461, loss_ce: 0.001584
2021-12-10 14:17:57,325 iteration 4598 : loss : 0.004806, loss_ce: 0.001201
2021-12-10 14:17:59,985 iteration 4599 : loss : 0.004257, loss_ce: 0.001027
2021-12-10 14:18:02,645 iteration 4600 : loss : 0.003811, loss_ce: 0.001686
2021-12-10 14:18:05,306 iteration 4601 : loss : 0.004141, loss_ce: 0.002131
2021-12-10 14:18:07,970 iteration 4602 : loss : 0.003693, loss_ce: 0.000982
2021-12-10 14:18:10,597 iteration 4603 : loss : 0.004098, loss_ce: 0.001455
2021-12-10 14:18:13,201 iteration 4604 : loss : 0.003050, loss_ce: 0.001412
2021-12-10 14:18:15,953 iteration 4605 : loss : 0.003460, loss_ce: 0.001540
2021-12-10 14:18:18,578 iteration 4606 : loss : 0.003791, loss_ce: 0.001514
2021-12-10 14:18:21,363 iteration 4607 : loss : 0.004517, loss_ce: 0.002078
 68%|██████████████████▎        | 271/400 [3:51:44<1:47:49, 50.15s/it]2021-12-10 14:18:24,122 iteration 4608 : loss : 0.003749, loss_ce: 0.001760
2021-12-10 14:18:26,724 iteration 4609 : loss : 0.003075, loss_ce: 0.001446
2021-12-10 14:18:29,367 iteration 4610 : loss : 0.003348, loss_ce: 0.001047
2021-12-10 14:18:31,983 iteration 4611 : loss : 0.003150, loss_ce: 0.001131
2021-12-10 14:18:34,735 iteration 4612 : loss : 0.003698, loss_ce: 0.001745
2021-12-10 14:18:37,336 iteration 4613 : loss : 0.003069, loss_ce: 0.001406
2021-12-10 14:18:40,080 iteration 4614 : loss : 0.004105, loss_ce: 0.001609
2021-12-10 14:18:42,684 iteration 4615 : loss : 0.003610, loss_ce: 0.001441
2021-12-10 14:18:45,484 iteration 4616 : loss : 0.002624, loss_ce: 0.000886
2021-12-10 14:18:48,084 iteration 4617 : loss : 0.003280, loss_ce: 0.001057
2021-12-10 14:18:50,859 iteration 4618 : loss : 0.003765, loss_ce: 0.001438
2021-12-10 14:18:53,459 iteration 4619 : loss : 0.003910, loss_ce: 0.001607
2021-12-10 14:18:56,117 iteration 4620 : loss : 0.003524, loss_ce: 0.001579
2021-12-10 14:18:58,764 iteration 4621 : loss : 0.004044, loss_ce: 0.001208
2021-12-10 14:19:01,387 iteration 4622 : loss : 0.003577, loss_ce: 0.001810
2021-12-10 14:19:04,171 iteration 4623 : loss : 0.003450, loss_ce: 0.001328
2021-12-10 14:19:06,774 iteration 4624 : loss : 0.002913, loss_ce: 0.001011
 68%|██████████████████▎        | 272/400 [3:52:29<1:43:57, 48.73s/it]2021-12-10 14:19:09,430 iteration 4625 : loss : 0.004128, loss_ce: 0.001829
2021-12-10 14:19:12,203 iteration 4626 : loss : 0.003884, loss_ce: 0.001380
2021-12-10 14:19:14,821 iteration 4627 : loss : 0.002693, loss_ce: 0.001151
2021-12-10 14:19:17,440 iteration 4628 : loss : 0.003189, loss_ce: 0.001370
2021-12-10 14:19:20,198 iteration 4629 : loss : 0.004524, loss_ce: 0.001452
2021-12-10 14:19:22,805 iteration 4630 : loss : 0.002994, loss_ce: 0.001182
2021-12-10 14:19:25,453 iteration 4631 : loss : 0.002891, loss_ce: 0.001159
2021-12-10 14:19:28,206 iteration 4632 : loss : 0.003337, loss_ce: 0.000991
2021-12-10 14:19:30,803 iteration 4633 : loss : 0.003277, loss_ce: 0.001546
2021-12-10 14:19:33,398 iteration 4634 : loss : 0.003848, loss_ce: 0.001779
2021-12-10 14:19:36,169 iteration 4635 : loss : 0.003223, loss_ce: 0.001450
2021-12-10 14:19:38,765 iteration 4636 : loss : 0.003576, loss_ce: 0.001220
2021-12-10 14:19:41,377 iteration 4637 : loss : 0.003040, loss_ce: 0.000958
2021-12-10 14:19:44,149 iteration 4638 : loss : 0.003226, loss_ce: 0.000765
2021-12-10 14:19:46,743 iteration 4639 : loss : 0.003285, loss_ce: 0.001277
2021-12-10 14:19:49,346 iteration 4640 : loss : 0.003224, loss_ce: 0.001350
2021-12-10 14:19:52,125 iteration 4641 : loss : 0.003494, loss_ce: 0.001289
 68%|██████████████████▍        | 273/400 [3:53:14<1:41:00, 47.72s/it]2021-12-10 14:19:54,759 iteration 4642 : loss : 0.003083, loss_ce: 0.001406
2021-12-10 14:19:57,526 iteration 4643 : loss : 0.002571, loss_ce: 0.000859
2021-12-10 14:20:00,118 iteration 4644 : loss : 0.002572, loss_ce: 0.001299
2021-12-10 14:20:02,737 iteration 4645 : loss : 0.004656, loss_ce: 0.001433
2021-12-10 14:20:05,504 iteration 4646 : loss : 0.003619, loss_ce: 0.001418
2021-12-10 14:20:08,131 iteration 4647 : loss : 0.004310, loss_ce: 0.001344
2021-12-10 14:20:10,835 iteration 4648 : loss : 0.003376, loss_ce: 0.001103
2021-12-10 14:20:13,516 iteration 4649 : loss : 0.002796, loss_ce: 0.001067
2021-12-10 14:20:16,131 iteration 4650 : loss : 0.004288, loss_ce: 0.001748
2021-12-10 14:20:18,916 iteration 4651 : loss : 0.003022, loss_ce: 0.001359
2021-12-10 14:20:21,525 iteration 4652 : loss : 0.003284, loss_ce: 0.001393
2021-12-10 14:20:24,089 iteration 4653 : loss : 0.004666, loss_ce: 0.001472
2021-12-10 14:20:26,842 iteration 4654 : loss : 0.003888, loss_ce: 0.001746
2021-12-10 14:20:29,442 iteration 4655 : loss : 0.004317, loss_ce: 0.001829
2021-12-10 14:20:32,054 iteration 4656 : loss : 0.005010, loss_ce: 0.001738
2021-12-10 14:20:34,811 iteration 4657 : loss : 0.003826, loss_ce: 0.002204
2021-12-10 14:20:37,435 iteration 4658 : loss : 0.004013, loss_ce: 0.001593
 68%|██████████████████▍        | 274/400 [3:54:00<1:38:41, 47.00s/it]2021-12-10 14:20:40,224 iteration 4659 : loss : 0.003384, loss_ce: 0.001676
2021-12-10 14:20:42,847 iteration 4660 : loss : 0.002931, loss_ce: 0.000944
2021-12-10 14:20:45,467 iteration 4661 : loss : 0.003960, loss_ce: 0.002254
2021-12-10 14:20:48,249 iteration 4662 : loss : 0.003070, loss_ce: 0.001341
2021-12-10 14:20:50,857 iteration 4663 : loss : 0.004041, loss_ce: 0.001267
2021-12-10 14:20:53,547 iteration 4664 : loss : 0.004287, loss_ce: 0.001513
2021-12-10 14:20:56,148 iteration 4665 : loss : 0.004193, loss_ce: 0.001645
2021-12-10 14:20:58,775 iteration 4666 : loss : 0.003936, loss_ce: 0.001679
2021-12-10 14:21:01,529 iteration 4667 : loss : 0.003750, loss_ce: 0.001638
2021-12-10 14:21:04,123 iteration 4668 : loss : 0.003986, loss_ce: 0.001093
2021-12-10 14:21:06,850 iteration 4669 : loss : 0.004194, loss_ce: 0.001806
2021-12-10 14:21:09,445 iteration 4670 : loss : 0.004358, loss_ce: 0.002146
2021-12-10 14:21:12,213 iteration 4671 : loss : 0.004361, loss_ce: 0.001617
2021-12-10 14:21:14,814 iteration 4672 : loss : 0.003740, loss_ce: 0.001458
2021-12-10 14:21:17,510 iteration 4673 : loss : 0.003355, loss_ce: 0.001511
2021-12-10 14:21:20,202 iteration 4674 : loss : 0.003732, loss_ce: 0.001373
2021-12-10 14:21:20,202 Training Data Eval:
2021-12-10 14:21:34,972   Average segmentation loss on training set: 0.0036
2021-12-10 14:21:34,972 Validation Data Eval:
2021-12-10 14:21:40,060   Average segmentation loss on validation set: 0.1252
2021-12-10 14:21:42,658 iteration 4675 : loss : 0.004119, loss_ce: 0.001814
 69%|██████████████████▌        | 275/400 [3:55:05<1:49:18, 52.46s/it]2021-12-10 14:21:45,363 iteration 4676 : loss : 0.003676, loss_ce: 0.001572
2021-12-10 14:21:47,975 iteration 4677 : loss : 0.003877, loss_ce: 0.001587
2021-12-10 14:21:50,629 iteration 4678 : loss : 0.003407, loss_ce: 0.001556
2021-12-10 14:21:53,275 iteration 4679 : loss : 0.003996, loss_ce: 0.001301
2021-12-10 14:21:55,895 iteration 4680 : loss : 0.003255, loss_ce: 0.001022
2021-12-10 14:21:58,657 iteration 4681 : loss : 0.004324, loss_ce: 0.001448
2021-12-10 14:22:01,255 iteration 4682 : loss : 0.003742, loss_ce: 0.001278
2021-12-10 14:22:03,874 iteration 4683 : loss : 0.003789, loss_ce: 0.001989
2021-12-10 14:22:06,477 iteration 4684 : loss : 0.003866, loss_ce: 0.000887
2021-12-10 14:22:09,228 iteration 4685 : loss : 0.003696, loss_ce: 0.001712
2021-12-10 14:22:11,850 iteration 4686 : loss : 0.004152, loss_ce: 0.001652
2021-12-10 14:22:14,556 iteration 4687 : loss : 0.004451, loss_ce: 0.001543
2021-12-10 14:22:17,221 iteration 4688 : loss : 0.004403, loss_ce: 0.001848
2021-12-10 14:22:19,845 iteration 4689 : loss : 0.003926, loss_ce: 0.001634
2021-12-10 14:22:22,588 iteration 4690 : loss : 0.003909, loss_ce: 0.001690
2021-12-10 14:22:25,285 iteration 4691 : loss : 0.003867, loss_ce: 0.001894
2021-12-10 14:22:27,895 iteration 4692 : loss : 0.004276, loss_ce: 0.001835
 69%|██████████████████▋        | 276/400 [3:55:50<1:43:56, 50.30s/it]2021-12-10 14:22:30,565 iteration 4693 : loss : 0.003283, loss_ce: 0.001573
2021-12-10 14:22:33,185 iteration 4694 : loss : 0.003833, loss_ce: 0.001531
2021-12-10 14:22:35,841 iteration 4695 : loss : 0.003599, loss_ce: 0.001165
2021-12-10 14:22:38,497 iteration 4696 : loss : 0.004166, loss_ce: 0.001717
2021-12-10 14:22:41,276 iteration 4697 : loss : 0.003453, loss_ce: 0.001721
2021-12-10 14:22:43,912 iteration 4698 : loss : 0.004272, loss_ce: 0.001144
2021-12-10 14:22:46,674 iteration 4699 : loss : 0.003628, loss_ce: 0.001477
2021-12-10 14:22:49,273 iteration 4700 : loss : 0.004134, loss_ce: 0.001342
2021-12-10 14:22:51,975 iteration 4701 : loss : 0.003805, loss_ce: 0.001890
2021-12-10 14:22:54,689 iteration 4702 : loss : 0.003324, loss_ce: 0.001372
2021-12-10 14:22:57,313 iteration 4703 : loss : 0.003810, loss_ce: 0.001834
2021-12-10 14:22:59,969 iteration 4704 : loss : 0.002757, loss_ce: 0.001434
2021-12-10 14:23:02,621 iteration 4705 : loss : 0.003955, loss_ce: 0.001729
2021-12-10 14:23:05,274 iteration 4706 : loss : 0.003624, loss_ce: 0.001307
2021-12-10 14:23:07,908 iteration 4707 : loss : 0.005174, loss_ce: 0.001469
2021-12-10 14:23:10,649 iteration 4708 : loss : 0.004382, loss_ce: 0.001078
2021-12-10 14:23:13,254 iteration 4709 : loss : 0.003231, loss_ce: 0.000934
 69%|██████████████████▋        | 277/400 [3:56:36<1:40:04, 48.81s/it]2021-12-10 14:23:16,083 iteration 4710 : loss : 0.003208, loss_ce: 0.001474
2021-12-10 14:23:18,707 iteration 4711 : loss : 0.004045, loss_ce: 0.001950
2021-12-10 14:23:21,336 iteration 4712 : loss : 0.003775, loss_ce: 0.001289
2021-12-10 14:23:24,111 iteration 4713 : loss : 0.003480, loss_ce: 0.001046
2021-12-10 14:23:26,699 iteration 4714 : loss : 0.003552, loss_ce: 0.001136
2021-12-10 14:23:29,318 iteration 4715 : loss : 0.002863, loss_ce: 0.001215
2021-12-10 14:23:32,092 iteration 4716 : loss : 0.003598, loss_ce: 0.000980
2021-12-10 14:23:34,691 iteration 4717 : loss : 0.003349, loss_ce: 0.001187
2021-12-10 14:23:37,430 iteration 4718 : loss : 0.002968, loss_ce: 0.000851
2021-12-10 14:23:40,028 iteration 4719 : loss : 0.004470, loss_ce: 0.001099
2021-12-10 14:23:42,723 iteration 4720 : loss : 0.003333, loss_ce: 0.001276
2021-12-10 14:23:45,442 iteration 4721 : loss : 0.003038, loss_ce: 0.001214
2021-12-10 14:23:48,072 iteration 4722 : loss : 0.003210, loss_ce: 0.001287
2021-12-10 14:23:50,707 iteration 4723 : loss : 0.003049, loss_ce: 0.001399
2021-12-10 14:23:53,365 iteration 4724 : loss : 0.003527, loss_ce: 0.001576
2021-12-10 14:23:55,997 iteration 4725 : loss : 0.003340, loss_ce: 0.001531
2021-12-10 14:23:58,755 iteration 4726 : loss : 0.003175, loss_ce: 0.001294
 70%|██████████████████▊        | 278/400 [3:57:21<1:37:14, 47.82s/it]2021-12-10 14:24:01,547 iteration 4727 : loss : 0.003114, loss_ce: 0.001598
2021-12-10 14:24:04,140 iteration 4728 : loss : 0.003452, loss_ce: 0.001256
2021-12-10 14:24:06,760 iteration 4729 : loss : 0.004095, loss_ce: 0.001506
2021-12-10 14:24:09,529 iteration 4730 : loss : 0.003760, loss_ce: 0.001012
2021-12-10 14:24:12,136 iteration 4731 : loss : 0.003278, loss_ce: 0.001753
2021-12-10 14:24:14,885 iteration 4732 : loss : 0.003246, loss_ce: 0.001354
2021-12-10 14:24:17,483 iteration 4733 : loss : 0.003520, loss_ce: 0.001552
2021-12-10 14:24:20,103 iteration 4734 : loss : 0.003728, loss_ce: 0.001588
2021-12-10 14:24:22,729 iteration 4735 : loss : 0.002939, loss_ce: 0.001370
2021-12-10 14:24:25,439 iteration 4736 : loss : 0.003680, loss_ce: 0.001586
2021-12-10 14:24:28,208 iteration 4737 : loss : 0.003929, loss_ce: 0.000816
2021-12-10 14:24:30,805 iteration 4738 : loss : 0.003974, loss_ce: 0.001583
2021-12-10 14:24:33,447 iteration 4739 : loss : 0.003555, loss_ce: 0.001105
2021-12-10 14:24:36,068 iteration 4740 : loss : 0.003321, loss_ce: 0.000927
2021-12-10 14:24:38,835 iteration 4741 : loss : 0.002755, loss_ce: 0.001204
2021-12-10 14:24:41,469 iteration 4742 : loss : 0.002684, loss_ce: 0.000906
2021-12-10 14:24:44,235 iteration 4743 : loss : 0.003586, loss_ce: 0.001398
 70%|██████████████████▊        | 279/400 [3:58:07<1:35:01, 47.12s/it]2021-12-10 14:24:46,954 iteration 4744 : loss : 0.002976, loss_ce: 0.001035
2021-12-10 14:24:49,591 iteration 4745 : loss : 0.003690, loss_ce: 0.001401
2021-12-10 14:24:52,212 iteration 4746 : loss : 0.003252, loss_ce: 0.001080
2021-12-10 14:24:54,994 iteration 4747 : loss : 0.003025, loss_ce: 0.001142
2021-12-10 14:24:57,600 iteration 4748 : loss : 0.003589, loss_ce: 0.001646
2021-12-10 14:25:00,219 iteration 4749 : loss : 0.003277, loss_ce: 0.001426
2021-12-10 14:25:02,991 iteration 4750 : loss : 0.002160, loss_ce: 0.000461
2021-12-10 14:25:05,596 iteration 4751 : loss : 0.003737, loss_ce: 0.001620
2021-12-10 14:25:08,199 iteration 4752 : loss : 0.003041, loss_ce: 0.001368
2021-12-10 14:25:10,864 iteration 4753 : loss : 0.002796, loss_ce: 0.001102
2021-12-10 14:25:13,526 iteration 4754 : loss : 0.003207, loss_ce: 0.001285
2021-12-10 14:25:16,305 iteration 4755 : loss : 0.003418, loss_ce: 0.001482
2021-12-10 14:25:18,896 iteration 4756 : loss : 0.003311, loss_ce: 0.001171
2021-12-10 14:25:21,623 iteration 4757 : loss : 0.004367, loss_ce: 0.002082
2021-12-10 14:25:24,227 iteration 4758 : loss : 0.003440, loss_ce: 0.001018
2021-12-10 14:25:26,848 iteration 4759 : loss : 0.004692, loss_ce: 0.001554
2021-12-10 14:25:26,848 Training Data Eval:
2021-12-10 14:25:41,657   Average segmentation loss on training set: 0.0029
2021-12-10 14:25:41,658 Validation Data Eval:
2021-12-10 14:25:46,850   Average segmentation loss on validation set: 0.1302
2021-12-10 14:25:49,476 iteration 4760 : loss : 0.003149, loss_ce: 0.001428
 70%|██████████████████▉        | 280/400 [3:59:12<1:45:06, 52.55s/it]2021-12-10 14:25:52,100 iteration 4761 : loss : 0.003121, loss_ce: 0.001180
2021-12-10 14:25:54,921 iteration 4762 : loss : 0.002665, loss_ce: 0.001040
2021-12-10 14:25:57,526 iteration 4763 : loss : 0.003105, loss_ce: 0.001204
2021-12-10 14:26:00,198 iteration 4764 : loss : 0.002691, loss_ce: 0.001083
2021-12-10 14:26:02,805 iteration 4765 : loss : 0.002718, loss_ce: 0.000986
2021-12-10 14:26:05,427 iteration 4766 : loss : 0.002123, loss_ce: 0.000751
2021-12-10 14:26:08,192 iteration 4767 : loss : 0.003175, loss_ce: 0.001571
2021-12-10 14:26:10,827 iteration 4768 : loss : 0.003132, loss_ce: 0.001437
2021-12-10 14:26:13,550 iteration 4769 : loss : 0.003482, loss_ce: 0.001264
2021-12-10 14:26:16,146 iteration 4770 : loss : 0.003156, loss_ce: 0.001345
2021-12-10 14:26:18,773 iteration 4771 : loss : 0.003288, loss_ce: 0.001097
2021-12-10 14:26:21,498 iteration 4772 : loss : 0.002811, loss_ce: 0.001188
2021-12-10 14:26:24,122 iteration 4773 : loss : 0.003046, loss_ce: 0.001388
2021-12-10 14:26:26,862 iteration 4774 : loss : 0.003280, loss_ce: 0.001236
2021-12-10 14:26:29,436 iteration 4775 : loss : 0.003618, loss_ce: 0.001135
2021-12-10 14:26:32,139 iteration 4776 : loss : 0.003282, loss_ce: 0.001658
2021-12-10 14:26:34,752 iteration 4777 : loss : 0.003354, loss_ce: 0.001638
 70%|██████████████████▉        | 281/400 [3:59:57<1:39:54, 50.37s/it]2021-12-10 14:26:37,468 iteration 4778 : loss : 0.002324, loss_ce: 0.001086
2021-12-10 14:26:40,063 iteration 4779 : loss : 0.002797, loss_ce: 0.001285
2021-12-10 14:26:42,687 iteration 4780 : loss : 0.003212, loss_ce: 0.001071
2021-12-10 14:26:45,431 iteration 4781 : loss : 0.004167, loss_ce: 0.001033
2021-12-10 14:26:48,162 iteration 4782 : loss : 0.002818, loss_ce: 0.001211
2021-12-10 14:26:50,829 iteration 4783 : loss : 0.003161, loss_ce: 0.000974
2021-12-10 14:26:53,490 iteration 4784 : loss : 0.003655, loss_ce: 0.001623
2021-12-10 14:26:56,117 iteration 4785 : loss : 0.003439, loss_ce: 0.001663
2021-12-10 14:26:58,721 iteration 4786 : loss : 0.003376, loss_ce: 0.001510
2021-12-10 14:27:01,478 iteration 4787 : loss : 0.003409, loss_ce: 0.001343
2021-12-10 14:27:04,048 iteration 4788 : loss : 0.002860, loss_ce: 0.001172
2021-12-10 14:27:06,852 iteration 4789 : loss : 0.003544, loss_ce: 0.001321
2021-12-10 14:27:09,461 iteration 4790 : loss : 0.003045, loss_ce: 0.001178
2021-12-10 14:27:12,089 iteration 4791 : loss : 0.003422, loss_ce: 0.001387
2021-12-10 14:27:14,727 iteration 4792 : loss : 0.003124, loss_ce: 0.001349
2021-12-10 14:27:17,345 iteration 4793 : loss : 0.002595, loss_ce: 0.001406
2021-12-10 14:27:19,972 iteration 4794 : loss : 0.002656, loss_ce: 0.000918
 70%|███████████████████        | 282/400 [4:00:42<1:36:01, 48.83s/it]2021-12-10 14:27:22,662 iteration 4795 : loss : 0.002664, loss_ce: 0.000827
2021-12-10 14:27:25,283 iteration 4796 : loss : 0.003615, loss_ce: 0.001850
2021-12-10 14:27:27,910 iteration 4797 : loss : 0.002726, loss_ce: 0.000815
2021-12-10 14:27:30,619 iteration 4798 : loss : 0.003119, loss_ce: 0.000939
2021-12-10 14:27:33,382 iteration 4799 : loss : 0.002593, loss_ce: 0.001035
2021-12-10 14:27:36,014 iteration 4800 : loss : 0.003056, loss_ce: 0.001107
2021-12-10 14:27:38,616 iteration 4801 : loss : 0.003876, loss_ce: 0.002139
2021-12-10 14:27:41,380 iteration 4802 : loss : 0.003023, loss_ce: 0.001664
2021-12-10 14:27:43,979 iteration 4803 : loss : 0.002784, loss_ce: 0.001158
2021-12-10 14:27:46,581 iteration 4804 : loss : 0.003500, loss_ce: 0.001451
2021-12-10 14:27:49,401 iteration 4805 : loss : 0.003883, loss_ce: 0.001320
2021-12-10 14:27:52,021 iteration 4806 : loss : 0.002814, loss_ce: 0.001132
2021-12-10 14:27:54,614 iteration 4807 : loss : 0.003736, loss_ce: 0.001469
2021-12-10 14:27:57,330 iteration 4808 : loss : 0.004027, loss_ce: 0.001288
2021-12-10 14:27:59,984 iteration 4809 : loss : 0.003318, loss_ce: 0.001149
2021-12-10 14:28:02,621 iteration 4810 : loss : 0.003071, loss_ce: 0.001076
2021-12-10 14:28:05,329 iteration 4811 : loss : 0.003154, loss_ce: 0.001274
 71%|███████████████████        | 283/400 [4:01:28<1:33:10, 47.79s/it]2021-12-10 14:28:08,103 iteration 4812 : loss : 0.003814, loss_ce: 0.000868
2021-12-10 14:28:10,705 iteration 4813 : loss : 0.003632, loss_ce: 0.001506
2021-12-10 14:28:13,444 iteration 4814 : loss : 0.003129, loss_ce: 0.001048
2021-12-10 14:28:16,041 iteration 4815 : loss : 0.002958, loss_ce: 0.001375
2021-12-10 14:28:18,649 iteration 4816 : loss : 0.003067, loss_ce: 0.001473
2021-12-10 14:28:21,260 iteration 4817 : loss : 0.003238, loss_ce: 0.000885
2021-12-10 14:28:23,879 iteration 4818 : loss : 0.003626, loss_ce: 0.001936
2021-12-10 14:28:26,555 iteration 4819 : loss : 0.003623, loss_ce: 0.001328
2021-12-10 14:28:29,158 iteration 4820 : loss : 0.004256, loss_ce: 0.001460
2021-12-10 14:28:31,886 iteration 4821 : loss : 0.003343, loss_ce: 0.001439
2021-12-10 14:28:34,484 iteration 4822 : loss : 0.002863, loss_ce: 0.001251
2021-12-10 14:28:37,058 iteration 4823 : loss : 0.002835, loss_ce: 0.000986
2021-12-10 14:28:39,677 iteration 4824 : loss : 0.003713, loss_ce: 0.001535
2021-12-10 14:28:42,443 iteration 4825 : loss : 0.003406, loss_ce: 0.001026
2021-12-10 14:28:45,045 iteration 4826 : loss : 0.003564, loss_ce: 0.001697
2021-12-10 14:28:47,668 iteration 4827 : loss : 0.003066, loss_ce: 0.001395
2021-12-10 14:28:50,272 iteration 4828 : loss : 0.002892, loss_ce: 0.001288
 71%|███████████████████▏       | 284/400 [4:02:13<1:30:44, 46.93s/it]2021-12-10 14:28:52,955 iteration 4829 : loss : 0.003082, loss_ce: 0.001191
2021-12-10 14:28:55,592 iteration 4830 : loss : 0.002828, loss_ce: 0.001158
2021-12-10 14:28:58,228 iteration 4831 : loss : 0.003170, loss_ce: 0.001561
2021-12-10 14:29:00,834 iteration 4832 : loss : 0.002951, loss_ce: 0.001219
2021-12-10 14:29:03,466 iteration 4833 : loss : 0.003456, loss_ce: 0.001100
2021-12-10 14:29:06,106 iteration 4834 : loss : 0.002432, loss_ce: 0.000915
2021-12-10 14:29:08,732 iteration 4835 : loss : 0.002716, loss_ce: 0.000794
2021-12-10 14:29:11,360 iteration 4836 : loss : 0.003391, loss_ce: 0.001565
2021-12-10 14:29:14,123 iteration 4837 : loss : 0.002563, loss_ce: 0.001190
2021-12-10 14:29:16,720 iteration 4838 : loss : 0.002884, loss_ce: 0.000772
2021-12-10 14:29:19,320 iteration 4839 : loss : 0.003339, loss_ce: 0.001501
2021-12-10 14:29:21,980 iteration 4840 : loss : 0.003549, loss_ce: 0.001081
2021-12-10 14:29:24,610 iteration 4841 : loss : 0.003631, loss_ce: 0.001451
2021-12-10 14:29:27,319 iteration 4842 : loss : 0.003224, loss_ce: 0.001145
2021-12-10 14:29:29,939 iteration 4843 : loss : 0.003239, loss_ce: 0.001343
2021-12-10 14:29:32,649 iteration 4844 : loss : 0.003050, loss_ce: 0.001141
2021-12-10 14:29:32,649 Training Data Eval:
2021-12-10 14:29:47,285   Average segmentation loss on training set: 0.0029
2021-12-10 14:29:47,285 Validation Data Eval:
2021-12-10 14:29:52,469   Average segmentation loss on validation set: 0.1239
2021-12-10 14:29:55,137 iteration 4845 : loss : 0.003011, loss_ce: 0.001363
 71%|███████████████████▏       | 285/400 [4:03:17<1:40:15, 52.31s/it]2021-12-10 14:29:57,872 iteration 4846 : loss : 0.002923, loss_ce: 0.001552
2021-12-10 14:30:00,563 iteration 4847 : loss : 0.004296, loss_ce: 0.001366
2021-12-10 14:30:03,158 iteration 4848 : loss : 0.003294, loss_ce: 0.001482
2021-12-10 14:30:05,872 iteration 4849 : loss : 0.004117, loss_ce: 0.001833
2021-12-10 14:30:08,469 iteration 4850 : loss : 0.004404, loss_ce: 0.001508
2021-12-10 14:30:11,086 iteration 4851 : loss : 0.003352, loss_ce: 0.001146
2021-12-10 14:30:13,705 iteration 4852 : loss : 0.002779, loss_ce: 0.001242
2021-12-10 14:30:16,434 iteration 4853 : loss : 0.002878, loss_ce: 0.001170
2021-12-10 14:30:19,009 iteration 4854 : loss : 0.002557, loss_ce: 0.000816
2021-12-10 14:30:21,754 iteration 4855 : loss : 0.003511, loss_ce: 0.001555
2021-12-10 14:30:24,337 iteration 4856 : loss : 0.004235, loss_ce: 0.001410
2021-12-10 14:30:27,101 iteration 4857 : loss : 0.003207, loss_ce: 0.001306
2021-12-10 14:30:29,718 iteration 4858 : loss : 0.003058, loss_ce: 0.001434
2021-12-10 14:30:32,322 iteration 4859 : loss : 0.003932, loss_ce: 0.000941
2021-12-10 14:30:34,931 iteration 4860 : loss : 0.003598, loss_ce: 0.001686
2021-12-10 14:30:37,585 iteration 4861 : loss : 0.006485, loss_ce: 0.001621
2021-12-10 14:30:40,205 iteration 4862 : loss : 0.002990, loss_ce: 0.000987
 72%|███████████████████▎       | 286/400 [4:04:03<1:35:15, 50.14s/it]2021-12-10 14:30:42,864 iteration 4863 : loss : 0.003735, loss_ce: 0.001611
2021-12-10 14:30:45,638 iteration 4864 : loss : 0.006286, loss_ce: 0.001978
2021-12-10 14:30:48,235 iteration 4865 : loss : 0.004386, loss_ce: 0.002023
2021-12-10 14:30:50,959 iteration 4866 : loss : 0.006019, loss_ce: 0.002226
2021-12-10 14:30:53,550 iteration 4867 : loss : 0.005565, loss_ce: 0.001908
2021-12-10 14:30:56,126 iteration 4868 : loss : 0.006448, loss_ce: 0.001768
2021-12-10 14:30:58,749 iteration 4869 : loss : 0.005178, loss_ce: 0.001595
2021-12-10 14:31:01,370 iteration 4870 : loss : 0.005626, loss_ce: 0.002366
2021-12-10 14:31:04,001 iteration 4871 : loss : 0.005059, loss_ce: 0.002187
2021-12-10 14:31:06,617 iteration 4872 : loss : 0.005695, loss_ce: 0.002342
2021-12-10 14:31:09,337 iteration 4873 : loss : 0.005568, loss_ce: 0.002464
2021-12-10 14:31:12,046 iteration 4874 : loss : 0.004588, loss_ce: 0.001316
2021-12-10 14:31:14,647 iteration 4875 : loss : 0.004881, loss_ce: 0.001931
2021-12-10 14:31:17,224 iteration 4876 : loss : 0.004480, loss_ce: 0.001583
2021-12-10 14:31:19,970 iteration 4877 : loss : 0.005169, loss_ce: 0.002217
2021-12-10 14:31:22,665 iteration 4878 : loss : 0.004380, loss_ce: 0.001674
2021-12-10 14:31:25,238 iteration 4879 : loss : 0.004215, loss_ce: 0.002023
 72%|███████████████████▎       | 287/400 [4:04:48<1:31:32, 48.61s/it]2021-12-10 14:31:28,066 iteration 4880 : loss : 0.004672, loss_ce: 0.002007
2021-12-10 14:31:30,689 iteration 4881 : loss : 0.004034, loss_ce: 0.001596
2021-12-10 14:31:33,324 iteration 4882 : loss : 0.003803, loss_ce: 0.001626
2021-12-10 14:31:35,946 iteration 4883 : loss : 0.003988, loss_ce: 0.001726
2021-12-10 14:31:38,569 iteration 4884 : loss : 0.004318, loss_ce: 0.001375
2021-12-10 14:31:41,173 iteration 4885 : loss : 0.003174, loss_ce: 0.001144
2021-12-10 14:31:43,913 iteration 4886 : loss : 0.004487, loss_ce: 0.001541
2021-12-10 14:31:46,616 iteration 4887 : loss : 0.004175, loss_ce: 0.001961
2021-12-10 14:31:49,198 iteration 4888 : loss : 0.003104, loss_ce: 0.001338
2021-12-10 14:31:51,912 iteration 4889 : loss : 0.004363, loss_ce: 0.000859
2021-12-10 14:31:54,573 iteration 4890 : loss : 0.004647, loss_ce: 0.002033
2021-12-10 14:31:57,193 iteration 4891 : loss : 0.004053, loss_ce: 0.001458
2021-12-10 14:31:59,890 iteration 4892 : loss : 0.003275, loss_ce: 0.001293
2021-12-10 14:32:02,514 iteration 4893 : loss : 0.003663, loss_ce: 0.001466
2021-12-10 14:32:05,136 iteration 4894 : loss : 0.004062, loss_ce: 0.001157
2021-12-10 14:32:07,747 iteration 4895 : loss : 0.003842, loss_ce: 0.001718
2021-12-10 14:32:10,512 iteration 4896 : loss : 0.003993, loss_ce: 0.001479
 72%|███████████████████▍       | 288/400 [4:05:33<1:28:51, 47.61s/it]2021-12-10 14:32:13,147 iteration 4897 : loss : 0.003761, loss_ce: 0.001597
2021-12-10 14:32:15,811 iteration 4898 : loss : 0.002941, loss_ce: 0.000869
2021-12-10 14:32:18,434 iteration 4899 : loss : 0.002543, loss_ce: 0.000754
2021-12-10 14:32:21,072 iteration 4900 : loss : 0.004078, loss_ce: 0.001803
2021-12-10 14:32:23,676 iteration 4901 : loss : 0.003261, loss_ce: 0.001345
2021-12-10 14:32:26,435 iteration 4902 : loss : 0.003759, loss_ce: 0.001248
2021-12-10 14:32:29,038 iteration 4903 : loss : 0.004326, loss_ce: 0.001745
2021-12-10 14:32:31,652 iteration 4904 : loss : 0.004558, loss_ce: 0.001667
2021-12-10 14:32:34,267 iteration 4905 : loss : 0.003813, loss_ce: 0.001495
2021-12-10 14:32:37,038 iteration 4906 : loss : 0.004593, loss_ce: 0.002233
2021-12-10 14:32:39,629 iteration 4907 : loss : 0.003824, loss_ce: 0.001052
2021-12-10 14:32:42,246 iteration 4908 : loss : 0.003323, loss_ce: 0.001421
2021-12-10 14:32:45,017 iteration 4909 : loss : 0.004172, loss_ce: 0.001675
2021-12-10 14:32:47,612 iteration 4910 : loss : 0.003365, loss_ce: 0.001453
2021-12-10 14:32:50,228 iteration 4911 : loss : 0.002723, loss_ce: 0.000814
2021-12-10 14:32:52,891 iteration 4912 : loss : 0.003990, loss_ce: 0.001972
2021-12-10 14:32:55,554 iteration 4913 : loss : 0.003468, loss_ce: 0.001196
 72%|███████████████████▌       | 289/400 [4:06:18<1:26:38, 46.84s/it]2021-12-10 14:32:58,341 iteration 4914 : loss : 0.003164, loss_ce: 0.001134
2021-12-10 14:33:00,935 iteration 4915 : loss : 0.003651, loss_ce: 0.001234
2021-12-10 14:33:03,517 iteration 4916 : loss : 0.002881, loss_ce: 0.001261
2021-12-10 14:33:06,305 iteration 4917 : loss : 0.003389, loss_ce: 0.001186
2021-12-10 14:33:08,904 iteration 4918 : loss : 0.003834, loss_ce: 0.001501
2021-12-10 14:33:11,531 iteration 4919 : loss : 0.003196, loss_ce: 0.001547
2021-12-10 14:33:14,245 iteration 4920 : loss : 0.004458, loss_ce: 0.001596
2021-12-10 14:33:16,856 iteration 4921 : loss : 0.004292, loss_ce: 0.001879
2021-12-10 14:33:19,479 iteration 4922 : loss : 0.004156, loss_ce: 0.001851
2021-12-10 14:33:22,225 iteration 4923 : loss : 0.003279, loss_ce: 0.001236
2021-12-10 14:33:24,822 iteration 4924 : loss : 0.002736, loss_ce: 0.001078
2021-12-10 14:33:27,440 iteration 4925 : loss : 0.002809, loss_ce: 0.000967
2021-12-10 14:33:30,069 iteration 4926 : loss : 0.003183, loss_ce: 0.001151
2021-12-10 14:33:32,836 iteration 4927 : loss : 0.004425, loss_ce: 0.001278
2021-12-10 14:33:35,421 iteration 4928 : loss : 0.002780, loss_ce: 0.001385
2021-12-10 14:33:38,011 iteration 4929 : loss : 0.003349, loss_ce: 0.001400
2021-12-10 14:33:38,011 Training Data Eval:
2021-12-10 14:33:52,832   Average segmentation loss on training set: 0.0029
2021-12-10 14:33:52,832 Validation Data Eval:
2021-12-10 14:33:57,836   Average segmentation loss on validation set: 0.1353
2021-12-10 14:34:00,600 iteration 4930 : loss : 0.003035, loss_ce: 0.001274
 72%|███████████████████▌       | 290/400 [4:07:23<1:35:53, 52.30s/it]2021-12-10 14:34:03,261 iteration 4931 : loss : 0.003041, loss_ce: 0.000929
2021-12-10 14:34:05,967 iteration 4932 : loss : 0.003232, loss_ce: 0.001505
2021-12-10 14:34:08,584 iteration 4933 : loss : 0.003520, loss_ce: 0.001680
2021-12-10 14:34:11,245 iteration 4934 : loss : 0.002884, loss_ce: 0.000854
2021-12-10 14:34:13,851 iteration 4935 : loss : 0.002881, loss_ce: 0.000786
2021-12-10 14:34:16,471 iteration 4936 : loss : 0.003253, loss_ce: 0.001826
2021-12-10 14:34:19,074 iteration 4937 : loss : 0.003106, loss_ce: 0.001539
2021-12-10 14:34:21,841 iteration 4938 : loss : 0.004411, loss_ce: 0.001269
2021-12-10 14:34:24,457 iteration 4939 : loss : 0.004065, loss_ce: 0.001478
2021-12-10 14:34:27,116 iteration 4940 : loss : 0.004158, loss_ce: 0.001241
2021-12-10 14:34:29,779 iteration 4941 : loss : 0.003135, loss_ce: 0.001429
2021-12-10 14:34:32,440 iteration 4942 : loss : 0.003307, loss_ce: 0.001587
2021-12-10 14:34:35,070 iteration 4943 : loss : 0.003529, loss_ce: 0.001199
2021-12-10 14:34:37,855 iteration 4944 : loss : 0.002943, loss_ce: 0.001099
2021-12-10 14:34:40,459 iteration 4945 : loss : 0.002573, loss_ce: 0.000887
2021-12-10 14:34:43,081 iteration 4946 : loss : 0.003010, loss_ce: 0.000859
2021-12-10 14:34:45,853 iteration 4947 : loss : 0.002852, loss_ce: 0.001255
 73%|███████████████████▋       | 291/400 [4:08:08<1:31:10, 50.19s/it]2021-12-10 14:34:48,512 iteration 4948 : loss : 0.003916, loss_ce: 0.001332
2021-12-10 14:34:51,122 iteration 4949 : loss : 0.002749, loss_ce: 0.001150
2021-12-10 14:34:53,743 iteration 4950 : loss : 0.002692, loss_ce: 0.001023
2021-12-10 14:34:56,506 iteration 4951 : loss : 0.002680, loss_ce: 0.001117
2021-12-10 14:34:59,101 iteration 4952 : loss : 0.003762, loss_ce: 0.001282
2021-12-10 14:35:01,719 iteration 4953 : loss : 0.003365, loss_ce: 0.001381
2021-12-10 14:35:04,495 iteration 4954 : loss : 0.002754, loss_ce: 0.001166
2021-12-10 14:35:07,087 iteration 4955 : loss : 0.003085, loss_ce: 0.001165
2021-12-10 14:35:09,722 iteration 4956 : loss : 0.002824, loss_ce: 0.000805
2021-12-10 14:35:12,313 iteration 4957 : loss : 0.002662, loss_ce: 0.001282
2021-12-10 14:35:14,943 iteration 4958 : loss : 0.002509, loss_ce: 0.001057
2021-12-10 14:35:17,594 iteration 4959 : loss : 0.003490, loss_ce: 0.001532
2021-12-10 14:35:20,396 iteration 4960 : loss : 0.002856, loss_ce: 0.001291
2021-12-10 14:35:22,994 iteration 4961 : loss : 0.002739, loss_ce: 0.000936
2021-12-10 14:35:25,670 iteration 4962 : loss : 0.003059, loss_ce: 0.000945
2021-12-10 14:35:28,266 iteration 4963 : loss : 0.002823, loss_ce: 0.001173
2021-12-10 14:35:30,889 iteration 4964 : loss : 0.003804, loss_ce: 0.001531
 73%|███████████████████▋       | 292/400 [4:08:53<1:27:33, 48.64s/it]2021-12-10 14:35:33,741 iteration 4965 : loss : 0.003264, loss_ce: 0.001567
2021-12-10 14:35:36,348 iteration 4966 : loss : 0.003024, loss_ce: 0.001247
2021-12-10 14:35:38,974 iteration 4967 : loss : 0.003190, loss_ce: 0.001128
2021-12-10 14:35:41,598 iteration 4968 : loss : 0.002758, loss_ce: 0.001062
2021-12-10 14:35:44,201 iteration 4969 : loss : 0.003489, loss_ce: 0.001019
2021-12-10 14:35:46,959 iteration 4970 : loss : 0.002474, loss_ce: 0.001010
2021-12-10 14:35:49,586 iteration 4971 : loss : 0.003129, loss_ce: 0.001165
2021-12-10 14:35:52,332 iteration 4972 : loss : 0.002970, loss_ce: 0.001064
2021-12-10 14:35:54,953 iteration 4973 : loss : 0.003059, loss_ce: 0.001404
2021-12-10 14:35:57,613 iteration 4974 : loss : 0.002988, loss_ce: 0.001127
2021-12-10 14:36:00,247 iteration 4975 : loss : 0.003348, loss_ce: 0.001228
2021-12-10 14:36:02,852 iteration 4976 : loss : 0.002723, loss_ce: 0.000935
2021-12-10 14:36:05,615 iteration 4977 : loss : 0.002999, loss_ce: 0.001491
2021-12-10 14:36:08,213 iteration 4978 : loss : 0.003324, loss_ce: 0.001069
2021-12-10 14:36:11,011 iteration 4979 : loss : 0.003751, loss_ce: 0.001354
2021-12-10 14:36:13,588 iteration 4980 : loss : 0.002559, loss_ce: 0.001051
2021-12-10 14:36:16,190 iteration 4981 : loss : 0.002618, loss_ce: 0.001048
 73%|███████████████████▊       | 293/400 [4:09:39<1:24:57, 47.64s/it]2021-12-10 14:36:18,913 iteration 4982 : loss : 0.003524, loss_ce: 0.001175
2021-12-10 14:36:21,696 iteration 4983 : loss : 0.002423, loss_ce: 0.000993
2021-12-10 14:36:24,318 iteration 4984 : loss : 0.002789, loss_ce: 0.001106
2021-12-10 14:36:27,075 iteration 4985 : loss : 0.003103, loss_ce: 0.001000
2021-12-10 14:36:29,672 iteration 4986 : loss : 0.003467, loss_ce: 0.001721
2021-12-10 14:36:32,378 iteration 4987 : loss : 0.002779, loss_ce: 0.001113
2021-12-10 14:36:35,030 iteration 4988 : loss : 0.003484, loss_ce: 0.001094
2021-12-10 14:36:37,678 iteration 4989 : loss : 0.003145, loss_ce: 0.000770
2021-12-10 14:36:40,363 iteration 4990 : loss : 0.002918, loss_ce: 0.001216
2021-12-10 14:36:43,061 iteration 4991 : loss : 0.002608, loss_ce: 0.000936
2021-12-10 14:36:45,672 iteration 4992 : loss : 0.003004, loss_ce: 0.001038
2021-12-10 14:36:48,433 iteration 4993 : loss : 0.003291, loss_ce: 0.001299
2021-12-10 14:36:51,054 iteration 4994 : loss : 0.003688, loss_ce: 0.001808
2021-12-10 14:36:53,707 iteration 4995 : loss : 0.002668, loss_ce: 0.001271
2021-12-10 14:36:56,379 iteration 4996 : loss : 0.002915, loss_ce: 0.001132
2021-12-10 14:36:58,978 iteration 4997 : loss : 0.003055, loss_ce: 0.001429
2021-12-10 14:37:01,778 iteration 4998 : loss : 0.004670, loss_ce: 0.001482
 74%|███████████████████▊       | 294/400 [4:10:24<1:23:04, 47.02s/it]2021-12-10 14:37:04,430 iteration 4999 : loss : 0.002620, loss_ce: 0.001030
2021-12-10 14:37:07,093 iteration 5000 : loss : 0.002653, loss_ce: 0.001024
2021-12-10 14:37:09,715 iteration 5001 : loss : 0.003562, loss_ce: 0.001756
2021-12-10 14:37:12,423 iteration 5002 : loss : 0.003207, loss_ce: 0.001401
2021-12-10 14:37:15,042 iteration 5003 : loss : 0.003478, loss_ce: 0.000950
2021-12-10 14:37:17,753 iteration 5004 : loss : 0.002950, loss_ce: 0.001302
2021-12-10 14:37:20,398 iteration 5005 : loss : 0.002382, loss_ce: 0.001037
2021-12-10 14:37:23,012 iteration 5006 : loss : 0.002564, loss_ce: 0.001068
2021-12-10 14:37:25,795 iteration 5007 : loss : 0.003280, loss_ce: 0.001279
2021-12-10 14:37:28,387 iteration 5008 : loss : 0.003814, loss_ce: 0.001775
2021-12-10 14:37:31,044 iteration 5009 : loss : 0.003220, loss_ce: 0.001318
2021-12-10 14:37:33,667 iteration 5010 : loss : 0.004946, loss_ce: 0.001526
2021-12-10 14:37:36,393 iteration 5011 : loss : 0.003121, loss_ce: 0.001185
2021-12-10 14:37:39,018 iteration 5012 : loss : 0.003909, loss_ce: 0.001126
2021-12-10 14:37:41,674 iteration 5013 : loss : 0.004510, loss_ce: 0.001281
2021-12-10 14:37:44,338 iteration 5014 : loss : 0.004483, loss_ce: 0.001336
2021-12-10 14:37:44,338 Training Data Eval:
2021-12-10 14:37:58,885   Average segmentation loss on training set: 0.0040
2021-12-10 14:37:58,885 Validation Data Eval:
2021-12-10 14:38:04,221   Average segmentation loss on validation set: 0.1605
2021-12-10 14:38:06,883 iteration 5015 : loss : 0.003254, loss_ce: 0.001424
 74%|███████████████████▉       | 295/400 [4:11:29<1:31:47, 52.45s/it]2021-12-10 14:38:09,535 iteration 5016 : loss : 0.004511, loss_ce: 0.001762
2021-12-10 14:38:12,302 iteration 5017 : loss : 0.003997, loss_ce: 0.001286
2021-12-10 14:38:14,924 iteration 5018 : loss : 0.002555, loss_ce: 0.000839
2021-12-10 14:38:17,629 iteration 5019 : loss : 0.003172, loss_ce: 0.001482
2021-12-10 14:38:20,216 iteration 5020 : loss : 0.006591, loss_ce: 0.001442
2021-12-10 14:38:22,838 iteration 5021 : loss : 0.003948, loss_ce: 0.001405
2021-12-10 14:38:25,649 iteration 5022 : loss : 0.003281, loss_ce: 0.001063
2021-12-10 14:38:28,273 iteration 5023 : loss : 0.004552, loss_ce: 0.001349
2021-12-10 14:38:30,936 iteration 5024 : loss : 0.004176, loss_ce: 0.002062
2021-12-10 14:38:33,549 iteration 5025 : loss : 0.004341, loss_ce: 0.001986
2021-12-10 14:38:36,307 iteration 5026 : loss : 0.003741, loss_ce: 0.001821
2021-12-10 14:38:38,927 iteration 5027 : loss : 0.002539, loss_ce: 0.000952
2021-12-10 14:38:41,553 iteration 5028 : loss : 0.003532, loss_ce: 0.001277
2021-12-10 14:38:44,302 iteration 5029 : loss : 0.003663, loss_ce: 0.001274
2021-12-10 14:38:46,890 iteration 5030 : loss : 0.003459, loss_ce: 0.001404
2021-12-10 14:38:49,552 iteration 5031 : loss : 0.002996, loss_ce: 0.001386
2021-12-10 14:38:52,153 iteration 5032 : loss : 0.003087, loss_ce: 0.001441
 74%|███████████████████▉       | 296/400 [4:12:14<1:27:10, 50.29s/it]2021-12-10 14:38:54,814 iteration 5033 : loss : 0.002647, loss_ce: 0.001173
2021-12-10 14:38:57,470 iteration 5034 : loss : 0.004069, loss_ce: 0.001785
2021-12-10 14:39:00,126 iteration 5035 : loss : 0.004490, loss_ce: 0.001231
2021-12-10 14:39:02,781 iteration 5036 : loss : 0.002853, loss_ce: 0.001429
2021-12-10 14:39:05,402 iteration 5037 : loss : 0.002741, loss_ce: 0.000948
2021-12-10 14:39:08,187 iteration 5038 : loss : 0.003067, loss_ce: 0.001392
2021-12-10 14:39:10,780 iteration 5039 : loss : 0.004934, loss_ce: 0.000974
2021-12-10 14:39:13,404 iteration 5040 : loss : 0.003610, loss_ce: 0.001296
2021-12-10 14:39:16,183 iteration 5041 : loss : 0.004341, loss_ce: 0.001611
2021-12-10 14:39:18,780 iteration 5042 : loss : 0.004313, loss_ce: 0.001864
2021-12-10 14:39:21,434 iteration 5043 : loss : 0.004724, loss_ce: 0.002016
2021-12-10 14:39:24,054 iteration 5044 : loss : 0.003819, loss_ce: 0.001418
2021-12-10 14:39:26,836 iteration 5045 : loss : 0.003059, loss_ce: 0.001097
2021-12-10 14:39:29,431 iteration 5046 : loss : 0.003232, loss_ce: 0.001177
2021-12-10 14:39:32,055 iteration 5047 : loss : 0.003606, loss_ce: 0.001450
2021-12-10 14:39:34,764 iteration 5048 : loss : 0.003468, loss_ce: 0.001488
2021-12-10 14:39:37,375 iteration 5049 : loss : 0.004401, loss_ce: 0.001663
 74%|████████████████████       | 297/400 [4:13:00<1:23:43, 48.77s/it]2021-12-10 14:39:40,056 iteration 5050 : loss : 0.004678, loss_ce: 0.001220
2021-12-10 14:39:42,757 iteration 5051 : loss : 0.003555, loss_ce: 0.001172
2021-12-10 14:39:45,379 iteration 5052 : loss : 0.003760, loss_ce: 0.001708
2021-12-10 14:39:48,056 iteration 5053 : loss : 0.002890, loss_ce: 0.001061
2021-12-10 14:39:50,717 iteration 5054 : loss : 0.003940, loss_ce: 0.001598
2021-12-10 14:39:53,341 iteration 5055 : loss : 0.002910, loss_ce: 0.001304
2021-12-10 14:39:56,114 iteration 5056 : loss : 0.004290, loss_ce: 0.001639
2021-12-10 14:39:58,720 iteration 5057 : loss : 0.003717, loss_ce: 0.001562
2021-12-10 14:40:01,318 iteration 5058 : loss : 0.002844, loss_ce: 0.001108
2021-12-10 14:40:04,105 iteration 5059 : loss : 0.002959, loss_ce: 0.001431
2021-12-10 14:40:06,712 iteration 5060 : loss : 0.003637, loss_ce: 0.001715
2021-12-10 14:40:09,309 iteration 5061 : loss : 0.004085, loss_ce: 0.001742
2021-12-10 14:40:11,967 iteration 5062 : loss : 0.003111, loss_ce: 0.001295
2021-12-10 14:40:14,617 iteration 5063 : loss : 0.003181, loss_ce: 0.001549
2021-12-10 14:40:17,235 iteration 5064 : loss : 0.002897, loss_ce: 0.000873
2021-12-10 14:40:19,862 iteration 5065 : loss : 0.003137, loss_ce: 0.000861
2021-12-10 14:40:22,620 iteration 5066 : loss : 0.003054, loss_ce: 0.001191
 74%|████████████████████       | 298/400 [4:13:45<1:21:06, 47.71s/it]2021-12-10 14:40:25,402 iteration 5067 : loss : 0.003679, loss_ce: 0.001951
2021-12-10 14:40:27,993 iteration 5068 : loss : 0.002802, loss_ce: 0.001074
2021-12-10 14:40:30,615 iteration 5069 : loss : 0.002898, loss_ce: 0.001291
2021-12-10 14:40:33,266 iteration 5070 : loss : 0.003233, loss_ce: 0.001147
2021-12-10 14:40:35,914 iteration 5071 : loss : 0.002981, loss_ce: 0.001035
2021-12-10 14:40:38,516 iteration 5072 : loss : 0.002659, loss_ce: 0.001098
2021-12-10 14:40:41,115 iteration 5073 : loss : 0.002738, loss_ce: 0.000827
2021-12-10 14:40:43,736 iteration 5074 : loss : 0.002150, loss_ce: 0.000736
2021-12-10 14:40:46,492 iteration 5075 : loss : 0.003537, loss_ce: 0.001269
2021-12-10 14:40:49,090 iteration 5076 : loss : 0.002983, loss_ce: 0.001262
2021-12-10 14:40:51,685 iteration 5077 : loss : 0.003291, loss_ce: 0.001372
2021-12-10 14:40:54,417 iteration 5078 : loss : 0.003378, loss_ce: 0.001402
2021-12-10 14:40:57,075 iteration 5079 : loss : 0.002910, loss_ce: 0.001059
2021-12-10 14:40:59,731 iteration 5080 : loss : 0.002487, loss_ce: 0.001191
2021-12-10 14:41:02,395 iteration 5081 : loss : 0.002430, loss_ce: 0.000901
2021-12-10 14:41:05,017 iteration 5082 : loss : 0.003228, loss_ce: 0.001587
2021-12-10 14:41:07,627 iteration 5083 : loss : 0.002704, loss_ce: 0.001116
 75%|████████████████████▏      | 299/400 [4:14:30<1:18:57, 46.90s/it]2021-12-10 14:41:10,468 iteration 5084 : loss : 0.002864, loss_ce: 0.001363
2021-12-10 14:41:13,086 iteration 5085 : loss : 0.002779, loss_ce: 0.000825
2021-12-10 14:41:15,737 iteration 5086 : loss : 0.002533, loss_ce: 0.001218
2021-12-10 14:41:18,387 iteration 5087 : loss : 0.002932, loss_ce: 0.000916
2021-12-10 14:41:21,155 iteration 5088 : loss : 0.002786, loss_ce: 0.001131
2021-12-10 14:41:23,751 iteration 5089 : loss : 0.002402, loss_ce: 0.000966
2021-12-10 14:41:26,363 iteration 5090 : loss : 0.002871, loss_ce: 0.001409
2021-12-10 14:41:29,063 iteration 5091 : loss : 0.002825, loss_ce: 0.000976
2021-12-10 14:41:31,712 iteration 5092 : loss : 0.002581, loss_ce: 0.001061
2021-12-10 14:41:34,327 iteration 5093 : loss : 0.002353, loss_ce: 0.001077
2021-12-10 14:41:37,101 iteration 5094 : loss : 0.003164, loss_ce: 0.000944
2021-12-10 14:41:39,695 iteration 5095 : loss : 0.002724, loss_ce: 0.001429
2021-12-10 14:41:42,309 iteration 5096 : loss : 0.003267, loss_ce: 0.001526
2021-12-10 14:41:45,409 iteration 5097 : loss : 0.003828, loss_ce: 0.001339
2021-12-10 14:41:48,039 iteration 5098 : loss : 0.002666, loss_ce: 0.001070
2021-12-10 14:41:50,813 iteration 5099 : loss : 0.002267, loss_ce: 0.000748
2021-12-10 14:41:50,813 Training Data Eval:
2021-12-10 14:42:05,649   Average segmentation loss on training set: 0.0025
2021-12-10 14:42:05,649 Validation Data Eval:
2021-12-10 14:42:10,847   Average segmentation loss on validation set: 0.1317
2021-12-10 14:42:13,601 iteration 5100 : loss : 0.002883, loss_ce: 0.001387
2021-12-10 14:42:19,416 save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/NEW_TU/NEW_TU_ADAM_seed1234_no_daepoch_299.pth
 75%|████████████████████▎      | 300/400 [4:15:42<1:30:35, 54.35s/it]2021-12-10 14:42:21,047 iteration 5101 : loss : 0.003242, loss_ce: 0.001250
2021-12-10 14:42:23,073 iteration 5102 : loss : 0.002747, loss_ce: 0.001130
2021-12-10 14:42:25,623 iteration 5103 : loss : 0.003120, loss_ce: 0.000809
2021-12-10 14:42:28,032 iteration 5104 : loss : 0.002599, loss_ce: 0.000986
2021-12-10 14:42:30,469 iteration 5105 : loss : 0.002934, loss_ce: 0.001485
2021-12-10 14:42:33,024 iteration 5106 : loss : 0.002293, loss_ce: 0.000718
2021-12-10 14:42:35,463 iteration 5107 : loss : 0.002546, loss_ce: 0.001163
2021-12-10 14:42:38,078 iteration 5108 : loss : 0.002475, loss_ce: 0.001163
2021-12-10 14:42:40,705 iteration 5109 : loss : 0.002720, loss_ce: 0.000977
2021-12-10 14:42:43,306 iteration 5110 : loss : 0.002757, loss_ce: 0.001196
2021-12-10 14:42:46,097 iteration 5111 : loss : 0.002419, loss_ce: 0.001085
2021-12-10 14:42:48,700 iteration 5112 : loss : 0.002617, loss_ce: 0.001233
2021-12-10 14:42:51,325 iteration 5113 : loss : 0.003776, loss_ce: 0.001337
2021-12-10 14:42:54,099 iteration 5114 : loss : 0.002084, loss_ce: 0.000596
2021-12-10 14:42:56,712 iteration 5115 : loss : 0.002934, loss_ce: 0.001412
2021-12-10 14:42:59,477 iteration 5116 : loss : 0.002227, loss_ce: 0.000883
2021-12-10 14:43:02,086 iteration 5117 : loss : 0.002231, loss_ce: 0.000996
 75%|████████████████████▎      | 301/400 [4:16:24<1:23:55, 50.87s/it]2021-12-10 14:43:04,865 iteration 5118 : loss : 0.002651, loss_ce: 0.001328
2021-12-10 14:43:07,470 iteration 5119 : loss : 0.002295, loss_ce: 0.001053
2021-12-10 14:43:10,214 iteration 5120 : loss : 0.003692, loss_ce: 0.001521
2021-12-10 14:43:12,839 iteration 5121 : loss : 0.002883, loss_ce: 0.001323
2021-12-10 14:43:15,608 iteration 5122 : loss : 0.002536, loss_ce: 0.000754
2021-12-10 14:43:18,374 iteration 5123 : loss : 0.002573, loss_ce: 0.000934
2021-12-10 14:43:21,036 iteration 5124 : loss : 0.002457, loss_ce: 0.000901
2021-12-10 14:43:23,808 iteration 5125 : loss : 0.002600, loss_ce: 0.001191
2021-12-10 14:43:26,399 iteration 5126 : loss : 0.002690, loss_ce: 0.001281
2021-12-10 14:43:29,163 iteration 5127 : loss : 0.002821, loss_ce: 0.001291
2021-12-10 14:43:31,789 iteration 5128 : loss : 0.002884, loss_ce: 0.001436
2021-12-10 14:43:34,548 iteration 5129 : loss : 0.002878, loss_ce: 0.001176
2021-12-10 14:43:37,143 iteration 5130 : loss : 0.002263, loss_ce: 0.001064
2021-12-10 14:43:39,876 iteration 5131 : loss : 0.002740, loss_ce: 0.000967
2021-12-10 14:43:42,634 iteration 5132 : loss : 0.002913, loss_ce: 0.001165
2021-12-10 14:43:45,237 iteration 5133 : loss : 0.002635, loss_ce: 0.000919
2021-12-10 14:43:47,998 iteration 5134 : loss : 0.002156, loss_ce: 0.000618
 76%|████████████████████▍      | 302/400 [4:17:10<1:20:39, 49.38s/it]2021-12-10 14:43:50,799 iteration 5135 : loss : 0.002571, loss_ce: 0.001112
2021-12-10 14:43:53,395 iteration 5136 : loss : 0.002502, loss_ce: 0.001269
2021-12-10 14:43:56,100 iteration 5137 : loss : 0.001987, loss_ce: 0.000712
2021-12-10 14:43:58,751 iteration 5138 : loss : 0.002188, loss_ce: 0.001019
2021-12-10 14:44:01,517 iteration 5139 : loss : 0.002732, loss_ce: 0.001176
2021-12-10 14:44:04,115 iteration 5140 : loss : 0.001920, loss_ce: 0.000721
2021-12-10 14:44:06,799 iteration 5141 : loss : 0.002228, loss_ce: 0.001091
2021-12-10 14:44:09,451 iteration 5142 : loss : 0.002909, loss_ce: 0.001003
2021-12-10 14:44:12,189 iteration 5143 : loss : 0.002784, loss_ce: 0.000812
2021-12-10 14:44:14,843 iteration 5144 : loss : 0.002616, loss_ce: 0.001233
2021-12-10 14:44:17,511 iteration 5145 : loss : 0.002310, loss_ce: 0.000922
2021-12-10 14:44:20,298 iteration 5146 : loss : 0.003127, loss_ce: 0.001240
2021-12-10 14:44:22,876 iteration 5147 : loss : 0.002476, loss_ce: 0.001161
2021-12-10 14:44:25,649 iteration 5148 : loss : 0.002706, loss_ce: 0.001075
2021-12-10 14:44:28,255 iteration 5149 : loss : 0.002286, loss_ce: 0.000914
2021-12-10 14:44:30,877 iteration 5150 : loss : 0.002343, loss_ce: 0.001110
2021-12-10 14:44:33,616 iteration 5151 : loss : 0.002223, loss_ce: 0.000735
 76%|████████████████████▍      | 303/400 [4:17:56<1:18:00, 48.25s/it]2021-12-10 14:44:36,350 iteration 5152 : loss : 0.002749, loss_ce: 0.001140
2021-12-10 14:44:38,946 iteration 5153 : loss : 0.002734, loss_ce: 0.001024
2021-12-10 14:44:41,581 iteration 5154 : loss : 0.001988, loss_ce: 0.000775
2021-12-10 14:44:44,263 iteration 5155 : loss : 0.002425, loss_ce: 0.001006
2021-12-10 14:44:46,961 iteration 5156 : loss : 0.002475, loss_ce: 0.001256
2021-12-10 14:44:49,560 iteration 5157 : loss : 0.003123, loss_ce: 0.000896
2021-12-10 14:44:52,322 iteration 5158 : loss : 0.003347, loss_ce: 0.001342
2021-12-10 14:44:54,932 iteration 5159 : loss : 0.002461, loss_ce: 0.001139
2021-12-10 14:44:57,528 iteration 5160 : loss : 0.002659, loss_ce: 0.001001
2021-12-10 14:45:00,300 iteration 5161 : loss : 0.002567, loss_ce: 0.001211
2021-12-10 14:45:02,930 iteration 5162 : loss : 0.003142, loss_ce: 0.000661
2021-12-10 14:45:05,555 iteration 5163 : loss : 0.002727, loss_ce: 0.001086
2021-12-10 14:45:08,319 iteration 5164 : loss : 0.002707, loss_ce: 0.001226
2021-12-10 14:45:10,953 iteration 5165 : loss : 0.003073, loss_ce: 0.000819
2021-12-10 14:45:13,682 iteration 5166 : loss : 0.003504, loss_ce: 0.002055
2021-12-10 14:45:16,449 iteration 5167 : loss : 0.002437, loss_ce: 0.000947
2021-12-10 14:45:19,057 iteration 5168 : loss : 0.002509, loss_ce: 0.001153
 76%|████████████████████▌      | 304/400 [4:18:41<1:15:51, 47.41s/it]2021-12-10 14:45:21,842 iteration 5169 : loss : 0.003142, loss_ce: 0.001299
2021-12-10 14:45:24,473 iteration 5170 : loss : 0.002733, loss_ce: 0.001006
2021-12-10 14:45:27,092 iteration 5171 : loss : 0.002888, loss_ce: 0.001444
2021-12-10 14:45:29,859 iteration 5172 : loss : 0.004057, loss_ce: 0.001670
2021-12-10 14:45:32,466 iteration 5173 : loss : 0.002396, loss_ce: 0.000961
2021-12-10 14:45:35,132 iteration 5174 : loss : 0.002752, loss_ce: 0.001067
2021-12-10 14:45:37,762 iteration 5175 : loss : 0.002721, loss_ce: 0.000742
2021-12-10 14:45:40,459 iteration 5176 : loss : 0.002992, loss_ce: 0.000909
2021-12-10 14:45:43,161 iteration 5177 : loss : 0.002679, loss_ce: 0.000713
2021-12-10 14:45:45,854 iteration 5178 : loss : 0.003114, loss_ce: 0.001434
2021-12-10 14:45:48,465 iteration 5179 : loss : 0.002206, loss_ce: 0.001026
2021-12-10 14:45:51,116 iteration 5180 : loss : 0.002970, loss_ce: 0.000914
2021-12-10 14:45:53,728 iteration 5181 : loss : 0.002767, loss_ce: 0.001036
2021-12-10 14:45:56,382 iteration 5182 : loss : 0.002811, loss_ce: 0.001143
2021-12-10 14:45:59,127 iteration 5183 : loss : 0.003082, loss_ce: 0.001365
2021-12-10 14:46:01,748 iteration 5184 : loss : 0.002921, loss_ce: 0.001248
2021-12-10 14:46:01,748 Training Data Eval:
2021-12-10 14:46:16,449   Average segmentation loss on training set: 0.0026
2021-12-10 14:46:16,450 Validation Data Eval:
2021-12-10 14:46:21,666   Average segmentation loss on validation set: 0.1287
2021-12-10 14:46:24,257 iteration 5185 : loss : 0.002812, loss_ce: 0.001274
 76%|████████████████████▌      | 305/400 [4:19:47<1:23:30, 52.75s/it]2021-12-10 14:46:27,051 iteration 5186 : loss : 0.002624, loss_ce: 0.000820
2021-12-10 14:46:29,653 iteration 5187 : loss : 0.002575, loss_ce: 0.001001
2021-12-10 14:46:32,360 iteration 5188 : loss : 0.002733, loss_ce: 0.001461
2021-12-10 14:46:34,977 iteration 5189 : loss : 0.002239, loss_ce: 0.000807
2021-12-10 14:46:37,683 iteration 5190 : loss : 0.002619, loss_ce: 0.001089
2021-12-10 14:46:40,348 iteration 5191 : loss : 0.002792, loss_ce: 0.001099
2021-12-10 14:46:42,920 iteration 5192 : loss : 0.002375, loss_ce: 0.001102
2021-12-10 14:46:45,665 iteration 5193 : loss : 0.002950, loss_ce: 0.001468
2021-12-10 14:46:48,279 iteration 5194 : loss : 0.002405, loss_ce: 0.000969
2021-12-10 14:46:51,058 iteration 5195 : loss : 0.002661, loss_ce: 0.001173
2021-12-10 14:46:53,666 iteration 5196 : loss : 0.002658, loss_ce: 0.001267
2021-12-10 14:46:56,295 iteration 5197 : loss : 0.002663, loss_ce: 0.001189
2021-12-10 14:46:59,060 iteration 5198 : loss : 0.002468, loss_ce: 0.000918
2021-12-10 14:47:01,664 iteration 5199 : loss : 0.002543, loss_ce: 0.000917
2021-12-10 14:47:04,288 iteration 5200 : loss : 0.002376, loss_ce: 0.000841
2021-12-10 14:47:07,067 iteration 5201 : loss : 0.002758, loss_ce: 0.000839
2021-12-10 14:47:09,669 iteration 5202 : loss : 0.002148, loss_ce: 0.000821
 76%|████████████████████▋      | 306/400 [4:20:32<1:19:11, 50.55s/it]2021-12-10 14:47:12,437 iteration 5203 : loss : 0.002398, loss_ce: 0.001151
2021-12-10 14:47:15,031 iteration 5204 : loss : 0.002286, loss_ce: 0.001382
2021-12-10 14:47:17,721 iteration 5205 : loss : 0.002748, loss_ce: 0.001351
2021-12-10 14:47:20,422 iteration 5206 : loss : 0.003306, loss_ce: 0.000948
2021-12-10 14:47:23,023 iteration 5207 : loss : 0.002248, loss_ce: 0.001062
2021-12-10 14:47:25,625 iteration 5208 : loss : 0.003063, loss_ce: 0.001402
2021-12-10 14:47:28,252 iteration 5209 : loss : 0.002346, loss_ce: 0.000487
2021-12-10 14:47:31,025 iteration 5210 : loss : 0.002610, loss_ce: 0.001035
2021-12-10 14:47:33,627 iteration 5211 : loss : 0.002405, loss_ce: 0.000913
2021-12-10 14:47:36,311 iteration 5212 : loss : 0.002404, loss_ce: 0.001015
2021-12-10 14:47:39,001 iteration 5213 : loss : 0.002377, loss_ce: 0.001098
2021-12-10 14:47:41,702 iteration 5214 : loss : 0.004195, loss_ce: 0.001012
2021-12-10 14:47:44,295 iteration 5215 : loss : 0.003779, loss_ce: 0.001359
2021-12-10 14:47:46,996 iteration 5216 : loss : 0.001907, loss_ce: 0.000812
2021-12-10 14:47:49,610 iteration 5217 : loss : 0.002600, loss_ce: 0.001250
2021-12-10 14:47:52,369 iteration 5218 : loss : 0.003043, loss_ce: 0.001216
2021-12-10 14:47:54,998 iteration 5219 : loss : 0.003132, loss_ce: 0.001188
 77%|████████████████████▋      | 307/400 [4:21:17<1:15:55, 48.98s/it]2021-12-10 14:47:57,800 iteration 5220 : loss : 0.002556, loss_ce: 0.001131
2021-12-10 14:48:00,402 iteration 5221 : loss : 0.002295, loss_ce: 0.000880
2021-12-10 14:48:03,025 iteration 5222 : loss : 0.003110, loss_ce: 0.001515
2021-12-10 14:48:05,728 iteration 5223 : loss : 0.004767, loss_ce: 0.000905
2021-12-10 14:48:08,351 iteration 5224 : loss : 0.002309, loss_ce: 0.000903
2021-12-10 14:48:11,130 iteration 5225 : loss : 0.002494, loss_ce: 0.000969
2021-12-10 14:48:13,738 iteration 5226 : loss : 0.003064, loss_ce: 0.001503
2021-12-10 14:48:16,402 iteration 5227 : loss : 0.002336, loss_ce: 0.000934
2021-12-10 14:48:18,969 iteration 5228 : loss : 0.003511, loss_ce: 0.001459
2021-12-10 14:48:21,619 iteration 5229 : loss : 0.002163, loss_ce: 0.000963
2021-12-10 14:48:24,239 iteration 5230 : loss : 0.003361, loss_ce: 0.000995
2021-12-10 14:48:27,053 iteration 5231 : loss : 0.003140, loss_ce: 0.001051
2021-12-10 14:48:29,628 iteration 5232 : loss : 0.003310, loss_ce: 0.001376
2021-12-10 14:48:32,238 iteration 5233 : loss : 0.003581, loss_ce: 0.001227
2021-12-10 14:48:34,990 iteration 5234 : loss : 0.003185, loss_ce: 0.001057
2021-12-10 14:48:37,557 iteration 5235 : loss : 0.002080, loss_ce: 0.000781
2021-12-10 14:48:40,319 iteration 5236 : loss : 0.002429, loss_ce: 0.000931
 77%|████████████████████▊      | 308/400 [4:22:03<1:13:24, 47.88s/it]2021-12-10 14:48:43,045 iteration 5237 : loss : 0.003711, loss_ce: 0.001456
2021-12-10 14:48:45,618 iteration 5238 : loss : 0.002979, loss_ce: 0.001000
2021-12-10 14:48:48,322 iteration 5239 : loss : 0.002579, loss_ce: 0.001101
2021-12-10 14:48:50,992 iteration 5240 : loss : 0.002472, loss_ce: 0.001156
2021-12-10 14:48:53,612 iteration 5241 : loss : 0.002668, loss_ce: 0.001184
2021-12-10 14:48:56,280 iteration 5242 : loss : 0.002568, loss_ce: 0.001125
2021-12-10 14:48:58,907 iteration 5243 : loss : 0.002851, loss_ce: 0.001003
2021-12-10 14:49:01,525 iteration 5244 : loss : 0.003966, loss_ce: 0.000957
2021-12-10 14:49:04,279 iteration 5245 : loss : 0.003956, loss_ce: 0.001260
2021-12-10 14:49:06,876 iteration 5246 : loss : 0.003058, loss_ce: 0.001596
2021-12-10 14:49:09,489 iteration 5247 : loss : 0.003467, loss_ce: 0.001090
2021-12-10 14:49:12,247 iteration 5248 : loss : 0.002428, loss_ce: 0.001028
2021-12-10 14:49:14,847 iteration 5249 : loss : 0.002372, loss_ce: 0.001056
2021-12-10 14:49:17,471 iteration 5250 : loss : 0.002126, loss_ce: 0.000645
2021-12-10 14:49:20,238 iteration 5251 : loss : 0.003168, loss_ce: 0.001191
2021-12-10 14:49:22,863 iteration 5252 : loss : 0.002270, loss_ce: 0.000938
2021-12-10 14:49:25,590 iteration 5253 : loss : 0.003782, loss_ce: 0.001453
 77%|████████████████████▊      | 309/400 [4:22:48<1:11:26, 47.10s/it]2021-12-10 14:49:28,319 iteration 5254 : loss : 0.003158, loss_ce: 0.001042
2021-12-10 14:49:30,882 iteration 5255 : loss : 0.002712, loss_ce: 0.000942
2021-12-10 14:49:33,536 iteration 5256 : loss : 0.003655, loss_ce: 0.001097
2021-12-10 14:49:36,320 iteration 5257 : loss : 0.002574, loss_ce: 0.001100
2021-12-10 14:49:38,930 iteration 5258 : loss : 0.002919, loss_ce: 0.000916
2021-12-10 14:49:41,591 iteration 5259 : loss : 0.003216, loss_ce: 0.001585
2021-12-10 14:49:44,239 iteration 5260 : loss : 0.003054, loss_ce: 0.001493
2021-12-10 14:49:46,867 iteration 5261 : loss : 0.002688, loss_ce: 0.001043
2021-12-10 14:49:49,591 iteration 5262 : loss : 0.002349, loss_ce: 0.000982
2021-12-10 14:49:52,348 iteration 5263 : loss : 0.002808, loss_ce: 0.000981
2021-12-10 14:49:54,943 iteration 5264 : loss : 0.002833, loss_ce: 0.001068
2021-12-10 14:49:57,572 iteration 5265 : loss : 0.002435, loss_ce: 0.000946
2021-12-10 14:50:00,175 iteration 5266 : loss : 0.003052, loss_ce: 0.001796
2021-12-10 14:50:02,959 iteration 5267 : loss : 0.002571, loss_ce: 0.001026
2021-12-10 14:50:05,554 iteration 5268 : loss : 0.003798, loss_ce: 0.001650
2021-12-10 14:50:08,169 iteration 5269 : loss : 0.002333, loss_ce: 0.000998
2021-12-10 14:50:08,169 Training Data Eval:
2021-12-10 14:50:22,791   Average segmentation loss on training set: 0.0025
2021-12-10 14:50:22,792 Validation Data Eval:
2021-12-10 14:50:27,894   Average segmentation loss on validation set: 0.1302
2021-12-10 14:50:30,605 iteration 5270 : loss : 0.002702, loss_ce: 0.001138
 78%|████████████████████▉      | 310/400 [4:23:53<1:18:42, 52.47s/it]2021-12-10 14:50:33,339 iteration 5271 : loss : 0.002341, loss_ce: 0.000916
2021-12-10 14:50:35,948 iteration 5272 : loss : 0.002587, loss_ce: 0.000889
2021-12-10 14:50:38,573 iteration 5273 : loss : 0.002202, loss_ce: 0.000827
2021-12-10 14:50:41,337 iteration 5274 : loss : 0.003069, loss_ce: 0.001608
2021-12-10 14:50:43,968 iteration 5275 : loss : 0.002927, loss_ce: 0.001054
2021-12-10 14:50:46,740 iteration 5276 : loss : 0.003017, loss_ce: 0.001140
2021-12-10 14:50:49,385 iteration 5277 : loss : 0.002339, loss_ce: 0.000902
2021-12-10 14:50:52,007 iteration 5278 : loss : 0.002636, loss_ce: 0.001026
2021-12-10 14:50:54,724 iteration 5279 : loss : 0.002162, loss_ce: 0.000669
2021-12-10 14:50:57,320 iteration 5280 : loss : 0.003046, loss_ce: 0.001275
2021-12-10 14:51:00,099 iteration 5281 : loss : 0.003870, loss_ce: 0.001087
2021-12-10 14:51:02,697 iteration 5282 : loss : 0.003055, loss_ce: 0.001308
2021-12-10 14:51:05,319 iteration 5283 : loss : 0.002368, loss_ce: 0.001268
2021-12-10 14:51:08,094 iteration 5284 : loss : 0.003293, loss_ce: 0.000803
2021-12-10 14:51:10,731 iteration 5285 : loss : 0.002822, loss_ce: 0.001045
2021-12-10 14:51:13,351 iteration 5286 : loss : 0.002627, loss_ce: 0.001441
2021-12-10 14:51:16,118 iteration 5287 : loss : 0.003884, loss_ce: 0.001382
 78%|████████████████████▉      | 311/400 [4:24:38<1:14:44, 50.39s/it]2021-12-10 14:51:18,915 iteration 5288 : loss : 0.002368, loss_ce: 0.001155
2021-12-10 14:51:21,515 iteration 5289 : loss : 0.003435, loss_ce: 0.001473
2021-12-10 14:51:24,183 iteration 5290 : loss : 0.002197, loss_ce: 0.000795
2021-12-10 14:51:26,782 iteration 5291 : loss : 0.003602, loss_ce: 0.001592
2021-12-10 14:51:29,497 iteration 5292 : loss : 0.002294, loss_ce: 0.001032
2021-12-10 14:51:32,100 iteration 5293 : loss : 0.002352, loss_ce: 0.000922
2021-12-10 14:51:34,709 iteration 5294 : loss : 0.004016, loss_ce: 0.001192
2021-12-10 14:51:37,474 iteration 5295 : loss : 0.002935, loss_ce: 0.001465
2021-12-10 14:51:40,104 iteration 5296 : loss : 0.002463, loss_ce: 0.000862
2021-12-10 14:51:42,816 iteration 5297 : loss : 0.002703, loss_ce: 0.001094
2021-12-10 14:51:45,398 iteration 5298 : loss : 0.003320, loss_ce: 0.001181
2021-12-10 14:51:48,026 iteration 5299 : loss : 0.002332, loss_ce: 0.001037
2021-12-10 14:51:50,700 iteration 5300 : loss : 0.002790, loss_ce: 0.000997
2021-12-10 14:51:53,327 iteration 5301 : loss : 0.002521, loss_ce: 0.000850
2021-12-10 14:51:56,087 iteration 5302 : loss : 0.003473, loss_ce: 0.001485
2021-12-10 14:51:58,680 iteration 5303 : loss : 0.002468, loss_ce: 0.000983
2021-12-10 14:52:01,371 iteration 5304 : loss : 0.002758, loss_ce: 0.000847
 78%|█████████████████████      | 312/400 [4:25:24<1:11:38, 48.84s/it]2021-12-10 14:52:04,110 iteration 5305 : loss : 0.003732, loss_ce: 0.001042
2021-12-10 14:52:06,709 iteration 5306 : loss : 0.002640, loss_ce: 0.001126
2021-12-10 14:52:09,267 iteration 5307 : loss : 0.002461, loss_ce: 0.000840
2021-12-10 14:52:11,896 iteration 5308 : loss : 0.002796, loss_ce: 0.001267
2021-12-10 14:52:14,599 iteration 5309 : loss : 0.003033, loss_ce: 0.001415
2021-12-10 14:52:17,360 iteration 5310 : loss : 0.002784, loss_ce: 0.000934
2021-12-10 14:52:19,966 iteration 5311 : loss : 0.002489, loss_ce: 0.000948
2021-12-10 14:52:22,581 iteration 5312 : loss : 0.002815, loss_ce: 0.000962
2021-12-10 14:52:25,345 iteration 5313 : loss : 0.003105, loss_ce: 0.001393
2021-12-10 14:52:27,954 iteration 5314 : loss : 0.002750, loss_ce: 0.001255
2021-12-10 14:52:30,669 iteration 5315 : loss : 0.002406, loss_ce: 0.001025
2021-12-10 14:52:33,264 iteration 5316 : loss : 0.002424, loss_ce: 0.001276
2021-12-10 14:52:35,976 iteration 5317 : loss : 0.002774, loss_ce: 0.001106
2021-12-10 14:52:38,612 iteration 5318 : loss : 0.003222, loss_ce: 0.001244
2021-12-10 14:52:41,231 iteration 5319 : loss : 0.002410, loss_ce: 0.001183
2021-12-10 14:52:43,987 iteration 5320 : loss : 0.003064, loss_ce: 0.000888
2021-12-10 14:52:46,615 iteration 5321 : loss : 0.003168, loss_ce: 0.000767
 78%|█████████████████████▏     | 313/400 [4:26:09<1:09:15, 47.76s/it]2021-12-10 14:52:49,288 iteration 5322 : loss : 0.002240, loss_ce: 0.000555
2021-12-10 14:52:51,892 iteration 5323 : loss : 0.003036, loss_ce: 0.001067
2021-12-10 14:52:54,645 iteration 5324 : loss : 0.003299, loss_ce: 0.001693
2021-12-10 14:52:57,245 iteration 5325 : loss : 0.003632, loss_ce: 0.001248
2021-12-10 14:52:59,930 iteration 5326 : loss : 0.002614, loss_ce: 0.001034
2021-12-10 14:53:02,534 iteration 5327 : loss : 0.002189, loss_ce: 0.000789
2021-12-10 14:53:05,288 iteration 5328 : loss : 0.002528, loss_ce: 0.000954
2021-12-10 14:53:07,886 iteration 5329 : loss : 0.004027, loss_ce: 0.001589
2021-12-10 14:53:10,511 iteration 5330 : loss : 0.002659, loss_ce: 0.001151
2021-12-10 14:53:13,268 iteration 5331 : loss : 0.003052, loss_ce: 0.000805
2021-12-10 14:53:15,861 iteration 5332 : loss : 0.002923, loss_ce: 0.001067
2021-12-10 14:53:18,583 iteration 5333 : loss : 0.003299, loss_ce: 0.001564
2021-12-10 14:53:21,179 iteration 5334 : loss : 0.002747, loss_ce: 0.001212
2021-12-10 14:53:23,768 iteration 5335 : loss : 0.003326, loss_ce: 0.001331
2021-12-10 14:53:26,537 iteration 5336 : loss : 0.003093, loss_ce: 0.000878
2021-12-10 14:53:29,142 iteration 5337 : loss : 0.002199, loss_ce: 0.001015
2021-12-10 14:53:31,801 iteration 5338 : loss : 0.003084, loss_ce: 0.001233
 78%|█████████████████████▏     | 314/400 [4:26:54<1:07:21, 46.99s/it]2021-12-10 14:53:34,435 iteration 5339 : loss : 0.002825, loss_ce: 0.000708
2021-12-10 14:53:37,067 iteration 5340 : loss : 0.003154, loss_ce: 0.000733
2021-12-10 14:53:39,847 iteration 5341 : loss : 0.002820, loss_ce: 0.001087
2021-12-10 14:53:42,440 iteration 5342 : loss : 0.002517, loss_ce: 0.001365
2021-12-10 14:53:45,057 iteration 5343 : loss : 0.003158, loss_ce: 0.001691
2021-12-10 14:53:47,767 iteration 5344 : loss : 0.003676, loss_ce: 0.001222
2021-12-10 14:53:50,389 iteration 5345 : loss : 0.003030, loss_ce: 0.001284
2021-12-10 14:53:53,154 iteration 5346 : loss : 0.002543, loss_ce: 0.001119
2021-12-10 14:53:55,745 iteration 5347 : loss : 0.003011, loss_ce: 0.001284
2021-12-10 14:53:58,368 iteration 5348 : loss : 0.003380, loss_ce: 0.001275
2021-12-10 14:54:00,981 iteration 5349 : loss : 0.002899, loss_ce: 0.001112
2021-12-10 14:54:03,733 iteration 5350 : loss : 0.002760, loss_ce: 0.000929
2021-12-10 14:54:06,358 iteration 5351 : loss : 0.003118, loss_ce: 0.001434
2021-12-10 14:54:09,067 iteration 5352 : loss : 0.002225, loss_ce: 0.001025
2021-12-10 14:54:11,797 iteration 5353 : loss : 0.002846, loss_ce: 0.001187
2021-12-10 14:54:14,395 iteration 5354 : loss : 0.002146, loss_ce: 0.001175
2021-12-10 14:54:14,395 Training Data Eval:
2021-12-10 14:54:28,917   Average segmentation loss on training set: 0.0024
2021-12-10 14:54:28,917 Validation Data Eval:
2021-12-10 14:54:34,134   Average segmentation loss on validation set: 0.1358
2021-12-10 14:54:36,753 iteration 5355 : loss : 0.002814, loss_ce: 0.000798
 79%|█████████████████████▎     | 315/400 [4:27:59<1:14:12, 52.38s/it]2021-12-10 14:54:39,441 iteration 5356 : loss : 0.002239, loss_ce: 0.000879
2021-12-10 14:54:42,207 iteration 5357 : loss : 0.003005, loss_ce: 0.001090
2021-12-10 14:54:44,817 iteration 5358 : loss : 0.002525, loss_ce: 0.001038
2021-12-10 14:54:47,415 iteration 5359 : loss : 0.002318, loss_ce: 0.000887
2021-12-10 14:54:50,037 iteration 5360 : loss : 0.002997, loss_ce: 0.001146
2021-12-10 14:54:52,802 iteration 5361 : loss : 0.001986, loss_ce: 0.000835
2021-12-10 14:54:55,399 iteration 5362 : loss : 0.002239, loss_ce: 0.000694
2021-12-10 14:54:58,118 iteration 5363 : loss : 0.002551, loss_ce: 0.000992
2021-12-10 14:55:00,720 iteration 5364 : loss : 0.002263, loss_ce: 0.000955
2021-12-10 14:55:03,334 iteration 5365 : loss : 0.002120, loss_ce: 0.001081
2021-12-10 14:55:05,988 iteration 5366 : loss : 0.002640, loss_ce: 0.000876
2021-12-10 14:55:08,608 iteration 5367 : loss : 0.002537, loss_ce: 0.000885
2021-12-10 14:55:11,238 iteration 5368 : loss : 0.001912, loss_ce: 0.000712
2021-12-10 14:55:13,861 iteration 5369 : loss : 0.002763, loss_ce: 0.001430
2021-12-10 14:55:16,624 iteration 5370 : loss : 0.001802, loss_ce: 0.000789
2021-12-10 14:55:19,228 iteration 5371 : loss : 0.002315, loss_ce: 0.000756
2021-12-10 14:55:21,825 iteration 5372 : loss : 0.002350, loss_ce: 0.000893
 79%|█████████████████████▎     | 316/400 [4:28:44<1:10:15, 50.19s/it]2021-12-10 14:55:24,552 iteration 5373 : loss : 0.002405, loss_ce: 0.001197
2021-12-10 14:55:27,156 iteration 5374 : loss : 0.003113, loss_ce: 0.000814
2021-12-10 14:55:29,774 iteration 5375 : loss : 0.002081, loss_ce: 0.000709
2021-12-10 14:55:32,382 iteration 5376 : loss : 0.003099, loss_ce: 0.001076
2021-12-10 14:55:35,154 iteration 5377 : loss : 0.003853, loss_ce: 0.000867
2021-12-10 14:55:37,748 iteration 5378 : loss : 0.002165, loss_ce: 0.000711
2021-12-10 14:55:40,361 iteration 5379 : loss : 0.002407, loss_ce: 0.000998
2021-12-10 14:55:43,134 iteration 5380 : loss : 0.002870, loss_ce: 0.000851
2021-12-10 14:55:45,740 iteration 5381 : loss : 0.002928, loss_ce: 0.001821
2021-12-10 14:55:48,460 iteration 5382 : loss : 0.002391, loss_ce: 0.001200
2021-12-10 14:55:51,061 iteration 5383 : loss : 0.003233, loss_ce: 0.001413
2021-12-10 14:55:53,683 iteration 5384 : loss : 0.002538, loss_ce: 0.001298
2021-12-10 14:55:56,394 iteration 5385 : loss : 0.002544, loss_ce: 0.001184
2021-12-10 14:55:59,019 iteration 5386 : loss : 0.003095, loss_ce: 0.001189
2021-12-10 14:56:01,626 iteration 5387 : loss : 0.002252, loss_ce: 0.001264
2021-12-10 14:56:04,253 iteration 5388 : loss : 0.002392, loss_ce: 0.000845
2021-12-10 14:56:07,008 iteration 5389 : loss : 0.002556, loss_ce: 0.001062
 79%|█████████████████████▍     | 317/400 [4:29:29<1:07:20, 48.68s/it]2021-12-10 14:56:09,636 iteration 5390 : loss : 0.002654, loss_ce: 0.000967
2021-12-10 14:56:12,292 iteration 5391 : loss : 0.002590, loss_ce: 0.000848
2021-12-10 14:56:14,920 iteration 5392 : loss : 0.002587, loss_ce: 0.001267
2021-12-10 14:56:17,526 iteration 5393 : loss : 0.002739, loss_ce: 0.001163
2021-12-10 14:56:20,337 iteration 5394 : loss : 0.003718, loss_ce: 0.001525
2021-12-10 14:56:22,945 iteration 5395 : loss : 0.002084, loss_ce: 0.000924
2021-12-10 14:56:25,543 iteration 5396 : loss : 0.002440, loss_ce: 0.000880
2021-12-10 14:56:28,154 iteration 5397 : loss : 0.003117, loss_ce: 0.001224
2021-12-10 14:56:30,910 iteration 5398 : loss : 0.002220, loss_ce: 0.000969
2021-12-10 14:56:33,441 iteration 5399 : loss : 0.002195, loss_ce: 0.000929
2021-12-10 14:56:36,062 iteration 5400 : loss : 0.002890, loss_ce: 0.001487
2021-12-10 14:56:38,841 iteration 5401 : loss : 0.002293, loss_ce: 0.000706
2021-12-10 14:56:41,426 iteration 5402 : loss : 0.002120, loss_ce: 0.000923
2021-12-10 14:56:44,037 iteration 5403 : loss : 0.002750, loss_ce: 0.001057
2021-12-10 14:56:46,699 iteration 5404 : loss : 0.002079, loss_ce: 0.000852
2021-12-10 14:56:49,333 iteration 5405 : loss : 0.002284, loss_ce: 0.001158
2021-12-10 14:56:51,974 iteration 5406 : loss : 0.002272, loss_ce: 0.001136
 80%|█████████████████████▍     | 318/400 [4:30:14<1:05:00, 47.57s/it]2021-12-10 14:56:54,681 iteration 5407 : loss : 0.003206, loss_ce: 0.001591
2021-12-10 14:56:57,278 iteration 5408 : loss : 0.002578, loss_ce: 0.000770
2021-12-10 14:56:59,986 iteration 5409 : loss : 0.002576, loss_ce: 0.001095
2021-12-10 14:57:02,623 iteration 5410 : loss : 0.002067, loss_ce: 0.000832
2021-12-10 14:57:05,232 iteration 5411 : loss : 0.002684, loss_ce: 0.001084
2021-12-10 14:57:08,001 iteration 5412 : loss : 0.002328, loss_ce: 0.001005
2021-12-10 14:57:10,602 iteration 5413 : loss : 0.002020, loss_ce: 0.001009
2021-12-10 14:57:13,231 iteration 5414 : loss : 0.002469, loss_ce: 0.001355
2021-12-10 14:57:15,888 iteration 5415 : loss : 0.002241, loss_ce: 0.000866
2021-12-10 14:57:18,479 iteration 5416 : loss : 0.002269, loss_ce: 0.000851
2021-12-10 14:57:21,137 iteration 5417 : loss : 0.003057, loss_ce: 0.001138
2021-12-10 14:57:23,734 iteration 5418 : loss : 0.002509, loss_ce: 0.001001
2021-12-10 14:57:26,357 iteration 5419 : loss : 0.002175, loss_ce: 0.000959
2021-12-10 14:57:28,976 iteration 5420 : loss : 0.002330, loss_ce: 0.000961
2021-12-10 14:57:31,733 iteration 5421 : loss : 0.001979, loss_ce: 0.000796
2021-12-10 14:57:34,326 iteration 5422 : loss : 0.002475, loss_ce: 0.000999
2021-12-10 14:57:37,045 iteration 5423 : loss : 0.002345, loss_ce: 0.000804
 80%|█████████████████████▌     | 319/400 [4:30:59<1:03:12, 46.82s/it]2021-12-10 14:57:39,664 iteration 5424 : loss : 0.002243, loss_ce: 0.001074
2021-12-10 14:57:42,431 iteration 5425 : loss : 0.002432, loss_ce: 0.001073
2021-12-10 14:57:45,025 iteration 5426 : loss : 0.001919, loss_ce: 0.000878
2021-12-10 14:57:47,641 iteration 5427 : loss : 0.002245, loss_ce: 0.000895
2021-12-10 14:57:50,411 iteration 5428 : loss : 0.001870, loss_ce: 0.000491
2021-12-10 14:57:53,029 iteration 5429 : loss : 0.002604, loss_ce: 0.001222
2021-12-10 14:57:55,637 iteration 5430 : loss : 0.002540, loss_ce: 0.000995
2021-12-10 14:57:58,350 iteration 5431 : loss : 0.002389, loss_ce: 0.001030
2021-12-10 14:58:00,941 iteration 5432 : loss : 0.002375, loss_ce: 0.000892
2021-12-10 14:58:03,639 iteration 5433 : loss : 0.001938, loss_ce: 0.000599
2021-12-10 14:58:06,230 iteration 5434 : loss : 0.002244, loss_ce: 0.000951
2021-12-10 14:58:08,886 iteration 5435 : loss : 0.002318, loss_ce: 0.001067
2021-12-10 14:58:11,509 iteration 5436 : loss : 0.001902, loss_ce: 0.000770
2021-12-10 14:58:14,141 iteration 5437 : loss : 0.002173, loss_ce: 0.000723
2021-12-10 14:58:16,747 iteration 5438 : loss : 0.002274, loss_ce: 0.000927
2021-12-10 14:58:19,511 iteration 5439 : loss : 0.002414, loss_ce: 0.001188
2021-12-10 14:58:19,511 Training Data Eval:
2021-12-10 14:58:34,138   Average segmentation loss on training set: 0.0019
2021-12-10 14:58:34,138 Validation Data Eval:
2021-12-10 14:58:39,188   Average segmentation loss on validation set: 0.1312
2021-12-10 14:58:41,917 iteration 5440 : loss : 0.002125, loss_ce: 0.001040
 80%|█████████████████████▌     | 320/400 [4:32:04<1:09:38, 52.23s/it]2021-12-10 14:58:44,699 iteration 5441 : loss : 0.002164, loss_ce: 0.000834
2021-12-10 14:58:47,432 iteration 5442 : loss : 0.001633, loss_ce: 0.000714
2021-12-10 14:58:50,035 iteration 5443 : loss : 0.002059, loss_ce: 0.000949
2021-12-10 14:58:52,629 iteration 5444 : loss : 0.001887, loss_ce: 0.000700
2021-12-10 14:58:55,333 iteration 5445 : loss : 0.002114, loss_ce: 0.000988
2021-12-10 14:58:57,917 iteration 5446 : loss : 0.002253, loss_ce: 0.001035
2021-12-10 14:59:00,619 iteration 5447 : loss : 0.002494, loss_ce: 0.000900
2021-12-10 14:59:03,219 iteration 5448 : loss : 0.002399, loss_ce: 0.000795
2021-12-10 14:59:06,023 iteration 5449 : loss : 0.002548, loss_ce: 0.001420
2021-12-10 14:59:08,636 iteration 5450 : loss : 0.002786, loss_ce: 0.001331
2021-12-10 14:59:11,227 iteration 5451 : loss : 0.002576, loss_ce: 0.000832
2021-12-10 14:59:13,930 iteration 5452 : loss : 0.001970, loss_ce: 0.000636
2021-12-10 14:59:16,529 iteration 5453 : loss : 0.002133, loss_ce: 0.001085
2021-12-10 14:59:19,181 iteration 5454 : loss : 0.002751, loss_ce: 0.000795
2021-12-10 14:59:21,807 iteration 5455 : loss : 0.002449, loss_ce: 0.001080
2021-12-10 14:59:24,373 iteration 5456 : loss : 0.002255, loss_ce: 0.000967
2021-12-10 14:59:26,996 iteration 5457 : loss : 0.002186, loss_ce: 0.001052
 80%|█████████████████████▋     | 321/400 [4:32:49<1:05:56, 50.09s/it]2021-12-10 14:59:29,694 iteration 5458 : loss : 0.002671, loss_ce: 0.000888
2021-12-10 14:59:32,310 iteration 5459 : loss : 0.002884, loss_ce: 0.001464
2021-12-10 14:59:35,069 iteration 5460 : loss : 0.002558, loss_ce: 0.001176
2021-12-10 14:59:37,648 iteration 5461 : loss : 0.002564, loss_ce: 0.000898
2021-12-10 14:59:40,332 iteration 5462 : loss : 0.002357, loss_ce: 0.000950
2021-12-10 14:59:43,034 iteration 5463 : loss : 0.003081, loss_ce: 0.001452
2021-12-10 14:59:45,701 iteration 5464 : loss : 0.002899, loss_ce: 0.001441
2021-12-10 14:59:48,221 iteration 5465 : loss : 0.002983, loss_ce: 0.001236
2021-12-10 14:59:50,970 iteration 5466 : loss : 0.002794, loss_ce: 0.000780
2021-12-10 14:59:53,595 iteration 5467 : loss : 0.002272, loss_ce: 0.001189
2021-12-10 14:59:56,358 iteration 5468 : loss : 0.002302, loss_ce: 0.001075
2021-12-10 14:59:58,979 iteration 5469 : loss : 0.003101, loss_ce: 0.001168
2021-12-10 15:00:01,606 iteration 5470 : loss : 0.002557, loss_ce: 0.001102
2021-12-10 15:00:04,234 iteration 5471 : loss : 0.002559, loss_ce: 0.000774
2021-12-10 15:00:06,859 iteration 5472 : loss : 0.002346, loss_ce: 0.001214
2021-12-10 15:00:09,623 iteration 5473 : loss : 0.003095, loss_ce: 0.001019
2021-12-10 15:00:12,251 iteration 5474 : loss : 0.002630, loss_ce: 0.001259
 80%|█████████████████████▋     | 322/400 [4:33:35<1:03:13, 48.64s/it]2021-12-10 15:00:14,930 iteration 5475 : loss : 0.002034, loss_ce: 0.000840
2021-12-10 15:00:17,724 iteration 5476 : loss : 0.001933, loss_ce: 0.000772
2021-12-10 15:00:20,319 iteration 5477 : loss : 0.002395, loss_ce: 0.000803
2021-12-10 15:00:22,927 iteration 5478 : loss : 0.002045, loss_ce: 0.000771
2021-12-10 15:00:25,652 iteration 5479 : loss : 0.002326, loss_ce: 0.001090
2021-12-10 15:00:28,426 iteration 5480 : loss : 0.002439, loss_ce: 0.001045
2021-12-10 15:00:31,028 iteration 5481 : loss : 0.002223, loss_ce: 0.001113
2021-12-10 15:00:33,691 iteration 5482 : loss : 0.002619, loss_ce: 0.001261
2021-12-10 15:00:36,413 iteration 5483 : loss : 0.002888, loss_ce: 0.001546
2021-12-10 15:00:39,003 iteration 5484 : loss : 0.002600, loss_ce: 0.000965
2021-12-10 15:00:41,656 iteration 5485 : loss : 0.002444, loss_ce: 0.001029
2021-12-10 15:00:44,274 iteration 5486 : loss : 0.002364, loss_ce: 0.001201
2021-12-10 15:00:46,930 iteration 5487 : loss : 0.002250, loss_ce: 0.001055
2021-12-10 15:00:49,558 iteration 5488 : loss : 0.002676, loss_ce: 0.000892
2021-12-10 15:00:52,351 iteration 5489 : loss : 0.002760, loss_ce: 0.000926
2021-12-10 15:00:54,952 iteration 5490 : loss : 0.002458, loss_ce: 0.001160
2021-12-10 15:00:57,676 iteration 5491 : loss : 0.002795, loss_ce: 0.000967
 81%|█████████████████████▊     | 323/400 [4:34:20<1:01:10, 47.67s/it]2021-12-10 15:01:00,325 iteration 5492 : loss : 0.003096, loss_ce: 0.001031
2021-12-10 15:01:02,948 iteration 5493 : loss : 0.002839, loss_ce: 0.000948
2021-12-10 15:01:05,638 iteration 5494 : loss : 0.002416, loss_ce: 0.000844
2021-12-10 15:01:08,276 iteration 5495 : loss : 0.003078, loss_ce: 0.001065
2021-12-10 15:01:10,897 iteration 5496 : loss : 0.002611, loss_ce: 0.000921
2021-12-10 15:01:13,679 iteration 5497 : loss : 0.002352, loss_ce: 0.001062
2021-12-10 15:01:16,285 iteration 5498 : loss : 0.002148, loss_ce: 0.000968
2021-12-10 15:01:18,913 iteration 5499 : loss : 0.001809, loss_ce: 0.000912
2021-12-10 15:01:21,538 iteration 5500 : loss : 0.002463, loss_ce: 0.001251
2021-12-10 15:01:24,321 iteration 5501 : loss : 0.002745, loss_ce: 0.001370
2021-12-10 15:01:26,917 iteration 5502 : loss : 0.002450, loss_ce: 0.000968
2021-12-10 15:01:29,530 iteration 5503 : loss : 0.002399, loss_ce: 0.001059
2021-12-10 15:01:32,187 iteration 5504 : loss : 0.002654, loss_ce: 0.001044
2021-12-10 15:01:34,837 iteration 5505 : loss : 0.002822, loss_ce: 0.000724
2021-12-10 15:01:37,472 iteration 5506 : loss : 0.002747, loss_ce: 0.001203
2021-12-10 15:01:40,270 iteration 5507 : loss : 0.002574, loss_ce: 0.000989
2021-12-10 15:01:42,880 iteration 5508 : loss : 0.002718, loss_ce: 0.001488
 81%|███████████████████████▍     | 324/400 [4:35:05<59:26, 46.93s/it]2021-12-10 15:01:45,494 iteration 5509 : loss : 0.002615, loss_ce: 0.001229
2021-12-10 15:01:48,282 iteration 5510 : loss : 0.002212, loss_ce: 0.000866
2021-12-10 15:01:50,878 iteration 5511 : loss : 0.002108, loss_ce: 0.000712
2021-12-10 15:01:53,498 iteration 5512 : loss : 0.002409, loss_ce: 0.000703
2021-12-10 15:01:56,158 iteration 5513 : loss : 0.001850, loss_ce: 0.000766
2021-12-10 15:01:58,938 iteration 5514 : loss : 0.002476, loss_ce: 0.001131
2021-12-10 15:02:01,559 iteration 5515 : loss : 0.002108, loss_ce: 0.000890
2021-12-10 15:02:04,178 iteration 5516 : loss : 0.003161, loss_ce: 0.001064
2021-12-10 15:02:06,928 iteration 5517 : loss : 0.002408, loss_ce: 0.001067
2021-12-10 15:02:09,535 iteration 5518 : loss : 0.002166, loss_ce: 0.000910
2021-12-10 15:02:12,194 iteration 5519 : loss : 0.002984, loss_ce: 0.001277
2021-12-10 15:02:14,807 iteration 5520 : loss : 0.002010, loss_ce: 0.001029
2021-12-10 15:02:17,441 iteration 5521 : loss : 0.002622, loss_ce: 0.000985
2021-12-10 15:02:20,167 iteration 5522 : loss : 0.002491, loss_ce: 0.001006
2021-12-10 15:02:22,788 iteration 5523 : loss : 0.002193, loss_ce: 0.000893
2021-12-10 15:02:25,413 iteration 5524 : loss : 0.002595, loss_ce: 0.001287
2021-12-10 15:02:25,413 Training Data Eval:
2021-12-10 15:02:40,150   Average segmentation loss on training set: 0.0023
2021-12-10 15:02:40,150 Validation Data Eval:
2021-12-10 15:02:45,347   Average segmentation loss on validation set: 0.1321
2021-12-10 15:02:47,974 iteration 5525 : loss : 0.002864, loss_ce: 0.001168
 81%|█████████████████████▉     | 325/400 [4:36:10<1:05:28, 52.38s/it]2021-12-10 15:02:50,627 iteration 5526 : loss : 0.002385, loss_ce: 0.000906
2021-12-10 15:02:53,389 iteration 5527 : loss : 0.002338, loss_ce: 0.000596
2021-12-10 15:02:56,021 iteration 5528 : loss : 0.002162, loss_ce: 0.000826
2021-12-10 15:02:58,588 iteration 5529 : loss : 0.002476, loss_ce: 0.000631
2021-12-10 15:03:01,335 iteration 5530 : loss : 0.002683, loss_ce: 0.001067
2021-12-10 15:03:03,961 iteration 5531 : loss : 0.002576, loss_ce: 0.001414
2021-12-10 15:03:06,575 iteration 5532 : loss : 0.003620, loss_ce: 0.000527
2021-12-10 15:03:09,206 iteration 5533 : loss : 0.002622, loss_ce: 0.001061
2021-12-10 15:03:11,965 iteration 5534 : loss : 0.002808, loss_ce: 0.001300
2021-12-10 15:03:14,559 iteration 5535 : loss : 0.003385, loss_ce: 0.001523
2021-12-10 15:03:17,182 iteration 5536 : loss : 0.002719, loss_ce: 0.001122
2021-12-10 15:03:19,948 iteration 5537 : loss : 0.003094, loss_ce: 0.001266
2021-12-10 15:03:22,579 iteration 5538 : loss : 0.003465, loss_ce: 0.002012
2021-12-10 15:03:25,287 iteration 5539 : loss : 0.002389, loss_ce: 0.000788
2021-12-10 15:03:27,956 iteration 5540 : loss : 0.002766, loss_ce: 0.001285
2021-12-10 15:03:30,572 iteration 5541 : loss : 0.002722, loss_ce: 0.000803
2021-12-10 15:03:33,230 iteration 5542 : loss : 0.002295, loss_ce: 0.000722
 82%|██████████████████████     | 326/400 [4:36:56<1:01:57, 50.24s/it]2021-12-10 15:03:35,899 iteration 5543 : loss : 0.002489, loss_ce: 0.000995
2021-12-10 15:03:38,680 iteration 5544 : loss : 0.003191, loss_ce: 0.001263
2021-12-10 15:03:41,282 iteration 5545 : loss : 0.002333, loss_ce: 0.000741
2021-12-10 15:03:43,904 iteration 5546 : loss : 0.002618, loss_ce: 0.001076
2021-12-10 15:03:46,506 iteration 5547 : loss : 0.003010, loss_ce: 0.000991
2021-12-10 15:03:49,136 iteration 5548 : loss : 0.003167, loss_ce: 0.001486
2021-12-10 15:03:51,896 iteration 5549 : loss : 0.003073, loss_ce: 0.001683
2021-12-10 15:03:54,490 iteration 5550 : loss : 0.002951, loss_ce: 0.000699
2021-12-10 15:03:57,094 iteration 5551 : loss : 0.003124, loss_ce: 0.001233
2021-12-10 15:03:59,854 iteration 5552 : loss : 0.002491, loss_ce: 0.001333
2021-12-10 15:04:02,448 iteration 5553 : loss : 0.002845, loss_ce: 0.001141
2021-12-10 15:04:05,069 iteration 5554 : loss : 0.002150, loss_ce: 0.000899
2021-12-10 15:04:07,822 iteration 5555 : loss : 0.002808, loss_ce: 0.001202
2021-12-10 15:04:10,431 iteration 5556 : loss : 0.002223, loss_ce: 0.000827
2021-12-10 15:04:13,186 iteration 5557 : loss : 0.002375, loss_ce: 0.001034
2021-12-10 15:04:15,782 iteration 5558 : loss : 0.002710, loss_ce: 0.001219
2021-12-10 15:04:18,392 iteration 5559 : loss : 0.002475, loss_ce: 0.000955
 82%|███████████████████████▋     | 327/400 [4:37:41<59:16, 48.72s/it]2021-12-10 15:04:21,160 iteration 5560 : loss : 0.002199, loss_ce: 0.000966
2021-12-10 15:04:23,834 iteration 5561 : loss : 0.002564, loss_ce: 0.000759
2021-12-10 15:04:26,420 iteration 5562 : loss : 0.002475, loss_ce: 0.000777
2021-12-10 15:04:29,109 iteration 5563 : loss : 0.002582, loss_ce: 0.000932
2021-12-10 15:04:31,757 iteration 5564 : loss : 0.002221, loss_ce: 0.001068
2021-12-10 15:04:34,477 iteration 5565 : loss : 0.002306, loss_ce: 0.001029
2021-12-10 15:04:37,071 iteration 5566 : loss : 0.002311, loss_ce: 0.001060
2021-12-10 15:04:39,673 iteration 5567 : loss : 0.002325, loss_ce: 0.001134
2021-12-10 15:04:42,324 iteration 5568 : loss : 0.002449, loss_ce: 0.001061
2021-12-10 15:04:44,940 iteration 5569 : loss : 0.001874, loss_ce: 0.000714
2021-12-10 15:04:47,684 iteration 5570 : loss : 0.002407, loss_ce: 0.000933
2021-12-10 15:04:50,275 iteration 5571 : loss : 0.002716, loss_ce: 0.000791
2021-12-10 15:04:53,042 iteration 5572 : loss : 0.002480, loss_ce: 0.001133
2021-12-10 15:04:55,636 iteration 5573 : loss : 0.002359, loss_ce: 0.001129
2021-12-10 15:04:58,252 iteration 5574 : loss : 0.002260, loss_ce: 0.000917
2021-12-10 15:05:00,871 iteration 5575 : loss : 0.003960, loss_ce: 0.001238
2021-12-10 15:05:03,618 iteration 5576 : loss : 0.003135, loss_ce: 0.001326
 82%|███████████████████████▊     | 328/400 [4:38:26<57:12, 47.67s/it]2021-12-10 15:05:06,386 iteration 5577 : loss : 0.002332, loss_ce: 0.001193
2021-12-10 15:05:08,991 iteration 5578 : loss : 0.002134, loss_ce: 0.000714
2021-12-10 15:05:11,588 iteration 5579 : loss : 0.001913, loss_ce: 0.000608
2021-12-10 15:05:14,212 iteration 5580 : loss : 0.001865, loss_ce: 0.000668
2021-12-10 15:05:17,002 iteration 5581 : loss : 0.001838, loss_ce: 0.000793
2021-12-10 15:05:19,633 iteration 5582 : loss : 0.002264, loss_ce: 0.000945
2021-12-10 15:05:22,258 iteration 5583 : loss : 0.002691, loss_ce: 0.000906
2021-12-10 15:05:24,879 iteration 5584 : loss : 0.001889, loss_ce: 0.000839
2021-12-10 15:05:27,642 iteration 5585 : loss : 0.002626, loss_ce: 0.001370
2021-12-10 15:05:30,233 iteration 5586 : loss : 0.002473, loss_ce: 0.000911
2021-12-10 15:05:32,895 iteration 5587 : loss : 0.001901, loss_ce: 0.000779
2021-12-10 15:05:35,519 iteration 5588 : loss : 0.002905, loss_ce: 0.001076
2021-12-10 15:05:38,179 iteration 5589 : loss : 0.002291, loss_ce: 0.000741
2021-12-10 15:05:40,953 iteration 5590 : loss : 0.002228, loss_ce: 0.000994
2021-12-10 15:05:43,543 iteration 5591 : loss : 0.002514, loss_ce: 0.001476
2021-12-10 15:05:46,165 iteration 5592 : loss : 0.002351, loss_ce: 0.000899
2021-12-10 15:05:48,772 iteration 5593 : loss : 0.002079, loss_ce: 0.000765
 82%|███████████████████████▊     | 329/400 [4:39:11<55:30, 46.91s/it]2021-12-10 15:05:51,469 iteration 5594 : loss : 0.002336, loss_ce: 0.001147
2021-12-10 15:05:54,121 iteration 5595 : loss : 0.002210, loss_ce: 0.000782
2021-12-10 15:05:56,723 iteration 5596 : loss : 0.001853, loss_ce: 0.000777
2021-12-10 15:05:59,318 iteration 5597 : loss : 0.002158, loss_ce: 0.001210
2021-12-10 15:06:02,088 iteration 5598 : loss : 0.002762, loss_ce: 0.000797
2021-12-10 15:06:04,688 iteration 5599 : loss : 0.002226, loss_ce: 0.001059
2021-12-10 15:06:07,280 iteration 5600 : loss : 0.002096, loss_ce: 0.000764
2021-12-10 15:06:09,937 iteration 5601 : loss : 0.002361, loss_ce: 0.000777
2021-12-10 15:06:12,529 iteration 5602 : loss : 0.001902, loss_ce: 0.001057
2021-12-10 15:06:15,156 iteration 5603 : loss : 0.002059, loss_ce: 0.001096
2021-12-10 15:06:17,783 iteration 5604 : loss : 0.001718, loss_ce: 0.000893
2021-12-10 15:06:20,410 iteration 5605 : loss : 0.002416, loss_ce: 0.000840
2021-12-10 15:06:23,118 iteration 5606 : loss : 0.002125, loss_ce: 0.000634
2021-12-10 15:06:25,693 iteration 5607 : loss : 0.001859, loss_ce: 0.000693
2021-12-10 15:06:28,315 iteration 5608 : loss : 0.002256, loss_ce: 0.000968
2021-12-10 15:06:30,947 iteration 5609 : loss : 0.002154, loss_ce: 0.001068
2021-12-10 15:06:30,948 Training Data Eval:
2021-12-10 15:06:45,644   Average segmentation loss on training set: 0.0019
2021-12-10 15:06:45,645 Validation Data Eval:
2021-12-10 15:06:50,722   Average segmentation loss on validation set: 0.1328
2021-12-10 15:06:53,424 iteration 5610 : loss : 0.002140, loss_ce: 0.000745
 82%|██████████████████████▎    | 330/400 [4:40:16<1:00:56, 52.24s/it]2021-12-10 15:06:56,078 iteration 5611 : loss : 0.001898, loss_ce: 0.000718
2021-12-10 15:06:58,697 iteration 5612 : loss : 0.002187, loss_ce: 0.000619
2021-12-10 15:07:01,359 iteration 5613 : loss : 0.001722, loss_ce: 0.000792
2021-12-10 15:07:03,977 iteration 5614 : loss : 0.002013, loss_ce: 0.000917
2021-12-10 15:07:06,634 iteration 5615 : loss : 0.003230, loss_ce: 0.001037
2021-12-10 15:07:09,292 iteration 5616 : loss : 0.002505, loss_ce: 0.001146
2021-12-10 15:07:11,926 iteration 5617 : loss : 0.002021, loss_ce: 0.000715
2021-12-10 15:07:14,561 iteration 5618 : loss : 0.001772, loss_ce: 0.000794
2021-12-10 15:07:17,270 iteration 5619 : loss : 0.002281, loss_ce: 0.001137
2021-12-10 15:07:19,965 iteration 5620 : loss : 0.002172, loss_ce: 0.000805
2021-12-10 15:07:22,562 iteration 5621 : loss : 0.001814, loss_ce: 0.000880
2021-12-10 15:07:25,193 iteration 5622 : loss : 0.002178, loss_ce: 0.000945
2021-12-10 15:07:27,960 iteration 5623 : loss : 0.002103, loss_ce: 0.001023
2021-12-10 15:07:30,573 iteration 5624 : loss : 0.003281, loss_ce: 0.000861
2021-12-10 15:07:33,208 iteration 5625 : loss : 0.001826, loss_ce: 0.000687
2021-12-10 15:07:35,825 iteration 5626 : loss : 0.002103, loss_ce: 0.001201
2021-12-10 15:07:38,450 iteration 5627 : loss : 0.002732, loss_ce: 0.001365
 83%|███████████████████████▉     | 331/400 [4:41:01<57:35, 50.07s/it]2021-12-10 15:07:41,215 iteration 5628 : loss : 0.001754, loss_ce: 0.000656
2021-12-10 15:07:43,843 iteration 5629 : loss : 0.002298, loss_ce: 0.000917
2021-12-10 15:07:46,457 iteration 5630 : loss : 0.001992, loss_ce: 0.000768
2021-12-10 15:07:49,210 iteration 5631 : loss : 0.001870, loss_ce: 0.000855
2021-12-10 15:07:51,812 iteration 5632 : loss : 0.002145, loss_ce: 0.001108
2021-12-10 15:07:54,427 iteration 5633 : loss : 0.002156, loss_ce: 0.001251
2021-12-10 15:07:57,028 iteration 5634 : loss : 0.001990, loss_ce: 0.000785
2021-12-10 15:07:59,809 iteration 5635 : loss : 0.001910, loss_ce: 0.001052
2021-12-10 15:08:02,400 iteration 5636 : loss : 0.001863, loss_ce: 0.000789
2021-12-10 15:08:05,026 iteration 5637 : loss : 0.003145, loss_ce: 0.000746
2021-12-10 15:08:07,720 iteration 5638 : loss : 0.001839, loss_ce: 0.000875
2021-12-10 15:08:10,299 iteration 5639 : loss : 0.002048, loss_ce: 0.001048
2021-12-10 15:08:12,916 iteration 5640 : loss : 0.002371, loss_ce: 0.000630
2021-12-10 15:08:15,578 iteration 5641 : loss : 0.002353, loss_ce: 0.000835
2021-12-10 15:08:18,195 iteration 5642 : loss : 0.002389, loss_ce: 0.000771
2021-12-10 15:08:20,818 iteration 5643 : loss : 0.002449, loss_ce: 0.000814
2021-12-10 15:08:23,446 iteration 5644 : loss : 0.002351, loss_ce: 0.000882
 83%|████████████████████████     | 332/400 [4:41:46<55:01, 48.55s/it]2021-12-10 15:08:26,216 iteration 5645 : loss : 0.002529, loss_ce: 0.001086
2021-12-10 15:08:28,819 iteration 5646 : loss : 0.002216, loss_ce: 0.000996
2021-12-10 15:08:31,442 iteration 5647 : loss : 0.001996, loss_ce: 0.001044
2021-12-10 15:08:34,063 iteration 5648 : loss : 0.001934, loss_ce: 0.000754
2021-12-10 15:08:36,687 iteration 5649 : loss : 0.002542, loss_ce: 0.001385
2021-12-10 15:08:39,487 iteration 5650 : loss : 0.002149, loss_ce: 0.001229
2021-12-10 15:08:42,095 iteration 5651 : loss : 0.001525, loss_ce: 0.000545
2021-12-10 15:08:44,693 iteration 5652 : loss : 0.001819, loss_ce: 0.000812
2021-12-10 15:08:47,326 iteration 5653 : loss : 0.002221, loss_ce: 0.000896
2021-12-10 15:08:49,955 iteration 5654 : loss : 0.002809, loss_ce: 0.000761
2021-12-10 15:08:52,775 iteration 5655 : loss : 0.002386, loss_ce: 0.000866
2021-12-10 15:08:55,379 iteration 5656 : loss : 0.002387, loss_ce: 0.001312
2021-12-10 15:08:57,974 iteration 5657 : loss : 0.001674, loss_ce: 0.000585
2021-12-10 15:09:00,566 iteration 5658 : loss : 0.002537, loss_ce: 0.000756
2021-12-10 15:09:03,339 iteration 5659 : loss : 0.002615, loss_ce: 0.000865
2021-12-10 15:09:05,953 iteration 5660 : loss : 0.002029, loss_ce: 0.001053
2021-12-10 15:09:08,587 iteration 5661 : loss : 0.001914, loss_ce: 0.000946
 83%|████████████████████████▏    | 333/400 [4:42:31<53:04, 47.53s/it]2021-12-10 15:09:11,190 iteration 5662 : loss : 0.002260, loss_ce: 0.001150
2021-12-10 15:09:13,850 iteration 5663 : loss : 0.002291, loss_ce: 0.001225
2021-12-10 15:09:16,439 iteration 5664 : loss : 0.002020, loss_ce: 0.001046
2021-12-10 15:09:19,044 iteration 5665 : loss : 0.001979, loss_ce: 0.000771
2021-12-10 15:09:21,804 iteration 5666 : loss : 0.003102, loss_ce: 0.001184
2021-12-10 15:09:24,397 iteration 5667 : loss : 0.001922, loss_ce: 0.000543
2021-12-10 15:09:27,079 iteration 5668 : loss : 0.002124, loss_ce: 0.000668
2021-12-10 15:09:29,673 iteration 5669 : loss : 0.003148, loss_ce: 0.001654
2021-12-10 15:09:32,304 iteration 5670 : loss : 0.002112, loss_ce: 0.000904
2021-12-10 15:09:34,882 iteration 5671 : loss : 0.002520, loss_ce: 0.001144
2021-12-10 15:09:37,514 iteration 5672 : loss : 0.002587, loss_ce: 0.001046
2021-12-10 15:09:40,311 iteration 5673 : loss : 0.003231, loss_ce: 0.001036
2021-12-10 15:09:42,920 iteration 5674 : loss : 0.001815, loss_ce: 0.000640
2021-12-10 15:09:45,535 iteration 5675 : loss : 0.002443, loss_ce: 0.001007
2021-12-10 15:09:48,134 iteration 5676 : loss : 0.002260, loss_ce: 0.001067
2021-12-10 15:09:50,746 iteration 5677 : loss : 0.002255, loss_ce: 0.000907
2021-12-10 15:09:53,346 iteration 5678 : loss : 0.001833, loss_ce: 0.000834
 84%|████████████████████████▏    | 334/400 [4:43:16<51:21, 46.70s/it]2021-12-10 15:09:56,020 iteration 5679 : loss : 0.002830, loss_ce: 0.000816
2021-12-10 15:09:58,631 iteration 5680 : loss : 0.002286, loss_ce: 0.001159
2021-12-10 15:10:01,428 iteration 5681 : loss : 0.001849, loss_ce: 0.000845
2021-12-10 15:10:04,028 iteration 5682 : loss : 0.002387, loss_ce: 0.001073
2021-12-10 15:10:06,606 iteration 5683 : loss : 0.002189, loss_ce: 0.000827
2021-12-10 15:10:09,225 iteration 5684 : loss : 0.002244, loss_ce: 0.000926
2021-12-10 15:10:11,985 iteration 5685 : loss : 0.002241, loss_ce: 0.000685
2021-12-10 15:10:14,584 iteration 5686 : loss : 0.002030, loss_ce: 0.001009
2021-12-10 15:10:17,201 iteration 5687 : loss : 0.002803, loss_ce: 0.001119
2021-12-10 15:10:19,850 iteration 5688 : loss : 0.002530, loss_ce: 0.001367
2021-12-10 15:10:22,471 iteration 5689 : loss : 0.002713, loss_ce: 0.000813
2021-12-10 15:10:25,174 iteration 5690 : loss : 0.002812, loss_ce: 0.000889
2021-12-10 15:10:27,759 iteration 5691 : loss : 0.002197, loss_ce: 0.000740
2021-12-10 15:10:30,428 iteration 5692 : loss : 0.002366, loss_ce: 0.000852
2021-12-10 15:10:33,026 iteration 5693 : loss : 0.002357, loss_ce: 0.001259
2021-12-10 15:10:35,652 iteration 5694 : loss : 0.002405, loss_ce: 0.001088
2021-12-10 15:10:35,652 Training Data Eval:
2021-12-10 15:10:50,400   Average segmentation loss on training set: 0.0023
2021-12-10 15:10:50,400 Validation Data Eval:
2021-12-10 15:10:55,572   Average segmentation loss on validation set: 0.1506
2021-12-10 15:10:58,196 iteration 5695 : loss : 0.002059, loss_ce: 0.000952
 84%|████████████████████████▎    | 335/400 [4:44:21<56:29, 52.14s/it]2021-12-10 15:11:00,942 iteration 5696 : loss : 0.002602, loss_ce: 0.000807
2021-12-10 15:11:03,526 iteration 5697 : loss : 0.002205, loss_ce: 0.000672
2021-12-10 15:11:06,209 iteration 5698 : loss : 0.002101, loss_ce: 0.000802
2021-12-10 15:11:08,771 iteration 5699 : loss : 0.002080, loss_ce: 0.000907
2021-12-10 15:11:11,392 iteration 5700 : loss : 0.001873, loss_ce: 0.000643
2021-12-10 15:11:14,161 iteration 5701 : loss : 0.002323, loss_ce: 0.001295
2021-12-10 15:11:16,754 iteration 5702 : loss : 0.001893, loss_ce: 0.000803
2021-12-10 15:11:19,363 iteration 5703 : loss : 0.001947, loss_ce: 0.000455
2021-12-10 15:11:22,144 iteration 5704 : loss : 0.002249, loss_ce: 0.001096
2021-12-10 15:11:24,739 iteration 5705 : loss : 0.002480, loss_ce: 0.000788
2021-12-10 15:11:27,358 iteration 5706 : loss : 0.001993, loss_ce: 0.000814
2021-12-10 15:11:30,059 iteration 5707 : loss : 0.002390, loss_ce: 0.001004
2021-12-10 15:11:32,655 iteration 5708 : loss : 0.002605, loss_ce: 0.000937
2021-12-10 15:11:35,436 iteration 5709 : loss : 0.003040, loss_ce: 0.001412
2021-12-10 15:11:38,039 iteration 5710 : loss : 0.001614, loss_ce: 0.000777
2021-12-10 15:11:40,611 iteration 5711 : loss : 0.001954, loss_ce: 0.001012
2021-12-10 15:11:43,200 iteration 5712 : loss : 0.002189, loss_ce: 0.001120
 84%|████████████████████████▎    | 336/400 [4:45:06<53:20, 50.00s/it]2021-12-10 15:11:45,860 iteration 5713 : loss : 0.002369, loss_ce: 0.000781
2021-12-10 15:11:48,512 iteration 5714 : loss : 0.002412, loss_ce: 0.001027
2021-12-10 15:11:51,159 iteration 5715 : loss : 0.002064, loss_ce: 0.001030
2021-12-10 15:11:53,808 iteration 5716 : loss : 0.002992, loss_ce: 0.000994
2021-12-10 15:11:56,470 iteration 5717 : loss : 0.002195, loss_ce: 0.001159
2021-12-10 15:11:59,093 iteration 5718 : loss : 0.001729, loss_ce: 0.000770
2021-12-10 15:12:01,877 iteration 5719 : loss : 0.002330, loss_ce: 0.000865
2021-12-10 15:12:04,483 iteration 5720 : loss : 0.002150, loss_ce: 0.000959
2021-12-10 15:12:07,190 iteration 5721 : loss : 0.002220, loss_ce: 0.000960
2021-12-10 15:12:09,788 iteration 5722 : loss : 0.002085, loss_ce: 0.000841
2021-12-10 15:12:12,449 iteration 5723 : loss : 0.001936, loss_ce: 0.000923
2021-12-10 15:12:15,061 iteration 5724 : loss : 0.002789, loss_ce: 0.000948
2021-12-10 15:12:17,670 iteration 5725 : loss : 0.002182, loss_ce: 0.001062
2021-12-10 15:12:20,430 iteration 5726 : loss : 0.001551, loss_ce: 0.000704
2021-12-10 15:12:23,035 iteration 5727 : loss : 0.002206, loss_ce: 0.000808
2021-12-10 15:12:25,685 iteration 5728 : loss : 0.002225, loss_ce: 0.000885
2021-12-10 15:12:28,279 iteration 5729 : loss : 0.002254, loss_ce: 0.001059
 84%|████████████████████████▍    | 337/400 [4:45:51<50:57, 48.52s/it]2021-12-10 15:12:31,025 iteration 5730 : loss : 0.001931, loss_ce: 0.000667
2021-12-10 15:12:33,630 iteration 5731 : loss : 0.002241, loss_ce: 0.001179
2021-12-10 15:12:36,228 iteration 5732 : loss : 0.001970, loss_ce: 0.000774
2021-12-10 15:12:38,882 iteration 5733 : loss : 0.002123, loss_ce: 0.000912
2021-12-10 15:12:41,533 iteration 5734 : loss : 0.001851, loss_ce: 0.000761
2021-12-10 15:12:44,144 iteration 5735 : loss : 0.002505, loss_ce: 0.001228
2021-12-10 15:12:46,799 iteration 5736 : loss : 0.002838, loss_ce: 0.000516
2021-12-10 15:12:49,438 iteration 5737 : loss : 0.002442, loss_ce: 0.001028
2021-12-10 15:12:52,054 iteration 5738 : loss : 0.002263, loss_ce: 0.000896
2021-12-10 15:12:54,807 iteration 5739 : loss : 0.002143, loss_ce: 0.001023
2021-12-10 15:12:57,508 iteration 5740 : loss : 0.002639, loss_ce: 0.001180
2021-12-10 15:13:00,109 iteration 5741 : loss : 0.002236, loss_ce: 0.000737
2021-12-10 15:13:02,897 iteration 5742 : loss : 0.002276, loss_ce: 0.001442
2021-12-10 15:13:05,495 iteration 5743 : loss : 0.001955, loss_ce: 0.000732
2021-12-10 15:13:08,158 iteration 5744 : loss : 0.002330, loss_ce: 0.001192
2021-12-10 15:13:10,779 iteration 5745 : loss : 0.001904, loss_ce: 0.000781
2021-12-10 15:13:13,559 iteration 5746 : loss : 0.003426, loss_ce: 0.000923
 84%|████████████████████████▌    | 338/400 [4:46:36<49:08, 47.55s/it]2021-12-10 15:13:16,201 iteration 5747 : loss : 0.002858, loss_ce: 0.001226
2021-12-10 15:13:18,830 iteration 5748 : loss : 0.002179, loss_ce: 0.000712
2021-12-10 15:13:21,442 iteration 5749 : loss : 0.002425, loss_ce: 0.001024
2021-12-10 15:13:24,099 iteration 5750 : loss : 0.002240, loss_ce: 0.000950
2021-12-10 15:13:26,726 iteration 5751 : loss : 0.002560, loss_ce: 0.001023
2021-12-10 15:13:29,515 iteration 5752 : loss : 0.002276, loss_ce: 0.000884
2021-12-10 15:13:32,118 iteration 5753 : loss : 0.002151, loss_ce: 0.001197
2021-12-10 15:13:34,782 iteration 5754 : loss : 0.001915, loss_ce: 0.000659
2021-12-10 15:13:37,402 iteration 5755 : loss : 0.001754, loss_ce: 0.000774
2021-12-10 15:13:40,182 iteration 5756 : loss : 0.002571, loss_ce: 0.001103
2021-12-10 15:13:42,786 iteration 5757 : loss : 0.001421, loss_ce: 0.000688
2021-12-10 15:13:45,431 iteration 5758 : loss : 0.002217, loss_ce: 0.001219
2021-12-10 15:13:48,054 iteration 5759 : loss : 0.001740, loss_ce: 0.000874
2021-12-10 15:13:50,709 iteration 5760 : loss : 0.002127, loss_ce: 0.000778
2021-12-10 15:13:53,336 iteration 5761 : loss : 0.003146, loss_ce: 0.001009
2021-12-10 15:13:55,945 iteration 5762 : loss : 0.001858, loss_ce: 0.000670
2021-12-10 15:13:58,758 iteration 5763 : loss : 0.002453, loss_ce: 0.000587
 85%|████████████████████████▌    | 339/400 [4:47:21<47:37, 46.84s/it]2021-12-10 15:14:01,399 iteration 5764 : loss : 0.001744, loss_ce: 0.000704
2021-12-10 15:14:03,986 iteration 5765 : loss : 0.002477, loss_ce: 0.000721
2021-12-10 15:14:06,717 iteration 5766 : loss : 0.002191, loss_ce: 0.000852
2021-12-10 15:14:09,479 iteration 5767 : loss : 0.002834, loss_ce: 0.001184
2021-12-10 15:14:12,097 iteration 5768 : loss : 0.001902, loss_ce: 0.001077
2021-12-10 15:14:14,713 iteration 5769 : loss : 0.001901, loss_ce: 0.000806
2021-12-10 15:14:17,417 iteration 5770 : loss : 0.002170, loss_ce: 0.001201
2021-12-10 15:14:20,127 iteration 5771 : loss : 0.002288, loss_ce: 0.001039
2021-12-10 15:14:22,877 iteration 5772 : loss : 0.002352, loss_ce: 0.000909
2021-12-10 15:14:25,497 iteration 5773 : loss : 0.002373, loss_ce: 0.000823
2021-12-10 15:14:28,162 iteration 5774 : loss : 0.001666, loss_ce: 0.000592
2021-12-10 15:14:30,790 iteration 5775 : loss : 0.001734, loss_ce: 0.000744
2021-12-10 15:14:33,592 iteration 5776 : loss : 0.002078, loss_ce: 0.000902
2021-12-10 15:14:36,166 iteration 5777 : loss : 0.002189, loss_ce: 0.000948
2021-12-10 15:14:38,874 iteration 5778 : loss : 0.002321, loss_ce: 0.000956
2021-12-10 15:14:41,548 iteration 5779 : loss : 0.001973, loss_ce: 0.000699
2021-12-10 15:14:41,548 Training Data Eval:
2021-12-10 15:14:56,252   Average segmentation loss on training set: 0.0019
2021-12-10 15:14:56,252 Validation Data Eval:
2021-12-10 15:15:01,370   Average segmentation loss on validation set: 0.1405
2021-12-10 15:15:04,156 iteration 5780 : loss : 0.001833, loss_ce: 0.000828
 85%|████████████████████████▋    | 340/400 [4:48:26<52:24, 52.41s/it]2021-12-10 15:15:06,805 iteration 5781 : loss : 0.001738, loss_ce: 0.000877
2021-12-10 15:15:09,395 iteration 5782 : loss : 0.001759, loss_ce: 0.000813
2021-12-10 15:15:12,010 iteration 5783 : loss : 0.002133, loss_ce: 0.000884
2021-12-10 15:15:14,795 iteration 5784 : loss : 0.002023, loss_ce: 0.000796
2021-12-10 15:15:17,399 iteration 5785 : loss : 0.002162, loss_ce: 0.000749
2021-12-10 15:15:20,054 iteration 5786 : loss : 0.002260, loss_ce: 0.001036
2021-12-10 15:15:22,712 iteration 5787 : loss : 0.001805, loss_ce: 0.000731
2021-12-10 15:15:25,333 iteration 5788 : loss : 0.002215, loss_ce: 0.000681
2021-12-10 15:15:28,116 iteration 5789 : loss : 0.001714, loss_ce: 0.000686
2021-12-10 15:15:30,718 iteration 5790 : loss : 0.002349, loss_ce: 0.001087
2021-12-10 15:15:33,312 iteration 5791 : loss : 0.001618, loss_ce: 0.000815
2021-12-10 15:15:35,977 iteration 5792 : loss : 0.001945, loss_ce: 0.001018
2021-12-10 15:15:38,607 iteration 5793 : loss : 0.001885, loss_ce: 0.000794
2021-12-10 15:15:41,398 iteration 5794 : loss : 0.002012, loss_ce: 0.000803
2021-12-10 15:15:44,003 iteration 5795 : loss : 0.001825, loss_ce: 0.000884
2021-12-10 15:15:46,626 iteration 5796 : loss : 0.001559, loss_ce: 0.000578
2021-12-10 15:15:49,406 iteration 5797 : loss : 0.002016, loss_ce: 0.000695
 85%|████████████████████████▋    | 341/400 [4:49:12<49:25, 50.26s/it]2021-12-10 15:15:52,041 iteration 5798 : loss : 0.002053, loss_ce: 0.000785
2021-12-10 15:15:54,711 iteration 5799 : loss : 0.001850, loss_ce: 0.000775
2021-12-10 15:15:57,338 iteration 5800 : loss : 0.002139, loss_ce: 0.000773
2021-12-10 15:15:59,957 iteration 5801 : loss : 0.001823, loss_ce: 0.000538
2021-12-10 15:16:02,730 iteration 5802 : loss : 0.001689, loss_ce: 0.000709
2021-12-10 15:16:05,332 iteration 5803 : loss : 0.002246, loss_ce: 0.001190
2021-12-10 15:16:07,977 iteration 5804 : loss : 0.001624, loss_ce: 0.000698
2021-12-10 15:16:10,593 iteration 5805 : loss : 0.002038, loss_ce: 0.000720
2021-12-10 15:16:13,367 iteration 5806 : loss : 0.002126, loss_ce: 0.000741
2021-12-10 15:16:15,961 iteration 5807 : loss : 0.001503, loss_ce: 0.000644
2021-12-10 15:16:18,619 iteration 5808 : loss : 0.001898, loss_ce: 0.000844
2021-12-10 15:16:21,244 iteration 5809 : loss : 0.001703, loss_ce: 0.000712
2021-12-10 15:16:24,023 iteration 5810 : loss : 0.002225, loss_ce: 0.000933
2021-12-10 15:16:26,629 iteration 5811 : loss : 0.001948, loss_ce: 0.000911
2021-12-10 15:16:29,243 iteration 5812 : loss : 0.001960, loss_ce: 0.000813
2021-12-10 15:16:32,014 iteration 5813 : loss : 0.001870, loss_ce: 0.000884
2021-12-10 15:16:34,631 iteration 5814 : loss : 0.001877, loss_ce: 0.000887
 86%|████████████████████████▊    | 342/400 [4:49:57<47:07, 48.75s/it]2021-12-10 15:16:37,292 iteration 5815 : loss : 0.003603, loss_ce: 0.001118
2021-12-10 15:16:39,910 iteration 5816 : loss : 0.001799, loss_ce: 0.000730
2021-12-10 15:16:42,656 iteration 5817 : loss : 0.002079, loss_ce: 0.001138
2021-12-10 15:16:45,277 iteration 5818 : loss : 0.001936, loss_ce: 0.000842
2021-12-10 15:16:48,045 iteration 5819 : loss : 0.001999, loss_ce: 0.000922
2021-12-10 15:16:50,640 iteration 5820 : loss : 0.001739, loss_ce: 0.000638
2021-12-10 15:16:53,376 iteration 5821 : loss : 0.002401, loss_ce: 0.001014
2021-12-10 15:16:55,968 iteration 5822 : loss : 0.001690, loss_ce: 0.000467
2021-12-10 15:16:58,592 iteration 5823 : loss : 0.001720, loss_ce: 0.000717
2021-12-10 15:17:01,205 iteration 5824 : loss : 0.001889, loss_ce: 0.000833
2021-12-10 15:17:03,970 iteration 5825 : loss : 0.001772, loss_ce: 0.000659
2021-12-10 15:17:06,570 iteration 5826 : loss : 0.001836, loss_ce: 0.000631
2021-12-10 15:17:09,184 iteration 5827 : loss : 0.002718, loss_ce: 0.000937
2021-12-10 15:17:11,955 iteration 5828 : loss : 0.001592, loss_ce: 0.000806
2021-12-10 15:17:14,570 iteration 5829 : loss : 0.001936, loss_ce: 0.000972
2021-12-10 15:17:17,184 iteration 5830 : loss : 0.002085, loss_ce: 0.001130
2021-12-10 15:17:19,946 iteration 5831 : loss : 0.002063, loss_ce: 0.001045
 86%|████████████████████████▊    | 343/400 [4:50:42<45:20, 47.73s/it]2021-12-10 15:17:22,577 iteration 5832 : loss : 0.002047, loss_ce: 0.000908
2021-12-10 15:17:25,200 iteration 5833 : loss : 0.002738, loss_ce: 0.000696
2021-12-10 15:17:27,972 iteration 5834 : loss : 0.002444, loss_ce: 0.000770
2021-12-10 15:17:30,596 iteration 5835 : loss : 0.002177, loss_ce: 0.000589
2021-12-10 15:17:33,214 iteration 5836 : loss : 0.002002, loss_ce: 0.000879
2021-12-10 15:17:35,971 iteration 5837 : loss : 0.002092, loss_ce: 0.001057
2021-12-10 15:17:38,563 iteration 5838 : loss : 0.002264, loss_ce: 0.000921
2021-12-10 15:17:41,298 iteration 5839 : loss : 0.001932, loss_ce: 0.000660
2021-12-10 15:17:43,930 iteration 5840 : loss : 0.002049, loss_ce: 0.000987
2021-12-10 15:17:46,548 iteration 5841 : loss : 0.002347, loss_ce: 0.001510
2021-12-10 15:17:49,302 iteration 5842 : loss : 0.001777, loss_ce: 0.000653
2021-12-10 15:17:51,930 iteration 5843 : loss : 0.001743, loss_ce: 0.000780
2021-12-10 15:17:54,555 iteration 5844 : loss : 0.002051, loss_ce: 0.000987
2021-12-10 15:17:57,163 iteration 5845 : loss : 0.002172, loss_ce: 0.000920
2021-12-10 15:17:59,930 iteration 5846 : loss : 0.001775, loss_ce: 0.000761
2021-12-10 15:18:02,537 iteration 5847 : loss : 0.001796, loss_ce: 0.000686
2021-12-10 15:18:05,205 iteration 5848 : loss : 0.002001, loss_ce: 0.000822
 86%|████████████████████████▉    | 344/400 [4:51:28<43:51, 46.99s/it]2021-12-10 15:18:07,864 iteration 5849 : loss : 0.001611, loss_ce: 0.000876
2021-12-10 15:18:10,467 iteration 5850 : loss : 0.001840, loss_ce: 0.000953
2021-12-10 15:18:13,241 iteration 5851 : loss : 0.002956, loss_ce: 0.000769
2021-12-10 15:18:15,868 iteration 5852 : loss : 0.001872, loss_ce: 0.000713
2021-12-10 15:18:18,490 iteration 5853 : loss : 0.001953, loss_ce: 0.000711
2021-12-10 15:18:21,158 iteration 5854 : loss : 0.001974, loss_ce: 0.000740
2021-12-10 15:18:23,778 iteration 5855 : loss : 0.001888, loss_ce: 0.000912
2021-12-10 15:18:26,547 iteration 5856 : loss : 0.001975, loss_ce: 0.000978
2021-12-10 15:18:29,143 iteration 5857 : loss : 0.002154, loss_ce: 0.001078
2021-12-10 15:18:31,838 iteration 5858 : loss : 0.002425, loss_ce: 0.001021
2021-12-10 15:18:34,542 iteration 5859 : loss : 0.002147, loss_ce: 0.000570
2021-12-10 15:18:37,154 iteration 5860 : loss : 0.001956, loss_ce: 0.000860
2021-12-10 15:18:39,801 iteration 5861 : loss : 0.002074, loss_ce: 0.000986
2021-12-10 15:18:42,464 iteration 5862 : loss : 0.002239, loss_ce: 0.000990
2021-12-10 15:18:45,038 iteration 5863 : loss : 0.002028, loss_ce: 0.001029
2021-12-10 15:18:47,764 iteration 5864 : loss : 0.002051, loss_ce: 0.000707
2021-12-10 15:18:47,764 Training Data Eval:
2021-12-10 15:19:02,681   Average segmentation loss on training set: 0.0018
2021-12-10 15:19:02,682 Validation Data Eval:
2021-12-10 15:19:07,874   Average segmentation loss on validation set: 0.1317
2021-12-10 15:19:10,494 iteration 5865 : loss : 0.001865, loss_ce: 0.000657
 86%|█████████████████████████    | 345/400 [4:52:33<48:06, 52.48s/it]2021-12-10 15:19:13,350 iteration 5866 : loss : 0.001664, loss_ce: 0.000570
2021-12-10 15:19:15,969 iteration 5867 : loss : 0.001944, loss_ce: 0.000889
2021-12-10 15:19:18,734 iteration 5868 : loss : 0.002170, loss_ce: 0.000847
2021-12-10 15:19:21,530 iteration 5869 : loss : 0.002299, loss_ce: 0.000843
2021-12-10 15:19:24,125 iteration 5870 : loss : 0.001406, loss_ce: 0.000524
2021-12-10 15:19:26,911 iteration 5871 : loss : 0.001587, loss_ce: 0.000669
2021-12-10 15:19:29,655 iteration 5872 : loss : 0.001904, loss_ce: 0.000765
2021-12-10 15:19:32,441 iteration 5873 : loss : 0.002289, loss_ce: 0.001050
2021-12-10 15:19:35,046 iteration 5874 : loss : 0.001582, loss_ce: 0.000624
2021-12-10 15:19:37,814 iteration 5875 : loss : 0.002715, loss_ce: 0.000912
2021-12-10 15:19:40,558 iteration 5876 : loss : 0.001513, loss_ce: 0.000735
2021-12-10 15:19:43,221 iteration 5877 : loss : 0.001969, loss_ce: 0.001034
2021-12-10 15:19:45,980 iteration 5878 : loss : 0.001741, loss_ce: 0.000947
2021-12-10 15:19:48,771 iteration 5879 : loss : 0.001583, loss_ce: 0.000601
2021-12-10 15:19:51,537 iteration 5880 : loss : 0.002431, loss_ce: 0.000877
2021-12-10 15:19:54,271 iteration 5881 : loss : 0.002284, loss_ce: 0.000739
2021-12-10 15:19:57,035 iteration 5882 : loss : 0.001860, loss_ce: 0.000947
 86%|█████████████████████████    | 346/400 [4:53:19<45:37, 50.69s/it]2021-12-10 15:19:59,730 iteration 5883 : loss : 0.001489, loss_ce: 0.000578
2021-12-10 15:20:02,606 iteration 5884 : loss : 0.001682, loss_ce: 0.000769
2021-12-10 15:20:05,395 iteration 5885 : loss : 0.002290, loss_ce: 0.000824
2021-12-10 15:20:08,139 iteration 5886 : loss : 0.001924, loss_ce: 0.000963
2021-12-10 15:20:10,898 iteration 5887 : loss : 0.001574, loss_ce: 0.000530
2021-12-10 15:20:13,664 iteration 5888 : loss : 0.001752, loss_ce: 0.000765
2021-12-10 15:20:16,391 iteration 5889 : loss : 0.001797, loss_ce: 0.000763
2021-12-10 15:20:19,168 iteration 5890 : loss : 0.002522, loss_ce: 0.001163
2021-12-10 15:20:21,905 iteration 5891 : loss : 0.002561, loss_ce: 0.000977
2021-12-10 15:20:24,657 iteration 5892 : loss : 0.001979, loss_ce: 0.000888
2021-12-10 15:20:27,398 iteration 5893 : loss : 0.002204, loss_ce: 0.000923
2021-12-10 15:20:30,116 iteration 5894 : loss : 0.001983, loss_ce: 0.000753
2021-12-10 15:20:32,836 iteration 5895 : loss : 0.002001, loss_ce: 0.000804
2021-12-10 15:20:35,580 iteration 5896 : loss : 0.001902, loss_ce: 0.000839
2021-12-10 15:20:38,325 iteration 5897 : loss : 0.001994, loss_ce: 0.000993
2021-12-10 15:20:41,047 iteration 5898 : loss : 0.001730, loss_ce: 0.000778
2021-12-10 15:20:43,816 iteration 5899 : loss : 0.002044, loss_ce: 0.000714
 87%|█████████████████████████▏   | 347/400 [4:54:06<43:44, 49.52s/it]2021-12-10 15:20:46,621 iteration 5900 : loss : 0.002659, loss_ce: 0.000668
2021-12-10 15:20:49,504 iteration 5901 : loss : 0.001735, loss_ce: 0.000867
2021-12-10 15:20:52,223 iteration 5902 : loss : 0.002103, loss_ce: 0.000611
2021-12-10 15:20:54,942 iteration 5903 : loss : 0.002165, loss_ce: 0.000822
2021-12-10 15:20:57,684 iteration 5904 : loss : 0.002482, loss_ce: 0.000813
2021-12-10 15:21:00,562 iteration 5905 : loss : 0.002148, loss_ce: 0.000850
2021-12-10 15:21:03,285 iteration 5906 : loss : 0.001771, loss_ce: 0.000687
2021-12-10 15:21:06,188 iteration 5907 : loss : 0.002203, loss_ce: 0.000978
2021-12-10 15:21:08,928 iteration 5908 : loss : 0.002724, loss_ce: 0.000689
2021-12-10 15:21:11,807 iteration 5909 : loss : 0.001927, loss_ce: 0.000556
2021-12-10 15:21:14,551 iteration 5910 : loss : 0.002250, loss_ce: 0.001365
2021-12-10 15:21:17,275 iteration 5911 : loss : 0.002206, loss_ce: 0.000920
2021-12-10 15:21:20,023 iteration 5912 : loss : 0.001611, loss_ce: 0.000704
2021-12-10 15:21:22,752 iteration 5913 : loss : 0.001757, loss_ce: 0.000671
2021-12-10 15:21:25,471 iteration 5914 : loss : 0.002028, loss_ce: 0.001036
2021-12-10 15:21:28,239 iteration 5915 : loss : 0.002034, loss_ce: 0.001215
2021-12-10 15:21:31,093 iteration 5916 : loss : 0.002212, loss_ce: 0.001151
 87%|█████████████████████████▏   | 348/400 [4:54:53<42:20, 48.85s/it]2021-12-10 15:21:33,880 iteration 5917 : loss : 0.002288, loss_ce: 0.001188
2021-12-10 15:21:36,744 iteration 5918 : loss : 0.001889, loss_ce: 0.000803
2021-12-10 15:21:39,462 iteration 5919 : loss : 0.002429, loss_ce: 0.000899
2021-12-10 15:21:42,339 iteration 5920 : loss : 0.001969, loss_ce: 0.000819
2021-12-10 15:21:45,059 iteration 5921 : loss : 0.001919, loss_ce: 0.000985
2021-12-10 15:21:47,776 iteration 5922 : loss : 0.002235, loss_ce: 0.000662
2021-12-10 15:21:50,611 iteration 5923 : loss : 0.001730, loss_ce: 0.000747
2021-12-10 15:21:53,485 iteration 5924 : loss : 0.002033, loss_ce: 0.000965
2021-12-10 15:21:56,208 iteration 5925 : loss : 0.001648, loss_ce: 0.000670
2021-12-10 15:21:59,078 iteration 5926 : loss : 0.001663, loss_ce: 0.000664
2021-12-10 15:22:01,820 iteration 5927 : loss : 0.002509, loss_ce: 0.000947
2021-12-10 15:22:04,746 iteration 5928 : loss : 0.002287, loss_ce: 0.000685
2021-12-10 15:22:07,502 iteration 5929 : loss : 0.001912, loss_ce: 0.000760
2021-12-10 15:22:10,365 iteration 5930 : loss : 0.001704, loss_ce: 0.000789
2021-12-10 15:22:13,236 iteration 5931 : loss : 0.002398, loss_ce: 0.000616
2021-12-10 15:22:16,121 iteration 5932 : loss : 0.001636, loss_ce: 0.000744
2021-12-10 15:22:18,845 iteration 5933 : loss : 0.001781, loss_ce: 0.000684
 87%|█████████████████████████▎   | 349/400 [4:55:41<41:14, 48.52s/it]2021-12-10 15:22:21,629 iteration 5934 : loss : 0.002248, loss_ce: 0.001062
2021-12-10 15:22:24,455 iteration 5935 : loss : 0.001780, loss_ce: 0.000751
2021-12-10 15:22:27,318 iteration 5936 : loss : 0.001699, loss_ce: 0.000692
2021-12-10 15:22:30,246 iteration 5937 : loss : 0.001598, loss_ce: 0.000560
2021-12-10 15:22:32,987 iteration 5938 : loss : 0.001973, loss_ce: 0.000829
2021-12-10 15:22:35,737 iteration 5939 : loss : 0.001821, loss_ce: 0.000912
2021-12-10 15:22:38,488 iteration 5940 : loss : 0.001789, loss_ce: 0.000695
2021-12-10 15:22:41,093 iteration 5941 : loss : 0.001765, loss_ce: 0.000983
2021-12-10 15:22:43,858 iteration 5942 : loss : 0.001765, loss_ce: 0.000772
2021-12-10 15:22:46,575 iteration 5943 : loss : 0.001612, loss_ce: 0.000722
2021-12-10 15:22:49,307 iteration 5944 : loss : 0.001987, loss_ce: 0.000739
2021-12-10 15:22:52,040 iteration 5945 : loss : 0.001975, loss_ce: 0.000611
2021-12-10 15:22:54,764 iteration 5946 : loss : 0.001665, loss_ce: 0.000781
2021-12-10 15:22:57,626 iteration 5947 : loss : 0.002680, loss_ce: 0.001250
2021-12-10 15:23:00,571 iteration 5948 : loss : 0.001849, loss_ce: 0.000742
2021-12-10 15:23:03,361 iteration 5949 : loss : 0.001556, loss_ce: 0.000571
2021-12-10 15:23:03,362 Training Data Eval:
2021-12-10 15:23:19,038   Average segmentation loss on training set: 0.0016
2021-12-10 15:23:19,038 Validation Data Eval:
2021-12-10 15:23:24,485   Average segmentation loss on validation set: 0.1408
2021-12-10 15:23:27,318 iteration 5950 : loss : 0.001907, loss_ce: 0.000930
2021-12-10 15:23:33,414 save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/NEW_TU/NEW_TU_ADAM_seed1234_no_daepoch_349.pth
 88%|█████████████████████████▍   | 350/400 [4:56:56<46:55, 56.32s/it]2021-12-10 15:23:35,170 iteration 5951 : loss : 0.002015, loss_ce: 0.000802
2021-12-10 15:23:37,578 iteration 5952 : loss : 0.001956, loss_ce: 0.001055
2021-12-10 15:23:40,205 iteration 5953 : loss : 0.001649, loss_ce: 0.000589
2021-12-10 15:23:42,974 iteration 5954 : loss : 0.001957, loss_ce: 0.000904
2021-12-10 15:23:45,577 iteration 5955 : loss : 0.001862, loss_ce: 0.001042
2021-12-10 15:23:48,297 iteration 5956 : loss : 0.001576, loss_ce: 0.000762
2021-12-10 15:23:50,895 iteration 5957 : loss : 0.002587, loss_ce: 0.001180
2021-12-10 15:23:53,649 iteration 5958 : loss : 0.001809, loss_ce: 0.000882
2021-12-10 15:23:56,370 iteration 5959 : loss : 0.001915, loss_ce: 0.000889
2021-12-10 15:23:59,097 iteration 5960 : loss : 0.001459, loss_ce: 0.000755
2021-12-10 15:24:01,970 iteration 5961 : loss : 0.001987, loss_ce: 0.000545
2021-12-10 15:24:04,837 iteration 5962 : loss : 0.002086, loss_ce: 0.001110
2021-12-10 15:24:07,701 iteration 5963 : loss : 0.001830, loss_ce: 0.000569
2021-12-10 15:24:10,566 iteration 5964 : loss : 0.002331, loss_ce: 0.000754
2021-12-10 15:24:13,400 iteration 5965 : loss : 0.001786, loss_ce: 0.000753
2021-12-10 15:24:16,268 iteration 5966 : loss : 0.001356, loss_ce: 0.000417
2021-12-10 15:24:19,181 iteration 5967 : loss : 0.002746, loss_ce: 0.000829
 88%|█████████████████████████▍   | 351/400 [4:57:41<43:25, 53.17s/it]2021-12-10 15:24:21,955 iteration 5968 : loss : 0.001948, loss_ce: 0.000818
2021-12-10 15:24:24,840 iteration 5969 : loss : 0.001898, loss_ce: 0.000771
2021-12-10 15:24:27,564 iteration 5970 : loss : 0.002961, loss_ce: 0.001112
2021-12-10 15:24:30,391 iteration 5971 : loss : 0.001463, loss_ce: 0.000678
2021-12-10 15:24:33,418 iteration 5972 : loss : 0.001990, loss_ce: 0.000925
2021-12-10 15:24:36,147 iteration 5973 : loss : 0.001371, loss_ce: 0.000425
2021-12-10 15:24:38,984 iteration 5974 : loss : 0.001653, loss_ce: 0.000786
2021-12-10 15:24:41,821 iteration 5975 : loss : 0.002138, loss_ce: 0.000928
2021-12-10 15:24:44,659 iteration 5976 : loss : 0.001730, loss_ce: 0.000658
2021-12-10 15:24:47,514 iteration 5977 : loss : 0.001668, loss_ce: 0.000692
2021-12-10 15:24:50,365 iteration 5978 : loss : 0.001847, loss_ce: 0.000657
2021-12-10 15:24:53,230 iteration 5979 : loss : 0.001723, loss_ce: 0.000705
2021-12-10 15:24:56,077 iteration 5980 : loss : 0.002154, loss_ce: 0.000929
2021-12-10 15:24:58,837 iteration 5981 : loss : 0.002044, loss_ce: 0.000934
2021-12-10 15:25:01,612 iteration 5982 : loss : 0.001864, loss_ce: 0.000940
2021-12-10 15:25:04,332 iteration 5983 : loss : 0.001523, loss_ce: 0.000639
2021-12-10 15:25:07,239 iteration 5984 : loss : 0.001763, loss_ce: 0.000667
 88%|█████████████████████████▌   | 352/400 [4:58:30<41:18, 51.63s/it]2021-12-10 15:25:10,016 iteration 5985 : loss : 0.002028, loss_ce: 0.001013
2021-12-10 15:25:12,749 iteration 5986 : loss : 0.001821, loss_ce: 0.000774
2021-12-10 15:25:15,629 iteration 5987 : loss : 0.002120, loss_ce: 0.001113
2021-12-10 15:25:18,356 iteration 5988 : loss : 0.001872, loss_ce: 0.000584
2021-12-10 15:25:21,190 iteration 5989 : loss : 0.001582, loss_ce: 0.000419
2021-12-10 15:25:24,014 iteration 5990 : loss : 0.001544, loss_ce: 0.000846
2021-12-10 15:25:26,851 iteration 5991 : loss : 0.001924, loss_ce: 0.001005
2021-12-10 15:25:29,846 iteration 5992 : loss : 0.001797, loss_ce: 0.000627
2021-12-10 15:25:32,571 iteration 5993 : loss : 0.001850, loss_ce: 0.000895
2021-12-10 15:25:35,407 iteration 5994 : loss : 0.001307, loss_ce: 0.000487
2021-12-10 15:25:38,409 iteration 5995 : loss : 0.001492, loss_ce: 0.000661
2021-12-10 15:25:41,310 iteration 5996 : loss : 0.002194, loss_ce: 0.000832
2021-12-10 15:25:44,141 iteration 5997 : loss : 0.001771, loss_ce: 0.000728
2021-12-10 15:25:46,970 iteration 5998 : loss : 0.001952, loss_ce: 0.001145
2021-12-10 15:25:49,807 iteration 5999 : loss : 0.001382, loss_ce: 0.000687
2021-12-10 15:25:52,535 iteration 6000 : loss : 0.001543, loss_ce: 0.000619
2021-12-10 15:25:55,404 iteration 6001 : loss : 0.001861, loss_ce: 0.000768
 88%|█████████████████████████▌   | 353/400 [4:59:18<39:37, 50.59s/it]2021-12-10 15:25:58,172 iteration 6002 : loss : 0.001847, loss_ce: 0.000819
2021-12-10 15:26:01,041 iteration 6003 : loss : 0.001892, loss_ce: 0.000772
2021-12-10 15:26:03,770 iteration 6004 : loss : 0.001681, loss_ce: 0.000728
2021-12-10 15:26:06,608 iteration 6005 : loss : 0.001625, loss_ce: 0.000724
2021-12-10 15:26:09,494 iteration 6006 : loss : 0.001824, loss_ce: 0.000704
2021-12-10 15:26:12,422 iteration 6007 : loss : 0.001389, loss_ce: 0.000572
2021-12-10 15:26:15,153 iteration 6008 : loss : 0.001487, loss_ce: 0.000585
2021-12-10 15:26:18,002 iteration 6009 : loss : 0.001476, loss_ce: 0.000611
2021-12-10 15:26:20,861 iteration 6010 : loss : 0.001871, loss_ce: 0.001087
2021-12-10 15:26:23,716 iteration 6011 : loss : 0.001873, loss_ce: 0.000788
2021-12-10 15:26:26,688 iteration 6012 : loss : 0.001279, loss_ce: 0.000653
2021-12-10 15:26:29,610 iteration 6013 : loss : 0.001633, loss_ce: 0.000827
2021-12-10 15:26:32,479 iteration 6014 : loss : 0.001575, loss_ce: 0.000623
2021-12-10 15:26:35,311 iteration 6015 : loss : 0.001454, loss_ce: 0.000675
2021-12-10 15:26:38,346 iteration 6016 : loss : 0.001275, loss_ce: 0.000537
2021-12-10 15:26:41,196 iteration 6017 : loss : 0.001272, loss_ce: 0.000420
2021-12-10 15:26:44,183 iteration 6018 : loss : 0.002104, loss_ce: 0.001149
 88%|█████████████████████████▋   | 354/400 [5:00:07<38:22, 50.05s/it]2021-12-10 15:26:46,961 iteration 6019 : loss : 0.001903, loss_ce: 0.001040
2021-12-10 15:26:49,850 iteration 6020 : loss : 0.001664, loss_ce: 0.000661
2021-12-10 15:26:52,774 iteration 6021 : loss : 0.001572, loss_ce: 0.000659
2021-12-10 15:26:55,694 iteration 6022 : loss : 0.001804, loss_ce: 0.000669
2021-12-10 15:26:58,611 iteration 6023 : loss : 0.001432, loss_ce: 0.000628
2021-12-10 15:27:01,462 iteration 6024 : loss : 0.001958, loss_ce: 0.001054
2021-12-10 15:27:04,320 iteration 6025 : loss : 0.001408, loss_ce: 0.000518
2021-12-10 15:27:07,223 iteration 6026 : loss : 0.001678, loss_ce: 0.000894
2021-12-10 15:27:10,148 iteration 6027 : loss : 0.001646, loss_ce: 0.000812
2021-12-10 15:27:12,986 iteration 6028 : loss : 0.001423, loss_ce: 0.000521
2021-12-10 15:27:15,883 iteration 6029 : loss : 0.001977, loss_ce: 0.000783
2021-12-10 15:27:18,751 iteration 6030 : loss : 0.001467, loss_ce: 0.000592
2021-12-10 15:27:21,680 iteration 6031 : loss : 0.001368, loss_ce: 0.000608
2021-12-10 15:27:24,595 iteration 6032 : loss : 0.001981, loss_ce: 0.000843
2021-12-10 15:27:27,519 iteration 6033 : loss : 0.001462, loss_ce: 0.000588
2021-12-10 15:27:30,352 iteration 6034 : loss : 0.001570, loss_ce: 0.000618
2021-12-10 15:27:30,353 Training Data Eval:
2021-12-10 15:27:46,244   Average segmentation loss on training set: 0.0015
2021-12-10 15:27:46,245 Validation Data Eval:
2021-12-10 15:27:51,621   Average segmentation loss on validation set: 0.1410
2021-12-10 15:27:54,356 iteration 6035 : loss : 0.001930, loss_ce: 0.000696
 89%|█████████████████████████▋   | 355/400 [5:01:17<42:03, 56.09s/it]2021-12-10 15:27:57,142 iteration 6036 : loss : 0.001494, loss_ce: 0.000681
2021-12-10 15:27:59,994 iteration 6037 : loss : 0.001803, loss_ce: 0.000707
2021-12-10 15:28:02,845 iteration 6038 : loss : 0.001676, loss_ce: 0.000676
2021-12-10 15:28:05,708 iteration 6039 : loss : 0.002231, loss_ce: 0.000924
2021-12-10 15:28:08,546 iteration 6040 : loss : 0.001699, loss_ce: 0.000761
2021-12-10 15:28:11,388 iteration 6041 : loss : 0.001770, loss_ce: 0.000819
2021-12-10 15:28:14,253 iteration 6042 : loss : 0.001625, loss_ce: 0.000905
2021-12-10 15:28:17,003 iteration 6043 : loss : 0.001642, loss_ce: 0.000782
2021-12-10 15:28:19,731 iteration 6044 : loss : 0.002009, loss_ce: 0.000811
2021-12-10 15:28:22,454 iteration 6045 : loss : 0.001918, loss_ce: 0.000675
2021-12-10 15:28:25,321 iteration 6046 : loss : 0.002092, loss_ce: 0.000627
2021-12-10 15:28:28,065 iteration 6047 : loss : 0.001543, loss_ce: 0.000684
2021-12-10 15:28:30,917 iteration 6048 : loss : 0.001800, loss_ce: 0.001003
2021-12-10 15:28:33,773 iteration 6049 : loss : 0.001404, loss_ce: 0.000635
2021-12-10 15:28:36,607 iteration 6050 : loss : 0.001695, loss_ce: 0.000553
2021-12-10 15:28:39,438 iteration 6051 : loss : 0.001819, loss_ce: 0.000797
2021-12-10 15:28:42,462 iteration 6052 : loss : 0.002020, loss_ce: 0.000604
 89%|█████████████████████████▊   | 356/400 [5:02:05<39:22, 53.69s/it]2021-12-10 15:28:45,248 iteration 6053 : loss : 0.001763, loss_ce: 0.000745
2021-12-10 15:28:48,105 iteration 6054 : loss : 0.001656, loss_ce: 0.000970
2021-12-10 15:28:50,977 iteration 6055 : loss : 0.001885, loss_ce: 0.000918
2021-12-10 15:28:53,808 iteration 6056 : loss : 0.002058, loss_ce: 0.000865
2021-12-10 15:28:56,672 iteration 6057 : loss : 0.002270, loss_ce: 0.000634
2021-12-10 15:28:59,377 iteration 6058 : loss : 0.001631, loss_ce: 0.000832
2021-12-10 15:29:02,260 iteration 6059 : loss : 0.001419, loss_ce: 0.000718
2021-12-10 15:29:04,991 iteration 6060 : loss : 0.001504, loss_ce: 0.000592
2021-12-10 15:29:07,880 iteration 6061 : loss : 0.001978, loss_ce: 0.000770
2021-12-10 15:29:10,604 iteration 6062 : loss : 0.001581, loss_ce: 0.000597
2021-12-10 15:29:13,442 iteration 6063 : loss : 0.001661, loss_ce: 0.000671
2021-12-10 15:29:16,272 iteration 6064 : loss : 0.001511, loss_ce: 0.000627
2021-12-10 15:29:19,101 iteration 6065 : loss : 0.001785, loss_ce: 0.000940
2021-12-10 15:29:21,993 iteration 6066 : loss : 0.001638, loss_ce: 0.000736
2021-12-10 15:29:24,772 iteration 6067 : loss : 0.001663, loss_ce: 0.000854
2021-12-10 15:29:27,631 iteration 6068 : loss : 0.001942, loss_ce: 0.000814
2021-12-10 15:29:30,468 iteration 6069 : loss : 0.001617, loss_ce: 0.000600
 89%|█████████████████████████▉   | 357/400 [5:02:53<37:15, 51.99s/it]2021-12-10 15:29:33,522 iteration 6070 : loss : 0.001933, loss_ce: 0.001009
2021-12-10 15:29:36,249 iteration 6071 : loss : 0.002558, loss_ce: 0.001029
2021-12-10 15:29:39,103 iteration 6072 : loss : 0.001448, loss_ce: 0.000740
2021-12-10 15:29:42,089 iteration 6073 : loss : 0.001707, loss_ce: 0.000769
2021-12-10 15:29:45,000 iteration 6074 : loss : 0.001577, loss_ce: 0.000856
2021-12-10 15:29:47,838 iteration 6075 : loss : 0.002294, loss_ce: 0.000756
2021-12-10 15:29:50,862 iteration 6076 : loss : 0.001695, loss_ce: 0.000696
2021-12-10 15:29:53,710 iteration 6077 : loss : 0.001642, loss_ce: 0.000720
2021-12-10 15:29:56,602 iteration 6078 : loss : 0.001826, loss_ce: 0.000850
2021-12-10 15:29:59,486 iteration 6079 : loss : 0.002058, loss_ce: 0.001014
2021-12-10 15:30:02,262 iteration 6080 : loss : 0.001697, loss_ce: 0.000810
2021-12-10 15:30:05,124 iteration 6081 : loss : 0.001813, loss_ce: 0.000702
2021-12-10 15:30:07,981 iteration 6082 : loss : 0.001452, loss_ce: 0.000782
2021-12-10 15:30:10,868 iteration 6083 : loss : 0.001367, loss_ce: 0.000550
2021-12-10 15:30:13,599 iteration 6084 : loss : 0.001742, loss_ce: 0.000929
2021-12-10 15:30:16,360 iteration 6085 : loss : 0.001522, loss_ce: 0.000552
2021-12-10 15:30:19,087 iteration 6086 : loss : 0.001598, loss_ce: 0.000606
 90%|█████████████████████████▉   | 358/400 [5:03:41<35:41, 50.98s/it]2021-12-10 15:30:22,046 iteration 6087 : loss : 0.001772, loss_ce: 0.000886
2021-12-10 15:30:24,784 iteration 6088 : loss : 0.001394, loss_ce: 0.000531
2021-12-10 15:30:27,639 iteration 6089 : loss : 0.001386, loss_ce: 0.000572
2021-12-10 15:30:30,504 iteration 6090 : loss : 0.001489, loss_ce: 0.000710
2021-12-10 15:30:33,369 iteration 6091 : loss : 0.001639, loss_ce: 0.000764
2021-12-10 15:30:36,339 iteration 6092 : loss : 0.001468, loss_ce: 0.000736
2021-12-10 15:30:39,262 iteration 6093 : loss : 0.002125, loss_ce: 0.000819
2021-12-10 15:30:42,159 iteration 6094 : loss : 0.001658, loss_ce: 0.000643
2021-12-10 15:30:45,044 iteration 6095 : loss : 0.001557, loss_ce: 0.000602
2021-12-10 15:30:47,911 iteration 6096 : loss : 0.001806, loss_ce: 0.000602
2021-12-10 15:30:50,745 iteration 6097 : loss : 0.001537, loss_ce: 0.000778
2021-12-10 15:30:53,573 iteration 6098 : loss : 0.001831, loss_ce: 0.000850
2021-12-10 15:30:56,543 iteration 6099 : loss : 0.001432, loss_ce: 0.000539
2021-12-10 15:30:59,336 iteration 6100 : loss : 0.001751, loss_ce: 0.000610
2021-12-10 15:31:02,171 iteration 6101 : loss : 0.001844, loss_ce: 0.000937
2021-12-10 15:31:05,191 iteration 6102 : loss : 0.001610, loss_ce: 0.000642
2021-12-10 15:31:08,040 iteration 6103 : loss : 0.001218, loss_ce: 0.000454
 90%|██████████████████████████   | 359/400 [5:04:30<34:25, 50.37s/it]2021-12-10 15:31:11,031 iteration 6104 : loss : 0.001377, loss_ce: 0.000587
2021-12-10 15:31:13,864 iteration 6105 : loss : 0.001779, loss_ce: 0.000633
2021-12-10 15:31:16,687 iteration 6106 : loss : 0.001736, loss_ce: 0.000849
2021-12-10 15:31:19,526 iteration 6107 : loss : 0.001493, loss_ce: 0.000445
2021-12-10 15:31:22,416 iteration 6108 : loss : 0.001654, loss_ce: 0.000709
2021-12-10 15:31:25,343 iteration 6109 : loss : 0.001731, loss_ce: 0.000677
2021-12-10 15:31:28,240 iteration 6110 : loss : 0.001456, loss_ce: 0.000746
2021-12-10 15:31:31,129 iteration 6111 : loss : 0.001929, loss_ce: 0.000884
2021-12-10 15:31:33,992 iteration 6112 : loss : 0.001706, loss_ce: 0.000895
2021-12-10 15:31:36,965 iteration 6113 : loss : 0.001431, loss_ce: 0.000538
2021-12-10 15:31:39,886 iteration 6114 : loss : 0.001405, loss_ce: 0.000630
2021-12-10 15:31:42,817 iteration 6115 : loss : 0.001439, loss_ce: 0.000629
2021-12-10 15:31:45,735 iteration 6116 : loss : 0.001932, loss_ce: 0.000667
2021-12-10 15:31:48,592 iteration 6117 : loss : 0.001574, loss_ce: 0.000596
2021-12-10 15:31:51,492 iteration 6118 : loss : 0.001385, loss_ce: 0.000662
2021-12-10 15:31:54,417 iteration 6119 : loss : 0.001657, loss_ce: 0.000912
2021-12-10 15:31:54,417 Training Data Eval:
2021-12-10 15:32:10,240   Average segmentation loss on training set: 0.0014
2021-12-10 15:32:10,241 Validation Data Eval:
2021-12-10 15:32:15,796   Average segmentation loss on validation set: 0.1413
2021-12-10 15:32:18,809 iteration 6120 : loss : 0.001697, loss_ce: 0.000912
 90%|██████████████████████████   | 360/400 [5:05:41<37:39, 56.49s/it]2021-12-10 15:32:21,842 iteration 6121 : loss : 0.001484, loss_ce: 0.000545
2021-12-10 15:32:24,588 iteration 6122 : loss : 0.001948, loss_ce: 0.000868
2021-12-10 15:32:27,594 iteration 6123 : loss : 0.001570, loss_ce: 0.000699
2021-12-10 15:32:30,512 iteration 6124 : loss : 0.001528, loss_ce: 0.000567
2021-12-10 15:32:33,345 iteration 6125 : loss : 0.001723, loss_ce: 0.000891
2021-12-10 15:32:36,174 iteration 6126 : loss : 0.001785, loss_ce: 0.000948
2021-12-10 15:32:39,010 iteration 6127 : loss : 0.001332, loss_ce: 0.000667
2021-12-10 15:32:41,895 iteration 6128 : loss : 0.001378, loss_ce: 0.000521
2021-12-10 15:32:44,828 iteration 6129 : loss : 0.002461, loss_ce: 0.000897
2021-12-10 15:32:47,707 iteration 6130 : loss : 0.001933, loss_ce: 0.000938
2021-12-10 15:32:50,440 iteration 6131 : loss : 0.001865, loss_ce: 0.000694
2021-12-10 15:32:53,294 iteration 6132 : loss : 0.001502, loss_ce: 0.000719
2021-12-10 15:32:56,148 iteration 6133 : loss : 0.001444, loss_ce: 0.000681
2021-12-10 15:32:59,003 iteration 6134 : loss : 0.001480, loss_ce: 0.000613
2021-12-10 15:33:01,865 iteration 6135 : loss : 0.001721, loss_ce: 0.000636
2021-12-10 15:33:04,722 iteration 6136 : loss : 0.001624, loss_ce: 0.000793
2021-12-10 15:33:07,601 iteration 6137 : loss : 0.001920, loss_ce: 0.000840
 90%|██████████████████████████▏  | 361/400 [5:06:30<35:12, 54.18s/it]2021-12-10 15:33:10,438 iteration 6138 : loss : 0.001354, loss_ce: 0.000469
2021-12-10 15:33:13,194 iteration 6139 : loss : 0.001482, loss_ce: 0.000643
2021-12-10 15:33:15,917 iteration 6140 : loss : 0.001764, loss_ce: 0.000839
2021-12-10 15:33:18,641 iteration 6141 : loss : 0.001572, loss_ce: 0.000626
2021-12-10 15:33:21,503 iteration 6142 : loss : 0.001668, loss_ce: 0.000674
2021-12-10 15:33:24,371 iteration 6143 : loss : 0.002030, loss_ce: 0.001056
2021-12-10 15:33:27,263 iteration 6144 : loss : 0.001344, loss_ce: 0.000575
2021-12-10 15:33:30,002 iteration 6145 : loss : 0.001320, loss_ce: 0.000571
2021-12-10 15:33:32,664 iteration 6146 : loss : 0.001470, loss_ce: 0.000680
2021-12-10 15:33:35,384 iteration 6147 : loss : 0.001606, loss_ce: 0.000724
2021-12-10 15:33:38,251 iteration 6148 : loss : 0.001660, loss_ce: 0.000978
2021-12-10 15:33:40,991 iteration 6149 : loss : 0.001489, loss_ce: 0.000634
2021-12-10 15:33:43,847 iteration 6150 : loss : 0.001926, loss_ce: 0.001092
2021-12-10 15:33:46,707 iteration 6151 : loss : 0.001427, loss_ce: 0.000733
2021-12-10 15:33:49,576 iteration 6152 : loss : 0.001519, loss_ce: 0.000647
2021-12-10 15:33:52,437 iteration 6153 : loss : 0.001700, loss_ce: 0.000588
2021-12-10 15:33:55,298 iteration 6154 : loss : 0.001420, loss_ce: 0.000594
 90%|██████████████████████████▏  | 362/400 [5:07:18<33:04, 52.23s/it]2021-12-10 15:33:58,276 iteration 6155 : loss : 0.001634, loss_ce: 0.000840
2021-12-10 15:34:01,113 iteration 6156 : loss : 0.001618, loss_ce: 0.000730
2021-12-10 15:34:04,007 iteration 6157 : loss : 0.001878, loss_ce: 0.000655
2021-12-10 15:34:06,800 iteration 6158 : loss : 0.001850, loss_ce: 0.001058
2021-12-10 15:34:09,742 iteration 6159 : loss : 0.001925, loss_ce: 0.000641
2021-12-10 15:34:12,670 iteration 6160 : loss : 0.001521, loss_ce: 0.000436
2021-12-10 15:34:15,392 iteration 6161 : loss : 0.001669, loss_ce: 0.000803
2021-12-10 15:34:18,394 iteration 6162 : loss : 0.001814, loss_ce: 0.000796
2021-12-10 15:34:21,308 iteration 6163 : loss : 0.001171, loss_ce: 0.000590
2021-12-10 15:34:24,144 iteration 6164 : loss : 0.001331, loss_ce: 0.000648
2021-12-10 15:34:26,970 iteration 6165 : loss : 0.001932, loss_ce: 0.000744
2021-12-10 15:34:30,009 iteration 6166 : loss : 0.001416, loss_ce: 0.000658
2021-12-10 15:34:32,774 iteration 6167 : loss : 0.001816, loss_ce: 0.000568
2021-12-10 15:34:35,606 iteration 6168 : loss : 0.001472, loss_ce: 0.000711
2021-12-10 15:34:38,438 iteration 6169 : loss : 0.002229, loss_ce: 0.001164
2021-12-10 15:34:41,276 iteration 6170 : loss : 0.001843, loss_ce: 0.000707
2021-12-10 15:34:44,110 iteration 6171 : loss : 0.001953, loss_ce: 0.000632
 91%|██████████████████████████▎  | 363/400 [5:08:06<31:34, 51.21s/it]2021-12-10 15:34:47,054 iteration 6172 : loss : 0.001445, loss_ce: 0.000847
2021-12-10 15:34:49,971 iteration 6173 : loss : 0.001606, loss_ce: 0.000659
2021-12-10 15:34:52,700 iteration 6174 : loss : 0.001704, loss_ce: 0.000715
2021-12-10 15:34:55,698 iteration 6175 : loss : 0.001341, loss_ce: 0.000490
2021-12-10 15:34:58,431 iteration 6176 : loss : 0.001440, loss_ce: 0.000719
2021-12-10 15:35:01,340 iteration 6177 : loss : 0.001389, loss_ce: 0.000766
2021-12-10 15:35:04,227 iteration 6178 : loss : 0.001907, loss_ce: 0.000868
2021-12-10 15:35:07,006 iteration 6179 : loss : 0.002127, loss_ce: 0.000880
2021-12-10 15:35:09,846 iteration 6180 : loss : 0.001759, loss_ce: 0.000601
2021-12-10 15:35:12,780 iteration 6181 : loss : 0.001627, loss_ce: 0.000574
2021-12-10 15:35:15,718 iteration 6182 : loss : 0.001586, loss_ce: 0.000699
2021-12-10 15:35:18,641 iteration 6183 : loss : 0.001342, loss_ce: 0.000615
2021-12-10 15:35:21,557 iteration 6184 : loss : 0.001933, loss_ce: 0.000621
2021-12-10 15:35:24,487 iteration 6185 : loss : 0.001647, loss_ce: 0.000796
2021-12-10 15:35:27,355 iteration 6186 : loss : 0.001828, loss_ce: 0.000656
2021-12-10 15:35:30,274 iteration 6187 : loss : 0.002532, loss_ce: 0.001149
2021-12-10 15:35:33,011 iteration 6188 : loss : 0.001879, loss_ce: 0.000814
 91%|██████████████████████████▍  | 364/400 [5:08:55<30:18, 50.52s/it]2021-12-10 15:35:35,960 iteration 6189 : loss : 0.001465, loss_ce: 0.000459
2021-12-10 15:35:38,683 iteration 6190 : loss : 0.001992, loss_ce: 0.001071
2021-12-10 15:35:41,704 iteration 6191 : loss : 0.001323, loss_ce: 0.000486
2021-12-10 15:35:44,540 iteration 6192 : loss : 0.001689, loss_ce: 0.000809
2021-12-10 15:35:47,430 iteration 6193 : loss : 0.001893, loss_ce: 0.000825
2021-12-10 15:35:50,358 iteration 6194 : loss : 0.001547, loss_ce: 0.000674
2021-12-10 15:35:53,092 iteration 6195 : loss : 0.001951, loss_ce: 0.000610
2021-12-10 15:35:55,947 iteration 6196 : loss : 0.001572, loss_ce: 0.000703
2021-12-10 15:35:58,807 iteration 6197 : loss : 0.002091, loss_ce: 0.000770
2021-12-10 15:36:01,793 iteration 6198 : loss : 0.001818, loss_ce: 0.000890
2021-12-10 15:36:04,706 iteration 6199 : loss : 0.002027, loss_ce: 0.000961
2021-12-10 15:36:07,538 iteration 6200 : loss : 0.001737, loss_ce: 0.000683
2021-12-10 15:36:10,373 iteration 6201 : loss : 0.001596, loss_ce: 0.000587
2021-12-10 15:36:13,382 iteration 6202 : loss : 0.001676, loss_ce: 0.000900
2021-12-10 15:36:16,251 iteration 6203 : loss : 0.001578, loss_ce: 0.000584
2021-12-10 15:36:19,164 iteration 6204 : loss : 0.001610, loss_ce: 0.000852
2021-12-10 15:36:19,164 Training Data Eval:
2021-12-10 15:36:34,995   Average segmentation loss on training set: 0.0014
2021-12-10 15:36:34,996 Validation Data Eval:
2021-12-10 15:36:40,554   Average segmentation loss on validation set: 0.1449
2021-12-10 15:36:43,387 iteration 6205 : loss : 0.001788, loss_ce: 0.000809
 91%|██████████████████████████▍  | 365/400 [5:10:06<32:56, 56.48s/it]2021-12-10 15:36:46,317 iteration 6206 : loss : 0.001519, loss_ce: 0.000708
2021-12-10 15:36:49,181 iteration 6207 : loss : 0.001488, loss_ce: 0.000765
2021-12-10 15:36:52,019 iteration 6208 : loss : 0.001468, loss_ce: 0.000635
2021-12-10 15:36:54,848 iteration 6209 : loss : 0.002062, loss_ce: 0.000884
2021-12-10 15:36:57,880 iteration 6210 : loss : 0.002057, loss_ce: 0.000630
2021-12-10 15:37:00,743 iteration 6211 : loss : 0.001544, loss_ce: 0.000631
2021-12-10 15:37:03,467 iteration 6212 : loss : 0.001685, loss_ce: 0.000864
2021-12-10 15:37:06,298 iteration 6213 : loss : 0.001506, loss_ce: 0.000549
2021-12-10 15:37:09,307 iteration 6214 : loss : 0.001779, loss_ce: 0.001140
2021-12-10 15:37:12,193 iteration 6215 : loss : 0.001564, loss_ce: 0.000664
2021-12-10 15:37:14,917 iteration 6216 : loss : 0.001652, loss_ce: 0.000534
2021-12-10 15:37:17,947 iteration 6217 : loss : 0.001853, loss_ce: 0.000806
2021-12-10 15:37:20,806 iteration 6218 : loss : 0.001610, loss_ce: 0.000831
2021-12-10 15:37:23,528 iteration 6219 : loss : 0.001390, loss_ce: 0.000484
2021-12-10 15:37:26,552 iteration 6220 : loss : 0.001395, loss_ce: 0.000630
2021-12-10 15:37:29,399 iteration 6221 : loss : 0.001281, loss_ce: 0.000533
2021-12-10 15:37:32,293 iteration 6222 : loss : 0.001401, loss_ce: 0.000655
 92%|██████████████████████████▌  | 366/400 [5:10:55<30:42, 54.21s/it]2021-12-10 15:37:35,219 iteration 6223 : loss : 0.001493, loss_ce: 0.000502
2021-12-10 15:37:38,148 iteration 6224 : loss : 0.001503, loss_ce: 0.000613
2021-12-10 15:37:40,871 iteration 6225 : loss : 0.001455, loss_ce: 0.000876
2021-12-10 15:37:43,892 iteration 6226 : loss : 0.001640, loss_ce: 0.000667
2021-12-10 15:37:46,798 iteration 6227 : loss : 0.001362, loss_ce: 0.000538
2021-12-10 15:37:49,520 iteration 6228 : loss : 0.002213, loss_ce: 0.001046
2021-12-10 15:37:52,358 iteration 6229 : loss : 0.001433, loss_ce: 0.000658
2021-12-10 15:37:55,244 iteration 6230 : loss : 0.001543, loss_ce: 0.000912
2021-12-10 15:37:58,174 iteration 6231 : loss : 0.001380, loss_ce: 0.000688
2021-12-10 15:38:01,089 iteration 6232 : loss : 0.001276, loss_ce: 0.000607
2021-12-10 15:38:03,959 iteration 6233 : loss : 0.001387, loss_ce: 0.000554
2021-12-10 15:38:06,813 iteration 6234 : loss : 0.001264, loss_ce: 0.000571
2021-12-10 15:38:09,669 iteration 6235 : loss : 0.001809, loss_ce: 0.000867
2021-12-10 15:38:12,510 iteration 6236 : loss : 0.001486, loss_ce: 0.000610
2021-12-10 15:38:15,343 iteration 6237 : loss : 0.001296, loss_ce: 0.000545
2021-12-10 15:38:18,167 iteration 6238 : loss : 0.001681, loss_ce: 0.000648
2021-12-10 15:38:21,054 iteration 6239 : loss : 0.001488, loss_ce: 0.000789
 92%|██████████████████████████▌  | 367/400 [5:11:43<28:54, 52.57s/it]2021-12-10 15:38:24,031 iteration 6240 : loss : 0.001381, loss_ce: 0.000540
2021-12-10 15:38:26,964 iteration 6241 : loss : 0.001466, loss_ce: 0.000538
2021-12-10 15:38:29,813 iteration 6242 : loss : 0.001588, loss_ce: 0.000660
2021-12-10 15:38:32,707 iteration 6243 : loss : 0.001845, loss_ce: 0.001008
2021-12-10 15:38:35,635 iteration 6244 : loss : 0.001430, loss_ce: 0.000567
2021-12-10 15:38:38,567 iteration 6245 : loss : 0.001746, loss_ce: 0.000544
2021-12-10 15:38:41,292 iteration 6246 : loss : 0.001251, loss_ce: 0.000682
2021-12-10 15:38:44,185 iteration 6247 : loss : 0.001474, loss_ce: 0.000721
2021-12-10 15:38:47,113 iteration 6248 : loss : 0.001304, loss_ce: 0.000520
2021-12-10 15:38:50,044 iteration 6249 : loss : 0.001727, loss_ce: 0.000796
2021-12-10 15:38:52,774 iteration 6250 : loss : 0.001582, loss_ce: 0.000748
2021-12-10 15:38:55,664 iteration 6251 : loss : 0.001248, loss_ce: 0.000579
2021-12-10 15:38:58,592 iteration 6252 : loss : 0.001525, loss_ce: 0.000773
2021-12-10 15:39:01,331 iteration 6253 : loss : 0.001596, loss_ce: 0.000840
2021-12-10 15:39:04,189 iteration 6254 : loss : 0.001773, loss_ce: 0.000539
2021-12-10 15:39:07,049 iteration 6255 : loss : 0.001780, loss_ce: 0.000911
2021-12-10 15:39:09,898 iteration 6256 : loss : 0.001820, loss_ce: 0.000873
 92%|██████████████████████████▋  | 368/400 [5:12:32<27:26, 51.45s/it]2021-12-10 15:39:12,851 iteration 6257 : loss : 0.001375, loss_ce: 0.000779
2021-12-10 15:39:15,628 iteration 6258 : loss : 0.001657, loss_ce: 0.000991
2021-12-10 15:39:18,633 iteration 6259 : loss : 0.001456, loss_ce: 0.000588
2021-12-10 15:39:21,548 iteration 6260 : loss : 0.001422, loss_ce: 0.000814
2021-12-10 15:39:24,415 iteration 6261 : loss : 0.001401, loss_ce: 0.000520
2021-12-10 15:39:27,254 iteration 6262 : loss : 0.001358, loss_ce: 0.000607
2021-12-10 15:39:30,088 iteration 6263 : loss : 0.001307, loss_ce: 0.000583
2021-12-10 15:39:32,937 iteration 6264 : loss : 0.001432, loss_ce: 0.000608
2021-12-10 15:39:35,770 iteration 6265 : loss : 0.001502, loss_ce: 0.000735
2021-12-10 15:39:38,612 iteration 6266 : loss : 0.001683, loss_ce: 0.000772
2021-12-10 15:39:41,464 iteration 6267 : loss : 0.001470, loss_ce: 0.000467
2021-12-10 15:39:44,327 iteration 6268 : loss : 0.001244, loss_ce: 0.000598
2021-12-10 15:39:47,180 iteration 6269 : loss : 0.001395, loss_ce: 0.000487
2021-12-10 15:39:50,034 iteration 6270 : loss : 0.001274, loss_ce: 0.000584
2021-12-10 15:39:52,894 iteration 6271 : loss : 0.001479, loss_ce: 0.000750
2021-12-10 15:39:55,764 iteration 6272 : loss : 0.001254, loss_ce: 0.000654
2021-12-10 15:39:58,625 iteration 6273 : loss : 0.001297, loss_ce: 0.000553
 92%|██████████████████████████▊  | 369/400 [5:13:21<26:09, 50.63s/it]2021-12-10 15:40:01,417 iteration 6274 : loss : 0.001639, loss_ce: 0.000798
2021-12-10 15:40:04,257 iteration 6275 : loss : 0.001392, loss_ce: 0.000652
2021-12-10 15:40:07,157 iteration 6276 : loss : 0.001509, loss_ce: 0.000737
2021-12-10 15:40:09,881 iteration 6277 : loss : 0.001696, loss_ce: 0.000483
2021-12-10 15:40:12,722 iteration 6278 : loss : 0.001169, loss_ce: 0.000496
2021-12-10 15:40:15,557 iteration 6279 : loss : 0.001346, loss_ce: 0.000638
2021-12-10 15:40:18,390 iteration 6280 : loss : 0.001538, loss_ce: 0.000817
2021-12-10 15:40:21,280 iteration 6281 : loss : 0.001401, loss_ce: 0.000788
2021-12-10 15:40:24,002 iteration 6282 : loss : 0.001451, loss_ce: 0.000576
2021-12-10 15:40:26,842 iteration 6283 : loss : 0.001733, loss_ce: 0.000857
2021-12-10 15:40:29,707 iteration 6284 : loss : 0.001362, loss_ce: 0.000725
2021-12-10 15:40:32,431 iteration 6285 : loss : 0.001306, loss_ce: 0.000440
2021-12-10 15:40:35,289 iteration 6286 : loss : 0.001626, loss_ce: 0.000772
2021-12-10 15:40:38,154 iteration 6287 : loss : 0.001502, loss_ce: 0.000667
2021-12-10 15:40:41,078 iteration 6288 : loss : 0.001730, loss_ce: 0.000781
2021-12-10 15:40:43,804 iteration 6289 : loss : 0.001441, loss_ce: 0.000453
2021-12-10 15:40:43,804 Training Data Eval:
2021-12-10 15:40:59,395   Average segmentation loss on training set: 0.0013
2021-12-10 15:40:59,396 Validation Data Eval:
2021-12-10 15:41:04,916   Average segmentation loss on validation set: 0.1526
2021-12-10 15:41:07,661 iteration 6290 : loss : 0.001255, loss_ce: 0.000600
 92%|██████████████████████████▊  | 370/400 [5:14:30<28:04, 56.16s/it]2021-12-10 15:41:10,455 iteration 6291 : loss : 0.001304, loss_ce: 0.000628
2021-12-10 15:41:13,324 iteration 6292 : loss : 0.001496, loss_ce: 0.000689
2021-12-10 15:41:16,071 iteration 6293 : loss : 0.001472, loss_ce: 0.000775
2021-12-10 15:41:18,925 iteration 6294 : loss : 0.002067, loss_ce: 0.000650
2021-12-10 15:41:21,805 iteration 6295 : loss : 0.001527, loss_ce: 0.000725
2021-12-10 15:41:24,539 iteration 6296 : loss : 0.001335, loss_ce: 0.000597
2021-12-10 15:41:27,295 iteration 6297 : loss : 0.001559, loss_ce: 0.000584
2021-12-10 15:41:30,163 iteration 6298 : loss : 0.001521, loss_ce: 0.000598
2021-12-10 15:41:33,031 iteration 6299 : loss : 0.001499, loss_ce: 0.000786
2021-12-10 15:41:35,899 iteration 6300 : loss : 0.001309, loss_ce: 0.000642
2021-12-10 15:41:38,628 iteration 6301 : loss : 0.001386, loss_ce: 0.000729
2021-12-10 15:41:41,373 iteration 6302 : loss : 0.001295, loss_ce: 0.000505
2021-12-10 15:41:44,121 iteration 6303 : loss : 0.001543, loss_ce: 0.000681
2021-12-10 15:41:46,996 iteration 6304 : loss : 0.002172, loss_ce: 0.000746
2021-12-10 15:41:49,733 iteration 6305 : loss : 0.001801, loss_ce: 0.000670
2021-12-10 15:41:52,459 iteration 6306 : loss : 0.001576, loss_ce: 0.000632
2021-12-10 15:41:55,328 iteration 6307 : loss : 0.001209, loss_ce: 0.000461
 93%|██████████████████████████▉  | 371/400 [5:15:18<25:54, 53.61s/it]2021-12-10 15:41:58,263 iteration 6308 : loss : 0.001857, loss_ce: 0.000540
2021-12-10 15:42:00,992 iteration 6309 : loss : 0.001269, loss_ce: 0.000616
2021-12-10 15:42:03,716 iteration 6310 : loss : 0.001562, loss_ce: 0.000597
2021-12-10 15:42:06,579 iteration 6311 : loss : 0.001502, loss_ce: 0.000554
2021-12-10 15:42:09,324 iteration 6312 : loss : 0.001249, loss_ce: 0.000605
2021-12-10 15:42:12,180 iteration 6313 : loss : 0.001462, loss_ce: 0.000734
2021-12-10 15:42:14,910 iteration 6314 : loss : 0.001312, loss_ce: 0.000574
2021-12-10 15:42:17,637 iteration 6315 : loss : 0.001256, loss_ce: 0.000550
2021-12-10 15:42:20,506 iteration 6316 : loss : 0.001766, loss_ce: 0.000832
2021-12-10 15:42:23,246 iteration 6317 : loss : 0.001674, loss_ce: 0.000945
2021-12-10 15:42:26,001 iteration 6318 : loss : 0.001503, loss_ce: 0.000806
2021-12-10 15:42:28,727 iteration 6319 : loss : 0.001737, loss_ce: 0.000597
2021-12-10 15:42:31,620 iteration 6320 : loss : 0.001142, loss_ce: 0.000541
2021-12-10 15:42:34,348 iteration 6321 : loss : 0.001393, loss_ce: 0.000480
2021-12-10 15:42:37,212 iteration 6322 : loss : 0.001307, loss_ce: 0.000636
2021-12-10 15:42:39,939 iteration 6323 : loss : 0.001740, loss_ce: 0.000800
2021-12-10 15:42:42,681 iteration 6324 : loss : 0.001166, loss_ce: 0.000503
 93%|██████████████████████████▉  | 372/400 [5:16:05<24:08, 51.73s/it]2021-12-10 15:42:45,470 iteration 6325 : loss : 0.001372, loss_ce: 0.000715
2021-12-10 15:42:48,216 iteration 6326 : loss : 0.001322, loss_ce: 0.000592
2021-12-10 15:42:51,097 iteration 6327 : loss : 0.001207, loss_ce: 0.000491
2021-12-10 15:42:53,829 iteration 6328 : loss : 0.001116, loss_ce: 0.000660
2021-12-10 15:42:56,551 iteration 6329 : loss : 0.001067, loss_ce: 0.000354
2021-12-10 15:42:59,304 iteration 6330 : loss : 0.001410, loss_ce: 0.000750
2021-12-10 15:43:02,039 iteration 6331 : loss : 0.001295, loss_ce: 0.000560
2021-12-10 15:43:04,793 iteration 6332 : loss : 0.001341, loss_ce: 0.000600
2021-12-10 15:43:07,684 iteration 6333 : loss : 0.001456, loss_ce: 0.000676
2021-12-10 15:43:10,415 iteration 6334 : loss : 0.001732, loss_ce: 0.000830
2021-12-10 15:43:13,139 iteration 6335 : loss : 0.001538, loss_ce: 0.000641
2021-12-10 15:43:15,886 iteration 6336 : loss : 0.001315, loss_ce: 0.000563
2021-12-10 15:43:18,641 iteration 6337 : loss : 0.001545, loss_ce: 0.000776
2021-12-10 15:43:21,387 iteration 6338 : loss : 0.001314, loss_ce: 0.000533
2021-12-10 15:43:24,269 iteration 6339 : loss : 0.001371, loss_ce: 0.000641
2021-12-10 15:43:26,999 iteration 6340 : loss : 0.001251, loss_ce: 0.000537
2021-12-10 15:43:29,726 iteration 6341 : loss : 0.001270, loss_ce: 0.000627
 93%|███████████████████████████  | 373/400 [5:16:52<22:38, 50.32s/it]2021-12-10 15:43:32,510 iteration 6342 : loss : 0.001339, loss_ce: 0.000697
2021-12-10 15:43:35,238 iteration 6343 : loss : 0.001246, loss_ce: 0.000507
2021-12-10 15:43:37,982 iteration 6344 : loss : 0.001572, loss_ce: 0.000614
2021-12-10 15:43:40,863 iteration 6345 : loss : 0.001508, loss_ce: 0.000669
2021-12-10 15:43:43,594 iteration 6346 : loss : 0.001529, loss_ce: 0.000600
2021-12-10 15:43:46,355 iteration 6347 : loss : 0.001415, loss_ce: 0.000548
2021-12-10 15:43:49,248 iteration 6348 : loss : 0.001277, loss_ce: 0.000644
2021-12-10 15:43:51,985 iteration 6349 : loss : 0.001242, loss_ce: 0.000522
2021-12-10 15:43:54,709 iteration 6350 : loss : 0.001306, loss_ce: 0.000658
2021-12-10 15:43:57,451 iteration 6351 : loss : 0.001189, loss_ce: 0.000635
2021-12-10 15:44:00,323 iteration 6352 : loss : 0.001300, loss_ce: 0.000513
2021-12-10 15:44:03,053 iteration 6353 : loss : 0.001278, loss_ce: 0.000675
2021-12-10 15:44:05,772 iteration 6354 : loss : 0.001257, loss_ce: 0.000370
2021-12-10 15:44:08,644 iteration 6355 : loss : 0.001744, loss_ce: 0.000926
2021-12-10 15:44:11,391 iteration 6356 : loss : 0.001357, loss_ce: 0.000609
2021-12-10 15:44:14,125 iteration 6357 : loss : 0.002005, loss_ce: 0.001145
2021-12-10 15:44:16,907 iteration 6358 : loss : 0.001305, loss_ce: 0.000564
 94%|███████████████████████████  | 374/400 [5:17:39<21:23, 49.38s/it]2021-12-10 15:44:19,732 iteration 6359 : loss : 0.001384, loss_ce: 0.000551
2021-12-10 15:44:22,598 iteration 6360 : loss : 0.001249, loss_ce: 0.000694
2021-12-10 15:44:25,353 iteration 6361 : loss : 0.001105, loss_ce: 0.000436
2021-12-10 15:44:28,069 iteration 6362 : loss : 0.001736, loss_ce: 0.000780
2021-12-10 15:44:30,839 iteration 6363 : loss : 0.001420, loss_ce: 0.000700
2021-12-10 15:44:33,566 iteration 6364 : loss : 0.001733, loss_ce: 0.000967
2021-12-10 15:44:36,289 iteration 6365 : loss : 0.001758, loss_ce: 0.000835
2021-12-10 15:44:39,163 iteration 6366 : loss : 0.001257, loss_ce: 0.000579
2021-12-10 15:44:41,891 iteration 6367 : loss : 0.001435, loss_ce: 0.000454
2021-12-10 15:44:44,762 iteration 6368 : loss : 0.002055, loss_ce: 0.000869
2021-12-10 15:44:47,495 iteration 6369 : loss : 0.001499, loss_ce: 0.000631
2021-12-10 15:44:50,355 iteration 6370 : loss : 0.001539, loss_ce: 0.000869
2021-12-10 15:44:53,138 iteration 6371 : loss : 0.001369, loss_ce: 0.000574
2021-12-10 15:44:55,867 iteration 6372 : loss : 0.001430, loss_ce: 0.000596
2021-12-10 15:44:58,624 iteration 6373 : loss : 0.001537, loss_ce: 0.000858
2021-12-10 15:45:01,380 iteration 6374 : loss : 0.001162, loss_ce: 0.000470
2021-12-10 15:45:01,380 Training Data Eval:
2021-12-10 15:45:16,733   Average segmentation loss on training set: 0.0012
2021-12-10 15:45:16,734 Validation Data Eval:
2021-12-10 15:45:22,076   Average segmentation loss on validation set: 0.1436
2021-12-10 15:45:24,795 iteration 6375 : loss : 0.001555, loss_ce: 0.000800
 94%|███████████████████████████▏ | 375/400 [5:18:47<22:53, 54.93s/it]2021-12-10 15:45:27,723 iteration 6376 : loss : 0.001165, loss_ce: 0.000627
2021-12-10 15:45:30,472 iteration 6377 : loss : 0.001393, loss_ce: 0.000521
2021-12-10 15:45:33,193 iteration 6378 : loss : 0.001012, loss_ce: 0.000415
2021-12-10 15:45:35,943 iteration 6379 : loss : 0.001556, loss_ce: 0.000790
2021-12-10 15:45:38,684 iteration 6380 : loss : 0.001346, loss_ce: 0.000630
2021-12-10 15:45:41,412 iteration 6381 : loss : 0.001422, loss_ce: 0.000752
2021-12-10 15:45:44,161 iteration 6382 : loss : 0.001497, loss_ce: 0.000763
2021-12-10 15:45:46,889 iteration 6383 : loss : 0.001305, loss_ce: 0.000542
2021-12-10 15:45:49,646 iteration 6384 : loss : 0.001363, loss_ce: 0.000633
2021-12-10 15:45:52,530 iteration 6385 : loss : 0.001616, loss_ce: 0.000816
2021-12-10 15:45:55,278 iteration 6386 : loss : 0.001740, loss_ce: 0.000650
2021-12-10 15:45:58,063 iteration 6387 : loss : 0.001027, loss_ce: 0.000466
2021-12-10 15:46:00,812 iteration 6388 : loss : 0.001353, loss_ce: 0.000581
2021-12-10 15:46:03,592 iteration 6389 : loss : 0.001645, loss_ce: 0.000627
2021-12-10 15:46:06,335 iteration 6390 : loss : 0.001409, loss_ce: 0.000447
2021-12-10 15:46:09,120 iteration 6391 : loss : 0.001373, loss_ce: 0.000766
2021-12-10 15:46:11,865 iteration 6392 : loss : 0.001562, loss_ce: 0.000890
 94%|███████████████████████████▎ | 376/400 [5:19:34<21:01, 52.57s/it]2021-12-10 15:46:14,616 iteration 6393 : loss : 0.001268, loss_ce: 0.000636
2021-12-10 15:46:17,370 iteration 6394 : loss : 0.001603, loss_ce: 0.000643
2021-12-10 15:46:20,100 iteration 6395 : loss : 0.001382, loss_ce: 0.000761
2021-12-10 15:46:22,845 iteration 6396 : loss : 0.001266, loss_ce: 0.000587
2021-12-10 15:46:25,728 iteration 6397 : loss : 0.001212, loss_ce: 0.000655
2021-12-10 15:46:28,531 iteration 6398 : loss : 0.001498, loss_ce: 0.000586
2021-12-10 15:46:31,284 iteration 6399 : loss : 0.001623, loss_ce: 0.000912
2021-12-10 15:46:34,039 iteration 6400 : loss : 0.001169, loss_ce: 0.000570
2021-12-10 15:46:36,734 iteration 6401 : loss : 0.001486, loss_ce: 0.000779
2021-12-10 15:46:39,485 iteration 6402 : loss : 0.001374, loss_ce: 0.000486
2021-12-10 15:46:42,201 iteration 6403 : loss : 0.001228, loss_ce: 0.000601
2021-12-10 15:46:44,923 iteration 6404 : loss : 0.001475, loss_ce: 0.000670
2021-12-10 15:46:47,684 iteration 6405 : loss : 0.001301, loss_ce: 0.000438
2021-12-10 15:46:50,446 iteration 6406 : loss : 0.001393, loss_ce: 0.000431
2021-12-10 15:46:53,198 iteration 6407 : loss : 0.001392, loss_ce: 0.000630
2021-12-10 15:46:55,992 iteration 6408 : loss : 0.001233, loss_ce: 0.000572
2021-12-10 15:46:58,737 iteration 6409 : loss : 0.001480, loss_ce: 0.000708
 94%|███████████████████████████▎ | 377/400 [5:20:21<19:29, 50.87s/it]2021-12-10 15:47:01,478 iteration 6410 : loss : 0.001359, loss_ce: 0.000382
2021-12-10 15:47:04,229 iteration 6411 : loss : 0.001115, loss_ce: 0.000553
2021-12-10 15:47:06,972 iteration 6412 : loss : 0.001481, loss_ce: 0.000601
2021-12-10 15:47:09,725 iteration 6413 : loss : 0.001489, loss_ce: 0.000751
2021-12-10 15:47:12,617 iteration 6414 : loss : 0.001532, loss_ce: 0.000765
2021-12-10 15:47:15,364 iteration 6415 : loss : 0.001200, loss_ce: 0.000515
2021-12-10 15:47:18,148 iteration 6416 : loss : 0.001071, loss_ce: 0.000476
2021-12-10 15:47:20,884 iteration 6417 : loss : 0.001393, loss_ce: 0.000709
2021-12-10 15:47:23,650 iteration 6418 : loss : 0.001333, loss_ce: 0.000724
2021-12-10 15:47:26,372 iteration 6419 : loss : 0.001071, loss_ce: 0.000409
2021-12-10 15:47:29,150 iteration 6420 : loss : 0.001767, loss_ce: 0.000713
2021-12-10 15:47:32,019 iteration 6421 : loss : 0.001266, loss_ce: 0.000653
2021-12-10 15:47:34,769 iteration 6422 : loss : 0.001776, loss_ce: 0.000663
2021-12-10 15:47:37,526 iteration 6423 : loss : 0.001262, loss_ce: 0.000580
2021-12-10 15:47:40,281 iteration 6424 : loss : 0.001287, loss_ce: 0.000520
2021-12-10 15:47:43,028 iteration 6425 : loss : 0.001358, loss_ce: 0.000597
2021-12-10 15:47:45,807 iteration 6426 : loss : 0.001303, loss_ce: 0.000659
 94%|███████████████████████████▍ | 378/400 [5:21:08<18:14, 49.73s/it]2021-12-10 15:47:48,656 iteration 6427 : loss : 0.001194, loss_ce: 0.000583
2021-12-10 15:47:51,395 iteration 6428 : loss : 0.001645, loss_ce: 0.000714
2021-12-10 15:47:54,154 iteration 6429 : loss : 0.001473, loss_ce: 0.000794
2021-12-10 15:47:56,908 iteration 6430 : loss : 0.001061, loss_ce: 0.000430
2021-12-10 15:47:59,673 iteration 6431 : loss : 0.001482, loss_ce: 0.000444
2021-12-10 15:48:02,425 iteration 6432 : loss : 0.001431, loss_ce: 0.000716
2021-12-10 15:48:05,208 iteration 6433 : loss : 0.001003, loss_ce: 0.000441
2021-12-10 15:48:07,951 iteration 6434 : loss : 0.001316, loss_ce: 0.000537
2021-12-10 15:48:10,734 iteration 6435 : loss : 0.001090, loss_ce: 0.000500
2021-12-10 15:48:13,479 iteration 6436 : loss : 0.001735, loss_ce: 0.000724
2021-12-10 15:48:16,236 iteration 6437 : loss : 0.001459, loss_ce: 0.000815
2021-12-10 15:48:18,988 iteration 6438 : loss : 0.001086, loss_ce: 0.000450
2021-12-10 15:48:21,769 iteration 6439 : loss : 0.001434, loss_ce: 0.000625
2021-12-10 15:48:24,517 iteration 6440 : loss : 0.001955, loss_ce: 0.000872
2021-12-10 15:48:27,305 iteration 6441 : loss : 0.001218, loss_ce: 0.000682
2021-12-10 15:48:29,930 iteration 6442 : loss : 0.001233, loss_ce: 0.000645
2021-12-10 15:48:32,706 iteration 6443 : loss : 0.001513, loss_ce: 0.000751
 95%|███████████████████████████▍ | 379/400 [5:21:55<17:06, 48.88s/it]2021-12-10 15:48:35,546 iteration 6444 : loss : 0.001201, loss_ce: 0.000434
2021-12-10 15:48:38,289 iteration 6445 : loss : 0.001326, loss_ce: 0.000682
2021-12-10 15:48:41,039 iteration 6446 : loss : 0.001324, loss_ce: 0.000519
2021-12-10 15:48:43,750 iteration 6447 : loss : 0.001469, loss_ce: 0.000718
2021-12-10 15:48:46,632 iteration 6448 : loss : 0.001455, loss_ce: 0.000820
2021-12-10 15:48:49,427 iteration 6449 : loss : 0.001414, loss_ce: 0.000618
2021-12-10 15:48:52,029 iteration 6450 : loss : 0.001425, loss_ce: 0.000622
2021-12-10 15:48:54,885 iteration 6451 : loss : 0.001084, loss_ce: 0.000529
2021-12-10 15:48:57,640 iteration 6452 : loss : 0.001423, loss_ce: 0.000712
2021-12-10 15:49:00,513 iteration 6453 : loss : 0.001280, loss_ce: 0.000473
2021-12-10 15:49:03,263 iteration 6454 : loss : 0.001146, loss_ce: 0.000580
2021-12-10 15:49:06,038 iteration 6455 : loss : 0.001509, loss_ce: 0.000664
2021-12-10 15:49:08,789 iteration 6456 : loss : 0.001174, loss_ce: 0.000646
2021-12-10 15:49:11,548 iteration 6457 : loss : 0.001110, loss_ce: 0.000525
2021-12-10 15:49:14,286 iteration 6458 : loss : 0.001353, loss_ce: 0.000455
2021-12-10 15:49:17,015 iteration 6459 : loss : 0.001188, loss_ce: 0.000570
2021-12-10 15:49:17,015 Training Data Eval:
2021-12-10 15:49:32,056   Average segmentation loss on training set: 0.0011
2021-12-10 15:49:32,057 Validation Data Eval:
2021-12-10 15:49:37,406   Average segmentation loss on validation set: 0.1495
2021-12-10 15:49:40,288 iteration 6460 : loss : 0.001358, loss_ce: 0.000619
 95%|███████████████████████████▌ | 380/400 [5:23:03<18:09, 54.49s/it]2021-12-10 15:49:43,010 iteration 6461 : loss : 0.001270, loss_ce: 0.000599
2021-12-10 15:49:45,735 iteration 6462 : loss : 0.001540, loss_ce: 0.000863
2021-12-10 15:49:48,477 iteration 6463 : loss : 0.001287, loss_ce: 0.000461
2021-12-10 15:49:51,195 iteration 6464 : loss : 0.001285, loss_ce: 0.000684
2021-12-10 15:49:54,102 iteration 6465 : loss : 0.001071, loss_ce: 0.000458
2021-12-10 15:49:56,697 iteration 6466 : loss : 0.001418, loss_ce: 0.000573
2021-12-10 15:49:59,551 iteration 6467 : loss : 0.001201, loss_ce: 0.000554
2021-12-10 15:50:02,336 iteration 6468 : loss : 0.001303, loss_ce: 0.000678
2021-12-10 15:50:05,145 iteration 6469 : loss : 0.001369, loss_ce: 0.000692
2021-12-10 15:50:07,750 iteration 6470 : loss : 0.001349, loss_ce: 0.000624
2021-12-10 15:50:10,470 iteration 6471 : loss : 0.001454, loss_ce: 0.000641
2021-12-10 15:50:13,253 iteration 6472 : loss : 0.001260, loss_ce: 0.000604
2021-12-10 15:50:16,053 iteration 6473 : loss : 0.001141, loss_ce: 0.000597
2021-12-10 15:50:18,869 iteration 6474 : loss : 0.001280, loss_ce: 0.000504
2021-12-10 15:50:21,470 iteration 6475 : loss : 0.001191, loss_ce: 0.000557
2021-12-10 15:50:24,191 iteration 6476 : loss : 0.001519, loss_ce: 0.000613
2021-12-10 15:50:26,975 iteration 6477 : loss : 0.001431, loss_ce: 0.000622
 95%|███████████████████████████▌ | 381/400 [5:23:49<16:30, 52.15s/it]2021-12-10 15:50:29,722 iteration 6478 : loss : 0.001491, loss_ce: 0.000678
2021-12-10 15:50:32,502 iteration 6479 : loss : 0.001702, loss_ce: 0.000674
2021-12-10 15:50:35,101 iteration 6480 : loss : 0.001279, loss_ce: 0.000634
2021-12-10 15:50:37,864 iteration 6481 : loss : 0.001249, loss_ce: 0.000605
2021-12-10 15:50:40,653 iteration 6482 : loss : 0.001291, loss_ce: 0.000657
2021-12-10 15:50:43,260 iteration 6483 : loss : 0.001157, loss_ce: 0.000553
2021-12-10 15:50:46,031 iteration 6484 : loss : 0.001180, loss_ce: 0.000632
2021-12-10 15:50:48,827 iteration 6485 : loss : 0.001249, loss_ce: 0.000687
2021-12-10 15:50:51,429 iteration 6486 : loss : 0.001222, loss_ce: 0.000355
2021-12-10 15:50:54,211 iteration 6487 : loss : 0.001346, loss_ce: 0.000469
2021-12-10 15:50:56,839 iteration 6488 : loss : 0.001394, loss_ce: 0.000545
2021-12-10 15:50:59,597 iteration 6489 : loss : 0.001793, loss_ce: 0.001089
2021-12-10 15:51:02,372 iteration 6490 : loss : 0.001310, loss_ce: 0.000599
2021-12-10 15:51:04,973 iteration 6491 : loss : 0.001415, loss_ce: 0.000424
2021-12-10 15:51:07,739 iteration 6492 : loss : 0.001423, loss_ce: 0.000765
2021-12-10 15:51:10,332 iteration 6493 : loss : 0.001030, loss_ce: 0.000465
2021-12-10 15:51:13,078 iteration 6494 : loss : 0.001293, loss_ce: 0.000565
 96%|███████████████████████████▋ | 382/400 [5:24:35<15:06, 50.34s/it]2021-12-10 15:51:15,809 iteration 6495 : loss : 0.001209, loss_ce: 0.000533
2021-12-10 15:51:18,466 iteration 6496 : loss : 0.001237, loss_ce: 0.000735
2021-12-10 15:51:21,183 iteration 6497 : loss : 0.001408, loss_ce: 0.000567
2021-12-10 15:51:23,799 iteration 6498 : loss : 0.001204, loss_ce: 0.000408
2021-12-10 15:51:26,574 iteration 6499 : loss : 0.001262, loss_ce: 0.000744
2021-12-10 15:51:29,243 iteration 6500 : loss : 0.001339, loss_ce: 0.000505
2021-12-10 15:51:31,971 iteration 6501 : loss : 0.000946, loss_ce: 0.000428
2021-12-10 15:51:34,591 iteration 6502 : loss : 0.000969, loss_ce: 0.000477
2021-12-10 15:51:37,372 iteration 6503 : loss : 0.001264, loss_ce: 0.000600
2021-12-10 15:51:40,038 iteration 6504 : loss : 0.001305, loss_ce: 0.000493
2021-12-10 15:51:42,672 iteration 6505 : loss : 0.001384, loss_ce: 0.000724
2021-12-10 15:51:45,345 iteration 6506 : loss : 0.001805, loss_ce: 0.000933
2021-12-10 15:51:48,039 iteration 6507 : loss : 0.001275, loss_ce: 0.000434
2021-12-10 15:51:50,688 iteration 6508 : loss : 0.001372, loss_ce: 0.000726
2021-12-10 15:51:53,339 iteration 6509 : loss : 0.001305, loss_ce: 0.000606
2021-12-10 15:51:55,978 iteration 6510 : loss : 0.001518, loss_ce: 0.000793
2021-12-10 15:51:58,588 iteration 6511 : loss : 0.001883, loss_ce: 0.000765
 96%|███████████████████████████▊ | 383/400 [5:25:21<13:51, 48.89s/it]2021-12-10 15:52:01,404 iteration 6512 : loss : 0.001080, loss_ce: 0.000624
2021-12-10 15:52:04,026 iteration 6513 : loss : 0.001271, loss_ce: 0.000793
2021-12-10 15:52:06,790 iteration 6514 : loss : 0.001187, loss_ce: 0.000535
2021-12-10 15:52:09,384 iteration 6515 : loss : 0.001293, loss_ce: 0.000722
2021-12-10 15:52:12,033 iteration 6516 : loss : 0.001569, loss_ce: 0.000776
2021-12-10 15:52:14,648 iteration 6517 : loss : 0.001433, loss_ce: 0.000558
2021-12-10 15:52:17,405 iteration 6518 : loss : 0.001184, loss_ce: 0.000355
2021-12-10 15:52:20,032 iteration 6519 : loss : 0.001339, loss_ce: 0.000635
2021-12-10 15:52:22,654 iteration 6520 : loss : 0.001391, loss_ce: 0.000846
2021-12-10 15:52:25,418 iteration 6521 : loss : 0.001100, loss_ce: 0.000496
2021-12-10 15:52:28,187 iteration 6522 : loss : 0.001633, loss_ce: 0.000533
2021-12-10 15:52:30,784 iteration 6523 : loss : 0.001547, loss_ce: 0.000786
2021-12-10 15:52:33,410 iteration 6524 : loss : 0.001580, loss_ce: 0.000799
2021-12-10 15:52:36,133 iteration 6525 : loss : 0.000996, loss_ce: 0.000487
2021-12-10 15:52:38,825 iteration 6526 : loss : 0.001627, loss_ce: 0.000681
2021-12-10 15:52:41,512 iteration 6527 : loss : 0.001007, loss_ce: 0.000437
2021-12-10 15:52:44,118 iteration 6528 : loss : 0.000801, loss_ce: 0.000319
 96%|███████████████████████████▊ | 384/400 [5:26:06<12:46, 47.88s/it]2021-12-10 15:52:46,827 iteration 6529 : loss : 0.001122, loss_ce: 0.000452
2021-12-10 15:52:49,451 iteration 6530 : loss : 0.001102, loss_ce: 0.000505
2021-12-10 15:52:52,214 iteration 6531 : loss : 0.001409, loss_ce: 0.000776
2021-12-10 15:52:54,845 iteration 6532 : loss : 0.001507, loss_ce: 0.000707
2021-12-10 15:52:57,581 iteration 6533 : loss : 0.001024, loss_ce: 0.000475
2021-12-10 15:53:00,245 iteration 6534 : loss : 0.001665, loss_ce: 0.000829
2021-12-10 15:53:02,911 iteration 6535 : loss : 0.001791, loss_ce: 0.000626
2021-12-10 15:53:05,568 iteration 6536 : loss : 0.001030, loss_ce: 0.000430
2021-12-10 15:53:08,189 iteration 6537 : loss : 0.001457, loss_ce: 0.000817
2021-12-10 15:53:10,968 iteration 6538 : loss : 0.001349, loss_ce: 0.000771
2021-12-10 15:53:13,574 iteration 6539 : loss : 0.000971, loss_ce: 0.000433
2021-12-10 15:53:16,176 iteration 6540 : loss : 0.001125, loss_ce: 0.000372
2021-12-10 15:53:18,932 iteration 6541 : loss : 0.001119, loss_ce: 0.000558
2021-12-10 15:53:21,621 iteration 6542 : loss : 0.001138, loss_ce: 0.000590
2021-12-10 15:53:24,202 iteration 6543 : loss : 0.001234, loss_ce: 0.000624
2021-12-10 15:53:26,925 iteration 6544 : loss : 0.001479, loss_ce: 0.000600
2021-12-10 15:53:26,926 Training Data Eval:
2021-12-10 15:53:41,705   Average segmentation loss on training set: 0.0011
2021-12-10 15:53:41,706 Validation Data Eval:
2021-12-10 15:53:46,902   Average segmentation loss on validation set: 0.1587
2021-12-10 15:53:49,516 iteration 6545 : loss : 0.001171, loss_ce: 0.000500
 96%|███████████████████████████▉ | 385/400 [5:27:12<13:17, 53.14s/it]2021-12-10 15:53:52,358 iteration 6546 : loss : 0.001260, loss_ce: 0.000534
2021-12-10 15:53:54,974 iteration 6547 : loss : 0.001244, loss_ce: 0.000542
2021-12-10 15:53:57,731 iteration 6548 : loss : 0.000929, loss_ce: 0.000387
2021-12-10 15:54:00,366 iteration 6549 : loss : 0.001996, loss_ce: 0.000887
2021-12-10 15:54:03,123 iteration 6550 : loss : 0.001526, loss_ce: 0.000730
2021-12-10 15:54:05,750 iteration 6551 : loss : 0.002177, loss_ce: 0.001029
2021-12-10 15:54:08,490 iteration 6552 : loss : 0.001117, loss_ce: 0.000476
2021-12-10 15:54:11,193 iteration 6553 : loss : 0.001081, loss_ce: 0.000500
2021-12-10 15:54:13,992 iteration 6554 : loss : 0.001178, loss_ce: 0.000574
2021-12-10 15:54:16,591 iteration 6555 : loss : 0.001658, loss_ce: 0.000861
2021-12-10 15:54:19,251 iteration 6556 : loss : 0.001099, loss_ce: 0.000492
2021-12-10 15:54:22,036 iteration 6557 : loss : 0.001070, loss_ce: 0.000495
2021-12-10 15:54:24,632 iteration 6558 : loss : 0.001127, loss_ce: 0.000517
2021-12-10 15:54:27,257 iteration 6559 : loss : 0.001444, loss_ce: 0.000793
2021-12-10 15:54:29,920 iteration 6560 : loss : 0.001179, loss_ce: 0.000559
2021-12-10 15:54:32,700 iteration 6561 : loss : 0.001028, loss_ce: 0.000363
2021-12-10 15:54:35,305 iteration 6562 : loss : 0.001207, loss_ce: 0.000680
 96%|███████████████████████████▉ | 386/400 [5:27:58<11:53, 50.93s/it]2021-12-10 15:54:37,960 iteration 6563 : loss : 0.001582, loss_ce: 0.000839
2021-12-10 15:54:40,737 iteration 6564 : loss : 0.001428, loss_ce: 0.000753
2021-12-10 15:54:43,340 iteration 6565 : loss : 0.001066, loss_ce: 0.000595
2021-12-10 15:54:46,005 iteration 6566 : loss : 0.001059, loss_ce: 0.000522
2021-12-10 15:54:48,767 iteration 6567 : loss : 0.001073, loss_ce: 0.000324
2021-12-10 15:54:51,439 iteration 6568 : loss : 0.001070, loss_ce: 0.000488
2021-12-10 15:54:54,213 iteration 6569 : loss : 0.001197, loss_ce: 0.000587
2021-12-10 15:54:56,825 iteration 6570 : loss : 0.001291, loss_ce: 0.000765
2021-12-10 15:54:59,583 iteration 6571 : loss : 0.001137, loss_ce: 0.000470
2021-12-10 15:55:02,259 iteration 6572 : loss : 0.001496, loss_ce: 0.000657
2021-12-10 15:55:05,006 iteration 6573 : loss : 0.001123, loss_ce: 0.000562
2021-12-10 15:55:07,770 iteration 6574 : loss : 0.001184, loss_ce: 0.000565
2021-12-10 15:55:10,380 iteration 6575 : loss : 0.001146, loss_ce: 0.000500
2021-12-10 15:55:13,156 iteration 6576 : loss : 0.001238, loss_ce: 0.000576
2021-12-10 15:55:15,907 iteration 6577 : loss : 0.001538, loss_ce: 0.000786
2021-12-10 15:55:18,616 iteration 6578 : loss : 0.001205, loss_ce: 0.000661
2021-12-10 15:55:21,360 iteration 6579 : loss : 0.000948, loss_ce: 0.000398
 97%|████████████████████████████ | 387/400 [5:28:44<10:43, 49.47s/it]2021-12-10 15:55:24,124 iteration 6580 : loss : 0.001059, loss_ce: 0.000526
2021-12-10 15:55:26,920 iteration 6581 : loss : 0.001623, loss_ce: 0.000508
2021-12-10 15:55:29,684 iteration 6582 : loss : 0.001118, loss_ce: 0.000551
2021-12-10 15:55:32,316 iteration 6583 : loss : 0.001444, loss_ce: 0.000607
2021-12-10 15:55:35,071 iteration 6584 : loss : 0.001059, loss_ce: 0.000430
2021-12-10 15:55:37,855 iteration 6585 : loss : 0.000999, loss_ce: 0.000497
2021-12-10 15:55:40,603 iteration 6586 : loss : 0.001574, loss_ce: 0.000646
2021-12-10 15:55:43,380 iteration 6587 : loss : 0.001636, loss_ce: 0.000782
2021-12-10 15:55:45,984 iteration 6588 : loss : 0.001572, loss_ce: 0.000935
2021-12-10 15:55:48,733 iteration 6589 : loss : 0.001288, loss_ce: 0.000588
2021-12-10 15:55:51,464 iteration 6590 : loss : 0.001407, loss_ce: 0.000544
2021-12-10 15:55:54,248 iteration 6591 : loss : 0.001462, loss_ce: 0.000818
2021-12-10 15:55:56,985 iteration 6592 : loss : 0.001055, loss_ce: 0.000349
2021-12-10 15:55:59,746 iteration 6593 : loss : 0.001009, loss_ce: 0.000411
2021-12-10 15:56:02,461 iteration 6594 : loss : 0.001478, loss_ce: 0.000941
2021-12-10 15:56:05,210 iteration 6595 : loss : 0.001318, loss_ce: 0.000693
2021-12-10 15:56:07,982 iteration 6596 : loss : 0.001174, loss_ce: 0.000443
 97%|████████████████████████████▏| 388/400 [5:29:30<09:43, 48.61s/it]2021-12-10 15:56:10,787 iteration 6597 : loss : 0.001528, loss_ce: 0.000604
2021-12-10 15:56:13,523 iteration 6598 : loss : 0.001243, loss_ce: 0.000695
2021-12-10 15:56:16,265 iteration 6599 : loss : 0.000974, loss_ce: 0.000497
2021-12-10 15:56:19,014 iteration 6600 : loss : 0.001213, loss_ce: 0.000605
2021-12-10 15:56:21,753 iteration 6601 : loss : 0.001328, loss_ce: 0.000788
2021-12-10 15:56:24,613 iteration 6602 : loss : 0.001394, loss_ce: 0.000721
2021-12-10 15:56:27,368 iteration 6603 : loss : 0.001227, loss_ce: 0.000736
2021-12-10 15:56:30,112 iteration 6604 : loss : 0.000979, loss_ce: 0.000478
2021-12-10 15:56:32,851 iteration 6605 : loss : 0.000945, loss_ce: 0.000399
2021-12-10 15:56:35,753 iteration 6606 : loss : 0.001304, loss_ce: 0.000541
2021-12-10 15:56:38,502 iteration 6607 : loss : 0.001431, loss_ce: 0.000602
2021-12-10 15:56:41,227 iteration 6608 : loss : 0.001245, loss_ce: 0.000562
2021-12-10 15:56:43,953 iteration 6609 : loss : 0.001409, loss_ce: 0.000571
2021-12-10 15:56:46,821 iteration 6610 : loss : 0.001359, loss_ce: 0.000542
2021-12-10 15:56:49,571 iteration 6611 : loss : 0.001007, loss_ce: 0.000369
2021-12-10 15:56:52,302 iteration 6612 : loss : 0.001323, loss_ce: 0.000732
2021-12-10 15:56:55,023 iteration 6613 : loss : 0.001130, loss_ce: 0.000636
 97%|████████████████████████████▏| 389/400 [5:30:17<08:49, 48.14s/it]2021-12-10 15:56:57,955 iteration 6614 : loss : 0.001222, loss_ce: 0.000411
2021-12-10 15:57:00,714 iteration 6615 : loss : 0.001858, loss_ce: 0.000967
2021-12-10 15:57:03,484 iteration 6616 : loss : 0.001528, loss_ce: 0.000758
2021-12-10 15:57:06,206 iteration 6617 : loss : 0.001300, loss_ce: 0.000603
2021-12-10 15:57:08,933 iteration 6618 : loss : 0.001156, loss_ce: 0.000560
2021-12-10 15:57:11,683 iteration 6619 : loss : 0.001149, loss_ce: 0.000645
2021-12-10 15:57:14,548 iteration 6620 : loss : 0.001334, loss_ce: 0.000782
2021-12-10 15:57:17,277 iteration 6621 : loss : 0.001779, loss_ce: 0.000817
2021-12-10 15:57:19,997 iteration 6622 : loss : 0.001231, loss_ce: 0.000521
2021-12-10 15:57:22,753 iteration 6623 : loss : 0.001501, loss_ce: 0.000562
2021-12-10 15:57:25,490 iteration 6624 : loss : 0.001297, loss_ce: 0.000699
2021-12-10 15:57:28,347 iteration 6625 : loss : 0.001201, loss_ce: 0.000463
2021-12-10 15:57:31,096 iteration 6626 : loss : 0.001235, loss_ce: 0.000636
2021-12-10 15:57:33,987 iteration 6627 : loss : 0.001462, loss_ce: 0.000596
2021-12-10 15:57:36,710 iteration 6628 : loss : 0.001205, loss_ce: 0.000585
2021-12-10 15:57:39,429 iteration 6629 : loss : 0.001180, loss_ce: 0.000433
2021-12-10 15:57:39,429 Training Data Eval:
2021-12-10 15:57:54,842   Average segmentation loss on training set: 0.0010
2021-12-10 15:57:54,843 Validation Data Eval:
2021-12-10 15:58:00,290   Average segmentation loss on validation set: 0.1454
2021-12-10 15:58:03,212 iteration 6630 : loss : 0.000861, loss_ce: 0.000349
 98%|████████████████████████████▎| 390/400 [5:31:26<09:01, 54.16s/it]2021-12-10 15:58:06,010 iteration 6631 : loss : 0.001146, loss_ce: 0.000548
2021-12-10 15:58:08,732 iteration 6632 : loss : 0.001169, loss_ce: 0.000482
2021-12-10 15:58:11,598 iteration 6633 : loss : 0.000978, loss_ce: 0.000448
2021-12-10 15:58:14,320 iteration 6634 : loss : 0.001193, loss_ce: 0.000443
2021-12-10 15:58:17,184 iteration 6635 : loss : 0.001188, loss_ce: 0.000661
2021-12-10 15:58:19,919 iteration 6636 : loss : 0.001227, loss_ce: 0.000640
2021-12-10 15:58:22,812 iteration 6637 : loss : 0.001307, loss_ce: 0.000650
2021-12-10 15:58:25,537 iteration 6638 : loss : 0.001149, loss_ce: 0.000704
2021-12-10 15:58:28,309 iteration 6639 : loss : 0.001059, loss_ce: 0.000485
2021-12-10 15:58:31,204 iteration 6640 : loss : 0.001615, loss_ce: 0.000585
2021-12-10 15:58:33,928 iteration 6641 : loss : 0.001080, loss_ce: 0.000547
2021-12-10 15:58:36,695 iteration 6642 : loss : 0.001151, loss_ce: 0.000435
2021-12-10 15:58:39,555 iteration 6643 : loss : 0.001440, loss_ce: 0.000609
2021-12-10 15:58:42,412 iteration 6644 : loss : 0.001266, loss_ce: 0.000633
2021-12-10 15:58:45,139 iteration 6645 : loss : 0.001092, loss_ce: 0.000515
2021-12-10 15:58:48,021 iteration 6646 : loss : 0.001000, loss_ce: 0.000422
2021-12-10 15:58:50,751 iteration 6647 : loss : 0.001116, loss_ce: 0.000644
 98%|████████████████████████████▎| 391/400 [5:32:13<07:49, 52.17s/it]2021-12-10 15:58:53,663 iteration 6648 : loss : 0.001335, loss_ce: 0.000634
2021-12-10 15:58:56,505 iteration 6649 : loss : 0.001620, loss_ce: 0.000568
2021-12-10 15:58:59,241 iteration 6650 : loss : 0.001384, loss_ce: 0.000869
2021-12-10 15:59:02,139 iteration 6651 : loss : 0.001198, loss_ce: 0.000445
2021-12-10 15:59:04,857 iteration 6652 : loss : 0.001188, loss_ce: 0.000572
2021-12-10 15:59:07,726 iteration 6653 : loss : 0.001938, loss_ce: 0.000891
2021-12-10 15:59:10,508 iteration 6654 : loss : 0.001442, loss_ce: 0.000667
2021-12-10 15:59:13,401 iteration 6655 : loss : 0.001934, loss_ce: 0.000729
2021-12-10 15:59:16,119 iteration 6656 : loss : 0.001017, loss_ce: 0.000476
2021-12-10 15:59:18,991 iteration 6657 : loss : 0.001043, loss_ce: 0.000610
2021-12-10 15:59:21,917 iteration 6658 : loss : 0.001266, loss_ce: 0.000492
2021-12-10 15:59:24,638 iteration 6659 : loss : 0.000878, loss_ce: 0.000382
2021-12-10 15:59:27,553 iteration 6660 : loss : 0.001221, loss_ce: 0.000646
2021-12-10 15:59:30,301 iteration 6661 : loss : 0.001282, loss_ce: 0.000537
2021-12-10 15:59:33,157 iteration 6662 : loss : 0.001283, loss_ce: 0.000560
2021-12-10 15:59:35,882 iteration 6663 : loss : 0.001163, loss_ce: 0.000673
2021-12-10 15:59:38,736 iteration 6664 : loss : 0.001248, loss_ce: 0.000484
 98%|████████████████████████████▍| 392/400 [5:33:01<06:47, 50.92s/it]2021-12-10 15:59:41,730 iteration 6665 : loss : 0.001032, loss_ce: 0.000488
2021-12-10 15:59:44,461 iteration 6666 : loss : 0.001173, loss_ce: 0.000640
2021-12-10 15:59:47,391 iteration 6667 : loss : 0.001164, loss_ce: 0.000604
2021-12-10 15:59:50,151 iteration 6668 : loss : 0.001171, loss_ce: 0.000600
2021-12-10 15:59:53,021 iteration 6669 : loss : 0.001166, loss_ce: 0.000579
2021-12-10 15:59:55,892 iteration 6670 : loss : 0.001447, loss_ce: 0.000569
2021-12-10 15:59:58,756 iteration 6671 : loss : 0.001364, loss_ce: 0.000630
2021-12-10 16:00:01,629 iteration 6672 : loss : 0.001220, loss_ce: 0.000492
2021-12-10 16:00:04,490 iteration 6673 : loss : 0.001210, loss_ce: 0.000448
2021-12-10 16:00:07,364 iteration 6674 : loss : 0.001195, loss_ce: 0.000724
2021-12-10 16:00:10,228 iteration 6675 : loss : 0.001123, loss_ce: 0.000492
2021-12-10 16:00:13,095 iteration 6676 : loss : 0.001361, loss_ce: 0.000682
2021-12-10 16:00:15,961 iteration 6677 : loss : 0.001349, loss_ce: 0.000644
2021-12-10 16:00:18,829 iteration 6678 : loss : 0.001168, loss_ce: 0.000543
2021-12-10 16:00:21,704 iteration 6679 : loss : 0.001510, loss_ce: 0.000500
2021-12-10 16:00:24,542 iteration 6680 : loss : 0.001038, loss_ce: 0.000515
2021-12-10 16:00:27,414 iteration 6681 : loss : 0.001092, loss_ce: 0.000589
 98%|████████████████████████████▍| 393/400 [5:33:50<05:51, 50.24s/it]2021-12-10 16:00:30,196 iteration 6682 : loss : 0.001114, loss_ce: 0.000554
2021-12-10 16:00:33,028 iteration 6683 : loss : 0.001044, loss_ce: 0.000387
2021-12-10 16:00:35,877 iteration 6684 : loss : 0.001258, loss_ce: 0.000732
2021-12-10 16:00:38,727 iteration 6685 : loss : 0.000867, loss_ce: 0.000424
2021-12-10 16:00:41,583 iteration 6686 : loss : 0.001288, loss_ce: 0.000507
2021-12-10 16:00:44,442 iteration 6687 : loss : 0.001530, loss_ce: 0.000773
2021-12-10 16:00:47,389 iteration 6688 : loss : 0.001284, loss_ce: 0.000683
2021-12-10 16:00:50,318 iteration 6689 : loss : 0.001364, loss_ce: 0.000613
2021-12-10 16:00:53,227 iteration 6690 : loss : 0.001209, loss_ce: 0.000622
2021-12-10 16:00:55,961 iteration 6691 : loss : 0.001218, loss_ce: 0.000590
2021-12-10 16:00:58,866 iteration 6692 : loss : 0.000966, loss_ce: 0.000497
2021-12-10 16:01:01,584 iteration 6693 : loss : 0.000937, loss_ce: 0.000466
2021-12-10 16:01:04,606 iteration 6694 : loss : 0.001177, loss_ce: 0.000561
2021-12-10 16:01:07,366 iteration 6695 : loss : 0.001367, loss_ce: 0.000534
2021-12-10 16:01:10,234 iteration 6696 : loss : 0.001171, loss_ce: 0.000488
2021-12-10 16:01:13,104 iteration 6697 : loss : 0.001092, loss_ce: 0.000548
2021-12-10 16:01:15,931 iteration 6698 : loss : 0.001016, loss_ce: 0.000448
 98%|████████████████████████████▌| 394/400 [5:34:38<04:58, 49.72s/it]2021-12-10 16:01:18,808 iteration 6699 : loss : 0.000964, loss_ce: 0.000485
2021-12-10 16:01:21,645 iteration 6700 : loss : 0.001086, loss_ce: 0.000667
2021-12-10 16:01:24,471 iteration 6701 : loss : 0.001403, loss_ce: 0.000672
2021-12-10 16:01:27,402 iteration 6702 : loss : 0.001287, loss_ce: 0.000580
2021-12-10 16:01:30,336 iteration 6703 : loss : 0.001396, loss_ce: 0.000521
2021-12-10 16:01:33,062 iteration 6704 : loss : 0.001270, loss_ce: 0.000733
2021-12-10 16:01:35,952 iteration 6705 : loss : 0.001249, loss_ce: 0.000600
2021-12-10 16:01:38,664 iteration 6706 : loss : 0.001307, loss_ce: 0.000670
2021-12-10 16:01:41,530 iteration 6707 : loss : 0.001037, loss_ce: 0.000384
2021-12-10 16:01:44,467 iteration 6708 : loss : 0.001345, loss_ce: 0.000629
2021-12-10 16:01:47,186 iteration 6709 : loss : 0.000972, loss_ce: 0.000370
2021-12-10 16:01:49,932 iteration 6710 : loss : 0.001205, loss_ce: 0.000456
2021-12-10 16:01:52,757 iteration 6711 : loss : 0.001077, loss_ce: 0.000503
2021-12-10 16:01:55,606 iteration 6712 : loss : 0.001280, loss_ce: 0.000858
2021-12-10 16:01:58,339 iteration 6713 : loss : 0.001141, loss_ce: 0.000434
2021-12-10 16:02:01,203 iteration 6714 : loss : 0.001469, loss_ce: 0.000673
2021-12-10 16:02:01,203 Training Data Eval:
2021-12-10 16:02:16,500   Average segmentation loss on training set: 0.0010
2021-12-10 16:02:16,501 Validation Data Eval:
2021-12-10 16:02:21,953   Average segmentation loss on validation set: 0.1453
2021-12-10 16:02:24,822 iteration 6715 : loss : 0.001083, loss_ce: 0.000636
 99%|████████████████████████████▋| 395/400 [5:35:47<04:37, 55.47s/it]2021-12-10 16:02:27,580 iteration 6716 : loss : 0.001282, loss_ce: 0.000666
2021-12-10 16:02:30,325 iteration 6717 : loss : 0.001079, loss_ce: 0.000474
2021-12-10 16:02:33,182 iteration 6718 : loss : 0.001304, loss_ce: 0.000759
2021-12-10 16:02:36,045 iteration 6719 : loss : 0.000959, loss_ce: 0.000412
2021-12-10 16:02:38,755 iteration 6720 : loss : 0.001197, loss_ce: 0.000520
2021-12-10 16:02:41,618 iteration 6721 : loss : 0.001251, loss_ce: 0.000506
2021-12-10 16:02:44,356 iteration 6722 : loss : 0.001025, loss_ce: 0.000613
2021-12-10 16:02:47,105 iteration 6723 : loss : 0.001340, loss_ce: 0.000532
2021-12-10 16:02:49,978 iteration 6724 : loss : 0.001323, loss_ce: 0.000536
2021-12-10 16:02:52,732 iteration 6725 : loss : 0.001303, loss_ce: 0.000697
2021-12-10 16:02:55,510 iteration 6726 : loss : 0.001235, loss_ce: 0.000594
2021-12-10 16:02:58,251 iteration 6727 : loss : 0.001664, loss_ce: 0.000784
2021-12-10 16:03:01,004 iteration 6728 : loss : 0.001024, loss_ce: 0.000555
2021-12-10 16:03:03,716 iteration 6729 : loss : 0.001112, loss_ce: 0.000430
2021-12-10 16:03:06,597 iteration 6730 : loss : 0.001339, loss_ce: 0.000765
2021-12-10 16:03:09,324 iteration 6731 : loss : 0.000993, loss_ce: 0.000365
2021-12-10 16:03:12,107 iteration 6732 : loss : 0.001385, loss_ce: 0.000551
 99%|████████████████████████████▋| 396/400 [5:36:34<03:32, 53.02s/it]2021-12-10 16:03:14,942 iteration 6733 : loss : 0.001383, loss_ce: 0.000466
2021-12-10 16:03:17,697 iteration 6734 : loss : 0.001166, loss_ce: 0.000500
2021-12-10 16:03:20,480 iteration 6735 : loss : 0.001183, loss_ce: 0.000462
2021-12-10 16:03:23,144 iteration 6736 : loss : 0.001238, loss_ce: 0.000676
2021-12-10 16:03:25,905 iteration 6737 : loss : 0.001108, loss_ce: 0.000573
2021-12-10 16:03:28,681 iteration 6738 : loss : 0.001187, loss_ce: 0.000504
2021-12-10 16:03:31,475 iteration 6739 : loss : 0.000882, loss_ce: 0.000384
2021-12-10 16:03:34,243 iteration 6740 : loss : 0.000976, loss_ce: 0.000460
2021-12-10 16:03:36,846 iteration 6741 : loss : 0.000979, loss_ce: 0.000539
2021-12-10 16:03:39,620 iteration 6742 : loss : 0.001258, loss_ce: 0.000572
2021-12-10 16:03:42,402 iteration 6743 : loss : 0.001106, loss_ce: 0.000620
2021-12-10 16:03:45,067 iteration 6744 : loss : 0.001495, loss_ce: 0.000800
2021-12-10 16:03:47,690 iteration 6745 : loss : 0.001225, loss_ce: 0.000728
2021-12-10 16:03:50,445 iteration 6746 : loss : 0.001077, loss_ce: 0.000607
2021-12-10 16:03:53,183 iteration 6747 : loss : 0.001018, loss_ce: 0.000534
2021-12-10 16:03:55,955 iteration 6748 : loss : 0.001322, loss_ce: 0.000737
2021-12-10 16:03:58,751 iteration 6749 : loss : 0.000893, loss_ce: 0.000338
 99%|████████████████████████████▊| 397/400 [5:37:21<02:33, 51.11s/it]2021-12-10 16:04:01,408 iteration 6750 : loss : 0.001245, loss_ce: 0.000614
2021-12-10 16:04:04,171 iteration 6751 : loss : 0.001367, loss_ce: 0.000819
2021-12-10 16:04:06,798 iteration 6752 : loss : 0.001265, loss_ce: 0.000676
2021-12-10 16:04:09,536 iteration 6753 : loss : 0.001136, loss_ce: 0.000428
2021-12-10 16:04:12,308 iteration 6754 : loss : 0.001171, loss_ce: 0.000485
2021-12-10 16:04:15,110 iteration 6755 : loss : 0.001349, loss_ce: 0.000527
2021-12-10 16:04:17,708 iteration 6756 : loss : 0.001418, loss_ce: 0.000443
2021-12-10 16:04:20,485 iteration 6757 : loss : 0.001094, loss_ce: 0.000582
2021-12-10 16:04:23,094 iteration 6758 : loss : 0.001030, loss_ce: 0.000395
2021-12-10 16:04:25,860 iteration 6759 : loss : 0.000879, loss_ce: 0.000374
2021-12-10 16:04:28,467 iteration 6760 : loss : 0.001263, loss_ce: 0.000574
2021-12-10 16:04:31,240 iteration 6761 : loss : 0.000987, loss_ce: 0.000484
2021-12-10 16:04:33,908 iteration 6762 : loss : 0.001183, loss_ce: 0.000575
2021-12-10 16:04:36,574 iteration 6763 : loss : 0.001338, loss_ce: 0.000699
2021-12-10 16:04:39,194 iteration 6764 : loss : 0.001171, loss_ce: 0.000635
2021-12-10 16:04:41,919 iteration 6765 : loss : 0.001044, loss_ce: 0.000612
2021-12-10 16:04:44,568 iteration 6766 : loss : 0.000937, loss_ce: 0.000537
100%|████████████████████████████▊| 398/400 [5:38:07<01:39, 49.52s/it]2021-12-10 16:04:47,366 iteration 6767 : loss : 0.001493, loss_ce: 0.000928
2021-12-10 16:04:50,025 iteration 6768 : loss : 0.001002, loss_ce: 0.000410
2021-12-10 16:04:52,816 iteration 6769 : loss : 0.001011, loss_ce: 0.000505
2021-12-10 16:04:55,425 iteration 6770 : loss : 0.001093, loss_ce: 0.000642
2021-12-10 16:04:58,205 iteration 6771 : loss : 0.001011, loss_ce: 0.000405
2021-12-10 16:05:00,999 iteration 6772 : loss : 0.001231, loss_ce: 0.000739
2021-12-10 16:05:03,603 iteration 6773 : loss : 0.000982, loss_ce: 0.000478
2021-12-10 16:05:06,381 iteration 6774 : loss : 0.001024, loss_ce: 0.000377
2021-12-10 16:05:08,985 iteration 6775 : loss : 0.000997, loss_ce: 0.000509
2021-12-10 16:05:11,738 iteration 6776 : loss : 0.001253, loss_ce: 0.000672
2021-12-10 16:05:14,347 iteration 6777 : loss : 0.001100, loss_ce: 0.000486
2021-12-10 16:05:17,109 iteration 6778 : loss : 0.001140, loss_ce: 0.000437
2021-12-10 16:05:19,884 iteration 6779 : loss : 0.001176, loss_ce: 0.000538
2021-12-10 16:05:22,515 iteration 6780 : loss : 0.001030, loss_ce: 0.000421
2021-12-10 16:05:25,282 iteration 6781 : loss : 0.001275, loss_ce: 0.000598
2021-12-10 16:05:27,950 iteration 6782 : loss : 0.001351, loss_ce: 0.000698
2021-12-10 16:05:30,732 iteration 6783 : loss : 0.001218, loss_ce: 0.000585
100%|████████████████████████████▉| 399/400 [5:38:53<00:48, 48.51s/it]2021-12-10 16:05:33,534 iteration 6784 : loss : 0.001256, loss_ce: 0.000346
2021-12-10 16:05:36,132 iteration 6785 : loss : 0.001238, loss_ce: 0.000489
2021-12-10 16:05:38,840 iteration 6786 : loss : 0.001101, loss_ce: 0.000593
2021-12-10 16:05:41,561 iteration 6787 : loss : 0.001555, loss_ce: 0.000537
2021-12-10 16:05:44,382 iteration 6788 : loss : 0.001066, loss_ce: 0.000430
2021-12-10 16:05:46,988 iteration 6789 : loss : 0.001110, loss_ce: 0.000624
2021-12-10 16:05:49,713 iteration 6790 : loss : 0.001348, loss_ce: 0.000923
2021-12-10 16:05:52,488 iteration 6791 : loss : 0.001179, loss_ce: 0.000716
2021-12-10 16:05:55,090 iteration 6792 : loss : 0.001054, loss_ce: 0.000436
2021-12-10 16:05:57,857 iteration 6793 : loss : 0.001076, loss_ce: 0.000506
2021-12-10 16:06:00,528 iteration 6794 : loss : 0.000895, loss_ce: 0.000434
2021-12-10 16:06:03,301 iteration 6795 : loss : 0.001123, loss_ce: 0.000509
2021-12-10 16:06:05,908 iteration 6796 : loss : 0.001519, loss_ce: 0.000618
2021-12-10 16:06:08,672 iteration 6797 : loss : 0.001123, loss_ce: 0.000449
2021-12-10 16:06:11,396 iteration 6798 : loss : 0.001303, loss_ce: 0.000779
2021-12-10 16:06:14,173 iteration 6799 : loss : 0.001001, loss_ce: 0.000516
2021-12-10 16:06:14,173 Training Data Eval:
2021-12-10 16:06:28,948   Average segmentation loss on training set: 0.0009
2021-12-10 16:06:28,948 Validation Data Eval:
2021-12-10 16:06:34,260   Average segmentation loss on validation set: 0.1498
2021-12-10 16:06:36,994 iteration 6800 : loss : 0.001209, loss_ce: 0.000723
2021-12-10 16:06:42,963 save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/NEW_TU/NEW_TU_ADAM_seed1234_no_daepoch_399.pth
2021-12-10 16:06:48,748 save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/NEW_TU/NEW_TU_ADAM_seed1234_no_daepoch_399.pth
100%|████████████████████████████▉| 399/400 [5:40:11<00:51, 51.16s/it]
