2021-12-11 19:20:15,004 Logging directory: /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/TransUNet/log_dir/trRUNMC_cv1_r3/i2i2l/
2021-12-11 19:20:15,004 Tensorboard directory: /scratch_net/biwidl217_second/arismu/Tensorboard/trRUNMC_cv1_r3/i2i2l/
2021-12-11 19:20:15,004 ============================================================
2021-12-11 19:20:15,004 EXPERIMENT NAME: trRUNMC_cv1_r3/i2i2l/
2021-12-11 19:20:15,004 ============================================================
2021-12-11 19:20:15,004 Loading data...
2021-12-11 19:20:15,004 Reading NCI - RUNMC images...
2021-12-11 19:20:15,004 Data root directory: /itet-stor/arismu/bmicdatasets-originals/Originals/Challenge_Datasets/NCI_Prostate/
2021-12-11 19:20:15,019 Already preprocessed this configuration. Loading now!
2021-12-11 19:20:15,052 Training Images: (256, 256, 286)
2021-12-11 19:20:15,053 Training Labels: (256, 256, 286)
2021-12-11 19:20:15,053 Validation Images: (256, 256, 98)
2021-12-11 19:20:15,053 Validation Labels: (256, 256, 98)
2021-12-11 19:20:15,053 ============================================================
2021-12-11 19:20:15,223 17 iterations per epoch. 6800 max iterations 
  0%|                                         | 0/400 [00:00<?, ?it/s]2021-12-11 19:20:18,338 iteration 1 : loss : 0.927022, loss_ce: 1.122041
2021-12-11 19:20:19,735 iteration 2 : loss : 0.904998, loss_ce: 1.098883
2021-12-11 19:20:21,233 iteration 3 : loss : 0.820096, loss_ce: 0.969267
2021-12-11 19:20:22,678 iteration 4 : loss : 0.761056, loss_ce: 0.838435
2021-12-11 19:20:24,032 iteration 5 : loss : 0.705781, loss_ce: 0.731925
2021-12-11 19:20:25,441 iteration 6 : loss : 0.685787, loss_ce: 0.707022
2021-12-11 19:20:26,894 iteration 7 : loss : 0.664299, loss_ce: 0.679996
2021-12-11 19:20:28,416 iteration 8 : loss : 0.587532, loss_ce: 0.582775
2021-12-11 19:20:29,798 iteration 9 : loss : 0.645157, loss_ce: 0.617729
2021-12-11 19:20:31,186 iteration 10 : loss : 0.567031, loss_ce: 0.540879
2021-12-11 19:20:32,549 iteration 11 : loss : 0.559412, loss_ce: 0.518662
2021-12-11 19:20:33,973 iteration 12 : loss : 0.531070, loss_ce: 0.484453
2021-12-11 19:20:35,464 iteration 13 : loss : 0.530899, loss_ce: 0.486051
2021-12-11 19:20:36,831 iteration 14 : loss : 0.508165, loss_ce: 0.460564
2021-12-11 19:20:38,314 iteration 15 : loss : 0.480331, loss_ce: 0.433523
2021-12-11 19:20:39,726 iteration 16 : loss : 0.506175, loss_ce: 0.439345
2021-12-11 19:20:41,125 iteration 17 : loss : 0.470857, loss_ce: 0.429190
  0%|                               | 1/400 [00:25<2:52:49, 25.99s/it]2021-12-11 19:20:42,612 iteration 18 : loss : 0.457183, loss_ce: 0.386917
2021-12-11 19:20:44,078 iteration 19 : loss : 0.450805, loss_ce: 0.382423
2021-12-11 19:20:45,504 iteration 20 : loss : 0.430681, loss_ce: 0.365227
2021-12-11 19:20:47,019 iteration 21 : loss : 0.430248, loss_ce: 0.354229
2021-12-11 19:20:48,426 iteration 22 : loss : 0.435164, loss_ce: 0.354225
2021-12-11 19:20:49,869 iteration 23 : loss : 0.393705, loss_ce: 0.315930
2021-12-11 19:20:51,231 iteration 24 : loss : 0.414165, loss_ce: 0.338785
2021-12-11 19:20:52,550 iteration 25 : loss : 0.417661, loss_ce: 0.331424
2021-12-11 19:20:53,914 iteration 26 : loss : 0.429793, loss_ce: 0.324375
2021-12-11 19:20:55,351 iteration 27 : loss : 0.356775, loss_ce: 0.283036
2021-12-11 19:20:56,755 iteration 28 : loss : 0.385655, loss_ce: 0.291660
2021-12-11 19:20:58,337 iteration 29 : loss : 0.388689, loss_ce: 0.295090
2021-12-11 19:20:59,822 iteration 30 : loss : 0.392649, loss_ce: 0.290984
2021-12-11 19:21:01,259 iteration 31 : loss : 0.347594, loss_ce: 0.261740
2021-12-11 19:21:02,784 iteration 32 : loss : 0.366557, loss_ce: 0.266696
2021-12-11 19:21:04,426 iteration 33 : loss : 0.349688, loss_ce: 0.261221
2021-12-11 19:21:05,956 iteration 34 : loss : 0.365669, loss_ce: 0.252880
  0%|▏                              | 2/400 [00:50<2:47:45, 25.29s/it]2021-12-11 19:21:07,637 iteration 35 : loss : 0.325486, loss_ce: 0.246385
2021-12-11 19:21:09,214 iteration 36 : loss : 0.349244, loss_ce: 0.248481
2021-12-11 19:21:10,821 iteration 37 : loss : 0.327589, loss_ce: 0.239212
2021-12-11 19:21:12,567 iteration 38 : loss : 0.327626, loss_ce: 0.219908
2021-12-11 19:21:14,153 iteration 39 : loss : 0.406099, loss_ce: 0.257959
2021-12-11 19:21:15,779 iteration 40 : loss : 0.316856, loss_ce: 0.228919
2021-12-11 19:21:17,289 iteration 41 : loss : 0.326441, loss_ce: 0.209032
2021-12-11 19:21:19,011 iteration 42 : loss : 0.318030, loss_ce: 0.218968
2021-12-11 19:21:20,515 iteration 43 : loss : 0.360352, loss_ce: 0.213918
2021-12-11 19:21:22,111 iteration 44 : loss : 0.314749, loss_ce: 0.199916
2021-12-11 19:21:23,735 iteration 45 : loss : 0.418056, loss_ce: 0.252659
2021-12-11 19:21:25,203 iteration 46 : loss : 0.336996, loss_ce: 0.201044
2021-12-11 19:21:26,762 iteration 47 : loss : 0.342677, loss_ce: 0.181070
2021-12-11 19:21:28,352 iteration 48 : loss : 0.307415, loss_ce: 0.190934
2021-12-11 19:21:29,924 iteration 49 : loss : 0.309391, loss_ce: 0.178558
2021-12-11 19:21:31,552 iteration 50 : loss : 0.293203, loss_ce: 0.169364
2021-12-11 19:21:33,135 iteration 51 : loss : 0.291430, loss_ce: 0.192554
  1%|▏                              | 3/400 [01:17<2:53:02, 26.15s/it]2021-12-11 19:21:34,673 iteration 52 : loss : 0.316295, loss_ce: 0.197940
2021-12-11 19:21:36,138 iteration 53 : loss : 0.305439, loss_ce: 0.198142
2021-12-11 19:21:37,741 iteration 54 : loss : 0.261846, loss_ce: 0.168105
2021-12-11 19:21:39,327 iteration 55 : loss : 0.354075, loss_ce: 0.208820
2021-12-11 19:21:40,942 iteration 56 : loss : 0.268478, loss_ce: 0.160559
2021-12-11 19:21:42,548 iteration 57 : loss : 0.320758, loss_ce: 0.185858
2021-12-11 19:21:44,135 iteration 58 : loss : 0.298589, loss_ce: 0.179796
2021-12-11 19:21:45,693 iteration 59 : loss : 0.305895, loss_ce: 0.169140
2021-12-11 19:21:47,331 iteration 60 : loss : 0.296503, loss_ce: 0.162167
2021-12-11 19:21:48,987 iteration 61 : loss : 0.266072, loss_ce: 0.155303
2021-12-11 19:21:50,553 iteration 62 : loss : 0.285438, loss_ce: 0.154002
2021-12-11 19:21:52,041 iteration 63 : loss : 0.257400, loss_ce: 0.152242
2021-12-11 19:21:53,591 iteration 64 : loss : 0.337932, loss_ce: 0.212065
2021-12-11 19:21:55,141 iteration 65 : loss : 0.314989, loss_ce: 0.163502
2021-12-11 19:21:56,764 iteration 66 : loss : 0.273192, loss_ce: 0.151924
2021-12-11 19:21:58,282 iteration 67 : loss : 0.324115, loss_ce: 0.182907
2021-12-11 19:21:59,837 iteration 68 : loss : 0.335297, loss_ce: 0.164451
  1%|▎                              | 4/400 [01:44<2:54:02, 26.37s/it]2021-12-11 19:22:01,463 iteration 69 : loss : 0.304225, loss_ce: 0.147697
2021-12-11 19:22:03,057 iteration 70 : loss : 0.347755, loss_ce: 0.186719
2021-12-11 19:22:04,576 iteration 71 : loss : 0.274430, loss_ce: 0.140719
2021-12-11 19:22:06,206 iteration 72 : loss : 0.290808, loss_ce: 0.141923
2021-12-11 19:22:07,756 iteration 73 : loss : 0.263272, loss_ce: 0.152233
2021-12-11 19:22:09,417 iteration 74 : loss : 0.285917, loss_ce: 0.151601
2021-12-11 19:22:11,007 iteration 75 : loss : 0.287703, loss_ce: 0.175216
2021-12-11 19:22:12,649 iteration 76 : loss : 0.281607, loss_ce: 0.152313
2021-12-11 19:22:14,313 iteration 77 : loss : 0.275302, loss_ce: 0.142473
2021-12-11 19:22:15,955 iteration 78 : loss : 0.228482, loss_ce: 0.135992
2021-12-11 19:22:17,467 iteration 79 : loss : 0.227384, loss_ce: 0.115024
2021-12-11 19:22:19,091 iteration 80 : loss : 0.334911, loss_ce: 0.158512
2021-12-11 19:22:20,654 iteration 81 : loss : 0.245566, loss_ce: 0.120936
2021-12-11 19:22:22,218 iteration 82 : loss : 0.296883, loss_ce: 0.164457
2021-12-11 19:22:23,858 iteration 83 : loss : 0.239535, loss_ce: 0.120328
2021-12-11 19:22:25,391 iteration 84 : loss : 0.272044, loss_ce: 0.138522
2021-12-11 19:22:25,392 Training Data Eval:
2021-12-11 19:22:33,133   Average segmentation loss on training set: 0.3715
2021-12-11 19:22:33,133 Validation Data Eval:
2021-12-11 19:22:35,966   Average segmentation loss on validation set: 0.3534
2021-12-11 19:22:37,851 Found new lowest validation loss at iteration 84! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/NEW_TU/UNET_ADAM_best_val_loss_seed2.pth
2021-12-11 19:22:39,509 iteration 85 : loss : 0.270282, loss_ce: 0.140960
  1%|▍                              | 5/400 [02:24<3:25:10, 31.17s/it]2021-12-11 19:22:41,100 iteration 86 : loss : 0.286977, loss_ce: 0.121464
2021-12-11 19:22:42,561 iteration 87 : loss : 0.271799, loss_ce: 0.132430
2021-12-11 19:22:44,083 iteration 88 : loss : 0.222866, loss_ce: 0.101044
2021-12-11 19:22:45,714 iteration 89 : loss : 0.230025, loss_ce: 0.114878
2021-12-11 19:22:47,230 iteration 90 : loss : 0.213705, loss_ce: 0.109580
2021-12-11 19:22:48,780 iteration 91 : loss : 0.287584, loss_ce: 0.154614
2021-12-11 19:22:50,325 iteration 92 : loss : 0.230274, loss_ce: 0.120044
2021-12-11 19:22:51,974 iteration 93 : loss : 0.231609, loss_ce: 0.124699
2021-12-11 19:22:53,628 iteration 94 : loss : 0.213280, loss_ce: 0.131682
2021-12-11 19:22:55,176 iteration 95 : loss : 0.246810, loss_ce: 0.121472
2021-12-11 19:22:56,685 iteration 96 : loss : 0.205644, loss_ce: 0.102737
2021-12-11 19:22:58,201 iteration 97 : loss : 0.179010, loss_ce: 0.094236
2021-12-11 19:22:59,755 iteration 98 : loss : 0.253362, loss_ce: 0.122952
2021-12-11 19:23:01,476 iteration 99 : loss : 0.207807, loss_ce: 0.107698
2021-12-11 19:23:03,205 iteration 100 : loss : 0.271696, loss_ce: 0.134716
2021-12-11 19:23:04,750 iteration 101 : loss : 0.306201, loss_ce: 0.159813
2021-12-11 19:23:06,318 iteration 102 : loss : 0.252702, loss_ce: 0.116028
  2%|▍                              | 6/400 [02:51<3:14:57, 29.69s/it]2021-12-11 19:23:07,972 iteration 103 : loss : 0.250308, loss_ce: 0.119864
2021-12-11 19:23:09,611 iteration 104 : loss : 0.267823, loss_ce: 0.124731
2021-12-11 19:23:11,220 iteration 105 : loss : 0.250327, loss_ce: 0.119888
2021-12-11 19:23:12,829 iteration 106 : loss : 0.235280, loss_ce: 0.104190
2021-12-11 19:23:14,509 iteration 107 : loss : 0.214541, loss_ce: 0.101204
2021-12-11 19:23:16,083 iteration 108 : loss : 0.242797, loss_ce: 0.122153
2021-12-11 19:23:17,681 iteration 109 : loss : 0.187013, loss_ce: 0.092615
2021-12-11 19:23:19,310 iteration 110 : loss : 0.252928, loss_ce: 0.129439
2021-12-11 19:23:21,114 iteration 111 : loss : 0.199678, loss_ce: 0.099320
2021-12-11 19:23:22,674 iteration 112 : loss : 0.250574, loss_ce: 0.119659
2021-12-11 19:23:24,391 iteration 113 : loss : 0.199901, loss_ce: 0.095999
2021-12-11 19:23:25,986 iteration 114 : loss : 0.208423, loss_ce: 0.087767
2021-12-11 19:23:27,490 iteration 115 : loss : 0.189375, loss_ce: 0.086382
2021-12-11 19:23:29,082 iteration 116 : loss : 0.272410, loss_ce: 0.133396
2021-12-11 19:23:30,633 iteration 117 : loss : 0.161240, loss_ce: 0.079019
2021-12-11 19:23:32,285 iteration 118 : loss : 0.243403, loss_ce: 0.105797
2021-12-11 19:23:33,833 iteration 119 : loss : 0.268175, loss_ce: 0.127531
  2%|▌                              | 7/400 [03:18<3:09:47, 28.98s/it]2021-12-11 19:23:35,547 iteration 120 : loss : 0.236176, loss_ce: 0.128738
2021-12-11 19:23:37,182 iteration 121 : loss : 0.274487, loss_ce: 0.133805
2021-12-11 19:23:38,655 iteration 122 : loss : 0.213064, loss_ce: 0.100086
2021-12-11 19:23:40,251 iteration 123 : loss : 0.228979, loss_ce: 0.114229
2021-12-11 19:23:41,807 iteration 124 : loss : 0.195546, loss_ce: 0.087409
2021-12-11 19:23:43,374 iteration 125 : loss : 0.217839, loss_ce: 0.090734
2021-12-11 19:23:44,934 iteration 126 : loss : 0.170207, loss_ce: 0.080540
2021-12-11 19:23:46,503 iteration 127 : loss : 0.263893, loss_ce: 0.128052
2021-12-11 19:23:48,042 iteration 128 : loss : 0.222921, loss_ce: 0.095262
2021-12-11 19:23:49,687 iteration 129 : loss : 0.256188, loss_ce: 0.127360
2021-12-11 19:23:51,141 iteration 130 : loss : 0.224616, loss_ce: 0.103562
2021-12-11 19:23:52,684 iteration 131 : loss : 0.218056, loss_ce: 0.113222
2021-12-11 19:23:54,262 iteration 132 : loss : 0.211272, loss_ce: 0.101548
2021-12-11 19:23:55,844 iteration 133 : loss : 0.281704, loss_ce: 0.157619
2021-12-11 19:23:57,404 iteration 134 : loss : 0.196404, loss_ce: 0.077508
2021-12-11 19:23:58,942 iteration 135 : loss : 0.183382, loss_ce: 0.068929
2021-12-11 19:24:00,602 iteration 136 : loss : 0.180417, loss_ce: 0.085735
  2%|▌                              | 8/400 [03:45<3:04:42, 28.27s/it]2021-12-11 19:24:02,327 iteration 137 : loss : 0.221670, loss_ce: 0.089259
2021-12-11 19:24:03,832 iteration 138 : loss : 0.166565, loss_ce: 0.077402
2021-12-11 19:24:05,508 iteration 139 : loss : 0.212397, loss_ce: 0.072039
2021-12-11 19:24:07,072 iteration 140 : loss : 0.290144, loss_ce: 0.134701
2021-12-11 19:24:08,583 iteration 141 : loss : 0.234790, loss_ce: 0.099390
2021-12-11 19:24:10,138 iteration 142 : loss : 0.196301, loss_ce: 0.088634
2021-12-11 19:24:11,721 iteration 143 : loss : 0.225284, loss_ce: 0.096290
2021-12-11 19:24:13,268 iteration 144 : loss : 0.191368, loss_ce: 0.069542
2021-12-11 19:24:14,844 iteration 145 : loss : 0.195501, loss_ce: 0.099897
2021-12-11 19:24:16,458 iteration 146 : loss : 0.160893, loss_ce: 0.071900
2021-12-11 19:24:18,040 iteration 147 : loss : 0.256499, loss_ce: 0.122934
2021-12-11 19:24:19,725 iteration 148 : loss : 0.187562, loss_ce: 0.088287
2021-12-11 19:24:21,391 iteration 149 : loss : 0.223383, loss_ce: 0.105292
2021-12-11 19:24:23,052 iteration 150 : loss : 0.190646, loss_ce: 0.091554
2021-12-11 19:24:24,575 iteration 151 : loss : 0.193102, loss_ce: 0.114008
2021-12-11 19:24:26,041 iteration 152 : loss : 0.143752, loss_ce: 0.081015
2021-12-11 19:24:27,592 iteration 153 : loss : 0.180978, loss_ce: 0.083481
  2%|▋                              | 9/400 [04:12<3:01:37, 27.87s/it]2021-12-11 19:24:29,267 iteration 154 : loss : 0.230999, loss_ce: 0.118203
2021-12-11 19:24:30,833 iteration 155 : loss : 0.174334, loss_ce: 0.093326
2021-12-11 19:24:32,350 iteration 156 : loss : 0.200353, loss_ce: 0.093650
2021-12-11 19:24:33,871 iteration 157 : loss : 0.185896, loss_ce: 0.089673
2021-12-11 19:24:35,515 iteration 158 : loss : 0.217929, loss_ce: 0.094848
2021-12-11 19:24:37,153 iteration 159 : loss : 0.183295, loss_ce: 0.083692
2021-12-11 19:24:38,701 iteration 160 : loss : 0.204185, loss_ce: 0.090035
2021-12-11 19:24:40,372 iteration 161 : loss : 0.120145, loss_ce: 0.062513
2021-12-11 19:24:41,949 iteration 162 : loss : 0.201062, loss_ce: 0.075554
2021-12-11 19:24:43,528 iteration 163 : loss : 0.229862, loss_ce: 0.107018
2021-12-11 19:24:45,087 iteration 164 : loss : 0.202826, loss_ce: 0.078940
2021-12-11 19:24:46,574 iteration 165 : loss : 0.180171, loss_ce: 0.084763
2021-12-11 19:24:48,180 iteration 166 : loss : 0.264452, loss_ce: 0.156235
2021-12-11 19:24:49,877 iteration 167 : loss : 0.255111, loss_ce: 0.121882
2021-12-11 19:24:51,429 iteration 168 : loss : 0.206879, loss_ce: 0.078535
2021-12-11 19:24:53,054 iteration 169 : loss : 0.176029, loss_ce: 0.085839
2021-12-11 19:24:53,055 Training Data Eval:
2021-12-11 19:25:00,834   Average segmentation loss on training set: 0.2712
2021-12-11 19:25:00,834 Validation Data Eval:
2021-12-11 19:25:03,641   Average segmentation loss on validation set: 0.2908
2021-12-11 19:25:05,555 Found new lowest validation loss at iteration 169! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/NEW_TU/UNET_ADAM_best_val_loss_seed2.pth
2021-12-11 19:25:07,251 iteration 170 : loss : 0.198367, loss_ce: 0.089641
  2%|▊                             | 10/400 [04:52<3:24:48, 31.51s/it]2021-12-11 19:25:08,956 iteration 171 : loss : 0.168481, loss_ce: 0.077374
2021-12-11 19:25:10,465 iteration 172 : loss : 0.178751, loss_ce: 0.089809
2021-12-11 19:25:12,102 iteration 173 : loss : 0.192813, loss_ce: 0.086158
2021-12-11 19:25:13,583 iteration 174 : loss : 0.180082, loss_ce: 0.105250
2021-12-11 19:25:15,116 iteration 175 : loss : 0.186173, loss_ce: 0.075696
2021-12-11 19:25:16,650 iteration 176 : loss : 0.181505, loss_ce: 0.087634
2021-12-11 19:25:18,255 iteration 177 : loss : 0.154793, loss_ce: 0.071035
2021-12-11 19:25:19,816 iteration 178 : loss : 0.174831, loss_ce: 0.072438
2021-12-11 19:25:21,297 iteration 179 : loss : 0.185790, loss_ce: 0.073994
2021-12-11 19:25:22,967 iteration 180 : loss : 0.210503, loss_ce: 0.105779
2021-12-11 19:25:24,586 iteration 181 : loss : 0.168810, loss_ce: 0.076813
2021-12-11 19:25:26,146 iteration 182 : loss : 0.175611, loss_ce: 0.084463
2021-12-11 19:25:27,745 iteration 183 : loss : 0.176527, loss_ce: 0.067063
2021-12-11 19:25:29,490 iteration 184 : loss : 0.196020, loss_ce: 0.074116
2021-12-11 19:25:31,218 iteration 185 : loss : 0.202819, loss_ce: 0.088437
2021-12-11 19:25:32,773 iteration 186 : loss : 0.187880, loss_ce: 0.074051
2021-12-11 19:25:34,370 iteration 187 : loss : 0.123646, loss_ce: 0.059883
  3%|▊                             | 11/400 [05:19<3:15:34, 30.17s/it]2021-12-11 19:25:35,962 iteration 188 : loss : 0.154786, loss_ce: 0.069868
2021-12-11 19:25:37,642 iteration 189 : loss : 0.176039, loss_ce: 0.076923
2021-12-11 19:25:39,253 iteration 190 : loss : 0.214982, loss_ce: 0.104829
2021-12-11 19:25:40,851 iteration 191 : loss : 0.150990, loss_ce: 0.065363
2021-12-11 19:25:42,422 iteration 192 : loss : 0.184729, loss_ce: 0.068356
2021-12-11 19:25:43,913 iteration 193 : loss : 0.183202, loss_ce: 0.077057
2021-12-11 19:25:45,528 iteration 194 : loss : 0.185668, loss_ce: 0.079574
2021-12-11 19:25:47,152 iteration 195 : loss : 0.160555, loss_ce: 0.063437
2021-12-11 19:25:48,703 iteration 196 : loss : 0.159065, loss_ce: 0.076165
2021-12-11 19:25:50,317 iteration 197 : loss : 0.195144, loss_ce: 0.069248
2021-12-11 19:25:51,910 iteration 198 : loss : 0.162906, loss_ce: 0.063811
2021-12-11 19:25:53,374 iteration 199 : loss : 0.240671, loss_ce: 0.083227
2021-12-11 19:25:54,925 iteration 200 : loss : 0.184219, loss_ce: 0.083034
2021-12-11 19:25:56,631 iteration 201 : loss : 0.181577, loss_ce: 0.082227
2021-12-11 19:25:58,176 iteration 202 : loss : 0.158261, loss_ce: 0.069092
2021-12-11 19:25:59,691 iteration 203 : loss : 0.210972, loss_ce: 0.106721
2021-12-11 19:26:01,169 iteration 204 : loss : 0.145700, loss_ce: 0.073135
  3%|▉                             | 12/400 [05:46<3:08:28, 29.14s/it]2021-12-11 19:26:02,727 iteration 205 : loss : 0.184052, loss_ce: 0.085698
2021-12-11 19:26:04,328 iteration 206 : loss : 0.228844, loss_ce: 0.113989
2021-12-11 19:26:06,015 iteration 207 : loss : 0.177908, loss_ce: 0.089564
2021-12-11 19:26:07,708 iteration 208 : loss : 0.150097, loss_ce: 0.057451
2021-12-11 19:26:09,227 iteration 209 : loss : 0.161257, loss_ce: 0.064805
2021-12-11 19:26:10,723 iteration 210 : loss : 0.146925, loss_ce: 0.054817
2021-12-11 19:26:12,283 iteration 211 : loss : 0.160841, loss_ce: 0.065547
2021-12-11 19:26:13,752 iteration 212 : loss : 0.209452, loss_ce: 0.086557
2021-12-11 19:26:15,372 iteration 213 : loss : 0.174754, loss_ce: 0.079595
2021-12-11 19:26:16,966 iteration 214 : loss : 0.238419, loss_ce: 0.081648
2021-12-11 19:26:18,462 iteration 215 : loss : 0.154513, loss_ce: 0.064696
2021-12-11 19:26:20,094 iteration 216 : loss : 0.194881, loss_ce: 0.082996
2021-12-11 19:26:21,625 iteration 217 : loss : 0.144323, loss_ce: 0.061419
2021-12-11 19:26:23,164 iteration 218 : loss : 0.118958, loss_ce: 0.051476
2021-12-11 19:26:24,712 iteration 219 : loss : 0.153295, loss_ce: 0.057987
2021-12-11 19:26:26,212 iteration 220 : loss : 0.187564, loss_ce: 0.085704
2021-12-11 19:26:27,760 iteration 221 : loss : 0.144289, loss_ce: 0.075138
  3%|▉                             | 13/400 [06:12<3:02:59, 28.37s/it]2021-12-11 19:26:29,536 iteration 222 : loss : 0.166507, loss_ce: 0.066358
2021-12-11 19:26:31,164 iteration 223 : loss : 0.146062, loss_ce: 0.054792
2021-12-11 19:26:32,627 iteration 224 : loss : 0.164451, loss_ce: 0.072974
2021-12-11 19:26:34,247 iteration 225 : loss : 0.167039, loss_ce: 0.066706
2021-12-11 19:26:35,878 iteration 226 : loss : 0.234292, loss_ce: 0.094421
2021-12-11 19:26:37,493 iteration 227 : loss : 0.174104, loss_ce: 0.075599
2021-12-11 19:26:39,089 iteration 228 : loss : 0.181156, loss_ce: 0.075452
2021-12-11 19:26:40,681 iteration 229 : loss : 0.150635, loss_ce: 0.064870
2021-12-11 19:26:42,244 iteration 230 : loss : 0.173886, loss_ce: 0.078488
2021-12-11 19:26:43,771 iteration 231 : loss : 0.196487, loss_ce: 0.072426
2021-12-11 19:26:45,437 iteration 232 : loss : 0.157202, loss_ce: 0.089811
2021-12-11 19:26:47,084 iteration 233 : loss : 0.166354, loss_ce: 0.088798
2021-12-11 19:26:48,697 iteration 234 : loss : 0.177283, loss_ce: 0.058337
2021-12-11 19:26:50,263 iteration 235 : loss : 0.133744, loss_ce: 0.057218
2021-12-11 19:26:51,807 iteration 236 : loss : 0.159852, loss_ce: 0.067561
2021-12-11 19:26:53,344 iteration 237 : loss : 0.130417, loss_ce: 0.054866
2021-12-11 19:26:54,792 iteration 238 : loss : 0.144830, loss_ce: 0.066669
  4%|█                             | 14/400 [06:39<2:59:53, 27.96s/it]2021-12-11 19:26:56,369 iteration 239 : loss : 0.142818, loss_ce: 0.054569
2021-12-11 19:26:58,012 iteration 240 : loss : 0.158604, loss_ce: 0.082529
2021-12-11 19:26:59,531 iteration 241 : loss : 0.209036, loss_ce: 0.067447
2021-12-11 19:27:01,157 iteration 242 : loss : 0.158406, loss_ce: 0.064821
2021-12-11 19:27:02,817 iteration 243 : loss : 0.175270, loss_ce: 0.081825
2021-12-11 19:27:04,449 iteration 244 : loss : 0.146822, loss_ce: 0.067085
2021-12-11 19:27:05,927 iteration 245 : loss : 0.140605, loss_ce: 0.051578
2021-12-11 19:27:07,506 iteration 246 : loss : 0.148276, loss_ce: 0.053812
2021-12-11 19:27:09,011 iteration 247 : loss : 0.152650, loss_ce: 0.064946
2021-12-11 19:27:10,471 iteration 248 : loss : 0.120886, loss_ce: 0.047038
2021-12-11 19:27:12,147 iteration 249 : loss : 0.171794, loss_ce: 0.061885
2021-12-11 19:27:13,784 iteration 250 : loss : 0.160824, loss_ce: 0.070643
2021-12-11 19:27:15,316 iteration 251 : loss : 0.129778, loss_ce: 0.055189
2021-12-11 19:27:16,893 iteration 252 : loss : 0.112014, loss_ce: 0.061392
2021-12-11 19:27:18,406 iteration 253 : loss : 0.185382, loss_ce: 0.064910
2021-12-11 19:27:19,913 iteration 254 : loss : 0.169913, loss_ce: 0.069667
2021-12-11 19:27:19,913 Training Data Eval:
2021-12-11 19:27:27,691   Average segmentation loss on training set: 0.1868
2021-12-11 19:27:27,691 Validation Data Eval:
2021-12-11 19:27:30,348   Average segmentation loss on validation set: 0.3014
2021-12-11 19:27:31,900 iteration 255 : loss : 0.205999, loss_ce: 0.085246
  4%|█▏                            | 15/400 [07:16<3:17:06, 30.72s/it]2021-12-11 19:27:33,527 iteration 256 : loss : 0.164269, loss_ce: 0.061823
2021-12-11 19:27:35,067 iteration 257 : loss : 0.173456, loss_ce: 0.091676
2021-12-11 19:27:36,774 iteration 258 : loss : 0.160664, loss_ce: 0.052070
2021-12-11 19:27:38,280 iteration 259 : loss : 0.181238, loss_ce: 0.063356
2021-12-11 19:27:39,875 iteration 260 : loss : 0.167055, loss_ce: 0.071482
2021-12-11 19:27:41,484 iteration 261 : loss : 0.168154, loss_ce: 0.072452
2021-12-11 19:27:43,079 iteration 262 : loss : 0.161217, loss_ce: 0.087967
2021-12-11 19:27:44,595 iteration 263 : loss : 0.195484, loss_ce: 0.100152
2021-12-11 19:27:46,099 iteration 264 : loss : 0.164016, loss_ce: 0.068191
2021-12-11 19:27:47,718 iteration 265 : loss : 0.133871, loss_ce: 0.062381
2021-12-11 19:27:49,309 iteration 266 : loss : 0.174695, loss_ce: 0.061090
2021-12-11 19:27:50,860 iteration 267 : loss : 0.135213, loss_ce: 0.054080
2021-12-11 19:27:52,426 iteration 268 : loss : 0.124671, loss_ce: 0.061501
2021-12-11 19:27:53,964 iteration 269 : loss : 0.127735, loss_ce: 0.056636
2021-12-11 19:27:55,432 iteration 270 : loss : 0.154151, loss_ce: 0.061158
2021-12-11 19:27:57,016 iteration 271 : loss : 0.261431, loss_ce: 0.095581
2021-12-11 19:27:58,667 iteration 272 : loss : 0.179630, loss_ce: 0.087062
  4%|█▏                            | 16/400 [07:43<3:09:01, 29.53s/it]2021-12-11 19:28:00,281 iteration 273 : loss : 0.119588, loss_ce: 0.053548
2021-12-11 19:28:01,870 iteration 274 : loss : 0.148718, loss_ce: 0.062623
2021-12-11 19:28:03,428 iteration 275 : loss : 0.135659, loss_ce: 0.062749
2021-12-11 19:28:04,923 iteration 276 : loss : 0.152058, loss_ce: 0.074338
2021-12-11 19:28:06,582 iteration 277 : loss : 0.158047, loss_ce: 0.058669
2021-12-11 19:28:08,063 iteration 278 : loss : 0.255754, loss_ce: 0.096384
2021-12-11 19:28:09,625 iteration 279 : loss : 0.142066, loss_ce: 0.059421
2021-12-11 19:28:11,081 iteration 280 : loss : 0.125853, loss_ce: 0.063508
2021-12-11 19:28:12,660 iteration 281 : loss : 0.151259, loss_ce: 0.061082
2021-12-11 19:28:14,266 iteration 282 : loss : 0.174719, loss_ce: 0.067060
2021-12-11 19:28:15,848 iteration 283 : loss : 0.140466, loss_ce: 0.067486
2021-12-11 19:28:17,357 iteration 284 : loss : 0.109452, loss_ce: 0.041879
2021-12-11 19:28:18,936 iteration 285 : loss : 0.139345, loss_ce: 0.050074
2021-12-11 19:28:20,535 iteration 286 : loss : 0.129864, loss_ce: 0.047043
2021-12-11 19:28:22,040 iteration 287 : loss : 0.168589, loss_ce: 0.067690
2021-12-11 19:28:23,614 iteration 288 : loss : 0.132549, loss_ce: 0.057735
2021-12-11 19:28:25,166 iteration 289 : loss : 0.137525, loss_ce: 0.068026
  4%|█▎                            | 17/400 [08:10<3:02:42, 28.62s/it]2021-12-11 19:28:26,807 iteration 290 : loss : 0.129994, loss_ce: 0.058598
2021-12-11 19:28:28,375 iteration 291 : loss : 0.101565, loss_ce: 0.043918
2021-12-11 19:28:29,946 iteration 292 : loss : 0.104017, loss_ce: 0.042577
2021-12-11 19:28:31,679 iteration 293 : loss : 0.156843, loss_ce: 0.075906
2021-12-11 19:28:33,206 iteration 294 : loss : 0.125120, loss_ce: 0.056218
2021-12-11 19:28:34,728 iteration 295 : loss : 0.224073, loss_ce: 0.084631
2021-12-11 19:28:36,271 iteration 296 : loss : 0.139608, loss_ce: 0.051783
2021-12-11 19:28:37,913 iteration 297 : loss : 0.160476, loss_ce: 0.074145
2021-12-11 19:28:39,430 iteration 298 : loss : 0.145933, loss_ce: 0.047301
2021-12-11 19:28:41,037 iteration 299 : loss : 0.176733, loss_ce: 0.058780
2021-12-11 19:28:42,561 iteration 300 : loss : 0.117877, loss_ce: 0.048514
2021-12-11 19:28:44,117 iteration 301 : loss : 0.159447, loss_ce: 0.061892
2021-12-11 19:28:45,796 iteration 302 : loss : 0.229967, loss_ce: 0.126830
2021-12-11 19:28:47,409 iteration 303 : loss : 0.137042, loss_ce: 0.067428
2021-12-11 19:28:48,956 iteration 304 : loss : 0.103061, loss_ce: 0.041405
2021-12-11 19:28:50,530 iteration 305 : loss : 0.120805, loss_ce: 0.051788
2021-12-11 19:28:52,091 iteration 306 : loss : 0.151084, loss_ce: 0.059058
  4%|█▎                            | 18/400 [08:36<2:58:57, 28.11s/it]2021-12-11 19:28:53,690 iteration 307 : loss : 0.157146, loss_ce: 0.073765
2021-12-11 19:28:55,308 iteration 308 : loss : 0.164349, loss_ce: 0.057553
2021-12-11 19:28:56,883 iteration 309 : loss : 0.136608, loss_ce: 0.062288
2021-12-11 19:28:58,422 iteration 310 : loss : 0.112988, loss_ce: 0.045186
2021-12-11 19:28:59,943 iteration 311 : loss : 0.127898, loss_ce: 0.053006
2021-12-11 19:29:01,526 iteration 312 : loss : 0.205300, loss_ce: 0.055008
2021-12-11 19:29:03,148 iteration 313 : loss : 0.121942, loss_ce: 0.046399
2021-12-11 19:29:04,605 iteration 314 : loss : 0.165849, loss_ce: 0.065699
2021-12-11 19:29:06,139 iteration 315 : loss : 0.167797, loss_ce: 0.071961
2021-12-11 19:29:07,779 iteration 316 : loss : 0.160521, loss_ce: 0.069027
2021-12-11 19:29:09,436 iteration 317 : loss : 0.166516, loss_ce: 0.070686
2021-12-11 19:29:10,995 iteration 318 : loss : 0.180823, loss_ce: 0.097293
2021-12-11 19:29:12,576 iteration 319 : loss : 0.122593, loss_ce: 0.052523
2021-12-11 19:29:14,157 iteration 320 : loss : 0.124290, loss_ce: 0.050549
2021-12-11 19:29:15,683 iteration 321 : loss : 0.162957, loss_ce: 0.062561
2021-12-11 19:29:17,184 iteration 322 : loss : 0.093644, loss_ce: 0.042022
2021-12-11 19:29:18,727 iteration 323 : loss : 0.127203, loss_ce: 0.054343
  5%|█▍                            | 19/400 [09:03<2:55:41, 27.67s/it]2021-12-11 19:29:20,362 iteration 324 : loss : 0.107341, loss_ce: 0.041080
2021-12-11 19:29:21,882 iteration 325 : loss : 0.147532, loss_ce: 0.053013
2021-12-11 19:29:23,402 iteration 326 : loss : 0.199287, loss_ce: 0.088946
2021-12-11 19:29:24,886 iteration 327 : loss : 0.155850, loss_ce: 0.068902
2021-12-11 19:29:26,465 iteration 328 : loss : 0.138022, loss_ce: 0.048623
2021-12-11 19:29:28,099 iteration 329 : loss : 0.194955, loss_ce: 0.072635
2021-12-11 19:29:29,632 iteration 330 : loss : 0.137214, loss_ce: 0.062839
2021-12-11 19:29:31,192 iteration 331 : loss : 0.147876, loss_ce: 0.058835
2021-12-11 19:29:32,657 iteration 332 : loss : 0.104191, loss_ce: 0.044645
2021-12-11 19:29:34,273 iteration 333 : loss : 0.163064, loss_ce: 0.070728
2021-12-11 19:29:35,843 iteration 334 : loss : 0.127253, loss_ce: 0.051263
2021-12-11 19:29:37,484 iteration 335 : loss : 0.155862, loss_ce: 0.085218
2021-12-11 19:29:39,040 iteration 336 : loss : 0.125801, loss_ce: 0.062943
2021-12-11 19:29:40,577 iteration 337 : loss : 0.169928, loss_ce: 0.059491
2021-12-11 19:29:42,133 iteration 338 : loss : 0.123421, loss_ce: 0.052111
2021-12-11 19:29:43,663 iteration 339 : loss : 0.133130, loss_ce: 0.059438
2021-12-11 19:29:43,663 Training Data Eval:
2021-12-11 19:29:51,442   Average segmentation loss on training set: 0.1353
2021-12-11 19:29:51,443 Validation Data Eval:
2021-12-11 19:29:54,101   Average segmentation loss on validation set: 0.1658
2021-12-11 19:29:56,205 Found new lowest validation loss at iteration 339! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/NEW_TU/UNET_ADAM_best_val_loss_seed2.pth
2021-12-11 19:29:57,840 iteration 340 : loss : 0.170172, loss_ce: 0.086249
  5%|█▌                            | 20/400 [09:42<3:16:59, 31.10s/it]2021-12-11 19:29:59,442 iteration 341 : loss : 0.099423, loss_ce: 0.045333
2021-12-11 19:30:01,069 iteration 342 : loss : 0.139350, loss_ce: 0.060069
2021-12-11 19:30:02,679 iteration 343 : loss : 0.129698, loss_ce: 0.056401
2021-12-11 19:30:04,230 iteration 344 : loss : 0.116519, loss_ce: 0.053986
2021-12-11 19:30:05,772 iteration 345 : loss : 0.117676, loss_ce: 0.050368
2021-12-11 19:30:07,392 iteration 346 : loss : 0.099516, loss_ce: 0.043454
2021-12-11 19:30:09,016 iteration 347 : loss : 0.161369, loss_ce: 0.075110
2021-12-11 19:30:10,564 iteration 348 : loss : 0.119291, loss_ce: 0.053234
2021-12-11 19:30:12,129 iteration 349 : loss : 0.140261, loss_ce: 0.052993
2021-12-11 19:30:13,731 iteration 350 : loss : 0.121384, loss_ce: 0.052604
2021-12-11 19:30:15,278 iteration 351 : loss : 0.122459, loss_ce: 0.050078
2021-12-11 19:30:16,961 iteration 352 : loss : 0.153207, loss_ce: 0.080454
2021-12-11 19:30:18,642 iteration 353 : loss : 0.168695, loss_ce: 0.072241
2021-12-11 19:30:20,189 iteration 354 : loss : 0.124994, loss_ce: 0.046075
2021-12-11 19:30:21,801 iteration 355 : loss : 0.159062, loss_ce: 0.053635
2021-12-11 19:30:23,376 iteration 356 : loss : 0.113931, loss_ce: 0.041047
2021-12-11 19:30:24,966 iteration 357 : loss : 0.119143, loss_ce: 0.039687
  5%|█▌                            | 21/400 [10:09<3:08:55, 29.91s/it]2021-12-11 19:30:26,722 iteration 358 : loss : 0.191546, loss_ce: 0.102342
2021-12-11 19:30:28,391 iteration 359 : loss : 0.121877, loss_ce: 0.053129
2021-12-11 19:30:29,943 iteration 360 : loss : 0.098970, loss_ce: 0.034042
2021-12-11 19:30:31,551 iteration 361 : loss : 0.150811, loss_ce: 0.059011
2021-12-11 19:30:33,155 iteration 362 : loss : 0.150153, loss_ce: 0.081059
2021-12-11 19:30:34,638 iteration 363 : loss : 0.114753, loss_ce: 0.050519
2021-12-11 19:30:36,218 iteration 364 : loss : 0.231826, loss_ce: 0.093619
2021-12-11 19:30:37,737 iteration 365 : loss : 0.148620, loss_ce: 0.060281
2021-12-11 19:30:39,289 iteration 366 : loss : 0.165349, loss_ce: 0.052970
2021-12-11 19:30:40,874 iteration 367 : loss : 0.143757, loss_ce: 0.058886
2021-12-11 19:30:42,426 iteration 368 : loss : 0.163689, loss_ce: 0.065741
2021-12-11 19:30:43,958 iteration 369 : loss : 0.101165, loss_ce: 0.036312
2021-12-11 19:30:45,527 iteration 370 : loss : 0.162030, loss_ce: 0.078461
2021-12-11 19:30:47,100 iteration 371 : loss : 0.141116, loss_ce: 0.056243
2021-12-11 19:30:48,610 iteration 372 : loss : 0.109875, loss_ce: 0.048504
2021-12-11 19:30:50,164 iteration 373 : loss : 0.076814, loss_ce: 0.030497
2021-12-11 19:30:51,773 iteration 374 : loss : 0.151703, loss_ce: 0.070508
  6%|█▋                            | 22/400 [10:36<3:02:33, 28.98s/it]2021-12-11 19:30:53,401 iteration 375 : loss : 0.108289, loss_ce: 0.050638
2021-12-11 19:30:54,954 iteration 376 : loss : 0.167978, loss_ce: 0.049600
2021-12-11 19:30:56,531 iteration 377 : loss : 0.124303, loss_ce: 0.044955
2021-12-11 19:30:58,186 iteration 378 : loss : 0.128036, loss_ce: 0.047150
2021-12-11 19:30:59,778 iteration 379 : loss : 0.104072, loss_ce: 0.045757
2021-12-11 19:31:01,311 iteration 380 : loss : 0.135896, loss_ce: 0.063795
2021-12-11 19:31:02,897 iteration 381 : loss : 0.159063, loss_ce: 0.068470
2021-12-11 19:31:04,391 iteration 382 : loss : 0.100443, loss_ce: 0.043339
2021-12-11 19:31:06,011 iteration 383 : loss : 0.119722, loss_ce: 0.029145
2021-12-11 19:31:07,579 iteration 384 : loss : 0.121903, loss_ce: 0.050794
2021-12-11 19:31:09,118 iteration 385 : loss : 0.126113, loss_ce: 0.051793
2021-12-11 19:31:10,690 iteration 386 : loss : 0.144184, loss_ce: 0.047792
2021-12-11 19:31:12,201 iteration 387 : loss : 0.088405, loss_ce: 0.035040
2021-12-11 19:31:13,799 iteration 388 : loss : 0.127661, loss_ce: 0.055146
2021-12-11 19:31:15,353 iteration 389 : loss : 0.107654, loss_ce: 0.036763
2021-12-11 19:31:16,932 iteration 390 : loss : 0.143195, loss_ce: 0.075902
2021-12-11 19:31:18,533 iteration 391 : loss : 0.086321, loss_ce: 0.035334
  6%|█▋                            | 23/400 [11:03<2:57:54, 28.31s/it]2021-12-11 19:31:20,233 iteration 392 : loss : 0.126131, loss_ce: 0.054469
2021-12-11 19:31:21,742 iteration 393 : loss : 0.120366, loss_ce: 0.057075
2021-12-11 19:31:23,315 iteration 394 : loss : 0.143549, loss_ce: 0.049374
2021-12-11 19:31:24,823 iteration 395 : loss : 0.107471, loss_ce: 0.037953
2021-12-11 19:31:26,379 iteration 396 : loss : 0.106482, loss_ce: 0.039743
2021-12-11 19:31:28,041 iteration 397 : loss : 0.115971, loss_ce: 0.055384
2021-12-11 19:31:29,599 iteration 398 : loss : 0.107328, loss_ce: 0.037099
2021-12-11 19:31:31,178 iteration 399 : loss : 0.108838, loss_ce: 0.040494
2021-12-11 19:31:32,718 iteration 400 : loss : 0.101753, loss_ce: 0.040301
2021-12-11 19:31:34,307 iteration 401 : loss : 0.091668, loss_ce: 0.043405
2021-12-11 19:31:35,985 iteration 402 : loss : 0.089084, loss_ce: 0.039044
2021-12-11 19:31:37,595 iteration 403 : loss : 0.125659, loss_ce: 0.050102
2021-12-11 19:31:39,145 iteration 404 : loss : 0.090402, loss_ce: 0.035187
2021-12-11 19:31:40,696 iteration 405 : loss : 0.147013, loss_ce: 0.072484
2021-12-11 19:31:42,312 iteration 406 : loss : 0.130621, loss_ce: 0.051842
2021-12-11 19:31:43,930 iteration 407 : loss : 0.116599, loss_ce: 0.046781
2021-12-11 19:31:45,403 iteration 408 : loss : 0.094264, loss_ce: 0.041543
  6%|█▊                            | 24/400 [11:30<2:54:43, 27.88s/it]2021-12-11 19:31:47,110 iteration 409 : loss : 0.146863, loss_ce: 0.046728
2021-12-11 19:31:48,720 iteration 410 : loss : 0.095712, loss_ce: 0.041952
2021-12-11 19:31:50,323 iteration 411 : loss : 0.194003, loss_ce: 0.081192
2021-12-11 19:31:51,870 iteration 412 : loss : 0.110059, loss_ce: 0.049789
2021-12-11 19:31:53,437 iteration 413 : loss : 0.097777, loss_ce: 0.032478
2021-12-11 19:31:54,949 iteration 414 : loss : 0.124982, loss_ce: 0.049870
2021-12-11 19:31:56,602 iteration 415 : loss : 0.122731, loss_ce: 0.051787
2021-12-11 19:31:58,135 iteration 416 : loss : 0.100951, loss_ce: 0.045252
2021-12-11 19:31:59,744 iteration 417 : loss : 0.137467, loss_ce: 0.049518
2021-12-11 19:32:01,230 iteration 418 : loss : 0.104367, loss_ce: 0.058561
2021-12-11 19:32:02,780 iteration 419 : loss : 0.148602, loss_ce: 0.055699
2021-12-11 19:32:04,356 iteration 420 : loss : 0.101588, loss_ce: 0.047037
2021-12-11 19:32:06,006 iteration 421 : loss : 0.176290, loss_ce: 0.096069
2021-12-11 19:32:07,553 iteration 422 : loss : 0.119730, loss_ce: 0.039332
2021-12-11 19:32:09,132 iteration 423 : loss : 0.123095, loss_ce: 0.045680
2021-12-11 19:32:10,747 iteration 424 : loss : 0.113678, loss_ce: 0.043565
2021-12-11 19:32:10,747 Training Data Eval:
2021-12-11 19:32:18,539   Average segmentation loss on training set: 0.1388
2021-12-11 19:32:18,539 Validation Data Eval:
2021-12-11 19:32:21,209   Average segmentation loss on validation set: 0.2650
2021-12-11 19:32:22,846 iteration 425 : loss : 0.132543, loss_ce: 0.058042
  6%|█▉                            | 25/400 [12:07<3:12:10, 30.75s/it]2021-12-11 19:32:24,536 iteration 426 : loss : 0.098872, loss_ce: 0.039285
2021-12-11 19:32:26,113 iteration 427 : loss : 0.145838, loss_ce: 0.050841
2021-12-11 19:32:27,742 iteration 428 : loss : 0.120228, loss_ce: 0.052520
2021-12-11 19:32:29,276 iteration 429 : loss : 0.095524, loss_ce: 0.034600
2021-12-11 19:32:30,867 iteration 430 : loss : 0.146268, loss_ce: 0.052489
2021-12-11 19:32:32,366 iteration 431 : loss : 0.105498, loss_ce: 0.041729
2021-12-11 19:32:33,895 iteration 432 : loss : 0.073177, loss_ce: 0.030278
2021-12-11 19:32:35,482 iteration 433 : loss : 0.098032, loss_ce: 0.031685
2021-12-11 19:32:37,030 iteration 434 : loss : 0.085312, loss_ce: 0.030366
2021-12-11 19:32:38,582 iteration 435 : loss : 0.150616, loss_ce: 0.069281
2021-12-11 19:32:40,200 iteration 436 : loss : 0.127288, loss_ce: 0.051791
2021-12-11 19:32:41,778 iteration 437 : loss : 0.101549, loss_ce: 0.042249
2021-12-11 19:32:43,348 iteration 438 : loss : 0.153068, loss_ce: 0.088996
2021-12-11 19:32:44,907 iteration 439 : loss : 0.120444, loss_ce: 0.054404
2021-12-11 19:32:46,420 iteration 440 : loss : 0.088170, loss_ce: 0.036648
2021-12-11 19:32:47,966 iteration 441 : loss : 0.108979, loss_ce: 0.053367
2021-12-11 19:32:49,498 iteration 442 : loss : 0.172551, loss_ce: 0.065278
  6%|█▉                            | 26/400 [12:34<3:04:00, 29.52s/it]2021-12-11 19:32:51,133 iteration 443 : loss : 0.094864, loss_ce: 0.044660
2021-12-11 19:32:52,689 iteration 444 : loss : 0.112924, loss_ce: 0.048338
2021-12-11 19:32:54,481 iteration 445 : loss : 0.137942, loss_ce: 0.066362
2021-12-11 19:32:55,985 iteration 446 : loss : 0.158308, loss_ce: 0.059912
2021-12-11 19:32:57,653 iteration 447 : loss : 0.127488, loss_ce: 0.058182
2021-12-11 19:32:59,275 iteration 448 : loss : 0.094038, loss_ce: 0.044466
2021-12-11 19:33:00,834 iteration 449 : loss : 0.112839, loss_ce: 0.045058
2021-12-11 19:33:02,311 iteration 450 : loss : 0.088321, loss_ce: 0.037289
2021-12-11 19:33:03,865 iteration 451 : loss : 0.101075, loss_ce: 0.033265
2021-12-11 19:33:05,458 iteration 452 : loss : 0.081149, loss_ce: 0.036033
2021-12-11 19:33:07,035 iteration 453 : loss : 0.073860, loss_ce: 0.028134
2021-12-11 19:33:08,648 iteration 454 : loss : 0.180044, loss_ce: 0.060588
2021-12-11 19:33:10,305 iteration 455 : loss : 0.076752, loss_ce: 0.025521
2021-12-11 19:33:11,836 iteration 456 : loss : 0.115682, loss_ce: 0.036882
2021-12-11 19:33:13,370 iteration 457 : loss : 0.124639, loss_ce: 0.051680
2021-12-11 19:33:14,931 iteration 458 : loss : 0.129283, loss_ce: 0.059690
2021-12-11 19:33:16,504 iteration 459 : loss : 0.099233, loss_ce: 0.039894
  7%|██                            | 27/400 [13:01<2:58:50, 28.77s/it]2021-12-11 19:33:18,044 iteration 460 : loss : 0.094960, loss_ce: 0.031836
2021-12-11 19:33:19,638 iteration 461 : loss : 0.109099, loss_ce: 0.042311
2021-12-11 19:33:21,216 iteration 462 : loss : 0.123537, loss_ce: 0.032734
2021-12-11 19:33:22,680 iteration 463 : loss : 0.078733, loss_ce: 0.036405
2021-12-11 19:33:24,327 iteration 464 : loss : 0.097535, loss_ce: 0.039465
2021-12-11 19:33:25,877 iteration 465 : loss : 0.101314, loss_ce: 0.050740
2021-12-11 19:33:27,494 iteration 466 : loss : 0.105419, loss_ce: 0.045000
2021-12-11 19:33:29,024 iteration 467 : loss : 0.101593, loss_ce: 0.035082
2021-12-11 19:33:30,576 iteration 468 : loss : 0.087404, loss_ce: 0.032534
2021-12-11 19:33:32,099 iteration 469 : loss : 0.117144, loss_ce: 0.042684
2021-12-11 19:33:33,744 iteration 470 : loss : 0.143615, loss_ce: 0.071154
2021-12-11 19:33:35,256 iteration 471 : loss : 0.101262, loss_ce: 0.041441
2021-12-11 19:33:36,886 iteration 472 : loss : 0.121272, loss_ce: 0.048502
2021-12-11 19:33:38,501 iteration 473 : loss : 0.084746, loss_ce: 0.038449
2021-12-11 19:33:40,144 iteration 474 : loss : 0.094592, loss_ce: 0.041999
2021-12-11 19:33:41,728 iteration 475 : loss : 0.114985, loss_ce: 0.038631
2021-12-11 19:33:43,337 iteration 476 : loss : 0.099521, loss_ce: 0.048859
  7%|██                            | 28/400 [13:28<2:54:44, 28.18s/it]2021-12-11 19:33:44,971 iteration 477 : loss : 0.092810, loss_ce: 0.044196
2021-12-11 19:33:46,593 iteration 478 : loss : 0.100173, loss_ce: 0.035786
2021-12-11 19:33:48,094 iteration 479 : loss : 0.095482, loss_ce: 0.038537
2021-12-11 19:33:49,558 iteration 480 : loss : 0.085209, loss_ce: 0.038298
2021-12-11 19:33:51,109 iteration 481 : loss : 0.091515, loss_ce: 0.040024
2021-12-11 19:33:52,738 iteration 482 : loss : 0.101908, loss_ce: 0.039537
2021-12-11 19:33:54,329 iteration 483 : loss : 0.091524, loss_ce: 0.032273
2021-12-11 19:33:55,898 iteration 484 : loss : 0.073505, loss_ce: 0.031816
2021-12-11 19:33:57,382 iteration 485 : loss : 0.070834, loss_ce: 0.031105
2021-12-11 19:33:58,941 iteration 486 : loss : 0.195795, loss_ce: 0.066473
2021-12-11 19:34:00,542 iteration 487 : loss : 0.138269, loss_ce: 0.073127
2021-12-11 19:34:02,226 iteration 488 : loss : 0.155357, loss_ce: 0.059757
2021-12-11 19:34:03,835 iteration 489 : loss : 0.055581, loss_ce: 0.021058
2021-12-11 19:34:05,356 iteration 490 : loss : 0.081345, loss_ce: 0.033119
2021-12-11 19:34:06,997 iteration 491 : loss : 0.128143, loss_ce: 0.050532
2021-12-11 19:34:08,514 iteration 492 : loss : 0.116376, loss_ce: 0.056077
2021-12-11 19:34:10,060 iteration 493 : loss : 0.143122, loss_ce: 0.067939
  7%|██▏                           | 29/400 [13:54<2:51:33, 27.75s/it]2021-12-11 19:34:11,648 iteration 494 : loss : 0.094382, loss_ce: 0.038319
2021-12-11 19:34:13,215 iteration 495 : loss : 0.071868, loss_ce: 0.030732
2021-12-11 19:34:14,685 iteration 496 : loss : 0.097536, loss_ce: 0.043000
2021-12-11 19:34:16,299 iteration 497 : loss : 0.079346, loss_ce: 0.030847
2021-12-11 19:34:17,862 iteration 498 : loss : 0.131959, loss_ce: 0.053109
2021-12-11 19:34:19,519 iteration 499 : loss : 0.093247, loss_ce: 0.044060
2021-12-11 19:34:20,986 iteration 500 : loss : 0.086419, loss_ce: 0.034168
2021-12-11 19:34:22,565 iteration 501 : loss : 0.105358, loss_ce: 0.032462
2021-12-11 19:34:24,096 iteration 502 : loss : 0.103643, loss_ce: 0.036450
2021-12-11 19:34:25,664 iteration 503 : loss : 0.112333, loss_ce: 0.056135
2021-12-11 19:34:27,328 iteration 504 : loss : 0.072176, loss_ce: 0.027634
2021-12-11 19:34:28,991 iteration 505 : loss : 0.075015, loss_ce: 0.034307
2021-12-11 19:34:30,587 iteration 506 : loss : 0.129113, loss_ce: 0.061263
2021-12-11 19:34:32,141 iteration 507 : loss : 0.072302, loss_ce: 0.025937
2021-12-11 19:34:33,744 iteration 508 : loss : 0.116076, loss_ce: 0.041045
2021-12-11 19:34:35,375 iteration 509 : loss : 0.105319, loss_ce: 0.055713
2021-12-11 19:34:35,376 Training Data Eval:
2021-12-11 19:34:43,165   Average segmentation loss on training set: 0.0903
2021-12-11 19:34:43,166 Validation Data Eval:
2021-12-11 19:34:45,835   Average segmentation loss on validation set: 0.1379
2021-12-11 19:34:47,753 Found new lowest validation loss at iteration 509! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/NEW_TU/UNET_ADAM_best_val_loss_seed2.pth
2021-12-11 19:34:49,318 iteration 510 : loss : 0.070892, loss_ce: 0.029982
  8%|██▎                           | 30/400 [14:34<3:12:25, 31.20s/it]2021-12-11 19:34:50,908 iteration 511 : loss : 0.071614, loss_ce: 0.026609
2021-12-11 19:34:52,462 iteration 512 : loss : 0.089761, loss_ce: 0.039916
2021-12-11 19:34:54,031 iteration 513 : loss : 0.084530, loss_ce: 0.031798
2021-12-11 19:34:55,637 iteration 514 : loss : 0.101597, loss_ce: 0.041657
2021-12-11 19:34:57,119 iteration 515 : loss : 0.088582, loss_ce: 0.039652
2021-12-11 19:34:58,566 iteration 516 : loss : 0.060770, loss_ce: 0.023791
2021-12-11 19:35:00,218 iteration 517 : loss : 0.107830, loss_ce: 0.050922
2021-12-11 19:35:01,893 iteration 518 : loss : 0.151075, loss_ce: 0.060807
2021-12-11 19:35:03,555 iteration 519 : loss : 0.076593, loss_ce: 0.035336
2021-12-11 19:35:05,133 iteration 520 : loss : 0.081246, loss_ce: 0.037198
2021-12-11 19:35:06,624 iteration 521 : loss : 0.065265, loss_ce: 0.025934
2021-12-11 19:35:08,241 iteration 522 : loss : 0.099205, loss_ce: 0.039555
2021-12-11 19:35:09,799 iteration 523 : loss : 0.098745, loss_ce: 0.031764
2021-12-11 19:35:11,334 iteration 524 : loss : 0.091104, loss_ce: 0.045810
2021-12-11 19:35:12,883 iteration 525 : loss : 0.081996, loss_ce: 0.031048
2021-12-11 19:35:14,501 iteration 526 : loss : 0.067440, loss_ce: 0.025701
2021-12-11 19:35:16,098 iteration 527 : loss : 0.115162, loss_ce: 0.039043
  8%|██▎                           | 31/400 [15:00<3:03:43, 29.87s/it]2021-12-11 19:35:17,694 iteration 528 : loss : 0.082156, loss_ce: 0.034242
2021-12-11 19:35:19,399 iteration 529 : loss : 0.142972, loss_ce: 0.043912
2021-12-11 19:35:20,939 iteration 530 : loss : 0.060652, loss_ce: 0.025816
2021-12-11 19:35:22,447 iteration 531 : loss : 0.082898, loss_ce: 0.030240
2021-12-11 19:35:24,031 iteration 532 : loss : 0.088963, loss_ce: 0.043611
2021-12-11 19:35:25,600 iteration 533 : loss : 0.084556, loss_ce: 0.036903
2021-12-11 19:35:27,156 iteration 534 : loss : 0.081202, loss_ce: 0.031499
2021-12-11 19:35:28,772 iteration 535 : loss : 0.087386, loss_ce: 0.035829
2021-12-11 19:35:30,345 iteration 536 : loss : 0.091099, loss_ce: 0.044340
2021-12-11 19:35:31,898 iteration 537 : loss : 0.086199, loss_ce: 0.035976
2021-12-11 19:35:33,470 iteration 538 : loss : 0.113039, loss_ce: 0.046692
2021-12-11 19:35:34,955 iteration 539 : loss : 0.075642, loss_ce: 0.031225
2021-12-11 19:35:36,671 iteration 540 : loss : 0.107764, loss_ce: 0.053591
2021-12-11 19:35:38,368 iteration 541 : loss : 0.130982, loss_ce: 0.058794
2021-12-11 19:35:39,881 iteration 542 : loss : 0.113642, loss_ce: 0.045138
2021-12-11 19:35:41,455 iteration 543 : loss : 0.088652, loss_ce: 0.035854
2021-12-11 19:35:43,002 iteration 544 : loss : 0.153037, loss_ce: 0.051722
  8%|██▍                           | 32/400 [15:27<2:57:46, 28.98s/it]2021-12-11 19:35:44,711 iteration 545 : loss : 0.096823, loss_ce: 0.042958
2021-12-11 19:35:46,360 iteration 546 : loss : 0.086101, loss_ce: 0.035786
2021-12-11 19:35:47,997 iteration 547 : loss : 0.086389, loss_ce: 0.040396
2021-12-11 19:35:49,495 iteration 548 : loss : 0.135554, loss_ce: 0.054676
2021-12-11 19:35:51,001 iteration 549 : loss : 0.109088, loss_ce: 0.040466
2021-12-11 19:35:52,510 iteration 550 : loss : 0.090305, loss_ce: 0.036094
2021-12-11 19:35:54,022 iteration 551 : loss : 0.091856, loss_ce: 0.025078
2021-12-11 19:35:55,635 iteration 552 : loss : 0.150937, loss_ce: 0.071608
2021-12-11 19:35:57,205 iteration 553 : loss : 0.096371, loss_ce: 0.040460
2021-12-11 19:35:58,791 iteration 554 : loss : 0.141916, loss_ce: 0.057027
2021-12-11 19:36:00,408 iteration 555 : loss : 0.083812, loss_ce: 0.024821
2021-12-11 19:36:02,065 iteration 556 : loss : 0.117996, loss_ce: 0.055021
2021-12-11 19:36:03,590 iteration 557 : loss : 0.105933, loss_ce: 0.050248
2021-12-11 19:36:05,085 iteration 558 : loss : 0.089756, loss_ce: 0.032856
2021-12-11 19:36:06,622 iteration 559 : loss : 0.105958, loss_ce: 0.037124
2021-12-11 19:36:08,264 iteration 560 : loss : 0.129204, loss_ce: 0.060466
2021-12-11 19:36:09,887 iteration 561 : loss : 0.080233, loss_ce: 0.038524
  8%|██▍                           | 33/400 [15:54<2:53:26, 28.35s/it]2021-12-11 19:36:11,567 iteration 562 : loss : 0.124764, loss_ce: 0.044807
2021-12-11 19:36:13,090 iteration 563 : loss : 0.059919, loss_ce: 0.030584
2021-12-11 19:36:14,602 iteration 564 : loss : 0.087324, loss_ce: 0.042713
2021-12-11 19:36:16,205 iteration 565 : loss : 0.088963, loss_ce: 0.038671
2021-12-11 19:36:17,791 iteration 566 : loss : 0.127031, loss_ce: 0.038637
2021-12-11 19:36:19,389 iteration 567 : loss : 0.127000, loss_ce: 0.051216
2021-12-11 19:36:20,989 iteration 568 : loss : 0.125570, loss_ce: 0.037578
2021-12-11 19:36:22,656 iteration 569 : loss : 0.176268, loss_ce: 0.061466
2021-12-11 19:36:24,256 iteration 570 : loss : 0.128329, loss_ce: 0.060595
2021-12-11 19:36:25,868 iteration 571 : loss : 0.089185, loss_ce: 0.035022
2021-12-11 19:36:27,513 iteration 572 : loss : 0.102384, loss_ce: 0.049797
2021-12-11 19:36:29,046 iteration 573 : loss : 0.082370, loss_ce: 0.037738
2021-12-11 19:36:30,707 iteration 574 : loss : 0.105345, loss_ce: 0.039529
2021-12-11 19:36:32,263 iteration 575 : loss : 0.129244, loss_ce: 0.038451
2021-12-11 19:36:33,764 iteration 576 : loss : 0.109381, loss_ce: 0.056520
2021-12-11 19:36:35,473 iteration 577 : loss : 0.161155, loss_ce: 0.086647
2021-12-11 19:36:37,097 iteration 578 : loss : 0.105674, loss_ce: 0.050576
  8%|██▌                           | 34/400 [16:21<2:50:50, 28.01s/it]2021-12-11 19:36:38,644 iteration 579 : loss : 0.078565, loss_ce: 0.037149
2021-12-11 19:36:40,267 iteration 580 : loss : 0.111863, loss_ce: 0.044191
2021-12-11 19:36:41,993 iteration 581 : loss : 0.068035, loss_ce: 0.030011
2021-12-11 19:36:43,504 iteration 582 : loss : 0.064943, loss_ce: 0.027968
2021-12-11 19:36:45,056 iteration 583 : loss : 0.103998, loss_ce: 0.048055
2021-12-11 19:36:46,663 iteration 584 : loss : 0.121300, loss_ce: 0.057197
2021-12-11 19:36:48,196 iteration 585 : loss : 0.086897, loss_ce: 0.029649
2021-12-11 19:36:49,805 iteration 586 : loss : 0.086213, loss_ce: 0.033302
2021-12-11 19:36:51,393 iteration 587 : loss : 0.070479, loss_ce: 0.034795
2021-12-11 19:36:52,909 iteration 588 : loss : 0.090912, loss_ce: 0.036505
2021-12-11 19:36:54,546 iteration 589 : loss : 0.113166, loss_ce: 0.050889
2021-12-11 19:36:56,092 iteration 590 : loss : 0.106092, loss_ce: 0.042912
2021-12-11 19:36:57,630 iteration 591 : loss : 0.100244, loss_ce: 0.033332
2021-12-11 19:36:59,226 iteration 592 : loss : 0.075599, loss_ce: 0.033425
2021-12-11 19:37:00,725 iteration 593 : loss : 0.089898, loss_ce: 0.034912
2021-12-11 19:37:02,358 iteration 594 : loss : 0.091255, loss_ce: 0.034823
2021-12-11 19:37:02,359 Training Data Eval:
2021-12-11 19:37:10,127   Average segmentation loss on training set: 0.0751
2021-12-11 19:37:10,128 Validation Data Eval:
2021-12-11 19:37:12,782   Average segmentation loss on validation set: 0.1260
2021-12-11 19:37:14,720 Found new lowest validation loss at iteration 594! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/NEW_TU/UNET_ADAM_best_val_loss_seed2.pth
2021-12-11 19:37:16,306 iteration 595 : loss : 0.108509, loss_ce: 0.041081
  9%|██▋                           | 35/400 [17:01<3:10:49, 31.37s/it]2021-12-11 19:37:18,017 iteration 596 : loss : 0.096994, loss_ce: 0.038267
2021-12-11 19:37:19,572 iteration 597 : loss : 0.059614, loss_ce: 0.024392
2021-12-11 19:37:21,131 iteration 598 : loss : 0.088874, loss_ce: 0.029038
2021-12-11 19:37:22,726 iteration 599 : loss : 0.162251, loss_ce: 0.066500
2021-12-11 19:37:24,337 iteration 600 : loss : 0.073800, loss_ce: 0.026113
2021-12-11 19:37:25,935 iteration 601 : loss : 0.075387, loss_ce: 0.027073
2021-12-11 19:37:27,400 iteration 602 : loss : 0.089534, loss_ce: 0.038872
2021-12-11 19:37:28,952 iteration 603 : loss : 0.076737, loss_ce: 0.031113
2021-12-11 19:37:30,473 iteration 604 : loss : 0.132616, loss_ce: 0.043378
2021-12-11 19:37:32,140 iteration 605 : loss : 0.087368, loss_ce: 0.035271
2021-12-11 19:37:33,653 iteration 606 : loss : 0.066297, loss_ce: 0.025683
2021-12-11 19:37:35,167 iteration 607 : loss : 0.088315, loss_ce: 0.034074
2021-12-11 19:37:36,678 iteration 608 : loss : 0.049783, loss_ce: 0.024732
2021-12-11 19:37:38,188 iteration 609 : loss : 0.091255, loss_ce: 0.034249
2021-12-11 19:37:39,847 iteration 610 : loss : 0.117021, loss_ce: 0.055637
2021-12-11 19:37:41,395 iteration 611 : loss : 0.074888, loss_ce: 0.035452
2021-12-11 19:37:42,884 iteration 612 : loss : 0.057460, loss_ce: 0.024677
  9%|██▋                           | 36/400 [17:27<3:01:34, 29.93s/it]2021-12-11 19:37:44,502 iteration 613 : loss : 0.099253, loss_ce: 0.041083
2021-12-11 19:37:46,127 iteration 614 : loss : 0.075581, loss_ce: 0.033551
2021-12-11 19:37:47,700 iteration 615 : loss : 0.097563, loss_ce: 0.048423
2021-12-11 19:37:49,244 iteration 616 : loss : 0.130943, loss_ce: 0.043855
2021-12-11 19:37:50,850 iteration 617 : loss : 0.121654, loss_ce: 0.049506
2021-12-11 19:37:52,495 iteration 618 : loss : 0.068476, loss_ce: 0.032394
2021-12-11 19:37:54,076 iteration 619 : loss : 0.082197, loss_ce: 0.029502
2021-12-11 19:37:55,691 iteration 620 : loss : 0.093169, loss_ce: 0.037095
2021-12-11 19:37:57,150 iteration 621 : loss : 0.075356, loss_ce: 0.027223
2021-12-11 19:37:58,780 iteration 622 : loss : 0.094695, loss_ce: 0.037443
2021-12-11 19:38:00,418 iteration 623 : loss : 0.109590, loss_ce: 0.045968
2021-12-11 19:38:01,895 iteration 624 : loss : 0.090243, loss_ce: 0.038657
2021-12-11 19:38:03,600 iteration 625 : loss : 0.079375, loss_ce: 0.033106
2021-12-11 19:38:05,150 iteration 626 : loss : 0.066837, loss_ce: 0.026134
2021-12-11 19:38:06,636 iteration 627 : loss : 0.116983, loss_ce: 0.037307
2021-12-11 19:38:08,099 iteration 628 : loss : 0.102259, loss_ce: 0.038863
2021-12-11 19:38:09,687 iteration 629 : loss : 0.062319, loss_ce: 0.025648
  9%|██▊                           | 37/400 [17:54<2:55:24, 28.99s/it]2021-12-11 19:38:11,194 iteration 630 : loss : 0.085903, loss_ce: 0.035363
2021-12-11 19:38:12,746 iteration 631 : loss : 0.118401, loss_ce: 0.041877
2021-12-11 19:38:14,229 iteration 632 : loss : 0.074161, loss_ce: 0.025815
2021-12-11 19:38:15,826 iteration 633 : loss : 0.076156, loss_ce: 0.037393
2021-12-11 19:38:17,405 iteration 634 : loss : 0.074901, loss_ce: 0.036550
2021-12-11 19:38:19,000 iteration 635 : loss : 0.082219, loss_ce: 0.037812
2021-12-11 19:38:20,534 iteration 636 : loss : 0.117852, loss_ce: 0.042760
2021-12-11 19:38:22,048 iteration 637 : loss : 0.083203, loss_ce: 0.037597
2021-12-11 19:38:23,565 iteration 638 : loss : 0.065635, loss_ce: 0.031626
2021-12-11 19:38:25,169 iteration 639 : loss : 0.074331, loss_ce: 0.039052
2021-12-11 19:38:26,784 iteration 640 : loss : 0.107713, loss_ce: 0.035703
2021-12-11 19:38:28,299 iteration 641 : loss : 0.072862, loss_ce: 0.028812
2021-12-11 19:38:29,869 iteration 642 : loss : 0.095287, loss_ce: 0.035268
2021-12-11 19:38:31,405 iteration 643 : loss : 0.081128, loss_ce: 0.028285
2021-12-11 19:38:32,963 iteration 644 : loss : 0.080186, loss_ce: 0.025385
2021-12-11 19:38:34,480 iteration 645 : loss : 0.105658, loss_ce: 0.038642
2021-12-11 19:38:36,084 iteration 646 : loss : 0.071354, loss_ce: 0.029631
 10%|██▊                           | 38/400 [18:20<2:50:14, 28.22s/it]2021-12-11 19:38:37,682 iteration 647 : loss : 0.066446, loss_ce: 0.027182
2021-12-11 19:38:39,297 iteration 648 : loss : 0.105597, loss_ce: 0.043376
2021-12-11 19:38:40,883 iteration 649 : loss : 0.076356, loss_ce: 0.030882
2021-12-11 19:38:42,364 iteration 650 : loss : 0.078618, loss_ce: 0.039076
2021-12-11 19:38:43,930 iteration 651 : loss : 0.082780, loss_ce: 0.030504
2021-12-11 19:38:45,429 iteration 652 : loss : 0.093329, loss_ce: 0.029687
2021-12-11 19:38:47,002 iteration 653 : loss : 0.127253, loss_ce: 0.041880
2021-12-11 19:38:48,628 iteration 654 : loss : 0.107119, loss_ce: 0.038203
2021-12-11 19:38:50,224 iteration 655 : loss : 0.057203, loss_ce: 0.024518
2021-12-11 19:38:51,708 iteration 656 : loss : 0.074423, loss_ce: 0.027835
2021-12-11 19:38:53,272 iteration 657 : loss : 0.062306, loss_ce: 0.026974
2021-12-11 19:38:54,906 iteration 658 : loss : 0.134878, loss_ce: 0.044089
2021-12-11 19:38:56,530 iteration 659 : loss : 0.081062, loss_ce: 0.031673
2021-12-11 19:38:58,111 iteration 660 : loss : 0.067723, loss_ce: 0.026067
2021-12-11 19:38:59,678 iteration 661 : loss : 0.085791, loss_ce: 0.038778
2021-12-11 19:39:01,196 iteration 662 : loss : 0.072203, loss_ce: 0.035167
2021-12-11 19:39:02,755 iteration 663 : loss : 0.065607, loss_ce: 0.023852
 10%|██▉                           | 39/400 [18:47<2:46:58, 27.75s/it]2021-12-11 19:39:04,321 iteration 664 : loss : 0.073930, loss_ce: 0.036817
2021-12-11 19:39:05,863 iteration 665 : loss : 0.066534, loss_ce: 0.029770
2021-12-11 19:39:07,436 iteration 666 : loss : 0.078793, loss_ce: 0.031877
2021-12-11 19:39:08,949 iteration 667 : loss : 0.054227, loss_ce: 0.022770
2021-12-11 19:39:10,582 iteration 668 : loss : 0.093725, loss_ce: 0.035277
2021-12-11 19:39:12,101 iteration 669 : loss : 0.094247, loss_ce: 0.048838
2021-12-11 19:39:13,626 iteration 670 : loss : 0.072214, loss_ce: 0.031319
2021-12-11 19:39:15,234 iteration 671 : loss : 0.068361, loss_ce: 0.024275
2021-12-11 19:39:16,856 iteration 672 : loss : 0.074372, loss_ce: 0.027009
2021-12-11 19:39:18,372 iteration 673 : loss : 0.069618, loss_ce: 0.031543
2021-12-11 19:39:19,963 iteration 674 : loss : 0.120656, loss_ce: 0.048879
2021-12-11 19:39:21,573 iteration 675 : loss : 0.066973, loss_ce: 0.026053
2021-12-11 19:39:23,106 iteration 676 : loss : 0.085501, loss_ce: 0.026034
2021-12-11 19:39:24,683 iteration 677 : loss : 0.084093, loss_ce: 0.036821
2021-12-11 19:39:26,243 iteration 678 : loss : 0.059435, loss_ce: 0.023949
2021-12-11 19:39:27,753 iteration 679 : loss : 0.105757, loss_ce: 0.048097
2021-12-11 19:39:27,753 Training Data Eval:
2021-12-11 19:39:35,521   Average segmentation loss on training set: 0.0693
2021-12-11 19:39:35,522 Validation Data Eval:
2021-12-11 19:39:38,185   Average segmentation loss on validation set: 0.1665
2021-12-11 19:39:39,769 iteration 680 : loss : 0.116094, loss_ce: 0.022396
 10%|███                           | 40/400 [19:24<3:03:10, 30.53s/it]2021-12-11 19:39:41,453 iteration 681 : loss : 0.076054, loss_ce: 0.033835
2021-12-11 19:39:42,970 iteration 682 : loss : 0.045948, loss_ce: 0.016911
2021-12-11 19:39:44,557 iteration 683 : loss : 0.082062, loss_ce: 0.037191
2021-12-11 19:39:46,143 iteration 684 : loss : 0.067589, loss_ce: 0.025926
2021-12-11 19:39:47,776 iteration 685 : loss : 0.053380, loss_ce: 0.023471
2021-12-11 19:39:49,231 iteration 686 : loss : 0.073526, loss_ce: 0.023663
2021-12-11 19:39:50,735 iteration 687 : loss : 0.056104, loss_ce: 0.020153
2021-12-11 19:39:52,360 iteration 688 : loss : 0.070656, loss_ce: 0.030647
2021-12-11 19:39:53,930 iteration 689 : loss : 0.072505, loss_ce: 0.034981
2021-12-11 19:39:55,430 iteration 690 : loss : 0.095381, loss_ce: 0.047841
2021-12-11 19:39:57,082 iteration 691 : loss : 0.084948, loss_ce: 0.037520
2021-12-11 19:39:58,717 iteration 692 : loss : 0.099507, loss_ce: 0.034205
2021-12-11 19:40:00,330 iteration 693 : loss : 0.102462, loss_ce: 0.047889
2021-12-11 19:40:01,899 iteration 694 : loss : 0.060446, loss_ce: 0.024788
2021-12-11 19:40:03,457 iteration 695 : loss : 0.088634, loss_ce: 0.029823
2021-12-11 19:40:05,002 iteration 696 : loss : 0.081107, loss_ce: 0.032758
2021-12-11 19:40:06,568 iteration 697 : loss : 0.100258, loss_ce: 0.035641
 10%|███                           | 41/400 [19:51<2:55:58, 29.41s/it]2021-12-11 19:40:08,167 iteration 698 : loss : 0.074930, loss_ce: 0.027896
2021-12-11 19:40:09,730 iteration 699 : loss : 0.068451, loss_ce: 0.025354
2021-12-11 19:40:11,299 iteration 700 : loss : 0.077084, loss_ce: 0.028383
2021-12-11 19:40:12,839 iteration 701 : loss : 0.069462, loss_ce: 0.026581
2021-12-11 19:40:14,439 iteration 702 : loss : 0.057697, loss_ce: 0.019935
2021-12-11 19:40:16,004 iteration 703 : loss : 0.095338, loss_ce: 0.039449
2021-12-11 19:40:17,552 iteration 704 : loss : 0.074846, loss_ce: 0.024251
2021-12-11 19:40:19,063 iteration 705 : loss : 0.101064, loss_ce: 0.040530
2021-12-11 19:40:20,673 iteration 706 : loss : 0.069840, loss_ce: 0.031417
2021-12-11 19:40:22,269 iteration 707 : loss : 0.083021, loss_ce: 0.041027
2021-12-11 19:40:23,845 iteration 708 : loss : 0.068770, loss_ce: 0.029426
2021-12-11 19:40:25,434 iteration 709 : loss : 0.051361, loss_ce: 0.021584
2021-12-11 19:40:27,009 iteration 710 : loss : 0.079657, loss_ce: 0.025284
2021-12-11 19:40:28,626 iteration 711 : loss : 0.117038, loss_ce: 0.032238
2021-12-11 19:40:30,254 iteration 712 : loss : 0.080803, loss_ce: 0.038965
2021-12-11 19:40:31,774 iteration 713 : loss : 0.067277, loss_ce: 0.028612
2021-12-11 19:40:33,322 iteration 714 : loss : 0.069450, loss_ce: 0.032035
 10%|███▏                          | 42/400 [20:18<2:50:44, 28.62s/it]2021-12-11 19:40:34,926 iteration 715 : loss : 0.063344, loss_ce: 0.026900
2021-12-11 19:40:36,475 iteration 716 : loss : 0.106114, loss_ce: 0.027548
2021-12-11 19:40:38,010 iteration 717 : loss : 0.059285, loss_ce: 0.021481
2021-12-11 19:40:39,461 iteration 718 : loss : 0.075039, loss_ce: 0.026554
2021-12-11 19:40:41,004 iteration 719 : loss : 0.069546, loss_ce: 0.036066
2021-12-11 19:40:42,467 iteration 720 : loss : 0.059122, loss_ce: 0.025497
2021-12-11 19:40:44,168 iteration 721 : loss : 0.100629, loss_ce: 0.033849
2021-12-11 19:40:45,735 iteration 722 : loss : 0.053314, loss_ce: 0.024356
2021-12-11 19:40:47,307 iteration 723 : loss : 0.085081, loss_ce: 0.031820
2021-12-11 19:40:48,956 iteration 724 : loss : 0.089031, loss_ce: 0.037485
2021-12-11 19:40:50,470 iteration 725 : loss : 0.062130, loss_ce: 0.025129
2021-12-11 19:40:52,049 iteration 726 : loss : 0.114403, loss_ce: 0.059547
2021-12-11 19:40:53,567 iteration 727 : loss : 0.047342, loss_ce: 0.018531
2021-12-11 19:40:55,092 iteration 728 : loss : 0.073429, loss_ce: 0.023956
2021-12-11 19:40:56,620 iteration 729 : loss : 0.094331, loss_ce: 0.043140
2021-12-11 19:40:58,205 iteration 730 : loss : 0.089463, loss_ce: 0.039559
2021-12-11 19:40:59,712 iteration 731 : loss : 0.101193, loss_ce: 0.037017
 11%|███▏                          | 43/400 [20:44<2:46:17, 27.95s/it]2021-12-11 19:41:01,375 iteration 732 : loss : 0.057532, loss_ce: 0.022684
2021-12-11 19:41:02,962 iteration 733 : loss : 0.078259, loss_ce: 0.031030
2021-12-11 19:41:04,541 iteration 734 : loss : 0.091867, loss_ce: 0.041071
2021-12-11 19:41:06,139 iteration 735 : loss : 0.068723, loss_ce: 0.024958
2021-12-11 19:41:07,727 iteration 736 : loss : 0.059877, loss_ce: 0.024153
2021-12-11 19:41:09,223 iteration 737 : loss : 0.053160, loss_ce: 0.022710
2021-12-11 19:41:10,874 iteration 738 : loss : 0.092875, loss_ce: 0.038577
2021-12-11 19:41:12,465 iteration 739 : loss : 0.075962, loss_ce: 0.038394
2021-12-11 19:41:14,021 iteration 740 : loss : 0.066987, loss_ce: 0.024307
2021-12-11 19:41:15,622 iteration 741 : loss : 0.067538, loss_ce: 0.024950
2021-12-11 19:41:17,217 iteration 742 : loss : 0.072636, loss_ce: 0.027243
2021-12-11 19:41:18,766 iteration 743 : loss : 0.073969, loss_ce: 0.025705
2021-12-11 19:41:20,341 iteration 744 : loss : 0.057559, loss_ce: 0.025336
2021-12-11 19:41:21,903 iteration 745 : loss : 0.067469, loss_ce: 0.024619
2021-12-11 19:41:23,441 iteration 746 : loss : 0.124529, loss_ce: 0.041105
2021-12-11 19:41:24,990 iteration 747 : loss : 0.084736, loss_ce: 0.042970
2021-12-11 19:41:26,569 iteration 748 : loss : 0.066646, loss_ce: 0.023402
 11%|███▎                          | 44/400 [21:11<2:43:51, 27.62s/it]2021-12-11 19:41:28,164 iteration 749 : loss : 0.096624, loss_ce: 0.034073
2021-12-11 19:41:29,695 iteration 750 : loss : 0.061368, loss_ce: 0.018813
2021-12-11 19:41:31,307 iteration 751 : loss : 0.095796, loss_ce: 0.038228
2021-12-11 19:41:32,839 iteration 752 : loss : 0.071514, loss_ce: 0.029147
2021-12-11 19:41:34,436 iteration 753 : loss : 0.083395, loss_ce: 0.035570
2021-12-11 19:41:35,988 iteration 754 : loss : 0.056546, loss_ce: 0.019415
2021-12-11 19:41:37,566 iteration 755 : loss : 0.060816, loss_ce: 0.022614
2021-12-11 19:41:39,031 iteration 756 : loss : 0.064909, loss_ce: 0.027620
2021-12-11 19:41:40,517 iteration 757 : loss : 0.062872, loss_ce: 0.027439
2021-12-11 19:41:42,075 iteration 758 : loss : 0.056867, loss_ce: 0.020633
2021-12-11 19:41:43,684 iteration 759 : loss : 0.118783, loss_ce: 0.037326
2021-12-11 19:41:45,259 iteration 760 : loss : 0.067632, loss_ce: 0.023942
2021-12-11 19:41:46,861 iteration 761 : loss : 0.095215, loss_ce: 0.028708
2021-12-11 19:41:48,329 iteration 762 : loss : 0.059916, loss_ce: 0.026662
2021-12-11 19:41:49,884 iteration 763 : loss : 0.065781, loss_ce: 0.031934
2021-12-11 19:41:51,355 iteration 764 : loss : 0.065589, loss_ce: 0.024963
2021-12-11 19:41:51,355 Training Data Eval:
2021-12-11 19:41:59,133   Average segmentation loss on training set: 0.0776
2021-12-11 19:41:59,134 Validation Data Eval:
2021-12-11 19:42:01,801   Average segmentation loss on validation set: 0.1432
2021-12-11 19:42:03,265 iteration 765 : loss : 0.068435, loss_ce: 0.030719
 11%|███▍                          | 45/400 [21:48<2:59:31, 30.34s/it]2021-12-11 19:42:04,969 iteration 766 : loss : 0.069313, loss_ce: 0.024987
2021-12-11 19:42:06,698 iteration 767 : loss : 0.085641, loss_ce: 0.034481
2021-12-11 19:42:08,305 iteration 768 : loss : 0.083261, loss_ce: 0.029159
2021-12-11 19:42:09,918 iteration 769 : loss : 0.079075, loss_ce: 0.036111
2021-12-11 19:42:11,580 iteration 770 : loss : 0.094675, loss_ce: 0.047438
2021-12-11 19:42:13,180 iteration 771 : loss : 0.055921, loss_ce: 0.027476
2021-12-11 19:42:14,679 iteration 772 : loss : 0.063023, loss_ce: 0.027588
2021-12-11 19:42:16,241 iteration 773 : loss : 0.086499, loss_ce: 0.032530
2021-12-11 19:42:17,889 iteration 774 : loss : 0.063060, loss_ce: 0.027481
2021-12-11 19:42:19,394 iteration 775 : loss : 0.061669, loss_ce: 0.027227
2021-12-11 19:42:20,963 iteration 776 : loss : 0.121952, loss_ce: 0.043690
2021-12-11 19:42:22,648 iteration 777 : loss : 0.054668, loss_ce: 0.024297
2021-12-11 19:42:24,234 iteration 778 : loss : 0.059553, loss_ce: 0.021879
2021-12-11 19:42:25,798 iteration 779 : loss : 0.080007, loss_ce: 0.031247
2021-12-11 19:42:27,484 iteration 780 : loss : 0.093460, loss_ce: 0.040921
2021-12-11 19:42:29,107 iteration 781 : loss : 0.062422, loss_ce: 0.022781
2021-12-11 19:42:30,647 iteration 782 : loss : 0.069134, loss_ce: 0.031222
 12%|███▍                          | 46/400 [22:15<2:53:46, 29.45s/it]2021-12-11 19:42:32,270 iteration 783 : loss : 0.066362, loss_ce: 0.027547
2021-12-11 19:42:33,777 iteration 784 : loss : 0.053777, loss_ce: 0.019593
2021-12-11 19:42:35,421 iteration 785 : loss : 0.072507, loss_ce: 0.024909
2021-12-11 19:42:36,967 iteration 786 : loss : 0.092506, loss_ce: 0.033871
2021-12-11 19:42:38,597 iteration 787 : loss : 0.087908, loss_ce: 0.037206
2021-12-11 19:42:40,114 iteration 788 : loss : 0.091338, loss_ce: 0.041630
2021-12-11 19:42:41,735 iteration 789 : loss : 0.108830, loss_ce: 0.039571
2021-12-11 19:42:43,361 iteration 790 : loss : 0.063937, loss_ce: 0.025876
2021-12-11 19:42:44,846 iteration 791 : loss : 0.051598, loss_ce: 0.023927
2021-12-11 19:42:46,481 iteration 792 : loss : 0.065977, loss_ce: 0.025450
2021-12-11 19:42:48,080 iteration 793 : loss : 0.083741, loss_ce: 0.033561
2021-12-11 19:42:49,695 iteration 794 : loss : 0.078324, loss_ce: 0.033825
2021-12-11 19:42:51,288 iteration 795 : loss : 0.063915, loss_ce: 0.025653
2021-12-11 19:42:52,957 iteration 796 : loss : 0.078421, loss_ce: 0.032235
2021-12-11 19:42:54,514 iteration 797 : loss : 0.063231, loss_ce: 0.032116
2021-12-11 19:42:56,072 iteration 798 : loss : 0.071868, loss_ce: 0.030768
2021-12-11 19:42:57,765 iteration 799 : loss : 0.144210, loss_ce: 0.046461
 12%|███▌                          | 47/400 [22:42<2:49:09, 28.75s/it]2021-12-11 19:42:59,421 iteration 800 : loss : 0.068358, loss_ce: 0.034631
2021-12-11 19:43:00,974 iteration 801 : loss : 0.087371, loss_ce: 0.028219
2021-12-11 19:43:02,582 iteration 802 : loss : 0.088227, loss_ce: 0.047523
2021-12-11 19:43:04,066 iteration 803 : loss : 0.050950, loss_ce: 0.019788
2021-12-11 19:43:05,727 iteration 804 : loss : 0.106360, loss_ce: 0.032550
2021-12-11 19:43:07,274 iteration 805 : loss : 0.070386, loss_ce: 0.027957
2021-12-11 19:43:08,761 iteration 806 : loss : 0.077194, loss_ce: 0.031320
2021-12-11 19:43:10,313 iteration 807 : loss : 0.057398, loss_ce: 0.028618
2021-12-11 19:43:11,947 iteration 808 : loss : 0.079823, loss_ce: 0.024346
2021-12-11 19:43:13,578 iteration 809 : loss : 0.068916, loss_ce: 0.027996
2021-12-11 19:43:15,094 iteration 810 : loss : 0.054322, loss_ce: 0.018519
2021-12-11 19:43:16,692 iteration 811 : loss : 0.081856, loss_ce: 0.037338
2021-12-11 19:43:18,187 iteration 812 : loss : 0.075403, loss_ce: 0.033354
2021-12-11 19:43:19,824 iteration 813 : loss : 0.063119, loss_ce: 0.027385
2021-12-11 19:43:21,496 iteration 814 : loss : 0.156173, loss_ce: 0.045322
2021-12-11 19:43:22,918 iteration 815 : loss : 0.054695, loss_ce: 0.025702
2021-12-11 19:43:24,543 iteration 816 : loss : 0.097376, loss_ce: 0.037591
 12%|███▌                          | 48/400 [23:09<2:45:12, 28.16s/it]2021-12-11 19:43:26,117 iteration 817 : loss : 0.058964, loss_ce: 0.025172
2021-12-11 19:43:27,663 iteration 818 : loss : 0.067079, loss_ce: 0.027786
2021-12-11 19:43:29,377 iteration 819 : loss : 0.078384, loss_ce: 0.035171
2021-12-11 19:43:31,014 iteration 820 : loss : 0.088176, loss_ce: 0.033754
2021-12-11 19:43:32,623 iteration 821 : loss : 0.087655, loss_ce: 0.031645
2021-12-11 19:43:34,193 iteration 822 : loss : 0.067909, loss_ce: 0.029215
2021-12-11 19:43:35,789 iteration 823 : loss : 0.056901, loss_ce: 0.021275
2021-12-11 19:43:37,289 iteration 824 : loss : 0.073563, loss_ce: 0.023073
2021-12-11 19:43:38,840 iteration 825 : loss : 0.113028, loss_ce: 0.033640
2021-12-11 19:43:40,331 iteration 826 : loss : 0.065630, loss_ce: 0.026060
2021-12-11 19:43:41,878 iteration 827 : loss : 0.102170, loss_ce: 0.031547
2021-12-11 19:43:43,347 iteration 828 : loss : 0.057210, loss_ce: 0.022709
2021-12-11 19:43:44,988 iteration 829 : loss : 0.073806, loss_ce: 0.034434
2021-12-11 19:43:46,526 iteration 830 : loss : 0.084518, loss_ce: 0.037650
2021-12-11 19:43:48,126 iteration 831 : loss : 0.099159, loss_ce: 0.044386
2021-12-11 19:43:49,701 iteration 832 : loss : 0.071454, loss_ce: 0.022265
2021-12-11 19:43:51,271 iteration 833 : loss : 0.065412, loss_ce: 0.026892
 12%|███▋                          | 49/400 [23:36<2:42:13, 27.73s/it]2021-12-11 19:43:52,802 iteration 834 : loss : 0.061393, loss_ce: 0.020237
2021-12-11 19:43:54,264 iteration 835 : loss : 0.047432, loss_ce: 0.014380
2021-12-11 19:43:55,892 iteration 836 : loss : 0.072504, loss_ce: 0.025070
2021-12-11 19:43:57,420 iteration 837 : loss : 0.080646, loss_ce: 0.031935
2021-12-11 19:43:59,007 iteration 838 : loss : 0.073151, loss_ce: 0.031915
2021-12-11 19:44:00,476 iteration 839 : loss : 0.066907, loss_ce: 0.025108
2021-12-11 19:44:01,962 iteration 840 : loss : 0.052557, loss_ce: 0.023973
2021-12-11 19:44:03,468 iteration 841 : loss : 0.065153, loss_ce: 0.024007
2021-12-11 19:44:05,111 iteration 842 : loss : 0.091406, loss_ce: 0.032430
2021-12-11 19:44:06,630 iteration 843 : loss : 0.081046, loss_ce: 0.028725
2021-12-11 19:44:08,242 iteration 844 : loss : 0.054507, loss_ce: 0.021728
2021-12-11 19:44:09,771 iteration 845 : loss : 0.071896, loss_ce: 0.038715
2021-12-11 19:44:11,306 iteration 846 : loss : 0.055874, loss_ce: 0.026113
2021-12-11 19:44:12,947 iteration 847 : loss : 0.079688, loss_ce: 0.028687
2021-12-11 19:44:14,497 iteration 848 : loss : 0.060942, loss_ce: 0.024731
2021-12-11 19:44:16,022 iteration 849 : loss : 0.063644, loss_ce: 0.023684
2021-12-11 19:44:16,022 Training Data Eval:
2021-12-11 19:44:23,791   Average segmentation loss on training set: 0.0543
2021-12-11 19:44:23,791 Validation Data Eval:
2021-12-11 19:44:26,454   Average segmentation loss on validation set: 0.1208
2021-12-11 19:44:28,370 Found new lowest validation loss at iteration 849! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/NEW_TU/UNET_ADAM_best_val_loss_seed2.pth
2021-12-11 19:44:29,895 iteration 850 : loss : 0.086860, loss_ce: 0.042480
 12%|███▊                          | 50/400 [24:14<3:00:49, 31.00s/it]2021-12-11 19:44:31,500 iteration 851 : loss : 0.061127, loss_ce: 0.025079
2021-12-11 19:44:33,046 iteration 852 : loss : 0.066789, loss_ce: 0.021774
2021-12-11 19:44:34,611 iteration 853 : loss : 0.071022, loss_ce: 0.025087
2021-12-11 19:44:36,196 iteration 854 : loss : 0.055876, loss_ce: 0.026233
2021-12-11 19:44:37,712 iteration 855 : loss : 0.055327, loss_ce: 0.025996
2021-12-11 19:44:39,303 iteration 856 : loss : 0.066148, loss_ce: 0.029231
2021-12-11 19:44:40,836 iteration 857 : loss : 0.093449, loss_ce: 0.043235
2021-12-11 19:44:42,489 iteration 858 : loss : 0.039792, loss_ce: 0.016541
2021-12-11 19:44:43,909 iteration 859 : loss : 0.057362, loss_ce: 0.019950
2021-12-11 19:44:45,452 iteration 860 : loss : 0.060359, loss_ce: 0.025604
2021-12-11 19:44:47,001 iteration 861 : loss : 0.073938, loss_ce: 0.022864
2021-12-11 19:44:48,580 iteration 862 : loss : 0.068756, loss_ce: 0.033236
2021-12-11 19:44:50,130 iteration 863 : loss : 0.101171, loss_ce: 0.036868
2021-12-11 19:44:51,666 iteration 864 : loss : 0.060066, loss_ce: 0.026070
2021-12-11 19:44:53,238 iteration 865 : loss : 0.050269, loss_ce: 0.019232
2021-12-11 19:44:54,750 iteration 866 : loss : 0.064126, loss_ce: 0.027713
2021-12-11 19:44:56,337 iteration 867 : loss : 0.062142, loss_ce: 0.024542
 13%|███▊                          | 51/400 [24:41<2:52:21, 29.63s/it]2021-12-11 19:44:57,940 iteration 868 : loss : 0.047550, loss_ce: 0.021017
2021-12-11 19:44:59,541 iteration 869 : loss : 0.066681, loss_ce: 0.030335
2021-12-11 19:45:00,998 iteration 870 : loss : 0.062955, loss_ce: 0.029150
2021-12-11 19:45:02,523 iteration 871 : loss : 0.055607, loss_ce: 0.025808
2021-12-11 19:45:04,060 iteration 872 : loss : 0.059286, loss_ce: 0.025913
2021-12-11 19:45:05,631 iteration 873 : loss : 0.074887, loss_ce: 0.033026
2021-12-11 19:45:07,189 iteration 874 : loss : 0.058431, loss_ce: 0.023991
2021-12-11 19:45:08,759 iteration 875 : loss : 0.091689, loss_ce: 0.032743
2021-12-11 19:45:10,312 iteration 876 : loss : 0.050133, loss_ce: 0.018473
2021-12-11 19:45:11,947 iteration 877 : loss : 0.051106, loss_ce: 0.022170
2021-12-11 19:45:13,466 iteration 878 : loss : 0.116442, loss_ce: 0.030121
2021-12-11 19:45:15,010 iteration 879 : loss : 0.070208, loss_ce: 0.023807
2021-12-11 19:45:16,521 iteration 880 : loss : 0.055395, loss_ce: 0.025605
2021-12-11 19:45:18,145 iteration 881 : loss : 0.057074, loss_ce: 0.019800
2021-12-11 19:45:19,731 iteration 882 : loss : 0.072109, loss_ce: 0.029371
2021-12-11 19:45:21,260 iteration 883 : loss : 0.048768, loss_ce: 0.016816
2021-12-11 19:45:22,860 iteration 884 : loss : 0.064506, loss_ce: 0.026400
 13%|███▉                          | 52/400 [25:07<2:46:27, 28.70s/it]2021-12-11 19:45:24,488 iteration 885 : loss : 0.065418, loss_ce: 0.033998
2021-12-11 19:45:26,047 iteration 886 : loss : 0.075366, loss_ce: 0.038050
2021-12-11 19:45:27,602 iteration 887 : loss : 0.072698, loss_ce: 0.027185
2021-12-11 19:45:29,186 iteration 888 : loss : 0.069372, loss_ce: 0.027134
2021-12-11 19:45:30,756 iteration 889 : loss : 0.110042, loss_ce: 0.025965
2021-12-11 19:45:32,283 iteration 890 : loss : 0.049929, loss_ce: 0.021534
2021-12-11 19:45:33,850 iteration 891 : loss : 0.069594, loss_ce: 0.043255
2021-12-11 19:45:35,413 iteration 892 : loss : 0.051433, loss_ce: 0.021657
2021-12-11 19:45:36,958 iteration 893 : loss : 0.070792, loss_ce: 0.034221
2021-12-11 19:45:38,482 iteration 894 : loss : 0.063790, loss_ce: 0.024065
2021-12-11 19:45:40,012 iteration 895 : loss : 0.067529, loss_ce: 0.021881
2021-12-11 19:45:41,522 iteration 896 : loss : 0.067898, loss_ce: 0.038738
2021-12-11 19:45:43,232 iteration 897 : loss : 0.069734, loss_ce: 0.027086
2021-12-11 19:45:44,764 iteration 898 : loss : 0.067712, loss_ce: 0.023397
2021-12-11 19:45:46,384 iteration 899 : loss : 0.073589, loss_ce: 0.026370
2021-12-11 19:45:47,970 iteration 900 : loss : 0.076069, loss_ce: 0.029965
2021-12-11 19:45:49,492 iteration 901 : loss : 0.064942, loss_ce: 0.026088
 13%|███▉                          | 53/400 [25:34<2:42:24, 28.08s/it]2021-12-11 19:45:51,201 iteration 902 : loss : 0.065911, loss_ce: 0.034229
2021-12-11 19:45:52,792 iteration 903 : loss : 0.078354, loss_ce: 0.025601
2021-12-11 19:45:54,336 iteration 904 : loss : 0.080048, loss_ce: 0.034835
2021-12-11 19:45:55,873 iteration 905 : loss : 0.068961, loss_ce: 0.030484
2021-12-11 19:45:57,527 iteration 906 : loss : 0.059006, loss_ce: 0.026588
2021-12-11 19:45:59,034 iteration 907 : loss : 0.053862, loss_ce: 0.023054
2021-12-11 19:46:00,552 iteration 908 : loss : 0.067132, loss_ce: 0.032875
2021-12-11 19:46:02,141 iteration 909 : loss : 0.064966, loss_ce: 0.029281
2021-12-11 19:46:03,802 iteration 910 : loss : 0.057909, loss_ce: 0.024128
2021-12-11 19:46:05,353 iteration 911 : loss : 0.062328, loss_ce: 0.021832
2021-12-11 19:46:06,946 iteration 912 : loss : 0.065303, loss_ce: 0.026977
2021-12-11 19:46:08,497 iteration 913 : loss : 0.090726, loss_ce: 0.030966
2021-12-11 19:46:09,982 iteration 914 : loss : 0.053554, loss_ce: 0.023844
2021-12-11 19:46:11,555 iteration 915 : loss : 0.078656, loss_ce: 0.027514
2021-12-11 19:46:13,188 iteration 916 : loss : 0.080303, loss_ce: 0.026583
2021-12-11 19:46:14,768 iteration 917 : loss : 0.057766, loss_ce: 0.023509
2021-12-11 19:46:16,417 iteration 918 : loss : 0.106195, loss_ce: 0.035600
 14%|████                          | 54/400 [26:01<2:39:56, 27.74s/it]2021-12-11 19:46:18,012 iteration 919 : loss : 0.060971, loss_ce: 0.020111
2021-12-11 19:46:19,645 iteration 920 : loss : 0.047339, loss_ce: 0.021855
2021-12-11 19:46:21,145 iteration 921 : loss : 0.048849, loss_ce: 0.020485
2021-12-11 19:46:22,740 iteration 922 : loss : 0.075600, loss_ce: 0.022425
2021-12-11 19:46:24,225 iteration 923 : loss : 0.057190, loss_ce: 0.020568
2021-12-11 19:46:25,807 iteration 924 : loss : 0.083203, loss_ce: 0.024539
2021-12-11 19:46:27,402 iteration 925 : loss : 0.075459, loss_ce: 0.022061
2021-12-11 19:46:28,987 iteration 926 : loss : 0.079757, loss_ce: 0.029643
2021-12-11 19:46:30,471 iteration 927 : loss : 0.103542, loss_ce: 0.028120
2021-12-11 19:46:32,096 iteration 928 : loss : 0.064798, loss_ce: 0.029494
2021-12-11 19:46:33,630 iteration 929 : loss : 0.054062, loss_ce: 0.021651
2021-12-11 19:46:35,119 iteration 930 : loss : 0.053470, loss_ce: 0.023234
2021-12-11 19:46:36,633 iteration 931 : loss : 0.095633, loss_ce: 0.052211
2021-12-11 19:46:38,197 iteration 932 : loss : 0.061959, loss_ce: 0.032906
2021-12-11 19:46:39,793 iteration 933 : loss : 0.063011, loss_ce: 0.031664
2021-12-11 19:46:41,309 iteration 934 : loss : 0.057569, loss_ce: 0.018161
2021-12-11 19:46:41,310 Training Data Eval:
2021-12-11 19:46:49,074   Average segmentation loss on training set: 0.0542
2021-12-11 19:46:49,074 Validation Data Eval:
2021-12-11 19:46:51,745   Average segmentation loss on validation set: 0.0929
2021-12-11 19:46:53,677 Found new lowest validation loss at iteration 934! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/NEW_TU/UNET_ADAM_best_val_loss_seed2.pth
2021-12-11 19:46:55,284 iteration 935 : loss : 0.051774, loss_ce: 0.021953
 14%|████▏                         | 55/400 [26:40<2:58:40, 31.07s/it]2021-12-11 19:46:56,911 iteration 936 : loss : 0.053131, loss_ce: 0.023322
2021-12-11 19:46:58,451 iteration 937 : loss : 0.094458, loss_ce: 0.033760
2021-12-11 19:47:00,028 iteration 938 : loss : 0.053475, loss_ce: 0.023179
2021-12-11 19:47:01,699 iteration 939 : loss : 0.093271, loss_ce: 0.033709
2021-12-11 19:47:03,198 iteration 940 : loss : 0.052775, loss_ce: 0.019184
2021-12-11 19:47:04,736 iteration 941 : loss : 0.066785, loss_ce: 0.024575
2021-12-11 19:47:06,286 iteration 942 : loss : 0.082748, loss_ce: 0.036042
2021-12-11 19:47:07,859 iteration 943 : loss : 0.093275, loss_ce: 0.030030
2021-12-11 19:47:09,424 iteration 944 : loss : 0.097972, loss_ce: 0.041938
2021-12-11 19:47:11,008 iteration 945 : loss : 0.095206, loss_ce: 0.041404
2021-12-11 19:47:12,562 iteration 946 : loss : 0.053810, loss_ce: 0.021409
2021-12-11 19:47:14,118 iteration 947 : loss : 0.076733, loss_ce: 0.025394
2021-12-11 19:47:15,754 iteration 948 : loss : 0.115887, loss_ce: 0.049534
2021-12-11 19:47:17,388 iteration 949 : loss : 0.087336, loss_ce: 0.038344
2021-12-11 19:47:19,040 iteration 950 : loss : 0.081117, loss_ce: 0.031023
2021-12-11 19:47:20,587 iteration 951 : loss : 0.072210, loss_ce: 0.028731
2021-12-11 19:47:22,189 iteration 952 : loss : 0.081003, loss_ce: 0.030844
 14%|████▏                         | 56/400 [27:07<2:50:59, 29.82s/it]2021-12-11 19:47:23,780 iteration 953 : loss : 0.066055, loss_ce: 0.025000
2021-12-11 19:47:25,311 iteration 954 : loss : 0.066181, loss_ce: 0.024104
2021-12-11 19:47:26,904 iteration 955 : loss : 0.090673, loss_ce: 0.034005
2021-12-11 19:47:28,489 iteration 956 : loss : 0.056007, loss_ce: 0.018140
2021-12-11 19:47:30,065 iteration 957 : loss : 0.078658, loss_ce: 0.029816
2021-12-11 19:47:31,657 iteration 958 : loss : 0.076353, loss_ce: 0.027808
2021-12-11 19:47:33,288 iteration 959 : loss : 0.081564, loss_ce: 0.034928
2021-12-11 19:47:34,886 iteration 960 : loss : 0.063613, loss_ce: 0.029208
2021-12-11 19:47:36,464 iteration 961 : loss : 0.060397, loss_ce: 0.024188
2021-12-11 19:47:38,065 iteration 962 : loss : 0.073346, loss_ce: 0.022751
2021-12-11 19:47:39,564 iteration 963 : loss : 0.064716, loss_ce: 0.027168
2021-12-11 19:47:41,143 iteration 964 : loss : 0.093061, loss_ce: 0.028739
2021-12-11 19:47:42,666 iteration 965 : loss : 0.049668, loss_ce: 0.018093
2021-12-11 19:47:44,327 iteration 966 : loss : 0.079558, loss_ce: 0.027980
2021-12-11 19:47:45,910 iteration 967 : loss : 0.069615, loss_ce: 0.033461
2021-12-11 19:47:47,387 iteration 968 : loss : 0.055458, loss_ce: 0.021542
2021-12-11 19:47:48,961 iteration 969 : loss : 0.061200, loss_ce: 0.028858
 14%|████▎                         | 57/400 [27:33<2:45:14, 28.90s/it]2021-12-11 19:47:50,526 iteration 970 : loss : 0.071697, loss_ce: 0.036652
2021-12-11 19:47:52,087 iteration 971 : loss : 0.061741, loss_ce: 0.026306
2021-12-11 19:47:53,644 iteration 972 : loss : 0.063282, loss_ce: 0.023721
2021-12-11 19:47:55,238 iteration 973 : loss : 0.047953, loss_ce: 0.019862
2021-12-11 19:47:56,809 iteration 974 : loss : 0.063014, loss_ce: 0.024127
2021-12-11 19:47:58,336 iteration 975 : loss : 0.065850, loss_ce: 0.022655
2021-12-11 19:47:59,984 iteration 976 : loss : 0.061544, loss_ce: 0.026262
2021-12-11 19:48:01,549 iteration 977 : loss : 0.046362, loss_ce: 0.017498
2021-12-11 19:48:03,152 iteration 978 : loss : 0.055100, loss_ce: 0.020261
2021-12-11 19:48:04,684 iteration 979 : loss : 0.049048, loss_ce: 0.019242
2021-12-11 19:48:06,226 iteration 980 : loss : 0.065299, loss_ce: 0.022339
2021-12-11 19:48:07,753 iteration 981 : loss : 0.027865, loss_ce: 0.010537
2021-12-11 19:48:09,354 iteration 982 : loss : 0.064797, loss_ce: 0.023532
2021-12-11 19:48:10,992 iteration 983 : loss : 0.081093, loss_ce: 0.037671
2021-12-11 19:48:12,631 iteration 984 : loss : 0.063994, loss_ce: 0.026098
2021-12-11 19:48:14,234 iteration 985 : loss : 0.059760, loss_ce: 0.023367
2021-12-11 19:48:15,770 iteration 986 : loss : 0.050166, loss_ce: 0.017244
 14%|████▎                         | 58/400 [28:00<2:41:11, 28.28s/it]2021-12-11 19:48:17,300 iteration 987 : loss : 0.046952, loss_ce: 0.018331
2021-12-11 19:48:18,859 iteration 988 : loss : 0.060755, loss_ce: 0.022560
2021-12-11 19:48:20,412 iteration 989 : loss : 0.046355, loss_ce: 0.016882
2021-12-11 19:48:21,965 iteration 990 : loss : 0.062424, loss_ce: 0.025216
2021-12-11 19:48:23,531 iteration 991 : loss : 0.055806, loss_ce: 0.022000
2021-12-11 19:48:25,058 iteration 992 : loss : 0.044788, loss_ce: 0.017563
2021-12-11 19:48:26,548 iteration 993 : loss : 0.052523, loss_ce: 0.020886
2021-12-11 19:48:27,983 iteration 994 : loss : 0.058494, loss_ce: 0.019993
2021-12-11 19:48:29,632 iteration 995 : loss : 0.079525, loss_ce: 0.042507
2021-12-11 19:48:31,229 iteration 996 : loss : 0.052905, loss_ce: 0.024728
2021-12-11 19:48:32,847 iteration 997 : loss : 0.065258, loss_ce: 0.024585
2021-12-11 19:48:34,450 iteration 998 : loss : 0.056829, loss_ce: 0.020149
2021-12-11 19:48:35,973 iteration 999 : loss : 0.058655, loss_ce: 0.024773
2021-12-11 19:48:37,600 iteration 1000 : loss : 0.062198, loss_ce: 0.031791
2021-12-11 19:48:39,142 iteration 1001 : loss : 0.046630, loss_ce: 0.018198
2021-12-11 19:48:40,727 iteration 1002 : loss : 0.079336, loss_ce: 0.031499
2021-12-11 19:48:42,216 iteration 1003 : loss : 0.101575, loss_ce: 0.031395
 15%|████▍                         | 59/400 [28:27<2:37:34, 27.73s/it]2021-12-11 19:48:43,821 iteration 1004 : loss : 0.053435, loss_ce: 0.018812
2021-12-11 19:48:45,379 iteration 1005 : loss : 0.074459, loss_ce: 0.034864
2021-12-11 19:48:47,047 iteration 1006 : loss : 0.075281, loss_ce: 0.032805
2021-12-11 19:48:48,667 iteration 1007 : loss : 0.068360, loss_ce: 0.031265
2021-12-11 19:48:50,292 iteration 1008 : loss : 0.073674, loss_ce: 0.043544
2021-12-11 19:48:51,826 iteration 1009 : loss : 0.051265, loss_ce: 0.019582
2021-12-11 19:48:53,306 iteration 1010 : loss : 0.051356, loss_ce: 0.017557
2021-12-11 19:48:54,843 iteration 1011 : loss : 0.066145, loss_ce: 0.024876
2021-12-11 19:48:56,462 iteration 1012 : loss : 0.062900, loss_ce: 0.028093
2021-12-11 19:48:58,021 iteration 1013 : loss : 0.049733, loss_ce: 0.019101
2021-12-11 19:48:59,570 iteration 1014 : loss : 0.037244, loss_ce: 0.014812
2021-12-11 19:49:01,278 iteration 1015 : loss : 0.078932, loss_ce: 0.030799
2021-12-11 19:49:02,834 iteration 1016 : loss : 0.051505, loss_ce: 0.021168
2021-12-11 19:49:04,355 iteration 1017 : loss : 0.080059, loss_ce: 0.035411
2021-12-11 19:49:05,994 iteration 1018 : loss : 0.086017, loss_ce: 0.027550
2021-12-11 19:49:07,603 iteration 1019 : loss : 0.068954, loss_ce: 0.030461
2021-12-11 19:49:07,604 Training Data Eval:
2021-12-11 19:49:15,387   Average segmentation loss on training set: 0.0700
2021-12-11 19:49:15,387 Validation Data Eval:
2021-12-11 19:49:18,058   Average segmentation loss on validation set: 0.1500
2021-12-11 19:49:19,708 iteration 1020 : loss : 0.071151, loss_ce: 0.028534
 15%|████▌                         | 60/400 [29:04<2:53:43, 30.66s/it]2021-12-11 19:49:21,313 iteration 1021 : loss : 0.052400, loss_ce: 0.019608
2021-12-11 19:49:22,972 iteration 1022 : loss : 0.066764, loss_ce: 0.031471
2021-12-11 19:49:24,487 iteration 1023 : loss : 0.047198, loss_ce: 0.018264
2021-12-11 19:49:26,024 iteration 1024 : loss : 0.049911, loss_ce: 0.017422
2021-12-11 19:49:27,641 iteration 1025 : loss : 0.046204, loss_ce: 0.019977
2021-12-11 19:49:29,224 iteration 1026 : loss : 0.080024, loss_ce: 0.019474
2021-12-11 19:49:30,758 iteration 1027 : loss : 0.049327, loss_ce: 0.017250
2021-12-11 19:49:32,417 iteration 1028 : loss : 0.069659, loss_ce: 0.021512
2021-12-11 19:49:34,037 iteration 1029 : loss : 0.074692, loss_ce: 0.026879
2021-12-11 19:49:35,611 iteration 1030 : loss : 0.087677, loss_ce: 0.034605
2021-12-11 19:49:37,302 iteration 1031 : loss : 0.068885, loss_ce: 0.027298
2021-12-11 19:49:38,899 iteration 1032 : loss : 0.061037, loss_ce: 0.028101
2021-12-11 19:49:40,443 iteration 1033 : loss : 0.053976, loss_ce: 0.026782
2021-12-11 19:49:41,949 iteration 1034 : loss : 0.046939, loss_ce: 0.017859
2021-12-11 19:49:43,556 iteration 1035 : loss : 0.078483, loss_ce: 0.033673
2021-12-11 19:49:45,191 iteration 1036 : loss : 0.067546, loss_ce: 0.026712
2021-12-11 19:49:46,672 iteration 1037 : loss : 0.049405, loss_ce: 0.020675
 15%|████▌                         | 61/400 [29:31<2:46:57, 29.55s/it]2021-12-11 19:49:48,251 iteration 1038 : loss : 0.050588, loss_ce: 0.022050
2021-12-11 19:49:49,784 iteration 1039 : loss : 0.048076, loss_ce: 0.019356
2021-12-11 19:49:51,325 iteration 1040 : loss : 0.071194, loss_ce: 0.024379
2021-12-11 19:49:52,883 iteration 1041 : loss : 0.058821, loss_ce: 0.027921
2021-12-11 19:49:54,416 iteration 1042 : loss : 0.054602, loss_ce: 0.030275
2021-12-11 19:49:55,958 iteration 1043 : loss : 0.067389, loss_ce: 0.023907
2021-12-11 19:49:57,607 iteration 1044 : loss : 0.069144, loss_ce: 0.028277
2021-12-11 19:49:59,179 iteration 1045 : loss : 0.075495, loss_ce: 0.028235
2021-12-11 19:50:00,700 iteration 1046 : loss : 0.045907, loss_ce: 0.021773
2021-12-11 19:50:02,129 iteration 1047 : loss : 0.040907, loss_ce: 0.014940
2021-12-11 19:50:03,695 iteration 1048 : loss : 0.044305, loss_ce: 0.022150
2021-12-11 19:50:05,309 iteration 1049 : loss : 0.067065, loss_ce: 0.022592
2021-12-11 19:50:06,856 iteration 1050 : loss : 0.138091, loss_ce: 0.028955
2021-12-11 19:50:08,384 iteration 1051 : loss : 0.053050, loss_ce: 0.023126
2021-12-11 19:50:09,995 iteration 1052 : loss : 0.084292, loss_ce: 0.023643
2021-12-11 19:50:11,590 iteration 1053 : loss : 0.110078, loss_ce: 0.032289
2021-12-11 19:50:13,168 iteration 1054 : loss : 0.083765, loss_ce: 0.033844
 16%|████▋                         | 62/400 [29:58<2:41:18, 28.63s/it]2021-12-11 19:50:14,791 iteration 1055 : loss : 0.058200, loss_ce: 0.014155
2021-12-11 19:50:16,269 iteration 1056 : loss : 0.055505, loss_ce: 0.026333
2021-12-11 19:50:17,867 iteration 1057 : loss : 0.083324, loss_ce: 0.025996
2021-12-11 19:50:19,433 iteration 1058 : loss : 0.073726, loss_ce: 0.025898
2021-12-11 19:50:21,005 iteration 1059 : loss : 0.088905, loss_ce: 0.033593
2021-12-11 19:50:22,491 iteration 1060 : loss : 0.048108, loss_ce: 0.014813
2021-12-11 19:50:24,159 iteration 1061 : loss : 0.080201, loss_ce: 0.038487
2021-12-11 19:50:25,740 iteration 1062 : loss : 0.065258, loss_ce: 0.020586
2021-12-11 19:50:27,460 iteration 1063 : loss : 0.055706, loss_ce: 0.023991
2021-12-11 19:50:29,084 iteration 1064 : loss : 0.073723, loss_ce: 0.022505
2021-12-11 19:50:30,743 iteration 1065 : loss : 0.071214, loss_ce: 0.033664
2021-12-11 19:50:32,262 iteration 1066 : loss : 0.043146, loss_ce: 0.017150
2021-12-11 19:50:33,785 iteration 1067 : loss : 0.050801, loss_ce: 0.022417
2021-12-11 19:50:35,394 iteration 1068 : loss : 0.053667, loss_ce: 0.022738
2021-12-11 19:50:36,981 iteration 1069 : loss : 0.056340, loss_ce: 0.026836
2021-12-11 19:50:38,671 iteration 1070 : loss : 0.108449, loss_ce: 0.028982
2021-12-11 19:50:40,238 iteration 1071 : loss : 0.071125, loss_ce: 0.032449
 16%|████▋                         | 63/400 [30:25<2:38:11, 28.17s/it]2021-12-11 19:50:41,970 iteration 1072 : loss : 0.065656, loss_ce: 0.018343
2021-12-11 19:50:43,561 iteration 1073 : loss : 0.075158, loss_ce: 0.033267
2021-12-11 19:50:45,160 iteration 1074 : loss : 0.069705, loss_ce: 0.023780
2021-12-11 19:50:46,766 iteration 1075 : loss : 0.077650, loss_ce: 0.026511
2021-12-11 19:50:48,292 iteration 1076 : loss : 0.062337, loss_ce: 0.025068
2021-12-11 19:50:49,945 iteration 1077 : loss : 0.061490, loss_ce: 0.020749
2021-12-11 19:50:51,478 iteration 1078 : loss : 0.049888, loss_ce: 0.021301
2021-12-11 19:50:53,112 iteration 1079 : loss : 0.066570, loss_ce: 0.029589
2021-12-11 19:50:54,604 iteration 1080 : loss : 0.042230, loss_ce: 0.015104
2021-12-11 19:50:56,152 iteration 1081 : loss : 0.057930, loss_ce: 0.034171
2021-12-11 19:50:57,788 iteration 1082 : loss : 0.073827, loss_ce: 0.037040
2021-12-11 19:50:59,312 iteration 1083 : loss : 0.048493, loss_ce: 0.018982
2021-12-11 19:51:00,862 iteration 1084 : loss : 0.068346, loss_ce: 0.020674
2021-12-11 19:51:02,445 iteration 1085 : loss : 0.053378, loss_ce: 0.022448
2021-12-11 19:51:03,994 iteration 1086 : loss : 0.068519, loss_ce: 0.031921
2021-12-11 19:51:05,653 iteration 1087 : loss : 0.047112, loss_ce: 0.019279
2021-12-11 19:51:07,226 iteration 1088 : loss : 0.059767, loss_ce: 0.024052
 16%|████▊                         | 64/400 [30:52<2:35:43, 27.81s/it]2021-12-11 19:51:08,815 iteration 1089 : loss : 0.087081, loss_ce: 0.030879
2021-12-11 19:51:10,344 iteration 1090 : loss : 0.072641, loss_ce: 0.024180
2021-12-11 19:51:11,963 iteration 1091 : loss : 0.051787, loss_ce: 0.023213
2021-12-11 19:51:13,540 iteration 1092 : loss : 0.056303, loss_ce: 0.024030
2021-12-11 19:51:15,116 iteration 1093 : loss : 0.053049, loss_ce: 0.022416
2021-12-11 19:51:16,709 iteration 1094 : loss : 0.055899, loss_ce: 0.026703
2021-12-11 19:51:18,310 iteration 1095 : loss : 0.118764, loss_ce: 0.035658
2021-12-11 19:51:19,887 iteration 1096 : loss : 0.044687, loss_ce: 0.020088
2021-12-11 19:51:21,400 iteration 1097 : loss : 0.065826, loss_ce: 0.023028
2021-12-11 19:51:22,927 iteration 1098 : loss : 0.044875, loss_ce: 0.021500
2021-12-11 19:51:24,517 iteration 1099 : loss : 0.049880, loss_ce: 0.019309
2021-12-11 19:51:26,057 iteration 1100 : loss : 0.055135, loss_ce: 0.023257
2021-12-11 19:51:27,590 iteration 1101 : loss : 0.052070, loss_ce: 0.019796
2021-12-11 19:51:29,238 iteration 1102 : loss : 0.074754, loss_ce: 0.020321
2021-12-11 19:51:30,790 iteration 1103 : loss : 0.063946, loss_ce: 0.023388
2021-12-11 19:51:32,302 iteration 1104 : loss : 0.075458, loss_ce: 0.033759
2021-12-11 19:51:32,302 Training Data Eval:
2021-12-11 19:51:40,078   Average segmentation loss on training set: 0.0414
2021-12-11 19:51:40,078 Validation Data Eval:
2021-12-11 19:51:42,733   Average segmentation loss on validation set: 0.1311
2021-12-11 19:51:44,288 iteration 1105 : loss : 0.069102, loss_ce: 0.038851
 16%|████▉                         | 65/400 [31:29<2:50:46, 30.59s/it]2021-12-11 19:51:45,916 iteration 1106 : loss : 0.055456, loss_ce: 0.019202
2021-12-11 19:51:47,551 iteration 1107 : loss : 0.063533, loss_ce: 0.027923
2021-12-11 19:51:49,069 iteration 1108 : loss : 0.041718, loss_ce: 0.014601
2021-12-11 19:51:50,573 iteration 1109 : loss : 0.077148, loss_ce: 0.032038
2021-12-11 19:51:52,118 iteration 1110 : loss : 0.048363, loss_ce: 0.020534
2021-12-11 19:51:53,685 iteration 1111 : loss : 0.044093, loss_ce: 0.017625
2021-12-11 19:51:55,265 iteration 1112 : loss : 0.053149, loss_ce: 0.024121
2021-12-11 19:51:56,794 iteration 1113 : loss : 0.054742, loss_ce: 0.020659
2021-12-11 19:51:58,302 iteration 1114 : loss : 0.070514, loss_ce: 0.025524
2021-12-11 19:51:59,762 iteration 1115 : loss : 0.063318, loss_ce: 0.020756
2021-12-11 19:52:01,410 iteration 1116 : loss : 0.081350, loss_ce: 0.037228
2021-12-11 19:52:03,072 iteration 1117 : loss : 0.066326, loss_ce: 0.030435
2021-12-11 19:52:04,599 iteration 1118 : loss : 0.048323, loss_ce: 0.019529
2021-12-11 19:52:06,118 iteration 1119 : loss : 0.045886, loss_ce: 0.018900
2021-12-11 19:52:07,621 iteration 1120 : loss : 0.054675, loss_ce: 0.020737
2021-12-11 19:52:09,133 iteration 1121 : loss : 0.048961, loss_ce: 0.014954
2021-12-11 19:52:10,635 iteration 1122 : loss : 0.052363, loss_ce: 0.022801
 16%|████▉                         | 66/400 [31:55<2:43:11, 29.32s/it]2021-12-11 19:52:12,263 iteration 1123 : loss : 0.053621, loss_ce: 0.025717
2021-12-11 19:52:13,787 iteration 1124 : loss : 0.055104, loss_ce: 0.023794
2021-12-11 19:52:15,402 iteration 1125 : loss : 0.068847, loss_ce: 0.028771
2021-12-11 19:52:17,094 iteration 1126 : loss : 0.085877, loss_ce: 0.039123
2021-12-11 19:52:18,687 iteration 1127 : loss : 0.091664, loss_ce: 0.034805
2021-12-11 19:52:20,279 iteration 1128 : loss : 0.054845, loss_ce: 0.016197
2021-12-11 19:52:21,842 iteration 1129 : loss : 0.036808, loss_ce: 0.013586
2021-12-11 19:52:23,467 iteration 1130 : loss : 0.070081, loss_ce: 0.034687
2021-12-11 19:52:25,113 iteration 1131 : loss : 0.108262, loss_ce: 0.036634
2021-12-11 19:52:26,724 iteration 1132 : loss : 0.063469, loss_ce: 0.024200
2021-12-11 19:52:28,317 iteration 1133 : loss : 0.060881, loss_ce: 0.025499
2021-12-11 19:52:29,895 iteration 1134 : loss : 0.074444, loss_ce: 0.029473
2021-12-11 19:52:31,412 iteration 1135 : loss : 0.048193, loss_ce: 0.017141
2021-12-11 19:52:32,980 iteration 1136 : loss : 0.065244, loss_ce: 0.026286
2021-12-11 19:52:34,522 iteration 1137 : loss : 0.052388, loss_ce: 0.019315
2021-12-11 19:52:36,171 iteration 1138 : loss : 0.064759, loss_ce: 0.032612
2021-12-11 19:52:37,810 iteration 1139 : loss : 0.046503, loss_ce: 0.019107
 17%|█████                         | 67/400 [32:22<2:39:08, 28.67s/it]2021-12-11 19:52:39,424 iteration 1140 : loss : 0.053370, loss_ce: 0.021939
2021-12-11 19:52:41,011 iteration 1141 : loss : 0.048006, loss_ce: 0.019301
2021-12-11 19:52:42,525 iteration 1142 : loss : 0.043664, loss_ce: 0.016992
2021-12-11 19:52:44,102 iteration 1143 : loss : 0.111173, loss_ce: 0.040482
2021-12-11 19:52:45,720 iteration 1144 : loss : 0.055052, loss_ce: 0.023265
2021-12-11 19:52:47,275 iteration 1145 : loss : 0.049027, loss_ce: 0.016840
2021-12-11 19:52:48,878 iteration 1146 : loss : 0.057452, loss_ce: 0.023167
2021-12-11 19:52:50,370 iteration 1147 : loss : 0.039680, loss_ce: 0.014002
2021-12-11 19:52:51,922 iteration 1148 : loss : 0.051191, loss_ce: 0.018519
2021-12-11 19:52:53,537 iteration 1149 : loss : 0.045518, loss_ce: 0.021757
2021-12-11 19:52:55,116 iteration 1150 : loss : 0.049177, loss_ce: 0.022687
2021-12-11 19:52:56,689 iteration 1151 : loss : 0.067882, loss_ce: 0.020787
2021-12-11 19:52:58,292 iteration 1152 : loss : 0.112600, loss_ce: 0.023987
2021-12-11 19:52:59,865 iteration 1153 : loss : 0.042927, loss_ce: 0.015862
2021-12-11 19:53:01,363 iteration 1154 : loss : 0.067924, loss_ce: 0.035452
2021-12-11 19:53:03,028 iteration 1155 : loss : 0.074924, loss_ce: 0.028874
2021-12-11 19:53:04,627 iteration 1156 : loss : 0.099476, loss_ce: 0.030973
 17%|█████                         | 68/400 [32:49<2:35:33, 28.11s/it]2021-12-11 19:53:06,201 iteration 1157 : loss : 0.043565, loss_ce: 0.016032
2021-12-11 19:53:07,901 iteration 1158 : loss : 0.061749, loss_ce: 0.020818
2021-12-11 19:53:09,544 iteration 1159 : loss : 0.063592, loss_ce: 0.024351
2021-12-11 19:53:11,028 iteration 1160 : loss : 0.055750, loss_ce: 0.027539
2021-12-11 19:53:12,587 iteration 1161 : loss : 0.045729, loss_ce: 0.016677
2021-12-11 19:53:14,146 iteration 1162 : loss : 0.059253, loss_ce: 0.016275
2021-12-11 19:53:15,824 iteration 1163 : loss : 0.084011, loss_ce: 0.029865
2021-12-11 19:53:17,428 iteration 1164 : loss : 0.049628, loss_ce: 0.017901
2021-12-11 19:53:18,934 iteration 1165 : loss : 0.053853, loss_ce: 0.027848
2021-12-11 19:53:20,497 iteration 1166 : loss : 0.044731, loss_ce: 0.020801
2021-12-11 19:53:22,090 iteration 1167 : loss : 0.071092, loss_ce: 0.032202
2021-12-11 19:53:23,573 iteration 1168 : loss : 0.049254, loss_ce: 0.018888
2021-12-11 19:53:25,135 iteration 1169 : loss : 0.068739, loss_ce: 0.021649
2021-12-11 19:53:26,705 iteration 1170 : loss : 0.061011, loss_ce: 0.021493
2021-12-11 19:53:28,192 iteration 1171 : loss : 0.063072, loss_ce: 0.019568
2021-12-11 19:53:29,750 iteration 1172 : loss : 0.059274, loss_ce: 0.025812
2021-12-11 19:53:31,333 iteration 1173 : loss : 0.061061, loss_ce: 0.037514
 17%|█████▏                        | 69/400 [33:16<2:32:46, 27.69s/it]2021-12-11 19:53:32,987 iteration 1174 : loss : 0.058271, loss_ce: 0.017808
2021-12-11 19:53:34,528 iteration 1175 : loss : 0.040448, loss_ce: 0.017797
2021-12-11 19:53:36,149 iteration 1176 : loss : 0.076707, loss_ce: 0.034527
2021-12-11 19:53:37,826 iteration 1177 : loss : 0.058431, loss_ce: 0.026786
2021-12-11 19:53:39,414 iteration 1178 : loss : 0.060299, loss_ce: 0.027708
2021-12-11 19:53:40,892 iteration 1179 : loss : 0.047628, loss_ce: 0.019544
2021-12-11 19:53:42,504 iteration 1180 : loss : 0.061826, loss_ce: 0.023011
2021-12-11 19:53:43,991 iteration 1181 : loss : 0.044856, loss_ce: 0.019016
2021-12-11 19:53:45,670 iteration 1182 : loss : 0.066151, loss_ce: 0.024145
2021-12-11 19:53:47,226 iteration 1183 : loss : 0.049795, loss_ce: 0.020779
2021-12-11 19:53:48,722 iteration 1184 : loss : 0.045086, loss_ce: 0.018251
2021-12-11 19:53:50,317 iteration 1185 : loss : 0.067605, loss_ce: 0.024237
2021-12-11 19:53:51,837 iteration 1186 : loss : 0.061241, loss_ce: 0.021536
2021-12-11 19:53:53,433 iteration 1187 : loss : 0.059336, loss_ce: 0.024609
2021-12-11 19:53:54,945 iteration 1188 : loss : 0.042289, loss_ce: 0.015716
2021-12-11 19:53:56,515 iteration 1189 : loss : 0.053556, loss_ce: 0.018451
2021-12-11 19:53:56,516 Training Data Eval:
2021-12-11 19:54:04,299   Average segmentation loss on training set: 0.0574
2021-12-11 19:54:04,299 Validation Data Eval:
2021-12-11 19:54:06,958   Average segmentation loss on validation set: 0.1134
2021-12-11 19:54:08,554 iteration 1190 : loss : 0.053530, loss_ce: 0.020770
 18%|█████▎                        | 70/400 [33:53<2:48:01, 30.55s/it]2021-12-11 19:54:10,145 iteration 1191 : loss : 0.038643, loss_ce: 0.017070
2021-12-11 19:54:11,669 iteration 1192 : loss : 0.043404, loss_ce: 0.017722
2021-12-11 19:54:13,239 iteration 1193 : loss : 0.066552, loss_ce: 0.020960
2021-12-11 19:54:14,764 iteration 1194 : loss : 0.063492, loss_ce: 0.022016
2021-12-11 19:54:16,381 iteration 1195 : loss : 0.053931, loss_ce: 0.018087
2021-12-11 19:54:17,870 iteration 1196 : loss : 0.051200, loss_ce: 0.019459
2021-12-11 19:54:19,498 iteration 1197 : loss : 0.047390, loss_ce: 0.022526
2021-12-11 19:54:21,074 iteration 1198 : loss : 0.054961, loss_ce: 0.029961
2021-12-11 19:54:22,662 iteration 1199 : loss : 0.048065, loss_ce: 0.015848
2021-12-11 19:54:24,287 iteration 1200 : loss : 0.080715, loss_ce: 0.033897
2021-12-11 19:54:25,849 iteration 1201 : loss : 0.035920, loss_ce: 0.015956
2021-12-11 19:54:27,469 iteration 1202 : loss : 0.051460, loss_ce: 0.024731
2021-12-11 19:54:29,035 iteration 1203 : loss : 0.043191, loss_ce: 0.016202
2021-12-11 19:54:30,598 iteration 1204 : loss : 0.050619, loss_ce: 0.021247
2021-12-11 19:54:32,211 iteration 1205 : loss : 0.066999, loss_ce: 0.036751
2021-12-11 19:54:33,848 iteration 1206 : loss : 0.096656, loss_ce: 0.025691
2021-12-11 19:54:35,376 iteration 1207 : loss : 0.055177, loss_ce: 0.016182
 18%|█████▎                        | 71/400 [34:20<2:41:24, 29.44s/it]2021-12-11 19:54:36,946 iteration 1208 : loss : 0.052623, loss_ce: 0.024310
2021-12-11 19:54:38,509 iteration 1209 : loss : 0.051529, loss_ce: 0.018184
2021-12-11 19:54:39,982 iteration 1210 : loss : 0.048907, loss_ce: 0.014920
2021-12-11 19:54:41,575 iteration 1211 : loss : 0.077356, loss_ce: 0.028054
2021-12-11 19:54:43,087 iteration 1212 : loss : 0.038919, loss_ce: 0.016155
2021-12-11 19:54:44,662 iteration 1213 : loss : 0.076425, loss_ce: 0.020528
2021-12-11 19:54:46,255 iteration 1214 : loss : 0.049789, loss_ce: 0.021064
2021-12-11 19:54:47,813 iteration 1215 : loss : 0.054321, loss_ce: 0.023725
2021-12-11 19:54:49,353 iteration 1216 : loss : 0.044215, loss_ce: 0.018580
2021-12-11 19:54:50,965 iteration 1217 : loss : 0.049652, loss_ce: 0.022449
2021-12-11 19:54:52,418 iteration 1218 : loss : 0.047162, loss_ce: 0.022441
2021-12-11 19:54:54,016 iteration 1219 : loss : 0.060357, loss_ce: 0.022225
2021-12-11 19:54:55,555 iteration 1220 : loss : 0.068341, loss_ce: 0.027870
2021-12-11 19:54:57,237 iteration 1221 : loss : 0.064242, loss_ce: 0.025010
2021-12-11 19:54:58,845 iteration 1222 : loss : 0.054457, loss_ce: 0.019684
2021-12-11 19:55:00,390 iteration 1223 : loss : 0.041570, loss_ce: 0.017372
2021-12-11 19:55:01,988 iteration 1224 : loss : 0.052516, loss_ce: 0.021119
 18%|█████▍                        | 72/400 [34:46<2:36:15, 28.58s/it]2021-12-11 19:55:03,645 iteration 1225 : loss : 0.051130, loss_ce: 0.018055
2021-12-11 19:55:05,212 iteration 1226 : loss : 0.063017, loss_ce: 0.024273
2021-12-11 19:55:06,732 iteration 1227 : loss : 0.037105, loss_ce: 0.012469
2021-12-11 19:55:08,410 iteration 1228 : loss : 0.064663, loss_ce: 0.021258
2021-12-11 19:55:10,053 iteration 1229 : loss : 0.056862, loss_ce: 0.025108
2021-12-11 19:55:11,672 iteration 1230 : loss : 0.050787, loss_ce: 0.021904
2021-12-11 19:55:13,228 iteration 1231 : loss : 0.071889, loss_ce: 0.025349
2021-12-11 19:55:14,856 iteration 1232 : loss : 0.044197, loss_ce: 0.019181
2021-12-11 19:55:16,548 iteration 1233 : loss : 0.063394, loss_ce: 0.029617
2021-12-11 19:55:18,141 iteration 1234 : loss : 0.056388, loss_ce: 0.024410
2021-12-11 19:55:19,699 iteration 1235 : loss : 0.057319, loss_ce: 0.024744
2021-12-11 19:55:21,218 iteration 1236 : loss : 0.035565, loss_ce: 0.013231
2021-12-11 19:55:22,696 iteration 1237 : loss : 0.045806, loss_ce: 0.015284
2021-12-11 19:55:24,252 iteration 1238 : loss : 0.057030, loss_ce: 0.024176
2021-12-11 19:55:25,872 iteration 1239 : loss : 0.049353, loss_ce: 0.017619
2021-12-11 19:55:27,351 iteration 1240 : loss : 0.041596, loss_ce: 0.016754
2021-12-11 19:55:29,014 iteration 1241 : loss : 0.038698, loss_ce: 0.016637
 18%|█████▍                        | 73/400 [35:13<2:33:15, 28.12s/it]2021-12-11 19:55:30,562 iteration 1242 : loss : 0.043070, loss_ce: 0.017730
2021-12-11 19:55:32,049 iteration 1243 : loss : 0.033150, loss_ce: 0.015950
2021-12-11 19:55:33,553 iteration 1244 : loss : 0.048435, loss_ce: 0.018002
2021-12-11 19:55:35,099 iteration 1245 : loss : 0.044343, loss_ce: 0.017073
2021-12-11 19:55:36,671 iteration 1246 : loss : 0.056664, loss_ce: 0.025752
2021-12-11 19:55:38,273 iteration 1247 : loss : 0.043809, loss_ce: 0.013771
2021-12-11 19:55:39,791 iteration 1248 : loss : 0.038331, loss_ce: 0.013934
2021-12-11 19:55:41,399 iteration 1249 : loss : 0.045676, loss_ce: 0.016482
2021-12-11 19:55:42,923 iteration 1250 : loss : 0.049256, loss_ce: 0.019058
2021-12-11 19:55:44,505 iteration 1251 : loss : 0.045386, loss_ce: 0.018749
2021-12-11 19:55:46,080 iteration 1252 : loss : 0.088259, loss_ce: 0.024679
2021-12-11 19:55:47,663 iteration 1253 : loss : 0.056390, loss_ce: 0.023349
2021-12-11 19:55:49,197 iteration 1254 : loss : 0.059159, loss_ce: 0.027284
2021-12-11 19:55:50,799 iteration 1255 : loss : 0.039863, loss_ce: 0.016363
2021-12-11 19:55:52,429 iteration 1256 : loss : 0.049435, loss_ce: 0.017306
2021-12-11 19:55:53,995 iteration 1257 : loss : 0.036826, loss_ce: 0.016159
2021-12-11 19:55:55,641 iteration 1258 : loss : 0.053401, loss_ce: 0.026612
 18%|█████▌                        | 74/400 [35:40<2:30:20, 27.67s/it]2021-12-11 19:55:57,267 iteration 1259 : loss : 0.046829, loss_ce: 0.016040
2021-12-11 19:55:58,880 iteration 1260 : loss : 0.059809, loss_ce: 0.018538
2021-12-11 19:56:00,469 iteration 1261 : loss : 0.048674, loss_ce: 0.019795
2021-12-11 19:56:01,989 iteration 1262 : loss : 0.031751, loss_ce: 0.015516
2021-12-11 19:56:03,615 iteration 1263 : loss : 0.043105, loss_ce: 0.016026
2021-12-11 19:56:05,106 iteration 1264 : loss : 0.039638, loss_ce: 0.018506
2021-12-11 19:56:06,608 iteration 1265 : loss : 0.039948, loss_ce: 0.015878
2021-12-11 19:56:08,092 iteration 1266 : loss : 0.036842, loss_ce: 0.015883
2021-12-11 19:56:09,760 iteration 1267 : loss : 0.044715, loss_ce: 0.017138
2021-12-11 19:56:11,310 iteration 1268 : loss : 0.111316, loss_ce: 0.026971
2021-12-11 19:56:12,927 iteration 1269 : loss : 0.062069, loss_ce: 0.021605
2021-12-11 19:56:14,439 iteration 1270 : loss : 0.044983, loss_ce: 0.015047
2021-12-11 19:56:15,990 iteration 1271 : loss : 0.052685, loss_ce: 0.022853
2021-12-11 19:56:17,532 iteration 1272 : loss : 0.065558, loss_ce: 0.028452
2021-12-11 19:56:19,142 iteration 1273 : loss : 0.048815, loss_ce: 0.024025
2021-12-11 19:56:20,722 iteration 1274 : loss : 0.051936, loss_ce: 0.017671
2021-12-11 19:56:20,722 Training Data Eval:
2021-12-11 19:56:28,491   Average segmentation loss on training set: 0.0340
2021-12-11 19:56:28,491 Validation Data Eval:
2021-12-11 19:56:31,153   Average segmentation loss on validation set: 0.1330
2021-12-11 19:56:32,735 iteration 1275 : loss : 0.046602, loss_ce: 0.014818
 19%|█████▋                        | 75/400 [36:17<2:45:12, 30.50s/it]2021-12-11 19:56:34,464 iteration 1276 : loss : 0.075417, loss_ce: 0.021740
2021-12-11 19:56:35,982 iteration 1277 : loss : 0.037573, loss_ce: 0.014167
2021-12-11 19:56:37,580 iteration 1278 : loss : 0.046242, loss_ce: 0.019337
2021-12-11 19:56:39,031 iteration 1279 : loss : 0.041257, loss_ce: 0.020586
2021-12-11 19:56:40,487 iteration 1280 : loss : 0.050860, loss_ce: 0.025551
2021-12-11 19:56:42,107 iteration 1281 : loss : 0.049847, loss_ce: 0.022141
2021-12-11 19:56:43,615 iteration 1282 : loss : 0.068288, loss_ce: 0.038339
2021-12-11 19:56:45,145 iteration 1283 : loss : 0.044552, loss_ce: 0.018777
2021-12-11 19:56:46,701 iteration 1284 : loss : 0.042470, loss_ce: 0.020001
2021-12-11 19:56:48,440 iteration 1285 : loss : 0.054398, loss_ce: 0.018880
2021-12-11 19:56:50,052 iteration 1286 : loss : 0.049665, loss_ce: 0.017389
2021-12-11 19:56:51,591 iteration 1287 : loss : 0.049742, loss_ce: 0.017735
2021-12-11 19:56:53,181 iteration 1288 : loss : 0.068129, loss_ce: 0.027394
2021-12-11 19:56:54,839 iteration 1289 : loss : 0.043367, loss_ce: 0.015944
2021-12-11 19:56:56,365 iteration 1290 : loss : 0.072200, loss_ce: 0.021612
2021-12-11 19:56:57,933 iteration 1291 : loss : 0.044701, loss_ce: 0.017434
2021-12-11 19:56:59,433 iteration 1292 : loss : 0.035897, loss_ce: 0.014057
 19%|█████▋                        | 76/400 [36:44<2:38:31, 29.36s/it]2021-12-11 19:57:01,044 iteration 1293 : loss : 0.043582, loss_ce: 0.019876
2021-12-11 19:57:02,558 iteration 1294 : loss : 0.051854, loss_ce: 0.021857
2021-12-11 19:57:04,132 iteration 1295 : loss : 0.042450, loss_ce: 0.017129
2021-12-11 19:57:05,677 iteration 1296 : loss : 0.049417, loss_ce: 0.020205
2021-12-11 19:57:07,220 iteration 1297 : loss : 0.047413, loss_ce: 0.018717
2021-12-11 19:57:08,787 iteration 1298 : loss : 0.037149, loss_ce: 0.016003
2021-12-11 19:57:10,295 iteration 1299 : loss : 0.049613, loss_ce: 0.018571
2021-12-11 19:57:11,911 iteration 1300 : loss : 0.096852, loss_ce: 0.023292
2021-12-11 19:57:13,489 iteration 1301 : loss : 0.056877, loss_ce: 0.024921
2021-12-11 19:57:15,105 iteration 1302 : loss : 0.053959, loss_ce: 0.017949
2021-12-11 19:57:16,617 iteration 1303 : loss : 0.070761, loss_ce: 0.031813
2021-12-11 19:57:18,222 iteration 1304 : loss : 0.077385, loss_ce: 0.022322
2021-12-11 19:57:19,791 iteration 1305 : loss : 0.046585, loss_ce: 0.020285
2021-12-11 19:57:21,425 iteration 1306 : loss : 0.047282, loss_ce: 0.017388
2021-12-11 19:57:23,060 iteration 1307 : loss : 0.049968, loss_ce: 0.019019
2021-12-11 19:57:24,636 iteration 1308 : loss : 0.056231, loss_ce: 0.033317
2021-12-11 19:57:26,197 iteration 1309 : loss : 0.049213, loss_ce: 0.017565
 19%|█████▊                        | 77/400 [37:11<2:33:50, 28.58s/it]2021-12-11 19:57:27,829 iteration 1310 : loss : 0.065313, loss_ce: 0.026539
2021-12-11 19:57:29,475 iteration 1311 : loss : 0.054854, loss_ce: 0.021514
2021-12-11 19:57:31,024 iteration 1312 : loss : 0.055676, loss_ce: 0.027266
2021-12-11 19:57:32,512 iteration 1313 : loss : 0.038471, loss_ce: 0.016388
2021-12-11 19:57:34,081 iteration 1314 : loss : 0.040078, loss_ce: 0.017507
2021-12-11 19:57:35,658 iteration 1315 : loss : 0.051895, loss_ce: 0.018895
2021-12-11 19:57:37,185 iteration 1316 : loss : 0.040893, loss_ce: 0.017845
2021-12-11 19:57:38,791 iteration 1317 : loss : 0.048092, loss_ce: 0.024636
2021-12-11 19:57:40,396 iteration 1318 : loss : 0.061777, loss_ce: 0.024698
2021-12-11 19:57:41,931 iteration 1319 : loss : 0.054165, loss_ce: 0.018293
2021-12-11 19:57:43,483 iteration 1320 : loss : 0.044798, loss_ce: 0.015102
2021-12-11 19:57:45,052 iteration 1321 : loss : 0.067639, loss_ce: 0.023493
2021-12-11 19:57:46,724 iteration 1322 : loss : 0.057772, loss_ce: 0.022014
2021-12-11 19:57:48,325 iteration 1323 : loss : 0.034352, loss_ce: 0.013733
2021-12-11 19:57:49,921 iteration 1324 : loss : 0.053179, loss_ce: 0.017672
2021-12-11 19:57:51,544 iteration 1325 : loss : 0.048182, loss_ce: 0.016002
2021-12-11 19:57:53,048 iteration 1326 : loss : 0.055458, loss_ce: 0.019823
 20%|█████▊                        | 78/400 [37:37<2:30:36, 28.06s/it]2021-12-11 19:57:54,692 iteration 1327 : loss : 0.055844, loss_ce: 0.028079
2021-12-11 19:57:56,367 iteration 1328 : loss : 0.075761, loss_ce: 0.023607
2021-12-11 19:57:57,856 iteration 1329 : loss : 0.062764, loss_ce: 0.030570
2021-12-11 19:57:59,420 iteration 1330 : loss : 0.052378, loss_ce: 0.019328
2021-12-11 19:58:00,980 iteration 1331 : loss : 0.039930, loss_ce: 0.013675
2021-12-11 19:58:02,532 iteration 1332 : loss : 0.033487, loss_ce: 0.013679
2021-12-11 19:58:04,132 iteration 1333 : loss : 0.078388, loss_ce: 0.019242
2021-12-11 19:58:05,684 iteration 1334 : loss : 0.038942, loss_ce: 0.015595
2021-12-11 19:58:07,366 iteration 1335 : loss : 0.050046, loss_ce: 0.017319
2021-12-11 19:58:08,976 iteration 1336 : loss : 0.064965, loss_ce: 0.027993
2021-12-11 19:58:10,606 iteration 1337 : loss : 0.051793, loss_ce: 0.023168
2021-12-11 19:58:12,243 iteration 1338 : loss : 0.067776, loss_ce: 0.027572
2021-12-11 19:58:13,859 iteration 1339 : loss : 0.058103, loss_ce: 0.023765
2021-12-11 19:58:15,371 iteration 1340 : loss : 0.036948, loss_ce: 0.012610
2021-12-11 19:58:16,925 iteration 1341 : loss : 0.051752, loss_ce: 0.022195
2021-12-11 19:58:18,478 iteration 1342 : loss : 0.053021, loss_ce: 0.019017
2021-12-11 19:58:20,050 iteration 1343 : loss : 0.046457, loss_ce: 0.016698
 20%|█████▉                        | 79/400 [38:04<2:28:25, 27.74s/it]2021-12-11 19:58:21,635 iteration 1344 : loss : 0.038136, loss_ce: 0.013872
2021-12-11 19:58:23,162 iteration 1345 : loss : 0.045023, loss_ce: 0.020093
2021-12-11 19:58:24,672 iteration 1346 : loss : 0.044068, loss_ce: 0.015390
2021-12-11 19:58:26,315 iteration 1347 : loss : 0.080829, loss_ce: 0.018639
2021-12-11 19:58:27,955 iteration 1348 : loss : 0.042995, loss_ce: 0.016843
2021-12-11 19:58:29,554 iteration 1349 : loss : 0.064637, loss_ce: 0.029491
2021-12-11 19:58:31,161 iteration 1350 : loss : 0.075751, loss_ce: 0.032922
2021-12-11 19:58:32,674 iteration 1351 : loss : 0.053778, loss_ce: 0.017168
2021-12-11 19:58:34,329 iteration 1352 : loss : 0.046933, loss_ce: 0.018269
2021-12-11 19:58:35,825 iteration 1353 : loss : 0.045742, loss_ce: 0.019391
2021-12-11 19:58:37,411 iteration 1354 : loss : 0.037162, loss_ce: 0.015672
2021-12-11 19:58:38,907 iteration 1355 : loss : 0.083858, loss_ce: 0.025905
2021-12-11 19:58:40,514 iteration 1356 : loss : 0.066683, loss_ce: 0.023130
2021-12-11 19:58:42,019 iteration 1357 : loss : 0.050722, loss_ce: 0.029098
2021-12-11 19:58:43,573 iteration 1358 : loss : 0.057214, loss_ce: 0.018714
2021-12-11 19:58:45,068 iteration 1359 : loss : 0.047946, loss_ce: 0.024950
2021-12-11 19:58:45,068 Training Data Eval:
2021-12-11 19:58:52,829   Average segmentation loss on training set: 0.1002
2021-12-11 19:58:52,829 Validation Data Eval:
2021-12-11 19:58:55,481   Average segmentation loss on validation set: 0.1452
2021-12-11 19:58:57,021 iteration 1360 : loss : 0.061116, loss_ce: 0.021968
 20%|██████                        | 80/400 [38:41<2:42:43, 30.51s/it]2021-12-11 19:58:58,681 iteration 1361 : loss : 0.101423, loss_ce: 0.035861
2021-12-11 19:59:00,262 iteration 1362 : loss : 0.040364, loss_ce: 0.018253
2021-12-11 19:59:01,888 iteration 1363 : loss : 0.037189, loss_ce: 0.013786
2021-12-11 19:59:03,518 iteration 1364 : loss : 0.070331, loss_ce: 0.020846
2021-12-11 19:59:05,194 iteration 1365 : loss : 0.064419, loss_ce: 0.027399
2021-12-11 19:59:06,770 iteration 1366 : loss : 0.059497, loss_ce: 0.027277
2021-12-11 19:59:08,291 iteration 1367 : loss : 0.039568, loss_ce: 0.017948
2021-12-11 19:59:09,875 iteration 1368 : loss : 0.062981, loss_ce: 0.027631
2021-12-11 19:59:11,415 iteration 1369 : loss : 0.064324, loss_ce: 0.019528
2021-12-11 19:59:12,984 iteration 1370 : loss : 0.048940, loss_ce: 0.015790
2021-12-11 19:59:14,478 iteration 1371 : loss : 0.041378, loss_ce: 0.017089
2021-12-11 19:59:16,073 iteration 1372 : loss : 0.076057, loss_ce: 0.024589
2021-12-11 19:59:17,755 iteration 1373 : loss : 0.056071, loss_ce: 0.028652
2021-12-11 19:59:19,324 iteration 1374 : loss : 0.050156, loss_ce: 0.015824
2021-12-11 19:59:20,968 iteration 1375 : loss : 0.053583, loss_ce: 0.017432
2021-12-11 19:59:22,446 iteration 1376 : loss : 0.034901, loss_ce: 0.014163
2021-12-11 19:59:24,055 iteration 1377 : loss : 0.064908, loss_ce: 0.025626
 20%|██████                        | 81/400 [39:08<2:36:40, 29.47s/it]2021-12-11 19:59:25,764 iteration 1378 : loss : 0.044948, loss_ce: 0.021775
2021-12-11 19:59:27,402 iteration 1379 : loss : 0.073295, loss_ce: 0.022188
2021-12-11 19:59:28,977 iteration 1380 : loss : 0.046494, loss_ce: 0.021060
2021-12-11 19:59:30,563 iteration 1381 : loss : 0.041181, loss_ce: 0.017142
2021-12-11 19:59:32,118 iteration 1382 : loss : 0.048818, loss_ce: 0.018568
2021-12-11 19:59:33,682 iteration 1383 : loss : 0.060716, loss_ce: 0.015626
2021-12-11 19:59:35,346 iteration 1384 : loss : 0.066729, loss_ce: 0.028033
2021-12-11 19:59:36,835 iteration 1385 : loss : 0.030855, loss_ce: 0.012158
2021-12-11 19:59:38,511 iteration 1386 : loss : 0.051497, loss_ce: 0.022513
2021-12-11 19:59:40,054 iteration 1387 : loss : 0.079048, loss_ce: 0.025074
2021-12-11 19:59:41,680 iteration 1388 : loss : 0.072358, loss_ce: 0.021048
2021-12-11 19:59:43,290 iteration 1389 : loss : 0.074210, loss_ce: 0.036402
2021-12-11 19:59:44,789 iteration 1390 : loss : 0.057679, loss_ce: 0.023926
2021-12-11 19:59:46,373 iteration 1391 : loss : 0.056042, loss_ce: 0.016480
2021-12-11 19:59:47,932 iteration 1392 : loss : 0.085402, loss_ce: 0.050026
2021-12-11 19:59:49,517 iteration 1393 : loss : 0.104707, loss_ce: 0.033700
2021-12-11 19:59:51,095 iteration 1394 : loss : 0.060259, loss_ce: 0.020109
 20%|██████▏                       | 82/400 [39:35<2:32:18, 28.74s/it]2021-12-11 19:59:52,791 iteration 1395 : loss : 0.059841, loss_ce: 0.027876
2021-12-11 19:59:54,288 iteration 1396 : loss : 0.055664, loss_ce: 0.024925
2021-12-11 19:59:55,917 iteration 1397 : loss : 0.055795, loss_ce: 0.024005
2021-12-11 19:59:57,399 iteration 1398 : loss : 0.043651, loss_ce: 0.017869
2021-12-11 19:59:58,999 iteration 1399 : loss : 0.045897, loss_ce: 0.020707
2021-12-11 20:00:00,656 iteration 1400 : loss : 0.072352, loss_ce: 0.026647
2021-12-11 20:00:02,196 iteration 1401 : loss : 0.041394, loss_ce: 0.014471
2021-12-11 20:00:03,862 iteration 1402 : loss : 0.062410, loss_ce: 0.024231
2021-12-11 20:00:05,458 iteration 1403 : loss : 0.063496, loss_ce: 0.020227
2021-12-11 20:00:07,131 iteration 1404 : loss : 0.061542, loss_ce: 0.023147
2021-12-11 20:00:08,536 iteration 1405 : loss : 0.040688, loss_ce: 0.015009
2021-12-11 20:00:10,148 iteration 1406 : loss : 0.047552, loss_ce: 0.017978
2021-12-11 20:00:11,694 iteration 1407 : loss : 0.045915, loss_ce: 0.018270
2021-12-11 20:00:13,205 iteration 1408 : loss : 0.061066, loss_ce: 0.031702
2021-12-11 20:00:14,872 iteration 1409 : loss : 0.072432, loss_ce: 0.021204
2021-12-11 20:00:16,397 iteration 1410 : loss : 0.062650, loss_ce: 0.025434
2021-12-11 20:00:17,886 iteration 1411 : loss : 0.033743, loss_ce: 0.013565
 21%|██████▏                       | 83/400 [40:02<2:28:44, 28.15s/it]2021-12-11 20:00:19,543 iteration 1412 : loss : 0.045743, loss_ce: 0.021924
2021-12-11 20:00:21,040 iteration 1413 : loss : 0.034192, loss_ce: 0.011452
2021-12-11 20:00:22,649 iteration 1414 : loss : 0.044670, loss_ce: 0.018189
2021-12-11 20:00:24,154 iteration 1415 : loss : 0.045072, loss_ce: 0.017027
2021-12-11 20:00:25,717 iteration 1416 : loss : 0.042477, loss_ce: 0.017174
2021-12-11 20:00:27,315 iteration 1417 : loss : 0.061373, loss_ce: 0.023295
2021-12-11 20:00:28,905 iteration 1418 : loss : 0.035653, loss_ce: 0.012047
2021-12-11 20:00:30,389 iteration 1419 : loss : 0.041120, loss_ce: 0.017001
2021-12-11 20:00:31,926 iteration 1420 : loss : 0.050948, loss_ce: 0.015359
2021-12-11 20:00:33,481 iteration 1421 : loss : 0.066356, loss_ce: 0.038577
2021-12-11 20:00:35,040 iteration 1422 : loss : 0.049261, loss_ce: 0.020352
2021-12-11 20:00:36,556 iteration 1423 : loss : 0.048819, loss_ce: 0.015845
2021-12-11 20:00:38,025 iteration 1424 : loss : 0.028907, loss_ce: 0.011595
2021-12-11 20:00:39,608 iteration 1425 : loss : 0.072311, loss_ce: 0.019088
2021-12-11 20:00:41,193 iteration 1426 : loss : 0.051411, loss_ce: 0.026104
2021-12-11 20:00:42,758 iteration 1427 : loss : 0.083053, loss_ce: 0.017232
2021-12-11 20:00:44,442 iteration 1428 : loss : 0.072468, loss_ce: 0.027804
 21%|██████▎                       | 84/400 [40:29<2:25:46, 27.68s/it]2021-12-11 20:00:46,099 iteration 1429 : loss : 0.071178, loss_ce: 0.041819
2021-12-11 20:00:47,644 iteration 1430 : loss : 0.040742, loss_ce: 0.015831
2021-12-11 20:00:49,148 iteration 1431 : loss : 0.060259, loss_ce: 0.020294
2021-12-11 20:00:50,710 iteration 1432 : loss : 0.052903, loss_ce: 0.023909
2021-12-11 20:00:52,196 iteration 1433 : loss : 0.040172, loss_ce: 0.018403
2021-12-11 20:00:53,856 iteration 1434 : loss : 0.051953, loss_ce: 0.020070
2021-12-11 20:00:55,470 iteration 1435 : loss : 0.050384, loss_ce: 0.016983
2021-12-11 20:00:57,107 iteration 1436 : loss : 0.051887, loss_ce: 0.023852
2021-12-11 20:00:58,671 iteration 1437 : loss : 0.046734, loss_ce: 0.019820
2021-12-11 20:01:00,223 iteration 1438 : loss : 0.042883, loss_ce: 0.018751
2021-12-11 20:01:01,802 iteration 1439 : loss : 0.069794, loss_ce: 0.024628
2021-12-11 20:01:03,308 iteration 1440 : loss : 0.046487, loss_ce: 0.016668
2021-12-11 20:01:04,884 iteration 1441 : loss : 0.048085, loss_ce: 0.019958
2021-12-11 20:01:06,438 iteration 1442 : loss : 0.055275, loss_ce: 0.017573
2021-12-11 20:01:08,065 iteration 1443 : loss : 0.059783, loss_ce: 0.019928
2021-12-11 20:01:09,624 iteration 1444 : loss : 0.048226, loss_ce: 0.012642
2021-12-11 20:01:09,624 Training Data Eval:
2021-12-11 20:01:17,395   Average segmentation loss on training set: 0.0375
2021-12-11 20:01:17,395 Validation Data Eval:
2021-12-11 20:01:20,056   Average segmentation loss on validation set: 0.0929
2021-12-11 20:01:22,004 Found new lowest validation loss at iteration 1444! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/NEW_TU/UNET_ADAM_best_val_loss_seed2.pth
2021-12-11 20:01:23,642 iteration 1445 : loss : 0.048068, loss_ce: 0.022265
 21%|██████▍                       | 85/400 [41:08<2:43:27, 31.13s/it]2021-12-11 20:01:25,184 iteration 1446 : loss : 0.045170, loss_ce: 0.015507
2021-12-11 20:01:26,648 iteration 1447 : loss : 0.038144, loss_ce: 0.018958
2021-12-11 20:01:28,266 iteration 1448 : loss : 0.039805, loss_ce: 0.010774
2021-12-11 20:01:29,884 iteration 1449 : loss : 0.057825, loss_ce: 0.021177
2021-12-11 20:01:31,431 iteration 1450 : loss : 0.044890, loss_ce: 0.018121
2021-12-11 20:01:33,022 iteration 1451 : loss : 0.037430, loss_ce: 0.010565
2021-12-11 20:01:34,577 iteration 1452 : loss : 0.058181, loss_ce: 0.037951
2021-12-11 20:01:36,172 iteration 1453 : loss : 0.044970, loss_ce: 0.019383
2021-12-11 20:01:37,746 iteration 1454 : loss : 0.043932, loss_ce: 0.013589
2021-12-11 20:01:39,335 iteration 1455 : loss : 0.039624, loss_ce: 0.014343
2021-12-11 20:01:40,857 iteration 1456 : loss : 0.040040, loss_ce: 0.012868
2021-12-11 20:01:42,475 iteration 1457 : loss : 0.051174, loss_ce: 0.022341
2021-12-11 20:01:44,072 iteration 1458 : loss : 0.043561, loss_ce: 0.018055
2021-12-11 20:01:45,605 iteration 1459 : loss : 0.035574, loss_ce: 0.012554
2021-12-11 20:01:47,159 iteration 1460 : loss : 0.041872, loss_ce: 0.016797
2021-12-11 20:01:48,658 iteration 1461 : loss : 0.049538, loss_ce: 0.016961
2021-12-11 20:01:50,294 iteration 1462 : loss : 0.055615, loss_ce: 0.021094
 22%|██████▍                       | 86/400 [41:35<2:35:53, 29.79s/it]2021-12-11 20:01:52,056 iteration 1463 : loss : 0.069091, loss_ce: 0.021323
2021-12-11 20:01:53,578 iteration 1464 : loss : 0.048620, loss_ce: 0.022643
2021-12-11 20:01:55,291 iteration 1465 : loss : 0.051902, loss_ce: 0.018771
2021-12-11 20:01:56,866 iteration 1466 : loss : 0.047488, loss_ce: 0.017803
2021-12-11 20:01:58,393 iteration 1467 : loss : 0.059753, loss_ce: 0.025708
2021-12-11 20:01:59,975 iteration 1468 : loss : 0.053688, loss_ce: 0.026048
2021-12-11 20:02:01,527 iteration 1469 : loss : 0.065950, loss_ce: 0.026985
2021-12-11 20:02:03,036 iteration 1470 : loss : 0.082408, loss_ce: 0.018708
2021-12-11 20:02:04,607 iteration 1471 : loss : 0.042420, loss_ce: 0.021071
2021-12-11 20:02:06,198 iteration 1472 : loss : 0.043090, loss_ce: 0.016470
2021-12-11 20:02:07,718 iteration 1473 : loss : 0.036030, loss_ce: 0.017920
2021-12-11 20:02:09,325 iteration 1474 : loss : 0.066901, loss_ce: 0.021689
2021-12-11 20:02:10,849 iteration 1475 : loss : 0.038702, loss_ce: 0.016034
2021-12-11 20:02:12,384 iteration 1476 : loss : 0.037124, loss_ce: 0.014327
2021-12-11 20:02:14,037 iteration 1477 : loss : 0.042769, loss_ce: 0.018849
2021-12-11 20:02:15,554 iteration 1478 : loss : 0.052046, loss_ce: 0.017186
2021-12-11 20:02:17,122 iteration 1479 : loss : 0.068528, loss_ce: 0.019441
 22%|██████▌                       | 87/400 [42:01<2:30:46, 28.90s/it]2021-12-11 20:02:18,609 iteration 1480 : loss : 0.031405, loss_ce: 0.011082
2021-12-11 20:02:20,277 iteration 1481 : loss : 0.048598, loss_ce: 0.022263
2021-12-11 20:02:21,844 iteration 1482 : loss : 0.042720, loss_ce: 0.017166
2021-12-11 20:02:23,484 iteration 1483 : loss : 0.053345, loss_ce: 0.021196
2021-12-11 20:02:25,086 iteration 1484 : loss : 0.042056, loss_ce: 0.013198
2021-12-11 20:02:26,705 iteration 1485 : loss : 0.034822, loss_ce: 0.016783
2021-12-11 20:02:28,262 iteration 1486 : loss : 0.042073, loss_ce: 0.013772
2021-12-11 20:02:29,817 iteration 1487 : loss : 0.030275, loss_ce: 0.011433
2021-12-11 20:02:31,315 iteration 1488 : loss : 0.033564, loss_ce: 0.015067
2021-12-11 20:02:32,844 iteration 1489 : loss : 0.055703, loss_ce: 0.024853
2021-12-11 20:02:34,434 iteration 1490 : loss : 0.047092, loss_ce: 0.017611
2021-12-11 20:02:35,892 iteration 1491 : loss : 0.051476, loss_ce: 0.015826
2021-12-11 20:02:37,382 iteration 1492 : loss : 0.050095, loss_ce: 0.021567
2021-12-11 20:02:38,970 iteration 1493 : loss : 0.042752, loss_ce: 0.017412
2021-12-11 20:02:40,517 iteration 1494 : loss : 0.042526, loss_ce: 0.013594
2021-12-11 20:02:42,000 iteration 1495 : loss : 0.037992, loss_ce: 0.010379
2021-12-11 20:02:43,608 iteration 1496 : loss : 0.046540, loss_ce: 0.018692
 22%|██████▌                       | 88/400 [42:28<2:26:30, 28.18s/it]2021-12-11 20:02:45,140 iteration 1497 : loss : 0.032997, loss_ce: 0.012947
2021-12-11 20:02:46,746 iteration 1498 : loss : 0.055896, loss_ce: 0.019640
2021-12-11 20:02:48,238 iteration 1499 : loss : 0.046410, loss_ce: 0.016774
2021-12-11 20:02:49,810 iteration 1500 : loss : 0.050267, loss_ce: 0.021821
2021-12-11 20:02:51,350 iteration 1501 : loss : 0.049266, loss_ce: 0.023198
2021-12-11 20:02:52,998 iteration 1502 : loss : 0.059515, loss_ce: 0.015053
2021-12-11 20:02:54,708 iteration 1503 : loss : 0.102250, loss_ce: 0.029678
2021-12-11 20:02:56,256 iteration 1504 : loss : 0.034849, loss_ce: 0.014968
2021-12-11 20:02:57,863 iteration 1505 : loss : 0.046199, loss_ce: 0.020646
2021-12-11 20:02:59,459 iteration 1506 : loss : 0.041414, loss_ce: 0.017323
2021-12-11 20:03:01,059 iteration 1507 : loss : 0.048520, loss_ce: 0.014325
2021-12-11 20:03:02,655 iteration 1508 : loss : 0.052915, loss_ce: 0.026067
2021-12-11 20:03:04,219 iteration 1509 : loss : 0.045598, loss_ce: 0.018864
2021-12-11 20:03:05,875 iteration 1510 : loss : 0.065755, loss_ce: 0.023108
2021-12-11 20:03:07,518 iteration 1511 : loss : 0.052058, loss_ce: 0.022685
2021-12-11 20:03:09,096 iteration 1512 : loss : 0.048339, loss_ce: 0.014175
2021-12-11 20:03:10,677 iteration 1513 : loss : 0.047030, loss_ce: 0.017498
 22%|██████▋                       | 89/400 [42:55<2:24:19, 27.84s/it]2021-12-11 20:03:12,350 iteration 1514 : loss : 0.047938, loss_ce: 0.017184
2021-12-11 20:03:13,871 iteration 1515 : loss : 0.035643, loss_ce: 0.014503
2021-12-11 20:03:15,440 iteration 1516 : loss : 0.071658, loss_ce: 0.028793
2021-12-11 20:03:16,924 iteration 1517 : loss : 0.039593, loss_ce: 0.015865
2021-12-11 20:03:18,529 iteration 1518 : loss : 0.034618, loss_ce: 0.012457
2021-12-11 20:03:20,171 iteration 1519 : loss : 0.036987, loss_ce: 0.013624
2021-12-11 20:03:21,794 iteration 1520 : loss : 0.048082, loss_ce: 0.019808
2021-12-11 20:03:23,375 iteration 1521 : loss : 0.049271, loss_ce: 0.013113
2021-12-11 20:03:24,902 iteration 1522 : loss : 0.043854, loss_ce: 0.017614
2021-12-11 20:03:26,434 iteration 1523 : loss : 0.051147, loss_ce: 0.017487
2021-12-11 20:03:28,013 iteration 1524 : loss : 0.038623, loss_ce: 0.016098
2021-12-11 20:03:29,503 iteration 1525 : loss : 0.060109, loss_ce: 0.024033
2021-12-11 20:03:31,098 iteration 1526 : loss : 0.057462, loss_ce: 0.027174
2021-12-11 20:03:32,705 iteration 1527 : loss : 0.040420, loss_ce: 0.018935
2021-12-11 20:03:34,229 iteration 1528 : loss : 0.036104, loss_ce: 0.015158
2021-12-11 20:03:35,736 iteration 1529 : loss : 0.044052, loss_ce: 0.016725
2021-12-11 20:03:35,736 Training Data Eval:
2021-12-11 20:03:43,498   Average segmentation loss on training set: 0.0623
2021-12-11 20:03:43,499 Validation Data Eval:
2021-12-11 20:03:46,168   Average segmentation loss on validation set: 0.0986
2021-12-11 20:03:47,761 iteration 1530 : loss : 0.046066, loss_ce: 0.020581
 22%|██████▊                       | 90/400 [43:32<2:38:11, 30.62s/it]2021-12-11 20:03:49,400 iteration 1531 : loss : 0.058940, loss_ce: 0.022337
2021-12-11 20:03:50,965 iteration 1532 : loss : 0.041330, loss_ce: 0.017190
2021-12-11 20:03:52,465 iteration 1533 : loss : 0.037883, loss_ce: 0.013936
2021-12-11 20:03:54,004 iteration 1534 : loss : 0.041447, loss_ce: 0.019739
2021-12-11 20:03:55,627 iteration 1535 : loss : 0.042437, loss_ce: 0.016792
2021-12-11 20:03:57,251 iteration 1536 : loss : 0.056090, loss_ce: 0.029133
2021-12-11 20:03:58,806 iteration 1537 : loss : 0.054790, loss_ce: 0.016589
2021-12-11 20:04:00,414 iteration 1538 : loss : 0.032448, loss_ce: 0.013791
2021-12-11 20:04:01,981 iteration 1539 : loss : 0.036672, loss_ce: 0.016617
2021-12-11 20:04:03,533 iteration 1540 : loss : 0.043086, loss_ce: 0.017546
2021-12-11 20:04:05,063 iteration 1541 : loss : 0.031530, loss_ce: 0.013832
2021-12-11 20:04:06,567 iteration 1542 : loss : 0.033833, loss_ce: 0.014171
2021-12-11 20:04:08,109 iteration 1543 : loss : 0.069525, loss_ce: 0.023097
2021-12-11 20:04:09,589 iteration 1544 : loss : 0.035265, loss_ce: 0.013623
2021-12-11 20:04:11,269 iteration 1545 : loss : 0.058840, loss_ce: 0.023809
2021-12-11 20:04:12,784 iteration 1546 : loss : 0.061330, loss_ce: 0.014467
2021-12-11 20:04:14,434 iteration 1547 : loss : 0.038493, loss_ce: 0.015785
 23%|██████▊                       | 91/400 [43:59<2:31:34, 29.43s/it]2021-12-11 20:04:16,077 iteration 1548 : loss : 0.060788, loss_ce: 0.032455
2021-12-11 20:04:17,538 iteration 1549 : loss : 0.038832, loss_ce: 0.016854
2021-12-11 20:04:19,053 iteration 1550 : loss : 0.043910, loss_ce: 0.019870
2021-12-11 20:04:20,490 iteration 1551 : loss : 0.033331, loss_ce: 0.012014
2021-12-11 20:04:22,068 iteration 1552 : loss : 0.039813, loss_ce: 0.012888
2021-12-11 20:04:23,713 iteration 1553 : loss : 0.052105, loss_ce: 0.019986
2021-12-11 20:04:25,297 iteration 1554 : loss : 0.038548, loss_ce: 0.015179
2021-12-11 20:04:26,835 iteration 1555 : loss : 0.041378, loss_ce: 0.018101
2021-12-11 20:04:28,426 iteration 1556 : loss : 0.040007, loss_ce: 0.014981
2021-12-11 20:04:29,950 iteration 1557 : loss : 0.049534, loss_ce: 0.019665
2021-12-11 20:04:31,503 iteration 1558 : loss : 0.038601, loss_ce: 0.019801
2021-12-11 20:04:33,077 iteration 1559 : loss : 0.045521, loss_ce: 0.016618
2021-12-11 20:04:34,577 iteration 1560 : loss : 0.034645, loss_ce: 0.015953
2021-12-11 20:04:36,164 iteration 1561 : loss : 0.039473, loss_ce: 0.012117
2021-12-11 20:04:37,674 iteration 1562 : loss : 0.047463, loss_ce: 0.012291
2021-12-11 20:04:39,284 iteration 1563 : loss : 0.037971, loss_ce: 0.017597
2021-12-11 20:04:40,917 iteration 1564 : loss : 0.042560, loss_ce: 0.017449
 23%|██████▉                       | 92/400 [44:25<2:26:32, 28.55s/it]2021-12-11 20:04:42,501 iteration 1565 : loss : 0.043114, loss_ce: 0.019726
2021-12-11 20:04:44,060 iteration 1566 : loss : 0.038956, loss_ce: 0.014099
2021-12-11 20:04:45,679 iteration 1567 : loss : 0.048780, loss_ce: 0.016005
2021-12-11 20:04:47,207 iteration 1568 : loss : 0.063929, loss_ce: 0.017717
2021-12-11 20:04:48,787 iteration 1569 : loss : 0.052500, loss_ce: 0.023874
2021-12-11 20:04:50,356 iteration 1570 : loss : 0.033352, loss_ce: 0.015063
2021-12-11 20:04:51,876 iteration 1571 : loss : 0.073736, loss_ce: 0.016001
2021-12-11 20:04:53,513 iteration 1572 : loss : 0.052191, loss_ce: 0.016476
2021-12-11 20:04:55,100 iteration 1573 : loss : 0.057350, loss_ce: 0.024575
2021-12-11 20:04:56,611 iteration 1574 : loss : 0.036379, loss_ce: 0.016777
2021-12-11 20:04:58,064 iteration 1575 : loss : 0.043259, loss_ce: 0.018191
2021-12-11 20:04:59,597 iteration 1576 : loss : 0.040871, loss_ce: 0.018312
2021-12-11 20:05:01,139 iteration 1577 : loss : 0.028629, loss_ce: 0.010890
2021-12-11 20:05:02,698 iteration 1578 : loss : 0.061015, loss_ce: 0.021609
2021-12-11 20:05:04,288 iteration 1579 : loss : 0.027143, loss_ce: 0.010779
2021-12-11 20:05:05,796 iteration 1580 : loss : 0.051072, loss_ce: 0.022243
2021-12-11 20:05:07,342 iteration 1581 : loss : 0.043115, loss_ce: 0.015159
 23%|██████▉                       | 93/400 [44:52<2:22:48, 27.91s/it]2021-12-11 20:05:09,033 iteration 1582 : loss : 0.067140, loss_ce: 0.023363
2021-12-11 20:05:10,578 iteration 1583 : loss : 0.060740, loss_ce: 0.016247
2021-12-11 20:05:12,157 iteration 1584 : loss : 0.029142, loss_ce: 0.015510
2021-12-11 20:05:13,710 iteration 1585 : loss : 0.036676, loss_ce: 0.012272
2021-12-11 20:05:15,254 iteration 1586 : loss : 0.044614, loss_ce: 0.017740
2021-12-11 20:05:16,696 iteration 1587 : loss : 0.034612, loss_ce: 0.014463
2021-12-11 20:05:18,282 iteration 1588 : loss : 0.043273, loss_ce: 0.019131
2021-12-11 20:05:19,832 iteration 1589 : loss : 0.032913, loss_ce: 0.014321
2021-12-11 20:05:21,532 iteration 1590 : loss : 0.048692, loss_ce: 0.018699
2021-12-11 20:05:23,040 iteration 1591 : loss : 0.029803, loss_ce: 0.010432
2021-12-11 20:05:24,591 iteration 1592 : loss : 0.053226, loss_ce: 0.019322
2021-12-11 20:05:26,253 iteration 1593 : loss : 0.050309, loss_ce: 0.020890
2021-12-11 20:05:27,903 iteration 1594 : loss : 0.048686, loss_ce: 0.017019
2021-12-11 20:05:29,461 iteration 1595 : loss : 0.031240, loss_ce: 0.011740
2021-12-11 20:05:31,030 iteration 1596 : loss : 0.039505, loss_ce: 0.018671
2021-12-11 20:05:32,576 iteration 1597 : loss : 0.048597, loss_ce: 0.020500
2021-12-11 20:05:34,164 iteration 1598 : loss : 0.042118, loss_ce: 0.015139
 24%|███████                       | 94/400 [45:19<2:20:41, 27.59s/it]2021-12-11 20:05:35,755 iteration 1599 : loss : 0.030861, loss_ce: 0.012378
2021-12-11 20:05:37,317 iteration 1600 : loss : 0.037523, loss_ce: 0.013163
2021-12-11 20:05:38,955 iteration 1601 : loss : 0.038781, loss_ce: 0.016011
2021-12-11 20:05:40,661 iteration 1602 : loss : 0.059569, loss_ce: 0.022142
2021-12-11 20:05:42,218 iteration 1603 : loss : 0.045474, loss_ce: 0.019328
2021-12-11 20:05:43,745 iteration 1604 : loss : 0.044638, loss_ce: 0.018289
2021-12-11 20:05:45,355 iteration 1605 : loss : 0.043406, loss_ce: 0.014960
2021-12-11 20:05:46,908 iteration 1606 : loss : 0.053058, loss_ce: 0.030023
2021-12-11 20:05:48,441 iteration 1607 : loss : 0.032071, loss_ce: 0.012038
2021-12-11 20:05:50,097 iteration 1608 : loss : 0.036911, loss_ce: 0.012447
2021-12-11 20:05:51,663 iteration 1609 : loss : 0.055682, loss_ce: 0.025535
2021-12-11 20:05:53,250 iteration 1610 : loss : 0.036779, loss_ce: 0.014497
2021-12-11 20:05:54,926 iteration 1611 : loss : 0.074655, loss_ce: 0.024432
2021-12-11 20:05:56,498 iteration 1612 : loss : 0.032771, loss_ce: 0.014923
2021-12-11 20:05:57,918 iteration 1613 : loss : 0.050687, loss_ce: 0.023646
2021-12-11 20:05:59,520 iteration 1614 : loss : 0.058960, loss_ce: 0.020848
2021-12-11 20:05:59,520 Training Data Eval:
2021-12-11 20:06:07,283   Average segmentation loss on training set: 0.0268
2021-12-11 20:06:07,284 Validation Data Eval:
2021-12-11 20:06:09,944   Average segmentation loss on validation set: 0.0888
2021-12-11 20:06:11,846 Found new lowest validation loss at iteration 1614! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/NEW_TU/UNET_ADAM_best_val_loss_seed2.pth
2021-12-11 20:06:13,448 iteration 1615 : loss : 0.035207, loss_ce: 0.013557
 24%|███████▏                      | 95/400 [45:58<2:38:03, 31.09s/it]2021-12-11 20:06:15,122 iteration 1616 : loss : 0.041440, loss_ce: 0.014521
2021-12-11 20:06:16,712 iteration 1617 : loss : 0.052295, loss_ce: 0.015080
2021-12-11 20:06:18,197 iteration 1618 : loss : 0.029059, loss_ce: 0.012593
2021-12-11 20:06:19,685 iteration 1619 : loss : 0.032361, loss_ce: 0.010451
2021-12-11 20:06:21,148 iteration 1620 : loss : 0.045826, loss_ce: 0.013640
2021-12-11 20:06:22,724 iteration 1621 : loss : 0.054546, loss_ce: 0.031138
2021-12-11 20:06:24,441 iteration 1622 : loss : 0.055340, loss_ce: 0.015411
2021-12-11 20:06:26,006 iteration 1623 : loss : 0.069304, loss_ce: 0.033810
2021-12-11 20:06:27,527 iteration 1624 : loss : 0.038955, loss_ce: 0.014536
2021-12-11 20:06:29,067 iteration 1625 : loss : 0.034790, loss_ce: 0.013842
2021-12-11 20:06:30,604 iteration 1626 : loss : 0.032858, loss_ce: 0.014537
2021-12-11 20:06:32,147 iteration 1627 : loss : 0.054562, loss_ce: 0.018299
2021-12-11 20:06:33,803 iteration 1628 : loss : 0.053152, loss_ce: 0.022474
2021-12-11 20:06:35,362 iteration 1629 : loss : 0.032037, loss_ce: 0.012164
2021-12-11 20:06:36,862 iteration 1630 : loss : 0.046634, loss_ce: 0.016734
2021-12-11 20:06:38,568 iteration 1631 : loss : 0.070280, loss_ce: 0.028765
2021-12-11 20:06:40,219 iteration 1632 : loss : 0.054862, loss_ce: 0.020590
 24%|███████▏                      | 96/400 [46:25<2:30:57, 29.79s/it]2021-12-11 20:06:41,904 iteration 1633 : loss : 0.040878, loss_ce: 0.016222
2021-12-11 20:06:43,503 iteration 1634 : loss : 0.052885, loss_ce: 0.017585
2021-12-11 20:06:45,074 iteration 1635 : loss : 0.036072, loss_ce: 0.017460
2021-12-11 20:06:46,730 iteration 1636 : loss : 0.042165, loss_ce: 0.019364
2021-12-11 20:06:48,313 iteration 1637 : loss : 0.040681, loss_ce: 0.014546
2021-12-11 20:06:49,845 iteration 1638 : loss : 0.044326, loss_ce: 0.019684
2021-12-11 20:06:51,513 iteration 1639 : loss : 0.079253, loss_ce: 0.017878
2021-12-11 20:06:53,118 iteration 1640 : loss : 0.079930, loss_ce: 0.018229
2021-12-11 20:06:54,611 iteration 1641 : loss : 0.031655, loss_ce: 0.015548
2021-12-11 20:06:56,148 iteration 1642 : loss : 0.036396, loss_ce: 0.012023
2021-12-11 20:06:57,739 iteration 1643 : loss : 0.035152, loss_ce: 0.010200
2021-12-11 20:06:59,260 iteration 1644 : loss : 0.042317, loss_ce: 0.014863
2021-12-11 20:07:00,805 iteration 1645 : loss : 0.048842, loss_ce: 0.017481
2021-12-11 20:07:02,352 iteration 1646 : loss : 0.045414, loss_ce: 0.019129
2021-12-11 20:07:03,885 iteration 1647 : loss : 0.045300, loss_ce: 0.015648
2021-12-11 20:07:05,453 iteration 1648 : loss : 0.056927, loss_ce: 0.024938
2021-12-11 20:07:06,961 iteration 1649 : loss : 0.047779, loss_ce: 0.023713
 24%|███████▎                      | 97/400 [46:51<2:25:50, 28.88s/it]2021-12-11 20:07:08,617 iteration 1650 : loss : 0.034843, loss_ce: 0.016150
2021-12-11 20:07:10,318 iteration 1651 : loss : 0.064596, loss_ce: 0.022834
2021-12-11 20:07:11,816 iteration 1652 : loss : 0.056599, loss_ce: 0.018069
2021-12-11 20:07:13,311 iteration 1653 : loss : 0.036565, loss_ce: 0.013071
2021-12-11 20:07:14,905 iteration 1654 : loss : 0.086826, loss_ce: 0.023543
2021-12-11 20:07:16,526 iteration 1655 : loss : 0.053264, loss_ce: 0.020114
2021-12-11 20:07:18,072 iteration 1656 : loss : 0.030510, loss_ce: 0.011884
2021-12-11 20:07:19,756 iteration 1657 : loss : 0.057131, loss_ce: 0.018783
2021-12-11 20:07:21,373 iteration 1658 : loss : 0.055223, loss_ce: 0.028846
2021-12-11 20:07:22,879 iteration 1659 : loss : 0.028822, loss_ce: 0.009194
2021-12-11 20:07:24,572 iteration 1660 : loss : 0.045314, loss_ce: 0.015682
2021-12-11 20:07:26,231 iteration 1661 : loss : 0.039817, loss_ce: 0.013080
2021-12-11 20:07:27,798 iteration 1662 : loss : 0.043412, loss_ce: 0.016533
2021-12-11 20:07:29,234 iteration 1663 : loss : 0.034847, loss_ce: 0.017996
2021-12-11 20:07:30,893 iteration 1664 : loss : 0.056852, loss_ce: 0.022603
2021-12-11 20:07:32,511 iteration 1665 : loss : 0.042925, loss_ce: 0.013720
2021-12-11 20:07:34,158 iteration 1666 : loss : 0.056061, loss_ce: 0.024338
 24%|███████▎                      | 98/400 [47:18<2:22:49, 28.38s/it]2021-12-11 20:07:35,817 iteration 1667 : loss : 0.050897, loss_ce: 0.017830
2021-12-11 20:07:37,398 iteration 1668 : loss : 0.047843, loss_ce: 0.017802
2021-12-11 20:07:38,918 iteration 1669 : loss : 0.034905, loss_ce: 0.012991
2021-12-11 20:07:40,507 iteration 1670 : loss : 0.050908, loss_ce: 0.020732
2021-12-11 20:07:42,062 iteration 1671 : loss : 0.033014, loss_ce: 0.012760
2021-12-11 20:07:43,694 iteration 1672 : loss : 0.036761, loss_ce: 0.013998
2021-12-11 20:07:45,290 iteration 1673 : loss : 0.051181, loss_ce: 0.020385
2021-12-11 20:07:46,943 iteration 1674 : loss : 0.041806, loss_ce: 0.020294
2021-12-11 20:07:48,474 iteration 1675 : loss : 0.046826, loss_ce: 0.013630
2021-12-11 20:07:50,029 iteration 1676 : loss : 0.063212, loss_ce: 0.023362
2021-12-11 20:07:51,681 iteration 1677 : loss : 0.053742, loss_ce: 0.025908
2021-12-11 20:07:53,115 iteration 1678 : loss : 0.042587, loss_ce: 0.018324
2021-12-11 20:07:54,648 iteration 1679 : loss : 0.039055, loss_ce: 0.010694
2021-12-11 20:07:56,253 iteration 1680 : loss : 0.036956, loss_ce: 0.017445
2021-12-11 20:07:57,858 iteration 1681 : loss : 0.049723, loss_ce: 0.028854
2021-12-11 20:07:59,467 iteration 1682 : loss : 0.041784, loss_ce: 0.014683
2021-12-11 20:08:00,971 iteration 1683 : loss : 0.030924, loss_ce: 0.010059
 25%|███████▍                      | 99/400 [47:45<2:20:00, 27.91s/it]2021-12-11 20:08:02,624 iteration 1684 : loss : 0.038986, loss_ce: 0.014368
2021-12-11 20:08:04,189 iteration 1685 : loss : 0.042080, loss_ce: 0.014186
2021-12-11 20:08:05,734 iteration 1686 : loss : 0.031751, loss_ce: 0.012249
2021-12-11 20:08:07,219 iteration 1687 : loss : 0.038075, loss_ce: 0.016132
2021-12-11 20:08:08,928 iteration 1688 : loss : 0.036236, loss_ce: 0.015892
2021-12-11 20:08:10,512 iteration 1689 : loss : 0.043714, loss_ce: 0.016312
2021-12-11 20:08:12,128 iteration 1690 : loss : 0.054286, loss_ce: 0.025364
2021-12-11 20:08:13,614 iteration 1691 : loss : 0.081318, loss_ce: 0.022490
2021-12-11 20:08:15,232 iteration 1692 : loss : 0.064735, loss_ce: 0.022299
2021-12-11 20:08:16,663 iteration 1693 : loss : 0.034295, loss_ce: 0.013896
2021-12-11 20:08:18,260 iteration 1694 : loss : 0.028689, loss_ce: 0.011457
2021-12-11 20:08:19,901 iteration 1695 : loss : 0.061213, loss_ce: 0.026742
2021-12-11 20:08:21,546 iteration 1696 : loss : 0.050992, loss_ce: 0.018106
2021-12-11 20:08:23,105 iteration 1697 : loss : 0.039257, loss_ce: 0.015255
2021-12-11 20:08:24,730 iteration 1698 : loss : 0.042459, loss_ce: 0.015133
2021-12-11 20:08:26,304 iteration 1699 : loss : 0.045185, loss_ce: 0.025787
2021-12-11 20:08:26,304 Training Data Eval:
2021-12-11 20:08:34,056   Average segmentation loss on training set: 0.0284
2021-12-11 20:08:34,057 Validation Data Eval:
2021-12-11 20:08:36,712   Average segmentation loss on validation set: 0.1107
2021-12-11 20:08:38,242 iteration 1700 : loss : 0.038449, loss_ce: 0.013105
 25%|███████▎                     | 100/400 [48:23<2:33:34, 30.72s/it]2021-12-11 20:08:39,867 iteration 1701 : loss : 0.039041, loss_ce: 0.017400
2021-12-11 20:08:41,405 iteration 1702 : loss : 0.048959, loss_ce: 0.022752
2021-12-11 20:08:43,050 iteration 1703 : loss : 0.034895, loss_ce: 0.014879
2021-12-11 20:08:44,678 iteration 1704 : loss : 0.037363, loss_ce: 0.016221
2021-12-11 20:08:46,231 iteration 1705 : loss : 0.055364, loss_ce: 0.018943
2021-12-11 20:08:47,847 iteration 1706 : loss : 0.054693, loss_ce: 0.015394
2021-12-11 20:08:49,389 iteration 1707 : loss : 0.042963, loss_ce: 0.019681
2021-12-11 20:08:50,947 iteration 1708 : loss : 0.033394, loss_ce: 0.012137
2021-12-11 20:08:52,680 iteration 1709 : loss : 0.047676, loss_ce: 0.018365
2021-12-11 20:08:54,203 iteration 1710 : loss : 0.051145, loss_ce: 0.021929
2021-12-11 20:08:55,787 iteration 1711 : loss : 0.043163, loss_ce: 0.016557
2021-12-11 20:08:57,372 iteration 1712 : loss : 0.045658, loss_ce: 0.016053
2021-12-11 20:08:58,940 iteration 1713 : loss : 0.039893, loss_ce: 0.014606
2021-12-11 20:09:00,485 iteration 1714 : loss : 0.030435, loss_ce: 0.011911
2021-12-11 20:09:02,120 iteration 1715 : loss : 0.043417, loss_ce: 0.018972
2021-12-11 20:09:03,661 iteration 1716 : loss : 0.047158, loss_ce: 0.014824
2021-12-11 20:09:05,252 iteration 1717 : loss : 0.038968, loss_ce: 0.016686
 25%|███████▎                     | 101/400 [48:50<2:27:31, 29.60s/it]2021-12-11 20:09:06,922 iteration 1718 : loss : 0.051111, loss_ce: 0.021504
2021-12-11 20:09:08,583 iteration 1719 : loss : 0.039490, loss_ce: 0.011146
2021-12-11 20:09:10,192 iteration 1720 : loss : 0.039026, loss_ce: 0.012369
2021-12-11 20:09:11,776 iteration 1721 : loss : 0.061154, loss_ce: 0.030655
2021-12-11 20:09:13,296 iteration 1722 : loss : 0.027105, loss_ce: 0.009631
2021-12-11 20:09:14,837 iteration 1723 : loss : 0.039481, loss_ce: 0.015512
2021-12-11 20:09:16,320 iteration 1724 : loss : 0.029429, loss_ce: 0.013101
2021-12-11 20:09:17,821 iteration 1725 : loss : 0.038179, loss_ce: 0.016714
2021-12-11 20:09:19,514 iteration 1726 : loss : 0.050987, loss_ce: 0.020579
2021-12-11 20:09:21,128 iteration 1727 : loss : 0.054958, loss_ce: 0.019190
2021-12-11 20:09:22,803 iteration 1728 : loss : 0.052105, loss_ce: 0.025687
2021-12-11 20:09:24,333 iteration 1729 : loss : 0.040199, loss_ce: 0.014341
2021-12-11 20:09:25,914 iteration 1730 : loss : 0.037597, loss_ce: 0.014618
2021-12-11 20:09:27,430 iteration 1731 : loss : 0.051688, loss_ce: 0.023371
2021-12-11 20:09:29,010 iteration 1732 : loss : 0.036028, loss_ce: 0.015178
2021-12-11 20:09:30,576 iteration 1733 : loss : 0.047922, loss_ce: 0.013742
2021-12-11 20:09:32,121 iteration 1734 : loss : 0.045605, loss_ce: 0.013746
 26%|███████▍                     | 102/400 [49:16<2:22:56, 28.78s/it]2021-12-11 20:09:33,827 iteration 1735 : loss : 0.038240, loss_ce: 0.013139
2021-12-11 20:09:35,400 iteration 1736 : loss : 0.039181, loss_ce: 0.015198
2021-12-11 20:09:36,994 iteration 1737 : loss : 0.060191, loss_ce: 0.023967
2021-12-11 20:09:38,548 iteration 1738 : loss : 0.058701, loss_ce: 0.022594
2021-12-11 20:09:40,108 iteration 1739 : loss : 0.060758, loss_ce: 0.036279
2021-12-11 20:09:41,648 iteration 1740 : loss : 0.060437, loss_ce: 0.014262
2021-12-11 20:09:43,306 iteration 1741 : loss : 0.044265, loss_ce: 0.013707
2021-12-11 20:09:44,878 iteration 1742 : loss : 0.036936, loss_ce: 0.013463
2021-12-11 20:09:46,442 iteration 1743 : loss : 0.048999, loss_ce: 0.029811
2021-12-11 20:09:47,949 iteration 1744 : loss : 0.044213, loss_ce: 0.014915
2021-12-11 20:09:49,577 iteration 1745 : loss : 0.047435, loss_ce: 0.019017
2021-12-11 20:09:51,117 iteration 1746 : loss : 0.061790, loss_ce: 0.022485
2021-12-11 20:09:52,673 iteration 1747 : loss : 0.061496, loss_ce: 0.022757
2021-12-11 20:09:54,183 iteration 1748 : loss : 0.029763, loss_ce: 0.014021
2021-12-11 20:09:55,765 iteration 1749 : loss : 0.049517, loss_ce: 0.018488
2021-12-11 20:09:57,279 iteration 1750 : loss : 0.049292, loss_ce: 0.028344
2021-12-11 20:09:58,795 iteration 1751 : loss : 0.041079, loss_ce: 0.013889
 26%|███████▍                     | 103/400 [49:43<2:19:20, 28.15s/it]2021-12-11 20:10:00,417 iteration 1752 : loss : 0.031636, loss_ce: 0.014047
2021-12-11 20:10:02,074 iteration 1753 : loss : 0.057690, loss_ce: 0.026886
2021-12-11 20:10:03,664 iteration 1754 : loss : 0.035571, loss_ce: 0.016235
2021-12-11 20:10:05,271 iteration 1755 : loss : 0.057065, loss_ce: 0.017822
2021-12-11 20:10:06,893 iteration 1756 : loss : 0.077268, loss_ce: 0.041883
2021-12-11 20:10:08,472 iteration 1757 : loss : 0.058773, loss_ce: 0.015075
2021-12-11 20:10:10,050 iteration 1758 : loss : 0.051986, loss_ce: 0.019563
2021-12-11 20:10:11,602 iteration 1759 : loss : 0.047840, loss_ce: 0.015903
2021-12-11 20:10:13,223 iteration 1760 : loss : 0.056108, loss_ce: 0.022349
2021-12-11 20:10:14,726 iteration 1761 : loss : 0.030788, loss_ce: 0.013698
2021-12-11 20:10:16,357 iteration 1762 : loss : 0.071402, loss_ce: 0.028902
2021-12-11 20:10:17,882 iteration 1763 : loss : 0.053901, loss_ce: 0.016948
2021-12-11 20:10:19,485 iteration 1764 : loss : 0.118706, loss_ce: 0.028186
2021-12-11 20:10:21,096 iteration 1765 : loss : 0.072975, loss_ce: 0.019450
2021-12-11 20:10:22,605 iteration 1766 : loss : 0.034908, loss_ce: 0.015161
2021-12-11 20:10:24,169 iteration 1767 : loss : 0.047916, loss_ce: 0.020518
2021-12-11 20:10:25,814 iteration 1768 : loss : 0.048860, loss_ce: 0.018463
 26%|███████▌                     | 104/400 [50:10<2:17:11, 27.81s/it]2021-12-11 20:10:27,428 iteration 1769 : loss : 0.038790, loss_ce: 0.012879
2021-12-11 20:10:29,198 iteration 1770 : loss : 0.078327, loss_ce: 0.034250
2021-12-11 20:10:30,750 iteration 1771 : loss : 0.055185, loss_ce: 0.021563
2021-12-11 20:10:32,262 iteration 1772 : loss : 0.033289, loss_ce: 0.010460
2021-12-11 20:10:33,750 iteration 1773 : loss : 0.044800, loss_ce: 0.014467
2021-12-11 20:10:35,314 iteration 1774 : loss : 0.043975, loss_ce: 0.018599
2021-12-11 20:10:36,941 iteration 1775 : loss : 0.050294, loss_ce: 0.025929
2021-12-11 20:10:38,505 iteration 1776 : loss : 0.071494, loss_ce: 0.019697
2021-12-11 20:10:40,041 iteration 1777 : loss : 0.047898, loss_ce: 0.018468
2021-12-11 20:10:41,587 iteration 1778 : loss : 0.041093, loss_ce: 0.015180
2021-12-11 20:10:43,165 iteration 1779 : loss : 0.055770, loss_ce: 0.020081
2021-12-11 20:10:44,704 iteration 1780 : loss : 0.059192, loss_ce: 0.021646
2021-12-11 20:10:46,241 iteration 1781 : loss : 0.048230, loss_ce: 0.022112
2021-12-11 20:10:47,825 iteration 1782 : loss : 0.053060, loss_ce: 0.019528
2021-12-11 20:10:49,332 iteration 1783 : loss : 0.037494, loss_ce: 0.019273
2021-12-11 20:10:51,001 iteration 1784 : loss : 0.034718, loss_ce: 0.014084
2021-12-11 20:10:51,001 Training Data Eval:
2021-12-11 20:10:58,755   Average segmentation loss on training set: 0.0551
2021-12-11 20:10:58,755 Validation Data Eval:
2021-12-11 20:11:01,416   Average segmentation loss on validation set: 0.0898
2021-12-11 20:11:02,988 iteration 1785 : loss : 0.041117, loss_ce: 0.015061
 26%|███████▌                     | 105/400 [50:47<2:30:32, 30.62s/it]2021-12-11 20:11:04,745 iteration 1786 : loss : 0.053769, loss_ce: 0.028563
2021-12-11 20:11:06,426 iteration 1787 : loss : 0.057409, loss_ce: 0.019969
2021-12-11 20:11:08,030 iteration 1788 : loss : 0.041434, loss_ce: 0.017295
2021-12-11 20:11:09,611 iteration 1789 : loss : 0.042902, loss_ce: 0.015390
2021-12-11 20:11:11,177 iteration 1790 : loss : 0.033338, loss_ce: 0.014730
2021-12-11 20:11:12,672 iteration 1791 : loss : 0.028398, loss_ce: 0.013226
2021-12-11 20:11:14,250 iteration 1792 : loss : 0.046765, loss_ce: 0.014647
2021-12-11 20:11:15,878 iteration 1793 : loss : 0.048156, loss_ce: 0.024772
2021-12-11 20:11:17,405 iteration 1794 : loss : 0.031848, loss_ce: 0.014465
2021-12-11 20:11:18,988 iteration 1795 : loss : 0.049425, loss_ce: 0.018489
2021-12-11 20:11:20,558 iteration 1796 : loss : 0.038048, loss_ce: 0.012867
2021-12-11 20:11:22,233 iteration 1797 : loss : 0.035244, loss_ce: 0.012463
2021-12-11 20:11:23,808 iteration 1798 : loss : 0.080987, loss_ce: 0.027313
2021-12-11 20:11:25,412 iteration 1799 : loss : 0.043299, loss_ce: 0.015040
2021-12-11 20:11:27,015 iteration 1800 : loss : 0.065808, loss_ce: 0.031198
2021-12-11 20:11:28,622 iteration 1801 : loss : 0.036788, loss_ce: 0.016009
2021-12-11 20:11:30,094 iteration 1802 : loss : 0.074658, loss_ce: 0.022122
 26%|███████▋                     | 106/400 [51:14<2:24:52, 29.57s/it]2021-12-11 20:11:31,757 iteration 1803 : loss : 0.046848, loss_ce: 0.016473
2021-12-11 20:11:33,299 iteration 1804 : loss : 0.045456, loss_ce: 0.008568
2021-12-11 20:11:34,802 iteration 1805 : loss : 0.031957, loss_ce: 0.015301
2021-12-11 20:11:36,321 iteration 1806 : loss : 0.055867, loss_ce: 0.020555
2021-12-11 20:11:37,896 iteration 1807 : loss : 0.039271, loss_ce: 0.014093
2021-12-11 20:11:39,474 iteration 1808 : loss : 0.056452, loss_ce: 0.023850
2021-12-11 20:11:41,018 iteration 1809 : loss : 0.042866, loss_ce: 0.017901
2021-12-11 20:11:42,571 iteration 1810 : loss : 0.046771, loss_ce: 0.017638
2021-12-11 20:11:44,186 iteration 1811 : loss : 0.042588, loss_ce: 0.015416
2021-12-11 20:11:45,852 iteration 1812 : loss : 0.050797, loss_ce: 0.025062
2021-12-11 20:11:47,475 iteration 1813 : loss : 0.073758, loss_ce: 0.024847
2021-12-11 20:11:49,152 iteration 1814 : loss : 0.052439, loss_ce: 0.021776
2021-12-11 20:11:50,758 iteration 1815 : loss : 0.035819, loss_ce: 0.018105
2021-12-11 20:11:52,412 iteration 1816 : loss : 0.068077, loss_ce: 0.026505
2021-12-11 20:11:53,990 iteration 1817 : loss : 0.038942, loss_ce: 0.012144
2021-12-11 20:11:55,689 iteration 1818 : loss : 0.038185, loss_ce: 0.019261
2021-12-11 20:11:57,250 iteration 1819 : loss : 0.038551, loss_ce: 0.014042
 27%|███████▊                     | 107/400 [51:42<2:20:50, 28.84s/it]2021-12-11 20:11:58,948 iteration 1820 : loss : 0.057806, loss_ce: 0.020114
2021-12-11 20:12:00,489 iteration 1821 : loss : 0.028665, loss_ce: 0.010003
2021-12-11 20:12:02,025 iteration 1822 : loss : 0.038288, loss_ce: 0.019068
2021-12-11 20:12:03,643 iteration 1823 : loss : 0.043605, loss_ce: 0.017912
2021-12-11 20:12:05,210 iteration 1824 : loss : 0.034439, loss_ce: 0.012795
2021-12-11 20:12:06,790 iteration 1825 : loss : 0.036192, loss_ce: 0.012933
2021-12-11 20:12:08,270 iteration 1826 : loss : 0.042353, loss_ce: 0.017759
2021-12-11 20:12:09,782 iteration 1827 : loss : 0.059331, loss_ce: 0.016133
2021-12-11 20:12:11,396 iteration 1828 : loss : 0.037677, loss_ce: 0.016907
2021-12-11 20:12:13,012 iteration 1829 : loss : 0.076592, loss_ce: 0.021325
2021-12-11 20:12:14,583 iteration 1830 : loss : 0.041309, loss_ce: 0.015254
2021-12-11 20:12:16,139 iteration 1831 : loss : 0.041936, loss_ce: 0.016716
2021-12-11 20:12:17,701 iteration 1832 : loss : 0.037684, loss_ce: 0.013089
2021-12-11 20:12:19,237 iteration 1833 : loss : 0.034409, loss_ce: 0.018996
2021-12-11 20:12:20,865 iteration 1834 : loss : 0.034671, loss_ce: 0.013382
2021-12-11 20:12:22,343 iteration 1835 : loss : 0.033106, loss_ce: 0.011647
2021-12-11 20:12:23,872 iteration 1836 : loss : 0.042716, loss_ce: 0.017191
 27%|███████▊                     | 108/400 [52:08<2:17:08, 28.18s/it]2021-12-11 20:12:25,432 iteration 1837 : loss : 0.045496, loss_ce: 0.010182
2021-12-11 20:12:27,083 iteration 1838 : loss : 0.060014, loss_ce: 0.026630
2021-12-11 20:12:28,580 iteration 1839 : loss : 0.032822, loss_ce: 0.015382
2021-12-11 20:12:30,158 iteration 1840 : loss : 0.058835, loss_ce: 0.015166
2021-12-11 20:12:31,703 iteration 1841 : loss : 0.049124, loss_ce: 0.019148
2021-12-11 20:12:33,397 iteration 1842 : loss : 0.042537, loss_ce: 0.020946
2021-12-11 20:12:34,940 iteration 1843 : loss : 0.034437, loss_ce: 0.015180
2021-12-11 20:12:36,507 iteration 1844 : loss : 0.038747, loss_ce: 0.015566
2021-12-11 20:12:38,062 iteration 1845 : loss : 0.035361, loss_ce: 0.013916
2021-12-11 20:12:39,638 iteration 1846 : loss : 0.044866, loss_ce: 0.017860
2021-12-11 20:12:41,099 iteration 1847 : loss : 0.028235, loss_ce: 0.010425
2021-12-11 20:12:42,678 iteration 1848 : loss : 0.044988, loss_ce: 0.015602
2021-12-11 20:12:44,245 iteration 1849 : loss : 0.038622, loss_ce: 0.014238
2021-12-11 20:12:45,822 iteration 1850 : loss : 0.042808, loss_ce: 0.017474
2021-12-11 20:12:47,436 iteration 1851 : loss : 0.044626, loss_ce: 0.017815
2021-12-11 20:12:48,901 iteration 1852 : loss : 0.031877, loss_ce: 0.016933
2021-12-11 20:12:50,505 iteration 1853 : loss : 0.032154, loss_ce: 0.014427
 27%|███████▉                     | 109/400 [52:35<2:14:24, 27.71s/it]2021-12-11 20:12:52,156 iteration 1854 : loss : 0.051362, loss_ce: 0.016877
2021-12-11 20:12:53,784 iteration 1855 : loss : 0.038991, loss_ce: 0.016435
2021-12-11 20:12:55,252 iteration 1856 : loss : 0.039754, loss_ce: 0.015270
2021-12-11 20:12:56,721 iteration 1857 : loss : 0.030449, loss_ce: 0.013499
2021-12-11 20:12:58,213 iteration 1858 : loss : 0.027055, loss_ce: 0.011955
2021-12-11 20:12:59,790 iteration 1859 : loss : 0.040331, loss_ce: 0.014504
2021-12-11 20:13:01,421 iteration 1860 : loss : 0.043833, loss_ce: 0.016013
2021-12-11 20:13:02,998 iteration 1861 : loss : 0.036921, loss_ce: 0.019265
2021-12-11 20:13:04,584 iteration 1862 : loss : 0.030481, loss_ce: 0.014218
2021-12-11 20:13:06,195 iteration 1863 : loss : 0.061867, loss_ce: 0.021750
2021-12-11 20:13:07,789 iteration 1864 : loss : 0.033089, loss_ce: 0.011724
2021-12-11 20:13:09,361 iteration 1865 : loss : 0.060709, loss_ce: 0.018342
2021-12-11 20:13:10,955 iteration 1866 : loss : 0.027937, loss_ce: 0.009778
2021-12-11 20:13:12,404 iteration 1867 : loss : 0.033741, loss_ce: 0.011657
2021-12-11 20:13:13,922 iteration 1868 : loss : 0.035771, loss_ce: 0.012795
2021-12-11 20:13:15,442 iteration 1869 : loss : 0.033635, loss_ce: 0.015128
2021-12-11 20:13:15,442 Training Data Eval:
2021-12-11 20:13:23,204   Average segmentation loss on training set: 0.0307
2021-12-11 20:13:23,205 Validation Data Eval:
2021-12-11 20:13:25,868   Average segmentation loss on validation set: 0.1166
2021-12-11 20:13:27,445 iteration 1870 : loss : 0.052614, loss_ce: 0.019282
 28%|███████▉                     | 110/400 [53:12<2:27:20, 30.48s/it]2021-12-11 20:13:29,133 iteration 1871 : loss : 0.050097, loss_ce: 0.014369
2021-12-11 20:13:30,743 iteration 1872 : loss : 0.059608, loss_ce: 0.022689
2021-12-11 20:13:32,379 iteration 1873 : loss : 0.030087, loss_ce: 0.009772
2021-12-11 20:13:33,984 iteration 1874 : loss : 0.047384, loss_ce: 0.014104
2021-12-11 20:13:35,468 iteration 1875 : loss : 0.024684, loss_ce: 0.010438
2021-12-11 20:13:36,932 iteration 1876 : loss : 0.028697, loss_ce: 0.012675
2021-12-11 20:13:38,548 iteration 1877 : loss : 0.033122, loss_ce: 0.010441
2021-12-11 20:13:40,147 iteration 1878 : loss : 0.058402, loss_ce: 0.032428
2021-12-11 20:13:41,714 iteration 1879 : loss : 0.035918, loss_ce: 0.011898
2021-12-11 20:13:43,315 iteration 1880 : loss : 0.057235, loss_ce: 0.022713
2021-12-11 20:13:44,870 iteration 1881 : loss : 0.051436, loss_ce: 0.022855
2021-12-11 20:13:46,508 iteration 1882 : loss : 0.076958, loss_ce: 0.024126
2021-12-11 20:13:48,095 iteration 1883 : loss : 0.023621, loss_ce: 0.007738
2021-12-11 20:13:49,624 iteration 1884 : loss : 0.033353, loss_ce: 0.012355
2021-12-11 20:13:51,114 iteration 1885 : loss : 0.026473, loss_ce: 0.009725
2021-12-11 20:13:52,708 iteration 1886 : loss : 0.041013, loss_ce: 0.015386
2021-12-11 20:13:54,293 iteration 1887 : loss : 0.061945, loss_ce: 0.023187
 28%|████████                     | 111/400 [53:39<2:21:33, 29.39s/it]2021-12-11 20:13:56,039 iteration 1888 : loss : 0.039784, loss_ce: 0.013278
2021-12-11 20:13:57,553 iteration 1889 : loss : 0.051782, loss_ce: 0.014986
2021-12-11 20:13:59,042 iteration 1890 : loss : 0.032773, loss_ce: 0.014538
2021-12-11 20:14:00,547 iteration 1891 : loss : 0.034875, loss_ce: 0.012297
2021-12-11 20:14:02,094 iteration 1892 : loss : 0.026715, loss_ce: 0.012672
2021-12-11 20:14:03,681 iteration 1893 : loss : 0.049241, loss_ce: 0.014549
2021-12-11 20:14:05,246 iteration 1894 : loss : 0.043835, loss_ce: 0.018122
2021-12-11 20:14:06,734 iteration 1895 : loss : 0.031386, loss_ce: 0.013513
2021-12-11 20:14:08,385 iteration 1896 : loss : 0.033702, loss_ce: 0.014346
2021-12-11 20:14:09,980 iteration 1897 : loss : 0.066744, loss_ce: 0.023329
2021-12-11 20:14:11,650 iteration 1898 : loss : 0.046539, loss_ce: 0.020766
2021-12-11 20:14:13,212 iteration 1899 : loss : 0.044987, loss_ce: 0.015797
2021-12-11 20:14:14,724 iteration 1900 : loss : 0.065895, loss_ce: 0.029145
2021-12-11 20:14:16,206 iteration 1901 : loss : 0.033752, loss_ce: 0.011367
2021-12-11 20:14:17,758 iteration 1902 : loss : 0.040994, loss_ce: 0.015813
2021-12-11 20:14:19,375 iteration 1903 : loss : 0.045024, loss_ce: 0.021356
2021-12-11 20:14:21,000 iteration 1904 : loss : 0.040127, loss_ce: 0.015304
 28%|████████                     | 112/400 [54:05<2:17:13, 28.59s/it]2021-12-11 20:14:22,548 iteration 1905 : loss : 0.035684, loss_ce: 0.014984
2021-12-11 20:14:24,153 iteration 1906 : loss : 0.031672, loss_ce: 0.010373
2021-12-11 20:14:25,772 iteration 1907 : loss : 0.038349, loss_ce: 0.014663
2021-12-11 20:14:27,509 iteration 1908 : loss : 0.050065, loss_ce: 0.020471
2021-12-11 20:14:28,998 iteration 1909 : loss : 0.027537, loss_ce: 0.011230
2021-12-11 20:14:30,560 iteration 1910 : loss : 0.034075, loss_ce: 0.013315
2021-12-11 20:14:32,175 iteration 1911 : loss : 0.038839, loss_ce: 0.015149
2021-12-11 20:14:33,874 iteration 1912 : loss : 0.045687, loss_ce: 0.019194
2021-12-11 20:14:35,486 iteration 1913 : loss : 0.048655, loss_ce: 0.016979
2021-12-11 20:14:37,178 iteration 1914 : loss : 0.057456, loss_ce: 0.023484
2021-12-11 20:14:38,762 iteration 1915 : loss : 0.034936, loss_ce: 0.012160
2021-12-11 20:14:40,302 iteration 1916 : loss : 0.032671, loss_ce: 0.011241
2021-12-11 20:14:41,855 iteration 1917 : loss : 0.034406, loss_ce: 0.013289
2021-12-11 20:14:43,472 iteration 1918 : loss : 0.064653, loss_ce: 0.034836
2021-12-11 20:14:44,993 iteration 1919 : loss : 0.042675, loss_ce: 0.013291
2021-12-11 20:14:46,467 iteration 1920 : loss : 0.043874, loss_ce: 0.018091
2021-12-11 20:14:48,119 iteration 1921 : loss : 0.053483, loss_ce: 0.018940
 28%|████████▏                    | 113/400 [54:32<2:14:38, 28.15s/it]2021-12-11 20:14:49,813 iteration 1922 : loss : 0.055232, loss_ce: 0.029030
2021-12-11 20:14:51,333 iteration 1923 : loss : 0.038379, loss_ce: 0.016979
2021-12-11 20:14:52,984 iteration 1924 : loss : 0.062947, loss_ce: 0.017165
2021-12-11 20:14:54,489 iteration 1925 : loss : 0.049590, loss_ce: 0.014161
2021-12-11 20:14:56,123 iteration 1926 : loss : 0.043667, loss_ce: 0.016387
2021-12-11 20:14:57,774 iteration 1927 : loss : 0.032625, loss_ce: 0.015290
2021-12-11 20:14:59,294 iteration 1928 : loss : 0.051402, loss_ce: 0.018405
2021-12-11 20:15:01,028 iteration 1929 : loss : 0.063372, loss_ce: 0.028997
2021-12-11 20:15:02,606 iteration 1930 : loss : 0.047146, loss_ce: 0.020724
2021-12-11 20:15:04,244 iteration 1931 : loss : 0.048309, loss_ce: 0.017321
2021-12-11 20:15:05,846 iteration 1932 : loss : 0.064969, loss_ce: 0.022374
2021-12-11 20:15:07,449 iteration 1933 : loss : 0.041556, loss_ce: 0.016825
2021-12-11 20:15:09,010 iteration 1934 : loss : 0.044931, loss_ce: 0.013722
2021-12-11 20:15:10,594 iteration 1935 : loss : 0.036579, loss_ce: 0.015869
2021-12-11 20:15:12,145 iteration 1936 : loss : 0.035727, loss_ce: 0.014451
2021-12-11 20:15:13,651 iteration 1937 : loss : 0.033453, loss_ce: 0.011565
2021-12-11 20:15:15,258 iteration 1938 : loss : 0.041821, loss_ce: 0.016933
 28%|████████▎                    | 114/400 [55:00<2:12:43, 27.85s/it]2021-12-11 20:15:16,930 iteration 1939 : loss : 0.040705, loss_ce: 0.016611
2021-12-11 20:15:18,446 iteration 1940 : loss : 0.044197, loss_ce: 0.023843
2021-12-11 20:15:20,014 iteration 1941 : loss : 0.032084, loss_ce: 0.012265
2021-12-11 20:15:21,609 iteration 1942 : loss : 0.037062, loss_ce: 0.013117
2021-12-11 20:15:23,167 iteration 1943 : loss : 0.032857, loss_ce: 0.012082
2021-12-11 20:15:24,732 iteration 1944 : loss : 0.040791, loss_ce: 0.013745
2021-12-11 20:15:26,318 iteration 1945 : loss : 0.046433, loss_ce: 0.017145
2021-12-11 20:15:27,846 iteration 1946 : loss : 0.042250, loss_ce: 0.011626
2021-12-11 20:15:29,400 iteration 1947 : loss : 0.058295, loss_ce: 0.018626
2021-12-11 20:15:30,992 iteration 1948 : loss : 0.033521, loss_ce: 0.012891
2021-12-11 20:15:32,519 iteration 1949 : loss : 0.037808, loss_ce: 0.013818
2021-12-11 20:15:34,133 iteration 1950 : loss : 0.040646, loss_ce: 0.016427
2021-12-11 20:15:35,735 iteration 1951 : loss : 0.042233, loss_ce: 0.018080
2021-12-11 20:15:37,310 iteration 1952 : loss : 0.040147, loss_ce: 0.017958
2021-12-11 20:15:38,793 iteration 1953 : loss : 0.048867, loss_ce: 0.029691
2021-12-11 20:15:40,387 iteration 1954 : loss : 0.044137, loss_ce: 0.024487
2021-12-11 20:15:40,387 Training Data Eval:
2021-12-11 20:15:48,154   Average segmentation loss on training set: 0.0305
2021-12-11 20:15:48,154 Validation Data Eval:
2021-12-11 20:15:50,810   Average segmentation loss on validation set: 0.1044
2021-12-11 20:15:52,415 iteration 1955 : loss : 0.035685, loss_ce: 0.015325
 29%|████████▎                    | 115/400 [55:37<2:25:31, 30.64s/it]2021-12-11 20:15:54,034 iteration 1956 : loss : 0.046916, loss_ce: 0.019989
2021-12-11 20:15:55,652 iteration 1957 : loss : 0.046456, loss_ce: 0.023011
2021-12-11 20:15:57,212 iteration 1958 : loss : 0.053474, loss_ce: 0.016467
2021-12-11 20:15:58,752 iteration 1959 : loss : 0.037031, loss_ce: 0.011929
2021-12-11 20:16:00,205 iteration 1960 : loss : 0.030879, loss_ce: 0.011829
2021-12-11 20:16:01,637 iteration 1961 : loss : 0.031458, loss_ce: 0.012174
2021-12-11 20:16:03,261 iteration 1962 : loss : 0.038513, loss_ce: 0.017513
2021-12-11 20:16:04,765 iteration 1963 : loss : 0.033014, loss_ce: 0.011666
2021-12-11 20:16:06,370 iteration 1964 : loss : 0.038896, loss_ce: 0.014279
2021-12-11 20:16:07,837 iteration 1965 : loss : 0.028634, loss_ce: 0.012808
2021-12-11 20:16:09,391 iteration 1966 : loss : 0.034536, loss_ce: 0.015059
2021-12-11 20:16:11,069 iteration 1967 : loss : 0.036530, loss_ce: 0.013314
2021-12-11 20:16:12,822 iteration 1968 : loss : 0.053183, loss_ce: 0.022465
2021-12-11 20:16:14,441 iteration 1969 : loss : 0.049231, loss_ce: 0.018987
2021-12-11 20:16:15,934 iteration 1970 : loss : 0.028819, loss_ce: 0.011823
2021-12-11 20:16:17,509 iteration 1971 : loss : 0.030057, loss_ce: 0.011668
2021-12-11 20:16:19,092 iteration 1972 : loss : 0.034420, loss_ce: 0.010544
 29%|████████▍                    | 116/400 [56:03<2:19:24, 29.45s/it]2021-12-11 20:16:20,666 iteration 1973 : loss : 0.029846, loss_ce: 0.013009
2021-12-11 20:16:22,185 iteration 1974 : loss : 0.034772, loss_ce: 0.013917
2021-12-11 20:16:23,776 iteration 1975 : loss : 0.035705, loss_ce: 0.014574
2021-12-11 20:16:25,302 iteration 1976 : loss : 0.053247, loss_ce: 0.023557
2021-12-11 20:16:26,924 iteration 1977 : loss : 0.034882, loss_ce: 0.013020
2021-12-11 20:16:28,582 iteration 1978 : loss : 0.029657, loss_ce: 0.010876
2021-12-11 20:16:30,083 iteration 1979 : loss : 0.034319, loss_ce: 0.013703
2021-12-11 20:16:31,592 iteration 1980 : loss : 0.029266, loss_ce: 0.010500
2021-12-11 20:16:33,120 iteration 1981 : loss : 0.031100, loss_ce: 0.013109
2021-12-11 20:16:34,746 iteration 1982 : loss : 0.042067, loss_ce: 0.015107
2021-12-11 20:16:36,234 iteration 1983 : loss : 0.035691, loss_ce: 0.011755
2021-12-11 20:16:37,865 iteration 1984 : loss : 0.055024, loss_ce: 0.022243
2021-12-11 20:16:39,414 iteration 1985 : loss : 0.047576, loss_ce: 0.016843
2021-12-11 20:16:41,040 iteration 1986 : loss : 0.052830, loss_ce: 0.017128
2021-12-11 20:16:42,571 iteration 1987 : loss : 0.033975, loss_ce: 0.011479
2021-12-11 20:16:44,044 iteration 1988 : loss : 0.031099, loss_ce: 0.012974
2021-12-11 20:16:45,594 iteration 1989 : loss : 0.043464, loss_ce: 0.014672
 29%|████████▍                    | 117/400 [56:30<2:14:43, 28.56s/it]2021-12-11 20:16:47,226 iteration 1990 : loss : 0.058347, loss_ce: 0.015154
2021-12-11 20:16:48,719 iteration 1991 : loss : 0.032596, loss_ce: 0.011912
2021-12-11 20:16:50,309 iteration 1992 : loss : 0.027640, loss_ce: 0.009199
2021-12-11 20:16:51,901 iteration 1993 : loss : 0.037008, loss_ce: 0.011879
2021-12-11 20:16:53,535 iteration 1994 : loss : 0.040035, loss_ce: 0.019778
2021-12-11 20:16:55,081 iteration 1995 : loss : 0.029484, loss_ce: 0.011701
2021-12-11 20:16:56,680 iteration 1996 : loss : 0.037551, loss_ce: 0.014486
2021-12-11 20:16:58,191 iteration 1997 : loss : 0.027797, loss_ce: 0.011905
2021-12-11 20:16:59,760 iteration 1998 : loss : 0.032358, loss_ce: 0.012206
2021-12-11 20:17:01,364 iteration 1999 : loss : 0.033338, loss_ce: 0.012736
2021-12-11 20:17:02,932 iteration 2000 : loss : 0.038777, loss_ce: 0.018259
2021-12-11 20:17:04,441 iteration 2001 : loss : 0.042442, loss_ce: 0.013642
2021-12-11 20:17:06,067 iteration 2002 : loss : 0.035352, loss_ce: 0.014000
2021-12-11 20:17:07,573 iteration 2003 : loss : 0.036400, loss_ce: 0.011098
2021-12-11 20:17:09,173 iteration 2004 : loss : 0.034793, loss_ce: 0.014998
2021-12-11 20:17:10,694 iteration 2005 : loss : 0.038966, loss_ce: 0.019976
2021-12-11 20:17:12,243 iteration 2006 : loss : 0.037762, loss_ce: 0.012807
 30%|████████▌                    | 118/400 [56:57<2:11:32, 27.99s/it]2021-12-11 20:17:13,949 iteration 2007 : loss : 0.048179, loss_ce: 0.016026
2021-12-11 20:17:15,547 iteration 2008 : loss : 0.032750, loss_ce: 0.014150
2021-12-11 20:17:17,066 iteration 2009 : loss : 0.032373, loss_ce: 0.014696
2021-12-11 20:17:18,640 iteration 2010 : loss : 0.033759, loss_ce: 0.014234
2021-12-11 20:17:20,125 iteration 2011 : loss : 0.041021, loss_ce: 0.014513
2021-12-11 20:17:21,589 iteration 2012 : loss : 0.027914, loss_ce: 0.010835
2021-12-11 20:17:23,102 iteration 2013 : loss : 0.035188, loss_ce: 0.017659
2021-12-11 20:17:24,691 iteration 2014 : loss : 0.033786, loss_ce: 0.014251
2021-12-11 20:17:26,299 iteration 2015 : loss : 0.044112, loss_ce: 0.015795
2021-12-11 20:17:27,932 iteration 2016 : loss : 0.046549, loss_ce: 0.019863
2021-12-11 20:17:29,518 iteration 2017 : loss : 0.035820, loss_ce: 0.012577
2021-12-11 20:17:31,005 iteration 2018 : loss : 0.031905, loss_ce: 0.010643
2021-12-11 20:17:32,574 iteration 2019 : loss : 0.030842, loss_ce: 0.012055
2021-12-11 20:17:34,127 iteration 2020 : loss : 0.035369, loss_ce: 0.012737
2021-12-11 20:17:35,667 iteration 2021 : loss : 0.025346, loss_ce: 0.009721
2021-12-11 20:17:37,227 iteration 2022 : loss : 0.042983, loss_ce: 0.014532
2021-12-11 20:17:38,813 iteration 2023 : loss : 0.030655, loss_ce: 0.009714
 30%|████████▋                    | 119/400 [57:23<2:09:05, 27.56s/it]2021-12-11 20:17:40,433 iteration 2024 : loss : 0.046896, loss_ce: 0.021992
2021-12-11 20:17:42,189 iteration 2025 : loss : 0.079927, loss_ce: 0.029858
2021-12-11 20:17:43,719 iteration 2026 : loss : 0.037730, loss_ce: 0.012263
2021-12-11 20:17:45,330 iteration 2027 : loss : 0.032976, loss_ce: 0.010358
2021-12-11 20:17:46,788 iteration 2028 : loss : 0.029590, loss_ce: 0.012628
2021-12-11 20:17:48,275 iteration 2029 : loss : 0.037971, loss_ce: 0.010832
2021-12-11 20:17:49,870 iteration 2030 : loss : 0.038429, loss_ce: 0.012267
2021-12-11 20:17:51,468 iteration 2031 : loss : 0.041219, loss_ce: 0.015023
2021-12-11 20:17:53,054 iteration 2032 : loss : 0.055948, loss_ce: 0.026975
2021-12-11 20:17:54,511 iteration 2033 : loss : 0.030144, loss_ce: 0.014076
2021-12-11 20:17:56,033 iteration 2034 : loss : 0.031637, loss_ce: 0.009096
2021-12-11 20:17:57,648 iteration 2035 : loss : 0.032773, loss_ce: 0.012479
2021-12-11 20:17:59,191 iteration 2036 : loss : 0.027553, loss_ce: 0.012221
2021-12-11 20:18:00,701 iteration 2037 : loss : 0.037809, loss_ce: 0.016005
2021-12-11 20:18:02,380 iteration 2038 : loss : 0.075145, loss_ce: 0.025855
2021-12-11 20:18:03,994 iteration 2039 : loss : 0.034665, loss_ce: 0.014146
2021-12-11 20:18:03,994 Training Data Eval:
2021-12-11 20:18:11,779   Average segmentation loss on training set: 0.0267
2021-12-11 20:18:11,779 Validation Data Eval:
2021-12-11 20:18:14,436   Average segmentation loss on validation set: 0.0769
2021-12-11 20:18:16,477 Found new lowest validation loss at iteration 2039! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/NEW_TU/UNET_ADAM_best_val_loss_seed2.pth
2021-12-11 20:18:18,128 iteration 2040 : loss : 0.039433, loss_ce: 0.017484
 30%|████████▋                    | 120/400 [58:02<2:25:04, 31.09s/it]2021-12-11 20:18:19,715 iteration 2041 : loss : 0.029030, loss_ce: 0.012054
2021-12-11 20:18:21,311 iteration 2042 : loss : 0.032255, loss_ce: 0.011133
2021-12-11 20:18:22,893 iteration 2043 : loss : 0.035652, loss_ce: 0.013414
2021-12-11 20:18:24,441 iteration 2044 : loss : 0.041278, loss_ce: 0.019513
2021-12-11 20:18:26,113 iteration 2045 : loss : 0.039737, loss_ce: 0.016227
2021-12-11 20:18:27,693 iteration 2046 : loss : 0.060721, loss_ce: 0.016176
2021-12-11 20:18:29,207 iteration 2047 : loss : 0.034715, loss_ce: 0.013365
2021-12-11 20:18:30,704 iteration 2048 : loss : 0.033441, loss_ce: 0.013091
2021-12-11 20:18:32,334 iteration 2049 : loss : 0.046040, loss_ce: 0.021506
2021-12-11 20:18:33,946 iteration 2050 : loss : 0.039835, loss_ce: 0.011789
2021-12-11 20:18:35,478 iteration 2051 : loss : 0.048487, loss_ce: 0.027325
2021-12-11 20:18:37,110 iteration 2052 : loss : 0.033114, loss_ce: 0.012235
2021-12-11 20:18:38,716 iteration 2053 : loss : 0.035448, loss_ce: 0.013569
2021-12-11 20:18:40,270 iteration 2054 : loss : 0.033261, loss_ce: 0.012563
2021-12-11 20:18:41,860 iteration 2055 : loss : 0.039821, loss_ce: 0.015840
2021-12-11 20:18:43,388 iteration 2056 : loss : 0.027543, loss_ce: 0.009652
2021-12-11 20:18:44,907 iteration 2057 : loss : 0.030768, loss_ce: 0.012142
 30%|████████▊                    | 121/400 [58:29<2:18:33, 29.80s/it]2021-12-11 20:18:46,512 iteration 2058 : loss : 0.036074, loss_ce: 0.018695
2021-12-11 20:18:48,137 iteration 2059 : loss : 0.028595, loss_ce: 0.010456
2021-12-11 20:18:49,787 iteration 2060 : loss : 0.037260, loss_ce: 0.013368
2021-12-11 20:18:51,357 iteration 2061 : loss : 0.036429, loss_ce: 0.017723
2021-12-11 20:18:52,863 iteration 2062 : loss : 0.040514, loss_ce: 0.015504
2021-12-11 20:18:54,613 iteration 2063 : loss : 0.048837, loss_ce: 0.019692
2021-12-11 20:18:56,193 iteration 2064 : loss : 0.038591, loss_ce: 0.013733
2021-12-11 20:18:57,837 iteration 2065 : loss : 0.059152, loss_ce: 0.018774
2021-12-11 20:18:59,392 iteration 2066 : loss : 0.033010, loss_ce: 0.013241
2021-12-11 20:19:00,998 iteration 2067 : loss : 0.046541, loss_ce: 0.016226
2021-12-11 20:19:02,509 iteration 2068 : loss : 0.029469, loss_ce: 0.010710
2021-12-11 20:19:04,085 iteration 2069 : loss : 0.031744, loss_ce: 0.015278
2021-12-11 20:19:05,710 iteration 2070 : loss : 0.038405, loss_ce: 0.015926
2021-12-11 20:19:07,221 iteration 2071 : loss : 0.027557, loss_ce: 0.010523
2021-12-11 20:19:08,734 iteration 2072 : loss : 0.030057, loss_ce: 0.014511
2021-12-11 20:19:10,346 iteration 2073 : loss : 0.042964, loss_ce: 0.016407
2021-12-11 20:19:11,836 iteration 2074 : loss : 0.036065, loss_ce: 0.011418
 30%|████████▊                    | 122/400 [58:56<2:14:04, 28.94s/it]2021-12-11 20:19:13,454 iteration 2075 : loss : 0.030289, loss_ce: 0.015004
2021-12-11 20:19:15,055 iteration 2076 : loss : 0.035392, loss_ce: 0.015485
2021-12-11 20:19:16,662 iteration 2077 : loss : 0.039124, loss_ce: 0.018596
2021-12-11 20:19:18,296 iteration 2078 : loss : 0.036425, loss_ce: 0.013605
2021-12-11 20:19:19,906 iteration 2079 : loss : 0.041245, loss_ce: 0.014192
2021-12-11 20:19:21,426 iteration 2080 : loss : 0.036200, loss_ce: 0.013631
2021-12-11 20:19:22,913 iteration 2081 : loss : 0.049863, loss_ce: 0.015236
2021-12-11 20:19:24,473 iteration 2082 : loss : 0.037308, loss_ce: 0.011371
2021-12-11 20:19:26,013 iteration 2083 : loss : 0.038047, loss_ce: 0.012961
2021-12-11 20:19:27,506 iteration 2084 : loss : 0.034350, loss_ce: 0.016783
2021-12-11 20:19:29,086 iteration 2085 : loss : 0.062122, loss_ce: 0.014361
2021-12-11 20:19:30,763 iteration 2086 : loss : 0.029892, loss_ce: 0.009787
2021-12-11 20:19:32,244 iteration 2087 : loss : 0.032613, loss_ce: 0.010111
2021-12-11 20:19:33,785 iteration 2088 : loss : 0.032328, loss_ce: 0.011642
2021-12-11 20:19:35,372 iteration 2089 : loss : 0.035299, loss_ce: 0.013467
2021-12-11 20:19:36,936 iteration 2090 : loss : 0.033725, loss_ce: 0.016478
2021-12-11 20:19:38,602 iteration 2091 : loss : 0.051046, loss_ce: 0.020582
 31%|████████▉                    | 123/400 [59:23<2:10:35, 28.29s/it]2021-12-11 20:19:40,198 iteration 2092 : loss : 0.036081, loss_ce: 0.011524
2021-12-11 20:19:41,684 iteration 2093 : loss : 0.026141, loss_ce: 0.009881
2021-12-11 20:19:43,282 iteration 2094 : loss : 0.030006, loss_ce: 0.010459
2021-12-11 20:19:45,039 iteration 2095 : loss : 0.035887, loss_ce: 0.013494
2021-12-11 20:19:46,576 iteration 2096 : loss : 0.034792, loss_ce: 0.013948
2021-12-11 20:19:48,124 iteration 2097 : loss : 0.061788, loss_ce: 0.017082
2021-12-11 20:19:49,619 iteration 2098 : loss : 0.033676, loss_ce: 0.011516
2021-12-11 20:19:51,160 iteration 2099 : loss : 0.029710, loss_ce: 0.011601
2021-12-11 20:19:52,775 iteration 2100 : loss : 0.035431, loss_ce: 0.013040
2021-12-11 20:19:54,236 iteration 2101 : loss : 0.038033, loss_ce: 0.012008
2021-12-11 20:19:55,830 iteration 2102 : loss : 0.042702, loss_ce: 0.018180
2021-12-11 20:19:57,334 iteration 2103 : loss : 0.036306, loss_ce: 0.016493
2021-12-11 20:19:58,801 iteration 2104 : loss : 0.030902, loss_ce: 0.009742
2021-12-11 20:20:00,370 iteration 2105 : loss : 0.039497, loss_ce: 0.017807
2021-12-11 20:20:01,950 iteration 2106 : loss : 0.038608, loss_ce: 0.014870
2021-12-11 20:20:03,460 iteration 2107 : loss : 0.032875, loss_ce: 0.011205
2021-12-11 20:20:04,951 iteration 2108 : loss : 0.034197, loss_ce: 0.012807
 31%|████████▉                    | 124/400 [59:49<2:07:27, 27.71s/it]2021-12-11 20:20:06,587 iteration 2109 : loss : 0.066626, loss_ce: 0.018292
2021-12-11 20:20:08,174 iteration 2110 : loss : 0.035912, loss_ce: 0.013315
2021-12-11 20:20:09,806 iteration 2111 : loss : 0.031294, loss_ce: 0.011489
2021-12-11 20:20:11,491 iteration 2112 : loss : 0.049951, loss_ce: 0.021928
2021-12-11 20:20:13,120 iteration 2113 : loss : 0.044412, loss_ce: 0.014883
2021-12-11 20:20:14,725 iteration 2114 : loss : 0.033643, loss_ce: 0.009047
2021-12-11 20:20:16,250 iteration 2115 : loss : 0.036024, loss_ce: 0.012448
2021-12-11 20:20:17,767 iteration 2116 : loss : 0.038918, loss_ce: 0.012971
2021-12-11 20:20:19,442 iteration 2117 : loss : 0.037647, loss_ce: 0.011228
2021-12-11 20:20:21,054 iteration 2118 : loss : 0.044428, loss_ce: 0.020074
2021-12-11 20:20:22,771 iteration 2119 : loss : 0.045070, loss_ce: 0.018347
2021-12-11 20:20:24,414 iteration 2120 : loss : 0.029833, loss_ce: 0.016236
2021-12-11 20:20:26,051 iteration 2121 : loss : 0.050383, loss_ce: 0.024473
2021-12-11 20:20:27,694 iteration 2122 : loss : 0.057099, loss_ce: 0.032920
2021-12-11 20:20:29,184 iteration 2123 : loss : 0.039173, loss_ce: 0.012559
2021-12-11 20:20:30,825 iteration 2124 : loss : 0.041597, loss_ce: 0.016689
2021-12-11 20:20:30,825 Training Data Eval:
2021-12-11 20:20:38,583   Average segmentation loss on training set: 0.0388
2021-12-11 20:20:38,584 Validation Data Eval:
2021-12-11 20:20:41,240   Average segmentation loss on validation set: 0.0796
2021-12-11 20:20:42,774 iteration 2125 : loss : 0.030102, loss_ce: 0.014371
 31%|████████▍                  | 125/400 [1:00:27<2:20:54, 30.74s/it]2021-12-11 20:20:44,458 iteration 2126 : loss : 0.065083, loss_ce: 0.019933
2021-12-11 20:20:45,947 iteration 2127 : loss : 0.026947, loss_ce: 0.011181
2021-12-11 20:20:47,432 iteration 2128 : loss : 0.029110, loss_ce: 0.011786
2021-12-11 20:20:49,082 iteration 2129 : loss : 0.048883, loss_ce: 0.020133
2021-12-11 20:20:50,630 iteration 2130 : loss : 0.043198, loss_ce: 0.016142
2021-12-11 20:20:52,137 iteration 2131 : loss : 0.032104, loss_ce: 0.012735
2021-12-11 20:20:53,737 iteration 2132 : loss : 0.038169, loss_ce: 0.011870
2021-12-11 20:20:55,297 iteration 2133 : loss : 0.030823, loss_ce: 0.012725
2021-12-11 20:20:56,942 iteration 2134 : loss : 0.049962, loss_ce: 0.018904
2021-12-11 20:20:58,429 iteration 2135 : loss : 0.038690, loss_ce: 0.012798
2021-12-11 20:21:00,067 iteration 2136 : loss : 0.036365, loss_ce: 0.015469
2021-12-11 20:21:01,623 iteration 2137 : loss : 0.034057, loss_ce: 0.014381
2021-12-11 20:21:03,282 iteration 2138 : loss : 0.054533, loss_ce: 0.018914
2021-12-11 20:21:04,821 iteration 2139 : loss : 0.034426, loss_ce: 0.017130
2021-12-11 20:21:06,437 iteration 2140 : loss : 0.059350, loss_ce: 0.035463
2021-12-11 20:21:08,030 iteration 2141 : loss : 0.031590, loss_ce: 0.010837
2021-12-11 20:21:09,634 iteration 2142 : loss : 0.047612, loss_ce: 0.016165
 32%|████████▌                  | 126/400 [1:00:54<2:15:03, 29.58s/it]2021-12-11 20:21:11,273 iteration 2143 : loss : 0.039311, loss_ce: 0.019198
2021-12-11 20:21:12,859 iteration 2144 : loss : 0.026316, loss_ce: 0.010499
2021-12-11 20:21:14,431 iteration 2145 : loss : 0.043034, loss_ce: 0.015473
2021-12-11 20:21:15,956 iteration 2146 : loss : 0.034874, loss_ce: 0.013306
2021-12-11 20:21:17,460 iteration 2147 : loss : 0.026288, loss_ce: 0.010041
2021-12-11 20:21:19,006 iteration 2148 : loss : 0.029311, loss_ce: 0.012162
2021-12-11 20:21:20,633 iteration 2149 : loss : 0.051813, loss_ce: 0.017423
2021-12-11 20:21:22,153 iteration 2150 : loss : 0.031577, loss_ce: 0.014164
2021-12-11 20:21:23,712 iteration 2151 : loss : 0.036629, loss_ce: 0.013597
2021-12-11 20:21:25,212 iteration 2152 : loss : 0.039639, loss_ce: 0.018856
2021-12-11 20:21:26,760 iteration 2153 : loss : 0.031821, loss_ce: 0.010571
2021-12-11 20:21:28,314 iteration 2154 : loss : 0.030806, loss_ce: 0.009726
2021-12-11 20:21:29,911 iteration 2155 : loss : 0.052439, loss_ce: 0.027142
2021-12-11 20:21:31,408 iteration 2156 : loss : 0.028397, loss_ce: 0.011839
2021-12-11 20:21:33,092 iteration 2157 : loss : 0.044736, loss_ce: 0.018944
2021-12-11 20:21:34,727 iteration 2158 : loss : 0.045151, loss_ce: 0.014891
2021-12-11 20:21:36,336 iteration 2159 : loss : 0.045627, loss_ce: 0.016370
 32%|████████▌                  | 127/400 [1:01:21<2:10:37, 28.71s/it]2021-12-11 20:21:37,973 iteration 2160 : loss : 0.049212, loss_ce: 0.017232
2021-12-11 20:21:39,646 iteration 2161 : loss : 0.065893, loss_ce: 0.024486
2021-12-11 20:21:41,283 iteration 2162 : loss : 0.035528, loss_ce: 0.014199
2021-12-11 20:21:42,782 iteration 2163 : loss : 0.042541, loss_ce: 0.015089
2021-12-11 20:21:44,408 iteration 2164 : loss : 0.036885, loss_ce: 0.012798
2021-12-11 20:21:46,018 iteration 2165 : loss : 0.029294, loss_ce: 0.011804
2021-12-11 20:21:47,617 iteration 2166 : loss : 0.050328, loss_ce: 0.014364
2021-12-11 20:21:49,249 iteration 2167 : loss : 0.028592, loss_ce: 0.009056
2021-12-11 20:21:50,828 iteration 2168 : loss : 0.037581, loss_ce: 0.014874
2021-12-11 20:21:52,396 iteration 2169 : loss : 0.040789, loss_ce: 0.013687
2021-12-11 20:21:53,912 iteration 2170 : loss : 0.049168, loss_ce: 0.026340
2021-12-11 20:21:55,530 iteration 2171 : loss : 0.051688, loss_ce: 0.018383
2021-12-11 20:21:57,223 iteration 2172 : loss : 0.041507, loss_ce: 0.012403
2021-12-11 20:21:58,771 iteration 2173 : loss : 0.038185, loss_ce: 0.012355
2021-12-11 20:22:00,269 iteration 2174 : loss : 0.030609, loss_ce: 0.014446
2021-12-11 20:22:01,780 iteration 2175 : loss : 0.034765, loss_ce: 0.011876
2021-12-11 20:22:03,472 iteration 2176 : loss : 0.049276, loss_ce: 0.017237
 32%|████████▋                  | 128/400 [1:01:48<2:08:02, 28.24s/it]2021-12-11 20:22:05,133 iteration 2177 : loss : 0.035629, loss_ce: 0.011188
2021-12-11 20:22:06,769 iteration 2178 : loss : 0.032560, loss_ce: 0.013764
2021-12-11 20:22:08,312 iteration 2179 : loss : 0.033884, loss_ce: 0.016470
2021-12-11 20:22:09,861 iteration 2180 : loss : 0.040711, loss_ce: 0.015019
2021-12-11 20:22:11,466 iteration 2181 : loss : 0.042514, loss_ce: 0.019162
2021-12-11 20:22:13,017 iteration 2182 : loss : 0.042733, loss_ce: 0.011676
2021-12-11 20:22:14,503 iteration 2183 : loss : 0.032507, loss_ce: 0.013464
2021-12-11 20:22:16,144 iteration 2184 : loss : 0.027694, loss_ce: 0.009013
2021-12-11 20:22:17,655 iteration 2185 : loss : 0.031353, loss_ce: 0.012394
2021-12-11 20:22:19,189 iteration 2186 : loss : 0.041911, loss_ce: 0.014418
2021-12-11 20:22:20,740 iteration 2187 : loss : 0.026231, loss_ce: 0.010205
2021-12-11 20:22:22,259 iteration 2188 : loss : 0.048619, loss_ce: 0.012444
2021-12-11 20:22:23,892 iteration 2189 : loss : 0.035201, loss_ce: 0.013089
2021-12-11 20:22:25,448 iteration 2190 : loss : 0.035712, loss_ce: 0.012214
2021-12-11 20:22:27,045 iteration 2191 : loss : 0.053589, loss_ce: 0.018538
2021-12-11 20:22:28,566 iteration 2192 : loss : 0.046911, loss_ce: 0.018788
2021-12-11 20:22:30,142 iteration 2193 : loss : 0.052730, loss_ce: 0.022049
 32%|████████▋                  | 129/400 [1:02:14<2:05:25, 27.77s/it]2021-12-11 20:22:31,818 iteration 2194 : loss : 0.040682, loss_ce: 0.020437
2021-12-11 20:22:33,355 iteration 2195 : loss : 0.028207, loss_ce: 0.009742
2021-12-11 20:22:34,905 iteration 2196 : loss : 0.035859, loss_ce: 0.013636
2021-12-11 20:22:36,498 iteration 2197 : loss : 0.032879, loss_ce: 0.017681
2021-12-11 20:22:38,094 iteration 2198 : loss : 0.038302, loss_ce: 0.018623
2021-12-11 20:22:39,673 iteration 2199 : loss : 0.034108, loss_ce: 0.014486
2021-12-11 20:22:41,206 iteration 2200 : loss : 0.034959, loss_ce: 0.011820
2021-12-11 20:22:42,722 iteration 2201 : loss : 0.027318, loss_ce: 0.010726
2021-12-11 20:22:44,340 iteration 2202 : loss : 0.064184, loss_ce: 0.017332
2021-12-11 20:22:45,966 iteration 2203 : loss : 0.025733, loss_ce: 0.012821
2021-12-11 20:22:47,495 iteration 2204 : loss : 0.031639, loss_ce: 0.014194
2021-12-11 20:22:48,964 iteration 2205 : loss : 0.027240, loss_ce: 0.010751
2021-12-11 20:22:50,432 iteration 2206 : loss : 0.039684, loss_ce: 0.010739
2021-12-11 20:22:51,950 iteration 2207 : loss : 0.040644, loss_ce: 0.014521
2021-12-11 20:22:53,527 iteration 2208 : loss : 0.046075, loss_ce: 0.013657
2021-12-11 20:22:55,067 iteration 2209 : loss : 0.032470, loss_ce: 0.011078
2021-12-11 20:22:55,067 Training Data Eval:
2021-12-11 20:23:02,822   Average segmentation loss on training set: 0.0285
2021-12-11 20:23:02,822 Validation Data Eval:
2021-12-11 20:23:05,469   Average segmentation loss on validation set: 0.1184
2021-12-11 20:23:07,036 iteration 2210 : loss : 0.034251, loss_ce: 0.011136
 32%|████████▊                  | 130/400 [1:02:51<2:17:16, 30.51s/it]2021-12-11 20:23:08,696 iteration 2211 : loss : 0.037701, loss_ce: 0.014056
2021-12-11 20:23:10,291 iteration 2212 : loss : 0.028397, loss_ce: 0.012325
2021-12-11 20:23:11,890 iteration 2213 : loss : 0.039527, loss_ce: 0.015557
2021-12-11 20:23:13,493 iteration 2214 : loss : 0.039675, loss_ce: 0.013515
2021-12-11 20:23:15,120 iteration 2215 : loss : 0.052233, loss_ce: 0.021597
2021-12-11 20:23:16,616 iteration 2216 : loss : 0.038549, loss_ce: 0.013199
2021-12-11 20:23:18,241 iteration 2217 : loss : 0.041193, loss_ce: 0.016912
2021-12-11 20:23:19,747 iteration 2218 : loss : 0.040460, loss_ce: 0.015966
2021-12-11 20:23:21,359 iteration 2219 : loss : 0.041584, loss_ce: 0.016193
2021-12-11 20:23:22,817 iteration 2220 : loss : 0.032567, loss_ce: 0.011248
2021-12-11 20:23:24,336 iteration 2221 : loss : 0.031681, loss_ce: 0.010153
2021-12-11 20:23:25,952 iteration 2222 : loss : 0.036879, loss_ce: 0.013594
2021-12-11 20:23:27,535 iteration 2223 : loss : 0.042739, loss_ce: 0.012898
2021-12-11 20:23:29,169 iteration 2224 : loss : 0.056320, loss_ce: 0.025103
2021-12-11 20:23:30,665 iteration 2225 : loss : 0.020425, loss_ce: 0.007242
2021-12-11 20:23:32,320 iteration 2226 : loss : 0.056324, loss_ce: 0.033678
2021-12-11 20:23:33,895 iteration 2227 : loss : 0.029591, loss_ce: 0.011286
 33%|████████▊                  | 131/400 [1:03:18<2:11:51, 29.41s/it]2021-12-11 20:23:35,580 iteration 2228 : loss : 0.028516, loss_ce: 0.013834
2021-12-11 20:23:37,164 iteration 2229 : loss : 0.036168, loss_ce: 0.014677
2021-12-11 20:23:38,762 iteration 2230 : loss : 0.042079, loss_ce: 0.014896
2021-12-11 20:23:40,225 iteration 2231 : loss : 0.026575, loss_ce: 0.010812
2021-12-11 20:23:41,746 iteration 2232 : loss : 0.032614, loss_ce: 0.014235
2021-12-11 20:23:43,274 iteration 2233 : loss : 0.034088, loss_ce: 0.012310
2021-12-11 20:23:44,827 iteration 2234 : loss : 0.033776, loss_ce: 0.011701
2021-12-11 20:23:46,373 iteration 2235 : loss : 0.050274, loss_ce: 0.011491
2021-12-11 20:23:48,106 iteration 2236 : loss : 0.048226, loss_ce: 0.016968
2021-12-11 20:23:49,682 iteration 2237 : loss : 0.039768, loss_ce: 0.016942
2021-12-11 20:23:51,265 iteration 2238 : loss : 0.047176, loss_ce: 0.022531
2021-12-11 20:23:52,838 iteration 2239 : loss : 0.038372, loss_ce: 0.015293
2021-12-11 20:23:54,466 iteration 2240 : loss : 0.041643, loss_ce: 0.015578
2021-12-11 20:23:56,167 iteration 2241 : loss : 0.045906, loss_ce: 0.012354
2021-12-11 20:23:57,810 iteration 2242 : loss : 0.035517, loss_ce: 0.012132
2021-12-11 20:23:59,530 iteration 2243 : loss : 0.029764, loss_ce: 0.008781
2021-12-11 20:24:01,113 iteration 2244 : loss : 0.034908, loss_ce: 0.014679
 33%|████████▉                  | 132/400 [1:03:45<2:08:25, 28.75s/it]2021-12-11 20:24:02,865 iteration 2245 : loss : 0.055779, loss_ce: 0.020144
2021-12-11 20:24:04,407 iteration 2246 : loss : 0.032873, loss_ce: 0.012225
2021-12-11 20:24:06,106 iteration 2247 : loss : 0.069516, loss_ce: 0.018303
2021-12-11 20:24:07,718 iteration 2248 : loss : 0.040377, loss_ce: 0.016905
2021-12-11 20:24:09,313 iteration 2249 : loss : 0.036343, loss_ce: 0.012537
2021-12-11 20:24:10,880 iteration 2250 : loss : 0.042183, loss_ce: 0.017136
2021-12-11 20:24:12,371 iteration 2251 : loss : 0.038358, loss_ce: 0.012277
2021-12-11 20:24:14,078 iteration 2252 : loss : 0.055830, loss_ce: 0.019004
2021-12-11 20:24:15,756 iteration 2253 : loss : 0.050103, loss_ce: 0.021607
2021-12-11 20:24:17,322 iteration 2254 : loss : 0.036169, loss_ce: 0.014949
2021-12-11 20:24:18,862 iteration 2255 : loss : 0.034403, loss_ce: 0.011372
2021-12-11 20:24:20,467 iteration 2256 : loss : 0.029317, loss_ce: 0.013464
2021-12-11 20:24:22,023 iteration 2257 : loss : 0.029569, loss_ce: 0.010523
2021-12-11 20:24:23,520 iteration 2258 : loss : 0.028294, loss_ce: 0.012551
2021-12-11 20:24:25,187 iteration 2259 : loss : 0.023319, loss_ce: 0.008916
2021-12-11 20:24:26,748 iteration 2260 : loss : 0.034363, loss_ce: 0.012987
2021-12-11 20:24:28,353 iteration 2261 : loss : 0.035472, loss_ce: 0.014658
 33%|████████▉                  | 133/400 [1:04:13<2:05:55, 28.30s/it]2021-12-11 20:24:30,009 iteration 2262 : loss : 0.039709, loss_ce: 0.015508
2021-12-11 20:24:31,584 iteration 2263 : loss : 0.032492, loss_ce: 0.012745
2021-12-11 20:24:33,201 iteration 2264 : loss : 0.044542, loss_ce: 0.016209
2021-12-11 20:24:34,761 iteration 2265 : loss : 0.028051, loss_ce: 0.009798
2021-12-11 20:24:36,316 iteration 2266 : loss : 0.036274, loss_ce: 0.011861
2021-12-11 20:24:37,801 iteration 2267 : loss : 0.023980, loss_ce: 0.009412
2021-12-11 20:24:39,340 iteration 2268 : loss : 0.031555, loss_ce: 0.014127
2021-12-11 20:24:40,859 iteration 2269 : loss : 0.029698, loss_ce: 0.014067
2021-12-11 20:24:42,349 iteration 2270 : loss : 0.025604, loss_ce: 0.010338
2021-12-11 20:24:43,896 iteration 2271 : loss : 0.052206, loss_ce: 0.022670
2021-12-11 20:24:45,524 iteration 2272 : loss : 0.031686, loss_ce: 0.011810
2021-12-11 20:24:47,145 iteration 2273 : loss : 0.033039, loss_ce: 0.013705
2021-12-11 20:24:48,718 iteration 2274 : loss : 0.036066, loss_ce: 0.015527
2021-12-11 20:24:50,273 iteration 2275 : loss : 0.040608, loss_ce: 0.014491
2021-12-11 20:24:51,782 iteration 2276 : loss : 0.050504, loss_ce: 0.020626
2021-12-11 20:24:53,338 iteration 2277 : loss : 0.022800, loss_ce: 0.006358
2021-12-11 20:24:54,933 iteration 2278 : loss : 0.040232, loss_ce: 0.014059
 34%|█████████                  | 134/400 [1:04:39<2:03:10, 27.78s/it]2021-12-11 20:24:56,476 iteration 2279 : loss : 0.025878, loss_ce: 0.008808
2021-12-11 20:24:57,968 iteration 2280 : loss : 0.034631, loss_ce: 0.016917
2021-12-11 20:24:59,524 iteration 2281 : loss : 0.044411, loss_ce: 0.014338
2021-12-11 20:25:01,010 iteration 2282 : loss : 0.036358, loss_ce: 0.011579
2021-12-11 20:25:02,590 iteration 2283 : loss : 0.043190, loss_ce: 0.012519
2021-12-11 20:25:04,070 iteration 2284 : loss : 0.060652, loss_ce: 0.030366
2021-12-11 20:25:05,665 iteration 2285 : loss : 0.038752, loss_ce: 0.016908
2021-12-11 20:25:07,200 iteration 2286 : loss : 0.038818, loss_ce: 0.017549
2021-12-11 20:25:08,748 iteration 2287 : loss : 0.034511, loss_ce: 0.011489
2021-12-11 20:25:10,295 iteration 2288 : loss : 0.035969, loss_ce: 0.011385
2021-12-11 20:25:11,875 iteration 2289 : loss : 0.038591, loss_ce: 0.012773
2021-12-11 20:25:13,436 iteration 2290 : loss : 0.042840, loss_ce: 0.015354
2021-12-11 20:25:15,113 iteration 2291 : loss : 0.058145, loss_ce: 0.023849
2021-12-11 20:25:16,714 iteration 2292 : loss : 0.039658, loss_ce: 0.014983
2021-12-11 20:25:18,291 iteration 2293 : loss : 0.053810, loss_ce: 0.020227
2021-12-11 20:25:19,832 iteration 2294 : loss : 0.036356, loss_ce: 0.016669
2021-12-11 20:25:19,832 Training Data Eval:
2021-12-11 20:25:27,590   Average segmentation loss on training set: 0.0314
2021-12-11 20:25:27,590 Validation Data Eval:
2021-12-11 20:25:30,253   Average segmentation loss on validation set: 0.0757
2021-12-11 20:25:32,177 Found new lowest validation loss at iteration 2294! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/NEW_TU/UNET_ADAM_best_val_loss_seed2.pth
2021-12-11 20:25:33,770 iteration 2295 : loss : 0.047614, loss_ce: 0.015051
 34%|█████████                  | 135/400 [1:05:18<2:17:20, 31.10s/it]2021-12-11 20:25:35,323 iteration 2296 : loss : 0.033292, loss_ce: 0.013737
2021-12-11 20:25:36,943 iteration 2297 : loss : 0.037949, loss_ce: 0.013141
2021-12-11 20:25:38,513 iteration 2298 : loss : 0.038909, loss_ce: 0.013340
2021-12-11 20:25:40,117 iteration 2299 : loss : 0.056504, loss_ce: 0.016286
2021-12-11 20:25:41,655 iteration 2300 : loss : 0.031601, loss_ce: 0.013388
2021-12-11 20:25:43,228 iteration 2301 : loss : 0.027503, loss_ce: 0.010433
2021-12-11 20:25:44,840 iteration 2302 : loss : 0.035170, loss_ce: 0.013081
2021-12-11 20:25:46,440 iteration 2303 : loss : 0.049879, loss_ce: 0.015671
2021-12-11 20:25:48,034 iteration 2304 : loss : 0.036991, loss_ce: 0.013847
2021-12-11 20:25:49,584 iteration 2305 : loss : 0.047377, loss_ce: 0.019082
2021-12-11 20:25:51,111 iteration 2306 : loss : 0.036270, loss_ce: 0.014268
2021-12-11 20:25:52,757 iteration 2307 : loss : 0.044279, loss_ce: 0.016823
2021-12-11 20:25:54,273 iteration 2308 : loss : 0.028063, loss_ce: 0.010749
2021-12-11 20:25:55,892 iteration 2309 : loss : 0.034462, loss_ce: 0.013724
2021-12-11 20:25:57,487 iteration 2310 : loss : 0.036706, loss_ce: 0.015369
2021-12-11 20:25:59,006 iteration 2311 : loss : 0.043913, loss_ce: 0.016036
2021-12-11 20:26:00,500 iteration 2312 : loss : 0.036751, loss_ce: 0.012596
 34%|█████████▏                 | 136/400 [1:05:45<2:11:04, 29.79s/it]2021-12-11 20:26:02,119 iteration 2313 : loss : 0.044331, loss_ce: 0.014681
2021-12-11 20:26:03,703 iteration 2314 : loss : 0.028677, loss_ce: 0.009008
2021-12-11 20:26:05,363 iteration 2315 : loss : 0.054027, loss_ce: 0.014064
2021-12-11 20:26:06,842 iteration 2316 : loss : 0.031282, loss_ce: 0.011614
2021-12-11 20:26:08,478 iteration 2317 : loss : 0.039813, loss_ce: 0.013858
2021-12-11 20:26:10,069 iteration 2318 : loss : 0.036383, loss_ce: 0.015326
2021-12-11 20:26:11,652 iteration 2319 : loss : 0.033883, loss_ce: 0.012929
2021-12-11 20:26:13,313 iteration 2320 : loss : 0.045169, loss_ce: 0.024977
2021-12-11 20:26:14,818 iteration 2321 : loss : 0.043058, loss_ce: 0.012504
2021-12-11 20:26:16,373 iteration 2322 : loss : 0.039541, loss_ce: 0.018417
2021-12-11 20:26:17,931 iteration 2323 : loss : 0.030987, loss_ce: 0.013777
2021-12-11 20:26:19,523 iteration 2324 : loss : 0.029298, loss_ce: 0.009401
2021-12-11 20:26:21,058 iteration 2325 : loss : 0.029023, loss_ce: 0.011225
2021-12-11 20:26:22,633 iteration 2326 : loss : 0.042090, loss_ce: 0.019007
2021-12-11 20:26:24,175 iteration 2327 : loss : 0.027617, loss_ce: 0.011788
2021-12-11 20:26:25,781 iteration 2328 : loss : 0.046743, loss_ce: 0.024013
2021-12-11 20:26:27,313 iteration 2329 : loss : 0.027369, loss_ce: 0.010724
 34%|█████████▏                 | 137/400 [1:06:12<2:06:39, 28.90s/it]2021-12-11 20:26:28,912 iteration 2330 : loss : 0.027333, loss_ce: 0.010336
2021-12-11 20:26:30,474 iteration 2331 : loss : 0.039885, loss_ce: 0.016712
2021-12-11 20:26:32,096 iteration 2332 : loss : 0.039236, loss_ce: 0.015900
2021-12-11 20:26:33,736 iteration 2333 : loss : 0.030070, loss_ce: 0.014801
2021-12-11 20:26:35,282 iteration 2334 : loss : 0.025265, loss_ce: 0.011046
2021-12-11 20:26:36,835 iteration 2335 : loss : 0.042026, loss_ce: 0.012026
2021-12-11 20:26:38,459 iteration 2336 : loss : 0.060024, loss_ce: 0.016360
2021-12-11 20:26:40,077 iteration 2337 : loss : 0.034336, loss_ce: 0.015758
2021-12-11 20:26:41,620 iteration 2338 : loss : 0.030662, loss_ce: 0.011860
2021-12-11 20:26:43,208 iteration 2339 : loss : 0.043984, loss_ce: 0.015677
2021-12-11 20:26:44,844 iteration 2340 : loss : 0.040787, loss_ce: 0.017683
2021-12-11 20:26:46,327 iteration 2341 : loss : 0.027164, loss_ce: 0.006620
2021-12-11 20:26:47,890 iteration 2342 : loss : 0.033148, loss_ce: 0.012658
2021-12-11 20:26:49,536 iteration 2343 : loss : 0.047966, loss_ce: 0.017414
2021-12-11 20:26:51,144 iteration 2344 : loss : 0.030844, loss_ce: 0.012058
2021-12-11 20:26:52,773 iteration 2345 : loss : 0.043948, loss_ce: 0.015149
2021-12-11 20:26:54,358 iteration 2346 : loss : 0.031828, loss_ce: 0.012145
 34%|█████████▎                 | 138/400 [1:06:39<2:03:44, 28.34s/it]2021-12-11 20:26:55,987 iteration 2347 : loss : 0.026490, loss_ce: 0.008437
2021-12-11 20:26:57,537 iteration 2348 : loss : 0.037433, loss_ce: 0.013157
2021-12-11 20:26:59,171 iteration 2349 : loss : 0.029439, loss_ce: 0.011832
2021-12-11 20:27:00,725 iteration 2350 : loss : 0.035967, loss_ce: 0.011861
2021-12-11 20:27:02,319 iteration 2351 : loss : 0.116754, loss_ce: 0.019543
2021-12-11 20:27:03,899 iteration 2352 : loss : 0.034290, loss_ce: 0.011450
2021-12-11 20:27:05,526 iteration 2353 : loss : 0.038038, loss_ce: 0.016609
2021-12-11 20:27:07,170 iteration 2354 : loss : 0.052354, loss_ce: 0.020944
2021-12-11 20:27:08,652 iteration 2355 : loss : 0.029264, loss_ce: 0.010993
2021-12-11 20:27:10,233 iteration 2356 : loss : 0.028338, loss_ce: 0.010865
2021-12-11 20:27:11,795 iteration 2357 : loss : 0.049923, loss_ce: 0.016399
2021-12-11 20:27:13,391 iteration 2358 : loss : 0.034757, loss_ce: 0.014558
2021-12-11 20:27:15,085 iteration 2359 : loss : 0.038904, loss_ce: 0.016951
2021-12-11 20:27:16,620 iteration 2360 : loss : 0.032382, loss_ce: 0.014427
2021-12-11 20:27:18,220 iteration 2361 : loss : 0.046048, loss_ce: 0.016540
2021-12-11 20:27:19,905 iteration 2362 : loss : 0.052398, loss_ce: 0.022730
2021-12-11 20:27:21,406 iteration 2363 : loss : 0.038953, loss_ce: 0.018245
 35%|█████████▍                 | 139/400 [1:07:06<2:01:35, 27.95s/it]2021-12-11 20:27:22,947 iteration 2364 : loss : 0.050528, loss_ce: 0.014447
2021-12-11 20:27:24,468 iteration 2365 : loss : 0.040709, loss_ce: 0.011378
2021-12-11 20:27:26,055 iteration 2366 : loss : 0.038393, loss_ce: 0.015132
2021-12-11 20:27:27,600 iteration 2367 : loss : 0.039992, loss_ce: 0.019432
2021-12-11 20:27:29,125 iteration 2368 : loss : 0.039772, loss_ce: 0.013621
2021-12-11 20:27:30,711 iteration 2369 : loss : 0.042208, loss_ce: 0.016084
2021-12-11 20:27:32,179 iteration 2370 : loss : 0.035928, loss_ce: 0.012840
2021-12-11 20:27:33,797 iteration 2371 : loss : 0.036556, loss_ce: 0.013825
2021-12-11 20:27:35,353 iteration 2372 : loss : 0.029508, loss_ce: 0.012749
2021-12-11 20:27:36,869 iteration 2373 : loss : 0.034062, loss_ce: 0.012543
2021-12-11 20:27:38,401 iteration 2374 : loss : 0.035846, loss_ce: 0.013097
2021-12-11 20:27:39,997 iteration 2375 : loss : 0.046311, loss_ce: 0.016400
2021-12-11 20:27:41,608 iteration 2376 : loss : 0.032752, loss_ce: 0.012026
2021-12-11 20:27:43,151 iteration 2377 : loss : 0.034889, loss_ce: 0.012920
2021-12-11 20:27:44,697 iteration 2378 : loss : 0.024430, loss_ce: 0.009531
2021-12-11 20:27:46,267 iteration 2379 : loss : 0.040540, loss_ce: 0.022148
2021-12-11 20:27:46,267 Training Data Eval:
2021-12-11 20:27:54,020   Average segmentation loss on training set: 0.0246
2021-12-11 20:27:54,021 Validation Data Eval:
2021-12-11 20:27:56,676   Average segmentation loss on validation set: 0.0954
2021-12-11 20:27:58,177 iteration 2380 : loss : 0.027815, loss_ce: 0.013079
 35%|█████████▍                 | 140/400 [1:07:43<2:12:36, 30.60s/it]2021-12-11 20:27:59,914 iteration 2381 : loss : 0.056115, loss_ce: 0.015839
2021-12-11 20:28:01,503 iteration 2382 : loss : 0.031142, loss_ce: 0.012490
2021-12-11 20:28:03,060 iteration 2383 : loss : 0.040620, loss_ce: 0.014002
2021-12-11 20:28:04,568 iteration 2384 : loss : 0.033226, loss_ce: 0.012112
2021-12-11 20:28:06,129 iteration 2385 : loss : 0.032277, loss_ce: 0.010924
2021-12-11 20:28:07,736 iteration 2386 : loss : 0.034753, loss_ce: 0.008958
2021-12-11 20:28:09,368 iteration 2387 : loss : 0.032069, loss_ce: 0.011397
2021-12-11 20:28:10,950 iteration 2388 : loss : 0.033671, loss_ce: 0.015816
2021-12-11 20:28:12,527 iteration 2389 : loss : 0.028986, loss_ce: 0.009398
2021-12-11 20:28:14,042 iteration 2390 : loss : 0.047341, loss_ce: 0.021777
2021-12-11 20:28:15,514 iteration 2391 : loss : 0.035947, loss_ce: 0.013255
2021-12-11 20:28:17,225 iteration 2392 : loss : 0.044029, loss_ce: 0.010051
2021-12-11 20:28:18,863 iteration 2393 : loss : 0.037426, loss_ce: 0.013452
2021-12-11 20:28:20,440 iteration 2394 : loss : 0.047349, loss_ce: 0.017256
2021-12-11 20:28:22,074 iteration 2395 : loss : 0.044553, loss_ce: 0.020587
2021-12-11 20:28:23,583 iteration 2396 : loss : 0.031781, loss_ce: 0.013242
2021-12-11 20:28:25,217 iteration 2397 : loss : 0.032894, loss_ce: 0.016135
 35%|█████████▌                 | 141/400 [1:08:10<2:07:28, 29.53s/it]2021-12-11 20:28:26,807 iteration 2398 : loss : 0.026843, loss_ce: 0.013014
2021-12-11 20:28:28,474 iteration 2399 : loss : 0.029286, loss_ce: 0.011604
2021-12-11 20:28:30,031 iteration 2400 : loss : 0.040910, loss_ce: 0.015494
2021-12-11 20:28:31,748 iteration 2401 : loss : 0.082326, loss_ce: 0.031832
2021-12-11 20:28:33,311 iteration 2402 : loss : 0.050162, loss_ce: 0.021078
2021-12-11 20:28:34,855 iteration 2403 : loss : 0.036137, loss_ce: 0.013101
2021-12-11 20:28:36,380 iteration 2404 : loss : 0.030623, loss_ce: 0.010726
2021-12-11 20:28:38,004 iteration 2405 : loss : 0.052884, loss_ce: 0.018196
2021-12-11 20:28:39,503 iteration 2406 : loss : 0.033398, loss_ce: 0.013407
2021-12-11 20:28:41,042 iteration 2407 : loss : 0.037985, loss_ce: 0.012315
2021-12-11 20:28:42,778 iteration 2408 : loss : 0.040285, loss_ce: 0.013186
2021-12-11 20:28:44,303 iteration 2409 : loss : 0.032867, loss_ce: 0.013897
2021-12-11 20:28:45,830 iteration 2410 : loss : 0.039951, loss_ce: 0.016499
2021-12-11 20:28:47,341 iteration 2411 : loss : 0.036316, loss_ce: 0.013790
2021-12-11 20:28:48,870 iteration 2412 : loss : 0.031838, loss_ce: 0.011312
2021-12-11 20:28:50,371 iteration 2413 : loss : 0.045072, loss_ce: 0.020158
2021-12-11 20:28:51,872 iteration 2414 : loss : 0.025269, loss_ce: 0.010348
 36%|█████████▌                 | 142/400 [1:08:36<2:03:16, 28.67s/it]2021-12-11 20:28:53,554 iteration 2415 : loss : 0.033724, loss_ce: 0.011778
2021-12-11 20:28:55,087 iteration 2416 : loss : 0.036996, loss_ce: 0.013399
2021-12-11 20:28:56,650 iteration 2417 : loss : 0.027661, loss_ce: 0.013594
2021-12-11 20:28:58,150 iteration 2418 : loss : 0.027108, loss_ce: 0.008623
2021-12-11 20:28:59,714 iteration 2419 : loss : 0.052238, loss_ce: 0.015616
2021-12-11 20:29:01,348 iteration 2420 : loss : 0.034165, loss_ce: 0.016182
2021-12-11 20:29:02,899 iteration 2421 : loss : 0.032107, loss_ce: 0.015085
2021-12-11 20:29:04,448 iteration 2422 : loss : 0.033053, loss_ce: 0.014442
2021-12-11 20:29:05,922 iteration 2423 : loss : 0.032649, loss_ce: 0.014012
2021-12-11 20:29:07,483 iteration 2424 : loss : 0.039330, loss_ce: 0.015616
2021-12-11 20:29:09,073 iteration 2425 : loss : 0.024708, loss_ce: 0.008587
2021-12-11 20:29:10,660 iteration 2426 : loss : 0.042490, loss_ce: 0.015497
2021-12-11 20:29:12,159 iteration 2427 : loss : 0.031603, loss_ce: 0.013070
2021-12-11 20:29:13,699 iteration 2428 : loss : 0.032926, loss_ce: 0.010574
2021-12-11 20:29:15,212 iteration 2429 : loss : 0.046418, loss_ce: 0.014896
2021-12-11 20:29:16,763 iteration 2430 : loss : 0.037928, loss_ce: 0.015047
2021-12-11 20:29:18,348 iteration 2431 : loss : 0.029930, loss_ce: 0.009808
 36%|█████████▋                 | 143/400 [1:09:03<1:59:58, 28.01s/it]2021-12-11 20:29:19,895 iteration 2432 : loss : 0.025179, loss_ce: 0.008011
2021-12-11 20:29:21,428 iteration 2433 : loss : 0.029896, loss_ce: 0.013942
2021-12-11 20:29:23,009 iteration 2434 : loss : 0.038624, loss_ce: 0.016103
2021-12-11 20:29:24,561 iteration 2435 : loss : 0.025068, loss_ce: 0.010397
2021-12-11 20:29:26,195 iteration 2436 : loss : 0.031813, loss_ce: 0.011956
2021-12-11 20:29:27,763 iteration 2437 : loss : 0.035337, loss_ce: 0.014632
2021-12-11 20:29:29,260 iteration 2438 : loss : 0.025240, loss_ce: 0.009309
2021-12-11 20:29:30,810 iteration 2439 : loss : 0.026783, loss_ce: 0.009177
2021-12-11 20:29:32,366 iteration 2440 : loss : 0.033640, loss_ce: 0.012978
2021-12-11 20:29:34,049 iteration 2441 : loss : 0.044369, loss_ce: 0.014867
2021-12-11 20:29:35,620 iteration 2442 : loss : 0.028081, loss_ce: 0.009640
2021-12-11 20:29:37,241 iteration 2443 : loss : 0.027779, loss_ce: 0.011605
2021-12-11 20:29:38,857 iteration 2444 : loss : 0.041299, loss_ce: 0.014562
2021-12-11 20:29:40,543 iteration 2445 : loss : 0.025800, loss_ce: 0.009430
2021-12-11 20:29:42,086 iteration 2446 : loss : 0.029978, loss_ce: 0.013004
2021-12-11 20:29:43,732 iteration 2447 : loss : 0.041719, loss_ce: 0.013680
2021-12-11 20:29:45,248 iteration 2448 : loss : 0.040964, loss_ce: 0.022694
 36%|█████████▋                 | 144/400 [1:09:30<1:58:05, 27.68s/it]2021-12-11 20:29:46,878 iteration 2449 : loss : 0.025663, loss_ce: 0.007628
2021-12-11 20:29:48,390 iteration 2450 : loss : 0.038180, loss_ce: 0.012556
2021-12-11 20:29:49,895 iteration 2451 : loss : 0.034348, loss_ce: 0.010792
2021-12-11 20:29:51,434 iteration 2452 : loss : 0.034489, loss_ce: 0.016246
2021-12-11 20:29:52,975 iteration 2453 : loss : 0.023899, loss_ce: 0.010436
2021-12-11 20:29:54,506 iteration 2454 : loss : 0.042956, loss_ce: 0.017125
2021-12-11 20:29:56,173 iteration 2455 : loss : 0.036369, loss_ce: 0.013904
2021-12-11 20:29:57,761 iteration 2456 : loss : 0.024214, loss_ce: 0.010491
2021-12-11 20:29:59,288 iteration 2457 : loss : 0.035464, loss_ce: 0.015002
2021-12-11 20:30:00,896 iteration 2458 : loss : 0.036941, loss_ce: 0.011760
2021-12-11 20:30:02,456 iteration 2459 : loss : 0.033329, loss_ce: 0.011979
2021-12-11 20:30:04,086 iteration 2460 : loss : 0.048869, loss_ce: 0.012936
2021-12-11 20:30:05,688 iteration 2461 : loss : 0.037467, loss_ce: 0.009854
2021-12-11 20:30:07,376 iteration 2462 : loss : 0.038691, loss_ce: 0.017895
2021-12-11 20:30:08,921 iteration 2463 : loss : 0.034264, loss_ce: 0.015465
2021-12-11 20:30:10,500 iteration 2464 : loss : 0.047580, loss_ce: 0.027178
2021-12-11 20:30:10,500 Training Data Eval:
2021-12-11 20:30:18,272   Average segmentation loss on training set: 0.0275
2021-12-11 20:30:18,273 Validation Data Eval:
2021-12-11 20:30:20,933   Average segmentation loss on validation set: 0.0795
2021-12-11 20:30:22,498 iteration 2465 : loss : 0.030737, loss_ce: 0.012143
 36%|█████████▊                 | 145/400 [1:10:07<2:09:49, 30.55s/it]2021-12-11 20:30:24,136 iteration 2466 : loss : 0.030309, loss_ce: 0.010657
2021-12-11 20:30:25,683 iteration 2467 : loss : 0.024103, loss_ce: 0.008788
2021-12-11 20:30:27,331 iteration 2468 : loss : 0.040108, loss_ce: 0.014710
2021-12-11 20:30:28,836 iteration 2469 : loss : 0.030254, loss_ce: 0.012945
2021-12-11 20:30:30,435 iteration 2470 : loss : 0.039924, loss_ce: 0.015795
2021-12-11 20:30:32,023 iteration 2471 : loss : 0.031684, loss_ce: 0.014441
2021-12-11 20:30:33,619 iteration 2472 : loss : 0.031936, loss_ce: 0.011941
2021-12-11 20:30:35,176 iteration 2473 : loss : 0.028910, loss_ce: 0.011764
2021-12-11 20:30:36,630 iteration 2474 : loss : 0.030778, loss_ce: 0.012417
2021-12-11 20:30:38,230 iteration 2475 : loss : 0.038241, loss_ce: 0.022956
2021-12-11 20:30:39,822 iteration 2476 : loss : 0.039913, loss_ce: 0.011331
2021-12-11 20:30:41,389 iteration 2477 : loss : 0.030805, loss_ce: 0.010571
2021-12-11 20:30:42,929 iteration 2478 : loss : 0.037291, loss_ce: 0.012987
2021-12-11 20:30:44,542 iteration 2479 : loss : 0.039846, loss_ce: 0.013106
2021-12-11 20:30:46,087 iteration 2480 : loss : 0.024595, loss_ce: 0.008564
2021-12-11 20:30:47,612 iteration 2481 : loss : 0.030848, loss_ce: 0.013092
2021-12-11 20:30:49,283 iteration 2482 : loss : 0.044589, loss_ce: 0.018703
 36%|█████████▊                 | 146/400 [1:10:34<2:04:32, 29.42s/it]2021-12-11 20:30:50,882 iteration 2483 : loss : 0.051730, loss_ce: 0.021685
2021-12-11 20:30:52,469 iteration 2484 : loss : 0.093850, loss_ce: 0.019341
2021-12-11 20:30:54,056 iteration 2485 : loss : 0.042503, loss_ce: 0.014758
2021-12-11 20:30:55,629 iteration 2486 : loss : 0.042429, loss_ce: 0.017927
2021-12-11 20:30:57,128 iteration 2487 : loss : 0.025327, loss_ce: 0.012040
2021-12-11 20:30:58,755 iteration 2488 : loss : 0.032940, loss_ce: 0.015729
2021-12-11 20:31:00,354 iteration 2489 : loss : 0.045868, loss_ce: 0.018726
2021-12-11 20:31:01,992 iteration 2490 : loss : 0.031802, loss_ce: 0.014163
2021-12-11 20:31:03,575 iteration 2491 : loss : 0.037352, loss_ce: 0.010184
2021-12-11 20:31:05,169 iteration 2492 : loss : 0.037783, loss_ce: 0.013958
2021-12-11 20:31:06,685 iteration 2493 : loss : 0.029515, loss_ce: 0.011555
2021-12-11 20:31:08,247 iteration 2494 : loss : 0.032512, loss_ce: 0.011851
2021-12-11 20:31:09,899 iteration 2495 : loss : 0.025308, loss_ce: 0.011100
2021-12-11 20:31:11,335 iteration 2496 : loss : 0.020554, loss_ce: 0.008252
2021-12-11 20:31:12,847 iteration 2497 : loss : 0.031399, loss_ce: 0.010591
2021-12-11 20:31:14,551 iteration 2498 : loss : 0.036937, loss_ce: 0.015635
2021-12-11 20:31:16,123 iteration 2499 : loss : 0.029380, loss_ce: 0.012944
 37%|█████████▉                 | 147/400 [1:11:00<2:00:47, 28.65s/it]2021-12-11 20:31:17,766 iteration 2500 : loss : 0.038384, loss_ce: 0.014084
2021-12-11 20:31:19,359 iteration 2501 : loss : 0.025102, loss_ce: 0.010702
2021-12-11 20:31:20,947 iteration 2502 : loss : 0.028789, loss_ce: 0.013824
2021-12-11 20:31:22,492 iteration 2503 : loss : 0.031409, loss_ce: 0.015147
2021-12-11 20:31:24,100 iteration 2504 : loss : 0.029934, loss_ce: 0.011044
2021-12-11 20:31:25,676 iteration 2505 : loss : 0.028145, loss_ce: 0.009518
2021-12-11 20:31:27,259 iteration 2506 : loss : 0.026281, loss_ce: 0.010483
2021-12-11 20:31:28,767 iteration 2507 : loss : 0.021489, loss_ce: 0.007947
2021-12-11 20:31:30,236 iteration 2508 : loss : 0.030013, loss_ce: 0.012940
2021-12-11 20:31:31,760 iteration 2509 : loss : 0.028630, loss_ce: 0.014342
2021-12-11 20:31:33,243 iteration 2510 : loss : 0.044990, loss_ce: 0.013555
2021-12-11 20:31:34,783 iteration 2511 : loss : 0.036628, loss_ce: 0.016160
2021-12-11 20:31:36,315 iteration 2512 : loss : 0.023536, loss_ce: 0.008631
2021-12-11 20:31:37,862 iteration 2513 : loss : 0.036902, loss_ce: 0.016599
2021-12-11 20:31:39,432 iteration 2514 : loss : 0.036194, loss_ce: 0.014353
2021-12-11 20:31:40,962 iteration 2515 : loss : 0.027625, loss_ce: 0.007947
2021-12-11 20:31:42,467 iteration 2516 : loss : 0.035708, loss_ce: 0.014558
 37%|█████████▉                 | 148/400 [1:11:27<1:57:24, 27.96s/it]2021-12-11 20:31:44,058 iteration 2517 : loss : 0.028284, loss_ce: 0.010395
2021-12-11 20:31:45,725 iteration 2518 : loss : 0.037926, loss_ce: 0.015331
2021-12-11 20:31:47,283 iteration 2519 : loss : 0.036079, loss_ce: 0.013975
2021-12-11 20:31:48,807 iteration 2520 : loss : 0.028465, loss_ce: 0.009078
2021-12-11 20:31:50,390 iteration 2521 : loss : 0.029791, loss_ce: 0.013328
2021-12-11 20:31:51,881 iteration 2522 : loss : 0.022981, loss_ce: 0.009369
2021-12-11 20:31:53,312 iteration 2523 : loss : 0.041440, loss_ce: 0.010190
2021-12-11 20:31:54,917 iteration 2524 : loss : 0.029984, loss_ce: 0.013295
2021-12-11 20:31:56,426 iteration 2525 : loss : 0.032885, loss_ce: 0.013787
2021-12-11 20:31:57,937 iteration 2526 : loss : 0.027040, loss_ce: 0.010603
2021-12-11 20:31:59,541 iteration 2527 : loss : 0.041285, loss_ce: 0.015666
2021-12-11 20:32:01,063 iteration 2528 : loss : 0.025837, loss_ce: 0.010360
2021-12-11 20:32:02,651 iteration 2529 : loss : 0.031426, loss_ce: 0.013682
2021-12-11 20:32:04,214 iteration 2530 : loss : 0.039945, loss_ce: 0.012174
2021-12-11 20:32:05,755 iteration 2531 : loss : 0.036974, loss_ce: 0.013553
2021-12-11 20:32:07,339 iteration 2532 : loss : 0.032205, loss_ce: 0.011328
2021-12-11 20:32:08,905 iteration 2533 : loss : 0.039021, loss_ce: 0.022759
 37%|██████████                 | 149/400 [1:11:53<1:55:02, 27.50s/it]2021-12-11 20:32:10,463 iteration 2534 : loss : 0.022160, loss_ce: 0.009633
2021-12-11 20:32:12,044 iteration 2535 : loss : 0.026937, loss_ce: 0.007565
2021-12-11 20:32:13,657 iteration 2536 : loss : 0.030492, loss_ce: 0.013300
2021-12-11 20:32:15,277 iteration 2537 : loss : 0.045865, loss_ce: 0.017592
2021-12-11 20:32:16,911 iteration 2538 : loss : 0.040301, loss_ce: 0.015537
2021-12-11 20:32:18,417 iteration 2539 : loss : 0.025267, loss_ce: 0.008997
2021-12-11 20:32:19,959 iteration 2540 : loss : 0.035200, loss_ce: 0.012014
2021-12-11 20:32:21,659 iteration 2541 : loss : 0.062713, loss_ce: 0.017869
2021-12-11 20:32:23,149 iteration 2542 : loss : 0.029949, loss_ce: 0.010415
2021-12-11 20:32:24,708 iteration 2543 : loss : 0.035353, loss_ce: 0.011186
2021-12-11 20:32:26,337 iteration 2544 : loss : 0.036548, loss_ce: 0.014803
2021-12-11 20:32:27,950 iteration 2545 : loss : 0.053327, loss_ce: 0.025332
2021-12-11 20:32:29,453 iteration 2546 : loss : 0.023599, loss_ce: 0.008954
2021-12-11 20:32:31,007 iteration 2547 : loss : 0.048234, loss_ce: 0.011830
2021-12-11 20:32:32,550 iteration 2548 : loss : 0.046778, loss_ce: 0.015204
2021-12-11 20:32:34,168 iteration 2549 : loss : 0.037617, loss_ce: 0.012023
2021-12-11 20:32:34,169 Training Data Eval:
2021-12-11 20:32:41,948   Average segmentation loss on training set: 0.0207
2021-12-11 20:32:41,949 Validation Data Eval:
2021-12-11 20:32:44,607   Average segmentation loss on validation set: 0.0919
2021-12-11 20:32:46,144 iteration 2550 : loss : 0.038730, loss_ce: 0.020608
2021-12-11 20:32:48,136 save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/NEW_TU/UNET_ADAM_seed2epoch_149.pth
 38%|██████████▏                | 150/400 [1:12:32<2:09:10, 31.00s/it]2021-12-11 20:32:49,672 iteration 2551 : loss : 0.027148, loss_ce: 0.009834
2021-12-11 20:32:51,225 iteration 2552 : loss : 0.026104, loss_ce: 0.009837
2021-12-11 20:32:52,865 iteration 2553 : loss : 0.041726, loss_ce: 0.016377
2021-12-11 20:32:54,471 iteration 2554 : loss : 0.045991, loss_ce: 0.011735
2021-12-11 20:32:56,022 iteration 2555 : loss : 0.039869, loss_ce: 0.011375
2021-12-11 20:32:57,502 iteration 2556 : loss : 0.029585, loss_ce: 0.013746
2021-12-11 20:32:59,118 iteration 2557 : loss : 0.040623, loss_ce: 0.014967
2021-12-11 20:33:00,732 iteration 2558 : loss : 0.029378, loss_ce: 0.013621
2021-12-11 20:33:02,360 iteration 2559 : loss : 0.049182, loss_ce: 0.012460
2021-12-11 20:33:03,975 iteration 2560 : loss : 0.033328, loss_ce: 0.012170
2021-12-11 20:33:05,527 iteration 2561 : loss : 0.028207, loss_ce: 0.011714
2021-12-11 20:33:07,037 iteration 2562 : loss : 0.033086, loss_ce: 0.017242
2021-12-11 20:33:08,588 iteration 2563 : loss : 0.024326, loss_ce: 0.008240
2021-12-11 20:33:10,142 iteration 2564 : loss : 0.034902, loss_ce: 0.015791
2021-12-11 20:33:11,694 iteration 2565 : loss : 0.029736, loss_ce: 0.007612
2021-12-11 20:33:13,220 iteration 2566 : loss : 0.023396, loss_ce: 0.010540
2021-12-11 20:33:14,890 iteration 2567 : loss : 0.043979, loss_ce: 0.018631
 38%|██████████▏                | 151/400 [1:12:59<2:03:27, 29.75s/it]2021-12-11 20:33:16,503 iteration 2568 : loss : 0.025410, loss_ce: 0.012121
2021-12-11 20:33:18,060 iteration 2569 : loss : 0.030096, loss_ce: 0.011109
2021-12-11 20:33:19,581 iteration 2570 : loss : 0.042435, loss_ce: 0.012093
2021-12-11 20:33:21,148 iteration 2571 : loss : 0.037063, loss_ce: 0.013867
2021-12-11 20:33:22,634 iteration 2572 : loss : 0.025509, loss_ce: 0.008201
2021-12-11 20:33:24,146 iteration 2573 : loss : 0.022829, loss_ce: 0.008927
2021-12-11 20:33:25,681 iteration 2574 : loss : 0.036531, loss_ce: 0.013217
2021-12-11 20:33:27,273 iteration 2575 : loss : 0.029800, loss_ce: 0.010553
2021-12-11 20:33:28,952 iteration 2576 : loss : 0.034685, loss_ce: 0.015103
2021-12-11 20:33:30,490 iteration 2577 : loss : 0.032846, loss_ce: 0.012189
2021-12-11 20:33:32,079 iteration 2578 : loss : 0.038716, loss_ce: 0.020265
2021-12-11 20:33:33,611 iteration 2579 : loss : 0.032577, loss_ce: 0.010266
2021-12-11 20:33:35,220 iteration 2580 : loss : 0.037096, loss_ce: 0.012196
2021-12-11 20:33:36,906 iteration 2581 : loss : 0.035816, loss_ce: 0.013562
2021-12-11 20:33:38,358 iteration 2582 : loss : 0.029095, loss_ce: 0.011945
2021-12-11 20:33:39,961 iteration 2583 : loss : 0.026702, loss_ce: 0.008872
2021-12-11 20:33:41,487 iteration 2584 : loss : 0.024716, loss_ce: 0.009526
 38%|██████████▎                | 152/400 [1:13:26<1:59:01, 28.80s/it]2021-12-11 20:33:43,168 iteration 2585 : loss : 0.061918, loss_ce: 0.025304
2021-12-11 20:33:44,734 iteration 2586 : loss : 0.035655, loss_ce: 0.015186
2021-12-11 20:33:46,234 iteration 2587 : loss : 0.022611, loss_ce: 0.007607
2021-12-11 20:33:47,764 iteration 2588 : loss : 0.033366, loss_ce: 0.013838
2021-12-11 20:33:49,242 iteration 2589 : loss : 0.029231, loss_ce: 0.011431
2021-12-11 20:33:50,846 iteration 2590 : loss : 0.035953, loss_ce: 0.011900
2021-12-11 20:33:52,399 iteration 2591 : loss : 0.032061, loss_ce: 0.013838
2021-12-11 20:33:53,932 iteration 2592 : loss : 0.024416, loss_ce: 0.009554
2021-12-11 20:33:55,455 iteration 2593 : loss : 0.036569, loss_ce: 0.011545
2021-12-11 20:33:57,051 iteration 2594 : loss : 0.025811, loss_ce: 0.009695
2021-12-11 20:33:58,723 iteration 2595 : loss : 0.043104, loss_ce: 0.013151
2021-12-11 20:34:00,211 iteration 2596 : loss : 0.021566, loss_ce: 0.006983
2021-12-11 20:34:01,810 iteration 2597 : loss : 0.076964, loss_ce: 0.018135
2021-12-11 20:34:03,335 iteration 2598 : loss : 0.028768, loss_ce: 0.012541
2021-12-11 20:34:04,935 iteration 2599 : loss : 0.027996, loss_ce: 0.012602
2021-12-11 20:34:06,487 iteration 2600 : loss : 0.067162, loss_ce: 0.021201
2021-12-11 20:34:08,059 iteration 2601 : loss : 0.043839, loss_ce: 0.017197
 38%|██████████▎                | 153/400 [1:13:52<1:55:49, 28.13s/it]2021-12-11 20:34:09,695 iteration 2602 : loss : 0.050231, loss_ce: 0.016113
2021-12-11 20:34:11,354 iteration 2603 : loss : 0.053059, loss_ce: 0.017487
2021-12-11 20:34:12,918 iteration 2604 : loss : 0.033342, loss_ce: 0.013960
2021-12-11 20:34:14,344 iteration 2605 : loss : 0.024384, loss_ce: 0.007027
2021-12-11 20:34:16,052 iteration 2606 : loss : 0.050176, loss_ce: 0.014931
2021-12-11 20:34:17,656 iteration 2607 : loss : 0.036343, loss_ce: 0.012425
2021-12-11 20:34:19,221 iteration 2608 : loss : 0.037452, loss_ce: 0.016234
2021-12-11 20:34:20,883 iteration 2609 : loss : 0.043026, loss_ce: 0.015136
2021-12-11 20:34:22,521 iteration 2610 : loss : 0.033178, loss_ce: 0.010767
2021-12-11 20:34:24,116 iteration 2611 : loss : 0.039031, loss_ce: 0.013910
2021-12-11 20:34:25,737 iteration 2612 : loss : 0.038989, loss_ce: 0.018825
2021-12-11 20:34:27,247 iteration 2613 : loss : 0.028667, loss_ce: 0.012087
2021-12-11 20:34:28,889 iteration 2614 : loss : 0.047338, loss_ce: 0.015402
2021-12-11 20:34:30,419 iteration 2615 : loss : 0.048492, loss_ce: 0.018795
2021-12-11 20:34:32,019 iteration 2616 : loss : 0.033624, loss_ce: 0.016630
2021-12-11 20:34:33,571 iteration 2617 : loss : 0.030122, loss_ce: 0.009338
2021-12-11 20:34:35,084 iteration 2618 : loss : 0.029773, loss_ce: 0.011919
 38%|██████████▍                | 154/400 [1:14:19<1:53:58, 27.80s/it]2021-12-11 20:34:36,672 iteration 2619 : loss : 0.040577, loss_ce: 0.014979
2021-12-11 20:34:38,200 iteration 2620 : loss : 0.025582, loss_ce: 0.011068
2021-12-11 20:34:39,821 iteration 2621 : loss : 0.048004, loss_ce: 0.017403
2021-12-11 20:34:41,366 iteration 2622 : loss : 0.048852, loss_ce: 0.012754
2021-12-11 20:34:42,952 iteration 2623 : loss : 0.043694, loss_ce: 0.020032
2021-12-11 20:34:44,458 iteration 2624 : loss : 0.024519, loss_ce: 0.007220
2021-12-11 20:34:46,065 iteration 2625 : loss : 0.055070, loss_ce: 0.008947
2021-12-11 20:34:47,651 iteration 2626 : loss : 0.045808, loss_ce: 0.019999
2021-12-11 20:34:49,370 iteration 2627 : loss : 0.042057, loss_ce: 0.013862
2021-12-11 20:34:50,871 iteration 2628 : loss : 0.035216, loss_ce: 0.014785
2021-12-11 20:34:52,505 iteration 2629 : loss : 0.034457, loss_ce: 0.014590
2021-12-11 20:34:54,088 iteration 2630 : loss : 0.032953, loss_ce: 0.013448
2021-12-11 20:34:55,660 iteration 2631 : loss : 0.037227, loss_ce: 0.016770
2021-12-11 20:34:57,215 iteration 2632 : loss : 0.026807, loss_ce: 0.009685
2021-12-11 20:34:58,811 iteration 2633 : loss : 0.038645, loss_ce: 0.020523
2021-12-11 20:35:00,387 iteration 2634 : loss : 0.037788, loss_ce: 0.012362
2021-12-11 20:35:00,388 Training Data Eval:
2021-12-11 20:35:08,135   Average segmentation loss on training set: 0.0246
2021-12-11 20:35:08,136 Validation Data Eval:
2021-12-11 20:35:10,793   Average segmentation loss on validation set: 0.0913
2021-12-11 20:35:12,350 iteration 2635 : loss : 0.031196, loss_ce: 0.012372
 39%|██████████▍                | 155/400 [1:14:57<2:05:06, 30.64s/it]2021-12-11 20:35:13,973 iteration 2636 : loss : 0.036141, loss_ce: 0.015462
2021-12-11 20:35:15,623 iteration 2637 : loss : 0.033410, loss_ce: 0.013026
2021-12-11 20:35:17,160 iteration 2638 : loss : 0.034045, loss_ce: 0.011471
2021-12-11 20:35:18,664 iteration 2639 : loss : 0.026149, loss_ce: 0.012270
2021-12-11 20:35:20,198 iteration 2640 : loss : 0.027761, loss_ce: 0.009384
2021-12-11 20:35:21,742 iteration 2641 : loss : 0.034339, loss_ce: 0.015794
2021-12-11 20:35:23,250 iteration 2642 : loss : 0.022233, loss_ce: 0.008100
2021-12-11 20:35:24,935 iteration 2643 : loss : 0.026961, loss_ce: 0.009709
2021-12-11 20:35:26,474 iteration 2644 : loss : 0.028303, loss_ce: 0.010597
2021-12-11 20:35:27,986 iteration 2645 : loss : 0.027605, loss_ce: 0.008796
2021-12-11 20:35:29,742 iteration 2646 : loss : 0.031675, loss_ce: 0.011065
2021-12-11 20:35:31,387 iteration 2647 : loss : 0.042345, loss_ce: 0.017131
2021-12-11 20:35:32,927 iteration 2648 : loss : 0.031572, loss_ce: 0.012963
2021-12-11 20:35:34,518 iteration 2649 : loss : 0.034047, loss_ce: 0.013385
2021-12-11 20:35:36,159 iteration 2650 : loss : 0.025654, loss_ce: 0.008051
2021-12-11 20:35:37,765 iteration 2651 : loss : 0.030090, loss_ce: 0.013070
2021-12-11 20:35:39,272 iteration 2652 : loss : 0.027012, loss_ce: 0.009821
 39%|██████████▌                | 156/400 [1:15:24<2:00:04, 29.53s/it]2021-12-11 20:35:40,968 iteration 2653 : loss : 0.026836, loss_ce: 0.011966
2021-12-11 20:35:42,562 iteration 2654 : loss : 0.031576, loss_ce: 0.010680
2021-12-11 20:35:44,237 iteration 2655 : loss : 0.032773, loss_ce: 0.016110
2021-12-11 20:35:45,789 iteration 2656 : loss : 0.030785, loss_ce: 0.010607
2021-12-11 20:35:47,347 iteration 2657 : loss : 0.030970, loss_ce: 0.011668
2021-12-11 20:35:48,785 iteration 2658 : loss : 0.025130, loss_ce: 0.011024
2021-12-11 20:35:50,288 iteration 2659 : loss : 0.036592, loss_ce: 0.009151
2021-12-11 20:35:51,902 iteration 2660 : loss : 0.032142, loss_ce: 0.010014
2021-12-11 20:35:53,432 iteration 2661 : loss : 0.026387, loss_ce: 0.011053
2021-12-11 20:35:54,993 iteration 2662 : loss : 0.032392, loss_ce: 0.014627
2021-12-11 20:35:56,524 iteration 2663 : loss : 0.037958, loss_ce: 0.010118
2021-12-11 20:35:58,206 iteration 2664 : loss : 0.032892, loss_ce: 0.012629
2021-12-11 20:35:59,785 iteration 2665 : loss : 0.036109, loss_ce: 0.014160
2021-12-11 20:36:01,310 iteration 2666 : loss : 0.020654, loss_ce: 0.006867
2021-12-11 20:36:02,951 iteration 2667 : loss : 0.034932, loss_ce: 0.012654
2021-12-11 20:36:04,475 iteration 2668 : loss : 0.027235, loss_ce: 0.009463
2021-12-11 20:36:06,011 iteration 2669 : loss : 0.026702, loss_ce: 0.008865
 39%|██████████▌                | 157/400 [1:15:50<1:56:11, 28.69s/it]2021-12-11 20:36:07,675 iteration 2670 : loss : 0.034861, loss_ce: 0.015566
2021-12-11 20:36:09,378 iteration 2671 : loss : 0.037770, loss_ce: 0.011930
2021-12-11 20:36:10,990 iteration 2672 : loss : 0.024151, loss_ce: 0.009124
2021-12-11 20:36:12,503 iteration 2673 : loss : 0.025855, loss_ce: 0.012692
2021-12-11 20:36:14,108 iteration 2674 : loss : 0.033882, loss_ce: 0.015016
2021-12-11 20:36:15,544 iteration 2675 : loss : 0.020125, loss_ce: 0.008293
2021-12-11 20:36:17,238 iteration 2676 : loss : 0.034920, loss_ce: 0.008399
2021-12-11 20:36:18,846 iteration 2677 : loss : 0.032513, loss_ce: 0.012271
2021-12-11 20:36:20,412 iteration 2678 : loss : 0.027381, loss_ce: 0.011639
2021-12-11 20:36:21,961 iteration 2679 : loss : 0.031313, loss_ce: 0.009610
2021-12-11 20:36:23,520 iteration 2680 : loss : 0.022712, loss_ce: 0.008776
2021-12-11 20:36:25,098 iteration 2681 : loss : 0.030544, loss_ce: 0.009791
2021-12-11 20:36:26,678 iteration 2682 : loss : 0.040063, loss_ce: 0.013246
2021-12-11 20:36:28,228 iteration 2683 : loss : 0.042222, loss_ce: 0.011759
2021-12-11 20:36:29,727 iteration 2684 : loss : 0.031388, loss_ce: 0.014319
2021-12-11 20:36:31,300 iteration 2685 : loss : 0.026002, loss_ce: 0.010518
2021-12-11 20:36:32,797 iteration 2686 : loss : 0.032151, loss_ce: 0.014268
 40%|██████████▋                | 158/400 [1:16:17<1:53:24, 28.12s/it]2021-12-11 20:36:34,319 iteration 2687 : loss : 0.029720, loss_ce: 0.008049
2021-12-11 20:36:35,875 iteration 2688 : loss : 0.038952, loss_ce: 0.013741
2021-12-11 20:36:37,402 iteration 2689 : loss : 0.028367, loss_ce: 0.010383
2021-12-11 20:36:39,081 iteration 2690 : loss : 0.036016, loss_ce: 0.015814
2021-12-11 20:36:40,586 iteration 2691 : loss : 0.029314, loss_ce: 0.011098
2021-12-11 20:36:42,092 iteration 2692 : loss : 0.029452, loss_ce: 0.008539
2021-12-11 20:36:43,661 iteration 2693 : loss : 0.032261, loss_ce: 0.011537
2021-12-11 20:36:45,307 iteration 2694 : loss : 0.033771, loss_ce: 0.011248
2021-12-11 20:36:46,833 iteration 2695 : loss : 0.030535, loss_ce: 0.011851
2021-12-11 20:36:48,409 iteration 2696 : loss : 0.026288, loss_ce: 0.010877
2021-12-11 20:36:49,898 iteration 2697 : loss : 0.021212, loss_ce: 0.008499
2021-12-11 20:36:51,306 iteration 2698 : loss : 0.021147, loss_ce: 0.009321
2021-12-11 20:36:52,873 iteration 2699 : loss : 0.043049, loss_ce: 0.016840
2021-12-11 20:36:54,500 iteration 2700 : loss : 0.029309, loss_ce: 0.013764
2021-12-11 20:36:56,061 iteration 2701 : loss : 0.033786, loss_ce: 0.013421
2021-12-11 20:36:57,653 iteration 2702 : loss : 0.057718, loss_ce: 0.009420
2021-12-11 20:36:59,203 iteration 2703 : loss : 0.023690, loss_ce: 0.008346
 40%|██████████▋                | 159/400 [1:16:44<1:50:52, 27.61s/it]2021-12-11 20:37:00,944 iteration 2704 : loss : 0.036161, loss_ce: 0.013696
2021-12-11 20:37:02,450 iteration 2705 : loss : 0.042504, loss_ce: 0.014230
2021-12-11 20:37:03,961 iteration 2706 : loss : 0.039843, loss_ce: 0.021269
2021-12-11 20:37:05,599 iteration 2707 : loss : 0.034385, loss_ce: 0.013151
2021-12-11 20:37:07,072 iteration 2708 : loss : 0.021863, loss_ce: 0.008761
2021-12-11 20:37:08,626 iteration 2709 : loss : 0.035313, loss_ce: 0.009149
2021-12-11 20:37:10,123 iteration 2710 : loss : 0.025239, loss_ce: 0.008521
2021-12-11 20:37:11,793 iteration 2711 : loss : 0.043629, loss_ce: 0.014724
2021-12-11 20:37:13,282 iteration 2712 : loss : 0.022237, loss_ce: 0.008301
2021-12-11 20:37:14,959 iteration 2713 : loss : 0.055389, loss_ce: 0.019355
2021-12-11 20:37:16,451 iteration 2714 : loss : 0.026579, loss_ce: 0.008736
2021-12-11 20:37:18,026 iteration 2715 : loss : 0.039326, loss_ce: 0.021549
2021-12-11 20:37:19,545 iteration 2716 : loss : 0.032243, loss_ce: 0.011959
2021-12-11 20:37:21,041 iteration 2717 : loss : 0.025346, loss_ce: 0.012219
2021-12-11 20:37:22,541 iteration 2718 : loss : 0.029361, loss_ce: 0.010990
2021-12-11 20:37:24,169 iteration 2719 : loss : 0.055982, loss_ce: 0.019148
2021-12-11 20:37:24,169 Training Data Eval:
2021-12-11 20:37:31,916   Average segmentation loss on training set: 0.0210
2021-12-11 20:37:31,917 Validation Data Eval:
2021-12-11 20:37:34,563   Average segmentation loss on validation set: 0.0875
2021-12-11 20:37:36,041 iteration 2720 : loss : 0.020756, loss_ce: 0.008603
 40%|██████████▊                | 160/400 [1:17:20<2:01:29, 30.37s/it]2021-12-11 20:37:37,675 iteration 2721 : loss : 0.035159, loss_ce: 0.014766
2021-12-11 20:37:39,264 iteration 2722 : loss : 0.030961, loss_ce: 0.012576
2021-12-11 20:37:40,856 iteration 2723 : loss : 0.021370, loss_ce: 0.008122
2021-12-11 20:37:42,350 iteration 2724 : loss : 0.035000, loss_ce: 0.010540
2021-12-11 20:37:43,797 iteration 2725 : loss : 0.027208, loss_ce: 0.009803
2021-12-11 20:37:45,321 iteration 2726 : loss : 0.032348, loss_ce: 0.011201
2021-12-11 20:37:46,801 iteration 2727 : loss : 0.022387, loss_ce: 0.007200
2021-12-11 20:37:48,474 iteration 2728 : loss : 0.029598, loss_ce: 0.015533
2021-12-11 20:37:50,042 iteration 2729 : loss : 0.042107, loss_ce: 0.015911
2021-12-11 20:37:51,640 iteration 2730 : loss : 0.025015, loss_ce: 0.009949
2021-12-11 20:37:53,230 iteration 2731 : loss : 0.036594, loss_ce: 0.014081
2021-12-11 20:37:54,895 iteration 2732 : loss : 0.038460, loss_ce: 0.014579
2021-12-11 20:37:56,491 iteration 2733 : loss : 0.080933, loss_ce: 0.031304
2021-12-11 20:37:58,070 iteration 2734 : loss : 0.030927, loss_ce: 0.008202
2021-12-11 20:37:59,522 iteration 2735 : loss : 0.029652, loss_ce: 0.011752
2021-12-11 20:38:01,146 iteration 2736 : loss : 0.044597, loss_ce: 0.022495
2021-12-11 20:38:02,680 iteration 2737 : loss : 0.027349, loss_ce: 0.009848
 40%|██████████▊                | 161/400 [1:17:47<1:56:31, 29.25s/it]2021-12-11 20:38:04,279 iteration 2738 : loss : 0.028365, loss_ce: 0.012838
2021-12-11 20:38:05,809 iteration 2739 : loss : 0.040078, loss_ce: 0.018753
2021-12-11 20:38:07,382 iteration 2740 : loss : 0.045427, loss_ce: 0.014384
2021-12-11 20:38:08,961 iteration 2741 : loss : 0.026099, loss_ce: 0.008207
2021-12-11 20:38:10,433 iteration 2742 : loss : 0.027641, loss_ce: 0.010195
2021-12-11 20:38:11,993 iteration 2743 : loss : 0.039525, loss_ce: 0.019313
2021-12-11 20:38:13,585 iteration 2744 : loss : 0.031278, loss_ce: 0.011543
2021-12-11 20:38:15,158 iteration 2745 : loss : 0.035248, loss_ce: 0.012197
2021-12-11 20:38:16,655 iteration 2746 : loss : 0.056678, loss_ce: 0.013804
2021-12-11 20:38:18,225 iteration 2747 : loss : 0.032541, loss_ce: 0.008955
2021-12-11 20:38:19,833 iteration 2748 : loss : 0.031355, loss_ce: 0.009825
2021-12-11 20:38:21,310 iteration 2749 : loss : 0.036038, loss_ce: 0.014287
2021-12-11 20:38:22,902 iteration 2750 : loss : 0.057976, loss_ce: 0.018613
2021-12-11 20:38:24,419 iteration 2751 : loss : 0.021385, loss_ce: 0.008480
2021-12-11 20:38:25,889 iteration 2752 : loss : 0.053306, loss_ce: 0.008331
2021-12-11 20:38:27,541 iteration 2753 : loss : 0.036761, loss_ce: 0.015069
2021-12-11 20:38:29,149 iteration 2754 : loss : 0.039963, loss_ce: 0.015960
 40%|██████████▉                | 162/400 [1:18:13<1:52:43, 28.42s/it]2021-12-11 20:38:30,770 iteration 2755 : loss : 0.026526, loss_ce: 0.012141
2021-12-11 20:38:32,332 iteration 2756 : loss : 0.043387, loss_ce: 0.023108
2021-12-11 20:38:33,885 iteration 2757 : loss : 0.053365, loss_ce: 0.020622
2021-12-11 20:38:35,507 iteration 2758 : loss : 0.047870, loss_ce: 0.016929
2021-12-11 20:38:37,071 iteration 2759 : loss : 0.055335, loss_ce: 0.015980
2021-12-11 20:38:38,626 iteration 2760 : loss : 0.037750, loss_ce: 0.014448
2021-12-11 20:38:40,090 iteration 2761 : loss : 0.041919, loss_ce: 0.014301
2021-12-11 20:38:41,568 iteration 2762 : loss : 0.025273, loss_ce: 0.009752
2021-12-11 20:38:43,168 iteration 2763 : loss : 0.044134, loss_ce: 0.013584
2021-12-11 20:38:44,714 iteration 2764 : loss : 0.034808, loss_ce: 0.012277
2021-12-11 20:38:46,275 iteration 2765 : loss : 0.047249, loss_ce: 0.016637
2021-12-11 20:38:47,796 iteration 2766 : loss : 0.028540, loss_ce: 0.009671
2021-12-11 20:38:49,374 iteration 2767 : loss : 0.035421, loss_ce: 0.011382
2021-12-11 20:38:50,894 iteration 2768 : loss : 0.030979, loss_ce: 0.007574
2021-12-11 20:38:52,445 iteration 2769 : loss : 0.031967, loss_ce: 0.011642
2021-12-11 20:38:54,003 iteration 2770 : loss : 0.038336, loss_ce: 0.019560
2021-12-11 20:38:55,538 iteration 2771 : loss : 0.037142, loss_ce: 0.010430
 41%|███████████                | 163/400 [1:18:40<1:49:51, 27.81s/it]2021-12-11 20:38:57,223 iteration 2772 : loss : 0.030195, loss_ce: 0.013704
2021-12-11 20:38:58,719 iteration 2773 : loss : 0.025123, loss_ce: 0.009825
2021-12-11 20:39:00,202 iteration 2774 : loss : 0.040068, loss_ce: 0.010326
2021-12-11 20:39:01,720 iteration 2775 : loss : 0.033677, loss_ce: 0.011772
2021-12-11 20:39:03,234 iteration 2776 : loss : 0.022501, loss_ce: 0.008046
2021-12-11 20:39:04,790 iteration 2777 : loss : 0.026615, loss_ce: 0.009402
2021-12-11 20:39:06,433 iteration 2778 : loss : 0.038209, loss_ce: 0.013967
2021-12-11 20:39:08,118 iteration 2779 : loss : 0.031681, loss_ce: 0.012357
2021-12-11 20:39:09,627 iteration 2780 : loss : 0.021498, loss_ce: 0.006972
2021-12-11 20:39:11,219 iteration 2781 : loss : 0.037364, loss_ce: 0.012587
2021-12-11 20:39:12,764 iteration 2782 : loss : 0.029434, loss_ce: 0.010296
2021-12-11 20:39:14,271 iteration 2783 : loss : 0.043604, loss_ce: 0.020860
2021-12-11 20:39:15,953 iteration 2784 : loss : 0.041832, loss_ce: 0.015348
2021-12-11 20:39:17,582 iteration 2785 : loss : 0.039703, loss_ce: 0.011188
2021-12-11 20:39:19,180 iteration 2786 : loss : 0.033128, loss_ce: 0.016071
2021-12-11 20:39:20,788 iteration 2787 : loss : 0.024031, loss_ce: 0.010023
2021-12-11 20:39:22,308 iteration 2788 : loss : 0.029311, loss_ce: 0.014565
 41%|███████████                | 164/400 [1:19:07<1:48:09, 27.50s/it]2021-12-11 20:39:23,895 iteration 2789 : loss : 0.032668, loss_ce: 0.012390
2021-12-11 20:39:25,485 iteration 2790 : loss : 0.027791, loss_ce: 0.008760
2021-12-11 20:39:27,007 iteration 2791 : loss : 0.029321, loss_ce: 0.012101
2021-12-11 20:39:28,628 iteration 2792 : loss : 0.067728, loss_ce: 0.023067
2021-12-11 20:39:30,132 iteration 2793 : loss : 0.030064, loss_ce: 0.011488
2021-12-11 20:39:31,727 iteration 2794 : loss : 0.030855, loss_ce: 0.010922
2021-12-11 20:39:33,227 iteration 2795 : loss : 0.027530, loss_ce: 0.009545
2021-12-11 20:39:34,818 iteration 2796 : loss : 0.030780, loss_ce: 0.010844
2021-12-11 20:39:36,407 iteration 2797 : loss : 0.029789, loss_ce: 0.012504
2021-12-11 20:39:38,028 iteration 2798 : loss : 0.045120, loss_ce: 0.023619
2021-12-11 20:39:39,536 iteration 2799 : loss : 0.021415, loss_ce: 0.009967
2021-12-11 20:39:41,026 iteration 2800 : loss : 0.044555, loss_ce: 0.013425
2021-12-11 20:39:42,508 iteration 2801 : loss : 0.021444, loss_ce: 0.006798
2021-12-11 20:39:44,113 iteration 2802 : loss : 0.030976, loss_ce: 0.010574
2021-12-11 20:39:45,655 iteration 2803 : loss : 0.028659, loss_ce: 0.011683
2021-12-11 20:39:47,176 iteration 2804 : loss : 0.027431, loss_ce: 0.009057
2021-12-11 20:39:47,176 Training Data Eval:
2021-12-11 20:39:54,911   Average segmentation loss on training set: 0.0199
2021-12-11 20:39:54,912 Validation Data Eval:
2021-12-11 20:39:57,559   Average segmentation loss on validation set: 0.1013
2021-12-11 20:39:59,070 iteration 2805 : loss : 0.025636, loss_ce: 0.010360
 41%|███████████▏               | 165/400 [1:19:43<1:58:34, 30.28s/it]2021-12-11 20:40:00,811 iteration 2806 : loss : 0.029052, loss_ce: 0.011826
2021-12-11 20:40:02,292 iteration 2807 : loss : 0.027652, loss_ce: 0.009882
2021-12-11 20:40:03,786 iteration 2808 : loss : 0.023005, loss_ce: 0.008797
2021-12-11 20:40:05,366 iteration 2809 : loss : 0.021375, loss_ce: 0.007474
2021-12-11 20:40:06,897 iteration 2810 : loss : 0.027633, loss_ce: 0.011884
2021-12-11 20:40:08,538 iteration 2811 : loss : 0.034572, loss_ce: 0.011097
2021-12-11 20:40:10,208 iteration 2812 : loss : 0.032349, loss_ce: 0.011800
2021-12-11 20:40:11,673 iteration 2813 : loss : 0.027327, loss_ce: 0.009751
2021-12-11 20:40:13,241 iteration 2814 : loss : 0.029002, loss_ce: 0.013924
2021-12-11 20:40:14,843 iteration 2815 : loss : 0.030118, loss_ce: 0.012034
2021-12-11 20:40:16,378 iteration 2816 : loss : 0.030566, loss_ce: 0.011775
2021-12-11 20:40:17,915 iteration 2817 : loss : 0.033381, loss_ce: 0.014941
2021-12-11 20:40:19,581 iteration 2818 : loss : 0.032419, loss_ce: 0.010142
2021-12-11 20:40:21,211 iteration 2819 : loss : 0.025919, loss_ce: 0.010582
2021-12-11 20:40:22,744 iteration 2820 : loss : 0.028674, loss_ce: 0.011308
2021-12-11 20:40:24,299 iteration 2821 : loss : 0.020990, loss_ce: 0.008298
2021-12-11 20:40:25,918 iteration 2822 : loss : 0.040387, loss_ce: 0.009306
 42%|███████████▏               | 166/400 [1:20:10<1:54:03, 29.25s/it]2021-12-11 20:40:27,568 iteration 2823 : loss : 0.025974, loss_ce: 0.008684
2021-12-11 20:40:29,158 iteration 2824 : loss : 0.039887, loss_ce: 0.010055
2021-12-11 20:40:30,745 iteration 2825 : loss : 0.041639, loss_ce: 0.015655
2021-12-11 20:40:32,253 iteration 2826 : loss : 0.020306, loss_ce: 0.007174
2021-12-11 20:40:33,856 iteration 2827 : loss : 0.025649, loss_ce: 0.010565
2021-12-11 20:40:35,395 iteration 2828 : loss : 0.026248, loss_ce: 0.009994
2021-12-11 20:40:36,920 iteration 2829 : loss : 0.037703, loss_ce: 0.011013
2021-12-11 20:40:38,503 iteration 2830 : loss : 0.026783, loss_ce: 0.012159
2021-12-11 20:40:40,044 iteration 2831 : loss : 0.039263, loss_ce: 0.010088
2021-12-11 20:40:41,535 iteration 2832 : loss : 0.025668, loss_ce: 0.010018
2021-12-11 20:40:43,169 iteration 2833 : loss : 0.023632, loss_ce: 0.009538
2021-12-11 20:40:44,742 iteration 2834 : loss : 0.030688, loss_ce: 0.012758
2021-12-11 20:40:46,323 iteration 2835 : loss : 0.048463, loss_ce: 0.021367
2021-12-11 20:40:47,914 iteration 2836 : loss : 0.034210, loss_ce: 0.013130
2021-12-11 20:40:49,529 iteration 2837 : loss : 0.027090, loss_ce: 0.009434
2021-12-11 20:40:51,125 iteration 2838 : loss : 0.029612, loss_ce: 0.010670
2021-12-11 20:40:52,617 iteration 2839 : loss : 0.026042, loss_ce: 0.010805
 42%|███████████▎               | 167/400 [1:20:37<1:50:36, 28.48s/it]2021-12-11 20:40:54,213 iteration 2840 : loss : 0.034358, loss_ce: 0.011329
2021-12-11 20:40:55,725 iteration 2841 : loss : 0.026556, loss_ce: 0.012740
2021-12-11 20:40:57,193 iteration 2842 : loss : 0.019283, loss_ce: 0.006687
2021-12-11 20:40:58,722 iteration 2843 : loss : 0.028202, loss_ce: 0.008288
2021-12-11 20:41:00,327 iteration 2844 : loss : 0.037710, loss_ce: 0.016222
2021-12-11 20:41:01,947 iteration 2845 : loss : 0.027835, loss_ce: 0.010058
2021-12-11 20:41:03,490 iteration 2846 : loss : 0.037631, loss_ce: 0.011761
2021-12-11 20:41:05,059 iteration 2847 : loss : 0.034916, loss_ce: 0.013141
2021-12-11 20:41:06,692 iteration 2848 : loss : 0.033616, loss_ce: 0.015698
2021-12-11 20:41:08,212 iteration 2849 : loss : 0.026889, loss_ce: 0.008187
2021-12-11 20:41:09,734 iteration 2850 : loss : 0.026262, loss_ce: 0.007902
2021-12-11 20:41:11,297 iteration 2851 : loss : 0.035454, loss_ce: 0.016108
2021-12-11 20:41:12,861 iteration 2852 : loss : 0.047281, loss_ce: 0.021102
2021-12-11 20:41:14,376 iteration 2853 : loss : 0.026246, loss_ce: 0.011591
2021-12-11 20:41:15,976 iteration 2854 : loss : 0.027983, loss_ce: 0.012059
2021-12-11 20:41:17,530 iteration 2855 : loss : 0.038501, loss_ce: 0.016265
2021-12-11 20:41:19,152 iteration 2856 : loss : 0.025709, loss_ce: 0.010008
 42%|███████████▎               | 168/400 [1:21:03<1:47:52, 27.90s/it]2021-12-11 20:41:20,845 iteration 2857 : loss : 0.053601, loss_ce: 0.012906
2021-12-11 20:41:22,425 iteration 2858 : loss : 0.033199, loss_ce: 0.009880
2021-12-11 20:41:23,926 iteration 2859 : loss : 0.022421, loss_ce: 0.007712
2021-12-11 20:41:25,553 iteration 2860 : loss : 0.042330, loss_ce: 0.017980
2021-12-11 20:41:27,067 iteration 2861 : loss : 0.025510, loss_ce: 0.008357
2021-12-11 20:41:28,659 iteration 2862 : loss : 0.026435, loss_ce: 0.009162
2021-12-11 20:41:30,286 iteration 2863 : loss : 0.037000, loss_ce: 0.012133
2021-12-11 20:41:31,850 iteration 2864 : loss : 0.025000, loss_ce: 0.011535
2021-12-11 20:41:33,338 iteration 2865 : loss : 0.026949, loss_ce: 0.009692
2021-12-11 20:41:34,878 iteration 2866 : loss : 0.022886, loss_ce: 0.006691
2021-12-11 20:41:36,505 iteration 2867 : loss : 0.028084, loss_ce: 0.010995
2021-12-11 20:41:38,116 iteration 2868 : loss : 0.026303, loss_ce: 0.011012
2021-12-11 20:41:39,627 iteration 2869 : loss : 0.027595, loss_ce: 0.012583
2021-12-11 20:41:41,199 iteration 2870 : loss : 0.037424, loss_ce: 0.016079
2021-12-11 20:41:42,662 iteration 2871 : loss : 0.019965, loss_ce: 0.009395
2021-12-11 20:41:44,219 iteration 2872 : loss : 0.060526, loss_ce: 0.021331
2021-12-11 20:41:45,833 iteration 2873 : loss : 0.035410, loss_ce: 0.017500
 42%|███████████▍               | 169/400 [1:21:30<1:46:01, 27.54s/it]2021-12-11 20:41:47,461 iteration 2874 : loss : 0.038355, loss_ce: 0.011475
2021-12-11 20:41:48,924 iteration 2875 : loss : 0.020674, loss_ce: 0.008145
2021-12-11 20:41:50,446 iteration 2876 : loss : 0.023824, loss_ce: 0.009412
2021-12-11 20:41:52,026 iteration 2877 : loss : 0.032458, loss_ce: 0.010759
2021-12-11 20:41:53,615 iteration 2878 : loss : 0.040964, loss_ce: 0.014583
2021-12-11 20:41:55,112 iteration 2879 : loss : 0.031028, loss_ce: 0.014577
2021-12-11 20:41:56,759 iteration 2880 : loss : 0.051305, loss_ce: 0.023979
2021-12-11 20:41:58,307 iteration 2881 : loss : 0.030287, loss_ce: 0.014378
2021-12-11 20:41:59,983 iteration 2882 : loss : 0.085386, loss_ce: 0.027206
2021-12-11 20:42:01,648 iteration 2883 : loss : 0.039850, loss_ce: 0.017998
2021-12-11 20:42:03,307 iteration 2884 : loss : 0.029919, loss_ce: 0.009553
2021-12-11 20:42:04,884 iteration 2885 : loss : 0.029890, loss_ce: 0.013309
2021-12-11 20:42:06,397 iteration 2886 : loss : 0.035815, loss_ce: 0.010334
2021-12-11 20:42:07,956 iteration 2887 : loss : 0.028116, loss_ce: 0.010935
2021-12-11 20:42:09,633 iteration 2888 : loss : 0.040086, loss_ce: 0.013838
2021-12-11 20:42:11,217 iteration 2889 : loss : 0.046930, loss_ce: 0.020543
2021-12-11 20:42:11,218 Training Data Eval:
2021-12-11 20:42:18,951   Average segmentation loss on training set: 0.0354
2021-12-11 20:42:18,952 Validation Data Eval:
2021-12-11 20:42:21,594   Average segmentation loss on validation set: 0.1821
2021-12-11 20:42:23,191 iteration 2890 : loss : 0.038710, loss_ce: 0.015903
 42%|███████████▍               | 170/400 [1:22:08<1:56:50, 30.48s/it]2021-12-11 20:42:24,881 iteration 2891 : loss : 0.035841, loss_ce: 0.018154
2021-12-11 20:42:26,377 iteration 2892 : loss : 0.033533, loss_ce: 0.016455
2021-12-11 20:42:27,917 iteration 2893 : loss : 0.056837, loss_ce: 0.018845
2021-12-11 20:42:29,516 iteration 2894 : loss : 0.028061, loss_ce: 0.010664
2021-12-11 20:42:31,049 iteration 2895 : loss : 0.028639, loss_ce: 0.009723
2021-12-11 20:42:32,557 iteration 2896 : loss : 0.039469, loss_ce: 0.016023
2021-12-11 20:42:34,114 iteration 2897 : loss : 0.035482, loss_ce: 0.012735
2021-12-11 20:42:35,668 iteration 2898 : loss : 0.040559, loss_ce: 0.021160
2021-12-11 20:42:37,276 iteration 2899 : loss : 0.048806, loss_ce: 0.018576
2021-12-11 20:42:38,774 iteration 2900 : loss : 0.028182, loss_ce: 0.009542
2021-12-11 20:42:40,429 iteration 2901 : loss : 0.029636, loss_ce: 0.011891
2021-12-11 20:42:41,874 iteration 2902 : loss : 0.028875, loss_ce: 0.009078
2021-12-11 20:42:43,465 iteration 2903 : loss : 0.030039, loss_ce: 0.012640
2021-12-11 20:42:45,089 iteration 2904 : loss : 0.049096, loss_ce: 0.015433
2021-12-11 20:42:46,643 iteration 2905 : loss : 0.042216, loss_ce: 0.013747
2021-12-11 20:42:48,262 iteration 2906 : loss : 0.039120, loss_ce: 0.014244
2021-12-11 20:42:49,774 iteration 2907 : loss : 0.025940, loss_ce: 0.010451
 43%|███████████▌               | 171/400 [1:22:34<1:51:52, 29.31s/it]2021-12-11 20:42:51,392 iteration 2908 : loss : 0.030286, loss_ce: 0.011092
2021-12-11 20:42:52,874 iteration 2909 : loss : 0.032183, loss_ce: 0.007372
2021-12-11 20:42:54,470 iteration 2910 : loss : 0.031733, loss_ce: 0.010295
2021-12-11 20:42:56,042 iteration 2911 : loss : 0.030003, loss_ce: 0.010736
2021-12-11 20:42:57,602 iteration 2912 : loss : 0.025410, loss_ce: 0.008965
2021-12-11 20:42:59,213 iteration 2913 : loss : 0.035186, loss_ce: 0.016374
2021-12-11 20:43:00,785 iteration 2914 : loss : 0.036975, loss_ce: 0.015056
2021-12-11 20:43:02,413 iteration 2915 : loss : 0.030579, loss_ce: 0.011930
2021-12-11 20:43:03,912 iteration 2916 : loss : 0.027888, loss_ce: 0.013588
2021-12-11 20:43:05,543 iteration 2917 : loss : 0.042387, loss_ce: 0.017247
2021-12-11 20:43:07,133 iteration 2918 : loss : 0.034891, loss_ce: 0.011405
2021-12-11 20:43:08,741 iteration 2919 : loss : 0.049394, loss_ce: 0.024869
2021-12-11 20:43:10,336 iteration 2920 : loss : 0.034220, loss_ce: 0.009565
2021-12-11 20:43:11,981 iteration 2921 : loss : 0.034062, loss_ce: 0.010807
2021-12-11 20:43:13,539 iteration 2922 : loss : 0.027672, loss_ce: 0.010865
2021-12-11 20:43:15,147 iteration 2923 : loss : 0.034546, loss_ce: 0.013503
2021-12-11 20:43:16,688 iteration 2924 : loss : 0.027536, loss_ce: 0.009238
 43%|███████████▌               | 172/400 [1:23:01<1:48:39, 28.59s/it]2021-12-11 20:43:18,429 iteration 2925 : loss : 0.040531, loss_ce: 0.016685
2021-12-11 20:43:19,964 iteration 2926 : loss : 0.027836, loss_ce: 0.008334
2021-12-11 20:43:21,602 iteration 2927 : loss : 0.032945, loss_ce: 0.013943
2021-12-11 20:43:23,345 iteration 2928 : loss : 0.041985, loss_ce: 0.011423
2021-12-11 20:43:24,892 iteration 2929 : loss : 0.022711, loss_ce: 0.007240
2021-12-11 20:43:26,421 iteration 2930 : loss : 0.038053, loss_ce: 0.017476
2021-12-11 20:43:27,902 iteration 2931 : loss : 0.035724, loss_ce: 0.012475
2021-12-11 20:43:29,545 iteration 2932 : loss : 0.025263, loss_ce: 0.009425
2021-12-11 20:43:31,091 iteration 2933 : loss : 0.033143, loss_ce: 0.012201
2021-12-11 20:43:32,719 iteration 2934 : loss : 0.026116, loss_ce: 0.011596
2021-12-11 20:43:34,305 iteration 2935 : loss : 0.042954, loss_ce: 0.013181
2021-12-11 20:43:35,951 iteration 2936 : loss : 0.028674, loss_ce: 0.013396
2021-12-11 20:43:37,502 iteration 2937 : loss : 0.025742, loss_ce: 0.010164
2021-12-11 20:43:39,070 iteration 2938 : loss : 0.026348, loss_ce: 0.009811
2021-12-11 20:43:40,625 iteration 2939 : loss : 0.025814, loss_ce: 0.010950
2021-12-11 20:43:42,222 iteration 2940 : loss : 0.029539, loss_ce: 0.008528
2021-12-11 20:43:43,781 iteration 2941 : loss : 0.032316, loss_ce: 0.011061
 43%|███████████▋               | 173/400 [1:23:28<1:46:28, 28.14s/it]2021-12-11 20:43:45,430 iteration 2942 : loss : 0.029680, loss_ce: 0.010721
2021-12-11 20:43:46,896 iteration 2943 : loss : 0.022309, loss_ce: 0.008694
2021-12-11 20:43:48,384 iteration 2944 : loss : 0.033482, loss_ce: 0.011275
2021-12-11 20:43:49,999 iteration 2945 : loss : 0.035324, loss_ce: 0.015150
2021-12-11 20:43:51,517 iteration 2946 : loss : 0.030429, loss_ce: 0.011717
2021-12-11 20:43:53,012 iteration 2947 : loss : 0.017298, loss_ce: 0.005570
2021-12-11 20:43:54,571 iteration 2948 : loss : 0.027975, loss_ce: 0.009930
2021-12-11 20:43:56,165 iteration 2949 : loss : 0.025603, loss_ce: 0.009183
2021-12-11 20:43:57,711 iteration 2950 : loss : 0.030126, loss_ce: 0.013763
2021-12-11 20:43:59,214 iteration 2951 : loss : 0.024456, loss_ce: 0.008995
2021-12-11 20:44:00,769 iteration 2952 : loss : 0.027366, loss_ce: 0.007388
2021-12-11 20:44:02,330 iteration 2953 : loss : 0.030351, loss_ce: 0.012057
2021-12-11 20:44:03,930 iteration 2954 : loss : 0.051296, loss_ce: 0.015008
2021-12-11 20:44:05,441 iteration 2955 : loss : 0.030822, loss_ce: 0.016957
2021-12-11 20:44:06,993 iteration 2956 : loss : 0.027333, loss_ce: 0.012997
2021-12-11 20:44:08,552 iteration 2957 : loss : 0.047133, loss_ce: 0.013559
2021-12-11 20:44:10,117 iteration 2958 : loss : 0.040081, loss_ce: 0.013248
 44%|███████████▋               | 174/400 [1:23:54<1:43:57, 27.60s/it]2021-12-11 20:44:11,824 iteration 2959 : loss : 0.026454, loss_ce: 0.011865
2021-12-11 20:44:13,425 iteration 2960 : loss : 0.023726, loss_ce: 0.008682
2021-12-11 20:44:15,062 iteration 2961 : loss : 0.027530, loss_ce: 0.013282
2021-12-11 20:44:16,571 iteration 2962 : loss : 0.024052, loss_ce: 0.007606
2021-12-11 20:44:18,119 iteration 2963 : loss : 0.031954, loss_ce: 0.011523
2021-12-11 20:44:19,744 iteration 2964 : loss : 0.035643, loss_ce: 0.012799
2021-12-11 20:44:21,324 iteration 2965 : loss : 0.029745, loss_ce: 0.013725
2021-12-11 20:44:22,867 iteration 2966 : loss : 0.026485, loss_ce: 0.009122
2021-12-11 20:44:24,521 iteration 2967 : loss : 0.037551, loss_ce: 0.013215
2021-12-11 20:44:26,081 iteration 2968 : loss : 0.038300, loss_ce: 0.015350
2021-12-11 20:44:27,584 iteration 2969 : loss : 0.031066, loss_ce: 0.007977
2021-12-11 20:44:29,109 iteration 2970 : loss : 0.026109, loss_ce: 0.009884
2021-12-11 20:44:30,685 iteration 2971 : loss : 0.034366, loss_ce: 0.012790
2021-12-11 20:44:32,286 iteration 2972 : loss : 0.026169, loss_ce: 0.008799
2021-12-11 20:44:33,849 iteration 2973 : loss : 0.030496, loss_ce: 0.012970
2021-12-11 20:44:35,540 iteration 2974 : loss : 0.031785, loss_ce: 0.012511
2021-12-11 20:44:35,541 Training Data Eval:
2021-12-11 20:44:43,275   Average segmentation loss on training set: 0.0212
2021-12-11 20:44:43,276 Validation Data Eval:
2021-12-11 20:44:45,925   Average segmentation loss on validation set: 0.0848
2021-12-11 20:44:47,455 iteration 2975 : loss : 0.051610, loss_ce: 0.015886
 44%|███████████▊               | 175/400 [1:24:32<1:54:27, 30.52s/it]2021-12-11 20:44:49,108 iteration 2976 : loss : 0.028765, loss_ce: 0.011444
2021-12-11 20:44:50,821 iteration 2977 : loss : 0.036359, loss_ce: 0.014679
2021-12-11 20:44:52,395 iteration 2978 : loss : 0.032849, loss_ce: 0.012688
2021-12-11 20:44:54,035 iteration 2979 : loss : 0.048739, loss_ce: 0.017501
2021-12-11 20:44:55,775 iteration 2980 : loss : 0.031079, loss_ce: 0.013204
2021-12-11 20:44:57,341 iteration 2981 : loss : 0.022332, loss_ce: 0.009825
2021-12-11 20:44:58,894 iteration 2982 : loss : 0.027700, loss_ce: 0.010338
2021-12-11 20:45:00,492 iteration 2983 : loss : 0.029253, loss_ce: 0.006466
2021-12-11 20:45:02,087 iteration 2984 : loss : 0.027204, loss_ce: 0.011785
2021-12-11 20:45:03,666 iteration 2985 : loss : 0.026132, loss_ce: 0.011357
2021-12-11 20:45:05,213 iteration 2986 : loss : 0.036219, loss_ce: 0.014060
2021-12-11 20:45:06,743 iteration 2987 : loss : 0.023377, loss_ce: 0.008048
2021-12-11 20:45:08,328 iteration 2988 : loss : 0.025888, loss_ce: 0.010070
2021-12-11 20:45:09,850 iteration 2989 : loss : 0.022879, loss_ce: 0.008090
2021-12-11 20:45:11,422 iteration 2990 : loss : 0.031631, loss_ce: 0.014738
2021-12-11 20:45:12,945 iteration 2991 : loss : 0.023835, loss_ce: 0.006250
2021-12-11 20:45:14,533 iteration 2992 : loss : 0.027961, loss_ce: 0.013551
 44%|███████████▉               | 176/400 [1:24:59<1:50:05, 29.49s/it]2021-12-11 20:45:16,183 iteration 2993 : loss : 0.027891, loss_ce: 0.010982
2021-12-11 20:45:17,734 iteration 2994 : loss : 0.023382, loss_ce: 0.008782
2021-12-11 20:45:19,343 iteration 2995 : loss : 0.033871, loss_ce: 0.013295
2021-12-11 20:45:20,866 iteration 2996 : loss : 0.029255, loss_ce: 0.011502
2021-12-11 20:45:22,422 iteration 2997 : loss : 0.023322, loss_ce: 0.007241
2021-12-11 20:45:24,019 iteration 2998 : loss : 0.021767, loss_ce: 0.010369
2021-12-11 20:45:25,583 iteration 2999 : loss : 0.030539, loss_ce: 0.010049
2021-12-11 20:45:27,138 iteration 3000 : loss : 0.024088, loss_ce: 0.008688
2021-12-11 20:45:28,798 iteration 3001 : loss : 0.029547, loss_ce: 0.011778
2021-12-11 20:45:30,415 iteration 3002 : loss : 0.029186, loss_ce: 0.010772
2021-12-11 20:45:31,901 iteration 3003 : loss : 0.026277, loss_ce: 0.009909
2021-12-11 20:45:33,453 iteration 3004 : loss : 0.027793, loss_ce: 0.013973
2021-12-11 20:45:34,986 iteration 3005 : loss : 0.023794, loss_ce: 0.008927
2021-12-11 20:45:36,521 iteration 3006 : loss : 0.027615, loss_ce: 0.009095
2021-12-11 20:45:38,087 iteration 3007 : loss : 0.027624, loss_ce: 0.008793
2021-12-11 20:45:39,583 iteration 3008 : loss : 0.025591, loss_ce: 0.008711
2021-12-11 20:45:41,091 iteration 3009 : loss : 0.029099, loss_ce: 0.008543
 44%|███████████▉               | 177/400 [1:25:25<1:46:19, 28.61s/it]2021-12-11 20:45:42,807 iteration 3010 : loss : 0.039567, loss_ce: 0.014604
2021-12-11 20:45:44,347 iteration 3011 : loss : 0.035130, loss_ce: 0.011148
2021-12-11 20:45:45,861 iteration 3012 : loss : 0.027835, loss_ce: 0.008527
2021-12-11 20:45:47,510 iteration 3013 : loss : 0.028193, loss_ce: 0.010064
2021-12-11 20:45:49,104 iteration 3014 : loss : 0.032634, loss_ce: 0.013268
2021-12-11 20:45:50,694 iteration 3015 : loss : 0.027545, loss_ce: 0.008088
2021-12-11 20:45:52,175 iteration 3016 : loss : 0.022724, loss_ce: 0.006969
2021-12-11 20:45:53,813 iteration 3017 : loss : 0.039209, loss_ce: 0.021417
2021-12-11 20:45:55,476 iteration 3018 : loss : 0.029227, loss_ce: 0.015360
2021-12-11 20:45:57,214 iteration 3019 : loss : 0.039278, loss_ce: 0.015185
2021-12-11 20:45:58,761 iteration 3020 : loss : 0.027004, loss_ce: 0.008435
2021-12-11 20:46:00,324 iteration 3021 : loss : 0.025289, loss_ce: 0.009195
2021-12-11 20:46:01,810 iteration 3022 : loss : 0.020768, loss_ce: 0.009509
2021-12-11 20:46:03,337 iteration 3023 : loss : 0.023405, loss_ce: 0.008089
2021-12-11 20:46:04,899 iteration 3024 : loss : 0.029159, loss_ce: 0.013072
2021-12-11 20:46:06,462 iteration 3025 : loss : 0.031389, loss_ce: 0.012903
2021-12-11 20:46:07,981 iteration 3026 : loss : 0.025619, loss_ce: 0.007960
 44%|████████████               | 178/400 [1:25:52<1:43:56, 28.09s/it]2021-12-11 20:46:09,599 iteration 3027 : loss : 0.033631, loss_ce: 0.014806
2021-12-11 20:46:11,272 iteration 3028 : loss : 0.035290, loss_ce: 0.013481
2021-12-11 20:46:12,803 iteration 3029 : loss : 0.020663, loss_ce: 0.007883
2021-12-11 20:46:14,434 iteration 3030 : loss : 0.026816, loss_ce: 0.009387
2021-12-11 20:46:16,070 iteration 3031 : loss : 0.032840, loss_ce: 0.009581
2021-12-11 20:46:17,714 iteration 3032 : loss : 0.025441, loss_ce: 0.009904
2021-12-11 20:46:19,302 iteration 3033 : loss : 0.027130, loss_ce: 0.007991
2021-12-11 20:46:20,841 iteration 3034 : loss : 0.021922, loss_ce: 0.006473
2021-12-11 20:46:22,337 iteration 3035 : loss : 0.025463, loss_ce: 0.010467
2021-12-11 20:46:23,947 iteration 3036 : loss : 0.030393, loss_ce: 0.013692
2021-12-11 20:46:25,459 iteration 3037 : loss : 0.026210, loss_ce: 0.011436
2021-12-11 20:46:26,939 iteration 3038 : loss : 0.025189, loss_ce: 0.012123
2021-12-11 20:46:28,447 iteration 3039 : loss : 0.022797, loss_ce: 0.008340
2021-12-11 20:46:30,100 iteration 3040 : loss : 0.043579, loss_ce: 0.010640
2021-12-11 20:46:31,551 iteration 3041 : loss : 0.021279, loss_ce: 0.007749
2021-12-11 20:46:33,062 iteration 3042 : loss : 0.023278, loss_ce: 0.010166
2021-12-11 20:46:34,571 iteration 3043 : loss : 0.025245, loss_ce: 0.010986
 45%|████████████               | 179/400 [1:26:19<1:41:49, 27.64s/it]2021-12-11 20:46:36,225 iteration 3044 : loss : 0.026812, loss_ce: 0.009657
2021-12-11 20:46:37,699 iteration 3045 : loss : 0.028153, loss_ce: 0.009434
2021-12-11 20:46:39,361 iteration 3046 : loss : 0.036497, loss_ce: 0.015340
2021-12-11 20:46:41,037 iteration 3047 : loss : 0.027260, loss_ce: 0.008979
2021-12-11 20:46:42,635 iteration 3048 : loss : 0.030690, loss_ce: 0.010212
2021-12-11 20:46:44,237 iteration 3049 : loss : 0.024299, loss_ce: 0.007784
2021-12-11 20:46:45,847 iteration 3050 : loss : 0.036360, loss_ce: 0.009865
2021-12-11 20:46:47,507 iteration 3051 : loss : 0.021430, loss_ce: 0.008102
2021-12-11 20:46:49,117 iteration 3052 : loss : 0.032120, loss_ce: 0.015583
2021-12-11 20:46:50,600 iteration 3053 : loss : 0.017730, loss_ce: 0.006268
2021-12-11 20:46:52,124 iteration 3054 : loss : 0.028451, loss_ce: 0.012216
2021-12-11 20:46:53,604 iteration 3055 : loss : 0.031371, loss_ce: 0.012447
2021-12-11 20:46:55,070 iteration 3056 : loss : 0.020640, loss_ce: 0.006341
2021-12-11 20:46:56,761 iteration 3057 : loss : 0.030587, loss_ce: 0.012148
2021-12-11 20:46:58,285 iteration 3058 : loss : 0.029301, loss_ce: 0.009372
2021-12-11 20:46:59,805 iteration 3059 : loss : 0.028677, loss_ce: 0.016236
2021-12-11 20:46:59,805 Training Data Eval:
2021-12-11 20:47:07,561   Average segmentation loss on training set: 0.0188
2021-12-11 20:47:07,561 Validation Data Eval:
2021-12-11 20:47:10,219   Average segmentation loss on validation set: 0.0879
2021-12-11 20:47:11,821 iteration 3060 : loss : 0.029965, loss_ce: 0.010433
 45%|████████████▏              | 180/400 [1:26:56<1:51:55, 30.52s/it]2021-12-11 20:47:13,449 iteration 3061 : loss : 0.021757, loss_ce: 0.006489
2021-12-11 20:47:15,047 iteration 3062 : loss : 0.032844, loss_ce: 0.015862
2021-12-11 20:47:16,588 iteration 3063 : loss : 0.020371, loss_ce: 0.008518
2021-12-11 20:47:18,154 iteration 3064 : loss : 0.024669, loss_ce: 0.012417
2021-12-11 20:47:19,760 iteration 3065 : loss : 0.026541, loss_ce: 0.007848
2021-12-11 20:47:21,275 iteration 3066 : loss : 0.020394, loss_ce: 0.006569
2021-12-11 20:47:22,918 iteration 3067 : loss : 0.032933, loss_ce: 0.014807
2021-12-11 20:47:24,572 iteration 3068 : loss : 0.028805, loss_ce: 0.011424
2021-12-11 20:47:26,069 iteration 3069 : loss : 0.014005, loss_ce: 0.005133
2021-12-11 20:47:27,634 iteration 3070 : loss : 0.032012, loss_ce: 0.011575
2021-12-11 20:47:29,361 iteration 3071 : loss : 0.044148, loss_ce: 0.015101
2021-12-11 20:47:30,924 iteration 3072 : loss : 0.024006, loss_ce: 0.008619
2021-12-11 20:47:32,473 iteration 3073 : loss : 0.024922, loss_ce: 0.007747
2021-12-11 20:47:34,034 iteration 3074 : loss : 0.030035, loss_ce: 0.011965
2021-12-11 20:47:35,632 iteration 3075 : loss : 0.030088, loss_ce: 0.010499
2021-12-11 20:47:37,137 iteration 3076 : loss : 0.017154, loss_ce: 0.006461
2021-12-11 20:47:38,807 iteration 3077 : loss : 0.044239, loss_ce: 0.017564
 45%|████████████▏              | 181/400 [1:27:23<1:47:32, 29.46s/it]2021-12-11 20:47:40,503 iteration 3078 : loss : 0.040582, loss_ce: 0.010579
2021-12-11 20:47:42,054 iteration 3079 : loss : 0.023150, loss_ce: 0.007532
2021-12-11 20:47:43,602 iteration 3080 : loss : 0.029154, loss_ce: 0.008462
2021-12-11 20:47:45,187 iteration 3081 : loss : 0.026645, loss_ce: 0.010261
2021-12-11 20:47:46,760 iteration 3082 : loss : 0.028334, loss_ce: 0.009641
2021-12-11 20:47:48,334 iteration 3083 : loss : 0.038765, loss_ce: 0.013693
2021-12-11 20:47:49,938 iteration 3084 : loss : 0.035284, loss_ce: 0.014618
2021-12-11 20:47:51,437 iteration 3085 : loss : 0.026182, loss_ce: 0.009247
2021-12-11 20:47:52,980 iteration 3086 : loss : 0.027678, loss_ce: 0.012596
2021-12-11 20:47:54,602 iteration 3087 : loss : 0.025334, loss_ce: 0.010270
2021-12-11 20:47:56,162 iteration 3088 : loss : 0.028464, loss_ce: 0.012747
2021-12-11 20:47:57,831 iteration 3089 : loss : 0.035265, loss_ce: 0.012345
2021-12-11 20:47:59,331 iteration 3090 : loss : 0.023639, loss_ce: 0.009112
2021-12-11 20:48:00,957 iteration 3091 : loss : 0.028983, loss_ce: 0.010280
2021-12-11 20:48:02,487 iteration 3092 : loss : 0.031459, loss_ce: 0.012892
2021-12-11 20:48:04,002 iteration 3093 : loss : 0.020899, loss_ce: 0.008445
2021-12-11 20:48:05,553 iteration 3094 : loss : 0.049959, loss_ce: 0.012985
 46%|████████████▎              | 182/400 [1:27:50<1:44:05, 28.65s/it]2021-12-11 20:48:07,224 iteration 3095 : loss : 0.021846, loss_ce: 0.009005
2021-12-11 20:48:08,797 iteration 3096 : loss : 0.027358, loss_ce: 0.011118
2021-12-11 20:48:10,398 iteration 3097 : loss : 0.024271, loss_ce: 0.010622
2021-12-11 20:48:12,007 iteration 3098 : loss : 0.038875, loss_ce: 0.014045
2021-12-11 20:48:13,622 iteration 3099 : loss : 0.033829, loss_ce: 0.015159
2021-12-11 20:48:15,207 iteration 3100 : loss : 0.024394, loss_ce: 0.008505
2021-12-11 20:48:16,739 iteration 3101 : loss : 0.018763, loss_ce: 0.006619
2021-12-11 20:48:18,212 iteration 3102 : loss : 0.023865, loss_ce: 0.008757
2021-12-11 20:48:19,816 iteration 3103 : loss : 0.030087, loss_ce: 0.015187
2021-12-11 20:48:21,364 iteration 3104 : loss : 0.027609, loss_ce: 0.008454
2021-12-11 20:48:22,980 iteration 3105 : loss : 0.021719, loss_ce: 0.008601
2021-12-11 20:48:24,557 iteration 3106 : loss : 0.027291, loss_ce: 0.009876
2021-12-11 20:48:26,189 iteration 3107 : loss : 0.038123, loss_ce: 0.013273
2021-12-11 20:48:27,794 iteration 3108 : loss : 0.031224, loss_ce: 0.012133
2021-12-11 20:48:29,288 iteration 3109 : loss : 0.023484, loss_ce: 0.010530
2021-12-11 20:48:30,815 iteration 3110 : loss : 0.025361, loss_ce: 0.009086
2021-12-11 20:48:32,394 iteration 3111 : loss : 0.030189, loss_ce: 0.008013
 46%|████████████▎              | 183/400 [1:28:17<1:41:39, 28.11s/it]2021-12-11 20:48:33,974 iteration 3112 : loss : 0.030068, loss_ce: 0.010915
2021-12-11 20:48:35,566 iteration 3113 : loss : 0.036851, loss_ce: 0.014218
2021-12-11 20:48:37,080 iteration 3114 : loss : 0.023353, loss_ce: 0.010248
2021-12-11 20:48:38,675 iteration 3115 : loss : 0.026596, loss_ce: 0.009444
2021-12-11 20:48:40,169 iteration 3116 : loss : 0.025848, loss_ce: 0.010427
2021-12-11 20:48:41,821 iteration 3117 : loss : 0.043799, loss_ce: 0.010746
2021-12-11 20:48:43,405 iteration 3118 : loss : 0.023021, loss_ce: 0.010306
2021-12-11 20:48:44,994 iteration 3119 : loss : 0.024257, loss_ce: 0.009724
2021-12-11 20:48:46,496 iteration 3120 : loss : 0.028983, loss_ce: 0.007792
2021-12-11 20:48:48,091 iteration 3121 : loss : 0.060684, loss_ce: 0.016562
2021-12-11 20:48:49,649 iteration 3122 : loss : 0.028118, loss_ce: 0.013065
2021-12-11 20:48:51,345 iteration 3123 : loss : 0.034324, loss_ce: 0.012628
2021-12-11 20:48:52,874 iteration 3124 : loss : 0.024297, loss_ce: 0.009547
2021-12-11 20:48:54,393 iteration 3125 : loss : 0.017816, loss_ce: 0.007145
2021-12-11 20:48:55,917 iteration 3126 : loss : 0.023833, loss_ce: 0.009884
2021-12-11 20:48:57,452 iteration 3127 : loss : 0.026744, loss_ce: 0.011773
2021-12-11 20:48:58,997 iteration 3128 : loss : 0.034695, loss_ce: 0.008744
 46%|████████████▍              | 184/400 [1:28:43<1:39:33, 27.66s/it]2021-12-11 20:49:00,578 iteration 3129 : loss : 0.026874, loss_ce: 0.010628
2021-12-11 20:49:02,085 iteration 3130 : loss : 0.022613, loss_ce: 0.008576
2021-12-11 20:49:03,698 iteration 3131 : loss : 0.040857, loss_ce: 0.024266
2021-12-11 20:49:05,286 iteration 3132 : loss : 0.035785, loss_ce: 0.012778
2021-12-11 20:49:06,801 iteration 3133 : loss : 0.020414, loss_ce: 0.008491
2021-12-11 20:49:08,403 iteration 3134 : loss : 0.030845, loss_ce: 0.012062
2021-12-11 20:49:10,015 iteration 3135 : loss : 0.029516, loss_ce: 0.007257
2021-12-11 20:49:11,525 iteration 3136 : loss : 0.020293, loss_ce: 0.009353
2021-12-11 20:49:13,033 iteration 3137 : loss : 0.023637, loss_ce: 0.009759
2021-12-11 20:49:14,574 iteration 3138 : loss : 0.024187, loss_ce: 0.008886
2021-12-11 20:49:16,291 iteration 3139 : loss : 0.028722, loss_ce: 0.009387
2021-12-11 20:49:17,895 iteration 3140 : loss : 0.024956, loss_ce: 0.008894
2021-12-11 20:49:19,451 iteration 3141 : loss : 0.024013, loss_ce: 0.009729
2021-12-11 20:49:20,948 iteration 3142 : loss : 0.022018, loss_ce: 0.007938
2021-12-11 20:49:22,539 iteration 3143 : loss : 0.044740, loss_ce: 0.012246
2021-12-11 20:49:24,158 iteration 3144 : loss : 0.044017, loss_ce: 0.010857
2021-12-11 20:49:24,158 Training Data Eval:
2021-12-11 20:49:31,908   Average segmentation loss on training set: 0.0177
2021-12-11 20:49:31,908 Validation Data Eval:
2021-12-11 20:49:34,565   Average segmentation loss on validation set: 0.0793
2021-12-11 20:49:36,054 iteration 3145 : loss : 0.022054, loss_ce: 0.009526
 46%|████████████▍              | 185/400 [1:29:20<1:49:12, 30.48s/it]2021-12-11 20:49:37,767 iteration 3146 : loss : 0.025328, loss_ce: 0.009971
2021-12-11 20:49:39,403 iteration 3147 : loss : 0.034895, loss_ce: 0.014114
2021-12-11 20:49:40,898 iteration 3148 : loss : 0.026231, loss_ce: 0.009442
2021-12-11 20:49:42,461 iteration 3149 : loss : 0.034874, loss_ce: 0.009397
2021-12-11 20:49:44,028 iteration 3150 : loss : 0.029759, loss_ce: 0.008489
2021-12-11 20:49:45,494 iteration 3151 : loss : 0.022802, loss_ce: 0.009474
2021-12-11 20:49:47,115 iteration 3152 : loss : 0.022654, loss_ce: 0.011241
2021-12-11 20:49:48,651 iteration 3153 : loss : 0.026057, loss_ce: 0.011812
2021-12-11 20:49:50,218 iteration 3154 : loss : 0.033442, loss_ce: 0.008794
2021-12-11 20:49:51,793 iteration 3155 : loss : 0.022478, loss_ce: 0.007507
2021-12-11 20:49:53,384 iteration 3156 : loss : 0.027858, loss_ce: 0.012569
2021-12-11 20:49:54,867 iteration 3157 : loss : 0.033441, loss_ce: 0.007632
2021-12-11 20:49:56,512 iteration 3158 : loss : 0.032122, loss_ce: 0.012432
2021-12-11 20:49:58,074 iteration 3159 : loss : 0.027062, loss_ce: 0.011747
2021-12-11 20:49:59,632 iteration 3160 : loss : 0.029254, loss_ce: 0.012946
2021-12-11 20:50:01,284 iteration 3161 : loss : 0.039605, loss_ce: 0.015560
2021-12-11 20:50:02,966 iteration 3162 : loss : 0.030589, loss_ce: 0.012998
 46%|████████████▌              | 186/400 [1:29:47<1:44:52, 29.41s/it]2021-12-11 20:50:04,538 iteration 3163 : loss : 0.029169, loss_ce: 0.008636
2021-12-11 20:50:06,044 iteration 3164 : loss : 0.031759, loss_ce: 0.009581
2021-12-11 20:50:07,578 iteration 3165 : loss : 0.018191, loss_ce: 0.007046
2021-12-11 20:50:09,140 iteration 3166 : loss : 0.036836, loss_ce: 0.017833
2021-12-11 20:50:10,723 iteration 3167 : loss : 0.054237, loss_ce: 0.018853
2021-12-11 20:50:12,222 iteration 3168 : loss : 0.021462, loss_ce: 0.010154
2021-12-11 20:50:13,796 iteration 3169 : loss : 0.025622, loss_ce: 0.009905
2021-12-11 20:50:15,387 iteration 3170 : loss : 0.036022, loss_ce: 0.014288
2021-12-11 20:50:17,019 iteration 3171 : loss : 0.037075, loss_ce: 0.010308
2021-12-11 20:50:18,626 iteration 3172 : loss : 0.023660, loss_ce: 0.010110
2021-12-11 20:50:20,225 iteration 3173 : loss : 0.028434, loss_ce: 0.011902
2021-12-11 20:50:21,860 iteration 3174 : loss : 0.032278, loss_ce: 0.011341
2021-12-11 20:50:23,418 iteration 3175 : loss : 0.023479, loss_ce: 0.008318
2021-12-11 20:50:25,008 iteration 3176 : loss : 0.023853, loss_ce: 0.011505
2021-12-11 20:50:26,525 iteration 3177 : loss : 0.024026, loss_ce: 0.011226
2021-12-11 20:50:28,092 iteration 3178 : loss : 0.024622, loss_ce: 0.007343
2021-12-11 20:50:29,689 iteration 3179 : loss : 0.034274, loss_ce: 0.009843
 47%|████████████▌              | 187/400 [1:30:14<1:41:32, 28.60s/it]2021-12-11 20:50:31,389 iteration 3180 : loss : 0.019962, loss_ce: 0.007731
2021-12-11 20:50:32,963 iteration 3181 : loss : 0.037341, loss_ce: 0.015179
2021-12-11 20:50:34,588 iteration 3182 : loss : 0.025636, loss_ce: 0.009360
2021-12-11 20:50:36,208 iteration 3183 : loss : 0.034852, loss_ce: 0.015935
2021-12-11 20:50:37,690 iteration 3184 : loss : 0.022666, loss_ce: 0.009272
2021-12-11 20:50:39,193 iteration 3185 : loss : 0.029349, loss_ce: 0.011043
2021-12-11 20:50:40,718 iteration 3186 : loss : 0.031546, loss_ce: 0.017858
2021-12-11 20:50:42,222 iteration 3187 : loss : 0.021282, loss_ce: 0.006662
2021-12-11 20:50:43,768 iteration 3188 : loss : 0.029101, loss_ce: 0.008655
2021-12-11 20:50:45,257 iteration 3189 : loss : 0.019955, loss_ce: 0.008587
2021-12-11 20:50:46,866 iteration 3190 : loss : 0.032011, loss_ce: 0.011580
2021-12-11 20:50:48,459 iteration 3191 : loss : 0.028975, loss_ce: 0.009697
2021-12-11 20:50:50,008 iteration 3192 : loss : 0.020787, loss_ce: 0.008480
2021-12-11 20:50:51,515 iteration 3193 : loss : 0.024544, loss_ce: 0.009573
2021-12-11 20:50:52,994 iteration 3194 : loss : 0.025578, loss_ce: 0.007731
2021-12-11 20:50:54,523 iteration 3195 : loss : 0.025098, loss_ce: 0.007411
2021-12-11 20:50:56,120 iteration 3196 : loss : 0.019527, loss_ce: 0.004924
 47%|████████████▋              | 188/400 [1:30:40<1:38:45, 27.95s/it]2021-12-11 20:50:57,723 iteration 3197 : loss : 0.022412, loss_ce: 0.007086
2021-12-11 20:50:59,223 iteration 3198 : loss : 0.034100, loss_ce: 0.010924
2021-12-11 20:51:00,712 iteration 3199 : loss : 0.024163, loss_ce: 0.008670
2021-12-11 20:51:02,230 iteration 3200 : loss : 0.026184, loss_ce: 0.010224
2021-12-11 20:51:03,814 iteration 3201 : loss : 0.031484, loss_ce: 0.011685
2021-12-11 20:51:05,402 iteration 3202 : loss : 0.022343, loss_ce: 0.008466
2021-12-11 20:51:06,885 iteration 3203 : loss : 0.037526, loss_ce: 0.008121
2021-12-11 20:51:08,463 iteration 3204 : loss : 0.026611, loss_ce: 0.012742
2021-12-11 20:51:10,052 iteration 3205 : loss : 0.018461, loss_ce: 0.005479
2021-12-11 20:51:11,573 iteration 3206 : loss : 0.025811, loss_ce: 0.009998
2021-12-11 20:51:13,071 iteration 3207 : loss : 0.018545, loss_ce: 0.005519
2021-12-11 20:51:14,582 iteration 3208 : loss : 0.025607, loss_ce: 0.007184
2021-12-11 20:51:16,183 iteration 3209 : loss : 0.021523, loss_ce: 0.008185
2021-12-11 20:51:17,756 iteration 3210 : loss : 0.037566, loss_ce: 0.013352
2021-12-11 20:51:19,367 iteration 3211 : loss : 0.027542, loss_ce: 0.013440
2021-12-11 20:51:20,972 iteration 3212 : loss : 0.025749, loss_ce: 0.010354
2021-12-11 20:51:22,517 iteration 3213 : loss : 0.029879, loss_ce: 0.015212
 47%|████████████▊              | 189/400 [1:31:07<1:36:39, 27.49s/it]2021-12-11 20:51:24,116 iteration 3214 : loss : 0.026143, loss_ce: 0.010006
2021-12-11 20:51:25,635 iteration 3215 : loss : 0.018700, loss_ce: 0.007971
2021-12-11 20:51:27,173 iteration 3216 : loss : 0.026219, loss_ce: 0.011428
2021-12-11 20:51:28,767 iteration 3217 : loss : 0.040012, loss_ce: 0.012159
2021-12-11 20:51:30,276 iteration 3218 : loss : 0.023387, loss_ce: 0.009297
2021-12-11 20:51:31,791 iteration 3219 : loss : 0.021157, loss_ce: 0.006683
2021-12-11 20:51:33,372 iteration 3220 : loss : 0.034359, loss_ce: 0.015794
2021-12-11 20:51:34,958 iteration 3221 : loss : 0.039632, loss_ce: 0.014514
2021-12-11 20:51:36,469 iteration 3222 : loss : 0.019235, loss_ce: 0.006543
2021-12-11 20:51:38,058 iteration 3223 : loss : 0.050169, loss_ce: 0.017347
2021-12-11 20:51:39,609 iteration 3224 : loss : 0.016047, loss_ce: 0.005692
2021-12-11 20:51:41,096 iteration 3225 : loss : 0.031902, loss_ce: 0.010903
2021-12-11 20:51:42,631 iteration 3226 : loss : 0.028921, loss_ce: 0.013254
2021-12-11 20:51:44,207 iteration 3227 : loss : 0.031122, loss_ce: 0.011892
2021-12-11 20:51:45,753 iteration 3228 : loss : 0.025366, loss_ce: 0.010148
2021-12-11 20:51:47,329 iteration 3229 : loss : 0.024971, loss_ce: 0.008765
2021-12-11 20:51:47,329 Training Data Eval:
2021-12-11 20:51:55,084   Average segmentation loss on training set: 0.0192
2021-12-11 20:51:55,084 Validation Data Eval:
2021-12-11 20:51:57,738   Average segmentation loss on validation set: 0.1220
2021-12-11 20:51:59,263 iteration 3230 : loss : 0.031967, loss_ce: 0.017126
 48%|████████████▊              | 190/400 [1:31:44<1:45:54, 30.26s/it]2021-12-11 20:52:00,762 iteration 3231 : loss : 0.022638, loss_ce: 0.008105
2021-12-11 20:52:02,316 iteration 3232 : loss : 0.022863, loss_ce: 0.008610
2021-12-11 20:52:03,886 iteration 3233 : loss : 0.027971, loss_ce: 0.009265
2021-12-11 20:52:05,400 iteration 3234 : loss : 0.023083, loss_ce: 0.009198
2021-12-11 20:52:06,970 iteration 3235 : loss : 0.023611, loss_ce: 0.008830
2021-12-11 20:52:08,400 iteration 3236 : loss : 0.021305, loss_ce: 0.009728
2021-12-11 20:52:09,927 iteration 3237 : loss : 0.019313, loss_ce: 0.007204
2021-12-11 20:52:11,479 iteration 3238 : loss : 0.029920, loss_ce: 0.011225
2021-12-11 20:52:12,939 iteration 3239 : loss : 0.023406, loss_ce: 0.009546
2021-12-11 20:52:14,545 iteration 3240 : loss : 0.030874, loss_ce: 0.011645
2021-12-11 20:52:16,199 iteration 3241 : loss : 0.029812, loss_ce: 0.009962
2021-12-11 20:52:17,776 iteration 3242 : loss : 0.023673, loss_ce: 0.007895
2021-12-11 20:52:19,384 iteration 3243 : loss : 0.025370, loss_ce: 0.010420
2021-12-11 20:52:20,889 iteration 3244 : loss : 0.030871, loss_ce: 0.008808
2021-12-11 20:52:22,470 iteration 3245 : loss : 0.037217, loss_ce: 0.010739
2021-12-11 20:52:24,071 iteration 3246 : loss : 0.036789, loss_ce: 0.012158
2021-12-11 20:52:25,763 iteration 3247 : loss : 0.036240, loss_ce: 0.011145
 48%|████████████▉              | 191/400 [1:32:10<1:41:28, 29.13s/it]2021-12-11 20:52:27,453 iteration 3248 : loss : 0.046294, loss_ce: 0.016014
2021-12-11 20:52:29,070 iteration 3249 : loss : 0.028962, loss_ce: 0.011691
2021-12-11 20:52:30,641 iteration 3250 : loss : 0.038792, loss_ce: 0.013310
2021-12-11 20:52:32,212 iteration 3251 : loss : 0.022265, loss_ce: 0.007485
2021-12-11 20:52:33,661 iteration 3252 : loss : 0.019444, loss_ce: 0.009227
2021-12-11 20:52:35,195 iteration 3253 : loss : 0.030519, loss_ce: 0.009544
2021-12-11 20:52:36,799 iteration 3254 : loss : 0.030608, loss_ce: 0.013789
2021-12-11 20:52:38,364 iteration 3255 : loss : 0.028979, loss_ce: 0.011558
2021-12-11 20:52:39,967 iteration 3256 : loss : 0.031238, loss_ce: 0.013472
2021-12-11 20:52:41,548 iteration 3257 : loss : 0.031166, loss_ce: 0.013030
2021-12-11 20:52:43,036 iteration 3258 : loss : 0.022595, loss_ce: 0.006130
2021-12-11 20:52:44,605 iteration 3259 : loss : 0.024799, loss_ce: 0.009612
2021-12-11 20:52:46,186 iteration 3260 : loss : 0.025289, loss_ce: 0.009853
2021-12-11 20:52:47,741 iteration 3261 : loss : 0.027921, loss_ce: 0.010293
2021-12-11 20:52:49,391 iteration 3262 : loss : 0.037224, loss_ce: 0.013943
2021-12-11 20:52:50,930 iteration 3263 : loss : 0.024808, loss_ce: 0.008612
2021-12-11 20:52:52,570 iteration 3264 : loss : 0.030925, loss_ce: 0.009524
 48%|████████████▉              | 192/400 [1:32:37<1:38:34, 28.44s/it]2021-12-11 20:52:54,160 iteration 3265 : loss : 0.033145, loss_ce: 0.013934
2021-12-11 20:52:55,751 iteration 3266 : loss : 0.022645, loss_ce: 0.006912
2021-12-11 20:52:57,327 iteration 3267 : loss : 0.018860, loss_ce: 0.005903
2021-12-11 20:52:58,903 iteration 3268 : loss : 0.024088, loss_ce: 0.007925
2021-12-11 20:53:00,407 iteration 3269 : loss : 0.025041, loss_ce: 0.013323
2021-12-11 20:53:01,976 iteration 3270 : loss : 0.027534, loss_ce: 0.009937
2021-12-11 20:53:03,445 iteration 3271 : loss : 0.017017, loss_ce: 0.005571
2021-12-11 20:53:05,086 iteration 3272 : loss : 0.033827, loss_ce: 0.012881
2021-12-11 20:53:06,630 iteration 3273 : loss : 0.023366, loss_ce: 0.009598
2021-12-11 20:53:08,102 iteration 3274 : loss : 0.027747, loss_ce: 0.009169
2021-12-11 20:53:09,636 iteration 3275 : loss : 0.028025, loss_ce: 0.010259
2021-12-11 20:53:11,170 iteration 3276 : loss : 0.026013, loss_ce: 0.006956
2021-12-11 20:53:12,649 iteration 3277 : loss : 0.022360, loss_ce: 0.008582
2021-12-11 20:53:14,191 iteration 3278 : loss : 0.020109, loss_ce: 0.007978
2021-12-11 20:53:15,627 iteration 3279 : loss : 0.025971, loss_ce: 0.015137
2021-12-11 20:53:17,251 iteration 3280 : loss : 0.031264, loss_ce: 0.012967
2021-12-11 20:53:18,788 iteration 3281 : loss : 0.019559, loss_ce: 0.006773
 48%|█████████████              | 193/400 [1:33:03<1:35:47, 27.77s/it]2021-12-11 20:53:20,444 iteration 3282 : loss : 0.025768, loss_ce: 0.005978
2021-12-11 20:53:22,042 iteration 3283 : loss : 0.030964, loss_ce: 0.011138
2021-12-11 20:53:23,618 iteration 3284 : loss : 0.024373, loss_ce: 0.009325
2021-12-11 20:53:25,220 iteration 3285 : loss : 0.032585, loss_ce: 0.010246
2021-12-11 20:53:26,766 iteration 3286 : loss : 0.026012, loss_ce: 0.007189
2021-12-11 20:53:28,438 iteration 3287 : loss : 0.030728, loss_ce: 0.012641
2021-12-11 20:53:29,931 iteration 3288 : loss : 0.024887, loss_ce: 0.010313
2021-12-11 20:53:31,626 iteration 3289 : loss : 0.029032, loss_ce: 0.010088
2021-12-11 20:53:33,269 iteration 3290 : loss : 0.024429, loss_ce: 0.007868
2021-12-11 20:53:34,915 iteration 3291 : loss : 0.033677, loss_ce: 0.015813
2021-12-11 20:53:36,484 iteration 3292 : loss : 0.026196, loss_ce: 0.008270
2021-12-11 20:53:38,043 iteration 3293 : loss : 0.034982, loss_ce: 0.011095
2021-12-11 20:53:39,728 iteration 3294 : loss : 0.030757, loss_ce: 0.012040
2021-12-11 20:53:41,347 iteration 3295 : loss : 0.023700, loss_ce: 0.010837
2021-12-11 20:53:42,906 iteration 3296 : loss : 0.024828, loss_ce: 0.008552
2021-12-11 20:53:44,438 iteration 3297 : loss : 0.024097, loss_ce: 0.008216
2021-12-11 20:53:46,116 iteration 3298 : loss : 0.022643, loss_ce: 0.009901
 48%|█████████████              | 194/400 [1:33:30<1:34:53, 27.64s/it]2021-12-11 20:53:47,658 iteration 3299 : loss : 0.020350, loss_ce: 0.005129
2021-12-11 20:53:49,271 iteration 3300 : loss : 0.031878, loss_ce: 0.010024
2021-12-11 20:53:50,845 iteration 3301 : loss : 0.020987, loss_ce: 0.009622
2021-12-11 20:53:52,381 iteration 3302 : loss : 0.027543, loss_ce: 0.009602
2021-12-11 20:53:54,018 iteration 3303 : loss : 0.026485, loss_ce: 0.011864
2021-12-11 20:53:55,636 iteration 3304 : loss : 0.029810, loss_ce: 0.011286
2021-12-11 20:53:57,184 iteration 3305 : loss : 0.025122, loss_ce: 0.007827
2021-12-11 20:53:58,754 iteration 3306 : loss : 0.034174, loss_ce: 0.010728
2021-12-11 20:54:00,476 iteration 3307 : loss : 0.045894, loss_ce: 0.019968
2021-12-11 20:54:02,124 iteration 3308 : loss : 0.035558, loss_ce: 0.017214
2021-12-11 20:54:03,763 iteration 3309 : loss : 0.019351, loss_ce: 0.008478
2021-12-11 20:54:05,278 iteration 3310 : loss : 0.032625, loss_ce: 0.018843
2021-12-11 20:54:06,942 iteration 3311 : loss : 0.037869, loss_ce: 0.013588
2021-12-11 20:54:08,511 iteration 3312 : loss : 0.032065, loss_ce: 0.009467
2021-12-11 20:54:10,172 iteration 3313 : loss : 0.028526, loss_ce: 0.011983
2021-12-11 20:54:11,747 iteration 3314 : loss : 0.027359, loss_ce: 0.008932
2021-12-11 20:54:11,747 Training Data Eval:
2021-12-11 20:54:19,513   Average segmentation loss on training set: 0.0194
2021-12-11 20:54:19,514 Validation Data Eval:
2021-12-11 20:54:22,166   Average segmentation loss on validation set: 0.0758
2021-12-11 20:54:23,659 iteration 3315 : loss : 0.023955, loss_ce: 0.009242
 49%|█████████████▏             | 195/400 [1:34:08<1:44:34, 30.61s/it]2021-12-11 20:54:25,224 iteration 3316 : loss : 0.019643, loss_ce: 0.007881
2021-12-11 20:54:26,790 iteration 3317 : loss : 0.031560, loss_ce: 0.014937
2021-12-11 20:54:28,328 iteration 3318 : loss : 0.029772, loss_ce: 0.012429
2021-12-11 20:54:29,827 iteration 3319 : loss : 0.034644, loss_ce: 0.013055
2021-12-11 20:54:31,475 iteration 3320 : loss : 0.041763, loss_ce: 0.015526
2021-12-11 20:54:32,995 iteration 3321 : loss : 0.021766, loss_ce: 0.007231
2021-12-11 20:54:34,620 iteration 3322 : loss : 0.035830, loss_ce: 0.008896
2021-12-11 20:54:36,123 iteration 3323 : loss : 0.027625, loss_ce: 0.008896
2021-12-11 20:54:37,676 iteration 3324 : loss : 0.031707, loss_ce: 0.014169
2021-12-11 20:54:39,276 iteration 3325 : loss : 0.032045, loss_ce: 0.014477
2021-12-11 20:54:40,793 iteration 3326 : loss : 0.027310, loss_ce: 0.009920
2021-12-11 20:54:42,338 iteration 3327 : loss : 0.021618, loss_ce: 0.006133
2021-12-11 20:54:43,972 iteration 3328 : loss : 0.030194, loss_ce: 0.011047
2021-12-11 20:54:45,539 iteration 3329 : loss : 0.029521, loss_ce: 0.011020
2021-12-11 20:54:47,068 iteration 3330 : loss : 0.023835, loss_ce: 0.012115
2021-12-11 20:54:48,537 iteration 3331 : loss : 0.023553, loss_ce: 0.010673
2021-12-11 20:54:50,125 iteration 3332 : loss : 0.027922, loss_ce: 0.008597
 49%|█████████████▏             | 196/400 [1:34:34<1:39:50, 29.37s/it]2021-12-11 20:54:51,791 iteration 3333 : loss : 0.030238, loss_ce: 0.011323
2021-12-11 20:54:53,379 iteration 3334 : loss : 0.034086, loss_ce: 0.015932
2021-12-11 20:54:55,039 iteration 3335 : loss : 0.026328, loss_ce: 0.011053
2021-12-11 20:54:56,615 iteration 3336 : loss : 0.029562, loss_ce: 0.009072
2021-12-11 20:54:58,237 iteration 3337 : loss : 0.033151, loss_ce: 0.012542
2021-12-11 20:54:59,922 iteration 3338 : loss : 0.032196, loss_ce: 0.015837
2021-12-11 20:55:01,427 iteration 3339 : loss : 0.028367, loss_ce: 0.010903
2021-12-11 20:55:02,911 iteration 3340 : loss : 0.043423, loss_ce: 0.010584
2021-12-11 20:55:04,460 iteration 3341 : loss : 0.032043, loss_ce: 0.010892
2021-12-11 20:55:05,995 iteration 3342 : loss : 0.022361, loss_ce: 0.010419
2021-12-11 20:55:07,591 iteration 3343 : loss : 0.023637, loss_ce: 0.010661
2021-12-11 20:55:09,159 iteration 3344 : loss : 0.025847, loss_ce: 0.009006
2021-12-11 20:55:10,744 iteration 3345 : loss : 0.026056, loss_ce: 0.009969
2021-12-11 20:55:12,267 iteration 3346 : loss : 0.025536, loss_ce: 0.009951
2021-12-11 20:55:13,784 iteration 3347 : loss : 0.022568, loss_ce: 0.008456
2021-12-11 20:55:15,252 iteration 3348 : loss : 0.020860, loss_ce: 0.007884
2021-12-11 20:55:16,882 iteration 3349 : loss : 0.033889, loss_ce: 0.010013
 49%|█████████████▎             | 197/400 [1:35:01<1:36:42, 28.58s/it]2021-12-11 20:55:18,510 iteration 3350 : loss : 0.030573, loss_ce: 0.010557
2021-12-11 20:55:20,132 iteration 3351 : loss : 0.024333, loss_ce: 0.007883
2021-12-11 20:55:21,742 iteration 3352 : loss : 0.041903, loss_ce: 0.019804
2021-12-11 20:55:23,403 iteration 3353 : loss : 0.035163, loss_ce: 0.011268
2021-12-11 20:55:24,942 iteration 3354 : loss : 0.022359, loss_ce: 0.008666
2021-12-11 20:55:26,582 iteration 3355 : loss : 0.031813, loss_ce: 0.013334
2021-12-11 20:55:28,211 iteration 3356 : loss : 0.033256, loss_ce: 0.010710
2021-12-11 20:55:29,763 iteration 3357 : loss : 0.028884, loss_ce: 0.007193
2021-12-11 20:55:31,376 iteration 3358 : loss : 0.023723, loss_ce: 0.010054
2021-12-11 20:55:32,850 iteration 3359 : loss : 0.021037, loss_ce: 0.006860
2021-12-11 20:55:34,382 iteration 3360 : loss : 0.029216, loss_ce: 0.010191
2021-12-11 20:55:35,941 iteration 3361 : loss : 0.032483, loss_ce: 0.011513
2021-12-11 20:55:37,491 iteration 3362 : loss : 0.029895, loss_ce: 0.012034
2021-12-11 20:55:39,138 iteration 3363 : loss : 0.043128, loss_ce: 0.014630
2021-12-11 20:55:40,635 iteration 3364 : loss : 0.022577, loss_ce: 0.010014
2021-12-11 20:55:42,234 iteration 3365 : loss : 0.036697, loss_ce: 0.014132
2021-12-11 20:55:43,716 iteration 3366 : loss : 0.020056, loss_ce: 0.009378
 50%|█████████████▎             | 198/400 [1:35:28<1:34:27, 28.06s/it]2021-12-11 20:55:45,351 iteration 3367 : loss : 0.021750, loss_ce: 0.008203
2021-12-11 20:55:46,879 iteration 3368 : loss : 0.018885, loss_ce: 0.008121
2021-12-11 20:55:48,361 iteration 3369 : loss : 0.025208, loss_ce: 0.007454
2021-12-11 20:55:49,989 iteration 3370 : loss : 0.033173, loss_ce: 0.014829
2021-12-11 20:55:51,681 iteration 3371 : loss : 0.033809, loss_ce: 0.011866
2021-12-11 20:55:53,203 iteration 3372 : loss : 0.018313, loss_ce: 0.007190
2021-12-11 20:55:54,783 iteration 3373 : loss : 0.029619, loss_ce: 0.011173
2021-12-11 20:55:56,286 iteration 3374 : loss : 0.021185, loss_ce: 0.007189
2021-12-11 20:55:57,800 iteration 3375 : loss : 0.029123, loss_ce: 0.010163
2021-12-11 20:55:59,354 iteration 3376 : loss : 0.033833, loss_ce: 0.009033
2021-12-11 20:56:00,806 iteration 3377 : loss : 0.015558, loss_ce: 0.006124
2021-12-11 20:56:02,395 iteration 3378 : loss : 0.036556, loss_ce: 0.009331
2021-12-11 20:56:04,056 iteration 3379 : loss : 0.045901, loss_ce: 0.020856
2021-12-11 20:56:05,675 iteration 3380 : loss : 0.031548, loss_ce: 0.009899
2021-12-11 20:56:07,280 iteration 3381 : loss : 0.032564, loss_ce: 0.011914
2021-12-11 20:56:08,860 iteration 3382 : loss : 0.023344, loss_ce: 0.008404
2021-12-11 20:56:10,386 iteration 3383 : loss : 0.021370, loss_ce: 0.007952
 50%|█████████████▍             | 199/400 [1:35:55<1:32:35, 27.64s/it]2021-12-11 20:56:12,077 iteration 3384 : loss : 0.046237, loss_ce: 0.013348
2021-12-11 20:56:13,688 iteration 3385 : loss : 0.028060, loss_ce: 0.009775
2021-12-11 20:56:15,201 iteration 3386 : loss : 0.020377, loss_ce: 0.006256
2021-12-11 20:56:16,836 iteration 3387 : loss : 0.028752, loss_ce: 0.011297
2021-12-11 20:56:18,429 iteration 3388 : loss : 0.035094, loss_ce: 0.015743
2021-12-11 20:56:19,963 iteration 3389 : loss : 0.018774, loss_ce: 0.007493
2021-12-11 20:56:21,396 iteration 3390 : loss : 0.018418, loss_ce: 0.006854
2021-12-11 20:56:23,007 iteration 3391 : loss : 0.030958, loss_ce: 0.012303
2021-12-11 20:56:24,611 iteration 3392 : loss : 0.040314, loss_ce: 0.013640
2021-12-11 20:56:26,194 iteration 3393 : loss : 0.032856, loss_ce: 0.013002
2021-12-11 20:56:27,788 iteration 3394 : loss : 0.020960, loss_ce: 0.008485
2021-12-11 20:56:29,277 iteration 3395 : loss : 0.020252, loss_ce: 0.008170
2021-12-11 20:56:30,902 iteration 3396 : loss : 0.026678, loss_ce: 0.011741
2021-12-11 20:56:32,493 iteration 3397 : loss : 0.023982, loss_ce: 0.009319
2021-12-11 20:56:34,091 iteration 3398 : loss : 0.029036, loss_ce: 0.013422
2021-12-11 20:56:35,637 iteration 3399 : loss : 0.033378, loss_ce: 0.010639
2021-12-11 20:56:35,638 Training Data Eval:
2021-12-11 20:56:43,388   Average segmentation loss on training set: 0.0188
2021-12-11 20:56:43,389 Validation Data Eval:
2021-12-11 20:56:46,037   Average segmentation loss on validation set: 0.0734
2021-12-11 20:56:47,960 Found new lowest validation loss at iteration 3399! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/NEW_TU/UNET_ADAM_best_val_loss_seed2.pth
2021-12-11 20:56:49,443 iteration 3400 : loss : 0.024989, loss_ce: 0.008782
2021-12-11 20:56:51,485 save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/NEW_TU/UNET_ADAM_seed2epoch_199.pth
 50%|█████████████▌             | 200/400 [1:36:36<1:45:32, 31.66s/it]2021-12-11 20:56:53,013 iteration 3401 : loss : 0.025292, loss_ce: 0.011318
2021-12-11 20:56:54,501 iteration 3402 : loss : 0.021791, loss_ce: 0.008454
2021-12-11 20:56:56,154 iteration 3403 : loss : 0.032804, loss_ce: 0.012443
2021-12-11 20:56:57,779 iteration 3404 : loss : 0.027944, loss_ce: 0.010665
2021-12-11 20:56:59,279 iteration 3405 : loss : 0.040588, loss_ce: 0.008905
2021-12-11 20:57:00,917 iteration 3406 : loss : 0.022547, loss_ce: 0.007626
2021-12-11 20:57:02,454 iteration 3407 : loss : 0.023743, loss_ce: 0.008592
2021-12-11 20:57:03,929 iteration 3408 : loss : 0.026448, loss_ce: 0.008970
2021-12-11 20:57:05,486 iteration 3409 : loss : 0.024965, loss_ce: 0.008790
2021-12-11 20:57:07,075 iteration 3410 : loss : 0.025568, loss_ce: 0.011647
2021-12-11 20:57:08,695 iteration 3411 : loss : 0.027871, loss_ce: 0.010835
2021-12-11 20:57:10,288 iteration 3412 : loss : 0.023917, loss_ce: 0.010304
2021-12-11 20:57:11,855 iteration 3413 : loss : 0.031511, loss_ce: 0.008487
2021-12-11 20:57:13,498 iteration 3414 : loss : 0.046723, loss_ce: 0.019241
2021-12-11 20:57:15,080 iteration 3415 : loss : 0.020897, loss_ce: 0.009160
2021-12-11 20:57:16,735 iteration 3416 : loss : 0.023284, loss_ce: 0.007097
2021-12-11 20:57:18,370 iteration 3417 : loss : 0.028892, loss_ce: 0.009681
 50%|█████████████▌             | 201/400 [1:37:03<1:40:18, 30.24s/it]2021-12-11 20:57:19,921 iteration 3418 : loss : 0.017779, loss_ce: 0.005660
2021-12-11 20:57:21,371 iteration 3419 : loss : 0.021874, loss_ce: 0.010103
2021-12-11 20:57:22,881 iteration 3420 : loss : 0.022226, loss_ce: 0.007801
2021-12-11 20:57:24,369 iteration 3421 : loss : 0.021687, loss_ce: 0.008226
2021-12-11 20:57:25,851 iteration 3422 : loss : 0.024242, loss_ce: 0.008055
2021-12-11 20:57:27,432 iteration 3423 : loss : 0.028127, loss_ce: 0.013720
2021-12-11 20:57:29,006 iteration 3424 : loss : 0.028024, loss_ce: 0.012140
2021-12-11 20:57:30,590 iteration 3425 : loss : 0.022567, loss_ce: 0.008075
2021-12-11 20:57:32,038 iteration 3426 : loss : 0.025873, loss_ce: 0.009653
2021-12-11 20:57:33,598 iteration 3427 : loss : 0.025427, loss_ce: 0.007114
2021-12-11 20:57:35,187 iteration 3428 : loss : 0.021916, loss_ce: 0.007327
2021-12-11 20:57:36,699 iteration 3429 : loss : 0.019716, loss_ce: 0.005771
2021-12-11 20:57:38,284 iteration 3430 : loss : 0.023778, loss_ce: 0.009438
2021-12-11 20:57:39,861 iteration 3431 : loss : 0.029365, loss_ce: 0.009402
2021-12-11 20:57:41,501 iteration 3432 : loss : 0.027294, loss_ce: 0.010257
2021-12-11 20:57:43,126 iteration 3433 : loss : 0.026800, loss_ce: 0.009433
2021-12-11 20:57:44,694 iteration 3434 : loss : 0.025567, loss_ce: 0.007488
 50%|█████████████▋             | 202/400 [1:37:29<1:35:55, 29.07s/it]2021-12-11 20:57:46,303 iteration 3435 : loss : 0.029842, loss_ce: 0.010173
2021-12-11 20:57:47,935 iteration 3436 : loss : 0.044282, loss_ce: 0.017105
2021-12-11 20:57:49,583 iteration 3437 : loss : 0.024807, loss_ce: 0.008379
2021-12-11 20:57:51,236 iteration 3438 : loss : 0.037116, loss_ce: 0.013220
2021-12-11 20:57:52,742 iteration 3439 : loss : 0.023434, loss_ce: 0.008266
2021-12-11 20:57:54,342 iteration 3440 : loss : 0.031320, loss_ce: 0.012864
2021-12-11 20:57:55,884 iteration 3441 : loss : 0.027011, loss_ce: 0.008826
2021-12-11 20:57:57,452 iteration 3442 : loss : 0.022730, loss_ce: 0.009035
2021-12-11 20:57:59,123 iteration 3443 : loss : 0.033677, loss_ce: 0.015470
2021-12-11 20:58:00,655 iteration 3444 : loss : 0.032212, loss_ce: 0.010048
2021-12-11 20:58:02,245 iteration 3445 : loss : 0.037723, loss_ce: 0.017205
2021-12-11 20:58:03,875 iteration 3446 : loss : 0.022746, loss_ce: 0.010831
2021-12-11 20:58:05,494 iteration 3447 : loss : 0.046698, loss_ce: 0.015749
2021-12-11 20:58:06,993 iteration 3448 : loss : 0.025297, loss_ce: 0.009398
2021-12-11 20:58:08,516 iteration 3449 : loss : 0.023212, loss_ce: 0.009447
2021-12-11 20:58:10,047 iteration 3450 : loss : 0.024179, loss_ce: 0.008699
2021-12-11 20:58:11,575 iteration 3451 : loss : 0.018691, loss_ce: 0.010287
 51%|█████████████▋             | 203/400 [1:37:56<1:33:18, 28.42s/it]2021-12-11 20:58:13,107 iteration 3452 : loss : 0.020051, loss_ce: 0.008038
2021-12-11 20:58:14,718 iteration 3453 : loss : 0.027103, loss_ce: 0.010072
2021-12-11 20:58:16,444 iteration 3454 : loss : 0.034380, loss_ce: 0.014672
2021-12-11 20:58:17,990 iteration 3455 : loss : 0.031923, loss_ce: 0.013529
2021-12-11 20:58:19,582 iteration 3456 : loss : 0.037486, loss_ce: 0.011380
2021-12-11 20:58:21,091 iteration 3457 : loss : 0.020882, loss_ce: 0.008307
2021-12-11 20:58:22,588 iteration 3458 : loss : 0.024949, loss_ce: 0.006990
2021-12-11 20:58:24,212 iteration 3459 : loss : 0.027310, loss_ce: 0.011738
2021-12-11 20:58:25,716 iteration 3460 : loss : 0.020987, loss_ce: 0.008475
2021-12-11 20:58:27,207 iteration 3461 : loss : 0.018479, loss_ce: 0.006180
2021-12-11 20:58:28,641 iteration 3462 : loss : 0.019145, loss_ce: 0.008827
2021-12-11 20:58:30,236 iteration 3463 : loss : 0.022883, loss_ce: 0.009078
2021-12-11 20:58:31,820 iteration 3464 : loss : 0.028690, loss_ce: 0.008674
2021-12-11 20:58:33,335 iteration 3465 : loss : 0.022173, loss_ce: 0.007570
2021-12-11 20:58:34,987 iteration 3466 : loss : 0.033088, loss_ce: 0.013462
2021-12-11 20:58:36,457 iteration 3467 : loss : 0.015742, loss_ce: 0.005831
2021-12-11 20:58:37,998 iteration 3468 : loss : 0.021770, loss_ce: 0.006706
 51%|█████████████▊             | 204/400 [1:38:22<1:30:51, 27.81s/it]2021-12-11 20:58:39,592 iteration 3469 : loss : 0.021840, loss_ce: 0.009071
2021-12-11 20:58:41,128 iteration 3470 : loss : 0.024535, loss_ce: 0.008589
2021-12-11 20:58:42,759 iteration 3471 : loss : 0.025368, loss_ce: 0.008492
2021-12-11 20:58:44,410 iteration 3472 : loss : 0.036185, loss_ce: 0.012275
2021-12-11 20:58:45,913 iteration 3473 : loss : 0.017715, loss_ce: 0.007611
2021-12-11 20:58:47,526 iteration 3474 : loss : 0.028634, loss_ce: 0.009653
2021-12-11 20:58:49,090 iteration 3475 : loss : 0.017500, loss_ce: 0.007351
2021-12-11 20:58:50,618 iteration 3476 : loss : 0.025963, loss_ce: 0.008782
2021-12-11 20:58:52,161 iteration 3477 : loss : 0.018275, loss_ce: 0.006138
2021-12-11 20:58:53,735 iteration 3478 : loss : 0.022695, loss_ce: 0.008809
2021-12-11 20:58:55,281 iteration 3479 : loss : 0.022884, loss_ce: 0.009277
2021-12-11 20:58:56,785 iteration 3480 : loss : 0.027743, loss_ce: 0.013892
2021-12-11 20:58:58,305 iteration 3481 : loss : 0.027988, loss_ce: 0.008155
2021-12-11 20:58:59,854 iteration 3482 : loss : 0.021650, loss_ce: 0.008384
2021-12-11 20:59:01,493 iteration 3483 : loss : 0.036454, loss_ce: 0.018841
2021-12-11 20:59:03,080 iteration 3484 : loss : 0.029930, loss_ce: 0.009568
2021-12-11 20:59:03,080 Training Data Eval:
2021-12-11 20:59:10,846   Average segmentation loss on training set: 0.0162
2021-12-11 20:59:10,846 Validation Data Eval:
2021-12-11 20:59:13,503   Average segmentation loss on validation set: 0.0784
2021-12-11 20:59:15,040 iteration 3485 : loss : 0.021665, loss_ce: 0.008443
 51%|█████████████▊             | 205/400 [1:38:59<1:39:23, 30.58s/it]2021-12-11 20:59:16,675 iteration 3486 : loss : 0.028121, loss_ce: 0.008035
2021-12-11 20:59:18,231 iteration 3487 : loss : 0.023939, loss_ce: 0.009382
2021-12-11 20:59:19,787 iteration 3488 : loss : 0.026595, loss_ce: 0.007177
2021-12-11 20:59:21,220 iteration 3489 : loss : 0.026183, loss_ce: 0.011385
2021-12-11 20:59:22,819 iteration 3490 : loss : 0.027514, loss_ce: 0.009738
2021-12-11 20:59:24,458 iteration 3491 : loss : 0.032305, loss_ce: 0.013995
2021-12-11 20:59:26,040 iteration 3492 : loss : 0.017718, loss_ce: 0.005648
2021-12-11 20:59:27,577 iteration 3493 : loss : 0.030939, loss_ce: 0.011171
2021-12-11 20:59:29,158 iteration 3494 : loss : 0.020003, loss_ce: 0.006849
2021-12-11 20:59:30,761 iteration 3495 : loss : 0.024722, loss_ce: 0.007978
2021-12-11 20:59:32,460 iteration 3496 : loss : 0.038934, loss_ce: 0.014460
2021-12-11 20:59:34,036 iteration 3497 : loss : 0.021015, loss_ce: 0.008657
2021-12-11 20:59:35,655 iteration 3498 : loss : 0.025627, loss_ce: 0.010738
2021-12-11 20:59:37,192 iteration 3499 : loss : 0.022018, loss_ce: 0.010909
2021-12-11 20:59:38,768 iteration 3500 : loss : 0.022801, loss_ce: 0.008908
2021-12-11 20:59:40,449 iteration 3501 : loss : 0.030344, loss_ce: 0.011309
2021-12-11 20:59:42,018 iteration 3502 : loss : 0.020494, loss_ce: 0.010791
 52%|█████████████▉             | 206/400 [1:39:26<1:35:23, 29.50s/it]2021-12-11 20:59:43,676 iteration 3503 : loss : 0.040223, loss_ce: 0.010146
2021-12-11 20:59:45,244 iteration 3504 : loss : 0.021043, loss_ce: 0.006882
2021-12-11 20:59:46,807 iteration 3505 : loss : 0.017137, loss_ce: 0.007419
2021-12-11 20:59:48,437 iteration 3506 : loss : 0.029486, loss_ce: 0.009696
2021-12-11 20:59:49,938 iteration 3507 : loss : 0.019780, loss_ce: 0.007736
2021-12-11 20:59:51,493 iteration 3508 : loss : 0.026675, loss_ce: 0.006875
2021-12-11 20:59:53,104 iteration 3509 : loss : 0.028499, loss_ce: 0.012214
2021-12-11 20:59:54,662 iteration 3510 : loss : 0.022121, loss_ce: 0.008637
2021-12-11 20:59:56,463 iteration 3511 : loss : 0.039490, loss_ce: 0.017177
2021-12-11 20:59:57,969 iteration 3512 : loss : 0.019010, loss_ce: 0.006922
2021-12-11 20:59:59,441 iteration 3513 : loss : 0.021572, loss_ce: 0.009256
2021-12-11 21:00:01,002 iteration 3514 : loss : 0.024557, loss_ce: 0.010766
2021-12-11 21:00:02,556 iteration 3515 : loss : 0.025307, loss_ce: 0.011834
2021-12-11 21:00:04,095 iteration 3516 : loss : 0.021788, loss_ce: 0.009251
2021-12-11 21:00:05,647 iteration 3517 : loss : 0.024302, loss_ce: 0.010830
2021-12-11 21:00:07,320 iteration 3518 : loss : 0.044786, loss_ce: 0.016364
2021-12-11 21:00:08,945 iteration 3519 : loss : 0.022862, loss_ce: 0.008687
 52%|█████████████▉             | 207/400 [1:39:53<1:32:24, 28.73s/it]2021-12-11 21:00:10,496 iteration 3520 : loss : 0.024577, loss_ce: 0.008637
2021-12-11 21:00:12,042 iteration 3521 : loss : 0.027752, loss_ce: 0.006722
2021-12-11 21:00:13,539 iteration 3522 : loss : 0.025022, loss_ce: 0.006669
2021-12-11 21:00:15,140 iteration 3523 : loss : 0.036048, loss_ce: 0.019798
2021-12-11 21:00:16,792 iteration 3524 : loss : 0.026589, loss_ce: 0.011415
2021-12-11 21:00:18,315 iteration 3525 : loss : 0.026826, loss_ce: 0.007094
2021-12-11 21:00:19,909 iteration 3526 : loss : 0.023216, loss_ce: 0.012496
2021-12-11 21:00:21,570 iteration 3527 : loss : 0.031913, loss_ce: 0.011807
2021-12-11 21:00:23,107 iteration 3528 : loss : 0.051915, loss_ce: 0.009336
2021-12-11 21:00:24,667 iteration 3529 : loss : 0.024757, loss_ce: 0.008126
2021-12-11 21:00:26,225 iteration 3530 : loss : 0.027777, loss_ce: 0.009823
2021-12-11 21:00:27,785 iteration 3531 : loss : 0.033613, loss_ce: 0.011353
2021-12-11 21:00:29,372 iteration 3532 : loss : 0.026984, loss_ce: 0.011052
2021-12-11 21:00:30,974 iteration 3533 : loss : 0.039704, loss_ce: 0.016080
2021-12-11 21:00:32,500 iteration 3534 : loss : 0.046787, loss_ce: 0.019449
2021-12-11 21:00:34,079 iteration 3535 : loss : 0.037071, loss_ce: 0.014799
2021-12-11 21:00:35,617 iteration 3536 : loss : 0.049864, loss_ce: 0.022362
 52%|██████████████             | 208/400 [1:40:20<1:29:57, 28.11s/it]2021-12-11 21:00:37,335 iteration 3537 : loss : 0.035981, loss_ce: 0.015498
2021-12-11 21:00:38,858 iteration 3538 : loss : 0.029795, loss_ce: 0.010703
2021-12-11 21:00:40,379 iteration 3539 : loss : 0.030315, loss_ce: 0.009856
2021-12-11 21:00:41,983 iteration 3540 : loss : 0.040961, loss_ce: 0.016598
2021-12-11 21:00:43,602 iteration 3541 : loss : 0.029764, loss_ce: 0.011084
2021-12-11 21:00:45,196 iteration 3542 : loss : 0.029817, loss_ce: 0.011098
2021-12-11 21:00:46,851 iteration 3543 : loss : 0.036396, loss_ce: 0.015442
2021-12-11 21:00:48,481 iteration 3544 : loss : 0.042906, loss_ce: 0.009866
2021-12-11 21:00:50,119 iteration 3545 : loss : 0.031222, loss_ce: 0.010872
2021-12-11 21:00:51,746 iteration 3546 : loss : 0.037188, loss_ce: 0.013843
2021-12-11 21:00:53,397 iteration 3547 : loss : 0.037037, loss_ce: 0.014456
2021-12-11 21:00:54,917 iteration 3548 : loss : 0.021432, loss_ce: 0.006723
2021-12-11 21:00:56,586 iteration 3549 : loss : 0.045912, loss_ce: 0.024268
2021-12-11 21:00:58,126 iteration 3550 : loss : 0.026692, loss_ce: 0.009357
2021-12-11 21:00:59,651 iteration 3551 : loss : 0.034881, loss_ce: 0.014622
2021-12-11 21:01:01,162 iteration 3552 : loss : 0.035647, loss_ce: 0.018136
2021-12-11 21:01:02,684 iteration 3553 : loss : 0.022521, loss_ce: 0.008751
 52%|██████████████             | 209/400 [1:40:47<1:28:30, 27.80s/it]2021-12-11 21:01:04,301 iteration 3554 : loss : 0.032257, loss_ce: 0.013005
2021-12-11 21:01:05,850 iteration 3555 : loss : 0.029967, loss_ce: 0.012951
2021-12-11 21:01:07,489 iteration 3556 : loss : 0.029723, loss_ce: 0.014054
2021-12-11 21:01:09,153 iteration 3557 : loss : 0.033948, loss_ce: 0.013438
2021-12-11 21:01:10,708 iteration 3558 : loss : 0.029192, loss_ce: 0.009898
2021-12-11 21:01:12,290 iteration 3559 : loss : 0.049795, loss_ce: 0.014117
2021-12-11 21:01:13,836 iteration 3560 : loss : 0.029234, loss_ce: 0.012569
2021-12-11 21:01:15,298 iteration 3561 : loss : 0.018263, loss_ce: 0.008729
2021-12-11 21:01:16,875 iteration 3562 : loss : 0.036374, loss_ce: 0.015924
2021-12-11 21:01:18,444 iteration 3563 : loss : 0.034413, loss_ce: 0.012406
2021-12-11 21:01:20,063 iteration 3564 : loss : 0.046013, loss_ce: 0.014011
2021-12-11 21:01:21,575 iteration 3565 : loss : 0.032822, loss_ce: 0.008223
2021-12-11 21:01:23,087 iteration 3566 : loss : 0.025815, loss_ce: 0.010143
2021-12-11 21:01:24,736 iteration 3567 : loss : 0.030615, loss_ce: 0.013504
2021-12-11 21:01:26,294 iteration 3568 : loss : 0.032309, loss_ce: 0.011273
2021-12-11 21:01:27,807 iteration 3569 : loss : 0.032014, loss_ce: 0.016377
2021-12-11 21:01:27,807 Training Data Eval:
2021-12-11 21:01:35,560   Average segmentation loss on training set: 0.0179
2021-12-11 21:01:35,561 Validation Data Eval:
2021-12-11 21:01:38,212   Average segmentation loss on validation set: 0.1196
2021-12-11 21:01:39,808 iteration 3570 : loss : 0.038292, loss_ce: 0.011073
 52%|██████████████▏            | 210/400 [1:41:24<1:36:53, 30.60s/it]2021-12-11 21:01:41,459 iteration 3571 : loss : 0.022481, loss_ce: 0.010945
2021-12-11 21:01:42,952 iteration 3572 : loss : 0.020280, loss_ce: 0.007265
2021-12-11 21:01:44,531 iteration 3573 : loss : 0.029032, loss_ce: 0.010478
2021-12-11 21:01:46,099 iteration 3574 : loss : 0.026199, loss_ce: 0.007143
2021-12-11 21:01:47,598 iteration 3575 : loss : 0.026960, loss_ce: 0.008710
2021-12-11 21:01:49,210 iteration 3576 : loss : 0.023425, loss_ce: 0.006543
2021-12-11 21:01:50,795 iteration 3577 : loss : 0.023758, loss_ce: 0.009389
2021-12-11 21:01:52,248 iteration 3578 : loss : 0.027140, loss_ce: 0.009757
2021-12-11 21:01:53,772 iteration 3579 : loss : 0.027738, loss_ce: 0.010734
2021-12-11 21:01:55,299 iteration 3580 : loss : 0.025543, loss_ce: 0.009871
2021-12-11 21:01:56,794 iteration 3581 : loss : 0.027219, loss_ce: 0.014957
2021-12-11 21:01:58,336 iteration 3582 : loss : 0.023032, loss_ce: 0.008731
2021-12-11 21:01:59,935 iteration 3583 : loss : 0.031312, loss_ce: 0.010036
2021-12-11 21:02:01,508 iteration 3584 : loss : 0.026582, loss_ce: 0.008429
2021-12-11 21:02:03,012 iteration 3585 : loss : 0.038695, loss_ce: 0.013831
2021-12-11 21:02:04,646 iteration 3586 : loss : 0.031031, loss_ce: 0.013944
2021-12-11 21:02:06,198 iteration 3587 : loss : 0.022260, loss_ce: 0.008671
 53%|██████████████▏            | 211/400 [1:41:51<1:32:24, 29.33s/it]2021-12-11 21:02:07,890 iteration 3588 : loss : 0.020009, loss_ce: 0.008057
2021-12-11 21:02:09,375 iteration 3589 : loss : 0.020902, loss_ce: 0.006257
2021-12-11 21:02:10,898 iteration 3590 : loss : 0.024684, loss_ce: 0.010492
2021-12-11 21:02:12,448 iteration 3591 : loss : 0.019997, loss_ce: 0.006470
2021-12-11 21:02:14,199 iteration 3592 : loss : 0.031073, loss_ce: 0.011820
2021-12-11 21:02:15,738 iteration 3593 : loss : 0.021368, loss_ce: 0.007723
2021-12-11 21:02:17,287 iteration 3594 : loss : 0.025621, loss_ce: 0.010287
2021-12-11 21:02:18,881 iteration 3595 : loss : 0.032719, loss_ce: 0.013252
2021-12-11 21:02:20,449 iteration 3596 : loss : 0.017864, loss_ce: 0.006104
2021-12-11 21:02:22,054 iteration 3597 : loss : 0.029883, loss_ce: 0.011873
2021-12-11 21:02:23,543 iteration 3598 : loss : 0.020244, loss_ce: 0.008597
2021-12-11 21:02:25,150 iteration 3599 : loss : 0.029424, loss_ce: 0.009661
2021-12-11 21:02:26,594 iteration 3600 : loss : 0.020415, loss_ce: 0.007684
2021-12-11 21:02:28,154 iteration 3601 : loss : 0.025154, loss_ce: 0.010807
2021-12-11 21:02:29,644 iteration 3602 : loss : 0.019899, loss_ce: 0.006428
2021-12-11 21:02:31,218 iteration 3603 : loss : 0.022733, loss_ce: 0.012394
2021-12-11 21:02:32,700 iteration 3604 : loss : 0.017527, loss_ce: 0.006913
 53%|██████████████▎            | 212/400 [1:42:17<1:29:15, 28.49s/it]2021-12-11 21:02:34,324 iteration 3605 : loss : 0.024808, loss_ce: 0.008711
2021-12-11 21:02:35,851 iteration 3606 : loss : 0.024937, loss_ce: 0.012039
2021-12-11 21:02:37,433 iteration 3607 : loss : 0.040143, loss_ce: 0.017256
2021-12-11 21:02:38,973 iteration 3608 : loss : 0.020993, loss_ce: 0.007673
2021-12-11 21:02:40,496 iteration 3609 : loss : 0.019493, loss_ce: 0.008499
2021-12-11 21:02:42,055 iteration 3610 : loss : 0.022733, loss_ce: 0.008943
2021-12-11 21:02:43,533 iteration 3611 : loss : 0.028275, loss_ce: 0.008044
2021-12-11 21:02:45,011 iteration 3612 : loss : 0.021290, loss_ce: 0.006820
2021-12-11 21:02:46,675 iteration 3613 : loss : 0.030809, loss_ce: 0.011874
2021-12-11 21:02:48,172 iteration 3614 : loss : 0.019760, loss_ce: 0.007308
2021-12-11 21:02:49,626 iteration 3615 : loss : 0.021691, loss_ce: 0.007274
2021-12-11 21:02:51,195 iteration 3616 : loss : 0.023762, loss_ce: 0.009175
2021-12-11 21:02:52,790 iteration 3617 : loss : 0.023241, loss_ce: 0.008759
2021-12-11 21:02:54,366 iteration 3618 : loss : 0.018830, loss_ce: 0.007877
2021-12-11 21:02:55,917 iteration 3619 : loss : 0.026899, loss_ce: 0.007840
2021-12-11 21:02:57,422 iteration 3620 : loss : 0.022030, loss_ce: 0.006439
2021-12-11 21:02:58,995 iteration 3621 : loss : 0.032258, loss_ce: 0.011582
 53%|██████████████▍            | 213/400 [1:42:43<1:26:43, 27.82s/it]2021-12-11 21:03:00,612 iteration 3622 : loss : 0.028992, loss_ce: 0.014115
2021-12-11 21:03:02,236 iteration 3623 : loss : 0.021086, loss_ce: 0.004733
2021-12-11 21:03:03,792 iteration 3624 : loss : 0.017041, loss_ce: 0.006818
2021-12-11 21:03:05,343 iteration 3625 : loss : 0.030251, loss_ce: 0.011910
2021-12-11 21:03:06,841 iteration 3626 : loss : 0.021035, loss_ce: 0.010082
2021-12-11 21:03:08,320 iteration 3627 : loss : 0.022284, loss_ce: 0.008291
2021-12-11 21:03:09,935 iteration 3628 : loss : 0.069688, loss_ce: 0.017105
2021-12-11 21:03:11,672 iteration 3629 : loss : 0.024789, loss_ce: 0.010016
2021-12-11 21:03:13,137 iteration 3630 : loss : 0.023844, loss_ce: 0.008625
2021-12-11 21:03:14,697 iteration 3631 : loss : 0.027682, loss_ce: 0.008589
2021-12-11 21:03:16,398 iteration 3632 : loss : 0.029089, loss_ce: 0.010423
2021-12-11 21:03:17,956 iteration 3633 : loss : 0.024251, loss_ce: 0.008834
2021-12-11 21:03:19,495 iteration 3634 : loss : 0.029406, loss_ce: 0.011059
2021-12-11 21:03:21,160 iteration 3635 : loss : 0.040468, loss_ce: 0.017409
2021-12-11 21:03:22,794 iteration 3636 : loss : 0.028459, loss_ce: 0.008509
2021-12-11 21:03:24,354 iteration 3637 : loss : 0.034253, loss_ce: 0.011612
2021-12-11 21:03:25,908 iteration 3638 : loss : 0.021298, loss_ce: 0.008580
 54%|██████████████▍            | 214/400 [1:43:10<1:25:25, 27.55s/it]2021-12-11 21:03:27,462 iteration 3639 : loss : 0.024563, loss_ce: 0.008487
2021-12-11 21:03:28,952 iteration 3640 : loss : 0.036306, loss_ce: 0.013016
2021-12-11 21:03:30,429 iteration 3641 : loss : 0.020528, loss_ce: 0.006409
2021-12-11 21:03:31,986 iteration 3642 : loss : 0.029168, loss_ce: 0.007422
2021-12-11 21:03:33,472 iteration 3643 : loss : 0.020110, loss_ce: 0.008313
2021-12-11 21:03:34,979 iteration 3644 : loss : 0.014062, loss_ce: 0.005143
2021-12-11 21:03:36,528 iteration 3645 : loss : 0.022911, loss_ce: 0.007567
2021-12-11 21:03:38,080 iteration 3646 : loss : 0.027699, loss_ce: 0.008576
2021-12-11 21:03:39,637 iteration 3647 : loss : 0.030106, loss_ce: 0.007213
2021-12-11 21:03:41,219 iteration 3648 : loss : 0.030380, loss_ce: 0.011316
2021-12-11 21:03:42,760 iteration 3649 : loss : 0.020564, loss_ce: 0.005567
2021-12-11 21:03:44,328 iteration 3650 : loss : 0.025497, loss_ce: 0.012959
2021-12-11 21:03:45,914 iteration 3651 : loss : 0.026405, loss_ce: 0.009266
2021-12-11 21:03:47,626 iteration 3652 : loss : 0.028321, loss_ce: 0.009096
2021-12-11 21:03:49,142 iteration 3653 : loss : 0.023572, loss_ce: 0.011989
2021-12-11 21:03:50,628 iteration 3654 : loss : 0.020613, loss_ce: 0.010256
2021-12-11 21:03:50,664 Training Data Eval:
2021-12-11 21:03:58,417   Average segmentation loss on training set: 0.0197
2021-12-11 21:03:58,417 Validation Data Eval:
2021-12-11 21:04:01,079   Average segmentation loss on validation set: 0.0685
2021-12-11 21:04:03,025 Found new lowest validation loss at iteration 3654! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/NEW_TU/UNET_ADAM_best_val_loss_seed2.pth
2021-12-11 21:04:04,610 iteration 3655 : loss : 0.023566, loss_ce: 0.009153
 54%|██████████████▌            | 215/400 [1:43:49<1:35:16, 30.90s/it]2021-12-11 21:04:06,284 iteration 3656 : loss : 0.023437, loss_ce: 0.009244
2021-12-11 21:04:07,789 iteration 3657 : loss : 0.019596, loss_ce: 0.009292
2021-12-11 21:04:09,417 iteration 3658 : loss : 0.023027, loss_ce: 0.009856
2021-12-11 21:04:11,104 iteration 3659 : loss : 0.037353, loss_ce: 0.012959
2021-12-11 21:04:12,674 iteration 3660 : loss : 0.026978, loss_ce: 0.006308
2021-12-11 21:04:14,174 iteration 3661 : loss : 0.019219, loss_ce: 0.008043
2021-12-11 21:04:15,741 iteration 3662 : loss : 0.020944, loss_ce: 0.007454
2021-12-11 21:04:17,279 iteration 3663 : loss : 0.030649, loss_ce: 0.009825
2021-12-11 21:04:18,880 iteration 3664 : loss : 0.019951, loss_ce: 0.006944
2021-12-11 21:04:20,434 iteration 3665 : loss : 0.031423, loss_ce: 0.016948
2021-12-11 21:04:21,989 iteration 3666 : loss : 0.022779, loss_ce: 0.007164
2021-12-11 21:04:23,531 iteration 3667 : loss : 0.026098, loss_ce: 0.011378
2021-12-11 21:04:24,991 iteration 3668 : loss : 0.021838, loss_ce: 0.004731
2021-12-11 21:04:26,612 iteration 3669 : loss : 0.023254, loss_ce: 0.010457
2021-12-11 21:04:28,116 iteration 3670 : loss : 0.017844, loss_ce: 0.006266
2021-12-11 21:04:29,656 iteration 3671 : loss : 0.020747, loss_ce: 0.009099
2021-12-11 21:04:31,385 iteration 3672 : loss : 0.058905, loss_ce: 0.014462
 54%|██████████████▌            | 216/400 [1:44:16<1:30:57, 29.66s/it]2021-12-11 21:04:33,023 iteration 3673 : loss : 0.022896, loss_ce: 0.009660
2021-12-11 21:04:34,649 iteration 3674 : loss : 0.029252, loss_ce: 0.007142
2021-12-11 21:04:36,313 iteration 3675 : loss : 0.028383, loss_ce: 0.010656
2021-12-11 21:04:37,795 iteration 3676 : loss : 0.020550, loss_ce: 0.007491
2021-12-11 21:04:39,373 iteration 3677 : loss : 0.022224, loss_ce: 0.006171
2021-12-11 21:04:41,019 iteration 3678 : loss : 0.036801, loss_ce: 0.012074
2021-12-11 21:04:42,575 iteration 3679 : loss : 0.019514, loss_ce: 0.006730
2021-12-11 21:04:44,141 iteration 3680 : loss : 0.033916, loss_ce: 0.013026
2021-12-11 21:04:45,692 iteration 3681 : loss : 0.021809, loss_ce: 0.008827
2021-12-11 21:04:47,158 iteration 3682 : loss : 0.022938, loss_ce: 0.007827
2021-12-11 21:04:48,607 iteration 3683 : loss : 0.021306, loss_ce: 0.008081
2021-12-11 21:04:50,231 iteration 3684 : loss : 0.018142, loss_ce: 0.007206
2021-12-11 21:04:51,752 iteration 3685 : loss : 0.023704, loss_ce: 0.007712
2021-12-11 21:04:53,324 iteration 3686 : loss : 0.024142, loss_ce: 0.009525
2021-12-11 21:04:54,845 iteration 3687 : loss : 0.016300, loss_ce: 0.005642
2021-12-11 21:04:56,399 iteration 3688 : loss : 0.023686, loss_ce: 0.011947
2021-12-11 21:04:57,979 iteration 3689 : loss : 0.025221, loss_ce: 0.008786
 54%|██████████████▋            | 217/400 [1:44:42<1:27:39, 28.74s/it]2021-12-11 21:04:59,602 iteration 3690 : loss : 0.038873, loss_ce: 0.011031
2021-12-11 21:05:01,187 iteration 3691 : loss : 0.027490, loss_ce: 0.006381
2021-12-11 21:05:02,771 iteration 3692 : loss : 0.026107, loss_ce: 0.013425
2021-12-11 21:05:04,263 iteration 3693 : loss : 0.018718, loss_ce: 0.008128
2021-12-11 21:05:05,815 iteration 3694 : loss : 0.027200, loss_ce: 0.011048
2021-12-11 21:05:07,382 iteration 3695 : loss : 0.022697, loss_ce: 0.011022
2021-12-11 21:05:08,926 iteration 3696 : loss : 0.030551, loss_ce: 0.009348
2021-12-11 21:05:10,512 iteration 3697 : loss : 0.029668, loss_ce: 0.009046
2021-12-11 21:05:12,167 iteration 3698 : loss : 0.032184, loss_ce: 0.013109
2021-12-11 21:05:13,673 iteration 3699 : loss : 0.020588, loss_ce: 0.008741
2021-12-11 21:05:15,234 iteration 3700 : loss : 0.020656, loss_ce: 0.005761
2021-12-11 21:05:16,684 iteration 3701 : loss : 0.019753, loss_ce: 0.008498
2021-12-11 21:05:18,257 iteration 3702 : loss : 0.030032, loss_ce: 0.013119
2021-12-11 21:05:19,822 iteration 3703 : loss : 0.019061, loss_ce: 0.007884
2021-12-11 21:05:21,273 iteration 3704 : loss : 0.019647, loss_ce: 0.007467
2021-12-11 21:05:22,913 iteration 3705 : loss : 0.029731, loss_ce: 0.010594
2021-12-11 21:05:24,374 iteration 3706 : loss : 0.016820, loss_ce: 0.005035
 55%|██████████████▋            | 218/400 [1:45:09<1:25:02, 28.04s/it]2021-12-11 21:05:26,028 iteration 3707 : loss : 0.021732, loss_ce: 0.010936
2021-12-11 21:05:27,505 iteration 3708 : loss : 0.022282, loss_ce: 0.007968
2021-12-11 21:05:29,192 iteration 3709 : loss : 0.040414, loss_ce: 0.012506
2021-12-11 21:05:30,760 iteration 3710 : loss : 0.025986, loss_ce: 0.009266
2021-12-11 21:05:32,272 iteration 3711 : loss : 0.019159, loss_ce: 0.006348
2021-12-11 21:05:33,766 iteration 3712 : loss : 0.020912, loss_ce: 0.009273
2021-12-11 21:05:35,441 iteration 3713 : loss : 0.024526, loss_ce: 0.008701
2021-12-11 21:05:37,003 iteration 3714 : loss : 0.022458, loss_ce: 0.009268
2021-12-11 21:05:38,527 iteration 3715 : loss : 0.019466, loss_ce: 0.008262
2021-12-11 21:05:40,082 iteration 3716 : loss : 0.026447, loss_ce: 0.013995
2021-12-11 21:05:41,695 iteration 3717 : loss : 0.022872, loss_ce: 0.009875
2021-12-11 21:05:43,233 iteration 3718 : loss : 0.020674, loss_ce: 0.007867
2021-12-11 21:05:44,806 iteration 3719 : loss : 0.022562, loss_ce: 0.008767
2021-12-11 21:05:46,484 iteration 3720 : loss : 0.033843, loss_ce: 0.010672
2021-12-11 21:05:48,018 iteration 3721 : loss : 0.021578, loss_ce: 0.008838
2021-12-11 21:05:49,558 iteration 3722 : loss : 0.022584, loss_ce: 0.009886
2021-12-11 21:05:51,190 iteration 3723 : loss : 0.031347, loss_ce: 0.008400
 55%|██████████████▊            | 219/400 [1:45:36<1:23:28, 27.67s/it]2021-12-11 21:05:52,878 iteration 3724 : loss : 0.023652, loss_ce: 0.008746
2021-12-11 21:05:54,445 iteration 3725 : loss : 0.033736, loss_ce: 0.013357
2021-12-11 21:05:56,161 iteration 3726 : loss : 0.021671, loss_ce: 0.007239
2021-12-11 21:05:57,679 iteration 3727 : loss : 0.019141, loss_ce: 0.006239
2021-12-11 21:05:59,236 iteration 3728 : loss : 0.031500, loss_ce: 0.016975
2021-12-11 21:06:00,873 iteration 3729 : loss : 0.033900, loss_ce: 0.011182
2021-12-11 21:06:02,417 iteration 3730 : loss : 0.032407, loss_ce: 0.009257
2021-12-11 21:06:03,912 iteration 3731 : loss : 0.025631, loss_ce: 0.008360
2021-12-11 21:06:05,479 iteration 3732 : loss : 0.028555, loss_ce: 0.011091
2021-12-11 21:06:07,018 iteration 3733 : loss : 0.028794, loss_ce: 0.009274
2021-12-11 21:06:08,593 iteration 3734 : loss : 0.022675, loss_ce: 0.008749
2021-12-11 21:06:10,173 iteration 3735 : loss : 0.030926, loss_ce: 0.014498
2021-12-11 21:06:11,784 iteration 3736 : loss : 0.026265, loss_ce: 0.007728
2021-12-11 21:06:13,359 iteration 3737 : loss : 0.029560, loss_ce: 0.011455
2021-12-11 21:06:14,922 iteration 3738 : loss : 0.034860, loss_ce: 0.011783
2021-12-11 21:06:16,483 iteration 3739 : loss : 0.021349, loss_ce: 0.007007
2021-12-11 21:06:16,483 Training Data Eval:
2021-12-11 21:06:24,217   Average segmentation loss on training set: 0.0169
2021-12-11 21:06:24,217 Validation Data Eval:
2021-12-11 21:06:26,923   Average segmentation loss on validation set: 0.0873
2021-12-11 21:06:28,533 iteration 3740 : loss : 0.022773, loss_ce: 0.007403
 55%|██████████████▊            | 220/400 [1:46:13<1:31:43, 30.57s/it]2021-12-11 21:06:30,174 iteration 3741 : loss : 0.026162, loss_ce: 0.010343
2021-12-11 21:06:31,693 iteration 3742 : loss : 0.025847, loss_ce: 0.011403
2021-12-11 21:06:33,229 iteration 3743 : loss : 0.022123, loss_ce: 0.007278
2021-12-11 21:06:34,837 iteration 3744 : loss : 0.022314, loss_ce: 0.009191
2021-12-11 21:06:36,345 iteration 3745 : loss : 0.020250, loss_ce: 0.007663
2021-12-11 21:06:37,948 iteration 3746 : loss : 0.018075, loss_ce: 0.006779
2021-12-11 21:06:39,550 iteration 3747 : loss : 0.037821, loss_ce: 0.006670
2021-12-11 21:06:41,114 iteration 3748 : loss : 0.025580, loss_ce: 0.011623
2021-12-11 21:06:42,661 iteration 3749 : loss : 0.024836, loss_ce: 0.011461
2021-12-11 21:06:44,236 iteration 3750 : loss : 0.027500, loss_ce: 0.009906
2021-12-11 21:06:45,827 iteration 3751 : loss : 0.038535, loss_ce: 0.009888
2021-12-11 21:06:47,393 iteration 3752 : loss : 0.021575, loss_ce: 0.008405
2021-12-11 21:06:48,896 iteration 3753 : loss : 0.033695, loss_ce: 0.010367
2021-12-11 21:06:50,373 iteration 3754 : loss : 0.016080, loss_ce: 0.005544
2021-12-11 21:06:51,885 iteration 3755 : loss : 0.022069, loss_ce: 0.009893
2021-12-11 21:06:53,438 iteration 3756 : loss : 0.027650, loss_ce: 0.010507
2021-12-11 21:06:55,000 iteration 3757 : loss : 0.025722, loss_ce: 0.008397
 55%|██████████████▉            | 221/400 [1:46:39<1:27:32, 29.34s/it]2021-12-11 21:06:56,644 iteration 3758 : loss : 0.029494, loss_ce: 0.011000
2021-12-11 21:06:58,205 iteration 3759 : loss : 0.019695, loss_ce: 0.006683
2021-12-11 21:06:59,659 iteration 3760 : loss : 0.021271, loss_ce: 0.007194
2021-12-11 21:07:01,272 iteration 3761 : loss : 0.033327, loss_ce: 0.012463
2021-12-11 21:07:02,831 iteration 3762 : loss : 0.026933, loss_ce: 0.007811
2021-12-11 21:07:04,459 iteration 3763 : loss : 0.037555, loss_ce: 0.015500
2021-12-11 21:07:06,063 iteration 3764 : loss : 0.024518, loss_ce: 0.009471
2021-12-11 21:07:07,626 iteration 3765 : loss : 0.022634, loss_ce: 0.008791
2021-12-11 21:07:09,176 iteration 3766 : loss : 0.028388, loss_ce: 0.011086
2021-12-11 21:07:10,823 iteration 3767 : loss : 0.028461, loss_ce: 0.008978
2021-12-11 21:07:12,398 iteration 3768 : loss : 0.022798, loss_ce: 0.010016
2021-12-11 21:07:13,927 iteration 3769 : loss : 0.018238, loss_ce: 0.007521
2021-12-11 21:07:15,418 iteration 3770 : loss : 0.019404, loss_ce: 0.006505
2021-12-11 21:07:16,933 iteration 3771 : loss : 0.018140, loss_ce: 0.006494
2021-12-11 21:07:18,481 iteration 3772 : loss : 0.021670, loss_ce: 0.006761
2021-12-11 21:07:19,955 iteration 3773 : loss : 0.017438, loss_ce: 0.006033
2021-12-11 21:07:21,440 iteration 3774 : loss : 0.020166, loss_ce: 0.008029
 56%|██████████████▉            | 222/400 [1:47:06<1:24:27, 28.47s/it]2021-12-11 21:07:23,012 iteration 3775 : loss : 0.030061, loss_ce: 0.007416
2021-12-11 21:07:24,607 iteration 3776 : loss : 0.031265, loss_ce: 0.012037
2021-12-11 21:07:26,303 iteration 3777 : loss : 0.031863, loss_ce: 0.010752
2021-12-11 21:07:27,836 iteration 3778 : loss : 0.016279, loss_ce: 0.007735
2021-12-11 21:07:29,443 iteration 3779 : loss : 0.018367, loss_ce: 0.006600
2021-12-11 21:07:30,982 iteration 3780 : loss : 0.024148, loss_ce: 0.011960
2021-12-11 21:07:32,529 iteration 3781 : loss : 0.021997, loss_ce: 0.007606
2021-12-11 21:07:34,108 iteration 3782 : loss : 0.025884, loss_ce: 0.010843
2021-12-11 21:07:35,713 iteration 3783 : loss : 0.016777, loss_ce: 0.005319
2021-12-11 21:07:37,326 iteration 3784 : loss : 0.025104, loss_ce: 0.010621
2021-12-11 21:07:38,841 iteration 3785 : loss : 0.018504, loss_ce: 0.006865
2021-12-11 21:07:40,414 iteration 3786 : loss : 0.017629, loss_ce: 0.005440
2021-12-11 21:07:42,054 iteration 3787 : loss : 0.046932, loss_ce: 0.019965
2021-12-11 21:07:43,691 iteration 3788 : loss : 0.027815, loss_ce: 0.010474
2021-12-11 21:07:45,211 iteration 3789 : loss : 0.023012, loss_ce: 0.006665
2021-12-11 21:07:46,795 iteration 3790 : loss : 0.023373, loss_ce: 0.008763
2021-12-11 21:07:48,256 iteration 3791 : loss : 0.020260, loss_ce: 0.007643
 56%|███████████████            | 223/400 [1:47:33<1:22:31, 27.97s/it]2021-12-11 21:07:49,861 iteration 3792 : loss : 0.018607, loss_ce: 0.007442
2021-12-11 21:07:51,419 iteration 3793 : loss : 0.021466, loss_ce: 0.009101
2021-12-11 21:07:52,914 iteration 3794 : loss : 0.019744, loss_ce: 0.007336
2021-12-11 21:07:54,592 iteration 3795 : loss : 0.028831, loss_ce: 0.011582
2021-12-11 21:07:56,194 iteration 3796 : loss : 0.045757, loss_ce: 0.011163
2021-12-11 21:07:57,725 iteration 3797 : loss : 0.018214, loss_ce: 0.006212
2021-12-11 21:07:59,396 iteration 3798 : loss : 0.020136, loss_ce: 0.007234
2021-12-11 21:08:00,910 iteration 3799 : loss : 0.019952, loss_ce: 0.011077
2021-12-11 21:08:02,521 iteration 3800 : loss : 0.021498, loss_ce: 0.006758
2021-12-11 21:08:04,026 iteration 3801 : loss : 0.017441, loss_ce: 0.006134
2021-12-11 21:08:05,588 iteration 3802 : loss : 0.019176, loss_ce: 0.005155
2021-12-11 21:08:07,134 iteration 3803 : loss : 0.017922, loss_ce: 0.005874
2021-12-11 21:08:08,580 iteration 3804 : loss : 0.021479, loss_ce: 0.007834
2021-12-11 21:08:10,175 iteration 3805 : loss : 0.021209, loss_ce: 0.008477
2021-12-11 21:08:11,694 iteration 3806 : loss : 0.028797, loss_ce: 0.008510
2021-12-11 21:08:13,235 iteration 3807 : loss : 0.024765, loss_ce: 0.010210
2021-12-11 21:08:14,814 iteration 3808 : loss : 0.023159, loss_ce: 0.008284
 56%|███████████████            | 224/400 [1:47:59<1:20:48, 27.55s/it]2021-12-11 21:08:16,436 iteration 3809 : loss : 0.021126, loss_ce: 0.009048
2021-12-11 21:08:17,989 iteration 3810 : loss : 0.025524, loss_ce: 0.011735
2021-12-11 21:08:19,674 iteration 3811 : loss : 0.024213, loss_ce: 0.007661
2021-12-11 21:08:21,202 iteration 3812 : loss : 0.021945, loss_ce: 0.007611
2021-12-11 21:08:22,786 iteration 3813 : loss : 0.026177, loss_ce: 0.006494
2021-12-11 21:08:24,255 iteration 3814 : loss : 0.017676, loss_ce: 0.005910
2021-12-11 21:08:25,884 iteration 3815 : loss : 0.026555, loss_ce: 0.009136
2021-12-11 21:08:27,574 iteration 3816 : loss : 0.027919, loss_ce: 0.009816
2021-12-11 21:08:29,153 iteration 3817 : loss : 0.020186, loss_ce: 0.009485
2021-12-11 21:08:30,850 iteration 3818 : loss : 0.022553, loss_ce: 0.009541
2021-12-11 21:08:32,360 iteration 3819 : loss : 0.021622, loss_ce: 0.009877
2021-12-11 21:08:33,968 iteration 3820 : loss : 0.026075, loss_ce: 0.011978
2021-12-11 21:08:35,526 iteration 3821 : loss : 0.018585, loss_ce: 0.008196
2021-12-11 21:08:36,978 iteration 3822 : loss : 0.018276, loss_ce: 0.007542
2021-12-11 21:08:38,480 iteration 3823 : loss : 0.018699, loss_ce: 0.006440
2021-12-11 21:08:40,015 iteration 3824 : loss : 0.023378, loss_ce: 0.008827
2021-12-11 21:08:40,016 Training Data Eval:
2021-12-11 21:08:47,760   Average segmentation loss on training set: 0.0141
2021-12-11 21:08:47,761 Validation Data Eval:
2021-12-11 21:08:50,423   Average segmentation loss on validation set: 0.0706
2021-12-11 21:08:51,930 iteration 3825 : loss : 0.021331, loss_ce: 0.007996
 56%|███████████████▏           | 225/400 [1:48:36<1:28:43, 30.42s/it]2021-12-11 21:08:53,437 iteration 3826 : loss : 0.021480, loss_ce: 0.007756
2021-12-11 21:08:55,002 iteration 3827 : loss : 0.025889, loss_ce: 0.009156
2021-12-11 21:08:56,596 iteration 3828 : loss : 0.022740, loss_ce: 0.008814
2021-12-11 21:08:58,152 iteration 3829 : loss : 0.024709, loss_ce: 0.010667
2021-12-11 21:08:59,714 iteration 3830 : loss : 0.024757, loss_ce: 0.010312
2021-12-11 21:09:01,356 iteration 3831 : loss : 0.031522, loss_ce: 0.007355
2021-12-11 21:09:02,819 iteration 3832 : loss : 0.016856, loss_ce: 0.005538
2021-12-11 21:09:04,405 iteration 3833 : loss : 0.023210, loss_ce: 0.007852
2021-12-11 21:09:05,938 iteration 3834 : loss : 0.016138, loss_ce: 0.007944
2021-12-11 21:09:07,549 iteration 3835 : loss : 0.020375, loss_ce: 0.009482
2021-12-11 21:09:09,177 iteration 3836 : loss : 0.025457, loss_ce: 0.010581
2021-12-11 21:09:10,657 iteration 3837 : loss : 0.021008, loss_ce: 0.008060
2021-12-11 21:09:12,164 iteration 3838 : loss : 0.021332, loss_ce: 0.006651
2021-12-11 21:09:13,673 iteration 3839 : loss : 0.021367, loss_ce: 0.007725
2021-12-11 21:09:15,117 iteration 3840 : loss : 0.022036, loss_ce: 0.006116
2021-12-11 21:09:16,632 iteration 3841 : loss : 0.023370, loss_ce: 0.008004
2021-12-11 21:09:18,144 iteration 3842 : loss : 0.031913, loss_ce: 0.006919
 56%|███████████████▎           | 226/400 [1:49:02<1:24:33, 29.16s/it]2021-12-11 21:09:19,793 iteration 3843 : loss : 0.017780, loss_ce: 0.007250
2021-12-11 21:09:21,359 iteration 3844 : loss : 0.026981, loss_ce: 0.010983
2021-12-11 21:09:22,876 iteration 3845 : loss : 0.028635, loss_ce: 0.010213
2021-12-11 21:09:24,410 iteration 3846 : loss : 0.017331, loss_ce: 0.004918
2021-12-11 21:09:26,015 iteration 3847 : loss : 0.021171, loss_ce: 0.006648
2021-12-11 21:09:27,548 iteration 3848 : loss : 0.018438, loss_ce: 0.006868
2021-12-11 21:09:29,021 iteration 3849 : loss : 0.017842, loss_ce: 0.006441
2021-12-11 21:09:30,606 iteration 3850 : loss : 0.040001, loss_ce: 0.010142
2021-12-11 21:09:32,216 iteration 3851 : loss : 0.029604, loss_ce: 0.016057
2021-12-11 21:09:33,740 iteration 3852 : loss : 0.032802, loss_ce: 0.014156
2021-12-11 21:09:35,249 iteration 3853 : loss : 0.020971, loss_ce: 0.011307
2021-12-11 21:09:36,853 iteration 3854 : loss : 0.029502, loss_ce: 0.011200
2021-12-11 21:09:38,415 iteration 3855 : loss : 0.024255, loss_ce: 0.010172
2021-12-11 21:09:39,994 iteration 3856 : loss : 0.026476, loss_ce: 0.008564
2021-12-11 21:09:41,517 iteration 3857 : loss : 0.018793, loss_ce: 0.007210
2021-12-11 21:09:43,106 iteration 3858 : loss : 0.020687, loss_ce: 0.007529
2021-12-11 21:09:44,682 iteration 3859 : loss : 0.025608, loss_ce: 0.006754
 57%|███████████████▎           | 227/400 [1:49:29<1:21:48, 28.37s/it]2021-12-11 21:09:46,311 iteration 3860 : loss : 0.022832, loss_ce: 0.010406
2021-12-11 21:09:47,948 iteration 3861 : loss : 0.034136, loss_ce: 0.013405
2021-12-11 21:09:49,438 iteration 3862 : loss : 0.024079, loss_ce: 0.011230
2021-12-11 21:09:51,036 iteration 3863 : loss : 0.025081, loss_ce: 0.012030
2021-12-11 21:09:52,659 iteration 3864 : loss : 0.020629, loss_ce: 0.007546
2021-12-11 21:09:54,382 iteration 3865 : loss : 0.036359, loss_ce: 0.017232
2021-12-11 21:09:56,091 iteration 3866 : loss : 0.028840, loss_ce: 0.011512
2021-12-11 21:09:57,635 iteration 3867 : loss : 0.017951, loss_ce: 0.006400
2021-12-11 21:09:59,241 iteration 3868 : loss : 0.025358, loss_ce: 0.010247
2021-12-11 21:10:00,838 iteration 3869 : loss : 0.026202, loss_ce: 0.009448
2021-12-11 21:10:02,477 iteration 3870 : loss : 0.037872, loss_ce: 0.014131
2021-12-11 21:10:04,052 iteration 3871 : loss : 0.035419, loss_ce: 0.009382
2021-12-11 21:10:05,592 iteration 3872 : loss : 0.029615, loss_ce: 0.012407
2021-12-11 21:10:07,137 iteration 3873 : loss : 0.027650, loss_ce: 0.009748
2021-12-11 21:10:08,757 iteration 3874 : loss : 0.022060, loss_ce: 0.007978
2021-12-11 21:10:10,369 iteration 3875 : loss : 0.024253, loss_ce: 0.008892
2021-12-11 21:10:11,926 iteration 3876 : loss : 0.026889, loss_ce: 0.005643
 57%|███████████████▍           | 228/400 [1:49:56<1:20:21, 28.03s/it]2021-12-11 21:10:13,507 iteration 3877 : loss : 0.021118, loss_ce: 0.007462
2021-12-11 21:10:15,164 iteration 3878 : loss : 0.023322, loss_ce: 0.010216
2021-12-11 21:10:16,752 iteration 3879 : loss : 0.026300, loss_ce: 0.012815
2021-12-11 21:10:18,308 iteration 3880 : loss : 0.019408, loss_ce: 0.007842
2021-12-11 21:10:19,817 iteration 3881 : loss : 0.024468, loss_ce: 0.012431
2021-12-11 21:10:21,455 iteration 3882 : loss : 0.044220, loss_ce: 0.018408
2021-12-11 21:10:23,064 iteration 3883 : loss : 0.040469, loss_ce: 0.020290
2021-12-11 21:10:24,583 iteration 3884 : loss : 0.028632, loss_ce: 0.005256
2021-12-11 21:10:26,093 iteration 3885 : loss : 0.021172, loss_ce: 0.006908
2021-12-11 21:10:27,604 iteration 3886 : loss : 0.027398, loss_ce: 0.009212
2021-12-11 21:10:29,232 iteration 3887 : loss : 0.031298, loss_ce: 0.012209
2021-12-11 21:10:30,802 iteration 3888 : loss : 0.027890, loss_ce: 0.012662
2021-12-11 21:10:32,373 iteration 3889 : loss : 0.027253, loss_ce: 0.012313
2021-12-11 21:10:33,837 iteration 3890 : loss : 0.022749, loss_ce: 0.008327
2021-12-11 21:10:35,414 iteration 3891 : loss : 0.015220, loss_ce: 0.005742
2021-12-11 21:10:36,993 iteration 3892 : loss : 0.031616, loss_ce: 0.008130
2021-12-11 21:10:38,671 iteration 3893 : loss : 0.028488, loss_ce: 0.014503
 57%|███████████████▍           | 229/400 [1:50:23<1:18:47, 27.65s/it]2021-12-11 21:10:40,223 iteration 3894 : loss : 0.023622, loss_ce: 0.010370
2021-12-11 21:10:41,839 iteration 3895 : loss : 0.030620, loss_ce: 0.011519
2021-12-11 21:10:43,383 iteration 3896 : loss : 0.032901, loss_ce: 0.007736
2021-12-11 21:10:44,974 iteration 3897 : loss : 0.034529, loss_ce: 0.016329
2021-12-11 21:10:46,510 iteration 3898 : loss : 0.023002, loss_ce: 0.008793
2021-12-11 21:10:48,113 iteration 3899 : loss : 0.027907, loss_ce: 0.011999
2021-12-11 21:10:49,766 iteration 3900 : loss : 0.025740, loss_ce: 0.007881
2021-12-11 21:10:51,275 iteration 3901 : loss : 0.021200, loss_ce: 0.006478
2021-12-11 21:10:52,800 iteration 3902 : loss : 0.017058, loss_ce: 0.006242
2021-12-11 21:10:54,357 iteration 3903 : loss : 0.017461, loss_ce: 0.006388
2021-12-11 21:10:56,000 iteration 3904 : loss : 0.026758, loss_ce: 0.008787
2021-12-11 21:10:57,566 iteration 3905 : loss : 0.023018, loss_ce: 0.010414
2021-12-11 21:10:59,083 iteration 3906 : loss : 0.023057, loss_ce: 0.010128
2021-12-11 21:11:00,670 iteration 3907 : loss : 0.022388, loss_ce: 0.006528
2021-12-11 21:11:02,319 iteration 3908 : loss : 0.029326, loss_ce: 0.009948
2021-12-11 21:11:03,931 iteration 3909 : loss : 0.017942, loss_ce: 0.006749
2021-12-11 21:11:03,931 Training Data Eval:
2021-12-11 21:11:11,695   Average segmentation loss on training set: 0.0157
2021-12-11 21:11:11,695 Validation Data Eval:
2021-12-11 21:11:14,356   Average segmentation loss on validation set: 0.0804
2021-12-11 21:11:15,825 iteration 3910 : loss : 0.017005, loss_ce: 0.005780
 57%|███████████████▌           | 230/400 [1:51:00<1:26:24, 30.50s/it]2021-12-11 21:11:17,382 iteration 3911 : loss : 0.020215, loss_ce: 0.006216
2021-12-11 21:11:19,012 iteration 3912 : loss : 0.027814, loss_ce: 0.010959
2021-12-11 21:11:20,493 iteration 3913 : loss : 0.022174, loss_ce: 0.006665
2021-12-11 21:11:21,956 iteration 3914 : loss : 0.017176, loss_ce: 0.006295
2021-12-11 21:11:23,414 iteration 3915 : loss : 0.018638, loss_ce: 0.006156
2021-12-11 21:11:25,040 iteration 3916 : loss : 0.025168, loss_ce: 0.008260
2021-12-11 21:11:26,673 iteration 3917 : loss : 0.033830, loss_ce: 0.008021
2021-12-11 21:11:28,311 iteration 3918 : loss : 0.035820, loss_ce: 0.016088
2021-12-11 21:11:29,886 iteration 3919 : loss : 0.025965, loss_ce: 0.010022
2021-12-11 21:11:31,480 iteration 3920 : loss : 0.027670, loss_ce: 0.013773
2021-12-11 21:11:33,053 iteration 3921 : loss : 0.045019, loss_ce: 0.014153
2021-12-11 21:11:34,579 iteration 3922 : loss : 0.019733, loss_ce: 0.007222
2021-12-11 21:11:36,139 iteration 3923 : loss : 0.021110, loss_ce: 0.008638
2021-12-11 21:11:37,698 iteration 3924 : loss : 0.034362, loss_ce: 0.013295
2021-12-11 21:11:39,428 iteration 3925 : loss : 0.026268, loss_ce: 0.010770
2021-12-11 21:11:41,001 iteration 3926 : loss : 0.024670, loss_ce: 0.009101
2021-12-11 21:11:42,595 iteration 3927 : loss : 0.026438, loss_ce: 0.011787
 58%|███████████████▌           | 231/400 [1:51:27<1:22:45, 29.38s/it]2021-12-11 21:11:44,238 iteration 3928 : loss : 0.028305, loss_ce: 0.011679
2021-12-11 21:11:45,908 iteration 3929 : loss : 0.026079, loss_ce: 0.010454
2021-12-11 21:11:47,656 iteration 3930 : loss : 0.039285, loss_ce: 0.013169
2021-12-11 21:11:49,250 iteration 3931 : loss : 0.030374, loss_ce: 0.012746
2021-12-11 21:11:50,889 iteration 3932 : loss : 0.039800, loss_ce: 0.010308
2021-12-11 21:11:52,427 iteration 3933 : loss : 0.031441, loss_ce: 0.007716
2021-12-11 21:11:54,000 iteration 3934 : loss : 0.023425, loss_ce: 0.008544
2021-12-11 21:11:55,638 iteration 3935 : loss : 0.040359, loss_ce: 0.015826
2021-12-11 21:11:57,191 iteration 3936 : loss : 0.026240, loss_ce: 0.010575
2021-12-11 21:11:58,764 iteration 3937 : loss : 0.020359, loss_ce: 0.005884
2021-12-11 21:12:00,299 iteration 3938 : loss : 0.025291, loss_ce: 0.011753
2021-12-11 21:12:01,973 iteration 3939 : loss : 0.034154, loss_ce: 0.011199
2021-12-11 21:12:03,518 iteration 3940 : loss : 0.025561, loss_ce: 0.006705
2021-12-11 21:12:05,087 iteration 3941 : loss : 0.022488, loss_ce: 0.010288
2021-12-11 21:12:06,640 iteration 3942 : loss : 0.035511, loss_ce: 0.015854
2021-12-11 21:12:08,264 iteration 3943 : loss : 0.025534, loss_ce: 0.011614
2021-12-11 21:12:09,835 iteration 3944 : loss : 0.026050, loss_ce: 0.008278
 58%|███████████████▋           | 232/400 [1:51:54<1:20:27, 28.74s/it]2021-12-11 21:12:11,440 iteration 3945 : loss : 0.017986, loss_ce: 0.007887
2021-12-11 21:12:12,905 iteration 3946 : loss : 0.016691, loss_ce: 0.006088
2021-12-11 21:12:14,463 iteration 3947 : loss : 0.019920, loss_ce: 0.006974
2021-12-11 21:12:15,998 iteration 3948 : loss : 0.022125, loss_ce: 0.009279
2021-12-11 21:12:17,574 iteration 3949 : loss : 0.026471, loss_ce: 0.012758
2021-12-11 21:12:19,135 iteration 3950 : loss : 0.021724, loss_ce: 0.008076
2021-12-11 21:12:20,737 iteration 3951 : loss : 0.022018, loss_ce: 0.008380
2021-12-11 21:12:22,295 iteration 3952 : loss : 0.018528, loss_ce: 0.008761
2021-12-11 21:12:23,846 iteration 3953 : loss : 0.025071, loss_ce: 0.009094
2021-12-11 21:12:25,453 iteration 3954 : loss : 0.025158, loss_ce: 0.009118
2021-12-11 21:12:27,035 iteration 3955 : loss : 0.025912, loss_ce: 0.009080
2021-12-11 21:12:28,572 iteration 3956 : loss : 0.021815, loss_ce: 0.008889
2021-12-11 21:12:30,111 iteration 3957 : loss : 0.024850, loss_ce: 0.011307
2021-12-11 21:12:31,770 iteration 3958 : loss : 0.023520, loss_ce: 0.008412
2021-12-11 21:12:33,298 iteration 3959 : loss : 0.018519, loss_ce: 0.005356
2021-12-11 21:12:34,861 iteration 3960 : loss : 0.030765, loss_ce: 0.007391
2021-12-11 21:12:36,465 iteration 3961 : loss : 0.020923, loss_ce: 0.007037
 58%|███████████████▋           | 233/400 [1:52:21<1:18:13, 28.11s/it]2021-12-11 21:12:38,245 iteration 3962 : loss : 0.028682, loss_ce: 0.010685
2021-12-11 21:12:39,747 iteration 3963 : loss : 0.019390, loss_ce: 0.007523
2021-12-11 21:12:41,359 iteration 3964 : loss : 0.025208, loss_ce: 0.011299
2021-12-11 21:12:43,027 iteration 3965 : loss : 0.032426, loss_ce: 0.008587
2021-12-11 21:12:44,566 iteration 3966 : loss : 0.027544, loss_ce: 0.010051
2021-12-11 21:12:46,106 iteration 3967 : loss : 0.030370, loss_ce: 0.008399
2021-12-11 21:12:47,763 iteration 3968 : loss : 0.023474, loss_ce: 0.008911
2021-12-11 21:12:49,394 iteration 3969 : loss : 0.028022, loss_ce: 0.012746
2021-12-11 21:12:51,067 iteration 3970 : loss : 0.026637, loss_ce: 0.013424
2021-12-11 21:12:52,594 iteration 3971 : loss : 0.023948, loss_ce: 0.006839
2021-12-11 21:12:54,128 iteration 3972 : loss : 0.026133, loss_ce: 0.010346
2021-12-11 21:12:55,716 iteration 3973 : loss : 0.031528, loss_ce: 0.013003
2021-12-11 21:12:57,381 iteration 3974 : loss : 0.025220, loss_ce: 0.009817
2021-12-11 21:12:59,029 iteration 3975 : loss : 0.027973, loss_ce: 0.011143
2021-12-11 21:13:00,707 iteration 3976 : loss : 0.024054, loss_ce: 0.010323
2021-12-11 21:13:02,274 iteration 3977 : loss : 0.024393, loss_ce: 0.008989
2021-12-11 21:13:03,834 iteration 3978 : loss : 0.024994, loss_ce: 0.011028
 58%|███████████████▊           | 234/400 [1:52:48<1:17:09, 27.89s/it]2021-12-11 21:13:05,484 iteration 3979 : loss : 0.027091, loss_ce: 0.008482
2021-12-11 21:13:07,089 iteration 3980 : loss : 0.019365, loss_ce: 0.008744
2021-12-11 21:13:08,621 iteration 3981 : loss : 0.020406, loss_ce: 0.006981
2021-12-11 21:13:10,344 iteration 3982 : loss : 0.024420, loss_ce: 0.007792
2021-12-11 21:13:11,913 iteration 3983 : loss : 0.019581, loss_ce: 0.005409
2021-12-11 21:13:13,538 iteration 3984 : loss : 0.026277, loss_ce: 0.009950
2021-12-11 21:13:15,114 iteration 3985 : loss : 0.022263, loss_ce: 0.006561
2021-12-11 21:13:16,643 iteration 3986 : loss : 0.022413, loss_ce: 0.008888
2021-12-11 21:13:18,177 iteration 3987 : loss : 0.021720, loss_ce: 0.009972
2021-12-11 21:13:19,813 iteration 3988 : loss : 0.030686, loss_ce: 0.015673
2021-12-11 21:13:21,395 iteration 3989 : loss : 0.032519, loss_ce: 0.013174
2021-12-11 21:13:22,955 iteration 3990 : loss : 0.021378, loss_ce: 0.006903
2021-12-11 21:13:24,520 iteration 3991 : loss : 0.025488, loss_ce: 0.009280
2021-12-11 21:13:26,229 iteration 3992 : loss : 0.046847, loss_ce: 0.012688
2021-12-11 21:13:27,795 iteration 3993 : loss : 0.025569, loss_ce: 0.013643
2021-12-11 21:13:29,356 iteration 3994 : loss : 0.029125, loss_ce: 0.011094
2021-12-11 21:13:29,356 Training Data Eval:
2021-12-11 21:13:37,107   Average segmentation loss on training set: 0.0151
2021-12-11 21:13:37,107 Validation Data Eval:
2021-12-11 21:13:39,759   Average segmentation loss on validation set: 0.0873
2021-12-11 21:13:41,296 iteration 3995 : loss : 0.021978, loss_ce: 0.005873
 59%|███████████████▊           | 235/400 [1:53:26<1:24:34, 30.76s/it]2021-12-11 21:13:43,006 iteration 3996 : loss : 0.024426, loss_ce: 0.012515
2021-12-11 21:13:44,613 iteration 3997 : loss : 0.022991, loss_ce: 0.007694
2021-12-11 21:13:46,170 iteration 3998 : loss : 0.022875, loss_ce: 0.007858
2021-12-11 21:13:47,793 iteration 3999 : loss : 0.021204, loss_ce: 0.007135
2021-12-11 21:13:49,375 iteration 4000 : loss : 0.020385, loss_ce: 0.007700
2021-12-11 21:13:51,072 iteration 4001 : loss : 0.025667, loss_ce: 0.007213
2021-12-11 21:13:52,635 iteration 4002 : loss : 0.020676, loss_ce: 0.009149
2021-12-11 21:13:54,203 iteration 4003 : loss : 0.021365, loss_ce: 0.006525
2021-12-11 21:13:55,764 iteration 4004 : loss : 0.023479, loss_ce: 0.007730
2021-12-11 21:13:57,357 iteration 4005 : loss : 0.027708, loss_ce: 0.011235
2021-12-11 21:13:59,046 iteration 4006 : loss : 0.038723, loss_ce: 0.011585
2021-12-11 21:14:00,594 iteration 4007 : loss : 0.021143, loss_ce: 0.007717
2021-12-11 21:14:02,172 iteration 4008 : loss : 0.021496, loss_ce: 0.005594
2021-12-11 21:14:03,731 iteration 4009 : loss : 0.019610, loss_ce: 0.007322
2021-12-11 21:14:05,227 iteration 4010 : loss : 0.016328, loss_ce: 0.005786
2021-12-11 21:14:06,842 iteration 4011 : loss : 0.030943, loss_ce: 0.008924
2021-12-11 21:14:08,459 iteration 4012 : loss : 0.022227, loss_ce: 0.009512
 59%|███████████████▉           | 236/400 [1:53:53<1:21:07, 29.68s/it]2021-12-11 21:14:10,075 iteration 4013 : loss : 0.022734, loss_ce: 0.005646
2021-12-11 21:14:11,705 iteration 4014 : loss : 0.040781, loss_ce: 0.014086
2021-12-11 21:14:13,240 iteration 4015 : loss : 0.020358, loss_ce: 0.009891
2021-12-11 21:14:14,843 iteration 4016 : loss : 0.020928, loss_ce: 0.007186
2021-12-11 21:14:16,368 iteration 4017 : loss : 0.026360, loss_ce: 0.009072
2021-12-11 21:14:18,032 iteration 4018 : loss : 0.029363, loss_ce: 0.011218
2021-12-11 21:14:19,687 iteration 4019 : loss : 0.025617, loss_ce: 0.011947
2021-12-11 21:14:21,244 iteration 4020 : loss : 0.019883, loss_ce: 0.006452
2021-12-11 21:14:22,823 iteration 4021 : loss : 0.026192, loss_ce: 0.009495
2021-12-11 21:14:24,387 iteration 4022 : loss : 0.024670, loss_ce: 0.007595
2021-12-11 21:14:25,975 iteration 4023 : loss : 0.027981, loss_ce: 0.011778
2021-12-11 21:14:27,568 iteration 4024 : loss : 0.040169, loss_ce: 0.013163
2021-12-11 21:14:29,119 iteration 4025 : loss : 0.028068, loss_ce: 0.009345
2021-12-11 21:14:30,661 iteration 4026 : loss : 0.017950, loss_ce: 0.007499
2021-12-11 21:14:32,207 iteration 4027 : loss : 0.019576, loss_ce: 0.007233
2021-12-11 21:14:33,773 iteration 4028 : loss : 0.017689, loss_ce: 0.004313
2021-12-11 21:14:35,355 iteration 4029 : loss : 0.020442, loss_ce: 0.007807
 59%|███████████████▉           | 237/400 [1:54:20<1:18:21, 28.84s/it]2021-12-11 21:14:37,006 iteration 4030 : loss : 0.029705, loss_ce: 0.011412
2021-12-11 21:14:38,562 iteration 4031 : loss : 0.022447, loss_ce: 0.008545
2021-12-11 21:14:40,185 iteration 4032 : loss : 0.025782, loss_ce: 0.010468
2021-12-11 21:14:41,852 iteration 4033 : loss : 0.027903, loss_ce: 0.008729
2021-12-11 21:14:43,391 iteration 4034 : loss : 0.024926, loss_ce: 0.007649
2021-12-11 21:14:44,970 iteration 4035 : loss : 0.025560, loss_ce: 0.008582
2021-12-11 21:14:46,529 iteration 4036 : loss : 0.015770, loss_ce: 0.005616
2021-12-11 21:14:48,147 iteration 4037 : loss : 0.022881, loss_ce: 0.006840
2021-12-11 21:14:49,719 iteration 4038 : loss : 0.022595, loss_ce: 0.013507
2021-12-11 21:14:51,170 iteration 4039 : loss : 0.020313, loss_ce: 0.009482
2021-12-11 21:14:52,728 iteration 4040 : loss : 0.044511, loss_ce: 0.008536
2021-12-11 21:14:54,430 iteration 4041 : loss : 0.031711, loss_ce: 0.015070
2021-12-11 21:14:55,926 iteration 4042 : loss : 0.022312, loss_ce: 0.009405
2021-12-11 21:14:57,544 iteration 4043 : loss : 0.023980, loss_ce: 0.008179
2021-12-11 21:14:59,119 iteration 4044 : loss : 0.035181, loss_ce: 0.014595
2021-12-11 21:15:00,653 iteration 4045 : loss : 0.024369, loss_ce: 0.008919
2021-12-11 21:15:02,262 iteration 4046 : loss : 0.022145, loss_ce: 0.007718
 60%|████████████████           | 238/400 [1:54:47<1:16:18, 28.26s/it]2021-12-11 21:15:03,844 iteration 4047 : loss : 0.020356, loss_ce: 0.008454
2021-12-11 21:15:05,395 iteration 4048 : loss : 0.018469, loss_ce: 0.005273
2021-12-11 21:15:07,053 iteration 4049 : loss : 0.032728, loss_ce: 0.010735
2021-12-11 21:15:08,632 iteration 4050 : loss : 0.025848, loss_ce: 0.006822
2021-12-11 21:15:10,212 iteration 4051 : loss : 0.017541, loss_ce: 0.005940
2021-12-11 21:15:11,769 iteration 4052 : loss : 0.025330, loss_ce: 0.007994
2021-12-11 21:15:13,316 iteration 4053 : loss : 0.027085, loss_ce: 0.012846
2021-12-11 21:15:14,835 iteration 4054 : loss : 0.022911, loss_ce: 0.010074
2021-12-11 21:15:16,513 iteration 4055 : loss : 0.024075, loss_ce: 0.007193
2021-12-11 21:15:18,130 iteration 4056 : loss : 0.039264, loss_ce: 0.011711
2021-12-11 21:15:19,770 iteration 4057 : loss : 0.038658, loss_ce: 0.015750
2021-12-11 21:15:21,251 iteration 4058 : loss : 0.022344, loss_ce: 0.009645
2021-12-11 21:15:22,887 iteration 4059 : loss : 0.025708, loss_ce: 0.010972
2021-12-11 21:15:24,498 iteration 4060 : loss : 0.022573, loss_ce: 0.009075
2021-12-11 21:15:26,056 iteration 4061 : loss : 0.039549, loss_ce: 0.008065
2021-12-11 21:15:27,598 iteration 4062 : loss : 0.026557, loss_ce: 0.011489
2021-12-11 21:15:29,292 iteration 4063 : loss : 0.037102, loss_ce: 0.011458
 60%|████████████████▏          | 239/400 [1:55:14<1:14:51, 27.90s/it]2021-12-11 21:15:30,926 iteration 4064 : loss : 0.031862, loss_ce: 0.010166
2021-12-11 21:15:32,498 iteration 4065 : loss : 0.026577, loss_ce: 0.009330
2021-12-11 21:15:33,974 iteration 4066 : loss : 0.026266, loss_ce: 0.009205
2021-12-11 21:15:35,491 iteration 4067 : loss : 0.031839, loss_ce: 0.007769
2021-12-11 21:15:37,080 iteration 4068 : loss : 0.030163, loss_ce: 0.012417
2021-12-11 21:15:38,700 iteration 4069 : loss : 0.028982, loss_ce: 0.009661
2021-12-11 21:15:40,289 iteration 4070 : loss : 0.026534, loss_ce: 0.013752
2021-12-11 21:15:41,789 iteration 4071 : loss : 0.023232, loss_ce: 0.008816
2021-12-11 21:15:43,353 iteration 4072 : loss : 0.026186, loss_ce: 0.010125
2021-12-11 21:15:44,939 iteration 4073 : loss : 0.033664, loss_ce: 0.013993
2021-12-11 21:15:46,455 iteration 4074 : loss : 0.028118, loss_ce: 0.009856
2021-12-11 21:15:48,076 iteration 4075 : loss : 0.038370, loss_ce: 0.015545
2021-12-11 21:15:49,678 iteration 4076 : loss : 0.024707, loss_ce: 0.008375
2021-12-11 21:15:51,286 iteration 4077 : loss : 0.020966, loss_ce: 0.008812
2021-12-11 21:15:52,947 iteration 4078 : loss : 0.038767, loss_ce: 0.011035
2021-12-11 21:15:54,533 iteration 4079 : loss : 0.022151, loss_ce: 0.007802
2021-12-11 21:15:54,534 Training Data Eval:
2021-12-11 21:16:02,286   Average segmentation loss on training set: 0.0307
2021-12-11 21:16:02,286 Validation Data Eval:
2021-12-11 21:16:04,955   Average segmentation loss on validation set: 0.1079
2021-12-11 21:16:06,529 iteration 4080 : loss : 0.024990, loss_ce: 0.007698
 60%|████████████████▏          | 240/400 [1:55:51<1:21:51, 30.70s/it]2021-12-11 21:16:08,151 iteration 4081 : loss : 0.031335, loss_ce: 0.014561
2021-12-11 21:16:09,802 iteration 4082 : loss : 0.031966, loss_ce: 0.011083
2021-12-11 21:16:11,291 iteration 4083 : loss : 0.030425, loss_ce: 0.014669
2021-12-11 21:16:12,808 iteration 4084 : loss : 0.022971, loss_ce: 0.007580
2021-12-11 21:16:14,381 iteration 4085 : loss : 0.029213, loss_ce: 0.006473
2021-12-11 21:16:15,914 iteration 4086 : loss : 0.031501, loss_ce: 0.010836
2021-12-11 21:16:17,478 iteration 4087 : loss : 0.035182, loss_ce: 0.010454
2021-12-11 21:16:19,058 iteration 4088 : loss : 0.022948, loss_ce: 0.011085
2021-12-11 21:16:20,655 iteration 4089 : loss : 0.027411, loss_ce: 0.010069
2021-12-11 21:16:22,221 iteration 4090 : loss : 0.025441, loss_ce: 0.011144
2021-12-11 21:16:23,843 iteration 4091 : loss : 0.038387, loss_ce: 0.014417
2021-12-11 21:16:25,353 iteration 4092 : loss : 0.027353, loss_ce: 0.007661
2021-12-11 21:16:26,887 iteration 4093 : loss : 0.018484, loss_ce: 0.008207
2021-12-11 21:16:28,532 iteration 4094 : loss : 0.028149, loss_ce: 0.008497
2021-12-11 21:16:30,114 iteration 4095 : loss : 0.026161, loss_ce: 0.008353
2021-12-11 21:16:31,727 iteration 4096 : loss : 0.022340, loss_ce: 0.009377
2021-12-11 21:16:33,351 iteration 4097 : loss : 0.025253, loss_ce: 0.010047
 60%|████████████████▎          | 241/400 [1:56:18<1:18:15, 29.53s/it]2021-12-11 21:16:34,998 iteration 4098 : loss : 0.019619, loss_ce: 0.007191
2021-12-11 21:16:36,574 iteration 4099 : loss : 0.019888, loss_ce: 0.007026
2021-12-11 21:16:38,104 iteration 4100 : loss : 0.025742, loss_ce: 0.009480
2021-12-11 21:16:39,701 iteration 4101 : loss : 0.020102, loss_ce: 0.008734
2021-12-11 21:16:41,370 iteration 4102 : loss : 0.036267, loss_ce: 0.012833
2021-12-11 21:16:42,862 iteration 4103 : loss : 0.019978, loss_ce: 0.007821
2021-12-11 21:16:44,454 iteration 4104 : loss : 0.024249, loss_ce: 0.008580
2021-12-11 21:16:46,086 iteration 4105 : loss : 0.026162, loss_ce: 0.009206
2021-12-11 21:16:47,768 iteration 4106 : loss : 0.043605, loss_ce: 0.015846
2021-12-11 21:16:49,375 iteration 4107 : loss : 0.029260, loss_ce: 0.012695
2021-12-11 21:16:51,002 iteration 4108 : loss : 0.021877, loss_ce: 0.009590
2021-12-11 21:16:52,609 iteration 4109 : loss : 0.023644, loss_ce: 0.006419
2021-12-11 21:16:54,246 iteration 4110 : loss : 0.021090, loss_ce: 0.006649
2021-12-11 21:16:55,856 iteration 4111 : loss : 0.022822, loss_ce: 0.006064
2021-12-11 21:16:57,319 iteration 4112 : loss : 0.017503, loss_ce: 0.006503
2021-12-11 21:16:58,963 iteration 4113 : loss : 0.035064, loss_ce: 0.012285
2021-12-11 21:17:00,544 iteration 4114 : loss : 0.032321, loss_ce: 0.014257
 60%|████████████████▎          | 242/400 [1:56:45<1:15:55, 28.83s/it]2021-12-11 21:17:02,167 iteration 4115 : loss : 0.027290, loss_ce: 0.008059
2021-12-11 21:17:03,698 iteration 4116 : loss : 0.019201, loss_ce: 0.008097
2021-12-11 21:17:05,202 iteration 4117 : loss : 0.020832, loss_ce: 0.010599
2021-12-11 21:17:06,758 iteration 4118 : loss : 0.026061, loss_ce: 0.006790
2021-12-11 21:17:08,213 iteration 4119 : loss : 0.018467, loss_ce: 0.006828
2021-12-11 21:17:09,907 iteration 4120 : loss : 0.025126, loss_ce: 0.007592
2021-12-11 21:17:11,474 iteration 4121 : loss : 0.023970, loss_ce: 0.009425
2021-12-11 21:17:13,078 iteration 4122 : loss : 0.021735, loss_ce: 0.008148
2021-12-11 21:17:14,682 iteration 4123 : loss : 0.029652, loss_ce: 0.010995
2021-12-11 21:17:16,174 iteration 4124 : loss : 0.018045, loss_ce: 0.007202
2021-12-11 21:17:17,778 iteration 4125 : loss : 0.026304, loss_ce: 0.008769
2021-12-11 21:17:19,497 iteration 4126 : loss : 0.024687, loss_ce: 0.010235
2021-12-11 21:17:21,155 iteration 4127 : loss : 0.027883, loss_ce: 0.014008
2021-12-11 21:17:22,703 iteration 4128 : loss : 0.020849, loss_ce: 0.008837
2021-12-11 21:17:24,419 iteration 4129 : loss : 0.034513, loss_ce: 0.008345
2021-12-11 21:17:26,059 iteration 4130 : loss : 0.021724, loss_ce: 0.007214
2021-12-11 21:17:27,643 iteration 4131 : loss : 0.020171, loss_ce: 0.007689
 61%|████████████████▍          | 243/400 [1:57:12<1:14:04, 28.31s/it]2021-12-11 21:17:29,339 iteration 4132 : loss : 0.035007, loss_ce: 0.014160
2021-12-11 21:17:30,850 iteration 4133 : loss : 0.022157, loss_ce: 0.009824
2021-12-11 21:17:32,494 iteration 4134 : loss : 0.016835, loss_ce: 0.007004
2021-12-11 21:17:34,087 iteration 4135 : loss : 0.030986, loss_ce: 0.010166
2021-12-11 21:17:35,654 iteration 4136 : loss : 0.018577, loss_ce: 0.005744
2021-12-11 21:17:37,255 iteration 4137 : loss : 0.022880, loss_ce: 0.010768
2021-12-11 21:17:38,868 iteration 4138 : loss : 0.021647, loss_ce: 0.011188
2021-12-11 21:17:40,484 iteration 4139 : loss : 0.067571, loss_ce: 0.026393
2021-12-11 21:17:42,114 iteration 4140 : loss : 0.028962, loss_ce: 0.009413
2021-12-11 21:17:43,691 iteration 4141 : loss : 0.023967, loss_ce: 0.006480
2021-12-11 21:17:45,240 iteration 4142 : loss : 0.019169, loss_ce: 0.007563
2021-12-11 21:17:46,778 iteration 4143 : loss : 0.025279, loss_ce: 0.009245
2021-12-11 21:17:48,378 iteration 4144 : loss : 0.020728, loss_ce: 0.007718
2021-12-11 21:17:49,934 iteration 4145 : loss : 0.026496, loss_ce: 0.009978
2021-12-11 21:17:51,391 iteration 4146 : loss : 0.034988, loss_ce: 0.010284
2021-12-11 21:17:52,936 iteration 4147 : loss : 0.024698, loss_ce: 0.008762
2021-12-11 21:17:54,510 iteration 4148 : loss : 0.029520, loss_ce: 0.012273
 61%|████████████████▍          | 244/400 [1:57:39<1:12:29, 27.88s/it]2021-12-11 21:17:56,154 iteration 4149 : loss : 0.033883, loss_ce: 0.013678
2021-12-11 21:17:57,702 iteration 4150 : loss : 0.017785, loss_ce: 0.006165
2021-12-11 21:17:59,262 iteration 4151 : loss : 0.026818, loss_ce: 0.011347
2021-12-11 21:18:00,925 iteration 4152 : loss : 0.030729, loss_ce: 0.011785
2021-12-11 21:18:02,554 iteration 4153 : loss : 0.029429, loss_ce: 0.012300
2021-12-11 21:18:04,057 iteration 4154 : loss : 0.020555, loss_ce: 0.008008
2021-12-11 21:18:05,589 iteration 4155 : loss : 0.021335, loss_ce: 0.009413
2021-12-11 21:18:07,134 iteration 4156 : loss : 0.031363, loss_ce: 0.010535
2021-12-11 21:18:08,721 iteration 4157 : loss : 0.025307, loss_ce: 0.009139
2021-12-11 21:18:10,265 iteration 4158 : loss : 0.018482, loss_ce: 0.007303
2021-12-11 21:18:11,889 iteration 4159 : loss : 0.018769, loss_ce: 0.008059
2021-12-11 21:18:13,474 iteration 4160 : loss : 0.028007, loss_ce: 0.009932
2021-12-11 21:18:15,019 iteration 4161 : loss : 0.026018, loss_ce: 0.009519
2021-12-11 21:18:16,621 iteration 4162 : loss : 0.025856, loss_ce: 0.008527
2021-12-11 21:18:18,211 iteration 4163 : loss : 0.027910, loss_ce: 0.010084
2021-12-11 21:18:19,751 iteration 4164 : loss : 0.021011, loss_ce: 0.006358
2021-12-11 21:18:19,752 Training Data Eval:
2021-12-11 21:18:27,502   Average segmentation loss on training set: 0.0152
2021-12-11 21:18:27,503 Validation Data Eval:
2021-12-11 21:18:30,161   Average segmentation loss on validation set: 0.0852
2021-12-11 21:18:31,754 iteration 4165 : loss : 0.028809, loss_ce: 0.009001
 61%|████████████████▌          | 245/400 [1:58:16<1:19:17, 30.69s/it]2021-12-11 21:18:33,359 iteration 4166 : loss : 0.040208, loss_ce: 0.008935
2021-12-11 21:18:34,886 iteration 4167 : loss : 0.017627, loss_ce: 0.007285
2021-12-11 21:18:36,356 iteration 4168 : loss : 0.020444, loss_ce: 0.006020
2021-12-11 21:18:37,862 iteration 4169 : loss : 0.022598, loss_ce: 0.009368
2021-12-11 21:18:39,510 iteration 4170 : loss : 0.043486, loss_ce: 0.015998
2021-12-11 21:18:41,188 iteration 4171 : loss : 0.023239, loss_ce: 0.008404
2021-12-11 21:18:42,692 iteration 4172 : loss : 0.020075, loss_ce: 0.004389
2021-12-11 21:18:44,256 iteration 4173 : loss : 0.027366, loss_ce: 0.009427
2021-12-11 21:18:45,832 iteration 4174 : loss : 0.035798, loss_ce: 0.016674
2021-12-11 21:18:47,444 iteration 4175 : loss : 0.022654, loss_ce: 0.007593
2021-12-11 21:18:49,025 iteration 4176 : loss : 0.023851, loss_ce: 0.010237
2021-12-11 21:18:50,618 iteration 4177 : loss : 0.028670, loss_ce: 0.009365
2021-12-11 21:18:52,179 iteration 4178 : loss : 0.021533, loss_ce: 0.008818
2021-12-11 21:18:53,832 iteration 4179 : loss : 0.031544, loss_ce: 0.011869
2021-12-11 21:18:55,400 iteration 4180 : loss : 0.026918, loss_ce: 0.009202
2021-12-11 21:18:56,854 iteration 4181 : loss : 0.030343, loss_ce: 0.008958
2021-12-11 21:18:58,457 iteration 4182 : loss : 0.020255, loss_ce: 0.009166
 62%|████████████████▌          | 246/400 [1:58:43<1:15:41, 29.49s/it]2021-12-11 21:19:00,085 iteration 4183 : loss : 0.024499, loss_ce: 0.008647
2021-12-11 21:19:01,673 iteration 4184 : loss : 0.024209, loss_ce: 0.009680
2021-12-11 21:19:03,242 iteration 4185 : loss : 0.026645, loss_ce: 0.009155
2021-12-11 21:19:04,773 iteration 4186 : loss : 0.021431, loss_ce: 0.008257
2021-12-11 21:19:06,413 iteration 4187 : loss : 0.029369, loss_ce: 0.009633
2021-12-11 21:19:08,037 iteration 4188 : loss : 0.026813, loss_ce: 0.011791
2021-12-11 21:19:09,633 iteration 4189 : loss : 0.019379, loss_ce: 0.005807
2021-12-11 21:19:11,277 iteration 4190 : loss : 0.024014, loss_ce: 0.008171
2021-12-11 21:19:12,818 iteration 4191 : loss : 0.022746, loss_ce: 0.008293
2021-12-11 21:19:14,389 iteration 4192 : loss : 0.018620, loss_ce: 0.005044
2021-12-11 21:19:15,969 iteration 4193 : loss : 0.024938, loss_ce: 0.007698
2021-12-11 21:19:17,569 iteration 4194 : loss : 0.021904, loss_ce: 0.008791
2021-12-11 21:19:19,305 iteration 4195 : loss : 0.040976, loss_ce: 0.011872
2021-12-11 21:19:20,836 iteration 4196 : loss : 0.019170, loss_ce: 0.010048
2021-12-11 21:19:22,479 iteration 4197 : loss : 0.020864, loss_ce: 0.006575
2021-12-11 21:19:24,067 iteration 4198 : loss : 0.030667, loss_ce: 0.012350
2021-12-11 21:19:25,552 iteration 4199 : loss : 0.022572, loss_ce: 0.007480
 62%|████████████████▋          | 247/400 [1:59:10<1:13:22, 28.78s/it]2021-12-11 21:19:27,143 iteration 4200 : loss : 0.021428, loss_ce: 0.006424
2021-12-11 21:19:28,745 iteration 4201 : loss : 0.019783, loss_ce: 0.008465
2021-12-11 21:19:30,225 iteration 4202 : loss : 0.016532, loss_ce: 0.007321
2021-12-11 21:19:31,744 iteration 4203 : loss : 0.018177, loss_ce: 0.007478
2021-12-11 21:19:33,304 iteration 4204 : loss : 0.020531, loss_ce: 0.007413
2021-12-11 21:19:34,832 iteration 4205 : loss : 0.020603, loss_ce: 0.006801
2021-12-11 21:19:36,302 iteration 4206 : loss : 0.022414, loss_ce: 0.007374
2021-12-11 21:19:37,824 iteration 4207 : loss : 0.019921, loss_ce: 0.008609
2021-12-11 21:19:39,408 iteration 4208 : loss : 0.023038, loss_ce: 0.008570
2021-12-11 21:19:41,075 iteration 4209 : loss : 0.030985, loss_ce: 0.008228
2021-12-11 21:19:42,717 iteration 4210 : loss : 0.019732, loss_ce: 0.008255
2021-12-11 21:19:44,132 iteration 4211 : loss : 0.015249, loss_ce: 0.006003
2021-12-11 21:19:45,690 iteration 4212 : loss : 0.021883, loss_ce: 0.009606
2021-12-11 21:19:47,245 iteration 4213 : loss : 0.022569, loss_ce: 0.010640
2021-12-11 21:19:48,874 iteration 4214 : loss : 0.026182, loss_ce: 0.007991
2021-12-11 21:19:50,414 iteration 4215 : loss : 0.019803, loss_ce: 0.006821
2021-12-11 21:19:52,080 iteration 4216 : loss : 0.037884, loss_ce: 0.012064
 62%|████████████████▋          | 248/400 [1:59:36<1:11:11, 28.10s/it]2021-12-11 21:19:53,819 iteration 4217 : loss : 0.021916, loss_ce: 0.009615
2021-12-11 21:19:55,311 iteration 4218 : loss : 0.018147, loss_ce: 0.008901
2021-12-11 21:19:56,818 iteration 4219 : loss : 0.020748, loss_ce: 0.007688
2021-12-11 21:19:58,517 iteration 4220 : loss : 0.028472, loss_ce: 0.010129
2021-12-11 21:20:00,115 iteration 4221 : loss : 0.024079, loss_ce: 0.006564
2021-12-11 21:20:01,726 iteration 4222 : loss : 0.023022, loss_ce: 0.010213
2021-12-11 21:20:03,311 iteration 4223 : loss : 0.020885, loss_ce: 0.007015
2021-12-11 21:20:04,874 iteration 4224 : loss : 0.022488, loss_ce: 0.006485
2021-12-11 21:20:06,409 iteration 4225 : loss : 0.022813, loss_ce: 0.007083
2021-12-11 21:20:07,955 iteration 4226 : loss : 0.023226, loss_ce: 0.005693
2021-12-11 21:20:09,632 iteration 4227 : loss : 0.041852, loss_ce: 0.012525
2021-12-11 21:20:11,184 iteration 4228 : loss : 0.035093, loss_ce: 0.013639
2021-12-11 21:20:12,794 iteration 4229 : loss : 0.025675, loss_ce: 0.009811
2021-12-11 21:20:14,375 iteration 4230 : loss : 0.025030, loss_ce: 0.011589
2021-12-11 21:20:15,914 iteration 4231 : loss : 0.019350, loss_ce: 0.006403
2021-12-11 21:20:17,451 iteration 4232 : loss : 0.023547, loss_ce: 0.009822
2021-12-11 21:20:19,011 iteration 4233 : loss : 0.026914, loss_ce: 0.012167
 62%|████████████████▊          | 249/400 [2:00:03<1:09:49, 27.75s/it]2021-12-11 21:20:20,708 iteration 4234 : loss : 0.026851, loss_ce: 0.012905
2021-12-11 21:20:22,266 iteration 4235 : loss : 0.026390, loss_ce: 0.008420
2021-12-11 21:20:23,766 iteration 4236 : loss : 0.020290, loss_ce: 0.007633
2021-12-11 21:20:25,271 iteration 4237 : loss : 0.027450, loss_ce: 0.011969
2021-12-11 21:20:26,816 iteration 4238 : loss : 0.022641, loss_ce: 0.007049
2021-12-11 21:20:28,431 iteration 4239 : loss : 0.021696, loss_ce: 0.008103
2021-12-11 21:20:30,022 iteration 4240 : loss : 0.028562, loss_ce: 0.009076
2021-12-11 21:20:31,587 iteration 4241 : loss : 0.025330, loss_ce: 0.010745
2021-12-11 21:20:33,022 iteration 4242 : loss : 0.016392, loss_ce: 0.006275
2021-12-11 21:20:34,619 iteration 4243 : loss : 0.032098, loss_ce: 0.011931
2021-12-11 21:20:36,129 iteration 4244 : loss : 0.021669, loss_ce: 0.006541
2021-12-11 21:20:37,674 iteration 4245 : loss : 0.017180, loss_ce: 0.006157
2021-12-11 21:20:39,195 iteration 4246 : loss : 0.017892, loss_ce: 0.006035
2021-12-11 21:20:40,738 iteration 4247 : loss : 0.021369, loss_ce: 0.005917
2021-12-11 21:20:42,204 iteration 4248 : loss : 0.019966, loss_ce: 0.007031
2021-12-11 21:20:43,833 iteration 4249 : loss : 0.018823, loss_ce: 0.006916
2021-12-11 21:20:43,834 Training Data Eval:
2021-12-11 21:20:51,589   Average segmentation loss on training set: 0.0157
2021-12-11 21:20:51,590 Validation Data Eval:
2021-12-11 21:20:54,246   Average segmentation loss on validation set: 0.0761
2021-12-11 21:20:55,818 iteration 4250 : loss : 0.018510, loss_ce: 0.006565
2021-12-11 21:20:57,833 save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/NEW_TU/UNET_ADAM_seed2epoch_249.pth
 62%|████████████████▉          | 250/400 [2:00:42<1:17:37, 31.05s/it]2021-12-11 21:20:59,434 iteration 4251 : loss : 0.023990, loss_ce: 0.007938
2021-12-11 21:21:01,000 iteration 4252 : loss : 0.023364, loss_ce: 0.005829
2021-12-11 21:21:02,593 iteration 4253 : loss : 0.019523, loss_ce: 0.009443
2021-12-11 21:21:04,191 iteration 4254 : loss : 0.018188, loss_ce: 0.006783
2021-12-11 21:21:05,779 iteration 4255 : loss : 0.032228, loss_ce: 0.010597
2021-12-11 21:21:07,314 iteration 4256 : loss : 0.032998, loss_ce: 0.011794
2021-12-11 21:21:08,886 iteration 4257 : loss : 0.022701, loss_ce: 0.009811
2021-12-11 21:21:10,531 iteration 4258 : loss : 0.031418, loss_ce: 0.015950
2021-12-11 21:21:11,984 iteration 4259 : loss : 0.017048, loss_ce: 0.005745
2021-12-11 21:21:13,570 iteration 4260 : loss : 0.019993, loss_ce: 0.006249
2021-12-11 21:21:15,052 iteration 4261 : loss : 0.016214, loss_ce: 0.005241
2021-12-11 21:21:16,588 iteration 4262 : loss : 0.019552, loss_ce: 0.008008
2021-12-11 21:21:18,193 iteration 4263 : loss : 0.026594, loss_ce: 0.011364
2021-12-11 21:21:19,744 iteration 4264 : loss : 0.022255, loss_ce: 0.009458
2021-12-11 21:21:21,169 iteration 4265 : loss : 0.017006, loss_ce: 0.007045
2021-12-11 21:21:22,748 iteration 4266 : loss : 0.023574, loss_ce: 0.007437
2021-12-11 21:21:24,353 iteration 4267 : loss : 0.023449, loss_ce: 0.009679
 63%|████████████████▉          | 251/400 [2:01:09<1:13:46, 29.71s/it]2021-12-11 21:21:25,903 iteration 4268 : loss : 0.019654, loss_ce: 0.007025
2021-12-11 21:21:27,400 iteration 4269 : loss : 0.015809, loss_ce: 0.004238
2021-12-11 21:21:28,932 iteration 4270 : loss : 0.023679, loss_ce: 0.006743
2021-12-11 21:21:30,471 iteration 4271 : loss : 0.025373, loss_ce: 0.009153
2021-12-11 21:21:32,020 iteration 4272 : loss : 0.020344, loss_ce: 0.007920
2021-12-11 21:21:33,548 iteration 4273 : loss : 0.024671, loss_ce: 0.010207
2021-12-11 21:21:35,101 iteration 4274 : loss : 0.031673, loss_ce: 0.016392
2021-12-11 21:21:36,630 iteration 4275 : loss : 0.019944, loss_ce: 0.007578
2021-12-11 21:21:38,151 iteration 4276 : loss : 0.020248, loss_ce: 0.007499
2021-12-11 21:21:39,714 iteration 4277 : loss : 0.022697, loss_ce: 0.009290
2021-12-11 21:21:41,255 iteration 4278 : loss : 0.019513, loss_ce: 0.004835
2021-12-11 21:21:42,757 iteration 4279 : loss : 0.016591, loss_ce: 0.006703
2021-12-11 21:21:44,321 iteration 4280 : loss : 0.033258, loss_ce: 0.011327
2021-12-11 21:21:45,888 iteration 4281 : loss : 0.021781, loss_ce: 0.008088
2021-12-11 21:21:47,484 iteration 4282 : loss : 0.026674, loss_ce: 0.009486
2021-12-11 21:21:49,128 iteration 4283 : loss : 0.019682, loss_ce: 0.008897
2021-12-11 21:21:50,778 iteration 4284 : loss : 0.027307, loss_ce: 0.011236
 63%|█████████████████          | 252/400 [2:01:35<1:10:51, 28.73s/it]2021-12-11 21:21:52,331 iteration 4285 : loss : 0.019114, loss_ce: 0.009758
2021-12-11 21:21:53,838 iteration 4286 : loss : 0.020063, loss_ce: 0.007360
2021-12-11 21:21:55,407 iteration 4287 : loss : 0.035107, loss_ce: 0.014256
2021-12-11 21:21:56,907 iteration 4288 : loss : 0.017499, loss_ce: 0.004688
2021-12-11 21:21:58,409 iteration 4289 : loss : 0.017989, loss_ce: 0.007333
2021-12-11 21:21:59,965 iteration 4290 : loss : 0.020718, loss_ce: 0.007774
2021-12-11 21:22:01,605 iteration 4291 : loss : 0.020983, loss_ce: 0.009473
2021-12-11 21:22:03,206 iteration 4292 : loss : 0.022807, loss_ce: 0.011643
2021-12-11 21:22:04,656 iteration 4293 : loss : 0.020738, loss_ce: 0.007463
2021-12-11 21:22:06,180 iteration 4294 : loss : 0.019386, loss_ce: 0.008964
2021-12-11 21:22:07,888 iteration 4295 : loss : 0.030896, loss_ce: 0.010990
2021-12-11 21:22:09,415 iteration 4296 : loss : 0.021249, loss_ce: 0.007655
2021-12-11 21:22:10,923 iteration 4297 : loss : 0.018834, loss_ce: 0.005864
2021-12-11 21:22:12,553 iteration 4298 : loss : 0.028167, loss_ce: 0.008434
2021-12-11 21:22:14,147 iteration 4299 : loss : 0.023090, loss_ce: 0.007075
2021-12-11 21:22:15,816 iteration 4300 : loss : 0.025871, loss_ce: 0.008784
2021-12-11 21:22:17,387 iteration 4301 : loss : 0.027765, loss_ce: 0.010247
 63%|█████████████████          | 253/400 [2:02:02<1:08:49, 28.09s/it]2021-12-11 21:22:19,075 iteration 4302 : loss : 0.021717, loss_ce: 0.008649
2021-12-11 21:22:20,561 iteration 4303 : loss : 0.019170, loss_ce: 0.010037
2021-12-11 21:22:22,124 iteration 4304 : loss : 0.025181, loss_ce: 0.010799
2021-12-11 21:22:23,698 iteration 4305 : loss : 0.023474, loss_ce: 0.006292
2021-12-11 21:22:25,253 iteration 4306 : loss : 0.023418, loss_ce: 0.007228
2021-12-11 21:22:26,899 iteration 4307 : loss : 0.019593, loss_ce: 0.007101
2021-12-11 21:22:28,453 iteration 4308 : loss : 0.021428, loss_ce: 0.007828
2021-12-11 21:22:30,063 iteration 4309 : loss : 0.028571, loss_ce: 0.009333
2021-12-11 21:22:31,555 iteration 4310 : loss : 0.019587, loss_ce: 0.006629
2021-12-11 21:22:33,220 iteration 4311 : loss : 0.026621, loss_ce: 0.011454
2021-12-11 21:22:34,757 iteration 4312 : loss : 0.021999, loss_ce: 0.010025
2021-12-11 21:22:36,374 iteration 4313 : loss : 0.020245, loss_ce: 0.008515
2021-12-11 21:22:37,958 iteration 4314 : loss : 0.027691, loss_ce: 0.007533
2021-12-11 21:22:39,482 iteration 4315 : loss : 0.018718, loss_ce: 0.007512
2021-12-11 21:22:41,014 iteration 4316 : loss : 0.023180, loss_ce: 0.009600
2021-12-11 21:22:42,588 iteration 4317 : loss : 0.019382, loss_ce: 0.008094
2021-12-11 21:22:44,255 iteration 4318 : loss : 0.017985, loss_ce: 0.006338
 64%|█████████████████▏         | 254/400 [2:02:29<1:07:27, 27.72s/it]2021-12-11 21:22:45,854 iteration 4319 : loss : 0.026108, loss_ce: 0.010883
2021-12-11 21:22:47,311 iteration 4320 : loss : 0.019488, loss_ce: 0.007627
2021-12-11 21:22:49,034 iteration 4321 : loss : 0.032033, loss_ce: 0.014270
2021-12-11 21:22:50,595 iteration 4322 : loss : 0.024835, loss_ce: 0.008571
2021-12-11 21:22:52,165 iteration 4323 : loss : 0.020763, loss_ce: 0.006715
2021-12-11 21:22:53,693 iteration 4324 : loss : 0.015060, loss_ce: 0.006238
2021-12-11 21:22:55,217 iteration 4325 : loss : 0.029458, loss_ce: 0.008253
2021-12-11 21:22:56,832 iteration 4326 : loss : 0.033658, loss_ce: 0.011003
2021-12-11 21:22:58,495 iteration 4327 : loss : 0.017456, loss_ce: 0.007041
2021-12-11 21:23:00,107 iteration 4328 : loss : 0.018969, loss_ce: 0.008843
2021-12-11 21:23:01,650 iteration 4329 : loss : 0.021918, loss_ce: 0.008002
2021-12-11 21:23:03,146 iteration 4330 : loss : 0.019845, loss_ce: 0.008240
2021-12-11 21:23:04,682 iteration 4331 : loss : 0.018489, loss_ce: 0.007931
2021-12-11 21:23:06,174 iteration 4332 : loss : 0.019163, loss_ce: 0.006501
2021-12-11 21:23:07,630 iteration 4333 : loss : 0.015308, loss_ce: 0.005995
2021-12-11 21:23:09,204 iteration 4334 : loss : 0.022645, loss_ce: 0.009405
2021-12-11 21:23:09,204 Training Data Eval:
2021-12-11 21:23:16,958   Average segmentation loss on training set: 0.0139
2021-12-11 21:23:16,958 Validation Data Eval:
2021-12-11 21:23:19,613   Average segmentation loss on validation set: 0.0724
2021-12-11 21:23:21,214 iteration 4335 : loss : 0.035543, loss_ce: 0.009013
 64%|█████████████████▏         | 255/400 [2:03:06<1:13:41, 30.49s/it]2021-12-11 21:23:22,744 iteration 4336 : loss : 0.017521, loss_ce: 0.007118
2021-12-11 21:23:24,342 iteration 4337 : loss : 0.021899, loss_ce: 0.008940
2021-12-11 21:23:25,938 iteration 4338 : loss : 0.025626, loss_ce: 0.009541
2021-12-11 21:23:27,414 iteration 4339 : loss : 0.027224, loss_ce: 0.006785
2021-12-11 21:23:28,993 iteration 4340 : loss : 0.030567, loss_ce: 0.006676
2021-12-11 21:23:30,549 iteration 4341 : loss : 0.019703, loss_ce: 0.008045
2021-12-11 21:23:32,091 iteration 4342 : loss : 0.016011, loss_ce: 0.005434
2021-12-11 21:23:33,734 iteration 4343 : loss : 0.031303, loss_ce: 0.009712
2021-12-11 21:23:35,257 iteration 4344 : loss : 0.022485, loss_ce: 0.008044
2021-12-11 21:23:36,774 iteration 4345 : loss : 0.018539, loss_ce: 0.007465
2021-12-11 21:23:38,213 iteration 4346 : loss : 0.014783, loss_ce: 0.004585
2021-12-11 21:23:39,843 iteration 4347 : loss : 0.025421, loss_ce: 0.008714
2021-12-11 21:23:41,468 iteration 4348 : loss : 0.019249, loss_ce: 0.008590
2021-12-11 21:23:42,960 iteration 4349 : loss : 0.021070, loss_ce: 0.008621
2021-12-11 21:23:44,451 iteration 4350 : loss : 0.018484, loss_ce: 0.005950
2021-12-11 21:23:46,090 iteration 4351 : loss : 0.019537, loss_ce: 0.008111
2021-12-11 21:23:47,700 iteration 4352 : loss : 0.023304, loss_ce: 0.009455
 64%|█████████████████▎         | 256/400 [2:03:32<1:10:18, 29.29s/it]2021-12-11 21:23:49,286 iteration 4353 : loss : 0.015375, loss_ce: 0.005455
2021-12-11 21:23:50,932 iteration 4354 : loss : 0.020689, loss_ce: 0.006138
2021-12-11 21:23:52,536 iteration 4355 : loss : 0.021857, loss_ce: 0.007596
2021-12-11 21:23:54,062 iteration 4356 : loss : 0.018014, loss_ce: 0.006949
2021-12-11 21:23:55,720 iteration 4357 : loss : 0.030400, loss_ce: 0.012615
2021-12-11 21:23:57,257 iteration 4358 : loss : 0.019868, loss_ce: 0.008027
2021-12-11 21:23:58,860 iteration 4359 : loss : 0.025402, loss_ce: 0.007152
2021-12-11 21:24:00,355 iteration 4360 : loss : 0.017451, loss_ce: 0.006988
2021-12-11 21:24:01,987 iteration 4361 : loss : 0.034616, loss_ce: 0.014291
2021-12-11 21:24:03,493 iteration 4362 : loss : 0.020284, loss_ce: 0.006403
2021-12-11 21:24:05,062 iteration 4363 : loss : 0.021643, loss_ce: 0.008562
2021-12-11 21:24:06,624 iteration 4364 : loss : 0.026361, loss_ce: 0.012031
2021-12-11 21:24:08,240 iteration 4365 : loss : 0.021382, loss_ce: 0.006839
2021-12-11 21:24:09,765 iteration 4366 : loss : 0.025314, loss_ce: 0.009223
2021-12-11 21:24:11,247 iteration 4367 : loss : 0.019489, loss_ce: 0.008182
2021-12-11 21:24:12,764 iteration 4368 : loss : 0.014082, loss_ce: 0.005050
2021-12-11 21:24:14,375 iteration 4369 : loss : 0.026721, loss_ce: 0.010714
 64%|█████████████████▎         | 257/400 [2:03:59<1:07:56, 28.51s/it]2021-12-11 21:24:15,943 iteration 4370 : loss : 0.023341, loss_ce: 0.009786
2021-12-11 21:24:17,684 iteration 4371 : loss : 0.032834, loss_ce: 0.011521
2021-12-11 21:24:19,303 iteration 4372 : loss : 0.034436, loss_ce: 0.009182
2021-12-11 21:24:20,912 iteration 4373 : loss : 0.033874, loss_ce: 0.011744
2021-12-11 21:24:22,448 iteration 4374 : loss : 0.020172, loss_ce: 0.007767
2021-12-11 21:24:24,020 iteration 4375 : loss : 0.017620, loss_ce: 0.007147
2021-12-11 21:24:25,614 iteration 4376 : loss : 0.018763, loss_ce: 0.006168
2021-12-11 21:24:27,132 iteration 4377 : loss : 0.016503, loss_ce: 0.006520
2021-12-11 21:24:28,748 iteration 4378 : loss : 0.023656, loss_ce: 0.011586
2021-12-11 21:24:30,276 iteration 4379 : loss : 0.020526, loss_ce: 0.007378
2021-12-11 21:24:31,847 iteration 4380 : loss : 0.031010, loss_ce: 0.012386
2021-12-11 21:24:33,441 iteration 4381 : loss : 0.021907, loss_ce: 0.005931
2021-12-11 21:24:35,119 iteration 4382 : loss : 0.030658, loss_ce: 0.012118
2021-12-11 21:24:36,684 iteration 4383 : loss : 0.032048, loss_ce: 0.010117
2021-12-11 21:24:38,303 iteration 4384 : loss : 0.017913, loss_ce: 0.005969
2021-12-11 21:24:39,948 iteration 4385 : loss : 0.026131, loss_ce: 0.014495
2021-12-11 21:24:41,496 iteration 4386 : loss : 0.020378, loss_ce: 0.005262
 64%|█████████████████▍         | 258/400 [2:04:26<1:06:28, 28.09s/it]2021-12-11 21:24:43,198 iteration 4387 : loss : 0.024495, loss_ce: 0.006636
2021-12-11 21:24:44,784 iteration 4388 : loss : 0.019850, loss_ce: 0.008794
2021-12-11 21:24:46,370 iteration 4389 : loss : 0.019419, loss_ce: 0.008331
2021-12-11 21:24:47,979 iteration 4390 : loss : 0.022352, loss_ce: 0.009269
2021-12-11 21:24:49,634 iteration 4391 : loss : 0.027060, loss_ce: 0.009675
2021-12-11 21:24:51,240 iteration 4392 : loss : 0.021208, loss_ce: 0.008380
2021-12-11 21:24:52,918 iteration 4393 : loss : 0.021531, loss_ce: 0.008650
2021-12-11 21:24:54,403 iteration 4394 : loss : 0.015628, loss_ce: 0.005886
2021-12-11 21:24:55,967 iteration 4395 : loss : 0.015942, loss_ce: 0.006421
2021-12-11 21:24:57,543 iteration 4396 : loss : 0.021673, loss_ce: 0.008976
2021-12-11 21:24:59,034 iteration 4397 : loss : 0.019047, loss_ce: 0.006527
2021-12-11 21:25:00,597 iteration 4398 : loss : 0.016419, loss_ce: 0.006755
2021-12-11 21:25:02,162 iteration 4399 : loss : 0.024660, loss_ce: 0.007562
2021-12-11 21:25:03,663 iteration 4400 : loss : 0.024134, loss_ce: 0.009761
2021-12-11 21:25:05,271 iteration 4401 : loss : 0.033815, loss_ce: 0.019895
2021-12-11 21:25:06,752 iteration 4402 : loss : 0.017829, loss_ce: 0.005764
2021-12-11 21:25:08,334 iteration 4403 : loss : 0.019093, loss_ce: 0.006164
 65%|█████████████████▍         | 259/400 [2:04:53<1:05:08, 27.72s/it]2021-12-11 21:25:10,038 iteration 4404 : loss : 0.035125, loss_ce: 0.014843
2021-12-11 21:25:11,599 iteration 4405 : loss : 0.020398, loss_ce: 0.007505
2021-12-11 21:25:13,195 iteration 4406 : loss : 0.019117, loss_ce: 0.008258
2021-12-11 21:25:14,774 iteration 4407 : loss : 0.026654, loss_ce: 0.007353
2021-12-11 21:25:16,297 iteration 4408 : loss : 0.020446, loss_ce: 0.009821
2021-12-11 21:25:17,795 iteration 4409 : loss : 0.020064, loss_ce: 0.006890
2021-12-11 21:25:19,452 iteration 4410 : loss : 0.024203, loss_ce: 0.007580
2021-12-11 21:25:21,048 iteration 4411 : loss : 0.024649, loss_ce: 0.008504
2021-12-11 21:25:22,628 iteration 4412 : loss : 0.022042, loss_ce: 0.007384
2021-12-11 21:25:24,216 iteration 4413 : loss : 0.018298, loss_ce: 0.007543
2021-12-11 21:25:25,745 iteration 4414 : loss : 0.028657, loss_ce: 0.008159
2021-12-11 21:25:27,247 iteration 4415 : loss : 0.016311, loss_ce: 0.007556
2021-12-11 21:25:28,827 iteration 4416 : loss : 0.024135, loss_ce: 0.008148
2021-12-11 21:25:30,414 iteration 4417 : loss : 0.022662, loss_ce: 0.009147
2021-12-11 21:25:32,001 iteration 4418 : loss : 0.017819, loss_ce: 0.007023
2021-12-11 21:25:33,549 iteration 4419 : loss : 0.019115, loss_ce: 0.006562
2021-12-11 21:25:33,549 Training Data Eval:
2021-12-11 21:25:41,301   Average segmentation loss on training set: 0.0149
2021-12-11 21:25:41,301 Validation Data Eval:
2021-12-11 21:25:43,960   Average segmentation loss on validation set: 0.0711
2021-12-11 21:25:45,491 iteration 4420 : loss : 0.019035, loss_ce: 0.005063
 65%|█████████████████▌         | 260/400 [2:05:30<1:11:16, 30.55s/it]2021-12-11 21:25:47,111 iteration 4421 : loss : 0.029481, loss_ce: 0.009106
2021-12-11 21:25:48,645 iteration 4422 : loss : 0.018262, loss_ce: 0.005867
2021-12-11 21:25:50,178 iteration 4423 : loss : 0.016715, loss_ce: 0.005875
2021-12-11 21:25:51,781 iteration 4424 : loss : 0.021054, loss_ce: 0.007343
2021-12-11 21:25:53,332 iteration 4425 : loss : 0.025456, loss_ce: 0.007378
2021-12-11 21:25:54,869 iteration 4426 : loss : 0.018790, loss_ce: 0.005458
2021-12-11 21:25:56,439 iteration 4427 : loss : 0.021776, loss_ce: 0.008950
2021-12-11 21:25:58,031 iteration 4428 : loss : 0.023622, loss_ce: 0.010326
2021-12-11 21:25:59,476 iteration 4429 : loss : 0.022703, loss_ce: 0.009903
2021-12-11 21:26:01,045 iteration 4430 : loss : 0.030258, loss_ce: 0.014038
2021-12-11 21:26:02,657 iteration 4431 : loss : 0.027431, loss_ce: 0.008915
2021-12-11 21:26:04,295 iteration 4432 : loss : 0.022927, loss_ce: 0.008756
2021-12-11 21:26:05,889 iteration 4433 : loss : 0.022424, loss_ce: 0.005825
2021-12-11 21:26:07,501 iteration 4434 : loss : 0.025249, loss_ce: 0.010919
2021-12-11 21:26:09,008 iteration 4435 : loss : 0.017609, loss_ce: 0.005389
2021-12-11 21:26:10,545 iteration 4436 : loss : 0.019887, loss_ce: 0.009252
2021-12-11 21:26:12,097 iteration 4437 : loss : 0.018512, loss_ce: 0.006496
 65%|█████████████████▌         | 261/400 [2:05:56<1:08:01, 29.37s/it]2021-12-11 21:26:13,822 iteration 4438 : loss : 0.023661, loss_ce: 0.008742
2021-12-11 21:26:15,303 iteration 4439 : loss : 0.016695, loss_ce: 0.007231
2021-12-11 21:26:16,945 iteration 4440 : loss : 0.021379, loss_ce: 0.010667
2021-12-11 21:26:18,518 iteration 4441 : loss : 0.018814, loss_ce: 0.007721
2021-12-11 21:26:20,194 iteration 4442 : loss : 0.028099, loss_ce: 0.010863
2021-12-11 21:26:21,851 iteration 4443 : loss : 0.032895, loss_ce: 0.013772
2021-12-11 21:26:23,448 iteration 4444 : loss : 0.022272, loss_ce: 0.007865
2021-12-11 21:26:24,987 iteration 4445 : loss : 0.020081, loss_ce: 0.006934
2021-12-11 21:26:26,618 iteration 4446 : loss : 0.056632, loss_ce: 0.014051
2021-12-11 21:26:28,290 iteration 4447 : loss : 0.025492, loss_ce: 0.008702
2021-12-11 21:26:29,838 iteration 4448 : loss : 0.023018, loss_ce: 0.008194
2021-12-11 21:26:31,516 iteration 4449 : loss : 0.029463, loss_ce: 0.012065
2021-12-11 21:26:33,072 iteration 4450 : loss : 0.034424, loss_ce: 0.021118
2021-12-11 21:26:34,677 iteration 4451 : loss : 0.019784, loss_ce: 0.007640
2021-12-11 21:26:36,197 iteration 4452 : loss : 0.029103, loss_ce: 0.010116
2021-12-11 21:26:37,707 iteration 4453 : loss : 0.015769, loss_ce: 0.006308
2021-12-11 21:26:39,248 iteration 4454 : loss : 0.020585, loss_ce: 0.008002
 66%|█████████████████▋         | 262/400 [2:06:24<1:06:00, 28.70s/it]2021-12-11 21:26:40,840 iteration 4455 : loss : 0.030138, loss_ce: 0.010660
2021-12-11 21:26:42,315 iteration 4456 : loss : 0.027497, loss_ce: 0.010163
2021-12-11 21:26:43,870 iteration 4457 : loss : 0.021878, loss_ce: 0.008206
2021-12-11 21:26:45,389 iteration 4458 : loss : 0.029135, loss_ce: 0.012126
2021-12-11 21:26:46,985 iteration 4459 : loss : 0.025141, loss_ce: 0.007057
2021-12-11 21:26:48,503 iteration 4460 : loss : 0.016628, loss_ce: 0.006665
2021-12-11 21:26:50,040 iteration 4461 : loss : 0.019690, loss_ce: 0.008944
2021-12-11 21:26:51,683 iteration 4462 : loss : 0.038611, loss_ce: 0.015017
2021-12-11 21:26:53,174 iteration 4463 : loss : 0.019937, loss_ce: 0.007600
2021-12-11 21:26:54,706 iteration 4464 : loss : 0.017964, loss_ce: 0.008185
2021-12-11 21:26:56,392 iteration 4465 : loss : 0.071535, loss_ce: 0.011752
2021-12-11 21:26:57,867 iteration 4466 : loss : 0.019129, loss_ce: 0.007213
2021-12-11 21:26:59,447 iteration 4467 : loss : 0.043986, loss_ce: 0.023716
2021-12-11 21:27:01,006 iteration 4468 : loss : 0.029905, loss_ce: 0.010638
2021-12-11 21:27:02,560 iteration 4469 : loss : 0.029695, loss_ce: 0.007541
2021-12-11 21:27:04,102 iteration 4470 : loss : 0.033747, loss_ce: 0.013809
2021-12-11 21:27:05,714 iteration 4471 : loss : 0.030731, loss_ce: 0.008074
 66%|█████████████████▊         | 263/400 [2:06:50<1:04:00, 28.03s/it]2021-12-11 21:27:07,285 iteration 4472 : loss : 0.024866, loss_ce: 0.011301
2021-12-11 21:27:08,890 iteration 4473 : loss : 0.029348, loss_ce: 0.011594
2021-12-11 21:27:10,563 iteration 4474 : loss : 0.025797, loss_ce: 0.010966
2021-12-11 21:27:12,163 iteration 4475 : loss : 0.026844, loss_ce: 0.010304
2021-12-11 21:27:13,706 iteration 4476 : loss : 0.036022, loss_ce: 0.012054
2021-12-11 21:27:15,235 iteration 4477 : loss : 0.024228, loss_ce: 0.009559
2021-12-11 21:27:16,904 iteration 4478 : loss : 0.023547, loss_ce: 0.011748
2021-12-11 21:27:18,456 iteration 4479 : loss : 0.025080, loss_ce: 0.010920
2021-12-11 21:27:19,935 iteration 4480 : loss : 0.023802, loss_ce: 0.009050
2021-12-11 21:27:21,555 iteration 4481 : loss : 0.027442, loss_ce: 0.007878
2021-12-11 21:27:23,118 iteration 4482 : loss : 0.021673, loss_ce: 0.007225
2021-12-11 21:27:24,619 iteration 4483 : loss : 0.035913, loss_ce: 0.008450
2021-12-11 21:27:26,269 iteration 4484 : loss : 0.028479, loss_ce: 0.010119
2021-12-11 21:27:27,895 iteration 4485 : loss : 0.026819, loss_ce: 0.011436
2021-12-11 21:27:29,530 iteration 4486 : loss : 0.023069, loss_ce: 0.007464
2021-12-11 21:27:31,044 iteration 4487 : loss : 0.026609, loss_ce: 0.007044
2021-12-11 21:27:32,572 iteration 4488 : loss : 0.040992, loss_ce: 0.014682
 66%|█████████████████▊         | 264/400 [2:07:17<1:02:44, 27.68s/it]2021-12-11 21:27:34,240 iteration 4489 : loss : 0.021847, loss_ce: 0.008402
2021-12-11 21:27:35,743 iteration 4490 : loss : 0.022323, loss_ce: 0.010227
2021-12-11 21:27:37,358 iteration 4491 : loss : 0.046454, loss_ce: 0.016545
2021-12-11 21:27:39,024 iteration 4492 : loss : 0.029062, loss_ce: 0.012683
2021-12-11 21:27:40,564 iteration 4493 : loss : 0.025263, loss_ce: 0.008906
2021-12-11 21:27:42,136 iteration 4494 : loss : 0.026285, loss_ce: 0.007515
2021-12-11 21:27:43,713 iteration 4495 : loss : 0.032457, loss_ce: 0.009912
2021-12-11 21:27:45,242 iteration 4496 : loss : 0.022762, loss_ce: 0.010350
2021-12-11 21:27:46,876 iteration 4497 : loss : 0.020576, loss_ce: 0.008883
2021-12-11 21:27:48,443 iteration 4498 : loss : 0.027187, loss_ce: 0.007069
2021-12-11 21:27:50,040 iteration 4499 : loss : 0.025767, loss_ce: 0.007800
2021-12-11 21:27:51,524 iteration 4500 : loss : 0.017107, loss_ce: 0.005512
2021-12-11 21:27:53,037 iteration 4501 : loss : 0.026386, loss_ce: 0.006381
2021-12-11 21:27:54,559 iteration 4502 : loss : 0.036532, loss_ce: 0.013105
2021-12-11 21:27:56,203 iteration 4503 : loss : 0.033243, loss_ce: 0.013487
2021-12-11 21:27:57,746 iteration 4504 : loss : 0.018164, loss_ce: 0.006193
2021-12-11 21:27:57,746 Training Data Eval:
2021-12-11 21:28:05,492   Average segmentation loss on training set: 0.0186
2021-12-11 21:28:05,492 Validation Data Eval:
2021-12-11 21:28:08,156   Average segmentation loss on validation set: 0.1196
2021-12-11 21:28:09,742 iteration 4505 : loss : 0.025949, loss_ce: 0.009574
 66%|█████████████████▉         | 265/400 [2:07:54<1:08:40, 30.53s/it]2021-12-11 21:28:11,317 iteration 4506 : loss : 0.029205, loss_ce: 0.011636
2021-12-11 21:28:12,899 iteration 4507 : loss : 0.021801, loss_ce: 0.008996
2021-12-11 21:28:14,430 iteration 4508 : loss : 0.021788, loss_ce: 0.007656
2021-12-11 21:28:15,943 iteration 4509 : loss : 0.031559, loss_ce: 0.006840
2021-12-11 21:28:17,589 iteration 4510 : loss : 0.020213, loss_ce: 0.005984
2021-12-11 21:28:19,136 iteration 4511 : loss : 0.026921, loss_ce: 0.007259
2021-12-11 21:28:20,788 iteration 4512 : loss : 0.028047, loss_ce: 0.013855
2021-12-11 21:28:22,480 iteration 4513 : loss : 0.029573, loss_ce: 0.010425
2021-12-11 21:28:23,945 iteration 4514 : loss : 0.024571, loss_ce: 0.008285
2021-12-11 21:28:25,481 iteration 4515 : loss : 0.025802, loss_ce: 0.008039
2021-12-11 21:28:26,973 iteration 4516 : loss : 0.019449, loss_ce: 0.007136
2021-12-11 21:28:28,478 iteration 4517 : loss : 0.018836, loss_ce: 0.007341
2021-12-11 21:28:30,068 iteration 4518 : loss : 0.030926, loss_ce: 0.010177
2021-12-11 21:28:31,528 iteration 4519 : loss : 0.020174, loss_ce: 0.006737
2021-12-11 21:28:33,125 iteration 4520 : loss : 0.027179, loss_ce: 0.010827
2021-12-11 21:28:34,678 iteration 4521 : loss : 0.019314, loss_ce: 0.007478
2021-12-11 21:28:36,246 iteration 4522 : loss : 0.023118, loss_ce: 0.008044
 66%|█████████████████▉         | 266/400 [2:08:21<1:05:29, 29.32s/it]2021-12-11 21:28:37,967 iteration 4523 : loss : 0.019052, loss_ce: 0.007188
2021-12-11 21:28:39,497 iteration 4524 : loss : 0.016823, loss_ce: 0.006363
2021-12-11 21:28:40,970 iteration 4525 : loss : 0.020448, loss_ce: 0.009270
2021-12-11 21:28:42,489 iteration 4526 : loss : 0.020495, loss_ce: 0.005882
2021-12-11 21:28:44,003 iteration 4527 : loss : 0.021831, loss_ce: 0.008525
2021-12-11 21:28:45,565 iteration 4528 : loss : 0.018934, loss_ce: 0.006937
2021-12-11 21:28:47,075 iteration 4529 : loss : 0.018111, loss_ce: 0.005712
2021-12-11 21:28:48,626 iteration 4530 : loss : 0.023380, loss_ce: 0.008716
2021-12-11 21:28:50,292 iteration 4531 : loss : 0.024215, loss_ce: 0.008222
2021-12-11 21:28:51,759 iteration 4532 : loss : 0.015727, loss_ce: 0.005561
2021-12-11 21:28:53,475 iteration 4533 : loss : 0.034656, loss_ce: 0.013525
2021-12-11 21:28:54,990 iteration 4534 : loss : 0.019733, loss_ce: 0.009146
2021-12-11 21:28:56,587 iteration 4535 : loss : 0.029321, loss_ce: 0.014288
2021-12-11 21:28:58,164 iteration 4536 : loss : 0.025593, loss_ce: 0.006892
2021-12-11 21:28:59,681 iteration 4537 : loss : 0.026538, loss_ce: 0.006851
2021-12-11 21:29:01,213 iteration 4538 : loss : 0.019953, loss_ce: 0.008448
2021-12-11 21:29:02,656 iteration 4539 : loss : 0.017791, loss_ce: 0.006491
 67%|██████████████████         | 267/400 [2:08:47<1:03:03, 28.45s/it]2021-12-11 21:29:04,215 iteration 4540 : loss : 0.019887, loss_ce: 0.008544
2021-12-11 21:29:05,766 iteration 4541 : loss : 0.023084, loss_ce: 0.007932
2021-12-11 21:29:07,329 iteration 4542 : loss : 0.027952, loss_ce: 0.009582
2021-12-11 21:29:09,061 iteration 4543 : loss : 0.023340, loss_ce: 0.008489
2021-12-11 21:29:10,565 iteration 4544 : loss : 0.022276, loss_ce: 0.008882
2021-12-11 21:29:12,081 iteration 4545 : loss : 0.015238, loss_ce: 0.005632
2021-12-11 21:29:13,652 iteration 4546 : loss : 0.024464, loss_ce: 0.010388
2021-12-11 21:29:15,232 iteration 4547 : loss : 0.023336, loss_ce: 0.007600
2021-12-11 21:29:16,774 iteration 4548 : loss : 0.027686, loss_ce: 0.012350
2021-12-11 21:29:18,254 iteration 4549 : loss : 0.021141, loss_ce: 0.007130
2021-12-11 21:29:19,908 iteration 4550 : loss : 0.017949, loss_ce: 0.005925
2021-12-11 21:29:21,565 iteration 4551 : loss : 0.028348, loss_ce: 0.008181
2021-12-11 21:29:23,138 iteration 4552 : loss : 0.027852, loss_ce: 0.008867
2021-12-11 21:29:24,679 iteration 4553 : loss : 0.016266, loss_ce: 0.004645
2021-12-11 21:29:26,302 iteration 4554 : loss : 0.025773, loss_ce: 0.006556
2021-12-11 21:29:27,816 iteration 4555 : loss : 0.026571, loss_ce: 0.009954
2021-12-11 21:29:29,383 iteration 4556 : loss : 0.020929, loss_ce: 0.008017
 67%|██████████████████         | 268/400 [2:09:14<1:01:26, 27.93s/it]2021-12-11 21:29:31,001 iteration 4557 : loss : 0.016274, loss_ce: 0.007788
2021-12-11 21:29:32,584 iteration 4558 : loss : 0.026912, loss_ce: 0.010834
2021-12-11 21:29:34,206 iteration 4559 : loss : 0.016826, loss_ce: 0.005309
2021-12-11 21:29:35,780 iteration 4560 : loss : 0.019868, loss_ce: 0.005795
2021-12-11 21:29:37,391 iteration 4561 : loss : 0.033039, loss_ce: 0.008445
2021-12-11 21:29:38,921 iteration 4562 : loss : 0.025972, loss_ce: 0.007490
2021-12-11 21:29:40,529 iteration 4563 : loss : 0.025068, loss_ce: 0.011950
2021-12-11 21:29:42,154 iteration 4564 : loss : 0.030024, loss_ce: 0.011279
2021-12-11 21:29:43,827 iteration 4565 : loss : 0.030445, loss_ce: 0.010300
2021-12-11 21:29:45,463 iteration 4566 : loss : 0.031149, loss_ce: 0.014354
2021-12-11 21:29:47,018 iteration 4567 : loss : 0.021130, loss_ce: 0.008372
2021-12-11 21:29:48,576 iteration 4568 : loss : 0.021172, loss_ce: 0.006837
2021-12-11 21:29:50,250 iteration 4569 : loss : 0.043945, loss_ce: 0.007852
2021-12-11 21:29:51,947 iteration 4570 : loss : 0.025164, loss_ce: 0.012045
2021-12-11 21:29:53,512 iteration 4571 : loss : 0.030317, loss_ce: 0.011340
2021-12-11 21:29:55,015 iteration 4572 : loss : 0.027901, loss_ce: 0.009192
2021-12-11 21:29:56,628 iteration 4573 : loss : 0.037680, loss_ce: 0.015365
 67%|██████████████████▏        | 269/400 [2:09:41<1:00:32, 27.73s/it]2021-12-11 21:29:58,158 iteration 4574 : loss : 0.016973, loss_ce: 0.007294
2021-12-11 21:29:59,793 iteration 4575 : loss : 0.032434, loss_ce: 0.009992
2021-12-11 21:30:01,518 iteration 4576 : loss : 0.023625, loss_ce: 0.008110
2021-12-11 21:30:03,114 iteration 4577 : loss : 0.021102, loss_ce: 0.006350
2021-12-11 21:30:04,591 iteration 4578 : loss : 0.024918, loss_ce: 0.010809
2021-12-11 21:30:06,222 iteration 4579 : loss : 0.025714, loss_ce: 0.007748
2021-12-11 21:30:07,791 iteration 4580 : loss : 0.023079, loss_ce: 0.009048
2021-12-11 21:30:09,358 iteration 4581 : loss : 0.019094, loss_ce: 0.007046
2021-12-11 21:30:10,909 iteration 4582 : loss : 0.021805, loss_ce: 0.008721
2021-12-11 21:30:12,587 iteration 4583 : loss : 0.040245, loss_ce: 0.008913
2021-12-11 21:30:14,156 iteration 4584 : loss : 0.035616, loss_ce: 0.009441
2021-12-11 21:30:15,664 iteration 4585 : loss : 0.018952, loss_ce: 0.006185
2021-12-11 21:30:17,212 iteration 4586 : loss : 0.019227, loss_ce: 0.009013
2021-12-11 21:30:18,774 iteration 4587 : loss : 0.018742, loss_ce: 0.006621
2021-12-11 21:30:20,416 iteration 4588 : loss : 0.021072, loss_ce: 0.008764
2021-12-11 21:30:21,981 iteration 4589 : loss : 0.043066, loss_ce: 0.022721
2021-12-11 21:30:21,981 Training Data Eval:
2021-12-11 21:30:29,723   Average segmentation loss on training set: 0.0139
2021-12-11 21:30:29,723 Validation Data Eval:
2021-12-11 21:30:32,377   Average segmentation loss on validation set: 0.0717
2021-12-11 21:30:33,984 iteration 4590 : loss : 0.035587, loss_ce: 0.020516
 68%|██████████████████▏        | 270/400 [2:10:18<1:06:19, 30.61s/it]2021-12-11 21:30:35,776 iteration 4591 : loss : 0.026066, loss_ce: 0.008392
2021-12-11 21:30:37,343 iteration 4592 : loss : 0.021429, loss_ce: 0.009347
2021-12-11 21:30:38,905 iteration 4593 : loss : 0.028771, loss_ce: 0.010227
2021-12-11 21:30:40,486 iteration 4594 : loss : 0.027058, loss_ce: 0.010727
2021-12-11 21:30:42,063 iteration 4595 : loss : 0.018413, loss_ce: 0.007060
2021-12-11 21:30:43,754 iteration 4596 : loss : 0.024048, loss_ce: 0.010498
2021-12-11 21:30:45,256 iteration 4597 : loss : 0.030059, loss_ce: 0.009421
2021-12-11 21:30:46,718 iteration 4598 : loss : 0.018269, loss_ce: 0.005396
2021-12-11 21:30:48,247 iteration 4599 : loss : 0.024812, loss_ce: 0.009082
2021-12-11 21:30:49,823 iteration 4600 : loss : 0.022039, loss_ce: 0.007574
2021-12-11 21:30:51,421 iteration 4601 : loss : 0.030092, loss_ce: 0.016192
2021-12-11 21:30:53,091 iteration 4602 : loss : 0.035536, loss_ce: 0.013083
2021-12-11 21:30:54,755 iteration 4603 : loss : 0.024323, loss_ce: 0.009278
2021-12-11 21:30:56,268 iteration 4604 : loss : 0.017980, loss_ce: 0.006202
2021-12-11 21:30:57,834 iteration 4605 : loss : 0.017514, loss_ce: 0.004979
2021-12-11 21:30:59,378 iteration 4606 : loss : 0.022910, loss_ce: 0.007301
2021-12-11 21:31:00,923 iteration 4607 : loss : 0.021699, loss_ce: 0.008586
 68%|██████████████████▎        | 271/400 [2:10:45<1:03:26, 29.51s/it]2021-12-11 21:31:02,577 iteration 4608 : loss : 0.017881, loss_ce: 0.005868
2021-12-11 21:31:04,167 iteration 4609 : loss : 0.022764, loss_ce: 0.007324
2021-12-11 21:31:05,767 iteration 4610 : loss : 0.022440, loss_ce: 0.005149
2021-12-11 21:31:07,394 iteration 4611 : loss : 0.026144, loss_ce: 0.010381
2021-12-11 21:31:08,976 iteration 4612 : loss : 0.026057, loss_ce: 0.010826
2021-12-11 21:31:10,558 iteration 4613 : loss : 0.026375, loss_ce: 0.008473
2021-12-11 21:31:12,132 iteration 4614 : loss : 0.016988, loss_ce: 0.005331
2021-12-11 21:31:13,844 iteration 4615 : loss : 0.034882, loss_ce: 0.014574
2021-12-11 21:31:15,348 iteration 4616 : loss : 0.020806, loss_ce: 0.008976
2021-12-11 21:31:16,943 iteration 4617 : loss : 0.022755, loss_ce: 0.007078
2021-12-11 21:31:18,473 iteration 4618 : loss : 0.015081, loss_ce: 0.005438
2021-12-11 21:31:20,071 iteration 4619 : loss : 0.024171, loss_ce: 0.009835
2021-12-11 21:31:21,604 iteration 4620 : loss : 0.017015, loss_ce: 0.006326
2021-12-11 21:31:23,143 iteration 4621 : loss : 0.017902, loss_ce: 0.005906
2021-12-11 21:31:24,729 iteration 4622 : loss : 0.026720, loss_ce: 0.010138
2021-12-11 21:31:26,310 iteration 4623 : loss : 0.019696, loss_ce: 0.008958
2021-12-11 21:31:27,839 iteration 4624 : loss : 0.023291, loss_ce: 0.007579
 68%|██████████████████▎        | 272/400 [2:11:12<1:01:17, 28.73s/it]2021-12-11 21:31:29,546 iteration 4625 : loss : 0.027183, loss_ce: 0.007778
2021-12-11 21:31:31,157 iteration 4626 : loss : 0.029545, loss_ce: 0.010175
2021-12-11 21:31:32,714 iteration 4627 : loss : 0.017450, loss_ce: 0.007682
2021-12-11 21:31:34,278 iteration 4628 : loss : 0.021837, loss_ce: 0.007718
2021-12-11 21:31:35,776 iteration 4629 : loss : 0.046135, loss_ce: 0.008211
2021-12-11 21:31:37,358 iteration 4630 : loss : 0.019224, loss_ce: 0.009549
2021-12-11 21:31:38,912 iteration 4631 : loss : 0.027608, loss_ce: 0.009294
2021-12-11 21:31:40,482 iteration 4632 : loss : 0.021442, loss_ce: 0.006254
2021-12-11 21:31:42,070 iteration 4633 : loss : 0.019634, loss_ce: 0.006722
2021-12-11 21:31:43,720 iteration 4634 : loss : 0.036655, loss_ce: 0.016874
2021-12-11 21:31:45,152 iteration 4635 : loss : 0.015244, loss_ce: 0.004744
2021-12-11 21:31:46,628 iteration 4636 : loss : 0.014107, loss_ce: 0.005033
2021-12-11 21:31:48,180 iteration 4637 : loss : 0.030688, loss_ce: 0.009697
2021-12-11 21:31:49,736 iteration 4638 : loss : 0.025027, loss_ce: 0.011527
2021-12-11 21:31:51,335 iteration 4639 : loss : 0.023287, loss_ce: 0.006848
2021-12-11 21:31:52,939 iteration 4640 : loss : 0.025805, loss_ce: 0.010967
2021-12-11 21:31:54,510 iteration 4641 : loss : 0.023280, loss_ce: 0.008488
 68%|███████████████████▊         | 273/400 [2:11:39<59:30, 28.11s/it]2021-12-11 21:31:56,124 iteration 4642 : loss : 0.019477, loss_ce: 0.007871
2021-12-11 21:31:57,686 iteration 4643 : loss : 0.025464, loss_ce: 0.009508
2021-12-11 21:31:59,272 iteration 4644 : loss : 0.023754, loss_ce: 0.011372
2021-12-11 21:32:00,798 iteration 4645 : loss : 0.022166, loss_ce: 0.006984
2021-12-11 21:32:02,349 iteration 4646 : loss : 0.020203, loss_ce: 0.007793
2021-12-11 21:32:03,914 iteration 4647 : loss : 0.020737, loss_ce: 0.008240
2021-12-11 21:32:05,431 iteration 4648 : loss : 0.024663, loss_ce: 0.012833
2021-12-11 21:32:07,152 iteration 4649 : loss : 0.024193, loss_ce: 0.008802
2021-12-11 21:32:08,583 iteration 4650 : loss : 0.017609, loss_ce: 0.006758
2021-12-11 21:32:10,153 iteration 4651 : loss : 0.028528, loss_ce: 0.011023
2021-12-11 21:32:11,711 iteration 4652 : loss : 0.021320, loss_ce: 0.007715
2021-12-11 21:32:13,181 iteration 4653 : loss : 0.015187, loss_ce: 0.006828
2021-12-11 21:32:14,664 iteration 4654 : loss : 0.017236, loss_ce: 0.005011
2021-12-11 21:32:16,283 iteration 4655 : loss : 0.033944, loss_ce: 0.012473
2021-12-11 21:32:17,836 iteration 4656 : loss : 0.021358, loss_ce: 0.007409
2021-12-11 21:32:19,392 iteration 4657 : loss : 0.021927, loss_ce: 0.008855
2021-12-11 21:32:20,935 iteration 4658 : loss : 0.015038, loss_ce: 0.005829
 68%|███████████████████▊         | 274/400 [2:12:05<57:58, 27.60s/it]2021-12-11 21:32:22,562 iteration 4659 : loss : 0.019078, loss_ce: 0.007184
2021-12-11 21:32:24,079 iteration 4660 : loss : 0.016244, loss_ce: 0.006106
2021-12-11 21:32:25,699 iteration 4661 : loss : 0.019206, loss_ce: 0.007743
2021-12-11 21:32:27,153 iteration 4662 : loss : 0.015665, loss_ce: 0.007668
2021-12-11 21:32:28,813 iteration 4663 : loss : 0.024379, loss_ce: 0.009605
2021-12-11 21:32:30,369 iteration 4664 : loss : 0.023226, loss_ce: 0.009349
2021-12-11 21:32:31,918 iteration 4665 : loss : 0.023721, loss_ce: 0.009948
2021-12-11 21:32:33,547 iteration 4666 : loss : 0.021783, loss_ce: 0.009464
2021-12-11 21:32:35,176 iteration 4667 : loss : 0.032023, loss_ce: 0.008443
2021-12-11 21:32:36,716 iteration 4668 : loss : 0.016400, loss_ce: 0.006903
2021-12-11 21:32:38,345 iteration 4669 : loss : 0.019397, loss_ce: 0.007119
2021-12-11 21:32:39,923 iteration 4670 : loss : 0.040630, loss_ce: 0.012333
2021-12-11 21:32:41,447 iteration 4671 : loss : 0.015799, loss_ce: 0.005671
2021-12-11 21:32:42,976 iteration 4672 : loss : 0.014387, loss_ce: 0.005130
2021-12-11 21:32:44,436 iteration 4673 : loss : 0.014557, loss_ce: 0.004815
2021-12-11 21:32:46,021 iteration 4674 : loss : 0.017840, loss_ce: 0.003954
2021-12-11 21:32:46,021 Training Data Eval:
2021-12-11 21:32:53,753   Average segmentation loss on training set: 0.0138
2021-12-11 21:32:53,753 Validation Data Eval:
2021-12-11 21:32:56,402   Average segmentation loss on validation set: 0.1021
2021-12-11 21:32:57,873 iteration 4675 : loss : 0.015313, loss_ce: 0.005776
 69%|██████████████████▌        | 275/400 [2:12:42<1:03:20, 30.41s/it]2021-12-11 21:32:59,492 iteration 4676 : loss : 0.017808, loss_ce: 0.007522
2021-12-11 21:33:00,997 iteration 4677 : loss : 0.016591, loss_ce: 0.006877
2021-12-11 21:33:02,601 iteration 4678 : loss : 0.022219, loss_ce: 0.007154
2021-12-11 21:33:04,258 iteration 4679 : loss : 0.024649, loss_ce: 0.010255
2021-12-11 21:33:05,741 iteration 4680 : loss : 0.015638, loss_ce: 0.005926
2021-12-11 21:33:07,289 iteration 4681 : loss : 0.019188, loss_ce: 0.007826
2021-12-11 21:33:08,824 iteration 4682 : loss : 0.019133, loss_ce: 0.006950
2021-12-11 21:33:10,332 iteration 4683 : loss : 0.017463, loss_ce: 0.005718
2021-12-11 21:33:11,888 iteration 4684 : loss : 0.018839, loss_ce: 0.006198
2021-12-11 21:33:13,499 iteration 4685 : loss : 0.018788, loss_ce: 0.008440
2021-12-11 21:33:14,997 iteration 4686 : loss : 0.024971, loss_ce: 0.008783
2021-12-11 21:33:16,565 iteration 4687 : loss : 0.033316, loss_ce: 0.009529
2021-12-11 21:33:18,016 iteration 4688 : loss : 0.012362, loss_ce: 0.005277
2021-12-11 21:33:19,598 iteration 4689 : loss : 0.021965, loss_ce: 0.008261
2021-12-11 21:33:21,055 iteration 4690 : loss : 0.017732, loss_ce: 0.006227
2021-12-11 21:33:22,605 iteration 4691 : loss : 0.024179, loss_ce: 0.006497
2021-12-11 21:33:24,276 iteration 4692 : loss : 0.026508, loss_ce: 0.009607
 69%|██████████████████▋        | 276/400 [2:13:09<1:00:21, 29.21s/it]2021-12-11 21:33:25,873 iteration 4693 : loss : 0.022034, loss_ce: 0.008308
2021-12-11 21:33:27,408 iteration 4694 : loss : 0.022872, loss_ce: 0.007000
2021-12-11 21:33:28,998 iteration 4695 : loss : 0.022405, loss_ce: 0.007575
2021-12-11 21:33:30,581 iteration 4696 : loss : 0.017588, loss_ce: 0.006424
2021-12-11 21:33:32,082 iteration 4697 : loss : 0.020839, loss_ce: 0.008857
2021-12-11 21:33:33,593 iteration 4698 : loss : 0.020054, loss_ce: 0.007933
2021-12-11 21:33:35,133 iteration 4699 : loss : 0.021731, loss_ce: 0.005935
2021-12-11 21:33:36,682 iteration 4700 : loss : 0.018438, loss_ce: 0.007220
2021-12-11 21:33:38,206 iteration 4701 : loss : 0.015500, loss_ce: 0.004127
2021-12-11 21:33:39,822 iteration 4702 : loss : 0.023025, loss_ce: 0.008187
2021-12-11 21:33:41,396 iteration 4703 : loss : 0.026820, loss_ce: 0.012414
2021-12-11 21:33:42,980 iteration 4704 : loss : 0.031863, loss_ce: 0.006690
2021-12-11 21:33:44,567 iteration 4705 : loss : 0.023612, loss_ce: 0.005867
2021-12-11 21:33:46,042 iteration 4706 : loss : 0.016525, loss_ce: 0.006172
2021-12-11 21:33:47,576 iteration 4707 : loss : 0.021977, loss_ce: 0.007269
2021-12-11 21:33:49,124 iteration 4708 : loss : 0.020328, loss_ce: 0.009088
2021-12-11 21:33:50,650 iteration 4709 : loss : 0.025694, loss_ce: 0.009883
 69%|████████████████████         | 277/400 [2:13:35<58:07, 28.35s/it]2021-12-11 21:33:52,226 iteration 4710 : loss : 0.019183, loss_ce: 0.006821
2021-12-11 21:33:53,719 iteration 4711 : loss : 0.021787, loss_ce: 0.006884
2021-12-11 21:33:55,186 iteration 4712 : loss : 0.017718, loss_ce: 0.005940
2021-12-11 21:33:56,736 iteration 4713 : loss : 0.018621, loss_ce: 0.005302
2021-12-11 21:33:58,209 iteration 4714 : loss : 0.014828, loss_ce: 0.005054
2021-12-11 21:33:59,777 iteration 4715 : loss : 0.020414, loss_ce: 0.010213
2021-12-11 21:34:01,380 iteration 4716 : loss : 0.028172, loss_ce: 0.010329
2021-12-11 21:34:02,910 iteration 4717 : loss : 0.020208, loss_ce: 0.007587
2021-12-11 21:34:04,482 iteration 4718 : loss : 0.019854, loss_ce: 0.007018
2021-12-11 21:34:06,013 iteration 4719 : loss : 0.014872, loss_ce: 0.004834
2021-12-11 21:34:07,561 iteration 4720 : loss : 0.020224, loss_ce: 0.009479
2021-12-11 21:34:09,085 iteration 4721 : loss : 0.035053, loss_ce: 0.009909
2021-12-11 21:34:10,719 iteration 4722 : loss : 0.020281, loss_ce: 0.007849
2021-12-11 21:34:12,373 iteration 4723 : loss : 0.022355, loss_ce: 0.008099
2021-12-11 21:34:14,030 iteration 4724 : loss : 0.028478, loss_ce: 0.014472
2021-12-11 21:34:15,544 iteration 4725 : loss : 0.024170, loss_ce: 0.008459
2021-12-11 21:34:17,143 iteration 4726 : loss : 0.023220, loss_ce: 0.007306
 70%|████████████████████▏        | 278/400 [2:14:01<56:31, 27.80s/it]2021-12-11 21:34:18,773 iteration 4727 : loss : 0.021307, loss_ce: 0.007236
2021-12-11 21:34:20,353 iteration 4728 : loss : 0.016421, loss_ce: 0.005484
2021-12-11 21:34:21,872 iteration 4729 : loss : 0.019374, loss_ce: 0.005882
2021-12-11 21:34:23,447 iteration 4730 : loss : 0.020583, loss_ce: 0.007949
2021-12-11 21:34:25,009 iteration 4731 : loss : 0.022798, loss_ce: 0.006148
2021-12-11 21:34:26,573 iteration 4732 : loss : 0.017281, loss_ce: 0.006309
2021-12-11 21:34:28,058 iteration 4733 : loss : 0.015565, loss_ce: 0.005607
2021-12-11 21:34:29,543 iteration 4734 : loss : 0.016083, loss_ce: 0.005216
2021-12-11 21:34:31,185 iteration 4735 : loss : 0.021645, loss_ce: 0.009641
2021-12-11 21:34:32,776 iteration 4736 : loss : 0.020848, loss_ce: 0.007845
2021-12-11 21:34:34,442 iteration 4737 : loss : 0.028386, loss_ce: 0.008614
2021-12-11 21:34:36,076 iteration 4738 : loss : 0.039193, loss_ce: 0.005616
2021-12-11 21:34:37,613 iteration 4739 : loss : 0.018678, loss_ce: 0.006669
2021-12-11 21:34:39,093 iteration 4740 : loss : 0.015761, loss_ce: 0.006405
2021-12-11 21:34:40,636 iteration 4741 : loss : 0.040041, loss_ce: 0.024980
2021-12-11 21:34:42,100 iteration 4742 : loss : 0.017295, loss_ce: 0.005884
2021-12-11 21:34:43,653 iteration 4743 : loss : 0.014069, loss_ce: 0.004563
 70%|████████████████████▏        | 279/400 [2:14:28<55:16, 27.41s/it]2021-12-11 21:34:45,286 iteration 4744 : loss : 0.021301, loss_ce: 0.008887
2021-12-11 21:34:46,855 iteration 4745 : loss : 0.017962, loss_ce: 0.006901
2021-12-11 21:34:48,402 iteration 4746 : loss : 0.019139, loss_ce: 0.007792
2021-12-11 21:34:50,006 iteration 4747 : loss : 0.020715, loss_ce: 0.008311
2021-12-11 21:34:51,680 iteration 4748 : loss : 0.026768, loss_ce: 0.010282
2021-12-11 21:34:53,314 iteration 4749 : loss : 0.028610, loss_ce: 0.007387
2021-12-11 21:34:54,868 iteration 4750 : loss : 0.019006, loss_ce: 0.007312
2021-12-11 21:34:56,361 iteration 4751 : loss : 0.021130, loss_ce: 0.006997
2021-12-11 21:34:57,924 iteration 4752 : loss : 0.029372, loss_ce: 0.007673
2021-12-11 21:34:59,525 iteration 4753 : loss : 0.019387, loss_ce: 0.009368
2021-12-11 21:35:01,102 iteration 4754 : loss : 0.018927, loss_ce: 0.005781
2021-12-11 21:35:02,692 iteration 4755 : loss : 0.023392, loss_ce: 0.008929
2021-12-11 21:35:04,254 iteration 4756 : loss : 0.018051, loss_ce: 0.007213
2021-12-11 21:35:05,824 iteration 4757 : loss : 0.020833, loss_ce: 0.008374
2021-12-11 21:35:07,501 iteration 4758 : loss : 0.026207, loss_ce: 0.008965
2021-12-11 21:35:08,992 iteration 4759 : loss : 0.015740, loss_ce: 0.005893
2021-12-11 21:35:08,993 Training Data Eval:
2021-12-11 21:35:16,742   Average segmentation loss on training set: 0.0139
2021-12-11 21:35:16,742 Validation Data Eval:
2021-12-11 21:35:19,399   Average segmentation loss on validation set: 0.0787
2021-12-11 21:35:20,955 iteration 4760 : loss : 0.022154, loss_ce: 0.007361
 70%|██████████████████▉        | 280/400 [2:15:05<1:00:45, 30.38s/it]2021-12-11 21:35:22,590 iteration 4761 : loss : 0.024135, loss_ce: 0.010305
2021-12-11 21:35:24,200 iteration 4762 : loss : 0.028890, loss_ce: 0.006595
2021-12-11 21:35:25,790 iteration 4763 : loss : 0.018571, loss_ce: 0.005986
2021-12-11 21:35:27,444 iteration 4764 : loss : 0.019785, loss_ce: 0.006360
2021-12-11 21:35:29,061 iteration 4765 : loss : 0.018065, loss_ce: 0.006860
2021-12-11 21:35:30,761 iteration 4766 : loss : 0.031419, loss_ce: 0.006998
2021-12-11 21:35:32,479 iteration 4767 : loss : 0.028758, loss_ce: 0.013625
2021-12-11 21:35:34,091 iteration 4768 : loss : 0.022064, loss_ce: 0.008587
2021-12-11 21:35:35,591 iteration 4769 : loss : 0.016490, loss_ce: 0.005677
2021-12-11 21:35:37,217 iteration 4770 : loss : 0.024392, loss_ce: 0.013628
2021-12-11 21:35:38,778 iteration 4771 : loss : 0.029540, loss_ce: 0.009526
2021-12-11 21:35:40,295 iteration 4772 : loss : 0.018730, loss_ce: 0.006662
2021-12-11 21:35:41,780 iteration 4773 : loss : 0.015822, loss_ce: 0.006812
2021-12-11 21:35:43,390 iteration 4774 : loss : 0.028119, loss_ce: 0.009467
2021-12-11 21:35:44,882 iteration 4775 : loss : 0.017026, loss_ce: 0.006260
2021-12-11 21:35:46,445 iteration 4776 : loss : 0.020105, loss_ce: 0.007206
2021-12-11 21:35:47,995 iteration 4777 : loss : 0.024467, loss_ce: 0.009549
 70%|████████████████████▎        | 281/400 [2:15:32<58:15, 29.37s/it]2021-12-11 21:35:49,638 iteration 4778 : loss : 0.019952, loss_ce: 0.009053
2021-12-11 21:35:51,157 iteration 4779 : loss : 0.015284, loss_ce: 0.005942
2021-12-11 21:35:52,672 iteration 4780 : loss : 0.019044, loss_ce: 0.007785
2021-12-11 21:35:54,276 iteration 4781 : loss : 0.019785, loss_ce: 0.006997
2021-12-11 21:35:55,887 iteration 4782 : loss : 0.024402, loss_ce: 0.009741
2021-12-11 21:35:57,439 iteration 4783 : loss : 0.019839, loss_ce: 0.007831
2021-12-11 21:35:59,074 iteration 4784 : loss : 0.021431, loss_ce: 0.006762
2021-12-11 21:36:00,634 iteration 4785 : loss : 0.016400, loss_ce: 0.005373
2021-12-11 21:36:02,185 iteration 4786 : loss : 0.013785, loss_ce: 0.005307
2021-12-11 21:36:03,730 iteration 4787 : loss : 0.044208, loss_ce: 0.013413
2021-12-11 21:36:05,323 iteration 4788 : loss : 0.020365, loss_ce: 0.005089
2021-12-11 21:36:06,766 iteration 4789 : loss : 0.015906, loss_ce: 0.005741
2021-12-11 21:36:08,212 iteration 4790 : loss : 0.014671, loss_ce: 0.005024
2021-12-11 21:36:09,786 iteration 4791 : loss : 0.030447, loss_ce: 0.013466
2021-12-11 21:36:11,365 iteration 4792 : loss : 0.020028, loss_ce: 0.008156
2021-12-11 21:36:13,003 iteration 4793 : loss : 0.023433, loss_ce: 0.008112
2021-12-11 21:36:14,543 iteration 4794 : loss : 0.017256, loss_ce: 0.004697
 70%|████████████████████▍        | 282/400 [2:15:59<56:06, 28.53s/it]2021-12-11 21:36:16,200 iteration 4795 : loss : 0.025978, loss_ce: 0.009200
2021-12-11 21:36:17,796 iteration 4796 : loss : 0.034354, loss_ce: 0.014393
2021-12-11 21:36:19,366 iteration 4797 : loss : 0.016586, loss_ce: 0.005721
2021-12-11 21:36:20,964 iteration 4798 : loss : 0.021998, loss_ce: 0.008119
2021-12-11 21:36:22,493 iteration 4799 : loss : 0.021591, loss_ce: 0.004653
2021-12-11 21:36:24,077 iteration 4800 : loss : 0.019874, loss_ce: 0.007352
2021-12-11 21:36:25,608 iteration 4801 : loss : 0.016039, loss_ce: 0.007061
2021-12-11 21:36:27,218 iteration 4802 : loss : 0.019772, loss_ce: 0.007564
2021-12-11 21:36:28,772 iteration 4803 : loss : 0.017240, loss_ce: 0.006402
2021-12-11 21:36:30,369 iteration 4804 : loss : 0.015189, loss_ce: 0.005541
2021-12-11 21:36:32,030 iteration 4805 : loss : 0.021391, loss_ce: 0.008414
2021-12-11 21:36:33,634 iteration 4806 : loss : 0.032982, loss_ce: 0.007072
2021-12-11 21:36:35,128 iteration 4807 : loss : 0.016336, loss_ce: 0.004891
2021-12-11 21:36:36,744 iteration 4808 : loss : 0.022390, loss_ce: 0.008082
2021-12-11 21:36:38,253 iteration 4809 : loss : 0.017532, loss_ce: 0.008346
2021-12-11 21:36:39,805 iteration 4810 : loss : 0.028484, loss_ce: 0.009068
2021-12-11 21:36:41,434 iteration 4811 : loss : 0.020668, loss_ce: 0.008203
 71%|████████████████████▌        | 283/400 [2:16:26<54:40, 28.04s/it]2021-12-11 21:36:43,052 iteration 4812 : loss : 0.020943, loss_ce: 0.006344
2021-12-11 21:36:44,569 iteration 4813 : loss : 0.016078, loss_ce: 0.005450
2021-12-11 21:36:46,285 iteration 4814 : loss : 0.025511, loss_ce: 0.009854
2021-12-11 21:36:47,832 iteration 4815 : loss : 0.016995, loss_ce: 0.005897
2021-12-11 21:36:49,340 iteration 4816 : loss : 0.016655, loss_ce: 0.005861
2021-12-11 21:36:50,840 iteration 4817 : loss : 0.015599, loss_ce: 0.005830
2021-12-11 21:36:52,356 iteration 4818 : loss : 0.030127, loss_ce: 0.009374
2021-12-11 21:36:53,934 iteration 4819 : loss : 0.023229, loss_ce: 0.006825
2021-12-11 21:36:55,441 iteration 4820 : loss : 0.018867, loss_ce: 0.008233
2021-12-11 21:36:57,003 iteration 4821 : loss : 0.020156, loss_ce: 0.006338
2021-12-11 21:36:58,624 iteration 4822 : loss : 0.028726, loss_ce: 0.011080
2021-12-11 21:37:00,197 iteration 4823 : loss : 0.027192, loss_ce: 0.006415
2021-12-11 21:37:01,726 iteration 4824 : loss : 0.020739, loss_ce: 0.005206
2021-12-11 21:37:03,348 iteration 4825 : loss : 0.023409, loss_ce: 0.012082
2021-12-11 21:37:05,113 iteration 4826 : loss : 0.021558, loss_ce: 0.009606
2021-12-11 21:37:06,639 iteration 4827 : loss : 0.018678, loss_ce: 0.009816
2021-12-11 21:37:08,145 iteration 4828 : loss : 0.015478, loss_ce: 0.005734
 71%|████████████████████▌        | 284/400 [2:16:52<53:25, 27.64s/it]2021-12-11 21:37:09,730 iteration 4829 : loss : 0.014864, loss_ce: 0.007200
2021-12-11 21:37:11,348 iteration 4830 : loss : 0.018852, loss_ce: 0.008308
2021-12-11 21:37:12,937 iteration 4831 : loss : 0.020159, loss_ce: 0.010493
2021-12-11 21:37:14,534 iteration 4832 : loss : 0.016386, loss_ce: 0.005562
2021-12-11 21:37:16,094 iteration 4833 : loss : 0.022784, loss_ce: 0.010284
2021-12-11 21:37:17,746 iteration 4834 : loss : 0.019728, loss_ce: 0.007115
2021-12-11 21:37:19,293 iteration 4835 : loss : 0.023263, loss_ce: 0.009850
2021-12-11 21:37:20,819 iteration 4836 : loss : 0.021041, loss_ce: 0.006089
2021-12-11 21:37:22,395 iteration 4837 : loss : 0.015089, loss_ce: 0.004198
2021-12-11 21:37:23,986 iteration 4838 : loss : 0.017697, loss_ce: 0.006506
2021-12-11 21:37:25,439 iteration 4839 : loss : 0.018327, loss_ce: 0.005915
2021-12-11 21:37:26,968 iteration 4840 : loss : 0.026920, loss_ce: 0.009285
2021-12-11 21:37:28,579 iteration 4841 : loss : 0.020160, loss_ce: 0.007585
2021-12-11 21:37:30,164 iteration 4842 : loss : 0.024483, loss_ce: 0.009177
2021-12-11 21:37:31,710 iteration 4843 : loss : 0.019043, loss_ce: 0.006804
2021-12-11 21:37:33,342 iteration 4844 : loss : 0.021611, loss_ce: 0.005970
2021-12-11 21:37:33,342 Training Data Eval:
2021-12-11 21:37:41,084   Average segmentation loss on training set: 0.0120
2021-12-11 21:37:41,085 Validation Data Eval:
2021-12-11 21:37:43,742   Average segmentation loss on validation set: 0.0804
2021-12-11 21:37:45,251 iteration 4845 : loss : 0.017572, loss_ce: 0.006258
 71%|████████████████████▋        | 285/400 [2:17:30<58:25, 30.48s/it]2021-12-11 21:37:46,864 iteration 4846 : loss : 0.020404, loss_ce: 0.007545
2021-12-11 21:37:48,363 iteration 4847 : loss : 0.014248, loss_ce: 0.004477
2021-12-11 21:37:50,026 iteration 4848 : loss : 0.021190, loss_ce: 0.009133
2021-12-11 21:37:51,552 iteration 4849 : loss : 0.015673, loss_ce: 0.005297
2021-12-11 21:37:53,023 iteration 4850 : loss : 0.016364, loss_ce: 0.007527
2021-12-11 21:37:54,692 iteration 4851 : loss : 0.028868, loss_ce: 0.012056
2021-12-11 21:37:56,239 iteration 4852 : loss : 0.019815, loss_ce: 0.009632
2021-12-11 21:37:57,843 iteration 4853 : loss : 0.019175, loss_ce: 0.004190
2021-12-11 21:37:59,565 iteration 4854 : loss : 0.024368, loss_ce: 0.008908
2021-12-11 21:38:01,147 iteration 4855 : loss : 0.021925, loss_ce: 0.007174
2021-12-11 21:38:02,629 iteration 4856 : loss : 0.014835, loss_ce: 0.004622
2021-12-11 21:38:04,254 iteration 4857 : loss : 0.020710, loss_ce: 0.010198
2021-12-11 21:38:05,862 iteration 4858 : loss : 0.024394, loss_ce: 0.009100
2021-12-11 21:38:07,421 iteration 4859 : loss : 0.016572, loss_ce: 0.006981
2021-12-11 21:38:09,020 iteration 4860 : loss : 0.030942, loss_ce: 0.011953
2021-12-11 21:38:10,583 iteration 4861 : loss : 0.017844, loss_ce: 0.006957
2021-12-11 21:38:12,076 iteration 4862 : loss : 0.016510, loss_ce: 0.006710
 72%|████████████████████▋        | 286/400 [2:17:56<55:49, 29.38s/it]2021-12-11 21:38:13,638 iteration 4863 : loss : 0.017977, loss_ce: 0.006427
2021-12-11 21:38:15,257 iteration 4864 : loss : 0.023078, loss_ce: 0.008092
2021-12-11 21:38:16,925 iteration 4865 : loss : 0.031681, loss_ce: 0.013057
2021-12-11 21:38:18,474 iteration 4866 : loss : 0.014711, loss_ce: 0.005715
2021-12-11 21:38:20,052 iteration 4867 : loss : 0.021462, loss_ce: 0.008736
2021-12-11 21:38:21,577 iteration 4868 : loss : 0.017365, loss_ce: 0.007974
2021-12-11 21:38:23,105 iteration 4869 : loss : 0.024363, loss_ce: 0.009822
2021-12-11 21:38:24,764 iteration 4870 : loss : 0.023882, loss_ce: 0.007889
2021-12-11 21:38:26,363 iteration 4871 : loss : 0.017862, loss_ce: 0.006869
2021-12-11 21:38:27,853 iteration 4872 : loss : 0.020243, loss_ce: 0.007760
2021-12-11 21:38:29,323 iteration 4873 : loss : 0.018536, loss_ce: 0.005629
2021-12-11 21:38:30,769 iteration 4874 : loss : 0.014874, loss_ce: 0.006177
2021-12-11 21:38:32,318 iteration 4875 : loss : 0.014554, loss_ce: 0.004475
2021-12-11 21:38:33,803 iteration 4876 : loss : 0.019701, loss_ce: 0.006201
2021-12-11 21:38:35,467 iteration 4877 : loss : 0.027649, loss_ce: 0.010783
2021-12-11 21:38:37,020 iteration 4878 : loss : 0.017445, loss_ce: 0.005710
2021-12-11 21:38:38,564 iteration 4879 : loss : 0.018944, loss_ce: 0.007539
 72%|████████████████████▊        | 287/400 [2:18:23<53:42, 28.51s/it]2021-12-11 21:38:40,267 iteration 4880 : loss : 0.024624, loss_ce: 0.012989
2021-12-11 21:38:41,803 iteration 4881 : loss : 0.023946, loss_ce: 0.007480
2021-12-11 21:38:43,357 iteration 4882 : loss : 0.016183, loss_ce: 0.004421
2021-12-11 21:38:44,925 iteration 4883 : loss : 0.023025, loss_ce: 0.006895
2021-12-11 21:38:46,504 iteration 4884 : loss : 0.015151, loss_ce: 0.008405
2021-12-11 21:38:48,216 iteration 4885 : loss : 0.020934, loss_ce: 0.005918
2021-12-11 21:38:49,844 iteration 4886 : loss : 0.020269, loss_ce: 0.006558
2021-12-11 21:38:51,536 iteration 4887 : loss : 0.025005, loss_ce: 0.009696
2021-12-11 21:38:53,096 iteration 4888 : loss : 0.019867, loss_ce: 0.005371
2021-12-11 21:38:54,640 iteration 4889 : loss : 0.014276, loss_ce: 0.004600
2021-12-11 21:38:56,279 iteration 4890 : loss : 0.025525, loss_ce: 0.010507
2021-12-11 21:38:57,915 iteration 4891 : loss : 0.023165, loss_ce: 0.012161
2021-12-11 21:38:59,408 iteration 4892 : loss : 0.019153, loss_ce: 0.007150
2021-12-11 21:39:00,928 iteration 4893 : loss : 0.017067, loss_ce: 0.007682
2021-12-11 21:39:02,480 iteration 4894 : loss : 0.020682, loss_ce: 0.005064
2021-12-11 21:39:03,996 iteration 4895 : loss : 0.018295, loss_ce: 0.006788
2021-12-11 21:39:05,594 iteration 4896 : loss : 0.020791, loss_ce: 0.007739
 72%|████████████████████▉        | 288/400 [2:18:50<52:23, 28.07s/it]2021-12-11 21:39:07,191 iteration 4897 : loss : 0.017894, loss_ce: 0.006004
2021-12-11 21:39:08,779 iteration 4898 : loss : 0.029619, loss_ce: 0.007904
2021-12-11 21:39:10,193 iteration 4899 : loss : 0.017584, loss_ce: 0.007123
2021-12-11 21:39:11,855 iteration 4900 : loss : 0.022740, loss_ce: 0.006722
2021-12-11 21:39:13,389 iteration 4901 : loss : 0.014612, loss_ce: 0.003571
2021-12-11 21:39:15,020 iteration 4902 : loss : 0.024502, loss_ce: 0.009149
2021-12-11 21:39:16,691 iteration 4903 : loss : 0.022568, loss_ce: 0.009168
2021-12-11 21:39:18,339 iteration 4904 : loss : 0.024186, loss_ce: 0.011600
2021-12-11 21:39:19,934 iteration 4905 : loss : 0.025372, loss_ce: 0.007291
2021-12-11 21:39:21,533 iteration 4906 : loss : 0.022320, loss_ce: 0.008755
2021-12-11 21:39:22,987 iteration 4907 : loss : 0.015967, loss_ce: 0.006197
2021-12-11 21:39:24,483 iteration 4908 : loss : 0.019897, loss_ce: 0.008357
2021-12-11 21:39:26,034 iteration 4909 : loss : 0.018900, loss_ce: 0.007602
2021-12-11 21:39:27,588 iteration 4910 : loss : 0.018622, loss_ce: 0.006393
2021-12-11 21:39:29,096 iteration 4911 : loss : 0.029272, loss_ce: 0.008913
2021-12-11 21:39:30,695 iteration 4912 : loss : 0.021331, loss_ce: 0.006786
2021-12-11 21:39:32,259 iteration 4913 : loss : 0.018580, loss_ce: 0.005611
 72%|████████████████████▉        | 289/400 [2:19:17<51:08, 27.65s/it]2021-12-11 21:39:33,811 iteration 4914 : loss : 0.023034, loss_ce: 0.009852
2021-12-11 21:39:35,379 iteration 4915 : loss : 0.016761, loss_ce: 0.007470
2021-12-11 21:39:36,998 iteration 4916 : loss : 0.032396, loss_ce: 0.010806
2021-12-11 21:39:38,574 iteration 4917 : loss : 0.015972, loss_ce: 0.005042
2021-12-11 21:39:40,150 iteration 4918 : loss : 0.022654, loss_ce: 0.010875
2021-12-11 21:39:41,701 iteration 4919 : loss : 0.018828, loss_ce: 0.009809
2021-12-11 21:39:43,342 iteration 4920 : loss : 0.024889, loss_ce: 0.009172
2021-12-11 21:39:44,834 iteration 4921 : loss : 0.017791, loss_ce: 0.006323
2021-12-11 21:39:46,436 iteration 4922 : loss : 0.017973, loss_ce: 0.006001
2021-12-11 21:39:48,008 iteration 4923 : loss : 0.026665, loss_ce: 0.011015
2021-12-11 21:39:49,592 iteration 4924 : loss : 0.021065, loss_ce: 0.009863
2021-12-11 21:39:51,129 iteration 4925 : loss : 0.021539, loss_ce: 0.007356
2021-12-11 21:39:52,577 iteration 4926 : loss : 0.015044, loss_ce: 0.007059
2021-12-11 21:39:54,133 iteration 4927 : loss : 0.013543, loss_ce: 0.004672
2021-12-11 21:39:55,723 iteration 4928 : loss : 0.018026, loss_ce: 0.007786
2021-12-11 21:39:57,228 iteration 4929 : loss : 0.030671, loss_ce: 0.009784
2021-12-11 21:39:57,228 Training Data Eval:
2021-12-11 21:40:04,975   Average segmentation loss on training set: 0.0128
2021-12-11 21:40:04,975 Validation Data Eval:
2021-12-11 21:40:07,631   Average segmentation loss on validation set: 0.0800
2021-12-11 21:40:09,195 iteration 4930 : loss : 0.023850, loss_ce: 0.007738
 72%|█████████████████████        | 290/400 [2:19:54<55:48, 30.44s/it]2021-12-11 21:40:10,864 iteration 4931 : loss : 0.019947, loss_ce: 0.009580
2021-12-11 21:40:12,472 iteration 4932 : loss : 0.020961, loss_ce: 0.006038
2021-12-11 21:40:13,975 iteration 4933 : loss : 0.017027, loss_ce: 0.006715
2021-12-11 21:40:15,539 iteration 4934 : loss : 0.017968, loss_ce: 0.005350
2021-12-11 21:40:17,075 iteration 4935 : loss : 0.016532, loss_ce: 0.003762
2021-12-11 21:40:18,666 iteration 4936 : loss : 0.016516, loss_ce: 0.005559
2021-12-11 21:40:20,186 iteration 4937 : loss : 0.016356, loss_ce: 0.005354
2021-12-11 21:40:21,685 iteration 4938 : loss : 0.017709, loss_ce: 0.006993
2021-12-11 21:40:23,359 iteration 4939 : loss : 0.029968, loss_ce: 0.016494
2021-12-11 21:40:24,871 iteration 4940 : loss : 0.019542, loss_ce: 0.007386
2021-12-11 21:40:26,432 iteration 4941 : loss : 0.023898, loss_ce: 0.009514
2021-12-11 21:40:28,189 iteration 4942 : loss : 0.018216, loss_ce: 0.007145
2021-12-11 21:40:29,727 iteration 4943 : loss : 0.020097, loss_ce: 0.009684
2021-12-11 21:40:31,249 iteration 4944 : loss : 0.019295, loss_ce: 0.009743
2021-12-11 21:40:32,811 iteration 4945 : loss : 0.014293, loss_ce: 0.004970
2021-12-11 21:40:34,288 iteration 4946 : loss : 0.022379, loss_ce: 0.007805
2021-12-11 21:40:35,919 iteration 4947 : loss : 0.023319, loss_ce: 0.008750
 73%|█████████████████████        | 291/400 [2:20:20<53:15, 29.32s/it]2021-12-11 21:40:37,573 iteration 4948 : loss : 0.023595, loss_ce: 0.008562
2021-12-11 21:40:39,267 iteration 4949 : loss : 0.020875, loss_ce: 0.008584
2021-12-11 21:40:40,781 iteration 4950 : loss : 0.018395, loss_ce: 0.009035
2021-12-11 21:40:42,327 iteration 4951 : loss : 0.021315, loss_ce: 0.007682
2021-12-11 21:40:43,887 iteration 4952 : loss : 0.022617, loss_ce: 0.008372
2021-12-11 21:40:45,545 iteration 4953 : loss : 0.022197, loss_ce: 0.006742
2021-12-11 21:40:47,010 iteration 4954 : loss : 0.019922, loss_ce: 0.006220
2021-12-11 21:40:48,517 iteration 4955 : loss : 0.017393, loss_ce: 0.008663
2021-12-11 21:40:50,122 iteration 4956 : loss : 0.024125, loss_ce: 0.007606
2021-12-11 21:40:51,694 iteration 4957 : loss : 0.017775, loss_ce: 0.007337
2021-12-11 21:40:53,441 iteration 4958 : loss : 0.025398, loss_ce: 0.010074
2021-12-11 21:40:55,108 iteration 4959 : loss : 0.031763, loss_ce: 0.014327
2021-12-11 21:40:56,820 iteration 4960 : loss : 0.018317, loss_ce: 0.008184
2021-12-11 21:40:58,366 iteration 4961 : loss : 0.025444, loss_ce: 0.005965
2021-12-11 21:40:59,934 iteration 4962 : loss : 0.019231, loss_ce: 0.008456
2021-12-11 21:41:01,557 iteration 4963 : loss : 0.020043, loss_ce: 0.007286
2021-12-11 21:41:03,167 iteration 4964 : loss : 0.020677, loss_ce: 0.006791
 73%|█████████████████████▏       | 292/400 [2:20:47<51:39, 28.70s/it]2021-12-11 21:41:04,772 iteration 4965 : loss : 0.021996, loss_ce: 0.007246
2021-12-11 21:41:06,337 iteration 4966 : loss : 0.015194, loss_ce: 0.005283
2021-12-11 21:41:07,911 iteration 4967 : loss : 0.022117, loss_ce: 0.005868
2021-12-11 21:41:09,433 iteration 4968 : loss : 0.031723, loss_ce: 0.005901
2021-12-11 21:41:11,024 iteration 4969 : loss : 0.026171, loss_ce: 0.009260
2021-12-11 21:41:12,641 iteration 4970 : loss : 0.021152, loss_ce: 0.011194
2021-12-11 21:41:14,188 iteration 4971 : loss : 0.019576, loss_ce: 0.007416
2021-12-11 21:41:15,687 iteration 4972 : loss : 0.020738, loss_ce: 0.006552
2021-12-11 21:41:17,229 iteration 4973 : loss : 0.013819, loss_ce: 0.004552
2021-12-11 21:41:18,827 iteration 4974 : loss : 0.018184, loss_ce: 0.008599
2021-12-11 21:41:20,507 iteration 4975 : loss : 0.016222, loss_ce: 0.005867
2021-12-11 21:41:22,042 iteration 4976 : loss : 0.020132, loss_ce: 0.006832
2021-12-11 21:41:23,594 iteration 4977 : loss : 0.017307, loss_ce: 0.006394
2021-12-11 21:41:25,175 iteration 4978 : loss : 0.017798, loss_ce: 0.007387
2021-12-11 21:41:26,700 iteration 4979 : loss : 0.017261, loss_ce: 0.006097
2021-12-11 21:41:28,195 iteration 4980 : loss : 0.013041, loss_ce: 0.004393
2021-12-11 21:41:29,741 iteration 4981 : loss : 0.019088, loss_ce: 0.006991
 73%|█████████████████████▏       | 293/400 [2:21:14<50:02, 28.06s/it]2021-12-11 21:41:31,401 iteration 4982 : loss : 0.034240, loss_ce: 0.007396
2021-12-11 21:41:32,877 iteration 4983 : loss : 0.017795, loss_ce: 0.005538
2021-12-11 21:41:34,457 iteration 4984 : loss : 0.016794, loss_ce: 0.003930
2021-12-11 21:41:35,934 iteration 4985 : loss : 0.014876, loss_ce: 0.004629
2021-12-11 21:41:37,454 iteration 4986 : loss : 0.020679, loss_ce: 0.006293
2021-12-11 21:41:39,023 iteration 4987 : loss : 0.018099, loss_ce: 0.007806
2021-12-11 21:41:40,614 iteration 4988 : loss : 0.022688, loss_ce: 0.011253
2021-12-11 21:41:42,152 iteration 4989 : loss : 0.020810, loss_ce: 0.008308
2021-12-11 21:41:43,755 iteration 4990 : loss : 0.018673, loss_ce: 0.008062
2021-12-11 21:41:45,296 iteration 4991 : loss : 0.019107, loss_ce: 0.005849
2021-12-11 21:41:46,872 iteration 4992 : loss : 0.019709, loss_ce: 0.006479
2021-12-11 21:41:48,439 iteration 4993 : loss : 0.019255, loss_ce: 0.009431
2021-12-11 21:41:50,161 iteration 4994 : loss : 0.021979, loss_ce: 0.009258
2021-12-11 21:41:51,800 iteration 4995 : loss : 0.023870, loss_ce: 0.010860
2021-12-11 21:41:53,324 iteration 4996 : loss : 0.017573, loss_ce: 0.005081
2021-12-11 21:41:54,919 iteration 4997 : loss : 0.019921, loss_ce: 0.007179
2021-12-11 21:41:56,506 iteration 4998 : loss : 0.021381, loss_ce: 0.008265
 74%|█████████████████████▎       | 294/400 [2:21:41<48:53, 27.68s/it]2021-12-11 21:41:58,144 iteration 4999 : loss : 0.023233, loss_ce: 0.009600
2021-12-11 21:41:59,641 iteration 5000 : loss : 0.017037, loss_ce: 0.005248
2021-12-11 21:42:01,240 iteration 5001 : loss : 0.022095, loss_ce: 0.005626
2021-12-11 21:42:02,901 iteration 5002 : loss : 0.021449, loss_ce: 0.006456
2021-12-11 21:42:04,596 iteration 5003 : loss : 0.023185, loss_ce: 0.009885
2021-12-11 21:42:06,154 iteration 5004 : loss : 0.016372, loss_ce: 0.006976
2021-12-11 21:42:07,752 iteration 5005 : loss : 0.019492, loss_ce: 0.008220
2021-12-11 21:42:09,255 iteration 5006 : loss : 0.015106, loss_ce: 0.005545
2021-12-11 21:42:10,846 iteration 5007 : loss : 0.019456, loss_ce: 0.004012
2021-12-11 21:42:12,359 iteration 5008 : loss : 0.018777, loss_ce: 0.006036
2021-12-11 21:42:13,856 iteration 5009 : loss : 0.019350, loss_ce: 0.009697
2021-12-11 21:42:15,464 iteration 5010 : loss : 0.016617, loss_ce: 0.007037
2021-12-11 21:42:16,976 iteration 5011 : loss : 0.015257, loss_ce: 0.006076
2021-12-11 21:42:18,514 iteration 5012 : loss : 0.023643, loss_ce: 0.005873
2021-12-11 21:42:20,172 iteration 5013 : loss : 0.021713, loss_ce: 0.009691
2021-12-11 21:42:21,650 iteration 5014 : loss : 0.019916, loss_ce: 0.006787
2021-12-11 21:42:21,650 Training Data Eval:
2021-12-11 21:42:29,397   Average segmentation loss on training set: 0.0124
2021-12-11 21:42:29,397 Validation Data Eval:
2021-12-11 21:42:32,052   Average segmentation loss on validation set: 0.0903
2021-12-11 21:42:33,595 iteration 5015 : loss : 0.022783, loss_ce: 0.007035
 74%|█████████████████████▍       | 295/400 [2:22:18<53:22, 30.50s/it]2021-12-11 21:42:35,251 iteration 5016 : loss : 0.021478, loss_ce: 0.009620
2021-12-11 21:42:36,712 iteration 5017 : loss : 0.013173, loss_ce: 0.004858
2021-12-11 21:42:38,394 iteration 5018 : loss : 0.018275, loss_ce: 0.007975
2021-12-11 21:42:39,879 iteration 5019 : loss : 0.016373, loss_ce: 0.005622
2021-12-11 21:42:41,504 iteration 5020 : loss : 0.024741, loss_ce: 0.008597
2021-12-11 21:42:43,058 iteration 5021 : loss : 0.022407, loss_ce: 0.008322
2021-12-11 21:42:44,605 iteration 5022 : loss : 0.016660, loss_ce: 0.004693
2021-12-11 21:42:46,165 iteration 5023 : loss : 0.021800, loss_ce: 0.011359
2021-12-11 21:42:47,804 iteration 5024 : loss : 0.021337, loss_ce: 0.007168
2021-12-11 21:42:49,392 iteration 5025 : loss : 0.019704, loss_ce: 0.007484
2021-12-11 21:42:51,023 iteration 5026 : loss : 0.019032, loss_ce: 0.007711
2021-12-11 21:42:52,539 iteration 5027 : loss : 0.014048, loss_ce: 0.004851
2021-12-11 21:42:54,021 iteration 5028 : loss : 0.015589, loss_ce: 0.006228
2021-12-11 21:42:55,661 iteration 5029 : loss : 0.022833, loss_ce: 0.010269
2021-12-11 21:42:57,193 iteration 5030 : loss : 0.018197, loss_ce: 0.008026
2021-12-11 21:42:58,804 iteration 5031 : loss : 0.036311, loss_ce: 0.012971
2021-12-11 21:43:00,279 iteration 5032 : loss : 0.013684, loss_ce: 0.004446
 74%|█████████████████████▍       | 296/400 [2:22:45<50:52, 29.35s/it]2021-12-11 21:43:01,822 iteration 5033 : loss : 0.019859, loss_ce: 0.007044
2021-12-11 21:43:03,323 iteration 5034 : loss : 0.023282, loss_ce: 0.007596
2021-12-11 21:43:04,871 iteration 5035 : loss : 0.018561, loss_ce: 0.006255
2021-12-11 21:43:06,377 iteration 5036 : loss : 0.016718, loss_ce: 0.006414
2021-12-11 21:43:07,918 iteration 5037 : loss : 0.025261, loss_ce: 0.008095
2021-12-11 21:43:09,438 iteration 5038 : loss : 0.019103, loss_ce: 0.006114
2021-12-11 21:43:11,010 iteration 5039 : loss : 0.019067, loss_ce: 0.006948
2021-12-11 21:43:12,615 iteration 5040 : loss : 0.015567, loss_ce: 0.005345
2021-12-11 21:43:14,160 iteration 5041 : loss : 0.017312, loss_ce: 0.006856
2021-12-11 21:43:15,835 iteration 5042 : loss : 0.027752, loss_ce: 0.008893
2021-12-11 21:43:17,297 iteration 5043 : loss : 0.016780, loss_ce: 0.005488
2021-12-11 21:43:18,909 iteration 5044 : loss : 0.013987, loss_ce: 0.004697
2021-12-11 21:43:20,498 iteration 5045 : loss : 0.021845, loss_ce: 0.009448
2021-12-11 21:43:22,074 iteration 5046 : loss : 0.029986, loss_ce: 0.007753
2021-12-11 21:43:23,557 iteration 5047 : loss : 0.014443, loss_ce: 0.004174
2021-12-11 21:43:25,039 iteration 5048 : loss : 0.014712, loss_ce: 0.006860
2021-12-11 21:43:26,498 iteration 5049 : loss : 0.013500, loss_ce: 0.005460
 74%|█████████████████████▌       | 297/400 [2:23:11<48:46, 28.41s/it]2021-12-11 21:43:28,133 iteration 5050 : loss : 0.015622, loss_ce: 0.004590
2021-12-11 21:43:29,761 iteration 5051 : loss : 0.027993, loss_ce: 0.008894
2021-12-11 21:43:31,425 iteration 5052 : loss : 0.024837, loss_ce: 0.010018
2021-12-11 21:43:33,075 iteration 5053 : loss : 0.032726, loss_ce: 0.010075
2021-12-11 21:43:34,608 iteration 5054 : loss : 0.024488, loss_ce: 0.006389
2021-12-11 21:43:36,180 iteration 5055 : loss : 0.017215, loss_ce: 0.005816
2021-12-11 21:43:37,763 iteration 5056 : loss : 0.016175, loss_ce: 0.006088
2021-12-11 21:43:39,422 iteration 5057 : loss : 0.019937, loss_ce: 0.008223
2021-12-11 21:43:41,074 iteration 5058 : loss : 0.023062, loss_ce: 0.008376
2021-12-11 21:43:42,626 iteration 5059 : loss : 0.018053, loss_ce: 0.006628
2021-12-11 21:43:44,242 iteration 5060 : loss : 0.021744, loss_ce: 0.010011
2021-12-11 21:43:45,877 iteration 5061 : loss : 0.022026, loss_ce: 0.008405
2021-12-11 21:43:47,559 iteration 5062 : loss : 0.020284, loss_ce: 0.007395
2021-12-11 21:43:49,228 iteration 5063 : loss : 0.028646, loss_ce: 0.012153
2021-12-11 21:43:50,781 iteration 5064 : loss : 0.027453, loss_ce: 0.008671
2021-12-11 21:43:52,421 iteration 5065 : loss : 0.014820, loss_ce: 0.006745
2021-12-11 21:43:53,929 iteration 5066 : loss : 0.017624, loss_ce: 0.006731
 74%|█████████████████████▌       | 298/400 [2:23:38<47:47, 28.12s/it]2021-12-11 21:43:55,412 iteration 5067 : loss : 0.017495, loss_ce: 0.006033
2021-12-11 21:43:57,018 iteration 5068 : loss : 0.015856, loss_ce: 0.004616
2021-12-11 21:43:58,604 iteration 5069 : loss : 0.016470, loss_ce: 0.008087
2021-12-11 21:44:00,100 iteration 5070 : loss : 0.020629, loss_ce: 0.006796
2021-12-11 21:44:01,706 iteration 5071 : loss : 0.031140, loss_ce: 0.012803
2021-12-11 21:44:03,185 iteration 5072 : loss : 0.016443, loss_ce: 0.005793
2021-12-11 21:44:04,818 iteration 5073 : loss : 0.019631, loss_ce: 0.007959
2021-12-11 21:44:06,346 iteration 5074 : loss : 0.016527, loss_ce: 0.006570
2021-12-11 21:44:07,880 iteration 5075 : loss : 0.020490, loss_ce: 0.007463
2021-12-11 21:44:09,462 iteration 5076 : loss : 0.026317, loss_ce: 0.006343
2021-12-11 21:44:11,039 iteration 5077 : loss : 0.029110, loss_ce: 0.009209
2021-12-11 21:44:12,548 iteration 5078 : loss : 0.020359, loss_ce: 0.009923
2021-12-11 21:44:14,036 iteration 5079 : loss : 0.016360, loss_ce: 0.006963
2021-12-11 21:44:15,560 iteration 5080 : loss : 0.016444, loss_ce: 0.006266
2021-12-11 21:44:17,161 iteration 5081 : loss : 0.021961, loss_ce: 0.006356
2021-12-11 21:44:18,703 iteration 5082 : loss : 0.014581, loss_ce: 0.005760
2021-12-11 21:44:20,281 iteration 5083 : loss : 0.022708, loss_ce: 0.005059
 75%|█████████████████████▋       | 299/400 [2:24:05<46:26, 27.59s/it]2021-12-11 21:44:21,945 iteration 5084 : loss : 0.017437, loss_ce: 0.008410
2021-12-11 21:44:23,642 iteration 5085 : loss : 0.023207, loss_ce: 0.008141
2021-12-11 21:44:25,253 iteration 5086 : loss : 0.016554, loss_ce: 0.004846
2021-12-11 21:44:26,755 iteration 5087 : loss : 0.018425, loss_ce: 0.007585
2021-12-11 21:44:28,257 iteration 5088 : loss : 0.022476, loss_ce: 0.009326
2021-12-11 21:44:29,839 iteration 5089 : loss : 0.022769, loss_ce: 0.005653
2021-12-11 21:44:31,415 iteration 5090 : loss : 0.014166, loss_ce: 0.003066
2021-12-11 21:44:33,052 iteration 5091 : loss : 0.025233, loss_ce: 0.008037
2021-12-11 21:44:34,642 iteration 5092 : loss : 0.024079, loss_ce: 0.008752
2021-12-11 21:44:36,149 iteration 5093 : loss : 0.016374, loss_ce: 0.004817
2021-12-11 21:44:37,747 iteration 5094 : loss : 0.025616, loss_ce: 0.008703
2021-12-11 21:44:39,244 iteration 5095 : loss : 0.017849, loss_ce: 0.007425
2021-12-11 21:44:40,791 iteration 5096 : loss : 0.018857, loss_ce: 0.008211
2021-12-11 21:44:42,272 iteration 5097 : loss : 0.025405, loss_ce: 0.012302
2021-12-11 21:44:43,919 iteration 5098 : loss : 0.020506, loss_ce: 0.006816
2021-12-11 21:44:45,516 iteration 5099 : loss : 0.024734, loss_ce: 0.006682
2021-12-11 21:44:45,517 Training Data Eval:
2021-12-11 21:44:53,249   Average segmentation loss on training set: 0.0116
2021-12-11 21:44:53,249 Validation Data Eval:
2021-12-11 21:44:55,905   Average segmentation loss on validation set: 0.0822
2021-12-11 21:44:57,535 iteration 5100 : loss : 0.021989, loss_ce: 0.005698
2021-12-11 21:44:59,505 save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/NEW_TU/UNET_ADAM_seed2epoch_299.pth
 75%|█████████████████████▊       | 300/400 [2:24:44<51:46, 31.06s/it]2021-12-11 21:45:01,204 iteration 5101 : loss : 0.025691, loss_ce: 0.010262
2021-12-11 21:45:02,759 iteration 5102 : loss : 0.018979, loss_ce: 0.006456
2021-12-11 21:45:04,340 iteration 5103 : loss : 0.016934, loss_ce: 0.008537
2021-12-11 21:45:05,977 iteration 5104 : loss : 0.023537, loss_ce: 0.006799
2021-12-11 21:45:07,502 iteration 5105 : loss : 0.016033, loss_ce: 0.006007
2021-12-11 21:45:09,042 iteration 5106 : loss : 0.017822, loss_ce: 0.006042
2021-12-11 21:45:10,680 iteration 5107 : loss : 0.026634, loss_ce: 0.007679
2021-12-11 21:45:12,274 iteration 5108 : loss : 0.019067, loss_ce: 0.009118
2021-12-11 21:45:13,846 iteration 5109 : loss : 0.023944, loss_ce: 0.009509
2021-12-11 21:45:15,365 iteration 5110 : loss : 0.014451, loss_ce: 0.004725
2021-12-11 21:45:16,956 iteration 5111 : loss : 0.021626, loss_ce: 0.007724
2021-12-11 21:45:18,642 iteration 5112 : loss : 0.027517, loss_ce: 0.009141
2021-12-11 21:45:20,248 iteration 5113 : loss : 0.018696, loss_ce: 0.005885
2021-12-11 21:45:21,900 iteration 5114 : loss : 0.021481, loss_ce: 0.007738
2021-12-11 21:45:23,469 iteration 5115 : loss : 0.024168, loss_ce: 0.007100
2021-12-11 21:45:25,008 iteration 5116 : loss : 0.029455, loss_ce: 0.010265
2021-12-11 21:45:26,615 iteration 5117 : loss : 0.020419, loss_ce: 0.008272
 75%|█████████████████████▊       | 301/400 [2:25:11<49:19, 29.90s/it]2021-12-11 21:45:28,284 iteration 5118 : loss : 0.027925, loss_ce: 0.007605
2021-12-11 21:45:29,835 iteration 5119 : loss : 0.021191, loss_ce: 0.008896
2021-12-11 21:45:31,333 iteration 5120 : loss : 0.013452, loss_ce: 0.005178
2021-12-11 21:45:32,954 iteration 5121 : loss : 0.017583, loss_ce: 0.004957
2021-12-11 21:45:34,630 iteration 5122 : loss : 0.020626, loss_ce: 0.009344
2021-12-11 21:45:36,292 iteration 5123 : loss : 0.029475, loss_ce: 0.009335
2021-12-11 21:45:37,798 iteration 5124 : loss : 0.014225, loss_ce: 0.006835
2021-12-11 21:45:39,298 iteration 5125 : loss : 0.016697, loss_ce: 0.005701
2021-12-11 21:45:40,879 iteration 5126 : loss : 0.022835, loss_ce: 0.008425
2021-12-11 21:45:42,423 iteration 5127 : loss : 0.021575, loss_ce: 0.008885
2021-12-11 21:45:43,934 iteration 5128 : loss : 0.014712, loss_ce: 0.004301
2021-12-11 21:45:45,510 iteration 5129 : loss : 0.018884, loss_ce: 0.008297
2021-12-11 21:45:47,065 iteration 5130 : loss : 0.021820, loss_ce: 0.009536
2021-12-11 21:45:48,656 iteration 5131 : loss : 0.015914, loss_ce: 0.005726
2021-12-11 21:45:50,222 iteration 5132 : loss : 0.019673, loss_ce: 0.007313
2021-12-11 21:45:51,860 iteration 5133 : loss : 0.033692, loss_ce: 0.011416
2021-12-11 21:45:53,412 iteration 5134 : loss : 0.021425, loss_ce: 0.005359
 76%|█████████████████████▉       | 302/400 [2:25:38<47:18, 28.96s/it]2021-12-11 21:45:55,020 iteration 5135 : loss : 0.018157, loss_ce: 0.008776
2021-12-11 21:45:56,579 iteration 5136 : loss : 0.013688, loss_ce: 0.004111
2021-12-11 21:45:58,076 iteration 5137 : loss : 0.019319, loss_ce: 0.006899
2021-12-11 21:45:59,673 iteration 5138 : loss : 0.015279, loss_ce: 0.006613
2021-12-11 21:46:01,355 iteration 5139 : loss : 0.023875, loss_ce: 0.008380
2021-12-11 21:46:02,999 iteration 5140 : loss : 0.026764, loss_ce: 0.009061
2021-12-11 21:46:04,516 iteration 5141 : loss : 0.033058, loss_ce: 0.010309
2021-12-11 21:46:06,107 iteration 5142 : loss : 0.019673, loss_ce: 0.006783
2021-12-11 21:46:07,658 iteration 5143 : loss : 0.015515, loss_ce: 0.007442
2021-12-11 21:46:09,315 iteration 5144 : loss : 0.022272, loss_ce: 0.009726
2021-12-11 21:46:11,035 iteration 5145 : loss : 0.014014, loss_ce: 0.003774
2021-12-11 21:46:12,650 iteration 5146 : loss : 0.018301, loss_ce: 0.006128
2021-12-11 21:46:14,149 iteration 5147 : loss : 0.019216, loss_ce: 0.004426
2021-12-11 21:46:15,710 iteration 5148 : loss : 0.020690, loss_ce: 0.007318
2021-12-11 21:46:17,245 iteration 5149 : loss : 0.020053, loss_ce: 0.007906
2021-12-11 21:46:18,787 iteration 5150 : loss : 0.019529, loss_ce: 0.010294
2021-12-11 21:46:20,400 iteration 5151 : loss : 0.025038, loss_ce: 0.013026
 76%|█████████████████████▉       | 303/400 [2:26:05<45:53, 28.39s/it]2021-12-11 21:46:22,050 iteration 5152 : loss : 0.019572, loss_ce: 0.007879
2021-12-11 21:46:23,621 iteration 5153 : loss : 0.019292, loss_ce: 0.007006
2021-12-11 21:46:25,100 iteration 5154 : loss : 0.015813, loss_ce: 0.005183
2021-12-11 21:46:26,604 iteration 5155 : loss : 0.014408, loss_ce: 0.004869
2021-12-11 21:46:28,151 iteration 5156 : loss : 0.023264, loss_ce: 0.005457
2021-12-11 21:46:29,647 iteration 5157 : loss : 0.012474, loss_ce: 0.004823
2021-12-11 21:46:31,162 iteration 5158 : loss : 0.014628, loss_ce: 0.005064
2021-12-11 21:46:32,742 iteration 5159 : loss : 0.024264, loss_ce: 0.008586
2021-12-11 21:46:34,324 iteration 5160 : loss : 0.019232, loss_ce: 0.008291
2021-12-11 21:46:35,918 iteration 5161 : loss : 0.019739, loss_ce: 0.007426
2021-12-11 21:46:37,577 iteration 5162 : loss : 0.014575, loss_ce: 0.003802
2021-12-11 21:46:39,175 iteration 5163 : loss : 0.017998, loss_ce: 0.009551
2021-12-11 21:46:40,704 iteration 5164 : loss : 0.017652, loss_ce: 0.006036
2021-12-11 21:46:42,357 iteration 5165 : loss : 0.019035, loss_ce: 0.005837
2021-12-11 21:46:43,942 iteration 5166 : loss : 0.018242, loss_ce: 0.006439
2021-12-11 21:46:45,557 iteration 5167 : loss : 0.036636, loss_ce: 0.009317
2021-12-11 21:46:47,022 iteration 5168 : loss : 0.014492, loss_ce: 0.006866
 76%|██████████████████████       | 304/400 [2:26:31<44:32, 27.84s/it]2021-12-11 21:46:48,697 iteration 5169 : loss : 0.019630, loss_ce: 0.005786
2021-12-11 21:46:50,237 iteration 5170 : loss : 0.015191, loss_ce: 0.007162
2021-12-11 21:46:51,805 iteration 5171 : loss : 0.024849, loss_ce: 0.007120
2021-12-11 21:46:53,388 iteration 5172 : loss : 0.019273, loss_ce: 0.007052
2021-12-11 21:46:55,048 iteration 5173 : loss : 0.027151, loss_ce: 0.009932
2021-12-11 21:46:56,629 iteration 5174 : loss : 0.011439, loss_ce: 0.003113
2021-12-11 21:46:58,240 iteration 5175 : loss : 0.018441, loss_ce: 0.006347
2021-12-11 21:46:59,907 iteration 5176 : loss : 0.021132, loss_ce: 0.007177
2021-12-11 21:47:01,490 iteration 5177 : loss : 0.018759, loss_ce: 0.007587
2021-12-11 21:47:03,081 iteration 5178 : loss : 0.013802, loss_ce: 0.005796
2021-12-11 21:47:04,615 iteration 5179 : loss : 0.016923, loss_ce: 0.007743
2021-12-11 21:47:06,102 iteration 5180 : loss : 0.014771, loss_ce: 0.006011
2021-12-11 21:47:07,601 iteration 5181 : loss : 0.025939, loss_ce: 0.009279
2021-12-11 21:47:09,151 iteration 5182 : loss : 0.022788, loss_ce: 0.009891
2021-12-11 21:47:10,696 iteration 5183 : loss : 0.018052, loss_ce: 0.006273
2021-12-11 21:47:12,208 iteration 5184 : loss : 0.016533, loss_ce: 0.007874
2021-12-11 21:47:12,208 Training Data Eval:
2021-12-11 21:47:19,958   Average segmentation loss on training set: 0.0111
2021-12-11 21:47:19,958 Validation Data Eval:
2021-12-11 21:47:22,617   Average segmentation loss on validation set: 0.0835
2021-12-11 21:47:24,152 iteration 5185 : loss : 0.013568, loss_ce: 0.005174
 76%|██████████████████████       | 305/400 [2:27:08<48:29, 30.63s/it]2021-12-11 21:47:25,833 iteration 5186 : loss : 0.025461, loss_ce: 0.007176
2021-12-11 21:47:27,327 iteration 5187 : loss : 0.014922, loss_ce: 0.005929
2021-12-11 21:47:28,890 iteration 5188 : loss : 0.015084, loss_ce: 0.004624
2021-12-11 21:47:30,471 iteration 5189 : loss : 0.039990, loss_ce: 0.015603
2021-12-11 21:47:32,154 iteration 5190 : loss : 0.021851, loss_ce: 0.006656
2021-12-11 21:47:33,693 iteration 5191 : loss : 0.016827, loss_ce: 0.006044
2021-12-11 21:47:35,261 iteration 5192 : loss : 0.019298, loss_ce: 0.008065
2021-12-11 21:47:36,877 iteration 5193 : loss : 0.017069, loss_ce: 0.007631
2021-12-11 21:47:38,483 iteration 5194 : loss : 0.023869, loss_ce: 0.006636
2021-12-11 21:47:40,046 iteration 5195 : loss : 0.026051, loss_ce: 0.008529
2021-12-11 21:47:41,742 iteration 5196 : loss : 0.025269, loss_ce: 0.008648
2021-12-11 21:47:43,299 iteration 5197 : loss : 0.016738, loss_ce: 0.005061
2021-12-11 21:47:44,818 iteration 5198 : loss : 0.020068, loss_ce: 0.012288
2021-12-11 21:47:46,525 iteration 5199 : loss : 0.019645, loss_ce: 0.007547
2021-12-11 21:47:48,015 iteration 5200 : loss : 0.018216, loss_ce: 0.007551
2021-12-11 21:47:49,504 iteration 5201 : loss : 0.015861, loss_ce: 0.006734
2021-12-11 21:47:51,046 iteration 5202 : loss : 0.022110, loss_ce: 0.007875
 76%|██████████████████████▏      | 306/400 [2:27:35<46:13, 29.51s/it]2021-12-11 21:47:52,652 iteration 5203 : loss : 0.019526, loss_ce: 0.007848
2021-12-11 21:47:54,288 iteration 5204 : loss : 0.015475, loss_ce: 0.006079
2021-12-11 21:47:55,903 iteration 5205 : loss : 0.030690, loss_ce: 0.008576
2021-12-11 21:47:57,635 iteration 5206 : loss : 0.026480, loss_ce: 0.009568
2021-12-11 21:47:59,275 iteration 5207 : loss : 0.039612, loss_ce: 0.010868
2021-12-11 21:48:00,858 iteration 5208 : loss : 0.015525, loss_ce: 0.005881
2021-12-11 21:48:02,493 iteration 5209 : loss : 0.020133, loss_ce: 0.007920
2021-12-11 21:48:04,125 iteration 5210 : loss : 0.022967, loss_ce: 0.011132
2021-12-11 21:48:05,690 iteration 5211 : loss : 0.019339, loss_ce: 0.006253
2021-12-11 21:48:07,332 iteration 5212 : loss : 0.029707, loss_ce: 0.008704
2021-12-11 21:48:08,888 iteration 5213 : loss : 0.021077, loss_ce: 0.009456
2021-12-11 21:48:10,453 iteration 5214 : loss : 0.018650, loss_ce: 0.008509
2021-12-11 21:48:11,918 iteration 5215 : loss : 0.013229, loss_ce: 0.004417
2021-12-11 21:48:13,447 iteration 5216 : loss : 0.017200, loss_ce: 0.005638
2021-12-11 21:48:15,090 iteration 5217 : loss : 0.024416, loss_ce: 0.011560
2021-12-11 21:48:16,599 iteration 5218 : loss : 0.013870, loss_ce: 0.004452
2021-12-11 21:48:18,172 iteration 5219 : loss : 0.025744, loss_ce: 0.009253
 77%|██████████████████████▎      | 307/400 [2:28:03<44:37, 28.80s/it]2021-12-11 21:48:19,703 iteration 5220 : loss : 0.014132, loss_ce: 0.005671
2021-12-11 21:48:21,194 iteration 5221 : loss : 0.024919, loss_ce: 0.006764
2021-12-11 21:48:22,803 iteration 5222 : loss : 0.019431, loss_ce: 0.005602
2021-12-11 21:48:24,353 iteration 5223 : loss : 0.014831, loss_ce: 0.006511
2021-12-11 21:48:26,008 iteration 5224 : loss : 0.021314, loss_ce: 0.004778
2021-12-11 21:48:27,542 iteration 5225 : loss : 0.014341, loss_ce: 0.005990
2021-12-11 21:48:29,126 iteration 5226 : loss : 0.016711, loss_ce: 0.007262
2021-12-11 21:48:30,717 iteration 5227 : loss : 0.022697, loss_ce: 0.007819
2021-12-11 21:48:32,192 iteration 5228 : loss : 0.012462, loss_ce: 0.003697
2021-12-11 21:48:33,793 iteration 5229 : loss : 0.022116, loss_ce: 0.008201
2021-12-11 21:48:35,291 iteration 5230 : loss : 0.014127, loss_ce: 0.005240
2021-12-11 21:48:36,861 iteration 5231 : loss : 0.018495, loss_ce: 0.005545
2021-12-11 21:48:38,523 iteration 5232 : loss : 0.021260, loss_ce: 0.007539
2021-12-11 21:48:39,957 iteration 5233 : loss : 0.015498, loss_ce: 0.006381
2021-12-11 21:48:41,519 iteration 5234 : loss : 0.020815, loss_ce: 0.008442
2021-12-11 21:48:43,126 iteration 5235 : loss : 0.022286, loss_ce: 0.010148
2021-12-11 21:48:44,800 iteration 5236 : loss : 0.026897, loss_ce: 0.010890
 77%|██████████████████████▎      | 308/400 [2:28:29<43:09, 28.14s/it]2021-12-11 21:48:46,329 iteration 5237 : loss : 0.013227, loss_ce: 0.005902
2021-12-11 21:48:47,883 iteration 5238 : loss : 0.017832, loss_ce: 0.007675
2021-12-11 21:48:49,427 iteration 5239 : loss : 0.019497, loss_ce: 0.007348
2021-12-11 21:48:51,061 iteration 5240 : loss : 0.043592, loss_ce: 0.008069
2021-12-11 21:48:52,644 iteration 5241 : loss : 0.022171, loss_ce: 0.008609
2021-12-11 21:48:54,346 iteration 5242 : loss : 0.024264, loss_ce: 0.011114
2021-12-11 21:48:55,962 iteration 5243 : loss : 0.019036, loss_ce: 0.008769
2021-12-11 21:48:57,513 iteration 5244 : loss : 0.018566, loss_ce: 0.006347
2021-12-11 21:48:59,154 iteration 5245 : loss : 0.022128, loss_ce: 0.006182
2021-12-11 21:49:00,754 iteration 5246 : loss : 0.021990, loss_ce: 0.007912
2021-12-11 21:49:02,303 iteration 5247 : loss : 0.016245, loss_ce: 0.005472
2021-12-11 21:49:03,941 iteration 5248 : loss : 0.022575, loss_ce: 0.009863
2021-12-11 21:49:05,487 iteration 5249 : loss : 0.018947, loss_ce: 0.006624
2021-12-11 21:49:07,055 iteration 5250 : loss : 0.019948, loss_ce: 0.006944
2021-12-11 21:49:08,688 iteration 5251 : loss : 0.016122, loss_ce: 0.006255
2021-12-11 21:49:10,231 iteration 5252 : loss : 0.013919, loss_ce: 0.006378
2021-12-11 21:49:11,768 iteration 5253 : loss : 0.015033, loss_ce: 0.005127
 77%|██████████████████████▍      | 309/400 [2:28:56<42:08, 27.79s/it]2021-12-11 21:49:13,377 iteration 5254 : loss : 0.019904, loss_ce: 0.009028
2021-12-11 21:49:15,003 iteration 5255 : loss : 0.020111, loss_ce: 0.006132
2021-12-11 21:49:16,582 iteration 5256 : loss : 0.024759, loss_ce: 0.010476
2021-12-11 21:49:18,183 iteration 5257 : loss : 0.019384, loss_ce: 0.006535
2021-12-11 21:49:19,667 iteration 5258 : loss : 0.015057, loss_ce: 0.005733
2021-12-11 21:49:21,205 iteration 5259 : loss : 0.023189, loss_ce: 0.008171
2021-12-11 21:49:22,871 iteration 5260 : loss : 0.020500, loss_ce: 0.007434
2021-12-11 21:49:24,427 iteration 5261 : loss : 0.019635, loss_ce: 0.008647
2021-12-11 21:49:25,959 iteration 5262 : loss : 0.019636, loss_ce: 0.007765
2021-12-11 21:49:27,567 iteration 5263 : loss : 0.024437, loss_ce: 0.008055
2021-12-11 21:49:29,179 iteration 5264 : loss : 0.019869, loss_ce: 0.007791
2021-12-11 21:49:30,795 iteration 5265 : loss : 0.024312, loss_ce: 0.012939
2021-12-11 21:49:32,329 iteration 5266 : loss : 0.019262, loss_ce: 0.006464
2021-12-11 21:49:34,000 iteration 5267 : loss : 0.020819, loss_ce: 0.009234
2021-12-11 21:49:35,415 iteration 5268 : loss : 0.013561, loss_ce: 0.003104
2021-12-11 21:49:36,852 iteration 5269 : loss : 0.014160, loss_ce: 0.005094
2021-12-11 21:49:36,852 Training Data Eval:
2021-12-11 21:49:44,599   Average segmentation loss on training set: 0.0111
2021-12-11 21:49:44,600 Validation Data Eval:
2021-12-11 21:49:47,256   Average segmentation loss on validation set: 0.0690
2021-12-11 21:49:48,794 iteration 5270 : loss : 0.027143, loss_ce: 0.004820
 78%|██████████████████████▍      | 310/400 [2:29:33<45:50, 30.56s/it]2021-12-11 21:49:50,543 iteration 5271 : loss : 0.027806, loss_ce: 0.009058
2021-12-11 21:49:52,199 iteration 5272 : loss : 0.020788, loss_ce: 0.008238
2021-12-11 21:49:53,772 iteration 5273 : loss : 0.019557, loss_ce: 0.008344
2021-12-11 21:49:55,352 iteration 5274 : loss : 0.023381, loss_ce: 0.010018
2021-12-11 21:49:56,877 iteration 5275 : loss : 0.014025, loss_ce: 0.005531
2021-12-11 21:49:58,409 iteration 5276 : loss : 0.024097, loss_ce: 0.008022
2021-12-11 21:50:00,090 iteration 5277 : loss : 0.025232, loss_ce: 0.011729
2021-12-11 21:50:01,682 iteration 5278 : loss : 0.020728, loss_ce: 0.005007
2021-12-11 21:50:03,297 iteration 5279 : loss : 0.030622, loss_ce: 0.010371
2021-12-11 21:50:04,788 iteration 5280 : loss : 0.016467, loss_ce: 0.005089
2021-12-11 21:50:06,310 iteration 5281 : loss : 0.016571, loss_ce: 0.007185
2021-12-11 21:50:07,835 iteration 5282 : loss : 0.021849, loss_ce: 0.008593
2021-12-11 21:50:09,352 iteration 5283 : loss : 0.021731, loss_ce: 0.008210
2021-12-11 21:50:10,921 iteration 5284 : loss : 0.016949, loss_ce: 0.006397
2021-12-11 21:50:12,456 iteration 5285 : loss : 0.018684, loss_ce: 0.007604
2021-12-11 21:50:13,958 iteration 5286 : loss : 0.020944, loss_ce: 0.009794
2021-12-11 21:50:15,537 iteration 5287 : loss : 0.016764, loss_ce: 0.005831
 78%|██████████████████████▌      | 311/400 [2:30:00<43:38, 29.42s/it]2021-12-11 21:50:17,163 iteration 5288 : loss : 0.018154, loss_ce: 0.008185
2021-12-11 21:50:18,671 iteration 5289 : loss : 0.022450, loss_ce: 0.008088
2021-12-11 21:50:20,377 iteration 5290 : loss : 0.023408, loss_ce: 0.007429
2021-12-11 21:50:21,946 iteration 5291 : loss : 0.019908, loss_ce: 0.008668
2021-12-11 21:50:23,541 iteration 5292 : loss : 0.017506, loss_ce: 0.004444
2021-12-11 21:50:25,048 iteration 5293 : loss : 0.019441, loss_ce: 0.006519
2021-12-11 21:50:26,659 iteration 5294 : loss : 0.027267, loss_ce: 0.006850
2021-12-11 21:50:28,233 iteration 5295 : loss : 0.021173, loss_ce: 0.006681
2021-12-11 21:50:29,718 iteration 5296 : loss : 0.023324, loss_ce: 0.005292
2021-12-11 21:50:31,246 iteration 5297 : loss : 0.023025, loss_ce: 0.007155
2021-12-11 21:50:32,753 iteration 5298 : loss : 0.036117, loss_ce: 0.017411
2021-12-11 21:50:34,276 iteration 5299 : loss : 0.020349, loss_ce: 0.004474
2021-12-11 21:50:35,791 iteration 5300 : loss : 0.015625, loss_ce: 0.005819
2021-12-11 21:50:37,319 iteration 5301 : loss : 0.018006, loss_ce: 0.004369
2021-12-11 21:50:38,952 iteration 5302 : loss : 0.021478, loss_ce: 0.009106
2021-12-11 21:50:40,555 iteration 5303 : loss : 0.017967, loss_ce: 0.008316
2021-12-11 21:50:42,110 iteration 5304 : loss : 0.027872, loss_ce: 0.014698
 78%|██████████████████████▌      | 312/400 [2:30:26<41:53, 28.56s/it]2021-12-11 21:50:43,658 iteration 5305 : loss : 0.013568, loss_ce: 0.004642
2021-12-11 21:50:45,262 iteration 5306 : loss : 0.025651, loss_ce: 0.012305
2021-12-11 21:50:46,852 iteration 5307 : loss : 0.020607, loss_ce: 0.007698
2021-12-11 21:50:48,392 iteration 5308 : loss : 0.016181, loss_ce: 0.005847
2021-12-11 21:50:49,974 iteration 5309 : loss : 0.016782, loss_ce: 0.008622
2021-12-11 21:50:51,674 iteration 5310 : loss : 0.017449, loss_ce: 0.005672
2021-12-11 21:50:53,230 iteration 5311 : loss : 0.018824, loss_ce: 0.006709
2021-12-11 21:50:54,869 iteration 5312 : loss : 0.038051, loss_ce: 0.014370
2021-12-11 21:50:56,434 iteration 5313 : loss : 0.018316, loss_ce: 0.009579
2021-12-11 21:50:57,995 iteration 5314 : loss : 0.019332, loss_ce: 0.006560
2021-12-11 21:50:59,518 iteration 5315 : loss : 0.017359, loss_ce: 0.005958
2021-12-11 21:51:01,064 iteration 5316 : loss : 0.015320, loss_ce: 0.004210
2021-12-11 21:51:02,595 iteration 5317 : loss : 0.014500, loss_ce: 0.004392
2021-12-11 21:51:04,216 iteration 5318 : loss : 0.017688, loss_ce: 0.006558
2021-12-11 21:51:05,765 iteration 5319 : loss : 0.022305, loss_ce: 0.007757
2021-12-11 21:51:07,273 iteration 5320 : loss : 0.017020, loss_ce: 0.005923
2021-12-11 21:51:08,793 iteration 5321 : loss : 0.028024, loss_ce: 0.010981
 78%|██████████████████████▋      | 313/400 [2:30:53<40:35, 28.00s/it]2021-12-11 21:51:10,345 iteration 5322 : loss : 0.016489, loss_ce: 0.005931
2021-12-11 21:51:11,943 iteration 5323 : loss : 0.028310, loss_ce: 0.008258
2021-12-11 21:51:13,478 iteration 5324 : loss : 0.023552, loss_ce: 0.008301
2021-12-11 21:51:15,113 iteration 5325 : loss : 0.019369, loss_ce: 0.008003
2021-12-11 21:51:16,731 iteration 5326 : loss : 0.016840, loss_ce: 0.005663
2021-12-11 21:51:18,303 iteration 5327 : loss : 0.016919, loss_ce: 0.006964
2021-12-11 21:51:19,904 iteration 5328 : loss : 0.014455, loss_ce: 0.004784
2021-12-11 21:51:21,509 iteration 5329 : loss : 0.025581, loss_ce: 0.014820
2021-12-11 21:51:23,137 iteration 5330 : loss : 0.015785, loss_ce: 0.005033
2021-12-11 21:51:24,633 iteration 5331 : loss : 0.020134, loss_ce: 0.006722
2021-12-11 21:51:26,150 iteration 5332 : loss : 0.018212, loss_ce: 0.007126
2021-12-11 21:51:27,689 iteration 5333 : loss : 0.021296, loss_ce: 0.005814
2021-12-11 21:51:29,225 iteration 5334 : loss : 0.014978, loss_ce: 0.004380
2021-12-11 21:51:30,897 iteration 5335 : loss : 0.032962, loss_ce: 0.011852
2021-12-11 21:51:32,478 iteration 5336 : loss : 0.017183, loss_ce: 0.005579
2021-12-11 21:51:34,036 iteration 5337 : loss : 0.015696, loss_ce: 0.005442
2021-12-11 21:51:35,492 iteration 5338 : loss : 0.014572, loss_ce: 0.005074
 78%|██████████████████████▊      | 314/400 [2:31:20<39:34, 27.61s/it]2021-12-11 21:51:37,096 iteration 5339 : loss : 0.017759, loss_ce: 0.007096
2021-12-11 21:51:38,658 iteration 5340 : loss : 0.015208, loss_ce: 0.008633
2021-12-11 21:51:40,246 iteration 5341 : loss : 0.017389, loss_ce: 0.006814
2021-12-11 21:51:41,858 iteration 5342 : loss : 0.020158, loss_ce: 0.005365
2021-12-11 21:51:43,388 iteration 5343 : loss : 0.018854, loss_ce: 0.006351
2021-12-11 21:51:44,915 iteration 5344 : loss : 0.018985, loss_ce: 0.009244
2021-12-11 21:51:46,415 iteration 5345 : loss : 0.015212, loss_ce: 0.004591
2021-12-11 21:51:47,949 iteration 5346 : loss : 0.024651, loss_ce: 0.008784
2021-12-11 21:51:49,607 iteration 5347 : loss : 0.019787, loss_ce: 0.007951
2021-12-11 21:51:51,208 iteration 5348 : loss : 0.023133, loss_ce: 0.008407
2021-12-11 21:51:52,766 iteration 5349 : loss : 0.014260, loss_ce: 0.006045
2021-12-11 21:51:54,258 iteration 5350 : loss : 0.012988, loss_ce: 0.004631
2021-12-11 21:51:55,865 iteration 5351 : loss : 0.023797, loss_ce: 0.004813
2021-12-11 21:51:57,430 iteration 5352 : loss : 0.014967, loss_ce: 0.005375
2021-12-11 21:51:59,045 iteration 5353 : loss : 0.022770, loss_ce: 0.009849
2021-12-11 21:52:00,553 iteration 5354 : loss : 0.017405, loss_ce: 0.005986
2021-12-11 21:52:00,553 Training Data Eval:
2021-12-11 21:52:08,298   Average segmentation loss on training set: 0.0107
2021-12-11 21:52:08,299 Validation Data Eval:
2021-12-11 21:52:10,945   Average segmentation loss on validation set: 0.0731
2021-12-11 21:52:12,436 iteration 5355 : loss : 0.014961, loss_ce: 0.005428
 79%|██████████████████████▊      | 315/400 [2:31:57<43:04, 30.41s/it]2021-12-11 21:52:14,123 iteration 5356 : loss : 0.032181, loss_ce: 0.014840
2021-12-11 21:52:15,587 iteration 5357 : loss : 0.011663, loss_ce: 0.003684
2021-12-11 21:52:17,143 iteration 5358 : loss : 0.012763, loss_ce: 0.003178
2021-12-11 21:52:18,665 iteration 5359 : loss : 0.026953, loss_ce: 0.016390
2021-12-11 21:52:20,210 iteration 5360 : loss : 0.015405, loss_ce: 0.005289
2021-12-11 21:52:21,866 iteration 5361 : loss : 0.023630, loss_ce: 0.007982
2021-12-11 21:52:23,497 iteration 5362 : loss : 0.019307, loss_ce: 0.011444
2021-12-11 21:52:25,053 iteration 5363 : loss : 0.016890, loss_ce: 0.007038
2021-12-11 21:52:26,507 iteration 5364 : loss : 0.022988, loss_ce: 0.004134
2021-12-11 21:52:28,118 iteration 5365 : loss : 0.015846, loss_ce: 0.005387
2021-12-11 21:52:29,607 iteration 5366 : loss : 0.020036, loss_ce: 0.006519
2021-12-11 21:52:31,193 iteration 5367 : loss : 0.018305, loss_ce: 0.004899
2021-12-11 21:52:32,851 iteration 5368 : loss : 0.019234, loss_ce: 0.006720
2021-12-11 21:52:34,435 iteration 5369 : loss : 0.017642, loss_ce: 0.007274
2021-12-11 21:52:36,011 iteration 5370 : loss : 0.020979, loss_ce: 0.006071
2021-12-11 21:52:37,660 iteration 5371 : loss : 0.016465, loss_ce: 0.004697
2021-12-11 21:52:39,193 iteration 5372 : loss : 0.022750, loss_ce: 0.008950
 79%|██████████████████████▉      | 316/400 [2:32:24<41:02, 29.32s/it]2021-12-11 21:52:40,726 iteration 5373 : loss : 0.014913, loss_ce: 0.006267
2021-12-11 21:52:42,304 iteration 5374 : loss : 0.022457, loss_ce: 0.006422
2021-12-11 21:52:43,812 iteration 5375 : loss : 0.015673, loss_ce: 0.005128
2021-12-11 21:52:45,303 iteration 5376 : loss : 0.014883, loss_ce: 0.004771
2021-12-11 21:52:46,742 iteration 5377 : loss : 0.019312, loss_ce: 0.002727
2021-12-11 21:52:48,179 iteration 5378 : loss : 0.013391, loss_ce: 0.004734
2021-12-11 21:52:49,755 iteration 5379 : loss : 0.016744, loss_ce: 0.005917
2021-12-11 21:52:51,273 iteration 5380 : loss : 0.015625, loss_ce: 0.006150
2021-12-11 21:52:52,835 iteration 5381 : loss : 0.021042, loss_ce: 0.008561
2021-12-11 21:52:54,439 iteration 5382 : loss : 0.026895, loss_ce: 0.007216
2021-12-11 21:52:56,052 iteration 5383 : loss : 0.018824, loss_ce: 0.007354
2021-12-11 21:52:57,599 iteration 5384 : loss : 0.015898, loss_ce: 0.006982
2021-12-11 21:52:59,148 iteration 5385 : loss : 0.017725, loss_ce: 0.007824
2021-12-11 21:53:00,763 iteration 5386 : loss : 0.015720, loss_ce: 0.005685
2021-12-11 21:53:02,331 iteration 5387 : loss : 0.023486, loss_ce: 0.009633
2021-12-11 21:53:03,798 iteration 5388 : loss : 0.014574, loss_ce: 0.005476
2021-12-11 21:53:05,311 iteration 5389 : loss : 0.014203, loss_ce: 0.004912
 79%|██████████████████████▉      | 317/400 [2:32:50<39:13, 28.35s/it]2021-12-11 21:53:07,030 iteration 5390 : loss : 0.026384, loss_ce: 0.007879
2021-12-11 21:53:08,483 iteration 5391 : loss : 0.015319, loss_ce: 0.004996
2021-12-11 21:53:10,078 iteration 5392 : loss : 0.018204, loss_ce: 0.007990
2021-12-11 21:53:11,689 iteration 5393 : loss : 0.030044, loss_ce: 0.009619
2021-12-11 21:53:13,246 iteration 5394 : loss : 0.018344, loss_ce: 0.007475
2021-12-11 21:53:14,743 iteration 5395 : loss : 0.016133, loss_ce: 0.006902
2021-12-11 21:53:16,363 iteration 5396 : loss : 0.028076, loss_ce: 0.008638
2021-12-11 21:53:17,933 iteration 5397 : loss : 0.020204, loss_ce: 0.007633
2021-12-11 21:53:19,374 iteration 5398 : loss : 0.012026, loss_ce: 0.005721
2021-12-11 21:53:20,899 iteration 5399 : loss : 0.013018, loss_ce: 0.005342
2021-12-11 21:53:22,555 iteration 5400 : loss : 0.022370, loss_ce: 0.006638
2021-12-11 21:53:24,171 iteration 5401 : loss : 0.018255, loss_ce: 0.005455
2021-12-11 21:53:25,730 iteration 5402 : loss : 0.017038, loss_ce: 0.006127
2021-12-11 21:53:27,342 iteration 5403 : loss : 0.023658, loss_ce: 0.006668
2021-12-11 21:53:28,868 iteration 5404 : loss : 0.017687, loss_ce: 0.008125
2021-12-11 21:53:30,359 iteration 5405 : loss : 0.013196, loss_ce: 0.004024
2021-12-11 21:53:31,809 iteration 5406 : loss : 0.016762, loss_ce: 0.004487
 80%|███████████████████████      | 318/400 [2:33:16<37:59, 27.80s/it]2021-12-11 21:53:33,502 iteration 5407 : loss : 0.018121, loss_ce: 0.005264
2021-12-11 21:53:35,043 iteration 5408 : loss : 0.021328, loss_ce: 0.006249
2021-12-11 21:53:36,548 iteration 5409 : loss : 0.014703, loss_ce: 0.007182
2021-12-11 21:53:38,062 iteration 5410 : loss : 0.016381, loss_ce: 0.004851
2021-12-11 21:53:39,658 iteration 5411 : loss : 0.016154, loss_ce: 0.005634
2021-12-11 21:53:41,278 iteration 5412 : loss : 0.020857, loss_ce: 0.009713
2021-12-11 21:53:42,789 iteration 5413 : loss : 0.015917, loss_ce: 0.005956
2021-12-11 21:53:44,412 iteration 5414 : loss : 0.020345, loss_ce: 0.007912
2021-12-11 21:53:45,964 iteration 5415 : loss : 0.016203, loss_ce: 0.005447
2021-12-11 21:53:47,592 iteration 5416 : loss : 0.019761, loss_ce: 0.008931
2021-12-11 21:53:49,115 iteration 5417 : loss : 0.019727, loss_ce: 0.007164
2021-12-11 21:53:50,666 iteration 5418 : loss : 0.014274, loss_ce: 0.004348
2021-12-11 21:53:52,196 iteration 5419 : loss : 0.012569, loss_ce: 0.005447
2021-12-11 21:53:53,746 iteration 5420 : loss : 0.014199, loss_ce: 0.006208
2021-12-11 21:53:55,336 iteration 5421 : loss : 0.022351, loss_ce: 0.007109
2021-12-11 21:53:56,909 iteration 5422 : loss : 0.020822, loss_ce: 0.006897
2021-12-11 21:53:58,531 iteration 5423 : loss : 0.027545, loss_ce: 0.008091
 80%|███████████████████████▏     | 319/400 [2:33:43<37:05, 27.47s/it]2021-12-11 21:54:00,189 iteration 5424 : loss : 0.019550, loss_ce: 0.007855
2021-12-11 21:54:01,772 iteration 5425 : loss : 0.021602, loss_ce: 0.008654
2021-12-11 21:54:03,362 iteration 5426 : loss : 0.019750, loss_ce: 0.005673
2021-12-11 21:54:05,052 iteration 5427 : loss : 0.019432, loss_ce: 0.005437
2021-12-11 21:54:06,690 iteration 5428 : loss : 0.020525, loss_ce: 0.007928
2021-12-11 21:54:08,204 iteration 5429 : loss : 0.013375, loss_ce: 0.004928
2021-12-11 21:54:09,666 iteration 5430 : loss : 0.013803, loss_ce: 0.005681
2021-12-11 21:54:11,304 iteration 5431 : loss : 0.021252, loss_ce: 0.007328
2021-12-11 21:54:12,826 iteration 5432 : loss : 0.016405, loss_ce: 0.005361
2021-12-11 21:54:14,523 iteration 5433 : loss : 0.020531, loss_ce: 0.007013
2021-12-11 21:54:16,177 iteration 5434 : loss : 0.022521, loss_ce: 0.008200
2021-12-11 21:54:17,774 iteration 5435 : loss : 0.016678, loss_ce: 0.007601
2021-12-11 21:54:19,397 iteration 5436 : loss : 0.019515, loss_ce: 0.008747
2021-12-11 21:54:20,920 iteration 5437 : loss : 0.019945, loss_ce: 0.004977
2021-12-11 21:54:22,487 iteration 5438 : loss : 0.019752, loss_ce: 0.008543
2021-12-11 21:54:24,083 iteration 5439 : loss : 0.022324, loss_ce: 0.007135
2021-12-11 21:54:24,083 Training Data Eval:
2021-12-11 21:54:31,821   Average segmentation loss on training set: 0.0111
2021-12-11 21:54:31,821 Validation Data Eval:
2021-12-11 21:54:34,481   Average segmentation loss on validation set: 0.0805
2021-12-11 21:54:36,054 iteration 5440 : loss : 0.015114, loss_ce: 0.005376
 80%|███████████████████████▏     | 320/400 [2:34:20<40:39, 30.49s/it]2021-12-11 21:54:37,600 iteration 5441 : loss : 0.016271, loss_ce: 0.006509
2021-12-11 21:54:39,304 iteration 5442 : loss : 0.029398, loss_ce: 0.012172
2021-12-11 21:54:40,908 iteration 5443 : loss : 0.024353, loss_ce: 0.009497
2021-12-11 21:54:42,453 iteration 5444 : loss : 0.014910, loss_ce: 0.006422
2021-12-11 21:54:43,982 iteration 5445 : loss : 0.019021, loss_ce: 0.006812
2021-12-11 21:54:45,545 iteration 5446 : loss : 0.018665, loss_ce: 0.007456
2021-12-11 21:54:47,023 iteration 5447 : loss : 0.019217, loss_ce: 0.003484
2021-12-11 21:54:48,609 iteration 5448 : loss : 0.021551, loss_ce: 0.006962
2021-12-11 21:54:50,149 iteration 5449 : loss : 0.018563, loss_ce: 0.005466
2021-12-11 21:54:51,665 iteration 5450 : loss : 0.020977, loss_ce: 0.006715
2021-12-11 21:54:53,235 iteration 5451 : loss : 0.012584, loss_ce: 0.003493
2021-12-11 21:54:54,814 iteration 5452 : loss : 0.015331, loss_ce: 0.005654
2021-12-11 21:54:56,435 iteration 5453 : loss : 0.019539, loss_ce: 0.007089
2021-12-11 21:54:58,020 iteration 5454 : loss : 0.019664, loss_ce: 0.007994
2021-12-11 21:54:59,585 iteration 5455 : loss : 0.015789, loss_ce: 0.007585
2021-12-11 21:55:01,181 iteration 5456 : loss : 0.017668, loss_ce: 0.004757
2021-12-11 21:55:02,769 iteration 5457 : loss : 0.016464, loss_ce: 0.006383
 80%|███████████████████████▎     | 321/400 [2:34:47<38:39, 29.36s/it]2021-12-11 21:55:04,472 iteration 5458 : loss : 0.018733, loss_ce: 0.005337
2021-12-11 21:55:05,983 iteration 5459 : loss : 0.015590, loss_ce: 0.005245
2021-12-11 21:55:07,545 iteration 5460 : loss : 0.017966, loss_ce: 0.007132
2021-12-11 21:55:09,141 iteration 5461 : loss : 0.019138, loss_ce: 0.006360
2021-12-11 21:55:10,757 iteration 5462 : loss : 0.018081, loss_ce: 0.007548
2021-12-11 21:55:12,283 iteration 5463 : loss : 0.014193, loss_ce: 0.004492
2021-12-11 21:55:13,988 iteration 5464 : loss : 0.035549, loss_ce: 0.013511
2021-12-11 21:55:15,512 iteration 5465 : loss : 0.019117, loss_ce: 0.006426
2021-12-11 21:55:17,041 iteration 5466 : loss : 0.016201, loss_ce: 0.006245
2021-12-11 21:55:18,684 iteration 5467 : loss : 0.017019, loss_ce: 0.005931
2021-12-11 21:55:20,316 iteration 5468 : loss : 0.018698, loss_ce: 0.007990
2021-12-11 21:55:21,956 iteration 5469 : loss : 0.023570, loss_ce: 0.009099
2021-12-11 21:55:23,495 iteration 5470 : loss : 0.016589, loss_ce: 0.007686
2021-12-11 21:55:25,026 iteration 5471 : loss : 0.015393, loss_ce: 0.007674
2021-12-11 21:55:26,657 iteration 5472 : loss : 0.017887, loss_ce: 0.007662
2021-12-11 21:55:28,190 iteration 5473 : loss : 0.016143, loss_ce: 0.004625
2021-12-11 21:55:29,817 iteration 5474 : loss : 0.018793, loss_ce: 0.005066
 80%|███████████████████████▎     | 322/400 [2:35:14<37:15, 28.66s/it]2021-12-11 21:55:31,396 iteration 5475 : loss : 0.016508, loss_ce: 0.005903
2021-12-11 21:55:32,936 iteration 5476 : loss : 0.014176, loss_ce: 0.006248
2021-12-11 21:55:34,543 iteration 5477 : loss : 0.013293, loss_ce: 0.004546
2021-12-11 21:55:36,174 iteration 5478 : loss : 0.020818, loss_ce: 0.008912
2021-12-11 21:55:37,699 iteration 5479 : loss : 0.018142, loss_ce: 0.004920
2021-12-11 21:55:39,262 iteration 5480 : loss : 0.026692, loss_ce: 0.004994
2021-12-11 21:55:40,840 iteration 5481 : loss : 0.020116, loss_ce: 0.007953
2021-12-11 21:55:42,410 iteration 5482 : loss : 0.017439, loss_ce: 0.006051
2021-12-11 21:55:43,926 iteration 5483 : loss : 0.019459, loss_ce: 0.007074
2021-12-11 21:55:45,558 iteration 5484 : loss : 0.019450, loss_ce: 0.007959
2021-12-11 21:55:47,042 iteration 5485 : loss : 0.014800, loss_ce: 0.006651
2021-12-11 21:55:48,746 iteration 5486 : loss : 0.018408, loss_ce: 0.006390
2021-12-11 21:55:50,250 iteration 5487 : loss : 0.015762, loss_ce: 0.007860
2021-12-11 21:55:51,864 iteration 5488 : loss : 0.022407, loss_ce: 0.006337
2021-12-11 21:55:53,373 iteration 5489 : loss : 0.018182, loss_ce: 0.004479
2021-12-11 21:55:54,978 iteration 5490 : loss : 0.016904, loss_ce: 0.006152
2021-12-11 21:55:56,503 iteration 5491 : loss : 0.015636, loss_ce: 0.005170
 81%|███████████████████████▍     | 323/400 [2:35:41<36:01, 28.07s/it]2021-12-11 21:55:58,153 iteration 5492 : loss : 0.022651, loss_ce: 0.009779
2021-12-11 21:55:59,651 iteration 5493 : loss : 0.015921, loss_ce: 0.005346
2021-12-11 21:56:01,175 iteration 5494 : loss : 0.016503, loss_ce: 0.007440
2021-12-11 21:56:02,815 iteration 5495 : loss : 0.025010, loss_ce: 0.005816
2021-12-11 21:56:04,316 iteration 5496 : loss : 0.018598, loss_ce: 0.006457
2021-12-11 21:56:05,895 iteration 5497 : loss : 0.015975, loss_ce: 0.006890
2021-12-11 21:56:07,511 iteration 5498 : loss : 0.016512, loss_ce: 0.007238
2021-12-11 21:56:09,083 iteration 5499 : loss : 0.017232, loss_ce: 0.004682
2021-12-11 21:56:10,649 iteration 5500 : loss : 0.015617, loss_ce: 0.004874
2021-12-11 21:56:12,182 iteration 5501 : loss : 0.013642, loss_ce: 0.004748
2021-12-11 21:56:13,703 iteration 5502 : loss : 0.018316, loss_ce: 0.010689
2021-12-11 21:56:15,408 iteration 5503 : loss : 0.025262, loss_ce: 0.006573
2021-12-11 21:56:16,993 iteration 5504 : loss : 0.020159, loss_ce: 0.007755
2021-12-11 21:56:18,478 iteration 5505 : loss : 0.013535, loss_ce: 0.004673
2021-12-11 21:56:19,994 iteration 5506 : loss : 0.015065, loss_ce: 0.005423
2021-12-11 21:56:21,644 iteration 5507 : loss : 0.022852, loss_ce: 0.007780
2021-12-11 21:56:23,247 iteration 5508 : loss : 0.025052, loss_ce: 0.009901
 81%|███████████████████████▍     | 324/400 [2:36:08<35:03, 27.67s/it]2021-12-11 21:56:24,913 iteration 5509 : loss : 0.023871, loss_ce: 0.010599
2021-12-11 21:56:26,454 iteration 5510 : loss : 0.017752, loss_ce: 0.006225
2021-12-11 21:56:28,030 iteration 5511 : loss : 0.023388, loss_ce: 0.008124
2021-12-11 21:56:29,585 iteration 5512 : loss : 0.018844, loss_ce: 0.007474
2021-12-11 21:56:31,140 iteration 5513 : loss : 0.014227, loss_ce: 0.007282
2021-12-11 21:56:32,764 iteration 5514 : loss : 0.026582, loss_ce: 0.009855
2021-12-11 21:56:34,314 iteration 5515 : loss : 0.015955, loss_ce: 0.005819
2021-12-11 21:56:35,877 iteration 5516 : loss : 0.014636, loss_ce: 0.006970
2021-12-11 21:56:37,460 iteration 5517 : loss : 0.022210, loss_ce: 0.007111
2021-12-11 21:56:38,937 iteration 5518 : loss : 0.013452, loss_ce: 0.004485
2021-12-11 21:56:40,588 iteration 5519 : loss : 0.023627, loss_ce: 0.006782
2021-12-11 21:56:42,137 iteration 5520 : loss : 0.025395, loss_ce: 0.005880
2021-12-11 21:56:43,802 iteration 5521 : loss : 0.018363, loss_ce: 0.006366
2021-12-11 21:56:45,358 iteration 5522 : loss : 0.017862, loss_ce: 0.006395
2021-12-11 21:56:46,979 iteration 5523 : loss : 0.021927, loss_ce: 0.008483
2021-12-11 21:56:48,619 iteration 5524 : loss : 0.020752, loss_ce: 0.009369
2021-12-11 21:56:48,619 Training Data Eval:
2021-12-11 21:56:56,367   Average segmentation loss on training set: 0.0117
2021-12-11 21:56:56,368 Validation Data Eval:
2021-12-11 21:56:59,024   Average segmentation loss on validation set: 0.1038
2021-12-11 21:57:00,689 iteration 5525 : loss : 0.020222, loss_ce: 0.008957
 81%|███████████████████████▌     | 325/400 [2:36:45<38:15, 30.61s/it]2021-12-11 21:57:02,314 iteration 5526 : loss : 0.019405, loss_ce: 0.006327
2021-12-11 21:57:03,801 iteration 5527 : loss : 0.016128, loss_ce: 0.007118
2021-12-11 21:57:05,447 iteration 5528 : loss : 0.025475, loss_ce: 0.008295
2021-12-11 21:57:06,977 iteration 5529 : loss : 0.013833, loss_ce: 0.004977
2021-12-11 21:57:08,482 iteration 5530 : loss : 0.015907, loss_ce: 0.005970
2021-12-11 21:57:09,935 iteration 5531 : loss : 0.012307, loss_ce: 0.003590
2021-12-11 21:57:11,424 iteration 5532 : loss : 0.020329, loss_ce: 0.007732
2021-12-11 21:57:13,024 iteration 5533 : loss : 0.015727, loss_ce: 0.007062
2021-12-11 21:57:14,505 iteration 5534 : loss : 0.012277, loss_ce: 0.004015
2021-12-11 21:57:16,025 iteration 5535 : loss : 0.015523, loss_ce: 0.005881
2021-12-11 21:57:17,632 iteration 5536 : loss : 0.016634, loss_ce: 0.004756
2021-12-11 21:57:19,242 iteration 5537 : loss : 0.016682, loss_ce: 0.007477
2021-12-11 21:57:20,913 iteration 5538 : loss : 0.018278, loss_ce: 0.004909
2021-12-11 21:57:22,483 iteration 5539 : loss : 0.015359, loss_ce: 0.005477
2021-12-11 21:57:23,962 iteration 5540 : loss : 0.018030, loss_ce: 0.007632
2021-12-11 21:57:25,648 iteration 5541 : loss : 0.026968, loss_ce: 0.011588
2021-12-11 21:57:27,221 iteration 5542 : loss : 0.015650, loss_ce: 0.005822
 82%|███████████████████████▋     | 326/400 [2:37:12<36:14, 29.38s/it]2021-12-11 21:57:28,905 iteration 5543 : loss : 0.019747, loss_ce: 0.008788
2021-12-11 21:57:30,440 iteration 5544 : loss : 0.017722, loss_ce: 0.006283
2021-12-11 21:57:32,046 iteration 5545 : loss : 0.016006, loss_ce: 0.006910
2021-12-11 21:57:33,716 iteration 5546 : loss : 0.027038, loss_ce: 0.006621
2021-12-11 21:57:35,333 iteration 5547 : loss : 0.017660, loss_ce: 0.007456
2021-12-11 21:57:36,879 iteration 5548 : loss : 0.018149, loss_ce: 0.004181
2021-12-11 21:57:38,409 iteration 5549 : loss : 0.016254, loss_ce: 0.004192
2021-12-11 21:57:40,004 iteration 5550 : loss : 0.015784, loss_ce: 0.006419
2021-12-11 21:57:41,530 iteration 5551 : loss : 0.017585, loss_ce: 0.008016
2021-12-11 21:57:42,958 iteration 5552 : loss : 0.013480, loss_ce: 0.004175
2021-12-11 21:57:44,530 iteration 5553 : loss : 0.020290, loss_ce: 0.007615
2021-12-11 21:57:46,071 iteration 5554 : loss : 0.018975, loss_ce: 0.007397
2021-12-11 21:57:47,539 iteration 5555 : loss : 0.015888, loss_ce: 0.006419
2021-12-11 21:57:49,164 iteration 5556 : loss : 0.027040, loss_ce: 0.009571
2021-12-11 21:57:50,760 iteration 5557 : loss : 0.020945, loss_ce: 0.012853
2021-12-11 21:57:52,328 iteration 5558 : loss : 0.018310, loss_ce: 0.005619
2021-12-11 21:57:53,880 iteration 5559 : loss : 0.017499, loss_ce: 0.005010
 82%|███████████████████████▋     | 327/400 [2:37:38<34:45, 28.57s/it]2021-12-11 21:57:55,521 iteration 5560 : loss : 0.019123, loss_ce: 0.006188
2021-12-11 21:57:57,054 iteration 5561 : loss : 0.020093, loss_ce: 0.006372
2021-12-11 21:57:58,600 iteration 5562 : loss : 0.017403, loss_ce: 0.007414
2021-12-11 21:58:00,133 iteration 5563 : loss : 0.021200, loss_ce: 0.008980
2021-12-11 21:58:01,735 iteration 5564 : loss : 0.014953, loss_ce: 0.006105
2021-12-11 21:58:03,345 iteration 5565 : loss : 0.021938, loss_ce: 0.010752
2021-12-11 21:58:04,918 iteration 5566 : loss : 0.018169, loss_ce: 0.007622
2021-12-11 21:58:06,519 iteration 5567 : loss : 0.017692, loss_ce: 0.008314
2021-12-11 21:58:08,064 iteration 5568 : loss : 0.028228, loss_ce: 0.009960
2021-12-11 21:58:09,627 iteration 5569 : loss : 0.016610, loss_ce: 0.006282
2021-12-11 21:58:11,131 iteration 5570 : loss : 0.013317, loss_ce: 0.004028
2021-12-11 21:58:12,574 iteration 5571 : loss : 0.012493, loss_ce: 0.004511
2021-12-11 21:58:14,083 iteration 5572 : loss : 0.019955, loss_ce: 0.006910
2021-12-11 21:58:15,553 iteration 5573 : loss : 0.010372, loss_ce: 0.002912
2021-12-11 21:58:17,098 iteration 5574 : loss : 0.015101, loss_ce: 0.004521
2021-12-11 21:58:18,769 iteration 5575 : loss : 0.022283, loss_ce: 0.007550
2021-12-11 21:58:20,363 iteration 5576 : loss : 0.023656, loss_ce: 0.008252
 82%|███████████████████████▊     | 328/400 [2:38:05<33:31, 27.94s/it]2021-12-11 21:58:22,000 iteration 5577 : loss : 0.020184, loss_ce: 0.009198
2021-12-11 21:58:23,607 iteration 5578 : loss : 0.020890, loss_ce: 0.007210
2021-12-11 21:58:25,242 iteration 5579 : loss : 0.020977, loss_ce: 0.008737
2021-12-11 21:58:26,785 iteration 5580 : loss : 0.022305, loss_ce: 0.008152
2021-12-11 21:58:28,285 iteration 5581 : loss : 0.013000, loss_ce: 0.005206
2021-12-11 21:58:29,854 iteration 5582 : loss : 0.012850, loss_ce: 0.003640
2021-12-11 21:58:31,403 iteration 5583 : loss : 0.011050, loss_ce: 0.004003
2021-12-11 21:58:33,021 iteration 5584 : loss : 0.023860, loss_ce: 0.010785
2021-12-11 21:58:34,563 iteration 5585 : loss : 0.017477, loss_ce: 0.004773
2021-12-11 21:58:36,201 iteration 5586 : loss : 0.020298, loss_ce: 0.006669
2021-12-11 21:58:37,696 iteration 5587 : loss : 0.018078, loss_ce: 0.007405
2021-12-11 21:58:39,235 iteration 5588 : loss : 0.016680, loss_ce: 0.005896
2021-12-11 21:58:40,724 iteration 5589 : loss : 0.013194, loss_ce: 0.003606
2021-12-11 21:58:42,237 iteration 5590 : loss : 0.019546, loss_ce: 0.004890
2021-12-11 21:58:43,761 iteration 5591 : loss : 0.015293, loss_ce: 0.005980
2021-12-11 21:58:45,393 iteration 5592 : loss : 0.020933, loss_ce: 0.007354
2021-12-11 21:58:46,986 iteration 5593 : loss : 0.020542, loss_ce: 0.008142
 82%|███████████████████████▊     | 329/400 [2:38:31<32:35, 27.55s/it]2021-12-11 21:58:48,554 iteration 5594 : loss : 0.018764, loss_ce: 0.005547
2021-12-11 21:58:50,155 iteration 5595 : loss : 0.019319, loss_ce: 0.008407
2021-12-11 21:58:51,693 iteration 5596 : loss : 0.021151, loss_ce: 0.007505
2021-12-11 21:58:53,320 iteration 5597 : loss : 0.015973, loss_ce: 0.006265
2021-12-11 21:58:54,818 iteration 5598 : loss : 0.012744, loss_ce: 0.004976
2021-12-11 21:58:56,373 iteration 5599 : loss : 0.020012, loss_ce: 0.007728
2021-12-11 21:58:57,914 iteration 5600 : loss : 0.014267, loss_ce: 0.005396
2021-12-11 21:58:59,450 iteration 5601 : loss : 0.013017, loss_ce: 0.005730
2021-12-11 21:59:01,028 iteration 5602 : loss : 0.015159, loss_ce: 0.005865
2021-12-11 21:59:02,503 iteration 5603 : loss : 0.012886, loss_ce: 0.005000
2021-12-11 21:59:04,087 iteration 5604 : loss : 0.036757, loss_ce: 0.012560
2021-12-11 21:59:05,698 iteration 5605 : loss : 0.024869, loss_ce: 0.010017
2021-12-11 21:59:07,282 iteration 5606 : loss : 0.021293, loss_ce: 0.006975
2021-12-11 21:59:08,855 iteration 5607 : loss : 0.017856, loss_ce: 0.005775
2021-12-11 21:59:10,426 iteration 5608 : loss : 0.014029, loss_ce: 0.004212
2021-12-11 21:59:12,044 iteration 5609 : loss : 0.013108, loss_ce: 0.005201
2021-12-11 21:59:12,044 Training Data Eval:
2021-12-11 21:59:19,807   Average segmentation loss on training set: 0.0112
2021-12-11 21:59:19,807 Validation Data Eval:
2021-12-11 21:59:22,464   Average segmentation loss on validation set: 0.0943
2021-12-11 21:59:23,979 iteration 5610 : loss : 0.016352, loss_ce: 0.006107
 82%|███████████████████████▉     | 330/400 [2:39:08<35:26, 30.38s/it]2021-12-11 21:59:25,584 iteration 5611 : loss : 0.030878, loss_ce: 0.012651
2021-12-11 21:59:27,170 iteration 5612 : loss : 0.029601, loss_ce: 0.007100
2021-12-11 21:59:28,740 iteration 5613 : loss : 0.016067, loss_ce: 0.005878
2021-12-11 21:59:30,305 iteration 5614 : loss : 0.018318, loss_ce: 0.007195
2021-12-11 21:59:31,776 iteration 5615 : loss : 0.011541, loss_ce: 0.005005
2021-12-11 21:59:33,380 iteration 5616 : loss : 0.015815, loss_ce: 0.006730
2021-12-11 21:59:35,015 iteration 5617 : loss : 0.018746, loss_ce: 0.007124
2021-12-11 21:59:36,615 iteration 5618 : loss : 0.017997, loss_ce: 0.008021
2021-12-11 21:59:38,155 iteration 5619 : loss : 0.017679, loss_ce: 0.004799
2021-12-11 21:59:39,797 iteration 5620 : loss : 0.013662, loss_ce: 0.004930
2021-12-11 21:59:41,286 iteration 5621 : loss : 0.017045, loss_ce: 0.005620
2021-12-11 21:59:42,860 iteration 5622 : loss : 0.017963, loss_ce: 0.005724
2021-12-11 21:59:44,528 iteration 5623 : loss : 0.026094, loss_ce: 0.009437
2021-12-11 21:59:46,030 iteration 5624 : loss : 0.018558, loss_ce: 0.005002
2021-12-11 21:59:47,524 iteration 5625 : loss : 0.015265, loss_ce: 0.006250
2021-12-11 21:59:49,054 iteration 5626 : loss : 0.013578, loss_ce: 0.003905
2021-12-11 21:59:50,646 iteration 5627 : loss : 0.016628, loss_ce: 0.006173
 83%|███████████████████████▉     | 331/400 [2:39:35<33:39, 29.27s/it]2021-12-11 21:59:52,392 iteration 5628 : loss : 0.022356, loss_ce: 0.010319
2021-12-11 21:59:53,907 iteration 5629 : loss : 0.014930, loss_ce: 0.006106
2021-12-11 21:59:55,505 iteration 5630 : loss : 0.017914, loss_ce: 0.006379
2021-12-11 21:59:57,063 iteration 5631 : loss : 0.020541, loss_ce: 0.007387
2021-12-11 21:59:58,668 iteration 5632 : loss : 0.018593, loss_ce: 0.008306
2021-12-11 22:00:00,300 iteration 5633 : loss : 0.019111, loss_ce: 0.007055
2021-12-11 22:00:01,877 iteration 5634 : loss : 0.014721, loss_ce: 0.006142
2021-12-11 22:00:03,421 iteration 5635 : loss : 0.015821, loss_ce: 0.005713
2021-12-11 22:00:05,013 iteration 5636 : loss : 0.020347, loss_ce: 0.004808
2021-12-11 22:00:06,567 iteration 5637 : loss : 0.017928, loss_ce: 0.005261
2021-12-11 22:00:08,145 iteration 5638 : loss : 0.022207, loss_ce: 0.010754
2021-12-11 22:00:09,738 iteration 5639 : loss : 0.016349, loss_ce: 0.005634
2021-12-11 22:00:11,331 iteration 5640 : loss : 0.017671, loss_ce: 0.007666
2021-12-11 22:00:12,817 iteration 5641 : loss : 0.016420, loss_ce: 0.005069
2021-12-11 22:00:14,328 iteration 5642 : loss : 0.019439, loss_ce: 0.007718
2021-12-11 22:00:15,880 iteration 5643 : loss : 0.017530, loss_ce: 0.005383
2021-12-11 22:00:17,412 iteration 5644 : loss : 0.017024, loss_ce: 0.006654
 83%|████████████████████████     | 332/400 [2:40:02<32:19, 28.52s/it]2021-12-11 22:00:19,001 iteration 5645 : loss : 0.016256, loss_ce: 0.004824
2021-12-11 22:00:20,551 iteration 5646 : loss : 0.014273, loss_ce: 0.004807
2021-12-11 22:00:22,151 iteration 5647 : loss : 0.019122, loss_ce: 0.006086
2021-12-11 22:00:23,732 iteration 5648 : loss : 0.024923, loss_ce: 0.006179
2021-12-11 22:00:25,287 iteration 5649 : loss : 0.014209, loss_ce: 0.004828
2021-12-11 22:00:26,904 iteration 5650 : loss : 0.029580, loss_ce: 0.009636
2021-12-11 22:00:28,451 iteration 5651 : loss : 0.015317, loss_ce: 0.006980
2021-12-11 22:00:29,973 iteration 5652 : loss : 0.015086, loss_ce: 0.005622
2021-12-11 22:00:31,508 iteration 5653 : loss : 0.018016, loss_ce: 0.006100
2021-12-11 22:00:33,154 iteration 5654 : loss : 0.012452, loss_ce: 0.004637
2021-12-11 22:00:34,693 iteration 5655 : loss : 0.023319, loss_ce: 0.008000
2021-12-11 22:00:36,286 iteration 5656 : loss : 0.022708, loss_ce: 0.009712
2021-12-11 22:00:37,828 iteration 5657 : loss : 0.018401, loss_ce: 0.008771
2021-12-11 22:00:39,464 iteration 5658 : loss : 0.025133, loss_ce: 0.008043
2021-12-11 22:00:41,132 iteration 5659 : loss : 0.015890, loss_ce: 0.007152
2021-12-11 22:00:42,600 iteration 5660 : loss : 0.012925, loss_ce: 0.004771
2021-12-11 22:00:44,200 iteration 5661 : loss : 0.019545, loss_ce: 0.006924
 83%|████████████████████████▏    | 333/400 [2:40:29<31:15, 28.00s/it]2021-12-11 22:00:45,771 iteration 5662 : loss : 0.014259, loss_ce: 0.005696
2021-12-11 22:00:47,384 iteration 5663 : loss : 0.014728, loss_ce: 0.007310
2021-12-11 22:00:49,017 iteration 5664 : loss : 0.020473, loss_ce: 0.007514
2021-12-11 22:00:50,559 iteration 5665 : loss : 0.011564, loss_ce: 0.002618
2021-12-11 22:00:52,198 iteration 5666 : loss : 0.014602, loss_ce: 0.005044
2021-12-11 22:00:53,789 iteration 5667 : loss : 0.019471, loss_ce: 0.006108
2021-12-11 22:00:55,378 iteration 5668 : loss : 0.020564, loss_ce: 0.006319
2021-12-11 22:00:57,034 iteration 5669 : loss : 0.020403, loss_ce: 0.010625
2021-12-11 22:00:58,618 iteration 5670 : loss : 0.016899, loss_ce: 0.005638
2021-12-11 22:01:00,259 iteration 5671 : loss : 0.023242, loss_ce: 0.005839
2021-12-11 22:01:01,731 iteration 5672 : loss : 0.017936, loss_ce: 0.004797
2021-12-11 22:01:03,272 iteration 5673 : loss : 0.014516, loss_ce: 0.006081
2021-12-11 22:01:04,768 iteration 5674 : loss : 0.030217, loss_ce: 0.009634
2021-12-11 22:01:06,455 iteration 5675 : loss : 0.023396, loss_ce: 0.008561
2021-12-11 22:01:08,016 iteration 5676 : loss : 0.022306, loss_ce: 0.012298
2021-12-11 22:01:09,546 iteration 5677 : loss : 0.015787, loss_ce: 0.005572
2021-12-11 22:01:11,098 iteration 5678 : loss : 0.016765, loss_ce: 0.006203
 84%|████████████████████████▏    | 334/400 [2:40:55<30:26, 27.67s/it]2021-12-11 22:01:12,750 iteration 5679 : loss : 0.023993, loss_ce: 0.007909
2021-12-11 22:01:14,302 iteration 5680 : loss : 0.013614, loss_ce: 0.005876
2021-12-11 22:01:15,908 iteration 5681 : loss : 0.013523, loss_ce: 0.004005
2021-12-11 22:01:17,380 iteration 5682 : loss : 0.012282, loss_ce: 0.004034
2021-12-11 22:01:18,846 iteration 5683 : loss : 0.010884, loss_ce: 0.004643
2021-12-11 22:01:20,478 iteration 5684 : loss : 0.020571, loss_ce: 0.011993
2021-12-11 22:01:22,065 iteration 5685 : loss : 0.025767, loss_ce: 0.007553
2021-12-11 22:01:23,632 iteration 5686 : loss : 0.015801, loss_ce: 0.005533
2021-12-11 22:01:25,226 iteration 5687 : loss : 0.018949, loss_ce: 0.005440
2021-12-11 22:01:26,874 iteration 5688 : loss : 0.027477, loss_ce: 0.011215
2021-12-11 22:01:28,411 iteration 5689 : loss : 0.013950, loss_ce: 0.005783
2021-12-11 22:01:29,903 iteration 5690 : loss : 0.015814, loss_ce: 0.005617
2021-12-11 22:01:31,493 iteration 5691 : loss : 0.014432, loss_ce: 0.006221
2021-12-11 22:01:33,053 iteration 5692 : loss : 0.012015, loss_ce: 0.003581
2021-12-11 22:01:34,477 iteration 5693 : loss : 0.012656, loss_ce: 0.005222
2021-12-11 22:01:36,050 iteration 5694 : loss : 0.018568, loss_ce: 0.007762
2021-12-11 22:01:36,051 Training Data Eval:
2021-12-11 22:01:43,802   Average segmentation loss on training set: 0.0105
2021-12-11 22:01:43,803 Validation Data Eval:
2021-12-11 22:01:46,453   Average segmentation loss on validation set: 0.0733
2021-12-11 22:01:48,006 iteration 5695 : loss : 0.023458, loss_ce: 0.009150
 84%|████████████████████████▎    | 335/400 [2:41:32<32:58, 30.44s/it]2021-12-11 22:01:49,633 iteration 5696 : loss : 0.020337, loss_ce: 0.006045
2021-12-11 22:01:51,141 iteration 5697 : loss : 0.013946, loss_ce: 0.004130
2021-12-11 22:01:52,771 iteration 5698 : loss : 0.020035, loss_ce: 0.007075
2021-12-11 22:01:54,419 iteration 5699 : loss : 0.021569, loss_ce: 0.005352
2021-12-11 22:01:55,889 iteration 5700 : loss : 0.014268, loss_ce: 0.006061
2021-12-11 22:01:57,569 iteration 5701 : loss : 0.026915, loss_ce: 0.005065
2021-12-11 22:01:59,160 iteration 5702 : loss : 0.015632, loss_ce: 0.005762
2021-12-11 22:02:00,799 iteration 5703 : loss : 0.017232, loss_ce: 0.006674
2021-12-11 22:02:02,322 iteration 5704 : loss : 0.017859, loss_ce: 0.007124
2021-12-11 22:02:03,850 iteration 5705 : loss : 0.014363, loss_ce: 0.005803
2021-12-11 22:02:05,353 iteration 5706 : loss : 0.018438, loss_ce: 0.007551
2021-12-11 22:02:06,944 iteration 5707 : loss : 0.026584, loss_ce: 0.007276
2021-12-11 22:02:08,501 iteration 5708 : loss : 0.018441, loss_ce: 0.009637
2021-12-11 22:02:10,006 iteration 5709 : loss : 0.015560, loss_ce: 0.005247
2021-12-11 22:02:11,535 iteration 5710 : loss : 0.017436, loss_ce: 0.008509
2021-12-11 22:02:13,101 iteration 5711 : loss : 0.011572, loss_ce: 0.004875
2021-12-11 22:02:14,676 iteration 5712 : loss : 0.016996, loss_ce: 0.007109
 84%|████████████████████████▎    | 336/400 [2:41:59<31:15, 29.31s/it]2021-12-11 22:02:16,312 iteration 5713 : loss : 0.013314, loss_ce: 0.005702
2021-12-11 22:02:17,902 iteration 5714 : loss : 0.017645, loss_ce: 0.005442
2021-12-11 22:02:19,411 iteration 5715 : loss : 0.015917, loss_ce: 0.006208
2021-12-11 22:02:21,018 iteration 5716 : loss : 0.021047, loss_ce: 0.007636
2021-12-11 22:02:22,507 iteration 5717 : loss : 0.012974, loss_ce: 0.004848
2021-12-11 22:02:24,018 iteration 5718 : loss : 0.022918, loss_ce: 0.010693
2021-12-11 22:02:25,618 iteration 5719 : loss : 0.020798, loss_ce: 0.006044
2021-12-11 22:02:27,247 iteration 5720 : loss : 0.031139, loss_ce: 0.012723
2021-12-11 22:02:28,745 iteration 5721 : loss : 0.016818, loss_ce: 0.004728
2021-12-11 22:02:30,348 iteration 5722 : loss : 0.020210, loss_ce: 0.007886
2021-12-11 22:02:31,980 iteration 5723 : loss : 0.021430, loss_ce: 0.008026
2021-12-11 22:02:33,567 iteration 5724 : loss : 0.018494, loss_ce: 0.009419
2021-12-11 22:02:35,106 iteration 5725 : loss : 0.016691, loss_ce: 0.006604
2021-12-11 22:02:36,718 iteration 5726 : loss : 0.012852, loss_ce: 0.005104
2021-12-11 22:02:38,304 iteration 5727 : loss : 0.021414, loss_ce: 0.011024
2021-12-11 22:02:39,824 iteration 5728 : loss : 0.016048, loss_ce: 0.004780
2021-12-11 22:02:41,298 iteration 5729 : loss : 0.016823, loss_ce: 0.004585
 84%|████████████████████████▍    | 337/400 [2:42:26<29:55, 28.50s/it]2021-12-11 22:02:43,019 iteration 5730 : loss : 0.025231, loss_ce: 0.012255
2021-12-11 22:02:44,663 iteration 5731 : loss : 0.025172, loss_ce: 0.009009
2021-12-11 22:02:46,263 iteration 5732 : loss : 0.022781, loss_ce: 0.005253
2021-12-11 22:02:47,816 iteration 5733 : loss : 0.018142, loss_ce: 0.006934
2021-12-11 22:02:49,342 iteration 5734 : loss : 0.011257, loss_ce: 0.003916
2021-12-11 22:02:51,014 iteration 5735 : loss : 0.021674, loss_ce: 0.006953
2021-12-11 22:02:52,658 iteration 5736 : loss : 0.026790, loss_ce: 0.009694
2021-12-11 22:02:54,212 iteration 5737 : loss : 0.018666, loss_ce: 0.007495
2021-12-11 22:02:55,738 iteration 5738 : loss : 0.014792, loss_ce: 0.006498
2021-12-11 22:02:57,316 iteration 5739 : loss : 0.017754, loss_ce: 0.005054
2021-12-11 22:02:58,940 iteration 5740 : loss : 0.018071, loss_ce: 0.007586
2021-12-11 22:03:00,517 iteration 5741 : loss : 0.012595, loss_ce: 0.005265
2021-12-11 22:03:02,041 iteration 5742 : loss : 0.020923, loss_ce: 0.004226
2021-12-11 22:03:03,618 iteration 5743 : loss : 0.018679, loss_ce: 0.005524
2021-12-11 22:03:05,144 iteration 5744 : loss : 0.018840, loss_ce: 0.008497
2021-12-11 22:03:06,731 iteration 5745 : loss : 0.012927, loss_ce: 0.004047
2021-12-11 22:03:08,255 iteration 5746 : loss : 0.019737, loss_ce: 0.009465
 84%|████████████████████████▌    | 338/400 [2:42:53<28:58, 28.04s/it]2021-12-11 22:03:09,921 iteration 5747 : loss : 0.021468, loss_ce: 0.008084
2021-12-11 22:03:11,453 iteration 5748 : loss : 0.016390, loss_ce: 0.006117
2021-12-11 22:03:13,075 iteration 5749 : loss : 0.027694, loss_ce: 0.013192
2021-12-11 22:03:14,656 iteration 5750 : loss : 0.014051, loss_ce: 0.003853
2021-12-11 22:03:16,289 iteration 5751 : loss : 0.021340, loss_ce: 0.008356
2021-12-11 22:03:17,867 iteration 5752 : loss : 0.019690, loss_ce: 0.006050
2021-12-11 22:03:19,478 iteration 5753 : loss : 0.024853, loss_ce: 0.012571
2021-12-11 22:03:21,032 iteration 5754 : loss : 0.016236, loss_ce: 0.005487
2021-12-11 22:03:22,561 iteration 5755 : loss : 0.020301, loss_ce: 0.006329
2021-12-11 22:03:24,081 iteration 5756 : loss : 0.020228, loss_ce: 0.009788
2021-12-11 22:03:25,658 iteration 5757 : loss : 0.019470, loss_ce: 0.006240
2021-12-11 22:03:27,153 iteration 5758 : loss : 0.010765, loss_ce: 0.003060
2021-12-11 22:03:28,784 iteration 5759 : loss : 0.041543, loss_ce: 0.011898
2021-12-11 22:03:30,340 iteration 5760 : loss : 0.013928, loss_ce: 0.005085
2021-12-11 22:03:31,933 iteration 5761 : loss : 0.017655, loss_ce: 0.006531
2021-12-11 22:03:33,575 iteration 5762 : loss : 0.018812, loss_ce: 0.008358
2021-12-11 22:03:35,171 iteration 5763 : loss : 0.021611, loss_ce: 0.008572
 85%|████████████████████████▌    | 339/400 [2:43:20<28:09, 27.70s/it]2021-12-11 22:03:36,868 iteration 5764 : loss : 0.019788, loss_ce: 0.010263
2021-12-11 22:03:38,454 iteration 5765 : loss : 0.022658, loss_ce: 0.007766
2021-12-11 22:03:39,986 iteration 5766 : loss : 0.017550, loss_ce: 0.006066
2021-12-11 22:03:41,600 iteration 5767 : loss : 0.024304, loss_ce: 0.009812
2021-12-11 22:03:43,216 iteration 5768 : loss : 0.029467, loss_ce: 0.009488
2021-12-11 22:03:44,815 iteration 5769 : loss : 0.020013, loss_ce: 0.004936
2021-12-11 22:03:46,420 iteration 5770 : loss : 0.022336, loss_ce: 0.008936
2021-12-11 22:03:47,898 iteration 5771 : loss : 0.013094, loss_ce: 0.005271
2021-12-11 22:03:49,480 iteration 5772 : loss : 0.014061, loss_ce: 0.005091
2021-12-11 22:03:50,958 iteration 5773 : loss : 0.014635, loss_ce: 0.004997
2021-12-11 22:03:52,473 iteration 5774 : loss : 0.015313, loss_ce: 0.005779
2021-12-11 22:03:54,053 iteration 5775 : loss : 0.022748, loss_ce: 0.008587
2021-12-11 22:03:55,503 iteration 5776 : loss : 0.014662, loss_ce: 0.005562
2021-12-11 22:03:57,034 iteration 5777 : loss : 0.014000, loss_ce: 0.004522
2021-12-11 22:03:58,629 iteration 5778 : loss : 0.017761, loss_ce: 0.006236
2021-12-11 22:04:00,200 iteration 5779 : loss : 0.012633, loss_ce: 0.005236
2021-12-11 22:04:00,200 Training Data Eval:
2021-12-11 22:04:07,947   Average segmentation loss on training set: 0.0104
2021-12-11 22:04:07,948 Validation Data Eval:
2021-12-11 22:04:10,605   Average segmentation loss on validation set: 0.0789
2021-12-11 22:04:12,142 iteration 5780 : loss : 0.015732, loss_ce: 0.005759
 85%|████████████████████████▋    | 340/400 [2:43:56<30:29, 30.48s/it]2021-12-11 22:04:13,760 iteration 5781 : loss : 0.017812, loss_ce: 0.005980
2021-12-11 22:04:15,223 iteration 5782 : loss : 0.011529, loss_ce: 0.003964
2021-12-11 22:04:16,800 iteration 5783 : loss : 0.015815, loss_ce: 0.004848
2021-12-11 22:04:18,399 iteration 5784 : loss : 0.013050, loss_ce: 0.004032
2021-12-11 22:04:19,975 iteration 5785 : loss : 0.013972, loss_ce: 0.006086
2021-12-11 22:04:21,611 iteration 5786 : loss : 0.016128, loss_ce: 0.006393
2021-12-11 22:04:23,173 iteration 5787 : loss : 0.018461, loss_ce: 0.005214
2021-12-11 22:04:24,745 iteration 5788 : loss : 0.017760, loss_ce: 0.007083
2021-12-11 22:04:26,308 iteration 5789 : loss : 0.023099, loss_ce: 0.006746
2021-12-11 22:04:27,912 iteration 5790 : loss : 0.018586, loss_ce: 0.007984
2021-12-11 22:04:29,514 iteration 5791 : loss : 0.013352, loss_ce: 0.004766
2021-12-11 22:04:31,165 iteration 5792 : loss : 0.019364, loss_ce: 0.006177
2021-12-11 22:04:32,683 iteration 5793 : loss : 0.014463, loss_ce: 0.005406
2021-12-11 22:04:34,202 iteration 5794 : loss : 0.014811, loss_ce: 0.004527
2021-12-11 22:04:35,746 iteration 5795 : loss : 0.016358, loss_ce: 0.007453
2021-12-11 22:04:37,289 iteration 5796 : loss : 0.013318, loss_ce: 0.005074
2021-12-11 22:04:38,816 iteration 5797 : loss : 0.013495, loss_ce: 0.004676
 85%|████████████████████████▋    | 341/400 [2:44:23<28:51, 29.34s/it]2021-12-11 22:04:40,382 iteration 5798 : loss : 0.013495, loss_ce: 0.004326
2021-12-11 22:04:41,894 iteration 5799 : loss : 0.013704, loss_ce: 0.005284
2021-12-11 22:04:43,342 iteration 5800 : loss : 0.010480, loss_ce: 0.004050
2021-12-11 22:04:44,897 iteration 5801 : loss : 0.016727, loss_ce: 0.007701
2021-12-11 22:04:46,398 iteration 5802 : loss : 0.013086, loss_ce: 0.005278
2021-12-11 22:04:47,992 iteration 5803 : loss : 0.017195, loss_ce: 0.005598
2021-12-11 22:04:49,496 iteration 5804 : loss : 0.016991, loss_ce: 0.006864
2021-12-11 22:04:50,996 iteration 5805 : loss : 0.013485, loss_ce: 0.004389
2021-12-11 22:04:52,483 iteration 5806 : loss : 0.013321, loss_ce: 0.005584
2021-12-11 22:04:54,062 iteration 5807 : loss : 0.031348, loss_ce: 0.010061
2021-12-11 22:04:55,674 iteration 5808 : loss : 0.022186, loss_ce: 0.007378
2021-12-11 22:04:57,289 iteration 5809 : loss : 0.020524, loss_ce: 0.007856
2021-12-11 22:04:58,959 iteration 5810 : loss : 0.023424, loss_ce: 0.006193
2021-12-11 22:05:00,546 iteration 5811 : loss : 0.025881, loss_ce: 0.010352
2021-12-11 22:05:02,090 iteration 5812 : loss : 0.021929, loss_ce: 0.009488
2021-12-11 22:05:03,606 iteration 5813 : loss : 0.013573, loss_ce: 0.003817
2021-12-11 22:05:05,141 iteration 5814 : loss : 0.019389, loss_ce: 0.006693
 86%|████████████████████████▊    | 342/400 [2:44:49<27:29, 28.44s/it]2021-12-11 22:05:06,835 iteration 5815 : loss : 0.024925, loss_ce: 0.009244
2021-12-11 22:05:08,387 iteration 5816 : loss : 0.013862, loss_ce: 0.005205
2021-12-11 22:05:10,036 iteration 5817 : loss : 0.018582, loss_ce: 0.008100
2021-12-11 22:05:11,653 iteration 5818 : loss : 0.019291, loss_ce: 0.006667
2021-12-11 22:05:13,193 iteration 5819 : loss : 0.013450, loss_ce: 0.003583
2021-12-11 22:05:14,725 iteration 5820 : loss : 0.017490, loss_ce: 0.006532
2021-12-11 22:05:16,318 iteration 5821 : loss : 0.016738, loss_ce: 0.005562
2021-12-11 22:05:17,976 iteration 5822 : loss : 0.020457, loss_ce: 0.006717
2021-12-11 22:05:19,484 iteration 5823 : loss : 0.013946, loss_ce: 0.006174
2021-12-11 22:05:21,151 iteration 5824 : loss : 0.025700, loss_ce: 0.006204
2021-12-11 22:05:22,740 iteration 5825 : loss : 0.013014, loss_ce: 0.004377
2021-12-11 22:05:24,329 iteration 5826 : loss : 0.013884, loss_ce: 0.005821
2021-12-11 22:05:25,834 iteration 5827 : loss : 0.016701, loss_ce: 0.005912
2021-12-11 22:05:27,492 iteration 5828 : loss : 0.026129, loss_ce: 0.005568
2021-12-11 22:05:29,054 iteration 5829 : loss : 0.015242, loss_ce: 0.005339
2021-12-11 22:05:30,559 iteration 5830 : loss : 0.016698, loss_ce: 0.005615
2021-12-11 22:05:32,205 iteration 5831 : loss : 0.024224, loss_ce: 0.008866
 86%|████████████████████████▊    | 343/400 [2:45:17<26:37, 28.02s/it]2021-12-11 22:05:33,884 iteration 5832 : loss : 0.015684, loss_ce: 0.006460
2021-12-11 22:05:35,527 iteration 5833 : loss : 0.021542, loss_ce: 0.007541
2021-12-11 22:05:37,097 iteration 5834 : loss : 0.014782, loss_ce: 0.006828
2021-12-11 22:05:38,655 iteration 5835 : loss : 0.018720, loss_ce: 0.007402
2021-12-11 22:05:40,192 iteration 5836 : loss : 0.025131, loss_ce: 0.008347
2021-12-11 22:05:41,835 iteration 5837 : loss : 0.020097, loss_ce: 0.006732
2021-12-11 22:05:43,406 iteration 5838 : loss : 0.017483, loss_ce: 0.004769
2021-12-11 22:05:44,980 iteration 5839 : loss : 0.026053, loss_ce: 0.009127
2021-12-11 22:05:46,549 iteration 5840 : loss : 0.013743, loss_ce: 0.004741
2021-12-11 22:05:48,170 iteration 5841 : loss : 0.020314, loss_ce: 0.006672
2021-12-11 22:05:49,674 iteration 5842 : loss : 0.013709, loss_ce: 0.004417
2021-12-11 22:05:51,171 iteration 5843 : loss : 0.013913, loss_ce: 0.005034
2021-12-11 22:05:52,740 iteration 5844 : loss : 0.017618, loss_ce: 0.006595
2021-12-11 22:05:54,238 iteration 5845 : loss : 0.011936, loss_ce: 0.003947
2021-12-11 22:05:55,734 iteration 5846 : loss : 0.013960, loss_ce: 0.005558
2021-12-11 22:05:57,246 iteration 5847 : loss : 0.015650, loss_ce: 0.005987
2021-12-11 22:05:58,763 iteration 5848 : loss : 0.015779, loss_ce: 0.005104
 86%|████████████████████████▉    | 344/400 [2:45:43<25:44, 27.58s/it]2021-12-11 22:06:00,385 iteration 5849 : loss : 0.018295, loss_ce: 0.005486
2021-12-11 22:06:02,022 iteration 5850 : loss : 0.027408, loss_ce: 0.012222
2021-12-11 22:06:03,624 iteration 5851 : loss : 0.014507, loss_ce: 0.003727
2021-12-11 22:06:05,201 iteration 5852 : loss : 0.015697, loss_ce: 0.006760
2021-12-11 22:06:06,716 iteration 5853 : loss : 0.016580, loss_ce: 0.005286
2021-12-11 22:06:08,330 iteration 5854 : loss : 0.016163, loss_ce: 0.005636
2021-12-11 22:06:09,882 iteration 5855 : loss : 0.014371, loss_ce: 0.006564
2021-12-11 22:06:11,442 iteration 5856 : loss : 0.023897, loss_ce: 0.011431
2021-12-11 22:06:13,033 iteration 5857 : loss : 0.016010, loss_ce: 0.005550
2021-12-11 22:06:14,637 iteration 5858 : loss : 0.014611, loss_ce: 0.004650
2021-12-11 22:06:16,296 iteration 5859 : loss : 0.023397, loss_ce: 0.007042
2021-12-11 22:06:17,882 iteration 5860 : loss : 0.014790, loss_ce: 0.004986
2021-12-11 22:06:19,415 iteration 5861 : loss : 0.019962, loss_ce: 0.008967
2021-12-11 22:06:20,992 iteration 5862 : loss : 0.015300, loss_ce: 0.005806
2021-12-11 22:06:22,567 iteration 5863 : loss : 0.024635, loss_ce: 0.007486
2021-12-11 22:06:24,240 iteration 5864 : loss : 0.017708, loss_ce: 0.007840
2021-12-11 22:06:24,240 Training Data Eval:
2021-12-11 22:06:31,990   Average segmentation loss on training set: 0.0101
2021-12-11 22:06:31,991 Validation Data Eval:
2021-12-11 22:06:34,646   Average segmentation loss on validation set: 0.0878
2021-12-11 22:06:36,303 iteration 5865 : loss : 0.025112, loss_ce: 0.007635
 86%|█████████████████████████    | 345/400 [2:46:21<28:01, 30.57s/it]2021-12-11 22:06:37,863 iteration 5866 : loss : 0.015745, loss_ce: 0.003581
2021-12-11 22:06:39,388 iteration 5867 : loss : 0.012413, loss_ce: 0.004676
2021-12-11 22:06:40,970 iteration 5868 : loss : 0.016279, loss_ce: 0.006010
2021-12-11 22:06:42,497 iteration 5869 : loss : 0.018759, loss_ce: 0.006275
2021-12-11 22:06:44,172 iteration 5870 : loss : 0.028208, loss_ce: 0.010032
2021-12-11 22:06:45,723 iteration 5871 : loss : 0.013593, loss_ce: 0.004594
2021-12-11 22:06:47,247 iteration 5872 : loss : 0.015330, loss_ce: 0.004539
2021-12-11 22:06:48,828 iteration 5873 : loss : 0.020021, loss_ce: 0.012849
2021-12-11 22:06:50,409 iteration 5874 : loss : 0.015807, loss_ce: 0.005199
2021-12-11 22:06:51,995 iteration 5875 : loss : 0.012426, loss_ce: 0.005508
2021-12-11 22:06:53,659 iteration 5876 : loss : 0.018977, loss_ce: 0.007908
2021-12-11 22:06:55,284 iteration 5877 : loss : 0.020871, loss_ce: 0.009125
2021-12-11 22:06:56,785 iteration 5878 : loss : 0.017029, loss_ce: 0.005194
2021-12-11 22:06:58,334 iteration 5879 : loss : 0.022111, loss_ce: 0.008427
2021-12-11 22:06:59,929 iteration 5880 : loss : 0.021827, loss_ce: 0.005744
2021-12-11 22:07:01,450 iteration 5881 : loss : 0.015196, loss_ce: 0.005748
2021-12-11 22:07:02,943 iteration 5882 : loss : 0.016118, loss_ce: 0.005210
 86%|█████████████████████████    | 346/400 [2:46:47<26:27, 29.39s/it]2021-12-11 22:07:04,514 iteration 5883 : loss : 0.014884, loss_ce: 0.004734
2021-12-11 22:07:05,974 iteration 5884 : loss : 0.014094, loss_ce: 0.004722
2021-12-11 22:07:07,604 iteration 5885 : loss : 0.019830, loss_ce: 0.004562
2021-12-11 22:07:09,149 iteration 5886 : loss : 0.021691, loss_ce: 0.006411
2021-12-11 22:07:10,755 iteration 5887 : loss : 0.018378, loss_ce: 0.006130
2021-12-11 22:07:12,316 iteration 5888 : loss : 0.011040, loss_ce: 0.004378
2021-12-11 22:07:13,953 iteration 5889 : loss : 0.013914, loss_ce: 0.004499
2021-12-11 22:07:15,496 iteration 5890 : loss : 0.019197, loss_ce: 0.008313
2021-12-11 22:07:17,058 iteration 5891 : loss : 0.019775, loss_ce: 0.005894
2021-12-11 22:07:18,653 iteration 5892 : loss : 0.018075, loss_ce: 0.004840
2021-12-11 22:07:20,184 iteration 5893 : loss : 0.018474, loss_ce: 0.007463
2021-12-11 22:07:21,681 iteration 5894 : loss : 0.016506, loss_ce: 0.006720
2021-12-11 22:07:23,170 iteration 5895 : loss : 0.012877, loss_ce: 0.004653
2021-12-11 22:07:24,670 iteration 5896 : loss : 0.019783, loss_ce: 0.007226
2021-12-11 22:07:26,220 iteration 5897 : loss : 0.015815, loss_ce: 0.007059
2021-12-11 22:07:27,731 iteration 5898 : loss : 0.027462, loss_ce: 0.009891
2021-12-11 22:07:29,332 iteration 5899 : loss : 0.018775, loss_ce: 0.007531
 87%|█████████████████████████▏   | 347/400 [2:47:14<25:09, 28.49s/it]2021-12-11 22:07:30,864 iteration 5900 : loss : 0.016918, loss_ce: 0.005590
2021-12-11 22:07:32,525 iteration 5901 : loss : 0.015782, loss_ce: 0.005965
2021-12-11 22:07:34,185 iteration 5902 : loss : 0.022576, loss_ce: 0.010998
2021-12-11 22:07:35,731 iteration 5903 : loss : 0.023494, loss_ce: 0.007954
2021-12-11 22:07:37,302 iteration 5904 : loss : 0.018251, loss_ce: 0.006925
2021-12-11 22:07:38,799 iteration 5905 : loss : 0.014669, loss_ce: 0.005178
2021-12-11 22:07:40,350 iteration 5906 : loss : 0.016836, loss_ce: 0.006698
2021-12-11 22:07:41,928 iteration 5907 : loss : 0.017296, loss_ce: 0.006459
2021-12-11 22:07:43,480 iteration 5908 : loss : 0.016963, loss_ce: 0.005941
2021-12-11 22:07:44,991 iteration 5909 : loss : 0.012442, loss_ce: 0.004872
2021-12-11 22:07:46,524 iteration 5910 : loss : 0.014481, loss_ce: 0.006108
2021-12-11 22:07:48,070 iteration 5911 : loss : 0.016702, loss_ce: 0.005508
2021-12-11 22:07:49,770 iteration 5912 : loss : 0.039532, loss_ce: 0.006442
2021-12-11 22:07:51,258 iteration 5913 : loss : 0.018580, loss_ce: 0.006245
2021-12-11 22:07:52,906 iteration 5914 : loss : 0.014500, loss_ce: 0.004903
2021-12-11 22:07:54,520 iteration 5915 : loss : 0.018672, loss_ce: 0.007754
2021-12-11 22:07:56,078 iteration 5916 : loss : 0.016016, loss_ce: 0.005699
 87%|█████████████████████████▏   | 348/400 [2:47:40<24:14, 27.97s/it]2021-12-11 22:07:57,687 iteration 5917 : loss : 0.019327, loss_ce: 0.005017
2021-12-11 22:07:59,350 iteration 5918 : loss : 0.024096, loss_ce: 0.008095
2021-12-11 22:08:00,860 iteration 5919 : loss : 0.016849, loss_ce: 0.009897
2021-12-11 22:08:02,534 iteration 5920 : loss : 0.021094, loss_ce: 0.008491
2021-12-11 22:08:04,079 iteration 5921 : loss : 0.014827, loss_ce: 0.004524
2021-12-11 22:08:05,696 iteration 5922 : loss : 0.021174, loss_ce: 0.008922
2021-12-11 22:08:07,238 iteration 5923 : loss : 0.022971, loss_ce: 0.006633
2021-12-11 22:08:08,748 iteration 5924 : loss : 0.012898, loss_ce: 0.005127
2021-12-11 22:08:10,279 iteration 5925 : loss : 0.015997, loss_ce: 0.004926
2021-12-11 22:08:11,827 iteration 5926 : loss : 0.013645, loss_ce: 0.005009
2021-12-11 22:08:13,460 iteration 5927 : loss : 0.020533, loss_ce: 0.008721
2021-12-11 22:08:14,923 iteration 5928 : loss : 0.013120, loss_ce: 0.005385
2021-12-11 22:08:16,433 iteration 5929 : loss : 0.015010, loss_ce: 0.004147
2021-12-11 22:08:18,001 iteration 5930 : loss : 0.015711, loss_ce: 0.005221
2021-12-11 22:08:19,574 iteration 5931 : loss : 0.016673, loss_ce: 0.006880
2021-12-11 22:08:21,118 iteration 5932 : loss : 0.016814, loss_ce: 0.007230
2021-12-11 22:08:22,632 iteration 5933 : loss : 0.011666, loss_ce: 0.004301
 87%|█████████████████████████▎   | 349/400 [2:48:07<23:24, 27.54s/it]2021-12-11 22:08:24,177 iteration 5934 : loss : 0.012678, loss_ce: 0.004368
2021-12-11 22:08:25,667 iteration 5935 : loss : 0.014278, loss_ce: 0.006602
2021-12-11 22:08:27,142 iteration 5936 : loss : 0.019368, loss_ce: 0.007513
2021-12-11 22:08:28,729 iteration 5937 : loss : 0.019557, loss_ce: 0.008449
2021-12-11 22:08:30,313 iteration 5938 : loss : 0.019182, loss_ce: 0.008609
2021-12-11 22:08:31,940 iteration 5939 : loss : 0.025105, loss_ce: 0.008687
2021-12-11 22:08:33,465 iteration 5940 : loss : 0.012597, loss_ce: 0.004645
2021-12-11 22:08:35,067 iteration 5941 : loss : 0.015746, loss_ce: 0.005516
2021-12-11 22:08:36,636 iteration 5942 : loss : 0.013586, loss_ce: 0.005247
2021-12-11 22:08:38,243 iteration 5943 : loss : 0.013831, loss_ce: 0.005009
2021-12-11 22:08:39,705 iteration 5944 : loss : 0.015730, loss_ce: 0.006239
2021-12-11 22:08:41,392 iteration 5945 : loss : 0.034356, loss_ce: 0.010657
2021-12-11 22:08:42,971 iteration 5946 : loss : 0.012938, loss_ce: 0.004934
2021-12-11 22:08:44,657 iteration 5947 : loss : 0.026106, loss_ce: 0.009407
2021-12-11 22:08:46,295 iteration 5948 : loss : 0.024542, loss_ce: 0.007903
2021-12-11 22:08:47,855 iteration 5949 : loss : 0.019104, loss_ce: 0.005339
2021-12-11 22:08:47,855 Training Data Eval:
2021-12-11 22:08:55,613   Average segmentation loss on training set: 0.0100
2021-12-11 22:08:55,613 Validation Data Eval:
2021-12-11 22:08:58,276   Average segmentation loss on validation set: 0.0946
2021-12-11 22:08:59,768 iteration 5950 : loss : 0.013503, loss_ce: 0.004278
2021-12-11 22:09:01,732 save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/NEW_TU/UNET_ADAM_seed2epoch_349.pth
 88%|█████████████████████████▍   | 350/400 [2:48:46<25:49, 30.99s/it]2021-12-11 22:09:03,225 iteration 5951 : loss : 0.016717, loss_ce: 0.004830
2021-12-11 22:09:04,801 iteration 5952 : loss : 0.017105, loss_ce: 0.008081
2021-12-11 22:09:06,471 iteration 5953 : loss : 0.021685, loss_ce: 0.009886
2021-12-11 22:09:08,002 iteration 5954 : loss : 0.017333, loss_ce: 0.003983
2021-12-11 22:09:09,686 iteration 5955 : loss : 0.025323, loss_ce: 0.009243
2021-12-11 22:09:11,218 iteration 5956 : loss : 0.020049, loss_ce: 0.005071
2021-12-11 22:09:12,817 iteration 5957 : loss : 0.019789, loss_ce: 0.008767
2021-12-11 22:09:14,429 iteration 5958 : loss : 0.022766, loss_ce: 0.009503
2021-12-11 22:09:16,032 iteration 5959 : loss : 0.018734, loss_ce: 0.004068
2021-12-11 22:09:17,564 iteration 5960 : loss : 0.019700, loss_ce: 0.004389
2021-12-11 22:09:19,173 iteration 5961 : loss : 0.021082, loss_ce: 0.010496
2021-12-11 22:09:20,772 iteration 5962 : loss : 0.017900, loss_ce: 0.006571
2021-12-11 22:09:22,302 iteration 5963 : loss : 0.018483, loss_ce: 0.005995
2021-12-11 22:09:23,932 iteration 5964 : loss : 0.031928, loss_ce: 0.012217
2021-12-11 22:09:25,531 iteration 5965 : loss : 0.014179, loss_ce: 0.006850
2021-12-11 22:09:27,067 iteration 5966 : loss : 0.011819, loss_ce: 0.004015
2021-12-11 22:09:28,724 iteration 5967 : loss : 0.023062, loss_ce: 0.009040
 88%|█████████████████████████▍   | 351/400 [2:49:13<24:20, 29.81s/it]2021-12-11 22:09:30,330 iteration 5968 : loss : 0.015976, loss_ce: 0.005473
2021-12-11 22:09:31,872 iteration 5969 : loss : 0.017070, loss_ce: 0.008589
2021-12-11 22:09:33,461 iteration 5970 : loss : 0.019937, loss_ce: 0.008229
2021-12-11 22:09:34,977 iteration 5971 : loss : 0.012852, loss_ce: 0.005330
2021-12-11 22:09:36,475 iteration 5972 : loss : 0.014197, loss_ce: 0.003756
2021-12-11 22:09:37,977 iteration 5973 : loss : 0.020172, loss_ce: 0.009579
2021-12-11 22:09:39,524 iteration 5974 : loss : 0.025290, loss_ce: 0.006259
2021-12-11 22:09:41,091 iteration 5975 : loss : 0.015491, loss_ce: 0.008986
2021-12-11 22:09:42,687 iteration 5976 : loss : 0.022650, loss_ce: 0.007211
2021-12-11 22:09:44,183 iteration 5977 : loss : 0.016350, loss_ce: 0.005718
2021-12-11 22:09:45,714 iteration 5978 : loss : 0.016334, loss_ce: 0.006417
2021-12-11 22:09:47,271 iteration 5979 : loss : 0.017179, loss_ce: 0.004323
2021-12-11 22:09:48,900 iteration 5980 : loss : 0.023311, loss_ce: 0.005225
2021-12-11 22:09:50,557 iteration 5981 : loss : 0.021629, loss_ce: 0.009457
2021-12-11 22:09:52,142 iteration 5982 : loss : 0.021763, loss_ce: 0.010382
2021-12-11 22:09:53,721 iteration 5983 : loss : 0.017473, loss_ce: 0.004879
2021-12-11 22:09:55,361 iteration 5984 : loss : 0.025471, loss_ce: 0.008482
 88%|█████████████████████████▌   | 352/400 [2:49:40<23:05, 28.86s/it]2021-12-11 22:09:57,031 iteration 5985 : loss : 0.021753, loss_ce: 0.008045
2021-12-11 22:09:58,485 iteration 5986 : loss : 0.015571, loss_ce: 0.008787
2021-12-11 22:10:00,109 iteration 5987 : loss : 0.027143, loss_ce: 0.008287
2021-12-11 22:10:01,597 iteration 5988 : loss : 0.013369, loss_ce: 0.005316
2021-12-11 22:10:03,178 iteration 5989 : loss : 0.015423, loss_ce: 0.005868
2021-12-11 22:10:04,733 iteration 5990 : loss : 0.023793, loss_ce: 0.006784
2021-12-11 22:10:06,381 iteration 5991 : loss : 0.021011, loss_ce: 0.005106
2021-12-11 22:10:08,013 iteration 5992 : loss : 0.030689, loss_ce: 0.007190
2021-12-11 22:10:09,561 iteration 5993 : loss : 0.020238, loss_ce: 0.008115
2021-12-11 22:10:11,034 iteration 5994 : loss : 0.012549, loss_ce: 0.005426
2021-12-11 22:10:12,696 iteration 5995 : loss : 0.014543, loss_ce: 0.004694
2021-12-11 22:10:14,303 iteration 5996 : loss : 0.014617, loss_ce: 0.007644
2021-12-11 22:10:15,819 iteration 5997 : loss : 0.016580, loss_ce: 0.004535
2021-12-11 22:10:17,530 iteration 5998 : loss : 0.018917, loss_ce: 0.006930
2021-12-11 22:10:19,070 iteration 5999 : loss : 0.022730, loss_ce: 0.008182
2021-12-11 22:10:20,768 iteration 6000 : loss : 0.021027, loss_ce: 0.008620
2021-12-11 22:10:22,273 iteration 6001 : loss : 0.011802, loss_ce: 0.004367
 88%|█████████████████████████▌   | 353/400 [2:50:07<22:08, 28.27s/it]2021-12-11 22:10:23,822 iteration 6002 : loss : 0.015184, loss_ce: 0.005542
2021-12-11 22:10:25,407 iteration 6003 : loss : 0.012567, loss_ce: 0.005495
2021-12-11 22:10:26,946 iteration 6004 : loss : 0.016109, loss_ce: 0.006511
2021-12-11 22:10:28,470 iteration 6005 : loss : 0.015761, loss_ce: 0.005729
2021-12-11 22:10:30,086 iteration 6006 : loss : 0.019099, loss_ce: 0.005571
2021-12-11 22:10:31,597 iteration 6007 : loss : 0.015061, loss_ce: 0.006051
2021-12-11 22:10:33,146 iteration 6008 : loss : 0.017591, loss_ce: 0.006527
2021-12-11 22:10:34,749 iteration 6009 : loss : 0.020406, loss_ce: 0.006269
2021-12-11 22:10:36,251 iteration 6010 : loss : 0.015615, loss_ce: 0.003751
2021-12-11 22:10:37,851 iteration 6011 : loss : 0.019117, loss_ce: 0.006209
2021-12-11 22:10:39,491 iteration 6012 : loss : 0.016157, loss_ce: 0.006952
2021-12-11 22:10:41,041 iteration 6013 : loss : 0.019091, loss_ce: 0.006342
2021-12-11 22:10:42,558 iteration 6014 : loss : 0.014948, loss_ce: 0.005616
2021-12-11 22:10:44,029 iteration 6015 : loss : 0.012716, loss_ce: 0.006030
2021-12-11 22:10:45,559 iteration 6016 : loss : 0.013666, loss_ce: 0.004120
2021-12-11 22:10:47,116 iteration 6017 : loss : 0.018968, loss_ce: 0.006138
2021-12-11 22:10:48,581 iteration 6018 : loss : 0.014827, loss_ce: 0.005752
 88%|█████████████████████████▋   | 354/400 [2:50:33<21:13, 27.68s/it]2021-12-11 22:10:50,256 iteration 6019 : loss : 0.014775, loss_ce: 0.005217
2021-12-11 22:10:51,840 iteration 6020 : loss : 0.021997, loss_ce: 0.007016
2021-12-11 22:10:53,351 iteration 6021 : loss : 0.012545, loss_ce: 0.004430
2021-12-11 22:10:54,947 iteration 6022 : loss : 0.015917, loss_ce: 0.006090
2021-12-11 22:10:56,558 iteration 6023 : loss : 0.014253, loss_ce: 0.005542
2021-12-11 22:10:58,098 iteration 6024 : loss : 0.013564, loss_ce: 0.004841
2021-12-11 22:10:59,610 iteration 6025 : loss : 0.021363, loss_ce: 0.004264
2021-12-11 22:11:01,144 iteration 6026 : loss : 0.015403, loss_ce: 0.005202
2021-12-11 22:11:02,773 iteration 6027 : loss : 0.014484, loss_ce: 0.006473
2021-12-11 22:11:04,289 iteration 6028 : loss : 0.011819, loss_ce: 0.005060
2021-12-11 22:11:05,860 iteration 6029 : loss : 0.023693, loss_ce: 0.011098
2021-12-11 22:11:07,483 iteration 6030 : loss : 0.020198, loss_ce: 0.008184
2021-12-11 22:11:09,102 iteration 6031 : loss : 0.026651, loss_ce: 0.009313
2021-12-11 22:11:10,648 iteration 6032 : loss : 0.021315, loss_ce: 0.005514
2021-12-11 22:11:12,212 iteration 6033 : loss : 0.022032, loss_ce: 0.007539
2021-12-11 22:11:13,722 iteration 6034 : loss : 0.011321, loss_ce: 0.003807
2021-12-11 22:11:13,723 Training Data Eval:
2021-12-11 22:11:21,490   Average segmentation loss on training set: 0.0095
2021-12-11 22:11:21,491 Validation Data Eval:
2021-12-11 22:11:24,156   Average segmentation loss on validation set: 0.0728
2021-12-11 22:11:25,661 iteration 6035 : loss : 0.014545, loss_ce: 0.005879
 89%|█████████████████████████▋   | 355/400 [2:51:10<22:52, 30.51s/it]2021-12-11 22:11:27,304 iteration 6036 : loss : 0.014153, loss_ce: 0.006492
2021-12-11 22:11:28,804 iteration 6037 : loss : 0.011932, loss_ce: 0.004622
2021-12-11 22:11:30,325 iteration 6038 : loss : 0.013667, loss_ce: 0.004916
2021-12-11 22:11:31,779 iteration 6039 : loss : 0.013953, loss_ce: 0.004684
2021-12-11 22:11:33,298 iteration 6040 : loss : 0.017625, loss_ce: 0.005582
2021-12-11 22:11:34,915 iteration 6041 : loss : 0.017808, loss_ce: 0.006680
2021-12-11 22:11:36,417 iteration 6042 : loss : 0.016240, loss_ce: 0.004133
2021-12-11 22:11:37,886 iteration 6043 : loss : 0.011779, loss_ce: 0.003062
2021-12-11 22:11:39,482 iteration 6044 : loss : 0.014948, loss_ce: 0.004800
2021-12-11 22:11:41,008 iteration 6045 : loss : 0.015735, loss_ce: 0.007102
2021-12-11 22:11:42,569 iteration 6046 : loss : 0.020413, loss_ce: 0.008715
2021-12-11 22:11:44,098 iteration 6047 : loss : 0.012572, loss_ce: 0.004688
2021-12-11 22:11:45,705 iteration 6048 : loss : 0.018032, loss_ce: 0.007320
2021-12-11 22:11:47,250 iteration 6049 : loss : 0.013729, loss_ce: 0.006275
2021-12-11 22:11:48,776 iteration 6050 : loss : 0.018870, loss_ce: 0.006167
2021-12-11 22:11:50,408 iteration 6051 : loss : 0.013453, loss_ce: 0.004183
2021-12-11 22:11:51,919 iteration 6052 : loss : 0.016276, loss_ce: 0.007006
 89%|█████████████████████████▊   | 356/400 [2:51:36<21:26, 29.23s/it]2021-12-11 22:11:53,468 iteration 6053 : loss : 0.018799, loss_ce: 0.006448
2021-12-11 22:11:54,926 iteration 6054 : loss : 0.014736, loss_ce: 0.007062
2021-12-11 22:11:56,499 iteration 6055 : loss : 0.016813, loss_ce: 0.006240
2021-12-11 22:11:58,011 iteration 6056 : loss : 0.014152, loss_ce: 0.005226
2021-12-11 22:11:59,492 iteration 6057 : loss : 0.014438, loss_ce: 0.004275
2021-12-11 22:12:01,030 iteration 6058 : loss : 0.016457, loss_ce: 0.004724
2021-12-11 22:12:02,609 iteration 6059 : loss : 0.016714, loss_ce: 0.007438
2021-12-11 22:12:04,277 iteration 6060 : loss : 0.035047, loss_ce: 0.013147
2021-12-11 22:12:05,812 iteration 6061 : loss : 0.016186, loss_ce: 0.006552
2021-12-11 22:12:07,416 iteration 6062 : loss : 0.020951, loss_ce: 0.006950
2021-12-11 22:12:08,905 iteration 6063 : loss : 0.020389, loss_ce: 0.006237
2021-12-11 22:12:10,505 iteration 6064 : loss : 0.017498, loss_ce: 0.008077
2021-12-11 22:12:11,983 iteration 6065 : loss : 0.010635, loss_ce: 0.003874
2021-12-11 22:12:13,468 iteration 6066 : loss : 0.010164, loss_ce: 0.002897
2021-12-11 22:12:14,986 iteration 6067 : loss : 0.014526, loss_ce: 0.006150
2021-12-11 22:12:16,470 iteration 6068 : loss : 0.012650, loss_ce: 0.003226
2021-12-11 22:12:17,989 iteration 6069 : loss : 0.021933, loss_ce: 0.008028
 89%|█████████████████████████▉   | 357/400 [2:52:02<20:16, 28.28s/it]2021-12-11 22:12:19,579 iteration 6070 : loss : 0.011031, loss_ce: 0.005534
2021-12-11 22:12:21,056 iteration 6071 : loss : 0.012359, loss_ce: 0.004100
2021-12-11 22:12:22,596 iteration 6072 : loss : 0.013545, loss_ce: 0.006542
2021-12-11 22:12:24,128 iteration 6073 : loss : 0.014246, loss_ce: 0.005050
2021-12-11 22:12:25,687 iteration 6074 : loss : 0.019200, loss_ce: 0.007930
2021-12-11 22:12:27,136 iteration 6075 : loss : 0.011836, loss_ce: 0.004927
2021-12-11 22:12:28,646 iteration 6076 : loss : 0.013644, loss_ce: 0.003013
2021-12-11 22:12:30,184 iteration 6077 : loss : 0.016570, loss_ce: 0.005871
2021-12-11 22:12:31,763 iteration 6078 : loss : 0.022028, loss_ce: 0.007430
2021-12-11 22:12:33,396 iteration 6079 : loss : 0.031510, loss_ce: 0.012548
2021-12-11 22:12:34,938 iteration 6080 : loss : 0.016094, loss_ce: 0.005364
2021-12-11 22:12:36,506 iteration 6081 : loss : 0.022958, loss_ce: 0.009219
2021-12-11 22:12:37,960 iteration 6082 : loss : 0.015071, loss_ce: 0.004434
2021-12-11 22:12:39,442 iteration 6083 : loss : 0.014835, loss_ce: 0.004134
2021-12-11 22:12:40,968 iteration 6084 : loss : 0.022413, loss_ce: 0.004922
2021-12-11 22:12:42,477 iteration 6085 : loss : 0.030135, loss_ce: 0.010047
2021-12-11 22:12:44,017 iteration 6086 : loss : 0.011343, loss_ce: 0.003522
 90%|█████████████████████████▉   | 358/400 [2:52:28<19:19, 27.60s/it]2021-12-11 22:12:45,541 iteration 6087 : loss : 0.019260, loss_ce: 0.005995
2021-12-11 22:12:47,107 iteration 6088 : loss : 0.015831, loss_ce: 0.006273
2021-12-11 22:12:48,614 iteration 6089 : loss : 0.016588, loss_ce: 0.005265
2021-12-11 22:12:50,043 iteration 6090 : loss : 0.011832, loss_ce: 0.004872
2021-12-11 22:12:51,590 iteration 6091 : loss : 0.013419, loss_ce: 0.004267
2021-12-11 22:12:53,130 iteration 6092 : loss : 0.015727, loss_ce: 0.004626
2021-12-11 22:12:54,648 iteration 6093 : loss : 0.016809, loss_ce: 0.006571
2021-12-11 22:12:56,132 iteration 6094 : loss : 0.014153, loss_ce: 0.004854
2021-12-11 22:12:57,616 iteration 6095 : loss : 0.013518, loss_ce: 0.004279
2021-12-11 22:12:59,159 iteration 6096 : loss : 0.015245, loss_ce: 0.004433
2021-12-11 22:13:00,705 iteration 6097 : loss : 0.012884, loss_ce: 0.005157
2021-12-11 22:13:02,322 iteration 6098 : loss : 0.020151, loss_ce: 0.008630
2021-12-11 22:13:03,901 iteration 6099 : loss : 0.016473, loss_ce: 0.006564
2021-12-11 22:13:05,460 iteration 6100 : loss : 0.016285, loss_ce: 0.008499
2021-12-11 22:13:07,006 iteration 6101 : loss : 0.017392, loss_ce: 0.006709
2021-12-11 22:13:08,575 iteration 6102 : loss : 0.019004, loss_ce: 0.009542
2021-12-11 22:13:10,154 iteration 6103 : loss : 0.022750, loss_ce: 0.007689
 90%|██████████████████████████   | 359/400 [2:52:54<18:33, 27.17s/it]2021-12-11 22:13:11,808 iteration 6104 : loss : 0.019029, loss_ce: 0.008037
2021-12-11 22:13:13,404 iteration 6105 : loss : 0.023212, loss_ce: 0.011407
2021-12-11 22:13:14,963 iteration 6106 : loss : 0.021988, loss_ce: 0.010335
2021-12-11 22:13:16,494 iteration 6107 : loss : 0.017079, loss_ce: 0.005947
2021-12-11 22:13:18,009 iteration 6108 : loss : 0.014990, loss_ce: 0.005769
2021-12-11 22:13:19,525 iteration 6109 : loss : 0.026487, loss_ce: 0.007423
2021-12-11 22:13:21,024 iteration 6110 : loss : 0.015067, loss_ce: 0.005875
2021-12-11 22:13:22,537 iteration 6111 : loss : 0.017415, loss_ce: 0.007885
2021-12-11 22:13:24,054 iteration 6112 : loss : 0.016776, loss_ce: 0.003849
2021-12-11 22:13:25,583 iteration 6113 : loss : 0.016301, loss_ce: 0.006668
2021-12-11 22:13:27,150 iteration 6114 : loss : 0.020489, loss_ce: 0.005636
2021-12-11 22:13:28,671 iteration 6115 : loss : 0.015085, loss_ce: 0.005755
2021-12-11 22:13:30,219 iteration 6116 : loss : 0.019605, loss_ce: 0.007111
2021-12-11 22:13:31,703 iteration 6117 : loss : 0.014237, loss_ce: 0.005383
2021-12-11 22:13:33,175 iteration 6118 : loss : 0.011837, loss_ce: 0.003418
2021-12-11 22:13:34,792 iteration 6119 : loss : 0.020038, loss_ce: 0.008986
2021-12-11 22:13:34,792 Training Data Eval:
2021-12-11 22:13:42,493   Average segmentation loss on training set: 0.0096
2021-12-11 22:13:42,494 Validation Data Eval:
2021-12-11 22:13:45,131   Average segmentation loss on validation set: 0.0889
2021-12-11 22:13:46,643 iteration 6120 : loss : 0.020587, loss_ce: 0.005839
 90%|██████████████████████████   | 360/400 [2:53:31<19:58, 29.96s/it]2021-12-11 22:13:48,206 iteration 6121 : loss : 0.019702, loss_ce: 0.006051
2021-12-11 22:13:49,732 iteration 6122 : loss : 0.016038, loss_ce: 0.006758
2021-12-11 22:13:51,257 iteration 6123 : loss : 0.025542, loss_ce: 0.009669
2021-12-11 22:13:52,729 iteration 6124 : loss : 0.013991, loss_ce: 0.004875
2021-12-11 22:13:54,260 iteration 6125 : loss : 0.020703, loss_ce: 0.007972
2021-12-11 22:13:55,744 iteration 6126 : loss : 0.018629, loss_ce: 0.011310
2021-12-11 22:13:57,305 iteration 6127 : loss : 0.013417, loss_ce: 0.004299
2021-12-11 22:13:58,813 iteration 6128 : loss : 0.015804, loss_ce: 0.005066
2021-12-11 22:14:00,430 iteration 6129 : loss : 0.014647, loss_ce: 0.005340
2021-12-11 22:14:01,937 iteration 6130 : loss : 0.015548, loss_ce: 0.003892
2021-12-11 22:14:03,550 iteration 6131 : loss : 0.016080, loss_ce: 0.007484
2021-12-11 22:14:05,062 iteration 6132 : loss : 0.016331, loss_ce: 0.008140
2021-12-11 22:14:06,615 iteration 6133 : loss : 0.026754, loss_ce: 0.008152
2021-12-11 22:14:08,152 iteration 6134 : loss : 0.019257, loss_ce: 0.007082
2021-12-11 22:14:09,779 iteration 6135 : loss : 0.033809, loss_ce: 0.010635
2021-12-11 22:14:11,308 iteration 6136 : loss : 0.013547, loss_ce: 0.003816
2021-12-11 22:14:12,805 iteration 6137 : loss : 0.017946, loss_ce: 0.007156
 90%|██████████████████████████▏  | 361/400 [2:53:57<18:44, 28.82s/it]2021-12-11 22:14:14,355 iteration 6138 : loss : 0.017875, loss_ce: 0.006063
2021-12-11 22:14:15,877 iteration 6139 : loss : 0.016266, loss_ce: 0.006421
2021-12-11 22:14:17,386 iteration 6140 : loss : 0.014209, loss_ce: 0.006430
2021-12-11 22:14:18,838 iteration 6141 : loss : 0.012492, loss_ce: 0.004641
2021-12-11 22:14:20,279 iteration 6142 : loss : 0.012688, loss_ce: 0.005615
2021-12-11 22:14:21,851 iteration 6143 : loss : 0.018184, loss_ce: 0.005443
2021-12-11 22:14:23,367 iteration 6144 : loss : 0.018250, loss_ce: 0.008018
2021-12-11 22:14:24,872 iteration 6145 : loss : 0.015484, loss_ce: 0.006663
2021-12-11 22:14:26,352 iteration 6146 : loss : 0.030574, loss_ce: 0.006479
2021-12-11 22:14:27,865 iteration 6147 : loss : 0.014826, loss_ce: 0.006022
2021-12-11 22:14:29,434 iteration 6148 : loss : 0.016205, loss_ce: 0.005609
2021-12-11 22:14:30,991 iteration 6149 : loss : 0.020335, loss_ce: 0.006729
2021-12-11 22:14:32,597 iteration 6150 : loss : 0.024204, loss_ce: 0.007479
2021-12-11 22:14:34,195 iteration 6151 : loss : 0.020548, loss_ce: 0.004668
2021-12-11 22:14:35,680 iteration 6152 : loss : 0.014456, loss_ce: 0.005593
2021-12-11 22:14:37,224 iteration 6153 : loss : 0.013685, loss_ce: 0.004447
2021-12-11 22:14:38,783 iteration 6154 : loss : 0.022689, loss_ce: 0.008978
 90%|██████████████████████████▏  | 362/400 [2:54:23<17:42, 27.97s/it]2021-12-11 22:14:40,414 iteration 6155 : loss : 0.023275, loss_ce: 0.007006
2021-12-11 22:14:41,977 iteration 6156 : loss : 0.016855, loss_ce: 0.006412
2021-12-11 22:14:43,522 iteration 6157 : loss : 0.016476, loss_ce: 0.005497
2021-12-11 22:14:45,131 iteration 6158 : loss : 0.018263, loss_ce: 0.004865
2021-12-11 22:14:46,631 iteration 6159 : loss : 0.013789, loss_ce: 0.004579
2021-12-11 22:14:48,141 iteration 6160 : loss : 0.011697, loss_ce: 0.004627
2021-12-11 22:14:49,706 iteration 6161 : loss : 0.024209, loss_ce: 0.006277
2021-12-11 22:14:51,301 iteration 6162 : loss : 0.023252, loss_ce: 0.006138
2021-12-11 22:14:52,841 iteration 6163 : loss : 0.019684, loss_ce: 0.007419
2021-12-11 22:14:54,298 iteration 6164 : loss : 0.012891, loss_ce: 0.003414
2021-12-11 22:14:55,884 iteration 6165 : loss : 0.019139, loss_ce: 0.006575
2021-12-11 22:14:57,392 iteration 6166 : loss : 0.018747, loss_ce: 0.006596
2021-12-11 22:14:58,988 iteration 6167 : loss : 0.017404, loss_ce: 0.008356
2021-12-11 22:15:00,540 iteration 6168 : loss : 0.020560, loss_ce: 0.007116
2021-12-11 22:15:02,060 iteration 6169 : loss : 0.015948, loss_ce: 0.004069
2021-12-11 22:15:03,540 iteration 6170 : loss : 0.014579, loss_ce: 0.006684
2021-12-11 22:15:05,053 iteration 6171 : loss : 0.018610, loss_ce: 0.008975
 91%|██████████████████████████▎  | 363/400 [2:54:49<16:56, 27.46s/it]2021-12-11 22:15:06,621 iteration 6172 : loss : 0.020027, loss_ce: 0.007468
2021-12-11 22:15:08,228 iteration 6173 : loss : 0.026227, loss_ce: 0.006902
2021-12-11 22:15:09,787 iteration 6174 : loss : 0.014762, loss_ce: 0.005495
2021-12-11 22:15:11,421 iteration 6175 : loss : 0.014088, loss_ce: 0.004257
2021-12-11 22:15:12,978 iteration 6176 : loss : 0.014266, loss_ce: 0.005531
2021-12-11 22:15:14,502 iteration 6177 : loss : 0.019611, loss_ce: 0.011330
2021-12-11 22:15:16,043 iteration 6178 : loss : 0.017968, loss_ce: 0.006496
2021-12-11 22:15:17,536 iteration 6179 : loss : 0.019864, loss_ce: 0.006686
2021-12-11 22:15:19,120 iteration 6180 : loss : 0.020982, loss_ce: 0.009278
2021-12-11 22:15:20,608 iteration 6181 : loss : 0.012524, loss_ce: 0.003738
2021-12-11 22:15:22,108 iteration 6182 : loss : 0.017079, loss_ce: 0.004182
2021-12-11 22:15:23,688 iteration 6183 : loss : 0.019143, loss_ce: 0.007648
2021-12-11 22:15:25,242 iteration 6184 : loss : 0.016308, loss_ce: 0.007571
2021-12-11 22:15:26,828 iteration 6185 : loss : 0.022502, loss_ce: 0.005699
2021-12-11 22:15:28,347 iteration 6186 : loss : 0.013497, loss_ce: 0.004301
2021-12-11 22:15:29,894 iteration 6187 : loss : 0.016209, loss_ce: 0.009236
2021-12-11 22:15:31,510 iteration 6188 : loss : 0.021030, loss_ce: 0.009651
 91%|██████████████████████████▍  | 364/400 [2:55:16<16:17, 27.16s/it]2021-12-11 22:15:33,163 iteration 6189 : loss : 0.018126, loss_ce: 0.004020
2021-12-11 22:15:34,757 iteration 6190 : loss : 0.024796, loss_ce: 0.007977
2021-12-11 22:15:36,269 iteration 6191 : loss : 0.014264, loss_ce: 0.006803
2021-12-11 22:15:37,749 iteration 6192 : loss : 0.012314, loss_ce: 0.004611
2021-12-11 22:15:39,274 iteration 6193 : loss : 0.016468, loss_ce: 0.005121
2021-12-11 22:15:40,753 iteration 6194 : loss : 0.016468, loss_ce: 0.006392
2021-12-11 22:15:42,364 iteration 6195 : loss : 0.014873, loss_ce: 0.005224
2021-12-11 22:15:43,886 iteration 6196 : loss : 0.015702, loss_ce: 0.004847
2021-12-11 22:15:45,366 iteration 6197 : loss : 0.015035, loss_ce: 0.006923
2021-12-11 22:15:47,013 iteration 6198 : loss : 0.024586, loss_ce: 0.006768
2021-12-11 22:15:48,533 iteration 6199 : loss : 0.015186, loss_ce: 0.005886
2021-12-11 22:15:50,045 iteration 6200 : loss : 0.015822, loss_ce: 0.006853
2021-12-11 22:15:51,590 iteration 6201 : loss : 0.014022, loss_ce: 0.005494
2021-12-11 22:15:53,065 iteration 6202 : loss : 0.014498, loss_ce: 0.004608
2021-12-11 22:15:54,752 iteration 6203 : loss : 0.021956, loss_ce: 0.009959
2021-12-11 22:15:56,228 iteration 6204 : loss : 0.012856, loss_ce: 0.005660
2021-12-11 22:15:56,228 Training Data Eval:
2021-12-11 22:16:03,925   Average segmentation loss on training set: 0.0094
2021-12-11 22:16:03,926 Validation Data Eval:
2021-12-11 22:16:06,564   Average segmentation loss on validation set: 0.0739
2021-12-11 22:16:08,151 iteration 6205 : loss : 0.025648, loss_ce: 0.008683
 91%|██████████████████████████▍  | 365/400 [2:55:52<17:30, 30.01s/it]2021-12-11 22:16:09,766 iteration 6206 : loss : 0.023598, loss_ce: 0.009440
2021-12-11 22:16:11,317 iteration 6207 : loss : 0.015535, loss_ce: 0.006184
2021-12-11 22:16:12,892 iteration 6208 : loss : 0.031172, loss_ce: 0.010665
2021-12-11 22:16:14,436 iteration 6209 : loss : 0.016254, loss_ce: 0.005467
2021-12-11 22:16:15,983 iteration 6210 : loss : 0.013101, loss_ce: 0.005361
2021-12-11 22:16:17,500 iteration 6211 : loss : 0.030377, loss_ce: 0.016554
2021-12-11 22:16:19,043 iteration 6212 : loss : 0.014633, loss_ce: 0.005621
2021-12-11 22:16:20,482 iteration 6213 : loss : 0.013248, loss_ce: 0.004441
2021-12-11 22:16:22,090 iteration 6214 : loss : 0.022719, loss_ce: 0.008205
2021-12-11 22:16:23,617 iteration 6215 : loss : 0.017234, loss_ce: 0.005287
2021-12-11 22:16:25,153 iteration 6216 : loss : 0.017646, loss_ce: 0.005409
2021-12-11 22:16:26,717 iteration 6217 : loss : 0.023769, loss_ce: 0.008339
2021-12-11 22:16:28,204 iteration 6218 : loss : 0.014290, loss_ce: 0.005506
2021-12-11 22:16:29,750 iteration 6219 : loss : 0.018798, loss_ce: 0.006529
2021-12-11 22:16:31,199 iteration 6220 : loss : 0.015112, loss_ce: 0.004052
2021-12-11 22:16:32,804 iteration 6221 : loss : 0.014172, loss_ce: 0.004339
2021-12-11 22:16:34,346 iteration 6222 : loss : 0.012366, loss_ce: 0.005298
 92%|██████████████████████████▌  | 366/400 [2:56:19<16:21, 28.86s/it]2021-12-11 22:16:35,956 iteration 6223 : loss : 0.017241, loss_ce: 0.007089
2021-12-11 22:16:37,530 iteration 6224 : loss : 0.016889, loss_ce: 0.006927
2021-12-11 22:16:39,088 iteration 6225 : loss : 0.013600, loss_ce: 0.006502
2021-12-11 22:16:40,618 iteration 6226 : loss : 0.019442, loss_ce: 0.007243
2021-12-11 22:16:42,225 iteration 6227 : loss : 0.013573, loss_ce: 0.004621
2021-12-11 22:16:43,747 iteration 6228 : loss : 0.018147, loss_ce: 0.006543
2021-12-11 22:16:45,316 iteration 6229 : loss : 0.016537, loss_ce: 0.004823
2021-12-11 22:16:46,903 iteration 6230 : loss : 0.026960, loss_ce: 0.004840
2021-12-11 22:16:48,385 iteration 6231 : loss : 0.015900, loss_ce: 0.007294
2021-12-11 22:16:49,898 iteration 6232 : loss : 0.017297, loss_ce: 0.006086
2021-12-11 22:16:51,502 iteration 6233 : loss : 0.021979, loss_ce: 0.007534
2021-12-11 22:16:53,025 iteration 6234 : loss : 0.020235, loss_ce: 0.007674
2021-12-11 22:16:54,552 iteration 6235 : loss : 0.015610, loss_ce: 0.004755
2021-12-11 22:16:56,134 iteration 6236 : loss : 0.019185, loss_ce: 0.006902
2021-12-11 22:16:57,689 iteration 6237 : loss : 0.019247, loss_ce: 0.005841
2021-12-11 22:16:59,283 iteration 6238 : loss : 0.017920, loss_ce: 0.006921
2021-12-11 22:17:00,889 iteration 6239 : loss : 0.026282, loss_ce: 0.010305
 92%|██████████████████████████▌  | 367/400 [2:56:45<15:29, 28.16s/it]2021-12-11 22:17:02,436 iteration 6240 : loss : 0.017574, loss_ce: 0.005616
2021-12-11 22:17:03,915 iteration 6241 : loss : 0.019078, loss_ce: 0.007944
2021-12-11 22:17:05,477 iteration 6242 : loss : 0.016529, loss_ce: 0.007947
2021-12-11 22:17:07,010 iteration 6243 : loss : 0.027715, loss_ce: 0.012409
2021-12-11 22:17:08,554 iteration 6244 : loss : 0.015473, loss_ce: 0.005440
2021-12-11 22:17:10,115 iteration 6245 : loss : 0.014153, loss_ce: 0.005957
2021-12-11 22:17:11,629 iteration 6246 : loss : 0.016333, loss_ce: 0.006388
2021-12-11 22:17:13,130 iteration 6247 : loss : 0.013520, loss_ce: 0.004260
2021-12-11 22:17:14,696 iteration 6248 : loss : 0.031649, loss_ce: 0.009561
2021-12-11 22:17:16,263 iteration 6249 : loss : 0.014343, loss_ce: 0.004645
2021-12-11 22:17:17,702 iteration 6250 : loss : 0.013893, loss_ce: 0.003142
2021-12-11 22:17:19,276 iteration 6251 : loss : 0.026943, loss_ce: 0.017549
2021-12-11 22:17:20,741 iteration 6252 : loss : 0.013902, loss_ce: 0.004122
2021-12-11 22:17:22,355 iteration 6253 : loss : 0.016295, loss_ce: 0.006098
2021-12-11 22:17:23,805 iteration 6254 : loss : 0.009321, loss_ce: 0.003855
2021-12-11 22:17:25,481 iteration 6255 : loss : 0.032582, loss_ce: 0.008989
2021-12-11 22:17:26,988 iteration 6256 : loss : 0.015878, loss_ce: 0.006391
 92%|██████████████████████████▋  | 368/400 [2:57:11<14:41, 27.54s/it]2021-12-11 22:17:28,620 iteration 6257 : loss : 0.021941, loss_ce: 0.008198
2021-12-11 22:17:30,142 iteration 6258 : loss : 0.012061, loss_ce: 0.005806
2021-12-11 22:17:31,695 iteration 6259 : loss : 0.017855, loss_ce: 0.007592
2021-12-11 22:17:33,226 iteration 6260 : loss : 0.015695, loss_ce: 0.004104
2021-12-11 22:17:34,718 iteration 6261 : loss : 0.012644, loss_ce: 0.004960
2021-12-11 22:17:36,281 iteration 6262 : loss : 0.017466, loss_ce: 0.007031
2021-12-11 22:17:37,870 iteration 6263 : loss : 0.021078, loss_ce: 0.005042
2021-12-11 22:17:39,386 iteration 6264 : loss : 0.012875, loss_ce: 0.005937
2021-12-11 22:17:40,876 iteration 6265 : loss : 0.013940, loss_ce: 0.005486
2021-12-11 22:17:42,408 iteration 6266 : loss : 0.014239, loss_ce: 0.005743
2021-12-11 22:17:43,944 iteration 6267 : loss : 0.017517, loss_ce: 0.006256
2021-12-11 22:17:45,466 iteration 6268 : loss : 0.017743, loss_ce: 0.007477
2021-12-11 22:17:46,974 iteration 6269 : loss : 0.019682, loss_ce: 0.005866
2021-12-11 22:17:48,531 iteration 6270 : loss : 0.016621, loss_ce: 0.004799
2021-12-11 22:17:50,055 iteration 6271 : loss : 0.017191, loss_ce: 0.004003
2021-12-11 22:17:51,569 iteration 6272 : loss : 0.012239, loss_ce: 0.003199
2021-12-11 22:17:53,028 iteration 6273 : loss : 0.010914, loss_ce: 0.004642
 92%|██████████████████████████▊  | 369/400 [2:57:37<13:59, 27.09s/it]2021-12-11 22:17:54,592 iteration 6274 : loss : 0.016849, loss_ce: 0.005199
2021-12-11 22:17:56,119 iteration 6275 : loss : 0.016788, loss_ce: 0.007215
2021-12-11 22:17:57,638 iteration 6276 : loss : 0.015380, loss_ce: 0.005245
2021-12-11 22:17:59,213 iteration 6277 : loss : 0.025375, loss_ce: 0.008235
2021-12-11 22:18:00,811 iteration 6278 : loss : 0.017316, loss_ce: 0.006695
2021-12-11 22:18:02,459 iteration 6279 : loss : 0.024122, loss_ce: 0.007141
2021-12-11 22:18:04,006 iteration 6280 : loss : 0.015079, loss_ce: 0.006399
2021-12-11 22:18:05,528 iteration 6281 : loss : 0.015224, loss_ce: 0.004721
2021-12-11 22:18:07,030 iteration 6282 : loss : 0.014065, loss_ce: 0.005017
2021-12-11 22:18:08,615 iteration 6283 : loss : 0.021122, loss_ce: 0.005855
2021-12-11 22:18:10,224 iteration 6284 : loss : 0.016427, loss_ce: 0.007436
2021-12-11 22:18:11,760 iteration 6285 : loss : 0.016074, loss_ce: 0.005857
2021-12-11 22:18:13,291 iteration 6286 : loss : 0.023527, loss_ce: 0.014343
2021-12-11 22:18:14,867 iteration 6287 : loss : 0.014167, loss_ce: 0.004655
2021-12-11 22:18:16,470 iteration 6288 : loss : 0.019748, loss_ce: 0.006391
2021-12-11 22:18:17,985 iteration 6289 : loss : 0.014766, loss_ce: 0.004896
2021-12-11 22:18:17,985 Training Data Eval:
2021-12-11 22:18:25,700   Average segmentation loss on training set: 0.0094
2021-12-11 22:18:25,701 Validation Data Eval:
2021-12-11 22:18:28,354   Average segmentation loss on validation set: 0.0838
2021-12-11 22:18:29,843 iteration 6290 : loss : 0.012776, loss_ce: 0.004572
 92%|██████████████████████████▊  | 370/400 [2:58:14<15:00, 30.01s/it]2021-12-11 22:18:31,428 iteration 6291 : loss : 0.012889, loss_ce: 0.003075
2021-12-11 22:18:33,047 iteration 6292 : loss : 0.013889, loss_ce: 0.004740
2021-12-11 22:18:34,563 iteration 6293 : loss : 0.013144, loss_ce: 0.005084
2021-12-11 22:18:36,117 iteration 6294 : loss : 0.014848, loss_ce: 0.005365
2021-12-11 22:18:37,678 iteration 6295 : loss : 0.017914, loss_ce: 0.006568
2021-12-11 22:18:39,188 iteration 6296 : loss : 0.013286, loss_ce: 0.004796
2021-12-11 22:18:40,715 iteration 6297 : loss : 0.017879, loss_ce: 0.004802
2021-12-11 22:18:42,220 iteration 6298 : loss : 0.010904, loss_ce: 0.003544
2021-12-11 22:18:43,792 iteration 6299 : loss : 0.017686, loss_ce: 0.006660
2021-12-11 22:18:45,321 iteration 6300 : loss : 0.017384, loss_ce: 0.005964
2021-12-11 22:18:46,811 iteration 6301 : loss : 0.014883, loss_ce: 0.005247
2021-12-11 22:18:48,297 iteration 6302 : loss : 0.015598, loss_ce: 0.005900
2021-12-11 22:18:49,842 iteration 6303 : loss : 0.019192, loss_ce: 0.008500
2021-12-11 22:18:51,347 iteration 6304 : loss : 0.014914, loss_ce: 0.005386
2021-12-11 22:18:52,806 iteration 6305 : loss : 0.011335, loss_ce: 0.004763
2021-12-11 22:18:54,272 iteration 6306 : loss : 0.012956, loss_ce: 0.004460
2021-12-11 22:18:55,869 iteration 6307 : loss : 0.014653, loss_ce: 0.004591
 93%|██████████████████████████▉  | 371/400 [2:58:40<13:55, 28.82s/it]2021-12-11 22:18:57,422 iteration 6308 : loss : 0.012811, loss_ce: 0.004839
2021-12-11 22:18:58,980 iteration 6309 : loss : 0.017377, loss_ce: 0.006153
2021-12-11 22:19:00,528 iteration 6310 : loss : 0.019889, loss_ce: 0.008033
2021-12-11 22:19:02,029 iteration 6311 : loss : 0.018426, loss_ce: 0.004997
2021-12-11 22:19:03,592 iteration 6312 : loss : 0.013540, loss_ce: 0.004424
2021-12-11 22:19:05,096 iteration 6313 : loss : 0.013618, loss_ce: 0.003913
2021-12-11 22:19:06,665 iteration 6314 : loss : 0.018551, loss_ce: 0.006944
2021-12-11 22:19:08,255 iteration 6315 : loss : 0.024162, loss_ce: 0.008381
2021-12-11 22:19:09,782 iteration 6316 : loss : 0.020985, loss_ce: 0.009112
2021-12-11 22:19:11,340 iteration 6317 : loss : 0.013255, loss_ce: 0.004603
2021-12-11 22:19:12,944 iteration 6318 : loss : 0.019221, loss_ce: 0.008753
2021-12-11 22:19:14,577 iteration 6319 : loss : 0.017228, loss_ce: 0.005569
2021-12-11 22:19:16,204 iteration 6320 : loss : 0.014817, loss_ce: 0.005933
2021-12-11 22:19:17,787 iteration 6321 : loss : 0.019060, loss_ce: 0.007271
2021-12-11 22:19:19,396 iteration 6322 : loss : 0.016009, loss_ce: 0.006149
2021-12-11 22:19:20,807 iteration 6323 : loss : 0.011628, loss_ce: 0.004920
2021-12-11 22:19:22,349 iteration 6324 : loss : 0.016773, loss_ce: 0.004347
 93%|██████████████████████████▉  | 372/400 [2:59:07<13:07, 28.12s/it]2021-12-11 22:19:23,877 iteration 6325 : loss : 0.018338, loss_ce: 0.005710
2021-12-11 22:19:25,334 iteration 6326 : loss : 0.011261, loss_ce: 0.004840
2021-12-11 22:19:26,785 iteration 6327 : loss : 0.011689, loss_ce: 0.004290
2021-12-11 22:19:28,383 iteration 6328 : loss : 0.017949, loss_ce: 0.008277
2021-12-11 22:19:30,014 iteration 6329 : loss : 0.016620, loss_ce: 0.006206
2021-12-11 22:19:31,569 iteration 6330 : loss : 0.013927, loss_ce: 0.005437
2021-12-11 22:19:33,160 iteration 6331 : loss : 0.028324, loss_ce: 0.014766
2021-12-11 22:19:34,677 iteration 6332 : loss : 0.015217, loss_ce: 0.005209
2021-12-11 22:19:36,199 iteration 6333 : loss : 0.016451, loss_ce: 0.007347
2021-12-11 22:19:37,753 iteration 6334 : loss : 0.012468, loss_ce: 0.004764
2021-12-11 22:19:39,433 iteration 6335 : loss : 0.020944, loss_ce: 0.010417
2021-12-11 22:19:41,005 iteration 6336 : loss : 0.015091, loss_ce: 0.005445
2021-12-11 22:19:42,466 iteration 6337 : loss : 0.014588, loss_ce: 0.005512
2021-12-11 22:19:44,070 iteration 6338 : loss : 0.017594, loss_ce: 0.005155
2021-12-11 22:19:45,582 iteration 6339 : loss : 0.010994, loss_ce: 0.003690
2021-12-11 22:19:47,128 iteration 6340 : loss : 0.017743, loss_ce: 0.009139
2021-12-11 22:19:48,691 iteration 6341 : loss : 0.023391, loss_ce: 0.006961
 93%|███████████████████████████  | 373/400 [2:59:33<12:24, 27.58s/it]2021-12-11 22:19:50,386 iteration 6342 : loss : 0.018738, loss_ce: 0.008454
2021-12-11 22:19:51,912 iteration 6343 : loss : 0.016343, loss_ce: 0.004833
2021-12-11 22:19:53,452 iteration 6344 : loss : 0.015372, loss_ce: 0.006699
2021-12-11 22:19:54,990 iteration 6345 : loss : 0.018547, loss_ce: 0.009340
2021-12-11 22:19:56,484 iteration 6346 : loss : 0.013496, loss_ce: 0.003669
2021-12-11 22:19:58,010 iteration 6347 : loss : 0.029949, loss_ce: 0.011112
2021-12-11 22:19:59,644 iteration 6348 : loss : 0.025701, loss_ce: 0.007971
2021-12-11 22:20:01,127 iteration 6349 : loss : 0.014030, loss_ce: 0.005911
2021-12-11 22:20:02,635 iteration 6350 : loss : 0.014558, loss_ce: 0.003843
2021-12-11 22:20:04,136 iteration 6351 : loss : 0.013935, loss_ce: 0.004763
2021-12-11 22:20:05,721 iteration 6352 : loss : 0.018915, loss_ce: 0.007751
2021-12-11 22:20:07,310 iteration 6353 : loss : 0.017741, loss_ce: 0.007401
2021-12-11 22:20:08,942 iteration 6354 : loss : 0.016011, loss_ce: 0.006234
2021-12-11 22:20:10,440 iteration 6355 : loss : 0.012265, loss_ce: 0.005475
2021-12-11 22:20:11,996 iteration 6356 : loss : 0.017985, loss_ce: 0.008411
2021-12-11 22:20:13,506 iteration 6357 : loss : 0.019295, loss_ce: 0.006563
2021-12-11 22:20:15,101 iteration 6358 : loss : 0.017652, loss_ce: 0.006296
 94%|███████████████████████████  | 374/400 [2:59:59<11:48, 27.23s/it]2021-12-11 22:20:16,707 iteration 6359 : loss : 0.015144, loss_ce: 0.005137
2021-12-11 22:20:18,198 iteration 6360 : loss : 0.016588, loss_ce: 0.004819
2021-12-11 22:20:19,746 iteration 6361 : loss : 0.020768, loss_ce: 0.005735
2021-12-11 22:20:21,312 iteration 6362 : loss : 0.013006, loss_ce: 0.005832
2021-12-11 22:20:22,929 iteration 6363 : loss : 0.020242, loss_ce: 0.008009
2021-12-11 22:20:24,425 iteration 6364 : loss : 0.014399, loss_ce: 0.005892
2021-12-11 22:20:25,932 iteration 6365 : loss : 0.015944, loss_ce: 0.005650
2021-12-11 22:20:27,535 iteration 6366 : loss : 0.024021, loss_ce: 0.010113
2021-12-11 22:20:29,068 iteration 6367 : loss : 0.013772, loss_ce: 0.005596
2021-12-11 22:20:30,600 iteration 6368 : loss : 0.014532, loss_ce: 0.004962
2021-12-11 22:20:32,184 iteration 6369 : loss : 0.013814, loss_ce: 0.005699
2021-12-11 22:20:33,775 iteration 6370 : loss : 0.021259, loss_ce: 0.006351
2021-12-11 22:20:35,370 iteration 6371 : loss : 0.018953, loss_ce: 0.006876
2021-12-11 22:20:36,929 iteration 6372 : loss : 0.015727, loss_ce: 0.007115
2021-12-11 22:20:38,343 iteration 6373 : loss : 0.010944, loss_ce: 0.002620
2021-12-11 22:20:39,855 iteration 6374 : loss : 0.012286, loss_ce: 0.004574
2021-12-11 22:20:39,856 Training Data Eval:
2021-12-11 22:20:47,609   Average segmentation loss on training set: 0.0090
2021-12-11 22:20:47,609 Validation Data Eval:
2021-12-11 22:20:50,265   Average segmentation loss on validation set: 0.0735
2021-12-11 22:20:51,816 iteration 6375 : loss : 0.016539, loss_ce: 0.005275
 94%|███████████████████████████▏ | 375/400 [3:00:36<12:31, 30.08s/it]2021-12-11 22:20:53,692 iteration 6376 : loss : 0.021079, loss_ce: 0.007098
2021-12-11 22:20:55,247 iteration 6377 : loss : 0.013966, loss_ce: 0.005206
2021-12-11 22:20:56,790 iteration 6378 : loss : 0.017593, loss_ce: 0.005937
2021-12-11 22:20:58,403 iteration 6379 : loss : 0.016297, loss_ce: 0.004399
2021-12-11 22:20:59,883 iteration 6380 : loss : 0.012964, loss_ce: 0.006216
2021-12-11 22:21:01,372 iteration 6381 : loss : 0.015601, loss_ce: 0.005398
2021-12-11 22:21:02,997 iteration 6382 : loss : 0.027331, loss_ce: 0.011188
2021-12-11 22:21:04,606 iteration 6383 : loss : 0.013302, loss_ce: 0.004845
2021-12-11 22:21:06,121 iteration 6384 : loss : 0.014093, loss_ce: 0.005477
2021-12-11 22:21:07,803 iteration 6385 : loss : 0.024173, loss_ce: 0.009915
2021-12-11 22:21:09,374 iteration 6386 : loss : 0.017100, loss_ce: 0.005636
2021-12-11 22:21:11,082 iteration 6387 : loss : 0.020137, loss_ce: 0.008564
2021-12-11 22:21:12,622 iteration 6388 : loss : 0.011091, loss_ce: 0.003668
2021-12-11 22:21:14,079 iteration 6389 : loss : 0.013408, loss_ce: 0.003853
2021-12-11 22:21:15,627 iteration 6390 : loss : 0.018924, loss_ce: 0.006256
2021-12-11 22:21:17,322 iteration 6391 : loss : 0.024929, loss_ce: 0.006175
2021-12-11 22:21:18,822 iteration 6392 : loss : 0.010757, loss_ce: 0.004225
 94%|███████████████████████████▎ | 376/400 [3:01:03<11:39, 29.16s/it]2021-12-11 22:21:20,454 iteration 6393 : loss : 0.012600, loss_ce: 0.003995
2021-12-11 22:21:22,049 iteration 6394 : loss : 0.016123, loss_ce: 0.005124
2021-12-11 22:21:23,584 iteration 6395 : loss : 0.013062, loss_ce: 0.005883
2021-12-11 22:21:25,262 iteration 6396 : loss : 0.017197, loss_ce: 0.006940
2021-12-11 22:21:26,795 iteration 6397 : loss : 0.016904, loss_ce: 0.006758
2021-12-11 22:21:28,290 iteration 6398 : loss : 0.012442, loss_ce: 0.003536
2021-12-11 22:21:29,876 iteration 6399 : loss : 0.014191, loss_ce: 0.004218
2021-12-11 22:21:31,458 iteration 6400 : loss : 0.014872, loss_ce: 0.006959
2021-12-11 22:21:32,944 iteration 6401 : loss : 0.012555, loss_ce: 0.004813
2021-12-11 22:21:34,515 iteration 6402 : loss : 0.019221, loss_ce: 0.008374
2021-12-11 22:21:36,235 iteration 6403 : loss : 0.016781, loss_ce: 0.006614
2021-12-11 22:21:37,800 iteration 6404 : loss : 0.014116, loss_ce: 0.004047
2021-12-11 22:21:39,373 iteration 6405 : loss : 0.018598, loss_ce: 0.006779
2021-12-11 22:21:41,138 iteration 6406 : loss : 0.017260, loss_ce: 0.007487
2021-12-11 22:21:42,643 iteration 6407 : loss : 0.013305, loss_ce: 0.003806
2021-12-11 22:21:44,210 iteration 6408 : loss : 0.014847, loss_ce: 0.003449
2021-12-11 22:21:45,757 iteration 6409 : loss : 0.015501, loss_ce: 0.005595
 94%|███████████████████████████▎ | 377/400 [3:01:30<10:55, 28.49s/it]2021-12-11 22:21:47,546 iteration 6410 : loss : 0.019705, loss_ce: 0.008107
2021-12-11 22:21:49,241 iteration 6411 : loss : 0.020954, loss_ce: 0.008181
2021-12-11 22:21:50,846 iteration 6412 : loss : 0.016998, loss_ce: 0.007624
2021-12-11 22:21:52,422 iteration 6413 : loss : 0.017704, loss_ce: 0.007558
2021-12-11 22:21:54,044 iteration 6414 : loss : 0.018019, loss_ce: 0.006558
2021-12-11 22:21:55,586 iteration 6415 : loss : 0.016681, loss_ce: 0.005090
2021-12-11 22:21:57,150 iteration 6416 : loss : 0.020389, loss_ce: 0.005189
2021-12-11 22:21:58,765 iteration 6417 : loss : 0.020687, loss_ce: 0.009465
2021-12-11 22:22:00,381 iteration 6418 : loss : 0.018000, loss_ce: 0.006637
2021-12-11 22:22:01,956 iteration 6419 : loss : 0.015064, loss_ce: 0.004792
2021-12-11 22:22:03,582 iteration 6420 : loss : 0.034511, loss_ce: 0.011855
2021-12-11 22:22:05,166 iteration 6421 : loss : 0.013607, loss_ce: 0.004934
2021-12-11 22:22:06,640 iteration 6422 : loss : 0.013182, loss_ce: 0.005607
2021-12-11 22:22:08,259 iteration 6423 : loss : 0.020960, loss_ce: 0.007182
2021-12-11 22:22:09,898 iteration 6424 : loss : 0.015167, loss_ce: 0.006806
2021-12-11 22:22:11,376 iteration 6425 : loss : 0.013017, loss_ce: 0.003836
2021-12-11 22:22:13,004 iteration 6426 : loss : 0.020343, loss_ce: 0.008541
 94%|███████████████████████████▍ | 378/400 [3:01:57<10:18, 28.12s/it]2021-12-11 22:22:14,658 iteration 6427 : loss : 0.015916, loss_ce: 0.005909
2021-12-11 22:22:16,141 iteration 6428 : loss : 0.014442, loss_ce: 0.006650
2021-12-11 22:22:17,758 iteration 6429 : loss : 0.022346, loss_ce: 0.008234
2021-12-11 22:22:19,261 iteration 6430 : loss : 0.012815, loss_ce: 0.003441
2021-12-11 22:22:20,838 iteration 6431 : loss : 0.017478, loss_ce: 0.005741
2021-12-11 22:22:22,428 iteration 6432 : loss : 0.015462, loss_ce: 0.005826
2021-12-11 22:22:24,066 iteration 6433 : loss : 0.020597, loss_ce: 0.007672
2021-12-11 22:22:25,537 iteration 6434 : loss : 0.010420, loss_ce: 0.003666
2021-12-11 22:22:27,112 iteration 6435 : loss : 0.014393, loss_ce: 0.006924
2021-12-11 22:22:28,662 iteration 6436 : loss : 0.015571, loss_ce: 0.005952
2021-12-11 22:22:30,274 iteration 6437 : loss : 0.021591, loss_ce: 0.005005
2021-12-11 22:22:31,906 iteration 6438 : loss : 0.016555, loss_ce: 0.006452
2021-12-11 22:22:33,518 iteration 6439 : loss : 0.014948, loss_ce: 0.005841
2021-12-11 22:22:35,176 iteration 6440 : loss : 0.022489, loss_ce: 0.008287
2021-12-11 22:22:36,789 iteration 6441 : loss : 0.017871, loss_ce: 0.005970
2021-12-11 22:22:38,381 iteration 6442 : loss : 0.017368, loss_ce: 0.007496
2021-12-11 22:22:40,000 iteration 6443 : loss : 0.020144, loss_ce: 0.007915
 95%|███████████████████████████▍ | 379/400 [3:02:24<09:43, 27.78s/it]2021-12-11 22:22:41,708 iteration 6444 : loss : 0.017378, loss_ce: 0.007975
2021-12-11 22:22:43,389 iteration 6445 : loss : 0.017966, loss_ce: 0.006677
2021-12-11 22:22:44,996 iteration 6446 : loss : 0.014454, loss_ce: 0.003437
2021-12-11 22:22:46,568 iteration 6447 : loss : 0.019239, loss_ce: 0.009846
2021-12-11 22:22:48,150 iteration 6448 : loss : 0.013472, loss_ce: 0.005942
2021-12-11 22:22:49,798 iteration 6449 : loss : 0.020445, loss_ce: 0.006659
2021-12-11 22:22:51,329 iteration 6450 : loss : 0.012307, loss_ce: 0.005024
2021-12-11 22:22:52,832 iteration 6451 : loss : 0.015066, loss_ce: 0.005239
2021-12-11 22:22:54,444 iteration 6452 : loss : 0.016499, loss_ce: 0.007559
2021-12-11 22:22:56,039 iteration 6453 : loss : 0.016865, loss_ce: 0.006855
2021-12-11 22:22:57,614 iteration 6454 : loss : 0.015610, loss_ce: 0.005263
2021-12-11 22:22:59,170 iteration 6455 : loss : 0.016295, loss_ce: 0.005554
2021-12-11 22:23:00,874 iteration 6456 : loss : 0.018604, loss_ce: 0.007309
2021-12-11 22:23:02,469 iteration 6457 : loss : 0.013673, loss_ce: 0.004372
2021-12-11 22:23:03,994 iteration 6458 : loss : 0.015081, loss_ce: 0.004345
2021-12-11 22:23:05,498 iteration 6459 : loss : 0.013682, loss_ce: 0.005194
2021-12-11 22:23:05,498 Training Data Eval:
2021-12-11 22:23:13,264   Average segmentation loss on training set: 0.0086
2021-12-11 22:23:13,265 Validation Data Eval:
2021-12-11 22:23:15,921   Average segmentation loss on validation set: 0.0803
2021-12-11 22:23:17,533 iteration 6460 : loss : 0.021612, loss_ce: 0.005812
 95%|███████████████████████████▌ | 380/400 [3:03:02<10:14, 30.71s/it]2021-12-11 22:23:19,183 iteration 6461 : loss : 0.020833, loss_ce: 0.007347
2021-12-11 22:23:20,776 iteration 6462 : loss : 0.016459, loss_ce: 0.005995
2021-12-11 22:23:22,300 iteration 6463 : loss : 0.009366, loss_ce: 0.002532
2021-12-11 22:23:23,824 iteration 6464 : loss : 0.013031, loss_ce: 0.004373
2021-12-11 22:23:25,382 iteration 6465 : loss : 0.019383, loss_ce: 0.006087
2021-12-11 22:23:26,990 iteration 6466 : loss : 0.016998, loss_ce: 0.005621
2021-12-11 22:23:28,579 iteration 6467 : loss : 0.016427, loss_ce: 0.007932
2021-12-11 22:23:30,236 iteration 6468 : loss : 0.016546, loss_ce: 0.007691
2021-12-11 22:23:31,813 iteration 6469 : loss : 0.017393, loss_ce: 0.007738
2021-12-11 22:23:33,366 iteration 6470 : loss : 0.018688, loss_ce: 0.005595
2021-12-11 22:23:34,916 iteration 6471 : loss : 0.015114, loss_ce: 0.004760
2021-12-11 22:23:36,476 iteration 6472 : loss : 0.016987, loss_ce: 0.005255
2021-12-11 22:23:37,975 iteration 6473 : loss : 0.013903, loss_ce: 0.006601
2021-12-11 22:23:39,624 iteration 6474 : loss : 0.016138, loss_ce: 0.008160
2021-12-11 22:23:41,118 iteration 6475 : loss : 0.012723, loss_ce: 0.004542
2021-12-11 22:23:42,652 iteration 6476 : loss : 0.014536, loss_ce: 0.004950
2021-12-11 22:23:44,142 iteration 6477 : loss : 0.011318, loss_ce: 0.003782
 95%|███████████████████████████▌ | 381/400 [3:03:28<09:20, 29.48s/it]2021-12-11 22:23:45,821 iteration 6478 : loss : 0.013445, loss_ce: 0.005396
2021-12-11 22:23:47,585 iteration 6479 : loss : 0.020162, loss_ce: 0.011439
2021-12-11 22:23:49,190 iteration 6480 : loss : 0.020372, loss_ce: 0.004282
2021-12-11 22:23:50,803 iteration 6481 : loss : 0.015473, loss_ce: 0.006158
2021-12-11 22:23:52,416 iteration 6482 : loss : 0.016986, loss_ce: 0.006549
2021-12-11 22:23:53,966 iteration 6483 : loss : 0.017605, loss_ce: 0.006042
2021-12-11 22:23:55,533 iteration 6484 : loss : 0.017128, loss_ce: 0.004655
2021-12-11 22:23:57,134 iteration 6485 : loss : 0.019356, loss_ce: 0.008597
2021-12-11 22:23:58,812 iteration 6486 : loss : 0.019718, loss_ce: 0.006388
2021-12-11 22:24:00,423 iteration 6487 : loss : 0.015114, loss_ce: 0.004526
2021-12-11 22:24:01,884 iteration 6488 : loss : 0.011633, loss_ce: 0.004650
2021-12-11 22:24:03,523 iteration 6489 : loss : 0.015058, loss_ce: 0.004072
2021-12-11 22:24:04,984 iteration 6490 : loss : 0.013256, loss_ce: 0.005276
2021-12-11 22:24:06,604 iteration 6491 : loss : 0.022173, loss_ce: 0.006734
2021-12-11 22:24:08,149 iteration 6492 : loss : 0.012264, loss_ce: 0.004308
2021-12-11 22:24:09,756 iteration 6493 : loss : 0.021477, loss_ce: 0.005674
2021-12-11 22:24:11,331 iteration 6494 : loss : 0.016101, loss_ce: 0.005866
 96%|███████████████████████████▋ | 382/400 [3:03:56<08:38, 28.79s/it]2021-12-11 22:24:13,029 iteration 6495 : loss : 0.011681, loss_ce: 0.002953
2021-12-11 22:24:14,589 iteration 6496 : loss : 0.014657, loss_ce: 0.005301
2021-12-11 22:24:16,207 iteration 6497 : loss : 0.011671, loss_ce: 0.004090
2021-12-11 22:24:17,819 iteration 6498 : loss : 0.019112, loss_ce: 0.008529
2021-12-11 22:24:19,535 iteration 6499 : loss : 0.023227, loss_ce: 0.008038
2021-12-11 22:24:21,174 iteration 6500 : loss : 0.017388, loss_ce: 0.006734
2021-12-11 22:24:22,841 iteration 6501 : loss : 0.014298, loss_ce: 0.003515
2021-12-11 22:24:24,490 iteration 6502 : loss : 0.017785, loss_ce: 0.006408
2021-12-11 22:24:26,198 iteration 6503 : loss : 0.020278, loss_ce: 0.007693
2021-12-11 22:24:27,720 iteration 6504 : loss : 0.014705, loss_ce: 0.007928
2021-12-11 22:24:29,267 iteration 6505 : loss : 0.014920, loss_ce: 0.003990
2021-12-11 22:24:30,830 iteration 6506 : loss : 0.013799, loss_ce: 0.004062
2021-12-11 22:24:32,393 iteration 6507 : loss : 0.012642, loss_ce: 0.004938
2021-12-11 22:24:33,979 iteration 6508 : loss : 0.012990, loss_ce: 0.003802
2021-12-11 22:24:35,550 iteration 6509 : loss : 0.013842, loss_ce: 0.005927
2021-12-11 22:24:37,098 iteration 6510 : loss : 0.015654, loss_ce: 0.004944
2021-12-11 22:24:38,683 iteration 6511 : loss : 0.014388, loss_ce: 0.006360
 96%|███████████████████████████▊ | 383/400 [3:04:23<08:02, 28.36s/it]2021-12-11 22:24:40,322 iteration 6512 : loss : 0.015793, loss_ce: 0.006346
2021-12-11 22:24:41,830 iteration 6513 : loss : 0.018802, loss_ce: 0.007364
2021-12-11 22:24:43,394 iteration 6514 : loss : 0.013553, loss_ce: 0.003214
2021-12-11 22:24:44,977 iteration 6515 : loss : 0.012499, loss_ce: 0.003588
2021-12-11 22:24:46,562 iteration 6516 : loss : 0.021036, loss_ce: 0.005871
2021-12-11 22:24:48,236 iteration 6517 : loss : 0.015746, loss_ce: 0.006816
2021-12-11 22:24:49,746 iteration 6518 : loss : 0.017936, loss_ce: 0.007468
2021-12-11 22:24:51,411 iteration 6519 : loss : 0.020182, loss_ce: 0.006095
2021-12-11 22:24:52,913 iteration 6520 : loss : 0.011720, loss_ce: 0.004852
2021-12-11 22:24:54,544 iteration 6521 : loss : 0.013725, loss_ce: 0.005604
2021-12-11 22:24:56,116 iteration 6522 : loss : 0.016668, loss_ce: 0.006717
2021-12-11 22:24:57,627 iteration 6523 : loss : 0.019114, loss_ce: 0.005141
2021-12-11 22:24:59,213 iteration 6524 : loss : 0.027799, loss_ce: 0.010474
2021-12-11 22:25:00,776 iteration 6525 : loss : 0.014057, loss_ce: 0.004489
2021-12-11 22:25:02,381 iteration 6526 : loss : 0.013748, loss_ce: 0.005140
2021-12-11 22:25:04,037 iteration 6527 : loss : 0.017038, loss_ce: 0.005475
2021-12-11 22:25:05,646 iteration 6528 : loss : 0.015380, loss_ce: 0.005891
 96%|███████████████████████████▊ | 384/400 [3:04:50<07:26, 27.94s/it]2021-12-11 22:25:07,222 iteration 6529 : loss : 0.012290, loss_ce: 0.004334
2021-12-11 22:25:08,703 iteration 6530 : loss : 0.010146, loss_ce: 0.004332
2021-12-11 22:25:10,283 iteration 6531 : loss : 0.011470, loss_ce: 0.002445
2021-12-11 22:25:11,894 iteration 6532 : loss : 0.010589, loss_ce: 0.003415
2021-12-11 22:25:13,428 iteration 6533 : loss : 0.014007, loss_ce: 0.005587
2021-12-11 22:25:15,049 iteration 6534 : loss : 0.017369, loss_ce: 0.004865
2021-12-11 22:25:16,638 iteration 6535 : loss : 0.017437, loss_ce: 0.006677
2021-12-11 22:25:18,263 iteration 6536 : loss : 0.015215, loss_ce: 0.006263
2021-12-11 22:25:19,972 iteration 6537 : loss : 0.024022, loss_ce: 0.006308
2021-12-11 22:25:21,512 iteration 6538 : loss : 0.016083, loss_ce: 0.005352
2021-12-11 22:25:23,247 iteration 6539 : loss : 0.025864, loss_ce: 0.009308
2021-12-11 22:25:24,778 iteration 6540 : loss : 0.015685, loss_ce: 0.006723
2021-12-11 22:25:26,268 iteration 6541 : loss : 0.012011, loss_ce: 0.004770
2021-12-11 22:25:27,824 iteration 6542 : loss : 0.024407, loss_ce: 0.009004
2021-12-11 22:25:29,492 iteration 6543 : loss : 0.016462, loss_ce: 0.006483
2021-12-11 22:25:31,062 iteration 6544 : loss : 0.016491, loss_ce: 0.006648
2021-12-11 22:25:31,062 Training Data Eval:
2021-12-11 22:25:38,818   Average segmentation loss on training set: 0.0087
2021-12-11 22:25:38,819 Validation Data Eval:
2021-12-11 22:25:41,472   Average segmentation loss on validation set: 0.0859
2021-12-11 22:25:43,045 iteration 6545 : loss : 0.011097, loss_ce: 0.002780
 96%|███████████████████████████▉ | 385/400 [3:05:27<07:41, 30.78s/it]2021-12-11 22:25:44,753 iteration 6546 : loss : 0.019684, loss_ce: 0.006890
2021-12-11 22:25:46,256 iteration 6547 : loss : 0.019329, loss_ce: 0.004428
2021-12-11 22:25:47,852 iteration 6548 : loss : 0.027003, loss_ce: 0.008536
2021-12-11 22:25:49,541 iteration 6549 : loss : 0.019600, loss_ce: 0.005686
2021-12-11 22:25:51,117 iteration 6550 : loss : 0.012627, loss_ce: 0.005614
2021-12-11 22:25:52,778 iteration 6551 : loss : 0.018571, loss_ce: 0.007922
2021-12-11 22:25:54,481 iteration 6552 : loss : 0.017898, loss_ce: 0.007691
2021-12-11 22:25:56,054 iteration 6553 : loss : 0.017398, loss_ce: 0.006916
2021-12-11 22:25:57,794 iteration 6554 : loss : 0.023198, loss_ce: 0.006877
2021-12-11 22:25:59,336 iteration 6555 : loss : 0.016666, loss_ce: 0.006235
2021-12-11 22:26:00,947 iteration 6556 : loss : 0.016908, loss_ce: 0.006007
2021-12-11 22:26:02,437 iteration 6557 : loss : 0.010444, loss_ce: 0.003858
2021-12-11 22:26:04,080 iteration 6558 : loss : 0.023232, loss_ce: 0.008488
2021-12-11 22:26:05,586 iteration 6559 : loss : 0.010877, loss_ce: 0.003640
2021-12-11 22:26:07,099 iteration 6560 : loss : 0.012432, loss_ce: 0.005327
2021-12-11 22:26:08,698 iteration 6561 : loss : 0.013615, loss_ce: 0.004881
2021-12-11 22:26:10,286 iteration 6562 : loss : 0.021551, loss_ce: 0.009161
 96%|███████████████████████████▉ | 386/400 [3:05:55<06:56, 29.72s/it]2021-12-11 22:26:11,952 iteration 6563 : loss : 0.022170, loss_ce: 0.010114
2021-12-11 22:26:13,581 iteration 6564 : loss : 0.019835, loss_ce: 0.005677
2021-12-11 22:26:15,114 iteration 6565 : loss : 0.013559, loss_ce: 0.003935
2021-12-11 22:26:16,775 iteration 6566 : loss : 0.034514, loss_ce: 0.012880
2021-12-11 22:26:18,371 iteration 6567 : loss : 0.022339, loss_ce: 0.005932
2021-12-11 22:26:19,944 iteration 6568 : loss : 0.012557, loss_ce: 0.004809
2021-12-11 22:26:21,487 iteration 6569 : loss : 0.020413, loss_ce: 0.006067
2021-12-11 22:26:23,182 iteration 6570 : loss : 0.016439, loss_ce: 0.007078
2021-12-11 22:26:24,672 iteration 6571 : loss : 0.011640, loss_ce: 0.004597
2021-12-11 22:26:26,203 iteration 6572 : loss : 0.012584, loss_ce: 0.004257
2021-12-11 22:26:27,718 iteration 6573 : loss : 0.014858, loss_ce: 0.005213
2021-12-11 22:26:29,302 iteration 6574 : loss : 0.015644, loss_ce: 0.005875
2021-12-11 22:26:30,765 iteration 6575 : loss : 0.010458, loss_ce: 0.004251
2021-12-11 22:26:32,355 iteration 6576 : loss : 0.018316, loss_ce: 0.006916
2021-12-11 22:26:33,946 iteration 6577 : loss : 0.017149, loss_ce: 0.006318
2021-12-11 22:26:35,548 iteration 6578 : loss : 0.013508, loss_ce: 0.005892
2021-12-11 22:26:37,116 iteration 6579 : loss : 0.019718, loss_ce: 0.004480
 97%|████████████████████████████ | 387/400 [3:06:21<06:15, 28.85s/it]2021-12-11 22:26:38,814 iteration 6580 : loss : 0.015992, loss_ce: 0.005763
2021-12-11 22:26:40,446 iteration 6581 : loss : 0.028672, loss_ce: 0.009244
2021-12-11 22:26:42,094 iteration 6582 : loss : 0.030204, loss_ce: 0.011630
2021-12-11 22:26:43,686 iteration 6583 : loss : 0.012017, loss_ce: 0.004325
2021-12-11 22:26:45,292 iteration 6584 : loss : 0.015695, loss_ce: 0.005459
2021-12-11 22:26:46,823 iteration 6585 : loss : 0.015076, loss_ce: 0.004882
2021-12-11 22:26:48,424 iteration 6586 : loss : 0.016480, loss_ce: 0.006229
2021-12-11 22:26:49,937 iteration 6587 : loss : 0.013897, loss_ce: 0.005596
2021-12-11 22:26:51,580 iteration 6588 : loss : 0.017246, loss_ce: 0.006228
2021-12-11 22:26:53,149 iteration 6589 : loss : 0.012105, loss_ce: 0.003776
2021-12-11 22:26:54,700 iteration 6590 : loss : 0.014825, loss_ce: 0.006060
2021-12-11 22:26:56,229 iteration 6591 : loss : 0.013973, loss_ce: 0.005624
2021-12-11 22:26:57,806 iteration 6592 : loss : 0.012561, loss_ce: 0.003626
2021-12-11 22:26:59,447 iteration 6593 : loss : 0.019738, loss_ce: 0.008844
2021-12-11 22:27:00,997 iteration 6594 : loss : 0.012064, loss_ce: 0.004158
2021-12-11 22:27:02,492 iteration 6595 : loss : 0.013252, loss_ce: 0.004068
2021-12-11 22:27:04,021 iteration 6596 : loss : 0.009198, loss_ce: 0.003441
 97%|████████████████████████████▏| 388/400 [3:06:48<05:39, 28.27s/it]2021-12-11 22:27:05,730 iteration 6597 : loss : 0.014853, loss_ce: 0.006876
2021-12-11 22:27:07,382 iteration 6598 : loss : 0.018540, loss_ce: 0.004773
2021-12-11 22:27:08,911 iteration 6599 : loss : 0.014813, loss_ce: 0.005561
2021-12-11 22:27:10,542 iteration 6600 : loss : 0.025275, loss_ce: 0.009012
2021-12-11 22:27:12,052 iteration 6601 : loss : 0.012576, loss_ce: 0.004973
2021-12-11 22:27:13,508 iteration 6602 : loss : 0.010904, loss_ce: 0.003533
2021-12-11 22:27:15,110 iteration 6603 : loss : 0.022524, loss_ce: 0.006462
2021-12-11 22:27:16,782 iteration 6604 : loss : 0.019136, loss_ce: 0.006996
2021-12-11 22:27:18,390 iteration 6605 : loss : 0.022652, loss_ce: 0.008914
2021-12-11 22:27:19,983 iteration 6606 : loss : 0.016114, loss_ce: 0.007968
2021-12-11 22:27:21,519 iteration 6607 : loss : 0.020786, loss_ce: 0.006994
2021-12-11 22:27:23,133 iteration 6608 : loss : 0.015581, loss_ce: 0.005241
2021-12-11 22:27:24,807 iteration 6609 : loss : 0.018985, loss_ce: 0.008272
2021-12-11 22:27:26,363 iteration 6610 : loss : 0.024971, loss_ce: 0.008222
2021-12-11 22:27:27,832 iteration 6611 : loss : 0.012165, loss_ce: 0.005068
2021-12-11 22:27:29,414 iteration 6612 : loss : 0.014418, loss_ce: 0.005320
2021-12-11 22:27:31,047 iteration 6613 : loss : 0.019536, loss_ce: 0.005590
 97%|████████████████████████████▏| 389/400 [3:07:15<05:06, 27.90s/it]2021-12-11 22:27:32,569 iteration 6614 : loss : 0.010294, loss_ce: 0.003999
2021-12-11 22:27:34,174 iteration 6615 : loss : 0.025415, loss_ce: 0.010925
2021-12-11 22:27:35,785 iteration 6616 : loss : 0.014113, loss_ce: 0.005371
2021-12-11 22:27:37,325 iteration 6617 : loss : 0.013265, loss_ce: 0.002551
2021-12-11 22:27:38,909 iteration 6618 : loss : 0.015482, loss_ce: 0.005785
2021-12-11 22:27:40,534 iteration 6619 : loss : 0.014736, loss_ce: 0.005476
2021-12-11 22:27:42,123 iteration 6620 : loss : 0.020989, loss_ce: 0.006649
2021-12-11 22:27:43,612 iteration 6621 : loss : 0.014777, loss_ce: 0.006650
2021-12-11 22:27:45,062 iteration 6622 : loss : 0.010952, loss_ce: 0.003539
2021-12-11 22:27:46,639 iteration 6623 : loss : 0.016563, loss_ce: 0.008033
2021-12-11 22:27:48,079 iteration 6624 : loss : 0.012310, loss_ce: 0.004220
2021-12-11 22:27:49,523 iteration 6625 : loss : 0.010771, loss_ce: 0.004356
2021-12-11 22:27:51,080 iteration 6626 : loss : 0.015987, loss_ce: 0.006058
2021-12-11 22:27:52,587 iteration 6627 : loss : 0.010287, loss_ce: 0.003273
2021-12-11 22:27:54,200 iteration 6628 : loss : 0.015958, loss_ce: 0.005509
2021-12-11 22:27:55,699 iteration 6629 : loss : 0.013540, loss_ce: 0.005459
2021-12-11 22:27:55,699 Training Data Eval:
2021-12-11 22:28:03,447   Average segmentation loss on training set: 0.0085
2021-12-11 22:28:03,447 Validation Data Eval:
2021-12-11 22:28:06,105   Average segmentation loss on validation set: 0.0757
2021-12-11 22:28:07,687 iteration 6630 : loss : 0.015837, loss_ce: 0.006472
 98%|████████████████████████████▎| 390/400 [3:07:52<05:05, 30.52s/it]2021-12-11 22:28:09,197 iteration 6631 : loss : 0.012145, loss_ce: 0.004482
2021-12-11 22:28:10,794 iteration 6632 : loss : 0.018801, loss_ce: 0.004048
2021-12-11 22:28:12,344 iteration 6633 : loss : 0.012869, loss_ce: 0.004852
2021-12-11 22:28:13,860 iteration 6634 : loss : 0.013371, loss_ce: 0.005401
2021-12-11 22:28:15,480 iteration 6635 : loss : 0.010377, loss_ce: 0.004140
2021-12-11 22:28:17,001 iteration 6636 : loss : 0.011632, loss_ce: 0.005688
2021-12-11 22:28:18,595 iteration 6637 : loss : 0.018954, loss_ce: 0.006490
2021-12-11 22:28:20,191 iteration 6638 : loss : 0.010641, loss_ce: 0.003107
2021-12-11 22:28:21,779 iteration 6639 : loss : 0.018385, loss_ce: 0.006082
2021-12-11 22:28:23,384 iteration 6640 : loss : 0.017825, loss_ce: 0.004615
2021-12-11 22:28:24,941 iteration 6641 : loss : 0.017233, loss_ce: 0.006902
2021-12-11 22:28:26,513 iteration 6642 : loss : 0.014918, loss_ce: 0.004731
2021-12-11 22:28:28,164 iteration 6643 : loss : 0.016444, loss_ce: 0.007641
2021-12-11 22:28:29,838 iteration 6644 : loss : 0.016659, loss_ce: 0.006966
2021-12-11 22:28:31,399 iteration 6645 : loss : 0.017310, loss_ce: 0.006971
2021-12-11 22:28:32,967 iteration 6646 : loss : 0.017865, loss_ce: 0.008824
2021-12-11 22:28:34,552 iteration 6647 : loss : 0.016602, loss_ce: 0.003339
 98%|████████████████████████████▎| 391/400 [3:08:19<04:24, 29.42s/it]2021-12-11 22:28:36,241 iteration 6648 : loss : 0.014792, loss_ce: 0.005309
2021-12-11 22:28:37,865 iteration 6649 : loss : 0.018385, loss_ce: 0.005231
2021-12-11 22:28:39,376 iteration 6650 : loss : 0.012838, loss_ce: 0.004758
2021-12-11 22:28:40,927 iteration 6651 : loss : 0.014733, loss_ce: 0.006302
2021-12-11 22:28:42,542 iteration 6652 : loss : 0.015529, loss_ce: 0.005984
2021-12-11 22:28:44,191 iteration 6653 : loss : 0.016373, loss_ce: 0.005120
2021-12-11 22:28:45,919 iteration 6654 : loss : 0.020404, loss_ce: 0.006995
2021-12-11 22:28:47,480 iteration 6655 : loss : 0.012161, loss_ce: 0.004769
2021-12-11 22:28:49,159 iteration 6656 : loss : 0.018452, loss_ce: 0.006540
2021-12-11 22:28:50,764 iteration 6657 : loss : 0.019954, loss_ce: 0.006319
2021-12-11 22:28:52,411 iteration 6658 : loss : 0.017128, loss_ce: 0.005958
2021-12-11 22:28:54,014 iteration 6659 : loss : 0.022698, loss_ce: 0.006724
2021-12-11 22:28:55,586 iteration 6660 : loss : 0.013042, loss_ce: 0.005951
2021-12-11 22:28:57,101 iteration 6661 : loss : 0.012257, loss_ce: 0.004121
2021-12-11 22:28:58,725 iteration 6662 : loss : 0.016827, loss_ce: 0.005776
2021-12-11 22:29:00,268 iteration 6663 : loss : 0.013359, loss_ce: 0.005710
2021-12-11 22:29:01,889 iteration 6664 : loss : 0.012337, loss_ce: 0.005860
 98%|████████████████████████████▍| 392/400 [3:08:46<03:50, 28.80s/it]2021-12-11 22:29:03,551 iteration 6665 : loss : 0.023183, loss_ce: 0.008250
2021-12-11 22:29:05,176 iteration 6666 : loss : 0.011760, loss_ce: 0.003421
2021-12-11 22:29:06,763 iteration 6667 : loss : 0.020489, loss_ce: 0.007744
2021-12-11 22:29:08,481 iteration 6668 : loss : 0.021503, loss_ce: 0.010416
2021-12-11 22:29:10,004 iteration 6669 : loss : 0.014662, loss_ce: 0.004934
2021-12-11 22:29:11,527 iteration 6670 : loss : 0.010988, loss_ce: 0.004205
2021-12-11 22:29:13,065 iteration 6671 : loss : 0.018202, loss_ce: 0.006931
2021-12-11 22:29:14,542 iteration 6672 : loss : 0.012869, loss_ce: 0.003361
2021-12-11 22:29:16,173 iteration 6673 : loss : 0.025046, loss_ce: 0.009006
2021-12-11 22:29:17,719 iteration 6674 : loss : 0.015022, loss_ce: 0.006565
2021-12-11 22:29:19,362 iteration 6675 : loss : 0.014923, loss_ce: 0.004987
2021-12-11 22:29:20,882 iteration 6676 : loss : 0.012483, loss_ce: 0.003689
2021-12-11 22:29:22,430 iteration 6677 : loss : 0.013981, loss_ce: 0.003552
2021-12-11 22:29:23,867 iteration 6678 : loss : 0.010618, loss_ce: 0.004507
2021-12-11 22:29:25,581 iteration 6679 : loss : 0.016172, loss_ce: 0.007016
2021-12-11 22:29:27,158 iteration 6680 : loss : 0.019973, loss_ce: 0.007176
2021-12-11 22:29:28,762 iteration 6681 : loss : 0.012944, loss_ce: 0.005399
 98%|████████████████████████████▍| 393/400 [3:09:13<03:17, 28.22s/it]2021-12-11 22:29:30,411 iteration 6682 : loss : 0.012321, loss_ce: 0.005506
2021-12-11 22:29:32,104 iteration 6683 : loss : 0.013882, loss_ce: 0.004381
2021-12-11 22:29:33,629 iteration 6684 : loss : 0.023665, loss_ce: 0.008344
2021-12-11 22:29:35,265 iteration 6685 : loss : 0.022964, loss_ce: 0.008900
2021-12-11 22:29:36,776 iteration 6686 : loss : 0.015524, loss_ce: 0.007581
2021-12-11 22:29:38,313 iteration 6687 : loss : 0.025022, loss_ce: 0.006637
2021-12-11 22:29:39,951 iteration 6688 : loss : 0.015010, loss_ce: 0.005469
2021-12-11 22:29:41,508 iteration 6689 : loss : 0.012408, loss_ce: 0.005188
2021-12-11 22:29:43,056 iteration 6690 : loss : 0.015058, loss_ce: 0.005935
2021-12-11 22:29:44,707 iteration 6691 : loss : 0.018797, loss_ce: 0.007332
2021-12-11 22:29:46,317 iteration 6692 : loss : 0.027610, loss_ce: 0.007605
2021-12-11 22:29:47,966 iteration 6693 : loss : 0.013315, loss_ce: 0.004033
2021-12-11 22:29:49,582 iteration 6694 : loss : 0.015201, loss_ce: 0.006153
2021-12-11 22:29:51,233 iteration 6695 : loss : 0.016321, loss_ce: 0.007025
2021-12-11 22:29:52,758 iteration 6696 : loss : 0.012449, loss_ce: 0.005236
2021-12-11 22:29:54,390 iteration 6697 : loss : 0.014766, loss_ce: 0.004713
2021-12-11 22:29:55,975 iteration 6698 : loss : 0.014231, loss_ce: 0.004749
 98%|████████████████████████████▌| 394/400 [3:09:40<02:47, 27.92s/it]2021-12-11 22:29:57,571 iteration 6699 : loss : 0.014289, loss_ce: 0.007380
2021-12-11 22:29:59,240 iteration 6700 : loss : 0.019748, loss_ce: 0.008661
2021-12-11 22:30:00,807 iteration 6701 : loss : 0.013509, loss_ce: 0.005734
2021-12-11 22:30:02,349 iteration 6702 : loss : 0.022744, loss_ce: 0.006998
2021-12-11 22:30:03,906 iteration 6703 : loss : 0.014380, loss_ce: 0.004557
2021-12-11 22:30:05,538 iteration 6704 : loss : 0.015708, loss_ce: 0.005332
2021-12-11 22:30:07,074 iteration 6705 : loss : 0.019341, loss_ce: 0.006240
2021-12-11 22:30:08,606 iteration 6706 : loss : 0.013868, loss_ce: 0.005789
2021-12-11 22:30:10,137 iteration 6707 : loss : 0.017398, loss_ce: 0.004906
2021-12-11 22:30:11,611 iteration 6708 : loss : 0.012361, loss_ce: 0.004300
2021-12-11 22:30:13,130 iteration 6709 : loss : 0.011007, loss_ce: 0.003592
2021-12-11 22:30:14,663 iteration 6710 : loss : 0.018833, loss_ce: 0.006325
2021-12-11 22:30:16,184 iteration 6711 : loss : 0.014138, loss_ce: 0.002498
2021-12-11 22:30:17,782 iteration 6712 : loss : 0.013680, loss_ce: 0.004938
2021-12-11 22:30:19,397 iteration 6713 : loss : 0.014211, loss_ce: 0.004911
2021-12-11 22:30:21,003 iteration 6714 : loss : 0.014282, loss_ce: 0.006584
2021-12-11 22:30:21,003 Training Data Eval:
2021-12-11 22:30:28,766   Average segmentation loss on training set: 0.0081
2021-12-11 22:30:28,767 Validation Data Eval:
2021-12-11 22:30:31,427   Average segmentation loss on validation set: 0.0816
2021-12-11 22:30:33,053 iteration 6715 : loss : 0.014237, loss_ce: 0.004620
 99%|████████████████████████████▋| 395/400 [3:10:17<02:33, 30.67s/it]2021-12-11 22:30:34,707 iteration 6716 : loss : 0.009128, loss_ce: 0.003275
2021-12-11 22:30:36,280 iteration 6717 : loss : 0.024254, loss_ce: 0.008757
2021-12-11 22:30:37,781 iteration 6718 : loss : 0.011260, loss_ce: 0.003533
2021-12-11 22:30:39,332 iteration 6719 : loss : 0.012979, loss_ce: 0.003977
2021-12-11 22:30:40,896 iteration 6720 : loss : 0.012182, loss_ce: 0.004332
2021-12-11 22:30:42,520 iteration 6721 : loss : 0.019529, loss_ce: 0.007373
2021-12-11 22:30:44,155 iteration 6722 : loss : 0.018542, loss_ce: 0.005716
2021-12-11 22:30:45,720 iteration 6723 : loss : 0.013693, loss_ce: 0.004543
2021-12-11 22:30:47,253 iteration 6724 : loss : 0.015703, loss_ce: 0.007028
2021-12-11 22:30:48,868 iteration 6725 : loss : 0.012869, loss_ce: 0.004804
2021-12-11 22:30:50,441 iteration 6726 : loss : 0.017427, loss_ce: 0.004833
2021-12-11 22:30:52,050 iteration 6727 : loss : 0.016351, loss_ce: 0.006897
2021-12-11 22:30:53,655 iteration 6728 : loss : 0.014407, loss_ce: 0.006007
2021-12-11 22:30:55,166 iteration 6729 : loss : 0.013137, loss_ce: 0.004398
2021-12-11 22:30:56,704 iteration 6730 : loss : 0.020365, loss_ce: 0.006371
2021-12-11 22:30:58,241 iteration 6731 : loss : 0.012912, loss_ce: 0.005900
2021-12-11 22:30:59,814 iteration 6732 : loss : 0.013145, loss_ce: 0.006203
 99%|████████████████████████████▋| 396/400 [3:10:44<01:57, 29.49s/it]2021-12-11 22:31:01,505 iteration 6733 : loss : 0.014953, loss_ce: 0.006431
2021-12-11 22:31:03,030 iteration 6734 : loss : 0.007674, loss_ce: 0.002301
2021-12-11 22:31:04,623 iteration 6735 : loss : 0.015217, loss_ce: 0.007603
2021-12-11 22:31:06,196 iteration 6736 : loss : 0.016754, loss_ce: 0.004922
2021-12-11 22:31:07,726 iteration 6737 : loss : 0.014329, loss_ce: 0.006495
2021-12-11 22:31:09,289 iteration 6738 : loss : 0.011961, loss_ce: 0.004227
2021-12-11 22:31:10,905 iteration 6739 : loss : 0.021360, loss_ce: 0.008816
2021-12-11 22:31:12,572 iteration 6740 : loss : 0.017961, loss_ce: 0.006731
2021-12-11 22:31:14,078 iteration 6741 : loss : 0.010118, loss_ce: 0.003887
2021-12-11 22:31:15,706 iteration 6742 : loss : 0.015786, loss_ce: 0.006846
2021-12-11 22:31:17,313 iteration 6743 : loss : 0.019062, loss_ce: 0.006359
2021-12-11 22:31:18,987 iteration 6744 : loss : 0.015560, loss_ce: 0.006953
2021-12-11 22:31:20,522 iteration 6745 : loss : 0.019811, loss_ce: 0.005758
2021-12-11 22:31:22,072 iteration 6746 : loss : 0.015898, loss_ce: 0.006284
2021-12-11 22:31:23,631 iteration 6747 : loss : 0.017246, loss_ce: 0.005617
2021-12-11 22:31:25,223 iteration 6748 : loss : 0.013524, loss_ce: 0.004765
2021-12-11 22:31:26,837 iteration 6749 : loss : 0.018295, loss_ce: 0.006239
 99%|████████████████████████████▊| 397/400 [3:11:11<01:26, 28.75s/it]2021-12-11 22:31:28,443 iteration 6750 : loss : 0.020876, loss_ce: 0.008581
2021-12-11 22:31:30,076 iteration 6751 : loss : 0.019194, loss_ce: 0.009553
2021-12-11 22:31:31,706 iteration 6752 : loss : 0.016234, loss_ce: 0.007597
2021-12-11 22:31:33,301 iteration 6753 : loss : 0.017103, loss_ce: 0.007404
2021-12-11 22:31:34,945 iteration 6754 : loss : 0.017453, loss_ce: 0.004610
2021-12-11 22:31:36,519 iteration 6755 : loss : 0.009269, loss_ce: 0.002643
2021-12-11 22:31:38,099 iteration 6756 : loss : 0.013037, loss_ce: 0.004838
2021-12-11 22:31:39,698 iteration 6757 : loss : 0.016932, loss_ce: 0.007241
2021-12-11 22:31:41,231 iteration 6758 : loss : 0.009014, loss_ce: 0.003604
2021-12-11 22:31:42,862 iteration 6759 : loss : 0.016661, loss_ce: 0.005995
2021-12-11 22:31:44,427 iteration 6760 : loss : 0.013308, loss_ce: 0.005054
2021-12-11 22:31:46,046 iteration 6761 : loss : 0.015285, loss_ce: 0.006160
2021-12-11 22:31:47,504 iteration 6762 : loss : 0.010502, loss_ce: 0.003715
2021-12-11 22:31:49,080 iteration 6763 : loss : 0.016232, loss_ce: 0.004075
2021-12-11 22:31:50,609 iteration 6764 : loss : 0.019272, loss_ce: 0.007399
2021-12-11 22:31:52,122 iteration 6765 : loss : 0.011438, loss_ce: 0.003194
2021-12-11 22:31:53,663 iteration 6766 : loss : 0.014582, loss_ce: 0.005313
100%|████████████████████████████▊| 398/400 [3:11:38<00:56, 28.18s/it]2021-12-11 22:31:55,429 iteration 6767 : loss : 0.016726, loss_ce: 0.005445
2021-12-11 22:31:56,931 iteration 6768 : loss : 0.014042, loss_ce: 0.006386
2021-12-11 22:31:58,502 iteration 6769 : loss : 0.015928, loss_ce: 0.004882
2021-12-11 22:31:59,999 iteration 6770 : loss : 0.010763, loss_ce: 0.004020
2021-12-11 22:32:01,556 iteration 6771 : loss : 0.018147, loss_ce: 0.005756
2021-12-11 22:32:03,209 iteration 6772 : loss : 0.017842, loss_ce: 0.004987
2021-12-11 22:32:04,804 iteration 6773 : loss : 0.011675, loss_ce: 0.004437
2021-12-11 22:32:06,381 iteration 6774 : loss : 0.014779, loss_ce: 0.005767
2021-12-11 22:32:07,943 iteration 6775 : loss : 0.020984, loss_ce: 0.007863
2021-12-11 22:32:09,589 iteration 6776 : loss : 0.026548, loss_ce: 0.011168
2021-12-11 22:32:11,160 iteration 6777 : loss : 0.016903, loss_ce: 0.006136
2021-12-11 22:32:12,693 iteration 6778 : loss : 0.011834, loss_ce: 0.003763
2021-12-11 22:32:14,248 iteration 6779 : loss : 0.012518, loss_ce: 0.003668
2021-12-11 22:32:15,736 iteration 6780 : loss : 0.010544, loss_ce: 0.003392
2021-12-11 22:32:17,249 iteration 6781 : loss : 0.011911, loss_ce: 0.005125
2021-12-11 22:32:18,822 iteration 6782 : loss : 0.010613, loss_ce: 0.004243
2021-12-11 22:32:20,395 iteration 6783 : loss : 0.013730, loss_ce: 0.005625
100%|████████████████████████████▉| 399/400 [3:12:05<00:27, 27.74s/it]2021-12-11 22:32:22,137 iteration 6784 : loss : 0.020642, loss_ce: 0.007232
2021-12-11 22:32:23,626 iteration 6785 : loss : 0.018931, loss_ce: 0.007731
2021-12-11 22:32:25,080 iteration 6786 : loss : 0.011716, loss_ce: 0.004931
2021-12-11 22:32:26,676 iteration 6787 : loss : 0.015176, loss_ce: 0.005168
2021-12-11 22:32:28,163 iteration 6788 : loss : 0.020420, loss_ce: 0.004909
2021-12-11 22:32:29,753 iteration 6789 : loss : 0.011108, loss_ce: 0.004412
2021-12-11 22:32:31,342 iteration 6790 : loss : 0.013638, loss_ce: 0.004508
2021-12-11 22:32:32,977 iteration 6791 : loss : 0.020270, loss_ce: 0.006220
2021-12-11 22:32:34,588 iteration 6792 : loss : 0.014980, loss_ce: 0.005212
2021-12-11 22:32:36,177 iteration 6793 : loss : 0.012572, loss_ce: 0.004008
2021-12-11 22:32:37,777 iteration 6794 : loss : 0.013701, loss_ce: 0.005080
2021-12-11 22:32:39,330 iteration 6795 : loss : 0.012962, loss_ce: 0.004448
2021-12-11 22:32:40,909 iteration 6796 : loss : 0.014226, loss_ce: 0.004625
2021-12-11 22:32:42,427 iteration 6797 : loss : 0.013856, loss_ce: 0.005374
2021-12-11 22:32:43,907 iteration 6798 : loss : 0.013772, loss_ce: 0.004664
2021-12-11 22:32:45,465 iteration 6799 : loss : 0.018470, loss_ce: 0.008533
2021-12-11 22:32:45,465 Training Data Eval:
2021-12-11 22:32:53,216   Average segmentation loss on training set: 0.0083
2021-12-11 22:32:53,217 Validation Data Eval:
2021-12-11 22:32:55,871   Average segmentation loss on validation set: 0.0765
2021-12-11 22:32:57,425 iteration 6800 : loss : 0.014445, loss_ce: 0.006752
2021-12-11 22:32:59,551 save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/NEW_TU/UNET_ADAM_seed2epoch_399.pth
2021-12-11 22:33:01,566 save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/NEW_TU/UNET_ADAM_seed2epoch_399.pth
100%|████████████████████████████▉| 399/400 [3:12:46<00:28, 28.99s/it]
