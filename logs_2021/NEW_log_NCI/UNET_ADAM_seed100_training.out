2021-12-11 19:17:25,859 Logging directory: /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/TransUNet/log_dir/trRUNMC_cv1_r3/i2i2l/
2021-12-11 19:17:25,860 Tensorboard directory: /scratch_net/biwidl217_second/arismu/Tensorboard/trRUNMC_cv1_r3/i2i2l/
2021-12-11 19:17:25,860 ============================================================
2021-12-11 19:17:25,860 EXPERIMENT NAME: trRUNMC_cv1_r3/i2i2l/
2021-12-11 19:17:25,860 ============================================================
2021-12-11 19:17:25,860 Loading data...
2021-12-11 19:17:25,860 Reading NCI - RUNMC images...
2021-12-11 19:17:25,860 Data root directory: /itet-stor/arismu/bmicdatasets-originals/Originals/Challenge_Datasets/NCI_Prostate/
2021-12-11 19:17:25,863 Already preprocessed this configuration. Loading now!
2021-12-11 19:17:25,888 Training Images: (256, 256, 286)
2021-12-11 19:17:25,888 Training Labels: (256, 256, 286)
2021-12-11 19:17:25,888 Validation Images: (256, 256, 98)
2021-12-11 19:17:25,888 Validation Labels: (256, 256, 98)
2021-12-11 19:17:25,888 ============================================================
2021-12-11 19:17:25,925 17 iterations per epoch. 6800 max iterations 
  0%|                                         | 0/400 [00:00<?, ?it/s]2021-12-11 19:17:28,855 iteration 1 : loss : 0.815387, loss_ce: 0.941383
2021-12-11 19:17:30,275 iteration 2 : loss : 0.789468, loss_ce: 0.889774
2021-12-11 19:17:31,664 iteration 3 : loss : 0.748390, loss_ce: 0.793652
2021-12-11 19:17:33,106 iteration 4 : loss : 0.684964, loss_ce: 0.727675
2021-12-11 19:17:34,468 iteration 5 : loss : 0.655798, loss_ce: 0.645508
2021-12-11 19:17:35,960 iteration 6 : loss : 0.604217, loss_ce: 0.578272
2021-12-11 19:17:37,417 iteration 7 : loss : 0.600344, loss_ce: 0.556795
2021-12-11 19:17:38,872 iteration 8 : loss : 0.564262, loss_ce: 0.509098
2021-12-11 19:17:40,211 iteration 9 : loss : 0.536057, loss_ce: 0.491096
2021-12-11 19:17:41,671 iteration 10 : loss : 0.512509, loss_ce: 0.462035
2021-12-11 19:17:43,142 iteration 11 : loss : 0.490542, loss_ce: 0.432905
2021-12-11 19:17:44,642 iteration 12 : loss : 0.464005, loss_ce: 0.411416
2021-12-11 19:17:46,047 iteration 13 : loss : 0.505287, loss_ce: 0.429255
2021-12-11 19:17:47,546 iteration 14 : loss : 0.426996, loss_ce: 0.354793
2021-12-11 19:17:48,974 iteration 15 : loss : 0.443861, loss_ce: 0.362404
2021-12-11 19:17:50,384 iteration 16 : loss : 0.440679, loss_ce: 0.360757
2021-12-11 19:17:51,765 iteration 17 : loss : 0.467492, loss_ce: 0.346045
  0%|                               | 1/400 [00:25<2:52:16, 25.91s/it]2021-12-11 19:17:53,288 iteration 18 : loss : 0.397373, loss_ce: 0.308345
2021-12-11 19:17:54,741 iteration 19 : loss : 0.414227, loss_ce: 0.292262
2021-12-11 19:17:56,280 iteration 20 : loss : 0.394118, loss_ce: 0.293765
2021-12-11 19:17:57,702 iteration 21 : loss : 0.428348, loss_ce: 0.302849
2021-12-11 19:17:59,061 iteration 22 : loss : 0.432670, loss_ce: 0.295408
2021-12-11 19:18:00,540 iteration 23 : loss : 0.438399, loss_ce: 0.294597
2021-12-11 19:18:02,018 iteration 24 : loss : 0.402717, loss_ce: 0.281607
2021-12-11 19:18:03,534 iteration 25 : loss : 0.408995, loss_ce: 0.296463
2021-12-11 19:18:04,966 iteration 26 : loss : 0.358290, loss_ce: 0.250916
2021-12-11 19:18:06,344 iteration 27 : loss : 0.379982, loss_ce: 0.252750
2021-12-11 19:18:07,708 iteration 28 : loss : 0.316500, loss_ce: 0.214670
2021-12-11 19:18:09,167 iteration 29 : loss : 0.364453, loss_ce: 0.244662
2021-12-11 19:18:10,561 iteration 30 : loss : 0.352563, loss_ce: 0.237125
2021-12-11 19:18:11,985 iteration 31 : loss : 0.326776, loss_ce: 0.205714
2021-12-11 19:18:13,391 iteration 32 : loss : 0.337797, loss_ce: 0.242519
2021-12-11 19:18:14,862 iteration 33 : loss : 0.348895, loss_ce: 0.230520
2021-12-11 19:18:16,394 iteration 34 : loss : 0.299587, loss_ce: 0.193724
  0%|▏                              | 2/400 [00:50<2:46:46, 25.14s/it]2021-12-11 19:18:17,900 iteration 35 : loss : 0.321047, loss_ce: 0.214998
2021-12-11 19:18:19,348 iteration 36 : loss : 0.373784, loss_ce: 0.213771
2021-12-11 19:18:20,817 iteration 37 : loss : 0.302521, loss_ce: 0.184262
2021-12-11 19:18:22,262 iteration 38 : loss : 0.295231, loss_ce: 0.176848
2021-12-11 19:18:23,606 iteration 39 : loss : 0.345357, loss_ce: 0.207169
2021-12-11 19:18:25,016 iteration 40 : loss : 0.351442, loss_ce: 0.220211
2021-12-11 19:18:26,340 iteration 41 : loss : 0.301976, loss_ce: 0.178105
2021-12-11 19:18:27,787 iteration 42 : loss : 0.354774, loss_ce: 0.214330
2021-12-11 19:18:29,279 iteration 43 : loss : 0.259805, loss_ce: 0.149180
2021-12-11 19:18:30,615 iteration 44 : loss : 0.320356, loss_ce: 0.197252
2021-12-11 19:18:32,111 iteration 45 : loss : 0.305083, loss_ce: 0.163952
2021-12-11 19:18:33,555 iteration 46 : loss : 0.281397, loss_ce: 0.165542
2021-12-11 19:18:34,993 iteration 47 : loss : 0.297765, loss_ce: 0.165371
2021-12-11 19:18:36,435 iteration 48 : loss : 0.268719, loss_ce: 0.162449
2021-12-11 19:18:37,930 iteration 49 : loss : 0.331626, loss_ce: 0.190743
2021-12-11 19:18:39,435 iteration 50 : loss : 0.284741, loss_ce: 0.160649
2021-12-11 19:18:40,950 iteration 51 : loss : 0.250676, loss_ce: 0.135701
  1%|▏                              | 3/400 [01:15<2:44:34, 24.87s/it]2021-12-11 19:18:42,380 iteration 52 : loss : 0.305993, loss_ce: 0.156741
2021-12-11 19:18:43,789 iteration 53 : loss : 0.282702, loss_ce: 0.155947
2021-12-11 19:18:45,340 iteration 54 : loss : 0.306161, loss_ce: 0.161557
2021-12-11 19:18:46,910 iteration 55 : loss : 0.341614, loss_ce: 0.175037
2021-12-11 19:18:48,487 iteration 56 : loss : 0.280580, loss_ce: 0.156721
2021-12-11 19:18:49,993 iteration 57 : loss : 0.262448, loss_ce: 0.146719
2021-12-11 19:18:51,461 iteration 58 : loss : 0.315709, loss_ce: 0.178585
2021-12-11 19:18:52,937 iteration 59 : loss : 0.265083, loss_ce: 0.140130
2021-12-11 19:18:54,444 iteration 60 : loss : 0.219837, loss_ce: 0.134934
2021-12-11 19:18:55,957 iteration 61 : loss : 0.271944, loss_ce: 0.147510
2021-12-11 19:18:57,554 iteration 62 : loss : 0.297388, loss_ce: 0.143052
2021-12-11 19:18:59,068 iteration 63 : loss : 0.265987, loss_ce: 0.150586
2021-12-11 19:19:00,642 iteration 64 : loss : 0.324175, loss_ce: 0.173133
2021-12-11 19:19:02,186 iteration 65 : loss : 0.262293, loss_ce: 0.122409
2021-12-11 19:19:03,773 iteration 66 : loss : 0.275734, loss_ce: 0.139376
2021-12-11 19:19:05,300 iteration 67 : loss : 0.255910, loss_ce: 0.135050
2021-12-11 19:19:06,757 iteration 68 : loss : 0.245615, loss_ce: 0.130378
  1%|▎                              | 4/400 [01:40<2:46:35, 25.24s/it]2021-12-11 19:19:08,367 iteration 69 : loss : 0.329515, loss_ce: 0.158504
2021-12-11 19:19:09,861 iteration 70 : loss : 0.315448, loss_ce: 0.151961
2021-12-11 19:19:11,367 iteration 71 : loss : 0.275539, loss_ce: 0.169979
2021-12-11 19:19:12,912 iteration 72 : loss : 0.267044, loss_ce: 0.139809
2021-12-11 19:19:14,473 iteration 73 : loss : 0.236417, loss_ce: 0.119449
2021-12-11 19:19:16,007 iteration 74 : loss : 0.237183, loss_ce: 0.123346
2021-12-11 19:19:17,562 iteration 75 : loss : 0.244514, loss_ce: 0.140834
2021-12-11 19:19:19,021 iteration 76 : loss : 0.261068, loss_ce: 0.139665
2021-12-11 19:19:20,571 iteration 77 : loss : 0.301372, loss_ce: 0.147346
2021-12-11 19:19:22,110 iteration 78 : loss : 0.243374, loss_ce: 0.106171
2021-12-11 19:19:23,658 iteration 79 : loss : 0.275420, loss_ce: 0.126941
2021-12-11 19:19:25,103 iteration 80 : loss : 0.266540, loss_ce: 0.120509
2021-12-11 19:19:26,699 iteration 81 : loss : 0.285122, loss_ce: 0.150556
2021-12-11 19:19:28,218 iteration 82 : loss : 0.307387, loss_ce: 0.124423
2021-12-11 19:19:29,701 iteration 83 : loss : 0.305137, loss_ce: 0.115171
2021-12-11 19:19:31,309 iteration 84 : loss : 0.326660, loss_ce: 0.161941
2021-12-11 19:19:31,309 Training Data Eval:
2021-12-11 19:19:38,917   Average segmentation loss on training set: 0.2678
2021-12-11 19:19:38,917 Validation Data Eval:
2021-12-11 19:19:41,706   Average segmentation loss on validation set: 0.2691
2021-12-11 19:19:43,648 Found new lowest validation loss at iteration 84! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/NEW_TU/UNET_ADAM_best_val_loss_seed100.pth
2021-12-11 19:19:45,037 iteration 85 : loss : 0.309797, loss_ce: 0.160385
  1%|▍                              | 5/400 [02:19<3:17:08, 29.95s/it]2021-12-11 19:19:46,579 iteration 86 : loss : 0.258956, loss_ce: 0.137054
2021-12-11 19:19:48,030 iteration 87 : loss : 0.247647, loss_ce: 0.113955
2021-12-11 19:19:49,494 iteration 88 : loss : 0.212552, loss_ce: 0.119364
2021-12-11 19:19:51,032 iteration 89 : loss : 0.299669, loss_ce: 0.133134
2021-12-11 19:19:52,546 iteration 90 : loss : 0.224723, loss_ce: 0.113814
2021-12-11 19:19:54,125 iteration 91 : loss : 0.269630, loss_ce: 0.146293
2021-12-11 19:19:55,724 iteration 92 : loss : 0.260308, loss_ce: 0.115690
2021-12-11 19:19:57,192 iteration 93 : loss : 0.236883, loss_ce: 0.104423
2021-12-11 19:19:58,768 iteration 94 : loss : 0.235177, loss_ce: 0.126280
2021-12-11 19:20:00,288 iteration 95 : loss : 0.307630, loss_ce: 0.166810
2021-12-11 19:20:01,940 iteration 96 : loss : 0.246443, loss_ce: 0.119256
2021-12-11 19:20:03,467 iteration 97 : loss : 0.284005, loss_ce: 0.128113
2021-12-11 19:20:05,025 iteration 98 : loss : 0.319652, loss_ce: 0.139273
2021-12-11 19:20:06,542 iteration 99 : loss : 0.296041, loss_ce: 0.126350
2021-12-11 19:20:08,104 iteration 100 : loss : 0.234563, loss_ce: 0.107905
2021-12-11 19:20:09,625 iteration 101 : loss : 0.245734, loss_ce: 0.115126
2021-12-11 19:20:11,126 iteration 102 : loss : 0.284703, loss_ce: 0.148925
  2%|▍                              | 6/400 [02:45<3:08:00, 28.63s/it]2021-12-11 19:20:12,724 iteration 103 : loss : 0.274873, loss_ce: 0.118682
2021-12-11 19:20:14,310 iteration 104 : loss : 0.254462, loss_ce: 0.122223
2021-12-11 19:20:15,899 iteration 105 : loss : 0.153796, loss_ce: 0.074401
2021-12-11 19:20:17,564 iteration 106 : loss : 0.242882, loss_ce: 0.110940
2021-12-11 19:20:19,132 iteration 107 : loss : 0.296856, loss_ce: 0.119574
2021-12-11 19:20:20,691 iteration 108 : loss : 0.235831, loss_ce: 0.094005
2021-12-11 19:20:22,158 iteration 109 : loss : 0.288822, loss_ce: 0.133252
2021-12-11 19:20:23,657 iteration 110 : loss : 0.230880, loss_ce: 0.106260
2021-12-11 19:20:25,256 iteration 111 : loss : 0.236191, loss_ce: 0.118055
2021-12-11 19:20:26,790 iteration 112 : loss : 0.234665, loss_ce: 0.110163
2021-12-11 19:20:28,265 iteration 113 : loss : 0.205561, loss_ce: 0.092135
2021-12-11 19:20:29,846 iteration 114 : loss : 0.248871, loss_ce: 0.105415
2021-12-11 19:20:31,372 iteration 115 : loss : 0.201388, loss_ce: 0.106890
2021-12-11 19:20:32,940 iteration 116 : loss : 0.255690, loss_ce: 0.142665
2021-12-11 19:20:34,452 iteration 117 : loss : 0.228733, loss_ce: 0.104244
2021-12-11 19:20:35,976 iteration 118 : loss : 0.283605, loss_ce: 0.148903
2021-12-11 19:20:37,517 iteration 119 : loss : 0.207641, loss_ce: 0.086191
  2%|▌                              | 7/400 [03:11<3:02:44, 27.90s/it]2021-12-11 19:20:39,149 iteration 120 : loss : 0.228364, loss_ce: 0.107925
2021-12-11 19:20:40,721 iteration 121 : loss : 0.278267, loss_ce: 0.121377
2021-12-11 19:20:42,186 iteration 122 : loss : 0.259015, loss_ce: 0.135353
2021-12-11 19:20:43,767 iteration 123 : loss : 0.226333, loss_ce: 0.106991
2021-12-11 19:20:45,342 iteration 124 : loss : 0.286361, loss_ce: 0.130736
2021-12-11 19:20:46,868 iteration 125 : loss : 0.229014, loss_ce: 0.126428
2021-12-11 19:20:48,441 iteration 126 : loss : 0.282445, loss_ce: 0.120645
2021-12-11 19:20:50,033 iteration 127 : loss : 0.235968, loss_ce: 0.102836
2021-12-11 19:20:51,674 iteration 128 : loss : 0.211932, loss_ce: 0.102791
2021-12-11 19:20:53,192 iteration 129 : loss : 0.228411, loss_ce: 0.098007
2021-12-11 19:20:54,793 iteration 130 : loss : 0.241581, loss_ce: 0.128258
2021-12-11 19:20:56,340 iteration 131 : loss : 0.242566, loss_ce: 0.130146
2021-12-11 19:20:57,834 iteration 132 : loss : 0.257126, loss_ce: 0.114514
2021-12-11 19:20:59,435 iteration 133 : loss : 0.252501, loss_ce: 0.104856
2021-12-11 19:21:00,984 iteration 134 : loss : 0.253643, loss_ce: 0.110599
2021-12-11 19:21:02,542 iteration 135 : loss : 0.193720, loss_ce: 0.089418
2021-12-11 19:21:04,075 iteration 136 : loss : 0.249674, loss_ce: 0.118953
  2%|▌                              | 8/400 [03:38<2:59:28, 27.47s/it]2021-12-11 19:21:05,587 iteration 137 : loss : 0.176254, loss_ce: 0.068643
2021-12-11 19:21:07,070 iteration 138 : loss : 0.243406, loss_ce: 0.127639
2021-12-11 19:21:08,673 iteration 139 : loss : 0.210913, loss_ce: 0.084021
2021-12-11 19:21:10,312 iteration 140 : loss : 0.247091, loss_ce: 0.100407
2021-12-11 19:21:11,872 iteration 141 : loss : 0.234303, loss_ce: 0.099889
2021-12-11 19:21:13,362 iteration 142 : loss : 0.180979, loss_ce: 0.081390
2021-12-11 19:21:14,842 iteration 143 : loss : 0.237129, loss_ce: 0.107754
2021-12-11 19:21:16,436 iteration 144 : loss : 0.234500, loss_ce: 0.099381
2021-12-11 19:21:18,162 iteration 145 : loss : 0.192135, loss_ce: 0.097210
2021-12-11 19:21:19,686 iteration 146 : loss : 0.243306, loss_ce: 0.108699
2021-12-11 19:21:21,239 iteration 147 : loss : 0.248066, loss_ce: 0.109899
2021-12-11 19:21:22,788 iteration 148 : loss : 0.229392, loss_ce: 0.110832
2021-12-11 19:21:24,353 iteration 149 : loss : 0.232072, loss_ce: 0.097755
2021-12-11 19:21:25,890 iteration 150 : loss : 0.297141, loss_ce: 0.154848
2021-12-11 19:21:27,442 iteration 151 : loss : 0.179593, loss_ce: 0.088865
2021-12-11 19:21:29,050 iteration 152 : loss : 0.198252, loss_ce: 0.095545
2021-12-11 19:21:30,661 iteration 153 : loss : 0.212489, loss_ce: 0.101416
  2%|▋                              | 9/400 [04:04<2:57:13, 27.19s/it]2021-12-11 19:21:32,242 iteration 154 : loss : 0.186494, loss_ce: 0.084440
2021-12-11 19:21:33,817 iteration 155 : loss : 0.254559, loss_ce: 0.116573
2021-12-11 19:21:35,369 iteration 156 : loss : 0.195346, loss_ce: 0.090174
2021-12-11 19:21:36,930 iteration 157 : loss : 0.243575, loss_ce: 0.101211
2021-12-11 19:21:38,496 iteration 158 : loss : 0.237209, loss_ce: 0.112582
2021-12-11 19:21:40,038 iteration 159 : loss : 0.224603, loss_ce: 0.098950
2021-12-11 19:21:41,575 iteration 160 : loss : 0.290761, loss_ce: 0.110820
2021-12-11 19:21:43,138 iteration 161 : loss : 0.208972, loss_ce: 0.098762
2021-12-11 19:21:44,763 iteration 162 : loss : 0.177087, loss_ce: 0.080697
2021-12-11 19:21:46,212 iteration 163 : loss : 0.173407, loss_ce: 0.076645
2021-12-11 19:21:47,799 iteration 164 : loss : 0.166637, loss_ce: 0.072710
2021-12-11 19:21:49,325 iteration 165 : loss : 0.164254, loss_ce: 0.068340
2021-12-11 19:21:50,926 iteration 166 : loss : 0.224921, loss_ce: 0.096158
2021-12-11 19:21:52,578 iteration 167 : loss : 0.213082, loss_ce: 0.100162
2021-12-11 19:21:54,152 iteration 168 : loss : 0.201520, loss_ce: 0.091382
2021-12-11 19:21:55,695 iteration 169 : loss : 0.202522, loss_ce: 0.092640
2021-12-11 19:21:55,695 Training Data Eval:
2021-12-11 19:22:03,332   Average segmentation loss on training set: 0.1731
2021-12-11 19:22:03,333 Validation Data Eval:
2021-12-11 19:22:05,971   Average segmentation loss on validation set: 0.1801
2021-12-11 19:22:07,919 Found new lowest validation loss at iteration 169! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/NEW_TU/UNET_ADAM_best_val_loss_seed100.pth
2021-12-11 19:22:09,373 iteration 170 : loss : 0.176454, loss_ce: 0.083067
  2%|▊                             | 10/400 [04:43<3:19:52, 30.75s/it]2021-12-11 19:22:10,880 iteration 171 : loss : 0.217366, loss_ce: 0.111121
2021-12-11 19:22:12,247 iteration 172 : loss : 0.258344, loss_ce: 0.102144
2021-12-11 19:22:13,710 iteration 173 : loss : 0.167445, loss_ce: 0.077305
2021-12-11 19:22:15,310 iteration 174 : loss : 0.236942, loss_ce: 0.099405
2021-12-11 19:22:16,831 iteration 175 : loss : 0.177670, loss_ce: 0.079691
2021-12-11 19:22:18,469 iteration 176 : loss : 0.213927, loss_ce: 0.085032
2021-12-11 19:22:19,985 iteration 177 : loss : 0.242945, loss_ce: 0.100290
2021-12-11 19:22:21,573 iteration 178 : loss : 0.183935, loss_ce: 0.071515
2021-12-11 19:22:23,148 iteration 179 : loss : 0.208336, loss_ce: 0.086210
2021-12-11 19:22:24,715 iteration 180 : loss : 0.202085, loss_ce: 0.067636
2021-12-11 19:22:26,316 iteration 181 : loss : 0.173740, loss_ce: 0.068913
2021-12-11 19:22:27,898 iteration 182 : loss : 0.164241, loss_ce: 0.066863
2021-12-11 19:22:29,488 iteration 183 : loss : 0.185409, loss_ce: 0.073713
2021-12-11 19:22:31,038 iteration 184 : loss : 0.174388, loss_ce: 0.078515
2021-12-11 19:22:32,548 iteration 185 : loss : 0.225410, loss_ce: 0.116351
2021-12-11 19:22:34,048 iteration 186 : loss : 0.174969, loss_ce: 0.083729
2021-12-11 19:22:35,529 iteration 187 : loss : 0.260238, loss_ce: 0.141490
  3%|▊                             | 11/400 [05:09<3:10:14, 29.34s/it]2021-12-11 19:22:37,137 iteration 188 : loss : 0.305768, loss_ce: 0.141456
2021-12-11 19:22:38,760 iteration 189 : loss : 0.218804, loss_ce: 0.103179
2021-12-11 19:22:40,361 iteration 190 : loss : 0.211844, loss_ce: 0.081292
2021-12-11 19:22:41,910 iteration 191 : loss : 0.212038, loss_ce: 0.096743
2021-12-11 19:22:43,357 iteration 192 : loss : 0.160879, loss_ce: 0.068928
2021-12-11 19:22:44,853 iteration 193 : loss : 0.283172, loss_ce: 0.120576
2021-12-11 19:22:46,335 iteration 194 : loss : 0.249031, loss_ce: 0.117496
2021-12-11 19:22:47,952 iteration 195 : loss : 0.153673, loss_ce: 0.059656
2021-12-11 19:22:49,526 iteration 196 : loss : 0.169003, loss_ce: 0.062421
2021-12-11 19:22:51,076 iteration 197 : loss : 0.174235, loss_ce: 0.074396
2021-12-11 19:22:52,658 iteration 198 : loss : 0.218853, loss_ce: 0.099827
2021-12-11 19:22:54,223 iteration 199 : loss : 0.190660, loss_ce: 0.092269
2021-12-11 19:22:55,753 iteration 200 : loss : 0.199453, loss_ce: 0.083346
2021-12-11 19:22:57,289 iteration 201 : loss : 0.206327, loss_ce: 0.091355
2021-12-11 19:22:58,712 iteration 202 : loss : 0.165626, loss_ce: 0.062680
2021-12-11 19:23:00,293 iteration 203 : loss : 0.172752, loss_ce: 0.074261
2021-12-11 19:23:01,820 iteration 204 : loss : 0.216008, loss_ce: 0.108618
  3%|▉                             | 12/400 [05:35<3:03:46, 28.42s/it]2021-12-11 19:23:03,484 iteration 205 : loss : 0.197596, loss_ce: 0.085497
2021-12-11 19:23:05,044 iteration 206 : loss : 0.307477, loss_ce: 0.145890
2021-12-11 19:23:06,665 iteration 207 : loss : 0.237541, loss_ce: 0.095548
2021-12-11 19:23:08,268 iteration 208 : loss : 0.173925, loss_ce: 0.091232
2021-12-11 19:23:09,842 iteration 209 : loss : 0.190422, loss_ce: 0.089611
2021-12-11 19:23:11,370 iteration 210 : loss : 0.179454, loss_ce: 0.090982
2021-12-11 19:23:12,925 iteration 211 : loss : 0.177091, loss_ce: 0.083456
2021-12-11 19:23:14,534 iteration 212 : loss : 0.170307, loss_ce: 0.071379
2021-12-11 19:23:16,122 iteration 213 : loss : 0.180982, loss_ce: 0.081676
2021-12-11 19:23:17,655 iteration 214 : loss : 0.212599, loss_ce: 0.096218
2021-12-11 19:23:19,150 iteration 215 : loss : 0.156182, loss_ce: 0.069672
2021-12-11 19:23:20,752 iteration 216 : loss : 0.142424, loss_ce: 0.057634
2021-12-11 19:23:22,356 iteration 217 : loss : 0.181276, loss_ce: 0.070991
2021-12-11 19:23:23,880 iteration 218 : loss : 0.168022, loss_ce: 0.071816
2021-12-11 19:23:25,395 iteration 219 : loss : 0.160203, loss_ce: 0.075593
2021-12-11 19:23:27,004 iteration 220 : loss : 0.171288, loss_ce: 0.065775
2021-12-11 19:23:28,591 iteration 221 : loss : 0.149072, loss_ce: 0.064061
  3%|▉                             | 13/400 [06:02<3:00:03, 27.92s/it]2021-12-11 19:23:30,183 iteration 222 : loss : 0.149076, loss_ce: 0.059915
2021-12-11 19:23:31,713 iteration 223 : loss : 0.233145, loss_ce: 0.114331
2021-12-11 19:23:33,240 iteration 224 : loss : 0.155177, loss_ce: 0.060657
2021-12-11 19:23:34,890 iteration 225 : loss : 0.144405, loss_ce: 0.066379
2021-12-11 19:23:36,483 iteration 226 : loss : 0.143580, loss_ce: 0.060895
2021-12-11 19:23:38,014 iteration 227 : loss : 0.182967, loss_ce: 0.076524
2021-12-11 19:23:39,549 iteration 228 : loss : 0.161476, loss_ce: 0.058766
2021-12-11 19:23:41,115 iteration 229 : loss : 0.191939, loss_ce: 0.080911
2021-12-11 19:23:42,609 iteration 230 : loss : 0.134306, loss_ce: 0.064867
2021-12-11 19:23:44,147 iteration 231 : loss : 0.168955, loss_ce: 0.073369
2021-12-11 19:23:45,674 iteration 232 : loss : 0.161435, loss_ce: 0.070002
2021-12-11 19:23:47,147 iteration 233 : loss : 0.149308, loss_ce: 0.076185
2021-12-11 19:23:48,677 iteration 234 : loss : 0.223265, loss_ce: 0.096910
2021-12-11 19:23:50,176 iteration 235 : loss : 0.175430, loss_ce: 0.082369
2021-12-11 19:23:51,705 iteration 236 : loss : 0.322713, loss_ce: 0.149267
2021-12-11 19:23:53,193 iteration 237 : loss : 0.229267, loss_ce: 0.133429
2021-12-11 19:23:54,777 iteration 238 : loss : 0.177334, loss_ce: 0.063763
  4%|█                             | 14/400 [06:28<2:56:15, 27.40s/it]2021-12-11 19:23:56,356 iteration 239 : loss : 0.209324, loss_ce: 0.082349
2021-12-11 19:23:58,008 iteration 240 : loss : 0.164956, loss_ce: 0.061568
2021-12-11 19:23:59,589 iteration 241 : loss : 0.158863, loss_ce: 0.062369
2021-12-11 19:24:01,106 iteration 242 : loss : 0.161274, loss_ce: 0.063606
2021-12-11 19:24:02,629 iteration 243 : loss : 0.147975, loss_ce: 0.058995
2021-12-11 19:24:04,162 iteration 244 : loss : 0.151887, loss_ce: 0.063088
2021-12-11 19:24:05,657 iteration 245 : loss : 0.148471, loss_ce: 0.052306
2021-12-11 19:24:07,177 iteration 246 : loss : 0.198677, loss_ce: 0.072244
2021-12-11 19:24:08,734 iteration 247 : loss : 0.165859, loss_ce: 0.081276
2021-12-11 19:24:10,308 iteration 248 : loss : 0.140742, loss_ce: 0.066165
2021-12-11 19:24:11,824 iteration 249 : loss : 0.147577, loss_ce: 0.064120
2021-12-11 19:24:13,384 iteration 250 : loss : 0.213906, loss_ce: 0.090135
2021-12-11 19:24:14,859 iteration 251 : loss : 0.124664, loss_ce: 0.054600
2021-12-11 19:24:16,477 iteration 252 : loss : 0.147158, loss_ce: 0.069904
2021-12-11 19:24:18,030 iteration 253 : loss : 0.108109, loss_ce: 0.039897
2021-12-11 19:24:19,550 iteration 254 : loss : 0.138787, loss_ce: 0.067426
2021-12-11 19:24:19,550 Training Data Eval:
2021-12-11 19:24:27,180   Average segmentation loss on training set: 0.1711
2021-12-11 19:24:27,180 Validation Data Eval:
2021-12-11 19:24:29,816   Average segmentation loss on validation set: 0.1659
2021-12-11 19:24:31,784 Found new lowest validation loss at iteration 254! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/NEW_TU/UNET_ADAM_best_val_loss_seed100.pth
2021-12-11 19:24:33,176 iteration 255 : loss : 0.132360, loss_ce: 0.061767
  4%|█▏                            | 15/400 [07:07<3:17:03, 30.71s/it]2021-12-11 19:24:34,627 iteration 256 : loss : 0.138811, loss_ce: 0.063252
2021-12-11 19:24:36,095 iteration 257 : loss : 0.147239, loss_ce: 0.068072
2021-12-11 19:24:37,678 iteration 258 : loss : 0.146495, loss_ce: 0.071388
2021-12-11 19:24:39,224 iteration 259 : loss : 0.189038, loss_ce: 0.089393
2021-12-11 19:24:40,726 iteration 260 : loss : 0.126473, loss_ce: 0.069002
2021-12-11 19:24:42,294 iteration 261 : loss : 0.175757, loss_ce: 0.072609
2021-12-11 19:24:43,885 iteration 262 : loss : 0.251152, loss_ce: 0.120030
2021-12-11 19:24:45,369 iteration 263 : loss : 0.127735, loss_ce: 0.052387
2021-12-11 19:24:47,020 iteration 264 : loss : 0.247935, loss_ce: 0.102387
2021-12-11 19:24:48,658 iteration 265 : loss : 0.180752, loss_ce: 0.099955
2021-12-11 19:24:50,232 iteration 266 : loss : 0.176644, loss_ce: 0.072865
2021-12-11 19:24:51,861 iteration 267 : loss : 0.137113, loss_ce: 0.049693
2021-12-11 19:24:53,428 iteration 268 : loss : 0.172347, loss_ce: 0.080178
2021-12-11 19:24:54,966 iteration 269 : loss : 0.245496, loss_ce: 0.130102
2021-12-11 19:24:56,476 iteration 270 : loss : 0.210660, loss_ce: 0.080875
2021-12-11 19:24:57,985 iteration 271 : loss : 0.165439, loss_ce: 0.076830
2021-12-11 19:24:59,475 iteration 272 : loss : 0.167195, loss_ce: 0.062617
  4%|█▏                            | 16/400 [07:33<3:08:04, 29.39s/it]2021-12-11 19:25:01,107 iteration 273 : loss : 0.148775, loss_ce: 0.065909
2021-12-11 19:25:02,649 iteration 274 : loss : 0.229366, loss_ce: 0.106060
2021-12-11 19:25:04,177 iteration 275 : loss : 0.219776, loss_ce: 0.055163
2021-12-11 19:25:05,703 iteration 276 : loss : 0.111143, loss_ce: 0.047433
2021-12-11 19:25:07,220 iteration 277 : loss : 0.119357, loss_ce: 0.049532
2021-12-11 19:25:08,756 iteration 278 : loss : 0.213325, loss_ce: 0.088933
2021-12-11 19:25:10,291 iteration 279 : loss : 0.183672, loss_ce: 0.080094
2021-12-11 19:25:11,817 iteration 280 : loss : 0.172795, loss_ce: 0.089660
2021-12-11 19:25:13,407 iteration 281 : loss : 0.126512, loss_ce: 0.064779
2021-12-11 19:25:14,977 iteration 282 : loss : 0.098880, loss_ce: 0.038686
2021-12-11 19:25:16,534 iteration 283 : loss : 0.131359, loss_ce: 0.055835
2021-12-11 19:25:18,100 iteration 284 : loss : 0.150536, loss_ce: 0.090395
2021-12-11 19:25:19,687 iteration 285 : loss : 0.171820, loss_ce: 0.058288
2021-12-11 19:25:21,140 iteration 286 : loss : 0.148855, loss_ce: 0.061522
2021-12-11 19:25:22,670 iteration 287 : loss : 0.158566, loss_ce: 0.068291
2021-12-11 19:25:24,228 iteration 288 : loss : 0.142689, loss_ce: 0.060072
2021-12-11 19:25:25,744 iteration 289 : loss : 0.194623, loss_ce: 0.078291
  4%|█▎                            | 17/400 [07:59<3:01:35, 28.45s/it]2021-12-11 19:25:27,360 iteration 290 : loss : 0.147507, loss_ce: 0.066362
2021-12-11 19:25:28,866 iteration 291 : loss : 0.123155, loss_ce: 0.046745
2021-12-11 19:25:30,358 iteration 292 : loss : 0.147168, loss_ce: 0.069726
2021-12-11 19:25:31,938 iteration 293 : loss : 0.143319, loss_ce: 0.052409
2021-12-11 19:25:33,462 iteration 294 : loss : 0.118908, loss_ce: 0.057411
2021-12-11 19:25:35,095 iteration 295 : loss : 0.153498, loss_ce: 0.077051
2021-12-11 19:25:36,686 iteration 296 : loss : 0.150164, loss_ce: 0.063954
2021-12-11 19:25:38,240 iteration 297 : loss : 0.146703, loss_ce: 0.079419
2021-12-11 19:25:39,776 iteration 298 : loss : 0.161058, loss_ce: 0.074822
2021-12-11 19:25:41,259 iteration 299 : loss : 0.137308, loss_ce: 0.056865
2021-12-11 19:25:42,770 iteration 300 : loss : 0.142039, loss_ce: 0.063171
2021-12-11 19:25:44,224 iteration 301 : loss : 0.151427, loss_ce: 0.062766
2021-12-11 19:25:45,817 iteration 302 : loss : 0.144762, loss_ce: 0.055884
2021-12-11 19:25:47,404 iteration 303 : loss : 0.119328, loss_ce: 0.042542
2021-12-11 19:25:48,992 iteration 304 : loss : 0.168380, loss_ce: 0.074337
2021-12-11 19:25:50,504 iteration 305 : loss : 0.132330, loss_ce: 0.051586
2021-12-11 19:25:52,041 iteration 306 : loss : 0.143424, loss_ce: 0.056398
  4%|█▎                            | 18/400 [08:26<2:57:00, 27.80s/it]2021-12-11 19:25:53,553 iteration 307 : loss : 0.170567, loss_ce: 0.062121
2021-12-11 19:25:55,023 iteration 308 : loss : 0.147543, loss_ce: 0.069238
2021-12-11 19:25:56,506 iteration 309 : loss : 0.137120, loss_ce: 0.067169
2021-12-11 19:25:58,058 iteration 310 : loss : 0.149811, loss_ce: 0.065160
2021-12-11 19:25:59,636 iteration 311 : loss : 0.154030, loss_ce: 0.072348
2021-12-11 19:26:01,221 iteration 312 : loss : 0.135650, loss_ce: 0.057941
2021-12-11 19:26:02,740 iteration 313 : loss : 0.149741, loss_ce: 0.069712
2021-12-11 19:26:04,336 iteration 314 : loss : 0.138607, loss_ce: 0.065472
2021-12-11 19:26:05,923 iteration 315 : loss : 0.120627, loss_ce: 0.049672
2021-12-11 19:26:07,457 iteration 316 : loss : 0.154972, loss_ce: 0.059179
2021-12-11 19:26:08,947 iteration 317 : loss : 0.147861, loss_ce: 0.049159
2021-12-11 19:26:10,459 iteration 318 : loss : 0.124062, loss_ce: 0.047011
2021-12-11 19:26:12,054 iteration 319 : loss : 0.118016, loss_ce: 0.045131
2021-12-11 19:26:13,567 iteration 320 : loss : 0.167177, loss_ce: 0.058208
2021-12-11 19:26:15,045 iteration 321 : loss : 0.119810, loss_ce: 0.061615
2021-12-11 19:26:16,584 iteration 322 : loss : 0.134466, loss_ce: 0.055720
2021-12-11 19:26:18,166 iteration 323 : loss : 0.147646, loss_ce: 0.064978
  5%|█▍                            | 19/400 [08:52<2:53:20, 27.30s/it]2021-12-11 19:26:19,671 iteration 324 : loss : 0.159940, loss_ce: 0.067428
2021-12-11 19:26:21,256 iteration 325 : loss : 0.162707, loss_ce: 0.062084
2021-12-11 19:26:22,780 iteration 326 : loss : 0.104632, loss_ce: 0.044742
2021-12-11 19:26:24,397 iteration 327 : loss : 0.128447, loss_ce: 0.054565
2021-12-11 19:26:25,981 iteration 328 : loss : 0.126362, loss_ce: 0.052760
2021-12-11 19:26:27,528 iteration 329 : loss : 0.105336, loss_ce: 0.043105
2021-12-11 19:26:28,980 iteration 330 : loss : 0.114785, loss_ce: 0.046094
2021-12-11 19:26:30,580 iteration 331 : loss : 0.103761, loss_ce: 0.039441
2021-12-11 19:26:32,164 iteration 332 : loss : 0.120877, loss_ce: 0.049299
2021-12-11 19:26:33,659 iteration 333 : loss : 0.109828, loss_ce: 0.047286
2021-12-11 19:26:35,238 iteration 334 : loss : 0.131723, loss_ce: 0.065208
2021-12-11 19:26:36,746 iteration 335 : loss : 0.163223, loss_ce: 0.055770
2021-12-11 19:26:38,333 iteration 336 : loss : 0.115769, loss_ce: 0.052203
2021-12-11 19:26:39,832 iteration 337 : loss : 0.111505, loss_ce: 0.043920
2021-12-11 19:26:41,297 iteration 338 : loss : 0.141932, loss_ce: 0.070074
2021-12-11 19:26:42,835 iteration 339 : loss : 0.106283, loss_ce: 0.039726
2021-12-11 19:26:42,836 Training Data Eval:
2021-12-11 19:26:50,455   Average segmentation loss on training set: 0.1042
2021-12-11 19:26:50,455 Validation Data Eval:
2021-12-11 19:26:53,090   Average segmentation loss on validation set: 0.1364
2021-12-11 19:26:55,019 Found new lowest validation loss at iteration 339! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/NEW_TU/UNET_ADAM_best_val_loss_seed100.pth
2021-12-11 19:26:56,455 iteration 340 : loss : 0.137991, loss_ce: 0.052686
  5%|█▌                            | 20/400 [09:30<3:13:46, 30.60s/it]2021-12-11 19:26:57,992 iteration 341 : loss : 0.142253, loss_ce: 0.061043
2021-12-11 19:26:59,507 iteration 342 : loss : 0.098460, loss_ce: 0.035939
2021-12-11 19:27:01,139 iteration 343 : loss : 0.153383, loss_ce: 0.076426
2021-12-11 19:27:02,670 iteration 344 : loss : 0.173150, loss_ce: 0.069663
2021-12-11 19:27:04,227 iteration 345 : loss : 0.156123, loss_ce: 0.069344
2021-12-11 19:27:05,849 iteration 346 : loss : 0.147693, loss_ce: 0.059206
2021-12-11 19:27:07,415 iteration 347 : loss : 0.109500, loss_ce: 0.056534
2021-12-11 19:27:09,048 iteration 348 : loss : 0.150467, loss_ce: 0.061394
2021-12-11 19:27:10,568 iteration 349 : loss : 0.126031, loss_ce: 0.060827
2021-12-11 19:27:12,018 iteration 350 : loss : 0.104542, loss_ce: 0.044427
2021-12-11 19:27:13,622 iteration 351 : loss : 0.119383, loss_ce: 0.045429
2021-12-11 19:27:15,160 iteration 352 : loss : 0.137528, loss_ce: 0.055650
2021-12-11 19:27:16,801 iteration 353 : loss : 0.127551, loss_ce: 0.050324
2021-12-11 19:27:18,371 iteration 354 : loss : 0.138832, loss_ce: 0.060314
2021-12-11 19:27:19,985 iteration 355 : loss : 0.154964, loss_ce: 0.059056
2021-12-11 19:27:21,480 iteration 356 : loss : 0.152463, loss_ce: 0.057787
2021-12-11 19:27:23,000 iteration 357 : loss : 0.134503, loss_ce: 0.050922
  5%|█▌                            | 21/400 [09:57<3:05:35, 29.38s/it]2021-12-11 19:27:24,652 iteration 358 : loss : 0.108577, loss_ce: 0.040576
2021-12-11 19:27:26,245 iteration 359 : loss : 0.111394, loss_ce: 0.055478
2021-12-11 19:27:27,792 iteration 360 : loss : 0.213096, loss_ce: 0.064381
2021-12-11 19:27:29,369 iteration 361 : loss : 0.183189, loss_ce: 0.062873
2021-12-11 19:27:30,828 iteration 362 : loss : 0.136685, loss_ce: 0.052829
2021-12-11 19:27:32,444 iteration 363 : loss : 0.142507, loss_ce: 0.070695
2021-12-11 19:27:34,030 iteration 364 : loss : 0.186550, loss_ce: 0.098247
2021-12-11 19:27:35,559 iteration 365 : loss : 0.096914, loss_ce: 0.043373
2021-12-11 19:27:37,103 iteration 366 : loss : 0.139186, loss_ce: 0.057399
2021-12-11 19:27:38,735 iteration 367 : loss : 0.161700, loss_ce: 0.070201
2021-12-11 19:27:40,224 iteration 368 : loss : 0.128150, loss_ce: 0.045617
2021-12-11 19:27:41,797 iteration 369 : loss : 0.105587, loss_ce: 0.049792
2021-12-11 19:27:43,257 iteration 370 : loss : 0.127782, loss_ce: 0.042120
2021-12-11 19:27:44,858 iteration 371 : loss : 0.146110, loss_ce: 0.070084
2021-12-11 19:27:46,464 iteration 372 : loss : 0.139125, loss_ce: 0.054108
2021-12-11 19:27:48,025 iteration 373 : loss : 0.097021, loss_ce: 0.034712
2021-12-11 19:27:49,538 iteration 374 : loss : 0.096681, loss_ce: 0.041627
  6%|█▋                            | 22/400 [10:23<2:59:43, 28.53s/it]2021-12-11 19:27:51,158 iteration 375 : loss : 0.154608, loss_ce: 0.067568
2021-12-11 19:27:52,724 iteration 376 : loss : 0.113313, loss_ce: 0.051590
2021-12-11 19:27:54,298 iteration 377 : loss : 0.164074, loss_ce: 0.069681
2021-12-11 19:27:55,857 iteration 378 : loss : 0.147866, loss_ce: 0.066822
2021-12-11 19:27:57,339 iteration 379 : loss : 0.161914, loss_ce: 0.060810
2021-12-11 19:27:58,919 iteration 380 : loss : 0.105044, loss_ce: 0.048908
2021-12-11 19:28:00,371 iteration 381 : loss : 0.089678, loss_ce: 0.035370
2021-12-11 19:28:02,028 iteration 382 : loss : 0.124065, loss_ce: 0.057758
2021-12-11 19:28:03,625 iteration 383 : loss : 0.140482, loss_ce: 0.056551
2021-12-11 19:28:05,162 iteration 384 : loss : 0.099108, loss_ce: 0.041691
2021-12-11 19:28:06,659 iteration 385 : loss : 0.087923, loss_ce: 0.039210
2021-12-11 19:28:08,242 iteration 386 : loss : 0.153925, loss_ce: 0.068495
2021-12-11 19:28:09,822 iteration 387 : loss : 0.132006, loss_ce: 0.050065
2021-12-11 19:28:11,419 iteration 388 : loss : 0.110351, loss_ce: 0.047365
2021-12-11 19:28:12,940 iteration 389 : loss : 0.115875, loss_ce: 0.042915
2021-12-11 19:28:14,522 iteration 390 : loss : 0.117530, loss_ce: 0.065612
2021-12-11 19:28:16,041 iteration 391 : loss : 0.113929, loss_ce: 0.044969
  6%|█▋                            | 23/400 [10:50<2:55:25, 27.92s/it]2021-12-11 19:28:17,733 iteration 392 : loss : 0.105776, loss_ce: 0.046666
2021-12-11 19:28:19,220 iteration 393 : loss : 0.117178, loss_ce: 0.056045
2021-12-11 19:28:20,779 iteration 394 : loss : 0.121537, loss_ce: 0.047566
2021-12-11 19:28:22,297 iteration 395 : loss : 0.142888, loss_ce: 0.062127
2021-12-11 19:28:23,883 iteration 396 : loss : 0.121532, loss_ce: 0.049403
2021-12-11 19:28:25,469 iteration 397 : loss : 0.100055, loss_ce: 0.043331
2021-12-11 19:28:27,105 iteration 398 : loss : 0.123824, loss_ce: 0.058794
2021-12-11 19:28:28,627 iteration 399 : loss : 0.085704, loss_ce: 0.032901
2021-12-11 19:28:30,225 iteration 400 : loss : 0.098109, loss_ce: 0.042371
2021-12-11 19:28:31,705 iteration 401 : loss : 0.128686, loss_ce: 0.042418
2021-12-11 19:28:33,306 iteration 402 : loss : 0.133676, loss_ce: 0.058769
2021-12-11 19:28:34,941 iteration 403 : loss : 0.085760, loss_ce: 0.039575
2021-12-11 19:28:36,507 iteration 404 : loss : 0.095934, loss_ce: 0.030874
2021-12-11 19:28:38,107 iteration 405 : loss : 0.137936, loss_ce: 0.055944
2021-12-11 19:28:39,627 iteration 406 : loss : 0.122020, loss_ce: 0.052815
2021-12-11 19:28:41,134 iteration 407 : loss : 0.092106, loss_ce: 0.034503
2021-12-11 19:28:42,639 iteration 408 : loss : 0.080949, loss_ce: 0.030867
  6%|█▊                            | 24/400 [11:16<2:52:28, 27.52s/it]2021-12-11 19:28:44,341 iteration 409 : loss : 0.098309, loss_ce: 0.038643
2021-12-11 19:28:45,881 iteration 410 : loss : 0.120877, loss_ce: 0.045186
2021-12-11 19:28:47,450 iteration 411 : loss : 0.101770, loss_ce: 0.036857
2021-12-11 19:28:48,989 iteration 412 : loss : 0.104207, loss_ce: 0.046258
2021-12-11 19:28:50,511 iteration 413 : loss : 0.114556, loss_ce: 0.042283
2021-12-11 19:28:52,075 iteration 414 : loss : 0.108540, loss_ce: 0.047955
2021-12-11 19:28:53,671 iteration 415 : loss : 0.144728, loss_ce: 0.080640
2021-12-11 19:28:55,087 iteration 416 : loss : 0.086097, loss_ce: 0.033456
2021-12-11 19:28:56,669 iteration 417 : loss : 0.162437, loss_ce: 0.059931
2021-12-11 19:28:58,234 iteration 418 : loss : 0.110610, loss_ce: 0.036425
2021-12-11 19:28:59,755 iteration 419 : loss : 0.183704, loss_ce: 0.076848
2021-12-11 19:29:01,311 iteration 420 : loss : 0.087996, loss_ce: 0.035994
2021-12-11 19:29:02,768 iteration 421 : loss : 0.116359, loss_ce: 0.037824
2021-12-11 19:29:04,346 iteration 422 : loss : 0.103513, loss_ce: 0.047394
2021-12-11 19:29:05,863 iteration 423 : loss : 0.114514, loss_ce: 0.050129
2021-12-11 19:29:07,382 iteration 424 : loss : 0.116934, loss_ce: 0.055125
2021-12-11 19:29:07,382 Training Data Eval:
2021-12-11 19:29:15,032   Average segmentation loss on training set: 0.1297
2021-12-11 19:29:15,033 Validation Data Eval:
2021-12-11 19:29:17,668   Average segmentation loss on validation set: 0.1435
2021-12-11 19:29:19,269 iteration 425 : loss : 0.130067, loss_ce: 0.054304
  6%|█▉                            | 25/400 [11:53<3:09:05, 30.25s/it]2021-12-11 19:29:20,903 iteration 426 : loss : 0.116470, loss_ce: 0.045711
2021-12-11 19:29:22,411 iteration 427 : loss : 0.119993, loss_ce: 0.051084
2021-12-11 19:29:24,068 iteration 428 : loss : 0.113687, loss_ce: 0.050000
2021-12-11 19:29:25,600 iteration 429 : loss : 0.113761, loss_ce: 0.045052
2021-12-11 19:29:27,070 iteration 430 : loss : 0.104639, loss_ce: 0.048132
2021-12-11 19:29:28,639 iteration 431 : loss : 0.087686, loss_ce: 0.042021
2021-12-11 19:29:30,232 iteration 432 : loss : 0.092970, loss_ce: 0.034725
2021-12-11 19:29:31,711 iteration 433 : loss : 0.098802, loss_ce: 0.042478
2021-12-11 19:29:33,205 iteration 434 : loss : 0.108353, loss_ce: 0.037928
2021-12-11 19:29:34,763 iteration 435 : loss : 0.104487, loss_ce: 0.043051
2021-12-11 19:29:36,346 iteration 436 : loss : 0.179258, loss_ce: 0.059270
2021-12-11 19:29:37,853 iteration 437 : loss : 0.089920, loss_ce: 0.037323
2021-12-11 19:29:39,368 iteration 438 : loss : 0.112152, loss_ce: 0.042567
2021-12-11 19:29:40,891 iteration 439 : loss : 0.112914, loss_ce: 0.047107
2021-12-11 19:29:42,561 iteration 440 : loss : 0.126297, loss_ce: 0.052061
2021-12-11 19:29:44,096 iteration 441 : loss : 0.094503, loss_ce: 0.043448
2021-12-11 19:29:45,600 iteration 442 : loss : 0.109902, loss_ce: 0.038815
  6%|█▉                            | 26/400 [12:19<3:01:15, 29.08s/it]2021-12-11 19:29:47,226 iteration 443 : loss : 0.102113, loss_ce: 0.038162
2021-12-11 19:29:48,732 iteration 444 : loss : 0.088841, loss_ce: 0.033710
2021-12-11 19:29:50,222 iteration 445 : loss : 0.095592, loss_ce: 0.039902
2021-12-11 19:29:51,740 iteration 446 : loss : 0.096454, loss_ce: 0.033727
2021-12-11 19:29:53,334 iteration 447 : loss : 0.118024, loss_ce: 0.044368
2021-12-11 19:29:54,795 iteration 448 : loss : 0.095322, loss_ce: 0.032116
2021-12-11 19:29:56,300 iteration 449 : loss : 0.102235, loss_ce: 0.032358
2021-12-11 19:29:57,762 iteration 450 : loss : 0.117291, loss_ce: 0.058787
2021-12-11 19:29:59,305 iteration 451 : loss : 0.125841, loss_ce: 0.050737
2021-12-11 19:30:00,856 iteration 452 : loss : 0.090387, loss_ce: 0.032497
2021-12-11 19:30:02,366 iteration 453 : loss : 0.075287, loss_ce: 0.033798
2021-12-11 19:30:04,013 iteration 454 : loss : 0.133004, loss_ce: 0.064738
2021-12-11 19:30:05,589 iteration 455 : loss : 0.137102, loss_ce: 0.058081
2021-12-11 19:30:07,118 iteration 456 : loss : 0.084976, loss_ce: 0.030150
2021-12-11 19:30:08,643 iteration 457 : loss : 0.092957, loss_ce: 0.046039
2021-12-11 19:30:10,163 iteration 458 : loss : 0.088520, loss_ce: 0.043530
2021-12-11 19:30:11,705 iteration 459 : loss : 0.115904, loss_ce: 0.056455
  7%|██                            | 27/400 [12:45<2:55:13, 28.19s/it]2021-12-11 19:30:13,231 iteration 460 : loss : 0.094169, loss_ce: 0.049013
2021-12-11 19:30:14,744 iteration 461 : loss : 0.074835, loss_ce: 0.033499
2021-12-11 19:30:16,359 iteration 462 : loss : 0.140565, loss_ce: 0.052832
2021-12-11 19:30:17,933 iteration 463 : loss : 0.147730, loss_ce: 0.048760
2021-12-11 19:30:19,602 iteration 464 : loss : 0.145759, loss_ce: 0.058698
2021-12-11 19:30:21,194 iteration 465 : loss : 0.102308, loss_ce: 0.047634
2021-12-11 19:30:22,712 iteration 466 : loss : 0.093064, loss_ce: 0.042316
2021-12-11 19:30:24,243 iteration 467 : loss : 0.117225, loss_ce: 0.050911
2021-12-11 19:30:25,747 iteration 468 : loss : 0.077821, loss_ce: 0.033186
2021-12-11 19:30:27,339 iteration 469 : loss : 0.074810, loss_ce: 0.035030
2021-12-11 19:30:28,885 iteration 470 : loss : 0.070552, loss_ce: 0.030163
2021-12-11 19:30:30,429 iteration 471 : loss : 0.158678, loss_ce: 0.077979
2021-12-11 19:30:32,000 iteration 472 : loss : 0.067533, loss_ce: 0.027592
2021-12-11 19:30:33,550 iteration 473 : loss : 0.096259, loss_ce: 0.041341
2021-12-11 19:30:35,051 iteration 474 : loss : 0.146413, loss_ce: 0.051718
2021-12-11 19:30:36,582 iteration 475 : loss : 0.120761, loss_ce: 0.042263
2021-12-11 19:30:38,200 iteration 476 : loss : 0.089846, loss_ce: 0.036010
  7%|██                            | 28/400 [13:12<2:51:36, 27.68s/it]2021-12-11 19:30:39,784 iteration 477 : loss : 0.074795, loss_ce: 0.036629
2021-12-11 19:30:41,269 iteration 478 : loss : 0.077683, loss_ce: 0.033909
2021-12-11 19:30:42,838 iteration 479 : loss : 0.103046, loss_ce: 0.039648
2021-12-11 19:30:44,378 iteration 480 : loss : 0.122798, loss_ce: 0.042341
2021-12-11 19:30:45,882 iteration 481 : loss : 0.100008, loss_ce: 0.034990
2021-12-11 19:30:47,511 iteration 482 : loss : 0.088469, loss_ce: 0.035820
2021-12-11 19:30:48,994 iteration 483 : loss : 0.122301, loss_ce: 0.057859
2021-12-11 19:30:50,545 iteration 484 : loss : 0.097083, loss_ce: 0.035054
2021-12-11 19:30:52,110 iteration 485 : loss : 0.138842, loss_ce: 0.055960
2021-12-11 19:30:53,745 iteration 486 : loss : 0.081606, loss_ce: 0.032362
2021-12-11 19:30:55,284 iteration 487 : loss : 0.120583, loss_ce: 0.040096
2021-12-11 19:30:56,750 iteration 488 : loss : 0.105521, loss_ce: 0.045305
2021-12-11 19:30:58,323 iteration 489 : loss : 0.095341, loss_ce: 0.042544
2021-12-11 19:30:59,863 iteration 490 : loss : 0.090928, loss_ce: 0.041194
2021-12-11 19:31:01,464 iteration 491 : loss : 0.127083, loss_ce: 0.041390
2021-12-11 19:31:02,993 iteration 492 : loss : 0.095528, loss_ce: 0.053434
2021-12-11 19:31:04,513 iteration 493 : loss : 0.093212, loss_ce: 0.044664
  7%|██▏                           | 29/400 [13:38<2:48:37, 27.27s/it]2021-12-11 19:31:06,083 iteration 494 : loss : 0.120317, loss_ce: 0.041846
2021-12-11 19:31:07,555 iteration 495 : loss : 0.114636, loss_ce: 0.039652
2021-12-11 19:31:09,102 iteration 496 : loss : 0.085146, loss_ce: 0.031601
2021-12-11 19:31:10,725 iteration 497 : loss : 0.105623, loss_ce: 0.045190
2021-12-11 19:31:12,376 iteration 498 : loss : 0.130274, loss_ce: 0.079593
2021-12-11 19:31:13,946 iteration 499 : loss : 0.111113, loss_ce: 0.035594
2021-12-11 19:31:15,619 iteration 500 : loss : 0.121935, loss_ce: 0.046166
2021-12-11 19:31:17,168 iteration 501 : loss : 0.096528, loss_ce: 0.032027
2021-12-11 19:31:18,658 iteration 502 : loss : 0.088157, loss_ce: 0.037390
2021-12-11 19:31:20,299 iteration 503 : loss : 0.097773, loss_ce: 0.031585
2021-12-11 19:31:21,961 iteration 504 : loss : 0.097149, loss_ce: 0.036954
2021-12-11 19:31:23,468 iteration 505 : loss : 0.106211, loss_ce: 0.040588
2021-12-11 19:31:25,044 iteration 506 : loss : 0.107534, loss_ce: 0.042708
2021-12-11 19:31:26,651 iteration 507 : loss : 0.100290, loss_ce: 0.040159
2021-12-11 19:31:28,185 iteration 508 : loss : 0.082367, loss_ce: 0.034190
2021-12-11 19:31:29,746 iteration 509 : loss : 0.094918, loss_ce: 0.042319
2021-12-11 19:31:29,746 Training Data Eval:
2021-12-11 19:31:37,408   Average segmentation loss on training set: 0.1559
2021-12-11 19:31:37,408 Validation Data Eval:
2021-12-11 19:31:40,044   Average segmentation loss on validation set: 0.1444
2021-12-11 19:31:41,489 iteration 510 : loss : 0.102719, loss_ce: 0.038638
  8%|██▎                           | 30/400 [14:15<3:06:06, 30.18s/it]2021-12-11 19:31:42,931 iteration 511 : loss : 0.072755, loss_ce: 0.031725
2021-12-11 19:31:44,631 iteration 512 : loss : 0.125313, loss_ce: 0.051421
2021-12-11 19:31:46,130 iteration 513 : loss : 0.111723, loss_ce: 0.055125
2021-12-11 19:31:47,706 iteration 514 : loss : 0.109868, loss_ce: 0.041052
2021-12-11 19:31:49,220 iteration 515 : loss : 0.073538, loss_ce: 0.032397
2021-12-11 19:31:50,708 iteration 516 : loss : 0.070424, loss_ce: 0.034185
2021-12-11 19:31:52,388 iteration 517 : loss : 0.084451, loss_ce: 0.031779
2021-12-11 19:31:53,973 iteration 518 : loss : 0.132105, loss_ce: 0.069236
2021-12-11 19:31:55,478 iteration 519 : loss : 0.092222, loss_ce: 0.033326
2021-12-11 19:31:56,980 iteration 520 : loss : 0.109154, loss_ce: 0.054799
2021-12-11 19:31:58,619 iteration 521 : loss : 0.185130, loss_ce: 0.048686
2021-12-11 19:32:00,136 iteration 522 : loss : 0.063540, loss_ce: 0.026225
2021-12-11 19:32:01,712 iteration 523 : loss : 0.064042, loss_ce: 0.030100
2021-12-11 19:32:03,139 iteration 524 : loss : 0.075968, loss_ce: 0.030951
2021-12-11 19:32:04,658 iteration 525 : loss : 0.070555, loss_ce: 0.030602
2021-12-11 19:32:06,224 iteration 526 : loss : 0.082555, loss_ce: 0.033253
2021-12-11 19:32:07,787 iteration 527 : loss : 0.094768, loss_ce: 0.040190
  8%|██▎                           | 31/400 [14:41<2:58:27, 29.02s/it]2021-12-11 19:32:09,410 iteration 528 : loss : 0.076495, loss_ce: 0.027926
2021-12-11 19:32:10,949 iteration 529 : loss : 0.065127, loss_ce: 0.031507
2021-12-11 19:32:12,464 iteration 530 : loss : 0.059459, loss_ce: 0.023382
2021-12-11 19:32:14,057 iteration 531 : loss : 0.167949, loss_ce: 0.058144
2021-12-11 19:32:15,522 iteration 532 : loss : 0.102469, loss_ce: 0.030753
2021-12-11 19:32:17,076 iteration 533 : loss : 0.066902, loss_ce: 0.030583
2021-12-11 19:32:18,630 iteration 534 : loss : 0.106187, loss_ce: 0.050812
2021-12-11 19:32:20,183 iteration 535 : loss : 0.084018, loss_ce: 0.034346
2021-12-11 19:32:21,651 iteration 536 : loss : 0.116900, loss_ce: 0.053488
2021-12-11 19:32:23,183 iteration 537 : loss : 0.084437, loss_ce: 0.036155
2021-12-11 19:32:24,702 iteration 538 : loss : 0.077614, loss_ce: 0.029385
2021-12-11 19:32:26,199 iteration 539 : loss : 0.109475, loss_ce: 0.039771
2021-12-11 19:32:27,686 iteration 540 : loss : 0.111081, loss_ce: 0.052875
2021-12-11 19:32:29,215 iteration 541 : loss : 0.093903, loss_ce: 0.045713
2021-12-11 19:32:30,680 iteration 542 : loss : 0.097577, loss_ce: 0.036513
2021-12-11 19:32:32,178 iteration 543 : loss : 0.096625, loss_ce: 0.032696
2021-12-11 19:32:33,712 iteration 544 : loss : 0.117866, loss_ce: 0.041020
  8%|██▍                           | 32/400 [15:07<2:52:17, 28.09s/it]2021-12-11 19:32:35,274 iteration 545 : loss : 0.108501, loss_ce: 0.045317
2021-12-11 19:32:36,824 iteration 546 : loss : 0.077195, loss_ce: 0.031568
2021-12-11 19:32:38,363 iteration 547 : loss : 0.128427, loss_ce: 0.056827
2021-12-11 19:32:39,832 iteration 548 : loss : 0.103944, loss_ce: 0.043771
2021-12-11 19:32:41,373 iteration 549 : loss : 0.074230, loss_ce: 0.033286
2021-12-11 19:32:43,012 iteration 550 : loss : 0.136739, loss_ce: 0.064498
2021-12-11 19:32:44,583 iteration 551 : loss : 0.088533, loss_ce: 0.036352
2021-12-11 19:32:46,190 iteration 552 : loss : 0.102900, loss_ce: 0.049903
2021-12-11 19:32:47,796 iteration 553 : loss : 0.118403, loss_ce: 0.061240
2021-12-11 19:32:49,289 iteration 554 : loss : 0.065453, loss_ce: 0.027608
2021-12-11 19:32:50,849 iteration 555 : loss : 0.080962, loss_ce: 0.040180
2021-12-11 19:32:52,471 iteration 556 : loss : 0.105993, loss_ce: 0.042127
2021-12-11 19:32:54,007 iteration 557 : loss : 0.094496, loss_ce: 0.046532
2021-12-11 19:32:55,516 iteration 558 : loss : 0.088057, loss_ce: 0.034658
2021-12-11 19:32:57,089 iteration 559 : loss : 0.093188, loss_ce: 0.038198
2021-12-11 19:32:58,665 iteration 560 : loss : 0.096240, loss_ce: 0.039223
2021-12-11 19:33:00,166 iteration 561 : loss : 0.122982, loss_ce: 0.036253
  8%|██▍                           | 33/400 [15:34<2:48:48, 27.60s/it]2021-12-11 19:33:01,731 iteration 562 : loss : 0.090013, loss_ce: 0.037507
2021-12-11 19:33:03,288 iteration 563 : loss : 0.078387, loss_ce: 0.036445
2021-12-11 19:33:04,891 iteration 564 : loss : 0.086301, loss_ce: 0.041618
2021-12-11 19:33:06,457 iteration 565 : loss : 0.152528, loss_ce: 0.086766
2021-12-11 19:33:07,923 iteration 566 : loss : 0.068282, loss_ce: 0.026230
2021-12-11 19:33:09,511 iteration 567 : loss : 0.094871, loss_ce: 0.032471
2021-12-11 19:33:11,014 iteration 568 : loss : 0.085140, loss_ce: 0.031219
2021-12-11 19:33:12,553 iteration 569 : loss : 0.086276, loss_ce: 0.033116
2021-12-11 19:33:14,180 iteration 570 : loss : 0.093819, loss_ce: 0.036575
2021-12-11 19:33:15,772 iteration 571 : loss : 0.089256, loss_ce: 0.036682
2021-12-11 19:33:17,344 iteration 572 : loss : 0.073760, loss_ce: 0.027740
2021-12-11 19:33:18,868 iteration 573 : loss : 0.069788, loss_ce: 0.027743
2021-12-11 19:33:20,402 iteration 574 : loss : 0.089174, loss_ce: 0.036543
2021-12-11 19:33:21,983 iteration 575 : loss : 0.106869, loss_ce: 0.045558
2021-12-11 19:33:23,527 iteration 576 : loss : 0.070400, loss_ce: 0.034141
2021-12-11 19:33:25,146 iteration 577 : loss : 0.151147, loss_ce: 0.047060
2021-12-11 19:33:26,710 iteration 578 : loss : 0.104948, loss_ce: 0.037898
  8%|██▌                           | 34/400 [16:00<2:46:24, 27.28s/it]2021-12-11 19:33:28,282 iteration 579 : loss : 0.058126, loss_ce: 0.020429
2021-12-11 19:33:29,817 iteration 580 : loss : 0.100267, loss_ce: 0.048337
2021-12-11 19:33:31,363 iteration 581 : loss : 0.067664, loss_ce: 0.031268
2021-12-11 19:33:32,924 iteration 582 : loss : 0.069356, loss_ce: 0.026006
2021-12-11 19:33:34,445 iteration 583 : loss : 0.101071, loss_ce: 0.047658
2021-12-11 19:33:35,881 iteration 584 : loss : 0.067618, loss_ce: 0.028296
2021-12-11 19:33:37,377 iteration 585 : loss : 0.070357, loss_ce: 0.027207
2021-12-11 19:33:38,950 iteration 586 : loss : 0.077867, loss_ce: 0.037558
2021-12-11 19:33:40,481 iteration 587 : loss : 0.071803, loss_ce: 0.029788
2021-12-11 19:33:42,099 iteration 588 : loss : 0.100935, loss_ce: 0.037559
2021-12-11 19:33:43,645 iteration 589 : loss : 0.068366, loss_ce: 0.028939
2021-12-11 19:33:45,157 iteration 590 : loss : 0.118932, loss_ce: 0.075657
2021-12-11 19:33:46,687 iteration 591 : loss : 0.069850, loss_ce: 0.027183
2021-12-11 19:33:48,213 iteration 592 : loss : 0.091429, loss_ce: 0.036536
2021-12-11 19:33:49,794 iteration 593 : loss : 0.117210, loss_ce: 0.045675
2021-12-11 19:33:51,395 iteration 594 : loss : 0.080727, loss_ce: 0.042509
2021-12-11 19:33:51,395 Training Data Eval:
2021-12-11 19:33:59,053   Average segmentation loss on training set: 0.1568
2021-12-11 19:33:59,054 Validation Data Eval:
2021-12-11 19:34:01,691   Average segmentation loss on validation set: 0.2811
2021-12-11 19:34:03,254 iteration 595 : loss : 0.073519, loss_ce: 0.027994
  9%|██▋                           | 35/400 [16:37<3:02:52, 30.06s/it]2021-12-11 19:34:04,786 iteration 596 : loss : 0.067297, loss_ce: 0.030005
2021-12-11 19:34:06,334 iteration 597 : loss : 0.106726, loss_ce: 0.048320
2021-12-11 19:34:07,910 iteration 598 : loss : 0.076259, loss_ce: 0.032355
2021-12-11 19:34:09,506 iteration 599 : loss : 0.048452, loss_ce: 0.020086
2021-12-11 19:34:10,962 iteration 600 : loss : 0.076541, loss_ce: 0.037207
2021-12-11 19:34:12,495 iteration 601 : loss : 0.074180, loss_ce: 0.026399
2021-12-11 19:34:14,071 iteration 602 : loss : 0.068715, loss_ce: 0.033571
2021-12-11 19:34:15,515 iteration 603 : loss : 0.086524, loss_ce: 0.034967
2021-12-11 19:34:17,033 iteration 604 : loss : 0.085330, loss_ce: 0.034058
2021-12-11 19:34:18,572 iteration 605 : loss : 0.082206, loss_ce: 0.035530
2021-12-11 19:34:20,066 iteration 606 : loss : 0.085280, loss_ce: 0.032097
2021-12-11 19:34:21,595 iteration 607 : loss : 0.100545, loss_ce: 0.040139
2021-12-11 19:34:23,240 iteration 608 : loss : 0.083464, loss_ce: 0.029859
2021-12-11 19:34:24,759 iteration 609 : loss : 0.063430, loss_ce: 0.027128
2021-12-11 19:34:26,353 iteration 610 : loss : 0.087279, loss_ce: 0.033751
2021-12-11 19:34:27,927 iteration 611 : loss : 0.108067, loss_ce: 0.037330
2021-12-11 19:34:29,460 iteration 612 : loss : 0.075205, loss_ce: 0.031969
  9%|██▋                           | 36/400 [17:03<2:55:20, 28.90s/it]2021-12-11 19:34:31,062 iteration 613 : loss : 0.086445, loss_ce: 0.039492
2021-12-11 19:34:32,712 iteration 614 : loss : 0.088245, loss_ce: 0.037645
2021-12-11 19:34:34,251 iteration 615 : loss : 0.073921, loss_ce: 0.027942
2021-12-11 19:34:35,738 iteration 616 : loss : 0.098327, loss_ce: 0.054478
2021-12-11 19:34:37,274 iteration 617 : loss : 0.097695, loss_ce: 0.044807
2021-12-11 19:34:38,762 iteration 618 : loss : 0.099965, loss_ce: 0.042592
2021-12-11 19:34:40,296 iteration 619 : loss : 0.103970, loss_ce: 0.036020
2021-12-11 19:34:41,919 iteration 620 : loss : 0.137628, loss_ce: 0.056796
2021-12-11 19:34:43,411 iteration 621 : loss : 0.074331, loss_ce: 0.029513
2021-12-11 19:34:44,979 iteration 622 : loss : 0.061281, loss_ce: 0.026747
2021-12-11 19:34:46,580 iteration 623 : loss : 0.108010, loss_ce: 0.032739
2021-12-11 19:34:48,090 iteration 624 : loss : 0.106692, loss_ce: 0.038667
2021-12-11 19:34:49,565 iteration 625 : loss : 0.099820, loss_ce: 0.036624
2021-12-11 19:34:51,052 iteration 626 : loss : 0.060915, loss_ce: 0.022732
2021-12-11 19:34:52,567 iteration 627 : loss : 0.080432, loss_ce: 0.024515
2021-12-11 19:34:54,077 iteration 628 : loss : 0.107061, loss_ce: 0.057905
2021-12-11 19:34:55,647 iteration 629 : loss : 0.077729, loss_ce: 0.030488
  9%|██▊                           | 37/400 [17:29<2:49:56, 28.09s/it]2021-12-11 19:34:57,208 iteration 630 : loss : 0.060434, loss_ce: 0.025384
2021-12-11 19:34:58,780 iteration 631 : loss : 0.092692, loss_ce: 0.048891
2021-12-11 19:35:00,335 iteration 632 : loss : 0.101620, loss_ce: 0.043795
2021-12-11 19:35:01,914 iteration 633 : loss : 0.071055, loss_ce: 0.028985
2021-12-11 19:35:03,514 iteration 634 : loss : 0.076288, loss_ce: 0.035484
2021-12-11 19:35:05,052 iteration 635 : loss : 0.117132, loss_ce: 0.042265
2021-12-11 19:35:06,672 iteration 636 : loss : 0.090693, loss_ce: 0.042054
2021-12-11 19:35:08,167 iteration 637 : loss : 0.080457, loss_ce: 0.030839
2021-12-11 19:35:09,676 iteration 638 : loss : 0.144311, loss_ce: 0.061847
2021-12-11 19:35:11,252 iteration 639 : loss : 0.084913, loss_ce: 0.036967
2021-12-11 19:35:12,773 iteration 640 : loss : 0.083019, loss_ce: 0.033769
2021-12-11 19:35:14,353 iteration 641 : loss : 0.067655, loss_ce: 0.029083
2021-12-11 19:35:15,946 iteration 642 : loss : 0.061307, loss_ce: 0.025078
2021-12-11 19:35:17,488 iteration 643 : loss : 0.092976, loss_ce: 0.040266
2021-12-11 19:35:19,025 iteration 644 : loss : 0.054497, loss_ce: 0.023339
2021-12-11 19:35:20,590 iteration 645 : loss : 0.076369, loss_ce: 0.031454
2021-12-11 19:35:22,113 iteration 646 : loss : 0.076319, loss_ce: 0.033905
 10%|██▊                           | 38/400 [17:56<2:46:32, 27.60s/it]2021-12-11 19:35:23,678 iteration 647 : loss : 0.083016, loss_ce: 0.028960
2021-12-11 19:35:25,170 iteration 648 : loss : 0.081066, loss_ce: 0.038495
2021-12-11 19:35:26,662 iteration 649 : loss : 0.061690, loss_ce: 0.029183
2021-12-11 19:35:28,238 iteration 650 : loss : 0.143830, loss_ce: 0.043178
2021-12-11 19:35:29,818 iteration 651 : loss : 0.072965, loss_ce: 0.027617
2021-12-11 19:35:31,295 iteration 652 : loss : 0.066472, loss_ce: 0.027690
2021-12-11 19:35:32,860 iteration 653 : loss : 0.056716, loss_ce: 0.026632
2021-12-11 19:35:34,398 iteration 654 : loss : 0.075302, loss_ce: 0.027646
2021-12-11 19:35:35,868 iteration 655 : loss : 0.083720, loss_ce: 0.033802
2021-12-11 19:35:37,450 iteration 656 : loss : 0.112627, loss_ce: 0.046447
2021-12-11 19:35:38,987 iteration 657 : loss : 0.073865, loss_ce: 0.026187
2021-12-11 19:35:40,524 iteration 658 : loss : 0.101712, loss_ce: 0.036665
2021-12-11 19:35:42,117 iteration 659 : loss : 0.079605, loss_ce: 0.026596
2021-12-11 19:35:43,665 iteration 660 : loss : 0.086144, loss_ce: 0.035997
2021-12-11 19:35:45,237 iteration 661 : loss : 0.061563, loss_ce: 0.030723
2021-12-11 19:35:46,805 iteration 662 : loss : 0.072409, loss_ce: 0.030751
2021-12-11 19:35:48,331 iteration 663 : loss : 0.114924, loss_ce: 0.052360
 10%|██▉                           | 39/400 [18:22<2:43:34, 27.19s/it]2021-12-11 19:35:49,871 iteration 664 : loss : 0.104074, loss_ce: 0.055688
2021-12-11 19:35:51,444 iteration 665 : loss : 0.072233, loss_ce: 0.023432
2021-12-11 19:35:53,001 iteration 666 : loss : 0.069898, loss_ce: 0.022647
2021-12-11 19:35:54,598 iteration 667 : loss : 0.081976, loss_ce: 0.032777
2021-12-11 19:35:56,110 iteration 668 : loss : 0.040580, loss_ce: 0.015912
2021-12-11 19:35:57,707 iteration 669 : loss : 0.077235, loss_ce: 0.035199
2021-12-11 19:35:59,304 iteration 670 : loss : 0.093644, loss_ce: 0.039105
2021-12-11 19:36:00,898 iteration 671 : loss : 0.081434, loss_ce: 0.032699
2021-12-11 19:36:02,358 iteration 672 : loss : 0.064196, loss_ce: 0.028656
2021-12-11 19:36:03,902 iteration 673 : loss : 0.060028, loss_ce: 0.023882
2021-12-11 19:36:05,587 iteration 674 : loss : 0.066138, loss_ce: 0.033115
2021-12-11 19:36:07,130 iteration 675 : loss : 0.090572, loss_ce: 0.035251
2021-12-11 19:36:08,651 iteration 676 : loss : 0.058539, loss_ce: 0.024206
2021-12-11 19:36:10,310 iteration 677 : loss : 0.074477, loss_ce: 0.033611
2021-12-11 19:36:11,868 iteration 678 : loss : 0.090507, loss_ce: 0.027889
2021-12-11 19:36:13,362 iteration 679 : loss : 0.086619, loss_ce: 0.036753
2021-12-11 19:36:13,362 Training Data Eval:
2021-12-11 19:36:20,993   Average segmentation loss on training set: 0.0549
2021-12-11 19:36:20,994 Validation Data Eval:
2021-12-11 19:36:23,632   Average segmentation loss on validation set: 0.1147
2021-12-11 19:36:25,584 Found new lowest validation loss at iteration 679! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/NEW_TU/UNET_ADAM_best_val_loss_seed100.pth
2021-12-11 19:36:26,991 iteration 680 : loss : 0.091517, loss_ce: 0.035079
 10%|███                           | 40/400 [19:01<3:03:46, 30.63s/it]2021-12-11 19:36:28,607 iteration 681 : loss : 0.097688, loss_ce: 0.036054
2021-12-11 19:36:30,071 iteration 682 : loss : 0.066070, loss_ce: 0.024023
2021-12-11 19:36:31,524 iteration 683 : loss : 0.080108, loss_ce: 0.025004
2021-12-11 19:36:33,138 iteration 684 : loss : 0.070474, loss_ce: 0.028656
2021-12-11 19:36:34,749 iteration 685 : loss : 0.081331, loss_ce: 0.030588
2021-12-11 19:36:36,336 iteration 686 : loss : 0.062543, loss_ce: 0.026831
2021-12-11 19:36:37,916 iteration 687 : loss : 0.060012, loss_ce: 0.028752
2021-12-11 19:36:39,532 iteration 688 : loss : 0.074436, loss_ce: 0.030126
2021-12-11 19:36:41,119 iteration 689 : loss : 0.059645, loss_ce: 0.027836
2021-12-11 19:36:42,660 iteration 690 : loss : 0.083233, loss_ce: 0.034782
2021-12-11 19:36:44,252 iteration 691 : loss : 0.062638, loss_ce: 0.023467
2021-12-11 19:36:45,739 iteration 692 : loss : 0.054317, loss_ce: 0.025269
2021-12-11 19:36:47,260 iteration 693 : loss : 0.057612, loss_ce: 0.023289
2021-12-11 19:36:48,791 iteration 694 : loss : 0.081145, loss_ce: 0.029023
2021-12-11 19:36:50,361 iteration 695 : loss : 0.100922, loss_ce: 0.035068
2021-12-11 19:36:51,862 iteration 696 : loss : 0.156920, loss_ce: 0.036150
2021-12-11 19:36:53,311 iteration 697 : loss : 0.054178, loss_ce: 0.025249
 10%|███                           | 41/400 [19:27<2:55:32, 29.34s/it]2021-12-11 19:36:54,908 iteration 698 : loss : 0.073695, loss_ce: 0.036795
2021-12-11 19:36:56,481 iteration 699 : loss : 0.088727, loss_ce: 0.033611
2021-12-11 19:36:57,984 iteration 700 : loss : 0.069844, loss_ce: 0.025726
2021-12-11 19:36:59,500 iteration 701 : loss : 0.075011, loss_ce: 0.025076
2021-12-11 19:37:01,082 iteration 702 : loss : 0.074516, loss_ce: 0.033494
2021-12-11 19:37:02,637 iteration 703 : loss : 0.096314, loss_ce: 0.031543
2021-12-11 19:37:04,257 iteration 704 : loss : 0.130540, loss_ce: 0.037050
2021-12-11 19:37:05,838 iteration 705 : loss : 0.071838, loss_ce: 0.036561
2021-12-11 19:37:07,459 iteration 706 : loss : 0.116690, loss_ce: 0.035611
2021-12-11 19:37:08,981 iteration 707 : loss : 0.092995, loss_ce: 0.040709
2021-12-11 19:37:10,537 iteration 708 : loss : 0.091480, loss_ce: 0.032464
2021-12-11 19:37:12,106 iteration 709 : loss : 0.097548, loss_ce: 0.030228
2021-12-11 19:37:13,602 iteration 710 : loss : 0.068783, loss_ce: 0.032313
2021-12-11 19:37:15,186 iteration 711 : loss : 0.075287, loss_ce: 0.033158
2021-12-11 19:37:16,719 iteration 712 : loss : 0.134550, loss_ce: 0.044603
2021-12-11 19:37:18,186 iteration 713 : loss : 0.055034, loss_ce: 0.022124
2021-12-11 19:37:19,674 iteration 714 : loss : 0.070727, loss_ce: 0.027160
 10%|███▏                          | 42/400 [19:53<2:49:42, 28.44s/it]2021-12-11 19:37:21,311 iteration 715 : loss : 0.077684, loss_ce: 0.037142
2021-12-11 19:37:22,837 iteration 716 : loss : 0.062164, loss_ce: 0.026104
2021-12-11 19:37:24,348 iteration 717 : loss : 0.082090, loss_ce: 0.027791
2021-12-11 19:37:25,872 iteration 718 : loss : 0.090563, loss_ce: 0.035666
2021-12-11 19:37:27,478 iteration 719 : loss : 0.075001, loss_ce: 0.028792
2021-12-11 19:37:28,982 iteration 720 : loss : 0.075846, loss_ce: 0.022492
2021-12-11 19:37:30,567 iteration 721 : loss : 0.069232, loss_ce: 0.023531
2021-12-11 19:37:32,118 iteration 722 : loss : 0.078700, loss_ce: 0.033640
2021-12-11 19:37:33,621 iteration 723 : loss : 0.056681, loss_ce: 0.021885
2021-12-11 19:37:35,264 iteration 724 : loss : 0.098099, loss_ce: 0.046249
2021-12-11 19:37:36,741 iteration 725 : loss : 0.060092, loss_ce: 0.022639
2021-12-11 19:37:38,319 iteration 726 : loss : 0.080470, loss_ce: 0.023222
2021-12-11 19:37:39,914 iteration 727 : loss : 0.099728, loss_ce: 0.031525
2021-12-11 19:37:41,627 iteration 728 : loss : 0.072223, loss_ce: 0.031725
2021-12-11 19:37:43,056 iteration 729 : loss : 0.045617, loss_ce: 0.021184
2021-12-11 19:37:44,610 iteration 730 : loss : 0.059618, loss_ce: 0.026355
2021-12-11 19:37:46,163 iteration 731 : loss : 0.072259, loss_ce: 0.026250
 11%|███▏                          | 43/400 [20:20<2:45:44, 27.85s/it]2021-12-11 19:37:47,838 iteration 732 : loss : 0.068105, loss_ce: 0.028487
2021-12-11 19:37:49,393 iteration 733 : loss : 0.121876, loss_ce: 0.053718
2021-12-11 19:37:50,875 iteration 734 : loss : 0.074419, loss_ce: 0.029246
2021-12-11 19:37:52,403 iteration 735 : loss : 0.062862, loss_ce: 0.025807
2021-12-11 19:37:53,956 iteration 736 : loss : 0.078290, loss_ce: 0.037195
2021-12-11 19:37:55,549 iteration 737 : loss : 0.059900, loss_ce: 0.023845
2021-12-11 19:37:57,093 iteration 738 : loss : 0.054878, loss_ce: 0.023758
2021-12-11 19:37:58,614 iteration 739 : loss : 0.069879, loss_ce: 0.029303
2021-12-11 19:38:00,147 iteration 740 : loss : 0.093425, loss_ce: 0.043247
2021-12-11 19:38:01,699 iteration 741 : loss : 0.066797, loss_ce: 0.030274
2021-12-11 19:38:03,315 iteration 742 : loss : 0.083653, loss_ce: 0.034856
2021-12-11 19:38:04,831 iteration 743 : loss : 0.088630, loss_ce: 0.037812
2021-12-11 19:38:06,345 iteration 744 : loss : 0.073302, loss_ce: 0.028356
2021-12-11 19:38:07,906 iteration 745 : loss : 0.060516, loss_ce: 0.027009
2021-12-11 19:38:09,436 iteration 746 : loss : 0.114621, loss_ce: 0.061975
2021-12-11 19:38:11,004 iteration 747 : loss : 0.112795, loss_ce: 0.032415
2021-12-11 19:38:12,451 iteration 748 : loss : 0.056606, loss_ce: 0.025593
 11%|███▎                          | 44/400 [20:46<2:42:30, 27.39s/it]2021-12-11 19:38:14,041 iteration 749 : loss : 0.058354, loss_ce: 0.025570
2021-12-11 19:38:15,623 iteration 750 : loss : 0.068227, loss_ce: 0.031788
2021-12-11 19:38:17,089 iteration 751 : loss : 0.070586, loss_ce: 0.029425
2021-12-11 19:38:18,628 iteration 752 : loss : 0.066681, loss_ce: 0.028717
2021-12-11 19:38:20,248 iteration 753 : loss : 0.075028, loss_ce: 0.032842
2021-12-11 19:38:21,755 iteration 754 : loss : 0.084348, loss_ce: 0.033840
2021-12-11 19:38:23,293 iteration 755 : loss : 0.065915, loss_ce: 0.026727
2021-12-11 19:38:24,786 iteration 756 : loss : 0.055512, loss_ce: 0.024076
2021-12-11 19:38:26,295 iteration 757 : loss : 0.062659, loss_ce: 0.024320
2021-12-11 19:38:27,833 iteration 758 : loss : 0.076819, loss_ce: 0.030845
2021-12-11 19:38:29,295 iteration 759 : loss : 0.055462, loss_ce: 0.021013
2021-12-11 19:38:30,855 iteration 760 : loss : 0.116973, loss_ce: 0.041802
2021-12-11 19:38:32,433 iteration 761 : loss : 0.069183, loss_ce: 0.022814
2021-12-11 19:38:33,993 iteration 762 : loss : 0.073706, loss_ce: 0.033564
2021-12-11 19:38:35,526 iteration 763 : loss : 0.062506, loss_ce: 0.026400
2021-12-11 19:38:37,017 iteration 764 : loss : 0.066392, loss_ce: 0.025969
2021-12-11 19:38:37,017 Training Data Eval:
2021-12-11 19:38:44,651   Average segmentation loss on training set: 0.0854
2021-12-11 19:38:44,651 Validation Data Eval:
2021-12-11 19:38:47,282   Average segmentation loss on validation set: 0.1349
2021-12-11 19:38:48,846 iteration 765 : loss : 0.066359, loss_ce: 0.025824
 11%|███▍                          | 45/400 [21:22<2:58:01, 30.09s/it]2021-12-11 19:38:50,402 iteration 766 : loss : 0.076182, loss_ce: 0.029621
2021-12-11 19:38:51,995 iteration 767 : loss : 0.076673, loss_ce: 0.025856
2021-12-11 19:38:53,441 iteration 768 : loss : 0.066055, loss_ce: 0.026556
2021-12-11 19:38:54,986 iteration 769 : loss : 0.171911, loss_ce: 0.031848
2021-12-11 19:38:56,477 iteration 770 : loss : 0.060279, loss_ce: 0.024601
2021-12-11 19:38:58,080 iteration 771 : loss : 0.081327, loss_ce: 0.029521
2021-12-11 19:38:59,678 iteration 772 : loss : 0.068701, loss_ce: 0.034187
2021-12-11 19:39:01,225 iteration 773 : loss : 0.075944, loss_ce: 0.029397
2021-12-11 19:39:02,773 iteration 774 : loss : 0.057263, loss_ce: 0.026093
2021-12-11 19:39:04,294 iteration 775 : loss : 0.057958, loss_ce: 0.021931
2021-12-11 19:39:05,742 iteration 776 : loss : 0.063058, loss_ce: 0.026344
2021-12-11 19:39:07,335 iteration 777 : loss : 0.059714, loss_ce: 0.023380
2021-12-11 19:39:08,878 iteration 778 : loss : 0.047650, loss_ce: 0.020460
2021-12-11 19:39:10,451 iteration 779 : loss : 0.065369, loss_ce: 0.034496
2021-12-11 19:39:11,938 iteration 780 : loss : 0.068060, loss_ce: 0.025917
2021-12-11 19:39:13,517 iteration 781 : loss : 0.064233, loss_ce: 0.029030
2021-12-11 19:39:15,100 iteration 782 : loss : 0.096170, loss_ce: 0.044573
 12%|███▍                          | 46/400 [21:49<2:50:43, 28.94s/it]2021-12-11 19:39:16,726 iteration 783 : loss : 0.061117, loss_ce: 0.031002
2021-12-11 19:39:18,264 iteration 784 : loss : 0.072826, loss_ce: 0.026540
2021-12-11 19:39:19,846 iteration 785 : loss : 0.050749, loss_ce: 0.022219
2021-12-11 19:39:21,374 iteration 786 : loss : 0.103062, loss_ce: 0.037498
2021-12-11 19:39:22,916 iteration 787 : loss : 0.076437, loss_ce: 0.031655
2021-12-11 19:39:24,480 iteration 788 : loss : 0.058757, loss_ce: 0.019036
2021-12-11 19:39:26,134 iteration 789 : loss : 0.106770, loss_ce: 0.059399
2021-12-11 19:39:27,745 iteration 790 : loss : 0.054545, loss_ce: 0.018768
2021-12-11 19:39:29,255 iteration 791 : loss : 0.073515, loss_ce: 0.028074
2021-12-11 19:39:30,805 iteration 792 : loss : 0.078402, loss_ce: 0.035523
2021-12-11 19:39:32,257 iteration 793 : loss : 0.084801, loss_ce: 0.027276
2021-12-11 19:39:33,773 iteration 794 : loss : 0.046840, loss_ce: 0.020128
2021-12-11 19:39:35,311 iteration 795 : loss : 0.076930, loss_ce: 0.030144
2021-12-11 19:39:36,845 iteration 796 : loss : 0.078261, loss_ce: 0.030895
2021-12-11 19:39:38,338 iteration 797 : loss : 0.057078, loss_ce: 0.025972
2021-12-11 19:39:39,846 iteration 798 : loss : 0.118132, loss_ce: 0.032847
2021-12-11 19:39:41,412 iteration 799 : loss : 0.050444, loss_ce: 0.019456
 12%|███▌                          | 47/400 [22:15<2:45:37, 28.15s/it]2021-12-11 19:39:43,040 iteration 800 : loss : 0.074290, loss_ce: 0.016846
2021-12-11 19:39:44,535 iteration 801 : loss : 0.068700, loss_ce: 0.025098
2021-12-11 19:39:46,062 iteration 802 : loss : 0.072957, loss_ce: 0.039114
2021-12-11 19:39:47,676 iteration 803 : loss : 0.095633, loss_ce: 0.053762
2021-12-11 19:39:49,158 iteration 804 : loss : 0.053064, loss_ce: 0.023424
2021-12-11 19:39:50,636 iteration 805 : loss : 0.152854, loss_ce: 0.034681
2021-12-11 19:39:52,185 iteration 806 : loss : 0.087749, loss_ce: 0.034928
2021-12-11 19:39:53,804 iteration 807 : loss : 0.080607, loss_ce: 0.032344
2021-12-11 19:39:55,391 iteration 808 : loss : 0.087641, loss_ce: 0.034718
2021-12-11 19:39:56,960 iteration 809 : loss : 0.131794, loss_ce: 0.043968
2021-12-11 19:39:58,541 iteration 810 : loss : 0.113458, loss_ce: 0.041431
2021-12-11 19:40:00,043 iteration 811 : loss : 0.068570, loss_ce: 0.028600
2021-12-11 19:40:01,651 iteration 812 : loss : 0.129765, loss_ce: 0.060340
2021-12-11 19:40:03,187 iteration 813 : loss : 0.086195, loss_ce: 0.034171
2021-12-11 19:40:04,739 iteration 814 : loss : 0.102431, loss_ce: 0.046154
2021-12-11 19:40:06,330 iteration 815 : loss : 0.083581, loss_ce: 0.030901
2021-12-11 19:40:07,752 iteration 816 : loss : 0.063581, loss_ce: 0.023675
 12%|███▌                          | 48/400 [22:41<2:41:58, 27.61s/it]2021-12-11 19:40:09,293 iteration 817 : loss : 0.064939, loss_ce: 0.023488
2021-12-11 19:40:10,855 iteration 818 : loss : 0.082062, loss_ce: 0.036045
2021-12-11 19:40:12,386 iteration 819 : loss : 0.059398, loss_ce: 0.025825
2021-12-11 19:40:14,013 iteration 820 : loss : 0.097557, loss_ce: 0.038002
2021-12-11 19:40:15,499 iteration 821 : loss : 0.090123, loss_ce: 0.034309
2021-12-11 19:40:17,055 iteration 822 : loss : 0.061590, loss_ce: 0.025202
2021-12-11 19:40:18,589 iteration 823 : loss : 0.071542, loss_ce: 0.027940
2021-12-11 19:40:20,094 iteration 824 : loss : 0.068758, loss_ce: 0.029902
2021-12-11 19:40:21,637 iteration 825 : loss : 0.063297, loss_ce: 0.020448
2021-12-11 19:40:23,197 iteration 826 : loss : 0.067508, loss_ce: 0.028478
2021-12-11 19:40:24,724 iteration 827 : loss : 0.120397, loss_ce: 0.033852
2021-12-11 19:40:26,300 iteration 828 : loss : 0.087276, loss_ce: 0.040064
2021-12-11 19:40:27,837 iteration 829 : loss : 0.095591, loss_ce: 0.034211
2021-12-11 19:40:29,465 iteration 830 : loss : 0.100626, loss_ce: 0.029218
2021-12-11 19:40:31,013 iteration 831 : loss : 0.088061, loss_ce: 0.033219
2021-12-11 19:40:32,532 iteration 832 : loss : 0.050394, loss_ce: 0.020012
2021-12-11 19:40:34,019 iteration 833 : loss : 0.065092, loss_ce: 0.030524
 12%|███▋                          | 49/400 [23:08<2:39:08, 27.20s/it]2021-12-11 19:40:35,553 iteration 834 : loss : 0.067502, loss_ce: 0.022575
2021-12-11 19:40:37,116 iteration 835 : loss : 0.078998, loss_ce: 0.032815
2021-12-11 19:40:38,676 iteration 836 : loss : 0.067832, loss_ce: 0.030042
2021-12-11 19:40:40,186 iteration 837 : loss : 0.061242, loss_ce: 0.027320
2021-12-11 19:40:41,695 iteration 838 : loss : 0.082925, loss_ce: 0.036949
2021-12-11 19:40:43,300 iteration 839 : loss : 0.067941, loss_ce: 0.022737
2021-12-11 19:40:44,919 iteration 840 : loss : 0.085304, loss_ce: 0.030509
2021-12-11 19:40:46,463 iteration 841 : loss : 0.073790, loss_ce: 0.038861
2021-12-11 19:40:48,112 iteration 842 : loss : 0.085378, loss_ce: 0.035010
2021-12-11 19:40:49,627 iteration 843 : loss : 0.057995, loss_ce: 0.021143
2021-12-11 19:40:51,200 iteration 844 : loss : 0.093934, loss_ce: 0.045798
2021-12-11 19:40:52,700 iteration 845 : loss : 0.072079, loss_ce: 0.032677
2021-12-11 19:40:54,237 iteration 846 : loss : 0.081562, loss_ce: 0.030144
2021-12-11 19:40:55,823 iteration 847 : loss : 0.083607, loss_ce: 0.029751
2021-12-11 19:40:57,282 iteration 848 : loss : 0.071800, loss_ce: 0.027034
2021-12-11 19:40:58,847 iteration 849 : loss : 0.060664, loss_ce: 0.026755
2021-12-11 19:40:58,847 Training Data Eval:
2021-12-11 19:41:06,489   Average segmentation loss on training set: 0.1326
2021-12-11 19:41:06,490 Validation Data Eval:
2021-12-11 19:41:09,130   Average segmentation loss on validation set: 0.2858
2021-12-11 19:41:10,733 iteration 850 : loss : 0.071699, loss_ce: 0.023310
 12%|███▊                          | 50/400 [23:44<2:55:20, 30.06s/it]2021-12-11 19:41:12,335 iteration 851 : loss : 0.058217, loss_ce: 0.028963
2021-12-11 19:41:13,927 iteration 852 : loss : 0.076033, loss_ce: 0.024462
2021-12-11 19:41:15,512 iteration 853 : loss : 0.082193, loss_ce: 0.033303
2021-12-11 19:41:17,010 iteration 854 : loss : 0.067637, loss_ce: 0.025164
2021-12-11 19:41:18,471 iteration 855 : loss : 0.060680, loss_ce: 0.024209
2021-12-11 19:41:19,967 iteration 856 : loss : 0.074224, loss_ce: 0.028428
2021-12-11 19:41:21,591 iteration 857 : loss : 0.056415, loss_ce: 0.023942
2021-12-11 19:41:23,128 iteration 858 : loss : 0.096721, loss_ce: 0.037583
2021-12-11 19:41:24,756 iteration 859 : loss : 0.053425, loss_ce: 0.022526
2021-12-11 19:41:26,335 iteration 860 : loss : 0.102029, loss_ce: 0.040435
2021-12-11 19:41:27,865 iteration 861 : loss : 0.071276, loss_ce: 0.026947
2021-12-11 19:41:29,405 iteration 862 : loss : 0.067539, loss_ce: 0.016768
2021-12-11 19:41:30,902 iteration 863 : loss : 0.099059, loss_ce: 0.043063
2021-12-11 19:41:32,430 iteration 864 : loss : 0.050384, loss_ce: 0.022144
2021-12-11 19:41:33,904 iteration 865 : loss : 0.070961, loss_ce: 0.032286
2021-12-11 19:41:35,393 iteration 866 : loss : 0.047736, loss_ce: 0.018939
2021-12-11 19:41:36,887 iteration 867 : loss : 0.066077, loss_ce: 0.026838
 13%|███▊                          | 51/400 [24:11<2:48:01, 28.89s/it]2021-12-11 19:41:38,501 iteration 868 : loss : 0.062156, loss_ce: 0.020014
2021-12-11 19:41:39,999 iteration 869 : loss : 0.059592, loss_ce: 0.025066
2021-12-11 19:41:41,561 iteration 870 : loss : 0.068097, loss_ce: 0.022149
2021-12-11 19:41:43,127 iteration 871 : loss : 0.068607, loss_ce: 0.023755
2021-12-11 19:41:44,605 iteration 872 : loss : 0.047402, loss_ce: 0.021205
2021-12-11 19:41:46,091 iteration 873 : loss : 0.050422, loss_ce: 0.018595
2021-12-11 19:41:47,709 iteration 874 : loss : 0.064322, loss_ce: 0.028381
2021-12-11 19:41:49,257 iteration 875 : loss : 0.061343, loss_ce: 0.029259
2021-12-11 19:41:50,785 iteration 876 : loss : 0.077409, loss_ce: 0.034168
2021-12-11 19:41:52,256 iteration 877 : loss : 0.059057, loss_ce: 0.020183
2021-12-11 19:41:53,753 iteration 878 : loss : 0.062689, loss_ce: 0.022468
2021-12-11 19:41:55,301 iteration 879 : loss : 0.063296, loss_ce: 0.022860
2021-12-11 19:41:56,796 iteration 880 : loss : 0.048650, loss_ce: 0.019561
2021-12-11 19:41:58,373 iteration 881 : loss : 0.083395, loss_ce: 0.033969
2021-12-11 19:41:59,886 iteration 882 : loss : 0.061940, loss_ce: 0.027281
2021-12-11 19:42:01,404 iteration 883 : loss : 0.071285, loss_ce: 0.022687
2021-12-11 19:42:03,060 iteration 884 : loss : 0.060781, loss_ce: 0.021654
 13%|███▉                          | 52/400 [24:37<2:42:49, 28.07s/it]2021-12-11 19:42:04,717 iteration 885 : loss : 0.065334, loss_ce: 0.027943
2021-12-11 19:42:06,244 iteration 886 : loss : 0.053241, loss_ce: 0.019771
2021-12-11 19:42:07,772 iteration 887 : loss : 0.072218, loss_ce: 0.035090
2021-12-11 19:42:09,309 iteration 888 : loss : 0.075514, loss_ce: 0.026890
2021-12-11 19:42:10,817 iteration 889 : loss : 0.066631, loss_ce: 0.021483
2021-12-11 19:42:12,406 iteration 890 : loss : 0.073133, loss_ce: 0.038271
2021-12-11 19:42:13,967 iteration 891 : loss : 0.061249, loss_ce: 0.031954
2021-12-11 19:42:15,515 iteration 892 : loss : 0.083793, loss_ce: 0.027261
2021-12-11 19:42:17,137 iteration 893 : loss : 0.086854, loss_ce: 0.037867
2021-12-11 19:42:18,693 iteration 894 : loss : 0.074447, loss_ce: 0.029114
2021-12-11 19:42:20,253 iteration 895 : loss : 0.061331, loss_ce: 0.021312
2021-12-11 19:42:21,850 iteration 896 : loss : 0.070787, loss_ce: 0.021534
2021-12-11 19:42:23,327 iteration 897 : loss : 0.050710, loss_ce: 0.020136
2021-12-11 19:42:24,965 iteration 898 : loss : 0.072433, loss_ce: 0.028133
2021-12-11 19:42:26,491 iteration 899 : loss : 0.060997, loss_ce: 0.023517
2021-12-11 19:42:28,049 iteration 900 : loss : 0.098148, loss_ce: 0.035815
2021-12-11 19:42:29,573 iteration 901 : loss : 0.075668, loss_ce: 0.041087
 13%|███▉                          | 53/400 [25:03<2:39:39, 27.61s/it]2021-12-11 19:42:31,152 iteration 902 : loss : 0.053539, loss_ce: 0.021951
2021-12-11 19:42:32,722 iteration 903 : loss : 0.084050, loss_ce: 0.030974
2021-12-11 19:42:34,224 iteration 904 : loss : 0.071470, loss_ce: 0.034143
2021-12-11 19:42:35,755 iteration 905 : loss : 0.107530, loss_ce: 0.030408
2021-12-11 19:42:37,244 iteration 906 : loss : 0.057497, loss_ce: 0.023303
2021-12-11 19:42:38,824 iteration 907 : loss : 0.047957, loss_ce: 0.023397
2021-12-11 19:42:40,303 iteration 908 : loss : 0.062176, loss_ce: 0.034184
2021-12-11 19:42:41,863 iteration 909 : loss : 0.075714, loss_ce: 0.039237
2021-12-11 19:42:43,417 iteration 910 : loss : 0.079613, loss_ce: 0.026890
2021-12-11 19:42:44,977 iteration 911 : loss : 0.083252, loss_ce: 0.027192
2021-12-11 19:42:46,432 iteration 912 : loss : 0.066625, loss_ce: 0.026036
2021-12-11 19:42:48,010 iteration 913 : loss : 0.072867, loss_ce: 0.029166
2021-12-11 19:42:49,519 iteration 914 : loss : 0.055437, loss_ce: 0.025253
2021-12-11 19:42:51,080 iteration 915 : loss : 0.066898, loss_ce: 0.030822
2021-12-11 19:42:52,635 iteration 916 : loss : 0.059953, loss_ce: 0.021752
2021-12-11 19:42:54,165 iteration 917 : loss : 0.062476, loss_ce: 0.023399
2021-12-11 19:42:55,707 iteration 918 : loss : 0.084233, loss_ce: 0.030944
 14%|████                          | 54/400 [25:29<2:36:38, 27.16s/it]2021-12-11 19:42:57,349 iteration 919 : loss : 0.046124, loss_ce: 0.018277
2021-12-11 19:42:58,831 iteration 920 : loss : 0.111605, loss_ce: 0.079269
2021-12-11 19:43:00,463 iteration 921 : loss : 0.066616, loss_ce: 0.027580
2021-12-11 19:43:01,908 iteration 922 : loss : 0.051632, loss_ce: 0.025273
2021-12-11 19:43:03,393 iteration 923 : loss : 0.046935, loss_ce: 0.018481
2021-12-11 19:43:04,924 iteration 924 : loss : 0.057561, loss_ce: 0.020963
2021-12-11 19:43:06,396 iteration 925 : loss : 0.040647, loss_ce: 0.014466
2021-12-11 19:43:07,874 iteration 926 : loss : 0.066846, loss_ce: 0.020772
2021-12-11 19:43:09,422 iteration 927 : loss : 0.057493, loss_ce: 0.027590
2021-12-11 19:43:10,895 iteration 928 : loss : 0.062014, loss_ce: 0.022938
2021-12-11 19:43:12,580 iteration 929 : loss : 0.094881, loss_ce: 0.042208
2021-12-11 19:43:14,128 iteration 930 : loss : 0.067692, loss_ce: 0.039585
2021-12-11 19:43:15,676 iteration 931 : loss : 0.059952, loss_ce: 0.023449
2021-12-11 19:43:17,224 iteration 932 : loss : 0.075011, loss_ce: 0.023259
2021-12-11 19:43:18,898 iteration 933 : loss : 0.086651, loss_ce: 0.029449
2021-12-11 19:43:20,433 iteration 934 : loss : 0.063339, loss_ce: 0.023187
2021-12-11 19:43:20,433 Training Data Eval:
2021-12-11 19:43:28,099   Average segmentation loss on training set: 0.0440
2021-12-11 19:43:28,099 Validation Data Eval:
2021-12-11 19:43:30,746   Average segmentation loss on validation set: 0.1147
2021-12-11 19:43:32,259 iteration 935 : loss : 0.055820, loss_ce: 0.019046
 14%|████▏                         | 55/400 [26:06<2:52:22, 29.98s/it]2021-12-11 19:43:33,825 iteration 936 : loss : 0.080622, loss_ce: 0.021737
2021-12-11 19:43:35,342 iteration 937 : loss : 0.059722, loss_ce: 0.026074
2021-12-11 19:43:36,959 iteration 938 : loss : 0.061651, loss_ce: 0.030354
2021-12-11 19:43:38,500 iteration 939 : loss : 0.084087, loss_ce: 0.037046
2021-12-11 19:43:40,004 iteration 940 : loss : 0.084449, loss_ce: 0.032909
2021-12-11 19:43:41,569 iteration 941 : loss : 0.075066, loss_ce: 0.023912
2021-12-11 19:43:43,089 iteration 942 : loss : 0.059507, loss_ce: 0.017751
2021-12-11 19:43:44,546 iteration 943 : loss : 0.104924, loss_ce: 0.032082
2021-12-11 19:43:46,048 iteration 944 : loss : 0.048934, loss_ce: 0.018323
2021-12-11 19:43:47,554 iteration 945 : loss : 0.084434, loss_ce: 0.048257
2021-12-11 19:43:49,097 iteration 946 : loss : 0.051468, loss_ce: 0.018162
2021-12-11 19:43:50,739 iteration 947 : loss : 0.065733, loss_ce: 0.029941
2021-12-11 19:43:52,248 iteration 948 : loss : 0.078476, loss_ce: 0.028712
2021-12-11 19:43:53,816 iteration 949 : loss : 0.061191, loss_ce: 0.025693
2021-12-11 19:43:55,418 iteration 950 : loss : 0.104492, loss_ce: 0.028946
2021-12-11 19:43:57,028 iteration 951 : loss : 0.089490, loss_ce: 0.045235
2021-12-11 19:43:58,518 iteration 952 : loss : 0.068014, loss_ce: 0.020704
 14%|████▏                         | 56/400 [26:32<2:45:29, 28.86s/it]2021-12-11 19:44:00,101 iteration 953 : loss : 0.064809, loss_ce: 0.024338
2021-12-11 19:44:01,748 iteration 954 : loss : 0.062763, loss_ce: 0.024333
2021-12-11 19:44:03,271 iteration 955 : loss : 0.037295, loss_ce: 0.015785
2021-12-11 19:44:04,788 iteration 956 : loss : 0.050162, loss_ce: 0.021794
2021-12-11 19:44:06,209 iteration 957 : loss : 0.054342, loss_ce: 0.017321
2021-12-11 19:44:07,718 iteration 958 : loss : 0.061527, loss_ce: 0.020322
2021-12-11 19:44:09,196 iteration 959 : loss : 0.063006, loss_ce: 0.030473
2021-12-11 19:44:10,674 iteration 960 : loss : 0.057904, loss_ce: 0.023453
2021-12-11 19:44:12,215 iteration 961 : loss : 0.078356, loss_ce: 0.031416
2021-12-11 19:44:13,728 iteration 962 : loss : 0.054014, loss_ce: 0.017970
2021-12-11 19:44:15,304 iteration 963 : loss : 0.066485, loss_ce: 0.023184
2021-12-11 19:44:16,866 iteration 964 : loss : 0.065562, loss_ce: 0.023947
2021-12-11 19:44:18,401 iteration 965 : loss : 0.051166, loss_ce: 0.020293
2021-12-11 19:44:20,025 iteration 966 : loss : 0.097481, loss_ce: 0.045560
2021-12-11 19:44:21,557 iteration 967 : loss : 0.102595, loss_ce: 0.038943
2021-12-11 19:44:23,121 iteration 968 : loss : 0.076706, loss_ce: 0.036941
2021-12-11 19:44:24,763 iteration 969 : loss : 0.050443, loss_ce: 0.018152
 14%|████▎                         | 57/400 [26:58<2:40:30, 28.08s/it]2021-12-11 19:44:26,329 iteration 970 : loss : 0.071042, loss_ce: 0.031525
2021-12-11 19:44:27,948 iteration 971 : loss : 0.085777, loss_ce: 0.028587
2021-12-11 19:44:29,429 iteration 972 : loss : 0.053560, loss_ce: 0.020734
2021-12-11 19:44:30,912 iteration 973 : loss : 0.050365, loss_ce: 0.019193
2021-12-11 19:44:32,439 iteration 974 : loss : 0.055037, loss_ce: 0.020628
2021-12-11 19:44:33,933 iteration 975 : loss : 0.082300, loss_ce: 0.026128
2021-12-11 19:44:35,432 iteration 976 : loss : 0.085092, loss_ce: 0.028737
2021-12-11 19:44:37,029 iteration 977 : loss : 0.081515, loss_ce: 0.030194
2021-12-11 19:44:38,607 iteration 978 : loss : 0.068001, loss_ce: 0.030727
2021-12-11 19:44:40,182 iteration 979 : loss : 0.061195, loss_ce: 0.029117
2021-12-11 19:44:41,701 iteration 980 : loss : 0.063725, loss_ce: 0.023225
2021-12-11 19:44:43,294 iteration 981 : loss : 0.077992, loss_ce: 0.030803
2021-12-11 19:44:44,771 iteration 982 : loss : 0.068519, loss_ce: 0.038500
2021-12-11 19:44:46,327 iteration 983 : loss : 0.069258, loss_ce: 0.029733
2021-12-11 19:44:47,878 iteration 984 : loss : 0.053089, loss_ce: 0.025078
2021-12-11 19:44:49,403 iteration 985 : loss : 0.091452, loss_ce: 0.034294
2021-12-11 19:44:50,933 iteration 986 : loss : 0.073875, loss_ce: 0.024518
 14%|████▎                         | 58/400 [27:25<2:36:46, 27.50s/it]2021-12-11 19:44:52,512 iteration 987 : loss : 0.048819, loss_ce: 0.021884
2021-12-11 19:44:54,122 iteration 988 : loss : 0.074159, loss_ce: 0.030163
2021-12-11 19:44:55,628 iteration 989 : loss : 0.066477, loss_ce: 0.023690
2021-12-11 19:44:57,223 iteration 990 : loss : 0.061452, loss_ce: 0.034458
2021-12-11 19:44:58,805 iteration 991 : loss : 0.061759, loss_ce: 0.030931
2021-12-11 19:45:00,287 iteration 992 : loss : 0.066316, loss_ce: 0.022188
2021-12-11 19:45:01,950 iteration 993 : loss : 0.059676, loss_ce: 0.027846
2021-12-11 19:45:03,549 iteration 994 : loss : 0.072329, loss_ce: 0.022759
2021-12-11 19:45:05,114 iteration 995 : loss : 0.066137, loss_ce: 0.025589
2021-12-11 19:45:06,625 iteration 996 : loss : 0.044996, loss_ce: 0.017835
2021-12-11 19:45:08,204 iteration 997 : loss : 0.069469, loss_ce: 0.031680
2021-12-11 19:45:09,747 iteration 998 : loss : 0.064157, loss_ce: 0.025066
2021-12-11 19:45:11,412 iteration 999 : loss : 0.057638, loss_ce: 0.023798
2021-12-11 19:45:13,010 iteration 1000 : loss : 0.064705, loss_ce: 0.030076
2021-12-11 19:45:14,575 iteration 1001 : loss : 0.060631, loss_ce: 0.024230
2021-12-11 19:45:16,057 iteration 1002 : loss : 0.047178, loss_ce: 0.014738
2021-12-11 19:45:17,572 iteration 1003 : loss : 0.068196, loss_ce: 0.028066
 15%|████▍                         | 59/400 [27:51<2:34:51, 27.25s/it]2021-12-11 19:45:19,129 iteration 1004 : loss : 0.092197, loss_ce: 0.040128
2021-12-11 19:45:20,765 iteration 1005 : loss : 0.120102, loss_ce: 0.043418
2021-12-11 19:45:22,318 iteration 1006 : loss : 0.069402, loss_ce: 0.032383
2021-12-11 19:45:23,887 iteration 1007 : loss : 0.060814, loss_ce: 0.026493
2021-12-11 19:45:25,447 iteration 1008 : loss : 0.073618, loss_ce: 0.024981
2021-12-11 19:45:27,016 iteration 1009 : loss : 0.074714, loss_ce: 0.028698
2021-12-11 19:45:28,516 iteration 1010 : loss : 0.075898, loss_ce: 0.034065
2021-12-11 19:45:30,049 iteration 1011 : loss : 0.044465, loss_ce: 0.017714
2021-12-11 19:45:31,672 iteration 1012 : loss : 0.094637, loss_ce: 0.028598
2021-12-11 19:45:33,189 iteration 1013 : loss : 0.087985, loss_ce: 0.026983
2021-12-11 19:45:34,766 iteration 1014 : loss : 0.044309, loss_ce: 0.015789
2021-12-11 19:45:36,291 iteration 1015 : loss : 0.086626, loss_ce: 0.036839
2021-12-11 19:45:37,746 iteration 1016 : loss : 0.056934, loss_ce: 0.028651
2021-12-11 19:45:39,383 iteration 1017 : loss : 0.075228, loss_ce: 0.024281
2021-12-11 19:45:40,993 iteration 1018 : loss : 0.056139, loss_ce: 0.024348
2021-12-11 19:45:42,650 iteration 1019 : loss : 0.056122, loss_ce: 0.022514
2021-12-11 19:45:42,650 Training Data Eval:
2021-12-11 19:45:50,291   Average segmentation loss on training set: 0.0513
2021-12-11 19:45:50,291 Validation Data Eval:
2021-12-11 19:45:52,936   Average segmentation loss on validation set: 0.1006
2021-12-11 19:45:54,906 Found new lowest validation loss at iteration 1019! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/NEW_TU/UNET_ADAM_best_val_loss_seed100.pth
2021-12-11 19:45:56,419 iteration 1020 : loss : 0.059116, loss_ce: 0.025206
 15%|████▌                         | 60/400 [28:30<2:54:07, 30.73s/it]2021-12-11 19:45:57,994 iteration 1021 : loss : 0.071758, loss_ce: 0.027348
2021-12-11 19:45:59,443 iteration 1022 : loss : 0.066368, loss_ce: 0.022594
2021-12-11 19:46:00,952 iteration 1023 : loss : 0.096424, loss_ce: 0.033625
2021-12-11 19:46:02,509 iteration 1024 : loss : 0.041405, loss_ce: 0.019183
2021-12-11 19:46:04,013 iteration 1025 : loss : 0.075950, loss_ce: 0.033770
2021-12-11 19:46:05,581 iteration 1026 : loss : 0.076703, loss_ce: 0.027326
2021-12-11 19:46:07,123 iteration 1027 : loss : 0.064788, loss_ce: 0.032369
2021-12-11 19:46:08,625 iteration 1028 : loss : 0.072861, loss_ce: 0.021508
2021-12-11 19:46:10,193 iteration 1029 : loss : 0.088481, loss_ce: 0.026794
2021-12-11 19:46:11,758 iteration 1030 : loss : 0.068977, loss_ce: 0.027233
2021-12-11 19:46:13,380 iteration 1031 : loss : 0.054651, loss_ce: 0.022537
2021-12-11 19:46:14,865 iteration 1032 : loss : 0.043401, loss_ce: 0.016921
2021-12-11 19:46:16,469 iteration 1033 : loss : 0.070285, loss_ce: 0.030034
2021-12-11 19:46:18,085 iteration 1034 : loss : 0.068405, loss_ce: 0.034452
2021-12-11 19:46:19,671 iteration 1035 : loss : 0.092683, loss_ce: 0.036056
2021-12-11 19:46:21,300 iteration 1036 : loss : 0.077053, loss_ce: 0.035247
2021-12-11 19:46:22,728 iteration 1037 : loss : 0.053203, loss_ce: 0.020891
 15%|████▌                         | 61/400 [28:56<2:46:07, 29.40s/it]2021-12-11 19:46:24,246 iteration 1038 : loss : 0.045286, loss_ce: 0.019429
2021-12-11 19:46:25,791 iteration 1039 : loss : 0.055610, loss_ce: 0.021311
2021-12-11 19:46:27,267 iteration 1040 : loss : 0.055264, loss_ce: 0.019726
2021-12-11 19:46:28,879 iteration 1041 : loss : 0.061767, loss_ce: 0.025803
2021-12-11 19:46:30,524 iteration 1042 : loss : 0.070690, loss_ce: 0.028770
2021-12-11 19:46:32,019 iteration 1043 : loss : 0.060695, loss_ce: 0.024036
2021-12-11 19:46:33,556 iteration 1044 : loss : 0.068561, loss_ce: 0.027261
2021-12-11 19:46:35,065 iteration 1045 : loss : 0.058501, loss_ce: 0.031601
2021-12-11 19:46:36,620 iteration 1046 : loss : 0.084933, loss_ce: 0.032870
2021-12-11 19:46:38,239 iteration 1047 : loss : 0.051750, loss_ce: 0.023062
2021-12-11 19:46:39,789 iteration 1048 : loss : 0.076023, loss_ce: 0.032594
2021-12-11 19:46:41,278 iteration 1049 : loss : 0.058717, loss_ce: 0.022571
2021-12-11 19:46:42,781 iteration 1050 : loss : 0.045407, loss_ce: 0.020659
2021-12-11 19:46:44,333 iteration 1051 : loss : 0.062286, loss_ce: 0.023115
2021-12-11 19:46:45,877 iteration 1052 : loss : 0.064460, loss_ce: 0.026719
2021-12-11 19:46:47,550 iteration 1053 : loss : 0.068611, loss_ce: 0.028439
2021-12-11 19:46:49,066 iteration 1054 : loss : 0.049182, loss_ce: 0.018867
 16%|████▋                         | 62/400 [29:23<2:40:26, 28.48s/it]2021-12-11 19:46:50,644 iteration 1055 : loss : 0.054599, loss_ce: 0.020803
2021-12-11 19:46:52,192 iteration 1056 : loss : 0.095327, loss_ce: 0.050614
2021-12-11 19:46:53,776 iteration 1057 : loss : 0.071412, loss_ce: 0.019250
2021-12-11 19:46:55,258 iteration 1058 : loss : 0.059893, loss_ce: 0.027487
2021-12-11 19:46:56,874 iteration 1059 : loss : 0.064480, loss_ce: 0.027880
2021-12-11 19:46:58,404 iteration 1060 : loss : 0.052019, loss_ce: 0.025965
2021-12-11 19:46:59,999 iteration 1061 : loss : 0.046111, loss_ce: 0.017454
2021-12-11 19:47:01,563 iteration 1062 : loss : 0.052020, loss_ce: 0.019868
2021-12-11 19:47:03,173 iteration 1063 : loss : 0.062260, loss_ce: 0.021545
2021-12-11 19:47:04,696 iteration 1064 : loss : 0.051338, loss_ce: 0.024704
2021-12-11 19:47:06,170 iteration 1065 : loss : 0.061685, loss_ce: 0.024613
2021-12-11 19:47:07,725 iteration 1066 : loss : 0.050892, loss_ce: 0.022070
2021-12-11 19:47:09,404 iteration 1067 : loss : 0.058367, loss_ce: 0.022109
2021-12-11 19:47:11,009 iteration 1068 : loss : 0.087885, loss_ce: 0.035755
2021-12-11 19:47:12,508 iteration 1069 : loss : 0.049684, loss_ce: 0.022240
2021-12-11 19:47:14,150 iteration 1070 : loss : 0.056069, loss_ce: 0.019358
2021-12-11 19:47:15,688 iteration 1071 : loss : 0.066141, loss_ce: 0.028225
 16%|████▋                         | 63/400 [29:49<2:36:50, 27.92s/it]2021-12-11 19:47:17,235 iteration 1072 : loss : 0.043568, loss_ce: 0.017848
2021-12-11 19:47:18,893 iteration 1073 : loss : 0.066371, loss_ce: 0.024295
2021-12-11 19:47:20,409 iteration 1074 : loss : 0.039960, loss_ce: 0.019271
2021-12-11 19:47:21,965 iteration 1075 : loss : 0.049091, loss_ce: 0.020565
2021-12-11 19:47:23,465 iteration 1076 : loss : 0.069250, loss_ce: 0.028749
2021-12-11 19:47:25,048 iteration 1077 : loss : 0.086061, loss_ce: 0.029317
2021-12-11 19:47:26,536 iteration 1078 : loss : 0.055451, loss_ce: 0.020955
2021-12-11 19:47:28,087 iteration 1079 : loss : 0.050892, loss_ce: 0.021781
2021-12-11 19:47:29,659 iteration 1080 : loss : 0.070324, loss_ce: 0.029819
2021-12-11 19:47:31,224 iteration 1081 : loss : 0.049395, loss_ce: 0.021588
2021-12-11 19:47:32,781 iteration 1082 : loss : 0.071470, loss_ce: 0.030766
2021-12-11 19:47:34,327 iteration 1083 : loss : 0.069790, loss_ce: 0.026373
2021-12-11 19:47:35,919 iteration 1084 : loss : 0.097229, loss_ce: 0.025045
2021-12-11 19:47:37,454 iteration 1085 : loss : 0.073824, loss_ce: 0.024371
2021-12-11 19:47:39,029 iteration 1086 : loss : 0.053135, loss_ce: 0.019920
2021-12-11 19:47:40,507 iteration 1087 : loss : 0.048474, loss_ce: 0.018867
2021-12-11 19:47:42,029 iteration 1088 : loss : 0.065396, loss_ce: 0.032196
 16%|████▊                         | 64/400 [30:16<2:33:43, 27.45s/it]2021-12-11 19:47:43,500 iteration 1089 : loss : 0.047642, loss_ce: 0.020634
2021-12-11 19:47:45,050 iteration 1090 : loss : 0.070390, loss_ce: 0.023772
2021-12-11 19:47:46,634 iteration 1091 : loss : 0.073374, loss_ce: 0.036446
2021-12-11 19:47:48,244 iteration 1092 : loss : 0.067317, loss_ce: 0.021226
2021-12-11 19:47:49,822 iteration 1093 : loss : 0.064691, loss_ce: 0.018996
2021-12-11 19:47:51,471 iteration 1094 : loss : 0.133914, loss_ce: 0.033763
2021-12-11 19:47:52,951 iteration 1095 : loss : 0.065510, loss_ce: 0.025624
2021-12-11 19:47:54,453 iteration 1096 : loss : 0.045506, loss_ce: 0.020430
2021-12-11 19:47:55,934 iteration 1097 : loss : 0.055776, loss_ce: 0.021821
2021-12-11 19:47:57,528 iteration 1098 : loss : 0.078728, loss_ce: 0.040079
2021-12-11 19:47:59,070 iteration 1099 : loss : 0.062910, loss_ce: 0.023919
2021-12-11 19:48:00,668 iteration 1100 : loss : 0.073829, loss_ce: 0.034144
2021-12-11 19:48:02,283 iteration 1101 : loss : 0.066513, loss_ce: 0.027779
2021-12-11 19:48:03,818 iteration 1102 : loss : 0.080322, loss_ce: 0.033039
2021-12-11 19:48:05,375 iteration 1103 : loss : 0.043380, loss_ce: 0.018721
2021-12-11 19:48:06,939 iteration 1104 : loss : 0.053464, loss_ce: 0.022955
2021-12-11 19:48:06,940 Training Data Eval:
2021-12-11 19:48:14,586   Average segmentation loss on training set: 0.0529
2021-12-11 19:48:14,587 Validation Data Eval:
2021-12-11 19:48:17,224   Average segmentation loss on validation set: 0.0842
2021-12-11 19:48:19,155 Found new lowest validation loss at iteration 1104! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/NEW_TU/UNET_ADAM_best_val_loss_seed100.pth
2021-12-11 19:48:20,598 iteration 1105 : loss : 0.052918, loss_ce: 0.022790
 16%|████▉                         | 65/400 [30:54<2:51:53, 30.79s/it]2021-12-11 19:48:22,125 iteration 1106 : loss : 0.059167, loss_ce: 0.019945
2021-12-11 19:48:23,583 iteration 1107 : loss : 0.052183, loss_ce: 0.019939
2021-12-11 19:48:25,044 iteration 1108 : loss : 0.052910, loss_ce: 0.017652
2021-12-11 19:48:26,659 iteration 1109 : loss : 0.064409, loss_ce: 0.025242
2021-12-11 19:48:28,193 iteration 1110 : loss : 0.047680, loss_ce: 0.019856
2021-12-11 19:48:29,827 iteration 1111 : loss : 0.095428, loss_ce: 0.032478
2021-12-11 19:48:31,330 iteration 1112 : loss : 0.050633, loss_ce: 0.021138
2021-12-11 19:48:32,873 iteration 1113 : loss : 0.060598, loss_ce: 0.019486
2021-12-11 19:48:34,435 iteration 1114 : loss : 0.060080, loss_ce: 0.020865
2021-12-11 19:48:36,044 iteration 1115 : loss : 0.037250, loss_ce: 0.014789
2021-12-11 19:48:37,506 iteration 1116 : loss : 0.056938, loss_ce: 0.025614
2021-12-11 19:48:38,998 iteration 1117 : loss : 0.049406, loss_ce: 0.020512
2021-12-11 19:48:40,570 iteration 1118 : loss : 0.065315, loss_ce: 0.026505
2021-12-11 19:48:42,146 iteration 1119 : loss : 0.056701, loss_ce: 0.025099
2021-12-11 19:48:43,686 iteration 1120 : loss : 0.043479, loss_ce: 0.014475
2021-12-11 19:48:45,208 iteration 1121 : loss : 0.043661, loss_ce: 0.020049
2021-12-11 19:48:46,682 iteration 1122 : loss : 0.053099, loss_ce: 0.017678
 16%|████▉                         | 66/400 [31:20<2:43:31, 29.37s/it]2021-12-11 19:48:48,346 iteration 1123 : loss : 0.035937, loss_ce: 0.014028
2021-12-11 19:48:49,887 iteration 1124 : loss : 0.044421, loss_ce: 0.020708
2021-12-11 19:48:51,395 iteration 1125 : loss : 0.060647, loss_ce: 0.019737
2021-12-11 19:48:52,949 iteration 1126 : loss : 0.045165, loss_ce: 0.015281
2021-12-11 19:48:54,461 iteration 1127 : loss : 0.044511, loss_ce: 0.017092
2021-12-11 19:48:56,079 iteration 1128 : loss : 0.055737, loss_ce: 0.024280
2021-12-11 19:48:57,717 iteration 1129 : loss : 0.066755, loss_ce: 0.025435
2021-12-11 19:48:59,206 iteration 1130 : loss : 0.050854, loss_ce: 0.020509
2021-12-11 19:49:00,801 iteration 1131 : loss : 0.063875, loss_ce: 0.026884
2021-12-11 19:49:02,440 iteration 1132 : loss : 0.053975, loss_ce: 0.019045
2021-12-11 19:49:04,060 iteration 1133 : loss : 0.057861, loss_ce: 0.025955
2021-12-11 19:49:05,667 iteration 1134 : loss : 0.087268, loss_ce: 0.027386
2021-12-11 19:49:07,198 iteration 1135 : loss : 0.105655, loss_ce: 0.037088
2021-12-11 19:49:08,711 iteration 1136 : loss : 0.036969, loss_ce: 0.016959
2021-12-11 19:49:10,238 iteration 1137 : loss : 0.083478, loss_ce: 0.041613
2021-12-11 19:49:11,807 iteration 1138 : loss : 0.068704, loss_ce: 0.026334
2021-12-11 19:49:13,291 iteration 1139 : loss : 0.055021, loss_ce: 0.022300
 17%|█████                         | 67/400 [31:47<2:38:25, 28.55s/it]2021-12-11 19:49:14,866 iteration 1140 : loss : 0.052898, loss_ce: 0.021148
2021-12-11 19:49:16,430 iteration 1141 : loss : 0.067107, loss_ce: 0.029501
2021-12-11 19:49:18,090 iteration 1142 : loss : 0.055804, loss_ce: 0.023575
2021-12-11 19:49:19,644 iteration 1143 : loss : 0.051547, loss_ce: 0.021137
2021-12-11 19:49:21,208 iteration 1144 : loss : 0.074485, loss_ce: 0.022041
2021-12-11 19:49:22,795 iteration 1145 : loss : 0.071187, loss_ce: 0.030814
2021-12-11 19:49:24,312 iteration 1146 : loss : 0.046014, loss_ce: 0.019701
2021-12-11 19:49:25,840 iteration 1147 : loss : 0.044028, loss_ce: 0.018191
2021-12-11 19:49:27,348 iteration 1148 : loss : 0.047831, loss_ce: 0.018564
2021-12-11 19:49:28,891 iteration 1149 : loss : 0.043589, loss_ce: 0.020683
2021-12-11 19:49:30,392 iteration 1150 : loss : 0.049451, loss_ce: 0.020119
2021-12-11 19:49:31,918 iteration 1151 : loss : 0.036321, loss_ce: 0.016144
2021-12-11 19:49:33,420 iteration 1152 : loss : 0.065627, loss_ce: 0.026996
2021-12-11 19:49:35,046 iteration 1153 : loss : 0.076336, loss_ce: 0.023927
2021-12-11 19:49:36,625 iteration 1154 : loss : 0.046521, loss_ce: 0.015279
2021-12-11 19:49:38,222 iteration 1155 : loss : 0.051706, loss_ce: 0.017119
2021-12-11 19:49:39,869 iteration 1156 : loss : 0.086974, loss_ce: 0.026677
 17%|█████                         | 68/400 [32:13<2:34:40, 27.95s/it]2021-12-11 19:49:41,516 iteration 1157 : loss : 0.071162, loss_ce: 0.026767
2021-12-11 19:49:43,038 iteration 1158 : loss : 0.043137, loss_ce: 0.016434
2021-12-11 19:49:44,479 iteration 1159 : loss : 0.042038, loss_ce: 0.015658
2021-12-11 19:49:45,979 iteration 1160 : loss : 0.069665, loss_ce: 0.035627
2021-12-11 19:49:47,541 iteration 1161 : loss : 0.077642, loss_ce: 0.026832
2021-12-11 19:49:49,103 iteration 1162 : loss : 0.054906, loss_ce: 0.022936
2021-12-11 19:49:50,642 iteration 1163 : loss : 0.056250, loss_ce: 0.026607
2021-12-11 19:49:52,241 iteration 1164 : loss : 0.070403, loss_ce: 0.030120
2021-12-11 19:49:53,703 iteration 1165 : loss : 0.052305, loss_ce: 0.022850
2021-12-11 19:49:55,189 iteration 1166 : loss : 0.061722, loss_ce: 0.021137
2021-12-11 19:49:56,741 iteration 1167 : loss : 0.065466, loss_ce: 0.031563
2021-12-11 19:49:58,352 iteration 1168 : loss : 0.099495, loss_ce: 0.028605
2021-12-11 19:49:59,840 iteration 1169 : loss : 0.073063, loss_ce: 0.021698
2021-12-11 19:50:01,396 iteration 1170 : loss : 0.066772, loss_ce: 0.022650
2021-12-11 19:50:03,075 iteration 1171 : loss : 0.119155, loss_ce: 0.036627
2021-12-11 19:50:04,553 iteration 1172 : loss : 0.057939, loss_ce: 0.020508
2021-12-11 19:50:06,024 iteration 1173 : loss : 0.036000, loss_ce: 0.013630
 17%|█████▏                        | 69/400 [32:40<2:31:14, 27.42s/it]2021-12-11 19:50:07,627 iteration 1174 : loss : 0.054709, loss_ce: 0.021141
2021-12-11 19:50:09,238 iteration 1175 : loss : 0.087694, loss_ce: 0.037833
2021-12-11 19:50:10,790 iteration 1176 : loss : 0.074491, loss_ce: 0.025722
2021-12-11 19:50:12,311 iteration 1177 : loss : 0.065021, loss_ce: 0.027527
2021-12-11 19:50:13,780 iteration 1178 : loss : 0.078982, loss_ce: 0.029621
2021-12-11 19:50:15,376 iteration 1179 : loss : 0.051159, loss_ce: 0.020625
2021-12-11 19:50:16,947 iteration 1180 : loss : 0.056339, loss_ce: 0.021568
2021-12-11 19:50:18,432 iteration 1181 : loss : 0.065811, loss_ce: 0.020423
2021-12-11 19:50:19,935 iteration 1182 : loss : 0.041299, loss_ce: 0.016761
2021-12-11 19:50:21,462 iteration 1183 : loss : 0.042819, loss_ce: 0.018444
2021-12-11 19:50:23,009 iteration 1184 : loss : 0.074029, loss_ce: 0.029530
2021-12-11 19:50:24,536 iteration 1185 : loss : 0.057322, loss_ce: 0.030776
2021-12-11 19:50:26,087 iteration 1186 : loss : 0.059974, loss_ce: 0.018930
2021-12-11 19:50:27,584 iteration 1187 : loss : 0.039724, loss_ce: 0.017116
2021-12-11 19:50:29,157 iteration 1188 : loss : 0.086872, loss_ce: 0.033122
2021-12-11 19:50:30,746 iteration 1189 : loss : 0.088630, loss_ce: 0.019648
2021-12-11 19:50:30,747 Training Data Eval:
2021-12-11 19:50:38,360   Average segmentation loss on training set: 0.0456
2021-12-11 19:50:38,360 Validation Data Eval:
2021-12-11 19:50:40,994   Average segmentation loss on validation set: 0.0794
2021-12-11 19:50:43,086 Found new lowest validation loss at iteration 1189! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/NEW_TU/UNET_ADAM_best_val_loss_seed100.pth
2021-12-11 19:50:44,500 iteration 1190 : loss : 0.053760, loss_ce: 0.017973
 18%|█████▎                        | 70/400 [33:18<2:49:01, 30.73s/it]2021-12-11 19:50:45,983 iteration 1191 : loss : 0.049807, loss_ce: 0.016674
2021-12-11 19:50:47,421 iteration 1192 : loss : 0.076061, loss_ce: 0.041540
2021-12-11 19:50:48,844 iteration 1193 : loss : 0.050252, loss_ce: 0.019259
2021-12-11 19:50:50,384 iteration 1194 : loss : 0.076177, loss_ce: 0.027044
2021-12-11 19:50:51,910 iteration 1195 : loss : 0.062333, loss_ce: 0.027621
2021-12-11 19:50:53,467 iteration 1196 : loss : 0.043725, loss_ce: 0.018903
2021-12-11 19:50:55,045 iteration 1197 : loss : 0.067083, loss_ce: 0.021370
2021-12-11 19:50:56,514 iteration 1198 : loss : 0.037599, loss_ce: 0.013854
2021-12-11 19:50:58,029 iteration 1199 : loss : 0.061629, loss_ce: 0.031257
2021-12-11 19:50:59,492 iteration 1200 : loss : 0.049387, loss_ce: 0.018661
2021-12-11 19:51:00,997 iteration 1201 : loss : 0.055355, loss_ce: 0.018882
2021-12-11 19:51:02,590 iteration 1202 : loss : 0.055863, loss_ce: 0.023433
2021-12-11 19:51:04,177 iteration 1203 : loss : 0.052657, loss_ce: 0.022862
2021-12-11 19:51:05,639 iteration 1204 : loss : 0.052006, loss_ce: 0.016612
2021-12-11 19:51:07,213 iteration 1205 : loss : 0.042101, loss_ce: 0.019366
2021-12-11 19:51:08,707 iteration 1206 : loss : 0.060885, loss_ce: 0.022285
2021-12-11 19:51:10,306 iteration 1207 : loss : 0.048296, loss_ce: 0.020634
 18%|█████▎                        | 71/400 [33:44<2:40:24, 29.25s/it]2021-12-11 19:51:11,856 iteration 1208 : loss : 0.067118, loss_ce: 0.025659
2021-12-11 19:51:13,444 iteration 1209 : loss : 0.051417, loss_ce: 0.019388
2021-12-11 19:51:14,915 iteration 1210 : loss : 0.042358, loss_ce: 0.016197
2021-12-11 19:51:16,514 iteration 1211 : loss : 0.081655, loss_ce: 0.036672
2021-12-11 19:51:18,042 iteration 1212 : loss : 0.038932, loss_ce: 0.015608
2021-12-11 19:51:19,484 iteration 1213 : loss : 0.036869, loss_ce: 0.013683
2021-12-11 19:51:21,098 iteration 1214 : loss : 0.068861, loss_ce: 0.031074
2021-12-11 19:51:22,620 iteration 1215 : loss : 0.039621, loss_ce: 0.017025
2021-12-11 19:51:24,155 iteration 1216 : loss : 0.047466, loss_ce: 0.015992
2021-12-11 19:51:25,821 iteration 1217 : loss : 0.078906, loss_ce: 0.032376
2021-12-11 19:51:27,300 iteration 1218 : loss : 0.047626, loss_ce: 0.022527
2021-12-11 19:51:28,959 iteration 1219 : loss : 0.071378, loss_ce: 0.035768
2021-12-11 19:51:30,537 iteration 1220 : loss : 0.045510, loss_ce: 0.017937
2021-12-11 19:51:32,142 iteration 1221 : loss : 0.055561, loss_ce: 0.019853
2021-12-11 19:51:33,660 iteration 1222 : loss : 0.056417, loss_ce: 0.022560
2021-12-11 19:51:35,163 iteration 1223 : loss : 0.050924, loss_ce: 0.017522
2021-12-11 19:51:36,686 iteration 1224 : loss : 0.067897, loss_ce: 0.022662
 18%|█████▍                        | 72/400 [34:10<2:35:12, 28.39s/it]2021-12-11 19:51:38,253 iteration 1225 : loss : 0.046475, loss_ce: 0.014438
2021-12-11 19:51:39,811 iteration 1226 : loss : 0.044508, loss_ce: 0.014815
2021-12-11 19:51:41,301 iteration 1227 : loss : 0.046620, loss_ce: 0.017380
2021-12-11 19:51:42,808 iteration 1228 : loss : 0.095317, loss_ce: 0.037191
2021-12-11 19:51:44,468 iteration 1229 : loss : 0.078692, loss_ce: 0.038366
2021-12-11 19:51:46,049 iteration 1230 : loss : 0.049559, loss_ce: 0.019307
2021-12-11 19:51:47,609 iteration 1231 : loss : 0.045253, loss_ce: 0.017307
2021-12-11 19:51:49,112 iteration 1232 : loss : 0.055900, loss_ce: 0.022218
2021-12-11 19:51:50,712 iteration 1233 : loss : 0.037082, loss_ce: 0.013595
2021-12-11 19:51:52,361 iteration 1234 : loss : 0.063773, loss_ce: 0.025582
2021-12-11 19:51:53,820 iteration 1235 : loss : 0.048990, loss_ce: 0.018409
2021-12-11 19:51:55,401 iteration 1236 : loss : 0.076894, loss_ce: 0.036436
2021-12-11 19:51:56,937 iteration 1237 : loss : 0.073277, loss_ce: 0.020893
2021-12-11 19:51:58,423 iteration 1238 : loss : 0.051742, loss_ce: 0.021811
2021-12-11 19:51:59,987 iteration 1239 : loss : 0.041540, loss_ce: 0.018415
2021-12-11 19:52:01,621 iteration 1240 : loss : 0.068040, loss_ce: 0.025944
2021-12-11 19:52:03,153 iteration 1241 : loss : 0.058026, loss_ce: 0.026103
 18%|█████▍                        | 73/400 [34:37<2:31:36, 27.82s/it]2021-12-11 19:52:04,770 iteration 1242 : loss : 0.054702, loss_ce: 0.028911
2021-12-11 19:52:06,304 iteration 1243 : loss : 0.056650, loss_ce: 0.022588
2021-12-11 19:52:07,930 iteration 1244 : loss : 0.062523, loss_ce: 0.024094
2021-12-11 19:52:09,534 iteration 1245 : loss : 0.070028, loss_ce: 0.024066
2021-12-11 19:52:11,067 iteration 1246 : loss : 0.052266, loss_ce: 0.021664
2021-12-11 19:52:12,770 iteration 1247 : loss : 0.089388, loss_ce: 0.029387
2021-12-11 19:52:14,273 iteration 1248 : loss : 0.040730, loss_ce: 0.017739
2021-12-11 19:52:15,817 iteration 1249 : loss : 0.068202, loss_ce: 0.031489
2021-12-11 19:52:17,361 iteration 1250 : loss : 0.088308, loss_ce: 0.019277
2021-12-11 19:52:18,978 iteration 1251 : loss : 0.048711, loss_ce: 0.021695
2021-12-11 19:52:20,466 iteration 1252 : loss : 0.079129, loss_ce: 0.025905
2021-12-11 19:52:21,988 iteration 1253 : loss : 0.075669, loss_ce: 0.031541
2021-12-11 19:52:23,520 iteration 1254 : loss : 0.051883, loss_ce: 0.016914
2021-12-11 19:52:25,172 iteration 1255 : loss : 0.065326, loss_ce: 0.024634
2021-12-11 19:52:26,698 iteration 1256 : loss : 0.051112, loss_ce: 0.019220
2021-12-11 19:52:28,148 iteration 1257 : loss : 0.049877, loss_ce: 0.018505
2021-12-11 19:52:29,597 iteration 1258 : loss : 0.041962, loss_ce: 0.020594
 18%|█████▌                        | 74/400 [35:03<2:28:53, 27.40s/it]2021-12-11 19:52:31,173 iteration 1259 : loss : 0.046584, loss_ce: 0.018252
2021-12-11 19:52:32,811 iteration 1260 : loss : 0.045314, loss_ce: 0.018258
2021-12-11 19:52:34,330 iteration 1261 : loss : 0.055556, loss_ce: 0.019307
2021-12-11 19:52:35,809 iteration 1262 : loss : 0.038443, loss_ce: 0.014067
2021-12-11 19:52:37,341 iteration 1263 : loss : 0.047285, loss_ce: 0.017173
2021-12-11 19:52:38,891 iteration 1264 : loss : 0.053243, loss_ce: 0.021398
2021-12-11 19:52:40,431 iteration 1265 : loss : 0.052166, loss_ce: 0.016421
2021-12-11 19:52:41,935 iteration 1266 : loss : 0.041279, loss_ce: 0.017235
2021-12-11 19:52:43,422 iteration 1267 : loss : 0.080403, loss_ce: 0.034750
2021-12-11 19:52:44,923 iteration 1268 : loss : 0.048131, loss_ce: 0.019213
2021-12-11 19:52:46,434 iteration 1269 : loss : 0.059308, loss_ce: 0.028034
2021-12-11 19:52:48,014 iteration 1270 : loss : 0.040555, loss_ce: 0.015558
2021-12-11 19:52:49,632 iteration 1271 : loss : 0.070898, loss_ce: 0.032972
2021-12-11 19:52:51,069 iteration 1272 : loss : 0.043314, loss_ce: 0.013984
2021-12-11 19:52:52,568 iteration 1273 : loss : 0.055336, loss_ce: 0.017815
2021-12-11 19:52:54,134 iteration 1274 : loss : 0.061307, loss_ce: 0.025028
2021-12-11 19:52:54,134 Training Data Eval:
2021-12-11 19:53:01,791   Average segmentation loss on training set: 0.0501
2021-12-11 19:53:01,791 Validation Data Eval:
2021-12-11 19:53:04,431   Average segmentation loss on validation set: 0.0890
2021-12-11 19:53:05,934 iteration 1275 : loss : 0.057652, loss_ce: 0.024502
 19%|█████▋                        | 75/400 [35:40<2:42:57, 30.09s/it]2021-12-11 19:53:07,496 iteration 1276 : loss : 0.041054, loss_ce: 0.016963
2021-12-11 19:53:09,158 iteration 1277 : loss : 0.063025, loss_ce: 0.026594
2021-12-11 19:53:10,707 iteration 1278 : loss : 0.064400, loss_ce: 0.026615
2021-12-11 19:53:12,225 iteration 1279 : loss : 0.058485, loss_ce: 0.021804
2021-12-11 19:53:13,796 iteration 1280 : loss : 0.046516, loss_ce: 0.021676
2021-12-11 19:53:15,290 iteration 1281 : loss : 0.055182, loss_ce: 0.022083
2021-12-11 19:53:16,825 iteration 1282 : loss : 0.037754, loss_ce: 0.014108
2021-12-11 19:53:18,280 iteration 1283 : loss : 0.062518, loss_ce: 0.018210
2021-12-11 19:53:19,788 iteration 1284 : loss : 0.036727, loss_ce: 0.015073
2021-12-11 19:53:21,303 iteration 1285 : loss : 0.043864, loss_ce: 0.014504
2021-12-11 19:53:22,881 iteration 1286 : loss : 0.072263, loss_ce: 0.033332
2021-12-11 19:53:24,466 iteration 1287 : loss : 0.046095, loss_ce: 0.019285
2021-12-11 19:53:25,964 iteration 1288 : loss : 0.046710, loss_ce: 0.018095
2021-12-11 19:53:27,502 iteration 1289 : loss : 0.047173, loss_ce: 0.017851
2021-12-11 19:53:29,000 iteration 1290 : loss : 0.064372, loss_ce: 0.024889
2021-12-11 19:53:30,494 iteration 1291 : loss : 0.046333, loss_ce: 0.017712
2021-12-11 19:53:31,982 iteration 1292 : loss : 0.070645, loss_ce: 0.040764
 19%|█████▋                        | 76/400 [36:06<2:35:54, 28.87s/it]2021-12-11 19:53:33,655 iteration 1293 : loss : 0.056165, loss_ce: 0.026620
2021-12-11 19:53:35,120 iteration 1294 : loss : 0.038764, loss_ce: 0.016725
2021-12-11 19:53:36,707 iteration 1295 : loss : 0.065733, loss_ce: 0.023742
2021-12-11 19:53:38,260 iteration 1296 : loss : 0.073053, loss_ce: 0.020681
2021-12-11 19:53:39,686 iteration 1297 : loss : 0.035595, loss_ce: 0.014617
2021-12-11 19:53:41,279 iteration 1298 : loss : 0.065971, loss_ce: 0.026410
2021-12-11 19:53:42,790 iteration 1299 : loss : 0.043797, loss_ce: 0.018672
2021-12-11 19:53:44,405 iteration 1300 : loss : 0.065020, loss_ce: 0.023311
2021-12-11 19:53:46,029 iteration 1301 : loss : 0.082925, loss_ce: 0.028991
2021-12-11 19:53:47,503 iteration 1302 : loss : 0.061105, loss_ce: 0.019971
2021-12-11 19:53:49,073 iteration 1303 : loss : 0.055973, loss_ce: 0.016820
2021-12-11 19:53:50,663 iteration 1304 : loss : 0.054615, loss_ce: 0.023701
2021-12-11 19:53:52,285 iteration 1305 : loss : 0.085893, loss_ce: 0.032818
2021-12-11 19:53:53,844 iteration 1306 : loss : 0.047202, loss_ce: 0.018966
2021-12-11 19:53:55,357 iteration 1307 : loss : 0.041080, loss_ce: 0.014719
2021-12-11 19:53:56,891 iteration 1308 : loss : 0.061330, loss_ce: 0.029242
2021-12-11 19:53:58,403 iteration 1309 : loss : 0.037923, loss_ce: 0.014320
 19%|█████▊                        | 77/400 [36:32<2:31:28, 28.14s/it]2021-12-11 19:53:59,956 iteration 1310 : loss : 0.053148, loss_ce: 0.018968
2021-12-11 19:54:01,599 iteration 1311 : loss : 0.061295, loss_ce: 0.020658
2021-12-11 19:54:03,155 iteration 1312 : loss : 0.053946, loss_ce: 0.018311
2021-12-11 19:54:04,681 iteration 1313 : loss : 0.053845, loss_ce: 0.021348
2021-12-11 19:54:06,267 iteration 1314 : loss : 0.061523, loss_ce: 0.028183
2021-12-11 19:54:07,879 iteration 1315 : loss : 0.045537, loss_ce: 0.025286
2021-12-11 19:54:09,391 iteration 1316 : loss : 0.047965, loss_ce: 0.019458
2021-12-11 19:54:10,867 iteration 1317 : loss : 0.040280, loss_ce: 0.014809
2021-12-11 19:54:12,352 iteration 1318 : loss : 0.040821, loss_ce: 0.015231
2021-12-11 19:54:13,908 iteration 1319 : loss : 0.058953, loss_ce: 0.021596
2021-12-11 19:54:15,376 iteration 1320 : loss : 0.043509, loss_ce: 0.016653
2021-12-11 19:54:16,914 iteration 1321 : loss : 0.050486, loss_ce: 0.023506
2021-12-11 19:54:18,428 iteration 1322 : loss : 0.045588, loss_ce: 0.017109
2021-12-11 19:54:20,013 iteration 1323 : loss : 0.044879, loss_ce: 0.015034
2021-12-11 19:54:21,646 iteration 1324 : loss : 0.069427, loss_ce: 0.031518
2021-12-11 19:54:23,178 iteration 1325 : loss : 0.054732, loss_ce: 0.022952
2021-12-11 19:54:24,712 iteration 1326 : loss : 0.058689, loss_ce: 0.022839
 20%|█████▊                        | 78/400 [36:58<2:28:03, 27.59s/it]2021-12-11 19:54:26,262 iteration 1327 : loss : 0.035457, loss_ce: 0.012441
2021-12-11 19:54:27,803 iteration 1328 : loss : 0.048041, loss_ce: 0.017275
2021-12-11 19:54:29,354 iteration 1329 : loss : 0.056483, loss_ce: 0.023218
2021-12-11 19:54:30,972 iteration 1330 : loss : 0.053108, loss_ce: 0.017067
2021-12-11 19:54:32,507 iteration 1331 : loss : 0.047523, loss_ce: 0.018321
2021-12-11 19:54:34,028 iteration 1332 : loss : 0.050410, loss_ce: 0.019155
2021-12-11 19:54:35,540 iteration 1333 : loss : 0.040741, loss_ce: 0.016111
2021-12-11 19:54:37,144 iteration 1334 : loss : 0.034500, loss_ce: 0.014452
2021-12-11 19:54:38,761 iteration 1335 : loss : 0.034555, loss_ce: 0.014282
2021-12-11 19:54:40,250 iteration 1336 : loss : 0.040384, loss_ce: 0.020143
2021-12-11 19:54:41,853 iteration 1337 : loss : 0.070169, loss_ce: 0.025521
2021-12-11 19:54:43,365 iteration 1338 : loss : 0.044955, loss_ce: 0.020067
2021-12-11 19:54:44,868 iteration 1339 : loss : 0.053633, loss_ce: 0.020224
2021-12-11 19:54:46,367 iteration 1340 : loss : 0.042272, loss_ce: 0.017315
2021-12-11 19:54:47,928 iteration 1341 : loss : 0.067379, loss_ce: 0.027757
2021-12-11 19:54:49,544 iteration 1342 : loss : 0.071934, loss_ce: 0.026903
2021-12-11 19:54:51,004 iteration 1343 : loss : 0.040409, loss_ce: 0.012632
 20%|█████▉                        | 79/400 [37:25<2:25:30, 27.20s/it]2021-12-11 19:54:52,615 iteration 1344 : loss : 0.043406, loss_ce: 0.014940
2021-12-11 19:54:54,119 iteration 1345 : loss : 0.044298, loss_ce: 0.012406
2021-12-11 19:54:55,713 iteration 1346 : loss : 0.048693, loss_ce: 0.017855
2021-12-11 19:54:57,254 iteration 1347 : loss : 0.039388, loss_ce: 0.018128
2021-12-11 19:54:58,755 iteration 1348 : loss : 0.054246, loss_ce: 0.023536
2021-12-11 19:55:00,296 iteration 1349 : loss : 0.052962, loss_ce: 0.022085
2021-12-11 19:55:01,815 iteration 1350 : loss : 0.050248, loss_ce: 0.015969
2021-12-11 19:55:03,445 iteration 1351 : loss : 0.079200, loss_ce: 0.035792
2021-12-11 19:55:04,937 iteration 1352 : loss : 0.067351, loss_ce: 0.034879
2021-12-11 19:55:06,469 iteration 1353 : loss : 0.054459, loss_ce: 0.026759
2021-12-11 19:55:08,044 iteration 1354 : loss : 0.053421, loss_ce: 0.019096
2021-12-11 19:55:09,509 iteration 1355 : loss : 0.053259, loss_ce: 0.017482
2021-12-11 19:55:11,113 iteration 1356 : loss : 0.052294, loss_ce: 0.019004
2021-12-11 19:55:12,591 iteration 1357 : loss : 0.043912, loss_ce: 0.020097
2021-12-11 19:55:14,096 iteration 1358 : loss : 0.057114, loss_ce: 0.026344
2021-12-11 19:55:15,711 iteration 1359 : loss : 0.052997, loss_ce: 0.024572
2021-12-11 19:55:15,711 Training Data Eval:
2021-12-11 19:55:23,353   Average segmentation loss on training set: 0.0436
2021-12-11 19:55:23,353 Validation Data Eval:
2021-12-11 19:55:25,999   Average segmentation loss on validation set: 0.0989
2021-12-11 19:55:27,560 iteration 1360 : loss : 0.060345, loss_ce: 0.025151
 20%|██████                        | 80/400 [38:01<2:40:01, 30.01s/it]2021-12-11 19:55:29,204 iteration 1361 : loss : 0.061057, loss_ce: 0.019469
2021-12-11 19:55:30,738 iteration 1362 : loss : 0.060782, loss_ce: 0.017882
2021-12-11 19:55:32,275 iteration 1363 : loss : 0.042341, loss_ce: 0.017781
2021-12-11 19:55:33,743 iteration 1364 : loss : 0.058365, loss_ce: 0.028816
2021-12-11 19:55:35,248 iteration 1365 : loss : 0.062612, loss_ce: 0.019305
2021-12-11 19:55:36,859 iteration 1366 : loss : 0.070664, loss_ce: 0.030987
2021-12-11 19:55:38,418 iteration 1367 : loss : 0.075226, loss_ce: 0.040010
2021-12-11 19:55:40,190 iteration 1368 : loss : 0.052528, loss_ce: 0.021248
2021-12-11 19:55:41,775 iteration 1369 : loss : 0.045286, loss_ce: 0.016581
2021-12-11 19:55:43,274 iteration 1370 : loss : 0.052550, loss_ce: 0.024142
2021-12-11 19:55:44,802 iteration 1371 : loss : 0.049152, loss_ce: 0.018355
2021-12-11 19:55:46,484 iteration 1372 : loss : 0.078561, loss_ce: 0.035835
2021-12-11 19:55:48,007 iteration 1373 : loss : 0.063756, loss_ce: 0.029022
2021-12-11 19:55:49,501 iteration 1374 : loss : 0.054034, loss_ce: 0.022913
2021-12-11 19:55:51,018 iteration 1375 : loss : 0.035838, loss_ce: 0.014788
2021-12-11 19:55:52,550 iteration 1376 : loss : 0.049569, loss_ce: 0.016513
2021-12-11 19:55:54,161 iteration 1377 : loss : 0.056509, loss_ce: 0.031764
 20%|██████                        | 81/400 [38:28<2:34:06, 28.99s/it]2021-12-11 19:55:55,835 iteration 1378 : loss : 0.062483, loss_ce: 0.033350
2021-12-11 19:55:57,430 iteration 1379 : loss : 0.055978, loss_ce: 0.024456
2021-12-11 19:55:58,979 iteration 1380 : loss : 0.066685, loss_ce: 0.021263
2021-12-11 19:56:00,570 iteration 1381 : loss : 0.042845, loss_ce: 0.017865
2021-12-11 19:56:02,134 iteration 1382 : loss : 0.067644, loss_ce: 0.027349
2021-12-11 19:56:03,620 iteration 1383 : loss : 0.082716, loss_ce: 0.023303
2021-12-11 19:56:05,209 iteration 1384 : loss : 0.047745, loss_ce: 0.018690
2021-12-11 19:56:06,785 iteration 1385 : loss : 0.038713, loss_ce: 0.015749
2021-12-11 19:56:08,315 iteration 1386 : loss : 0.080947, loss_ce: 0.030382
2021-12-11 19:56:09,966 iteration 1387 : loss : 0.059987, loss_ce: 0.019459
2021-12-11 19:56:11,509 iteration 1388 : loss : 0.064712, loss_ce: 0.026575
2021-12-11 19:56:13,074 iteration 1389 : loss : 0.047618, loss_ce: 0.017370
2021-12-11 19:56:14,646 iteration 1390 : loss : 0.050298, loss_ce: 0.020109
2021-12-11 19:56:16,200 iteration 1391 : loss : 0.057620, loss_ce: 0.015529
2021-12-11 19:56:17,764 iteration 1392 : loss : 0.063556, loss_ce: 0.020014
2021-12-11 19:56:19,293 iteration 1393 : loss : 0.039075, loss_ce: 0.012679
2021-12-11 19:56:20,823 iteration 1394 : loss : 0.052761, loss_ce: 0.029003
 20%|██████▏                       | 82/400 [38:54<2:29:56, 28.29s/it]2021-12-11 19:56:22,411 iteration 1395 : loss : 0.044855, loss_ce: 0.017193
2021-12-11 19:56:23,917 iteration 1396 : loss : 0.044490, loss_ce: 0.017671
2021-12-11 19:56:25,481 iteration 1397 : loss : 0.063429, loss_ce: 0.020553
2021-12-11 19:56:27,105 iteration 1398 : loss : 0.032509, loss_ce: 0.013757
2021-12-11 19:56:28,675 iteration 1399 : loss : 0.077968, loss_ce: 0.040876
2021-12-11 19:56:30,204 iteration 1400 : loss : 0.080574, loss_ce: 0.047316
2021-12-11 19:56:31,721 iteration 1401 : loss : 0.054972, loss_ce: 0.019354
2021-12-11 19:56:33,186 iteration 1402 : loss : 0.041110, loss_ce: 0.016570
2021-12-11 19:56:34,841 iteration 1403 : loss : 0.055612, loss_ce: 0.023145
2021-12-11 19:56:36,430 iteration 1404 : loss : 0.057084, loss_ce: 0.019990
2021-12-11 19:56:37,993 iteration 1405 : loss : 0.038537, loss_ce: 0.017045
2021-12-11 19:56:39,552 iteration 1406 : loss : 0.055842, loss_ce: 0.019824
2021-12-11 19:56:41,048 iteration 1407 : loss : 0.046671, loss_ce: 0.023593
2021-12-11 19:56:42,608 iteration 1408 : loss : 0.049551, loss_ce: 0.016964
2021-12-11 19:56:44,230 iteration 1409 : loss : 0.073138, loss_ce: 0.025377
2021-12-11 19:56:45,803 iteration 1410 : loss : 0.065310, loss_ce: 0.020857
2021-12-11 19:56:47,337 iteration 1411 : loss : 0.048653, loss_ce: 0.020251
 21%|██████▏                       | 83/400 [39:21<2:26:37, 27.75s/it]2021-12-11 19:56:48,834 iteration 1412 : loss : 0.051297, loss_ce: 0.015571
2021-12-11 19:56:50,421 iteration 1413 : loss : 0.039936, loss_ce: 0.014963
2021-12-11 19:56:51,955 iteration 1414 : loss : 0.040929, loss_ce: 0.019588
2021-12-11 19:56:53,436 iteration 1415 : loss : 0.043030, loss_ce: 0.015375
2021-12-11 19:56:54,997 iteration 1416 : loss : 0.046200, loss_ce: 0.014883
2021-12-11 19:56:56,593 iteration 1417 : loss : 0.052112, loss_ce: 0.020277
2021-12-11 19:56:58,064 iteration 1418 : loss : 0.033242, loss_ce: 0.010421
2021-12-11 19:56:59,710 iteration 1419 : loss : 0.053044, loss_ce: 0.017010
2021-12-11 19:57:01,355 iteration 1420 : loss : 0.044221, loss_ce: 0.014712
2021-12-11 19:57:02,862 iteration 1421 : loss : 0.044308, loss_ce: 0.018169
2021-12-11 19:57:04,402 iteration 1422 : loss : 0.041687, loss_ce: 0.016672
2021-12-11 19:57:05,904 iteration 1423 : loss : 0.069661, loss_ce: 0.028740
2021-12-11 19:57:07,487 iteration 1424 : loss : 0.051900, loss_ce: 0.018078
2021-12-11 19:57:09,105 iteration 1425 : loss : 0.057079, loss_ce: 0.022860
2021-12-11 19:57:10,522 iteration 1426 : loss : 0.040294, loss_ce: 0.016384
2021-12-11 19:57:12,026 iteration 1427 : loss : 0.045331, loss_ce: 0.020259
2021-12-11 19:57:13,571 iteration 1428 : loss : 0.052801, loss_ce: 0.021077
 21%|██████▎                       | 84/400 [39:47<2:23:46, 27.30s/it]2021-12-11 19:57:15,257 iteration 1429 : loss : 0.062125, loss_ce: 0.024089
2021-12-11 19:57:16,745 iteration 1430 : loss : 0.053585, loss_ce: 0.018097
2021-12-11 19:57:18,281 iteration 1431 : loss : 0.045106, loss_ce: 0.020339
2021-12-11 19:57:19,827 iteration 1432 : loss : 0.041894, loss_ce: 0.016765
2021-12-11 19:57:21,449 iteration 1433 : loss : 0.071843, loss_ce: 0.029828
2021-12-11 19:57:23,051 iteration 1434 : loss : 0.064999, loss_ce: 0.027934
2021-12-11 19:57:24,493 iteration 1435 : loss : 0.039169, loss_ce: 0.012788
2021-12-11 19:57:26,109 iteration 1436 : loss : 0.048143, loss_ce: 0.020712
2021-12-11 19:57:27,583 iteration 1437 : loss : 0.091941, loss_ce: 0.020019
2021-12-11 19:57:29,037 iteration 1438 : loss : 0.035685, loss_ce: 0.016762
2021-12-11 19:57:30,596 iteration 1439 : loss : 0.034461, loss_ce: 0.011231
2021-12-11 19:57:32,216 iteration 1440 : loss : 0.040461, loss_ce: 0.018716
2021-12-11 19:57:33,735 iteration 1441 : loss : 0.038234, loss_ce: 0.017762
2021-12-11 19:57:35,230 iteration 1442 : loss : 0.068667, loss_ce: 0.028619
2021-12-11 19:57:36,789 iteration 1443 : loss : 0.043481, loss_ce: 0.017366
2021-12-11 19:57:38,402 iteration 1444 : loss : 0.041493, loss_ce: 0.021062
2021-12-11 19:57:38,402 Training Data Eval:
2021-12-11 19:57:46,042   Average segmentation loss on training set: 0.0415
2021-12-11 19:57:46,042 Validation Data Eval:
2021-12-11 19:57:48,674   Average segmentation loss on validation set: 0.0843
2021-12-11 19:57:50,259 iteration 1445 : loss : 0.045785, loss_ce: 0.014207
 21%|██████▍                       | 85/400 [40:24<2:38:06, 30.12s/it]2021-12-11 19:57:51,899 iteration 1446 : loss : 0.044815, loss_ce: 0.015877
2021-12-11 19:57:53,486 iteration 1447 : loss : 0.069901, loss_ce: 0.028521
2021-12-11 19:57:55,013 iteration 1448 : loss : 0.046470, loss_ce: 0.023047
2021-12-11 19:57:56,565 iteration 1449 : loss : 0.069191, loss_ce: 0.025970
2021-12-11 19:57:58,019 iteration 1450 : loss : 0.055567, loss_ce: 0.024744
2021-12-11 19:57:59,507 iteration 1451 : loss : 0.047940, loss_ce: 0.014873
2021-12-11 19:58:01,059 iteration 1452 : loss : 0.097301, loss_ce: 0.020004
2021-12-11 19:58:02,658 iteration 1453 : loss : 0.079114, loss_ce: 0.026219
2021-12-11 19:58:04,169 iteration 1454 : loss : 0.036894, loss_ce: 0.015903
2021-12-11 19:58:05,684 iteration 1455 : loss : 0.047081, loss_ce: 0.018094
2021-12-11 19:58:07,240 iteration 1456 : loss : 0.047568, loss_ce: 0.017183
2021-12-11 19:58:08,789 iteration 1457 : loss : 0.059041, loss_ce: 0.024107
2021-12-11 19:58:10,323 iteration 1458 : loss : 0.037291, loss_ce: 0.013345
2021-12-11 19:58:11,763 iteration 1459 : loss : 0.046483, loss_ce: 0.019429
2021-12-11 19:58:13,361 iteration 1460 : loss : 0.057514, loss_ce: 0.028168
2021-12-11 19:58:14,894 iteration 1461 : loss : 0.046840, loss_ce: 0.014935
2021-12-11 19:58:16,476 iteration 1462 : loss : 0.042197, loss_ce: 0.014357
 22%|██████▍                       | 86/400 [40:50<2:31:28, 28.95s/it]2021-12-11 19:58:18,026 iteration 1463 : loss : 0.048722, loss_ce: 0.022020
2021-12-11 19:58:19,600 iteration 1464 : loss : 0.049675, loss_ce: 0.015971
2021-12-11 19:58:21,210 iteration 1465 : loss : 0.058644, loss_ce: 0.026131
2021-12-11 19:58:22,745 iteration 1466 : loss : 0.045329, loss_ce: 0.014993
2021-12-11 19:58:24,277 iteration 1467 : loss : 0.055357, loss_ce: 0.020660
2021-12-11 19:58:25,835 iteration 1468 : loss : 0.042910, loss_ce: 0.016344
2021-12-11 19:58:27,406 iteration 1469 : loss : 0.032891, loss_ce: 0.012712
2021-12-11 19:58:28,959 iteration 1470 : loss : 0.043042, loss_ce: 0.017065
2021-12-11 19:58:30,429 iteration 1471 : loss : 0.054103, loss_ce: 0.018893
2021-12-11 19:58:31,949 iteration 1472 : loss : 0.043628, loss_ce: 0.014441
2021-12-11 19:58:33,548 iteration 1473 : loss : 0.037473, loss_ce: 0.016634
2021-12-11 19:58:35,061 iteration 1474 : loss : 0.046157, loss_ce: 0.018695
2021-12-11 19:58:36,604 iteration 1475 : loss : 0.049387, loss_ce: 0.016343
2021-12-11 19:58:38,199 iteration 1476 : loss : 0.065747, loss_ce: 0.035344
2021-12-11 19:58:39,730 iteration 1477 : loss : 0.043416, loss_ce: 0.015422
2021-12-11 19:58:41,334 iteration 1478 : loss : 0.042284, loss_ce: 0.015099
2021-12-11 19:58:42,908 iteration 1479 : loss : 0.070379, loss_ce: 0.026010
 22%|██████▌                       | 87/400 [41:17<2:27:04, 28.19s/it]2021-12-11 19:58:44,492 iteration 1480 : loss : 0.052261, loss_ce: 0.032141
2021-12-11 19:58:46,105 iteration 1481 : loss : 0.043377, loss_ce: 0.019006
2021-12-11 19:58:47,631 iteration 1482 : loss : 0.039398, loss_ce: 0.016573
2021-12-11 19:58:49,098 iteration 1483 : loss : 0.032422, loss_ce: 0.013746
2021-12-11 19:58:50,587 iteration 1484 : loss : 0.049710, loss_ce: 0.022325
2021-12-11 19:58:52,089 iteration 1485 : loss : 0.040849, loss_ce: 0.014364
2021-12-11 19:58:53,599 iteration 1486 : loss : 0.054910, loss_ce: 0.018191
2021-12-11 19:58:55,208 iteration 1487 : loss : 0.041092, loss_ce: 0.015997
2021-12-11 19:58:56,722 iteration 1488 : loss : 0.041157, loss_ce: 0.015920
2021-12-11 19:58:58,286 iteration 1489 : loss : 0.037344, loss_ce: 0.014420
2021-12-11 19:58:59,820 iteration 1490 : loss : 0.039886, loss_ce: 0.015550
2021-12-11 19:59:01,295 iteration 1491 : loss : 0.050885, loss_ce: 0.016394
2021-12-11 19:59:02,856 iteration 1492 : loss : 0.055945, loss_ce: 0.025311
2021-12-11 19:59:04,574 iteration 1493 : loss : 0.047666, loss_ce: 0.018446
2021-12-11 19:59:06,143 iteration 1494 : loss : 0.052928, loss_ce: 0.018049
2021-12-11 19:59:07,694 iteration 1495 : loss : 0.062273, loss_ce: 0.022878
2021-12-11 19:59:09,231 iteration 1496 : loss : 0.047065, loss_ce: 0.016074
 22%|██████▌                       | 88/400 [41:43<2:23:41, 27.63s/it]2021-12-11 19:59:10,770 iteration 1497 : loss : 0.033275, loss_ce: 0.013866
2021-12-11 19:59:12,198 iteration 1498 : loss : 0.030829, loss_ce: 0.011912
2021-12-11 19:59:13,662 iteration 1499 : loss : 0.044954, loss_ce: 0.020209
2021-12-11 19:59:15,339 iteration 1500 : loss : 0.068493, loss_ce: 0.024759
2021-12-11 19:59:16,810 iteration 1501 : loss : 0.040162, loss_ce: 0.012335
2021-12-11 19:59:18,360 iteration 1502 : loss : 0.049114, loss_ce: 0.016413
2021-12-11 19:59:19,946 iteration 1503 : loss : 0.045376, loss_ce: 0.013624
2021-12-11 19:59:21,463 iteration 1504 : loss : 0.045554, loss_ce: 0.020285
2021-12-11 19:59:22,955 iteration 1505 : loss : 0.038262, loss_ce: 0.016613
2021-12-11 19:59:24,538 iteration 1506 : loss : 0.039561, loss_ce: 0.014601
2021-12-11 19:59:26,051 iteration 1507 : loss : 0.036284, loss_ce: 0.015019
2021-12-11 19:59:27,597 iteration 1508 : loss : 0.129984, loss_ce: 0.028565
2021-12-11 19:59:29,120 iteration 1509 : loss : 0.036476, loss_ce: 0.015209
2021-12-11 19:59:30,631 iteration 1510 : loss : 0.043409, loss_ce: 0.012560
2021-12-11 19:59:32,260 iteration 1511 : loss : 0.064079, loss_ce: 0.036583
2021-12-11 19:59:33,796 iteration 1512 : loss : 0.053934, loss_ce: 0.021133
2021-12-11 19:59:35,333 iteration 1513 : loss : 0.037401, loss_ce: 0.014070
 22%|██████▋                       | 89/400 [42:09<2:20:50, 27.17s/it]2021-12-11 19:59:36,928 iteration 1514 : loss : 0.047885, loss_ce: 0.019549
2021-12-11 19:59:38,476 iteration 1515 : loss : 0.043147, loss_ce: 0.019349
2021-12-11 19:59:40,050 iteration 1516 : loss : 0.059345, loss_ce: 0.033118
2021-12-11 19:59:41,556 iteration 1517 : loss : 0.042309, loss_ce: 0.019515
2021-12-11 19:59:43,031 iteration 1518 : loss : 0.034574, loss_ce: 0.015177
2021-12-11 19:59:44,556 iteration 1519 : loss : 0.041484, loss_ce: 0.017338
2021-12-11 19:59:46,227 iteration 1520 : loss : 0.047631, loss_ce: 0.019112
2021-12-11 19:59:47,716 iteration 1521 : loss : 0.041104, loss_ce: 0.014303
2021-12-11 19:59:49,314 iteration 1522 : loss : 0.045659, loss_ce: 0.015108
2021-12-11 19:59:50,890 iteration 1523 : loss : 0.042090, loss_ce: 0.017380
2021-12-11 19:59:52,381 iteration 1524 : loss : 0.037757, loss_ce: 0.013762
2021-12-11 19:59:53,904 iteration 1525 : loss : 0.033664, loss_ce: 0.014516
2021-12-11 19:59:55,425 iteration 1526 : loss : 0.046941, loss_ce: 0.015102
2021-12-11 19:59:57,042 iteration 1527 : loss : 0.047622, loss_ce: 0.018526
2021-12-11 19:59:58,618 iteration 1528 : loss : 0.040152, loss_ce: 0.014312
2021-12-11 20:00:00,153 iteration 1529 : loss : 0.045532, loss_ce: 0.013658
2021-12-11 20:00:00,154 Training Data Eval:
2021-12-11 20:00:07,797   Average segmentation loss on training set: 0.0313
2021-12-11 20:00:07,798 Validation Data Eval:
2021-12-11 20:00:10,436   Average segmentation loss on validation set: 0.0991
2021-12-11 20:00:11,939 iteration 1530 : loss : 0.044691, loss_ce: 0.020116
 22%|██████▊                       | 90/400 [42:46<2:35:01, 30.00s/it]2021-12-11 20:00:13,549 iteration 1531 : loss : 0.043352, loss_ce: 0.018563
2021-12-11 20:00:15,131 iteration 1532 : loss : 0.061454, loss_ce: 0.026420
2021-12-11 20:00:16,620 iteration 1533 : loss : 0.043124, loss_ce: 0.015608
2021-12-11 20:00:18,141 iteration 1534 : loss : 0.039393, loss_ce: 0.018896
2021-12-11 20:00:19,625 iteration 1535 : loss : 0.045148, loss_ce: 0.019953
2021-12-11 20:00:21,183 iteration 1536 : loss : 0.050654, loss_ce: 0.016152
2021-12-11 20:00:22,686 iteration 1537 : loss : 0.051543, loss_ce: 0.024848
2021-12-11 20:00:24,111 iteration 1538 : loss : 0.075809, loss_ce: 0.022340
2021-12-11 20:00:25,582 iteration 1539 : loss : 0.049033, loss_ce: 0.020086
2021-12-11 20:00:27,129 iteration 1540 : loss : 0.045580, loss_ce: 0.020738
2021-12-11 20:00:28,716 iteration 1541 : loss : 0.042639, loss_ce: 0.016950
2021-12-11 20:00:30,354 iteration 1542 : loss : 0.054403, loss_ce: 0.022215
2021-12-11 20:00:31,894 iteration 1543 : loss : 0.045065, loss_ce: 0.011727
2021-12-11 20:00:33,460 iteration 1544 : loss : 0.046613, loss_ce: 0.020092
2021-12-11 20:00:34,938 iteration 1545 : loss : 0.050644, loss_ce: 0.018904
2021-12-11 20:00:36,451 iteration 1546 : loss : 0.050251, loss_ce: 0.014823
2021-12-11 20:00:38,016 iteration 1547 : loss : 0.039360, loss_ce: 0.016851
 23%|██████▊                       | 91/400 [43:12<2:28:27, 28.83s/it]2021-12-11 20:00:39,571 iteration 1548 : loss : 0.038505, loss_ce: 0.011706
2021-12-11 20:00:41,035 iteration 1549 : loss : 0.062130, loss_ce: 0.023938
2021-12-11 20:00:42,602 iteration 1550 : loss : 0.058939, loss_ce: 0.018265
2021-12-11 20:00:44,159 iteration 1551 : loss : 0.058798, loss_ce: 0.023019
2021-12-11 20:00:45,671 iteration 1552 : loss : 0.048113, loss_ce: 0.013412
2021-12-11 20:00:47,247 iteration 1553 : loss : 0.041622, loss_ce: 0.021532
2021-12-11 20:00:48,701 iteration 1554 : loss : 0.096181, loss_ce: 0.052103
2021-12-11 20:00:50,196 iteration 1555 : loss : 0.046489, loss_ce: 0.013634
2021-12-11 20:00:51,822 iteration 1556 : loss : 0.057478, loss_ce: 0.020206
2021-12-11 20:00:53,385 iteration 1557 : loss : 0.059071, loss_ce: 0.019963
2021-12-11 20:00:54,846 iteration 1558 : loss : 0.044177, loss_ce: 0.014406
2021-12-11 20:00:56,456 iteration 1559 : loss : 0.065563, loss_ce: 0.023514
2021-12-11 20:00:57,948 iteration 1560 : loss : 0.043675, loss_ce: 0.022840
2021-12-11 20:00:59,490 iteration 1561 : loss : 0.045008, loss_ce: 0.018630
2021-12-11 20:01:01,021 iteration 1562 : loss : 0.045511, loss_ce: 0.023084
2021-12-11 20:01:02,587 iteration 1563 : loss : 0.047951, loss_ce: 0.016790
2021-12-11 20:01:04,095 iteration 1564 : loss : 0.039991, loss_ce: 0.014806
 23%|██████▉                       | 92/400 [43:38<2:23:44, 28.00s/it]2021-12-11 20:01:05,626 iteration 1565 : loss : 0.037484, loss_ce: 0.018246
2021-12-11 20:01:07,203 iteration 1566 : loss : 0.043756, loss_ce: 0.012224
2021-12-11 20:01:08,744 iteration 1567 : loss : 0.043428, loss_ce: 0.018543
2021-12-11 20:01:10,367 iteration 1568 : loss : 0.053146, loss_ce: 0.018106
2021-12-11 20:01:11,950 iteration 1569 : loss : 0.055147, loss_ce: 0.021747
2021-12-11 20:01:13,500 iteration 1570 : loss : 0.035915, loss_ce: 0.012175
2021-12-11 20:01:15,039 iteration 1571 : loss : 0.053575, loss_ce: 0.018201
2021-12-11 20:01:16,661 iteration 1572 : loss : 0.060576, loss_ce: 0.021682
2021-12-11 20:01:18,117 iteration 1573 : loss : 0.038887, loss_ce: 0.017717
2021-12-11 20:01:19,690 iteration 1574 : loss : 0.050193, loss_ce: 0.019071
2021-12-11 20:01:21,292 iteration 1575 : loss : 0.036470, loss_ce: 0.014328
2021-12-11 20:01:22,886 iteration 1576 : loss : 0.040207, loss_ce: 0.016313
2021-12-11 20:01:24,359 iteration 1577 : loss : 0.038356, loss_ce: 0.014196
2021-12-11 20:01:25,861 iteration 1578 : loss : 0.034980, loss_ce: 0.011255
2021-12-11 20:01:27,458 iteration 1579 : loss : 0.059175, loss_ce: 0.021035
2021-12-11 20:01:29,030 iteration 1580 : loss : 0.054241, loss_ce: 0.018059
2021-12-11 20:01:30,684 iteration 1581 : loss : 0.043047, loss_ce: 0.015989
 23%|██████▉                       | 93/400 [44:04<2:21:06, 27.58s/it]2021-12-11 20:01:32,277 iteration 1582 : loss : 0.030180, loss_ce: 0.011097
2021-12-11 20:01:33,827 iteration 1583 : loss : 0.041769, loss_ce: 0.016694
2021-12-11 20:01:35,291 iteration 1584 : loss : 0.056087, loss_ce: 0.018028
2021-12-11 20:01:36,830 iteration 1585 : loss : 0.083478, loss_ce: 0.019178
2021-12-11 20:01:38,444 iteration 1586 : loss : 0.052336, loss_ce: 0.014955
2021-12-11 20:01:39,989 iteration 1587 : loss : 0.046310, loss_ce: 0.015770
2021-12-11 20:01:41,618 iteration 1588 : loss : 0.055449, loss_ce: 0.023802
2021-12-11 20:01:43,156 iteration 1589 : loss : 0.061638, loss_ce: 0.016838
2021-12-11 20:01:44,716 iteration 1590 : loss : 0.051091, loss_ce: 0.023468
2021-12-11 20:01:46,210 iteration 1591 : loss : 0.067453, loss_ce: 0.035351
2021-12-11 20:01:47,703 iteration 1592 : loss : 0.046215, loss_ce: 0.020581
2021-12-11 20:01:49,304 iteration 1593 : loss : 0.064930, loss_ce: 0.019602
2021-12-11 20:01:50,847 iteration 1594 : loss : 0.052553, loss_ce: 0.028638
2021-12-11 20:01:52,407 iteration 1595 : loss : 0.058884, loss_ce: 0.027802
2021-12-11 20:01:53,962 iteration 1596 : loss : 0.036858, loss_ce: 0.016372
2021-12-11 20:01:55,458 iteration 1597 : loss : 0.045463, loss_ce: 0.017163
2021-12-11 20:01:57,026 iteration 1598 : loss : 0.050557, loss_ce: 0.023748
 24%|███████                       | 94/400 [44:31<2:18:45, 27.21s/it]2021-12-11 20:01:58,624 iteration 1599 : loss : 0.037254, loss_ce: 0.015889
2021-12-11 20:02:00,129 iteration 1600 : loss : 0.042398, loss_ce: 0.016221
2021-12-11 20:02:01,651 iteration 1601 : loss : 0.050393, loss_ce: 0.016534
2021-12-11 20:02:03,163 iteration 1602 : loss : 0.052498, loss_ce: 0.025163
2021-12-11 20:02:04,784 iteration 1603 : loss : 0.061028, loss_ce: 0.023626
2021-12-11 20:02:06,299 iteration 1604 : loss : 0.046924, loss_ce: 0.022830
2021-12-11 20:02:07,916 iteration 1605 : loss : 0.052119, loss_ce: 0.017629
2021-12-11 20:02:09,507 iteration 1606 : loss : 0.042786, loss_ce: 0.013639
2021-12-11 20:02:11,045 iteration 1607 : loss : 0.050312, loss_ce: 0.019139
2021-12-11 20:02:12,641 iteration 1608 : loss : 0.037587, loss_ce: 0.013319
2021-12-11 20:02:14,213 iteration 1609 : loss : 0.037213, loss_ce: 0.014127
2021-12-11 20:02:15,742 iteration 1610 : loss : 0.043011, loss_ce: 0.019151
2021-12-11 20:02:17,311 iteration 1611 : loss : 0.049087, loss_ce: 0.019808
2021-12-11 20:02:18,847 iteration 1612 : loss : 0.040812, loss_ce: 0.019961
2021-12-11 20:02:20,397 iteration 1613 : loss : 0.044756, loss_ce: 0.019927
2021-12-11 20:02:21,947 iteration 1614 : loss : 0.038792, loss_ce: 0.013534
2021-12-11 20:02:21,948 Training Data Eval:
2021-12-11 20:02:29,582   Average segmentation loss on training set: 0.0321
2021-12-11 20:02:29,583 Validation Data Eval:
2021-12-11 20:02:32,211   Average segmentation loss on validation set: 0.0784
2021-12-11 20:02:34,211 Found new lowest validation loss at iteration 1614! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/NEW_TU/UNET_ADAM_best_val_loss_seed100.pth
2021-12-11 20:02:35,706 iteration 1615 : loss : 0.056835, loss_ce: 0.026758
 24%|███████▏                      | 95/400 [45:09<2:35:47, 30.65s/it]2021-12-11 20:02:37,167 iteration 1616 : loss : 0.041691, loss_ce: 0.012703
2021-12-11 20:02:38,598 iteration 1617 : loss : 0.030388, loss_ce: 0.013353
2021-12-11 20:02:40,104 iteration 1618 : loss : 0.021587, loss_ce: 0.008560
2021-12-11 20:02:41,677 iteration 1619 : loss : 0.031026, loss_ce: 0.014712
2021-12-11 20:02:43,147 iteration 1620 : loss : 0.041734, loss_ce: 0.016489
2021-12-11 20:02:44,708 iteration 1621 : loss : 0.046692, loss_ce: 0.017384
2021-12-11 20:02:46,261 iteration 1622 : loss : 0.036492, loss_ce: 0.013014
2021-12-11 20:02:47,730 iteration 1623 : loss : 0.029358, loss_ce: 0.013570
2021-12-11 20:02:49,284 iteration 1624 : loss : 0.039197, loss_ce: 0.016139
2021-12-11 20:02:50,738 iteration 1625 : loss : 0.032527, loss_ce: 0.016635
2021-12-11 20:02:52,240 iteration 1626 : loss : 0.032044, loss_ce: 0.013410
2021-12-11 20:02:53,727 iteration 1627 : loss : 0.044837, loss_ce: 0.012783
2021-12-11 20:02:55,275 iteration 1628 : loss : 0.052803, loss_ce: 0.016015
2021-12-11 20:02:56,841 iteration 1629 : loss : 0.047008, loss_ce: 0.020459
2021-12-11 20:02:58,313 iteration 1630 : loss : 0.041152, loss_ce: 0.014842
2021-12-11 20:02:59,832 iteration 1631 : loss : 0.052688, loss_ce: 0.021938
2021-12-11 20:03:01,259 iteration 1632 : loss : 0.030621, loss_ce: 0.011877
 24%|███████▏                      | 96/400 [45:35<2:27:32, 29.12s/it]2021-12-11 20:03:02,895 iteration 1633 : loss : 0.037378, loss_ce: 0.013423
2021-12-11 20:03:04,456 iteration 1634 : loss : 0.042863, loss_ce: 0.019876
2021-12-11 20:03:05,970 iteration 1635 : loss : 0.040857, loss_ce: 0.018656
2021-12-11 20:03:07,405 iteration 1636 : loss : 0.037034, loss_ce: 0.015506
2021-12-11 20:03:08,995 iteration 1637 : loss : 0.035443, loss_ce: 0.012899
2021-12-11 20:03:10,553 iteration 1638 : loss : 0.051129, loss_ce: 0.018367
2021-12-11 20:03:12,156 iteration 1639 : loss : 0.043548, loss_ce: 0.017111
2021-12-11 20:03:13,675 iteration 1640 : loss : 0.036484, loss_ce: 0.017093
2021-12-11 20:03:15,254 iteration 1641 : loss : 0.041265, loss_ce: 0.016263
2021-12-11 20:03:16,899 iteration 1642 : loss : 0.061330, loss_ce: 0.021118
2021-12-11 20:03:18,463 iteration 1643 : loss : 0.028651, loss_ce: 0.011847
2021-12-11 20:03:20,024 iteration 1644 : loss : 0.049664, loss_ce: 0.021481
2021-12-11 20:03:21,473 iteration 1645 : loss : 0.036908, loss_ce: 0.012836
2021-12-11 20:03:22,985 iteration 1646 : loss : 0.034752, loss_ce: 0.013486
2021-12-11 20:03:24,581 iteration 1647 : loss : 0.045889, loss_ce: 0.024356
2021-12-11 20:03:26,098 iteration 1648 : loss : 0.040930, loss_ce: 0.019302
2021-12-11 20:03:27,731 iteration 1649 : loss : 0.058338, loss_ce: 0.019069
 24%|███████▎                      | 97/400 [46:01<2:23:02, 28.32s/it]2021-12-11 20:03:29,319 iteration 1650 : loss : 0.036393, loss_ce: 0.013171
2021-12-11 20:03:30,916 iteration 1651 : loss : 0.079932, loss_ce: 0.036376
2021-12-11 20:03:32,517 iteration 1652 : loss : 0.061227, loss_ce: 0.016517
2021-12-11 20:03:34,089 iteration 1653 : loss : 0.054432, loss_ce: 0.027060
2021-12-11 20:03:35,617 iteration 1654 : loss : 0.038820, loss_ce: 0.012852
2021-12-11 20:03:37,143 iteration 1655 : loss : 0.070420, loss_ce: 0.022403
2021-12-11 20:03:38,656 iteration 1656 : loss : 0.037943, loss_ce: 0.017229
2021-12-11 20:03:40,262 iteration 1657 : loss : 0.043242, loss_ce: 0.019226
2021-12-11 20:03:41,744 iteration 1658 : loss : 0.033253, loss_ce: 0.013657
2021-12-11 20:03:43,282 iteration 1659 : loss : 0.046248, loss_ce: 0.020683
2021-12-11 20:03:44,941 iteration 1660 : loss : 0.057190, loss_ce: 0.029468
2021-12-11 20:03:46,507 iteration 1661 : loss : 0.044496, loss_ce: 0.018468
2021-12-11 20:03:48,028 iteration 1662 : loss : 0.046752, loss_ce: 0.018652
2021-12-11 20:03:49,630 iteration 1663 : loss : 0.050313, loss_ce: 0.019825
2021-12-11 20:03:51,229 iteration 1664 : loss : 0.055704, loss_ce: 0.021242
2021-12-11 20:03:52,738 iteration 1665 : loss : 0.032250, loss_ce: 0.014691
2021-12-11 20:03:54,243 iteration 1666 : loss : 0.040467, loss_ce: 0.016579
 24%|███████▎                      | 98/400 [46:28<2:19:49, 27.78s/it]2021-12-11 20:03:55,815 iteration 1667 : loss : 0.033219, loss_ce: 0.014421
2021-12-11 20:03:57,424 iteration 1668 : loss : 0.048683, loss_ce: 0.022373
2021-12-11 20:03:58,945 iteration 1669 : loss : 0.042193, loss_ce: 0.017740
2021-12-11 20:04:00,473 iteration 1670 : loss : 0.050227, loss_ce: 0.015553
2021-12-11 20:04:02,031 iteration 1671 : loss : 0.039508, loss_ce: 0.015967
2021-12-11 20:04:03,571 iteration 1672 : loss : 0.037371, loss_ce: 0.013092
2021-12-11 20:04:05,066 iteration 1673 : loss : 0.048189, loss_ce: 0.018250
2021-12-11 20:04:06,655 iteration 1674 : loss : 0.049976, loss_ce: 0.024415
2021-12-11 20:04:08,161 iteration 1675 : loss : 0.039560, loss_ce: 0.013822
2021-12-11 20:04:09,732 iteration 1676 : loss : 0.036244, loss_ce: 0.016005
2021-12-11 20:04:11,345 iteration 1677 : loss : 0.049759, loss_ce: 0.022558
2021-12-11 20:04:12,919 iteration 1678 : loss : 0.074245, loss_ce: 0.020187
2021-12-11 20:04:14,510 iteration 1679 : loss : 0.041496, loss_ce: 0.012388
2021-12-11 20:04:16,072 iteration 1680 : loss : 0.036807, loss_ce: 0.017033
2021-12-11 20:04:17,595 iteration 1681 : loss : 0.060983, loss_ce: 0.019397
2021-12-11 20:04:19,094 iteration 1682 : loss : 0.047064, loss_ce: 0.023282
2021-12-11 20:04:20,669 iteration 1683 : loss : 0.064355, loss_ce: 0.030606
 25%|███████▍                      | 99/400 [46:54<2:17:19, 27.37s/it]2021-12-11 20:04:22,271 iteration 1684 : loss : 0.029856, loss_ce: 0.010907
2021-12-11 20:04:23,771 iteration 1685 : loss : 0.052849, loss_ce: 0.016973
2021-12-11 20:04:25,370 iteration 1686 : loss : 0.044445, loss_ce: 0.016821
2021-12-11 20:04:26,866 iteration 1687 : loss : 0.031986, loss_ce: 0.009744
2021-12-11 20:04:28,433 iteration 1688 : loss : 0.042711, loss_ce: 0.015200
2021-12-11 20:04:30,005 iteration 1689 : loss : 0.052348, loss_ce: 0.021552
2021-12-11 20:04:31,480 iteration 1690 : loss : 0.036456, loss_ce: 0.012498
2021-12-11 20:04:32,992 iteration 1691 : loss : 0.052056, loss_ce: 0.017012
2021-12-11 20:04:34,562 iteration 1692 : loss : 0.033346, loss_ce: 0.014280
2021-12-11 20:04:36,161 iteration 1693 : loss : 0.039541, loss_ce: 0.014304
2021-12-11 20:04:37,747 iteration 1694 : loss : 0.046453, loss_ce: 0.013702
2021-12-11 20:04:39,252 iteration 1695 : loss : 0.051735, loss_ce: 0.013706
2021-12-11 20:04:40,787 iteration 1696 : loss : 0.057671, loss_ce: 0.027382
2021-12-11 20:04:42,357 iteration 1697 : loss : 0.056268, loss_ce: 0.023058
2021-12-11 20:04:43,914 iteration 1698 : loss : 0.027177, loss_ce: 0.009966
2021-12-11 20:04:45,435 iteration 1699 : loss : 0.038383, loss_ce: 0.017125
2021-12-11 20:04:45,435 Training Data Eval:
2021-12-11 20:04:53,087   Average segmentation loss on training set: 0.0296
2021-12-11 20:04:53,088 Validation Data Eval:
2021-12-11 20:04:55,724   Average segmentation loss on validation set: 0.1013
2021-12-11 20:04:57,289 iteration 1700 : loss : 0.039293, loss_ce: 0.016564
 25%|███████▎                     | 100/400 [47:31<2:30:44, 30.15s/it]2021-12-11 20:04:58,870 iteration 1701 : loss : 0.033493, loss_ce: 0.013908
2021-12-11 20:05:00,413 iteration 1702 : loss : 0.035544, loss_ce: 0.013076
2021-12-11 20:05:02,029 iteration 1703 : loss : 0.067482, loss_ce: 0.028945
2021-12-11 20:05:03,570 iteration 1704 : loss : 0.044194, loss_ce: 0.020262
2021-12-11 20:05:05,142 iteration 1705 : loss : 0.048236, loss_ce: 0.021184
2021-12-11 20:05:06,754 iteration 1706 : loss : 0.046772, loss_ce: 0.020119
2021-12-11 20:05:08,276 iteration 1707 : loss : 0.036773, loss_ce: 0.016220
2021-12-11 20:05:09,814 iteration 1708 : loss : 0.077839, loss_ce: 0.023998
2021-12-11 20:05:11,341 iteration 1709 : loss : 0.045214, loss_ce: 0.022048
2021-12-11 20:05:12,918 iteration 1710 : loss : 0.057297, loss_ce: 0.021500
2021-12-11 20:05:14,458 iteration 1711 : loss : 0.046979, loss_ce: 0.017820
2021-12-11 20:05:15,938 iteration 1712 : loss : 0.031418, loss_ce: 0.014205
2021-12-11 20:05:17,493 iteration 1713 : loss : 0.077589, loss_ce: 0.024286
2021-12-11 20:05:19,110 iteration 1714 : loss : 0.055047, loss_ce: 0.014982
2021-12-11 20:05:20,754 iteration 1715 : loss : 0.047825, loss_ce: 0.020895
2021-12-11 20:05:22,227 iteration 1716 : loss : 0.035503, loss_ce: 0.011402
2021-12-11 20:05:23,817 iteration 1717 : loss : 0.052738, loss_ce: 0.017361
 25%|███████▎                     | 101/400 [47:57<2:24:49, 29.06s/it]2021-12-11 20:05:25,419 iteration 1718 : loss : 0.045975, loss_ce: 0.023376
2021-12-11 20:05:26,952 iteration 1719 : loss : 0.066933, loss_ce: 0.014670
2021-12-11 20:05:28,533 iteration 1720 : loss : 0.047656, loss_ce: 0.015658
2021-12-11 20:05:30,046 iteration 1721 : loss : 0.052881, loss_ce: 0.017910
2021-12-11 20:05:31,622 iteration 1722 : loss : 0.050829, loss_ce: 0.019139
2021-12-11 20:05:33,119 iteration 1723 : loss : 0.063679, loss_ce: 0.020922
2021-12-11 20:05:34,683 iteration 1724 : loss : 0.031639, loss_ce: 0.011768
2021-12-11 20:05:36,223 iteration 1725 : loss : 0.049189, loss_ce: 0.015779
2021-12-11 20:05:37,775 iteration 1726 : loss : 0.044183, loss_ce: 0.017312
2021-12-11 20:05:39,395 iteration 1727 : loss : 0.057812, loss_ce: 0.023401
2021-12-11 20:05:40,854 iteration 1728 : loss : 0.037165, loss_ce: 0.012135
2021-12-11 20:05:42,410 iteration 1729 : loss : 0.052945, loss_ce: 0.018376
2021-12-11 20:05:44,010 iteration 1730 : loss : 0.036239, loss_ce: 0.018033
2021-12-11 20:05:45,530 iteration 1731 : loss : 0.051272, loss_ce: 0.028015
2021-12-11 20:05:47,044 iteration 1732 : loss : 0.053804, loss_ce: 0.021107
2021-12-11 20:05:48,534 iteration 1733 : loss : 0.038604, loss_ce: 0.015713
2021-12-11 20:05:50,054 iteration 1734 : loss : 0.048252, loss_ce: 0.023731
 26%|███████▍                     | 102/400 [48:24<2:20:07, 28.21s/it]2021-12-11 20:05:51,774 iteration 1735 : loss : 0.034348, loss_ce: 0.014463
2021-12-11 20:05:53,286 iteration 1736 : loss : 0.070911, loss_ce: 0.023183
2021-12-11 20:05:54,957 iteration 1737 : loss : 0.048962, loss_ce: 0.022390
2021-12-11 20:05:56,508 iteration 1738 : loss : 0.039725, loss_ce: 0.021014
2021-12-11 20:05:57,979 iteration 1739 : loss : 0.036803, loss_ce: 0.014745
2021-12-11 20:05:59,574 iteration 1740 : loss : 0.034351, loss_ce: 0.014606
2021-12-11 20:06:01,152 iteration 1741 : loss : 0.031917, loss_ce: 0.011610
2021-12-11 20:06:02,716 iteration 1742 : loss : 0.039217, loss_ce: 0.013896
2021-12-11 20:06:04,185 iteration 1743 : loss : 0.050915, loss_ce: 0.015289
2021-12-11 20:06:05,804 iteration 1744 : loss : 0.052091, loss_ce: 0.021777
2021-12-11 20:06:07,400 iteration 1745 : loss : 0.056324, loss_ce: 0.021393
2021-12-11 20:06:08,984 iteration 1746 : loss : 0.052873, loss_ce: 0.027098
2021-12-11 20:06:10,493 iteration 1747 : loss : 0.035719, loss_ce: 0.015259
2021-12-11 20:06:12,058 iteration 1748 : loss : 0.039821, loss_ce: 0.015253
2021-12-11 20:06:13,502 iteration 1749 : loss : 0.037705, loss_ce: 0.011212
2021-12-11 20:06:15,055 iteration 1750 : loss : 0.109110, loss_ce: 0.022148
2021-12-11 20:06:16,699 iteration 1751 : loss : 0.042988, loss_ce: 0.016752
 26%|███████▍                     | 103/400 [48:50<2:17:20, 27.74s/it]2021-12-11 20:06:18,364 iteration 1752 : loss : 0.084648, loss_ce: 0.021579
2021-12-11 20:06:19,818 iteration 1753 : loss : 0.042459, loss_ce: 0.013852
2021-12-11 20:06:21,418 iteration 1754 : loss : 0.041437, loss_ce: 0.014297
2021-12-11 20:06:22,916 iteration 1755 : loss : 0.041487, loss_ce: 0.018961
2021-12-11 20:06:24,471 iteration 1756 : loss : 0.057918, loss_ce: 0.021103
2021-12-11 20:06:25,968 iteration 1757 : loss : 0.031229, loss_ce: 0.013543
2021-12-11 20:06:27,487 iteration 1758 : loss : 0.040123, loss_ce: 0.020539
2021-12-11 20:06:28,985 iteration 1759 : loss : 0.038638, loss_ce: 0.012942
2021-12-11 20:06:30,488 iteration 1760 : loss : 0.040960, loss_ce: 0.013948
2021-12-11 20:06:32,092 iteration 1761 : loss : 0.040151, loss_ce: 0.013742
2021-12-11 20:06:33,552 iteration 1762 : loss : 0.035211, loss_ce: 0.013575
2021-12-11 20:06:35,042 iteration 1763 : loss : 0.043828, loss_ce: 0.015533
2021-12-11 20:06:36,479 iteration 1764 : loss : 0.033285, loss_ce: 0.010827
2021-12-11 20:06:38,084 iteration 1765 : loss : 0.032398, loss_ce: 0.016710
2021-12-11 20:06:39,689 iteration 1766 : loss : 0.046564, loss_ce: 0.023165
2021-12-11 20:06:41,203 iteration 1767 : loss : 0.040808, loss_ce: 0.017490
2021-12-11 20:06:42,768 iteration 1768 : loss : 0.043068, loss_ce: 0.016734
 26%|███████▌                     | 104/400 [49:16<2:14:23, 27.24s/it]2021-12-11 20:06:44,357 iteration 1769 : loss : 0.034115, loss_ce: 0.013688
2021-12-11 20:06:45,875 iteration 1770 : loss : 0.039956, loss_ce: 0.016249
2021-12-11 20:06:47,332 iteration 1771 : loss : 0.048331, loss_ce: 0.019426
2021-12-11 20:06:48,819 iteration 1772 : loss : 0.039809, loss_ce: 0.021002
2021-12-11 20:06:50,403 iteration 1773 : loss : 0.065839, loss_ce: 0.021478
2021-12-11 20:06:51,971 iteration 1774 : loss : 0.030234, loss_ce: 0.009896
2021-12-11 20:06:53,546 iteration 1775 : loss : 0.037052, loss_ce: 0.014240
2021-12-11 20:06:55,047 iteration 1776 : loss : 0.028095, loss_ce: 0.013533
2021-12-11 20:06:56,549 iteration 1777 : loss : 0.025326, loss_ce: 0.010099
2021-12-11 20:06:58,013 iteration 1778 : loss : 0.042817, loss_ce: 0.015851
2021-12-11 20:06:59,589 iteration 1779 : loss : 0.047504, loss_ce: 0.018581
2021-12-11 20:07:01,138 iteration 1780 : loss : 0.055797, loss_ce: 0.025530
2021-12-11 20:07:02,618 iteration 1781 : loss : 0.036937, loss_ce: 0.015627
2021-12-11 20:07:04,187 iteration 1782 : loss : 0.041733, loss_ce: 0.015589
2021-12-11 20:07:05,744 iteration 1783 : loss : 0.041438, loss_ce: 0.015334
2021-12-11 20:07:07,260 iteration 1784 : loss : 0.043362, loss_ce: 0.015948
2021-12-11 20:07:07,260 Training Data Eval:
2021-12-11 20:07:14,899   Average segmentation loss on training set: 0.0308
2021-12-11 20:07:14,900 Validation Data Eval:
2021-12-11 20:07:17,539   Average segmentation loss on validation set: 0.0765
2021-12-11 20:07:19,482 Found new lowest validation loss at iteration 1784! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/NEW_TU/UNET_ADAM_best_val_loss_seed100.pth
2021-12-11 20:07:20,972 iteration 1785 : loss : 0.036570, loss_ce: 0.014000
 26%|███████▌                     | 105/400 [49:55<2:30:05, 30.53s/it]2021-12-11 20:07:22,474 iteration 1786 : loss : 0.047684, loss_ce: 0.023927
2021-12-11 20:07:23,886 iteration 1787 : loss : 0.040703, loss_ce: 0.015064
2021-12-11 20:07:25,463 iteration 1788 : loss : 0.057526, loss_ce: 0.031339
2021-12-11 20:07:27,032 iteration 1789 : loss : 0.041943, loss_ce: 0.014450
2021-12-11 20:07:28,580 iteration 1790 : loss : 0.036303, loss_ce: 0.016117
2021-12-11 20:07:30,179 iteration 1791 : loss : 0.041704, loss_ce: 0.015966
2021-12-11 20:07:31,676 iteration 1792 : loss : 0.035296, loss_ce: 0.012736
2021-12-11 20:07:33,177 iteration 1793 : loss : 0.053590, loss_ce: 0.017784
2021-12-11 20:07:34,707 iteration 1794 : loss : 0.031009, loss_ce: 0.011403
2021-12-11 20:07:36,278 iteration 1795 : loss : 0.047429, loss_ce: 0.016674
2021-12-11 20:07:37,815 iteration 1796 : loss : 0.044904, loss_ce: 0.021611
2021-12-11 20:07:39,437 iteration 1797 : loss : 0.041667, loss_ce: 0.014620
2021-12-11 20:07:41,085 iteration 1798 : loss : 0.032547, loss_ce: 0.012182
2021-12-11 20:07:42,600 iteration 1799 : loss : 0.039158, loss_ce: 0.016235
2021-12-11 20:07:44,162 iteration 1800 : loss : 0.041739, loss_ce: 0.014867
2021-12-11 20:07:45,653 iteration 1801 : loss : 0.034898, loss_ce: 0.011276
2021-12-11 20:07:47,177 iteration 1802 : loss : 0.046399, loss_ce: 0.015603
 26%|███████▋                     | 106/400 [50:21<2:23:13, 29.23s/it]2021-12-11 20:07:48,839 iteration 1803 : loss : 0.038752, loss_ce: 0.012521
2021-12-11 20:07:50,441 iteration 1804 : loss : 0.038323, loss_ce: 0.010020
2021-12-11 20:07:51,969 iteration 1805 : loss : 0.042546, loss_ce: 0.011653
2021-12-11 20:07:53,474 iteration 1806 : loss : 0.036042, loss_ce: 0.014547
2021-12-11 20:07:54,982 iteration 1807 : loss : 0.056643, loss_ce: 0.019429
2021-12-11 20:07:56,518 iteration 1808 : loss : 0.036850, loss_ce: 0.016762
2021-12-11 20:07:58,009 iteration 1809 : loss : 0.027203, loss_ce: 0.010212
2021-12-11 20:07:59,450 iteration 1810 : loss : 0.025154, loss_ce: 0.009119
2021-12-11 20:08:01,031 iteration 1811 : loss : 0.051986, loss_ce: 0.022905
2021-12-11 20:08:02,639 iteration 1812 : loss : 0.038706, loss_ce: 0.013344
2021-12-11 20:08:04,296 iteration 1813 : loss : 0.042393, loss_ce: 0.012917
2021-12-11 20:08:05,874 iteration 1814 : loss : 0.038728, loss_ce: 0.017938
2021-12-11 20:08:07,368 iteration 1815 : loss : 0.032226, loss_ce: 0.010202
2021-12-11 20:08:08,824 iteration 1816 : loss : 0.038455, loss_ce: 0.017745
2021-12-11 20:08:10,428 iteration 1817 : loss : 0.050137, loss_ce: 0.018539
2021-12-11 20:08:11,962 iteration 1818 : loss : 0.051968, loss_ce: 0.020970
2021-12-11 20:08:13,538 iteration 1819 : loss : 0.047056, loss_ce: 0.023616
 27%|███████▊                     | 107/400 [50:47<2:18:32, 28.37s/it]2021-12-11 20:08:15,191 iteration 1820 : loss : 0.042847, loss_ce: 0.017567
2021-12-11 20:08:16,703 iteration 1821 : loss : 0.031818, loss_ce: 0.015006
2021-12-11 20:08:18,246 iteration 1822 : loss : 0.039422, loss_ce: 0.014471
2021-12-11 20:08:19,702 iteration 1823 : loss : 0.028967, loss_ce: 0.009629
2021-12-11 20:08:21,126 iteration 1824 : loss : 0.031440, loss_ce: 0.012708
2021-12-11 20:08:22,700 iteration 1825 : loss : 0.047753, loss_ce: 0.018624
2021-12-11 20:08:24,149 iteration 1826 : loss : 0.038375, loss_ce: 0.018201
2021-12-11 20:08:25,785 iteration 1827 : loss : 0.126750, loss_ce: 0.038237
2021-12-11 20:08:27,305 iteration 1828 : loss : 0.037939, loss_ce: 0.014474
2021-12-11 20:08:28,847 iteration 1829 : loss : 0.047065, loss_ce: 0.015859
2021-12-11 20:08:30,364 iteration 1830 : loss : 0.033426, loss_ce: 0.014444
2021-12-11 20:08:31,970 iteration 1831 : loss : 0.059626, loss_ce: 0.035610
2021-12-11 20:08:33,495 iteration 1832 : loss : 0.036782, loss_ce: 0.011333
2021-12-11 20:08:35,026 iteration 1833 : loss : 0.030388, loss_ce: 0.014633
2021-12-11 20:08:36,657 iteration 1834 : loss : 0.046108, loss_ce: 0.017904
2021-12-11 20:08:38,171 iteration 1835 : loss : 0.039805, loss_ce: 0.018847
2021-12-11 20:08:39,710 iteration 1836 : loss : 0.054739, loss_ce: 0.019256
 27%|███████▊                     | 108/400 [51:13<2:14:51, 27.71s/it]2021-12-11 20:08:41,339 iteration 1837 : loss : 0.028647, loss_ce: 0.011319
2021-12-11 20:08:42,942 iteration 1838 : loss : 0.041762, loss_ce: 0.018728
2021-12-11 20:08:44,456 iteration 1839 : loss : 0.043639, loss_ce: 0.017920
2021-12-11 20:08:45,964 iteration 1840 : loss : 0.036463, loss_ce: 0.016319
2021-12-11 20:08:47,534 iteration 1841 : loss : 0.067882, loss_ce: 0.030308
2021-12-11 20:08:49,137 iteration 1842 : loss : 0.049658, loss_ce: 0.019209
2021-12-11 20:08:50,602 iteration 1843 : loss : 0.032981, loss_ce: 0.014752
2021-12-11 20:08:52,152 iteration 1844 : loss : 0.047551, loss_ce: 0.017303
2021-12-11 20:08:53,628 iteration 1845 : loss : 0.037404, loss_ce: 0.014434
2021-12-11 20:08:55,262 iteration 1846 : loss : 0.040312, loss_ce: 0.017397
2021-12-11 20:08:56,845 iteration 1847 : loss : 0.046752, loss_ce: 0.016906
2021-12-11 20:08:58,381 iteration 1848 : loss : 0.034334, loss_ce: 0.013636
2021-12-11 20:08:59,840 iteration 1849 : loss : 0.028002, loss_ce: 0.013011
2021-12-11 20:09:01,385 iteration 1850 : loss : 0.061512, loss_ce: 0.021131
2021-12-11 20:09:02,956 iteration 1851 : loss : 0.056247, loss_ce: 0.020390
2021-12-11 20:09:04,508 iteration 1852 : loss : 0.045960, loss_ce: 0.021415
2021-12-11 20:09:06,054 iteration 1853 : loss : 0.045307, loss_ce: 0.011096
 27%|███████▉                     | 109/400 [51:40<2:12:24, 27.30s/it]2021-12-11 20:09:07,605 iteration 1854 : loss : 0.034602, loss_ce: 0.011870
2021-12-11 20:09:09,128 iteration 1855 : loss : 0.038369, loss_ce: 0.014100
2021-12-11 20:09:10,668 iteration 1856 : loss : 0.032620, loss_ce: 0.010812
2021-12-11 20:09:12,213 iteration 1857 : loss : 0.055670, loss_ce: 0.020304
2021-12-11 20:09:13,744 iteration 1858 : loss : 0.035452, loss_ce: 0.017269
2021-12-11 20:09:15,266 iteration 1859 : loss : 0.033365, loss_ce: 0.016178
2021-12-11 20:09:16,908 iteration 1860 : loss : 0.055337, loss_ce: 0.025052
2021-12-11 20:09:18,470 iteration 1861 : loss : 0.044520, loss_ce: 0.015928
2021-12-11 20:09:20,007 iteration 1862 : loss : 0.038910, loss_ce: 0.018740
2021-12-11 20:09:21,586 iteration 1863 : loss : 0.046576, loss_ce: 0.020678
2021-12-11 20:09:23,147 iteration 1864 : loss : 0.045790, loss_ce: 0.016283
2021-12-11 20:09:24,771 iteration 1865 : loss : 0.045372, loss_ce: 0.021832
2021-12-11 20:09:26,369 iteration 1866 : loss : 0.040323, loss_ce: 0.021130
2021-12-11 20:09:27,934 iteration 1867 : loss : 0.072694, loss_ce: 0.022257
2021-12-11 20:09:29,452 iteration 1868 : loss : 0.040721, loss_ce: 0.019067
2021-12-11 20:09:30,996 iteration 1869 : loss : 0.052427, loss_ce: 0.018266
2021-12-11 20:09:30,996 Training Data Eval:
2021-12-11 20:09:38,625   Average segmentation loss on training set: 0.0361
2021-12-11 20:09:38,626 Validation Data Eval:
2021-12-11 20:09:41,258   Average segmentation loss on validation set: 0.1626
2021-12-11 20:09:42,739 iteration 1870 : loss : 0.040436, loss_ce: 0.012587
 28%|███████▉                     | 110/400 [52:16<2:25:33, 30.11s/it]2021-12-11 20:09:44,305 iteration 1871 : loss : 0.039644, loss_ce: 0.018677
2021-12-11 20:09:45,806 iteration 1872 : loss : 0.034375, loss_ce: 0.013005
2021-12-11 20:09:47,340 iteration 1873 : loss : 0.047797, loss_ce: 0.021438
2021-12-11 20:09:48,985 iteration 1874 : loss : 0.043810, loss_ce: 0.018274
2021-12-11 20:09:50,607 iteration 1875 : loss : 0.035955, loss_ce: 0.019027
2021-12-11 20:09:52,231 iteration 1876 : loss : 0.039380, loss_ce: 0.012441
2021-12-11 20:09:53,824 iteration 1877 : loss : 0.052457, loss_ce: 0.015465
2021-12-11 20:09:55,325 iteration 1878 : loss : 0.036300, loss_ce: 0.013604
2021-12-11 20:09:56,834 iteration 1879 : loss : 0.040033, loss_ce: 0.018010
2021-12-11 20:09:58,331 iteration 1880 : loss : 0.036442, loss_ce: 0.014053
2021-12-11 20:09:59,831 iteration 1881 : loss : 0.025968, loss_ce: 0.008703
2021-12-11 20:10:01,379 iteration 1882 : loss : 0.054933, loss_ce: 0.014259
2021-12-11 20:10:02,860 iteration 1883 : loss : 0.034390, loss_ce: 0.013631
2021-12-11 20:10:04,465 iteration 1884 : loss : 0.035669, loss_ce: 0.014894
2021-12-11 20:10:05,957 iteration 1885 : loss : 0.031576, loss_ce: 0.011858
2021-12-11 20:10:07,519 iteration 1886 : loss : 0.040688, loss_ce: 0.018143
2021-12-11 20:10:09,023 iteration 1887 : loss : 0.041703, loss_ce: 0.014316
 28%|████████                     | 111/400 [52:43<2:19:31, 28.97s/it]2021-12-11 20:10:10,634 iteration 1888 : loss : 0.041886, loss_ce: 0.013241
2021-12-11 20:10:12,248 iteration 1889 : loss : 0.040166, loss_ce: 0.016351
2021-12-11 20:10:13,719 iteration 1890 : loss : 0.031956, loss_ce: 0.012777
2021-12-11 20:10:15,257 iteration 1891 : loss : 0.034753, loss_ce: 0.018076
2021-12-11 20:10:16,794 iteration 1892 : loss : 0.038029, loss_ce: 0.013238
2021-12-11 20:10:18,412 iteration 1893 : loss : 0.057663, loss_ce: 0.022308
2021-12-11 20:10:19,935 iteration 1894 : loss : 0.060543, loss_ce: 0.022774
2021-12-11 20:10:21,505 iteration 1895 : loss : 0.038650, loss_ce: 0.013036
2021-12-11 20:10:23,042 iteration 1896 : loss : 0.033584, loss_ce: 0.013719
2021-12-11 20:10:24,590 iteration 1897 : loss : 0.057371, loss_ce: 0.019689
2021-12-11 20:10:26,213 iteration 1898 : loss : 0.034993, loss_ce: 0.012880
2021-12-11 20:10:27,683 iteration 1899 : loss : 0.029509, loss_ce: 0.010608
2021-12-11 20:10:29,295 iteration 1900 : loss : 0.050767, loss_ce: 0.020796
2021-12-11 20:10:30,928 iteration 1901 : loss : 0.043919, loss_ce: 0.016918
2021-12-11 20:10:32,455 iteration 1902 : loss : 0.030130, loss_ce: 0.009598
2021-12-11 20:10:34,036 iteration 1903 : loss : 0.050623, loss_ce: 0.021909
2021-12-11 20:10:35,631 iteration 1904 : loss : 0.051489, loss_ce: 0.019484
 28%|████████                     | 112/400 [53:09<2:15:39, 28.26s/it]2021-12-11 20:10:37,266 iteration 1905 : loss : 0.045171, loss_ce: 0.017759
2021-12-11 20:10:38,800 iteration 1906 : loss : 0.043430, loss_ce: 0.014826
2021-12-11 20:10:40,331 iteration 1907 : loss : 0.032708, loss_ce: 0.011940
2021-12-11 20:10:41,992 iteration 1908 : loss : 0.052792, loss_ce: 0.016755
2021-12-11 20:10:43,555 iteration 1909 : loss : 0.029333, loss_ce: 0.010655
2021-12-11 20:10:45,121 iteration 1910 : loss : 0.070003, loss_ce: 0.014889
2021-12-11 20:10:46,713 iteration 1911 : loss : 0.035261, loss_ce: 0.012399
2021-12-11 20:10:48,174 iteration 1912 : loss : 0.032194, loss_ce: 0.011480
2021-12-11 20:10:49,762 iteration 1913 : loss : 0.041633, loss_ce: 0.018615
2021-12-11 20:10:51,305 iteration 1914 : loss : 0.040845, loss_ce: 0.019947
2021-12-11 20:10:52,868 iteration 1915 : loss : 0.053248, loss_ce: 0.021116
2021-12-11 20:10:54,411 iteration 1916 : loss : 0.040032, loss_ce: 0.016243
2021-12-11 20:10:55,944 iteration 1917 : loss : 0.042550, loss_ce: 0.020891
2021-12-11 20:10:57,522 iteration 1918 : loss : 0.043525, loss_ce: 0.014692
2021-12-11 20:10:59,030 iteration 1919 : loss : 0.049412, loss_ce: 0.017512
2021-12-11 20:11:00,553 iteration 1920 : loss : 0.038224, loss_ce: 0.014516
2021-12-11 20:11:02,166 iteration 1921 : loss : 0.066220, loss_ce: 0.037402
 28%|████████▏                    | 113/400 [53:36<2:12:42, 27.74s/it]2021-12-11 20:11:03,712 iteration 1922 : loss : 0.032917, loss_ce: 0.014608
2021-12-11 20:11:05,257 iteration 1923 : loss : 0.039559, loss_ce: 0.016565
2021-12-11 20:11:06,838 iteration 1924 : loss : 0.028169, loss_ce: 0.012262
2021-12-11 20:11:08,452 iteration 1925 : loss : 0.061286, loss_ce: 0.027141
2021-12-11 20:11:09,980 iteration 1926 : loss : 0.028621, loss_ce: 0.011275
2021-12-11 20:11:11,486 iteration 1927 : loss : 0.033686, loss_ce: 0.013296
2021-12-11 20:11:13,109 iteration 1928 : loss : 0.054458, loss_ce: 0.024867
2021-12-11 20:11:14,609 iteration 1929 : loss : 0.036664, loss_ce: 0.013561
2021-12-11 20:11:16,109 iteration 1930 : loss : 0.027421, loss_ce: 0.012256
2021-12-11 20:11:17,664 iteration 1931 : loss : 0.080605, loss_ce: 0.019828
2021-12-11 20:11:19,266 iteration 1932 : loss : 0.042030, loss_ce: 0.015087
2021-12-11 20:11:20,884 iteration 1933 : loss : 0.045042, loss_ce: 0.023211
2021-12-11 20:11:22,330 iteration 1934 : loss : 0.027811, loss_ce: 0.010917
2021-12-11 20:11:23,878 iteration 1935 : loss : 0.056333, loss_ce: 0.019590
2021-12-11 20:11:25,493 iteration 1936 : loss : 0.041684, loss_ce: 0.020838
2021-12-11 20:11:26,980 iteration 1937 : loss : 0.040847, loss_ce: 0.011331
2021-12-11 20:11:28,450 iteration 1938 : loss : 0.043715, loss_ce: 0.015526
 28%|████████▎                    | 114/400 [54:02<2:10:08, 27.30s/it]2021-12-11 20:11:29,982 iteration 1939 : loss : 0.032392, loss_ce: 0.010882
2021-12-11 20:11:31,632 iteration 1940 : loss : 0.049992, loss_ce: 0.023420
2021-12-11 20:11:33,263 iteration 1941 : loss : 0.048981, loss_ce: 0.019807
2021-12-11 20:11:34,830 iteration 1942 : loss : 0.050602, loss_ce: 0.018312
2021-12-11 20:11:36,350 iteration 1943 : loss : 0.036297, loss_ce: 0.014837
2021-12-11 20:11:37,918 iteration 1944 : loss : 0.027857, loss_ce: 0.010259
2021-12-11 20:11:39,425 iteration 1945 : loss : 0.057256, loss_ce: 0.018977
2021-12-11 20:11:40,962 iteration 1946 : loss : 0.033424, loss_ce: 0.011275
2021-12-11 20:11:42,538 iteration 1947 : loss : 0.042790, loss_ce: 0.018481
2021-12-11 20:11:44,082 iteration 1948 : loss : 0.068971, loss_ce: 0.018787
2021-12-11 20:11:45,601 iteration 1949 : loss : 0.030265, loss_ce: 0.012235
2021-12-11 20:11:47,089 iteration 1950 : loss : 0.032843, loss_ce: 0.015159
2021-12-11 20:11:48,691 iteration 1951 : loss : 0.046854, loss_ce: 0.017554
2021-12-11 20:11:50,272 iteration 1952 : loss : 0.052266, loss_ce: 0.016331
2021-12-11 20:11:51,890 iteration 1953 : loss : 0.046261, loss_ce: 0.020230
2021-12-11 20:11:53,455 iteration 1954 : loss : 0.026084, loss_ce: 0.012358
2021-12-11 20:11:53,455 Training Data Eval:
2021-12-11 20:12:01,074   Average segmentation loss on training set: 0.0314
2021-12-11 20:12:01,075 Validation Data Eval:
2021-12-11 20:12:03,702   Average segmentation loss on validation set: 0.1109
2021-12-11 20:12:05,263 iteration 1955 : loss : 0.044255, loss_ce: 0.014720
 29%|████████▎                    | 115/400 [54:39<2:23:14, 30.16s/it]2021-12-11 20:12:06,808 iteration 1956 : loss : 0.051461, loss_ce: 0.014459
2021-12-11 20:12:08,445 iteration 1957 : loss : 0.055430, loss_ce: 0.022355
2021-12-11 20:12:10,070 iteration 1958 : loss : 0.044683, loss_ce: 0.016632
2021-12-11 20:12:11,629 iteration 1959 : loss : 0.040837, loss_ce: 0.014522
2021-12-11 20:12:13,108 iteration 1960 : loss : 0.033724, loss_ce: 0.013989
2021-12-11 20:12:14,681 iteration 1961 : loss : 0.050218, loss_ce: 0.023496
2021-12-11 20:12:16,256 iteration 1962 : loss : 0.048178, loss_ce: 0.021638
2021-12-11 20:12:17,746 iteration 1963 : loss : 0.040100, loss_ce: 0.015741
2021-12-11 20:12:19,247 iteration 1964 : loss : 0.034711, loss_ce: 0.014536
2021-12-11 20:12:20,743 iteration 1965 : loss : 0.053610, loss_ce: 0.023126
2021-12-11 20:12:22,353 iteration 1966 : loss : 0.039383, loss_ce: 0.018310
2021-12-11 20:12:23,996 iteration 1967 : loss : 0.044421, loss_ce: 0.017071
2021-12-11 20:12:25,571 iteration 1968 : loss : 0.049080, loss_ce: 0.021966
2021-12-11 20:12:27,141 iteration 1969 : loss : 0.039484, loss_ce: 0.014486
2021-12-11 20:12:28,675 iteration 1970 : loss : 0.042191, loss_ce: 0.011727
2021-12-11 20:12:30,266 iteration 1971 : loss : 0.052439, loss_ce: 0.021836
2021-12-11 20:12:31,776 iteration 1972 : loss : 0.052938, loss_ce: 0.019282
 29%|████████▍                    | 116/400 [55:05<2:17:33, 29.06s/it]2021-12-11 20:12:33,223 iteration 1973 : loss : 0.030028, loss_ce: 0.011343
2021-12-11 20:12:34,789 iteration 1974 : loss : 0.037720, loss_ce: 0.015669
2021-12-11 20:12:36,325 iteration 1975 : loss : 0.046372, loss_ce: 0.014735
2021-12-11 20:12:37,935 iteration 1976 : loss : 0.045599, loss_ce: 0.019978
2021-12-11 20:12:39,493 iteration 1977 : loss : 0.045889, loss_ce: 0.013783
2021-12-11 20:12:40,952 iteration 1978 : loss : 0.034691, loss_ce: 0.013854
2021-12-11 20:12:42,413 iteration 1979 : loss : 0.034278, loss_ce: 0.014496
2021-12-11 20:12:43,965 iteration 1980 : loss : 0.041085, loss_ce: 0.021197
2021-12-11 20:12:45,470 iteration 1981 : loss : 0.046146, loss_ce: 0.013744
2021-12-11 20:12:46,931 iteration 1982 : loss : 0.042111, loss_ce: 0.015833
2021-12-11 20:12:48,536 iteration 1983 : loss : 0.048583, loss_ce: 0.026193
2021-12-11 20:12:50,013 iteration 1984 : loss : 0.040365, loss_ce: 0.010795
2021-12-11 20:12:51,561 iteration 1985 : loss : 0.027939, loss_ce: 0.010278
2021-12-11 20:12:53,110 iteration 1986 : loss : 0.046506, loss_ce: 0.021747
2021-12-11 20:12:54,710 iteration 1987 : loss : 0.034388, loss_ce: 0.015715
2021-12-11 20:12:56,188 iteration 1988 : loss : 0.036555, loss_ce: 0.010874
2021-12-11 20:12:57,732 iteration 1989 : loss : 0.041356, loss_ce: 0.021133
 29%|████████▍                    | 117/400 [55:31<2:12:41, 28.13s/it]2021-12-11 20:12:59,222 iteration 1990 : loss : 0.023024, loss_ce: 0.009955
2021-12-11 20:13:00,713 iteration 1991 : loss : 0.027385, loss_ce: 0.009930
2021-12-11 20:13:02,285 iteration 1992 : loss : 0.040146, loss_ce: 0.014739
2021-12-11 20:13:03,958 iteration 1993 : loss : 0.036129, loss_ce: 0.017567
2021-12-11 20:13:05,452 iteration 1994 : loss : 0.027705, loss_ce: 0.010592
2021-12-11 20:13:06,992 iteration 1995 : loss : 0.062556, loss_ce: 0.017003
2021-12-11 20:13:08,535 iteration 1996 : loss : 0.051293, loss_ce: 0.015862
2021-12-11 20:13:10,070 iteration 1997 : loss : 0.027597, loss_ce: 0.009119
2021-12-11 20:13:11,617 iteration 1998 : loss : 0.033386, loss_ce: 0.012586
2021-12-11 20:13:13,138 iteration 1999 : loss : 0.044128, loss_ce: 0.017050
2021-12-11 20:13:14,746 iteration 2000 : loss : 0.035096, loss_ce: 0.010104
2021-12-11 20:13:16,262 iteration 2001 : loss : 0.047110, loss_ce: 0.021336
2021-12-11 20:13:17,877 iteration 2002 : loss : 0.040872, loss_ce: 0.020904
2021-12-11 20:13:19,374 iteration 2003 : loss : 0.036013, loss_ce: 0.016274
2021-12-11 20:13:20,932 iteration 2004 : loss : 0.048670, loss_ce: 0.015880
2021-12-11 20:13:22,521 iteration 2005 : loss : 0.048470, loss_ce: 0.019344
2021-12-11 20:13:24,099 iteration 2006 : loss : 0.054330, loss_ce: 0.020279
 30%|████████▌                    | 118/400 [55:58<2:09:44, 27.60s/it]2021-12-11 20:13:25,705 iteration 2007 : loss : 0.037199, loss_ce: 0.015212
2021-12-11 20:13:27,216 iteration 2008 : loss : 0.044636, loss_ce: 0.019081
2021-12-11 20:13:28,753 iteration 2009 : loss : 0.066004, loss_ce: 0.019575
2021-12-11 20:13:30,237 iteration 2010 : loss : 0.040758, loss_ce: 0.015512
2021-12-11 20:13:31,762 iteration 2011 : loss : 0.035594, loss_ce: 0.014652
2021-12-11 20:13:33,310 iteration 2012 : loss : 0.046540, loss_ce: 0.016544
2021-12-11 20:13:34,901 iteration 2013 : loss : 0.037298, loss_ce: 0.012901
2021-12-11 20:13:36,479 iteration 2014 : loss : 0.040456, loss_ce: 0.014550
2021-12-11 20:13:37,948 iteration 2015 : loss : 0.031769, loss_ce: 0.011358
2021-12-11 20:13:39,479 iteration 2016 : loss : 0.041490, loss_ce: 0.012343
2021-12-11 20:13:40,920 iteration 2017 : loss : 0.032197, loss_ce: 0.013054
2021-12-11 20:13:42,447 iteration 2018 : loss : 0.051475, loss_ce: 0.020961
2021-12-11 20:13:43,930 iteration 2019 : loss : 0.029969, loss_ce: 0.012289
2021-12-11 20:13:45,507 iteration 2020 : loss : 0.041237, loss_ce: 0.016609
2021-12-11 20:13:47,082 iteration 2021 : loss : 0.034924, loss_ce: 0.013532
2021-12-11 20:13:48,680 iteration 2022 : loss : 0.036801, loss_ce: 0.015699
2021-12-11 20:13:50,213 iteration 2023 : loss : 0.042442, loss_ce: 0.014361
 30%|████████▋                    | 119/400 [56:24<2:07:10, 27.15s/it]2021-12-11 20:13:51,825 iteration 2024 : loss : 0.036023, loss_ce: 0.014912
2021-12-11 20:13:53,299 iteration 2025 : loss : 0.030497, loss_ce: 0.009823
2021-12-11 20:13:54,803 iteration 2026 : loss : 0.039673, loss_ce: 0.015600
2021-12-11 20:13:56,366 iteration 2027 : loss : 0.035931, loss_ce: 0.013586
2021-12-11 20:13:57,929 iteration 2028 : loss : 0.034638, loss_ce: 0.013722
2021-12-11 20:13:59,396 iteration 2029 : loss : 0.032081, loss_ce: 0.014239
2021-12-11 20:14:00,968 iteration 2030 : loss : 0.035356, loss_ce: 0.012771
2021-12-11 20:14:02,530 iteration 2031 : loss : 0.030214, loss_ce: 0.009941
2021-12-11 20:14:04,112 iteration 2032 : loss : 0.035256, loss_ce: 0.012428
2021-12-11 20:14:05,637 iteration 2033 : loss : 0.045863, loss_ce: 0.014282
2021-12-11 20:14:07,105 iteration 2034 : loss : 0.030694, loss_ce: 0.009857
2021-12-11 20:14:08,581 iteration 2035 : loss : 0.026097, loss_ce: 0.011650
2021-12-11 20:14:10,163 iteration 2036 : loss : 0.031512, loss_ce: 0.013201
2021-12-11 20:14:11,704 iteration 2037 : loss : 0.034810, loss_ce: 0.012445
2021-12-11 20:14:13,195 iteration 2038 : loss : 0.035401, loss_ce: 0.012734
2021-12-11 20:14:14,754 iteration 2039 : loss : 0.041512, loss_ce: 0.018083
2021-12-11 20:14:14,754 Training Data Eval:
2021-12-11 20:14:22,363   Average segmentation loss on training set: 0.0316
2021-12-11 20:14:22,364 Validation Data Eval:
2021-12-11 20:14:24,995   Average segmentation loss on validation set: 0.1175
2021-12-11 20:14:26,496 iteration 2040 : loss : 0.036212, loss_ce: 0.011059
 30%|████████▋                    | 120/400 [57:00<2:19:30, 29.89s/it]2021-12-11 20:14:28,076 iteration 2041 : loss : 0.032343, loss_ce: 0.012992
2021-12-11 20:14:29,598 iteration 2042 : loss : 0.032362, loss_ce: 0.012455
2021-12-11 20:14:31,130 iteration 2043 : loss : 0.029176, loss_ce: 0.012490
2021-12-11 20:14:32,725 iteration 2044 : loss : 0.030692, loss_ce: 0.012407
2021-12-11 20:14:34,340 iteration 2045 : loss : 0.034860, loss_ce: 0.011798
2021-12-11 20:14:35,914 iteration 2046 : loss : 0.053732, loss_ce: 0.023456
2021-12-11 20:14:37,481 iteration 2047 : loss : 0.033822, loss_ce: 0.010829
2021-12-11 20:14:38,955 iteration 2048 : loss : 0.031255, loss_ce: 0.010155
2021-12-11 20:14:40,464 iteration 2049 : loss : 0.033984, loss_ce: 0.011774
2021-12-11 20:14:42,036 iteration 2050 : loss : 0.047174, loss_ce: 0.015139
2021-12-11 20:14:43,623 iteration 2051 : loss : 0.040531, loss_ce: 0.013258
2021-12-11 20:14:45,120 iteration 2052 : loss : 0.037631, loss_ce: 0.019075
2021-12-11 20:14:46,660 iteration 2053 : loss : 0.029274, loss_ce: 0.009765
2021-12-11 20:14:48,202 iteration 2054 : loss : 0.038428, loss_ce: 0.013505
2021-12-11 20:14:49,778 iteration 2055 : loss : 0.055297, loss_ce: 0.025560
2021-12-11 20:14:51,334 iteration 2056 : loss : 0.040993, loss_ce: 0.015929
2021-12-11 20:14:52,908 iteration 2057 : loss : 0.030516, loss_ce: 0.011886
 30%|████████▊                    | 121/400 [57:27<2:14:09, 28.85s/it]2021-12-11 20:14:54,569 iteration 2058 : loss : 0.028152, loss_ce: 0.013167
2021-12-11 20:14:56,144 iteration 2059 : loss : 0.034368, loss_ce: 0.012067
2021-12-11 20:14:57,749 iteration 2060 : loss : 0.042651, loss_ce: 0.013428
2021-12-11 20:14:59,253 iteration 2061 : loss : 0.027686, loss_ce: 0.012987
2021-12-11 20:15:00,731 iteration 2062 : loss : 0.032019, loss_ce: 0.011261
2021-12-11 20:15:02,215 iteration 2063 : loss : 0.023876, loss_ce: 0.010149
2021-12-11 20:15:03,813 iteration 2064 : loss : 0.031076, loss_ce: 0.013823
2021-12-11 20:15:05,370 iteration 2065 : loss : 0.047943, loss_ce: 0.019029
2021-12-11 20:15:06,963 iteration 2066 : loss : 0.061253, loss_ce: 0.021711
2021-12-11 20:15:08,491 iteration 2067 : loss : 0.031094, loss_ce: 0.011454
2021-12-11 20:15:10,086 iteration 2068 : loss : 0.039038, loss_ce: 0.018345
2021-12-11 20:15:11,688 iteration 2069 : loss : 0.041225, loss_ce: 0.011653
2021-12-11 20:15:13,238 iteration 2070 : loss : 0.029643, loss_ce: 0.011713
2021-12-11 20:15:14,764 iteration 2071 : loss : 0.030546, loss_ce: 0.012504
2021-12-11 20:15:16,242 iteration 2072 : loss : 0.029942, loss_ce: 0.013248
2021-12-11 20:15:17,716 iteration 2073 : loss : 0.040201, loss_ce: 0.014334
2021-12-11 20:15:19,259 iteration 2074 : loss : 0.049397, loss_ce: 0.014163
 30%|████████▊                    | 122/400 [57:53<2:10:11, 28.10s/it]2021-12-11 20:15:20,855 iteration 2075 : loss : 0.030748, loss_ce: 0.010018
2021-12-11 20:15:22,465 iteration 2076 : loss : 0.042563, loss_ce: 0.013156
2021-12-11 20:15:24,023 iteration 2077 : loss : 0.031956, loss_ce: 0.012422
2021-12-11 20:15:25,524 iteration 2078 : loss : 0.036385, loss_ce: 0.017913
2021-12-11 20:15:27,056 iteration 2079 : loss : 0.048325, loss_ce: 0.018801
2021-12-11 20:15:28,654 iteration 2080 : loss : 0.040583, loss_ce: 0.013944
2021-12-11 20:15:30,209 iteration 2081 : loss : 0.036468, loss_ce: 0.016113
2021-12-11 20:15:31,758 iteration 2082 : loss : 0.035010, loss_ce: 0.011740
2021-12-11 20:15:33,315 iteration 2083 : loss : 0.027113, loss_ce: 0.010071
2021-12-11 20:15:34,854 iteration 2084 : loss : 0.035003, loss_ce: 0.012778
2021-12-11 20:15:36,348 iteration 2085 : loss : 0.038174, loss_ce: 0.017264
2021-12-11 20:15:37,878 iteration 2086 : loss : 0.027255, loss_ce: 0.012645
2021-12-11 20:15:39,363 iteration 2087 : loss : 0.043091, loss_ce: 0.014700
2021-12-11 20:15:41,012 iteration 2088 : loss : 0.047915, loss_ce: 0.022434
2021-12-11 20:15:42,532 iteration 2089 : loss : 0.035309, loss_ce: 0.012880
2021-12-11 20:15:44,124 iteration 2090 : loss : 0.031856, loss_ce: 0.010688
2021-12-11 20:15:45,664 iteration 2091 : loss : 0.041977, loss_ce: 0.017006
 31%|████████▉                    | 123/400 [58:19<2:07:22, 27.59s/it]2021-12-11 20:15:47,233 iteration 2092 : loss : 0.032298, loss_ce: 0.013936
2021-12-11 20:15:48,863 iteration 2093 : loss : 0.033440, loss_ce: 0.015521
2021-12-11 20:15:50,419 iteration 2094 : loss : 0.030149, loss_ce: 0.012934
2021-12-11 20:15:52,017 iteration 2095 : loss : 0.055143, loss_ce: 0.020816
2021-12-11 20:15:53,615 iteration 2096 : loss : 0.048374, loss_ce: 0.015545
2021-12-11 20:15:55,120 iteration 2097 : loss : 0.031532, loss_ce: 0.016050
2021-12-11 20:15:56,725 iteration 2098 : loss : 0.036309, loss_ce: 0.013411
2021-12-11 20:15:58,320 iteration 2099 : loss : 0.047108, loss_ce: 0.017192
2021-12-11 20:15:59,956 iteration 2100 : loss : 0.043718, loss_ce: 0.018486
2021-12-11 20:16:01,509 iteration 2101 : loss : 0.057370, loss_ce: 0.014460
2021-12-11 20:16:03,028 iteration 2102 : loss : 0.032359, loss_ce: 0.011562
2021-12-11 20:16:04,742 iteration 2103 : loss : 0.041087, loss_ce: 0.015715
2021-12-11 20:16:06,340 iteration 2104 : loss : 0.026188, loss_ce: 0.008850
2021-12-11 20:16:07,841 iteration 2105 : loss : 0.028469, loss_ce: 0.008060
2021-12-11 20:16:09,473 iteration 2106 : loss : 0.047464, loss_ce: 0.014181
2021-12-11 20:16:11,031 iteration 2107 : loss : 0.035029, loss_ce: 0.011706
2021-12-11 20:16:12,588 iteration 2108 : loss : 0.031482, loss_ce: 0.011298
 31%|████████▉                    | 124/400 [58:46<2:05:59, 27.39s/it]2021-12-11 20:16:14,176 iteration 2109 : loss : 0.055413, loss_ce: 0.021287
2021-12-11 20:16:15,704 iteration 2110 : loss : 0.033218, loss_ce: 0.009773
2021-12-11 20:16:17,380 iteration 2111 : loss : 0.045710, loss_ce: 0.014556
2021-12-11 20:16:19,059 iteration 2112 : loss : 0.036793, loss_ce: 0.014194
2021-12-11 20:16:20,568 iteration 2113 : loss : 0.029638, loss_ce: 0.010917
2021-12-11 20:16:22,085 iteration 2114 : loss : 0.038856, loss_ce: 0.017965
2021-12-11 20:16:23,519 iteration 2115 : loss : 0.051235, loss_ce: 0.015951
2021-12-11 20:16:25,084 iteration 2116 : loss : 0.038514, loss_ce: 0.015173
2021-12-11 20:16:26,701 iteration 2117 : loss : 0.042619, loss_ce: 0.013343
2021-12-11 20:16:28,250 iteration 2118 : loss : 0.043293, loss_ce: 0.019057
2021-12-11 20:16:29,822 iteration 2119 : loss : 0.041325, loss_ce: 0.014543
2021-12-11 20:16:31,363 iteration 2120 : loss : 0.054120, loss_ce: 0.020222
2021-12-11 20:16:33,003 iteration 2121 : loss : 0.042825, loss_ce: 0.015360
2021-12-11 20:16:34,499 iteration 2122 : loss : 0.036542, loss_ce: 0.013744
2021-12-11 20:16:36,075 iteration 2123 : loss : 0.036685, loss_ce: 0.019190
2021-12-11 20:16:37,652 iteration 2124 : loss : 0.050590, loss_ce: 0.019957
2021-12-11 20:16:37,652 Training Data Eval:
2021-12-11 20:16:45,279   Average segmentation loss on training set: 0.0259
2021-12-11 20:16:45,279 Validation Data Eval:
2021-12-11 20:16:47,922   Average segmentation loss on validation set: 0.0907
2021-12-11 20:16:49,482 iteration 2125 : loss : 0.026170, loss_ce: 0.009935
 31%|█████████                    | 125/400 [59:23<2:18:36, 30.24s/it]2021-12-11 20:16:51,069 iteration 2126 : loss : 0.030449, loss_ce: 0.010313
2021-12-11 20:16:52,727 iteration 2127 : loss : 0.036064, loss_ce: 0.013509
2021-12-11 20:16:54,223 iteration 2128 : loss : 0.027511, loss_ce: 0.012429
2021-12-11 20:16:55,786 iteration 2129 : loss : 0.032410, loss_ce: 0.013546
2021-12-11 20:16:57,283 iteration 2130 : loss : 0.040138, loss_ce: 0.012716
2021-12-11 20:16:58,911 iteration 2131 : loss : 0.045652, loss_ce: 0.019115
2021-12-11 20:17:00,537 iteration 2132 : loss : 0.036567, loss_ce: 0.014465
2021-12-11 20:17:02,133 iteration 2133 : loss : 0.043153, loss_ce: 0.016039
2021-12-11 20:17:03,739 iteration 2134 : loss : 0.049182, loss_ce: 0.017330
2021-12-11 20:17:05,307 iteration 2135 : loss : 0.036446, loss_ce: 0.011882
2021-12-11 20:17:06,861 iteration 2136 : loss : 0.037127, loss_ce: 0.014810
2021-12-11 20:17:08,418 iteration 2137 : loss : 0.053814, loss_ce: 0.016357
2021-12-11 20:17:09,921 iteration 2138 : loss : 0.040487, loss_ce: 0.014363
2021-12-11 20:17:11,390 iteration 2139 : loss : 0.030563, loss_ce: 0.013947
2021-12-11 20:17:12,897 iteration 2140 : loss : 0.036328, loss_ce: 0.011285
2021-12-11 20:17:14,442 iteration 2141 : loss : 0.044045, loss_ce: 0.017827
2021-12-11 20:17:15,986 iteration 2142 : loss : 0.057699, loss_ce: 0.028439
 32%|█████████▏                   | 126/400 [59:50<2:12:59, 29.12s/it]2021-12-11 20:17:17,596 iteration 2143 : loss : 0.035585, loss_ce: 0.009762
2021-12-11 20:17:19,135 iteration 2144 : loss : 0.052256, loss_ce: 0.016352
2021-12-11 20:17:20,599 iteration 2145 : loss : 0.027425, loss_ce: 0.014596
2021-12-11 20:17:22,292 iteration 2146 : loss : 0.033811, loss_ce: 0.012395
2021-12-11 20:17:23,907 iteration 2147 : loss : 0.033538, loss_ce: 0.012266
2021-12-11 20:17:25,466 iteration 2148 : loss : 0.036781, loss_ce: 0.014302
2021-12-11 20:17:27,034 iteration 2149 : loss : 0.057223, loss_ce: 0.022855
2021-12-11 20:17:28,646 iteration 2150 : loss : 0.037257, loss_ce: 0.013586
2021-12-11 20:17:30,251 iteration 2151 : loss : 0.035028, loss_ce: 0.013664
2021-12-11 20:17:31,739 iteration 2152 : loss : 0.026148, loss_ce: 0.010049
2021-12-11 20:17:33,256 iteration 2153 : loss : 0.045051, loss_ce: 0.014607
2021-12-11 20:17:34,730 iteration 2154 : loss : 0.030100, loss_ce: 0.013914
2021-12-11 20:17:36,233 iteration 2155 : loss : 0.032259, loss_ce: 0.012062
2021-12-11 20:17:37,814 iteration 2156 : loss : 0.038798, loss_ce: 0.015478
2021-12-11 20:17:39,361 iteration 2157 : loss : 0.039600, loss_ce: 0.014765
2021-12-11 20:17:40,909 iteration 2158 : loss : 0.039134, loss_ce: 0.015189
2021-12-11 20:17:42,493 iteration 2159 : loss : 0.057448, loss_ce: 0.017456
 32%|████████▌                  | 127/400 [1:00:16<2:08:56, 28.34s/it]2021-12-11 20:17:44,004 iteration 2160 : loss : 0.026138, loss_ce: 0.008942
2021-12-11 20:17:45,564 iteration 2161 : loss : 0.032532, loss_ce: 0.013508
2021-12-11 20:17:47,120 iteration 2162 : loss : 0.039170, loss_ce: 0.016694
2021-12-11 20:17:48,567 iteration 2163 : loss : 0.033173, loss_ce: 0.010063
2021-12-11 20:17:50,117 iteration 2164 : loss : 0.035230, loss_ce: 0.015691
2021-12-11 20:17:51,669 iteration 2165 : loss : 0.024339, loss_ce: 0.007568
2021-12-11 20:17:53,272 iteration 2166 : loss : 0.050897, loss_ce: 0.024094
2021-12-11 20:17:54,820 iteration 2167 : loss : 0.035098, loss_ce: 0.017262
2021-12-11 20:17:56,368 iteration 2168 : loss : 0.034062, loss_ce: 0.013354
2021-12-11 20:17:57,938 iteration 2169 : loss : 0.030796, loss_ce: 0.011918
2021-12-11 20:17:59,462 iteration 2170 : loss : 0.029531, loss_ce: 0.010204
2021-12-11 20:18:00,993 iteration 2171 : loss : 0.022749, loss_ce: 0.007019
2021-12-11 20:18:02,442 iteration 2172 : loss : 0.030255, loss_ce: 0.014022
2021-12-11 20:18:03,983 iteration 2173 : loss : 0.045195, loss_ce: 0.015264
2021-12-11 20:18:05,577 iteration 2174 : loss : 0.037794, loss_ce: 0.014026
2021-12-11 20:18:07,063 iteration 2175 : loss : 0.040351, loss_ce: 0.012022
2021-12-11 20:18:08,579 iteration 2176 : loss : 0.035947, loss_ce: 0.016022
 32%|████████▋                  | 128/400 [1:00:42<2:05:23, 27.66s/it]2021-12-11 20:18:10,279 iteration 2177 : loss : 0.042479, loss_ce: 0.015248
2021-12-11 20:18:11,763 iteration 2178 : loss : 0.024582, loss_ce: 0.010656
2021-12-11 20:18:13,304 iteration 2179 : loss : 0.031815, loss_ce: 0.013212
2021-12-11 20:18:14,870 iteration 2180 : loss : 0.030575, loss_ce: 0.009574
2021-12-11 20:18:16,384 iteration 2181 : loss : 0.038551, loss_ce: 0.014252
2021-12-11 20:18:17,965 iteration 2182 : loss : 0.029556, loss_ce: 0.009892
2021-12-11 20:18:19,469 iteration 2183 : loss : 0.033847, loss_ce: 0.011067
2021-12-11 20:18:20,946 iteration 2184 : loss : 0.036298, loss_ce: 0.018064
2021-12-11 20:18:22,393 iteration 2185 : loss : 0.031443, loss_ce: 0.012022
2021-12-11 20:18:24,028 iteration 2186 : loss : 0.058087, loss_ce: 0.026128
2021-12-11 20:18:25,500 iteration 2187 : loss : 0.025699, loss_ce: 0.013055
2021-12-11 20:18:27,101 iteration 2188 : loss : 0.033066, loss_ce: 0.013074
2021-12-11 20:18:28,591 iteration 2189 : loss : 0.032740, loss_ce: 0.012295
2021-12-11 20:18:30,182 iteration 2190 : loss : 0.029201, loss_ce: 0.010827
2021-12-11 20:18:31,653 iteration 2191 : loss : 0.030879, loss_ce: 0.013045
2021-12-11 20:18:33,188 iteration 2192 : loss : 0.033926, loss_ce: 0.012474
2021-12-11 20:18:34,799 iteration 2193 : loss : 0.047028, loss_ce: 0.020845
 32%|████████▋                  | 129/400 [1:01:08<2:02:59, 27.23s/it]2021-12-11 20:18:36,340 iteration 2194 : loss : 0.039583, loss_ce: 0.014593
2021-12-11 20:18:37,836 iteration 2195 : loss : 0.040374, loss_ce: 0.015429
2021-12-11 20:18:39,394 iteration 2196 : loss : 0.040917, loss_ce: 0.018463
2021-12-11 20:18:40,971 iteration 2197 : loss : 0.045062, loss_ce: 0.016385
2021-12-11 20:18:42,481 iteration 2198 : loss : 0.027541, loss_ce: 0.012543
2021-12-11 20:18:44,163 iteration 2199 : loss : 0.036124, loss_ce: 0.014951
2021-12-11 20:18:45,701 iteration 2200 : loss : 0.028749, loss_ce: 0.011993
2021-12-11 20:18:47,246 iteration 2201 : loss : 0.047730, loss_ce: 0.014691
2021-12-11 20:18:48,778 iteration 2202 : loss : 0.051000, loss_ce: 0.013895
2021-12-11 20:18:50,351 iteration 2203 : loss : 0.031025, loss_ce: 0.010508
2021-12-11 20:18:51,947 iteration 2204 : loss : 0.044627, loss_ce: 0.017093
2021-12-11 20:18:53,383 iteration 2205 : loss : 0.030105, loss_ce: 0.012295
2021-12-11 20:18:54,848 iteration 2206 : loss : 0.030050, loss_ce: 0.013876
2021-12-11 20:18:56,391 iteration 2207 : loss : 0.052712, loss_ce: 0.023967
2021-12-11 20:18:57,902 iteration 2208 : loss : 0.036775, loss_ce: 0.016404
2021-12-11 20:18:59,505 iteration 2209 : loss : 0.031575, loss_ce: 0.010488
2021-12-11 20:18:59,506 Training Data Eval:
2021-12-11 20:19:07,134   Average segmentation loss on training set: 0.0251
2021-12-11 20:19:07,135 Validation Data Eval:
2021-12-11 20:19:09,765   Average segmentation loss on validation set: 0.0816
2021-12-11 20:19:11,324 iteration 2210 : loss : 0.026292, loss_ce: 0.008946
 32%|████████▊                  | 130/400 [1:01:45<2:15:04, 30.02s/it]2021-12-11 20:19:12,931 iteration 2211 : loss : 0.038381, loss_ce: 0.018081
2021-12-11 20:19:14,397 iteration 2212 : loss : 0.023900, loss_ce: 0.007550
2021-12-11 20:19:15,880 iteration 2213 : loss : 0.026487, loss_ce: 0.009147
2021-12-11 20:19:17,433 iteration 2214 : loss : 0.029563, loss_ce: 0.011813
2021-12-11 20:19:18,950 iteration 2215 : loss : 0.023193, loss_ce: 0.008830
2021-12-11 20:19:20,454 iteration 2216 : loss : 0.026119, loss_ce: 0.011531
2021-12-11 20:19:21,915 iteration 2217 : loss : 0.032600, loss_ce: 0.014375
2021-12-11 20:19:23,464 iteration 2218 : loss : 0.026514, loss_ce: 0.009709
2021-12-11 20:19:24,988 iteration 2219 : loss : 0.034210, loss_ce: 0.012937
2021-12-11 20:19:26,533 iteration 2220 : loss : 0.030052, loss_ce: 0.014990
2021-12-11 20:19:28,143 iteration 2221 : loss : 0.041837, loss_ce: 0.018643
2021-12-11 20:19:29,671 iteration 2222 : loss : 0.045074, loss_ce: 0.014171
2021-12-11 20:19:31,325 iteration 2223 : loss : 0.041373, loss_ce: 0.014385
2021-12-11 20:19:32,839 iteration 2224 : loss : 0.056459, loss_ce: 0.015781
2021-12-11 20:19:34,363 iteration 2225 : loss : 0.026481, loss_ce: 0.009386
2021-12-11 20:19:36,035 iteration 2226 : loss : 0.041394, loss_ce: 0.016968
2021-12-11 20:19:37,629 iteration 2227 : loss : 0.038394, loss_ce: 0.012350
 33%|████████▊                  | 131/400 [1:02:11<2:09:35, 28.90s/it]2021-12-11 20:19:39,263 iteration 2228 : loss : 0.046650, loss_ce: 0.018801
2021-12-11 20:19:40,825 iteration 2229 : loss : 0.038996, loss_ce: 0.015747
2021-12-11 20:19:42,327 iteration 2230 : loss : 0.035373, loss_ce: 0.014196
2021-12-11 20:19:43,816 iteration 2231 : loss : 0.028308, loss_ce: 0.015179
2021-12-11 20:19:45,308 iteration 2232 : loss : 0.025734, loss_ce: 0.008901
2021-12-11 20:19:46,802 iteration 2233 : loss : 0.028268, loss_ce: 0.009264
2021-12-11 20:19:48,372 iteration 2234 : loss : 0.058286, loss_ce: 0.021942
2021-12-11 20:19:49,848 iteration 2235 : loss : 0.031881, loss_ce: 0.015029
2021-12-11 20:19:51,347 iteration 2236 : loss : 0.038036, loss_ce: 0.015714
2021-12-11 20:19:52,880 iteration 2237 : loss : 0.033848, loss_ce: 0.013862
2021-12-11 20:19:54,381 iteration 2238 : loss : 0.044046, loss_ce: 0.014707
2021-12-11 20:19:55,946 iteration 2239 : loss : 0.029555, loss_ce: 0.010517
2021-12-11 20:19:57,416 iteration 2240 : loss : 0.030654, loss_ce: 0.011574
2021-12-11 20:19:58,982 iteration 2241 : loss : 0.033378, loss_ce: 0.013913
2021-12-11 20:20:00,470 iteration 2242 : loss : 0.030521, loss_ce: 0.012892
2021-12-11 20:20:01,948 iteration 2243 : loss : 0.030170, loss_ce: 0.008260
2021-12-11 20:20:03,467 iteration 2244 : loss : 0.021293, loss_ce: 0.008016
 33%|████████▉                  | 132/400 [1:02:37<2:04:59, 27.98s/it]2021-12-11 20:20:05,007 iteration 2245 : loss : 0.028353, loss_ce: 0.012035
2021-12-11 20:20:06,574 iteration 2246 : loss : 0.033969, loss_ce: 0.014933
2021-12-11 20:20:08,102 iteration 2247 : loss : 0.036257, loss_ce: 0.012673
2021-12-11 20:20:09,534 iteration 2248 : loss : 0.022498, loss_ce: 0.009197
2021-12-11 20:20:11,138 iteration 2249 : loss : 0.033769, loss_ce: 0.013865
2021-12-11 20:20:12,797 iteration 2250 : loss : 0.035861, loss_ce: 0.013859
2021-12-11 20:20:14,261 iteration 2251 : loss : 0.033033, loss_ce: 0.012727
2021-12-11 20:20:15,819 iteration 2252 : loss : 0.028546, loss_ce: 0.009149
2021-12-11 20:20:17,299 iteration 2253 : loss : 0.039064, loss_ce: 0.012004
2021-12-11 20:20:18,900 iteration 2254 : loss : 0.047237, loss_ce: 0.019704
2021-12-11 20:20:20,489 iteration 2255 : loss : 0.027650, loss_ce: 0.012447
2021-12-11 20:20:22,116 iteration 2256 : loss : 0.052194, loss_ce: 0.019382
2021-12-11 20:20:23,642 iteration 2257 : loss : 0.039941, loss_ce: 0.012656
2021-12-11 20:20:25,178 iteration 2258 : loss : 0.048584, loss_ce: 0.019527
2021-12-11 20:20:26,760 iteration 2259 : loss : 0.043144, loss_ce: 0.013926
2021-12-11 20:20:28,319 iteration 2260 : loss : 0.057628, loss_ce: 0.024571
2021-12-11 20:20:29,811 iteration 2261 : loss : 0.043402, loss_ce: 0.012073
 33%|████████▉                  | 133/400 [1:03:03<2:02:20, 27.49s/it]2021-12-11 20:20:31,514 iteration 2262 : loss : 0.035443, loss_ce: 0.015236
2021-12-11 20:20:33,073 iteration 2263 : loss : 0.032355, loss_ce: 0.011721
2021-12-11 20:20:34,659 iteration 2264 : loss : 0.043012, loss_ce: 0.013047
2021-12-11 20:20:36,229 iteration 2265 : loss : 0.030727, loss_ce: 0.011878
2021-12-11 20:20:37,760 iteration 2266 : loss : 0.036157, loss_ce: 0.012668
2021-12-11 20:20:39,290 iteration 2267 : loss : 0.033653, loss_ce: 0.010660
2021-12-11 20:20:40,754 iteration 2268 : loss : 0.033283, loss_ce: 0.013617
2021-12-11 20:20:42,299 iteration 2269 : loss : 0.052350, loss_ce: 0.020917
2021-12-11 20:20:43,785 iteration 2270 : loss : 0.031085, loss_ce: 0.011858
2021-12-11 20:20:45,283 iteration 2271 : loss : 0.056884, loss_ce: 0.034548
2021-12-11 20:20:46,769 iteration 2272 : loss : 0.037056, loss_ce: 0.010411
2021-12-11 20:20:48,341 iteration 2273 : loss : 0.041742, loss_ce: 0.012105
2021-12-11 20:20:49,818 iteration 2274 : loss : 0.036056, loss_ce: 0.011570
2021-12-11 20:20:51,325 iteration 2275 : loss : 0.030413, loss_ce: 0.013252
2021-12-11 20:20:52,871 iteration 2276 : loss : 0.060071, loss_ce: 0.019887
2021-12-11 20:20:54,380 iteration 2277 : loss : 0.034056, loss_ce: 0.014621
2021-12-11 20:20:55,911 iteration 2278 : loss : 0.035906, loss_ce: 0.015066
 34%|█████████                  | 134/400 [1:03:30<2:00:02, 27.08s/it]2021-12-11 20:20:57,584 iteration 2279 : loss : 0.053027, loss_ce: 0.029241
2021-12-11 20:20:59,152 iteration 2280 : loss : 0.033741, loss_ce: 0.015305
2021-12-11 20:21:00,622 iteration 2281 : loss : 0.032519, loss_ce: 0.011449
2021-12-11 20:21:02,272 iteration 2282 : loss : 0.051836, loss_ce: 0.020779
2021-12-11 20:21:03,773 iteration 2283 : loss : 0.032770, loss_ce: 0.011640
2021-12-11 20:21:05,395 iteration 2284 : loss : 0.058603, loss_ce: 0.020173
2021-12-11 20:21:06,896 iteration 2285 : loss : 0.030743, loss_ce: 0.011646
2021-12-11 20:21:08,418 iteration 2286 : loss : 0.028231, loss_ce: 0.010684
2021-12-11 20:21:09,989 iteration 2287 : loss : 0.041192, loss_ce: 0.012769
2021-12-11 20:21:11,446 iteration 2288 : loss : 0.039203, loss_ce: 0.015937
2021-12-11 20:21:13,007 iteration 2289 : loss : 0.032261, loss_ce: 0.012071
2021-12-11 20:21:14,549 iteration 2290 : loss : 0.036016, loss_ce: 0.014337
2021-12-11 20:21:16,065 iteration 2291 : loss : 0.035352, loss_ce: 0.011603
2021-12-11 20:21:17,663 iteration 2292 : loss : 0.049796, loss_ce: 0.016128
2021-12-11 20:21:19,154 iteration 2293 : loss : 0.038396, loss_ce: 0.014683
2021-12-11 20:21:20,677 iteration 2294 : loss : 0.036516, loss_ce: 0.015386
2021-12-11 20:21:20,677 Training Data Eval:
2021-12-11 20:21:28,289   Average segmentation loss on training set: 0.0415
2021-12-11 20:21:28,289 Validation Data Eval:
2021-12-11 20:21:30,923   Average segmentation loss on validation set: 0.0841
2021-12-11 20:21:32,461 iteration 2295 : loss : 0.033153, loss_ce: 0.011263
 34%|█████████                  | 135/400 [1:04:06<2:12:07, 29.92s/it]2021-12-11 20:21:34,036 iteration 2296 : loss : 0.038618, loss_ce: 0.014425
2021-12-11 20:21:35,615 iteration 2297 : loss : 0.044462, loss_ce: 0.014131
2021-12-11 20:21:37,276 iteration 2298 : loss : 0.050681, loss_ce: 0.017855
2021-12-11 20:21:38,807 iteration 2299 : loss : 0.040230, loss_ce: 0.010772
2021-12-11 20:21:40,434 iteration 2300 : loss : 0.048205, loss_ce: 0.017131
2021-12-11 20:21:41,954 iteration 2301 : loss : 0.031549, loss_ce: 0.014215
2021-12-11 20:21:43,477 iteration 2302 : loss : 0.033762, loss_ce: 0.017328
2021-12-11 20:21:44,974 iteration 2303 : loss : 0.030490, loss_ce: 0.009481
2021-12-11 20:21:46,433 iteration 2304 : loss : 0.040290, loss_ce: 0.016423
2021-12-11 20:21:48,004 iteration 2305 : loss : 0.040114, loss_ce: 0.014193
2021-12-11 20:21:49,484 iteration 2306 : loss : 0.040498, loss_ce: 0.013264
2021-12-11 20:21:50,957 iteration 2307 : loss : 0.031012, loss_ce: 0.012915
2021-12-11 20:21:52,494 iteration 2308 : loss : 0.039639, loss_ce: 0.018013
2021-12-11 20:21:54,045 iteration 2309 : loss : 0.035725, loss_ce: 0.014280
2021-12-11 20:21:55,608 iteration 2310 : loss : 0.041821, loss_ce: 0.020529
2021-12-11 20:21:57,230 iteration 2311 : loss : 0.043920, loss_ce: 0.019842
2021-12-11 20:21:58,780 iteration 2312 : loss : 0.030237, loss_ce: 0.011663
 34%|█████████▏                 | 136/400 [1:04:32<2:06:53, 28.84s/it]2021-12-11 20:22:00,351 iteration 2313 : loss : 0.036750, loss_ce: 0.017462
2021-12-11 20:22:01,840 iteration 2314 : loss : 0.033865, loss_ce: 0.013293
2021-12-11 20:22:03,377 iteration 2315 : loss : 0.026945, loss_ce: 0.009941
2021-12-11 20:22:04,953 iteration 2316 : loss : 0.029440, loss_ce: 0.013194
2021-12-11 20:22:06,412 iteration 2317 : loss : 0.041280, loss_ce: 0.016367
2021-12-11 20:22:08,004 iteration 2318 : loss : 0.028671, loss_ce: 0.012870
2021-12-11 20:22:09,622 iteration 2319 : loss : 0.054685, loss_ce: 0.015760
2021-12-11 20:22:11,115 iteration 2320 : loss : 0.040404, loss_ce: 0.020134
2021-12-11 20:22:12,641 iteration 2321 : loss : 0.048414, loss_ce: 0.014422
2021-12-11 20:22:14,199 iteration 2322 : loss : 0.025245, loss_ce: 0.009730
2021-12-11 20:22:15,805 iteration 2323 : loss : 0.046617, loss_ce: 0.016381
2021-12-11 20:22:17,358 iteration 2324 : loss : 0.037030, loss_ce: 0.010865
2021-12-11 20:22:18,900 iteration 2325 : loss : 0.034109, loss_ce: 0.017043
2021-12-11 20:22:20,476 iteration 2326 : loss : 0.037542, loss_ce: 0.019183
2021-12-11 20:22:22,027 iteration 2327 : loss : 0.026217, loss_ce: 0.008915
2021-12-11 20:22:23,679 iteration 2328 : loss : 0.037627, loss_ce: 0.015186
2021-12-11 20:22:25,200 iteration 2329 : loss : 0.046224, loss_ce: 0.017277
 34%|█████████▏                 | 137/400 [1:04:59<2:03:13, 28.11s/it]2021-12-11 20:22:26,754 iteration 2330 : loss : 0.029322, loss_ce: 0.011185
2021-12-11 20:22:28,245 iteration 2331 : loss : 0.040679, loss_ce: 0.012666
2021-12-11 20:22:29,853 iteration 2332 : loss : 0.063397, loss_ce: 0.030858
2021-12-11 20:22:31,330 iteration 2333 : loss : 0.028392, loss_ce: 0.014820
2021-12-11 20:22:32,849 iteration 2334 : loss : 0.032999, loss_ce: 0.007649
2021-12-11 20:22:34,498 iteration 2335 : loss : 0.051688, loss_ce: 0.024271
2021-12-11 20:22:36,001 iteration 2336 : loss : 0.026698, loss_ce: 0.012697
2021-12-11 20:22:37,545 iteration 2337 : loss : 0.027440, loss_ce: 0.011063
2021-12-11 20:22:39,110 iteration 2338 : loss : 0.037843, loss_ce: 0.014763
2021-12-11 20:22:40,667 iteration 2339 : loss : 0.058326, loss_ce: 0.021963
2021-12-11 20:22:42,243 iteration 2340 : loss : 0.046262, loss_ce: 0.017844
2021-12-11 20:22:43,782 iteration 2341 : loss : 0.035839, loss_ce: 0.013135
2021-12-11 20:22:45,354 iteration 2342 : loss : 0.024195, loss_ce: 0.008909
2021-12-11 20:22:46,903 iteration 2343 : loss : 0.028358, loss_ce: 0.010807
2021-12-11 20:22:48,358 iteration 2344 : loss : 0.025952, loss_ce: 0.008867
2021-12-11 20:22:49,852 iteration 2345 : loss : 0.036148, loss_ce: 0.013394
2021-12-11 20:22:51,308 iteration 2346 : loss : 0.033288, loss_ce: 0.011446
 34%|█████████▎                 | 138/400 [1:05:25<2:00:07, 27.51s/it]2021-12-11 20:22:52,941 iteration 2347 : loss : 0.040313, loss_ce: 0.016083
2021-12-11 20:22:54,444 iteration 2348 : loss : 0.032715, loss_ce: 0.011799
2021-12-11 20:22:56,006 iteration 2349 : loss : 0.047639, loss_ce: 0.024229
2021-12-11 20:22:57,459 iteration 2350 : loss : 0.032600, loss_ce: 0.016005
2021-12-11 20:22:59,014 iteration 2351 : loss : 0.045801, loss_ce: 0.014779
2021-12-11 20:23:00,638 iteration 2352 : loss : 0.034918, loss_ce: 0.014822
2021-12-11 20:23:02,089 iteration 2353 : loss : 0.027997, loss_ce: 0.011942
2021-12-11 20:23:03,629 iteration 2354 : loss : 0.032534, loss_ce: 0.009687
2021-12-11 20:23:05,109 iteration 2355 : loss : 0.029311, loss_ce: 0.013302
2021-12-11 20:23:06,740 iteration 2356 : loss : 0.059610, loss_ce: 0.021539
2021-12-11 20:23:08,343 iteration 2357 : loss : 0.036051, loss_ce: 0.015686
2021-12-11 20:23:10,032 iteration 2358 : loss : 0.052857, loss_ce: 0.021322
2021-12-11 20:23:11,623 iteration 2359 : loss : 0.041113, loss_ce: 0.015301
2021-12-11 20:23:13,069 iteration 2360 : loss : 0.053380, loss_ce: 0.011668
2021-12-11 20:23:14,551 iteration 2361 : loss : 0.040313, loss_ce: 0.013838
2021-12-11 20:23:16,082 iteration 2362 : loss : 0.037589, loss_ce: 0.015583
2021-12-11 20:23:17,615 iteration 2363 : loss : 0.028822, loss_ce: 0.009128
 35%|█████████▍                 | 139/400 [1:05:51<1:58:06, 27.15s/it]2021-12-11 20:23:19,189 iteration 2364 : loss : 0.048718, loss_ce: 0.020546
2021-12-11 20:23:20,665 iteration 2365 : loss : 0.044989, loss_ce: 0.013521
2021-12-11 20:23:22,231 iteration 2366 : loss : 0.034026, loss_ce: 0.014782
2021-12-11 20:23:23,730 iteration 2367 : loss : 0.049328, loss_ce: 0.015329
2021-12-11 20:23:25,350 iteration 2368 : loss : 0.053544, loss_ce: 0.017846
2021-12-11 20:23:26,889 iteration 2369 : loss : 0.051807, loss_ce: 0.018527
2021-12-11 20:23:28,389 iteration 2370 : loss : 0.021633, loss_ce: 0.007352
2021-12-11 20:23:29,936 iteration 2371 : loss : 0.037847, loss_ce: 0.016430
2021-12-11 20:23:31,400 iteration 2372 : loss : 0.033129, loss_ce: 0.015946
2021-12-11 20:23:32,935 iteration 2373 : loss : 0.028314, loss_ce: 0.009596
2021-12-11 20:23:34,525 iteration 2374 : loss : 0.040881, loss_ce: 0.014825
2021-12-11 20:23:36,012 iteration 2375 : loss : 0.040443, loss_ce: 0.013953
2021-12-11 20:23:37,595 iteration 2376 : loss : 0.034693, loss_ce: 0.015102
2021-12-11 20:23:39,115 iteration 2377 : loss : 0.038443, loss_ce: 0.012760
2021-12-11 20:23:40,766 iteration 2378 : loss : 0.045469, loss_ce: 0.023466
2021-12-11 20:23:42,332 iteration 2379 : loss : 0.050183, loss_ce: 0.015889
2021-12-11 20:23:42,332 Training Data Eval:
2021-12-11 20:23:49,967   Average segmentation loss on training set: 0.0345
2021-12-11 20:23:49,967 Validation Data Eval:
2021-12-11 20:23:52,603   Average segmentation loss on validation set: 0.1214
2021-12-11 20:23:54,265 iteration 2380 : loss : 0.035190, loss_ce: 0.014553
 35%|█████████▍                 | 140/400 [1:06:28<2:09:59, 30.00s/it]2021-12-11 20:23:55,819 iteration 2381 : loss : 0.033853, loss_ce: 0.011628
2021-12-11 20:23:57,417 iteration 2382 : loss : 0.050832, loss_ce: 0.025060
2021-12-11 20:23:59,012 iteration 2383 : loss : 0.036245, loss_ce: 0.014019
2021-12-11 20:24:00,553 iteration 2384 : loss : 0.043237, loss_ce: 0.013673
2021-12-11 20:24:02,123 iteration 2385 : loss : 0.038179, loss_ce: 0.018272
2021-12-11 20:24:03,750 iteration 2386 : loss : 0.043829, loss_ce: 0.015491
2021-12-11 20:24:05,265 iteration 2387 : loss : 0.050513, loss_ce: 0.016952
2021-12-11 20:24:06,832 iteration 2388 : loss : 0.024410, loss_ce: 0.010506
2021-12-11 20:24:08,326 iteration 2389 : loss : 0.033397, loss_ce: 0.012224
2021-12-11 20:24:09,878 iteration 2390 : loss : 0.026121, loss_ce: 0.010281
2021-12-11 20:24:11,376 iteration 2391 : loss : 0.031574, loss_ce: 0.010816
2021-12-11 20:24:12,850 iteration 2392 : loss : 0.030309, loss_ce: 0.011836
2021-12-11 20:24:14,333 iteration 2393 : loss : 0.034622, loss_ce: 0.013532
2021-12-11 20:24:15,882 iteration 2394 : loss : 0.056300, loss_ce: 0.013319
2021-12-11 20:24:17,558 iteration 2395 : loss : 0.055585, loss_ce: 0.015624
2021-12-11 20:24:19,169 iteration 2396 : loss : 0.025003, loss_ce: 0.010039
2021-12-11 20:24:20,721 iteration 2397 : loss : 0.037493, loss_ce: 0.012936
 35%|█████████▌                 | 141/400 [1:06:54<2:04:54, 28.94s/it]2021-12-11 20:24:22,408 iteration 2398 : loss : 0.040182, loss_ce: 0.021424
2021-12-11 20:24:23,874 iteration 2399 : loss : 0.025206, loss_ce: 0.009281
2021-12-11 20:24:25,384 iteration 2400 : loss : 0.032631, loss_ce: 0.008886
2021-12-11 20:24:26,929 iteration 2401 : loss : 0.030593, loss_ce: 0.010320
2021-12-11 20:24:28,427 iteration 2402 : loss : 0.032044, loss_ce: 0.013308
2021-12-11 20:24:29,961 iteration 2403 : loss : 0.023728, loss_ce: 0.008531
2021-12-11 20:24:31,469 iteration 2404 : loss : 0.030600, loss_ce: 0.014304
2021-12-11 20:24:33,005 iteration 2405 : loss : 0.033171, loss_ce: 0.011926
2021-12-11 20:24:34,606 iteration 2406 : loss : 0.044383, loss_ce: 0.018221
2021-12-11 20:24:36,097 iteration 2407 : loss : 0.024812, loss_ce: 0.008654
2021-12-11 20:24:37,631 iteration 2408 : loss : 0.037921, loss_ce: 0.016208
2021-12-11 20:24:39,183 iteration 2409 : loss : 0.040515, loss_ce: 0.014732
2021-12-11 20:24:40,762 iteration 2410 : loss : 0.055197, loss_ce: 0.014559
2021-12-11 20:24:42,248 iteration 2411 : loss : 0.032153, loss_ce: 0.010070
2021-12-11 20:24:43,886 iteration 2412 : loss : 0.041451, loss_ce: 0.016019
2021-12-11 20:24:45,509 iteration 2413 : loss : 0.048824, loss_ce: 0.023113
2021-12-11 20:24:47,106 iteration 2414 : loss : 0.037433, loss_ce: 0.015527
 36%|█████████▌                 | 142/400 [1:07:21<2:01:07, 28.17s/it]2021-12-11 20:24:48,698 iteration 2415 : loss : 0.033319, loss_ce: 0.010661
2021-12-11 20:24:50,238 iteration 2416 : loss : 0.039447, loss_ce: 0.021679
2021-12-11 20:24:51,791 iteration 2417 : loss : 0.031573, loss_ce: 0.010292
2021-12-11 20:24:53,363 iteration 2418 : loss : 0.038031, loss_ce: 0.011591
2021-12-11 20:24:54,906 iteration 2419 : loss : 0.028359, loss_ce: 0.013026
2021-12-11 20:24:56,392 iteration 2420 : loss : 0.038272, loss_ce: 0.014625
2021-12-11 20:24:58,038 iteration 2421 : loss : 0.032851, loss_ce: 0.010223
2021-12-11 20:24:59,600 iteration 2422 : loss : 0.036003, loss_ce: 0.011234
2021-12-11 20:25:01,152 iteration 2423 : loss : 0.035676, loss_ce: 0.016342
2021-12-11 20:25:02,649 iteration 2424 : loss : 0.029008, loss_ce: 0.009812
2021-12-11 20:25:04,269 iteration 2425 : loss : 0.034067, loss_ce: 0.016128
2021-12-11 20:25:05,814 iteration 2426 : loss : 0.029146, loss_ce: 0.010995
2021-12-11 20:25:07,456 iteration 2427 : loss : 0.068322, loss_ce: 0.023078
2021-12-11 20:25:09,072 iteration 2428 : loss : 0.043400, loss_ce: 0.018689
2021-12-11 20:25:10,703 iteration 2429 : loss : 0.034884, loss_ce: 0.013913
2021-12-11 20:25:12,241 iteration 2430 : loss : 0.040900, loss_ce: 0.018503
2021-12-11 20:25:13,737 iteration 2431 : loss : 0.027351, loss_ce: 0.012055
 36%|█████████▋                 | 143/400 [1:07:47<1:58:42, 27.71s/it]2021-12-11 20:25:15,410 iteration 2432 : loss : 0.036421, loss_ce: 0.015099
2021-12-11 20:25:16,965 iteration 2433 : loss : 0.069573, loss_ce: 0.029494
2021-12-11 20:25:18,518 iteration 2434 : loss : 0.035597, loss_ce: 0.010576
2021-12-11 20:25:20,181 iteration 2435 : loss : 0.029518, loss_ce: 0.015796
2021-12-11 20:25:21,630 iteration 2436 : loss : 0.032775, loss_ce: 0.011553
2021-12-11 20:25:23,088 iteration 2437 : loss : 0.026257, loss_ce: 0.010522
2021-12-11 20:25:24,772 iteration 2438 : loss : 0.042191, loss_ce: 0.017402
2021-12-11 20:25:26,333 iteration 2439 : loss : 0.035282, loss_ce: 0.014625
2021-12-11 20:25:27,857 iteration 2440 : loss : 0.043060, loss_ce: 0.015332
2021-12-11 20:25:29,370 iteration 2441 : loss : 0.035381, loss_ce: 0.011348
2021-12-11 20:25:30,860 iteration 2442 : loss : 0.042895, loss_ce: 0.014373
2021-12-11 20:25:32,342 iteration 2443 : loss : 0.026907, loss_ce: 0.011669
2021-12-11 20:25:33,907 iteration 2444 : loss : 0.028674, loss_ce: 0.010468
2021-12-11 20:25:35,350 iteration 2445 : loss : 0.044350, loss_ce: 0.009344
2021-12-11 20:25:36,974 iteration 2446 : loss : 0.041365, loss_ce: 0.013851
2021-12-11 20:25:38,585 iteration 2447 : loss : 0.042580, loss_ce: 0.017585
2021-12-11 20:25:40,118 iteration 2448 : loss : 0.028834, loss_ce: 0.010034
 36%|█████████▋                 | 144/400 [1:08:14<1:56:31, 27.31s/it]2021-12-11 20:25:41,677 iteration 2449 : loss : 0.033565, loss_ce: 0.013616
2021-12-11 20:25:43,283 iteration 2450 : loss : 0.039682, loss_ce: 0.014666
2021-12-11 20:25:44,885 iteration 2451 : loss : 0.040946, loss_ce: 0.017167
2021-12-11 20:25:46,348 iteration 2452 : loss : 0.025743, loss_ce: 0.011906
2021-12-11 20:25:47,864 iteration 2453 : loss : 0.035168, loss_ce: 0.008732
2021-12-11 20:25:49,439 iteration 2454 : loss : 0.046454, loss_ce: 0.023784
2021-12-11 20:25:51,007 iteration 2455 : loss : 0.045804, loss_ce: 0.027022
2021-12-11 20:25:52,685 iteration 2456 : loss : 0.046265, loss_ce: 0.017645
2021-12-11 20:25:54,219 iteration 2457 : loss : 0.039127, loss_ce: 0.013992
2021-12-11 20:25:55,837 iteration 2458 : loss : 0.036646, loss_ce: 0.011437
2021-12-11 20:25:57,334 iteration 2459 : loss : 0.046661, loss_ce: 0.013822
2021-12-11 20:25:58,875 iteration 2460 : loss : 0.030087, loss_ce: 0.009303
2021-12-11 20:26:00,438 iteration 2461 : loss : 0.036989, loss_ce: 0.013428
2021-12-11 20:26:01,958 iteration 2462 : loss : 0.035314, loss_ce: 0.016253
2021-12-11 20:26:03,566 iteration 2463 : loss : 0.044201, loss_ce: 0.014863
2021-12-11 20:26:05,180 iteration 2464 : loss : 0.027884, loss_ce: 0.011809
2021-12-11 20:26:05,180 Training Data Eval:
2021-12-11 20:26:12,828   Average segmentation loss on training set: 0.0323
2021-12-11 20:26:12,829 Validation Data Eval:
2021-12-11 20:26:15,474   Average segmentation loss on validation set: 0.1277
2021-12-11 20:26:16,991 iteration 2465 : loss : 0.029834, loss_ce: 0.010495
 36%|█████████▊                 | 145/400 [1:08:51<2:08:15, 30.18s/it]2021-12-11 20:26:18,546 iteration 2466 : loss : 0.028488, loss_ce: 0.010726
2021-12-11 20:26:20,148 iteration 2467 : loss : 0.044223, loss_ce: 0.024718
2021-12-11 20:26:21,654 iteration 2468 : loss : 0.027472, loss_ce: 0.011842
2021-12-11 20:26:23,117 iteration 2469 : loss : 0.020208, loss_ce: 0.009722
2021-12-11 20:26:24,712 iteration 2470 : loss : 0.047774, loss_ce: 0.019242
2021-12-11 20:26:26,318 iteration 2471 : loss : 0.036257, loss_ce: 0.013388
2021-12-11 20:26:27,965 iteration 2472 : loss : 0.031484, loss_ce: 0.011621
2021-12-11 20:26:29,433 iteration 2473 : loss : 0.033386, loss_ce: 0.012309
2021-12-11 20:26:31,007 iteration 2474 : loss : 0.042236, loss_ce: 0.016468
2021-12-11 20:26:32,483 iteration 2475 : loss : 0.025826, loss_ce: 0.010615
2021-12-11 20:26:34,083 iteration 2476 : loss : 0.051548, loss_ce: 0.015388
2021-12-11 20:26:35,611 iteration 2477 : loss : 0.024840, loss_ce: 0.009941
2021-12-11 20:26:37,145 iteration 2478 : loss : 0.033182, loss_ce: 0.009336
2021-12-11 20:26:38,792 iteration 2479 : loss : 0.035503, loss_ce: 0.011295
2021-12-11 20:26:40,394 iteration 2480 : loss : 0.061399, loss_ce: 0.021652
2021-12-11 20:26:41,907 iteration 2481 : loss : 0.028840, loss_ce: 0.010988
2021-12-11 20:26:43,465 iteration 2482 : loss : 0.028326, loss_ce: 0.010066
 36%|█████████▊                 | 146/400 [1:09:17<2:03:03, 29.07s/it]2021-12-11 20:26:45,043 iteration 2483 : loss : 0.027180, loss_ce: 0.009780
2021-12-11 20:26:46,640 iteration 2484 : loss : 0.049724, loss_ce: 0.013552
2021-12-11 20:26:48,260 iteration 2485 : loss : 0.037067, loss_ce: 0.012908
2021-12-11 20:26:49,797 iteration 2486 : loss : 0.025282, loss_ce: 0.011750
2021-12-11 20:26:51,314 iteration 2487 : loss : 0.029865, loss_ce: 0.010601
2021-12-11 20:26:52,907 iteration 2488 : loss : 0.022543, loss_ce: 0.008267
2021-12-11 20:26:54,515 iteration 2489 : loss : 0.041841, loss_ce: 0.016256
2021-12-11 20:26:56,030 iteration 2490 : loss : 0.027835, loss_ce: 0.011982
2021-12-11 20:26:57,577 iteration 2491 : loss : 0.034998, loss_ce: 0.013322
2021-12-11 20:26:59,075 iteration 2492 : loss : 0.040417, loss_ce: 0.015977
2021-12-11 20:27:00,587 iteration 2493 : loss : 0.026023, loss_ce: 0.008021
2021-12-11 20:27:02,071 iteration 2494 : loss : 0.035340, loss_ce: 0.015468
2021-12-11 20:27:03,594 iteration 2495 : loss : 0.041125, loss_ce: 0.012401
2021-12-11 20:27:05,173 iteration 2496 : loss : 0.045784, loss_ce: 0.012933
2021-12-11 20:27:06,753 iteration 2497 : loss : 0.045777, loss_ce: 0.018440
2021-12-11 20:27:08,213 iteration 2498 : loss : 0.033808, loss_ce: 0.014290
2021-12-11 20:27:09,811 iteration 2499 : loss : 0.031312, loss_ce: 0.014715
 37%|█████████▉                 | 147/400 [1:09:43<1:59:06, 28.25s/it]2021-12-11 20:27:11,417 iteration 2500 : loss : 0.040927, loss_ce: 0.015389
2021-12-11 20:27:12,898 iteration 2501 : loss : 0.028266, loss_ce: 0.009012
2021-12-11 20:27:14,429 iteration 2502 : loss : 0.037387, loss_ce: 0.012697
2021-12-11 20:27:15,976 iteration 2503 : loss : 0.033274, loss_ce: 0.015939
2021-12-11 20:27:17,555 iteration 2504 : loss : 0.039365, loss_ce: 0.014514
2021-12-11 20:27:19,026 iteration 2505 : loss : 0.021404, loss_ce: 0.009134
2021-12-11 20:27:20,531 iteration 2506 : loss : 0.037617, loss_ce: 0.009342
2021-12-11 20:27:22,103 iteration 2507 : loss : 0.024553, loss_ce: 0.008976
2021-12-11 20:27:23,631 iteration 2508 : loss : 0.027528, loss_ce: 0.012443
2021-12-11 20:27:25,234 iteration 2509 : loss : 0.034024, loss_ce: 0.013317
2021-12-11 20:27:26,762 iteration 2510 : loss : 0.030285, loss_ce: 0.009596
2021-12-11 20:27:28,244 iteration 2511 : loss : 0.032726, loss_ce: 0.014717
2021-12-11 20:27:29,835 iteration 2512 : loss : 0.026990, loss_ce: 0.009130
2021-12-11 20:27:31,348 iteration 2513 : loss : 0.027435, loss_ce: 0.011173
2021-12-11 20:27:32,926 iteration 2514 : loss : 0.041346, loss_ce: 0.015086
2021-12-11 20:27:34,442 iteration 2515 : loss : 0.033783, loss_ce: 0.015981
2021-12-11 20:27:36,200 iteration 2516 : loss : 0.038154, loss_ce: 0.018253
 37%|█████████▉                 | 148/400 [1:10:10<1:56:18, 27.69s/it]2021-12-11 20:27:37,796 iteration 2517 : loss : 0.035633, loss_ce: 0.012087
2021-12-11 20:27:39,377 iteration 2518 : loss : 0.032626, loss_ce: 0.008782
2021-12-11 20:27:40,853 iteration 2519 : loss : 0.024099, loss_ce: 0.007777
2021-12-11 20:27:42,431 iteration 2520 : loss : 0.032023, loss_ce: 0.014943
2021-12-11 20:27:43,981 iteration 2521 : loss : 0.036596, loss_ce: 0.017119
2021-12-11 20:27:45,553 iteration 2522 : loss : 0.044675, loss_ce: 0.016867
2021-12-11 20:27:47,097 iteration 2523 : loss : 0.042690, loss_ce: 0.012177
2021-12-11 20:27:48,681 iteration 2524 : loss : 0.027948, loss_ce: 0.011679
2021-12-11 20:27:50,194 iteration 2525 : loss : 0.035122, loss_ce: 0.009672
2021-12-11 20:27:51,682 iteration 2526 : loss : 0.028897, loss_ce: 0.010510
2021-12-11 20:27:53,236 iteration 2527 : loss : 0.040468, loss_ce: 0.018972
2021-12-11 20:27:54,806 iteration 2528 : loss : 0.031570, loss_ce: 0.014000
2021-12-11 20:27:56,370 iteration 2529 : loss : 0.031963, loss_ce: 0.012544
2021-12-11 20:27:57,841 iteration 2530 : loss : 0.045074, loss_ce: 0.016378
2021-12-11 20:27:59,401 iteration 2531 : loss : 0.034632, loss_ce: 0.010105
2021-12-11 20:28:01,011 iteration 2532 : loss : 0.047331, loss_ce: 0.020800
2021-12-11 20:28:02,494 iteration 2533 : loss : 0.038627, loss_ce: 0.009230
 37%|██████████                 | 149/400 [1:10:36<1:54:05, 27.27s/it]2021-12-11 20:28:04,082 iteration 2534 : loss : 0.029004, loss_ce: 0.010293
2021-12-11 20:28:05,526 iteration 2535 : loss : 0.037946, loss_ce: 0.014369
2021-12-11 20:28:07,018 iteration 2536 : loss : 0.021493, loss_ce: 0.008663
2021-12-11 20:28:08,648 iteration 2537 : loss : 0.049512, loss_ce: 0.025276
2021-12-11 20:28:10,069 iteration 2538 : loss : 0.033507, loss_ce: 0.010627
2021-12-11 20:28:11,534 iteration 2539 : loss : 0.035690, loss_ce: 0.014013
2021-12-11 20:28:13,053 iteration 2540 : loss : 0.032605, loss_ce: 0.015268
2021-12-11 20:28:14,666 iteration 2541 : loss : 0.042104, loss_ce: 0.017260
2021-12-11 20:28:16,202 iteration 2542 : loss : 0.046432, loss_ce: 0.012961
2021-12-11 20:28:17,827 iteration 2543 : loss : 0.045343, loss_ce: 0.012720
2021-12-11 20:28:19,453 iteration 2544 : loss : 0.063623, loss_ce: 0.023189
2021-12-11 20:28:20,953 iteration 2545 : loss : 0.026603, loss_ce: 0.011066
2021-12-11 20:28:22,684 iteration 2546 : loss : 0.046781, loss_ce: 0.017415
2021-12-11 20:28:24,288 iteration 2547 : loss : 0.048735, loss_ce: 0.017639
2021-12-11 20:28:25,916 iteration 2548 : loss : 0.044725, loss_ce: 0.019778
2021-12-11 20:28:27,454 iteration 2549 : loss : 0.037922, loss_ce: 0.011824
2021-12-11 20:28:27,455 Training Data Eval:
2021-12-11 20:28:35,094   Average segmentation loss on training set: 0.0227
2021-12-11 20:28:35,095 Validation Data Eval:
2021-12-11 20:28:37,729   Average segmentation loss on validation set: 0.0934
2021-12-11 20:28:39,267 iteration 2550 : loss : 0.039603, loss_ce: 0.009146
2021-12-11 20:28:41,308 save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/NEW_TU/UNET_ADAM_seed100epoch_149.pth
 38%|██████████▏                | 150/400 [1:11:15<2:08:00, 30.72s/it]2021-12-11 20:28:42,761 iteration 2551 : loss : 0.051405, loss_ce: 0.016922
2021-12-11 20:28:44,223 iteration 2552 : loss : 0.021922, loss_ce: 0.009341
2021-12-11 20:28:45,719 iteration 2553 : loss : 0.029758, loss_ce: 0.009987
2021-12-11 20:28:47,230 iteration 2554 : loss : 0.028951, loss_ce: 0.011323
2021-12-11 20:28:48,737 iteration 2555 : loss : 0.032890, loss_ce: 0.011532
2021-12-11 20:28:50,278 iteration 2556 : loss : 0.034811, loss_ce: 0.014222
2021-12-11 20:28:51,806 iteration 2557 : loss : 0.029022, loss_ce: 0.010720
2021-12-11 20:28:53,327 iteration 2558 : loss : 0.030518, loss_ce: 0.009695
2021-12-11 20:28:54,804 iteration 2559 : loss : 0.039146, loss_ce: 0.019414
2021-12-11 20:28:56,426 iteration 2560 : loss : 0.029327, loss_ce: 0.009910
2021-12-11 20:28:57,951 iteration 2561 : loss : 0.047222, loss_ce: 0.016982
2021-12-11 20:28:59,507 iteration 2562 : loss : 0.026512, loss_ce: 0.010043
2021-12-11 20:29:00,976 iteration 2563 : loss : 0.032631, loss_ce: 0.013278
2021-12-11 20:29:02,473 iteration 2564 : loss : 0.023667, loss_ce: 0.009612
2021-12-11 20:29:03,976 iteration 2565 : loss : 0.023227, loss_ce: 0.008686
2021-12-11 20:29:05,438 iteration 2566 : loss : 0.024434, loss_ce: 0.008771
2021-12-11 20:29:06,950 iteration 2567 : loss : 0.045894, loss_ce: 0.011041
 38%|██████████▏                | 151/400 [1:11:41<2:01:13, 29.21s/it]2021-12-11 20:29:08,508 iteration 2568 : loss : 0.028805, loss_ce: 0.011345
2021-12-11 20:29:10,048 iteration 2569 : loss : 0.024279, loss_ce: 0.009164
2021-12-11 20:29:11,670 iteration 2570 : loss : 0.038690, loss_ce: 0.012187
2021-12-11 20:29:13,202 iteration 2571 : loss : 0.026520, loss_ce: 0.007404
2021-12-11 20:29:14,657 iteration 2572 : loss : 0.028152, loss_ce: 0.008707
2021-12-11 20:29:16,158 iteration 2573 : loss : 0.032096, loss_ce: 0.012363
2021-12-11 20:29:17,646 iteration 2574 : loss : 0.035157, loss_ce: 0.013447
2021-12-11 20:29:19,100 iteration 2575 : loss : 0.025369, loss_ce: 0.008240
2021-12-11 20:29:20,567 iteration 2576 : loss : 0.024503, loss_ce: 0.007239
2021-12-11 20:29:22,126 iteration 2577 : loss : 0.051956, loss_ce: 0.027766
2021-12-11 20:29:23,631 iteration 2578 : loss : 0.030471, loss_ce: 0.011078
2021-12-11 20:29:25,176 iteration 2579 : loss : 0.024894, loss_ce: 0.008656
2021-12-11 20:29:26,687 iteration 2580 : loss : 0.030524, loss_ce: 0.008351
2021-12-11 20:29:28,240 iteration 2581 : loss : 0.027089, loss_ce: 0.011304
2021-12-11 20:29:29,840 iteration 2582 : loss : 0.025500, loss_ce: 0.011136
2021-12-11 20:29:31,345 iteration 2583 : loss : 0.027087, loss_ce: 0.012300
2021-12-11 20:29:32,857 iteration 2584 : loss : 0.033491, loss_ce: 0.010906
 38%|██████████▎                | 152/400 [1:12:06<1:56:38, 28.22s/it]2021-12-11 20:29:34,440 iteration 2585 : loss : 0.027818, loss_ce: 0.009330
2021-12-11 20:29:36,149 iteration 2586 : loss : 0.054343, loss_ce: 0.016549
2021-12-11 20:29:37,763 iteration 2587 : loss : 0.048064, loss_ce: 0.016361
2021-12-11 20:29:39,307 iteration 2588 : loss : 0.035992, loss_ce: 0.013545
2021-12-11 20:29:40,779 iteration 2589 : loss : 0.037505, loss_ce: 0.011045
2021-12-11 20:29:42,349 iteration 2590 : loss : 0.038218, loss_ce: 0.012741
2021-12-11 20:29:43,902 iteration 2591 : loss : 0.023781, loss_ce: 0.008915
2021-12-11 20:29:45,400 iteration 2592 : loss : 0.021768, loss_ce: 0.010628
2021-12-11 20:29:46,847 iteration 2593 : loss : 0.030648, loss_ce: 0.015300
2021-12-11 20:29:48,375 iteration 2594 : loss : 0.049118, loss_ce: 0.024618
2021-12-11 20:29:49,850 iteration 2595 : loss : 0.025995, loss_ce: 0.009031
2021-12-11 20:29:51,361 iteration 2596 : loss : 0.038167, loss_ce: 0.011202
2021-12-11 20:29:52,881 iteration 2597 : loss : 0.033864, loss_ce: 0.011658
2021-12-11 20:29:54,430 iteration 2598 : loss : 0.032566, loss_ce: 0.013915
2021-12-11 20:29:55,975 iteration 2599 : loss : 0.028247, loss_ce: 0.011122
2021-12-11 20:29:57,482 iteration 2600 : loss : 0.041697, loss_ce: 0.017102
2021-12-11 20:29:58,945 iteration 2601 : loss : 0.030535, loss_ce: 0.011689
 38%|██████████▎                | 153/400 [1:12:33<1:53:32, 27.58s/it]2021-12-11 20:30:00,515 iteration 2602 : loss : 0.027256, loss_ce: 0.009616
2021-12-11 20:30:02,069 iteration 2603 : loss : 0.053026, loss_ce: 0.011948
2021-12-11 20:30:03,610 iteration 2604 : loss : 0.035365, loss_ce: 0.011253
2021-12-11 20:30:05,141 iteration 2605 : loss : 0.033991, loss_ce: 0.014442
2021-12-11 20:30:06,692 iteration 2606 : loss : 0.027123, loss_ce: 0.010717
2021-12-11 20:30:08,245 iteration 2607 : loss : 0.027389, loss_ce: 0.010663
2021-12-11 20:30:09,742 iteration 2608 : loss : 0.032199, loss_ce: 0.011461
2021-12-11 20:30:11,317 iteration 2609 : loss : 0.036020, loss_ce: 0.013442
2021-12-11 20:30:12,916 iteration 2610 : loss : 0.035634, loss_ce: 0.012091
2021-12-11 20:30:14,514 iteration 2611 : loss : 0.029468, loss_ce: 0.012712
2021-12-11 20:30:16,099 iteration 2612 : loss : 0.038867, loss_ce: 0.013427
2021-12-11 20:30:17,713 iteration 2613 : loss : 0.038434, loss_ce: 0.013354
2021-12-11 20:30:19,298 iteration 2614 : loss : 0.031612, loss_ce: 0.013119
2021-12-11 20:30:20,849 iteration 2615 : loss : 0.033198, loss_ce: 0.014285
2021-12-11 20:30:22,445 iteration 2616 : loss : 0.030403, loss_ce: 0.011297
2021-12-11 20:30:23,987 iteration 2617 : loss : 0.043629, loss_ce: 0.015837
2021-12-11 20:30:25,565 iteration 2618 : loss : 0.033643, loss_ce: 0.009930
 38%|██████████▍                | 154/400 [1:12:59<1:51:53, 27.29s/it]2021-12-11 20:30:27,267 iteration 2619 : loss : 0.035025, loss_ce: 0.014316
2021-12-11 20:30:28,831 iteration 2620 : loss : 0.033123, loss_ce: 0.010715
2021-12-11 20:30:30,263 iteration 2621 : loss : 0.031934, loss_ce: 0.012348
2021-12-11 20:30:31,859 iteration 2622 : loss : 0.045019, loss_ce: 0.014305
2021-12-11 20:30:33,351 iteration 2623 : loss : 0.024539, loss_ce: 0.009870
2021-12-11 20:30:34,938 iteration 2624 : loss : 0.037588, loss_ce: 0.014364
2021-12-11 20:30:36,529 iteration 2625 : loss : 0.034275, loss_ce: 0.013834
2021-12-11 20:30:38,105 iteration 2626 : loss : 0.027774, loss_ce: 0.009889
2021-12-11 20:30:39,579 iteration 2627 : loss : 0.028211, loss_ce: 0.014085
2021-12-11 20:30:41,068 iteration 2628 : loss : 0.025875, loss_ce: 0.010512
2021-12-11 20:30:42,520 iteration 2629 : loss : 0.030651, loss_ce: 0.007716
2021-12-11 20:30:44,094 iteration 2630 : loss : 0.054447, loss_ce: 0.010339
2021-12-11 20:30:45,563 iteration 2631 : loss : 0.040398, loss_ce: 0.019190
2021-12-11 20:30:47,044 iteration 2632 : loss : 0.032771, loss_ce: 0.011167
2021-12-11 20:30:48,589 iteration 2633 : loss : 0.027365, loss_ce: 0.009674
2021-12-11 20:30:50,112 iteration 2634 : loss : 0.031896, loss_ce: 0.010792
2021-12-11 20:30:50,112 Training Data Eval:
2021-12-11 20:30:57,746   Average segmentation loss on training set: 0.0249
2021-12-11 20:30:57,746 Validation Data Eval:
2021-12-11 20:31:00,376   Average segmentation loss on validation set: 0.0791
2021-12-11 20:31:01,873 iteration 2635 : loss : 0.038894, loss_ce: 0.016168
 39%|██████████▍                | 155/400 [1:13:35<2:02:28, 29.99s/it]2021-12-11 20:31:03,402 iteration 2636 : loss : 0.023990, loss_ce: 0.008680
2021-12-11 20:31:04,916 iteration 2637 : loss : 0.038731, loss_ce: 0.020178
2021-12-11 20:31:06,536 iteration 2638 : loss : 0.063179, loss_ce: 0.025278
2021-12-11 20:31:08,069 iteration 2639 : loss : 0.035291, loss_ce: 0.013198
2021-12-11 20:31:09,619 iteration 2640 : loss : 0.044369, loss_ce: 0.018917
2021-12-11 20:31:11,155 iteration 2641 : loss : 0.034768, loss_ce: 0.012709
2021-12-11 20:31:12,717 iteration 2642 : loss : 0.032924, loss_ce: 0.010094
2021-12-11 20:31:14,242 iteration 2643 : loss : 0.031834, loss_ce: 0.012203
2021-12-11 20:31:15,838 iteration 2644 : loss : 0.034329, loss_ce: 0.015919
2021-12-11 20:31:17,319 iteration 2645 : loss : 0.027336, loss_ce: 0.012037
2021-12-11 20:31:18,821 iteration 2646 : loss : 0.049237, loss_ce: 0.015148
2021-12-11 20:31:20,431 iteration 2647 : loss : 0.054896, loss_ce: 0.023548
2021-12-11 20:31:21,929 iteration 2648 : loss : 0.032583, loss_ce: 0.010988
2021-12-11 20:31:23,478 iteration 2649 : loss : 0.035175, loss_ce: 0.011584
2021-12-11 20:31:25,140 iteration 2650 : loss : 0.040456, loss_ce: 0.014191
2021-12-11 20:31:26,662 iteration 2651 : loss : 0.032124, loss_ce: 0.012326
2021-12-11 20:31:28,282 iteration 2652 : loss : 0.028100, loss_ce: 0.010921
 39%|██████████▌                | 156/400 [1:14:02<1:57:36, 28.92s/it]2021-12-11 20:31:29,920 iteration 2653 : loss : 0.043106, loss_ce: 0.015140
2021-12-11 20:31:31,401 iteration 2654 : loss : 0.024039, loss_ce: 0.009946
2021-12-11 20:31:32,917 iteration 2655 : loss : 0.029071, loss_ce: 0.011647
2021-12-11 20:31:34,473 iteration 2656 : loss : 0.027421, loss_ce: 0.012827
2021-12-11 20:31:36,030 iteration 2657 : loss : 0.033529, loss_ce: 0.014293
2021-12-11 20:31:37,638 iteration 2658 : loss : 0.048441, loss_ce: 0.016085
2021-12-11 20:31:39,198 iteration 2659 : loss : 0.042861, loss_ce: 0.017464
2021-12-11 20:31:40,826 iteration 2660 : loss : 0.032956, loss_ce: 0.014276
2021-12-11 20:31:42,275 iteration 2661 : loss : 0.033809, loss_ce: 0.010769
2021-12-11 20:31:43,871 iteration 2662 : loss : 0.023949, loss_ce: 0.009776
2021-12-11 20:31:45,446 iteration 2663 : loss : 0.040183, loss_ce: 0.018407
2021-12-11 20:31:46,932 iteration 2664 : loss : 0.033893, loss_ce: 0.012365
2021-12-11 20:31:48,433 iteration 2665 : loss : 0.020250, loss_ce: 0.007572
2021-12-11 20:31:50,048 iteration 2666 : loss : 0.031728, loss_ce: 0.011312
2021-12-11 20:31:51,538 iteration 2667 : loss : 0.029436, loss_ce: 0.010804
2021-12-11 20:31:53,144 iteration 2668 : loss : 0.037900, loss_ce: 0.014646
2021-12-11 20:31:54,661 iteration 2669 : loss : 0.025445, loss_ce: 0.007221
 39%|██████████▌                | 157/400 [1:14:28<1:54:02, 28.16s/it]2021-12-11 20:31:56,156 iteration 2670 : loss : 0.026041, loss_ce: 0.009438
2021-12-11 20:31:57,622 iteration 2671 : loss : 0.034211, loss_ce: 0.013470
2021-12-11 20:31:59,122 iteration 2672 : loss : 0.035606, loss_ce: 0.011282
2021-12-11 20:32:00,620 iteration 2673 : loss : 0.028067, loss_ce: 0.008205
2021-12-11 20:32:02,181 iteration 2674 : loss : 0.036987, loss_ce: 0.012324
2021-12-11 20:32:03,832 iteration 2675 : loss : 0.026528, loss_ce: 0.008976
2021-12-11 20:32:05,345 iteration 2676 : loss : 0.024928, loss_ce: 0.008291
2021-12-11 20:32:06,878 iteration 2677 : loss : 0.030573, loss_ce: 0.013748
2021-12-11 20:32:08,347 iteration 2678 : loss : 0.028256, loss_ce: 0.012008
2021-12-11 20:32:09,886 iteration 2679 : loss : 0.039261, loss_ce: 0.016614
2021-12-11 20:32:11,491 iteration 2680 : loss : 0.038188, loss_ce: 0.016630
2021-12-11 20:32:13,045 iteration 2681 : loss : 0.032428, loss_ce: 0.010400
2021-12-11 20:32:14,607 iteration 2682 : loss : 0.039032, loss_ce: 0.016171
2021-12-11 20:32:16,113 iteration 2683 : loss : 0.027763, loss_ce: 0.012261
2021-12-11 20:32:17,663 iteration 2684 : loss : 0.026725, loss_ce: 0.011592
2021-12-11 20:32:19,231 iteration 2685 : loss : 0.029244, loss_ce: 0.012293
2021-12-11 20:32:20,810 iteration 2686 : loss : 0.079057, loss_ce: 0.017911
 40%|██████████▋                | 158/400 [1:14:54<1:51:08, 27.56s/it]2021-12-11 20:32:22,336 iteration 2687 : loss : 0.030277, loss_ce: 0.011921
2021-12-11 20:32:23,844 iteration 2688 : loss : 0.029625, loss_ce: 0.010542
2021-12-11 20:32:25,338 iteration 2689 : loss : 0.054718, loss_ce: 0.019110
2021-12-11 20:32:26,922 iteration 2690 : loss : 0.061448, loss_ce: 0.012415
2021-12-11 20:32:28,408 iteration 2691 : loss : 0.026514, loss_ce: 0.011105
2021-12-11 20:32:29,900 iteration 2692 : loss : 0.060417, loss_ce: 0.025738
2021-12-11 20:32:31,384 iteration 2693 : loss : 0.032035, loss_ce: 0.011049
2021-12-11 20:32:32,929 iteration 2694 : loss : 0.044434, loss_ce: 0.022236
2021-12-11 20:32:34,455 iteration 2695 : loss : 0.027097, loss_ce: 0.012900
2021-12-11 20:32:35,976 iteration 2696 : loss : 0.027412, loss_ce: 0.012704
2021-12-11 20:32:37,500 iteration 2697 : loss : 0.036002, loss_ce: 0.015336
2021-12-11 20:32:38,989 iteration 2698 : loss : 0.032192, loss_ce: 0.010427
2021-12-11 20:32:40,502 iteration 2699 : loss : 0.029475, loss_ce: 0.013401
2021-12-11 20:32:41,982 iteration 2700 : loss : 0.030719, loss_ce: 0.009294
2021-12-11 20:32:43,625 iteration 2701 : loss : 0.031314, loss_ce: 0.010345
2021-12-11 20:32:45,217 iteration 2702 : loss : 0.037810, loss_ce: 0.019453
2021-12-11 20:32:46,825 iteration 2703 : loss : 0.046005, loss_ce: 0.017702
 40%|██████████▋                | 159/400 [1:15:20<1:48:49, 27.09s/it]2021-12-11 20:32:48,479 iteration 2704 : loss : 0.052453, loss_ce: 0.015982
2021-12-11 20:32:49,962 iteration 2705 : loss : 0.023902, loss_ce: 0.010244
2021-12-11 20:32:51,539 iteration 2706 : loss : 0.062916, loss_ce: 0.021176
2021-12-11 20:32:53,056 iteration 2707 : loss : 0.025277, loss_ce: 0.011834
2021-12-11 20:32:54,630 iteration 2708 : loss : 0.026123, loss_ce: 0.010227
2021-12-11 20:32:56,152 iteration 2709 : loss : 0.032127, loss_ce: 0.012931
2021-12-11 20:32:57,624 iteration 2710 : loss : 0.025930, loss_ce: 0.010370
2021-12-11 20:32:59,176 iteration 2711 : loss : 0.024511, loss_ce: 0.009390
2021-12-11 20:33:00,755 iteration 2712 : loss : 0.030329, loss_ce: 0.009178
2021-12-11 20:33:02,253 iteration 2713 : loss : 0.030972, loss_ce: 0.013913
2021-12-11 20:33:03,864 iteration 2714 : loss : 0.033943, loss_ce: 0.013522
2021-12-11 20:33:05,453 iteration 2715 : loss : 0.042319, loss_ce: 0.011707
2021-12-11 20:33:07,079 iteration 2716 : loss : 0.029178, loss_ce: 0.010163
2021-12-11 20:33:08,606 iteration 2717 : loss : 0.034123, loss_ce: 0.013998
2021-12-11 20:33:10,202 iteration 2718 : loss : 0.044664, loss_ce: 0.013309
2021-12-11 20:33:11,709 iteration 2719 : loss : 0.026096, loss_ce: 0.008319
2021-12-11 20:33:11,710 Training Data Eval:
2021-12-11 20:33:19,359   Average segmentation loss on training set: 0.0211
2021-12-11 20:33:19,359 Validation Data Eval:
2021-12-11 20:33:21,996   Average segmentation loss on validation set: 0.0838
2021-12-11 20:33:23,484 iteration 2720 : loss : 0.023174, loss_ce: 0.007631
 40%|██████████▊                | 160/400 [1:15:57<1:59:50, 29.96s/it]2021-12-11 20:33:25,089 iteration 2721 : loss : 0.026474, loss_ce: 0.010751
2021-12-11 20:33:26,642 iteration 2722 : loss : 0.055035, loss_ce: 0.020231
2021-12-11 20:33:28,224 iteration 2723 : loss : 0.032338, loss_ce: 0.013838
2021-12-11 20:33:29,768 iteration 2724 : loss : 0.045165, loss_ce: 0.017197
2021-12-11 20:33:31,289 iteration 2725 : loss : 0.037595, loss_ce: 0.013284
2021-12-11 20:33:32,967 iteration 2726 : loss : 0.044688, loss_ce: 0.017401
2021-12-11 20:33:34,562 iteration 2727 : loss : 0.033607, loss_ce: 0.014096
2021-12-11 20:33:36,096 iteration 2728 : loss : 0.024563, loss_ce: 0.008926
2021-12-11 20:33:37,634 iteration 2729 : loss : 0.035208, loss_ce: 0.017297
2021-12-11 20:33:39,100 iteration 2730 : loss : 0.024867, loss_ce: 0.009434
2021-12-11 20:33:40,682 iteration 2731 : loss : 0.027829, loss_ce: 0.010731
2021-12-11 20:33:42,294 iteration 2732 : loss : 0.038972, loss_ce: 0.016605
2021-12-11 20:33:43,857 iteration 2733 : loss : 0.044911, loss_ce: 0.018119
2021-12-11 20:33:45,407 iteration 2734 : loss : 0.029335, loss_ce: 0.009955
2021-12-11 20:33:47,049 iteration 2735 : loss : 0.041234, loss_ce: 0.012772
2021-12-11 20:33:48,580 iteration 2736 : loss : 0.025188, loss_ce: 0.011847
2021-12-11 20:33:50,161 iteration 2737 : loss : 0.033131, loss_ce: 0.012626
 40%|██████████▊                | 161/400 [1:16:24<1:55:25, 28.98s/it]2021-12-11 20:33:51,679 iteration 2738 : loss : 0.019621, loss_ce: 0.007192
2021-12-11 20:33:53,344 iteration 2739 : loss : 0.028674, loss_ce: 0.012338
2021-12-11 20:33:54,965 iteration 2740 : loss : 0.038046, loss_ce: 0.016943
2021-12-11 20:33:56,482 iteration 2741 : loss : 0.026064, loss_ce: 0.008962
2021-12-11 20:33:57,954 iteration 2742 : loss : 0.031009, loss_ce: 0.009135
2021-12-11 20:33:59,508 iteration 2743 : loss : 0.038054, loss_ce: 0.011926
2021-12-11 20:34:01,183 iteration 2744 : loss : 0.047341, loss_ce: 0.020700
2021-12-11 20:34:02,717 iteration 2745 : loss : 0.027300, loss_ce: 0.009205
2021-12-11 20:34:04,236 iteration 2746 : loss : 0.022597, loss_ce: 0.007607
2021-12-11 20:34:05,879 iteration 2747 : loss : 0.057378, loss_ce: 0.027301
2021-12-11 20:34:07,386 iteration 2748 : loss : 0.026074, loss_ce: 0.009642
2021-12-11 20:34:08,942 iteration 2749 : loss : 0.030393, loss_ce: 0.014099
2021-12-11 20:34:10,447 iteration 2750 : loss : 0.035681, loss_ce: 0.011295
2021-12-11 20:34:12,008 iteration 2751 : loss : 0.039538, loss_ce: 0.010834
2021-12-11 20:34:13,505 iteration 2752 : loss : 0.027118, loss_ce: 0.010952
2021-12-11 20:34:15,031 iteration 2753 : loss : 0.029888, loss_ce: 0.012015
2021-12-11 20:34:16,582 iteration 2754 : loss : 0.039933, loss_ce: 0.015178
 40%|██████████▉                | 162/400 [1:16:50<1:51:54, 28.21s/it]2021-12-11 20:34:18,162 iteration 2755 : loss : 0.030965, loss_ce: 0.012469
2021-12-11 20:34:19,723 iteration 2756 : loss : 0.030271, loss_ce: 0.012513
2021-12-11 20:34:21,222 iteration 2757 : loss : 0.025627, loss_ce: 0.010223
2021-12-11 20:34:22,752 iteration 2758 : loss : 0.033618, loss_ce: 0.013120
2021-12-11 20:34:24,283 iteration 2759 : loss : 0.031767, loss_ce: 0.011687
2021-12-11 20:34:25,860 iteration 2760 : loss : 0.046895, loss_ce: 0.013395
2021-12-11 20:34:27,408 iteration 2761 : loss : 0.023116, loss_ce: 0.008387
2021-12-11 20:34:28,928 iteration 2762 : loss : 0.034002, loss_ce: 0.014066
2021-12-11 20:34:30,454 iteration 2763 : loss : 0.036409, loss_ce: 0.013750
2021-12-11 20:34:31,925 iteration 2764 : loss : 0.030283, loss_ce: 0.013769
2021-12-11 20:34:33,455 iteration 2765 : loss : 0.031902, loss_ce: 0.013403
2021-12-11 20:34:35,041 iteration 2766 : loss : 0.033355, loss_ce: 0.013799
2021-12-11 20:34:36,514 iteration 2767 : loss : 0.018602, loss_ce: 0.005503
2021-12-11 20:34:38,172 iteration 2768 : loss : 0.035010, loss_ce: 0.015168
2021-12-11 20:34:39,696 iteration 2769 : loss : 0.026994, loss_ce: 0.008519
2021-12-11 20:34:41,205 iteration 2770 : loss : 0.026024, loss_ce: 0.012679
2021-12-11 20:34:42,730 iteration 2771 : loss : 0.026882, loss_ce: 0.013372
 41%|███████████                | 163/400 [1:17:16<1:48:59, 27.59s/it]2021-12-11 20:34:44,377 iteration 2772 : loss : 0.031241, loss_ce: 0.010776
2021-12-11 20:34:45,856 iteration 2773 : loss : 0.032631, loss_ce: 0.011954
2021-12-11 20:34:47,361 iteration 2774 : loss : 0.030731, loss_ce: 0.014207
2021-12-11 20:34:48,899 iteration 2775 : loss : 0.030005, loss_ce: 0.013189
2021-12-11 20:34:50,434 iteration 2776 : loss : 0.032449, loss_ce: 0.014636
2021-12-11 20:34:52,006 iteration 2777 : loss : 0.036170, loss_ce: 0.015954
2021-12-11 20:34:53,466 iteration 2778 : loss : 0.024895, loss_ce: 0.010338
2021-12-11 20:34:55,043 iteration 2779 : loss : 0.065416, loss_ce: 0.024220
2021-12-11 20:34:56,672 iteration 2780 : loss : 0.038230, loss_ce: 0.015800
2021-12-11 20:34:58,163 iteration 2781 : loss : 0.033059, loss_ce: 0.013381
2021-12-11 20:34:59,732 iteration 2782 : loss : 0.032418, loss_ce: 0.011968
2021-12-11 20:35:01,342 iteration 2783 : loss : 0.041795, loss_ce: 0.013268
2021-12-11 20:35:02,999 iteration 2784 : loss : 0.050296, loss_ce: 0.026450
2021-12-11 20:35:04,475 iteration 2785 : loss : 0.022935, loss_ce: 0.007654
2021-12-11 20:35:06,028 iteration 2786 : loss : 0.034686, loss_ce: 0.013483
2021-12-11 20:35:07,651 iteration 2787 : loss : 0.038282, loss_ce: 0.010490
2021-12-11 20:35:09,207 iteration 2788 : loss : 0.031164, loss_ce: 0.009782
 41%|███████████                | 164/400 [1:17:43<1:47:12, 27.26s/it]2021-12-11 20:35:10,791 iteration 2789 : loss : 0.021449, loss_ce: 0.010518
2021-12-11 20:35:12,295 iteration 2790 : loss : 0.036686, loss_ce: 0.009998
2021-12-11 20:35:13,854 iteration 2791 : loss : 0.041358, loss_ce: 0.011796
2021-12-11 20:35:15,445 iteration 2792 : loss : 0.050161, loss_ce: 0.012917
2021-12-11 20:35:16,990 iteration 2793 : loss : 0.034938, loss_ce: 0.015470
2021-12-11 20:35:18,555 iteration 2794 : loss : 0.035525, loss_ce: 0.014986
2021-12-11 20:35:20,171 iteration 2795 : loss : 0.053175, loss_ce: 0.023287
2021-12-11 20:35:21,814 iteration 2796 : loss : 0.052917, loss_ce: 0.020995
2021-12-11 20:35:23,398 iteration 2797 : loss : 0.031632, loss_ce: 0.012141
2021-12-11 20:35:25,036 iteration 2798 : loss : 0.039397, loss_ce: 0.012153
2021-12-11 20:35:26,631 iteration 2799 : loss : 0.047148, loss_ce: 0.017079
2021-12-11 20:35:28,223 iteration 2800 : loss : 0.029695, loss_ce: 0.013768
2021-12-11 20:35:29,801 iteration 2801 : loss : 0.028558, loss_ce: 0.012207
2021-12-11 20:35:31,279 iteration 2802 : loss : 0.020423, loss_ce: 0.008705
2021-12-11 20:35:32,921 iteration 2803 : loss : 0.042201, loss_ce: 0.014182
2021-12-11 20:35:34,454 iteration 2804 : loss : 0.040433, loss_ce: 0.015498
2021-12-11 20:35:34,454 Training Data Eval:
2021-12-11 20:35:42,075   Average segmentation loss on training set: 0.0318
2021-12-11 20:35:42,076 Validation Data Eval:
2021-12-11 20:35:44,714   Average segmentation loss on validation set: 0.0677
2021-12-11 20:35:46,823 Found new lowest validation loss at iteration 2804! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/NEW_TU/UNET_ADAM_best_val_loss_seed100.pth
2021-12-11 20:35:48,251 iteration 2805 : loss : 0.044787, loss_ce: 0.014071
 41%|███████████▏               | 165/400 [1:18:22<2:00:36, 30.79s/it]2021-12-11 20:35:49,770 iteration 2806 : loss : 0.033306, loss_ce: 0.012235
2021-12-11 20:35:51,388 iteration 2807 : loss : 0.050709, loss_ce: 0.016585
2021-12-11 20:35:52,790 iteration 2808 : loss : 0.028687, loss_ce: 0.013382
2021-12-11 20:35:54,315 iteration 2809 : loss : 0.029882, loss_ce: 0.011058
2021-12-11 20:35:55,904 iteration 2810 : loss : 0.029938, loss_ce: 0.011733
2021-12-11 20:35:57,410 iteration 2811 : loss : 0.026534, loss_ce: 0.010281
2021-12-11 20:35:58,962 iteration 2812 : loss : 0.030779, loss_ce: 0.011997
2021-12-11 20:36:00,539 iteration 2813 : loss : 0.024387, loss_ce: 0.008349
2021-12-11 20:36:02,082 iteration 2814 : loss : 0.033386, loss_ce: 0.013267
2021-12-11 20:36:03,581 iteration 2815 : loss : 0.021282, loss_ce: 0.009189
2021-12-11 20:36:05,085 iteration 2816 : loss : 0.033972, loss_ce: 0.014880
2021-12-11 20:36:06,581 iteration 2817 : loss : 0.025001, loss_ce: 0.007570
2021-12-11 20:36:08,198 iteration 2818 : loss : 0.043452, loss_ce: 0.013787
2021-12-11 20:36:09,802 iteration 2819 : loss : 0.033778, loss_ce: 0.018832
2021-12-11 20:36:11,454 iteration 2820 : loss : 0.040443, loss_ce: 0.016368
2021-12-11 20:36:12,993 iteration 2821 : loss : 0.028055, loss_ce: 0.011445
2021-12-11 20:36:14,498 iteration 2822 : loss : 0.028890, loss_ce: 0.009578
 42%|███████████▏               | 166/400 [1:18:48<1:54:46, 29.43s/it]2021-12-11 20:36:16,176 iteration 2823 : loss : 0.050078, loss_ce: 0.017545
2021-12-11 20:36:17,667 iteration 2824 : loss : 0.021850, loss_ce: 0.007795
2021-12-11 20:36:19,242 iteration 2825 : loss : 0.029971, loss_ce: 0.012755
2021-12-11 20:36:20,738 iteration 2826 : loss : 0.026206, loss_ce: 0.010251
2021-12-11 20:36:22,315 iteration 2827 : loss : 0.041628, loss_ce: 0.022374
2021-12-11 20:36:23,871 iteration 2828 : loss : 0.031133, loss_ce: 0.014262
2021-12-11 20:36:25,545 iteration 2829 : loss : 0.031553, loss_ce: 0.012325
2021-12-11 20:36:27,027 iteration 2830 : loss : 0.022960, loss_ce: 0.010151
2021-12-11 20:36:28,563 iteration 2831 : loss : 0.032436, loss_ce: 0.014731
2021-12-11 20:36:30,149 iteration 2832 : loss : 0.027309, loss_ce: 0.007514
2021-12-11 20:36:31,739 iteration 2833 : loss : 0.036101, loss_ce: 0.013594
2021-12-11 20:36:33,262 iteration 2834 : loss : 0.035095, loss_ce: 0.011358
2021-12-11 20:36:34,835 iteration 2835 : loss : 0.056843, loss_ce: 0.016505
2021-12-11 20:36:36,432 iteration 2836 : loss : 0.029359, loss_ce: 0.011834
2021-12-11 20:36:37,971 iteration 2837 : loss : 0.033606, loss_ce: 0.009308
2021-12-11 20:36:39,455 iteration 2838 : loss : 0.020951, loss_ce: 0.006542
2021-12-11 20:36:41,026 iteration 2839 : loss : 0.033790, loss_ce: 0.011745
 42%|███████████▎               | 167/400 [1:19:15<1:50:54, 28.56s/it]2021-12-11 20:36:42,592 iteration 2840 : loss : 0.034959, loss_ce: 0.017894
2021-12-11 20:36:44,149 iteration 2841 : loss : 0.025990, loss_ce: 0.010380
2021-12-11 20:36:45,696 iteration 2842 : loss : 0.058720, loss_ce: 0.021229
2021-12-11 20:36:47,177 iteration 2843 : loss : 0.023347, loss_ce: 0.009032
2021-12-11 20:36:48,617 iteration 2844 : loss : 0.019562, loss_ce: 0.006914
2021-12-11 20:36:50,131 iteration 2845 : loss : 0.035358, loss_ce: 0.013228
2021-12-11 20:36:51,778 iteration 2846 : loss : 0.042763, loss_ce: 0.013267
2021-12-11 20:36:53,376 iteration 2847 : loss : 0.031891, loss_ce: 0.009752
2021-12-11 20:36:54,920 iteration 2848 : loss : 0.036447, loss_ce: 0.010980
2021-12-11 20:36:56,507 iteration 2849 : loss : 0.038686, loss_ce: 0.014522
2021-12-11 20:36:58,050 iteration 2850 : loss : 0.037966, loss_ce: 0.016582
2021-12-11 20:36:59,682 iteration 2851 : loss : 0.036421, loss_ce: 0.017509
2021-12-11 20:37:01,194 iteration 2852 : loss : 0.028780, loss_ce: 0.008021
2021-12-11 20:37:02,760 iteration 2853 : loss : 0.033254, loss_ce: 0.011608
2021-12-11 20:37:04,284 iteration 2854 : loss : 0.034639, loss_ce: 0.009571
2021-12-11 20:37:05,780 iteration 2855 : loss : 0.032492, loss_ce: 0.014035
2021-12-11 20:37:07,227 iteration 2856 : loss : 0.023773, loss_ce: 0.011711
 42%|███████████▎               | 168/400 [1:19:41<1:47:42, 27.85s/it]2021-12-11 20:37:08,822 iteration 2857 : loss : 0.030394, loss_ce: 0.013926
2021-12-11 20:37:10,488 iteration 2858 : loss : 0.043018, loss_ce: 0.012009
2021-12-11 20:37:12,080 iteration 2859 : loss : 0.024959, loss_ce: 0.009714
2021-12-11 20:37:13,657 iteration 2860 : loss : 0.028241, loss_ce: 0.011089
2021-12-11 20:37:15,216 iteration 2861 : loss : 0.029930, loss_ce: 0.009310
2021-12-11 20:37:16,797 iteration 2862 : loss : 0.043417, loss_ce: 0.011486
2021-12-11 20:37:18,285 iteration 2863 : loss : 0.028609, loss_ce: 0.009987
2021-12-11 20:37:19,816 iteration 2864 : loss : 0.028582, loss_ce: 0.009906
2021-12-11 20:37:21,343 iteration 2865 : loss : 0.024497, loss_ce: 0.009824
2021-12-11 20:37:22,873 iteration 2866 : loss : 0.025961, loss_ce: 0.009492
2021-12-11 20:37:24,509 iteration 2867 : loss : 0.037074, loss_ce: 0.012481
2021-12-11 20:37:26,089 iteration 2868 : loss : 0.035235, loss_ce: 0.014863
2021-12-11 20:37:27,681 iteration 2869 : loss : 0.037395, loss_ce: 0.014898
2021-12-11 20:37:29,319 iteration 2870 : loss : 0.041186, loss_ce: 0.012671
2021-12-11 20:37:30,802 iteration 2871 : loss : 0.033103, loss_ce: 0.016854
2021-12-11 20:37:32,313 iteration 2872 : loss : 0.037214, loss_ce: 0.019224
2021-12-11 20:37:33,881 iteration 2873 : loss : 0.027595, loss_ce: 0.011630
 42%|███████████▍               | 169/400 [1:20:08<1:45:50, 27.49s/it]2021-12-11 20:37:35,446 iteration 2874 : loss : 0.024839, loss_ce: 0.009482
2021-12-11 20:37:37,055 iteration 2875 : loss : 0.030272, loss_ce: 0.013510
2021-12-11 20:37:38,556 iteration 2876 : loss : 0.041208, loss_ce: 0.014662
2021-12-11 20:37:40,029 iteration 2877 : loss : 0.029478, loss_ce: 0.008991
2021-12-11 20:37:41,545 iteration 2878 : loss : 0.026921, loss_ce: 0.007634
2021-12-11 20:37:43,001 iteration 2879 : loss : 0.027170, loss_ce: 0.011641
2021-12-11 20:37:44,554 iteration 2880 : loss : 0.030226, loss_ce: 0.014709
2021-12-11 20:37:46,017 iteration 2881 : loss : 0.021640, loss_ce: 0.009716
2021-12-11 20:37:47,523 iteration 2882 : loss : 0.050513, loss_ce: 0.016437
2021-12-11 20:37:49,090 iteration 2883 : loss : 0.040349, loss_ce: 0.012656
2021-12-11 20:37:50,678 iteration 2884 : loss : 0.042431, loss_ce: 0.017980
2021-12-11 20:37:52,241 iteration 2885 : loss : 0.023439, loss_ce: 0.008559
2021-12-11 20:37:53,749 iteration 2886 : loss : 0.026508, loss_ce: 0.009469
2021-12-11 20:37:55,248 iteration 2887 : loss : 0.033183, loss_ce: 0.010943
2021-12-11 20:37:56,813 iteration 2888 : loss : 0.025006, loss_ce: 0.009936
2021-12-11 20:37:58,359 iteration 2889 : loss : 0.030655, loss_ce: 0.010984
2021-12-11 20:37:58,359 Training Data Eval:
2021-12-11 20:38:05,998   Average segmentation loss on training set: 0.0240
2021-12-11 20:38:05,998 Validation Data Eval:
2021-12-11 20:38:08,638   Average segmentation loss on validation set: 0.0820
2021-12-11 20:38:10,161 iteration 2890 : loss : 0.038896, loss_ce: 0.018551
 42%|███████████▍               | 170/400 [1:20:44<1:55:29, 30.13s/it]2021-12-11 20:38:11,729 iteration 2891 : loss : 0.035266, loss_ce: 0.015509
2021-12-11 20:38:13,295 iteration 2892 : loss : 0.026982, loss_ce: 0.009987
2021-12-11 20:38:14,760 iteration 2893 : loss : 0.025915, loss_ce: 0.010680
2021-12-11 20:38:16,258 iteration 2894 : loss : 0.020418, loss_ce: 0.007271
2021-12-11 20:38:17,757 iteration 2895 : loss : 0.030599, loss_ce: 0.010463
2021-12-11 20:38:19,289 iteration 2896 : loss : 0.028899, loss_ce: 0.011725
2021-12-11 20:38:20,949 iteration 2897 : loss : 0.071114, loss_ce: 0.018730
2021-12-11 20:38:22,509 iteration 2898 : loss : 0.042462, loss_ce: 0.014197
2021-12-11 20:38:24,097 iteration 2899 : loss : 0.031569, loss_ce: 0.012955
2021-12-11 20:38:25,760 iteration 2900 : loss : 0.038749, loss_ce: 0.016001
2021-12-11 20:38:27,334 iteration 2901 : loss : 0.032409, loss_ce: 0.012051
2021-12-11 20:38:28,860 iteration 2902 : loss : 0.037127, loss_ce: 0.015122
2021-12-11 20:38:30,406 iteration 2903 : loss : 0.032813, loss_ce: 0.010806
2021-12-11 20:38:31,944 iteration 2904 : loss : 0.033790, loss_ce: 0.018952
2021-12-11 20:38:33,526 iteration 2905 : loss : 0.029169, loss_ce: 0.012488
2021-12-11 20:38:35,027 iteration 2906 : loss : 0.025973, loss_ce: 0.011228
2021-12-11 20:38:36,598 iteration 2907 : loss : 0.024705, loss_ce: 0.009464
 43%|███████████▌               | 171/400 [1:21:10<1:50:45, 29.02s/it]2021-12-11 20:38:38,196 iteration 2908 : loss : 0.026965, loss_ce: 0.009547
2021-12-11 20:38:39,784 iteration 2909 : loss : 0.036935, loss_ce: 0.012180
2021-12-11 20:38:41,376 iteration 2910 : loss : 0.024950, loss_ce: 0.008665
2021-12-11 20:38:42,975 iteration 2911 : loss : 0.033128, loss_ce: 0.011315
2021-12-11 20:38:44,482 iteration 2912 : loss : 0.027038, loss_ce: 0.009816
2021-12-11 20:38:46,049 iteration 2913 : loss : 0.033282, loss_ce: 0.010336
2021-12-11 20:38:47,625 iteration 2914 : loss : 0.031140, loss_ce: 0.012850
2021-12-11 20:38:49,174 iteration 2915 : loss : 0.037514, loss_ce: 0.020445
2021-12-11 20:38:50,719 iteration 2916 : loss : 0.029403, loss_ce: 0.012247
2021-12-11 20:38:52,257 iteration 2917 : loss : 0.030663, loss_ce: 0.010483
2021-12-11 20:38:53,751 iteration 2918 : loss : 0.027690, loss_ce: 0.012321
2021-12-11 20:38:55,307 iteration 2919 : loss : 0.027949, loss_ce: 0.009196
2021-12-11 20:38:56,816 iteration 2920 : loss : 0.025643, loss_ce: 0.009722
2021-12-11 20:38:58,349 iteration 2921 : loss : 0.028605, loss_ce: 0.013136
2021-12-11 20:38:59,861 iteration 2922 : loss : 0.037944, loss_ce: 0.011292
2021-12-11 20:39:01,479 iteration 2923 : loss : 0.039769, loss_ce: 0.010802
2021-12-11 20:39:03,068 iteration 2924 : loss : 0.023571, loss_ce: 0.009335
 43%|███████████▌               | 172/400 [1:21:37<1:47:22, 28.26s/it]2021-12-11 20:39:04,662 iteration 2925 : loss : 0.038413, loss_ce: 0.017651
2021-12-11 20:39:06,140 iteration 2926 : loss : 0.024863, loss_ce: 0.008875
2021-12-11 20:39:07,675 iteration 2927 : loss : 0.020975, loss_ce: 0.007282
2021-12-11 20:39:09,244 iteration 2928 : loss : 0.024181, loss_ce: 0.009183
2021-12-11 20:39:10,742 iteration 2929 : loss : 0.027439, loss_ce: 0.007253
2021-12-11 20:39:12,232 iteration 2930 : loss : 0.024858, loss_ce: 0.010829
2021-12-11 20:39:13,756 iteration 2931 : loss : 0.051722, loss_ce: 0.013618
2021-12-11 20:39:15,378 iteration 2932 : loss : 0.031325, loss_ce: 0.012217
2021-12-11 20:39:16,963 iteration 2933 : loss : 0.041888, loss_ce: 0.018257
2021-12-11 20:39:18,574 iteration 2934 : loss : 0.030127, loss_ce: 0.014876
2021-12-11 20:39:20,090 iteration 2935 : loss : 0.029242, loss_ce: 0.009888
2021-12-11 20:39:21,619 iteration 2936 : loss : 0.027831, loss_ce: 0.011917
2021-12-11 20:39:23,164 iteration 2937 : loss : 0.027678, loss_ce: 0.013595
2021-12-11 20:39:24,730 iteration 2938 : loss : 0.035681, loss_ce: 0.012199
2021-12-11 20:39:26,175 iteration 2939 : loss : 0.031864, loss_ce: 0.008379
2021-12-11 20:39:27,690 iteration 2940 : loss : 0.024694, loss_ce: 0.009362
2021-12-11 20:39:29,206 iteration 2941 : loss : 0.039265, loss_ce: 0.016907
 43%|███████████▋               | 173/400 [1:22:03<1:44:29, 27.62s/it]2021-12-11 20:39:30,870 iteration 2942 : loss : 0.035121, loss_ce: 0.016199
2021-12-11 20:39:32,447 iteration 2943 : loss : 0.024993, loss_ce: 0.011051
2021-12-11 20:39:34,009 iteration 2944 : loss : 0.041587, loss_ce: 0.015987
2021-12-11 20:39:35,547 iteration 2945 : loss : 0.042039, loss_ce: 0.018169
2021-12-11 20:39:37,149 iteration 2946 : loss : 0.035988, loss_ce: 0.014423
2021-12-11 20:39:38,661 iteration 2947 : loss : 0.035490, loss_ce: 0.011247
2021-12-11 20:39:40,262 iteration 2948 : loss : 0.027726, loss_ce: 0.010333
2021-12-11 20:39:41,790 iteration 2949 : loss : 0.028644, loss_ce: 0.011197
2021-12-11 20:39:43,243 iteration 2950 : loss : 0.022202, loss_ce: 0.008291
2021-12-11 20:39:44,769 iteration 2951 : loss : 0.030963, loss_ce: 0.009262
2021-12-11 20:39:46,219 iteration 2952 : loss : 0.083469, loss_ce: 0.015947
2021-12-11 20:39:47,815 iteration 2953 : loss : 0.028125, loss_ce: 0.010590
2021-12-11 20:39:49,362 iteration 2954 : loss : 0.027576, loss_ce: 0.010625
2021-12-11 20:39:50,909 iteration 2955 : loss : 0.038819, loss_ce: 0.010792
2021-12-11 20:39:52,392 iteration 2956 : loss : 0.039918, loss_ce: 0.022417
2021-12-11 20:39:53,865 iteration 2957 : loss : 0.032569, loss_ce: 0.011289
2021-12-11 20:39:55,401 iteration 2958 : loss : 0.041820, loss_ce: 0.019585
 44%|███████████▋               | 174/400 [1:22:29<1:42:25, 27.19s/it]2021-12-11 20:39:57,008 iteration 2959 : loss : 0.036723, loss_ce: 0.018209
2021-12-11 20:39:58,579 iteration 2960 : loss : 0.032871, loss_ce: 0.015671
2021-12-11 20:40:00,154 iteration 2961 : loss : 0.046764, loss_ce: 0.025666
2021-12-11 20:40:01,725 iteration 2962 : loss : 0.028829, loss_ce: 0.009671
2021-12-11 20:40:03,235 iteration 2963 : loss : 0.029104, loss_ce: 0.011945
2021-12-11 20:40:04,738 iteration 2964 : loss : 0.038640, loss_ce: 0.013930
2021-12-11 20:40:06,196 iteration 2965 : loss : 0.046467, loss_ce: 0.014194
2021-12-11 20:40:07,647 iteration 2966 : loss : 0.035770, loss_ce: 0.012278
2021-12-11 20:40:09,205 iteration 2967 : loss : 0.035609, loss_ce: 0.013639
2021-12-11 20:40:10,830 iteration 2968 : loss : 0.067616, loss_ce: 0.021235
2021-12-11 20:40:12,410 iteration 2969 : loss : 0.032452, loss_ce: 0.012653
2021-12-11 20:40:13,925 iteration 2970 : loss : 0.030205, loss_ce: 0.011114
2021-12-11 20:40:15,393 iteration 2971 : loss : 0.030980, loss_ce: 0.014458
2021-12-11 20:40:16,978 iteration 2972 : loss : 0.033993, loss_ce: 0.011309
2021-12-11 20:40:18,473 iteration 2973 : loss : 0.034423, loss_ce: 0.013205
2021-12-11 20:40:20,072 iteration 2974 : loss : 0.022861, loss_ce: 0.007217
2021-12-11 20:40:20,072 Training Data Eval:
2021-12-11 20:40:27,709   Average segmentation loss on training set: 0.0222
2021-12-11 20:40:27,709 Validation Data Eval:
2021-12-11 20:40:30,352   Average segmentation loss on validation set: 0.0707
2021-12-11 20:40:31,931 iteration 2975 : loss : 0.042275, loss_ce: 0.013360
 44%|███████████▊               | 175/400 [1:23:06<1:52:29, 30.00s/it]2021-12-11 20:40:33,594 iteration 2976 : loss : 0.033854, loss_ce: 0.019049
2021-12-11 20:40:35,066 iteration 2977 : loss : 0.034378, loss_ce: 0.014139
2021-12-11 20:40:36,514 iteration 2978 : loss : 0.045000, loss_ce: 0.016848
2021-12-11 20:40:38,087 iteration 2979 : loss : 0.026935, loss_ce: 0.009577
2021-12-11 20:40:39,755 iteration 2980 : loss : 0.035857, loss_ce: 0.015287
2021-12-11 20:40:41,311 iteration 2981 : loss : 0.040797, loss_ce: 0.013770
2021-12-11 20:40:42,973 iteration 2982 : loss : 0.029540, loss_ce: 0.012682
2021-12-11 20:40:44,491 iteration 2983 : loss : 0.035036, loss_ce: 0.016290
2021-12-11 20:40:46,098 iteration 2984 : loss : 0.028482, loss_ce: 0.010686
2021-12-11 20:40:47,655 iteration 2985 : loss : 0.040049, loss_ce: 0.011139
2021-12-11 20:40:49,246 iteration 2986 : loss : 0.031322, loss_ce: 0.013423
2021-12-11 20:40:50,740 iteration 2987 : loss : 0.032784, loss_ce: 0.014629
2021-12-11 20:40:52,250 iteration 2988 : loss : 0.022198, loss_ce: 0.006677
2021-12-11 20:40:53,804 iteration 2989 : loss : 0.024180, loss_ce: 0.007009
2021-12-11 20:40:55,370 iteration 2990 : loss : 0.035694, loss_ce: 0.014850
2021-12-11 20:40:56,996 iteration 2991 : loss : 0.032439, loss_ce: 0.011858
2021-12-11 20:40:58,681 iteration 2992 : loss : 0.034536, loss_ce: 0.013834
 44%|███████████▉               | 176/400 [1:23:32<1:48:20, 29.02s/it]2021-12-11 20:41:00,181 iteration 2993 : loss : 0.035906, loss_ce: 0.008221
2021-12-11 20:41:01,763 iteration 2994 : loss : 0.029350, loss_ce: 0.011206
2021-12-11 20:41:03,390 iteration 2995 : loss : 0.031242, loss_ce: 0.013467
2021-12-11 20:41:04,926 iteration 2996 : loss : 0.040016, loss_ce: 0.014831
2021-12-11 20:41:06,446 iteration 2997 : loss : 0.024957, loss_ce: 0.008942
2021-12-11 20:41:07,970 iteration 2998 : loss : 0.024327, loss_ce: 0.006926
2021-12-11 20:41:09,560 iteration 2999 : loss : 0.032692, loss_ce: 0.012346
2021-12-11 20:41:11,084 iteration 3000 : loss : 0.052099, loss_ce: 0.015996
2021-12-11 20:41:12,661 iteration 3001 : loss : 0.026491, loss_ce: 0.010391
2021-12-11 20:41:14,113 iteration 3002 : loss : 0.034166, loss_ce: 0.012952
2021-12-11 20:41:15,700 iteration 3003 : loss : 0.034991, loss_ce: 0.013804
2021-12-11 20:41:17,152 iteration 3004 : loss : 0.024480, loss_ce: 0.009354
2021-12-11 20:41:18,709 iteration 3005 : loss : 0.038632, loss_ce: 0.013968
2021-12-11 20:41:20,291 iteration 3006 : loss : 0.036643, loss_ce: 0.014090
2021-12-11 20:41:21,789 iteration 3007 : loss : 0.021428, loss_ce: 0.008078
2021-12-11 20:41:23,426 iteration 3008 : loss : 0.039542, loss_ce: 0.021243
2021-12-11 20:41:24,943 iteration 3009 : loss : 0.028120, loss_ce: 0.015329
 44%|███████████▉               | 177/400 [1:23:59<1:44:46, 28.19s/it]2021-12-11 20:41:26,502 iteration 3010 : loss : 0.027774, loss_ce: 0.010534
2021-12-11 20:41:28,030 iteration 3011 : loss : 0.036522, loss_ce: 0.012828
2021-12-11 20:41:29,531 iteration 3012 : loss : 0.026389, loss_ce: 0.008418
2021-12-11 20:41:31,068 iteration 3013 : loss : 0.023683, loss_ce: 0.011015
2021-12-11 20:41:32,658 iteration 3014 : loss : 0.040981, loss_ce: 0.014286
2021-12-11 20:41:34,221 iteration 3015 : loss : 0.031001, loss_ce: 0.010986
2021-12-11 20:41:35,747 iteration 3016 : loss : 0.023834, loss_ce: 0.009013
2021-12-11 20:41:37,280 iteration 3017 : loss : 0.031534, loss_ce: 0.008566
2021-12-11 20:41:38,762 iteration 3018 : loss : 0.023517, loss_ce: 0.006170
2021-12-11 20:41:40,278 iteration 3019 : loss : 0.032430, loss_ce: 0.011770
2021-12-11 20:41:41,692 iteration 3020 : loss : 0.024276, loss_ce: 0.011444
2021-12-11 20:41:43,134 iteration 3021 : loss : 0.030566, loss_ce: 0.011208
2021-12-11 20:41:44,643 iteration 3022 : loss : 0.032866, loss_ce: 0.010542
2021-12-11 20:41:46,201 iteration 3023 : loss : 0.027080, loss_ce: 0.012968
2021-12-11 20:41:47,740 iteration 3024 : loss : 0.031456, loss_ce: 0.011638
2021-12-11 20:41:49,172 iteration 3025 : loss : 0.025958, loss_ce: 0.010307
2021-12-11 20:41:50,735 iteration 3026 : loss : 0.029316, loss_ce: 0.013945
 44%|████████████               | 178/400 [1:24:24<1:41:39, 27.47s/it]2021-12-11 20:41:52,312 iteration 3027 : loss : 0.031071, loss_ce: 0.014095
2021-12-11 20:41:53,839 iteration 3028 : loss : 0.031001, loss_ce: 0.012817
2021-12-11 20:41:55,382 iteration 3029 : loss : 0.031388, loss_ce: 0.014306
2021-12-11 20:41:57,013 iteration 3030 : loss : 0.029628, loss_ce: 0.011038
2021-12-11 20:41:58,451 iteration 3031 : loss : 0.024771, loss_ce: 0.009703
2021-12-11 20:41:59,977 iteration 3032 : loss : 0.023290, loss_ce: 0.007644
2021-12-11 20:42:01,532 iteration 3033 : loss : 0.029959, loss_ce: 0.015475
2021-12-11 20:42:03,056 iteration 3034 : loss : 0.022628, loss_ce: 0.007686
2021-12-11 20:42:04,724 iteration 3035 : loss : 0.036615, loss_ce: 0.011910
2021-12-11 20:42:06,274 iteration 3036 : loss : 0.024092, loss_ce: 0.010518
2021-12-11 20:42:07,869 iteration 3037 : loss : 0.023141, loss_ce: 0.008303
2021-12-11 20:42:09,331 iteration 3038 : loss : 0.023248, loss_ce: 0.005863
2021-12-11 20:42:11,031 iteration 3039 : loss : 0.033429, loss_ce: 0.010847
2021-12-11 20:42:12,506 iteration 3040 : loss : 0.024990, loss_ce: 0.011023
2021-12-11 20:42:13,999 iteration 3041 : loss : 0.036935, loss_ce: 0.015166
2021-12-11 20:42:15,494 iteration 3042 : loss : 0.024797, loss_ce: 0.010192
2021-12-11 20:42:17,139 iteration 3043 : loss : 0.026234, loss_ce: 0.010442
 45%|████████████               | 179/400 [1:24:51<1:40:00, 27.15s/it]2021-12-11 20:42:18,736 iteration 3044 : loss : 0.050214, loss_ce: 0.019672
2021-12-11 20:42:20,243 iteration 3045 : loss : 0.027499, loss_ce: 0.011028
2021-12-11 20:42:21,744 iteration 3046 : loss : 0.036175, loss_ce: 0.012083
2021-12-11 20:42:23,389 iteration 3047 : loss : 0.051201, loss_ce: 0.025664
2021-12-11 20:42:24,978 iteration 3048 : loss : 0.029144, loss_ce: 0.014406
2021-12-11 20:42:26,478 iteration 3049 : loss : 0.030360, loss_ce: 0.011674
2021-12-11 20:42:28,105 iteration 3050 : loss : 0.029921, loss_ce: 0.014541
2021-12-11 20:42:29,673 iteration 3051 : loss : 0.067354, loss_ce: 0.016604
2021-12-11 20:42:31,300 iteration 3052 : loss : 0.039181, loss_ce: 0.016018
2021-12-11 20:42:32,869 iteration 3053 : loss : 0.022433, loss_ce: 0.008850
2021-12-11 20:42:34,444 iteration 3054 : loss : 0.034451, loss_ce: 0.013505
2021-12-11 20:42:36,025 iteration 3055 : loss : 0.043400, loss_ce: 0.018257
2021-12-11 20:42:37,561 iteration 3056 : loss : 0.032173, loss_ce: 0.011306
2021-12-11 20:42:39,059 iteration 3057 : loss : 0.028785, loss_ce: 0.010773
2021-12-11 20:42:40,678 iteration 3058 : loss : 0.051277, loss_ce: 0.019140
2021-12-11 20:42:42,290 iteration 3059 : loss : 0.038192, loss_ce: 0.014730
2021-12-11 20:42:42,291 Training Data Eval:
2021-12-11 20:42:49,920   Average segmentation loss on training set: 0.0243
2021-12-11 20:42:49,920 Validation Data Eval:
2021-12-11 20:42:52,560   Average segmentation loss on validation set: 0.0770
2021-12-11 20:42:54,099 iteration 3060 : loss : 0.030447, loss_ce: 0.010933
 45%|████████████▏              | 180/400 [1:25:28<1:50:21, 30.10s/it]2021-12-11 20:42:55,647 iteration 3061 : loss : 0.043752, loss_ce: 0.014934
2021-12-11 20:42:57,214 iteration 3062 : loss : 0.046116, loss_ce: 0.013983
2021-12-11 20:42:58,738 iteration 3063 : loss : 0.036757, loss_ce: 0.014257
2021-12-11 20:43:00,330 iteration 3064 : loss : 0.034265, loss_ce: 0.017811
2021-12-11 20:43:01,869 iteration 3065 : loss : 0.043387, loss_ce: 0.010774
2021-12-11 20:43:03,391 iteration 3066 : loss : 0.032026, loss_ce: 0.008336
2021-12-11 20:43:04,951 iteration 3067 : loss : 0.036295, loss_ce: 0.017308
2021-12-11 20:43:06,550 iteration 3068 : loss : 0.020655, loss_ce: 0.007055
2021-12-11 20:43:08,154 iteration 3069 : loss : 0.040136, loss_ce: 0.008436
2021-12-11 20:43:09,631 iteration 3070 : loss : 0.023218, loss_ce: 0.009030
2021-12-11 20:43:11,247 iteration 3071 : loss : 0.028949, loss_ce: 0.010936
2021-12-11 20:43:12,814 iteration 3072 : loss : 0.021419, loss_ce: 0.007775
2021-12-11 20:43:14,323 iteration 3073 : loss : 0.032023, loss_ce: 0.010703
2021-12-11 20:43:15,973 iteration 3074 : loss : 0.037950, loss_ce: 0.016552
2021-12-11 20:43:17,573 iteration 3075 : loss : 0.036716, loss_ce: 0.014224
2021-12-11 20:43:19,099 iteration 3076 : loss : 0.029806, loss_ce: 0.012749
2021-12-11 20:43:20,753 iteration 3077 : loss : 0.040430, loss_ce: 0.021804
 45%|████████████▏              | 181/400 [1:25:54<1:46:04, 29.06s/it]2021-12-11 20:43:22,225 iteration 3078 : loss : 0.019764, loss_ce: 0.007928
2021-12-11 20:43:23,811 iteration 3079 : loss : 0.042451, loss_ce: 0.014002
2021-12-11 20:43:25,354 iteration 3080 : loss : 0.030139, loss_ce: 0.011362
2021-12-11 20:43:26,877 iteration 3081 : loss : 0.037687, loss_ce: 0.010643
2021-12-11 20:43:28,426 iteration 3082 : loss : 0.029610, loss_ce: 0.011230
2021-12-11 20:43:29,965 iteration 3083 : loss : 0.033964, loss_ce: 0.014583
2021-12-11 20:43:31,482 iteration 3084 : loss : 0.023047, loss_ce: 0.008952
2021-12-11 20:43:33,029 iteration 3085 : loss : 0.053315, loss_ce: 0.011510
2021-12-11 20:43:34,518 iteration 3086 : loss : 0.021800, loss_ce: 0.007995
2021-12-11 20:43:36,005 iteration 3087 : loss : 0.030324, loss_ce: 0.007915
2021-12-11 20:43:37,490 iteration 3088 : loss : 0.022554, loss_ce: 0.007668
2021-12-11 20:43:38,987 iteration 3089 : loss : 0.028174, loss_ce: 0.010776
2021-12-11 20:43:40,546 iteration 3090 : loss : 0.029421, loss_ce: 0.010433
2021-12-11 20:43:42,042 iteration 3091 : loss : 0.035226, loss_ce: 0.013201
2021-12-11 20:43:43,489 iteration 3092 : loss : 0.032725, loss_ce: 0.015228
2021-12-11 20:43:45,015 iteration 3093 : loss : 0.023683, loss_ce: 0.007543
2021-12-11 20:43:46,517 iteration 3094 : loss : 0.038669, loss_ce: 0.018898
 46%|████████████▎              | 182/400 [1:26:20<1:41:59, 28.07s/it]2021-12-11 20:43:48,145 iteration 3095 : loss : 0.024855, loss_ce: 0.007953
2021-12-11 20:43:49,659 iteration 3096 : loss : 0.022181, loss_ce: 0.008306
2021-12-11 20:43:51,179 iteration 3097 : loss : 0.038968, loss_ce: 0.015180
2021-12-11 20:43:52,668 iteration 3098 : loss : 0.025249, loss_ce: 0.008588
2021-12-11 20:43:54,280 iteration 3099 : loss : 0.055863, loss_ce: 0.015973
2021-12-11 20:43:55,773 iteration 3100 : loss : 0.028142, loss_ce: 0.008951
2021-12-11 20:43:57,317 iteration 3101 : loss : 0.028381, loss_ce: 0.013474
2021-12-11 20:43:58,902 iteration 3102 : loss : 0.038924, loss_ce: 0.012490
2021-12-11 20:44:00,427 iteration 3103 : loss : 0.028869, loss_ce: 0.008088
2021-12-11 20:44:01,959 iteration 3104 : loss : 0.029012, loss_ce: 0.009764
2021-12-11 20:44:03,479 iteration 3105 : loss : 0.025852, loss_ce: 0.008072
2021-12-11 20:44:05,165 iteration 3106 : loss : 0.056934, loss_ce: 0.026284
2021-12-11 20:44:06,689 iteration 3107 : loss : 0.032415, loss_ce: 0.011462
2021-12-11 20:44:08,164 iteration 3108 : loss : 0.027866, loss_ce: 0.009279
2021-12-11 20:44:09,753 iteration 3109 : loss : 0.046172, loss_ce: 0.024865
2021-12-11 20:44:11,348 iteration 3110 : loss : 0.049277, loss_ce: 0.025193
2021-12-11 20:44:12,852 iteration 3111 : loss : 0.032451, loss_ce: 0.009939
 46%|████████████▎              | 183/400 [1:26:46<1:39:38, 27.55s/it]2021-12-11 20:44:14,386 iteration 3112 : loss : 0.022854, loss_ce: 0.009124
2021-12-11 20:44:15,909 iteration 3113 : loss : 0.027965, loss_ce: 0.011865
2021-12-11 20:44:17,567 iteration 3114 : loss : 0.055438, loss_ce: 0.014681
2021-12-11 20:44:19,158 iteration 3115 : loss : 0.023444, loss_ce: 0.010575
2021-12-11 20:44:20,721 iteration 3116 : loss : 0.027302, loss_ce: 0.011249
2021-12-11 20:44:22,243 iteration 3117 : loss : 0.026706, loss_ce: 0.011932
2021-12-11 20:44:23,845 iteration 3118 : loss : 0.026687, loss_ce: 0.010863
2021-12-11 20:44:25,467 iteration 3119 : loss : 0.037023, loss_ce: 0.015067
2021-12-11 20:44:27,023 iteration 3120 : loss : 0.022635, loss_ce: 0.007328
2021-12-11 20:44:28,579 iteration 3121 : loss : 0.036647, loss_ce: 0.011050
2021-12-11 20:44:30,178 iteration 3122 : loss : 0.034655, loss_ce: 0.010226
2021-12-11 20:44:31,721 iteration 3123 : loss : 0.024062, loss_ce: 0.008957
2021-12-11 20:44:33,280 iteration 3124 : loss : 0.027408, loss_ce: 0.010748
2021-12-11 20:44:34,852 iteration 3125 : loss : 0.050824, loss_ce: 0.025053
2021-12-11 20:44:36,328 iteration 3126 : loss : 0.024303, loss_ce: 0.009821
2021-12-11 20:44:37,884 iteration 3127 : loss : 0.028119, loss_ce: 0.011628
2021-12-11 20:44:39,345 iteration 3128 : loss : 0.025658, loss_ce: 0.008337
 46%|████████████▍              | 184/400 [1:27:13<1:38:01, 27.23s/it]2021-12-11 20:44:40,955 iteration 3129 : loss : 0.027999, loss_ce: 0.009634
2021-12-11 20:44:42,525 iteration 3130 : loss : 0.040073, loss_ce: 0.014512
2021-12-11 20:44:44,139 iteration 3131 : loss : 0.033931, loss_ce: 0.012565
2021-12-11 20:44:45,672 iteration 3132 : loss : 0.027605, loss_ce: 0.011402
2021-12-11 20:44:47,153 iteration 3133 : loss : 0.028702, loss_ce: 0.010222
2021-12-11 20:44:48,696 iteration 3134 : loss : 0.022000, loss_ce: 0.006949
2021-12-11 20:44:50,234 iteration 3135 : loss : 0.032629, loss_ce: 0.010634
2021-12-11 20:44:51,833 iteration 3136 : loss : 0.045373, loss_ce: 0.017324
2021-12-11 20:44:53,397 iteration 3137 : loss : 0.035341, loss_ce: 0.016115
2021-12-11 20:44:54,989 iteration 3138 : loss : 0.027860, loss_ce: 0.013447
2021-12-11 20:44:56,602 iteration 3139 : loss : 0.036609, loss_ce: 0.013320
2021-12-11 20:44:58,197 iteration 3140 : loss : 0.039852, loss_ce: 0.014667
2021-12-11 20:44:59,793 iteration 3141 : loss : 0.040131, loss_ce: 0.014775
2021-12-11 20:45:01,330 iteration 3142 : loss : 0.026357, loss_ce: 0.008936
2021-12-11 20:45:02,946 iteration 3143 : loss : 0.031241, loss_ce: 0.013049
2021-12-11 20:45:04,592 iteration 3144 : loss : 0.023093, loss_ce: 0.009493
2021-12-11 20:45:04,592 Training Data Eval:
2021-12-11 20:45:12,226   Average segmentation loss on training set: 0.0226
2021-12-11 20:45:12,227 Validation Data Eval:
2021-12-11 20:45:14,884   Average segmentation loss on validation set: 0.0809
2021-12-11 20:45:16,315 iteration 3145 : loss : 0.024694, loss_ce: 0.009025
 46%|████████████▍              | 185/400 [1:27:50<1:48:03, 30.16s/it]2021-12-11 20:45:17,804 iteration 3146 : loss : 0.024856, loss_ce: 0.008768
2021-12-11 20:45:19,320 iteration 3147 : loss : 0.027277, loss_ce: 0.010840
2021-12-11 20:45:20,851 iteration 3148 : loss : 0.025735, loss_ce: 0.008379
2021-12-11 20:45:22,362 iteration 3149 : loss : 0.019894, loss_ce: 0.006581
2021-12-11 20:45:23,879 iteration 3150 : loss : 0.023535, loss_ce: 0.009846
2021-12-11 20:45:25,384 iteration 3151 : loss : 0.034203, loss_ce: 0.008274
2021-12-11 20:45:26,925 iteration 3152 : loss : 0.025506, loss_ce: 0.009642
2021-12-11 20:45:28,511 iteration 3153 : loss : 0.024578, loss_ce: 0.009896
2021-12-11 20:45:30,013 iteration 3154 : loss : 0.024920, loss_ce: 0.011230
2021-12-11 20:45:31,534 iteration 3155 : loss : 0.024705, loss_ce: 0.007995
2021-12-11 20:45:33,138 iteration 3156 : loss : 0.038417, loss_ce: 0.015723
2021-12-11 20:45:34,712 iteration 3157 : loss : 0.032420, loss_ce: 0.011407
2021-12-11 20:45:36,236 iteration 3158 : loss : 0.033320, loss_ce: 0.013664
2021-12-11 20:45:37,768 iteration 3159 : loss : 0.023989, loss_ce: 0.009018
2021-12-11 20:45:39,304 iteration 3160 : loss : 0.030114, loss_ce: 0.014570
2021-12-11 20:45:40,799 iteration 3161 : loss : 0.025296, loss_ce: 0.008576
2021-12-11 20:45:42,407 iteration 3162 : loss : 0.022426, loss_ce: 0.008423
 46%|████████████▌              | 186/400 [1:28:16<1:43:12, 28.94s/it]2021-12-11 20:45:44,039 iteration 3163 : loss : 0.030492, loss_ce: 0.013265
2021-12-11 20:45:45,637 iteration 3164 : loss : 0.022871, loss_ce: 0.008260
2021-12-11 20:45:47,165 iteration 3165 : loss : 0.025269, loss_ce: 0.008755
2021-12-11 20:45:48,767 iteration 3166 : loss : 0.025477, loss_ce: 0.008540
2021-12-11 20:45:50,312 iteration 3167 : loss : 0.017804, loss_ce: 0.007188
2021-12-11 20:45:51,987 iteration 3168 : loss : 0.033523, loss_ce: 0.013954
2021-12-11 20:45:53,625 iteration 3169 : loss : 0.044943, loss_ce: 0.021746
2021-12-11 20:45:55,155 iteration 3170 : loss : 0.022380, loss_ce: 0.009299
2021-12-11 20:45:56,614 iteration 3171 : loss : 0.021520, loss_ce: 0.009469
2021-12-11 20:45:58,231 iteration 3172 : loss : 0.021086, loss_ce: 0.007643
2021-12-11 20:45:59,839 iteration 3173 : loss : 0.020958, loss_ce: 0.007794
2021-12-11 20:46:01,370 iteration 3174 : loss : 0.030712, loss_ce: 0.012154
2021-12-11 20:46:03,017 iteration 3175 : loss : 0.050138, loss_ce: 0.014113
2021-12-11 20:46:04,564 iteration 3176 : loss : 0.031951, loss_ce: 0.011197
2021-12-11 20:46:06,156 iteration 3177 : loss : 0.031325, loss_ce: 0.010530
2021-12-11 20:46:07,642 iteration 3178 : loss : 0.032645, loss_ce: 0.010594
2021-12-11 20:46:09,164 iteration 3179 : loss : 0.040343, loss_ce: 0.012705
 47%|████████████▌              | 187/400 [1:28:43<1:40:24, 28.28s/it]2021-12-11 20:46:10,799 iteration 3180 : loss : 0.042778, loss_ce: 0.019734
2021-12-11 20:46:12,309 iteration 3181 : loss : 0.022510, loss_ce: 0.007723
2021-12-11 20:46:13,860 iteration 3182 : loss : 0.032437, loss_ce: 0.010002
2021-12-11 20:46:15,376 iteration 3183 : loss : 0.021242, loss_ce: 0.005946
2021-12-11 20:46:16,959 iteration 3184 : loss : 0.024592, loss_ce: 0.008869
2021-12-11 20:46:18,548 iteration 3185 : loss : 0.029093, loss_ce: 0.010165
2021-12-11 20:46:20,003 iteration 3186 : loss : 0.028980, loss_ce: 0.013978
2021-12-11 20:46:21,559 iteration 3187 : loss : 0.020272, loss_ce: 0.007335
2021-12-11 20:46:23,085 iteration 3188 : loss : 0.024112, loss_ce: 0.009530
2021-12-11 20:46:24,649 iteration 3189 : loss : 0.026061, loss_ce: 0.011082
2021-12-11 20:46:26,183 iteration 3190 : loss : 0.024570, loss_ce: 0.008469
2021-12-11 20:46:27,846 iteration 3191 : loss : 0.042527, loss_ce: 0.010886
2021-12-11 20:46:29,379 iteration 3192 : loss : 0.030260, loss_ce: 0.009263
2021-12-11 20:46:30,976 iteration 3193 : loss : 0.035466, loss_ce: 0.016975
2021-12-11 20:46:32,563 iteration 3194 : loss : 0.035636, loss_ce: 0.011611
2021-12-11 20:46:34,119 iteration 3195 : loss : 0.026921, loss_ce: 0.011496
2021-12-11 20:46:35,661 iteration 3196 : loss : 0.027048, loss_ce: 0.011717
 47%|████████████▋              | 188/400 [1:29:09<1:38:02, 27.75s/it]2021-12-11 20:46:37,166 iteration 3197 : loss : 0.023588, loss_ce: 0.009736
2021-12-11 20:46:38,693 iteration 3198 : loss : 0.026675, loss_ce: 0.011644
2021-12-11 20:46:40,236 iteration 3199 : loss : 0.039875, loss_ce: 0.017720
2021-12-11 20:46:41,879 iteration 3200 : loss : 0.027926, loss_ce: 0.013384
2021-12-11 20:46:43,456 iteration 3201 : loss : 0.029254, loss_ce: 0.008361
2021-12-11 20:46:44,996 iteration 3202 : loss : 0.038826, loss_ce: 0.014990
2021-12-11 20:46:46,640 iteration 3203 : loss : 0.028880, loss_ce: 0.011885
2021-12-11 20:46:48,231 iteration 3204 : loss : 0.023860, loss_ce: 0.007121
2021-12-11 20:46:49,839 iteration 3205 : loss : 0.026018, loss_ce: 0.007941
2021-12-11 20:46:51,397 iteration 3206 : loss : 0.023763, loss_ce: 0.009008
2021-12-11 20:46:53,048 iteration 3207 : loss : 0.032330, loss_ce: 0.014099
2021-12-11 20:46:54,546 iteration 3208 : loss : 0.027312, loss_ce: 0.007689
2021-12-11 20:46:56,037 iteration 3209 : loss : 0.030281, loss_ce: 0.014994
2021-12-11 20:46:57,489 iteration 3210 : loss : 0.020712, loss_ce: 0.009411
2021-12-11 20:46:59,023 iteration 3211 : loss : 0.028231, loss_ce: 0.008265
2021-12-11 20:47:00,538 iteration 3212 : loss : 0.023673, loss_ce: 0.008840
2021-12-11 20:47:02,083 iteration 3213 : loss : 0.038163, loss_ce: 0.010990
 47%|████████████▊              | 189/400 [1:29:36<1:36:10, 27.35s/it]2021-12-11 20:47:03,679 iteration 3214 : loss : 0.025367, loss_ce: 0.012060
2021-12-11 20:47:05,316 iteration 3215 : loss : 0.031113, loss_ce: 0.011639
2021-12-11 20:47:06,925 iteration 3216 : loss : 0.033129, loss_ce: 0.011649
2021-12-11 20:47:08,530 iteration 3217 : loss : 0.046898, loss_ce: 0.009007
2021-12-11 20:47:10,105 iteration 3218 : loss : 0.027195, loss_ce: 0.009829
2021-12-11 20:47:11,624 iteration 3219 : loss : 0.025024, loss_ce: 0.008628
2021-12-11 20:47:13,209 iteration 3220 : loss : 0.038277, loss_ce: 0.016114
2021-12-11 20:47:14,724 iteration 3221 : loss : 0.027062, loss_ce: 0.009871
2021-12-11 20:47:16,277 iteration 3222 : loss : 0.041508, loss_ce: 0.025399
2021-12-11 20:47:17,850 iteration 3223 : loss : 0.025363, loss_ce: 0.006657
2021-12-11 20:47:19,496 iteration 3224 : loss : 0.023981, loss_ce: 0.008358
2021-12-11 20:47:21,021 iteration 3225 : loss : 0.029374, loss_ce: 0.010065
2021-12-11 20:47:22,664 iteration 3226 : loss : 0.036007, loss_ce: 0.011842
2021-12-11 20:47:24,230 iteration 3227 : loss : 0.025950, loss_ce: 0.010503
2021-12-11 20:47:25,697 iteration 3228 : loss : 0.021943, loss_ce: 0.009732
2021-12-11 20:47:27,313 iteration 3229 : loss : 0.033247, loss_ce: 0.013122
2021-12-11 20:47:27,314 Training Data Eval:
2021-12-11 20:47:34,952   Average segmentation loss on training set: 0.0192
2021-12-11 20:47:34,952 Validation Data Eval:
2021-12-11 20:47:37,586   Average segmentation loss on validation set: 0.0963
2021-12-11 20:47:39,236 iteration 3230 : loss : 0.045535, loss_ce: 0.014859
 48%|████████████▊              | 190/400 [1:30:13<1:46:00, 30.29s/it]2021-12-11 20:47:40,793 iteration 3231 : loss : 0.042867, loss_ce: 0.014594
2021-12-11 20:47:42,323 iteration 3232 : loss : 0.025661, loss_ce: 0.011008
2021-12-11 20:47:43,858 iteration 3233 : loss : 0.030220, loss_ce: 0.009611
2021-12-11 20:47:45,344 iteration 3234 : loss : 0.026611, loss_ce: 0.008305
2021-12-11 20:47:46,842 iteration 3235 : loss : 0.022069, loss_ce: 0.005531
2021-12-11 20:47:48,411 iteration 3236 : loss : 0.023381, loss_ce: 0.010237
2021-12-11 20:47:50,002 iteration 3237 : loss : 0.022274, loss_ce: 0.009442
2021-12-11 20:47:51,563 iteration 3238 : loss : 0.030888, loss_ce: 0.006521
2021-12-11 20:47:53,112 iteration 3239 : loss : 0.024226, loss_ce: 0.009743
2021-12-11 20:47:54,676 iteration 3240 : loss : 0.033522, loss_ce: 0.010925
2021-12-11 20:47:56,272 iteration 3241 : loss : 0.035297, loss_ce: 0.014772
2021-12-11 20:47:57,916 iteration 3242 : loss : 0.029613, loss_ce: 0.014512
2021-12-11 20:47:59,428 iteration 3243 : loss : 0.025965, loss_ce: 0.011977
2021-12-11 20:48:00,971 iteration 3244 : loss : 0.040468, loss_ce: 0.010731
2021-12-11 20:48:02,501 iteration 3245 : loss : 0.027083, loss_ce: 0.011264
2021-12-11 20:48:04,135 iteration 3246 : loss : 0.033688, loss_ce: 0.014182
2021-12-11 20:48:05,759 iteration 3247 : loss : 0.027609, loss_ce: 0.009760
 48%|████████████▉              | 191/400 [1:30:39<1:41:34, 29.16s/it]2021-12-11 20:48:07,498 iteration 3248 : loss : 0.030197, loss_ce: 0.015197
2021-12-11 20:48:08,968 iteration 3249 : loss : 0.020834, loss_ce: 0.005946
2021-12-11 20:48:10,544 iteration 3250 : loss : 0.033037, loss_ce: 0.011040
2021-12-11 20:48:12,090 iteration 3251 : loss : 0.033338, loss_ce: 0.006264
2021-12-11 20:48:13,588 iteration 3252 : loss : 0.023064, loss_ce: 0.009301
2021-12-11 20:48:15,153 iteration 3253 : loss : 0.038140, loss_ce: 0.016080
2021-12-11 20:48:16,696 iteration 3254 : loss : 0.041081, loss_ce: 0.011118
2021-12-11 20:48:18,298 iteration 3255 : loss : 0.026548, loss_ce: 0.009406
2021-12-11 20:48:19,776 iteration 3256 : loss : 0.026522, loss_ce: 0.014914
2021-12-11 20:48:21,307 iteration 3257 : loss : 0.029563, loss_ce: 0.009180
2021-12-11 20:48:22,920 iteration 3258 : loss : 0.032379, loss_ce: 0.013291
2021-12-11 20:48:24,469 iteration 3259 : loss : 0.039616, loss_ce: 0.015153
2021-12-11 20:48:25,975 iteration 3260 : loss : 0.029383, loss_ce: 0.011936
2021-12-11 20:48:27,581 iteration 3261 : loss : 0.034456, loss_ce: 0.013076
2021-12-11 20:48:29,125 iteration 3262 : loss : 0.045466, loss_ce: 0.017842
2021-12-11 20:48:30,659 iteration 3263 : loss : 0.040254, loss_ce: 0.013974
2021-12-11 20:48:32,188 iteration 3264 : loss : 0.033406, loss_ce: 0.011413
 48%|████████████▉              | 192/400 [1:31:06<1:38:15, 28.34s/it]2021-12-11 20:48:33,664 iteration 3265 : loss : 0.020886, loss_ce: 0.007692
2021-12-11 20:48:35,286 iteration 3266 : loss : 0.025198, loss_ce: 0.010837
2021-12-11 20:48:36,778 iteration 3267 : loss : 0.023798, loss_ce: 0.010492
2021-12-11 20:48:38,428 iteration 3268 : loss : 0.033756, loss_ce: 0.013152
2021-12-11 20:48:39,920 iteration 3269 : loss : 0.031882, loss_ce: 0.012274
2021-12-11 20:48:41,417 iteration 3270 : loss : 0.020077, loss_ce: 0.007594
2021-12-11 20:48:43,025 iteration 3271 : loss : 0.026273, loss_ce: 0.008995
2021-12-11 20:48:44,540 iteration 3272 : loss : 0.025718, loss_ce: 0.009475
2021-12-11 20:48:46,039 iteration 3273 : loss : 0.028506, loss_ce: 0.010181
2021-12-11 20:48:47,607 iteration 3274 : loss : 0.027108, loss_ce: 0.008640
2021-12-11 20:48:49,104 iteration 3275 : loss : 0.020845, loss_ce: 0.008586
2021-12-11 20:48:50,638 iteration 3276 : loss : 0.024625, loss_ce: 0.008175
2021-12-11 20:48:52,233 iteration 3277 : loss : 0.024185, loss_ce: 0.010996
2021-12-11 20:48:53,811 iteration 3278 : loss : 0.028444, loss_ce: 0.011053
2021-12-11 20:48:55,405 iteration 3279 : loss : 0.038940, loss_ce: 0.016889
2021-12-11 20:48:56,972 iteration 3280 : loss : 0.029600, loss_ce: 0.012045
2021-12-11 20:48:58,521 iteration 3281 : loss : 0.021936, loss_ce: 0.006892
 48%|█████████████              | 193/400 [1:31:32<1:35:41, 27.74s/it]2021-12-11 20:49:00,074 iteration 3282 : loss : 0.022096, loss_ce: 0.009723
2021-12-11 20:49:01,711 iteration 3283 : loss : 0.036324, loss_ce: 0.014298
2021-12-11 20:49:03,223 iteration 3284 : loss : 0.018984, loss_ce: 0.008510
2021-12-11 20:49:04,673 iteration 3285 : loss : 0.023469, loss_ce: 0.008962
2021-12-11 20:49:06,272 iteration 3286 : loss : 0.026709, loss_ce: 0.007972
2021-12-11 20:49:07,852 iteration 3287 : loss : 0.030328, loss_ce: 0.012792
2021-12-11 20:49:09,394 iteration 3288 : loss : 0.026238, loss_ce: 0.010002
2021-12-11 20:49:10,951 iteration 3289 : loss : 0.027870, loss_ce: 0.007714
2021-12-11 20:49:12,432 iteration 3290 : loss : 0.025129, loss_ce: 0.007631
2021-12-11 20:49:14,026 iteration 3291 : loss : 0.029621, loss_ce: 0.009909
2021-12-11 20:49:15,545 iteration 3292 : loss : 0.029558, loss_ce: 0.012256
2021-12-11 20:49:17,017 iteration 3293 : loss : 0.018761, loss_ce: 0.006831
2021-12-11 20:49:18,504 iteration 3294 : loss : 0.020216, loss_ce: 0.008434
2021-12-11 20:49:20,025 iteration 3295 : loss : 0.023012, loss_ce: 0.009679
2021-12-11 20:49:21,588 iteration 3296 : loss : 0.024536, loss_ce: 0.008218
2021-12-11 20:49:23,150 iteration 3297 : loss : 0.030432, loss_ce: 0.011905
2021-12-11 20:49:24,620 iteration 3298 : loss : 0.023686, loss_ce: 0.008893
 48%|█████████████              | 194/400 [1:31:58<1:33:33, 27.25s/it]2021-12-11 20:49:26,151 iteration 3299 : loss : 0.022751, loss_ce: 0.008523
2021-12-11 20:49:27,670 iteration 3300 : loss : 0.022848, loss_ce: 0.007609
2021-12-11 20:49:29,251 iteration 3301 : loss : 0.022982, loss_ce: 0.007262
2021-12-11 20:49:30,729 iteration 3302 : loss : 0.023442, loss_ce: 0.007184
2021-12-11 20:49:32,328 iteration 3303 : loss : 0.027396, loss_ce: 0.010006
2021-12-11 20:49:33,896 iteration 3304 : loss : 0.026466, loss_ce: 0.014603
2021-12-11 20:49:35,488 iteration 3305 : loss : 0.024230, loss_ce: 0.008978
2021-12-11 20:49:36,990 iteration 3306 : loss : 0.020107, loss_ce: 0.008070
2021-12-11 20:49:38,602 iteration 3307 : loss : 0.034336, loss_ce: 0.012129
2021-12-11 20:49:40,244 iteration 3308 : loss : 0.034478, loss_ce: 0.013968
2021-12-11 20:49:41,809 iteration 3309 : loss : 0.021939, loss_ce: 0.008204
2021-12-11 20:49:43,420 iteration 3310 : loss : 0.031763, loss_ce: 0.009140
2021-12-11 20:49:44,943 iteration 3311 : loss : 0.024857, loss_ce: 0.006920
2021-12-11 20:49:46,416 iteration 3312 : loss : 0.020443, loss_ce: 0.008814
2021-12-11 20:49:48,004 iteration 3313 : loss : 0.031843, loss_ce: 0.011794
2021-12-11 20:49:49,429 iteration 3314 : loss : 0.021389, loss_ce: 0.009140
2021-12-11 20:49:49,429 Training Data Eval:
2021-12-11 20:49:57,060   Average segmentation loss on training set: 0.0196
2021-12-11 20:49:57,104 Validation Data Eval:
2021-12-11 20:49:59,730   Average segmentation loss on validation set: 0.1007
2021-12-11 20:50:01,220 iteration 3315 : loss : 0.027323, loss_ce: 0.011100
 49%|█████████████▏             | 195/400 [1:32:35<1:42:40, 30.05s/it]2021-12-11 20:50:02,789 iteration 3316 : loss : 0.021163, loss_ce: 0.005139
2021-12-11 20:50:04,352 iteration 3317 : loss : 0.037355, loss_ce: 0.015242
2021-12-11 20:50:05,907 iteration 3318 : loss : 0.029865, loss_ce: 0.013795
2021-12-11 20:50:07,395 iteration 3319 : loss : 0.021674, loss_ce: 0.008296
2021-12-11 20:50:09,043 iteration 3320 : loss : 0.033799, loss_ce: 0.011738
2021-12-11 20:50:10,519 iteration 3321 : loss : 0.021783, loss_ce: 0.010256
2021-12-11 20:50:11,965 iteration 3322 : loss : 0.020866, loss_ce: 0.007128
2021-12-11 20:50:13,517 iteration 3323 : loss : 0.029746, loss_ce: 0.012683
2021-12-11 20:50:15,075 iteration 3324 : loss : 0.026169, loss_ce: 0.009330
2021-12-11 20:50:16,692 iteration 3325 : loss : 0.035196, loss_ce: 0.011786
2021-12-11 20:50:18,251 iteration 3326 : loss : 0.027100, loss_ce: 0.008915
2021-12-11 20:50:19,946 iteration 3327 : loss : 0.049102, loss_ce: 0.016899
2021-12-11 20:50:21,454 iteration 3328 : loss : 0.024753, loss_ce: 0.012457
2021-12-11 20:50:22,962 iteration 3329 : loss : 0.027912, loss_ce: 0.009221
2021-12-11 20:50:24,516 iteration 3330 : loss : 0.031635, loss_ce: 0.013430
2021-12-11 20:50:26,008 iteration 3331 : loss : 0.021294, loss_ce: 0.009460
2021-12-11 20:50:27,442 iteration 3332 : loss : 0.024053, loss_ce: 0.008646
 49%|█████████████▏             | 196/400 [1:33:01<1:38:16, 28.90s/it]2021-12-11 20:50:29,005 iteration 3333 : loss : 0.027345, loss_ce: 0.010331
2021-12-11 20:50:30,555 iteration 3334 : loss : 0.023999, loss_ce: 0.010884
2021-12-11 20:50:32,151 iteration 3335 : loss : 0.034445, loss_ce: 0.013749
2021-12-11 20:50:33,642 iteration 3336 : loss : 0.023191, loss_ce: 0.008088
2021-12-11 20:50:35,126 iteration 3337 : loss : 0.024625, loss_ce: 0.008847
2021-12-11 20:50:36,699 iteration 3338 : loss : 0.023960, loss_ce: 0.008822
2021-12-11 20:50:38,282 iteration 3339 : loss : 0.042179, loss_ce: 0.012728
2021-12-11 20:50:39,839 iteration 3340 : loss : 0.031793, loss_ce: 0.013487
2021-12-11 20:50:41,340 iteration 3341 : loss : 0.021781, loss_ce: 0.009260
2021-12-11 20:50:42,869 iteration 3342 : loss : 0.023009, loss_ce: 0.012422
2021-12-11 20:50:44,381 iteration 3343 : loss : 0.022918, loss_ce: 0.009251
2021-12-11 20:50:45,989 iteration 3344 : loss : 0.021377, loss_ce: 0.005957
2021-12-11 20:50:47,587 iteration 3345 : loss : 0.025552, loss_ce: 0.012021
2021-12-11 20:50:49,132 iteration 3346 : loss : 0.031396, loss_ce: 0.009376
2021-12-11 20:50:50,657 iteration 3347 : loss : 0.019763, loss_ce: 0.006928
2021-12-11 20:50:52,272 iteration 3348 : loss : 0.025872, loss_ce: 0.010293
2021-12-11 20:50:53,763 iteration 3349 : loss : 0.032125, loss_ce: 0.007628
 49%|█████████████▎             | 197/400 [1:33:27<1:35:10, 28.13s/it]2021-12-11 20:50:55,302 iteration 3350 : loss : 0.023789, loss_ce: 0.011422
2021-12-11 20:50:56,873 iteration 3351 : loss : 0.026081, loss_ce: 0.008837
2021-12-11 20:50:58,376 iteration 3352 : loss : 0.026404, loss_ce: 0.008200
2021-12-11 20:50:59,916 iteration 3353 : loss : 0.024476, loss_ce: 0.006920
2021-12-11 20:51:01,427 iteration 3354 : loss : 0.020996, loss_ce: 0.005648
2021-12-11 20:51:02,979 iteration 3355 : loss : 0.021417, loss_ce: 0.008120
2021-12-11 20:51:04,461 iteration 3356 : loss : 0.035568, loss_ce: 0.015903
2021-12-11 20:51:05,953 iteration 3357 : loss : 0.021206, loss_ce: 0.008839
2021-12-11 20:51:07,484 iteration 3358 : loss : 0.022679, loss_ce: 0.007114
2021-12-11 20:51:09,003 iteration 3359 : loss : 0.023793, loss_ce: 0.010905
2021-12-11 20:51:10,574 iteration 3360 : loss : 0.018555, loss_ce: 0.005912
2021-12-11 20:51:12,128 iteration 3361 : loss : 0.030562, loss_ce: 0.011723
2021-12-11 20:51:13,635 iteration 3362 : loss : 0.028542, loss_ce: 0.009945
2021-12-11 20:51:15,070 iteration 3363 : loss : 0.031688, loss_ce: 0.009916
2021-12-11 20:51:16,661 iteration 3364 : loss : 0.028466, loss_ce: 0.011415
2021-12-11 20:51:18,178 iteration 3365 : loss : 0.028232, loss_ce: 0.011550
2021-12-11 20:51:19,701 iteration 3366 : loss : 0.020620, loss_ce: 0.008088
 50%|█████████████▎             | 198/400 [1:33:53<1:32:29, 27.47s/it]2021-12-11 20:51:21,393 iteration 3367 : loss : 0.031564, loss_ce: 0.013442
2021-12-11 20:51:22,923 iteration 3368 : loss : 0.024857, loss_ce: 0.011754
2021-12-11 20:51:24,476 iteration 3369 : loss : 0.036850, loss_ce: 0.014544
2021-12-11 20:51:25,954 iteration 3370 : loss : 0.034247, loss_ce: 0.009826
2021-12-11 20:51:27,481 iteration 3371 : loss : 0.021055, loss_ce: 0.007414
2021-12-11 20:51:29,129 iteration 3372 : loss : 0.036079, loss_ce: 0.010540
2021-12-11 20:51:30,680 iteration 3373 : loss : 0.031096, loss_ce: 0.011176
2021-12-11 20:51:32,294 iteration 3374 : loss : 0.021234, loss_ce: 0.008326
2021-12-11 20:51:33,935 iteration 3375 : loss : 0.047412, loss_ce: 0.019763
2021-12-11 20:51:35,389 iteration 3376 : loss : 0.020965, loss_ce: 0.006947
2021-12-11 20:51:36,980 iteration 3377 : loss : 0.026451, loss_ce: 0.010280
2021-12-11 20:51:38,476 iteration 3378 : loss : 0.022909, loss_ce: 0.006646
2021-12-11 20:51:40,045 iteration 3379 : loss : 0.021888, loss_ce: 0.008370
2021-12-11 20:51:41,525 iteration 3380 : loss : 0.022348, loss_ce: 0.007562
2021-12-11 20:51:43,087 iteration 3381 : loss : 0.024377, loss_ce: 0.012043
2021-12-11 20:51:44,656 iteration 3382 : loss : 0.032368, loss_ce: 0.010945
2021-12-11 20:51:46,188 iteration 3383 : loss : 0.028597, loss_ce: 0.011687
 50%|█████████████▍             | 199/400 [1:34:20<1:31:02, 27.18s/it]2021-12-11 20:51:47,767 iteration 3384 : loss : 0.033079, loss_ce: 0.010315
2021-12-11 20:51:49,273 iteration 3385 : loss : 0.032036, loss_ce: 0.011794
2021-12-11 20:51:50,770 iteration 3386 : loss : 0.022437, loss_ce: 0.006849
2021-12-11 20:51:52,251 iteration 3387 : loss : 0.030145, loss_ce: 0.009932
2021-12-11 20:51:53,836 iteration 3388 : loss : 0.032801, loss_ce: 0.011717
2021-12-11 20:51:55,324 iteration 3389 : loss : 0.027137, loss_ce: 0.009703
2021-12-11 20:51:56,864 iteration 3390 : loss : 0.031787, loss_ce: 0.012000
2021-12-11 20:51:58,493 iteration 3391 : loss : 0.022448, loss_ce: 0.010995
2021-12-11 20:52:00,079 iteration 3392 : loss : 0.037079, loss_ce: 0.012863
2021-12-11 20:52:01,558 iteration 3393 : loss : 0.024793, loss_ce: 0.009729
2021-12-11 20:52:03,084 iteration 3394 : loss : 0.026996, loss_ce: 0.008981
2021-12-11 20:52:04,632 iteration 3395 : loss : 0.025503, loss_ce: 0.010645
2021-12-11 20:52:06,172 iteration 3396 : loss : 0.023470, loss_ce: 0.008690
2021-12-11 20:52:07,648 iteration 3397 : loss : 0.022523, loss_ce: 0.008702
2021-12-11 20:52:09,318 iteration 3398 : loss : 0.031652, loss_ce: 0.009457
2021-12-11 20:52:10,871 iteration 3399 : loss : 0.025786, loss_ce: 0.010656
2021-12-11 20:52:10,871 Training Data Eval:
2021-12-11 20:52:18,510   Average segmentation loss on training set: 0.0177
2021-12-11 20:52:18,511 Validation Data Eval:
2021-12-11 20:52:21,144   Average segmentation loss on validation set: 0.0779
2021-12-11 20:52:22,684 iteration 3400 : loss : 0.025571, loss_ce: 0.007146
2021-12-11 20:52:24,660 save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/NEW_TU/UNET_ADAM_seed100epoch_199.pth
 50%|█████████████▌             | 200/400 [1:34:58<1:41:50, 30.55s/it]2021-12-11 20:52:26,155 iteration 3401 : loss : 0.042044, loss_ce: 0.017795
2021-12-11 20:52:27,620 iteration 3402 : loss : 0.022512, loss_ce: 0.008318
2021-12-11 20:52:29,173 iteration 3403 : loss : 0.035460, loss_ce: 0.013628
2021-12-11 20:52:30,623 iteration 3404 : loss : 0.025361, loss_ce: 0.007307
2021-12-11 20:52:32,131 iteration 3405 : loss : 0.025071, loss_ce: 0.006083
2021-12-11 20:52:33,595 iteration 3406 : loss : 0.024734, loss_ce: 0.012066
2021-12-11 20:52:35,097 iteration 3407 : loss : 0.027669, loss_ce: 0.011182
2021-12-11 20:52:36,634 iteration 3408 : loss : 0.025114, loss_ce: 0.012135
2021-12-11 20:52:38,174 iteration 3409 : loss : 0.023976, loss_ce: 0.004837
2021-12-11 20:52:39,694 iteration 3410 : loss : 0.022852, loss_ce: 0.008843
2021-12-11 20:52:41,270 iteration 3411 : loss : 0.037841, loss_ce: 0.010457
2021-12-11 20:52:42,868 iteration 3412 : loss : 0.023881, loss_ce: 0.010265
2021-12-11 20:52:44,507 iteration 3413 : loss : 0.024703, loss_ce: 0.010576
2021-12-11 20:52:46,102 iteration 3414 : loss : 0.035830, loss_ce: 0.011804
2021-12-11 20:52:47,523 iteration 3415 : loss : 0.021044, loss_ce: 0.008911
2021-12-11 20:52:49,084 iteration 3416 : loss : 0.021722, loss_ce: 0.008178
2021-12-11 20:52:50,600 iteration 3417 : loss : 0.020338, loss_ce: 0.008378
 50%|█████████████▌             | 201/400 [1:35:24<1:36:47, 29.18s/it]2021-12-11 20:52:52,274 iteration 3418 : loss : 0.037290, loss_ce: 0.012933
2021-12-11 20:52:53,829 iteration 3419 : loss : 0.027980, loss_ce: 0.014455
2021-12-11 20:52:55,314 iteration 3420 : loss : 0.023659, loss_ce: 0.011804
2021-12-11 20:52:56,859 iteration 3421 : loss : 0.047338, loss_ce: 0.012221
2021-12-11 20:52:58,390 iteration 3422 : loss : 0.031657, loss_ce: 0.011772
2021-12-11 20:52:59,977 iteration 3423 : loss : 0.024032, loss_ce: 0.011735
2021-12-11 20:53:01,451 iteration 3424 : loss : 0.021829, loss_ce: 0.007053
2021-12-11 20:53:03,043 iteration 3425 : loss : 0.024723, loss_ce: 0.011584
2021-12-11 20:53:04,556 iteration 3426 : loss : 0.025446, loss_ce: 0.007952
2021-12-11 20:53:06,214 iteration 3427 : loss : 0.040008, loss_ce: 0.013387
2021-12-11 20:53:07,772 iteration 3428 : loss : 0.024060, loss_ce: 0.010017
2021-12-11 20:53:09,321 iteration 3429 : loss : 0.033306, loss_ce: 0.016823
2021-12-11 20:53:10,867 iteration 3430 : loss : 0.019514, loss_ce: 0.006528
2021-12-11 20:53:12,446 iteration 3431 : loss : 0.025119, loss_ce: 0.008847
2021-12-11 20:53:13,947 iteration 3432 : loss : 0.022269, loss_ce: 0.006667
2021-12-11 20:53:15,498 iteration 3433 : loss : 0.023421, loss_ce: 0.006669
2021-12-11 20:53:17,007 iteration 3434 : loss : 0.024568, loss_ce: 0.007207
 50%|█████████████▋             | 202/400 [1:35:51<1:33:33, 28.35s/it]2021-12-11 20:53:18,520 iteration 3435 : loss : 0.022090, loss_ce: 0.010120
2021-12-11 20:53:20,078 iteration 3436 : loss : 0.029574, loss_ce: 0.011565
2021-12-11 20:53:21,570 iteration 3437 : loss : 0.020027, loss_ce: 0.006413
2021-12-11 20:53:23,090 iteration 3438 : loss : 0.025870, loss_ce: 0.012421
2021-12-11 20:53:24,703 iteration 3439 : loss : 0.024200, loss_ce: 0.009233
2021-12-11 20:53:26,299 iteration 3440 : loss : 0.038197, loss_ce: 0.012666
2021-12-11 20:53:27,728 iteration 3441 : loss : 0.019149, loss_ce: 0.008846
2021-12-11 20:53:29,228 iteration 3442 : loss : 0.019265, loss_ce: 0.006059
2021-12-11 20:53:30,805 iteration 3443 : loss : 0.024143, loss_ce: 0.008087
2021-12-11 20:53:32,316 iteration 3444 : loss : 0.022214, loss_ce: 0.007960
2021-12-11 20:53:33,899 iteration 3445 : loss : 0.019842, loss_ce: 0.006918
2021-12-11 20:53:35,413 iteration 3446 : loss : 0.021972, loss_ce: 0.007183
2021-12-11 20:53:36,970 iteration 3447 : loss : 0.026704, loss_ce: 0.013308
2021-12-11 20:53:38,429 iteration 3448 : loss : 0.023717, loss_ce: 0.007885
2021-12-11 20:53:39,973 iteration 3449 : loss : 0.035764, loss_ce: 0.010410
2021-12-11 20:53:41,565 iteration 3450 : loss : 0.027775, loss_ce: 0.010216
2021-12-11 20:53:43,052 iteration 3451 : loss : 0.017842, loss_ce: 0.007345
 51%|█████████████▋             | 203/400 [1:36:17<1:30:48, 27.66s/it]2021-12-11 20:53:44,615 iteration 3452 : loss : 0.021488, loss_ce: 0.007185
2021-12-11 20:53:46,196 iteration 3453 : loss : 0.026875, loss_ce: 0.008610
2021-12-11 20:53:47,800 iteration 3454 : loss : 0.028635, loss_ce: 0.009874
2021-12-11 20:53:49,422 iteration 3455 : loss : 0.032186, loss_ce: 0.013429
2021-12-11 20:53:50,977 iteration 3456 : loss : 0.029876, loss_ce: 0.011060
2021-12-11 20:53:52,547 iteration 3457 : loss : 0.029234, loss_ce: 0.011971
2021-12-11 20:53:54,118 iteration 3458 : loss : 0.019930, loss_ce: 0.009382
2021-12-11 20:53:55,739 iteration 3459 : loss : 0.027200, loss_ce: 0.012387
2021-12-11 20:53:57,314 iteration 3460 : loss : 0.025937, loss_ce: 0.009424
2021-12-11 20:53:58,853 iteration 3461 : loss : 0.026084, loss_ce: 0.010350
2021-12-11 20:54:00,346 iteration 3462 : loss : 0.029295, loss_ce: 0.012081
2021-12-11 20:54:01,810 iteration 3463 : loss : 0.031937, loss_ce: 0.011821
2021-12-11 20:54:03,335 iteration 3464 : loss : 0.035194, loss_ce: 0.012349
2021-12-11 20:54:04,826 iteration 3465 : loss : 0.024160, loss_ce: 0.008753
2021-12-11 20:54:06,378 iteration 3466 : loss : 0.023047, loss_ce: 0.008761
2021-12-11 20:54:08,076 iteration 3467 : loss : 0.027897, loss_ce: 0.010786
2021-12-11 20:54:09,737 iteration 3468 : loss : 0.046690, loss_ce: 0.014382
 51%|█████████████▊             | 204/400 [1:36:43<1:29:23, 27.37s/it]2021-12-11 20:54:11,239 iteration 3469 : loss : 0.023151, loss_ce: 0.008986
2021-12-11 20:54:12,929 iteration 3470 : loss : 0.031401, loss_ce: 0.010904
2021-12-11 20:54:14,508 iteration 3471 : loss : 0.025277, loss_ce: 0.009639
2021-12-11 20:54:16,102 iteration 3472 : loss : 0.032839, loss_ce: 0.013038
2021-12-11 20:54:17,706 iteration 3473 : loss : 0.033316, loss_ce: 0.020301
2021-12-11 20:54:19,204 iteration 3474 : loss : 0.033914, loss_ce: 0.014277
2021-12-11 20:54:20,869 iteration 3475 : loss : 0.033417, loss_ce: 0.013323
2021-12-11 20:54:22,425 iteration 3476 : loss : 0.046316, loss_ce: 0.017725
2021-12-11 20:54:24,003 iteration 3477 : loss : 0.036191, loss_ce: 0.011848
2021-12-11 20:54:25,554 iteration 3478 : loss : 0.025941, loss_ce: 0.007766
2021-12-11 20:54:27,073 iteration 3479 : loss : 0.026519, loss_ce: 0.011171
2021-12-11 20:54:28,577 iteration 3480 : loss : 0.021292, loss_ce: 0.008349
2021-12-11 20:54:30,120 iteration 3481 : loss : 0.030865, loss_ce: 0.014121
2021-12-11 20:54:31,592 iteration 3482 : loss : 0.026430, loss_ce: 0.008861
2021-12-11 20:54:33,187 iteration 3483 : loss : 0.028751, loss_ce: 0.011869
2021-12-11 20:54:34,729 iteration 3484 : loss : 0.026933, loss_ce: 0.008427
2021-12-11 20:54:34,730 Training Data Eval:
2021-12-11 20:54:42,361   Average segmentation loss on training set: 0.0243
2021-12-11 20:54:42,361 Validation Data Eval:
2021-12-11 20:54:45,001   Average segmentation loss on validation set: 0.0676
2021-12-11 20:54:46,950 Found new lowest validation loss at iteration 3484! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/NEW_TU/UNET_ADAM_best_val_loss_seed100.pth
2021-12-11 20:54:48,403 iteration 3485 : loss : 0.022921, loss_ce: 0.009162
 51%|█████████████▊             | 205/400 [1:37:22<1:39:57, 30.76s/it]2021-12-11 20:54:49,857 iteration 3486 : loss : 0.021033, loss_ce: 0.007190
2021-12-11 20:54:51,329 iteration 3487 : loss : 0.028495, loss_ce: 0.011227
2021-12-11 20:54:52,875 iteration 3488 : loss : 0.023129, loss_ce: 0.013303
2021-12-11 20:54:54,361 iteration 3489 : loss : 0.028046, loss_ce: 0.009939
2021-12-11 20:54:55,978 iteration 3490 : loss : 0.027050, loss_ce: 0.011358
2021-12-11 20:54:57,551 iteration 3491 : loss : 0.031469, loss_ce: 0.014216
2021-12-11 20:54:59,002 iteration 3492 : loss : 0.022211, loss_ce: 0.006577
2021-12-11 20:55:00,625 iteration 3493 : loss : 0.038893, loss_ce: 0.008379
2021-12-11 20:55:02,186 iteration 3494 : loss : 0.030998, loss_ce: 0.017649
2021-12-11 20:55:03,632 iteration 3495 : loss : 0.018939, loss_ce: 0.008064
2021-12-11 20:55:05,203 iteration 3496 : loss : 0.043293, loss_ce: 0.014335
2021-12-11 20:55:06,805 iteration 3497 : loss : 0.038341, loss_ce: 0.015769
2021-12-11 20:55:08,377 iteration 3498 : loss : 0.026592, loss_ce: 0.010080
2021-12-11 20:55:09,968 iteration 3499 : loss : 0.035444, loss_ce: 0.008692
2021-12-11 20:55:11,483 iteration 3500 : loss : 0.026766, loss_ce: 0.007560
2021-12-11 20:55:13,041 iteration 3501 : loss : 0.027172, loss_ce: 0.010055
2021-12-11 20:55:14,589 iteration 3502 : loss : 0.026194, loss_ce: 0.008259
 52%|█████████████▉             | 206/400 [1:37:48<1:35:00, 29.38s/it]2021-12-11 20:55:16,104 iteration 3503 : loss : 0.019418, loss_ce: 0.008651
2021-12-11 20:55:17,653 iteration 3504 : loss : 0.024136, loss_ce: 0.008652
2021-12-11 20:55:19,192 iteration 3505 : loss : 0.025853, loss_ce: 0.012191
2021-12-11 20:55:20,815 iteration 3506 : loss : 0.031133, loss_ce: 0.010883
2021-12-11 20:55:22,319 iteration 3507 : loss : 0.025285, loss_ce: 0.011706
2021-12-11 20:55:23,768 iteration 3508 : loss : 0.018271, loss_ce: 0.005682
2021-12-11 20:55:25,320 iteration 3509 : loss : 0.032124, loss_ce: 0.012225
2021-12-11 20:55:26,956 iteration 3510 : loss : 0.023498, loss_ce: 0.008868
2021-12-11 20:55:28,478 iteration 3511 : loss : 0.022812, loss_ce: 0.008982
2021-12-11 20:55:30,030 iteration 3512 : loss : 0.026870, loss_ce: 0.009172
2021-12-11 20:55:31,493 iteration 3513 : loss : 0.033568, loss_ce: 0.012318
2021-12-11 20:55:32,945 iteration 3514 : loss : 0.015877, loss_ce: 0.006730
2021-12-11 20:55:34,460 iteration 3515 : loss : 0.019579, loss_ce: 0.006922
2021-12-11 20:55:36,030 iteration 3516 : loss : 0.027369, loss_ce: 0.009831
2021-12-11 20:55:37,576 iteration 3517 : loss : 0.028341, loss_ce: 0.012635
2021-12-11 20:55:39,056 iteration 3518 : loss : 0.018203, loss_ce: 0.008253
2021-12-11 20:55:40,540 iteration 3519 : loss : 0.026007, loss_ce: 0.009404
 52%|█████████████▉             | 207/400 [1:38:14<1:31:12, 28.36s/it]2021-12-11 20:55:42,130 iteration 3520 : loss : 0.023686, loss_ce: 0.009028
2021-12-11 20:55:43,699 iteration 3521 : loss : 0.027467, loss_ce: 0.011090
2021-12-11 20:55:45,277 iteration 3522 : loss : 0.045201, loss_ce: 0.016204
2021-12-11 20:55:46,930 iteration 3523 : loss : 0.035770, loss_ce: 0.016930
2021-12-11 20:55:48,461 iteration 3524 : loss : 0.022872, loss_ce: 0.006651
2021-12-11 20:55:50,031 iteration 3525 : loss : 0.032610, loss_ce: 0.013047
2021-12-11 20:55:51,596 iteration 3526 : loss : 0.029731, loss_ce: 0.013254
2021-12-11 20:55:53,168 iteration 3527 : loss : 0.024036, loss_ce: 0.007417
2021-12-11 20:55:54,696 iteration 3528 : loss : 0.019762, loss_ce: 0.008971
2021-12-11 20:55:56,252 iteration 3529 : loss : 0.025188, loss_ce: 0.007983
2021-12-11 20:55:57,785 iteration 3530 : loss : 0.033454, loss_ce: 0.010913
2021-12-11 20:55:59,354 iteration 3531 : loss : 0.025990, loss_ce: 0.009113
2021-12-11 20:56:00,861 iteration 3532 : loss : 0.018915, loss_ce: 0.006582
2021-12-11 20:56:02,351 iteration 3533 : loss : 0.031072, loss_ce: 0.011400
2021-12-11 20:56:03,848 iteration 3534 : loss : 0.024048, loss_ce: 0.012680
2021-12-11 20:56:05,321 iteration 3535 : loss : 0.023509, loss_ce: 0.008750
2021-12-11 20:56:06,801 iteration 3536 : loss : 0.021794, loss_ce: 0.006389
 52%|██████████████             | 208/400 [1:38:40<1:28:43, 27.73s/it]2021-12-11 20:56:08,348 iteration 3537 : loss : 0.026796, loss_ce: 0.009182
2021-12-11 20:56:09,883 iteration 3538 : loss : 0.028682, loss_ce: 0.008478
2021-12-11 20:56:11,448 iteration 3539 : loss : 0.028100, loss_ce: 0.012567
2021-12-11 20:56:12,967 iteration 3540 : loss : 0.024022, loss_ce: 0.006149
2021-12-11 20:56:14,577 iteration 3541 : loss : 0.023993, loss_ce: 0.010968
2021-12-11 20:56:16,099 iteration 3542 : loss : 0.022311, loss_ce: 0.006159
2021-12-11 20:56:17,655 iteration 3543 : loss : 0.026203, loss_ce: 0.011955
2021-12-11 20:56:19,239 iteration 3544 : loss : 0.030593, loss_ce: 0.011843
2021-12-11 20:56:20,749 iteration 3545 : loss : 0.023718, loss_ce: 0.008064
2021-12-11 20:56:22,201 iteration 3546 : loss : 0.021956, loss_ce: 0.009751
2021-12-11 20:56:23,781 iteration 3547 : loss : 0.023539, loss_ce: 0.008808
2021-12-11 20:56:25,364 iteration 3548 : loss : 0.021510, loss_ce: 0.007224
2021-12-11 20:56:26,920 iteration 3549 : loss : 0.029387, loss_ce: 0.014701
2021-12-11 20:56:28,410 iteration 3550 : loss : 0.023883, loss_ce: 0.008406
2021-12-11 20:56:30,012 iteration 3551 : loss : 0.030475, loss_ce: 0.007743
2021-12-11 20:56:31,619 iteration 3552 : loss : 0.030077, loss_ce: 0.012026
2021-12-11 20:56:33,223 iteration 3553 : loss : 0.035206, loss_ce: 0.011256
 52%|██████████████             | 209/400 [1:39:07<1:27:00, 27.33s/it]2021-12-11 20:56:34,788 iteration 3554 : loss : 0.023334, loss_ce: 0.010776
2021-12-11 20:56:36,380 iteration 3555 : loss : 0.027106, loss_ce: 0.011466
2021-12-11 20:56:37,908 iteration 3556 : loss : 0.035014, loss_ce: 0.010882
2021-12-11 20:56:39,423 iteration 3557 : loss : 0.028397, loss_ce: 0.011939
2021-12-11 20:56:40,899 iteration 3558 : loss : 0.020575, loss_ce: 0.007080
2021-12-11 20:56:42,531 iteration 3559 : loss : 0.027967, loss_ce: 0.010121
2021-12-11 20:56:44,055 iteration 3560 : loss : 0.024867, loss_ce: 0.006945
2021-12-11 20:56:45,632 iteration 3561 : loss : 0.025662, loss_ce: 0.010466
2021-12-11 20:56:47,177 iteration 3562 : loss : 0.025759, loss_ce: 0.009127
2021-12-11 20:56:48,711 iteration 3563 : loss : 0.021919, loss_ce: 0.008127
2021-12-11 20:56:50,285 iteration 3564 : loss : 0.024660, loss_ce: 0.008136
2021-12-11 20:56:51,773 iteration 3565 : loss : 0.021683, loss_ce: 0.008727
2021-12-11 20:56:53,202 iteration 3566 : loss : 0.018754, loss_ce: 0.007041
2021-12-11 20:56:54,667 iteration 3567 : loss : 0.023866, loss_ce: 0.007106
2021-12-11 20:56:56,247 iteration 3568 : loss : 0.026880, loss_ce: 0.009699
2021-12-11 20:56:57,727 iteration 3569 : loss : 0.024648, loss_ce: 0.010428
2021-12-11 20:56:57,728 Training Data Eval:
2021-12-11 20:57:05,376   Average segmentation loss on training set: 0.0159
2021-12-11 20:57:05,376 Validation Data Eval:
2021-12-11 20:57:08,012   Average segmentation loss on validation set: 0.0797
2021-12-11 20:57:09,517 iteration 3570 : loss : 0.022071, loss_ce: 0.007302
 52%|██████████████▏            | 210/400 [1:39:43<1:35:04, 30.02s/it]2021-12-11 20:57:11,116 iteration 3571 : loss : 0.029265, loss_ce: 0.012630
2021-12-11 20:57:12,738 iteration 3572 : loss : 0.023829, loss_ce: 0.008943
2021-12-11 20:57:14,307 iteration 3573 : loss : 0.027952, loss_ce: 0.010090
2021-12-11 20:57:15,849 iteration 3574 : loss : 0.019223, loss_ce: 0.008160
2021-12-11 20:57:17,348 iteration 3575 : loss : 0.024914, loss_ce: 0.010652
2021-12-11 20:57:18,849 iteration 3576 : loss : 0.035105, loss_ce: 0.012593
2021-12-11 20:57:20,433 iteration 3577 : loss : 0.024309, loss_ce: 0.010712
2021-12-11 20:57:21,947 iteration 3578 : loss : 0.029543, loss_ce: 0.010888
2021-12-11 20:57:23,501 iteration 3579 : loss : 0.017643, loss_ce: 0.006049
2021-12-11 20:57:25,093 iteration 3580 : loss : 0.024153, loss_ce: 0.009892
2021-12-11 20:57:26,677 iteration 3581 : loss : 0.021092, loss_ce: 0.007661
2021-12-11 20:57:28,237 iteration 3582 : loss : 0.029171, loss_ce: 0.009561
2021-12-11 20:57:29,764 iteration 3583 : loss : 0.039587, loss_ce: 0.010549
2021-12-11 20:57:31,226 iteration 3584 : loss : 0.023295, loss_ce: 0.007821
2021-12-11 20:57:32,732 iteration 3585 : loss : 0.017425, loss_ce: 0.006496
2021-12-11 20:57:34,205 iteration 3586 : loss : 0.019045, loss_ce: 0.005842
2021-12-11 20:57:35,743 iteration 3587 : loss : 0.018537, loss_ce: 0.008123
 53%|██████████████▏            | 211/400 [1:40:09<1:30:58, 28.88s/it]2021-12-11 20:57:37,374 iteration 3588 : loss : 0.020699, loss_ce: 0.007692
2021-12-11 20:57:38,986 iteration 3589 : loss : 0.040860, loss_ce: 0.010964
2021-12-11 20:57:40,524 iteration 3590 : loss : 0.047228, loss_ce: 0.012829
2021-12-11 20:57:42,011 iteration 3591 : loss : 0.025385, loss_ce: 0.008334
2021-12-11 20:57:43,547 iteration 3592 : loss : 0.023107, loss_ce: 0.009271
2021-12-11 20:57:45,165 iteration 3593 : loss : 0.022399, loss_ce: 0.010862
2021-12-11 20:57:46,692 iteration 3594 : loss : 0.024860, loss_ce: 0.007407
2021-12-11 20:57:48,215 iteration 3595 : loss : 0.031861, loss_ce: 0.012636
2021-12-11 20:57:49,722 iteration 3596 : loss : 0.024204, loss_ce: 0.010314
2021-12-11 20:57:51,266 iteration 3597 : loss : 0.022240, loss_ce: 0.008746
2021-12-11 20:57:52,829 iteration 3598 : loss : 0.022836, loss_ce: 0.009867
2021-12-11 20:57:54,408 iteration 3599 : loss : 0.032206, loss_ce: 0.010238
2021-12-11 20:57:55,892 iteration 3600 : loss : 0.025792, loss_ce: 0.013580
2021-12-11 20:57:57,469 iteration 3601 : loss : 0.026489, loss_ce: 0.010213
2021-12-11 20:57:59,042 iteration 3602 : loss : 0.035376, loss_ce: 0.014195
2021-12-11 20:58:00,550 iteration 3603 : loss : 0.029025, loss_ce: 0.014653
2021-12-11 20:58:02,083 iteration 3604 : loss : 0.031414, loss_ce: 0.008699
 53%|██████████████▎            | 212/400 [1:40:36<1:28:06, 28.12s/it]2021-12-11 20:58:03,774 iteration 3605 : loss : 0.039786, loss_ce: 0.015329
2021-12-11 20:58:05,254 iteration 3606 : loss : 0.050423, loss_ce: 0.011266
2021-12-11 20:58:06,699 iteration 3607 : loss : 0.013493, loss_ce: 0.005073
2021-12-11 20:58:08,285 iteration 3608 : loss : 0.030735, loss_ce: 0.010427
2021-12-11 20:58:09,865 iteration 3609 : loss : 0.035465, loss_ce: 0.012234
2021-12-11 20:58:11,347 iteration 3610 : loss : 0.018290, loss_ce: 0.006675
2021-12-11 20:58:12,882 iteration 3611 : loss : 0.030677, loss_ce: 0.012695
2021-12-11 20:58:14,370 iteration 3612 : loss : 0.022639, loss_ce: 0.009181
2021-12-11 20:58:15,915 iteration 3613 : loss : 0.021040, loss_ce: 0.007543
2021-12-11 20:58:17,408 iteration 3614 : loss : 0.024404, loss_ce: 0.009335
2021-12-11 20:58:18,931 iteration 3615 : loss : 0.025745, loss_ce: 0.008798
2021-12-11 20:58:20,448 iteration 3616 : loss : 0.026804, loss_ce: 0.011902
2021-12-11 20:58:22,011 iteration 3617 : loss : 0.023543, loss_ce: 0.010590
2021-12-11 20:58:23,573 iteration 3618 : loss : 0.025384, loss_ce: 0.009076
2021-12-11 20:58:25,093 iteration 3619 : loss : 0.021682, loss_ce: 0.007441
2021-12-11 20:58:26,635 iteration 3620 : loss : 0.021999, loss_ce: 0.006580
2021-12-11 20:58:28,156 iteration 3621 : loss : 0.023716, loss_ce: 0.010851
 53%|██████████████▍            | 213/400 [1:41:02<1:25:43, 27.51s/it]2021-12-11 20:58:29,752 iteration 3622 : loss : 0.021999, loss_ce: 0.006727
2021-12-11 20:58:31,342 iteration 3623 : loss : 0.024087, loss_ce: 0.008775
2021-12-11 20:58:32,933 iteration 3624 : loss : 0.025393, loss_ce: 0.010194
2021-12-11 20:58:34,385 iteration 3625 : loss : 0.021489, loss_ce: 0.007997
2021-12-11 20:58:35,942 iteration 3626 : loss : 0.038550, loss_ce: 0.011534
2021-12-11 20:58:37,514 iteration 3627 : loss : 0.027688, loss_ce: 0.010707
2021-12-11 20:58:39,086 iteration 3628 : loss : 0.036584, loss_ce: 0.011125
2021-12-11 20:58:40,710 iteration 3629 : loss : 0.026157, loss_ce: 0.011013
2021-12-11 20:58:42,262 iteration 3630 : loss : 0.021924, loss_ce: 0.009636
2021-12-11 20:58:43,809 iteration 3631 : loss : 0.020722, loss_ce: 0.007229
2021-12-11 20:58:45,386 iteration 3632 : loss : 0.024147, loss_ce: 0.012341
2021-12-11 20:58:46,969 iteration 3633 : loss : 0.022455, loss_ce: 0.007574
2021-12-11 20:58:48,468 iteration 3634 : loss : 0.021995, loss_ce: 0.005933
2021-12-11 20:58:50,118 iteration 3635 : loss : 0.025120, loss_ce: 0.012053
2021-12-11 20:58:51,569 iteration 3636 : loss : 0.019819, loss_ce: 0.008418
2021-12-11 20:58:53,096 iteration 3637 : loss : 0.020691, loss_ce: 0.007692
2021-12-11 20:58:54,648 iteration 3638 : loss : 0.022091, loss_ce: 0.007045
 54%|██████████████▍            | 214/400 [1:41:28<1:24:19, 27.20s/it]2021-12-11 20:58:56,238 iteration 3639 : loss : 0.036873, loss_ce: 0.013048
2021-12-11 20:58:57,814 iteration 3640 : loss : 0.025095, loss_ce: 0.007271
2021-12-11 20:58:59,383 iteration 3641 : loss : 0.021431, loss_ce: 0.007412
2021-12-11 20:59:00,894 iteration 3642 : loss : 0.023349, loss_ce: 0.010250
2021-12-11 20:59:02,501 iteration 3643 : loss : 0.025758, loss_ce: 0.007342
2021-12-11 20:59:04,073 iteration 3644 : loss : 0.023689, loss_ce: 0.008831
2021-12-11 20:59:05,688 iteration 3645 : loss : 0.043092, loss_ce: 0.011542
2021-12-11 20:59:07,250 iteration 3646 : loss : 0.038858, loss_ce: 0.017078
2021-12-11 20:59:08,768 iteration 3647 : loss : 0.023006, loss_ce: 0.009747
2021-12-11 20:59:10,332 iteration 3648 : loss : 0.025602, loss_ce: 0.009725
2021-12-11 20:59:11,770 iteration 3649 : loss : 0.022553, loss_ce: 0.008109
2021-12-11 20:59:13,318 iteration 3650 : loss : 0.027676, loss_ce: 0.010832
2021-12-11 20:59:14,819 iteration 3651 : loss : 0.033989, loss_ce: 0.015958
2021-12-11 20:59:16,296 iteration 3652 : loss : 0.024386, loss_ce: 0.009622
2021-12-11 20:59:17,886 iteration 3653 : loss : 0.027061, loss_ce: 0.011565
2021-12-11 20:59:19,403 iteration 3654 : loss : 0.020148, loss_ce: 0.007517
2021-12-11 20:59:19,403 Training Data Eval:
2021-12-11 20:59:27,052   Average segmentation loss on training set: 0.0172
2021-12-11 20:59:27,053 Validation Data Eval:
2021-12-11 20:59:29,693   Average segmentation loss on validation set: 0.0903
2021-12-11 20:59:31,383 iteration 3655 : loss : 0.038682, loss_ce: 0.013601
 54%|██████████████▌            | 215/400 [1:42:05<1:32:40, 30.06s/it]2021-12-11 20:59:32,961 iteration 3656 : loss : 0.026804, loss_ce: 0.008585
2021-12-11 20:59:34,550 iteration 3657 : loss : 0.020036, loss_ce: 0.008460
2021-12-11 20:59:36,087 iteration 3658 : loss : 0.020468, loss_ce: 0.008665
2021-12-11 20:59:37,566 iteration 3659 : loss : 0.045786, loss_ce: 0.014935
2021-12-11 20:59:39,184 iteration 3660 : loss : 0.032230, loss_ce: 0.011588
2021-12-11 20:59:40,726 iteration 3661 : loss : 0.026044, loss_ce: 0.010882
2021-12-11 20:59:42,206 iteration 3662 : loss : 0.024203, loss_ce: 0.010626
2021-12-11 20:59:43,736 iteration 3663 : loss : 0.022949, loss_ce: 0.008551
2021-12-11 20:59:45,300 iteration 3664 : loss : 0.030923, loss_ce: 0.012265
2021-12-11 20:59:46,948 iteration 3665 : loss : 0.029156, loss_ce: 0.008536
2021-12-11 20:59:48,537 iteration 3666 : loss : 0.029494, loss_ce: 0.014937
2021-12-11 20:59:50,084 iteration 3667 : loss : 0.029716, loss_ce: 0.011306
2021-12-11 20:59:51,600 iteration 3668 : loss : 0.027347, loss_ce: 0.010633
2021-12-11 20:59:53,168 iteration 3669 : loss : 0.031101, loss_ce: 0.009552
2021-12-11 20:59:54,643 iteration 3670 : loss : 0.026578, loss_ce: 0.013393
2021-12-11 20:59:56,165 iteration 3671 : loss : 0.039504, loss_ce: 0.011859
2021-12-11 20:59:57,688 iteration 3672 : loss : 0.029508, loss_ce: 0.009453
 54%|██████████████▌            | 216/400 [1:42:31<1:28:44, 28.94s/it]2021-12-11 20:59:59,242 iteration 3673 : loss : 0.022344, loss_ce: 0.009802
2021-12-11 21:00:00,862 iteration 3674 : loss : 0.024317, loss_ce: 0.011235
2021-12-11 21:00:02,474 iteration 3675 : loss : 0.033556, loss_ce: 0.013715
2021-12-11 21:00:04,080 iteration 3676 : loss : 0.030415, loss_ce: 0.009309
2021-12-11 21:00:05,638 iteration 3677 : loss : 0.024605, loss_ce: 0.010905
2021-12-11 21:00:07,289 iteration 3678 : loss : 0.027447, loss_ce: 0.008628
2021-12-11 21:00:08,752 iteration 3679 : loss : 0.021270, loss_ce: 0.007608
2021-12-11 21:00:10,233 iteration 3680 : loss : 0.019675, loss_ce: 0.007568
2021-12-11 21:00:11,769 iteration 3681 : loss : 0.024652, loss_ce: 0.007218
2021-12-11 21:00:13,228 iteration 3682 : loss : 0.018459, loss_ce: 0.005698
2021-12-11 21:00:14,750 iteration 3683 : loss : 0.035800, loss_ce: 0.017171
2021-12-11 21:00:16,224 iteration 3684 : loss : 0.025694, loss_ce: 0.009708
2021-12-11 21:00:17,744 iteration 3685 : loss : 0.018666, loss_ce: 0.007050
2021-12-11 21:00:19,345 iteration 3686 : loss : 0.021884, loss_ce: 0.008509
2021-12-11 21:00:20,957 iteration 3687 : loss : 0.034040, loss_ce: 0.012981
2021-12-11 21:00:22,518 iteration 3688 : loss : 0.027750, loss_ce: 0.010490
2021-12-11 21:00:24,099 iteration 3689 : loss : 0.027305, loss_ce: 0.008226
 54%|██████████████▋            | 217/400 [1:42:58<1:25:56, 28.18s/it]2021-12-11 21:00:25,790 iteration 3690 : loss : 0.023745, loss_ce: 0.011190
2021-12-11 21:00:27,299 iteration 3691 : loss : 0.036629, loss_ce: 0.008487
2021-12-11 21:00:28,874 iteration 3692 : loss : 0.030020, loss_ce: 0.009129
2021-12-11 21:00:30,366 iteration 3693 : loss : 0.017243, loss_ce: 0.004698
2021-12-11 21:00:31,935 iteration 3694 : loss : 0.028628, loss_ce: 0.008352
2021-12-11 21:00:33,524 iteration 3695 : loss : 0.023872, loss_ce: 0.008141
2021-12-11 21:00:35,008 iteration 3696 : loss : 0.020098, loss_ce: 0.008018
2021-12-11 21:00:36,546 iteration 3697 : loss : 0.026421, loss_ce: 0.008840
2021-12-11 21:00:38,192 iteration 3698 : loss : 0.030516, loss_ce: 0.008948
2021-12-11 21:00:39,727 iteration 3699 : loss : 0.026959, loss_ce: 0.014279
2021-12-11 21:00:41,263 iteration 3700 : loss : 0.019982, loss_ce: 0.005953
2021-12-11 21:00:42,726 iteration 3701 : loss : 0.027491, loss_ce: 0.013002
2021-12-11 21:00:44,293 iteration 3702 : loss : 0.030293, loss_ce: 0.011795
2021-12-11 21:00:45,838 iteration 3703 : loss : 0.021917, loss_ce: 0.007804
2021-12-11 21:00:47,368 iteration 3704 : loss : 0.029455, loss_ce: 0.009966
2021-12-11 21:00:48,924 iteration 3705 : loss : 0.029898, loss_ce: 0.013316
2021-12-11 21:00:50,405 iteration 3706 : loss : 0.027983, loss_ce: 0.008474
 55%|██████████████▋            | 218/400 [1:43:24<1:23:46, 27.62s/it]2021-12-11 21:00:52,001 iteration 3707 : loss : 0.058266, loss_ce: 0.011652
2021-12-11 21:00:53,633 iteration 3708 : loss : 0.056403, loss_ce: 0.020107
2021-12-11 21:00:55,194 iteration 3709 : loss : 0.026693, loss_ce: 0.009104
2021-12-11 21:00:56,648 iteration 3710 : loss : 0.021171, loss_ce: 0.007894
2021-12-11 21:00:58,295 iteration 3711 : loss : 0.031182, loss_ce: 0.012304
2021-12-11 21:00:59,791 iteration 3712 : loss : 0.031091, loss_ce: 0.009429
2021-12-11 21:01:01,263 iteration 3713 : loss : 0.019334, loss_ce: 0.007296
2021-12-11 21:01:02,834 iteration 3714 : loss : 0.030001, loss_ce: 0.011763
2021-12-11 21:01:04,334 iteration 3715 : loss : 0.022726, loss_ce: 0.008159
2021-12-11 21:01:05,881 iteration 3716 : loss : 0.028040, loss_ce: 0.010954
2021-12-11 21:01:07,436 iteration 3717 : loss : 0.022742, loss_ce: 0.010478
2021-12-11 21:01:09,013 iteration 3718 : loss : 0.026284, loss_ce: 0.009264
2021-12-11 21:01:10,659 iteration 3719 : loss : 0.034958, loss_ce: 0.011928
2021-12-11 21:01:12,280 iteration 3720 : loss : 0.026197, loss_ce: 0.010033
2021-12-11 21:01:13,831 iteration 3721 : loss : 0.026878, loss_ce: 0.010903
2021-12-11 21:01:15,441 iteration 3722 : loss : 0.044741, loss_ce: 0.011725
2021-12-11 21:01:16,965 iteration 3723 : loss : 0.024329, loss_ce: 0.010047
 55%|██████████████▊            | 219/400 [1:43:51<1:22:20, 27.30s/it]2021-12-11 21:01:18,540 iteration 3724 : loss : 0.023947, loss_ce: 0.011338
2021-12-11 21:01:20,128 iteration 3725 : loss : 0.031631, loss_ce: 0.012316
2021-12-11 21:01:21,662 iteration 3726 : loss : 0.020320, loss_ce: 0.008430
2021-12-11 21:01:23,205 iteration 3727 : loss : 0.023883, loss_ce: 0.008819
2021-12-11 21:01:24,640 iteration 3728 : loss : 0.022419, loss_ce: 0.010251
2021-12-11 21:01:26,261 iteration 3729 : loss : 0.024574, loss_ce: 0.007473
2021-12-11 21:01:27,771 iteration 3730 : loss : 0.020265, loss_ce: 0.007801
2021-12-11 21:01:29,355 iteration 3731 : loss : 0.022419, loss_ce: 0.008833
2021-12-11 21:01:30,901 iteration 3732 : loss : 0.028720, loss_ce: 0.012471
2021-12-11 21:01:32,370 iteration 3733 : loss : 0.017980, loss_ce: 0.005074
2021-12-11 21:01:33,950 iteration 3734 : loss : 0.030610, loss_ce: 0.010603
2021-12-11 21:01:35,559 iteration 3735 : loss : 0.027282, loss_ce: 0.009433
2021-12-11 21:01:37,120 iteration 3736 : loss : 0.046616, loss_ce: 0.018139
2021-12-11 21:01:38,724 iteration 3737 : loss : 0.032271, loss_ce: 0.013354
2021-12-11 21:01:40,267 iteration 3738 : loss : 0.031652, loss_ce: 0.010848
2021-12-11 21:01:41,800 iteration 3739 : loss : 0.030798, loss_ce: 0.009276
2021-12-11 21:01:41,800 Training Data Eval:
2021-12-11 21:01:49,423   Average segmentation loss on training set: 0.0197
2021-12-11 21:01:49,423 Validation Data Eval:
2021-12-11 21:01:52,054   Average segmentation loss on validation set: 0.0991
2021-12-11 21:01:53,546 iteration 3740 : loss : 0.036813, loss_ce: 0.013001
 55%|██████████████▊            | 220/400 [1:44:27<1:30:15, 30.09s/it]2021-12-11 21:01:55,139 iteration 3741 : loss : 0.029897, loss_ce: 0.014237
2021-12-11 21:01:56,664 iteration 3742 : loss : 0.020468, loss_ce: 0.007146
2021-12-11 21:01:58,181 iteration 3743 : loss : 0.025939, loss_ce: 0.007547
2021-12-11 21:01:59,751 iteration 3744 : loss : 0.018351, loss_ce: 0.006780
2021-12-11 21:02:01,380 iteration 3745 : loss : 0.032111, loss_ce: 0.017770
2021-12-11 21:02:02,898 iteration 3746 : loss : 0.028352, loss_ce: 0.007238
2021-12-11 21:02:04,490 iteration 3747 : loss : 0.034541, loss_ce: 0.014905
2021-12-11 21:02:06,092 iteration 3748 : loss : 0.027915, loss_ce: 0.009731
2021-12-11 21:02:07,639 iteration 3749 : loss : 0.027572, loss_ce: 0.007332
2021-12-11 21:02:09,283 iteration 3750 : loss : 0.031666, loss_ce: 0.011171
2021-12-11 21:02:10,819 iteration 3751 : loss : 0.036656, loss_ce: 0.015454
2021-12-11 21:02:12,361 iteration 3752 : loss : 0.025649, loss_ce: 0.010974
2021-12-11 21:02:13,895 iteration 3753 : loss : 0.024319, loss_ce: 0.007541
2021-12-11 21:02:15,364 iteration 3754 : loss : 0.024833, loss_ce: 0.011992
2021-12-11 21:02:16,909 iteration 3755 : loss : 0.029844, loss_ce: 0.011902
2021-12-11 21:02:18,418 iteration 3756 : loss : 0.021600, loss_ce: 0.007145
2021-12-11 21:02:19,954 iteration 3757 : loss : 0.029847, loss_ce: 0.011462
 55%|██████████████▉            | 221/400 [1:44:54<1:26:28, 28.98s/it]2021-12-11 21:02:21,572 iteration 3758 : loss : 0.029602, loss_ce: 0.010598
2021-12-11 21:02:23,159 iteration 3759 : loss : 0.038841, loss_ce: 0.014892
2021-12-11 21:02:24,744 iteration 3760 : loss : 0.030756, loss_ce: 0.012113
2021-12-11 21:02:26,288 iteration 3761 : loss : 0.025851, loss_ce: 0.012201
2021-12-11 21:02:27,873 iteration 3762 : loss : 0.033149, loss_ce: 0.014077
2021-12-11 21:02:29,475 iteration 3763 : loss : 0.039969, loss_ce: 0.023916
2021-12-11 21:02:30,972 iteration 3764 : loss : 0.026035, loss_ce: 0.006017
2021-12-11 21:02:32,428 iteration 3765 : loss : 0.028254, loss_ce: 0.010246
2021-12-11 21:02:33,921 iteration 3766 : loss : 0.017892, loss_ce: 0.005650
2021-12-11 21:02:35,456 iteration 3767 : loss : 0.028818, loss_ce: 0.010296
2021-12-11 21:02:37,066 iteration 3768 : loss : 0.026086, loss_ce: 0.010293
2021-12-11 21:02:38,609 iteration 3769 : loss : 0.027699, loss_ce: 0.009223
2021-12-11 21:02:40,208 iteration 3770 : loss : 0.025331, loss_ce: 0.009138
2021-12-11 21:02:41,837 iteration 3771 : loss : 0.025199, loss_ce: 0.010614
2021-12-11 21:02:43,422 iteration 3772 : loss : 0.033190, loss_ce: 0.008409
2021-12-11 21:02:44,974 iteration 3773 : loss : 0.025012, loss_ce: 0.007782
2021-12-11 21:02:46,537 iteration 3774 : loss : 0.029762, loss_ce: 0.013213
 56%|██████████████▉            | 222/400 [1:45:20<1:23:51, 28.26s/it]2021-12-11 21:02:48,167 iteration 3775 : loss : 0.027859, loss_ce: 0.010759
2021-12-11 21:02:49,722 iteration 3776 : loss : 0.018615, loss_ce: 0.007024
2021-12-11 21:02:51,257 iteration 3777 : loss : 0.029439, loss_ce: 0.008119
2021-12-11 21:02:52,849 iteration 3778 : loss : 0.037654, loss_ce: 0.013946
2021-12-11 21:02:54,331 iteration 3779 : loss : 0.025135, loss_ce: 0.009493
2021-12-11 21:02:55,935 iteration 3780 : loss : 0.035399, loss_ce: 0.016380
2021-12-11 21:02:57,521 iteration 3781 : loss : 0.025834, loss_ce: 0.008915
2021-12-11 21:02:59,121 iteration 3782 : loss : 0.034691, loss_ce: 0.014059
2021-12-11 21:03:00,736 iteration 3783 : loss : 0.028668, loss_ce: 0.013008
2021-12-11 21:03:02,232 iteration 3784 : loss : 0.025694, loss_ce: 0.006968
2021-12-11 21:03:03,769 iteration 3785 : loss : 0.036725, loss_ce: 0.010556
2021-12-11 21:03:05,301 iteration 3786 : loss : 0.028621, loss_ce: 0.012485
2021-12-11 21:03:06,778 iteration 3787 : loss : 0.035318, loss_ce: 0.013571
2021-12-11 21:03:08,323 iteration 3788 : loss : 0.037999, loss_ce: 0.014190
2021-12-11 21:03:09,850 iteration 3789 : loss : 0.028317, loss_ce: 0.012371
2021-12-11 21:03:11,353 iteration 3790 : loss : 0.024703, loss_ce: 0.009758
2021-12-11 21:03:12,953 iteration 3791 : loss : 0.020158, loss_ce: 0.008549
 56%|███████████████            | 223/400 [1:45:47<1:21:44, 27.71s/it]2021-12-11 21:03:14,484 iteration 3792 : loss : 0.027132, loss_ce: 0.009201
2021-12-11 21:03:15,949 iteration 3793 : loss : 0.020519, loss_ce: 0.005052
2021-12-11 21:03:17,455 iteration 3794 : loss : 0.023108, loss_ce: 0.009623
2021-12-11 21:03:18,965 iteration 3795 : loss : 0.024362, loss_ce: 0.007241
2021-12-11 21:03:20,567 iteration 3796 : loss : 0.022107, loss_ce: 0.007037
2021-12-11 21:03:22,135 iteration 3797 : loss : 0.020840, loss_ce: 0.006469
2021-12-11 21:03:23,628 iteration 3798 : loss : 0.021056, loss_ce: 0.007538
2021-12-11 21:03:25,245 iteration 3799 : loss : 0.034865, loss_ce: 0.013152
2021-12-11 21:03:26,925 iteration 3800 : loss : 0.042990, loss_ce: 0.021161
2021-12-11 21:03:28,536 iteration 3801 : loss : 0.035035, loss_ce: 0.012722
2021-12-11 21:03:30,186 iteration 3802 : loss : 0.034647, loss_ce: 0.013876
2021-12-11 21:03:31,709 iteration 3803 : loss : 0.027177, loss_ce: 0.012637
2021-12-11 21:03:33,233 iteration 3804 : loss : 0.024411, loss_ce: 0.008289
2021-12-11 21:03:34,773 iteration 3805 : loss : 0.028651, loss_ce: 0.010827
2021-12-11 21:03:36,227 iteration 3806 : loss : 0.025934, loss_ce: 0.011366
2021-12-11 21:03:37,779 iteration 3807 : loss : 0.030348, loss_ce: 0.010510
2021-12-11 21:03:39,296 iteration 3808 : loss : 0.028902, loss_ce: 0.012842
 56%|███████████████            | 224/400 [1:46:13<1:20:04, 27.30s/it]2021-12-11 21:03:40,885 iteration 3809 : loss : 0.029050, loss_ce: 0.012283
2021-12-11 21:03:42,457 iteration 3810 : loss : 0.033623, loss_ce: 0.010844
2021-12-11 21:03:43,966 iteration 3811 : loss : 0.020126, loss_ce: 0.007438
2021-12-11 21:03:45,511 iteration 3812 : loss : 0.023232, loss_ce: 0.006805
2021-12-11 21:03:47,004 iteration 3813 : loss : 0.021918, loss_ce: 0.009499
2021-12-11 21:03:48,594 iteration 3814 : loss : 0.026437, loss_ce: 0.012473
2021-12-11 21:03:50,224 iteration 3815 : loss : 0.028419, loss_ce: 0.010042
2021-12-11 21:03:51,719 iteration 3816 : loss : 0.019138, loss_ce: 0.006421
2021-12-11 21:03:53,147 iteration 3817 : loss : 0.019192, loss_ce: 0.006454
2021-12-11 21:03:54,660 iteration 3818 : loss : 0.022850, loss_ce: 0.006701
2021-12-11 21:03:56,239 iteration 3819 : loss : 0.028352, loss_ce: 0.010640
2021-12-11 21:03:57,707 iteration 3820 : loss : 0.016309, loss_ce: 0.006995
2021-12-11 21:03:59,308 iteration 3821 : loss : 0.025970, loss_ce: 0.010933
2021-12-11 21:04:00,837 iteration 3822 : loss : 0.028164, loss_ce: 0.008595
2021-12-11 21:04:02,336 iteration 3823 : loss : 0.022364, loss_ce: 0.007719
2021-12-11 21:04:03,930 iteration 3824 : loss : 0.024480, loss_ce: 0.008924
2021-12-11 21:04:03,931 Training Data Eval:
2021-12-11 21:04:11,569   Average segmentation loss on training set: 0.0183
2021-12-11 21:04:11,569 Validation Data Eval:
2021-12-11 21:04:14,199   Average segmentation loss on validation set: 0.1016
2021-12-11 21:04:15,654 iteration 3825 : loss : 0.024174, loss_ce: 0.008668
 56%|███████████████▏           | 225/400 [1:46:49<1:27:32, 30.02s/it]2021-12-11 21:04:17,298 iteration 3826 : loss : 0.025366, loss_ce: 0.011241
2021-12-11 21:04:18,920 iteration 3827 : loss : 0.035095, loss_ce: 0.014074
2021-12-11 21:04:20,414 iteration 3828 : loss : 0.017038, loss_ce: 0.008976
2021-12-11 21:04:21,919 iteration 3829 : loss : 0.016180, loss_ce: 0.005876
2021-12-11 21:04:23,545 iteration 3830 : loss : 0.023394, loss_ce: 0.006927
2021-12-11 21:04:25,141 iteration 3831 : loss : 0.024243, loss_ce: 0.009998
2021-12-11 21:04:26,702 iteration 3832 : loss : 0.033037, loss_ce: 0.014925
2021-12-11 21:04:28,269 iteration 3833 : loss : 0.055119, loss_ce: 0.020088
2021-12-11 21:04:29,767 iteration 3834 : loss : 0.019751, loss_ce: 0.005604
2021-12-11 21:04:31,333 iteration 3835 : loss : 0.041570, loss_ce: 0.009633
2021-12-11 21:04:32,843 iteration 3836 : loss : 0.021311, loss_ce: 0.009309
2021-12-11 21:04:34,288 iteration 3837 : loss : 0.019824, loss_ce: 0.008154
2021-12-11 21:04:35,860 iteration 3838 : loss : 0.024057, loss_ce: 0.010001
2021-12-11 21:04:37,352 iteration 3839 : loss : 0.032158, loss_ce: 0.009015
2021-12-11 21:04:38,907 iteration 3840 : loss : 0.023342, loss_ce: 0.008564
2021-12-11 21:04:40,362 iteration 3841 : loss : 0.020600, loss_ce: 0.007878
2021-12-11 21:04:41,936 iteration 3842 : loss : 0.050440, loss_ce: 0.013538
 56%|███████████████▎           | 226/400 [1:47:16<1:23:48, 28.90s/it]2021-12-11 21:04:43,497 iteration 3843 : loss : 0.025314, loss_ce: 0.007225
2021-12-11 21:04:45,088 iteration 3844 : loss : 0.030148, loss_ce: 0.010890
2021-12-11 21:04:46,530 iteration 3845 : loss : 0.038487, loss_ce: 0.013783
2021-12-11 21:04:48,088 iteration 3846 : loss : 0.032846, loss_ce: 0.013086
2021-12-11 21:04:49,733 iteration 3847 : loss : 0.032425, loss_ce: 0.011212
2021-12-11 21:04:51,229 iteration 3848 : loss : 0.026721, loss_ce: 0.010944
2021-12-11 21:04:52,726 iteration 3849 : loss : 0.022338, loss_ce: 0.008099
2021-12-11 21:04:54,323 iteration 3850 : loss : 0.025466, loss_ce: 0.008162
2021-12-11 21:04:55,937 iteration 3851 : loss : 0.033615, loss_ce: 0.011215
2021-12-11 21:04:57,509 iteration 3852 : loss : 0.028685, loss_ce: 0.009722
2021-12-11 21:04:59,024 iteration 3853 : loss : 0.021641, loss_ce: 0.007809
2021-12-11 21:05:00,464 iteration 3854 : loss : 0.019584, loss_ce: 0.007604
2021-12-11 21:05:01,974 iteration 3855 : loss : 0.015802, loss_ce: 0.004055
2021-12-11 21:05:03,614 iteration 3856 : loss : 0.025424, loss_ce: 0.011768
2021-12-11 21:05:05,126 iteration 3857 : loss : 0.033245, loss_ce: 0.010203
2021-12-11 21:05:06,666 iteration 3858 : loss : 0.023598, loss_ce: 0.009966
2021-12-11 21:05:08,149 iteration 3859 : loss : 0.026800, loss_ce: 0.012445
 57%|███████████████▎           | 227/400 [1:47:42<1:20:59, 28.09s/it]2021-12-11 21:05:09,670 iteration 3860 : loss : 0.020099, loss_ce: 0.009750
2021-12-11 21:05:11,164 iteration 3861 : loss : 0.033474, loss_ce: 0.013616
2021-12-11 21:05:12,649 iteration 3862 : loss : 0.022484, loss_ce: 0.006385
2021-12-11 21:05:14,191 iteration 3863 : loss : 0.029239, loss_ce: 0.012134
2021-12-11 21:05:15,644 iteration 3864 : loss : 0.019426, loss_ce: 0.007261
2021-12-11 21:05:17,209 iteration 3865 : loss : 0.024729, loss_ce: 0.011703
2021-12-11 21:05:18,722 iteration 3866 : loss : 0.022817, loss_ce: 0.009520
2021-12-11 21:05:20,296 iteration 3867 : loss : 0.030081, loss_ce: 0.011723
2021-12-11 21:05:21,758 iteration 3868 : loss : 0.022828, loss_ce: 0.009545
2021-12-11 21:05:23,369 iteration 3869 : loss : 0.030261, loss_ce: 0.008339
2021-12-11 21:05:24,875 iteration 3870 : loss : 0.027174, loss_ce: 0.008587
2021-12-11 21:05:26,455 iteration 3871 : loss : 0.027115, loss_ce: 0.010194
2021-12-11 21:05:27,987 iteration 3872 : loss : 0.023090, loss_ce: 0.007287
2021-12-11 21:05:29,498 iteration 3873 : loss : 0.032820, loss_ce: 0.009274
2021-12-11 21:05:31,085 iteration 3874 : loss : 0.023322, loss_ce: 0.007808
2021-12-11 21:05:32,643 iteration 3875 : loss : 0.050685, loss_ce: 0.015933
2021-12-11 21:05:34,273 iteration 3876 : loss : 0.031721, loss_ce: 0.014383
 57%|███████████████▍           | 228/400 [1:48:08<1:18:50, 27.50s/it]2021-12-11 21:05:35,851 iteration 3877 : loss : 0.021607, loss_ce: 0.008698
2021-12-11 21:05:37,415 iteration 3878 : loss : 0.022325, loss_ce: 0.007617
2021-12-11 21:05:39,003 iteration 3879 : loss : 0.024860, loss_ce: 0.013028
2021-12-11 21:05:40,532 iteration 3880 : loss : 0.019028, loss_ce: 0.006778
2021-12-11 21:05:42,087 iteration 3881 : loss : 0.025737, loss_ce: 0.007445
2021-12-11 21:05:43,661 iteration 3882 : loss : 0.021739, loss_ce: 0.009783
2021-12-11 21:05:45,212 iteration 3883 : loss : 0.020896, loss_ce: 0.006866
2021-12-11 21:05:46,756 iteration 3884 : loss : 0.022110, loss_ce: 0.007796
2021-12-11 21:05:48,253 iteration 3885 : loss : 0.019209, loss_ce: 0.006004
2021-12-11 21:05:49,823 iteration 3886 : loss : 0.033135, loss_ce: 0.016254
2021-12-11 21:05:51,365 iteration 3887 : loss : 0.023435, loss_ce: 0.008078
2021-12-11 21:05:52,994 iteration 3888 : loss : 0.025541, loss_ce: 0.012740
2021-12-11 21:05:54,502 iteration 3889 : loss : 0.026479, loss_ce: 0.007731
2021-12-11 21:05:56,020 iteration 3890 : loss : 0.016995, loss_ce: 0.005772
2021-12-11 21:05:57,600 iteration 3891 : loss : 0.039163, loss_ce: 0.019009
2021-12-11 21:05:59,142 iteration 3892 : loss : 0.027276, loss_ce: 0.009209
2021-12-11 21:06:00,632 iteration 3893 : loss : 0.043137, loss_ce: 0.011249
 57%|███████████████▍           | 229/400 [1:48:34<1:17:24, 27.16s/it]2021-12-11 21:06:02,201 iteration 3894 : loss : 0.024656, loss_ce: 0.009259
2021-12-11 21:06:03,774 iteration 3895 : loss : 0.030922, loss_ce: 0.014333
2021-12-11 21:06:05,251 iteration 3896 : loss : 0.017073, loss_ce: 0.006189
2021-12-11 21:06:06,838 iteration 3897 : loss : 0.024619, loss_ce: 0.008274
2021-12-11 21:06:08,397 iteration 3898 : loss : 0.034588, loss_ce: 0.009472
2021-12-11 21:06:09,948 iteration 3899 : loss : 0.019002, loss_ce: 0.006306
2021-12-11 21:06:11,502 iteration 3900 : loss : 0.025191, loss_ce: 0.012682
2021-12-11 21:06:12,940 iteration 3901 : loss : 0.022160, loss_ce: 0.010295
2021-12-11 21:06:14,484 iteration 3902 : loss : 0.018035, loss_ce: 0.006075
2021-12-11 21:06:15,975 iteration 3903 : loss : 0.023174, loss_ce: 0.006797
2021-12-11 21:06:17,512 iteration 3904 : loss : 0.022543, loss_ce: 0.009511
2021-12-11 21:06:19,053 iteration 3905 : loss : 0.032968, loss_ce: 0.018615
2021-12-11 21:06:20,585 iteration 3906 : loss : 0.018813, loss_ce: 0.006707
2021-12-11 21:06:22,154 iteration 3907 : loss : 0.028638, loss_ce: 0.008729
2021-12-11 21:06:23,591 iteration 3908 : loss : 0.022142, loss_ce: 0.007609
2021-12-11 21:06:25,048 iteration 3909 : loss : 0.022159, loss_ce: 0.008409
2021-12-11 21:06:25,048 Training Data Eval:
2021-12-11 21:06:32,675   Average segmentation loss on training set: 0.0161
2021-12-11 21:06:32,676 Validation Data Eval:
2021-12-11 21:06:35,312   Average segmentation loss on validation set: 0.0726
2021-12-11 21:06:36,846 iteration 3910 : loss : 0.023097, loss_ce: 0.009122
 57%|███████████████▌           | 230/400 [1:49:10<1:24:38, 29.87s/it]2021-12-11 21:06:38,346 iteration 3911 : loss : 0.017994, loss_ce: 0.008293
2021-12-11 21:06:39,856 iteration 3912 : loss : 0.036870, loss_ce: 0.010680
2021-12-11 21:06:41,407 iteration 3913 : loss : 0.026312, loss_ce: 0.011850
2021-12-11 21:06:42,848 iteration 3914 : loss : 0.015415, loss_ce: 0.006493
2021-12-11 21:06:44,409 iteration 3915 : loss : 0.026182, loss_ce: 0.009212
2021-12-11 21:06:45,956 iteration 3916 : loss : 0.023152, loss_ce: 0.008634
2021-12-11 21:06:47,535 iteration 3917 : loss : 0.027549, loss_ce: 0.009114
2021-12-11 21:06:49,053 iteration 3918 : loss : 0.024604, loss_ce: 0.007329
2021-12-11 21:06:50,587 iteration 3919 : loss : 0.024510, loss_ce: 0.006866
2021-12-11 21:06:52,144 iteration 3920 : loss : 0.029856, loss_ce: 0.008151
2021-12-11 21:06:53,731 iteration 3921 : loss : 0.018586, loss_ce: 0.005548
2021-12-11 21:06:55,311 iteration 3922 : loss : 0.041547, loss_ce: 0.010884
2021-12-11 21:06:56,948 iteration 3923 : loss : 0.034009, loss_ce: 0.013802
2021-12-11 21:06:58,450 iteration 3924 : loss : 0.024396, loss_ce: 0.008700
2021-12-11 21:06:59,908 iteration 3925 : loss : 0.028967, loss_ce: 0.013967
2021-12-11 21:07:01,591 iteration 3926 : loss : 0.029804, loss_ce: 0.012330
2021-12-11 21:07:03,149 iteration 3927 : loss : 0.027781, loss_ce: 0.013116
 58%|███████████████▌           | 231/400 [1:49:37<1:21:07, 28.80s/it]2021-12-11 21:07:04,703 iteration 3928 : loss : 0.023822, loss_ce: 0.008618
2021-12-11 21:07:06,189 iteration 3929 : loss : 0.026689, loss_ce: 0.016552
2021-12-11 21:07:07,725 iteration 3930 : loss : 0.034410, loss_ce: 0.015208
2021-12-11 21:07:09,181 iteration 3931 : loss : 0.027410, loss_ce: 0.006810
2021-12-11 21:07:10,713 iteration 3932 : loss : 0.031482, loss_ce: 0.010231
2021-12-11 21:07:12,281 iteration 3933 : loss : 0.021901, loss_ce: 0.010823
2021-12-11 21:07:13,831 iteration 3934 : loss : 0.042809, loss_ce: 0.015052
2021-12-11 21:07:15,351 iteration 3935 : loss : 0.027673, loss_ce: 0.009993
2021-12-11 21:07:16,845 iteration 3936 : loss : 0.019367, loss_ce: 0.005759
2021-12-11 21:07:18,378 iteration 3937 : loss : 0.024854, loss_ce: 0.007025
2021-12-11 21:07:19,906 iteration 3938 : loss : 0.026640, loss_ce: 0.007319
2021-12-11 21:07:21,500 iteration 3939 : loss : 0.033170, loss_ce: 0.007419
2021-12-11 21:07:23,033 iteration 3940 : loss : 0.024646, loss_ce: 0.009837
2021-12-11 21:07:24,570 iteration 3941 : loss : 0.026086, loss_ce: 0.007034
2021-12-11 21:07:26,053 iteration 3942 : loss : 0.019926, loss_ce: 0.009991
2021-12-11 21:07:27,543 iteration 3943 : loss : 0.032218, loss_ce: 0.013736
2021-12-11 21:07:29,057 iteration 3944 : loss : 0.031487, loss_ce: 0.009633
 58%|███████████████▋           | 232/400 [1:50:03<1:18:13, 27.94s/it]2021-12-11 21:07:30,683 iteration 3945 : loss : 0.027529, loss_ce: 0.007946
2021-12-11 21:07:32,189 iteration 3946 : loss : 0.022529, loss_ce: 0.008507
2021-12-11 21:07:33,670 iteration 3947 : loss : 0.024682, loss_ce: 0.009675
2021-12-11 21:07:35,241 iteration 3948 : loss : 0.028366, loss_ce: 0.012587
2021-12-11 21:07:36,839 iteration 3949 : loss : 0.031558, loss_ce: 0.008800
2021-12-11 21:07:38,345 iteration 3950 : loss : 0.020021, loss_ce: 0.008917
2021-12-11 21:07:39,815 iteration 3951 : loss : 0.024601, loss_ce: 0.005271
2021-12-11 21:07:41,518 iteration 3952 : loss : 0.026916, loss_ce: 0.011172
2021-12-11 21:07:43,055 iteration 3953 : loss : 0.023507, loss_ce: 0.010594
2021-12-11 21:07:44,547 iteration 3954 : loss : 0.019793, loss_ce: 0.007002
2021-12-11 21:07:46,103 iteration 3955 : loss : 0.022412, loss_ce: 0.010065
2021-12-11 21:07:47,673 iteration 3956 : loss : 0.032087, loss_ce: 0.017670
2021-12-11 21:07:49,265 iteration 3957 : loss : 0.035289, loss_ce: 0.010580
2021-12-11 21:07:50,859 iteration 3958 : loss : 0.025321, loss_ce: 0.011664
2021-12-11 21:07:52,305 iteration 3959 : loss : 0.022119, loss_ce: 0.005251
2021-12-11 21:07:53,875 iteration 3960 : loss : 0.024350, loss_ce: 0.008944
2021-12-11 21:07:55,378 iteration 3961 : loss : 0.024169, loss_ce: 0.007307
 58%|███████████████▋           | 233/400 [1:50:29<1:16:24, 27.45s/it]2021-12-11 21:07:56,954 iteration 3962 : loss : 0.026086, loss_ce: 0.010630
2021-12-11 21:07:58,597 iteration 3963 : loss : 0.029278, loss_ce: 0.011480
2021-12-11 21:08:00,072 iteration 3964 : loss : 0.019872, loss_ce: 0.005353
2021-12-11 21:08:01,621 iteration 3965 : loss : 0.018207, loss_ce: 0.007473
2021-12-11 21:08:03,247 iteration 3966 : loss : 0.027737, loss_ce: 0.012552
2021-12-11 21:08:04,782 iteration 3967 : loss : 0.026058, loss_ce: 0.005853
2021-12-11 21:08:06,318 iteration 3968 : loss : 0.017054, loss_ce: 0.005515
2021-12-11 21:08:07,810 iteration 3969 : loss : 0.020732, loss_ce: 0.006640
2021-12-11 21:08:09,341 iteration 3970 : loss : 0.025436, loss_ce: 0.006135
2021-12-11 21:08:10,874 iteration 3971 : loss : 0.022672, loss_ce: 0.007319
2021-12-11 21:08:12,406 iteration 3972 : loss : 0.023267, loss_ce: 0.008558
2021-12-11 21:08:14,005 iteration 3973 : loss : 0.031884, loss_ce: 0.012258
2021-12-11 21:08:15,604 iteration 3974 : loss : 0.031488, loss_ce: 0.014931
2021-12-11 21:08:17,128 iteration 3975 : loss : 0.023655, loss_ce: 0.006884
2021-12-11 21:08:18,647 iteration 3976 : loss : 0.020975, loss_ce: 0.007015
2021-12-11 21:08:20,207 iteration 3977 : loss : 0.023956, loss_ce: 0.012162
2021-12-11 21:08:21,741 iteration 3978 : loss : 0.024597, loss_ce: 0.010558
 58%|███████████████▊           | 234/400 [1:50:55<1:15:02, 27.12s/it]2021-12-11 21:08:23,377 iteration 3979 : loss : 0.023548, loss_ce: 0.011278
2021-12-11 21:08:24,830 iteration 3980 : loss : 0.021386, loss_ce: 0.008202
2021-12-11 21:08:26,358 iteration 3981 : loss : 0.032082, loss_ce: 0.010378
2021-12-11 21:08:27,959 iteration 3982 : loss : 0.023493, loss_ce: 0.010478
2021-12-11 21:08:29,499 iteration 3983 : loss : 0.030888, loss_ce: 0.007995
2021-12-11 21:08:31,067 iteration 3984 : loss : 0.035085, loss_ce: 0.016825
2021-12-11 21:08:32,633 iteration 3985 : loss : 0.020574, loss_ce: 0.006459
2021-12-11 21:08:34,217 iteration 3986 : loss : 0.029453, loss_ce: 0.010134
2021-12-11 21:08:35,683 iteration 3987 : loss : 0.024408, loss_ce: 0.009731
2021-12-11 21:08:37,206 iteration 3988 : loss : 0.024722, loss_ce: 0.009517
2021-12-11 21:08:38,757 iteration 3989 : loss : 0.021423, loss_ce: 0.007927
2021-12-11 21:08:40,319 iteration 3990 : loss : 0.027317, loss_ce: 0.011365
2021-12-11 21:08:41,886 iteration 3991 : loss : 0.029040, loss_ce: 0.014620
2021-12-11 21:08:43,457 iteration 3992 : loss : 0.022902, loss_ce: 0.008398
2021-12-11 21:08:44,996 iteration 3993 : loss : 0.024331, loss_ce: 0.010062
2021-12-11 21:08:46,640 iteration 3994 : loss : 0.018771, loss_ce: 0.005979
2021-12-11 21:08:46,640 Training Data Eval:
2021-12-11 21:08:54,297   Average segmentation loss on training set: 0.0152
2021-12-11 21:08:54,298 Validation Data Eval:
2021-12-11 21:08:56,942   Average segmentation loss on validation set: 0.0855
2021-12-11 21:08:58,584 iteration 3995 : loss : 0.027077, loss_ce: 0.009519
 59%|███████████████▊           | 235/400 [1:51:32<1:22:36, 30.04s/it]2021-12-11 21:09:00,148 iteration 3996 : loss : 0.022176, loss_ce: 0.010498
2021-12-11 21:09:01,631 iteration 3997 : loss : 0.024553, loss_ce: 0.009674
2021-12-11 21:09:03,104 iteration 3998 : loss : 0.022260, loss_ce: 0.006649
2021-12-11 21:09:04,701 iteration 3999 : loss : 0.034340, loss_ce: 0.009369
2021-12-11 21:09:06,241 iteration 4000 : loss : 0.020077, loss_ce: 0.008108
2021-12-11 21:09:07,820 iteration 4001 : loss : 0.017245, loss_ce: 0.008282
2021-12-11 21:09:09,270 iteration 4002 : loss : 0.021952, loss_ce: 0.007115
2021-12-11 21:09:10,859 iteration 4003 : loss : 0.030696, loss_ce: 0.010731
2021-12-11 21:09:12,434 iteration 4004 : loss : 0.034266, loss_ce: 0.014478
2021-12-11 21:09:13,986 iteration 4005 : loss : 0.021433, loss_ce: 0.008707
2021-12-11 21:09:15,471 iteration 4006 : loss : 0.024529, loss_ce: 0.007490
2021-12-11 21:09:17,004 iteration 4007 : loss : 0.031373, loss_ce: 0.009639
2021-12-11 21:09:18,515 iteration 4008 : loss : 0.018963, loss_ce: 0.009080
2021-12-11 21:09:20,056 iteration 4009 : loss : 0.017751, loss_ce: 0.005870
2021-12-11 21:09:21,600 iteration 4010 : loss : 0.019620, loss_ce: 0.007415
2021-12-11 21:09:23,124 iteration 4011 : loss : 0.023554, loss_ce: 0.007549
2021-12-11 21:09:24,675 iteration 4012 : loss : 0.023194, loss_ce: 0.009223
 59%|███████████████▉           | 236/400 [1:51:58<1:18:52, 28.86s/it]2021-12-11 21:09:26,139 iteration 4013 : loss : 0.017462, loss_ce: 0.007913
2021-12-11 21:09:27,733 iteration 4014 : loss : 0.021548, loss_ce: 0.008566
2021-12-11 21:09:29,222 iteration 4015 : loss : 0.020736, loss_ce: 0.009438
2021-12-11 21:09:30,869 iteration 4016 : loss : 0.020368, loss_ce: 0.007464
2021-12-11 21:09:32,418 iteration 4017 : loss : 0.024584, loss_ce: 0.007467
2021-12-11 21:09:33,890 iteration 4018 : loss : 0.022013, loss_ce: 0.007518
2021-12-11 21:09:35,433 iteration 4019 : loss : 0.024323, loss_ce: 0.008502
2021-12-11 21:09:36,933 iteration 4020 : loss : 0.020537, loss_ce: 0.006289
2021-12-11 21:09:38,494 iteration 4021 : loss : 0.029793, loss_ce: 0.007541
2021-12-11 21:09:40,124 iteration 4022 : loss : 0.029022, loss_ce: 0.009174
2021-12-11 21:09:41,595 iteration 4023 : loss : 0.016444, loss_ce: 0.007684
2021-12-11 21:09:43,169 iteration 4024 : loss : 0.049980, loss_ce: 0.020686
2021-12-11 21:09:44,713 iteration 4025 : loss : 0.025146, loss_ce: 0.008187
2021-12-11 21:09:46,310 iteration 4026 : loss : 0.033527, loss_ce: 0.009354
2021-12-11 21:09:47,784 iteration 4027 : loss : 0.018786, loss_ce: 0.005685
2021-12-11 21:09:49,449 iteration 4028 : loss : 0.031880, loss_ce: 0.012706
2021-12-11 21:09:51,098 iteration 4029 : loss : 0.026188, loss_ce: 0.010375
 59%|███████████████▉           | 237/400 [1:52:25<1:16:24, 28.13s/it]2021-12-11 21:09:52,648 iteration 4030 : loss : 0.022733, loss_ce: 0.008076
2021-12-11 21:09:54,174 iteration 4031 : loss : 0.025684, loss_ce: 0.011191
2021-12-11 21:09:55,633 iteration 4032 : loss : 0.018005, loss_ce: 0.005199
2021-12-11 21:09:57,125 iteration 4033 : loss : 0.021883, loss_ce: 0.008420
2021-12-11 21:09:58,691 iteration 4034 : loss : 0.023316, loss_ce: 0.011290
2021-12-11 21:10:00,268 iteration 4035 : loss : 0.033221, loss_ce: 0.012332
2021-12-11 21:10:01,825 iteration 4036 : loss : 0.021362, loss_ce: 0.009283
2021-12-11 21:10:03,321 iteration 4037 : loss : 0.020139, loss_ce: 0.009881
2021-12-11 21:10:04,850 iteration 4038 : loss : 0.024262, loss_ce: 0.009835
2021-12-11 21:10:06,398 iteration 4039 : loss : 0.026172, loss_ce: 0.007864
2021-12-11 21:10:07,913 iteration 4040 : loss : 0.031686, loss_ce: 0.011061
2021-12-11 21:10:09,494 iteration 4041 : loss : 0.022831, loss_ce: 0.009217
2021-12-11 21:10:11,063 iteration 4042 : loss : 0.021460, loss_ce: 0.007421
2021-12-11 21:10:12,602 iteration 4043 : loss : 0.025805, loss_ce: 0.009539
2021-12-11 21:10:14,140 iteration 4044 : loss : 0.022170, loss_ce: 0.008447
2021-12-11 21:10:15,683 iteration 4045 : loss : 0.019759, loss_ce: 0.005375
2021-12-11 21:10:17,267 iteration 4046 : loss : 0.025255, loss_ce: 0.009256
 60%|████████████████           | 238/400 [1:52:51<1:14:20, 27.54s/it]2021-12-11 21:10:18,890 iteration 4047 : loss : 0.027299, loss_ce: 0.010394
2021-12-11 21:10:20,425 iteration 4048 : loss : 0.024086, loss_ce: 0.007458
2021-12-11 21:10:21,956 iteration 4049 : loss : 0.020135, loss_ce: 0.005746
2021-12-11 21:10:23,426 iteration 4050 : loss : 0.025462, loss_ce: 0.008115
2021-12-11 21:10:24,957 iteration 4051 : loss : 0.018104, loss_ce: 0.007212
2021-12-11 21:10:26,447 iteration 4052 : loss : 0.018847, loss_ce: 0.007585
2021-12-11 21:10:28,006 iteration 4053 : loss : 0.038812, loss_ce: 0.008767
2021-12-11 21:10:29,582 iteration 4054 : loss : 0.023233, loss_ce: 0.009656
2021-12-11 21:10:31,130 iteration 4055 : loss : 0.020306, loss_ce: 0.009208
2021-12-11 21:10:32,667 iteration 4056 : loss : 0.020875, loss_ce: 0.009325
2021-12-11 21:10:34,163 iteration 4057 : loss : 0.031459, loss_ce: 0.007495
2021-12-11 21:10:35,667 iteration 4058 : loss : 0.016779, loss_ce: 0.006602
2021-12-11 21:10:37,243 iteration 4059 : loss : 0.021109, loss_ce: 0.006925
2021-12-11 21:10:38,747 iteration 4060 : loss : 0.026657, loss_ce: 0.010540
2021-12-11 21:10:40,194 iteration 4061 : loss : 0.021095, loss_ce: 0.009074
2021-12-11 21:10:41,692 iteration 4062 : loss : 0.020162, loss_ce: 0.008321
2021-12-11 21:10:43,276 iteration 4063 : loss : 0.025312, loss_ce: 0.009914
 60%|████████████████▏          | 239/400 [1:53:17<1:12:39, 27.08s/it]2021-12-11 21:10:44,839 iteration 4064 : loss : 0.018637, loss_ce: 0.006577
2021-12-11 21:10:46,351 iteration 4065 : loss : 0.024824, loss_ce: 0.006133
2021-12-11 21:10:47,878 iteration 4066 : loss : 0.019081, loss_ce: 0.006719
2021-12-11 21:10:49,416 iteration 4067 : loss : 0.025862, loss_ce: 0.009586
2021-12-11 21:10:50,976 iteration 4068 : loss : 0.026004, loss_ce: 0.009900
2021-12-11 21:10:52,598 iteration 4069 : loss : 0.030356, loss_ce: 0.013753
2021-12-11 21:10:54,087 iteration 4070 : loss : 0.025764, loss_ce: 0.008179
2021-12-11 21:10:55,617 iteration 4071 : loss : 0.023231, loss_ce: 0.007919
2021-12-11 21:10:57,163 iteration 4072 : loss : 0.022698, loss_ce: 0.008065
2021-12-11 21:10:58,725 iteration 4073 : loss : 0.021868, loss_ce: 0.008631
2021-12-11 21:11:00,266 iteration 4074 : loss : 0.024857, loss_ce: 0.010015
2021-12-11 21:11:01,900 iteration 4075 : loss : 0.030848, loss_ce: 0.009912
2021-12-11 21:11:03,477 iteration 4076 : loss : 0.017130, loss_ce: 0.007443
2021-12-11 21:11:05,079 iteration 4077 : loss : 0.027997, loss_ce: 0.011533
2021-12-11 21:11:06,671 iteration 4078 : loss : 0.025784, loss_ce: 0.010197
2021-12-11 21:11:08,166 iteration 4079 : loss : 0.018062, loss_ce: 0.006321
2021-12-11 21:11:08,167 Training Data Eval:
2021-12-11 21:11:15,825   Average segmentation loss on training set: 0.0149
2021-12-11 21:11:15,826 Validation Data Eval:
2021-12-11 21:11:18,469   Average segmentation loss on validation set: 0.0893
2021-12-11 21:11:20,094 iteration 4080 : loss : 0.031531, loss_ce: 0.013752
 60%|████████████████▏          | 240/400 [1:53:54<1:20:00, 30.00s/it]2021-12-11 21:11:21,658 iteration 4081 : loss : 0.019234, loss_ce: 0.007698
2021-12-11 21:11:23,183 iteration 4082 : loss : 0.021350, loss_ce: 0.007178
2021-12-11 21:11:24,710 iteration 4083 : loss : 0.021427, loss_ce: 0.011561
2021-12-11 21:11:26,286 iteration 4084 : loss : 0.025376, loss_ce: 0.007677
2021-12-11 21:11:27,908 iteration 4085 : loss : 0.030963, loss_ce: 0.009438
2021-12-11 21:11:29,505 iteration 4086 : loss : 0.021603, loss_ce: 0.009954
2021-12-11 21:11:31,023 iteration 4087 : loss : 0.025141, loss_ce: 0.006935
2021-12-11 21:11:32,557 iteration 4088 : loss : 0.018620, loss_ce: 0.007357
2021-12-11 21:11:34,122 iteration 4089 : loss : 0.024102, loss_ce: 0.007988
2021-12-11 21:11:35,700 iteration 4090 : loss : 0.021677, loss_ce: 0.009016
2021-12-11 21:11:37,201 iteration 4091 : loss : 0.019099, loss_ce: 0.006841
2021-12-11 21:11:38,795 iteration 4092 : loss : 0.015602, loss_ce: 0.005536
2021-12-11 21:11:40,326 iteration 4093 : loss : 0.019808, loss_ce: 0.007666
2021-12-11 21:11:41,829 iteration 4094 : loss : 0.018847, loss_ce: 0.005927
2021-12-11 21:11:43,340 iteration 4095 : loss : 0.023005, loss_ce: 0.008404
2021-12-11 21:11:44,880 iteration 4096 : loss : 0.021953, loss_ce: 0.008453
2021-12-11 21:11:46,420 iteration 4097 : loss : 0.021158, loss_ce: 0.009348
 60%|████████████████▎          | 241/400 [1:54:20<1:16:34, 28.90s/it]2021-12-11 21:11:48,031 iteration 4098 : loss : 0.021738, loss_ce: 0.007907
2021-12-11 21:11:49,543 iteration 4099 : loss : 0.030597, loss_ce: 0.006668
2021-12-11 21:11:51,028 iteration 4100 : loss : 0.021514, loss_ce: 0.008995
2021-12-11 21:11:52,523 iteration 4101 : loss : 0.017831, loss_ce: 0.006239
2021-12-11 21:11:54,067 iteration 4102 : loss : 0.020626, loss_ce: 0.008381
2021-12-11 21:11:55,601 iteration 4103 : loss : 0.015733, loss_ce: 0.005683
2021-12-11 21:11:57,085 iteration 4104 : loss : 0.019131, loss_ce: 0.008064
2021-12-11 21:11:58,635 iteration 4105 : loss : 0.025970, loss_ce: 0.009764
2021-12-11 21:12:00,124 iteration 4106 : loss : 0.019675, loss_ce: 0.003941
2021-12-11 21:12:01,754 iteration 4107 : loss : 0.039755, loss_ce: 0.023408
2021-12-11 21:12:03,335 iteration 4108 : loss : 0.029497, loss_ce: 0.013533
2021-12-11 21:12:04,817 iteration 4109 : loss : 0.019934, loss_ce: 0.004646
2021-12-11 21:12:06,370 iteration 4110 : loss : 0.031363, loss_ce: 0.011177
2021-12-11 21:12:07,973 iteration 4111 : loss : 0.027853, loss_ce: 0.011034
2021-12-11 21:12:09,480 iteration 4112 : loss : 0.024231, loss_ce: 0.008625
2021-12-11 21:12:11,037 iteration 4113 : loss : 0.020400, loss_ce: 0.008179
2021-12-11 21:12:12,653 iteration 4114 : loss : 0.026446, loss_ce: 0.008566
 60%|████████████████▎          | 242/400 [1:54:46<1:13:59, 28.10s/it]2021-12-11 21:12:14,196 iteration 4115 : loss : 0.021358, loss_ce: 0.005853
2021-12-11 21:12:15,659 iteration 4116 : loss : 0.019578, loss_ce: 0.008741
2021-12-11 21:12:17,330 iteration 4117 : loss : 0.028321, loss_ce: 0.008568
2021-12-11 21:12:18,991 iteration 4118 : loss : 0.022679, loss_ce: 0.009206
2021-12-11 21:12:20,556 iteration 4119 : loss : 0.022002, loss_ce: 0.009547
2021-12-11 21:12:22,113 iteration 4120 : loss : 0.050087, loss_ce: 0.007467
2021-12-11 21:12:23,663 iteration 4121 : loss : 0.018630, loss_ce: 0.008057
2021-12-11 21:12:25,179 iteration 4122 : loss : 0.023331, loss_ce: 0.009001
2021-12-11 21:12:26,845 iteration 4123 : loss : 0.026793, loss_ce: 0.009217
2021-12-11 21:12:28,335 iteration 4124 : loss : 0.030309, loss_ce: 0.010415
2021-12-11 21:12:29,941 iteration 4125 : loss : 0.026149, loss_ce: 0.007745
2021-12-11 21:12:31,490 iteration 4126 : loss : 0.017893, loss_ce: 0.007601
2021-12-11 21:12:33,064 iteration 4127 : loss : 0.025571, loss_ce: 0.011074
2021-12-11 21:12:34,578 iteration 4128 : loss : 0.025146, loss_ce: 0.012973
2021-12-11 21:12:36,169 iteration 4129 : loss : 0.018611, loss_ce: 0.007057
2021-12-11 21:12:37,698 iteration 4130 : loss : 0.018340, loss_ce: 0.009222
2021-12-11 21:12:39,151 iteration 4131 : loss : 0.018295, loss_ce: 0.005174
 61%|████████████████▍          | 243/400 [1:55:13<1:12:16, 27.62s/it]2021-12-11 21:12:40,768 iteration 4132 : loss : 0.032626, loss_ce: 0.016045
2021-12-11 21:12:42,365 iteration 4133 : loss : 0.029744, loss_ce: 0.013161
2021-12-11 21:12:43,828 iteration 4134 : loss : 0.019263, loss_ce: 0.007911
2021-12-11 21:12:45,423 iteration 4135 : loss : 0.022477, loss_ce: 0.008538
2021-12-11 21:12:46,973 iteration 4136 : loss : 0.024410, loss_ce: 0.012269
2021-12-11 21:12:48,477 iteration 4137 : loss : 0.023236, loss_ce: 0.010847
2021-12-11 21:12:49,977 iteration 4138 : loss : 0.022673, loss_ce: 0.010535
2021-12-11 21:12:51,531 iteration 4139 : loss : 0.032232, loss_ce: 0.009778
2021-12-11 21:12:53,123 iteration 4140 : loss : 0.027162, loss_ce: 0.009123
2021-12-11 21:12:54,664 iteration 4141 : loss : 0.033832, loss_ce: 0.008116
2021-12-11 21:12:56,257 iteration 4142 : loss : 0.030140, loss_ce: 0.008477
2021-12-11 21:12:57,848 iteration 4143 : loss : 0.029496, loss_ce: 0.009031
2021-12-11 21:12:59,371 iteration 4144 : loss : 0.023669, loss_ce: 0.008749
2021-12-11 21:13:00,887 iteration 4145 : loss : 0.019121, loss_ce: 0.005529
2021-12-11 21:13:02,424 iteration 4146 : loss : 0.025053, loss_ce: 0.007713
2021-12-11 21:13:03,942 iteration 4147 : loss : 0.025450, loss_ce: 0.009755
2021-12-11 21:13:05,385 iteration 4148 : loss : 0.015420, loss_ce: 0.005502
 61%|████████████████▍          | 244/400 [1:55:39<1:10:43, 27.20s/it]2021-12-11 21:13:07,066 iteration 4149 : loss : 0.039063, loss_ce: 0.017570
2021-12-11 21:13:08,530 iteration 4150 : loss : 0.021197, loss_ce: 0.006136
2021-12-11 21:13:10,098 iteration 4151 : loss : 0.020396, loss_ce: 0.010124
2021-12-11 21:13:11,543 iteration 4152 : loss : 0.019177, loss_ce: 0.007418
2021-12-11 21:13:13,116 iteration 4153 : loss : 0.028823, loss_ce: 0.007809
2021-12-11 21:13:14,672 iteration 4154 : loss : 0.031701, loss_ce: 0.011858
2021-12-11 21:13:16,270 iteration 4155 : loss : 0.027852, loss_ce: 0.009972
2021-12-11 21:13:17,723 iteration 4156 : loss : 0.014637, loss_ce: 0.005231
2021-12-11 21:13:19,291 iteration 4157 : loss : 0.026292, loss_ce: 0.009154
2021-12-11 21:13:20,823 iteration 4158 : loss : 0.026099, loss_ce: 0.010387
2021-12-11 21:13:22,394 iteration 4159 : loss : 0.015903, loss_ce: 0.006299
2021-12-11 21:13:23,926 iteration 4160 : loss : 0.026035, loss_ce: 0.012372
2021-12-11 21:13:25,464 iteration 4161 : loss : 0.022106, loss_ce: 0.008853
2021-12-11 21:13:26,970 iteration 4162 : loss : 0.021132, loss_ce: 0.007410
2021-12-11 21:13:28,553 iteration 4163 : loss : 0.038959, loss_ce: 0.010189
2021-12-11 21:13:30,143 iteration 4164 : loss : 0.023336, loss_ce: 0.010038
2021-12-11 21:13:30,143 Training Data Eval:
2021-12-11 21:13:37,780   Average segmentation loss on training set: 0.0163
2021-12-11 21:13:37,781 Validation Data Eval:
2021-12-11 21:13:40,421   Average segmentation loss on validation set: 0.0612
2021-12-11 21:13:42,381 Found new lowest validation loss at iteration 4164! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/NEW_TU/UNET_ADAM_best_val_loss_seed100.pth
2021-12-11 21:13:43,854 iteration 4165 : loss : 0.051873, loss_ce: 0.018175
 61%|████████████████▌          | 245/400 [1:56:17<1:19:00, 30.58s/it]2021-12-11 21:13:45,292 iteration 4166 : loss : 0.016026, loss_ce: 0.006212
2021-12-11 21:13:46,794 iteration 4167 : loss : 0.024600, loss_ce: 0.008043
2021-12-11 21:13:48,348 iteration 4168 : loss : 0.024697, loss_ce: 0.009755
2021-12-11 21:13:49,906 iteration 4169 : loss : 0.022748, loss_ce: 0.009513
2021-12-11 21:13:51,484 iteration 4170 : loss : 0.031317, loss_ce: 0.013291
2021-12-11 21:13:52,977 iteration 4171 : loss : 0.022082, loss_ce: 0.009339
2021-12-11 21:13:54,504 iteration 4172 : loss : 0.024988, loss_ce: 0.009534
2021-12-11 21:13:55,955 iteration 4173 : loss : 0.018090, loss_ce: 0.005482
2021-12-11 21:13:57,530 iteration 4174 : loss : 0.039153, loss_ce: 0.013007
2021-12-11 21:13:59,074 iteration 4175 : loss : 0.025571, loss_ce: 0.007777
2021-12-11 21:14:00,689 iteration 4176 : loss : 0.027543, loss_ce: 0.008692
2021-12-11 21:14:02,157 iteration 4177 : loss : 0.019549, loss_ce: 0.008937
2021-12-11 21:14:03,686 iteration 4178 : loss : 0.016751, loss_ce: 0.006765
2021-12-11 21:14:05,266 iteration 4179 : loss : 0.021625, loss_ce: 0.007551
2021-12-11 21:14:06,878 iteration 4180 : loss : 0.024464, loss_ce: 0.008911
2021-12-11 21:14:08,447 iteration 4181 : loss : 0.024272, loss_ce: 0.010340
2021-12-11 21:14:10,038 iteration 4182 : loss : 0.038146, loss_ce: 0.014209
 62%|████████████████▌          | 246/400 [1:56:44<1:15:06, 29.26s/it]2021-12-11 21:14:11,599 iteration 4183 : loss : 0.027295, loss_ce: 0.008684
2021-12-11 21:14:13,115 iteration 4184 : loss : 0.019901, loss_ce: 0.006213
2021-12-11 21:14:14,673 iteration 4185 : loss : 0.034854, loss_ce: 0.010868
2021-12-11 21:14:16,187 iteration 4186 : loss : 0.018705, loss_ce: 0.006572
2021-12-11 21:14:17,673 iteration 4187 : loss : 0.024059, loss_ce: 0.010124
2021-12-11 21:14:19,182 iteration 4188 : loss : 0.023939, loss_ce: 0.010015
2021-12-11 21:14:20,645 iteration 4189 : loss : 0.021416, loss_ce: 0.007471
2021-12-11 21:14:22,272 iteration 4190 : loss : 0.042693, loss_ce: 0.018805
2021-12-11 21:14:23,847 iteration 4191 : loss : 0.020967, loss_ce: 0.004872
2021-12-11 21:14:25,322 iteration 4192 : loss : 0.018771, loss_ce: 0.009140
2021-12-11 21:14:26,789 iteration 4193 : loss : 0.018880, loss_ce: 0.005981
2021-12-11 21:14:28,313 iteration 4194 : loss : 0.027926, loss_ce: 0.009615
2021-12-11 21:14:29,836 iteration 4195 : loss : 0.019117, loss_ce: 0.007793
2021-12-11 21:14:31,326 iteration 4196 : loss : 0.017822, loss_ce: 0.006756
2021-12-11 21:14:32,815 iteration 4197 : loss : 0.021435, loss_ce: 0.008107
2021-12-11 21:14:34,298 iteration 4198 : loss : 0.022468, loss_ce: 0.004872
2021-12-11 21:14:35,876 iteration 4199 : loss : 0.027953, loss_ce: 0.010465
 62%|████████████████▋          | 247/400 [1:57:09<1:11:59, 28.24s/it]2021-12-11 21:14:37,442 iteration 4200 : loss : 0.024687, loss_ce: 0.007847
2021-12-11 21:14:39,026 iteration 4201 : loss : 0.027198, loss_ce: 0.013868
2021-12-11 21:14:40,641 iteration 4202 : loss : 0.023346, loss_ce: 0.010243
2021-12-11 21:14:42,255 iteration 4203 : loss : 0.026770, loss_ce: 0.009487
2021-12-11 21:14:43,837 iteration 4204 : loss : 0.016000, loss_ce: 0.005794
2021-12-11 21:14:45,218 iteration 4205 : loss : 0.014012, loss_ce: 0.004782
2021-12-11 21:14:46,770 iteration 4206 : loss : 0.016902, loss_ce: 0.005290
2021-12-11 21:14:48,256 iteration 4207 : loss : 0.015456, loss_ce: 0.007210
2021-12-11 21:14:49,838 iteration 4208 : loss : 0.022304, loss_ce: 0.007564
2021-12-11 21:14:51,349 iteration 4209 : loss : 0.019506, loss_ce: 0.006043
2021-12-11 21:14:52,865 iteration 4210 : loss : 0.014746, loss_ce: 0.005181
2021-12-11 21:14:54,412 iteration 4211 : loss : 0.020603, loss_ce: 0.007987
2021-12-11 21:14:55,912 iteration 4212 : loss : 0.017811, loss_ce: 0.007388
2021-12-11 21:14:57,508 iteration 4213 : loss : 0.018287, loss_ce: 0.005230
2021-12-11 21:14:59,105 iteration 4214 : loss : 0.027510, loss_ce: 0.011641
2021-12-11 21:15:00,687 iteration 4215 : loss : 0.031608, loss_ce: 0.007848
2021-12-11 21:15:02,210 iteration 4216 : loss : 0.019971, loss_ce: 0.006993
 62%|████████████████▋          | 248/400 [1:57:36<1:10:05, 27.67s/it]2021-12-11 21:15:03,883 iteration 4217 : loss : 0.045268, loss_ce: 0.011665
2021-12-11 21:15:05,509 iteration 4218 : loss : 0.022394, loss_ce: 0.011039
2021-12-11 21:15:07,071 iteration 4219 : loss : 0.020153, loss_ce: 0.007080
2021-12-11 21:15:08,609 iteration 4220 : loss : 0.022481, loss_ce: 0.006871
2021-12-11 21:15:10,179 iteration 4221 : loss : 0.024909, loss_ce: 0.007615
2021-12-11 21:15:11,770 iteration 4222 : loss : 0.018897, loss_ce: 0.008301
2021-12-11 21:15:13,440 iteration 4223 : loss : 0.036705, loss_ce: 0.011117
2021-12-11 21:15:14,987 iteration 4224 : loss : 0.022682, loss_ce: 0.008441
2021-12-11 21:15:16,597 iteration 4225 : loss : 0.023922, loss_ce: 0.012322
2021-12-11 21:15:18,297 iteration 4226 : loss : 0.028391, loss_ce: 0.010593
2021-12-11 21:15:19,808 iteration 4227 : loss : 0.020150, loss_ce: 0.006243
2021-12-11 21:15:21,380 iteration 4228 : loss : 0.022884, loss_ce: 0.010325
2021-12-11 21:15:22,859 iteration 4229 : loss : 0.021148, loss_ce: 0.007898
2021-12-11 21:15:24,456 iteration 4230 : loss : 0.022503, loss_ce: 0.007486
2021-12-11 21:15:26,018 iteration 4231 : loss : 0.020666, loss_ce: 0.007281
2021-12-11 21:15:27,610 iteration 4232 : loss : 0.026793, loss_ce: 0.011054
2021-12-11 21:15:29,098 iteration 4233 : loss : 0.020303, loss_ce: 0.007381
 62%|████████████████▊          | 249/400 [1:58:03<1:09:02, 27.43s/it]2021-12-11 21:15:30,727 iteration 4234 : loss : 0.024350, loss_ce: 0.010149
2021-12-11 21:15:32,209 iteration 4235 : loss : 0.018327, loss_ce: 0.007009
2021-12-11 21:15:33,800 iteration 4236 : loss : 0.032578, loss_ce: 0.014407
2021-12-11 21:15:35,336 iteration 4237 : loss : 0.019711, loss_ce: 0.009867
2021-12-11 21:15:36,930 iteration 4238 : loss : 0.028107, loss_ce: 0.008927
2021-12-11 21:15:38,397 iteration 4239 : loss : 0.021642, loss_ce: 0.006671
2021-12-11 21:15:40,025 iteration 4240 : loss : 0.031611, loss_ce: 0.011089
2021-12-11 21:15:41,549 iteration 4241 : loss : 0.019070, loss_ce: 0.006192
2021-12-11 21:15:43,063 iteration 4242 : loss : 0.033351, loss_ce: 0.009551
2021-12-11 21:15:44,590 iteration 4243 : loss : 0.022020, loss_ce: 0.008316
2021-12-11 21:15:46,181 iteration 4244 : loss : 0.028472, loss_ce: 0.009654
2021-12-11 21:15:47,778 iteration 4245 : loss : 0.060130, loss_ce: 0.013709
2021-12-11 21:15:49,296 iteration 4246 : loss : 0.024543, loss_ce: 0.010936
2021-12-11 21:15:50,814 iteration 4247 : loss : 0.023528, loss_ce: 0.005721
2021-12-11 21:15:52,387 iteration 4248 : loss : 0.034159, loss_ce: 0.012172
2021-12-11 21:15:53,935 iteration 4249 : loss : 0.028239, loss_ce: 0.013530
2021-12-11 21:15:53,935 Training Data Eval:
2021-12-11 21:16:01,552   Average segmentation loss on training set: 0.0184
2021-12-11 21:16:01,553 Validation Data Eval:
2021-12-11 21:16:04,188   Average segmentation loss on validation set: 0.0822
2021-12-11 21:16:05,763 iteration 4250 : loss : 0.029725, loss_ce: 0.009385
2021-12-11 21:16:07,761 save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/NEW_TU/UNET_ADAM_seed100epoch_249.pth
 62%|████████████████▉          | 250/400 [1:58:41<1:16:58, 30.79s/it]2021-12-11 21:16:09,283 iteration 4251 : loss : 0.020409, loss_ce: 0.007279
2021-12-11 21:16:10,768 iteration 4252 : loss : 0.028463, loss_ce: 0.010406
2021-12-11 21:16:12,276 iteration 4253 : loss : 0.025962, loss_ce: 0.009304
2021-12-11 21:16:13,868 iteration 4254 : loss : 0.022620, loss_ce: 0.009451
2021-12-11 21:16:15,311 iteration 4255 : loss : 0.016402, loss_ce: 0.005905
2021-12-11 21:16:16,848 iteration 4256 : loss : 0.025400, loss_ce: 0.005715
2021-12-11 21:16:18,460 iteration 4257 : loss : 0.029950, loss_ce: 0.011443
2021-12-11 21:16:19,966 iteration 4258 : loss : 0.019607, loss_ce: 0.006750
2021-12-11 21:16:21,518 iteration 4259 : loss : 0.021212, loss_ce: 0.007857
2021-12-11 21:16:23,061 iteration 4260 : loss : 0.019395, loss_ce: 0.006296
2021-12-11 21:16:24,620 iteration 4261 : loss : 0.020107, loss_ce: 0.007144
2021-12-11 21:16:26,250 iteration 4262 : loss : 0.021092, loss_ce: 0.009423
2021-12-11 21:16:27,793 iteration 4263 : loss : 0.017816, loss_ce: 0.006497
2021-12-11 21:16:29,275 iteration 4264 : loss : 0.025165, loss_ce: 0.007858
2021-12-11 21:16:30,789 iteration 4265 : loss : 0.022950, loss_ce: 0.007055
2021-12-11 21:16:32,304 iteration 4266 : loss : 0.024904, loss_ce: 0.008786
2021-12-11 21:16:33,847 iteration 4267 : loss : 0.017063, loss_ce: 0.007995
 63%|████████████████▉          | 251/400 [1:59:07<1:12:59, 29.39s/it]2021-12-11 21:16:35,421 iteration 4268 : loss : 0.027272, loss_ce: 0.010540
2021-12-11 21:16:36,902 iteration 4269 : loss : 0.022330, loss_ce: 0.006841
2021-12-11 21:16:38,406 iteration 4270 : loss : 0.024754, loss_ce: 0.003826
2021-12-11 21:16:39,878 iteration 4271 : loss : 0.016245, loss_ce: 0.006999
2021-12-11 21:16:41,453 iteration 4272 : loss : 0.023577, loss_ce: 0.008136
2021-12-11 21:16:43,003 iteration 4273 : loss : 0.025747, loss_ce: 0.011602
2021-12-11 21:16:44,575 iteration 4274 : loss : 0.029736, loss_ce: 0.012024
2021-12-11 21:16:45,993 iteration 4275 : loss : 0.020024, loss_ce: 0.008981
2021-12-11 21:16:47,476 iteration 4276 : loss : 0.022411, loss_ce: 0.007498
2021-12-11 21:16:48,975 iteration 4277 : loss : 0.016384, loss_ce: 0.006278
2021-12-11 21:16:50,501 iteration 4278 : loss : 0.028989, loss_ce: 0.008999
2021-12-11 21:16:51,971 iteration 4279 : loss : 0.016744, loss_ce: 0.005334
2021-12-11 21:16:53,451 iteration 4280 : loss : 0.020194, loss_ce: 0.005942
2021-12-11 21:16:55,112 iteration 4281 : loss : 0.033296, loss_ce: 0.017109
2021-12-11 21:16:56,665 iteration 4282 : loss : 0.020482, loss_ce: 0.008063
2021-12-11 21:16:58,121 iteration 4283 : loss : 0.018860, loss_ce: 0.007349
2021-12-11 21:16:59,641 iteration 4284 : loss : 0.020026, loss_ce: 0.008971
 63%|█████████████████          | 252/400 [1:59:33<1:09:50, 28.31s/it]2021-12-11 21:17:01,262 iteration 4285 : loss : 0.025034, loss_ce: 0.011319
2021-12-11 21:17:02,842 iteration 4286 : loss : 0.017890, loss_ce: 0.004857
2021-12-11 21:17:04,435 iteration 4287 : loss : 0.031582, loss_ce: 0.013259
2021-12-11 21:17:05,975 iteration 4288 : loss : 0.018781, loss_ce: 0.005586
2021-12-11 21:17:07,524 iteration 4289 : loss : 0.020899, loss_ce: 0.006777
2021-12-11 21:17:09,163 iteration 4290 : loss : 0.029264, loss_ce: 0.010147
2021-12-11 21:17:10,638 iteration 4291 : loss : 0.023276, loss_ce: 0.007609
2021-12-11 21:17:12,237 iteration 4292 : loss : 0.018671, loss_ce: 0.007437
2021-12-11 21:17:13,793 iteration 4293 : loss : 0.033345, loss_ce: 0.014609
2021-12-11 21:17:15,336 iteration 4294 : loss : 0.040358, loss_ce: 0.021069
2021-12-11 21:17:16,921 iteration 4295 : loss : 0.018597, loss_ce: 0.007562
2021-12-11 21:17:18,395 iteration 4296 : loss : 0.016208, loss_ce: 0.006294
2021-12-11 21:17:19,949 iteration 4297 : loss : 0.015626, loss_ce: 0.005554
2021-12-11 21:17:21,439 iteration 4298 : loss : 0.025045, loss_ce: 0.007341
2021-12-11 21:17:23,058 iteration 4299 : loss : 0.035742, loss_ce: 0.016421
2021-12-11 21:17:24,645 iteration 4300 : loss : 0.026993, loss_ce: 0.008005
2021-12-11 21:17:26,164 iteration 4301 : loss : 0.018432, loss_ce: 0.006696
 63%|█████████████████          | 253/400 [2:00:00<1:08:02, 27.77s/it]2021-12-11 21:17:27,757 iteration 4302 : loss : 0.017914, loss_ce: 0.006628
2021-12-11 21:17:29,352 iteration 4303 : loss : 0.018886, loss_ce: 0.006130
2021-12-11 21:17:30,830 iteration 4304 : loss : 0.019496, loss_ce: 0.006409
2021-12-11 21:17:32,421 iteration 4305 : loss : 0.025120, loss_ce: 0.007793
2021-12-11 21:17:33,918 iteration 4306 : loss : 0.019341, loss_ce: 0.006160
2021-12-11 21:17:35,422 iteration 4307 : loss : 0.018664, loss_ce: 0.007061
2021-12-11 21:17:37,015 iteration 4308 : loss : 0.027942, loss_ce: 0.009149
2021-12-11 21:17:38,569 iteration 4309 : loss : 0.019078, loss_ce: 0.006095
2021-12-11 21:17:40,131 iteration 4310 : loss : 0.022818, loss_ce: 0.010520
2021-12-11 21:17:41,671 iteration 4311 : loss : 0.024780, loss_ce: 0.013619
2021-12-11 21:17:43,306 iteration 4312 : loss : 0.027303, loss_ce: 0.010024
2021-12-11 21:17:44,834 iteration 4313 : loss : 0.027728, loss_ce: 0.009814
2021-12-11 21:17:46,368 iteration 4314 : loss : 0.023470, loss_ce: 0.007703
2021-12-11 21:17:47,860 iteration 4315 : loss : 0.020342, loss_ce: 0.007089
2021-12-11 21:17:49,454 iteration 4316 : loss : 0.029261, loss_ce: 0.010920
2021-12-11 21:17:50,969 iteration 4317 : loss : 0.019750, loss_ce: 0.007520
2021-12-11 21:17:52,490 iteration 4318 : loss : 0.021122, loss_ce: 0.010050
 64%|█████████████████▏         | 254/400 [2:00:26<1:06:31, 27.34s/it]2021-12-11 21:17:54,119 iteration 4319 : loss : 0.026888, loss_ce: 0.009942
2021-12-11 21:17:55,711 iteration 4320 : loss : 0.023835, loss_ce: 0.009664
2021-12-11 21:17:57,317 iteration 4321 : loss : 0.022611, loss_ce: 0.010409
2021-12-11 21:17:58,873 iteration 4322 : loss : 0.031775, loss_ce: 0.009401
2021-12-11 21:18:00,376 iteration 4323 : loss : 0.016001, loss_ce: 0.005147
2021-12-11 21:18:01,945 iteration 4324 : loss : 0.028290, loss_ce: 0.010777
2021-12-11 21:18:03,590 iteration 4325 : loss : 0.028143, loss_ce: 0.007143
2021-12-11 21:18:05,128 iteration 4326 : loss : 0.023224, loss_ce: 0.012319
2021-12-11 21:18:06,638 iteration 4327 : loss : 0.019418, loss_ce: 0.007407
2021-12-11 21:18:08,152 iteration 4328 : loss : 0.027060, loss_ce: 0.009648
2021-12-11 21:18:09,776 iteration 4329 : loss : 0.026357, loss_ce: 0.010549
2021-12-11 21:18:11,273 iteration 4330 : loss : 0.015058, loss_ce: 0.005246
2021-12-11 21:18:12,939 iteration 4331 : loss : 0.053640, loss_ce: 0.015112
2021-12-11 21:18:14,520 iteration 4332 : loss : 0.029594, loss_ce: 0.013652
2021-12-11 21:18:15,987 iteration 4333 : loss : 0.025304, loss_ce: 0.007628
2021-12-11 21:18:17,480 iteration 4334 : loss : 0.017633, loss_ce: 0.006843
2021-12-11 21:18:17,480 Training Data Eval:
2021-12-11 21:18:25,145   Average segmentation loss on training set: 0.0250
2021-12-11 21:18:25,146 Validation Data Eval:
2021-12-11 21:18:27,793   Average segmentation loss on validation set: 0.1031
2021-12-11 21:18:29,410 iteration 4335 : loss : 0.024828, loss_ce: 0.012944
 64%|█████████████████▏         | 255/400 [2:01:03<1:13:01, 30.21s/it]2021-12-11 21:18:30,998 iteration 4336 : loss : 0.023243, loss_ce: 0.009006
2021-12-11 21:18:32,564 iteration 4337 : loss : 0.024328, loss_ce: 0.009681
2021-12-11 21:18:34,205 iteration 4338 : loss : 0.029514, loss_ce: 0.012381
2021-12-11 21:18:35,729 iteration 4339 : loss : 0.030251, loss_ce: 0.009059
2021-12-11 21:18:37,292 iteration 4340 : loss : 0.024138, loss_ce: 0.009321
2021-12-11 21:18:38,869 iteration 4341 : loss : 0.028284, loss_ce: 0.012294
2021-12-11 21:18:40,403 iteration 4342 : loss : 0.027921, loss_ce: 0.009197
2021-12-11 21:18:41,948 iteration 4343 : loss : 0.016440, loss_ce: 0.004531
2021-12-11 21:18:43,463 iteration 4344 : loss : 0.022098, loss_ce: 0.007515
2021-12-11 21:18:45,001 iteration 4345 : loss : 0.027120, loss_ce: 0.008167
2021-12-11 21:18:46,509 iteration 4346 : loss : 0.017765, loss_ce: 0.008326
2021-12-11 21:18:48,084 iteration 4347 : loss : 0.025705, loss_ce: 0.008523
2021-12-11 21:18:49,648 iteration 4348 : loss : 0.023858, loss_ce: 0.012112
2021-12-11 21:18:51,195 iteration 4349 : loss : 0.027653, loss_ce: 0.011096
2021-12-11 21:18:52,712 iteration 4350 : loss : 0.019079, loss_ce: 0.008581
2021-12-11 21:18:54,186 iteration 4351 : loss : 0.026379, loss_ce: 0.010863
2021-12-11 21:18:55,716 iteration 4352 : loss : 0.016063, loss_ce: 0.006026
 64%|█████████████████▎         | 256/400 [2:01:29<1:09:42, 29.04s/it]2021-12-11 21:18:57,317 iteration 4353 : loss : 0.016936, loss_ce: 0.006238
2021-12-11 21:18:58,940 iteration 4354 : loss : 0.032028, loss_ce: 0.008778
2021-12-11 21:19:00,433 iteration 4355 : loss : 0.018075, loss_ce: 0.006118
2021-12-11 21:19:02,005 iteration 4356 : loss : 0.023395, loss_ce: 0.011348
2021-12-11 21:19:03,560 iteration 4357 : loss : 0.022384, loss_ce: 0.009722
2021-12-11 21:19:05,068 iteration 4358 : loss : 0.021066, loss_ce: 0.008343
2021-12-11 21:19:06,590 iteration 4359 : loss : 0.015182, loss_ce: 0.005126
2021-12-11 21:19:08,112 iteration 4360 : loss : 0.022759, loss_ce: 0.007533
2021-12-11 21:19:09,724 iteration 4361 : loss : 0.025175, loss_ce: 0.011377
2021-12-11 21:19:11,217 iteration 4362 : loss : 0.017375, loss_ce: 0.005308
2021-12-11 21:19:12,672 iteration 4363 : loss : 0.021204, loss_ce: 0.010028
2021-12-11 21:19:14,269 iteration 4364 : loss : 0.021229, loss_ce: 0.008128
2021-12-11 21:19:15,804 iteration 4365 : loss : 0.019732, loss_ce: 0.007869
2021-12-11 21:19:17,243 iteration 4366 : loss : 0.017847, loss_ce: 0.007152
2021-12-11 21:19:18,765 iteration 4367 : loss : 0.031943, loss_ce: 0.010174
2021-12-11 21:19:20,380 iteration 4368 : loss : 0.022416, loss_ce: 0.008194
2021-12-11 21:19:21,854 iteration 4369 : loss : 0.024726, loss_ce: 0.006443
 64%|█████████████████▎         | 257/400 [2:01:55<1:07:08, 28.17s/it]2021-12-11 21:19:23,453 iteration 4370 : loss : 0.037525, loss_ce: 0.009967
2021-12-11 21:19:24,998 iteration 4371 : loss : 0.020972, loss_ce: 0.009027
2021-12-11 21:19:26,463 iteration 4372 : loss : 0.018363, loss_ce: 0.008294
2021-12-11 21:19:28,030 iteration 4373 : loss : 0.022266, loss_ce: 0.006467
2021-12-11 21:19:29,555 iteration 4374 : loss : 0.019302, loss_ce: 0.008611
2021-12-11 21:19:31,030 iteration 4375 : loss : 0.022295, loss_ce: 0.011072
2021-12-11 21:19:32,526 iteration 4376 : loss : 0.022549, loss_ce: 0.007689
2021-12-11 21:19:34,153 iteration 4377 : loss : 0.027042, loss_ce: 0.008561
2021-12-11 21:19:35,737 iteration 4378 : loss : 0.030929, loss_ce: 0.013768
2021-12-11 21:19:37,365 iteration 4379 : loss : 0.029888, loss_ce: 0.012479
2021-12-11 21:19:38,919 iteration 4380 : loss : 0.017193, loss_ce: 0.007540
2021-12-11 21:19:40,495 iteration 4381 : loss : 0.023187, loss_ce: 0.008245
2021-12-11 21:19:42,024 iteration 4382 : loss : 0.023921, loss_ce: 0.009951
2021-12-11 21:19:43,599 iteration 4383 : loss : 0.023428, loss_ce: 0.006132
2021-12-11 21:19:45,154 iteration 4384 : loss : 0.025836, loss_ce: 0.009011
2021-12-11 21:19:46,610 iteration 4385 : loss : 0.019764, loss_ce: 0.008212
2021-12-11 21:19:48,159 iteration 4386 : loss : 0.027853, loss_ce: 0.010908
 64%|█████████████████▍         | 258/400 [2:02:22<1:05:20, 27.61s/it]2021-12-11 21:19:49,725 iteration 4387 : loss : 0.018431, loss_ce: 0.006995
2021-12-11 21:19:51,294 iteration 4388 : loss : 0.021480, loss_ce: 0.008626
2021-12-11 21:19:52,764 iteration 4389 : loss : 0.017595, loss_ce: 0.007821
2021-12-11 21:19:54,235 iteration 4390 : loss : 0.022355, loss_ce: 0.008352
2021-12-11 21:19:55,762 iteration 4391 : loss : 0.020515, loss_ce: 0.008060
2021-12-11 21:19:57,335 iteration 4392 : loss : 0.023283, loss_ce: 0.010516
2021-12-11 21:19:58,825 iteration 4393 : loss : 0.020205, loss_ce: 0.006881
2021-12-11 21:20:00,473 iteration 4394 : loss : 0.026322, loss_ce: 0.010607
2021-12-11 21:20:02,044 iteration 4395 : loss : 0.020348, loss_ce: 0.007141
2021-12-11 21:20:03,632 iteration 4396 : loss : 0.025002, loss_ce: 0.007993
2021-12-11 21:20:05,166 iteration 4397 : loss : 0.030334, loss_ce: 0.010143
2021-12-11 21:20:06,674 iteration 4398 : loss : 0.027857, loss_ce: 0.008377
2021-12-11 21:20:08,197 iteration 4399 : loss : 0.018530, loss_ce: 0.005721
2021-12-11 21:20:09,700 iteration 4400 : loss : 0.017983, loss_ce: 0.006986
2021-12-11 21:20:11,208 iteration 4401 : loss : 0.023961, loss_ce: 0.011198
2021-12-11 21:20:12,680 iteration 4402 : loss : 0.018161, loss_ce: 0.005687
2021-12-11 21:20:14,222 iteration 4403 : loss : 0.024106, loss_ce: 0.007226
 65%|█████████████████▍         | 259/400 [2:02:48<1:03:47, 27.14s/it]2021-12-11 21:20:15,731 iteration 4404 : loss : 0.014681, loss_ce: 0.006902
2021-12-11 21:20:17,360 iteration 4405 : loss : 0.022051, loss_ce: 0.006026
2021-12-11 21:20:18,924 iteration 4406 : loss : 0.028453, loss_ce: 0.008861
2021-12-11 21:20:20,395 iteration 4407 : loss : 0.017930, loss_ce: 0.006606
2021-12-11 21:20:21,842 iteration 4408 : loss : 0.025523, loss_ce: 0.006465
2021-12-11 21:20:23,392 iteration 4409 : loss : 0.015189, loss_ce: 0.005907
2021-12-11 21:20:24,929 iteration 4410 : loss : 0.025611, loss_ce: 0.007840
2021-12-11 21:20:26,547 iteration 4411 : loss : 0.018936, loss_ce: 0.008500
2021-12-11 21:20:28,019 iteration 4412 : loss : 0.022765, loss_ce: 0.008628
2021-12-11 21:20:29,618 iteration 4413 : loss : 0.028084, loss_ce: 0.008040
2021-12-11 21:20:31,063 iteration 4414 : loss : 0.019067, loss_ce: 0.006499
2021-12-11 21:20:32,618 iteration 4415 : loss : 0.027894, loss_ce: 0.011811
2021-12-11 21:20:34,123 iteration 4416 : loss : 0.023628, loss_ce: 0.005921
2021-12-11 21:20:35,649 iteration 4417 : loss : 0.021231, loss_ce: 0.007444
2021-12-11 21:20:37,200 iteration 4418 : loss : 0.024424, loss_ce: 0.010682
2021-12-11 21:20:38,762 iteration 4419 : loss : 0.026785, loss_ce: 0.008634
2021-12-11 21:20:38,763 Training Data Eval:
2021-12-11 21:20:46,411   Average segmentation loss on training set: 0.0149
2021-12-11 21:20:46,412 Validation Data Eval:
2021-12-11 21:20:49,053   Average segmentation loss on validation set: 0.0823
2021-12-11 21:20:50,540 iteration 4420 : loss : 0.018994, loss_ce: 0.007516
 65%|█████████████████▌         | 260/400 [2:03:24<1:09:45, 29.90s/it]2021-12-11 21:20:52,143 iteration 4421 : loss : 0.020062, loss_ce: 0.006349
2021-12-11 21:20:53,743 iteration 4422 : loss : 0.025457, loss_ce: 0.009036
2021-12-11 21:20:55,390 iteration 4423 : loss : 0.023832, loss_ce: 0.009577
2021-12-11 21:20:56,995 iteration 4424 : loss : 0.029052, loss_ce: 0.010383
2021-12-11 21:20:58,484 iteration 4425 : loss : 0.016379, loss_ce: 0.005601
2021-12-11 21:21:00,067 iteration 4426 : loss : 0.020048, loss_ce: 0.007669
2021-12-11 21:21:01,676 iteration 4427 : loss : 0.031330, loss_ce: 0.008585
2021-12-11 21:21:03,318 iteration 4428 : loss : 0.027455, loss_ce: 0.009449
2021-12-11 21:21:04,923 iteration 4429 : loss : 0.043762, loss_ce: 0.017439
2021-12-11 21:21:06,449 iteration 4430 : loss : 0.030050, loss_ce: 0.011019
2021-12-11 21:21:07,958 iteration 4431 : loss : 0.022032, loss_ce: 0.009787
2021-12-11 21:21:09,482 iteration 4432 : loss : 0.016738, loss_ce: 0.006640
2021-12-11 21:21:10,997 iteration 4433 : loss : 0.019553, loss_ce: 0.007765
2021-12-11 21:21:12,520 iteration 4434 : loss : 0.018192, loss_ce: 0.006435
2021-12-11 21:21:14,085 iteration 4435 : loss : 0.028995, loss_ce: 0.010450
2021-12-11 21:21:15,744 iteration 4436 : loss : 0.032191, loss_ce: 0.013549
2021-12-11 21:21:17,227 iteration 4437 : loss : 0.023162, loss_ce: 0.008624
 65%|█████████████████▌         | 261/400 [2:03:51<1:07:01, 28.93s/it]2021-12-11 21:21:18,863 iteration 4438 : loss : 0.026325, loss_ce: 0.008911
2021-12-11 21:21:20,368 iteration 4439 : loss : 0.032480, loss_ce: 0.010539
2021-12-11 21:21:21,953 iteration 4440 : loss : 0.025129, loss_ce: 0.008886
2021-12-11 21:21:23,520 iteration 4441 : loss : 0.022381, loss_ce: 0.009398
2021-12-11 21:21:25,004 iteration 4442 : loss : 0.016519, loss_ce: 0.007086
2021-12-11 21:21:26,551 iteration 4443 : loss : 0.026411, loss_ce: 0.010593
2021-12-11 21:21:28,058 iteration 4444 : loss : 0.023941, loss_ce: 0.007899
2021-12-11 21:21:29,609 iteration 4445 : loss : 0.018078, loss_ce: 0.006975
2021-12-11 21:21:31,178 iteration 4446 : loss : 0.021981, loss_ce: 0.008889
2021-12-11 21:21:32,788 iteration 4447 : loss : 0.022551, loss_ce: 0.008392
2021-12-11 21:21:34,316 iteration 4448 : loss : 0.027486, loss_ce: 0.006168
2021-12-11 21:21:35,865 iteration 4449 : loss : 0.020048, loss_ce: 0.009527
2021-12-11 21:21:37,464 iteration 4450 : loss : 0.025997, loss_ce: 0.010205
2021-12-11 21:21:38,936 iteration 4451 : loss : 0.022119, loss_ce: 0.007821
2021-12-11 21:21:40,489 iteration 4452 : loss : 0.024708, loss_ce: 0.010301
2021-12-11 21:21:42,109 iteration 4453 : loss : 0.025583, loss_ce: 0.008701
2021-12-11 21:21:43,675 iteration 4454 : loss : 0.026971, loss_ce: 0.012603
 66%|█████████████████▋         | 262/400 [2:04:17<1:04:50, 28.19s/it]2021-12-11 21:21:45,314 iteration 4455 : loss : 0.020205, loss_ce: 0.007541
2021-12-11 21:21:46,844 iteration 4456 : loss : 0.021871, loss_ce: 0.009433
2021-12-11 21:21:48,291 iteration 4457 : loss : 0.016277, loss_ce: 0.007493
2021-12-11 21:21:49,856 iteration 4458 : loss : 0.026822, loss_ce: 0.012054
2021-12-11 21:21:51,369 iteration 4459 : loss : 0.017341, loss_ce: 0.006693
2021-12-11 21:21:52,906 iteration 4460 : loss : 0.017020, loss_ce: 0.005761
2021-12-11 21:21:54,390 iteration 4461 : loss : 0.021194, loss_ce: 0.009411
2021-12-11 21:21:55,883 iteration 4462 : loss : 0.035228, loss_ce: 0.014431
2021-12-11 21:21:57,378 iteration 4463 : loss : 0.018446, loss_ce: 0.006430
2021-12-11 21:21:58,862 iteration 4464 : loss : 0.019361, loss_ce: 0.007094
2021-12-11 21:22:00,426 iteration 4465 : loss : 0.023335, loss_ce: 0.009164
2021-12-11 21:22:01,989 iteration 4466 : loss : 0.033623, loss_ce: 0.011607
2021-12-11 21:22:03,516 iteration 4467 : loss : 0.016841, loss_ce: 0.006069
2021-12-11 21:22:05,031 iteration 4468 : loss : 0.019004, loss_ce: 0.006268
2021-12-11 21:22:06,541 iteration 4469 : loss : 0.027613, loss_ce: 0.007123
2021-12-11 21:22:08,119 iteration 4470 : loss : 0.030698, loss_ce: 0.010545
2021-12-11 21:22:09,696 iteration 4471 : loss : 0.019928, loss_ce: 0.006638
 66%|█████████████████▊         | 263/400 [2:04:43<1:02:52, 27.54s/it]2021-12-11 21:22:11,235 iteration 4472 : loss : 0.021459, loss_ce: 0.009059
2021-12-11 21:22:12,758 iteration 4473 : loss : 0.020109, loss_ce: 0.008787
2021-12-11 21:22:14,317 iteration 4474 : loss : 0.019579, loss_ce: 0.006696
2021-12-11 21:22:15,813 iteration 4475 : loss : 0.017800, loss_ce: 0.007236
2021-12-11 21:22:17,259 iteration 4476 : loss : 0.018071, loss_ce: 0.005728
2021-12-11 21:22:18,797 iteration 4477 : loss : 0.020922, loss_ce: 0.008224
2021-12-11 21:22:20,335 iteration 4478 : loss : 0.026322, loss_ce: 0.008650
2021-12-11 21:22:21,866 iteration 4479 : loss : 0.028288, loss_ce: 0.007474
2021-12-11 21:22:23,364 iteration 4480 : loss : 0.015164, loss_ce: 0.006122
2021-12-11 21:22:24,850 iteration 4481 : loss : 0.018217, loss_ce: 0.007328
2021-12-11 21:22:26,449 iteration 4482 : loss : 0.023484, loss_ce: 0.007685
2021-12-11 21:22:28,076 iteration 4483 : loss : 0.032212, loss_ce: 0.013088
2021-12-11 21:22:29,667 iteration 4484 : loss : 0.030441, loss_ce: 0.009722
2021-12-11 21:22:31,177 iteration 4485 : loss : 0.017218, loss_ce: 0.004969
2021-12-11 21:22:32,832 iteration 4486 : loss : 0.034311, loss_ce: 0.014343
2021-12-11 21:22:34,336 iteration 4487 : loss : 0.020563, loss_ce: 0.008863
2021-12-11 21:22:35,905 iteration 4488 : loss : 0.018984, loss_ce: 0.007846
 66%|█████████████████▊         | 264/400 [2:05:10<1:01:31, 27.14s/it]2021-12-11 21:22:37,511 iteration 4489 : loss : 0.027239, loss_ce: 0.010746
2021-12-11 21:22:39,046 iteration 4490 : loss : 0.019087, loss_ce: 0.006812
2021-12-11 21:22:40,694 iteration 4491 : loss : 0.027720, loss_ce: 0.010792
2021-12-11 21:22:42,262 iteration 4492 : loss : 0.023484, loss_ce: 0.008540
2021-12-11 21:22:43,870 iteration 4493 : loss : 0.024995, loss_ce: 0.008456
2021-12-11 21:22:45,320 iteration 4494 : loss : 0.018772, loss_ce: 0.006981
2021-12-11 21:22:46,878 iteration 4495 : loss : 0.024382, loss_ce: 0.011377
2021-12-11 21:22:48,452 iteration 4496 : loss : 0.027049, loss_ce: 0.008368
2021-12-11 21:22:49,917 iteration 4497 : loss : 0.017008, loss_ce: 0.004674
2021-12-11 21:22:51,540 iteration 4498 : loss : 0.025065, loss_ce: 0.010910
2021-12-11 21:22:53,192 iteration 4499 : loss : 0.039860, loss_ce: 0.020161
2021-12-11 21:22:54,763 iteration 4500 : loss : 0.021041, loss_ce: 0.008904
2021-12-11 21:22:56,254 iteration 4501 : loss : 0.025926, loss_ce: 0.010206
2021-12-11 21:22:57,734 iteration 4502 : loss : 0.021217, loss_ce: 0.008155
2021-12-11 21:22:59,334 iteration 4503 : loss : 0.020869, loss_ce: 0.008361
2021-12-11 21:23:00,881 iteration 4504 : loss : 0.021696, loss_ce: 0.007519
2021-12-11 21:23:00,881 Training Data Eval:
2021-12-11 21:23:08,530   Average segmentation loss on training set: 0.0139
2021-12-11 21:23:08,531 Validation Data Eval:
2021-12-11 21:23:11,176   Average segmentation loss on validation set: 0.0797
2021-12-11 21:23:12,638 iteration 4505 : loss : 0.017362, loss_ce: 0.007142
 66%|█████████████████▉         | 265/400 [2:05:46<1:07:32, 30.02s/it]2021-12-11 21:23:14,267 iteration 4506 : loss : 0.027245, loss_ce: 0.008760
2021-12-11 21:23:15,775 iteration 4507 : loss : 0.014039, loss_ce: 0.004514
2021-12-11 21:23:17,369 iteration 4508 : loss : 0.032174, loss_ce: 0.009206
2021-12-11 21:23:18,938 iteration 4509 : loss : 0.021798, loss_ce: 0.007374
2021-12-11 21:23:20,482 iteration 4510 : loss : 0.018197, loss_ce: 0.007326
2021-12-11 21:23:21,992 iteration 4511 : loss : 0.020855, loss_ce: 0.007089
2021-12-11 21:23:23,519 iteration 4512 : loss : 0.014501, loss_ce: 0.005700
2021-12-11 21:23:25,077 iteration 4513 : loss : 0.032051, loss_ce: 0.017623
2021-12-11 21:23:26,548 iteration 4514 : loss : 0.018968, loss_ce: 0.006800
2021-12-11 21:23:28,064 iteration 4515 : loss : 0.024160, loss_ce: 0.008394
2021-12-11 21:23:29,711 iteration 4516 : loss : 0.023762, loss_ce: 0.009597
2021-12-11 21:23:31,246 iteration 4517 : loss : 0.021275, loss_ce: 0.006949
2021-12-11 21:23:32,814 iteration 4518 : loss : 0.020515, loss_ce: 0.006384
2021-12-11 21:23:34,369 iteration 4519 : loss : 0.022313, loss_ce: 0.009982
2021-12-11 21:23:35,854 iteration 4520 : loss : 0.017872, loss_ce: 0.006043
2021-12-11 21:23:37,418 iteration 4521 : loss : 0.026629, loss_ce: 0.008891
2021-12-11 21:23:38,930 iteration 4522 : loss : 0.019316, loss_ce: 0.008575
 66%|█████████████████▉         | 266/400 [2:06:13<1:04:32, 28.90s/it]2021-12-11 21:23:40,611 iteration 4523 : loss : 0.018745, loss_ce: 0.006827
2021-12-11 21:23:42,080 iteration 4524 : loss : 0.015124, loss_ce: 0.006024
2021-12-11 21:23:43,694 iteration 4525 : loss : 0.026928, loss_ce: 0.006940
2021-12-11 21:23:45,246 iteration 4526 : loss : 0.019937, loss_ce: 0.008596
2021-12-11 21:23:46,796 iteration 4527 : loss : 0.024633, loss_ce: 0.010864
2021-12-11 21:23:48,390 iteration 4528 : loss : 0.019122, loss_ce: 0.007176
2021-12-11 21:23:49,913 iteration 4529 : loss : 0.022486, loss_ce: 0.010464
2021-12-11 21:23:51,474 iteration 4530 : loss : 0.021193, loss_ce: 0.008508
2021-12-11 21:23:52,970 iteration 4531 : loss : 0.018349, loss_ce: 0.008093
2021-12-11 21:23:54,552 iteration 4532 : loss : 0.023451, loss_ce: 0.009938
2021-12-11 21:23:56,160 iteration 4533 : loss : 0.030388, loss_ce: 0.011513
2021-12-11 21:23:57,835 iteration 4534 : loss : 0.021074, loss_ce: 0.007767
2021-12-11 21:23:59,303 iteration 4535 : loss : 0.018065, loss_ce: 0.005805
2021-12-11 21:24:00,860 iteration 4536 : loss : 0.025107, loss_ce: 0.013396
2021-12-11 21:24:02,470 iteration 4537 : loss : 0.026058, loss_ce: 0.009321
2021-12-11 21:24:03,997 iteration 4538 : loss : 0.020874, loss_ce: 0.006932
2021-12-11 21:24:05,563 iteration 4539 : loss : 0.023308, loss_ce: 0.008291
 67%|██████████████████         | 267/400 [2:06:39<1:02:33, 28.22s/it]2021-12-11 21:24:07,189 iteration 4540 : loss : 0.032345, loss_ce: 0.010112
2021-12-11 21:24:08,651 iteration 4541 : loss : 0.018669, loss_ce: 0.006617
2021-12-11 21:24:10,240 iteration 4542 : loss : 0.018776, loss_ce: 0.004892
2021-12-11 21:24:11,690 iteration 4543 : loss : 0.018894, loss_ce: 0.007058
2021-12-11 21:24:13,258 iteration 4544 : loss : 0.022272, loss_ce: 0.009571
2021-12-11 21:24:14,866 iteration 4545 : loss : 0.028716, loss_ce: 0.013644
2021-12-11 21:24:16,432 iteration 4546 : loss : 0.021186, loss_ce: 0.007574
2021-12-11 21:24:17,988 iteration 4547 : loss : 0.017827, loss_ce: 0.008203
2021-12-11 21:24:19,527 iteration 4548 : loss : 0.031158, loss_ce: 0.016053
2021-12-11 21:24:21,147 iteration 4549 : loss : 0.025503, loss_ce: 0.010251
2021-12-11 21:24:22,761 iteration 4550 : loss : 0.024614, loss_ce: 0.008540
2021-12-11 21:24:24,358 iteration 4551 : loss : 0.034914, loss_ce: 0.007763
2021-12-11 21:24:25,812 iteration 4552 : loss : 0.015939, loss_ce: 0.006319
2021-12-11 21:24:27,288 iteration 4553 : loss : 0.029458, loss_ce: 0.010291
2021-12-11 21:24:28,845 iteration 4554 : loss : 0.018255, loss_ce: 0.007456
2021-12-11 21:24:30,442 iteration 4555 : loss : 0.030499, loss_ce: 0.011882
2021-12-11 21:24:31,967 iteration 4556 : loss : 0.019757, loss_ce: 0.008797
 67%|██████████████████         | 268/400 [2:07:06<1:00:53, 27.67s/it]2021-12-11 21:24:33,582 iteration 4557 : loss : 0.020247, loss_ce: 0.009136
2021-12-11 21:24:35,192 iteration 4558 : loss : 0.029502, loss_ce: 0.014122
2021-12-11 21:24:36,719 iteration 4559 : loss : 0.029030, loss_ce: 0.008916
2021-12-11 21:24:38,235 iteration 4560 : loss : 0.016344, loss_ce: 0.004484
2021-12-11 21:24:39,770 iteration 4561 : loss : 0.022104, loss_ce: 0.005933
2021-12-11 21:24:41,322 iteration 4562 : loss : 0.023234, loss_ce: 0.008140
2021-12-11 21:24:42,808 iteration 4563 : loss : 0.019759, loss_ce: 0.007275
2021-12-11 21:24:44,353 iteration 4564 : loss : 0.040589, loss_ce: 0.013683
2021-12-11 21:24:45,854 iteration 4565 : loss : 0.019352, loss_ce: 0.007654
2021-12-11 21:24:47,330 iteration 4566 : loss : 0.019677, loss_ce: 0.009353
2021-12-11 21:24:48,874 iteration 4567 : loss : 0.021416, loss_ce: 0.008272
2021-12-11 21:24:50,391 iteration 4568 : loss : 0.020084, loss_ce: 0.005949
2021-12-11 21:24:51,936 iteration 4569 : loss : 0.022463, loss_ce: 0.010310
2021-12-11 21:24:53,414 iteration 4570 : loss : 0.019981, loss_ce: 0.008048
2021-12-11 21:24:54,925 iteration 4571 : loss : 0.020411, loss_ce: 0.011049
2021-12-11 21:24:56,439 iteration 4572 : loss : 0.020077, loss_ce: 0.005783
2021-12-11 21:24:58,031 iteration 4573 : loss : 0.023645, loss_ce: 0.010428
 67%|███████████████████▌         | 269/400 [2:07:32<59:22, 27.19s/it]2021-12-11 21:24:59,595 iteration 4574 : loss : 0.021716, loss_ce: 0.005863
2021-12-11 21:25:01,095 iteration 4575 : loss : 0.016698, loss_ce: 0.006160
2021-12-11 21:25:02,665 iteration 4576 : loss : 0.023083, loss_ce: 0.011536
2021-12-11 21:25:04,257 iteration 4577 : loss : 0.024661, loss_ce: 0.008780
2021-12-11 21:25:05,809 iteration 4578 : loss : 0.030100, loss_ce: 0.015492
2021-12-11 21:25:07,340 iteration 4579 : loss : 0.021471, loss_ce: 0.009948
2021-12-11 21:25:08,864 iteration 4580 : loss : 0.018335, loss_ce: 0.007654
2021-12-11 21:25:10,499 iteration 4581 : loss : 0.020197, loss_ce: 0.006274
2021-12-11 21:25:12,049 iteration 4582 : loss : 0.018513, loss_ce: 0.008035
2021-12-11 21:25:13,593 iteration 4583 : loss : 0.017429, loss_ce: 0.006626
2021-12-11 21:25:15,121 iteration 4584 : loss : 0.023855, loss_ce: 0.009077
2021-12-11 21:25:16,684 iteration 4585 : loss : 0.022742, loss_ce: 0.007723
2021-12-11 21:25:18,195 iteration 4586 : loss : 0.017724, loss_ce: 0.007929
2021-12-11 21:25:19,822 iteration 4587 : loss : 0.023233, loss_ce: 0.007344
2021-12-11 21:25:21,329 iteration 4588 : loss : 0.017636, loss_ce: 0.004410
2021-12-11 21:25:22,865 iteration 4589 : loss : 0.020460, loss_ce: 0.008725
2021-12-11 21:25:22,865 Training Data Eval:
2021-12-11 21:25:30,533   Average segmentation loss on training set: 0.0152
2021-12-11 21:25:30,534 Validation Data Eval:
2021-12-11 21:25:33,182   Average segmentation loss on validation set: 0.0948
2021-12-11 21:25:34,852 iteration 4590 : loss : 0.025503, loss_ce: 0.007948
 68%|██████████████████▏        | 270/400 [2:08:08<1:05:10, 30.08s/it]2021-12-11 21:25:36,362 iteration 4591 : loss : 0.017315, loss_ce: 0.004638
2021-12-11 21:25:37,901 iteration 4592 : loss : 0.021043, loss_ce: 0.007091
2021-12-11 21:25:39,354 iteration 4593 : loss : 0.017858, loss_ce: 0.005007
2021-12-11 21:25:40,865 iteration 4594 : loss : 0.035835, loss_ce: 0.018138
2021-12-11 21:25:42,423 iteration 4595 : loss : 0.024278, loss_ce: 0.004736
2021-12-11 21:25:44,049 iteration 4596 : loss : 0.023354, loss_ce: 0.007869
2021-12-11 21:25:45,578 iteration 4597 : loss : 0.019390, loss_ce: 0.008293
2021-12-11 21:25:47,037 iteration 4598 : loss : 0.019389, loss_ce: 0.007872
2021-12-11 21:25:48,531 iteration 4599 : loss : 0.020669, loss_ce: 0.005054
2021-12-11 21:25:50,135 iteration 4600 : loss : 0.017520, loss_ce: 0.008006
2021-12-11 21:25:51,783 iteration 4601 : loss : 0.021447, loss_ce: 0.010867
2021-12-11 21:25:53,231 iteration 4602 : loss : 0.017281, loss_ce: 0.006361
2021-12-11 21:25:54,706 iteration 4603 : loss : 0.017638, loss_ce: 0.007402
2021-12-11 21:25:56,273 iteration 4604 : loss : 0.031930, loss_ce: 0.009435
2021-12-11 21:25:57,827 iteration 4605 : loss : 0.023874, loss_ce: 0.006142
2021-12-11 21:25:59,425 iteration 4606 : loss : 0.021317, loss_ce: 0.006498
2021-12-11 21:26:00,929 iteration 4607 : loss : 0.017139, loss_ce: 0.008660
 68%|██████████████████▎        | 271/400 [2:08:35<1:02:05, 28.88s/it]2021-12-11 21:26:02,544 iteration 4608 : loss : 0.021074, loss_ce: 0.006045
2021-12-11 21:26:04,146 iteration 4609 : loss : 0.023960, loss_ce: 0.010500
2021-12-11 21:26:05,722 iteration 4610 : loss : 0.025415, loss_ce: 0.006126
2021-12-11 21:26:07,256 iteration 4611 : loss : 0.019113, loss_ce: 0.007819
2021-12-11 21:26:08,722 iteration 4612 : loss : 0.016414, loss_ce: 0.006000
2021-12-11 21:26:10,276 iteration 4613 : loss : 0.020405, loss_ce: 0.008463
2021-12-11 21:26:11,853 iteration 4614 : loss : 0.021391, loss_ce: 0.008103
2021-12-11 21:26:13,423 iteration 4615 : loss : 0.030758, loss_ce: 0.010394
2021-12-11 21:26:15,033 iteration 4616 : loss : 0.020511, loss_ce: 0.006672
2021-12-11 21:26:16,506 iteration 4617 : loss : 0.019375, loss_ce: 0.008293
2021-12-11 21:26:18,081 iteration 4618 : loss : 0.025040, loss_ce: 0.009672
2021-12-11 21:26:19,667 iteration 4619 : loss : 0.021349, loss_ce: 0.007146
2021-12-11 21:26:21,253 iteration 4620 : loss : 0.022697, loss_ce: 0.007773
2021-12-11 21:26:22,858 iteration 4621 : loss : 0.028009, loss_ce: 0.010204
2021-12-11 21:26:24,397 iteration 4622 : loss : 0.021491, loss_ce: 0.007214
2021-12-11 21:26:25,912 iteration 4623 : loss : 0.023192, loss_ce: 0.007667
2021-12-11 21:26:27,444 iteration 4624 : loss : 0.019099, loss_ce: 0.007673
 68%|██████████████████▎        | 272/400 [2:09:01<1:00:05, 28.17s/it]2021-12-11 21:26:29,017 iteration 4625 : loss : 0.018710, loss_ce: 0.007890
2021-12-11 21:26:30,519 iteration 4626 : loss : 0.015605, loss_ce: 0.004848
2021-12-11 21:26:32,090 iteration 4627 : loss : 0.014913, loss_ce: 0.004763
2021-12-11 21:26:33,577 iteration 4628 : loss : 0.022765, loss_ce: 0.008254
2021-12-11 21:26:35,066 iteration 4629 : loss : 0.018229, loss_ce: 0.007156
2021-12-11 21:26:36,583 iteration 4630 : loss : 0.019295, loss_ce: 0.006474
2021-12-11 21:26:38,204 iteration 4631 : loss : 0.019117, loss_ce: 0.007424
2021-12-11 21:26:39,744 iteration 4632 : loss : 0.014927, loss_ce: 0.004469
2021-12-11 21:26:41,290 iteration 4633 : loss : 0.022366, loss_ce: 0.009290
2021-12-11 21:26:42,736 iteration 4634 : loss : 0.016857, loss_ce: 0.007474
2021-12-11 21:26:44,304 iteration 4635 : loss : 0.021511, loss_ce: 0.006777
2021-12-11 21:26:45,850 iteration 4636 : loss : 0.023308, loss_ce: 0.009912
2021-12-11 21:26:47,404 iteration 4637 : loss : 0.018792, loss_ce: 0.006362
2021-12-11 21:26:49,015 iteration 4638 : loss : 0.022867, loss_ce: 0.010135
2021-12-11 21:26:50,642 iteration 4639 : loss : 0.023978, loss_ce: 0.007191
2021-12-11 21:26:52,219 iteration 4640 : loss : 0.021804, loss_ce: 0.009114
2021-12-11 21:26:53,736 iteration 4641 : loss : 0.015640, loss_ce: 0.006100
 68%|███████████████████▊         | 273/400 [2:09:27<58:26, 27.61s/it]2021-12-11 21:26:55,369 iteration 4642 : loss : 0.021305, loss_ce: 0.006759
2021-12-11 21:26:56,943 iteration 4643 : loss : 0.028804, loss_ce: 0.011426
2021-12-11 21:26:58,521 iteration 4644 : loss : 0.024859, loss_ce: 0.012714
2021-12-11 21:27:00,219 iteration 4645 : loss : 0.019193, loss_ce: 0.007889
2021-12-11 21:27:01,734 iteration 4646 : loss : 0.017594, loss_ce: 0.007493
2021-12-11 21:27:03,249 iteration 4647 : loss : 0.018065, loss_ce: 0.006784
2021-12-11 21:27:04,697 iteration 4648 : loss : 0.016986, loss_ce: 0.006352
2021-12-11 21:27:06,248 iteration 4649 : loss : 0.026178, loss_ce: 0.010360
2021-12-11 21:27:07,771 iteration 4650 : loss : 0.019628, loss_ce: 0.006533
2021-12-11 21:27:09,326 iteration 4651 : loss : 0.022413, loss_ce: 0.008737
2021-12-11 21:27:10,876 iteration 4652 : loss : 0.019900, loss_ce: 0.008150
2021-12-11 21:27:12,421 iteration 4653 : loss : 0.021912, loss_ce: 0.007737
2021-12-11 21:27:13,968 iteration 4654 : loss : 0.019129, loss_ce: 0.008316
2021-12-11 21:27:15,525 iteration 4655 : loss : 0.022834, loss_ce: 0.006937
2021-12-11 21:27:17,137 iteration 4656 : loss : 0.049912, loss_ce: 0.011316
2021-12-11 21:27:18,712 iteration 4657 : loss : 0.074507, loss_ce: 0.007113
2021-12-11 21:27:20,208 iteration 4658 : loss : 0.043150, loss_ce: 0.011169
 68%|███████████████████▊         | 274/400 [2:09:54<57:15, 27.27s/it]2021-12-11 21:27:21,779 iteration 4659 : loss : 0.018601, loss_ce: 0.006161
2021-12-11 21:27:23,349 iteration 4660 : loss : 0.022301, loss_ce: 0.004987
2021-12-11 21:27:24,907 iteration 4661 : loss : 0.024771, loss_ce: 0.013430
2021-12-11 21:27:26,568 iteration 4662 : loss : 0.033329, loss_ce: 0.017730
2021-12-11 21:27:28,040 iteration 4663 : loss : 0.027727, loss_ce: 0.007548
2021-12-11 21:27:29,599 iteration 4664 : loss : 0.020703, loss_ce: 0.006440
2021-12-11 21:27:31,284 iteration 4665 : loss : 0.037591, loss_ce: 0.014463
2021-12-11 21:27:32,766 iteration 4666 : loss : 0.016805, loss_ce: 0.006473
2021-12-11 21:27:34,299 iteration 4667 : loss : 0.026535, loss_ce: 0.010745
2021-12-11 21:27:35,822 iteration 4668 : loss : 0.026879, loss_ce: 0.006209
2021-12-11 21:27:37,471 iteration 4669 : loss : 0.023269, loss_ce: 0.008293
2021-12-11 21:27:39,088 iteration 4670 : loss : 0.021743, loss_ce: 0.009186
2021-12-11 21:27:40,551 iteration 4671 : loss : 0.021390, loss_ce: 0.007008
2021-12-11 21:27:42,221 iteration 4672 : loss : 0.032901, loss_ce: 0.012738
2021-12-11 21:27:43,796 iteration 4673 : loss : 0.026136, loss_ce: 0.008093
2021-12-11 21:27:45,411 iteration 4674 : loss : 0.027646, loss_ce: 0.014102
2021-12-11 21:27:45,412 Training Data Eval:
2021-12-11 21:27:53,061   Average segmentation loss on training set: 0.0170
2021-12-11 21:27:53,061 Validation Data Eval:
2021-12-11 21:27:55,698   Average segmentation loss on validation set: 0.0810
2021-12-11 21:27:57,215 iteration 4675 : loss : 0.021148, loss_ce: 0.008012
 69%|██████████████████▌        | 275/400 [2:10:31<1:02:53, 30.19s/it]2021-12-11 21:27:58,873 iteration 4676 : loss : 0.022949, loss_ce: 0.007795
2021-12-11 21:28:00,400 iteration 4677 : loss : 0.019196, loss_ce: 0.007066
2021-12-11 21:28:01,931 iteration 4678 : loss : 0.031694, loss_ce: 0.009996
2021-12-11 21:28:03,485 iteration 4679 : loss : 0.023043, loss_ce: 0.011595
2021-12-11 21:28:04,989 iteration 4680 : loss : 0.020244, loss_ce: 0.006696
2021-12-11 21:28:06,585 iteration 4681 : loss : 0.024689, loss_ce: 0.007769
2021-12-11 21:28:08,067 iteration 4682 : loss : 0.021578, loss_ce: 0.004830
2021-12-11 21:28:09,606 iteration 4683 : loss : 0.024608, loss_ce: 0.010186
2021-12-11 21:28:11,195 iteration 4684 : loss : 0.020502, loss_ce: 0.009358
2021-12-11 21:28:12,748 iteration 4685 : loss : 0.020134, loss_ce: 0.008053
2021-12-11 21:28:14,204 iteration 4686 : loss : 0.016085, loss_ce: 0.005625
2021-12-11 21:28:15,795 iteration 4687 : loss : 0.021757, loss_ce: 0.010988
2021-12-11 21:28:17,411 iteration 4688 : loss : 0.027726, loss_ce: 0.009222
2021-12-11 21:28:19,036 iteration 4689 : loss : 0.024496, loss_ce: 0.009879
2021-12-11 21:28:20,561 iteration 4690 : loss : 0.019453, loss_ce: 0.005181
2021-12-11 21:28:22,055 iteration 4691 : loss : 0.021901, loss_ce: 0.007183
2021-12-11 21:28:23,642 iteration 4692 : loss : 0.019590, loss_ce: 0.007961
 69%|██████████████████▋        | 276/400 [2:10:57<1:00:03, 29.06s/it]2021-12-11 21:28:25,255 iteration 4693 : loss : 0.031283, loss_ce: 0.010974
2021-12-11 21:28:26,767 iteration 4694 : loss : 0.018566, loss_ce: 0.005186
2021-12-11 21:28:28,370 iteration 4695 : loss : 0.029424, loss_ce: 0.013120
2021-12-11 21:28:29,933 iteration 4696 : loss : 0.023190, loss_ce: 0.008897
2021-12-11 21:28:31,535 iteration 4697 : loss : 0.023051, loss_ce: 0.010383
2021-12-11 21:28:32,979 iteration 4698 : loss : 0.020232, loss_ce: 0.007353
2021-12-11 21:28:34,519 iteration 4699 : loss : 0.022676, loss_ce: 0.007897
2021-12-11 21:28:36,068 iteration 4700 : loss : 0.034197, loss_ce: 0.011391
2021-12-11 21:28:37,628 iteration 4701 : loss : 0.024846, loss_ce: 0.010241
2021-12-11 21:28:39,090 iteration 4702 : loss : 0.022138, loss_ce: 0.008314
2021-12-11 21:28:40,667 iteration 4703 : loss : 0.022942, loss_ce: 0.009380
2021-12-11 21:28:42,218 iteration 4704 : loss : 0.032055, loss_ce: 0.008056
2021-12-11 21:28:43,700 iteration 4705 : loss : 0.015587, loss_ce: 0.005422
2021-12-11 21:28:45,205 iteration 4706 : loss : 0.019242, loss_ce: 0.007961
2021-12-11 21:28:46,811 iteration 4707 : loss : 0.019193, loss_ce: 0.007508
2021-12-11 21:28:48,334 iteration 4708 : loss : 0.025830, loss_ce: 0.006107
2021-12-11 21:28:49,856 iteration 4709 : loss : 0.019470, loss_ce: 0.007026
 69%|████████████████████         | 277/400 [2:11:23<57:49, 28.20s/it]2021-12-11 21:28:51,510 iteration 4710 : loss : 0.034171, loss_ce: 0.011605
2021-12-11 21:28:53,049 iteration 4711 : loss : 0.020953, loss_ce: 0.009076
2021-12-11 21:28:54,599 iteration 4712 : loss : 0.019448, loss_ce: 0.007960
2021-12-11 21:28:56,099 iteration 4713 : loss : 0.016613, loss_ce: 0.005822
2021-12-11 21:28:57,592 iteration 4714 : loss : 0.016224, loss_ce: 0.006788
2021-12-11 21:28:59,211 iteration 4715 : loss : 0.030523, loss_ce: 0.010689
2021-12-11 21:29:00,757 iteration 4716 : loss : 0.017812, loss_ce: 0.007098
2021-12-11 21:29:02,295 iteration 4717 : loss : 0.032024, loss_ce: 0.011562
2021-12-11 21:29:03,832 iteration 4718 : loss : 0.014562, loss_ce: 0.004933
2021-12-11 21:29:05,335 iteration 4719 : loss : 0.016298, loss_ce: 0.005551
2021-12-11 21:29:06,945 iteration 4720 : loss : 0.024558, loss_ce: 0.011054
2021-12-11 21:29:08,478 iteration 4721 : loss : 0.019359, loss_ce: 0.006071
2021-12-11 21:29:10,011 iteration 4722 : loss : 0.019815, loss_ce: 0.008183
2021-12-11 21:29:11,630 iteration 4723 : loss : 0.028809, loss_ce: 0.008007
2021-12-11 21:29:13,108 iteration 4724 : loss : 0.019285, loss_ce: 0.009503
2021-12-11 21:29:14,627 iteration 4725 : loss : 0.022024, loss_ce: 0.008205
2021-12-11 21:29:16,121 iteration 4726 : loss : 0.022968, loss_ce: 0.007592
 70%|████████████████████▏        | 278/400 [2:11:50<56:10, 27.62s/it]2021-12-11 21:29:17,693 iteration 4727 : loss : 0.020380, loss_ce: 0.007099
2021-12-11 21:29:19,250 iteration 4728 : loss : 0.027459, loss_ce: 0.012003
2021-12-11 21:29:20,831 iteration 4729 : loss : 0.015170, loss_ce: 0.004711
2021-12-11 21:29:22,386 iteration 4730 : loss : 0.031440, loss_ce: 0.012170
2021-12-11 21:29:23,927 iteration 4731 : loss : 0.023335, loss_ce: 0.006698
2021-12-11 21:29:25,386 iteration 4732 : loss : 0.020107, loss_ce: 0.008289
2021-12-11 21:29:27,025 iteration 4733 : loss : 0.033639, loss_ce: 0.013924
2021-12-11 21:29:28,567 iteration 4734 : loss : 0.022105, loss_ce: 0.008597
2021-12-11 21:29:30,046 iteration 4735 : loss : 0.021117, loss_ce: 0.007505
2021-12-11 21:29:31,639 iteration 4736 : loss : 0.024583, loss_ce: 0.008772
2021-12-11 21:29:33,206 iteration 4737 : loss : 0.019942, loss_ce: 0.008765
2021-12-11 21:29:34,872 iteration 4738 : loss : 0.031188, loss_ce: 0.009737
2021-12-11 21:29:36,439 iteration 4739 : loss : 0.018028, loss_ce: 0.006866
2021-12-11 21:29:38,001 iteration 4740 : loss : 0.019857, loss_ce: 0.005895
2021-12-11 21:29:39,546 iteration 4741 : loss : 0.036086, loss_ce: 0.018021
2021-12-11 21:29:41,144 iteration 4742 : loss : 0.025275, loss_ce: 0.010790
2021-12-11 21:29:42,884 iteration 4743 : loss : 0.029427, loss_ce: 0.013298
 70%|████████████████████▏        | 279/400 [2:12:16<55:11, 27.36s/it]2021-12-11 21:29:44,500 iteration 4744 : loss : 0.018797, loss_ce: 0.006649
2021-12-11 21:29:46,050 iteration 4745 : loss : 0.038599, loss_ce: 0.022625
2021-12-11 21:29:47,591 iteration 4746 : loss : 0.021794, loss_ce: 0.006824
2021-12-11 21:29:49,057 iteration 4747 : loss : 0.020991, loss_ce: 0.011563
2021-12-11 21:29:50,700 iteration 4748 : loss : 0.026483, loss_ce: 0.009254
2021-12-11 21:29:52,186 iteration 4749 : loss : 0.021726, loss_ce: 0.008720
2021-12-11 21:29:53,742 iteration 4750 : loss : 0.036628, loss_ce: 0.009097
2021-12-11 21:29:55,304 iteration 4751 : loss : 0.022413, loss_ce: 0.009884
2021-12-11 21:29:56,841 iteration 4752 : loss : 0.024703, loss_ce: 0.006416
2021-12-11 21:29:58,352 iteration 4753 : loss : 0.015750, loss_ce: 0.005127
2021-12-11 21:29:59,905 iteration 4754 : loss : 0.021805, loss_ce: 0.010032
2021-12-11 21:30:01,540 iteration 4755 : loss : 0.026170, loss_ce: 0.007757
2021-12-11 21:30:03,122 iteration 4756 : loss : 0.024842, loss_ce: 0.007293
2021-12-11 21:30:04,687 iteration 4757 : loss : 0.027399, loss_ce: 0.014328
2021-12-11 21:30:06,307 iteration 4758 : loss : 0.027118, loss_ce: 0.009837
2021-12-11 21:30:07,826 iteration 4759 : loss : 0.024659, loss_ce: 0.014595
2021-12-11 21:30:07,827 Training Data Eval:
2021-12-11 21:30:15,471   Average segmentation loss on training set: 0.0148
2021-12-11 21:30:15,472 Validation Data Eval:
2021-12-11 21:30:18,110   Average segmentation loss on validation set: 0.0782
2021-12-11 21:30:19,676 iteration 4760 : loss : 0.020165, loss_ce: 0.007221
 70%|██████████████████▉        | 280/400 [2:12:53<1:00:23, 30.19s/it]2021-12-11 21:30:21,205 iteration 4761 : loss : 0.015307, loss_ce: 0.005243
2021-12-11 21:30:22,837 iteration 4762 : loss : 0.030109, loss_ce: 0.009414
2021-12-11 21:30:24,406 iteration 4763 : loss : 0.020096, loss_ce: 0.008427
2021-12-11 21:30:25,892 iteration 4764 : loss : 0.020817, loss_ce: 0.007361
2021-12-11 21:30:27,431 iteration 4765 : loss : 0.020936, loss_ce: 0.008443
2021-12-11 21:30:28,972 iteration 4766 : loss : 0.020690, loss_ce: 0.006063
2021-12-11 21:30:30,559 iteration 4767 : loss : 0.029706, loss_ce: 0.012579
2021-12-11 21:30:32,203 iteration 4768 : loss : 0.023315, loss_ce: 0.010374
2021-12-11 21:30:33,828 iteration 4769 : loss : 0.035947, loss_ce: 0.009475
2021-12-11 21:30:35,387 iteration 4770 : loss : 0.016279, loss_ce: 0.007582
2021-12-11 21:30:36,889 iteration 4771 : loss : 0.017427, loss_ce: 0.007312
2021-12-11 21:30:38,421 iteration 4772 : loss : 0.014118, loss_ce: 0.004314
2021-12-11 21:30:39,925 iteration 4773 : loss : 0.018274, loss_ce: 0.006641
2021-12-11 21:30:41,423 iteration 4774 : loss : 0.015996, loss_ce: 0.006506
2021-12-11 21:30:42,984 iteration 4775 : loss : 0.026011, loss_ce: 0.010503
2021-12-11 21:30:44,512 iteration 4776 : loss : 0.024289, loss_ce: 0.009536
2021-12-11 21:30:46,048 iteration 4777 : loss : 0.016571, loss_ce: 0.005468
 70%|████████████████████▎        | 281/400 [2:13:20<57:36, 29.05s/it]2021-12-11 21:30:47,687 iteration 4778 : loss : 0.024037, loss_ce: 0.008542
2021-12-11 21:30:49,193 iteration 4779 : loss : 0.016289, loss_ce: 0.005214
2021-12-11 21:30:50,709 iteration 4780 : loss : 0.034411, loss_ce: 0.007294
2021-12-11 21:30:52,219 iteration 4781 : loss : 0.017091, loss_ce: 0.007916
2021-12-11 21:30:53,821 iteration 4782 : loss : 0.022489, loss_ce: 0.007498
2021-12-11 21:30:55,296 iteration 4783 : loss : 0.018620, loss_ce: 0.005145
2021-12-11 21:30:56,898 iteration 4784 : loss : 0.016980, loss_ce: 0.006474
2021-12-11 21:30:58,573 iteration 4785 : loss : 0.021730, loss_ce: 0.009834
2021-12-11 21:31:00,113 iteration 4786 : loss : 0.015578, loss_ce: 0.005675
2021-12-11 21:31:01,695 iteration 4787 : loss : 0.023124, loss_ce: 0.007282
2021-12-11 21:31:03,258 iteration 4788 : loss : 0.016544, loss_ce: 0.006700
2021-12-11 21:31:04,807 iteration 4789 : loss : 0.019419, loss_ce: 0.007262
2021-12-11 21:31:06,336 iteration 4790 : loss : 0.018217, loss_ce: 0.007469
2021-12-11 21:31:07,847 iteration 4791 : loss : 0.015923, loss_ce: 0.005548
2021-12-11 21:31:09,386 iteration 4792 : loss : 0.026469, loss_ce: 0.011924
2021-12-11 21:31:10,957 iteration 4793 : loss : 0.025914, loss_ce: 0.012936
2021-12-11 21:31:12,477 iteration 4794 : loss : 0.066368, loss_ce: 0.020259
 70%|████████████████████▍        | 282/400 [2:13:46<55:34, 28.26s/it]2021-12-11 21:31:13,986 iteration 4795 : loss : 0.018063, loss_ce: 0.005830
2021-12-11 21:31:15,462 iteration 4796 : loss : 0.026074, loss_ce: 0.010256
2021-12-11 21:31:16,990 iteration 4797 : loss : 0.019211, loss_ce: 0.007143
2021-12-11 21:31:18,599 iteration 4798 : loss : 0.034477, loss_ce: 0.013599
2021-12-11 21:31:20,138 iteration 4799 : loss : 0.031327, loss_ce: 0.008131
2021-12-11 21:31:21,693 iteration 4800 : loss : 0.036686, loss_ce: 0.016819
2021-12-11 21:31:23,242 iteration 4801 : loss : 0.024353, loss_ce: 0.011848
2021-12-11 21:31:24,676 iteration 4802 : loss : 0.021014, loss_ce: 0.006316
2021-12-11 21:31:26,225 iteration 4803 : loss : 0.022492, loss_ce: 0.009894
2021-12-11 21:31:27,726 iteration 4804 : loss : 0.024810, loss_ce: 0.007818
2021-12-11 21:31:29,290 iteration 4805 : loss : 0.031344, loss_ce: 0.011123
2021-12-11 21:31:30,780 iteration 4806 : loss : 0.022910, loss_ce: 0.006498
2021-12-11 21:31:32,400 iteration 4807 : loss : 0.023427, loss_ce: 0.009739
2021-12-11 21:31:34,158 iteration 4808 : loss : 0.031393, loss_ce: 0.011434
2021-12-11 21:31:35,603 iteration 4809 : loss : 0.023566, loss_ce: 0.009254
2021-12-11 21:31:37,186 iteration 4810 : loss : 0.028005, loss_ce: 0.011161
2021-12-11 21:31:38,706 iteration 4811 : loss : 0.019774, loss_ce: 0.007502
 71%|████████████████████▌        | 283/400 [2:14:12<53:55, 27.65s/it]2021-12-11 21:31:40,249 iteration 4812 : loss : 0.019715, loss_ce: 0.007221
2021-12-11 21:31:41,808 iteration 4813 : loss : 0.024221, loss_ce: 0.008955
2021-12-11 21:31:43,305 iteration 4814 : loss : 0.019199, loss_ce: 0.009131
2021-12-11 21:31:44,845 iteration 4815 : loss : 0.023489, loss_ce: 0.008228
2021-12-11 21:31:46,381 iteration 4816 : loss : 0.025634, loss_ce: 0.008939
2021-12-11 21:31:47,799 iteration 4817 : loss : 0.022024, loss_ce: 0.007428
2021-12-11 21:31:49,373 iteration 4818 : loss : 0.029907, loss_ce: 0.012553
2021-12-11 21:31:50,941 iteration 4819 : loss : 0.022357, loss_ce: 0.007416
2021-12-11 21:31:52,538 iteration 4820 : loss : 0.016713, loss_ce: 0.006907
2021-12-11 21:31:54,065 iteration 4821 : loss : 0.021257, loss_ce: 0.010501
2021-12-11 21:31:55,623 iteration 4822 : loss : 0.035655, loss_ce: 0.010474
2021-12-11 21:31:57,138 iteration 4823 : loss : 0.019028, loss_ce: 0.007402
2021-12-11 21:31:58,760 iteration 4824 : loss : 0.016061, loss_ce: 0.005744
2021-12-11 21:32:00,284 iteration 4825 : loss : 0.015511, loss_ce: 0.004695
2021-12-11 21:32:01,792 iteration 4826 : loss : 0.025891, loss_ce: 0.008703
2021-12-11 21:32:03,467 iteration 4827 : loss : 0.027247, loss_ce: 0.010478
2021-12-11 21:32:05,069 iteration 4828 : loss : 0.032703, loss_ce: 0.014109
 71%|████████████████████▌        | 284/400 [2:14:39<52:43, 27.27s/it]2021-12-11 21:32:06,671 iteration 4829 : loss : 0.020637, loss_ce: 0.008061
2021-12-11 21:32:08,137 iteration 4830 : loss : 0.017791, loss_ce: 0.006012
2021-12-11 21:32:09,754 iteration 4831 : loss : 0.032433, loss_ce: 0.012448
2021-12-11 21:32:11,280 iteration 4832 : loss : 0.026795, loss_ce: 0.010792
2021-12-11 21:32:12,875 iteration 4833 : loss : 0.020983, loss_ce: 0.005969
2021-12-11 21:32:14,500 iteration 4834 : loss : 0.018753, loss_ce: 0.006335
2021-12-11 21:32:16,009 iteration 4835 : loss : 0.021619, loss_ce: 0.007989
2021-12-11 21:32:17,578 iteration 4836 : loss : 0.021301, loss_ce: 0.007057
2021-12-11 21:32:19,069 iteration 4837 : loss : 0.025695, loss_ce: 0.005765
2021-12-11 21:32:20,640 iteration 4838 : loss : 0.022731, loss_ce: 0.009404
2021-12-11 21:32:22,212 iteration 4839 : loss : 0.019944, loss_ce: 0.009601
2021-12-11 21:32:23,767 iteration 4840 : loss : 0.024122, loss_ce: 0.008729
2021-12-11 21:32:25,379 iteration 4841 : loss : 0.017438, loss_ce: 0.005985
2021-12-11 21:32:26,936 iteration 4842 : loss : 0.019289, loss_ce: 0.007611
2021-12-11 21:32:28,483 iteration 4843 : loss : 0.025541, loss_ce: 0.011113
2021-12-11 21:32:29,957 iteration 4844 : loss : 0.017313, loss_ce: 0.008096
2021-12-11 21:32:29,957 Training Data Eval:
2021-12-11 21:32:37,595   Average segmentation loss on training set: 0.0132
2021-12-11 21:32:37,596 Validation Data Eval:
2021-12-11 21:32:40,231   Average segmentation loss on validation set: 0.0776
2021-12-11 21:32:41,732 iteration 4845 : loss : 0.020574, loss_ce: 0.006197
 71%|████████████████████▋        | 285/400 [2:15:15<57:39, 30.09s/it]2021-12-11 21:32:43,339 iteration 4846 : loss : 0.019954, loss_ce: 0.007930
2021-12-11 21:32:44,862 iteration 4847 : loss : 0.021079, loss_ce: 0.006623
2021-12-11 21:32:46,511 iteration 4848 : loss : 0.024725, loss_ce: 0.010772
2021-12-11 21:32:48,039 iteration 4849 : loss : 0.017408, loss_ce: 0.007644
2021-12-11 21:32:49,604 iteration 4850 : loss : 0.045973, loss_ce: 0.007704
2021-12-11 21:32:51,221 iteration 4851 : loss : 0.019259, loss_ce: 0.008406
2021-12-11 21:32:52,744 iteration 4852 : loss : 0.021851, loss_ce: 0.008616
2021-12-11 21:32:54,255 iteration 4853 : loss : 0.018129, loss_ce: 0.006792
2021-12-11 21:32:55,723 iteration 4854 : loss : 0.016178, loss_ce: 0.005828
2021-12-11 21:32:57,259 iteration 4855 : loss : 0.017816, loss_ce: 0.006201
2021-12-11 21:32:58,820 iteration 4856 : loss : 0.025438, loss_ce: 0.009297
2021-12-11 21:33:00,408 iteration 4857 : loss : 0.022900, loss_ce: 0.012019
2021-12-11 21:33:01,954 iteration 4858 : loss : 0.018733, loss_ce: 0.008076
2021-12-11 21:33:03,438 iteration 4859 : loss : 0.016362, loss_ce: 0.005836
2021-12-11 21:33:04,946 iteration 4860 : loss : 0.020844, loss_ce: 0.005355
2021-12-11 21:33:06,419 iteration 4861 : loss : 0.018240, loss_ce: 0.005426
2021-12-11 21:33:08,037 iteration 4862 : loss : 0.019753, loss_ce: 0.006485
 72%|████████████████████▋        | 286/400 [2:15:42<55:00, 28.95s/it]2021-12-11 21:33:09,651 iteration 4863 : loss : 0.019049, loss_ce: 0.006345
2021-12-11 21:33:11,214 iteration 4864 : loss : 0.022928, loss_ce: 0.007440
2021-12-11 21:33:12,774 iteration 4865 : loss : 0.022575, loss_ce: 0.008142
2021-12-11 21:33:14,334 iteration 4866 : loss : 0.029972, loss_ce: 0.012489
2021-12-11 21:33:15,906 iteration 4867 : loss : 0.032035, loss_ce: 0.009964
2021-12-11 21:33:17,453 iteration 4868 : loss : 0.022949, loss_ce: 0.010790
2021-12-11 21:33:18,961 iteration 4869 : loss : 0.016407, loss_ce: 0.005363
2021-12-11 21:33:20,434 iteration 4870 : loss : 0.015053, loss_ce: 0.005493
2021-12-11 21:33:21,935 iteration 4871 : loss : 0.018552, loss_ce: 0.005954
2021-12-11 21:33:23,469 iteration 4872 : loss : 0.017703, loss_ce: 0.007455
2021-12-11 21:33:25,012 iteration 4873 : loss : 0.026941, loss_ce: 0.009195
2021-12-11 21:33:26,558 iteration 4874 : loss : 0.020552, loss_ce: 0.007053
2021-12-11 21:33:28,069 iteration 4875 : loss : 0.017878, loss_ce: 0.005236
2021-12-11 21:33:29,524 iteration 4876 : loss : 0.018769, loss_ce: 0.007963
2021-12-11 21:33:31,036 iteration 4877 : loss : 0.016866, loss_ce: 0.005474
2021-12-11 21:33:32,584 iteration 4878 : loss : 0.025090, loss_ce: 0.007924
2021-12-11 21:33:34,173 iteration 4879 : loss : 0.018714, loss_ce: 0.005551
 72%|████████████████████▊        | 287/400 [2:16:08<52:56, 28.11s/it]2021-12-11 21:33:35,788 iteration 4880 : loss : 0.018962, loss_ce: 0.006162
2021-12-11 21:33:37,316 iteration 4881 : loss : 0.014471, loss_ce: 0.004472
2021-12-11 21:33:38,785 iteration 4882 : loss : 0.015240, loss_ce: 0.003868
2021-12-11 21:33:40,347 iteration 4883 : loss : 0.026613, loss_ce: 0.012518
2021-12-11 21:33:41,836 iteration 4884 : loss : 0.020894, loss_ce: 0.008850
2021-12-11 21:33:43,381 iteration 4885 : loss : 0.019465, loss_ce: 0.005752
2021-12-11 21:33:44,951 iteration 4886 : loss : 0.016226, loss_ce: 0.005008
2021-12-11 21:33:46,465 iteration 4887 : loss : 0.020514, loss_ce: 0.008314
2021-12-11 21:33:48,007 iteration 4888 : loss : 0.017731, loss_ce: 0.004365
2021-12-11 21:33:49,529 iteration 4889 : loss : 0.021223, loss_ce: 0.009531
2021-12-11 21:33:51,073 iteration 4890 : loss : 0.019497, loss_ce: 0.006471
2021-12-11 21:33:52,610 iteration 4891 : loss : 0.019558, loss_ce: 0.009005
2021-12-11 21:33:54,202 iteration 4892 : loss : 0.020119, loss_ce: 0.008843
2021-12-11 21:33:55,900 iteration 4893 : loss : 0.032411, loss_ce: 0.013155
2021-12-11 21:33:57,435 iteration 4894 : loss : 0.017163, loss_ce: 0.006915
2021-12-11 21:33:58,966 iteration 4895 : loss : 0.020433, loss_ce: 0.009986
2021-12-11 21:34:00,477 iteration 4896 : loss : 0.017746, loss_ce: 0.006380
 72%|████████████████████▉        | 288/400 [2:16:34<51:27, 27.57s/it]2021-12-11 21:34:01,988 iteration 4897 : loss : 0.015406, loss_ce: 0.006523
2021-12-11 21:34:03,505 iteration 4898 : loss : 0.014798, loss_ce: 0.005253
2021-12-11 21:34:04,978 iteration 4899 : loss : 0.018003, loss_ce: 0.007512
2021-12-11 21:34:06,600 iteration 4900 : loss : 0.027482, loss_ce: 0.011834
2021-12-11 21:34:08,153 iteration 4901 : loss : 0.016307, loss_ce: 0.005102
2021-12-11 21:34:09,656 iteration 4902 : loss : 0.017400, loss_ce: 0.003679
2021-12-11 21:34:11,202 iteration 4903 : loss : 0.012726, loss_ce: 0.004871
2021-12-11 21:34:12,726 iteration 4904 : loss : 0.024597, loss_ce: 0.012777
2021-12-11 21:34:14,239 iteration 4905 : loss : 0.018600, loss_ce: 0.009603
2021-12-11 21:34:15,758 iteration 4906 : loss : 0.018158, loss_ce: 0.005852
2021-12-11 21:34:17,298 iteration 4907 : loss : 0.019157, loss_ce: 0.006731
2021-12-11 21:34:18,735 iteration 4908 : loss : 0.020092, loss_ce: 0.005554
2021-12-11 21:34:20,270 iteration 4909 : loss : 0.020737, loss_ce: 0.006444
2021-12-11 21:34:21,783 iteration 4910 : loss : 0.020596, loss_ce: 0.004282
2021-12-11 21:34:23,421 iteration 4911 : loss : 0.019643, loss_ce: 0.007563
2021-12-11 21:34:25,019 iteration 4912 : loss : 0.026946, loss_ce: 0.008999
2021-12-11 21:34:26,526 iteration 4913 : loss : 0.018705, loss_ce: 0.006615
 72%|████████████████████▉        | 289/400 [2:17:00<50:09, 27.11s/it]2021-12-11 21:34:28,040 iteration 4914 : loss : 0.016153, loss_ce: 0.004913
2021-12-11 21:34:29,605 iteration 4915 : loss : 0.017805, loss_ce: 0.007259
2021-12-11 21:34:31,160 iteration 4916 : loss : 0.028096, loss_ce: 0.008337
2021-12-11 21:34:32,692 iteration 4917 : loss : 0.017869, loss_ce: 0.007019
2021-12-11 21:34:34,194 iteration 4918 : loss : 0.015706, loss_ce: 0.006721
2021-12-11 21:34:35,671 iteration 4919 : loss : 0.017019, loss_ce: 0.006063
2021-12-11 21:34:37,234 iteration 4920 : loss : 0.021978, loss_ce: 0.010336
2021-12-11 21:34:38,775 iteration 4921 : loss : 0.017025, loss_ce: 0.003932
2021-12-11 21:34:40,327 iteration 4922 : loss : 0.021554, loss_ce: 0.003977
2021-12-11 21:34:41,864 iteration 4923 : loss : 0.020515, loss_ce: 0.007794
2021-12-11 21:34:43,422 iteration 4924 : loss : 0.025012, loss_ce: 0.009158
2021-12-11 21:34:45,077 iteration 4925 : loss : 0.027282, loss_ce: 0.010924
2021-12-11 21:34:46,573 iteration 4926 : loss : 0.018804, loss_ce: 0.006254
2021-12-11 21:34:48,165 iteration 4927 : loss : 0.016050, loss_ce: 0.006006
2021-12-11 21:34:49,774 iteration 4928 : loss : 0.025863, loss_ce: 0.011106
2021-12-11 21:34:51,374 iteration 4929 : loss : 0.025923, loss_ce: 0.008427
2021-12-11 21:34:51,375 Training Data Eval:
2021-12-11 21:34:59,041   Average segmentation loss on training set: 0.0129
2021-12-11 21:34:59,041 Validation Data Eval:
2021-12-11 21:35:01,690   Average segmentation loss on validation set: 0.0712
2021-12-11 21:35:03,254 iteration 4930 : loss : 0.016293, loss_ce: 0.006498
 72%|█████████████████████        | 290/400 [2:17:37<54:59, 30.00s/it]2021-12-11 21:35:04,881 iteration 4931 : loss : 0.024162, loss_ce: 0.011226
2021-12-11 21:35:06,396 iteration 4932 : loss : 0.019079, loss_ce: 0.007273
2021-12-11 21:35:07,896 iteration 4933 : loss : 0.022047, loss_ce: 0.007301
2021-12-11 21:35:09,447 iteration 4934 : loss : 0.021149, loss_ce: 0.009299
2021-12-11 21:35:11,020 iteration 4935 : loss : 0.021922, loss_ce: 0.006714
2021-12-11 21:35:12,563 iteration 4936 : loss : 0.014805, loss_ce: 0.005967
2021-12-11 21:35:14,135 iteration 4937 : loss : 0.016120, loss_ce: 0.005704
2021-12-11 21:35:15,675 iteration 4938 : loss : 0.039468, loss_ce: 0.012856
2021-12-11 21:35:17,268 iteration 4939 : loss : 0.024672, loss_ce: 0.009892
2021-12-11 21:35:18,771 iteration 4940 : loss : 0.020440, loss_ce: 0.005793
2021-12-11 21:35:20,309 iteration 4941 : loss : 0.016715, loss_ce: 0.006475
2021-12-11 21:35:21,892 iteration 4942 : loss : 0.020995, loss_ce: 0.008956
2021-12-11 21:35:23,390 iteration 4943 : loss : 0.012586, loss_ce: 0.003868
2021-12-11 21:35:24,936 iteration 4944 : loss : 0.027540, loss_ce: 0.010328
2021-12-11 21:35:26,615 iteration 4945 : loss : 0.029284, loss_ce: 0.008660
2021-12-11 21:35:28,208 iteration 4946 : loss : 0.023425, loss_ce: 0.010512
2021-12-11 21:35:29,839 iteration 4947 : loss : 0.026050, loss_ce: 0.009022
 73%|█████████████████████        | 291/400 [2:18:03<52:38, 28.97s/it]2021-12-11 21:35:31,472 iteration 4948 : loss : 0.022790, loss_ce: 0.008574
2021-12-11 21:35:32,993 iteration 4949 : loss : 0.017882, loss_ce: 0.006830
2021-12-11 21:35:34,484 iteration 4950 : loss : 0.020662, loss_ce: 0.007446
2021-12-11 21:35:36,013 iteration 4951 : loss : 0.025698, loss_ce: 0.008903
2021-12-11 21:35:37,472 iteration 4952 : loss : 0.025488, loss_ce: 0.009287
2021-12-11 21:35:39,048 iteration 4953 : loss : 0.017622, loss_ce: 0.007042
2021-12-11 21:35:40,534 iteration 4954 : loss : 0.020408, loss_ce: 0.007460
2021-12-11 21:35:42,042 iteration 4955 : loss : 0.015984, loss_ce: 0.006137
2021-12-11 21:35:43,570 iteration 4956 : loss : 0.023941, loss_ce: 0.009304
2021-12-11 21:35:45,102 iteration 4957 : loss : 0.016503, loss_ce: 0.007114
2021-12-11 21:35:46,655 iteration 4958 : loss : 0.036748, loss_ce: 0.017485
2021-12-11 21:35:48,106 iteration 4959 : loss : 0.015879, loss_ce: 0.005358
2021-12-11 21:35:49,633 iteration 4960 : loss : 0.019049, loss_ce: 0.005722
2021-12-11 21:35:51,128 iteration 4961 : loss : 0.021208, loss_ce: 0.008808
2021-12-11 21:35:52,704 iteration 4962 : loss : 0.017978, loss_ce: 0.007528
2021-12-11 21:35:54,188 iteration 4963 : loss : 0.018197, loss_ce: 0.006729
2021-12-11 21:35:55,808 iteration 4964 : loss : 0.023116, loss_ce: 0.007834
 73%|█████████████████████▏       | 292/400 [2:18:29<50:31, 28.07s/it]2021-12-11 21:35:57,468 iteration 4965 : loss : 0.026540, loss_ce: 0.010087
2021-12-11 21:35:59,129 iteration 4966 : loss : 0.021023, loss_ce: 0.006056
2021-12-11 21:36:00,621 iteration 4967 : loss : 0.021427, loss_ce: 0.008596
2021-12-11 21:36:02,165 iteration 4968 : loss : 0.031214, loss_ce: 0.012412
2021-12-11 21:36:03,684 iteration 4969 : loss : 0.019029, loss_ce: 0.004152
2021-12-11 21:36:05,174 iteration 4970 : loss : 0.014348, loss_ce: 0.004784
2021-12-11 21:36:06,767 iteration 4971 : loss : 0.019795, loss_ce: 0.007819
2021-12-11 21:36:08,372 iteration 4972 : loss : 0.030084, loss_ce: 0.008575
2021-12-11 21:36:09,888 iteration 4973 : loss : 0.019011, loss_ce: 0.007076
2021-12-11 21:36:11,398 iteration 4974 : loss : 0.019624, loss_ce: 0.007528
2021-12-11 21:36:12,930 iteration 4975 : loss : 0.023265, loss_ce: 0.007883
2021-12-11 21:36:14,477 iteration 4976 : loss : 0.023486, loss_ce: 0.008751
2021-12-11 21:36:16,105 iteration 4977 : loss : 0.025077, loss_ce: 0.013453
2021-12-11 21:36:17,628 iteration 4978 : loss : 0.034202, loss_ce: 0.011711
2021-12-11 21:36:19,168 iteration 4979 : loss : 0.026231, loss_ce: 0.012676
2021-12-11 21:36:20,605 iteration 4980 : loss : 0.014773, loss_ce: 0.005304
2021-12-11 21:36:22,144 iteration 4981 : loss : 0.030162, loss_ce: 0.010441
 73%|█████████████████████▏       | 293/400 [2:18:56<49:07, 27.55s/it]2021-12-11 21:36:23,708 iteration 4982 : loss : 0.021006, loss_ce: 0.009059
2021-12-11 21:36:25,219 iteration 4983 : loss : 0.014331, loss_ce: 0.004624
2021-12-11 21:36:26,822 iteration 4984 : loss : 0.029029, loss_ce: 0.011490
2021-12-11 21:36:28,366 iteration 4985 : loss : 0.019793, loss_ce: 0.006992
2021-12-11 21:36:29,990 iteration 4986 : loss : 0.022222, loss_ce: 0.008751
2021-12-11 21:36:31,511 iteration 4987 : loss : 0.017935, loss_ce: 0.007732
2021-12-11 21:36:33,032 iteration 4988 : loss : 0.020862, loss_ce: 0.009436
2021-12-11 21:36:34,560 iteration 4989 : loss : 0.019166, loss_ce: 0.006622
2021-12-11 21:36:36,179 iteration 4990 : loss : 0.017602, loss_ce: 0.005684
2021-12-11 21:36:37,725 iteration 4991 : loss : 0.019747, loss_ce: 0.005420
2021-12-11 21:36:39,264 iteration 4992 : loss : 0.022129, loss_ce: 0.009887
2021-12-11 21:36:40,866 iteration 4993 : loss : 0.021162, loss_ce: 0.009914
2021-12-11 21:36:42,491 iteration 4994 : loss : 0.032914, loss_ce: 0.009058
2021-12-11 21:36:44,072 iteration 4995 : loss : 0.025557, loss_ce: 0.010087
2021-12-11 21:36:45,608 iteration 4996 : loss : 0.023884, loss_ce: 0.007290
2021-12-11 21:36:47,235 iteration 4997 : loss : 0.021602, loss_ce: 0.008662
2021-12-11 21:36:48,735 iteration 4998 : loss : 0.018519, loss_ce: 0.006518
 74%|█████████████████████▎       | 294/400 [2:19:22<48:10, 27.26s/it]2021-12-11 21:36:50,350 iteration 4999 : loss : 0.023658, loss_ce: 0.009074
2021-12-11 21:36:51,832 iteration 5000 : loss : 0.015462, loss_ce: 0.005347
2021-12-11 21:36:53,336 iteration 5001 : loss : 0.025014, loss_ce: 0.007846
2021-12-11 21:36:54,910 iteration 5002 : loss : 0.019116, loss_ce: 0.007675
2021-12-11 21:36:56,412 iteration 5003 : loss : 0.020276, loss_ce: 0.005954
2021-12-11 21:36:58,021 iteration 5004 : loss : 0.034579, loss_ce: 0.013128
2021-12-11 21:36:59,527 iteration 5005 : loss : 0.019972, loss_ce: 0.006234
2021-12-11 21:37:01,096 iteration 5006 : loss : 0.025459, loss_ce: 0.011264
2021-12-11 21:37:02,657 iteration 5007 : loss : 0.019979, loss_ce: 0.006993
2021-12-11 21:37:04,135 iteration 5008 : loss : 0.019811, loss_ce: 0.006703
2021-12-11 21:37:05,663 iteration 5009 : loss : 0.020326, loss_ce: 0.006061
2021-12-11 21:37:07,313 iteration 5010 : loss : 0.041492, loss_ce: 0.015024
2021-12-11 21:37:08,861 iteration 5011 : loss : 0.019799, loss_ce: 0.011126
2021-12-11 21:37:10,461 iteration 5012 : loss : 0.024151, loss_ce: 0.010572
2021-12-11 21:37:12,154 iteration 5013 : loss : 0.022848, loss_ce: 0.010219
2021-12-11 21:37:13,615 iteration 5014 : loss : 0.016873, loss_ce: 0.005775
2021-12-11 21:37:13,616 Training Data Eval:
2021-12-11 21:37:21,281   Average segmentation loss on training set: 0.0127
2021-12-11 21:37:21,281 Validation Data Eval:
2021-12-11 21:37:23,928   Average segmentation loss on validation set: 0.0678
2021-12-11 21:37:25,454 iteration 5015 : loss : 0.016313, loss_ce: 0.003846
 74%|█████████████████████▍       | 295/400 [2:19:59<52:40, 30.10s/it]2021-12-11 21:37:26,988 iteration 5016 : loss : 0.021541, loss_ce: 0.008284
2021-12-11 21:37:28,507 iteration 5017 : loss : 0.018579, loss_ce: 0.005469
2021-12-11 21:37:30,206 iteration 5018 : loss : 0.032015, loss_ce: 0.012538
2021-12-11 21:37:31,771 iteration 5019 : loss : 0.015548, loss_ce: 0.004678
2021-12-11 21:37:33,333 iteration 5020 : loss : 0.017952, loss_ce: 0.008075
2021-12-11 21:37:34,954 iteration 5021 : loss : 0.017713, loss_ce: 0.006684
2021-12-11 21:37:36,555 iteration 5022 : loss : 0.028134, loss_ce: 0.012258
2021-12-11 21:37:38,136 iteration 5023 : loss : 0.018741, loss_ce: 0.007579
2021-12-11 21:37:39,643 iteration 5024 : loss : 0.015046, loss_ce: 0.005588
2021-12-11 21:37:41,152 iteration 5025 : loss : 0.017841, loss_ce: 0.006807
2021-12-11 21:37:42,694 iteration 5026 : loss : 0.026203, loss_ce: 0.011184
2021-12-11 21:37:44,236 iteration 5027 : loss : 0.018305, loss_ce: 0.005111
2021-12-11 21:37:45,787 iteration 5028 : loss : 0.019584, loss_ce: 0.006993
2021-12-11 21:37:47,287 iteration 5029 : loss : 0.014763, loss_ce: 0.005624
2021-12-11 21:37:48,876 iteration 5030 : loss : 0.018550, loss_ce: 0.006730
2021-12-11 21:37:50,492 iteration 5031 : loss : 0.023631, loss_ce: 0.008836
2021-12-11 21:37:52,111 iteration 5032 : loss : 0.019848, loss_ce: 0.007092
 74%|█████████████████████▍       | 296/400 [2:20:26<50:23, 29.07s/it]2021-12-11 21:37:53,710 iteration 5033 : loss : 0.021244, loss_ce: 0.010311
2021-12-11 21:37:55,266 iteration 5034 : loss : 0.024840, loss_ce: 0.007664
2021-12-11 21:37:56,788 iteration 5035 : loss : 0.018943, loss_ce: 0.006329
2021-12-11 21:37:58,248 iteration 5036 : loss : 0.014991, loss_ce: 0.005181
2021-12-11 21:37:59,761 iteration 5037 : loss : 0.015326, loss_ce: 0.005290
2021-12-11 21:38:01,440 iteration 5038 : loss : 0.021748, loss_ce: 0.009179
2021-12-11 21:38:02,993 iteration 5039 : loss : 0.019679, loss_ce: 0.006376
2021-12-11 21:38:04,568 iteration 5040 : loss : 0.022732, loss_ce: 0.008723
2021-12-11 21:38:06,108 iteration 5041 : loss : 0.023701, loss_ce: 0.007271
2021-12-11 21:38:07,645 iteration 5042 : loss : 0.015544, loss_ce: 0.005910
2021-12-11 21:38:09,156 iteration 5043 : loss : 0.018167, loss_ce: 0.005951
2021-12-11 21:38:10,712 iteration 5044 : loss : 0.015616, loss_ce: 0.005175
2021-12-11 21:38:12,157 iteration 5045 : loss : 0.013401, loss_ce: 0.004079
2021-12-11 21:38:13,707 iteration 5046 : loss : 0.027349, loss_ce: 0.007554
2021-12-11 21:38:15,221 iteration 5047 : loss : 0.016797, loss_ce: 0.006290
2021-12-11 21:38:16,706 iteration 5048 : loss : 0.014925, loss_ce: 0.005528
2021-12-11 21:38:18,343 iteration 5049 : loss : 0.023762, loss_ce: 0.010008
 74%|█████████████████████▌       | 297/400 [2:20:52<48:26, 28.22s/it]2021-12-11 21:38:19,965 iteration 5050 : loss : 0.028623, loss_ce: 0.008138
2021-12-11 21:38:21,451 iteration 5051 : loss : 0.015670, loss_ce: 0.006162
2021-12-11 21:38:23,021 iteration 5052 : loss : 0.019181, loss_ce: 0.009158
2021-12-11 21:38:24,508 iteration 5053 : loss : 0.017569, loss_ce: 0.006032
2021-12-11 21:38:26,074 iteration 5054 : loss : 0.016247, loss_ce: 0.006896
2021-12-11 21:38:27,565 iteration 5055 : loss : 0.015334, loss_ce: 0.005394
2021-12-11 21:38:29,089 iteration 5056 : loss : 0.024235, loss_ce: 0.007016
2021-12-11 21:38:30,615 iteration 5057 : loss : 0.020858, loss_ce: 0.009739
2021-12-11 21:38:32,125 iteration 5058 : loss : 0.014759, loss_ce: 0.004723
2021-12-11 21:38:33,673 iteration 5059 : loss : 0.017465, loss_ce: 0.007647
2021-12-11 21:38:35,266 iteration 5060 : loss : 0.019773, loss_ce: 0.004662
2021-12-11 21:38:36,855 iteration 5061 : loss : 0.019954, loss_ce: 0.009410
2021-12-11 21:38:38,455 iteration 5062 : loss : 0.018692, loss_ce: 0.006324
2021-12-11 21:38:39,967 iteration 5063 : loss : 0.016536, loss_ce: 0.006115
2021-12-11 21:38:41,514 iteration 5064 : loss : 0.018891, loss_ce: 0.004598
2021-12-11 21:38:43,123 iteration 5065 : loss : 0.027724, loss_ce: 0.008308
2021-12-11 21:38:44,548 iteration 5066 : loss : 0.017382, loss_ce: 0.007204
 74%|█████████████████████▌       | 298/400 [2:21:18<46:56, 27.61s/it]2021-12-11 21:38:46,238 iteration 5067 : loss : 0.030957, loss_ce: 0.009472
2021-12-11 21:38:47,767 iteration 5068 : loss : 0.013780, loss_ce: 0.004428
2021-12-11 21:38:49,289 iteration 5069 : loss : 0.023077, loss_ce: 0.008209
2021-12-11 21:38:50,816 iteration 5070 : loss : 0.018180, loss_ce: 0.008519
2021-12-11 21:38:52,407 iteration 5071 : loss : 0.020376, loss_ce: 0.008293
2021-12-11 21:38:53,963 iteration 5072 : loss : 0.020541, loss_ce: 0.006363
2021-12-11 21:38:55,556 iteration 5073 : loss : 0.026748, loss_ce: 0.007374
2021-12-11 21:38:57,135 iteration 5074 : loss : 0.022345, loss_ce: 0.007863
2021-12-11 21:38:58,604 iteration 5075 : loss : 0.021119, loss_ce: 0.009393
2021-12-11 21:39:00,084 iteration 5076 : loss : 0.017176, loss_ce: 0.006606
2021-12-11 21:39:01,689 iteration 5077 : loss : 0.016910, loss_ce: 0.006008
2021-12-11 21:39:03,242 iteration 5078 : loss : 0.016752, loss_ce: 0.005432
2021-12-11 21:39:04,769 iteration 5079 : loss : 0.013451, loss_ce: 0.005011
2021-12-11 21:39:06,329 iteration 5080 : loss : 0.016949, loss_ce: 0.006121
2021-12-11 21:39:07,898 iteration 5081 : loss : 0.021416, loss_ce: 0.010408
2021-12-11 21:39:09,416 iteration 5082 : loss : 0.022940, loss_ce: 0.006017
2021-12-11 21:39:10,926 iteration 5083 : loss : 0.035360, loss_ce: 0.011947
 75%|█████████████████████▋       | 299/400 [2:21:45<45:51, 27.24s/it]2021-12-11 21:39:12,519 iteration 5084 : loss : 0.022689, loss_ce: 0.010914
2021-12-11 21:39:14,159 iteration 5085 : loss : 0.026317, loss_ce: 0.009117
2021-12-11 21:39:15,629 iteration 5086 : loss : 0.014836, loss_ce: 0.004169
2021-12-11 21:39:17,185 iteration 5087 : loss : 0.014475, loss_ce: 0.003381
2021-12-11 21:39:18,666 iteration 5088 : loss : 0.013994, loss_ce: 0.006227
2021-12-11 21:39:20,186 iteration 5089 : loss : 0.019474, loss_ce: 0.007642
2021-12-11 21:39:21,755 iteration 5090 : loss : 0.027497, loss_ce: 0.010912
2021-12-11 21:39:23,332 iteration 5091 : loss : 0.023412, loss_ce: 0.008412
2021-12-11 21:39:24,861 iteration 5092 : loss : 0.025430, loss_ce: 0.006659
2021-12-11 21:39:26,414 iteration 5093 : loss : 0.019566, loss_ce: 0.006442
2021-12-11 21:39:27,968 iteration 5094 : loss : 0.020930, loss_ce: 0.006089
2021-12-11 21:39:29,537 iteration 5095 : loss : 0.016607, loss_ce: 0.007484
2021-12-11 21:39:31,155 iteration 5096 : loss : 0.022224, loss_ce: 0.006588
2021-12-11 21:39:32,750 iteration 5097 : loss : 0.023912, loss_ce: 0.011511
2021-12-11 21:39:34,286 iteration 5098 : loss : 0.020349, loss_ce: 0.008584
2021-12-11 21:39:35,872 iteration 5099 : loss : 0.016581, loss_ce: 0.006148
2021-12-11 21:39:35,872 Training Data Eval:
2021-12-11 21:39:43,537   Average segmentation loss on training set: 0.0117
2021-12-11 21:39:43,538 Validation Data Eval:
2021-12-11 21:39:46,182   Average segmentation loss on validation set: 0.0744
2021-12-11 21:39:47,700 iteration 5100 : loss : 0.018722, loss_ce: 0.005622
2021-12-11 21:39:49,681 save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/NEW_TU/UNET_ADAM_seed100epoch_299.pth
 75%|█████████████████████▊       | 300/400 [2:22:23<51:08, 30.68s/it]2021-12-11 21:39:51,174 iteration 5101 : loss : 0.019763, loss_ce: 0.004405
2021-12-11 21:39:52,688 iteration 5102 : loss : 0.021110, loss_ce: 0.010739
2021-12-11 21:39:54,133 iteration 5103 : loss : 0.020936, loss_ce: 0.008177
2021-12-11 21:39:55,642 iteration 5104 : loss : 0.019786, loss_ce: 0.006229
2021-12-11 21:39:57,157 iteration 5105 : loss : 0.017425, loss_ce: 0.004752
2021-12-11 21:39:58,689 iteration 5106 : loss : 0.026210, loss_ce: 0.010104
2021-12-11 21:40:00,245 iteration 5107 : loss : 0.018148, loss_ce: 0.007071
2021-12-11 21:40:01,810 iteration 5108 : loss : 0.017569, loss_ce: 0.006841
2021-12-11 21:40:03,349 iteration 5109 : loss : 0.016880, loss_ce: 0.006801
2021-12-11 21:40:04,791 iteration 5110 : loss : 0.013616, loss_ce: 0.005130
2021-12-11 21:40:06,351 iteration 5111 : loss : 0.021481, loss_ce: 0.005914
2021-12-11 21:40:07,832 iteration 5112 : loss : 0.013664, loss_ce: 0.005267
2021-12-11 21:40:09,443 iteration 5113 : loss : 0.019556, loss_ce: 0.007610
2021-12-11 21:40:10,940 iteration 5114 : loss : 0.013775, loss_ce: 0.005183
2021-12-11 21:40:12,441 iteration 5115 : loss : 0.018167, loss_ce: 0.008271
2021-12-11 21:40:13,988 iteration 5116 : loss : 0.023886, loss_ce: 0.008301
2021-12-11 21:40:15,536 iteration 5117 : loss : 0.018166, loss_ce: 0.006055
 75%|█████████████████████▊       | 301/400 [2:22:49<48:15, 29.25s/it]2021-12-11 21:40:17,133 iteration 5118 : loss : 0.017332, loss_ce: 0.007482
2021-12-11 21:40:18,684 iteration 5119 : loss : 0.027741, loss_ce: 0.009217
2021-12-11 21:40:20,321 iteration 5120 : loss : 0.018010, loss_ce: 0.004748
2021-12-11 21:40:21,820 iteration 5121 : loss : 0.017138, loss_ce: 0.006178
2021-12-11 21:40:23,373 iteration 5122 : loss : 0.022451, loss_ce: 0.006134
2021-12-11 21:40:24,909 iteration 5123 : loss : 0.019914, loss_ce: 0.009344
2021-12-11 21:40:26,417 iteration 5124 : loss : 0.022973, loss_ce: 0.005863
2021-12-11 21:40:27,962 iteration 5125 : loss : 0.016341, loss_ce: 0.005701
2021-12-11 21:40:29,481 iteration 5126 : loss : 0.016892, loss_ce: 0.006520
2021-12-11 21:40:31,042 iteration 5127 : loss : 0.023504, loss_ce: 0.008991
2021-12-11 21:40:32,686 iteration 5128 : loss : 0.021854, loss_ce: 0.007323
2021-12-11 21:40:34,297 iteration 5129 : loss : 0.018994, loss_ce: 0.007093
2021-12-11 21:40:35,771 iteration 5130 : loss : 0.015083, loss_ce: 0.005871
2021-12-11 21:40:37,339 iteration 5131 : loss : 0.018746, loss_ce: 0.006714
2021-12-11 21:40:38,893 iteration 5132 : loss : 0.019640, loss_ce: 0.008913
2021-12-11 21:40:40,408 iteration 5133 : loss : 0.018972, loss_ce: 0.007842
2021-12-11 21:40:41,890 iteration 5134 : loss : 0.012836, loss_ce: 0.004273
 76%|█████████████████████▉       | 302/400 [2:23:16<46:21, 28.38s/it]2021-12-11 21:40:43,458 iteration 5135 : loss : 0.020730, loss_ce: 0.007686
2021-12-11 21:40:45,089 iteration 5136 : loss : 0.018915, loss_ce: 0.006744
2021-12-11 21:40:46,715 iteration 5137 : loss : 0.021859, loss_ce: 0.008131
2021-12-11 21:40:48,360 iteration 5138 : loss : 0.020680, loss_ce: 0.009548
2021-12-11 21:40:49,834 iteration 5139 : loss : 0.011458, loss_ce: 0.003435
2021-12-11 21:40:51,430 iteration 5140 : loss : 0.023479, loss_ce: 0.009670
2021-12-11 21:40:52,910 iteration 5141 : loss : 0.016357, loss_ce: 0.007737
2021-12-11 21:40:54,533 iteration 5142 : loss : 0.029704, loss_ce: 0.009599
2021-12-11 21:40:56,009 iteration 5143 : loss : 0.014544, loss_ce: 0.005425
2021-12-11 21:40:57,488 iteration 5144 : loss : 0.019843, loss_ce: 0.010368
2021-12-11 21:40:59,054 iteration 5145 : loss : 0.022908, loss_ce: 0.008337
2021-12-11 21:41:00,723 iteration 5146 : loss : 0.033509, loss_ce: 0.009614
2021-12-11 21:41:02,276 iteration 5147 : loss : 0.015240, loss_ce: 0.006996
2021-12-11 21:41:03,852 iteration 5148 : loss : 0.024413, loss_ce: 0.008904
2021-12-11 21:41:05,368 iteration 5149 : loss : 0.020472, loss_ce: 0.006754
2021-12-11 21:41:06,875 iteration 5150 : loss : 0.018024, loss_ce: 0.006645
2021-12-11 21:41:08,351 iteration 5151 : loss : 0.014125, loss_ce: 0.004437
 76%|█████████████████████▉       | 303/400 [2:23:42<44:56, 27.80s/it]2021-12-11 21:41:09,968 iteration 5152 : loss : 0.020444, loss_ce: 0.005666
2021-12-11 21:41:11,475 iteration 5153 : loss : 0.013379, loss_ce: 0.006210
2021-12-11 21:41:13,059 iteration 5154 : loss : 0.027885, loss_ce: 0.010303
2021-12-11 21:41:14,538 iteration 5155 : loss : 0.011014, loss_ce: 0.003581
2021-12-11 21:41:16,066 iteration 5156 : loss : 0.033853, loss_ce: 0.010718
2021-12-11 21:41:17,662 iteration 5157 : loss : 0.024526, loss_ce: 0.009279
2021-12-11 21:41:19,230 iteration 5158 : loss : 0.019321, loss_ce: 0.006503
2021-12-11 21:41:20,824 iteration 5159 : loss : 0.026337, loss_ce: 0.008604
2021-12-11 21:41:22,432 iteration 5160 : loss : 0.020181, loss_ce: 0.009030
2021-12-11 21:41:24,026 iteration 5161 : loss : 0.018000, loss_ce: 0.007450
2021-12-11 21:41:25,539 iteration 5162 : loss : 0.018389, loss_ce: 0.004951
2021-12-11 21:41:27,064 iteration 5163 : loss : 0.022222, loss_ce: 0.008533
2021-12-11 21:41:28,556 iteration 5164 : loss : 0.017440, loss_ce: 0.008639
2021-12-11 21:41:30,112 iteration 5165 : loss : 0.020200, loss_ce: 0.006134
2021-12-11 21:41:31,660 iteration 5166 : loss : 0.017990, loss_ce: 0.007412
2021-12-11 21:41:33,161 iteration 5167 : loss : 0.016914, loss_ce: 0.007341
2021-12-11 21:41:34,756 iteration 5168 : loss : 0.025463, loss_ce: 0.010603
 76%|██████████████████████       | 304/400 [2:24:08<43:48, 27.38s/it]2021-12-11 21:41:36,301 iteration 5169 : loss : 0.021438, loss_ce: 0.008520
2021-12-11 21:41:37,851 iteration 5170 : loss : 0.018136, loss_ce: 0.007522
2021-12-11 21:41:39,368 iteration 5171 : loss : 0.021310, loss_ce: 0.005516
2021-12-11 21:41:40,925 iteration 5172 : loss : 0.016316, loss_ce: 0.005107
2021-12-11 21:41:42,437 iteration 5173 : loss : 0.016665, loss_ce: 0.007276
2021-12-11 21:41:44,003 iteration 5174 : loss : 0.019220, loss_ce: 0.007926
2021-12-11 21:41:45,637 iteration 5175 : loss : 0.036928, loss_ce: 0.013862
2021-12-11 21:41:47,177 iteration 5176 : loss : 0.042997, loss_ce: 0.018391
2021-12-11 21:41:48,828 iteration 5177 : loss : 0.033830, loss_ce: 0.013420
2021-12-11 21:41:50,340 iteration 5178 : loss : 0.025164, loss_ce: 0.004539
2021-12-11 21:41:51,946 iteration 5179 : loss : 0.031740, loss_ce: 0.015922
2021-12-11 21:41:53,508 iteration 5180 : loss : 0.019371, loss_ce: 0.007555
2021-12-11 21:41:55,102 iteration 5181 : loss : 0.022043, loss_ce: 0.008560
2021-12-11 21:41:56,708 iteration 5182 : loss : 0.033119, loss_ce: 0.012343
2021-12-11 21:41:58,299 iteration 5183 : loss : 0.027837, loss_ce: 0.007711
2021-12-11 21:41:59,999 iteration 5184 : loss : 0.020506, loss_ce: 0.009505
2021-12-11 21:42:00,000 Training Data Eval:
2021-12-11 21:42:07,635   Average segmentation loss on training set: 0.0143
2021-12-11 21:42:07,636 Validation Data Eval:
2021-12-11 21:42:10,273   Average segmentation loss on validation set: 0.0857
2021-12-11 21:42:11,824 iteration 5185 : loss : 0.019515, loss_ce: 0.008249
 76%|██████████████████████       | 305/400 [2:24:45<47:57, 30.29s/it]2021-12-11 21:42:13,415 iteration 5186 : loss : 0.018343, loss_ce: 0.007360
2021-12-11 21:42:15,018 iteration 5187 : loss : 0.025097, loss_ce: 0.010400
2021-12-11 21:42:16,532 iteration 5188 : loss : 0.019792, loss_ce: 0.005625
2021-12-11 21:42:18,083 iteration 5189 : loss : 0.016646, loss_ce: 0.006858
2021-12-11 21:42:19,558 iteration 5190 : loss : 0.020177, loss_ce: 0.008428
2021-12-11 21:42:21,050 iteration 5191 : loss : 0.022551, loss_ce: 0.009699
2021-12-11 21:42:22,640 iteration 5192 : loss : 0.018621, loss_ce: 0.007244
2021-12-11 21:42:24,207 iteration 5193 : loss : 0.032064, loss_ce: 0.016186
2021-12-11 21:42:25,753 iteration 5194 : loss : 0.018950, loss_ce: 0.007756
2021-12-11 21:42:27,320 iteration 5195 : loss : 0.057572, loss_ce: 0.022511
2021-12-11 21:42:28,993 iteration 5196 : loss : 0.028546, loss_ce: 0.008149
2021-12-11 21:42:30,451 iteration 5197 : loss : 0.017202, loss_ce: 0.004979
2021-12-11 21:42:32,048 iteration 5198 : loss : 0.037285, loss_ce: 0.017824
2021-12-11 21:42:33,640 iteration 5199 : loss : 0.021100, loss_ce: 0.007583
2021-12-11 21:42:35,223 iteration 5200 : loss : 0.018248, loss_ce: 0.005684
2021-12-11 21:42:36,746 iteration 5201 : loss : 0.016579, loss_ce: 0.004786
2021-12-11 21:42:38,293 iteration 5202 : loss : 0.023620, loss_ce: 0.009259
 76%|██████████████████████▏      | 306/400 [2:25:12<45:39, 29.14s/it]2021-12-11 21:42:39,784 iteration 5203 : loss : 0.016381, loss_ce: 0.005143
2021-12-11 21:42:41,359 iteration 5204 : loss : 0.021401, loss_ce: 0.008061
2021-12-11 21:42:42,914 iteration 5205 : loss : 0.021040, loss_ce: 0.008451
2021-12-11 21:42:44,390 iteration 5206 : loss : 0.014532, loss_ce: 0.006208
2021-12-11 21:42:45,961 iteration 5207 : loss : 0.021565, loss_ce: 0.008484
2021-12-11 21:42:47,574 iteration 5208 : loss : 0.020245, loss_ce: 0.007832
2021-12-11 21:42:49,144 iteration 5209 : loss : 0.018959, loss_ce: 0.007475
2021-12-11 21:42:50,670 iteration 5210 : loss : 0.016377, loss_ce: 0.005371
2021-12-11 21:42:52,165 iteration 5211 : loss : 0.015025, loss_ce: 0.004651
2021-12-11 21:42:53,725 iteration 5212 : loss : 0.017679, loss_ce: 0.005011
2021-12-11 21:42:55,306 iteration 5213 : loss : 0.050570, loss_ce: 0.014291
2021-12-11 21:42:56,839 iteration 5214 : loss : 0.021798, loss_ce: 0.013879
2021-12-11 21:42:58,360 iteration 5215 : loss : 0.024939, loss_ce: 0.010971
2021-12-11 21:42:59,891 iteration 5216 : loss : 0.018760, loss_ce: 0.009173
2021-12-11 21:43:01,373 iteration 5217 : loss : 0.014688, loss_ce: 0.004996
2021-12-11 21:43:02,937 iteration 5218 : loss : 0.019870, loss_ce: 0.006349
2021-12-11 21:43:04,497 iteration 5219 : loss : 0.024002, loss_ce: 0.010664
 77%|██████████████████████▎      | 307/400 [2:25:38<43:48, 28.26s/it]2021-12-11 21:43:06,152 iteration 5220 : loss : 0.025849, loss_ce: 0.010046
2021-12-11 21:43:07,671 iteration 5221 : loss : 0.019420, loss_ce: 0.008046
2021-12-11 21:43:09,123 iteration 5222 : loss : 0.017772, loss_ce: 0.004470
2021-12-11 21:43:10,646 iteration 5223 : loss : 0.023255, loss_ce: 0.010183
2021-12-11 21:43:12,259 iteration 5224 : loss : 0.029394, loss_ce: 0.010266
2021-12-11 21:43:13,738 iteration 5225 : loss : 0.020970, loss_ce: 0.005697
2021-12-11 21:43:15,412 iteration 5226 : loss : 0.028559, loss_ce: 0.011266
2021-12-11 21:43:16,860 iteration 5227 : loss : 0.020695, loss_ce: 0.007796
2021-12-11 21:43:18,313 iteration 5228 : loss : 0.014179, loss_ce: 0.005802
2021-12-11 21:43:19,793 iteration 5229 : loss : 0.018076, loss_ce: 0.007451
2021-12-11 21:43:21,357 iteration 5230 : loss : 0.022918, loss_ce: 0.011367
2021-12-11 21:43:22,923 iteration 5231 : loss : 0.027640, loss_ce: 0.007734
2021-12-11 21:43:24,424 iteration 5232 : loss : 0.018567, loss_ce: 0.007757
2021-12-11 21:43:25,996 iteration 5233 : loss : 0.028088, loss_ce: 0.010698
2021-12-11 21:43:27,438 iteration 5234 : loss : 0.013732, loss_ce: 0.004889
2021-12-11 21:43:29,062 iteration 5235 : loss : 0.022659, loss_ce: 0.006871
2021-12-11 21:43:30,588 iteration 5236 : loss : 0.018844, loss_ce: 0.006662
 77%|██████████████████████▎      | 308/400 [2:26:04<42:20, 27.61s/it]2021-12-11 21:43:32,231 iteration 5237 : loss : 0.017525, loss_ce: 0.005324
2021-12-11 21:43:33,769 iteration 5238 : loss : 0.017660, loss_ce: 0.007320
2021-12-11 21:43:35,311 iteration 5239 : loss : 0.016829, loss_ce: 0.004328
2021-12-11 21:43:36,943 iteration 5240 : loss : 0.030009, loss_ce: 0.009588
2021-12-11 21:43:38,517 iteration 5241 : loss : 0.021759, loss_ce: 0.008529
2021-12-11 21:43:40,089 iteration 5242 : loss : 0.022152, loss_ce: 0.008731
2021-12-11 21:43:41,629 iteration 5243 : loss : 0.018332, loss_ce: 0.005901
2021-12-11 21:43:43,180 iteration 5244 : loss : 0.025293, loss_ce: 0.008910
2021-12-11 21:43:44,728 iteration 5245 : loss : 0.024016, loss_ce: 0.008419
2021-12-11 21:43:46,165 iteration 5246 : loss : 0.013513, loss_ce: 0.005577
2021-12-11 21:43:47,700 iteration 5247 : loss : 0.016880, loss_ce: 0.005569
2021-12-11 21:43:49,268 iteration 5248 : loss : 0.017030, loss_ce: 0.005949
2021-12-11 21:43:50,833 iteration 5249 : loss : 0.020349, loss_ce: 0.007451
2021-12-11 21:43:52,365 iteration 5250 : loss : 0.020304, loss_ce: 0.008739
2021-12-11 21:43:53,970 iteration 5251 : loss : 0.019198, loss_ce: 0.006935
2021-12-11 21:43:55,505 iteration 5252 : loss : 0.018257, loss_ce: 0.005983
2021-12-11 21:43:57,080 iteration 5253 : loss : 0.015023, loss_ce: 0.005578
 77%|██████████████████████▍      | 309/400 [2:26:31<41:22, 27.28s/it]2021-12-11 21:43:58,593 iteration 5254 : loss : 0.018079, loss_ce: 0.005920
2021-12-11 21:44:00,190 iteration 5255 : loss : 0.019179, loss_ce: 0.006154
2021-12-11 21:44:01,748 iteration 5256 : loss : 0.016250, loss_ce: 0.006555
2021-12-11 21:44:03,374 iteration 5257 : loss : 0.026015, loss_ce: 0.007123
2021-12-11 21:44:04,846 iteration 5258 : loss : 0.028983, loss_ce: 0.011470
2021-12-11 21:44:06,416 iteration 5259 : loss : 0.021778, loss_ce: 0.006150
2021-12-11 21:44:07,927 iteration 5260 : loss : 0.016727, loss_ce: 0.006775
2021-12-11 21:44:09,471 iteration 5261 : loss : 0.018991, loss_ce: 0.008561
2021-12-11 21:44:10,950 iteration 5262 : loss : 0.012042, loss_ce: 0.005130
2021-12-11 21:44:12,487 iteration 5263 : loss : 0.019662, loss_ce: 0.007429
2021-12-11 21:44:14,003 iteration 5264 : loss : 0.014788, loss_ce: 0.005149
2021-12-11 21:44:15,463 iteration 5265 : loss : 0.014130, loss_ce: 0.005232
2021-12-11 21:44:17,007 iteration 5266 : loss : 0.017769, loss_ce: 0.007271
2021-12-11 21:44:18,492 iteration 5267 : loss : 0.017685, loss_ce: 0.006224
2021-12-11 21:44:20,139 iteration 5268 : loss : 0.019191, loss_ce: 0.007176
2021-12-11 21:44:21,743 iteration 5269 : loss : 0.020446, loss_ce: 0.009386
2021-12-11 21:44:21,744 Training Data Eval:
2021-12-11 21:44:29,384   Average segmentation loss on training set: 0.0117
2021-12-11 21:44:29,385 Validation Data Eval:
2021-12-11 21:44:32,019   Average segmentation loss on validation set: 0.0749
2021-12-11 21:44:33,611 iteration 5270 : loss : 0.019753, loss_ce: 0.006983
 78%|██████████████████████▍      | 310/400 [2:27:07<45:04, 30.05s/it]2021-12-11 21:44:35,290 iteration 5271 : loss : 0.016991, loss_ce: 0.006891
2021-12-11 21:44:36,831 iteration 5272 : loss : 0.019722, loss_ce: 0.006921
2021-12-11 21:44:38,377 iteration 5273 : loss : 0.016691, loss_ce: 0.006870
2021-12-11 21:44:39,863 iteration 5274 : loss : 0.015436, loss_ce: 0.005104
2021-12-11 21:44:41,433 iteration 5275 : loss : 0.021017, loss_ce: 0.005958
2021-12-11 21:44:42,997 iteration 5276 : loss : 0.014454, loss_ce: 0.004264
2021-12-11 21:44:44,463 iteration 5277 : loss : 0.020244, loss_ce: 0.006227
2021-12-11 21:44:46,135 iteration 5278 : loss : 0.020351, loss_ce: 0.008107
2021-12-11 21:44:47,662 iteration 5279 : loss : 0.019231, loss_ce: 0.005325
2021-12-11 21:44:49,275 iteration 5280 : loss : 0.020452, loss_ce: 0.007311
2021-12-11 21:44:50,826 iteration 5281 : loss : 0.018262, loss_ce: 0.009582
2021-12-11 21:44:52,399 iteration 5282 : loss : 0.021157, loss_ce: 0.007443
2021-12-11 21:44:53,967 iteration 5283 : loss : 0.015713, loss_ce: 0.004772
2021-12-11 21:44:55,534 iteration 5284 : loss : 0.016416, loss_ce: 0.007481
2021-12-11 21:44:57,090 iteration 5285 : loss : 0.017809, loss_ce: 0.007766
2021-12-11 21:44:58,680 iteration 5286 : loss : 0.016502, loss_ce: 0.005722
2021-12-11 21:45:00,337 iteration 5287 : loss : 0.025607, loss_ce: 0.011074
 78%|██████████████████████▌      | 311/400 [2:27:34<43:05, 29.05s/it]2021-12-11 21:45:01,875 iteration 5288 : loss : 0.016022, loss_ce: 0.005948
2021-12-11 21:45:03,427 iteration 5289 : loss : 0.024183, loss_ce: 0.007483
2021-12-11 21:45:05,023 iteration 5290 : loss : 0.024190, loss_ce: 0.008301
2021-12-11 21:45:06,656 iteration 5291 : loss : 0.025971, loss_ce: 0.010324
2021-12-11 21:45:08,222 iteration 5292 : loss : 0.016235, loss_ce: 0.006263
2021-12-11 21:45:09,734 iteration 5293 : loss : 0.017446, loss_ce: 0.004868
2021-12-11 21:45:11,342 iteration 5294 : loss : 0.020717, loss_ce: 0.009456
2021-12-11 21:45:12,844 iteration 5295 : loss : 0.014265, loss_ce: 0.005107
2021-12-11 21:45:14,405 iteration 5296 : loss : 0.018573, loss_ce: 0.005752
2021-12-11 21:45:16,028 iteration 5297 : loss : 0.022366, loss_ce: 0.007091
2021-12-11 21:45:17,517 iteration 5298 : loss : 0.015696, loss_ce: 0.006819
2021-12-11 21:45:19,114 iteration 5299 : loss : 0.019989, loss_ce: 0.008621
2021-12-11 21:45:20,582 iteration 5300 : loss : 0.018230, loss_ce: 0.007013
2021-12-11 21:45:22,128 iteration 5301 : loss : 0.029352, loss_ce: 0.010509
2021-12-11 21:45:23,644 iteration 5302 : loss : 0.017022, loss_ce: 0.006834
2021-12-11 21:45:25,112 iteration 5303 : loss : 0.015001, loss_ce: 0.005033
2021-12-11 21:45:26,703 iteration 5304 : loss : 0.020317, loss_ce: 0.008420
 78%|██████████████████████▌      | 312/400 [2:28:00<41:25, 28.25s/it]2021-12-11 21:45:28,290 iteration 5305 : loss : 0.036517, loss_ce: 0.011605
2021-12-11 21:45:29,854 iteration 5306 : loss : 0.025449, loss_ce: 0.008082
2021-12-11 21:45:31,393 iteration 5307 : loss : 0.015850, loss_ce: 0.005677
2021-12-11 21:45:32,974 iteration 5308 : loss : 0.016137, loss_ce: 0.006700
2021-12-11 21:45:34,506 iteration 5309 : loss : 0.014604, loss_ce: 0.004358
2021-12-11 21:45:36,036 iteration 5310 : loss : 0.022642, loss_ce: 0.010315
2021-12-11 21:45:37,575 iteration 5311 : loss : 0.017420, loss_ce: 0.006402
2021-12-11 21:45:39,120 iteration 5312 : loss : 0.016141, loss_ce: 0.004861
2021-12-11 21:45:40,695 iteration 5313 : loss : 0.025540, loss_ce: 0.006829
2021-12-11 21:45:42,196 iteration 5314 : loss : 0.020915, loss_ce: 0.008346
2021-12-11 21:45:43,761 iteration 5315 : loss : 0.028008, loss_ce: 0.013521
2021-12-11 21:45:45,181 iteration 5316 : loss : 0.014049, loss_ce: 0.005797
2021-12-11 21:45:46,735 iteration 5317 : loss : 0.016752, loss_ce: 0.005783
2021-12-11 21:45:48,307 iteration 5318 : loss : 0.020044, loss_ce: 0.006380
2021-12-11 21:45:49,885 iteration 5319 : loss : 0.025658, loss_ce: 0.007294
2021-12-11 21:45:51,466 iteration 5320 : loss : 0.026604, loss_ce: 0.010515
2021-12-11 21:45:52,946 iteration 5321 : loss : 0.021363, loss_ce: 0.004426
 78%|██████████████████████▋      | 313/400 [2:28:27<40:05, 27.65s/it]2021-12-11 21:45:54,628 iteration 5322 : loss : 0.020584, loss_ce: 0.009574
2021-12-11 21:45:56,227 iteration 5323 : loss : 0.018983, loss_ce: 0.006747
2021-12-11 21:45:57,781 iteration 5324 : loss : 0.016723, loss_ce: 0.007231
2021-12-11 21:45:59,339 iteration 5325 : loss : 0.024463, loss_ce: 0.008766
2021-12-11 21:46:00,979 iteration 5326 : loss : 0.021880, loss_ce: 0.005684
2021-12-11 21:46:02,552 iteration 5327 : loss : 0.020943, loss_ce: 0.007337
2021-12-11 21:46:04,088 iteration 5328 : loss : 0.018279, loss_ce: 0.007163
2021-12-11 21:46:05,632 iteration 5329 : loss : 0.020788, loss_ce: 0.007558
2021-12-11 21:46:07,181 iteration 5330 : loss : 0.025407, loss_ce: 0.008432
2021-12-11 21:46:08,664 iteration 5331 : loss : 0.015654, loss_ce: 0.005611
2021-12-11 21:46:10,376 iteration 5332 : loss : 0.027924, loss_ce: 0.010856
2021-12-11 21:46:11,912 iteration 5333 : loss : 0.018811, loss_ce: 0.006931
2021-12-11 21:46:13,347 iteration 5334 : loss : 0.014937, loss_ce: 0.004238
2021-12-11 21:46:14,901 iteration 5335 : loss : 0.019662, loss_ce: 0.005472
2021-12-11 21:46:16,428 iteration 5336 : loss : 0.020117, loss_ce: 0.005888
2021-12-11 21:46:17,958 iteration 5337 : loss : 0.020922, loss_ce: 0.007961
2021-12-11 21:46:19,511 iteration 5338 : loss : 0.024735, loss_ce: 0.010302
 78%|██████████████████████▊      | 314/400 [2:28:53<39:09, 27.32s/it]2021-12-11 21:46:21,075 iteration 5339 : loss : 0.020405, loss_ce: 0.007872
2021-12-11 21:46:22,589 iteration 5340 : loss : 0.016451, loss_ce: 0.006403
2021-12-11 21:46:24,206 iteration 5341 : loss : 0.020167, loss_ce: 0.004483
2021-12-11 21:46:25,794 iteration 5342 : loss : 0.021875, loss_ce: 0.007316
2021-12-11 21:46:27,351 iteration 5343 : loss : 0.022661, loss_ce: 0.008390
2021-12-11 21:46:28,844 iteration 5344 : loss : 0.015518, loss_ce: 0.007047
2021-12-11 21:46:30,363 iteration 5345 : loss : 0.016861, loss_ce: 0.008288
2021-12-11 21:46:31,861 iteration 5346 : loss : 0.019461, loss_ce: 0.008342
2021-12-11 21:46:33,428 iteration 5347 : loss : 0.013464, loss_ce: 0.005763
2021-12-11 21:46:34,922 iteration 5348 : loss : 0.019219, loss_ce: 0.006894
2021-12-11 21:46:36,421 iteration 5349 : loss : 0.022469, loss_ce: 0.007387
2021-12-11 21:46:37,951 iteration 5350 : loss : 0.021874, loss_ce: 0.007373
2021-12-11 21:46:39,428 iteration 5351 : loss : 0.015408, loss_ce: 0.005773
2021-12-11 21:46:41,029 iteration 5352 : loss : 0.017244, loss_ce: 0.006179
2021-12-11 21:46:42,583 iteration 5353 : loss : 0.016872, loss_ce: 0.006593
2021-12-11 21:46:44,071 iteration 5354 : loss : 0.015479, loss_ce: 0.006200
2021-12-11 21:46:44,071 Training Data Eval:
2021-12-11 21:46:51,710   Average segmentation loss on training set: 0.0119
2021-12-11 21:46:51,711 Validation Data Eval:
2021-12-11 21:46:54,351   Average segmentation loss on validation set: 0.0761
2021-12-11 21:46:55,883 iteration 5355 : loss : 0.021699, loss_ce: 0.010149
 79%|██████████████████████▊      | 315/400 [2:29:29<42:33, 30.04s/it]2021-12-11 21:46:57,506 iteration 5356 : loss : 0.023705, loss_ce: 0.010426
2021-12-11 21:46:59,012 iteration 5357 : loss : 0.012881, loss_ce: 0.004642
2021-12-11 21:47:00,509 iteration 5358 : loss : 0.017224, loss_ce: 0.006785
2021-12-11 21:47:02,002 iteration 5359 : loss : 0.017184, loss_ce: 0.005894
2021-12-11 21:47:03,591 iteration 5360 : loss : 0.022209, loss_ce: 0.008214
2021-12-11 21:47:05,108 iteration 5361 : loss : 0.018342, loss_ce: 0.008123
2021-12-11 21:47:06,673 iteration 5362 : loss : 0.014253, loss_ce: 0.004621
2021-12-11 21:47:08,357 iteration 5363 : loss : 0.019857, loss_ce: 0.007322
2021-12-11 21:47:09,894 iteration 5364 : loss : 0.034158, loss_ce: 0.008329
2021-12-11 21:47:11,452 iteration 5365 : loss : 0.021858, loss_ce: 0.007724
2021-12-11 21:47:13,017 iteration 5366 : loss : 0.022635, loss_ce: 0.008035
2021-12-11 21:47:14,459 iteration 5367 : loss : 0.016851, loss_ce: 0.005400
2021-12-11 21:47:16,098 iteration 5368 : loss : 0.028845, loss_ce: 0.010307
2021-12-11 21:47:17,614 iteration 5369 : loss : 0.011513, loss_ce: 0.004350
2021-12-11 21:47:19,128 iteration 5370 : loss : 0.016438, loss_ce: 0.007225
2021-12-11 21:47:20,640 iteration 5371 : loss : 0.013280, loss_ce: 0.003376
2021-12-11 21:47:22,096 iteration 5372 : loss : 0.013268, loss_ce: 0.005207
 79%|██████████████████████▉      | 316/400 [2:29:56<40:26, 28.89s/it]2021-12-11 21:47:23,658 iteration 5373 : loss : 0.018475, loss_ce: 0.006718
2021-12-11 21:47:25,156 iteration 5374 : loss : 0.020187, loss_ce: 0.005071
2021-12-11 21:47:26,701 iteration 5375 : loss : 0.016199, loss_ce: 0.005869
2021-12-11 21:47:28,247 iteration 5376 : loss : 0.024090, loss_ce: 0.008169
2021-12-11 21:47:29,801 iteration 5377 : loss : 0.021131, loss_ce: 0.005093
2021-12-11 21:47:31,383 iteration 5378 : loss : 0.023271, loss_ce: 0.006645
2021-12-11 21:47:32,908 iteration 5379 : loss : 0.018087, loss_ce: 0.006863
2021-12-11 21:47:34,382 iteration 5380 : loss : 0.016680, loss_ce: 0.006913
2021-12-11 21:47:35,981 iteration 5381 : loss : 0.021142, loss_ce: 0.008354
2021-12-11 21:47:37,519 iteration 5382 : loss : 0.017884, loss_ce: 0.006919
2021-12-11 21:47:39,044 iteration 5383 : loss : 0.022635, loss_ce: 0.011189
2021-12-11 21:47:40,561 iteration 5384 : loss : 0.015910, loss_ce: 0.007652
2021-12-11 21:47:42,126 iteration 5385 : loss : 0.024610, loss_ce: 0.009710
2021-12-11 21:47:43,630 iteration 5386 : loss : 0.016903, loss_ce: 0.006334
2021-12-11 21:47:45,258 iteration 5387 : loss : 0.021226, loss_ce: 0.007541
2021-12-11 21:47:46,822 iteration 5388 : loss : 0.022420, loss_ce: 0.006682
2021-12-11 21:47:48,428 iteration 5389 : loss : 0.029756, loss_ce: 0.012620
 79%|██████████████████████▉      | 317/400 [2:30:22<38:54, 28.12s/it]2021-12-11 21:47:49,956 iteration 5390 : loss : 0.014106, loss_ce: 0.004946
2021-12-11 21:47:51,564 iteration 5391 : loss : 0.024130, loss_ce: 0.007588
2021-12-11 21:47:53,086 iteration 5392 : loss : 0.018600, loss_ce: 0.005272
2021-12-11 21:47:54,583 iteration 5393 : loss : 0.017976, loss_ce: 0.006430
2021-12-11 21:47:56,104 iteration 5394 : loss : 0.014832, loss_ce: 0.004016
2021-12-11 21:47:57,646 iteration 5395 : loss : 0.024642, loss_ce: 0.007721
2021-12-11 21:47:59,152 iteration 5396 : loss : 0.019464, loss_ce: 0.007135
2021-12-11 21:48:00,754 iteration 5397 : loss : 0.022833, loss_ce: 0.008975
2021-12-11 21:48:02,421 iteration 5398 : loss : 0.025705, loss_ce: 0.008828
2021-12-11 21:48:04,009 iteration 5399 : loss : 0.023429, loss_ce: 0.008505
2021-12-11 21:48:05,510 iteration 5400 : loss : 0.020355, loss_ce: 0.007789
2021-12-11 21:48:07,084 iteration 5401 : loss : 0.018244, loss_ce: 0.009308
2021-12-11 21:48:08,601 iteration 5402 : loss : 0.017034, loss_ce: 0.008190
2021-12-11 21:48:10,149 iteration 5403 : loss : 0.021510, loss_ce: 0.012927
2021-12-11 21:48:11,712 iteration 5404 : loss : 0.014735, loss_ce: 0.005991
2021-12-11 21:48:13,370 iteration 5405 : loss : 0.024634, loss_ce: 0.008150
2021-12-11 21:48:14,862 iteration 5406 : loss : 0.015146, loss_ce: 0.006729
 80%|███████████████████████      | 318/400 [2:30:48<37:44, 27.61s/it]2021-12-11 21:48:16,402 iteration 5407 : loss : 0.021417, loss_ce: 0.008992
2021-12-11 21:48:17,952 iteration 5408 : loss : 0.018724, loss_ce: 0.007459
2021-12-11 21:48:19,404 iteration 5409 : loss : 0.014457, loss_ce: 0.004822
2021-12-11 21:48:20,957 iteration 5410 : loss : 0.024574, loss_ce: 0.008838
2021-12-11 21:48:22,450 iteration 5411 : loss : 0.017749, loss_ce: 0.006429
2021-12-11 21:48:24,006 iteration 5412 : loss : 0.020572, loss_ce: 0.008130
2021-12-11 21:48:25,519 iteration 5413 : loss : 0.016077, loss_ce: 0.006841
2021-12-11 21:48:27,063 iteration 5414 : loss : 0.014277, loss_ce: 0.005415
2021-12-11 21:48:28,701 iteration 5415 : loss : 0.025109, loss_ce: 0.009321
2021-12-11 21:48:30,200 iteration 5416 : loss : 0.016889, loss_ce: 0.005424
2021-12-11 21:48:31,724 iteration 5417 : loss : 0.016620, loss_ce: 0.005392
2021-12-11 21:48:33,340 iteration 5418 : loss : 0.017070, loss_ce: 0.006978
2021-12-11 21:48:34,817 iteration 5419 : loss : 0.020342, loss_ce: 0.007869
2021-12-11 21:48:36,291 iteration 5420 : loss : 0.015739, loss_ce: 0.006414
2021-12-11 21:48:37,875 iteration 5421 : loss : 0.018810, loss_ce: 0.006974
2021-12-11 21:48:39,480 iteration 5422 : loss : 0.023875, loss_ce: 0.005143
2021-12-11 21:48:41,072 iteration 5423 : loss : 0.025242, loss_ce: 0.009976
 80%|███████████████████████▏     | 319/400 [2:31:15<36:42, 27.20s/it]2021-12-11 21:48:42,656 iteration 5424 : loss : 0.019107, loss_ce: 0.005881
2021-12-11 21:48:44,167 iteration 5425 : loss : 0.027715, loss_ce: 0.005972
2021-12-11 21:48:45,752 iteration 5426 : loss : 0.021872, loss_ce: 0.009574
2021-12-11 21:48:47,246 iteration 5427 : loss : 0.016026, loss_ce: 0.004753
2021-12-11 21:48:48,754 iteration 5428 : loss : 0.015778, loss_ce: 0.005617
2021-12-11 21:48:50,269 iteration 5429 : loss : 0.020074, loss_ce: 0.007088
2021-12-11 21:48:51,911 iteration 5430 : loss : 0.017902, loss_ce: 0.005664
2021-12-11 21:48:53,427 iteration 5431 : loss : 0.023619, loss_ce: 0.008157
2021-12-11 21:48:54,943 iteration 5432 : loss : 0.018039, loss_ce: 0.007012
2021-12-11 21:48:56,536 iteration 5433 : loss : 0.027353, loss_ce: 0.011989
2021-12-11 21:48:58,058 iteration 5434 : loss : 0.018088, loss_ce: 0.006304
2021-12-11 21:48:59,700 iteration 5435 : loss : 0.024692, loss_ce: 0.011454
2021-12-11 21:49:01,226 iteration 5436 : loss : 0.016217, loss_ce: 0.006843
2021-12-11 21:49:02,645 iteration 5437 : loss : 0.014322, loss_ce: 0.005158
2021-12-11 21:49:04,280 iteration 5438 : loss : 0.018572, loss_ce: 0.006799
2021-12-11 21:49:05,795 iteration 5439 : loss : 0.012426, loss_ce: 0.004250
2021-12-11 21:49:05,795 Training Data Eval:
2021-12-11 21:49:13,438   Average segmentation loss on training set: 0.0114
2021-12-11 21:49:13,439 Validation Data Eval:
2021-12-11 21:49:16,080   Average segmentation loss on validation set: 0.0858
2021-12-11 21:49:17,667 iteration 5440 : loss : 0.027867, loss_ce: 0.007552
 80%|███████████████████████▏     | 320/400 [2:31:51<40:01, 30.02s/it]2021-12-11 21:49:19,143 iteration 5441 : loss : 0.014382, loss_ce: 0.004360
2021-12-11 21:49:20,700 iteration 5442 : loss : 0.029716, loss_ce: 0.012561
2021-12-11 21:49:22,273 iteration 5443 : loss : 0.013611, loss_ce: 0.004444
2021-12-11 21:49:23,833 iteration 5444 : loss : 0.014102, loss_ce: 0.004852
2021-12-11 21:49:25,465 iteration 5445 : loss : 0.027272, loss_ce: 0.011263
2021-12-11 21:49:26,977 iteration 5446 : loss : 0.020508, loss_ce: 0.005934
2021-12-11 21:49:28,504 iteration 5447 : loss : 0.026782, loss_ce: 0.013511
2021-12-11 21:49:30,054 iteration 5448 : loss : 0.021992, loss_ce: 0.008879
2021-12-11 21:49:31,590 iteration 5449 : loss : 0.018751, loss_ce: 0.005817
2021-12-11 21:49:33,183 iteration 5450 : loss : 0.022064, loss_ce: 0.011307
2021-12-11 21:49:34,717 iteration 5451 : loss : 0.018582, loss_ce: 0.008144
2021-12-11 21:49:36,313 iteration 5452 : loss : 0.020948, loss_ce: 0.008159
2021-12-11 21:49:37,870 iteration 5453 : loss : 0.018958, loss_ce: 0.007719
2021-12-11 21:49:39,311 iteration 5454 : loss : 0.011860, loss_ce: 0.005286
2021-12-11 21:49:40,947 iteration 5455 : loss : 0.024510, loss_ce: 0.009180
2021-12-11 21:49:42,546 iteration 5456 : loss : 0.019936, loss_ce: 0.007902
2021-12-11 21:49:44,086 iteration 5457 : loss : 0.017068, loss_ce: 0.006017
 80%|███████████████████████▎     | 321/400 [2:32:18<38:05, 28.94s/it]2021-12-11 21:49:45,635 iteration 5458 : loss : 0.017085, loss_ce: 0.007088
2021-12-11 21:49:47,145 iteration 5459 : loss : 0.016303, loss_ce: 0.006085
2021-12-11 21:49:48,719 iteration 5460 : loss : 0.021167, loss_ce: 0.008482
2021-12-11 21:49:50,345 iteration 5461 : loss : 0.021283, loss_ce: 0.008426
2021-12-11 21:49:51,899 iteration 5462 : loss : 0.017401, loss_ce: 0.004495
2021-12-11 21:49:53,407 iteration 5463 : loss : 0.018447, loss_ce: 0.006979
2021-12-11 21:49:54,928 iteration 5464 : loss : 0.020279, loss_ce: 0.007711
2021-12-11 21:49:56,414 iteration 5465 : loss : 0.018854, loss_ce: 0.006173
2021-12-11 21:49:58,031 iteration 5466 : loss : 0.017006, loss_ce: 0.007164
2021-12-11 21:49:59,548 iteration 5467 : loss : 0.018588, loss_ce: 0.008716
2021-12-11 21:50:01,102 iteration 5468 : loss : 0.025206, loss_ce: 0.011406
2021-12-11 21:50:02,587 iteration 5469 : loss : 0.012654, loss_ce: 0.004305
2021-12-11 21:50:04,168 iteration 5470 : loss : 0.018298, loss_ce: 0.006913
2021-12-11 21:50:05,707 iteration 5471 : loss : 0.017572, loss_ce: 0.005845
2021-12-11 21:50:07,296 iteration 5472 : loss : 0.017521, loss_ce: 0.006026
2021-12-11 21:50:08,903 iteration 5473 : loss : 0.024243, loss_ce: 0.007765
2021-12-11 21:50:10,472 iteration 5474 : loss : 0.022218, loss_ce: 0.008368
 80%|███████████████████████▎     | 322/400 [2:32:44<36:37, 28.17s/it]2021-12-11 21:50:12,034 iteration 5475 : loss : 0.012655, loss_ce: 0.003410
2021-12-11 21:50:13,536 iteration 5476 : loss : 0.023274, loss_ce: 0.007561
2021-12-11 21:50:15,043 iteration 5477 : loss : 0.013532, loss_ce: 0.005317
2021-12-11 21:50:16,571 iteration 5478 : loss : 0.017701, loss_ce: 0.007293
2021-12-11 21:50:18,209 iteration 5479 : loss : 0.021341, loss_ce: 0.009315
2021-12-11 21:50:19,822 iteration 5480 : loss : 0.022462, loss_ce: 0.008873
2021-12-11 21:50:21,363 iteration 5481 : loss : 0.015026, loss_ce: 0.004126
2021-12-11 21:50:22,900 iteration 5482 : loss : 0.013707, loss_ce: 0.004611
2021-12-11 21:50:24,456 iteration 5483 : loss : 0.016916, loss_ce: 0.006174
2021-12-11 21:50:25,957 iteration 5484 : loss : 0.015516, loss_ce: 0.005943
2021-12-11 21:50:27,393 iteration 5485 : loss : 0.013631, loss_ce: 0.004785
2021-12-11 21:50:29,016 iteration 5486 : loss : 0.023618, loss_ce: 0.009145
2021-12-11 21:50:30,694 iteration 5487 : loss : 0.018882, loss_ce: 0.006922
2021-12-11 21:50:32,235 iteration 5488 : loss : 0.018104, loss_ce: 0.006677
2021-12-11 21:50:33,761 iteration 5489 : loss : 0.014958, loss_ce: 0.005634
2021-12-11 21:50:35,268 iteration 5490 : loss : 0.033375, loss_ce: 0.012022
2021-12-11 21:50:36,801 iteration 5491 : loss : 0.017455, loss_ce: 0.006346
 81%|███████████████████████▍     | 323/400 [2:33:10<35:26, 27.62s/it]2021-12-11 21:50:38,421 iteration 5492 : loss : 0.018629, loss_ce: 0.006783
2021-12-11 21:50:39,928 iteration 5493 : loss : 0.018554, loss_ce: 0.008071
2021-12-11 21:50:41,413 iteration 5494 : loss : 0.023721, loss_ce: 0.005517
2021-12-11 21:50:43,006 iteration 5495 : loss : 0.031444, loss_ce: 0.004429
2021-12-11 21:50:44,506 iteration 5496 : loss : 0.015393, loss_ce: 0.005593
2021-12-11 21:50:46,039 iteration 5497 : loss : 0.016283, loss_ce: 0.005157
2021-12-11 21:50:47,610 iteration 5498 : loss : 0.028647, loss_ce: 0.017117
2021-12-11 21:50:49,147 iteration 5499 : loss : 0.019060, loss_ce: 0.007107
2021-12-11 21:50:50,727 iteration 5500 : loss : 0.021152, loss_ce: 0.007735
2021-12-11 21:50:52,365 iteration 5501 : loss : 0.026055, loss_ce: 0.009928
2021-12-11 21:50:53,947 iteration 5502 : loss : 0.022335, loss_ce: 0.010754
2021-12-11 21:50:55,490 iteration 5503 : loss : 0.024481, loss_ce: 0.007462
2021-12-11 21:50:57,062 iteration 5504 : loss : 0.019115, loss_ce: 0.008036
2021-12-11 21:50:58,609 iteration 5505 : loss : 0.017461, loss_ce: 0.006658
2021-12-11 21:51:00,107 iteration 5506 : loss : 0.018081, loss_ce: 0.006810
2021-12-11 21:51:01,671 iteration 5507 : loss : 0.020101, loss_ce: 0.006094
2021-12-11 21:51:03,225 iteration 5508 : loss : 0.017367, loss_ce: 0.007434
 81%|███████████████████████▍     | 324/400 [2:33:37<34:31, 27.26s/it]2021-12-11 21:51:04,795 iteration 5509 : loss : 0.020292, loss_ce: 0.006107
2021-12-11 21:51:06,473 iteration 5510 : loss : 0.021540, loss_ce: 0.006665
2021-12-11 21:51:08,018 iteration 5511 : loss : 0.020317, loss_ce: 0.010207
2021-12-11 21:51:09,652 iteration 5512 : loss : 0.024709, loss_ce: 0.004691
2021-12-11 21:51:11,147 iteration 5513 : loss : 0.016174, loss_ce: 0.003845
2021-12-11 21:51:12,735 iteration 5514 : loss : 0.019815, loss_ce: 0.007661
2021-12-11 21:51:14,357 iteration 5515 : loss : 0.023086, loss_ce: 0.006848
2021-12-11 21:51:15,812 iteration 5516 : loss : 0.014618, loss_ce: 0.005398
2021-12-11 21:51:17,380 iteration 5517 : loss : 0.022305, loss_ce: 0.006993
2021-12-11 21:51:18,911 iteration 5518 : loss : 0.020449, loss_ce: 0.008516
2021-12-11 21:51:20,426 iteration 5519 : loss : 0.015894, loss_ce: 0.005156
2021-12-11 21:51:21,993 iteration 5520 : loss : 0.031265, loss_ce: 0.012696
2021-12-11 21:51:23,670 iteration 5521 : loss : 0.020621, loss_ce: 0.007042
2021-12-11 21:51:25,137 iteration 5522 : loss : 0.013614, loss_ce: 0.005747
2021-12-11 21:51:26,733 iteration 5523 : loss : 0.028323, loss_ce: 0.015938
2021-12-11 21:51:28,297 iteration 5524 : loss : 0.029679, loss_ce: 0.012413
2021-12-11 21:51:28,298 Training Data Eval:
2021-12-11 21:51:35,946   Average segmentation loss on training set: 0.0116
2021-12-11 21:51:35,947 Validation Data Eval:
2021-12-11 21:51:38,587   Average segmentation loss on validation set: 0.0733
2021-12-11 21:51:40,180 iteration 5525 : loss : 0.023709, loss_ce: 0.009793
 81%|███████████████████████▌     | 325/400 [2:34:14<37:42, 30.17s/it]2021-12-11 21:51:41,864 iteration 5526 : loss : 0.022248, loss_ce: 0.008884
2021-12-11 21:51:43,419 iteration 5527 : loss : 0.017747, loss_ce: 0.005944
2021-12-11 21:51:44,987 iteration 5528 : loss : 0.016588, loss_ce: 0.005905
2021-12-11 21:51:46,503 iteration 5529 : loss : 0.014094, loss_ce: 0.005296
2021-12-11 21:51:47,982 iteration 5530 : loss : 0.013780, loss_ce: 0.003499
2021-12-11 21:51:49,537 iteration 5531 : loss : 0.014030, loss_ce: 0.005094
2021-12-11 21:51:50,997 iteration 5532 : loss : 0.017856, loss_ce: 0.005991
2021-12-11 21:51:52,576 iteration 5533 : loss : 0.016472, loss_ce: 0.006689
2021-12-11 21:51:54,135 iteration 5534 : loss : 0.024882, loss_ce: 0.008364
2021-12-11 21:51:55,696 iteration 5535 : loss : 0.017398, loss_ce: 0.006465
2021-12-11 21:51:57,223 iteration 5536 : loss : 0.021578, loss_ce: 0.006294
2021-12-11 21:51:58,759 iteration 5537 : loss : 0.018797, loss_ce: 0.005838
2021-12-11 21:52:00,293 iteration 5538 : loss : 0.016361, loss_ce: 0.008342
2021-12-11 21:52:01,840 iteration 5539 : loss : 0.019262, loss_ce: 0.007574
2021-12-11 21:52:03,411 iteration 5540 : loss : 0.012331, loss_ce: 0.003864
2021-12-11 21:52:04,887 iteration 5541 : loss : 0.018947, loss_ce: 0.008377
2021-12-11 21:52:06,399 iteration 5542 : loss : 0.015997, loss_ce: 0.006842
 82%|███████████████████████▋     | 326/400 [2:34:40<35:44, 28.98s/it]2021-12-11 21:52:08,034 iteration 5543 : loss : 0.024355, loss_ce: 0.009749
2021-12-11 21:52:09,681 iteration 5544 : loss : 0.028668, loss_ce: 0.007428
2021-12-11 21:52:11,294 iteration 5545 : loss : 0.035567, loss_ce: 0.015432
2021-12-11 21:52:12,800 iteration 5546 : loss : 0.011900, loss_ce: 0.005178
2021-12-11 21:52:14,367 iteration 5547 : loss : 0.015083, loss_ce: 0.005981
2021-12-11 21:52:15,877 iteration 5548 : loss : 0.014879, loss_ce: 0.005336
2021-12-11 21:52:17,405 iteration 5549 : loss : 0.018296, loss_ce: 0.006858
2021-12-11 21:52:18,977 iteration 5550 : loss : 0.023819, loss_ce: 0.009436
2021-12-11 21:52:20,540 iteration 5551 : loss : 0.017062, loss_ce: 0.003974
2021-12-11 21:52:22,186 iteration 5552 : loss : 0.032202, loss_ce: 0.010192
2021-12-11 21:52:23,762 iteration 5553 : loss : 0.019764, loss_ce: 0.007261
2021-12-11 21:52:25,403 iteration 5554 : loss : 0.026578, loss_ce: 0.007026
2021-12-11 21:52:27,019 iteration 5555 : loss : 0.020667, loss_ce: 0.007006
2021-12-11 21:52:28,614 iteration 5556 : loss : 0.019956, loss_ce: 0.007947
2021-12-11 21:52:30,195 iteration 5557 : loss : 0.027551, loss_ce: 0.008115
2021-12-11 21:52:31,719 iteration 5558 : loss : 0.020641, loss_ce: 0.007671
2021-12-11 21:52:33,195 iteration 5559 : loss : 0.014364, loss_ce: 0.004571
 82%|███████████████████████▋     | 327/400 [2:35:07<34:27, 28.33s/it]2021-12-11 21:52:34,771 iteration 5560 : loss : 0.018208, loss_ce: 0.006321
2021-12-11 21:52:36,392 iteration 5561 : loss : 0.019844, loss_ce: 0.005426
2021-12-11 21:52:37,947 iteration 5562 : loss : 0.017295, loss_ce: 0.005366
2021-12-11 21:52:39,552 iteration 5563 : loss : 0.028850, loss_ce: 0.010295
2021-12-11 21:52:41,018 iteration 5564 : loss : 0.019040, loss_ce: 0.005595
2021-12-11 21:52:42,578 iteration 5565 : loss : 0.023429, loss_ce: 0.007017
2021-12-11 21:52:44,112 iteration 5566 : loss : 0.016193, loss_ce: 0.005329
2021-12-11 21:52:45,698 iteration 5567 : loss : 0.017445, loss_ce: 0.009261
2021-12-11 21:52:47,280 iteration 5568 : loss : 0.020292, loss_ce: 0.009390
2021-12-11 21:52:48,862 iteration 5569 : loss : 0.018109, loss_ce: 0.008246
2021-12-11 21:52:50,403 iteration 5570 : loss : 0.016475, loss_ce: 0.007405
2021-12-11 21:52:51,950 iteration 5571 : loss : 0.018542, loss_ce: 0.005323
2021-12-11 21:52:53,394 iteration 5572 : loss : 0.014077, loss_ce: 0.004697
2021-12-11 21:52:54,965 iteration 5573 : loss : 0.023577, loss_ce: 0.008808
2021-12-11 21:52:56,462 iteration 5574 : loss : 0.014529, loss_ce: 0.005643
2021-12-11 21:52:57,932 iteration 5575 : loss : 0.014814, loss_ce: 0.005744
2021-12-11 21:52:59,394 iteration 5576 : loss : 0.017367, loss_ce: 0.005036
 82%|███████████████████████▊     | 328/400 [2:35:33<33:13, 27.69s/it]2021-12-11 21:53:01,026 iteration 5577 : loss : 0.026592, loss_ce: 0.008273
2021-12-11 21:53:02,587 iteration 5578 : loss : 0.014342, loss_ce: 0.004882
2021-12-11 21:53:04,243 iteration 5579 : loss : 0.044982, loss_ce: 0.010025
2021-12-11 21:53:05,850 iteration 5580 : loss : 0.018626, loss_ce: 0.006434
2021-12-11 21:53:07,418 iteration 5581 : loss : 0.021087, loss_ce: 0.009397
2021-12-11 21:53:08,949 iteration 5582 : loss : 0.016728, loss_ce: 0.006407
2021-12-11 21:53:10,438 iteration 5583 : loss : 0.011999, loss_ce: 0.003465
2021-12-11 21:53:11,959 iteration 5584 : loss : 0.019380, loss_ce: 0.008192
2021-12-11 21:53:13,429 iteration 5585 : loss : 0.016012, loss_ce: 0.005222
2021-12-11 21:53:14,919 iteration 5586 : loss : 0.015528, loss_ce: 0.005791
2021-12-11 21:53:16,533 iteration 5587 : loss : 0.022353, loss_ce: 0.009687
2021-12-11 21:53:18,109 iteration 5588 : loss : 0.023432, loss_ce: 0.008681
2021-12-11 21:53:19,716 iteration 5589 : loss : 0.025890, loss_ce: 0.008639
2021-12-11 21:53:21,201 iteration 5590 : loss : 0.022693, loss_ce: 0.009944
2021-12-11 21:53:22,772 iteration 5591 : loss : 0.027734, loss_ce: 0.009910
2021-12-11 21:53:24,336 iteration 5592 : loss : 0.021380, loss_ce: 0.008264
2021-12-11 21:53:25,793 iteration 5593 : loss : 0.015280, loss_ce: 0.007271
 82%|███████████████████████▊     | 329/400 [2:35:59<32:18, 27.30s/it]2021-12-11 21:53:27,381 iteration 5594 : loss : 0.013276, loss_ce: 0.003661
2021-12-11 21:53:28,866 iteration 5595 : loss : 0.015074, loss_ce: 0.005584
2021-12-11 21:53:30,473 iteration 5596 : loss : 0.028489, loss_ce: 0.008499
2021-12-11 21:53:32,032 iteration 5597 : loss : 0.017424, loss_ce: 0.006970
2021-12-11 21:53:33,695 iteration 5598 : loss : 0.024877, loss_ce: 0.011720
2021-12-11 21:53:35,332 iteration 5599 : loss : 0.021268, loss_ce: 0.006624
2021-12-11 21:53:36,821 iteration 5600 : loss : 0.017097, loss_ce: 0.006515
2021-12-11 21:53:38,378 iteration 5601 : loss : 0.024261, loss_ce: 0.008682
2021-12-11 21:53:39,924 iteration 5602 : loss : 0.023473, loss_ce: 0.008049
2021-12-11 21:53:41,479 iteration 5603 : loss : 0.035251, loss_ce: 0.016299
2021-12-11 21:53:43,013 iteration 5604 : loss : 0.019382, loss_ce: 0.006379
2021-12-11 21:53:44,509 iteration 5605 : loss : 0.017661, loss_ce: 0.007938
2021-12-11 21:53:46,083 iteration 5606 : loss : 0.025506, loss_ce: 0.008979
2021-12-11 21:53:47,605 iteration 5607 : loss : 0.016016, loss_ce: 0.007017
2021-12-11 21:53:49,167 iteration 5608 : loss : 0.014780, loss_ce: 0.006369
2021-12-11 21:53:50,670 iteration 5609 : loss : 0.017363, loss_ce: 0.005937
2021-12-11 21:53:50,671 Training Data Eval:
2021-12-11 21:53:58,299   Average segmentation loss on training set: 0.0126
2021-12-11 21:53:58,299 Validation Data Eval:
2021-12-11 21:54:00,942   Average segmentation loss on validation set: 0.0807
2021-12-11 21:54:02,557 iteration 5610 : loss : 0.025984, loss_ce: 0.010296
 82%|███████████████████████▉     | 330/400 [2:36:36<35:09, 30.14s/it]2021-12-11 21:54:04,084 iteration 5611 : loss : 0.011668, loss_ce: 0.004320
2021-12-11 21:54:05,680 iteration 5612 : loss : 0.026785, loss_ce: 0.009233
2021-12-11 21:54:07,188 iteration 5613 : loss : 0.018561, loss_ce: 0.003806
2021-12-11 21:54:08,709 iteration 5614 : loss : 0.020233, loss_ce: 0.008278
2021-12-11 21:54:10,233 iteration 5615 : loss : 0.021497, loss_ce: 0.009795
2021-12-11 21:54:11,774 iteration 5616 : loss : 0.014932, loss_ce: 0.004421
2021-12-11 21:54:13,470 iteration 5617 : loss : 0.038138, loss_ce: 0.012594
2021-12-11 21:54:15,070 iteration 5618 : loss : 0.029758, loss_ce: 0.008725
2021-12-11 21:54:16,618 iteration 5619 : loss : 0.014953, loss_ce: 0.006903
2021-12-11 21:54:18,111 iteration 5620 : loss : 0.017739, loss_ce: 0.006915
2021-12-11 21:54:19,586 iteration 5621 : loss : 0.016573, loss_ce: 0.005839
2021-12-11 21:54:21,063 iteration 5622 : loss : 0.014965, loss_ce: 0.006158
2021-12-11 21:54:22,667 iteration 5623 : loss : 0.014706, loss_ce: 0.004744
2021-12-11 21:54:24,189 iteration 5624 : loss : 0.016448, loss_ce: 0.006200
2021-12-11 21:54:25,718 iteration 5625 : loss : 0.028082, loss_ce: 0.012227
2021-12-11 21:54:27,286 iteration 5626 : loss : 0.022280, loss_ce: 0.007661
2021-12-11 21:54:28,826 iteration 5627 : loss : 0.017821, loss_ce: 0.007385
 83%|███████████████████████▉     | 331/400 [2:37:02<33:19, 28.98s/it]2021-12-11 21:54:30,402 iteration 5628 : loss : 0.013879, loss_ce: 0.006205
2021-12-11 21:54:31,956 iteration 5629 : loss : 0.026051, loss_ce: 0.009778
2021-12-11 21:54:33,526 iteration 5630 : loss : 0.016699, loss_ce: 0.006712
2021-12-11 21:54:35,086 iteration 5631 : loss : 0.020672, loss_ce: 0.009644
2021-12-11 21:54:36,701 iteration 5632 : loss : 0.016614, loss_ce: 0.006272
2021-12-11 21:54:38,156 iteration 5633 : loss : 0.021449, loss_ce: 0.004656
2021-12-11 21:54:39,760 iteration 5634 : loss : 0.027065, loss_ce: 0.006263
2021-12-11 21:54:41,300 iteration 5635 : loss : 0.017763, loss_ce: 0.006553
2021-12-11 21:54:42,766 iteration 5636 : loss : 0.019017, loss_ce: 0.005768
2021-12-11 21:54:44,393 iteration 5637 : loss : 0.017767, loss_ce: 0.008000
2021-12-11 21:54:45,928 iteration 5638 : loss : 0.017192, loss_ce: 0.007521
2021-12-11 21:54:47,488 iteration 5639 : loss : 0.018539, loss_ce: 0.005543
2021-12-11 21:54:49,033 iteration 5640 : loss : 0.018715, loss_ce: 0.006847
2021-12-11 21:54:50,559 iteration 5641 : loss : 0.015081, loss_ce: 0.004969
2021-12-11 21:54:52,194 iteration 5642 : loss : 0.021788, loss_ce: 0.009533
2021-12-11 21:54:53,636 iteration 5643 : loss : 0.018326, loss_ce: 0.008208
2021-12-11 21:54:55,158 iteration 5644 : loss : 0.019635, loss_ce: 0.008068
 83%|████████████████████████     | 332/400 [2:37:29<31:56, 28.19s/it]2021-12-11 21:54:56,679 iteration 5645 : loss : 0.020543, loss_ce: 0.005655
2021-12-11 21:54:58,189 iteration 5646 : loss : 0.017583, loss_ce: 0.004625
2021-12-11 21:54:59,659 iteration 5647 : loss : 0.012845, loss_ce: 0.004188
2021-12-11 21:55:01,194 iteration 5648 : loss : 0.022139, loss_ce: 0.009233
2021-12-11 21:55:02,691 iteration 5649 : loss : 0.012280, loss_ce: 0.003153
2021-12-11 21:55:04,284 iteration 5650 : loss : 0.019200, loss_ce: 0.008717
2021-12-11 21:55:05,866 iteration 5651 : loss : 0.018722, loss_ce: 0.008248
2021-12-11 21:55:07,402 iteration 5652 : loss : 0.018703, loss_ce: 0.005677
2021-12-11 21:55:08,925 iteration 5653 : loss : 0.019021, loss_ce: 0.005397
2021-12-11 21:55:10,456 iteration 5654 : loss : 0.017648, loss_ce: 0.006948
2021-12-11 21:55:11,901 iteration 5655 : loss : 0.017420, loss_ce: 0.008728
2021-12-11 21:55:13,529 iteration 5656 : loss : 0.038856, loss_ce: 0.010911
2021-12-11 21:55:15,129 iteration 5657 : loss : 0.029882, loss_ce: 0.010509
2021-12-11 21:55:16,721 iteration 5658 : loss : 0.026296, loss_ce: 0.011295
2021-12-11 21:55:18,217 iteration 5659 : loss : 0.017893, loss_ce: 0.006849
2021-12-11 21:55:19,784 iteration 5660 : loss : 0.031087, loss_ce: 0.008729
2021-12-11 21:55:21,317 iteration 5661 : loss : 0.019902, loss_ce: 0.007637
 83%|████████████████████████▏    | 333/400 [2:37:55<30:47, 27.58s/it]2021-12-11 21:55:22,887 iteration 5662 : loss : 0.019741, loss_ce: 0.007238
2021-12-11 21:55:24,427 iteration 5663 : loss : 0.017711, loss_ce: 0.005716
2021-12-11 21:55:25,975 iteration 5664 : loss : 0.019818, loss_ce: 0.009173
2021-12-11 21:55:27,454 iteration 5665 : loss : 0.015392, loss_ce: 0.005420
2021-12-11 21:55:29,015 iteration 5666 : loss : 0.023321, loss_ce: 0.005145
2021-12-11 21:55:30,604 iteration 5667 : loss : 0.020168, loss_ce: 0.006637
2021-12-11 21:55:32,163 iteration 5668 : loss : 0.018642, loss_ce: 0.006646
2021-12-11 21:55:33,639 iteration 5669 : loss : 0.019899, loss_ce: 0.006939
2021-12-11 21:55:35,160 iteration 5670 : loss : 0.024029, loss_ce: 0.009052
2021-12-11 21:55:36,643 iteration 5671 : loss : 0.017742, loss_ce: 0.006938
2021-12-11 21:55:38,279 iteration 5672 : loss : 0.025291, loss_ce: 0.011856
2021-12-11 21:55:39,790 iteration 5673 : loss : 0.020286, loss_ce: 0.006845
2021-12-11 21:55:41,329 iteration 5674 : loss : 0.016356, loss_ce: 0.004638
2021-12-11 21:55:42,818 iteration 5675 : loss : 0.014905, loss_ce: 0.006707
2021-12-11 21:55:44,406 iteration 5676 : loss : 0.022005, loss_ce: 0.008618
2021-12-11 21:55:45,929 iteration 5677 : loss : 0.022122, loss_ce: 0.005464
2021-12-11 21:55:47,562 iteration 5678 : loss : 0.018139, loss_ce: 0.006942
 84%|████████████████████████▏    | 334/400 [2:38:21<29:53, 27.18s/it]2021-12-11 21:55:49,181 iteration 5679 : loss : 0.017385, loss_ce: 0.005693
2021-12-11 21:55:50,676 iteration 5680 : loss : 0.016661, loss_ce: 0.006648
2021-12-11 21:55:52,219 iteration 5681 : loss : 0.016825, loss_ce: 0.006692
2021-12-11 21:55:53,799 iteration 5682 : loss : 0.026672, loss_ce: 0.008478
2021-12-11 21:55:55,362 iteration 5683 : loss : 0.031916, loss_ce: 0.014583
2021-12-11 21:55:56,965 iteration 5684 : loss : 0.023599, loss_ce: 0.007647
2021-12-11 21:55:58,544 iteration 5685 : loss : 0.013942, loss_ce: 0.003716
2021-12-11 21:56:00,079 iteration 5686 : loss : 0.021199, loss_ce: 0.007682
2021-12-11 21:56:01,581 iteration 5687 : loss : 0.015290, loss_ce: 0.004112
2021-12-11 21:56:03,106 iteration 5688 : loss : 0.019656, loss_ce: 0.005759
2021-12-11 21:56:04,626 iteration 5689 : loss : 0.018299, loss_ce: 0.008026
2021-12-11 21:56:06,186 iteration 5690 : loss : 0.018928, loss_ce: 0.009403
2021-12-11 21:56:07,705 iteration 5691 : loss : 0.014469, loss_ce: 0.003856
2021-12-11 21:56:09,208 iteration 5692 : loss : 0.015282, loss_ce: 0.005063
2021-12-11 21:56:10,817 iteration 5693 : loss : 0.019998, loss_ce: 0.009085
2021-12-11 21:56:12,396 iteration 5694 : loss : 0.025756, loss_ce: 0.009417
2021-12-11 21:56:12,397 Training Data Eval:
2021-12-11 21:56:20,033   Average segmentation loss on training set: 0.0105
2021-12-11 21:56:20,034 Validation Data Eval:
2021-12-11 21:56:22,673   Average segmentation loss on validation set: 0.0708
2021-12-11 21:56:24,185 iteration 5695 : loss : 0.022539, loss_ce: 0.007924
 84%|████████████████████████▎    | 335/400 [2:38:58<32:30, 30.01s/it]2021-12-11 21:56:25,742 iteration 5696 : loss : 0.014980, loss_ce: 0.004828
2021-12-11 21:56:27,375 iteration 5697 : loss : 0.023225, loss_ce: 0.009173
2021-12-11 21:56:28,926 iteration 5698 : loss : 0.018112, loss_ce: 0.008043
2021-12-11 21:56:30,536 iteration 5699 : loss : 0.021382, loss_ce: 0.007159
2021-12-11 21:56:32,089 iteration 5700 : loss : 0.015065, loss_ce: 0.005201
2021-12-11 21:56:33,616 iteration 5701 : loss : 0.017993, loss_ce: 0.009300
2021-12-11 21:56:35,174 iteration 5702 : loss : 0.011310, loss_ce: 0.003629
2021-12-11 21:56:36,701 iteration 5703 : loss : 0.013074, loss_ce: 0.005646
2021-12-11 21:56:38,278 iteration 5704 : loss : 0.018308, loss_ce: 0.008160
2021-12-11 21:56:39,856 iteration 5705 : loss : 0.014070, loss_ce: 0.004839
2021-12-11 21:56:41,361 iteration 5706 : loss : 0.020603, loss_ce: 0.003753
2021-12-11 21:56:43,013 iteration 5707 : loss : 0.029003, loss_ce: 0.011711
2021-12-11 21:56:44,534 iteration 5708 : loss : 0.021057, loss_ce: 0.009145
2021-12-11 21:56:46,092 iteration 5709 : loss : 0.023313, loss_ce: 0.010593
2021-12-11 21:56:47,724 iteration 5710 : loss : 0.020772, loss_ce: 0.008793
2021-12-11 21:56:49,244 iteration 5711 : loss : 0.020668, loss_ce: 0.010155
2021-12-11 21:56:50,769 iteration 5712 : loss : 0.018457, loss_ce: 0.007973
 84%|████████████████████████▎    | 336/400 [2:39:24<30:54, 28.98s/it]2021-12-11 21:56:52,302 iteration 5713 : loss : 0.017175, loss_ce: 0.004576
2021-12-11 21:56:53,814 iteration 5714 : loss : 0.017162, loss_ce: 0.006397
2021-12-11 21:56:55,314 iteration 5715 : loss : 0.013729, loss_ce: 0.005187
2021-12-11 21:56:56,902 iteration 5716 : loss : 0.015842, loss_ce: 0.006884
2021-12-11 21:56:58,483 iteration 5717 : loss : 0.018307, loss_ce: 0.006690
2021-12-11 21:56:59,958 iteration 5718 : loss : 0.022888, loss_ce: 0.006891
2021-12-11 21:57:01,529 iteration 5719 : loss : 0.014282, loss_ce: 0.005537
2021-12-11 21:57:03,042 iteration 5720 : loss : 0.017083, loss_ce: 0.007272
2021-12-11 21:57:04,469 iteration 5721 : loss : 0.015126, loss_ce: 0.004022
2021-12-11 21:57:05,996 iteration 5722 : loss : 0.016205, loss_ce: 0.006006
2021-12-11 21:57:07,519 iteration 5723 : loss : 0.016479, loss_ce: 0.006431
2021-12-11 21:57:09,070 iteration 5724 : loss : 0.012749, loss_ce: 0.004644
2021-12-11 21:57:10,644 iteration 5725 : loss : 0.013718, loss_ce: 0.005830
2021-12-11 21:57:12,154 iteration 5726 : loss : 0.014598, loss_ce: 0.006158
2021-12-11 21:57:13,680 iteration 5727 : loss : 0.019572, loss_ce: 0.007161
2021-12-11 21:57:15,183 iteration 5728 : loss : 0.023979, loss_ce: 0.011006
2021-12-11 21:57:16,757 iteration 5729 : loss : 0.016029, loss_ce: 0.005300
 84%|████████████████████████▍    | 337/400 [2:39:50<29:29, 28.08s/it]2021-12-11 21:57:18,341 iteration 5730 : loss : 0.022214, loss_ce: 0.007105
2021-12-11 21:57:19,924 iteration 5731 : loss : 0.013558, loss_ce: 0.004916
2021-12-11 21:57:21,457 iteration 5732 : loss : 0.019169, loss_ce: 0.005400
2021-12-11 21:57:22,950 iteration 5733 : loss : 0.017494, loss_ce: 0.004796
2021-12-11 21:57:24,486 iteration 5734 : loss : 0.023595, loss_ce: 0.008475
2021-12-11 21:57:26,031 iteration 5735 : loss : 0.019345, loss_ce: 0.010050
2021-12-11 21:57:27,556 iteration 5736 : loss : 0.023853, loss_ce: 0.012051
2021-12-11 21:57:29,072 iteration 5737 : loss : 0.020918, loss_ce: 0.008205
2021-12-11 21:57:30,620 iteration 5738 : loss : 0.011328, loss_ce: 0.004509
2021-12-11 21:57:32,097 iteration 5739 : loss : 0.015099, loss_ce: 0.006088
2021-12-11 21:57:33,660 iteration 5740 : loss : 0.018928, loss_ce: 0.006856
2021-12-11 21:57:35,215 iteration 5741 : loss : 0.019688, loss_ce: 0.009588
2021-12-11 21:57:36,758 iteration 5742 : loss : 0.017589, loss_ce: 0.007116
2021-12-11 21:57:38,271 iteration 5743 : loss : 0.015351, loss_ce: 0.006474
2021-12-11 21:57:39,868 iteration 5744 : loss : 0.017963, loss_ce: 0.007767
2021-12-11 21:57:41,409 iteration 5745 : loss : 0.015938, loss_ce: 0.004788
2021-12-11 21:57:42,870 iteration 5746 : loss : 0.016336, loss_ce: 0.003981
 84%|████████████████████████▌    | 338/400 [2:40:16<28:24, 27.49s/it]2021-12-11 21:57:44,471 iteration 5747 : loss : 0.014579, loss_ce: 0.004443
2021-12-11 21:57:46,049 iteration 5748 : loss : 0.017579, loss_ce: 0.006073
2021-12-11 21:57:47,637 iteration 5749 : loss : 0.018317, loss_ce: 0.007668
2021-12-11 21:57:49,261 iteration 5750 : loss : 0.020404, loss_ce: 0.005835
2021-12-11 21:57:50,732 iteration 5751 : loss : 0.015906, loss_ce: 0.006067
2021-12-11 21:57:52,301 iteration 5752 : loss : 0.020619, loss_ce: 0.006309
2021-12-11 21:57:53,833 iteration 5753 : loss : 0.018816, loss_ce: 0.006780
2021-12-11 21:57:55,306 iteration 5754 : loss : 0.013635, loss_ce: 0.005233
2021-12-11 21:57:56,841 iteration 5755 : loss : 0.029648, loss_ce: 0.015433
2021-12-11 21:57:58,375 iteration 5756 : loss : 0.016153, loss_ce: 0.004758
2021-12-11 21:57:59,929 iteration 5757 : loss : 0.014329, loss_ce: 0.006987
2021-12-11 21:58:01,458 iteration 5758 : loss : 0.019706, loss_ce: 0.004117
2021-12-11 21:58:02,991 iteration 5759 : loss : 0.020104, loss_ce: 0.009504
2021-12-11 21:58:04,604 iteration 5760 : loss : 0.021784, loss_ce: 0.007928
2021-12-11 21:58:06,063 iteration 5761 : loss : 0.013412, loss_ce: 0.004866
2021-12-11 21:58:07,769 iteration 5762 : loss : 0.020683, loss_ce: 0.008363
2021-12-11 21:58:09,289 iteration 5763 : loss : 0.017431, loss_ce: 0.006424
 85%|████████████████████████▌    | 339/400 [2:40:43<27:37, 27.17s/it]2021-12-11 21:58:10,874 iteration 5764 : loss : 0.018267, loss_ce: 0.006617
2021-12-11 21:58:12,453 iteration 5765 : loss : 0.021287, loss_ce: 0.005812
2021-12-11 21:58:14,011 iteration 5766 : loss : 0.013230, loss_ce: 0.005324
2021-12-11 21:58:15,580 iteration 5767 : loss : 0.017229, loss_ce: 0.006303
2021-12-11 21:58:17,297 iteration 5768 : loss : 0.023645, loss_ce: 0.007405
2021-12-11 21:58:18,831 iteration 5769 : loss : 0.013468, loss_ce: 0.005604
2021-12-11 21:58:20,360 iteration 5770 : loss : 0.017542, loss_ce: 0.006820
2021-12-11 21:58:21,888 iteration 5771 : loss : 0.016070, loss_ce: 0.007484
2021-12-11 21:58:23,436 iteration 5772 : loss : 0.020381, loss_ce: 0.007210
2021-12-11 21:58:25,059 iteration 5773 : loss : 0.016612, loss_ce: 0.007442
2021-12-11 21:58:26,663 iteration 5774 : loss : 0.019456, loss_ce: 0.008189
2021-12-11 21:58:28,279 iteration 5775 : loss : 0.019049, loss_ce: 0.006736
2021-12-11 21:58:29,783 iteration 5776 : loss : 0.014957, loss_ce: 0.004780
2021-12-11 21:58:31,298 iteration 5777 : loss : 0.019022, loss_ce: 0.007356
2021-12-11 21:58:32,872 iteration 5778 : loss : 0.019757, loss_ce: 0.005576
2021-12-11 21:58:34,390 iteration 5779 : loss : 0.018358, loss_ce: 0.007225
2021-12-11 21:58:34,390 Training Data Eval:
2021-12-11 21:58:42,026   Average segmentation loss on training set: 0.0106
2021-12-11 21:58:42,027 Validation Data Eval:
2021-12-11 21:58:44,659   Average segmentation loss on validation set: 0.0771
2021-12-11 21:58:46,244 iteration 5780 : loss : 0.013941, loss_ce: 0.004753
 85%|████████████████████████▋    | 340/400 [2:41:20<30:06, 30.11s/it]2021-12-11 21:58:47,943 iteration 5781 : loss : 0.032230, loss_ce: 0.009470
2021-12-11 21:58:49,397 iteration 5782 : loss : 0.016856, loss_ce: 0.008966
2021-12-11 21:58:50,882 iteration 5783 : loss : 0.017666, loss_ce: 0.007516
2021-12-11 21:58:52,381 iteration 5784 : loss : 0.015158, loss_ce: 0.005220
2021-12-11 21:58:53,848 iteration 5785 : loss : 0.014655, loss_ce: 0.006429
2021-12-11 21:58:55,390 iteration 5786 : loss : 0.020595, loss_ce: 0.004699
2021-12-11 21:58:56,915 iteration 5787 : loss : 0.017268, loss_ce: 0.006800
2021-12-11 21:58:58,355 iteration 5788 : loss : 0.013755, loss_ce: 0.005050
2021-12-11 21:58:59,821 iteration 5789 : loss : 0.011423, loss_ce: 0.004413
2021-12-11 21:59:01,381 iteration 5790 : loss : 0.011342, loss_ce: 0.004074
2021-12-11 21:59:02,910 iteration 5791 : loss : 0.014559, loss_ce: 0.006202
2021-12-11 21:59:04,393 iteration 5792 : loss : 0.014797, loss_ce: 0.005511
2021-12-11 21:59:05,990 iteration 5793 : loss : 0.018241, loss_ce: 0.005463
2021-12-11 21:59:07,597 iteration 5794 : loss : 0.017369, loss_ce: 0.007020
2021-12-11 21:59:09,092 iteration 5795 : loss : 0.011810, loss_ce: 0.004976
2021-12-11 21:59:10,647 iteration 5796 : loss : 0.015592, loss_ce: 0.006454
2021-12-11 21:59:12,188 iteration 5797 : loss : 0.016917, loss_ce: 0.006089
 85%|████████████████████████▋    | 341/400 [2:41:46<28:22, 28.86s/it]2021-12-11 21:59:13,861 iteration 5798 : loss : 0.022541, loss_ce: 0.006087
2021-12-11 21:59:15,390 iteration 5799 : loss : 0.015908, loss_ce: 0.004567
2021-12-11 21:59:16,915 iteration 5800 : loss : 0.029287, loss_ce: 0.007004
2021-12-11 21:59:18,359 iteration 5801 : loss : 0.012725, loss_ce: 0.004165
2021-12-11 21:59:19,912 iteration 5802 : loss : 0.015429, loss_ce: 0.007513
2021-12-11 21:59:21,378 iteration 5803 : loss : 0.013605, loss_ce: 0.004454
2021-12-11 21:59:23,012 iteration 5804 : loss : 0.029280, loss_ce: 0.010860
2021-12-11 21:59:24,512 iteration 5805 : loss : 0.017639, loss_ce: 0.007959
2021-12-11 21:59:26,002 iteration 5806 : loss : 0.017210, loss_ce: 0.007265
2021-12-11 21:59:27,548 iteration 5807 : loss : 0.013472, loss_ce: 0.004992
2021-12-11 21:59:29,060 iteration 5808 : loss : 0.024268, loss_ce: 0.010044
2021-12-11 21:59:30,690 iteration 5809 : loss : 0.029547, loss_ce: 0.009458
2021-12-11 21:59:32,163 iteration 5810 : loss : 0.022935, loss_ce: 0.006076
2021-12-11 21:59:33,680 iteration 5811 : loss : 0.016740, loss_ce: 0.006987
2021-12-11 21:59:35,292 iteration 5812 : loss : 0.019587, loss_ce: 0.008480
2021-12-11 21:59:36,788 iteration 5813 : loss : 0.022624, loss_ce: 0.007044
2021-12-11 21:59:38,320 iteration 5814 : loss : 0.016522, loss_ce: 0.006537
 86%|████████████████████████▊    | 342/400 [2:42:12<27:06, 28.04s/it]2021-12-11 21:59:40,002 iteration 5815 : loss : 0.025894, loss_ce: 0.010182
2021-12-11 21:59:41,466 iteration 5816 : loss : 0.019775, loss_ce: 0.005620
2021-12-11 21:59:43,021 iteration 5817 : loss : 0.014970, loss_ce: 0.004178
2021-12-11 21:59:44,538 iteration 5818 : loss : 0.020149, loss_ce: 0.005912
2021-12-11 21:59:46,178 iteration 5819 : loss : 0.018545, loss_ce: 0.007765
2021-12-11 21:59:47,719 iteration 5820 : loss : 0.016140, loss_ce: 0.006949
2021-12-11 21:59:49,227 iteration 5821 : loss : 0.016496, loss_ce: 0.006344
2021-12-11 21:59:50,803 iteration 5822 : loss : 0.021944, loss_ce: 0.005449
2021-12-11 21:59:52,400 iteration 5823 : loss : 0.014930, loss_ce: 0.004994
2021-12-11 21:59:53,939 iteration 5824 : loss : 0.015087, loss_ce: 0.005107
2021-12-11 21:59:55,474 iteration 5825 : loss : 0.020239, loss_ce: 0.008495
2021-12-11 21:59:56,969 iteration 5826 : loss : 0.021303, loss_ce: 0.006760
2021-12-11 21:59:58,456 iteration 5827 : loss : 0.019109, loss_ce: 0.004625
2021-12-11 21:59:59,912 iteration 5828 : loss : 0.011245, loss_ce: 0.004712
2021-12-11 22:00:01,445 iteration 5829 : loss : 0.020658, loss_ce: 0.007583
2021-12-11 22:00:02,989 iteration 5830 : loss : 0.021367, loss_ce: 0.008277
2021-12-11 22:00:04,580 iteration 5831 : loss : 0.016680, loss_ce: 0.006450
 86%|████████████████████████▊    | 343/400 [2:42:38<26:07, 27.51s/it]2021-12-11 22:00:06,252 iteration 5832 : loss : 0.024232, loss_ce: 0.008377
2021-12-11 22:00:07,761 iteration 5833 : loss : 0.013883, loss_ce: 0.004445
2021-12-11 22:00:09,377 iteration 5834 : loss : 0.020354, loss_ce: 0.008534
2021-12-11 22:00:11,068 iteration 5835 : loss : 0.029007, loss_ce: 0.010983
2021-12-11 22:00:12,580 iteration 5836 : loss : 0.018691, loss_ce: 0.007395
2021-12-11 22:00:14,193 iteration 5837 : loss : 0.027201, loss_ce: 0.013503
2021-12-11 22:00:15,803 iteration 5838 : loss : 0.025884, loss_ce: 0.006692
2021-12-11 22:00:17,265 iteration 5839 : loss : 0.018347, loss_ce: 0.006004
2021-12-11 22:00:19,010 iteration 5840 : loss : 0.020228, loss_ce: 0.009357
2021-12-11 22:00:20,522 iteration 5841 : loss : 0.011669, loss_ce: 0.004656
2021-12-11 22:00:22,177 iteration 5842 : loss : 0.020667, loss_ce: 0.008084
2021-12-11 22:00:23,824 iteration 5843 : loss : 0.019658, loss_ce: 0.005821
2021-12-11 22:00:25,382 iteration 5844 : loss : 0.021306, loss_ce: 0.006149
2021-12-11 22:00:26,968 iteration 5845 : loss : 0.022566, loss_ce: 0.007653
2021-12-11 22:00:28,500 iteration 5846 : loss : 0.014728, loss_ce: 0.005996
2021-12-11 22:00:30,027 iteration 5847 : loss : 0.012661, loss_ce: 0.004027
2021-12-11 22:00:31,485 iteration 5848 : loss : 0.014111, loss_ce: 0.004056
 86%|████████████████████████▉    | 344/400 [2:43:05<25:30, 27.32s/it]2021-12-11 22:00:33,005 iteration 5849 : loss : 0.015945, loss_ce: 0.005128
2021-12-11 22:00:34,615 iteration 5850 : loss : 0.024683, loss_ce: 0.007024
2021-12-11 22:00:36,106 iteration 5851 : loss : 0.015160, loss_ce: 0.005819
2021-12-11 22:00:37,607 iteration 5852 : loss : 0.015566, loss_ce: 0.005022
2021-12-11 22:00:39,076 iteration 5853 : loss : 0.022191, loss_ce: 0.006456
2021-12-11 22:00:40,651 iteration 5854 : loss : 0.021043, loss_ce: 0.007694
2021-12-11 22:00:42,176 iteration 5855 : loss : 0.020487, loss_ce: 0.005973
2021-12-11 22:00:43,658 iteration 5856 : loss : 0.017494, loss_ce: 0.006888
2021-12-11 22:00:45,236 iteration 5857 : loss : 0.017451, loss_ce: 0.007327
2021-12-11 22:00:46,747 iteration 5858 : loss : 0.020698, loss_ce: 0.005199
2021-12-11 22:00:48,316 iteration 5859 : loss : 0.023253, loss_ce: 0.012965
2021-12-11 22:00:49,878 iteration 5860 : loss : 0.016670, loss_ce: 0.006412
2021-12-11 22:00:51,425 iteration 5861 : loss : 0.019151, loss_ce: 0.008407
2021-12-11 22:00:52,941 iteration 5862 : loss : 0.017479, loss_ce: 0.006482
2021-12-11 22:00:54,464 iteration 5863 : loss : 0.018261, loss_ce: 0.006995
2021-12-11 22:00:55,986 iteration 5864 : loss : 0.016459, loss_ce: 0.006121
2021-12-11 22:00:55,987 Training Data Eval:
2021-12-11 22:01:03,635   Average segmentation loss on training set: 0.0109
2021-12-11 22:01:03,635 Validation Data Eval:
2021-12-11 22:01:06,278   Average segmentation loss on validation set: 0.0724
2021-12-11 22:01:07,789 iteration 5865 : loss : 0.013556, loss_ce: 0.004421
 86%|█████████████████████████    | 345/400 [2:43:41<27:31, 30.02s/it]2021-12-11 22:01:09,379 iteration 5866 : loss : 0.022286, loss_ce: 0.007528
2021-12-11 22:01:10,922 iteration 5867 : loss : 0.015651, loss_ce: 0.006486
2021-12-11 22:01:12,393 iteration 5868 : loss : 0.013159, loss_ce: 0.004823
2021-12-11 22:01:13,895 iteration 5869 : loss : 0.012690, loss_ce: 0.004538
2021-12-11 22:01:15,350 iteration 5870 : loss : 0.015779, loss_ce: 0.005946
2021-12-11 22:01:16,865 iteration 5871 : loss : 0.016127, loss_ce: 0.006395
2021-12-11 22:01:18,388 iteration 5872 : loss : 0.013574, loss_ce: 0.005835
2021-12-11 22:01:19,843 iteration 5873 : loss : 0.013183, loss_ce: 0.005984
2021-12-11 22:01:21,309 iteration 5874 : loss : 0.023621, loss_ce: 0.005122
2021-12-11 22:01:22,913 iteration 5875 : loss : 0.016634, loss_ce: 0.006387
2021-12-11 22:01:24,531 iteration 5876 : loss : 0.021965, loss_ce: 0.009396
2021-12-11 22:01:26,088 iteration 5877 : loss : 0.021395, loss_ce: 0.008135
2021-12-11 22:01:27,679 iteration 5878 : loss : 0.021587, loss_ce: 0.007257
2021-12-11 22:01:29,176 iteration 5879 : loss : 0.019619, loss_ce: 0.005574
2021-12-11 22:01:30,693 iteration 5880 : loss : 0.018419, loss_ce: 0.006461
2021-12-11 22:01:32,269 iteration 5881 : loss : 0.025395, loss_ce: 0.007936
2021-12-11 22:01:33,786 iteration 5882 : loss : 0.016732, loss_ce: 0.005767
 86%|█████████████████████████    | 346/400 [2:44:07<25:55, 28.81s/it]2021-12-11 22:01:35,461 iteration 5883 : loss : 0.017727, loss_ce: 0.006129
2021-12-11 22:01:36,947 iteration 5884 : loss : 0.015446, loss_ce: 0.005509
2021-12-11 22:01:38,546 iteration 5885 : loss : 0.021396, loss_ce: 0.005593
2021-12-11 22:01:40,039 iteration 5886 : loss : 0.013060, loss_ce: 0.004593
2021-12-11 22:01:41,596 iteration 5887 : loss : 0.017614, loss_ce: 0.005374
2021-12-11 22:01:43,035 iteration 5888 : loss : 0.014670, loss_ce: 0.006189
2021-12-11 22:01:44,539 iteration 5889 : loss : 0.013603, loss_ce: 0.005676
2021-12-11 22:01:46,110 iteration 5890 : loss : 0.017240, loss_ce: 0.007455
2021-12-11 22:01:47,690 iteration 5891 : loss : 0.023318, loss_ce: 0.006745
2021-12-11 22:01:49,292 iteration 5892 : loss : 0.015929, loss_ce: 0.007506
2021-12-11 22:01:50,757 iteration 5893 : loss : 0.011950, loss_ce: 0.003173
2021-12-11 22:01:52,247 iteration 5894 : loss : 0.017013, loss_ce: 0.005140
2021-12-11 22:01:53,815 iteration 5895 : loss : 0.019238, loss_ce: 0.007851
2021-12-11 22:01:55,265 iteration 5896 : loss : 0.013805, loss_ce: 0.004572
2021-12-11 22:01:56,858 iteration 5897 : loss : 0.016557, loss_ce: 0.008399
2021-12-11 22:01:58,442 iteration 5898 : loss : 0.018073, loss_ce: 0.007478
2021-12-11 22:01:59,965 iteration 5899 : loss : 0.017621, loss_ce: 0.005956
 87%|█████████████████████████▏   | 347/400 [2:44:34<24:45, 28.02s/it]2021-12-11 22:02:01,438 iteration 5900 : loss : 0.013254, loss_ce: 0.005558
2021-12-11 22:02:02,927 iteration 5901 : loss : 0.013401, loss_ce: 0.005456
2021-12-11 22:02:04,374 iteration 5902 : loss : 0.012988, loss_ce: 0.004931
2021-12-11 22:02:05,873 iteration 5903 : loss : 0.018992, loss_ce: 0.007781
2021-12-11 22:02:07,424 iteration 5904 : loss : 0.021202, loss_ce: 0.005986
2021-12-11 22:02:09,014 iteration 5905 : loss : 0.019724, loss_ce: 0.009525
2021-12-11 22:02:10,613 iteration 5906 : loss : 0.018748, loss_ce: 0.004923
2021-12-11 22:02:12,080 iteration 5907 : loss : 0.012658, loss_ce: 0.005330
2021-12-11 22:02:13,606 iteration 5908 : loss : 0.020616, loss_ce: 0.006426
2021-12-11 22:02:15,211 iteration 5909 : loss : 0.014983, loss_ce: 0.007676
2021-12-11 22:02:16,749 iteration 5910 : loss : 0.012630, loss_ce: 0.003966
2021-12-11 22:02:18,323 iteration 5911 : loss : 0.019153, loss_ce: 0.004511
2021-12-11 22:02:19,881 iteration 5912 : loss : 0.021198, loss_ce: 0.005164
2021-12-11 22:02:21,410 iteration 5913 : loss : 0.015396, loss_ce: 0.006566
2021-12-11 22:02:22,932 iteration 5914 : loss : 0.014914, loss_ce: 0.006917
2021-12-11 22:02:24,497 iteration 5915 : loss : 0.016693, loss_ce: 0.008177
2021-12-11 22:02:25,982 iteration 5916 : loss : 0.013129, loss_ce: 0.004592
 87%|█████████████████████████▏   | 348/400 [2:45:00<23:45, 27.42s/it]2021-12-11 22:02:27,497 iteration 5917 : loss : 0.014830, loss_ce: 0.005624
2021-12-11 22:02:29,101 iteration 5918 : loss : 0.025178, loss_ce: 0.013240
2021-12-11 22:02:30,724 iteration 5919 : loss : 0.018994, loss_ce: 0.006656
2021-12-11 22:02:32,339 iteration 5920 : loss : 0.021756, loss_ce: 0.006681
2021-12-11 22:02:33,867 iteration 5921 : loss : 0.019017, loss_ce: 0.006658
2021-12-11 22:02:35,454 iteration 5922 : loss : 0.018009, loss_ce: 0.008437
2021-12-11 22:02:37,007 iteration 5923 : loss : 0.015959, loss_ce: 0.006589
2021-12-11 22:02:38,463 iteration 5924 : loss : 0.014040, loss_ce: 0.004940
2021-12-11 22:02:39,978 iteration 5925 : loss : 0.015290, loss_ce: 0.004638
2021-12-11 22:02:41,577 iteration 5926 : loss : 0.026815, loss_ce: 0.007456
2021-12-11 22:02:43,072 iteration 5927 : loss : 0.012226, loss_ce: 0.004799
2021-12-11 22:02:44,677 iteration 5928 : loss : 0.014676, loss_ce: 0.006190
2021-12-11 22:02:46,249 iteration 5929 : loss : 0.016195, loss_ce: 0.007089
2021-12-11 22:02:47,855 iteration 5930 : loss : 0.020704, loss_ce: 0.007153
2021-12-11 22:02:49,341 iteration 5931 : loss : 0.020752, loss_ce: 0.007969
2021-12-11 22:02:50,890 iteration 5932 : loss : 0.019958, loss_ce: 0.007390
2021-12-11 22:02:52,468 iteration 5933 : loss : 0.023370, loss_ce: 0.006674
 87%|█████████████████████████▎   | 349/400 [2:45:26<23:04, 27.14s/it]2021-12-11 22:02:54,069 iteration 5934 : loss : 0.012688, loss_ce: 0.003938
2021-12-11 22:02:55,624 iteration 5935 : loss : 0.014098, loss_ce: 0.004130
2021-12-11 22:02:57,274 iteration 5936 : loss : 0.023562, loss_ce: 0.008024
2021-12-11 22:02:58,889 iteration 5937 : loss : 0.023745, loss_ce: 0.011329
2021-12-11 22:03:00,450 iteration 5938 : loss : 0.025639, loss_ce: 0.008666
2021-12-11 22:03:02,020 iteration 5939 : loss : 0.016820, loss_ce: 0.006329
2021-12-11 22:03:03,588 iteration 5940 : loss : 0.017237, loss_ce: 0.007105
2021-12-11 22:03:05,042 iteration 5941 : loss : 0.014371, loss_ce: 0.006385
2021-12-11 22:03:06,621 iteration 5942 : loss : 0.017190, loss_ce: 0.005558
2021-12-11 22:03:08,100 iteration 5943 : loss : 0.012249, loss_ce: 0.004231
2021-12-11 22:03:09,638 iteration 5944 : loss : 0.016409, loss_ce: 0.005962
2021-12-11 22:03:11,152 iteration 5945 : loss : 0.016288, loss_ce: 0.005614
2021-12-11 22:03:12,635 iteration 5946 : loss : 0.020756, loss_ce: 0.007152
2021-12-11 22:03:14,111 iteration 5947 : loss : 0.013746, loss_ce: 0.004929
2021-12-11 22:03:15,701 iteration 5948 : loss : 0.017857, loss_ce: 0.007132
2021-12-11 22:03:17,197 iteration 5949 : loss : 0.012783, loss_ce: 0.005130
2021-12-11 22:03:17,197 Training Data Eval:
2021-12-11 22:03:24,861   Average segmentation loss on training set: 0.0101
2021-12-11 22:03:24,862 Validation Data Eval:
2021-12-11 22:03:27,501   Average segmentation loss on validation set: 0.0769
2021-12-11 22:03:29,123 iteration 5950 : loss : 0.019767, loss_ce: 0.005033
2021-12-11 22:03:31,079 save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/NEW_TU/UNET_ADAM_seed100epoch_349.pth
 88%|█████████████████████████▍   | 350/400 [2:46:05<25:28, 30.57s/it]2021-12-11 22:03:32,496 iteration 5951 : loss : 0.017600, loss_ce: 0.005392
2021-12-11 22:03:33,956 iteration 5952 : loss : 0.024415, loss_ce: 0.012391
2021-12-11 22:03:35,470 iteration 5953 : loss : 0.019065, loss_ce: 0.007977
2021-12-11 22:03:37,066 iteration 5954 : loss : 0.021245, loss_ce: 0.006923
2021-12-11 22:03:38,586 iteration 5955 : loss : 0.014843, loss_ce: 0.005559
2021-12-11 22:03:40,206 iteration 5956 : loss : 0.019403, loss_ce: 0.007234
2021-12-11 22:03:41,733 iteration 5957 : loss : 0.017839, loss_ce: 0.005616
2021-12-11 22:03:43,237 iteration 5958 : loss : 0.013445, loss_ce: 0.005631
2021-12-11 22:03:44,760 iteration 5959 : loss : 0.014939, loss_ce: 0.004681
2021-12-11 22:03:46,253 iteration 5960 : loss : 0.011130, loss_ce: 0.003368
2021-12-11 22:03:47,803 iteration 5961 : loss : 0.017485, loss_ce: 0.006546
2021-12-11 22:03:49,396 iteration 5962 : loss : 0.016592, loss_ce: 0.006380
2021-12-11 22:03:50,859 iteration 5963 : loss : 0.012322, loss_ce: 0.005215
2021-12-11 22:03:52,582 iteration 5964 : loss : 0.023843, loss_ce: 0.009574
2021-12-11 22:03:54,101 iteration 5965 : loss : 0.015541, loss_ce: 0.005636
2021-12-11 22:03:55,685 iteration 5966 : loss : 0.017349, loss_ce: 0.006187
2021-12-11 22:03:57,187 iteration 5967 : loss : 0.022288, loss_ce: 0.007340
 88%|█████████████████████████▍   | 351/400 [2:46:31<23:52, 29.24s/it]2021-12-11 22:03:58,740 iteration 5968 : loss : 0.018900, loss_ce: 0.007929
2021-12-11 22:04:00,321 iteration 5969 : loss : 0.020697, loss_ce: 0.006475
2021-12-11 22:04:01,878 iteration 5970 : loss : 0.016549, loss_ce: 0.005469
2021-12-11 22:04:03,348 iteration 5971 : loss : 0.013105, loss_ce: 0.005220
2021-12-11 22:04:04,847 iteration 5972 : loss : 0.014008, loss_ce: 0.005165
2021-12-11 22:04:06,397 iteration 5973 : loss : 0.012078, loss_ce: 0.004966
2021-12-11 22:04:07,889 iteration 5974 : loss : 0.017095, loss_ce: 0.005619
2021-12-11 22:04:09,466 iteration 5975 : loss : 0.021326, loss_ce: 0.006582
2021-12-11 22:04:11,016 iteration 5976 : loss : 0.026971, loss_ce: 0.006896
2021-12-11 22:04:12,577 iteration 5977 : loss : 0.016511, loss_ce: 0.006453
2021-12-11 22:04:14,129 iteration 5978 : loss : 0.015200, loss_ce: 0.005927
2021-12-11 22:04:15,626 iteration 5979 : loss : 0.013034, loss_ce: 0.004947
2021-12-11 22:04:17,216 iteration 5980 : loss : 0.010106, loss_ce: 0.003334
2021-12-11 22:04:18,784 iteration 5981 : loss : 0.016185, loss_ce: 0.006229
2021-12-11 22:04:20,368 iteration 5982 : loss : 0.025279, loss_ce: 0.009205
2021-12-11 22:04:21,858 iteration 5983 : loss : 0.014295, loss_ce: 0.006422
2021-12-11 22:04:23,346 iteration 5984 : loss : 0.016304, loss_ce: 0.004629
 88%|█████████████████████████▌   | 352/400 [2:46:57<22:39, 28.32s/it]2021-12-11 22:04:25,028 iteration 5985 : loss : 0.026349, loss_ce: 0.013344
2021-12-11 22:04:26,540 iteration 5986 : loss : 0.014548, loss_ce: 0.006028
2021-12-11 22:04:28,139 iteration 5987 : loss : 0.035238, loss_ce: 0.006679
2021-12-11 22:04:29,767 iteration 5988 : loss : 0.016375, loss_ce: 0.007612
2021-12-11 22:04:31,295 iteration 5989 : loss : 0.014815, loss_ce: 0.005649
2021-12-11 22:04:32,865 iteration 5990 : loss : 0.015936, loss_ce: 0.008398
2021-12-11 22:04:34,326 iteration 5991 : loss : 0.012735, loss_ce: 0.004323
2021-12-11 22:04:35,900 iteration 5992 : loss : 0.018534, loss_ce: 0.005337
2021-12-11 22:04:37,390 iteration 5993 : loss : 0.009658, loss_ce: 0.003084
2021-12-11 22:04:38,914 iteration 5994 : loss : 0.020487, loss_ce: 0.006302
2021-12-11 22:04:40,472 iteration 5995 : loss : 0.026886, loss_ce: 0.012065
2021-12-11 22:04:42,086 iteration 5996 : loss : 0.017313, loss_ce: 0.005698
2021-12-11 22:04:43,704 iteration 5997 : loss : 0.019163, loss_ce: 0.008441
2021-12-11 22:04:45,207 iteration 5998 : loss : 0.013362, loss_ce: 0.004378
2021-12-11 22:04:46,772 iteration 5999 : loss : 0.025781, loss_ce: 0.007689
2021-12-11 22:04:48,346 iteration 6000 : loss : 0.019717, loss_ce: 0.008536
2021-12-11 22:04:49,955 iteration 6001 : loss : 0.022743, loss_ce: 0.007271
 88%|█████████████████████████▌   | 353/400 [2:47:24<21:46, 27.81s/it]2021-12-11 22:04:51,617 iteration 6002 : loss : 0.014064, loss_ce: 0.005681
2021-12-11 22:04:53,215 iteration 6003 : loss : 0.016242, loss_ce: 0.006058
2021-12-11 22:04:54,758 iteration 6004 : loss : 0.014905, loss_ce: 0.006787
2021-12-11 22:04:56,349 iteration 6005 : loss : 0.013527, loss_ce: 0.005965
2021-12-11 22:04:57,822 iteration 6006 : loss : 0.018862, loss_ce: 0.009128
2021-12-11 22:04:59,356 iteration 6007 : loss : 0.015003, loss_ce: 0.004759
2021-12-11 22:05:00,889 iteration 6008 : loss : 0.018073, loss_ce: 0.006984
2021-12-11 22:05:02,526 iteration 6009 : loss : 0.028874, loss_ce: 0.011764
2021-12-11 22:05:03,970 iteration 6010 : loss : 0.012896, loss_ce: 0.005005
2021-12-11 22:05:05,535 iteration 6011 : loss : 0.020724, loss_ce: 0.007086
2021-12-11 22:05:07,070 iteration 6012 : loss : 0.022611, loss_ce: 0.006577
2021-12-11 22:05:08,782 iteration 6013 : loss : 0.032302, loss_ce: 0.011011
2021-12-11 22:05:10,320 iteration 6014 : loss : 0.014788, loss_ce: 0.005276
2021-12-11 22:05:11,832 iteration 6015 : loss : 0.019198, loss_ce: 0.006570
2021-12-11 22:05:13,380 iteration 6016 : loss : 0.013450, loss_ce: 0.003720
2021-12-11 22:05:14,874 iteration 6017 : loss : 0.020285, loss_ce: 0.005977
2021-12-11 22:05:16,511 iteration 6018 : loss : 0.019713, loss_ce: 0.008059
 88%|█████████████████████████▋   | 354/400 [2:47:50<21:01, 27.43s/it]2021-12-11 22:05:18,130 iteration 6019 : loss : 0.023844, loss_ce: 0.008489
2021-12-11 22:05:19,674 iteration 6020 : loss : 0.015653, loss_ce: 0.006127
2021-12-11 22:05:21,205 iteration 6021 : loss : 0.015162, loss_ce: 0.005341
2021-12-11 22:05:22,771 iteration 6022 : loss : 0.012797, loss_ce: 0.004834
2021-12-11 22:05:24,226 iteration 6023 : loss : 0.011366, loss_ce: 0.003728
2021-12-11 22:05:25,833 iteration 6024 : loss : 0.023245, loss_ce: 0.010244
2021-12-11 22:05:27,431 iteration 6025 : loss : 0.025223, loss_ce: 0.009809
2021-12-11 22:05:29,015 iteration 6026 : loss : 0.022759, loss_ce: 0.009188
2021-12-11 22:05:30,531 iteration 6027 : loss : 0.014887, loss_ce: 0.006050
2021-12-11 22:05:32,020 iteration 6028 : loss : 0.016798, loss_ce: 0.007215
2021-12-11 22:05:33,617 iteration 6029 : loss : 0.022437, loss_ce: 0.009848
2021-12-11 22:05:35,104 iteration 6030 : loss : 0.013574, loss_ce: 0.004896
2021-12-11 22:05:36,747 iteration 6031 : loss : 0.026185, loss_ce: 0.006988
2021-12-11 22:05:38,358 iteration 6032 : loss : 0.016617, loss_ce: 0.005436
2021-12-11 22:05:39,943 iteration 6033 : loss : 0.019840, loss_ce: 0.009189
2021-12-11 22:05:41,568 iteration 6034 : loss : 0.014243, loss_ce: 0.004643
2021-12-11 22:05:41,569 Training Data Eval:
2021-12-11 22:05:49,198   Average segmentation loss on training set: 0.0103
2021-12-11 22:05:49,199 Validation Data Eval:
2021-12-11 22:05:51,836   Average segmentation loss on validation set: 0.0743
2021-12-11 22:05:53,316 iteration 6035 : loss : 0.020180, loss_ce: 0.005347
 89%|█████████████████████████▋   | 355/400 [2:48:27<22:40, 30.24s/it]2021-12-11 22:05:54,979 iteration 6036 : loss : 0.017173, loss_ce: 0.005794
2021-12-11 22:05:56,587 iteration 6037 : loss : 0.019321, loss_ce: 0.007131
2021-12-11 22:05:58,101 iteration 6038 : loss : 0.016769, loss_ce: 0.006435
2021-12-11 22:05:59,664 iteration 6039 : loss : 0.020789, loss_ce: 0.009290
2021-12-11 22:06:01,204 iteration 6040 : loss : 0.017257, loss_ce: 0.007714
2021-12-11 22:06:02,874 iteration 6041 : loss : 0.027808, loss_ce: 0.010757
2021-12-11 22:06:04,484 iteration 6042 : loss : 0.015836, loss_ce: 0.006173
2021-12-11 22:06:06,032 iteration 6043 : loss : 0.014069, loss_ce: 0.006428
2021-12-11 22:06:07,571 iteration 6044 : loss : 0.016991, loss_ce: 0.005745
2021-12-11 22:06:09,167 iteration 6045 : loss : 0.018474, loss_ce: 0.006221
2021-12-11 22:06:10,716 iteration 6046 : loss : 0.017802, loss_ce: 0.005226
2021-12-11 22:06:12,254 iteration 6047 : loss : 0.017791, loss_ce: 0.004839
2021-12-11 22:06:13,903 iteration 6048 : loss : 0.036006, loss_ce: 0.006733
2021-12-11 22:06:15,497 iteration 6049 : loss : 0.021167, loss_ce: 0.009226
2021-12-11 22:06:17,008 iteration 6050 : loss : 0.014503, loss_ce: 0.005900
2021-12-11 22:06:18,613 iteration 6051 : loss : 0.017299, loss_ce: 0.007577
2021-12-11 22:06:20,066 iteration 6052 : loss : 0.015051, loss_ce: 0.003869
 89%|█████████████████████████▊   | 356/400 [2:48:54<21:24, 29.19s/it]2021-12-11 22:06:21,619 iteration 6053 : loss : 0.015177, loss_ce: 0.007099
2021-12-11 22:06:23,255 iteration 6054 : loss : 0.029583, loss_ce: 0.010417
2021-12-11 22:06:24,780 iteration 6055 : loss : 0.013969, loss_ce: 0.004758
2021-12-11 22:06:26,289 iteration 6056 : loss : 0.019950, loss_ce: 0.007649
2021-12-11 22:06:27,792 iteration 6057 : loss : 0.013996, loss_ce: 0.004736
2021-12-11 22:06:29,391 iteration 6058 : loss : 0.013492, loss_ce: 0.005416
2021-12-11 22:06:30,870 iteration 6059 : loss : 0.012373, loss_ce: 0.004605
2021-12-11 22:06:32,471 iteration 6060 : loss : 0.015480, loss_ce: 0.007057
2021-12-11 22:06:33,957 iteration 6061 : loss : 0.017551, loss_ce: 0.007802
2021-12-11 22:06:35,593 iteration 6062 : loss : 0.015442, loss_ce: 0.007546
2021-12-11 22:06:37,227 iteration 6063 : loss : 0.020990, loss_ce: 0.007055
2021-12-11 22:06:38,774 iteration 6064 : loss : 0.032286, loss_ce: 0.008123
2021-12-11 22:06:40,403 iteration 6065 : loss : 0.017540, loss_ce: 0.008337
2021-12-11 22:06:41,956 iteration 6066 : loss : 0.015098, loss_ce: 0.005421
2021-12-11 22:06:43,472 iteration 6067 : loss : 0.034643, loss_ce: 0.005201
2021-12-11 22:06:45,103 iteration 6068 : loss : 0.023046, loss_ce: 0.006995
2021-12-11 22:06:46,615 iteration 6069 : loss : 0.045224, loss_ce: 0.003996
 89%|█████████████████████████▉   | 357/400 [2:49:20<20:21, 28.40s/it]2021-12-11 22:06:48,242 iteration 6070 : loss : 0.020530, loss_ce: 0.009736
2021-12-11 22:06:49,832 iteration 6071 : loss : 0.018688, loss_ce: 0.005033
2021-12-11 22:06:51,382 iteration 6072 : loss : 0.019457, loss_ce: 0.005179
2021-12-11 22:06:52,959 iteration 6073 : loss : 0.022612, loss_ce: 0.008054
2021-12-11 22:06:54,525 iteration 6074 : loss : 0.013052, loss_ce: 0.003730
2021-12-11 22:06:56,138 iteration 6075 : loss : 0.020151, loss_ce: 0.007663
2021-12-11 22:06:57,649 iteration 6076 : loss : 0.017018, loss_ce: 0.007594
2021-12-11 22:06:59,152 iteration 6077 : loss : 0.017270, loss_ce: 0.007611
2021-12-11 22:07:00,689 iteration 6078 : loss : 0.024784, loss_ce: 0.008735
2021-12-11 22:07:02,241 iteration 6079 : loss : 0.023732, loss_ce: 0.004963
2021-12-11 22:07:03,781 iteration 6080 : loss : 0.015458, loss_ce: 0.004894
2021-12-11 22:07:05,246 iteration 6081 : loss : 0.021356, loss_ce: 0.008279
2021-12-11 22:07:06,848 iteration 6082 : loss : 0.021345, loss_ce: 0.008345
2021-12-11 22:07:08,472 iteration 6083 : loss : 0.024551, loss_ce: 0.010002
2021-12-11 22:07:09,965 iteration 6084 : loss : 0.017090, loss_ce: 0.005227
2021-12-11 22:07:11,456 iteration 6085 : loss : 0.019306, loss_ce: 0.009223
2021-12-11 22:07:13,146 iteration 6086 : loss : 0.027349, loss_ce: 0.009326
 90%|█████████████████████████▉   | 358/400 [2:49:47<19:29, 27.84s/it]2021-12-11 22:07:14,714 iteration 6087 : loss : 0.026992, loss_ce: 0.008350
2021-12-11 22:07:16,259 iteration 6088 : loss : 0.015477, loss_ce: 0.004859
2021-12-11 22:07:17,848 iteration 6089 : loss : 0.019780, loss_ce: 0.009472
2021-12-11 22:07:19,357 iteration 6090 : loss : 0.015227, loss_ce: 0.004959
2021-12-11 22:07:20,852 iteration 6091 : loss : 0.011113, loss_ce: 0.003163
2021-12-11 22:07:22,470 iteration 6092 : loss : 0.026630, loss_ce: 0.010758
2021-12-11 22:07:24,127 iteration 6093 : loss : 0.019237, loss_ce: 0.007719
2021-12-11 22:07:25,727 iteration 6094 : loss : 0.018708, loss_ce: 0.008711
2021-12-11 22:07:27,194 iteration 6095 : loss : 0.019972, loss_ce: 0.004701
2021-12-11 22:07:28,818 iteration 6096 : loss : 0.020027, loss_ce: 0.004554
2021-12-11 22:07:30,307 iteration 6097 : loss : 0.014970, loss_ce: 0.007567
2021-12-11 22:07:31,913 iteration 6098 : loss : 0.016340, loss_ce: 0.008961
2021-12-11 22:07:33,446 iteration 6099 : loss : 0.018640, loss_ce: 0.009668
2021-12-11 22:07:35,012 iteration 6100 : loss : 0.025108, loss_ce: 0.007749
2021-12-11 22:07:36,639 iteration 6101 : loss : 0.022152, loss_ce: 0.009664
2021-12-11 22:07:38,135 iteration 6102 : loss : 0.014290, loss_ce: 0.005765
2021-12-11 22:07:39,692 iteration 6103 : loss : 0.026674, loss_ce: 0.007720
 90%|██████████████████████████   | 359/400 [2:50:13<18:45, 27.45s/it]2021-12-11 22:07:41,311 iteration 6104 : loss : 0.015628, loss_ce: 0.006060
2021-12-11 22:07:42,823 iteration 6105 : loss : 0.015137, loss_ce: 0.004396
2021-12-11 22:07:44,313 iteration 6106 : loss : 0.011946, loss_ce: 0.004773
2021-12-11 22:07:45,803 iteration 6107 : loss : 0.014004, loss_ce: 0.005478
2021-12-11 22:07:47,338 iteration 6108 : loss : 0.016897, loss_ce: 0.005686
2021-12-11 22:07:48,921 iteration 6109 : loss : 0.017483, loss_ce: 0.007498
2021-12-11 22:07:50,402 iteration 6110 : loss : 0.015612, loss_ce: 0.007077
2021-12-11 22:07:51,949 iteration 6111 : loss : 0.021401, loss_ce: 0.007187
2021-12-11 22:07:53,539 iteration 6112 : loss : 0.016944, loss_ce: 0.005153
2021-12-11 22:07:55,071 iteration 6113 : loss : 0.017048, loss_ce: 0.005594
2021-12-11 22:07:56,610 iteration 6114 : loss : 0.016891, loss_ce: 0.006947
2021-12-11 22:07:58,222 iteration 6115 : loss : 0.015184, loss_ce: 0.004867
2021-12-11 22:07:59,756 iteration 6116 : loss : 0.016483, loss_ce: 0.005689
2021-12-11 22:08:01,296 iteration 6117 : loss : 0.017357, loss_ce: 0.006868
2021-12-11 22:08:02,854 iteration 6118 : loss : 0.016330, loss_ce: 0.008367
2021-12-11 22:08:04,385 iteration 6119 : loss : 0.018448, loss_ce: 0.007035
2021-12-11 22:08:04,386 Training Data Eval:
2021-12-11 22:08:12,004   Average segmentation loss on training set: 0.0106
2021-12-11 22:08:12,005 Validation Data Eval:
2021-12-11 22:08:14,639   Average segmentation loss on validation set: 0.0818
2021-12-11 22:08:16,265 iteration 6120 : loss : 0.016894, loss_ce: 0.006248
 90%|██████████████████████████   | 360/400 [2:50:50<20:07, 30.19s/it]2021-12-11 22:08:17,893 iteration 6121 : loss : 0.018561, loss_ce: 0.005835
2021-12-11 22:08:19,443 iteration 6122 : loss : 0.017229, loss_ce: 0.007284
2021-12-11 22:08:20,972 iteration 6123 : loss : 0.019306, loss_ce: 0.006764
2021-12-11 22:08:22,598 iteration 6124 : loss : 0.023816, loss_ce: 0.008703
2021-12-11 22:08:24,152 iteration 6125 : loss : 0.015598, loss_ce: 0.004699
2021-12-11 22:08:25,812 iteration 6126 : loss : 0.019756, loss_ce: 0.008362
2021-12-11 22:08:27,465 iteration 6127 : loss : 0.021708, loss_ce: 0.010730
2021-12-11 22:08:28,996 iteration 6128 : loss : 0.016109, loss_ce: 0.005775
2021-12-11 22:08:30,491 iteration 6129 : loss : 0.015382, loss_ce: 0.005009
2021-12-11 22:08:32,046 iteration 6130 : loss : 0.019100, loss_ce: 0.007795
2021-12-11 22:08:33,543 iteration 6131 : loss : 0.020942, loss_ce: 0.005722
2021-12-11 22:08:35,176 iteration 6132 : loss : 0.020227, loss_ce: 0.006356
2021-12-11 22:08:36,767 iteration 6133 : loss : 0.019633, loss_ce: 0.009015
2021-12-11 22:08:38,289 iteration 6134 : loss : 0.014513, loss_ce: 0.005126
2021-12-11 22:08:39,779 iteration 6135 : loss : 0.015601, loss_ce: 0.007484
2021-12-11 22:08:41,271 iteration 6136 : loss : 0.011835, loss_ce: 0.003537
2021-12-11 22:08:42,773 iteration 6137 : loss : 0.020044, loss_ce: 0.006940
 90%|██████████████████████████▏  | 361/400 [2:51:16<18:54, 29.08s/it]2021-12-11 22:08:44,308 iteration 6138 : loss : 0.018920, loss_ce: 0.006203
2021-12-11 22:08:45,814 iteration 6139 : loss : 0.016376, loss_ce: 0.003905
2021-12-11 22:08:47,309 iteration 6140 : loss : 0.014255, loss_ce: 0.005054
2021-12-11 22:08:48,775 iteration 6141 : loss : 0.017050, loss_ce: 0.007663
2021-12-11 22:08:50,344 iteration 6142 : loss : 0.020108, loss_ce: 0.008060
2021-12-11 22:08:51,831 iteration 6143 : loss : 0.018910, loss_ce: 0.009101
2021-12-11 22:08:53,450 iteration 6144 : loss : 0.019245, loss_ce: 0.008323
2021-12-11 22:08:54,946 iteration 6145 : loss : 0.017943, loss_ce: 0.007894
2021-12-11 22:08:56,406 iteration 6146 : loss : 0.013448, loss_ce: 0.004212
2021-12-11 22:08:57,927 iteration 6147 : loss : 0.014279, loss_ce: 0.005348
2021-12-11 22:08:59,445 iteration 6148 : loss : 0.013854, loss_ce: 0.005670
2021-12-11 22:09:00,931 iteration 6149 : loss : 0.011851, loss_ce: 0.004256
2021-12-11 22:09:02,503 iteration 6150 : loss : 0.016888, loss_ce: 0.006271
2021-12-11 22:09:04,209 iteration 6151 : loss : 0.017957, loss_ce: 0.004320
2021-12-11 22:09:05,734 iteration 6152 : loss : 0.013827, loss_ce: 0.005734
2021-12-11 22:09:07,291 iteration 6153 : loss : 0.016661, loss_ce: 0.007745
2021-12-11 22:09:08,909 iteration 6154 : loss : 0.021778, loss_ce: 0.008199
 90%|██████████████████████████▏  | 362/400 [2:51:43<17:51, 28.20s/it]2021-12-11 22:09:10,567 iteration 6155 : loss : 0.017689, loss_ce: 0.006929
2021-12-11 22:09:12,062 iteration 6156 : loss : 0.012379, loss_ce: 0.005322
2021-12-11 22:09:13,592 iteration 6157 : loss : 0.011690, loss_ce: 0.003478
2021-12-11 22:09:15,154 iteration 6158 : loss : 0.013985, loss_ce: 0.005009
2021-12-11 22:09:16,648 iteration 6159 : loss : 0.015189, loss_ce: 0.005445
2021-12-11 22:09:18,172 iteration 6160 : loss : 0.015696, loss_ce: 0.006667
2021-12-11 22:09:19,730 iteration 6161 : loss : 0.016493, loss_ce: 0.004737
2021-12-11 22:09:21,382 iteration 6162 : loss : 0.022529, loss_ce: 0.004397
2021-12-11 22:09:22,928 iteration 6163 : loss : 0.017663, loss_ce: 0.007536
2021-12-11 22:09:24,517 iteration 6164 : loss : 0.021625, loss_ce: 0.008582
2021-12-11 22:09:26,052 iteration 6165 : loss : 0.026499, loss_ce: 0.011686
2021-12-11 22:09:27,580 iteration 6166 : loss : 0.015625, loss_ce: 0.006698
2021-12-11 22:09:29,089 iteration 6167 : loss : 0.015399, loss_ce: 0.005888
2021-12-11 22:09:30,666 iteration 6168 : loss : 0.019692, loss_ce: 0.007588
2021-12-11 22:09:32,233 iteration 6169 : loss : 0.016354, loss_ce: 0.004607
2021-12-11 22:09:33,746 iteration 6170 : loss : 0.020005, loss_ce: 0.007665
2021-12-11 22:09:35,246 iteration 6171 : loss : 0.015044, loss_ce: 0.005812
 91%|██████████████████████████▎  | 363/400 [2:52:09<17:02, 27.64s/it]2021-12-11 22:09:36,784 iteration 6172 : loss : 0.012907, loss_ce: 0.004360
2021-12-11 22:09:38,417 iteration 6173 : loss : 0.019504, loss_ce: 0.006965
2021-12-11 22:09:39,955 iteration 6174 : loss : 0.016449, loss_ce: 0.006181
2021-12-11 22:09:41,534 iteration 6175 : loss : 0.022651, loss_ce: 0.009354
2021-12-11 22:09:43,080 iteration 6176 : loss : 0.019006, loss_ce: 0.007930
2021-12-11 22:09:44,709 iteration 6177 : loss : 0.024609, loss_ce: 0.009751
2021-12-11 22:09:46,248 iteration 6178 : loss : 0.017982, loss_ce: 0.006877
2021-12-11 22:09:47,786 iteration 6179 : loss : 0.013664, loss_ce: 0.006397
2021-12-11 22:09:49,333 iteration 6180 : loss : 0.014825, loss_ce: 0.005294
2021-12-11 22:09:50,804 iteration 6181 : loss : 0.012643, loss_ce: 0.004048
2021-12-11 22:09:52,349 iteration 6182 : loss : 0.021495, loss_ce: 0.005142
2021-12-11 22:09:53,968 iteration 6183 : loss : 0.017745, loss_ce: 0.007242
2021-12-11 22:09:55,541 iteration 6184 : loss : 0.024342, loss_ce: 0.008819
2021-12-11 22:09:57,065 iteration 6185 : loss : 0.021296, loss_ce: 0.007923
2021-12-11 22:09:58,626 iteration 6186 : loss : 0.017896, loss_ce: 0.005709
2021-12-11 22:10:00,227 iteration 6187 : loss : 0.013927, loss_ce: 0.004611
2021-12-11 22:10:01,679 iteration 6188 : loss : 0.014174, loss_ce: 0.004670
 91%|██████████████████████████▍  | 364/400 [2:52:35<16:22, 27.28s/it]2021-12-11 22:10:03,176 iteration 6189 : loss : 0.012211, loss_ce: 0.003690
2021-12-11 22:10:04,620 iteration 6190 : loss : 0.015666, loss_ce: 0.005800
2021-12-11 22:10:06,295 iteration 6191 : loss : 0.030875, loss_ce: 0.011094
2021-12-11 22:10:07,870 iteration 6192 : loss : 0.013114, loss_ce: 0.004984
2021-12-11 22:10:09,311 iteration 6193 : loss : 0.011324, loss_ce: 0.004034
2021-12-11 22:10:10,830 iteration 6194 : loss : 0.016128, loss_ce: 0.005686
2021-12-11 22:10:12,408 iteration 6195 : loss : 0.016059, loss_ce: 0.006019
2021-12-11 22:10:13,997 iteration 6196 : loss : 0.015375, loss_ce: 0.007415
2021-12-11 22:10:15,552 iteration 6197 : loss : 0.020848, loss_ce: 0.012310
2021-12-11 22:10:17,093 iteration 6198 : loss : 0.014651, loss_ce: 0.005247
2021-12-11 22:10:18,648 iteration 6199 : loss : 0.016979, loss_ce: 0.005228
2021-12-11 22:10:20,100 iteration 6200 : loss : 0.011027, loss_ce: 0.005004
2021-12-11 22:10:21,636 iteration 6201 : loss : 0.025520, loss_ce: 0.008214
2021-12-11 22:10:23,114 iteration 6202 : loss : 0.014211, loss_ce: 0.006079
2021-12-11 22:10:24,615 iteration 6203 : loss : 0.016384, loss_ce: 0.004432
2021-12-11 22:10:26,177 iteration 6204 : loss : 0.013771, loss_ce: 0.005840
2021-12-11 22:10:26,178 Training Data Eval:
2021-12-11 22:10:33,823   Average segmentation loss on training set: 0.0096
2021-12-11 22:10:33,824 Validation Data Eval:
2021-12-11 22:10:36,466   Average segmentation loss on validation set: 0.0768
2021-12-11 22:10:38,023 iteration 6205 : loss : 0.019609, loss_ce: 0.005682
 91%|██████████████████████████▍  | 365/400 [2:53:12<17:30, 30.00s/it]2021-12-11 22:10:39,627 iteration 6206 : loss : 0.016274, loss_ce: 0.007280
2021-12-11 22:10:41,166 iteration 6207 : loss : 0.020203, loss_ce: 0.006014
2021-12-11 22:10:42,781 iteration 6208 : loss : 0.020730, loss_ce: 0.007025
2021-12-11 22:10:44,306 iteration 6209 : loss : 0.018128, loss_ce: 0.005036
2021-12-11 22:10:45,802 iteration 6210 : loss : 0.015621, loss_ce: 0.005816
2021-12-11 22:10:47,385 iteration 6211 : loss : 0.022769, loss_ce: 0.009928
2021-12-11 22:10:48,882 iteration 6212 : loss : 0.013434, loss_ce: 0.004587
2021-12-11 22:10:50,392 iteration 6213 : loss : 0.016371, loss_ce: 0.004533
2021-12-11 22:10:51,908 iteration 6214 : loss : 0.029844, loss_ce: 0.006245
2021-12-11 22:10:53,474 iteration 6215 : loss : 0.018124, loss_ce: 0.008596
2021-12-11 22:10:55,011 iteration 6216 : loss : 0.019141, loss_ce: 0.005641
2021-12-11 22:10:56,469 iteration 6217 : loss : 0.014082, loss_ce: 0.004557
2021-12-11 22:10:58,011 iteration 6218 : loss : 0.012132, loss_ce: 0.004828
2021-12-11 22:10:59,520 iteration 6219 : loss : 0.018016, loss_ce: 0.006225
2021-12-11 22:11:01,051 iteration 6220 : loss : 0.016641, loss_ce: 0.004736
2021-12-11 22:11:02,688 iteration 6221 : loss : 0.017603, loss_ce: 0.007824
2021-12-11 22:11:04,243 iteration 6222 : loss : 0.015692, loss_ce: 0.007653
 92%|██████████████████████████▌  | 366/400 [2:53:38<16:21, 28.87s/it]2021-12-11 22:11:05,851 iteration 6223 : loss : 0.025635, loss_ce: 0.005637
2021-12-11 22:11:07,364 iteration 6224 : loss : 0.014761, loss_ce: 0.004362
2021-12-11 22:11:08,898 iteration 6225 : loss : 0.031027, loss_ce: 0.015227
2021-12-11 22:11:10,537 iteration 6226 : loss : 0.022276, loss_ce: 0.007549
2021-12-11 22:11:12,063 iteration 6227 : loss : 0.013591, loss_ce: 0.003373
2021-12-11 22:11:13,612 iteration 6228 : loss : 0.017219, loss_ce: 0.006980
2021-12-11 22:11:15,086 iteration 6229 : loss : 0.013807, loss_ce: 0.005514
2021-12-11 22:11:16,589 iteration 6230 : loss : 0.019328, loss_ce: 0.007793
2021-12-11 22:11:18,121 iteration 6231 : loss : 0.016889, loss_ce: 0.007304
2021-12-11 22:11:19,663 iteration 6232 : loss : 0.013850, loss_ce: 0.005820
2021-12-11 22:11:21,195 iteration 6233 : loss : 0.018691, loss_ce: 0.007846
2021-12-11 22:11:22,758 iteration 6234 : loss : 0.017199, loss_ce: 0.006348
2021-12-11 22:11:24,377 iteration 6235 : loss : 0.020997, loss_ce: 0.004666
2021-12-11 22:11:25,825 iteration 6236 : loss : 0.012860, loss_ce: 0.005163
2021-12-11 22:11:27,371 iteration 6237 : loss : 0.015884, loss_ce: 0.006277
2021-12-11 22:11:28,844 iteration 6238 : loss : 0.009919, loss_ce: 0.003354
2021-12-11 22:11:30,345 iteration 6239 : loss : 0.014068, loss_ce: 0.005880
 92%|██████████████████████████▌  | 367/400 [2:54:04<15:25, 28.04s/it]2021-12-11 22:11:31,970 iteration 6240 : loss : 0.017741, loss_ce: 0.007304
2021-12-11 22:11:33,557 iteration 6241 : loss : 0.017966, loss_ce: 0.007512
2021-12-11 22:11:35,146 iteration 6242 : loss : 0.017511, loss_ce: 0.006762
2021-12-11 22:11:36,614 iteration 6243 : loss : 0.012270, loss_ce: 0.004269
2021-12-11 22:11:38,112 iteration 6244 : loss : 0.013453, loss_ce: 0.004147
2021-12-11 22:11:39,630 iteration 6245 : loss : 0.014951, loss_ce: 0.005600
2021-12-11 22:11:41,118 iteration 6246 : loss : 0.016099, loss_ce: 0.005915
2021-12-11 22:11:42,616 iteration 6247 : loss : 0.016477, loss_ce: 0.003872
2021-12-11 22:11:44,253 iteration 6248 : loss : 0.016605, loss_ce: 0.007235
2021-12-11 22:11:45,768 iteration 6249 : loss : 0.016742, loss_ce: 0.006565
2021-12-11 22:11:47,339 iteration 6250 : loss : 0.022109, loss_ce: 0.009081
2021-12-11 22:11:48,965 iteration 6251 : loss : 0.017043, loss_ce: 0.006723
2021-12-11 22:11:50,540 iteration 6252 : loss : 0.021393, loss_ce: 0.006049
2021-12-11 22:11:52,042 iteration 6253 : loss : 0.015712, loss_ce: 0.005177
2021-12-11 22:11:53,513 iteration 6254 : loss : 0.011184, loss_ce: 0.004609
2021-12-11 22:11:55,109 iteration 6255 : loss : 0.015359, loss_ce: 0.005989
2021-12-11 22:11:56,637 iteration 6256 : loss : 0.013260, loss_ce: 0.004706
 92%|██████████████████████████▋  | 368/400 [2:54:30<14:40, 27.51s/it]2021-12-11 22:11:58,246 iteration 6257 : loss : 0.012556, loss_ce: 0.003880
2021-12-11 22:11:59,719 iteration 6258 : loss : 0.012601, loss_ce: 0.004138
2021-12-11 22:12:01,311 iteration 6259 : loss : 0.015783, loss_ce: 0.005335
2021-12-11 22:12:02,967 iteration 6260 : loss : 0.033394, loss_ce: 0.007805
2021-12-11 22:12:04,509 iteration 6261 : loss : 0.017050, loss_ce: 0.006283
2021-12-11 22:12:06,092 iteration 6262 : loss : 0.016759, loss_ce: 0.007134
2021-12-11 22:12:07,597 iteration 6263 : loss : 0.015391, loss_ce: 0.005124
2021-12-11 22:12:09,084 iteration 6264 : loss : 0.016303, loss_ce: 0.006453
2021-12-11 22:12:10,612 iteration 6265 : loss : 0.020436, loss_ce: 0.007013
2021-12-11 22:12:12,115 iteration 6266 : loss : 0.012018, loss_ce: 0.004482
2021-12-11 22:12:13,864 iteration 6267 : loss : 0.023190, loss_ce: 0.008956
2021-12-11 22:12:15,399 iteration 6268 : loss : 0.016877, loss_ce: 0.006395
2021-12-11 22:12:16,949 iteration 6269 : loss : 0.016218, loss_ce: 0.006676
2021-12-11 22:12:18,464 iteration 6270 : loss : 0.014335, loss_ce: 0.006109
2021-12-11 22:12:20,083 iteration 6271 : loss : 0.016698, loss_ce: 0.006945
2021-12-11 22:12:21,584 iteration 6272 : loss : 0.018475, loss_ce: 0.006394
2021-12-11 22:12:23,205 iteration 6273 : loss : 0.022947, loss_ce: 0.008251
 92%|██████████████████████████▊  | 369/400 [2:54:57<14:04, 27.23s/it]2021-12-11 22:12:24,879 iteration 6274 : loss : 0.022922, loss_ce: 0.009635
2021-12-11 22:12:26,361 iteration 6275 : loss : 0.021952, loss_ce: 0.007290
2021-12-11 22:12:27,822 iteration 6276 : loss : 0.015622, loss_ce: 0.006552
2021-12-11 22:12:29,357 iteration 6277 : loss : 0.014109, loss_ce: 0.004905
2021-12-11 22:12:30,957 iteration 6278 : loss : 0.019382, loss_ce: 0.007611
2021-12-11 22:12:32,554 iteration 6279 : loss : 0.020799, loss_ce: 0.007685
2021-12-11 22:12:34,034 iteration 6280 : loss : 0.018530, loss_ce: 0.005942
2021-12-11 22:12:35,549 iteration 6281 : loss : 0.017360, loss_ce: 0.005182
2021-12-11 22:12:37,078 iteration 6282 : loss : 0.015796, loss_ce: 0.006746
2021-12-11 22:12:38,704 iteration 6283 : loss : 0.026864, loss_ce: 0.011328
2021-12-11 22:12:40,266 iteration 6284 : loss : 0.022341, loss_ce: 0.008505
2021-12-11 22:12:41,835 iteration 6285 : loss : 0.019774, loss_ce: 0.007780
2021-12-11 22:12:43,434 iteration 6286 : loss : 0.019219, loss_ce: 0.009835
2021-12-11 22:12:45,013 iteration 6287 : loss : 0.012548, loss_ce: 0.004547
2021-12-11 22:12:46,464 iteration 6288 : loss : 0.016421, loss_ce: 0.005360
2021-12-11 22:12:47,992 iteration 6289 : loss : 0.016144, loss_ce: 0.006679
2021-12-11 22:12:47,992 Training Data Eval:
2021-12-11 22:12:55,646   Average segmentation loss on training set: 0.0095
2021-12-11 22:12:55,646 Validation Data Eval:
2021-12-11 22:12:58,292   Average segmentation loss on validation set: 0.0759
2021-12-11 22:12:59,855 iteration 6290 : loss : 0.012343, loss_ce: 0.004436
 92%|██████████████████████████▊  | 370/400 [2:55:33<15:01, 30.05s/it]2021-12-11 22:13:01,411 iteration 6291 : loss : 0.017961, loss_ce: 0.005340
2021-12-11 22:13:02,855 iteration 6292 : loss : 0.015748, loss_ce: 0.004698
2021-12-11 22:13:04,351 iteration 6293 : loss : 0.015624, loss_ce: 0.003856
2021-12-11 22:13:05,974 iteration 6294 : loss : 0.026381, loss_ce: 0.008019
2021-12-11 22:13:07,514 iteration 6295 : loss : 0.019768, loss_ce: 0.006980
2021-12-11 22:13:08,976 iteration 6296 : loss : 0.017099, loss_ce: 0.006830
2021-12-11 22:13:10,577 iteration 6297 : loss : 0.022045, loss_ce: 0.009843
2021-12-11 22:13:12,108 iteration 6298 : loss : 0.019197, loss_ce: 0.009457
2021-12-11 22:13:13,636 iteration 6299 : loss : 0.017159, loss_ce: 0.006921
2021-12-11 22:13:15,227 iteration 6300 : loss : 0.017122, loss_ce: 0.004430
2021-12-11 22:13:16,792 iteration 6301 : loss : 0.014211, loss_ce: 0.006513
2021-12-11 22:13:18,418 iteration 6302 : loss : 0.018866, loss_ce: 0.007632
2021-12-11 22:13:19,931 iteration 6303 : loss : 0.016004, loss_ce: 0.006465
2021-12-11 22:13:21,486 iteration 6304 : loss : 0.019387, loss_ce: 0.007505
2021-12-11 22:13:23,003 iteration 6305 : loss : 0.014471, loss_ce: 0.004400
2021-12-11 22:13:24,538 iteration 6306 : loss : 0.015410, loss_ce: 0.007669
2021-12-11 22:13:26,055 iteration 6307 : loss : 0.013852, loss_ce: 0.004272
 93%|██████████████████████████▉  | 371/400 [2:56:00<13:58, 28.90s/it]2021-12-11 22:13:27,668 iteration 6308 : loss : 0.019797, loss_ce: 0.009540
2021-12-11 22:13:29,185 iteration 6309 : loss : 0.020374, loss_ce: 0.005295
2021-12-11 22:13:30,721 iteration 6310 : loss : 0.012462, loss_ce: 0.004744
2021-12-11 22:13:32,311 iteration 6311 : loss : 0.017552, loss_ce: 0.005285
2021-12-11 22:13:33,830 iteration 6312 : loss : 0.013672, loss_ce: 0.006246
2021-12-11 22:13:35,387 iteration 6313 : loss : 0.016343, loss_ce: 0.004579
2021-12-11 22:13:36,973 iteration 6314 : loss : 0.015217, loss_ce: 0.005469
2021-12-11 22:13:38,483 iteration 6315 : loss : 0.017013, loss_ce: 0.007344
2021-12-11 22:13:39,947 iteration 6316 : loss : 0.013857, loss_ce: 0.004136
2021-12-11 22:13:41,405 iteration 6317 : loss : 0.015511, loss_ce: 0.005316
2021-12-11 22:13:42,977 iteration 6318 : loss : 0.021596, loss_ce: 0.008590
2021-12-11 22:13:44,491 iteration 6319 : loss : 0.019568, loss_ce: 0.007414
2021-12-11 22:13:46,022 iteration 6320 : loss : 0.014266, loss_ce: 0.006236
2021-12-11 22:13:47,561 iteration 6321 : loss : 0.014415, loss_ce: 0.005279
2021-12-11 22:13:49,172 iteration 6322 : loss : 0.024867, loss_ce: 0.008782
2021-12-11 22:13:50,802 iteration 6323 : loss : 0.023300, loss_ce: 0.007216
2021-12-11 22:13:52,317 iteration 6324 : loss : 0.019304, loss_ce: 0.008614
 93%|██████████████████████████▉  | 372/400 [2:56:26<13:07, 28.11s/it]2021-12-11 22:13:53,838 iteration 6325 : loss : 0.012751, loss_ce: 0.005987
2021-12-11 22:13:55,306 iteration 6326 : loss : 0.011855, loss_ce: 0.004925
2021-12-11 22:13:56,895 iteration 6327 : loss : 0.015683, loss_ce: 0.005756
2021-12-11 22:13:58,425 iteration 6328 : loss : 0.012270, loss_ce: 0.003636
2021-12-11 22:13:59,912 iteration 6329 : loss : 0.015048, loss_ce: 0.004054
2021-12-11 22:14:01,447 iteration 6330 : loss : 0.012651, loss_ce: 0.003801
2021-12-11 22:14:03,222 iteration 6331 : loss : 0.024914, loss_ce: 0.008369
2021-12-11 22:14:04,744 iteration 6332 : loss : 0.015694, loss_ce: 0.006933
2021-12-11 22:14:06,310 iteration 6333 : loss : 0.013338, loss_ce: 0.003803
2021-12-11 22:14:07,852 iteration 6334 : loss : 0.014174, loss_ce: 0.006689
2021-12-11 22:14:09,493 iteration 6335 : loss : 0.018596, loss_ce: 0.007608
2021-12-11 22:14:10,964 iteration 6336 : loss : 0.009940, loss_ce: 0.003647
2021-12-11 22:14:12,519 iteration 6337 : loss : 0.019631, loss_ce: 0.007196
2021-12-11 22:14:14,158 iteration 6338 : loss : 0.031341, loss_ce: 0.006052
2021-12-11 22:14:15,674 iteration 6339 : loss : 0.016429, loss_ce: 0.007688
2021-12-11 22:14:17,171 iteration 6340 : loss : 0.014276, loss_ce: 0.006871
2021-12-11 22:14:18,730 iteration 6341 : loss : 0.013098, loss_ce: 0.003864
 93%|███████████████████████████  | 373/400 [2:56:52<12:25, 27.60s/it]2021-12-11 22:14:20,309 iteration 6342 : loss : 0.025064, loss_ce: 0.010480
2021-12-11 22:14:21,837 iteration 6343 : loss : 0.023388, loss_ce: 0.006344
2021-12-11 22:14:23,456 iteration 6344 : loss : 0.022460, loss_ce: 0.008536
2021-12-11 22:14:24,994 iteration 6345 : loss : 0.010818, loss_ce: 0.003623
2021-12-11 22:14:26,500 iteration 6346 : loss : 0.020998, loss_ce: 0.009753
2021-12-11 22:14:28,071 iteration 6347 : loss : 0.021445, loss_ce: 0.010820
2021-12-11 22:14:29,580 iteration 6348 : loss : 0.013635, loss_ce: 0.005696
2021-12-11 22:14:31,105 iteration 6349 : loss : 0.020645, loss_ce: 0.008300
2021-12-11 22:14:32,644 iteration 6350 : loss : 0.013948, loss_ce: 0.005177
2021-12-11 22:14:34,206 iteration 6351 : loss : 0.013676, loss_ce: 0.005838
2021-12-11 22:14:35,792 iteration 6352 : loss : 0.016801, loss_ce: 0.006012
2021-12-11 22:14:37,451 iteration 6353 : loss : 0.029519, loss_ce: 0.010124
2021-12-11 22:14:38,967 iteration 6354 : loss : 0.018513, loss_ce: 0.004731
2021-12-11 22:14:40,579 iteration 6355 : loss : 0.016413, loss_ce: 0.005685
2021-12-11 22:14:42,201 iteration 6356 : loss : 0.021488, loss_ce: 0.007284
2021-12-11 22:14:43,754 iteration 6357 : loss : 0.014211, loss_ce: 0.006801
2021-12-11 22:14:45,354 iteration 6358 : loss : 0.016783, loss_ce: 0.005135
 94%|███████████████████████████  | 374/400 [2:57:19<11:49, 27.31s/it]2021-12-11 22:14:46,914 iteration 6359 : loss : 0.013273, loss_ce: 0.004371
2021-12-11 22:14:48,343 iteration 6360 : loss : 0.010376, loss_ce: 0.003596
2021-12-11 22:14:49,955 iteration 6361 : loss : 0.017055, loss_ce: 0.005788
2021-12-11 22:14:51,510 iteration 6362 : loss : 0.013667, loss_ce: 0.005538
2021-12-11 22:14:53,204 iteration 6363 : loss : 0.029148, loss_ce: 0.009749
2021-12-11 22:14:54,787 iteration 6364 : loss : 0.013829, loss_ce: 0.003656
2021-12-11 22:14:56,322 iteration 6365 : loss : 0.020121, loss_ce: 0.008506
2021-12-11 22:14:57,853 iteration 6366 : loss : 0.016328, loss_ce: 0.005666
2021-12-11 22:14:59,459 iteration 6367 : loss : 0.019110, loss_ce: 0.007029
2021-12-11 22:15:01,035 iteration 6368 : loss : 0.024526, loss_ce: 0.007780
2021-12-11 22:15:02,578 iteration 6369 : loss : 0.020658, loss_ce: 0.004605
2021-12-11 22:15:04,155 iteration 6370 : loss : 0.018348, loss_ce: 0.008228
2021-12-11 22:15:05,646 iteration 6371 : loss : 0.012953, loss_ce: 0.005053
2021-12-11 22:15:07,197 iteration 6372 : loss : 0.017335, loss_ce: 0.006262
2021-12-11 22:15:08,694 iteration 6373 : loss : 0.013187, loss_ce: 0.005907
2021-12-11 22:15:10,142 iteration 6374 : loss : 0.011698, loss_ce: 0.004402
2021-12-11 22:15:10,143 Training Data Eval:
2021-12-11 22:15:17,794   Average segmentation loss on training set: 0.0094
2021-12-11 22:15:17,794 Validation Data Eval:
2021-12-11 22:15:20,437   Average segmentation loss on validation set: 0.0704
2021-12-11 22:15:22,022 iteration 6375 : loss : 0.014547, loss_ce: 0.007309
 94%|███████████████████████████▏ | 375/400 [2:57:56<12:32, 30.11s/it]2021-12-11 22:15:23,683 iteration 6376 : loss : 0.018627, loss_ce: 0.005976
2021-12-11 22:15:25,259 iteration 6377 : loss : 0.017894, loss_ce: 0.004655
2021-12-11 22:15:26,782 iteration 6378 : loss : 0.016092, loss_ce: 0.007736
2021-12-11 22:15:28,330 iteration 6379 : loss : 0.017256, loss_ce: 0.007177
2021-12-11 22:15:29,929 iteration 6380 : loss : 0.024273, loss_ce: 0.006578
2021-12-11 22:15:31,536 iteration 6381 : loss : 0.025183, loss_ce: 0.010679
2021-12-11 22:15:33,090 iteration 6382 : loss : 0.013983, loss_ce: 0.006410
2021-12-11 22:15:34,671 iteration 6383 : loss : 0.018433, loss_ce: 0.005866
2021-12-11 22:15:36,281 iteration 6384 : loss : 0.022899, loss_ce: 0.008430
2021-12-11 22:15:37,711 iteration 6385 : loss : 0.010662, loss_ce: 0.003878
2021-12-11 22:15:39,298 iteration 6386 : loss : 0.022294, loss_ce: 0.007764
2021-12-11 22:15:40,891 iteration 6387 : loss : 0.018361, loss_ce: 0.008567
2021-12-11 22:15:42,357 iteration 6388 : loss : 0.014390, loss_ce: 0.006956
2021-12-11 22:15:43,952 iteration 6389 : loss : 0.013615, loss_ce: 0.005492
2021-12-11 22:15:45,520 iteration 6390 : loss : 0.019387, loss_ce: 0.005680
2021-12-11 22:15:47,107 iteration 6391 : loss : 0.018597, loss_ce: 0.008152
2021-12-11 22:15:48,711 iteration 6392 : loss : 0.025165, loss_ce: 0.006239
 94%|███████████████████████████▎ | 376/400 [2:58:22<11:38, 29.09s/it]2021-12-11 22:15:50,262 iteration 6393 : loss : 0.011393, loss_ce: 0.005605
2021-12-11 22:15:51,781 iteration 6394 : loss : 0.012014, loss_ce: 0.005276
2021-12-11 22:15:53,289 iteration 6395 : loss : 0.010737, loss_ce: 0.003052
2021-12-11 22:15:54,845 iteration 6396 : loss : 0.016345, loss_ce: 0.006186
2021-12-11 22:15:56,465 iteration 6397 : loss : 0.019617, loss_ce: 0.005679
2021-12-11 22:15:58,073 iteration 6398 : loss : 0.015722, loss_ce: 0.005359
2021-12-11 22:15:59,541 iteration 6399 : loss : 0.016184, loss_ce: 0.004405
2021-12-11 22:16:01,059 iteration 6400 : loss : 0.011456, loss_ce: 0.004013
2021-12-11 22:16:02,533 iteration 6401 : loss : 0.011256, loss_ce: 0.004085
2021-12-11 22:16:04,114 iteration 6402 : loss : 0.019743, loss_ce: 0.008348
2021-12-11 22:16:05,618 iteration 6403 : loss : 0.014115, loss_ce: 0.006053
2021-12-11 22:16:07,102 iteration 6404 : loss : 0.013431, loss_ce: 0.006056
2021-12-11 22:16:08,771 iteration 6405 : loss : 0.029983, loss_ce: 0.010399
2021-12-11 22:16:10,244 iteration 6406 : loss : 0.014692, loss_ce: 0.005941
2021-12-11 22:16:11,815 iteration 6407 : loss : 0.021589, loss_ce: 0.008129
2021-12-11 22:16:13,395 iteration 6408 : loss : 0.013713, loss_ce: 0.004703
2021-12-11 22:16:14,876 iteration 6409 : loss : 0.010627, loss_ce: 0.003496
 94%|███████████████████████████▎ | 377/400 [2:58:48<10:48, 28.21s/it]2021-12-11 22:16:16,384 iteration 6410 : loss : 0.012667, loss_ce: 0.004548
2021-12-11 22:16:17,891 iteration 6411 : loss : 0.014274, loss_ce: 0.006241
2021-12-11 22:16:19,490 iteration 6412 : loss : 0.019733, loss_ce: 0.006350
2021-12-11 22:16:21,034 iteration 6413 : loss : 0.016203, loss_ce: 0.006624
2021-12-11 22:16:22,619 iteration 6414 : loss : 0.016550, loss_ce: 0.005871
2021-12-11 22:16:24,203 iteration 6415 : loss : 0.017759, loss_ce: 0.004860
2021-12-11 22:16:25,723 iteration 6416 : loss : 0.013561, loss_ce: 0.004824
2021-12-11 22:16:27,306 iteration 6417 : loss : 0.022184, loss_ce: 0.007067
2021-12-11 22:16:28,839 iteration 6418 : loss : 0.013384, loss_ce: 0.005250
2021-12-11 22:16:30,379 iteration 6419 : loss : 0.017964, loss_ce: 0.008079
2021-12-11 22:16:31,943 iteration 6420 : loss : 0.019255, loss_ce: 0.007995
2021-12-11 22:16:33,528 iteration 6421 : loss : 0.016725, loss_ce: 0.007480
2021-12-11 22:16:35,051 iteration 6422 : loss : 0.015759, loss_ce: 0.006308
2021-12-11 22:16:36,606 iteration 6423 : loss : 0.012849, loss_ce: 0.004883
2021-12-11 22:16:38,100 iteration 6424 : loss : 0.014698, loss_ce: 0.004680
2021-12-11 22:16:39,777 iteration 6425 : loss : 0.020135, loss_ce: 0.007503
2021-12-11 22:16:41,256 iteration 6426 : loss : 0.014922, loss_ce: 0.005131
 94%|███████████████████████████▍ | 378/400 [2:59:15<10:08, 27.66s/it]2021-12-11 22:16:42,862 iteration 6427 : loss : 0.018957, loss_ce: 0.006932
2021-12-11 22:16:44,447 iteration 6428 : loss : 0.018606, loss_ce: 0.006273
2021-12-11 22:16:45,976 iteration 6429 : loss : 0.018553, loss_ce: 0.007593
2021-12-11 22:16:47,581 iteration 6430 : loss : 0.018924, loss_ce: 0.007858
2021-12-11 22:16:49,110 iteration 6431 : loss : 0.017906, loss_ce: 0.005711
2021-12-11 22:16:50,652 iteration 6432 : loss : 0.015265, loss_ce: 0.005214
2021-12-11 22:16:52,186 iteration 6433 : loss : 0.013288, loss_ce: 0.003518
2021-12-11 22:16:53,739 iteration 6434 : loss : 0.030527, loss_ce: 0.014973
2021-12-11 22:16:55,179 iteration 6435 : loss : 0.011577, loss_ce: 0.003788
2021-12-11 22:16:56,673 iteration 6436 : loss : 0.012208, loss_ce: 0.005640
2021-12-11 22:16:58,136 iteration 6437 : loss : 0.012264, loss_ce: 0.004322
2021-12-11 22:16:59,596 iteration 6438 : loss : 0.011241, loss_ce: 0.004941
2021-12-11 22:17:01,187 iteration 6439 : loss : 0.025714, loss_ce: 0.008930
2021-12-11 22:17:02,741 iteration 6440 : loss : 0.015276, loss_ce: 0.005087
2021-12-11 22:17:04,295 iteration 6441 : loss : 0.013133, loss_ce: 0.005589
2021-12-11 22:17:05,835 iteration 6442 : loss : 0.011456, loss_ce: 0.004874
2021-12-11 22:17:07,340 iteration 6443 : loss : 0.019303, loss_ce: 0.005959
 95%|███████████████████████████▍ | 379/400 [2:59:41<09:30, 27.19s/it]2021-12-11 22:17:08,886 iteration 6444 : loss : 0.014446, loss_ce: 0.006778
2021-12-11 22:17:10,380 iteration 6445 : loss : 0.010594, loss_ce: 0.003886
2021-12-11 22:17:11,936 iteration 6446 : loss : 0.014501, loss_ce: 0.005259
2021-12-11 22:17:13,462 iteration 6447 : loss : 0.012178, loss_ce: 0.005026
2021-12-11 22:17:14,997 iteration 6448 : loss : 0.017426, loss_ce: 0.004268
2021-12-11 22:17:16,550 iteration 6449 : loss : 0.019905, loss_ce: 0.006400
2021-12-11 22:17:18,145 iteration 6450 : loss : 0.020394, loss_ce: 0.005945
2021-12-11 22:17:19,656 iteration 6451 : loss : 0.016503, loss_ce: 0.005778
2021-12-11 22:17:21,242 iteration 6452 : loss : 0.024553, loss_ce: 0.008001
2021-12-11 22:17:22,751 iteration 6453 : loss : 0.015163, loss_ce: 0.006703
2021-12-11 22:17:24,294 iteration 6454 : loss : 0.016165, loss_ce: 0.005180
2021-12-11 22:17:25,770 iteration 6455 : loss : 0.013647, loss_ce: 0.005416
2021-12-11 22:17:27,320 iteration 6456 : loss : 0.015008, loss_ce: 0.007047
2021-12-11 22:17:28,837 iteration 6457 : loss : 0.012396, loss_ce: 0.005003
2021-12-11 22:17:30,323 iteration 6458 : loss : 0.014329, loss_ce: 0.007004
2021-12-11 22:17:31,916 iteration 6459 : loss : 0.017004, loss_ce: 0.006104
2021-12-11 22:17:31,916 Training Data Eval:
2021-12-11 22:17:39,559   Average segmentation loss on training set: 0.0091
2021-12-11 22:17:39,560 Validation Data Eval:
2021-12-11 22:17:42,209   Average segmentation loss on validation set: 0.0718
2021-12-11 22:17:43,891 iteration 6460 : loss : 0.012707, loss_ce: 0.004476
 95%|███████████████████████████▌ | 380/400 [3:00:18<09:59, 30.00s/it]2021-12-11 22:17:45,445 iteration 6461 : loss : 0.011464, loss_ce: 0.003648
2021-12-11 22:17:46,992 iteration 6462 : loss : 0.014480, loss_ce: 0.005687
2021-12-11 22:17:48,483 iteration 6463 : loss : 0.012637, loss_ce: 0.005232
2021-12-11 22:17:49,997 iteration 6464 : loss : 0.019224, loss_ce: 0.007033
2021-12-11 22:17:51,526 iteration 6465 : loss : 0.012005, loss_ce: 0.004068
2021-12-11 22:17:53,052 iteration 6466 : loss : 0.017499, loss_ce: 0.006721
2021-12-11 22:17:54,599 iteration 6467 : loss : 0.017873, loss_ce: 0.007581
2021-12-11 22:17:56,077 iteration 6468 : loss : 0.014572, loss_ce: 0.004040
2021-12-11 22:17:57,678 iteration 6469 : loss : 0.030051, loss_ce: 0.008835
2021-12-11 22:17:59,240 iteration 6470 : loss : 0.014132, loss_ce: 0.005536
2021-12-11 22:18:00,789 iteration 6471 : loss : 0.019119, loss_ce: 0.008454
2021-12-11 22:18:02,332 iteration 6472 : loss : 0.017459, loss_ce: 0.006022
2021-12-11 22:18:03,905 iteration 6473 : loss : 0.014513, loss_ce: 0.005811
2021-12-11 22:18:05,471 iteration 6474 : loss : 0.012438, loss_ce: 0.005099
2021-12-11 22:18:07,056 iteration 6475 : loss : 0.018504, loss_ce: 0.005838
2021-12-11 22:18:08,621 iteration 6476 : loss : 0.017489, loss_ce: 0.006620
2021-12-11 22:18:10,184 iteration 6477 : loss : 0.016189, loss_ce: 0.007102
 95%|███████████████████████████▌ | 381/400 [3:00:44<09:08, 28.89s/it]2021-12-11 22:18:11,766 iteration 6478 : loss : 0.013617, loss_ce: 0.005576
2021-12-11 22:18:13,313 iteration 6479 : loss : 0.016798, loss_ce: 0.005561
2021-12-11 22:18:14,827 iteration 6480 : loss : 0.011636, loss_ce: 0.004110
2021-12-11 22:18:16,499 iteration 6481 : loss : 0.021029, loss_ce: 0.007505
2021-12-11 22:18:18,010 iteration 6482 : loss : 0.018156, loss_ce: 0.007742
2021-12-11 22:18:19,605 iteration 6483 : loss : 0.027672, loss_ce: 0.009939
2021-12-11 22:18:21,051 iteration 6484 : loss : 0.017899, loss_ce: 0.006218
2021-12-11 22:18:22,591 iteration 6485 : loss : 0.012550, loss_ce: 0.003750
2021-12-11 22:18:24,145 iteration 6486 : loss : 0.020000, loss_ce: 0.006776
2021-12-11 22:18:25,726 iteration 6487 : loss : 0.017879, loss_ce: 0.007116
2021-12-11 22:18:27,317 iteration 6488 : loss : 0.012069, loss_ce: 0.004040
2021-12-11 22:18:28,852 iteration 6489 : loss : 0.016288, loss_ce: 0.006074
2021-12-11 22:18:30,388 iteration 6490 : loss : 0.015253, loss_ce: 0.006299
2021-12-11 22:18:31,920 iteration 6491 : loss : 0.014293, loss_ce: 0.006710
2021-12-11 22:18:33,413 iteration 6492 : loss : 0.012647, loss_ce: 0.006553
2021-12-11 22:18:34,930 iteration 6493 : loss : 0.022151, loss_ce: 0.007582
2021-12-11 22:18:36,487 iteration 6494 : loss : 0.014969, loss_ce: 0.005550
 96%|███████████████████████████▋ | 382/400 [3:01:10<08:25, 28.11s/it]2021-12-11 22:18:38,008 iteration 6495 : loss : 0.012920, loss_ce: 0.005510
2021-12-11 22:18:39,537 iteration 6496 : loss : 0.017164, loss_ce: 0.005779
2021-12-11 22:18:41,109 iteration 6497 : loss : 0.012095, loss_ce: 0.006081
2021-12-11 22:18:42,603 iteration 6498 : loss : 0.015552, loss_ce: 0.003956
2021-12-11 22:18:44,133 iteration 6499 : loss : 0.018720, loss_ce: 0.004796
2021-12-11 22:18:45,781 iteration 6500 : loss : 0.025329, loss_ce: 0.006661
2021-12-11 22:18:47,389 iteration 6501 : loss : 0.017182, loss_ce: 0.008611
2021-12-11 22:18:48,986 iteration 6502 : loss : 0.013871, loss_ce: 0.004538
2021-12-11 22:18:50,535 iteration 6503 : loss : 0.016800, loss_ce: 0.006262
2021-12-11 22:18:52,109 iteration 6504 : loss : 0.021183, loss_ce: 0.010391
2021-12-11 22:18:53,584 iteration 6505 : loss : 0.012290, loss_ce: 0.004577
2021-12-11 22:18:55,139 iteration 6506 : loss : 0.017186, loss_ce: 0.004271
2021-12-11 22:18:56,649 iteration 6507 : loss : 0.015811, loss_ce: 0.006192
2021-12-11 22:18:58,102 iteration 6508 : loss : 0.015721, loss_ce: 0.005694
2021-12-11 22:18:59,614 iteration 6509 : loss : 0.013015, loss_ce: 0.004338
2021-12-11 22:19:01,037 iteration 6510 : loss : 0.010532, loss_ce: 0.004085
2021-12-11 22:19:02,615 iteration 6511 : loss : 0.015221, loss_ce: 0.006368
 96%|███████████████████████████▊ | 383/400 [3:01:36<07:47, 27.51s/it]2021-12-11 22:19:04,218 iteration 6512 : loss : 0.022800, loss_ce: 0.007549
2021-12-11 22:19:05,820 iteration 6513 : loss : 0.020543, loss_ce: 0.007758
2021-12-11 22:19:07,373 iteration 6514 : loss : 0.019480, loss_ce: 0.006283
2021-12-11 22:19:08,974 iteration 6515 : loss : 0.021885, loss_ce: 0.007593
2021-12-11 22:19:10,473 iteration 6516 : loss : 0.015438, loss_ce: 0.006095
2021-12-11 22:19:11,962 iteration 6517 : loss : 0.014522, loss_ce: 0.005858
2021-12-11 22:19:13,511 iteration 6518 : loss : 0.018412, loss_ce: 0.006503
2021-12-11 22:19:15,111 iteration 6519 : loss : 0.020926, loss_ce: 0.008333
2021-12-11 22:19:16,583 iteration 6520 : loss : 0.015741, loss_ce: 0.006157
2021-12-11 22:19:18,194 iteration 6521 : loss : 0.018060, loss_ce: 0.007120
2021-12-11 22:19:19,749 iteration 6522 : loss : 0.019465, loss_ce: 0.005818
2021-12-11 22:19:21,315 iteration 6523 : loss : 0.014816, loss_ce: 0.005751
2021-12-11 22:19:22,882 iteration 6524 : loss : 0.013693, loss_ce: 0.004749
2021-12-11 22:19:24,478 iteration 6525 : loss : 0.018233, loss_ce: 0.005790
2021-12-11 22:19:26,017 iteration 6526 : loss : 0.016780, loss_ce: 0.006128
2021-12-11 22:19:27,514 iteration 6527 : loss : 0.015122, loss_ce: 0.004798
2021-12-11 22:19:29,020 iteration 6528 : loss : 0.012797, loss_ce: 0.004777
 96%|███████████████████████████▊ | 384/400 [3:02:03<07:14, 27.18s/it]2021-12-11 22:19:30,763 iteration 6529 : loss : 0.017335, loss_ce: 0.007299
2021-12-11 22:19:32,290 iteration 6530 : loss : 0.020342, loss_ce: 0.007981
2021-12-11 22:19:33,931 iteration 6531 : loss : 0.023671, loss_ce: 0.008321
2021-12-11 22:19:35,484 iteration 6532 : loss : 0.027475, loss_ce: 0.012771
2021-12-11 22:19:37,118 iteration 6533 : loss : 0.024709, loss_ce: 0.005139
2021-12-11 22:19:38,794 iteration 6534 : loss : 0.029858, loss_ce: 0.008050
2021-12-11 22:19:40,274 iteration 6535 : loss : 0.020559, loss_ce: 0.004022
2021-12-11 22:19:41,812 iteration 6536 : loss : 0.019357, loss_ce: 0.007088
2021-12-11 22:19:43,353 iteration 6537 : loss : 0.014263, loss_ce: 0.005617
2021-12-11 22:19:44,919 iteration 6538 : loss : 0.014450, loss_ce: 0.006807
2021-12-11 22:19:46,567 iteration 6539 : loss : 0.019907, loss_ce: 0.007528
2021-12-11 22:19:48,098 iteration 6540 : loss : 0.014212, loss_ce: 0.006253
2021-12-11 22:19:49,657 iteration 6541 : loss : 0.013488, loss_ce: 0.005659
2021-12-11 22:19:51,255 iteration 6542 : loss : 0.025609, loss_ce: 0.009951
2021-12-11 22:19:52,831 iteration 6543 : loss : 0.020232, loss_ce: 0.007460
2021-12-11 22:19:54,302 iteration 6544 : loss : 0.011074, loss_ce: 0.003584
2021-12-11 22:19:54,303 Training Data Eval:
2021-12-11 22:20:01,957   Average segmentation loss on training set: 0.0094
2021-12-11 22:20:01,958 Validation Data Eval:
2021-12-11 22:20:04,595   Average segmentation loss on validation set: 0.0751
2021-12-11 22:20:06,022 iteration 6545 : loss : 0.009742, loss_ce: 0.002241
 96%|███████████████████████████▉ | 385/400 [3:02:40<07:31, 30.13s/it]2021-12-11 22:20:07,626 iteration 6546 : loss : 0.023151, loss_ce: 0.006705
2021-12-11 22:20:09,369 iteration 6547 : loss : 0.024223, loss_ce: 0.008897
2021-12-11 22:20:10,833 iteration 6548 : loss : 0.013440, loss_ce: 0.007583
2021-12-11 22:20:12,283 iteration 6549 : loss : 0.009674, loss_ce: 0.003218
2021-12-11 22:20:13,792 iteration 6550 : loss : 0.013637, loss_ce: 0.004997
2021-12-11 22:20:15,373 iteration 6551 : loss : 0.015148, loss_ce: 0.006694
2021-12-11 22:20:16,820 iteration 6552 : loss : 0.014017, loss_ce: 0.006185
2021-12-11 22:20:18,433 iteration 6553 : loss : 0.022724, loss_ce: 0.008308
2021-12-11 22:20:19,978 iteration 6554 : loss : 0.018633, loss_ce: 0.005895
2021-12-11 22:20:21,624 iteration 6555 : loss : 0.016065, loss_ce: 0.006054
2021-12-11 22:20:23,267 iteration 6556 : loss : 0.018871, loss_ce: 0.006242
2021-12-11 22:20:24,753 iteration 6557 : loss : 0.017754, loss_ce: 0.005563
2021-12-11 22:20:26,235 iteration 6558 : loss : 0.016232, loss_ce: 0.004534
2021-12-11 22:20:27,817 iteration 6559 : loss : 0.016382, loss_ce: 0.007216
2021-12-11 22:20:29,439 iteration 6560 : loss : 0.043812, loss_ce: 0.009650
2021-12-11 22:20:30,936 iteration 6561 : loss : 0.012566, loss_ce: 0.005027
2021-12-11 22:20:32,384 iteration 6562 : loss : 0.009974, loss_ce: 0.003189
 96%|███████████████████████████▉ | 386/400 [3:03:06<06:46, 29.00s/it]2021-12-11 22:20:33,952 iteration 6563 : loss : 0.011885, loss_ce: 0.004967
2021-12-11 22:20:35,447 iteration 6564 : loss : 0.014562, loss_ce: 0.003411
2021-12-11 22:20:36,917 iteration 6565 : loss : 0.010919, loss_ce: 0.003066
2021-12-11 22:20:38,412 iteration 6566 : loss : 0.011134, loss_ce: 0.004079
2021-12-11 22:20:40,030 iteration 6567 : loss : 0.013566, loss_ce: 0.005303
2021-12-11 22:20:41,587 iteration 6568 : loss : 0.026161, loss_ce: 0.010690
2021-12-11 22:20:43,185 iteration 6569 : loss : 0.030449, loss_ce: 0.011036
2021-12-11 22:20:44,721 iteration 6570 : loss : 0.015535, loss_ce: 0.003871
2021-12-11 22:20:46,394 iteration 6571 : loss : 0.021430, loss_ce: 0.009430
2021-12-11 22:20:47,860 iteration 6572 : loss : 0.011666, loss_ce: 0.004790
2021-12-11 22:20:49,454 iteration 6573 : loss : 0.025233, loss_ce: 0.008034
2021-12-11 22:20:50,972 iteration 6574 : loss : 0.011683, loss_ce: 0.003196
2021-12-11 22:20:52,603 iteration 6575 : loss : 0.026856, loss_ce: 0.008317
2021-12-11 22:20:54,148 iteration 6576 : loss : 0.020435, loss_ce: 0.008193
2021-12-11 22:20:55,656 iteration 6577 : loss : 0.015129, loss_ce: 0.004215
2021-12-11 22:20:57,223 iteration 6578 : loss : 0.010916, loss_ce: 0.003697
2021-12-11 22:20:58,732 iteration 6579 : loss : 0.016019, loss_ce: 0.007156
 97%|████████████████████████████ | 387/400 [3:03:32<06:06, 28.20s/it]2021-12-11 22:21:00,371 iteration 6580 : loss : 0.021962, loss_ce: 0.009541
2021-12-11 22:21:01,852 iteration 6581 : loss : 0.012331, loss_ce: 0.003647
2021-12-11 22:21:03,485 iteration 6582 : loss : 0.017522, loss_ce: 0.005451
2021-12-11 22:21:05,045 iteration 6583 : loss : 0.022511, loss_ce: 0.007643
2021-12-11 22:21:06,532 iteration 6584 : loss : 0.015260, loss_ce: 0.006102
2021-12-11 22:21:07,992 iteration 6585 : loss : 0.012518, loss_ce: 0.003916
2021-12-11 22:21:09,517 iteration 6586 : loss : 0.012979, loss_ce: 0.002731
2021-12-11 22:21:10,980 iteration 6587 : loss : 0.011398, loss_ce: 0.005208
2021-12-11 22:21:12,528 iteration 6588 : loss : 0.013384, loss_ce: 0.007056
2021-12-11 22:21:14,088 iteration 6589 : loss : 0.014124, loss_ce: 0.005620
2021-12-11 22:21:15,594 iteration 6590 : loss : 0.014643, loss_ce: 0.006579
2021-12-11 22:21:17,124 iteration 6591 : loss : 0.011030, loss_ce: 0.003840
2021-12-11 22:21:18,737 iteration 6592 : loss : 0.016329, loss_ce: 0.008326
2021-12-11 22:21:20,188 iteration 6593 : loss : 0.011817, loss_ce: 0.006009
2021-12-11 22:21:21,691 iteration 6594 : loss : 0.012622, loss_ce: 0.005081
2021-12-11 22:21:23,268 iteration 6595 : loss : 0.020670, loss_ce: 0.005945
2021-12-11 22:21:24,743 iteration 6596 : loss : 0.014293, loss_ce: 0.004536
 97%|████████████████████████████▏| 388/400 [3:03:58<05:30, 27.55s/it]2021-12-11 22:21:26,319 iteration 6597 : loss : 0.012412, loss_ce: 0.004858
2021-12-11 22:21:27,899 iteration 6598 : loss : 0.015683, loss_ce: 0.003082
2021-12-11 22:21:29,502 iteration 6599 : loss : 0.020595, loss_ce: 0.007536
2021-12-11 22:21:30,990 iteration 6600 : loss : 0.013833, loss_ce: 0.006184
2021-12-11 22:21:32,619 iteration 6601 : loss : 0.015902, loss_ce: 0.006389
2021-12-11 22:21:34,182 iteration 6602 : loss : 0.017168, loss_ce: 0.005640
2021-12-11 22:21:35,678 iteration 6603 : loss : 0.014288, loss_ce: 0.005910
2021-12-11 22:21:37,243 iteration 6604 : loss : 0.016433, loss_ce: 0.007507
2021-12-11 22:21:38,758 iteration 6605 : loss : 0.020389, loss_ce: 0.008522
2021-12-11 22:21:40,364 iteration 6606 : loss : 0.021810, loss_ce: 0.007965
2021-12-11 22:21:41,964 iteration 6607 : loss : 0.018155, loss_ce: 0.007036
2021-12-11 22:21:43,448 iteration 6608 : loss : 0.015983, loss_ce: 0.006615
2021-12-11 22:21:45,042 iteration 6609 : loss : 0.014456, loss_ce: 0.006403
2021-12-11 22:21:46,562 iteration 6610 : loss : 0.014455, loss_ce: 0.005283
2021-12-11 22:21:48,078 iteration 6611 : loss : 0.012232, loss_ce: 0.003165
2021-12-11 22:21:49,608 iteration 6612 : loss : 0.014585, loss_ce: 0.003957
2021-12-11 22:21:51,193 iteration 6613 : loss : 0.015731, loss_ce: 0.005686
 97%|████████████████████████████▏| 389/400 [3:04:25<04:59, 27.22s/it]2021-12-11 22:21:52,726 iteration 6614 : loss : 0.010346, loss_ce: 0.003532
2021-12-11 22:21:54,188 iteration 6615 : loss : 0.010331, loss_ce: 0.004036
2021-12-11 22:21:55,799 iteration 6616 : loss : 0.023267, loss_ce: 0.007129
2021-12-11 22:21:57,309 iteration 6617 : loss : 0.025722, loss_ce: 0.008960
2021-12-11 22:21:58,918 iteration 6618 : loss : 0.017385, loss_ce: 0.006605
2021-12-11 22:22:00,447 iteration 6619 : loss : 0.016364, loss_ce: 0.005824
2021-12-11 22:22:01,988 iteration 6620 : loss : 0.016259, loss_ce: 0.005392
2021-12-11 22:22:03,590 iteration 6621 : loss : 0.018397, loss_ce: 0.005715
2021-12-11 22:22:05,102 iteration 6622 : loss : 0.014534, loss_ce: 0.006670
2021-12-11 22:22:06,577 iteration 6623 : loss : 0.016358, loss_ce: 0.005279
2021-12-11 22:22:08,119 iteration 6624 : loss : 0.015180, loss_ce: 0.006064
2021-12-11 22:22:09,676 iteration 6625 : loss : 0.024951, loss_ce: 0.011330
2021-12-11 22:22:11,208 iteration 6626 : loss : 0.018417, loss_ce: 0.007254
2021-12-11 22:22:12,785 iteration 6627 : loss : 0.022128, loss_ce: 0.007846
2021-12-11 22:22:14,427 iteration 6628 : loss : 0.016386, loss_ce: 0.006577
2021-12-11 22:22:16,085 iteration 6629 : loss : 0.019670, loss_ce: 0.005636
2021-12-11 22:22:16,086 Training Data Eval:
2021-12-11 22:22:23,722   Average segmentation loss on training set: 0.0089
2021-12-11 22:22:23,723 Validation Data Eval:
2021-12-11 22:22:26,365   Average segmentation loss on validation set: 0.0847
2021-12-11 22:22:27,864 iteration 6630 : loss : 0.014643, loss_ce: 0.005593
 98%|████████████████████████████▎| 390/400 [3:05:01<05:00, 30.05s/it]2021-12-11 22:22:29,487 iteration 6631 : loss : 0.020279, loss_ce: 0.006335
2021-12-11 22:22:30,994 iteration 6632 : loss : 0.011902, loss_ce: 0.005528
2021-12-11 22:22:32,577 iteration 6633 : loss : 0.018772, loss_ce: 0.005119
2021-12-11 22:22:34,094 iteration 6634 : loss : 0.017913, loss_ce: 0.006393
2021-12-11 22:22:35,635 iteration 6635 : loss : 0.015403, loss_ce: 0.006214
2021-12-11 22:22:37,185 iteration 6636 : loss : 0.011405, loss_ce: 0.005300
2021-12-11 22:22:38,683 iteration 6637 : loss : 0.016324, loss_ce: 0.005424
2021-12-11 22:22:40,277 iteration 6638 : loss : 0.019671, loss_ce: 0.004282
2021-12-11 22:22:41,873 iteration 6639 : loss : 0.015954, loss_ce: 0.006411
2021-12-11 22:22:43,410 iteration 6640 : loss : 0.014169, loss_ce: 0.004406
2021-12-11 22:22:44,960 iteration 6641 : loss : 0.012935, loss_ce: 0.004250
2021-12-11 22:22:46,516 iteration 6642 : loss : 0.021561, loss_ce: 0.012320
2021-12-11 22:22:48,083 iteration 6643 : loss : 0.017077, loss_ce: 0.006481
2021-12-11 22:22:49,749 iteration 6644 : loss : 0.025242, loss_ce: 0.010039
2021-12-11 22:22:51,260 iteration 6645 : loss : 0.012839, loss_ce: 0.005430
2021-12-11 22:22:52,914 iteration 6646 : loss : 0.036027, loss_ce: 0.010967
2021-12-11 22:22:54,441 iteration 6647 : loss : 0.015413, loss_ce: 0.006134
 98%|████████████████████████████▎| 391/400 [3:05:28<04:21, 29.01s/it]2021-12-11 22:22:55,997 iteration 6648 : loss : 0.016901, loss_ce: 0.003652
2021-12-11 22:22:57,574 iteration 6649 : loss : 0.016411, loss_ce: 0.004592
2021-12-11 22:22:59,205 iteration 6650 : loss : 0.019721, loss_ce: 0.006579
2021-12-11 22:23:00,915 iteration 6651 : loss : 0.020688, loss_ce: 0.008856
2021-12-11 22:23:02,427 iteration 6652 : loss : 0.013983, loss_ce: 0.006011
2021-12-11 22:23:03,882 iteration 6653 : loss : 0.011342, loss_ce: 0.004480
2021-12-11 22:23:05,404 iteration 6654 : loss : 0.017842, loss_ce: 0.005841
2021-12-11 22:23:06,973 iteration 6655 : loss : 0.017441, loss_ce: 0.006138
2021-12-11 22:23:08,530 iteration 6656 : loss : 0.022890, loss_ce: 0.008441
2021-12-11 22:23:10,088 iteration 6657 : loss : 0.018112, loss_ce: 0.004836
2021-12-11 22:23:11,673 iteration 6658 : loss : 0.012782, loss_ce: 0.004417
2021-12-11 22:23:13,224 iteration 6659 : loss : 0.019419, loss_ce: 0.008624
2021-12-11 22:23:14,831 iteration 6660 : loss : 0.022123, loss_ce: 0.009914
2021-12-11 22:23:16,400 iteration 6661 : loss : 0.015747, loss_ce: 0.006128
2021-12-11 22:23:17,982 iteration 6662 : loss : 0.020998, loss_ce: 0.005364
2021-12-11 22:23:19,536 iteration 6663 : loss : 0.019223, loss_ce: 0.006948
2021-12-11 22:23:21,115 iteration 6664 : loss : 0.020380, loss_ce: 0.011527
 98%|████████████████████████████▍| 392/400 [3:05:55<03:46, 28.31s/it]2021-12-11 22:23:22,717 iteration 6665 : loss : 0.020031, loss_ce: 0.005638
2021-12-11 22:23:24,375 iteration 6666 : loss : 0.021203, loss_ce: 0.005462
2021-12-11 22:23:25,939 iteration 6667 : loss : 0.033604, loss_ce: 0.004999
2021-12-11 22:23:27,396 iteration 6668 : loss : 0.013395, loss_ce: 0.006881
2021-12-11 22:23:28,914 iteration 6669 : loss : 0.022353, loss_ce: 0.008579
2021-12-11 22:23:30,496 iteration 6670 : loss : 0.021440, loss_ce: 0.010883
2021-12-11 22:23:32,078 iteration 6671 : loss : 0.014734, loss_ce: 0.005155
2021-12-11 22:23:33,652 iteration 6672 : loss : 0.015800, loss_ce: 0.004638
2021-12-11 22:23:35,180 iteration 6673 : loss : 0.038322, loss_ce: 0.007247
2021-12-11 22:23:36,715 iteration 6674 : loss : 0.013964, loss_ce: 0.005956
2021-12-11 22:23:38,343 iteration 6675 : loss : 0.017511, loss_ce: 0.008227
2021-12-11 22:23:39,864 iteration 6676 : loss : 0.014799, loss_ce: 0.005637
2021-12-11 22:23:41,365 iteration 6677 : loss : 0.016378, loss_ce: 0.005548
2021-12-11 22:23:42,902 iteration 6678 : loss : 0.014127, loss_ce: 0.006614
2021-12-11 22:23:44,494 iteration 6679 : loss : 0.017005, loss_ce: 0.007247
2021-12-11 22:23:45,963 iteration 6680 : loss : 0.010131, loss_ce: 0.003637
2021-12-11 22:23:47,421 iteration 6681 : loss : 0.010913, loss_ce: 0.003504
 98%|████████████████████████████▍| 393/400 [3:06:21<03:13, 27.71s/it]2021-12-11 22:23:49,142 iteration 6682 : loss : 0.017746, loss_ce: 0.007623
2021-12-11 22:23:50,632 iteration 6683 : loss : 0.013113, loss_ce: 0.004991
2021-12-11 22:23:52,168 iteration 6684 : loss : 0.013788, loss_ce: 0.006397
2021-12-11 22:23:53,646 iteration 6685 : loss : 0.018798, loss_ce: 0.006334
2021-12-11 22:23:55,260 iteration 6686 : loss : 0.014476, loss_ce: 0.005786
2021-12-11 22:23:56,797 iteration 6687 : loss : 0.017781, loss_ce: 0.006486
2021-12-11 22:23:58,346 iteration 6688 : loss : 0.014632, loss_ce: 0.005327
2021-12-11 22:23:59,808 iteration 6689 : loss : 0.017359, loss_ce: 0.005438
2021-12-11 22:24:01,342 iteration 6690 : loss : 0.009914, loss_ce: 0.002840
2021-12-11 22:24:02,914 iteration 6691 : loss : 0.020046, loss_ce: 0.007082
2021-12-11 22:24:04,423 iteration 6692 : loss : 0.017491, loss_ce: 0.006024
2021-12-11 22:24:05,949 iteration 6693 : loss : 0.017086, loss_ce: 0.005781
2021-12-11 22:24:07,512 iteration 6694 : loss : 0.017971, loss_ce: 0.006535
2021-12-11 22:24:09,012 iteration 6695 : loss : 0.018657, loss_ce: 0.006020
2021-12-11 22:24:10,549 iteration 6696 : loss : 0.012478, loss_ce: 0.004814
2021-12-11 22:24:12,081 iteration 6697 : loss : 0.014569, loss_ce: 0.004880
2021-12-11 22:24:13,702 iteration 6698 : loss : 0.021424, loss_ce: 0.008420
 98%|████████████████████████████▌| 394/400 [3:06:47<02:43, 27.28s/it]2021-12-11 22:24:15,248 iteration 6699 : loss : 0.015983, loss_ce: 0.005243
2021-12-11 22:24:16,864 iteration 6700 : loss : 0.024629, loss_ce: 0.006058
2021-12-11 22:24:18,403 iteration 6701 : loss : 0.014262, loss_ce: 0.005406
2021-12-11 22:24:19,861 iteration 6702 : loss : 0.011048, loss_ce: 0.005039
2021-12-11 22:24:21,309 iteration 6703 : loss : 0.013836, loss_ce: 0.004721
2021-12-11 22:24:22,891 iteration 6704 : loss : 0.020349, loss_ce: 0.010662
2021-12-11 22:24:24,369 iteration 6705 : loss : 0.015136, loss_ce: 0.006818
2021-12-11 22:24:25,973 iteration 6706 : loss : 0.017022, loss_ce: 0.005635
2021-12-11 22:24:27,445 iteration 6707 : loss : 0.009757, loss_ce: 0.003467
2021-12-11 22:24:28,989 iteration 6708 : loss : 0.019892, loss_ce: 0.007683
2021-12-11 22:24:30,547 iteration 6709 : loss : 0.021463, loss_ce: 0.009050
2021-12-11 22:24:32,131 iteration 6710 : loss : 0.022942, loss_ce: 0.004600
2021-12-11 22:24:33,753 iteration 6711 : loss : 0.014875, loss_ce: 0.004685
2021-12-11 22:24:35,393 iteration 6712 : loss : 0.019161, loss_ce: 0.008074
2021-12-11 22:24:36,857 iteration 6713 : loss : 0.012214, loss_ce: 0.004715
2021-12-11 22:24:38,397 iteration 6714 : loss : 0.017017, loss_ce: 0.006186
2021-12-11 22:24:38,397 Training Data Eval:
2021-12-11 22:24:46,034   Average segmentation loss on training set: 0.0091
2021-12-11 22:24:46,035 Validation Data Eval:
2021-12-11 22:24:48,679   Average segmentation loss on validation set: 0.0711
2021-12-11 22:24:50,211 iteration 6715 : loss : 0.013972, loss_ce: 0.005094
 99%|████████████████████████████▋| 395/400 [3:07:24<02:30, 30.05s/it]2021-12-11 22:24:51,781 iteration 6716 : loss : 0.018357, loss_ce: 0.008332
2021-12-11 22:24:53,296 iteration 6717 : loss : 0.014583, loss_ce: 0.006281
2021-12-11 22:24:54,839 iteration 6718 : loss : 0.017158, loss_ce: 0.006999
2021-12-11 22:24:56,334 iteration 6719 : loss : 0.016314, loss_ce: 0.006599
2021-12-11 22:24:57,853 iteration 6720 : loss : 0.012808, loss_ce: 0.003928
2021-12-11 22:24:59,346 iteration 6721 : loss : 0.010349, loss_ce: 0.003494
2021-12-11 22:25:00,962 iteration 6722 : loss : 0.014357, loss_ce: 0.005708
2021-12-11 22:25:02,409 iteration 6723 : loss : 0.011997, loss_ce: 0.004004
2021-12-11 22:25:03,948 iteration 6724 : loss : 0.020927, loss_ce: 0.006864
2021-12-11 22:25:05,522 iteration 6725 : loss : 0.014013, loss_ce: 0.005322
2021-12-11 22:25:07,166 iteration 6726 : loss : 0.017365, loss_ce: 0.007570
2021-12-11 22:25:08,810 iteration 6727 : loss : 0.020265, loss_ce: 0.006599
2021-12-11 22:25:10,357 iteration 6728 : loss : 0.015953, loss_ce: 0.005570
2021-12-11 22:25:11,888 iteration 6729 : loss : 0.015847, loss_ce: 0.004780
2021-12-11 22:25:13,373 iteration 6730 : loss : 0.011589, loss_ce: 0.004133
2021-12-11 22:25:14,912 iteration 6731 : loss : 0.015516, loss_ce: 0.006076
2021-12-11 22:25:16,489 iteration 6732 : loss : 0.014815, loss_ce: 0.005900
 99%|████████████████████████████▋| 396/400 [3:07:50<01:55, 28.92s/it]2021-12-11 22:25:18,051 iteration 6733 : loss : 0.010416, loss_ce: 0.003535
2021-12-11 22:25:19,696 iteration 6734 : loss : 0.021304, loss_ce: 0.007270
2021-12-11 22:25:21,184 iteration 6735 : loss : 0.011305, loss_ce: 0.004433
2021-12-11 22:25:22,764 iteration 6736 : loss : 0.016844, loss_ce: 0.006820
2021-12-11 22:25:24,349 iteration 6737 : loss : 0.016879, loss_ce: 0.006106
2021-12-11 22:25:25,801 iteration 6738 : loss : 0.011179, loss_ce: 0.003156
2021-12-11 22:25:27,293 iteration 6739 : loss : 0.013532, loss_ce: 0.005044
2021-12-11 22:25:28,863 iteration 6740 : loss : 0.011425, loss_ce: 0.004949
2021-12-11 22:25:30,378 iteration 6741 : loss : 0.011883, loss_ce: 0.003922
2021-12-11 22:25:31,891 iteration 6742 : loss : 0.015360, loss_ce: 0.004725
2021-12-11 22:25:33,452 iteration 6743 : loss : 0.020712, loss_ce: 0.009379
2021-12-11 22:25:35,017 iteration 6744 : loss : 0.022605, loss_ce: 0.009572
2021-12-11 22:25:36,554 iteration 6745 : loss : 0.014592, loss_ce: 0.005592
2021-12-11 22:25:38,101 iteration 6746 : loss : 0.016086, loss_ce: 0.007080
2021-12-11 22:25:39,702 iteration 6747 : loss : 0.019656, loss_ce: 0.004180
2021-12-11 22:25:41,289 iteration 6748 : loss : 0.017313, loss_ce: 0.005237
2021-12-11 22:25:42,839 iteration 6749 : loss : 0.017450, loss_ce: 0.007691
 99%|████████████████████████████▊| 397/400 [3:08:16<01:24, 28.15s/it]2021-12-11 22:25:44,446 iteration 6750 : loss : 0.014614, loss_ce: 0.005673
2021-12-11 22:25:46,081 iteration 6751 : loss : 0.027219, loss_ce: 0.009988
2021-12-11 22:25:47,674 iteration 6752 : loss : 0.017790, loss_ce: 0.007418
2021-12-11 22:25:49,191 iteration 6753 : loss : 0.018772, loss_ce: 0.007555
2021-12-11 22:25:50,801 iteration 6754 : loss : 0.016753, loss_ce: 0.007570
2021-12-11 22:25:52,293 iteration 6755 : loss : 0.011126, loss_ce: 0.003100
2021-12-11 22:25:53,724 iteration 6756 : loss : 0.010029, loss_ce: 0.004413
2021-12-11 22:25:55,229 iteration 6757 : loss : 0.014567, loss_ce: 0.005995
2021-12-11 22:25:56,735 iteration 6758 : loss : 0.013412, loss_ce: 0.006499
2021-12-11 22:25:58,320 iteration 6759 : loss : 0.019654, loss_ce: 0.005527
2021-12-11 22:25:59,826 iteration 6760 : loss : 0.012593, loss_ce: 0.005717
2021-12-11 22:26:01,344 iteration 6761 : loss : 0.017489, loss_ce: 0.005821
2021-12-11 22:26:02,896 iteration 6762 : loss : 0.016404, loss_ce: 0.004909
2021-12-11 22:26:04,440 iteration 6763 : loss : 0.015170, loss_ce: 0.006581
2021-12-11 22:26:06,046 iteration 6764 : loss : 0.019323, loss_ce: 0.006899
2021-12-11 22:26:07,614 iteration 6765 : loss : 0.020872, loss_ce: 0.004869
2021-12-11 22:26:09,147 iteration 6766 : loss : 0.014062, loss_ce: 0.006258
100%|████████████████████████████▊| 398/400 [3:08:43<00:55, 27.59s/it]2021-12-11 22:26:10,793 iteration 6767 : loss : 0.023626, loss_ce: 0.010433
2021-12-11 22:26:12,301 iteration 6768 : loss : 0.014018, loss_ce: 0.004180
2021-12-11 22:26:13,809 iteration 6769 : loss : 0.011455, loss_ce: 0.003700
2021-12-11 22:26:15,359 iteration 6770 : loss : 0.020704, loss_ce: 0.006054
2021-12-11 22:26:16,864 iteration 6771 : loss : 0.014519, loss_ce: 0.006123
2021-12-11 22:26:18,412 iteration 6772 : loss : 0.023581, loss_ce: 0.008575
2021-12-11 22:26:19,885 iteration 6773 : loss : 0.011597, loss_ce: 0.004327
2021-12-11 22:26:21,407 iteration 6774 : loss : 0.020515, loss_ce: 0.007941
2021-12-11 22:26:22,895 iteration 6775 : loss : 0.015529, loss_ce: 0.003189
2021-12-11 22:26:24,467 iteration 6776 : loss : 0.014114, loss_ce: 0.005489
2021-12-11 22:26:26,003 iteration 6777 : loss : 0.020855, loss_ce: 0.008965
2021-12-11 22:26:27,475 iteration 6778 : loss : 0.014485, loss_ce: 0.005294
2021-12-11 22:26:28,998 iteration 6779 : loss : 0.014857, loss_ce: 0.007862
2021-12-11 22:26:30,566 iteration 6780 : loss : 0.012419, loss_ce: 0.004468
2021-12-11 22:26:32,116 iteration 6781 : loss : 0.014398, loss_ce: 0.005907
2021-12-11 22:26:33,617 iteration 6782 : loss : 0.016277, loss_ce: 0.006549
2021-12-11 22:26:35,211 iteration 6783 : loss : 0.024614, loss_ce: 0.009559
100%|████████████████████████████▉| 399/400 [3:09:09<00:27, 27.14s/it]2021-12-11 22:26:36,707 iteration 6784 : loss : 0.015146, loss_ce: 0.007228
2021-12-11 22:26:38,242 iteration 6785 : loss : 0.013733, loss_ce: 0.003979
2021-12-11 22:26:39,845 iteration 6786 : loss : 0.023143, loss_ce: 0.008453
2021-12-11 22:26:41,401 iteration 6787 : loss : 0.019323, loss_ce: 0.004747
2021-12-11 22:26:42,942 iteration 6788 : loss : 0.013643, loss_ce: 0.006380
2021-12-11 22:26:44,549 iteration 6789 : loss : 0.020551, loss_ce: 0.005325
2021-12-11 22:26:46,091 iteration 6790 : loss : 0.016118, loss_ce: 0.006814
2021-12-11 22:26:47,706 iteration 6791 : loss : 0.027586, loss_ce: 0.008557
2021-12-11 22:26:49,224 iteration 6792 : loss : 0.021512, loss_ce: 0.009793
2021-12-11 22:26:50,674 iteration 6793 : loss : 0.011494, loss_ce: 0.004219
2021-12-11 22:26:52,242 iteration 6794 : loss : 0.016525, loss_ce: 0.006083
2021-12-11 22:26:53,736 iteration 6795 : loss : 0.012250, loss_ce: 0.004924
2021-12-11 22:26:55,262 iteration 6796 : loss : 0.014744, loss_ce: 0.003923
2021-12-11 22:26:56,767 iteration 6797 : loss : 0.021220, loss_ce: 0.007253
2021-12-11 22:26:58,372 iteration 6798 : loss : 0.015598, loss_ce: 0.005241
2021-12-11 22:26:59,898 iteration 6799 : loss : 0.014400, loss_ce: 0.004436
2021-12-11 22:26:59,899 Training Data Eval:
2021-12-11 22:27:07,530   Average segmentation loss on training set: 0.0087
2021-12-11 22:27:07,531 Validation Data Eval:
2021-12-11 22:27:10,173   Average segmentation loss on validation set: 0.0752
2021-12-11 22:27:11,700 iteration 6800 : loss : 0.018164, loss_ce: 0.007227
2021-12-11 22:27:13,665 save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/NEW_TU/UNET_ADAM_seed100epoch_399.pth
2021-12-11 22:27:15,599 save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/NEW_TU/UNET_ADAM_seed100epoch_399.pth
100%|████████████████████████████▉| 399/400 [3:09:49<00:28, 28.55s/it]
