2021-12-17 15:44:40,872 Logging directory: /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/TransUNet/log_dir/trRUNMC_cv1_r3/i2i2l/
2021-12-17 15:44:40,873 Tensorboard directory: /scratch_net/biwidl217_second/arismu/Tensorboard/trRUNMC_cv1_r3/i2i2l/
2021-12-17 15:44:40,873 ============================================================
2021-12-17 15:44:40,873 EXPERIMENT NAME: trRUNMC_cv1_r3/i2i2l/
2021-12-17 15:44:40,873 ============================================================
2021-12-17 15:44:40,873 Loading data...
2021-12-17 15:44:40,873 Reading NCI - RUNMC images...
2021-12-17 15:44:40,873 Data root directory: /itet-stor/arismu/bmicdatasets-originals/Originals/Challenge_Datasets/NCI_Prostate/
2021-12-17 15:44:40,875 Already preprocessed this configuration. Loading now!
2021-12-17 15:44:40,892 Training Images: (256, 256, 286)
2021-12-17 15:44:40,892 Training Labels: (256, 256, 286)
2021-12-17 15:44:40,892 Validation Images: (256, 256, 98)
2021-12-17 15:44:40,892 Validation Labels: (256, 256, 98)
2021-12-17 15:44:40,892 ============================================================
2021-12-17 15:44:40,931 17 iterations per epoch. 6800 max iterations 
  0%|                                         | 0/400 [00:00<?, ?it/s]2021-12-17 15:44:43,449 iteration 1 : loss : 0.969076, loss_ce: 1.193729
2021-12-17 15:44:44,738 iteration 2 : loss : 0.976167, loss_ce: 1.189564
2021-12-17 15:44:46,003 iteration 3 : loss : 0.975741, loss_ce: 1.173044
2021-12-17 15:44:47,318 iteration 4 : loss : 0.943095, loss_ce: 1.146125
2021-12-17 15:44:48,566 iteration 5 : loss : 0.940868, loss_ce: 1.119719
2021-12-17 15:44:49,916 iteration 6 : loss : 0.918610, loss_ce: 1.088047
2021-12-17 15:44:51,240 iteration 7 : loss : 0.899285, loss_ce: 1.049595
2021-12-17 15:44:52,568 iteration 8 : loss : 0.873377, loss_ce: 1.013561
2021-12-17 15:44:53,785 iteration 9 : loss : 0.835436, loss_ce: 0.971335
2021-12-17 15:44:55,119 iteration 10 : loss : 0.816762, loss_ce: 0.929159
2021-12-17 15:44:56,458 iteration 11 : loss : 0.798396, loss_ce: 0.895309
2021-12-17 15:44:57,827 iteration 12 : loss : 0.771114, loss_ce: 0.854719
2021-12-17 15:44:59,109 iteration 13 : loss : 0.751536, loss_ce: 0.811430
2021-12-17 15:45:00,477 iteration 14 : loss : 0.729588, loss_ce: 0.778336
2021-12-17 15:45:01,786 iteration 15 : loss : 0.711650, loss_ce: 0.745119
2021-12-17 15:45:03,073 iteration 16 : loss : 0.686166, loss_ce: 0.708893
2021-12-17 15:45:04,337 iteration 17 : loss : 0.673516, loss_ce: 0.663460
  0%|                               | 1/400 [00:23<2:36:06, 23.48s/it]2021-12-17 15:45:05,738 iteration 18 : loss : 0.647712, loss_ce: 0.644823
2021-12-17 15:45:07,064 iteration 19 : loss : 0.637648, loss_ce: 0.600072
2021-12-17 15:45:08,477 iteration 20 : loss : 0.610557, loss_ce: 0.584498
2021-12-17 15:45:09,762 iteration 21 : loss : 0.599173, loss_ce: 0.550866
2021-12-17 15:45:11,002 iteration 22 : loss : 0.578467, loss_ce: 0.512300
2021-12-17 15:45:12,356 iteration 23 : loss : 0.563804, loss_ce: 0.492118
2021-12-17 15:45:13,711 iteration 24 : loss : 0.545465, loss_ce: 0.481734
2021-12-17 15:45:15,089 iteration 25 : loss : 0.533456, loss_ce: 0.475580
2021-12-17 15:45:16,392 iteration 26 : loss : 0.524163, loss_ce: 0.447055
2021-12-17 15:45:17,655 iteration 27 : loss : 0.511768, loss_ce: 0.413375
2021-12-17 15:45:18,905 iteration 28 : loss : 0.506613, loss_ce: 0.397374
2021-12-17 15:45:20,239 iteration 29 : loss : 0.498831, loss_ce: 0.397563
2021-12-17 15:45:21,514 iteration 30 : loss : 0.489215, loss_ce: 0.377717
2021-12-17 15:45:22,770 iteration 31 : loss : 0.479266, loss_ce: 0.338400
2021-12-17 15:45:24,065 iteration 32 : loss : 0.477240, loss_ce: 0.371992
2021-12-17 15:45:25,405 iteration 33 : loss : 0.474098, loss_ce: 0.354313
2021-12-17 15:45:26,808 iteration 34 : loss : 0.465564, loss_ce: 0.327875
  0%|▏                              | 2/400 [00:45<2:31:43, 22.87s/it]2021-12-17 15:45:28,197 iteration 35 : loss : 0.463776, loss_ce: 0.336763
2021-12-17 15:45:29,523 iteration 36 : loss : 0.453618, loss_ce: 0.280602
2021-12-17 15:45:30,868 iteration 37 : loss : 0.449627, loss_ce: 0.292428
2021-12-17 15:45:32,188 iteration 38 : loss : 0.444460, loss_ce: 0.291612
2021-12-17 15:45:33,413 iteration 39 : loss : 0.443931, loss_ce: 0.282210
2021-12-17 15:45:34,695 iteration 40 : loss : 0.445737, loss_ce: 0.298223
2021-12-17 15:45:35,905 iteration 41 : loss : 0.433455, loss_ce: 0.278845
2021-12-17 15:45:37,241 iteration 42 : loss : 0.435654, loss_ce: 0.280627
2021-12-17 15:45:38,553 iteration 43 : loss : 0.433229, loss_ce: 0.274679
2021-12-17 15:45:39,779 iteration 44 : loss : 0.434478, loss_ce: 0.283884
2021-12-17 15:45:41,149 iteration 45 : loss : 0.422926, loss_ce: 0.244281
2021-12-17 15:45:42,464 iteration 46 : loss : 0.429424, loss_ce: 0.261320
2021-12-17 15:45:43,779 iteration 47 : loss : 0.419047, loss_ce: 0.238162
2021-12-17 15:45:45,089 iteration 48 : loss : 0.425814, loss_ce: 0.262222
2021-12-17 15:45:46,450 iteration 49 : loss : 0.416816, loss_ce: 0.237809
2021-12-17 15:45:47,813 iteration 50 : loss : 0.412105, loss_ce: 0.230211
2021-12-17 15:45:49,194 iteration 51 : loss : 0.414966, loss_ce: 0.241386
  1%|▏                              | 3/400 [01:08<2:29:51, 22.65s/it]2021-12-17 15:45:50,508 iteration 52 : loss : 0.413994, loss_ce: 0.226672
2021-12-17 15:45:51,753 iteration 53 : loss : 0.411816, loss_ce: 0.235404
2021-12-17 15:45:53,124 iteration 54 : loss : 0.405650, loss_ce: 0.219622
2021-12-17 15:45:54,466 iteration 55 : loss : 0.405003, loss_ce: 0.210278
2021-12-17 15:45:55,816 iteration 56 : loss : 0.425719, loss_ce: 0.258766
2021-12-17 15:45:57,100 iteration 57 : loss : 0.415863, loss_ce: 0.245463
2021-12-17 15:45:58,360 iteration 58 : loss : 0.417446, loss_ce: 0.247652
2021-12-17 15:45:59,619 iteration 59 : loss : 0.410829, loss_ce: 0.224614
2021-12-17 15:46:00,903 iteration 60 : loss : 0.414622, loss_ce: 0.238253
2021-12-17 15:46:02,200 iteration 61 : loss : 0.406086, loss_ce: 0.224977
2021-12-17 15:46:03,579 iteration 62 : loss : 0.401632, loss_ce: 0.195860
2021-12-17 15:46:05,022 iteration 63 : loss : 0.412899, loss_ce: 0.235221
2021-12-17 15:46:06,351 iteration 64 : loss : 0.404569, loss_ce: 0.215441
2021-12-17 15:46:07,670 iteration 65 : loss : 0.393705, loss_ce: 0.190683
2021-12-17 15:46:09,036 iteration 66 : loss : 0.394822, loss_ce: 0.192801
2021-12-17 15:46:10,335 iteration 67 : loss : 0.398526, loss_ce: 0.210233
2021-12-17 15:46:11,580 iteration 68 : loss : 0.410400, loss_ce: 0.231314
  1%|▎                              | 4/400 [01:30<2:28:48, 22.55s/it]2021-12-17 15:46:12,986 iteration 69 : loss : 0.396289, loss_ce: 0.204869
2021-12-17 15:46:14,283 iteration 70 : loss : 0.384355, loss_ce: 0.176219
2021-12-17 15:46:15,589 iteration 71 : loss : 0.417057, loss_ce: 0.245947
2021-12-17 15:46:16,913 iteration 72 : loss : 0.399059, loss_ce: 0.211143
2021-12-17 15:46:18,256 iteration 73 : loss : 0.399116, loss_ce: 0.194537
2021-12-17 15:46:19,591 iteration 74 : loss : 0.393249, loss_ce: 0.196886
2021-12-17 15:46:20,906 iteration 75 : loss : 0.414552, loss_ce: 0.239755
2021-12-17 15:46:22,209 iteration 76 : loss : 0.396103, loss_ce: 0.200624
2021-12-17 15:46:23,600 iteration 77 : loss : 0.390228, loss_ce: 0.192639
2021-12-17 15:46:24,973 iteration 78 : loss : 0.400650, loss_ce: 0.207370
2021-12-17 15:46:26,352 iteration 79 : loss : 0.385105, loss_ce: 0.176686
2021-12-17 15:46:27,632 iteration 80 : loss : 0.385781, loss_ce: 0.178750
2021-12-17 15:46:29,047 iteration 81 : loss : 0.413908, loss_ce: 0.236829
2021-12-17 15:46:30,386 iteration 82 : loss : 0.383443, loss_ce: 0.167906
2021-12-17 15:46:31,695 iteration 83 : loss : 0.381409, loss_ce: 0.155624
2021-12-17 15:46:33,131 iteration 84 : loss : 0.406249, loss_ce: 0.218843
2021-12-17 15:46:33,131 Training Data Eval:
2021-12-17 15:46:40,130   Average segmentation loss on training set: 0.3915
2021-12-17 15:46:40,131 Validation Data Eval:
2021-12-17 15:46:42,709   Average segmentation loss on validation set: 0.4238
2021-12-17 15:46:49,310 Found new lowest validation loss at iteration 84! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/TU_3seeds/TU_RESNET_no_pretraining_SGD_best_val_loss_seed100.pth
2021-12-17 15:46:50,622 iteration 85 : loss : 0.409632, loss_ce: 0.225327
  1%|▍                              | 5/400 [02:09<3:07:36, 28.50s/it]2021-12-17 15:46:52,024 iteration 86 : loss : 0.399043, loss_ce: 0.214933
2021-12-17 15:46:53,316 iteration 87 : loss : 0.393614, loss_ce: 0.189906
2021-12-17 15:46:54,575 iteration 88 : loss : 0.410051, loss_ce: 0.236628
2021-12-17 15:46:55,894 iteration 89 : loss : 0.379041, loss_ce: 0.166798
2021-12-17 15:46:57,194 iteration 90 : loss : 0.388176, loss_ce: 0.185049
2021-12-17 15:46:58,548 iteration 91 : loss : 0.399879, loss_ce: 0.213714
2021-12-17 15:46:59,911 iteration 92 : loss : 0.384628, loss_ce: 0.167252
2021-12-17 15:47:01,169 iteration 93 : loss : 0.379832, loss_ce: 0.165870
2021-12-17 15:47:02,519 iteration 94 : loss : 0.395336, loss_ce: 0.200392
2021-12-17 15:47:03,824 iteration 95 : loss : 0.398417, loss_ce: 0.214051
2021-12-17 15:47:05,195 iteration 96 : loss : 0.391531, loss_ce: 0.194681
2021-12-17 15:47:06,513 iteration 97 : loss : 0.390206, loss_ce: 0.184683
2021-12-17 15:47:07,861 iteration 98 : loss : 0.384709, loss_ce: 0.169026
2021-12-17 15:47:09,168 iteration 99 : loss : 0.384216, loss_ce: 0.168421
2021-12-17 15:47:10,515 iteration 100 : loss : 0.391822, loss_ce: 0.191841
2021-12-17 15:47:11,812 iteration 101 : loss : 0.383901, loss_ce: 0.184553
2021-12-17 15:47:13,102 iteration 102 : loss : 0.403506, loss_ce: 0.218199
  2%|▍                              | 6/400 [02:32<2:53:41, 26.45s/it]2021-12-17 15:47:14,496 iteration 103 : loss : 0.380355, loss_ce: 0.165916
2021-12-17 15:47:15,865 iteration 104 : loss : 0.388930, loss_ce: 0.182391
2021-12-17 15:47:17,227 iteration 105 : loss : 0.384536, loss_ce: 0.188428
2021-12-17 15:47:18,663 iteration 106 : loss : 0.375753, loss_ce: 0.164428
2021-12-17 15:47:20,042 iteration 107 : loss : 0.380296, loss_ce: 0.159626
2021-12-17 15:47:21,399 iteration 108 : loss : 0.374475, loss_ce: 0.150891
2021-12-17 15:47:22,713 iteration 109 : loss : 0.398893, loss_ce: 0.202120
2021-12-17 15:47:24,068 iteration 110 : loss : 0.398166, loss_ce: 0.207072
2021-12-17 15:47:25,501 iteration 111 : loss : 0.392746, loss_ce: 0.203279
2021-12-17 15:47:26,877 iteration 112 : loss : 0.384078, loss_ce: 0.184998
2021-12-17 15:47:28,208 iteration 113 : loss : 0.381357, loss_ce: 0.171732
2021-12-17 15:47:29,624 iteration 114 : loss : 0.383155, loss_ce: 0.168907
2021-12-17 15:47:30,969 iteration 115 : loss : 0.398000, loss_ce: 0.219734
2021-12-17 15:47:32,362 iteration 116 : loss : 0.395099, loss_ce: 0.208154
2021-12-17 15:47:33,693 iteration 117 : loss : 0.388100, loss_ce: 0.193821
2021-12-17 15:47:35,045 iteration 118 : loss : 0.399072, loss_ce: 0.217515
2021-12-17 15:47:36,423 iteration 119 : loss : 0.376120, loss_ce: 0.169849
  2%|▌                              | 7/400 [02:55<2:46:32, 25.43s/it]2021-12-17 15:47:37,895 iteration 120 : loss : 0.386867, loss_ce: 0.191806
2021-12-17 15:47:39,296 iteration 121 : loss : 0.381403, loss_ce: 0.172261
2021-12-17 15:47:40,602 iteration 122 : loss : 0.387101, loss_ce: 0.196255
2021-12-17 15:47:42,005 iteration 123 : loss : 0.378570, loss_ce: 0.178702
2021-12-17 15:47:43,406 iteration 124 : loss : 0.373442, loss_ce: 0.166274
2021-12-17 15:47:44,761 iteration 125 : loss : 0.398009, loss_ce: 0.218295
2021-12-17 15:47:46,163 iteration 126 : loss : 0.373107, loss_ce: 0.160897
2021-12-17 15:47:47,571 iteration 127 : loss : 0.383427, loss_ce: 0.184374
2021-12-17 15:47:48,996 iteration 128 : loss : 0.393790, loss_ce: 0.205506
2021-12-17 15:47:50,349 iteration 129 : loss : 0.373634, loss_ce: 0.170033
2021-12-17 15:47:51,776 iteration 130 : loss : 0.391770, loss_ce: 0.208789
2021-12-17 15:47:53,130 iteration 131 : loss : 0.390743, loss_ce: 0.199080
2021-12-17 15:47:54,449 iteration 132 : loss : 0.372190, loss_ce: 0.155480
2021-12-17 15:47:55,867 iteration 133 : loss : 0.373636, loss_ce: 0.161750
2021-12-17 15:47:57,243 iteration 134 : loss : 0.371853, loss_ce: 0.171865
2021-12-17 15:47:58,624 iteration 135 : loss : 0.390572, loss_ce: 0.192604
2021-12-17 15:47:59,985 iteration 136 : loss : 0.380855, loss_ce: 0.189781
  2%|▌                              | 8/400 [03:19<2:42:13, 24.83s/it]2021-12-17 15:48:01,339 iteration 137 : loss : 0.365070, loss_ce: 0.160544
2021-12-17 15:48:02,674 iteration 138 : loss : 0.398287, loss_ce: 0.224023
2021-12-17 15:48:04,102 iteration 139 : loss : 0.371456, loss_ce: 0.160876
2021-12-17 15:48:05,558 iteration 140 : loss : 0.377020, loss_ce: 0.166984
2021-12-17 15:48:06,943 iteration 141 : loss : 0.368246, loss_ce: 0.157554
2021-12-17 15:48:08,260 iteration 142 : loss : 0.372281, loss_ce: 0.170883
2021-12-17 15:48:09,588 iteration 143 : loss : 0.384181, loss_ce: 0.181165
2021-12-17 15:48:11,006 iteration 144 : loss : 0.380066, loss_ce: 0.167004
2021-12-17 15:48:12,528 iteration 145 : loss : 0.386016, loss_ce: 0.204750
2021-12-17 15:48:13,880 iteration 146 : loss : 0.366968, loss_ce: 0.159926
2021-12-17 15:48:15,234 iteration 147 : loss : 0.379097, loss_ce: 0.187060
2021-12-17 15:48:16,609 iteration 148 : loss : 0.390905, loss_ce: 0.201526
2021-12-17 15:48:18,004 iteration 149 : loss : 0.378666, loss_ce: 0.179735
2021-12-17 15:48:19,361 iteration 150 : loss : 0.389322, loss_ce: 0.199850
2021-12-17 15:48:20,724 iteration 151 : loss : 0.380203, loss_ce: 0.182672
2021-12-17 15:48:22,150 iteration 152 : loss : 0.378190, loss_ce: 0.181853
2021-12-17 15:48:23,578 iteration 153 : loss : 0.373201, loss_ce: 0.187724
  2%|▋                              | 9/400 [03:42<2:39:18, 24.45s/it]2021-12-17 15:48:25,005 iteration 154 : loss : 0.381377, loss_ce: 0.179870
2021-12-17 15:48:26,401 iteration 155 : loss : 0.370397, loss_ce: 0.172752
2021-12-17 15:48:27,773 iteration 156 : loss : 0.378947, loss_ce: 0.190601
2021-12-17 15:48:29,163 iteration 157 : loss : 0.370157, loss_ce: 0.169202
2021-12-17 15:48:30,554 iteration 158 : loss : 0.379030, loss_ce: 0.184140
2021-12-17 15:48:31,925 iteration 159 : loss : 0.381914, loss_ce: 0.176076
2021-12-17 15:48:33,283 iteration 160 : loss : 0.369811, loss_ce: 0.152463
2021-12-17 15:48:34,678 iteration 161 : loss : 0.375011, loss_ce: 0.179982
2021-12-17 15:48:36,129 iteration 162 : loss : 0.371574, loss_ce: 0.182853
2021-12-17 15:48:37,420 iteration 163 : loss : 0.364368, loss_ce: 0.171313
2021-12-17 15:48:38,835 iteration 164 : loss : 0.362801, loss_ce: 0.165351
2021-12-17 15:48:40,184 iteration 165 : loss : 0.363097, loss_ce: 0.169113
2021-12-17 15:48:41,618 iteration 166 : loss : 0.374330, loss_ce: 0.178739
2021-12-17 15:48:43,037 iteration 167 : loss : 0.380887, loss_ce: 0.187874
2021-12-17 15:48:44,451 iteration 168 : loss : 0.370751, loss_ce: 0.179041
2021-12-17 15:48:45,806 iteration 169 : loss : 0.378224, loss_ce: 0.190293
2021-12-17 15:48:45,806 Training Data Eval:
2021-12-17 15:48:52,957   Average segmentation loss on training set: 0.3674
2021-12-17 15:48:52,957 Validation Data Eval:
2021-12-17 15:48:55,453   Average segmentation loss on validation set: 0.3892
2021-12-17 15:49:01,932 Found new lowest validation loss at iteration 169! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/TU_3seeds/TU_RESNET_no_pretraining_SGD_best_val_loss_seed100.pth
2021-12-17 15:49:03,287 iteration 170 : loss : 0.372473, loss_ce: 0.183003
  2%|▊                             | 10/400 [04:22<3:09:31, 29.16s/it]2021-12-17 15:49:04,674 iteration 171 : loss : 0.379080, loss_ce: 0.194648
2021-12-17 15:49:05,888 iteration 172 : loss : 0.367256, loss_ce: 0.151372
2021-12-17 15:49:07,139 iteration 173 : loss : 0.369499, loss_ce: 0.176955
2021-12-17 15:49:08,515 iteration 174 : loss : 0.362728, loss_ce: 0.152812
2021-12-17 15:49:09,809 iteration 175 : loss : 0.381001, loss_ce: 0.187275
2021-12-17 15:49:11,217 iteration 176 : loss : 0.362991, loss_ce: 0.157536
2021-12-17 15:49:12,525 iteration 177 : loss : 0.359545, loss_ce: 0.147994
2021-12-17 15:49:13,892 iteration 178 : loss : 0.358735, loss_ce: 0.147705
2021-12-17 15:49:15,241 iteration 179 : loss : 0.365867, loss_ce: 0.176917
2021-12-17 15:49:16,598 iteration 180 : loss : 0.374468, loss_ce: 0.172746
2021-12-17 15:49:17,957 iteration 181 : loss : 0.360054, loss_ce: 0.159318
2021-12-17 15:49:19,313 iteration 182 : loss : 0.368989, loss_ce: 0.170211
2021-12-17 15:49:20,680 iteration 183 : loss : 0.368521, loss_ce: 0.165193
2021-12-17 15:49:22,012 iteration 184 : loss : 0.363532, loss_ce: 0.176066
2021-12-17 15:49:23,301 iteration 185 : loss : 0.366463, loss_ce: 0.183851
2021-12-17 15:49:24,583 iteration 186 : loss : 0.381024, loss_ce: 0.187383
2021-12-17 15:49:25,847 iteration 187 : loss : 0.370479, loss_ce: 0.180123
  3%|▊                             | 11/400 [04:44<2:55:56, 27.14s/it]2021-12-17 15:49:27,245 iteration 188 : loss : 0.365791, loss_ce: 0.160174
2021-12-17 15:49:28,653 iteration 189 : loss : 0.366498, loss_ce: 0.176490
2021-12-17 15:49:30,100 iteration 190 : loss : 0.358875, loss_ce: 0.160266
2021-12-17 15:49:31,506 iteration 191 : loss : 0.356383, loss_ce: 0.156242
2021-12-17 15:49:32,826 iteration 192 : loss : 0.369503, loss_ce: 0.177469
2021-12-17 15:49:34,179 iteration 193 : loss : 0.366844, loss_ce: 0.158300
2021-12-17 15:49:35,521 iteration 194 : loss : 0.362727, loss_ce: 0.160763
2021-12-17 15:49:36,981 iteration 195 : loss : 0.359254, loss_ce: 0.165294
2021-12-17 15:49:38,395 iteration 196 : loss : 0.350078, loss_ce: 0.140661
2021-12-17 15:49:39,788 iteration 197 : loss : 0.359204, loss_ce: 0.167730
2021-12-17 15:49:41,212 iteration 198 : loss : 0.386495, loss_ce: 0.202839
2021-12-17 15:49:42,623 iteration 199 : loss : 0.378444, loss_ce: 0.195959
2021-12-17 15:49:43,972 iteration 200 : loss : 0.366953, loss_ce: 0.161822
2021-12-17 15:49:45,328 iteration 201 : loss : 0.368297, loss_ce: 0.173240
2021-12-17 15:49:46,611 iteration 202 : loss : 0.363195, loss_ce: 0.149842
2021-12-17 15:49:48,049 iteration 203 : loss : 0.359492, loss_ce: 0.171620
2021-12-17 15:49:49,420 iteration 204 : loss : 0.380781, loss_ce: 0.202138
  3%|▉                             | 12/400 [05:08<2:48:30, 26.06s/it]2021-12-17 15:49:50,933 iteration 205 : loss : 0.355148, loss_ce: 0.160397
2021-12-17 15:49:52,315 iteration 206 : loss : 0.358332, loss_ce: 0.156452
2021-12-17 15:49:53,757 iteration 207 : loss : 0.368563, loss_ce: 0.160431
2021-12-17 15:49:55,176 iteration 208 : loss : 0.364139, loss_ce: 0.182070
2021-12-17 15:49:56,572 iteration 209 : loss : 0.369628, loss_ce: 0.165182
2021-12-17 15:49:57,945 iteration 210 : loss : 0.364851, loss_ce: 0.178541
2021-12-17 15:49:59,330 iteration 211 : loss : 0.355134, loss_ce: 0.172134
2021-12-17 15:50:00,751 iteration 212 : loss : 0.375176, loss_ce: 0.195927
2021-12-17 15:50:02,171 iteration 213 : loss : 0.364768, loss_ce: 0.185688
2021-12-17 15:50:03,530 iteration 214 : loss : 0.358321, loss_ce: 0.156709
2021-12-17 15:50:04,875 iteration 215 : loss : 0.352376, loss_ce: 0.151402
2021-12-17 15:50:06,304 iteration 216 : loss : 0.356099, loss_ce: 0.162864
2021-12-17 15:50:07,736 iteration 217 : loss : 0.362910, loss_ce: 0.161237
2021-12-17 15:50:09,093 iteration 218 : loss : 0.366470, loss_ce: 0.181397
2021-12-17 15:50:10,440 iteration 219 : loss : 0.357456, loss_ce: 0.171074
2021-12-17 15:50:11,838 iteration 220 : loss : 0.350645, loss_ce: 0.156459
2021-12-17 15:50:13,254 iteration 221 : loss : 0.359644, loss_ce: 0.155850
  3%|▉                             | 13/400 [05:32<2:43:41, 25.38s/it]2021-12-17 15:50:14,691 iteration 222 : loss : 0.357810, loss_ce: 0.163306
2021-12-17 15:50:16,043 iteration 223 : loss : 0.366733, loss_ce: 0.177704
2021-12-17 15:50:17,411 iteration 224 : loss : 0.345833, loss_ce: 0.141265
2021-12-17 15:50:18,899 iteration 225 : loss : 0.360170, loss_ce: 0.177978
2021-12-17 15:50:20,296 iteration 226 : loss : 0.353369, loss_ce: 0.156370
2021-12-17 15:50:21,660 iteration 227 : loss : 0.346189, loss_ce: 0.149740
2021-12-17 15:50:23,017 iteration 228 : loss : 0.364273, loss_ce: 0.163109
2021-12-17 15:50:24,416 iteration 229 : loss : 0.353926, loss_ce: 0.154984
2021-12-17 15:50:25,754 iteration 230 : loss : 0.351510, loss_ce: 0.169863
2021-12-17 15:50:27,133 iteration 231 : loss : 0.354015, loss_ce: 0.165534
2021-12-17 15:50:28,509 iteration 232 : loss : 0.367587, loss_ce: 0.176287
2021-12-17 15:50:29,832 iteration 233 : loss : 0.366153, loss_ce: 0.189946
2021-12-17 15:50:31,200 iteration 234 : loss : 0.353809, loss_ce: 0.155402
2021-12-17 15:50:32,549 iteration 235 : loss : 0.344092, loss_ce: 0.152626
2021-12-17 15:50:33,921 iteration 236 : loss : 0.359153, loss_ce: 0.163779
2021-12-17 15:50:35,257 iteration 237 : loss : 0.361460, loss_ce: 0.179763
2021-12-17 15:50:36,672 iteration 238 : loss : 0.353731, loss_ce: 0.141529
  4%|█                             | 14/400 [05:55<2:39:29, 24.79s/it]2021-12-17 15:50:38,093 iteration 239 : loss : 0.346934, loss_ce: 0.149804
2021-12-17 15:50:39,550 iteration 240 : loss : 0.343004, loss_ce: 0.145158
2021-12-17 15:50:40,970 iteration 241 : loss : 0.352118, loss_ce: 0.161999
2021-12-17 15:50:42,323 iteration 242 : loss : 0.348189, loss_ce: 0.148570
2021-12-17 15:50:43,669 iteration 243 : loss : 0.339159, loss_ce: 0.145167
2021-12-17 15:50:45,051 iteration 244 : loss : 0.351648, loss_ce: 0.165925
2021-12-17 15:50:46,372 iteration 245 : loss : 0.350348, loss_ce: 0.141458
2021-12-17 15:50:47,732 iteration 246 : loss : 0.349326, loss_ce: 0.151100
2021-12-17 15:50:49,136 iteration 247 : loss : 0.356571, loss_ce: 0.163053
2021-12-17 15:50:50,546 iteration 248 : loss : 0.362762, loss_ce: 0.190402
2021-12-17 15:50:51,899 iteration 249 : loss : 0.343425, loss_ce: 0.148270
2021-12-17 15:50:53,273 iteration 250 : loss : 0.354442, loss_ce: 0.157566
2021-12-17 15:50:54,599 iteration 251 : loss : 0.361620, loss_ce: 0.179981
2021-12-17 15:50:56,046 iteration 252 : loss : 0.360662, loss_ce: 0.190336
2021-12-17 15:50:57,418 iteration 253 : loss : 0.338104, loss_ce: 0.142750
2021-12-17 15:50:58,778 iteration 254 : loss : 0.360035, loss_ce: 0.174566
2021-12-17 15:50:58,778 Training Data Eval:
2021-12-17 15:51:05,949   Average segmentation loss on training set: 0.3445
2021-12-17 15:51:05,949 Validation Data Eval:
2021-12-17 15:51:08,423   Average segmentation loss on validation set: 0.3656
2021-12-17 15:51:14,609 Found new lowest validation loss at iteration 254! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/TU_3seeds/TU_RESNET_no_pretraining_SGD_best_val_loss_seed100.pth
2021-12-17 15:51:15,934 iteration 255 : loss : 0.366173, loss_ce: 0.182001
  4%|█▏                            | 15/400 [06:35<3:07:02, 29.15s/it]2021-12-17 15:51:17,250 iteration 256 : loss : 0.351346, loss_ce: 0.147028
2021-12-17 15:51:18,521 iteration 257 : loss : 0.354971, loss_ce: 0.170200
2021-12-17 15:51:19,880 iteration 258 : loss : 0.364882, loss_ce: 0.179491
2021-12-17 15:51:21,207 iteration 259 : loss : 0.339102, loss_ce: 0.150323
2021-12-17 15:51:22,479 iteration 260 : loss : 0.371937, loss_ce: 0.209542
2021-12-17 15:51:23,825 iteration 261 : loss : 0.352469, loss_ce: 0.160622
2021-12-17 15:51:25,193 iteration 262 : loss : 0.353267, loss_ce: 0.159432
2021-12-17 15:51:26,471 iteration 263 : loss : 0.337716, loss_ce: 0.143796
2021-12-17 15:51:27,840 iteration 264 : loss : 0.340258, loss_ce: 0.132596
2021-12-17 15:51:29,261 iteration 265 : loss : 0.373151, loss_ce: 0.202106
2021-12-17 15:51:30,609 iteration 266 : loss : 0.350347, loss_ce: 0.145284
2021-12-17 15:51:32,020 iteration 267 : loss : 0.336495, loss_ce: 0.143181
2021-12-17 15:51:33,370 iteration 268 : loss : 0.344704, loss_ce: 0.163122
2021-12-17 15:51:34,709 iteration 269 : loss : 0.351751, loss_ce: 0.160393
2021-12-17 15:51:36,021 iteration 270 : loss : 0.341505, loss_ce: 0.145339
2021-12-17 15:51:37,321 iteration 271 : loss : 0.342750, loss_ce: 0.160040
2021-12-17 15:51:38,601 iteration 272 : loss : 0.347443, loss_ce: 0.157035
  4%|█▏                            | 16/400 [06:57<2:54:05, 27.20s/it]2021-12-17 15:51:40,055 iteration 273 : loss : 0.344563, loss_ce: 0.142451
2021-12-17 15:51:41,442 iteration 274 : loss : 0.337169, loss_ce: 0.153560
2021-12-17 15:51:42,838 iteration 275 : loss : 0.342516, loss_ce: 0.120424
2021-12-17 15:51:44,225 iteration 276 : loss : 0.348199, loss_ce: 0.162962
2021-12-17 15:51:45,601 iteration 277 : loss : 0.338801, loss_ce: 0.150896
2021-12-17 15:51:46,999 iteration 278 : loss : 0.353080, loss_ce: 0.162875
2021-12-17 15:51:48,384 iteration 279 : loss : 0.345891, loss_ce: 0.156873
2021-12-17 15:51:49,773 iteration 280 : loss : 0.340504, loss_ce: 0.161175
2021-12-17 15:51:51,202 iteration 281 : loss : 0.356932, loss_ce: 0.187709
2021-12-17 15:51:52,600 iteration 282 : loss : 0.342053, loss_ce: 0.145675
2021-12-17 15:51:53,946 iteration 283 : loss : 0.339421, loss_ce: 0.148640
2021-12-17 15:51:55,348 iteration 284 : loss : 0.355104, loss_ce: 0.186172
2021-12-17 15:51:56,776 iteration 285 : loss : 0.330841, loss_ce: 0.132002
2021-12-17 15:51:58,069 iteration 286 : loss : 0.333506, loss_ce: 0.149437
2021-12-17 15:51:59,454 iteration 287 : loss : 0.346399, loss_ce: 0.163580
2021-12-17 15:52:00,853 iteration 288 : loss : 0.338951, loss_ce: 0.158394
2021-12-17 15:52:02,212 iteration 289 : loss : 0.338732, loss_ce: 0.145794
  4%|█▎                            | 17/400 [07:21<2:46:43, 26.12s/it]2021-12-17 15:52:03,674 iteration 290 : loss : 0.340646, loss_ce: 0.164601
2021-12-17 15:52:05,003 iteration 291 : loss : 0.338835, loss_ce: 0.139290
2021-12-17 15:52:06,336 iteration 292 : loss : 0.341923, loss_ce: 0.160466
2021-12-17 15:52:07,763 iteration 293 : loss : 0.333109, loss_ce: 0.143914
2021-12-17 15:52:09,127 iteration 294 : loss : 0.333940, loss_ce: 0.158703
2021-12-17 15:52:10,557 iteration 295 : loss : 0.347871, loss_ce: 0.166256
2021-12-17 15:52:11,990 iteration 296 : loss : 0.342307, loss_ce: 0.167797
2021-12-17 15:52:13,381 iteration 297 : loss : 0.332515, loss_ce: 0.156445
2021-12-17 15:52:14,742 iteration 298 : loss : 0.339688, loss_ce: 0.170236
2021-12-17 15:52:16,059 iteration 299 : loss : 0.341387, loss_ce: 0.144518
2021-12-17 15:52:17,421 iteration 300 : loss : 0.330142, loss_ce: 0.148106
2021-12-17 15:52:18,718 iteration 301 : loss : 0.347060, loss_ce: 0.148412
2021-12-17 15:52:20,150 iteration 302 : loss : 0.322129, loss_ce: 0.134383
2021-12-17 15:52:21,568 iteration 303 : loss : 0.331663, loss_ce: 0.136161
2021-12-17 15:52:22,995 iteration 304 : loss : 0.341761, loss_ce: 0.162127
2021-12-17 15:52:24,355 iteration 305 : loss : 0.339134, loss_ce: 0.149056
2021-12-17 15:52:25,723 iteration 306 : loss : 0.334580, loss_ce: 0.144840
  4%|█▎                            | 18/400 [07:44<2:41:18, 25.34s/it]2021-12-17 15:52:27,098 iteration 307 : loss : 0.339725, loss_ce: 0.136231
2021-12-17 15:52:28,415 iteration 308 : loss : 0.340241, loss_ce: 0.159729
2021-12-17 15:52:29,748 iteration 309 : loss : 0.343467, loss_ce: 0.169238
2021-12-17 15:52:31,133 iteration 310 : loss : 0.331163, loss_ce: 0.147783
2021-12-17 15:52:32,542 iteration 311 : loss : 0.327466, loss_ce: 0.141143
2021-12-17 15:52:33,951 iteration 312 : loss : 0.322932, loss_ce: 0.135807
2021-12-17 15:52:35,294 iteration 313 : loss : 0.336937, loss_ce: 0.151189
2021-12-17 15:52:36,696 iteration 314 : loss : 0.346751, loss_ce: 0.177466
2021-12-17 15:52:38,133 iteration 315 : loss : 0.336046, loss_ce: 0.142603
2021-12-17 15:52:39,515 iteration 316 : loss : 0.345201, loss_ce: 0.152836
2021-12-17 15:52:40,828 iteration 317 : loss : 0.324325, loss_ce: 0.126929
2021-12-17 15:52:42,178 iteration 318 : loss : 0.333661, loss_ce: 0.150529
2021-12-17 15:52:43,615 iteration 319 : loss : 0.313623, loss_ce: 0.133620
2021-12-17 15:52:44,964 iteration 320 : loss : 0.318900, loss_ce: 0.130771
2021-12-17 15:52:46,327 iteration 321 : loss : 0.340990, loss_ce: 0.172235
2021-12-17 15:52:47,708 iteration 322 : loss : 0.331113, loss_ce: 0.151630
2021-12-17 15:52:49,130 iteration 323 : loss : 0.330937, loss_ce: 0.154217
  5%|█▍                            | 19/400 [08:08<2:37:12, 24.76s/it]2021-12-17 15:52:50,483 iteration 324 : loss : 0.315605, loss_ce: 0.120094
2021-12-17 15:52:51,849 iteration 325 : loss : 0.326315, loss_ce: 0.139212
2021-12-17 15:52:53,213 iteration 326 : loss : 0.316181, loss_ce: 0.146765
2021-12-17 15:52:54,664 iteration 327 : loss : 0.347160, loss_ce: 0.159853
2021-12-17 15:52:56,070 iteration 328 : loss : 0.329414, loss_ce: 0.157873
2021-12-17 15:52:57,445 iteration 329 : loss : 0.321464, loss_ce: 0.135431
2021-12-17 15:52:58,737 iteration 330 : loss : 0.335460, loss_ce: 0.154569
2021-12-17 15:53:00,158 iteration 331 : loss : 0.321751, loss_ce: 0.129198
2021-12-17 15:53:01,562 iteration 332 : loss : 0.325997, loss_ce: 0.156565
2021-12-17 15:53:02,877 iteration 333 : loss : 0.327737, loss_ce: 0.136138
2021-12-17 15:53:04,278 iteration 334 : loss : 0.341497, loss_ce: 0.169051
2021-12-17 15:53:05,628 iteration 335 : loss : 0.333632, loss_ce: 0.135067
2021-12-17 15:53:07,042 iteration 336 : loss : 0.320230, loss_ce: 0.139463
2021-12-17 15:53:08,391 iteration 337 : loss : 0.321024, loss_ce: 0.143582
2021-12-17 15:53:09,710 iteration 338 : loss : 0.336704, loss_ce: 0.162605
2021-12-17 15:53:11,101 iteration 339 : loss : 0.303237, loss_ce: 0.126156
2021-12-17 15:53:11,102 Training Data Eval:
2021-12-17 15:53:18,265   Average segmentation loss on training set: 0.3180
2021-12-17 15:53:18,265 Validation Data Eval:
2021-12-17 15:53:20,753   Average segmentation loss on validation set: 0.3312
2021-12-17 15:53:27,038 Found new lowest validation loss at iteration 339! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/TU_3seeds/TU_RESNET_no_pretraining_SGD_best_val_loss_seed100.pth
2021-12-17 15:53:28,409 iteration 340 : loss : 0.322167, loss_ce: 0.138732
  5%|█▌                            | 20/400 [08:47<3:04:23, 29.12s/it]2021-12-17 15:53:29,825 iteration 341 : loss : 0.314179, loss_ce: 0.139776
2021-12-17 15:53:31,200 iteration 342 : loss : 0.308587, loss_ce: 0.126129
2021-12-17 15:53:32,634 iteration 343 : loss : 0.337976, loss_ce: 0.169045
2021-12-17 15:53:33,951 iteration 344 : loss : 0.324449, loss_ce: 0.135416
2021-12-17 15:53:35,293 iteration 345 : loss : 0.326588, loss_ce: 0.149030
2021-12-17 15:53:36,690 iteration 346 : loss : 0.322619, loss_ce: 0.134865
2021-12-17 15:53:37,983 iteration 347 : loss : 0.304531, loss_ce: 0.133880
2021-12-17 15:53:39,402 iteration 348 : loss : 0.318338, loss_ce: 0.143775
2021-12-17 15:53:40,721 iteration 349 : loss : 0.318407, loss_ce: 0.139748
2021-12-17 15:53:41,961 iteration 350 : loss : 0.317472, loss_ce: 0.123136
2021-12-17 15:53:43,344 iteration 351 : loss : 0.333362, loss_ce: 0.140804
2021-12-17 15:53:44,666 iteration 352 : loss : 0.314610, loss_ce: 0.135925
2021-12-17 15:53:46,082 iteration 353 : loss : 0.310087, loss_ce: 0.126521
2021-12-17 15:53:47,435 iteration 354 : loss : 0.320105, loss_ce: 0.148126
2021-12-17 15:53:48,829 iteration 355 : loss : 0.326462, loss_ce: 0.145149
2021-12-17 15:53:50,112 iteration 356 : loss : 0.324730, loss_ce: 0.149834
2021-12-17 15:53:51,416 iteration 357 : loss : 0.317111, loss_ce: 0.138051
  5%|█▌                            | 21/400 [09:10<2:52:20, 27.28s/it]2021-12-17 15:53:52,872 iteration 358 : loss : 0.336743, loss_ce: 0.140342
2021-12-17 15:53:54,264 iteration 359 : loss : 0.309247, loss_ce: 0.150586
2021-12-17 15:53:55,637 iteration 360 : loss : 0.317795, loss_ce: 0.107772
2021-12-17 15:53:57,066 iteration 361 : loss : 0.319981, loss_ce: 0.133146
2021-12-17 15:53:58,398 iteration 362 : loss : 0.311012, loss_ce: 0.130521
2021-12-17 15:53:59,862 iteration 363 : loss : 0.322116, loss_ce: 0.168419
2021-12-17 15:54:01,274 iteration 364 : loss : 0.321053, loss_ce: 0.158411
2021-12-17 15:54:02,657 iteration 365 : loss : 0.302598, loss_ce: 0.127842
2021-12-17 15:54:04,035 iteration 366 : loss : 0.323126, loss_ce: 0.151950
2021-12-17 15:54:05,462 iteration 367 : loss : 0.322300, loss_ce: 0.149767
2021-12-17 15:54:06,806 iteration 368 : loss : 0.316273, loss_ce: 0.129689
2021-12-17 15:54:08,223 iteration 369 : loss : 0.319823, loss_ce: 0.138968
2021-12-17 15:54:09,540 iteration 370 : loss : 0.306534, loss_ce: 0.110519
2021-12-17 15:54:10,986 iteration 371 : loss : 0.309700, loss_ce: 0.142485
2021-12-17 15:54:12,430 iteration 372 : loss : 0.324004, loss_ce: 0.135599
2021-12-17 15:54:13,834 iteration 373 : loss : 0.299529, loss_ce: 0.125441
2021-12-17 15:54:15,197 iteration 374 : loss : 0.309771, loss_ce: 0.141840
  6%|█▋                            | 22/400 [09:34<2:45:15, 26.23s/it]2021-12-17 15:54:16,661 iteration 375 : loss : 0.308523, loss_ce: 0.134178
2021-12-17 15:54:18,072 iteration 376 : loss : 0.317891, loss_ce: 0.141601
2021-12-17 15:54:19,490 iteration 377 : loss : 0.311424, loss_ce: 0.125630
2021-12-17 15:54:20,885 iteration 378 : loss : 0.298167, loss_ce: 0.122085
2021-12-17 15:54:22,210 iteration 379 : loss : 0.310147, loss_ce: 0.120378
2021-12-17 15:54:23,631 iteration 380 : loss : 0.326313, loss_ce: 0.153873
2021-12-17 15:54:24,924 iteration 381 : loss : 0.299058, loss_ce: 0.110588
2021-12-17 15:54:26,394 iteration 382 : loss : 0.307485, loss_ce: 0.135668
2021-12-17 15:54:27,814 iteration 383 : loss : 0.299955, loss_ce: 0.121790
2021-12-17 15:54:29,187 iteration 384 : loss : 0.303650, loss_ce: 0.133954
2021-12-17 15:54:30,537 iteration 385 : loss : 0.314824, loss_ce: 0.141916
2021-12-17 15:54:31,956 iteration 386 : loss : 0.306156, loss_ce: 0.126697
2021-12-17 15:54:33,366 iteration 387 : loss : 0.322071, loss_ce: 0.139975
2021-12-17 15:54:34,802 iteration 388 : loss : 0.317355, loss_ce: 0.153975
2021-12-17 15:54:36,151 iteration 389 : loss : 0.314590, loss_ce: 0.118589
2021-12-17 15:54:37,555 iteration 390 : loss : 0.301156, loss_ce: 0.137786
2021-12-17 15:54:38,900 iteration 391 : loss : 0.305702, loss_ce: 0.133568
  6%|█▋                            | 23/400 [09:58<2:40:03, 25.47s/it]2021-12-17 15:54:40,436 iteration 392 : loss : 0.303218, loss_ce: 0.131906
2021-12-17 15:54:41,774 iteration 393 : loss : 0.319012, loss_ce: 0.151501
2021-12-17 15:54:43,168 iteration 394 : loss : 0.302870, loss_ce: 0.120913
2021-12-17 15:54:44,522 iteration 395 : loss : 0.308096, loss_ce: 0.146643
2021-12-17 15:54:45,948 iteration 396 : loss : 0.297414, loss_ce: 0.132944
2021-12-17 15:54:47,379 iteration 397 : loss : 0.299541, loss_ce: 0.132993
2021-12-17 15:54:48,790 iteration 398 : loss : 0.320738, loss_ce: 0.148286
2021-12-17 15:54:50,166 iteration 399 : loss : 0.298051, loss_ce: 0.121221
2021-12-17 15:54:51,594 iteration 400 : loss : 0.305705, loss_ce: 0.141659
2021-12-17 15:54:52,911 iteration 401 : loss : 0.281513, loss_ce: 0.108994
2021-12-17 15:54:54,344 iteration 402 : loss : 0.303988, loss_ce: 0.136503
2021-12-17 15:54:55,799 iteration 403 : loss : 0.299027, loss_ce: 0.134010
2021-12-17 15:54:57,190 iteration 404 : loss : 0.282851, loss_ce: 0.100971
2021-12-17 15:54:58,617 iteration 405 : loss : 0.308184, loss_ce: 0.115433
2021-12-17 15:54:59,962 iteration 406 : loss : 0.317031, loss_ce: 0.150243
2021-12-17 15:55:01,311 iteration 407 : loss : 0.293840, loss_ce: 0.118038
2021-12-17 15:55:02,663 iteration 408 : loss : 0.299436, loss_ce: 0.119922
  6%|█▊                            | 24/400 [10:21<2:36:24, 24.96s/it]2021-12-17 15:55:04,209 iteration 409 : loss : 0.296729, loss_ce: 0.117701
2021-12-17 15:55:05,585 iteration 410 : loss : 0.291375, loss_ce: 0.108766
2021-12-17 15:55:06,995 iteration 411 : loss : 0.284966, loss_ce: 0.108651
2021-12-17 15:55:08,358 iteration 412 : loss : 0.296684, loss_ce: 0.124930
2021-12-17 15:55:09,716 iteration 413 : loss : 0.296461, loss_ce: 0.119539
2021-12-17 15:55:11,113 iteration 414 : loss : 0.304654, loss_ce: 0.133912
2021-12-17 15:55:12,544 iteration 415 : loss : 0.314602, loss_ce: 0.158920
2021-12-17 15:55:13,813 iteration 416 : loss : 0.313178, loss_ce: 0.117549
2021-12-17 15:55:15,202 iteration 417 : loss : 0.297441, loss_ce: 0.125129
2021-12-17 15:55:16,600 iteration 418 : loss : 0.283626, loss_ce: 0.111918
2021-12-17 15:55:17,944 iteration 419 : loss : 0.292277, loss_ce: 0.105326
2021-12-17 15:55:19,326 iteration 420 : loss : 0.296922, loss_ce: 0.124931
2021-12-17 15:55:20,633 iteration 421 : loss : 0.285841, loss_ce: 0.103034
2021-12-17 15:55:22,048 iteration 422 : loss : 0.286104, loss_ce: 0.112700
2021-12-17 15:55:23,411 iteration 423 : loss : 0.294578, loss_ce: 0.128022
2021-12-17 15:55:24,767 iteration 424 : loss : 0.287270, loss_ce: 0.138853
2021-12-17 15:55:24,768 Training Data Eval:
2021-12-17 15:55:31,933   Average segmentation loss on training set: 0.3194
2021-12-17 15:55:31,934 Validation Data Eval:
2021-12-17 15:55:34,431   Average segmentation loss on validation set: 0.3137
2021-12-17 15:55:40,701 Found new lowest validation loss at iteration 424! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/TU_3seeds/TU_RESNET_no_pretraining_SGD_best_val_loss_seed100.pth
2021-12-17 15:55:42,143 iteration 425 : loss : 0.304305, loss_ce: 0.135430
  6%|█▉                            | 25/400 [11:01<3:03:13, 29.32s/it]2021-12-17 15:55:43,562 iteration 426 : loss : 0.286760, loss_ce: 0.118265
2021-12-17 15:55:44,843 iteration 427 : loss : 0.281099, loss_ce: 0.121177
2021-12-17 15:55:46,260 iteration 428 : loss : 0.278526, loss_ce: 0.117652
2021-12-17 15:55:47,562 iteration 429 : loss : 0.273638, loss_ce: 0.103764
2021-12-17 15:55:48,816 iteration 430 : loss : 0.293439, loss_ce: 0.131775
2021-12-17 15:55:50,174 iteration 431 : loss : 0.288976, loss_ce: 0.137515
2021-12-17 15:55:51,515 iteration 432 : loss : 0.300897, loss_ce: 0.116098
2021-12-17 15:55:52,776 iteration 433 : loss : 0.292814, loss_ce: 0.129065
2021-12-17 15:55:54,052 iteration 434 : loss : 0.263286, loss_ce: 0.101786
2021-12-17 15:55:55,389 iteration 435 : loss : 0.300939, loss_ce: 0.133447
2021-12-17 15:55:56,744 iteration 436 : loss : 0.313958, loss_ce: 0.114151
2021-12-17 15:55:58,035 iteration 437 : loss : 0.281317, loss_ce: 0.130073
2021-12-17 15:55:59,321 iteration 438 : loss : 0.266265, loss_ce: 0.108070
2021-12-17 15:56:00,622 iteration 439 : loss : 0.274544, loss_ce: 0.113575
2021-12-17 15:56:02,070 iteration 440 : loss : 0.302771, loss_ce: 0.137463
2021-12-17 15:56:03,385 iteration 441 : loss : 0.306242, loss_ce: 0.138323
2021-12-17 15:56:04,721 iteration 442 : loss : 0.265158, loss_ce: 0.107204
  6%|█▉                            | 26/400 [11:23<2:50:08, 27.30s/it]2021-12-17 15:56:06,204 iteration 443 : loss : 0.251894, loss_ce: 0.102715
2021-12-17 15:56:07,564 iteration 444 : loss : 0.292895, loss_ce: 0.112690
2021-12-17 15:56:08,916 iteration 445 : loss : 0.281790, loss_ce: 0.116060
2021-12-17 15:56:10,307 iteration 446 : loss : 0.267089, loss_ce: 0.091352
2021-12-17 15:56:11,731 iteration 447 : loss : 0.292359, loss_ce: 0.114113
2021-12-17 15:56:13,025 iteration 448 : loss : 0.277868, loss_ce: 0.092614
2021-12-17 15:56:14,372 iteration 449 : loss : 0.254936, loss_ce: 0.084603
2021-12-17 15:56:15,685 iteration 450 : loss : 0.280629, loss_ce: 0.131842
2021-12-17 15:56:17,075 iteration 451 : loss : 0.277837, loss_ce: 0.111130
2021-12-17 15:56:18,472 iteration 452 : loss : 0.280541, loss_ce: 0.106556
2021-12-17 15:56:19,833 iteration 453 : loss : 0.281449, loss_ce: 0.118109
2021-12-17 15:56:21,296 iteration 454 : loss : 0.264596, loss_ce: 0.119063
2021-12-17 15:56:22,703 iteration 455 : loss : 0.286415, loss_ce: 0.127343
2021-12-17 15:56:24,069 iteration 456 : loss : 0.267277, loss_ce: 0.103092
2021-12-17 15:56:25,436 iteration 457 : loss : 0.286543, loss_ce: 0.139114
2021-12-17 15:56:26,806 iteration 458 : loss : 0.274596, loss_ce: 0.123004
2021-12-17 15:56:28,204 iteration 459 : loss : 0.267347, loss_ce: 0.116804
  7%|██                            | 27/400 [11:47<2:42:34, 26.15s/it]2021-12-17 15:56:29,589 iteration 460 : loss : 0.291738, loss_ce: 0.136923
2021-12-17 15:56:30,954 iteration 461 : loss : 0.258521, loss_ce: 0.111985
2021-12-17 15:56:32,401 iteration 462 : loss : 0.293950, loss_ce: 0.131379
2021-12-17 15:56:33,776 iteration 463 : loss : 0.273399, loss_ce: 0.104208
2021-12-17 15:56:35,274 iteration 464 : loss : 0.297466, loss_ce: 0.114548
2021-12-17 15:56:36,688 iteration 465 : loss : 0.269728, loss_ce: 0.120923
2021-12-17 15:56:38,032 iteration 466 : loss : 0.256898, loss_ce: 0.119047
2021-12-17 15:56:39,398 iteration 467 : loss : 0.283343, loss_ce: 0.117694
2021-12-17 15:56:40,748 iteration 468 : loss : 0.260206, loss_ce: 0.109510
2021-12-17 15:56:42,153 iteration 469 : loss : 0.274071, loss_ce: 0.119204
2021-12-17 15:56:43,523 iteration 470 : loss : 0.258275, loss_ce: 0.106120
2021-12-17 15:56:44,907 iteration 471 : loss : 0.287168, loss_ce: 0.127651
2021-12-17 15:56:46,323 iteration 472 : loss : 0.274942, loss_ce: 0.122256
2021-12-17 15:56:47,712 iteration 473 : loss : 0.275327, loss_ce: 0.116869
2021-12-17 15:56:49,056 iteration 474 : loss : 0.271559, loss_ce: 0.099238
2021-12-17 15:56:50,442 iteration 475 : loss : 0.262604, loss_ce: 0.095673
2021-12-17 15:56:51,895 iteration 476 : loss : 0.276439, loss_ce: 0.109060
  7%|██                            | 28/400 [12:11<2:37:33, 25.41s/it]2021-12-17 15:56:53,327 iteration 477 : loss : 0.256242, loss_ce: 0.111455
2021-12-17 15:56:54,647 iteration 478 : loss : 0.256472, loss_ce: 0.110905
2021-12-17 15:56:56,045 iteration 479 : loss : 0.254587, loss_ce: 0.099232
2021-12-17 15:56:57,419 iteration 480 : loss : 0.264805, loss_ce: 0.088485
2021-12-17 15:56:58,743 iteration 481 : loss : 0.278199, loss_ce: 0.093063
2021-12-17 15:57:00,183 iteration 482 : loss : 0.274584, loss_ce: 0.110362
2021-12-17 15:57:01,510 iteration 483 : loss : 0.241686, loss_ce: 0.102272
2021-12-17 15:57:02,917 iteration 484 : loss : 0.296499, loss_ce: 0.118112
2021-12-17 15:57:04,315 iteration 485 : loss : 0.280284, loss_ce: 0.125945
2021-12-17 15:57:05,783 iteration 486 : loss : 0.289563, loss_ce: 0.121008
2021-12-17 15:57:07,153 iteration 487 : loss : 0.263689, loss_ce: 0.094157
2021-12-17 15:57:08,456 iteration 488 : loss : 0.276554, loss_ce: 0.128696
2021-12-17 15:57:09,866 iteration 489 : loss : 0.272529, loss_ce: 0.123154
2021-12-17 15:57:11,241 iteration 490 : loss : 0.274333, loss_ce: 0.118211
2021-12-17 15:57:12,675 iteration 491 : loss : 0.260387, loss_ce: 0.081212
2021-12-17 15:57:14,020 iteration 492 : loss : 0.275617, loss_ce: 0.131815
2021-12-17 15:57:15,368 iteration 493 : loss : 0.280640, loss_ce: 0.128227
  7%|██▏                           | 29/400 [12:34<2:33:33, 24.83s/it]2021-12-17 15:57:16,796 iteration 494 : loss : 0.258402, loss_ce: 0.092063
2021-12-17 15:57:18,114 iteration 495 : loss : 0.273351, loss_ce: 0.109766
2021-12-17 15:57:19,507 iteration 496 : loss : 0.257737, loss_ce: 0.086906
2021-12-17 15:57:20,958 iteration 497 : loss : 0.269808, loss_ce: 0.115304
2021-12-17 15:57:22,417 iteration 498 : loss : 0.254822, loss_ce: 0.126060
2021-12-17 15:57:23,814 iteration 499 : loss : 0.258244, loss_ce: 0.091970
2021-12-17 15:57:25,300 iteration 500 : loss : 0.275022, loss_ce: 0.116237
2021-12-17 15:57:26,679 iteration 501 : loss : 0.252059, loss_ce: 0.090479
2021-12-17 15:57:28,001 iteration 502 : loss : 0.279081, loss_ce: 0.133119
2021-12-17 15:57:29,465 iteration 503 : loss : 0.263640, loss_ce: 0.091550
2021-12-17 15:57:30,947 iteration 504 : loss : 0.250008, loss_ce: 0.100018
2021-12-17 15:57:32,298 iteration 505 : loss : 0.270474, loss_ce: 0.118743
2021-12-17 15:57:33,699 iteration 506 : loss : 0.259168, loss_ce: 0.106692
2021-12-17 15:57:35,129 iteration 507 : loss : 0.261375, loss_ce: 0.109702
2021-12-17 15:57:36,505 iteration 508 : loss : 0.249380, loss_ce: 0.107449
2021-12-17 15:57:37,902 iteration 509 : loss : 0.260577, loss_ce: 0.125942
2021-12-17 15:57:37,903 Training Data Eval:
2021-12-17 15:57:45,067   Average segmentation loss on training set: 0.2459
2021-12-17 15:57:45,067 Validation Data Eval:
2021-12-17 15:57:47,559   Average segmentation loss on validation set: 0.2591
2021-12-17 15:57:53,827 Found new lowest validation loss at iteration 509! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/TU_3seeds/TU_RESNET_no_pretraining_SGD_best_val_loss_seed100.pth
2021-12-17 15:57:55,110 iteration 510 : loss : 0.258063, loss_ce: 0.109598
  8%|██▎                           | 30/400 [13:14<3:00:41, 29.30s/it]2021-12-17 15:57:56,348 iteration 511 : loss : 0.255001, loss_ce: 0.108437
2021-12-17 15:57:57,802 iteration 512 : loss : 0.254674, loss_ce: 0.108689
2021-12-17 15:57:59,065 iteration 513 : loss : 0.263547, loss_ce: 0.120527
2021-12-17 15:58:00,413 iteration 514 : loss : 0.249245, loss_ce: 0.085695
2021-12-17 15:58:01,703 iteration 515 : loss : 0.236317, loss_ce: 0.092806
2021-12-17 15:58:02,941 iteration 516 : loss : 0.259730, loss_ce: 0.116377
2021-12-17 15:58:04,396 iteration 517 : loss : 0.271388, loss_ce: 0.101637
2021-12-17 15:58:05,746 iteration 518 : loss : 0.262717, loss_ce: 0.128740
2021-12-17 15:58:07,032 iteration 519 : loss : 0.248112, loss_ce: 0.092128
2021-12-17 15:58:08,313 iteration 520 : loss : 0.251475, loss_ce: 0.116241
2021-12-17 15:58:09,721 iteration 521 : loss : 0.289598, loss_ce: 0.098188
2021-12-17 15:58:11,009 iteration 522 : loss : 0.225485, loss_ce: 0.093557
2021-12-17 15:58:12,360 iteration 523 : loss : 0.235654, loss_ce: 0.103975
2021-12-17 15:58:13,573 iteration 524 : loss : 0.254857, loss_ce: 0.108048
2021-12-17 15:58:14,880 iteration 525 : loss : 0.229087, loss_ce: 0.091456
2021-12-17 15:58:16,236 iteration 526 : loss : 0.251306, loss_ce: 0.108248
2021-12-17 15:58:17,589 iteration 527 : loss : 0.246832, loss_ce: 0.097213
  8%|██▎                           | 31/400 [13:36<2:47:38, 27.26s/it]2021-12-17 15:58:19,072 iteration 528 : loss : 0.231753, loss_ce: 0.086433
2021-12-17 15:58:20,467 iteration 529 : loss : 0.240687, loss_ce: 0.101302
2021-12-17 15:58:21,833 iteration 530 : loss : 0.227682, loss_ce: 0.085411
2021-12-17 15:58:23,274 iteration 531 : loss : 0.282131, loss_ce: 0.107490
2021-12-17 15:58:24,606 iteration 532 : loss : 0.268736, loss_ce: 0.085067
2021-12-17 15:58:26,010 iteration 533 : loss : 0.235353, loss_ce: 0.101720
2021-12-17 15:58:27,383 iteration 534 : loss : 0.237236, loss_ce: 0.103475
2021-12-17 15:58:28,767 iteration 535 : loss : 0.224659, loss_ce: 0.089561
2021-12-17 15:58:30,088 iteration 536 : loss : 0.225518, loss_ce: 0.095665
2021-12-17 15:58:31,466 iteration 537 : loss : 0.243422, loss_ce: 0.092558
2021-12-17 15:58:32,832 iteration 538 : loss : 0.228698, loss_ce: 0.089529
2021-12-17 15:58:34,173 iteration 539 : loss : 0.233478, loss_ce: 0.085206
2021-12-17 15:58:35,507 iteration 540 : loss : 0.229168, loss_ce: 0.095301
2021-12-17 15:58:36,879 iteration 541 : loss : 0.243969, loss_ce: 0.118993
2021-12-17 15:58:38,195 iteration 542 : loss : 0.225456, loss_ce: 0.086735
2021-12-17 15:58:39,537 iteration 543 : loss : 0.288058, loss_ce: 0.094306
2021-12-17 15:58:40,911 iteration 544 : loss : 0.252982, loss_ce: 0.103604
  8%|██▍                           | 32/400 [14:00<2:39:56, 26.08s/it]2021-12-17 15:58:42,335 iteration 545 : loss : 0.235393, loss_ce: 0.096711
2021-12-17 15:58:43,716 iteration 546 : loss : 0.238458, loss_ce: 0.099428
2021-12-17 15:58:45,091 iteration 547 : loss : 0.234049, loss_ce: 0.091215
2021-12-17 15:58:46,410 iteration 548 : loss : 0.246467, loss_ce: 0.095924
2021-12-17 15:58:47,812 iteration 549 : loss : 0.239924, loss_ce: 0.103282
2021-12-17 15:58:49,272 iteration 550 : loss : 0.208999, loss_ce: 0.073806
2021-12-17 15:58:50,678 iteration 551 : loss : 0.227569, loss_ce: 0.077323
2021-12-17 15:58:52,089 iteration 552 : loss : 0.240923, loss_ce: 0.105069
2021-12-17 15:58:53,505 iteration 553 : loss : 0.244359, loss_ce: 0.117493
2021-12-17 15:58:54,811 iteration 554 : loss : 0.209976, loss_ce: 0.080995
2021-12-17 15:58:56,212 iteration 555 : loss : 0.238927, loss_ce: 0.105998
2021-12-17 15:58:57,673 iteration 556 : loss : 0.223397, loss_ce: 0.082927
2021-12-17 15:58:59,047 iteration 557 : loss : 0.241562, loss_ce: 0.109418
2021-12-17 15:59:00,381 iteration 558 : loss : 0.227513, loss_ce: 0.081540
2021-12-17 15:59:01,771 iteration 559 : loss : 0.225093, loss_ce: 0.097234
2021-12-17 15:59:03,186 iteration 560 : loss : 0.231564, loss_ce: 0.084951
2021-12-17 15:59:04,515 iteration 561 : loss : 0.235573, loss_ce: 0.069111
  8%|██▍                           | 33/400 [14:23<2:34:58, 25.34s/it]2021-12-17 15:59:05,919 iteration 562 : loss : 0.213191, loss_ce: 0.080858
2021-12-17 15:59:07,304 iteration 563 : loss : 0.220294, loss_ce: 0.090301
2021-12-17 15:59:08,727 iteration 564 : loss : 0.215013, loss_ce: 0.087713
2021-12-17 15:59:10,122 iteration 565 : loss : 0.229715, loss_ce: 0.103728
2021-12-17 15:59:11,415 iteration 566 : loss : 0.221008, loss_ce: 0.080063
2021-12-17 15:59:12,825 iteration 567 : loss : 0.253183, loss_ce: 0.072983
2021-12-17 15:59:14,176 iteration 568 : loss : 0.219353, loss_ce: 0.084413
2021-12-17 15:59:15,550 iteration 569 : loss : 0.238253, loss_ce: 0.087682
2021-12-17 15:59:17,003 iteration 570 : loss : 0.215664, loss_ce: 0.084165
2021-12-17 15:59:18,419 iteration 571 : loss : 0.230097, loss_ce: 0.084420
2021-12-17 15:59:19,807 iteration 572 : loss : 0.203965, loss_ce: 0.074242
2021-12-17 15:59:21,154 iteration 573 : loss : 0.230739, loss_ce: 0.092820
2021-12-17 15:59:22,506 iteration 574 : loss : 0.234021, loss_ce: 0.092389
2021-12-17 15:59:23,916 iteration 575 : loss : 0.217725, loss_ce: 0.085252
2021-12-17 15:59:25,303 iteration 576 : loss : 0.237630, loss_ce: 0.100903
2021-12-17 15:59:26,721 iteration 577 : loss : 0.282345, loss_ce: 0.102611
2021-12-17 15:59:28,120 iteration 578 : loss : 0.246502, loss_ce: 0.090291
  8%|██▌                           | 34/400 [14:47<2:31:21, 24.81s/it]2021-12-17 15:59:29,538 iteration 579 : loss : 0.199136, loss_ce: 0.064099
2021-12-17 15:59:30,895 iteration 580 : loss : 0.199431, loss_ce: 0.081780
2021-12-17 15:59:32,270 iteration 581 : loss : 0.214578, loss_ce: 0.089835
2021-12-17 15:59:33,664 iteration 582 : loss : 0.199880, loss_ce: 0.076274
2021-12-17 15:59:35,007 iteration 583 : loss : 0.224333, loss_ce: 0.090808
2021-12-17 15:59:36,286 iteration 584 : loss : 0.198838, loss_ce: 0.075539
2021-12-17 15:59:37,615 iteration 585 : loss : 0.225215, loss_ce: 0.082283
2021-12-17 15:59:39,023 iteration 586 : loss : 0.230919, loss_ce: 0.100899
2021-12-17 15:59:40,403 iteration 587 : loss : 0.206497, loss_ce: 0.076764
2021-12-17 15:59:41,821 iteration 588 : loss : 0.215583, loss_ce: 0.077873
2021-12-17 15:59:43,189 iteration 589 : loss : 0.206433, loss_ce: 0.082377
2021-12-17 15:59:44,537 iteration 590 : loss : 0.234188, loss_ce: 0.112579
2021-12-17 15:59:45,913 iteration 591 : loss : 0.211861, loss_ce: 0.081238
2021-12-17 15:59:47,265 iteration 592 : loss : 0.232066, loss_ce: 0.100572
2021-12-17 15:59:48,668 iteration 593 : loss : 0.225815, loss_ce: 0.089544
2021-12-17 15:59:50,090 iteration 594 : loss : 0.231194, loss_ce: 0.103707
2021-12-17 15:59:50,090 Training Data Eval:
2021-12-17 15:59:57,222   Average segmentation loss on training set: 0.2062
2021-12-17 15:59:57,222 Validation Data Eval:
2021-12-17 15:59:59,708   Average segmentation loss on validation set: 0.2249
2021-12-17 16:00:07,338 Found new lowest validation loss at iteration 594! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/TU_3seeds/TU_RESNET_no_pretraining_SGD_best_val_loss_seed100.pth
2021-12-17 16:00:08,745 iteration 595 : loss : 0.231607, loss_ce: 0.085112
  9%|██▋                           | 35/400 [15:27<2:59:49, 29.56s/it]2021-12-17 16:00:10,069 iteration 596 : loss : 0.213425, loss_ce: 0.087249
2021-12-17 16:00:11,387 iteration 597 : loss : 0.206630, loss_ce: 0.089556
2021-12-17 16:00:12,722 iteration 598 : loss : 0.234325, loss_ce: 0.092553
2021-12-17 16:00:14,090 iteration 599 : loss : 0.226740, loss_ce: 0.091684
2021-12-17 16:00:15,329 iteration 600 : loss : 0.202592, loss_ce: 0.083393
2021-12-17 16:00:16,638 iteration 601 : loss : 0.207243, loss_ce: 0.073250
2021-12-17 16:00:17,998 iteration 602 : loss : 0.182972, loss_ce: 0.066002
2021-12-17 16:00:19,227 iteration 603 : loss : 0.227392, loss_ce: 0.094549
2021-12-17 16:00:20,524 iteration 604 : loss : 0.210761, loss_ce: 0.074386
2021-12-17 16:00:21,840 iteration 605 : loss : 0.207507, loss_ce: 0.080776
2021-12-17 16:00:23,120 iteration 606 : loss : 0.225550, loss_ce: 0.090584
2021-12-17 16:00:24,424 iteration 607 : loss : 0.228116, loss_ce: 0.081936
2021-12-17 16:00:25,840 iteration 608 : loss : 0.226608, loss_ce: 0.082766
2021-12-17 16:00:27,139 iteration 609 : loss : 0.214283, loss_ce: 0.083661
2021-12-17 16:00:28,506 iteration 610 : loss : 0.200768, loss_ce: 0.072191
2021-12-17 16:00:29,818 iteration 611 : loss : 0.202524, loss_ce: 0.069924
2021-12-17 16:00:31,134 iteration 612 : loss : 0.198268, loss_ce: 0.075494
  9%|██▋                           | 36/400 [15:50<2:46:15, 27.41s/it]2021-12-17 16:00:32,545 iteration 613 : loss : 0.214984, loss_ce: 0.086291
2021-12-17 16:00:34,013 iteration 614 : loss : 0.214270, loss_ce: 0.091408
2021-12-17 16:00:35,415 iteration 615 : loss : 0.206320, loss_ce: 0.074283
2021-12-17 16:00:36,780 iteration 616 : loss : 0.233499, loss_ce: 0.117978
2021-12-17 16:00:38,188 iteration 617 : loss : 0.218849, loss_ce: 0.095544
2021-12-17 16:00:39,521 iteration 618 : loss : 0.215035, loss_ce: 0.077372
2021-12-17 16:00:40,893 iteration 619 : loss : 0.227077, loss_ce: 0.084857
2021-12-17 16:00:42,362 iteration 620 : loss : 0.215102, loss_ce: 0.072545
2021-12-17 16:00:43,731 iteration 621 : loss : 0.212658, loss_ce: 0.081060
2021-12-17 16:00:45,134 iteration 622 : loss : 0.196378, loss_ce: 0.077123
2021-12-17 16:00:46,576 iteration 623 : loss : 0.217594, loss_ce: 0.078113
2021-12-17 16:00:47,937 iteration 624 : loss : 0.228480, loss_ce: 0.079406
2021-12-17 16:00:49,272 iteration 625 : loss : 0.212404, loss_ce: 0.076919
2021-12-17 16:00:50,604 iteration 626 : loss : 0.213914, loss_ce: 0.075369
2021-12-17 16:00:51,966 iteration 627 : loss : 0.214063, loss_ce: 0.072996
2021-12-17 16:00:53,344 iteration 628 : loss : 0.208956, loss_ce: 0.101776
2021-12-17 16:00:54,759 iteration 629 : loss : 0.195710, loss_ce: 0.068339
  9%|██▊                           | 37/400 [16:13<2:38:56, 26.27s/it]2021-12-17 16:00:56,176 iteration 630 : loss : 0.195166, loss_ce: 0.074483
2021-12-17 16:00:57,592 iteration 631 : loss : 0.207643, loss_ce: 0.090174
2021-12-17 16:00:58,984 iteration 632 : loss : 0.185723, loss_ce: 0.064016
2021-12-17 16:01:00,397 iteration 633 : loss : 0.187650, loss_ce: 0.071391
2021-12-17 16:01:01,823 iteration 634 : loss : 0.202409, loss_ce: 0.088956
2021-12-17 16:01:03,199 iteration 635 : loss : 0.233975, loss_ce: 0.088439
2021-12-17 16:01:04,656 iteration 636 : loss : 0.217411, loss_ce: 0.094591
2021-12-17 16:01:05,999 iteration 637 : loss : 0.220103, loss_ce: 0.074286
2021-12-17 16:01:07,335 iteration 638 : loss : 0.222722, loss_ce: 0.082714
2021-12-17 16:01:08,749 iteration 639 : loss : 0.195385, loss_ce: 0.071777
2021-12-17 16:01:10,132 iteration 640 : loss : 0.197896, loss_ce: 0.080194
2021-12-17 16:01:11,542 iteration 641 : loss : 0.199688, loss_ce: 0.071987
2021-12-17 16:01:12,941 iteration 642 : loss : 0.194768, loss_ce: 0.067774
2021-12-17 16:01:14,323 iteration 643 : loss : 0.232928, loss_ce: 0.090991
2021-12-17 16:01:15,734 iteration 644 : loss : 0.203029, loss_ce: 0.072060
2021-12-17 16:01:17,132 iteration 645 : loss : 0.235716, loss_ce: 0.087471
2021-12-17 16:01:18,521 iteration 646 : loss : 0.207483, loss_ce: 0.078934
 10%|██▊                           | 38/400 [16:37<2:33:58, 25.52s/it]2021-12-17 16:01:19,944 iteration 647 : loss : 0.202308, loss_ce: 0.062717
2021-12-17 16:01:21,273 iteration 648 : loss : 0.204301, loss_ce: 0.090761
2021-12-17 16:01:22,614 iteration 649 : loss : 0.193090, loss_ce: 0.078768
2021-12-17 16:01:24,041 iteration 650 : loss : 0.247915, loss_ce: 0.070593
2021-12-17 16:01:25,452 iteration 651 : loss : 0.185549, loss_ce: 0.069354
2021-12-17 16:01:26,778 iteration 652 : loss : 0.179483, loss_ce: 0.073797
2021-12-17 16:01:28,138 iteration 653 : loss : 0.191450, loss_ce: 0.074935
2021-12-17 16:01:29,530 iteration 654 : loss : 0.190348, loss_ce: 0.064921
2021-12-17 16:01:30,853 iteration 655 : loss : 0.190838, loss_ce: 0.070679
2021-12-17 16:01:32,278 iteration 656 : loss : 0.188407, loss_ce: 0.070526
2021-12-17 16:01:33,635 iteration 657 : loss : 0.201665, loss_ce: 0.070847
2021-12-17 16:01:34,998 iteration 658 : loss : 0.194634, loss_ce: 0.071005
2021-12-17 16:01:36,403 iteration 659 : loss : 0.205548, loss_ce: 0.064716
2021-12-17 16:01:37,801 iteration 660 : loss : 0.211184, loss_ce: 0.087109
2021-12-17 16:01:39,199 iteration 661 : loss : 0.201567, loss_ce: 0.087338
2021-12-17 16:01:40,605 iteration 662 : loss : 0.218758, loss_ce: 0.084101
2021-12-17 16:01:41,980 iteration 663 : loss : 0.191408, loss_ce: 0.070660
 10%|██▉                           | 39/400 [17:01<2:29:49, 24.90s/it]2021-12-17 16:01:43,367 iteration 664 : loss : 0.207015, loss_ce: 0.080013
2021-12-17 16:01:44,781 iteration 665 : loss : 0.226083, loss_ce: 0.079490
2021-12-17 16:01:46,183 iteration 666 : loss : 0.189042, loss_ce: 0.064997
2021-12-17 16:01:47,611 iteration 667 : loss : 0.190273, loss_ce: 0.071399
2021-12-17 16:01:48,970 iteration 668 : loss : 0.190268, loss_ce: 0.069568
2021-12-17 16:01:50,399 iteration 669 : loss : 0.228130, loss_ce: 0.095664
2021-12-17 16:01:51,813 iteration 670 : loss : 0.197341, loss_ce: 0.074625
2021-12-17 16:01:53,200 iteration 671 : loss : 0.207580, loss_ce: 0.080643
2021-12-17 16:01:54,509 iteration 672 : loss : 0.175701, loss_ce: 0.064832
2021-12-17 16:01:55,876 iteration 673 : loss : 0.193217, loss_ce: 0.060527
2021-12-17 16:01:57,386 iteration 674 : loss : 0.216129, loss_ce: 0.090928
2021-12-17 16:01:58,769 iteration 675 : loss : 0.203554, loss_ce: 0.064324
2021-12-17 16:02:00,130 iteration 676 : loss : 0.177153, loss_ce: 0.062766
2021-12-17 16:02:01,607 iteration 677 : loss : 0.182352, loss_ce: 0.069754
2021-12-17 16:02:03,007 iteration 678 : loss : 0.190975, loss_ce: 0.054924
2021-12-17 16:02:04,350 iteration 679 : loss : 0.180112, loss_ce: 0.069252
2021-12-17 16:02:04,350 Training Data Eval:
2021-12-17 16:02:11,526   Average segmentation loss on training set: 0.1825
2021-12-17 16:02:11,527 Validation Data Eval:
2021-12-17 16:02:14,013   Average segmentation loss on validation set: 0.2064
2021-12-17 16:02:20,417 Found new lowest validation loss at iteration 679! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/TU_3seeds/TU_RESNET_no_pretraining_SGD_best_val_loss_seed100.pth
2021-12-17 16:02:21,767 iteration 680 : loss : 0.194474, loss_ce: 0.073086
 10%|███                           | 40/400 [17:40<2:56:12, 29.37s/it]2021-12-17 16:02:23,259 iteration 681 : loss : 0.194847, loss_ce: 0.074697
2021-12-17 16:02:24,576 iteration 682 : loss : 0.181237, loss_ce: 0.063553
2021-12-17 16:02:25,855 iteration 683 : loss : 0.198610, loss_ce: 0.064075
2021-12-17 16:02:27,233 iteration 684 : loss : 0.191643, loss_ce: 0.074344
2021-12-17 16:02:28,626 iteration 685 : loss : 0.189191, loss_ce: 0.070930
2021-12-17 16:02:29,989 iteration 686 : loss : 0.205216, loss_ce: 0.079844
2021-12-17 16:02:31,350 iteration 687 : loss : 0.165101, loss_ce: 0.060898
2021-12-17 16:02:32,743 iteration 688 : loss : 0.197731, loss_ce: 0.076455
2021-12-17 16:02:34,104 iteration 689 : loss : 0.170268, loss_ce: 0.065766
2021-12-17 16:02:35,428 iteration 690 : loss : 0.181668, loss_ce: 0.069251
2021-12-17 16:02:36,800 iteration 691 : loss : 0.198931, loss_ce: 0.063088
2021-12-17 16:02:38,073 iteration 692 : loss : 0.179038, loss_ce: 0.068781
2021-12-17 16:02:39,376 iteration 693 : loss : 0.203618, loss_ce: 0.078032
2021-12-17 16:02:40,701 iteration 694 : loss : 0.207300, loss_ce: 0.067199
2021-12-17 16:02:42,022 iteration 695 : loss : 0.189292, loss_ce: 0.063098
2021-12-17 16:02:43,312 iteration 696 : loss : 0.219862, loss_ce: 0.067901
2021-12-17 16:02:44,562 iteration 697 : loss : 0.170218, loss_ce: 0.064746
 10%|███                           | 41/400 [18:03<2:43:55, 27.40s/it]2021-12-17 16:02:46,019 iteration 698 : loss : 0.183503, loss_ce: 0.075288
2021-12-17 16:02:47,448 iteration 699 : loss : 0.214729, loss_ce: 0.082514
2021-12-17 16:02:48,820 iteration 700 : loss : 0.207786, loss_ce: 0.077027
2021-12-17 16:02:50,191 iteration 701 : loss : 0.204782, loss_ce: 0.073966
2021-12-17 16:02:51,622 iteration 702 : loss : 0.179799, loss_ce: 0.070680
2021-12-17 16:02:53,025 iteration 703 : loss : 0.176726, loss_ce: 0.055484
2021-12-17 16:02:54,488 iteration 704 : loss : 0.219763, loss_ce: 0.073188
2021-12-17 16:02:55,920 iteration 705 : loss : 0.181213, loss_ce: 0.073379
2021-12-17 16:02:57,354 iteration 706 : loss : 0.183963, loss_ce: 0.053184
2021-12-17 16:02:58,719 iteration 707 : loss : 0.185476, loss_ce: 0.072529
2021-12-17 16:03:00,132 iteration 708 : loss : 0.187641, loss_ce: 0.068726
2021-12-17 16:03:01,538 iteration 709 : loss : 0.190109, loss_ce: 0.061496
2021-12-17 16:03:02,877 iteration 710 : loss : 0.172698, loss_ce: 0.066329
2021-12-17 16:03:04,298 iteration 711 : loss : 0.191481, loss_ce: 0.071666
2021-12-17 16:03:05,657 iteration 712 : loss : 0.209454, loss_ce: 0.062943
2021-12-17 16:03:06,971 iteration 713 : loss : 0.173859, loss_ce: 0.064023
2021-12-17 16:03:08,313 iteration 714 : loss : 0.169624, loss_ce: 0.053698
 10%|███▏                          | 42/400 [18:27<2:36:55, 26.30s/it]2021-12-17 16:03:09,814 iteration 715 : loss : 0.191942, loss_ce: 0.079179
2021-12-17 16:03:11,183 iteration 716 : loss : 0.197057, loss_ce: 0.076208
2021-12-17 16:03:12,532 iteration 717 : loss : 0.192506, loss_ce: 0.067338
2021-12-17 16:03:13,892 iteration 718 : loss : 0.175632, loss_ce: 0.062046
2021-12-17 16:03:15,333 iteration 719 : loss : 0.188068, loss_ce: 0.068450
2021-12-17 16:03:16,685 iteration 720 : loss : 0.201534, loss_ce: 0.066237
2021-12-17 16:03:18,118 iteration 721 : loss : 0.187383, loss_ce: 0.061287
2021-12-17 16:03:19,515 iteration 722 : loss : 0.157584, loss_ce: 0.055526
2021-12-17 16:03:20,863 iteration 723 : loss : 0.173799, loss_ce: 0.057034
2021-12-17 16:03:22,337 iteration 724 : loss : 0.197432, loss_ce: 0.081529
2021-12-17 16:03:23,663 iteration 725 : loss : 0.153475, loss_ce: 0.053582
2021-12-17 16:03:25,060 iteration 726 : loss : 0.198207, loss_ce: 0.058118
2021-12-17 16:03:26,484 iteration 727 : loss : 0.212718, loss_ce: 0.067591
2021-12-17 16:03:27,998 iteration 728 : loss : 0.208232, loss_ce: 0.086439
2021-12-17 16:03:29,275 iteration 729 : loss : 0.163876, loss_ce: 0.060729
2021-12-17 16:03:30,664 iteration 730 : loss : 0.194470, loss_ce: 0.074357
2021-12-17 16:03:32,064 iteration 731 : loss : 0.189428, loss_ce: 0.071102
 11%|███▏                          | 43/400 [18:51<2:31:55, 25.53s/it]2021-12-17 16:03:33,584 iteration 732 : loss : 0.182335, loss_ce: 0.072191
2021-12-17 16:03:34,970 iteration 733 : loss : 0.201578, loss_ce: 0.079890
2021-12-17 16:03:36,298 iteration 734 : loss : 0.172782, loss_ce: 0.057767
2021-12-17 16:03:37,663 iteration 735 : loss : 0.196453, loss_ce: 0.072486
2021-12-17 16:03:39,051 iteration 736 : loss : 0.219662, loss_ce: 0.081329
2021-12-17 16:03:40,481 iteration 737 : loss : 0.161289, loss_ce: 0.052217
2021-12-17 16:03:41,866 iteration 738 : loss : 0.180241, loss_ce: 0.067705
2021-12-17 16:03:43,233 iteration 739 : loss : 0.213513, loss_ce: 0.082941
2021-12-17 16:03:44,607 iteration 740 : loss : 0.183647, loss_ce: 0.076743
2021-12-17 16:03:46,001 iteration 741 : loss : 0.182479, loss_ce: 0.067455
2021-12-17 16:03:47,437 iteration 742 : loss : 0.185494, loss_ce: 0.055162
2021-12-17 16:03:48,794 iteration 743 : loss : 0.181753, loss_ce: 0.060386
2021-12-17 16:03:50,154 iteration 744 : loss : 0.183824, loss_ce: 0.062171
2021-12-17 16:03:51,499 iteration 745 : loss : 0.153447, loss_ce: 0.054651
2021-12-17 16:03:52,874 iteration 746 : loss : 0.197292, loss_ce: 0.081673
2021-12-17 16:03:54,282 iteration 747 : loss : 0.193160, loss_ce: 0.062468
2021-12-17 16:03:55,582 iteration 748 : loss : 0.174486, loss_ce: 0.063668
 11%|███▎                          | 44/400 [19:14<2:27:56, 24.93s/it]2021-12-17 16:03:57,016 iteration 749 : loss : 0.166977, loss_ce: 0.057446
2021-12-17 16:03:58,418 iteration 750 : loss : 0.177854, loss_ce: 0.066752
2021-12-17 16:03:59,727 iteration 751 : loss : 0.162956, loss_ce: 0.055722
2021-12-17 16:04:01,136 iteration 752 : loss : 0.185905, loss_ce: 0.061418
2021-12-17 16:04:02,584 iteration 753 : loss : 0.172128, loss_ce: 0.064343
2021-12-17 16:04:03,942 iteration 754 : loss : 0.190183, loss_ce: 0.063817
2021-12-17 16:04:05,324 iteration 755 : loss : 0.167038, loss_ce: 0.058159
2021-12-17 16:04:06,655 iteration 756 : loss : 0.181537, loss_ce: 0.069977
2021-12-17 16:04:08,003 iteration 757 : loss : 0.168735, loss_ce: 0.061379
2021-12-17 16:04:09,383 iteration 758 : loss : 0.175720, loss_ce: 0.064498
2021-12-17 16:04:10,683 iteration 759 : loss : 0.161736, loss_ce: 0.054271
2021-12-17 16:04:12,079 iteration 760 : loss : 0.220192, loss_ce: 0.065629
2021-12-17 16:04:13,485 iteration 761 : loss : 0.176178, loss_ce: 0.054966
2021-12-17 16:04:14,892 iteration 762 : loss : 0.166176, loss_ce: 0.065166
2021-12-17 16:04:16,262 iteration 763 : loss : 0.200094, loss_ce: 0.077452
2021-12-17 16:04:17,590 iteration 764 : loss : 0.166332, loss_ce: 0.056703
2021-12-17 16:04:17,590 Training Data Eval:
2021-12-17 16:04:24,763   Average segmentation loss on training set: 0.1680
2021-12-17 16:04:24,764 Validation Data Eval:
2021-12-17 16:04:27,256   Average segmentation loss on validation set: 0.1905
2021-12-17 16:04:33,527 Found new lowest validation loss at iteration 764! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/TU_3seeds/TU_RESNET_no_pretraining_SGD_best_val_loss_seed100.pth
2021-12-17 16:04:34,929 iteration 765 : loss : 0.179896, loss_ce: 0.068644
 11%|███▍                          | 45/400 [19:54<2:53:06, 29.26s/it]2021-12-17 16:04:36,325 iteration 766 : loss : 0.200955, loss_ce: 0.068580
2021-12-17 16:04:37,682 iteration 767 : loss : 0.184376, loss_ce: 0.056759
2021-12-17 16:04:38,906 iteration 768 : loss : 0.191643, loss_ce: 0.067711
2021-12-17 16:04:40,214 iteration 769 : loss : 0.233172, loss_ce: 0.071105
2021-12-17 16:04:41,473 iteration 770 : loss : 0.165832, loss_ce: 0.057521
2021-12-17 16:04:42,850 iteration 771 : loss : 0.171930, loss_ce: 0.050046
2021-12-17 16:04:44,221 iteration 772 : loss : 0.147844, loss_ce: 0.053644
2021-12-17 16:04:45,551 iteration 773 : loss : 0.167224, loss_ce: 0.054080
2021-12-17 16:04:46,867 iteration 774 : loss : 0.169573, loss_ce: 0.066539
2021-12-17 16:04:48,171 iteration 775 : loss : 0.154248, loss_ce: 0.050410
2021-12-17 16:04:49,403 iteration 776 : loss : 0.178154, loss_ce: 0.068723
2021-12-17 16:04:50,768 iteration 777 : loss : 0.173405, loss_ce: 0.063829
2021-12-17 16:04:52,094 iteration 778 : loss : 0.155896, loss_ce: 0.054540
2021-12-17 16:04:53,417 iteration 779 : loss : 0.171210, loss_ce: 0.070925
2021-12-17 16:04:54,681 iteration 780 : loss : 0.180453, loss_ce: 0.062865
2021-12-17 16:04:56,042 iteration 781 : loss : 0.183924, loss_ce: 0.070833
2021-12-17 16:04:57,427 iteration 782 : loss : 0.187327, loss_ce: 0.062174
 12%|███▍                          | 46/400 [20:16<2:40:37, 27.22s/it]2021-12-17 16:04:58,903 iteration 783 : loss : 0.182607, loss_ce: 0.073322
2021-12-17 16:05:00,292 iteration 784 : loss : 0.186523, loss_ce: 0.060836
2021-12-17 16:05:01,707 iteration 785 : loss : 0.179553, loss_ce: 0.067890
2021-12-17 16:05:03,078 iteration 786 : loss : 0.173618, loss_ce: 0.050161
2021-12-17 16:05:04,470 iteration 787 : loss : 0.181535, loss_ce: 0.070646
2021-12-17 16:05:05,895 iteration 788 : loss : 0.152804, loss_ce: 0.042911
2021-12-17 16:05:07,395 iteration 789 : loss : 0.228930, loss_ce: 0.119541
2021-12-17 16:05:08,816 iteration 790 : loss : 0.165253, loss_ce: 0.051952
2021-12-17 16:05:10,181 iteration 791 : loss : 0.173164, loss_ce: 0.056122
2021-12-17 16:05:11,587 iteration 792 : loss : 0.185938, loss_ce: 0.074229
2021-12-17 16:05:12,879 iteration 793 : loss : 0.183870, loss_ce: 0.060315
2021-12-17 16:05:14,248 iteration 794 : loss : 0.167208, loss_ce: 0.058048
2021-12-17 16:05:15,629 iteration 795 : loss : 0.159098, loss_ce: 0.059098
2021-12-17 16:05:17,005 iteration 796 : loss : 0.155573, loss_ce: 0.048255
2021-12-17 16:05:18,349 iteration 797 : loss : 0.150125, loss_ce: 0.053288
2021-12-17 16:05:19,702 iteration 798 : loss : 0.211821, loss_ce: 0.072224
2021-12-17 16:05:21,115 iteration 799 : loss : 0.158857, loss_ce: 0.053299
 12%|███▌                          | 47/400 [20:40<2:33:55, 26.16s/it]2021-12-17 16:05:22,586 iteration 800 : loss : 0.172963, loss_ce: 0.045914
2021-12-17 16:05:23,917 iteration 801 : loss : 0.192390, loss_ce: 0.060946
2021-12-17 16:05:25,289 iteration 802 : loss : 0.165685, loss_ce: 0.059705
2021-12-17 16:05:26,732 iteration 803 : loss : 0.217853, loss_ce: 0.114950
2021-12-17 16:05:28,052 iteration 804 : loss : 0.181858, loss_ce: 0.071055
2021-12-17 16:05:29,375 iteration 805 : loss : 0.187417, loss_ce: 0.055854
2021-12-17 16:05:30,755 iteration 806 : loss : 0.186192, loss_ce: 0.057256
2021-12-17 16:05:32,216 iteration 807 : loss : 0.158271, loss_ce: 0.049592
2021-12-17 16:05:33,637 iteration 808 : loss : 0.166246, loss_ce: 0.053539
2021-12-17 16:05:34,993 iteration 809 : loss : 0.196582, loss_ce: 0.059760
2021-12-17 16:05:36,414 iteration 810 : loss : 0.190003, loss_ce: 0.057727
2021-12-17 16:05:37,763 iteration 811 : loss : 0.162137, loss_ce: 0.059003
2021-12-17 16:05:39,193 iteration 812 : loss : 0.169134, loss_ce: 0.057793
2021-12-17 16:05:40,550 iteration 813 : loss : 0.164606, loss_ce: 0.061540
2021-12-17 16:05:41,935 iteration 814 : loss : 0.173010, loss_ce: 0.071816
2021-12-17 16:05:43,359 iteration 815 : loss : 0.177075, loss_ce: 0.053285
2021-12-17 16:05:44,626 iteration 816 : loss : 0.156887, loss_ce: 0.051718
 12%|███▌                          | 48/400 [21:03<2:28:50, 25.37s/it]2021-12-17 16:05:46,030 iteration 817 : loss : 0.158013, loss_ce: 0.054016
2021-12-17 16:05:47,440 iteration 818 : loss : 0.174573, loss_ce: 0.060918
2021-12-17 16:05:48,797 iteration 819 : loss : 0.155856, loss_ce: 0.052963
2021-12-17 16:05:50,260 iteration 820 : loss : 0.184092, loss_ce: 0.065271
2021-12-17 16:05:51,558 iteration 821 : loss : 0.174498, loss_ce: 0.058572
2021-12-17 16:05:52,965 iteration 822 : loss : 0.164642, loss_ce: 0.059974
2021-12-17 16:05:54,338 iteration 823 : loss : 0.193482, loss_ce: 0.070164
2021-12-17 16:05:55,692 iteration 824 : loss : 0.171881, loss_ce: 0.060813
2021-12-17 16:05:57,069 iteration 825 : loss : 0.172129, loss_ce: 0.055065
2021-12-17 16:05:58,457 iteration 826 : loss : 0.148562, loss_ce: 0.058390
2021-12-17 16:05:59,804 iteration 827 : loss : 0.206887, loss_ce: 0.052234
2021-12-17 16:06:01,211 iteration 828 : loss : 0.159721, loss_ce: 0.056009
2021-12-17 16:06:02,588 iteration 829 : loss : 0.168088, loss_ce: 0.053489
2021-12-17 16:06:04,055 iteration 830 : loss : 0.183541, loss_ce: 0.061041
2021-12-17 16:06:05,442 iteration 831 : loss : 0.171116, loss_ce: 0.063466
2021-12-17 16:06:06,786 iteration 832 : loss : 0.155636, loss_ce: 0.052772
2021-12-17 16:06:08,120 iteration 833 : loss : 0.157492, loss_ce: 0.064176
 12%|███▋                          | 49/400 [21:27<2:25:07, 24.81s/it]2021-12-17 16:06:09,520 iteration 834 : loss : 0.179133, loss_ce: 0.053720
2021-12-17 16:06:10,908 iteration 835 : loss : 0.161277, loss_ce: 0.055943
2021-12-17 16:06:12,290 iteration 836 : loss : 0.172147, loss_ce: 0.065100
2021-12-17 16:06:13,654 iteration 837 : loss : 0.163482, loss_ce: 0.057920
2021-12-17 16:06:15,017 iteration 838 : loss : 0.165575, loss_ce: 0.058378
2021-12-17 16:06:16,454 iteration 839 : loss : 0.158581, loss_ce: 0.048524
2021-12-17 16:06:17,840 iteration 840 : loss : 0.178411, loss_ce: 0.063219
2021-12-17 16:06:19,216 iteration 841 : loss : 0.171205, loss_ce: 0.072884
2021-12-17 16:06:20,700 iteration 842 : loss : 0.192815, loss_ce: 0.073974
2021-12-17 16:06:22,059 iteration 843 : loss : 0.139582, loss_ce: 0.042219
2021-12-17 16:06:23,471 iteration 844 : loss : 0.172713, loss_ce: 0.059800
2021-12-17 16:06:24,818 iteration 845 : loss : 0.166424, loss_ce: 0.062283
2021-12-17 16:06:26,193 iteration 846 : loss : 0.185788, loss_ce: 0.065194
2021-12-17 16:06:27,595 iteration 847 : loss : 0.166390, loss_ce: 0.060844
2021-12-17 16:06:28,892 iteration 848 : loss : 0.140785, loss_ce: 0.045737
2021-12-17 16:06:30,294 iteration 849 : loss : 0.158305, loss_ce: 0.051882
2021-12-17 16:06:30,294 Training Data Eval:
2021-12-17 16:06:37,454   Average segmentation loss on training set: 0.1515
2021-12-17 16:06:37,455 Validation Data Eval:
2021-12-17 16:06:39,970   Average segmentation loss on validation set: 0.1893
2021-12-17 16:06:46,270 Found new lowest validation loss at iteration 849! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/TU_3seeds/TU_RESNET_no_pretraining_SGD_best_val_loss_seed100.pth
2021-12-17 16:06:47,711 iteration 850 : loss : 0.158330, loss_ce: 0.053523
 12%|███▊                          | 50/400 [22:06<2:50:34, 29.24s/it]2021-12-17 16:06:49,109 iteration 851 : loss : 0.168857, loss_ce: 0.070792
2021-12-17 16:06:50,461 iteration 852 : loss : 0.142383, loss_ce: 0.043989
2021-12-17 16:06:51,819 iteration 853 : loss : 0.159998, loss_ce: 0.052238
2021-12-17 16:06:53,088 iteration 854 : loss : 0.137685, loss_ce: 0.044355
2021-12-17 16:06:54,322 iteration 855 : loss : 0.160401, loss_ce: 0.052050
2021-12-17 16:06:55,598 iteration 856 : loss : 0.160931, loss_ce: 0.051602
2021-12-17 16:06:56,993 iteration 857 : loss : 0.170431, loss_ce: 0.060657
2021-12-17 16:06:58,307 iteration 858 : loss : 0.174311, loss_ce: 0.060279
2021-12-17 16:06:59,707 iteration 859 : loss : 0.158387, loss_ce: 0.051811
2021-12-17 16:07:01,068 iteration 860 : loss : 0.176784, loss_ce: 0.056963
2021-12-17 16:07:02,381 iteration 861 : loss : 0.168823, loss_ce: 0.054537
2021-12-17 16:07:03,700 iteration 862 : loss : 0.149106, loss_ce: 0.038851
2021-12-17 16:07:04,950 iteration 863 : loss : 0.166791, loss_ce: 0.066722
2021-12-17 16:07:06,259 iteration 864 : loss : 0.149874, loss_ce: 0.052419
2021-12-17 16:07:07,516 iteration 865 : loss : 0.152025, loss_ce: 0.056947
2021-12-17 16:07:08,791 iteration 866 : loss : 0.146256, loss_ce: 0.045402
2021-12-17 16:07:10,116 iteration 867 : loss : 0.156336, loss_ce: 0.054895
 13%|███▊                          | 51/400 [22:29<2:38:09, 27.19s/it]2021-12-17 16:07:11,578 iteration 868 : loss : 0.172181, loss_ce: 0.056925
2021-12-17 16:07:12,937 iteration 869 : loss : 0.152323, loss_ce: 0.055690
2021-12-17 16:07:14,349 iteration 870 : loss : 0.168855, loss_ce: 0.049824
2021-12-17 16:07:15,760 iteration 871 : loss : 0.181276, loss_ce: 0.050748
2021-12-17 16:07:17,096 iteration 872 : loss : 0.152877, loss_ce: 0.052243
2021-12-17 16:07:18,422 iteration 873 : loss : 0.158337, loss_ce: 0.046769
2021-12-17 16:07:19,825 iteration 874 : loss : 0.157631, loss_ce: 0.054106
2021-12-17 16:07:21,228 iteration 875 : loss : 0.150552, loss_ce: 0.059911
2021-12-17 16:07:22,608 iteration 876 : loss : 0.165063, loss_ce: 0.066392
2021-12-17 16:07:23,936 iteration 877 : loss : 0.163273, loss_ce: 0.056072
2021-12-17 16:07:25,276 iteration 878 : loss : 0.160598, loss_ce: 0.052263
2021-12-17 16:07:26,656 iteration 879 : loss : 0.159830, loss_ce: 0.056736
2021-12-17 16:07:28,004 iteration 880 : loss : 0.149299, loss_ce: 0.049053
2021-12-17 16:07:29,423 iteration 881 : loss : 0.162829, loss_ce: 0.057587
2021-12-17 16:07:30,777 iteration 882 : loss : 0.153776, loss_ce: 0.054677
2021-12-17 16:07:32,130 iteration 883 : loss : 0.165178, loss_ce: 0.047985
2021-12-17 16:07:33,619 iteration 884 : loss : 0.181776, loss_ce: 0.057292
 13%|███▉                          | 52/400 [22:52<2:31:16, 26.08s/it]2021-12-17 16:07:35,112 iteration 885 : loss : 0.175888, loss_ce: 0.070975
2021-12-17 16:07:36,460 iteration 886 : loss : 0.171850, loss_ce: 0.052751
2021-12-17 16:07:37,821 iteration 887 : loss : 0.152955, loss_ce: 0.052808
2021-12-17 16:07:39,206 iteration 888 : loss : 0.148477, loss_ce: 0.044203
2021-12-17 16:07:40,552 iteration 889 : loss : 0.152783, loss_ce: 0.041951
2021-12-17 16:07:41,977 iteration 890 : loss : 0.156621, loss_ce: 0.055468
2021-12-17 16:07:43,376 iteration 891 : loss : 0.161049, loss_ce: 0.065064
2021-12-17 16:07:44,758 iteration 892 : loss : 0.156619, loss_ce: 0.043121
2021-12-17 16:07:46,206 iteration 893 : loss : 0.173533, loss_ce: 0.061627
2021-12-17 16:07:47,589 iteration 894 : loss : 0.161483, loss_ce: 0.054315
2021-12-17 16:07:48,973 iteration 895 : loss : 0.161173, loss_ce: 0.052524
2021-12-17 16:07:50,393 iteration 896 : loss : 0.180713, loss_ce: 0.051206
2021-12-17 16:07:51,711 iteration 897 : loss : 0.147439, loss_ce: 0.048385
2021-12-17 16:07:53,178 iteration 898 : loss : 0.186674, loss_ce: 0.059244
2021-12-17 16:07:54,543 iteration 899 : loss : 0.170259, loss_ce: 0.055317
2021-12-17 16:07:55,937 iteration 900 : loss : 0.181826, loss_ce: 0.061364
2021-12-17 16:07:57,302 iteration 901 : loss : 0.178800, loss_ce: 0.085385
 13%|███▉                          | 53/400 [23:16<2:26:42, 25.37s/it]2021-12-17 16:07:58,744 iteration 902 : loss : 0.153204, loss_ce: 0.051634
2021-12-17 16:08:00,146 iteration 903 : loss : 0.166635, loss_ce: 0.055927
2021-12-17 16:08:01,491 iteration 904 : loss : 0.161997, loss_ce: 0.061487
2021-12-17 16:08:02,828 iteration 905 : loss : 0.197751, loss_ce: 0.060211
2021-12-17 16:08:04,163 iteration 906 : loss : 0.147791, loss_ce: 0.048953
2021-12-17 16:08:05,570 iteration 907 : loss : 0.148469, loss_ce: 0.054407
2021-12-17 16:08:06,898 iteration 908 : loss : 0.137645, loss_ce: 0.052636
2021-12-17 16:08:08,306 iteration 909 : loss : 0.174243, loss_ce: 0.067681
2021-12-17 16:08:09,675 iteration 910 : loss : 0.148977, loss_ce: 0.048434
2021-12-17 16:08:11,066 iteration 911 : loss : 0.153143, loss_ce: 0.049939
2021-12-17 16:08:12,373 iteration 912 : loss : 0.161636, loss_ce: 0.050763
2021-12-17 16:08:13,789 iteration 913 : loss : 0.143583, loss_ce: 0.042044
2021-12-17 16:08:15,131 iteration 914 : loss : 0.148797, loss_ce: 0.051079
2021-12-17 16:08:16,544 iteration 915 : loss : 0.164191, loss_ce: 0.062351
2021-12-17 16:08:17,894 iteration 916 : loss : 0.157893, loss_ce: 0.048965
2021-12-17 16:08:19,255 iteration 917 : loss : 0.152836, loss_ce: 0.046303
2021-12-17 16:08:20,624 iteration 918 : loss : 0.168969, loss_ce: 0.048713
 14%|████                          | 54/400 [23:39<2:22:43, 24.75s/it]2021-12-17 16:08:22,108 iteration 919 : loss : 0.146945, loss_ce: 0.048739
2021-12-17 16:08:23,431 iteration 920 : loss : 0.173170, loss_ce: 0.081280
2021-12-17 16:08:24,878 iteration 921 : loss : 0.157677, loss_ce: 0.053492
2021-12-17 16:08:26,170 iteration 922 : loss : 0.163272, loss_ce: 0.059378
2021-12-17 16:08:27,503 iteration 923 : loss : 0.157581, loss_ce: 0.052605
2021-12-17 16:08:28,868 iteration 924 : loss : 0.151699, loss_ce: 0.047292
2021-12-17 16:08:30,201 iteration 925 : loss : 0.152508, loss_ce: 0.045313
2021-12-17 16:08:31,528 iteration 926 : loss : 0.150185, loss_ce: 0.047921
2021-12-17 16:08:32,917 iteration 927 : loss : 0.157298, loss_ce: 0.058110
2021-12-17 16:08:34,246 iteration 928 : loss : 0.143191, loss_ce: 0.044529
2021-12-17 16:08:35,754 iteration 929 : loss : 0.162985, loss_ce: 0.065146
2021-12-17 16:08:37,129 iteration 930 : loss : 0.148236, loss_ce: 0.059050
2021-12-17 16:08:38,512 iteration 931 : loss : 0.155552, loss_ce: 0.045538
2021-12-17 16:08:39,898 iteration 932 : loss : 0.162631, loss_ce: 0.040715
2021-12-17 16:08:41,391 iteration 933 : loss : 0.173280, loss_ce: 0.055112
2021-12-17 16:08:42,747 iteration 934 : loss : 0.146783, loss_ce: 0.048696
2021-12-17 16:08:42,747 Training Data Eval:
2021-12-17 16:08:49,919   Average segmentation loss on training set: 0.1359
2021-12-17 16:08:49,919 Validation Data Eval:
2021-12-17 16:08:52,410   Average segmentation loss on validation set: 0.1866
2021-12-17 16:09:01,565 Found new lowest validation loss at iteration 934! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/TU_3seeds/TU_RESNET_no_pretraining_SGD_best_val_loss_seed100.pth
2021-12-17 16:09:02,927 iteration 935 : loss : 0.147556, loss_ce: 0.044795
 14%|████▏                         | 55/400 [24:22<2:52:35, 30.02s/it]2021-12-17 16:09:04,275 iteration 936 : loss : 0.153903, loss_ce: 0.037941
2021-12-17 16:09:05,565 iteration 937 : loss : 0.141878, loss_ce: 0.045632
2021-12-17 16:09:06,894 iteration 938 : loss : 0.149814, loss_ce: 0.058869
2021-12-17 16:09:08,203 iteration 939 : loss : 0.166842, loss_ce: 0.060960
2021-12-17 16:09:09,490 iteration 940 : loss : 0.148647, loss_ce: 0.050041
2021-12-17 16:09:10,822 iteration 941 : loss : 0.163847, loss_ce: 0.053648
2021-12-17 16:09:12,124 iteration 942 : loss : 0.145534, loss_ce: 0.038850
2021-12-17 16:09:13,368 iteration 943 : loss : 0.155447, loss_ce: 0.038632
2021-12-17 16:09:14,649 iteration 944 : loss : 0.146877, loss_ce: 0.043341
2021-12-17 16:09:15,936 iteration 945 : loss : 0.177395, loss_ce: 0.087659
2021-12-17 16:09:17,255 iteration 946 : loss : 0.132539, loss_ce: 0.039115
2021-12-17 16:09:18,674 iteration 947 : loss : 0.157746, loss_ce: 0.057739
2021-12-17 16:09:19,960 iteration 948 : loss : 0.155250, loss_ce: 0.052849
2021-12-17 16:09:21,306 iteration 949 : loss : 0.154500, loss_ce: 0.046841
2021-12-17 16:09:22,658 iteration 950 : loss : 0.197861, loss_ce: 0.053068
2021-12-17 16:09:24,051 iteration 951 : loss : 0.154749, loss_ce: 0.056589
2021-12-17 16:09:25,322 iteration 952 : loss : 0.165807, loss_ce: 0.047499
 14%|████▏                         | 56/400 [24:44<2:38:59, 27.73s/it]2021-12-17 16:09:26,720 iteration 953 : loss : 0.151185, loss_ce: 0.047999
2021-12-17 16:09:28,194 iteration 954 : loss : 0.149640, loss_ce: 0.048964
2021-12-17 16:09:29,571 iteration 955 : loss : 0.132962, loss_ce: 0.045689
2021-12-17 16:09:30,963 iteration 956 : loss : 0.142996, loss_ce: 0.047798
2021-12-17 16:09:32,269 iteration 957 : loss : 0.163801, loss_ce: 0.049046
2021-12-17 16:09:33,659 iteration 958 : loss : 0.139386, loss_ce: 0.038002
2021-12-17 16:09:35,025 iteration 959 : loss : 0.147161, loss_ce: 0.054106
2021-12-17 16:09:36,386 iteration 960 : loss : 0.157227, loss_ce: 0.052341
2021-12-17 16:09:37,793 iteration 961 : loss : 0.178036, loss_ce: 0.061329
2021-12-17 16:09:39,165 iteration 962 : loss : 0.142435, loss_ce: 0.045040
2021-12-17 16:09:40,589 iteration 963 : loss : 0.165299, loss_ce: 0.051379
2021-12-17 16:09:41,998 iteration 964 : loss : 0.166987, loss_ce: 0.063732
2021-12-17 16:09:43,371 iteration 965 : loss : 0.138876, loss_ce: 0.048765
2021-12-17 16:09:44,817 iteration 966 : loss : 0.176572, loss_ce: 0.069549
2021-12-17 16:09:46,197 iteration 967 : loss : 0.172634, loss_ce: 0.057913
2021-12-17 16:09:47,600 iteration 968 : loss : 0.159910, loss_ce: 0.057703
2021-12-17 16:09:49,017 iteration 969 : loss : 0.149192, loss_ce: 0.048757
 14%|████▎                         | 57/400 [25:08<2:31:36, 26.52s/it]2021-12-17 16:09:50,425 iteration 970 : loss : 0.134337, loss_ce: 0.039647
2021-12-17 16:09:51,865 iteration 971 : loss : 0.156932, loss_ce: 0.045558
2021-12-17 16:09:53,193 iteration 972 : loss : 0.140628, loss_ce: 0.043899
2021-12-17 16:09:54,532 iteration 973 : loss : 0.139124, loss_ce: 0.045041
2021-12-17 16:09:55,909 iteration 974 : loss : 0.166585, loss_ce: 0.054079
2021-12-17 16:09:57,256 iteration 975 : loss : 0.150899, loss_ce: 0.044045
2021-12-17 16:09:58,609 iteration 976 : loss : 0.160647, loss_ce: 0.047593
2021-12-17 16:10:00,042 iteration 977 : loss : 0.146395, loss_ce: 0.045237
2021-12-17 16:10:01,443 iteration 978 : loss : 0.158703, loss_ce: 0.061124
2021-12-17 16:10:02,856 iteration 979 : loss : 0.140084, loss_ce: 0.053416
2021-12-17 16:10:04,187 iteration 980 : loss : 0.165111, loss_ce: 0.054617
2021-12-17 16:10:05,625 iteration 981 : loss : 0.152175, loss_ce: 0.052276
2021-12-17 16:10:06,954 iteration 982 : loss : 0.154145, loss_ce: 0.061558
2021-12-17 16:10:08,366 iteration 983 : loss : 0.154466, loss_ce: 0.054884
2021-12-17 16:10:09,748 iteration 984 : loss : 0.169616, loss_ce: 0.062400
2021-12-17 16:10:11,108 iteration 985 : loss : 0.152684, loss_ce: 0.041952
2021-12-17 16:10:12,472 iteration 986 : loss : 0.137238, loss_ce: 0.037007
 14%|████▎                         | 58/400 [25:31<2:25:54, 25.60s/it]2021-12-17 16:10:13,907 iteration 987 : loss : 0.142281, loss_ce: 0.047578
2021-12-17 16:10:15,354 iteration 988 : loss : 0.170632, loss_ce: 0.063377
2021-12-17 16:10:16,702 iteration 989 : loss : 0.153375, loss_ce: 0.044981
2021-12-17 16:10:18,143 iteration 990 : loss : 0.155394, loss_ce: 0.064273
2021-12-17 16:10:19,565 iteration 991 : loss : 0.152803, loss_ce: 0.059752
2021-12-17 16:10:20,883 iteration 992 : loss : 0.153419, loss_ce: 0.041447
2021-12-17 16:10:22,362 iteration 993 : loss : 0.161066, loss_ce: 0.052655
2021-12-17 16:10:23,776 iteration 994 : loss : 0.145860, loss_ce: 0.043314
2021-12-17 16:10:25,173 iteration 995 : loss : 0.156674, loss_ce: 0.051732
2021-12-17 16:10:26,530 iteration 996 : loss : 0.142316, loss_ce: 0.045872
2021-12-17 16:10:27,946 iteration 997 : loss : 0.163588, loss_ce: 0.068039
2021-12-17 16:10:29,330 iteration 998 : loss : 0.162303, loss_ce: 0.054499
2021-12-17 16:10:30,786 iteration 999 : loss : 0.141073, loss_ce: 0.044641
2021-12-17 16:10:32,175 iteration 1000 : loss : 0.174329, loss_ce: 0.064311
2021-12-17 16:10:33,573 iteration 1001 : loss : 0.146921, loss_ce: 0.050835
2021-12-17 16:10:34,905 iteration 1002 : loss : 0.151893, loss_ce: 0.043387
2021-12-17 16:10:36,255 iteration 1003 : loss : 0.144112, loss_ce: 0.044882
 15%|████▍                         | 59/400 [25:55<2:22:23, 25.06s/it]2021-12-17 16:10:37,671 iteration 1004 : loss : 0.165701, loss_ce: 0.059024
2021-12-17 16:10:39,122 iteration 1005 : loss : 0.179881, loss_ce: 0.051249
2021-12-17 16:10:40,510 iteration 1006 : loss : 0.148382, loss_ce: 0.053479
2021-12-17 16:10:41,911 iteration 1007 : loss : 0.163033, loss_ce: 0.054108
2021-12-17 16:10:43,297 iteration 1008 : loss : 0.163187, loss_ce: 0.046330
2021-12-17 16:10:44,683 iteration 1009 : loss : 0.141775, loss_ce: 0.043661
2021-12-17 16:10:46,030 iteration 1010 : loss : 0.154889, loss_ce: 0.055170
2021-12-17 16:10:47,389 iteration 1011 : loss : 0.139628, loss_ce: 0.045231
2021-12-17 16:10:48,829 iteration 1012 : loss : 0.165314, loss_ce: 0.046199
2021-12-17 16:10:50,169 iteration 1013 : loss : 0.176723, loss_ce: 0.057239
2021-12-17 16:10:51,585 iteration 1014 : loss : 0.172865, loss_ce: 0.055875
2021-12-17 16:10:52,955 iteration 1015 : loss : 0.149958, loss_ce: 0.061017
2021-12-17 16:10:54,255 iteration 1016 : loss : 0.149312, loss_ce: 0.058655
2021-12-17 16:10:55,727 iteration 1017 : loss : 0.151435, loss_ce: 0.044721
2021-12-17 16:10:57,162 iteration 1018 : loss : 0.150390, loss_ce: 0.055777
2021-12-17 16:10:58,612 iteration 1019 : loss : 0.166928, loss_ce: 0.060805
2021-12-17 16:10:58,612 Training Data Eval:
2021-12-17 16:11:05,795   Average segmentation loss on training set: 0.1467
2021-12-17 16:11:05,795 Validation Data Eval:
2021-12-17 16:11:08,307   Average segmentation loss on validation set: 0.1829
2021-12-17 16:11:17,114 Found new lowest validation loss at iteration 1019! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/TU_3seeds/TU_RESNET_no_pretraining_SGD_best_val_loss_seed100.pth
2021-12-17 16:11:18,533 iteration 1020 : loss : 0.160501, loss_ce: 0.049382
 15%|████▌                         | 60/400 [26:37<2:51:16, 30.23s/it]2021-12-17 16:11:19,990 iteration 1021 : loss : 0.161292, loss_ce: 0.052592
2021-12-17 16:11:21,302 iteration 1022 : loss : 0.159799, loss_ce: 0.051371
2021-12-17 16:11:22,592 iteration 1023 : loss : 0.167316, loss_ce: 0.051351
2021-12-17 16:11:23,941 iteration 1024 : loss : 0.138404, loss_ce: 0.050993
2021-12-17 16:11:25,235 iteration 1025 : loss : 0.145049, loss_ce: 0.049633
2021-12-17 16:11:26,578 iteration 1026 : loss : 0.161055, loss_ce: 0.050547
2021-12-17 16:11:27,885 iteration 1027 : loss : 0.147534, loss_ce: 0.059201
2021-12-17 16:11:29,165 iteration 1028 : loss : 0.129861, loss_ce: 0.035520
2021-12-17 16:11:30,506 iteration 1029 : loss : 0.151879, loss_ce: 0.041859
2021-12-17 16:11:31,847 iteration 1030 : loss : 0.154715, loss_ce: 0.054007
2021-12-17 16:11:33,236 iteration 1031 : loss : 0.149438, loss_ce: 0.051435
2021-12-17 16:11:34,509 iteration 1032 : loss : 0.128500, loss_ce: 0.042011
2021-12-17 16:11:35,889 iteration 1033 : loss : 0.146651, loss_ce: 0.048933
2021-12-17 16:11:37,278 iteration 1034 : loss : 0.141248, loss_ce: 0.049558
2021-12-17 16:11:38,637 iteration 1035 : loss : 0.170372, loss_ce: 0.051239
2021-12-17 16:11:40,048 iteration 1036 : loss : 0.139770, loss_ce: 0.045931
2021-12-17 16:11:41,267 iteration 1037 : loss : 0.151157, loss_ce: 0.047894
 15%|████▌                         | 61/400 [27:00<2:38:04, 27.98s/it]2021-12-17 16:11:42,595 iteration 1038 : loss : 0.140197, loss_ce: 0.047483
2021-12-17 16:11:43,961 iteration 1039 : loss : 0.145700, loss_ce: 0.043484
2021-12-17 16:11:45,310 iteration 1040 : loss : 0.139641, loss_ce: 0.043145
2021-12-17 16:11:46,803 iteration 1041 : loss : 0.154027, loss_ce: 0.046501
2021-12-17 16:11:48,294 iteration 1042 : loss : 0.151215, loss_ce: 0.044517
2021-12-17 16:11:49,685 iteration 1043 : loss : 0.122932, loss_ce: 0.036587
2021-12-17 16:11:51,099 iteration 1044 : loss : 0.125293, loss_ce: 0.039895
2021-12-17 16:11:52,482 iteration 1045 : loss : 0.141909, loss_ce: 0.058366
2021-12-17 16:11:53,886 iteration 1046 : loss : 0.152876, loss_ce: 0.047050
2021-12-17 16:11:55,341 iteration 1047 : loss : 0.160872, loss_ce: 0.058036
2021-12-17 16:11:56,726 iteration 1048 : loss : 0.177937, loss_ce: 0.064965
2021-12-17 16:11:58,059 iteration 1049 : loss : 0.147224, loss_ce: 0.051838
2021-12-17 16:11:59,416 iteration 1050 : loss : 0.136421, loss_ce: 0.045454
2021-12-17 16:12:00,819 iteration 1051 : loss : 0.143865, loss_ce: 0.044556
2021-12-17 16:12:02,226 iteration 1052 : loss : 0.152727, loss_ce: 0.052806
2021-12-17 16:12:03,712 iteration 1053 : loss : 0.139874, loss_ce: 0.050170
2021-12-17 16:12:05,079 iteration 1054 : loss : 0.139357, loss_ce: 0.039867
 16%|████▋                         | 62/400 [27:24<2:30:32, 26.72s/it]2021-12-17 16:12:06,499 iteration 1055 : loss : 0.141371, loss_ce: 0.044826
2021-12-17 16:12:07,861 iteration 1056 : loss : 0.160650, loss_ce: 0.056381
2021-12-17 16:12:09,262 iteration 1057 : loss : 0.152160, loss_ce: 0.037582
2021-12-17 16:12:10,585 iteration 1058 : loss : 0.134508, loss_ce: 0.047168
2021-12-17 16:12:12,045 iteration 1059 : loss : 0.143067, loss_ce: 0.050927
2021-12-17 16:12:13,404 iteration 1060 : loss : 0.144516, loss_ce: 0.053449
2021-12-17 16:12:14,811 iteration 1061 : loss : 0.144511, loss_ce: 0.044992
2021-12-17 16:12:16,195 iteration 1062 : loss : 0.138824, loss_ce: 0.045693
2021-12-17 16:12:17,651 iteration 1063 : loss : 0.131937, loss_ce: 0.037034
2021-12-17 16:12:19,016 iteration 1064 : loss : 0.156350, loss_ce: 0.057334
2021-12-17 16:12:20,338 iteration 1065 : loss : 0.152322, loss_ce: 0.049361
2021-12-17 16:12:21,745 iteration 1066 : loss : 0.144053, loss_ce: 0.050577
2021-12-17 16:12:23,246 iteration 1067 : loss : 0.156815, loss_ce: 0.050923
2021-12-17 16:12:24,670 iteration 1068 : loss : 0.155117, loss_ce: 0.047080
2021-12-17 16:12:26,005 iteration 1069 : loss : 0.143118, loss_ce: 0.045816
2021-12-17 16:12:27,476 iteration 1070 : loss : 0.141517, loss_ce: 0.040089
2021-12-17 16:12:28,850 iteration 1071 : loss : 0.136673, loss_ce: 0.046430
 16%|████▋                         | 63/400 [27:47<2:25:07, 25.84s/it]2021-12-17 16:12:30,248 iteration 1072 : loss : 0.133060, loss_ce: 0.042555
2021-12-17 16:12:31,706 iteration 1073 : loss : 0.152418, loss_ce: 0.047477
2021-12-17 16:12:33,054 iteration 1074 : loss : 0.122206, loss_ce: 0.041761
2021-12-17 16:12:34,434 iteration 1075 : loss : 0.132817, loss_ce: 0.041075
2021-12-17 16:12:35,779 iteration 1076 : loss : 0.135756, loss_ce: 0.043465
2021-12-17 16:12:37,189 iteration 1077 : loss : 0.162046, loss_ce: 0.036587
2021-12-17 16:12:38,514 iteration 1078 : loss : 0.141222, loss_ce: 0.045786
2021-12-17 16:12:39,908 iteration 1079 : loss : 0.138937, loss_ce: 0.051314
2021-12-17 16:12:41,326 iteration 1080 : loss : 0.146453, loss_ce: 0.048023
2021-12-17 16:12:42,732 iteration 1081 : loss : 0.144983, loss_ce: 0.045218
2021-12-17 16:12:44,110 iteration 1082 : loss : 0.153185, loss_ce: 0.054397
2021-12-17 16:12:45,495 iteration 1083 : loss : 0.147687, loss_ce: 0.044329
2021-12-17 16:12:46,928 iteration 1084 : loss : 0.151533, loss_ce: 0.039958
2021-12-17 16:12:48,298 iteration 1085 : loss : 0.144059, loss_ce: 0.044494
2021-12-17 16:12:49,711 iteration 1086 : loss : 0.141631, loss_ce: 0.042560
2021-12-17 16:12:51,029 iteration 1087 : loss : 0.122554, loss_ce: 0.038467
2021-12-17 16:12:52,391 iteration 1088 : loss : 0.131189, loss_ce: 0.048514
 16%|████▊                         | 64/400 [28:11<2:20:51, 25.15s/it]2021-12-17 16:12:53,724 iteration 1089 : loss : 0.126570, loss_ce: 0.040816
2021-12-17 16:12:55,102 iteration 1090 : loss : 0.145547, loss_ce: 0.043067
2021-12-17 16:12:56,526 iteration 1091 : loss : 0.156191, loss_ce: 0.062885
2021-12-17 16:12:57,924 iteration 1092 : loss : 0.135921, loss_ce: 0.035325
2021-12-17 16:12:59,322 iteration 1093 : loss : 0.152265, loss_ce: 0.035328
2021-12-17 16:13:00,813 iteration 1094 : loss : 0.172558, loss_ce: 0.039160
2021-12-17 16:13:02,135 iteration 1095 : loss : 0.119642, loss_ce: 0.029958
2021-12-17 16:13:03,481 iteration 1096 : loss : 0.136148, loss_ce: 0.047655
2021-12-17 16:13:04,800 iteration 1097 : loss : 0.121541, loss_ce: 0.035695
2021-12-17 16:13:06,234 iteration 1098 : loss : 0.138090, loss_ce: 0.044214
2021-12-17 16:13:07,599 iteration 1099 : loss : 0.118643, loss_ce: 0.031512
2021-12-17 16:13:09,026 iteration 1100 : loss : 0.141832, loss_ce: 0.050788
2021-12-17 16:13:10,465 iteration 1101 : loss : 0.149927, loss_ce: 0.049262
2021-12-17 16:13:11,849 iteration 1102 : loss : 0.157263, loss_ce: 0.052816
2021-12-17 16:13:13,247 iteration 1103 : loss : 0.134245, loss_ce: 0.042145
2021-12-17 16:13:14,603 iteration 1104 : loss : 0.134713, loss_ce: 0.044012
2021-12-17 16:13:14,604 Training Data Eval:
2021-12-17 16:13:21,770   Average segmentation loss on training set: 0.1227
2021-12-17 16:13:21,771 Validation Data Eval:
2021-12-17 16:13:24,267   Average segmentation loss on validation set: 0.1683
2021-12-17 16:13:32,482 Found new lowest validation loss at iteration 1104! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/TU_3seeds/TU_RESNET_no_pretraining_SGD_best_val_loss_seed100.pth
2021-12-17 16:13:33,858 iteration 1105 : loss : 0.145325, loss_ce: 0.049000
 16%|████▉                         | 65/400 [28:52<2:47:45, 30.05s/it]2021-12-17 16:13:35,266 iteration 1106 : loss : 0.133257, loss_ce: 0.037442
2021-12-17 16:13:36,584 iteration 1107 : loss : 0.144368, loss_ce: 0.042992
2021-12-17 16:13:37,874 iteration 1108 : loss : 0.138236, loss_ce: 0.040727
2021-12-17 16:13:39,253 iteration 1109 : loss : 0.148337, loss_ce: 0.048138
2021-12-17 16:13:40,566 iteration 1110 : loss : 0.139442, loss_ce: 0.047246
2021-12-17 16:13:41,968 iteration 1111 : loss : 0.178228, loss_ce: 0.052072
2021-12-17 16:13:43,247 iteration 1112 : loss : 0.139651, loss_ce: 0.048750
2021-12-17 16:13:44,570 iteration 1113 : loss : 0.153362, loss_ce: 0.046060
2021-12-17 16:13:45,903 iteration 1114 : loss : 0.140613, loss_ce: 0.044520
2021-12-17 16:13:47,244 iteration 1115 : loss : 0.128445, loss_ce: 0.037881
2021-12-17 16:13:48,494 iteration 1116 : loss : 0.145349, loss_ce: 0.058161
2021-12-17 16:13:49,765 iteration 1117 : loss : 0.130268, loss_ce: 0.042482
2021-12-17 16:13:51,110 iteration 1118 : loss : 0.130015, loss_ce: 0.044760
2021-12-17 16:13:52,467 iteration 1119 : loss : 0.132532, loss_ce: 0.043024
2021-12-17 16:13:53,800 iteration 1120 : loss : 0.131781, loss_ce: 0.033096
2021-12-17 16:13:55,102 iteration 1121 : loss : 0.139104, loss_ce: 0.046924
2021-12-17 16:13:56,362 iteration 1122 : loss : 0.130618, loss_ce: 0.035139
 16%|████▉                         | 66/400 [29:15<2:34:39, 27.78s/it]2021-12-17 16:13:57,873 iteration 1123 : loss : 0.132516, loss_ce: 0.040919
2021-12-17 16:13:59,273 iteration 1124 : loss : 0.116293, loss_ce: 0.038829
2021-12-17 16:14:00,662 iteration 1125 : loss : 0.135077, loss_ce: 0.032466
2021-12-17 16:14:02,063 iteration 1126 : loss : 0.154892, loss_ce: 0.045372
2021-12-17 16:14:03,455 iteration 1127 : loss : 0.138195, loss_ce: 0.044584
2021-12-17 16:14:04,919 iteration 1128 : loss : 0.140055, loss_ce: 0.049111
2021-12-17 16:14:06,395 iteration 1129 : loss : 0.151488, loss_ce: 0.055513
2021-12-17 16:14:07,732 iteration 1130 : loss : 0.122752, loss_ce: 0.036778
2021-12-17 16:14:09,161 iteration 1131 : loss : 0.143542, loss_ce: 0.050642
2021-12-17 16:14:10,622 iteration 1132 : loss : 0.148685, loss_ce: 0.050526
2021-12-17 16:14:12,073 iteration 1133 : loss : 0.137635, loss_ce: 0.043606
2021-12-17 16:14:13,506 iteration 1134 : loss : 0.147047, loss_ce: 0.041670
2021-12-17 16:14:14,840 iteration 1135 : loss : 0.135007, loss_ce: 0.039506
2021-12-17 16:14:16,191 iteration 1136 : loss : 0.125547, loss_ce: 0.043649
2021-12-17 16:14:17,550 iteration 1137 : loss : 0.158948, loss_ce: 0.066219
2021-12-17 16:14:18,960 iteration 1138 : loss : 0.137823, loss_ce: 0.042672
2021-12-17 16:14:20,301 iteration 1139 : loss : 0.143811, loss_ce: 0.047916
 17%|█████                         | 67/400 [29:39<2:27:47, 26.63s/it]2021-12-17 16:14:21,752 iteration 1140 : loss : 0.127291, loss_ce: 0.041590
2021-12-17 16:14:23,168 iteration 1141 : loss : 0.161886, loss_ce: 0.063248
2021-12-17 16:14:24,666 iteration 1142 : loss : 0.142149, loss_ce: 0.045350
2021-12-17 16:14:26,061 iteration 1143 : loss : 0.151531, loss_ce: 0.052453
2021-12-17 16:14:27,467 iteration 1144 : loss : 0.150188, loss_ce: 0.037044
2021-12-17 16:14:28,860 iteration 1145 : loss : 0.140030, loss_ce: 0.042806
2021-12-17 16:14:30,228 iteration 1146 : loss : 0.121578, loss_ce: 0.036070
2021-12-17 16:14:31,594 iteration 1147 : loss : 0.124269, loss_ce: 0.040059
2021-12-17 16:14:32,953 iteration 1148 : loss : 0.127718, loss_ce: 0.041445
2021-12-17 16:14:34,334 iteration 1149 : loss : 0.123274, loss_ce: 0.043305
2021-12-17 16:14:35,689 iteration 1150 : loss : 0.135430, loss_ce: 0.044785
2021-12-17 16:14:37,060 iteration 1151 : loss : 0.123464, loss_ce: 0.038650
2021-12-17 16:14:38,417 iteration 1152 : loss : 0.142637, loss_ce: 0.045933
2021-12-17 16:14:39,879 iteration 1153 : loss : 0.159806, loss_ce: 0.042541
2021-12-17 16:14:41,292 iteration 1154 : loss : 0.125753, loss_ce: 0.032916
2021-12-17 16:14:42,710 iteration 1155 : loss : 0.150115, loss_ce: 0.046406
2021-12-17 16:14:44,186 iteration 1156 : loss : 0.147630, loss_ce: 0.044360
 17%|█████                         | 68/400 [30:03<2:22:46, 25.80s/it]2021-12-17 16:14:45,633 iteration 1157 : loss : 0.146271, loss_ce: 0.053719
2021-12-17 16:14:46,998 iteration 1158 : loss : 0.129151, loss_ce: 0.039828
2021-12-17 16:14:48,296 iteration 1159 : loss : 0.120207, loss_ce: 0.036189
2021-12-17 16:14:49,662 iteration 1160 : loss : 0.130813, loss_ce: 0.051401
2021-12-17 16:14:51,068 iteration 1161 : loss : 0.128728, loss_ce: 0.037439
2021-12-17 16:14:52,457 iteration 1162 : loss : 0.139114, loss_ce: 0.044703
2021-12-17 16:14:53,840 iteration 1163 : loss : 0.131078, loss_ce: 0.051357
2021-12-17 16:14:55,279 iteration 1164 : loss : 0.157748, loss_ce: 0.057560
2021-12-17 16:14:56,598 iteration 1165 : loss : 0.134190, loss_ce: 0.048630
2021-12-17 16:14:57,945 iteration 1166 : loss : 0.146548, loss_ce: 0.042101
2021-12-17 16:14:59,350 iteration 1167 : loss : 0.148099, loss_ce: 0.052548
2021-12-17 16:15:00,796 iteration 1168 : loss : 0.154341, loss_ce: 0.034824
2021-12-17 16:15:02,120 iteration 1169 : loss : 0.138784, loss_ce: 0.033966
2021-12-17 16:15:03,509 iteration 1170 : loss : 0.132761, loss_ce: 0.034271
2021-12-17 16:15:04,993 iteration 1171 : loss : 0.178583, loss_ce: 0.043558
2021-12-17 16:15:06,318 iteration 1172 : loss : 0.132759, loss_ce: 0.040080
2021-12-17 16:15:07,650 iteration 1173 : loss : 0.114950, loss_ce: 0.033838
 17%|█████▏                        | 69/400 [30:26<2:18:29, 25.11s/it]2021-12-17 16:15:09,117 iteration 1174 : loss : 0.123138, loss_ce: 0.035948
2021-12-17 16:15:10,561 iteration 1175 : loss : 0.139674, loss_ce: 0.047475
2021-12-17 16:15:11,906 iteration 1176 : loss : 0.140842, loss_ce: 0.041604
2021-12-17 16:15:13,263 iteration 1177 : loss : 0.141059, loss_ce: 0.050094
2021-12-17 16:15:14,584 iteration 1178 : loss : 0.138583, loss_ce: 0.042054
2021-12-17 16:15:16,013 iteration 1179 : loss : 0.134474, loss_ce: 0.044346
2021-12-17 16:15:17,421 iteration 1180 : loss : 0.132462, loss_ce: 0.043058
2021-12-17 16:15:18,753 iteration 1181 : loss : 0.132088, loss_ce: 0.036034
2021-12-17 16:15:20,114 iteration 1182 : loss : 0.120157, loss_ce: 0.036772
2021-12-17 16:15:21,503 iteration 1183 : loss : 0.126604, loss_ce: 0.038771
2021-12-17 16:15:22,907 iteration 1184 : loss : 0.142401, loss_ce: 0.047417
2021-12-17 16:15:24,277 iteration 1185 : loss : 0.138484, loss_ce: 0.060878
2021-12-17 16:15:25,671 iteration 1186 : loss : 0.125626, loss_ce: 0.033887
2021-12-17 16:15:27,008 iteration 1187 : loss : 0.138390, loss_ce: 0.048223
2021-12-17 16:15:28,425 iteration 1188 : loss : 0.140457, loss_ce: 0.042968
2021-12-17 16:15:29,839 iteration 1189 : loss : 0.147579, loss_ce: 0.030965
2021-12-17 16:15:29,839 Training Data Eval:
2021-12-17 16:15:37,009   Average segmentation loss on training set: 0.1260
2021-12-17 16:15:37,009 Validation Data Eval:
2021-12-17 16:15:39,498   Average segmentation loss on validation set: 0.1672
2021-12-17 16:15:45,819 Found new lowest validation loss at iteration 1189! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/TU_3seeds/TU_RESNET_no_pretraining_SGD_best_val_loss_seed100.pth
2021-12-17 16:15:47,181 iteration 1190 : loss : 0.132863, loss_ce: 0.036825
 18%|█████▎                        | 70/400 [31:06<2:41:51, 29.43s/it]2021-12-17 16:15:48,555 iteration 1191 : loss : 0.123937, loss_ce: 0.036439
2021-12-17 16:15:49,846 iteration 1192 : loss : 0.125903, loss_ce: 0.047238
2021-12-17 16:15:51,081 iteration 1193 : loss : 0.126611, loss_ce: 0.036915
2021-12-17 16:15:52,405 iteration 1194 : loss : 0.139144, loss_ce: 0.041822
2021-12-17 16:15:53,718 iteration 1195 : loss : 0.129795, loss_ce: 0.043668
2021-12-17 16:15:55,046 iteration 1196 : loss : 0.118719, loss_ce: 0.031141
2021-12-17 16:15:56,399 iteration 1197 : loss : 0.132751, loss_ce: 0.038676
2021-12-17 16:15:57,653 iteration 1198 : loss : 0.111351, loss_ce: 0.028245
2021-12-17 16:15:58,955 iteration 1199 : loss : 0.143663, loss_ce: 0.055977
2021-12-17 16:16:00,205 iteration 1200 : loss : 0.132960, loss_ce: 0.035937
2021-12-17 16:16:01,490 iteration 1201 : loss : 0.141767, loss_ce: 0.039597
2021-12-17 16:16:02,860 iteration 1202 : loss : 0.137372, loss_ce: 0.046508
2021-12-17 16:16:04,227 iteration 1203 : loss : 0.135763, loss_ce: 0.048357
2021-12-17 16:16:05,482 iteration 1204 : loss : 0.123755, loss_ce: 0.027918
2021-12-17 16:16:06,840 iteration 1205 : loss : 0.132233, loss_ce: 0.042641
2021-12-17 16:16:08,182 iteration 1206 : loss : 0.139790, loss_ce: 0.043303
2021-12-17 16:16:09,637 iteration 1207 : loss : 0.130498, loss_ce: 0.046836
 18%|█████▎                        | 71/400 [31:28<2:29:54, 27.34s/it]2021-12-17 16:16:11,080 iteration 1208 : loss : 0.136890, loss_ce: 0.043213
2021-12-17 16:16:12,478 iteration 1209 : loss : 0.141739, loss_ce: 0.041175
2021-12-17 16:16:13,804 iteration 1210 : loss : 0.125613, loss_ce: 0.034879
2021-12-17 16:16:15,242 iteration 1211 : loss : 0.152777, loss_ce: 0.059668
2021-12-17 16:16:16,611 iteration 1212 : loss : 0.125348, loss_ce: 0.042275
2021-12-17 16:16:17,914 iteration 1213 : loss : 0.116633, loss_ce: 0.033159
2021-12-17 16:16:19,373 iteration 1214 : loss : 0.134773, loss_ce: 0.045577
2021-12-17 16:16:20,740 iteration 1215 : loss : 0.119020, loss_ce: 0.039100
2021-12-17 16:16:22,119 iteration 1216 : loss : 0.121231, loss_ce: 0.031190
2021-12-17 16:16:23,604 iteration 1217 : loss : 0.158223, loss_ce: 0.055219
2021-12-17 16:16:24,926 iteration 1218 : loss : 0.122258, loss_ce: 0.038243
2021-12-17 16:16:26,434 iteration 1219 : loss : 0.148167, loss_ce: 0.064262
2021-12-17 16:16:27,811 iteration 1220 : loss : 0.130522, loss_ce: 0.044323
2021-12-17 16:16:29,249 iteration 1221 : loss : 0.140298, loss_ce: 0.040523
2021-12-17 16:16:30,588 iteration 1222 : loss : 0.149063, loss_ce: 0.043785
2021-12-17 16:16:31,945 iteration 1223 : loss : 0.137460, loss_ce: 0.038719
2021-12-17 16:16:33,322 iteration 1224 : loss : 0.142891, loss_ce: 0.036649
 18%|█████▍                        | 72/400 [31:52<2:23:27, 26.24s/it]2021-12-17 16:16:34,756 iteration 1225 : loss : 0.129098, loss_ce: 0.035288
2021-12-17 16:16:36,149 iteration 1226 : loss : 0.133411, loss_ce: 0.031229
2021-12-17 16:16:37,483 iteration 1227 : loss : 0.132353, loss_ce: 0.042424
2021-12-17 16:16:38,824 iteration 1228 : loss : 0.150716, loss_ce: 0.044434
2021-12-17 16:16:40,302 iteration 1229 : loss : 0.153643, loss_ce: 0.060077
2021-12-17 16:16:41,711 iteration 1230 : loss : 0.135127, loss_ce: 0.037781
2021-12-17 16:16:43,091 iteration 1231 : loss : 0.138183, loss_ce: 0.047379
2021-12-17 16:16:44,441 iteration 1232 : loss : 0.129960, loss_ce: 0.043247
2021-12-17 16:16:45,876 iteration 1233 : loss : 0.135924, loss_ce: 0.038040
2021-12-17 16:16:47,345 iteration 1234 : loss : 0.144280, loss_ce: 0.050268
2021-12-17 16:16:48,651 iteration 1235 : loss : 0.126782, loss_ce: 0.039304
2021-12-17 16:16:50,064 iteration 1236 : loss : 0.147106, loss_ce: 0.057765
2021-12-17 16:16:51,444 iteration 1237 : loss : 0.134900, loss_ce: 0.040048
2021-12-17 16:16:52,779 iteration 1238 : loss : 0.130344, loss_ce: 0.040603
2021-12-17 16:16:54,146 iteration 1239 : loss : 0.132558, loss_ce: 0.047768
2021-12-17 16:16:55,602 iteration 1240 : loss : 0.145933, loss_ce: 0.048639
2021-12-17 16:16:56,986 iteration 1241 : loss : 0.128501, loss_ce: 0.039864
 18%|█████▍                        | 73/400 [32:16<2:18:48, 25.47s/it]2021-12-17 16:16:58,464 iteration 1242 : loss : 0.139575, loss_ce: 0.053106
2021-12-17 16:16:59,844 iteration 1243 : loss : 0.133444, loss_ce: 0.041438
2021-12-17 16:17:01,305 iteration 1244 : loss : 0.132658, loss_ce: 0.043216
2021-12-17 16:17:02,746 iteration 1245 : loss : 0.139678, loss_ce: 0.041107
2021-12-17 16:17:04,120 iteration 1246 : loss : 0.131284, loss_ce: 0.043268
2021-12-17 16:17:05,645 iteration 1247 : loss : 0.155805, loss_ce: 0.045755
2021-12-17 16:17:06,987 iteration 1248 : loss : 0.131796, loss_ce: 0.039195
2021-12-17 16:17:08,353 iteration 1249 : loss : 0.129896, loss_ce: 0.045831
2021-12-17 16:17:09,731 iteration 1250 : loss : 0.170015, loss_ce: 0.042845
2021-12-17 16:17:11,163 iteration 1251 : loss : 0.152208, loss_ce: 0.056795
2021-12-17 16:17:12,496 iteration 1252 : loss : 0.156683, loss_ce: 0.040886
2021-12-17 16:17:13,874 iteration 1253 : loss : 0.131635, loss_ce: 0.041112
2021-12-17 16:17:15,260 iteration 1254 : loss : 0.116505, loss_ce: 0.031794
2021-12-17 16:17:16,747 iteration 1255 : loss : 0.131311, loss_ce: 0.046553
2021-12-17 16:17:18,111 iteration 1256 : loss : 0.128843, loss_ce: 0.037077
2021-12-17 16:17:19,403 iteration 1257 : loss : 0.123797, loss_ce: 0.036303
2021-12-17 16:17:20,707 iteration 1258 : loss : 0.115638, loss_ce: 0.041508
 18%|█████▌                        | 74/400 [32:39<2:15:31, 24.94s/it]2021-12-17 16:17:22,113 iteration 1259 : loss : 0.130617, loss_ce: 0.036771
2021-12-17 16:17:23,595 iteration 1260 : loss : 0.126065, loss_ce: 0.040372
2021-12-17 16:17:24,958 iteration 1261 : loss : 0.116924, loss_ce: 0.029144
2021-12-17 16:17:26,265 iteration 1262 : loss : 0.117481, loss_ce: 0.034424
2021-12-17 16:17:27,636 iteration 1263 : loss : 0.118619, loss_ce: 0.033892
2021-12-17 16:17:29,030 iteration 1264 : loss : 0.141795, loss_ce: 0.046228
2021-12-17 16:17:30,411 iteration 1265 : loss : 0.130887, loss_ce: 0.032762
2021-12-17 16:17:31,761 iteration 1266 : loss : 0.134492, loss_ce: 0.041117
2021-12-17 16:17:33,087 iteration 1267 : loss : 0.144771, loss_ce: 0.049095
2021-12-17 16:17:34,433 iteration 1268 : loss : 0.124148, loss_ce: 0.035999
2021-12-17 16:17:35,808 iteration 1269 : loss : 0.128176, loss_ce: 0.046969
2021-12-17 16:17:37,181 iteration 1270 : loss : 0.118011, loss_ce: 0.037524
2021-12-17 16:17:38,611 iteration 1271 : loss : 0.164818, loss_ce: 0.062915
2021-12-17 16:17:39,894 iteration 1272 : loss : 0.107210, loss_ce: 0.028760
2021-12-17 16:17:41,230 iteration 1273 : loss : 0.126435, loss_ce: 0.037593
2021-12-17 16:17:42,633 iteration 1274 : loss : 0.148313, loss_ce: 0.054978
2021-12-17 16:17:42,633 Training Data Eval:
2021-12-17 16:17:49,837   Average segmentation loss on training set: 0.1080
2021-12-17 16:17:49,837 Validation Data Eval:
2021-12-17 16:17:52,333   Average segmentation loss on validation set: 0.1722
2021-12-17 16:17:53,693 iteration 1275 : loss : 0.119826, loss_ce: 0.037815
 19%|█████▋                        | 75/400 [33:12<2:28:11, 27.36s/it]2021-12-17 16:17:55,129 iteration 1276 : loss : 0.122718, loss_ce: 0.038562
2021-12-17 16:17:56,620 iteration 1277 : loss : 0.146494, loss_ce: 0.045693
2021-12-17 16:17:57,996 iteration 1278 : loss : 0.135658, loss_ce: 0.037983
2021-12-17 16:17:59,362 iteration 1279 : loss : 0.142346, loss_ce: 0.045770
2021-12-17 16:18:00,751 iteration 1280 : loss : 0.130482, loss_ce: 0.043687
2021-12-17 16:18:02,086 iteration 1281 : loss : 0.134608, loss_ce: 0.043585
2021-12-17 16:18:03,466 iteration 1282 : loss : 0.116788, loss_ce: 0.037222
2021-12-17 16:18:04,774 iteration 1283 : loss : 0.141258, loss_ce: 0.039437
2021-12-17 16:18:06,134 iteration 1284 : loss : 0.127417, loss_ce: 0.035032
2021-12-17 16:18:07,447 iteration 1285 : loss : 0.116796, loss_ce: 0.033626
2021-12-17 16:18:08,864 iteration 1286 : loss : 0.150884, loss_ce: 0.047873
2021-12-17 16:18:10,280 iteration 1287 : loss : 0.115841, loss_ce: 0.038146
2021-12-17 16:18:11,618 iteration 1288 : loss : 0.119866, loss_ce: 0.035399
2021-12-17 16:18:12,981 iteration 1289 : loss : 0.139152, loss_ce: 0.046524
2021-12-17 16:18:14,304 iteration 1290 : loss : 0.153817, loss_ce: 0.047201
2021-12-17 16:18:15,625 iteration 1291 : loss : 0.132972, loss_ce: 0.037663
2021-12-17 16:18:16,954 iteration 1292 : loss : 0.145358, loss_ce: 0.063035
 19%|█████▋                        | 76/400 [33:36<2:21:05, 26.13s/it]2021-12-17 16:18:18,458 iteration 1293 : loss : 0.132397, loss_ce: 0.046671
2021-12-17 16:18:19,760 iteration 1294 : loss : 0.117967, loss_ce: 0.034814
2021-12-17 16:18:21,176 iteration 1295 : loss : 0.144743, loss_ce: 0.039422
2021-12-17 16:18:22,555 iteration 1296 : loss : 0.145596, loss_ce: 0.039515
2021-12-17 16:18:23,811 iteration 1297 : loss : 0.118840, loss_ce: 0.037137
2021-12-17 16:18:25,242 iteration 1298 : loss : 0.151121, loss_ce: 0.051733
2021-12-17 16:18:26,597 iteration 1299 : loss : 0.116698, loss_ce: 0.035928
2021-12-17 16:18:28,053 iteration 1300 : loss : 0.151825, loss_ce: 0.045664
2021-12-17 16:18:29,508 iteration 1301 : loss : 0.143603, loss_ce: 0.040583
2021-12-17 16:18:30,820 iteration 1302 : loss : 0.135356, loss_ce: 0.037020
2021-12-17 16:18:32,234 iteration 1303 : loss : 0.133114, loss_ce: 0.036378
2021-12-17 16:18:33,616 iteration 1304 : loss : 0.126821, loss_ce: 0.041692
2021-12-17 16:18:35,050 iteration 1305 : loss : 0.137108, loss_ce: 0.041938
2021-12-17 16:18:36,432 iteration 1306 : loss : 0.138070, loss_ce: 0.048900
2021-12-17 16:18:37,762 iteration 1307 : loss : 0.120091, loss_ce: 0.035971
2021-12-17 16:18:39,136 iteration 1308 : loss : 0.132624, loss_ce: 0.048365
2021-12-17 16:18:40,479 iteration 1309 : loss : 0.116451, loss_ce: 0.035023
 19%|█████▊                        | 77/400 [33:59<2:16:27, 25.35s/it]2021-12-17 16:18:41,886 iteration 1310 : loss : 0.130264, loss_ce: 0.041809
2021-12-17 16:18:43,343 iteration 1311 : loss : 0.129619, loss_ce: 0.036907
2021-12-17 16:18:44,700 iteration 1312 : loss : 0.138702, loss_ce: 0.038556
2021-12-17 16:18:46,059 iteration 1313 : loss : 0.124986, loss_ce: 0.038273
2021-12-17 16:18:47,485 iteration 1314 : loss : 0.144151, loss_ce: 0.054156
2021-12-17 16:18:48,920 iteration 1315 : loss : 0.137882, loss_ce: 0.055463
2021-12-17 16:18:50,259 iteration 1316 : loss : 0.116543, loss_ce: 0.036055
2021-12-17 16:18:51,583 iteration 1317 : loss : 0.117737, loss_ce: 0.031739
2021-12-17 16:18:52,905 iteration 1318 : loss : 0.126317, loss_ce: 0.038303
2021-12-17 16:18:54,309 iteration 1319 : loss : 0.130877, loss_ce: 0.038734
2021-12-17 16:18:55,630 iteration 1320 : loss : 0.127313, loss_ce: 0.037482
2021-12-17 16:18:57,010 iteration 1321 : loss : 0.132854, loss_ce: 0.044069
2021-12-17 16:18:58,375 iteration 1322 : loss : 0.125375, loss_ce: 0.037312
2021-12-17 16:18:59,797 iteration 1323 : loss : 0.119021, loss_ce: 0.029679
2021-12-17 16:19:01,227 iteration 1324 : loss : 0.116734, loss_ce: 0.037577
2021-12-17 16:19:02,584 iteration 1325 : loss : 0.124794, loss_ce: 0.037813
2021-12-17 16:19:03,949 iteration 1326 : loss : 0.121535, loss_ce: 0.034372
 20%|█████▊                        | 78/400 [34:23<2:13:00, 24.78s/it]2021-12-17 16:19:05,354 iteration 1327 : loss : 0.105004, loss_ce: 0.026654
2021-12-17 16:19:06,725 iteration 1328 : loss : 0.133241, loss_ce: 0.042696
2021-12-17 16:19:08,089 iteration 1329 : loss : 0.147169, loss_ce: 0.049307
2021-12-17 16:19:09,522 iteration 1330 : loss : 0.117067, loss_ce: 0.028470
2021-12-17 16:19:10,889 iteration 1331 : loss : 0.132532, loss_ce: 0.044213
2021-12-17 16:19:12,238 iteration 1332 : loss : 0.130467, loss_ce: 0.040826
2021-12-17 16:19:13,584 iteration 1333 : loss : 0.121500, loss_ce: 0.037687
2021-12-17 16:19:14,987 iteration 1334 : loss : 0.110417, loss_ce: 0.035555
2021-12-17 16:19:16,388 iteration 1335 : loss : 0.110639, loss_ce: 0.033546
2021-12-17 16:19:17,721 iteration 1336 : loss : 0.119919, loss_ce: 0.043124
2021-12-17 16:19:19,135 iteration 1337 : loss : 0.161654, loss_ce: 0.052553
2021-12-17 16:19:20,487 iteration 1338 : loss : 0.124445, loss_ce: 0.043072
2021-12-17 16:19:21,829 iteration 1339 : loss : 0.129378, loss_ce: 0.040871
2021-12-17 16:19:23,166 iteration 1340 : loss : 0.120191, loss_ce: 0.037415
2021-12-17 16:19:24,558 iteration 1341 : loss : 0.140699, loss_ce: 0.042433
2021-12-17 16:19:25,998 iteration 1342 : loss : 0.139572, loss_ce: 0.041069
2021-12-17 16:19:27,290 iteration 1343 : loss : 0.114308, loss_ce: 0.029555
 20%|█████▉                        | 79/400 [34:46<2:10:16, 24.35s/it]2021-12-17 16:19:28,752 iteration 1344 : loss : 0.127775, loss_ce: 0.035593
2021-12-17 16:19:30,103 iteration 1345 : loss : 0.112455, loss_ce: 0.027381
2021-12-17 16:19:31,513 iteration 1346 : loss : 0.131581, loss_ce: 0.041345
2021-12-17 16:19:32,882 iteration 1347 : loss : 0.118720, loss_ce: 0.039618
2021-12-17 16:19:34,217 iteration 1348 : loss : 0.132834, loss_ce: 0.044646
2021-12-17 16:19:35,582 iteration 1349 : loss : 0.135131, loss_ce: 0.038190
2021-12-17 16:19:36,931 iteration 1350 : loss : 0.124467, loss_ce: 0.027114
2021-12-17 16:19:38,374 iteration 1351 : loss : 0.139439, loss_ce: 0.043380
2021-12-17 16:19:39,702 iteration 1352 : loss : 0.120032, loss_ce: 0.036293
2021-12-17 16:19:41,074 iteration 1353 : loss : 0.135864, loss_ce: 0.045392
2021-12-17 16:19:42,442 iteration 1354 : loss : 0.124958, loss_ce: 0.034590
2021-12-17 16:19:43,749 iteration 1355 : loss : 0.124229, loss_ce: 0.034791
2021-12-17 16:19:45,189 iteration 1356 : loss : 0.140000, loss_ce: 0.042170
2021-12-17 16:19:46,504 iteration 1357 : loss : 0.121102, loss_ce: 0.042793
2021-12-17 16:19:47,851 iteration 1358 : loss : 0.137599, loss_ce: 0.049264
2021-12-17 16:19:49,298 iteration 1359 : loss : 0.148461, loss_ce: 0.065273
2021-12-17 16:19:49,298 Training Data Eval:
2021-12-17 16:19:56,377   Average segmentation loss on training set: 0.1096
2021-12-17 16:19:56,377 Validation Data Eval:
2021-12-17 16:19:58,874   Average segmentation loss on validation set: 0.1694
2021-12-17 16:20:00,268 iteration 1360 : loss : 0.112037, loss_ce: 0.032955
 20%|██████                        | 80/400 [35:19<2:23:40, 26.94s/it]2021-12-17 16:20:01,758 iteration 1361 : loss : 0.132356, loss_ce: 0.034349
2021-12-17 16:20:03,116 iteration 1362 : loss : 0.124804, loss_ce: 0.028634
2021-12-17 16:20:04,517 iteration 1363 : loss : 0.125811, loss_ce: 0.035882
2021-12-17 16:20:05,819 iteration 1364 : loss : 0.125360, loss_ce: 0.047205
2021-12-17 16:20:07,163 iteration 1365 : loss : 0.124989, loss_ce: 0.031173
2021-12-17 16:20:08,611 iteration 1366 : loss : 0.157059, loss_ce: 0.055673
2021-12-17 16:20:09,990 iteration 1367 : loss : 0.126235, loss_ce: 0.048198
2021-12-17 16:20:11,514 iteration 1368 : loss : 0.121358, loss_ce: 0.035744
2021-12-17 16:20:12,880 iteration 1369 : loss : 0.122029, loss_ce: 0.033104
2021-12-17 16:20:14,209 iteration 1370 : loss : 0.128225, loss_ce: 0.044405
2021-12-17 16:20:15,573 iteration 1371 : loss : 0.120804, loss_ce: 0.035190
2021-12-17 16:20:17,069 iteration 1372 : loss : 0.139642, loss_ce: 0.041911
2021-12-17 16:20:18,423 iteration 1373 : loss : 0.122496, loss_ce: 0.042805
2021-12-17 16:20:19,753 iteration 1374 : loss : 0.128057, loss_ce: 0.038940
2021-12-17 16:20:21,103 iteration 1375 : loss : 0.114640, loss_ce: 0.038248
2021-12-17 16:20:22,463 iteration 1376 : loss : 0.116283, loss_ce: 0.028235
2021-12-17 16:20:23,883 iteration 1377 : loss : 0.133681, loss_ce: 0.048327
 20%|██████                        | 81/400 [35:43<2:17:55, 25.94s/it]2021-12-17 16:20:25,391 iteration 1378 : loss : 0.129139, loss_ce: 0.047491
2021-12-17 16:20:26,811 iteration 1379 : loss : 0.130566, loss_ce: 0.041094
2021-12-17 16:20:28,175 iteration 1380 : loss : 0.148493, loss_ce: 0.043630
2021-12-17 16:20:29,585 iteration 1381 : loss : 0.115060, loss_ce: 0.037552
2021-12-17 16:20:30,968 iteration 1382 : loss : 0.139512, loss_ce: 0.048511
2021-12-17 16:20:32,284 iteration 1383 : loss : 0.133818, loss_ce: 0.036020
2021-12-17 16:20:33,687 iteration 1384 : loss : 0.128660, loss_ce: 0.045519
2021-12-17 16:20:35,076 iteration 1385 : loss : 0.116467, loss_ce: 0.037480
2021-12-17 16:20:36,435 iteration 1386 : loss : 0.130774, loss_ce: 0.044259
2021-12-17 16:20:37,904 iteration 1387 : loss : 0.133195, loss_ce: 0.042238
2021-12-17 16:20:39,261 iteration 1388 : loss : 0.120422, loss_ce: 0.033836
2021-12-17 16:20:40,615 iteration 1389 : loss : 0.126945, loss_ce: 0.036606
2021-12-17 16:20:42,012 iteration 1390 : loss : 0.144249, loss_ce: 0.045994
2021-12-17 16:20:43,393 iteration 1391 : loss : 0.120977, loss_ce: 0.028492
2021-12-17 16:20:44,778 iteration 1392 : loss : 0.125358, loss_ce: 0.033632
2021-12-17 16:20:46,127 iteration 1393 : loss : 0.124346, loss_ce: 0.034887
2021-12-17 16:20:47,480 iteration 1394 : loss : 0.116875, loss_ce: 0.039861
 20%|██████▏                       | 82/400 [36:06<2:13:46, 25.24s/it]2021-12-17 16:20:48,899 iteration 1395 : loss : 0.114482, loss_ce: 0.034814
2021-12-17 16:20:50,231 iteration 1396 : loss : 0.120146, loss_ce: 0.037656
2021-12-17 16:20:51,612 iteration 1397 : loss : 0.129893, loss_ce: 0.037527
2021-12-17 16:20:53,060 iteration 1398 : loss : 0.116272, loss_ce: 0.034815
2021-12-17 16:20:54,458 iteration 1399 : loss : 0.149759, loss_ce: 0.062586
2021-12-17 16:20:55,805 iteration 1400 : loss : 0.117762, loss_ce: 0.039688
2021-12-17 16:20:57,155 iteration 1401 : loss : 0.120997, loss_ce: 0.033742
2021-12-17 16:20:58,452 iteration 1402 : loss : 0.119820, loss_ce: 0.035596
2021-12-17 16:20:59,909 iteration 1403 : loss : 0.110285, loss_ce: 0.031906
2021-12-17 16:21:01,315 iteration 1404 : loss : 0.137150, loss_ce: 0.042630
2021-12-17 16:21:02,712 iteration 1405 : loss : 0.130103, loss_ce: 0.044728
2021-12-17 16:21:04,096 iteration 1406 : loss : 0.133302, loss_ce: 0.039916
2021-12-17 16:21:05,415 iteration 1407 : loss : 0.117516, loss_ce: 0.042816
2021-12-17 16:21:06,765 iteration 1408 : loss : 0.129968, loss_ce: 0.036572
2021-12-17 16:21:08,203 iteration 1409 : loss : 0.144348, loss_ce: 0.035803
2021-12-17 16:21:09,602 iteration 1410 : loss : 0.128906, loss_ce: 0.038367
2021-12-17 16:21:10,950 iteration 1411 : loss : 0.113268, loss_ce: 0.033800
 21%|██████▏                       | 83/400 [36:30<2:10:31, 24.70s/it]2021-12-17 16:21:12,285 iteration 1412 : loss : 0.119330, loss_ce: 0.026182
2021-12-17 16:21:13,699 iteration 1413 : loss : 0.131636, loss_ce: 0.041140
2021-12-17 16:21:15,066 iteration 1414 : loss : 0.127779, loss_ce: 0.044259
2021-12-17 16:21:16,378 iteration 1415 : loss : 0.134793, loss_ce: 0.037509
2021-12-17 16:21:17,751 iteration 1416 : loss : 0.115917, loss_ce: 0.028078
2021-12-17 16:21:19,157 iteration 1417 : loss : 0.122846, loss_ce: 0.036272
2021-12-17 16:21:20,470 iteration 1418 : loss : 0.113471, loss_ce: 0.029607
2021-12-17 16:21:21,942 iteration 1419 : loss : 0.133344, loss_ce: 0.033922
2021-12-17 16:21:23,363 iteration 1420 : loss : 0.128162, loss_ce: 0.030637
2021-12-17 16:21:24,697 iteration 1421 : loss : 0.113460, loss_ce: 0.034513
2021-12-17 16:21:26,063 iteration 1422 : loss : 0.137640, loss_ce: 0.043521
2021-12-17 16:21:27,408 iteration 1423 : loss : 0.124146, loss_ce: 0.041539
2021-12-17 16:21:28,822 iteration 1424 : loss : 0.133494, loss_ce: 0.040271
2021-12-17 16:21:30,260 iteration 1425 : loss : 0.129032, loss_ce: 0.040151
2021-12-17 16:21:31,514 iteration 1426 : loss : 0.118590, loss_ce: 0.035067
2021-12-17 16:21:32,853 iteration 1427 : loss : 0.120543, loss_ce: 0.041761
2021-12-17 16:21:34,228 iteration 1428 : loss : 0.132457, loss_ce: 0.040071
 21%|██████▎                       | 84/400 [36:53<2:07:51, 24.28s/it]2021-12-17 16:21:35,735 iteration 1429 : loss : 0.137290, loss_ce: 0.041350
2021-12-17 16:21:37,063 iteration 1430 : loss : 0.134670, loss_ce: 0.039774
2021-12-17 16:21:38,418 iteration 1431 : loss : 0.108997, loss_ce: 0.035347
2021-12-17 16:21:39,790 iteration 1432 : loss : 0.119622, loss_ce: 0.039169
2021-12-17 16:21:41,238 iteration 1433 : loss : 0.139469, loss_ce: 0.044953
2021-12-17 16:21:42,645 iteration 1434 : loss : 0.117660, loss_ce: 0.037610
2021-12-17 16:21:43,929 iteration 1435 : loss : 0.109173, loss_ce: 0.027140
2021-12-17 16:21:45,363 iteration 1436 : loss : 0.142343, loss_ce: 0.055691
2021-12-17 16:21:46,674 iteration 1437 : loss : 0.139204, loss_ce: 0.032510
2021-12-17 16:21:47,973 iteration 1438 : loss : 0.111129, loss_ce: 0.036058
2021-12-17 16:21:49,340 iteration 1439 : loss : 0.106379, loss_ce: 0.026825
2021-12-17 16:21:50,775 iteration 1440 : loss : 0.130691, loss_ce: 0.047366
2021-12-17 16:21:52,112 iteration 1441 : loss : 0.112318, loss_ce: 0.032017
2021-12-17 16:21:53,437 iteration 1442 : loss : 0.125790, loss_ce: 0.039645
2021-12-17 16:21:54,829 iteration 1443 : loss : 0.126689, loss_ce: 0.038947
2021-12-17 16:21:56,250 iteration 1444 : loss : 0.109847, loss_ce: 0.033296
2021-12-17 16:21:56,250 Training Data Eval:
2021-12-17 16:22:03,322   Average segmentation loss on training set: 0.1006
2021-12-17 16:22:03,323 Validation Data Eval:
2021-12-17 16:22:05,804   Average segmentation loss on validation set: 0.1642
2021-12-17 16:22:11,365 Found new lowest validation loss at iteration 1444! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/TU_3seeds/TU_RESNET_no_pretraining_SGD_best_val_loss_seed100.pth
2021-12-17 16:22:12,791 iteration 1445 : loss : 0.120671, loss_ce: 0.035226
 21%|██████▍                       | 85/400 [37:31<2:29:57, 28.57s/it]2021-12-17 16:22:14,218 iteration 1446 : loss : 0.106330, loss_ce: 0.026399
2021-12-17 16:22:15,579 iteration 1447 : loss : 0.153125, loss_ce: 0.045926
2021-12-17 16:22:16,882 iteration 1448 : loss : 0.130753, loss_ce: 0.051379
2021-12-17 16:22:18,209 iteration 1449 : loss : 0.120751, loss_ce: 0.036818
2021-12-17 16:22:19,443 iteration 1450 : loss : 0.141542, loss_ce: 0.052672
2021-12-17 16:22:20,709 iteration 1451 : loss : 0.111055, loss_ce: 0.027276
2021-12-17 16:22:22,032 iteration 1452 : loss : 0.144755, loss_ce: 0.027747
2021-12-17 16:22:23,404 iteration 1453 : loss : 0.115276, loss_ce: 0.030922
2021-12-17 16:22:24,684 iteration 1454 : loss : 0.107311, loss_ce: 0.034944
2021-12-17 16:22:25,976 iteration 1455 : loss : 0.107138, loss_ce: 0.030516
2021-12-17 16:22:27,301 iteration 1456 : loss : 0.127184, loss_ce: 0.039001
2021-12-17 16:22:28,631 iteration 1457 : loss : 0.125797, loss_ce: 0.041345
2021-12-17 16:22:29,943 iteration 1458 : loss : 0.115717, loss_ce: 0.030206
2021-12-17 16:22:31,170 iteration 1459 : loss : 0.106606, loss_ce: 0.032305
2021-12-17 16:22:32,534 iteration 1460 : loss : 0.160182, loss_ce: 0.066383
2021-12-17 16:22:33,845 iteration 1461 : loss : 0.115300, loss_ce: 0.028798
2021-12-17 16:22:35,165 iteration 1462 : loss : 0.124073, loss_ce: 0.036085
 22%|██████▍                       | 86/400 [37:54<2:19:45, 26.71s/it]2021-12-17 16:22:36,563 iteration 1463 : loss : 0.121566, loss_ce: 0.038770
2021-12-17 16:22:37,988 iteration 1464 : loss : 0.111539, loss_ce: 0.026056
2021-12-17 16:22:39,437 iteration 1465 : loss : 0.140087, loss_ce: 0.051281
2021-12-17 16:22:40,829 iteration 1466 : loss : 0.115590, loss_ce: 0.031510
2021-12-17 16:22:42,213 iteration 1467 : loss : 0.124351, loss_ce: 0.039283
2021-12-17 16:22:43,604 iteration 1468 : loss : 0.133132, loss_ce: 0.037345
2021-12-17 16:22:44,995 iteration 1469 : loss : 0.121278, loss_ce: 0.034784
2021-12-17 16:22:46,370 iteration 1470 : loss : 0.114968, loss_ce: 0.035556
2021-12-17 16:22:47,678 iteration 1471 : loss : 0.132834, loss_ce: 0.035255
2021-12-17 16:22:49,032 iteration 1472 : loss : 0.123355, loss_ce: 0.037661
2021-12-17 16:22:50,455 iteration 1473 : loss : 0.116672, loss_ce: 0.040390
2021-12-17 16:22:51,783 iteration 1474 : loss : 0.135650, loss_ce: 0.044696
2021-12-17 16:22:53,151 iteration 1475 : loss : 0.107442, loss_ce: 0.030007
2021-12-17 16:22:54,571 iteration 1476 : loss : 0.122831, loss_ce: 0.047632
2021-12-17 16:22:55,944 iteration 1477 : loss : 0.142019, loss_ce: 0.038356
2021-12-17 16:22:57,372 iteration 1478 : loss : 0.118090, loss_ce: 0.031461
2021-12-17 16:22:58,765 iteration 1479 : loss : 0.127292, loss_ce: 0.037140
 22%|██████▌                       | 87/400 [38:17<2:14:27, 25.78s/it]2021-12-17 16:23:00,190 iteration 1480 : loss : 0.119275, loss_ce: 0.047740
2021-12-17 16:23:01,627 iteration 1481 : loss : 0.129304, loss_ce: 0.040612
2021-12-17 16:23:02,974 iteration 1482 : loss : 0.114217, loss_ce: 0.039807
2021-12-17 16:23:04,293 iteration 1483 : loss : 0.110891, loss_ce: 0.033339
2021-12-17 16:23:05,620 iteration 1484 : loss : 0.120772, loss_ce: 0.040689
2021-12-17 16:23:06,962 iteration 1485 : loss : 0.113320, loss_ce: 0.032704
2021-12-17 16:23:08,317 iteration 1486 : loss : 0.119869, loss_ce: 0.031703
2021-12-17 16:23:09,755 iteration 1487 : loss : 0.124182, loss_ce: 0.037646
2021-12-17 16:23:11,113 iteration 1488 : loss : 0.109568, loss_ce: 0.030470
2021-12-17 16:23:12,507 iteration 1489 : loss : 0.109703, loss_ce: 0.029580
2021-12-17 16:23:13,869 iteration 1490 : loss : 0.118962, loss_ce: 0.038444
2021-12-17 16:23:15,190 iteration 1491 : loss : 0.107058, loss_ce: 0.026675
2021-12-17 16:23:16,592 iteration 1492 : loss : 0.108689, loss_ce: 0.030338
2021-12-17 16:23:18,053 iteration 1493 : loss : 0.122850, loss_ce: 0.039684
2021-12-17 16:23:19,455 iteration 1494 : loss : 0.131492, loss_ce: 0.038006
2021-12-17 16:23:20,821 iteration 1495 : loss : 0.119240, loss_ce: 0.034622
2021-12-17 16:23:22,195 iteration 1496 : loss : 0.113400, loss_ce: 0.033220
 22%|██████▌                       | 88/400 [38:41<2:10:22, 25.07s/it]2021-12-17 16:23:23,590 iteration 1497 : loss : 0.108043, loss_ce: 0.032760
2021-12-17 16:23:24,874 iteration 1498 : loss : 0.103427, loss_ce: 0.029106
2021-12-17 16:23:26,191 iteration 1499 : loss : 0.107289, loss_ce: 0.035300
2021-12-17 16:23:27,671 iteration 1500 : loss : 0.139378, loss_ce: 0.037951
2021-12-17 16:23:28,954 iteration 1501 : loss : 0.106280, loss_ce: 0.026785
2021-12-17 16:23:30,322 iteration 1502 : loss : 0.151044, loss_ce: 0.042706
2021-12-17 16:23:31,753 iteration 1503 : loss : 0.114742, loss_ce: 0.030979
2021-12-17 16:23:33,091 iteration 1504 : loss : 0.135901, loss_ce: 0.051641
2021-12-17 16:23:34,424 iteration 1505 : loss : 0.109811, loss_ce: 0.033434
2021-12-17 16:23:35,840 iteration 1506 : loss : 0.106841, loss_ce: 0.028743
2021-12-17 16:23:37,177 iteration 1507 : loss : 0.099213, loss_ce: 0.029510
2021-12-17 16:23:38,559 iteration 1508 : loss : 0.153753, loss_ce: 0.034212
2021-12-17 16:23:39,918 iteration 1509 : loss : 0.118579, loss_ce: 0.038564
2021-12-17 16:23:41,257 iteration 1510 : loss : 0.126820, loss_ce: 0.033861
2021-12-17 16:23:42,710 iteration 1511 : loss : 0.120332, loss_ce: 0.044264
2021-12-17 16:23:44,093 iteration 1512 : loss : 0.120858, loss_ce: 0.033488
2021-12-17 16:23:45,478 iteration 1513 : loss : 0.108785, loss_ce: 0.033079
 22%|██████▋                       | 89/400 [39:04<2:07:09, 24.53s/it]2021-12-17 16:23:46,911 iteration 1514 : loss : 0.120633, loss_ce: 0.035342
2021-12-17 16:23:48,271 iteration 1515 : loss : 0.112095, loss_ce: 0.035678
2021-12-17 16:23:49,659 iteration 1516 : loss : 0.123111, loss_ce: 0.042458
2021-12-17 16:23:50,996 iteration 1517 : loss : 0.125557, loss_ce: 0.044450
2021-12-17 16:23:52,310 iteration 1518 : loss : 0.111482, loss_ce: 0.036096
2021-12-17 16:23:53,673 iteration 1519 : loss : 0.111451, loss_ce: 0.032094
2021-12-17 16:23:55,166 iteration 1520 : loss : 0.177847, loss_ce: 0.069631
2021-12-17 16:23:56,491 iteration 1521 : loss : 0.108540, loss_ce: 0.028234
2021-12-17 16:23:57,911 iteration 1522 : loss : 0.135645, loss_ce: 0.037928
2021-12-17 16:23:59,280 iteration 1523 : loss : 0.120690, loss_ce: 0.037993
2021-12-17 16:24:00,604 iteration 1524 : loss : 0.108379, loss_ce: 0.031464
2021-12-17 16:24:01,963 iteration 1525 : loss : 0.109603, loss_ce: 0.033340
2021-12-17 16:24:03,322 iteration 1526 : loss : 0.141267, loss_ce: 0.041065
2021-12-17 16:24:04,758 iteration 1527 : loss : 0.115977, loss_ce: 0.035600
2021-12-17 16:24:06,157 iteration 1528 : loss : 0.118943, loss_ce: 0.036334
2021-12-17 16:24:07,509 iteration 1529 : loss : 0.119385, loss_ce: 0.027604
2021-12-17 16:24:07,509 Training Data Eval:
2021-12-17 16:24:14,672   Average segmentation loss on training set: 0.1064
2021-12-17 16:24:14,672 Validation Data Eval:
2021-12-17 16:24:17,157   Average segmentation loss on validation set: 0.1647
2021-12-17 16:24:18,500 iteration 1530 : loss : 0.119078, loss_ce: 0.045016
 22%|██████▊                       | 90/400 [39:37<2:19:56, 27.08s/it]2021-12-17 16:24:19,960 iteration 1531 : loss : 0.119345, loss_ce: 0.040585
2021-12-17 16:24:21,369 iteration 1532 : loss : 0.147680, loss_ce: 0.043716
2021-12-17 16:24:22,713 iteration 1533 : loss : 0.109592, loss_ce: 0.028490
2021-12-17 16:24:24,069 iteration 1534 : loss : 0.109956, loss_ce: 0.037496
2021-12-17 16:24:25,403 iteration 1535 : loss : 0.108915, loss_ce: 0.033128
2021-12-17 16:24:26,796 iteration 1536 : loss : 0.120203, loss_ce: 0.031248
2021-12-17 16:24:28,140 iteration 1537 : loss : 0.124333, loss_ce: 0.044564
2021-12-17 16:24:29,409 iteration 1538 : loss : 0.111083, loss_ce: 0.021376
2021-12-17 16:24:30,733 iteration 1539 : loss : 0.118827, loss_ce: 0.038563
2021-12-17 16:24:32,110 iteration 1540 : loss : 0.128909, loss_ce: 0.046188
2021-12-17 16:24:33,516 iteration 1541 : loss : 0.131212, loss_ce: 0.039485
2021-12-17 16:24:34,971 iteration 1542 : loss : 0.132519, loss_ce: 0.041238
2021-12-17 16:24:36,333 iteration 1543 : loss : 0.112106, loss_ce: 0.023155
2021-12-17 16:24:37,713 iteration 1544 : loss : 0.111834, loss_ce: 0.034865
2021-12-17 16:24:39,013 iteration 1545 : loss : 0.114701, loss_ce: 0.036439
2021-12-17 16:24:40,361 iteration 1546 : loss : 0.113462, loss_ce: 0.026579
2021-12-17 16:24:41,743 iteration 1547 : loss : 0.114617, loss_ce: 0.040073
 23%|██████▊                       | 91/400 [40:00<2:13:32, 25.93s/it]2021-12-17 16:24:43,147 iteration 1548 : loss : 0.122998, loss_ce: 0.032007
2021-12-17 16:24:44,459 iteration 1549 : loss : 0.133127, loss_ce: 0.034998
2021-12-17 16:24:45,867 iteration 1550 : loss : 0.108059, loss_ce: 0.026740
2021-12-17 16:24:47,245 iteration 1551 : loss : 0.140250, loss_ce: 0.041509
2021-12-17 16:24:48,598 iteration 1552 : loss : 0.110239, loss_ce: 0.023881
2021-12-17 16:24:50,013 iteration 1553 : loss : 0.124302, loss_ce: 0.042338
2021-12-17 16:24:51,302 iteration 1554 : loss : 0.119154, loss_ce: 0.045600
2021-12-17 16:24:52,638 iteration 1555 : loss : 0.112532, loss_ce: 0.031953
2021-12-17 16:24:54,099 iteration 1556 : loss : 0.138151, loss_ce: 0.043630
2021-12-17 16:24:55,450 iteration 1557 : loss : 0.112786, loss_ce: 0.028729
2021-12-17 16:24:56,758 iteration 1558 : loss : 0.105629, loss_ce: 0.028075
2021-12-17 16:24:58,191 iteration 1559 : loss : 0.139130, loss_ce: 0.043337
2021-12-17 16:24:59,523 iteration 1560 : loss : 0.121432, loss_ce: 0.049125
2021-12-17 16:25:00,892 iteration 1561 : loss : 0.117332, loss_ce: 0.039116
2021-12-17 16:25:02,253 iteration 1562 : loss : 0.122513, loss_ce: 0.045301
2021-12-17 16:25:03,639 iteration 1563 : loss : 0.128069, loss_ce: 0.039049
2021-12-17 16:25:04,980 iteration 1564 : loss : 0.116760, loss_ce: 0.033774
 23%|██████▉                       | 92/400 [40:24<2:08:58, 25.12s/it]2021-12-17 16:25:06,367 iteration 1565 : loss : 0.112963, loss_ce: 0.039875
2021-12-17 16:25:07,763 iteration 1566 : loss : 0.115202, loss_ce: 0.029191
2021-12-17 16:25:09,130 iteration 1567 : loss : 0.119784, loss_ce: 0.037897
2021-12-17 16:25:10,582 iteration 1568 : loss : 0.107550, loss_ce: 0.028412
2021-12-17 16:25:11,946 iteration 1569 : loss : 0.127937, loss_ce: 0.045097
2021-12-17 16:25:13,323 iteration 1570 : loss : 0.109857, loss_ce: 0.027941
2021-12-17 16:25:14,686 iteration 1571 : loss : 0.146131, loss_ce: 0.039584
2021-12-17 16:25:16,129 iteration 1572 : loss : 0.131894, loss_ce: 0.041104
2021-12-17 16:25:17,416 iteration 1573 : loss : 0.097870, loss_ce: 0.033800
2021-12-17 16:25:18,808 iteration 1574 : loss : 0.133018, loss_ce: 0.047700
2021-12-17 16:25:20,244 iteration 1575 : loss : 0.123426, loss_ce: 0.044035
2021-12-17 16:25:21,674 iteration 1576 : loss : 0.109323, loss_ce: 0.032934
2021-12-17 16:25:22,970 iteration 1577 : loss : 0.107814, loss_ce: 0.029906
2021-12-17 16:25:24,316 iteration 1578 : loss : 0.109348, loss_ce: 0.028973
2021-12-17 16:25:25,725 iteration 1579 : loss : 0.137002, loss_ce: 0.036726
2021-12-17 16:25:27,112 iteration 1580 : loss : 0.116352, loss_ce: 0.032396
2021-12-17 16:25:28,587 iteration 1581 : loss : 0.129558, loss_ce: 0.040997
 23%|██████▉                       | 93/400 [40:47<2:06:13, 24.67s/it]2021-12-17 16:25:30,029 iteration 1582 : loss : 0.113475, loss_ce: 0.036244
2021-12-17 16:25:31,414 iteration 1583 : loss : 0.117640, loss_ce: 0.032404
2021-12-17 16:25:32,709 iteration 1584 : loss : 0.108001, loss_ce: 0.028467
2021-12-17 16:25:34,080 iteration 1585 : loss : 0.160164, loss_ce: 0.032026
2021-12-17 16:25:35,507 iteration 1586 : loss : 0.122172, loss_ce: 0.028418
2021-12-17 16:25:36,880 iteration 1587 : loss : 0.105948, loss_ce: 0.025208
2021-12-17 16:25:38,303 iteration 1588 : loss : 0.129628, loss_ce: 0.046455
2021-12-17 16:25:39,668 iteration 1589 : loss : 0.114402, loss_ce: 0.024962
2021-12-17 16:25:41,058 iteration 1590 : loss : 0.112654, loss_ce: 0.038970
2021-12-17 16:25:42,392 iteration 1591 : loss : 0.137794, loss_ce: 0.056563
2021-12-17 16:25:43,721 iteration 1592 : loss : 0.118605, loss_ce: 0.041807
2021-12-17 16:25:45,140 iteration 1593 : loss : 0.118760, loss_ce: 0.026142
2021-12-17 16:25:46,524 iteration 1594 : loss : 0.118853, loss_ce: 0.048751
2021-12-17 16:25:47,913 iteration 1595 : loss : 0.135522, loss_ce: 0.047967
2021-12-17 16:25:49,276 iteration 1596 : loss : 0.116817, loss_ce: 0.037360
2021-12-17 16:25:50,610 iteration 1597 : loss : 0.105576, loss_ce: 0.029294
2021-12-17 16:25:52,029 iteration 1598 : loss : 0.119841, loss_ce: 0.041193
 24%|███████                       | 94/400 [41:11<2:03:55, 24.30s/it]2021-12-17 16:25:53,487 iteration 1599 : loss : 0.108786, loss_ce: 0.033291
2021-12-17 16:25:54,816 iteration 1600 : loss : 0.120103, loss_ce: 0.033447
2021-12-17 16:25:56,185 iteration 1601 : loss : 0.127420, loss_ce: 0.037182
2021-12-17 16:25:57,537 iteration 1602 : loss : 0.111039, loss_ce: 0.036244
2021-12-17 16:25:58,983 iteration 1603 : loss : 0.130365, loss_ce: 0.039205
2021-12-17 16:26:00,325 iteration 1604 : loss : 0.120961, loss_ce: 0.038799
2021-12-17 16:26:01,753 iteration 1605 : loss : 0.122945, loss_ce: 0.037830
2021-12-17 16:26:03,157 iteration 1606 : loss : 0.121996, loss_ce: 0.032348
2021-12-17 16:26:04,523 iteration 1607 : loss : 0.104397, loss_ce: 0.030236
2021-12-17 16:26:05,905 iteration 1608 : loss : 0.103269, loss_ce: 0.027054
2021-12-17 16:26:07,290 iteration 1609 : loss : 0.106099, loss_ce: 0.030959
2021-12-17 16:26:08,649 iteration 1610 : loss : 0.104468, loss_ce: 0.034420
2021-12-17 16:26:10,035 iteration 1611 : loss : 0.143299, loss_ce: 0.044767
2021-12-17 16:26:11,396 iteration 1612 : loss : 0.112887, loss_ce: 0.036577
2021-12-17 16:26:12,779 iteration 1613 : loss : 0.122581, loss_ce: 0.037925
2021-12-17 16:26:14,162 iteration 1614 : loss : 0.112213, loss_ce: 0.028831
2021-12-17 16:26:14,162 Training Data Eval:
2021-12-17 16:26:21,285   Average segmentation loss on training set: 0.0954
2021-12-17 16:26:21,285 Validation Data Eval:
2021-12-17 16:26:23,777   Average segmentation loss on validation set: 0.1667
2021-12-17 16:26:25,192 iteration 1615 : loss : 0.117813, loss_ce: 0.038088
 24%|███████▏                      | 95/400 [41:44<2:17:02, 26.96s/it]2021-12-17 16:26:26,584 iteration 1616 : loss : 0.115455, loss_ce: 0.028302
2021-12-17 16:26:27,905 iteration 1617 : loss : 0.096364, loss_ce: 0.027799
2021-12-17 16:26:29,278 iteration 1618 : loss : 0.099151, loss_ce: 0.026551
2021-12-17 16:26:30,695 iteration 1619 : loss : 0.110036, loss_ce: 0.040890
2021-12-17 16:26:32,012 iteration 1620 : loss : 0.111946, loss_ce: 0.030386
2021-12-17 16:26:33,416 iteration 1621 : loss : 0.111179, loss_ce: 0.036337
2021-12-17 16:26:34,771 iteration 1622 : loss : 0.116254, loss_ce: 0.033344
2021-12-17 16:26:36,087 iteration 1623 : loss : 0.103492, loss_ce: 0.035006
2021-12-17 16:26:37,457 iteration 1624 : loss : 0.118743, loss_ce: 0.035705
2021-12-17 16:26:38,756 iteration 1625 : loss : 0.106215, loss_ce: 0.035224
2021-12-17 16:26:40,100 iteration 1626 : loss : 0.103286, loss_ce: 0.030223
2021-12-17 16:26:41,420 iteration 1627 : loss : 0.102403, loss_ce: 0.023860
2021-12-17 16:26:42,801 iteration 1628 : loss : 0.118356, loss_ce: 0.029518
2021-12-17 16:26:44,170 iteration 1629 : loss : 0.120795, loss_ce: 0.040175
2021-12-17 16:26:45,468 iteration 1630 : loss : 0.106122, loss_ce: 0.030070
2021-12-17 16:26:46,827 iteration 1631 : loss : 0.106557, loss_ce: 0.034911
2021-12-17 16:26:48,102 iteration 1632 : loss : 0.094463, loss_ce: 0.027063
 24%|███████▏                      | 96/400 [42:07<2:10:26, 25.75s/it]2021-12-17 16:26:49,586 iteration 1633 : loss : 0.119183, loss_ce: 0.033446
2021-12-17 16:26:50,971 iteration 1634 : loss : 0.116197, loss_ce: 0.038828
2021-12-17 16:26:52,310 iteration 1635 : loss : 0.125440, loss_ce: 0.048469
2021-12-17 16:26:53,589 iteration 1636 : loss : 0.094167, loss_ce: 0.024862
2021-12-17 16:26:55,007 iteration 1637 : loss : 0.126693, loss_ce: 0.038592
2021-12-17 16:26:56,385 iteration 1638 : loss : 0.102642, loss_ce: 0.026123
2021-12-17 16:26:57,803 iteration 1639 : loss : 0.109445, loss_ce: 0.032056
2021-12-17 16:26:59,198 iteration 1640 : loss : 0.117580, loss_ce: 0.034091
2021-12-17 16:27:00,576 iteration 1641 : loss : 0.117735, loss_ce: 0.034534
2021-12-17 16:27:02,032 iteration 1642 : loss : 0.148673, loss_ce: 0.040997
2021-12-17 16:27:03,416 iteration 1643 : loss : 0.114632, loss_ce: 0.038907
2021-12-17 16:27:04,798 iteration 1644 : loss : 0.122607, loss_ce: 0.040922
2021-12-17 16:27:06,082 iteration 1645 : loss : 0.116508, loss_ce: 0.029087
2021-12-17 16:27:07,438 iteration 1646 : loss : 0.108278, loss_ce: 0.034017
2021-12-17 16:27:08,876 iteration 1647 : loss : 0.127202, loss_ce: 0.053142
2021-12-17 16:27:10,217 iteration 1648 : loss : 0.107563, loss_ce: 0.036131
2021-12-17 16:27:11,654 iteration 1649 : loss : 0.109018, loss_ce: 0.023879
 24%|███████▎                      | 97/400 [42:30<2:06:40, 25.09s/it]2021-12-17 16:27:13,073 iteration 1650 : loss : 0.105186, loss_ce: 0.026959
2021-12-17 16:27:14,493 iteration 1651 : loss : 0.144619, loss_ce: 0.055156
2021-12-17 16:27:15,914 iteration 1652 : loss : 0.129120, loss_ce: 0.037621
2021-12-17 16:27:17,311 iteration 1653 : loss : 0.135647, loss_ce: 0.051823
2021-12-17 16:27:18,669 iteration 1654 : loss : 0.100390, loss_ce: 0.026325
2021-12-17 16:27:20,015 iteration 1655 : loss : 0.117593, loss_ce: 0.028048
2021-12-17 16:27:21,364 iteration 1656 : loss : 0.099216, loss_ce: 0.032079
2021-12-17 16:27:22,803 iteration 1657 : loss : 0.117880, loss_ce: 0.039060
2021-12-17 16:27:24,131 iteration 1658 : loss : 0.098246, loss_ce: 0.030604
2021-12-17 16:27:25,493 iteration 1659 : loss : 0.117941, loss_ce: 0.038749
2021-12-17 16:27:26,976 iteration 1660 : loss : 0.160793, loss_ce: 0.068398
2021-12-17 16:27:28,351 iteration 1661 : loss : 0.112964, loss_ce: 0.031982
2021-12-17 16:27:29,692 iteration 1662 : loss : 0.128558, loss_ce: 0.034568
2021-12-17 16:27:31,106 iteration 1663 : loss : 0.118549, loss_ce: 0.034321
2021-12-17 16:27:32,518 iteration 1664 : loss : 0.119985, loss_ce: 0.029939
2021-12-17 16:27:33,841 iteration 1665 : loss : 0.098430, loss_ce: 0.030053
2021-12-17 16:27:35,160 iteration 1666 : loss : 0.106698, loss_ce: 0.030592
 24%|███████▎                      | 98/400 [42:54<2:03:52, 24.61s/it]2021-12-17 16:27:36,564 iteration 1667 : loss : 0.099012, loss_ce: 0.032044
2021-12-17 16:27:37,986 iteration 1668 : loss : 0.115131, loss_ce: 0.039088
2021-12-17 16:27:39,357 iteration 1669 : loss : 0.107476, loss_ce: 0.033828
2021-12-17 16:27:40,724 iteration 1670 : loss : 0.127046, loss_ce: 0.033727
2021-12-17 16:27:42,111 iteration 1671 : loss : 0.107403, loss_ce: 0.032639
2021-12-17 16:27:43,458 iteration 1672 : loss : 0.105446, loss_ce: 0.029835
2021-12-17 16:27:44,784 iteration 1673 : loss : 0.095429, loss_ce: 0.026717
2021-12-17 16:27:46,205 iteration 1674 : loss : 0.122651, loss_ce: 0.039911
2021-12-17 16:27:47,557 iteration 1675 : loss : 0.103806, loss_ce: 0.031785
2021-12-17 16:27:48,967 iteration 1676 : loss : 0.106658, loss_ce: 0.034663
2021-12-17 16:27:50,384 iteration 1677 : loss : 0.122615, loss_ce: 0.042473
2021-12-17 16:27:51,773 iteration 1678 : loss : 0.110365, loss_ce: 0.024631
2021-12-17 16:27:53,178 iteration 1679 : loss : 0.106361, loss_ce: 0.025248
2021-12-17 16:27:54,571 iteration 1680 : loss : 0.110950, loss_ce: 0.037944
2021-12-17 16:27:55,943 iteration 1681 : loss : 0.124218, loss_ce: 0.027987
2021-12-17 16:27:57,279 iteration 1682 : loss : 0.114348, loss_ce: 0.041308
2021-12-17 16:27:58,679 iteration 1683 : loss : 0.120155, loss_ce: 0.041043
 25%|███████▍                      | 99/400 [43:17<2:01:49, 24.28s/it]2021-12-17 16:28:00,096 iteration 1684 : loss : 0.098617, loss_ce: 0.025649
2021-12-17 16:28:01,412 iteration 1685 : loss : 0.107349, loss_ce: 0.030415
2021-12-17 16:28:02,821 iteration 1686 : loss : 0.109889, loss_ce: 0.032985
2021-12-17 16:28:04,143 iteration 1687 : loss : 0.102602, loss_ce: 0.023998
2021-12-17 16:28:05,530 iteration 1688 : loss : 0.106806, loss_ce: 0.030927
2021-12-17 16:28:06,920 iteration 1689 : loss : 0.118534, loss_ce: 0.041530
2021-12-17 16:28:08,224 iteration 1690 : loss : 0.102675, loss_ce: 0.026122
2021-12-17 16:28:09,534 iteration 1691 : loss : 0.121953, loss_ce: 0.032079
2021-12-17 16:28:10,915 iteration 1692 : loss : 0.099679, loss_ce: 0.028614
2021-12-17 16:28:12,337 iteration 1693 : loss : 0.109674, loss_ce: 0.032606
2021-12-17 16:28:13,737 iteration 1694 : loss : 0.119342, loss_ce: 0.029345
2021-12-17 16:28:15,071 iteration 1695 : loss : 0.106444, loss_ce: 0.024315
2021-12-17 16:28:16,445 iteration 1696 : loss : 0.131315, loss_ce: 0.047421
2021-12-17 16:28:17,850 iteration 1697 : loss : 0.127823, loss_ce: 0.045553
2021-12-17 16:28:19,243 iteration 1698 : loss : 0.102315, loss_ce: 0.032494
2021-12-17 16:28:20,587 iteration 1699 : loss : 0.106921, loss_ce: 0.036981
2021-12-17 16:28:20,587 Training Data Eval:
2021-12-17 16:28:27,706   Average segmentation loss on training set: 0.0913
2021-12-17 16:28:27,707 Validation Data Eval:
2021-12-17 16:28:30,146   Average segmentation loss on validation set: 0.1567
2021-12-17 16:28:36,358 Found new lowest validation loss at iteration 1699! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/TU_3seeds/TU_RESNET_no_pretraining_SGD_best_val_loss_seed100.pth
2021-12-17 16:28:37,766 iteration 1700 : loss : 0.105465, loss_ce: 0.033004
 25%|███████▎                     | 100/400 [43:56<2:23:37, 28.73s/it]2021-12-17 16:28:39,127 iteration 1701 : loss : 0.099956, loss_ce: 0.030713
2021-12-17 16:28:40,442 iteration 1702 : loss : 0.104183, loss_ce: 0.030270
2021-12-17 16:28:41,817 iteration 1703 : loss : 0.136453, loss_ce: 0.053037
2021-12-17 16:28:43,131 iteration 1704 : loss : 0.107188, loss_ce: 0.036232
2021-12-17 16:28:44,481 iteration 1705 : loss : 0.107920, loss_ce: 0.033224
2021-12-17 16:28:45,870 iteration 1706 : loss : 0.127334, loss_ce: 0.043723
2021-12-17 16:28:47,172 iteration 1707 : loss : 0.120409, loss_ce: 0.042633
2021-12-17 16:28:48,493 iteration 1708 : loss : 0.137286, loss_ce: 0.036118
2021-12-17 16:28:49,801 iteration 1709 : loss : 0.105731, loss_ce: 0.035598
2021-12-17 16:28:51,161 iteration 1710 : loss : 0.109013, loss_ce: 0.028115
2021-12-17 16:28:52,481 iteration 1711 : loss : 0.096877, loss_ce: 0.027951
2021-12-17 16:28:53,741 iteration 1712 : loss : 0.102444, loss_ce: 0.032412
2021-12-17 16:28:55,083 iteration 1713 : loss : 0.121403, loss_ce: 0.031025
2021-12-17 16:28:56,478 iteration 1714 : loss : 0.125785, loss_ce: 0.030454
2021-12-17 16:28:57,856 iteration 1715 : loss : 0.119968, loss_ce: 0.043376
2021-12-17 16:28:59,114 iteration 1716 : loss : 0.111506, loss_ce: 0.029191
2021-12-17 16:29:00,494 iteration 1717 : loss : 0.130064, loss_ce: 0.030520
 25%|███████▎                     | 101/400 [44:19<2:14:10, 26.93s/it]2021-12-17 16:29:01,918 iteration 1718 : loss : 0.121310, loss_ce: 0.043636
2021-12-17 16:29:03,276 iteration 1719 : loss : 0.116507, loss_ce: 0.026297
2021-12-17 16:29:04,682 iteration 1720 : loss : 0.112985, loss_ce: 0.028675
2021-12-17 16:29:06,032 iteration 1721 : loss : 0.098047, loss_ce: 0.026540
2021-12-17 16:29:07,446 iteration 1722 : loss : 0.118960, loss_ce: 0.031633
2021-12-17 16:29:08,783 iteration 1723 : loss : 0.142896, loss_ce: 0.038018
2021-12-17 16:29:10,185 iteration 1724 : loss : 0.095092, loss_ce: 0.027693
2021-12-17 16:29:11,577 iteration 1725 : loss : 0.110838, loss_ce: 0.027902
2021-12-17 16:29:12,967 iteration 1726 : loss : 0.116844, loss_ce: 0.038600
2021-12-17 16:29:14,409 iteration 1727 : loss : 0.113079, loss_ce: 0.039068
2021-12-17 16:29:15,713 iteration 1728 : loss : 0.100006, loss_ce: 0.027430
2021-12-17 16:29:17,115 iteration 1729 : loss : 0.109356, loss_ce: 0.031991
2021-12-17 16:29:18,543 iteration 1730 : loss : 0.105352, loss_ce: 0.035815
2021-12-17 16:29:19,919 iteration 1731 : loss : 0.108094, loss_ce: 0.040858
2021-12-17 16:29:21,272 iteration 1732 : loss : 0.096519, loss_ce: 0.028138
2021-12-17 16:29:22,607 iteration 1733 : loss : 0.114220, loss_ce: 0.038724
2021-12-17 16:29:23,964 iteration 1734 : loss : 0.103220, loss_ce: 0.029715
 26%|███████▍                     | 102/400 [44:43<2:08:34, 25.89s/it]2021-12-17 16:29:25,505 iteration 1735 : loss : 0.098863, loss_ce: 0.028690
2021-12-17 16:29:26,855 iteration 1736 : loss : 0.115532, loss_ce: 0.034837
2021-12-17 16:29:28,329 iteration 1737 : loss : 0.133565, loss_ce: 0.045774
2021-12-17 16:29:29,686 iteration 1738 : loss : 0.113181, loss_ce: 0.042794
2021-12-17 16:29:31,012 iteration 1739 : loss : 0.104000, loss_ce: 0.031020
2021-12-17 16:29:32,439 iteration 1740 : loss : 0.103862, loss_ce: 0.034807
2021-12-17 16:29:33,842 iteration 1741 : loss : 0.092070, loss_ce: 0.024673
2021-12-17 16:29:35,248 iteration 1742 : loss : 0.105736, loss_ce: 0.030816
2021-12-17 16:29:36,568 iteration 1743 : loss : 0.109149, loss_ce: 0.028240
2021-12-17 16:29:38,019 iteration 1744 : loss : 0.142732, loss_ce: 0.046215
2021-12-17 16:29:39,439 iteration 1745 : loss : 0.109055, loss_ce: 0.031501
2021-12-17 16:29:40,827 iteration 1746 : loss : 0.120109, loss_ce: 0.046482
2021-12-17 16:29:42,164 iteration 1747 : loss : 0.106392, loss_ce: 0.031900
2021-12-17 16:29:43,550 iteration 1748 : loss : 0.092626, loss_ce: 0.024641
2021-12-17 16:29:44,822 iteration 1749 : loss : 0.096597, loss_ce: 0.024104
2021-12-17 16:29:46,200 iteration 1750 : loss : 0.122836, loss_ce: 0.024967
2021-12-17 16:29:47,660 iteration 1751 : loss : 0.119578, loss_ce: 0.037432
 26%|███████▍                     | 103/400 [45:06<2:04:54, 25.23s/it]2021-12-17 16:29:49,157 iteration 1752 : loss : 0.124903, loss_ce: 0.027452
2021-12-17 16:29:50,453 iteration 1753 : loss : 0.108756, loss_ce: 0.030863
2021-12-17 16:29:51,880 iteration 1754 : loss : 0.103579, loss_ce: 0.028338
2021-12-17 16:29:53,209 iteration 1755 : loss : 0.095675, loss_ce: 0.030674
2021-12-17 16:29:54,585 iteration 1756 : loss : 0.115211, loss_ce: 0.037066
2021-12-17 16:29:55,919 iteration 1757 : loss : 0.087934, loss_ce: 0.025388
2021-12-17 16:29:57,280 iteration 1758 : loss : 0.112039, loss_ce: 0.042395
2021-12-17 16:29:58,617 iteration 1759 : loss : 0.101786, loss_ce: 0.021513
2021-12-17 16:29:59,960 iteration 1760 : loss : 0.111981, loss_ce: 0.030574
2021-12-17 16:30:01,385 iteration 1761 : loss : 0.110455, loss_ce: 0.025666
2021-12-17 16:30:02,690 iteration 1762 : loss : 0.102942, loss_ce: 0.031802
2021-12-17 16:30:04,022 iteration 1763 : loss : 0.111551, loss_ce: 0.032223
2021-12-17 16:30:05,323 iteration 1764 : loss : 0.093380, loss_ce: 0.022084
2021-12-17 16:30:06,716 iteration 1765 : loss : 0.099405, loss_ce: 0.033940
2021-12-17 16:30:08,147 iteration 1766 : loss : 0.113417, loss_ce: 0.042359
2021-12-17 16:30:09,502 iteration 1767 : loss : 0.112350, loss_ce: 0.036577
2021-12-17 16:30:10,883 iteration 1768 : loss : 0.111751, loss_ce: 0.031103
 26%|███████▌                     | 104/400 [45:30<2:01:30, 24.63s/it]2021-12-17 16:30:12,315 iteration 1769 : loss : 0.107630, loss_ce: 0.033100
2021-12-17 16:30:13,649 iteration 1770 : loss : 0.103257, loss_ce: 0.032154
2021-12-17 16:30:14,949 iteration 1771 : loss : 0.106331, loss_ce: 0.033302
2021-12-17 16:30:16,273 iteration 1772 : loss : 0.099341, loss_ce: 0.030410
2021-12-17 16:30:17,695 iteration 1773 : loss : 0.119714, loss_ce: 0.028965
2021-12-17 16:30:19,088 iteration 1774 : loss : 0.093401, loss_ce: 0.024600
2021-12-17 16:30:20,489 iteration 1775 : loss : 0.105386, loss_ce: 0.032222
2021-12-17 16:30:21,825 iteration 1776 : loss : 0.109056, loss_ce: 0.041044
2021-12-17 16:30:23,164 iteration 1777 : loss : 0.098999, loss_ce: 0.027189
2021-12-17 16:30:24,480 iteration 1778 : loss : 0.098542, loss_ce: 0.024781
2021-12-17 16:30:25,899 iteration 1779 : loss : 0.108775, loss_ce: 0.024990
2021-12-17 16:30:27,274 iteration 1780 : loss : 0.117877, loss_ce: 0.041409
2021-12-17 16:30:28,596 iteration 1781 : loss : 0.095883, loss_ce: 0.029355
2021-12-17 16:30:30,002 iteration 1782 : loss : 0.109772, loss_ce: 0.034248
2021-12-17 16:30:31,385 iteration 1783 : loss : 0.109086, loss_ce: 0.027081
2021-12-17 16:30:32,718 iteration 1784 : loss : 0.109565, loss_ce: 0.033997
2021-12-17 16:30:32,718 Training Data Eval:
2021-12-17 16:30:39,828   Average segmentation loss on training set: 0.0894
2021-12-17 16:30:39,828 Validation Data Eval:
2021-12-17 16:30:42,317   Average segmentation loss on validation set: 0.1609
2021-12-17 16:30:43,745 iteration 1785 : loss : 0.114892, loss_ce: 0.033529
 26%|███████▌                     | 105/400 [46:02<2:13:13, 27.10s/it]2021-12-17 16:30:45,191 iteration 1786 : loss : 0.099918, loss_ce: 0.033542
2021-12-17 16:30:46,498 iteration 1787 : loss : 0.111225, loss_ce: 0.034118
2021-12-17 16:30:47,923 iteration 1788 : loss : 0.129431, loss_ce: 0.054128
2021-12-17 16:30:49,328 iteration 1789 : loss : 0.112203, loss_ce: 0.032849
2021-12-17 16:30:50,711 iteration 1790 : loss : 0.106671, loss_ce: 0.038549
2021-12-17 16:30:52,146 iteration 1791 : loss : 0.136311, loss_ce: 0.040186
2021-12-17 16:30:53,480 iteration 1792 : loss : 0.109159, loss_ce: 0.031561
2021-12-17 16:30:54,829 iteration 1793 : loss : 0.123843, loss_ce: 0.038633
2021-12-17 16:30:56,201 iteration 1794 : loss : 0.104502, loss_ce: 0.033983
2021-12-17 16:30:57,610 iteration 1795 : loss : 0.118699, loss_ce: 0.036435
2021-12-17 16:30:58,967 iteration 1796 : loss : 0.108089, loss_ce: 0.034743
2021-12-17 16:31:00,410 iteration 1797 : loss : 0.098733, loss_ce: 0.023098
2021-12-17 16:31:01,845 iteration 1798 : loss : 0.109514, loss_ce: 0.032135
2021-12-17 16:31:03,193 iteration 1799 : loss : 0.102429, loss_ce: 0.032335
2021-12-17 16:31:04,592 iteration 1800 : loss : 0.101692, loss_ce: 0.027452
2021-12-17 16:31:05,909 iteration 1801 : loss : 0.101683, loss_ce: 0.026721
2021-12-17 16:31:07,261 iteration 1802 : loss : 0.113772, loss_ce: 0.029360
 26%|███████▋                     | 106/400 [46:26<2:07:30, 26.02s/it]2021-12-17 16:31:08,755 iteration 1803 : loss : 0.129920, loss_ce: 0.044889
2021-12-17 16:31:10,182 iteration 1804 : loss : 0.105773, loss_ce: 0.026603
2021-12-17 16:31:11,524 iteration 1805 : loss : 0.119368, loss_ce: 0.028275
2021-12-17 16:31:12,858 iteration 1806 : loss : 0.105844, loss_ce: 0.037857
2021-12-17 16:31:14,199 iteration 1807 : loss : 0.113158, loss_ce: 0.034603
2021-12-17 16:31:15,552 iteration 1808 : loss : 0.105221, loss_ce: 0.033659
2021-12-17 16:31:16,893 iteration 1809 : loss : 0.095794, loss_ce: 0.027478
2021-12-17 16:31:18,171 iteration 1810 : loss : 0.088378, loss_ce: 0.023238
2021-12-17 16:31:19,579 iteration 1811 : loss : 0.099886, loss_ce: 0.030633
2021-12-17 16:31:21,012 iteration 1812 : loss : 0.105333, loss_ce: 0.030366
2021-12-17 16:31:22,489 iteration 1813 : loss : 0.098736, loss_ce: 0.025664
2021-12-17 16:31:23,881 iteration 1814 : loss : 0.115609, loss_ce: 0.042357
2021-12-17 16:31:25,208 iteration 1815 : loss : 0.092728, loss_ce: 0.021189
2021-12-17 16:31:26,511 iteration 1816 : loss : 0.097876, loss_ce: 0.032281
2021-12-17 16:31:27,934 iteration 1817 : loss : 0.103011, loss_ce: 0.031534
2021-12-17 16:31:29,297 iteration 1818 : loss : 0.132693, loss_ce: 0.050002
2021-12-17 16:31:30,700 iteration 1819 : loss : 0.117456, loss_ce: 0.040869
 27%|███████▊                     | 107/400 [46:49<2:03:17, 25.25s/it]2021-12-17 16:31:32,186 iteration 1820 : loss : 0.094736, loss_ce: 0.029486
2021-12-17 16:31:33,517 iteration 1821 : loss : 0.096763, loss_ce: 0.029980
2021-12-17 16:31:34,889 iteration 1822 : loss : 0.107285, loss_ce: 0.031938
2021-12-17 16:31:36,175 iteration 1823 : loss : 0.091354, loss_ce: 0.023121
2021-12-17 16:31:37,447 iteration 1824 : loss : 0.092748, loss_ce: 0.026867
2021-12-17 16:31:38,852 iteration 1825 : loss : 0.110124, loss_ce: 0.032273
2021-12-17 16:31:40,143 iteration 1826 : loss : 0.095261, loss_ce: 0.032414
2021-12-17 16:31:41,603 iteration 1827 : loss : 0.158983, loss_ce: 0.030291
2021-12-17 16:31:42,943 iteration 1828 : loss : 0.096329, loss_ce: 0.026046
2021-12-17 16:31:44,289 iteration 1829 : loss : 0.100230, loss_ce: 0.024535
2021-12-17 16:31:45,634 iteration 1830 : loss : 0.111241, loss_ce: 0.038308
2021-12-17 16:31:47,062 iteration 1831 : loss : 0.105426, loss_ce: 0.038402
2021-12-17 16:31:48,426 iteration 1832 : loss : 0.093987, loss_ce: 0.021802
2021-12-17 16:31:49,799 iteration 1833 : loss : 0.103934, loss_ce: 0.034949
2021-12-17 16:31:51,248 iteration 1834 : loss : 0.108723, loss_ce: 0.034484
2021-12-17 16:31:52,593 iteration 1835 : loss : 0.106725, loss_ce: 0.038514
2021-12-17 16:31:53,960 iteration 1836 : loss : 0.100919, loss_ce: 0.024301
 27%|███████▊                     | 108/400 [47:13<1:59:58, 24.65s/it]2021-12-17 16:31:55,432 iteration 1837 : loss : 0.102353, loss_ce: 0.029755
2021-12-17 16:31:56,846 iteration 1838 : loss : 0.102418, loss_ce: 0.035707
2021-12-17 16:31:58,181 iteration 1839 : loss : 0.102514, loss_ce: 0.029709
2021-12-17 16:31:59,481 iteration 1840 : loss : 0.103201, loss_ce: 0.036075
2021-12-17 16:32:00,883 iteration 1841 : loss : 0.115834, loss_ce: 0.038005
2021-12-17 16:32:02,303 iteration 1842 : loss : 0.132012, loss_ce: 0.040554
2021-12-17 16:32:03,608 iteration 1843 : loss : 0.093008, loss_ce: 0.029762
2021-12-17 16:32:04,973 iteration 1844 : loss : 0.104341, loss_ce: 0.029705
2021-12-17 16:32:06,281 iteration 1845 : loss : 0.102515, loss_ce: 0.032114
2021-12-17 16:32:07,746 iteration 1846 : loss : 0.113377, loss_ce: 0.039452
2021-12-17 16:32:09,164 iteration 1847 : loss : 0.114243, loss_ce: 0.033821
2021-12-17 16:32:10,533 iteration 1848 : loss : 0.099517, loss_ce: 0.030950
2021-12-17 16:32:11,818 iteration 1849 : loss : 0.096663, loss_ce: 0.027450
2021-12-17 16:32:13,196 iteration 1850 : loss : 0.122602, loss_ce: 0.030590
2021-12-17 16:32:14,603 iteration 1851 : loss : 0.098796, loss_ce: 0.027085
2021-12-17 16:32:15,976 iteration 1852 : loss : 0.101621, loss_ce: 0.031035
2021-12-17 16:32:17,349 iteration 1853 : loss : 0.104343, loss_ce: 0.020966
 27%|███████▉                     | 109/400 [47:36<1:57:43, 24.27s/it]2021-12-17 16:32:18,760 iteration 1854 : loss : 0.102962, loss_ce: 0.027914
2021-12-17 16:32:20,117 iteration 1855 : loss : 0.116714, loss_ce: 0.034514
2021-12-17 16:32:21,475 iteration 1856 : loss : 0.090862, loss_ce: 0.018189
2021-12-17 16:32:22,841 iteration 1857 : loss : 0.112789, loss_ce: 0.033498
2021-12-17 16:32:24,192 iteration 1858 : loss : 0.102603, loss_ce: 0.033349
2021-12-17 16:32:25,512 iteration 1859 : loss : 0.102580, loss_ce: 0.035032
2021-12-17 16:32:27,000 iteration 1860 : loss : 0.124459, loss_ce: 0.042415
2021-12-17 16:32:28,390 iteration 1861 : loss : 0.099929, loss_ce: 0.026166
2021-12-17 16:32:29,747 iteration 1862 : loss : 0.103228, loss_ce: 0.033883
2021-12-17 16:32:31,153 iteration 1863 : loss : 0.116571, loss_ce: 0.037772
2021-12-17 16:32:32,535 iteration 1864 : loss : 0.103069, loss_ce: 0.029985
2021-12-17 16:32:33,977 iteration 1865 : loss : 0.113809, loss_ce: 0.039335
2021-12-17 16:32:35,389 iteration 1866 : loss : 0.103148, loss_ce: 0.037044
2021-12-17 16:32:36,776 iteration 1867 : loss : 0.156128, loss_ce: 0.039783
2021-12-17 16:32:38,117 iteration 1868 : loss : 0.102806, loss_ce: 0.035026
2021-12-17 16:32:39,482 iteration 1869 : loss : 0.117474, loss_ce: 0.031047
2021-12-17 16:32:39,482 Training Data Eval:
2021-12-17 16:32:46,573   Average segmentation loss on training set: 0.0901
2021-12-17 16:32:46,573 Validation Data Eval:
2021-12-17 16:32:49,048   Average segmentation loss on validation set: 0.1501
2021-12-17 16:32:56,046 Found new lowest validation loss at iteration 1869! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/TU_3seeds/TU_RESNET_no_pretraining_SGD_best_val_loss_seed100.pth
2021-12-17 16:32:57,372 iteration 1870 : loss : 0.097703, loss_ce: 0.022550
 28%|███████▉                     | 110/400 [48:16<2:20:08, 29.00s/it]2021-12-17 16:32:58,727 iteration 1871 : loss : 0.113544, loss_ce: 0.039540
2021-12-17 16:32:59,992 iteration 1872 : loss : 0.101988, loss_ce: 0.026749
2021-12-17 16:33:01,310 iteration 1873 : loss : 0.105574, loss_ce: 0.033029
2021-12-17 16:33:02,671 iteration 1874 : loss : 0.120734, loss_ce: 0.039914
2021-12-17 16:33:04,058 iteration 1875 : loss : 0.111668, loss_ce: 0.045258
2021-12-17 16:33:05,445 iteration 1876 : loss : 0.120763, loss_ce: 0.028551
2021-12-17 16:33:06,810 iteration 1877 : loss : 0.101034, loss_ce: 0.024263
2021-12-17 16:33:08,082 iteration 1878 : loss : 0.104679, loss_ce: 0.027597
2021-12-17 16:33:09,368 iteration 1879 : loss : 0.101860, loss_ce: 0.032659
2021-12-17 16:33:10,644 iteration 1880 : loss : 0.095798, loss_ce: 0.026694
2021-12-17 16:33:11,913 iteration 1881 : loss : 0.086642, loss_ce: 0.022136
2021-12-17 16:33:13,233 iteration 1882 : loss : 0.110539, loss_ce: 0.020577
2021-12-17 16:33:14,489 iteration 1883 : loss : 0.095798, loss_ce: 0.029418
2021-12-17 16:33:15,869 iteration 1884 : loss : 0.096539, loss_ce: 0.028912
2021-12-17 16:33:17,141 iteration 1885 : loss : 0.085794, loss_ce: 0.024842
2021-12-17 16:33:18,479 iteration 1886 : loss : 0.112549, loss_ce: 0.039784
2021-12-17 16:33:19,772 iteration 1887 : loss : 0.104835, loss_ce: 0.028948
 28%|████████                     | 111/400 [48:38<2:10:08, 27.02s/it]2021-12-17 16:33:21,224 iteration 1888 : loss : 0.103445, loss_ce: 0.026569
2021-12-17 16:33:22,683 iteration 1889 : loss : 0.105841, loss_ce: 0.031159
2021-12-17 16:33:24,021 iteration 1890 : loss : 0.093383, loss_ce: 0.025794
2021-12-17 16:33:25,419 iteration 1891 : loss : 0.094818, loss_ce: 0.032217
2021-12-17 16:33:26,799 iteration 1892 : loss : 0.110847, loss_ce: 0.031235
2021-12-17 16:33:28,215 iteration 1893 : loss : 0.121616, loss_ce: 0.037586
2021-12-17 16:33:29,595 iteration 1894 : loss : 0.104865, loss_ce: 0.030820
2021-12-17 16:33:31,001 iteration 1895 : loss : 0.106526, loss_ce: 0.025929
2021-12-17 16:33:32,389 iteration 1896 : loss : 0.100665, loss_ce: 0.033055
2021-12-17 16:33:33,768 iteration 1897 : loss : 0.111575, loss_ce: 0.032418
2021-12-17 16:33:35,226 iteration 1898 : loss : 0.121258, loss_ce: 0.043769
2021-12-17 16:33:36,554 iteration 1899 : loss : 0.093396, loss_ce: 0.026834
2021-12-17 16:33:38,008 iteration 1900 : loss : 0.116371, loss_ce: 0.040282
2021-12-17 16:33:39,459 iteration 1901 : loss : 0.118465, loss_ce: 0.034885
2021-12-17 16:33:40,817 iteration 1902 : loss : 0.103866, loss_ce: 0.025586
2021-12-17 16:33:42,225 iteration 1903 : loss : 0.115297, loss_ce: 0.040578
2021-12-17 16:33:43,641 iteration 1904 : loss : 0.103399, loss_ce: 0.026051
 28%|████████                     | 112/400 [49:02<2:05:09, 26.08s/it]2021-12-17 16:33:45,110 iteration 1905 : loss : 0.108109, loss_ce: 0.034996
2021-12-17 16:33:46,498 iteration 1906 : loss : 0.098522, loss_ce: 0.023200
2021-12-17 16:33:47,871 iteration 1907 : loss : 0.101424, loss_ce: 0.027818
2021-12-17 16:33:49,356 iteration 1908 : loss : 0.112738, loss_ce: 0.030625
2021-12-17 16:33:50,750 iteration 1909 : loss : 0.115914, loss_ce: 0.034711
2021-12-17 16:33:52,159 iteration 1910 : loss : 0.150644, loss_ce: 0.025656
2021-12-17 16:33:53,599 iteration 1911 : loss : 0.093918, loss_ce: 0.023489
2021-12-17 16:33:54,926 iteration 1912 : loss : 0.094244, loss_ce: 0.024900
2021-12-17 16:33:56,307 iteration 1913 : loss : 0.111773, loss_ce: 0.043344
2021-12-17 16:33:57,698 iteration 1914 : loss : 0.108305, loss_ce: 0.038570
2021-12-17 16:33:59,103 iteration 1915 : loss : 0.103985, loss_ce: 0.030251
2021-12-17 16:34:00,469 iteration 1916 : loss : 0.115410, loss_ce: 0.035302
2021-12-17 16:34:01,841 iteration 1917 : loss : 0.108575, loss_ce: 0.036512
2021-12-17 16:34:03,237 iteration 1918 : loss : 0.118413, loss_ce: 0.030971
2021-12-17 16:34:04,591 iteration 1919 : loss : 0.103085, loss_ce: 0.030825
2021-12-17 16:34:05,948 iteration 1920 : loss : 0.104536, loss_ce: 0.033376
2021-12-17 16:34:07,400 iteration 1921 : loss : 0.118080, loss_ce: 0.039883
 28%|████████▏                    | 113/400 [49:26<2:01:23, 25.38s/it]2021-12-17 16:34:08,810 iteration 1922 : loss : 0.102902, loss_ce: 0.038615
2021-12-17 16:34:10,200 iteration 1923 : loss : 0.100222, loss_ce: 0.032765
2021-12-17 16:34:11,633 iteration 1924 : loss : 0.096560, loss_ce: 0.033370
2021-12-17 16:34:13,022 iteration 1925 : loss : 0.134962, loss_ce: 0.042331
2021-12-17 16:34:14,376 iteration 1926 : loss : 0.094138, loss_ce: 0.029590
2021-12-17 16:34:15,731 iteration 1927 : loss : 0.108038, loss_ce: 0.033071
2021-12-17 16:34:17,194 iteration 1928 : loss : 0.134313, loss_ce: 0.053564
2021-12-17 16:34:18,542 iteration 1929 : loss : 0.108892, loss_ce: 0.032224
2021-12-17 16:34:19,879 iteration 1930 : loss : 0.090636, loss_ce: 0.029641
2021-12-17 16:34:21,284 iteration 1931 : loss : 0.135235, loss_ce: 0.027576
2021-12-17 16:34:22,718 iteration 1932 : loss : 0.125257, loss_ce: 0.036092
2021-12-17 16:34:24,147 iteration 1933 : loss : 0.106022, loss_ce: 0.036384
2021-12-17 16:34:25,443 iteration 1934 : loss : 0.086030, loss_ce: 0.023594
2021-12-17 16:34:26,838 iteration 1935 : loss : 0.122461, loss_ce: 0.033704
2021-12-17 16:34:28,293 iteration 1936 : loss : 0.104652, loss_ce: 0.034076
2021-12-17 16:34:29,624 iteration 1937 : loss : 0.114858, loss_ce: 0.027333
2021-12-17 16:34:30,932 iteration 1938 : loss : 0.111767, loss_ce: 0.027314
 28%|████████▎                    | 114/400 [49:50<1:58:19, 24.82s/it]2021-12-17 16:34:32,334 iteration 1939 : loss : 0.094499, loss_ce: 0.023597
2021-12-17 16:34:33,808 iteration 1940 : loss : 0.104281, loss_ce: 0.033010
2021-12-17 16:34:35,273 iteration 1941 : loss : 0.117400, loss_ce: 0.039183
2021-12-17 16:34:36,673 iteration 1942 : loss : 0.101517, loss_ce: 0.030382
2021-12-17 16:34:38,034 iteration 1943 : loss : 0.106130, loss_ce: 0.032276
2021-12-17 16:34:39,425 iteration 1944 : loss : 0.092672, loss_ce: 0.026896
2021-12-17 16:34:40,754 iteration 1945 : loss : 0.101407, loss_ce: 0.028132
2021-12-17 16:34:42,133 iteration 1946 : loss : 0.090387, loss_ce: 0.025490
2021-12-17 16:34:43,539 iteration 1947 : loss : 0.109151, loss_ce: 0.036127
2021-12-17 16:34:44,911 iteration 1948 : loss : 0.116671, loss_ce: 0.027614
2021-12-17 16:34:46,258 iteration 1949 : loss : 0.091948, loss_ce: 0.025951
2021-12-17 16:34:47,582 iteration 1950 : loss : 0.086385, loss_ce: 0.028308
2021-12-17 16:34:49,020 iteration 1951 : loss : 0.110610, loss_ce: 0.032098
2021-12-17 16:34:50,436 iteration 1952 : loss : 0.112855, loss_ce: 0.030839
2021-12-17 16:34:51,885 iteration 1953 : loss : 0.115918, loss_ce: 0.042941
2021-12-17 16:34:53,270 iteration 1954 : loss : 0.091361, loss_ce: 0.027297
2021-12-17 16:34:53,270 Training Data Eval:
2021-12-17 16:35:00,433   Average segmentation loss on training set: 0.0858
2021-12-17 16:35:00,434 Validation Data Eval:
2021-12-17 16:35:02,928   Average segmentation loss on validation set: 0.1568
2021-12-17 16:35:04,341 iteration 1955 : loss : 0.101958, loss_ce: 0.022659
 29%|████████▎                    | 115/400 [50:23<2:10:09, 27.40s/it]2021-12-17 16:35:05,744 iteration 1956 : loss : 0.110280, loss_ce: 0.024154
2021-12-17 16:35:07,208 iteration 1957 : loss : 0.108034, loss_ce: 0.036300
2021-12-17 16:35:08,667 iteration 1958 : loss : 0.123600, loss_ce: 0.038250
2021-12-17 16:35:10,053 iteration 1959 : loss : 0.116621, loss_ce: 0.035266
2021-12-17 16:35:11,371 iteration 1960 : loss : 0.092963, loss_ce: 0.024567
2021-12-17 16:35:12,775 iteration 1961 : loss : 0.097016, loss_ce: 0.031023
2021-12-17 16:35:14,183 iteration 1962 : loss : 0.111323, loss_ce: 0.040239
2021-12-17 16:35:15,513 iteration 1963 : loss : 0.090991, loss_ce: 0.027386
2021-12-17 16:35:16,863 iteration 1964 : loss : 0.092821, loss_ce: 0.025921
2021-12-17 16:35:18,218 iteration 1965 : loss : 0.097354, loss_ce: 0.033031
2021-12-17 16:35:19,669 iteration 1966 : loss : 0.098459, loss_ce: 0.028451
2021-12-17 16:35:21,116 iteration 1967 : loss : 0.105806, loss_ce: 0.033980
2021-12-17 16:35:22,535 iteration 1968 : loss : 0.095933, loss_ce: 0.030468
2021-12-17 16:35:23,937 iteration 1969 : loss : 0.114823, loss_ce: 0.036425
2021-12-17 16:35:25,300 iteration 1970 : loss : 0.100587, loss_ce: 0.024376
2021-12-17 16:35:26,719 iteration 1971 : loss : 0.105406, loss_ce: 0.036483
2021-12-17 16:35:28,053 iteration 1972 : loss : 0.120359, loss_ce: 0.033896
 29%|████████▍                    | 116/400 [50:47<2:04:26, 26.29s/it]2021-12-17 16:35:29,350 iteration 1973 : loss : 0.093754, loss_ce: 0.028058
2021-12-17 16:35:30,735 iteration 1974 : loss : 0.098348, loss_ce: 0.032075
2021-12-17 16:35:32,107 iteration 1975 : loss : 0.108878, loss_ce: 0.028373
2021-12-17 16:35:33,550 iteration 1976 : loss : 0.097990, loss_ce: 0.031687
2021-12-17 16:35:34,932 iteration 1977 : loss : 0.116795, loss_ce: 0.031497
2021-12-17 16:35:36,229 iteration 1978 : loss : 0.094474, loss_ce: 0.028766
2021-12-17 16:35:37,535 iteration 1979 : loss : 0.104957, loss_ce: 0.032125
2021-12-17 16:35:38,933 iteration 1980 : loss : 0.106371, loss_ce: 0.041173
2021-12-17 16:35:40,280 iteration 1981 : loss : 0.099536, loss_ce: 0.025524
2021-12-17 16:35:41,576 iteration 1982 : loss : 0.097614, loss_ce: 0.025547
2021-12-17 16:35:43,010 iteration 1983 : loss : 0.125333, loss_ce: 0.048129
2021-12-17 16:35:44,327 iteration 1984 : loss : 0.094333, loss_ce: 0.021069
2021-12-17 16:35:45,704 iteration 1985 : loss : 0.080979, loss_ce: 0.021159
2021-12-17 16:35:47,083 iteration 1986 : loss : 0.116205, loss_ce: 0.045515
2021-12-17 16:35:48,502 iteration 1987 : loss : 0.088685, loss_ce: 0.025758
2021-12-17 16:35:49,826 iteration 1988 : loss : 0.106768, loss_ce: 0.022510
2021-12-17 16:35:51,189 iteration 1989 : loss : 0.116024, loss_ce: 0.037788
 29%|████████▍                    | 117/400 [51:10<1:59:33, 25.35s/it]2021-12-17 16:35:52,545 iteration 1990 : loss : 0.085383, loss_ce: 0.026376
2021-12-17 16:35:53,887 iteration 1991 : loss : 0.101156, loss_ce: 0.029293
2021-12-17 16:35:55,288 iteration 1992 : loss : 0.111218, loss_ce: 0.031388
2021-12-17 16:35:56,776 iteration 1993 : loss : 0.116690, loss_ce: 0.045202
2021-12-17 16:35:58,098 iteration 1994 : loss : 0.087406, loss_ce: 0.024710
2021-12-17 16:35:59,465 iteration 1995 : loss : 0.103910, loss_ce: 0.023262
2021-12-17 16:36:00,839 iteration 1996 : loss : 0.116699, loss_ce: 0.028264
2021-12-17 16:36:02,214 iteration 1997 : loss : 0.087641, loss_ce: 0.022313
2021-12-17 16:36:03,600 iteration 1998 : loss : 0.109321, loss_ce: 0.032211
2021-12-17 16:36:04,958 iteration 1999 : loss : 0.107281, loss_ce: 0.034104
2021-12-17 16:36:06,388 iteration 2000 : loss : 0.099979, loss_ce: 0.020159
2021-12-17 16:36:07,736 iteration 2001 : loss : 0.108815, loss_ce: 0.035573
2021-12-17 16:36:09,166 iteration 2002 : loss : 0.094272, loss_ce: 0.033866
2021-12-17 16:36:10,506 iteration 2003 : loss : 0.097479, loss_ce: 0.032532
2021-12-17 16:36:11,900 iteration 2004 : loss : 0.113644, loss_ce: 0.032791
2021-12-17 16:36:13,309 iteration 2005 : loss : 0.122457, loss_ce: 0.042166
2021-12-17 16:36:14,698 iteration 2006 : loss : 0.124610, loss_ce: 0.043147
 30%|████████▌                    | 118/400 [51:33<1:56:32, 24.80s/it]2021-12-17 16:36:16,140 iteration 2007 : loss : 0.108691, loss_ce: 0.036276
2021-12-17 16:36:17,479 iteration 2008 : loss : 0.096581, loss_ce: 0.028442
2021-12-17 16:36:18,842 iteration 2009 : loss : 0.102198, loss_ce: 0.025762
2021-12-17 16:36:20,168 iteration 2010 : loss : 0.102361, loss_ce: 0.028571
2021-12-17 16:36:21,530 iteration 2011 : loss : 0.097139, loss_ce: 0.033593
2021-12-17 16:36:22,908 iteration 2012 : loss : 0.118742, loss_ce: 0.034543
2021-12-17 16:36:24,322 iteration 2013 : loss : 0.116269, loss_ce: 0.035965
2021-12-17 16:36:25,735 iteration 2014 : loss : 0.084379, loss_ce: 0.021804
2021-12-17 16:36:27,048 iteration 2015 : loss : 0.099524, loss_ce: 0.030640
2021-12-17 16:36:28,414 iteration 2016 : loss : 0.106222, loss_ce: 0.028730
2021-12-17 16:36:29,699 iteration 2017 : loss : 0.080885, loss_ce: 0.022726
2021-12-17 16:36:31,083 iteration 2018 : loss : 0.100220, loss_ce: 0.030878
2021-12-17 16:36:32,411 iteration 2019 : loss : 0.094678, loss_ce: 0.031282
2021-12-17 16:36:33,782 iteration 2020 : loss : 0.094701, loss_ce: 0.028768
2021-12-17 16:36:35,177 iteration 2021 : loss : 0.098149, loss_ce: 0.031165
2021-12-17 16:36:36,604 iteration 2022 : loss : 0.098248, loss_ce: 0.031829
2021-12-17 16:36:37,975 iteration 2023 : loss : 0.106120, loss_ce: 0.026740
 30%|████████▋                    | 119/400 [51:57<1:53:59, 24.34s/it]2021-12-17 16:36:39,431 iteration 2024 : loss : 0.108974, loss_ce: 0.033068
2021-12-17 16:36:40,747 iteration 2025 : loss : 0.087891, loss_ce: 0.023195
2021-12-17 16:36:42,088 iteration 2026 : loss : 0.095322, loss_ce: 0.030227
2021-12-17 16:36:43,486 iteration 2027 : loss : 0.100846, loss_ce: 0.028020
2021-12-17 16:36:44,869 iteration 2028 : loss : 0.109948, loss_ce: 0.031298
2021-12-17 16:36:46,170 iteration 2029 : loss : 0.092155, loss_ce: 0.031367
2021-12-17 16:36:47,545 iteration 2030 : loss : 0.117938, loss_ce: 0.034545
2021-12-17 16:36:48,935 iteration 2031 : loss : 0.091037, loss_ce: 0.024674
2021-12-17 16:36:50,341 iteration 2032 : loss : 0.099358, loss_ce: 0.028631
2021-12-17 16:36:51,712 iteration 2033 : loss : 0.106552, loss_ce: 0.027488
2021-12-17 16:36:53,017 iteration 2034 : loss : 0.094898, loss_ce: 0.024723
2021-12-17 16:36:54,340 iteration 2035 : loss : 0.084875, loss_ce: 0.025535
2021-12-17 16:36:55,747 iteration 2036 : loss : 0.088497, loss_ce: 0.027227
2021-12-17 16:36:57,105 iteration 2037 : loss : 0.093758, loss_ce: 0.025059
2021-12-17 16:36:58,430 iteration 2038 : loss : 0.095902, loss_ce: 0.026439
2021-12-17 16:36:59,811 iteration 2039 : loss : 0.094723, loss_ce: 0.029982
2021-12-17 16:36:59,811 Training Data Eval:
2021-12-17 16:37:06,986   Average segmentation loss on training set: 0.0771
2021-12-17 16:37:06,986 Validation Data Eval:
2021-12-17 16:37:09,487   Average segmentation loss on validation set: 0.1523
2021-12-17 16:37:10,842 iteration 2040 : loss : 0.107758, loss_ce: 0.027971
 30%|████████▋                    | 120/400 [52:29<2:05:30, 26.90s/it]2021-12-17 16:37:12,267 iteration 2041 : loss : 0.106303, loss_ce: 0.034125
2021-12-17 16:37:13,627 iteration 2042 : loss : 0.097828, loss_ce: 0.029842
2021-12-17 16:37:14,990 iteration 2043 : loss : 0.099513, loss_ce: 0.034148
2021-12-17 16:37:16,403 iteration 2044 : loss : 0.094828, loss_ce: 0.028233
2021-12-17 16:37:17,845 iteration 2045 : loss : 0.099903, loss_ce: 0.028155
2021-12-17 16:37:19,246 iteration 2046 : loss : 0.098757, loss_ce: 0.026977
2021-12-17 16:37:20,629 iteration 2047 : loss : 0.084080, loss_ce: 0.019346
2021-12-17 16:37:21,928 iteration 2048 : loss : 0.089586, loss_ce: 0.023288
2021-12-17 16:37:23,281 iteration 2049 : loss : 0.088177, loss_ce: 0.026030
2021-12-17 16:37:24,678 iteration 2050 : loss : 0.095148, loss_ce: 0.023579
2021-12-17 16:37:26,083 iteration 2051 : loss : 0.106891, loss_ce: 0.029704
2021-12-17 16:37:27,418 iteration 2052 : loss : 0.099061, loss_ce: 0.035161
2021-12-17 16:37:28,762 iteration 2053 : loss : 0.106046, loss_ce: 0.032918
2021-12-17 16:37:30,147 iteration 2054 : loss : 0.113807, loss_ce: 0.034777
2021-12-17 16:37:31,541 iteration 2055 : loss : 0.134173, loss_ce: 0.057893
2021-12-17 16:37:32,926 iteration 2056 : loss : 0.102368, loss_ce: 0.034331
2021-12-17 16:37:34,338 iteration 2057 : loss : 0.089799, loss_ce: 0.028868
 30%|████████▊                    | 121/400 [52:53<2:00:20, 25.88s/it]2021-12-17 16:37:35,828 iteration 2058 : loss : 0.097935, loss_ce: 0.031460
2021-12-17 16:37:37,221 iteration 2059 : loss : 0.103876, loss_ce: 0.032004
2021-12-17 16:37:38,642 iteration 2060 : loss : 0.102879, loss_ce: 0.026142
2021-12-17 16:37:39,981 iteration 2061 : loss : 0.091539, loss_ce: 0.031336
2021-12-17 16:37:41,299 iteration 2062 : loss : 0.094934, loss_ce: 0.024048
2021-12-17 16:37:42,617 iteration 2063 : loss : 0.087702, loss_ce: 0.027703
2021-12-17 16:37:43,994 iteration 2064 : loss : 0.087385, loss_ce: 0.029708
2021-12-17 16:37:45,378 iteration 2065 : loss : 0.098477, loss_ce: 0.027502
2021-12-17 16:37:46,796 iteration 2066 : loss : 0.115170, loss_ce: 0.029742
2021-12-17 16:37:48,132 iteration 2067 : loss : 0.112822, loss_ce: 0.033028
2021-12-17 16:37:49,545 iteration 2068 : loss : 0.103966, loss_ce: 0.036907
2021-12-17 16:37:50,973 iteration 2069 : loss : 0.104010, loss_ce: 0.027501
2021-12-17 16:37:52,330 iteration 2070 : loss : 0.091890, loss_ce: 0.025055
2021-12-17 16:37:53,685 iteration 2071 : loss : 0.088020, loss_ce: 0.026340
2021-12-17 16:37:55,006 iteration 2072 : loss : 0.086910, loss_ce: 0.026287
2021-12-17 16:37:56,309 iteration 2073 : loss : 0.098469, loss_ce: 0.028283
2021-12-17 16:37:57,684 iteration 2074 : loss : 0.126357, loss_ce: 0.032611
 30%|████████▊                    | 122/400 [53:16<1:56:22, 25.12s/it]2021-12-17 16:37:59,111 iteration 2075 : loss : 0.103643, loss_ce: 0.031003
2021-12-17 16:38:00,536 iteration 2076 : loss : 0.105402, loss_ce: 0.025677
2021-12-17 16:38:01,924 iteration 2077 : loss : 0.096232, loss_ce: 0.029750
2021-12-17 16:38:03,251 iteration 2078 : loss : 0.089487, loss_ce: 0.026629
2021-12-17 16:38:04,605 iteration 2079 : loss : 0.087716, loss_ce: 0.022349
2021-12-17 16:38:06,029 iteration 2080 : loss : 0.093500, loss_ce: 0.024473
2021-12-17 16:38:07,419 iteration 2081 : loss : 0.087932, loss_ce: 0.028751
2021-12-17 16:38:08,785 iteration 2082 : loss : 0.106605, loss_ce: 0.031715
2021-12-17 16:38:10,141 iteration 2083 : loss : 0.089591, loss_ce: 0.024059
2021-12-17 16:38:11,499 iteration 2084 : loss : 0.094822, loss_ce: 0.027539
2021-12-17 16:38:12,842 iteration 2085 : loss : 0.101011, loss_ce: 0.031710
2021-12-17 16:38:14,200 iteration 2086 : loss : 0.090101, loss_ce: 0.029331
2021-12-17 16:38:15,521 iteration 2087 : loss : 0.097483, loss_ce: 0.022337
2021-12-17 16:38:16,994 iteration 2088 : loss : 0.123387, loss_ce: 0.047568
2021-12-17 16:38:18,349 iteration 2089 : loss : 0.084264, loss_ce: 0.022360
2021-12-17 16:38:19,759 iteration 2090 : loss : 0.101642, loss_ce: 0.027612
2021-12-17 16:38:21,124 iteration 2091 : loss : 0.085990, loss_ce: 0.026387
 31%|████████▉                    | 123/400 [53:40<1:53:37, 24.61s/it]2021-12-17 16:38:22,571 iteration 2092 : loss : 0.093951, loss_ce: 0.026985
2021-12-17 16:38:24,016 iteration 2093 : loss : 0.117473, loss_ce: 0.044010
2021-12-17 16:38:25,412 iteration 2094 : loss : 0.122601, loss_ce: 0.041868
2021-12-17 16:38:26,800 iteration 2095 : loss : 0.095041, loss_ce: 0.027023
2021-12-17 16:38:28,218 iteration 2096 : loss : 0.114969, loss_ce: 0.035810
2021-12-17 16:38:29,548 iteration 2097 : loss : 0.100866, loss_ce: 0.040086
2021-12-17 16:38:30,974 iteration 2098 : loss : 0.095282, loss_ce: 0.028597
2021-12-17 16:38:32,382 iteration 2099 : loss : 0.112679, loss_ce: 0.032700
2021-12-17 16:38:33,841 iteration 2100 : loss : 0.112623, loss_ce: 0.037061
2021-12-17 16:38:35,222 iteration 2101 : loss : 0.116087, loss_ce: 0.027976
2021-12-17 16:38:36,569 iteration 2102 : loss : 0.096066, loss_ce: 0.026878
2021-12-17 16:38:38,045 iteration 2103 : loss : 0.123547, loss_ce: 0.046011
2021-12-17 16:38:39,452 iteration 2104 : loss : 0.087630, loss_ce: 0.024629
2021-12-17 16:38:40,796 iteration 2105 : loss : 0.093239, loss_ce: 0.024215
2021-12-17 16:38:42,239 iteration 2106 : loss : 0.099477, loss_ce: 0.022469
2021-12-17 16:38:43,614 iteration 2107 : loss : 0.103169, loss_ce: 0.031204
2021-12-17 16:38:45,007 iteration 2108 : loss : 0.090118, loss_ce: 0.024071
 31%|████████▉                    | 124/400 [54:04<1:52:12, 24.39s/it]2021-12-17 16:38:46,426 iteration 2109 : loss : 0.100363, loss_ce: 0.033462
2021-12-17 16:38:47,779 iteration 2110 : loss : 0.105361, loss_ce: 0.030551
2021-12-17 16:38:49,259 iteration 2111 : loss : 0.130857, loss_ce: 0.044981
2021-12-17 16:38:50,744 iteration 2112 : loss : 0.099406, loss_ce: 0.029916
2021-12-17 16:38:52,086 iteration 2113 : loss : 0.104868, loss_ce: 0.031726
2021-12-17 16:38:53,441 iteration 2114 : loss : 0.097646, loss_ce: 0.025052
2021-12-17 16:38:54,714 iteration 2115 : loss : 0.102780, loss_ce: 0.023650
2021-12-17 16:38:56,116 iteration 2116 : loss : 0.119977, loss_ce: 0.037762
2021-12-17 16:38:57,552 iteration 2117 : loss : 0.096731, loss_ce: 0.027501
2021-12-17 16:38:58,921 iteration 2118 : loss : 0.117228, loss_ce: 0.042937
2021-12-17 16:39:00,315 iteration 2119 : loss : 0.108780, loss_ce: 0.028137
2021-12-17 16:39:01,693 iteration 2120 : loss : 0.095138, loss_ce: 0.026531
2021-12-17 16:39:03,152 iteration 2121 : loss : 0.094662, loss_ce: 0.027268
2021-12-17 16:39:04,467 iteration 2122 : loss : 0.090254, loss_ce: 0.029059
2021-12-17 16:39:05,795 iteration 2123 : loss : 0.100843, loss_ce: 0.037840
2021-12-17 16:39:07,190 iteration 2124 : loss : 0.102587, loss_ce: 0.030776
2021-12-17 16:39:07,190 Training Data Eval:
2021-12-17 16:39:14,279   Average segmentation loss on training set: 0.0758
2021-12-17 16:39:14,280 Validation Data Eval:
2021-12-17 16:39:16,779   Average segmentation loss on validation set: 0.1536
2021-12-17 16:39:18,183 iteration 2125 : loss : 0.091625, loss_ce: 0.026962
 31%|█████████                    | 125/400 [54:37<2:03:53, 27.03s/it]2021-12-17 16:39:19,609 iteration 2126 : loss : 0.085441, loss_ce: 0.022182
2021-12-17 16:39:21,048 iteration 2127 : loss : 0.094641, loss_ce: 0.025758
2021-12-17 16:39:22,371 iteration 2128 : loss : 0.091734, loss_ce: 0.032345
2021-12-17 16:39:23,807 iteration 2129 : loss : 0.090731, loss_ce: 0.024764
2021-12-17 16:39:25,132 iteration 2130 : loss : 0.094617, loss_ce: 0.024364
2021-12-17 16:39:26,576 iteration 2131 : loss : 0.107407, loss_ce: 0.033634
2021-12-17 16:39:28,013 iteration 2132 : loss : 0.101324, loss_ce: 0.030671
2021-12-17 16:39:29,433 iteration 2133 : loss : 0.101585, loss_ce: 0.028705
2021-12-17 16:39:30,846 iteration 2134 : loss : 0.138106, loss_ce: 0.044222
2021-12-17 16:39:32,228 iteration 2135 : loss : 0.100787, loss_ce: 0.028256
2021-12-17 16:39:33,604 iteration 2136 : loss : 0.101434, loss_ce: 0.030556
2021-12-17 16:39:34,981 iteration 2137 : loss : 0.107255, loss_ce: 0.026671
2021-12-17 16:39:36,323 iteration 2138 : loss : 0.117038, loss_ce: 0.033767
2021-12-17 16:39:37,631 iteration 2139 : loss : 0.092851, loss_ce: 0.031504
2021-12-17 16:39:38,981 iteration 2140 : loss : 0.091044, loss_ce: 0.024894
2021-12-17 16:39:40,360 iteration 2141 : loss : 0.101174, loss_ce: 0.033002
2021-12-17 16:39:41,731 iteration 2142 : loss : 0.121261, loss_ce: 0.050104
 32%|█████████▏                   | 126/400 [55:00<1:58:40, 25.99s/it]2021-12-17 16:39:43,171 iteration 2143 : loss : 0.096363, loss_ce: 0.022365
2021-12-17 16:39:44,522 iteration 2144 : loss : 0.120667, loss_ce: 0.027635
2021-12-17 16:39:45,809 iteration 2145 : loss : 0.088410, loss_ce: 0.030638
2021-12-17 16:39:47,313 iteration 2146 : loss : 0.123197, loss_ce: 0.040312
2021-12-17 16:39:48,700 iteration 2147 : loss : 0.092635, loss_ce: 0.025838
2021-12-17 16:39:50,080 iteration 2148 : loss : 0.097264, loss_ce: 0.030812
2021-12-17 16:39:51,468 iteration 2149 : loss : 0.106675, loss_ce: 0.031737
2021-12-17 16:39:52,883 iteration 2150 : loss : 0.112943, loss_ce: 0.030881
2021-12-17 16:39:54,302 iteration 2151 : loss : 0.117913, loss_ce: 0.037480
2021-12-17 16:39:55,620 iteration 2152 : loss : 0.079606, loss_ce: 0.021854
2021-12-17 16:39:56,953 iteration 2153 : loss : 0.090826, loss_ce: 0.021200
2021-12-17 16:39:58,254 iteration 2154 : loss : 0.089098, loss_ce: 0.029099
2021-12-17 16:39:59,584 iteration 2155 : loss : 0.092202, loss_ce: 0.027251
2021-12-17 16:40:00,994 iteration 2156 : loss : 0.097288, loss_ce: 0.028227
2021-12-17 16:40:02,392 iteration 2157 : loss : 0.112360, loss_ce: 0.042654
2021-12-17 16:40:03,738 iteration 2158 : loss : 0.097892, loss_ce: 0.033802
2021-12-17 16:40:05,160 iteration 2159 : loss : 0.126435, loss_ce: 0.033885
 32%|█████████▏                   | 127/400 [55:24<1:54:45, 25.22s/it]2021-12-17 16:40:06,519 iteration 2160 : loss : 0.081544, loss_ce: 0.022463
2021-12-17 16:40:07,910 iteration 2161 : loss : 0.092103, loss_ce: 0.030746
2021-12-17 16:40:09,283 iteration 2162 : loss : 0.094680, loss_ce: 0.027638
2021-12-17 16:40:10,570 iteration 2163 : loss : 0.096639, loss_ce: 0.020650
2021-12-17 16:40:11,950 iteration 2164 : loss : 0.106222, loss_ce: 0.039244
2021-12-17 16:40:13,320 iteration 2165 : loss : 0.086785, loss_ce: 0.021736
2021-12-17 16:40:14,746 iteration 2166 : loss : 0.112695, loss_ce: 0.039255
2021-12-17 16:40:16,127 iteration 2167 : loss : 0.091970, loss_ce: 0.033713
2021-12-17 16:40:17,494 iteration 2168 : loss : 0.091293, loss_ce: 0.026988
2021-12-17 16:40:18,879 iteration 2169 : loss : 0.086018, loss_ce: 0.025024
2021-12-17 16:40:20,221 iteration 2170 : loss : 0.095878, loss_ce: 0.021883
2021-12-17 16:40:21,579 iteration 2171 : loss : 0.073163, loss_ce: 0.017110
2021-12-17 16:40:22,860 iteration 2172 : loss : 0.093299, loss_ce: 0.032466
2021-12-17 16:40:24,225 iteration 2173 : loss : 0.094791, loss_ce: 0.023698
2021-12-17 16:40:25,631 iteration 2174 : loss : 0.104341, loss_ce: 0.031648
2021-12-17 16:40:26,961 iteration 2175 : loss : 0.104070, loss_ce: 0.030096
2021-12-17 16:40:28,302 iteration 2176 : loss : 0.099742, loss_ce: 0.035655
 32%|█████████▎                   | 128/400 [55:47<1:51:29, 24.59s/it]2021-12-17 16:40:29,775 iteration 2177 : loss : 0.095457, loss_ce: 0.024170
2021-12-17 16:40:31,094 iteration 2178 : loss : 0.083744, loss_ce: 0.024693
2021-12-17 16:40:32,450 iteration 2179 : loss : 0.088042, loss_ce: 0.028896
2021-12-17 16:40:33,854 iteration 2180 : loss : 0.089146, loss_ce: 0.023566
2021-12-17 16:40:35,203 iteration 2181 : loss : 0.097022, loss_ce: 0.024452
2021-12-17 16:40:36,552 iteration 2182 : loss : 0.095896, loss_ce: 0.026195
2021-12-17 16:40:37,877 iteration 2183 : loss : 0.092765, loss_ce: 0.024296
2021-12-17 16:40:39,183 iteration 2184 : loss : 0.092701, loss_ce: 0.027657
2021-12-17 16:40:40,474 iteration 2185 : loss : 0.086734, loss_ce: 0.026025
2021-12-17 16:40:41,939 iteration 2186 : loss : 0.132317, loss_ce: 0.047264
2021-12-17 16:40:43,239 iteration 2187 : loss : 0.096723, loss_ce: 0.034561
2021-12-17 16:40:44,640 iteration 2188 : loss : 0.102875, loss_ce: 0.032242
2021-12-17 16:40:45,971 iteration 2189 : loss : 0.098065, loss_ce: 0.027053
2021-12-17 16:40:47,385 iteration 2190 : loss : 0.096260, loss_ce: 0.028856
2021-12-17 16:40:48,690 iteration 2191 : loss : 0.088042, loss_ce: 0.029790
2021-12-17 16:40:50,049 iteration 2192 : loss : 0.104530, loss_ce: 0.026578
2021-12-17 16:40:51,471 iteration 2193 : loss : 0.106671, loss_ce: 0.035984
 32%|█████████▎                   | 129/400 [56:10<1:49:10, 24.17s/it]2021-12-17 16:40:52,853 iteration 2194 : loss : 0.104976, loss_ce: 0.032069
2021-12-17 16:40:54,173 iteration 2195 : loss : 0.094781, loss_ce: 0.026352
2021-12-17 16:40:55,543 iteration 2196 : loss : 0.096029, loss_ce: 0.033445
2021-12-17 16:40:56,941 iteration 2197 : loss : 0.100081, loss_ce: 0.028640
2021-12-17 16:40:58,291 iteration 2198 : loss : 0.086946, loss_ce: 0.029991
2021-12-17 16:40:59,794 iteration 2199 : loss : 0.107640, loss_ce: 0.035332
2021-12-17 16:41:01,155 iteration 2200 : loss : 0.094277, loss_ce: 0.029426
2021-12-17 16:41:02,527 iteration 2201 : loss : 0.107013, loss_ce: 0.027597
2021-12-17 16:41:03,888 iteration 2202 : loss : 0.114295, loss_ce: 0.026612
2021-12-17 16:41:05,292 iteration 2203 : loss : 0.086813, loss_ce: 0.022501
2021-12-17 16:41:06,697 iteration 2204 : loss : 0.101788, loss_ce: 0.029177
2021-12-17 16:41:07,961 iteration 2205 : loss : 0.088556, loss_ce: 0.028330
2021-12-17 16:41:09,267 iteration 2206 : loss : 0.083096, loss_ce: 0.028645
2021-12-17 16:41:10,646 iteration 2207 : loss : 0.124853, loss_ce: 0.044513
2021-12-17 16:41:12,011 iteration 2208 : loss : 0.090937, loss_ce: 0.025861
2021-12-17 16:41:13,433 iteration 2209 : loss : 0.104063, loss_ce: 0.028127
2021-12-17 16:41:13,433 Training Data Eval:
2021-12-17 16:41:20,513   Average segmentation loss on training set: 0.0745
2021-12-17 16:41:20,514 Validation Data Eval:
2021-12-17 16:41:23,002   Average segmentation loss on validation set: 0.1654
2021-12-17 16:41:24,403 iteration 2210 : loss : 0.090201, loss_ce: 0.025060
 32%|█████████▍                   | 130/400 [56:43<2:00:35, 26.80s/it]2021-12-17 16:41:25,838 iteration 2211 : loss : 0.104299, loss_ce: 0.041328
2021-12-17 16:41:27,134 iteration 2212 : loss : 0.082477, loss_ce: 0.020985
2021-12-17 16:41:28,450 iteration 2213 : loss : 0.085845, loss_ce: 0.023547
2021-12-17 16:41:29,836 iteration 2214 : loss : 0.086291, loss_ce: 0.027328
2021-12-17 16:41:31,190 iteration 2215 : loss : 0.091505, loss_ce: 0.025387
2021-12-17 16:41:32,524 iteration 2216 : loss : 0.087638, loss_ce: 0.027963
2021-12-17 16:41:33,812 iteration 2217 : loss : 0.088999, loss_ce: 0.031647
2021-12-17 16:41:35,191 iteration 2218 : loss : 0.091353, loss_ce: 0.020092
2021-12-17 16:41:36,537 iteration 2219 : loss : 0.086154, loss_ce: 0.023366
2021-12-17 16:41:37,911 iteration 2220 : loss : 0.091178, loss_ce: 0.031792
2021-12-17 16:41:39,331 iteration 2221 : loss : 0.104792, loss_ce: 0.038528
2021-12-17 16:41:40,661 iteration 2222 : loss : 0.100284, loss_ce: 0.024959
2021-12-17 16:41:42,134 iteration 2223 : loss : 0.097587, loss_ce: 0.029614
2021-12-17 16:41:43,472 iteration 2224 : loss : 0.131030, loss_ce: 0.031367
2021-12-17 16:41:44,827 iteration 2225 : loss : 0.091838, loss_ce: 0.027649
2021-12-17 16:41:46,308 iteration 2226 : loss : 0.113829, loss_ce: 0.037921
2021-12-17 16:41:47,714 iteration 2227 : loss : 0.122456, loss_ce: 0.031108
 33%|█████████▍                   | 131/400 [57:06<1:55:26, 25.75s/it]2021-12-17 16:41:49,166 iteration 2228 : loss : 0.116167, loss_ce: 0.033399
2021-12-17 16:41:50,542 iteration 2229 : loss : 0.099938, loss_ce: 0.031876
2021-12-17 16:41:51,873 iteration 2230 : loss : 0.101372, loss_ce: 0.030004
2021-12-17 16:41:53,190 iteration 2231 : loss : 0.080226, loss_ce: 0.025857
2021-12-17 16:41:54,506 iteration 2232 : loss : 0.086819, loss_ce: 0.024252
2021-12-17 16:41:55,835 iteration 2233 : loss : 0.098491, loss_ce: 0.022393
2021-12-17 16:41:57,220 iteration 2234 : loss : 0.133502, loss_ce: 0.046075
2021-12-17 16:41:58,533 iteration 2235 : loss : 0.093464, loss_ce: 0.031457
2021-12-17 16:41:59,865 iteration 2236 : loss : 0.093200, loss_ce: 0.028223
2021-12-17 16:42:01,220 iteration 2237 : loss : 0.096998, loss_ce: 0.031389
2021-12-17 16:42:02,557 iteration 2238 : loss : 0.113375, loss_ce: 0.032202
2021-12-17 16:42:03,937 iteration 2239 : loss : 0.122371, loss_ce: 0.044052
2021-12-17 16:42:05,231 iteration 2240 : loss : 0.085054, loss_ce: 0.023619
2021-12-17 16:42:06,624 iteration 2241 : loss : 0.090983, loss_ce: 0.029539
2021-12-17 16:42:07,943 iteration 2242 : loss : 0.094406, loss_ce: 0.033195
2021-12-17 16:42:09,270 iteration 2243 : loss : 0.082874, loss_ce: 0.018164
2021-12-17 16:42:10,629 iteration 2244 : loss : 0.097758, loss_ce: 0.025734
 33%|█████████▌                   | 132/400 [57:29<1:51:12, 24.90s/it]2021-12-17 16:42:12,008 iteration 2245 : loss : 0.078822, loss_ce: 0.024254
2021-12-17 16:42:13,384 iteration 2246 : loss : 0.119015, loss_ce: 0.033613
2021-12-17 16:42:14,737 iteration 2247 : loss : 0.097163, loss_ce: 0.027135
2021-12-17 16:42:16,004 iteration 2248 : loss : 0.076119, loss_ce: 0.022631
2021-12-17 16:42:17,418 iteration 2249 : loss : 0.101744, loss_ce: 0.032843
2021-12-17 16:42:18,892 iteration 2250 : loss : 0.118619, loss_ce: 0.038448
2021-12-17 16:42:20,186 iteration 2251 : loss : 0.091657, loss_ce: 0.026736
2021-12-17 16:42:21,567 iteration 2252 : loss : 0.102090, loss_ce: 0.028094
2021-12-17 16:42:22,885 iteration 2253 : loss : 0.102577, loss_ce: 0.027775
2021-12-17 16:42:24,306 iteration 2254 : loss : 0.116899, loss_ce: 0.041983
2021-12-17 16:42:25,717 iteration 2255 : loss : 0.093962, loss_ce: 0.032298
2021-12-17 16:42:27,143 iteration 2256 : loss : 0.092008, loss_ce: 0.026384
2021-12-17 16:42:28,474 iteration 2257 : loss : 0.096095, loss_ce: 0.024346
2021-12-17 16:42:29,833 iteration 2258 : loss : 0.101468, loss_ce: 0.030831
2021-12-17 16:42:31,239 iteration 2259 : loss : 0.108480, loss_ce: 0.031631
2021-12-17 16:42:32,614 iteration 2260 : loss : 0.100385, loss_ce: 0.027607
2021-12-17 16:42:33,938 iteration 2261 : loss : 0.105193, loss_ce: 0.023466
 33%|█████████▋                   | 133/400 [57:53<1:48:41, 24.42s/it]2021-12-17 16:42:35,469 iteration 2262 : loss : 0.097512, loss_ce: 0.030901
2021-12-17 16:42:36,851 iteration 2263 : loss : 0.088688, loss_ce: 0.028188
2021-12-17 16:42:38,248 iteration 2264 : loss : 0.093421, loss_ce: 0.021415
2021-12-17 16:42:39,643 iteration 2265 : loss : 0.088312, loss_ce: 0.026409
2021-12-17 16:42:40,996 iteration 2266 : loss : 0.093263, loss_ce: 0.026298
2021-12-17 16:42:42,367 iteration 2267 : loss : 0.090563, loss_ce: 0.022692
2021-12-17 16:42:43,660 iteration 2268 : loss : 0.090623, loss_ce: 0.030356
2021-12-17 16:42:45,036 iteration 2269 : loss : 0.120247, loss_ce: 0.049824
2021-12-17 16:42:46,346 iteration 2270 : loss : 0.097781, loss_ce: 0.027724
2021-12-17 16:42:47,683 iteration 2271 : loss : 0.101031, loss_ce: 0.044819
2021-12-17 16:42:49,010 iteration 2272 : loss : 0.094157, loss_ce: 0.021707
2021-12-17 16:42:50,422 iteration 2273 : loss : 0.100917, loss_ce: 0.026216
2021-12-17 16:42:51,735 iteration 2274 : loss : 0.086525, loss_ce: 0.021234
2021-12-17 16:42:53,078 iteration 2275 : loss : 0.092428, loss_ce: 0.032384
2021-12-17 16:42:54,481 iteration 2276 : loss : 0.108003, loss_ce: 0.028677
2021-12-17 16:42:55,818 iteration 2277 : loss : 0.088691, loss_ce: 0.029921
2021-12-17 16:42:57,175 iteration 2278 : loss : 0.085857, loss_ce: 0.027491
 34%|█████████▋                   | 134/400 [58:16<1:46:42, 24.07s/it]2021-12-17 16:42:58,678 iteration 2279 : loss : 0.103468, loss_ce: 0.039036
2021-12-17 16:43:00,063 iteration 2280 : loss : 0.097172, loss_ce: 0.035113
2021-12-17 16:43:01,358 iteration 2281 : loss : 0.082290, loss_ce: 0.022440
2021-12-17 16:43:02,821 iteration 2282 : loss : 0.099154, loss_ce: 0.026940
2021-12-17 16:43:04,139 iteration 2283 : loss : 0.086520, loss_ce: 0.022939
2021-12-17 16:43:05,584 iteration 2284 : loss : 0.115757, loss_ce: 0.033690
2021-12-17 16:43:06,908 iteration 2285 : loss : 0.080664, loss_ce: 0.021683
2021-12-17 16:43:08,249 iteration 2286 : loss : 0.079389, loss_ce: 0.020181
2021-12-17 16:43:09,654 iteration 2287 : loss : 0.100928, loss_ce: 0.027951
2021-12-17 16:43:10,958 iteration 2288 : loss : 0.091864, loss_ce: 0.029035
2021-12-17 16:43:12,351 iteration 2289 : loss : 0.087264, loss_ce: 0.023440
2021-12-17 16:43:13,730 iteration 2290 : loss : 0.088683, loss_ce: 0.024524
2021-12-17 16:43:15,087 iteration 2291 : loss : 0.086076, loss_ce: 0.023429
2021-12-17 16:43:16,507 iteration 2292 : loss : 0.107464, loss_ce: 0.029967
2021-12-17 16:43:17,805 iteration 2293 : loss : 0.096475, loss_ce: 0.032918
2021-12-17 16:43:19,146 iteration 2294 : loss : 0.097460, loss_ce: 0.034544
2021-12-17 16:43:19,146 Training Data Eval:
2021-12-17 16:43:26,226   Average segmentation loss on training set: 0.0734
2021-12-17 16:43:26,227 Validation Data Eval:
2021-12-17 16:43:28,735   Average segmentation loss on validation set: 0.1560
2021-12-17 16:43:30,127 iteration 2295 : loss : 0.085283, loss_ce: 0.024772
 34%|█████████▊                   | 135/400 [58:49<1:58:04, 26.73s/it]2021-12-17 16:43:31,554 iteration 2296 : loss : 0.093644, loss_ce: 0.028951
2021-12-17 16:43:32,926 iteration 2297 : loss : 0.093569, loss_ce: 0.021006
2021-12-17 16:43:34,393 iteration 2298 : loss : 0.108195, loss_ce: 0.029861
2021-12-17 16:43:35,734 iteration 2299 : loss : 0.083902, loss_ce: 0.016459
2021-12-17 16:43:37,162 iteration 2300 : loss : 0.113894, loss_ce: 0.033614
2021-12-17 16:43:38,508 iteration 2301 : loss : 0.098902, loss_ce: 0.036480
2021-12-17 16:43:39,856 iteration 2302 : loss : 0.083440, loss_ce: 0.025759
2021-12-17 16:43:41,180 iteration 2303 : loss : 0.097429, loss_ce: 0.024537
2021-12-17 16:43:42,467 iteration 2304 : loss : 0.089869, loss_ce: 0.027721
2021-12-17 16:43:43,859 iteration 2305 : loss : 0.087962, loss_ce: 0.020531
2021-12-17 16:43:45,186 iteration 2306 : loss : 0.094090, loss_ce: 0.026509
2021-12-17 16:43:46,499 iteration 2307 : loss : 0.091124, loss_ce: 0.026756
2021-12-17 16:43:47,846 iteration 2308 : loss : 0.089927, loss_ce: 0.033084
2021-12-17 16:43:49,241 iteration 2309 : loss : 0.086528, loss_ce: 0.028460
2021-12-17 16:43:50,636 iteration 2310 : loss : 0.098379, loss_ce: 0.033719
2021-12-17 16:43:52,084 iteration 2311 : loss : 0.103996, loss_ce: 0.032467
2021-12-17 16:43:53,455 iteration 2312 : loss : 0.117657, loss_ce: 0.040238
 34%|█████████▊                   | 136/400 [59:12<1:53:07, 25.71s/it]2021-12-17 16:43:54,856 iteration 2313 : loss : 0.088484, loss_ce: 0.032579
2021-12-17 16:43:56,160 iteration 2314 : loss : 0.103187, loss_ce: 0.033943
2021-12-17 16:43:57,530 iteration 2315 : loss : 0.074568, loss_ce: 0.019125
2021-12-17 16:43:58,932 iteration 2316 : loss : 0.092052, loss_ce: 0.035814
2021-12-17 16:44:00,219 iteration 2317 : loss : 0.105369, loss_ce: 0.029396
2021-12-17 16:44:01,635 iteration 2318 : loss : 0.082388, loss_ce: 0.027699
2021-12-17 16:44:03,075 iteration 2319 : loss : 0.103445, loss_ce: 0.029160
2021-12-17 16:44:04,393 iteration 2320 : loss : 0.086631, loss_ce: 0.029950
2021-12-17 16:44:05,752 iteration 2321 : loss : 0.100684, loss_ce: 0.024753
2021-12-17 16:44:07,133 iteration 2322 : loss : 0.098518, loss_ce: 0.031295
2021-12-17 16:44:08,559 iteration 2323 : loss : 0.104664, loss_ce: 0.027346
2021-12-17 16:44:09,931 iteration 2324 : loss : 0.091982, loss_ce: 0.022813
2021-12-17 16:44:11,286 iteration 2325 : loss : 0.087100, loss_ce: 0.031109
2021-12-17 16:44:12,676 iteration 2326 : loss : 0.098940, loss_ce: 0.041421
2021-12-17 16:44:14,013 iteration 2327 : loss : 0.081807, loss_ce: 0.021943
2021-12-17 16:44:15,455 iteration 2328 : loss : 0.093450, loss_ce: 0.025249
2021-12-17 16:44:16,808 iteration 2329 : loss : 0.092229, loss_ce: 0.025080
 34%|█████████▉                   | 137/400 [59:35<1:49:36, 25.00s/it]2021-12-17 16:44:18,215 iteration 2330 : loss : 0.084667, loss_ce: 0.025712
2021-12-17 16:44:19,537 iteration 2331 : loss : 0.096056, loss_ce: 0.019453
2021-12-17 16:44:20,977 iteration 2332 : loss : 0.099645, loss_ce: 0.037046
2021-12-17 16:44:22,284 iteration 2333 : loss : 0.086495, loss_ce: 0.032161
2021-12-17 16:44:23,634 iteration 2334 : loss : 0.081502, loss_ce: 0.016138
2021-12-17 16:44:25,100 iteration 2335 : loss : 0.142755, loss_ce: 0.050919
2021-12-17 16:44:26,442 iteration 2336 : loss : 0.089655, loss_ce: 0.032060
2021-12-17 16:44:27,820 iteration 2337 : loss : 0.087736, loss_ce: 0.024321
2021-12-17 16:44:29,212 iteration 2338 : loss : 0.094725, loss_ce: 0.025057
2021-12-17 16:44:30,564 iteration 2339 : loss : 0.106758, loss_ce: 0.032645
2021-12-17 16:44:31,961 iteration 2340 : loss : 0.093077, loss_ce: 0.031882
2021-12-17 16:44:33,339 iteration 2341 : loss : 0.101802, loss_ce: 0.029200
2021-12-17 16:44:34,735 iteration 2342 : loss : 0.089510, loss_ce: 0.026900
2021-12-17 16:44:36,105 iteration 2343 : loss : 0.093109, loss_ce: 0.030648
2021-12-17 16:44:37,398 iteration 2344 : loss : 0.089297, loss_ce: 0.027262
2021-12-17 16:44:38,729 iteration 2345 : loss : 0.082696, loss_ce: 0.026618
2021-12-17 16:44:40,027 iteration 2346 : loss : 0.102974, loss_ce: 0.032228
 34%|██████████                   | 138/400 [59:59<1:46:50, 24.47s/it]2021-12-17 16:44:41,476 iteration 2347 : loss : 0.106065, loss_ce: 0.031223
2021-12-17 16:44:42,803 iteration 2348 : loss : 0.083287, loss_ce: 0.022030
2021-12-17 16:44:44,173 iteration 2349 : loss : 0.106982, loss_ce: 0.042976
2021-12-17 16:44:45,471 iteration 2350 : loss : 0.085463, loss_ce: 0.030114
2021-12-17 16:44:46,867 iteration 2351 : loss : 0.110294, loss_ce: 0.027413
2021-12-17 16:44:48,314 iteration 2352 : loss : 0.105647, loss_ce: 0.036333
2021-12-17 16:44:49,595 iteration 2353 : loss : 0.080807, loss_ce: 0.027626
2021-12-17 16:44:50,975 iteration 2354 : loss : 0.086826, loss_ce: 0.020816
2021-12-17 16:44:52,291 iteration 2355 : loss : 0.090868, loss_ce: 0.027796
2021-12-17 16:44:53,741 iteration 2356 : loss : 0.109913, loss_ce: 0.038502
2021-12-17 16:44:55,159 iteration 2357 : loss : 0.094121, loss_ce: 0.032632
2021-12-17 16:44:56,596 iteration 2358 : loss : 0.117349, loss_ce: 0.035013
2021-12-17 16:44:58,009 iteration 2359 : loss : 0.096047, loss_ce: 0.020693
2021-12-17 16:44:59,282 iteration 2360 : loss : 0.105391, loss_ce: 0.017985
2021-12-17 16:45:00,585 iteration 2361 : loss : 0.082336, loss_ce: 0.023315
2021-12-17 16:45:01,947 iteration 2362 : loss : 0.088780, loss_ce: 0.026840
2021-12-17 16:45:03,311 iteration 2363 : loss : 0.086442, loss_ce: 0.024078
 35%|█████████▍                 | 139/400 [1:00:22<1:44:53, 24.11s/it]2021-12-17 16:45:04,732 iteration 2364 : loss : 0.096108, loss_ce: 0.031009
2021-12-17 16:45:06,034 iteration 2365 : loss : 0.093489, loss_ce: 0.026489
2021-12-17 16:45:07,411 iteration 2366 : loss : 0.085367, loss_ce: 0.029686
2021-12-17 16:45:08,759 iteration 2367 : loss : 0.096619, loss_ce: 0.023139
2021-12-17 16:45:10,207 iteration 2368 : loss : 0.088526, loss_ce: 0.018335
2021-12-17 16:45:11,547 iteration 2369 : loss : 0.096983, loss_ce: 0.026521
2021-12-17 16:45:12,875 iteration 2370 : loss : 0.076583, loss_ce: 0.019416
2021-12-17 16:45:14,252 iteration 2371 : loss : 0.097081, loss_ce: 0.031370
2021-12-17 16:45:15,549 iteration 2372 : loss : 0.084433, loss_ce: 0.030063
2021-12-17 16:45:16,916 iteration 2373 : loss : 0.081856, loss_ce: 0.020285
2021-12-17 16:45:18,323 iteration 2374 : loss : 0.085189, loss_ce: 0.024404
2021-12-17 16:45:19,639 iteration 2375 : loss : 0.077420, loss_ce: 0.019301
2021-12-17 16:45:21,055 iteration 2376 : loss : 0.097368, loss_ce: 0.033523
2021-12-17 16:45:22,411 iteration 2377 : loss : 0.083326, loss_ce: 0.017923
2021-12-17 16:45:23,871 iteration 2378 : loss : 0.106413, loss_ce: 0.040644
2021-12-17 16:45:25,264 iteration 2379 : loss : 0.099920, loss_ce: 0.025384
2021-12-17 16:45:25,264 Training Data Eval:
2021-12-17 16:45:32,329   Average segmentation loss on training set: 0.0695
2021-12-17 16:45:32,329 Validation Data Eval:
2021-12-17 16:45:34,798   Average segmentation loss on validation set: 0.1585
2021-12-17 16:45:36,284 iteration 2380 : loss : 0.091326, loss_ce: 0.027148
 35%|█████████▍                 | 140/400 [1:00:55<1:55:59, 26.77s/it]2021-12-17 16:45:37,667 iteration 2381 : loss : 0.091042, loss_ce: 0.022566
2021-12-17 16:45:39,079 iteration 2382 : loss : 0.097021, loss_ce: 0.036372
2021-12-17 16:45:40,488 iteration 2383 : loss : 0.090559, loss_ce: 0.029533
2021-12-17 16:45:41,848 iteration 2384 : loss : 0.092967, loss_ce: 0.024179
2021-12-17 16:45:43,225 iteration 2385 : loss : 0.110218, loss_ce: 0.047139
2021-12-17 16:45:44,662 iteration 2386 : loss : 0.099483, loss_ce: 0.027053
2021-12-17 16:45:45,989 iteration 2387 : loss : 0.090123, loss_ce: 0.026914
2021-12-17 16:45:47,366 iteration 2388 : loss : 0.082863, loss_ce: 0.024971
2021-12-17 16:45:48,734 iteration 2389 : loss : 0.097261, loss_ce: 0.026890
2021-12-17 16:45:50,106 iteration 2390 : loss : 0.075654, loss_ce: 0.023454
2021-12-17 16:45:51,431 iteration 2391 : loss : 0.087779, loss_ce: 0.023882
2021-12-17 16:45:52,748 iteration 2392 : loss : 0.077507, loss_ce: 0.022569
2021-12-17 16:45:54,079 iteration 2393 : loss : 0.084050, loss_ce: 0.027978
2021-12-17 16:45:55,461 iteration 2394 : loss : 0.115861, loss_ce: 0.024398
2021-12-17 16:45:56,943 iteration 2395 : loss : 0.097119, loss_ce: 0.025149
2021-12-17 16:45:58,380 iteration 2396 : loss : 0.085733, loss_ce: 0.028231
2021-12-17 16:45:59,755 iteration 2397 : loss : 0.092802, loss_ce: 0.024496
 35%|█████████▌                 | 141/400 [1:01:18<1:51:17, 25.78s/it]2021-12-17 16:46:01,262 iteration 2398 : loss : 0.117550, loss_ce: 0.046843
2021-12-17 16:46:02,555 iteration 2399 : loss : 0.077835, loss_ce: 0.022183
2021-12-17 16:46:03,906 iteration 2400 : loss : 0.093669, loss_ce: 0.021896
2021-12-17 16:46:05,283 iteration 2401 : loss : 0.091025, loss_ce: 0.028327
2021-12-17 16:46:06,663 iteration 2402 : loss : 0.086147, loss_ce: 0.025656
2021-12-17 16:46:08,023 iteration 2403 : loss : 0.079045, loss_ce: 0.021832
2021-12-17 16:46:09,365 iteration 2404 : loss : 0.087135, loss_ce: 0.032247
2021-12-17 16:46:10,724 iteration 2405 : loss : 0.099203, loss_ce: 0.029279
2021-12-17 16:46:12,149 iteration 2406 : loss : 0.093321, loss_ce: 0.029405
2021-12-17 16:46:13,465 iteration 2407 : loss : 0.082576, loss_ce: 0.022983
2021-12-17 16:46:14,823 iteration 2408 : loss : 0.090029, loss_ce: 0.028622
2021-12-17 16:46:16,186 iteration 2409 : loss : 0.095428, loss_ce: 0.027616
2021-12-17 16:46:17,586 iteration 2410 : loss : 0.105434, loss_ce: 0.020933
2021-12-17 16:46:18,897 iteration 2411 : loss : 0.085383, loss_ce: 0.021134
2021-12-17 16:46:20,316 iteration 2412 : loss : 0.104054, loss_ce: 0.031941
2021-12-17 16:46:21,763 iteration 2413 : loss : 0.103797, loss_ce: 0.041247
2021-12-17 16:46:23,169 iteration 2414 : loss : 0.109450, loss_ce: 0.037182
 36%|█████████▌                 | 142/400 [1:01:42<1:47:47, 25.07s/it]2021-12-17 16:46:24,591 iteration 2415 : loss : 0.077991, loss_ce: 0.017605
2021-12-17 16:46:25,943 iteration 2416 : loss : 0.098993, loss_ce: 0.034727
2021-12-17 16:46:27,316 iteration 2417 : loss : 0.084505, loss_ce: 0.021481
2021-12-17 16:46:28,703 iteration 2418 : loss : 0.094268, loss_ce: 0.024264
2021-12-17 16:46:30,074 iteration 2419 : loss : 0.091106, loss_ce: 0.034130
2021-12-17 16:46:31,390 iteration 2420 : loss : 0.087366, loss_ce: 0.027915
2021-12-17 16:46:32,872 iteration 2421 : loss : 0.090409, loss_ce: 0.020875
2021-12-17 16:46:34,277 iteration 2422 : loss : 0.089488, loss_ce: 0.026151
2021-12-17 16:46:35,658 iteration 2423 : loss : 0.104837, loss_ce: 0.037510
2021-12-17 16:46:36,970 iteration 2424 : loss : 0.083323, loss_ce: 0.024394
2021-12-17 16:46:38,407 iteration 2425 : loss : 0.088866, loss_ce: 0.033132
2021-12-17 16:46:39,762 iteration 2426 : loss : 0.085536, loss_ce: 0.024968
2021-12-17 16:46:41,222 iteration 2427 : loss : 0.109965, loss_ce: 0.033997
2021-12-17 16:46:42,655 iteration 2428 : loss : 0.094390, loss_ce: 0.031048
2021-12-17 16:46:44,093 iteration 2429 : loss : 0.098653, loss_ce: 0.027467
2021-12-17 16:46:45,465 iteration 2430 : loss : 0.091182, loss_ce: 0.029096
2021-12-17 16:46:46,799 iteration 2431 : loss : 0.082412, loss_ce: 0.027085
 36%|█████████▋                 | 143/400 [1:02:05<1:45:33, 24.64s/it]2021-12-17 16:46:48,264 iteration 2432 : loss : 0.095292, loss_ce: 0.033422
2021-12-17 16:46:49,641 iteration 2433 : loss : 0.106945, loss_ce: 0.032461
2021-12-17 16:46:51,006 iteration 2434 : loss : 0.071846, loss_ce: 0.016339
2021-12-17 16:46:52,485 iteration 2435 : loss : 0.110389, loss_ce: 0.050623
2021-12-17 16:46:53,773 iteration 2436 : loss : 0.086431, loss_ce: 0.024425
2021-12-17 16:46:55,087 iteration 2437 : loss : 0.075065, loss_ce: 0.020105
2021-12-17 16:46:56,575 iteration 2438 : loss : 0.084313, loss_ce: 0.025321
2021-12-17 16:46:57,966 iteration 2439 : loss : 0.095751, loss_ce: 0.033222
2021-12-17 16:46:59,330 iteration 2440 : loss : 0.078090, loss_ce: 0.021151
2021-12-17 16:47:00,671 iteration 2441 : loss : 0.095272, loss_ce: 0.021394
2021-12-17 16:47:02,004 iteration 2442 : loss : 0.084548, loss_ce: 0.023779
2021-12-17 16:47:03,311 iteration 2443 : loss : 0.079607, loss_ce: 0.026206
2021-12-17 16:47:04,712 iteration 2444 : loss : 0.077549, loss_ce: 0.022703
2021-12-17 16:47:05,999 iteration 2445 : loss : 0.127899, loss_ce: 0.019089
2021-12-17 16:47:07,458 iteration 2446 : loss : 0.087567, loss_ce: 0.028312
2021-12-17 16:47:08,877 iteration 2447 : loss : 0.094342, loss_ce: 0.033629
2021-12-17 16:47:10,249 iteration 2448 : loss : 0.087498, loss_ce: 0.024054
 36%|█████████▋                 | 144/400 [1:02:29<1:43:36, 24.28s/it]2021-12-17 16:47:11,647 iteration 2449 : loss : 0.087572, loss_ce: 0.028560
2021-12-17 16:47:13,072 iteration 2450 : loss : 0.103107, loss_ce: 0.030602
2021-12-17 16:47:14,498 iteration 2451 : loss : 0.112714, loss_ce: 0.034392
2021-12-17 16:47:15,799 iteration 2452 : loss : 0.084512, loss_ce: 0.028359
2021-12-17 16:47:17,153 iteration 2453 : loss : 0.088652, loss_ce: 0.019822
2021-12-17 16:47:18,549 iteration 2454 : loss : 0.096426, loss_ce: 0.035748
2021-12-17 16:47:19,937 iteration 2455 : loss : 0.088969, loss_ce: 0.032671
2021-12-17 16:47:21,427 iteration 2456 : loss : 0.127741, loss_ce: 0.040698
2021-12-17 16:47:22,796 iteration 2457 : loss : 0.090217, loss_ce: 0.024562
2021-12-17 16:47:24,233 iteration 2458 : loss : 0.086637, loss_ce: 0.023184
2021-12-17 16:47:25,567 iteration 2459 : loss : 0.105666, loss_ce: 0.029519
2021-12-17 16:47:26,931 iteration 2460 : loss : 0.092002, loss_ce: 0.020752
2021-12-17 16:47:28,320 iteration 2461 : loss : 0.113026, loss_ce: 0.031939
2021-12-17 16:47:29,680 iteration 2462 : loss : 0.086379, loss_ce: 0.031278
2021-12-17 16:47:31,071 iteration 2463 : loss : 0.087807, loss_ce: 0.024577
2021-12-17 16:47:32,513 iteration 2464 : loss : 0.086751, loss_ce: 0.029198
2021-12-17 16:47:32,513 Training Data Eval:
2021-12-17 16:47:39,600   Average segmentation loss on training set: 0.0714
2021-12-17 16:47:39,600 Validation Data Eval:
2021-12-17 16:47:42,090   Average segmentation loss on validation set: 0.1466
2021-12-17 16:47:48,703 Found new lowest validation loss at iteration 2464! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/TU_3seeds/TU_RESNET_no_pretraining_SGD_best_val_loss_seed100.pth
2021-12-17 16:47:50,063 iteration 2465 : loss : 0.077410, loss_ce: 0.019840
 36%|█████████▊                 | 145/400 [1:03:09<2:02:59, 28.94s/it]2021-12-17 16:47:51,410 iteration 2466 : loss : 0.077419, loss_ce: 0.022970
2021-12-17 16:47:52,769 iteration 2467 : loss : 0.098117, loss_ce: 0.044415
2021-12-17 16:47:54,050 iteration 2468 : loss : 0.081358, loss_ce: 0.026806
2021-12-17 16:47:55,297 iteration 2469 : loss : 0.075983, loss_ce: 0.026030
2021-12-17 16:47:56,656 iteration 2470 : loss : 0.105921, loss_ce: 0.033184
2021-12-17 16:47:58,023 iteration 2471 : loss : 0.085912, loss_ce: 0.027723
2021-12-17 16:47:59,434 iteration 2472 : loss : 0.097573, loss_ce: 0.029372
2021-12-17 16:48:00,691 iteration 2473 : loss : 0.085479, loss_ce: 0.025982
2021-12-17 16:48:02,043 iteration 2474 : loss : 0.089271, loss_ce: 0.024550
2021-12-17 16:48:03,302 iteration 2475 : loss : 0.077397, loss_ce: 0.025019
2021-12-17 16:48:04,696 iteration 2476 : loss : 0.113597, loss_ce: 0.026770
2021-12-17 16:48:06,009 iteration 2477 : loss : 0.075858, loss_ce: 0.022865
2021-12-17 16:48:07,319 iteration 2478 : loss : 0.083629, loss_ce: 0.020689
2021-12-17 16:48:08,753 iteration 2479 : loss : 0.096502, loss_ce: 0.023655
2021-12-17 16:48:10,146 iteration 2480 : loss : 0.093650, loss_ce: 0.028029
2021-12-17 16:48:11,448 iteration 2481 : loss : 0.086642, loss_ce: 0.028519
2021-12-17 16:48:12,776 iteration 2482 : loss : 0.083923, loss_ce: 0.025522
 36%|█████████▊                 | 146/400 [1:03:31<1:54:37, 27.08s/it]2021-12-17 16:48:14,167 iteration 2483 : loss : 0.085894, loss_ce: 0.028409
2021-12-17 16:48:15,552 iteration 2484 : loss : 0.093387, loss_ce: 0.024545
2021-12-17 16:48:16,996 iteration 2485 : loss : 0.110563, loss_ce: 0.034156
2021-12-17 16:48:18,337 iteration 2486 : loss : 0.074626, loss_ce: 0.023799
2021-12-17 16:48:19,715 iteration 2487 : loss : 0.083150, loss_ce: 0.024381
2021-12-17 16:48:21,170 iteration 2488 : loss : 0.111841, loss_ce: 0.024219
2021-12-17 16:48:22,621 iteration 2489 : loss : 0.088686, loss_ce: 0.031213
2021-12-17 16:48:23,991 iteration 2490 : loss : 0.086354, loss_ce: 0.026583
2021-12-17 16:48:25,411 iteration 2491 : loss : 0.087682, loss_ce: 0.026761
2021-12-17 16:48:26,762 iteration 2492 : loss : 0.094116, loss_ce: 0.030004
2021-12-17 16:48:28,124 iteration 2493 : loss : 0.081155, loss_ce: 0.019734
2021-12-17 16:48:29,466 iteration 2494 : loss : 0.082624, loss_ce: 0.026719
2021-12-17 16:48:30,834 iteration 2495 : loss : 0.084113, loss_ce: 0.021658
2021-12-17 16:48:32,253 iteration 2496 : loss : 0.091458, loss_ce: 0.021022
2021-12-17 16:48:33,621 iteration 2497 : loss : 0.090922, loss_ce: 0.028224
2021-12-17 16:48:34,934 iteration 2498 : loss : 0.080117, loss_ce: 0.026847
2021-12-17 16:48:36,376 iteration 2499 : loss : 0.085714, loss_ce: 0.029530
 37%|█████████▉                 | 147/400 [1:03:55<1:49:44, 26.03s/it]2021-12-17 16:48:37,826 iteration 2500 : loss : 0.086825, loss_ce: 0.026047
2021-12-17 16:48:39,161 iteration 2501 : loss : 0.091286, loss_ce: 0.024093
2021-12-17 16:48:40,532 iteration 2502 : loss : 0.110313, loss_ce: 0.036499
2021-12-17 16:48:41,919 iteration 2503 : loss : 0.101424, loss_ce: 0.044919
2021-12-17 16:48:43,319 iteration 2504 : loss : 0.091569, loss_ce: 0.025326
2021-12-17 16:48:44,646 iteration 2505 : loss : 0.077449, loss_ce: 0.022311
2021-12-17 16:48:45,996 iteration 2506 : loss : 0.090569, loss_ce: 0.017899
2021-12-17 16:48:47,408 iteration 2507 : loss : 0.079374, loss_ce: 0.022392
2021-12-17 16:48:48,780 iteration 2508 : loss : 0.079566, loss_ce: 0.026414
2021-12-17 16:48:50,218 iteration 2509 : loss : 0.103932, loss_ce: 0.034495
2021-12-17 16:48:51,584 iteration 2510 : loss : 0.105571, loss_ce: 0.032508
2021-12-17 16:48:52,906 iteration 2511 : loss : 0.080211, loss_ce: 0.027447
2021-12-17 16:48:54,336 iteration 2512 : loss : 0.089183, loss_ce: 0.024550
2021-12-17 16:48:55,684 iteration 2513 : loss : 0.082177, loss_ce: 0.023035
2021-12-17 16:48:57,087 iteration 2514 : loss : 0.091484, loss_ce: 0.025027
2021-12-17 16:48:58,427 iteration 2515 : loss : 0.080507, loss_ce: 0.027459
2021-12-17 16:48:59,952 iteration 2516 : loss : 0.092858, loss_ce: 0.029699
 37%|█████████▉                 | 148/400 [1:04:19<1:46:15, 25.30s/it]2021-12-17 16:49:01,404 iteration 2517 : loss : 0.093811, loss_ce: 0.026843
2021-12-17 16:49:02,807 iteration 2518 : loss : 0.112151, loss_ce: 0.027265
2021-12-17 16:49:04,118 iteration 2519 : loss : 0.076001, loss_ce: 0.019479
2021-12-17 16:49:05,534 iteration 2520 : loss : 0.094913, loss_ce: 0.035539
2021-12-17 16:49:06,927 iteration 2521 : loss : 0.084755, loss_ce: 0.029493
2021-12-17 16:49:08,321 iteration 2522 : loss : 0.094072, loss_ce: 0.028229
2021-12-17 16:49:09,698 iteration 2523 : loss : 0.096168, loss_ce: 0.024076
2021-12-17 16:49:11,115 iteration 2524 : loss : 0.085529, loss_ce: 0.029563
2021-12-17 16:49:12,472 iteration 2525 : loss : 0.079288, loss_ce: 0.019863
2021-12-17 16:49:13,794 iteration 2526 : loss : 0.080871, loss_ce: 0.023403
2021-12-17 16:49:15,187 iteration 2527 : loss : 0.093935, loss_ce: 0.038042
2021-12-17 16:49:16,557 iteration 2528 : loss : 0.080357, loss_ce: 0.026668
2021-12-17 16:49:17,956 iteration 2529 : loss : 0.084938, loss_ce: 0.023203
2021-12-17 16:49:19,280 iteration 2530 : loss : 0.081077, loss_ce: 0.024202
2021-12-17 16:49:20,689 iteration 2531 : loss : 0.085916, loss_ce: 0.021965
2021-12-17 16:49:22,146 iteration 2532 : loss : 0.093518, loss_ce: 0.033912
2021-12-17 16:49:23,466 iteration 2533 : loss : 0.114557, loss_ce: 0.022052
 37%|██████████                 | 149/400 [1:04:42<1:43:34, 24.76s/it]2021-12-17 16:49:24,900 iteration 2534 : loss : 0.088363, loss_ce: 0.025261
2021-12-17 16:49:26,187 iteration 2535 : loss : 0.091191, loss_ce: 0.031283
2021-12-17 16:49:27,520 iteration 2536 : loss : 0.070945, loss_ce: 0.021101
2021-12-17 16:49:28,985 iteration 2537 : loss : 0.090402, loss_ce: 0.035249
2021-12-17 16:49:30,248 iteration 2538 : loss : 0.083144, loss_ce: 0.024081
2021-12-17 16:49:31,556 iteration 2539 : loss : 0.075253, loss_ce: 0.022729
2021-12-17 16:49:32,926 iteration 2540 : loss : 0.101923, loss_ce: 0.039148
2021-12-17 16:49:34,367 iteration 2541 : loss : 0.095970, loss_ce: 0.024901
2021-12-17 16:49:35,733 iteration 2542 : loss : 0.090101, loss_ce: 0.023222
2021-12-17 16:49:37,183 iteration 2543 : loss : 0.113377, loss_ce: 0.029086
2021-12-17 16:49:38,629 iteration 2544 : loss : 0.098695, loss_ce: 0.028429
2021-12-17 16:49:39,964 iteration 2545 : loss : 0.084909, loss_ce: 0.027044
2021-12-17 16:49:41,506 iteration 2546 : loss : 0.129745, loss_ce: 0.043254
2021-12-17 16:49:42,925 iteration 2547 : loss : 0.098154, loss_ce: 0.028236
2021-12-17 16:49:44,364 iteration 2548 : loss : 0.089099, loss_ce: 0.032721
2021-12-17 16:49:45,724 iteration 2549 : loss : 0.094330, loss_ce: 0.027050
2021-12-17 16:49:45,724 Training Data Eval:
2021-12-17 16:49:52,860   Average segmentation loss on training set: 0.0670
2021-12-17 16:49:52,861 Validation Data Eval:
2021-12-17 16:49:55,356   Average segmentation loss on validation set: 0.1518
2021-12-17 16:49:56,760 iteration 2550 : loss : 0.083650, loss_ce: 0.016263
 38%|██████████▏                | 150/400 [1:05:15<1:53:49, 27.32s/it]2021-12-17 16:49:58,197 iteration 2551 : loss : 0.093562, loss_ce: 0.028044
2021-12-17 16:49:59,602 iteration 2552 : loss : 0.078649, loss_ce: 0.024550
2021-12-17 16:50:00,994 iteration 2553 : loss : 0.072645, loss_ce: 0.019168
2021-12-17 16:50:02,351 iteration 2554 : loss : 0.084704, loss_ce: 0.023381
2021-12-17 16:50:03,701 iteration 2555 : loss : 0.086294, loss_ce: 0.025281
2021-12-17 16:50:05,077 iteration 2556 : loss : 0.079162, loss_ce: 0.025477
2021-12-17 16:50:06,437 iteration 2557 : loss : 0.078171, loss_ce: 0.022656
2021-12-17 16:50:07,791 iteration 2558 : loss : 0.079418, loss_ce: 0.021379
2021-12-17 16:50:09,108 iteration 2559 : loss : 0.116021, loss_ce: 0.054263
2021-12-17 16:50:10,572 iteration 2560 : loss : 0.085266, loss_ce: 0.025064
2021-12-17 16:50:11,937 iteration 2561 : loss : 0.101763, loss_ce: 0.031382
2021-12-17 16:50:13,335 iteration 2562 : loss : 0.083898, loss_ce: 0.026868
2021-12-17 16:50:14,648 iteration 2563 : loss : 0.099858, loss_ce: 0.034450
2021-12-17 16:50:15,979 iteration 2564 : loss : 0.081318, loss_ce: 0.029258
2021-12-17 16:50:17,308 iteration 2565 : loss : 0.068556, loss_ce: 0.019758
2021-12-17 16:50:18,622 iteration 2566 : loss : 0.081162, loss_ce: 0.022271
2021-12-17 16:50:19,988 iteration 2567 : loss : 0.098259, loss_ce: 0.020367
 38%|██████████▏                | 151/400 [1:05:39<1:48:17, 26.10s/it]2021-12-17 16:50:21,397 iteration 2568 : loss : 0.088819, loss_ce: 0.030013
2021-12-17 16:50:22,757 iteration 2569 : loss : 0.073163, loss_ce: 0.019824
2021-12-17 16:50:24,203 iteration 2570 : loss : 0.108094, loss_ce: 0.035055
2021-12-17 16:50:25,559 iteration 2571 : loss : 0.078869, loss_ce: 0.018550
2021-12-17 16:50:26,863 iteration 2572 : loss : 0.081079, loss_ce: 0.021544
2021-12-17 16:50:28,212 iteration 2573 : loss : 0.078046, loss_ce: 0.021705
2021-12-17 16:50:29,545 iteration 2574 : loss : 0.086524, loss_ce: 0.025507
2021-12-17 16:50:30,876 iteration 2575 : loss : 0.080664, loss_ce: 0.018673
2021-12-17 16:50:32,178 iteration 2576 : loss : 0.073944, loss_ce: 0.017488
2021-12-17 16:50:33,574 iteration 2577 : loss : 0.090588, loss_ce: 0.037014
2021-12-17 16:50:34,906 iteration 2578 : loss : 0.076000, loss_ce: 0.021591
2021-12-17 16:50:36,287 iteration 2579 : loss : 0.101235, loss_ce: 0.031883
2021-12-17 16:50:37,595 iteration 2580 : loss : 0.071805, loss_ce: 0.016024
2021-12-17 16:50:38,975 iteration 2581 : loss : 0.090157, loss_ce: 0.032610
2021-12-17 16:50:40,404 iteration 2582 : loss : 0.078443, loss_ce: 0.027961
2021-12-17 16:50:41,756 iteration 2583 : loss : 0.088895, loss_ce: 0.031416
2021-12-17 16:50:43,110 iteration 2584 : loss : 0.076476, loss_ce: 0.020021
 38%|██████████▎                | 152/400 [1:06:02<1:44:10, 25.20s/it]2021-12-17 16:50:44,539 iteration 2585 : loss : 0.092857, loss_ce: 0.027618
2021-12-17 16:50:46,058 iteration 2586 : loss : 0.103689, loss_ce: 0.034287
2021-12-17 16:50:47,494 iteration 2587 : loss : 0.099873, loss_ce: 0.028711
2021-12-17 16:50:48,866 iteration 2588 : loss : 0.096254, loss_ce: 0.029245
2021-12-17 16:50:50,173 iteration 2589 : loss : 0.082503, loss_ce: 0.019751
2021-12-17 16:50:51,582 iteration 2590 : loss : 0.107355, loss_ce: 0.030644
2021-12-17 16:50:52,934 iteration 2591 : loss : 0.077021, loss_ce: 0.023507
2021-12-17 16:50:54,256 iteration 2592 : loss : 0.077879, loss_ce: 0.028003
2021-12-17 16:50:55,541 iteration 2593 : loss : 0.076017, loss_ce: 0.023119
2021-12-17 16:50:56,916 iteration 2594 : loss : 0.086849, loss_ce: 0.030049
2021-12-17 16:50:58,228 iteration 2595 : loss : 0.077790, loss_ce: 0.022189
2021-12-17 16:50:59,573 iteration 2596 : loss : 0.092457, loss_ce: 0.025962
2021-12-17 16:51:00,919 iteration 2597 : loss : 0.079364, loss_ce: 0.020310
2021-12-17 16:51:02,292 iteration 2598 : loss : 0.084634, loss_ce: 0.026869
2021-12-17 16:51:03,675 iteration 2599 : loss : 0.083848, loss_ce: 0.026085
2021-12-17 16:51:05,002 iteration 2600 : loss : 0.089745, loss_ce: 0.027887
2021-12-17 16:51:06,320 iteration 2601 : loss : 0.080058, loss_ce: 0.022681
 38%|██████████▎                | 153/400 [1:06:25<1:41:17, 24.61s/it]2021-12-17 16:51:07,726 iteration 2602 : loss : 0.079294, loss_ce: 0.022892
2021-12-17 16:51:09,103 iteration 2603 : loss : 0.088839, loss_ce: 0.016781
2021-12-17 16:51:10,472 iteration 2604 : loss : 0.077048, loss_ce: 0.020399
2021-12-17 16:51:11,833 iteration 2605 : loss : 0.080073, loss_ce: 0.022476
2021-12-17 16:51:13,201 iteration 2606 : loss : 0.092770, loss_ce: 0.030329
2021-12-17 16:51:14,592 iteration 2607 : loss : 0.089256, loss_ce: 0.029244
2021-12-17 16:51:15,922 iteration 2608 : loss : 0.078340, loss_ce: 0.022895
2021-12-17 16:51:17,324 iteration 2609 : loss : 0.080166, loss_ce: 0.023190
2021-12-17 16:51:18,710 iteration 2610 : loss : 0.083835, loss_ce: 0.023886
2021-12-17 16:51:20,129 iteration 2611 : loss : 0.091599, loss_ce: 0.028197
2021-12-17 16:51:21,530 iteration 2612 : loss : 0.092822, loss_ce: 0.025636
2021-12-17 16:51:22,960 iteration 2613 : loss : 0.100804, loss_ce: 0.030449
2021-12-17 16:51:24,369 iteration 2614 : loss : 0.089978, loss_ce: 0.029224
2021-12-17 16:51:25,750 iteration 2615 : loss : 0.090735, loss_ce: 0.032165
2021-12-17 16:51:27,169 iteration 2616 : loss : 0.083583, loss_ce: 0.025392
2021-12-17 16:51:28,548 iteration 2617 : loss : 0.079146, loss_ce: 0.021807
2021-12-17 16:51:29,960 iteration 2618 : loss : 0.085829, loss_ce: 0.021598
 38%|██████████▍                | 154/400 [1:06:49<1:39:41, 24.32s/it]2021-12-17 16:51:31,493 iteration 2619 : loss : 0.101784, loss_ce: 0.034643
2021-12-17 16:51:32,858 iteration 2620 : loss : 0.102352, loss_ce: 0.030424
2021-12-17 16:51:34,118 iteration 2621 : loss : 0.088708, loss_ce: 0.028283
2021-12-17 16:51:35,503 iteration 2622 : loss : 0.117858, loss_ce: 0.034402
2021-12-17 16:51:36,841 iteration 2623 : loss : 0.074890, loss_ce: 0.022264
2021-12-17 16:51:38,255 iteration 2624 : loss : 0.110915, loss_ce: 0.037464
2021-12-17 16:51:39,678 iteration 2625 : loss : 0.085351, loss_ce: 0.029380
2021-12-17 16:51:41,074 iteration 2626 : loss : 0.082735, loss_ce: 0.026190
2021-12-17 16:51:42,387 iteration 2627 : loss : 0.079741, loss_ce: 0.027001
2021-12-17 16:51:43,718 iteration 2628 : loss : 0.079137, loss_ce: 0.023493
2021-12-17 16:51:45,027 iteration 2629 : loss : 0.099935, loss_ce: 0.023899
2021-12-17 16:51:46,439 iteration 2630 : loss : 0.098867, loss_ce: 0.014325
2021-12-17 16:51:47,743 iteration 2631 : loss : 0.090058, loss_ce: 0.036966
2021-12-17 16:51:49,055 iteration 2632 : loss : 0.080347, loss_ce: 0.018973
2021-12-17 16:51:50,433 iteration 2633 : loss : 0.068817, loss_ce: 0.019676
2021-12-17 16:51:51,782 iteration 2634 : loss : 0.078997, loss_ce: 0.020852
2021-12-17 16:51:51,782 Training Data Eval:
2021-12-17 16:51:58,911   Average segmentation loss on training set: 0.0657
2021-12-17 16:51:58,911 Validation Data Eval:
2021-12-17 16:52:01,400   Average segmentation loss on validation set: 0.1513
2021-12-17 16:52:02,746 iteration 2635 : loss : 0.092184, loss_ce: 0.028876
 39%|██████████▍                | 155/400 [1:07:21<1:49:39, 26.85s/it]2021-12-17 16:52:04,129 iteration 2636 : loss : 0.073948, loss_ce: 0.019641
2021-12-17 16:52:05,477 iteration 2637 : loss : 0.082200, loss_ce: 0.028946
2021-12-17 16:52:06,915 iteration 2638 : loss : 0.097873, loss_ce: 0.029306
2021-12-17 16:52:08,267 iteration 2639 : loss : 0.073599, loss_ce: 0.021289
2021-12-17 16:52:09,651 iteration 2640 : loss : 0.087846, loss_ce: 0.021728
2021-12-17 16:52:11,003 iteration 2641 : loss : 0.076361, loss_ce: 0.021633
2021-12-17 16:52:12,391 iteration 2642 : loss : 0.085356, loss_ce: 0.019862
2021-12-17 16:52:13,749 iteration 2643 : loss : 0.081451, loss_ce: 0.023927
2021-12-17 16:52:15,143 iteration 2644 : loss : 0.085403, loss_ce: 0.028932
2021-12-17 16:52:16,449 iteration 2645 : loss : 0.080104, loss_ce: 0.027967
2021-12-17 16:52:17,782 iteration 2646 : loss : 0.079976, loss_ce: 0.020524
2021-12-17 16:52:19,215 iteration 2647 : loss : 0.103072, loss_ce: 0.039235
2021-12-17 16:52:20,535 iteration 2648 : loss : 0.085743, loss_ce: 0.024445
2021-12-17 16:52:21,901 iteration 2649 : loss : 0.089513, loss_ce: 0.023809
2021-12-17 16:52:23,376 iteration 2650 : loss : 0.088053, loss_ce: 0.028868
2021-12-17 16:52:24,721 iteration 2651 : loss : 0.082740, loss_ce: 0.027329
2021-12-17 16:52:26,149 iteration 2652 : loss : 0.094526, loss_ce: 0.029849
 39%|██████████▌                | 156/400 [1:07:45<1:44:59, 25.82s/it]2021-12-17 16:52:27,618 iteration 2653 : loss : 0.101791, loss_ce: 0.030573
2021-12-17 16:52:28,933 iteration 2654 : loss : 0.078361, loss_ce: 0.024189
2021-12-17 16:52:30,287 iteration 2655 : loss : 0.081905, loss_ce: 0.026448
2021-12-17 16:52:31,623 iteration 2656 : loss : 0.092585, loss_ce: 0.036192
2021-12-17 16:52:33,013 iteration 2657 : loss : 0.080534, loss_ce: 0.026466
2021-12-17 16:52:34,429 iteration 2658 : loss : 0.098230, loss_ce: 0.027151
2021-12-17 16:52:35,812 iteration 2659 : loss : 0.081749, loss_ce: 0.023453
2021-12-17 16:52:37,246 iteration 2660 : loss : 0.094227, loss_ce: 0.034814
2021-12-17 16:52:38,526 iteration 2661 : loss : 0.073241, loss_ce: 0.018837
2021-12-17 16:52:39,955 iteration 2662 : loss : 0.085178, loss_ce: 0.028425
2021-12-17 16:52:41,374 iteration 2663 : loss : 0.103083, loss_ce: 0.035269
2021-12-17 16:52:42,681 iteration 2664 : loss : 0.082837, loss_ce: 0.023903
2021-12-17 16:52:44,019 iteration 2665 : loss : 0.067700, loss_ce: 0.020192
2021-12-17 16:52:45,457 iteration 2666 : loss : 0.083375, loss_ce: 0.025082
2021-12-17 16:52:46,779 iteration 2667 : loss : 0.074483, loss_ce: 0.021706
2021-12-17 16:52:48,207 iteration 2668 : loss : 0.093455, loss_ce: 0.032577
2021-12-17 16:52:49,563 iteration 2669 : loss : 0.076399, loss_ce: 0.015828
 39%|██████████▌                | 157/400 [1:08:08<1:41:39, 25.10s/it]2021-12-17 16:52:50,908 iteration 2670 : loss : 0.076983, loss_ce: 0.020184
2021-12-17 16:52:52,197 iteration 2671 : loss : 0.078600, loss_ce: 0.023483
2021-12-17 16:52:53,522 iteration 2672 : loss : 0.086148, loss_ce: 0.023251
2021-12-17 16:52:54,861 iteration 2673 : loss : 0.083978, loss_ce: 0.017878
2021-12-17 16:52:56,249 iteration 2674 : loss : 0.088197, loss_ce: 0.024256
2021-12-17 16:52:57,656 iteration 2675 : loss : 0.077891, loss_ce: 0.020953
2021-12-17 16:52:59,004 iteration 2676 : loss : 0.068486, loss_ce: 0.017760
2021-12-17 16:53:00,358 iteration 2677 : loss : 0.083894, loss_ce: 0.022728
2021-12-17 16:53:01,665 iteration 2678 : loss : 0.071085, loss_ce: 0.024338
2021-12-17 16:53:03,033 iteration 2679 : loss : 0.086426, loss_ce: 0.029014
2021-12-17 16:53:04,457 iteration 2680 : loss : 0.083662, loss_ce: 0.024407
2021-12-17 16:53:05,813 iteration 2681 : loss : 0.085236, loss_ce: 0.022907
2021-12-17 16:53:07,207 iteration 2682 : loss : 0.077845, loss_ce: 0.022973
2021-12-17 16:53:08,528 iteration 2683 : loss : 0.098952, loss_ce: 0.035666
2021-12-17 16:53:09,893 iteration 2684 : loss : 0.078604, loss_ce: 0.026276
2021-12-17 16:53:11,294 iteration 2685 : loss : 0.078364, loss_ce: 0.025694
2021-12-17 16:53:12,700 iteration 2686 : loss : 0.097538, loss_ce: 0.019854
 40%|██████████▋                | 158/400 [1:08:31<1:38:51, 24.51s/it]2021-12-17 16:53:14,093 iteration 2687 : loss : 0.080870, loss_ce: 0.026630
2021-12-17 16:53:15,439 iteration 2688 : loss : 0.081042, loss_ce: 0.022347
2021-12-17 16:53:16,767 iteration 2689 : loss : 0.075158, loss_ce: 0.019225
2021-12-17 16:53:18,173 iteration 2690 : loss : 0.115132, loss_ce: 0.020948
2021-12-17 16:53:19,500 iteration 2691 : loss : 0.073473, loss_ce: 0.021977
2021-12-17 16:53:20,832 iteration 2692 : loss : 0.082401, loss_ce: 0.023318
2021-12-17 16:53:22,160 iteration 2693 : loss : 0.078911, loss_ce: 0.022029
2021-12-17 16:53:23,550 iteration 2694 : loss : 0.075806, loss_ce: 0.023236
2021-12-17 16:53:24,904 iteration 2695 : loss : 0.093255, loss_ce: 0.034593
2021-12-17 16:53:26,262 iteration 2696 : loss : 0.079004, loss_ce: 0.025516
2021-12-17 16:53:27,595 iteration 2697 : loss : 0.087853, loss_ce: 0.029849
2021-12-17 16:53:28,925 iteration 2698 : loss : 0.071780, loss_ce: 0.016049
2021-12-17 16:53:30,278 iteration 2699 : loss : 0.098953, loss_ce: 0.035821
2021-12-17 16:53:31,613 iteration 2700 : loss : 0.083668, loss_ce: 0.023941
2021-12-17 16:53:33,091 iteration 2701 : loss : 0.082166, loss_ce: 0.018974
2021-12-17 16:53:34,489 iteration 2702 : loss : 0.087898, loss_ce: 0.034254
2021-12-17 16:53:35,909 iteration 2703 : loss : 0.082922, loss_ce: 0.027639
 40%|██████████▋                | 159/400 [1:08:55<1:36:52, 24.12s/it]2021-12-17 16:53:37,388 iteration 2704 : loss : 0.095032, loss_ce: 0.027719
2021-12-17 16:53:38,698 iteration 2705 : loss : 0.078943, loss_ce: 0.026300
2021-12-17 16:53:40,095 iteration 2706 : loss : 0.104674, loss_ce: 0.034386
2021-12-17 16:53:41,438 iteration 2707 : loss : 0.078671, loss_ce: 0.026641
2021-12-17 16:53:42,842 iteration 2708 : loss : 0.087923, loss_ce: 0.029399
2021-12-17 16:53:44,202 iteration 2709 : loss : 0.080116, loss_ce: 0.023619
2021-12-17 16:53:45,511 iteration 2710 : loss : 0.071350, loss_ce: 0.023437
2021-12-17 16:53:46,900 iteration 2711 : loss : 0.075064, loss_ce: 0.023966
2021-12-17 16:53:48,284 iteration 2712 : loss : 0.084881, loss_ce: 0.021706
2021-12-17 16:53:49,610 iteration 2713 : loss : 0.074958, loss_ce: 0.028158
2021-12-17 16:53:51,043 iteration 2714 : loss : 0.084464, loss_ce: 0.027717
2021-12-17 16:53:52,452 iteration 2715 : loss : 0.094677, loss_ce: 0.027018
2021-12-17 16:53:53,860 iteration 2716 : loss : 0.092560, loss_ce: 0.026890
2021-12-17 16:53:55,216 iteration 2717 : loss : 0.080153, loss_ce: 0.026083
2021-12-17 16:53:56,616 iteration 2718 : loss : 0.127730, loss_ce: 0.037289
2021-12-17 16:53:57,963 iteration 2719 : loss : 0.081215, loss_ce: 0.023641
2021-12-17 16:53:57,963 Training Data Eval:
2021-12-17 16:54:05,099   Average segmentation loss on training set: 0.0637
2021-12-17 16:54:05,099 Validation Data Eval:
2021-12-17 16:54:07,577   Average segmentation loss on validation set: 0.1504
2021-12-17 16:54:08,908 iteration 2720 : loss : 0.071762, loss_ce: 0.019258
 40%|██████████▊                | 160/400 [1:09:28<1:47:07, 26.78s/it]2021-12-17 16:54:10,364 iteration 2721 : loss : 0.082179, loss_ce: 0.028507
2021-12-17 16:54:11,738 iteration 2722 : loss : 0.089865, loss_ce: 0.028010
2021-12-17 16:54:13,139 iteration 2723 : loss : 0.084968, loss_ce: 0.025586
2021-12-17 16:54:14,519 iteration 2724 : loss : 0.096349, loss_ce: 0.025402
2021-12-17 16:54:15,852 iteration 2725 : loss : 0.077971, loss_ce: 0.020933
2021-12-17 16:54:17,338 iteration 2726 : loss : 0.113634, loss_ce: 0.031571
2021-12-17 16:54:18,748 iteration 2727 : loss : 0.091235, loss_ce: 0.031238
2021-12-17 16:54:20,116 iteration 2728 : loss : 0.078410, loss_ce: 0.022299
2021-12-17 16:54:21,476 iteration 2729 : loss : 0.106963, loss_ce: 0.034488
2021-12-17 16:54:22,791 iteration 2730 : loss : 0.079939, loss_ce: 0.021175
2021-12-17 16:54:24,173 iteration 2731 : loss : 0.085869, loss_ce: 0.023443
2021-12-17 16:54:25,595 iteration 2732 : loss : 0.098827, loss_ce: 0.035106
2021-12-17 16:54:26,974 iteration 2733 : loss : 0.080844, loss_ce: 0.023718
2021-12-17 16:54:28,336 iteration 2734 : loss : 0.077234, loss_ce: 0.020440
2021-12-17 16:54:29,783 iteration 2735 : loss : 0.078204, loss_ce: 0.018953
2021-12-17 16:54:31,144 iteration 2736 : loss : 0.073495, loss_ce: 0.024307
2021-12-17 16:54:32,541 iteration 2737 : loss : 0.080870, loss_ce: 0.024440
 40%|██████████▊                | 161/400 [1:09:51<1:42:55, 25.84s/it]2021-12-17 16:54:33,902 iteration 2738 : loss : 0.064313, loss_ce: 0.018910
2021-12-17 16:54:35,323 iteration 2739 : loss : 0.091137, loss_ce: 0.031892
2021-12-17 16:54:36,760 iteration 2740 : loss : 0.087806, loss_ce: 0.027682
2021-12-17 16:54:38,103 iteration 2741 : loss : 0.089409, loss_ce: 0.029541
2021-12-17 16:54:39,402 iteration 2742 : loss : 0.078463, loss_ce: 0.020173
2021-12-17 16:54:40,785 iteration 2743 : loss : 0.089743, loss_ce: 0.020875
2021-12-17 16:54:42,262 iteration 2744 : loss : 0.113947, loss_ce: 0.034449
2021-12-17 16:54:43,611 iteration 2745 : loss : 0.086731, loss_ce: 0.021092
2021-12-17 16:54:44,946 iteration 2746 : loss : 0.074465, loss_ce: 0.021548
2021-12-17 16:54:46,405 iteration 2747 : loss : 0.100935, loss_ce: 0.034648
2021-12-17 16:54:47,748 iteration 2748 : loss : 0.068487, loss_ce: 0.021633
2021-12-17 16:54:49,129 iteration 2749 : loss : 0.084521, loss_ce: 0.030866
2021-12-17 16:54:50,481 iteration 2750 : loss : 0.080317, loss_ce: 0.021040
2021-12-17 16:54:51,836 iteration 2751 : loss : 0.085211, loss_ce: 0.017577
2021-12-17 16:54:53,160 iteration 2752 : loss : 0.072414, loss_ce: 0.022914
2021-12-17 16:54:54,510 iteration 2753 : loss : 0.084604, loss_ce: 0.028266
2021-12-17 16:54:55,889 iteration 2754 : loss : 0.090648, loss_ce: 0.025764
 40%|██████████▉                | 162/400 [1:10:15<1:39:31, 25.09s/it]2021-12-17 16:54:57,314 iteration 2755 : loss : 0.074673, loss_ce: 0.021440
2021-12-17 16:54:58,687 iteration 2756 : loss : 0.091041, loss_ce: 0.029110
2021-12-17 16:55:00,016 iteration 2757 : loss : 0.084570, loss_ce: 0.025497
2021-12-17 16:55:01,372 iteration 2758 : loss : 0.080713, loss_ce: 0.025458
2021-12-17 16:55:02,734 iteration 2759 : loss : 0.076080, loss_ce: 0.020853
2021-12-17 16:55:04,139 iteration 2760 : loss : 0.098047, loss_ce: 0.020505
2021-12-17 16:55:05,498 iteration 2761 : loss : 0.075161, loss_ce: 0.018957
2021-12-17 16:55:06,851 iteration 2762 : loss : 0.085183, loss_ce: 0.025825
2021-12-17 16:55:08,217 iteration 2763 : loss : 0.087660, loss_ce: 0.026634
2021-12-17 16:55:09,527 iteration 2764 : loss : 0.075060, loss_ce: 0.026708
2021-12-17 16:55:10,895 iteration 2765 : loss : 0.105843, loss_ce: 0.039837
2021-12-17 16:55:12,317 iteration 2766 : loss : 0.102128, loss_ce: 0.030905
2021-12-17 16:55:13,616 iteration 2767 : loss : 0.068217, loss_ce: 0.015109
2021-12-17 16:55:15,088 iteration 2768 : loss : 0.086950, loss_ce: 0.026073
2021-12-17 16:55:16,435 iteration 2769 : loss : 0.077584, loss_ce: 0.023903
2021-12-17 16:55:17,746 iteration 2770 : loss : 0.073629, loss_ce: 0.024951
2021-12-17 16:55:19,104 iteration 2771 : loss : 0.072242, loss_ce: 0.025009
 41%|███████████                | 163/400 [1:10:38<1:36:53, 24.53s/it]2021-12-17 16:55:20,583 iteration 2772 : loss : 0.100338, loss_ce: 0.031396
2021-12-17 16:55:21,882 iteration 2773 : loss : 0.080676, loss_ce: 0.021154
2021-12-17 16:55:23,226 iteration 2774 : loss : 0.074519, loss_ce: 0.024795
2021-12-17 16:55:24,598 iteration 2775 : loss : 0.077175, loss_ce: 0.025802
2021-12-17 16:55:25,968 iteration 2776 : loss : 0.091619, loss_ce: 0.036622
2021-12-17 16:55:27,371 iteration 2777 : loss : 0.089102, loss_ce: 0.030514
2021-12-17 16:55:28,677 iteration 2778 : loss : 0.074002, loss_ce: 0.022475
2021-12-17 16:55:30,075 iteration 2779 : loss : 0.084437, loss_ce: 0.024092
2021-12-17 16:55:31,501 iteration 2780 : loss : 0.090464, loss_ce: 0.032040
2021-12-17 16:55:32,779 iteration 2781 : loss : 0.081981, loss_ce: 0.025554
2021-12-17 16:55:34,164 iteration 2782 : loss : 0.093603, loss_ce: 0.029523
2021-12-17 16:55:35,584 iteration 2783 : loss : 0.100414, loss_ce: 0.030802
2021-12-17 16:55:37,044 iteration 2784 : loss : 0.086786, loss_ce: 0.032248
2021-12-17 16:55:38,349 iteration 2785 : loss : 0.071450, loss_ce: 0.018441
2021-12-17 16:55:39,723 iteration 2786 : loss : 0.088892, loss_ce: 0.025376
2021-12-17 16:55:41,146 iteration 2787 : loss : 0.111493, loss_ce: 0.023525
2021-12-17 16:55:42,508 iteration 2788 : loss : 0.088481, loss_ce: 0.024914
 41%|███████████                | 164/400 [1:11:01<1:35:08, 24.19s/it]2021-12-17 16:55:43,920 iteration 2789 : loss : 0.071912, loss_ce: 0.026724
2021-12-17 16:55:45,249 iteration 2790 : loss : 0.085413, loss_ce: 0.022554
2021-12-17 16:55:46,636 iteration 2791 : loss : 0.074324, loss_ce: 0.019654
2021-12-17 16:55:48,053 iteration 2792 : loss : 0.099557, loss_ce: 0.024797
2021-12-17 16:55:49,425 iteration 2793 : loss : 0.089379, loss_ce: 0.030484
2021-12-17 16:55:50,811 iteration 2794 : loss : 0.090276, loss_ce: 0.026170
2021-12-17 16:55:52,243 iteration 2795 : loss : 0.088375, loss_ce: 0.024859
2021-12-17 16:55:53,696 iteration 2796 : loss : 0.087553, loss_ce: 0.024940
2021-12-17 16:55:55,099 iteration 2797 : loss : 0.078817, loss_ce: 0.026266
2021-12-17 16:55:56,541 iteration 2798 : loss : 0.077424, loss_ce: 0.019928
2021-12-17 16:55:57,955 iteration 2799 : loss : 0.106541, loss_ce: 0.033159
2021-12-17 16:55:59,351 iteration 2800 : loss : 0.075673, loss_ce: 0.025936
2021-12-17 16:56:00,711 iteration 2801 : loss : 0.086815, loss_ce: 0.032411
2021-12-17 16:56:02,029 iteration 2802 : loss : 0.072784, loss_ce: 0.022035
2021-12-17 16:56:03,483 iteration 2803 : loss : 0.097211, loss_ce: 0.026929
2021-12-17 16:56:04,852 iteration 2804 : loss : 0.087511, loss_ce: 0.029923
2021-12-17 16:56:04,852 Training Data Eval:
2021-12-17 16:56:11,918   Average segmentation loss on training set: 0.0617
2021-12-17 16:56:11,919 Validation Data Eval:
2021-12-17 16:56:14,392   Average segmentation loss on validation set: 0.1471
2021-12-17 16:56:15,773 iteration 2805 : loss : 0.099113, loss_ce: 0.024121
 41%|███████████▏               | 165/400 [1:11:34<1:45:24, 26.91s/it]2021-12-17 16:56:17,245 iteration 2806 : loss : 0.092061, loss_ce: 0.024481
2021-12-17 16:56:18,748 iteration 2807 : loss : 0.094383, loss_ce: 0.028143
2021-12-17 16:56:20,026 iteration 2808 : loss : 0.072906, loss_ce: 0.024454
2021-12-17 16:56:21,391 iteration 2809 : loss : 0.088210, loss_ce: 0.025560
2021-12-17 16:56:22,800 iteration 2810 : loss : 0.087847, loss_ce: 0.028926
2021-12-17 16:56:24,141 iteration 2811 : loss : 0.072594, loss_ce: 0.023789
2021-12-17 16:56:25,509 iteration 2812 : loss : 0.075099, loss_ce: 0.023871
2021-12-17 16:56:26,909 iteration 2813 : loss : 0.072678, loss_ce: 0.017774
2021-12-17 16:56:28,292 iteration 2814 : loss : 0.101286, loss_ce: 0.039734
2021-12-17 16:56:29,621 iteration 2815 : loss : 0.069388, loss_ce: 0.021673
2021-12-17 16:56:30,956 iteration 2816 : loss : 0.078114, loss_ce: 0.028713
2021-12-17 16:56:32,286 iteration 2817 : loss : 0.071258, loss_ce: 0.017413
2021-12-17 16:56:33,712 iteration 2818 : loss : 0.079444, loss_ce: 0.018615
2021-12-17 16:56:35,114 iteration 2819 : loss : 0.099843, loss_ce: 0.038092
2021-12-17 16:56:36,586 iteration 2820 : loss : 0.101457, loss_ce: 0.035085
2021-12-17 16:56:37,948 iteration 2821 : loss : 0.078253, loss_ce: 0.026541
2021-12-17 16:56:39,274 iteration 2822 : loss : 0.074471, loss_ce: 0.018963
 42%|███████████▏               | 166/400 [1:11:58<1:40:57, 25.89s/it]2021-12-17 16:56:40,766 iteration 2823 : loss : 0.087447, loss_ce: 0.024984
2021-12-17 16:56:42,082 iteration 2824 : loss : 0.074929, loss_ce: 0.019762
2021-12-17 16:56:43,473 iteration 2825 : loss : 0.089325, loss_ce: 0.032095
2021-12-17 16:56:44,801 iteration 2826 : loss : 0.067450, loss_ce: 0.020238
2021-12-17 16:56:46,194 iteration 2827 : loss : 0.088883, loss_ce: 0.036497
2021-12-17 16:56:47,576 iteration 2828 : loss : 0.080880, loss_ce: 0.027653
2021-12-17 16:56:49,035 iteration 2829 : loss : 0.088488, loss_ce: 0.028517
2021-12-17 16:56:50,334 iteration 2830 : loss : 0.072468, loss_ce: 0.023336
2021-12-17 16:56:51,693 iteration 2831 : loss : 0.077664, loss_ce: 0.025763
2021-12-17 16:56:53,097 iteration 2832 : loss : 0.083934, loss_ce: 0.020369
2021-12-17 16:56:54,523 iteration 2833 : loss : 0.088493, loss_ce: 0.026818
2021-12-17 16:56:55,881 iteration 2834 : loss : 0.109206, loss_ce: 0.029610
2021-12-17 16:56:57,278 iteration 2835 : loss : 0.125619, loss_ce: 0.033126
2021-12-17 16:56:58,695 iteration 2836 : loss : 0.093206, loss_ce: 0.028385
2021-12-17 16:57:00,068 iteration 2837 : loss : 0.083814, loss_ce: 0.018229
2021-12-17 16:57:01,379 iteration 2838 : loss : 0.070953, loss_ce: 0.018301
2021-12-17 16:57:02,783 iteration 2839 : loss : 0.083343, loss_ce: 0.026684
 42%|███████████▎               | 167/400 [1:12:21<1:37:45, 25.18s/it]2021-12-17 16:57:04,193 iteration 2840 : loss : 0.075903, loss_ce: 0.027984
2021-12-17 16:57:05,579 iteration 2841 : loss : 0.088005, loss_ce: 0.030141
2021-12-17 16:57:06,954 iteration 2842 : loss : 0.094306, loss_ce: 0.026076
2021-12-17 16:57:08,251 iteration 2843 : loss : 0.080644, loss_ce: 0.024257
2021-12-17 16:57:09,528 iteration 2844 : loss : 0.070529, loss_ce: 0.020257
2021-12-17 16:57:10,872 iteration 2845 : loss : 0.113964, loss_ce: 0.035438
2021-12-17 16:57:12,330 iteration 2846 : loss : 0.089503, loss_ce: 0.022503
2021-12-17 16:57:13,734 iteration 2847 : loss : 0.112629, loss_ce: 0.034739
2021-12-17 16:57:15,083 iteration 2848 : loss : 0.096218, loss_ce: 0.024350
2021-12-17 16:57:16,468 iteration 2849 : loss : 0.083697, loss_ce: 0.027901
2021-12-17 16:57:17,829 iteration 2850 : loss : 0.084572, loss_ce: 0.031963
2021-12-17 16:57:19,257 iteration 2851 : loss : 0.096376, loss_ce: 0.034081
2021-12-17 16:57:20,581 iteration 2852 : loss : 0.084940, loss_ce: 0.022959
2021-12-17 16:57:21,971 iteration 2853 : loss : 0.087493, loss_ce: 0.021159
2021-12-17 16:57:23,281 iteration 2854 : loss : 0.089812, loss_ce: 0.023384
2021-12-17 16:57:24,625 iteration 2855 : loss : 0.078530, loss_ce: 0.025720
2021-12-17 16:57:25,921 iteration 2856 : loss : 0.071063, loss_ce: 0.026866
 42%|███████████▎               | 168/400 [1:12:45<1:34:59, 24.57s/it]2021-12-17 16:57:27,350 iteration 2857 : loss : 0.075217, loss_ce: 0.026050
2021-12-17 16:57:28,825 iteration 2858 : loss : 0.095546, loss_ce: 0.022333
2021-12-17 16:57:30,225 iteration 2859 : loss : 0.078843, loss_ce: 0.025337
2021-12-17 16:57:31,617 iteration 2860 : loss : 0.078939, loss_ce: 0.023484
2021-12-17 16:57:32,993 iteration 2861 : loss : 0.083662, loss_ce: 0.021782
2021-12-17 16:57:34,403 iteration 2862 : loss : 0.087256, loss_ce: 0.020751
2021-12-17 16:57:35,738 iteration 2863 : loss : 0.070997, loss_ce: 0.022715
2021-12-17 16:57:37,103 iteration 2864 : loss : 0.078598, loss_ce: 0.021756
2021-12-17 16:57:38,454 iteration 2865 : loss : 0.081368, loss_ce: 0.024745
2021-12-17 16:57:39,802 iteration 2866 : loss : 0.069410, loss_ce: 0.017156
2021-12-17 16:57:41,251 iteration 2867 : loss : 0.113238, loss_ce: 0.033541
2021-12-17 16:57:42,653 iteration 2868 : loss : 0.097720, loss_ce: 0.032432
2021-12-17 16:57:44,056 iteration 2869 : loss : 0.094447, loss_ce: 0.028448
2021-12-17 16:57:45,496 iteration 2870 : loss : 0.084762, loss_ce: 0.026715
2021-12-17 16:57:46,804 iteration 2871 : loss : 0.093561, loss_ce: 0.036031
2021-12-17 16:57:48,149 iteration 2872 : loss : 0.078715, loss_ce: 0.029776
2021-12-17 16:57:49,503 iteration 2873 : loss : 0.079405, loss_ce: 0.027169
 42%|███████████▍               | 169/400 [1:13:08<1:33:26, 24.27s/it]2021-12-17 16:57:50,917 iteration 2874 : loss : 0.070622, loss_ce: 0.019620
2021-12-17 16:57:52,342 iteration 2875 : loss : 0.087096, loss_ce: 0.030219
2021-12-17 16:57:53,678 iteration 2876 : loss : 0.096908, loss_ce: 0.036272
2021-12-17 16:57:54,980 iteration 2877 : loss : 0.074795, loss_ce: 0.020971
2021-12-17 16:57:56,338 iteration 2878 : loss : 0.079179, loss_ce: 0.020595
2021-12-17 16:57:57,642 iteration 2879 : loss : 0.069514, loss_ce: 0.025147
2021-12-17 16:57:59,041 iteration 2880 : loss : 0.090931, loss_ce: 0.037361
2021-12-17 16:58:00,332 iteration 2881 : loss : 0.070829, loss_ce: 0.022213
2021-12-17 16:58:01,668 iteration 2882 : loss : 0.096414, loss_ce: 0.022411
2021-12-17 16:58:03,062 iteration 2883 : loss : 0.096310, loss_ce: 0.032672
2021-12-17 16:58:04,464 iteration 2884 : loss : 0.085619, loss_ce: 0.029112
2021-12-17 16:58:05,827 iteration 2885 : loss : 0.074914, loss_ce: 0.023054
2021-12-17 16:58:07,147 iteration 2886 : loss : 0.079806, loss_ce: 0.022953
2021-12-17 16:58:08,475 iteration 2887 : loss : 0.072437, loss_ce: 0.019656
2021-12-17 16:58:09,882 iteration 2888 : loss : 0.071940, loss_ce: 0.021499
2021-12-17 16:58:11,245 iteration 2889 : loss : 0.082479, loss_ce: 0.024805
2021-12-17 16:58:11,246 Training Data Eval:
2021-12-17 16:58:18,354   Average segmentation loss on training set: 0.0613
2021-12-17 16:58:18,355 Validation Data Eval:
2021-12-17 16:58:20,861   Average segmentation loss on validation set: 0.1478
2021-12-17 16:58:22,233 iteration 2890 : loss : 0.085059, loss_ce: 0.027844
 42%|███████████▍               | 170/400 [1:13:41<1:42:46, 26.81s/it]2021-12-17 16:58:23,652 iteration 2891 : loss : 0.071729, loss_ce: 0.024194
2021-12-17 16:58:25,034 iteration 2892 : loss : 0.076032, loss_ce: 0.021830
2021-12-17 16:58:26,321 iteration 2893 : loss : 0.065601, loss_ce: 0.019708
2021-12-17 16:58:27,646 iteration 2894 : loss : 0.063655, loss_ce: 0.016146
2021-12-17 16:58:28,981 iteration 2895 : loss : 0.073324, loss_ce: 0.019010
2021-12-17 16:58:30,343 iteration 2896 : loss : 0.086397, loss_ce: 0.025211
2021-12-17 16:58:31,812 iteration 2897 : loss : 0.105844, loss_ce: 0.017349
2021-12-17 16:58:33,195 iteration 2898 : loss : 0.104741, loss_ce: 0.028915
2021-12-17 16:58:34,562 iteration 2899 : loss : 0.077529, loss_ce: 0.027136
2021-12-17 16:58:36,049 iteration 2900 : loss : 0.112887, loss_ce: 0.042313
2021-12-17 16:58:37,442 iteration 2901 : loss : 0.075091, loss_ce: 0.022514
2021-12-17 16:58:38,773 iteration 2902 : loss : 0.079866, loss_ce: 0.028241
2021-12-17 16:58:40,136 iteration 2903 : loss : 0.080117, loss_ce: 0.016431
2021-12-17 16:58:41,480 iteration 2904 : loss : 0.082163, loss_ce: 0.027147
2021-12-17 16:58:42,877 iteration 2905 : loss : 0.088453, loss_ce: 0.031541
2021-12-17 16:58:44,201 iteration 2906 : loss : 0.117074, loss_ce: 0.046496
2021-12-17 16:58:45,562 iteration 2907 : loss : 0.072721, loss_ce: 0.021081
 43%|███████████▌               | 171/400 [1:14:04<1:38:19, 25.76s/it]2021-12-17 16:58:47,003 iteration 2908 : loss : 0.078930, loss_ce: 0.024310
2021-12-17 16:58:48,416 iteration 2909 : loss : 0.084075, loss_ce: 0.021993
2021-12-17 16:58:49,812 iteration 2910 : loss : 0.067252, loss_ce: 0.020164
2021-12-17 16:58:51,226 iteration 2911 : loss : 0.104214, loss_ce: 0.030570
2021-12-17 16:58:52,550 iteration 2912 : loss : 0.066025, loss_ce: 0.019016
2021-12-17 16:58:53,924 iteration 2913 : loss : 0.083861, loss_ce: 0.023951
2021-12-17 16:58:55,326 iteration 2914 : loss : 0.091554, loss_ce: 0.033032
2021-12-17 16:58:56,694 iteration 2915 : loss : 0.093349, loss_ce: 0.036763
2021-12-17 16:58:58,054 iteration 2916 : loss : 0.084935, loss_ce: 0.029978
2021-12-17 16:58:59,425 iteration 2917 : loss : 0.077372, loss_ce: 0.022686
2021-12-17 16:59:00,733 iteration 2918 : loss : 0.075110, loss_ce: 0.026589
2021-12-17 16:59:02,119 iteration 2919 : loss : 0.101932, loss_ce: 0.023935
2021-12-17 16:59:03,467 iteration 2920 : loss : 0.067528, loss_ce: 0.022138
2021-12-17 16:59:04,820 iteration 2921 : loss : 0.073310, loss_ce: 0.025612
2021-12-17 16:59:06,174 iteration 2922 : loss : 0.093643, loss_ce: 0.025585
2021-12-17 16:59:07,607 iteration 2923 : loss : 0.087765, loss_ce: 0.022834
2021-12-17 16:59:09,002 iteration 2924 : loss : 0.070795, loss_ce: 0.022758
 43%|███████████▌               | 172/400 [1:14:28<1:35:15, 25.07s/it]2021-12-17 16:59:10,434 iteration 2925 : loss : 0.087425, loss_ce: 0.031555
2021-12-17 16:59:11,744 iteration 2926 : loss : 0.069662, loss_ce: 0.019541
2021-12-17 16:59:13,115 iteration 2927 : loss : 0.073506, loss_ce: 0.018614
2021-12-17 16:59:14,511 iteration 2928 : loss : 0.074813, loss_ce: 0.023404
2021-12-17 16:59:15,843 iteration 2929 : loss : 0.084230, loss_ce: 0.020529
2021-12-17 16:59:17,159 iteration 2930 : loss : 0.071315, loss_ce: 0.023435
2021-12-17 16:59:18,526 iteration 2931 : loss : 0.132606, loss_ce: 0.019796
2021-12-17 16:59:19,963 iteration 2932 : loss : 0.090117, loss_ce: 0.029311
2021-12-17 16:59:21,349 iteration 2933 : loss : 0.089617, loss_ce: 0.030795
2021-12-17 16:59:22,763 iteration 2934 : loss : 0.093335, loss_ce: 0.035905
2021-12-17 16:59:24,096 iteration 2935 : loss : 0.069822, loss_ce: 0.016704
2021-12-17 16:59:25,461 iteration 2936 : loss : 0.079401, loss_ce: 0.028592
2021-12-17 16:59:26,845 iteration 2937 : loss : 0.084396, loss_ce: 0.030998
2021-12-17 16:59:28,230 iteration 2938 : loss : 0.108087, loss_ce: 0.031959
2021-12-17 16:59:29,511 iteration 2939 : loss : 0.073815, loss_ce: 0.017638
2021-12-17 16:59:30,855 iteration 2940 : loss : 0.071453, loss_ce: 0.020774
2021-12-17 16:59:32,209 iteration 2941 : loss : 0.089489, loss_ce: 0.031316
 43%|███████████▋               | 173/400 [1:14:51<1:32:43, 24.51s/it]2021-12-17 16:59:33,714 iteration 2942 : loss : 0.087634, loss_ce: 0.034305
2021-12-17 16:59:35,158 iteration 2943 : loss : 0.077022, loss_ce: 0.025094
2021-12-17 16:59:36,535 iteration 2944 : loss : 0.098586, loss_ce: 0.031759
2021-12-17 16:59:37,895 iteration 2945 : loss : 0.082214, loss_ce: 0.029956
2021-12-17 16:59:39,313 iteration 2946 : loss : 0.089385, loss_ce: 0.031138
2021-12-17 16:59:40,655 iteration 2947 : loss : 0.075812, loss_ce: 0.022813
2021-12-17 16:59:42,050 iteration 2948 : loss : 0.071330, loss_ce: 0.022234
2021-12-17 16:59:43,389 iteration 2949 : loss : 0.085902, loss_ce: 0.026084
2021-12-17 16:59:44,689 iteration 2950 : loss : 0.072477, loss_ce: 0.024156
2021-12-17 16:59:46,054 iteration 2951 : loss : 0.070793, loss_ce: 0.019355
2021-12-17 16:59:47,344 iteration 2952 : loss : 0.125750, loss_ce: 0.024243
2021-12-17 16:59:48,766 iteration 2953 : loss : 0.082868, loss_ce: 0.025239
2021-12-17 16:59:50,134 iteration 2954 : loss : 0.067287, loss_ce: 0.020833
2021-12-17 16:59:51,501 iteration 2955 : loss : 0.082617, loss_ce: 0.016072
2021-12-17 16:59:52,798 iteration 2956 : loss : 0.074105, loss_ce: 0.028364
2021-12-17 16:59:54,100 iteration 2957 : loss : 0.083459, loss_ce: 0.023260
2021-12-17 16:59:55,469 iteration 2958 : loss : 0.088392, loss_ce: 0.030379
 44%|███████████▋               | 174/400 [1:15:14<1:30:54, 24.13s/it]2021-12-17 16:59:56,922 iteration 2959 : loss : 0.080079, loss_ce: 0.029966
2021-12-17 16:59:58,282 iteration 2960 : loss : 0.086935, loss_ce: 0.029140
2021-12-17 16:59:59,681 iteration 2961 : loss : 0.082479, loss_ce: 0.026961
2021-12-17 17:00:01,070 iteration 2962 : loss : 0.084682, loss_ce: 0.024603
2021-12-17 17:00:02,403 iteration 2963 : loss : 0.075064, loss_ce: 0.027568
2021-12-17 17:00:03,743 iteration 2964 : loss : 0.090752, loss_ce: 0.026959
2021-12-17 17:00:05,050 iteration 2965 : loss : 0.077773, loss_ce: 0.021990
2021-12-17 17:00:06,346 iteration 2966 : loss : 0.067349, loss_ce: 0.017715
2021-12-17 17:00:07,723 iteration 2967 : loss : 0.075468, loss_ce: 0.025389
2021-12-17 17:00:09,175 iteration 2968 : loss : 0.096689, loss_ce: 0.021296
2021-12-17 17:00:10,572 iteration 2969 : loss : 0.073165, loss_ce: 0.024398
2021-12-17 17:00:11,917 iteration 2970 : loss : 0.071960, loss_ce: 0.019753
2021-12-17 17:00:13,221 iteration 2971 : loss : 0.080152, loss_ce: 0.026594
2021-12-17 17:00:14,613 iteration 2972 : loss : 0.088851, loss_ce: 0.026598
2021-12-17 17:00:15,973 iteration 2973 : loss : 0.085343, loss_ce: 0.028820
2021-12-17 17:00:17,385 iteration 2974 : loss : 0.067841, loss_ce: 0.018589
2021-12-17 17:00:17,385 Training Data Eval:
2021-12-17 17:00:24,458   Average segmentation loss on training set: 0.0630
2021-12-17 17:00:24,459 Validation Data Eval:
2021-12-17 17:00:26,941   Average segmentation loss on validation set: 0.1360
2021-12-17 17:00:34,925 Found new lowest validation loss at iteration 2974! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/TU_3seeds/TU_RESNET_no_pretraining_SGD_best_val_loss_seed100.pth
2021-12-17 17:00:36,323 iteration 2975 : loss : 0.079286, loss_ce: 0.018709
 44%|███████████▊               | 175/400 [1:15:55<1:49:19, 29.15s/it]2021-12-17 17:00:37,773 iteration 2976 : loss : 0.081805, loss_ce: 0.034240
2021-12-17 17:00:39,019 iteration 2977 : loss : 0.073851, loss_ce: 0.022429
2021-12-17 17:00:40,247 iteration 2978 : loss : 0.065858, loss_ce: 0.017778
2021-12-17 17:00:41,591 iteration 2979 : loss : 0.065696, loss_ce: 0.016951
2021-12-17 17:00:43,027 iteration 2980 : loss : 0.075071, loss_ce: 0.022177
2021-12-17 17:00:44,361 iteration 2981 : loss : 0.072287, loss_ce: 0.016910
2021-12-17 17:00:45,756 iteration 2982 : loss : 0.086583, loss_ce: 0.031058
2021-12-17 17:00:47,070 iteration 2983 : loss : 0.089995, loss_ce: 0.033610
2021-12-17 17:00:48,445 iteration 2984 : loss : 0.082480, loss_ce: 0.024637
2021-12-17 17:00:49,786 iteration 2985 : loss : 0.090183, loss_ce: 0.021633
2021-12-17 17:00:51,154 iteration 2986 : loss : 0.082188, loss_ce: 0.025813
2021-12-17 17:00:52,422 iteration 2987 : loss : 0.078045, loss_ce: 0.028587
2021-12-17 17:00:53,717 iteration 2988 : loss : 0.074067, loss_ce: 0.019881
2021-12-17 17:00:55,055 iteration 2989 : loss : 0.069945, loss_ce: 0.015809
2021-12-17 17:00:56,402 iteration 2990 : loss : 0.079634, loss_ce: 0.023870
2021-12-17 17:00:57,802 iteration 2991 : loss : 0.074065, loss_ce: 0.020833
2021-12-17 17:00:59,262 iteration 2992 : loss : 0.073862, loss_ce: 0.021687
 44%|███████████▉               | 176/400 [1:16:18<1:41:51, 27.28s/it]2021-12-17 17:01:00,578 iteration 2993 : loss : 0.075576, loss_ce: 0.015212
2021-12-17 17:01:01,909 iteration 2994 : loss : 0.075640, loss_ce: 0.020551
2021-12-17 17:01:03,366 iteration 2995 : loss : 0.082661, loss_ce: 0.030189
2021-12-17 17:01:04,762 iteration 2996 : loss : 0.079780, loss_ce: 0.024725
2021-12-17 17:01:06,160 iteration 2997 : loss : 0.066298, loss_ce: 0.019118
2021-12-17 17:01:07,553 iteration 2998 : loss : 0.070467, loss_ce: 0.015398
2021-12-17 17:01:08,990 iteration 2999 : loss : 0.078076, loss_ce: 0.024289
2021-12-17 17:01:10,383 iteration 3000 : loss : 0.085233, loss_ce: 0.023375
2021-12-17 17:01:11,814 iteration 3001 : loss : 0.069675, loss_ce: 0.021875
2021-12-17 17:01:13,145 iteration 3002 : loss : 0.073151, loss_ce: 0.024892
2021-12-17 17:01:14,607 iteration 3003 : loss : 0.075729, loss_ce: 0.023955
2021-12-17 17:01:15,928 iteration 3004 : loss : 0.063849, loss_ce: 0.019619
2021-12-17 17:01:17,344 iteration 3005 : loss : 0.085366, loss_ce: 0.023849
2021-12-17 17:01:18,762 iteration 3006 : loss : 0.084818, loss_ce: 0.026677
2021-12-17 17:01:20,132 iteration 3007 : loss : 0.062959, loss_ce: 0.017652
2021-12-17 17:01:21,624 iteration 3008 : loss : 0.093533, loss_ce: 0.036514
2021-12-17 17:01:23,003 iteration 3009 : loss : 0.078760, loss_ce: 0.029882
 44%|███████████▉               | 177/400 [1:16:42<1:37:27, 26.22s/it]2021-12-17 17:01:24,422 iteration 3010 : loss : 0.074949, loss_ce: 0.024342
2021-12-17 17:01:25,786 iteration 3011 : loss : 0.080048, loss_ce: 0.022040
2021-12-17 17:01:27,144 iteration 3012 : loss : 0.085309, loss_ce: 0.022873
2021-12-17 17:01:28,505 iteration 3013 : loss : 0.072724, loss_ce: 0.023286
2021-12-17 17:01:29,953 iteration 3014 : loss : 0.083063, loss_ce: 0.025504
2021-12-17 17:01:31,350 iteration 3015 : loss : 0.084755, loss_ce: 0.030449
2021-12-17 17:01:32,724 iteration 3016 : loss : 0.070148, loss_ce: 0.020211
2021-12-17 17:01:34,101 iteration 3017 : loss : 0.077595, loss_ce: 0.017739
2021-12-17 17:01:35,447 iteration 3018 : loss : 0.080778, loss_ce: 0.020438
2021-12-17 17:01:36,842 iteration 3019 : loss : 0.076025, loss_ce: 0.023786
2021-12-17 17:01:38,115 iteration 3020 : loss : 0.065779, loss_ce: 0.023568
2021-12-17 17:01:39,428 iteration 3021 : loss : 0.068597, loss_ce: 0.020313
2021-12-17 17:01:40,810 iteration 3022 : loss : 0.074983, loss_ce: 0.018468
2021-12-17 17:01:42,181 iteration 3023 : loss : 0.073581, loss_ce: 0.030360
2021-12-17 17:01:43,570 iteration 3024 : loss : 0.085807, loss_ce: 0.026107
2021-12-17 17:01:44,876 iteration 3025 : loss : 0.071654, loss_ce: 0.021662
2021-12-17 17:01:46,298 iteration 3026 : loss : 0.070812, loss_ce: 0.025323
 44%|████████████               | 178/400 [1:17:05<1:33:46, 25.35s/it]2021-12-17 17:01:47,733 iteration 3027 : loss : 0.081295, loss_ce: 0.031200
2021-12-17 17:01:49,100 iteration 3028 : loss : 0.076974, loss_ce: 0.026519
2021-12-17 17:01:50,485 iteration 3029 : loss : 0.078106, loss_ce: 0.029492
2021-12-17 17:01:51,940 iteration 3030 : loss : 0.079802, loss_ce: 0.022679
2021-12-17 17:01:53,228 iteration 3031 : loss : 0.065018, loss_ce: 0.019013
2021-12-17 17:01:54,610 iteration 3032 : loss : 0.082258, loss_ce: 0.021398
2021-12-17 17:01:56,033 iteration 3033 : loss : 0.078942, loss_ce: 0.029267
2021-12-17 17:01:57,397 iteration 3034 : loss : 0.077081, loss_ce: 0.021104
2021-12-17 17:01:58,850 iteration 3035 : loss : 0.092385, loss_ce: 0.026100
2021-12-17 17:02:00,257 iteration 3036 : loss : 0.076074, loss_ce: 0.022850
2021-12-17 17:02:01,686 iteration 3037 : loss : 0.077600, loss_ce: 0.023305
2021-12-17 17:02:02,999 iteration 3038 : loss : 0.065515, loss_ce: 0.013482
2021-12-17 17:02:04,523 iteration 3039 : loss : 0.117886, loss_ce: 0.038047
2021-12-17 17:02:05,847 iteration 3040 : loss : 0.069280, loss_ce: 0.023449
2021-12-17 17:02:07,193 iteration 3041 : loss : 0.077909, loss_ce: 0.022936
2021-12-17 17:02:08,536 iteration 3042 : loss : 0.072943, loss_ce: 0.026483
2021-12-17 17:02:10,019 iteration 3043 : loss : 0.083025, loss_ce: 0.027708
 45%|████████████               | 179/400 [1:17:29<1:31:33, 24.86s/it]2021-12-17 17:02:11,478 iteration 3044 : loss : 0.077557, loss_ce: 0.024380
2021-12-17 17:02:12,825 iteration 3045 : loss : 0.082012, loss_ce: 0.024814
2021-12-17 17:02:14,172 iteration 3046 : loss : 0.096325, loss_ce: 0.027669
2021-12-17 17:02:15,657 iteration 3047 : loss : 0.085875, loss_ce: 0.029161
2021-12-17 17:02:17,087 iteration 3048 : loss : 0.079102, loss_ce: 0.030723
2021-12-17 17:02:18,424 iteration 3049 : loss : 0.075432, loss_ce: 0.024110
2021-12-17 17:02:19,883 iteration 3050 : loss : 0.091317, loss_ce: 0.033702
2021-12-17 17:02:21,291 iteration 3051 : loss : 0.085214, loss_ce: 0.020003
2021-12-17 17:02:22,740 iteration 3052 : loss : 0.084720, loss_ce: 0.028506
2021-12-17 17:02:24,137 iteration 3053 : loss : 0.079428, loss_ce: 0.024106
2021-12-17 17:02:25,543 iteration 3054 : loss : 0.100443, loss_ce: 0.028465
2021-12-17 17:02:26,958 iteration 3055 : loss : 0.089151, loss_ce: 0.029572
2021-12-17 17:02:28,348 iteration 3056 : loss : 0.075281, loss_ce: 0.020212
2021-12-17 17:02:29,684 iteration 3057 : loss : 0.064108, loss_ce: 0.017499
2021-12-17 17:02:31,118 iteration 3058 : loss : 0.106318, loss_ce: 0.029188
2021-12-17 17:02:32,563 iteration 3059 : loss : 0.078282, loss_ce: 0.025330
2021-12-17 17:02:32,563 Training Data Eval:
2021-12-17 17:02:39,788   Average segmentation loss on training set: 0.0575
2021-12-17 17:02:39,789 Validation Data Eval:
2021-12-17 17:02:42,287   Average segmentation loss on validation set: 0.1464
2021-12-17 17:02:43,658 iteration 3060 : loss : 0.078703, loss_ce: 0.026008
 45%|████████████▏              | 180/400 [1:18:02<1:40:48, 27.49s/it]2021-12-17 17:02:45,066 iteration 3061 : loss : 0.097735, loss_ce: 0.031333
2021-12-17 17:02:46,475 iteration 3062 : loss : 0.085230, loss_ce: 0.023692
2021-12-17 17:02:47,837 iteration 3063 : loss : 0.072371, loss_ce: 0.018816
2021-12-17 17:02:49,273 iteration 3064 : loss : 0.090173, loss_ce: 0.036742
2021-12-17 17:02:50,660 iteration 3065 : loss : 0.082011, loss_ce: 0.019425
2021-12-17 17:02:52,031 iteration 3066 : loss : 0.074256, loss_ce: 0.014720
2021-12-17 17:02:53,424 iteration 3067 : loss : 0.080977, loss_ce: 0.027362
2021-12-17 17:02:54,871 iteration 3068 : loss : 0.065767, loss_ce: 0.017599
2021-12-17 17:02:56,311 iteration 3069 : loss : 0.081585, loss_ce: 0.017155
2021-12-17 17:02:57,648 iteration 3070 : loss : 0.068303, loss_ce: 0.021601
2021-12-17 17:02:59,102 iteration 3071 : loss : 0.075342, loss_ce: 0.023019
2021-12-17 17:03:00,509 iteration 3072 : loss : 0.067070, loss_ce: 0.018075
2021-12-17 17:03:01,849 iteration 3073 : loss : 0.089441, loss_ce: 0.030093
2021-12-17 17:03:03,317 iteration 3074 : loss : 0.092419, loss_ce: 0.031434
2021-12-17 17:03:04,730 iteration 3075 : loss : 0.071329, loss_ce: 0.018949
2021-12-17 17:03:06,081 iteration 3076 : loss : 0.070014, loss_ce: 0.025859
2021-12-17 17:03:07,529 iteration 3077 : loss : 0.103619, loss_ce: 0.040689
 45%|████████████▏              | 181/400 [1:18:26<1:36:22, 26.41s/it]2021-12-17 17:03:08,857 iteration 3078 : loss : 0.072456, loss_ce: 0.022264
2021-12-17 17:03:10,274 iteration 3079 : loss : 0.082308, loss_ce: 0.022511
2021-12-17 17:03:11,642 iteration 3080 : loss : 0.077143, loss_ce: 0.023581
2021-12-17 17:03:13,009 iteration 3081 : loss : 0.074356, loss_ce: 0.018787
2021-12-17 17:03:14,408 iteration 3082 : loss : 0.069874, loss_ce: 0.022279
2021-12-17 17:03:15,797 iteration 3083 : loss : 0.087883, loss_ce: 0.034415
2021-12-17 17:03:17,166 iteration 3084 : loss : 0.069388, loss_ce: 0.019761
2021-12-17 17:03:18,554 iteration 3085 : loss : 0.118839, loss_ce: 0.018373
2021-12-17 17:03:19,897 iteration 3086 : loss : 0.073798, loss_ce: 0.021985
2021-12-17 17:03:21,236 iteration 3087 : loss : 0.074307, loss_ce: 0.017372
2021-12-17 17:03:22,583 iteration 3088 : loss : 0.091554, loss_ce: 0.027803
2021-12-17 17:03:23,917 iteration 3089 : loss : 0.073108, loss_ce: 0.021880
2021-12-17 17:03:25,312 iteration 3090 : loss : 0.073474, loss_ce: 0.019915
2021-12-17 17:03:26,655 iteration 3091 : loss : 0.079282, loss_ce: 0.025511
2021-12-17 17:03:27,963 iteration 3092 : loss : 0.077328, loss_ce: 0.029121
2021-12-17 17:03:29,333 iteration 3093 : loss : 0.060663, loss_ce: 0.014471
2021-12-17 17:03:30,679 iteration 3094 : loss : 0.085007, loss_ce: 0.034333
 46%|████████████▎              | 182/400 [1:18:49<1:32:23, 25.43s/it]2021-12-17 17:03:32,175 iteration 3095 : loss : 0.074480, loss_ce: 0.018322
2021-12-17 17:03:33,532 iteration 3096 : loss : 0.073657, loss_ce: 0.023627
2021-12-17 17:03:34,898 iteration 3097 : loss : 0.089097, loss_ce: 0.029567
2021-12-17 17:03:36,228 iteration 3098 : loss : 0.078844, loss_ce: 0.023606
2021-12-17 17:03:37,659 iteration 3099 : loss : 0.090691, loss_ce: 0.025677
2021-12-17 17:03:38,981 iteration 3100 : loss : 0.069932, loss_ce: 0.017923
2021-12-17 17:03:40,342 iteration 3101 : loss : 0.075866, loss_ce: 0.027269
2021-12-17 17:03:41,751 iteration 3102 : loss : 0.067850, loss_ce: 0.017997
2021-12-17 17:03:43,109 iteration 3103 : loss : 0.075042, loss_ce: 0.017004
2021-12-17 17:03:44,485 iteration 3104 : loss : 0.066833, loss_ce: 0.015768
2021-12-17 17:03:45,837 iteration 3105 : loss : 0.075020, loss_ce: 0.022516
2021-12-17 17:03:47,348 iteration 3106 : loss : 0.077120, loss_ce: 0.023813
2021-12-17 17:03:48,709 iteration 3107 : loss : 0.074704, loss_ce: 0.025340
2021-12-17 17:03:50,021 iteration 3108 : loss : 0.076805, loss_ce: 0.022810
2021-12-17 17:03:51,453 iteration 3109 : loss : 0.074742, loss_ce: 0.032142
2021-12-17 17:03:52,883 iteration 3110 : loss : 0.092908, loss_ce: 0.039133
2021-12-17 17:03:54,209 iteration 3111 : loss : 0.080292, loss_ce: 0.022151
 46%|████████████▎              | 183/400 [1:19:13<1:29:54, 24.86s/it]2021-12-17 17:03:55,605 iteration 3112 : loss : 0.063250, loss_ce: 0.019252
2021-12-17 17:03:56,978 iteration 3113 : loss : 0.066624, loss_ce: 0.021807
2021-12-17 17:03:58,463 iteration 3114 : loss : 0.119738, loss_ce: 0.027276
2021-12-17 17:03:59,884 iteration 3115 : loss : 0.082831, loss_ce: 0.031702
2021-12-17 17:04:01,269 iteration 3116 : loss : 0.069249, loss_ce: 0.019332
2021-12-17 17:04:02,625 iteration 3117 : loss : 0.071354, loss_ce: 0.020558
2021-12-17 17:04:04,047 iteration 3118 : loss : 0.095094, loss_ce: 0.031845
2021-12-17 17:04:05,457 iteration 3119 : loss : 0.079401, loss_ce: 0.025559
2021-12-17 17:04:06,841 iteration 3120 : loss : 0.068120, loss_ce: 0.018679
2021-12-17 17:04:08,231 iteration 3121 : loss : 0.079144, loss_ce: 0.019522
2021-12-17 17:04:09,660 iteration 3122 : loss : 0.091279, loss_ce: 0.020203
2021-12-17 17:04:11,031 iteration 3123 : loss : 0.074173, loss_ce: 0.024018
2021-12-17 17:04:12,427 iteration 3124 : loss : 0.074148, loss_ce: 0.025476
2021-12-17 17:04:13,824 iteration 3125 : loss : 0.102399, loss_ce: 0.038722
2021-12-17 17:04:15,136 iteration 3126 : loss : 0.067987, loss_ce: 0.020862
2021-12-17 17:04:16,530 iteration 3127 : loss : 0.084598, loss_ce: 0.025748
2021-12-17 17:04:17,845 iteration 3128 : loss : 0.063678, loss_ce: 0.017100
 46%|████████████▍              | 184/400 [1:19:36<1:28:09, 24.49s/it]2021-12-17 17:04:19,307 iteration 3129 : loss : 0.082298, loss_ce: 0.023169
2021-12-17 17:04:20,689 iteration 3130 : loss : 0.071725, loss_ce: 0.018998
2021-12-17 17:04:22,109 iteration 3131 : loss : 0.102632, loss_ce: 0.038367
2021-12-17 17:04:23,474 iteration 3132 : loss : 0.073022, loss_ce: 0.025591
2021-12-17 17:04:24,807 iteration 3133 : loss : 0.068117, loss_ce: 0.019196
2021-12-17 17:04:26,186 iteration 3134 : loss : 0.066028, loss_ce: 0.017166
2021-12-17 17:04:27,562 iteration 3135 : loss : 0.078900, loss_ce: 0.027842
2021-12-17 17:04:28,980 iteration 3136 : loss : 0.089229, loss_ce: 0.026023
2021-12-17 17:04:30,369 iteration 3137 : loss : 0.079437, loss_ce: 0.029515
2021-12-17 17:04:31,773 iteration 3138 : loss : 0.098520, loss_ce: 0.042045
2021-12-17 17:04:33,212 iteration 3139 : loss : 0.084145, loss_ce: 0.024193
2021-12-17 17:04:34,624 iteration 3140 : loss : 0.077904, loss_ce: 0.023343
2021-12-17 17:04:36,039 iteration 3141 : loss : 0.071493, loss_ce: 0.019451
2021-12-17 17:04:37,406 iteration 3142 : loss : 0.075679, loss_ce: 0.020926
2021-12-17 17:04:38,832 iteration 3143 : loss : 0.077261, loss_ce: 0.025848
2021-12-17 17:04:40,264 iteration 3144 : loss : 0.076953, loss_ce: 0.025860
2021-12-17 17:04:40,265 Training Data Eval:
2021-12-17 17:04:47,404   Average segmentation loss on training set: 0.0590
2021-12-17 17:04:47,404 Validation Data Eval:
2021-12-17 17:04:49,891   Average segmentation loss on validation set: 0.1364
2021-12-17 17:04:51,200 iteration 3145 : loss : 0.067239, loss_ce: 0.018480
 46%|████████████▍              | 185/400 [1:20:10<1:37:17, 27.15s/it]2021-12-17 17:04:52,572 iteration 3146 : loss : 0.065729, loss_ce: 0.018573
2021-12-17 17:04:53,939 iteration 3147 : loss : 0.080476, loss_ce: 0.025556
2021-12-17 17:04:55,301 iteration 3148 : loss : 0.071769, loss_ce: 0.019282
2021-12-17 17:04:56,653 iteration 3149 : loss : 0.065758, loss_ce: 0.018355
2021-12-17 17:04:58,024 iteration 3150 : loss : 0.072701, loss_ce: 0.026562
2021-12-17 17:04:59,362 iteration 3151 : loss : 0.093456, loss_ce: 0.023705
2021-12-17 17:05:00,720 iteration 3152 : loss : 0.071054, loss_ce: 0.019876
2021-12-17 17:05:02,106 iteration 3153 : loss : 0.073434, loss_ce: 0.021168
2021-12-17 17:05:03,445 iteration 3154 : loss : 0.074769, loss_ce: 0.024882
2021-12-17 17:05:04,802 iteration 3155 : loss : 0.075180, loss_ce: 0.020956
2021-12-17 17:05:06,230 iteration 3156 : loss : 0.081260, loss_ce: 0.022606
2021-12-17 17:05:07,622 iteration 3157 : loss : 0.077124, loss_ce: 0.024340
2021-12-17 17:05:08,965 iteration 3158 : loss : 0.078212, loss_ce: 0.027583
2021-12-17 17:05:10,332 iteration 3159 : loss : 0.066621, loss_ce: 0.019723
2021-12-17 17:05:11,690 iteration 3160 : loss : 0.075559, loss_ce: 0.025390
2021-12-17 17:05:13,016 iteration 3161 : loss : 0.067436, loss_ce: 0.019148
2021-12-17 17:05:14,449 iteration 3162 : loss : 0.077202, loss_ce: 0.024636
 46%|████████████▌              | 186/400 [1:20:33<1:32:40, 25.98s/it]2021-12-17 17:05:15,924 iteration 3163 : loss : 0.086354, loss_ce: 0.029765
2021-12-17 17:05:17,323 iteration 3164 : loss : 0.073786, loss_ce: 0.021997
2021-12-17 17:05:18,674 iteration 3165 : loss : 0.065007, loss_ce: 0.018206
2021-12-17 17:05:20,098 iteration 3166 : loss : 0.068029, loss_ce: 0.017219
2021-12-17 17:05:21,465 iteration 3167 : loss : 0.062000, loss_ce: 0.016919
2021-12-17 17:05:22,951 iteration 3168 : loss : 0.091173, loss_ce: 0.033842
2021-12-17 17:05:24,403 iteration 3169 : loss : 0.090175, loss_ce: 0.034680
2021-12-17 17:05:25,739 iteration 3170 : loss : 0.069976, loss_ce: 0.024346
2021-12-17 17:05:27,050 iteration 3171 : loss : 0.066209, loss_ce: 0.021683
2021-12-17 17:05:28,453 iteration 3172 : loss : 0.075435, loss_ce: 0.024028
2021-12-17 17:05:29,881 iteration 3173 : loss : 0.070343, loss_ce: 0.022380
2021-12-17 17:05:31,249 iteration 3174 : loss : 0.078654, loss_ce: 0.025057
2021-12-17 17:05:32,698 iteration 3175 : loss : 0.097885, loss_ce: 0.025731
2021-12-17 17:05:34,063 iteration 3176 : loss : 0.087513, loss_ce: 0.026842
2021-12-17 17:05:35,479 iteration 3177 : loss : 0.100084, loss_ce: 0.033446
2021-12-17 17:05:36,798 iteration 3178 : loss : 0.079161, loss_ce: 0.022640
2021-12-17 17:05:38,155 iteration 3179 : loss : 0.105535, loss_ce: 0.028655
 47%|████████████▌              | 187/400 [1:20:57<1:29:48, 25.30s/it]2021-12-17 17:05:39,623 iteration 3180 : loss : 0.101487, loss_ce: 0.032687
2021-12-17 17:05:40,947 iteration 3181 : loss : 0.062570, loss_ce: 0.017098
2021-12-17 17:05:42,327 iteration 3182 : loss : 0.113641, loss_ce: 0.031803
2021-12-17 17:05:43,672 iteration 3183 : loss : 0.067726, loss_ce: 0.015327
2021-12-17 17:05:45,048 iteration 3184 : loss : 0.085980, loss_ce: 0.028146
2021-12-17 17:05:46,451 iteration 3185 : loss : 0.087558, loss_ce: 0.029831
2021-12-17 17:05:47,746 iteration 3186 : loss : 0.069840, loss_ce: 0.023691
2021-12-17 17:05:49,121 iteration 3187 : loss : 0.059613, loss_ce: 0.017613
2021-12-17 17:05:50,487 iteration 3188 : loss : 0.069427, loss_ce: 0.024185
2021-12-17 17:05:51,887 iteration 3189 : loss : 0.084183, loss_ce: 0.029756
2021-12-17 17:05:53,259 iteration 3190 : loss : 0.068009, loss_ce: 0.020297
2021-12-17 17:05:54,736 iteration 3191 : loss : 0.088767, loss_ce: 0.020624
2021-12-17 17:05:56,057 iteration 3192 : loss : 0.086748, loss_ce: 0.022308
2021-12-17 17:05:57,477 iteration 3193 : loss : 0.086668, loss_ce: 0.037461
2021-12-17 17:05:58,898 iteration 3194 : loss : 0.077945, loss_ce: 0.017256
2021-12-17 17:06:00,278 iteration 3195 : loss : 0.072675, loss_ce: 0.026238
2021-12-17 17:06:01,644 iteration 3196 : loss : 0.076640, loss_ce: 0.026806
 47%|████████████▋              | 188/400 [1:21:20<1:27:28, 24.76s/it]2021-12-17 17:06:03,005 iteration 3197 : loss : 0.066726, loss_ce: 0.021673
2021-12-17 17:06:04,355 iteration 3198 : loss : 0.082593, loss_ce: 0.027426
2021-12-17 17:06:05,726 iteration 3199 : loss : 0.088925, loss_ce: 0.029349
2021-12-17 17:06:07,176 iteration 3200 : loss : 0.085082, loss_ce: 0.031502
2021-12-17 17:06:08,571 iteration 3201 : loss : 0.121766, loss_ce: 0.027333
2021-12-17 17:06:09,951 iteration 3202 : loss : 0.077362, loss_ce: 0.023127
2021-12-17 17:06:11,415 iteration 3203 : loss : 0.075784, loss_ce: 0.024316
2021-12-17 17:06:12,770 iteration 3204 : loss : 0.070334, loss_ce: 0.017753
2021-12-17 17:06:14,190 iteration 3205 : loss : 0.092794, loss_ce: 0.025413
2021-12-17 17:06:15,567 iteration 3206 : loss : 0.072309, loss_ce: 0.023507
2021-12-17 17:06:17,022 iteration 3207 : loss : 0.102556, loss_ce: 0.039895
2021-12-17 17:06:18,347 iteration 3208 : loss : 0.070334, loss_ce: 0.018036
2021-12-17 17:06:19,690 iteration 3209 : loss : 0.076432, loss_ce: 0.030878
2021-12-17 17:06:20,981 iteration 3210 : loss : 0.065913, loss_ce: 0.023940
2021-12-17 17:06:22,332 iteration 3211 : loss : 0.076083, loss_ce: 0.019032
2021-12-17 17:06:23,688 iteration 3212 : loss : 0.080944, loss_ce: 0.025295
2021-12-17 17:06:25,065 iteration 3213 : loss : 0.083543, loss_ce: 0.020758
 47%|████████████▊              | 189/400 [1:21:44<1:25:39, 24.36s/it]2021-12-17 17:06:26,499 iteration 3214 : loss : 0.069150, loss_ce: 0.023570
2021-12-17 17:06:27,948 iteration 3215 : loss : 0.080679, loss_ce: 0.026170
2021-12-17 17:06:29,365 iteration 3216 : loss : 0.072871, loss_ce: 0.020959
2021-12-17 17:06:30,786 iteration 3217 : loss : 0.111332, loss_ce: 0.023133
2021-12-17 17:06:32,168 iteration 3218 : loss : 0.085211, loss_ce: 0.027278
2021-12-17 17:06:33,520 iteration 3219 : loss : 0.077697, loss_ce: 0.023364
2021-12-17 17:06:34,930 iteration 3220 : loss : 0.073793, loss_ce: 0.021911
2021-12-17 17:06:36,277 iteration 3221 : loss : 0.077726, loss_ce: 0.029576
2021-12-17 17:06:37,655 iteration 3222 : loss : 0.080473, loss_ce: 0.035204
2021-12-17 17:06:39,056 iteration 3223 : loss : 0.072017, loss_ce: 0.018447
2021-12-17 17:06:40,481 iteration 3224 : loss : 0.069343, loss_ce: 0.019475
2021-12-17 17:06:41,839 iteration 3225 : loss : 0.072044, loss_ce: 0.019006
2021-12-17 17:06:43,294 iteration 3226 : loss : 0.088356, loss_ce: 0.027549
2021-12-17 17:06:44,676 iteration 3227 : loss : 0.065319, loss_ce: 0.019730
2021-12-17 17:06:45,981 iteration 3228 : loss : 0.066288, loss_ce: 0.023612
2021-12-17 17:06:47,421 iteration 3229 : loss : 0.077094, loss_ce: 0.026593
2021-12-17 17:06:47,422 Training Data Eval:
2021-12-17 17:06:54,565   Average segmentation loss on training set: 0.0564
2021-12-17 17:06:54,565 Validation Data Eval:
2021-12-17 17:06:57,036   Average segmentation loss on validation set: 0.1386
2021-12-17 17:06:58,504 iteration 3230 : loss : 0.082510, loss_ce: 0.026941
 48%|████████████▊              | 190/400 [1:22:17<1:34:46, 27.08s/it]2021-12-17 17:06:59,916 iteration 3231 : loss : 0.074787, loss_ce: 0.022477
2021-12-17 17:07:01,292 iteration 3232 : loss : 0.072074, loss_ce: 0.026048
2021-12-17 17:07:02,646 iteration 3233 : loss : 0.079198, loss_ce: 0.023353
2021-12-17 17:07:03,977 iteration 3234 : loss : 0.078641, loss_ce: 0.023076
2021-12-17 17:07:05,312 iteration 3235 : loss : 0.065004, loss_ce: 0.015104
2021-12-17 17:07:06,708 iteration 3236 : loss : 0.076038, loss_ce: 0.023923
2021-12-17 17:07:08,110 iteration 3237 : loss : 0.064750, loss_ce: 0.021872
2021-12-17 17:07:09,493 iteration 3238 : loss : 0.078715, loss_ce: 0.016682
2021-12-17 17:07:10,856 iteration 3239 : loss : 0.063335, loss_ce: 0.019745
2021-12-17 17:07:12,241 iteration 3240 : loss : 0.074748, loss_ce: 0.022301
2021-12-17 17:07:13,652 iteration 3241 : loss : 0.075012, loss_ce: 0.023792
2021-12-17 17:07:15,109 iteration 3242 : loss : 0.082415, loss_ce: 0.030086
2021-12-17 17:07:16,450 iteration 3243 : loss : 0.069755, loss_ce: 0.024053
2021-12-17 17:07:17,805 iteration 3244 : loss : 0.107474, loss_ce: 0.029985
2021-12-17 17:07:19,150 iteration 3245 : loss : 0.073944, loss_ce: 0.023577
2021-12-17 17:07:20,581 iteration 3246 : loss : 0.085664, loss_ce: 0.031979
2021-12-17 17:07:21,971 iteration 3247 : loss : 0.066498, loss_ce: 0.018225
 48%|████████████▉              | 191/400 [1:22:41<1:30:33, 26.00s/it]2021-12-17 17:07:23,541 iteration 3248 : loss : 0.081818, loss_ce: 0.030622
2021-12-17 17:07:24,841 iteration 3249 : loss : 0.060225, loss_ce: 0.014836
2021-12-17 17:07:26,237 iteration 3250 : loss : 0.079082, loss_ce: 0.024455
2021-12-17 17:07:27,600 iteration 3251 : loss : 0.078132, loss_ce: 0.015400
2021-12-17 17:07:28,924 iteration 3252 : loss : 0.071390, loss_ce: 0.023639
2021-12-17 17:07:30,318 iteration 3253 : loss : 0.075164, loss_ce: 0.025278
2021-12-17 17:07:31,701 iteration 3254 : loss : 0.077686, loss_ce: 0.021479
2021-12-17 17:07:33,126 iteration 3255 : loss : 0.066157, loss_ce: 0.018194
2021-12-17 17:07:34,446 iteration 3256 : loss : 0.071518, loss_ce: 0.029013
2021-12-17 17:07:35,796 iteration 3257 : loss : 0.087565, loss_ce: 0.023981
2021-12-17 17:07:37,233 iteration 3258 : loss : 0.080735, loss_ce: 0.029466
2021-12-17 17:07:38,601 iteration 3259 : loss : 0.078731, loss_ce: 0.023480
2021-12-17 17:07:39,942 iteration 3260 : loss : 0.067505, loss_ce: 0.020938
2021-12-17 17:07:41,366 iteration 3261 : loss : 0.084525, loss_ce: 0.026583
2021-12-17 17:07:42,734 iteration 3262 : loss : 0.093464, loss_ce: 0.030854
2021-12-17 17:07:44,094 iteration 3263 : loss : 0.074357, loss_ce: 0.017985
2021-12-17 17:07:45,442 iteration 3264 : loss : 0.073673, loss_ce: 0.022232
 48%|████████████▉              | 192/400 [1:23:04<1:27:30, 25.24s/it]2021-12-17 17:07:46,762 iteration 3265 : loss : 0.056939, loss_ce: 0.016147
2021-12-17 17:07:48,152 iteration 3266 : loss : 0.075831, loss_ce: 0.027549
2021-12-17 17:07:49,474 iteration 3267 : loss : 0.070147, loss_ce: 0.021181
2021-12-17 17:07:50,938 iteration 3268 : loss : 0.092288, loss_ce: 0.031783
2021-12-17 17:07:52,242 iteration 3269 : loss : 0.064966, loss_ce: 0.019132
2021-12-17 17:07:53,560 iteration 3270 : loss : 0.065416, loss_ce: 0.019893
2021-12-17 17:07:55,000 iteration 3271 : loss : 0.082380, loss_ce: 0.026460
2021-12-17 17:07:56,341 iteration 3272 : loss : 0.065123, loss_ce: 0.019712
2021-12-17 17:07:57,685 iteration 3273 : loss : 0.086683, loss_ce: 0.025379
2021-12-17 17:07:59,093 iteration 3274 : loss : 0.073462, loss_ce: 0.020923
2021-12-17 17:08:00,413 iteration 3275 : loss : 0.062064, loss_ce: 0.018592
2021-12-17 17:08:01,779 iteration 3276 : loss : 0.069873, loss_ce: 0.017686
2021-12-17 17:08:03,201 iteration 3277 : loss : 0.073847, loss_ce: 0.026050
2021-12-17 17:08:04,556 iteration 3278 : loss : 0.075639, loss_ce: 0.023847
2021-12-17 17:08:05,962 iteration 3279 : loss : 0.099363, loss_ce: 0.035070
2021-12-17 17:08:07,337 iteration 3280 : loss : 0.072841, loss_ce: 0.023861
2021-12-17 17:08:08,710 iteration 3281 : loss : 0.065841, loss_ce: 0.015839
 48%|█████████████              | 193/400 [1:23:27<1:25:01, 24.65s/it]2021-12-17 17:08:10,102 iteration 3282 : loss : 0.069813, loss_ce: 0.022729
2021-12-17 17:08:11,564 iteration 3283 : loss : 0.084888, loss_ce: 0.026536
2021-12-17 17:08:12,901 iteration 3284 : loss : 0.065359, loss_ce: 0.022516
2021-12-17 17:08:14,195 iteration 3285 : loss : 0.060799, loss_ce: 0.016704
2021-12-17 17:08:15,615 iteration 3286 : loss : 0.076598, loss_ce: 0.017848
2021-12-17 17:08:17,017 iteration 3287 : loss : 0.073089, loss_ce: 0.024693
2021-12-17 17:08:18,397 iteration 3288 : loss : 0.077230, loss_ce: 0.021101
2021-12-17 17:08:19,786 iteration 3289 : loss : 0.090922, loss_ce: 0.021325
2021-12-17 17:08:21,092 iteration 3290 : loss : 0.062870, loss_ce: 0.015074
2021-12-17 17:08:22,497 iteration 3291 : loss : 0.073813, loss_ce: 0.020103
2021-12-17 17:08:23,845 iteration 3292 : loss : 0.068271, loss_ce: 0.023857
2021-12-17 17:08:25,161 iteration 3293 : loss : 0.063602, loss_ce: 0.019603
2021-12-17 17:08:26,492 iteration 3294 : loss : 0.060886, loss_ce: 0.018560
2021-12-17 17:08:27,862 iteration 3295 : loss : 0.064624, loss_ce: 0.021614
2021-12-17 17:08:29,245 iteration 3296 : loss : 0.066295, loss_ce: 0.019226
2021-12-17 17:08:30,596 iteration 3297 : loss : 0.092605, loss_ce: 0.036070
2021-12-17 17:08:31,905 iteration 3298 : loss : 0.068623, loss_ce: 0.021796
 48%|█████████████              | 194/400 [1:23:51<1:23:07, 24.21s/it]2021-12-17 17:08:33,299 iteration 3299 : loss : 0.062735, loss_ce: 0.020062
2021-12-17 17:08:34,637 iteration 3300 : loss : 0.074775, loss_ce: 0.023484
2021-12-17 17:08:36,037 iteration 3301 : loss : 0.089917, loss_ce: 0.021803
2021-12-17 17:08:37,340 iteration 3302 : loss : 0.066626, loss_ce: 0.016470
2021-12-17 17:08:38,745 iteration 3303 : loss : 0.074733, loss_ce: 0.022750
2021-12-17 17:08:40,125 iteration 3304 : loss : 0.071690, loss_ce: 0.028473
2021-12-17 17:08:41,528 iteration 3305 : loss : 0.072483, loss_ce: 0.020783
2021-12-17 17:08:42,863 iteration 3306 : loss : 0.062976, loss_ce: 0.019396
2021-12-17 17:08:44,303 iteration 3307 : loss : 0.077489, loss_ce: 0.025342
2021-12-17 17:08:45,736 iteration 3308 : loss : 0.100428, loss_ce: 0.032855
2021-12-17 17:08:47,113 iteration 3309 : loss : 0.065262, loss_ce: 0.019667
2021-12-17 17:08:48,539 iteration 3310 : loss : 0.115291, loss_ce: 0.029782
2021-12-17 17:08:49,902 iteration 3311 : loss : 0.084870, loss_ce: 0.019415
2021-12-17 17:08:51,229 iteration 3312 : loss : 0.063627, loss_ce: 0.021751
2021-12-17 17:08:52,639 iteration 3313 : loss : 0.077319, loss_ce: 0.025036
2021-12-17 17:08:53,911 iteration 3314 : loss : 0.062649, loss_ce: 0.021803
2021-12-17 17:08:53,912 Training Data Eval:
2021-12-17 17:09:01,014   Average segmentation loss on training set: 0.0553
2021-12-17 17:09:01,014 Validation Data Eval:
2021-12-17 17:09:03,508   Average segmentation loss on validation set: 0.1430
2021-12-17 17:09:04,858 iteration 3315 : loss : 0.076798, loss_ce: 0.025026
 49%|█████████████▏             | 195/400 [1:24:23<1:31:40, 26.83s/it]2021-12-17 17:09:06,280 iteration 3316 : loss : 0.067455, loss_ce: 0.015070
2021-12-17 17:09:07,660 iteration 3317 : loss : 0.080054, loss_ce: 0.026260
2021-12-17 17:09:09,034 iteration 3318 : loss : 0.095988, loss_ce: 0.035558
2021-12-17 17:09:10,363 iteration 3319 : loss : 0.067832, loss_ce: 0.019618
2021-12-17 17:09:11,829 iteration 3320 : loss : 0.082555, loss_ce: 0.026251
2021-12-17 17:09:13,134 iteration 3321 : loss : 0.062151, loss_ce: 0.022192
2021-12-17 17:09:14,422 iteration 3322 : loss : 0.061751, loss_ce: 0.015326
2021-12-17 17:09:15,799 iteration 3323 : loss : 0.087500, loss_ce: 0.030070
2021-12-17 17:09:17,168 iteration 3324 : loss : 0.070723, loss_ce: 0.019755
2021-12-17 17:09:18,594 iteration 3325 : loss : 0.093684, loss_ce: 0.025687
2021-12-17 17:09:19,985 iteration 3326 : loss : 0.079147, loss_ce: 0.025918
2021-12-17 17:09:21,478 iteration 3327 : loss : 0.080706, loss_ce: 0.021678
2021-12-17 17:09:22,806 iteration 3328 : loss : 0.074845, loss_ce: 0.030284
2021-12-17 17:09:24,149 iteration 3329 : loss : 0.070065, loss_ce: 0.017658
2021-12-17 17:09:25,548 iteration 3330 : loss : 0.068449, loss_ce: 0.025981
2021-12-17 17:09:26,842 iteration 3331 : loss : 0.066025, loss_ce: 0.020243
2021-12-17 17:09:28,116 iteration 3332 : loss : 0.070753, loss_ce: 0.019350
 49%|█████████████▏             | 196/400 [1:24:47<1:27:35, 25.76s/it]2021-12-17 17:09:29,525 iteration 3333 : loss : 0.082366, loss_ce: 0.024794
2021-12-17 17:09:30,894 iteration 3334 : loss : 0.067866, loss_ce: 0.023378
2021-12-17 17:09:32,314 iteration 3335 : loss : 0.089096, loss_ce: 0.029441
2021-12-17 17:09:33,645 iteration 3336 : loss : 0.071684, loss_ce: 0.022840
2021-12-17 17:09:34,962 iteration 3337 : loss : 0.069903, loss_ce: 0.020236
2021-12-17 17:09:36,354 iteration 3338 : loss : 0.086655, loss_ce: 0.033439
2021-12-17 17:09:37,760 iteration 3339 : loss : 0.080300, loss_ce: 0.021286
2021-12-17 17:09:39,124 iteration 3340 : loss : 0.085817, loss_ce: 0.026257
2021-12-17 17:09:40,452 iteration 3341 : loss : 0.070095, loss_ce: 0.022767
2021-12-17 17:09:41,770 iteration 3342 : loss : 0.092577, loss_ce: 0.038630
2021-12-17 17:09:43,119 iteration 3343 : loss : 0.074289, loss_ce: 0.025386
2021-12-17 17:09:44,537 iteration 3344 : loss : 0.069313, loss_ce: 0.015292
2021-12-17 17:09:45,959 iteration 3345 : loss : 0.067597, loss_ce: 0.026315
2021-12-17 17:09:47,331 iteration 3346 : loss : 0.087780, loss_ce: 0.026579
2021-12-17 17:09:48,678 iteration 3347 : loss : 0.076157, loss_ce: 0.022418
2021-12-17 17:09:50,116 iteration 3348 : loss : 0.075511, loss_ce: 0.024561
2021-12-17 17:09:51,434 iteration 3349 : loss : 0.075229, loss_ce: 0.016526
 49%|█████████████▎             | 197/400 [1:25:10<1:24:40, 25.03s/it]2021-12-17 17:09:52,804 iteration 3350 : loss : 0.066269, loss_ce: 0.023203
2021-12-17 17:09:54,206 iteration 3351 : loss : 0.072404, loss_ce: 0.021489
2021-12-17 17:09:55,530 iteration 3352 : loss : 0.080287, loss_ce: 0.020364
2021-12-17 17:09:56,892 iteration 3353 : loss : 0.067313, loss_ce: 0.017147
2021-12-17 17:09:58,228 iteration 3354 : loss : 0.070073, loss_ce: 0.015289
2021-12-17 17:09:59,595 iteration 3355 : loss : 0.070806, loss_ce: 0.023179
2021-12-17 17:10:00,916 iteration 3356 : loss : 0.087937, loss_ce: 0.031042
2021-12-17 17:10:02,247 iteration 3357 : loss : 0.060870, loss_ce: 0.019889
2021-12-17 17:10:03,617 iteration 3358 : loss : 0.065957, loss_ce: 0.017136
2021-12-17 17:10:04,956 iteration 3359 : loss : 0.071352, loss_ce: 0.025003
2021-12-17 17:10:06,351 iteration 3360 : loss : 0.061205, loss_ce: 0.014636
2021-12-17 17:10:07,724 iteration 3361 : loss : 0.063492, loss_ce: 0.018343
2021-12-17 17:10:09,056 iteration 3362 : loss : 0.072139, loss_ce: 0.021235
2021-12-17 17:10:10,341 iteration 3363 : loss : 0.075416, loss_ce: 0.021938
2021-12-17 17:10:11,756 iteration 3364 : loss : 0.078320, loss_ce: 0.024290
2021-12-17 17:10:13,098 iteration 3365 : loss : 0.078184, loss_ce: 0.024117
2021-12-17 17:10:14,445 iteration 3366 : loss : 0.067554, loss_ce: 0.022397
 50%|█████████████▎             | 198/400 [1:25:33<1:22:13, 24.42s/it]2021-12-17 17:10:15,957 iteration 3367 : loss : 0.074011, loss_ce: 0.024172
2021-12-17 17:10:17,319 iteration 3368 : loss : 0.084286, loss_ce: 0.032669
2021-12-17 17:10:18,695 iteration 3369 : loss : 0.066641, loss_ce: 0.023461
2021-12-17 17:10:20,010 iteration 3370 : loss : 0.064895, loss_ce: 0.014988
2021-12-17 17:10:21,360 iteration 3371 : loss : 0.059853, loss_ce: 0.017493
2021-12-17 17:10:22,774 iteration 3372 : loss : 0.089695, loss_ce: 0.026006
2021-12-17 17:10:24,140 iteration 3373 : loss : 0.088368, loss_ce: 0.031105
2021-12-17 17:10:25,576 iteration 3374 : loss : 0.068760, loss_ce: 0.022645
2021-12-17 17:10:27,041 iteration 3375 : loss : 0.082119, loss_ce: 0.024574
2021-12-17 17:10:28,334 iteration 3376 : loss : 0.059702, loss_ce: 0.016869
2021-12-17 17:10:29,742 iteration 3377 : loss : 0.068667, loss_ce: 0.023024
2021-12-17 17:10:31,070 iteration 3378 : loss : 0.073387, loss_ce: 0.020462
2021-12-17 17:10:32,465 iteration 3379 : loss : 0.065571, loss_ce: 0.020426
2021-12-17 17:10:33,784 iteration 3380 : loss : 0.061333, loss_ce: 0.016036
2021-12-17 17:10:35,168 iteration 3381 : loss : 0.080410, loss_ce: 0.029892
2021-12-17 17:10:36,567 iteration 3382 : loss : 0.075645, loss_ce: 0.020258
2021-12-17 17:10:37,926 iteration 3383 : loss : 0.088500, loss_ce: 0.029690
 50%|█████████████▍             | 199/400 [1:25:57<1:20:52, 24.14s/it]2021-12-17 17:10:39,347 iteration 3384 : loss : 0.071096, loss_ce: 0.021501
2021-12-17 17:10:40,684 iteration 3385 : loss : 0.083397, loss_ce: 0.026164
2021-12-17 17:10:42,003 iteration 3386 : loss : 0.065178, loss_ce: 0.015785
2021-12-17 17:10:43,315 iteration 3387 : loss : 0.087020, loss_ce: 0.025922
2021-12-17 17:10:44,733 iteration 3388 : loss : 0.067829, loss_ce: 0.020726
2021-12-17 17:10:46,043 iteration 3389 : loss : 0.072919, loss_ce: 0.018676
2021-12-17 17:10:47,416 iteration 3390 : loss : 0.079456, loss_ce: 0.025095
2021-12-17 17:10:48,872 iteration 3391 : loss : 0.073646, loss_ce: 0.028693
2021-12-17 17:10:50,277 iteration 3392 : loss : 0.077287, loss_ce: 0.025390
2021-12-17 17:10:51,585 iteration 3393 : loss : 0.066058, loss_ce: 0.022212
2021-12-17 17:10:52,935 iteration 3394 : loss : 0.069129, loss_ce: 0.021013
2021-12-17 17:10:54,306 iteration 3395 : loss : 0.071029, loss_ce: 0.024504
2021-12-17 17:10:55,682 iteration 3396 : loss : 0.070219, loss_ce: 0.020365
2021-12-17 17:10:56,999 iteration 3397 : loss : 0.067246, loss_ce: 0.020786
2021-12-17 17:10:58,497 iteration 3398 : loss : 0.084590, loss_ce: 0.025764
2021-12-17 17:10:59,875 iteration 3399 : loss : 0.066228, loss_ce: 0.022940
2021-12-17 17:10:59,875 Training Data Eval:
2021-12-17 17:11:06,933   Average segmentation loss on training set: 0.0543
2021-12-17 17:11:06,933 Validation Data Eval:
2021-12-17 17:11:09,406   Average segmentation loss on validation set: 0.1367
2021-12-17 17:11:10,806 iteration 3400 : loss : 0.072946, loss_ce: 0.017774
 50%|█████████████▌             | 200/400 [1:26:29<1:29:11, 26.76s/it]2021-12-17 17:11:12,272 iteration 3401 : loss : 0.083227, loss_ce: 0.029018
2021-12-17 17:11:13,663 iteration 3402 : loss : 0.081874, loss_ce: 0.030982
2021-12-17 17:11:15,108 iteration 3403 : loss : 0.086247, loss_ce: 0.031331
2021-12-17 17:11:16,426 iteration 3404 : loss : 0.070473, loss_ce: 0.018066
2021-12-17 17:11:17,779 iteration 3405 : loss : 0.067721, loss_ce: 0.015725
2021-12-17 17:11:19,086 iteration 3406 : loss : 0.067887, loss_ce: 0.025312
2021-12-17 17:11:20,421 iteration 3407 : loss : 0.080105, loss_ce: 0.030365
2021-12-17 17:11:21,785 iteration 3408 : loss : 0.061773, loss_ce: 0.017472
2021-12-17 17:11:23,142 iteration 3409 : loss : 0.064157, loss_ce: 0.012135
2021-12-17 17:11:24,506 iteration 3410 : loss : 0.069569, loss_ce: 0.023105
2021-12-17 17:11:25,907 iteration 3411 : loss : 0.095053, loss_ce: 0.027757
2021-12-17 17:11:27,331 iteration 3412 : loss : 0.067421, loss_ce: 0.023552
2021-12-17 17:11:28,785 iteration 3413 : loss : 0.077094, loss_ce: 0.027699
2021-12-17 17:11:30,201 iteration 3414 : loss : 0.127238, loss_ce: 0.036651
2021-12-17 17:11:31,473 iteration 3415 : loss : 0.064471, loss_ce: 0.019589
2021-12-17 17:11:32,858 iteration 3416 : loss : 0.074205, loss_ce: 0.026116
2021-12-17 17:11:34,203 iteration 3417 : loss : 0.064642, loss_ce: 0.021180
 50%|█████████████▌             | 201/400 [1:26:53<1:25:25, 25.75s/it]2021-12-17 17:11:35,704 iteration 3418 : loss : 0.089260, loss_ce: 0.021374
2021-12-17 17:11:37,068 iteration 3419 : loss : 0.092853, loss_ce: 0.038703
2021-12-17 17:11:38,372 iteration 3420 : loss : 0.067250, loss_ce: 0.027725
2021-12-17 17:11:39,734 iteration 3421 : loss : 0.080120, loss_ce: 0.021891
2021-12-17 17:11:41,098 iteration 3422 : loss : 0.074132, loss_ce: 0.022219
2021-12-17 17:11:42,520 iteration 3423 : loss : 0.088779, loss_ce: 0.036864
2021-12-17 17:11:43,832 iteration 3424 : loss : 0.062808, loss_ce: 0.017096
2021-12-17 17:11:45,217 iteration 3425 : loss : 0.071623, loss_ce: 0.028146
2021-12-17 17:11:46,558 iteration 3426 : loss : 0.060962, loss_ce: 0.013971
2021-12-17 17:11:48,019 iteration 3427 : loss : 0.096617, loss_ce: 0.030792
2021-12-17 17:11:49,391 iteration 3428 : loss : 0.072849, loss_ce: 0.023783
2021-12-17 17:11:50,783 iteration 3429 : loss : 0.075777, loss_ce: 0.028490
2021-12-17 17:11:52,178 iteration 3430 : loss : 0.060260, loss_ce: 0.015405
2021-12-17 17:11:53,596 iteration 3431 : loss : 0.077375, loss_ce: 0.024428
2021-12-17 17:11:54,919 iteration 3432 : loss : 0.067491, loss_ce: 0.019051
2021-12-17 17:11:56,299 iteration 3433 : loss : 0.081777, loss_ce: 0.020570
2021-12-17 17:11:57,656 iteration 3434 : loss : 0.069433, loss_ce: 0.019080
 50%|█████████████▋             | 202/400 [1:27:16<1:22:42, 25.06s/it]2021-12-17 17:11:59,011 iteration 3435 : loss : 0.063943, loss_ce: 0.023204
2021-12-17 17:12:00,356 iteration 3436 : loss : 0.081520, loss_ce: 0.024435
2021-12-17 17:12:01,674 iteration 3437 : loss : 0.063598, loss_ce: 0.017360
2021-12-17 17:12:03,033 iteration 3438 : loss : 0.082235, loss_ce: 0.033326
2021-12-17 17:12:04,458 iteration 3439 : loss : 0.066830, loss_ce: 0.020745
2021-12-17 17:12:05,877 iteration 3440 : loss : 0.075555, loss_ce: 0.018004
2021-12-17 17:12:07,147 iteration 3441 : loss : 0.059022, loss_ce: 0.021746
2021-12-17 17:12:08,485 iteration 3442 : loss : 0.060445, loss_ce: 0.015795
2021-12-17 17:12:09,878 iteration 3443 : loss : 0.069810, loss_ce: 0.020740
2021-12-17 17:12:11,216 iteration 3444 : loss : 0.064121, loss_ce: 0.016958
2021-12-17 17:12:12,603 iteration 3445 : loss : 0.064988, loss_ce: 0.019222
2021-12-17 17:12:13,942 iteration 3446 : loss : 0.082997, loss_ce: 0.025431
2021-12-17 17:12:15,303 iteration 3447 : loss : 0.078200, loss_ce: 0.033219
2021-12-17 17:12:16,602 iteration 3448 : loss : 0.062477, loss_ce: 0.017023
2021-12-17 17:12:17,990 iteration 3449 : loss : 0.078386, loss_ce: 0.018479
2021-12-17 17:12:19,402 iteration 3450 : loss : 0.068983, loss_ce: 0.017549
2021-12-17 17:12:20,719 iteration 3451 : loss : 0.067389, loss_ce: 0.025054
 51%|█████████████▋             | 203/400 [1:27:39<1:20:19, 24.46s/it]2021-12-17 17:12:22,131 iteration 3452 : loss : 0.062333, loss_ce: 0.016838
2021-12-17 17:12:23,541 iteration 3453 : loss : 0.069720, loss_ce: 0.021460
2021-12-17 17:12:24,954 iteration 3454 : loss : 0.072022, loss_ce: 0.019811
2021-12-17 17:12:26,339 iteration 3455 : loss : 0.071939, loss_ce: 0.026323
2021-12-17 17:12:27,722 iteration 3456 : loss : 0.080334, loss_ce: 0.023330
2021-12-17 17:12:29,107 iteration 3457 : loss : 0.068555, loss_ce: 0.019957
2021-12-17 17:12:30,511 iteration 3458 : loss : 0.062900, loss_ce: 0.024245
2021-12-17 17:12:31,951 iteration 3459 : loss : 0.069656, loss_ce: 0.025027
2021-12-17 17:12:33,346 iteration 3460 : loss : 0.066461, loss_ce: 0.020425
2021-12-17 17:12:34,711 iteration 3461 : loss : 0.067255, loss_ce: 0.021715
2021-12-17 17:12:36,032 iteration 3462 : loss : 0.066900, loss_ce: 0.020257
2021-12-17 17:12:37,323 iteration 3463 : loss : 0.059380, loss_ce: 0.015793
2021-12-17 17:12:38,687 iteration 3464 : loss : 0.069826, loss_ce: 0.021468
2021-12-17 17:12:40,012 iteration 3465 : loss : 0.067334, loss_ce: 0.017750
2021-12-17 17:12:41,398 iteration 3466 : loss : 0.061170, loss_ce: 0.019203
2021-12-17 17:12:42,850 iteration 3467 : loss : 0.092554, loss_ce: 0.032141
2021-12-17 17:12:44,326 iteration 3468 : loss : 0.077592, loss_ce: 0.021325
 51%|█████████████▊             | 204/400 [1:28:03<1:19:04, 24.21s/it]2021-12-17 17:12:45,665 iteration 3469 : loss : 0.069263, loss_ce: 0.022739
2021-12-17 17:12:47,145 iteration 3470 : loss : 0.087610, loss_ce: 0.025654
2021-12-17 17:12:48,547 iteration 3471 : loss : 0.067353, loss_ce: 0.021208
2021-12-17 17:12:49,960 iteration 3472 : loss : 0.081787, loss_ce: 0.027447
2021-12-17 17:12:51,380 iteration 3473 : loss : 0.077564, loss_ce: 0.029436
2021-12-17 17:12:52,711 iteration 3474 : loss : 0.070641, loss_ce: 0.022550
2021-12-17 17:12:54,150 iteration 3475 : loss : 0.081164, loss_ce: 0.025905
2021-12-17 17:12:55,505 iteration 3476 : loss : 0.069747, loss_ce: 0.021405
2021-12-17 17:12:56,913 iteration 3477 : loss : 0.088928, loss_ce: 0.021326
2021-12-17 17:12:58,307 iteration 3478 : loss : 0.061103, loss_ce: 0.017137
2021-12-17 17:12:59,661 iteration 3479 : loss : 0.068874, loss_ce: 0.023100
2021-12-17 17:13:00,988 iteration 3480 : loss : 0.059962, loss_ce: 0.018054
2021-12-17 17:13:02,360 iteration 3481 : loss : 0.081059, loss_ce: 0.035631
2021-12-17 17:13:03,670 iteration 3482 : loss : 0.077248, loss_ce: 0.022995
2021-12-17 17:13:05,085 iteration 3483 : loss : 0.066029, loss_ce: 0.020623
2021-12-17 17:13:06,440 iteration 3484 : loss : 0.065774, loss_ce: 0.014168
2021-12-17 17:13:06,440 Training Data Eval:
2021-12-17 17:13:13,521   Average segmentation loss on training set: 0.0523
2021-12-17 17:13:13,522 Validation Data Eval:
2021-12-17 17:13:16,028   Average segmentation loss on validation set: 0.1472
2021-12-17 17:13:17,422 iteration 3485 : loss : 0.069415, loss_ce: 0.021418
 51%|█████████████▊             | 205/400 [1:28:36<1:27:20, 26.87s/it]2021-12-17 17:13:18,827 iteration 3486 : loss : 0.063737, loss_ce: 0.017503
2021-12-17 17:13:20,200 iteration 3487 : loss : 0.064042, loss_ce: 0.019459
2021-12-17 17:13:21,606 iteration 3488 : loss : 0.088009, loss_ce: 0.043084
2021-12-17 17:13:22,935 iteration 3489 : loss : 0.071106, loss_ce: 0.018062
2021-12-17 17:13:24,357 iteration 3490 : loss : 0.091415, loss_ce: 0.030074
2021-12-17 17:13:25,766 iteration 3491 : loss : 0.084280, loss_ce: 0.028277
2021-12-17 17:13:27,063 iteration 3492 : loss : 0.057806, loss_ce: 0.014110
2021-12-17 17:13:28,516 iteration 3493 : loss : 0.093347, loss_ce: 0.022756
2021-12-17 17:13:29,896 iteration 3494 : loss : 0.065562, loss_ce: 0.024871
2021-12-17 17:13:31,180 iteration 3495 : loss : 0.069845, loss_ce: 0.024717
2021-12-17 17:13:32,571 iteration 3496 : loss : 0.115571, loss_ce: 0.028627
2021-12-17 17:13:33,996 iteration 3497 : loss : 0.078598, loss_ce: 0.024671
2021-12-17 17:13:35,363 iteration 3498 : loss : 0.071501, loss_ce: 0.022351
2021-12-17 17:13:36,772 iteration 3499 : loss : 0.079529, loss_ce: 0.019044
2021-12-17 17:13:38,103 iteration 3500 : loss : 0.069035, loss_ce: 0.018004
2021-12-17 17:13:39,484 iteration 3501 : loss : 0.068888, loss_ce: 0.020150
2021-12-17 17:13:40,858 iteration 3502 : loss : 0.083452, loss_ce: 0.024826
 52%|█████████████▉             | 206/400 [1:28:59<1:23:33, 25.84s/it]2021-12-17 17:13:42,208 iteration 3503 : loss : 0.058239, loss_ce: 0.019909
2021-12-17 17:13:43,589 iteration 3504 : loss : 0.070968, loss_ce: 0.021335
2021-12-17 17:13:44,956 iteration 3505 : loss : 0.076078, loss_ce: 0.030517
2021-12-17 17:13:46,402 iteration 3506 : loss : 0.067216, loss_ce: 0.020133
2021-12-17 17:13:47,732 iteration 3507 : loss : 0.070177, loss_ce: 0.023678
2021-12-17 17:13:49,038 iteration 3508 : loss : 0.061812, loss_ce: 0.016762
2021-12-17 17:13:50,397 iteration 3509 : loss : 0.068062, loss_ce: 0.020817
2021-12-17 17:13:51,855 iteration 3510 : loss : 0.066126, loss_ce: 0.019225
2021-12-17 17:13:53,206 iteration 3511 : loss : 0.071686, loss_ce: 0.024358
2021-12-17 17:13:54,584 iteration 3512 : loss : 0.083446, loss_ce: 0.026241
2021-12-17 17:13:55,891 iteration 3513 : loss : 0.072154, loss_ce: 0.020279
2021-12-17 17:13:57,187 iteration 3514 : loss : 0.054347, loss_ce: 0.017595
2021-12-17 17:13:58,534 iteration 3515 : loss : 0.058699, loss_ce: 0.015700
2021-12-17 17:13:59,929 iteration 3516 : loss : 0.088531, loss_ce: 0.028377
2021-12-17 17:14:01,287 iteration 3517 : loss : 0.065781, loss_ce: 0.018148
2021-12-17 17:14:02,596 iteration 3518 : loss : 0.060968, loss_ce: 0.019665
2021-12-17 17:14:03,917 iteration 3519 : loss : 0.086469, loss_ce: 0.028376
 52%|█████████████▉             | 207/400 [1:29:23<1:20:26, 25.01s/it]2021-12-17 17:14:05,321 iteration 3520 : loss : 0.064086, loss_ce: 0.019030
2021-12-17 17:14:06,715 iteration 3521 : loss : 0.068539, loss_ce: 0.021764
2021-12-17 17:14:08,107 iteration 3522 : loss : 0.068080, loss_ce: 0.022336
2021-12-17 17:14:09,564 iteration 3523 : loss : 0.087428, loss_ce: 0.028921
2021-12-17 17:14:10,906 iteration 3524 : loss : 0.085469, loss_ce: 0.018775
2021-12-17 17:14:12,294 iteration 3525 : loss : 0.081610, loss_ce: 0.030849
2021-12-17 17:14:13,689 iteration 3526 : loss : 0.076124, loss_ce: 0.031684
2021-12-17 17:14:15,086 iteration 3527 : loss : 0.080631, loss_ce: 0.024989
2021-12-17 17:14:16,410 iteration 3528 : loss : 0.060816, loss_ce: 0.020237
2021-12-17 17:14:17,791 iteration 3529 : loss : 0.075444, loss_ce: 0.021797
2021-12-17 17:14:19,145 iteration 3530 : loss : 0.072547, loss_ce: 0.019761
2021-12-17 17:14:20,527 iteration 3531 : loss : 0.071325, loss_ce: 0.021533
2021-12-17 17:14:21,860 iteration 3532 : loss : 0.063209, loss_ce: 0.018999
2021-12-17 17:14:23,189 iteration 3533 : loss : 0.070030, loss_ce: 0.020396
2021-12-17 17:14:24,533 iteration 3534 : loss : 0.069215, loss_ce: 0.028442
2021-12-17 17:14:25,832 iteration 3535 : loss : 0.066530, loss_ce: 0.022349
2021-12-17 17:14:27,138 iteration 3536 : loss : 0.060606, loss_ce: 0.016639
 52%|██████████████             | 208/400 [1:29:46<1:18:18, 24.47s/it]2021-12-17 17:14:28,525 iteration 3537 : loss : 0.070503, loss_ce: 0.021235
2021-12-17 17:14:29,890 iteration 3538 : loss : 0.072544, loss_ce: 0.018835
2021-12-17 17:14:31,289 iteration 3539 : loss : 0.072576, loss_ce: 0.026848
2021-12-17 17:14:32,596 iteration 3540 : loss : 0.084879, loss_ce: 0.013242
2021-12-17 17:14:34,010 iteration 3541 : loss : 0.075547, loss_ce: 0.025900
2021-12-17 17:14:35,350 iteration 3542 : loss : 0.062345, loss_ce: 0.013116
2021-12-17 17:14:36,740 iteration 3543 : loss : 0.068365, loss_ce: 0.025288
2021-12-17 17:14:38,144 iteration 3544 : loss : 0.072287, loss_ce: 0.022775
2021-12-17 17:14:39,476 iteration 3545 : loss : 0.067757, loss_ce: 0.020111
2021-12-17 17:14:40,772 iteration 3546 : loss : 0.072251, loss_ce: 0.028127
2021-12-17 17:14:42,188 iteration 3547 : loss : 0.069780, loss_ce: 0.021891
2021-12-17 17:14:43,584 iteration 3548 : loss : 0.066153, loss_ce: 0.018428
2021-12-17 17:14:44,947 iteration 3549 : loss : 0.073392, loss_ce: 0.027836
2021-12-17 17:14:46,277 iteration 3550 : loss : 0.063617, loss_ce: 0.018821
2021-12-17 17:14:47,699 iteration 3551 : loss : 0.081058, loss_ce: 0.020251
2021-12-17 17:14:49,129 iteration 3552 : loss : 0.082356, loss_ce: 0.027444
2021-12-17 17:14:50,552 iteration 3553 : loss : 0.070770, loss_ce: 0.021885
 52%|██████████████             | 209/400 [1:30:09<1:16:52, 24.15s/it]2021-12-17 17:14:51,955 iteration 3554 : loss : 0.063307, loss_ce: 0.019610
2021-12-17 17:14:53,355 iteration 3555 : loss : 0.073025, loss_ce: 0.027871
2021-12-17 17:14:54,701 iteration 3556 : loss : 0.071992, loss_ce: 0.021242
2021-12-17 17:14:56,043 iteration 3557 : loss : 0.062381, loss_ce: 0.020760
2021-12-17 17:14:57,349 iteration 3558 : loss : 0.056998, loss_ce: 0.015902
2021-12-17 17:14:58,764 iteration 3559 : loss : 0.079946, loss_ce: 0.024344
2021-12-17 17:15:00,116 iteration 3560 : loss : 0.104010, loss_ce: 0.026549
2021-12-17 17:15:01,501 iteration 3561 : loss : 0.075643, loss_ce: 0.024648
2021-12-17 17:15:02,855 iteration 3562 : loss : 0.066590, loss_ce: 0.018029
2021-12-17 17:15:04,219 iteration 3563 : loss : 0.070487, loss_ce: 0.022339
2021-12-17 17:15:05,602 iteration 3564 : loss : 0.073661, loss_ce: 0.020608
2021-12-17 17:15:06,919 iteration 3565 : loss : 0.067013, loss_ce: 0.023547
2021-12-17 17:15:08,191 iteration 3566 : loss : 0.054721, loss_ce: 0.017240
2021-12-17 17:15:09,486 iteration 3567 : loss : 0.071159, loss_ce: 0.017655
2021-12-17 17:15:10,876 iteration 3568 : loss : 0.075043, loss_ce: 0.021913
2021-12-17 17:15:12,207 iteration 3569 : loss : 0.065842, loss_ce: 0.020429
2021-12-17 17:15:12,207 Training Data Eval:
2021-12-17 17:15:19,314   Average segmentation loss on training set: 0.0503
2021-12-17 17:15:19,314 Validation Data Eval:
2021-12-17 17:15:21,819   Average segmentation loss on validation set: 0.1415
2021-12-17 17:15:23,171 iteration 3570 : loss : 0.066271, loss_ce: 0.016031
 52%|██████████████▏            | 210/400 [1:30:42<1:24:31, 26.69s/it]2021-12-17 17:15:24,626 iteration 3571 : loss : 0.077391, loss_ce: 0.027570
2021-12-17 17:15:26,053 iteration 3572 : loss : 0.066159, loss_ce: 0.021372
2021-12-17 17:15:27,436 iteration 3573 : loss : 0.070325, loss_ce: 0.019990
2021-12-17 17:15:28,760 iteration 3574 : loss : 0.058509, loss_ce: 0.019758
2021-12-17 17:15:30,085 iteration 3575 : loss : 0.065857, loss_ce: 0.021185
2021-12-17 17:15:31,419 iteration 3576 : loss : 0.070535, loss_ce: 0.019463
2021-12-17 17:15:32,808 iteration 3577 : loss : 0.065323, loss_ce: 0.020735
2021-12-17 17:15:34,152 iteration 3578 : loss : 0.067123, loss_ce: 0.019327
2021-12-17 17:15:35,526 iteration 3579 : loss : 0.061018, loss_ce: 0.016552
2021-12-17 17:15:36,933 iteration 3580 : loss : 0.062988, loss_ce: 0.023081
2021-12-17 17:15:38,340 iteration 3581 : loss : 0.076107, loss_ce: 0.024230
2021-12-17 17:15:39,726 iteration 3582 : loss : 0.090023, loss_ce: 0.026824
2021-12-17 17:15:41,083 iteration 3583 : loss : 0.088504, loss_ce: 0.020404
2021-12-17 17:15:42,373 iteration 3584 : loss : 0.065691, loss_ce: 0.020199
2021-12-17 17:15:43,707 iteration 3585 : loss : 0.053569, loss_ce: 0.016093
2021-12-17 17:15:45,020 iteration 3586 : loss : 0.058383, loss_ce: 0.016001
2021-12-17 17:15:46,381 iteration 3587 : loss : 0.064649, loss_ce: 0.022961
 53%|██████████████▏            | 211/400 [1:31:05<1:20:47, 25.65s/it]2021-12-17 17:15:47,870 iteration 3588 : loss : 0.058595, loss_ce: 0.018751
2021-12-17 17:15:49,289 iteration 3589 : loss : 0.076092, loss_ce: 0.018522
2021-12-17 17:15:50,649 iteration 3590 : loss : 0.071827, loss_ce: 0.018355
2021-12-17 17:15:51,968 iteration 3591 : loss : 0.060930, loss_ce: 0.016335
2021-12-17 17:15:53,323 iteration 3592 : loss : 0.058913, loss_ce: 0.020317
2021-12-17 17:15:54,714 iteration 3593 : loss : 0.067871, loss_ce: 0.025842
2021-12-17 17:15:56,086 iteration 3594 : loss : 0.062214, loss_ce: 0.015564
2021-12-17 17:15:57,439 iteration 3595 : loss : 0.082628, loss_ce: 0.025546
2021-12-17 17:15:58,774 iteration 3596 : loss : 0.060586, loss_ce: 0.020837
2021-12-17 17:16:00,143 iteration 3597 : loss : 0.075218, loss_ce: 0.025920
2021-12-17 17:16:01,537 iteration 3598 : loss : 0.085960, loss_ce: 0.030968
2021-12-17 17:16:02,922 iteration 3599 : loss : 0.079961, loss_ce: 0.021992
2021-12-17 17:16:04,237 iteration 3600 : loss : 0.065714, loss_ce: 0.025971
2021-12-17 17:16:05,622 iteration 3601 : loss : 0.066929, loss_ce: 0.020638
2021-12-17 17:16:07,013 iteration 3602 : loss : 0.079630, loss_ce: 0.025632
2021-12-17 17:16:08,352 iteration 3603 : loss : 0.066195, loss_ce: 0.025556
2021-12-17 17:16:09,706 iteration 3604 : loss : 0.069932, loss_ce: 0.014368
 53%|██████████████▎            | 212/400 [1:31:28<1:18:10, 24.95s/it]2021-12-17 17:16:11,214 iteration 3605 : loss : 0.083288, loss_ce: 0.029915
2021-12-17 17:16:12,508 iteration 3606 : loss : 0.074134, loss_ce: 0.018156
2021-12-17 17:16:13,781 iteration 3607 : loss : 0.055291, loss_ce: 0.016670
2021-12-17 17:16:15,191 iteration 3608 : loss : 0.088378, loss_ce: 0.028860
2021-12-17 17:16:16,600 iteration 3609 : loss : 0.085308, loss_ce: 0.028500
2021-12-17 17:16:17,904 iteration 3610 : loss : 0.054235, loss_ce: 0.015195
2021-12-17 17:16:19,268 iteration 3611 : loss : 0.066777, loss_ce: 0.018471
2021-12-17 17:16:20,581 iteration 3612 : loss : 0.062458, loss_ce: 0.021394
2021-12-17 17:16:21,949 iteration 3613 : loss : 0.064342, loss_ce: 0.021058
2021-12-17 17:16:23,289 iteration 3614 : loss : 0.068590, loss_ce: 0.021556
2021-12-17 17:16:24,646 iteration 3615 : loss : 0.074254, loss_ce: 0.019967
2021-12-17 17:16:26,001 iteration 3616 : loss : 0.068101, loss_ce: 0.025158
2021-12-17 17:16:27,383 iteration 3617 : loss : 0.071706, loss_ce: 0.024720
2021-12-17 17:16:28,761 iteration 3618 : loss : 0.070465, loss_ce: 0.021057
2021-12-17 17:16:30,100 iteration 3619 : loss : 0.057838, loss_ce: 0.015383
2021-12-17 17:16:31,473 iteration 3620 : loss : 0.065366, loss_ce: 0.014801
2021-12-17 17:16:32,812 iteration 3621 : loss : 0.081188, loss_ce: 0.032062
 53%|██████████████▍            | 213/400 [1:31:51<1:16:01, 24.39s/it]2021-12-17 17:16:34,226 iteration 3622 : loss : 0.069544, loss_ce: 0.018085
2021-12-17 17:16:35,599 iteration 3623 : loss : 0.064202, loss_ce: 0.016517
2021-12-17 17:16:36,982 iteration 3624 : loss : 0.078625, loss_ce: 0.026875
2021-12-17 17:16:38,276 iteration 3625 : loss : 0.068181, loss_ce: 0.023073
2021-12-17 17:16:39,646 iteration 3626 : loss : 0.075241, loss_ce: 0.021852
2021-12-17 17:16:41,033 iteration 3627 : loss : 0.073101, loss_ce: 0.024890
2021-12-17 17:16:42,421 iteration 3628 : loss : 0.083315, loss_ce: 0.025189
2021-12-17 17:16:43,878 iteration 3629 : loss : 0.068272, loss_ce: 0.023330
2021-12-17 17:16:45,260 iteration 3630 : loss : 0.068929, loss_ce: 0.024111
2021-12-17 17:16:46,627 iteration 3631 : loss : 0.064463, loss_ce: 0.018709
2021-12-17 17:16:48,017 iteration 3632 : loss : 0.076825, loss_ce: 0.030511
2021-12-17 17:16:49,415 iteration 3633 : loss : 0.064723, loss_ce: 0.015205
2021-12-17 17:16:50,745 iteration 3634 : loss : 0.060728, loss_ce: 0.015764
2021-12-17 17:16:52,217 iteration 3635 : loss : 0.067181, loss_ce: 0.025305
2021-12-17 17:16:53,509 iteration 3636 : loss : 0.058724, loss_ce: 0.021233
2021-12-17 17:16:54,876 iteration 3637 : loss : 0.055523, loss_ce: 0.016079
2021-12-17 17:16:56,251 iteration 3638 : loss : 0.062235, loss_ce: 0.017486
 54%|██████████████▍            | 214/400 [1:32:15<1:14:44, 24.11s/it]2021-12-17 17:16:57,679 iteration 3639 : loss : 0.085534, loss_ce: 0.027984
2021-12-17 17:16:59,070 iteration 3640 : loss : 0.069673, loss_ce: 0.015806
2021-12-17 17:17:00,448 iteration 3641 : loss : 0.076235, loss_ce: 0.025454
2021-12-17 17:17:01,778 iteration 3642 : loss : 0.072601, loss_ce: 0.026057
2021-12-17 17:17:03,155 iteration 3643 : loss : 0.068980, loss_ce: 0.017884
2021-12-17 17:17:04,539 iteration 3644 : loss : 0.069588, loss_ce: 0.019045
2021-12-17 17:17:05,974 iteration 3645 : loss : 0.088675, loss_ce: 0.024852
2021-12-17 17:17:07,358 iteration 3646 : loss : 0.073956, loss_ce: 0.028685
2021-12-17 17:17:08,695 iteration 3647 : loss : 0.062875, loss_ce: 0.021817
2021-12-17 17:17:10,076 iteration 3648 : loss : 0.081346, loss_ce: 0.022186
2021-12-17 17:17:11,350 iteration 3649 : loss : 0.057306, loss_ce: 0.016849
2021-12-17 17:17:12,728 iteration 3650 : loss : 0.068066, loss_ce: 0.023641
2021-12-17 17:17:14,063 iteration 3651 : loss : 0.089548, loss_ce: 0.035546
2021-12-17 17:17:15,376 iteration 3652 : loss : 0.062309, loss_ce: 0.020985
2021-12-17 17:17:16,799 iteration 3653 : loss : 0.097382, loss_ce: 0.033023
2021-12-17 17:17:18,140 iteration 3654 : loss : 0.057927, loss_ce: 0.017750
2021-12-17 17:17:18,140 Training Data Eval:
2021-12-17 17:17:25,215   Average segmentation loss on training set: 0.0492
2021-12-17 17:17:25,216 Validation Data Eval:
2021-12-17 17:17:27,722   Average segmentation loss on validation set: 0.1375
2021-12-17 17:17:29,233 iteration 3655 : loss : 0.086284, loss_ce: 0.028292
 54%|██████████████▌            | 215/400 [1:32:48<1:22:32, 26.77s/it]2021-12-17 17:17:30,643 iteration 3656 : loss : 0.058498, loss_ce: 0.014982
2021-12-17 17:17:32,040 iteration 3657 : loss : 0.056191, loss_ce: 0.018432
2021-12-17 17:17:33,401 iteration 3658 : loss : 0.079263, loss_ce: 0.030303
2021-12-17 17:17:34,711 iteration 3659 : loss : 0.072972, loss_ce: 0.021197
2021-12-17 17:17:36,146 iteration 3660 : loss : 0.094076, loss_ce: 0.031979
2021-12-17 17:17:37,496 iteration 3661 : loss : 0.070098, loss_ce: 0.023604
2021-12-17 17:17:38,795 iteration 3662 : loss : 0.064080, loss_ce: 0.022812
2021-12-17 17:17:40,153 iteration 3663 : loss : 0.068478, loss_ce: 0.023608
2021-12-17 17:17:41,548 iteration 3664 : loss : 0.067909, loss_ce: 0.019445
2021-12-17 17:17:43,015 iteration 3665 : loss : 0.063156, loss_ce: 0.016654
2021-12-17 17:17:44,424 iteration 3666 : loss : 0.074102, loss_ce: 0.028786
2021-12-17 17:17:45,764 iteration 3667 : loss : 0.070094, loss_ce: 0.023083
2021-12-17 17:17:47,107 iteration 3668 : loss : 0.069293, loss_ce: 0.016994
2021-12-17 17:17:48,481 iteration 3669 : loss : 0.081582, loss_ce: 0.023849
2021-12-17 17:17:49,781 iteration 3670 : loss : 0.060503, loss_ce: 0.022591
2021-12-17 17:17:51,130 iteration 3671 : loss : 0.066871, loss_ce: 0.015800
2021-12-17 17:17:52,474 iteration 3672 : loss : 0.066777, loss_ce: 0.017500
 54%|██████████████▌            | 216/400 [1:33:11<1:18:51, 25.71s/it]2021-12-17 17:17:53,879 iteration 3673 : loss : 0.069306, loss_ce: 0.023498
2021-12-17 17:17:55,306 iteration 3674 : loss : 0.072011, loss_ce: 0.026507
2021-12-17 17:17:56,727 iteration 3675 : loss : 0.073438, loss_ce: 0.025031
2021-12-17 17:17:58,137 iteration 3676 : loss : 0.074205, loss_ce: 0.018049
2021-12-17 17:17:59,520 iteration 3677 : loss : 0.068780, loss_ce: 0.024376
2021-12-17 17:18:00,950 iteration 3678 : loss : 0.085057, loss_ce: 0.021685
2021-12-17 17:18:02,247 iteration 3679 : loss : 0.057380, loss_ce: 0.016887
2021-12-17 17:18:03,572 iteration 3680 : loss : 0.065955, loss_ce: 0.022327
2021-12-17 17:18:04,931 iteration 3681 : loss : 0.083151, loss_ce: 0.023125
2021-12-17 17:18:06,208 iteration 3682 : loss : 0.053018, loss_ce: 0.014030
2021-12-17 17:18:07,561 iteration 3683 : loss : 0.085230, loss_ce: 0.035526
2021-12-17 17:18:08,861 iteration 3684 : loss : 0.064062, loss_ce: 0.018455
2021-12-17 17:18:10,209 iteration 3685 : loss : 0.063267, loss_ce: 0.017931
2021-12-17 17:18:11,635 iteration 3686 : loss : 0.069417, loss_ce: 0.021767
2021-12-17 17:18:13,069 iteration 3687 : loss : 0.079176, loss_ce: 0.026466
2021-12-17 17:18:14,448 iteration 3688 : loss : 0.075445, loss_ce: 0.023583
2021-12-17 17:18:15,836 iteration 3689 : loss : 0.091806, loss_ce: 0.025002
 54%|██████████████▋            | 217/400 [1:33:34<1:16:16, 25.01s/it]2021-12-17 17:18:17,356 iteration 3690 : loss : 0.073501, loss_ce: 0.027782
2021-12-17 17:18:18,689 iteration 3691 : loss : 0.092205, loss_ce: 0.023854
2021-12-17 17:18:20,083 iteration 3692 : loss : 0.068066, loss_ce: 0.017243
2021-12-17 17:18:21,395 iteration 3693 : loss : 0.060542, loss_ce: 0.014692
2021-12-17 17:18:22,772 iteration 3694 : loss : 0.083708, loss_ce: 0.025541
2021-12-17 17:18:24,148 iteration 3695 : loss : 0.060332, loss_ce: 0.017389
2021-12-17 17:18:25,466 iteration 3696 : loss : 0.056201, loss_ce: 0.018404
2021-12-17 17:18:26,800 iteration 3697 : loss : 0.070743, loss_ce: 0.021119
2021-12-17 17:18:28,247 iteration 3698 : loss : 0.080895, loss_ce: 0.025344
2021-12-17 17:18:29,605 iteration 3699 : loss : 0.062988, loss_ce: 0.024220
2021-12-17 17:18:30,957 iteration 3700 : loss : 0.063513, loss_ce: 0.018020
2021-12-17 17:18:32,261 iteration 3701 : loss : 0.066615, loss_ce: 0.025506
2021-12-17 17:18:33,654 iteration 3702 : loss : 0.073350, loss_ce: 0.022382
2021-12-17 17:18:35,017 iteration 3703 : loss : 0.058870, loss_ce: 0.015738
2021-12-17 17:18:36,374 iteration 3704 : loss : 0.065946, loss_ce: 0.019080
2021-12-17 17:18:37,740 iteration 3705 : loss : 0.071976, loss_ce: 0.026437
2021-12-17 17:18:39,048 iteration 3706 : loss : 0.065665, loss_ce: 0.018226
 55%|██████████████▋            | 218/400 [1:33:58<1:14:13, 24.47s/it]2021-12-17 17:18:40,487 iteration 3707 : loss : 0.127133, loss_ce: 0.022083
2021-12-17 17:18:41,949 iteration 3708 : loss : 0.095967, loss_ce: 0.024532
2021-12-17 17:18:43,297 iteration 3709 : loss : 0.074491, loss_ce: 0.019432
2021-12-17 17:18:44,572 iteration 3710 : loss : 0.059730, loss_ce: 0.019618
2021-12-17 17:18:46,029 iteration 3711 : loss : 0.082342, loss_ce: 0.029807
2021-12-17 17:18:47,347 iteration 3712 : loss : 0.070211, loss_ce: 0.021566
2021-12-17 17:18:48,664 iteration 3713 : loss : 0.057746, loss_ce: 0.017229
2021-12-17 17:18:50,069 iteration 3714 : loss : 0.079948, loss_ce: 0.031024
2021-12-17 17:18:51,412 iteration 3715 : loss : 0.063650, loss_ce: 0.018716
2021-12-17 17:18:52,776 iteration 3716 : loss : 0.077163, loss_ce: 0.029695
2021-12-17 17:18:54,154 iteration 3717 : loss : 0.064348, loss_ce: 0.023512
2021-12-17 17:18:55,556 iteration 3718 : loss : 0.069627, loss_ce: 0.021167
2021-12-17 17:18:57,010 iteration 3719 : loss : 0.065732, loss_ce: 0.019162
2021-12-17 17:18:58,449 iteration 3720 : loss : 0.083883, loss_ce: 0.028336
2021-12-17 17:18:59,819 iteration 3721 : loss : 0.069626, loss_ce: 0.024936
2021-12-17 17:19:01,249 iteration 3722 : loss : 0.069613, loss_ce: 0.017925
2021-12-17 17:19:02,586 iteration 3723 : loss : 0.066593, loss_ce: 0.020911
 55%|██████████████▊            | 219/400 [1:34:21<1:12:57, 24.19s/it]2021-12-17 17:19:03,997 iteration 3724 : loss : 0.065538, loss_ce: 0.025316
2021-12-17 17:19:05,396 iteration 3725 : loss : 0.087428, loss_ce: 0.032354
2021-12-17 17:19:06,750 iteration 3726 : loss : 0.071622, loss_ce: 0.026338
2021-12-17 17:19:08,127 iteration 3727 : loss : 0.068329, loss_ce: 0.019398
2021-12-17 17:19:09,417 iteration 3728 : loss : 0.072626, loss_ce: 0.028174
2021-12-17 17:19:10,811 iteration 3729 : loss : 0.072100, loss_ce: 0.017110
2021-12-17 17:19:12,130 iteration 3730 : loss : 0.056996, loss_ce: 0.016351
2021-12-17 17:19:13,543 iteration 3731 : loss : 0.065112, loss_ce: 0.022457
2021-12-17 17:19:14,902 iteration 3732 : loss : 0.071164, loss_ce: 0.025981
2021-12-17 17:19:16,209 iteration 3733 : loss : 0.052241, loss_ce: 0.012735
2021-12-17 17:19:17,613 iteration 3734 : loss : 0.074720, loss_ce: 0.022244
2021-12-17 17:19:19,039 iteration 3735 : loss : 0.067924, loss_ce: 0.019631
2021-12-17 17:19:20,427 iteration 3736 : loss : 0.068701, loss_ce: 0.021602
2021-12-17 17:19:21,847 iteration 3737 : loss : 0.082897, loss_ce: 0.033979
2021-12-17 17:19:23,201 iteration 3738 : loss : 0.074770, loss_ce: 0.020558
2021-12-17 17:19:24,559 iteration 3739 : loss : 0.092851, loss_ce: 0.023980
2021-12-17 17:19:24,559 Training Data Eval:
2021-12-17 17:19:31,610   Average segmentation loss on training set: 0.0507
2021-12-17 17:19:31,610 Validation Data Eval:
2021-12-17 17:19:34,107   Average segmentation loss on validation set: 0.1429
2021-12-17 17:19:35,452 iteration 3740 : loss : 0.062492, loss_ce: 0.017490
 55%|██████████████▊            | 220/400 [1:34:54<1:20:22, 26.79s/it]2021-12-17 17:19:36,878 iteration 3741 : loss : 0.085386, loss_ce: 0.030730
2021-12-17 17:19:38,219 iteration 3742 : loss : 0.065821, loss_ce: 0.019063
2021-12-17 17:19:39,554 iteration 3743 : loss : 0.061095, loss_ce: 0.015718
2021-12-17 17:19:40,940 iteration 3744 : loss : 0.055537, loss_ce: 0.015057
2021-12-17 17:19:42,380 iteration 3745 : loss : 0.091628, loss_ce: 0.044551
2021-12-17 17:19:43,715 iteration 3746 : loss : 0.054997, loss_ce: 0.010718
2021-12-17 17:19:45,105 iteration 3747 : loss : 0.085501, loss_ce: 0.028014
2021-12-17 17:19:46,518 iteration 3748 : loss : 0.085092, loss_ce: 0.026138
2021-12-17 17:19:47,899 iteration 3749 : loss : 0.071983, loss_ce: 0.019755
2021-12-17 17:19:49,359 iteration 3750 : loss : 0.091156, loss_ce: 0.032198
2021-12-17 17:19:50,703 iteration 3751 : loss : 0.070163, loss_ce: 0.024120
2021-12-17 17:19:52,042 iteration 3752 : loss : 0.063949, loss_ce: 0.020448
2021-12-17 17:19:53,391 iteration 3753 : loss : 0.066653, loss_ce: 0.018159
2021-12-17 17:19:54,688 iteration 3754 : loss : 0.059782, loss_ce: 0.023404
2021-12-17 17:19:56,059 iteration 3755 : loss : 0.074905, loss_ce: 0.024164
2021-12-17 17:19:57,392 iteration 3756 : loss : 0.062179, loss_ce: 0.018677
2021-12-17 17:19:58,760 iteration 3757 : loss : 0.078241, loss_ce: 0.025803
 55%|██████████████▉            | 221/400 [1:35:17<1:16:49, 25.75s/it]2021-12-17 17:20:00,212 iteration 3758 : loss : 0.064632, loss_ce: 0.018505
2021-12-17 17:20:01,612 iteration 3759 : loss : 0.073398, loss_ce: 0.023071
2021-12-17 17:20:03,005 iteration 3760 : loss : 0.075743, loss_ce: 0.024646
2021-12-17 17:20:04,375 iteration 3761 : loss : 0.061823, loss_ce: 0.024276
2021-12-17 17:20:05,778 iteration 3762 : loss : 0.070569, loss_ce: 0.024163
2021-12-17 17:20:07,190 iteration 3763 : loss : 0.071035, loss_ce: 0.025732
2021-12-17 17:20:08,513 iteration 3764 : loss : 0.066563, loss_ce: 0.013411
2021-12-17 17:20:09,804 iteration 3765 : loss : 0.067191, loss_ce: 0.021242
2021-12-17 17:20:11,125 iteration 3766 : loss : 0.061701, loss_ce: 0.017596
2021-12-17 17:20:12,498 iteration 3767 : loss : 0.075279, loss_ce: 0.022487
2021-12-17 17:20:13,927 iteration 3768 : loss : 0.067211, loss_ce: 0.022481
2021-12-17 17:20:15,298 iteration 3769 : loss : 0.062871, loss_ce: 0.018627
2021-12-17 17:20:16,707 iteration 3770 : loss : 0.063079, loss_ce: 0.019795
2021-12-17 17:20:18,092 iteration 3771 : loss : 0.068546, loss_ce: 0.023642
2021-12-17 17:20:19,496 iteration 3772 : loss : 0.076456, loss_ce: 0.017524
2021-12-17 17:20:20,880 iteration 3773 : loss : 0.066454, loss_ce: 0.018684
2021-12-17 17:20:22,265 iteration 3774 : loss : 0.069809, loss_ce: 0.028003
 56%|██████████████▉            | 222/400 [1:35:41<1:14:23, 25.08s/it]2021-12-17 17:20:23,733 iteration 3775 : loss : 0.066713, loss_ce: 0.020949
2021-12-17 17:20:25,093 iteration 3776 : loss : 0.055911, loss_ce: 0.017939
2021-12-17 17:20:26,452 iteration 3777 : loss : 0.078079, loss_ce: 0.020038
2021-12-17 17:20:27,860 iteration 3778 : loss : 0.075839, loss_ce: 0.023271
2021-12-17 17:20:29,170 iteration 3779 : loss : 0.070171, loss_ce: 0.023805
2021-12-17 17:20:30,582 iteration 3780 : loss : 0.084495, loss_ce: 0.035290
2021-12-17 17:20:31,980 iteration 3781 : loss : 0.079410, loss_ce: 0.031131
2021-12-17 17:20:33,404 iteration 3782 : loss : 0.085438, loss_ce: 0.025977
2021-12-17 17:20:34,811 iteration 3783 : loss : 0.065727, loss_ce: 0.026818
2021-12-17 17:20:36,121 iteration 3784 : loss : 0.061252, loss_ce: 0.013526
2021-12-17 17:20:37,490 iteration 3785 : loss : 0.083576, loss_ce: 0.020982
2021-12-17 17:20:38,855 iteration 3786 : loss : 0.073572, loss_ce: 0.025500
2021-12-17 17:20:40,179 iteration 3787 : loss : 0.069027, loss_ce: 0.023111
2021-12-17 17:20:41,565 iteration 3788 : loss : 0.072091, loss_ce: 0.021211
2021-12-17 17:20:42,922 iteration 3789 : loss : 0.079931, loss_ce: 0.029734
2021-12-17 17:20:44,253 iteration 3790 : loss : 0.060346, loss_ce: 0.019352
2021-12-17 17:20:45,664 iteration 3791 : loss : 0.062850, loss_ce: 0.017718
 56%|███████████████            | 223/400 [1:36:04<1:12:29, 24.57s/it]2021-12-17 17:20:47,038 iteration 3792 : loss : 0.067787, loss_ce: 0.020653
2021-12-17 17:20:48,329 iteration 3793 : loss : 0.051236, loss_ce: 0.011547
2021-12-17 17:20:49,669 iteration 3794 : loss : 0.061032, loss_ce: 0.020425
2021-12-17 17:20:51,012 iteration 3795 : loss : 0.059545, loss_ce: 0.014855
2021-12-17 17:20:52,432 iteration 3796 : loss : 0.077001, loss_ce: 0.020446
2021-12-17 17:20:53,822 iteration 3797 : loss : 0.056695, loss_ce: 0.015598
2021-12-17 17:20:55,137 iteration 3798 : loss : 0.058281, loss_ce: 0.018222
2021-12-17 17:20:56,577 iteration 3799 : loss : 0.071722, loss_ce: 0.022141
2021-12-17 17:20:58,070 iteration 3800 : loss : 0.113584, loss_ce: 0.047225
2021-12-17 17:20:59,510 iteration 3801 : loss : 0.079448, loss_ce: 0.018803
2021-12-17 17:21:00,922 iteration 3802 : loss : 0.072530, loss_ce: 0.022642
2021-12-17 17:21:02,271 iteration 3803 : loss : 0.085025, loss_ce: 0.024980
2021-12-17 17:21:03,630 iteration 3804 : loss : 0.061361, loss_ce: 0.017050
2021-12-17 17:21:04,986 iteration 3805 : loss : 0.074834, loss_ce: 0.022420
2021-12-17 17:21:06,269 iteration 3806 : loss : 0.058401, loss_ce: 0.022237
2021-12-17 17:21:07,643 iteration 3807 : loss : 0.058257, loss_ce: 0.016246
2021-12-17 17:21:08,986 iteration 3808 : loss : 0.087712, loss_ce: 0.032679
 56%|███████████████            | 224/400 [1:36:28<1:10:58, 24.20s/it]2021-12-17 17:21:10,427 iteration 3809 : loss : 0.063992, loss_ce: 0.020261
2021-12-17 17:21:11,825 iteration 3810 : loss : 0.076049, loss_ce: 0.021047
2021-12-17 17:21:13,162 iteration 3811 : loss : 0.062982, loss_ce: 0.018881
2021-12-17 17:21:14,542 iteration 3812 : loss : 0.077830, loss_ce: 0.019743
2021-12-17 17:21:15,822 iteration 3813 : loss : 0.059292, loss_ce: 0.021530
2021-12-17 17:21:17,234 iteration 3814 : loss : 0.085402, loss_ce: 0.039295
2021-12-17 17:21:18,686 iteration 3815 : loss : 0.070553, loss_ce: 0.025697
2021-12-17 17:21:20,021 iteration 3816 : loss : 0.055098, loss_ce: 0.015400
2021-12-17 17:21:21,292 iteration 3817 : loss : 0.057747, loss_ce: 0.017599
2021-12-17 17:21:22,621 iteration 3818 : loss : 0.062888, loss_ce: 0.017019
2021-12-17 17:21:24,017 iteration 3819 : loss : 0.092507, loss_ce: 0.034240
2021-12-17 17:21:25,320 iteration 3820 : loss : 0.055548, loss_ce: 0.018209
2021-12-17 17:21:26,744 iteration 3821 : loss : 0.075592, loss_ce: 0.028753
2021-12-17 17:21:28,098 iteration 3822 : loss : 0.080628, loss_ce: 0.024205
2021-12-17 17:21:29,424 iteration 3823 : loss : 0.069382, loss_ce: 0.020211
2021-12-17 17:21:30,809 iteration 3824 : loss : 0.074126, loss_ce: 0.023641
2021-12-17 17:21:30,810 Training Data Eval:
2021-12-17 17:21:37,898   Average segmentation loss on training set: 0.0506
2021-12-17 17:21:37,898 Validation Data Eval:
2021-12-17 17:21:40,343   Average segmentation loss on validation set: 0.1340
2021-12-17 17:21:46,858 Found new lowest validation loss at iteration 3824! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/TU_3seeds/TU_RESNET_no_pretraining_SGD_best_val_loss_seed100.pth
2021-12-17 17:21:48,144 iteration 3825 : loss : 0.062519, loss_ce: 0.016753
 56%|███████████████▏           | 225/400 [1:37:07<1:23:40, 28.69s/it]2021-12-17 17:21:49,581 iteration 3826 : loss : 0.075205, loss_ce: 0.028999
2021-12-17 17:21:50,960 iteration 3827 : loss : 0.082743, loss_ce: 0.027097
2021-12-17 17:21:52,230 iteration 3828 : loss : 0.056528, loss_ce: 0.021776
2021-12-17 17:21:53,506 iteration 3829 : loss : 0.055965, loss_ce: 0.016295
2021-12-17 17:21:54,898 iteration 3830 : loss : 0.065099, loss_ce: 0.016490
2021-12-17 17:21:56,266 iteration 3831 : loss : 0.084446, loss_ce: 0.028168
2021-12-17 17:21:57,608 iteration 3832 : loss : 0.066205, loss_ce: 0.026447
2021-12-17 17:21:58,945 iteration 3833 : loss : 0.087197, loss_ce: 0.021637
2021-12-17 17:22:00,216 iteration 3834 : loss : 0.063011, loss_ce: 0.016403
2021-12-17 17:22:01,558 iteration 3835 : loss : 0.073752, loss_ce: 0.015039
2021-12-17 17:22:02,815 iteration 3836 : loss : 0.060183, loss_ce: 0.019295
2021-12-17 17:22:04,047 iteration 3837 : loss : 0.054307, loss_ce: 0.018777
2021-12-17 17:22:05,401 iteration 3838 : loss : 0.069471, loss_ce: 0.026035
2021-12-17 17:22:06,672 iteration 3839 : loss : 0.073344, loss_ce: 0.018018
2021-12-17 17:22:07,998 iteration 3840 : loss : 0.062608, loss_ce: 0.018723
2021-12-17 17:22:09,238 iteration 3841 : loss : 0.066178, loss_ce: 0.021478
2021-12-17 17:22:10,586 iteration 3842 : loss : 0.085653, loss_ce: 0.018602
 56%|███████████████▎           | 226/400 [1:37:29<1:17:45, 26.81s/it]2021-12-17 17:22:11,958 iteration 3843 : loss : 0.073620, loss_ce: 0.022330
2021-12-17 17:22:13,360 iteration 3844 : loss : 0.072685, loss_ce: 0.022375
2021-12-17 17:22:14,653 iteration 3845 : loss : 0.060178, loss_ce: 0.018537
2021-12-17 17:22:16,036 iteration 3846 : loss : 0.072016, loss_ce: 0.031107
2021-12-17 17:22:17,529 iteration 3847 : loss : 0.085205, loss_ce: 0.028285
2021-12-17 17:22:18,889 iteration 3848 : loss : 0.066122, loss_ce: 0.020334
2021-12-17 17:22:20,247 iteration 3849 : loss : 0.063325, loss_ce: 0.020732
2021-12-17 17:22:21,695 iteration 3850 : loss : 0.070174, loss_ce: 0.018142
2021-12-17 17:22:23,156 iteration 3851 : loss : 0.117635, loss_ce: 0.028991
2021-12-17 17:22:24,583 iteration 3852 : loss : 0.065726, loss_ce: 0.021119
2021-12-17 17:22:25,952 iteration 3853 : loss : 0.062119, loss_ce: 0.019033
2021-12-17 17:22:27,240 iteration 3854 : loss : 0.055052, loss_ce: 0.016583
2021-12-17 17:22:28,576 iteration 3855 : loss : 0.059285, loss_ce: 0.014543
2021-12-17 17:22:30,036 iteration 3856 : loss : 0.069826, loss_ce: 0.025854
2021-12-17 17:22:31,382 iteration 3857 : loss : 0.076586, loss_ce: 0.021092
2021-12-17 17:22:32,729 iteration 3858 : loss : 0.085709, loss_ce: 0.032440
2021-12-17 17:22:34,064 iteration 3859 : loss : 0.066427, loss_ce: 0.022961
 57%|███████████████▎           | 227/400 [1:37:53<1:14:25, 25.81s/it]2021-12-17 17:22:35,472 iteration 3860 : loss : 0.058898, loss_ce: 0.020488
2021-12-17 17:22:36,824 iteration 3861 : loss : 0.061965, loss_ce: 0.022857
2021-12-17 17:22:38,158 iteration 3862 : loss : 0.069930, loss_ce: 0.019158
2021-12-17 17:22:39,549 iteration 3863 : loss : 0.062890, loss_ce: 0.021338
2021-12-17 17:22:40,838 iteration 3864 : loss : 0.055764, loss_ce: 0.015890
2021-12-17 17:22:42,233 iteration 3865 : loss : 0.065974, loss_ce: 0.023536
2021-12-17 17:22:43,583 iteration 3866 : loss : 0.059360, loss_ce: 0.019344
2021-12-17 17:22:44,981 iteration 3867 : loss : 0.100337, loss_ce: 0.035718
2021-12-17 17:22:46,283 iteration 3868 : loss : 0.060383, loss_ce: 0.021403
2021-12-17 17:22:47,716 iteration 3869 : loss : 0.068529, loss_ce: 0.016518
2021-12-17 17:22:49,054 iteration 3870 : loss : 0.062843, loss_ce: 0.019101
2021-12-17 17:22:50,457 iteration 3871 : loss : 0.063533, loss_ce: 0.020019
2021-12-17 17:22:51,824 iteration 3872 : loss : 0.060229, loss_ce: 0.017402
2021-12-17 17:22:53,179 iteration 3873 : loss : 0.082986, loss_ce: 0.023148
2021-12-17 17:22:54,602 iteration 3874 : loss : 0.063866, loss_ce: 0.018661
2021-12-17 17:22:55,991 iteration 3875 : loss : 0.072448, loss_ce: 0.016093
2021-12-17 17:22:57,442 iteration 3876 : loss : 0.068822, loss_ce: 0.024866
 57%|███████████████▍           | 228/400 [1:38:16<1:11:54, 25.08s/it]2021-12-17 17:22:58,840 iteration 3877 : loss : 0.058062, loss_ce: 0.019659
2021-12-17 17:23:00,247 iteration 3878 : loss : 0.062859, loss_ce: 0.018431
2021-12-17 17:23:01,674 iteration 3879 : loss : 0.074264, loss_ce: 0.034653
2021-12-17 17:23:03,041 iteration 3880 : loss : 0.067345, loss_ce: 0.020042
2021-12-17 17:23:04,426 iteration 3881 : loss : 0.071202, loss_ce: 0.017817
2021-12-17 17:23:05,835 iteration 3882 : loss : 0.075261, loss_ce: 0.028648
2021-12-17 17:23:07,216 iteration 3883 : loss : 0.056905, loss_ce: 0.015874
2021-12-17 17:23:08,597 iteration 3884 : loss : 0.063567, loss_ce: 0.019389
2021-12-17 17:23:09,920 iteration 3885 : loss : 0.058971, loss_ce: 0.014753
2021-12-17 17:23:11,321 iteration 3886 : loss : 0.070311, loss_ce: 0.022945
2021-12-17 17:23:12,713 iteration 3887 : loss : 0.071297, loss_ce: 0.022096
2021-12-17 17:23:14,150 iteration 3888 : loss : 0.080675, loss_ce: 0.034218
2021-12-17 17:23:15,486 iteration 3889 : loss : 0.063222, loss_ce: 0.016436
2021-12-17 17:23:16,837 iteration 3890 : loss : 0.054845, loss_ce: 0.014402
2021-12-17 17:23:18,245 iteration 3891 : loss : 0.068165, loss_ce: 0.023308
2021-12-17 17:23:19,614 iteration 3892 : loss : 0.067113, loss_ce: 0.018281
2021-12-17 17:23:20,953 iteration 3893 : loss : 0.070430, loss_ce: 0.017267
 57%|███████████████▍           | 229/400 [1:38:40<1:10:08, 24.61s/it]2021-12-17 17:23:22,380 iteration 3894 : loss : 0.071825, loss_ce: 0.022430
2021-12-17 17:23:23,789 iteration 3895 : loss : 0.073454, loss_ce: 0.027100
2021-12-17 17:23:25,096 iteration 3896 : loss : 0.059802, loss_ce: 0.017427
2021-12-17 17:23:26,510 iteration 3897 : loss : 0.056763, loss_ce: 0.015116
2021-12-17 17:23:27,909 iteration 3898 : loss : 0.072332, loss_ce: 0.018058
2021-12-17 17:23:29,286 iteration 3899 : loss : 0.080678, loss_ce: 0.020838
2021-12-17 17:23:30,670 iteration 3900 : loss : 0.060265, loss_ce: 0.023273
2021-12-17 17:23:31,961 iteration 3901 : loss : 0.055361, loss_ce: 0.020197
2021-12-17 17:23:33,337 iteration 3902 : loss : 0.055594, loss_ce: 0.016077
2021-12-17 17:23:34,666 iteration 3903 : loss : 0.056039, loss_ce: 0.016069
2021-12-17 17:23:36,045 iteration 3904 : loss : 0.058890, loss_ce: 0.018300
2021-12-17 17:23:37,414 iteration 3905 : loss : 0.070814, loss_ce: 0.031582
2021-12-17 17:23:38,780 iteration 3906 : loss : 0.067595, loss_ce: 0.022818
2021-12-17 17:23:40,146 iteration 3907 : loss : 0.081539, loss_ce: 0.021807
2021-12-17 17:23:41,451 iteration 3908 : loss : 0.078710, loss_ce: 0.022309
2021-12-17 17:23:42,775 iteration 3909 : loss : 0.058410, loss_ce: 0.017606
2021-12-17 17:23:42,775 Training Data Eval:
2021-12-17 17:23:49,969   Average segmentation loss on training set: 0.0478
2021-12-17 17:23:49,969 Validation Data Eval:
2021-12-17 17:23:52,455   Average segmentation loss on validation set: 0.1459
2021-12-17 17:23:53,836 iteration 3910 : loss : 0.061977, loss_ce: 0.021589
 57%|███████████████▌           | 230/400 [1:39:12<1:16:45, 27.09s/it]2021-12-17 17:23:55,192 iteration 3911 : loss : 0.055880, loss_ce: 0.019264
2021-12-17 17:23:56,542 iteration 3912 : loss : 0.081926, loss_ce: 0.025138
2021-12-17 17:23:57,938 iteration 3913 : loss : 0.066635, loss_ce: 0.026028
2021-12-17 17:23:59,231 iteration 3914 : loss : 0.055965, loss_ce: 0.019279
2021-12-17 17:24:00,627 iteration 3915 : loss : 0.087378, loss_ce: 0.025264
2021-12-17 17:24:02,001 iteration 3916 : loss : 0.062401, loss_ce: 0.019173
2021-12-17 17:24:03,396 iteration 3917 : loss : 0.059567, loss_ce: 0.015523
2021-12-17 17:24:04,762 iteration 3918 : loss : 0.063804, loss_ce: 0.017306
2021-12-17 17:24:06,119 iteration 3919 : loss : 0.061624, loss_ce: 0.016990
2021-12-17 17:24:07,509 iteration 3920 : loss : 0.085171, loss_ce: 0.015684
2021-12-17 17:24:08,881 iteration 3921 : loss : 0.070204, loss_ce: 0.019357
2021-12-17 17:24:10,283 iteration 3922 : loss : 0.077291, loss_ce: 0.018212
2021-12-17 17:24:11,726 iteration 3923 : loss : 0.079566, loss_ce: 0.031729
2021-12-17 17:24:13,048 iteration 3924 : loss : 0.070059, loss_ce: 0.020836
2021-12-17 17:24:14,335 iteration 3925 : loss : 0.057452, loss_ce: 0.020380
2021-12-17 17:24:15,821 iteration 3926 : loss : 0.077590, loss_ce: 0.027606
2021-12-17 17:24:17,207 iteration 3927 : loss : 0.068273, loss_ce: 0.027261
 58%|███████████████▌           | 231/400 [1:39:36<1:13:09, 25.97s/it]2021-12-17 17:24:18,608 iteration 3928 : loss : 0.060237, loss_ce: 0.019567
2021-12-17 17:24:19,932 iteration 3929 : loss : 0.070771, loss_ce: 0.034487
2021-12-17 17:24:21,295 iteration 3930 : loss : 0.061613, loss_ce: 0.015886
2021-12-17 17:24:22,602 iteration 3931 : loss : 0.061606, loss_ce: 0.014050
2021-12-17 17:24:23,985 iteration 3932 : loss : 0.076087, loss_ce: 0.020551
2021-12-17 17:24:25,332 iteration 3933 : loss : 0.065236, loss_ce: 0.023976
2021-12-17 17:24:26,715 iteration 3934 : loss : 0.073319, loss_ce: 0.021468
2021-12-17 17:24:28,075 iteration 3935 : loss : 0.068614, loss_ce: 0.021577
2021-12-17 17:24:29,403 iteration 3936 : loss : 0.056712, loss_ce: 0.014706
2021-12-17 17:24:30,775 iteration 3937 : loss : 0.065804, loss_ce: 0.017205
2021-12-17 17:24:32,131 iteration 3938 : loss : 0.064767, loss_ce: 0.016363
2021-12-17 17:24:33,537 iteration 3939 : loss : 0.075485, loss_ce: 0.015962
2021-12-17 17:24:34,893 iteration 3940 : loss : 0.065467, loss_ce: 0.023167
2021-12-17 17:24:36,261 iteration 3941 : loss : 0.060414, loss_ce: 0.017104
2021-12-17 17:24:37,587 iteration 3942 : loss : 0.057216, loss_ce: 0.023473
2021-12-17 17:24:38,924 iteration 3943 : loss : 0.061058, loss_ce: 0.019635
2021-12-17 17:24:40,271 iteration 3944 : loss : 0.072232, loss_ce: 0.019232
 58%|███████████████▋           | 232/400 [1:39:59<1:10:17, 25.10s/it]2021-12-17 17:24:41,742 iteration 3945 : loss : 0.064154, loss_ce: 0.017809
2021-12-17 17:24:43,089 iteration 3946 : loss : 0.057767, loss_ce: 0.020027
2021-12-17 17:24:44,426 iteration 3947 : loss : 0.064435, loss_ce: 0.022670
2021-12-17 17:24:45,836 iteration 3948 : loss : 0.068347, loss_ce: 0.024737
2021-12-17 17:24:47,262 iteration 3949 : loss : 0.076724, loss_ce: 0.019845
2021-12-17 17:24:48,607 iteration 3950 : loss : 0.059029, loss_ce: 0.023225
2021-12-17 17:24:49,920 iteration 3951 : loss : 0.057317, loss_ce: 0.011414
2021-12-17 17:24:51,365 iteration 3952 : loss : 0.067953, loss_ce: 0.026501
2021-12-17 17:24:52,718 iteration 3953 : loss : 0.058078, loss_ce: 0.019499
2021-12-17 17:24:54,031 iteration 3954 : loss : 0.056451, loss_ce: 0.017405
2021-12-17 17:24:55,416 iteration 3955 : loss : 0.069087, loss_ce: 0.025006
2021-12-17 17:24:56,819 iteration 3956 : loss : 0.064032, loss_ce: 0.025449
2021-12-17 17:24:58,234 iteration 3957 : loss : 0.097957, loss_ce: 0.024810
2021-12-17 17:24:59,653 iteration 3958 : loss : 0.061143, loss_ce: 0.022445
2021-12-17 17:25:00,929 iteration 3959 : loss : 0.056828, loss_ce: 0.014220
2021-12-17 17:25:02,325 iteration 3960 : loss : 0.066906, loss_ce: 0.021843
2021-12-17 17:25:03,673 iteration 3961 : loss : 0.059990, loss_ce: 0.013030
 58%|███████████████▋           | 233/400 [1:40:22<1:08:26, 24.59s/it]2021-12-17 17:25:05,110 iteration 3962 : loss : 0.068372, loss_ce: 0.022827
2021-12-17 17:25:06,522 iteration 3963 : loss : 0.080550, loss_ce: 0.027180
2021-12-17 17:25:07,838 iteration 3964 : loss : 0.062422, loss_ce: 0.016777
2021-12-17 17:25:09,214 iteration 3965 : loss : 0.058143, loss_ce: 0.020724
2021-12-17 17:25:10,656 iteration 3966 : loss : 0.066269, loss_ce: 0.026902
2021-12-17 17:25:12,010 iteration 3967 : loss : 0.073087, loss_ce: 0.014536
2021-12-17 17:25:13,371 iteration 3968 : loss : 0.060075, loss_ce: 0.017694
2021-12-17 17:25:14,709 iteration 3969 : loss : 0.061741, loss_ce: 0.018142
2021-12-17 17:25:16,080 iteration 3970 : loss : 0.060520, loss_ce: 0.013188
2021-12-17 17:25:17,445 iteration 3971 : loss : 0.058198, loss_ce: 0.014661
2021-12-17 17:25:18,825 iteration 3972 : loss : 0.086184, loss_ce: 0.030471
2021-12-17 17:25:20,254 iteration 3973 : loss : 0.072721, loss_ce: 0.026414
2021-12-17 17:25:21,661 iteration 3974 : loss : 0.076404, loss_ce: 0.031030
2021-12-17 17:25:23,015 iteration 3975 : loss : 0.068399, loss_ce: 0.016386
2021-12-17 17:25:24,365 iteration 3976 : loss : 0.063678, loss_ce: 0.020014
2021-12-17 17:25:25,755 iteration 3977 : loss : 0.064686, loss_ce: 0.023706
2021-12-17 17:25:27,118 iteration 3978 : loss : 0.076052, loss_ce: 0.028208
 58%|███████████████▊           | 234/400 [1:40:46<1:07:04, 24.25s/it]2021-12-17 17:25:28,595 iteration 3979 : loss : 0.071780, loss_ce: 0.028299
2021-12-17 17:25:29,885 iteration 3980 : loss : 0.068514, loss_ce: 0.023334
2021-12-17 17:25:31,244 iteration 3981 : loss : 0.073445, loss_ce: 0.017329
2021-12-17 17:25:32,625 iteration 3982 : loss : 0.064415, loss_ce: 0.023354
2021-12-17 17:25:34,003 iteration 3983 : loss : 0.097718, loss_ce: 0.021948
2021-12-17 17:25:35,397 iteration 3984 : loss : 0.082057, loss_ce: 0.031877
2021-12-17 17:25:36,789 iteration 3985 : loss : 0.061398, loss_ce: 0.017709
2021-12-17 17:25:38,196 iteration 3986 : loss : 0.081695, loss_ce: 0.022227
2021-12-17 17:25:39,514 iteration 3987 : loss : 0.073688, loss_ce: 0.027680
2021-12-17 17:25:40,866 iteration 3988 : loss : 0.068179, loss_ce: 0.020074
2021-12-17 17:25:42,247 iteration 3989 : loss : 0.075243, loss_ce: 0.022876
2021-12-17 17:25:43,630 iteration 3990 : loss : 0.064366, loss_ce: 0.022064
2021-12-17 17:25:45,024 iteration 3991 : loss : 0.064627, loss_ce: 0.023399
2021-12-17 17:25:46,422 iteration 3992 : loss : 0.072571, loss_ce: 0.021965
2021-12-17 17:25:47,791 iteration 3993 : loss : 0.061007, loss_ce: 0.019466
2021-12-17 17:25:49,207 iteration 3994 : loss : 0.068619, loss_ce: 0.017306
2021-12-17 17:25:49,207 Training Data Eval:
2021-12-17 17:25:56,329   Average segmentation loss on training set: 0.0465
2021-12-17 17:25:56,329 Validation Data Eval:
2021-12-17 17:25:58,803   Average segmentation loss on validation set: 0.1392
2021-12-17 17:26:00,273 iteration 3995 : loss : 0.070133, loss_ce: 0.022061
 59%|███████████████▊           | 235/400 [1:41:19<1:14:01, 26.92s/it]2021-12-17 17:26:01,684 iteration 3996 : loss : 0.065319, loss_ce: 0.025632
2021-12-17 17:26:03,000 iteration 3997 : loss : 0.066951, loss_ce: 0.025114
2021-12-17 17:26:04,310 iteration 3998 : loss : 0.062987, loss_ce: 0.015448
2021-12-17 17:26:05,734 iteration 3999 : loss : 0.084709, loss_ce: 0.022301
2021-12-17 17:26:07,101 iteration 4000 : loss : 0.060327, loss_ce: 0.020511
2021-12-17 17:26:08,499 iteration 4001 : loss : 0.062567, loss_ce: 0.022411
2021-12-17 17:26:09,793 iteration 4002 : loss : 0.074268, loss_ce: 0.021222
2021-12-17 17:26:11,211 iteration 4003 : loss : 0.068095, loss_ce: 0.019826
2021-12-17 17:26:12,617 iteration 4004 : loss : 0.090816, loss_ce: 0.029615
2021-12-17 17:26:14,000 iteration 4005 : loss : 0.060986, loss_ce: 0.021546
2021-12-17 17:26:15,311 iteration 4006 : loss : 0.062885, loss_ce: 0.016041
2021-12-17 17:26:16,668 iteration 4007 : loss : 0.062909, loss_ce: 0.017574
2021-12-17 17:26:18,020 iteration 4008 : loss : 0.055069, loss_ce: 0.020182
2021-12-17 17:26:19,379 iteration 4009 : loss : 0.076389, loss_ce: 0.022184
2021-12-17 17:26:20,758 iteration 4010 : loss : 0.063363, loss_ce: 0.019985
2021-12-17 17:26:22,104 iteration 4011 : loss : 0.064813, loss_ce: 0.020136
2021-12-17 17:26:23,476 iteration 4012 : loss : 0.072462, loss_ce: 0.023632
 59%|███████████████▉           | 236/400 [1:41:42<1:10:32, 25.81s/it]2021-12-17 17:26:24,803 iteration 4013 : loss : 0.054121, loss_ce: 0.019038
2021-12-17 17:26:26,218 iteration 4014 : loss : 0.060019, loss_ce: 0.019691
2021-12-17 17:26:27,526 iteration 4015 : loss : 0.071744, loss_ce: 0.029058
2021-12-17 17:26:28,944 iteration 4016 : loss : 0.063624, loss_ce: 0.018684
2021-12-17 17:26:30,323 iteration 4017 : loss : 0.068000, loss_ce: 0.015595
2021-12-17 17:26:31,625 iteration 4018 : loss : 0.059161, loss_ce: 0.018079
2021-12-17 17:26:33,003 iteration 4019 : loss : 0.082951, loss_ce: 0.024814
2021-12-17 17:26:34,343 iteration 4020 : loss : 0.058930, loss_ce: 0.014836
2021-12-17 17:26:35,725 iteration 4021 : loss : 0.076428, loss_ce: 0.020547
2021-12-17 17:26:37,165 iteration 4022 : loss : 0.065916, loss_ce: 0.018339
2021-12-17 17:26:38,465 iteration 4023 : loss : 0.058525, loss_ce: 0.021976
2021-12-17 17:26:39,859 iteration 4024 : loss : 0.084225, loss_ce: 0.021098
2021-12-17 17:26:41,229 iteration 4025 : loss : 0.065863, loss_ce: 0.019139
2021-12-17 17:26:42,643 iteration 4026 : loss : 0.064060, loss_ce: 0.017481
2021-12-17 17:26:43,930 iteration 4027 : loss : 0.056452, loss_ce: 0.015552
2021-12-17 17:26:45,410 iteration 4028 : loss : 0.067162, loss_ce: 0.026565
2021-12-17 17:26:46,865 iteration 4029 : loss : 0.064820, loss_ce: 0.021074
 59%|███████████████▉           | 237/400 [1:42:05<1:08:08, 25.08s/it]2021-12-17 17:26:48,297 iteration 4030 : loss : 0.062357, loss_ce: 0.018113
2021-12-17 17:26:49,648 iteration 4031 : loss : 0.060213, loss_ce: 0.022105
2021-12-17 17:26:50,941 iteration 4032 : loss : 0.056375, loss_ce: 0.013953
2021-12-17 17:26:52,259 iteration 4033 : loss : 0.060380, loss_ce: 0.020061
2021-12-17 17:26:53,654 iteration 4034 : loss : 0.068114, loss_ce: 0.024523
2021-12-17 17:26:55,053 iteration 4035 : loss : 0.080105, loss_ce: 0.020986
2021-12-17 17:26:56,420 iteration 4036 : loss : 0.061764, loss_ce: 0.019803
2021-12-17 17:26:57,740 iteration 4037 : loss : 0.070516, loss_ce: 0.029095
2021-12-17 17:26:59,096 iteration 4038 : loss : 0.064566, loss_ce: 0.019916
2021-12-17 17:27:00,479 iteration 4039 : loss : 0.074460, loss_ce: 0.018069
2021-12-17 17:27:01,838 iteration 4040 : loss : 0.064810, loss_ce: 0.016886
2021-12-17 17:27:03,241 iteration 4041 : loss : 0.079749, loss_ce: 0.026549
2021-12-17 17:27:04,614 iteration 4042 : loss : 0.069990, loss_ce: 0.021606
2021-12-17 17:27:05,981 iteration 4043 : loss : 0.057802, loss_ce: 0.018751
2021-12-17 17:27:07,339 iteration 4044 : loss : 0.061501, loss_ce: 0.020055
2021-12-17 17:27:08,712 iteration 4045 : loss : 0.063917, loss_ce: 0.018777
2021-12-17 17:27:10,120 iteration 4046 : loss : 0.078264, loss_ce: 0.025249
 60%|████████████████           | 238/400 [1:42:29<1:06:13, 24.53s/it]2021-12-17 17:27:11,558 iteration 4047 : loss : 0.061906, loss_ce: 0.019834
2021-12-17 17:27:12,913 iteration 4048 : loss : 0.075922, loss_ce: 0.016383
2021-12-17 17:27:14,269 iteration 4049 : loss : 0.056392, loss_ce: 0.014001
2021-12-17 17:27:15,582 iteration 4050 : loss : 0.076784, loss_ce: 0.023073
2021-12-17 17:27:16,932 iteration 4051 : loss : 0.060134, loss_ce: 0.020115
2021-12-17 17:27:18,241 iteration 4052 : loss : 0.056406, loss_ce: 0.018632
2021-12-17 17:27:19,613 iteration 4053 : loss : 0.070605, loss_ce: 0.018149
2021-12-17 17:27:21,003 iteration 4054 : loss : 0.057302, loss_ce: 0.018438
2021-12-17 17:27:22,375 iteration 4055 : loss : 0.062804, loss_ce: 0.022743
2021-12-17 17:27:23,737 iteration 4056 : loss : 0.062851, loss_ce: 0.022907
2021-12-17 17:27:25,052 iteration 4057 : loss : 0.060812, loss_ce: 0.015790
2021-12-17 17:27:26,382 iteration 4058 : loss : 0.054257, loss_ce: 0.016135
2021-12-17 17:27:27,776 iteration 4059 : loss : 0.063536, loss_ce: 0.018425
2021-12-17 17:27:29,115 iteration 4060 : loss : 0.060477, loss_ce: 0.019277
2021-12-17 17:27:30,404 iteration 4061 : loss : 0.058118, loss_ce: 0.021353
2021-12-17 17:27:31,746 iteration 4062 : loss : 0.056236, loss_ce: 0.018992
2021-12-17 17:27:33,147 iteration 4063 : loss : 0.061615, loss_ce: 0.017570
 60%|████████████████▏          | 239/400 [1:42:52<1:04:36, 24.08s/it]2021-12-17 17:27:34,546 iteration 4064 : loss : 0.054024, loss_ce: 0.015845
2021-12-17 17:27:35,872 iteration 4065 : loss : 0.056546, loss_ce: 0.012089
2021-12-17 17:27:37,228 iteration 4066 : loss : 0.059323, loss_ce: 0.017634
2021-12-17 17:27:38,579 iteration 4067 : loss : 0.068113, loss_ce: 0.020688
2021-12-17 17:27:39,964 iteration 4068 : loss : 0.066017, loss_ce: 0.020665
2021-12-17 17:27:41,348 iteration 4069 : loss : 0.074731, loss_ce: 0.026600
2021-12-17 17:27:42,671 iteration 4070 : loss : 0.065157, loss_ce: 0.017281
2021-12-17 17:27:44,032 iteration 4071 : loss : 0.068015, loss_ce: 0.019872
2021-12-17 17:27:45,397 iteration 4072 : loss : 0.072444, loss_ce: 0.024497
2021-12-17 17:27:46,785 iteration 4073 : loss : 0.063995, loss_ce: 0.020456
2021-12-17 17:27:48,146 iteration 4074 : loss : 0.078650, loss_ce: 0.029658
2021-12-17 17:27:49,585 iteration 4075 : loss : 0.083999, loss_ce: 0.022103
2021-12-17 17:27:50,959 iteration 4076 : loss : 0.054492, loss_ce: 0.018289
2021-12-17 17:27:52,373 iteration 4077 : loss : 0.070937, loss_ce: 0.024747
2021-12-17 17:27:53,786 iteration 4078 : loss : 0.073277, loss_ce: 0.022702
2021-12-17 17:27:55,120 iteration 4079 : loss : 0.058535, loss_ce: 0.017655
2021-12-17 17:27:55,120 Training Data Eval:
2021-12-17 17:28:02,245   Average segmentation loss on training set: 0.0474
2021-12-17 17:28:02,245 Validation Data Eval:
2021-12-17 17:28:04,726   Average segmentation loss on validation set: 0.1416
2021-12-17 17:28:06,168 iteration 4080 : loss : 0.071408, loss_ce: 0.024100
 60%|████████████████▏          | 240/400 [1:43:25<1:11:22, 26.77s/it]2021-12-17 17:28:07,559 iteration 4081 : loss : 0.059591, loss_ce: 0.020046
2021-12-17 17:28:08,917 iteration 4082 : loss : 0.062207, loss_ce: 0.020048
2021-12-17 17:28:10,271 iteration 4083 : loss : 0.056302, loss_ce: 0.018813
2021-12-17 17:28:11,665 iteration 4084 : loss : 0.074605, loss_ce: 0.019743
2021-12-17 17:28:13,104 iteration 4085 : loss : 0.067602, loss_ce: 0.017986
2021-12-17 17:28:14,514 iteration 4086 : loss : 0.072155, loss_ce: 0.028486
2021-12-17 17:28:15,864 iteration 4087 : loss : 0.074413, loss_ce: 0.020278
2021-12-17 17:28:17,216 iteration 4088 : loss : 0.068815, loss_ce: 0.022998
2021-12-17 17:28:18,596 iteration 4089 : loss : 0.061756, loss_ce: 0.016775
2021-12-17 17:28:19,977 iteration 4090 : loss : 0.056688, loss_ce: 0.018052
2021-12-17 17:28:21,313 iteration 4091 : loss : 0.055388, loss_ce: 0.014453
2021-12-17 17:28:22,668 iteration 4092 : loss : 0.054525, loss_ce: 0.015800
2021-12-17 17:28:24,031 iteration 4093 : loss : 0.068077, loss_ce: 0.022888
2021-12-17 17:28:25,353 iteration 4094 : loss : 0.057640, loss_ce: 0.016243
2021-12-17 17:28:26,704 iteration 4095 : loss : 0.057427, loss_ce: 0.018259
2021-12-17 17:28:28,062 iteration 4096 : loss : 0.062070, loss_ce: 0.019650
2021-12-17 17:28:29,431 iteration 4097 : loss : 0.074538, loss_ce: 0.027424
 60%|████████████████▎          | 241/400 [1:43:48<1:08:07, 25.71s/it]2021-12-17 17:28:30,883 iteration 4098 : loss : 0.060722, loss_ce: 0.018304
2021-12-17 17:28:32,223 iteration 4099 : loss : 0.077842, loss_ce: 0.017227
2021-12-17 17:28:33,528 iteration 4100 : loss : 0.059982, loss_ce: 0.021996
2021-12-17 17:28:34,864 iteration 4101 : loss : 0.057505, loss_ce: 0.018695
2021-12-17 17:28:36,232 iteration 4102 : loss : 0.062272, loss_ce: 0.020321
2021-12-17 17:28:37,576 iteration 4103 : loss : 0.076611, loss_ce: 0.025751
2021-12-17 17:28:38,899 iteration 4104 : loss : 0.056573, loss_ce: 0.020228
2021-12-17 17:28:40,270 iteration 4105 : loss : 0.058220, loss_ce: 0.018670
2021-12-17 17:28:41,586 iteration 4106 : loss : 0.062205, loss_ce: 0.011357
2021-12-17 17:28:43,035 iteration 4107 : loss : 0.073081, loss_ce: 0.029565
2021-12-17 17:28:44,430 iteration 4108 : loss : 0.070402, loss_ce: 0.023582
2021-12-17 17:28:45,736 iteration 4109 : loss : 0.057880, loss_ce: 0.011648
2021-12-17 17:28:47,109 iteration 4110 : loss : 0.073247, loss_ce: 0.025831
2021-12-17 17:28:48,518 iteration 4111 : loss : 0.072064, loss_ce: 0.025826
2021-12-17 17:28:49,857 iteration 4112 : loss : 0.074703, loss_ce: 0.021302
2021-12-17 17:28:51,233 iteration 4113 : loss : 0.058929, loss_ce: 0.019517
2021-12-17 17:28:52,670 iteration 4114 : loss : 0.082630, loss_ce: 0.029526
 60%|████████████████▎          | 242/400 [1:44:11<1:05:45, 24.97s/it]2021-12-17 17:28:54,053 iteration 4115 : loss : 0.058116, loss_ce: 0.013867
2021-12-17 17:28:55,359 iteration 4116 : loss : 0.055705, loss_ce: 0.019681
2021-12-17 17:28:56,840 iteration 4117 : loss : 0.075866, loss_ce: 0.020099
2021-12-17 17:28:58,303 iteration 4118 : loss : 0.075133, loss_ce: 0.026101
2021-12-17 17:28:59,690 iteration 4119 : loss : 0.071677, loss_ce: 0.026197
2021-12-17 17:29:01,061 iteration 4120 : loss : 0.090225, loss_ce: 0.015708
2021-12-17 17:29:02,433 iteration 4121 : loss : 0.061268, loss_ce: 0.024055
2021-12-17 17:29:03,770 iteration 4122 : loss : 0.065414, loss_ce: 0.018693
2021-12-17 17:29:05,192 iteration 4123 : loss : 0.065608, loss_ce: 0.018210
2021-12-17 17:29:06,492 iteration 4124 : loss : 0.060696, loss_ce: 0.017885
2021-12-17 17:29:07,906 iteration 4125 : loss : 0.068931, loss_ce: 0.019497
2021-12-17 17:29:09,281 iteration 4126 : loss : 0.061657, loss_ce: 0.021986
2021-12-17 17:29:10,677 iteration 4127 : loss : 0.067039, loss_ce: 0.022731
2021-12-17 17:29:12,001 iteration 4128 : loss : 0.067496, loss_ce: 0.026930
2021-12-17 17:29:13,412 iteration 4129 : loss : 0.059207, loss_ce: 0.018575
2021-12-17 17:29:14,771 iteration 4130 : loss : 0.059860, loss_ce: 0.024569
2021-12-17 17:29:16,065 iteration 4131 : loss : 0.045880, loss_ce: 0.010903
 61%|████████████████▍          | 243/400 [1:44:35<1:04:06, 24.50s/it]2021-12-17 17:29:17,531 iteration 4132 : loss : 0.070156, loss_ce: 0.021169
2021-12-17 17:29:18,944 iteration 4133 : loss : 0.082514, loss_ce: 0.026067
2021-12-17 17:29:20,225 iteration 4134 : loss : 0.059152, loss_ce: 0.019542
2021-12-17 17:29:21,628 iteration 4135 : loss : 0.068216, loss_ce: 0.020583
2021-12-17 17:29:22,992 iteration 4136 : loss : 0.060614, loss_ce: 0.023224
2021-12-17 17:29:24,330 iteration 4137 : loss : 0.063262, loss_ce: 0.022608
2021-12-17 17:29:25,665 iteration 4138 : loss : 0.060864, loss_ce: 0.023392
2021-12-17 17:29:27,060 iteration 4139 : loss : 0.075000, loss_ce: 0.019000
2021-12-17 17:29:28,472 iteration 4140 : loss : 0.085713, loss_ce: 0.023761
2021-12-17 17:29:29,822 iteration 4141 : loss : 0.073557, loss_ce: 0.019782
2021-12-17 17:29:31,204 iteration 4142 : loss : 0.073866, loss_ce: 0.019580
2021-12-17 17:29:32,614 iteration 4143 : loss : 0.069476, loss_ce: 0.017893
2021-12-17 17:29:33,957 iteration 4144 : loss : 0.065747, loss_ce: 0.022957
2021-12-17 17:29:35,292 iteration 4145 : loss : 0.057101, loss_ce: 0.014108
2021-12-17 17:29:36,653 iteration 4146 : loss : 0.066751, loss_ce: 0.019423
2021-12-17 17:29:37,995 iteration 4147 : loss : 0.063604, loss_ce: 0.018586
2021-12-17 17:29:39,281 iteration 4148 : loss : 0.045204, loss_ce: 0.013057
 61%|████████████████▍          | 244/400 [1:44:58<1:02:41, 24.11s/it]2021-12-17 17:29:40,800 iteration 4149 : loss : 0.087313, loss_ce: 0.026939
2021-12-17 17:29:42,083 iteration 4150 : loss : 0.056884, loss_ce: 0.014578
2021-12-17 17:29:43,478 iteration 4151 : loss : 0.072663, loss_ce: 0.031686
2021-12-17 17:29:44,764 iteration 4152 : loss : 0.054136, loss_ce: 0.017144
2021-12-17 17:29:46,159 iteration 4153 : loss : 0.080330, loss_ce: 0.019345
2021-12-17 17:29:47,538 iteration 4154 : loss : 0.065927, loss_ce: 0.024443
2021-12-17 17:29:48,950 iteration 4155 : loss : 0.064040, loss_ce: 0.017254
2021-12-17 17:29:50,229 iteration 4156 : loss : 0.046767, loss_ce: 0.013428
2021-12-17 17:29:51,621 iteration 4157 : loss : 0.070192, loss_ce: 0.020426
2021-12-17 17:29:52,968 iteration 4158 : loss : 0.069647, loss_ce: 0.026333
2021-12-17 17:29:54,361 iteration 4159 : loss : 0.061468, loss_ce: 0.020571
2021-12-17 17:29:55,727 iteration 4160 : loss : 0.071218, loss_ce: 0.028024
2021-12-17 17:29:57,082 iteration 4161 : loss : 0.055111, loss_ce: 0.016325
2021-12-17 17:29:58,417 iteration 4162 : loss : 0.060801, loss_ce: 0.017463
2021-12-17 17:29:59,812 iteration 4163 : loss : 0.079862, loss_ce: 0.019476
2021-12-17 17:30:01,207 iteration 4164 : loss : 0.071227, loss_ce: 0.026956
2021-12-17 17:30:01,207 Training Data Eval:
2021-12-17 17:30:08,288   Average segmentation loss on training set: 0.0452
2021-12-17 17:30:08,288 Validation Data Eval:
2021-12-17 17:30:10,757   Average segmentation loss on validation set: 0.1322
2021-12-17 17:30:17,035 Found new lowest validation loss at iteration 4164! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/TU_3seeds/TU_RESNET_no_pretraining_SGD_best_val_loss_seed100.pth
2021-12-17 17:30:18,435 iteration 4165 : loss : 0.070599, loss_ce: 0.023885
 61%|████████████████▌          | 245/400 [1:45:37<1:13:57, 28.63s/it]2021-12-17 17:30:19,753 iteration 4166 : loss : 0.054686, loss_ce: 0.016066
2021-12-17 17:30:21,085 iteration 4167 : loss : 0.079471, loss_ce: 0.018463
2021-12-17 17:30:22,437 iteration 4168 : loss : 0.054503, loss_ce: 0.017600
2021-12-17 17:30:23,768 iteration 4169 : loss : 0.060225, loss_ce: 0.020161
2021-12-17 17:30:25,125 iteration 4170 : loss : 0.073335, loss_ce: 0.025935
2021-12-17 17:30:26,407 iteration 4171 : loss : 0.066302, loss_ce: 0.026292
2021-12-17 17:30:27,710 iteration 4172 : loss : 0.068194, loss_ce: 0.022457
2021-12-17 17:30:28,947 iteration 4173 : loss : 0.056924, loss_ce: 0.014950
2021-12-17 17:30:30,302 iteration 4174 : loss : 0.071248, loss_ce: 0.022424
2021-12-17 17:30:31,630 iteration 4175 : loss : 0.066597, loss_ce: 0.016242
2021-12-17 17:30:32,988 iteration 4176 : loss : 0.066565, loss_ce: 0.019518
2021-12-17 17:30:34,245 iteration 4177 : loss : 0.056936, loss_ce: 0.021184
2021-12-17 17:30:35,549 iteration 4178 : loss : 0.060790, loss_ce: 0.021236
2021-12-17 17:30:36,903 iteration 4179 : loss : 0.059934, loss_ce: 0.017133
2021-12-17 17:30:38,293 iteration 4180 : loss : 0.065207, loss_ce: 0.020248
2021-12-17 17:30:39,633 iteration 4181 : loss : 0.062740, loss_ce: 0.022161
2021-12-17 17:30:41,001 iteration 4182 : loss : 0.081128, loss_ce: 0.024146
 62%|████████████████▌          | 246/400 [1:46:00<1:08:48, 26.81s/it]2021-12-17 17:30:42,366 iteration 4183 : loss : 0.109827, loss_ce: 0.028885
2021-12-17 17:30:43,674 iteration 4184 : loss : 0.058405, loss_ce: 0.017225
2021-12-17 17:30:45,062 iteration 4185 : loss : 0.062840, loss_ce: 0.018751
2021-12-17 17:30:46,434 iteration 4186 : loss : 0.056915, loss_ce: 0.018598
2021-12-17 17:30:47,788 iteration 4187 : loss : 0.063578, loss_ce: 0.021780
2021-12-17 17:30:49,146 iteration 4188 : loss : 0.062620, loss_ce: 0.018480
2021-12-17 17:30:50,462 iteration 4189 : loss : 0.058069, loss_ce: 0.016390
2021-12-17 17:30:51,933 iteration 4190 : loss : 0.068866, loss_ce: 0.024347
2021-12-17 17:30:53,360 iteration 4191 : loss : 0.061568, loss_ce: 0.014607
2021-12-17 17:30:54,681 iteration 4192 : loss : 0.055356, loss_ce: 0.023696
2021-12-17 17:30:55,982 iteration 4193 : loss : 0.057454, loss_ce: 0.016109
2021-12-17 17:30:57,349 iteration 4194 : loss : 0.061481, loss_ce: 0.017669
2021-12-17 17:30:58,698 iteration 4195 : loss : 0.052826, loss_ce: 0.017669
2021-12-17 17:31:00,044 iteration 4196 : loss : 0.052252, loss_ce: 0.014946
2021-12-17 17:31:01,373 iteration 4197 : loss : 0.053862, loss_ce: 0.017561
2021-12-17 17:31:02,698 iteration 4198 : loss : 0.064823, loss_ce: 0.013320
2021-12-17 17:31:04,109 iteration 4199 : loss : 0.077210, loss_ce: 0.026871
 62%|████████████████▋          | 247/400 [1:46:23<1:05:31, 25.70s/it]2021-12-17 17:31:05,516 iteration 4200 : loss : 0.057554, loss_ce: 0.015694
2021-12-17 17:31:06,918 iteration 4201 : loss : 0.065592, loss_ce: 0.025287
2021-12-17 17:31:08,349 iteration 4202 : loss : 0.056510, loss_ce: 0.020038
2021-12-17 17:31:09,784 iteration 4203 : loss : 0.081182, loss_ce: 0.024452
2021-12-17 17:31:11,188 iteration 4204 : loss : 0.055943, loss_ce: 0.017243
2021-12-17 17:31:12,427 iteration 4205 : loss : 0.048022, loss_ce: 0.013697
2021-12-17 17:31:13,777 iteration 4206 : loss : 0.072616, loss_ce: 0.019873
2021-12-17 17:31:15,116 iteration 4207 : loss : 0.056607, loss_ce: 0.019762
2021-12-17 17:31:16,526 iteration 4208 : loss : 0.073165, loss_ce: 0.023531
2021-12-17 17:31:17,884 iteration 4209 : loss : 0.058108, loss_ce: 0.014571
2021-12-17 17:31:19,232 iteration 4210 : loss : 0.054065, loss_ce: 0.016549
2021-12-17 17:31:20,617 iteration 4211 : loss : 0.057519, loss_ce: 0.019853
2021-12-17 17:31:21,956 iteration 4212 : loss : 0.056063, loss_ce: 0.020105
2021-12-17 17:31:23,386 iteration 4213 : loss : 0.057814, loss_ce: 0.015581
2021-12-17 17:31:24,805 iteration 4214 : loss : 0.067002, loss_ce: 0.024228
2021-12-17 17:31:26,203 iteration 4215 : loss : 0.072157, loss_ce: 0.015136
2021-12-17 17:31:27,565 iteration 4216 : loss : 0.073586, loss_ce: 0.025213
 62%|████████████████▋          | 248/400 [1:46:46<1:03:23, 25.03s/it]2021-12-17 17:31:29,045 iteration 4217 : loss : 0.098178, loss_ce: 0.028614
2021-12-17 17:31:30,477 iteration 4218 : loss : 0.074257, loss_ce: 0.030451
2021-12-17 17:31:31,860 iteration 4219 : loss : 0.059745, loss_ce: 0.018043
2021-12-17 17:31:33,232 iteration 4220 : loss : 0.067676, loss_ce: 0.018472
2021-12-17 17:31:34,629 iteration 4221 : loss : 0.078436, loss_ce: 0.022992
2021-12-17 17:31:36,038 iteration 4222 : loss : 0.059779, loss_ce: 0.021671
2021-12-17 17:31:37,522 iteration 4223 : loss : 0.090234, loss_ce: 0.027184
2021-12-17 17:31:38,878 iteration 4224 : loss : 0.063813, loss_ce: 0.017392
2021-12-17 17:31:40,280 iteration 4225 : loss : 0.058958, loss_ce: 0.019514
2021-12-17 17:31:41,720 iteration 4226 : loss : 0.067177, loss_ce: 0.024514
2021-12-17 17:31:43,069 iteration 4227 : loss : 0.061494, loss_ce: 0.017155
2021-12-17 17:31:44,478 iteration 4228 : loss : 0.067437, loss_ce: 0.027008
2021-12-17 17:31:45,801 iteration 4229 : loss : 0.060951, loss_ce: 0.022372
2021-12-17 17:31:47,218 iteration 4230 : loss : 0.063876, loss_ce: 0.017125
2021-12-17 17:31:48,617 iteration 4231 : loss : 0.069580, loss_ce: 0.018541
2021-12-17 17:31:50,032 iteration 4232 : loss : 0.096631, loss_ce: 0.036330
2021-12-17 17:31:51,348 iteration 4233 : loss : 0.060104, loss_ce: 0.018461
 62%|████████████████▊          | 249/400 [1:47:10<1:02:02, 24.65s/it]2021-12-17 17:31:52,815 iteration 4234 : loss : 0.068959, loss_ce: 0.023246
2021-12-17 17:31:54,147 iteration 4235 : loss : 0.055636, loss_ce: 0.018098
2021-12-17 17:31:55,565 iteration 4236 : loss : 0.070035, loss_ce: 0.029039
2021-12-17 17:31:56,921 iteration 4237 : loss : 0.057704, loss_ce: 0.021995
2021-12-17 17:31:58,350 iteration 4238 : loss : 0.076171, loss_ce: 0.021210
2021-12-17 17:31:59,650 iteration 4239 : loss : 0.077796, loss_ce: 0.020745
2021-12-17 17:32:01,094 iteration 4240 : loss : 0.075901, loss_ce: 0.024706
2021-12-17 17:32:02,449 iteration 4241 : loss : 0.057278, loss_ce: 0.015672
2021-12-17 17:32:03,793 iteration 4242 : loss : 0.062911, loss_ce: 0.016656
2021-12-17 17:32:05,161 iteration 4243 : loss : 0.069933, loss_ce: 0.019125
2021-12-17 17:32:06,583 iteration 4244 : loss : 0.067305, loss_ce: 0.018982
2021-12-17 17:32:07,964 iteration 4245 : loss : 0.093968, loss_ce: 0.021382
2021-12-17 17:32:09,321 iteration 4246 : loss : 0.062705, loss_ce: 0.023803
2021-12-17 17:32:10,682 iteration 4247 : loss : 0.067795, loss_ce: 0.015987
2021-12-17 17:32:12,088 iteration 4248 : loss : 0.073427, loss_ce: 0.021237
2021-12-17 17:32:13,453 iteration 4249 : loss : 0.062006, loss_ce: 0.023630
2021-12-17 17:32:13,454 Training Data Eval:
2021-12-17 17:32:20,584   Average segmentation loss on training set: 0.0477
2021-12-17 17:32:20,584 Validation Data Eval:
2021-12-17 17:32:23,064   Average segmentation loss on validation set: 0.1349
2021-12-17 17:32:24,481 iteration 4250 : loss : 0.071649, loss_ce: 0.020279
 62%|████████████████▉          | 250/400 [1:47:43<1:07:59, 27.20s/it]2021-12-17 17:32:25,967 iteration 4251 : loss : 0.067065, loss_ce: 0.021380
2021-12-17 17:32:27,371 iteration 4252 : loss : 0.073054, loss_ce: 0.027780
2021-12-17 17:32:28,772 iteration 4253 : loss : 0.061486, loss_ce: 0.017985
2021-12-17 17:32:30,222 iteration 4254 : loss : 0.062770, loss_ce: 0.022896
2021-12-17 17:32:31,505 iteration 4255 : loss : 0.049824, loss_ce: 0.015458
2021-12-17 17:32:32,875 iteration 4256 : loss : 0.064221, loss_ce: 0.015056
2021-12-17 17:32:34,313 iteration 4257 : loss : 0.071612, loss_ce: 0.021938
2021-12-17 17:32:35,650 iteration 4258 : loss : 0.060118, loss_ce: 0.018780
2021-12-17 17:32:37,026 iteration 4259 : loss : 0.080008, loss_ce: 0.023730
2021-12-17 17:32:38,402 iteration 4260 : loss : 0.055318, loss_ce: 0.015457
2021-12-17 17:32:39,792 iteration 4261 : loss : 0.062562, loss_ce: 0.018872
2021-12-17 17:32:41,247 iteration 4262 : loss : 0.060458, loss_ce: 0.021714
2021-12-17 17:32:42,619 iteration 4263 : loss : 0.056806, loss_ce: 0.018018
2021-12-17 17:32:43,939 iteration 4264 : loss : 0.069734, loss_ce: 0.020336
2021-12-17 17:32:45,290 iteration 4265 : loss : 0.068105, loss_ce: 0.019939
2021-12-17 17:32:46,654 iteration 4266 : loss : 0.063235, loss_ce: 0.019195
2021-12-17 17:32:48,033 iteration 4267 : loss : 0.054736, loss_ce: 0.020408
 63%|████████████████▉          | 251/400 [1:48:07<1:04:49, 26.10s/it]2021-12-17 17:32:49,450 iteration 4268 : loss : 0.071836, loss_ce: 0.025787
2021-12-17 17:32:50,771 iteration 4269 : loss : 0.061895, loss_ce: 0.017901
2021-12-17 17:32:52,116 iteration 4270 : loss : 0.074883, loss_ce: 0.009620
2021-12-17 17:32:53,440 iteration 4271 : loss : 0.056694, loss_ce: 0.020031
2021-12-17 17:32:54,838 iteration 4272 : loss : 0.086321, loss_ce: 0.033177
2021-12-17 17:32:56,227 iteration 4273 : loss : 0.056349, loss_ce: 0.017387
2021-12-17 17:32:57,637 iteration 4274 : loss : 0.062621, loss_ce: 0.022980
2021-12-17 17:32:58,896 iteration 4275 : loss : 0.051477, loss_ce: 0.017685
2021-12-17 17:33:00,221 iteration 4276 : loss : 0.064512, loss_ce: 0.017703
2021-12-17 17:33:01,553 iteration 4277 : loss : 0.059298, loss_ce: 0.018759
2021-12-17 17:33:02,887 iteration 4278 : loss : 0.057299, loss_ce: 0.013508
2021-12-17 17:33:04,198 iteration 4279 : loss : 0.053375, loss_ce: 0.010741
2021-12-17 17:33:05,522 iteration 4280 : loss : 0.065019, loss_ce: 0.015746
2021-12-17 17:33:06,991 iteration 4281 : loss : 0.068497, loss_ce: 0.024329
2021-12-17 17:33:08,355 iteration 4282 : loss : 0.059769, loss_ce: 0.021189
2021-12-17 17:33:09,635 iteration 4283 : loss : 0.058225, loss_ce: 0.020357
2021-12-17 17:33:10,983 iteration 4284 : loss : 0.067834, loss_ce: 0.026616
 63%|█████████████████          | 252/400 [1:48:30<1:02:03, 25.16s/it]2021-12-17 17:33:12,457 iteration 4285 : loss : 0.074800, loss_ce: 0.026102
2021-12-17 17:33:13,859 iteration 4286 : loss : 0.067687, loss_ce: 0.017437
2021-12-17 17:33:15,274 iteration 4287 : loss : 0.095690, loss_ce: 0.032987
2021-12-17 17:33:16,636 iteration 4288 : loss : 0.060280, loss_ce: 0.016320
2021-12-17 17:33:18,020 iteration 4289 : loss : 0.065561, loss_ce: 0.016555
2021-12-17 17:33:19,431 iteration 4290 : loss : 0.073876, loss_ce: 0.023347
2021-12-17 17:33:20,744 iteration 4291 : loss : 0.059200, loss_ce: 0.017478
2021-12-17 17:33:22,186 iteration 4292 : loss : 0.068765, loss_ce: 0.022262
2021-12-17 17:33:23,580 iteration 4293 : loss : 0.061855, loss_ce: 0.022047
2021-12-17 17:33:24,947 iteration 4294 : loss : 0.073065, loss_ce: 0.029019
2021-12-17 17:33:26,343 iteration 4295 : loss : 0.058870, loss_ce: 0.022226
2021-12-17 17:33:27,638 iteration 4296 : loss : 0.050592, loss_ce: 0.016934
2021-12-17 17:33:29,009 iteration 4297 : loss : 0.055676, loss_ce: 0.014094
2021-12-17 17:33:30,344 iteration 4298 : loss : 0.062710, loss_ce: 0.017717
2021-12-17 17:33:31,783 iteration 4299 : loss : 0.075144, loss_ce: 0.026524
2021-12-17 17:33:33,193 iteration 4300 : loss : 0.073225, loss_ce: 0.020718
2021-12-17 17:33:34,538 iteration 4301 : loss : 0.053655, loss_ce: 0.017387
 63%|█████████████████          | 253/400 [1:48:53<1:00:27, 24.67s/it]2021-12-17 17:33:35,967 iteration 4302 : loss : 0.063180, loss_ce: 0.021992
2021-12-17 17:33:37,367 iteration 4303 : loss : 0.063555, loss_ce: 0.018285
2021-12-17 17:33:38,667 iteration 4304 : loss : 0.051900, loss_ce: 0.014929
2021-12-17 17:33:40,059 iteration 4305 : loss : 0.073812, loss_ce: 0.019023
2021-12-17 17:33:41,396 iteration 4306 : loss : 0.074384, loss_ce: 0.022761
2021-12-17 17:33:42,744 iteration 4307 : loss : 0.057857, loss_ce: 0.016226
2021-12-17 17:33:44,167 iteration 4308 : loss : 0.067558, loss_ce: 0.021644
2021-12-17 17:33:45,497 iteration 4309 : loss : 0.069555, loss_ce: 0.019569
2021-12-17 17:33:46,887 iteration 4310 : loss : 0.071031, loss_ce: 0.025670
2021-12-17 17:33:48,264 iteration 4311 : loss : 0.066639, loss_ce: 0.025072
2021-12-17 17:33:49,725 iteration 4312 : loss : 0.076964, loss_ce: 0.023744
2021-12-17 17:33:51,087 iteration 4313 : loss : 0.064956, loss_ce: 0.021633
2021-12-17 17:33:52,435 iteration 4314 : loss : 0.072467, loss_ce: 0.022064
2021-12-17 17:33:53,773 iteration 4315 : loss : 0.055897, loss_ce: 0.015978
2021-12-17 17:33:55,190 iteration 4316 : loss : 0.058179, loss_ce: 0.017705
2021-12-17 17:33:56,524 iteration 4317 : loss : 0.063683, loss_ce: 0.019728
2021-12-17 17:33:57,871 iteration 4318 : loss : 0.061466, loss_ce: 0.026160
 64%|██████████████████▍          | 254/400 [1:49:16<59:03, 24.27s/it]2021-12-17 17:33:59,355 iteration 4319 : loss : 0.063538, loss_ce: 0.017591
2021-12-17 17:34:00,774 iteration 4320 : loss : 0.070487, loss_ce: 0.025059
2021-12-17 17:34:02,190 iteration 4321 : loss : 0.059568, loss_ce: 0.021274
2021-12-17 17:34:03,578 iteration 4322 : loss : 0.060389, loss_ce: 0.016266
2021-12-17 17:34:04,915 iteration 4323 : loss : 0.052954, loss_ce: 0.013815
2021-12-17 17:34:06,305 iteration 4324 : loss : 0.061980, loss_ce: 0.019146
2021-12-17 17:34:07,782 iteration 4325 : loss : 0.077699, loss_ce: 0.017241
2021-12-17 17:34:09,148 iteration 4326 : loss : 0.062241, loss_ce: 0.026088
2021-12-17 17:34:10,484 iteration 4327 : loss : 0.063210, loss_ce: 0.022494
2021-12-17 17:34:11,830 iteration 4328 : loss : 0.071563, loss_ce: 0.022780
2021-12-17 17:34:13,231 iteration 4329 : loss : 0.062307, loss_ce: 0.019927
2021-12-17 17:34:14,556 iteration 4330 : loss : 0.059937, loss_ce: 0.018643
2021-12-17 17:34:16,045 iteration 4331 : loss : 0.088052, loss_ce: 0.023040
2021-12-17 17:34:17,448 iteration 4332 : loss : 0.061779, loss_ce: 0.020998
2021-12-17 17:34:18,743 iteration 4333 : loss : 0.061200, loss_ce: 0.018654
2021-12-17 17:34:20,064 iteration 4334 : loss : 0.054257, loss_ce: 0.018072
2021-12-17 17:34:20,065 Training Data Eval:
2021-12-17 17:34:27,153   Average segmentation loss on training set: 0.0439
2021-12-17 17:34:27,154 Validation Data Eval:
2021-12-17 17:34:29,623   Average segmentation loss on validation set: 0.1347
2021-12-17 17:34:31,070 iteration 4335 : loss : 0.090828, loss_ce: 0.041843
 64%|█████████████████▏         | 255/400 [1:49:50<1:05:08, 26.95s/it]2021-12-17 17:34:32,500 iteration 4336 : loss : 0.067792, loss_ce: 0.022590
2021-12-17 17:34:33,898 iteration 4337 : loss : 0.065688, loss_ce: 0.022641
2021-12-17 17:34:35,351 iteration 4338 : loss : 0.090078, loss_ce: 0.035843
2021-12-17 17:34:36,693 iteration 4339 : loss : 0.067617, loss_ce: 0.019923
2021-12-17 17:34:38,074 iteration 4340 : loss : 0.059607, loss_ce: 0.018712
2021-12-17 17:34:39,466 iteration 4341 : loss : 0.071820, loss_ce: 0.029689
2021-12-17 17:34:40,819 iteration 4342 : loss : 0.081729, loss_ce: 0.023457
2021-12-17 17:34:42,191 iteration 4343 : loss : 0.060199, loss_ce: 0.015224
2021-12-17 17:34:43,527 iteration 4344 : loss : 0.068191, loss_ce: 0.021295
2021-12-17 17:34:44,900 iteration 4345 : loss : 0.067736, loss_ce: 0.019132
2021-12-17 17:34:46,237 iteration 4346 : loss : 0.050460, loss_ce: 0.015704
2021-12-17 17:34:47,649 iteration 4347 : loss : 0.066094, loss_ce: 0.019061
2021-12-17 17:34:49,033 iteration 4348 : loss : 0.065849, loss_ce: 0.028523
2021-12-17 17:34:50,392 iteration 4349 : loss : 0.063695, loss_ce: 0.017480
2021-12-17 17:34:51,745 iteration 4350 : loss : 0.051153, loss_ce: 0.016811
2021-12-17 17:34:53,071 iteration 4351 : loss : 0.062560, loss_ce: 0.023556
2021-12-17 17:34:54,418 iteration 4352 : loss : 0.054385, loss_ce: 0.016699
 64%|█████████████████▎         | 256/400 [1:50:13<1:02:05, 25.87s/it]2021-12-17 17:34:55,857 iteration 4353 : loss : 0.074813, loss_ce: 0.021451
2021-12-17 17:34:57,289 iteration 4354 : loss : 0.064797, loss_ce: 0.016057
2021-12-17 17:34:58,606 iteration 4355 : loss : 0.058608, loss_ce: 0.017338
2021-12-17 17:35:00,004 iteration 4356 : loss : 0.067025, loss_ce: 0.026562
2021-12-17 17:35:01,379 iteration 4357 : loss : 0.066442, loss_ce: 0.023355
2021-12-17 17:35:02,724 iteration 4358 : loss : 0.057475, loss_ce: 0.018559
2021-12-17 17:35:04,071 iteration 4359 : loss : 0.053731, loss_ce: 0.016428
2021-12-17 17:35:05,422 iteration 4360 : loss : 0.065894, loss_ce: 0.018864
2021-12-17 17:35:06,839 iteration 4361 : loss : 0.073188, loss_ce: 0.026374
2021-12-17 17:35:08,181 iteration 4362 : loss : 0.057690, loss_ce: 0.018235
2021-12-17 17:35:09,484 iteration 4363 : loss : 0.061929, loss_ce: 0.023035
2021-12-17 17:35:10,892 iteration 4364 : loss : 0.071313, loss_ce: 0.022847
2021-12-17 17:35:12,240 iteration 4365 : loss : 0.061615, loss_ce: 0.020883
2021-12-17 17:35:13,508 iteration 4366 : loss : 0.053063, loss_ce: 0.017274
2021-12-17 17:35:14,872 iteration 4367 : loss : 0.065077, loss_ce: 0.020053
2021-12-17 17:35:16,298 iteration 4368 : loss : 0.082247, loss_ce: 0.027882
2021-12-17 17:35:17,606 iteration 4369 : loss : 0.078267, loss_ce: 0.020336
 64%|██████████████████▋          | 257/400 [1:50:36<59:44, 25.07s/it]2021-12-17 17:35:19,032 iteration 4370 : loss : 0.092011, loss_ce: 0.021113
2021-12-17 17:35:20,405 iteration 4371 : loss : 0.066400, loss_ce: 0.026127
2021-12-17 17:35:21,708 iteration 4372 : loss : 0.061752, loss_ce: 0.023657
2021-12-17 17:35:23,108 iteration 4373 : loss : 0.069817, loss_ce: 0.019566
2021-12-17 17:35:24,464 iteration 4374 : loss : 0.058503, loss_ce: 0.019777
2021-12-17 17:35:25,763 iteration 4375 : loss : 0.060765, loss_ce: 0.019813
2021-12-17 17:35:27,109 iteration 4376 : loss : 0.060454, loss_ce: 0.019577
2021-12-17 17:35:28,554 iteration 4377 : loss : 0.079122, loss_ce: 0.024357
2021-12-17 17:35:29,944 iteration 4378 : loss : 0.075257, loss_ce: 0.024629
2021-12-17 17:35:31,391 iteration 4379 : loss : 0.074109, loss_ce: 0.028203
2021-12-17 17:35:32,771 iteration 4380 : loss : 0.062813, loss_ce: 0.024162
2021-12-17 17:35:34,165 iteration 4381 : loss : 0.082213, loss_ce: 0.030974
2021-12-17 17:35:35,520 iteration 4382 : loss : 0.072975, loss_ce: 0.025731
2021-12-17 17:35:36,880 iteration 4383 : loss : 0.058275, loss_ce: 0.013214
2021-12-17 17:35:38,253 iteration 4384 : loss : 0.090273, loss_ce: 0.031495
2021-12-17 17:35:39,534 iteration 4385 : loss : 0.058796, loss_ce: 0.021093
2021-12-17 17:35:40,909 iteration 4386 : loss : 0.060472, loss_ce: 0.021305
 64%|██████████████████▋          | 258/400 [1:51:00<58:04, 24.54s/it]2021-12-17 17:35:42,321 iteration 4387 : loss : 0.053280, loss_ce: 0.015074
2021-12-17 17:35:43,723 iteration 4388 : loss : 0.060819, loss_ce: 0.021236
2021-12-17 17:35:45,032 iteration 4389 : loss : 0.051180, loss_ce: 0.017683
2021-12-17 17:35:46,349 iteration 4390 : loss : 0.054817, loss_ce: 0.016896
2021-12-17 17:35:47,709 iteration 4391 : loss : 0.058786, loss_ce: 0.019708
2021-12-17 17:35:49,106 iteration 4392 : loss : 0.072370, loss_ce: 0.029280
2021-12-17 17:35:50,408 iteration 4393 : loss : 0.069893, loss_ce: 0.020982
2021-12-17 17:35:51,842 iteration 4394 : loss : 0.064374, loss_ce: 0.023848
2021-12-17 17:35:53,235 iteration 4395 : loss : 0.065348, loss_ce: 0.020744
2021-12-17 17:35:54,659 iteration 4396 : loss : 0.070162, loss_ce: 0.023605
2021-12-17 17:35:56,015 iteration 4397 : loss : 0.090643, loss_ce: 0.028958
2021-12-17 17:35:57,344 iteration 4398 : loss : 0.066475, loss_ce: 0.018496
2021-12-17 17:35:58,696 iteration 4399 : loss : 0.067934, loss_ce: 0.019393
2021-12-17 17:36:00,021 iteration 4400 : loss : 0.052191, loss_ce: 0.017833
2021-12-17 17:36:01,364 iteration 4401 : loss : 0.062721, loss_ce: 0.024754
2021-12-17 17:36:02,683 iteration 4402 : loss : 0.053670, loss_ce: 0.015673
2021-12-17 17:36:04,042 iteration 4403 : loss : 0.065586, loss_ce: 0.017401
 65%|██████████████████▊          | 259/400 [1:51:23<56:40, 24.11s/it]2021-12-17 17:36:05,420 iteration 4404 : loss : 0.052634, loss_ce: 0.020201
2021-12-17 17:36:06,815 iteration 4405 : loss : 0.076853, loss_ce: 0.020054
2021-12-17 17:36:08,185 iteration 4406 : loss : 0.069872, loss_ce: 0.018428
2021-12-17 17:36:09,498 iteration 4407 : loss : 0.056715, loss_ce: 0.017164
2021-12-17 17:36:10,789 iteration 4408 : loss : 0.059416, loss_ce: 0.013991
2021-12-17 17:36:12,161 iteration 4409 : loss : 0.055677, loss_ce: 0.017652
2021-12-17 17:36:13,531 iteration 4410 : loss : 0.073709, loss_ce: 0.022558
2021-12-17 17:36:14,952 iteration 4411 : loss : 0.057616, loss_ce: 0.020328
2021-12-17 17:36:16,263 iteration 4412 : loss : 0.070076, loss_ce: 0.025177
2021-12-17 17:36:17,683 iteration 4413 : loss : 0.069107, loss_ce: 0.020328
2021-12-17 17:36:18,961 iteration 4414 : loss : 0.059815, loss_ce: 0.016639
2021-12-17 17:36:20,339 iteration 4415 : loss : 0.079997, loss_ce: 0.027047
2021-12-17 17:36:21,659 iteration 4416 : loss : 0.064979, loss_ce: 0.015323
2021-12-17 17:36:23,021 iteration 4417 : loss : 0.066760, loss_ce: 0.018716
2021-12-17 17:36:24,398 iteration 4418 : loss : 0.068246, loss_ce: 0.025971
2021-12-17 17:36:25,782 iteration 4419 : loss : 0.061698, loss_ce: 0.018150
2021-12-17 17:36:25,782 Training Data Eval:
2021-12-17 17:36:32,871   Average segmentation loss on training set: 0.0431
2021-12-17 17:36:32,872 Validation Data Eval:
2021-12-17 17:36:35,337   Average segmentation loss on validation set: 0.1337
2021-12-17 17:36:36,664 iteration 4420 : loss : 0.051393, loss_ce: 0.017388
 65%|█████████████████▌         | 260/400 [1:51:55<1:02:13, 26.66s/it]2021-12-17 17:36:38,107 iteration 4421 : loss : 0.061040, loss_ce: 0.017580
2021-12-17 17:36:39,519 iteration 4422 : loss : 0.057994, loss_ce: 0.018019
2021-12-17 17:36:40,984 iteration 4423 : loss : 0.069926, loss_ce: 0.023229
2021-12-17 17:36:42,401 iteration 4424 : loss : 0.063057, loss_ce: 0.020709
2021-12-17 17:36:43,708 iteration 4425 : loss : 0.053692, loss_ce: 0.016217
2021-12-17 17:36:45,117 iteration 4426 : loss : 0.057816, loss_ce: 0.017185
2021-12-17 17:36:46,513 iteration 4427 : loss : 0.067299, loss_ce: 0.013678
2021-12-17 17:36:47,923 iteration 4428 : loss : 0.066178, loss_ce: 0.019760
2021-12-17 17:36:49,340 iteration 4429 : loss : 0.064307, loss_ce: 0.018185
2021-12-17 17:36:50,693 iteration 4430 : loss : 0.059053, loss_ce: 0.018020
2021-12-17 17:36:52,032 iteration 4431 : loss : 0.054295, loss_ce: 0.016979
2021-12-17 17:36:53,385 iteration 4432 : loss : 0.052394, loss_ce: 0.016825
2021-12-17 17:36:54,741 iteration 4433 : loss : 0.054403, loss_ce: 0.017979
2021-12-17 17:36:56,095 iteration 4434 : loss : 0.053248, loss_ce: 0.015556
2021-12-17 17:36:57,480 iteration 4435 : loss : 0.054688, loss_ce: 0.016003
2021-12-17 17:36:58,941 iteration 4436 : loss : 0.081564, loss_ce: 0.032117
2021-12-17 17:37:00,244 iteration 4437 : loss : 0.052015, loss_ce: 0.016315
 65%|██████████████████▉          | 261/400 [1:52:19<59:37, 25.74s/it]2021-12-17 17:37:01,724 iteration 4438 : loss : 0.087327, loss_ce: 0.026637
2021-12-17 17:37:03,056 iteration 4439 : loss : 0.076331, loss_ce: 0.020573
2021-12-17 17:37:04,467 iteration 4440 : loss : 0.063844, loss_ce: 0.020001
2021-12-17 17:37:05,866 iteration 4441 : loss : 0.061252, loss_ce: 0.021210
2021-12-17 17:37:07,183 iteration 4442 : loss : 0.051919, loss_ce: 0.018642
2021-12-17 17:37:08,561 iteration 4443 : loss : 0.059363, loss_ce: 0.019749
2021-12-17 17:37:09,905 iteration 4444 : loss : 0.074525, loss_ce: 0.022688
2021-12-17 17:37:11,290 iteration 4445 : loss : 0.058237, loss_ce: 0.016860
2021-12-17 17:37:12,677 iteration 4446 : loss : 0.058244, loss_ce: 0.018355
2021-12-17 17:37:14,067 iteration 4447 : loss : 0.066312, loss_ce: 0.022427
2021-12-17 17:37:15,419 iteration 4448 : loss : 0.070777, loss_ce: 0.017701
2021-12-17 17:37:16,800 iteration 4449 : loss : 0.059746, loss_ce: 0.023491
2021-12-17 17:37:18,215 iteration 4450 : loss : 0.067385, loss_ce: 0.022350
2021-12-17 17:37:19,515 iteration 4451 : loss : 0.057593, loss_ce: 0.017274
2021-12-17 17:37:20,889 iteration 4452 : loss : 0.060653, loss_ce: 0.022424
2021-12-17 17:37:22,337 iteration 4453 : loss : 0.071121, loss_ce: 0.023918
2021-12-17 17:37:23,717 iteration 4454 : loss : 0.079704, loss_ce: 0.028622
 66%|██████████████████▉          | 262/400 [1:52:42<57:38, 25.06s/it]2021-12-17 17:37:25,207 iteration 4455 : loss : 0.066222, loss_ce: 0.019584
2021-12-17 17:37:26,571 iteration 4456 : loss : 0.064110, loss_ce: 0.024326
2021-12-17 17:37:27,851 iteration 4457 : loss : 0.050135, loss_ce: 0.019387
2021-12-17 17:37:29,231 iteration 4458 : loss : 0.077536, loss_ce: 0.034065
2021-12-17 17:37:30,536 iteration 4459 : loss : 0.055046, loss_ce: 0.018067
2021-12-17 17:37:31,901 iteration 4460 : loss : 0.051005, loss_ce: 0.014497
2021-12-17 17:37:33,211 iteration 4461 : loss : 0.057784, loss_ce: 0.021561
2021-12-17 17:37:34,540 iteration 4462 : loss : 0.065011, loss_ce: 0.021458
2021-12-17 17:37:35,857 iteration 4463 : loss : 0.047498, loss_ce: 0.013005
2021-12-17 17:37:37,181 iteration 4464 : loss : 0.051638, loss_ce: 0.013879
2021-12-17 17:37:38,599 iteration 4465 : loss : 0.068634, loss_ce: 0.025109
2021-12-17 17:37:39,984 iteration 4466 : loss : 0.062161, loss_ce: 0.015722
2021-12-17 17:37:41,340 iteration 4467 : loss : 0.051229, loss_ce: 0.016185
2021-12-17 17:37:42,688 iteration 4468 : loss : 0.059626, loss_ce: 0.015966
2021-12-17 17:37:43,994 iteration 4469 : loss : 0.071459, loss_ce: 0.017380
2021-12-17 17:37:45,390 iteration 4470 : loss : 0.070935, loss_ce: 0.021311
2021-12-17 17:37:46,791 iteration 4471 : loss : 0.079942, loss_ce: 0.026092
 66%|███████████████████          | 263/400 [1:53:05<55:51, 24.46s/it]2021-12-17 17:37:48,168 iteration 4472 : loss : 0.058589, loss_ce: 0.020402
2021-12-17 17:37:49,509 iteration 4473 : loss : 0.055933, loss_ce: 0.019423
2021-12-17 17:37:50,884 iteration 4474 : loss : 0.060903, loss_ce: 0.016845
2021-12-17 17:37:52,203 iteration 4475 : loss : 0.061252, loss_ce: 0.022755
2021-12-17 17:37:53,474 iteration 4476 : loss : 0.062120, loss_ce: 0.019673
2021-12-17 17:37:54,840 iteration 4477 : loss : 0.056174, loss_ce: 0.017805
2021-12-17 17:37:56,210 iteration 4478 : loss : 0.065300, loss_ce: 0.018605
2021-12-17 17:37:57,576 iteration 4479 : loss : 0.064189, loss_ce: 0.012005
2021-12-17 17:37:58,902 iteration 4480 : loss : 0.052670, loss_ce: 0.017058
2021-12-17 17:38:00,216 iteration 4481 : loss : 0.059221, loss_ce: 0.021620
2021-12-17 17:38:01,630 iteration 4482 : loss : 0.060616, loss_ce: 0.016749
2021-12-17 17:38:03,075 iteration 4483 : loss : 0.075575, loss_ce: 0.026146
2021-12-17 17:38:04,480 iteration 4484 : loss : 0.079831, loss_ce: 0.026650
2021-12-17 17:38:05,812 iteration 4485 : loss : 0.046092, loss_ce: 0.011394
2021-12-17 17:38:07,270 iteration 4486 : loss : 0.090539, loss_ce: 0.035119
2021-12-17 17:38:08,587 iteration 4487 : loss : 0.067302, loss_ce: 0.026243
2021-12-17 17:38:09,936 iteration 4488 : loss : 0.065263, loss_ce: 0.023055
 66%|███████████████████▏         | 264/400 [1:53:29<54:33, 24.07s/it]2021-12-17 17:38:11,382 iteration 4489 : loss : 0.078406, loss_ce: 0.025945
2021-12-17 17:38:12,733 iteration 4490 : loss : 0.056884, loss_ce: 0.015074
2021-12-17 17:38:14,148 iteration 4491 : loss : 0.079690, loss_ce: 0.027232
2021-12-17 17:38:15,531 iteration 4492 : loss : 0.055841, loss_ce: 0.017668
2021-12-17 17:38:16,961 iteration 4493 : loss : 0.075706, loss_ce: 0.022656
2021-12-17 17:38:18,253 iteration 4494 : loss : 0.063776, loss_ce: 0.019346
2021-12-17 17:38:19,644 iteration 4495 : loss : 0.073894, loss_ce: 0.029651
2021-12-17 17:38:21,043 iteration 4496 : loss : 0.067527, loss_ce: 0.018187
2021-12-17 17:38:22,345 iteration 4497 : loss : 0.055131, loss_ce: 0.015235
2021-12-17 17:38:23,778 iteration 4498 : loss : 0.067752, loss_ce: 0.024022
2021-12-17 17:38:25,257 iteration 4499 : loss : 0.073119, loss_ce: 0.029314
2021-12-17 17:38:26,604 iteration 4500 : loss : 0.059167, loss_ce: 0.021998
2021-12-17 17:38:27,923 iteration 4501 : loss : 0.062015, loss_ce: 0.019602
2021-12-17 17:38:29,246 iteration 4502 : loss : 0.053932, loss_ce: 0.018524
2021-12-17 17:38:30,677 iteration 4503 : loss : 0.062268, loss_ce: 0.022396
2021-12-17 17:38:32,044 iteration 4504 : loss : 0.055784, loss_ce: 0.014776
2021-12-17 17:38:32,044 Training Data Eval:
2021-12-17 17:38:39,141   Average segmentation loss on training set: 0.0447
2021-12-17 17:38:39,141 Validation Data Eval:
2021-12-17 17:38:41,623   Average segmentation loss on validation set: 0.1236
2021-12-17 17:38:47,910 Found new lowest validation loss at iteration 4504! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/TU_3seeds/TU_RESNET_no_pretraining_SGD_best_val_loss_seed100.pth
2021-12-17 17:38:49,210 iteration 4505 : loss : 0.051412, loss_ce: 0.017154
 66%|█████████████████▉         | 265/400 [1:54:08<1:04:25, 28.63s/it]2021-12-17 17:38:50,624 iteration 4506 : loss : 0.067932, loss_ce: 0.019003
2021-12-17 17:38:51,905 iteration 4507 : loss : 0.048803, loss_ce: 0.013386
2021-12-17 17:38:53,265 iteration 4508 : loss : 0.073722, loss_ce: 0.019001
2021-12-17 17:38:54,595 iteration 4509 : loss : 0.062746, loss_ce: 0.018139
2021-12-17 17:38:55,914 iteration 4510 : loss : 0.055260, loss_ce: 0.016767
2021-12-17 17:38:57,256 iteration 4511 : loss : 0.057535, loss_ce: 0.017823
2021-12-17 17:38:58,563 iteration 4512 : loss : 0.048121, loss_ce: 0.015017
2021-12-17 17:38:59,895 iteration 4513 : loss : 0.060043, loss_ce: 0.023292
2021-12-17 17:39:01,155 iteration 4514 : loss : 0.059488, loss_ce: 0.017924
2021-12-17 17:39:02,455 iteration 4515 : loss : 0.060999, loss_ce: 0.019306
2021-12-17 17:39:03,870 iteration 4516 : loss : 0.071180, loss_ce: 0.023895
2021-12-17 17:39:05,178 iteration 4517 : loss : 0.062066, loss_ce: 0.016709
2021-12-17 17:39:06,521 iteration 4518 : loss : 0.059191, loss_ce: 0.017252
2021-12-17 17:39:07,847 iteration 4519 : loss : 0.066631, loss_ce: 0.025185
2021-12-17 17:39:09,120 iteration 4520 : loss : 0.059571, loss_ce: 0.016236
2021-12-17 17:39:10,456 iteration 4521 : loss : 0.064321, loss_ce: 0.017466
2021-12-17 17:39:11,721 iteration 4522 : loss : 0.056660, loss_ce: 0.022289
 66%|███████████████████▎         | 266/400 [1:54:30<59:50, 26.79s/it]2021-12-17 17:39:13,150 iteration 4523 : loss : 0.052126, loss_ce: 0.016159
2021-12-17 17:39:14,417 iteration 4524 : loss : 0.049018, loss_ce: 0.016208
2021-12-17 17:39:15,849 iteration 4525 : loss : 0.091175, loss_ce: 0.022002
2021-12-17 17:39:17,256 iteration 4526 : loss : 0.054623, loss_ce: 0.017394
2021-12-17 17:39:18,653 iteration 4527 : loss : 0.058648, loss_ce: 0.020889
2021-12-17 17:39:20,094 iteration 4528 : loss : 0.059090, loss_ce: 0.018710
2021-12-17 17:39:21,470 iteration 4529 : loss : 0.071152, loss_ce: 0.021996
2021-12-17 17:39:22,876 iteration 4530 : loss : 0.062916, loss_ce: 0.022578
2021-12-17 17:39:24,208 iteration 4531 : loss : 0.057511, loss_ce: 0.021363
2021-12-17 17:39:25,627 iteration 4532 : loss : 0.059247, loss_ce: 0.021897
2021-12-17 17:39:27,075 iteration 4533 : loss : 0.065748, loss_ce: 0.021455
2021-12-17 17:39:28,563 iteration 4534 : loss : 0.081229, loss_ce: 0.022800
2021-12-17 17:39:29,878 iteration 4535 : loss : 0.062680, loss_ce: 0.017444
2021-12-17 17:39:31,283 iteration 4536 : loss : 0.062971, loss_ce: 0.023826
2021-12-17 17:39:32,723 iteration 4537 : loss : 0.077430, loss_ce: 0.021953
2021-12-17 17:39:34,072 iteration 4538 : loss : 0.056084, loss_ce: 0.015800
2021-12-17 17:39:35,467 iteration 4539 : loss : 0.076681, loss_ce: 0.024497
 67%|███████████████████▎         | 267/400 [1:54:54<57:21, 25.88s/it]2021-12-17 17:39:36,937 iteration 4540 : loss : 0.069101, loss_ce: 0.017504
2021-12-17 17:39:38,249 iteration 4541 : loss : 0.050384, loss_ce: 0.014769
2021-12-17 17:39:39,636 iteration 4542 : loss : 0.052013, loss_ce: 0.010830
2021-12-17 17:39:40,925 iteration 4543 : loss : 0.052749, loss_ce: 0.016386
2021-12-17 17:39:42,328 iteration 4544 : loss : 0.068609, loss_ce: 0.027180
2021-12-17 17:39:43,762 iteration 4545 : loss : 0.081839, loss_ce: 0.033671
2021-12-17 17:39:45,155 iteration 4546 : loss : 0.069815, loss_ce: 0.020662
2021-12-17 17:39:46,537 iteration 4547 : loss : 0.059437, loss_ce: 0.022728
2021-12-17 17:39:47,889 iteration 4548 : loss : 0.063204, loss_ce: 0.020678
2021-12-17 17:39:49,339 iteration 4549 : loss : 0.061086, loss_ce: 0.019967
2021-12-17 17:39:50,788 iteration 4550 : loss : 0.076387, loss_ce: 0.021816
2021-12-17 17:39:52,220 iteration 4551 : loss : 0.091704, loss_ce: 0.017080
2021-12-17 17:39:53,516 iteration 4552 : loss : 0.059150, loss_ce: 0.019768
2021-12-17 17:39:54,840 iteration 4553 : loss : 0.065380, loss_ce: 0.021442
2021-12-17 17:39:56,199 iteration 4554 : loss : 0.054200, loss_ce: 0.016885
2021-12-17 17:39:57,609 iteration 4555 : loss : 0.066277, loss_ce: 0.021393
2021-12-17 17:39:58,970 iteration 4556 : loss : 0.054822, loss_ce: 0.021356
 67%|███████████████████▍         | 268/400 [1:55:18<55:21, 25.17s/it]2021-12-17 17:40:00,420 iteration 4557 : loss : 0.082727, loss_ce: 0.031662
2021-12-17 17:40:01,854 iteration 4558 : loss : 0.072244, loss_ce: 0.028099
2021-12-17 17:40:03,212 iteration 4559 : loss : 0.070139, loss_ce: 0.019010
2021-12-17 17:40:04,552 iteration 4560 : loss : 0.053366, loss_ce: 0.013373
2021-12-17 17:40:05,921 iteration 4561 : loss : 0.068731, loss_ce: 0.016223
2021-12-17 17:40:07,294 iteration 4562 : loss : 0.063958, loss_ce: 0.018584
2021-12-17 17:40:08,617 iteration 4563 : loss : 0.060903, loss_ce: 0.020901
2021-12-17 17:40:09,990 iteration 4564 : loss : 0.059908, loss_ce: 0.017858
2021-12-17 17:40:11,329 iteration 4565 : loss : 0.066323, loss_ce: 0.023600
2021-12-17 17:40:12,649 iteration 4566 : loss : 0.054570, loss_ce: 0.019453
2021-12-17 17:40:14,031 iteration 4567 : loss : 0.074144, loss_ce: 0.030834
2021-12-17 17:40:15,393 iteration 4568 : loss : 0.053939, loss_ce: 0.014527
2021-12-17 17:40:16,757 iteration 4569 : loss : 0.053494, loss_ce: 0.017648
2021-12-17 17:40:18,073 iteration 4570 : loss : 0.054002, loss_ce: 0.019429
2021-12-17 17:40:19,417 iteration 4571 : loss : 0.053471, loss_ce: 0.020663
2021-12-17 17:40:20,776 iteration 4572 : loss : 0.058690, loss_ce: 0.018046
2021-12-17 17:40:22,143 iteration 4573 : loss : 0.062127, loss_ce: 0.023572
 67%|███████████████████▌         | 269/400 [1:55:41<53:38, 24.57s/it]2021-12-17 17:40:23,554 iteration 4574 : loss : 0.060779, loss_ce: 0.015521
2021-12-17 17:40:24,886 iteration 4575 : loss : 0.050820, loss_ce: 0.014962
2021-12-17 17:40:26,284 iteration 4576 : loss : 0.057092, loss_ce: 0.025175
2021-12-17 17:40:27,694 iteration 4577 : loss : 0.066059, loss_ce: 0.019694
2021-12-17 17:40:29,065 iteration 4578 : loss : 0.063833, loss_ce: 0.022678
2021-12-17 17:40:30,421 iteration 4579 : loss : 0.057610, loss_ce: 0.021519
2021-12-17 17:40:31,771 iteration 4580 : loss : 0.054003, loss_ce: 0.018958
2021-12-17 17:40:33,220 iteration 4581 : loss : 0.066351, loss_ce: 0.020808
2021-12-17 17:40:34,588 iteration 4582 : loss : 0.080613, loss_ce: 0.027128
2021-12-17 17:40:35,972 iteration 4583 : loss : 0.052113, loss_ce: 0.015487
2021-12-17 17:40:37,315 iteration 4584 : loss : 0.061546, loss_ce: 0.020547
2021-12-17 17:40:38,699 iteration 4585 : loss : 0.068694, loss_ce: 0.020734
2021-12-17 17:40:40,042 iteration 4586 : loss : 0.056898, loss_ce: 0.018608
2021-12-17 17:40:41,484 iteration 4587 : loss : 0.077218, loss_ce: 0.026411
2021-12-17 17:40:42,820 iteration 4588 : loss : 0.059467, loss_ce: 0.012649
2021-12-17 17:40:44,192 iteration 4589 : loss : 0.059922, loss_ce: 0.020746
2021-12-17 17:40:44,192 Training Data Eval:
2021-12-17 17:40:51,338   Average segmentation loss on training set: 0.0432
2021-12-17 17:40:51,338 Validation Data Eval:
2021-12-17 17:40:53,799   Average segmentation loss on validation set: 0.1332
2021-12-17 17:40:55,289 iteration 4590 : loss : 0.069947, loss_ce: 0.019925
 68%|███████████████████▌         | 270/400 [1:56:14<58:48, 27.14s/it]2021-12-17 17:40:56,664 iteration 4591 : loss : 0.049408, loss_ce: 0.012274
2021-12-17 17:40:58,036 iteration 4592 : loss : 0.064289, loss_ce: 0.019675
2021-12-17 17:40:59,330 iteration 4593 : loss : 0.055734, loss_ce: 0.014306
2021-12-17 17:41:00,678 iteration 4594 : loss : 0.060902, loss_ce: 0.021637
2021-12-17 17:41:02,070 iteration 4595 : loss : 0.072768, loss_ce: 0.015636
2021-12-17 17:41:03,515 iteration 4596 : loss : 0.084473, loss_ce: 0.025684
2021-12-17 17:41:04,880 iteration 4597 : loss : 0.057099, loss_ce: 0.021521
2021-12-17 17:41:06,172 iteration 4598 : loss : 0.059802, loss_ce: 0.020719
2021-12-17 17:41:07,511 iteration 4599 : loss : 0.067122, loss_ce: 0.016713
2021-12-17 17:41:08,940 iteration 4600 : loss : 0.062230, loss_ce: 0.025470
2021-12-17 17:41:10,390 iteration 4601 : loss : 0.069464, loss_ce: 0.030137
2021-12-17 17:41:11,672 iteration 4602 : loss : 0.050829, loss_ce: 0.015923
2021-12-17 17:41:12,996 iteration 4603 : loss : 0.050992, loss_ce: 0.017390
2021-12-17 17:41:14,394 iteration 4604 : loss : 0.067766, loss_ce: 0.020804
2021-12-17 17:41:15,774 iteration 4605 : loss : 0.059381, loss_ce: 0.013707
2021-12-17 17:41:17,190 iteration 4606 : loss : 0.061310, loss_ce: 0.016928
2021-12-17 17:41:18,495 iteration 4607 : loss : 0.051690, loss_ce: 0.021077
 68%|███████████████████▋         | 271/400 [1:56:37<55:49, 25.96s/it]2021-12-17 17:41:19,945 iteration 4608 : loss : 0.069435, loss_ce: 0.018950
2021-12-17 17:41:21,359 iteration 4609 : loss : 0.073909, loss_ce: 0.026894
2021-12-17 17:41:22,746 iteration 4610 : loss : 0.067150, loss_ce: 0.014950
2021-12-17 17:41:24,101 iteration 4611 : loss : 0.053766, loss_ce: 0.018549
2021-12-17 17:41:25,390 iteration 4612 : loss : 0.052144, loss_ce: 0.016526
2021-12-17 17:41:26,782 iteration 4613 : loss : 0.063662, loss_ce: 0.024851
2021-12-17 17:41:28,175 iteration 4614 : loss : 0.082257, loss_ce: 0.023941
2021-12-17 17:41:29,569 iteration 4615 : loss : 0.079879, loss_ce: 0.023225
2021-12-17 17:41:30,991 iteration 4616 : loss : 0.059196, loss_ce: 0.016777
2021-12-17 17:41:32,304 iteration 4617 : loss : 0.055175, loss_ce: 0.020098
2021-12-17 17:41:33,707 iteration 4618 : loss : 0.071536, loss_ce: 0.021430
2021-12-17 17:41:35,109 iteration 4619 : loss : 0.063047, loss_ce: 0.019047
2021-12-17 17:41:36,507 iteration 4620 : loss : 0.056885, loss_ce: 0.015512
2021-12-17 17:41:37,921 iteration 4621 : loss : 0.087307, loss_ce: 0.028970
2021-12-17 17:41:39,293 iteration 4622 : loss : 0.063822, loss_ce: 0.019682
2021-12-17 17:41:40,640 iteration 4623 : loss : 0.075793, loss_ce: 0.022604
2021-12-17 17:41:42,001 iteration 4624 : loss : 0.063602, loss_ce: 0.022681
 68%|███████████████████▋         | 272/400 [1:57:01<53:48, 25.22s/it]2021-12-17 17:41:43,412 iteration 4625 : loss : 0.050533, loss_ce: 0.018159
2021-12-17 17:41:44,755 iteration 4626 : loss : 0.051036, loss_ce: 0.013826
2021-12-17 17:41:46,115 iteration 4627 : loss : 0.052723, loss_ce: 0.014781
2021-12-17 17:41:47,446 iteration 4628 : loss : 0.056220, loss_ce: 0.017540
2021-12-17 17:41:48,776 iteration 4629 : loss : 0.063440, loss_ce: 0.023569
2021-12-17 17:41:50,130 iteration 4630 : loss : 0.062798, loss_ce: 0.017666
2021-12-17 17:41:51,565 iteration 4631 : loss : 0.060872, loss_ce: 0.017825
2021-12-17 17:41:52,939 iteration 4632 : loss : 0.045126, loss_ce: 0.012009
2021-12-17 17:41:54,308 iteration 4633 : loss : 0.065730, loss_ce: 0.022401
2021-12-17 17:41:55,596 iteration 4634 : loss : 0.046376, loss_ce: 0.016497
2021-12-17 17:41:56,984 iteration 4635 : loss : 0.053543, loss_ce: 0.014841
2021-12-17 17:41:58,344 iteration 4636 : loss : 0.058690, loss_ce: 0.017614
2021-12-17 17:41:59,710 iteration 4637 : loss : 0.054459, loss_ce: 0.016228
2021-12-17 17:42:01,110 iteration 4638 : loss : 0.070554, loss_ce: 0.030443
2021-12-17 17:42:02,548 iteration 4639 : loss : 0.068491, loss_ce: 0.020207
2021-12-17 17:42:03,937 iteration 4640 : loss : 0.066601, loss_ce: 0.023090
2021-12-17 17:42:05,279 iteration 4641 : loss : 0.048446, loss_ce: 0.015718
 68%|███████████████████▊         | 273/400 [1:57:24<52:09, 24.64s/it]2021-12-17 17:42:06,747 iteration 4642 : loss : 0.072790, loss_ce: 0.018270
2021-12-17 17:42:08,140 iteration 4643 : loss : 0.069357, loss_ce: 0.026410
2021-12-17 17:42:09,521 iteration 4644 : loss : 0.056663, loss_ce: 0.018873
2021-12-17 17:42:11,023 iteration 4645 : loss : 0.062734, loss_ce: 0.022804
2021-12-17 17:42:12,355 iteration 4646 : loss : 0.059179, loss_ce: 0.020263
2021-12-17 17:42:13,696 iteration 4647 : loss : 0.069706, loss_ce: 0.022550
2021-12-17 17:42:14,969 iteration 4648 : loss : 0.050524, loss_ce: 0.018075
2021-12-17 17:42:16,353 iteration 4649 : loss : 0.074958, loss_ce: 0.023696
2021-12-17 17:42:17,699 iteration 4650 : loss : 0.056439, loss_ce: 0.017936
2021-12-17 17:42:19,074 iteration 4651 : loss : 0.062799, loss_ce: 0.022484
2021-12-17 17:42:20,461 iteration 4652 : loss : 0.062635, loss_ce: 0.022746
2021-12-17 17:42:21,834 iteration 4653 : loss : 0.053333, loss_ce: 0.017691
2021-12-17 17:42:23,207 iteration 4654 : loss : 0.053424, loss_ce: 0.020279
2021-12-17 17:42:24,589 iteration 4655 : loss : 0.066204, loss_ce: 0.018904
2021-12-17 17:42:26,026 iteration 4656 : loss : 0.111010, loss_ce: 0.021372
2021-12-17 17:42:27,389 iteration 4657 : loss : 0.129472, loss_ce: 0.021438
2021-12-17 17:42:28,713 iteration 4658 : loss : 0.067643, loss_ce: 0.015712
 68%|███████████████████▊         | 274/400 [1:57:47<50:59, 24.28s/it]2021-12-17 17:42:30,125 iteration 4659 : loss : 0.060313, loss_ce: 0.018648
2021-12-17 17:42:31,528 iteration 4660 : loss : 0.053669, loss_ce: 0.011392
2021-12-17 17:42:32,905 iteration 4661 : loss : 0.070728, loss_ce: 0.032996
2021-12-17 17:42:34,374 iteration 4662 : loss : 0.078929, loss_ce: 0.035351
2021-12-17 17:42:35,691 iteration 4663 : loss : 0.059274, loss_ce: 0.015264
2021-12-17 17:42:37,064 iteration 4664 : loss : 0.064762, loss_ce: 0.017666
2021-12-17 17:42:38,559 iteration 4665 : loss : 0.087287, loss_ce: 0.024517
2021-12-17 17:42:39,866 iteration 4666 : loss : 0.052309, loss_ce: 0.017694
2021-12-17 17:42:41,209 iteration 4667 : loss : 0.065031, loss_ce: 0.022207
2021-12-17 17:42:42,566 iteration 4668 : loss : 0.067963, loss_ce: 0.015029
2021-12-17 17:42:43,991 iteration 4669 : loss : 0.055370, loss_ce: 0.018216
2021-12-17 17:42:45,420 iteration 4670 : loss : 0.058312, loss_ce: 0.020387
2021-12-17 17:42:46,724 iteration 4671 : loss : 0.064372, loss_ce: 0.021851
2021-12-17 17:42:48,210 iteration 4672 : loss : 0.074461, loss_ce: 0.027506
2021-12-17 17:42:49,614 iteration 4673 : loss : 0.068786, loss_ce: 0.022803
2021-12-17 17:42:51,043 iteration 4674 : loss : 0.066447, loss_ce: 0.027318
2021-12-17 17:42:51,043 Training Data Eval:
2021-12-17 17:42:58,124   Average segmentation loss on training set: 0.0415
2021-12-17 17:42:58,124 Validation Data Eval:
2021-12-17 17:43:00,622   Average segmentation loss on validation set: 0.1416
2021-12-17 17:43:01,993 iteration 4675 : loss : 0.058225, loss_ce: 0.019550
 69%|███████████████████▉         | 275/400 [1:58:21<56:12, 26.98s/it]2021-12-17 17:43:03,501 iteration 4676 : loss : 0.066375, loss_ce: 0.020606
2021-12-17 17:43:04,857 iteration 4677 : loss : 0.062404, loss_ce: 0.019776
2021-12-17 17:43:06,216 iteration 4678 : loss : 0.072031, loss_ce: 0.020616
2021-12-17 17:43:07,585 iteration 4679 : loss : 0.061573, loss_ce: 0.029231
2021-12-17 17:43:08,926 iteration 4680 : loss : 0.052764, loss_ce: 0.015136
2021-12-17 17:43:10,312 iteration 4681 : loss : 0.062021, loss_ce: 0.016407
2021-12-17 17:43:11,630 iteration 4682 : loss : 0.058455, loss_ce: 0.013909
2021-12-17 17:43:12,988 iteration 4683 : loss : 0.062153, loss_ce: 0.022339
2021-12-17 17:43:14,386 iteration 4684 : loss : 0.083580, loss_ce: 0.030290
2021-12-17 17:43:15,764 iteration 4685 : loss : 0.060481, loss_ce: 0.021906
2021-12-17 17:43:17,065 iteration 4686 : loss : 0.053932, loss_ce: 0.016253
2021-12-17 17:43:18,492 iteration 4687 : loss : 0.056978, loss_ce: 0.020766
2021-12-17 17:43:19,927 iteration 4688 : loss : 0.062498, loss_ce: 0.019287
2021-12-17 17:43:21,352 iteration 4689 : loss : 0.073602, loss_ce: 0.026427
2021-12-17 17:43:22,701 iteration 4690 : loss : 0.062543, loss_ce: 0.015001
2021-12-17 17:43:24,026 iteration 4691 : loss : 0.058464, loss_ce: 0.016948
2021-12-17 17:43:25,389 iteration 4692 : loss : 0.060655, loss_ce: 0.021381
 69%|████████████████████         | 276/400 [1:58:44<53:32, 25.91s/it]2021-12-17 17:43:26,849 iteration 4693 : loss : 0.075379, loss_ce: 0.028632
2021-12-17 17:43:28,186 iteration 4694 : loss : 0.058489, loss_ce: 0.015189
2021-12-17 17:43:29,599 iteration 4695 : loss : 0.066006, loss_ce: 0.020708
2021-12-17 17:43:30,976 iteration 4696 : loss : 0.066346, loss_ce: 0.024300
2021-12-17 17:43:32,390 iteration 4697 : loss : 0.068822, loss_ce: 0.024089
2021-12-17 17:43:33,668 iteration 4698 : loss : 0.070624, loss_ce: 0.023713
2021-12-17 17:43:35,026 iteration 4699 : loss : 0.088698, loss_ce: 0.026804
2021-12-17 17:43:36,407 iteration 4700 : loss : 0.072012, loss_ce: 0.019610
2021-12-17 17:43:37,782 iteration 4701 : loss : 0.062764, loss_ce: 0.022872
2021-12-17 17:43:39,080 iteration 4702 : loss : 0.051370, loss_ce: 0.015462
2021-12-17 17:43:40,482 iteration 4703 : loss : 0.080225, loss_ce: 0.026128
2021-12-17 17:43:41,844 iteration 4704 : loss : 0.057648, loss_ce: 0.012877
2021-12-17 17:43:43,155 iteration 4705 : loss : 0.051605, loss_ce: 0.015765
2021-12-17 17:43:44,481 iteration 4706 : loss : 0.064027, loss_ce: 0.025599
2021-12-17 17:43:45,910 iteration 4707 : loss : 0.070347, loss_ce: 0.025363
2021-12-17 17:43:47,273 iteration 4708 : loss : 0.104169, loss_ce: 0.020240
2021-12-17 17:43:48,617 iteration 4709 : loss : 0.065758, loss_ce: 0.021285
 69%|████████████████████         | 277/400 [1:59:07<51:27, 25.10s/it]2021-12-17 17:43:50,105 iteration 4710 : loss : 0.076690, loss_ce: 0.023428
2021-12-17 17:43:51,432 iteration 4711 : loss : 0.063445, loss_ce: 0.024609
2021-12-17 17:43:52,797 iteration 4712 : loss : 0.063084, loss_ce: 0.023475
2021-12-17 17:43:54,129 iteration 4713 : loss : 0.050861, loss_ce: 0.015474
2021-12-17 17:43:55,466 iteration 4714 : loss : 0.051407, loss_ce: 0.017325
2021-12-17 17:43:56,902 iteration 4715 : loss : 0.075843, loss_ce: 0.021765
2021-12-17 17:43:58,306 iteration 4716 : loss : 0.049462, loss_ce: 0.016074
2021-12-17 17:43:59,675 iteration 4717 : loss : 0.070180, loss_ce: 0.019660
2021-12-17 17:44:01,028 iteration 4718 : loss : 0.056290, loss_ce: 0.016741
2021-12-17 17:44:02,374 iteration 4719 : loss : 0.048796, loss_ce: 0.014990
2021-12-17 17:44:03,802 iteration 4720 : loss : 0.057625, loss_ce: 0.019846
2021-12-17 17:44:05,161 iteration 4721 : loss : 0.052057, loss_ce: 0.014103
2021-12-17 17:44:06,521 iteration 4722 : loss : 0.057826, loss_ce: 0.019202
2021-12-17 17:44:07,916 iteration 4723 : loss : 0.069348, loss_ce: 0.016221
2021-12-17 17:44:09,218 iteration 4724 : loss : 0.059692, loss_ce: 0.025202
2021-12-17 17:44:10,550 iteration 4725 : loss : 0.060577, loss_ce: 0.020817
2021-12-17 17:44:11,878 iteration 4726 : loss : 0.062518, loss_ce: 0.018241
 70%|████████████████████▏        | 278/400 [1:59:31<49:55, 24.55s/it]2021-12-17 17:44:13,309 iteration 4727 : loss : 0.063034, loss_ce: 0.018367
2021-12-17 17:44:14,704 iteration 4728 : loss : 0.071942, loss_ce: 0.025227
2021-12-17 17:44:16,099 iteration 4729 : loss : 0.050909, loss_ce: 0.014613
2021-12-17 17:44:17,476 iteration 4730 : loss : 0.068961, loss_ce: 0.022202
2021-12-17 17:44:18,838 iteration 4731 : loss : 0.067647, loss_ce: 0.015983
2021-12-17 17:44:20,140 iteration 4732 : loss : 0.059329, loss_ce: 0.019920
2021-12-17 17:44:21,587 iteration 4733 : loss : 0.093954, loss_ce: 0.041060
2021-12-17 17:44:22,948 iteration 4734 : loss : 0.074652, loss_ce: 0.027135
2021-12-17 17:44:24,254 iteration 4735 : loss : 0.052530, loss_ce: 0.017316
2021-12-17 17:44:25,664 iteration 4736 : loss : 0.076561, loss_ce: 0.029897
2021-12-17 17:44:27,043 iteration 4737 : loss : 0.068694, loss_ce: 0.021332
2021-12-17 17:44:28,523 iteration 4738 : loss : 0.065483, loss_ce: 0.017369
2021-12-17 17:44:29,920 iteration 4739 : loss : 0.051094, loss_ce: 0.015232
2021-12-17 17:44:31,307 iteration 4740 : loss : 0.055439, loss_ce: 0.013364
2021-12-17 17:44:32,684 iteration 4741 : loss : 0.054247, loss_ce: 0.020319
2021-12-17 17:44:34,078 iteration 4742 : loss : 0.062103, loss_ce: 0.021376
2021-12-17 17:44:35,597 iteration 4743 : loss : 0.076432, loss_ce: 0.028786
 70%|████████████████████▏        | 279/400 [1:59:54<49:00, 24.30s/it]2021-12-17 17:44:37,049 iteration 4744 : loss : 0.053144, loss_ce: 0.016016
2021-12-17 17:44:38,420 iteration 4745 : loss : 0.062038, loss_ce: 0.022268
2021-12-17 17:44:39,783 iteration 4746 : loss : 0.073507, loss_ce: 0.019098
2021-12-17 17:44:41,090 iteration 4747 : loss : 0.051469, loss_ce: 0.019565
2021-12-17 17:44:42,545 iteration 4748 : loss : 0.081881, loss_ce: 0.027014
2021-12-17 17:44:43,858 iteration 4749 : loss : 0.061540, loss_ce: 0.022677
2021-12-17 17:44:45,240 iteration 4750 : loss : 0.063708, loss_ce: 0.015237
2021-12-17 17:44:46,631 iteration 4751 : loss : 0.072724, loss_ce: 0.026161
2021-12-17 17:44:47,984 iteration 4752 : loss : 0.071155, loss_ce: 0.015789
2021-12-17 17:44:49,326 iteration 4753 : loss : 0.049182, loss_ce: 0.014764
2021-12-17 17:44:50,714 iteration 4754 : loss : 0.064597, loss_ce: 0.024786
2021-12-17 17:44:52,158 iteration 4755 : loss : 0.067092, loss_ce: 0.017076
2021-12-17 17:44:53,552 iteration 4756 : loss : 0.067003, loss_ce: 0.018839
2021-12-17 17:44:54,927 iteration 4757 : loss : 0.054499, loss_ce: 0.022529
2021-12-17 17:44:56,365 iteration 4758 : loss : 0.063485, loss_ce: 0.018658
2021-12-17 17:44:57,738 iteration 4759 : loss : 0.082889, loss_ce: 0.041100
2021-12-17 17:44:57,738 Training Data Eval:
2021-12-17 17:45:04,855   Average segmentation loss on training set: 0.0420
2021-12-17 17:45:04,855 Validation Data Eval:
2021-12-17 17:45:07,322   Average segmentation loss on validation set: 0.1323
2021-12-17 17:45:08,716 iteration 4760 : loss : 0.055038, loss_ce: 0.014358
 70%|████████████████████▎        | 280/400 [2:00:27<53:53, 26.95s/it]2021-12-17 17:45:10,087 iteration 4761 : loss : 0.058846, loss_ce: 0.019064
2021-12-17 17:45:11,529 iteration 4762 : loss : 0.068048, loss_ce: 0.018545
2021-12-17 17:45:12,916 iteration 4763 : loss : 0.066374, loss_ce: 0.025942
2021-12-17 17:45:14,241 iteration 4764 : loss : 0.052510, loss_ce: 0.016600
2021-12-17 17:45:15,590 iteration 4765 : loss : 0.060310, loss_ce: 0.022965
2021-12-17 17:45:16,929 iteration 4766 : loss : 0.059508, loss_ce: 0.017408
2021-12-17 17:45:18,343 iteration 4767 : loss : 0.059641, loss_ce: 0.018838
2021-12-17 17:45:19,800 iteration 4768 : loss : 0.069108, loss_ce: 0.027187
2021-12-17 17:45:21,234 iteration 4769 : loss : 0.078712, loss_ce: 0.019959
2021-12-17 17:45:22,602 iteration 4770 : loss : 0.056910, loss_ce: 0.024256
2021-12-17 17:45:23,938 iteration 4771 : loss : 0.054549, loss_ce: 0.017667
2021-12-17 17:45:25,288 iteration 4772 : loss : 0.047644, loss_ce: 0.012449
2021-12-17 17:45:26,633 iteration 4773 : loss : 0.051184, loss_ce: 0.016526
2021-12-17 17:45:27,981 iteration 4774 : loss : 0.055098, loss_ce: 0.017398
2021-12-17 17:45:29,357 iteration 4775 : loss : 0.063426, loss_ce: 0.020101
2021-12-17 17:45:30,717 iteration 4776 : loss : 0.053723, loss_ce: 0.015715
2021-12-17 17:45:32,070 iteration 4777 : loss : 0.060634, loss_ce: 0.018975
 70%|████████████████████▎        | 281/400 [2:00:51<51:18, 25.87s/it]2021-12-17 17:45:33,548 iteration 4778 : loss : 0.056297, loss_ce: 0.016529
2021-12-17 17:45:34,870 iteration 4779 : loss : 0.054749, loss_ce: 0.016826
2021-12-17 17:45:36,205 iteration 4780 : loss : 0.081241, loss_ce: 0.025705
2021-12-17 17:45:37,549 iteration 4781 : loss : 0.048427, loss_ce: 0.018675
2021-12-17 17:45:38,966 iteration 4782 : loss : 0.060607, loss_ce: 0.019668
2021-12-17 17:45:40,317 iteration 4783 : loss : 0.051356, loss_ce: 0.012736
2021-12-17 17:45:41,732 iteration 4784 : loss : 0.055695, loss_ce: 0.016911
2021-12-17 17:45:43,177 iteration 4785 : loss : 0.070741, loss_ce: 0.029906
2021-12-17 17:45:44,542 iteration 4786 : loss : 0.049842, loss_ce: 0.015914
2021-12-17 17:45:45,935 iteration 4787 : loss : 0.055947, loss_ce: 0.010681
2021-12-17 17:45:47,304 iteration 4788 : loss : 0.056091, loss_ce: 0.018428
2021-12-17 17:45:48,676 iteration 4789 : loss : 0.060347, loss_ce: 0.017650
2021-12-17 17:45:50,032 iteration 4790 : loss : 0.057089, loss_ce: 0.019780
2021-12-17 17:45:51,372 iteration 4791 : loss : 0.047476, loss_ce: 0.015400
2021-12-17 17:45:52,727 iteration 4792 : loss : 0.070690, loss_ce: 0.026995
2021-12-17 17:45:54,125 iteration 4793 : loss : 0.066590, loss_ce: 0.027471
2021-12-17 17:45:55,471 iteration 4794 : loss : 0.098906, loss_ce: 0.013830
 70%|████████████████████▍        | 282/400 [2:01:14<49:24, 25.13s/it]2021-12-17 17:45:56,819 iteration 4795 : loss : 0.048268, loss_ce: 0.013058
2021-12-17 17:45:58,131 iteration 4796 : loss : 0.061468, loss_ce: 0.022048
2021-12-17 17:45:59,460 iteration 4797 : loss : 0.059475, loss_ce: 0.019283
2021-12-17 17:46:00,909 iteration 4798 : loss : 0.081942, loss_ce: 0.027844
2021-12-17 17:46:02,274 iteration 4799 : loss : 0.070643, loss_ce: 0.016993
2021-12-17 17:46:03,649 iteration 4800 : loss : 0.084511, loss_ce: 0.028239
2021-12-17 17:46:05,016 iteration 4801 : loss : 0.053158, loss_ce: 0.014572
2021-12-17 17:46:06,296 iteration 4802 : loss : 0.046198, loss_ce: 0.012818
2021-12-17 17:46:07,665 iteration 4803 : loss : 0.055646, loss_ce: 0.020339
2021-12-17 17:46:09,011 iteration 4804 : loss : 0.061594, loss_ce: 0.014043
2021-12-17 17:46:10,411 iteration 4805 : loss : 0.056179, loss_ce: 0.018681
2021-12-17 17:46:11,742 iteration 4806 : loss : 0.063924, loss_ce: 0.015718
2021-12-17 17:46:13,184 iteration 4807 : loss : 0.087839, loss_ce: 0.030508
2021-12-17 17:46:14,730 iteration 4808 : loss : 0.068859, loss_ce: 0.025847
2021-12-17 17:46:16,007 iteration 4809 : loss : 0.055975, loss_ce: 0.020186
2021-12-17 17:46:17,415 iteration 4810 : loss : 0.065326, loss_ce: 0.020936
2021-12-17 17:46:18,762 iteration 4811 : loss : 0.055629, loss_ce: 0.017637
 71%|████████████████████▌        | 283/400 [2:01:37<47:55, 24.58s/it]2021-12-17 17:46:20,141 iteration 4812 : loss : 0.061908, loss_ce: 0.019279
2021-12-17 17:46:21,518 iteration 4813 : loss : 0.064997, loss_ce: 0.022274
2021-12-17 17:46:22,832 iteration 4814 : loss : 0.051932, loss_ce: 0.018528
2021-12-17 17:46:24,196 iteration 4815 : loss : 0.053698, loss_ce: 0.016926
2021-12-17 17:46:25,527 iteration 4816 : loss : 0.055123, loss_ce: 0.016711
2021-12-17 17:46:26,790 iteration 4817 : loss : 0.054740, loss_ce: 0.017156
2021-12-17 17:46:28,204 iteration 4818 : loss : 0.077405, loss_ce: 0.027724
2021-12-17 17:46:29,595 iteration 4819 : loss : 0.065070, loss_ce: 0.018712
2021-12-17 17:46:31,012 iteration 4820 : loss : 0.058829, loss_ce: 0.020313
2021-12-17 17:46:32,362 iteration 4821 : loss : 0.051430, loss_ce: 0.018503
2021-12-17 17:46:33,746 iteration 4822 : loss : 0.071550, loss_ce: 0.020979
2021-12-17 17:46:35,075 iteration 4823 : loss : 0.066283, loss_ce: 0.022273
2021-12-17 17:46:36,487 iteration 4824 : loss : 0.055548, loss_ce: 0.016673
2021-12-17 17:46:37,843 iteration 4825 : loss : 0.046394, loss_ce: 0.012155
2021-12-17 17:46:39,180 iteration 4826 : loss : 0.059296, loss_ce: 0.017050
2021-12-17 17:46:40,648 iteration 4827 : loss : 0.061620, loss_ce: 0.016531
2021-12-17 17:46:42,083 iteration 4828 : loss : 0.067420, loss_ce: 0.024973
 71%|████████████████████▌        | 284/400 [2:02:01<46:47, 24.20s/it]2021-12-17 17:46:43,528 iteration 4829 : loss : 0.065093, loss_ce: 0.019764
2021-12-17 17:46:44,835 iteration 4830 : loss : 0.056841, loss_ce: 0.014895
2021-12-17 17:46:46,276 iteration 4831 : loss : 0.084082, loss_ce: 0.024180
2021-12-17 17:46:47,626 iteration 4832 : loss : 0.059976, loss_ce: 0.018768
2021-12-17 17:46:49,045 iteration 4833 : loss : 0.072326, loss_ce: 0.021865
2021-12-17 17:46:50,495 iteration 4834 : loss : 0.058783, loss_ce: 0.016808
2021-12-17 17:46:51,843 iteration 4835 : loss : 0.061135, loss_ce: 0.019501
2021-12-17 17:46:53,213 iteration 4836 : loss : 0.063124, loss_ce: 0.018232
2021-12-17 17:46:54,532 iteration 4837 : loss : 0.055875, loss_ce: 0.011324
2021-12-17 17:46:55,927 iteration 4838 : loss : 0.064080, loss_ce: 0.024729
2021-12-17 17:46:57,327 iteration 4839 : loss : 0.072570, loss_ce: 0.030499
2021-12-17 17:46:58,707 iteration 4840 : loss : 0.071133, loss_ce: 0.023628
2021-12-17 17:47:00,142 iteration 4841 : loss : 0.051984, loss_ce: 0.015031
2021-12-17 17:47:01,562 iteration 4842 : loss : 0.057655, loss_ce: 0.020083
2021-12-17 17:47:02,930 iteration 4843 : loss : 0.061461, loss_ce: 0.019899
2021-12-17 17:47:04,239 iteration 4844 : loss : 0.061328, loss_ce: 0.023405
2021-12-17 17:47:04,239 Training Data Eval:
2021-12-17 17:47:11,259   Average segmentation loss on training set: 0.0410
2021-12-17 17:47:11,259 Validation Data Eval:
2021-12-17 17:47:13,750   Average segmentation loss on validation set: 0.1387
2021-12-17 17:47:15,112 iteration 4845 : loss : 0.059938, loss_ce: 0.016458
 71%|████████████████████▋        | 285/400 [2:02:34<51:27, 26.85s/it]2021-12-17 17:47:16,567 iteration 4846 : loss : 0.071483, loss_ce: 0.021116
2021-12-17 17:47:17,913 iteration 4847 : loss : 0.057882, loss_ce: 0.014801
2021-12-17 17:47:19,376 iteration 4848 : loss : 0.065019, loss_ce: 0.023601
2021-12-17 17:47:20,731 iteration 4849 : loss : 0.055576, loss_ce: 0.020770
2021-12-17 17:47:22,122 iteration 4850 : loss : 0.116932, loss_ce: 0.022323
2021-12-17 17:47:23,498 iteration 4851 : loss : 0.059421, loss_ce: 0.022366
2021-12-17 17:47:24,830 iteration 4852 : loss : 0.056377, loss_ce: 0.017663
2021-12-17 17:47:26,172 iteration 4853 : loss : 0.051012, loss_ce: 0.015440
2021-12-17 17:47:27,477 iteration 4854 : loss : 0.048689, loss_ce: 0.014913
2021-12-17 17:47:28,867 iteration 4855 : loss : 0.055255, loss_ce: 0.016663
2021-12-17 17:47:30,267 iteration 4856 : loss : 0.057821, loss_ce: 0.018704
2021-12-17 17:47:31,679 iteration 4857 : loss : 0.067798, loss_ce: 0.032351
2021-12-17 17:47:33,048 iteration 4858 : loss : 0.060941, loss_ce: 0.019336
2021-12-17 17:47:34,361 iteration 4859 : loss : 0.049783, loss_ce: 0.014256
2021-12-17 17:47:35,702 iteration 4860 : loss : 0.070463, loss_ce: 0.018578
2021-12-17 17:47:37,003 iteration 4861 : loss : 0.057265, loss_ce: 0.015175
2021-12-17 17:47:38,502 iteration 4862 : loss : 0.063305, loss_ce: 0.017550
 72%|████████████████████▋        | 286/400 [2:02:57<49:02, 25.81s/it]2021-12-17 17:47:39,942 iteration 4863 : loss : 0.062017, loss_ce: 0.018778
2021-12-17 17:47:41,328 iteration 4864 : loss : 0.062377, loss_ce: 0.015968
2021-12-17 17:47:42,700 iteration 4865 : loss : 0.070073, loss_ce: 0.023036
2021-12-17 17:47:44,063 iteration 4866 : loss : 0.063196, loss_ce: 0.023757
2021-12-17 17:47:45,465 iteration 4867 : loss : 0.098272, loss_ce: 0.023171
2021-12-17 17:47:46,854 iteration 4868 : loss : 0.063984, loss_ce: 0.026074
2021-12-17 17:47:48,188 iteration 4869 : loss : 0.053575, loss_ce: 0.016545
2021-12-17 17:47:49,467 iteration 4870 : loss : 0.050511, loss_ce: 0.016477
2021-12-17 17:47:50,804 iteration 4871 : loss : 0.063370, loss_ce: 0.020155
2021-12-17 17:47:52,172 iteration 4872 : loss : 0.055360, loss_ce: 0.022055
2021-12-17 17:47:53,532 iteration 4873 : loss : 0.052670, loss_ce: 0.014746
2021-12-17 17:47:54,902 iteration 4874 : loss : 0.053782, loss_ce: 0.016954
2021-12-17 17:47:56,227 iteration 4875 : loss : 0.052778, loss_ce: 0.013428
2021-12-17 17:47:57,509 iteration 4876 : loss : 0.054561, loss_ce: 0.019565
2021-12-17 17:47:58,847 iteration 4877 : loss : 0.044323, loss_ce: 0.012548
2021-12-17 17:48:00,220 iteration 4878 : loss : 0.070438, loss_ce: 0.023681
2021-12-17 17:48:01,634 iteration 4879 : loss : 0.052986, loss_ce: 0.014337
 72%|████████████████████▊        | 287/400 [2:03:20<47:05, 25.01s/it]2021-12-17 17:48:03,077 iteration 4880 : loss : 0.054460, loss_ce: 0.015915
2021-12-17 17:48:04,379 iteration 4881 : loss : 0.066688, loss_ce: 0.020272
2021-12-17 17:48:05,689 iteration 4882 : loss : 0.062614, loss_ce: 0.015776
2021-12-17 17:48:07,072 iteration 4883 : loss : 0.075921, loss_ce: 0.025750
2021-12-17 17:48:08,394 iteration 4884 : loss : 0.064792, loss_ce: 0.023399
2021-12-17 17:48:09,761 iteration 4885 : loss : 0.054428, loss_ce: 0.013713
2021-12-17 17:48:11,146 iteration 4886 : loss : 0.061949, loss_ce: 0.018620
2021-12-17 17:48:12,490 iteration 4887 : loss : 0.067729, loss_ce: 0.022706
2021-12-17 17:48:13,874 iteration 4888 : loss : 0.054064, loss_ce: 0.013057
2021-12-17 17:48:15,216 iteration 4889 : loss : 0.062559, loss_ce: 0.024340
2021-12-17 17:48:16,588 iteration 4890 : loss : 0.072266, loss_ce: 0.025282
2021-12-17 17:48:17,961 iteration 4891 : loss : 0.061316, loss_ce: 0.025431
2021-12-17 17:48:19,351 iteration 4892 : loss : 0.053228, loss_ce: 0.020175
2021-12-17 17:48:20,859 iteration 4893 : loss : 0.065967, loss_ce: 0.022417
2021-12-17 17:48:22,219 iteration 4894 : loss : 0.065082, loss_ce: 0.027100
2021-12-17 17:48:23,564 iteration 4895 : loss : 0.056598, loss_ce: 0.019504
2021-12-17 17:48:24,897 iteration 4896 : loss : 0.059089, loss_ce: 0.018643
 72%|████████████████████▉        | 288/400 [2:03:44<45:42, 24.48s/it]2021-12-17 17:48:26,242 iteration 4897 : loss : 0.047686, loss_ce: 0.016286
2021-12-17 17:48:27,586 iteration 4898 : loss : 0.049415, loss_ce: 0.014012
2021-12-17 17:48:28,906 iteration 4899 : loss : 0.059168, loss_ce: 0.023006
2021-12-17 17:48:30,328 iteration 4900 : loss : 0.091827, loss_ce: 0.030930
2021-12-17 17:48:31,705 iteration 4901 : loss : 0.075400, loss_ce: 0.020436
2021-12-17 17:48:33,030 iteration 4902 : loss : 0.052119, loss_ce: 0.011256
2021-12-17 17:48:34,410 iteration 4903 : loss : 0.051587, loss_ce: 0.015852
2021-12-17 17:48:35,767 iteration 4904 : loss : 0.059767, loss_ce: 0.023573
2021-12-17 17:48:37,111 iteration 4905 : loss : 0.051913, loss_ce: 0.018765
2021-12-17 17:48:38,453 iteration 4906 : loss : 0.051384, loss_ce: 0.015589
2021-12-17 17:48:39,817 iteration 4907 : loss : 0.057978, loss_ce: 0.017431
2021-12-17 17:48:41,087 iteration 4908 : loss : 0.051601, loss_ce: 0.013193
2021-12-17 17:48:42,440 iteration 4909 : loss : 0.058775, loss_ce: 0.015541
2021-12-17 17:48:43,776 iteration 4910 : loss : 0.060276, loss_ce: 0.011834
2021-12-17 17:48:45,215 iteration 4911 : loss : 0.059754, loss_ce: 0.023335
2021-12-17 17:48:46,628 iteration 4912 : loss : 0.067316, loss_ce: 0.017590
2021-12-17 17:48:47,954 iteration 4913 : loss : 0.052962, loss_ce: 0.014594
 72%|████████████████████▉        | 289/400 [2:04:07<44:30, 24.05s/it]2021-12-17 17:48:49,311 iteration 4914 : loss : 0.048099, loss_ce: 0.013019
2021-12-17 17:48:50,702 iteration 4915 : loss : 0.060756, loss_ce: 0.019855
2021-12-17 17:48:52,084 iteration 4916 : loss : 0.068963, loss_ce: 0.019877
2021-12-17 17:48:53,452 iteration 4917 : loss : 0.057255, loss_ce: 0.017461
2021-12-17 17:48:54,779 iteration 4918 : loss : 0.050646, loss_ce: 0.019176
2021-12-17 17:48:56,107 iteration 4919 : loss : 0.060848, loss_ce: 0.019615
2021-12-17 17:48:57,493 iteration 4920 : loss : 0.067625, loss_ce: 0.030365
2021-12-17 17:48:58,834 iteration 4921 : loss : 0.055183, loss_ce: 0.012291
2021-12-17 17:49:00,189 iteration 4922 : loss : 0.083399, loss_ce: 0.016233
2021-12-17 17:49:01,553 iteration 4923 : loss : 0.064061, loss_ce: 0.021814
2021-12-17 17:49:02,928 iteration 4924 : loss : 0.065240, loss_ce: 0.019229
2021-12-17 17:49:04,405 iteration 4925 : loss : 0.075581, loss_ce: 0.024817
2021-12-17 17:49:05,745 iteration 4926 : loss : 0.065882, loss_ce: 0.021663
2021-12-17 17:49:07,161 iteration 4927 : loss : 0.051669, loss_ce: 0.016645
2021-12-17 17:49:08,585 iteration 4928 : loss : 0.069217, loss_ce: 0.027985
2021-12-17 17:49:09,996 iteration 4929 : loss : 0.066780, loss_ce: 0.019328
2021-12-17 17:49:09,996 Training Data Eval:
2021-12-17 17:49:17,059   Average segmentation loss on training set: 0.0407
2021-12-17 17:49:17,059 Validation Data Eval:
2021-12-17 17:49:19,565   Average segmentation loss on validation set: 0.1374
2021-12-17 17:49:20,962 iteration 4930 : loss : 0.059603, loss_ce: 0.023707
 72%|█████████████████████        | 290/400 [2:04:40<49:01, 26.74s/it]2021-12-17 17:49:22,430 iteration 4931 : loss : 0.066603, loss_ce: 0.025190
2021-12-17 17:49:23,768 iteration 4932 : loss : 0.052033, loss_ce: 0.016347
2021-12-17 17:49:25,089 iteration 4933 : loss : 0.060468, loss_ce: 0.018515
2021-12-17 17:49:26,465 iteration 4934 : loss : 0.061209, loss_ce: 0.024754
2021-12-17 17:49:27,865 iteration 4935 : loss : 0.065654, loss_ce: 0.018642
2021-12-17 17:49:29,235 iteration 4936 : loss : 0.045903, loss_ce: 0.014232
2021-12-17 17:49:30,620 iteration 4937 : loss : 0.058136, loss_ce: 0.015465
2021-12-17 17:49:31,978 iteration 4938 : loss : 0.061081, loss_ce: 0.017163
2021-12-17 17:49:33,385 iteration 4939 : loss : 0.061620, loss_ce: 0.021543
2021-12-17 17:49:34,702 iteration 4940 : loss : 0.061836, loss_ce: 0.016349
2021-12-17 17:49:36,068 iteration 4941 : loss : 0.054099, loss_ce: 0.017725
2021-12-17 17:49:37,486 iteration 4942 : loss : 0.058167, loss_ce: 0.018238
2021-12-17 17:49:38,822 iteration 4943 : loss : 0.047142, loss_ce: 0.013305
2021-12-17 17:49:40,185 iteration 4944 : loss : 0.057030, loss_ce: 0.019870
2021-12-17 17:49:41,623 iteration 4945 : loss : 0.057671, loss_ce: 0.016890
2021-12-17 17:49:43,035 iteration 4946 : loss : 0.075195, loss_ce: 0.031266
2021-12-17 17:49:44,480 iteration 4947 : loss : 0.059869, loss_ce: 0.018868
 73%|█████████████████████        | 291/400 [2:05:03<46:49, 25.77s/it]2021-12-17 17:49:45,943 iteration 4948 : loss : 0.070769, loss_ce: 0.022925
2021-12-17 17:49:47,282 iteration 4949 : loss : 0.048745, loss_ce: 0.016329
2021-12-17 17:49:48,597 iteration 4950 : loss : 0.055295, loss_ce: 0.015706
2021-12-17 17:49:49,947 iteration 4951 : loss : 0.062616, loss_ce: 0.018817
2021-12-17 17:49:51,239 iteration 4952 : loss : 0.058478, loss_ce: 0.018322
2021-12-17 17:49:52,649 iteration 4953 : loss : 0.050236, loss_ce: 0.015883
2021-12-17 17:49:53,966 iteration 4954 : loss : 0.058606, loss_ce: 0.017046
2021-12-17 17:49:55,305 iteration 4955 : loss : 0.045896, loss_ce: 0.014590
2021-12-17 17:49:56,639 iteration 4956 : loss : 0.063943, loss_ce: 0.018686
2021-12-17 17:49:57,990 iteration 4957 : loss : 0.054971, loss_ce: 0.019297
2021-12-17 17:49:59,369 iteration 4958 : loss : 0.054350, loss_ce: 0.018127
2021-12-17 17:50:00,661 iteration 4959 : loss : 0.048023, loss_ce: 0.012627
2021-12-17 17:50:02,048 iteration 4960 : loss : 0.058043, loss_ce: 0.016484
2021-12-17 17:50:03,363 iteration 4961 : loss : 0.053637, loss_ce: 0.018347
2021-12-17 17:50:04,765 iteration 4962 : loss : 0.060930, loss_ce: 0.020076
2021-12-17 17:50:06,087 iteration 4963 : loss : 0.054387, loss_ce: 0.019074
2021-12-17 17:50:07,522 iteration 4964 : loss : 0.068131, loss_ce: 0.017622
 73%|█████████████████████▏       | 292/400 [2:05:26<44:54, 24.95s/it]2021-12-17 17:50:08,997 iteration 4965 : loss : 0.059483, loss_ce: 0.017284
2021-12-17 17:50:10,460 iteration 4966 : loss : 0.064804, loss_ce: 0.018724
2021-12-17 17:50:11,766 iteration 4967 : loss : 0.048147, loss_ce: 0.016845
2021-12-17 17:50:13,134 iteration 4968 : loss : 0.061120, loss_ce: 0.021084
2021-12-17 17:50:14,477 iteration 4969 : loss : 0.051702, loss_ce: 0.012202
2021-12-17 17:50:15,808 iteration 4970 : loss : 0.046229, loss_ce: 0.012680
2021-12-17 17:50:17,214 iteration 4971 : loss : 0.054660, loss_ce: 0.018467
2021-12-17 17:50:18,630 iteration 4972 : loss : 0.057200, loss_ce: 0.016351
2021-12-17 17:50:19,951 iteration 4973 : loss : 0.049691, loss_ce: 0.016130
2021-12-17 17:50:21,277 iteration 4974 : loss : 0.059822, loss_ce: 0.020269
2021-12-17 17:50:22,612 iteration 4975 : loss : 0.065624, loss_ce: 0.020010
2021-12-17 17:50:23,958 iteration 4976 : loss : 0.067939, loss_ce: 0.023587
2021-12-17 17:50:25,397 iteration 4977 : loss : 0.070494, loss_ce: 0.027931
2021-12-17 17:50:26,748 iteration 4978 : loss : 0.076879, loss_ce: 0.019963
2021-12-17 17:50:28,117 iteration 4979 : loss : 0.063169, loss_ce: 0.027364
2021-12-17 17:50:29,402 iteration 4980 : loss : 0.044888, loss_ce: 0.013847
2021-12-17 17:50:30,770 iteration 4981 : loss : 0.066735, loss_ce: 0.016902
 73%|█████████████████████▏       | 293/400 [2:05:49<43:35, 24.44s/it]2021-12-17 17:50:32,187 iteration 4982 : loss : 0.057167, loss_ce: 0.019831
2021-12-17 17:50:33,514 iteration 4983 : loss : 0.048959, loss_ce: 0.014794
2021-12-17 17:50:34,927 iteration 4984 : loss : 0.066004, loss_ce: 0.024308
2021-12-17 17:50:36,297 iteration 4985 : loss : 0.054150, loss_ce: 0.015949
2021-12-17 17:50:37,739 iteration 4986 : loss : 0.056820, loss_ce: 0.020190
2021-12-17 17:50:39,086 iteration 4987 : loss : 0.057850, loss_ce: 0.024948
2021-12-17 17:50:40,440 iteration 4988 : loss : 0.058657, loss_ce: 0.020905
2021-12-17 17:50:41,793 iteration 4989 : loss : 0.058104, loss_ce: 0.019206
2021-12-17 17:50:43,234 iteration 4990 : loss : 0.082895, loss_ce: 0.021586
2021-12-17 17:50:44,599 iteration 4991 : loss : 0.053254, loss_ce: 0.012990
2021-12-17 17:50:45,958 iteration 4992 : loss : 0.059875, loss_ce: 0.023538
2021-12-17 17:50:47,373 iteration 4993 : loss : 0.051950, loss_ce: 0.018979
2021-12-17 17:50:48,815 iteration 4994 : loss : 0.066971, loss_ce: 0.016236
2021-12-17 17:50:50,177 iteration 4995 : loss : 0.061530, loss_ce: 0.018354
2021-12-17 17:50:51,529 iteration 4996 : loss : 0.069080, loss_ce: 0.025090
2021-12-17 17:50:52,959 iteration 4997 : loss : 0.060456, loss_ce: 0.022886
2021-12-17 17:50:54,281 iteration 4998 : loss : 0.053189, loss_ce: 0.016488
 74%|█████████████████████▎       | 294/400 [2:06:13<42:41, 24.17s/it]2021-12-17 17:50:55,732 iteration 4999 : loss : 0.063188, loss_ce: 0.021475
2021-12-17 17:50:57,028 iteration 5000 : loss : 0.056872, loss_ce: 0.017467
2021-12-17 17:50:58,368 iteration 5001 : loss : 0.070992, loss_ce: 0.019276
2021-12-17 17:50:59,773 iteration 5002 : loss : 0.065877, loss_ce: 0.025308
2021-12-17 17:51:01,114 iteration 5003 : loss : 0.066864, loss_ce: 0.015316
2021-12-17 17:51:02,545 iteration 5004 : loss : 0.061741, loss_ce: 0.018702
2021-12-17 17:51:03,883 iteration 5005 : loss : 0.060743, loss_ce: 0.017280
2021-12-17 17:51:05,276 iteration 5006 : loss : 0.060999, loss_ce: 0.014408
2021-12-17 17:51:06,608 iteration 5007 : loss : 0.049934, loss_ce: 0.016451
2021-12-17 17:51:07,910 iteration 5008 : loss : 0.048774, loss_ce: 0.014474
2021-12-17 17:51:09,269 iteration 5009 : loss : 0.065312, loss_ce: 0.020064
2021-12-17 17:51:10,721 iteration 5010 : loss : 0.104497, loss_ce: 0.034861
2021-12-17 17:51:12,099 iteration 5011 : loss : 0.068902, loss_ce: 0.034892
2021-12-17 17:51:13,524 iteration 5012 : loss : 0.068059, loss_ce: 0.023252
2021-12-17 17:51:15,036 iteration 5013 : loss : 0.059034, loss_ce: 0.019353
2021-12-17 17:51:16,310 iteration 5014 : loss : 0.049858, loss_ce: 0.014012
2021-12-17 17:51:16,310 Training Data Eval:
2021-12-17 17:51:23,382   Average segmentation loss on training set: 0.0403
2021-12-17 17:51:23,382 Validation Data Eval:
2021-12-17 17:51:25,850   Average segmentation loss on validation set: 0.1319
2021-12-17 17:51:27,222 iteration 5015 : loss : 0.043940, loss_ce: 0.008826
 74%|█████████████████████▍       | 295/400 [2:06:46<46:53, 26.79s/it]2021-12-17 17:51:28,603 iteration 5016 : loss : 0.075591, loss_ce: 0.025544
2021-12-17 17:51:29,945 iteration 5017 : loss : 0.053520, loss_ce: 0.014327
2021-12-17 17:51:31,452 iteration 5018 : loss : 0.081636, loss_ce: 0.028171
2021-12-17 17:51:32,774 iteration 5019 : loss : 0.052284, loss_ce: 0.011748
2021-12-17 17:51:34,166 iteration 5020 : loss : 0.061200, loss_ce: 0.019824
2021-12-17 17:51:35,605 iteration 5021 : loss : 0.063969, loss_ce: 0.017794
2021-12-17 17:51:37,030 iteration 5022 : loss : 0.070527, loss_ce: 0.028615
2021-12-17 17:51:38,419 iteration 5023 : loss : 0.055913, loss_ce: 0.020170
2021-12-17 17:51:39,757 iteration 5024 : loss : 0.047906, loss_ce: 0.015177
2021-12-17 17:51:41,075 iteration 5025 : loss : 0.048960, loss_ce: 0.015868
2021-12-17 17:51:42,442 iteration 5026 : loss : 0.067516, loss_ce: 0.022710
2021-12-17 17:51:43,813 iteration 5027 : loss : 0.044146, loss_ce: 0.011435
2021-12-17 17:51:45,192 iteration 5028 : loss : 0.069920, loss_ce: 0.021724
2021-12-17 17:51:46,522 iteration 5029 : loss : 0.049977, loss_ce: 0.016814
2021-12-17 17:51:47,909 iteration 5030 : loss : 0.063739, loss_ce: 0.019854
2021-12-17 17:51:49,333 iteration 5031 : loss : 0.064846, loss_ce: 0.022848
2021-12-17 17:51:50,759 iteration 5032 : loss : 0.066335, loss_ce: 0.019028
 74%|█████████████████████▍       | 296/400 [2:07:09<44:45, 25.82s/it]2021-12-17 17:51:52,174 iteration 5033 : loss : 0.070503, loss_ce: 0.030912
2021-12-17 17:51:53,518 iteration 5034 : loss : 0.059911, loss_ce: 0.014028
2021-12-17 17:51:54,856 iteration 5035 : loss : 0.055157, loss_ce: 0.017034
2021-12-17 17:51:56,157 iteration 5036 : loss : 0.046298, loss_ce: 0.014556
2021-12-17 17:51:57,505 iteration 5037 : loss : 0.048712, loss_ce: 0.015032
2021-12-17 17:51:58,997 iteration 5038 : loss : 0.060277, loss_ce: 0.024447
2021-12-17 17:52:00,335 iteration 5039 : loss : 0.056416, loss_ce: 0.015872
2021-12-17 17:52:01,726 iteration 5040 : loss : 0.070135, loss_ce: 0.026812
2021-12-17 17:52:03,091 iteration 5041 : loss : 0.057396, loss_ce: 0.017424
2021-12-17 17:52:04,452 iteration 5042 : loss : 0.047002, loss_ce: 0.014937
2021-12-17 17:52:05,784 iteration 5043 : loss : 0.056749, loss_ce: 0.016435
2021-12-17 17:52:07,160 iteration 5044 : loss : 0.047617, loss_ce: 0.012609
2021-12-17 17:52:08,444 iteration 5045 : loss : 0.048888, loss_ce: 0.013475
2021-12-17 17:52:09,820 iteration 5046 : loss : 0.057477, loss_ce: 0.016021
2021-12-17 17:52:11,144 iteration 5047 : loss : 0.052025, loss_ce: 0.016823
2021-12-17 17:52:12,456 iteration 5048 : loss : 0.047012, loss_ce: 0.014865
2021-12-17 17:52:13,891 iteration 5049 : loss : 0.064120, loss_ce: 0.024517
 74%|█████████████████████▌       | 297/400 [2:07:33<42:56, 25.01s/it]2021-12-17 17:52:15,309 iteration 5050 : loss : 0.058515, loss_ce: 0.015158
2021-12-17 17:52:16,617 iteration 5051 : loss : 0.054006, loss_ce: 0.019341
2021-12-17 17:52:18,012 iteration 5052 : loss : 0.056073, loss_ce: 0.023065
2021-12-17 17:52:19,313 iteration 5053 : loss : 0.051275, loss_ce: 0.014946
2021-12-17 17:52:20,700 iteration 5054 : loss : 0.061563, loss_ce: 0.021463
2021-12-17 17:52:22,039 iteration 5055 : loss : 0.063047, loss_ce: 0.021639
2021-12-17 17:52:23,390 iteration 5056 : loss : 0.060657, loss_ce: 0.016790
2021-12-17 17:52:24,750 iteration 5057 : loss : 0.066157, loss_ce: 0.028023
2021-12-17 17:52:26,079 iteration 5058 : loss : 0.061965, loss_ce: 0.019685
2021-12-17 17:52:27,450 iteration 5059 : loss : 0.056586, loss_ce: 0.020562
2021-12-17 17:52:28,864 iteration 5060 : loss : 0.075310, loss_ce: 0.020434
2021-12-17 17:52:30,227 iteration 5061 : loss : 0.073691, loss_ce: 0.031447
2021-12-17 17:52:31,637 iteration 5062 : loss : 0.055838, loss_ce: 0.017600
2021-12-17 17:52:32,958 iteration 5063 : loss : 0.054180, loss_ce: 0.018184
2021-12-17 17:52:34,325 iteration 5064 : loss : 0.060555, loss_ce: 0.013606
2021-12-17 17:52:35,744 iteration 5065 : loss : 0.068865, loss_ce: 0.020082
2021-12-17 17:52:37,016 iteration 5066 : loss : 0.049481, loss_ce: 0.017662
 74%|█████████████████████▌       | 298/400 [2:07:56<41:33, 24.44s/it]2021-12-17 17:52:38,542 iteration 5067 : loss : 0.060850, loss_ce: 0.015050
2021-12-17 17:52:39,894 iteration 5068 : loss : 0.051624, loss_ce: 0.013484
2021-12-17 17:52:41,215 iteration 5069 : loss : 0.078279, loss_ce: 0.022481
2021-12-17 17:52:42,563 iteration 5070 : loss : 0.052654, loss_ce: 0.019707
2021-12-17 17:52:43,976 iteration 5071 : loss : 0.058740, loss_ce: 0.022303
2021-12-17 17:52:45,356 iteration 5072 : loss : 0.054559, loss_ce: 0.015399
2021-12-17 17:52:46,767 iteration 5073 : loss : 0.072972, loss_ce: 0.017553
2021-12-17 17:52:48,168 iteration 5074 : loss : 0.061174, loss_ce: 0.020534
2021-12-17 17:52:49,458 iteration 5075 : loss : 0.060904, loss_ce: 0.023860
2021-12-17 17:52:50,753 iteration 5076 : loss : 0.053711, loss_ce: 0.017501
2021-12-17 17:52:52,162 iteration 5077 : loss : 0.069567, loss_ce: 0.022574
2021-12-17 17:52:53,527 iteration 5078 : loss : 0.065842, loss_ce: 0.021307
2021-12-17 17:52:54,874 iteration 5079 : loss : 0.042556, loss_ce: 0.012862
2021-12-17 17:52:56,259 iteration 5080 : loss : 0.059600, loss_ce: 0.019264
2021-12-17 17:52:57,643 iteration 5081 : loss : 0.063276, loss_ce: 0.024454
2021-12-17 17:52:58,984 iteration 5082 : loss : 0.063045, loss_ce: 0.016237
2021-12-17 17:53:00,316 iteration 5083 : loss : 0.062180, loss_ce: 0.018849
 75%|█████████████████████▋       | 299/400 [2:08:19<40:34, 24.10s/it]2021-12-17 17:53:01,739 iteration 5084 : loss : 0.076263, loss_ce: 0.029213
2021-12-17 17:53:03,193 iteration 5085 : loss : 0.059345, loss_ce: 0.019028
2021-12-17 17:53:04,487 iteration 5086 : loss : 0.047265, loss_ce: 0.012516
2021-12-17 17:53:05,865 iteration 5087 : loss : 0.059403, loss_ce: 0.014355
2021-12-17 17:53:07,178 iteration 5088 : loss : 0.052257, loss_ce: 0.019508
2021-12-17 17:53:08,527 iteration 5089 : loss : 0.049528, loss_ce: 0.015467
2021-12-17 17:53:09,915 iteration 5090 : loss : 0.061591, loss_ce: 0.022153
2021-12-17 17:53:11,314 iteration 5091 : loss : 0.067300, loss_ce: 0.019553
2021-12-17 17:53:12,671 iteration 5092 : loss : 0.061482, loss_ce: 0.015649
2021-12-17 17:53:14,028 iteration 5093 : loss : 0.049180, loss_ce: 0.015283
2021-12-17 17:53:15,404 iteration 5094 : loss : 0.050742, loss_ce: 0.014217
2021-12-17 17:53:16,779 iteration 5095 : loss : 0.057372, loss_ce: 0.019736
2021-12-17 17:53:18,210 iteration 5096 : loss : 0.063859, loss_ce: 0.017004
2021-12-17 17:53:19,614 iteration 5097 : loss : 0.059833, loss_ce: 0.020197
2021-12-17 17:53:20,968 iteration 5098 : loss : 0.053385, loss_ce: 0.018991
2021-12-17 17:53:22,371 iteration 5099 : loss : 0.069260, loss_ce: 0.019030
2021-12-17 17:53:22,372 Training Data Eval:
2021-12-17 17:53:29,466   Average segmentation loss on training set: 0.0395
2021-12-17 17:53:29,466 Validation Data Eval:
2021-12-17 17:53:31,936   Average segmentation loss on validation set: 0.1301
2021-12-17 17:53:33,284 iteration 5100 : loss : 0.056709, loss_ce: 0.015219
 75%|█████████████████████▊       | 300/400 [2:08:52<44:36, 26.76s/it]2021-12-17 17:53:34,737 iteration 5101 : loss : 0.059566, loss_ce: 0.012780
2021-12-17 17:53:36,171 iteration 5102 : loss : 0.072360, loss_ce: 0.030098
2021-12-17 17:53:37,497 iteration 5103 : loss : 0.059783, loss_ce: 0.019440
2021-12-17 17:53:38,860 iteration 5104 : loss : 0.066824, loss_ce: 0.017741
2021-12-17 17:53:40,202 iteration 5105 : loss : 0.054045, loss_ce: 0.014734
2021-12-17 17:53:41,566 iteration 5106 : loss : 0.069358, loss_ce: 0.021740
2021-12-17 17:53:42,937 iteration 5107 : loss : 0.056967, loss_ce: 0.019909
2021-12-17 17:53:44,320 iteration 5108 : loss : 0.057622, loss_ce: 0.020524
2021-12-17 17:53:45,686 iteration 5109 : loss : 0.055890, loss_ce: 0.019322
2021-12-17 17:53:46,970 iteration 5110 : loss : 0.049035, loss_ce: 0.015972
2021-12-17 17:53:48,394 iteration 5111 : loss : 0.057340, loss_ce: 0.015456
2021-12-17 17:53:49,701 iteration 5112 : loss : 0.044096, loss_ce: 0.014540
2021-12-17 17:53:51,128 iteration 5113 : loss : 0.065694, loss_ce: 0.019851
2021-12-17 17:53:52,451 iteration 5114 : loss : 0.053589, loss_ce: 0.017466
2021-12-17 17:53:53,781 iteration 5115 : loss : 0.049074, loss_ce: 0.017412
2021-12-17 17:53:55,159 iteration 5116 : loss : 0.063767, loss_ce: 0.022908
2021-12-17 17:53:56,543 iteration 5117 : loss : 0.060669, loss_ce: 0.020048
 75%|█████████████████████▊       | 301/400 [2:09:15<42:25, 25.71s/it]2021-12-17 17:53:57,971 iteration 5118 : loss : 0.061707, loss_ce: 0.021017
2021-12-17 17:53:59,333 iteration 5119 : loss : 0.069411, loss_ce: 0.020415
2021-12-17 17:54:00,771 iteration 5120 : loss : 0.054753, loss_ce: 0.015100
2021-12-17 17:54:02,098 iteration 5121 : loss : 0.052975, loss_ce: 0.017699
2021-12-17 17:54:03,436 iteration 5122 : loss : 0.061551, loss_ce: 0.017166
2021-12-17 17:54:04,793 iteration 5123 : loss : 0.062718, loss_ce: 0.027635
2021-12-17 17:54:06,118 iteration 5124 : loss : 0.069081, loss_ce: 0.015849
2021-12-17 17:54:07,495 iteration 5125 : loss : 0.062971, loss_ce: 0.019557
2021-12-17 17:54:08,842 iteration 5126 : loss : 0.051905, loss_ce: 0.016091
2021-12-17 17:54:10,230 iteration 5127 : loss : 0.073325, loss_ce: 0.026781
2021-12-17 17:54:11,687 iteration 5128 : loss : 0.068254, loss_ce: 0.021023
2021-12-17 17:54:13,100 iteration 5129 : loss : 0.070626, loss_ce: 0.022909
2021-12-17 17:54:14,395 iteration 5130 : loss : 0.049939, loss_ce: 0.016585
2021-12-17 17:54:15,779 iteration 5131 : loss : 0.048053, loss_ce: 0.012108
2021-12-17 17:54:17,158 iteration 5132 : loss : 0.060629, loss_ce: 0.021615
2021-12-17 17:54:18,484 iteration 5133 : loss : 0.053766, loss_ce: 0.019101
2021-12-17 17:54:19,798 iteration 5134 : loss : 0.042856, loss_ce: 0.012921
 76%|█████████████████████▉       | 302/400 [2:09:38<40:47, 24.97s/it]2021-12-17 17:54:21,205 iteration 5135 : loss : 0.054945, loss_ce: 0.017056
2021-12-17 17:54:22,654 iteration 5136 : loss : 0.072171, loss_ce: 0.025540
2021-12-17 17:54:24,090 iteration 5137 : loss : 0.058539, loss_ce: 0.018234
2021-12-17 17:54:25,539 iteration 5138 : loss : 0.065996, loss_ce: 0.025504
2021-12-17 17:54:26,831 iteration 5139 : loss : 0.043664, loss_ce: 0.011199
2021-12-17 17:54:28,230 iteration 5140 : loss : 0.059794, loss_ce: 0.024770
2021-12-17 17:54:29,540 iteration 5141 : loss : 0.051643, loss_ce: 0.020968
2021-12-17 17:54:30,987 iteration 5142 : loss : 0.074974, loss_ce: 0.021828
2021-12-17 17:54:32,296 iteration 5143 : loss : 0.048574, loss_ce: 0.015905
2021-12-17 17:54:33,611 iteration 5144 : loss : 0.047206, loss_ce: 0.016665
2021-12-17 17:54:34,997 iteration 5145 : loss : 0.064132, loss_ce: 0.021610
2021-12-17 17:54:36,490 iteration 5146 : loss : 0.082482, loss_ce: 0.021155
2021-12-17 17:54:37,872 iteration 5147 : loss : 0.055787, loss_ce: 0.020912
2021-12-17 17:54:39,264 iteration 5148 : loss : 0.063482, loss_ce: 0.019645
2021-12-17 17:54:40,601 iteration 5149 : loss : 0.052562, loss_ce: 0.014742
2021-12-17 17:54:41,934 iteration 5150 : loss : 0.053693, loss_ce: 0.017577
2021-12-17 17:54:43,244 iteration 5151 : loss : 0.051893, loss_ce: 0.014504
 76%|█████████████████████▉       | 303/400 [2:10:02<39:38, 24.52s/it]2021-12-17 17:54:44,696 iteration 5152 : loss : 0.076995, loss_ce: 0.022773
2021-12-17 17:54:45,990 iteration 5153 : loss : 0.050516, loss_ce: 0.019509
2021-12-17 17:54:47,392 iteration 5154 : loss : 0.058962, loss_ce: 0.019111
2021-12-17 17:54:48,698 iteration 5155 : loss : 0.048232, loss_ce: 0.015501
2021-12-17 17:54:50,047 iteration 5156 : loss : 0.058312, loss_ce: 0.017780
2021-12-17 17:54:51,464 iteration 5157 : loss : 0.050767, loss_ce: 0.016157
2021-12-17 17:54:52,862 iteration 5158 : loss : 0.052777, loss_ce: 0.013706
2021-12-17 17:54:54,271 iteration 5159 : loss : 0.072106, loss_ce: 0.023643
2021-12-17 17:54:55,696 iteration 5160 : loss : 0.051094, loss_ce: 0.018189
2021-12-17 17:54:57,111 iteration 5161 : loss : 0.060790, loss_ce: 0.019767
2021-12-17 17:54:58,446 iteration 5162 : loss : 0.051494, loss_ce: 0.013719
2021-12-17 17:54:59,805 iteration 5163 : loss : 0.057123, loss_ce: 0.017431
2021-12-17 17:55:01,111 iteration 5164 : loss : 0.059501, loss_ce: 0.025629
2021-12-17 17:55:02,489 iteration 5165 : loss : 0.047930, loss_ce: 0.011879
2021-12-17 17:55:03,859 iteration 5166 : loss : 0.053532, loss_ce: 0.020046
2021-12-17 17:55:05,171 iteration 5167 : loss : 0.055139, loss_ce: 0.020652
2021-12-17 17:55:06,583 iteration 5168 : loss : 0.077754, loss_ce: 0.028162
 76%|██████████████████████       | 304/400 [2:10:25<38:39, 24.16s/it]2021-12-17 17:55:07,969 iteration 5169 : loss : 0.058384, loss_ce: 0.018862
2021-12-17 17:55:09,345 iteration 5170 : loss : 0.062264, loss_ce: 0.027209
2021-12-17 17:55:10,693 iteration 5171 : loss : 0.059882, loss_ce: 0.012364
2021-12-17 17:55:12,074 iteration 5172 : loss : 0.051089, loss_ce: 0.017035
2021-12-17 17:55:13,411 iteration 5173 : loss : 0.053585, loss_ce: 0.021576
2021-12-17 17:55:14,805 iteration 5174 : loss : 0.057736, loss_ce: 0.017064
2021-12-17 17:55:16,239 iteration 5175 : loss : 0.072971, loss_ce: 0.022745
2021-12-17 17:55:17,588 iteration 5176 : loss : 0.057069, loss_ce: 0.014329
2021-12-17 17:55:19,055 iteration 5177 : loss : 0.074218, loss_ce: 0.029651
2021-12-17 17:55:20,385 iteration 5178 : loss : 0.070471, loss_ce: 0.016055
2021-12-17 17:55:21,794 iteration 5179 : loss : 0.073497, loss_ce: 0.028751
2021-12-17 17:55:23,173 iteration 5180 : loss : 0.054671, loss_ce: 0.019233
2021-12-17 17:55:24,593 iteration 5181 : loss : 0.061109, loss_ce: 0.021352
2021-12-17 17:55:26,005 iteration 5182 : loss : 0.066223, loss_ce: 0.019551
2021-12-17 17:55:27,420 iteration 5183 : loss : 0.066888, loss_ce: 0.017842
2021-12-17 17:55:28,866 iteration 5184 : loss : 0.064944, loss_ce: 0.026232
2021-12-17 17:55:28,866 Training Data Eval:
2021-12-17 17:55:35,935   Average segmentation loss on training set: 0.0393
2021-12-17 17:55:35,936 Validation Data Eval:
2021-12-17 17:55:38,436   Average segmentation loss on validation set: 0.1296
2021-12-17 17:55:39,833 iteration 5185 : loss : 0.066321, loss_ce: 0.023080
 76%|██████████████████████       | 305/400 [2:10:58<42:34, 26.89s/it]2021-12-17 17:55:41,260 iteration 5186 : loss : 0.052321, loss_ce: 0.017954
2021-12-17 17:55:42,671 iteration 5187 : loss : 0.071062, loss_ce: 0.025718
2021-12-17 17:55:43,976 iteration 5188 : loss : 0.058614, loss_ce: 0.015971
2021-12-17 17:55:45,351 iteration 5189 : loss : 0.051712, loss_ce: 0.018640
2021-12-17 17:55:46,658 iteration 5190 : loss : 0.050825, loss_ce: 0.017638
2021-12-17 17:55:47,994 iteration 5191 : loss : 0.053952, loss_ce: 0.018553
2021-12-17 17:55:49,408 iteration 5192 : loss : 0.069037, loss_ce: 0.017779
2021-12-17 17:55:50,788 iteration 5193 : loss : 0.069165, loss_ce: 0.028909
2021-12-17 17:55:52,147 iteration 5194 : loss : 0.052000, loss_ce: 0.017252
2021-12-17 17:55:53,531 iteration 5195 : loss : 0.062479, loss_ce: 0.019880
2021-12-17 17:55:55,019 iteration 5196 : loss : 0.067159, loss_ce: 0.014806
2021-12-17 17:55:56,303 iteration 5197 : loss : 0.051504, loss_ce: 0.013209
2021-12-17 17:55:57,711 iteration 5198 : loss : 0.067678, loss_ce: 0.021829
2021-12-17 17:55:59,104 iteration 5199 : loss : 0.058730, loss_ce: 0.018147
2021-12-17 17:56:00,488 iteration 5200 : loss : 0.050056, loss_ce: 0.012718
2021-12-17 17:56:01,823 iteration 5201 : loss : 0.055065, loss_ce: 0.012067
2021-12-17 17:56:03,193 iteration 5202 : loss : 0.056211, loss_ce: 0.019912
 76%|██████████████████████▏      | 306/400 [2:11:22<40:28, 25.83s/it]2021-12-17 17:56:04,544 iteration 5203 : loss : 0.049093, loss_ce: 0.012113
2021-12-17 17:56:05,950 iteration 5204 : loss : 0.067767, loss_ce: 0.022991
2021-12-17 17:56:07,327 iteration 5205 : loss : 0.049414, loss_ce: 0.015119
2021-12-17 17:56:08,636 iteration 5206 : loss : 0.044600, loss_ce: 0.015542
2021-12-17 17:56:09,990 iteration 5207 : loss : 0.048258, loss_ce: 0.015447
2021-12-17 17:56:11,423 iteration 5208 : loss : 0.075083, loss_ce: 0.025892
2021-12-17 17:56:12,799 iteration 5209 : loss : 0.054651, loss_ce: 0.018853
2021-12-17 17:56:14,155 iteration 5210 : loss : 0.053286, loss_ce: 0.014662
2021-12-17 17:56:15,485 iteration 5211 : loss : 0.047738, loss_ce: 0.011948
2021-12-17 17:56:16,868 iteration 5212 : loss : 0.064814, loss_ce: 0.019126
2021-12-17 17:56:18,262 iteration 5213 : loss : 0.091099, loss_ce: 0.026233
2021-12-17 17:56:19,599 iteration 5214 : loss : 0.069047, loss_ce: 0.035068
2021-12-17 17:56:20,936 iteration 5215 : loss : 0.062689, loss_ce: 0.021747
2021-12-17 17:56:22,283 iteration 5216 : loss : 0.054250, loss_ce: 0.019483
2021-12-17 17:56:23,607 iteration 5217 : loss : 0.053276, loss_ce: 0.015865
2021-12-17 17:56:24,965 iteration 5218 : loss : 0.065761, loss_ce: 0.020422
2021-12-17 17:56:26,359 iteration 5219 : loss : 0.071903, loss_ce: 0.024936
 77%|██████████████████████▎      | 307/400 [2:11:45<38:47, 25.03s/it]2021-12-17 17:56:27,848 iteration 5220 : loss : 0.061725, loss_ce: 0.020006
2021-12-17 17:56:29,177 iteration 5221 : loss : 0.047275, loss_ce: 0.015835
2021-12-17 17:56:30,464 iteration 5222 : loss : 0.048599, loss_ce: 0.009351
2021-12-17 17:56:31,820 iteration 5223 : loss : 0.049918, loss_ce: 0.016363
2021-12-17 17:56:33,243 iteration 5224 : loss : 0.070857, loss_ce: 0.018259
2021-12-17 17:56:34,533 iteration 5225 : loss : 0.055870, loss_ce: 0.014643
2021-12-17 17:56:36,010 iteration 5226 : loss : 0.066684, loss_ce: 0.023466
2021-12-17 17:56:37,292 iteration 5227 : loss : 0.045268, loss_ce: 0.013325
2021-12-17 17:56:38,597 iteration 5228 : loss : 0.049762, loss_ce: 0.017329
2021-12-17 17:56:39,940 iteration 5229 : loss : 0.052605, loss_ce: 0.018691
2021-12-17 17:56:41,321 iteration 5230 : loss : 0.062587, loss_ce: 0.026745
2021-12-17 17:56:42,702 iteration 5231 : loss : 0.084444, loss_ce: 0.021565
2021-12-17 17:56:44,028 iteration 5232 : loss : 0.052379, loss_ce: 0.017483
2021-12-17 17:56:45,426 iteration 5233 : loss : 0.061726, loss_ce: 0.023730
2021-12-17 17:56:46,715 iteration 5234 : loss : 0.044831, loss_ce: 0.013271
2021-12-17 17:56:48,161 iteration 5235 : loss : 0.084366, loss_ce: 0.026657
2021-12-17 17:56:49,503 iteration 5236 : loss : 0.063684, loss_ce: 0.019221
 77%|██████████████████████▎      | 308/400 [2:12:08<37:30, 24.46s/it]2021-12-17 17:56:50,938 iteration 5237 : loss : 0.062579, loss_ce: 0.017798
2021-12-17 17:56:52,301 iteration 5238 : loss : 0.053871, loss_ce: 0.020254
2021-12-17 17:56:53,659 iteration 5239 : loss : 0.057090, loss_ce: 0.015502
2021-12-17 17:56:55,106 iteration 5240 : loss : 0.060864, loss_ce: 0.016820
2021-12-17 17:56:56,501 iteration 5241 : loss : 0.058553, loss_ce: 0.021426
2021-12-17 17:56:57,891 iteration 5242 : loss : 0.059240, loss_ce: 0.022578
2021-12-17 17:56:59,267 iteration 5243 : loss : 0.065175, loss_ce: 0.021974
2021-12-17 17:57:00,658 iteration 5244 : loss : 0.065005, loss_ce: 0.021619
2021-12-17 17:57:02,022 iteration 5245 : loss : 0.056447, loss_ce: 0.017181
2021-12-17 17:57:03,290 iteration 5246 : loss : 0.044567, loss_ce: 0.015988
2021-12-17 17:57:04,653 iteration 5247 : loss : 0.051553, loss_ce: 0.015977
2021-12-17 17:57:06,053 iteration 5248 : loss : 0.053166, loss_ce: 0.015260
2021-12-17 17:57:07,409 iteration 5249 : loss : 0.067623, loss_ce: 0.024329
2021-12-17 17:57:08,775 iteration 5250 : loss : 0.054460, loss_ce: 0.019476
2021-12-17 17:57:10,195 iteration 5251 : loss : 0.060911, loss_ce: 0.017874
2021-12-17 17:57:11,555 iteration 5252 : loss : 0.061633, loss_ce: 0.016240
2021-12-17 17:57:12,956 iteration 5253 : loss : 0.049969, loss_ce: 0.016338
 77%|██████████████████████▍      | 309/400 [2:12:32<36:38, 24.16s/it]2021-12-17 17:57:14,307 iteration 5254 : loss : 0.052781, loss_ce: 0.016728
2021-12-17 17:57:15,716 iteration 5255 : loss : 0.062565, loss_ce: 0.017403
2021-12-17 17:57:17,090 iteration 5256 : loss : 0.044160, loss_ce: 0.012579
2021-12-17 17:57:18,531 iteration 5257 : loss : 0.083520, loss_ce: 0.023691
2021-12-17 17:57:19,858 iteration 5258 : loss : 0.071893, loss_ce: 0.024274
2021-12-17 17:57:21,252 iteration 5259 : loss : 0.072365, loss_ce: 0.018152
2021-12-17 17:57:22,589 iteration 5260 : loss : 0.057731, loss_ce: 0.018865
2021-12-17 17:57:23,940 iteration 5261 : loss : 0.049978, loss_ce: 0.017583
2021-12-17 17:57:25,246 iteration 5262 : loss : 0.043335, loss_ce: 0.014476
2021-12-17 17:57:26,625 iteration 5263 : loss : 0.055581, loss_ce: 0.017549
2021-12-17 17:57:27,961 iteration 5264 : loss : 0.055945, loss_ce: 0.015550
2021-12-17 17:57:29,251 iteration 5265 : loss : 0.053143, loss_ce: 0.016706
2021-12-17 17:57:30,618 iteration 5266 : loss : 0.053451, loss_ce: 0.019750
2021-12-17 17:57:31,932 iteration 5267 : loss : 0.069435, loss_ce: 0.022019
2021-12-17 17:57:33,348 iteration 5268 : loss : 0.057504, loss_ce: 0.019582
2021-12-17 17:57:34,784 iteration 5269 : loss : 0.069128, loss_ce: 0.028143
2021-12-17 17:57:34,784 Training Data Eval:
2021-12-17 17:57:41,848   Average segmentation loss on training set: 0.0391
2021-12-17 17:57:41,848 Validation Data Eval:
2021-12-17 17:57:44,319   Average segmentation loss on validation set: 0.1290
2021-12-17 17:57:45,759 iteration 5270 : loss : 0.060978, loss_ce: 0.019053
 78%|██████████████████████▍      | 310/400 [2:13:04<40:07, 26.75s/it]2021-12-17 17:57:47,233 iteration 5271 : loss : 0.058950, loss_ce: 0.021862
2021-12-17 17:57:48,601 iteration 5272 : loss : 0.058432, loss_ce: 0.020683
2021-12-17 17:57:49,960 iteration 5273 : loss : 0.049620, loss_ce: 0.017851
2021-12-17 17:57:51,277 iteration 5274 : loss : 0.051562, loss_ce: 0.015545
2021-12-17 17:57:52,668 iteration 5275 : loss : 0.057922, loss_ce: 0.015137
2021-12-17 17:57:54,050 iteration 5276 : loss : 0.059297, loss_ce: 0.017179
2021-12-17 17:57:55,357 iteration 5277 : loss : 0.071609, loss_ce: 0.019290
2021-12-17 17:57:56,838 iteration 5278 : loss : 0.055411, loss_ce: 0.019513
2021-12-17 17:57:58,194 iteration 5279 : loss : 0.061188, loss_ce: 0.015263
2021-12-17 17:57:59,620 iteration 5280 : loss : 0.067682, loss_ce: 0.022951
2021-12-17 17:58:00,983 iteration 5281 : loss : 0.054863, loss_ce: 0.023255
2021-12-17 17:58:02,369 iteration 5282 : loss : 0.058683, loss_ce: 0.019434
2021-12-17 17:58:03,736 iteration 5283 : loss : 0.055581, loss_ce: 0.015614
2021-12-17 17:58:05,125 iteration 5284 : loss : 0.070688, loss_ce: 0.028390
2021-12-17 17:58:06,492 iteration 5285 : loss : 0.058319, loss_ce: 0.020767
2021-12-17 17:58:07,890 iteration 5286 : loss : 0.055293, loss_ce: 0.018439
2021-12-17 17:58:09,347 iteration 5287 : loss : 0.067980, loss_ce: 0.025488
 78%|██████████████████████▌      | 311/400 [2:13:28<38:16, 25.80s/it]2021-12-17 17:58:10,730 iteration 5288 : loss : 0.063772, loss_ce: 0.019703
2021-12-17 17:58:12,104 iteration 5289 : loss : 0.067888, loss_ce: 0.021094
2021-12-17 17:58:13,513 iteration 5290 : loss : 0.067320, loss_ce: 0.022536
2021-12-17 17:58:14,925 iteration 5291 : loss : 0.060685, loss_ce: 0.022748
2021-12-17 17:58:16,323 iteration 5292 : loss : 0.046661, loss_ce: 0.015227
2021-12-17 17:58:17,673 iteration 5293 : loss : 0.062171, loss_ce: 0.018871
2021-12-17 17:58:19,096 iteration 5294 : loss : 0.067337, loss_ce: 0.022228
2021-12-17 17:58:20,406 iteration 5295 : loss : 0.046602, loss_ce: 0.013891
2021-12-17 17:58:21,771 iteration 5296 : loss : 0.062936, loss_ce: 0.019443
2021-12-17 17:58:23,208 iteration 5297 : loss : 0.074284, loss_ce: 0.020524
2021-12-17 17:58:24,520 iteration 5298 : loss : 0.047831, loss_ce: 0.017630
2021-12-17 17:58:25,941 iteration 5299 : loss : 0.069789, loss_ce: 0.025232
2021-12-17 17:58:27,238 iteration 5300 : loss : 0.048633, loss_ce: 0.015293
2021-12-17 17:58:28,608 iteration 5301 : loss : 0.075248, loss_ce: 0.024610
2021-12-17 17:58:29,950 iteration 5302 : loss : 0.056834, loss_ce: 0.018364
2021-12-17 17:58:31,225 iteration 5303 : loss : 0.046738, loss_ce: 0.013769
2021-12-17 17:58:32,644 iteration 5304 : loss : 0.076361, loss_ce: 0.026830
 78%|██████████████████████▌      | 312/400 [2:13:51<36:44, 25.05s/it]2021-12-17 17:58:34,061 iteration 5305 : loss : 0.068213, loss_ce: 0.021785
2021-12-17 17:58:35,454 iteration 5306 : loss : 0.070927, loss_ce: 0.020390
2021-12-17 17:58:36,812 iteration 5307 : loss : 0.052602, loss_ce: 0.018179
2021-12-17 17:58:38,191 iteration 5308 : loss : 0.059743, loss_ce: 0.020913
2021-12-17 17:58:39,545 iteration 5309 : loss : 0.049182, loss_ce: 0.013982
2021-12-17 17:58:40,900 iteration 5310 : loss : 0.053869, loss_ce: 0.021141
2021-12-17 17:58:42,275 iteration 5311 : loss : 0.051197, loss_ce: 0.016297
2021-12-17 17:58:43,650 iteration 5312 : loss : 0.052680, loss_ce: 0.015313
2021-12-17 17:58:45,057 iteration 5313 : loss : 0.073614, loss_ce: 0.020023
2021-12-17 17:58:46,381 iteration 5314 : loss : 0.052187, loss_ce: 0.019600
2021-12-17 17:58:47,783 iteration 5315 : loss : 0.056294, loss_ce: 0.019676
2021-12-17 17:58:49,049 iteration 5316 : loss : 0.043443, loss_ce: 0.015467
2021-12-17 17:58:50,433 iteration 5317 : loss : 0.055771, loss_ce: 0.018949
2021-12-17 17:58:51,831 iteration 5318 : loss : 0.059459, loss_ce: 0.017179
2021-12-17 17:58:53,233 iteration 5319 : loss : 0.066870, loss_ce: 0.022189
2021-12-17 17:58:54,635 iteration 5320 : loss : 0.068954, loss_ce: 0.024637
2021-12-17 17:58:55,946 iteration 5321 : loss : 0.057022, loss_ce: 0.011433
 78%|██████████████████████▋      | 313/400 [2:14:15<35:33, 24.53s/it]2021-12-17 17:58:57,402 iteration 5322 : loss : 0.054741, loss_ce: 0.021117
2021-12-17 17:58:58,822 iteration 5323 : loss : 0.065486, loss_ce: 0.019484
2021-12-17 17:59:00,193 iteration 5324 : loss : 0.056106, loss_ce: 0.020540
2021-12-17 17:59:01,567 iteration 5325 : loss : 0.059658, loss_ce: 0.017790
2021-12-17 17:59:03,010 iteration 5326 : loss : 0.065034, loss_ce: 0.017044
2021-12-17 17:59:04,405 iteration 5327 : loss : 0.055929, loss_ce: 0.018131
2021-12-17 17:59:05,770 iteration 5328 : loss : 0.060895, loss_ce: 0.019635
2021-12-17 17:59:07,140 iteration 5329 : loss : 0.057715, loss_ce: 0.019815
2021-12-17 17:59:08,502 iteration 5330 : loss : 0.063999, loss_ce: 0.023714
2021-12-17 17:59:09,803 iteration 5331 : loss : 0.046210, loss_ce: 0.015510
2021-12-17 17:59:11,331 iteration 5332 : loss : 0.091078, loss_ce: 0.035112
2021-12-17 17:59:12,686 iteration 5333 : loss : 0.054813, loss_ce: 0.016398
2021-12-17 17:59:13,956 iteration 5334 : loss : 0.067426, loss_ce: 0.019782
2021-12-17 17:59:15,329 iteration 5335 : loss : 0.050254, loss_ce: 0.013260
2021-12-17 17:59:16,679 iteration 5336 : loss : 0.059350, loss_ce: 0.016559
2021-12-17 17:59:18,035 iteration 5337 : loss : 0.061648, loss_ce: 0.021678
2021-12-17 17:59:19,407 iteration 5338 : loss : 0.060319, loss_ce: 0.018344
 78%|██████████████████████▊      | 314/400 [2:14:38<34:41, 24.21s/it]2021-12-17 17:59:20,804 iteration 5339 : loss : 0.054607, loss_ce: 0.019504
2021-12-17 17:59:22,145 iteration 5340 : loss : 0.057102, loss_ce: 0.019126
2021-12-17 17:59:23,575 iteration 5341 : loss : 0.060660, loss_ce: 0.014486
2021-12-17 17:59:24,971 iteration 5342 : loss : 0.053035, loss_ce: 0.016855
2021-12-17 17:59:26,347 iteration 5343 : loss : 0.056257, loss_ce: 0.017271
2021-12-17 17:59:27,677 iteration 5344 : loss : 0.050801, loss_ce: 0.018611
2021-12-17 17:59:29,021 iteration 5345 : loss : 0.055530, loss_ce: 0.018563
2021-12-17 17:59:30,360 iteration 5346 : loss : 0.048576, loss_ce: 0.015527
2021-12-17 17:59:31,741 iteration 5347 : loss : 0.046023, loss_ce: 0.015980
2021-12-17 17:59:33,065 iteration 5348 : loss : 0.053090, loss_ce: 0.015917
2021-12-17 17:59:34,398 iteration 5349 : loss : 0.052606, loss_ce: 0.015801
2021-12-17 17:59:35,748 iteration 5350 : loss : 0.055837, loss_ce: 0.016564
2021-12-17 17:59:37,055 iteration 5351 : loss : 0.049780, loss_ce: 0.014954
2021-12-17 17:59:38,475 iteration 5352 : loss : 0.065762, loss_ce: 0.021512
2021-12-17 17:59:39,842 iteration 5353 : loss : 0.057033, loss_ce: 0.019015
2021-12-17 17:59:41,161 iteration 5354 : loss : 0.050991, loss_ce: 0.018677
2021-12-17 17:59:41,161 Training Data Eval:
2021-12-17 17:59:48,236   Average segmentation loss on training set: 0.0387
2021-12-17 17:59:48,236 Validation Data Eval:
2021-12-17 17:59:50,700   Average segmentation loss on validation set: 0.1334
2021-12-17 17:59:52,092 iteration 5355 : loss : 0.063608, loss_ce: 0.022836
 79%|██████████████████████▊      | 315/400 [2:15:11<37:53, 26.75s/it]2021-12-17 17:59:53,565 iteration 5356 : loss : 0.080344, loss_ce: 0.030209
2021-12-17 17:59:54,893 iteration 5357 : loss : 0.048780, loss_ce: 0.015369
2021-12-17 17:59:56,218 iteration 5358 : loss : 0.053810, loss_ce: 0.018075
2021-12-17 17:59:57,536 iteration 5359 : loss : 0.050311, loss_ce: 0.015701
2021-12-17 17:59:58,931 iteration 5360 : loss : 0.064920, loss_ce: 0.024104
2021-12-17 18:00:00,273 iteration 5361 : loss : 0.056446, loss_ce: 0.021819
2021-12-17 18:00:01,655 iteration 5362 : loss : 0.053975, loss_ce: 0.017014
2021-12-17 18:00:03,151 iteration 5363 : loss : 0.063204, loss_ce: 0.022602
2021-12-17 18:00:04,520 iteration 5364 : loss : 0.079925, loss_ce: 0.019055
2021-12-17 18:00:05,898 iteration 5365 : loss : 0.064008, loss_ce: 0.019015
2021-12-17 18:00:07,242 iteration 5366 : loss : 0.061283, loss_ce: 0.019932
2021-12-17 18:00:08,528 iteration 5367 : loss : 0.047094, loss_ce: 0.013876
2021-12-17 18:00:10,002 iteration 5368 : loss : 0.073713, loss_ce: 0.021731
2021-12-17 18:00:11,348 iteration 5369 : loss : 0.044212, loss_ce: 0.014142
2021-12-17 18:00:12,685 iteration 5370 : loss : 0.054532, loss_ce: 0.021618
2021-12-17 18:00:14,032 iteration 5371 : loss : 0.058957, loss_ce: 0.015365
2021-12-17 18:00:15,312 iteration 5372 : loss : 0.052151, loss_ce: 0.018047
 79%|██████████████████████▉      | 316/400 [2:15:34<35:58, 25.69s/it]2021-12-17 18:00:16,715 iteration 5373 : loss : 0.055717, loss_ce: 0.018847
2021-12-17 18:00:18,054 iteration 5374 : loss : 0.075736, loss_ce: 0.016121
2021-12-17 18:00:19,420 iteration 5375 : loss : 0.065569, loss_ce: 0.021140
2021-12-17 18:00:20,792 iteration 5376 : loss : 0.060325, loss_ce: 0.017324
2021-12-17 18:00:22,184 iteration 5377 : loss : 0.060572, loss_ce: 0.014841
2021-12-17 18:00:23,565 iteration 5378 : loss : 0.063503, loss_ce: 0.017504
2021-12-17 18:00:24,900 iteration 5379 : loss : 0.049796, loss_ce: 0.016426
2021-12-17 18:00:26,191 iteration 5380 : loss : 0.054225, loss_ce: 0.017990
2021-12-17 18:00:27,611 iteration 5381 : loss : 0.052820, loss_ce: 0.017976
2021-12-17 18:00:28,975 iteration 5382 : loss : 0.065346, loss_ce: 0.024769
2021-12-17 18:00:30,321 iteration 5383 : loss : 0.068427, loss_ce: 0.029125
2021-12-17 18:00:31,647 iteration 5384 : loss : 0.053448, loss_ce: 0.020621
2021-12-17 18:00:33,012 iteration 5385 : loss : 0.067238, loss_ce: 0.024457
2021-12-17 18:00:34,331 iteration 5386 : loss : 0.055602, loss_ce: 0.017635
2021-12-17 18:00:35,782 iteration 5387 : loss : 0.090494, loss_ce: 0.032353
2021-12-17 18:00:37,180 iteration 5388 : loss : 0.048159, loss_ce: 0.012807
2021-12-17 18:00:38,612 iteration 5389 : loss : 0.063318, loss_ce: 0.023823
 79%|██████████████████████▉      | 317/400 [2:15:57<34:32, 24.97s/it]2021-12-17 18:00:39,997 iteration 5390 : loss : 0.051200, loss_ce: 0.014819
2021-12-17 18:00:41,423 iteration 5391 : loss : 0.079796, loss_ce: 0.022987
2021-12-17 18:00:42,752 iteration 5392 : loss : 0.062732, loss_ce: 0.017331
2021-12-17 18:00:44,064 iteration 5393 : loss : 0.054974, loss_ce: 0.016381
2021-12-17 18:00:45,407 iteration 5394 : loss : 0.046832, loss_ce: 0.011982
2021-12-17 18:00:46,763 iteration 5395 : loss : 0.078447, loss_ce: 0.027559
2021-12-17 18:00:48,094 iteration 5396 : loss : 0.056870, loss_ce: 0.017410
2021-12-17 18:00:49,496 iteration 5397 : loss : 0.066994, loss_ce: 0.025090
2021-12-17 18:00:50,994 iteration 5398 : loss : 0.068054, loss_ce: 0.020322
2021-12-17 18:00:52,392 iteration 5399 : loss : 0.062160, loss_ce: 0.019742
2021-12-17 18:00:53,729 iteration 5400 : loss : 0.062375, loss_ce: 0.022436
2021-12-17 18:00:55,119 iteration 5401 : loss : 0.070592, loss_ce: 0.034917
2021-12-17 18:00:56,451 iteration 5402 : loss : 0.046793, loss_ce: 0.018392
2021-12-17 18:00:57,814 iteration 5403 : loss : 0.054661, loss_ce: 0.019420
2021-12-17 18:00:59,206 iteration 5404 : loss : 0.048684, loss_ce: 0.016464
2021-12-17 18:01:00,674 iteration 5405 : loss : 0.059382, loss_ce: 0.015648
2021-12-17 18:01:01,989 iteration 5406 : loss : 0.051154, loss_ce: 0.018864
 80%|███████████████████████      | 318/400 [2:16:21<33:28, 24.49s/it]2021-12-17 18:01:03,377 iteration 5407 : loss : 0.051630, loss_ce: 0.018788
2021-12-17 18:01:04,719 iteration 5408 : loss : 0.050704, loss_ce: 0.016570
2021-12-17 18:01:06,006 iteration 5409 : loss : 0.052093, loss_ce: 0.015475
2021-12-17 18:01:07,379 iteration 5410 : loss : 0.062926, loss_ce: 0.019262
2021-12-17 18:01:08,701 iteration 5411 : loss : 0.047736, loss_ce: 0.014643
2021-12-17 18:01:10,074 iteration 5412 : loss : 0.051321, loss_ce: 0.016783
2021-12-17 18:01:11,402 iteration 5413 : loss : 0.054332, loss_ce: 0.018480
2021-12-17 18:01:12,769 iteration 5414 : loss : 0.047179, loss_ce: 0.015567
2021-12-17 18:01:14,226 iteration 5415 : loss : 0.062899, loss_ce: 0.019845
2021-12-17 18:01:15,555 iteration 5416 : loss : 0.050221, loss_ce: 0.013056
2021-12-17 18:01:16,909 iteration 5417 : loss : 0.047531, loss_ce: 0.013463
2021-12-17 18:01:18,341 iteration 5418 : loss : 0.059144, loss_ce: 0.024373
2021-12-17 18:01:19,636 iteration 5419 : loss : 0.063693, loss_ce: 0.021921
2021-12-17 18:01:20,939 iteration 5420 : loss : 0.051908, loss_ce: 0.018298
2021-12-17 18:01:22,343 iteration 5421 : loss : 0.075833, loss_ce: 0.027086
2021-12-17 18:01:23,768 iteration 5422 : loss : 0.060806, loss_ce: 0.013551
2021-12-17 18:01:25,174 iteration 5423 : loss : 0.072316, loss_ce: 0.028162
 80%|███████████████████████▏     | 319/400 [2:16:44<32:32, 24.10s/it]2021-12-17 18:01:26,571 iteration 5424 : loss : 0.059398, loss_ce: 0.016387
2021-12-17 18:01:27,893 iteration 5425 : loss : 0.072111, loss_ce: 0.015716
2021-12-17 18:01:29,300 iteration 5426 : loss : 0.064302, loss_ce: 0.024422
2021-12-17 18:01:30,583 iteration 5427 : loss : 0.050321, loss_ce: 0.014562
2021-12-17 18:01:31,912 iteration 5428 : loss : 0.045241, loss_ce: 0.013953
2021-12-17 18:01:33,255 iteration 5429 : loss : 0.060120, loss_ce: 0.019872
2021-12-17 18:01:34,720 iteration 5430 : loss : 0.055043, loss_ce: 0.016284
2021-12-17 18:01:36,071 iteration 5431 : loss : 0.061726, loss_ce: 0.022205
2021-12-17 18:01:37,410 iteration 5432 : loss : 0.054836, loss_ce: 0.019053
2021-12-17 18:01:38,828 iteration 5433 : loss : 0.050964, loss_ce: 0.017544
2021-12-17 18:01:40,180 iteration 5434 : loss : 0.056113, loss_ce: 0.019500
2021-12-17 18:01:41,645 iteration 5435 : loss : 0.070021, loss_ce: 0.024250
2021-12-17 18:01:43,001 iteration 5436 : loss : 0.045784, loss_ce: 0.015090
2021-12-17 18:01:44,251 iteration 5437 : loss : 0.043941, loss_ce: 0.013467
2021-12-17 18:01:45,702 iteration 5438 : loss : 0.057532, loss_ce: 0.019328
2021-12-17 18:01:47,026 iteration 5439 : loss : 0.052595, loss_ce: 0.012442
2021-12-17 18:01:47,026 Training Data Eval:
2021-12-17 18:01:54,120   Average segmentation loss on training set: 0.0383
2021-12-17 18:01:54,120 Validation Data Eval:
2021-12-17 18:01:56,588   Average segmentation loss on validation set: 0.1302
2021-12-17 18:01:58,005 iteration 5440 : loss : 0.078018, loss_ce: 0.020985
 80%|███████████████████████▏     | 320/400 [2:17:17<35:37, 26.72s/it]2021-12-17 18:01:59,329 iteration 5441 : loss : 0.045741, loss_ce: 0.012311
2021-12-17 18:02:00,698 iteration 5442 : loss : 0.064286, loss_ce: 0.019044
2021-12-17 18:02:02,098 iteration 5443 : loss : 0.055216, loss_ce: 0.016902
2021-12-17 18:02:03,480 iteration 5444 : loss : 0.049764, loss_ce: 0.013607
2021-12-17 18:02:04,927 iteration 5445 : loss : 0.085041, loss_ce: 0.029035
2021-12-17 18:02:06,246 iteration 5446 : loss : 0.053650, loss_ce: 0.017306
2021-12-17 18:02:07,582 iteration 5447 : loss : 0.057951, loss_ce: 0.020247
2021-12-17 18:02:08,951 iteration 5448 : loss : 0.061782, loss_ce: 0.018728
2021-12-17 18:02:10,303 iteration 5449 : loss : 0.049488, loss_ce: 0.015082
2021-12-17 18:02:11,725 iteration 5450 : loss : 0.058749, loss_ce: 0.024446
2021-12-17 18:02:13,082 iteration 5451 : loss : 0.057471, loss_ce: 0.020950
2021-12-17 18:02:14,502 iteration 5452 : loss : 0.064109, loss_ce: 0.023698
2021-12-17 18:02:15,881 iteration 5453 : loss : 0.052635, loss_ce: 0.017801
2021-12-17 18:02:17,150 iteration 5454 : loss : 0.042137, loss_ce: 0.015409
2021-12-17 18:02:18,609 iteration 5455 : loss : 0.070950, loss_ce: 0.021684
2021-12-17 18:02:20,027 iteration 5456 : loss : 0.060089, loss_ce: 0.019190
2021-12-17 18:02:21,389 iteration 5457 : loss : 0.049257, loss_ce: 0.014241
 80%|███████████████████████▎     | 321/400 [2:17:40<33:52, 25.72s/it]2021-12-17 18:02:22,777 iteration 5458 : loss : 0.046595, loss_ce: 0.014196
2021-12-17 18:02:24,092 iteration 5459 : loss : 0.050728, loss_ce: 0.016440
2021-12-17 18:02:25,485 iteration 5460 : loss : 0.061514, loss_ce: 0.019144
2021-12-17 18:02:26,879 iteration 5461 : loss : 0.049612, loss_ce: 0.017387
2021-12-17 18:02:28,239 iteration 5462 : loss : 0.050870, loss_ce: 0.012325
2021-12-17 18:02:29,582 iteration 5463 : loss : 0.056681, loss_ce: 0.019017
2021-12-17 18:02:30,925 iteration 5464 : loss : 0.058563, loss_ce: 0.020115
2021-12-17 18:02:32,242 iteration 5465 : loss : 0.054020, loss_ce: 0.015679
2021-12-17 18:02:33,676 iteration 5466 : loss : 0.053516, loss_ce: 0.018356
2021-12-17 18:02:35,015 iteration 5467 : loss : 0.057078, loss_ce: 0.020928
2021-12-17 18:02:36,381 iteration 5468 : loss : 0.057466, loss_ce: 0.020767
2021-12-17 18:02:37,692 iteration 5469 : loss : 0.044703, loss_ce: 0.013306
2021-12-17 18:02:39,096 iteration 5470 : loss : 0.058374, loss_ce: 0.020253
2021-12-17 18:02:40,468 iteration 5471 : loss : 0.049668, loss_ce: 0.014454
2021-12-17 18:02:41,874 iteration 5472 : loss : 0.056777, loss_ce: 0.016976
2021-12-17 18:02:43,267 iteration 5473 : loss : 0.072531, loss_ce: 0.021343
2021-12-17 18:02:44,668 iteration 5474 : loss : 0.057013, loss_ce: 0.021566
 80%|███████████████████████▎     | 322/400 [2:18:03<32:29, 24.99s/it]2021-12-17 18:02:46,070 iteration 5475 : loss : 0.045191, loss_ce: 0.011187
2021-12-17 18:02:47,409 iteration 5476 : loss : 0.062541, loss_ce: 0.017689
2021-12-17 18:02:48,743 iteration 5477 : loss : 0.049550, loss_ce: 0.015900
2021-12-17 18:02:50,100 iteration 5478 : loss : 0.049335, loss_ce: 0.018124
2021-12-17 18:02:51,552 iteration 5479 : loss : 0.061744, loss_ce: 0.024641
2021-12-17 18:02:52,974 iteration 5480 : loss : 0.087253, loss_ce: 0.036524
2021-12-17 18:02:54,332 iteration 5481 : loss : 0.047206, loss_ce: 0.011676
2021-12-17 18:02:55,680 iteration 5482 : loss : 0.047141, loss_ce: 0.014600
2021-12-17 18:02:57,051 iteration 5483 : loss : 0.054615, loss_ce: 0.018112
2021-12-17 18:02:58,395 iteration 5484 : loss : 0.053623, loss_ce: 0.019065
2021-12-17 18:02:59,674 iteration 5485 : loss : 0.048817, loss_ce: 0.014956
2021-12-17 18:03:01,115 iteration 5486 : loss : 0.064483, loss_ce: 0.022778
2021-12-17 18:03:02,609 iteration 5487 : loss : 0.059573, loss_ce: 0.018963
2021-12-17 18:03:03,967 iteration 5488 : loss : 0.059102, loss_ce: 0.018951
2021-12-17 18:03:05,318 iteration 5489 : loss : 0.052812, loss_ce: 0.018928
2021-12-17 18:03:06,649 iteration 5490 : loss : 0.083106, loss_ce: 0.024319
2021-12-17 18:03:07,996 iteration 5491 : loss : 0.054936, loss_ce: 0.019003
 81%|███████████████████████▍     | 323/400 [2:18:27<31:25, 24.49s/it]2021-12-17 18:03:09,412 iteration 5492 : loss : 0.070755, loss_ce: 0.023254
2021-12-17 18:03:10,749 iteration 5493 : loss : 0.050392, loss_ce: 0.018186
2021-12-17 18:03:12,062 iteration 5494 : loss : 0.061356, loss_ce: 0.014743
2021-12-17 18:03:13,479 iteration 5495 : loss : 0.111075, loss_ce: 0.019699
2021-12-17 18:03:14,805 iteration 5496 : loss : 0.065219, loss_ce: 0.017870
2021-12-17 18:03:16,167 iteration 5497 : loss : 0.049592, loss_ce: 0.013033
2021-12-17 18:03:17,554 iteration 5498 : loss : 0.063867, loss_ce: 0.030727
2021-12-17 18:03:18,912 iteration 5499 : loss : 0.063332, loss_ce: 0.019837
2021-12-17 18:03:20,290 iteration 5500 : loss : 0.058974, loss_ce: 0.020374
2021-12-17 18:03:21,731 iteration 5501 : loss : 0.058161, loss_ce: 0.022273
2021-12-17 18:03:23,129 iteration 5502 : loss : 0.065113, loss_ce: 0.022224
2021-12-17 18:03:24,466 iteration 5503 : loss : 0.050397, loss_ce: 0.012759
2021-12-17 18:03:25,853 iteration 5504 : loss : 0.056002, loss_ce: 0.022687
2021-12-17 18:03:27,216 iteration 5505 : loss : 0.054499, loss_ce: 0.017742
2021-12-17 18:03:28,539 iteration 5506 : loss : 0.053380, loss_ce: 0.017882
2021-12-17 18:03:29,923 iteration 5507 : loss : 0.069788, loss_ce: 0.022668
2021-12-17 18:03:31,286 iteration 5508 : loss : 0.056735, loss_ce: 0.019480
 81%|███████████████████████▍     | 324/400 [2:18:50<30:33, 24.13s/it]2021-12-17 18:03:32,687 iteration 5509 : loss : 0.048052, loss_ce: 0.014244
2021-12-17 18:03:34,164 iteration 5510 : loss : 0.063327, loss_ce: 0.019179
2021-12-17 18:03:35,541 iteration 5511 : loss : 0.077450, loss_ce: 0.034356
2021-12-17 18:03:36,959 iteration 5512 : loss : 0.060721, loss_ce: 0.011975
2021-12-17 18:03:38,279 iteration 5513 : loss : 0.054504, loss_ce: 0.011405
2021-12-17 18:03:39,681 iteration 5514 : loss : 0.051983, loss_ce: 0.016907
2021-12-17 18:03:41,116 iteration 5515 : loss : 0.066362, loss_ce: 0.019920
2021-12-17 18:03:42,406 iteration 5516 : loss : 0.044703, loss_ce: 0.015019
2021-12-17 18:03:43,800 iteration 5517 : loss : 0.059589, loss_ce: 0.017595
2021-12-17 18:03:45,154 iteration 5518 : loss : 0.064779, loss_ce: 0.022799
2021-12-17 18:03:46,500 iteration 5519 : loss : 0.054481, loss_ce: 0.017301
2021-12-17 18:03:47,889 iteration 5520 : loss : 0.067087, loss_ce: 0.022412
2021-12-17 18:03:49,367 iteration 5521 : loss : 0.064704, loss_ce: 0.021299
2021-12-17 18:03:50,663 iteration 5522 : loss : 0.046630, loss_ce: 0.016460
2021-12-17 18:03:52,030 iteration 5523 : loss : 0.064118, loss_ce: 0.024546
2021-12-17 18:03:53,406 iteration 5524 : loss : 0.060738, loss_ce: 0.024735
2021-12-17 18:03:53,407 Training Data Eval:
2021-12-17 18:04:00,492   Average segmentation loss on training set: 0.0378
2021-12-17 18:04:00,492 Validation Data Eval:
2021-12-17 18:04:02,951   Average segmentation loss on validation set: 0.1311
2021-12-17 18:04:04,376 iteration 5525 : loss : 0.068797, loss_ce: 0.025162
 81%|███████████████████████▌     | 325/400 [2:19:23<33:31, 26.82s/it]2021-12-17 18:04:05,881 iteration 5526 : loss : 0.069921, loss_ce: 0.024083
2021-12-17 18:04:07,217 iteration 5527 : loss : 0.055373, loss_ce: 0.016087
2021-12-17 18:04:08,609 iteration 5528 : loss : 0.055708, loss_ce: 0.017966
2021-12-17 18:04:09,956 iteration 5529 : loss : 0.055455, loss_ce: 0.014068
2021-12-17 18:04:11,265 iteration 5530 : loss : 0.053475, loss_ce: 0.012888
2021-12-17 18:04:12,639 iteration 5531 : loss : 0.046644, loss_ce: 0.014782
2021-12-17 18:04:13,929 iteration 5532 : loss : 0.077483, loss_ce: 0.024570
2021-12-17 18:04:15,324 iteration 5533 : loss : 0.058335, loss_ce: 0.019460
2021-12-17 18:04:16,708 iteration 5534 : loss : 0.058032, loss_ce: 0.017113
2021-12-17 18:04:18,094 iteration 5535 : loss : 0.056491, loss_ce: 0.018495
2021-12-17 18:04:19,440 iteration 5536 : loss : 0.053608, loss_ce: 0.014383
2021-12-17 18:04:20,802 iteration 5537 : loss : 0.048502, loss_ce: 0.013371
2021-12-17 18:04:22,153 iteration 5538 : loss : 0.048459, loss_ce: 0.020014
2021-12-17 18:04:23,531 iteration 5539 : loss : 0.055079, loss_ce: 0.018471
2021-12-17 18:04:24,917 iteration 5540 : loss : 0.048819, loss_ce: 0.014811
2021-12-17 18:04:26,210 iteration 5541 : loss : 0.052952, loss_ce: 0.016810
2021-12-17 18:04:27,548 iteration 5542 : loss : 0.056225, loss_ce: 0.019674
 82%|███████████████████████▋     | 326/400 [2:19:46<31:43, 25.72s/it]2021-12-17 18:04:29,015 iteration 5543 : loss : 0.073604, loss_ce: 0.027223
2021-12-17 18:04:30,471 iteration 5544 : loss : 0.061186, loss_ce: 0.015726
2021-12-17 18:04:31,894 iteration 5545 : loss : 0.060074, loss_ce: 0.018678
2021-12-17 18:04:33,187 iteration 5546 : loss : 0.045669, loss_ce: 0.016962
2021-12-17 18:04:34,569 iteration 5547 : loss : 0.046533, loss_ce: 0.016073
2021-12-17 18:04:35,903 iteration 5548 : loss : 0.053197, loss_ce: 0.016305
2021-12-17 18:04:37,254 iteration 5549 : loss : 0.053283, loss_ce: 0.019069
2021-12-17 18:04:38,640 iteration 5550 : loss : 0.059856, loss_ce: 0.019404
2021-12-17 18:04:40,057 iteration 5551 : loss : 0.056932, loss_ce: 0.013524
2021-12-17 18:04:41,506 iteration 5552 : loss : 0.071758, loss_ce: 0.021711
2021-12-17 18:04:42,884 iteration 5553 : loss : 0.061879, loss_ce: 0.019758
2021-12-17 18:04:44,322 iteration 5554 : loss : 0.075979, loss_ce: 0.021001
2021-12-17 18:04:45,746 iteration 5555 : loss : 0.061994, loss_ce: 0.021589
2021-12-17 18:04:47,148 iteration 5556 : loss : 0.057100, loss_ce: 0.020301
2021-12-17 18:04:48,538 iteration 5557 : loss : 0.060578, loss_ce: 0.017843
2021-12-17 18:04:49,882 iteration 5558 : loss : 0.074792, loss_ce: 0.023392
2021-12-17 18:04:51,176 iteration 5559 : loss : 0.049759, loss_ce: 0.014210
 82%|███████████████████████▋     | 327/400 [2:20:10<30:31, 25.10s/it]2021-12-17 18:04:52,580 iteration 5560 : loss : 0.054122, loss_ce: 0.016547
2021-12-17 18:04:54,016 iteration 5561 : loss : 0.077803, loss_ce: 0.020399
2021-12-17 18:04:55,400 iteration 5562 : loss : 0.055124, loss_ce: 0.015912
2021-12-17 18:04:56,821 iteration 5563 : loss : 0.066390, loss_ce: 0.018981
2021-12-17 18:04:58,116 iteration 5564 : loss : 0.063427, loss_ce: 0.019162
2021-12-17 18:04:59,501 iteration 5565 : loss : 0.064776, loss_ce: 0.016740
2021-12-17 18:05:00,831 iteration 5566 : loss : 0.053267, loss_ce: 0.015262
2021-12-17 18:05:02,239 iteration 5567 : loss : 0.047437, loss_ce: 0.017498
2021-12-17 18:05:03,651 iteration 5568 : loss : 0.078993, loss_ce: 0.034560
2021-12-17 18:05:05,065 iteration 5569 : loss : 0.058772, loss_ce: 0.022192
2021-12-17 18:05:06,435 iteration 5570 : loss : 0.058924, loss_ce: 0.025050
2021-12-17 18:05:07,803 iteration 5571 : loss : 0.048092, loss_ce: 0.011438
2021-12-17 18:05:09,086 iteration 5572 : loss : 0.046434, loss_ce: 0.014914
2021-12-17 18:05:10,488 iteration 5573 : loss : 0.058652, loss_ce: 0.021578
2021-12-17 18:05:11,814 iteration 5574 : loss : 0.047960, loss_ce: 0.015767
2021-12-17 18:05:13,123 iteration 5575 : loss : 0.044379, loss_ce: 0.013866
2021-12-17 18:05:14,400 iteration 5576 : loss : 0.049161, loss_ce: 0.013374
 82%|███████████████████████▊     | 328/400 [2:20:33<29:26, 24.53s/it]2021-12-17 18:05:15,868 iteration 5577 : loss : 0.066689, loss_ce: 0.020188
2021-12-17 18:05:17,241 iteration 5578 : loss : 0.060790, loss_ce: 0.021344
2021-12-17 18:05:18,693 iteration 5579 : loss : 0.062645, loss_ce: 0.013723
2021-12-17 18:05:20,097 iteration 5580 : loss : 0.067632, loss_ce: 0.020893
2021-12-17 18:05:21,470 iteration 5581 : loss : 0.060630, loss_ce: 0.023920
2021-12-17 18:05:22,819 iteration 5582 : loss : 0.054555, loss_ce: 0.020403
2021-12-17 18:05:24,137 iteration 5583 : loss : 0.048301, loss_ce: 0.012464
2021-12-17 18:05:25,496 iteration 5584 : loss : 0.064987, loss_ce: 0.023678
2021-12-17 18:05:26,804 iteration 5585 : loss : 0.046919, loss_ce: 0.014145
2021-12-17 18:05:28,135 iteration 5586 : loss : 0.049741, loss_ce: 0.018988
2021-12-17 18:05:29,582 iteration 5587 : loss : 0.068527, loss_ce: 0.024568
2021-12-17 18:05:30,940 iteration 5588 : loss : 0.055234, loss_ce: 0.019373
2021-12-17 18:05:32,360 iteration 5589 : loss : 0.059785, loss_ce: 0.017104
2021-12-17 18:05:33,667 iteration 5590 : loss : 0.052764, loss_ce: 0.020894
2021-12-17 18:05:35,059 iteration 5591 : loss : 0.074552, loss_ce: 0.024864
2021-12-17 18:05:36,434 iteration 5592 : loss : 0.062095, loss_ce: 0.019647
2021-12-17 18:05:37,710 iteration 5593 : loss : 0.048882, loss_ce: 0.020357
 82%|███████████████████████▊     | 329/400 [2:20:56<28:35, 24.16s/it]2021-12-17 18:05:39,116 iteration 5594 : loss : 0.054196, loss_ce: 0.012559
2021-12-17 18:05:40,434 iteration 5595 : loss : 0.043614, loss_ce: 0.013489
2021-12-17 18:05:41,868 iteration 5596 : loss : 0.056464, loss_ce: 0.015252
2021-12-17 18:05:43,245 iteration 5597 : loss : 0.059843, loss_ce: 0.020696
2021-12-17 18:05:44,722 iteration 5598 : loss : 0.065937, loss_ce: 0.027954
2021-12-17 18:05:46,161 iteration 5599 : loss : 0.058004, loss_ce: 0.017943
2021-12-17 18:05:47,474 iteration 5600 : loss : 0.048912, loss_ce: 0.014720
2021-12-17 18:05:48,866 iteration 5601 : loss : 0.063924, loss_ce: 0.018176
2021-12-17 18:05:50,236 iteration 5602 : loss : 0.055802, loss_ce: 0.015538
2021-12-17 18:05:51,599 iteration 5603 : loss : 0.057448, loss_ce: 0.022624
2021-12-17 18:05:52,971 iteration 5604 : loss : 0.083047, loss_ce: 0.025123
2021-12-17 18:05:54,303 iteration 5605 : loss : 0.050643, loss_ce: 0.018592
2021-12-17 18:05:55,699 iteration 5606 : loss : 0.068601, loss_ce: 0.020220
2021-12-17 18:05:57,028 iteration 5607 : loss : 0.050868, loss_ce: 0.018591
2021-12-17 18:05:58,422 iteration 5608 : loss : 0.047709, loss_ce: 0.017208
2021-12-17 18:05:59,746 iteration 5609 : loss : 0.059967, loss_ce: 0.018683
2021-12-17 18:05:59,746 Training Data Eval:
2021-12-17 18:06:06,880   Average segmentation loss on training set: 0.0381
2021-12-17 18:06:06,881 Validation Data Eval:
2021-12-17 18:06:09,325   Average segmentation loss on validation set: 0.1299
2021-12-17 18:06:10,718 iteration 5610 : loss : 0.059574, loss_ce: 0.021645
 82%|███████████████████████▉     | 330/400 [2:21:29<31:17, 26.82s/it]2021-12-17 18:06:12,087 iteration 5611 : loss : 0.040639, loss_ce: 0.013414
2021-12-17 18:06:13,502 iteration 5612 : loss : 0.072543, loss_ce: 0.022720
2021-12-17 18:06:14,850 iteration 5613 : loss : 0.061034, loss_ce: 0.010788
2021-12-17 18:06:16,192 iteration 5614 : loss : 0.054551, loss_ce: 0.017826
2021-12-17 18:06:17,557 iteration 5615 : loss : 0.068500, loss_ce: 0.031577
2021-12-17 18:06:18,930 iteration 5616 : loss : 0.045944, loss_ce: 0.011463
2021-12-17 18:06:20,430 iteration 5617 : loss : 0.078620, loss_ce: 0.021473
2021-12-17 18:06:21,837 iteration 5618 : loss : 0.058261, loss_ce: 0.014758
2021-12-17 18:06:23,206 iteration 5619 : loss : 0.048979, loss_ce: 0.017352
2021-12-17 18:06:24,521 iteration 5620 : loss : 0.056363, loss_ce: 0.019737
2021-12-17 18:06:25,837 iteration 5621 : loss : 0.071979, loss_ce: 0.024616
2021-12-17 18:06:27,120 iteration 5622 : loss : 0.044845, loss_ce: 0.016193
2021-12-17 18:06:28,530 iteration 5623 : loss : 0.054457, loss_ce: 0.017484
2021-12-17 18:06:29,870 iteration 5624 : loss : 0.046040, loss_ce: 0.015447
2021-12-17 18:06:31,222 iteration 5625 : loss : 0.063207, loss_ce: 0.024821
2021-12-17 18:06:32,607 iteration 5626 : loss : 0.050795, loss_ce: 0.016652
2021-12-17 18:06:33,957 iteration 5627 : loss : 0.064542, loss_ce: 0.023138
 83%|███████████████████████▉     | 331/400 [2:21:53<29:36, 25.74s/it]2021-12-17 18:06:35,369 iteration 5628 : loss : 0.044945, loss_ce: 0.014200
2021-12-17 18:06:36,743 iteration 5629 : loss : 0.061685, loss_ce: 0.021432
2021-12-17 18:06:38,124 iteration 5630 : loss : 0.055946, loss_ce: 0.018907
2021-12-17 18:06:39,512 iteration 5631 : loss : 0.059105, loss_ce: 0.023592
2021-12-17 18:06:40,944 iteration 5632 : loss : 0.055361, loss_ce: 0.017565
2021-12-17 18:06:42,235 iteration 5633 : loss : 0.060917, loss_ce: 0.013837
2021-12-17 18:06:43,658 iteration 5634 : loss : 0.081572, loss_ce: 0.019570
2021-12-17 18:06:45,011 iteration 5635 : loss : 0.055427, loss_ce: 0.018478
2021-12-17 18:06:46,320 iteration 5636 : loss : 0.050635, loss_ce: 0.013176
2021-12-17 18:06:47,770 iteration 5637 : loss : 0.056542, loss_ce: 0.019996
2021-12-17 18:06:49,125 iteration 5638 : loss : 0.052335, loss_ce: 0.020015
2021-12-17 18:06:50,508 iteration 5639 : loss : 0.065304, loss_ce: 0.018750
2021-12-17 18:06:51,877 iteration 5640 : loss : 0.062268, loss_ce: 0.020835
2021-12-17 18:06:53,196 iteration 5641 : loss : 0.048632, loss_ce: 0.014595
2021-12-17 18:06:54,654 iteration 5642 : loss : 0.065700, loss_ce: 0.026123
2021-12-17 18:06:55,938 iteration 5643 : loss : 0.052561, loss_ce: 0.019357
2021-12-17 18:06:57,287 iteration 5644 : loss : 0.060895, loss_ce: 0.024551
 83%|████████████████████████     | 332/400 [2:22:16<28:21, 25.02s/it]2021-12-17 18:06:58,651 iteration 5645 : loss : 0.050905, loss_ce: 0.015030
2021-12-17 18:06:59,994 iteration 5646 : loss : 0.051678, loss_ce: 0.013874
2021-12-17 18:07:01,303 iteration 5647 : loss : 0.044975, loss_ce: 0.012957
2021-12-17 18:07:02,660 iteration 5648 : loss : 0.064338, loss_ce: 0.024962
2021-12-17 18:07:03,982 iteration 5649 : loss : 0.044871, loss_ce: 0.010982
2021-12-17 18:07:05,400 iteration 5650 : loss : 0.055498, loss_ce: 0.018916
2021-12-17 18:07:06,753 iteration 5651 : loss : 0.055684, loss_ce: 0.021225
2021-12-17 18:07:08,129 iteration 5652 : loss : 0.049961, loss_ce: 0.014048
2021-12-17 18:07:09,476 iteration 5653 : loss : 0.051655, loss_ce: 0.013196
2021-12-17 18:07:10,825 iteration 5654 : loss : 0.050661, loss_ce: 0.016331
2021-12-17 18:07:12,105 iteration 5655 : loss : 0.049114, loss_ce: 0.019649
2021-12-17 18:07:13,552 iteration 5656 : loss : 0.071825, loss_ce: 0.019854
2021-12-17 18:07:14,962 iteration 5657 : loss : 0.060594, loss_ce: 0.018818
2021-12-17 18:07:16,368 iteration 5658 : loss : 0.073441, loss_ce: 0.027477
2021-12-17 18:07:17,700 iteration 5659 : loss : 0.053144, loss_ce: 0.017915
2021-12-17 18:07:19,098 iteration 5660 : loss : 0.060256, loss_ce: 0.016916
2021-12-17 18:07:20,464 iteration 5661 : loss : 0.048257, loss_ce: 0.016674
 83%|████████████████████████▏    | 333/400 [2:22:39<27:19, 24.47s/it]2021-12-17 18:07:21,874 iteration 5662 : loss : 0.061974, loss_ce: 0.020665
2021-12-17 18:07:23,205 iteration 5663 : loss : 0.056669, loss_ce: 0.016255
2021-12-17 18:07:24,574 iteration 5664 : loss : 0.053027, loss_ce: 0.020646
2021-12-17 18:07:25,891 iteration 5665 : loss : 0.046563, loss_ce: 0.015228
2021-12-17 18:07:27,266 iteration 5666 : loss : 0.081582, loss_ce: 0.016824
2021-12-17 18:07:28,664 iteration 5667 : loss : 0.049807, loss_ce: 0.015595
2021-12-17 18:07:30,044 iteration 5668 : loss : 0.050464, loss_ce: 0.014197
2021-12-17 18:07:31,344 iteration 5669 : loss : 0.048286, loss_ce: 0.015663
2021-12-17 18:07:32,679 iteration 5670 : loss : 0.048072, loss_ce: 0.014524
2021-12-17 18:07:33,998 iteration 5671 : loss : 0.055341, loss_ce: 0.019061
2021-12-17 18:07:35,451 iteration 5672 : loss : 0.070608, loss_ce: 0.026027
2021-12-17 18:07:36,787 iteration 5673 : loss : 0.056872, loss_ce: 0.018457
2021-12-17 18:07:38,136 iteration 5674 : loss : 0.051016, loss_ce: 0.013603
2021-12-17 18:07:39,466 iteration 5675 : loss : 0.049743, loss_ce: 0.018413
2021-12-17 18:07:40,892 iteration 5676 : loss : 0.056618, loss_ce: 0.018806
2021-12-17 18:07:42,236 iteration 5677 : loss : 0.054995, loss_ce: 0.012759
2021-12-17 18:07:43,682 iteration 5678 : loss : 0.053020, loss_ce: 0.017392
 84%|████████████████████████▏    | 334/400 [2:23:02<26:29, 24.09s/it]2021-12-17 18:07:45,129 iteration 5679 : loss : 0.051236, loss_ce: 0.017192
2021-12-17 18:07:46,447 iteration 5680 : loss : 0.054509, loss_ce: 0.018322
2021-12-17 18:07:47,827 iteration 5681 : loss : 0.056113, loss_ce: 0.021860
2021-12-17 18:07:49,179 iteration 5682 : loss : 0.054759, loss_ce: 0.017634
2021-12-17 18:07:50,575 iteration 5683 : loss : 0.066426, loss_ce: 0.023597
2021-12-17 18:07:52,009 iteration 5684 : loss : 0.066266, loss_ce: 0.021153
2021-12-17 18:07:53,407 iteration 5685 : loss : 0.054092, loss_ce: 0.014380
2021-12-17 18:07:54,771 iteration 5686 : loss : 0.068354, loss_ce: 0.027641
2021-12-17 18:07:56,093 iteration 5687 : loss : 0.053501, loss_ce: 0.011311
2021-12-17 18:07:57,452 iteration 5688 : loss : 0.057870, loss_ce: 0.015002
2021-12-17 18:07:58,802 iteration 5689 : loss : 0.051899, loss_ce: 0.020082
2021-12-17 18:08:00,193 iteration 5690 : loss : 0.075756, loss_ce: 0.043827
2021-12-17 18:08:01,533 iteration 5691 : loss : 0.052738, loss_ce: 0.014043
2021-12-17 18:08:02,846 iteration 5692 : loss : 0.046029, loss_ce: 0.013577
2021-12-17 18:08:04,238 iteration 5693 : loss : 0.065566, loss_ce: 0.025281
2021-12-17 18:08:05,646 iteration 5694 : loss : 0.063988, loss_ce: 0.025098
2021-12-17 18:08:05,646 Training Data Eval:
2021-12-17 18:08:12,710   Average segmentation loss on training set: 0.0377
2021-12-17 18:08:12,710 Validation Data Eval:
2021-12-17 18:08:15,195   Average segmentation loss on validation set: 0.1285
2021-12-17 18:08:16,548 iteration 5695 : loss : 0.063307, loss_ce: 0.020040
 84%|████████████████████████▎    | 335/400 [2:23:35<28:57, 26.73s/it]2021-12-17 18:08:17,961 iteration 5696 : loss : 0.051325, loss_ce: 0.013876
2021-12-17 18:08:19,378 iteration 5697 : loss : 0.059566, loss_ce: 0.019584
2021-12-17 18:08:20,744 iteration 5698 : loss : 0.067442, loss_ce: 0.022883
2021-12-17 18:08:22,179 iteration 5699 : loss : 0.087898, loss_ce: 0.026156
2021-12-17 18:08:23,548 iteration 5700 : loss : 0.054917, loss_ce: 0.017894
2021-12-17 18:08:24,907 iteration 5701 : loss : 0.050803, loss_ce: 0.019550
2021-12-17 18:08:26,285 iteration 5702 : loss : 0.050092, loss_ce: 0.011747
2021-12-17 18:08:27,640 iteration 5703 : loss : 0.049629, loss_ce: 0.017409
2021-12-17 18:08:29,045 iteration 5704 : loss : 0.054378, loss_ce: 0.019650
2021-12-17 18:08:30,433 iteration 5705 : loss : 0.056006, loss_ce: 0.019397
2021-12-17 18:08:31,756 iteration 5706 : loss : 0.052927, loss_ce: 0.010230
2021-12-17 18:08:33,232 iteration 5707 : loss : 0.064199, loss_ce: 0.021696
2021-12-17 18:08:34,576 iteration 5708 : loss : 0.061145, loss_ce: 0.023338
2021-12-17 18:08:35,960 iteration 5709 : loss : 0.057312, loss_ce: 0.023039
2021-12-17 18:08:37,396 iteration 5710 : loss : 0.058480, loss_ce: 0.021032
2021-12-17 18:08:38,726 iteration 5711 : loss : 0.064734, loss_ce: 0.030621
2021-12-17 18:08:40,075 iteration 5712 : loss : 0.054349, loss_ce: 0.019831
 84%|████████████████████████▎    | 336/400 [2:23:59<27:29, 25.77s/it]2021-12-17 18:08:41,449 iteration 5713 : loss : 0.057186, loss_ce: 0.015765
2021-12-17 18:08:42,777 iteration 5714 : loss : 0.064953, loss_ce: 0.019792
2021-12-17 18:08:44,115 iteration 5715 : loss : 0.049760, loss_ce: 0.015973
2021-12-17 18:08:45,489 iteration 5716 : loss : 0.048359, loss_ce: 0.017372
2021-12-17 18:08:46,887 iteration 5717 : loss : 0.064060, loss_ce: 0.022303
2021-12-17 18:08:48,193 iteration 5718 : loss : 0.054466, loss_ce: 0.014664
2021-12-17 18:08:49,590 iteration 5719 : loss : 0.047817, loss_ce: 0.016066
2021-12-17 18:08:50,934 iteration 5720 : loss : 0.051153, loss_ce: 0.018063
2021-12-17 18:08:52,211 iteration 5721 : loss : 0.051895, loss_ce: 0.013399
2021-12-17 18:08:53,568 iteration 5722 : loss : 0.052780, loss_ce: 0.016905
2021-12-17 18:08:54,917 iteration 5723 : loss : 0.054846, loss_ce: 0.017361
2021-12-17 18:08:56,197 iteration 5724 : loss : 0.042941, loss_ce: 0.012226
2021-12-17 18:08:57,590 iteration 5725 : loss : 0.061004, loss_ce: 0.024689
2021-12-17 18:08:58,910 iteration 5726 : loss : 0.052725, loss_ce: 0.019100
2021-12-17 18:09:00,260 iteration 5727 : loss : 0.056444, loss_ce: 0.017078
2021-12-17 18:09:01,603 iteration 5728 : loss : 0.059598, loss_ce: 0.025336
2021-12-17 18:09:02,998 iteration 5729 : loss : 0.052085, loss_ce: 0.017046
 84%|████████████████████████▍    | 337/400 [2:24:22<26:09, 24.91s/it]2021-12-17 18:09:04,428 iteration 5730 : loss : 0.085161, loss_ce: 0.025296
2021-12-17 18:09:05,826 iteration 5731 : loss : 0.049764, loss_ce: 0.016131
2021-12-17 18:09:07,169 iteration 5732 : loss : 0.057828, loss_ce: 0.014515
2021-12-17 18:09:08,497 iteration 5733 : loss : 0.083566, loss_ce: 0.024675
2021-12-17 18:09:09,864 iteration 5734 : loss : 0.060876, loss_ce: 0.015670
2021-12-17 18:09:11,235 iteration 5735 : loss : 0.054651, loss_ce: 0.020837
2021-12-17 18:09:12,581 iteration 5736 : loss : 0.073015, loss_ce: 0.033894
2021-12-17 18:09:13,916 iteration 5737 : loss : 0.064473, loss_ce: 0.022514
2021-12-17 18:09:15,251 iteration 5738 : loss : 0.039531, loss_ce: 0.011957
2021-12-17 18:09:16,564 iteration 5739 : loss : 0.053307, loss_ce: 0.018230
2021-12-17 18:09:17,969 iteration 5740 : loss : 0.059192, loss_ce: 0.017816
2021-12-17 18:09:19,344 iteration 5741 : loss : 0.057960, loss_ce: 0.023806
2021-12-17 18:09:20,710 iteration 5742 : loss : 0.057230, loss_ce: 0.019056
2021-12-17 18:09:22,049 iteration 5743 : loss : 0.061083, loss_ce: 0.023480
2021-12-17 18:09:23,468 iteration 5744 : loss : 0.054106, loss_ce: 0.019073
2021-12-17 18:09:24,824 iteration 5745 : loss : 0.064094, loss_ce: 0.016338
2021-12-17 18:09:26,115 iteration 5746 : loss : 0.048625, loss_ce: 0.010266
 84%|████████████████████████▌    | 338/400 [2:24:45<25:11, 24.38s/it]2021-12-17 18:09:27,563 iteration 5747 : loss : 0.045437, loss_ce: 0.012677
2021-12-17 18:09:28,951 iteration 5748 : loss : 0.058608, loss_ce: 0.016992
2021-12-17 18:09:30,354 iteration 5749 : loss : 0.051644, loss_ce: 0.018201
2021-12-17 18:09:31,788 iteration 5750 : loss : 0.078325, loss_ce: 0.022735
2021-12-17 18:09:33,096 iteration 5751 : loss : 0.062264, loss_ce: 0.023043
2021-12-17 18:09:34,480 iteration 5752 : loss : 0.056337, loss_ce: 0.015007
2021-12-17 18:09:35,816 iteration 5753 : loss : 0.066303, loss_ce: 0.020657
2021-12-17 18:09:37,112 iteration 5754 : loss : 0.051026, loss_ce: 0.016698
2021-12-17 18:09:38,478 iteration 5755 : loss : 0.055994, loss_ce: 0.021283
2021-12-17 18:09:39,844 iteration 5756 : loss : 0.063909, loss_ce: 0.019139
2021-12-17 18:09:41,178 iteration 5757 : loss : 0.048925, loss_ce: 0.020716
2021-12-17 18:09:42,538 iteration 5758 : loss : 0.061835, loss_ce: 0.014887
2021-12-17 18:09:43,915 iteration 5759 : loss : 0.057100, loss_ce: 0.022096
2021-12-17 18:09:45,349 iteration 5760 : loss : 0.061526, loss_ce: 0.019879
2021-12-17 18:09:46,635 iteration 5761 : loss : 0.043228, loss_ce: 0.012958
2021-12-17 18:09:48,154 iteration 5762 : loss : 0.056901, loss_ce: 0.018908
2021-12-17 18:09:49,505 iteration 5763 : loss : 0.051340, loss_ce: 0.017985
 85%|████████████████████████▌    | 339/400 [2:25:08<24:28, 24.08s/it]2021-12-17 18:09:50,931 iteration 5764 : loss : 0.066551, loss_ce: 0.020736
2021-12-17 18:09:52,324 iteration 5765 : loss : 0.066059, loss_ce: 0.016881
2021-12-17 18:09:53,697 iteration 5766 : loss : 0.050075, loss_ce: 0.017928
2021-12-17 18:09:55,075 iteration 5767 : loss : 0.047933, loss_ce: 0.016082
2021-12-17 18:09:56,540 iteration 5768 : loss : 0.064789, loss_ce: 0.018513
2021-12-17 18:09:57,884 iteration 5769 : loss : 0.051647, loss_ce: 0.015599
2021-12-17 18:09:59,237 iteration 5770 : loss : 0.052549, loss_ce: 0.018433
2021-12-17 18:10:00,601 iteration 5771 : loss : 0.060016, loss_ce: 0.022721
2021-12-17 18:10:01,982 iteration 5772 : loss : 0.057927, loss_ce: 0.018300
2021-12-17 18:10:03,412 iteration 5773 : loss : 0.074790, loss_ce: 0.034314
2021-12-17 18:10:04,844 iteration 5774 : loss : 0.058743, loss_ce: 0.022237
2021-12-17 18:10:06,291 iteration 5775 : loss : 0.058362, loss_ce: 0.018216
2021-12-17 18:10:07,614 iteration 5776 : loss : 0.060853, loss_ce: 0.019272
2021-12-17 18:10:08,947 iteration 5777 : loss : 0.056252, loss_ce: 0.019219
2021-12-17 18:10:10,344 iteration 5778 : loss : 0.057576, loss_ce: 0.015875
2021-12-17 18:10:11,698 iteration 5779 : loss : 0.057236, loss_ce: 0.019811
2021-12-17 18:10:11,698 Training Data Eval:
2021-12-17 18:10:18,762   Average segmentation loss on training set: 0.0387
2021-12-17 18:10:18,762 Validation Data Eval:
2021-12-17 18:10:21,204   Average segmentation loss on validation set: 0.1355
2021-12-17 18:10:22,627 iteration 5780 : loss : 0.051093, loss_ce: 0.017192
 85%|████████████████████████▋    | 340/400 [2:25:41<26:47, 26.79s/it]2021-12-17 18:10:24,161 iteration 5781 : loss : 0.079620, loss_ce: 0.022710
2021-12-17 18:10:25,429 iteration 5782 : loss : 0.052599, loss_ce: 0.019689
2021-12-17 18:10:26,744 iteration 5783 : loss : 0.055477, loss_ce: 0.020165
2021-12-17 18:10:28,071 iteration 5784 : loss : 0.046636, loss_ce: 0.013558
2021-12-17 18:10:29,378 iteration 5785 : loss : 0.050871, loss_ce: 0.018573
2021-12-17 18:10:30,758 iteration 5786 : loss : 0.091238, loss_ce: 0.019758
2021-12-17 18:10:32,103 iteration 5787 : loss : 0.049259, loss_ce: 0.015882
2021-12-17 18:10:33,369 iteration 5788 : loss : 0.049830, loss_ce: 0.016690
2021-12-17 18:10:34,670 iteration 5789 : loss : 0.040047, loss_ce: 0.013373
2021-12-17 18:10:36,055 iteration 5790 : loss : 0.042453, loss_ce: 0.013313
2021-12-17 18:10:37,415 iteration 5791 : loss : 0.058488, loss_ce: 0.023323
2021-12-17 18:10:38,734 iteration 5792 : loss : 0.045660, loss_ce: 0.013967
2021-12-17 18:10:40,134 iteration 5793 : loss : 0.056913, loss_ce: 0.015268
2021-12-17 18:10:41,562 iteration 5794 : loss : 0.060689, loss_ce: 0.023686
2021-12-17 18:10:42,890 iteration 5795 : loss : 0.047555, loss_ce: 0.015500
2021-12-17 18:10:44,260 iteration 5796 : loss : 0.046901, loss_ce: 0.015157
2021-12-17 18:10:45,632 iteration 5797 : loss : 0.057167, loss_ce: 0.017900
 85%|████████████████████████▋    | 341/400 [2:26:04<25:13, 25.66s/it]2021-12-17 18:10:47,134 iteration 5798 : loss : 0.051320, loss_ce: 0.013627
2021-12-17 18:10:48,482 iteration 5799 : loss : 0.061644, loss_ce: 0.019789
2021-12-17 18:10:49,819 iteration 5800 : loss : 0.054237, loss_ce: 0.014438
2021-12-17 18:10:51,096 iteration 5801 : loss : 0.047749, loss_ce: 0.013060
2021-12-17 18:10:52,472 iteration 5802 : loss : 0.052949, loss_ce: 0.022513
2021-12-17 18:10:53,768 iteration 5803 : loss : 0.043951, loss_ce: 0.012977
2021-12-17 18:10:55,220 iteration 5804 : loss : 0.083246, loss_ce: 0.024727
2021-12-17 18:10:56,547 iteration 5805 : loss : 0.061978, loss_ce: 0.025492
2021-12-17 18:10:57,856 iteration 5806 : loss : 0.048635, loss_ce: 0.014684
2021-12-17 18:10:59,223 iteration 5807 : loss : 0.046417, loss_ce: 0.015003
2021-12-17 18:11:00,565 iteration 5808 : loss : 0.055278, loss_ce: 0.019914
2021-12-17 18:11:02,015 iteration 5809 : loss : 0.069503, loss_ce: 0.019471
2021-12-17 18:11:03,300 iteration 5810 : loss : 0.065647, loss_ce: 0.014291
2021-12-17 18:11:04,645 iteration 5811 : loss : 0.052023, loss_ce: 0.017622
2021-12-17 18:11:06,036 iteration 5812 : loss : 0.053146, loss_ce: 0.020034
2021-12-17 18:11:07,358 iteration 5813 : loss : 0.053418, loss_ce: 0.015407
2021-12-17 18:11:08,719 iteration 5814 : loss : 0.066535, loss_ce: 0.026380
 86%|████████████████████████▊    | 342/400 [2:26:27<24:03, 24.88s/it]2021-12-17 18:11:10,283 iteration 5815 : loss : 0.070092, loss_ce: 0.026160
2021-12-17 18:11:11,580 iteration 5816 : loss : 0.048893, loss_ce: 0.014037
2021-12-17 18:11:12,945 iteration 5817 : loss : 0.059143, loss_ce: 0.016616
2021-12-17 18:11:14,286 iteration 5818 : loss : 0.063003, loss_ce: 0.016324
2021-12-17 18:11:15,730 iteration 5819 : loss : 0.058438, loss_ce: 0.022548
2021-12-17 18:11:17,079 iteration 5820 : loss : 0.051214, loss_ce: 0.018648
2021-12-17 18:11:18,418 iteration 5821 : loss : 0.057333, loss_ce: 0.016902
2021-12-17 18:11:19,830 iteration 5822 : loss : 0.055868, loss_ce: 0.015234
2021-12-17 18:11:21,207 iteration 5823 : loss : 0.058098, loss_ce: 0.020841
2021-12-17 18:11:22,565 iteration 5824 : loss : 0.061333, loss_ce: 0.018958
2021-12-17 18:11:23,922 iteration 5825 : loss : 0.067959, loss_ce: 0.027861
2021-12-17 18:11:25,251 iteration 5826 : loss : 0.058956, loss_ce: 0.016114
2021-12-17 18:11:26,576 iteration 5827 : loss : 0.060170, loss_ce: 0.015194
2021-12-17 18:11:27,852 iteration 5828 : loss : 0.040809, loss_ce: 0.014854
2021-12-17 18:11:29,219 iteration 5829 : loss : 0.045826, loss_ce: 0.015708
2021-12-17 18:11:30,596 iteration 5830 : loss : 0.064264, loss_ce: 0.027898
2021-12-17 18:11:32,010 iteration 5831 : loss : 0.058268, loss_ce: 0.021262
 86%|████████████████████████▊    | 343/400 [2:26:51<23:11, 24.41s/it]2021-12-17 18:11:33,507 iteration 5832 : loss : 0.061051, loss_ce: 0.022113
2021-12-17 18:11:34,826 iteration 5833 : loss : 0.044125, loss_ce: 0.013106
2021-12-17 18:11:36,248 iteration 5834 : loss : 0.062536, loss_ce: 0.021673
2021-12-17 18:11:37,742 iteration 5835 : loss : 0.083860, loss_ce: 0.028240
2021-12-17 18:11:39,079 iteration 5836 : loss : 0.059857, loss_ce: 0.025376
2021-12-17 18:11:40,503 iteration 5837 : loss : 0.081515, loss_ce: 0.030810
2021-12-17 18:11:41,927 iteration 5838 : loss : 0.064959, loss_ce: 0.018461
2021-12-17 18:11:43,216 iteration 5839 : loss : 0.050554, loss_ce: 0.014984
2021-12-17 18:11:44,759 iteration 5840 : loss : 0.069784, loss_ce: 0.024385
2021-12-17 18:11:46,103 iteration 5841 : loss : 0.047248, loss_ce: 0.015728
2021-12-17 18:11:47,514 iteration 5842 : loss : 0.082096, loss_ce: 0.034620
2021-12-17 18:11:48,936 iteration 5843 : loss : 0.055230, loss_ce: 0.018299
2021-12-17 18:11:50,329 iteration 5844 : loss : 0.062884, loss_ce: 0.018461
2021-12-17 18:11:51,743 iteration 5845 : loss : 0.054668, loss_ce: 0.016501
2021-12-17 18:11:53,111 iteration 5846 : loss : 0.051288, loss_ce: 0.017501
2021-12-17 18:11:54,464 iteration 5847 : loss : 0.059223, loss_ce: 0.018898
2021-12-17 18:11:55,760 iteration 5848 : loss : 0.046348, loss_ce: 0.013162
 86%|████████████████████████▉    | 344/400 [2:27:14<22:35, 24.21s/it]2021-12-17 18:11:57,127 iteration 5849 : loss : 0.046862, loss_ce: 0.013637
2021-12-17 18:11:58,549 iteration 5850 : loss : 0.072559, loss_ce: 0.020225
2021-12-17 18:11:59,860 iteration 5851 : loss : 0.052953, loss_ce: 0.019901
2021-12-17 18:12:01,188 iteration 5852 : loss : 0.049566, loss_ce: 0.015224
2021-12-17 18:12:02,491 iteration 5853 : loss : 0.070501, loss_ce: 0.013688
2021-12-17 18:12:03,856 iteration 5854 : loss : 0.055540, loss_ce: 0.019069
2021-12-17 18:12:05,202 iteration 5855 : loss : 0.066942, loss_ce: 0.016462
2021-12-17 18:12:06,509 iteration 5856 : loss : 0.048428, loss_ce: 0.015785
2021-12-17 18:12:07,887 iteration 5857 : loss : 0.057594, loss_ce: 0.022014
2021-12-17 18:12:09,215 iteration 5858 : loss : 0.058035, loss_ce: 0.014326
2021-12-17 18:12:10,608 iteration 5859 : loss : 0.057161, loss_ce: 0.022837
2021-12-17 18:12:12,000 iteration 5860 : loss : 0.044389, loss_ce: 0.015044
2021-12-17 18:12:13,379 iteration 5861 : loss : 0.051851, loss_ce: 0.018949
2021-12-17 18:12:14,719 iteration 5862 : loss : 0.046068, loss_ce: 0.014991
2021-12-17 18:12:16,069 iteration 5863 : loss : 0.056027, loss_ce: 0.017625
2021-12-17 18:12:17,414 iteration 5864 : loss : 0.048581, loss_ce: 0.015726
2021-12-17 18:12:17,414 Training Data Eval:
2021-12-17 18:12:24,505   Average segmentation loss on training set: 0.0371
2021-12-17 18:12:24,506 Validation Data Eval:
2021-12-17 18:12:26,968   Average segmentation loss on validation set: 0.1305
2021-12-17 18:12:28,311 iteration 5865 : loss : 0.050151, loss_ce: 0.014409
 86%|█████████████████████████    | 345/400 [2:27:47<24:29, 26.71s/it]2021-12-17 18:12:29,754 iteration 5866 : loss : 0.052732, loss_ce: 0.014717
2021-12-17 18:12:31,129 iteration 5867 : loss : 0.052290, loss_ce: 0.019861
2021-12-17 18:12:32,430 iteration 5868 : loss : 0.048005, loss_ce: 0.015043
2021-12-17 18:12:33,769 iteration 5869 : loss : 0.040082, loss_ce: 0.012221
2021-12-17 18:12:35,051 iteration 5870 : loss : 0.047133, loss_ce: 0.014786
2021-12-17 18:12:36,403 iteration 5871 : loss : 0.058391, loss_ce: 0.023940
2021-12-17 18:12:37,758 iteration 5872 : loss : 0.047549, loss_ce: 0.017156
2021-12-17 18:12:39,060 iteration 5873 : loss : 0.047021, loss_ce: 0.016960
2021-12-17 18:12:40,369 iteration 5874 : loss : 0.055460, loss_ce: 0.012280
2021-12-17 18:12:41,803 iteration 5875 : loss : 0.056157, loss_ce: 0.020143
2021-12-17 18:12:43,239 iteration 5876 : loss : 0.063331, loss_ce: 0.023244
2021-12-17 18:12:44,616 iteration 5877 : loss : 0.057616, loss_ce: 0.016802
2021-12-17 18:12:46,025 iteration 5878 : loss : 0.078197, loss_ce: 0.020795
2021-12-17 18:12:47,357 iteration 5879 : loss : 0.069327, loss_ce: 0.021005
2021-12-17 18:12:48,710 iteration 5880 : loss : 0.052763, loss_ce: 0.016870
2021-12-17 18:12:50,108 iteration 5881 : loss : 0.054052, loss_ce: 0.015321
2021-12-17 18:12:51,438 iteration 5882 : loss : 0.045558, loss_ce: 0.013408
 86%|█████████████████████████    | 346/400 [2:28:10<23:04, 25.64s/it]2021-12-17 18:12:52,947 iteration 5883 : loss : 0.072670, loss_ce: 0.020321
2021-12-17 18:12:54,262 iteration 5884 : loss : 0.052579, loss_ce: 0.017466
2021-12-17 18:12:55,674 iteration 5885 : loss : 0.077936, loss_ce: 0.018665
2021-12-17 18:12:56,994 iteration 5886 : loss : 0.046252, loss_ce: 0.014205
2021-12-17 18:12:58,327 iteration 5887 : loss : 0.053379, loss_ce: 0.013456
2021-12-17 18:12:59,597 iteration 5888 : loss : 0.044476, loss_ce: 0.015556
2021-12-17 18:13:00,943 iteration 5889 : loss : 0.061686, loss_ce: 0.021819
2021-12-17 18:13:02,343 iteration 5890 : loss : 0.072706, loss_ce: 0.029937
2021-12-17 18:13:03,741 iteration 5891 : loss : 0.063242, loss_ce: 0.018212
2021-12-17 18:13:05,163 iteration 5892 : loss : 0.059795, loss_ce: 0.028052
2021-12-17 18:13:06,456 iteration 5893 : loss : 0.048905, loss_ce: 0.013066
2021-12-17 18:13:07,789 iteration 5894 : loss : 0.051040, loss_ce: 0.013839
2021-12-17 18:13:09,197 iteration 5895 : loss : 0.061066, loss_ce: 0.023711
2021-12-17 18:13:10,477 iteration 5896 : loss : 0.050205, loss_ce: 0.016531
2021-12-17 18:13:11,850 iteration 5897 : loss : 0.068092, loss_ce: 0.026941
2021-12-17 18:13:13,257 iteration 5898 : loss : 0.059314, loss_ce: 0.022478
2021-12-17 18:13:14,589 iteration 5899 : loss : 0.050758, loss_ce: 0.014457
 87%|█████████████████████████▏   | 347/400 [2:28:33<21:59, 24.89s/it]2021-12-17 18:13:15,904 iteration 5900 : loss : 0.048383, loss_ce: 0.016874
2021-12-17 18:13:17,223 iteration 5901 : loss : 0.043828, loss_ce: 0.016039
2021-12-17 18:13:18,517 iteration 5902 : loss : 0.046075, loss_ce: 0.015493
2021-12-17 18:13:19,853 iteration 5903 : loss : 0.052221, loss_ce: 0.019603
2021-12-17 18:13:21,224 iteration 5904 : loss : 0.063813, loss_ce: 0.016846
2021-12-17 18:13:22,623 iteration 5905 : loss : 0.066907, loss_ce: 0.029791
2021-12-17 18:13:24,035 iteration 5906 : loss : 0.055626, loss_ce: 0.012839
2021-12-17 18:13:25,331 iteration 5907 : loss : 0.044698, loss_ce: 0.016472
2021-12-17 18:13:26,691 iteration 5908 : loss : 0.052514, loss_ce: 0.015757
2021-12-17 18:13:28,083 iteration 5909 : loss : 0.048974, loss_ce: 0.018177
2021-12-17 18:13:29,441 iteration 5910 : loss : 0.056589, loss_ce: 0.014831
2021-12-17 18:13:30,840 iteration 5911 : loss : 0.067488, loss_ce: 0.017418
2021-12-17 18:13:32,213 iteration 5912 : loss : 0.061965, loss_ce: 0.014229
2021-12-17 18:13:33,561 iteration 5913 : loss : 0.048265, loss_ce: 0.017070
2021-12-17 18:13:34,895 iteration 5914 : loss : 0.056137, loss_ce: 0.024447
2021-12-17 18:13:36,275 iteration 5915 : loss : 0.059163, loss_ce: 0.024299
2021-12-17 18:13:37,586 iteration 5916 : loss : 0.050211, loss_ce: 0.015326
 87%|█████████████████████████▏   | 348/400 [2:28:56<21:04, 24.32s/it]2021-12-17 18:13:38,951 iteration 5917 : loss : 0.045690, loss_ce: 0.015203
2021-12-17 18:13:40,374 iteration 5918 : loss : 0.071296, loss_ce: 0.027784
2021-12-17 18:13:41,798 iteration 5919 : loss : 0.060561, loss_ce: 0.020940
2021-12-17 18:13:43,228 iteration 5920 : loss : 0.050590, loss_ce: 0.013691
2021-12-17 18:13:44,579 iteration 5921 : loss : 0.067423, loss_ce: 0.018544
2021-12-17 18:13:45,975 iteration 5922 : loss : 0.067656, loss_ce: 0.028224
2021-12-17 18:13:47,349 iteration 5923 : loss : 0.055108, loss_ce: 0.019798
2021-12-17 18:13:48,635 iteration 5924 : loss : 0.054893, loss_ce: 0.018333
2021-12-17 18:13:49,987 iteration 5925 : loss : 0.048679, loss_ce: 0.014796
2021-12-17 18:13:51,409 iteration 5926 : loss : 0.074294, loss_ce: 0.023342
2021-12-17 18:13:52,737 iteration 5927 : loss : 0.041596, loss_ce: 0.014455
2021-12-17 18:13:54,154 iteration 5928 : loss : 0.049294, loss_ce: 0.016997
2021-12-17 18:13:55,539 iteration 5929 : loss : 0.058656, loss_ce: 0.023651
2021-12-17 18:13:56,963 iteration 5930 : loss : 0.059876, loss_ce: 0.019145
2021-12-17 18:13:58,273 iteration 5931 : loss : 0.058566, loss_ce: 0.021050
2021-12-17 18:13:59,643 iteration 5932 : loss : 0.058949, loss_ce: 0.017527
2021-12-17 18:14:01,040 iteration 5933 : loss : 0.060289, loss_ce: 0.014961
 87%|█████████████████████████▎   | 349/400 [2:29:20<20:27, 24.06s/it]2021-12-17 18:14:02,474 iteration 5934 : loss : 0.043612, loss_ce: 0.012569
2021-12-17 18:14:03,857 iteration 5935 : loss : 0.056429, loss_ce: 0.013275
2021-12-17 18:14:05,326 iteration 5936 : loss : 0.066484, loss_ce: 0.019081
2021-12-17 18:14:06,765 iteration 5937 : loss : 0.054269, loss_ce: 0.021674
2021-12-17 18:14:08,148 iteration 5938 : loss : 0.063284, loss_ce: 0.018550
2021-12-17 18:14:09,486 iteration 5939 : loss : 0.054772, loss_ce: 0.018108
2021-12-17 18:14:10,870 iteration 5940 : loss : 0.058407, loss_ce: 0.022987
2021-12-17 18:14:12,146 iteration 5941 : loss : 0.047116, loss_ce: 0.018166
2021-12-17 18:14:13,545 iteration 5942 : loss : 0.061687, loss_ce: 0.020248
2021-12-17 18:14:14,844 iteration 5943 : loss : 0.041585, loss_ce: 0.013090
2021-12-17 18:14:16,208 iteration 5944 : loss : 0.054608, loss_ce: 0.016701
2021-12-17 18:14:17,551 iteration 5945 : loss : 0.052359, loss_ce: 0.016248
2021-12-17 18:14:18,864 iteration 5946 : loss : 0.057422, loss_ce: 0.019724
2021-12-17 18:14:20,166 iteration 5947 : loss : 0.048717, loss_ce: 0.015113
2021-12-17 18:14:21,582 iteration 5948 : loss : 0.060394, loss_ce: 0.024542
2021-12-17 18:14:22,903 iteration 5949 : loss : 0.053838, loss_ce: 0.020160
2021-12-17 18:14:22,903 Training Data Eval:
2021-12-17 18:14:30,000   Average segmentation loss on training set: 0.0373
2021-12-17 18:14:30,000 Validation Data Eval:
2021-12-17 18:14:32,480   Average segmentation loss on validation set: 0.1251
2021-12-17 18:14:33,923 iteration 5950 : loss : 0.057536, loss_ce: 0.013829
 88%|█████████████████████████▍   | 350/400 [2:29:53<22:15, 26.71s/it]2021-12-17 18:14:35,309 iteration 5951 : loss : 0.047455, loss_ce: 0.011285
2021-12-17 18:14:36,672 iteration 5952 : loss : 0.045702, loss_ce: 0.018755
2021-12-17 18:14:38,060 iteration 5953 : loss : 0.057094, loss_ce: 0.021328
2021-12-17 18:14:39,500 iteration 5954 : loss : 0.057146, loss_ce: 0.016370
2021-12-17 18:14:40,841 iteration 5955 : loss : 0.053555, loss_ce: 0.015672
2021-12-17 18:14:42,268 iteration 5956 : loss : 0.059491, loss_ce: 0.018669
2021-12-17 18:14:43,613 iteration 5957 : loss : 0.052767, loss_ce: 0.014610
2021-12-17 18:14:44,934 iteration 5958 : loss : 0.041556, loss_ce: 0.015428
2021-12-17 18:14:46,292 iteration 5959 : loss : 0.048490, loss_ce: 0.014304
2021-12-17 18:14:47,611 iteration 5960 : loss : 0.040535, loss_ce: 0.010837
2021-12-17 18:14:48,993 iteration 5961 : loss : 0.062795, loss_ce: 0.021531
2021-12-17 18:14:50,396 iteration 5962 : loss : 0.070458, loss_ce: 0.024313
2021-12-17 18:14:51,687 iteration 5963 : loss : 0.046907, loss_ce: 0.017470
2021-12-17 18:14:53,202 iteration 5964 : loss : 0.093990, loss_ce: 0.034691
2021-12-17 18:14:54,519 iteration 5965 : loss : 0.055988, loss_ce: 0.019831
2021-12-17 18:14:55,909 iteration 5966 : loss : 0.057733, loss_ce: 0.020296
2021-12-17 18:14:57,233 iteration 5967 : loss : 0.074811, loss_ce: 0.023454
 88%|█████████████████████████▍   | 351/400 [2:30:16<20:58, 25.69s/it]2021-12-17 18:14:58,637 iteration 5968 : loss : 0.059716, loss_ce: 0.020075
2021-12-17 18:15:00,044 iteration 5969 : loss : 0.060449, loss_ce: 0.014576
2021-12-17 18:15:01,425 iteration 5970 : loss : 0.051949, loss_ce: 0.015907
2021-12-17 18:15:02,709 iteration 5971 : loss : 0.046529, loss_ce: 0.016442
2021-12-17 18:15:04,041 iteration 5972 : loss : 0.049107, loss_ce: 0.017241
2021-12-17 18:15:05,405 iteration 5973 : loss : 0.042379, loss_ce: 0.014308
2021-12-17 18:15:06,720 iteration 5974 : loss : 0.063719, loss_ce: 0.018065
2021-12-17 18:15:08,116 iteration 5975 : loss : 0.062859, loss_ce: 0.018704
2021-12-17 18:15:09,496 iteration 5976 : loss : 0.071726, loss_ce: 0.016786
2021-12-17 18:15:10,888 iteration 5977 : loss : 0.050891, loss_ce: 0.016784
2021-12-17 18:15:12,262 iteration 5978 : loss : 0.049159, loss_ce: 0.018715
2021-12-17 18:15:13,581 iteration 5979 : loss : 0.046208, loss_ce: 0.013524
2021-12-17 18:15:14,977 iteration 5980 : loss : 0.044514, loss_ce: 0.012427
2021-12-17 18:15:16,370 iteration 5981 : loss : 0.066991, loss_ce: 0.020904
2021-12-17 18:15:17,785 iteration 5982 : loss : 0.075011, loss_ce: 0.025625
2021-12-17 18:15:19,072 iteration 5983 : loss : 0.054337, loss_ce: 0.020906
2021-12-17 18:15:20,390 iteration 5984 : loss : 0.061462, loss_ce: 0.018103
 88%|█████████████████████████▌   | 352/400 [2:30:39<19:56, 24.93s/it]2021-12-17 18:15:21,905 iteration 5985 : loss : 0.065699, loss_ce: 0.026395
2021-12-17 18:15:23,220 iteration 5986 : loss : 0.052292, loss_ce: 0.020529
2021-12-17 18:15:24,626 iteration 5987 : loss : 0.102417, loss_ce: 0.018679
2021-12-17 18:15:26,062 iteration 5988 : loss : 0.051911, loss_ce: 0.019637
2021-12-17 18:15:27,416 iteration 5989 : loss : 0.057010, loss_ce: 0.018776
2021-12-17 18:15:28,802 iteration 5990 : loss : 0.061348, loss_ce: 0.028253
2021-12-17 18:15:30,080 iteration 5991 : loss : 0.048708, loss_ce: 0.013783
2021-12-17 18:15:31,481 iteration 5992 : loss : 0.054687, loss_ce: 0.015991
2021-12-17 18:15:32,794 iteration 5993 : loss : 0.037721, loss_ce: 0.009808
2021-12-17 18:15:34,151 iteration 5994 : loss : 0.063305, loss_ce: 0.019069
2021-12-17 18:15:35,536 iteration 5995 : loss : 0.052488, loss_ce: 0.016976
2021-12-17 18:15:36,972 iteration 5996 : loss : 0.054997, loss_ce: 0.016604
2021-12-17 18:15:38,398 iteration 5997 : loss : 0.060531, loss_ce: 0.023393
2021-12-17 18:15:39,728 iteration 5998 : loss : 0.047797, loss_ce: 0.015165
2021-12-17 18:15:41,110 iteration 5999 : loss : 0.077242, loss_ce: 0.020691
2021-12-17 18:15:42,491 iteration 6000 : loss : 0.078799, loss_ce: 0.029752
2021-12-17 18:15:43,915 iteration 6001 : loss : 0.069040, loss_ce: 0.020550
 88%|█████████████████████████▌   | 353/400 [2:31:03<19:11, 24.51s/it]2021-12-17 18:15:45,340 iteration 6002 : loss : 0.046198, loss_ce: 0.016097
2021-12-17 18:15:46,751 iteration 6003 : loss : 0.058726, loss_ce: 0.018843
2021-12-17 18:15:48,119 iteration 6004 : loss : 0.052357, loss_ce: 0.020263
2021-12-17 18:15:49,509 iteration 6005 : loss : 0.052496, loss_ce: 0.019095
2021-12-17 18:15:50,798 iteration 6006 : loss : 0.054654, loss_ce: 0.022445
2021-12-17 18:15:52,152 iteration 6007 : loss : 0.061186, loss_ce: 0.019433
2021-12-17 18:15:53,504 iteration 6008 : loss : 0.057173, loss_ce: 0.018880
2021-12-17 18:15:54,942 iteration 6009 : loss : 0.058704, loss_ce: 0.019037
2021-12-17 18:15:56,218 iteration 6010 : loss : 0.046128, loss_ce: 0.015547
2021-12-17 18:15:57,605 iteration 6011 : loss : 0.067837, loss_ce: 0.020952
2021-12-17 18:15:58,970 iteration 6012 : loss : 0.065593, loss_ce: 0.017728
2021-12-17 18:16:00,435 iteration 6013 : loss : 0.072055, loss_ce: 0.020365
2021-12-17 18:16:01,805 iteration 6014 : loss : 0.046390, loss_ce: 0.015263
2021-12-17 18:16:03,137 iteration 6015 : loss : 0.056431, loss_ce: 0.016784
2021-12-17 18:16:04,503 iteration 6016 : loss : 0.043034, loss_ce: 0.011741
2021-12-17 18:16:05,814 iteration 6017 : loss : 0.062573, loss_ce: 0.013523
2021-12-17 18:16:07,261 iteration 6018 : loss : 0.051619, loss_ce: 0.016100
 88%|█████████████████████████▋   | 354/400 [2:31:26<18:31, 24.16s/it]2021-12-17 18:16:08,723 iteration 6019 : loss : 0.061179, loss_ce: 0.021620
2021-12-17 18:16:10,079 iteration 6020 : loss : 0.052187, loss_ce: 0.019772
2021-12-17 18:16:11,438 iteration 6021 : loss : 0.051549, loss_ce: 0.015110
2021-12-17 18:16:12,809 iteration 6022 : loss : 0.045772, loss_ce: 0.015166
2021-12-17 18:16:14,098 iteration 6023 : loss : 0.046561, loss_ce: 0.014568
2021-12-17 18:16:15,519 iteration 6024 : loss : 0.062064, loss_ce: 0.021893
2021-12-17 18:16:16,933 iteration 6025 : loss : 0.083201, loss_ce: 0.024495
2021-12-17 18:16:18,329 iteration 6026 : loss : 0.057468, loss_ce: 0.018364
2021-12-17 18:16:19,657 iteration 6027 : loss : 0.049132, loss_ce: 0.016211
2021-12-17 18:16:20,970 iteration 6028 : loss : 0.055649, loss_ce: 0.018048
2021-12-17 18:16:22,370 iteration 6029 : loss : 0.070795, loss_ce: 0.026717
2021-12-17 18:16:23,691 iteration 6030 : loss : 0.053612, loss_ce: 0.017143
2021-12-17 18:16:25,145 iteration 6031 : loss : 0.072856, loss_ce: 0.018042
2021-12-17 18:16:26,543 iteration 6032 : loss : 0.051426, loss_ce: 0.014650
2021-12-17 18:16:27,938 iteration 6033 : loss : 0.070980, loss_ce: 0.029533
2021-12-17 18:16:29,377 iteration 6034 : loss : 0.048919, loss_ce: 0.014960
2021-12-17 18:16:29,377 Training Data Eval:
2021-12-17 18:16:36,443   Average segmentation loss on training set: 0.0365
2021-12-17 18:16:36,443 Validation Data Eval:
2021-12-17 18:16:38,887   Average segmentation loss on validation set: 0.1236
2021-12-17 18:16:45,263 Found new lowest validation loss at iteration 6034! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/TU_3seeds/TU_RESNET_no_pretraining_SGD_best_val_loss_seed100.pth
2021-12-17 18:16:46,585 iteration 6035 : loss : 0.048344, loss_ce: 0.011357
 89%|█████████████████████████▋   | 355/400 [2:32:05<21:31, 28.71s/it]2021-12-17 18:16:47,987 iteration 6036 : loss : 0.059194, loss_ce: 0.019050
2021-12-17 18:16:49,366 iteration 6037 : loss : 0.067090, loss_ce: 0.022030
2021-12-17 18:16:50,655 iteration 6038 : loss : 0.060681, loss_ce: 0.019812
2021-12-17 18:16:51,981 iteration 6039 : loss : 0.057086, loss_ce: 0.022374
2021-12-17 18:16:53,293 iteration 6040 : loss : 0.048747, loss_ce: 0.018333
2021-12-17 18:16:54,723 iteration 6041 : loss : 0.077055, loss_ce: 0.026519
2021-12-17 18:16:56,106 iteration 6042 : loss : 0.053431, loss_ce: 0.017209
2021-12-17 18:16:57,432 iteration 6043 : loss : 0.045673, loss_ce: 0.017881
2021-12-17 18:16:58,735 iteration 6044 : loss : 0.046942, loss_ce: 0.012681
2021-12-17 18:17:00,107 iteration 6045 : loss : 0.060954, loss_ce: 0.019903
2021-12-17 18:17:01,436 iteration 6046 : loss : 0.060532, loss_ce: 0.019215
2021-12-17 18:17:02,728 iteration 6047 : loss : 0.064381, loss_ce: 0.017748
2021-12-17 18:17:04,152 iteration 6048 : loss : 0.084621, loss_ce: 0.015837
2021-12-17 18:17:05,526 iteration 6049 : loss : 0.051543, loss_ce: 0.019497
2021-12-17 18:17:06,822 iteration 6050 : loss : 0.054836, loss_ce: 0.019976
2021-12-17 18:17:08,203 iteration 6051 : loss : 0.049726, loss_ce: 0.017198
2021-12-17 18:17:09,445 iteration 6052 : loss : 0.042358, loss_ce: 0.009780
 89%|█████████████████████████▊   | 356/400 [2:32:28<19:45, 26.95s/it]2021-12-17 18:17:10,788 iteration 6053 : loss : 0.051609, loss_ce: 0.019590
2021-12-17 18:17:12,259 iteration 6054 : loss : 0.079638, loss_ce: 0.025207
2021-12-17 18:17:13,574 iteration 6055 : loss : 0.048451, loss_ce: 0.013717
2021-12-17 18:17:14,912 iteration 6056 : loss : 0.048125, loss_ce: 0.017867
2021-12-17 18:17:16,275 iteration 6057 : loss : 0.053626, loss_ce: 0.016881
2021-12-17 18:17:17,732 iteration 6058 : loss : 0.050784, loss_ce: 0.019693
2021-12-17 18:17:19,078 iteration 6059 : loss : 0.046977, loss_ce: 0.015357
2021-12-17 18:17:20,524 iteration 6060 : loss : 0.046550, loss_ce: 0.016430
2021-12-17 18:17:21,861 iteration 6061 : loss : 0.059997, loss_ce: 0.023358
2021-12-17 18:17:23,323 iteration 6062 : loss : 0.064013, loss_ce: 0.026907
2021-12-17 18:17:24,767 iteration 6063 : loss : 0.070382, loss_ce: 0.024426
2021-12-17 18:17:26,146 iteration 6064 : loss : 0.083240, loss_ce: 0.020928
2021-12-17 18:17:27,597 iteration 6065 : loss : 0.078278, loss_ce: 0.032008
2021-12-17 18:17:28,951 iteration 6066 : loss : 0.046624, loss_ce: 0.015313
2021-12-17 18:17:30,291 iteration 6067 : loss : 0.074500, loss_ce: 0.013078
2021-12-17 18:17:31,758 iteration 6068 : loss : 0.071296, loss_ce: 0.022659
2021-12-17 18:17:33,105 iteration 6069 : loss : 0.111155, loss_ce: 0.016463
 89%|█████████████████████████▉   | 357/400 [2:32:52<18:36, 25.97s/it]2021-12-17 18:17:34,567 iteration 6070 : loss : 0.054715, loss_ce: 0.022555
2021-12-17 18:17:35,975 iteration 6071 : loss : 0.058375, loss_ce: 0.015791
2021-12-17 18:17:37,346 iteration 6072 : loss : 0.051431, loss_ce: 0.014426
2021-12-17 18:17:38,740 iteration 6073 : loss : 0.058112, loss_ce: 0.017656
2021-12-17 18:17:40,134 iteration 6074 : loss : 0.055808, loss_ce: 0.017055
2021-12-17 18:17:41,581 iteration 6075 : loss : 0.061468, loss_ce: 0.024196
2021-12-17 18:17:42,933 iteration 6076 : loss : 0.059266, loss_ce: 0.025271
2021-12-17 18:17:44,284 iteration 6077 : loss : 0.058520, loss_ce: 0.023393
2021-12-17 18:17:45,656 iteration 6078 : loss : 0.053101, loss_ce: 0.015261
2021-12-17 18:17:47,036 iteration 6079 : loss : 0.063223, loss_ce: 0.012604
2021-12-17 18:17:48,404 iteration 6080 : loss : 0.055519, loss_ce: 0.016293
2021-12-17 18:17:49,708 iteration 6081 : loss : 0.049136, loss_ce: 0.014866
2021-12-17 18:17:51,142 iteration 6082 : loss : 0.058758, loss_ce: 0.019146
2021-12-17 18:17:52,589 iteration 6083 : loss : 0.078730, loss_ce: 0.027495
2021-12-17 18:17:53,912 iteration 6084 : loss : 0.063076, loss_ce: 0.017046
2021-12-17 18:17:55,249 iteration 6085 : loss : 0.053944, loss_ce: 0.023368
2021-12-17 18:17:56,737 iteration 6086 : loss : 0.086006, loss_ce: 0.033064
 90%|█████████████████████████▉   | 358/400 [2:33:15<17:41, 25.26s/it]2021-12-17 18:17:58,166 iteration 6087 : loss : 0.072094, loss_ce: 0.019710
2021-12-17 18:17:59,540 iteration 6088 : loss : 0.058873, loss_ce: 0.019084
2021-12-17 18:18:00,961 iteration 6089 : loss : 0.065024, loss_ce: 0.024613
2021-12-17 18:18:02,311 iteration 6090 : loss : 0.046151, loss_ce: 0.011781
2021-12-17 18:18:03,646 iteration 6091 : loss : 0.048333, loss_ce: 0.013774
2021-12-17 18:18:05,096 iteration 6092 : loss : 0.065345, loss_ce: 0.021201
2021-12-17 18:18:06,557 iteration 6093 : loss : 0.058448, loss_ce: 0.020737
2021-12-17 18:18:07,984 iteration 6094 : loss : 0.060904, loss_ce: 0.026028
2021-12-17 18:18:09,290 iteration 6095 : loss : 0.050939, loss_ce: 0.013476
2021-12-17 18:18:10,735 iteration 6096 : loss : 0.073569, loss_ce: 0.015951
2021-12-17 18:18:12,072 iteration 6097 : loss : 0.045884, loss_ce: 0.017156
2021-12-17 18:18:13,481 iteration 6098 : loss : 0.053886, loss_ce: 0.023382
2021-12-17 18:18:14,855 iteration 6099 : loss : 0.051078, loss_ce: 0.018600
2021-12-17 18:18:16,247 iteration 6100 : loss : 0.057596, loss_ce: 0.017262
2021-12-17 18:18:17,682 iteration 6101 : loss : 0.064346, loss_ce: 0.024779
2021-12-17 18:18:19,005 iteration 6102 : loss : 0.050779, loss_ce: 0.017573
2021-12-17 18:18:20,396 iteration 6103 : loss : 0.049934, loss_ce: 0.013096
 90%|██████████████████████████   | 359/400 [2:33:39<16:56, 24.78s/it]2021-12-17 18:18:21,858 iteration 6104 : loss : 0.047445, loss_ce: 0.016576
2021-12-17 18:18:23,199 iteration 6105 : loss : 0.054392, loss_ce: 0.014381
2021-12-17 18:18:24,526 iteration 6106 : loss : 0.042441, loss_ce: 0.014348
2021-12-17 18:18:25,850 iteration 6107 : loss : 0.042971, loss_ce: 0.014191
2021-12-17 18:18:27,217 iteration 6108 : loss : 0.055906, loss_ce: 0.017691
2021-12-17 18:18:28,630 iteration 6109 : loss : 0.063747, loss_ce: 0.021931
2021-12-17 18:18:29,938 iteration 6110 : loss : 0.047893, loss_ce: 0.018615
2021-12-17 18:18:31,320 iteration 6111 : loss : 0.066512, loss_ce: 0.019274
2021-12-17 18:18:32,737 iteration 6112 : loss : 0.068476, loss_ce: 0.015763
2021-12-17 18:18:34,099 iteration 6113 : loss : 0.054485, loss_ce: 0.016283
2021-12-17 18:18:35,475 iteration 6114 : loss : 0.057679, loss_ce: 0.017211
2021-12-17 18:18:36,911 iteration 6115 : loss : 0.057483, loss_ce: 0.014098
2021-12-17 18:18:38,294 iteration 6116 : loss : 0.047679, loss_ce: 0.013401
2021-12-17 18:18:39,633 iteration 6117 : loss : 0.049098, loss_ce: 0.016221
2021-12-17 18:18:41,023 iteration 6118 : loss : 0.062633, loss_ce: 0.026533
2021-12-17 18:18:42,389 iteration 6119 : loss : 0.051552, loss_ce: 0.019502
2021-12-17 18:18:42,389 Training Data Eval:
2021-12-17 18:18:49,525   Average segmentation loss on training set: 0.0368
2021-12-17 18:18:49,525 Validation Data Eval:
2021-12-17 18:18:52,003   Average segmentation loss on validation set: 0.1318
2021-12-17 18:18:53,429 iteration 6120 : loss : 0.062719, loss_ce: 0.022848
 90%|██████████████████████████   | 360/400 [2:34:12<18:10, 27.26s/it]2021-12-17 18:18:54,898 iteration 6121 : loss : 0.053331, loss_ce: 0.015815
2021-12-17 18:18:56,290 iteration 6122 : loss : 0.054339, loss_ce: 0.020848
2021-12-17 18:18:57,651 iteration 6123 : loss : 0.049720, loss_ce: 0.017330
2021-12-17 18:18:59,096 iteration 6124 : loss : 0.058181, loss_ce: 0.015382
2021-12-17 18:19:00,473 iteration 6125 : loss : 0.054236, loss_ce: 0.015942
2021-12-17 18:19:01,941 iteration 6126 : loss : 0.059337, loss_ce: 0.018952
2021-12-17 18:19:03,407 iteration 6127 : loss : 0.077661, loss_ce: 0.034592
2021-12-17 18:19:04,763 iteration 6128 : loss : 0.049404, loss_ce: 0.014616
2021-12-17 18:19:06,087 iteration 6129 : loss : 0.048994, loss_ce: 0.014389
2021-12-17 18:19:07,476 iteration 6130 : loss : 0.073563, loss_ce: 0.026963
2021-12-17 18:19:08,819 iteration 6131 : loss : 0.053349, loss_ce: 0.015056
2021-12-17 18:19:10,239 iteration 6132 : loss : 0.063809, loss_ce: 0.016250
2021-12-17 18:19:11,644 iteration 6133 : loss : 0.057067, loss_ce: 0.020203
2021-12-17 18:19:12,992 iteration 6134 : loss : 0.051796, loss_ce: 0.015909
2021-12-17 18:19:14,317 iteration 6135 : loss : 0.056216, loss_ce: 0.023078
2021-12-17 18:19:15,642 iteration 6136 : loss : 0.048478, loss_ce: 0.013329
2021-12-17 18:19:16,982 iteration 6137 : loss : 0.069456, loss_ce: 0.023009
 90%|██████████████████████████▏  | 361/400 [2:34:36<16:59, 26.15s/it]2021-12-17 18:19:18,360 iteration 6138 : loss : 0.056116, loss_ce: 0.016572
2021-12-17 18:19:19,699 iteration 6139 : loss : 0.053242, loss_ce: 0.010494
2021-12-17 18:19:21,047 iteration 6140 : loss : 0.054167, loss_ce: 0.016122
2021-12-17 18:19:22,364 iteration 6141 : loss : 0.051729, loss_ce: 0.019986
2021-12-17 18:19:23,772 iteration 6142 : loss : 0.047942, loss_ce: 0.015233
2021-12-17 18:19:25,099 iteration 6143 : loss : 0.057935, loss_ce: 0.024023
2021-12-17 18:19:26,542 iteration 6144 : loss : 0.055849, loss_ce: 0.021030
2021-12-17 18:19:27,868 iteration 6145 : loss : 0.052627, loss_ce: 0.019041
2021-12-17 18:19:29,169 iteration 6146 : loss : 0.048603, loss_ce: 0.014268
2021-12-17 18:19:30,523 iteration 6147 : loss : 0.051541, loss_ce: 0.017838
2021-12-17 18:19:31,863 iteration 6148 : loss : 0.056683, loss_ce: 0.022321
2021-12-17 18:19:33,198 iteration 6149 : loss : 0.044073, loss_ce: 0.013185
2021-12-17 18:19:34,605 iteration 6150 : loss : 0.062269, loss_ce: 0.020519
2021-12-17 18:19:36,109 iteration 6151 : loss : 0.057290, loss_ce: 0.013281
2021-12-17 18:19:37,476 iteration 6152 : loss : 0.051309, loss_ce: 0.017082
2021-12-17 18:19:38,865 iteration 6153 : loss : 0.053817, loss_ce: 0.016872
2021-12-17 18:19:40,300 iteration 6154 : loss : 0.062034, loss_ce: 0.019327
 90%|██████████████████████████▏  | 362/400 [2:34:59<16:01, 25.30s/it]2021-12-17 18:19:41,785 iteration 6155 : loss : 0.061020, loss_ce: 0.021455
2021-12-17 18:19:43,098 iteration 6156 : loss : 0.043020, loss_ce: 0.014453
2021-12-17 18:19:44,450 iteration 6157 : loss : 0.050463, loss_ce: 0.013936
2021-12-17 18:19:45,841 iteration 6158 : loss : 0.050674, loss_ce: 0.015458
2021-12-17 18:19:47,160 iteration 6159 : loss : 0.053629, loss_ce: 0.015681
2021-12-17 18:19:48,526 iteration 6160 : loss : 0.052571, loss_ce: 0.017642
2021-12-17 18:19:49,903 iteration 6161 : loss : 0.061693, loss_ce: 0.017467
2021-12-17 18:19:51,307 iteration 6162 : loss : 0.058881, loss_ce: 0.013398
2021-12-17 18:19:52,684 iteration 6163 : loss : 0.054527, loss_ce: 0.018296
2021-12-17 18:19:54,098 iteration 6164 : loss : 0.066364, loss_ce: 0.029351
2021-12-17 18:19:55,462 iteration 6165 : loss : 0.051227, loss_ce: 0.016216
2021-12-17 18:19:56,813 iteration 6166 : loss : 0.054622, loss_ce: 0.022636
2021-12-17 18:19:58,147 iteration 6167 : loss : 0.064285, loss_ce: 0.022504
2021-12-17 18:19:59,553 iteration 6168 : loss : 0.072902, loss_ce: 0.023678
2021-12-17 18:20:00,935 iteration 6169 : loss : 0.066324, loss_ce: 0.015631
2021-12-17 18:20:02,285 iteration 6170 : loss : 0.070823, loss_ce: 0.025262
2021-12-17 18:20:03,627 iteration 6171 : loss : 0.045771, loss_ce: 0.015348
 91%|██████████████████████████▎  | 363/400 [2:35:22<15:14, 24.71s/it]2021-12-17 18:20:05,018 iteration 6172 : loss : 0.047664, loss_ce: 0.015789
2021-12-17 18:20:06,466 iteration 6173 : loss : 0.057049, loss_ce: 0.017215
2021-12-17 18:20:07,823 iteration 6174 : loss : 0.048127, loss_ce: 0.014736
2021-12-17 18:20:09,244 iteration 6175 : loss : 0.064973, loss_ce: 0.024740
2021-12-17 18:20:10,630 iteration 6176 : loss : 0.051374, loss_ce: 0.014569
2021-12-17 18:20:12,082 iteration 6177 : loss : 0.074016, loss_ce: 0.029657
2021-12-17 18:20:13,453 iteration 6178 : loss : 0.049722, loss_ce: 0.016964
2021-12-17 18:20:14,813 iteration 6179 : loss : 0.055637, loss_ce: 0.023330
2021-12-17 18:20:16,188 iteration 6180 : loss : 0.062704, loss_ce: 0.021132
2021-12-17 18:20:17,464 iteration 6181 : loss : 0.045527, loss_ce: 0.012526
2021-12-17 18:20:18,843 iteration 6182 : loss : 0.058778, loss_ce: 0.012767
2021-12-17 18:20:20,281 iteration 6183 : loss : 0.058346, loss_ce: 0.022243
2021-12-17 18:20:21,673 iteration 6184 : loss : 0.076628, loss_ce: 0.020915
2021-12-17 18:20:23,027 iteration 6185 : loss : 0.081306, loss_ce: 0.028361
2021-12-17 18:20:24,404 iteration 6186 : loss : 0.053012, loss_ce: 0.016688
2021-12-17 18:20:25,824 iteration 6187 : loss : 0.057758, loss_ce: 0.017664
2021-12-17 18:20:27,104 iteration 6188 : loss : 0.046658, loss_ce: 0.012986
 91%|██████████████████████████▍  | 364/400 [2:35:46<14:36, 24.34s/it]2021-12-17 18:20:28,463 iteration 6189 : loss : 0.046322, loss_ce: 0.012519
2021-12-17 18:20:29,748 iteration 6190 : loss : 0.049501, loss_ce: 0.014738
2021-12-17 18:20:31,246 iteration 6191 : loss : 0.067671, loss_ce: 0.021597
2021-12-17 18:20:32,652 iteration 6192 : loss : 0.049520, loss_ce: 0.016904
2021-12-17 18:20:33,918 iteration 6193 : loss : 0.040752, loss_ce: 0.013254
2021-12-17 18:20:35,278 iteration 6194 : loss : 0.056162, loss_ce: 0.019213
2021-12-17 18:20:36,677 iteration 6195 : loss : 0.049855, loss_ce: 0.016121
2021-12-17 18:20:38,076 iteration 6196 : loss : 0.050841, loss_ce: 0.017196
2021-12-17 18:20:39,452 iteration 6197 : loss : 0.056082, loss_ce: 0.022896
2021-12-17 18:20:40,809 iteration 6198 : loss : 0.049567, loss_ce: 0.015469
2021-12-17 18:20:42,181 iteration 6199 : loss : 0.057833, loss_ce: 0.012246
2021-12-17 18:20:43,478 iteration 6200 : loss : 0.043241, loss_ce: 0.016398
2021-12-17 18:20:44,869 iteration 6201 : loss : 0.072167, loss_ce: 0.021979
2021-12-17 18:20:46,204 iteration 6202 : loss : 0.046086, loss_ce: 0.016609
2021-12-17 18:20:47,553 iteration 6203 : loss : 0.048175, loss_ce: 0.011460
2021-12-17 18:20:48,944 iteration 6204 : loss : 0.057370, loss_ce: 0.021232
2021-12-17 18:20:48,944 Training Data Eval:
2021-12-17 18:20:56,086   Average segmentation loss on training set: 0.0369
2021-12-17 18:20:56,086 Validation Data Eval:
2021-12-17 18:20:58,566   Average segmentation loss on validation set: 0.1271
2021-12-17 18:20:59,945 iteration 6205 : loss : 0.069840, loss_ce: 0.018037
 91%|██████████████████████████▍  | 365/400 [2:36:19<15:41, 26.89s/it]2021-12-17 18:21:01,392 iteration 6206 : loss : 0.055368, loss_ce: 0.020948
2021-12-17 18:21:02,729 iteration 6207 : loss : 0.055904, loss_ce: 0.016122
2021-12-17 18:21:04,171 iteration 6208 : loss : 0.058706, loss_ce: 0.018640
2021-12-17 18:21:05,523 iteration 6209 : loss : 0.055019, loss_ce: 0.014963
2021-12-17 18:21:06,844 iteration 6210 : loss : 0.052695, loss_ce: 0.018031
2021-12-17 18:21:08,250 iteration 6211 : loss : 0.050777, loss_ce: 0.018258
2021-12-17 18:21:09,592 iteration 6212 : loss : 0.042229, loss_ce: 0.011785
2021-12-17 18:21:10,932 iteration 6213 : loss : 0.060775, loss_ce: 0.014036
2021-12-17 18:21:12,276 iteration 6214 : loss : 0.068932, loss_ce: 0.013297
2021-12-17 18:21:13,669 iteration 6215 : loss : 0.052734, loss_ce: 0.022637
2021-12-17 18:21:15,045 iteration 6216 : loss : 0.051125, loss_ce: 0.013622
2021-12-17 18:21:16,343 iteration 6217 : loss : 0.072555, loss_ce: 0.023355
2021-12-17 18:21:17,719 iteration 6218 : loss : 0.042347, loss_ce: 0.014076
2021-12-17 18:21:19,064 iteration 6219 : loss : 0.050965, loss_ce: 0.016801
2021-12-17 18:21:20,418 iteration 6220 : loss : 0.053773, loss_ce: 0.015178
2021-12-17 18:21:21,861 iteration 6221 : loss : 0.051362, loss_ce: 0.021238
2021-12-17 18:21:23,239 iteration 6222 : loss : 0.077686, loss_ce: 0.032073
 92%|██████████████████████████▌  | 366/400 [2:36:42<14:37, 25.81s/it]2021-12-17 18:21:24,680 iteration 6223 : loss : 0.096992, loss_ce: 0.023288
2021-12-17 18:21:26,023 iteration 6224 : loss : 0.049912, loss_ce: 0.012371
2021-12-17 18:21:27,377 iteration 6225 : loss : 0.065190, loss_ce: 0.022948
2021-12-17 18:21:28,810 iteration 6226 : loss : 0.060132, loss_ce: 0.018297
2021-12-17 18:21:30,166 iteration 6227 : loss : 0.048094, loss_ce: 0.010937
2021-12-17 18:21:31,545 iteration 6228 : loss : 0.058859, loss_ce: 0.022924
2021-12-17 18:21:32,856 iteration 6229 : loss : 0.045349, loss_ce: 0.015930
2021-12-17 18:21:34,203 iteration 6230 : loss : 0.048687, loss_ce: 0.017511
2021-12-17 18:21:35,583 iteration 6231 : loss : 0.052066, loss_ce: 0.018539
2021-12-17 18:21:36,965 iteration 6232 : loss : 0.071242, loss_ce: 0.023383
2021-12-17 18:21:38,320 iteration 6233 : loss : 0.056362, loss_ce: 0.021833
2021-12-17 18:21:39,692 iteration 6234 : loss : 0.046898, loss_ce: 0.014944
2021-12-17 18:21:41,120 iteration 6235 : loss : 0.063762, loss_ce: 0.014254
2021-12-17 18:21:42,403 iteration 6236 : loss : 0.044803, loss_ce: 0.014163
2021-12-17 18:21:43,755 iteration 6237 : loss : 0.050569, loss_ce: 0.017907
2021-12-17 18:21:45,068 iteration 6238 : loss : 0.047204, loss_ce: 0.012300
2021-12-17 18:21:46,403 iteration 6239 : loss : 0.043770, loss_ce: 0.015732
 92%|██████████████████████████▌  | 367/400 [2:37:05<13:45, 25.02s/it]2021-12-17 18:21:47,868 iteration 6240 : loss : 0.050771, loss_ce: 0.016796
2021-12-17 18:21:49,266 iteration 6241 : loss : 0.067336, loss_ce: 0.026239
2021-12-17 18:21:50,668 iteration 6242 : loss : 0.051024, loss_ce: 0.017417
2021-12-17 18:21:51,965 iteration 6243 : loss : 0.055695, loss_ce: 0.018596
2021-12-17 18:21:53,296 iteration 6244 : loss : 0.049783, loss_ce: 0.013727
2021-12-17 18:21:54,646 iteration 6245 : loss : 0.059340, loss_ce: 0.019038
2021-12-17 18:21:55,969 iteration 6246 : loss : 0.054799, loss_ce: 0.017697
2021-12-17 18:21:57,293 iteration 6247 : loss : 0.060178, loss_ce: 0.015104
2021-12-17 18:21:58,705 iteration 6248 : loss : 0.052503, loss_ce: 0.020170
2021-12-17 18:22:00,044 iteration 6249 : loss : 0.048128, loss_ce: 0.014015
2021-12-17 18:22:01,434 iteration 6250 : loss : 0.060279, loss_ce: 0.022826
2021-12-17 18:22:02,880 iteration 6251 : loss : 0.051925, loss_ce: 0.016030
2021-12-17 18:22:04,276 iteration 6252 : loss : 0.078973, loss_ce: 0.020073
2021-12-17 18:22:05,600 iteration 6253 : loss : 0.051076, loss_ce: 0.014329
2021-12-17 18:22:06,895 iteration 6254 : loss : 0.045043, loss_ce: 0.015058
2021-12-17 18:22:08,309 iteration 6255 : loss : 0.046859, loss_ce: 0.013749
2021-12-17 18:22:09,672 iteration 6256 : loss : 0.047801, loss_ce: 0.014538
 92%|██████████████████████████▋  | 368/400 [2:37:28<13:03, 24.49s/it]2021-12-17 18:22:11,110 iteration 6257 : loss : 0.048004, loss_ce: 0.013109
2021-12-17 18:22:12,423 iteration 6258 : loss : 0.047427, loss_ce: 0.014363
2021-12-17 18:22:13,842 iteration 6259 : loss : 0.060223, loss_ce: 0.018404
2021-12-17 18:22:15,327 iteration 6260 : loss : 0.092049, loss_ce: 0.023810
2021-12-17 18:22:16,698 iteration 6261 : loss : 0.058186, loss_ce: 0.021769
2021-12-17 18:22:18,105 iteration 6262 : loss : 0.055093, loss_ce: 0.018960
2021-12-17 18:22:19,438 iteration 6263 : loss : 0.049938, loss_ce: 0.015173
2021-12-17 18:22:20,740 iteration 6264 : loss : 0.053531, loss_ce: 0.018750
2021-12-17 18:22:22,107 iteration 6265 : loss : 0.049841, loss_ce: 0.016133
2021-12-17 18:22:23,438 iteration 6266 : loss : 0.045952, loss_ce: 0.014271
2021-12-17 18:22:24,960 iteration 6267 : loss : 0.074381, loss_ce: 0.030841
2021-12-17 18:22:26,309 iteration 6268 : loss : 0.053432, loss_ce: 0.017048
2021-12-17 18:22:27,681 iteration 6269 : loss : 0.051039, loss_ce: 0.017173
2021-12-17 18:22:29,025 iteration 6270 : loss : 0.056905, loss_ce: 0.023046
2021-12-17 18:22:30,459 iteration 6271 : loss : 0.054903, loss_ce: 0.020110
2021-12-17 18:22:31,782 iteration 6272 : loss : 0.052177, loss_ce: 0.014197
2021-12-17 18:22:33,222 iteration 6273 : loss : 0.062277, loss_ce: 0.020067
 92%|██████████████████████████▊  | 369/400 [2:37:52<12:30, 24.21s/it]2021-12-17 18:22:34,715 iteration 6274 : loss : 0.059481, loss_ce: 0.018405
2021-12-17 18:22:36,046 iteration 6275 : loss : 0.054002, loss_ce: 0.013160
2021-12-17 18:22:37,348 iteration 6276 : loss : 0.058256, loss_ce: 0.020921
2021-12-17 18:22:38,720 iteration 6277 : loss : 0.048955, loss_ce: 0.014658
2021-12-17 18:22:40,149 iteration 6278 : loss : 0.067093, loss_ce: 0.023994
2021-12-17 18:22:41,564 iteration 6279 : loss : 0.062044, loss_ce: 0.017878
2021-12-17 18:22:42,869 iteration 6280 : loss : 0.054359, loss_ce: 0.018720
2021-12-17 18:22:44,222 iteration 6281 : loss : 0.066351, loss_ce: 0.020254
2021-12-17 18:22:45,583 iteration 6282 : loss : 0.056162, loss_ce: 0.020824
2021-12-17 18:22:47,017 iteration 6283 : loss : 0.063473, loss_ce: 0.023566
2021-12-17 18:22:48,390 iteration 6284 : loss : 0.043926, loss_ce: 0.013190
2021-12-17 18:22:49,770 iteration 6285 : loss : 0.072254, loss_ce: 0.035620
2021-12-17 18:22:51,185 iteration 6286 : loss : 0.067850, loss_ce: 0.033381
2021-12-17 18:22:52,543 iteration 6287 : loss : 0.064348, loss_ce: 0.021192
2021-12-17 18:22:53,831 iteration 6288 : loss : 0.057708, loss_ce: 0.016631
2021-12-17 18:22:55,175 iteration 6289 : loss : 0.066593, loss_ce: 0.026930
2021-12-17 18:22:55,175 Training Data Eval:
2021-12-17 18:23:02,286   Average segmentation loss on training set: 0.0362
2021-12-17 18:23:02,287 Validation Data Eval:
2021-12-17 18:23:04,743   Average segmentation loss on validation set: 0.1251
2021-12-17 18:23:06,123 iteration 6290 : loss : 0.047370, loss_ce: 0.015202
 92%|██████████████████████████▊  | 370/400 [2:38:25<13:24, 26.82s/it]2021-12-17 18:23:07,531 iteration 6291 : loss : 0.049081, loss_ce: 0.014454
2021-12-17 18:23:08,819 iteration 6292 : loss : 0.044056, loss_ce: 0.012118
2021-12-17 18:23:10,145 iteration 6293 : loss : 0.048503, loss_ce: 0.012179
2021-12-17 18:23:11,575 iteration 6294 : loss : 0.058242, loss_ce: 0.016761
2021-12-17 18:23:12,941 iteration 6295 : loss : 0.064516, loss_ce: 0.019718
2021-12-17 18:23:14,242 iteration 6296 : loss : 0.050220, loss_ce: 0.018402
2021-12-17 18:23:15,673 iteration 6297 : loss : 0.072015, loss_ce: 0.025487
2021-12-17 18:23:17,037 iteration 6298 : loss : 0.062820, loss_ce: 0.028556
2021-12-17 18:23:18,385 iteration 6299 : loss : 0.056971, loss_ce: 0.020051
2021-12-17 18:23:19,779 iteration 6300 : loss : 0.063758, loss_ce: 0.017380
2021-12-17 18:23:21,157 iteration 6301 : loss : 0.048001, loss_ce: 0.019351
2021-12-17 18:23:22,580 iteration 6302 : loss : 0.059394, loss_ce: 0.020507
2021-12-17 18:23:23,905 iteration 6303 : loss : 0.048753, loss_ce: 0.016358
2021-12-17 18:23:25,277 iteration 6304 : loss : 0.049752, loss_ce: 0.016859
2021-12-17 18:23:26,608 iteration 6305 : loss : 0.061023, loss_ce: 0.016934
2021-12-17 18:23:27,973 iteration 6306 : loss : 0.058243, loss_ce: 0.023227
2021-12-17 18:23:29,320 iteration 6307 : loss : 0.047501, loss_ce: 0.015167
 93%|██████████████████████████▉  | 371/400 [2:38:48<12:26, 25.73s/it]2021-12-17 18:23:30,764 iteration 6308 : loss : 0.048014, loss_ce: 0.016090
2021-12-17 18:23:32,103 iteration 6309 : loss : 0.078024, loss_ce: 0.019019
2021-12-17 18:23:33,464 iteration 6310 : loss : 0.046241, loss_ce: 0.015030
2021-12-17 18:23:34,883 iteration 6311 : loss : 0.060324, loss_ce: 0.016862
2021-12-17 18:23:36,235 iteration 6312 : loss : 0.053950, loss_ce: 0.021769
2021-12-17 18:23:37,614 iteration 6313 : loss : 0.064035, loss_ce: 0.016476
2021-12-17 18:23:39,009 iteration 6314 : loss : 0.045431, loss_ce: 0.015446
2021-12-17 18:23:40,359 iteration 6315 : loss : 0.059162, loss_ce: 0.022238
2021-12-17 18:23:41,658 iteration 6316 : loss : 0.044905, loss_ce: 0.011113
2021-12-17 18:23:42,956 iteration 6317 : loss : 0.049912, loss_ce: 0.014852
2021-12-17 18:23:44,370 iteration 6318 : loss : 0.064983, loss_ce: 0.023073
2021-12-17 18:23:45,709 iteration 6319 : loss : 0.057028, loss_ce: 0.020943
2021-12-17 18:23:47,060 iteration 6320 : loss : 0.046733, loss_ce: 0.017807
2021-12-17 18:23:48,411 iteration 6321 : loss : 0.052354, loss_ce: 0.017512
2021-12-17 18:23:49,848 iteration 6322 : loss : 0.066924, loss_ce: 0.020826
2021-12-17 18:23:51,294 iteration 6323 : loss : 0.068244, loss_ce: 0.015516
2021-12-17 18:23:52,640 iteration 6324 : loss : 0.055569, loss_ce: 0.019766
 93%|██████████████████████████▉  | 372/400 [2:39:11<11:40, 25.01s/it]2021-12-17 18:23:54,015 iteration 6325 : loss : 0.045240, loss_ce: 0.016808
2021-12-17 18:23:55,319 iteration 6326 : loss : 0.040923, loss_ce: 0.013419
2021-12-17 18:23:56,717 iteration 6327 : loss : 0.050640, loss_ce: 0.017024
2021-12-17 18:23:58,051 iteration 6328 : loss : 0.052828, loss_ce: 0.015046
2021-12-17 18:23:59,359 iteration 6329 : loss : 0.053961, loss_ce: 0.014718
2021-12-17 18:24:00,713 iteration 6330 : loss : 0.042455, loss_ce: 0.011309
2021-12-17 18:24:02,240 iteration 6331 : loss : 0.086965, loss_ce: 0.022399
2021-12-17 18:24:03,562 iteration 6332 : loss : 0.062682, loss_ce: 0.027563
2021-12-17 18:24:04,959 iteration 6333 : loss : 0.056502, loss_ce: 0.016253
2021-12-17 18:24:06,322 iteration 6334 : loss : 0.051889, loss_ce: 0.019921
2021-12-17 18:24:07,777 iteration 6335 : loss : 0.073480, loss_ce: 0.023437
2021-12-17 18:24:09,074 iteration 6336 : loss : 0.040112, loss_ce: 0.013342
2021-12-17 18:24:10,459 iteration 6337 : loss : 0.050998, loss_ce: 0.017355
2021-12-17 18:24:11,909 iteration 6338 : loss : 0.063605, loss_ce: 0.011135
2021-12-17 18:24:13,240 iteration 6339 : loss : 0.061403, loss_ce: 0.023984
2021-12-17 18:24:14,572 iteration 6340 : loss : 0.047091, loss_ce: 0.020135
2021-12-17 18:24:15,940 iteration 6341 : loss : 0.047542, loss_ce: 0.013585
 93%|███████████████████████████  | 373/400 [2:39:35<11:01, 24.49s/it]2021-12-17 18:24:17,349 iteration 6342 : loss : 0.052270, loss_ce: 0.017310
2021-12-17 18:24:18,686 iteration 6343 : loss : 0.055061, loss_ce: 0.014371
2021-12-17 18:24:20,111 iteration 6344 : loss : 0.068088, loss_ce: 0.023850
2021-12-17 18:24:21,461 iteration 6345 : loss : 0.061658, loss_ce: 0.015674
2021-12-17 18:24:22,791 iteration 6346 : loss : 0.056323, loss_ce: 0.020102
2021-12-17 18:24:24,190 iteration 6347 : loss : 0.070502, loss_ce: 0.029828
2021-12-17 18:24:25,519 iteration 6348 : loss : 0.052278, loss_ce: 0.019950
2021-12-17 18:24:26,869 iteration 6349 : loss : 0.053164, loss_ce: 0.014715
2021-12-17 18:24:28,225 iteration 6350 : loss : 0.043884, loss_ce: 0.013980
2021-12-17 18:24:29,596 iteration 6351 : loss : 0.062638, loss_ce: 0.026953
2021-12-17 18:24:30,997 iteration 6352 : loss : 0.052962, loss_ce: 0.016601
2021-12-17 18:24:32,464 iteration 6353 : loss : 0.067402, loss_ce: 0.018743
2021-12-17 18:24:33,806 iteration 6354 : loss : 0.062726, loss_ce: 0.013555
2021-12-17 18:24:35,241 iteration 6355 : loss : 0.055007, loss_ce: 0.015939
2021-12-17 18:24:36,688 iteration 6356 : loss : 0.063222, loss_ce: 0.019578
2021-12-17 18:24:38,076 iteration 6357 : loss : 0.050780, loss_ce: 0.020289
2021-12-17 18:24:39,500 iteration 6358 : loss : 0.050173, loss_ce: 0.014443
 94%|███████████████████████████  | 374/400 [2:39:58<10:29, 24.22s/it]2021-12-17 18:24:40,904 iteration 6359 : loss : 0.049194, loss_ce: 0.015352
2021-12-17 18:24:42,164 iteration 6360 : loss : 0.040870, loss_ce: 0.012334
2021-12-17 18:24:43,597 iteration 6361 : loss : 0.055414, loss_ce: 0.018413
2021-12-17 18:24:44,968 iteration 6362 : loss : 0.048708, loss_ce: 0.017276
2021-12-17 18:24:46,422 iteration 6363 : loss : 0.065620, loss_ce: 0.019928
2021-12-17 18:24:47,825 iteration 6364 : loss : 0.048797, loss_ce: 0.014031
2021-12-17 18:24:49,194 iteration 6365 : loss : 0.067765, loss_ce: 0.023696
2021-12-17 18:24:50,551 iteration 6366 : loss : 0.056656, loss_ce: 0.018859
2021-12-17 18:24:51,964 iteration 6367 : loss : 0.073272, loss_ce: 0.027376
2021-12-17 18:24:53,353 iteration 6368 : loss : 0.063465, loss_ce: 0.016657
2021-12-17 18:24:54,715 iteration 6369 : loss : 0.057974, loss_ce: 0.013997
2021-12-17 18:24:56,112 iteration 6370 : loss : 0.059458, loss_ce: 0.023314
2021-12-17 18:24:57,424 iteration 6371 : loss : 0.044885, loss_ce: 0.015633
2021-12-17 18:24:58,806 iteration 6372 : loss : 0.061560, loss_ce: 0.020915
2021-12-17 18:25:00,121 iteration 6373 : loss : 0.050205, loss_ce: 0.020370
2021-12-17 18:25:01,403 iteration 6374 : loss : 0.044080, loss_ce: 0.013606
2021-12-17 18:25:01,403 Training Data Eval:
2021-12-17 18:25:08,469   Average segmentation loss on training set: 0.0363
2021-12-17 18:25:08,469 Validation Data Eval:
2021-12-17 18:25:10,950   Average segmentation loss on validation set: 0.1280
2021-12-17 18:25:12,366 iteration 6375 : loss : 0.050008, loss_ce: 0.020963
 94%|███████████████████████████▏ | 375/400 [2:40:31<11:10, 26.81s/it]2021-12-17 18:25:13,852 iteration 6376 : loss : 0.054552, loss_ce: 0.015652
2021-12-17 18:25:15,237 iteration 6377 : loss : 0.059177, loss_ce: 0.014100
2021-12-17 18:25:16,591 iteration 6378 : loss : 0.062114, loss_ce: 0.027030
2021-12-17 18:25:17,962 iteration 6379 : loss : 0.050175, loss_ce: 0.018342
2021-12-17 18:25:19,384 iteration 6380 : loss : 0.061280, loss_ce: 0.016236
2021-12-17 18:25:20,809 iteration 6381 : loss : 0.064193, loss_ce: 0.023786
2021-12-17 18:25:22,178 iteration 6382 : loss : 0.057899, loss_ce: 0.023036
2021-12-17 18:25:23,581 iteration 6383 : loss : 0.058080, loss_ce: 0.016589
2021-12-17 18:25:25,000 iteration 6384 : loss : 0.065601, loss_ce: 0.021036
2021-12-17 18:25:26,242 iteration 6385 : loss : 0.040591, loss_ce: 0.010436
2021-12-17 18:25:27,647 iteration 6386 : loss : 0.066716, loss_ce: 0.018976
2021-12-17 18:25:29,043 iteration 6387 : loss : 0.080603, loss_ce: 0.031825
2021-12-17 18:25:30,343 iteration 6388 : loss : 0.042917, loss_ce: 0.016438
2021-12-17 18:25:31,748 iteration 6389 : loss : 0.049254, loss_ce: 0.018043
2021-12-17 18:25:33,130 iteration 6390 : loss : 0.066420, loss_ce: 0.020115
2021-12-17 18:25:34,530 iteration 6391 : loss : 0.063927, loss_ce: 0.021875
2021-12-17 18:25:35,946 iteration 6392 : loss : 0.059578, loss_ce: 0.013620
 94%|███████████████████████████▎ | 376/400 [2:40:55<10:20, 25.84s/it]2021-12-17 18:25:37,328 iteration 6393 : loss : 0.046352, loss_ce: 0.018032
2021-12-17 18:25:38,677 iteration 6394 : loss : 0.045047, loss_ce: 0.016120
2021-12-17 18:25:40,000 iteration 6395 : loss : 0.041873, loss_ce: 0.011157
2021-12-17 18:25:41,391 iteration 6396 : loss : 0.063971, loss_ce: 0.023495
2021-12-17 18:25:42,793 iteration 6397 : loss : 0.053082, loss_ce: 0.014318
2021-12-17 18:25:44,207 iteration 6398 : loss : 0.059292, loss_ce: 0.020802
2021-12-17 18:25:45,509 iteration 6399 : loss : 0.049850, loss_ce: 0.014018
2021-12-17 18:25:46,852 iteration 6400 : loss : 0.041310, loss_ce: 0.012248
2021-12-17 18:25:48,160 iteration 6401 : loss : 0.040260, loss_ce: 0.012398
2021-12-17 18:25:49,566 iteration 6402 : loss : 0.054784, loss_ce: 0.019364
2021-12-17 18:25:50,880 iteration 6403 : loss : 0.050964, loss_ce: 0.015863
2021-12-17 18:25:52,180 iteration 6404 : loss : 0.054478, loss_ce: 0.023647
2021-12-17 18:25:53,669 iteration 6405 : loss : 0.085389, loss_ce: 0.032304
2021-12-17 18:25:54,968 iteration 6406 : loss : 0.043991, loss_ce: 0.014640
2021-12-17 18:25:56,359 iteration 6407 : loss : 0.064882, loss_ce: 0.023026
2021-12-17 18:25:57,763 iteration 6408 : loss : 0.051625, loss_ce: 0.014774
2021-12-17 18:25:59,063 iteration 6409 : loss : 0.039887, loss_ce: 0.011651
 94%|███████████████████████████▎ | 377/400 [2:41:18<09:35, 25.03s/it]2021-12-17 18:26:00,419 iteration 6410 : loss : 0.054304, loss_ce: 0.019197
2021-12-17 18:26:01,754 iteration 6411 : loss : 0.045972, loss_ce: 0.013406
2021-12-17 18:26:03,178 iteration 6412 : loss : 0.076124, loss_ce: 0.022356
2021-12-17 18:26:04,556 iteration 6413 : loss : 0.059312, loss_ce: 0.021418
2021-12-17 18:26:05,960 iteration 6414 : loss : 0.051061, loss_ce: 0.015770
2021-12-17 18:26:07,357 iteration 6415 : loss : 0.060130, loss_ce: 0.020162
2021-12-17 18:26:08,675 iteration 6416 : loss : 0.056729, loss_ce: 0.018112
2021-12-17 18:26:10,070 iteration 6417 : loss : 0.060546, loss_ce: 0.018332
2021-12-17 18:26:11,424 iteration 6418 : loss : 0.074007, loss_ce: 0.029785
2021-12-17 18:26:12,776 iteration 6419 : loss : 0.066784, loss_ce: 0.024373
2021-12-17 18:26:14,160 iteration 6420 : loss : 0.063870, loss_ce: 0.018895
2021-12-17 18:26:15,561 iteration 6421 : loss : 0.056658, loss_ce: 0.017934
2021-12-17 18:26:16,902 iteration 6422 : loss : 0.053031, loss_ce: 0.018244
2021-12-17 18:26:18,281 iteration 6423 : loss : 0.057262, loss_ce: 0.016368
2021-12-17 18:26:19,606 iteration 6424 : loss : 0.045357, loss_ce: 0.013459
2021-12-17 18:26:21,092 iteration 6425 : loss : 0.055994, loss_ce: 0.017297
2021-12-17 18:26:22,396 iteration 6426 : loss : 0.051478, loss_ce: 0.014093
 94%|███████████████████████████▍ | 378/400 [2:41:41<08:59, 24.52s/it]2021-12-17 18:26:23,831 iteration 6427 : loss : 0.054546, loss_ce: 0.020937
2021-12-17 18:26:25,237 iteration 6428 : loss : 0.066560, loss_ce: 0.018533
2021-12-17 18:26:26,590 iteration 6429 : loss : 0.053237, loss_ce: 0.019439
2021-12-17 18:26:28,012 iteration 6430 : loss : 0.046853, loss_ce: 0.015553
2021-12-17 18:26:29,362 iteration 6431 : loss : 0.073695, loss_ce: 0.019898
2021-12-17 18:26:30,724 iteration 6432 : loss : 0.055622, loss_ce: 0.017965
2021-12-17 18:26:32,079 iteration 6433 : loss : 0.048221, loss_ce: 0.012489
2021-12-17 18:26:33,446 iteration 6434 : loss : 0.061428, loss_ce: 0.021669
2021-12-17 18:26:34,718 iteration 6435 : loss : 0.045363, loss_ce: 0.014980
2021-12-17 18:26:36,033 iteration 6436 : loss : 0.044104, loss_ce: 0.018572
2021-12-17 18:26:37,327 iteration 6437 : loss : 0.048569, loss_ce: 0.015475
2021-12-17 18:26:38,609 iteration 6438 : loss : 0.042318, loss_ce: 0.014821
2021-12-17 18:26:40,030 iteration 6439 : loss : 0.067267, loss_ce: 0.019560
2021-12-17 18:26:41,411 iteration 6440 : loss : 0.049168, loss_ce: 0.014846
2021-12-17 18:26:42,787 iteration 6441 : loss : 0.044829, loss_ce: 0.014576
2021-12-17 18:26:44,144 iteration 6442 : loss : 0.045307, loss_ce: 0.016410
2021-12-17 18:26:45,487 iteration 6443 : loss : 0.052693, loss_ce: 0.016984
 95%|███████████████████████████▍ | 379/400 [2:42:04<08:25, 24.09s/it]2021-12-17 18:26:46,880 iteration 6444 : loss : 0.049698, loss_ce: 0.018959
2021-12-17 18:26:48,204 iteration 6445 : loss : 0.042896, loss_ce: 0.013726
2021-12-17 18:26:49,564 iteration 6446 : loss : 0.074777, loss_ce: 0.024281
2021-12-17 18:26:50,924 iteration 6447 : loss : 0.046998, loss_ce: 0.017823
2021-12-17 18:26:52,279 iteration 6448 : loss : 0.062219, loss_ce: 0.015898
2021-12-17 18:26:53,658 iteration 6449 : loss : 0.055619, loss_ce: 0.016577
2021-12-17 18:26:55,073 iteration 6450 : loss : 0.078448, loss_ce: 0.021813
2021-12-17 18:26:56,414 iteration 6451 : loss : 0.059737, loss_ce: 0.019593
2021-12-17 18:26:57,817 iteration 6452 : loss : 0.075346, loss_ce: 0.014890
2021-12-17 18:26:59,155 iteration 6453 : loss : 0.052323, loss_ce: 0.017883
2021-12-17 18:27:00,506 iteration 6454 : loss : 0.058016, loss_ce: 0.016648
2021-12-17 18:27:01,819 iteration 6455 : loss : 0.052293, loss_ce: 0.016585
2021-12-17 18:27:03,189 iteration 6456 : loss : 0.049724, loss_ce: 0.019684
2021-12-17 18:27:04,530 iteration 6457 : loss : 0.057167, loss_ce: 0.022228
2021-12-17 18:27:05,844 iteration 6458 : loss : 0.054932, loss_ce: 0.025499
2021-12-17 18:27:07,258 iteration 6459 : loss : 0.060563, loss_ce: 0.019363
2021-12-17 18:27:07,258 Training Data Eval:
2021-12-17 18:27:14,365   Average segmentation loss on training set: 0.0361
2021-12-17 18:27:14,365 Validation Data Eval:
2021-12-17 18:27:16,836   Average segmentation loss on validation set: 0.1256
2021-12-17 18:27:18,284 iteration 6460 : loss : 0.048305, loss_ce: 0.013973
 95%|███████████████████████████▌ | 380/400 [2:42:37<08:54, 26.70s/it]2021-12-17 18:27:19,680 iteration 6461 : loss : 0.049450, loss_ce: 0.016186
2021-12-17 18:27:21,041 iteration 6462 : loss : 0.048646, loss_ce: 0.017167
2021-12-17 18:27:22,354 iteration 6463 : loss : 0.054768, loss_ce: 0.019241
2021-12-17 18:27:23,705 iteration 6464 : loss : 0.067439, loss_ce: 0.024843
2021-12-17 18:27:25,075 iteration 6465 : loss : 0.052368, loss_ce: 0.014733
2021-12-17 18:27:26,437 iteration 6466 : loss : 0.058509, loss_ce: 0.021141
2021-12-17 18:27:27,796 iteration 6467 : loss : 0.060076, loss_ce: 0.023770
2021-12-17 18:27:29,107 iteration 6468 : loss : 0.049979, loss_ce: 0.012906
2021-12-17 18:27:30,513 iteration 6469 : loss : 0.057598, loss_ce: 0.014477
2021-12-17 18:27:31,899 iteration 6470 : loss : 0.043423, loss_ce: 0.013367
2021-12-17 18:27:33,278 iteration 6471 : loss : 0.060601, loss_ce: 0.023820
2021-12-17 18:27:34,600 iteration 6472 : loss : 0.056578, loss_ce: 0.017572
2021-12-17 18:27:35,990 iteration 6473 : loss : 0.054533, loss_ce: 0.017577
2021-12-17 18:27:37,359 iteration 6474 : loss : 0.051742, loss_ce: 0.018424
2021-12-17 18:27:38,757 iteration 6475 : loss : 0.053473, loss_ce: 0.014626
2021-12-17 18:27:40,138 iteration 6476 : loss : 0.056481, loss_ce: 0.017640
2021-12-17 18:27:41,508 iteration 6477 : loss : 0.056731, loss_ce: 0.017259
 95%|███████████████████████████▌ | 381/400 [2:43:00<08:07, 25.66s/it]2021-12-17 18:27:42,921 iteration 6478 : loss : 0.048735, loss_ce: 0.016201
2021-12-17 18:27:44,291 iteration 6479 : loss : 0.068251, loss_ce: 0.019151
2021-12-17 18:27:45,628 iteration 6480 : loss : 0.053117, loss_ce: 0.017779
2021-12-17 18:27:47,123 iteration 6481 : loss : 0.061921, loss_ce: 0.018930
2021-12-17 18:27:48,463 iteration 6482 : loss : 0.056189, loss_ce: 0.020220
2021-12-17 18:27:49,883 iteration 6483 : loss : 0.051733, loss_ce: 0.017691
2021-12-17 18:27:51,170 iteration 6484 : loss : 0.047667, loss_ce: 0.013786
2021-12-17 18:27:52,536 iteration 6485 : loss : 0.044733, loss_ce: 0.011679
2021-12-17 18:27:53,919 iteration 6486 : loss : 0.055403, loss_ce: 0.018401
2021-12-17 18:27:55,310 iteration 6487 : loss : 0.053453, loss_ce: 0.019470
2021-12-17 18:27:56,709 iteration 6488 : loss : 0.053683, loss_ce: 0.015187
2021-12-17 18:27:58,058 iteration 6489 : loss : 0.053203, loss_ce: 0.013071
2021-12-17 18:27:59,401 iteration 6490 : loss : 0.046172, loss_ce: 0.014625
2021-12-17 18:28:00,721 iteration 6491 : loss : 0.048827, loss_ce: 0.018980
2021-12-17 18:28:02,046 iteration 6492 : loss : 0.042153, loss_ce: 0.015524
2021-12-17 18:28:03,391 iteration 6493 : loss : 0.060397, loss_ce: 0.020261
2021-12-17 18:28:04,780 iteration 6494 : loss : 0.059683, loss_ce: 0.019635
 96%|███████████████████████████▋ | 382/400 [2:43:23<07:28, 24.94s/it]2021-12-17 18:28:06,139 iteration 6495 : loss : 0.045191, loss_ce: 0.016433
2021-12-17 18:28:07,492 iteration 6496 : loss : 0.052844, loss_ce: 0.015989
2021-12-17 18:28:08,885 iteration 6497 : loss : 0.042332, loss_ce: 0.015557
2021-12-17 18:28:10,201 iteration 6498 : loss : 0.048843, loss_ce: 0.010561
2021-12-17 18:28:11,555 iteration 6499 : loss : 0.068824, loss_ce: 0.014857
2021-12-17 18:28:13,013 iteration 6500 : loss : 0.063017, loss_ce: 0.018278
2021-12-17 18:28:14,446 iteration 6501 : loss : 0.052431, loss_ce: 0.021675
2021-12-17 18:28:15,829 iteration 6502 : loss : 0.051095, loss_ce: 0.014902
2021-12-17 18:28:17,212 iteration 6503 : loss : 0.055634, loss_ce: 0.015192
2021-12-17 18:28:18,601 iteration 6504 : loss : 0.055031, loss_ce: 0.021541
2021-12-17 18:28:19,903 iteration 6505 : loss : 0.043863, loss_ce: 0.013992
2021-12-17 18:28:21,283 iteration 6506 : loss : 0.060111, loss_ce: 0.013076
2021-12-17 18:28:22,610 iteration 6507 : loss : 0.054320, loss_ce: 0.022329
2021-12-17 18:28:23,897 iteration 6508 : loss : 0.056528, loss_ce: 0.015186
2021-12-17 18:28:25,253 iteration 6509 : loss : 0.046986, loss_ce: 0.014923
2021-12-17 18:28:26,523 iteration 6510 : loss : 0.039941, loss_ce: 0.013613
2021-12-17 18:28:27,914 iteration 6511 : loss : 0.052135, loss_ce: 0.017169
 96%|███████████████████████████▊ | 383/400 [2:43:47<06:54, 24.40s/it]2021-12-17 18:28:29,354 iteration 6512 : loss : 0.072850, loss_ce: 0.023018
2021-12-17 18:28:30,773 iteration 6513 : loss : 0.049651, loss_ce: 0.016428
2021-12-17 18:28:32,152 iteration 6514 : loss : 0.054189, loss_ce: 0.015447
2021-12-17 18:28:33,565 iteration 6515 : loss : 0.076731, loss_ce: 0.024388
2021-12-17 18:28:34,895 iteration 6516 : loss : 0.056513, loss_ce: 0.021618
2021-12-17 18:28:36,211 iteration 6517 : loss : 0.051558, loss_ce: 0.018982
2021-12-17 18:28:37,592 iteration 6518 : loss : 0.066302, loss_ce: 0.019922
2021-12-17 18:28:39,016 iteration 6519 : loss : 0.060394, loss_ce: 0.020481
2021-12-17 18:28:40,323 iteration 6520 : loss : 0.071871, loss_ce: 0.034749
2021-12-17 18:28:41,718 iteration 6521 : loss : 0.053457, loss_ce: 0.018745
2021-12-17 18:28:43,089 iteration 6522 : loss : 0.060340, loss_ce: 0.019476
2021-12-17 18:28:44,490 iteration 6523 : loss : 0.049055, loss_ce: 0.018001
2021-12-17 18:28:45,871 iteration 6524 : loss : 0.060260, loss_ce: 0.020608
2021-12-17 18:28:47,275 iteration 6525 : loss : 0.061314, loss_ce: 0.021966
2021-12-17 18:28:48,636 iteration 6526 : loss : 0.055753, loss_ce: 0.018890
2021-12-17 18:28:49,960 iteration 6527 : loss : 0.052977, loss_ce: 0.015841
2021-12-17 18:28:51,293 iteration 6528 : loss : 0.045631, loss_ce: 0.015996
 96%|███████████████████████████▊ | 384/400 [2:44:10<06:25, 24.09s/it]2021-12-17 18:28:52,858 iteration 6529 : loss : 0.060265, loss_ce: 0.024194
2021-12-17 18:28:54,198 iteration 6530 : loss : 0.060863, loss_ce: 0.023744
2021-12-17 18:28:55,636 iteration 6531 : loss : 0.055218, loss_ce: 0.016873
2021-12-17 18:28:57,006 iteration 6532 : loss : 0.072042, loss_ce: 0.028088
2021-12-17 18:28:58,428 iteration 6533 : loss : 0.072074, loss_ce: 0.015266
2021-12-17 18:28:59,932 iteration 6534 : loss : 0.068873, loss_ce: 0.017558
2021-12-17 18:29:01,243 iteration 6535 : loss : 0.072702, loss_ce: 0.013068
2021-12-17 18:29:02,608 iteration 6536 : loss : 0.074695, loss_ce: 0.027631
2021-12-17 18:29:03,979 iteration 6537 : loss : 0.051146, loss_ce: 0.017847
2021-12-17 18:29:05,358 iteration 6538 : loss : 0.062422, loss_ce: 0.026765
2021-12-17 18:29:06,854 iteration 6539 : loss : 0.069739, loss_ce: 0.022988
2021-12-17 18:29:08,192 iteration 6540 : loss : 0.053937, loss_ce: 0.022273
2021-12-17 18:29:09,523 iteration 6541 : loss : 0.044556, loss_ce: 0.016018
2021-12-17 18:29:10,954 iteration 6542 : loss : 0.050045, loss_ce: 0.017878
2021-12-17 18:29:12,362 iteration 6543 : loss : 0.068551, loss_ce: 0.023958
2021-12-17 18:29:13,646 iteration 6544 : loss : 0.042251, loss_ce: 0.012015
2021-12-17 18:29:13,646 Training Data Eval:
2021-12-17 18:29:20,743   Average segmentation loss on training set: 0.0361
2021-12-17 18:29:20,743 Validation Data Eval:
2021-12-17 18:29:23,193   Average segmentation loss on validation set: 0.1227
2021-12-17 18:29:29,659 Found new lowest validation loss at iteration 6544! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/TU_3seeds/TU_RESNET_no_pretraining_SGD_best_val_loss_seed100.pth
2021-12-17 18:29:30,916 iteration 6545 : loss : 0.046373, loss_ce: 0.010845
 96%|███████████████████████████▉ | 385/400 [2:44:50<07:11, 28.75s/it]2021-12-17 18:29:32,309 iteration 6546 : loss : 0.061871, loss_ce: 0.016512
2021-12-17 18:29:33,804 iteration 6547 : loss : 0.089051, loss_ce: 0.033762
2021-12-17 18:29:35,042 iteration 6548 : loss : 0.053558, loss_ce: 0.027003
2021-12-17 18:29:36,266 iteration 6549 : loss : 0.039335, loss_ce: 0.011952
2021-12-17 18:29:37,550 iteration 6550 : loss : 0.049818, loss_ce: 0.016022
2021-12-17 18:29:38,906 iteration 6551 : loss : 0.056764, loss_ce: 0.021427
2021-12-17 18:29:40,136 iteration 6552 : loss : 0.047838, loss_ce: 0.018622
2021-12-17 18:29:41,523 iteration 6553 : loss : 0.057956, loss_ce: 0.018589
2021-12-17 18:29:42,838 iteration 6554 : loss : 0.060986, loss_ce: 0.019400
2021-12-17 18:29:44,226 iteration 6555 : loss : 0.059209, loss_ce: 0.022338
2021-12-17 18:29:45,589 iteration 6556 : loss : 0.056471, loss_ce: 0.014766
2021-12-17 18:29:46,861 iteration 6557 : loss : 0.051429, loss_ce: 0.015595
2021-12-17 18:29:48,135 iteration 6558 : loss : 0.065759, loss_ce: 0.017985
2021-12-17 18:29:49,484 iteration 6559 : loss : 0.056995, loss_ce: 0.020748
2021-12-17 18:29:50,889 iteration 6560 : loss : 0.098670, loss_ce: 0.021173
2021-12-17 18:29:52,173 iteration 6561 : loss : 0.046404, loss_ce: 0.016025
2021-12-17 18:29:53,404 iteration 6562 : loss : 0.041373, loss_ce: 0.011470
 96%|███████████████████████████▉ | 386/400 [2:45:12<06:16, 26.87s/it]2021-12-17 18:29:54,798 iteration 6563 : loss : 0.043105, loss_ce: 0.015914
2021-12-17 18:29:56,135 iteration 6564 : loss : 0.060614, loss_ce: 0.014326
2021-12-17 18:29:57,464 iteration 6565 : loss : 0.046352, loss_ce: 0.012150
2021-12-17 18:29:58,839 iteration 6566 : loss : 0.041446, loss_ce: 0.013090
2021-12-17 18:30:00,243 iteration 6567 : loss : 0.068829, loss_ce: 0.026726
2021-12-17 18:30:01,628 iteration 6568 : loss : 0.052281, loss_ce: 0.017909
2021-12-17 18:30:03,052 iteration 6569 : loss : 0.062908, loss_ce: 0.021665
2021-12-17 18:30:04,419 iteration 6570 : loss : 0.071338, loss_ce: 0.019581
2021-12-17 18:30:05,910 iteration 6571 : loss : 0.063415, loss_ce: 0.027384
2021-12-17 18:30:07,233 iteration 6572 : loss : 0.044263, loss_ce: 0.016218
2021-12-17 18:30:08,678 iteration 6573 : loss : 0.078548, loss_ce: 0.023498
2021-12-17 18:30:10,036 iteration 6574 : loss : 0.047822, loss_ce: 0.012099
2021-12-17 18:30:11,478 iteration 6575 : loss : 0.080621, loss_ce: 0.024789
2021-12-17 18:30:12,855 iteration 6576 : loss : 0.047710, loss_ce: 0.015550
2021-12-17 18:30:14,204 iteration 6577 : loss : 0.050174, loss_ce: 0.014986
2021-12-17 18:30:15,616 iteration 6578 : loss : 0.044532, loss_ce: 0.012884
2021-12-17 18:30:16,964 iteration 6579 : loss : 0.055462, loss_ce: 0.023008
 97%|████████████████████████████ | 387/400 [2:45:36<05:36, 25.88s/it]2021-12-17 18:30:18,442 iteration 6580 : loss : 0.063254, loss_ce: 0.023031
2021-12-17 18:30:19,773 iteration 6581 : loss : 0.042198, loss_ce: 0.011754
2021-12-17 18:30:21,235 iteration 6582 : loss : 0.055241, loss_ce: 0.016737
2021-12-17 18:30:22,625 iteration 6583 : loss : 0.066194, loss_ce: 0.020067
2021-12-17 18:30:23,962 iteration 6584 : loss : 0.055090, loss_ce: 0.020343
2021-12-17 18:30:25,273 iteration 6585 : loss : 0.046936, loss_ce: 0.014293
2021-12-17 18:30:26,624 iteration 6586 : loss : 0.048003, loss_ce: 0.010435
2021-12-17 18:30:27,934 iteration 6587 : loss : 0.043972, loss_ce: 0.016609
2021-12-17 18:30:29,324 iteration 6588 : loss : 0.047795, loss_ce: 0.017762
2021-12-17 18:30:30,701 iteration 6589 : loss : 0.052107, loss_ce: 0.018109
2021-12-17 18:30:32,050 iteration 6590 : loss : 0.052413, loss_ce: 0.019438
2021-12-17 18:30:33,415 iteration 6591 : loss : 0.039598, loss_ce: 0.010991
2021-12-17 18:30:34,852 iteration 6592 : loss : 0.061273, loss_ce: 0.027378
2021-12-17 18:30:36,136 iteration 6593 : loss : 0.046635, loss_ce: 0.020577
2021-12-17 18:30:37,484 iteration 6594 : loss : 0.056916, loss_ce: 0.020147
2021-12-17 18:30:38,909 iteration 6595 : loss : 0.077082, loss_ce: 0.022047
2021-12-17 18:30:40,233 iteration 6596 : loss : 0.042162, loss_ce: 0.010894
 97%|████████████████████████████▏| 388/400 [2:45:59<05:01, 25.10s/it]2021-12-17 18:30:41,622 iteration 6597 : loss : 0.045586, loss_ce: 0.018671
2021-12-17 18:30:43,044 iteration 6598 : loss : 0.058521, loss_ce: 0.011388
2021-12-17 18:30:44,470 iteration 6599 : loss : 0.053439, loss_ce: 0.016410
2021-12-17 18:30:45,789 iteration 6600 : loss : 0.050795, loss_ce: 0.017957
2021-12-17 18:30:47,258 iteration 6601 : loss : 0.051270, loss_ce: 0.018191
2021-12-17 18:30:48,670 iteration 6602 : loss : 0.064179, loss_ce: 0.019621
2021-12-17 18:30:50,014 iteration 6603 : loss : 0.049731, loss_ce: 0.018296
2021-12-17 18:30:51,418 iteration 6604 : loss : 0.048862, loss_ce: 0.019124
2021-12-17 18:30:52,764 iteration 6605 : loss : 0.068402, loss_ce: 0.026395
2021-12-17 18:30:54,199 iteration 6606 : loss : 0.060728, loss_ce: 0.017374
2021-12-17 18:30:55,633 iteration 6607 : loss : 0.060008, loss_ce: 0.021759
2021-12-17 18:30:56,952 iteration 6608 : loss : 0.052957, loss_ce: 0.019876
2021-12-17 18:30:58,368 iteration 6609 : loss : 0.053738, loss_ce: 0.018915
2021-12-17 18:30:59,720 iteration 6610 : loss : 0.049359, loss_ce: 0.016887
2021-12-17 18:31:01,070 iteration 6611 : loss : 0.049967, loss_ce: 0.013521
2021-12-17 18:31:02,429 iteration 6612 : loss : 0.063599, loss_ce: 0.017078
2021-12-17 18:31:03,837 iteration 6613 : loss : 0.062943, loss_ce: 0.018639
 97%|████████████████████████████▏| 389/400 [2:46:22<04:31, 24.65s/it]2021-12-17 18:31:05,229 iteration 6614 : loss : 0.050055, loss_ce: 0.016028
2021-12-17 18:31:06,531 iteration 6615 : loss : 0.042846, loss_ce: 0.014170
2021-12-17 18:31:07,938 iteration 6616 : loss : 0.054966, loss_ce: 0.018020
2021-12-17 18:31:09,298 iteration 6617 : loss : 0.057451, loss_ce: 0.020286
2021-12-17 18:31:10,743 iteration 6618 : loss : 0.054384, loss_ce: 0.018179
2021-12-17 18:31:12,121 iteration 6619 : loss : 0.056594, loss_ce: 0.017634
2021-12-17 18:31:13,500 iteration 6620 : loss : 0.056960, loss_ce: 0.016302
2021-12-17 18:31:14,929 iteration 6621 : loss : 0.059356, loss_ce: 0.018182
2021-12-17 18:31:16,284 iteration 6622 : loss : 0.051331, loss_ce: 0.021503
2021-12-17 18:31:17,596 iteration 6623 : loss : 0.054014, loss_ce: 0.016371
2021-12-17 18:31:18,967 iteration 6624 : loss : 0.046076, loss_ce: 0.015273
2021-12-17 18:31:20,370 iteration 6625 : loss : 0.069786, loss_ce: 0.024178
2021-12-17 18:31:21,733 iteration 6626 : loss : 0.057081, loss_ce: 0.020068
2021-12-17 18:31:23,141 iteration 6627 : loss : 0.060601, loss_ce: 0.020881
2021-12-17 18:31:24,539 iteration 6628 : loss : 0.064859, loss_ce: 0.022447
2021-12-17 18:31:26,022 iteration 6629 : loss : 0.058799, loss_ce: 0.015161
2021-12-17 18:31:26,022 Training Data Eval:
2021-12-17 18:31:33,124   Average segmentation loss on training set: 0.0360
2021-12-17 18:31:33,124 Validation Data Eval:
2021-12-17 18:31:35,636   Average segmentation loss on validation set: 0.1312
2021-12-17 18:31:36,990 iteration 6630 : loss : 0.062126, loss_ce: 0.021879
 98%|████████████████████████████▎| 390/400 [2:46:56<04:31, 27.20s/it]2021-12-17 18:31:38,412 iteration 6631 : loss : 0.058502, loss_ce: 0.018332
2021-12-17 18:31:39,755 iteration 6632 : loss : 0.047226, loss_ce: 0.018692
2021-12-17 18:31:41,167 iteration 6633 : loss : 0.062174, loss_ce: 0.015955
2021-12-17 18:31:42,516 iteration 6634 : loss : 0.049105, loss_ce: 0.015335
2021-12-17 18:31:43,898 iteration 6635 : loss : 0.052245, loss_ce: 0.020165
2021-12-17 18:31:45,278 iteration 6636 : loss : 0.043349, loss_ce: 0.016498
2021-12-17 18:31:46,607 iteration 6637 : loss : 0.059577, loss_ce: 0.019648
2021-12-17 18:31:48,020 iteration 6638 : loss : 0.059196, loss_ce: 0.011806
2021-12-17 18:31:49,437 iteration 6639 : loss : 0.053736, loss_ce: 0.019584
2021-12-17 18:31:50,791 iteration 6640 : loss : 0.062977, loss_ce: 0.017414
2021-12-17 18:31:52,177 iteration 6641 : loss : 0.053688, loss_ce: 0.015997
2021-12-17 18:31:53,553 iteration 6642 : loss : 0.067921, loss_ce: 0.025678
2021-12-17 18:31:54,941 iteration 6643 : loss : 0.053696, loss_ce: 0.016846
2021-12-17 18:31:56,416 iteration 6644 : loss : 0.068504, loss_ce: 0.023865
2021-12-17 18:31:57,757 iteration 6645 : loss : 0.047989, loss_ce: 0.016190
2021-12-17 18:31:59,231 iteration 6646 : loss : 0.071179, loss_ce: 0.019271
2021-12-17 18:32:00,584 iteration 6647 : loss : 0.050503, loss_ce: 0.016090
 98%|████████████████████████████▎| 391/400 [2:47:19<03:55, 26.12s/it]2021-12-17 18:32:01,976 iteration 6648 : loss : 0.068007, loss_ce: 0.014725
2021-12-17 18:32:03,374 iteration 6649 : loss : 0.055094, loss_ce: 0.016044
2021-12-17 18:32:04,816 iteration 6650 : loss : 0.064273, loss_ce: 0.025122
2021-12-17 18:32:06,286 iteration 6651 : loss : 0.059233, loss_ce: 0.021594
2021-12-17 18:32:07,650 iteration 6652 : loss : 0.049029, loss_ce: 0.017651
2021-12-17 18:32:08,950 iteration 6653 : loss : 0.043929, loss_ce: 0.016070
2021-12-17 18:32:10,315 iteration 6654 : loss : 0.057366, loss_ce: 0.016663
2021-12-17 18:32:11,732 iteration 6655 : loss : 0.049437, loss_ce: 0.016105
2021-12-17 18:32:13,131 iteration 6656 : loss : 0.071109, loss_ce: 0.024106
2021-12-17 18:32:14,512 iteration 6657 : loss : 0.046986, loss_ce: 0.010986
2021-12-17 18:32:15,915 iteration 6658 : loss : 0.051438, loss_ce: 0.015251
2021-12-17 18:32:17,293 iteration 6659 : loss : 0.053100, loss_ce: 0.020093
2021-12-17 18:32:18,721 iteration 6660 : loss : 0.056551, loss_ce: 0.020974
2021-12-17 18:32:20,118 iteration 6661 : loss : 0.060433, loss_ce: 0.018969
2021-12-17 18:32:21,515 iteration 6662 : loss : 0.057270, loss_ce: 0.013207
2021-12-17 18:32:22,888 iteration 6663 : loss : 0.050332, loss_ce: 0.015024
2021-12-17 18:32:24,298 iteration 6664 : loss : 0.080382, loss_ce: 0.033786
 98%|████████████████████████████▍| 392/400 [2:47:43<03:23, 25.40s/it]2021-12-17 18:32:25,752 iteration 6665 : loss : 0.061011, loss_ce: 0.017462
2021-12-17 18:32:27,227 iteration 6666 : loss : 0.075302, loss_ce: 0.022100
2021-12-17 18:32:28,622 iteration 6667 : loss : 0.066455, loss_ce: 0.015954
2021-12-17 18:32:29,914 iteration 6668 : loss : 0.052616, loss_ce: 0.019782
2021-12-17 18:32:31,261 iteration 6669 : loss : 0.056727, loss_ce: 0.020383
2021-12-17 18:32:32,619 iteration 6670 : loss : 0.053963, loss_ce: 0.021219
2021-12-17 18:32:34,014 iteration 6671 : loss : 0.062736, loss_ce: 0.019113
2021-12-17 18:32:35,427 iteration 6672 : loss : 0.058899, loss_ce: 0.016825
2021-12-17 18:32:36,793 iteration 6673 : loss : 0.057556, loss_ce: 0.012483
2021-12-17 18:32:38,174 iteration 6674 : loss : 0.051822, loss_ce: 0.019853
2021-12-17 18:32:39,626 iteration 6675 : loss : 0.063501, loss_ce: 0.026993
2021-12-17 18:32:40,977 iteration 6676 : loss : 0.048749, loss_ce: 0.017423
2021-12-17 18:32:42,309 iteration 6677 : loss : 0.052749, loss_ce: 0.015844
2021-12-17 18:32:43,672 iteration 6678 : loss : 0.051678, loss_ce: 0.021072
2021-12-17 18:32:45,086 iteration 6679 : loss : 0.061125, loss_ce: 0.023651
2021-12-17 18:32:46,401 iteration 6680 : loss : 0.042702, loss_ce: 0.012335
2021-12-17 18:32:47,698 iteration 6681 : loss : 0.040548, loss_ce: 0.011582
 98%|████████████████████████████▍| 393/400 [2:48:06<02:53, 24.80s/it]2021-12-17 18:32:49,208 iteration 6682 : loss : 0.062357, loss_ce: 0.024676
2021-12-17 18:32:50,530 iteration 6683 : loss : 0.047475, loss_ce: 0.016386
2021-12-17 18:32:51,906 iteration 6684 : loss : 0.056332, loss_ce: 0.025189
2021-12-17 18:32:53,223 iteration 6685 : loss : 0.060288, loss_ce: 0.019368
2021-12-17 18:32:54,661 iteration 6686 : loss : 0.067803, loss_ce: 0.029380
2021-12-17 18:32:56,027 iteration 6687 : loss : 0.047614, loss_ce: 0.013949
2021-12-17 18:32:57,396 iteration 6688 : loss : 0.048133, loss_ce: 0.016608
2021-12-17 18:32:58,693 iteration 6689 : loss : 0.053251, loss_ce: 0.013248
2021-12-17 18:33:00,052 iteration 6690 : loss : 0.045591, loss_ce: 0.012637
2021-12-17 18:33:01,444 iteration 6691 : loss : 0.065081, loss_ce: 0.019914
2021-12-17 18:33:02,780 iteration 6692 : loss : 0.068719, loss_ce: 0.021081
2021-12-17 18:33:04,142 iteration 6693 : loss : 0.055815, loss_ce: 0.017344
2021-12-17 18:33:05,529 iteration 6694 : loss : 0.062540, loss_ce: 0.020333
2021-12-17 18:33:06,875 iteration 6695 : loss : 0.049770, loss_ce: 0.014956
2021-12-17 18:33:08,254 iteration 6696 : loss : 0.048739, loss_ce: 0.015567
2021-12-17 18:33:09,613 iteration 6697 : loss : 0.066006, loss_ce: 0.026286
2021-12-17 18:33:11,052 iteration 6698 : loss : 0.053075, loss_ce: 0.014973
 98%|████████████████████████████▌| 394/400 [2:48:30<02:26, 24.38s/it]2021-12-17 18:33:12,490 iteration 6699 : loss : 0.046558, loss_ce: 0.013812
2021-12-17 18:33:13,908 iteration 6700 : loss : 0.057507, loss_ce: 0.013453
2021-12-17 18:33:15,270 iteration 6701 : loss : 0.043991, loss_ce: 0.011846
2021-12-17 18:33:16,580 iteration 6702 : loss : 0.044586, loss_ce: 0.018220
2021-12-17 18:33:17,883 iteration 6703 : loss : 0.044201, loss_ce: 0.013425
2021-12-17 18:33:19,284 iteration 6704 : loss : 0.057532, loss_ce: 0.025151
2021-12-17 18:33:20,606 iteration 6705 : loss : 0.052830, loss_ce: 0.020706
2021-12-17 18:33:22,041 iteration 6706 : loss : 0.048700, loss_ce: 0.015184
2021-12-17 18:33:23,355 iteration 6707 : loss : 0.045346, loss_ce: 0.014058
2021-12-17 18:33:24,720 iteration 6708 : loss : 0.060506, loss_ce: 0.019579
2021-12-17 18:33:26,097 iteration 6709 : loss : 0.081168, loss_ce: 0.032957
2021-12-17 18:33:27,500 iteration 6710 : loss : 0.056281, loss_ce: 0.013421
2021-12-17 18:33:28,895 iteration 6711 : loss : 0.057741, loss_ce: 0.018005
2021-12-17 18:33:30,342 iteration 6712 : loss : 0.054673, loss_ce: 0.021611
2021-12-17 18:33:31,649 iteration 6713 : loss : 0.046377, loss_ce: 0.014058
2021-12-17 18:33:33,023 iteration 6714 : loss : 0.049595, loss_ce: 0.015955
2021-12-17 18:33:33,023 Training Data Eval:
2021-12-17 18:33:40,148   Average segmentation loss on training set: 0.0367
2021-12-17 18:33:40,149 Validation Data Eval:
2021-12-17 18:33:42,632   Average segmentation loss on validation set: 0.1226
2021-12-17 18:33:48,944 Found new lowest validation loss at iteration 6714! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/TU_3seeds/TU_RESNET_no_pretraining_SGD_best_val_loss_seed100.pth
2021-12-17 18:33:50,284 iteration 6715 : loss : 0.051317, loss_ce: 0.016477
 99%|████████████████████████████▋| 395/400 [2:49:09<02:24, 28.82s/it]2021-12-17 18:33:51,638 iteration 6716 : loss : 0.052095, loss_ce: 0.020681
2021-12-17 18:33:52,926 iteration 6717 : loss : 0.048928, loss_ce: 0.017142
2021-12-17 18:33:54,235 iteration 6718 : loss : 0.048411, loss_ce: 0.014908
2021-12-17 18:33:55,516 iteration 6719 : loss : 0.048302, loss_ce: 0.015989
2021-12-17 18:33:56,804 iteration 6720 : loss : 0.057447, loss_ce: 0.016984
2021-12-17 18:33:58,073 iteration 6721 : loss : 0.041534, loss_ce: 0.011953
2021-12-17 18:33:59,466 iteration 6722 : loss : 0.081951, loss_ce: 0.030377
2021-12-17 18:34:00,694 iteration 6723 : loss : 0.043254, loss_ce: 0.012030
2021-12-17 18:34:02,006 iteration 6724 : loss : 0.072178, loss_ce: 0.021020
2021-12-17 18:34:03,343 iteration 6725 : loss : 0.043955, loss_ce: 0.012838
2021-12-17 18:34:04,704 iteration 6726 : loss : 0.057549, loss_ce: 0.020986
2021-12-17 18:34:06,129 iteration 6727 : loss : 0.053674, loss_ce: 0.015975
2021-12-17 18:34:07,448 iteration 6728 : loss : 0.064187, loss_ce: 0.020745
2021-12-17 18:34:08,762 iteration 6729 : loss : 0.060350, loss_ce: 0.018413
2021-12-17 18:34:10,038 iteration 6730 : loss : 0.040278, loss_ce: 0.011926
2021-12-17 18:34:11,352 iteration 6731 : loss : 0.050772, loss_ce: 0.016662
2021-12-17 18:34:12,709 iteration 6732 : loss : 0.061062, loss_ce: 0.023154
 99%|████████████████████████████▋| 396/400 [2:49:31<01:47, 26.90s/it]2021-12-17 18:34:14,075 iteration 6733 : loss : 0.045439, loss_ce: 0.014538
2021-12-17 18:34:15,510 iteration 6734 : loss : 0.063565, loss_ce: 0.021510
2021-12-17 18:34:16,851 iteration 6735 : loss : 0.043762, loss_ce: 0.013864
2021-12-17 18:34:18,289 iteration 6736 : loss : 0.069456, loss_ce: 0.025866
2021-12-17 18:34:19,724 iteration 6737 : loss : 0.058081, loss_ce: 0.020418
2021-12-17 18:34:21,038 iteration 6738 : loss : 0.047292, loss_ce: 0.012768
2021-12-17 18:34:22,403 iteration 6739 : loss : 0.059154, loss_ce: 0.021297
2021-12-17 18:34:23,826 iteration 6740 : loss : 0.046961, loss_ce: 0.019183
2021-12-17 18:34:25,185 iteration 6741 : loss : 0.046607, loss_ce: 0.015761
2021-12-17 18:34:26,522 iteration 6742 : loss : 0.052904, loss_ce: 0.014389
2021-12-17 18:34:27,916 iteration 6743 : loss : 0.059484, loss_ce: 0.021791
2021-12-17 18:34:29,311 iteration 6744 : loss : 0.066427, loss_ce: 0.023842
2021-12-17 18:34:30,650 iteration 6745 : loss : 0.045591, loss_ce: 0.015153
2021-12-17 18:34:32,057 iteration 6746 : loss : 0.050488, loss_ce: 0.018440
2021-12-17 18:34:33,492 iteration 6747 : loss : 0.058018, loss_ce: 0.012471
2021-12-17 18:34:34,906 iteration 6748 : loss : 0.066356, loss_ce: 0.018442
2021-12-17 18:34:36,287 iteration 6749 : loss : 0.050530, loss_ce: 0.018325
 99%|████████████████████████████▊| 397/400 [2:49:55<01:17, 25.90s/it]2021-12-17 18:34:37,745 iteration 6750 : loss : 0.046920, loss_ce: 0.014472
2021-12-17 18:34:39,215 iteration 6751 : loss : 0.071286, loss_ce: 0.024207
2021-12-17 18:34:40,651 iteration 6752 : loss : 0.064719, loss_ce: 0.022537
2021-12-17 18:34:42,017 iteration 6753 : loss : 0.063557, loss_ce: 0.021132
2021-12-17 18:34:43,460 iteration 6754 : loss : 0.049389, loss_ce: 0.017189
2021-12-17 18:34:44,794 iteration 6755 : loss : 0.058145, loss_ce: 0.014055
2021-12-17 18:34:46,070 iteration 6756 : loss : 0.042919, loss_ce: 0.014164
2021-12-17 18:34:47,394 iteration 6757 : loss : 0.045209, loss_ce: 0.016389
2021-12-17 18:34:48,744 iteration 6758 : loss : 0.048275, loss_ce: 0.018372
2021-12-17 18:34:50,144 iteration 6759 : loss : 0.066825, loss_ce: 0.019854
2021-12-17 18:34:51,498 iteration 6760 : loss : 0.046101, loss_ce: 0.015688
2021-12-17 18:34:52,857 iteration 6761 : loss : 0.049353, loss_ce: 0.015051
2021-12-17 18:34:54,248 iteration 6762 : loss : 0.047763, loss_ce: 0.013529
2021-12-17 18:34:55,627 iteration 6763 : loss : 0.049355, loss_ce: 0.018647
2021-12-17 18:34:57,067 iteration 6764 : loss : 0.060105, loss_ce: 0.020257
2021-12-17 18:34:58,458 iteration 6765 : loss : 0.053072, loss_ce: 0.013013
2021-12-17 18:34:59,811 iteration 6766 : loss : 0.050711, loss_ce: 0.017044
100%|████████████████████████████▊| 398/400 [2:50:18<00:50, 25.19s/it]2021-12-17 18:35:01,291 iteration 6767 : loss : 0.066344, loss_ce: 0.027321
2021-12-17 18:35:02,623 iteration 6768 : loss : 0.049794, loss_ce: 0.014518
2021-12-17 18:35:03,965 iteration 6769 : loss : 0.047512, loss_ce: 0.014142
2021-12-17 18:35:05,341 iteration 6770 : loss : 0.060862, loss_ce: 0.016491
2021-12-17 18:35:06,696 iteration 6771 : loss : 0.046500, loss_ce: 0.017256
2021-12-17 18:35:08,086 iteration 6772 : loss : 0.053323, loss_ce: 0.018214
2021-12-17 18:35:09,383 iteration 6773 : loss : 0.047744, loss_ce: 0.016388
2021-12-17 18:35:10,749 iteration 6774 : loss : 0.053656, loss_ce: 0.017343
2021-12-17 18:35:12,118 iteration 6775 : loss : 0.073858, loss_ce: 0.013091
2021-12-17 18:35:13,469 iteration 6776 : loss : 0.051403, loss_ce: 0.016088
2021-12-17 18:35:14,848 iteration 6777 : loss : 0.056919, loss_ce: 0.019042
2021-12-17 18:35:16,173 iteration 6778 : loss : 0.046273, loss_ce: 0.015415
2021-12-17 18:35:17,532 iteration 6779 : loss : 0.049205, loss_ce: 0.016326
2021-12-17 18:35:18,936 iteration 6780 : loss : 0.053145, loss_ce: 0.017005
2021-12-17 18:35:20,314 iteration 6781 : loss : 0.050023, loss_ce: 0.017015
2021-12-17 18:35:21,660 iteration 6782 : loss : 0.056952, loss_ce: 0.021440
2021-12-17 18:35:23,085 iteration 6783 : loss : 0.058402, loss_ce: 0.017126
100%|████████████████████████████▉| 399/400 [2:50:42<00:24, 24.61s/it]2021-12-17 18:35:24,445 iteration 6784 : loss : 0.053456, loss_ce: 0.022639
2021-12-17 18:35:25,789 iteration 6785 : loss : 0.053126, loss_ce: 0.015674
2021-12-17 18:35:27,185 iteration 6786 : loss : 0.066595, loss_ce: 0.020820
2021-12-17 18:35:28,547 iteration 6787 : loss : 0.060366, loss_ce: 0.014090
2021-12-17 18:35:29,908 iteration 6788 : loss : 0.054232, loss_ce: 0.023476
2021-12-17 18:35:31,339 iteration 6789 : loss : 0.066455, loss_ce: 0.017674
2021-12-17 18:35:32,708 iteration 6790 : loss : 0.055016, loss_ce: 0.020928
2021-12-17 18:35:34,139 iteration 6791 : loss : 0.086467, loss_ce: 0.026440
2021-12-17 18:35:35,489 iteration 6792 : loss : 0.053332, loss_ce: 0.019911
2021-12-17 18:35:36,792 iteration 6793 : loss : 0.042610, loss_ce: 0.012588
2021-12-17 18:35:38,211 iteration 6794 : loss : 0.059126, loss_ce: 0.018597
2021-12-17 18:35:39,537 iteration 6795 : loss : 0.056160, loss_ce: 0.019257
2021-12-17 18:35:40,899 iteration 6796 : loss : 0.046846, loss_ce: 0.011596
2021-12-17 18:35:42,250 iteration 6797 : loss : 0.050451, loss_ce: 0.015694
2021-12-17 18:35:43,659 iteration 6798 : loss : 0.068266, loss_ce: 0.020079
2021-12-17 18:35:45,014 iteration 6799 : loss : 0.048610, loss_ce: 0.013699
2021-12-17 18:35:45,015 Training Data Eval:
2021-12-17 18:35:52,142   Average segmentation loss on training set: 0.0359
2021-12-17 18:35:52,143 Validation Data Eval:
2021-12-17 18:35:54,644   Average segmentation loss on validation set: 0.1267
2021-12-17 18:35:56,044 iteration 6800 : loss : 0.058048, loss_ce: 0.021532
100%|█████████████████████████████| 400/400 [2:51:15<00:00, 27.12s/it]100%|█████████████████████████████| 400/400 [2:51:15<00:00, 25.69s/it]
