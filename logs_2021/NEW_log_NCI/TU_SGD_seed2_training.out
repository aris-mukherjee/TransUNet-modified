2021-12-12 22:55:16,932 load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 256, 768])
load_pretrained: grid-size from 14 to 16
2021-12-12 22:55:18,021 Logging directory: /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/TransUNet/log_dir/trRUNMC_cv1_r3/i2i2l/
2021-12-12 22:55:18,021 Tensorboard directory: /scratch_net/biwidl217_second/arismu/Tensorboard/trRUNMC_cv1_r3/i2i2l/
2021-12-12 22:55:18,021 ============================================================
2021-12-12 22:55:18,021 EXPERIMENT NAME: trRUNMC_cv1_r3/i2i2l/
2021-12-12 22:55:18,022 ============================================================
2021-12-12 22:55:18,022 Loading data...
2021-12-12 22:55:18,022 Reading NCI - RUNMC images...
2021-12-12 22:55:18,022 Data root directory: /itet-stor/arismu/bmicdatasets-originals/Originals/Challenge_Datasets/NCI_Prostate/
2021-12-12 22:55:18,023 Already preprocessed this configuration. Loading now!
2021-12-12 22:55:18,046 Training Images: (256, 256, 286)
2021-12-12 22:55:18,046 Training Labels: (256, 256, 286)
2021-12-12 22:55:18,046 Validation Images: (256, 256, 98)
2021-12-12 22:55:18,047 Validation Labels: (256, 256, 98)
2021-12-12 22:55:18,047 ============================================================
2021-12-12 22:55:18,086 17 iterations per epoch. 6800 max iterations 
  0%|                                         | 0/400 [00:00<?, ?it/s]2021-12-12 22:55:20,499 iteration 1 : loss : 1.070721, loss_ce: 1.370284
2021-12-12 22:55:21,827 iteration 2 : loss : 1.056574, loss_ce: 1.356010
2021-12-12 22:55:23,229 iteration 3 : loss : 1.048751, loss_ce: 1.340193
2021-12-12 22:55:24,573 iteration 4 : loss : 1.046562, loss_ce: 1.316382
2021-12-12 22:55:25,854 iteration 5 : loss : 1.038145, loss_ce: 1.289864
2021-12-12 22:55:27,184 iteration 6 : loss : 1.007683, loss_ce: 1.247266
2021-12-12 22:55:28,552 iteration 7 : loss : 0.981630, loss_ce: 1.206526
2021-12-12 22:55:29,976 iteration 8 : loss : 0.955371, loss_ce: 1.160182
2021-12-12 22:55:31,264 iteration 9 : loss : 0.935916, loss_ce: 1.111504
2021-12-12 22:55:32,555 iteration 10 : loss : 0.899225, loss_ce: 1.061780
2021-12-12 22:55:33,835 iteration 11 : loss : 0.870107, loss_ce: 1.007300
2021-12-12 22:55:35,162 iteration 12 : loss : 0.825402, loss_ce: 0.950536
2021-12-12 22:55:36,545 iteration 13 : loss : 0.793280, loss_ce: 0.909720
2021-12-12 22:55:37,823 iteration 14 : loss : 0.768152, loss_ce: 0.858700
2021-12-12 22:55:39,200 iteration 15 : loss : 0.747093, loss_ce: 0.811511
2021-12-12 22:55:40,522 iteration 16 : loss : 0.711503, loss_ce: 0.762464
2021-12-12 22:55:41,834 iteration 17 : loss : 0.680661, loss_ce: 0.730996
  0%|                               | 1/400 [00:23<2:38:18, 23.81s/it]2021-12-12 22:55:43,197 iteration 18 : loss : 0.669341, loss_ce: 0.684153
2021-12-12 22:55:44,546 iteration 19 : loss : 0.640917, loss_ce: 0.649458
2021-12-12 22:55:45,878 iteration 20 : loss : 0.622052, loss_ce: 0.619825
2021-12-12 22:55:47,286 iteration 21 : loss : 0.597694, loss_ce: 0.582869
2021-12-12 22:55:48,607 iteration 22 : loss : 0.571993, loss_ce: 0.551543
2021-12-12 22:55:49,957 iteration 23 : loss : 0.569969, loss_ce: 0.528478
2021-12-12 22:55:51,241 iteration 24 : loss : 0.540536, loss_ce: 0.508635
2021-12-12 22:55:52,489 iteration 25 : loss : 0.527518, loss_ce: 0.476849
2021-12-12 22:55:53,776 iteration 26 : loss : 0.516820, loss_ce: 0.451764
2021-12-12 22:55:55,121 iteration 27 : loss : 0.501923, loss_ce: 0.443875
2021-12-12 22:55:56,448 iteration 28 : loss : 0.495587, loss_ce: 0.418745
2021-12-12 22:55:57,913 iteration 29 : loss : 0.477321, loss_ce: 0.406005
2021-12-12 22:55:59,294 iteration 30 : loss : 0.475323, loss_ce: 0.389417
2021-12-12 22:56:00,586 iteration 31 : loss : 0.450686, loss_ce: 0.376091
2021-12-12 22:56:01,899 iteration 32 : loss : 0.438529, loss_ce: 0.358016
2021-12-12 22:56:03,308 iteration 33 : loss : 0.426660, loss_ce: 0.345442
2021-12-12 22:56:04,621 iteration 34 : loss : 0.434673, loss_ce: 0.325682
  0%|▏                              | 2/400 [00:46<2:33:51, 23.19s/it]2021-12-12 22:56:06,039 iteration 35 : loss : 0.407945, loss_ce: 0.329893
2021-12-12 22:56:07,391 iteration 36 : loss : 0.403361, loss_ce: 0.312110
2021-12-12 22:56:08,770 iteration 37 : loss : 0.384649, loss_ce: 0.305179
2021-12-12 22:56:10,228 iteration 38 : loss : 0.398300, loss_ce: 0.289393
2021-12-12 22:56:11,651 iteration 39 : loss : 0.398795, loss_ce: 0.281167
2021-12-12 22:56:13,142 iteration 40 : loss : 0.362367, loss_ce: 0.280571
2021-12-12 22:56:14,556 iteration 41 : loss : 0.363628, loss_ce: 0.258282
2021-12-12 22:56:16,135 iteration 42 : loss : 0.361900, loss_ce: 0.269106
2021-12-12 22:56:17,544 iteration 43 : loss : 0.376408, loss_ce: 0.248701
2021-12-12 22:56:19,029 iteration 44 : loss : 0.345329, loss_ce: 0.241289
2021-12-12 22:56:20,532 iteration 45 : loss : 0.353969, loss_ce: 0.232517
2021-12-12 22:56:21,914 iteration 46 : loss : 0.342133, loss_ce: 0.232692
2021-12-12 22:56:23,360 iteration 47 : loss : 0.372024, loss_ce: 0.230284
2021-12-12 22:56:24,841 iteration 48 : loss : 0.331355, loss_ce: 0.230196
2021-12-12 22:56:26,311 iteration 49 : loss : 0.354656, loss_ce: 0.221910
2021-12-12 22:56:27,837 iteration 50 : loss : 0.326480, loss_ce: 0.206863
2021-12-12 22:56:29,321 iteration 51 : loss : 0.306855, loss_ce: 0.211697
  1%|▏                              | 3/400 [01:11<2:38:01, 23.88s/it]2021-12-12 22:56:30,751 iteration 52 : loss : 0.300635, loss_ce: 0.196708
2021-12-12 22:56:32,131 iteration 53 : loss : 0.307568, loss_ce: 0.204952
2021-12-12 22:56:33,623 iteration 54 : loss : 0.304018, loss_ce: 0.199529
2021-12-12 22:56:35,097 iteration 55 : loss : 0.309894, loss_ce: 0.185513
2021-12-12 22:56:36,602 iteration 56 : loss : 0.308627, loss_ce: 0.190886
2021-12-12 22:56:38,107 iteration 57 : loss : 0.314036, loss_ce: 0.182927
2021-12-12 22:56:39,586 iteration 58 : loss : 0.287096, loss_ce: 0.177890
2021-12-12 22:56:41,038 iteration 59 : loss : 0.293217, loss_ce: 0.172965
2021-12-12 22:56:42,573 iteration 60 : loss : 0.296531, loss_ce: 0.172506
2021-12-12 22:56:44,123 iteration 61 : loss : 0.273884, loss_ce: 0.170597
2021-12-12 22:56:45,592 iteration 62 : loss : 0.279145, loss_ce: 0.163014
2021-12-12 22:56:46,989 iteration 63 : loss : 0.264437, loss_ce: 0.166266
2021-12-12 22:56:48,439 iteration 64 : loss : 0.257915, loss_ce: 0.158753
2021-12-12 22:56:49,888 iteration 65 : loss : 0.299540, loss_ce: 0.162526
2021-12-12 22:56:51,393 iteration 66 : loss : 0.263794, loss_ce: 0.148050
2021-12-12 22:56:52,815 iteration 67 : loss : 0.254558, loss_ce: 0.148438
2021-12-12 22:56:54,271 iteration 68 : loss : 0.303777, loss_ce: 0.155117
  1%|▎                              | 4/400 [01:36<2:40:24, 24.31s/it]2021-12-12 22:56:55,779 iteration 69 : loss : 0.286755, loss_ce: 0.147215
2021-12-12 22:56:57,270 iteration 70 : loss : 0.261346, loss_ce: 0.145201
2021-12-12 22:56:58,695 iteration 71 : loss : 0.254551, loss_ce: 0.146032
2021-12-12 22:57:00,229 iteration 72 : loss : 0.272950, loss_ce: 0.140313
2021-12-12 22:57:01,688 iteration 73 : loss : 0.254709, loss_ce: 0.146136
2021-12-12 22:57:03,230 iteration 74 : loss : 0.254330, loss_ce: 0.137559
2021-12-12 22:57:04,713 iteration 75 : loss : 0.245356, loss_ce: 0.142385
2021-12-12 22:57:06,253 iteration 76 : loss : 0.249930, loss_ce: 0.137187
2021-12-12 22:57:07,804 iteration 77 : loss : 0.242003, loss_ce: 0.125624
2021-12-12 22:57:09,325 iteration 78 : loss : 0.239286, loss_ce: 0.138789
2021-12-12 22:57:10,751 iteration 79 : loss : 0.237646, loss_ce: 0.125586
2021-12-12 22:57:12,286 iteration 80 : loss : 0.265779, loss_ce: 0.128627
2021-12-12 22:57:13,745 iteration 81 : loss : 0.235395, loss_ce: 0.120719
2021-12-12 22:57:15,209 iteration 82 : loss : 0.222193, loss_ce: 0.121937
2021-12-12 22:57:16,735 iteration 83 : loss : 0.239995, loss_ce: 0.123952
2021-12-12 22:57:18,195 iteration 84 : loss : 0.214251, loss_ce: 0.112687
2021-12-12 22:57:18,195 Training Data Eval:
2021-12-12 22:57:25,751   Average segmentation loss on training set: 0.2338
2021-12-12 22:57:25,752 Validation Data Eval:
2021-12-12 22:57:28,360   Average segmentation loss on validation set: 0.2338
2021-12-12 22:57:34,677 Found new lowest validation loss at iteration 84! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/TU_3seeds/TU_SGD_best_val_loss_seed2.pth
2021-12-12 22:57:36,080 iteration 85 : loss : 0.227586, loss_ce: 0.124550
  1%|▍                              | 5/400 [02:18<3:21:33, 30.62s/it]2021-12-12 22:57:37,436 iteration 86 : loss : 0.231860, loss_ce: 0.112847
2021-12-12 22:57:38,696 iteration 87 : loss : 0.230997, loss_ce: 0.118980
2021-12-12 22:57:40,004 iteration 88 : loss : 0.228222, loss_ce: 0.109146
2021-12-12 22:57:41,438 iteration 89 : loss : 0.211291, loss_ce: 0.113229
2021-12-12 22:57:42,855 iteration 90 : loss : 0.206938, loss_ce: 0.109655
2021-12-12 22:57:44,339 iteration 91 : loss : 0.227676, loss_ce: 0.115328
2021-12-12 22:57:45,783 iteration 92 : loss : 0.201049, loss_ce: 0.105446
2021-12-12 22:57:47,318 iteration 93 : loss : 0.197131, loss_ce: 0.103661
2021-12-12 22:57:48,848 iteration 94 : loss : 0.209779, loss_ce: 0.116473
2021-12-12 22:57:50,295 iteration 95 : loss : 0.228029, loss_ce: 0.110215
2021-12-12 22:57:51,704 iteration 96 : loss : 0.218348, loss_ce: 0.106802
2021-12-12 22:57:53,114 iteration 97 : loss : 0.199648, loss_ce: 0.102711
2021-12-12 22:57:54,573 iteration 98 : loss : 0.207828, loss_ce: 0.103621
2021-12-12 22:57:56,150 iteration 99 : loss : 0.211679, loss_ce: 0.107461
2021-12-12 22:57:57,741 iteration 100 : loss : 0.202263, loss_ce: 0.102720
2021-12-12 22:57:59,183 iteration 101 : loss : 0.192096, loss_ce: 0.091292
2021-12-12 22:58:00,653 iteration 102 : loss : 0.203869, loss_ce: 0.094271
  2%|▍                              | 6/400 [02:42<3:07:34, 28.56s/it]2021-12-12 22:58:02,173 iteration 103 : loss : 0.193581, loss_ce: 0.095241
2021-12-12 22:58:03,687 iteration 104 : loss : 0.193177, loss_ce: 0.094395
2021-12-12 22:58:05,182 iteration 105 : loss : 0.198579, loss_ce: 0.099110
2021-12-12 22:58:06,678 iteration 106 : loss : 0.205312, loss_ce: 0.092781
2021-12-12 22:58:08,228 iteration 107 : loss : 0.199863, loss_ce: 0.102503
2021-12-12 22:58:09,688 iteration 108 : loss : 0.188588, loss_ce: 0.100426
2021-12-12 22:58:11,173 iteration 109 : loss : 0.186318, loss_ce: 0.089350
2021-12-12 22:58:12,701 iteration 110 : loss : 0.201330, loss_ce: 0.103492
2021-12-12 22:58:14,348 iteration 111 : loss : 0.209476, loss_ce: 0.100405
2021-12-12 22:58:15,793 iteration 112 : loss : 0.203910, loss_ce: 0.089842
2021-12-12 22:58:17,365 iteration 113 : loss : 0.185625, loss_ce: 0.085135
2021-12-12 22:58:18,849 iteration 114 : loss : 0.184875, loss_ce: 0.080725
2021-12-12 22:58:20,252 iteration 115 : loss : 0.181297, loss_ce: 0.084988
2021-12-12 22:58:21,726 iteration 116 : loss : 0.193039, loss_ce: 0.086670
2021-12-12 22:58:23,172 iteration 117 : loss : 0.180317, loss_ce: 0.089877
2021-12-12 22:58:24,716 iteration 118 : loss : 0.212303, loss_ce: 0.096137
2021-12-12 22:58:26,159 iteration 119 : loss : 0.180398, loss_ce: 0.086278
  2%|▌                              | 7/400 [03:08<3:00:32, 27.56s/it]2021-12-12 22:58:27,728 iteration 120 : loss : 0.194479, loss_ce: 0.094616
2021-12-12 22:58:29,243 iteration 121 : loss : 0.211238, loss_ce: 0.093181
2021-12-12 22:58:30,635 iteration 122 : loss : 0.177770, loss_ce: 0.081574
2021-12-12 22:58:32,111 iteration 123 : loss : 0.182470, loss_ce: 0.085334
2021-12-12 22:58:33,567 iteration 124 : loss : 0.177514, loss_ce: 0.078113
2021-12-12 22:58:35,020 iteration 125 : loss : 0.174658, loss_ce: 0.078673
2021-12-12 22:58:36,466 iteration 126 : loss : 0.171760, loss_ce: 0.082568
2021-12-12 22:58:37,933 iteration 127 : loss : 0.180516, loss_ce: 0.083716
2021-12-12 22:58:39,378 iteration 128 : loss : 0.165057, loss_ce: 0.073819
2021-12-12 22:58:40,912 iteration 129 : loss : 0.191233, loss_ce: 0.081137
2021-12-12 22:58:42,282 iteration 130 : loss : 0.172431, loss_ce: 0.078661
2021-12-12 22:58:43,729 iteration 131 : loss : 0.168989, loss_ce: 0.081269
2021-12-12 22:58:45,206 iteration 132 : loss : 0.176963, loss_ce: 0.078853
2021-12-12 22:58:46,697 iteration 133 : loss : 0.191564, loss_ce: 0.086621
2021-12-12 22:58:48,149 iteration 134 : loss : 0.164995, loss_ce: 0.072883
2021-12-12 22:58:49,596 iteration 135 : loss : 0.179733, loss_ce: 0.074766
2021-12-12 22:58:51,140 iteration 136 : loss : 0.169727, loss_ce: 0.077758
  2%|▌                              | 8/400 [03:33<2:54:42, 26.74s/it]2021-12-12 22:58:52,740 iteration 137 : loss : 0.175545, loss_ce: 0.073288
2021-12-12 22:58:54,151 iteration 138 : loss : 0.157749, loss_ce: 0.069914
2021-12-12 22:58:55,710 iteration 139 : loss : 0.180244, loss_ce: 0.067458
2021-12-12 22:58:57,173 iteration 140 : loss : 0.170344, loss_ce: 0.074559
2021-12-12 22:58:58,593 iteration 141 : loss : 0.166851, loss_ce: 0.073922
2021-12-12 22:59:00,042 iteration 142 : loss : 0.182401, loss_ce: 0.079427
2021-12-12 22:59:01,519 iteration 143 : loss : 0.182287, loss_ce: 0.074356
2021-12-12 22:59:02,968 iteration 144 : loss : 0.190791, loss_ce: 0.075620
2021-12-12 22:59:04,444 iteration 145 : loss : 0.175253, loss_ce: 0.083232
2021-12-12 22:59:05,950 iteration 146 : loss : 0.166814, loss_ce: 0.072175
2021-12-12 22:59:07,428 iteration 147 : loss : 0.176444, loss_ce: 0.082410
2021-12-12 22:59:09,011 iteration 148 : loss : 0.172674, loss_ce: 0.074823
2021-12-12 22:59:10,559 iteration 149 : loss : 0.162878, loss_ce: 0.066890
2021-12-12 22:59:12,104 iteration 150 : loss : 0.171824, loss_ce: 0.075312
2021-12-12 22:59:13,541 iteration 151 : loss : 0.164223, loss_ce: 0.081513
2021-12-12 22:59:14,931 iteration 152 : loss : 0.160467, loss_ce: 0.076043
2021-12-12 22:59:16,383 iteration 153 : loss : 0.154362, loss_ce: 0.062902
  2%|▋                              | 9/400 [03:58<2:51:12, 26.27s/it]2021-12-12 22:59:17,937 iteration 154 : loss : 0.162532, loss_ce: 0.073377
2021-12-12 22:59:19,405 iteration 155 : loss : 0.151132, loss_ce: 0.065314
2021-12-12 22:59:20,842 iteration 156 : loss : 0.159719, loss_ce: 0.071329
2021-12-12 22:59:22,273 iteration 157 : loss : 0.167398, loss_ce: 0.072223
2021-12-12 22:59:23,808 iteration 158 : loss : 0.169050, loss_ce: 0.070670
2021-12-12 22:59:25,337 iteration 159 : loss : 0.159108, loss_ce: 0.065806
2021-12-12 22:59:26,788 iteration 160 : loss : 0.171566, loss_ce: 0.072610
2021-12-12 22:59:28,345 iteration 161 : loss : 0.160148, loss_ce: 0.070047
2021-12-12 22:59:29,829 iteration 162 : loss : 0.163691, loss_ce: 0.061925
2021-12-12 22:59:31,309 iteration 163 : loss : 0.171119, loss_ce: 0.068302
2021-12-12 22:59:32,870 iteration 164 : loss : 0.164756, loss_ce: 0.062559
2021-12-12 22:59:34,287 iteration 165 : loss : 0.158237, loss_ce: 0.064854
2021-12-12 22:59:35,792 iteration 166 : loss : 0.175877, loss_ce: 0.085234
2021-12-12 22:59:37,373 iteration 167 : loss : 0.151383, loss_ce: 0.062009
2021-12-12 22:59:38,836 iteration 168 : loss : 0.171988, loss_ce: 0.067129
2021-12-12 22:59:40,327 iteration 169 : loss : 0.157534, loss_ce: 0.064446
2021-12-12 22:59:40,327 Training Data Eval:
2021-12-12 22:59:47,874   Average segmentation loss on training set: 0.1485
2021-12-12 22:59:47,875 Validation Data Eval:
2021-12-12 22:59:50,476   Average segmentation loss on validation set: 0.1704
2021-12-12 22:59:56,800 Found new lowest validation loss at iteration 169! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/TU_3seeds/TU_SGD_best_val_loss_seed2.pth
2021-12-12 22:59:58,248 iteration 170 : loss : 0.158345, loss_ce: 0.066831
  2%|▊                             | 10/400 [04:40<3:22:03, 31.08s/it]2021-12-12 22:59:59,704 iteration 171 : loss : 0.152883, loss_ce: 0.064842
2021-12-12 23:00:01,026 iteration 172 : loss : 0.166315, loss_ce: 0.073415
2021-12-12 23:00:02,438 iteration 173 : loss : 0.179962, loss_ce: 0.074190
2021-12-12 23:00:03,761 iteration 174 : loss : 0.149577, loss_ce: 0.066653
2021-12-12 23:00:05,212 iteration 175 : loss : 0.156828, loss_ce: 0.059326
2021-12-12 23:00:06,649 iteration 176 : loss : 0.144276, loss_ce: 0.059154
2021-12-12 23:00:08,145 iteration 177 : loss : 0.154330, loss_ce: 0.062414
2021-12-12 23:00:09,607 iteration 178 : loss : 0.146185, loss_ce: 0.058309
2021-12-12 23:00:11,006 iteration 179 : loss : 0.143923, loss_ce: 0.054042
2021-12-12 23:00:12,556 iteration 180 : loss : 0.146879, loss_ce: 0.058531
2021-12-12 23:00:14,061 iteration 181 : loss : 0.163016, loss_ce: 0.073770
2021-12-12 23:00:15,524 iteration 182 : loss : 0.163606, loss_ce: 0.069838
2021-12-12 23:00:17,016 iteration 183 : loss : 0.147309, loss_ce: 0.051613
2021-12-12 23:00:18,627 iteration 184 : loss : 0.177405, loss_ce: 0.068715
2021-12-12 23:00:20,234 iteration 185 : loss : 0.149318, loss_ce: 0.060503
2021-12-12 23:00:21,696 iteration 186 : loss : 0.155675, loss_ce: 0.052922
2021-12-12 23:00:23,193 iteration 187 : loss : 0.147202, loss_ce: 0.058629
  3%|▊                             | 11/400 [05:05<3:09:21, 29.21s/it]2021-12-12 23:00:24,666 iteration 188 : loss : 0.143184, loss_ce: 0.058782
2021-12-12 23:00:26,234 iteration 189 : loss : 0.168560, loss_ce: 0.066059
2021-12-12 23:00:27,746 iteration 190 : loss : 0.152252, loss_ce: 0.060562
2021-12-12 23:00:29,257 iteration 191 : loss : 0.150357, loss_ce: 0.060584
2021-12-12 23:00:30,727 iteration 192 : loss : 0.160559, loss_ce: 0.056887
2021-12-12 23:00:32,130 iteration 193 : loss : 0.143466, loss_ce: 0.053520
2021-12-12 23:00:33,635 iteration 194 : loss : 0.142242, loss_ce: 0.055872
2021-12-12 23:00:35,155 iteration 195 : loss : 0.141055, loss_ce: 0.054297
2021-12-12 23:00:36,610 iteration 196 : loss : 0.151190, loss_ce: 0.066111
2021-12-12 23:00:38,116 iteration 197 : loss : 0.158156, loss_ce: 0.060447
2021-12-12 23:00:39,605 iteration 198 : loss : 0.161728, loss_ce: 0.056898
2021-12-12 23:00:40,983 iteration 199 : loss : 0.149289, loss_ce: 0.052311
2021-12-12 23:00:42,438 iteration 200 : loss : 0.148148, loss_ce: 0.060896
2021-12-12 23:00:44,025 iteration 201 : loss : 0.150268, loss_ce: 0.061042
2021-12-12 23:00:45,479 iteration 202 : loss : 0.129090, loss_ce: 0.048810
2021-12-12 23:00:46,907 iteration 203 : loss : 0.166951, loss_ce: 0.076484
2021-12-12 23:00:48,301 iteration 204 : loss : 0.135828, loss_ce: 0.053475
  3%|▉                             | 12/400 [05:30<3:00:49, 27.96s/it]2021-12-12 23:00:49,748 iteration 205 : loss : 0.154222, loss_ce: 0.057069
2021-12-12 23:00:51,239 iteration 206 : loss : 0.162066, loss_ce: 0.069696
2021-12-12 23:00:52,805 iteration 207 : loss : 0.144312, loss_ce: 0.056798
2021-12-12 23:00:54,375 iteration 208 : loss : 0.147290, loss_ce: 0.053994
2021-12-12 23:00:55,807 iteration 209 : loss : 0.144799, loss_ce: 0.055309
2021-12-12 23:00:57,214 iteration 210 : loss : 0.144193, loss_ce: 0.055283
2021-12-12 23:00:58,676 iteration 211 : loss : 0.153177, loss_ce: 0.061366
2021-12-12 23:01:00,059 iteration 212 : loss : 0.133779, loss_ce: 0.048147
2021-12-12 23:01:01,585 iteration 213 : loss : 0.143933, loss_ce: 0.060027
2021-12-12 23:01:03,068 iteration 214 : loss : 0.165340, loss_ce: 0.058129
2021-12-12 23:01:04,472 iteration 215 : loss : 0.136611, loss_ce: 0.049683
2021-12-12 23:01:05,998 iteration 216 : loss : 0.137302, loss_ce: 0.051638
2021-12-12 23:01:07,444 iteration 217 : loss : 0.142564, loss_ce: 0.058600
2021-12-12 23:01:08,885 iteration 218 : loss : 0.134085, loss_ce: 0.050877
2021-12-12 23:01:10,336 iteration 219 : loss : 0.140578, loss_ce: 0.047166
2021-12-12 23:01:11,743 iteration 220 : loss : 0.161092, loss_ce: 0.065090
2021-12-12 23:01:13,190 iteration 221 : loss : 0.148843, loss_ce: 0.063176
  3%|▉                             | 13/400 [05:55<2:54:21, 27.03s/it]2021-12-12 23:01:14,817 iteration 222 : loss : 0.143886, loss_ce: 0.050238
2021-12-12 23:01:16,336 iteration 223 : loss : 0.139122, loss_ce: 0.050358
2021-12-12 23:01:17,712 iteration 224 : loss : 0.140076, loss_ce: 0.054480
2021-12-12 23:01:19,221 iteration 225 : loss : 0.150691, loss_ce: 0.052592
2021-12-12 23:01:20,737 iteration 226 : loss : 0.153227, loss_ce: 0.050973
2021-12-12 23:01:22,247 iteration 227 : loss : 0.137783, loss_ce: 0.053081
2021-12-12 23:01:23,737 iteration 228 : loss : 0.148053, loss_ce: 0.053447
2021-12-12 23:01:25,222 iteration 229 : loss : 0.148694, loss_ce: 0.066769
2021-12-12 23:01:26,685 iteration 230 : loss : 0.137723, loss_ce: 0.054897
2021-12-12 23:01:28,123 iteration 231 : loss : 0.153060, loss_ce: 0.047587
2021-12-12 23:01:29,688 iteration 232 : loss : 0.145304, loss_ce: 0.064811
2021-12-12 23:01:31,225 iteration 233 : loss : 0.149439, loss_ce: 0.064212
2021-12-12 23:01:32,733 iteration 234 : loss : 0.141763, loss_ce: 0.049360
2021-12-12 23:01:34,205 iteration 235 : loss : 0.122944, loss_ce: 0.046874
2021-12-12 23:01:35,674 iteration 236 : loss : 0.143632, loss_ce: 0.057492
2021-12-12 23:01:37,115 iteration 237 : loss : 0.120025, loss_ce: 0.048085
2021-12-12 23:01:38,483 iteration 238 : loss : 0.124721, loss_ce: 0.050732
  4%|█                             | 14/400 [06:20<2:50:29, 26.50s/it]2021-12-12 23:01:39,945 iteration 239 : loss : 0.140191, loss_ce: 0.050166
2021-12-12 23:01:41,480 iteration 240 : loss : 0.151893, loss_ce: 0.068708
2021-12-12 23:01:42,906 iteration 241 : loss : 0.138556, loss_ce: 0.046991
2021-12-12 23:01:44,433 iteration 242 : loss : 0.128522, loss_ce: 0.050310
2021-12-12 23:01:45,970 iteration 243 : loss : 0.129572, loss_ce: 0.054174
2021-12-12 23:01:47,497 iteration 244 : loss : 0.131601, loss_ce: 0.058220
2021-12-12 23:01:48,891 iteration 245 : loss : 0.133052, loss_ce: 0.047187
2021-12-12 23:01:50,372 iteration 246 : loss : 0.115044, loss_ce: 0.044483
2021-12-12 23:01:51,790 iteration 247 : loss : 0.119049, loss_ce: 0.047473
2021-12-12 23:01:53,169 iteration 248 : loss : 0.120779, loss_ce: 0.045940
2021-12-12 23:01:54,733 iteration 249 : loss : 0.122854, loss_ce: 0.051563
2021-12-12 23:01:56,261 iteration 250 : loss : 0.121327, loss_ce: 0.052568
2021-12-12 23:01:57,737 iteration 251 : loss : 0.105109, loss_ce: 0.044448
2021-12-12 23:01:59,206 iteration 252 : loss : 0.125320, loss_ce: 0.060101
2021-12-12 23:02:00,623 iteration 253 : loss : 0.130091, loss_ce: 0.047986
2021-12-12 23:02:02,038 iteration 254 : loss : 0.101811, loss_ce: 0.041652
2021-12-12 23:02:02,039 Training Data Eval:
2021-12-12 23:02:09,581   Average segmentation loss on training set: 0.1034
2021-12-12 23:02:09,581 Validation Data Eval:
2021-12-12 23:02:12,180   Average segmentation loss on validation set: 0.1324
2021-12-12 23:02:18,524 Found new lowest validation loss at iteration 254! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/TU_3seeds/TU_SGD_best_val_loss_seed2.pth
2021-12-12 23:02:19,883 iteration 255 : loss : 0.109221, loss_ce: 0.041928
  4%|█▏                            | 15/400 [07:01<3:18:52, 30.99s/it]2021-12-12 23:02:21,269 iteration 256 : loss : 0.116188, loss_ce: 0.047818
2021-12-12 23:02:22,597 iteration 257 : loss : 0.133753, loss_ce: 0.066772
2021-12-12 23:02:24,057 iteration 258 : loss : 0.133203, loss_ce: 0.047084
2021-12-12 23:02:25,359 iteration 259 : loss : 0.112530, loss_ce: 0.044009
2021-12-12 23:02:26,822 iteration 260 : loss : 0.140030, loss_ce: 0.062918
2021-12-12 23:02:28,323 iteration 261 : loss : 0.107966, loss_ce: 0.048456
2021-12-12 23:02:29,819 iteration 262 : loss : 0.113192, loss_ce: 0.053739
2021-12-12 23:02:31,242 iteration 263 : loss : 0.117185, loss_ce: 0.051644
2021-12-12 23:02:32,664 iteration 264 : loss : 0.102567, loss_ce: 0.042929
2021-12-12 23:02:34,169 iteration 265 : loss : 0.110047, loss_ce: 0.052629
2021-12-12 23:02:35,661 iteration 266 : loss : 0.135264, loss_ce: 0.045091
2021-12-12 23:02:37,114 iteration 267 : loss : 0.114805, loss_ce: 0.052393
2021-12-12 23:02:38,580 iteration 268 : loss : 0.087278, loss_ce: 0.045750
2021-12-12 23:02:40,031 iteration 269 : loss : 0.101937, loss_ce: 0.048416
2021-12-12 23:02:41,415 iteration 270 : loss : 0.101290, loss_ce: 0.043151
2021-12-12 23:02:42,899 iteration 271 : loss : 0.127001, loss_ce: 0.046122
2021-12-12 23:02:44,434 iteration 272 : loss : 0.103010, loss_ce: 0.044294
  4%|█▏                            | 16/400 [07:26<3:05:57, 29.06s/it]2021-12-12 23:02:45,944 iteration 273 : loss : 0.098231, loss_ce: 0.044778
2021-12-12 23:02:47,423 iteration 274 : loss : 0.110565, loss_ce: 0.046937
2021-12-12 23:02:48,891 iteration 275 : loss : 0.107524, loss_ce: 0.049694
2021-12-12 23:02:50,298 iteration 276 : loss : 0.092471, loss_ce: 0.045726
2021-12-12 23:02:51,835 iteration 277 : loss : 0.098807, loss_ce: 0.044642
2021-12-12 23:02:53,226 iteration 278 : loss : 0.133168, loss_ce: 0.042753
2021-12-12 23:02:54,696 iteration 279 : loss : 0.093741, loss_ce: 0.045384
2021-12-12 23:02:56,079 iteration 280 : loss : 0.089189, loss_ce: 0.043023
2021-12-12 23:02:57,559 iteration 281 : loss : 0.107149, loss_ce: 0.041910
2021-12-12 23:02:59,059 iteration 282 : loss : 0.114610, loss_ce: 0.056851
2021-12-12 23:03:00,541 iteration 283 : loss : 0.102635, loss_ce: 0.048659
2021-12-12 23:03:01,960 iteration 284 : loss : 0.080611, loss_ce: 0.038725
2021-12-12 23:03:03,433 iteration 285 : loss : 0.093788, loss_ce: 0.040555
2021-12-12 23:03:04,929 iteration 286 : loss : 0.098140, loss_ce: 0.043556
2021-12-12 23:03:06,345 iteration 287 : loss : 0.117301, loss_ce: 0.047425
2021-12-12 23:03:07,795 iteration 288 : loss : 0.092053, loss_ce: 0.044578
2021-12-12 23:03:09,251 iteration 289 : loss : 0.088480, loss_ce: 0.044697
  4%|█▎                            | 17/400 [07:51<2:57:20, 27.78s/it]2021-12-12 23:03:10,770 iteration 290 : loss : 0.093242, loss_ce: 0.040317
2021-12-12 23:03:12,245 iteration 291 : loss : 0.093527, loss_ce: 0.043266
2021-12-12 23:03:13,707 iteration 292 : loss : 0.094414, loss_ce: 0.046519
2021-12-12 23:03:15,305 iteration 293 : loss : 0.116489, loss_ce: 0.055813
2021-12-12 23:03:16,735 iteration 294 : loss : 0.088193, loss_ce: 0.041563
2021-12-12 23:03:18,179 iteration 295 : loss : 0.102036, loss_ce: 0.044662
2021-12-12 23:03:19,620 iteration 296 : loss : 0.106175, loss_ce: 0.045375
2021-12-12 23:03:21,149 iteration 297 : loss : 0.107357, loss_ce: 0.050876
2021-12-12 23:03:22,573 iteration 298 : loss : 0.092796, loss_ce: 0.037815
2021-12-12 23:03:24,066 iteration 299 : loss : 0.102673, loss_ce: 0.036388
2021-12-12 23:03:25,495 iteration 300 : loss : 0.081286, loss_ce: 0.036632
2021-12-12 23:03:26,958 iteration 301 : loss : 0.118626, loss_ce: 0.045862
2021-12-12 23:03:28,516 iteration 302 : loss : 0.112717, loss_ce: 0.057242
2021-12-12 23:03:30,018 iteration 303 : loss : 0.099254, loss_ce: 0.050290
2021-12-12 23:03:31,467 iteration 304 : loss : 0.083672, loss_ce: 0.037401
2021-12-12 23:03:32,935 iteration 305 : loss : 0.088733, loss_ce: 0.037901
2021-12-12 23:03:34,397 iteration 306 : loss : 0.103908, loss_ce: 0.044559
  4%|█▎                            | 18/400 [08:16<2:51:49, 26.99s/it]2021-12-12 23:03:35,873 iteration 307 : loss : 0.083081, loss_ce: 0.038815
2021-12-12 23:03:37,379 iteration 308 : loss : 0.110164, loss_ce: 0.041797
2021-12-12 23:03:38,854 iteration 309 : loss : 0.085337, loss_ce: 0.044539
2021-12-12 23:03:40,311 iteration 310 : loss : 0.101387, loss_ce: 0.042668
2021-12-12 23:03:41,741 iteration 311 : loss : 0.102172, loss_ce: 0.044875
2021-12-12 23:03:43,216 iteration 312 : loss : 0.177210, loss_ce: 0.057440
2021-12-12 23:03:44,728 iteration 313 : loss : 0.105225, loss_ce: 0.043223
2021-12-12 23:03:46,099 iteration 314 : loss : 0.087777, loss_ce: 0.040713
2021-12-12 23:03:47,531 iteration 315 : loss : 0.099566, loss_ce: 0.045390
2021-12-12 23:03:49,065 iteration 316 : loss : 0.098665, loss_ce: 0.044049
2021-12-12 23:03:50,602 iteration 317 : loss : 0.093414, loss_ce: 0.046633
2021-12-12 23:03:52,058 iteration 318 : loss : 0.088712, loss_ce: 0.045975
2021-12-12 23:03:53,529 iteration 319 : loss : 0.091246, loss_ce: 0.043521
2021-12-12 23:03:55,003 iteration 320 : loss : 0.091280, loss_ce: 0.036777
2021-12-12 23:03:56,439 iteration 321 : loss : 0.117181, loss_ce: 0.045282
2021-12-12 23:03:57,849 iteration 322 : loss : 0.088029, loss_ce: 0.041743
2021-12-12 23:03:59,295 iteration 323 : loss : 0.077498, loss_ce: 0.037657
  5%|█▍                            | 19/400 [08:41<2:47:23, 26.36s/it]2021-12-12 23:04:00,805 iteration 324 : loss : 0.086797, loss_ce: 0.040741
2021-12-12 23:04:02,236 iteration 325 : loss : 0.109267, loss_ce: 0.040415
2021-12-12 23:04:03,661 iteration 326 : loss : 0.081059, loss_ce: 0.034988
2021-12-12 23:04:05,065 iteration 327 : loss : 0.089160, loss_ce: 0.045499
2021-12-12 23:04:06,541 iteration 328 : loss : 0.083910, loss_ce: 0.033643
2021-12-12 23:04:08,061 iteration 329 : loss : 0.107433, loss_ce: 0.043042
2021-12-12 23:04:09,497 iteration 330 : loss : 0.092114, loss_ce: 0.047728
2021-12-12 23:04:10,957 iteration 331 : loss : 0.082106, loss_ce: 0.036647
2021-12-12 23:04:12,346 iteration 332 : loss : 0.072805, loss_ce: 0.037736
2021-12-12 23:04:13,859 iteration 333 : loss : 0.096412, loss_ce: 0.049758
2021-12-12 23:04:15,331 iteration 334 : loss : 0.087158, loss_ce: 0.038955
2021-12-12 23:04:16,871 iteration 335 : loss : 0.085958, loss_ce: 0.049792
2021-12-12 23:04:18,329 iteration 336 : loss : 0.075743, loss_ce: 0.038764
2021-12-12 23:04:19,765 iteration 337 : loss : 0.111048, loss_ce: 0.040994
2021-12-12 23:04:21,228 iteration 338 : loss : 0.077871, loss_ce: 0.038124
2021-12-12 23:04:22,659 iteration 339 : loss : 0.076126, loss_ce: 0.037760
2021-12-12 23:04:22,659 Training Data Eval:
2021-12-12 23:04:30,187   Average segmentation loss on training set: 0.0817
2021-12-12 23:04:30,187 Validation Data Eval:
2021-12-12 23:04:32,777   Average segmentation loss on validation set: 0.1205
2021-12-12 23:04:39,273 Found new lowest validation loss at iteration 339! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/TU_3seeds/TU_SGD_best_val_loss_seed2.pth
2021-12-12 23:04:40,676 iteration 340 : loss : 0.093837, loss_ce: 0.044443
  5%|█▌                            | 20/400 [09:22<3:15:30, 30.87s/it]2021-12-12 23:04:42,044 iteration 341 : loss : 0.079713, loss_ce: 0.043910
2021-12-12 23:04:43,442 iteration 342 : loss : 0.091047, loss_ce: 0.045518
2021-12-12 23:04:44,826 iteration 343 : loss : 0.078915, loss_ce: 0.039501
2021-12-12 23:04:46,152 iteration 344 : loss : 0.087122, loss_ce: 0.041803
2021-12-12 23:04:47,519 iteration 345 : loss : 0.094515, loss_ce: 0.040014
2021-12-12 23:04:49,021 iteration 346 : loss : 0.076059, loss_ce: 0.036762
2021-12-12 23:04:50,544 iteration 347 : loss : 0.087621, loss_ce: 0.040652
2021-12-12 23:04:51,992 iteration 348 : loss : 0.081551, loss_ce: 0.036481
2021-12-12 23:04:53,452 iteration 349 : loss : 0.096115, loss_ce: 0.042478
2021-12-12 23:04:54,944 iteration 350 : loss : 0.094682, loss_ce: 0.047048
2021-12-12 23:04:56,397 iteration 351 : loss : 0.082249, loss_ce: 0.035798
2021-12-12 23:04:57,951 iteration 352 : loss : 0.080132, loss_ce: 0.045531
2021-12-12 23:04:59,500 iteration 353 : loss : 0.116215, loss_ce: 0.050815
2021-12-12 23:05:00,946 iteration 354 : loss : 0.086793, loss_ce: 0.034434
2021-12-12 23:05:02,445 iteration 355 : loss : 0.075400, loss_ce: 0.030014
2021-12-12 23:05:03,916 iteration 356 : loss : 0.081395, loss_ce: 0.033370
2021-12-12 23:05:05,404 iteration 357 : loss : 0.082533, loss_ce: 0.036008
  5%|█▌                            | 21/400 [09:47<3:03:21, 29.03s/it]2021-12-12 23:05:07,016 iteration 358 : loss : 0.110456, loss_ce: 0.053005
2021-12-12 23:05:08,558 iteration 359 : loss : 0.087623, loss_ce: 0.043363
2021-12-12 23:05:10,001 iteration 360 : loss : 0.084979, loss_ce: 0.033794
2021-12-12 23:05:11,505 iteration 361 : loss : 0.117568, loss_ce: 0.046168
2021-12-12 23:05:13,002 iteration 362 : loss : 0.085942, loss_ce: 0.048412
2021-12-12 23:05:14,404 iteration 363 : loss : 0.065980, loss_ce: 0.034849
2021-12-12 23:05:15,887 iteration 364 : loss : 0.119962, loss_ce: 0.040588
2021-12-12 23:05:17,315 iteration 365 : loss : 0.070917, loss_ce: 0.033641
2021-12-12 23:05:18,783 iteration 366 : loss : 0.127538, loss_ce: 0.045989
2021-12-12 23:05:20,262 iteration 367 : loss : 0.080965, loss_ce: 0.035324
2021-12-12 23:05:21,717 iteration 368 : loss : 0.084432, loss_ce: 0.038232
2021-12-12 23:05:23,147 iteration 369 : loss : 0.066057, loss_ce: 0.031247
2021-12-12 23:05:24,612 iteration 370 : loss : 0.084356, loss_ce: 0.038655
2021-12-12 23:05:26,079 iteration 371 : loss : 0.084141, loss_ce: 0.032880
2021-12-12 23:05:27,505 iteration 372 : loss : 0.068945, loss_ce: 0.033103
2021-12-12 23:05:28,967 iteration 373 : loss : 0.075849, loss_ce: 0.033120
2021-12-12 23:05:30,465 iteration 374 : loss : 0.092441, loss_ce: 0.041800
  6%|█▋                            | 22/400 [10:12<2:55:22, 27.84s/it]2021-12-12 23:05:31,971 iteration 375 : loss : 0.075682, loss_ce: 0.034395
2021-12-12 23:05:33,426 iteration 376 : loss : 0.113723, loss_ce: 0.037515
2021-12-12 23:05:34,913 iteration 377 : loss : 0.077572, loss_ce: 0.033175
2021-12-12 23:05:36,452 iteration 378 : loss : 0.082120, loss_ce: 0.032421
2021-12-12 23:05:37,940 iteration 379 : loss : 0.066438, loss_ce: 0.033455
2021-12-12 23:05:39,384 iteration 380 : loss : 0.071944, loss_ce: 0.036753
2021-12-12 23:05:40,885 iteration 381 : loss : 0.074048, loss_ce: 0.036801
2021-12-12 23:05:42,288 iteration 382 : loss : 0.074365, loss_ce: 0.038438
2021-12-12 23:05:43,777 iteration 383 : loss : 0.110150, loss_ce: 0.029009
2021-12-12 23:05:45,243 iteration 384 : loss : 0.082455, loss_ce: 0.038121
2021-12-12 23:05:46,683 iteration 385 : loss : 0.074676, loss_ce: 0.036818
2021-12-12 23:05:48,155 iteration 386 : loss : 0.097341, loss_ce: 0.043006
2021-12-12 23:05:49,583 iteration 387 : loss : 0.068475, loss_ce: 0.029735
2021-12-12 23:05:51,087 iteration 388 : loss : 0.086044, loss_ce: 0.040012
2021-12-12 23:05:52,542 iteration 389 : loss : 0.076731, loss_ce: 0.030608
2021-12-12 23:05:54,015 iteration 390 : loss : 0.096906, loss_ce: 0.043513
2021-12-12 23:05:55,512 iteration 391 : loss : 0.071853, loss_ce: 0.031640
  6%|█▋                            | 23/400 [10:37<2:49:39, 27.00s/it]2021-12-12 23:05:57,090 iteration 392 : loss : 0.089161, loss_ce: 0.041970
2021-12-12 23:05:58,509 iteration 393 : loss : 0.075659, loss_ce: 0.038675
2021-12-12 23:05:59,982 iteration 394 : loss : 0.085600, loss_ce: 0.039316
2021-12-12 23:06:01,406 iteration 395 : loss : 0.075206, loss_ce: 0.033017
2021-12-12 23:06:02,862 iteration 396 : loss : 0.068149, loss_ce: 0.030889
2021-12-12 23:06:04,403 iteration 397 : loss : 0.067134, loss_ce: 0.035203
2021-12-12 23:06:05,858 iteration 398 : loss : 0.099598, loss_ce: 0.039137
2021-12-12 23:06:07,330 iteration 399 : loss : 0.094987, loss_ce: 0.042718
2021-12-12 23:06:08,769 iteration 400 : loss : 0.081486, loss_ce: 0.035221
2021-12-12 23:06:10,251 iteration 401 : loss : 0.064424, loss_ce: 0.034202
2021-12-12 23:06:11,821 iteration 402 : loss : 0.069366, loss_ce: 0.031762
2021-12-12 23:06:13,335 iteration 403 : loss : 0.082129, loss_ce: 0.036017
2021-12-12 23:06:14,781 iteration 404 : loss : 0.077971, loss_ce: 0.031280
2021-12-12 23:06:16,235 iteration 405 : loss : 0.094642, loss_ce: 0.051994
2021-12-12 23:06:17,742 iteration 406 : loss : 0.061757, loss_ce: 0.032418
2021-12-12 23:06:19,252 iteration 407 : loss : 0.083680, loss_ce: 0.033732
2021-12-12 23:06:20,634 iteration 408 : loss : 0.069047, loss_ce: 0.033741
  6%|█▊                            | 24/400 [11:02<2:45:40, 26.44s/it]2021-12-12 23:06:22,206 iteration 409 : loss : 0.088914, loss_ce: 0.031948
2021-12-12 23:06:23,707 iteration 410 : loss : 0.062827, loss_ce: 0.029261
2021-12-12 23:06:25,215 iteration 411 : loss : 0.105189, loss_ce: 0.033544
2021-12-12 23:06:26,665 iteration 412 : loss : 0.084731, loss_ce: 0.039593
2021-12-12 23:06:28,125 iteration 413 : loss : 0.066938, loss_ce: 0.027337
2021-12-12 23:06:29,541 iteration 414 : loss : 0.062992, loss_ce: 0.029372
2021-12-12 23:06:31,078 iteration 415 : loss : 0.096135, loss_ce: 0.039512
2021-12-12 23:06:32,513 iteration 416 : loss : 0.066738, loss_ce: 0.033141
2021-12-12 23:06:34,013 iteration 417 : loss : 0.100922, loss_ce: 0.037430
2021-12-12 23:06:35,408 iteration 418 : loss : 0.086227, loss_ce: 0.048899
2021-12-12 23:06:36,859 iteration 419 : loss : 0.090618, loss_ce: 0.031694
2021-12-12 23:06:38,321 iteration 420 : loss : 0.067716, loss_ce: 0.034320
2021-12-12 23:06:39,860 iteration 421 : loss : 0.071221, loss_ce: 0.034859
2021-12-12 23:06:41,305 iteration 422 : loss : 0.076788, loss_ce: 0.035394
2021-12-12 23:06:42,774 iteration 423 : loss : 0.063864, loss_ce: 0.030278
2021-12-12 23:06:44,281 iteration 424 : loss : 0.072224, loss_ce: 0.032679
2021-12-12 23:06:44,281 Training Data Eval:
2021-12-12 23:06:51,820   Average segmentation loss on training set: 0.0643
2021-12-12 23:06:51,821 Validation Data Eval:
2021-12-12 23:06:54,423   Average segmentation loss on validation set: 0.1097
2021-12-12 23:07:00,642 Found new lowest validation loss at iteration 424! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/TU_3seeds/TU_SGD_best_val_loss_seed2.pth
2021-12-12 23:07:02,069 iteration 425 : loss : 0.073856, loss_ce: 0.035970
  6%|█▉                            | 25/400 [11:44<3:13:20, 30.94s/it]2021-12-12 23:07:03,512 iteration 426 : loss : 0.067575, loss_ce: 0.031651
2021-12-12 23:07:04,873 iteration 427 : loss : 0.092055, loss_ce: 0.038594
2021-12-12 23:07:06,272 iteration 428 : loss : 0.075497, loss_ce: 0.034417
2021-12-12 23:07:07,633 iteration 429 : loss : 0.072365, loss_ce: 0.028109
2021-12-12 23:07:09,112 iteration 430 : loss : 0.083558, loss_ce: 0.033533
2021-12-12 23:07:10,521 iteration 431 : loss : 0.072636, loss_ce: 0.032421
2021-12-12 23:07:11,961 iteration 432 : loss : 0.060256, loss_ce: 0.026583
2021-12-12 23:07:13,449 iteration 433 : loss : 0.075782, loss_ce: 0.029305
2021-12-12 23:07:14,894 iteration 434 : loss : 0.053482, loss_ce: 0.024380
2021-12-12 23:07:16,347 iteration 435 : loss : 0.091287, loss_ce: 0.046826
2021-12-12 23:07:17,853 iteration 436 : loss : 0.081528, loss_ce: 0.034390
2021-12-12 23:07:19,341 iteration 437 : loss : 0.061871, loss_ce: 0.029095
2021-12-12 23:07:20,807 iteration 438 : loss : 0.095624, loss_ce: 0.052894
2021-12-12 23:07:22,269 iteration 439 : loss : 0.077953, loss_ce: 0.038557
2021-12-12 23:07:23,690 iteration 440 : loss : 0.063930, loss_ce: 0.028561
2021-12-12 23:07:25,140 iteration 441 : loss : 0.064984, loss_ce: 0.033195
2021-12-12 23:07:26,576 iteration 442 : loss : 0.128459, loss_ce: 0.042742
  6%|█▉                            | 26/400 [12:08<3:00:48, 29.01s/it]2021-12-12 23:07:28,091 iteration 443 : loss : 0.075168, loss_ce: 0.041713
2021-12-12 23:07:29,551 iteration 444 : loss : 0.071657, loss_ce: 0.031111
2021-12-12 23:07:31,202 iteration 445 : loss : 0.088273, loss_ce: 0.043206
2021-12-12 23:07:32,616 iteration 446 : loss : 0.097692, loss_ce: 0.036660
2021-12-12 23:07:34,168 iteration 447 : loss : 0.091967, loss_ce: 0.040777
2021-12-12 23:07:35,678 iteration 448 : loss : 0.065256, loss_ce: 0.031499
2021-12-12 23:07:37,131 iteration 449 : loss : 0.083624, loss_ce: 0.034543
2021-12-12 23:07:38,521 iteration 450 : loss : 0.063858, loss_ce: 0.032225
2021-12-12 23:07:39,980 iteration 451 : loss : 0.098356, loss_ce: 0.032205
2021-12-12 23:07:41,483 iteration 452 : loss : 0.066010, loss_ce: 0.031631
2021-12-12 23:07:42,957 iteration 453 : loss : 0.072284, loss_ce: 0.027926
2021-12-12 23:07:44,468 iteration 454 : loss : 0.114924, loss_ce: 0.037270
2021-12-12 23:07:46,017 iteration 455 : loss : 0.078951, loss_ce: 0.030047
2021-12-12 23:07:47,478 iteration 456 : loss : 0.087690, loss_ce: 0.032057
2021-12-12 23:07:48,920 iteration 457 : loss : 0.070819, loss_ce: 0.031740
2021-12-12 23:07:50,383 iteration 458 : loss : 0.090213, loss_ce: 0.042291
2021-12-12 23:07:51,861 iteration 459 : loss : 0.074043, loss_ce: 0.030663
  7%|██                            | 27/400 [12:33<2:53:23, 27.89s/it]2021-12-12 23:07:53,295 iteration 460 : loss : 0.058019, loss_ce: 0.024077
2021-12-12 23:07:54,782 iteration 461 : loss : 0.068087, loss_ce: 0.030959
2021-12-12 23:07:56,257 iteration 462 : loss : 0.077225, loss_ce: 0.026446
2021-12-12 23:07:57,645 iteration 463 : loss : 0.066818, loss_ce: 0.032691
2021-12-12 23:07:59,178 iteration 464 : loss : 0.075206, loss_ce: 0.032615
2021-12-12 23:08:00,630 iteration 465 : loss : 0.076044, loss_ce: 0.040485
2021-12-12 23:08:02,142 iteration 466 : loss : 0.073427, loss_ce: 0.032579
2021-12-12 23:08:03,592 iteration 467 : loss : 0.073791, loss_ce: 0.029383
2021-12-12 23:08:05,048 iteration 468 : loss : 0.076761, loss_ce: 0.030999
2021-12-12 23:08:06,474 iteration 469 : loss : 0.072705, loss_ce: 0.033351
2021-12-12 23:08:08,010 iteration 470 : loss : 0.099206, loss_ce: 0.047647
2021-12-12 23:08:09,436 iteration 471 : loss : 0.075777, loss_ce: 0.032065
2021-12-12 23:08:10,953 iteration 472 : loss : 0.072963, loss_ce: 0.029313
2021-12-12 23:08:12,462 iteration 473 : loss : 0.077535, loss_ce: 0.032873
2021-12-12 23:08:13,988 iteration 474 : loss : 0.080760, loss_ce: 0.033898
2021-12-12 23:08:15,466 iteration 475 : loss : 0.096202, loss_ce: 0.033141
2021-12-12 23:08:16,964 iteration 476 : loss : 0.073369, loss_ce: 0.037190
  7%|██                            | 28/400 [12:58<2:47:43, 27.05s/it]2021-12-12 23:08:18,464 iteration 477 : loss : 0.068811, loss_ce: 0.034012
2021-12-12 23:08:19,974 iteration 478 : loss : 0.078902, loss_ce: 0.031423
2021-12-12 23:08:21,386 iteration 479 : loss : 0.085672, loss_ce: 0.033723
2021-12-12 23:08:22,766 iteration 480 : loss : 0.055982, loss_ce: 0.028645
2021-12-12 23:08:24,223 iteration 481 : loss : 0.070747, loss_ce: 0.033295
2021-12-12 23:08:25,762 iteration 482 : loss : 0.071370, loss_ce: 0.030862
2021-12-12 23:08:27,248 iteration 483 : loss : 0.086697, loss_ce: 0.030227
2021-12-12 23:08:28,716 iteration 484 : loss : 0.057667, loss_ce: 0.027456
2021-12-12 23:08:30,118 iteration 485 : loss : 0.058710, loss_ce: 0.025511
2021-12-12 23:08:31,582 iteration 486 : loss : 0.124435, loss_ce: 0.037473
2021-12-12 23:08:33,081 iteration 487 : loss : 0.073500, loss_ce: 0.037890
2021-12-12 23:08:34,650 iteration 488 : loss : 0.079053, loss_ce: 0.033767
2021-12-12 23:08:36,150 iteration 489 : loss : 0.052238, loss_ce: 0.024072
2021-12-12 23:08:37,577 iteration 490 : loss : 0.057607, loss_ce: 0.026515
2021-12-12 23:08:39,097 iteration 491 : loss : 0.081998, loss_ce: 0.035778
2021-12-12 23:08:40,519 iteration 492 : loss : 0.070183, loss_ce: 0.032368
2021-12-12 23:08:41,971 iteration 493 : loss : 0.075896, loss_ce: 0.034338
  7%|██▏                           | 29/400 [13:23<2:43:28, 26.44s/it]2021-12-12 23:08:43,445 iteration 494 : loss : 0.073892, loss_ce: 0.029387
2021-12-12 23:08:44,905 iteration 495 : loss : 0.058519, loss_ce: 0.029094
2021-12-12 23:08:46,292 iteration 496 : loss : 0.061449, loss_ce: 0.030341
2021-12-12 23:08:47,810 iteration 497 : loss : 0.064278, loss_ce: 0.027421
2021-12-12 23:08:49,266 iteration 498 : loss : 0.097002, loss_ce: 0.043678
2021-12-12 23:08:50,811 iteration 499 : loss : 0.070586, loss_ce: 0.032416
2021-12-12 23:08:52,196 iteration 500 : loss : 0.062722, loss_ce: 0.027450
2021-12-12 23:08:53,673 iteration 501 : loss : 0.088841, loss_ce: 0.031415
2021-12-12 23:08:55,116 iteration 502 : loss : 0.080422, loss_ce: 0.029525
2021-12-12 23:08:56,592 iteration 503 : loss : 0.088040, loss_ce: 0.048050
2021-12-12 23:08:58,144 iteration 504 : loss : 0.069729, loss_ce: 0.028641
2021-12-12 23:08:59,695 iteration 505 : loss : 0.076539, loss_ce: 0.034214
2021-12-12 23:09:01,183 iteration 506 : loss : 0.080599, loss_ce: 0.041283
2021-12-12 23:09:02,639 iteration 507 : loss : 0.058287, loss_ce: 0.024619
2021-12-12 23:09:04,143 iteration 508 : loss : 0.078568, loss_ce: 0.028454
2021-12-12 23:09:05,661 iteration 509 : loss : 0.062107, loss_ce: 0.030435
2021-12-12 23:09:05,661 Training Data Eval:
2021-12-12 23:09:13,214   Average segmentation loss on training set: 0.0536
2021-12-12 23:09:13,215 Validation Data Eval:
2021-12-12 23:09:15,826   Average segmentation loss on validation set: 0.0982
2021-12-12 23:09:22,281 Found new lowest validation loss at iteration 509! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/TU_3seeds/TU_SGD_best_val_loss_seed2.pth
2021-12-12 23:09:23,617 iteration 510 : loss : 0.072948, loss_ce: 0.029406
  8%|██▎                           | 30/400 [14:05<3:11:11, 31.00s/it]2021-12-12 23:09:24,969 iteration 511 : loss : 0.068241, loss_ce: 0.027111
2021-12-12 23:09:26,308 iteration 512 : loss : 0.073356, loss_ce: 0.031046
2021-12-12 23:09:27,662 iteration 513 : loss : 0.072420, loss_ce: 0.029978
2021-12-12 23:09:29,059 iteration 514 : loss : 0.077080, loss_ce: 0.035440
2021-12-12 23:09:30,437 iteration 515 : loss : 0.051277, loss_ce: 0.026832
2021-12-12 23:09:31,800 iteration 516 : loss : 0.057757, loss_ce: 0.022682
2021-12-12 23:09:33,337 iteration 517 : loss : 0.067094, loss_ce: 0.033006
2021-12-12 23:09:34,899 iteration 518 : loss : 0.090014, loss_ce: 0.032231
2021-12-12 23:09:36,448 iteration 519 : loss : 0.061516, loss_ce: 0.032062
2021-12-12 23:09:37,929 iteration 520 : loss : 0.069350, loss_ce: 0.032786
2021-12-12 23:09:39,335 iteration 521 : loss : 0.062215, loss_ce: 0.024542
2021-12-12 23:09:40,852 iteration 522 : loss : 0.055306, loss_ce: 0.025799
2021-12-12 23:09:42,312 iteration 523 : loss : 0.068168, loss_ce: 0.024187
2021-12-12 23:09:43,754 iteration 524 : loss : 0.069212, loss_ce: 0.033551
2021-12-12 23:09:45,205 iteration 525 : loss : 0.067476, loss_ce: 0.029137
2021-12-12 23:09:46,711 iteration 526 : loss : 0.073820, loss_ce: 0.029957
2021-12-12 23:09:48,224 iteration 527 : loss : 0.080140, loss_ce: 0.030550
  8%|██▎                           | 31/400 [14:30<2:58:52, 29.08s/it]2021-12-12 23:09:49,712 iteration 528 : loss : 0.059409, loss_ce: 0.027468
2021-12-12 23:09:51,293 iteration 529 : loss : 0.107311, loss_ce: 0.035184
2021-12-12 23:09:52,737 iteration 530 : loss : 0.064108, loss_ce: 0.023210
2021-12-12 23:09:54,165 iteration 531 : loss : 0.067846, loss_ce: 0.026394
2021-12-12 23:09:55,651 iteration 532 : loss : 0.080752, loss_ce: 0.035480
2021-12-12 23:09:57,124 iteration 533 : loss : 0.069611, loss_ce: 0.029705
2021-12-12 23:09:58,580 iteration 534 : loss : 0.062950, loss_ce: 0.025034
2021-12-12 23:10:00,086 iteration 535 : loss : 0.071484, loss_ce: 0.028074
2021-12-12 23:10:01,562 iteration 536 : loss : 0.056375, loss_ce: 0.029814
2021-12-12 23:10:03,017 iteration 537 : loss : 0.062945, loss_ce: 0.026564
2021-12-12 23:10:04,492 iteration 538 : loss : 0.072037, loss_ce: 0.039499
2021-12-12 23:10:05,892 iteration 539 : loss : 0.065316, loss_ce: 0.028568
2021-12-12 23:10:07,483 iteration 540 : loss : 0.082023, loss_ce: 0.045170
2021-12-12 23:10:09,058 iteration 541 : loss : 0.103123, loss_ce: 0.050859
2021-12-12 23:10:10,476 iteration 542 : loss : 0.077496, loss_ce: 0.029731
2021-12-12 23:10:11,948 iteration 543 : loss : 0.061537, loss_ce: 0.027704
2021-12-12 23:10:13,398 iteration 544 : loss : 0.121296, loss_ce: 0.037518
  8%|██▍                           | 32/400 [14:55<2:51:11, 27.91s/it]2021-12-12 23:10:14,977 iteration 545 : loss : 0.083410, loss_ce: 0.035871
2021-12-12 23:10:16,526 iteration 546 : loss : 0.059874, loss_ce: 0.027916
2021-12-12 23:10:18,049 iteration 547 : loss : 0.077857, loss_ce: 0.034309
2021-12-12 23:10:19,461 iteration 548 : loss : 0.071311, loss_ce: 0.032583
2021-12-12 23:10:20,877 iteration 549 : loss : 0.071374, loss_ce: 0.029561
2021-12-12 23:10:22,311 iteration 550 : loss : 0.058351, loss_ce: 0.024401
2021-12-12 23:10:23,731 iteration 551 : loss : 0.066175, loss_ce: 0.023215
2021-12-12 23:10:25,242 iteration 552 : loss : 0.074043, loss_ce: 0.029644
2021-12-12 23:10:26,731 iteration 553 : loss : 0.074558, loss_ce: 0.032166
2021-12-12 23:10:28,214 iteration 554 : loss : 0.067749, loss_ce: 0.026696
2021-12-12 23:10:29,725 iteration 555 : loss : 0.071174, loss_ce: 0.023037
2021-12-12 23:10:31,272 iteration 556 : loss : 0.080027, loss_ce: 0.037835
2021-12-12 23:10:32,707 iteration 557 : loss : 0.077339, loss_ce: 0.042730
2021-12-12 23:10:34,115 iteration 558 : loss : 0.052794, loss_ce: 0.023182
2021-12-12 23:10:35,557 iteration 559 : loss : 0.070336, loss_ce: 0.027868
2021-12-12 23:10:37,088 iteration 560 : loss : 0.084370, loss_ce: 0.034620
2021-12-12 23:10:38,607 iteration 561 : loss : 0.067777, loss_ce: 0.031610
  8%|██▍                           | 33/400 [15:20<2:45:45, 27.10s/it]2021-12-12 23:10:40,153 iteration 562 : loss : 0.071372, loss_ce: 0.026298
2021-12-12 23:10:41,573 iteration 563 : loss : 0.066120, loss_ce: 0.033333
2021-12-12 23:10:42,995 iteration 564 : loss : 0.069269, loss_ce: 0.035964
2021-12-12 23:10:44,512 iteration 565 : loss : 0.055341, loss_ce: 0.027068
2021-12-12 23:10:45,992 iteration 566 : loss : 0.095026, loss_ce: 0.034146
2021-12-12 23:10:47,491 iteration 567 : loss : 0.088438, loss_ce: 0.034515
2021-12-12 23:10:48,985 iteration 568 : loss : 0.099771, loss_ce: 0.028676
2021-12-12 23:10:50,553 iteration 569 : loss : 0.109537, loss_ce: 0.039243
2021-12-12 23:10:52,038 iteration 570 : loss : 0.065965, loss_ce: 0.028127
2021-12-12 23:10:53,549 iteration 571 : loss : 0.065124, loss_ce: 0.029710
2021-12-12 23:10:55,083 iteration 572 : loss : 0.064872, loss_ce: 0.033836
2021-12-12 23:10:56,529 iteration 573 : loss : 0.073556, loss_ce: 0.033239
2021-12-12 23:10:58,080 iteration 574 : loss : 0.069582, loss_ce: 0.030133
2021-12-12 23:10:59,543 iteration 575 : loss : 0.065626, loss_ce: 0.025721
2021-12-12 23:11:00,954 iteration 576 : loss : 0.077369, loss_ce: 0.039028
2021-12-12 23:11:02,556 iteration 577 : loss : 0.099457, loss_ce: 0.043448
2021-12-12 23:11:04,064 iteration 578 : loss : 0.072554, loss_ce: 0.030319
  8%|██▌                           | 34/400 [15:46<2:42:17, 26.60s/it]2021-12-12 23:11:05,509 iteration 579 : loss : 0.049750, loss_ce: 0.025218
2021-12-12 23:11:07,021 iteration 580 : loss : 0.068984, loss_ce: 0.028050
2021-12-12 23:11:08,650 iteration 581 : loss : 0.065346, loss_ce: 0.028152
2021-12-12 23:11:10,068 iteration 582 : loss : 0.059900, loss_ce: 0.028280
2021-12-12 23:11:11,558 iteration 583 : loss : 0.065664, loss_ce: 0.031981
2021-12-12 23:11:13,068 iteration 584 : loss : 0.068776, loss_ce: 0.031079
2021-12-12 23:11:14,513 iteration 585 : loss : 0.070003, loss_ce: 0.026060
2021-12-12 23:11:16,018 iteration 586 : loss : 0.072146, loss_ce: 0.027793
2021-12-12 23:11:17,509 iteration 587 : loss : 0.054229, loss_ce: 0.026053
2021-12-12 23:11:18,936 iteration 588 : loss : 0.068589, loss_ce: 0.028004
2021-12-12 23:11:20,471 iteration 589 : loss : 0.083768, loss_ce: 0.037029
2021-12-12 23:11:21,929 iteration 590 : loss : 0.069168, loss_ce: 0.028736
2021-12-12 23:11:23,391 iteration 591 : loss : 0.059979, loss_ce: 0.025552
2021-12-12 23:11:24,902 iteration 592 : loss : 0.057535, loss_ce: 0.029130
2021-12-12 23:11:26,317 iteration 593 : loss : 0.069922, loss_ce: 0.030499
2021-12-12 23:11:27,834 iteration 594 : loss : 0.073703, loss_ce: 0.027875
2021-12-12 23:11:27,835 Training Data Eval:
2021-12-12 23:11:35,370   Average segmentation loss on training set: 0.0486
2021-12-12 23:11:35,370 Validation Data Eval:
2021-12-12 23:11:37,970   Average segmentation loss on validation set: 0.1016
2021-12-12 23:11:39,453 iteration 595 : loss : 0.083293, loss_ce: 0.029690
  9%|██▋                           | 35/400 [16:21<2:57:53, 29.24s/it]2021-12-12 23:11:41,048 iteration 596 : loss : 0.088149, loss_ce: 0.035884
2021-12-12 23:11:42,517 iteration 597 : loss : 0.052287, loss_ce: 0.024592
2021-12-12 23:11:43,983 iteration 598 : loss : 0.053149, loss_ce: 0.023974
2021-12-12 23:11:45,487 iteration 599 : loss : 0.084367, loss_ce: 0.027564
2021-12-12 23:11:47,015 iteration 600 : loss : 0.062144, loss_ce: 0.024932
2021-12-12 23:11:48,521 iteration 601 : loss : 0.062498, loss_ce: 0.026149
2021-12-12 23:11:49,908 iteration 602 : loss : 0.060678, loss_ce: 0.028811
2021-12-12 23:11:51,375 iteration 603 : loss : 0.062984, loss_ce: 0.029263
2021-12-12 23:11:52,806 iteration 604 : loss : 0.071893, loss_ce: 0.024955
2021-12-12 23:11:54,372 iteration 605 : loss : 0.069825, loss_ce: 0.030076
2021-12-12 23:11:55,804 iteration 606 : loss : 0.049460, loss_ce: 0.022224
2021-12-12 23:11:57,230 iteration 607 : loss : 0.047200, loss_ce: 0.020480
2021-12-12 23:11:58,655 iteration 608 : loss : 0.042720, loss_ce: 0.023429
2021-12-12 23:12:00,076 iteration 609 : loss : 0.060286, loss_ce: 0.024659
2021-12-12 23:12:01,641 iteration 610 : loss : 0.092343, loss_ce: 0.043267
2021-12-12 23:12:03,105 iteration 611 : loss : 0.071696, loss_ce: 0.036599
2021-12-12 23:12:04,511 iteration 612 : loss : 0.059333, loss_ce: 0.027112
  9%|██▋                           | 36/400 [16:46<2:49:46, 27.99s/it]2021-12-12 23:12:06,015 iteration 613 : loss : 0.078474, loss_ce: 0.031849
2021-12-12 23:12:07,542 iteration 614 : loss : 0.079295, loss_ce: 0.032955
2021-12-12 23:12:09,034 iteration 615 : loss : 0.053307, loss_ce: 0.026649
2021-12-12 23:12:10,488 iteration 616 : loss : 0.074739, loss_ce: 0.027148
2021-12-12 23:12:11,994 iteration 617 : loss : 0.071348, loss_ce: 0.027259
2021-12-12 23:12:13,537 iteration 618 : loss : 0.055349, loss_ce: 0.026690
2021-12-12 23:12:15,046 iteration 619 : loss : 0.054227, loss_ce: 0.024684
2021-12-12 23:12:16,565 iteration 620 : loss : 0.052994, loss_ce: 0.024586
2021-12-12 23:12:17,954 iteration 621 : loss : 0.060509, loss_ce: 0.023967
2021-12-12 23:12:19,486 iteration 622 : loss : 0.078232, loss_ce: 0.029715
2021-12-12 23:12:21,028 iteration 623 : loss : 0.064307, loss_ce: 0.028116
2021-12-12 23:12:22,429 iteration 624 : loss : 0.064050, loss_ce: 0.027958
2021-12-12 23:12:24,027 iteration 625 : loss : 0.077637, loss_ce: 0.031597
2021-12-12 23:12:25,489 iteration 626 : loss : 0.067720, loss_ce: 0.028475
2021-12-12 23:12:26,896 iteration 627 : loss : 0.089788, loss_ce: 0.030518
2021-12-12 23:12:28,279 iteration 628 : loss : 0.068033, loss_ce: 0.026240
2021-12-12 23:12:29,767 iteration 629 : loss : 0.054997, loss_ce: 0.025140
  9%|██▊                           | 37/400 [17:11<2:44:22, 27.17s/it]2021-12-12 23:12:31,195 iteration 630 : loss : 0.054217, loss_ce: 0.026452
2021-12-12 23:12:32,658 iteration 631 : loss : 0.065560, loss_ce: 0.026258
2021-12-12 23:12:34,063 iteration 632 : loss : 0.052553, loss_ce: 0.021476
2021-12-12 23:12:35,564 iteration 633 : loss : 0.072289, loss_ce: 0.034818
2021-12-12 23:12:37,050 iteration 634 : loss : 0.059860, loss_ce: 0.028811
2021-12-12 23:12:38,550 iteration 635 : loss : 0.059858, loss_ce: 0.025026
2021-12-12 23:12:39,999 iteration 636 : loss : 0.086890, loss_ce: 0.029991
2021-12-12 23:12:41,426 iteration 637 : loss : 0.068911, loss_ce: 0.030911
2021-12-12 23:12:42,857 iteration 638 : loss : 0.050964, loss_ce: 0.025385
2021-12-12 23:12:44,362 iteration 639 : loss : 0.058772, loss_ce: 0.027543
2021-12-12 23:12:45,883 iteration 640 : loss : 0.063398, loss_ce: 0.023299
2021-12-12 23:12:47,316 iteration 641 : loss : 0.052687, loss_ce: 0.021997
2021-12-12 23:12:48,789 iteration 642 : loss : 0.053027, loss_ce: 0.022481
2021-12-12 23:12:50,239 iteration 643 : loss : 0.061794, loss_ce: 0.026578
2021-12-12 23:12:51,700 iteration 644 : loss : 0.066760, loss_ce: 0.022802
2021-12-12 23:12:53,132 iteration 645 : loss : 0.056970, loss_ce: 0.024421
2021-12-12 23:12:54,635 iteration 646 : loss : 0.055651, loss_ce: 0.024016
 10%|██▊                           | 38/400 [17:36<2:39:45, 26.48s/it]2021-12-12 23:12:56,115 iteration 647 : loss : 0.057321, loss_ce: 0.026676
2021-12-12 23:12:57,637 iteration 648 : loss : 0.067182, loss_ce: 0.028727
2021-12-12 23:12:59,126 iteration 649 : loss : 0.068326, loss_ce: 0.028054
2021-12-12 23:13:00,527 iteration 650 : loss : 0.067749, loss_ce: 0.036962
2021-12-12 23:13:02,003 iteration 651 : loss : 0.065108, loss_ce: 0.025012
2021-12-12 23:13:03,416 iteration 652 : loss : 0.061115, loss_ce: 0.024080
2021-12-12 23:13:04,896 iteration 653 : loss : 0.096167, loss_ce: 0.028477
2021-12-12 23:13:06,426 iteration 654 : loss : 0.058876, loss_ce: 0.024047
2021-12-12 23:13:07,925 iteration 655 : loss : 0.047541, loss_ce: 0.020593
2021-12-12 23:13:09,340 iteration 656 : loss : 0.049717, loss_ce: 0.021301
2021-12-12 23:13:10,812 iteration 657 : loss : 0.046007, loss_ce: 0.021265
2021-12-12 23:13:12,332 iteration 658 : loss : 0.108041, loss_ce: 0.036541
2021-12-12 23:13:13,860 iteration 659 : loss : 0.063853, loss_ce: 0.029612
2021-12-12 23:13:15,358 iteration 660 : loss : 0.056992, loss_ce: 0.021187
2021-12-12 23:13:16,831 iteration 661 : loss : 0.058166, loss_ce: 0.028387
2021-12-12 23:13:18,264 iteration 662 : loss : 0.061079, loss_ce: 0.030276
2021-12-12 23:13:19,727 iteration 663 : loss : 0.052754, loss_ce: 0.020769
 10%|██▉                           | 39/400 [18:01<2:36:48, 26.06s/it]2021-12-12 23:13:21,196 iteration 664 : loss : 0.052362, loss_ce: 0.025455
2021-12-12 23:13:22,647 iteration 665 : loss : 0.065989, loss_ce: 0.030321
2021-12-12 23:13:24,128 iteration 666 : loss : 0.072829, loss_ce: 0.028888
2021-12-12 23:13:25,557 iteration 667 : loss : 0.055062, loss_ce: 0.027532
2021-12-12 23:13:27,079 iteration 668 : loss : 0.060141, loss_ce: 0.025395
2021-12-12 23:13:28,510 iteration 669 : loss : 0.067143, loss_ce: 0.029985
2021-12-12 23:13:29,948 iteration 670 : loss : 0.050844, loss_ce: 0.023571
2021-12-12 23:13:31,477 iteration 671 : loss : 0.053466, loss_ce: 0.019622
2021-12-12 23:13:32,996 iteration 672 : loss : 0.058760, loss_ce: 0.022288
2021-12-12 23:13:34,421 iteration 673 : loss : 0.055733, loss_ce: 0.027023
2021-12-12 23:13:35,918 iteration 674 : loss : 0.074946, loss_ce: 0.030477
2021-12-12 23:13:37,440 iteration 675 : loss : 0.086670, loss_ce: 0.035261
2021-12-12 23:13:38,886 iteration 676 : loss : 0.068220, loss_ce: 0.022591
2021-12-12 23:13:40,365 iteration 677 : loss : 0.066513, loss_ce: 0.030317
2021-12-12 23:13:41,825 iteration 678 : loss : 0.057190, loss_ce: 0.023503
2021-12-12 23:13:43,244 iteration 679 : loss : 0.081686, loss_ce: 0.041209
2021-12-12 23:13:43,244 Training Data Eval:
2021-12-12 23:13:50,782   Average segmentation loss on training set: 0.0409
2021-12-12 23:13:50,783 Validation Data Eval:
2021-12-12 23:13:53,386   Average segmentation loss on validation set: 0.0940
2021-12-12 23:13:59,688 Found new lowest validation loss at iteration 679! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/TU_3seeds/TU_SGD_best_val_loss_seed2.pth
2021-12-12 23:14:01,077 iteration 680 : loss : 0.081454, loss_ce: 0.021343
 10%|███                           | 40/400 [18:43<3:03:53, 30.65s/it]2021-12-12 23:14:02,518 iteration 681 : loss : 0.067973, loss_ce: 0.029403
2021-12-12 23:14:03,834 iteration 682 : loss : 0.050199, loss_ce: 0.018042
2021-12-12 23:14:05,206 iteration 683 : loss : 0.061210, loss_ce: 0.027838
2021-12-12 23:14:06,587 iteration 684 : loss : 0.053151, loss_ce: 0.023416
2021-12-12 23:14:08,024 iteration 685 : loss : 0.057109, loss_ce: 0.026698
2021-12-12 23:14:09,392 iteration 686 : loss : 0.058417, loss_ce: 0.021326
2021-12-12 23:14:10,817 iteration 687 : loss : 0.053775, loss_ce: 0.021868
2021-12-12 23:14:12,354 iteration 688 : loss : 0.060451, loss_ce: 0.029910
2021-12-12 23:14:13,845 iteration 689 : loss : 0.048596, loss_ce: 0.023678
2021-12-12 23:14:15,263 iteration 690 : loss : 0.072101, loss_ce: 0.038958
2021-12-12 23:14:16,810 iteration 691 : loss : 0.069083, loss_ce: 0.030013
2021-12-12 23:14:18,335 iteration 692 : loss : 0.068213, loss_ce: 0.024685
2021-12-12 23:14:19,861 iteration 693 : loss : 0.079950, loss_ce: 0.032240
2021-12-12 23:14:21,335 iteration 694 : loss : 0.058061, loss_ce: 0.024100
2021-12-12 23:14:22,803 iteration 695 : loss : 0.077048, loss_ce: 0.027278
2021-12-12 23:14:24,262 iteration 696 : loss : 0.053174, loss_ce: 0.024919
2021-12-12 23:14:25,751 iteration 697 : loss : 0.070149, loss_ce: 0.025998
 10%|███                           | 41/400 [19:07<2:52:39, 28.86s/it]2021-12-12 23:14:27,237 iteration 698 : loss : 0.060849, loss_ce: 0.025795
2021-12-12 23:14:28,704 iteration 699 : loss : 0.058410, loss_ce: 0.022224
2021-12-12 23:14:30,181 iteration 700 : loss : 0.056534, loss_ce: 0.023623
2021-12-12 23:14:31,635 iteration 701 : loss : 0.052114, loss_ce: 0.022872
2021-12-12 23:14:33,137 iteration 702 : loss : 0.054379, loss_ce: 0.019272
2021-12-12 23:14:34,605 iteration 703 : loss : 0.081280, loss_ce: 0.033096
2021-12-12 23:14:36,060 iteration 704 : loss : 0.058492, loss_ce: 0.020732
2021-12-12 23:14:37,486 iteration 705 : loss : 0.057863, loss_ce: 0.027383
2021-12-12 23:14:39,000 iteration 706 : loss : 0.065979, loss_ce: 0.029508
2021-12-12 23:14:40,497 iteration 707 : loss : 0.071505, loss_ce: 0.031981
2021-12-12 23:14:41,982 iteration 708 : loss : 0.081917, loss_ce: 0.036486
2021-12-12 23:14:43,478 iteration 709 : loss : 0.056219, loss_ce: 0.025044
2021-12-12 23:14:44,957 iteration 710 : loss : 0.058527, loss_ce: 0.021585
2021-12-12 23:14:46,475 iteration 711 : loss : 0.096924, loss_ce: 0.032896
2021-12-12 23:14:48,021 iteration 712 : loss : 0.062920, loss_ce: 0.031801
2021-12-12 23:14:49,455 iteration 713 : loss : 0.055512, loss_ce: 0.025519
2021-12-12 23:14:50,918 iteration 714 : loss : 0.046464, loss_ce: 0.021840
 10%|███▏                          | 42/400 [19:32<2:45:34, 27.75s/it]2021-12-12 23:14:52,416 iteration 715 : loss : 0.046884, loss_ce: 0.022673
2021-12-12 23:14:53,888 iteration 716 : loss : 0.092843, loss_ce: 0.028453
2021-12-12 23:14:55,335 iteration 717 : loss : 0.049033, loss_ce: 0.019394
2021-12-12 23:14:56,709 iteration 718 : loss : 0.046976, loss_ce: 0.019869
2021-12-12 23:14:58,167 iteration 719 : loss : 0.065404, loss_ce: 0.031591
2021-12-12 23:14:59,552 iteration 720 : loss : 0.062062, loss_ce: 0.026900
2021-12-12 23:15:01,139 iteration 721 : loss : 0.074969, loss_ce: 0.027830
2021-12-12 23:15:02,616 iteration 722 : loss : 0.050801, loss_ce: 0.023527
2021-12-12 23:15:04,112 iteration 723 : loss : 0.060573, loss_ce: 0.024781
2021-12-12 23:15:05,652 iteration 724 : loss : 0.062288, loss_ce: 0.023182
2021-12-12 23:15:07,077 iteration 725 : loss : 0.049930, loss_ce: 0.022264
2021-12-12 23:15:08,562 iteration 726 : loss : 0.064954, loss_ce: 0.028815
2021-12-12 23:15:10,013 iteration 727 : loss : 0.042569, loss_ce: 0.018776
2021-12-12 23:15:11,461 iteration 728 : loss : 0.057958, loss_ce: 0.020575
2021-12-12 23:15:12,904 iteration 729 : loss : 0.066807, loss_ce: 0.033017
2021-12-12 23:15:14,422 iteration 730 : loss : 0.055114, loss_ce: 0.018601
2021-12-12 23:15:15,854 iteration 731 : loss : 0.085832, loss_ce: 0.031695
 11%|███▏                          | 43/400 [19:57<2:40:05, 26.91s/it]2021-12-12 23:15:17,396 iteration 732 : loss : 0.051323, loss_ce: 0.021843
2021-12-12 23:15:18,891 iteration 733 : loss : 0.057646, loss_ce: 0.025228
2021-12-12 23:15:20,376 iteration 734 : loss : 0.069926, loss_ce: 0.034178
2021-12-12 23:15:21,881 iteration 735 : loss : 0.062424, loss_ce: 0.029781
2021-12-12 23:15:23,372 iteration 736 : loss : 0.052530, loss_ce: 0.023549
2021-12-12 23:15:24,784 iteration 737 : loss : 0.049940, loss_ce: 0.020429
2021-12-12 23:15:26,308 iteration 738 : loss : 0.057263, loss_ce: 0.023659
2021-12-12 23:15:27,801 iteration 739 : loss : 0.064410, loss_ce: 0.031915
2021-12-12 23:15:29,266 iteration 740 : loss : 0.051577, loss_ce: 0.019924
2021-12-12 23:15:30,767 iteration 741 : loss : 0.063100, loss_ce: 0.025302
2021-12-12 23:15:32,268 iteration 742 : loss : 0.058820, loss_ce: 0.023354
2021-12-12 23:15:33,722 iteration 743 : loss : 0.056250, loss_ce: 0.019378
2021-12-12 23:15:35,202 iteration 744 : loss : 0.051901, loss_ce: 0.023656
2021-12-12 23:15:36,669 iteration 745 : loss : 0.053539, loss_ce: 0.020576
2021-12-12 23:15:38,126 iteration 746 : loss : 0.081404, loss_ce: 0.028182
2021-12-12 23:15:39,577 iteration 747 : loss : 0.064855, loss_ce: 0.030877
2021-12-12 23:15:41,066 iteration 748 : loss : 0.060131, loss_ce: 0.023352
 11%|███▎                          | 44/400 [20:23<2:36:36, 26.39s/it]2021-12-12 23:15:42,546 iteration 749 : loss : 0.071999, loss_ce: 0.026647
2021-12-12 23:15:43,995 iteration 750 : loss : 0.051936, loss_ce: 0.018930
2021-12-12 23:15:45,504 iteration 751 : loss : 0.073184, loss_ce: 0.030198
2021-12-12 23:15:46,942 iteration 752 : loss : 0.057537, loss_ce: 0.024628
2021-12-12 23:15:48,442 iteration 753 : loss : 0.070246, loss_ce: 0.027644
2021-12-12 23:15:49,906 iteration 754 : loss : 0.040054, loss_ce: 0.015490
2021-12-12 23:15:51,384 iteration 755 : loss : 0.044975, loss_ce: 0.020316
2021-12-12 23:15:52,768 iteration 756 : loss : 0.057524, loss_ce: 0.024800
2021-12-12 23:15:54,179 iteration 757 : loss : 0.049336, loss_ce: 0.022064
2021-12-12 23:15:55,649 iteration 758 : loss : 0.056770, loss_ce: 0.023306
2021-12-12 23:15:57,157 iteration 759 : loss : 0.077079, loss_ce: 0.027051
2021-12-12 23:15:58,636 iteration 760 : loss : 0.060523, loss_ce: 0.022744
2021-12-12 23:16:00,163 iteration 761 : loss : 0.088297, loss_ce: 0.031768
2021-12-12 23:16:01,552 iteration 762 : loss : 0.050792, loss_ce: 0.023204
2021-12-12 23:16:03,019 iteration 763 : loss : 0.057319, loss_ce: 0.028105
2021-12-12 23:16:04,408 iteration 764 : loss : 0.049976, loss_ce: 0.021762
2021-12-12 23:16:04,409 Training Data Eval:
2021-12-12 23:16:11,945   Average segmentation loss on training set: 0.0409
2021-12-12 23:16:11,945 Validation Data Eval:
2021-12-12 23:16:14,547   Average segmentation loss on validation set: 0.0940
2021-12-12 23:16:15,926 iteration 765 : loss : 0.049421, loss_ce: 0.023174
 11%|███▍                          | 45/400 [20:57<2:51:11, 28.93s/it]2021-12-12 23:16:17,498 iteration 766 : loss : 0.055054, loss_ce: 0.023163
2021-12-12 23:16:19,110 iteration 767 : loss : 0.069189, loss_ce: 0.030697
2021-12-12 23:16:20,610 iteration 768 : loss : 0.060544, loss_ce: 0.025741
2021-12-12 23:16:22,119 iteration 769 : loss : 0.053192, loss_ce: 0.023897
2021-12-12 23:16:23,658 iteration 770 : loss : 0.071741, loss_ce: 0.035615
2021-12-12 23:16:25,156 iteration 771 : loss : 0.046209, loss_ce: 0.022273
2021-12-12 23:16:26,563 iteration 772 : loss : 0.048220, loss_ce: 0.024067
2021-12-12 23:16:28,022 iteration 773 : loss : 0.068123, loss_ce: 0.022023
2021-12-12 23:16:29,555 iteration 774 : loss : 0.052507, loss_ce: 0.021584
2021-12-12 23:16:30,962 iteration 775 : loss : 0.054946, loss_ce: 0.025074
2021-12-12 23:16:32,416 iteration 776 : loss : 0.087536, loss_ce: 0.030713
2021-12-12 23:16:33,988 iteration 777 : loss : 0.051997, loss_ce: 0.024771
2021-12-12 23:16:35,466 iteration 778 : loss : 0.052545, loss_ce: 0.020772
2021-12-12 23:16:36,933 iteration 779 : loss : 0.058548, loss_ce: 0.024292
2021-12-12 23:16:38,516 iteration 780 : loss : 0.085884, loss_ce: 0.033815
2021-12-12 23:16:40,030 iteration 781 : loss : 0.052417, loss_ce: 0.018614
2021-12-12 23:16:41,477 iteration 782 : loss : 0.049516, loss_ce: 0.020224
 12%|███▍                          | 46/400 [21:23<2:44:43, 27.92s/it]2021-12-12 23:16:42,982 iteration 783 : loss : 0.064682, loss_ce: 0.025038
2021-12-12 23:16:44,419 iteration 784 : loss : 0.043511, loss_ce: 0.017934
2021-12-12 23:16:45,949 iteration 785 : loss : 0.072400, loss_ce: 0.026050
2021-12-12 23:16:47,400 iteration 786 : loss : 0.065306, loss_ce: 0.025919
2021-12-12 23:16:48,915 iteration 787 : loss : 0.070824, loss_ce: 0.030420
2021-12-12 23:16:50,349 iteration 788 : loss : 0.063869, loss_ce: 0.028766
2021-12-12 23:16:51,859 iteration 789 : loss : 0.066978, loss_ce: 0.025988
2021-12-12 23:16:53,384 iteration 790 : loss : 0.042928, loss_ce: 0.018255
2021-12-12 23:16:54,791 iteration 791 : loss : 0.054286, loss_ce: 0.025069
2021-12-12 23:16:56,319 iteration 792 : loss : 0.059629, loss_ce: 0.023870
2021-12-12 23:16:57,817 iteration 793 : loss : 0.057690, loss_ce: 0.023706
2021-12-12 23:16:59,336 iteration 794 : loss : 0.057962, loss_ce: 0.024135
2021-12-12 23:17:00,838 iteration 795 : loss : 0.066091, loss_ce: 0.026413
2021-12-12 23:17:02,411 iteration 796 : loss : 0.074680, loss_ce: 0.030940
2021-12-12 23:17:03,880 iteration 797 : loss : 0.047622, loss_ce: 0.022359
2021-12-12 23:17:05,346 iteration 798 : loss : 0.058430, loss_ce: 0.025441
2021-12-12 23:17:06,931 iteration 799 : loss : 0.078235, loss_ce: 0.025674
 12%|███▌                          | 47/400 [21:48<2:39:54, 27.18s/it]2021-12-12 23:17:08,485 iteration 800 : loss : 0.053476, loss_ce: 0.028102
2021-12-12 23:17:09,938 iteration 801 : loss : 0.072349, loss_ce: 0.022766
2021-12-12 23:17:11,444 iteration 802 : loss : 0.061625, loss_ce: 0.031192
2021-12-12 23:17:12,843 iteration 803 : loss : 0.057878, loss_ce: 0.023412
2021-12-12 23:17:14,400 iteration 804 : loss : 0.088737, loss_ce: 0.027110
2021-12-12 23:17:15,850 iteration 805 : loss : 0.053378, loss_ce: 0.022148
2021-12-12 23:17:17,250 iteration 806 : loss : 0.058552, loss_ce: 0.023488
2021-12-12 23:17:18,709 iteration 807 : loss : 0.048774, loss_ce: 0.024883
2021-12-12 23:17:20,173 iteration 808 : loss : 0.058108, loss_ce: 0.019032
2021-12-12 23:17:21,693 iteration 809 : loss : 0.055183, loss_ce: 0.022166
2021-12-12 23:17:23,118 iteration 810 : loss : 0.053749, loss_ce: 0.019892
2021-12-12 23:17:24,629 iteration 811 : loss : 0.083095, loss_ce: 0.038118
2021-12-12 23:17:26,049 iteration 812 : loss : 0.052447, loss_ce: 0.026059
2021-12-12 23:17:27,579 iteration 813 : loss : 0.060588, loss_ce: 0.026493
2021-12-12 23:17:29,144 iteration 814 : loss : 0.096559, loss_ce: 0.025225
2021-12-12 23:17:30,496 iteration 815 : loss : 0.050136, loss_ce: 0.026487
2021-12-12 23:17:32,023 iteration 816 : loss : 0.063133, loss_ce: 0.027218
 12%|███▌                          | 48/400 [22:13<2:35:47, 26.55s/it]2021-12-12 23:17:33,495 iteration 817 : loss : 0.070503, loss_ce: 0.029977
2021-12-12 23:17:34,943 iteration 818 : loss : 0.051818, loss_ce: 0.026349
2021-12-12 23:17:36,547 iteration 819 : loss : 0.079341, loss_ce: 0.040324
2021-12-12 23:17:38,079 iteration 820 : loss : 0.059165, loss_ce: 0.023874
2021-12-12 23:17:39,589 iteration 821 : loss : 0.047171, loss_ce: 0.020269
2021-12-12 23:17:41,067 iteration 822 : loss : 0.069223, loss_ce: 0.030078
2021-12-12 23:17:42,577 iteration 823 : loss : 0.057927, loss_ce: 0.023621
2021-12-12 23:17:43,988 iteration 824 : loss : 0.050300, loss_ce: 0.019719
2021-12-12 23:17:45,454 iteration 825 : loss : 0.081882, loss_ce: 0.026587
2021-12-12 23:17:46,858 iteration 826 : loss : 0.039359, loss_ce: 0.017837
2021-12-12 23:17:48,320 iteration 827 : loss : 0.057925, loss_ce: 0.021868
2021-12-12 23:17:49,708 iteration 828 : loss : 0.050981, loss_ce: 0.019802
2021-12-12 23:17:51,249 iteration 829 : loss : 0.068037, loss_ce: 0.031583
2021-12-12 23:17:52,713 iteration 830 : loss : 0.061283, loss_ce: 0.029978
2021-12-12 23:17:54,214 iteration 831 : loss : 0.063154, loss_ce: 0.024903
2021-12-12 23:17:55,693 iteration 832 : loss : 0.050656, loss_ce: 0.019182
2021-12-12 23:17:57,172 iteration 833 : loss : 0.051668, loss_ce: 0.024661
 12%|███▋                          | 49/400 [22:39<2:32:52, 26.13s/it]2021-12-12 23:17:58,605 iteration 834 : loss : 0.052434, loss_ce: 0.020433
2021-12-12 23:17:59,982 iteration 835 : loss : 0.036168, loss_ce: 0.014742
2021-12-12 23:18:01,512 iteration 836 : loss : 0.065561, loss_ce: 0.022423
2021-12-12 23:18:02,950 iteration 837 : loss : 0.038535, loss_ce: 0.016495
2021-12-12 23:18:04,448 iteration 838 : loss : 0.058225, loss_ce: 0.026995
2021-12-12 23:18:05,835 iteration 839 : loss : 0.049625, loss_ce: 0.021112
2021-12-12 23:18:07,234 iteration 840 : loss : 0.044656, loss_ce: 0.022490
2021-12-12 23:18:08,659 iteration 841 : loss : 0.052700, loss_ce: 0.021018
2021-12-12 23:18:10,200 iteration 842 : loss : 0.078774, loss_ce: 0.026958
2021-12-12 23:18:11,633 iteration 843 : loss : 0.068166, loss_ce: 0.021680
2021-12-12 23:18:13,144 iteration 844 : loss : 0.058645, loss_ce: 0.021448
2021-12-12 23:18:14,595 iteration 845 : loss : 0.058514, loss_ce: 0.030276
2021-12-12 23:18:16,041 iteration 846 : loss : 0.047499, loss_ce: 0.023429
2021-12-12 23:18:17,579 iteration 847 : loss : 0.054191, loss_ce: 0.020331
2021-12-12 23:18:19,035 iteration 848 : loss : 0.047658, loss_ce: 0.020539
2021-12-12 23:18:20,474 iteration 849 : loss : 0.052414, loss_ce: 0.020020
2021-12-12 23:18:20,474 Training Data Eval:
2021-12-12 23:18:28,004   Average segmentation loss on training set: 0.0510
2021-12-12 23:18:28,004 Validation Data Eval:
2021-12-12 23:18:30,604   Average segmentation loss on validation set: 0.0899
2021-12-12 23:18:36,874 Found new lowest validation loss at iteration 849! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/TU_3seeds/TU_SGD_best_val_loss_seed2.pth
2021-12-12 23:18:38,186 iteration 850 : loss : 0.066208, loss_ce: 0.031764
 12%|███▊                          | 50/400 [23:20<2:58:28, 30.60s/it]2021-12-12 23:18:39,575 iteration 851 : loss : 0.054444, loss_ce: 0.022453
2021-12-12 23:18:40,916 iteration 852 : loss : 0.061910, loss_ce: 0.021104
2021-12-12 23:18:42,272 iteration 853 : loss : 0.062789, loss_ce: 0.023755
2021-12-12 23:18:43,647 iteration 854 : loss : 0.054862, loss_ce: 0.025295
2021-12-12 23:18:45,024 iteration 855 : loss : 0.049037, loss_ce: 0.022056
2021-12-12 23:18:46,519 iteration 856 : loss : 0.061260, loss_ce: 0.027269
2021-12-12 23:18:47,960 iteration 857 : loss : 0.060764, loss_ce: 0.025360
2021-12-12 23:18:49,516 iteration 858 : loss : 0.050026, loss_ce: 0.020447
2021-12-12 23:18:50,864 iteration 859 : loss : 0.052646, loss_ce: 0.018937
2021-12-12 23:18:52,312 iteration 860 : loss : 0.039745, loss_ce: 0.016955
2021-12-12 23:18:53,771 iteration 861 : loss : 0.059246, loss_ce: 0.021155
2021-12-12 23:18:55,249 iteration 862 : loss : 0.052399, loss_ce: 0.025485
2021-12-12 23:18:56,712 iteration 863 : loss : 0.055611, loss_ce: 0.020374
2021-12-12 23:18:58,156 iteration 864 : loss : 0.047967, loss_ce: 0.022129
2021-12-12 23:18:59,633 iteration 865 : loss : 0.047822, loss_ce: 0.020517
2021-12-12 23:19:01,062 iteration 866 : loss : 0.057424, loss_ce: 0.027595
2021-12-12 23:19:02,562 iteration 867 : loss : 0.050296, loss_ce: 0.020706
 13%|███▊                          | 51/400 [23:44<2:47:07, 28.73s/it]2021-12-12 23:19:04,055 iteration 868 : loss : 0.045587, loss_ce: 0.021538
2021-12-12 23:19:05,567 iteration 869 : loss : 0.054562, loss_ce: 0.025821
2021-12-12 23:19:06,963 iteration 870 : loss : 0.059473, loss_ce: 0.027110
2021-12-12 23:19:08,403 iteration 871 : loss : 0.040616, loss_ce: 0.017979
2021-12-12 23:19:09,841 iteration 872 : loss : 0.061329, loss_ce: 0.028916
2021-12-12 23:19:11,322 iteration 873 : loss : 0.055190, loss_ce: 0.024697
2021-12-12 23:19:12,792 iteration 874 : loss : 0.053612, loss_ce: 0.023747
2021-12-12 23:19:14,265 iteration 875 : loss : 0.055433, loss_ce: 0.021017
2021-12-12 23:19:15,734 iteration 876 : loss : 0.056201, loss_ce: 0.019186
2021-12-12 23:19:17,267 iteration 877 : loss : 0.056105, loss_ce: 0.026036
2021-12-12 23:19:18,698 iteration 878 : loss : 0.070485, loss_ce: 0.019259
2021-12-12 23:19:20,151 iteration 879 : loss : 0.055070, loss_ce: 0.018764
2021-12-12 23:19:21,574 iteration 880 : loss : 0.053602, loss_ce: 0.024241
2021-12-12 23:19:23,117 iteration 881 : loss : 0.064232, loss_ce: 0.023706
2021-12-12 23:19:24,607 iteration 882 : loss : 0.053903, loss_ce: 0.020278
2021-12-12 23:19:26,038 iteration 883 : loss : 0.059411, loss_ce: 0.020374
2021-12-12 23:19:27,544 iteration 884 : loss : 0.058192, loss_ce: 0.023230
 13%|███▉                          | 52/400 [24:09<2:40:06, 27.61s/it]2021-12-12 23:19:29,080 iteration 885 : loss : 0.052391, loss_ce: 0.029142
2021-12-12 23:19:30,551 iteration 886 : loss : 0.062515, loss_ce: 0.031610
2021-12-12 23:19:32,019 iteration 887 : loss : 0.059533, loss_ce: 0.025613
2021-12-12 23:19:33,505 iteration 888 : loss : 0.059497, loss_ce: 0.025009
2021-12-12 23:19:34,994 iteration 889 : loss : 0.071237, loss_ce: 0.016730
2021-12-12 23:19:36,436 iteration 890 : loss : 0.050611, loss_ce: 0.019685
2021-12-12 23:19:37,911 iteration 891 : loss : 0.059601, loss_ce: 0.036544
2021-12-12 23:19:39,379 iteration 892 : loss : 0.052074, loss_ce: 0.024389
2021-12-12 23:19:40,837 iteration 893 : loss : 0.051353, loss_ce: 0.023385
2021-12-12 23:19:42,279 iteration 894 : loss : 0.041628, loss_ce: 0.016540
2021-12-12 23:19:43,726 iteration 895 : loss : 0.050638, loss_ce: 0.018305
2021-12-12 23:19:45,163 iteration 896 : loss : 0.042883, loss_ce: 0.018252
2021-12-12 23:19:46,766 iteration 897 : loss : 0.077826, loss_ce: 0.031696
2021-12-12 23:19:48,212 iteration 898 : loss : 0.061082, loss_ce: 0.024376
2021-12-12 23:19:49,728 iteration 899 : loss : 0.061782, loss_ce: 0.025630
2021-12-12 23:19:51,233 iteration 900 : loss : 0.056941, loss_ce: 0.020002
2021-12-12 23:19:52,670 iteration 901 : loss : 0.053017, loss_ce: 0.024866
 13%|███▉                          | 53/400 [24:34<2:35:21, 26.86s/it]2021-12-12 23:19:54,243 iteration 902 : loss : 0.058212, loss_ce: 0.026930
2021-12-12 23:19:55,743 iteration 903 : loss : 0.065493, loss_ce: 0.023938
2021-12-12 23:19:57,213 iteration 904 : loss : 0.065836, loss_ce: 0.032562
2021-12-12 23:19:58,661 iteration 905 : loss : 0.051280, loss_ce: 0.021793
2021-12-12 23:20:00,217 iteration 906 : loss : 0.043178, loss_ce: 0.019896
2021-12-12 23:20:01,648 iteration 907 : loss : 0.051703, loss_ce: 0.022393
2021-12-12 23:20:03,106 iteration 908 : loss : 0.053281, loss_ce: 0.027748
2021-12-12 23:20:04,605 iteration 909 : loss : 0.057491, loss_ce: 0.027063
2021-12-12 23:20:06,160 iteration 910 : loss : 0.063453, loss_ce: 0.024015
2021-12-12 23:20:07,627 iteration 911 : loss : 0.040933, loss_ce: 0.017427
2021-12-12 23:20:09,141 iteration 912 : loss : 0.067565, loss_ce: 0.025379
2021-12-12 23:20:10,610 iteration 913 : loss : 0.063137, loss_ce: 0.021267
2021-12-12 23:20:12,015 iteration 914 : loss : 0.054593, loss_ce: 0.023085
2021-12-12 23:20:13,492 iteration 915 : loss : 0.048753, loss_ce: 0.020757
2021-12-12 23:20:15,025 iteration 916 : loss : 0.074855, loss_ce: 0.022657
2021-12-12 23:20:16,511 iteration 917 : loss : 0.054947, loss_ce: 0.023219
2021-12-12 23:20:18,055 iteration 918 : loss : 0.069550, loss_ce: 0.025865
 14%|████                          | 54/400 [25:00<2:32:21, 26.42s/it]2021-12-12 23:20:19,541 iteration 919 : loss : 0.060818, loss_ce: 0.021612
2021-12-12 23:20:21,072 iteration 920 : loss : 0.044171, loss_ce: 0.021439
2021-12-12 23:20:22,485 iteration 921 : loss : 0.049593, loss_ce: 0.021114
2021-12-12 23:20:23,983 iteration 922 : loss : 0.049269, loss_ce: 0.020115
2021-12-12 23:20:25,388 iteration 923 : loss : 0.047384, loss_ce: 0.017743
2021-12-12 23:20:26,882 iteration 924 : loss : 0.065289, loss_ce: 0.021074
2021-12-12 23:20:28,381 iteration 925 : loss : 0.058256, loss_ce: 0.019147
2021-12-12 23:20:29,872 iteration 926 : loss : 0.056426, loss_ce: 0.021431
2021-12-12 23:20:31,286 iteration 927 : loss : 0.073293, loss_ce: 0.017267
2021-12-12 23:20:32,816 iteration 928 : loss : 0.069684, loss_ce: 0.034544
2021-12-12 23:20:34,267 iteration 929 : loss : 0.053644, loss_ce: 0.022619
2021-12-12 23:20:35,676 iteration 930 : loss : 0.048612, loss_ce: 0.020255
2021-12-12 23:20:37,104 iteration 931 : loss : 0.069268, loss_ce: 0.039196
2021-12-12 23:20:38,574 iteration 932 : loss : 0.047970, loss_ce: 0.025775
2021-12-12 23:20:40,083 iteration 933 : loss : 0.056613, loss_ce: 0.027954
2021-12-12 23:20:41,509 iteration 934 : loss : 0.047539, loss_ce: 0.018014
2021-12-12 23:20:41,509 Training Data Eval:
2021-12-12 23:20:49,044   Average segmentation loss on training set: 0.0464
2021-12-12 23:20:49,045 Validation Data Eval:
2021-12-12 23:20:51,653   Average segmentation loss on validation set: 0.1017
2021-12-12 23:20:53,142 iteration 935 : loss : 0.047384, loss_ce: 0.021820
 14%|████▏                         | 55/400 [25:35<2:46:51, 29.02s/it]2021-12-12 23:20:54,657 iteration 936 : loss : 0.058396, loss_ce: 0.025323
2021-12-12 23:20:56,108 iteration 937 : loss : 0.079524, loss_ce: 0.030691
2021-12-12 23:20:57,594 iteration 938 : loss : 0.049134, loss_ce: 0.020213
2021-12-12 23:20:59,160 iteration 939 : loss : 0.069814, loss_ce: 0.020902
2021-12-12 23:21:00,569 iteration 940 : loss : 0.043416, loss_ce: 0.018852
2021-12-12 23:21:02,005 iteration 941 : loss : 0.070076, loss_ce: 0.025795
2021-12-12 23:21:03,483 iteration 942 : loss : 0.064097, loss_ce: 0.029005
2021-12-12 23:21:04,975 iteration 943 : loss : 0.070747, loss_ce: 0.025142
2021-12-12 23:21:06,444 iteration 944 : loss : 0.059938, loss_ce: 0.022069
2021-12-12 23:21:07,938 iteration 945 : loss : 0.050792, loss_ce: 0.024330
2021-12-12 23:21:09,407 iteration 946 : loss : 0.053975, loss_ce: 0.022158
2021-12-12 23:21:10,874 iteration 947 : loss : 0.060492, loss_ce: 0.022567
2021-12-12 23:21:12,417 iteration 948 : loss : 0.077899, loss_ce: 0.032509
2021-12-12 23:21:13,952 iteration 949 : loss : 0.072250, loss_ce: 0.030937
2021-12-12 23:21:15,500 iteration 950 : loss : 0.058500, loss_ce: 0.024324
2021-12-12 23:21:16,953 iteration 951 : loss : 0.047727, loss_ce: 0.021000
2021-12-12 23:21:18,459 iteration 952 : loss : 0.071694, loss_ce: 0.024153
 14%|████▏                         | 56/400 [26:00<2:40:01, 27.91s/it]2021-12-12 23:21:19,951 iteration 953 : loss : 0.040745, loss_ce: 0.016635
2021-12-12 23:21:21,395 iteration 954 : loss : 0.050387, loss_ce: 0.019398
2021-12-12 23:21:22,897 iteration 955 : loss : 0.054970, loss_ce: 0.021226
2021-12-12 23:21:24,388 iteration 956 : loss : 0.040720, loss_ce: 0.015385
2021-12-12 23:21:25,864 iteration 957 : loss : 0.057518, loss_ce: 0.023912
2021-12-12 23:21:27,362 iteration 958 : loss : 0.059895, loss_ce: 0.025498
2021-12-12 23:21:28,892 iteration 959 : loss : 0.067118, loss_ce: 0.032510
2021-12-12 23:21:30,394 iteration 960 : loss : 0.051065, loss_ce: 0.023120
2021-12-12 23:21:31,877 iteration 961 : loss : 0.054037, loss_ce: 0.020096
2021-12-12 23:21:33,390 iteration 962 : loss : 0.070716, loss_ce: 0.024217
2021-12-12 23:21:34,804 iteration 963 : loss : 0.044317, loss_ce: 0.020833
2021-12-12 23:21:36,306 iteration 964 : loss : 0.048648, loss_ce: 0.020581
2021-12-12 23:21:37,743 iteration 965 : loss : 0.045176, loss_ce: 0.017773
2021-12-12 23:21:39,306 iteration 966 : loss : 0.061579, loss_ce: 0.021779
2021-12-12 23:21:40,794 iteration 967 : loss : 0.055729, loss_ce: 0.026389
2021-12-12 23:21:42,189 iteration 968 : loss : 0.052347, loss_ce: 0.020857
2021-12-12 23:21:43,664 iteration 969 : loss : 0.057299, loss_ce: 0.026024
 14%|████▎                         | 57/400 [26:25<2:34:53, 27.10s/it]2021-12-12 23:21:45,127 iteration 970 : loss : 0.058555, loss_ce: 0.029243
2021-12-12 23:21:46,619 iteration 971 : loss : 0.071584, loss_ce: 0.028085
2021-12-12 23:21:48,081 iteration 972 : loss : 0.053163, loss_ce: 0.020181
2021-12-12 23:21:49,571 iteration 973 : loss : 0.057838, loss_ce: 0.022856
2021-12-12 23:21:51,045 iteration 974 : loss : 0.054910, loss_ce: 0.022295
2021-12-12 23:21:52,471 iteration 975 : loss : 0.077670, loss_ce: 0.024545
2021-12-12 23:21:54,005 iteration 976 : loss : 0.050245, loss_ce: 0.022100
2021-12-12 23:21:55,470 iteration 977 : loss : 0.049701, loss_ce: 0.020543
2021-12-12 23:21:56,960 iteration 978 : loss : 0.049025, loss_ce: 0.021420
2021-12-12 23:21:58,409 iteration 979 : loss : 0.039460, loss_ce: 0.017225
2021-12-12 23:21:59,853 iteration 980 : loss : 0.049285, loss_ce: 0.019484
2021-12-12 23:22:01,285 iteration 981 : loss : 0.035731, loss_ce: 0.013834
2021-12-12 23:22:02,781 iteration 982 : loss : 0.071144, loss_ce: 0.022819
2021-12-12 23:22:04,321 iteration 983 : loss : 0.058203, loss_ce: 0.026425
2021-12-12 23:22:05,851 iteration 984 : loss : 0.053901, loss_ce: 0.025476
2021-12-12 23:22:07,362 iteration 985 : loss : 0.071040, loss_ce: 0.028083
2021-12-12 23:22:08,796 iteration 986 : loss : 0.053877, loss_ce: 0.016789
 14%|████▎                         | 58/400 [26:50<2:31:05, 26.51s/it]2021-12-12 23:22:10,224 iteration 987 : loss : 0.046719, loss_ce: 0.017806
2021-12-12 23:22:11,682 iteration 988 : loss : 0.049545, loss_ce: 0.021189
2021-12-12 23:22:13,153 iteration 989 : loss : 0.044520, loss_ce: 0.017501
2021-12-12 23:22:14,607 iteration 990 : loss : 0.043511, loss_ce: 0.017594
2021-12-12 23:22:16,089 iteration 991 : loss : 0.048262, loss_ce: 0.020568
2021-12-12 23:22:17,539 iteration 992 : loss : 0.043002, loss_ce: 0.019283
2021-12-12 23:22:18,937 iteration 993 : loss : 0.042286, loss_ce: 0.018302
2021-12-12 23:22:20,280 iteration 994 : loss : 0.047264, loss_ce: 0.017521
2021-12-12 23:22:21,824 iteration 995 : loss : 0.066479, loss_ce: 0.034322
2021-12-12 23:22:23,315 iteration 996 : loss : 0.044363, loss_ce: 0.021809
2021-12-12 23:22:24,848 iteration 997 : loss : 0.056934, loss_ce: 0.021134
2021-12-12 23:22:26,369 iteration 998 : loss : 0.062680, loss_ce: 0.026154
2021-12-12 23:22:27,814 iteration 999 : loss : 0.057782, loss_ce: 0.022828
2021-12-12 23:22:29,357 iteration 1000 : loss : 0.058952, loss_ce: 0.031110
2021-12-12 23:22:30,814 iteration 1001 : loss : 0.050575, loss_ce: 0.020796
2021-12-12 23:22:32,361 iteration 1002 : loss : 0.074544, loss_ce: 0.028078
2021-12-12 23:22:33,780 iteration 1003 : loss : 0.076015, loss_ce: 0.021360
 15%|████▍                         | 59/400 [27:15<2:28:03, 26.05s/it]2021-12-12 23:22:35,297 iteration 1004 : loss : 0.062471, loss_ce: 0.022039
2021-12-12 23:22:36,778 iteration 1005 : loss : 0.055964, loss_ce: 0.027720
2021-12-12 23:22:38,354 iteration 1006 : loss : 0.057352, loss_ce: 0.026000
2021-12-12 23:22:39,893 iteration 1007 : loss : 0.048326, loss_ce: 0.020657
2021-12-12 23:22:41,440 iteration 1008 : loss : 0.051311, loss_ce: 0.029002
2021-12-12 23:22:42,896 iteration 1009 : loss : 0.047496, loss_ce: 0.018362
2021-12-12 23:22:44,308 iteration 1010 : loss : 0.041372, loss_ce: 0.015253
2021-12-12 23:22:45,776 iteration 1011 : loss : 0.050956, loss_ce: 0.022016
2021-12-12 23:22:47,314 iteration 1012 : loss : 0.073812, loss_ce: 0.028139
2021-12-12 23:22:48,792 iteration 1013 : loss : 0.039594, loss_ce: 0.016966
2021-12-12 23:22:50,262 iteration 1014 : loss : 0.036357, loss_ce: 0.015151
2021-12-12 23:22:51,895 iteration 1015 : loss : 0.068226, loss_ce: 0.026274
2021-12-12 23:22:53,368 iteration 1016 : loss : 0.046961, loss_ce: 0.019934
2021-12-12 23:22:54,817 iteration 1017 : loss : 0.054398, loss_ce: 0.022648
2021-12-12 23:22:56,364 iteration 1018 : loss : 0.073689, loss_ce: 0.023851
2021-12-12 23:22:57,886 iteration 1019 : loss : 0.055430, loss_ce: 0.022338
2021-12-12 23:22:57,886 Training Data Eval:
2021-12-12 23:23:05,435   Average segmentation loss on training set: 0.0337
2021-12-12 23:23:05,435 Validation Data Eval:
2021-12-12 23:23:08,043   Average segmentation loss on validation set: 0.0907
2021-12-12 23:23:09,599 iteration 1020 : loss : 0.052391, loss_ce: 0.020223
 15%|████▌                         | 60/400 [27:51<2:44:13, 28.98s/it]2021-12-12 23:23:11,100 iteration 1021 : loss : 0.046678, loss_ce: 0.018993
2021-12-12 23:23:12,673 iteration 1022 : loss : 0.058677, loss_ce: 0.026555
2021-12-12 23:23:14,107 iteration 1023 : loss : 0.041652, loss_ce: 0.017183
2021-12-12 23:23:15,556 iteration 1024 : loss : 0.047684, loss_ce: 0.018867
2021-12-12 23:23:17,081 iteration 1025 : loss : 0.050551, loss_ce: 0.022855
2021-12-12 23:23:18,581 iteration 1026 : loss : 0.060675, loss_ce: 0.015416
2021-12-12 23:23:20,047 iteration 1027 : loss : 0.044881, loss_ce: 0.016895
2021-12-12 23:23:21,609 iteration 1028 : loss : 0.053473, loss_ce: 0.018821
2021-12-12 23:23:23,144 iteration 1029 : loss : 0.065463, loss_ce: 0.020912
2021-12-12 23:23:24,637 iteration 1030 : loss : 0.053670, loss_ce: 0.023284
2021-12-12 23:23:26,230 iteration 1031 : loss : 0.049276, loss_ce: 0.021766
2021-12-12 23:23:27,735 iteration 1032 : loss : 0.059722, loss_ce: 0.028265
2021-12-12 23:23:29,192 iteration 1033 : loss : 0.049666, loss_ce: 0.023079
2021-12-12 23:23:30,625 iteration 1034 : loss : 0.045509, loss_ce: 0.017790
2021-12-12 23:23:32,155 iteration 1035 : loss : 0.044681, loss_ce: 0.021015
2021-12-12 23:23:33,705 iteration 1036 : loss : 0.057669, loss_ce: 0.022020
2021-12-12 23:23:35,109 iteration 1037 : loss : 0.042488, loss_ce: 0.020073
 15%|████▌                         | 61/400 [28:17<2:37:51, 27.94s/it]2021-12-12 23:23:36,585 iteration 1038 : loss : 0.052036, loss_ce: 0.022202
2021-12-12 23:23:38,031 iteration 1039 : loss : 0.038251, loss_ce: 0.016692
2021-12-12 23:23:39,476 iteration 1040 : loss : 0.061492, loss_ce: 0.024118
2021-12-12 23:23:40,939 iteration 1041 : loss : 0.042792, loss_ce: 0.020557
2021-12-12 23:23:42,381 iteration 1042 : loss : 0.039326, loss_ce: 0.019956
2021-12-12 23:23:43,835 iteration 1043 : loss : 0.046778, loss_ce: 0.020554
2021-12-12 23:23:45,354 iteration 1044 : loss : 0.054868, loss_ce: 0.029963
2021-12-12 23:23:46,844 iteration 1045 : loss : 0.055823, loss_ce: 0.022063
2021-12-12 23:23:48,278 iteration 1046 : loss : 0.042361, loss_ce: 0.020107
2021-12-12 23:23:49,634 iteration 1047 : loss : 0.042212, loss_ce: 0.017677
2021-12-12 23:23:51,112 iteration 1048 : loss : 0.041961, loss_ce: 0.018090
2021-12-12 23:23:52,631 iteration 1049 : loss : 0.056039, loss_ce: 0.022297
2021-12-12 23:23:54,096 iteration 1050 : loss : 0.078382, loss_ce: 0.018631
2021-12-12 23:23:55,536 iteration 1051 : loss : 0.055525, loss_ce: 0.024207
2021-12-12 23:23:57,047 iteration 1052 : loss : 0.052410, loss_ce: 0.018270
2021-12-12 23:23:58,551 iteration 1053 : loss : 0.072231, loss_ce: 0.019319
2021-12-12 23:24:00,024 iteration 1054 : loss : 0.046079, loss_ce: 0.019623
 16%|████▋                         | 62/400 [28:41<2:32:16, 27.03s/it]2021-12-12 23:24:01,528 iteration 1055 : loss : 0.063091, loss_ce: 0.017633
2021-12-12 23:24:02,918 iteration 1056 : loss : 0.048566, loss_ce: 0.021587
2021-12-12 23:24:04,416 iteration 1057 : loss : 0.062238, loss_ce: 0.023005
2021-12-12 23:24:05,894 iteration 1058 : loss : 0.075496, loss_ce: 0.026833
2021-12-12 23:24:07,388 iteration 1059 : loss : 0.058472, loss_ce: 0.022431
2021-12-12 23:24:08,790 iteration 1060 : loss : 0.057581, loss_ce: 0.019111
2021-12-12 23:24:10,339 iteration 1061 : loss : 0.053555, loss_ce: 0.025921
2021-12-12 23:24:11,828 iteration 1062 : loss : 0.053046, loss_ce: 0.019513
2021-12-12 23:24:13,430 iteration 1063 : loss : 0.060371, loss_ce: 0.026600
2021-12-12 23:24:14,941 iteration 1064 : loss : 0.054434, loss_ce: 0.018109
2021-12-12 23:24:16,496 iteration 1065 : loss : 0.047196, loss_ce: 0.023622
2021-12-12 23:24:17,939 iteration 1066 : loss : 0.047505, loss_ce: 0.018119
2021-12-12 23:24:19,381 iteration 1067 : loss : 0.046854, loss_ce: 0.021362
2021-12-12 23:24:20,889 iteration 1068 : loss : 0.043582, loss_ce: 0.019523
2021-12-12 23:24:22,382 iteration 1069 : loss : 0.052337, loss_ce: 0.023893
2021-12-12 23:24:23,959 iteration 1070 : loss : 0.085760, loss_ce: 0.027356
2021-12-12 23:24:25,444 iteration 1071 : loss : 0.055192, loss_ce: 0.024958
 16%|████▋                         | 63/400 [29:07<2:29:06, 26.55s/it]2021-12-12 23:24:27,044 iteration 1072 : loss : 0.058732, loss_ce: 0.017276
2021-12-12 23:24:28,539 iteration 1073 : loss : 0.058210, loss_ce: 0.025453
2021-12-12 23:24:30,038 iteration 1074 : loss : 0.061629, loss_ce: 0.024765
2021-12-12 23:24:31,544 iteration 1075 : loss : 0.063355, loss_ce: 0.018899
2021-12-12 23:24:32,984 iteration 1076 : loss : 0.044461, loss_ce: 0.018642
2021-12-12 23:24:34,529 iteration 1077 : loss : 0.048128, loss_ce: 0.016199
2021-12-12 23:24:35,976 iteration 1078 : loss : 0.051854, loss_ce: 0.024835
2021-12-12 23:24:37,521 iteration 1079 : loss : 0.049991, loss_ce: 0.019664
2021-12-12 23:24:38,920 iteration 1080 : loss : 0.041195, loss_ce: 0.014590
2021-12-12 23:24:40,376 iteration 1081 : loss : 0.046915, loss_ce: 0.024178
2021-12-12 23:24:41,882 iteration 1082 : loss : 0.052742, loss_ce: 0.025334
2021-12-12 23:24:43,320 iteration 1083 : loss : 0.042508, loss_ce: 0.017258
2021-12-12 23:24:44,793 iteration 1084 : loss : 0.048798, loss_ce: 0.016683
2021-12-12 23:24:46,278 iteration 1085 : loss : 0.052306, loss_ce: 0.023122
2021-12-12 23:24:47,744 iteration 1086 : loss : 0.056399, loss_ce: 0.025430
2021-12-12 23:24:49,289 iteration 1087 : loss : 0.048929, loss_ce: 0.019158
2021-12-12 23:24:50,775 iteration 1088 : loss : 0.047455, loss_ce: 0.018311
 16%|████▊                         | 64/400 [29:32<2:26:36, 26.18s/it]2021-12-12 23:24:52,251 iteration 1089 : loss : 0.063122, loss_ce: 0.020541
2021-12-12 23:24:53,694 iteration 1090 : loss : 0.055888, loss_ce: 0.017642
2021-12-12 23:24:55,215 iteration 1091 : loss : 0.046375, loss_ce: 0.023162
2021-12-12 23:24:56,698 iteration 1092 : loss : 0.061372, loss_ce: 0.025257
2021-12-12 23:24:58,175 iteration 1093 : loss : 0.046845, loss_ce: 0.019135
2021-12-12 23:24:59,673 iteration 1094 : loss : 0.054618, loss_ce: 0.024425
2021-12-12 23:25:01,176 iteration 1095 : loss : 0.076123, loss_ce: 0.020579
2021-12-12 23:25:02,649 iteration 1096 : loss : 0.050756, loss_ce: 0.024488
2021-12-12 23:25:04,074 iteration 1097 : loss : 0.054929, loss_ce: 0.018685
2021-12-12 23:25:05,511 iteration 1098 : loss : 0.039671, loss_ce: 0.019862
2021-12-12 23:25:07,017 iteration 1099 : loss : 0.048900, loss_ce: 0.020759
2021-12-12 23:25:08,467 iteration 1100 : loss : 0.050617, loss_ce: 0.020324
2021-12-12 23:25:09,914 iteration 1101 : loss : 0.048792, loss_ce: 0.018866
2021-12-12 23:25:11,461 iteration 1102 : loss : 0.045462, loss_ce: 0.015953
2021-12-12 23:25:12,925 iteration 1103 : loss : 0.042979, loss_ce: 0.016979
2021-12-12 23:25:14,344 iteration 1104 : loss : 0.053173, loss_ce: 0.021374
2021-12-12 23:25:14,344 Training Data Eval:
2021-12-12 23:25:21,879   Average segmentation loss on training set: 0.0324
2021-12-12 23:25:21,880 Validation Data Eval:
2021-12-12 23:25:24,473   Average segmentation loss on validation set: 0.0879
2021-12-12 23:25:30,874 Found new lowest validation loss at iteration 1104! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/TU_3seeds/TU_SGD_best_val_loss_seed2.pth
2021-12-12 23:25:32,241 iteration 1105 : loss : 0.050592, loss_ce: 0.022633
 16%|████▉                         | 65/400 [30:14<2:51:47, 30.77s/it]2021-12-12 23:25:33,637 iteration 1106 : loss : 0.052563, loss_ce: 0.019439
2021-12-12 23:25:35,061 iteration 1107 : loss : 0.059659, loss_ce: 0.029687
2021-12-12 23:25:36,366 iteration 1108 : loss : 0.043226, loss_ce: 0.017345
2021-12-12 23:25:37,661 iteration 1109 : loss : 0.070516, loss_ce: 0.031862
2021-12-12 23:25:39,073 iteration 1110 : loss : 0.048156, loss_ce: 0.021245
2021-12-12 23:25:40,549 iteration 1111 : loss : 0.048902, loss_ce: 0.020160
2021-12-12 23:25:42,038 iteration 1112 : loss : 0.049936, loss_ce: 0.022488
2021-12-12 23:25:43,477 iteration 1113 : loss : 0.059011, loss_ce: 0.020860
2021-12-12 23:25:44,889 iteration 1114 : loss : 0.060432, loss_ce: 0.021935
2021-12-12 23:25:46,273 iteration 1115 : loss : 0.045832, loss_ce: 0.015708
2021-12-12 23:25:47,817 iteration 1116 : loss : 0.064054, loss_ce: 0.027967
2021-12-12 23:25:49,383 iteration 1117 : loss : 0.043630, loss_ce: 0.019894
2021-12-12 23:25:50,817 iteration 1118 : loss : 0.042466, loss_ce: 0.018324
2021-12-12 23:25:52,246 iteration 1119 : loss : 0.038940, loss_ce: 0.016110
2021-12-12 23:25:53,656 iteration 1120 : loss : 0.047338, loss_ce: 0.017150
2021-12-12 23:25:55,078 iteration 1121 : loss : 0.044350, loss_ce: 0.015050
2021-12-12 23:25:56,494 iteration 1122 : loss : 0.052449, loss_ce: 0.021770
 16%|████▉                         | 66/400 [30:38<2:40:24, 28.82s/it]2021-12-12 23:25:58,007 iteration 1123 : loss : 0.057073, loss_ce: 0.027595
2021-12-12 23:25:59,456 iteration 1124 : loss : 0.043777, loss_ce: 0.018074
2021-12-12 23:26:00,973 iteration 1125 : loss : 0.049311, loss_ce: 0.018924
2021-12-12 23:26:02,556 iteration 1126 : loss : 0.053013, loss_ce: 0.021526
2021-12-12 23:26:04,057 iteration 1127 : loss : 0.056666, loss_ce: 0.021166
2021-12-12 23:26:05,565 iteration 1128 : loss : 0.066347, loss_ce: 0.022643
2021-12-12 23:26:07,027 iteration 1129 : loss : 0.040600, loss_ce: 0.015452
2021-12-12 23:26:08,549 iteration 1130 : loss : 0.063925, loss_ce: 0.033989
2021-12-12 23:26:10,090 iteration 1131 : loss : 0.085786, loss_ce: 0.027469
2021-12-12 23:26:11,601 iteration 1132 : loss : 0.052659, loss_ce: 0.018822
2021-12-12 23:26:13,093 iteration 1133 : loss : 0.056691, loss_ce: 0.023829
2021-12-12 23:26:14,574 iteration 1134 : loss : 0.055966, loss_ce: 0.023962
2021-12-12 23:26:16,008 iteration 1135 : loss : 0.044715, loss_ce: 0.015837
2021-12-12 23:26:17,488 iteration 1136 : loss : 0.053623, loss_ce: 0.021056
2021-12-12 23:26:18,937 iteration 1137 : loss : 0.044622, loss_ce: 0.018697
2021-12-12 23:26:20,481 iteration 1138 : loss : 0.053719, loss_ce: 0.024262
2021-12-12 23:26:22,021 iteration 1139 : loss : 0.052074, loss_ce: 0.022167
 17%|█████                         | 67/400 [31:03<2:34:26, 27.83s/it]2021-12-12 23:26:23,520 iteration 1140 : loss : 0.044851, loss_ce: 0.018861
2021-12-12 23:26:24,995 iteration 1141 : loss : 0.035356, loss_ce: 0.016685
2021-12-12 23:26:26,424 iteration 1142 : loss : 0.039094, loss_ce: 0.016309
2021-12-12 23:26:27,912 iteration 1143 : loss : 0.087549, loss_ce: 0.026183
2021-12-12 23:26:29,432 iteration 1144 : loss : 0.042457, loss_ce: 0.017787
2021-12-12 23:26:30,897 iteration 1145 : loss : 0.036457, loss_ce: 0.013648
2021-12-12 23:26:32,399 iteration 1146 : loss : 0.058005, loss_ce: 0.024657
2021-12-12 23:26:33,821 iteration 1147 : loss : 0.034783, loss_ce: 0.013630
2021-12-12 23:26:35,283 iteration 1148 : loss : 0.039359, loss_ce: 0.016015
2021-12-12 23:26:36,796 iteration 1149 : loss : 0.043416, loss_ce: 0.019174
2021-12-12 23:26:38,272 iteration 1150 : loss : 0.048527, loss_ce: 0.021630
2021-12-12 23:26:39,760 iteration 1151 : loss : 0.043748, loss_ce: 0.015319
2021-12-12 23:26:41,261 iteration 1152 : loss : 0.061983, loss_ce: 0.015960
2021-12-12 23:26:42,745 iteration 1153 : loss : 0.040426, loss_ce: 0.015808
2021-12-12 23:26:44,156 iteration 1154 : loss : 0.038834, loss_ce: 0.018881
2021-12-12 23:26:45,708 iteration 1155 : loss : 0.050825, loss_ce: 0.017068
2021-12-12 23:26:47,215 iteration 1156 : loss : 0.059402, loss_ce: 0.020402
 17%|█████                         | 68/400 [31:29<2:29:35, 27.04s/it]2021-12-12 23:26:48,682 iteration 1157 : loss : 0.032876, loss_ce: 0.014105
2021-12-12 23:26:50,269 iteration 1158 : loss : 0.057753, loss_ce: 0.019521
2021-12-12 23:26:51,807 iteration 1159 : loss : 0.050964, loss_ce: 0.023159
2021-12-12 23:26:53,206 iteration 1160 : loss : 0.050767, loss_ce: 0.027054
2021-12-12 23:26:54,671 iteration 1161 : loss : 0.042882, loss_ce: 0.018786
2021-12-12 23:26:56,135 iteration 1162 : loss : 0.056671, loss_ce: 0.015382
2021-12-12 23:26:57,700 iteration 1163 : loss : 0.073032, loss_ce: 0.022831
2021-12-12 23:26:59,195 iteration 1164 : loss : 0.043079, loss_ce: 0.017411
2021-12-12 23:27:00,619 iteration 1165 : loss : 0.052833, loss_ce: 0.027864
2021-12-12 23:27:02,093 iteration 1166 : loss : 0.044795, loss_ce: 0.021720
2021-12-12 23:27:03,588 iteration 1167 : loss : 0.051926, loss_ce: 0.023247
2021-12-12 23:27:04,985 iteration 1168 : loss : 0.042889, loss_ce: 0.016278
2021-12-12 23:27:06,458 iteration 1169 : loss : 0.041747, loss_ce: 0.014088
2021-12-12 23:27:07,938 iteration 1170 : loss : 0.039734, loss_ce: 0.015127
2021-12-12 23:27:09,337 iteration 1171 : loss : 0.039945, loss_ce: 0.016302
2021-12-12 23:27:10,803 iteration 1172 : loss : 0.042062, loss_ce: 0.019013
2021-12-12 23:27:12,293 iteration 1173 : loss : 0.042428, loss_ce: 0.023889
 17%|█████▏                        | 69/400 [31:54<2:25:55, 26.45s/it]2021-12-12 23:27:13,834 iteration 1174 : loss : 0.045566, loss_ce: 0.015342
2021-12-12 23:27:15,287 iteration 1175 : loss : 0.043798, loss_ce: 0.018943
2021-12-12 23:27:16,809 iteration 1176 : loss : 0.053054, loss_ce: 0.027871
2021-12-12 23:27:18,380 iteration 1177 : loss : 0.056958, loss_ce: 0.026674
2021-12-12 23:27:19,876 iteration 1178 : loss : 0.052789, loss_ce: 0.023884
2021-12-12 23:27:21,272 iteration 1179 : loss : 0.041148, loss_ce: 0.019641
2021-12-12 23:27:22,794 iteration 1180 : loss : 0.038094, loss_ce: 0.016374
2021-12-12 23:27:24,209 iteration 1181 : loss : 0.036135, loss_ce: 0.015523
2021-12-12 23:27:25,770 iteration 1182 : loss : 0.048593, loss_ce: 0.018901
2021-12-12 23:27:27,238 iteration 1183 : loss : 0.050374, loss_ce: 0.019716
2021-12-12 23:27:28,644 iteration 1184 : loss : 0.036163, loss_ce: 0.016594
2021-12-12 23:27:30,137 iteration 1185 : loss : 0.060793, loss_ce: 0.021879
2021-12-12 23:27:31,565 iteration 1186 : loss : 0.051930, loss_ce: 0.019630
2021-12-12 23:27:33,053 iteration 1187 : loss : 0.041862, loss_ce: 0.018783
2021-12-12 23:27:34,468 iteration 1188 : loss : 0.041841, loss_ce: 0.015385
2021-12-12 23:27:35,934 iteration 1189 : loss : 0.050929, loss_ce: 0.020168
2021-12-12 23:27:35,934 Training Data Eval:
2021-12-12 23:27:43,458   Average segmentation loss on training set: 0.0305
2021-12-12 23:27:43,459 Validation Data Eval:
2021-12-12 23:27:46,058   Average segmentation loss on validation set: 0.0927
2021-12-12 23:27:47,541 iteration 1190 : loss : 0.050554, loss_ce: 0.020080
 18%|█████▎                        | 70/400 [32:29<2:39:58, 29.09s/it]2021-12-12 23:27:49,021 iteration 1191 : loss : 0.038207, loss_ce: 0.016766
2021-12-12 23:27:50,461 iteration 1192 : loss : 0.041893, loss_ce: 0.019303
2021-12-12 23:27:51,931 iteration 1193 : loss : 0.058473, loss_ce: 0.018721
2021-12-12 23:27:53,366 iteration 1194 : loss : 0.042875, loss_ce: 0.017928
2021-12-12 23:27:54,875 iteration 1195 : loss : 0.055733, loss_ce: 0.018894
2021-12-12 23:27:56,275 iteration 1196 : loss : 0.047912, loss_ce: 0.016901
2021-12-12 23:27:57,770 iteration 1197 : loss : 0.044929, loss_ce: 0.022925
2021-12-12 23:27:59,243 iteration 1198 : loss : 0.046130, loss_ce: 0.025465
2021-12-12 23:28:00,726 iteration 1199 : loss : 0.047158, loss_ce: 0.018848
2021-12-12 23:28:02,233 iteration 1200 : loss : 0.054222, loss_ce: 0.018269
2021-12-12 23:28:03,695 iteration 1201 : loss : 0.033639, loss_ce: 0.015005
2021-12-12 23:28:05,206 iteration 1202 : loss : 0.038465, loss_ce: 0.018637
2021-12-12 23:28:06,671 iteration 1203 : loss : 0.045256, loss_ce: 0.016530
2021-12-12 23:28:08,131 iteration 1204 : loss : 0.059483, loss_ce: 0.025934
2021-12-12 23:28:09,635 iteration 1205 : loss : 0.060202, loss_ce: 0.034110
2021-12-12 23:28:11,162 iteration 1206 : loss : 0.068061, loss_ce: 0.019081
2021-12-12 23:28:12,612 iteration 1207 : loss : 0.057791, loss_ce: 0.017381
 18%|█████▎                        | 71/400 [32:54<2:32:54, 27.88s/it]2021-12-12 23:28:14,064 iteration 1208 : loss : 0.041783, loss_ce: 0.020730
2021-12-12 23:28:15,537 iteration 1209 : loss : 0.040495, loss_ce: 0.014956
2021-12-12 23:28:16,935 iteration 1210 : loss : 0.046106, loss_ce: 0.014852
2021-12-12 23:28:18,436 iteration 1211 : loss : 0.064182, loss_ce: 0.020523
2021-12-12 23:28:19,863 iteration 1212 : loss : 0.038115, loss_ce: 0.016098
2021-12-12 23:28:21,337 iteration 1213 : loss : 0.068642, loss_ce: 0.018672
2021-12-12 23:28:22,832 iteration 1214 : loss : 0.046658, loss_ce: 0.019351
2021-12-12 23:28:24,297 iteration 1215 : loss : 0.041148, loss_ce: 0.018071
2021-12-12 23:28:25,742 iteration 1216 : loss : 0.040782, loss_ce: 0.016488
2021-12-12 23:28:27,253 iteration 1217 : loss : 0.056312, loss_ce: 0.026561
2021-12-12 23:28:28,639 iteration 1218 : loss : 0.041421, loss_ce: 0.019750
2021-12-12 23:28:30,135 iteration 1219 : loss : 0.048452, loss_ce: 0.019188
2021-12-12 23:28:31,585 iteration 1220 : loss : 0.042649, loss_ce: 0.017704
2021-12-12 23:28:33,169 iteration 1221 : loss : 0.059910, loss_ce: 0.024870
2021-12-12 23:28:34,693 iteration 1222 : loss : 0.046246, loss_ce: 0.016111
2021-12-12 23:28:36,142 iteration 1223 : loss : 0.038188, loss_ce: 0.016528
2021-12-12 23:28:37,641 iteration 1224 : loss : 0.047806, loss_ce: 0.021833
 18%|█████▍                        | 72/400 [33:19<2:27:44, 27.03s/it]2021-12-12 23:28:39,177 iteration 1225 : loss : 0.043424, loss_ce: 0.018344
2021-12-12 23:28:40,656 iteration 1226 : loss : 0.058019, loss_ce: 0.023268
2021-12-12 23:28:42,086 iteration 1227 : loss : 0.048697, loss_ce: 0.017058
2021-12-12 23:28:43,657 iteration 1228 : loss : 0.078572, loss_ce: 0.025713
2021-12-12 23:28:45,192 iteration 1229 : loss : 0.044650, loss_ce: 0.018912
2021-12-12 23:28:46,707 iteration 1230 : loss : 0.038789, loss_ce: 0.017194
2021-12-12 23:28:48,168 iteration 1231 : loss : 0.058937, loss_ce: 0.021788
2021-12-12 23:28:49,696 iteration 1232 : loss : 0.044097, loss_ce: 0.021083
2021-12-12 23:28:51,284 iteration 1233 : loss : 0.057551, loss_ce: 0.026288
2021-12-12 23:28:52,787 iteration 1234 : loss : 0.057863, loss_ce: 0.022878
2021-12-12 23:28:54,241 iteration 1235 : loss : 0.045440, loss_ce: 0.023942
2021-12-12 23:28:55,678 iteration 1236 : loss : 0.030092, loss_ce: 0.013268
2021-12-12 23:28:57,071 iteration 1237 : loss : 0.038850, loss_ce: 0.014369
2021-12-12 23:28:58,533 iteration 1238 : loss : 0.047172, loss_ce: 0.020278
2021-12-12 23:29:00,040 iteration 1239 : loss : 0.058612, loss_ce: 0.018276
2021-12-12 23:29:01,435 iteration 1240 : loss : 0.034918, loss_ce: 0.014361
2021-12-12 23:29:03,003 iteration 1241 : loss : 0.042570, loss_ce: 0.018402
 18%|█████▍                        | 73/400 [33:44<2:24:35, 26.53s/it]2021-12-12 23:29:04,435 iteration 1242 : loss : 0.046483, loss_ce: 0.019330
2021-12-12 23:29:05,837 iteration 1243 : loss : 0.030451, loss_ce: 0.015084
2021-12-12 23:29:07,246 iteration 1244 : loss : 0.052370, loss_ce: 0.019339
2021-12-12 23:29:08,691 iteration 1245 : loss : 0.040864, loss_ce: 0.017102
2021-12-12 23:29:10,161 iteration 1246 : loss : 0.052783, loss_ce: 0.022432
2021-12-12 23:29:11,657 iteration 1247 : loss : 0.039804, loss_ce: 0.015307
2021-12-12 23:29:13,087 iteration 1248 : loss : 0.040563, loss_ce: 0.017463
2021-12-12 23:29:14,566 iteration 1249 : loss : 0.042452, loss_ce: 0.016215
2021-12-12 23:29:15,998 iteration 1250 : loss : 0.052771, loss_ce: 0.020466
2021-12-12 23:29:17,487 iteration 1251 : loss : 0.037641, loss_ce: 0.016578
2021-12-12 23:29:18,978 iteration 1252 : loss : 0.065517, loss_ce: 0.020191
2021-12-12 23:29:20,461 iteration 1253 : loss : 0.038316, loss_ce: 0.016280
2021-12-12 23:29:21,914 iteration 1254 : loss : 0.054875, loss_ce: 0.025725
2021-12-12 23:29:23,429 iteration 1255 : loss : 0.041788, loss_ce: 0.017591
2021-12-12 23:29:24,970 iteration 1256 : loss : 0.051513, loss_ce: 0.019591
2021-12-12 23:29:26,444 iteration 1257 : loss : 0.034910, loss_ce: 0.015569
2021-12-12 23:29:27,996 iteration 1258 : loss : 0.046015, loss_ce: 0.021408
 18%|█████▌                        | 74/400 [34:09<2:21:37, 26.07s/it]2021-12-12 23:29:29,503 iteration 1259 : loss : 0.044606, loss_ce: 0.017706
2021-12-12 23:29:31,025 iteration 1260 : loss : 0.059670, loss_ce: 0.018706
2021-12-12 23:29:32,514 iteration 1261 : loss : 0.050242, loss_ce: 0.018882
2021-12-12 23:29:33,942 iteration 1262 : loss : 0.034437, loss_ce: 0.016854
2021-12-12 23:29:35,467 iteration 1263 : loss : 0.038643, loss_ce: 0.014219
2021-12-12 23:29:36,875 iteration 1264 : loss : 0.040915, loss_ce: 0.019853
2021-12-12 23:29:38,291 iteration 1265 : loss : 0.044456, loss_ce: 0.017196
2021-12-12 23:29:39,686 iteration 1266 : loss : 0.042571, loss_ce: 0.019768
2021-12-12 23:29:41,248 iteration 1267 : loss : 0.045246, loss_ce: 0.018372
2021-12-12 23:29:42,704 iteration 1268 : loss : 0.097155, loss_ce: 0.020216
2021-12-12 23:29:44,205 iteration 1269 : loss : 0.051785, loss_ce: 0.017873
2021-12-12 23:29:45,625 iteration 1270 : loss : 0.042756, loss_ce: 0.017025
2021-12-12 23:29:47,091 iteration 1271 : loss : 0.037427, loss_ce: 0.014711
2021-12-12 23:29:48,539 iteration 1272 : loss : 0.045453, loss_ce: 0.020848
2021-12-12 23:29:50,049 iteration 1273 : loss : 0.045187, loss_ce: 0.022269
2021-12-12 23:29:51,531 iteration 1274 : loss : 0.040399, loss_ce: 0.015447
2021-12-12 23:29:51,532 Training Data Eval:
2021-12-12 23:29:59,076   Average segmentation loss on training set: 0.0330
2021-12-12 23:29:59,122 Validation Data Eval:
2021-12-12 23:30:01,730   Average segmentation loss on validation set: 0.0863
2021-12-12 23:30:08,128 Found new lowest validation loss at iteration 1274! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/TU_3seeds/TU_SGD_best_val_loss_seed2.pth
2021-12-12 23:30:09,501 iteration 1275 : loss : 0.056956, loss_ce: 0.020065
 19%|█████▋                        | 75/400 [34:51<2:46:17, 30.70s/it]2021-12-12 23:30:10,985 iteration 1276 : loss : 0.056523, loss_ce: 0.014375
2021-12-12 23:30:12,293 iteration 1277 : loss : 0.042557, loss_ce: 0.016018
2021-12-12 23:30:13,676 iteration 1278 : loss : 0.049978, loss_ce: 0.021411
2021-12-12 23:30:14,934 iteration 1279 : loss : 0.038215, loss_ce: 0.020251
2021-12-12 23:30:16,259 iteration 1280 : loss : 0.036336, loss_ce: 0.017541
2021-12-12 23:30:17,769 iteration 1281 : loss : 0.053858, loss_ce: 0.024766
2021-12-12 23:30:19,186 iteration 1282 : loss : 0.059912, loss_ce: 0.029410
2021-12-12 23:30:20,620 iteration 1283 : loss : 0.040655, loss_ce: 0.018983
2021-12-12 23:30:22,082 iteration 1284 : loss : 0.041240, loss_ce: 0.018495
2021-12-12 23:30:23,692 iteration 1285 : loss : 0.079200, loss_ce: 0.027674
2021-12-12 23:30:25,200 iteration 1286 : loss : 0.047438, loss_ce: 0.016982
2021-12-12 23:30:26,647 iteration 1287 : loss : 0.052501, loss_ce: 0.020384
2021-12-12 23:30:28,139 iteration 1288 : loss : 0.047442, loss_ce: 0.019376
2021-12-12 23:30:29,686 iteration 1289 : loss : 0.042593, loss_ce: 0.017080
2021-12-12 23:30:31,119 iteration 1290 : loss : 0.047926, loss_ce: 0.015461
2021-12-12 23:30:32,593 iteration 1291 : loss : 0.055355, loss_ce: 0.019652
2021-12-12 23:30:34,009 iteration 1292 : loss : 0.037828, loss_ce: 0.014101
 19%|█████▋                        | 76/400 [35:15<2:35:44, 28.84s/it]2021-12-12 23:30:35,533 iteration 1293 : loss : 0.044346, loss_ce: 0.020869
2021-12-12 23:30:36,958 iteration 1294 : loss : 0.049699, loss_ce: 0.019360
2021-12-12 23:30:38,406 iteration 1295 : loss : 0.036917, loss_ce: 0.015769
2021-12-12 23:30:39,862 iteration 1296 : loss : 0.038391, loss_ce: 0.015276
2021-12-12 23:30:41,312 iteration 1297 : loss : 0.044018, loss_ce: 0.018224
2021-12-12 23:30:42,781 iteration 1298 : loss : 0.038454, loss_ce: 0.017355
2021-12-12 23:30:44,203 iteration 1299 : loss : 0.051029, loss_ce: 0.019221
2021-12-12 23:30:45,724 iteration 1300 : loss : 0.069575, loss_ce: 0.019548
2021-12-12 23:30:47,204 iteration 1301 : loss : 0.039806, loss_ce: 0.019084
2021-12-12 23:30:48,725 iteration 1302 : loss : 0.036483, loss_ce: 0.012746
2021-12-12 23:30:50,156 iteration 1303 : loss : 0.049130, loss_ce: 0.021158
2021-12-12 23:30:51,672 iteration 1304 : loss : 0.079609, loss_ce: 0.024117
2021-12-12 23:30:53,145 iteration 1305 : loss : 0.048018, loss_ce: 0.022568
2021-12-12 23:30:54,662 iteration 1306 : loss : 0.054310, loss_ce: 0.020780
2021-12-12 23:30:56,193 iteration 1307 : loss : 0.051083, loss_ce: 0.018951
2021-12-12 23:30:57,682 iteration 1308 : loss : 0.048390, loss_ce: 0.026911
2021-12-12 23:30:59,152 iteration 1309 : loss : 0.050179, loss_ce: 0.017907
 19%|█████▊                        | 77/400 [35:41<2:29:16, 27.73s/it]2021-12-12 23:31:00,670 iteration 1310 : loss : 0.043244, loss_ce: 0.019493
2021-12-12 23:31:02,210 iteration 1311 : loss : 0.039411, loss_ce: 0.014612
2021-12-12 23:31:03,690 iteration 1312 : loss : 0.051322, loss_ce: 0.026132
2021-12-12 23:31:05,095 iteration 1313 : loss : 0.034538, loss_ce: 0.015147
2021-12-12 23:31:06,569 iteration 1314 : loss : 0.046259, loss_ce: 0.021996
2021-12-12 23:31:08,056 iteration 1315 : loss : 0.056607, loss_ce: 0.022094
2021-12-12 23:31:09,501 iteration 1316 : loss : 0.050658, loss_ce: 0.021679
2021-12-12 23:31:11,001 iteration 1317 : loss : 0.044641, loss_ce: 0.021653
2021-12-12 23:31:12,508 iteration 1318 : loss : 0.051962, loss_ce: 0.022287
2021-12-12 23:31:13,952 iteration 1319 : loss : 0.063887, loss_ce: 0.021165
2021-12-12 23:31:15,411 iteration 1320 : loss : 0.038701, loss_ce: 0.015683
2021-12-12 23:31:16,883 iteration 1321 : loss : 0.045756, loss_ce: 0.018283
2021-12-12 23:31:18,451 iteration 1322 : loss : 0.047294, loss_ce: 0.019020
2021-12-12 23:31:19,953 iteration 1323 : loss : 0.037994, loss_ce: 0.016732
2021-12-12 23:31:21,453 iteration 1324 : loss : 0.050038, loss_ce: 0.018465
2021-12-12 23:31:22,969 iteration 1325 : loss : 0.055327, loss_ce: 0.021638
2021-12-12 23:31:24,381 iteration 1326 : loss : 0.047134, loss_ce: 0.016252
 20%|█████▊                        | 78/400 [36:06<2:24:48, 26.98s/it]2021-12-12 23:31:25,917 iteration 1327 : loss : 0.042859, loss_ce: 0.024280
2021-12-12 23:31:27,483 iteration 1328 : loss : 0.059782, loss_ce: 0.020363
2021-12-12 23:31:28,886 iteration 1329 : loss : 0.044318, loss_ce: 0.022385
2021-12-12 23:31:30,356 iteration 1330 : loss : 0.060912, loss_ce: 0.026404
2021-12-12 23:31:31,838 iteration 1331 : loss : 0.044751, loss_ce: 0.016393
2021-12-12 23:31:33,290 iteration 1332 : loss : 0.035822, loss_ce: 0.016824
2021-12-12 23:31:34,785 iteration 1333 : loss : 0.072190, loss_ce: 0.018738
2021-12-12 23:31:36,248 iteration 1334 : loss : 0.036794, loss_ce: 0.015573
2021-12-12 23:31:37,840 iteration 1335 : loss : 0.042427, loss_ce: 0.015066
2021-12-12 23:31:39,350 iteration 1336 : loss : 0.062393, loss_ce: 0.028246
2021-12-12 23:31:40,882 iteration 1337 : loss : 0.046912, loss_ce: 0.018836
2021-12-12 23:31:42,422 iteration 1338 : loss : 0.060633, loss_ce: 0.027641
2021-12-12 23:31:43,951 iteration 1339 : loss : 0.043167, loss_ce: 0.018784
2021-12-12 23:31:45,382 iteration 1340 : loss : 0.037109, loss_ce: 0.014010
2021-12-12 23:31:46,845 iteration 1341 : loss : 0.041798, loss_ce: 0.017537
2021-12-12 23:31:48,315 iteration 1342 : loss : 0.050724, loss_ce: 0.017470
2021-12-12 23:31:49,773 iteration 1343 : loss : 0.041095, loss_ce: 0.016494
 20%|█████▉                        | 79/400 [36:31<2:21:47, 26.50s/it]2021-12-12 23:31:51,254 iteration 1344 : loss : 0.040749, loss_ce: 0.015187
2021-12-12 23:31:52,691 iteration 1345 : loss : 0.040291, loss_ce: 0.019379
2021-12-12 23:31:54,113 iteration 1346 : loss : 0.038015, loss_ce: 0.015739
2021-12-12 23:31:55,651 iteration 1347 : loss : 0.062714, loss_ce: 0.015161
2021-12-12 23:31:57,192 iteration 1348 : loss : 0.042304, loss_ce: 0.018746
2021-12-12 23:31:58,684 iteration 1349 : loss : 0.056752, loss_ce: 0.025840
2021-12-12 23:32:00,194 iteration 1350 : loss : 0.059574, loss_ce: 0.027612
2021-12-12 23:32:01,617 iteration 1351 : loss : 0.042100, loss_ce: 0.015006
2021-12-12 23:32:03,161 iteration 1352 : loss : 0.051485, loss_ce: 0.019176
2021-12-12 23:32:04,563 iteration 1353 : loss : 0.045658, loss_ce: 0.020493
2021-12-12 23:32:06,067 iteration 1354 : loss : 0.038759, loss_ce: 0.016439
2021-12-12 23:32:07,482 iteration 1355 : loss : 0.059475, loss_ce: 0.017585
2021-12-12 23:32:08,988 iteration 1356 : loss : 0.049890, loss_ce: 0.018702
2021-12-12 23:32:10,406 iteration 1357 : loss : 0.048132, loss_ce: 0.029724
2021-12-12 23:32:11,875 iteration 1358 : loss : 0.039053, loss_ce: 0.014701
2021-12-12 23:32:13,284 iteration 1359 : loss : 0.040430, loss_ce: 0.020847
2021-12-12 23:32:13,284 Training Data Eval:
2021-12-12 23:32:20,809   Average segmentation loss on training set: 0.0349
2021-12-12 23:32:20,809 Validation Data Eval:
2021-12-12 23:32:23,406   Average segmentation loss on validation set: 0.0868
2021-12-12 23:32:24,853 iteration 1360 : loss : 0.052686, loss_ce: 0.017620
 20%|██████                        | 80/400 [37:06<2:35:04, 29.08s/it]2021-12-12 23:32:26,401 iteration 1361 : loss : 0.053486, loss_ce: 0.017027
2021-12-12 23:32:27,889 iteration 1362 : loss : 0.049463, loss_ce: 0.022000
2021-12-12 23:32:29,385 iteration 1363 : loss : 0.034024, loss_ce: 0.013570
2021-12-12 23:32:30,914 iteration 1364 : loss : 0.050392, loss_ce: 0.018230
2021-12-12 23:32:32,481 iteration 1365 : loss : 0.053408, loss_ce: 0.020712
2021-12-12 23:32:33,966 iteration 1366 : loss : 0.053603, loss_ce: 0.025154
2021-12-12 23:32:35,399 iteration 1367 : loss : 0.042811, loss_ce: 0.019133
2021-12-12 23:32:36,883 iteration 1368 : loss : 0.049090, loss_ce: 0.021993
2021-12-12 23:32:38,334 iteration 1369 : loss : 0.059020, loss_ce: 0.018188
2021-12-12 23:32:39,807 iteration 1370 : loss : 0.049238, loss_ce: 0.017424
2021-12-12 23:32:41,214 iteration 1371 : loss : 0.036617, loss_ce: 0.016076
2021-12-12 23:32:42,705 iteration 1372 : loss : 0.055446, loss_ce: 0.017299
2021-12-12 23:32:44,287 iteration 1373 : loss : 0.051803, loss_ce: 0.028367
2021-12-12 23:32:45,748 iteration 1374 : loss : 0.055458, loss_ce: 0.017759
2021-12-12 23:32:47,271 iteration 1375 : loss : 0.040859, loss_ce: 0.014903
2021-12-12 23:32:48,669 iteration 1376 : loss : 0.033795, loss_ce: 0.014101
2021-12-12 23:32:50,190 iteration 1377 : loss : 0.056305, loss_ce: 0.020509
 20%|██████                        | 81/400 [37:32<2:28:37, 27.96s/it]2021-12-12 23:32:51,768 iteration 1378 : loss : 0.042713, loss_ce: 0.019814
2021-12-12 23:32:53,302 iteration 1379 : loss : 0.050540, loss_ce: 0.016318
2021-12-12 23:32:54,780 iteration 1380 : loss : 0.045056, loss_ce: 0.019295
2021-12-12 23:32:56,279 iteration 1381 : loss : 0.038353, loss_ce: 0.016371
2021-12-12 23:32:57,739 iteration 1382 : loss : 0.042233, loss_ce: 0.018385
2021-12-12 23:32:59,209 iteration 1383 : loss : 0.049909, loss_ce: 0.016373
2021-12-12 23:33:00,776 iteration 1384 : loss : 0.061969, loss_ce: 0.027172
2021-12-12 23:33:02,197 iteration 1385 : loss : 0.029664, loss_ce: 0.013064
2021-12-12 23:33:03,758 iteration 1386 : loss : 0.058414, loss_ce: 0.028029
2021-12-12 23:33:05,198 iteration 1387 : loss : 0.068716, loss_ce: 0.022247
2021-12-12 23:33:06,717 iteration 1388 : loss : 0.042002, loss_ce: 0.012145
2021-12-12 23:33:08,241 iteration 1389 : loss : 0.046465, loss_ce: 0.022407
2021-12-12 23:33:09,651 iteration 1390 : loss : 0.037433, loss_ce: 0.017314
2021-12-12 23:33:11,141 iteration 1391 : loss : 0.068838, loss_ce: 0.017932
2021-12-12 23:33:12,605 iteration 1392 : loss : 0.044649, loss_ce: 0.023152
2021-12-12 23:33:14,087 iteration 1393 : loss : 0.055858, loss_ce: 0.018185
2021-12-12 23:33:15,559 iteration 1394 : loss : 0.050305, loss_ce: 0.015160
 20%|██████▏                       | 82/400 [37:57<2:24:02, 27.18s/it]2021-12-12 23:33:17,124 iteration 1395 : loss : 0.057285, loss_ce: 0.028601
2021-12-12 23:33:18,530 iteration 1396 : loss : 0.041790, loss_ce: 0.018668
2021-12-12 23:33:20,051 iteration 1397 : loss : 0.047217, loss_ce: 0.019532
2021-12-12 23:33:21,443 iteration 1398 : loss : 0.033099, loss_ce: 0.013561
2021-12-12 23:33:22,939 iteration 1399 : loss : 0.055420, loss_ce: 0.024083
2021-12-12 23:33:24,490 iteration 1400 : loss : 0.053120, loss_ce: 0.017409
2021-12-12 23:33:25,934 iteration 1401 : loss : 0.038788, loss_ce: 0.014319
2021-12-12 23:33:27,472 iteration 1402 : loss : 0.056061, loss_ce: 0.021079
2021-12-12 23:33:28,963 iteration 1403 : loss : 0.046818, loss_ce: 0.015371
2021-12-12 23:33:30,526 iteration 1404 : loss : 0.050851, loss_ce: 0.020607
2021-12-12 23:33:31,852 iteration 1405 : loss : 0.035301, loss_ce: 0.014269
2021-12-12 23:33:33,351 iteration 1406 : loss : 0.044672, loss_ce: 0.015879
2021-12-12 23:33:34,797 iteration 1407 : loss : 0.046260, loss_ce: 0.020967
2021-12-12 23:33:36,215 iteration 1408 : loss : 0.047903, loss_ce: 0.023903
2021-12-12 23:33:37,762 iteration 1409 : loss : 0.069230, loss_ce: 0.019781
2021-12-12 23:33:39,193 iteration 1410 : loss : 0.059987, loss_ce: 0.025235
2021-12-12 23:33:40,588 iteration 1411 : loss : 0.036452, loss_ce: 0.014748
 21%|██████▏                       | 83/400 [38:22<2:20:10, 26.53s/it]2021-12-12 23:33:42,122 iteration 1412 : loss : 0.040560, loss_ce: 0.018638
2021-12-12 23:33:43,522 iteration 1413 : loss : 0.029890, loss_ce: 0.012113
2021-12-12 23:33:45,017 iteration 1414 : loss : 0.043367, loss_ce: 0.018227
2021-12-12 23:33:46,439 iteration 1415 : loss : 0.050102, loss_ce: 0.020502
2021-12-12 23:33:47,899 iteration 1416 : loss : 0.036087, loss_ce: 0.015039
2021-12-12 23:33:49,381 iteration 1417 : loss : 0.043391, loss_ce: 0.018804
2021-12-12 23:33:50,859 iteration 1418 : loss : 0.041541, loss_ce: 0.015973
2021-12-12 23:33:52,253 iteration 1419 : loss : 0.036741, loss_ce: 0.015291
2021-12-12 23:33:53,700 iteration 1420 : loss : 0.040988, loss_ce: 0.013176
2021-12-12 23:33:55,153 iteration 1421 : loss : 0.052803, loss_ce: 0.030434
2021-12-12 23:33:56,634 iteration 1422 : loss : 0.050500, loss_ce: 0.019375
2021-12-12 23:33:58,061 iteration 1423 : loss : 0.052096, loss_ce: 0.018546
2021-12-12 23:33:59,444 iteration 1424 : loss : 0.032014, loss_ce: 0.013649
2021-12-12 23:34:00,928 iteration 1425 : loss : 0.047892, loss_ce: 0.015141
2021-12-12 23:34:02,436 iteration 1426 : loss : 0.056391, loss_ce: 0.031497
2021-12-12 23:34:03,902 iteration 1427 : loss : 0.075585, loss_ce: 0.015306
2021-12-12 23:34:05,472 iteration 1428 : loss : 0.054960, loss_ce: 0.019654
 21%|██████▎                       | 84/400 [38:47<2:17:08, 26.04s/it]2021-12-12 23:34:07,015 iteration 1429 : loss : 0.049438, loss_ce: 0.022029
2021-12-12 23:34:08,491 iteration 1430 : loss : 0.052168, loss_ce: 0.020512
2021-12-12 23:34:09,906 iteration 1431 : loss : 0.044368, loss_ce: 0.016623
2021-12-12 23:34:11,380 iteration 1432 : loss : 0.046559, loss_ce: 0.019732
2021-12-12 23:34:12,778 iteration 1433 : loss : 0.045498, loss_ce: 0.020359
2021-12-12 23:34:14,329 iteration 1434 : loss : 0.047065, loss_ce: 0.020629
2021-12-12 23:34:15,836 iteration 1435 : loss : 0.045378, loss_ce: 0.016626
2021-12-12 23:34:17,371 iteration 1436 : loss : 0.059878, loss_ce: 0.027927
2021-12-12 23:34:18,841 iteration 1437 : loss : 0.040308, loss_ce: 0.017977
2021-12-12 23:34:20,300 iteration 1438 : loss : 0.039886, loss_ce: 0.017084
2021-12-12 23:34:21,785 iteration 1439 : loss : 0.058607, loss_ce: 0.019495
2021-12-12 23:34:23,200 iteration 1440 : loss : 0.049005, loss_ce: 0.017245
2021-12-12 23:34:24,696 iteration 1441 : loss : 0.045573, loss_ce: 0.017819
2021-12-12 23:34:26,160 iteration 1442 : loss : 0.046364, loss_ce: 0.015466
2021-12-12 23:34:27,685 iteration 1443 : loss : 0.041447, loss_ce: 0.015923
2021-12-12 23:34:29,154 iteration 1444 : loss : 0.053863, loss_ce: 0.013634
2021-12-12 23:34:29,154 Training Data Eval:
2021-12-12 23:34:36,683   Average segmentation loss on training set: 0.0284
2021-12-12 23:34:36,683 Validation Data Eval:
2021-12-12 23:34:39,278   Average segmentation loss on validation set: 0.0950
2021-12-12 23:34:40,798 iteration 1445 : loss : 0.045400, loss_ce: 0.020605
 21%|██████▍                       | 85/400 [39:22<2:31:20, 28.83s/it]2021-12-12 23:34:42,237 iteration 1446 : loss : 0.043926, loss_ce: 0.016602
2021-12-12 23:34:43,625 iteration 1447 : loss : 0.034001, loss_ce: 0.016275
2021-12-12 23:34:45,145 iteration 1448 : loss : 0.039942, loss_ce: 0.016414
2021-12-12 23:34:46,675 iteration 1449 : loss : 0.054115, loss_ce: 0.018950
2021-12-12 23:34:48,126 iteration 1450 : loss : 0.045273, loss_ce: 0.016679
2021-12-12 23:34:49,623 iteration 1451 : loss : 0.043087, loss_ce: 0.014593
2021-12-12 23:34:51,083 iteration 1452 : loss : 0.049972, loss_ce: 0.029763
2021-12-12 23:34:52,582 iteration 1453 : loss : 0.045969, loss_ce: 0.020258
2021-12-12 23:34:54,054 iteration 1454 : loss : 0.052152, loss_ce: 0.018434
2021-12-12 23:34:55,543 iteration 1455 : loss : 0.038627, loss_ce: 0.013694
2021-12-12 23:34:56,972 iteration 1456 : loss : 0.036133, loss_ce: 0.012092
2021-12-12 23:34:58,496 iteration 1457 : loss : 0.051359, loss_ce: 0.021942
2021-12-12 23:34:59,987 iteration 1458 : loss : 0.039244, loss_ce: 0.016106
2021-12-12 23:35:01,430 iteration 1459 : loss : 0.043056, loss_ce: 0.016646
2021-12-12 23:35:02,891 iteration 1460 : loss : 0.051063, loss_ce: 0.019466
2021-12-12 23:35:04,303 iteration 1461 : loss : 0.045729, loss_ce: 0.018074
2021-12-12 23:35:05,831 iteration 1462 : loss : 0.043355, loss_ce: 0.019576
 22%|██████▍                       | 86/400 [39:47<2:24:54, 27.69s/it]2021-12-12 23:35:07,453 iteration 1463 : loss : 0.081145, loss_ce: 0.023138
2021-12-12 23:35:08,886 iteration 1464 : loss : 0.048371, loss_ce: 0.023730
2021-12-12 23:35:10,476 iteration 1465 : loss : 0.056835, loss_ce: 0.021022
2021-12-12 23:35:11,951 iteration 1466 : loss : 0.046651, loss_ce: 0.016402
2021-12-12 23:35:13,389 iteration 1467 : loss : 0.044746, loss_ce: 0.017516
2021-12-12 23:35:14,880 iteration 1468 : loss : 0.049840, loss_ce: 0.022250
2021-12-12 23:35:16,346 iteration 1469 : loss : 0.074024, loss_ce: 0.026892
2021-12-12 23:35:17,763 iteration 1470 : loss : 0.059358, loss_ce: 0.014986
2021-12-12 23:35:19,232 iteration 1471 : loss : 0.038405, loss_ce: 0.017122
2021-12-12 23:35:20,733 iteration 1472 : loss : 0.056118, loss_ce: 0.020460
2021-12-12 23:35:22,160 iteration 1473 : loss : 0.038932, loss_ce: 0.019171
2021-12-12 23:35:23,671 iteration 1474 : loss : 0.057023, loss_ce: 0.018189
2021-12-12 23:35:25,112 iteration 1475 : loss : 0.036368, loss_ce: 0.016415
2021-12-12 23:35:26,553 iteration 1476 : loss : 0.036251, loss_ce: 0.016537
2021-12-12 23:35:28,098 iteration 1477 : loss : 0.046416, loss_ce: 0.021623
2021-12-12 23:35:29,529 iteration 1478 : loss : 0.048419, loss_ce: 0.014468
2021-12-12 23:35:30,998 iteration 1479 : loss : 0.049951, loss_ce: 0.016920
 22%|██████▌                       | 87/400 [40:12<2:20:29, 26.93s/it]2021-12-12 23:35:32,386 iteration 1480 : loss : 0.033466, loss_ce: 0.013266
2021-12-12 23:35:33,940 iteration 1481 : loss : 0.043523, loss_ce: 0.018327
2021-12-12 23:35:35,406 iteration 1482 : loss : 0.037710, loss_ce: 0.015454
2021-12-12 23:35:36,956 iteration 1483 : loss : 0.059511, loss_ce: 0.023043
2021-12-12 23:35:38,458 iteration 1484 : loss : 0.040712, loss_ce: 0.013502
2021-12-12 23:35:39,975 iteration 1485 : loss : 0.041804, loss_ce: 0.020439
2021-12-12 23:35:41,439 iteration 1486 : loss : 0.034069, loss_ce: 0.013169
2021-12-12 23:35:42,921 iteration 1487 : loss : 0.026704, loss_ce: 0.010853
2021-12-12 23:35:44,330 iteration 1488 : loss : 0.040283, loss_ce: 0.018028
2021-12-12 23:35:45,772 iteration 1489 : loss : 0.048758, loss_ce: 0.021740
2021-12-12 23:35:47,268 iteration 1490 : loss : 0.052658, loss_ce: 0.019563
2021-12-12 23:35:48,647 iteration 1491 : loss : 0.048132, loss_ce: 0.015915
2021-12-12 23:35:50,053 iteration 1492 : loss : 0.057747, loss_ce: 0.027643
2021-12-12 23:35:51,550 iteration 1493 : loss : 0.047241, loss_ce: 0.020765
2021-12-12 23:35:53,016 iteration 1494 : loss : 0.043738, loss_ce: 0.014204
2021-12-12 23:35:54,416 iteration 1495 : loss : 0.043901, loss_ce: 0.013553
2021-12-12 23:35:55,924 iteration 1496 : loss : 0.041997, loss_ce: 0.019459
 22%|██████▌                       | 88/400 [40:37<2:16:55, 26.33s/it]2021-12-12 23:35:57,366 iteration 1497 : loss : 0.032932, loss_ce: 0.014846
2021-12-12 23:35:58,866 iteration 1498 : loss : 0.056233, loss_ce: 0.022796
2021-12-12 23:36:00,268 iteration 1499 : loss : 0.051685, loss_ce: 0.020624
2021-12-12 23:36:01,744 iteration 1500 : loss : 0.050726, loss_ce: 0.024454
2021-12-12 23:36:03,193 iteration 1501 : loss : 0.034239, loss_ce: 0.015790
2021-12-12 23:36:04,731 iteration 1502 : loss : 0.057690, loss_ce: 0.014036
2021-12-12 23:36:06,321 iteration 1503 : loss : 0.096259, loss_ce: 0.025069
2021-12-12 23:36:07,774 iteration 1504 : loss : 0.040064, loss_ce: 0.018823
2021-12-12 23:36:09,275 iteration 1505 : loss : 0.043586, loss_ce: 0.019143
2021-12-12 23:36:10,765 iteration 1506 : loss : 0.043631, loss_ce: 0.018530
2021-12-12 23:36:12,261 iteration 1507 : loss : 0.042219, loss_ce: 0.014558
2021-12-12 23:36:13,759 iteration 1508 : loss : 0.050188, loss_ce: 0.026869
2021-12-12 23:36:15,239 iteration 1509 : loss : 0.044942, loss_ce: 0.017584
2021-12-12 23:36:16,788 iteration 1510 : loss : 0.043619, loss_ce: 0.014830
2021-12-12 23:36:18,326 iteration 1511 : loss : 0.046675, loss_ce: 0.020900
2021-12-12 23:36:19,813 iteration 1512 : loss : 0.046248, loss_ce: 0.014956
2021-12-12 23:36:21,298 iteration 1513 : loss : 0.043828, loss_ce: 0.016414
 22%|██████▋                       | 89/400 [41:03<2:14:59, 26.04s/it]2021-12-12 23:36:22,849 iteration 1514 : loss : 0.047286, loss_ce: 0.016911
2021-12-12 23:36:24,266 iteration 1515 : loss : 0.039349, loss_ce: 0.017374
2021-12-12 23:36:25,744 iteration 1516 : loss : 0.047187, loss_ce: 0.020501
2021-12-12 23:36:27,143 iteration 1517 : loss : 0.043466, loss_ce: 0.016813
2021-12-12 23:36:28,639 iteration 1518 : loss : 0.039714, loss_ce: 0.014635
2021-12-12 23:36:30,178 iteration 1519 : loss : 0.045251, loss_ce: 0.017057
2021-12-12 23:36:31,696 iteration 1520 : loss : 0.051302, loss_ce: 0.018180
2021-12-12 23:36:33,192 iteration 1521 : loss : 0.053258, loss_ce: 0.014622
2021-12-12 23:36:34,625 iteration 1522 : loss : 0.037459, loss_ce: 0.014876
2021-12-12 23:36:36,070 iteration 1523 : loss : 0.044893, loss_ce: 0.017057
2021-12-12 23:36:37,549 iteration 1524 : loss : 0.040669, loss_ce: 0.016844
2021-12-12 23:36:38,950 iteration 1525 : loss : 0.045133, loss_ce: 0.017775
2021-12-12 23:36:40,442 iteration 1526 : loss : 0.047128, loss_ce: 0.023782
2021-12-12 23:36:41,954 iteration 1527 : loss : 0.049379, loss_ce: 0.023814
2021-12-12 23:36:43,380 iteration 1528 : loss : 0.038388, loss_ce: 0.015309
2021-12-12 23:36:44,805 iteration 1529 : loss : 0.049405, loss_ce: 0.019298
2021-12-12 23:36:44,805 Training Data Eval:
2021-12-12 23:36:52,320   Average segmentation loss on training set: 0.0314
2021-12-12 23:36:52,321 Validation Data Eval:
2021-12-12 23:36:54,921   Average segmentation loss on validation set: 0.0839
2021-12-12 23:37:01,382 Found new lowest validation loss at iteration 1529! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/TU_3seeds/TU_SGD_best_val_loss_seed2.pth
2021-12-12 23:37:02,784 iteration 1530 : loss : 0.046676, loss_ce: 0.020511
 22%|██████▊                       | 90/400 [41:44<2:38:29, 30.68s/it]2021-12-12 23:37:04,191 iteration 1531 : loss : 0.041438, loss_ce: 0.017106
2021-12-12 23:37:05,538 iteration 1532 : loss : 0.040200, loss_ce: 0.014129
2021-12-12 23:37:06,837 iteration 1533 : loss : 0.033014, loss_ce: 0.013043
2021-12-12 23:37:08,171 iteration 1534 : loss : 0.047282, loss_ce: 0.023026
2021-12-12 23:37:09,584 iteration 1535 : loss : 0.041763, loss_ce: 0.016956
2021-12-12 23:37:11,043 iteration 1536 : loss : 0.043637, loss_ce: 0.020784
2021-12-12 23:37:12,492 iteration 1537 : loss : 0.038643, loss_ce: 0.014187
2021-12-12 23:37:14,005 iteration 1538 : loss : 0.039870, loss_ce: 0.016865
2021-12-12 23:37:15,495 iteration 1539 : loss : 0.037820, loss_ce: 0.016426
2021-12-12 23:37:16,958 iteration 1540 : loss : 0.041782, loss_ce: 0.019583
2021-12-12 23:37:18,398 iteration 1541 : loss : 0.027193, loss_ce: 0.012567
2021-12-12 23:37:19,812 iteration 1542 : loss : 0.038228, loss_ce: 0.016339
2021-12-12 23:37:21,255 iteration 1543 : loss : 0.053094, loss_ce: 0.017653
2021-12-12 23:37:22,651 iteration 1544 : loss : 0.031807, loss_ce: 0.012659
2021-12-12 23:37:24,223 iteration 1545 : loss : 0.045307, loss_ce: 0.018179
2021-12-12 23:37:25,638 iteration 1546 : loss : 0.058320, loss_ce: 0.015512
2021-12-12 23:37:27,187 iteration 1547 : loss : 0.040817, loss_ce: 0.015706
 23%|██████▊                       | 91/400 [42:09<2:28:17, 28.79s/it]2021-12-12 23:37:28,714 iteration 1548 : loss : 0.044867, loss_ce: 0.019838
2021-12-12 23:37:30,099 iteration 1549 : loss : 0.033191, loss_ce: 0.013466
2021-12-12 23:37:31,540 iteration 1550 : loss : 0.041468, loss_ce: 0.016457
2021-12-12 23:37:32,898 iteration 1551 : loss : 0.034416, loss_ce: 0.013136
2021-12-12 23:37:34,383 iteration 1552 : loss : 0.039091, loss_ce: 0.014619
2021-12-12 23:37:35,899 iteration 1553 : loss : 0.048901, loss_ce: 0.019324
2021-12-12 23:37:37,393 iteration 1554 : loss : 0.036386, loss_ce: 0.015048
2021-12-12 23:37:38,841 iteration 1555 : loss : 0.043155, loss_ce: 0.018208
2021-12-12 23:37:40,332 iteration 1556 : loss : 0.045700, loss_ce: 0.016819
2021-12-12 23:37:41,770 iteration 1557 : loss : 0.042632, loss_ce: 0.017695
2021-12-12 23:37:43,234 iteration 1558 : loss : 0.043070, loss_ce: 0.020205
2021-12-12 23:37:44,709 iteration 1559 : loss : 0.047464, loss_ce: 0.018294
2021-12-12 23:37:46,130 iteration 1560 : loss : 0.033579, loss_ce: 0.016002
2021-12-12 23:37:47,641 iteration 1561 : loss : 0.033714, loss_ce: 0.012468
2021-12-12 23:37:49,067 iteration 1562 : loss : 0.044015, loss_ce: 0.013029
2021-12-12 23:37:50,577 iteration 1563 : loss : 0.035426, loss_ce: 0.015636
2021-12-12 23:37:52,087 iteration 1564 : loss : 0.040797, loss_ce: 0.017152
 23%|██████▉                       | 92/400 [42:34<2:21:48, 27.62s/it]2021-12-12 23:37:53,591 iteration 1565 : loss : 0.040872, loss_ce: 0.019308
2021-12-12 23:37:55,052 iteration 1566 : loss : 0.037859, loss_ce: 0.015874
2021-12-12 23:37:56,553 iteration 1567 : loss : 0.045063, loss_ce: 0.015792
2021-12-12 23:37:57,991 iteration 1568 : loss : 0.050371, loss_ce: 0.017153
2021-12-12 23:37:59,479 iteration 1569 : loss : 0.039099, loss_ce: 0.019554
2021-12-12 23:38:00,948 iteration 1570 : loss : 0.028069, loss_ce: 0.014104
2021-12-12 23:38:02,381 iteration 1571 : loss : 0.065338, loss_ce: 0.015264
2021-12-12 23:38:03,911 iteration 1572 : loss : 0.060962, loss_ce: 0.022290
2021-12-12 23:38:05,395 iteration 1573 : loss : 0.045913, loss_ce: 0.019873
2021-12-12 23:38:06,815 iteration 1574 : loss : 0.030528, loss_ce: 0.013404
2021-12-12 23:38:08,184 iteration 1575 : loss : 0.039608, loss_ce: 0.017646
2021-12-12 23:38:09,632 iteration 1576 : loss : 0.045037, loss_ce: 0.019696
2021-12-12 23:38:11,083 iteration 1577 : loss : 0.034667, loss_ce: 0.013990
2021-12-12 23:38:12,547 iteration 1578 : loss : 0.066112, loss_ce: 0.025145
2021-12-12 23:38:14,047 iteration 1579 : loss : 0.039198, loss_ce: 0.015852
2021-12-12 23:38:15,472 iteration 1580 : loss : 0.040503, loss_ce: 0.016677
2021-12-12 23:38:16,923 iteration 1581 : loss : 0.033734, loss_ce: 0.012780
 23%|██████▉                       | 93/400 [42:58<2:17:04, 26.79s/it]2021-12-12 23:38:18,494 iteration 1582 : loss : 0.054127, loss_ce: 0.018166
2021-12-12 23:38:19,950 iteration 1583 : loss : 0.050655, loss_ce: 0.017343
2021-12-12 23:38:21,435 iteration 1584 : loss : 0.040126, loss_ce: 0.021270
2021-12-12 23:38:22,894 iteration 1585 : loss : 0.036970, loss_ce: 0.013384
2021-12-12 23:38:24,345 iteration 1586 : loss : 0.045898, loss_ce: 0.020442
2021-12-12 23:38:25,711 iteration 1587 : loss : 0.030770, loss_ce: 0.013892
2021-12-12 23:38:27,196 iteration 1588 : loss : 0.044159, loss_ce: 0.021280
2021-12-12 23:38:28,664 iteration 1589 : loss : 0.037317, loss_ce: 0.015766
2021-12-12 23:38:30,252 iteration 1590 : loss : 0.051791, loss_ce: 0.020180
2021-12-12 23:38:31,678 iteration 1591 : loss : 0.039420, loss_ce: 0.014197
2021-12-12 23:38:33,133 iteration 1592 : loss : 0.044643, loss_ce: 0.016980
2021-12-12 23:38:34,698 iteration 1593 : loss : 0.055716, loss_ce: 0.022158
2021-12-12 23:38:36,245 iteration 1594 : loss : 0.048569, loss_ce: 0.017483
2021-12-12 23:38:37,701 iteration 1595 : loss : 0.028860, loss_ce: 0.010981
2021-12-12 23:38:39,173 iteration 1596 : loss : 0.041707, loss_ce: 0.019681
2021-12-12 23:38:40,634 iteration 1597 : loss : 0.035535, loss_ce: 0.015943
2021-12-12 23:38:42,121 iteration 1598 : loss : 0.042424, loss_ce: 0.016317
 24%|███████                       | 94/400 [43:24<2:14:11, 26.31s/it]2021-12-12 23:38:43,601 iteration 1599 : loss : 0.035528, loss_ce: 0.015163
2021-12-12 23:38:45,069 iteration 1600 : loss : 0.035065, loss_ce: 0.013351
2021-12-12 23:38:46,600 iteration 1601 : loss : 0.046498, loss_ce: 0.020153
2021-12-12 23:38:48,201 iteration 1602 : loss : 0.062241, loss_ce: 0.024259
2021-12-12 23:38:49,668 iteration 1603 : loss : 0.038976, loss_ce: 0.015854
2021-12-12 23:38:51,100 iteration 1604 : loss : 0.047584, loss_ce: 0.019161
2021-12-12 23:38:52,612 iteration 1605 : loss : 0.049489, loss_ce: 0.017306
2021-12-12 23:38:54,076 iteration 1606 : loss : 0.040462, loss_ce: 0.019744
2021-12-12 23:38:55,512 iteration 1607 : loss : 0.031915, loss_ce: 0.014024
2021-12-12 23:38:57,055 iteration 1608 : loss : 0.039001, loss_ce: 0.014396
2021-12-12 23:38:58,517 iteration 1609 : loss : 0.047438, loss_ce: 0.023536
2021-12-12 23:39:00,015 iteration 1610 : loss : 0.040875, loss_ce: 0.016434
2021-12-12 23:39:01,581 iteration 1611 : loss : 0.049483, loss_ce: 0.015760
2021-12-12 23:39:03,049 iteration 1612 : loss : 0.030557, loss_ce: 0.014193
2021-12-12 23:39:04,384 iteration 1613 : loss : 0.046031, loss_ce: 0.021262
2021-12-12 23:39:05,878 iteration 1614 : loss : 0.044725, loss_ce: 0.014207
2021-12-12 23:39:05,878 Training Data Eval:
2021-12-12 23:39:13,401   Average segmentation loss on training set: 0.0310
2021-12-12 23:39:13,402 Validation Data Eval:
2021-12-12 23:39:15,999   Average segmentation loss on validation set: 0.0865
2021-12-12 23:39:17,486 iteration 1615 : loss : 0.036747, loss_ce: 0.014622
 24%|███████▏                      | 95/400 [43:59<2:27:33, 29.03s/it]2021-12-12 23:39:19,038 iteration 1616 : loss : 0.046447, loss_ce: 0.017367
2021-12-12 23:39:20,528 iteration 1617 : loss : 0.050127, loss_ce: 0.015549
2021-12-12 23:39:21,926 iteration 1618 : loss : 0.028069, loss_ce: 0.012465
2021-12-12 23:39:23,327 iteration 1619 : loss : 0.032396, loss_ce: 0.012017
2021-12-12 23:39:24,703 iteration 1620 : loss : 0.042567, loss_ce: 0.013525
2021-12-12 23:39:26,193 iteration 1621 : loss : 0.055763, loss_ce: 0.033201
2021-12-12 23:39:27,786 iteration 1622 : loss : 0.064438, loss_ce: 0.018347
2021-12-12 23:39:29,249 iteration 1623 : loss : 0.045174, loss_ce: 0.019741
2021-12-12 23:39:30,676 iteration 1624 : loss : 0.040184, loss_ce: 0.015497
2021-12-12 23:39:32,140 iteration 1625 : loss : 0.040117, loss_ce: 0.017250
2021-12-12 23:39:33,578 iteration 1626 : loss : 0.036685, loss_ce: 0.016336
2021-12-12 23:39:35,034 iteration 1627 : loss : 0.041690, loss_ce: 0.015043
2021-12-12 23:39:36,572 iteration 1628 : loss : 0.055034, loss_ce: 0.021446
2021-12-12 23:39:38,024 iteration 1629 : loss : 0.031061, loss_ce: 0.012633
2021-12-12 23:39:39,429 iteration 1630 : loss : 0.042005, loss_ce: 0.016347
2021-12-12 23:39:41,009 iteration 1631 : loss : 0.047508, loss_ce: 0.020155
2021-12-12 23:39:42,552 iteration 1632 : loss : 0.049427, loss_ce: 0.017673
 24%|███████▏                      | 96/400 [44:24<2:21:02, 27.84s/it]2021-12-12 23:39:44,117 iteration 1633 : loss : 0.041903, loss_ce: 0.015595
2021-12-12 23:39:45,613 iteration 1634 : loss : 0.058836, loss_ce: 0.021661
2021-12-12 23:39:47,080 iteration 1635 : loss : 0.033250, loss_ce: 0.016404
2021-12-12 23:39:48,629 iteration 1636 : loss : 0.047597, loss_ce: 0.022914
2021-12-12 23:39:50,118 iteration 1637 : loss : 0.046882, loss_ce: 0.016145
2021-12-12 23:39:51,562 iteration 1638 : loss : 0.061590, loss_ce: 0.027520
2021-12-12 23:39:53,130 iteration 1639 : loss : 0.055068, loss_ce: 0.012782
2021-12-12 23:39:54,632 iteration 1640 : loss : 0.081942, loss_ce: 0.027576
2021-12-12 23:39:56,032 iteration 1641 : loss : 0.030968, loss_ce: 0.015189
2021-12-12 23:39:57,480 iteration 1642 : loss : 0.027654, loss_ce: 0.011191
2021-12-12 23:39:58,983 iteration 1643 : loss : 0.034380, loss_ce: 0.011362
2021-12-12 23:40:00,436 iteration 1644 : loss : 0.040266, loss_ce: 0.015830
2021-12-12 23:40:01,888 iteration 1645 : loss : 0.043454, loss_ce: 0.016629
2021-12-12 23:40:03,344 iteration 1646 : loss : 0.031241, loss_ce: 0.013316
2021-12-12 23:40:04,785 iteration 1647 : loss : 0.053523, loss_ce: 0.019285
2021-12-12 23:40:06,261 iteration 1648 : loss : 0.050612, loss_ce: 0.022412
2021-12-12 23:40:07,676 iteration 1649 : loss : 0.034953, loss_ce: 0.016509
 24%|███████▎                      | 97/400 [44:49<2:16:28, 27.02s/it]2021-12-12 23:40:09,214 iteration 1650 : loss : 0.041909, loss_ce: 0.019512
2021-12-12 23:40:10,806 iteration 1651 : loss : 0.051904, loss_ce: 0.014943
2021-12-12 23:40:12,227 iteration 1652 : loss : 0.046981, loss_ce: 0.015049
2021-12-12 23:40:13,638 iteration 1653 : loss : 0.036585, loss_ce: 0.013400
2021-12-12 23:40:15,144 iteration 1654 : loss : 0.058295, loss_ce: 0.016039
2021-12-12 23:40:16,667 iteration 1655 : loss : 0.056041, loss_ce: 0.020051
2021-12-12 23:40:18,123 iteration 1656 : loss : 0.041075, loss_ce: 0.016078
2021-12-12 23:40:19,697 iteration 1657 : loss : 0.050304, loss_ce: 0.017465
2021-12-12 23:40:21,215 iteration 1658 : loss : 0.048729, loss_ce: 0.024315
2021-12-12 23:40:22,633 iteration 1659 : loss : 0.029040, loss_ce: 0.010507
2021-12-12 23:40:24,209 iteration 1660 : loss : 0.058454, loss_ce: 0.023244
2021-12-12 23:40:25,761 iteration 1661 : loss : 0.034834, loss_ce: 0.012322
2021-12-12 23:40:27,235 iteration 1662 : loss : 0.038983, loss_ce: 0.015779
2021-12-12 23:40:28,592 iteration 1663 : loss : 0.029517, loss_ce: 0.015872
2021-12-12 23:40:30,140 iteration 1664 : loss : 0.064010, loss_ce: 0.021914
2021-12-12 23:40:31,652 iteration 1665 : loss : 0.048463, loss_ce: 0.021065
2021-12-12 23:40:33,193 iteration 1666 : loss : 0.046976, loss_ce: 0.020326
 24%|███████▎                      | 98/400 [45:15<2:13:45, 26.57s/it]2021-12-12 23:40:34,748 iteration 1667 : loss : 0.047914, loss_ce: 0.015893
2021-12-12 23:40:36,232 iteration 1668 : loss : 0.041945, loss_ce: 0.014531
2021-12-12 23:40:37,663 iteration 1669 : loss : 0.032687, loss_ce: 0.014349
2021-12-12 23:40:39,154 iteration 1670 : loss : 0.047138, loss_ce: 0.022438
2021-12-12 23:40:40,632 iteration 1671 : loss : 0.044170, loss_ce: 0.018131
2021-12-12 23:40:42,163 iteration 1672 : loss : 0.032622, loss_ce: 0.012965
2021-12-12 23:40:43,665 iteration 1673 : loss : 0.047579, loss_ce: 0.019909
2021-12-12 23:40:45,214 iteration 1674 : loss : 0.043942, loss_ce: 0.021049
2021-12-12 23:40:46,675 iteration 1675 : loss : 0.041160, loss_ce: 0.012849
2021-12-12 23:40:48,133 iteration 1676 : loss : 0.051521, loss_ce: 0.017910
2021-12-12 23:40:49,682 iteration 1677 : loss : 0.044852, loss_ce: 0.019762
2021-12-12 23:40:51,044 iteration 1678 : loss : 0.032774, loss_ce: 0.013769
2021-12-12 23:40:52,480 iteration 1679 : loss : 0.038421, loss_ce: 0.011942
2021-12-12 23:40:53,984 iteration 1680 : loss : 0.040661, loss_ce: 0.018886
2021-12-12 23:40:55,489 iteration 1681 : loss : 0.039683, loss_ce: 0.023309
2021-12-12 23:40:56,991 iteration 1682 : loss : 0.041874, loss_ce: 0.015261
2021-12-12 23:40:58,408 iteration 1683 : loss : 0.031356, loss_ce: 0.011173
 25%|███████▍                      | 99/400 [45:40<2:11:16, 26.17s/it]2021-12-12 23:40:59,942 iteration 1684 : loss : 0.055594, loss_ce: 0.020656
2021-12-12 23:41:01,415 iteration 1685 : loss : 0.051951, loss_ce: 0.017027
2021-12-12 23:41:02,879 iteration 1686 : loss : 0.032295, loss_ce: 0.012659
2021-12-12 23:41:04,283 iteration 1687 : loss : 0.044600, loss_ce: 0.020800
2021-12-12 23:41:05,878 iteration 1688 : loss : 0.037086, loss_ce: 0.016481
2021-12-12 23:41:07,371 iteration 1689 : loss : 0.047209, loss_ce: 0.019273
2021-12-12 23:41:08,908 iteration 1690 : loss : 0.050313, loss_ce: 0.022834
2021-12-12 23:41:10,310 iteration 1691 : loss : 0.049879, loss_ce: 0.011756
2021-12-12 23:41:11,829 iteration 1692 : loss : 0.063248, loss_ce: 0.020669
2021-12-12 23:41:13,178 iteration 1693 : loss : 0.037435, loss_ce: 0.015375
2021-12-12 23:41:14,678 iteration 1694 : loss : 0.037473, loss_ce: 0.014379
2021-12-12 23:41:16,213 iteration 1695 : loss : 0.047195, loss_ce: 0.019077
2021-12-12 23:41:17,761 iteration 1696 : loss : 0.039716, loss_ce: 0.014236
2021-12-12 23:41:19,228 iteration 1697 : loss : 0.044972, loss_ce: 0.017183
2021-12-12 23:41:20,748 iteration 1698 : loss : 0.041901, loss_ce: 0.017889
2021-12-12 23:41:22,226 iteration 1699 : loss : 0.039923, loss_ce: 0.022064
2021-12-12 23:41:22,226 Training Data Eval:
2021-12-12 23:41:29,763   Average segmentation loss on training set: 0.0311
2021-12-12 23:41:29,764 Validation Data Eval:
2021-12-12 23:41:32,360   Average segmentation loss on validation set: 0.0861
2021-12-12 23:41:33,804 iteration 1700 : loss : 0.040732, loss_ce: 0.013004
 25%|███████▎                     | 100/400 [46:15<2:24:40, 28.93s/it]2021-12-12 23:41:35,322 iteration 1701 : loss : 0.040306, loss_ce: 0.018116
2021-12-12 23:41:36,766 iteration 1702 : loss : 0.044883, loss_ce: 0.019762
2021-12-12 23:41:38,310 iteration 1703 : loss : 0.036433, loss_ce: 0.016867
2021-12-12 23:41:39,838 iteration 1704 : loss : 0.048658, loss_ce: 0.021807
2021-12-12 23:41:41,296 iteration 1705 : loss : 0.046325, loss_ce: 0.015951
2021-12-12 23:41:42,812 iteration 1706 : loss : 0.038594, loss_ce: 0.012035
2021-12-12 23:41:44,260 iteration 1707 : loss : 0.043372, loss_ce: 0.018526
2021-12-12 23:41:45,718 iteration 1708 : loss : 0.039255, loss_ce: 0.015890
2021-12-12 23:41:47,341 iteration 1709 : loss : 0.057700, loss_ce: 0.021896
2021-12-12 23:41:48,772 iteration 1710 : loss : 0.043324, loss_ce: 0.020281
2021-12-12 23:41:50,259 iteration 1711 : loss : 0.046958, loss_ce: 0.017639
2021-12-12 23:41:51,744 iteration 1712 : loss : 0.057355, loss_ce: 0.019519
2021-12-12 23:41:53,226 iteration 1713 : loss : 0.048908, loss_ce: 0.016251
2021-12-12 23:41:54,680 iteration 1714 : loss : 0.033906, loss_ce: 0.014581
2021-12-12 23:41:56,212 iteration 1715 : loss : 0.047094, loss_ce: 0.017652
2021-12-12 23:41:57,669 iteration 1716 : loss : 0.051657, loss_ce: 0.015003
2021-12-12 23:41:59,181 iteration 1717 : loss : 0.033928, loss_ce: 0.014363
 25%|███████▎                     | 101/400 [46:41<2:18:52, 27.87s/it]2021-12-12 23:42:00,732 iteration 1718 : loss : 0.040730, loss_ce: 0.015764
2021-12-12 23:42:02,279 iteration 1719 : loss : 0.035666, loss_ce: 0.012221
2021-12-12 23:42:03,794 iteration 1720 : loss : 0.057107, loss_ce: 0.021592
2021-12-12 23:42:05,290 iteration 1721 : loss : 0.046777, loss_ce: 0.022168
2021-12-12 23:42:06,720 iteration 1722 : loss : 0.030753, loss_ce: 0.011396
2021-12-12 23:42:08,163 iteration 1723 : loss : 0.036811, loss_ce: 0.015123
2021-12-12 23:42:09,558 iteration 1724 : loss : 0.032933, loss_ce: 0.015349
2021-12-12 23:42:10,972 iteration 1725 : loss : 0.036053, loss_ce: 0.016619
2021-12-12 23:42:12,545 iteration 1726 : loss : 0.036283, loss_ce: 0.012934
2021-12-12 23:42:14,069 iteration 1727 : loss : 0.055827, loss_ce: 0.019300
2021-12-12 23:42:15,637 iteration 1728 : loss : 0.042794, loss_ce: 0.018925
2021-12-12 23:42:17,078 iteration 1729 : loss : 0.046270, loss_ce: 0.017286
2021-12-12 23:42:18,562 iteration 1730 : loss : 0.038627, loss_ce: 0.014771
2021-12-12 23:42:19,993 iteration 1731 : loss : 0.030771, loss_ce: 0.014628
2021-12-12 23:42:21,476 iteration 1732 : loss : 0.038498, loss_ce: 0.015946
2021-12-12 23:42:22,986 iteration 1733 : loss : 0.036258, loss_ce: 0.013248
2021-12-12 23:42:24,435 iteration 1734 : loss : 0.051426, loss_ce: 0.016354
 26%|███████▍                     | 102/400 [47:06<2:14:30, 27.08s/it]2021-12-12 23:42:26,018 iteration 1735 : loss : 0.037457, loss_ce: 0.012518
2021-12-12 23:42:27,494 iteration 1736 : loss : 0.035779, loss_ce: 0.015312
2021-12-12 23:42:28,992 iteration 1737 : loss : 0.052538, loss_ce: 0.019267
2021-12-12 23:42:30,458 iteration 1738 : loss : 0.044708, loss_ce: 0.015984
2021-12-12 23:42:31,921 iteration 1739 : loss : 0.052944, loss_ce: 0.026793
2021-12-12 23:42:33,381 iteration 1740 : loss : 0.058972, loss_ce: 0.014736
2021-12-12 23:42:34,937 iteration 1741 : loss : 0.045285, loss_ce: 0.015644
2021-12-12 23:42:36,417 iteration 1742 : loss : 0.048907, loss_ce: 0.018745
2021-12-12 23:42:37,889 iteration 1743 : loss : 0.052849, loss_ce: 0.030710
2021-12-12 23:42:39,325 iteration 1744 : loss : 0.039496, loss_ce: 0.014241
2021-12-12 23:42:40,860 iteration 1745 : loss : 0.042398, loss_ce: 0.017088
2021-12-12 23:42:42,307 iteration 1746 : loss : 0.046681, loss_ce: 0.017954
2021-12-12 23:42:43,764 iteration 1747 : loss : 0.041146, loss_ce: 0.014391
2021-12-12 23:42:45,182 iteration 1748 : loss : 0.040165, loss_ce: 0.019720
2021-12-12 23:42:46,673 iteration 1749 : loss : 0.045191, loss_ce: 0.017872
2021-12-12 23:42:48,100 iteration 1750 : loss : 0.032888, loss_ce: 0.017345
2021-12-12 23:42:49,527 iteration 1751 : loss : 0.043006, loss_ce: 0.016301
 26%|███████▍                     | 103/400 [47:31<2:11:06, 26.49s/it]2021-12-12 23:42:51,035 iteration 1752 : loss : 0.038227, loss_ce: 0.017433
2021-12-12 23:42:52,581 iteration 1753 : loss : 0.052571, loss_ce: 0.025607
2021-12-12 23:42:54,081 iteration 1754 : loss : 0.038668, loss_ce: 0.016879
2021-12-12 23:42:55,573 iteration 1755 : loss : 0.043543, loss_ce: 0.013560
2021-12-12 23:42:57,099 iteration 1756 : loss : 0.037037, loss_ce: 0.016289
2021-12-12 23:42:58,577 iteration 1757 : loss : 0.037283, loss_ce: 0.012778
2021-12-12 23:43:00,075 iteration 1758 : loss : 0.045313, loss_ce: 0.018193
2021-12-12 23:43:01,538 iteration 1759 : loss : 0.040489, loss_ce: 0.015659
2021-12-12 23:43:03,060 iteration 1760 : loss : 0.042175, loss_ce: 0.020664
2021-12-12 23:43:04,475 iteration 1761 : loss : 0.032633, loss_ce: 0.013345
2021-12-12 23:43:06,011 iteration 1762 : loss : 0.053751, loss_ce: 0.021756
2021-12-12 23:43:07,466 iteration 1763 : loss : 0.042758, loss_ce: 0.014532
2021-12-12 23:43:08,970 iteration 1764 : loss : 0.084421, loss_ce: 0.019175
2021-12-12 23:43:10,480 iteration 1765 : loss : 0.043034, loss_ce: 0.012181
2021-12-12 23:43:11,904 iteration 1766 : loss : 0.031312, loss_ce: 0.014537
2021-12-12 23:43:13,368 iteration 1767 : loss : 0.041178, loss_ce: 0.016576
2021-12-12 23:43:14,905 iteration 1768 : loss : 0.047244, loss_ce: 0.017083
 26%|███████▌                     | 104/400 [47:56<2:09:01, 26.15s/it]2021-12-12 23:43:16,408 iteration 1769 : loss : 0.036215, loss_ce: 0.012668
2021-12-12 23:43:18,059 iteration 1770 : loss : 0.074398, loss_ce: 0.032919
2021-12-12 23:43:19,544 iteration 1771 : loss : 0.042374, loss_ce: 0.014701
2021-12-12 23:43:20,962 iteration 1772 : loss : 0.031756, loss_ce: 0.011011
2021-12-12 23:43:22,360 iteration 1773 : loss : 0.036965, loss_ce: 0.012618
2021-12-12 23:43:23,832 iteration 1774 : loss : 0.038909, loss_ce: 0.018429
2021-12-12 23:43:25,360 iteration 1775 : loss : 0.042406, loss_ce: 0.020379
2021-12-12 23:43:26,821 iteration 1776 : loss : 0.064025, loss_ce: 0.015869
2021-12-12 23:43:28,269 iteration 1777 : loss : 0.043594, loss_ce: 0.017900
2021-12-12 23:43:29,724 iteration 1778 : loss : 0.047028, loss_ce: 0.018816
2021-12-12 23:43:31,200 iteration 1779 : loss : 0.040956, loss_ce: 0.015079
2021-12-12 23:43:32,647 iteration 1780 : loss : 0.038683, loss_ce: 0.016367
2021-12-12 23:43:34,101 iteration 1781 : loss : 0.047775, loss_ce: 0.022351
2021-12-12 23:43:35,612 iteration 1782 : loss : 0.037339, loss_ce: 0.014060
2021-12-12 23:43:37,040 iteration 1783 : loss : 0.036881, loss_ce: 0.018214
2021-12-12 23:43:38,592 iteration 1784 : loss : 0.034029, loss_ce: 0.013664
2021-12-12 23:43:38,592 Training Data Eval:
2021-12-12 23:43:46,116   Average segmentation loss on training set: 0.0308
2021-12-12 23:43:46,117 Validation Data Eval:
2021-12-12 23:43:48,719   Average segmentation loss on validation set: 0.0838
2021-12-12 23:43:55,229 Found new lowest validation loss at iteration 1784! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/TU_3seeds/TU_SGD_best_val_loss_seed2.pth
2021-12-12 23:43:56,607 iteration 1785 : loss : 0.037724, loss_ce: 0.015401
 26%|███████▌                     | 105/400 [48:38<2:31:31, 30.82s/it]2021-12-12 23:43:58,121 iteration 1786 : loss : 0.039233, loss_ce: 0.019173
2021-12-12 23:43:59,587 iteration 1787 : loss : 0.038655, loss_ce: 0.016185
2021-12-12 23:44:00,970 iteration 1788 : loss : 0.041230, loss_ce: 0.016470
2021-12-12 23:44:02,341 iteration 1789 : loss : 0.052982, loss_ce: 0.017281
2021-12-12 23:44:03,702 iteration 1790 : loss : 0.033796, loss_ce: 0.016192
2021-12-12 23:44:05,050 iteration 1791 : loss : 0.028123, loss_ce: 0.014309
2021-12-12 23:44:06,545 iteration 1792 : loss : 0.048393, loss_ce: 0.015200
2021-12-12 23:44:08,060 iteration 1793 : loss : 0.038934, loss_ce: 0.018673
2021-12-12 23:44:09,501 iteration 1794 : loss : 0.036159, loss_ce: 0.017038
2021-12-12 23:44:10,986 iteration 1795 : loss : 0.039408, loss_ce: 0.016962
2021-12-12 23:44:12,464 iteration 1796 : loss : 0.047823, loss_ce: 0.017056
2021-12-12 23:44:14,028 iteration 1797 : loss : 0.035514, loss_ce: 0.014929
2021-12-12 23:44:15,505 iteration 1798 : loss : 0.039186, loss_ce: 0.013886
2021-12-12 23:44:17,010 iteration 1799 : loss : 0.041921, loss_ce: 0.017692
2021-12-12 23:44:18,517 iteration 1800 : loss : 0.058179, loss_ce: 0.025028
2021-12-12 23:44:20,026 iteration 1801 : loss : 0.033213, loss_ce: 0.014186
2021-12-12 23:44:21,418 iteration 1802 : loss : 0.062253, loss_ce: 0.017299
 26%|███████▋                     | 106/400 [49:03<2:22:10, 29.02s/it]2021-12-12 23:44:22,955 iteration 1803 : loss : 0.047964, loss_ce: 0.016699
2021-12-12 23:44:24,411 iteration 1804 : loss : 0.036033, loss_ce: 0.010469
2021-12-12 23:44:25,837 iteration 1805 : loss : 0.034910, loss_ce: 0.016311
2021-12-12 23:44:27,265 iteration 1806 : loss : 0.045337, loss_ce: 0.015544
2021-12-12 23:44:28,746 iteration 1807 : loss : 0.038865, loss_ce: 0.013584
2021-12-12 23:44:30,233 iteration 1808 : loss : 0.045349, loss_ce: 0.019136
2021-12-12 23:44:31,689 iteration 1809 : loss : 0.040751, loss_ce: 0.017485
2021-12-12 23:44:33,169 iteration 1810 : loss : 0.038568, loss_ce: 0.014736
2021-12-12 23:44:34,674 iteration 1811 : loss : 0.039999, loss_ce: 0.015594
2021-12-12 23:44:36,219 iteration 1812 : loss : 0.037733, loss_ce: 0.019270
2021-12-12 23:44:37,736 iteration 1813 : loss : 0.062454, loss_ce: 0.021724
2021-12-12 23:44:39,296 iteration 1814 : loss : 0.059898, loss_ce: 0.025875
2021-12-12 23:44:40,795 iteration 1815 : loss : 0.040448, loss_ce: 0.020023
2021-12-12 23:44:42,334 iteration 1816 : loss : 0.057524, loss_ce: 0.021056
2021-12-12 23:44:43,829 iteration 1817 : loss : 0.042646, loss_ce: 0.014258
2021-12-12 23:44:45,402 iteration 1818 : loss : 0.042952, loss_ce: 0.022746
2021-12-12 23:44:46,857 iteration 1819 : loss : 0.040614, loss_ce: 0.016087
 27%|███████▊                     | 107/400 [49:28<2:16:26, 27.94s/it]2021-12-12 23:44:48,422 iteration 1820 : loss : 0.058964, loss_ce: 0.019933
2021-12-12 23:44:49,878 iteration 1821 : loss : 0.032947, loss_ce: 0.012180
2021-12-12 23:44:51,317 iteration 1822 : loss : 0.036729, loss_ce: 0.017805
2021-12-12 23:44:52,830 iteration 1823 : loss : 0.044228, loss_ce: 0.016912
2021-12-12 23:44:54,293 iteration 1824 : loss : 0.037661, loss_ce: 0.014834
2021-12-12 23:44:55,778 iteration 1825 : loss : 0.044964, loss_ce: 0.016052
2021-12-12 23:44:57,169 iteration 1826 : loss : 0.057039, loss_ce: 0.022611
2021-12-12 23:44:58,603 iteration 1827 : loss : 0.064949, loss_ce: 0.017456
2021-12-12 23:45:00,116 iteration 1828 : loss : 0.041322, loss_ce: 0.019084
2021-12-12 23:45:01,620 iteration 1829 : loss : 0.077002, loss_ce: 0.021324
2021-12-12 23:45:03,087 iteration 1830 : loss : 0.034408, loss_ce: 0.014002
2021-12-12 23:45:04,539 iteration 1831 : loss : 0.046801, loss_ce: 0.020496
2021-12-12 23:45:06,003 iteration 1832 : loss : 0.035661, loss_ce: 0.012636
2021-12-12 23:45:07,440 iteration 1833 : loss : 0.035386, loss_ce: 0.020685
2021-12-12 23:45:08,974 iteration 1834 : loss : 0.035802, loss_ce: 0.014698
2021-12-12 23:45:10,367 iteration 1835 : loss : 0.042184, loss_ce: 0.014811
2021-12-12 23:45:11,805 iteration 1836 : loss : 0.043915, loss_ce: 0.016963
 27%|███████▊                     | 108/400 [49:53<2:11:37, 27.05s/it]2021-12-12 23:45:13,255 iteration 1837 : loss : 0.043944, loss_ce: 0.010080
2021-12-12 23:45:14,794 iteration 1838 : loss : 0.052246, loss_ce: 0.022265
2021-12-12 23:45:16,200 iteration 1839 : loss : 0.035066, loss_ce: 0.015427
2021-12-12 23:45:17,675 iteration 1840 : loss : 0.040190, loss_ce: 0.012626
2021-12-12 23:45:19,153 iteration 1841 : loss : 0.037908, loss_ce: 0.013190
2021-12-12 23:45:20,710 iteration 1842 : loss : 0.038701, loss_ce: 0.016421
2021-12-12 23:45:22,168 iteration 1843 : loss : 0.037449, loss_ce: 0.015367
2021-12-12 23:45:23,640 iteration 1844 : loss : 0.041759, loss_ce: 0.019625
2021-12-12 23:45:25,104 iteration 1845 : loss : 0.035274, loss_ce: 0.013734
2021-12-12 23:45:26,589 iteration 1846 : loss : 0.046657, loss_ce: 0.014646
2021-12-12 23:45:27,983 iteration 1847 : loss : 0.029020, loss_ce: 0.012165
2021-12-12 23:45:29,455 iteration 1848 : loss : 0.035440, loss_ce: 0.015015
2021-12-12 23:45:30,924 iteration 1849 : loss : 0.045473, loss_ce: 0.016548
2021-12-12 23:45:32,408 iteration 1850 : loss : 0.045974, loss_ce: 0.018030
2021-12-12 23:45:33,926 iteration 1851 : loss : 0.045935, loss_ce: 0.020045
2021-12-12 23:45:35,307 iteration 1852 : loss : 0.033380, loss_ce: 0.016938
2021-12-12 23:45:36,813 iteration 1853 : loss : 0.032949, loss_ce: 0.016441
 27%|███████▉                     | 109/400 [50:18<2:08:12, 26.43s/it]2021-12-12 23:45:38,348 iteration 1854 : loss : 0.057087, loss_ce: 0.019754
2021-12-12 23:45:39,874 iteration 1855 : loss : 0.048484, loss_ce: 0.018057
2021-12-12 23:45:41,251 iteration 1856 : loss : 0.036958, loss_ce: 0.016640
2021-12-12 23:45:42,636 iteration 1857 : loss : 0.031422, loss_ce: 0.015378
2021-12-12 23:45:44,066 iteration 1858 : loss : 0.031878, loss_ce: 0.015428
2021-12-12 23:45:45,544 iteration 1859 : loss : 0.036379, loss_ce: 0.014211
2021-12-12 23:45:47,053 iteration 1860 : loss : 0.043588, loss_ce: 0.016045
2021-12-12 23:45:48,535 iteration 1861 : loss : 0.041174, loss_ce: 0.019039
2021-12-12 23:45:50,046 iteration 1862 : loss : 0.038952, loss_ce: 0.019450
2021-12-12 23:45:51,551 iteration 1863 : loss : 0.047247, loss_ce: 0.018189
2021-12-12 23:45:53,049 iteration 1864 : loss : 0.039957, loss_ce: 0.015374
2021-12-12 23:45:54,530 iteration 1865 : loss : 0.055332, loss_ce: 0.015673
2021-12-12 23:45:56,015 iteration 1866 : loss : 0.028206, loss_ce: 0.011372
2021-12-12 23:45:57,384 iteration 1867 : loss : 0.030165, loss_ce: 0.011619
2021-12-12 23:45:58,821 iteration 1868 : loss : 0.035589, loss_ce: 0.012713
2021-12-12 23:46:00,258 iteration 1869 : loss : 0.041339, loss_ce: 0.020465
2021-12-12 23:46:00,258 Training Data Eval:
2021-12-12 23:46:07,782   Average segmentation loss on training set: 0.0289
2021-12-12 23:46:07,782 Validation Data Eval:
2021-12-12 23:46:10,381   Average segmentation loss on validation set: 0.0900
2021-12-12 23:46:11,864 iteration 1870 : loss : 0.049380, loss_ce: 0.019283
 28%|███████▉                     | 110/400 [50:53<2:20:15, 29.02s/it]2021-12-12 23:46:13,425 iteration 1871 : loss : 0.057020, loss_ce: 0.017045
2021-12-12 23:46:14,938 iteration 1872 : loss : 0.033373, loss_ce: 0.011821
2021-12-12 23:46:16,463 iteration 1873 : loss : 0.044473, loss_ce: 0.014926
2021-12-12 23:46:17,967 iteration 1874 : loss : 0.044796, loss_ce: 0.016062
2021-12-12 23:46:19,368 iteration 1875 : loss : 0.030567, loss_ce: 0.013330
2021-12-12 23:46:20,752 iteration 1876 : loss : 0.032794, loss_ce: 0.015911
2021-12-12 23:46:22,280 iteration 1877 : loss : 0.039691, loss_ce: 0.013609
2021-12-12 23:46:23,774 iteration 1878 : loss : 0.044788, loss_ce: 0.023338
2021-12-12 23:46:25,250 iteration 1879 : loss : 0.041230, loss_ce: 0.013756
2021-12-12 23:46:26,755 iteration 1880 : loss : 0.055520, loss_ce: 0.023960
2021-12-12 23:46:28,241 iteration 1881 : loss : 0.051296, loss_ce: 0.027879
2021-12-12 23:46:29,779 iteration 1882 : loss : 0.059398, loss_ce: 0.022882
2021-12-12 23:46:31,271 iteration 1883 : loss : 0.030927, loss_ce: 0.011653
2021-12-12 23:46:32,712 iteration 1884 : loss : 0.032412, loss_ce: 0.013383
2021-12-12 23:46:34,110 iteration 1885 : loss : 0.029180, loss_ce: 0.012079
2021-12-12 23:46:35,594 iteration 1886 : loss : 0.049709, loss_ce: 0.019622
2021-12-12 23:46:37,086 iteration 1887 : loss : 0.054455, loss_ce: 0.025255
 28%|████████                     | 111/400 [51:19<2:14:16, 27.88s/it]2021-12-12 23:46:38,709 iteration 1888 : loss : 0.054301, loss_ce: 0.018679
2021-12-12 23:46:40,132 iteration 1889 : loss : 0.039142, loss_ce: 0.014956
2021-12-12 23:46:41,531 iteration 1890 : loss : 0.032187, loss_ce: 0.015484
2021-12-12 23:46:42,949 iteration 1891 : loss : 0.037263, loss_ce: 0.013875
2021-12-12 23:46:44,411 iteration 1892 : loss : 0.036407, loss_ce: 0.017456
2021-12-12 23:46:45,898 iteration 1893 : loss : 0.031615, loss_ce: 0.010657
2021-12-12 23:46:47,357 iteration 1894 : loss : 0.042694, loss_ce: 0.016394
2021-12-12 23:46:48,764 iteration 1895 : loss : 0.033343, loss_ce: 0.013571
2021-12-12 23:46:50,312 iteration 1896 : loss : 0.050581, loss_ce: 0.021837
2021-12-12 23:46:51,812 iteration 1897 : loss : 0.044656, loss_ce: 0.015768
2021-12-12 23:46:53,366 iteration 1898 : loss : 0.040217, loss_ce: 0.018314
2021-12-12 23:46:54,842 iteration 1899 : loss : 0.039324, loss_ce: 0.013640
2021-12-12 23:46:56,276 iteration 1900 : loss : 0.047473, loss_ce: 0.019329
2021-12-12 23:46:57,677 iteration 1901 : loss : 0.036606, loss_ce: 0.012915
2021-12-12 23:46:59,143 iteration 1902 : loss : 0.039945, loss_ce: 0.016473
2021-12-12 23:47:00,658 iteration 1903 : loss : 0.037746, loss_ce: 0.014958
2021-12-12 23:47:02,185 iteration 1904 : loss : 0.033406, loss_ce: 0.013923
 28%|████████                     | 112/400 [51:44<2:09:49, 27.05s/it]2021-12-12 23:47:03,631 iteration 1905 : loss : 0.041563, loss_ce: 0.018000
2021-12-12 23:47:05,141 iteration 1906 : loss : 0.037661, loss_ce: 0.012517
2021-12-12 23:47:06,661 iteration 1907 : loss : 0.042676, loss_ce: 0.017897
2021-12-12 23:47:08,269 iteration 1908 : loss : 0.039952, loss_ce: 0.015903
2021-12-12 23:47:09,662 iteration 1909 : loss : 0.028001, loss_ce: 0.012750
2021-12-12 23:47:11,128 iteration 1910 : loss : 0.037122, loss_ce: 0.014368
2021-12-12 23:47:12,643 iteration 1911 : loss : 0.037113, loss_ce: 0.016918
2021-12-12 23:47:14,221 iteration 1912 : loss : 0.049546, loss_ce: 0.020867
2021-12-12 23:47:15,731 iteration 1913 : loss : 0.049634, loss_ce: 0.017529
2021-12-12 23:47:17,297 iteration 1914 : loss : 0.059040, loss_ce: 0.024518
2021-12-12 23:47:18,778 iteration 1915 : loss : 0.030756, loss_ce: 0.011466
2021-12-12 23:47:20,229 iteration 1916 : loss : 0.046367, loss_ce: 0.016534
2021-12-12 23:47:21,684 iteration 1917 : loss : 0.031306, loss_ce: 0.013583
2021-12-12 23:47:23,208 iteration 1918 : loss : 0.039961, loss_ce: 0.018171
2021-12-12 23:47:24,649 iteration 1919 : loss : 0.042807, loss_ce: 0.013584
2021-12-12 23:47:26,045 iteration 1920 : loss : 0.033024, loss_ce: 0.015322
2021-12-12 23:47:27,592 iteration 1921 : loss : 0.056750, loss_ce: 0.020313
 28%|████████▏                    | 113/400 [52:09<2:07:01, 26.55s/it]2021-12-12 23:47:29,169 iteration 1922 : loss : 0.053929, loss_ce: 0.020033
2021-12-12 23:47:30,615 iteration 1923 : loss : 0.039557, loss_ce: 0.015157
2021-12-12 23:47:32,151 iteration 1924 : loss : 0.044290, loss_ce: 0.014146
2021-12-12 23:47:33,576 iteration 1925 : loss : 0.047894, loss_ce: 0.013628
2021-12-12 23:47:35,114 iteration 1926 : loss : 0.040903, loss_ce: 0.016076
2021-12-12 23:47:36,677 iteration 1927 : loss : 0.037446, loss_ce: 0.017592
2021-12-12 23:47:38,107 iteration 1928 : loss : 0.039101, loss_ce: 0.012889
2021-12-12 23:47:39,721 iteration 1929 : loss : 0.066473, loss_ce: 0.031462
2021-12-12 23:47:41,205 iteration 1930 : loss : 0.039332, loss_ce: 0.017731
2021-12-12 23:47:42,751 iteration 1931 : loss : 0.053218, loss_ce: 0.017998
2021-12-12 23:47:44,252 iteration 1932 : loss : 0.044310, loss_ce: 0.013861
2021-12-12 23:47:45,755 iteration 1933 : loss : 0.037289, loss_ce: 0.014859
2021-12-12 23:47:47,225 iteration 1934 : loss : 0.039096, loss_ce: 0.012530
2021-12-12 23:47:48,721 iteration 1935 : loss : 0.037155, loss_ce: 0.013889
2021-12-12 23:47:50,179 iteration 1936 : loss : 0.043400, loss_ce: 0.018281
2021-12-12 23:47:51,597 iteration 1937 : loss : 0.034529, loss_ce: 0.013304
2021-12-12 23:47:53,098 iteration 1938 : loss : 0.038342, loss_ce: 0.017700
 28%|████████▎                    | 114/400 [52:35<2:05:04, 26.24s/it]2021-12-12 23:47:54,659 iteration 1939 : loss : 0.039966, loss_ce: 0.017034
2021-12-12 23:47:56,080 iteration 1940 : loss : 0.031811, loss_ce: 0.015206
2021-12-12 23:47:57,552 iteration 1941 : loss : 0.034516, loss_ce: 0.013554
2021-12-12 23:47:59,042 iteration 1942 : loss : 0.040801, loss_ce: 0.014873
2021-12-12 23:48:00,506 iteration 1943 : loss : 0.042963, loss_ce: 0.015621
2021-12-12 23:48:01,983 iteration 1944 : loss : 0.042815, loss_ce: 0.016550
2021-12-12 23:48:03,474 iteration 1945 : loss : 0.047828, loss_ce: 0.018430
2021-12-12 23:48:04,918 iteration 1946 : loss : 0.048674, loss_ce: 0.014109
2021-12-12 23:48:06,379 iteration 1947 : loss : 0.040441, loss_ce: 0.011300
2021-12-12 23:48:07,871 iteration 1948 : loss : 0.042963, loss_ce: 0.019339
2021-12-12 23:48:09,301 iteration 1949 : loss : 0.033641, loss_ce: 0.011572
2021-12-12 23:48:10,827 iteration 1950 : loss : 0.049341, loss_ce: 0.019592
2021-12-12 23:48:12,328 iteration 1951 : loss : 0.039909, loss_ce: 0.014455
2021-12-12 23:48:13,807 iteration 1952 : loss : 0.036413, loss_ce: 0.016714
2021-12-12 23:48:15,208 iteration 1953 : loss : 0.043815, loss_ce: 0.024962
2021-12-12 23:48:16,719 iteration 1954 : loss : 0.034150, loss_ce: 0.016457
2021-12-12 23:48:16,719 Training Data Eval:
2021-12-12 23:48:24,258   Average segmentation loss on training set: 0.0289
2021-12-12 23:48:24,259 Validation Data Eval:
2021-12-12 23:48:26,857   Average segmentation loss on validation set: 0.0852
2021-12-12 23:48:28,364 iteration 1955 : loss : 0.041081, loss_ce: 0.015794
 29%|████████▎                    | 115/400 [53:10<2:17:29, 28.95s/it]2021-12-12 23:48:29,862 iteration 1956 : loss : 0.047785, loss_ce: 0.018106
2021-12-12 23:48:31,386 iteration 1957 : loss : 0.047883, loss_ce: 0.022962
2021-12-12 23:48:32,871 iteration 1958 : loss : 0.034884, loss_ce: 0.011237
2021-12-12 23:48:34,321 iteration 1959 : loss : 0.045221, loss_ce: 0.012915
2021-12-12 23:48:35,699 iteration 1960 : loss : 0.036495, loss_ce: 0.014860
2021-12-12 23:48:37,053 iteration 1961 : loss : 0.029883, loss_ce: 0.012313
2021-12-12 23:48:38,562 iteration 1962 : loss : 0.035695, loss_ce: 0.016245
2021-12-12 23:48:39,977 iteration 1963 : loss : 0.035372, loss_ce: 0.014234
2021-12-12 23:48:41,485 iteration 1964 : loss : 0.046741, loss_ce: 0.014419
2021-12-12 23:48:42,882 iteration 1965 : loss : 0.034213, loss_ce: 0.015490
2021-12-12 23:48:44,342 iteration 1966 : loss : 0.035413, loss_ce: 0.014261
2021-12-12 23:48:45,916 iteration 1967 : loss : 0.036376, loss_ce: 0.015312
2021-12-12 23:48:47,549 iteration 1968 : loss : 0.057119, loss_ce: 0.023522
2021-12-12 23:48:49,077 iteration 1969 : loss : 0.044518, loss_ce: 0.016316
2021-12-12 23:48:50,481 iteration 1970 : loss : 0.036904, loss_ce: 0.016159
2021-12-12 23:48:51,961 iteration 1971 : loss : 0.033905, loss_ce: 0.012156
2021-12-12 23:48:53,445 iteration 1972 : loss : 0.033172, loss_ce: 0.011755
 29%|████████▍                    | 116/400 [53:35<2:11:31, 27.79s/it]2021-12-12 23:48:54,926 iteration 1973 : loss : 0.033105, loss_ce: 0.014427
2021-12-12 23:48:56,353 iteration 1974 : loss : 0.034188, loss_ce: 0.014699
2021-12-12 23:48:57,851 iteration 1975 : loss : 0.040924, loss_ce: 0.015331
2021-12-12 23:48:59,289 iteration 1976 : loss : 0.034185, loss_ce: 0.016249
2021-12-12 23:49:00,817 iteration 1977 : loss : 0.042543, loss_ce: 0.015122
2021-12-12 23:49:02,365 iteration 1978 : loss : 0.038261, loss_ce: 0.014508
2021-12-12 23:49:03,780 iteration 1979 : loss : 0.037562, loss_ce: 0.015706
2021-12-12 23:49:05,197 iteration 1980 : loss : 0.030958, loss_ce: 0.012101
2021-12-12 23:49:06,638 iteration 1981 : loss : 0.038501, loss_ce: 0.016439
2021-12-12 23:49:08,153 iteration 1982 : loss : 0.036942, loss_ce: 0.014174
2021-12-12 23:49:09,557 iteration 1983 : loss : 0.041339, loss_ce: 0.014234
2021-12-12 23:49:11,096 iteration 1984 : loss : 0.050433, loss_ce: 0.018111
2021-12-12 23:49:12,558 iteration 1985 : loss : 0.047266, loss_ce: 0.017165
2021-12-12 23:49:14,080 iteration 1986 : loss : 0.047812, loss_ce: 0.017112
2021-12-12 23:49:15,527 iteration 1987 : loss : 0.040047, loss_ce: 0.014859
2021-12-12 23:49:16,923 iteration 1988 : loss : 0.039077, loss_ce: 0.016883
2021-12-12 23:49:18,386 iteration 1989 : loss : 0.039051, loss_ce: 0.014699
 29%|████████▍                    | 117/400 [54:00<2:07:02, 26.93s/it]2021-12-12 23:49:19,905 iteration 1990 : loss : 0.040631, loss_ce: 0.012298
2021-12-12 23:49:21,305 iteration 1991 : loss : 0.034970, loss_ce: 0.014649
2021-12-12 23:49:22,795 iteration 1992 : loss : 0.035924, loss_ce: 0.012852
2021-12-12 23:49:24,284 iteration 1993 : loss : 0.037149, loss_ce: 0.014176
2021-12-12 23:49:25,815 iteration 1994 : loss : 0.041159, loss_ce: 0.017922
2021-12-12 23:49:27,259 iteration 1995 : loss : 0.033655, loss_ce: 0.012986
2021-12-12 23:49:28,764 iteration 1996 : loss : 0.038928, loss_ce: 0.016813
2021-12-12 23:49:30,185 iteration 1997 : loss : 0.034851, loss_ce: 0.014668
2021-12-12 23:49:31,665 iteration 1998 : loss : 0.035672, loss_ce: 0.013508
2021-12-12 23:49:33,174 iteration 1999 : loss : 0.039300, loss_ce: 0.016259
2021-12-12 23:49:34,643 iteration 2000 : loss : 0.043355, loss_ce: 0.020500
2021-12-12 23:49:36,064 iteration 2001 : loss : 0.038128, loss_ce: 0.012953
2021-12-12 23:49:37,586 iteration 2002 : loss : 0.034784, loss_ce: 0.015259
2021-12-12 23:49:39,001 iteration 2003 : loss : 0.039369, loss_ce: 0.011868
2021-12-12 23:49:40,493 iteration 2004 : loss : 0.039462, loss_ce: 0.019082
2021-12-12 23:49:41,921 iteration 2005 : loss : 0.038522, loss_ce: 0.018915
2021-12-12 23:49:43,377 iteration 2006 : loss : 0.041900, loss_ce: 0.015474
 30%|████████▌                    | 118/400 [54:25<2:03:50, 26.35s/it]2021-12-12 23:49:44,960 iteration 2007 : loss : 0.051682, loss_ce: 0.018049
2021-12-12 23:49:46,456 iteration 2008 : loss : 0.037279, loss_ce: 0.016076
2021-12-12 23:49:47,886 iteration 2009 : loss : 0.036436, loss_ce: 0.015748
2021-12-12 23:49:49,365 iteration 2010 : loss : 0.039314, loss_ce: 0.018499
2021-12-12 23:49:50,775 iteration 2011 : loss : 0.046075, loss_ce: 0.017403
2021-12-12 23:49:52,161 iteration 2012 : loss : 0.031151, loss_ce: 0.012284
2021-12-12 23:49:53,590 iteration 2013 : loss : 0.034471, loss_ce: 0.017586
2021-12-12 23:49:55,074 iteration 2014 : loss : 0.033985, loss_ce: 0.013873
2021-12-12 23:49:56,580 iteration 2015 : loss : 0.051035, loss_ce: 0.016482
2021-12-12 23:49:58,118 iteration 2016 : loss : 0.045393, loss_ce: 0.020049
2021-12-12 23:49:59,615 iteration 2017 : loss : 0.037617, loss_ce: 0.015143
2021-12-12 23:50:01,012 iteration 2018 : loss : 0.039495, loss_ce: 0.013385
2021-12-12 23:50:02,482 iteration 2019 : loss : 0.026967, loss_ce: 0.010446
2021-12-12 23:50:03,947 iteration 2020 : loss : 0.039421, loss_ce: 0.015551
2021-12-12 23:50:05,403 iteration 2021 : loss : 0.033929, loss_ce: 0.015289
2021-12-12 23:50:06,870 iteration 2022 : loss : 0.053980, loss_ce: 0.017963
2021-12-12 23:50:08,351 iteration 2023 : loss : 0.044697, loss_ce: 0.013004
 30%|████████▋                    | 119/400 [54:50<2:01:28, 25.94s/it]2021-12-12 23:50:09,885 iteration 2024 : loss : 0.039504, loss_ce: 0.018318
2021-12-12 23:50:11,521 iteration 2025 : loss : 0.058386, loss_ce: 0.019799
2021-12-12 23:50:12,961 iteration 2026 : loss : 0.033920, loss_ce: 0.011659
2021-12-12 23:50:14,461 iteration 2027 : loss : 0.035403, loss_ce: 0.012913
2021-12-12 23:50:15,831 iteration 2028 : loss : 0.033251, loss_ce: 0.015513
2021-12-12 23:50:17,232 iteration 2029 : loss : 0.045354, loss_ce: 0.014145
2021-12-12 23:50:18,717 iteration 2030 : loss : 0.039934, loss_ce: 0.013996
2021-12-12 23:50:20,207 iteration 2031 : loss : 0.042820, loss_ce: 0.016597
2021-12-12 23:50:21,681 iteration 2032 : loss : 0.041027, loss_ce: 0.019550
2021-12-12 23:50:23,048 iteration 2033 : loss : 0.029338, loss_ce: 0.013609
2021-12-12 23:50:24,476 iteration 2034 : loss : 0.030944, loss_ce: 0.010383
2021-12-12 23:50:25,976 iteration 2035 : loss : 0.045838, loss_ce: 0.016338
2021-12-12 23:50:27,437 iteration 2036 : loss : 0.035613, loss_ce: 0.016967
2021-12-12 23:50:28,854 iteration 2037 : loss : 0.034304, loss_ce: 0.014190
2021-12-12 23:50:30,415 iteration 2038 : loss : 0.073873, loss_ce: 0.020183
2021-12-12 23:50:31,920 iteration 2039 : loss : 0.042594, loss_ce: 0.017188
2021-12-12 23:50:31,921 Training Data Eval:
2021-12-12 23:50:39,465   Average segmentation loss on training set: 0.0241
2021-12-12 23:50:39,466 Validation Data Eval:
2021-12-12 23:50:42,060   Average segmentation loss on validation set: 0.0857
2021-12-12 23:50:43,596 iteration 2040 : loss : 0.038082, loss_ce: 0.017126
 30%|████████▋                    | 120/400 [55:25<2:14:04, 28.73s/it]2021-12-12 23:50:45,066 iteration 2041 : loss : 0.032686, loss_ce: 0.014901
2021-12-12 23:50:46,559 iteration 2042 : loss : 0.044275, loss_ce: 0.017744
2021-12-12 23:50:48,046 iteration 2043 : loss : 0.045284, loss_ce: 0.014719
2021-12-12 23:50:49,509 iteration 2044 : loss : 0.039726, loss_ce: 0.018352
2021-12-12 23:50:51,073 iteration 2045 : loss : 0.045204, loss_ce: 0.019138
2021-12-12 23:50:52,552 iteration 2046 : loss : 0.064510, loss_ce: 0.018506
2021-12-12 23:50:53,995 iteration 2047 : loss : 0.030007, loss_ce: 0.012804
2021-12-12 23:50:55,399 iteration 2048 : loss : 0.038469, loss_ce: 0.015210
2021-12-12 23:50:56,921 iteration 2049 : loss : 0.055522, loss_ce: 0.024533
2021-12-12 23:50:58,436 iteration 2050 : loss : 0.039953, loss_ce: 0.012857
2021-12-12 23:50:59,879 iteration 2051 : loss : 0.040267, loss_ce: 0.017339
2021-12-12 23:51:01,405 iteration 2052 : loss : 0.046013, loss_ce: 0.017253
2021-12-12 23:51:02,891 iteration 2053 : loss : 0.037264, loss_ce: 0.015452
2021-12-12 23:51:04,359 iteration 2054 : loss : 0.040408, loss_ce: 0.014440
2021-12-12 23:51:05,851 iteration 2055 : loss : 0.056809, loss_ce: 0.020221
2021-12-12 23:51:07,289 iteration 2056 : loss : 0.032534, loss_ce: 0.012530
2021-12-12 23:51:08,725 iteration 2057 : loss : 0.033598, loss_ce: 0.015079
 30%|████████▊                    | 121/400 [55:50<2:08:34, 27.65s/it]2021-12-12 23:51:10,227 iteration 2058 : loss : 0.039587, loss_ce: 0.018711
2021-12-12 23:51:11,759 iteration 2059 : loss : 0.043169, loss_ce: 0.015364
2021-12-12 23:51:13,305 iteration 2060 : loss : 0.043063, loss_ce: 0.015246
2021-12-12 23:51:14,771 iteration 2061 : loss : 0.038165, loss_ce: 0.017365
2021-12-12 23:51:16,191 iteration 2062 : loss : 0.044651, loss_ce: 0.016285
2021-12-12 23:51:17,838 iteration 2063 : loss : 0.043432, loss_ce: 0.016964
2021-12-12 23:51:19,319 iteration 2064 : loss : 0.037070, loss_ce: 0.014227
2021-12-12 23:51:20,861 iteration 2065 : loss : 0.048888, loss_ce: 0.015148
2021-12-12 23:51:22,321 iteration 2066 : loss : 0.035982, loss_ce: 0.015250
2021-12-12 23:51:23,845 iteration 2067 : loss : 0.055054, loss_ce: 0.017880
2021-12-12 23:51:25,268 iteration 2068 : loss : 0.028939, loss_ce: 0.010720
2021-12-12 23:51:26,745 iteration 2069 : loss : 0.040405, loss_ce: 0.018462
2021-12-12 23:51:28,270 iteration 2070 : loss : 0.041795, loss_ce: 0.018906
2021-12-12 23:51:29,705 iteration 2071 : loss : 0.032180, loss_ce: 0.013571
2021-12-12 23:51:31,130 iteration 2072 : loss : 0.035365, loss_ce: 0.016646
2021-12-12 23:51:32,650 iteration 2073 : loss : 0.043409, loss_ce: 0.017807
2021-12-12 23:51:34,055 iteration 2074 : loss : 0.043405, loss_ce: 0.013064
 30%|████████▊                    | 122/400 [56:16<2:04:52, 26.95s/it]2021-12-12 23:51:35,557 iteration 2075 : loss : 0.038529, loss_ce: 0.017372
2021-12-12 23:51:37,066 iteration 2076 : loss : 0.041011, loss_ce: 0.018097
2021-12-12 23:51:38,576 iteration 2077 : loss : 0.044502, loss_ce: 0.018928
2021-12-12 23:51:40,097 iteration 2078 : loss : 0.042138, loss_ce: 0.015275
2021-12-12 23:51:41,605 iteration 2079 : loss : 0.043172, loss_ce: 0.017173
2021-12-12 23:51:43,040 iteration 2080 : loss : 0.032905, loss_ce: 0.010625
2021-12-12 23:51:44,442 iteration 2081 : loss : 0.034693, loss_ce: 0.012251
2021-12-12 23:51:45,917 iteration 2082 : loss : 0.058933, loss_ce: 0.016569
2021-12-12 23:51:47,365 iteration 2083 : loss : 0.036537, loss_ce: 0.014359
2021-12-12 23:51:48,768 iteration 2084 : loss : 0.039421, loss_ce: 0.018472
2021-12-12 23:51:50,256 iteration 2085 : loss : 0.057866, loss_ce: 0.012342
2021-12-12 23:51:51,834 iteration 2086 : loss : 0.038470, loss_ce: 0.013507
2021-12-12 23:51:53,231 iteration 2087 : loss : 0.039686, loss_ce: 0.013329
2021-12-12 23:51:54,684 iteration 2088 : loss : 0.034035, loss_ce: 0.013165
2021-12-12 23:51:56,170 iteration 2089 : loss : 0.038960, loss_ce: 0.015609
2021-12-12 23:51:57,643 iteration 2090 : loss : 0.041031, loss_ce: 0.018652
2021-12-12 23:51:59,204 iteration 2091 : loss : 0.042872, loss_ce: 0.017204
 31%|████████▉                    | 123/400 [56:41<2:01:56, 26.41s/it]2021-12-12 23:52:00,697 iteration 2092 : loss : 0.037970, loss_ce: 0.012834
2021-12-12 23:52:02,102 iteration 2093 : loss : 0.027180, loss_ce: 0.011385
2021-12-12 23:52:03,604 iteration 2094 : loss : 0.041581, loss_ce: 0.016061
2021-12-12 23:52:05,242 iteration 2095 : loss : 0.057222, loss_ce: 0.022111
2021-12-12 23:52:06,699 iteration 2096 : loss : 0.034731, loss_ce: 0.014875
2021-12-12 23:52:08,155 iteration 2097 : loss : 0.051028, loss_ce: 0.015583
2021-12-12 23:52:09,561 iteration 2098 : loss : 0.033218, loss_ce: 0.013222
2021-12-12 23:52:11,015 iteration 2099 : loss : 0.030095, loss_ce: 0.013016
2021-12-12 23:52:12,526 iteration 2100 : loss : 0.045974, loss_ce: 0.017416
2021-12-12 23:52:13,903 iteration 2101 : loss : 0.046079, loss_ce: 0.017566
2021-12-12 23:52:15,402 iteration 2102 : loss : 0.042883, loss_ce: 0.019037
2021-12-12 23:52:16,828 iteration 2103 : loss : 0.031234, loss_ce: 0.016078
2021-12-12 23:52:18,212 iteration 2104 : loss : 0.035829, loss_ce: 0.012113
2021-12-12 23:52:19,688 iteration 2105 : loss : 0.051488, loss_ce: 0.026646
2021-12-12 23:52:21,166 iteration 2106 : loss : 0.037338, loss_ce: 0.015027
2021-12-12 23:52:22,594 iteration 2107 : loss : 0.035789, loss_ce: 0.011911
2021-12-12 23:52:24,004 iteration 2108 : loss : 0.035135, loss_ce: 0.014193
 31%|████████▉                    | 124/400 [57:05<1:59:16, 25.93s/it]2021-12-12 23:52:25,515 iteration 2109 : loss : 0.061867, loss_ce: 0.018086
2021-12-12 23:52:27,001 iteration 2110 : loss : 0.049950, loss_ce: 0.018075
2021-12-12 23:52:28,529 iteration 2111 : loss : 0.043597, loss_ce: 0.015744
2021-12-12 23:52:30,117 iteration 2112 : loss : 0.037272, loss_ce: 0.015552
2021-12-12 23:52:31,641 iteration 2113 : loss : 0.041769, loss_ce: 0.014786
2021-12-12 23:52:33,145 iteration 2114 : loss : 0.039929, loss_ce: 0.014757
2021-12-12 23:52:34,577 iteration 2115 : loss : 0.035656, loss_ce: 0.012464
2021-12-12 23:52:36,003 iteration 2116 : loss : 0.042121, loss_ce: 0.014314
2021-12-12 23:52:37,567 iteration 2117 : loss : 0.042793, loss_ce: 0.014213
2021-12-12 23:52:39,053 iteration 2118 : loss : 0.041726, loss_ce: 0.016299
2021-12-12 23:52:40,644 iteration 2119 : loss : 0.042542, loss_ce: 0.018428
2021-12-12 23:52:42,194 iteration 2120 : loss : 0.035643, loss_ce: 0.018888
2021-12-12 23:52:43,729 iteration 2121 : loss : 0.057726, loss_ce: 0.026172
2021-12-12 23:52:45,253 iteration 2122 : loss : 0.047845, loss_ce: 0.025711
2021-12-12 23:52:46,664 iteration 2123 : loss : 0.038150, loss_ce: 0.013322
2021-12-12 23:52:48,217 iteration 2124 : loss : 0.041148, loss_ce: 0.016407
2021-12-12 23:52:48,217 Training Data Eval:
2021-12-12 23:52:55,745   Average segmentation loss on training set: 0.0280
2021-12-12 23:52:55,746 Validation Data Eval:
2021-12-12 23:52:58,347   Average segmentation loss on validation set: 0.0874
2021-12-12 23:52:59,796 iteration 2125 : loss : 0.039253, loss_ce: 0.018620
 31%|█████████                    | 125/400 [57:41<2:12:24, 28.89s/it]2021-12-12 23:53:01,357 iteration 2126 : loss : 0.051563, loss_ce: 0.016307
2021-12-12 23:53:02,769 iteration 2127 : loss : 0.032942, loss_ce: 0.013851
2021-12-12 23:53:04,167 iteration 2128 : loss : 0.036177, loss_ce: 0.015100
2021-12-12 23:53:05,703 iteration 2129 : loss : 0.043058, loss_ce: 0.016556
2021-12-12 23:53:07,163 iteration 2130 : loss : 0.036744, loss_ce: 0.015151
2021-12-12 23:53:08,577 iteration 2131 : loss : 0.027941, loss_ce: 0.010853
2021-12-12 23:53:10,071 iteration 2132 : loss : 0.040668, loss_ce: 0.012733
2021-12-12 23:53:11,539 iteration 2133 : loss : 0.029269, loss_ce: 0.012267
2021-12-12 23:53:13,081 iteration 2134 : loss : 0.037951, loss_ce: 0.014946
2021-12-12 23:53:14,491 iteration 2135 : loss : 0.040965, loss_ce: 0.012735
2021-12-12 23:53:16,016 iteration 2136 : loss : 0.050890, loss_ce: 0.020288
2021-12-12 23:53:17,476 iteration 2137 : loss : 0.038276, loss_ce: 0.017011
2021-12-12 23:53:19,026 iteration 2138 : loss : 0.041726, loss_ce: 0.011720
2021-12-12 23:53:20,493 iteration 2139 : loss : 0.028454, loss_ce: 0.014057
2021-12-12 23:53:22,010 iteration 2140 : loss : 0.046008, loss_ce: 0.027834
2021-12-12 23:53:23,507 iteration 2141 : loss : 0.038099, loss_ce: 0.013349
2021-12-12 23:53:25,017 iteration 2142 : loss : 0.050061, loss_ce: 0.015319
 32%|█████████▏                   | 126/400 [58:06<2:06:53, 27.79s/it]2021-12-12 23:53:26,557 iteration 2143 : loss : 0.038867, loss_ce: 0.019753
2021-12-12 23:53:28,050 iteration 2144 : loss : 0.039528, loss_ce: 0.016985
2021-12-12 23:53:29,525 iteration 2145 : loss : 0.037905, loss_ce: 0.014795
2021-12-12 23:53:30,967 iteration 2146 : loss : 0.032007, loss_ce: 0.012527
2021-12-12 23:53:32,383 iteration 2147 : loss : 0.034063, loss_ce: 0.012326
2021-12-12 23:53:33,837 iteration 2148 : loss : 0.031849, loss_ce: 0.012778
2021-12-12 23:53:35,372 iteration 2149 : loss : 0.063521, loss_ce: 0.019462
2021-12-12 23:53:36,807 iteration 2150 : loss : 0.033871, loss_ce: 0.014314
2021-12-12 23:53:38,273 iteration 2151 : loss : 0.033532, loss_ce: 0.013061
2021-12-12 23:53:39,688 iteration 2152 : loss : 0.035063, loss_ce: 0.016338
2021-12-12 23:53:41,151 iteration 2153 : loss : 0.039973, loss_ce: 0.013827
2021-12-12 23:53:42,634 iteration 2154 : loss : 0.028009, loss_ce: 0.010666
2021-12-12 23:53:44,131 iteration 2155 : loss : 0.038543, loss_ce: 0.018273
2021-12-12 23:53:45,543 iteration 2156 : loss : 0.034007, loss_ce: 0.014064
2021-12-12 23:53:47,109 iteration 2157 : loss : 0.039097, loss_ce: 0.015311
2021-12-12 23:53:48,655 iteration 2158 : loss : 0.039126, loss_ce: 0.012791
2021-12-12 23:53:50,158 iteration 2159 : loss : 0.043537, loss_ce: 0.017571
 32%|█████████▏                   | 127/400 [58:32<2:02:48, 26.99s/it]2021-12-12 23:53:51,680 iteration 2160 : loss : 0.037346, loss_ce: 0.013836
2021-12-12 23:53:53,247 iteration 2161 : loss : 0.055379, loss_ce: 0.025131
2021-12-12 23:53:54,797 iteration 2162 : loss : 0.042127, loss_ce: 0.017915
2021-12-12 23:53:56,215 iteration 2163 : loss : 0.037738, loss_ce: 0.014272
2021-12-12 23:53:57,735 iteration 2164 : loss : 0.037348, loss_ce: 0.013458
2021-12-12 23:53:59,246 iteration 2165 : loss : 0.032824, loss_ce: 0.014297
2021-12-12 23:54:00,761 iteration 2166 : loss : 0.044510, loss_ce: 0.012486
2021-12-12 23:54:02,295 iteration 2167 : loss : 0.042496, loss_ce: 0.013506
2021-12-12 23:54:03,780 iteration 2168 : loss : 0.035301, loss_ce: 0.014964
2021-12-12 23:54:05,258 iteration 2169 : loss : 0.034607, loss_ce: 0.014812
2021-12-12 23:54:06,698 iteration 2170 : loss : 0.047871, loss_ce: 0.022678
2021-12-12 23:54:08,214 iteration 2171 : loss : 0.047803, loss_ce: 0.016555
2021-12-12 23:54:09,798 iteration 2172 : loss : 0.046677, loss_ce: 0.014378
2021-12-12 23:54:11,229 iteration 2173 : loss : 0.049477, loss_ce: 0.017006
2021-12-12 23:54:12,616 iteration 2174 : loss : 0.032225, loss_ce: 0.015680
2021-12-12 23:54:14,032 iteration 2175 : loss : 0.040566, loss_ce: 0.015255
2021-12-12 23:54:15,606 iteration 2176 : loss : 0.052360, loss_ce: 0.018575
 32%|█████████▎                   | 128/400 [58:57<2:00:16, 26.53s/it]2021-12-12 23:54:17,149 iteration 2177 : loss : 0.036958, loss_ce: 0.013658
2021-12-12 23:54:18,683 iteration 2178 : loss : 0.040906, loss_ce: 0.017500
2021-12-12 23:54:20,135 iteration 2179 : loss : 0.037734, loss_ce: 0.018590
2021-12-12 23:54:21,592 iteration 2180 : loss : 0.032253, loss_ce: 0.012719
2021-12-12 23:54:23,101 iteration 2181 : loss : 0.042228, loss_ce: 0.020000
2021-12-12 23:54:24,554 iteration 2182 : loss : 0.045226, loss_ce: 0.013492
2021-12-12 23:54:25,961 iteration 2183 : loss : 0.034467, loss_ce: 0.015094
2021-12-12 23:54:27,497 iteration 2184 : loss : 0.037191, loss_ce: 0.013279
2021-12-12 23:54:28,936 iteration 2185 : loss : 0.030211, loss_ce: 0.012353
2021-12-12 23:54:30,385 iteration 2186 : loss : 0.041917, loss_ce: 0.014815
2021-12-12 23:54:31,848 iteration 2187 : loss : 0.028135, loss_ce: 0.011168
2021-12-12 23:54:33,281 iteration 2188 : loss : 0.038787, loss_ce: 0.011398
2021-12-12 23:54:34,820 iteration 2189 : loss : 0.034539, loss_ce: 0.013627
2021-12-12 23:54:36,286 iteration 2190 : loss : 0.032917, loss_ce: 0.011688
2021-12-12 23:54:37,782 iteration 2191 : loss : 0.076030, loss_ce: 0.025363
2021-12-12 23:54:39,213 iteration 2192 : loss : 0.033269, loss_ce: 0.011064
2021-12-12 23:54:40,689 iteration 2193 : loss : 0.045742, loss_ce: 0.019194
 32%|█████████▎                   | 129/400 [59:22<1:57:51, 26.10s/it]2021-12-12 23:54:42,246 iteration 2194 : loss : 0.043489, loss_ce: 0.022227
2021-12-12 23:54:43,701 iteration 2195 : loss : 0.037527, loss_ce: 0.014970
2021-12-12 23:54:45,160 iteration 2196 : loss : 0.033913, loss_ce: 0.012975
2021-12-12 23:54:46,658 iteration 2197 : loss : 0.038126, loss_ce: 0.018282
2021-12-12 23:54:48,152 iteration 2198 : loss : 0.040022, loss_ce: 0.020838
2021-12-12 23:54:49,633 iteration 2199 : loss : 0.046972, loss_ce: 0.021875
2021-12-12 23:54:51,089 iteration 2200 : loss : 0.035250, loss_ce: 0.013957
2021-12-12 23:54:52,517 iteration 2201 : loss : 0.034238, loss_ce: 0.013829
2021-12-12 23:54:54,039 iteration 2202 : loss : 0.067559, loss_ce: 0.016430
2021-12-12 23:54:55,563 iteration 2203 : loss : 0.037212, loss_ce: 0.019426
2021-12-12 23:54:57,019 iteration 2204 : loss : 0.029690, loss_ce: 0.014270
2021-12-12 23:54:58,404 iteration 2205 : loss : 0.027927, loss_ce: 0.012094
2021-12-12 23:54:59,793 iteration 2206 : loss : 0.036355, loss_ce: 0.011397
2021-12-12 23:55:01,219 iteration 2207 : loss : 0.041146, loss_ce: 0.014681
2021-12-12 23:55:02,707 iteration 2208 : loss : 0.038647, loss_ce: 0.011767
2021-12-12 23:55:04,157 iteration 2209 : loss : 0.050500, loss_ce: 0.017132
2021-12-12 23:55:04,158 Training Data Eval:
2021-12-12 23:55:11,698   Average segmentation loss on training set: 0.0230
2021-12-12 23:55:11,699 Validation Data Eval:
2021-12-12 23:55:14,296   Average segmentation loss on validation set: 0.0846
2021-12-12 23:55:15,775 iteration 2210 : loss : 0.045879, loss_ce: 0.015289
 32%|█████████▍                   | 130/400 [59:57<2:09:34, 28.79s/it]2021-12-12 23:55:17,325 iteration 2211 : loss : 0.044823, loss_ce: 0.014731
2021-12-12 23:55:18,823 iteration 2212 : loss : 0.041058, loss_ce: 0.018630
2021-12-12 23:55:20,325 iteration 2213 : loss : 0.040689, loss_ce: 0.015959
2021-12-12 23:55:21,828 iteration 2214 : loss : 0.030288, loss_ce: 0.011596
2021-12-12 23:55:23,361 iteration 2215 : loss : 0.049564, loss_ce: 0.021778
2021-12-12 23:55:24,764 iteration 2216 : loss : 0.035122, loss_ce: 0.011495
2021-12-12 23:55:26,290 iteration 2217 : loss : 0.047926, loss_ce: 0.018455
2021-12-12 23:55:27,714 iteration 2218 : loss : 0.034257, loss_ce: 0.013714
2021-12-12 23:55:29,246 iteration 2219 : loss : 0.035534, loss_ce: 0.013436
2021-12-12 23:55:30,621 iteration 2220 : loss : 0.038155, loss_ce: 0.013033
2021-12-12 23:55:32,054 iteration 2221 : loss : 0.035705, loss_ce: 0.013096
2021-12-12 23:55:33,565 iteration 2222 : loss : 0.038535, loss_ce: 0.015481
2021-12-12 23:55:35,050 iteration 2223 : loss : 0.050190, loss_ce: 0.017416
2021-12-12 23:55:36,590 iteration 2224 : loss : 0.047077, loss_ce: 0.020645
2021-12-12 23:55:38,004 iteration 2225 : loss : 0.027627, loss_ce: 0.010922
2021-12-12 23:55:39,552 iteration 2226 : loss : 0.040614, loss_ce: 0.019500
2021-12-12 23:55:41,005 iteration 2227 : loss : 0.037685, loss_ce: 0.014603
 33%|████████▊                  | 131/400 [1:00:22<2:04:17, 27.72s/it]2021-12-12 23:55:42,571 iteration 2228 : loss : 0.051137, loss_ce: 0.023522
2021-12-12 23:55:44,053 iteration 2229 : loss : 0.045935, loss_ce: 0.018749
2021-12-12 23:55:45,576 iteration 2230 : loss : 0.040089, loss_ce: 0.013842
2021-12-12 23:55:46,953 iteration 2231 : loss : 0.027070, loss_ce: 0.010827
2021-12-12 23:55:48,378 iteration 2232 : loss : 0.056333, loss_ce: 0.022037
2021-12-12 23:55:49,821 iteration 2233 : loss : 0.035506, loss_ce: 0.013075
2021-12-12 23:55:51,281 iteration 2234 : loss : 0.037818, loss_ce: 0.014137
2021-12-12 23:55:52,727 iteration 2235 : loss : 0.041365, loss_ce: 0.009901
2021-12-12 23:55:54,332 iteration 2236 : loss : 0.052656, loss_ce: 0.021555
2021-12-12 23:55:55,808 iteration 2237 : loss : 0.032282, loss_ce: 0.014236
2021-12-12 23:55:57,294 iteration 2238 : loss : 0.057248, loss_ce: 0.027734
2021-12-12 23:55:58,768 iteration 2239 : loss : 0.042347, loss_ce: 0.014865
2021-12-12 23:56:00,285 iteration 2240 : loss : 0.050492, loss_ce: 0.018369
2021-12-12 23:56:01,826 iteration 2241 : loss : 0.050432, loss_ce: 0.015313
2021-12-12 23:56:03,374 iteration 2242 : loss : 0.031713, loss_ce: 0.011974
2021-12-12 23:56:04,955 iteration 2243 : loss : 0.039538, loss_ce: 0.012705
2021-12-12 23:56:06,430 iteration 2244 : loss : 0.036887, loss_ce: 0.016872
 33%|████████▉                  | 132/400 [1:00:48<2:00:44, 27.03s/it]2021-12-12 23:56:08,042 iteration 2245 : loss : 0.052639, loss_ce: 0.020000
2021-12-12 23:56:09,504 iteration 2246 : loss : 0.028276, loss_ce: 0.011289
2021-12-12 23:56:11,075 iteration 2247 : loss : 0.074217, loss_ce: 0.020201
2021-12-12 23:56:12,581 iteration 2248 : loss : 0.043150, loss_ce: 0.017550
2021-12-12 23:56:14,072 iteration 2249 : loss : 0.044703, loss_ce: 0.017305
2021-12-12 23:56:15,555 iteration 2250 : loss : 0.043592, loss_ce: 0.018023
2021-12-12 23:56:16,957 iteration 2251 : loss : 0.035788, loss_ce: 0.012385
2021-12-12 23:56:18,535 iteration 2252 : loss : 0.049913, loss_ce: 0.017422
2021-12-12 23:56:20,100 iteration 2253 : loss : 0.043789, loss_ce: 0.017509
2021-12-12 23:56:21,580 iteration 2254 : loss : 0.041449, loss_ce: 0.016936
2021-12-12 23:56:23,019 iteration 2255 : loss : 0.044689, loss_ce: 0.015199
2021-12-12 23:56:24,514 iteration 2256 : loss : 0.031033, loss_ce: 0.012443
2021-12-12 23:56:25,978 iteration 2257 : loss : 0.032110, loss_ce: 0.012579
2021-12-12 23:56:27,384 iteration 2258 : loss : 0.031089, loss_ce: 0.013395
2021-12-12 23:56:28,934 iteration 2259 : loss : 0.034254, loss_ce: 0.013482
2021-12-12 23:56:30,377 iteration 2260 : loss : 0.034120, loss_ce: 0.013100
2021-12-12 23:56:31,872 iteration 2261 : loss : 0.041658, loss_ce: 0.015703
 33%|████████▉                  | 133/400 [1:01:13<1:58:10, 26.56s/it]2021-12-12 23:56:33,415 iteration 2262 : loss : 0.043793, loss_ce: 0.019011
2021-12-12 23:56:34,896 iteration 2263 : loss : 0.037149, loss_ce: 0.014874
2021-12-12 23:56:36,423 iteration 2264 : loss : 0.048271, loss_ce: 0.020643
2021-12-12 23:56:37,893 iteration 2265 : loss : 0.036232, loss_ce: 0.013118
2021-12-12 23:56:39,354 iteration 2266 : loss : 0.041284, loss_ce: 0.012040
2021-12-12 23:56:40,747 iteration 2267 : loss : 0.029703, loss_ce: 0.012131
2021-12-12 23:56:42,198 iteration 2268 : loss : 0.034388, loss_ce: 0.015139
2021-12-12 23:56:43,640 iteration 2269 : loss : 0.037282, loss_ce: 0.017226
2021-12-12 23:56:45,044 iteration 2270 : loss : 0.024816, loss_ce: 0.009677
2021-12-12 23:56:46,507 iteration 2271 : loss : 0.044047, loss_ce: 0.018467
2021-12-12 23:56:48,035 iteration 2272 : loss : 0.051571, loss_ce: 0.020093
2021-12-12 23:56:49,568 iteration 2273 : loss : 0.059640, loss_ce: 0.017895
2021-12-12 23:56:51,038 iteration 2274 : loss : 0.039808, loss_ce: 0.017074
2021-12-12 23:56:52,501 iteration 2275 : loss : 0.044360, loss_ce: 0.016644
2021-12-12 23:56:53,917 iteration 2276 : loss : 0.037792, loss_ce: 0.016008
2021-12-12 23:56:55,367 iteration 2277 : loss : 0.040804, loss_ce: 0.013124
2021-12-12 23:56:56,858 iteration 2278 : loss : 0.038376, loss_ce: 0.013440
 34%|█████████                  | 134/400 [1:01:38<1:55:38, 26.09s/it]2021-12-12 23:56:58,305 iteration 2279 : loss : 0.031654, loss_ce: 0.011803
2021-12-12 23:56:59,721 iteration 2280 : loss : 0.037504, loss_ce: 0.016374
2021-12-12 23:57:01,182 iteration 2281 : loss : 0.047177, loss_ce: 0.015506
2021-12-12 23:57:02,583 iteration 2282 : loss : 0.041432, loss_ce: 0.014217
2021-12-12 23:57:04,060 iteration 2283 : loss : 0.046022, loss_ce: 0.014014
2021-12-12 23:57:05,451 iteration 2284 : loss : 0.039247, loss_ce: 0.016283
2021-12-12 23:57:06,954 iteration 2285 : loss : 0.038650, loss_ce: 0.015871
2021-12-12 23:57:08,395 iteration 2286 : loss : 0.043891, loss_ce: 0.019222
2021-12-12 23:57:09,850 iteration 2287 : loss : 0.029090, loss_ce: 0.009077
2021-12-12 23:57:11,312 iteration 2288 : loss : 0.063980, loss_ce: 0.013038
2021-12-12 23:57:12,796 iteration 2289 : loss : 0.032346, loss_ce: 0.010841
2021-12-12 23:57:14,274 iteration 2290 : loss : 0.035575, loss_ce: 0.014573
2021-12-12 23:57:15,841 iteration 2291 : loss : 0.054580, loss_ce: 0.022318
2021-12-12 23:57:17,347 iteration 2292 : loss : 0.041272, loss_ce: 0.014848
2021-12-12 23:57:18,828 iteration 2293 : loss : 0.049511, loss_ce: 0.018277
2021-12-12 23:57:20,277 iteration 2294 : loss : 0.043860, loss_ce: 0.020838
2021-12-12 23:57:20,278 Training Data Eval:
2021-12-12 23:57:27,802   Average segmentation loss on training set: 0.0250
2021-12-12 23:57:27,803 Validation Data Eval:
2021-12-12 23:57:30,401   Average segmentation loss on validation set: 0.0838
2021-12-12 23:57:36,736 Found new lowest validation loss at iteration 2294! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/TU_3seeds/TU_SGD_best_val_loss_seed2.pth
2021-12-12 23:57:38,125 iteration 2295 : loss : 0.048550, loss_ce: 0.014753
 34%|█████████                  | 135/400 [1:02:20<2:15:19, 30.64s/it]2021-12-12 23:57:39,471 iteration 2296 : loss : 0.029389, loss_ce: 0.012554
2021-12-12 23:57:40,892 iteration 2297 : loss : 0.033700, loss_ce: 0.012037
2021-12-12 23:57:42,265 iteration 2298 : loss : 0.041228, loss_ce: 0.014528
2021-12-12 23:57:43,657 iteration 2299 : loss : 0.043307, loss_ce: 0.013304
2021-12-12 23:57:45,024 iteration 2300 : loss : 0.031095, loss_ce: 0.012673
2021-12-12 23:57:46,491 iteration 2301 : loss : 0.033664, loss_ce: 0.013289
2021-12-12 23:57:48,013 iteration 2302 : loss : 0.037452, loss_ce: 0.013419
2021-12-12 23:57:49,521 iteration 2303 : loss : 0.050964, loss_ce: 0.016678
2021-12-12 23:57:51,023 iteration 2304 : loss : 0.033068, loss_ce: 0.014302
2021-12-12 23:57:52,483 iteration 2305 : loss : 0.034657, loss_ce: 0.015592
2021-12-12 23:57:53,924 iteration 2306 : loss : 0.043539, loss_ce: 0.015964
2021-12-12 23:57:55,461 iteration 2307 : loss : 0.038455, loss_ce: 0.016013
2021-12-12 23:57:56,892 iteration 2308 : loss : 0.030909, loss_ce: 0.012969
2021-12-12 23:57:58,410 iteration 2309 : loss : 0.038879, loss_ce: 0.016261
2021-12-12 23:57:59,907 iteration 2310 : loss : 0.053234, loss_ce: 0.019144
2021-12-12 23:58:01,340 iteration 2311 : loss : 0.035883, loss_ce: 0.013294
2021-12-12 23:58:02,744 iteration 2312 : loss : 0.041391, loss_ce: 0.014332
 34%|█████████▏                 | 136/400 [1:02:44<2:06:52, 28.84s/it]2021-12-12 23:58:04,251 iteration 2313 : loss : 0.045392, loss_ce: 0.014707
2021-12-12 23:58:05,754 iteration 2314 : loss : 0.035609, loss_ce: 0.011790
2021-12-12 23:58:07,315 iteration 2315 : loss : 0.037701, loss_ce: 0.011800
2021-12-12 23:58:08,716 iteration 2316 : loss : 0.038442, loss_ce: 0.013845
2021-12-12 23:58:10,274 iteration 2317 : loss : 0.051467, loss_ce: 0.015962
2021-12-12 23:58:11,789 iteration 2318 : loss : 0.035222, loss_ce: 0.014331
2021-12-12 23:58:13,295 iteration 2319 : loss : 0.037806, loss_ce: 0.015499
2021-12-12 23:58:14,838 iteration 2320 : loss : 0.044811, loss_ce: 0.023823
2021-12-12 23:58:16,276 iteration 2321 : loss : 0.038326, loss_ce: 0.012421
2021-12-12 23:58:17,755 iteration 2322 : loss : 0.038635, loss_ce: 0.016571
2021-12-12 23:58:19,234 iteration 2323 : loss : 0.034549, loss_ce: 0.016389
2021-12-12 23:58:20,753 iteration 2324 : loss : 0.040199, loss_ce: 0.013361
2021-12-12 23:58:22,215 iteration 2325 : loss : 0.033855, loss_ce: 0.014297
2021-12-12 23:58:23,712 iteration 2326 : loss : 0.033331, loss_ce: 0.015535
2021-12-12 23:58:25,182 iteration 2327 : loss : 0.034444, loss_ce: 0.013097
2021-12-12 23:58:26,690 iteration 2328 : loss : 0.048123, loss_ce: 0.023042
2021-12-12 23:58:28,128 iteration 2329 : loss : 0.031486, loss_ce: 0.012486
 34%|█████████▏                 | 137/400 [1:03:10<2:01:51, 27.80s/it]2021-12-12 23:58:29,637 iteration 2330 : loss : 0.032349, loss_ce: 0.011435
2021-12-12 23:58:31,118 iteration 2331 : loss : 0.041463, loss_ce: 0.019034
2021-12-12 23:58:32,657 iteration 2332 : loss : 0.052538, loss_ce: 0.020304
2021-12-12 23:58:34,212 iteration 2333 : loss : 0.042333, loss_ce: 0.021652
2021-12-12 23:58:35,683 iteration 2334 : loss : 0.028086, loss_ce: 0.013198
2021-12-12 23:58:37,160 iteration 2335 : loss : 0.039120, loss_ce: 0.012027
2021-12-12 23:58:38,698 iteration 2336 : loss : 0.054328, loss_ce: 0.014019
2021-12-12 23:58:40,208 iteration 2337 : loss : 0.032625, loss_ce: 0.014875
2021-12-12 23:58:41,677 iteration 2338 : loss : 0.040285, loss_ce: 0.013971
2021-12-12 23:58:43,187 iteration 2339 : loss : 0.039150, loss_ce: 0.013459
2021-12-12 23:58:44,742 iteration 2340 : loss : 0.048972, loss_ce: 0.021613
2021-12-12 23:58:46,155 iteration 2341 : loss : 0.030967, loss_ce: 0.009016
2021-12-12 23:58:47,640 iteration 2342 : loss : 0.032908, loss_ce: 0.014045
2021-12-12 23:58:49,195 iteration 2343 : loss : 0.062133, loss_ce: 0.027090
2021-12-12 23:58:50,713 iteration 2344 : loss : 0.037091, loss_ce: 0.015725
2021-12-12 23:58:52,261 iteration 2345 : loss : 0.048573, loss_ce: 0.015548
2021-12-12 23:58:53,762 iteration 2346 : loss : 0.034728, loss_ce: 0.015152
 34%|█████████▎                 | 138/400 [1:03:35<1:58:32, 27.15s/it]2021-12-12 23:58:55,295 iteration 2347 : loss : 0.031969, loss_ce: 0.012243
2021-12-12 23:58:56,768 iteration 2348 : loss : 0.044124, loss_ce: 0.015763
2021-12-12 23:58:58,311 iteration 2349 : loss : 0.038339, loss_ce: 0.015248
2021-12-12 23:58:59,781 iteration 2350 : loss : 0.043578, loss_ce: 0.016094
2021-12-12 23:59:01,282 iteration 2351 : loss : 0.066159, loss_ce: 0.013530
2021-12-12 23:59:02,779 iteration 2352 : loss : 0.031075, loss_ce: 0.010673
2021-12-12 23:59:04,320 iteration 2353 : loss : 0.044705, loss_ce: 0.019540
2021-12-12 23:59:05,872 iteration 2354 : loss : 0.039000, loss_ce: 0.015360
2021-12-12 23:59:07,281 iteration 2355 : loss : 0.031171, loss_ce: 0.012139
2021-12-12 23:59:08,765 iteration 2356 : loss : 0.035691, loss_ce: 0.014762
2021-12-12 23:59:10,247 iteration 2357 : loss : 0.042304, loss_ce: 0.014612
2021-12-12 23:59:11,764 iteration 2358 : loss : 0.033637, loss_ce: 0.014931
2021-12-12 23:59:13,374 iteration 2359 : loss : 0.040511, loss_ce: 0.017731
2021-12-12 23:59:14,833 iteration 2360 : loss : 0.030295, loss_ce: 0.012277
2021-12-12 23:59:16,351 iteration 2361 : loss : 0.043977, loss_ce: 0.013183
2021-12-12 23:59:17,948 iteration 2362 : loss : 0.048049, loss_ce: 0.018817
2021-12-12 23:59:19,370 iteration 2363 : loss : 0.034147, loss_ce: 0.016139
 35%|█████████▍                 | 139/400 [1:04:01<1:56:05, 26.69s/it]2021-12-12 23:59:20,815 iteration 2364 : loss : 0.042234, loss_ce: 0.010388
2021-12-12 23:59:22,250 iteration 2365 : loss : 0.046534, loss_ce: 0.011579
2021-12-12 23:59:23,752 iteration 2366 : loss : 0.040805, loss_ce: 0.017234
2021-12-12 23:59:25,216 iteration 2367 : loss : 0.045674, loss_ce: 0.022737
2021-12-12 23:59:26,666 iteration 2368 : loss : 0.033584, loss_ce: 0.012845
2021-12-12 23:59:28,168 iteration 2369 : loss : 0.038649, loss_ce: 0.015231
2021-12-12 23:59:29,563 iteration 2370 : loss : 0.030900, loss_ce: 0.011587
2021-12-12 23:59:31,088 iteration 2371 : loss : 0.038527, loss_ce: 0.014753
2021-12-12 23:59:32,553 iteration 2372 : loss : 0.033411, loss_ce: 0.014283
2021-12-12 23:59:33,983 iteration 2373 : loss : 0.034012, loss_ce: 0.014103
2021-12-12 23:59:35,427 iteration 2374 : loss : 0.034017, loss_ce: 0.013010
2021-12-12 23:59:36,925 iteration 2375 : loss : 0.049908, loss_ce: 0.015441
2021-12-12 23:59:38,444 iteration 2376 : loss : 0.031046, loss_ce: 0.012250
2021-12-12 23:59:39,888 iteration 2377 : loss : 0.034290, loss_ce: 0.012713
2021-12-12 23:59:41,339 iteration 2378 : loss : 0.029796, loss_ce: 0.011534
2021-12-12 23:59:42,816 iteration 2379 : loss : 0.038745, loss_ce: 0.019809
2021-12-12 23:59:42,816 Training Data Eval:
2021-12-12 23:59:50,348   Average segmentation loss on training set: 0.0229
2021-12-12 23:59:50,349 Validation Data Eval:
2021-12-12 23:59:52,949   Average segmentation loss on validation set: 0.0813
2021-12-12 23:59:59,280 Found new lowest validation loss at iteration 2379! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/TU_3seeds/TU_SGD_best_val_loss_seed2.pth
2021-12-13 00:00:00,596 iteration 2380 : loss : 0.029819, loss_ce: 0.015040
 35%|█████████▍                 | 140/400 [1:04:42<2:14:32, 31.05s/it]2021-12-13 00:00:02,090 iteration 2381 : loss : 0.055437, loss_ce: 0.015298
2021-12-13 00:00:03,468 iteration 2382 : loss : 0.034593, loss_ce: 0.013164
2021-12-13 00:00:04,816 iteration 2383 : loss : 0.037667, loss_ce: 0.016801
2021-12-13 00:00:06,120 iteration 2384 : loss : 0.030069, loss_ce: 0.011623
2021-12-13 00:00:07,474 iteration 2385 : loss : 0.041174, loss_ce: 0.017204
2021-12-13 00:00:08,880 iteration 2386 : loss : 0.046494, loss_ce: 0.012875
2021-12-13 00:00:10,327 iteration 2387 : loss : 0.033390, loss_ce: 0.011849
2021-12-13 00:00:11,792 iteration 2388 : loss : 0.042765, loss_ce: 0.021440
2021-12-13 00:00:13,270 iteration 2389 : loss : 0.032871, loss_ce: 0.012142
2021-12-13 00:00:14,711 iteration 2390 : loss : 0.034527, loss_ce: 0.013683
2021-12-13 00:00:16,108 iteration 2391 : loss : 0.036796, loss_ce: 0.013391
2021-12-13 00:00:17,714 iteration 2392 : loss : 0.042849, loss_ce: 0.010237
2021-12-13 00:00:19,246 iteration 2393 : loss : 0.048182, loss_ce: 0.017613
2021-12-13 00:00:20,730 iteration 2394 : loss : 0.053383, loss_ce: 0.021640
2021-12-13 00:00:22,266 iteration 2395 : loss : 0.041538, loss_ce: 0.016924
2021-12-13 00:00:23,691 iteration 2396 : loss : 0.032878, loss_ce: 0.013704
2021-12-13 00:00:25,223 iteration 2397 : loss : 0.042374, loss_ce: 0.022414
 35%|█████████▌                 | 141/400 [1:05:07<2:05:42, 29.12s/it]2021-12-13 00:00:26,708 iteration 2398 : loss : 0.029542, loss_ce: 0.013959
2021-12-13 00:00:28,263 iteration 2399 : loss : 0.038033, loss_ce: 0.014716
2021-12-13 00:00:29,721 iteration 2400 : loss : 0.039379, loss_ce: 0.015562
2021-12-13 00:00:31,321 iteration 2401 : loss : 0.050195, loss_ce: 0.016100
2021-12-13 00:00:32,792 iteration 2402 : loss : 0.042036, loss_ce: 0.017192
2021-12-13 00:00:34,245 iteration 2403 : loss : 0.034461, loss_ce: 0.013247
2021-12-13 00:00:35,681 iteration 2404 : loss : 0.040842, loss_ce: 0.014473
2021-12-13 00:00:37,202 iteration 2405 : loss : 0.041443, loss_ce: 0.015107
2021-12-13 00:00:38,617 iteration 2406 : loss : 0.033381, loss_ce: 0.014727
2021-12-13 00:00:40,074 iteration 2407 : loss : 0.035607, loss_ce: 0.013105
2021-12-13 00:00:41,694 iteration 2408 : loss : 0.042344, loss_ce: 0.014847
2021-12-13 00:00:43,127 iteration 2409 : loss : 0.032458, loss_ce: 0.013918
2021-12-13 00:00:44,568 iteration 2410 : loss : 0.044104, loss_ce: 0.016602
2021-12-13 00:00:46,016 iteration 2411 : loss : 0.037311, loss_ce: 0.015168
2021-12-13 00:00:47,457 iteration 2412 : loss : 0.030913, loss_ce: 0.012384
2021-12-13 00:00:48,876 iteration 2413 : loss : 0.044457, loss_ce: 0.018626
2021-12-13 00:00:50,290 iteration 2414 : loss : 0.029720, loss_ce: 0.012692
 36%|█████████▌                 | 142/400 [1:05:32<1:59:59, 27.90s/it]2021-12-13 00:00:51,847 iteration 2415 : loss : 0.030902, loss_ce: 0.010252
2021-12-13 00:00:53,290 iteration 2416 : loss : 0.039574, loss_ce: 0.015149
2021-12-13 00:00:54,761 iteration 2417 : loss : 0.034265, loss_ce: 0.016667
2021-12-13 00:00:56,175 iteration 2418 : loss : 0.045616, loss_ce: 0.015507
2021-12-13 00:00:57,641 iteration 2419 : loss : 0.051796, loss_ce: 0.019034
2021-12-13 00:00:59,217 iteration 2420 : loss : 0.040473, loss_ce: 0.016617
2021-12-13 00:01:00,682 iteration 2421 : loss : 0.030059, loss_ce: 0.014699
2021-12-13 00:01:02,159 iteration 2422 : loss : 0.038393, loss_ce: 0.016730
2021-12-13 00:01:03,551 iteration 2423 : loss : 0.029632, loss_ce: 0.013931
2021-12-13 00:01:05,023 iteration 2424 : loss : 0.034964, loss_ce: 0.013506
2021-12-13 00:01:06,520 iteration 2425 : loss : 0.031334, loss_ce: 0.010571
2021-12-13 00:01:07,980 iteration 2426 : loss : 0.039122, loss_ce: 0.014897
2021-12-13 00:01:09,389 iteration 2427 : loss : 0.028911, loss_ce: 0.012960
2021-12-13 00:01:10,836 iteration 2428 : loss : 0.035508, loss_ce: 0.012534
2021-12-13 00:01:12,266 iteration 2429 : loss : 0.053688, loss_ce: 0.017089
2021-12-13 00:01:13,728 iteration 2430 : loss : 0.035756, loss_ce: 0.015930
2021-12-13 00:01:15,216 iteration 2431 : loss : 0.038632, loss_ce: 0.012052
 36%|█████████▋                 | 143/400 [1:05:57<1:55:41, 27.01s/it]2021-12-13 00:01:16,660 iteration 2432 : loss : 0.030619, loss_ce: 0.011568
2021-12-13 00:01:18,099 iteration 2433 : loss : 0.033651, loss_ce: 0.014997
2021-12-13 00:01:19,591 iteration 2434 : loss : 0.042407, loss_ce: 0.016429
2021-12-13 00:01:21,056 iteration 2435 : loss : 0.030018, loss_ce: 0.012462
2021-12-13 00:01:22,589 iteration 2436 : loss : 0.034729, loss_ce: 0.013541
2021-12-13 00:01:24,057 iteration 2437 : loss : 0.033989, loss_ce: 0.014189
2021-12-13 00:01:25,462 iteration 2438 : loss : 0.029906, loss_ce: 0.012934
2021-12-13 00:01:26,920 iteration 2439 : loss : 0.030116, loss_ce: 0.010663
2021-12-13 00:01:28,393 iteration 2440 : loss : 0.032775, loss_ce: 0.012686
2021-12-13 00:01:29,964 iteration 2441 : loss : 0.052089, loss_ce: 0.016762
2021-12-13 00:01:31,467 iteration 2442 : loss : 0.037041, loss_ce: 0.012323
2021-12-13 00:01:32,980 iteration 2443 : loss : 0.029896, loss_ce: 0.012566
2021-12-13 00:01:34,491 iteration 2444 : loss : 0.038231, loss_ce: 0.014703
2021-12-13 00:01:36,061 iteration 2445 : loss : 0.041556, loss_ce: 0.014420
2021-12-13 00:01:37,506 iteration 2446 : loss : 0.030694, loss_ce: 0.013467
2021-12-13 00:01:39,036 iteration 2447 : loss : 0.041689, loss_ce: 0.015056
2021-12-13 00:01:40,466 iteration 2448 : loss : 0.034635, loss_ce: 0.019351
 36%|█████████▋                 | 144/400 [1:06:22<1:52:59, 26.48s/it]2021-12-13 00:01:41,977 iteration 2449 : loss : 0.026909, loss_ce: 0.009012
2021-12-13 00:01:43,390 iteration 2450 : loss : 0.034370, loss_ce: 0.014075
2021-12-13 00:01:44,800 iteration 2451 : loss : 0.031173, loss_ce: 0.011649
2021-12-13 00:01:46,240 iteration 2452 : loss : 0.034112, loss_ce: 0.015420
2021-12-13 00:01:47,689 iteration 2453 : loss : 0.033557, loss_ce: 0.015249
2021-12-13 00:01:49,129 iteration 2454 : loss : 0.042668, loss_ce: 0.016979
2021-12-13 00:01:50,685 iteration 2455 : loss : 0.046655, loss_ce: 0.016800
2021-12-13 00:01:52,167 iteration 2456 : loss : 0.029867, loss_ce: 0.013618
2021-12-13 00:01:53,597 iteration 2457 : loss : 0.031265, loss_ce: 0.014474
2021-12-13 00:01:55,096 iteration 2458 : loss : 0.048911, loss_ce: 0.016781
2021-12-13 00:01:56,568 iteration 2459 : loss : 0.029980, loss_ce: 0.011161
2021-12-13 00:01:58,086 iteration 2460 : loss : 0.037216, loss_ce: 0.010817
2021-12-13 00:01:59,583 iteration 2461 : loss : 0.046252, loss_ce: 0.013491
2021-12-13 00:02:01,150 iteration 2462 : loss : 0.041771, loss_ce: 0.018045
2021-12-13 00:02:02,606 iteration 2463 : loss : 0.034618, loss_ce: 0.013130
2021-12-13 00:02:04,084 iteration 2464 : loss : 0.042050, loss_ce: 0.023068
2021-12-13 00:02:04,085 Training Data Eval:
2021-12-13 00:02:11,612   Average segmentation loss on training set: 0.0214
2021-12-13 00:02:11,612 Validation Data Eval:
2021-12-13 00:02:14,215   Average segmentation loss on validation set: 0.0825
2021-12-13 00:02:15,685 iteration 2465 : loss : 0.031097, loss_ce: 0.014531
 36%|█████████▊                 | 145/400 [1:06:57<2:03:41, 29.10s/it]2021-12-13 00:02:17,225 iteration 2466 : loss : 0.037941, loss_ce: 0.013982
2021-12-13 00:02:18,689 iteration 2467 : loss : 0.024051, loss_ce: 0.009451
2021-12-13 00:02:20,231 iteration 2468 : loss : 0.032659, loss_ce: 0.011378
2021-12-13 00:02:21,651 iteration 2469 : loss : 0.034688, loss_ce: 0.015413
2021-12-13 00:02:23,154 iteration 2470 : loss : 0.043508, loss_ce: 0.015657
2021-12-13 00:02:24,654 iteration 2471 : loss : 0.035716, loss_ce: 0.017601
2021-12-13 00:02:26,146 iteration 2472 : loss : 0.027956, loss_ce: 0.010195
2021-12-13 00:02:27,611 iteration 2473 : loss : 0.034230, loss_ce: 0.013405
2021-12-13 00:02:28,978 iteration 2474 : loss : 0.027776, loss_ce: 0.011077
2021-12-13 00:02:30,468 iteration 2475 : loss : 0.042534, loss_ce: 0.025079
2021-12-13 00:02:31,952 iteration 2476 : loss : 0.041317, loss_ce: 0.012639
2021-12-13 00:02:33,426 iteration 2477 : loss : 0.031760, loss_ce: 0.010873
2021-12-13 00:02:34,886 iteration 2478 : loss : 0.040105, loss_ce: 0.013248
2021-12-13 00:02:36,396 iteration 2479 : loss : 0.031202, loss_ce: 0.010571
2021-12-13 00:02:37,845 iteration 2480 : loss : 0.027374, loss_ce: 0.010239
2021-12-13 00:02:39,275 iteration 2481 : loss : 0.029790, loss_ce: 0.013315
2021-12-13 00:02:40,860 iteration 2482 : loss : 0.057989, loss_ce: 0.021606
 36%|█████████▊                 | 146/400 [1:07:22<1:58:12, 27.92s/it]2021-12-13 00:02:42,355 iteration 2483 : loss : 0.040352, loss_ce: 0.018628
2021-12-13 00:02:43,852 iteration 2484 : loss : 0.052606, loss_ce: 0.011641
2021-12-13 00:02:45,346 iteration 2485 : loss : 0.046100, loss_ce: 0.014645
2021-12-13 00:02:46,832 iteration 2486 : loss : 0.038620, loss_ce: 0.015042
2021-12-13 00:02:48,250 iteration 2487 : loss : 0.024818, loss_ce: 0.010977
2021-12-13 00:02:49,774 iteration 2488 : loss : 0.035337, loss_ce: 0.016772
2021-12-13 00:02:51,280 iteration 2489 : loss : 0.041247, loss_ce: 0.017168
2021-12-13 00:02:52,816 iteration 2490 : loss : 0.042368, loss_ce: 0.018738
2021-12-13 00:02:54,303 iteration 2491 : loss : 0.031926, loss_ce: 0.009496
2021-12-13 00:02:55,796 iteration 2492 : loss : 0.045265, loss_ce: 0.016419
2021-12-13 00:02:57,217 iteration 2493 : loss : 0.031728, loss_ce: 0.011037
2021-12-13 00:02:58,681 iteration 2494 : loss : 0.037422, loss_ce: 0.013135
2021-12-13 00:03:00,219 iteration 2495 : loss : 0.031513, loss_ce: 0.013895
2021-12-13 00:03:01,577 iteration 2496 : loss : 0.024690, loss_ce: 0.009968
2021-12-13 00:03:03,005 iteration 2497 : loss : 0.038839, loss_ce: 0.013386
2021-12-13 00:03:04,594 iteration 2498 : loss : 0.042758, loss_ce: 0.016833
2021-12-13 00:03:06,065 iteration 2499 : loss : 0.033567, loss_ce: 0.015473
 37%|█████████▉                 | 147/400 [1:07:48<1:54:18, 27.11s/it]2021-12-13 00:03:07,589 iteration 2500 : loss : 0.047747, loss_ce: 0.016532
2021-12-13 00:03:09,105 iteration 2501 : loss : 0.031509, loss_ce: 0.013209
2021-12-13 00:03:10,599 iteration 2502 : loss : 0.063726, loss_ce: 0.029776
2021-12-13 00:03:12,051 iteration 2503 : loss : 0.035500, loss_ce: 0.016735
2021-12-13 00:03:13,551 iteration 2504 : loss : 0.054656, loss_ce: 0.021669
2021-12-13 00:03:15,038 iteration 2505 : loss : 0.031124, loss_ce: 0.010389
2021-12-13 00:03:16,520 iteration 2506 : loss : 0.030979, loss_ce: 0.015101
2021-12-13 00:03:17,946 iteration 2507 : loss : 0.023340, loss_ce: 0.009150
2021-12-13 00:03:19,332 iteration 2508 : loss : 0.029163, loss_ce: 0.012455
2021-12-13 00:03:20,773 iteration 2509 : loss : 0.034814, loss_ce: 0.015947
2021-12-13 00:03:22,177 iteration 2510 : loss : 0.050416, loss_ce: 0.013963
2021-12-13 00:03:23,632 iteration 2511 : loss : 0.030624, loss_ce: 0.013437
2021-12-13 00:03:25,082 iteration 2512 : loss : 0.029788, loss_ce: 0.012380
2021-12-13 00:03:26,534 iteration 2513 : loss : 0.040850, loss_ce: 0.016999
2021-12-13 00:03:28,007 iteration 2514 : loss : 0.043735, loss_ce: 0.016185
2021-12-13 00:03:29,448 iteration 2515 : loss : 0.043530, loss_ce: 0.014954
2021-12-13 00:03:30,866 iteration 2516 : loss : 0.036600, loss_ce: 0.014783
 37%|█████████▉                 | 148/400 [1:08:12<1:50:57, 26.42s/it]2021-12-13 00:03:32,345 iteration 2517 : loss : 0.038241, loss_ce: 0.016560
2021-12-13 00:03:33,908 iteration 2518 : loss : 0.041652, loss_ce: 0.017390
2021-12-13 00:03:35,379 iteration 2519 : loss : 0.038112, loss_ce: 0.014466
2021-12-13 00:03:36,816 iteration 2520 : loss : 0.026291, loss_ce: 0.009792
2021-12-13 00:03:38,306 iteration 2521 : loss : 0.031016, loss_ce: 0.015831
2021-12-13 00:03:39,710 iteration 2522 : loss : 0.033626, loss_ce: 0.013966
2021-12-13 00:03:41,060 iteration 2523 : loss : 0.032747, loss_ce: 0.009478
2021-12-13 00:03:42,562 iteration 2524 : loss : 0.035756, loss_ce: 0.016817
2021-12-13 00:03:43,988 iteration 2525 : loss : 0.034155, loss_ce: 0.014521
2021-12-13 00:03:45,419 iteration 2526 : loss : 0.037377, loss_ce: 0.016146
2021-12-13 00:03:46,923 iteration 2527 : loss : 0.042403, loss_ce: 0.015778
2021-12-13 00:03:48,354 iteration 2528 : loss : 0.036626, loss_ce: 0.015160
2021-12-13 00:03:49,841 iteration 2529 : loss : 0.035679, loss_ce: 0.013715
2021-12-13 00:03:51,313 iteration 2530 : loss : 0.039919, loss_ce: 0.013691
2021-12-13 00:03:52,762 iteration 2531 : loss : 0.045419, loss_ce: 0.016246
2021-12-13 00:03:54,251 iteration 2532 : loss : 0.044731, loss_ce: 0.015287
2021-12-13 00:03:55,721 iteration 2533 : loss : 0.040461, loss_ce: 0.022685
 37%|██████████                 | 149/400 [1:08:37<1:48:33, 25.95s/it]2021-12-13 00:03:57,171 iteration 2534 : loss : 0.025019, loss_ce: 0.011510
2021-12-13 00:03:58,658 iteration 2535 : loss : 0.035660, loss_ce: 0.011194
2021-12-13 00:04:00,170 iteration 2536 : loss : 0.033051, loss_ce: 0.014463
2021-12-13 00:04:01,683 iteration 2537 : loss : 0.046251, loss_ce: 0.014699
2021-12-13 00:04:03,214 iteration 2538 : loss : 0.041232, loss_ce: 0.016364
2021-12-13 00:04:04,622 iteration 2539 : loss : 0.031559, loss_ce: 0.012192
2021-12-13 00:04:06,083 iteration 2540 : loss : 0.039503, loss_ce: 0.014085
2021-12-13 00:04:07,680 iteration 2541 : loss : 0.056130, loss_ce: 0.014535
2021-12-13 00:04:09,087 iteration 2542 : loss : 0.041497, loss_ce: 0.014527
2021-12-13 00:04:10,548 iteration 2543 : loss : 0.036133, loss_ce: 0.013767
2021-12-13 00:04:12,084 iteration 2544 : loss : 0.042523, loss_ce: 0.017276
2021-12-13 00:04:13,612 iteration 2545 : loss : 0.041423, loss_ce: 0.021078
2021-12-13 00:04:15,028 iteration 2546 : loss : 0.035089, loss_ce: 0.014155
2021-12-13 00:04:16,493 iteration 2547 : loss : 0.046700, loss_ce: 0.011261
2021-12-13 00:04:17,950 iteration 2548 : loss : 0.036501, loss_ce: 0.015015
2021-12-13 00:04:19,475 iteration 2549 : loss : 0.044541, loss_ce: 0.016283
2021-12-13 00:04:19,475 Training Data Eval:
2021-12-13 00:04:27,014   Average segmentation loss on training set: 0.0237
2021-12-13 00:04:27,015 Validation Data Eval:
2021-12-13 00:04:29,616   Average segmentation loss on validation set: 0.0876
2021-12-13 00:04:31,063 iteration 2550 : loss : 0.038679, loss_ce: 0.020714
 38%|██████████▏                | 150/400 [1:09:13<1:59:51, 28.76s/it]2021-12-13 00:04:32,531 iteration 2551 : loss : 0.033607, loss_ce: 0.012656
2021-12-13 00:04:33,993 iteration 2552 : loss : 0.031747, loss_ce: 0.013745
2021-12-13 00:04:35,528 iteration 2553 : loss : 0.041807, loss_ce: 0.016560
2021-12-13 00:04:37,032 iteration 2554 : loss : 0.057012, loss_ce: 0.015378
2021-12-13 00:04:38,478 iteration 2555 : loss : 0.036213, loss_ce: 0.011299
2021-12-13 00:04:39,872 iteration 2556 : loss : 0.033859, loss_ce: 0.014362
2021-12-13 00:04:41,382 iteration 2557 : loss : 0.036373, loss_ce: 0.015501
2021-12-13 00:04:42,887 iteration 2558 : loss : 0.034266, loss_ce: 0.015190
2021-12-13 00:04:44,404 iteration 2559 : loss : 0.043352, loss_ce: 0.011948
2021-12-13 00:04:45,919 iteration 2560 : loss : 0.028441, loss_ce: 0.011474
2021-12-13 00:04:47,372 iteration 2561 : loss : 0.035250, loss_ce: 0.014532
2021-12-13 00:04:48,794 iteration 2562 : loss : 0.036264, loss_ce: 0.019026
2021-12-13 00:04:50,249 iteration 2563 : loss : 0.034888, loss_ce: 0.012174
2021-12-13 00:04:51,726 iteration 2564 : loss : 0.043868, loss_ce: 0.020875
2021-12-13 00:04:53,181 iteration 2565 : loss : 0.033497, loss_ce: 0.010364
2021-12-13 00:04:54,622 iteration 2566 : loss : 0.034373, loss_ce: 0.015789
2021-12-13 00:04:56,176 iteration 2567 : loss : 0.040185, loss_ce: 0.016069
 38%|██████████▏                | 151/400 [1:09:38<1:54:50, 27.67s/it]2021-12-13 00:04:57,682 iteration 2568 : loss : 0.027618, loss_ce: 0.012571
2021-12-13 00:04:59,146 iteration 2569 : loss : 0.034378, loss_ce: 0.012475
2021-12-13 00:05:00,582 iteration 2570 : loss : 0.043756, loss_ce: 0.011612
2021-12-13 00:05:02,050 iteration 2571 : loss : 0.038940, loss_ce: 0.016237
2021-12-13 00:05:03,449 iteration 2572 : loss : 0.028214, loss_ce: 0.009261
2021-12-13 00:05:04,869 iteration 2573 : loss : 0.026222, loss_ce: 0.010558
2021-12-13 00:05:06,317 iteration 2574 : loss : 0.042500, loss_ce: 0.015409
2021-12-13 00:05:07,824 iteration 2575 : loss : 0.029618, loss_ce: 0.011366
2021-12-13 00:05:09,391 iteration 2576 : loss : 0.039804, loss_ce: 0.016589
2021-12-13 00:05:10,834 iteration 2577 : loss : 0.039787, loss_ce: 0.014907
2021-12-13 00:05:12,324 iteration 2578 : loss : 0.033852, loss_ce: 0.017767
2021-12-13 00:05:13,767 iteration 2579 : loss : 0.043302, loss_ce: 0.013931
2021-12-13 00:05:15,265 iteration 2580 : loss : 0.030167, loss_ce: 0.010173
2021-12-13 00:05:16,841 iteration 2581 : loss : 0.044016, loss_ce: 0.017192
2021-12-13 00:05:18,210 iteration 2582 : loss : 0.036639, loss_ce: 0.015078
2021-12-13 00:05:19,712 iteration 2583 : loss : 0.029726, loss_ce: 0.010171
2021-12-13 00:05:21,152 iteration 2584 : loss : 0.028483, loss_ce: 0.011011
 38%|██████████▎                | 152/400 [1:10:03<1:51:01, 26.86s/it]2021-12-13 00:05:22,708 iteration 2585 : loss : 0.038396, loss_ce: 0.017325
2021-12-13 00:05:24,179 iteration 2586 : loss : 0.043749, loss_ce: 0.018698
2021-12-13 00:05:25,586 iteration 2587 : loss : 0.030960, loss_ce: 0.011606
2021-12-13 00:05:27,024 iteration 2588 : loss : 0.042088, loss_ce: 0.018003
2021-12-13 00:05:28,416 iteration 2589 : loss : 0.033593, loss_ce: 0.012976
2021-12-13 00:05:29,925 iteration 2590 : loss : 0.041018, loss_ce: 0.015346
2021-12-13 00:05:31,381 iteration 2591 : loss : 0.040507, loss_ce: 0.017619
2021-12-13 00:05:32,828 iteration 2592 : loss : 0.029617, loss_ce: 0.011509
2021-12-13 00:05:34,253 iteration 2593 : loss : 0.038168, loss_ce: 0.014184
2021-12-13 00:05:35,745 iteration 2594 : loss : 0.037150, loss_ce: 0.014453
2021-12-13 00:05:37,307 iteration 2595 : loss : 0.043228, loss_ce: 0.014351
2021-12-13 00:05:38,713 iteration 2596 : loss : 0.034334, loss_ce: 0.011827
2021-12-13 00:05:40,188 iteration 2597 : loss : 0.053544, loss_ce: 0.015284
2021-12-13 00:05:41,620 iteration 2598 : loss : 0.033753, loss_ce: 0.014869
2021-12-13 00:05:43,123 iteration 2599 : loss : 0.030866, loss_ce: 0.014432
2021-12-13 00:05:44,584 iteration 2600 : loss : 0.044352, loss_ce: 0.016935
2021-12-13 00:05:46,080 iteration 2601 : loss : 0.034430, loss_ce: 0.013861
 38%|██████████▎                | 153/400 [1:10:28<1:48:11, 26.28s/it]2021-12-13 00:05:47,607 iteration 2602 : loss : 0.041311, loss_ce: 0.012299
2021-12-13 00:05:49,159 iteration 2603 : loss : 0.047537, loss_ce: 0.015310
2021-12-13 00:05:50,627 iteration 2604 : loss : 0.037436, loss_ce: 0.018092
2021-12-13 00:05:51,983 iteration 2605 : loss : 0.025912, loss_ce: 0.008641
2021-12-13 00:05:53,573 iteration 2606 : loss : 0.044081, loss_ce: 0.015168
2021-12-13 00:05:55,081 iteration 2607 : loss : 0.035824, loss_ce: 0.012400
2021-12-13 00:05:56,554 iteration 2608 : loss : 0.035939, loss_ce: 0.017326
2021-12-13 00:05:58,131 iteration 2609 : loss : 0.037074, loss_ce: 0.013928
2021-12-13 00:05:59,649 iteration 2610 : loss : 0.040487, loss_ce: 0.015461
2021-12-13 00:06:01,141 iteration 2611 : loss : 0.041928, loss_ce: 0.016621
2021-12-13 00:06:02,667 iteration 2612 : loss : 0.047453, loss_ce: 0.023473
2021-12-13 00:06:04,102 iteration 2613 : loss : 0.033701, loss_ce: 0.013027
2021-12-13 00:06:05,635 iteration 2614 : loss : 0.042773, loss_ce: 0.013462
2021-12-13 00:06:07,074 iteration 2615 : loss : 0.037004, loss_ce: 0.012140
2021-12-13 00:06:08,576 iteration 2616 : loss : 0.032772, loss_ce: 0.015684
2021-12-13 00:06:10,033 iteration 2617 : loss : 0.034788, loss_ce: 0.010726
2021-12-13 00:06:11,454 iteration 2618 : loss : 0.036889, loss_ce: 0.014624
 38%|██████████▍                | 154/400 [1:10:53<1:46:38, 26.01s/it]2021-12-13 00:06:12,931 iteration 2619 : loss : 0.040387, loss_ce: 0.014355
2021-12-13 00:06:14,372 iteration 2620 : loss : 0.029678, loss_ce: 0.013950
2021-12-13 00:06:15,892 iteration 2621 : loss : 0.034987, loss_ce: 0.013723
2021-12-13 00:06:17,345 iteration 2622 : loss : 0.049976, loss_ce: 0.014015
2021-12-13 00:06:18,841 iteration 2623 : loss : 0.032339, loss_ce: 0.013889
2021-12-13 00:06:20,283 iteration 2624 : loss : 0.030294, loss_ce: 0.010786
2021-12-13 00:06:21,770 iteration 2625 : loss : 0.059697, loss_ce: 0.013602
2021-12-13 00:06:23,257 iteration 2626 : loss : 0.045594, loss_ce: 0.018134
2021-12-13 00:06:24,872 iteration 2627 : loss : 0.047694, loss_ce: 0.017535
2021-12-13 00:06:26,296 iteration 2628 : loss : 0.041645, loss_ce: 0.017221
2021-12-13 00:06:27,820 iteration 2629 : loss : 0.043031, loss_ce: 0.017144
2021-12-13 00:06:29,311 iteration 2630 : loss : 0.038987, loss_ce: 0.014750
2021-12-13 00:06:30,782 iteration 2631 : loss : 0.032672, loss_ce: 0.015102
2021-12-13 00:06:32,254 iteration 2632 : loss : 0.026396, loss_ce: 0.010165
2021-12-13 00:06:33,748 iteration 2633 : loss : 0.044362, loss_ce: 0.022137
2021-12-13 00:06:35,233 iteration 2634 : loss : 0.035110, loss_ce: 0.011652
2021-12-13 00:06:35,233 Training Data Eval:
2021-12-13 00:06:42,755   Average segmentation loss on training set: 0.0256
2021-12-13 00:06:42,756 Validation Data Eval:
2021-12-13 00:06:45,356   Average segmentation loss on validation set: 0.0883
2021-12-13 00:06:46,823 iteration 2635 : loss : 0.035762, loss_ce: 0.013771
 39%|██████████▍                | 155/400 [1:11:28<1:57:40, 28.82s/it]2021-12-13 00:06:48,341 iteration 2636 : loss : 0.037405, loss_ce: 0.016204
2021-12-13 00:06:49,882 iteration 2637 : loss : 0.050203, loss_ce: 0.019688
2021-12-13 00:06:51,326 iteration 2638 : loss : 0.037208, loss_ce: 0.012020
2021-12-13 00:06:52,743 iteration 2639 : loss : 0.032509, loss_ce: 0.015064
2021-12-13 00:06:54,185 iteration 2640 : loss : 0.033913, loss_ce: 0.013018
2021-12-13 00:06:55,638 iteration 2641 : loss : 0.037639, loss_ce: 0.018729
2021-12-13 00:06:57,062 iteration 2642 : loss : 0.032743, loss_ce: 0.011988
2021-12-13 00:06:58,650 iteration 2643 : loss : 0.035809, loss_ce: 0.012864
2021-12-13 00:07:00,098 iteration 2644 : loss : 0.031531, loss_ce: 0.011867
2021-12-13 00:07:01,518 iteration 2645 : loss : 0.030922, loss_ce: 0.010996
2021-12-13 00:07:03,157 iteration 2646 : loss : 0.037020, loss_ce: 0.014054
2021-12-13 00:07:04,690 iteration 2647 : loss : 0.043591, loss_ce: 0.018209
2021-12-13 00:07:06,147 iteration 2648 : loss : 0.041487, loss_ce: 0.015006
2021-12-13 00:07:07,628 iteration 2649 : loss : 0.038693, loss_ce: 0.016357
2021-12-13 00:07:09,151 iteration 2650 : loss : 0.036555, loss_ce: 0.012449
2021-12-13 00:07:10,651 iteration 2651 : loss : 0.040957, loss_ce: 0.017533
2021-12-13 00:07:12,062 iteration 2652 : loss : 0.029893, loss_ce: 0.011669
 39%|██████████▌                | 156/400 [1:11:54<1:52:49, 27.74s/it]2021-12-13 00:07:13,620 iteration 2653 : loss : 0.032224, loss_ce: 0.014094
2021-12-13 00:07:15,110 iteration 2654 : loss : 0.034912, loss_ce: 0.011489
2021-12-13 00:07:16,681 iteration 2655 : loss : 0.039063, loss_ce: 0.018644
2021-12-13 00:07:18,133 iteration 2656 : loss : 0.038861, loss_ce: 0.011484
2021-12-13 00:07:19,593 iteration 2657 : loss : 0.036032, loss_ce: 0.012876
2021-12-13 00:07:20,948 iteration 2658 : loss : 0.025467, loss_ce: 0.012164
2021-12-13 00:07:22,356 iteration 2659 : loss : 0.041143, loss_ce: 0.009737
2021-12-13 00:07:23,865 iteration 2660 : loss : 0.042919, loss_ce: 0.013404
2021-12-13 00:07:25,308 iteration 2661 : loss : 0.028517, loss_ce: 0.013310
2021-12-13 00:07:26,770 iteration 2662 : loss : 0.038268, loss_ce: 0.019350
2021-12-13 00:07:28,207 iteration 2663 : loss : 0.050840, loss_ce: 0.018105
2021-12-13 00:07:29,763 iteration 2664 : loss : 0.034759, loss_ce: 0.016288
2021-12-13 00:07:31,244 iteration 2665 : loss : 0.038989, loss_ce: 0.014403
2021-12-13 00:07:32,690 iteration 2666 : loss : 0.023881, loss_ce: 0.008940
2021-12-13 00:07:34,214 iteration 2667 : loss : 0.053646, loss_ce: 0.017737
2021-12-13 00:07:35,648 iteration 2668 : loss : 0.032666, loss_ce: 0.013300
2021-12-13 00:07:37,082 iteration 2669 : loss : 0.041138, loss_ce: 0.015290
 39%|██████████▌                | 157/400 [1:12:19<1:49:02, 26.93s/it]2021-12-13 00:07:38,625 iteration 2670 : loss : 0.040690, loss_ce: 0.017747
2021-12-13 00:07:40,203 iteration 2671 : loss : 0.076498, loss_ce: 0.026416
2021-12-13 00:07:41,708 iteration 2672 : loss : 0.032123, loss_ce: 0.012852
2021-12-13 00:07:43,125 iteration 2673 : loss : 0.030324, loss_ce: 0.015928
2021-12-13 00:07:44,623 iteration 2674 : loss : 0.037740, loss_ce: 0.018318
2021-12-13 00:07:45,981 iteration 2675 : loss : 0.027948, loss_ce: 0.012225
2021-12-13 00:07:47,554 iteration 2676 : loss : 0.042426, loss_ce: 0.011693
2021-12-13 00:07:49,051 iteration 2677 : loss : 0.043134, loss_ce: 0.017134
2021-12-13 00:07:50,516 iteration 2678 : loss : 0.030950, loss_ce: 0.012574
2021-12-13 00:07:51,995 iteration 2679 : loss : 0.046042, loss_ce: 0.015966
2021-12-13 00:07:53,455 iteration 2680 : loss : 0.031289, loss_ce: 0.012867
2021-12-13 00:07:54,936 iteration 2681 : loss : 0.029760, loss_ce: 0.011078
2021-12-13 00:07:56,416 iteration 2682 : loss : 0.031253, loss_ce: 0.012145
2021-12-13 00:07:57,873 iteration 2683 : loss : 0.068416, loss_ce: 0.017079
2021-12-13 00:07:59,291 iteration 2684 : loss : 0.032381, loss_ce: 0.015099
2021-12-13 00:08:00,783 iteration 2685 : loss : 0.031801, loss_ce: 0.014394
2021-12-13 00:08:02,195 iteration 2686 : loss : 0.034114, loss_ce: 0.014954
 40%|██████████▋                | 158/400 [1:12:44<1:46:24, 26.38s/it]2021-12-13 00:08:03,612 iteration 2687 : loss : 0.039391, loss_ce: 0.011800
2021-12-13 00:08:05,074 iteration 2688 : loss : 0.037606, loss_ce: 0.011890
2021-12-13 00:08:06,512 iteration 2689 : loss : 0.041024, loss_ce: 0.014883
2021-12-13 00:08:08,074 iteration 2690 : loss : 0.039519, loss_ce: 0.016682
2021-12-13 00:08:09,478 iteration 2691 : loss : 0.025433, loss_ce: 0.010751
2021-12-13 00:08:10,912 iteration 2692 : loss : 0.034196, loss_ce: 0.011300
2021-12-13 00:08:12,380 iteration 2693 : loss : 0.038511, loss_ce: 0.011670
2021-12-13 00:08:13,915 iteration 2694 : loss : 0.038063, loss_ce: 0.013733
2021-12-13 00:08:15,356 iteration 2695 : loss : 0.041205, loss_ce: 0.016041
2021-12-13 00:08:16,844 iteration 2696 : loss : 0.032770, loss_ce: 0.014038
2021-12-13 00:08:18,246 iteration 2697 : loss : 0.026880, loss_ce: 0.011818
2021-12-13 00:08:19,584 iteration 2698 : loss : 0.023737, loss_ce: 0.011312
2021-12-13 00:08:21,058 iteration 2699 : loss : 0.037433, loss_ce: 0.014688
2021-12-13 00:08:22,573 iteration 2700 : loss : 0.038262, loss_ce: 0.018046
2021-12-13 00:08:24,038 iteration 2701 : loss : 0.031946, loss_ce: 0.012852
2021-12-13 00:08:25,539 iteration 2702 : loss : 0.053389, loss_ce: 0.011128
2021-12-13 00:08:27,010 iteration 2703 : loss : 0.031367, loss_ce: 0.012397
 40%|██████████▋                | 159/400 [1:13:08<1:44:05, 25.91s/it]2021-12-13 00:08:28,615 iteration 2704 : loss : 0.040009, loss_ce: 0.016226
2021-12-13 00:08:30,038 iteration 2705 : loss : 0.036849, loss_ce: 0.010438
2021-12-13 00:08:31,460 iteration 2706 : loss : 0.035171, loss_ce: 0.017626
2021-12-13 00:08:33,014 iteration 2707 : loss : 0.039964, loss_ce: 0.014482
2021-12-13 00:08:34,401 iteration 2708 : loss : 0.023014, loss_ce: 0.010122
2021-12-13 00:08:35,866 iteration 2709 : loss : 0.037819, loss_ce: 0.011465
2021-12-13 00:08:37,275 iteration 2710 : loss : 0.028085, loss_ce: 0.010999
2021-12-13 00:08:38,832 iteration 2711 : loss : 0.035610, loss_ce: 0.013476
2021-12-13 00:08:40,238 iteration 2712 : loss : 0.026269, loss_ce: 0.010586
2021-12-13 00:08:41,807 iteration 2713 : loss : 0.045412, loss_ce: 0.014484
2021-12-13 00:08:43,213 iteration 2714 : loss : 0.033439, loss_ce: 0.011958
2021-12-13 00:08:44,693 iteration 2715 : loss : 0.039915, loss_ce: 0.019671
2021-12-13 00:08:46,123 iteration 2716 : loss : 0.038911, loss_ce: 0.015027
2021-12-13 00:08:47,526 iteration 2717 : loss : 0.031403, loss_ce: 0.014571
2021-12-13 00:08:48,945 iteration 2718 : loss : 0.033656, loss_ce: 0.012601
2021-12-13 00:08:50,462 iteration 2719 : loss : 0.052353, loss_ce: 0.015322
2021-12-13 00:08:50,463 Training Data Eval:
2021-12-13 00:08:57,997   Average segmentation loss on training set: 0.0221
2021-12-13 00:08:57,997 Validation Data Eval:
2021-12-13 00:09:00,590   Average segmentation loss on validation set: 0.0905
2021-12-13 00:09:01,994 iteration 2720 : loss : 0.027840, loss_ce: 0.011728
 40%|██████████▊                | 160/400 [1:13:43<1:54:32, 28.63s/it]2021-12-13 00:09:03,515 iteration 2721 : loss : 0.034902, loss_ce: 0.014059
2021-12-13 00:09:05,012 iteration 2722 : loss : 0.037218, loss_ce: 0.015474
2021-12-13 00:09:06,511 iteration 2723 : loss : 0.029932, loss_ce: 0.010979
2021-12-13 00:09:07,921 iteration 2724 : loss : 0.031421, loss_ce: 0.010763
2021-12-13 00:09:09,292 iteration 2725 : loss : 0.032285, loss_ce: 0.011956
2021-12-13 00:09:10,718 iteration 2726 : loss : 0.039389, loss_ce: 0.016384
2021-12-13 00:09:12,103 iteration 2727 : loss : 0.024659, loss_ce: 0.009312
2021-12-13 00:09:13,674 iteration 2728 : loss : 0.045621, loss_ce: 0.020707
2021-12-13 00:09:15,158 iteration 2729 : loss : 0.043865, loss_ce: 0.015785
2021-12-13 00:09:16,662 iteration 2730 : loss : 0.033106, loss_ce: 0.013835
2021-12-13 00:09:18,158 iteration 2731 : loss : 0.036721, loss_ce: 0.014481
2021-12-13 00:09:19,722 iteration 2732 : loss : 0.043032, loss_ce: 0.017952
2021-12-13 00:09:21,233 iteration 2733 : loss : 0.049545, loss_ce: 0.019909
2021-12-13 00:09:22,719 iteration 2734 : loss : 0.026053, loss_ce: 0.007973
2021-12-13 00:09:24,103 iteration 2735 : loss : 0.032571, loss_ce: 0.013430
2021-12-13 00:09:25,622 iteration 2736 : loss : 0.043307, loss_ce: 0.020791
2021-12-13 00:09:27,074 iteration 2737 : loss : 0.037488, loss_ce: 0.016265
 40%|██████████▊                | 161/400 [1:14:09<1:49:48, 27.57s/it]2021-12-13 00:09:28,567 iteration 2738 : loss : 0.036208, loss_ce: 0.018478
2021-12-13 00:09:30,013 iteration 2739 : loss : 0.040038, loss_ce: 0.018466
2021-12-13 00:09:31,494 iteration 2740 : loss : 0.029024, loss_ce: 0.011792
2021-12-13 00:09:32,983 iteration 2741 : loss : 0.042210, loss_ce: 0.014533
2021-12-13 00:09:34,377 iteration 2742 : loss : 0.028007, loss_ce: 0.011339
2021-12-13 00:09:35,848 iteration 2743 : loss : 0.039679, loss_ce: 0.018737
2021-12-13 00:09:37,359 iteration 2744 : loss : 0.036880, loss_ce: 0.014499
2021-12-13 00:09:38,834 iteration 2745 : loss : 0.035886, loss_ce: 0.014252
2021-12-13 00:09:40,243 iteration 2746 : loss : 0.036016, loss_ce: 0.010659
2021-12-13 00:09:41,714 iteration 2747 : loss : 0.037118, loss_ce: 0.012789
2021-12-13 00:09:43,224 iteration 2748 : loss : 0.046051, loss_ce: 0.015587
2021-12-13 00:09:44,617 iteration 2749 : loss : 0.032905, loss_ce: 0.015113
2021-12-13 00:09:46,111 iteration 2750 : loss : 0.049632, loss_ce: 0.016083
2021-12-13 00:09:47,541 iteration 2751 : loss : 0.023853, loss_ce: 0.010864
2021-12-13 00:09:48,925 iteration 2752 : loss : 0.044140, loss_ce: 0.010531
2021-12-13 00:09:50,469 iteration 2753 : loss : 0.043187, loss_ce: 0.018916
2021-12-13 00:09:51,977 iteration 2754 : loss : 0.027701, loss_ce: 0.011733
 40%|██████████▉                | 162/400 [1:14:33<1:46:11, 26.77s/it]2021-12-13 00:09:53,485 iteration 2755 : loss : 0.025984, loss_ce: 0.011917
2021-12-13 00:09:54,960 iteration 2756 : loss : 0.039730, loss_ce: 0.020415
2021-12-13 00:09:56,421 iteration 2757 : loss : 0.030758, loss_ce: 0.011796
2021-12-13 00:09:57,950 iteration 2758 : loss : 0.037467, loss_ce: 0.012400
2021-12-13 00:09:59,440 iteration 2759 : loss : 0.039349, loss_ce: 0.013120
2021-12-13 00:10:00,907 iteration 2760 : loss : 0.038941, loss_ce: 0.015765
2021-12-13 00:10:02,292 iteration 2761 : loss : 0.036882, loss_ce: 0.012363
2021-12-13 00:10:03,696 iteration 2762 : loss : 0.026057, loss_ce: 0.012011
2021-12-13 00:10:05,200 iteration 2763 : loss : 0.051564, loss_ce: 0.016041
2021-12-13 00:10:06,657 iteration 2764 : loss : 0.033220, loss_ce: 0.012979
2021-12-13 00:10:08,127 iteration 2765 : loss : 0.046514, loss_ce: 0.017464
2021-12-13 00:10:09,559 iteration 2766 : loss : 0.032665, loss_ce: 0.013777
2021-12-13 00:10:11,040 iteration 2767 : loss : 0.045123, loss_ce: 0.017374
2021-12-13 00:10:12,459 iteration 2768 : loss : 0.023479, loss_ce: 0.007870
2021-12-13 00:10:13,915 iteration 2769 : loss : 0.031769, loss_ce: 0.013277
2021-12-13 00:10:15,392 iteration 2770 : loss : 0.038085, loss_ce: 0.017914
2021-12-13 00:10:16,830 iteration 2771 : loss : 0.029656, loss_ce: 0.009499
 41%|███████████                | 163/400 [1:14:58<1:43:28, 26.19s/it]2021-12-13 00:10:18,383 iteration 2772 : loss : 0.036301, loss_ce: 0.015420
2021-12-13 00:10:19,790 iteration 2773 : loss : 0.032178, loss_ce: 0.013321
2021-12-13 00:10:21,184 iteration 2774 : loss : 0.040950, loss_ce: 0.010998
2021-12-13 00:10:22,615 iteration 2775 : loss : 0.037217, loss_ce: 0.014229
2021-12-13 00:10:24,037 iteration 2776 : loss : 0.029415, loss_ce: 0.011644
2021-12-13 00:10:25,510 iteration 2777 : loss : 0.021880, loss_ce: 0.008816
2021-12-13 00:10:27,042 iteration 2778 : loss : 0.048299, loss_ce: 0.016890
2021-12-13 00:10:28,607 iteration 2779 : loss : 0.038993, loss_ce: 0.014901
2021-12-13 00:10:30,026 iteration 2780 : loss : 0.024684, loss_ce: 0.009217
2021-12-13 00:10:31,554 iteration 2781 : loss : 0.046010, loss_ce: 0.014912
2021-12-13 00:10:33,006 iteration 2782 : loss : 0.033337, loss_ce: 0.012011
2021-12-13 00:10:34,429 iteration 2783 : loss : 0.038617, loss_ce: 0.018165
2021-12-13 00:10:36,000 iteration 2784 : loss : 0.049588, loss_ce: 0.017064
2021-12-13 00:10:37,546 iteration 2785 : loss : 0.040306, loss_ce: 0.011767
2021-12-13 00:10:39,043 iteration 2786 : loss : 0.036635, loss_ce: 0.015021
2021-12-13 00:10:40,551 iteration 2787 : loss : 0.027127, loss_ce: 0.012109
2021-12-13 00:10:41,982 iteration 2788 : loss : 0.031221, loss_ce: 0.015932
 41%|███████████                | 164/400 [1:15:23<1:41:47, 25.88s/it]2021-12-13 00:10:43,459 iteration 2789 : loss : 0.033434, loss_ce: 0.012734
2021-12-13 00:10:44,949 iteration 2790 : loss : 0.026808, loss_ce: 0.009595
2021-12-13 00:10:46,384 iteration 2791 : loss : 0.040142, loss_ce: 0.016070
2021-12-13 00:10:47,908 iteration 2792 : loss : 0.043253, loss_ce: 0.014307
2021-12-13 00:10:49,327 iteration 2793 : loss : 0.034506, loss_ce: 0.015221
2021-12-13 00:10:50,822 iteration 2794 : loss : 0.037086, loss_ce: 0.013260
2021-12-13 00:10:52,242 iteration 2795 : loss : 0.023414, loss_ce: 0.007803
2021-12-13 00:10:53,736 iteration 2796 : loss : 0.037572, loss_ce: 0.014208
2021-12-13 00:10:55,232 iteration 2797 : loss : 0.032375, loss_ce: 0.012967
2021-12-13 00:10:56,752 iteration 2798 : loss : 0.040563, loss_ce: 0.021328
2021-12-13 00:10:58,179 iteration 2799 : loss : 0.026478, loss_ce: 0.011525
2021-12-13 00:10:59,603 iteration 2800 : loss : 0.050523, loss_ce: 0.016493
2021-12-13 00:11:00,998 iteration 2801 : loss : 0.023841, loss_ce: 0.008314
2021-12-13 00:11:02,518 iteration 2802 : loss : 0.039222, loss_ce: 0.012702
2021-12-13 00:11:03,974 iteration 2803 : loss : 0.029822, loss_ce: 0.012866
2021-12-13 00:11:05,407 iteration 2804 : loss : 0.034384, loss_ce: 0.012647
2021-12-13 00:11:05,407 Training Data Eval:
2021-12-13 00:11:12,940   Average segmentation loss on training set: 0.0209
2021-12-13 00:11:12,940 Validation Data Eval:
2021-12-13 00:11:15,538   Average segmentation loss on validation set: 0.0837
2021-12-13 00:11:16,965 iteration 2805 : loss : 0.029367, loss_ce: 0.012703
 41%|███████████▏               | 165/400 [1:15:58<1:52:03, 28.61s/it]2021-12-13 00:11:18,575 iteration 2806 : loss : 0.042352, loss_ce: 0.018274
2021-12-13 00:11:19,965 iteration 2807 : loss : 0.035076, loss_ce: 0.013763
2021-12-13 00:11:21,375 iteration 2808 : loss : 0.028115, loss_ce: 0.011106
2021-12-13 00:11:22,853 iteration 2809 : loss : 0.027248, loss_ce: 0.009814
2021-12-13 00:11:24,294 iteration 2810 : loss : 0.036360, loss_ce: 0.015394
2021-12-13 00:11:25,844 iteration 2811 : loss : 0.036776, loss_ce: 0.012138
2021-12-13 00:11:27,405 iteration 2812 : loss : 0.034249, loss_ce: 0.014833
2021-12-13 00:11:28,784 iteration 2813 : loss : 0.026911, loss_ce: 0.011021
2021-12-13 00:11:30,263 iteration 2814 : loss : 0.047128, loss_ce: 0.023792
2021-12-13 00:11:31,784 iteration 2815 : loss : 0.033541, loss_ce: 0.012701
2021-12-13 00:11:33,229 iteration 2816 : loss : 0.028460, loss_ce: 0.010104
2021-12-13 00:11:34,675 iteration 2817 : loss : 0.042075, loss_ce: 0.015059
2021-12-13 00:11:36,239 iteration 2818 : loss : 0.051240, loss_ce: 0.018307
2021-12-13 00:11:37,782 iteration 2819 : loss : 0.032762, loss_ce: 0.013976
2021-12-13 00:11:39,229 iteration 2820 : loss : 0.030378, loss_ce: 0.012066
2021-12-13 00:11:40,705 iteration 2821 : loss : 0.025278, loss_ce: 0.010875
2021-12-13 00:11:42,214 iteration 2822 : loss : 0.066985, loss_ce: 0.016833
 42%|███████████▏               | 166/400 [1:16:24<1:47:38, 27.60s/it]2021-12-13 00:11:43,771 iteration 2823 : loss : 0.034394, loss_ce: 0.011522
2021-12-13 00:11:45,271 iteration 2824 : loss : 0.038682, loss_ce: 0.011035
2021-12-13 00:11:46,762 iteration 2825 : loss : 0.051215, loss_ce: 0.017150
2021-12-13 00:11:48,186 iteration 2826 : loss : 0.032292, loss_ce: 0.011782
2021-12-13 00:11:49,710 iteration 2827 : loss : 0.027790, loss_ce: 0.011099
2021-12-13 00:11:51,152 iteration 2828 : loss : 0.041311, loss_ce: 0.016438
2021-12-13 00:11:52,589 iteration 2829 : loss : 0.032960, loss_ce: 0.009825
2021-12-13 00:11:54,075 iteration 2830 : loss : 0.033436, loss_ce: 0.016159
2021-12-13 00:11:55,528 iteration 2831 : loss : 0.051001, loss_ce: 0.016424
2021-12-13 00:11:56,932 iteration 2832 : loss : 0.028473, loss_ce: 0.012546
2021-12-13 00:11:58,464 iteration 2833 : loss : 0.031441, loss_ce: 0.013244
2021-12-13 00:11:59,943 iteration 2834 : loss : 0.036219, loss_ce: 0.014276
2021-12-13 00:12:01,430 iteration 2835 : loss : 0.034456, loss_ce: 0.013769
2021-12-13 00:12:02,921 iteration 2836 : loss : 0.037560, loss_ce: 0.015261
2021-12-13 00:12:04,437 iteration 2837 : loss : 0.032064, loss_ce: 0.011125
2021-12-13 00:12:05,941 iteration 2838 : loss : 0.036449, loss_ce: 0.014034
2021-12-13 00:12:07,346 iteration 2839 : loss : 0.028795, loss_ce: 0.012062
 42%|███████████▎               | 167/400 [1:16:49<1:44:18, 26.86s/it]2021-12-13 00:12:08,843 iteration 2840 : loss : 0.036560, loss_ce: 0.013200
2021-12-13 00:12:10,269 iteration 2841 : loss : 0.029389, loss_ce: 0.013121
2021-12-13 00:12:11,675 iteration 2842 : loss : 0.024753, loss_ce: 0.009856
2021-12-13 00:12:13,134 iteration 2843 : loss : 0.030770, loss_ce: 0.010920
2021-12-13 00:12:14,648 iteration 2844 : loss : 0.037705, loss_ce: 0.016791
2021-12-13 00:12:16,178 iteration 2845 : loss : 0.042149, loss_ce: 0.016148
2021-12-13 00:12:17,632 iteration 2846 : loss : 0.031066, loss_ce: 0.011680
2021-12-13 00:12:19,113 iteration 2847 : loss : 0.038390, loss_ce: 0.016197
2021-12-13 00:12:20,678 iteration 2848 : loss : 0.043048, loss_ce: 0.020030
2021-12-13 00:12:22,126 iteration 2849 : loss : 0.039856, loss_ce: 0.014111
2021-12-13 00:12:23,552 iteration 2850 : loss : 0.029294, loss_ce: 0.010512
2021-12-13 00:12:25,018 iteration 2851 : loss : 0.029171, loss_ce: 0.013389
2021-12-13 00:12:26,494 iteration 2852 : loss : 0.044734, loss_ce: 0.017532
2021-12-13 00:12:27,925 iteration 2853 : loss : 0.030067, loss_ce: 0.011971
2021-12-13 00:12:29,429 iteration 2854 : loss : 0.031409, loss_ce: 0.014415
2021-12-13 00:12:30,893 iteration 2855 : loss : 0.037348, loss_ce: 0.015265
2021-12-13 00:12:32,421 iteration 2856 : loss : 0.035017, loss_ce: 0.013316
 42%|███████████▎               | 168/400 [1:17:14<1:41:47, 26.32s/it]2021-12-13 00:12:33,989 iteration 2857 : loss : 0.050674, loss_ce: 0.012352
2021-12-13 00:12:35,479 iteration 2858 : loss : 0.043861, loss_ce: 0.014153
2021-12-13 00:12:36,895 iteration 2859 : loss : 0.024371, loss_ce: 0.009422
2021-12-13 00:12:38,422 iteration 2860 : loss : 0.045950, loss_ce: 0.019726
2021-12-13 00:12:39,855 iteration 2861 : loss : 0.030929, loss_ce: 0.012280
2021-12-13 00:12:41,350 iteration 2862 : loss : 0.034567, loss_ce: 0.012830
2021-12-13 00:12:42,882 iteration 2863 : loss : 0.056619, loss_ce: 0.018294
2021-12-13 00:12:44,362 iteration 2864 : loss : 0.026344, loss_ce: 0.011897
2021-12-13 00:12:45,770 iteration 2865 : loss : 0.026257, loss_ce: 0.009921
2021-12-13 00:12:47,213 iteration 2866 : loss : 0.036988, loss_ce: 0.011714
2021-12-13 00:12:48,735 iteration 2867 : loss : 0.044252, loss_ce: 0.018075
2021-12-13 00:12:50,243 iteration 2868 : loss : 0.026841, loss_ce: 0.011244
2021-12-13 00:12:51,673 iteration 2869 : loss : 0.030763, loss_ce: 0.014877
2021-12-13 00:12:53,146 iteration 2870 : loss : 0.035190, loss_ce: 0.018197
2021-12-13 00:12:54,526 iteration 2871 : loss : 0.025010, loss_ce: 0.012134
2021-12-13 00:12:55,985 iteration 2872 : loss : 0.047210, loss_ce: 0.016600
2021-12-13 00:12:57,492 iteration 2873 : loss : 0.039524, loss_ce: 0.017669
 42%|███████████▍               | 169/400 [1:17:39<1:39:54, 25.95s/it]2021-12-13 00:12:58,969 iteration 2874 : loss : 0.031262, loss_ce: 0.009104
2021-12-13 00:13:00,349 iteration 2875 : loss : 0.024245, loss_ce: 0.010643
2021-12-13 00:13:01,796 iteration 2876 : loss : 0.026875, loss_ce: 0.011872
2021-12-13 00:13:03,269 iteration 2877 : loss : 0.040088, loss_ce: 0.013892
2021-12-13 00:13:04,760 iteration 2878 : loss : 0.042574, loss_ce: 0.017339
2021-12-13 00:13:06,168 iteration 2879 : loss : 0.031347, loss_ce: 0.015562
2021-12-13 00:13:07,700 iteration 2880 : loss : 0.041233, loss_ce: 0.017748
2021-12-13 00:13:09,151 iteration 2881 : loss : 0.034764, loss_ce: 0.014680
2021-12-13 00:13:10,708 iteration 2882 : loss : 0.057882, loss_ce: 0.017382
2021-12-13 00:13:12,256 iteration 2883 : loss : 0.045503, loss_ce: 0.020603
2021-12-13 00:13:13,818 iteration 2884 : loss : 0.039940, loss_ce: 0.013311
2021-12-13 00:13:15,298 iteration 2885 : loss : 0.035547, loss_ce: 0.016474
2021-12-13 00:13:16,726 iteration 2886 : loss : 0.034421, loss_ce: 0.010997
2021-12-13 00:13:18,184 iteration 2887 : loss : 0.040195, loss_ce: 0.014207
2021-12-13 00:13:19,748 iteration 2888 : loss : 0.037742, loss_ce: 0.013890
2021-12-13 00:13:21,229 iteration 2889 : loss : 0.047089, loss_ce: 0.018994
2021-12-13 00:13:21,229 Training Data Eval:
2021-12-13 00:13:28,749   Average segmentation loss on training set: 0.0201
2021-12-13 00:13:28,749 Validation Data Eval:
2021-12-13 00:13:31,344   Average segmentation loss on validation set: 0.0876
2021-12-13 00:13:32,851 iteration 2890 : loss : 0.040059, loss_ce: 0.016030
 42%|███████████▍               | 170/400 [1:18:14<1:50:17, 28.77s/it]2021-12-13 00:13:34,421 iteration 2891 : loss : 0.033674, loss_ce: 0.016627
2021-12-13 00:13:35,845 iteration 2892 : loss : 0.028859, loss_ce: 0.014608
2021-12-13 00:13:37,280 iteration 2893 : loss : 0.034913, loss_ce: 0.011632
2021-12-13 00:13:38,776 iteration 2894 : loss : 0.030507, loss_ce: 0.013949
2021-12-13 00:13:40,220 iteration 2895 : loss : 0.033032, loss_ce: 0.011975
2021-12-13 00:13:41,637 iteration 2896 : loss : 0.035242, loss_ce: 0.014716
2021-12-13 00:13:43,089 iteration 2897 : loss : 0.038815, loss_ce: 0.015604
2021-12-13 00:13:44,560 iteration 2898 : loss : 0.034393, loss_ce: 0.019792
2021-12-13 00:13:46,076 iteration 2899 : loss : 0.044987, loss_ce: 0.015765
2021-12-13 00:13:47,489 iteration 2900 : loss : 0.036153, loss_ce: 0.012354
2021-12-13 00:13:49,045 iteration 2901 : loss : 0.028889, loss_ce: 0.011195
2021-12-13 00:13:50,412 iteration 2902 : loss : 0.022893, loss_ce: 0.008369
2021-12-13 00:13:51,919 iteration 2903 : loss : 0.029042, loss_ce: 0.013830
2021-12-13 00:13:53,443 iteration 2904 : loss : 0.049047, loss_ce: 0.015514
2021-12-13 00:13:54,906 iteration 2905 : loss : 0.041592, loss_ce: 0.013698
2021-12-13 00:13:56,430 iteration 2906 : loss : 0.036932, loss_ce: 0.014232
2021-12-13 00:13:57,866 iteration 2907 : loss : 0.025137, loss_ce: 0.010442
 43%|███████████▌               | 171/400 [1:18:39<1:45:30, 27.64s/it]2021-12-13 00:13:59,372 iteration 2908 : loss : 0.041821, loss_ce: 0.017297
2021-12-13 00:14:00,770 iteration 2909 : loss : 0.037917, loss_ce: 0.010510
2021-12-13 00:14:02,268 iteration 2910 : loss : 0.037223, loss_ce: 0.013509
2021-12-13 00:14:03,740 iteration 2911 : loss : 0.036085, loss_ce: 0.014972
2021-12-13 00:14:05,198 iteration 2912 : loss : 0.030036, loss_ce: 0.010652
2021-12-13 00:14:06,705 iteration 2913 : loss : 0.032778, loss_ce: 0.012658
2021-12-13 00:14:08,185 iteration 2914 : loss : 0.038645, loss_ce: 0.015709
2021-12-13 00:14:09,703 iteration 2915 : loss : 0.032180, loss_ce: 0.012006
2021-12-13 00:14:11,115 iteration 2916 : loss : 0.026630, loss_ce: 0.013832
2021-12-13 00:14:12,642 iteration 2917 : loss : 0.043359, loss_ce: 0.017187
2021-12-13 00:14:14,139 iteration 2918 : loss : 0.032024, loss_ce: 0.011547
2021-12-13 00:14:15,644 iteration 2919 : loss : 0.040091, loss_ce: 0.016878
2021-12-13 00:14:17,136 iteration 2920 : loss : 0.040841, loss_ce: 0.011414
2021-12-13 00:14:18,689 iteration 2921 : loss : 0.031484, loss_ce: 0.010569
2021-12-13 00:14:20,147 iteration 2922 : loss : 0.029702, loss_ce: 0.011248
2021-12-13 00:14:21,655 iteration 2923 : loss : 0.041605, loss_ce: 0.020214
2021-12-13 00:14:23,108 iteration 2924 : loss : 0.035862, loss_ce: 0.012237
 43%|███████████▌               | 172/400 [1:19:05<1:42:19, 26.93s/it]2021-12-13 00:14:24,718 iteration 2925 : loss : 0.056591, loss_ce: 0.025240
2021-12-13 00:14:26,165 iteration 2926 : loss : 0.029538, loss_ce: 0.010056
2021-12-13 00:14:27,700 iteration 2927 : loss : 0.032884, loss_ce: 0.014725
2021-12-13 00:14:29,290 iteration 2928 : loss : 0.045816, loss_ce: 0.013788
2021-12-13 00:14:30,742 iteration 2929 : loss : 0.027866, loss_ce: 0.009846
2021-12-13 00:14:32,185 iteration 2930 : loss : 0.032612, loss_ce: 0.014665
2021-12-13 00:14:33,582 iteration 2931 : loss : 0.034630, loss_ce: 0.013558
2021-12-13 00:14:35,120 iteration 2932 : loss : 0.029848, loss_ce: 0.011698
2021-12-13 00:14:36,571 iteration 2933 : loss : 0.039145, loss_ce: 0.014726
2021-12-13 00:14:38,107 iteration 2934 : loss : 0.042146, loss_ce: 0.018029
2021-12-13 00:14:39,590 iteration 2935 : loss : 0.039888, loss_ce: 0.012478
2021-12-13 00:14:41,128 iteration 2936 : loss : 0.040204, loss_ce: 0.017780
2021-12-13 00:14:42,587 iteration 2937 : loss : 0.027545, loss_ce: 0.010963
2021-12-13 00:14:44,076 iteration 2938 : loss : 0.032804, loss_ce: 0.012134
2021-12-13 00:14:45,531 iteration 2939 : loss : 0.033716, loss_ce: 0.014738
2021-12-13 00:14:47,035 iteration 2940 : loss : 0.034841, loss_ce: 0.011881
2021-12-13 00:14:48,505 iteration 2941 : loss : 0.030023, loss_ce: 0.011867
 43%|███████████▋               | 173/400 [1:19:30<1:40:07, 26.47s/it]2021-12-13 00:14:50,051 iteration 2942 : loss : 0.040294, loss_ce: 0.015201
2021-12-13 00:14:51,436 iteration 2943 : loss : 0.026835, loss_ce: 0.010718
2021-12-13 00:14:52,846 iteration 2944 : loss : 0.044613, loss_ce: 0.013924
2021-12-13 00:14:54,362 iteration 2945 : loss : 0.038014, loss_ce: 0.016864
2021-12-13 00:14:55,792 iteration 2946 : loss : 0.029320, loss_ce: 0.012294
2021-12-13 00:14:57,209 iteration 2947 : loss : 0.021845, loss_ce: 0.007934
2021-12-13 00:14:58,674 iteration 2948 : loss : 0.037756, loss_ce: 0.015048
2021-12-13 00:15:00,187 iteration 2949 : loss : 0.026421, loss_ce: 0.009600
2021-12-13 00:15:01,643 iteration 2950 : loss : 0.031457, loss_ce: 0.014196
2021-12-13 00:15:03,061 iteration 2951 : loss : 0.033173, loss_ce: 0.012937
2021-12-13 00:15:04,531 iteration 2952 : loss : 0.030052, loss_ce: 0.008561
2021-12-13 00:15:06,006 iteration 2953 : loss : 0.036958, loss_ce: 0.013744
2021-12-13 00:15:07,502 iteration 2954 : loss : 0.052131, loss_ce: 0.015839
2021-12-13 00:15:08,929 iteration 2955 : loss : 0.027528, loss_ce: 0.013369
2021-12-13 00:15:10,386 iteration 2956 : loss : 0.029874, loss_ce: 0.013673
2021-12-13 00:15:11,852 iteration 2957 : loss : 0.043748, loss_ce: 0.010356
2021-12-13 00:15:13,316 iteration 2958 : loss : 0.044557, loss_ce: 0.012931
 44%|███████████▋               | 174/400 [1:19:55<1:37:48, 25.97s/it]2021-12-13 00:15:14,914 iteration 2959 : loss : 0.032688, loss_ce: 0.015178
2021-12-13 00:15:16,409 iteration 2960 : loss : 0.036549, loss_ce: 0.013138
2021-12-13 00:15:17,930 iteration 2961 : loss : 0.029232, loss_ce: 0.013379
2021-12-13 00:15:19,354 iteration 2962 : loss : 0.034292, loss_ce: 0.011535
2021-12-13 00:15:20,810 iteration 2963 : loss : 0.040448, loss_ce: 0.014783
2021-12-13 00:15:22,337 iteration 2964 : loss : 0.034333, loss_ce: 0.013164
2021-12-13 00:15:23,813 iteration 2965 : loss : 0.031278, loss_ce: 0.014335
2021-12-13 00:15:25,265 iteration 2966 : loss : 0.032311, loss_ce: 0.010633
2021-12-13 00:15:26,813 iteration 2967 : loss : 0.046213, loss_ce: 0.016919
2021-12-13 00:15:28,284 iteration 2968 : loss : 0.048283, loss_ce: 0.015764
2021-12-13 00:15:29,701 iteration 2969 : loss : 0.029253, loss_ce: 0.009548
2021-12-13 00:15:31,145 iteration 2970 : loss : 0.030932, loss_ce: 0.013246
2021-12-13 00:15:32,633 iteration 2971 : loss : 0.044304, loss_ce: 0.015229
2021-12-13 00:15:34,146 iteration 2972 : loss : 0.031244, loss_ce: 0.011611
2021-12-13 00:15:35,611 iteration 2973 : loss : 0.033463, loss_ce: 0.014198
2021-12-13 00:15:37,194 iteration 2974 : loss : 0.044163, loss_ce: 0.017718
2021-12-13 00:15:37,194 Training Data Eval:
2021-12-13 00:15:44,719   Average segmentation loss on training set: 0.0211
2021-12-13 00:15:44,719 Validation Data Eval:
2021-12-13 00:15:47,317   Average segmentation loss on validation set: 0.0832
2021-12-13 00:15:48,757 iteration 2975 : loss : 0.038215, loss_ce: 0.013555
 44%|███████████▊               | 175/400 [1:20:30<1:48:02, 28.81s/it]2021-12-13 00:15:50,311 iteration 2976 : loss : 0.043228, loss_ce: 0.017819
2021-12-13 00:15:51,907 iteration 2977 : loss : 0.042547, loss_ce: 0.015775
2021-12-13 00:15:53,384 iteration 2978 : loss : 0.044884, loss_ce: 0.017229
2021-12-13 00:15:54,927 iteration 2979 : loss : 0.051996, loss_ce: 0.013289
2021-12-13 00:15:56,551 iteration 2980 : loss : 0.056736, loss_ce: 0.022215
2021-12-13 00:15:58,022 iteration 2981 : loss : 0.028981, loss_ce: 0.012661
2021-12-13 00:15:59,487 iteration 2982 : loss : 0.040710, loss_ce: 0.015441
2021-12-13 00:16:00,997 iteration 2983 : loss : 0.033623, loss_ce: 0.008999
2021-12-13 00:16:02,495 iteration 2984 : loss : 0.033332, loss_ce: 0.015847
2021-12-13 00:16:03,976 iteration 2985 : loss : 0.030258, loss_ce: 0.013721
2021-12-13 00:16:05,436 iteration 2986 : loss : 0.027993, loss_ce: 0.010320
2021-12-13 00:16:06,884 iteration 2987 : loss : 0.030397, loss_ce: 0.011659
2021-12-13 00:16:08,389 iteration 2988 : loss : 0.034857, loss_ce: 0.013162
2021-12-13 00:16:09,827 iteration 2989 : loss : 0.029601, loss_ce: 0.010653
2021-12-13 00:16:11,302 iteration 2990 : loss : 0.046405, loss_ce: 0.019291
2021-12-13 00:16:12,732 iteration 2991 : loss : 0.026438, loss_ce: 0.008266
2021-12-13 00:16:14,236 iteration 2992 : loss : 0.039598, loss_ce: 0.017004
 44%|███████████▉               | 176/400 [1:20:56<1:43:49, 27.81s/it]2021-12-13 00:16:15,767 iteration 2993 : loss : 0.033178, loss_ce: 0.013509
2021-12-13 00:16:17,229 iteration 2994 : loss : 0.034709, loss_ce: 0.012945
2021-12-13 00:16:18,740 iteration 2995 : loss : 0.037791, loss_ce: 0.017056
2021-12-13 00:16:20,171 iteration 2996 : loss : 0.040067, loss_ce: 0.018066
2021-12-13 00:16:21,635 iteration 2997 : loss : 0.036862, loss_ce: 0.011791
2021-12-13 00:16:23,132 iteration 2998 : loss : 0.030116, loss_ce: 0.013200
2021-12-13 00:16:24,602 iteration 2999 : loss : 0.041564, loss_ce: 0.015307
2021-12-13 00:16:26,060 iteration 3000 : loss : 0.033767, loss_ce: 0.013344
2021-12-13 00:16:27,610 iteration 3001 : loss : 0.034631, loss_ce: 0.012287
2021-12-13 00:16:29,125 iteration 3002 : loss : 0.038873, loss_ce: 0.015867
2021-12-13 00:16:30,530 iteration 3003 : loss : 0.028208, loss_ce: 0.012861
2021-12-13 00:16:31,993 iteration 3004 : loss : 0.030490, loss_ce: 0.014629
2021-12-13 00:16:33,433 iteration 3005 : loss : 0.029794, loss_ce: 0.013307
2021-12-13 00:16:34,878 iteration 3006 : loss : 0.033648, loss_ce: 0.012968
2021-12-13 00:16:36,370 iteration 3007 : loss : 0.027233, loss_ce: 0.009135
2021-12-13 00:16:37,786 iteration 3008 : loss : 0.032096, loss_ce: 0.011455
2021-12-13 00:16:39,210 iteration 3009 : loss : 0.040303, loss_ce: 0.009376
 44%|███████████▉               | 177/400 [1:21:21<1:40:11, 26.96s/it]2021-12-13 00:16:40,802 iteration 3010 : loss : 0.048870, loss_ce: 0.013722
2021-12-13 00:16:42,255 iteration 3011 : loss : 0.044263, loss_ce: 0.012309
2021-12-13 00:16:43,684 iteration 3012 : loss : 0.032336, loss_ce: 0.011179
2021-12-13 00:16:45,233 iteration 3013 : loss : 0.029068, loss_ce: 0.011031
2021-12-13 00:16:46,731 iteration 3014 : loss : 0.035844, loss_ce: 0.015468
2021-12-13 00:16:48,219 iteration 3015 : loss : 0.047267, loss_ce: 0.014528
2021-12-13 00:16:49,615 iteration 3016 : loss : 0.027519, loss_ce: 0.009456
2021-12-13 00:16:51,144 iteration 3017 : loss : 0.047284, loss_ce: 0.024900
2021-12-13 00:16:52,699 iteration 3018 : loss : 0.038882, loss_ce: 0.019600
2021-12-13 00:16:54,316 iteration 3019 : loss : 0.052189, loss_ce: 0.020182
2021-12-13 00:16:55,765 iteration 3020 : loss : 0.038371, loss_ce: 0.012517
2021-12-13 00:16:57,229 iteration 3021 : loss : 0.025743, loss_ce: 0.011544
2021-12-13 00:16:58,624 iteration 3022 : loss : 0.027859, loss_ce: 0.014084
2021-12-13 00:17:00,057 iteration 3023 : loss : 0.030108, loss_ce: 0.011226
2021-12-13 00:17:01,532 iteration 3024 : loss : 0.043360, loss_ce: 0.019456
2021-12-13 00:17:03,007 iteration 3025 : loss : 0.030793, loss_ce: 0.012561
2021-12-13 00:17:04,434 iteration 3026 : loss : 0.035419, loss_ce: 0.010867
 44%|████████████               | 178/400 [1:21:46<1:37:49, 26.44s/it]2021-12-13 00:17:05,934 iteration 3027 : loss : 0.045881, loss_ce: 0.021145
2021-12-13 00:17:07,501 iteration 3028 : loss : 0.036693, loss_ce: 0.011900
2021-12-13 00:17:08,942 iteration 3029 : loss : 0.024674, loss_ce: 0.008752
2021-12-13 00:17:10,488 iteration 3030 : loss : 0.030838, loss_ce: 0.010585
2021-12-13 00:17:12,027 iteration 3031 : loss : 0.064130, loss_ce: 0.019815
2021-12-13 00:17:13,559 iteration 3032 : loss : 0.028320, loss_ce: 0.011183
2021-12-13 00:17:15,055 iteration 3033 : loss : 0.034169, loss_ce: 0.011956
2021-12-13 00:17:16,510 iteration 3034 : loss : 0.033833, loss_ce: 0.010479
2021-12-13 00:17:17,924 iteration 3035 : loss : 0.031651, loss_ce: 0.013739
2021-12-13 00:17:19,432 iteration 3036 : loss : 0.032117, loss_ce: 0.014730
2021-12-13 00:17:20,847 iteration 3037 : loss : 0.031522, loss_ce: 0.013250
2021-12-13 00:17:22,244 iteration 3038 : loss : 0.033872, loss_ce: 0.016048
2021-12-13 00:17:23,661 iteration 3039 : loss : 0.033743, loss_ce: 0.013663
2021-12-13 00:17:25,202 iteration 3040 : loss : 0.046008, loss_ce: 0.017085
2021-12-13 00:17:26,580 iteration 3041 : loss : 0.024473, loss_ce: 0.009540
2021-12-13 00:17:27,998 iteration 3042 : loss : 0.027630, loss_ce: 0.013298
2021-12-13 00:17:29,417 iteration 3043 : loss : 0.032969, loss_ce: 0.013870
 45%|████████████               | 179/400 [1:22:11<1:35:46, 26.00s/it]2021-12-13 00:17:30,951 iteration 3044 : loss : 0.026767, loss_ce: 0.010699
2021-12-13 00:17:32,345 iteration 3045 : loss : 0.031452, loss_ce: 0.011860
2021-12-13 00:17:33,900 iteration 3046 : loss : 0.038686, loss_ce: 0.017906
2021-12-13 00:17:35,470 iteration 3047 : loss : 0.039274, loss_ce: 0.013969
2021-12-13 00:17:36,974 iteration 3048 : loss : 0.032032, loss_ce: 0.011661
2021-12-13 00:17:38,478 iteration 3049 : loss : 0.026636, loss_ce: 0.009108
2021-12-13 00:17:39,993 iteration 3050 : loss : 0.033516, loss_ce: 0.009066
2021-12-13 00:17:41,550 iteration 3051 : loss : 0.027484, loss_ce: 0.011502
2021-12-13 00:17:43,059 iteration 3052 : loss : 0.035045, loss_ce: 0.016105
2021-12-13 00:17:44,458 iteration 3053 : loss : 0.023257, loss_ce: 0.008431
2021-12-13 00:17:45,888 iteration 3054 : loss : 0.030765, loss_ce: 0.013177
2021-12-13 00:17:47,290 iteration 3055 : loss : 0.038284, loss_ce: 0.016220
2021-12-13 00:17:48,690 iteration 3056 : loss : 0.022858, loss_ce: 0.008241
2021-12-13 00:17:50,272 iteration 3057 : loss : 0.042781, loss_ce: 0.017282
2021-12-13 00:17:51,703 iteration 3058 : loss : 0.030449, loss_ce: 0.012251
2021-12-13 00:17:53,137 iteration 3059 : loss : 0.025050, loss_ce: 0.013416
2021-12-13 00:17:53,138 Training Data Eval:
2021-12-13 00:18:00,663   Average segmentation loss on training set: 0.0192
2021-12-13 00:18:00,663 Validation Data Eval:
2021-12-13 00:18:03,261   Average segmentation loss on validation set: 0.0829
2021-12-13 00:18:04,781 iteration 3060 : loss : 0.036796, loss_ce: 0.014828
 45%|████████████▏              | 180/400 [1:22:46<1:45:38, 28.81s/it]2021-12-13 00:18:06,300 iteration 3061 : loss : 0.032121, loss_ce: 0.010433
2021-12-13 00:18:07,803 iteration 3062 : loss : 0.046292, loss_ce: 0.021107
2021-12-13 00:18:09,256 iteration 3063 : loss : 0.036556, loss_ce: 0.014929
2021-12-13 00:18:10,737 iteration 3064 : loss : 0.034255, loss_ce: 0.016855
2021-12-13 00:18:12,245 iteration 3065 : loss : 0.034043, loss_ce: 0.010103
2021-12-13 00:18:13,678 iteration 3066 : loss : 0.029350, loss_ce: 0.010225
2021-12-13 00:18:15,214 iteration 3067 : loss : 0.039920, loss_ce: 0.015900
2021-12-13 00:18:16,775 iteration 3068 : loss : 0.032248, loss_ce: 0.012211
2021-12-13 00:18:18,189 iteration 3069 : loss : 0.020242, loss_ce: 0.007431
2021-12-13 00:18:19,665 iteration 3070 : loss : 0.064818, loss_ce: 0.020627
2021-12-13 00:18:21,273 iteration 3071 : loss : 0.036958, loss_ce: 0.013358
2021-12-13 00:18:22,737 iteration 3072 : loss : 0.026109, loss_ce: 0.010908
2021-12-13 00:18:24,186 iteration 3073 : loss : 0.035336, loss_ce: 0.012191
2021-12-13 00:18:25,647 iteration 3074 : loss : 0.036255, loss_ce: 0.016423
2021-12-13 00:18:27,133 iteration 3075 : loss : 0.030863, loss_ce: 0.011378
2021-12-13 00:18:28,548 iteration 3076 : loss : 0.023909, loss_ce: 0.009548
2021-12-13 00:18:30,093 iteration 3077 : loss : 0.047439, loss_ce: 0.017240
 45%|████████████▏              | 181/400 [1:23:12<1:41:19, 27.76s/it]2021-12-13 00:18:31,652 iteration 3078 : loss : 0.057480, loss_ce: 0.010387
2021-12-13 00:18:33,104 iteration 3079 : loss : 0.041479, loss_ce: 0.013631
2021-12-13 00:18:34,561 iteration 3080 : loss : 0.027510, loss_ce: 0.009255
2021-12-13 00:18:36,036 iteration 3081 : loss : 0.034449, loss_ce: 0.013488
2021-12-13 00:18:37,515 iteration 3082 : loss : 0.031433, loss_ce: 0.011907
2021-12-13 00:18:39,004 iteration 3083 : loss : 0.030467, loss_ce: 0.011111
2021-12-13 00:18:40,503 iteration 3084 : loss : 0.039005, loss_ce: 0.015380
2021-12-13 00:18:41,910 iteration 3085 : loss : 0.028172, loss_ce: 0.010713
2021-12-13 00:18:43,363 iteration 3086 : loss : 0.032452, loss_ce: 0.015898
2021-12-13 00:18:44,882 iteration 3087 : loss : 0.037645, loss_ce: 0.013547
2021-12-13 00:18:46,348 iteration 3088 : loss : 0.037707, loss_ce: 0.015931
2021-12-13 00:18:47,898 iteration 3089 : loss : 0.050298, loss_ce: 0.016814
2021-12-13 00:18:49,309 iteration 3090 : loss : 0.033856, loss_ce: 0.012786
2021-12-13 00:18:50,821 iteration 3091 : loss : 0.035129, loss_ce: 0.013886
2021-12-13 00:18:52,252 iteration 3092 : loss : 0.029351, loss_ce: 0.013324
2021-12-13 00:18:53,672 iteration 3093 : loss : 0.025809, loss_ce: 0.010555
2021-12-13 00:18:55,130 iteration 3094 : loss : 0.043692, loss_ce: 0.011967
 46%|████████████▎              | 182/400 [1:23:37<1:37:53, 26.94s/it]2021-12-13 00:18:56,667 iteration 3095 : loss : 0.032233, loss_ce: 0.013983
2021-12-13 00:18:58,142 iteration 3096 : loss : 0.030937, loss_ce: 0.012587
2021-12-13 00:18:59,638 iteration 3097 : loss : 0.030549, loss_ce: 0.014330
2021-12-13 00:19:01,154 iteration 3098 : loss : 0.044962, loss_ce: 0.014525
2021-12-13 00:19:02,666 iteration 3099 : loss : 0.036200, loss_ce: 0.015819
2021-12-13 00:19:04,143 iteration 3100 : loss : 0.038449, loss_ce: 0.015494
2021-12-13 00:19:05,577 iteration 3101 : loss : 0.023435, loss_ce: 0.009500
2021-12-13 00:19:06,972 iteration 3102 : loss : 0.027718, loss_ce: 0.011432
2021-12-13 00:19:08,477 iteration 3103 : loss : 0.039372, loss_ce: 0.018116
2021-12-13 00:19:09,944 iteration 3104 : loss : 0.027246, loss_ce: 0.008842
2021-12-13 00:19:11,460 iteration 3105 : loss : 0.028884, loss_ce: 0.011940
2021-12-13 00:19:12,947 iteration 3106 : loss : 0.030546, loss_ce: 0.012209
2021-12-13 00:19:14,479 iteration 3107 : loss : 0.037824, loss_ce: 0.013693
2021-12-13 00:19:15,984 iteration 3108 : loss : 0.051288, loss_ce: 0.019415
2021-12-13 00:19:17,387 iteration 3109 : loss : 0.030754, loss_ce: 0.015770
2021-12-13 00:19:18,829 iteration 3110 : loss : 0.032520, loss_ce: 0.011879
2021-12-13 00:19:20,304 iteration 3111 : loss : 0.041119, loss_ce: 0.011252
 46%|████████████▎              | 183/400 [1:24:02<1:35:32, 26.41s/it]2021-12-13 00:19:21,769 iteration 3112 : loss : 0.026287, loss_ce: 0.010169
2021-12-13 00:19:23,269 iteration 3113 : loss : 0.035291, loss_ce: 0.013349
2021-12-13 00:19:24,698 iteration 3114 : loss : 0.031096, loss_ce: 0.014553
2021-12-13 00:19:26,190 iteration 3115 : loss : 0.030738, loss_ce: 0.013071
2021-12-13 00:19:27,591 iteration 3116 : loss : 0.026494, loss_ce: 0.010999
2021-12-13 00:19:29,144 iteration 3117 : loss : 0.046557, loss_ce: 0.010584
2021-12-13 00:19:30,631 iteration 3118 : loss : 0.031652, loss_ce: 0.014132
2021-12-13 00:19:32,117 iteration 3119 : loss : 0.029298, loss_ce: 0.013422
2021-12-13 00:19:33,531 iteration 3120 : loss : 0.031804, loss_ce: 0.010409
2021-12-13 00:19:35,031 iteration 3121 : loss : 0.047817, loss_ce: 0.014516
2021-12-13 00:19:36,490 iteration 3122 : loss : 0.036690, loss_ce: 0.017371
2021-12-13 00:19:38,072 iteration 3123 : loss : 0.041495, loss_ce: 0.015713
2021-12-13 00:19:39,509 iteration 3124 : loss : 0.035554, loss_ce: 0.013225
2021-12-13 00:19:40,942 iteration 3125 : loss : 0.023877, loss_ce: 0.010372
2021-12-13 00:19:42,374 iteration 3126 : loss : 0.035534, loss_ce: 0.013197
2021-12-13 00:19:43,822 iteration 3127 : loss : 0.033907, loss_ce: 0.016707
2021-12-13 00:19:45,289 iteration 3128 : loss : 0.040006, loss_ce: 0.011977
 46%|████████████▍              | 184/400 [1:24:27<1:33:32, 25.99s/it]2021-12-13 00:19:46,768 iteration 3129 : loss : 0.039933, loss_ce: 0.013625
2021-12-13 00:19:48,199 iteration 3130 : loss : 0.029874, loss_ce: 0.011649
2021-12-13 00:19:49,716 iteration 3131 : loss : 0.036638, loss_ce: 0.017695
2021-12-13 00:19:51,218 iteration 3132 : loss : 0.038791, loss_ce: 0.013648
2021-12-13 00:19:52,645 iteration 3133 : loss : 0.028105, loss_ce: 0.011525
2021-12-13 00:19:54,148 iteration 3134 : loss : 0.040564, loss_ce: 0.016251
2021-12-13 00:19:55,658 iteration 3135 : loss : 0.052150, loss_ce: 0.011684
2021-12-13 00:19:57,075 iteration 3136 : loss : 0.032219, loss_ce: 0.016742
2021-12-13 00:19:58,495 iteration 3137 : loss : 0.024286, loss_ce: 0.010682
2021-12-13 00:19:59,943 iteration 3138 : loss : 0.028269, loss_ce: 0.012141
2021-12-13 00:20:01,552 iteration 3139 : loss : 0.048481, loss_ce: 0.015111
2021-12-13 00:20:03,054 iteration 3140 : loss : 0.030757, loss_ce: 0.011227
2021-12-13 00:20:04,505 iteration 3141 : loss : 0.032521, loss_ce: 0.013612
2021-12-13 00:20:05,912 iteration 3142 : loss : 0.025901, loss_ce: 0.009100
2021-12-13 00:20:07,417 iteration 3143 : loss : 0.046254, loss_ce: 0.015049
2021-12-13 00:20:08,938 iteration 3144 : loss : 0.031888, loss_ce: 0.009219
2021-12-13 00:20:08,939 Training Data Eval:
2021-12-13 00:20:16,467   Average segmentation loss on training set: 0.0191
2021-12-13 00:20:16,467 Validation Data Eval:
2021-12-13 00:20:19,067   Average segmentation loss on validation set: 0.0821
2021-12-13 00:20:20,472 iteration 3145 : loss : 0.031221, loss_ce: 0.014755
 46%|████████████▍              | 185/400 [1:25:02<1:42:59, 28.74s/it]2021-12-13 00:20:22,071 iteration 3146 : loss : 0.036387, loss_ce: 0.015331
2021-12-13 00:20:23,616 iteration 3147 : loss : 0.058985, loss_ce: 0.023618
2021-12-13 00:20:25,026 iteration 3148 : loss : 0.030737, loss_ce: 0.010983
2021-12-13 00:20:26,498 iteration 3149 : loss : 0.037908, loss_ce: 0.010552
2021-12-13 00:20:27,974 iteration 3150 : loss : 0.038569, loss_ce: 0.011112
2021-12-13 00:20:29,361 iteration 3151 : loss : 0.028578, loss_ce: 0.013125
2021-12-13 00:20:30,869 iteration 3152 : loss : 0.028981, loss_ce: 0.014060
2021-12-13 00:20:32,318 iteration 3153 : loss : 0.031030, loss_ce: 0.013782
2021-12-13 00:20:33,797 iteration 3154 : loss : 0.041937, loss_ce: 0.012790
2021-12-13 00:20:35,276 iteration 3155 : loss : 0.026141, loss_ce: 0.009634
2021-12-13 00:20:36,771 iteration 3156 : loss : 0.032052, loss_ce: 0.011047
2021-12-13 00:20:38,172 iteration 3157 : loss : 0.031665, loss_ce: 0.010407
2021-12-13 00:20:39,717 iteration 3158 : loss : 0.027520, loss_ce: 0.010758
2021-12-13 00:20:41,182 iteration 3159 : loss : 0.037583, loss_ce: 0.015201
2021-12-13 00:20:42,637 iteration 3160 : loss : 0.031292, loss_ce: 0.013945
2021-12-13 00:20:44,188 iteration 3161 : loss : 0.035713, loss_ce: 0.012942
2021-12-13 00:20:45,768 iteration 3162 : loss : 0.031087, loss_ce: 0.014930
 46%|████████████▌              | 186/400 [1:25:27<1:38:49, 27.71s/it]2021-12-13 00:20:47,238 iteration 3163 : loss : 0.037418, loss_ce: 0.011845
2021-12-13 00:20:48,661 iteration 3164 : loss : 0.032449, loss_ce: 0.009417
2021-12-13 00:20:50,110 iteration 3165 : loss : 0.022983, loss_ce: 0.009913
2021-12-13 00:20:51,597 iteration 3166 : loss : 0.033926, loss_ce: 0.015563
2021-12-13 00:20:53,083 iteration 3167 : loss : 0.046940, loss_ce: 0.016045
2021-12-13 00:20:54,506 iteration 3168 : loss : 0.028454, loss_ce: 0.014097
2021-12-13 00:20:55,981 iteration 3169 : loss : 0.029034, loss_ce: 0.009956
2021-12-13 00:20:57,476 iteration 3170 : loss : 0.040068, loss_ce: 0.016679
2021-12-13 00:20:59,004 iteration 3171 : loss : 0.041265, loss_ce: 0.013779
2021-12-13 00:21:00,515 iteration 3172 : loss : 0.037966, loss_ce: 0.015004
2021-12-13 00:21:02,021 iteration 3173 : loss : 0.029620, loss_ce: 0.012230
2021-12-13 00:21:03,557 iteration 3174 : loss : 0.032090, loss_ce: 0.011357
2021-12-13 00:21:05,023 iteration 3175 : loss : 0.028023, loss_ce: 0.011342
2021-12-13 00:21:06,515 iteration 3176 : loss : 0.031313, loss_ce: 0.016292
2021-12-13 00:21:07,944 iteration 3177 : loss : 0.034986, loss_ce: 0.015799
2021-12-13 00:21:09,420 iteration 3178 : loss : 0.041967, loss_ce: 0.012895
2021-12-13 00:21:10,922 iteration 3179 : loss : 0.041542, loss_ce: 0.012004
 47%|████████████▌              | 187/400 [1:25:52<1:35:39, 26.94s/it]2021-12-13 00:21:12,504 iteration 3180 : loss : 0.027392, loss_ce: 0.011494
2021-12-13 00:21:13,988 iteration 3181 : loss : 0.031893, loss_ce: 0.014155
2021-12-13 00:21:15,504 iteration 3182 : loss : 0.039623, loss_ce: 0.014951
2021-12-13 00:21:17,021 iteration 3183 : loss : 0.031884, loss_ce: 0.013752
2021-12-13 00:21:18,414 iteration 3184 : loss : 0.033344, loss_ce: 0.014589
2021-12-13 00:21:19,827 iteration 3185 : loss : 0.035709, loss_ce: 0.014690
2021-12-13 00:21:21,259 iteration 3186 : loss : 0.027744, loss_ce: 0.014164
2021-12-13 00:21:22,672 iteration 3187 : loss : 0.024321, loss_ce: 0.009033
2021-12-13 00:21:24,135 iteration 3188 : loss : 0.032142, loss_ce: 0.010466
2021-12-13 00:21:25,544 iteration 3189 : loss : 0.022499, loss_ce: 0.010177
2021-12-13 00:21:27,056 iteration 3190 : loss : 0.042250, loss_ce: 0.014565
2021-12-13 00:21:28,558 iteration 3191 : loss : 0.033776, loss_ce: 0.011114
2021-12-13 00:21:30,018 iteration 3192 : loss : 0.025587, loss_ce: 0.010875
2021-12-13 00:21:31,441 iteration 3193 : loss : 0.029881, loss_ce: 0.013318
2021-12-13 00:21:32,840 iteration 3194 : loss : 0.032471, loss_ce: 0.010978
2021-12-13 00:21:34,288 iteration 3195 : loss : 0.032913, loss_ce: 0.011386
2021-12-13 00:21:35,812 iteration 3196 : loss : 0.030583, loss_ce: 0.009723
 47%|████████████▋              | 188/400 [1:26:17<1:33:01, 26.33s/it]2021-12-13 00:21:37,306 iteration 3197 : loss : 0.026396, loss_ce: 0.009854
2021-12-13 00:21:38,726 iteration 3198 : loss : 0.029591, loss_ce: 0.012097
2021-12-13 00:21:40,131 iteration 3199 : loss : 0.026774, loss_ce: 0.010664
2021-12-13 00:21:41,556 iteration 3200 : loss : 0.029442, loss_ce: 0.012441
2021-12-13 00:21:43,047 iteration 3201 : loss : 0.040510, loss_ce: 0.015118
2021-12-13 00:21:44,535 iteration 3202 : loss : 0.032078, loss_ce: 0.012466
2021-12-13 00:21:45,931 iteration 3203 : loss : 0.045446, loss_ce: 0.010671
2021-12-13 00:21:47,411 iteration 3204 : loss : 0.032260, loss_ce: 0.014623
2021-12-13 00:21:48,902 iteration 3205 : loss : 0.031254, loss_ce: 0.010885
2021-12-13 00:21:50,329 iteration 3206 : loss : 0.030775, loss_ce: 0.013092
2021-12-13 00:21:51,741 iteration 3207 : loss : 0.023390, loss_ce: 0.007557
2021-12-13 00:21:53,167 iteration 3208 : loss : 0.033826, loss_ce: 0.011327
2021-12-13 00:21:54,670 iteration 3209 : loss : 0.028971, loss_ce: 0.011757
2021-12-13 00:21:56,143 iteration 3210 : loss : 0.046504, loss_ce: 0.015906
2021-12-13 00:21:57,658 iteration 3211 : loss : 0.035996, loss_ce: 0.017006
2021-12-13 00:21:59,163 iteration 3212 : loss : 0.030935, loss_ce: 0.013847
2021-12-13 00:22:00,622 iteration 3213 : loss : 0.031344, loss_ce: 0.014867
 47%|████████████▊              | 189/400 [1:26:42<1:30:59, 25.87s/it]2021-12-13 00:22:02,116 iteration 3214 : loss : 0.032801, loss_ce: 0.012811
2021-12-13 00:22:03,548 iteration 3215 : loss : 0.025508, loss_ce: 0.011052
2021-12-13 00:22:04,992 iteration 3216 : loss : 0.033828, loss_ce: 0.015936
2021-12-13 00:22:06,486 iteration 3217 : loss : 0.057265, loss_ce: 0.016709
2021-12-13 00:22:07,923 iteration 3218 : loss : 0.028612, loss_ce: 0.012844
2021-12-13 00:22:09,346 iteration 3219 : loss : 0.028409, loss_ce: 0.009829
2021-12-13 00:22:10,829 iteration 3220 : loss : 0.052665, loss_ce: 0.025841
2021-12-13 00:22:12,318 iteration 3221 : loss : 0.035573, loss_ce: 0.012742
2021-12-13 00:22:13,735 iteration 3222 : loss : 0.026747, loss_ce: 0.010627
2021-12-13 00:22:15,213 iteration 3223 : loss : 0.042899, loss_ce: 0.009745
2021-12-13 00:22:16,671 iteration 3224 : loss : 0.027070, loss_ce: 0.011140
2021-12-13 00:22:18,068 iteration 3225 : loss : 0.034720, loss_ce: 0.013392
2021-12-13 00:22:19,520 iteration 3226 : loss : 0.028412, loss_ce: 0.013162
2021-12-13 00:22:20,994 iteration 3227 : loss : 0.033326, loss_ce: 0.012375
2021-12-13 00:22:22,454 iteration 3228 : loss : 0.039204, loss_ce: 0.016683
2021-12-13 00:22:23,954 iteration 3229 : loss : 0.030249, loss_ce: 0.011173
2021-12-13 00:22:23,954 Training Data Eval:
2021-12-13 00:22:31,488   Average segmentation loss on training set: 0.0186
2021-12-13 00:22:31,489 Validation Data Eval:
2021-12-13 00:22:34,086   Average segmentation loss on validation set: 0.0867
2021-12-13 00:22:35,524 iteration 3230 : loss : 0.030789, loss_ce: 0.015604
 48%|████████████▊              | 190/400 [1:27:17<1:40:01, 28.58s/it]2021-12-13 00:22:36,931 iteration 3231 : loss : 0.027199, loss_ce: 0.010635
2021-12-13 00:22:38,402 iteration 3232 : loss : 0.029846, loss_ce: 0.012765
2021-12-13 00:22:39,875 iteration 3233 : loss : 0.035137, loss_ce: 0.010425
2021-12-13 00:22:41,301 iteration 3234 : loss : 0.024266, loss_ce: 0.010095
2021-12-13 00:22:42,778 iteration 3235 : loss : 0.030351, loss_ce: 0.012015
2021-12-13 00:22:44,133 iteration 3236 : loss : 0.027042, loss_ce: 0.012730
2021-12-13 00:22:45,567 iteration 3237 : loss : 0.025132, loss_ce: 0.009961
2021-12-13 00:22:47,026 iteration 3238 : loss : 0.037644, loss_ce: 0.014784
2021-12-13 00:22:48,404 iteration 3239 : loss : 0.028371, loss_ce: 0.012488
2021-12-13 00:22:49,902 iteration 3240 : loss : 0.034230, loss_ce: 0.013950
2021-12-13 00:22:51,450 iteration 3241 : loss : 0.036357, loss_ce: 0.012976
2021-12-13 00:22:52,937 iteration 3242 : loss : 0.028986, loss_ce: 0.011161
2021-12-13 00:22:54,448 iteration 3243 : loss : 0.036954, loss_ce: 0.018703
2021-12-13 00:22:55,872 iteration 3244 : loss : 0.036419, loss_ce: 0.013816
2021-12-13 00:22:57,353 iteration 3245 : loss : 0.033921, loss_ce: 0.010745
2021-12-13 00:22:58,852 iteration 3246 : loss : 0.034907, loss_ce: 0.011635
2021-12-13 00:23:00,425 iteration 3247 : loss : 0.050152, loss_ce: 0.015536
 48%|████████████▉              | 191/400 [1:27:42<1:35:42, 27.48s/it]2021-12-13 00:23:01,984 iteration 3248 : loss : 0.042804, loss_ce: 0.012056
2021-12-13 00:23:03,494 iteration 3249 : loss : 0.037957, loss_ce: 0.013572
2021-12-13 00:23:04,971 iteration 3250 : loss : 0.036520, loss_ce: 0.012923
2021-12-13 00:23:06,454 iteration 3251 : loss : 0.036021, loss_ce: 0.015504
2021-12-13 00:23:07,825 iteration 3252 : loss : 0.027583, loss_ce: 0.013417
2021-12-13 00:23:09,269 iteration 3253 : loss : 0.034314, loss_ce: 0.011663
2021-12-13 00:23:10,778 iteration 3254 : loss : 0.034946, loss_ce: 0.015913
2021-12-13 00:23:12,260 iteration 3255 : loss : 0.034841, loss_ce: 0.013820
2021-12-13 00:23:13,762 iteration 3256 : loss : 0.032366, loss_ce: 0.013345
2021-12-13 00:23:15,239 iteration 3257 : loss : 0.037225, loss_ce: 0.012881
2021-12-13 00:23:16,655 iteration 3258 : loss : 0.023693, loss_ce: 0.007099
2021-12-13 00:23:18,142 iteration 3259 : loss : 0.033672, loss_ce: 0.013069
2021-12-13 00:23:19,636 iteration 3260 : loss : 0.031247, loss_ce: 0.012596
2021-12-13 00:23:21,093 iteration 3261 : loss : 0.036057, loss_ce: 0.014881
2021-12-13 00:23:22,639 iteration 3262 : loss : 0.045562, loss_ce: 0.016218
2021-12-13 00:23:24,090 iteration 3263 : loss : 0.053639, loss_ce: 0.025217
2021-12-13 00:23:25,625 iteration 3264 : loss : 0.034548, loss_ce: 0.013123
 48%|████████████▉              | 192/400 [1:28:07<1:32:53, 26.79s/it]2021-12-13 00:23:27,103 iteration 3265 : loss : 0.042982, loss_ce: 0.017017
2021-12-13 00:23:28,598 iteration 3266 : loss : 0.034729, loss_ce: 0.012417
2021-12-13 00:23:30,076 iteration 3267 : loss : 0.025052, loss_ce: 0.009137
2021-12-13 00:23:31,553 iteration 3268 : loss : 0.034366, loss_ce: 0.012257
2021-12-13 00:23:32,979 iteration 3269 : loss : 0.030787, loss_ce: 0.015865
2021-12-13 00:23:34,447 iteration 3270 : loss : 0.033721, loss_ce: 0.012944
2021-12-13 00:23:35,889 iteration 3271 : loss : 0.031142, loss_ce: 0.010748
2021-12-13 00:23:37,425 iteration 3272 : loss : 0.043662, loss_ce: 0.018650
2021-12-13 00:23:38,882 iteration 3273 : loss : 0.029636, loss_ce: 0.012793
2021-12-13 00:23:40,287 iteration 3274 : loss : 0.030424, loss_ce: 0.010318
2021-12-13 00:23:41,726 iteration 3275 : loss : 0.033201, loss_ce: 0.011269
2021-12-13 00:23:43,167 iteration 3276 : loss : 0.034210, loss_ce: 0.009729
2021-12-13 00:23:44,566 iteration 3277 : loss : 0.026608, loss_ce: 0.009874
2021-12-13 00:23:46,015 iteration 3278 : loss : 0.028405, loss_ce: 0.011067
2021-12-13 00:23:47,377 iteration 3279 : loss : 0.028580, loss_ce: 0.016938
2021-12-13 00:23:48,906 iteration 3280 : loss : 0.030757, loss_ce: 0.012383
2021-12-13 00:23:50,372 iteration 3281 : loss : 0.023991, loss_ce: 0.007589
 48%|█████████████              | 193/400 [1:28:32<1:30:18, 26.18s/it]2021-12-13 00:23:51,910 iteration 3282 : loss : 0.034268, loss_ce: 0.008800
2021-12-13 00:23:53,411 iteration 3283 : loss : 0.038278, loss_ce: 0.013664
2021-12-13 00:23:54,892 iteration 3284 : loss : 0.029818, loss_ce: 0.011909
2021-12-13 00:23:56,402 iteration 3285 : loss : 0.038989, loss_ce: 0.014393
2021-12-13 00:23:57,865 iteration 3286 : loss : 0.033672, loss_ce: 0.010714
2021-12-13 00:23:59,411 iteration 3287 : loss : 0.030991, loss_ce: 0.013662
2021-12-13 00:24:00,821 iteration 3288 : loss : 0.036791, loss_ce: 0.014644
2021-12-13 00:24:02,406 iteration 3289 : loss : 0.028646, loss_ce: 0.011544
2021-12-13 00:24:03,934 iteration 3290 : loss : 0.030470, loss_ce: 0.010970
2021-12-13 00:24:05,470 iteration 3291 : loss : 0.037819, loss_ce: 0.019023
2021-12-13 00:24:06,935 iteration 3292 : loss : 0.032677, loss_ce: 0.011731
2021-12-13 00:24:08,407 iteration 3293 : loss : 0.051765, loss_ce: 0.012738
2021-12-13 00:24:09,966 iteration 3294 : loss : 0.040132, loss_ce: 0.016236
2021-12-13 00:24:11,472 iteration 3295 : loss : 0.029340, loss_ce: 0.012550
2021-12-13 00:24:12,891 iteration 3296 : loss : 0.031335, loss_ce: 0.011717
2021-12-13 00:24:14,343 iteration 3297 : loss : 0.030893, loss_ce: 0.012194
2021-12-13 00:24:15,903 iteration 3298 : loss : 0.028852, loss_ce: 0.012146
 48%|█████████████              | 194/400 [1:28:57<1:29:13, 25.99s/it]2021-12-13 00:24:17,338 iteration 3299 : loss : 0.029787, loss_ce: 0.008297
2021-12-13 00:24:18,851 iteration 3300 : loss : 0.031072, loss_ce: 0.011068
2021-12-13 00:24:20,344 iteration 3301 : loss : 0.032745, loss_ce: 0.014519
2021-12-13 00:24:21,788 iteration 3302 : loss : 0.034818, loss_ce: 0.011900
2021-12-13 00:24:23,320 iteration 3303 : loss : 0.034687, loss_ce: 0.016012
2021-12-13 00:24:24,830 iteration 3304 : loss : 0.032439, loss_ce: 0.012887
2021-12-13 00:24:26,299 iteration 3305 : loss : 0.028941, loss_ce: 0.010500
2021-12-13 00:24:27,758 iteration 3306 : loss : 0.032420, loss_ce: 0.009660
2021-12-13 00:24:29,350 iteration 3307 : loss : 0.043765, loss_ce: 0.017520
2021-12-13 00:24:30,886 iteration 3308 : loss : 0.046239, loss_ce: 0.020687
2021-12-13 00:24:32,422 iteration 3309 : loss : 0.029913, loss_ce: 0.014714
2021-12-13 00:24:33,848 iteration 3310 : loss : 0.026461, loss_ce: 0.013965
2021-12-13 00:24:35,390 iteration 3311 : loss : 0.049943, loss_ce: 0.015337
2021-12-13 00:24:36,860 iteration 3312 : loss : 0.031412, loss_ce: 0.009134
2021-12-13 00:24:38,416 iteration 3313 : loss : 0.036485, loss_ce: 0.015285
2021-12-13 00:24:39,889 iteration 3314 : loss : 0.033716, loss_ce: 0.011822
2021-12-13 00:24:39,889 Training Data Eval:
2021-12-13 00:24:47,417   Average segmentation loss on training set: 0.0184
2021-12-13 00:24:47,417 Validation Data Eval:
2021-12-13 00:24:50,010   Average segmentation loss on validation set: 0.0846
2021-12-13 00:24:51,419 iteration 3315 : loss : 0.028094, loss_ce: 0.010810
 49%|█████████████▏             | 195/400 [1:29:33<1:38:33, 28.85s/it]2021-12-13 00:24:52,884 iteration 3316 : loss : 0.026988, loss_ce: 0.012565
2021-12-13 00:24:54,375 iteration 3317 : loss : 0.028992, loss_ce: 0.013281
2021-12-13 00:24:55,827 iteration 3318 : loss : 0.036297, loss_ce: 0.016982
2021-12-13 00:24:57,244 iteration 3319 : loss : 0.031699, loss_ce: 0.011889
2021-12-13 00:24:58,793 iteration 3320 : loss : 0.042309, loss_ce: 0.016503
2021-12-13 00:25:00,232 iteration 3321 : loss : 0.027778, loss_ce: 0.010026
2021-12-13 00:25:01,750 iteration 3322 : loss : 0.034307, loss_ce: 0.009903
2021-12-13 00:25:03,169 iteration 3323 : loss : 0.027514, loss_ce: 0.009466
2021-12-13 00:25:04,627 iteration 3324 : loss : 0.036601, loss_ce: 0.015841
2021-12-13 00:25:06,124 iteration 3325 : loss : 0.037898, loss_ce: 0.014505
2021-12-13 00:25:07,547 iteration 3326 : loss : 0.034894, loss_ce: 0.013652
2021-12-13 00:25:09,009 iteration 3327 : loss : 0.025958, loss_ce: 0.008358
2021-12-13 00:25:10,555 iteration 3328 : loss : 0.033111, loss_ce: 0.012802
2021-12-13 00:25:12,022 iteration 3329 : loss : 0.039624, loss_ce: 0.015865
2021-12-13 00:25:13,460 iteration 3330 : loss : 0.026066, loss_ce: 0.013269
2021-12-13 00:25:14,852 iteration 3331 : loss : 0.026162, loss_ce: 0.011977
2021-12-13 00:25:16,341 iteration 3332 : loss : 0.032770, loss_ce: 0.010463
 49%|█████████████▏             | 196/400 [1:29:58<1:34:04, 27.67s/it]2021-12-13 00:25:17,879 iteration 3333 : loss : 0.037456, loss_ce: 0.013822
2021-12-13 00:25:19,376 iteration 3334 : loss : 0.035846, loss_ce: 0.017260
2021-12-13 00:25:20,931 iteration 3335 : loss : 0.033334, loss_ce: 0.013968
2021-12-13 00:25:22,417 iteration 3336 : loss : 0.045033, loss_ce: 0.014092
2021-12-13 00:25:23,932 iteration 3337 : loss : 0.052295, loss_ce: 0.019531
2021-12-13 00:25:25,514 iteration 3338 : loss : 0.039888, loss_ce: 0.016713
2021-12-13 00:25:26,937 iteration 3339 : loss : 0.025384, loss_ce: 0.010064
2021-12-13 00:25:28,340 iteration 3340 : loss : 0.030851, loss_ce: 0.008529
2021-12-13 00:25:29,801 iteration 3341 : loss : 0.040434, loss_ce: 0.014672
2021-12-13 00:25:31,245 iteration 3342 : loss : 0.031090, loss_ce: 0.014583
2021-12-13 00:25:32,741 iteration 3343 : loss : 0.029029, loss_ce: 0.012935
2021-12-13 00:25:34,213 iteration 3344 : loss : 0.036394, loss_ce: 0.013401
2021-12-13 00:25:35,694 iteration 3345 : loss : 0.031844, loss_ce: 0.012901
2021-12-13 00:25:37,129 iteration 3346 : loss : 0.028826, loss_ce: 0.013150
2021-12-13 00:25:38,568 iteration 3347 : loss : 0.035703, loss_ce: 0.014586
2021-12-13 00:25:39,962 iteration 3348 : loss : 0.025869, loss_ce: 0.010825
2021-12-13 00:25:41,487 iteration 3349 : loss : 0.038954, loss_ce: 0.010869
 49%|█████████████▎             | 197/400 [1:30:23<1:31:03, 26.91s/it]2021-12-13 00:25:43,000 iteration 3350 : loss : 0.040822, loss_ce: 0.016211
2021-12-13 00:25:44,535 iteration 3351 : loss : 0.038504, loss_ce: 0.012728
2021-12-13 00:25:46,044 iteration 3352 : loss : 0.040172, loss_ce: 0.015720
2021-12-13 00:25:47,596 iteration 3353 : loss : 0.033974, loss_ce: 0.011845
2021-12-13 00:25:49,045 iteration 3354 : loss : 0.026632, loss_ce: 0.011648
2021-12-13 00:25:50,596 iteration 3355 : loss : 0.039894, loss_ce: 0.016494
2021-12-13 00:25:52,117 iteration 3356 : loss : 0.029867, loss_ce: 0.010936
2021-12-13 00:25:53,572 iteration 3357 : loss : 0.042536, loss_ce: 0.010822
2021-12-13 00:25:55,085 iteration 3358 : loss : 0.024256, loss_ce: 0.010282
2021-12-13 00:25:56,497 iteration 3359 : loss : 0.034433, loss_ce: 0.012046
2021-12-13 00:25:57,941 iteration 3360 : loss : 0.033334, loss_ce: 0.012923
2021-12-13 00:25:59,405 iteration 3361 : loss : 0.034246, loss_ce: 0.012890
2021-12-13 00:26:00,863 iteration 3362 : loss : 0.036819, loss_ce: 0.013128
2021-12-13 00:26:02,400 iteration 3363 : loss : 0.043636, loss_ce: 0.013350
2021-12-13 00:26:03,808 iteration 3364 : loss : 0.027333, loss_ce: 0.012497
2021-12-13 00:26:05,307 iteration 3365 : loss : 0.039018, loss_ce: 0.016564
2021-12-13 00:26:06,697 iteration 3366 : loss : 0.031207, loss_ce: 0.014575
 50%|█████████████▎             | 198/400 [1:30:48<1:28:52, 26.40s/it]2021-12-13 00:26:08,208 iteration 3367 : loss : 0.028279, loss_ce: 0.011117
2021-12-13 00:26:09,648 iteration 3368 : loss : 0.024888, loss_ce: 0.011727
2021-12-13 00:26:11,047 iteration 3369 : loss : 0.033806, loss_ce: 0.011155
2021-12-13 00:26:12,583 iteration 3370 : loss : 0.040861, loss_ce: 0.018575
2021-12-13 00:26:14,165 iteration 3371 : loss : 0.051837, loss_ce: 0.023215
2021-12-13 00:26:15,592 iteration 3372 : loss : 0.023897, loss_ce: 0.009680
2021-12-13 00:26:17,070 iteration 3373 : loss : 0.025418, loss_ce: 0.008599
2021-12-13 00:26:18,497 iteration 3374 : loss : 0.026961, loss_ce: 0.010098
2021-12-13 00:26:19,922 iteration 3375 : loss : 0.035630, loss_ce: 0.013743
2021-12-13 00:26:21,393 iteration 3376 : loss : 0.033166, loss_ce: 0.010130
2021-12-13 00:26:22,759 iteration 3377 : loss : 0.021769, loss_ce: 0.009262
2021-12-13 00:26:24,245 iteration 3378 : loss : 0.039584, loss_ce: 0.009557
2021-12-13 00:26:25,801 iteration 3379 : loss : 0.043114, loss_ce: 0.017794
2021-12-13 00:26:27,314 iteration 3380 : loss : 0.050612, loss_ce: 0.017212
2021-12-13 00:26:28,820 iteration 3381 : loss : 0.045314, loss_ce: 0.015452
2021-12-13 00:26:30,304 iteration 3382 : loss : 0.036608, loss_ce: 0.014256
2021-12-13 00:26:31,740 iteration 3383 : loss : 0.025349, loss_ce: 0.009834
 50%|█████████████▍             | 199/400 [1:31:13<1:27:04, 25.99s/it]2021-12-13 00:26:33,317 iteration 3384 : loss : 0.038682, loss_ce: 0.012647
2021-12-13 00:26:34,824 iteration 3385 : loss : 0.039286, loss_ce: 0.014205
2021-12-13 00:26:36,250 iteration 3386 : loss : 0.022674, loss_ce: 0.008294
2021-12-13 00:26:37,785 iteration 3387 : loss : 0.032479, loss_ce: 0.013673
2021-12-13 00:26:39,282 iteration 3388 : loss : 0.033368, loss_ce: 0.014952
2021-12-13 00:26:40,723 iteration 3389 : loss : 0.020215, loss_ce: 0.008606
2021-12-13 00:26:42,077 iteration 3390 : loss : 0.020436, loss_ce: 0.008869
2021-12-13 00:26:43,583 iteration 3391 : loss : 0.035069, loss_ce: 0.014008
2021-12-13 00:26:45,084 iteration 3392 : loss : 0.041285, loss_ce: 0.012226
2021-12-13 00:26:46,583 iteration 3393 : loss : 0.031171, loss_ce: 0.012325
2021-12-13 00:26:48,084 iteration 3394 : loss : 0.037479, loss_ce: 0.012767
2021-12-13 00:26:49,489 iteration 3395 : loss : 0.025854, loss_ce: 0.010827
2021-12-13 00:26:51,011 iteration 3396 : loss : 0.025455, loss_ce: 0.009170
2021-12-13 00:26:52,524 iteration 3397 : loss : 0.034518, loss_ce: 0.014103
2021-12-13 00:26:54,025 iteration 3398 : loss : 0.032851, loss_ce: 0.014502
2021-12-13 00:26:55,485 iteration 3399 : loss : 0.031073, loss_ce: 0.011540
2021-12-13 00:26:55,485 Training Data Eval:
2021-12-13 00:27:03,014   Average segmentation loss on training set: 0.0198
2021-12-13 00:27:03,014 Validation Data Eval:
2021-12-13 00:27:05,607   Average segmentation loss on validation set: 0.0786
2021-12-13 00:27:11,949 Found new lowest validation loss at iteration 3399! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/TU_3seeds/TU_SGD_best_val_loss_seed2.pth
2021-12-13 00:27:13,237 iteration 3400 : loss : 0.037670, loss_ce: 0.013480
 50%|█████████████▌             | 200/400 [1:31:55<1:42:09, 30.65s/it]2021-12-13 00:27:14,646 iteration 3401 : loss : 0.029375, loss_ce: 0.014722
2021-12-13 00:27:15,927 iteration 3402 : loss : 0.029138, loss_ce: 0.011764
2021-12-13 00:27:17,367 iteration 3403 : loss : 0.045937, loss_ce: 0.016550
2021-12-13 00:27:18,793 iteration 3404 : loss : 0.031577, loss_ce: 0.011476
2021-12-13 00:27:20,196 iteration 3405 : loss : 0.037491, loss_ce: 0.015068
2021-12-13 00:27:21,728 iteration 3406 : loss : 0.035001, loss_ce: 0.015690
2021-12-13 00:27:23,181 iteration 3407 : loss : 0.033671, loss_ce: 0.012790
2021-12-13 00:27:24,578 iteration 3408 : loss : 0.028684, loss_ce: 0.011098
2021-12-13 00:27:26,041 iteration 3409 : loss : 0.026275, loss_ce: 0.009384
2021-12-13 00:27:27,541 iteration 3410 : loss : 0.028461, loss_ce: 0.011567
2021-12-13 00:27:29,054 iteration 3411 : loss : 0.033246, loss_ce: 0.013539
2021-12-13 00:27:30,553 iteration 3412 : loss : 0.039385, loss_ce: 0.015148
2021-12-13 00:27:32,027 iteration 3413 : loss : 0.034938, loss_ce: 0.009211
2021-12-13 00:27:33,560 iteration 3414 : loss : 0.033954, loss_ce: 0.014625
2021-12-13 00:27:35,048 iteration 3415 : loss : 0.029437, loss_ce: 0.013855
2021-12-13 00:27:36,607 iteration 3416 : loss : 0.025618, loss_ce: 0.009680
2021-12-13 00:27:38,140 iteration 3417 : loss : 0.031396, loss_ce: 0.010719
 50%|█████████████▌             | 201/400 [1:32:20<1:35:54, 28.92s/it]2021-12-13 00:27:39,592 iteration 3418 : loss : 0.021591, loss_ce: 0.007921
2021-12-13 00:27:40,963 iteration 3419 : loss : 0.032102, loss_ce: 0.014241
2021-12-13 00:27:42,384 iteration 3420 : loss : 0.029556, loss_ce: 0.011079
2021-12-13 00:27:43,791 iteration 3421 : loss : 0.024228, loss_ce: 0.009656
2021-12-13 00:27:45,188 iteration 3422 : loss : 0.029241, loss_ce: 0.009968
2021-12-13 00:27:46,687 iteration 3423 : loss : 0.035212, loss_ce: 0.017644
2021-12-13 00:27:48,164 iteration 3424 : loss : 0.038534, loss_ce: 0.015528
2021-12-13 00:27:49,653 iteration 3425 : loss : 0.029529, loss_ce: 0.011797
2021-12-13 00:27:51,026 iteration 3426 : loss : 0.030438, loss_ce: 0.012254
2021-12-13 00:27:52,496 iteration 3427 : loss : 0.029734, loss_ce: 0.008849
2021-12-13 00:27:53,987 iteration 3428 : loss : 0.034837, loss_ce: 0.013313
2021-12-13 00:27:55,416 iteration 3429 : loss : 0.032895, loss_ce: 0.011424
2021-12-13 00:27:56,918 iteration 3430 : loss : 0.035045, loss_ce: 0.014748
2021-12-13 00:27:58,402 iteration 3431 : loss : 0.042589, loss_ce: 0.015000
2021-12-13 00:27:59,940 iteration 3432 : loss : 0.033296, loss_ce: 0.013571
2021-12-13 00:28:01,471 iteration 3433 : loss : 0.043457, loss_ce: 0.013654
2021-12-13 00:28:02,943 iteration 3434 : loss : 0.032844, loss_ce: 0.010536
 50%|█████████████▋             | 202/400 [1:32:44<1:31:21, 27.68s/it]2021-12-13 00:28:04,440 iteration 3435 : loss : 0.028413, loss_ce: 0.011251
2021-12-13 00:28:05,967 iteration 3436 : loss : 0.046099, loss_ce: 0.017871
2021-12-13 00:28:07,515 iteration 3437 : loss : 0.031582, loss_ce: 0.010527
2021-12-13 00:28:09,059 iteration 3438 : loss : 0.038324, loss_ce: 0.013895
2021-12-13 00:28:10,483 iteration 3439 : loss : 0.030018, loss_ce: 0.011540
2021-12-13 00:28:11,978 iteration 3440 : loss : 0.030643, loss_ce: 0.011975
2021-12-13 00:28:13,422 iteration 3441 : loss : 0.035265, loss_ce: 0.013720
2021-12-13 00:28:14,905 iteration 3442 : loss : 0.026816, loss_ce: 0.010869
2021-12-13 00:28:16,463 iteration 3443 : loss : 0.035382, loss_ce: 0.013922
2021-12-13 00:28:17,907 iteration 3444 : loss : 0.031506, loss_ce: 0.011175
2021-12-13 00:28:19,404 iteration 3445 : loss : 0.036767, loss_ce: 0.015343
2021-12-13 00:28:20,931 iteration 3446 : loss : 0.029246, loss_ce: 0.013223
2021-12-13 00:28:22,448 iteration 3447 : loss : 0.051731, loss_ce: 0.016027
2021-12-13 00:28:23,856 iteration 3448 : loss : 0.029265, loss_ce: 0.012058
2021-12-13 00:28:25,288 iteration 3449 : loss : 0.033534, loss_ce: 0.013615
2021-12-13 00:28:26,748 iteration 3450 : loss : 0.028827, loss_ce: 0.010598
2021-12-13 00:28:28,196 iteration 3451 : loss : 0.022288, loss_ce: 0.012443
 51%|█████████████▋             | 203/400 [1:33:10<1:28:30, 26.96s/it]2021-12-13 00:28:29,623 iteration 3452 : loss : 0.027681, loss_ce: 0.012398
2021-12-13 00:28:31,136 iteration 3453 : loss : 0.028382, loss_ce: 0.010760
2021-12-13 00:28:32,763 iteration 3454 : loss : 0.038155, loss_ce: 0.015176
2021-12-13 00:28:34,218 iteration 3455 : loss : 0.032957, loss_ce: 0.013871
2021-12-13 00:28:35,709 iteration 3456 : loss : 0.047618, loss_ce: 0.013014
2021-12-13 00:28:37,130 iteration 3457 : loss : 0.028452, loss_ce: 0.012188
2021-12-13 00:28:38,535 iteration 3458 : loss : 0.036389, loss_ce: 0.011017
2021-12-13 00:28:40,058 iteration 3459 : loss : 0.030791, loss_ce: 0.013576
2021-12-13 00:28:41,471 iteration 3460 : loss : 0.023905, loss_ce: 0.010240
2021-12-13 00:28:42,887 iteration 3461 : loss : 0.026451, loss_ce: 0.009653
2021-12-13 00:28:44,238 iteration 3462 : loss : 0.023231, loss_ce: 0.011111
2021-12-13 00:28:45,737 iteration 3463 : loss : 0.029623, loss_ce: 0.012926
2021-12-13 00:28:47,220 iteration 3464 : loss : 0.030168, loss_ce: 0.010272
2021-12-13 00:28:48,647 iteration 3465 : loss : 0.026803, loss_ce: 0.010439
2021-12-13 00:28:50,189 iteration 3466 : loss : 0.042218, loss_ce: 0.017550
2021-12-13 00:28:51,581 iteration 3467 : loss : 0.024640, loss_ce: 0.010124
2021-12-13 00:28:53,026 iteration 3468 : loss : 0.030115, loss_ce: 0.009759
 51%|█████████████▊             | 204/400 [1:33:34<1:25:58, 26.32s/it]2021-12-13 00:28:54,507 iteration 3469 : loss : 0.034381, loss_ce: 0.014889
2021-12-13 00:28:55,956 iteration 3470 : loss : 0.035637, loss_ce: 0.013955
2021-12-13 00:28:57,489 iteration 3471 : loss : 0.036049, loss_ce: 0.012993
2021-12-13 00:28:59,045 iteration 3472 : loss : 0.039910, loss_ce: 0.014445
2021-12-13 00:29:00,469 iteration 3473 : loss : 0.024777, loss_ce: 0.012067
2021-12-13 00:29:01,989 iteration 3474 : loss : 0.035610, loss_ce: 0.013879
2021-12-13 00:29:03,464 iteration 3475 : loss : 0.029911, loss_ce: 0.013009
2021-12-13 00:29:04,913 iteration 3476 : loss : 0.028706, loss_ce: 0.010617
2021-12-13 00:29:06,367 iteration 3477 : loss : 0.023452, loss_ce: 0.008276
2021-12-13 00:29:07,843 iteration 3478 : loss : 0.030949, loss_ce: 0.014192
2021-12-13 00:29:09,303 iteration 3479 : loss : 0.038992, loss_ce: 0.016733
2021-12-13 00:29:10,721 iteration 3480 : loss : 0.027843, loss_ce: 0.012797
2021-12-13 00:29:12,149 iteration 3481 : loss : 0.037596, loss_ce: 0.010679
2021-12-13 00:29:13,601 iteration 3482 : loss : 0.026539, loss_ce: 0.010741
2021-12-13 00:29:15,131 iteration 3483 : loss : 0.036697, loss_ce: 0.015152
2021-12-13 00:29:16,626 iteration 3484 : loss : 0.029307, loss_ce: 0.010311
2021-12-13 00:29:16,626 Training Data Eval:
2021-12-13 00:29:24,161   Average segmentation loss on training set: 0.0202
2021-12-13 00:29:24,162 Validation Data Eval:
2021-12-13 00:29:26,756   Average segmentation loss on validation set: 0.0865
2021-12-13 00:29:28,202 iteration 3485 : loss : 0.025317, loss_ce: 0.010136
 51%|█████████████▊             | 205/400 [1:34:10<1:34:10, 28.98s/it]2021-12-13 00:29:29,728 iteration 3486 : loss : 0.034327, loss_ce: 0.009852
2021-12-13 00:29:31,188 iteration 3487 : loss : 0.034866, loss_ce: 0.016134
2021-12-13 00:29:32,646 iteration 3488 : loss : 0.028521, loss_ce: 0.009194
2021-12-13 00:29:33,998 iteration 3489 : loss : 0.026222, loss_ce: 0.011831
2021-12-13 00:29:35,499 iteration 3490 : loss : 0.037426, loss_ce: 0.014926
2021-12-13 00:29:37,091 iteration 3491 : loss : 0.037327, loss_ce: 0.016822
2021-12-13 00:29:38,575 iteration 3492 : loss : 0.023500, loss_ce: 0.007834
2021-12-13 00:29:40,018 iteration 3493 : loss : 0.036844, loss_ce: 0.013371
2021-12-13 00:29:41,495 iteration 3494 : loss : 0.030360, loss_ce: 0.011775
2021-12-13 00:29:43,012 iteration 3495 : loss : 0.028738, loss_ce: 0.009894
2021-12-13 00:29:44,591 iteration 3496 : loss : 0.046569, loss_ce: 0.017393
2021-12-13 00:29:46,057 iteration 3497 : loss : 0.023528, loss_ce: 0.010297
2021-12-13 00:29:47,574 iteration 3498 : loss : 0.027209, loss_ce: 0.011646
2021-12-13 00:29:49,030 iteration 3499 : loss : 0.032552, loss_ce: 0.017286
2021-12-13 00:29:50,501 iteration 3500 : loss : 0.027813, loss_ce: 0.012399
2021-12-13 00:29:52,056 iteration 3501 : loss : 0.029337, loss_ce: 0.011336
2021-12-13 00:29:53,522 iteration 3502 : loss : 0.031675, loss_ce: 0.016386
 52%|█████████████▉             | 206/400 [1:34:35<1:30:08, 27.88s/it]2021-12-13 00:29:55,072 iteration 3503 : loss : 0.036053, loss_ce: 0.010805
2021-12-13 00:29:56,536 iteration 3504 : loss : 0.027688, loss_ce: 0.010960
2021-12-13 00:29:58,002 iteration 3505 : loss : 0.025116, loss_ce: 0.010471
2021-12-13 00:29:59,522 iteration 3506 : loss : 0.038960, loss_ce: 0.013163
2021-12-13 00:30:00,945 iteration 3507 : loss : 0.032391, loss_ce: 0.012263
2021-12-13 00:30:02,402 iteration 3508 : loss : 0.036094, loss_ce: 0.009521
2021-12-13 00:30:03,912 iteration 3509 : loss : 0.043070, loss_ce: 0.018600
2021-12-13 00:30:05,374 iteration 3510 : loss : 0.026375, loss_ce: 0.010516
2021-12-13 00:30:07,057 iteration 3511 : loss : 0.036551, loss_ce: 0.017901
2021-12-13 00:30:08,474 iteration 3512 : loss : 0.023293, loss_ce: 0.009526
2021-12-13 00:30:09,857 iteration 3513 : loss : 0.030925, loss_ce: 0.012266
2021-12-13 00:30:11,315 iteration 3514 : loss : 0.030347, loss_ce: 0.013749
2021-12-13 00:30:12,766 iteration 3515 : loss : 0.035923, loss_ce: 0.017531
2021-12-13 00:30:14,208 iteration 3516 : loss : 0.023441, loss_ce: 0.010965
2021-12-13 00:30:15,670 iteration 3517 : loss : 0.031820, loss_ce: 0.014985
2021-12-13 00:30:17,236 iteration 3518 : loss : 0.035449, loss_ce: 0.009803
2021-12-13 00:30:18,754 iteration 3519 : loss : 0.029723, loss_ce: 0.012979
 52%|█████████████▉             | 207/400 [1:35:00<1:27:07, 27.08s/it]2021-12-13 00:30:20,195 iteration 3520 : loss : 0.028611, loss_ce: 0.011439
2021-12-13 00:30:21,646 iteration 3521 : loss : 0.034106, loss_ce: 0.008899
2021-12-13 00:30:23,072 iteration 3522 : loss : 0.030514, loss_ce: 0.008779
2021-12-13 00:30:24,566 iteration 3523 : loss : 0.030488, loss_ce: 0.015776
2021-12-13 00:30:26,111 iteration 3524 : loss : 0.036146, loss_ce: 0.015464
2021-12-13 00:30:27,550 iteration 3525 : loss : 0.028149, loss_ce: 0.009153
2021-12-13 00:30:29,047 iteration 3526 : loss : 0.029798, loss_ce: 0.014694
2021-12-13 00:30:30,598 iteration 3527 : loss : 0.031257, loss_ce: 0.012768
2021-12-13 00:30:32,049 iteration 3528 : loss : 0.042473, loss_ce: 0.010373
2021-12-13 00:30:33,507 iteration 3529 : loss : 0.029015, loss_ce: 0.010986
2021-12-13 00:30:34,966 iteration 3530 : loss : 0.027063, loss_ce: 0.010674
2021-12-13 00:30:36,428 iteration 3531 : loss : 0.032232, loss_ce: 0.012437
2021-12-13 00:30:37,915 iteration 3532 : loss : 0.032180, loss_ce: 0.014879
2021-12-13 00:30:39,420 iteration 3533 : loss : 0.038070, loss_ce: 0.014641
2021-12-13 00:30:40,828 iteration 3534 : loss : 0.034811, loss_ce: 0.013077
2021-12-13 00:30:42,312 iteration 3535 : loss : 0.032522, loss_ce: 0.012683
2021-12-13 00:30:43,766 iteration 3536 : loss : 0.033880, loss_ce: 0.013618
 52%|██████████████             | 208/400 [1:35:25<1:24:40, 26.46s/it]2021-12-13 00:30:45,371 iteration 3537 : loss : 0.050836, loss_ce: 0.023876
2021-12-13 00:30:46,811 iteration 3538 : loss : 0.031172, loss_ce: 0.011934
2021-12-13 00:30:48,248 iteration 3539 : loss : 0.036808, loss_ce: 0.012530
2021-12-13 00:30:49,753 iteration 3540 : loss : 0.033486, loss_ce: 0.015162
2021-12-13 00:30:51,285 iteration 3541 : loss : 0.029738, loss_ce: 0.011345
2021-12-13 00:30:52,781 iteration 3542 : loss : 0.035262, loss_ce: 0.014822
2021-12-13 00:30:54,328 iteration 3543 : loss : 0.037008, loss_ce: 0.015555
2021-12-13 00:30:55,856 iteration 3544 : loss : 0.051586, loss_ce: 0.011984
2021-12-13 00:30:57,393 iteration 3545 : loss : 0.034400, loss_ce: 0.011176
2021-12-13 00:30:58,916 iteration 3546 : loss : 0.042184, loss_ce: 0.014584
2021-12-13 00:31:00,459 iteration 3547 : loss : 0.038871, loss_ce: 0.013774
2021-12-13 00:31:01,890 iteration 3548 : loss : 0.019222, loss_ce: 0.006789
2021-12-13 00:31:03,461 iteration 3549 : loss : 0.048952, loss_ce: 0.021602
2021-12-13 00:31:04,916 iteration 3550 : loss : 0.024759, loss_ce: 0.009356
2021-12-13 00:31:06,350 iteration 3551 : loss : 0.032999, loss_ce: 0.014305
2021-12-13 00:31:07,770 iteration 3552 : loss : 0.032618, loss_ce: 0.015771
2021-12-13 00:31:09,221 iteration 3553 : loss : 0.023250, loss_ce: 0.008850
 52%|██████████████             | 209/400 [1:35:51<1:23:16, 26.16s/it]2021-12-13 00:31:10,726 iteration 3554 : loss : 0.029397, loss_ce: 0.011539
2021-12-13 00:31:12,184 iteration 3555 : loss : 0.032731, loss_ce: 0.015181
2021-12-13 00:31:13,725 iteration 3556 : loss : 0.040420, loss_ce: 0.019390
2021-12-13 00:31:15,298 iteration 3557 : loss : 0.044345, loss_ce: 0.018814
2021-12-13 00:31:16,762 iteration 3558 : loss : 0.040897, loss_ce: 0.013045
2021-12-13 00:31:18,248 iteration 3559 : loss : 0.043306, loss_ce: 0.012302
2021-12-13 00:31:19,714 iteration 3560 : loss : 0.031664, loss_ce: 0.012909
2021-12-13 00:31:21,099 iteration 3561 : loss : 0.025924, loss_ce: 0.012818
2021-12-13 00:31:22,581 iteration 3562 : loss : 0.037824, loss_ce: 0.015442
2021-12-13 00:31:24,059 iteration 3563 : loss : 0.034464, loss_ce: 0.012432
2021-12-13 00:31:25,577 iteration 3564 : loss : 0.043927, loss_ce: 0.012634
2021-12-13 00:31:26,999 iteration 3565 : loss : 0.030561, loss_ce: 0.008036
2021-12-13 00:31:28,415 iteration 3566 : loss : 0.032197, loss_ce: 0.012753
2021-12-13 00:31:29,963 iteration 3567 : loss : 0.038939, loss_ce: 0.018110
2021-12-13 00:31:31,434 iteration 3568 : loss : 0.037035, loss_ce: 0.012158
2021-12-13 00:31:32,858 iteration 3569 : loss : 0.035376, loss_ce: 0.013528
2021-12-13 00:31:32,858 Training Data Eval:
2021-12-13 00:31:40,387   Average segmentation loss on training set: 0.0195
2021-12-13 00:31:40,388 Validation Data Eval:
2021-12-13 00:31:42,983   Average segmentation loss on validation set: 0.0980
2021-12-13 00:31:44,477 iteration 3570 : loss : 0.036681, loss_ce: 0.011225
 52%|██████████████▏            | 210/400 [1:36:26<1:31:29, 28.89s/it]2021-12-13 00:31:46,015 iteration 3571 : loss : 0.029613, loss_ce: 0.014757
2021-12-13 00:31:47,437 iteration 3572 : loss : 0.025959, loss_ce: 0.009448
2021-12-13 00:31:48,922 iteration 3573 : loss : 0.041000, loss_ce: 0.014302
2021-12-13 00:31:50,390 iteration 3574 : loss : 0.027126, loss_ce: 0.008772
2021-12-13 00:31:51,807 iteration 3575 : loss : 0.026835, loss_ce: 0.009357
2021-12-13 00:31:53,320 iteration 3576 : loss : 0.037427, loss_ce: 0.010981
2021-12-13 00:31:54,810 iteration 3577 : loss : 0.037089, loss_ce: 0.015020
2021-12-13 00:31:56,184 iteration 3578 : loss : 0.033992, loss_ce: 0.012106
2021-12-13 00:31:57,620 iteration 3579 : loss : 0.033468, loss_ce: 0.013513
2021-12-13 00:31:59,036 iteration 3580 : loss : 0.031368, loss_ce: 0.013072
2021-12-13 00:32:00,444 iteration 3581 : loss : 0.034182, loss_ce: 0.017788
2021-12-13 00:32:01,896 iteration 3582 : loss : 0.026599, loss_ce: 0.010050
2021-12-13 00:32:03,401 iteration 3583 : loss : 0.038187, loss_ce: 0.013385
2021-12-13 00:32:04,879 iteration 3584 : loss : 0.030101, loss_ce: 0.010052
2021-12-13 00:32:06,296 iteration 3585 : loss : 0.039496, loss_ce: 0.014111
2021-12-13 00:32:07,822 iteration 3586 : loss : 0.038975, loss_ce: 0.019385
2021-12-13 00:32:09,277 iteration 3587 : loss : 0.024903, loss_ce: 0.010445
 53%|██████████████▏            | 211/400 [1:36:51<1:27:08, 27.66s/it]2021-12-13 00:32:10,851 iteration 3588 : loss : 0.027605, loss_ce: 0.012093
2021-12-13 00:32:12,255 iteration 3589 : loss : 0.025284, loss_ce: 0.009060
2021-12-13 00:32:13,687 iteration 3590 : loss : 0.026846, loss_ce: 0.010943
2021-12-13 00:32:15,151 iteration 3591 : loss : 0.035874, loss_ce: 0.013040
2021-12-13 00:32:16,781 iteration 3592 : loss : 0.037339, loss_ce: 0.014784
2021-12-13 00:32:18,231 iteration 3593 : loss : 0.040404, loss_ce: 0.013994
2021-12-13 00:32:19,703 iteration 3594 : loss : 0.027271, loss_ce: 0.010133
2021-12-13 00:32:21,198 iteration 3595 : loss : 0.039501, loss_ce: 0.015142
2021-12-13 00:32:22,664 iteration 3596 : loss : 0.022604, loss_ce: 0.008839
2021-12-13 00:32:24,176 iteration 3597 : loss : 0.032161, loss_ce: 0.013073
2021-12-13 00:32:25,598 iteration 3598 : loss : 0.027143, loss_ce: 0.011353
2021-12-13 00:32:27,103 iteration 3599 : loss : 0.037584, loss_ce: 0.012276
2021-12-13 00:32:28,460 iteration 3600 : loss : 0.025010, loss_ce: 0.010101
2021-12-13 00:32:29,919 iteration 3601 : loss : 0.028273, loss_ce: 0.011470
2021-12-13 00:32:31,324 iteration 3602 : loss : 0.026469, loss_ce: 0.009279
2021-12-13 00:32:32,801 iteration 3603 : loss : 0.028536, loss_ce: 0.014610
2021-12-13 00:32:34,197 iteration 3604 : loss : 0.028572, loss_ce: 0.011698
 53%|██████████████▎            | 212/400 [1:37:16<1:24:06, 26.84s/it]2021-12-13 00:32:35,717 iteration 3605 : loss : 0.030259, loss_ce: 0.011240
2021-12-13 00:32:37,156 iteration 3606 : loss : 0.029686, loss_ce: 0.013766
2021-12-13 00:32:38,643 iteration 3607 : loss : 0.037710, loss_ce: 0.014673
2021-12-13 00:32:40,091 iteration 3608 : loss : 0.030935, loss_ce: 0.011446
2021-12-13 00:32:41,524 iteration 3609 : loss : 0.026014, loss_ce: 0.011867
2021-12-13 00:32:42,988 iteration 3610 : loss : 0.027050, loss_ce: 0.010816
2021-12-13 00:32:44,385 iteration 3611 : loss : 0.024282, loss_ce: 0.007121
2021-12-13 00:32:45,796 iteration 3612 : loss : 0.028214, loss_ce: 0.009860
2021-12-13 00:32:47,354 iteration 3613 : loss : 0.037553, loss_ce: 0.014020
2021-12-13 00:32:48,770 iteration 3614 : loss : 0.026497, loss_ce: 0.010380
2021-12-13 00:32:50,143 iteration 3615 : loss : 0.024887, loss_ce: 0.009822
2021-12-13 00:32:51,618 iteration 3616 : loss : 0.032862, loss_ce: 0.013934
2021-12-13 00:32:53,117 iteration 3617 : loss : 0.040012, loss_ce: 0.016099
2021-12-13 00:32:54,593 iteration 3618 : loss : 0.026308, loss_ce: 0.010434
2021-12-13 00:32:56,061 iteration 3619 : loss : 0.034228, loss_ce: 0.010370
2021-12-13 00:32:57,480 iteration 3620 : loss : 0.032475, loss_ce: 0.010307
2021-12-13 00:32:58,954 iteration 3621 : loss : 0.039752, loss_ce: 0.014732
 53%|██████████████▍            | 213/400 [1:37:40<1:21:41, 26.21s/it]2021-12-13 00:33:00,460 iteration 3622 : loss : 0.029011, loss_ce: 0.013241
2021-12-13 00:33:01,981 iteration 3623 : loss : 0.031404, loss_ce: 0.008428
2021-12-13 00:33:03,442 iteration 3624 : loss : 0.024571, loss_ce: 0.010156
2021-12-13 00:33:04,890 iteration 3625 : loss : 0.025957, loss_ce: 0.010561
2021-12-13 00:33:06,304 iteration 3626 : loss : 0.032377, loss_ce: 0.014277
2021-12-13 00:33:07,704 iteration 3627 : loss : 0.024263, loss_ce: 0.009707
2021-12-13 00:33:09,216 iteration 3628 : loss : 0.039815, loss_ce: 0.012834
2021-12-13 00:33:10,830 iteration 3629 : loss : 0.031612, loss_ce: 0.013003
2021-12-13 00:33:12,213 iteration 3630 : loss : 0.029634, loss_ce: 0.010733
2021-12-13 00:33:13,679 iteration 3631 : loss : 0.035522, loss_ce: 0.011294
2021-12-13 00:33:15,268 iteration 3632 : loss : 0.038080, loss_ce: 0.013257
2021-12-13 00:33:16,731 iteration 3633 : loss : 0.022458, loss_ce: 0.008912
2021-12-13 00:33:18,174 iteration 3634 : loss : 0.031494, loss_ce: 0.012436
2021-12-13 00:33:19,731 iteration 3635 : loss : 0.049294, loss_ce: 0.022149
2021-12-13 00:33:21,258 iteration 3636 : loss : 0.040511, loss_ce: 0.012466
2021-12-13 00:33:22,734 iteration 3637 : loss : 0.048841, loss_ce: 0.015228
2021-12-13 00:33:24,191 iteration 3638 : loss : 0.028393, loss_ce: 0.012464
 54%|██████████████▍            | 214/400 [1:38:06<1:20:21, 25.92s/it]2021-12-13 00:33:25,649 iteration 3639 : loss : 0.028171, loss_ce: 0.011907
2021-12-13 00:33:27,055 iteration 3640 : loss : 0.027442, loss_ce: 0.011422
2021-12-13 00:33:28,460 iteration 3641 : loss : 0.024569, loss_ce: 0.008863
2021-12-13 00:33:29,925 iteration 3642 : loss : 0.040711, loss_ce: 0.011588
2021-12-13 00:33:31,334 iteration 3643 : loss : 0.029256, loss_ce: 0.011715
2021-12-13 00:33:32,753 iteration 3644 : loss : 0.021643, loss_ce: 0.008432
2021-12-13 00:33:34,217 iteration 3645 : loss : 0.037438, loss_ce: 0.013349
2021-12-13 00:33:35,676 iteration 3646 : loss : 0.036473, loss_ce: 0.014326
2021-12-13 00:33:37,145 iteration 3647 : loss : 0.034934, loss_ce: 0.009540
2021-12-13 00:33:38,634 iteration 3648 : loss : 0.037504, loss_ce: 0.015009
2021-12-13 00:33:40,076 iteration 3649 : loss : 0.024683, loss_ce: 0.007933
2021-12-13 00:33:41,546 iteration 3650 : loss : 0.030321, loss_ce: 0.015720
2021-12-13 00:33:43,032 iteration 3651 : loss : 0.031780, loss_ce: 0.012657
2021-12-13 00:33:44,621 iteration 3652 : loss : 0.038131, loss_ce: 0.012711
2021-12-13 00:33:46,045 iteration 3653 : loss : 0.029070, loss_ce: 0.015409
2021-12-13 00:33:47,441 iteration 3654 : loss : 0.026490, loss_ce: 0.013084
2021-12-13 00:33:47,441 Training Data Eval:
2021-12-13 00:33:54,971   Average segmentation loss on training set: 0.0193
2021-12-13 00:33:54,971 Validation Data Eval:
2021-12-13 00:33:57,579   Average segmentation loss on validation set: 0.0878
2021-12-13 00:33:59,057 iteration 3655 : loss : 0.027799, loss_ce: 0.011571
 54%|██████████████▌            | 215/400 [1:38:41<1:28:12, 28.61s/it]2021-12-13 00:34:00,608 iteration 3656 : loss : 0.026087, loss_ce: 0.009826
2021-12-13 00:34:02,027 iteration 3657 : loss : 0.031463, loss_ce: 0.015642
2021-12-13 00:34:03,563 iteration 3658 : loss : 0.031312, loss_ce: 0.014126
2021-12-13 00:34:05,157 iteration 3659 : loss : 0.044257, loss_ce: 0.018574
2021-12-13 00:34:06,649 iteration 3660 : loss : 0.036928, loss_ce: 0.008259
2021-12-13 00:34:08,056 iteration 3661 : loss : 0.027311, loss_ce: 0.011853
2021-12-13 00:34:09,530 iteration 3662 : loss : 0.030372, loss_ce: 0.012076
2021-12-13 00:34:10,989 iteration 3663 : loss : 0.042531, loss_ce: 0.014325
2021-12-13 00:34:12,483 iteration 3664 : loss : 0.023384, loss_ce: 0.008726
2021-12-13 00:34:13,941 iteration 3665 : loss : 0.028589, loss_ce: 0.014156
2021-12-13 00:34:15,411 iteration 3666 : loss : 0.026695, loss_ce: 0.009669
2021-12-13 00:34:16,865 iteration 3667 : loss : 0.033236, loss_ce: 0.014138
2021-12-13 00:34:18,247 iteration 3668 : loss : 0.025703, loss_ce: 0.006473
2021-12-13 00:34:19,763 iteration 3669 : loss : 0.037231, loss_ce: 0.017707
2021-12-13 00:34:21,178 iteration 3670 : loss : 0.024126, loss_ce: 0.009300
2021-12-13 00:34:22,627 iteration 3671 : loss : 0.022166, loss_ce: 0.010350
2021-12-13 00:34:24,244 iteration 3672 : loss : 0.065591, loss_ce: 0.016750
 54%|██████████████▌            | 216/400 [1:39:06<1:24:35, 27.58s/it]2021-12-13 00:34:25,800 iteration 3673 : loss : 0.027411, loss_ce: 0.011924
2021-12-13 00:34:27,339 iteration 3674 : loss : 0.032927, loss_ce: 0.009626
2021-12-13 00:34:28,911 iteration 3675 : loss : 0.034453, loss_ce: 0.010737
2021-12-13 00:34:30,319 iteration 3676 : loss : 0.027834, loss_ce: 0.011309
2021-12-13 00:34:31,812 iteration 3677 : loss : 0.034861, loss_ce: 0.012461
2021-12-13 00:34:33,368 iteration 3678 : loss : 0.048987, loss_ce: 0.016588
2021-12-13 00:34:34,841 iteration 3679 : loss : 0.028553, loss_ce: 0.010689
2021-12-13 00:34:36,330 iteration 3680 : loss : 0.037505, loss_ce: 0.013688
2021-12-13 00:34:37,798 iteration 3681 : loss : 0.027589, loss_ce: 0.012211
2021-12-13 00:34:39,188 iteration 3682 : loss : 0.025386, loss_ce: 0.009836
2021-12-13 00:34:40,572 iteration 3683 : loss : 0.028284, loss_ce: 0.010319
2021-12-13 00:34:42,104 iteration 3684 : loss : 0.023863, loss_ce: 0.009951
2021-12-13 00:34:43,543 iteration 3685 : loss : 0.025987, loss_ce: 0.010085
2021-12-13 00:34:45,036 iteration 3686 : loss : 0.030461, loss_ce: 0.011488
2021-12-13 00:34:46,475 iteration 3687 : loss : 0.030020, loss_ce: 0.010381
2021-12-13 00:34:47,943 iteration 3688 : loss : 0.025719, loss_ce: 0.013432
2021-12-13 00:34:49,432 iteration 3689 : loss : 0.039391, loss_ce: 0.011918
 54%|██████████████▋            | 217/400 [1:39:31<1:21:55, 26.86s/it]2021-12-13 00:34:50,948 iteration 3690 : loss : 0.036866, loss_ce: 0.009816
2021-12-13 00:34:52,450 iteration 3691 : loss : 0.048888, loss_ce: 0.012687
2021-12-13 00:34:53,941 iteration 3692 : loss : 0.031190, loss_ce: 0.015031
2021-12-13 00:34:55,356 iteration 3693 : loss : 0.024194, loss_ce: 0.010223
2021-12-13 00:34:56,826 iteration 3694 : loss : 0.032447, loss_ce: 0.015173
2021-12-13 00:34:58,306 iteration 3695 : loss : 0.027049, loss_ce: 0.014058
2021-12-13 00:34:59,765 iteration 3696 : loss : 0.037040, loss_ce: 0.012685
2021-12-13 00:35:01,263 iteration 3697 : loss : 0.032352, loss_ce: 0.011252
2021-12-13 00:35:02,830 iteration 3698 : loss : 0.045596, loss_ce: 0.019763
2021-12-13 00:35:04,251 iteration 3699 : loss : 0.030841, loss_ce: 0.012354
2021-12-13 00:35:05,731 iteration 3700 : loss : 0.031109, loss_ce: 0.010584
2021-12-13 00:35:07,110 iteration 3701 : loss : 0.025238, loss_ce: 0.011992
2021-12-13 00:35:08,598 iteration 3702 : loss : 0.030004, loss_ce: 0.010428
2021-12-13 00:35:10,077 iteration 3703 : loss : 0.028917, loss_ce: 0.013456
2021-12-13 00:35:11,453 iteration 3704 : loss : 0.031206, loss_ce: 0.011730
2021-12-13 00:35:12,994 iteration 3705 : loss : 0.036414, loss_ce: 0.013746
2021-12-13 00:35:14,378 iteration 3706 : loss : 0.020815, loss_ce: 0.007063
 55%|██████████████▋            | 218/400 [1:39:56<1:19:44, 26.29s/it]2021-12-13 00:35:15,912 iteration 3707 : loss : 0.030098, loss_ce: 0.013696
2021-12-13 00:35:17,300 iteration 3708 : loss : 0.033202, loss_ce: 0.011460
2021-12-13 00:35:18,876 iteration 3709 : loss : 0.041826, loss_ce: 0.011162
2021-12-13 00:35:20,349 iteration 3710 : loss : 0.048046, loss_ce: 0.017935
2021-12-13 00:35:21,778 iteration 3711 : loss : 0.024743, loss_ce: 0.008869
2021-12-13 00:35:23,185 iteration 3712 : loss : 0.028451, loss_ce: 0.013158
2021-12-13 00:35:24,748 iteration 3713 : loss : 0.031426, loss_ce: 0.011437
2021-12-13 00:35:26,222 iteration 3714 : loss : 0.030000, loss_ce: 0.012161
2021-12-13 00:35:27,651 iteration 3715 : loss : 0.022950, loss_ce: 0.010493
2021-12-13 00:35:29,100 iteration 3716 : loss : 0.028642, loss_ce: 0.014569
2021-12-13 00:35:30,597 iteration 3717 : loss : 0.029096, loss_ce: 0.010974
2021-12-13 00:35:32,031 iteration 3718 : loss : 0.025666, loss_ce: 0.010822
2021-12-13 00:35:33,498 iteration 3719 : loss : 0.034029, loss_ce: 0.013547
2021-12-13 00:35:35,037 iteration 3720 : loss : 0.039591, loss_ce: 0.012766
2021-12-13 00:35:36,466 iteration 3721 : loss : 0.026224, loss_ce: 0.010444
2021-12-13 00:35:37,903 iteration 3722 : loss : 0.036878, loss_ce: 0.015812
2021-12-13 00:35:39,426 iteration 3723 : loss : 0.040614, loss_ce: 0.012879
 55%|██████████████▊            | 219/400 [1:40:21<1:18:10, 25.92s/it]2021-12-13 00:35:40,970 iteration 3724 : loss : 0.033371, loss_ce: 0.013681
2021-12-13 00:35:42,422 iteration 3725 : loss : 0.031565, loss_ce: 0.013065
2021-12-13 00:35:43,991 iteration 3726 : loss : 0.027771, loss_ce: 0.010316
2021-12-13 00:35:45,410 iteration 3727 : loss : 0.022786, loss_ce: 0.008128
2021-12-13 00:35:46,879 iteration 3728 : loss : 0.037083, loss_ce: 0.017118
2021-12-13 00:35:48,388 iteration 3729 : loss : 0.045561, loss_ce: 0.014835
2021-12-13 00:35:49,821 iteration 3730 : loss : 0.045307, loss_ce: 0.013635
2021-12-13 00:35:51,224 iteration 3731 : loss : 0.028898, loss_ce: 0.010790
2021-12-13 00:35:52,682 iteration 3732 : loss : 0.031451, loss_ce: 0.012648
2021-12-13 00:35:54,122 iteration 3733 : loss : 0.033891, loss_ce: 0.010473
2021-12-13 00:35:55,595 iteration 3734 : loss : 0.031930, loss_ce: 0.011365
2021-12-13 00:35:57,091 iteration 3735 : loss : 0.031224, loss_ce: 0.014874
2021-12-13 00:35:58,596 iteration 3736 : loss : 0.033822, loss_ce: 0.010833
2021-12-13 00:36:00,068 iteration 3737 : loss : 0.033346, loss_ce: 0.012612
2021-12-13 00:36:01,527 iteration 3738 : loss : 0.034263, loss_ce: 0.013363
2021-12-13 00:36:02,987 iteration 3739 : loss : 0.031690, loss_ce: 0.010828
2021-12-13 00:36:02,987 Training Data Eval:
2021-12-13 00:36:10,498   Average segmentation loss on training set: 0.0189
2021-12-13 00:36:10,499 Validation Data Eval:
2021-12-13 00:36:13,098   Average segmentation loss on validation set: 0.0894
2021-12-13 00:36:14,602 iteration 3740 : loss : 0.026810, loss_ce: 0.010529
 55%|██████████████▊            | 220/400 [1:40:56<1:26:04, 28.69s/it]2021-12-13 00:36:16,120 iteration 3741 : loss : 0.027133, loss_ce: 0.011295
2021-12-13 00:36:17,564 iteration 3742 : loss : 0.039908, loss_ce: 0.018483
2021-12-13 00:36:19,006 iteration 3743 : loss : 0.030262, loss_ce: 0.010509
2021-12-13 00:36:20,478 iteration 3744 : loss : 0.031498, loss_ce: 0.015075
2021-12-13 00:36:21,894 iteration 3745 : loss : 0.025779, loss_ce: 0.010395
2021-12-13 00:36:23,393 iteration 3746 : loss : 0.025386, loss_ce: 0.010688
2021-12-13 00:36:24,895 iteration 3747 : loss : 0.055418, loss_ce: 0.009264
2021-12-13 00:36:26,367 iteration 3748 : loss : 0.033529, loss_ce: 0.013857
2021-12-13 00:36:27,821 iteration 3749 : loss : 0.032668, loss_ce: 0.013859
2021-12-13 00:36:29,300 iteration 3750 : loss : 0.038803, loss_ce: 0.013893
2021-12-13 00:36:30,787 iteration 3751 : loss : 0.030212, loss_ce: 0.009093
2021-12-13 00:36:32,260 iteration 3752 : loss : 0.032886, loss_ce: 0.014001
2021-12-13 00:36:33,686 iteration 3753 : loss : 0.039510, loss_ce: 0.011178
2021-12-13 00:36:35,081 iteration 3754 : loss : 0.022475, loss_ce: 0.007698
2021-12-13 00:36:36,511 iteration 3755 : loss : 0.032180, loss_ce: 0.013820
2021-12-13 00:36:37,972 iteration 3756 : loss : 0.033546, loss_ce: 0.011211
2021-12-13 00:36:39,439 iteration 3757 : loss : 0.028939, loss_ce: 0.009015
 55%|██████████████▉            | 221/400 [1:41:21<1:22:09, 27.54s/it]2021-12-13 00:36:40,964 iteration 3758 : loss : 0.036313, loss_ce: 0.014087
2021-12-13 00:36:42,429 iteration 3759 : loss : 0.027123, loss_ce: 0.010010
2021-12-13 00:36:43,801 iteration 3760 : loss : 0.029887, loss_ce: 0.009980
2021-12-13 00:36:45,313 iteration 3761 : loss : 0.043933, loss_ce: 0.018788
2021-12-13 00:36:46,777 iteration 3762 : loss : 0.042430, loss_ce: 0.013967
2021-12-13 00:36:48,304 iteration 3763 : loss : 0.031580, loss_ce: 0.012884
2021-12-13 00:36:49,825 iteration 3764 : loss : 0.037654, loss_ce: 0.015388
2021-12-13 00:36:51,291 iteration 3765 : loss : 0.027965, loss_ce: 0.010877
2021-12-13 00:36:52,751 iteration 3766 : loss : 0.042563, loss_ce: 0.015001
2021-12-13 00:36:54,288 iteration 3767 : loss : 0.035725, loss_ce: 0.011056
2021-12-13 00:36:55,784 iteration 3768 : loss : 0.031373, loss_ce: 0.014099
2021-12-13 00:36:57,219 iteration 3769 : loss : 0.026719, loss_ce: 0.010683
2021-12-13 00:36:58,624 iteration 3770 : loss : 0.026029, loss_ce: 0.010154
2021-12-13 00:37:00,043 iteration 3771 : loss : 0.025355, loss_ce: 0.009852
2021-12-13 00:37:01,492 iteration 3772 : loss : 0.030747, loss_ce: 0.009930
2021-12-13 00:37:02,884 iteration 3773 : loss : 0.023975, loss_ce: 0.009112
2021-12-13 00:37:04,291 iteration 3774 : loss : 0.032967, loss_ce: 0.013717
 56%|██████████████▉            | 222/400 [1:41:46<1:19:17, 26.73s/it]2021-12-13 00:37:05,763 iteration 3775 : loss : 0.031921, loss_ce: 0.009079
2021-12-13 00:37:07,260 iteration 3776 : loss : 0.039860, loss_ce: 0.017403
2021-12-13 00:37:08,846 iteration 3777 : loss : 0.047024, loss_ce: 0.016842
2021-12-13 00:37:10,282 iteration 3778 : loss : 0.025996, loss_ce: 0.011701
2021-12-13 00:37:11,783 iteration 3779 : loss : 0.030107, loss_ce: 0.011474
2021-12-13 00:37:13,223 iteration 3780 : loss : 0.032070, loss_ce: 0.015979
2021-12-13 00:37:14,679 iteration 3781 : loss : 0.026250, loss_ce: 0.011125
2021-12-13 00:37:16,163 iteration 3782 : loss : 0.032820, loss_ce: 0.011929
2021-12-13 00:37:17,665 iteration 3783 : loss : 0.026019, loss_ce: 0.008254
2021-12-13 00:37:19,177 iteration 3784 : loss : 0.039692, loss_ce: 0.019846
2021-12-13 00:37:20,610 iteration 3785 : loss : 0.024550, loss_ce: 0.008674
2021-12-13 00:37:22,090 iteration 3786 : loss : 0.025087, loss_ce: 0.009368
2021-12-13 00:37:23,617 iteration 3787 : loss : 0.056514, loss_ce: 0.021931
2021-12-13 00:37:25,152 iteration 3788 : loss : 0.031498, loss_ce: 0.012350
2021-12-13 00:37:26,587 iteration 3789 : loss : 0.030005, loss_ce: 0.008930
2021-12-13 00:37:28,090 iteration 3790 : loss : 0.030375, loss_ce: 0.011809
2021-12-13 00:37:29,468 iteration 3791 : loss : 0.025718, loss_ce: 0.011048
 56%|███████████████            | 223/400 [1:42:11<1:17:28, 26.26s/it]2021-12-13 00:37:30,965 iteration 3792 : loss : 0.026664, loss_ce: 0.012160
2021-12-13 00:37:32,433 iteration 3793 : loss : 0.029574, loss_ce: 0.012381
2021-12-13 00:37:33,848 iteration 3794 : loss : 0.028368, loss_ce: 0.011566
2021-12-13 00:37:35,419 iteration 3795 : loss : 0.043662, loss_ce: 0.018294
2021-12-13 00:37:36,922 iteration 3796 : loss : 0.045018, loss_ce: 0.011826
2021-12-13 00:37:38,361 iteration 3797 : loss : 0.031214, loss_ce: 0.011167
2021-12-13 00:37:39,918 iteration 3798 : loss : 0.032690, loss_ce: 0.013017
2021-12-13 00:37:41,342 iteration 3799 : loss : 0.025735, loss_ce: 0.013651
2021-12-13 00:37:42,853 iteration 3800 : loss : 0.036002, loss_ce: 0.011360
2021-12-13 00:37:44,269 iteration 3801 : loss : 0.028439, loss_ce: 0.010546
2021-12-13 00:37:45,734 iteration 3802 : loss : 0.031365, loss_ce: 0.008791
2021-12-13 00:37:47,188 iteration 3803 : loss : 0.021847, loss_ce: 0.008283
2021-12-13 00:37:48,550 iteration 3804 : loss : 0.026527, loss_ce: 0.010218
2021-12-13 00:37:50,040 iteration 3805 : loss : 0.027576, loss_ce: 0.011742
2021-12-13 00:37:51,466 iteration 3806 : loss : 0.032040, loss_ce: 0.011699
2021-12-13 00:37:52,908 iteration 3807 : loss : 0.037988, loss_ce: 0.015825
2021-12-13 00:37:54,394 iteration 3808 : loss : 0.025419, loss_ce: 0.009187
 56%|███████████████            | 224/400 [1:42:36<1:15:52, 25.86s/it]2021-12-13 00:37:55,902 iteration 3809 : loss : 0.029685, loss_ce: 0.012119
2021-12-13 00:37:57,357 iteration 3810 : loss : 0.028400, loss_ce: 0.012172
2021-12-13 00:37:58,933 iteration 3811 : loss : 0.029206, loss_ce: 0.009539
2021-12-13 00:38:00,375 iteration 3812 : loss : 0.036214, loss_ce: 0.012605
2021-12-13 00:38:01,854 iteration 3813 : loss : 0.039600, loss_ce: 0.010211
2021-12-13 00:38:03,240 iteration 3814 : loss : 0.023043, loss_ce: 0.008379
2021-12-13 00:38:04,760 iteration 3815 : loss : 0.041904, loss_ce: 0.015205
2021-12-13 00:38:06,350 iteration 3816 : loss : 0.031620, loss_ce: 0.011610
2021-12-13 00:38:07,833 iteration 3817 : loss : 0.030084, loss_ce: 0.013902
2021-12-13 00:38:09,412 iteration 3818 : loss : 0.030121, loss_ce: 0.013370
2021-12-13 00:38:10,832 iteration 3819 : loss : 0.031065, loss_ce: 0.014766
2021-12-13 00:38:12,355 iteration 3820 : loss : 0.045200, loss_ce: 0.017774
2021-12-13 00:38:13,818 iteration 3821 : loss : 0.030339, loss_ce: 0.013426
2021-12-13 00:38:15,185 iteration 3822 : loss : 0.026045, loss_ce: 0.010867
2021-12-13 00:38:16,599 iteration 3823 : loss : 0.028312, loss_ce: 0.010574
2021-12-13 00:38:18,042 iteration 3824 : loss : 0.033670, loss_ce: 0.012940
2021-12-13 00:38:18,043 Training Data Eval:
2021-12-13 00:38:25,564   Average segmentation loss on training set: 0.0185
2021-12-13 00:38:25,565 Validation Data Eval:
2021-12-13 00:38:28,168   Average segmentation loss on validation set: 0.0794
2021-12-13 00:38:29,586 iteration 3825 : loss : 0.037229, loss_ce: 0.014077
 56%|███████████████▏           | 225/400 [1:43:11<1:23:36, 28.66s/it]2021-12-13 00:38:30,997 iteration 3826 : loss : 0.030876, loss_ce: 0.012098
2021-12-13 00:38:32,481 iteration 3827 : loss : 0.032807, loss_ce: 0.014083
2021-12-13 00:38:33,972 iteration 3828 : loss : 0.033838, loss_ce: 0.012479
2021-12-13 00:38:35,432 iteration 3829 : loss : 0.029210, loss_ce: 0.014177
2021-12-13 00:38:36,899 iteration 3830 : loss : 0.034310, loss_ce: 0.013457
2021-12-13 00:38:38,435 iteration 3831 : loss : 0.052110, loss_ce: 0.013279
2021-12-13 00:38:39,814 iteration 3832 : loss : 0.023700, loss_ce: 0.009021
2021-12-13 00:38:41,290 iteration 3833 : loss : 0.036440, loss_ce: 0.014065
2021-12-13 00:38:42,731 iteration 3834 : loss : 0.026033, loss_ce: 0.012513
2021-12-13 00:38:44,243 iteration 3835 : loss : 0.029333, loss_ce: 0.014048
2021-12-13 00:38:45,768 iteration 3836 : loss : 0.029306, loss_ce: 0.009775
2021-12-13 00:38:47,161 iteration 3837 : loss : 0.026873, loss_ce: 0.010575
2021-12-13 00:38:48,590 iteration 3838 : loss : 0.025745, loss_ce: 0.008690
2021-12-13 00:38:50,011 iteration 3839 : loss : 0.029891, loss_ce: 0.012054
2021-12-13 00:38:51,379 iteration 3840 : loss : 0.027335, loss_ce: 0.008251
2021-12-13 00:38:52,798 iteration 3841 : loss : 0.023882, loss_ce: 0.008550
2021-12-13 00:38:54,229 iteration 3842 : loss : 0.033738, loss_ce: 0.008793
 56%|███████████████▎           | 226/400 [1:43:36<1:19:37, 27.45s/it]2021-12-13 00:38:55,755 iteration 3843 : loss : 0.028269, loss_ce: 0.010917
2021-12-13 00:38:57,224 iteration 3844 : loss : 0.030882, loss_ce: 0.014490
2021-12-13 00:38:58,666 iteration 3845 : loss : 0.033358, loss_ce: 0.013063
2021-12-13 00:39:00,110 iteration 3846 : loss : 0.024921, loss_ce: 0.007004
2021-12-13 00:39:01,618 iteration 3847 : loss : 0.020929, loss_ce: 0.008319
2021-12-13 00:39:03,057 iteration 3848 : loss : 0.028131, loss_ce: 0.011609
2021-12-13 00:39:04,446 iteration 3849 : loss : 0.025710, loss_ce: 0.010609
2021-12-13 00:39:05,933 iteration 3850 : loss : 0.043154, loss_ce: 0.011445
2021-12-13 00:39:07,437 iteration 3851 : loss : 0.036015, loss_ce: 0.019680
2021-12-13 00:39:08,877 iteration 3852 : loss : 0.025502, loss_ce: 0.010493
2021-12-13 00:39:10,301 iteration 3853 : loss : 0.027987, loss_ce: 0.015404
2021-12-13 00:39:11,804 iteration 3854 : loss : 0.038781, loss_ce: 0.015431
2021-12-13 00:39:13,273 iteration 3855 : loss : 0.029400, loss_ce: 0.011485
2021-12-13 00:39:14,763 iteration 3856 : loss : 0.033882, loss_ce: 0.012912
2021-12-13 00:39:16,189 iteration 3857 : loss : 0.027072, loss_ce: 0.011102
2021-12-13 00:39:17,681 iteration 3858 : loss : 0.027300, loss_ce: 0.010320
2021-12-13 00:39:19,160 iteration 3859 : loss : 0.042583, loss_ce: 0.011696
 57%|███████████████▎           | 227/400 [1:44:01<1:16:58, 26.70s/it]2021-12-13 00:39:20,673 iteration 3860 : loss : 0.023927, loss_ce: 0.011360
2021-12-13 00:39:22,198 iteration 3861 : loss : 0.029846, loss_ce: 0.014415
2021-12-13 00:39:23,598 iteration 3862 : loss : 0.030489, loss_ce: 0.013462
2021-12-13 00:39:25,093 iteration 3863 : loss : 0.028998, loss_ce: 0.013815
2021-12-13 00:39:26,607 iteration 3864 : loss : 0.027166, loss_ce: 0.009424
2021-12-13 00:39:28,204 iteration 3865 : loss : 0.038620, loss_ce: 0.016980
2021-12-13 00:39:29,797 iteration 3866 : loss : 0.036853, loss_ce: 0.018456
2021-12-13 00:39:31,248 iteration 3867 : loss : 0.023434, loss_ce: 0.009125
2021-12-13 00:39:32,752 iteration 3868 : loss : 0.032279, loss_ce: 0.013818
2021-12-13 00:39:34,251 iteration 3869 : loss : 0.036927, loss_ce: 0.013019
2021-12-13 00:39:35,784 iteration 3870 : loss : 0.027799, loss_ce: 0.009463
2021-12-13 00:39:37,257 iteration 3871 : loss : 0.040638, loss_ce: 0.010953
2021-12-13 00:39:38,706 iteration 3872 : loss : 0.035306, loss_ce: 0.016417
2021-12-13 00:39:40,160 iteration 3873 : loss : 0.032288, loss_ce: 0.012915
2021-12-13 00:39:41,680 iteration 3874 : loss : 0.024417, loss_ce: 0.009803
2021-12-13 00:39:43,189 iteration 3875 : loss : 0.038820, loss_ce: 0.013569
2021-12-13 00:39:44,643 iteration 3876 : loss : 0.051902, loss_ce: 0.012355
 57%|███████████████▍           | 228/400 [1:44:26<1:15:29, 26.33s/it]2021-12-13 00:39:46,118 iteration 3877 : loss : 0.026620, loss_ce: 0.009951
2021-12-13 00:39:47,649 iteration 3878 : loss : 0.031492, loss_ce: 0.014058
2021-12-13 00:39:49,142 iteration 3879 : loss : 0.035105, loss_ce: 0.013996
2021-12-13 00:39:50,603 iteration 3880 : loss : 0.023449, loss_ce: 0.011193
2021-12-13 00:39:52,023 iteration 3881 : loss : 0.030968, loss_ce: 0.015878
2021-12-13 00:39:53,558 iteration 3882 : loss : 0.041579, loss_ce: 0.014423
2021-12-13 00:39:55,074 iteration 3883 : loss : 0.041863, loss_ce: 0.016723
2021-12-13 00:39:56,499 iteration 3884 : loss : 0.074702, loss_ce: 0.012542
2021-12-13 00:39:57,911 iteration 3885 : loss : 0.027661, loss_ce: 0.009902
2021-12-13 00:39:59,334 iteration 3886 : loss : 0.031215, loss_ce: 0.011115
2021-12-13 00:40:00,855 iteration 3887 : loss : 0.035407, loss_ce: 0.014721
2021-12-13 00:40:02,327 iteration 3888 : loss : 0.043066, loss_ce: 0.015072
2021-12-13 00:40:03,805 iteration 3889 : loss : 0.038788, loss_ce: 0.015111
2021-12-13 00:40:05,182 iteration 3890 : loss : 0.035795, loss_ce: 0.014221
2021-12-13 00:40:06,660 iteration 3891 : loss : 0.023212, loss_ce: 0.009462
2021-12-13 00:40:08,139 iteration 3892 : loss : 0.058447, loss_ce: 0.013055
2021-12-13 00:40:09,704 iteration 3893 : loss : 0.036391, loss_ce: 0.018789
 57%|███████████████▍           | 229/400 [1:44:51<1:13:57, 25.95s/it]2021-12-13 00:40:11,165 iteration 3894 : loss : 0.031723, loss_ce: 0.014097
2021-12-13 00:40:12,686 iteration 3895 : loss : 0.035166, loss_ce: 0.013362
2021-12-13 00:40:14,135 iteration 3896 : loss : 0.032933, loss_ce: 0.009730
2021-12-13 00:40:15,621 iteration 3897 : loss : 0.043126, loss_ce: 0.018103
2021-12-13 00:40:17,066 iteration 3898 : loss : 0.026884, loss_ce: 0.010253
2021-12-13 00:40:18,564 iteration 3899 : loss : 0.029844, loss_ce: 0.011824
2021-12-13 00:40:20,108 iteration 3900 : loss : 0.034557, loss_ce: 0.012141
2021-12-13 00:40:21,524 iteration 3901 : loss : 0.030565, loss_ce: 0.009990
2021-12-13 00:40:22,958 iteration 3902 : loss : 0.022749, loss_ce: 0.008771
2021-12-13 00:40:24,417 iteration 3903 : loss : 0.028518, loss_ce: 0.011471
2021-12-13 00:40:25,960 iteration 3904 : loss : 0.030793, loss_ce: 0.012855
2021-12-13 00:40:27,425 iteration 3905 : loss : 0.032990, loss_ce: 0.015039
2021-12-13 00:40:28,857 iteration 3906 : loss : 0.033243, loss_ce: 0.016129
2021-12-13 00:40:30,339 iteration 3907 : loss : 0.032223, loss_ce: 0.010521
2021-12-13 00:40:31,889 iteration 3908 : loss : 0.039520, loss_ce: 0.014240
2021-12-13 00:40:33,397 iteration 3909 : loss : 0.033317, loss_ce: 0.012660
2021-12-13 00:40:33,397 Training Data Eval:
2021-12-13 00:40:40,936   Average segmentation loss on training set: 0.0193
2021-12-13 00:40:40,936 Validation Data Eval:
2021-12-13 00:40:43,542   Average segmentation loss on validation set: 0.0867
2021-12-13 00:40:44,936 iteration 3910 : loss : 0.024397, loss_ce: 0.008721
 57%|███████████████▌           | 230/400 [1:45:26<1:21:25, 28.74s/it]2021-12-13 00:40:46,385 iteration 3911 : loss : 0.025168, loss_ce: 0.008768
2021-12-13 00:40:47,904 iteration 3912 : loss : 0.033782, loss_ce: 0.015603
2021-12-13 00:40:49,305 iteration 3913 : loss : 0.029190, loss_ce: 0.009848
2021-12-13 00:40:50,685 iteration 3914 : loss : 0.027733, loss_ce: 0.010784
2021-12-13 00:40:52,062 iteration 3915 : loss : 0.031232, loss_ce: 0.010715
2021-12-13 00:40:53,572 iteration 3916 : loss : 0.044061, loss_ce: 0.016681
2021-12-13 00:40:55,096 iteration 3917 : loss : 0.048414, loss_ce: 0.011658
2021-12-13 00:40:56,614 iteration 3918 : loss : 0.034251, loss_ce: 0.014749
2021-12-13 00:40:58,083 iteration 3919 : loss : 0.030122, loss_ce: 0.011513
2021-12-13 00:40:59,569 iteration 3920 : loss : 0.036029, loss_ce: 0.016336
2021-12-13 00:41:01,055 iteration 3921 : loss : 0.041163, loss_ce: 0.013014
2021-12-13 00:41:02,481 iteration 3922 : loss : 0.020537, loss_ce: 0.008970
2021-12-13 00:41:03,942 iteration 3923 : loss : 0.031531, loss_ce: 0.012646
2021-12-13 00:41:05,416 iteration 3924 : loss : 0.032235, loss_ce: 0.014095
2021-12-13 00:41:07,020 iteration 3925 : loss : 0.032902, loss_ce: 0.015563
2021-12-13 00:41:08,491 iteration 3926 : loss : 0.027079, loss_ce: 0.010400
2021-12-13 00:41:09,980 iteration 3927 : loss : 0.038988, loss_ce: 0.017908
 58%|███████████████▌           | 231/400 [1:45:51<1:17:49, 27.63s/it]2021-12-13 00:41:11,503 iteration 3928 : loss : 0.028425, loss_ce: 0.011950
2021-12-13 00:41:13,053 iteration 3929 : loss : 0.039055, loss_ce: 0.015865
2021-12-13 00:41:14,659 iteration 3930 : loss : 0.040918, loss_ce: 0.015042
2021-12-13 00:41:16,152 iteration 3931 : loss : 0.036551, loss_ce: 0.017069
2021-12-13 00:41:17,675 iteration 3932 : loss : 0.029836, loss_ce: 0.009411
2021-12-13 00:41:19,118 iteration 3933 : loss : 0.058437, loss_ce: 0.016847
2021-12-13 00:41:20,583 iteration 3934 : loss : 0.028070, loss_ce: 0.009920
2021-12-13 00:41:22,107 iteration 3935 : loss : 0.033706, loss_ce: 0.011426
2021-12-13 00:41:23,558 iteration 3936 : loss : 0.029544, loss_ce: 0.012230
2021-12-13 00:41:25,022 iteration 3937 : loss : 0.021799, loss_ce: 0.007262
2021-12-13 00:41:26,456 iteration 3938 : loss : 0.028312, loss_ce: 0.014431
2021-12-13 00:41:28,014 iteration 3939 : loss : 0.036483, loss_ce: 0.013150
2021-12-13 00:41:29,469 iteration 3940 : loss : 0.029171, loss_ce: 0.009058
2021-12-13 00:41:30,930 iteration 3941 : loss : 0.030143, loss_ce: 0.013490
2021-12-13 00:41:32,383 iteration 3942 : loss : 0.039345, loss_ce: 0.017247
2021-12-13 00:41:33,896 iteration 3943 : loss : 0.032825, loss_ce: 0.015359
2021-12-13 00:41:35,393 iteration 3944 : loss : 0.034094, loss_ce: 0.010759
 58%|███████████████▋           | 232/400 [1:46:17<1:15:29, 26.96s/it]2021-12-13 00:41:36,885 iteration 3945 : loss : 0.024242, loss_ce: 0.011356
2021-12-13 00:41:38,270 iteration 3946 : loss : 0.020788, loss_ce: 0.008072
2021-12-13 00:41:39,731 iteration 3947 : loss : 0.032775, loss_ce: 0.010920
2021-12-13 00:41:41,179 iteration 3948 : loss : 0.030197, loss_ce: 0.013544
2021-12-13 00:41:42,655 iteration 3949 : loss : 0.031771, loss_ce: 0.015424
2021-12-13 00:41:44,118 iteration 3950 : loss : 0.029156, loss_ce: 0.010014
2021-12-13 00:41:45,625 iteration 3951 : loss : 0.034031, loss_ce: 0.015135
2021-12-13 00:41:47,085 iteration 3952 : loss : 0.024897, loss_ce: 0.010918
2021-12-13 00:41:48,545 iteration 3953 : loss : 0.027881, loss_ce: 0.009256
2021-12-13 00:41:50,051 iteration 3954 : loss : 0.033586, loss_ce: 0.012129
2021-12-13 00:41:51,558 iteration 3955 : loss : 0.036970, loss_ce: 0.012921
2021-12-13 00:41:53,003 iteration 3956 : loss : 0.028946, loss_ce: 0.012731
2021-12-13 00:41:54,449 iteration 3957 : loss : 0.033731, loss_ce: 0.013379
2021-12-13 00:41:56,001 iteration 3958 : loss : 0.031206, loss_ce: 0.013021
2021-12-13 00:41:57,453 iteration 3959 : loss : 0.025692, loss_ce: 0.008304
2021-12-13 00:41:58,923 iteration 3960 : loss : 0.034218, loss_ce: 0.008463
2021-12-13 00:42:00,430 iteration 3961 : loss : 0.036456, loss_ce: 0.014612
 58%|███████████████▋           | 233/400 [1:46:42<1:13:26, 26.39s/it]2021-12-13 00:42:02,077 iteration 3962 : loss : 0.040324, loss_ce: 0.015311
2021-12-13 00:42:03,505 iteration 3963 : loss : 0.025180, loss_ce: 0.011568
2021-12-13 00:42:05,013 iteration 3964 : loss : 0.033183, loss_ce: 0.012762
2021-12-13 00:42:06,573 iteration 3965 : loss : 0.064008, loss_ce: 0.020685
2021-12-13 00:42:08,024 iteration 3966 : loss : 0.030491, loss_ce: 0.010640
2021-12-13 00:42:09,472 iteration 3967 : loss : 0.031848, loss_ce: 0.009923
2021-12-13 00:42:11,019 iteration 3968 : loss : 0.034049, loss_ce: 0.013263
2021-12-13 00:42:12,551 iteration 3969 : loss : 0.028787, loss_ce: 0.011707
2021-12-13 00:42:14,113 iteration 3970 : loss : 0.033750, loss_ce: 0.017769
2021-12-13 00:42:15,570 iteration 3971 : loss : 0.023444, loss_ce: 0.007959
2021-12-13 00:42:17,007 iteration 3972 : loss : 0.027523, loss_ce: 0.010468
2021-12-13 00:42:18,493 iteration 3973 : loss : 0.044334, loss_ce: 0.017691
2021-12-13 00:42:20,047 iteration 3974 : loss : 0.030999, loss_ce: 0.013640
2021-12-13 00:42:21,601 iteration 3975 : loss : 0.033234, loss_ce: 0.011323
2021-12-13 00:42:23,163 iteration 3976 : loss : 0.031633, loss_ce: 0.013662
2021-12-13 00:42:24,630 iteration 3977 : loss : 0.039728, loss_ce: 0.015514
2021-12-13 00:42:26,090 iteration 3978 : loss : 0.029506, loss_ce: 0.013104
 58%|███████████████▊           | 234/400 [1:47:08<1:12:24, 26.17s/it]2021-12-13 00:42:27,626 iteration 3979 : loss : 0.038243, loss_ce: 0.012623
2021-12-13 00:42:29,124 iteration 3980 : loss : 0.027234, loss_ce: 0.013148
2021-12-13 00:42:30,562 iteration 3981 : loss : 0.035676, loss_ce: 0.013097
2021-12-13 00:42:32,172 iteration 3982 : loss : 0.037628, loss_ce: 0.012848
2021-12-13 00:42:33,668 iteration 3983 : loss : 0.031560, loss_ce: 0.008821
2021-12-13 00:42:35,190 iteration 3984 : loss : 0.031965, loss_ce: 0.011989
2021-12-13 00:42:36,673 iteration 3985 : loss : 0.033227, loss_ce: 0.011650
2021-12-13 00:42:38,111 iteration 3986 : loss : 0.028790, loss_ce: 0.012065
2021-12-13 00:42:39,557 iteration 3987 : loss : 0.025123, loss_ce: 0.011355
2021-12-13 00:42:41,082 iteration 3988 : loss : 0.038612, loss_ce: 0.017311
2021-12-13 00:42:42,567 iteration 3989 : loss : 0.035970, loss_ce: 0.013609
2021-12-13 00:42:44,029 iteration 3990 : loss : 0.023688, loss_ce: 0.009311
2021-12-13 00:42:45,496 iteration 3991 : loss : 0.034676, loss_ce: 0.012497
2021-12-13 00:42:47,090 iteration 3992 : loss : 0.042312, loss_ce: 0.012492
2021-12-13 00:42:48,558 iteration 3993 : loss : 0.036154, loss_ce: 0.017727
2021-12-13 00:42:50,020 iteration 3994 : loss : 0.031069, loss_ce: 0.013569
2021-12-13 00:42:50,020 Training Data Eval:
2021-12-13 00:42:57,537   Average segmentation loss on training set: 0.0177
2021-12-13 00:42:57,537 Validation Data Eval:
2021-12-13 00:43:00,133   Average segmentation loss on validation set: 0.0841
2021-12-13 00:43:01,579 iteration 3995 : loss : 0.032891, loss_ce: 0.010338
 59%|███████████████▊           | 235/400 [1:47:43<1:19:38, 28.96s/it]2021-12-13 00:43:03,156 iteration 3996 : loss : 0.038019, loss_ce: 0.020013
2021-12-13 00:43:04,660 iteration 3997 : loss : 0.036335, loss_ce: 0.012953
2021-12-13 00:43:06,125 iteration 3998 : loss : 0.031395, loss_ce: 0.011898
2021-12-13 00:43:07,650 iteration 3999 : loss : 0.032434, loss_ce: 0.009700
2021-12-13 00:43:09,135 iteration 4000 : loss : 0.031946, loss_ce: 0.011839
2021-12-13 00:43:10,726 iteration 4001 : loss : 0.040190, loss_ce: 0.011650
2021-12-13 00:43:12,203 iteration 4002 : loss : 0.026166, loss_ce: 0.012055
2021-12-13 00:43:13,676 iteration 4003 : loss : 0.034180, loss_ce: 0.014258
2021-12-13 00:43:15,139 iteration 4004 : loss : 0.029070, loss_ce: 0.010561
2021-12-13 00:43:16,625 iteration 4005 : loss : 0.032668, loss_ce: 0.014348
2021-12-13 00:43:18,201 iteration 4006 : loss : 0.035804, loss_ce: 0.012373
2021-12-13 00:43:19,657 iteration 4007 : loss : 0.027634, loss_ce: 0.010519
2021-12-13 00:43:21,139 iteration 4008 : loss : 0.031678, loss_ce: 0.010403
2021-12-13 00:43:22,607 iteration 4009 : loss : 0.027308, loss_ce: 0.011615
2021-12-13 00:43:24,010 iteration 4010 : loss : 0.020820, loss_ce: 0.008418
2021-12-13 00:43:25,520 iteration 4011 : loss : 0.033605, loss_ce: 0.010666
2021-12-13 00:43:27,035 iteration 4012 : loss : 0.031412, loss_ce: 0.015144
 59%|███████████████▉           | 236/400 [1:48:08<1:16:17, 27.91s/it]2021-12-13 00:43:28,538 iteration 4013 : loss : 0.033890, loss_ce: 0.009084
2021-12-13 00:43:30,070 iteration 4014 : loss : 0.033525, loss_ce: 0.011755
2021-12-13 00:43:31,516 iteration 4015 : loss : 0.029927, loss_ce: 0.015065
2021-12-13 00:43:33,020 iteration 4016 : loss : 0.042132, loss_ce: 0.014013
2021-12-13 00:43:34,455 iteration 4017 : loss : 0.030824, loss_ce: 0.010601
2021-12-13 00:43:36,021 iteration 4018 : loss : 0.035803, loss_ce: 0.013561
2021-12-13 00:43:37,562 iteration 4019 : loss : 0.044917, loss_ce: 0.020195
2021-12-13 00:43:39,019 iteration 4020 : loss : 0.025402, loss_ce: 0.009692
2021-12-13 00:43:40,503 iteration 4021 : loss : 0.029607, loss_ce: 0.010844
2021-12-13 00:43:41,994 iteration 4022 : loss : 0.037062, loss_ce: 0.014682
2021-12-13 00:43:43,484 iteration 4023 : loss : 0.034452, loss_ce: 0.016251
2021-12-13 00:43:44,975 iteration 4024 : loss : 0.035104, loss_ce: 0.011604
2021-12-13 00:43:46,429 iteration 4025 : loss : 0.032592, loss_ce: 0.012760
2021-12-13 00:43:47,877 iteration 4026 : loss : 0.022056, loss_ce: 0.009565
2021-12-13 00:43:49,327 iteration 4027 : loss : 0.027872, loss_ce: 0.011367
2021-12-13 00:43:50,792 iteration 4028 : loss : 0.027384, loss_ce: 0.007891
2021-12-13 00:43:52,281 iteration 4029 : loss : 0.028611, loss_ce: 0.010908
 59%|███████████████▉           | 237/400 [1:48:34<1:13:38, 27.11s/it]2021-12-13 00:43:53,812 iteration 4030 : loss : 0.041904, loss_ce: 0.017065
2021-12-13 00:43:55,273 iteration 4031 : loss : 0.029224, loss_ce: 0.010672
2021-12-13 00:43:56,793 iteration 4032 : loss : 0.027204, loss_ce: 0.009686
2021-12-13 00:43:58,356 iteration 4033 : loss : 0.029710, loss_ce: 0.009530
2021-12-13 00:43:59,804 iteration 4034 : loss : 0.030412, loss_ce: 0.011237
2021-12-13 00:44:01,289 iteration 4035 : loss : 0.043772, loss_ce: 0.013945
2021-12-13 00:44:02,757 iteration 4036 : loss : 0.023396, loss_ce: 0.008847
2021-12-13 00:44:04,281 iteration 4037 : loss : 0.055220, loss_ce: 0.018060
2021-12-13 00:44:05,763 iteration 4038 : loss : 0.029334, loss_ce: 0.015021
2021-12-13 00:44:07,133 iteration 4039 : loss : 0.023443, loss_ce: 0.011489
2021-12-13 00:44:08,602 iteration 4040 : loss : 0.046165, loss_ce: 0.011111
2021-12-13 00:44:10,203 iteration 4041 : loss : 0.038601, loss_ce: 0.019721
2021-12-13 00:44:11,609 iteration 4042 : loss : 0.029326, loss_ce: 0.013029
2021-12-13 00:44:13,099 iteration 4043 : loss : 0.026821, loss_ce: 0.010706
2021-12-13 00:44:14,589 iteration 4044 : loss : 0.036964, loss_ce: 0.015287
2021-12-13 00:44:16,045 iteration 4045 : loss : 0.035886, loss_ce: 0.013617
2021-12-13 00:44:17,555 iteration 4046 : loss : 0.028654, loss_ce: 0.010150
 60%|████████████████           | 238/400 [1:48:59<1:11:42, 26.56s/it]2021-12-13 00:44:19,008 iteration 4047 : loss : 0.022254, loss_ce: 0.010228
2021-12-13 00:44:20,467 iteration 4048 : loss : 0.028028, loss_ce: 0.008635
2021-12-13 00:44:22,012 iteration 4049 : loss : 0.036073, loss_ce: 0.012221
2021-12-13 00:44:23,483 iteration 4050 : loss : 0.029526, loss_ce: 0.008660
2021-12-13 00:44:24,965 iteration 4051 : loss : 0.025464, loss_ce: 0.009057
2021-12-13 00:44:26,431 iteration 4052 : loss : 0.029948, loss_ce: 0.009138
2021-12-13 00:44:27,882 iteration 4053 : loss : 0.031662, loss_ce: 0.014962
2021-12-13 00:44:29,317 iteration 4054 : loss : 0.027419, loss_ce: 0.011946
2021-12-13 00:44:30,897 iteration 4055 : loss : 0.040431, loss_ce: 0.013256
2021-12-13 00:44:32,409 iteration 4056 : loss : 0.044549, loss_ce: 0.012835
2021-12-13 00:44:33,948 iteration 4057 : loss : 0.042295, loss_ce: 0.016631
2021-12-13 00:44:35,343 iteration 4058 : loss : 0.027116, loss_ce: 0.012155
2021-12-13 00:44:36,881 iteration 4059 : loss : 0.031566, loss_ce: 0.013323
2021-12-13 00:44:38,390 iteration 4060 : loss : 0.030999, loss_ce: 0.012140
2021-12-13 00:44:39,852 iteration 4061 : loss : 0.031526, loss_ce: 0.008504
2021-12-13 00:44:41,301 iteration 4062 : loss : 0.036070, loss_ce: 0.016755
2021-12-13 00:44:42,888 iteration 4063 : loss : 0.048872, loss_ce: 0.019556
 60%|████████████████▏          | 239/400 [1:49:24<1:10:17, 26.19s/it]2021-12-13 00:44:44,405 iteration 4064 : loss : 0.028865, loss_ce: 0.010794
2021-12-13 00:44:45,870 iteration 4065 : loss : 0.028119, loss_ce: 0.010777
2021-12-13 00:44:47,258 iteration 4066 : loss : 0.023782, loss_ce: 0.007812
2021-12-13 00:44:48,681 iteration 4067 : loss : 0.057690, loss_ce: 0.013139
2021-12-13 00:44:50,166 iteration 4068 : loss : 0.033903, loss_ce: 0.012554
2021-12-13 00:44:51,681 iteration 4069 : loss : 0.032866, loss_ce: 0.010769
2021-12-13 00:44:53,181 iteration 4070 : loss : 0.039653, loss_ce: 0.018345
2021-12-13 00:44:54,593 iteration 4071 : loss : 0.026875, loss_ce: 0.011220
2021-12-13 00:44:56,064 iteration 4072 : loss : 0.026447, loss_ce: 0.011603
2021-12-13 00:44:57,551 iteration 4073 : loss : 0.035299, loss_ce: 0.016922
2021-12-13 00:44:58,981 iteration 4074 : loss : 0.036175, loss_ce: 0.013606
2021-12-13 00:45:00,505 iteration 4075 : loss : 0.036160, loss_ce: 0.012934
2021-12-13 00:45:01,993 iteration 4076 : loss : 0.029342, loss_ce: 0.010251
2021-12-13 00:45:03,496 iteration 4077 : loss : 0.030114, loss_ce: 0.014843
2021-12-13 00:45:05,048 iteration 4078 : loss : 0.044112, loss_ce: 0.013576
2021-12-13 00:45:06,544 iteration 4079 : loss : 0.027427, loss_ce: 0.010791
2021-12-13 00:45:06,544 Training Data Eval:
2021-12-13 00:45:14,078   Average segmentation loss on training set: 0.0184
2021-12-13 00:45:14,078 Validation Data Eval:
2021-12-13 00:45:16,690   Average segmentation loss on validation set: 0.0799
2021-12-13 00:45:18,171 iteration 4080 : loss : 0.039247, loss_ce: 0.011228
 60%|████████████████▏          | 240/400 [1:50:00<1:17:07, 28.92s/it]2021-12-13 00:45:19,673 iteration 4081 : loss : 0.030828, loss_ce: 0.015843
2021-12-13 00:45:21,231 iteration 4082 : loss : 0.034852, loss_ce: 0.012765
2021-12-13 00:45:22,633 iteration 4083 : loss : 0.035089, loss_ce: 0.015771
2021-12-13 00:45:24,068 iteration 4084 : loss : 0.027826, loss_ce: 0.009748
2021-12-13 00:45:25,542 iteration 4085 : loss : 0.037180, loss_ce: 0.008548
2021-12-13 00:45:26,988 iteration 4086 : loss : 0.035563, loss_ce: 0.012385
2021-12-13 00:45:28,475 iteration 4087 : loss : 0.036016, loss_ce: 0.012405
2021-12-13 00:45:29,958 iteration 4088 : loss : 0.028990, loss_ce: 0.012487
2021-12-13 00:45:31,453 iteration 4089 : loss : 0.029221, loss_ce: 0.011596
2021-12-13 00:45:32,927 iteration 4090 : loss : 0.033068, loss_ce: 0.014935
2021-12-13 00:45:34,457 iteration 4091 : loss : 0.040549, loss_ce: 0.013602
2021-12-13 00:45:35,876 iteration 4092 : loss : 0.040111, loss_ce: 0.013293
2021-12-13 00:45:37,319 iteration 4093 : loss : 0.026713, loss_ce: 0.011048
2021-12-13 00:45:38,860 iteration 4094 : loss : 0.026764, loss_ce: 0.009304
2021-12-13 00:45:40,341 iteration 4095 : loss : 0.030624, loss_ce: 0.010354
2021-12-13 00:45:41,852 iteration 4096 : loss : 0.033697, loss_ce: 0.014571
2021-12-13 00:45:43,381 iteration 4097 : loss : 0.041375, loss_ce: 0.015946
 60%|████████████████▎          | 241/400 [1:50:25<1:13:41, 27.81s/it]2021-12-13 00:45:44,910 iteration 4098 : loss : 0.028073, loss_ce: 0.011952
2021-12-13 00:45:46,388 iteration 4099 : loss : 0.031234, loss_ce: 0.010303
2021-12-13 00:45:47,820 iteration 4100 : loss : 0.029686, loss_ce: 0.012950
2021-12-13 00:45:49,316 iteration 4101 : loss : 0.027327, loss_ce: 0.012403
2021-12-13 00:45:50,872 iteration 4102 : loss : 0.046049, loss_ce: 0.016293
2021-12-13 00:45:52,272 iteration 4103 : loss : 0.022555, loss_ce: 0.009710
2021-12-13 00:45:53,763 iteration 4104 : loss : 0.043798, loss_ce: 0.015864
2021-12-13 00:45:55,287 iteration 4105 : loss : 0.039508, loss_ce: 0.015941
2021-12-13 00:45:56,856 iteration 4106 : loss : 0.037550, loss_ce: 0.012799
2021-12-13 00:45:58,365 iteration 4107 : loss : 0.031534, loss_ce: 0.012617
2021-12-13 00:45:59,878 iteration 4108 : loss : 0.032563, loss_ce: 0.013888
2021-12-13 00:46:01,384 iteration 4109 : loss : 0.045606, loss_ce: 0.012118
2021-12-13 00:46:02,913 iteration 4110 : loss : 0.034982, loss_ce: 0.011255
2021-12-13 00:46:04,400 iteration 4111 : loss : 0.027623, loss_ce: 0.008419
2021-12-13 00:46:05,773 iteration 4112 : loss : 0.026701, loss_ce: 0.010580
2021-12-13 00:46:07,316 iteration 4113 : loss : 0.033092, loss_ce: 0.011630
2021-12-13 00:46:08,809 iteration 4114 : loss : 0.032069, loss_ce: 0.013250
 60%|████████████████▎          | 242/400 [1:50:50<1:11:20, 27.09s/it]2021-12-13 00:46:10,319 iteration 4115 : loss : 0.026697, loss_ce: 0.008142
2021-12-13 00:46:11,758 iteration 4116 : loss : 0.053117, loss_ce: 0.025064
2021-12-13 00:46:13,180 iteration 4117 : loss : 0.025656, loss_ce: 0.012701
2021-12-13 00:46:14,647 iteration 4118 : loss : 0.039155, loss_ce: 0.011152
2021-12-13 00:46:16,020 iteration 4119 : loss : 0.025372, loss_ce: 0.009445
2021-12-13 00:46:17,608 iteration 4120 : loss : 0.032062, loss_ce: 0.011279
2021-12-13 00:46:19,077 iteration 4121 : loss : 0.029765, loss_ce: 0.011266
2021-12-13 00:46:20,580 iteration 4122 : loss : 0.034437, loss_ce: 0.011961
2021-12-13 00:46:22,083 iteration 4123 : loss : 0.034997, loss_ce: 0.014142
2021-12-13 00:46:23,482 iteration 4124 : loss : 0.028272, loss_ce: 0.011665
2021-12-13 00:46:24,979 iteration 4125 : loss : 0.043828, loss_ce: 0.015190
2021-12-13 00:46:26,573 iteration 4126 : loss : 0.037545, loss_ce: 0.013923
2021-12-13 00:46:28,110 iteration 4127 : loss : 0.039265, loss_ce: 0.018427
2021-12-13 00:46:29,560 iteration 4128 : loss : 0.027651, loss_ce: 0.012495
2021-12-13 00:46:31,145 iteration 4129 : loss : 0.048246, loss_ce: 0.014229
2021-12-13 00:46:32,683 iteration 4130 : loss : 0.033326, loss_ce: 0.011882
2021-12-13 00:46:34,154 iteration 4131 : loss : 0.025111, loss_ce: 0.010690
 61%|████████████████▍          | 243/400 [1:51:16<1:09:31, 26.57s/it]2021-12-13 00:46:35,715 iteration 4132 : loss : 0.033002, loss_ce: 0.012047
2021-12-13 00:46:37,135 iteration 4133 : loss : 0.031502, loss_ce: 0.014805
2021-12-13 00:46:38,663 iteration 4134 : loss : 0.031187, loss_ce: 0.012785
2021-12-13 00:46:40,145 iteration 4135 : loss : 0.041218, loss_ce: 0.015005
2021-12-13 00:46:41,613 iteration 4136 : loss : 0.029688, loss_ce: 0.009360
2021-12-13 00:46:43,107 iteration 4137 : loss : 0.034310, loss_ce: 0.016629
2021-12-13 00:46:44,607 iteration 4138 : loss : 0.030545, loss_ce: 0.016342
2021-12-13 00:46:46,106 iteration 4139 : loss : 0.038763, loss_ce: 0.011462
2021-12-13 00:46:47,635 iteration 4140 : loss : 0.037159, loss_ce: 0.011380
2021-12-13 00:46:49,109 iteration 4141 : loss : 0.027929, loss_ce: 0.007773
2021-12-13 00:46:50,557 iteration 4142 : loss : 0.028593, loss_ce: 0.012285
2021-12-13 00:46:51,994 iteration 4143 : loss : 0.029957, loss_ce: 0.010779
2021-12-13 00:46:53,495 iteration 4144 : loss : 0.031376, loss_ce: 0.010952
2021-12-13 00:46:54,968 iteration 4145 : loss : 0.036556, loss_ce: 0.014808
2021-12-13 00:46:56,337 iteration 4146 : loss : 0.032026, loss_ce: 0.008871
2021-12-13 00:46:57,785 iteration 4147 : loss : 0.032546, loss_ce: 0.011391
2021-12-13 00:46:59,256 iteration 4148 : loss : 0.032301, loss_ce: 0.012539
 61%|████████████████▍          | 244/400 [1:51:41<1:07:56, 26.13s/it]2021-12-13 00:47:00,778 iteration 4149 : loss : 0.033368, loss_ce: 0.012694
2021-12-13 00:47:02,231 iteration 4150 : loss : 0.029521, loss_ce: 0.010558
2021-12-13 00:47:03,697 iteration 4151 : loss : 0.028027, loss_ce: 0.012128
2021-12-13 00:47:05,242 iteration 4152 : loss : 0.028435, loss_ce: 0.012622
2021-12-13 00:47:06,757 iteration 4153 : loss : 0.035920, loss_ce: 0.016646
2021-12-13 00:47:08,171 iteration 4154 : loss : 0.022194, loss_ce: 0.009642
2021-12-13 00:47:09,606 iteration 4155 : loss : 0.026948, loss_ce: 0.012995
2021-12-13 00:47:11,089 iteration 4156 : loss : 0.032565, loss_ce: 0.011499
2021-12-13 00:47:12,570 iteration 4157 : loss : 0.033401, loss_ce: 0.012780
2021-12-13 00:47:14,024 iteration 4158 : loss : 0.023924, loss_ce: 0.009404
2021-12-13 00:47:15,550 iteration 4159 : loss : 0.025222, loss_ce: 0.011264
2021-12-13 00:47:17,056 iteration 4160 : loss : 0.038351, loss_ce: 0.014719
2021-12-13 00:47:18,502 iteration 4161 : loss : 0.038554, loss_ce: 0.010815
2021-12-13 00:47:20,000 iteration 4162 : loss : 0.037934, loss_ce: 0.012953
2021-12-13 00:47:21,490 iteration 4163 : loss : 0.032972, loss_ce: 0.014036
2021-12-13 00:47:22,944 iteration 4164 : loss : 0.038182, loss_ce: 0.011568
2021-12-13 00:47:22,944 Training Data Eval:
2021-12-13 00:47:30,463   Average segmentation loss on training set: 0.0184
2021-12-13 00:47:30,463 Validation Data Eval:
2021-12-13 00:47:33,065   Average segmentation loss on validation set: 0.0790
2021-12-13 00:47:34,556 iteration 4165 : loss : 0.031665, loss_ce: 0.009489
 61%|████████████████▌          | 245/400 [1:52:16<1:14:36, 28.88s/it]2021-12-13 00:47:36,048 iteration 4166 : loss : 0.042320, loss_ce: 0.012234
2021-12-13 00:47:37,490 iteration 4167 : loss : 0.023905, loss_ce: 0.010165
2021-12-13 00:47:38,881 iteration 4168 : loss : 0.025786, loss_ce: 0.008111
2021-12-13 00:47:40,303 iteration 4169 : loss : 0.030000, loss_ce: 0.012859
2021-12-13 00:47:41,857 iteration 4170 : loss : 0.038359, loss_ce: 0.014274
2021-12-13 00:47:43,429 iteration 4171 : loss : 0.039707, loss_ce: 0.013584
2021-12-13 00:47:44,843 iteration 4172 : loss : 0.027108, loss_ce: 0.006894
2021-12-13 00:47:46,315 iteration 4173 : loss : 0.030687, loss_ce: 0.011649
2021-12-13 00:47:47,793 iteration 4174 : loss : 0.035307, loss_ce: 0.015428
2021-12-13 00:47:49,315 iteration 4175 : loss : 0.033878, loss_ce: 0.013498
2021-12-13 00:47:50,801 iteration 4176 : loss : 0.025763, loss_ce: 0.010675
2021-12-13 00:47:52,296 iteration 4177 : loss : 0.035158, loss_ce: 0.012668
2021-12-13 00:47:53,766 iteration 4178 : loss : 0.024580, loss_ce: 0.010818
2021-12-13 00:47:55,334 iteration 4179 : loss : 0.034065, loss_ce: 0.013677
2021-12-13 00:47:56,809 iteration 4180 : loss : 0.046819, loss_ce: 0.015256
2021-12-13 00:47:58,181 iteration 4181 : loss : 0.035811, loss_ce: 0.011343
2021-12-13 00:47:59,684 iteration 4182 : loss : 0.035917, loss_ce: 0.014674
 62%|████████████████▌          | 246/400 [1:52:41<1:11:13, 27.75s/it]2021-12-13 00:48:01,222 iteration 4183 : loss : 0.027944, loss_ce: 0.010348
2021-12-13 00:48:02,708 iteration 4184 : loss : 0.045756, loss_ce: 0.018170
2021-12-13 00:48:04,183 iteration 4185 : loss : 0.034502, loss_ce: 0.012948
2021-12-13 00:48:05,625 iteration 4186 : loss : 0.025013, loss_ce: 0.009766
2021-12-13 00:48:07,169 iteration 4187 : loss : 0.031279, loss_ce: 0.011068
2021-12-13 00:48:08,691 iteration 4188 : loss : 0.032530, loss_ce: 0.015952
2021-12-13 00:48:10,188 iteration 4189 : loss : 0.030189, loss_ce: 0.009468
2021-12-13 00:48:11,730 iteration 4190 : loss : 0.036811, loss_ce: 0.013969
2021-12-13 00:48:13,188 iteration 4191 : loss : 0.035576, loss_ce: 0.011674
2021-12-13 00:48:14,662 iteration 4192 : loss : 0.034967, loss_ce: 0.009437
2021-12-13 00:48:16,146 iteration 4193 : loss : 0.027315, loss_ce: 0.009794
2021-12-13 00:48:17,647 iteration 4194 : loss : 0.036662, loss_ce: 0.014644
2021-12-13 00:48:19,281 iteration 4195 : loss : 0.048062, loss_ce: 0.014718
2021-12-13 00:48:20,719 iteration 4196 : loss : 0.023345, loss_ce: 0.011857
2021-12-13 00:48:22,253 iteration 4197 : loss : 0.037356, loss_ce: 0.011850
2021-12-13 00:48:23,744 iteration 4198 : loss : 0.034514, loss_ce: 0.014920
2021-12-13 00:48:25,147 iteration 4199 : loss : 0.031638, loss_ce: 0.011645
 62%|████████████████▋          | 247/400 [1:53:07<1:09:01, 27.07s/it]2021-12-13 00:48:26,625 iteration 4200 : loss : 0.025974, loss_ce: 0.008191
2021-12-13 00:48:28,134 iteration 4201 : loss : 0.030604, loss_ce: 0.012385
2021-12-13 00:48:29,537 iteration 4202 : loss : 0.026591, loss_ce: 0.012760
2021-12-13 00:48:30,968 iteration 4203 : loss : 0.027269, loss_ce: 0.011287
2021-12-13 00:48:32,430 iteration 4204 : loss : 0.034678, loss_ce: 0.012479
2021-12-13 00:48:33,866 iteration 4205 : loss : 0.025468, loss_ce: 0.009578
2021-12-13 00:48:35,260 iteration 4206 : loss : 0.032075, loss_ce: 0.010295
2021-12-13 00:48:36,685 iteration 4207 : loss : 0.029140, loss_ce: 0.012746
2021-12-13 00:48:38,126 iteration 4208 : loss : 0.030007, loss_ce: 0.010864
2021-12-13 00:48:39,686 iteration 4209 : loss : 0.070376, loss_ce: 0.020883
2021-12-13 00:48:41,228 iteration 4210 : loss : 0.033834, loss_ce: 0.012968
2021-12-13 00:48:42,563 iteration 4211 : loss : 0.020130, loss_ce: 0.008793
2021-12-13 00:48:44,023 iteration 4212 : loss : 0.026648, loss_ce: 0.011870
2021-12-13 00:48:45,486 iteration 4213 : loss : 0.030481, loss_ce: 0.014757
2021-12-13 00:48:47,006 iteration 4214 : loss : 0.042645, loss_ce: 0.014667
2021-12-13 00:48:48,448 iteration 4215 : loss : 0.038405, loss_ce: 0.016314
2021-12-13 00:48:50,012 iteration 4216 : loss : 0.042755, loss_ce: 0.013324
 62%|████████████████▋          | 248/400 [1:53:31<1:06:54, 26.41s/it]2021-12-13 00:48:51,622 iteration 4217 : loss : 0.026468, loss_ce: 0.011349
2021-12-13 00:48:53,022 iteration 4218 : loss : 0.023377, loss_ce: 0.012000
2021-12-13 00:48:54,438 iteration 4219 : loss : 0.029079, loss_ce: 0.011473
2021-12-13 00:48:56,024 iteration 4220 : loss : 0.041500, loss_ce: 0.016764
2021-12-13 00:48:57,533 iteration 4221 : loss : 0.033619, loss_ce: 0.010772
2021-12-13 00:48:59,040 iteration 4222 : loss : 0.034906, loss_ce: 0.014728
2021-12-13 00:49:00,522 iteration 4223 : loss : 0.030071, loss_ce: 0.010327
2021-12-13 00:49:01,988 iteration 4224 : loss : 0.027403, loss_ce: 0.009920
2021-12-13 00:49:03,445 iteration 4225 : loss : 0.035554, loss_ce: 0.012188
2021-12-13 00:49:04,896 iteration 4226 : loss : 0.026866, loss_ce: 0.007976
2021-12-13 00:49:06,469 iteration 4227 : loss : 0.041098, loss_ce: 0.013559
2021-12-13 00:49:07,936 iteration 4228 : loss : 0.026463, loss_ce: 0.010423
2021-12-13 00:49:09,465 iteration 4229 : loss : 0.028815, loss_ce: 0.011553
2021-12-13 00:49:10,945 iteration 4230 : loss : 0.027141, loss_ce: 0.013786
2021-12-13 00:49:12,388 iteration 4231 : loss : 0.037073, loss_ce: 0.011810
2021-12-13 00:49:13,835 iteration 4232 : loss : 0.028833, loss_ce: 0.012303
2021-12-13 00:49:15,302 iteration 4233 : loss : 0.035106, loss_ce: 0.016420
 62%|████████████████▊          | 249/400 [1:53:57<1:05:36, 26.07s/it]2021-12-13 00:49:16,875 iteration 4234 : loss : 0.036063, loss_ce: 0.015152
2021-12-13 00:49:18,338 iteration 4235 : loss : 0.024995, loss_ce: 0.008280
2021-12-13 00:49:19,744 iteration 4236 : loss : 0.030912, loss_ce: 0.011477
2021-12-13 00:49:21,163 iteration 4237 : loss : 0.026637, loss_ce: 0.011039
2021-12-13 00:49:22,612 iteration 4238 : loss : 0.032762, loss_ce: 0.010878
2021-12-13 00:49:24,126 iteration 4239 : loss : 0.028289, loss_ce: 0.011666
2021-12-13 00:49:25,628 iteration 4240 : loss : 0.043810, loss_ce: 0.014543
2021-12-13 00:49:27,098 iteration 4241 : loss : 0.034173, loss_ce: 0.014214
2021-12-13 00:49:28,452 iteration 4242 : loss : 0.021778, loss_ce: 0.009131
2021-12-13 00:49:29,946 iteration 4243 : loss : 0.031898, loss_ce: 0.011942
2021-12-13 00:49:31,365 iteration 4244 : loss : 0.030208, loss_ce: 0.010600
2021-12-13 00:49:32,811 iteration 4245 : loss : 0.025359, loss_ce: 0.009395
2021-12-13 00:49:34,247 iteration 4246 : loss : 0.026059, loss_ce: 0.009963
2021-12-13 00:49:35,697 iteration 4247 : loss : 0.034456, loss_ce: 0.011557
2021-12-13 00:49:37,085 iteration 4248 : loss : 0.029219, loss_ce: 0.012614
2021-12-13 00:49:38,613 iteration 4249 : loss : 0.029557, loss_ce: 0.012453
2021-12-13 00:49:38,613 Training Data Eval:
2021-12-13 00:49:46,148   Average segmentation loss on training set: 0.0166
2021-12-13 00:49:46,149 Validation Data Eval:
2021-12-13 00:49:48,748   Average segmentation loss on validation set: 0.0867
2021-12-13 00:49:50,227 iteration 4250 : loss : 0.031229, loss_ce: 0.012408
 62%|████████████████▉          | 250/400 [1:54:32<1:11:49, 28.73s/it]2021-12-13 00:49:51,758 iteration 4251 : loss : 0.029152, loss_ce: 0.009689
2021-12-13 00:49:53,228 iteration 4252 : loss : 0.031379, loss_ce: 0.009210
2021-12-13 00:49:54,722 iteration 4253 : loss : 0.024908, loss_ce: 0.012440
2021-12-13 00:49:56,222 iteration 4254 : loss : 0.026726, loss_ce: 0.010602
2021-12-13 00:49:57,723 iteration 4255 : loss : 0.045778, loss_ce: 0.014829
2021-12-13 00:49:59,162 iteration 4256 : loss : 0.026192, loss_ce: 0.009371
2021-12-13 00:50:00,635 iteration 4257 : loss : 0.024113, loss_ce: 0.010771
2021-12-13 00:50:02,174 iteration 4258 : loss : 0.035196, loss_ce: 0.016023
2021-12-13 00:50:03,562 iteration 4259 : loss : 0.027551, loss_ce: 0.009871
2021-12-13 00:50:05,046 iteration 4260 : loss : 0.022737, loss_ce: 0.007494
2021-12-13 00:50:06,452 iteration 4261 : loss : 0.024141, loss_ce: 0.008273
2021-12-13 00:50:07,898 iteration 4262 : loss : 0.026144, loss_ce: 0.011386
2021-12-13 00:50:09,405 iteration 4263 : loss : 0.033106, loss_ce: 0.013422
2021-12-13 00:50:10,859 iteration 4264 : loss : 0.029772, loss_ce: 0.013322
2021-12-13 00:50:12,212 iteration 4265 : loss : 0.023928, loss_ce: 0.010521
2021-12-13 00:50:13,714 iteration 4266 : loss : 0.030764, loss_ce: 0.009633
2021-12-13 00:50:15,211 iteration 4267 : loss : 0.032845, loss_ce: 0.014562
 63%|████████████████▉          | 251/400 [1:54:57<1:08:32, 27.60s/it]2021-12-13 00:50:16,649 iteration 4268 : loss : 0.023141, loss_ce: 0.009021
2021-12-13 00:50:18,052 iteration 4269 : loss : 0.024334, loss_ce: 0.008110
2021-12-13 00:50:19,495 iteration 4270 : loss : 0.030737, loss_ce: 0.009179
2021-12-13 00:50:20,937 iteration 4271 : loss : 0.027059, loss_ce: 0.010272
2021-12-13 00:50:22,392 iteration 4272 : loss : 0.037083, loss_ce: 0.016106
2021-12-13 00:50:23,822 iteration 4273 : loss : 0.027664, loss_ce: 0.011501
2021-12-13 00:50:25,279 iteration 4274 : loss : 0.035193, loss_ce: 0.015635
2021-12-13 00:50:26,720 iteration 4275 : loss : 0.031025, loss_ce: 0.012501
2021-12-13 00:50:28,158 iteration 4276 : loss : 0.031301, loss_ce: 0.012277
2021-12-13 00:50:29,640 iteration 4277 : loss : 0.031579, loss_ce: 0.013941
2021-12-13 00:50:31,090 iteration 4278 : loss : 0.022513, loss_ce: 0.006731
2021-12-13 00:50:32,505 iteration 4279 : loss : 0.029943, loss_ce: 0.012794
2021-12-13 00:50:33,974 iteration 4280 : loss : 0.043182, loss_ce: 0.012930
2021-12-13 00:50:35,444 iteration 4281 : loss : 0.042885, loss_ce: 0.016768
2021-12-13 00:50:36,937 iteration 4282 : loss : 0.037010, loss_ce: 0.013746
2021-12-13 00:50:38,482 iteration 4283 : loss : 0.025837, loss_ce: 0.012416
2021-12-13 00:50:40,019 iteration 4284 : loss : 0.053626, loss_ce: 0.020678
 63%|█████████████████          | 252/400 [1:55:21<1:06:01, 26.77s/it]2021-12-13 00:50:41,468 iteration 4285 : loss : 0.024614, loss_ce: 0.012225
2021-12-13 00:50:42,892 iteration 4286 : loss : 0.024359, loss_ce: 0.009482
2021-12-13 00:50:44,367 iteration 4287 : loss : 0.033757, loss_ce: 0.012946
2021-12-13 00:50:45,783 iteration 4288 : loss : 0.023158, loss_ce: 0.007919
2021-12-13 00:50:47,201 iteration 4289 : loss : 0.022877, loss_ce: 0.010266
2021-12-13 00:50:48,662 iteration 4290 : loss : 0.025941, loss_ce: 0.009803
2021-12-13 00:50:50,191 iteration 4291 : loss : 0.038266, loss_ce: 0.017363
2021-12-13 00:50:51,706 iteration 4292 : loss : 0.034886, loss_ce: 0.018000
2021-12-13 00:50:53,074 iteration 4293 : loss : 0.032279, loss_ce: 0.012327
2021-12-13 00:50:54,498 iteration 4294 : loss : 0.028725, loss_ce: 0.013919
2021-12-13 00:50:56,096 iteration 4295 : loss : 0.038534, loss_ce: 0.013855
2021-12-13 00:50:57,538 iteration 4296 : loss : 0.029604, loss_ce: 0.011533
2021-12-13 00:50:58,965 iteration 4297 : loss : 0.024793, loss_ce: 0.007993
2021-12-13 00:51:00,494 iteration 4298 : loss : 0.036118, loss_ce: 0.012336
2021-12-13 00:51:01,989 iteration 4299 : loss : 0.030262, loss_ce: 0.010079
2021-12-13 00:51:03,548 iteration 4300 : loss : 0.048621, loss_ce: 0.016481
2021-12-13 00:51:05,018 iteration 4301 : loss : 0.044151, loss_ce: 0.016428
 63%|█████████████████          | 253/400 [1:55:46<1:04:16, 26.23s/it]2021-12-13 00:51:06,588 iteration 4302 : loss : 0.032838, loss_ce: 0.013096
2021-12-13 00:51:07,985 iteration 4303 : loss : 0.026022, loss_ce: 0.012928
2021-12-13 00:51:09,448 iteration 4304 : loss : 0.037976, loss_ce: 0.018846
2021-12-13 00:51:10,925 iteration 4305 : loss : 0.034063, loss_ce: 0.010490
2021-12-13 00:51:12,385 iteration 4306 : loss : 0.028589, loss_ce: 0.010599
2021-12-13 00:51:13,934 iteration 4307 : loss : 0.030188, loss_ce: 0.010374
2021-12-13 00:51:15,387 iteration 4308 : loss : 0.028470, loss_ce: 0.010670
2021-12-13 00:51:16,896 iteration 4309 : loss : 0.034609, loss_ce: 0.011672
2021-12-13 00:51:18,306 iteration 4310 : loss : 0.026020, loss_ce: 0.008360
2021-12-13 00:51:19,884 iteration 4311 : loss : 0.033724, loss_ce: 0.012637
2021-12-13 00:51:21,333 iteration 4312 : loss : 0.030152, loss_ce: 0.014739
2021-12-13 00:51:22,853 iteration 4313 : loss : 0.034319, loss_ce: 0.015060
2021-12-13 00:51:24,337 iteration 4314 : loss : 0.028331, loss_ce: 0.009061
2021-12-13 00:51:25,788 iteration 4315 : loss : 0.022428, loss_ce: 0.008272
2021-12-13 00:51:27,231 iteration 4316 : loss : 0.031931, loss_ce: 0.012172
2021-12-13 00:51:28,704 iteration 4317 : loss : 0.026308, loss_ce: 0.011417
2021-12-13 00:51:30,266 iteration 4318 : loss : 0.025848, loss_ce: 0.010425
 64%|█████████████████▏         | 254/400 [1:56:12<1:03:07, 25.94s/it]2021-12-13 00:51:31,762 iteration 4319 : loss : 0.028449, loss_ce: 0.011430
2021-12-13 00:51:33,133 iteration 4320 : loss : 0.023703, loss_ce: 0.010335
2021-12-13 00:51:34,742 iteration 4321 : loss : 0.036258, loss_ce: 0.017258
2021-12-13 00:51:36,203 iteration 4322 : loss : 0.032671, loss_ce: 0.012364
2021-12-13 00:51:37,665 iteration 4323 : loss : 0.032770, loss_ce: 0.011285
2021-12-13 00:51:39,107 iteration 4324 : loss : 0.018753, loss_ce: 0.008926
2021-12-13 00:51:40,548 iteration 4325 : loss : 0.036998, loss_ce: 0.011070
2021-12-13 00:51:42,055 iteration 4326 : loss : 0.036189, loss_ce: 0.012032
2021-12-13 00:51:43,601 iteration 4327 : loss : 0.025710, loss_ce: 0.010518
2021-12-13 00:51:45,105 iteration 4328 : loss : 0.032559, loss_ce: 0.014900
2021-12-13 00:51:46,553 iteration 4329 : loss : 0.024987, loss_ce: 0.009222
2021-12-13 00:51:47,960 iteration 4330 : loss : 0.025430, loss_ce: 0.011342
2021-12-13 00:51:49,400 iteration 4331 : loss : 0.029723, loss_ce: 0.013320
2021-12-13 00:51:50,807 iteration 4332 : loss : 0.028277, loss_ce: 0.010785
2021-12-13 00:51:52,172 iteration 4333 : loss : 0.029368, loss_ce: 0.011742
2021-12-13 00:51:53,648 iteration 4334 : loss : 0.027802, loss_ce: 0.009491
2021-12-13 00:51:53,648 Training Data Eval:
2021-12-13 00:52:01,179   Average segmentation loss on training set: 0.0174
2021-12-13 00:52:01,179 Validation Data Eval:
2021-12-13 00:52:03,776   Average segmentation loss on validation set: 0.0798
2021-12-13 00:52:05,262 iteration 4335 : loss : 0.052539, loss_ce: 0.013493
 64%|█████████████████▏         | 255/400 [1:56:47<1:09:14, 28.65s/it]2021-12-13 00:52:06,685 iteration 4336 : loss : 0.027492, loss_ce: 0.011004
2021-12-13 00:52:08,171 iteration 4337 : loss : 0.027303, loss_ce: 0.011262
2021-12-13 00:52:09,659 iteration 4338 : loss : 0.031803, loss_ce: 0.011867
2021-12-13 00:52:11,046 iteration 4339 : loss : 0.034208, loss_ce: 0.009953
2021-12-13 00:52:12,528 iteration 4340 : loss : 0.039832, loss_ce: 0.009327
2021-12-13 00:52:13,989 iteration 4341 : loss : 0.025543, loss_ce: 0.011283
2021-12-13 00:52:15,431 iteration 4342 : loss : 0.023382, loss_ce: 0.009653
2021-12-13 00:52:16,963 iteration 4343 : loss : 0.038469, loss_ce: 0.013261
2021-12-13 00:52:18,388 iteration 4344 : loss : 0.027647, loss_ce: 0.011407
2021-12-13 00:52:19,823 iteration 4345 : loss : 0.027104, loss_ce: 0.011441
2021-12-13 00:52:21,177 iteration 4346 : loss : 0.020862, loss_ce: 0.008068
2021-12-13 00:52:22,698 iteration 4347 : loss : 0.041561, loss_ce: 0.011656
2021-12-13 00:52:24,213 iteration 4348 : loss : 0.025693, loss_ce: 0.011077
2021-12-13 00:52:25,616 iteration 4349 : loss : 0.026581, loss_ce: 0.010939
2021-12-13 00:52:27,013 iteration 4350 : loss : 0.026736, loss_ce: 0.008839
2021-12-13 00:52:28,542 iteration 4351 : loss : 0.037706, loss_ce: 0.015691
2021-12-13 00:52:30,045 iteration 4352 : loss : 0.042839, loss_ce: 0.015552
 64%|█████████████████▎         | 256/400 [1:57:12<1:05:59, 27.49s/it]2021-12-13 00:52:31,511 iteration 4353 : loss : 0.021296, loss_ce: 0.007936
2021-12-13 00:52:33,040 iteration 4354 : loss : 0.033863, loss_ce: 0.010222
2021-12-13 00:52:34,536 iteration 4355 : loss : 0.023095, loss_ce: 0.008157
2021-12-13 00:52:35,972 iteration 4356 : loss : 0.032826, loss_ce: 0.012650
2021-12-13 00:52:37,507 iteration 4357 : loss : 0.039066, loss_ce: 0.013676
2021-12-13 00:52:38,940 iteration 4358 : loss : 0.032779, loss_ce: 0.013834
2021-12-13 00:52:40,440 iteration 4359 : loss : 0.034558, loss_ce: 0.010481
2021-12-13 00:52:41,850 iteration 4360 : loss : 0.028567, loss_ce: 0.011326
2021-12-13 00:52:43,365 iteration 4361 : loss : 0.041806, loss_ce: 0.015816
2021-12-13 00:52:44,773 iteration 4362 : loss : 0.025432, loss_ce: 0.008732
2021-12-13 00:52:46,265 iteration 4363 : loss : 0.031232, loss_ce: 0.012219
2021-12-13 00:52:47,729 iteration 4364 : loss : 0.025472, loss_ce: 0.011530
2021-12-13 00:52:49,238 iteration 4365 : loss : 0.030976, loss_ce: 0.012330
2021-12-13 00:52:50,672 iteration 4366 : loss : 0.026747, loss_ce: 0.011231
2021-12-13 00:52:52,069 iteration 4367 : loss : 0.027269, loss_ce: 0.011974
2021-12-13 00:52:53,501 iteration 4368 : loss : 0.022869, loss_ce: 0.008623
2021-12-13 00:52:55,012 iteration 4369 : loss : 0.024906, loss_ce: 0.009685
 64%|█████████████████▎         | 257/400 [1:57:36<1:03:43, 26.74s/it]2021-12-13 00:52:56,474 iteration 4370 : loss : 0.032184, loss_ce: 0.011719
2021-12-13 00:52:58,116 iteration 4371 : loss : 0.046178, loss_ce: 0.015514
2021-12-13 00:52:59,627 iteration 4372 : loss : 0.057866, loss_ce: 0.015191
2021-12-13 00:53:01,136 iteration 4373 : loss : 0.040254, loss_ce: 0.015452
2021-12-13 00:53:02,580 iteration 4374 : loss : 0.030982, loss_ce: 0.012205
2021-12-13 00:53:04,068 iteration 4375 : loss : 0.024980, loss_ce: 0.010800
2021-12-13 00:53:05,565 iteration 4376 : loss : 0.031695, loss_ce: 0.010504
2021-12-13 00:53:06,992 iteration 4377 : loss : 0.028397, loss_ce: 0.010296
2021-12-13 00:53:08,506 iteration 4378 : loss : 0.031104, loss_ce: 0.015156
2021-12-13 00:53:09,957 iteration 4379 : loss : 0.028793, loss_ce: 0.011151
2021-12-13 00:53:11,429 iteration 4380 : loss : 0.028040, loss_ce: 0.010726
2021-12-13 00:53:12,922 iteration 4381 : loss : 0.031634, loss_ce: 0.009728
2021-12-13 00:53:14,492 iteration 4382 : loss : 0.038267, loss_ce: 0.014481
2021-12-13 00:53:15,975 iteration 4383 : loss : 0.037531, loss_ce: 0.012694
2021-12-13 00:53:17,491 iteration 4384 : loss : 0.037269, loss_ce: 0.012809
2021-12-13 00:53:19,018 iteration 4385 : loss : 0.034043, loss_ce: 0.016498
2021-12-13 00:53:20,468 iteration 4386 : loss : 0.024415, loss_ce: 0.007259
 64%|█████████████████▍         | 258/400 [1:58:02<1:02:21, 26.35s/it]2021-12-13 00:53:22,060 iteration 4387 : loss : 0.043672, loss_ce: 0.010951
2021-12-13 00:53:23,548 iteration 4388 : loss : 0.029995, loss_ce: 0.013964
2021-12-13 00:53:25,038 iteration 4389 : loss : 0.028240, loss_ce: 0.012756
2021-12-13 00:53:26,552 iteration 4390 : loss : 0.034664, loss_ce: 0.015268
2021-12-13 00:53:28,116 iteration 4391 : loss : 0.033414, loss_ce: 0.012132
2021-12-13 00:53:29,617 iteration 4392 : loss : 0.025521, loss_ce: 0.011065
2021-12-13 00:53:31,185 iteration 4393 : loss : 0.032841, loss_ce: 0.013256
2021-12-13 00:53:32,587 iteration 4394 : loss : 0.023811, loss_ce: 0.009319
2021-12-13 00:53:34,079 iteration 4395 : loss : 0.023625, loss_ce: 0.011343
2021-12-13 00:53:35,560 iteration 4396 : loss : 0.036148, loss_ce: 0.013252
2021-12-13 00:53:36,970 iteration 4397 : loss : 0.022842, loss_ce: 0.007692
2021-12-13 00:53:38,436 iteration 4398 : loss : 0.024112, loss_ce: 0.009188
2021-12-13 00:53:39,906 iteration 4399 : loss : 0.030215, loss_ce: 0.009330
2021-12-13 00:53:41,318 iteration 4400 : loss : 0.025569, loss_ce: 0.008780
2021-12-13 00:53:42,825 iteration 4401 : loss : 0.034088, loss_ce: 0.016117
2021-12-13 00:53:44,214 iteration 4402 : loss : 0.027028, loss_ce: 0.009114
2021-12-13 00:53:45,693 iteration 4403 : loss : 0.026546, loss_ce: 0.009287
 65%|█████████████████▍         | 259/400 [1:58:27<1:01:08, 26.01s/it]2021-12-13 00:53:47,270 iteration 4404 : loss : 0.045226, loss_ce: 0.019656
2021-12-13 00:53:48,745 iteration 4405 : loss : 0.039372, loss_ce: 0.014387
2021-12-13 00:53:50,254 iteration 4406 : loss : 0.029501, loss_ce: 0.012979
2021-12-13 00:53:51,744 iteration 4407 : loss : 0.039327, loss_ce: 0.010279
2021-12-13 00:53:53,178 iteration 4408 : loss : 0.025339, loss_ce: 0.012530
2021-12-13 00:53:54,593 iteration 4409 : loss : 0.031101, loss_ce: 0.011336
2021-12-13 00:53:56,168 iteration 4410 : loss : 0.033333, loss_ce: 0.011103
2021-12-13 00:53:57,656 iteration 4411 : loss : 0.032540, loss_ce: 0.012266
2021-12-13 00:53:59,137 iteration 4412 : loss : 0.028076, loss_ce: 0.010749
2021-12-13 00:54:00,633 iteration 4413 : loss : 0.024790, loss_ce: 0.010509
2021-12-13 00:54:02,080 iteration 4414 : loss : 0.033476, loss_ce: 0.010761
2021-12-13 00:54:03,490 iteration 4415 : loss : 0.023573, loss_ce: 0.011502
2021-12-13 00:54:04,984 iteration 4416 : loss : 0.035554, loss_ce: 0.015607
2021-12-13 00:54:06,476 iteration 4417 : loss : 0.027785, loss_ce: 0.012736
2021-12-13 00:54:07,960 iteration 4418 : loss : 0.022990, loss_ce: 0.009941
2021-12-13 00:54:09,412 iteration 4419 : loss : 0.023601, loss_ce: 0.009136
2021-12-13 00:54:09,412 Training Data Eval:
2021-12-13 00:54:16,940   Average segmentation loss on training set: 0.0180
2021-12-13 00:54:16,941 Validation Data Eval:
2021-12-13 00:54:19,543   Average segmentation loss on validation set: 0.0791
2021-12-13 00:54:20,983 iteration 4420 : loss : 0.027900, loss_ce: 0.008764
 65%|█████████████████▌         | 260/400 [1:59:02<1:07:11, 28.80s/it]2021-12-13 00:54:22,487 iteration 4421 : loss : 0.038217, loss_ce: 0.010798
2021-12-13 00:54:23,933 iteration 4422 : loss : 0.028140, loss_ce: 0.009861
2021-12-13 00:54:25,373 iteration 4423 : loss : 0.022333, loss_ce: 0.008254
2021-12-13 00:54:26,886 iteration 4424 : loss : 0.031695, loss_ce: 0.012282
2021-12-13 00:54:28,351 iteration 4425 : loss : 0.049997, loss_ce: 0.016892
2021-12-13 00:54:29,801 iteration 4426 : loss : 0.021595, loss_ce: 0.006918
2021-12-13 00:54:31,279 iteration 4427 : loss : 0.028919, loss_ce: 0.012149
2021-12-13 00:54:32,778 iteration 4428 : loss : 0.032584, loss_ce: 0.013626
2021-12-13 00:54:34,150 iteration 4429 : loss : 0.029949, loss_ce: 0.013568
2021-12-13 00:54:35,622 iteration 4430 : loss : 0.034330, loss_ce: 0.015863
2021-12-13 00:54:37,132 iteration 4431 : loss : 0.040061, loss_ce: 0.012770
2021-12-13 00:54:38,665 iteration 4432 : loss : 0.037668, loss_ce: 0.018455
2021-12-13 00:54:40,160 iteration 4433 : loss : 0.034261, loss_ce: 0.011924
2021-12-13 00:54:41,667 iteration 4434 : loss : 0.031498, loss_ce: 0.012588
2021-12-13 00:54:43,089 iteration 4435 : loss : 0.026213, loss_ce: 0.008687
2021-12-13 00:54:44,534 iteration 4436 : loss : 0.027549, loss_ce: 0.013540
2021-12-13 00:54:45,982 iteration 4437 : loss : 0.027491, loss_ce: 0.009791
 65%|█████████████████▌         | 261/400 [1:59:27<1:04:04, 27.66s/it]2021-12-13 00:54:47,575 iteration 4438 : loss : 0.028675, loss_ce: 0.010316
2021-12-13 00:54:48,966 iteration 4439 : loss : 0.022081, loss_ce: 0.010788
2021-12-13 00:54:50,502 iteration 4440 : loss : 0.031730, loss_ce: 0.015038
2021-12-13 00:54:51,977 iteration 4441 : loss : 0.024511, loss_ce: 0.010194
2021-12-13 00:54:53,541 iteration 4442 : loss : 0.038364, loss_ce: 0.013274
2021-12-13 00:54:55,094 iteration 4443 : loss : 0.041108, loss_ce: 0.015181
2021-12-13 00:54:56,592 iteration 4444 : loss : 0.028821, loss_ce: 0.011002
2021-12-13 00:54:58,039 iteration 4445 : loss : 0.027053, loss_ce: 0.008884
2021-12-13 00:54:59,563 iteration 4446 : loss : 0.066077, loss_ce: 0.016074
2021-12-13 00:55:01,126 iteration 4447 : loss : 0.035598, loss_ce: 0.012698
2021-12-13 00:55:02,583 iteration 4448 : loss : 0.030248, loss_ce: 0.010368
2021-12-13 00:55:04,149 iteration 4449 : loss : 0.031740, loss_ce: 0.014652
2021-12-13 00:55:05,613 iteration 4450 : loss : 0.033567, loss_ce: 0.015568
2021-12-13 00:55:07,123 iteration 4451 : loss : 0.027619, loss_ce: 0.009757
2021-12-13 00:55:08,555 iteration 4452 : loss : 0.033351, loss_ce: 0.010114
2021-12-13 00:55:09,975 iteration 4453 : loss : 0.030639, loss_ce: 0.011894
2021-12-13 00:55:11,423 iteration 4454 : loss : 0.032128, loss_ce: 0.013953
 66%|█████████████████▋         | 262/400 [1:59:53<1:02:04, 26.99s/it]2021-12-13 00:55:12,910 iteration 4455 : loss : 0.041072, loss_ce: 0.012724
2021-12-13 00:55:14,311 iteration 4456 : loss : 0.031216, loss_ce: 0.011533
2021-12-13 00:55:15,764 iteration 4457 : loss : 0.028801, loss_ce: 0.011188
2021-12-13 00:55:17,198 iteration 4458 : loss : 0.032374, loss_ce: 0.012865
2021-12-13 00:55:18,701 iteration 4459 : loss : 0.047463, loss_ce: 0.012626
2021-12-13 00:55:20,127 iteration 4460 : loss : 0.024463, loss_ce: 0.010175
2021-12-13 00:55:21,573 iteration 4461 : loss : 0.027889, loss_ce: 0.012357
2021-12-13 00:55:23,122 iteration 4462 : loss : 0.038221, loss_ce: 0.011967
2021-12-13 00:55:24,533 iteration 4463 : loss : 0.023271, loss_ce: 0.008395
2021-12-13 00:55:25,973 iteration 4464 : loss : 0.022444, loss_ce: 0.010056
2021-12-13 00:55:27,546 iteration 4465 : loss : 0.043658, loss_ce: 0.011039
2021-12-13 00:55:28,942 iteration 4466 : loss : 0.022072, loss_ce: 0.008661
2021-12-13 00:55:30,440 iteration 4467 : loss : 0.030384, loss_ce: 0.013912
2021-12-13 00:55:31,902 iteration 4468 : loss : 0.032998, loss_ce: 0.011265
2021-12-13 00:55:33,365 iteration 4469 : loss : 0.026454, loss_ce: 0.007906
2021-12-13 00:55:34,818 iteration 4470 : loss : 0.032036, loss_ce: 0.014150
2021-12-13 00:55:36,333 iteration 4471 : loss : 0.035573, loss_ce: 0.011631
 66%|█████████████████▊         | 263/400 [2:00:18<1:00:12, 26.37s/it]2021-12-13 00:55:37,796 iteration 4472 : loss : 0.029941, loss_ce: 0.013434
2021-12-13 00:55:39,307 iteration 4473 : loss : 0.038292, loss_ce: 0.014215
2021-12-13 00:55:40,875 iteration 4474 : loss : 0.032943, loss_ce: 0.014282
2021-12-13 00:55:42,379 iteration 4475 : loss : 0.032160, loss_ce: 0.012942
2021-12-13 00:55:43,825 iteration 4476 : loss : 0.032598, loss_ce: 0.011250
2021-12-13 00:55:45,271 iteration 4477 : loss : 0.024739, loss_ce: 0.010325
2021-12-13 00:55:46,824 iteration 4478 : loss : 0.033656, loss_ce: 0.015524
2021-12-13 00:55:48,279 iteration 4479 : loss : 0.030186, loss_ce: 0.013520
2021-12-13 00:55:49,674 iteration 4480 : loss : 0.027381, loss_ce: 0.011117
2021-12-13 00:55:51,199 iteration 4481 : loss : 0.030499, loss_ce: 0.008327
2021-12-13 00:55:52,672 iteration 4482 : loss : 0.030589, loss_ce: 0.010636
2021-12-13 00:55:54,093 iteration 4483 : loss : 0.037891, loss_ce: 0.010102
2021-12-13 00:55:55,632 iteration 4484 : loss : 0.029610, loss_ce: 0.010075
2021-12-13 00:55:57,162 iteration 4485 : loss : 0.033010, loss_ce: 0.015065
2021-12-13 00:55:58,714 iteration 4486 : loss : 0.033940, loss_ce: 0.013271
2021-12-13 00:56:00,145 iteration 4487 : loss : 0.025082, loss_ce: 0.008346
2021-12-13 00:56:01,589 iteration 4488 : loss : 0.036634, loss_ce: 0.013003
 66%|███████████████████▏         | 264/400 [2:00:43<59:00, 26.03s/it]2021-12-13 00:56:03,145 iteration 4489 : loss : 0.030933, loss_ce: 0.014753
2021-12-13 00:56:04,587 iteration 4490 : loss : 0.022310, loss_ce: 0.011135
2021-12-13 00:56:06,094 iteration 4491 : loss : 0.034036, loss_ce: 0.011837
2021-12-13 00:56:07,651 iteration 4492 : loss : 0.035740, loss_ce: 0.018942
2021-12-13 00:56:09,101 iteration 4493 : loss : 0.032766, loss_ce: 0.013048
2021-12-13 00:56:10,579 iteration 4494 : loss : 0.026232, loss_ce: 0.008925
2021-12-13 00:56:12,060 iteration 4495 : loss : 0.048333, loss_ce: 0.016991
2021-12-13 00:56:13,498 iteration 4496 : loss : 0.024185, loss_ce: 0.011522
2021-12-13 00:56:15,034 iteration 4497 : loss : 0.031076, loss_ce: 0.014354
2021-12-13 00:56:16,502 iteration 4498 : loss : 0.030660, loss_ce: 0.009417
2021-12-13 00:56:17,998 iteration 4499 : loss : 0.040046, loss_ce: 0.013545
2021-12-13 00:56:19,407 iteration 4500 : loss : 0.024442, loss_ce: 0.008551
2021-12-13 00:56:20,833 iteration 4501 : loss : 0.024739, loss_ce: 0.007661
2021-12-13 00:56:22,269 iteration 4502 : loss : 0.032339, loss_ce: 0.010127
2021-12-13 00:56:23,811 iteration 4503 : loss : 0.032278, loss_ce: 0.012387
2021-12-13 00:56:25,275 iteration 4504 : loss : 0.025130, loss_ce: 0.009698
2021-12-13 00:56:25,275 Training Data Eval:
2021-12-13 00:56:32,811   Average segmentation loss on training set: 0.0183
2021-12-13 00:56:32,811 Validation Data Eval:
2021-12-13 00:56:35,422   Average segmentation loss on validation set: 0.0764
2021-12-13 00:56:41,079 Found new lowest validation loss at iteration 4504! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/TU_3seeds/TU_SGD_best_val_loss_seed2.pth
2021-12-13 00:56:42,471 iteration 4505 : loss : 0.027553, loss_ce: 0.011526
 66%|█████████████████▉         | 265/400 [2:01:24<1:08:35, 30.49s/it]2021-12-13 00:56:43,826 iteration 4506 : loss : 0.033874, loss_ce: 0.014672
2021-12-13 00:56:45,186 iteration 4507 : loss : 0.022174, loss_ce: 0.010098
2021-12-13 00:56:46,512 iteration 4508 : loss : 0.026325, loss_ce: 0.009130
2021-12-13 00:56:47,873 iteration 4509 : loss : 0.031599, loss_ce: 0.008071
2021-12-13 00:56:49,391 iteration 4510 : loss : 0.028748, loss_ce: 0.010394
2021-12-13 00:56:50,863 iteration 4511 : loss : 0.026218, loss_ce: 0.007943
2021-12-13 00:56:52,393 iteration 4512 : loss : 0.033462, loss_ce: 0.016228
2021-12-13 00:56:53,957 iteration 4513 : loss : 0.037981, loss_ce: 0.013400
2021-12-13 00:56:55,336 iteration 4514 : loss : 0.039163, loss_ce: 0.013496
2021-12-13 00:56:56,795 iteration 4515 : loss : 0.026886, loss_ce: 0.009098
2021-12-13 00:56:58,196 iteration 4516 : loss : 0.024370, loss_ce: 0.009848
2021-12-13 00:56:59,611 iteration 4517 : loss : 0.029320, loss_ce: 0.011472
2021-12-13 00:57:01,092 iteration 4518 : loss : 0.034047, loss_ce: 0.011257
2021-12-13 00:57:02,472 iteration 4519 : loss : 0.029964, loss_ce: 0.011254
2021-12-13 00:57:03,969 iteration 4520 : loss : 0.038882, loss_ce: 0.015158
2021-12-13 00:57:05,404 iteration 4521 : loss : 0.028729, loss_ce: 0.011471
2021-12-13 00:57:06,892 iteration 4522 : loss : 0.024918, loss_ce: 0.009731
 66%|█████████████████▉         | 266/400 [2:01:48<1:04:01, 28.67s/it]2021-12-13 00:57:08,475 iteration 4523 : loss : 0.027911, loss_ce: 0.011657
2021-12-13 00:57:09,908 iteration 4524 : loss : 0.024822, loss_ce: 0.009067
2021-12-13 00:57:11,299 iteration 4525 : loss : 0.022963, loss_ce: 0.010845
2021-12-13 00:57:12,732 iteration 4526 : loss : 0.028154, loss_ce: 0.009081
2021-12-13 00:57:14,164 iteration 4527 : loss : 0.021353, loss_ce: 0.008896
2021-12-13 00:57:15,631 iteration 4528 : loss : 0.025072, loss_ce: 0.010381
2021-12-13 00:57:17,033 iteration 4529 : loss : 0.023953, loss_ce: 0.008533
2021-12-13 00:57:18,495 iteration 4530 : loss : 0.034292, loss_ce: 0.014306
2021-12-13 00:57:20,058 iteration 4531 : loss : 0.045456, loss_ce: 0.013570
2021-12-13 00:57:21,448 iteration 4532 : loss : 0.023464, loss_ce: 0.009071
2021-12-13 00:57:23,065 iteration 4533 : loss : 0.051002, loss_ce: 0.018815
2021-12-13 00:57:24,495 iteration 4534 : loss : 0.026885, loss_ce: 0.012282
2021-12-13 00:57:25,993 iteration 4535 : loss : 0.032815, loss_ce: 0.015621
2021-12-13 00:57:27,473 iteration 4536 : loss : 0.025589, loss_ce: 0.008050
2021-12-13 00:57:28,915 iteration 4537 : loss : 0.037090, loss_ce: 0.011115
2021-12-13 00:57:30,363 iteration 4538 : loss : 0.027816, loss_ce: 0.011744
2021-12-13 00:57:31,729 iteration 4539 : loss : 0.021518, loss_ce: 0.008386
 67%|██████████████████         | 267/400 [2:02:13<1:01:00, 27.52s/it]2021-12-13 00:57:33,183 iteration 4540 : loss : 0.030593, loss_ce: 0.013411
2021-12-13 00:57:34,648 iteration 4541 : loss : 0.031269, loss_ce: 0.011963
2021-12-13 00:57:36,114 iteration 4542 : loss : 0.048493, loss_ce: 0.015626
2021-12-13 00:57:37,745 iteration 4543 : loss : 0.040457, loss_ce: 0.014967
2021-12-13 00:57:39,177 iteration 4544 : loss : 0.028575, loss_ce: 0.012244
2021-12-13 00:57:40,591 iteration 4545 : loss : 0.022997, loss_ce: 0.009295
2021-12-13 00:57:42,040 iteration 4546 : loss : 0.031118, loss_ce: 0.011979
2021-12-13 00:57:43,521 iteration 4547 : loss : 0.035858, loss_ce: 0.013067
2021-12-13 00:57:44,962 iteration 4548 : loss : 0.033463, loss_ce: 0.014711
2021-12-13 00:57:46,351 iteration 4549 : loss : 0.028775, loss_ce: 0.009110
2021-12-13 00:57:47,896 iteration 4550 : loss : 0.032645, loss_ce: 0.011855
2021-12-13 00:57:49,436 iteration 4551 : loss : 0.029127, loss_ce: 0.009008
2021-12-13 00:57:50,901 iteration 4552 : loss : 0.037712, loss_ce: 0.013117
2021-12-13 00:57:52,346 iteration 4553 : loss : 0.022936, loss_ce: 0.007893
2021-12-13 00:57:53,853 iteration 4554 : loss : 0.033401, loss_ce: 0.010767
2021-12-13 00:57:55,274 iteration 4555 : loss : 0.043050, loss_ce: 0.014281
2021-12-13 00:57:56,734 iteration 4556 : loss : 0.030380, loss_ce: 0.012683
 67%|███████████████████▍         | 268/400 [2:02:38<58:52, 26.76s/it]2021-12-13 00:57:58,227 iteration 4557 : loss : 0.020916, loss_ce: 0.010356
2021-12-13 00:57:59,707 iteration 4558 : loss : 0.035523, loss_ce: 0.015457
2021-12-13 00:58:01,228 iteration 4559 : loss : 0.032255, loss_ce: 0.011067
2021-12-13 00:58:02,699 iteration 4560 : loss : 0.033234, loss_ce: 0.009993
2021-12-13 00:58:04,206 iteration 4561 : loss : 0.035923, loss_ce: 0.011312
2021-12-13 00:58:05,640 iteration 4562 : loss : 0.032019, loss_ce: 0.009427
2021-12-13 00:58:07,137 iteration 4563 : loss : 0.037504, loss_ce: 0.018060
2021-12-13 00:58:08,650 iteration 4564 : loss : 0.034894, loss_ce: 0.013966
2021-12-13 00:58:10,204 iteration 4565 : loss : 0.034362, loss_ce: 0.011520
2021-12-13 00:58:11,724 iteration 4566 : loss : 0.043225, loss_ce: 0.018023
2021-12-13 00:58:13,186 iteration 4567 : loss : 0.028665, loss_ce: 0.011707
2021-12-13 00:58:14,645 iteration 4568 : loss : 0.033246, loss_ce: 0.010577
2021-12-13 00:58:16,207 iteration 4569 : loss : 0.042221, loss_ce: 0.008534
2021-12-13 00:58:17,780 iteration 4570 : loss : 0.045625, loss_ce: 0.020687
2021-12-13 00:58:19,246 iteration 4571 : loss : 0.034809, loss_ce: 0.014521
2021-12-13 00:58:20,654 iteration 4572 : loss : 0.025313, loss_ce: 0.009553
2021-12-13 00:58:22,153 iteration 4573 : loss : 0.032332, loss_ce: 0.014413
 67%|███████████████████▌         | 269/400 [2:03:04<57:33, 26.36s/it]2021-12-13 00:58:23,583 iteration 4574 : loss : 0.024146, loss_ce: 0.010532
2021-12-13 00:58:25,101 iteration 4575 : loss : 0.032131, loss_ce: 0.009941
2021-12-13 00:58:26,691 iteration 4576 : loss : 0.032039, loss_ce: 0.011672
2021-12-13 00:58:28,182 iteration 4577 : loss : 0.028774, loss_ce: 0.010733
2021-12-13 00:58:29,571 iteration 4578 : loss : 0.030279, loss_ce: 0.012727
2021-12-13 00:58:31,099 iteration 4579 : loss : 0.027882, loss_ce: 0.009550
2021-12-13 00:58:32,569 iteration 4580 : loss : 0.029759, loss_ce: 0.011871
2021-12-13 00:58:34,042 iteration 4581 : loss : 0.028805, loss_ce: 0.011515
2021-12-13 00:58:35,508 iteration 4582 : loss : 0.032056, loss_ce: 0.013588
2021-12-13 00:58:37,071 iteration 4583 : loss : 0.042055, loss_ce: 0.009730
2021-12-13 00:58:38,538 iteration 4584 : loss : 0.039847, loss_ce: 0.011115
2021-12-13 00:58:39,961 iteration 4585 : loss : 0.026596, loss_ce: 0.008910
2021-12-13 00:58:41,429 iteration 4586 : loss : 0.024224, loss_ce: 0.010931
2021-12-13 00:58:42,893 iteration 4587 : loss : 0.029575, loss_ce: 0.011363
2021-12-13 00:58:44,433 iteration 4588 : loss : 0.029142, loss_ce: 0.012487
2021-12-13 00:58:45,908 iteration 4589 : loss : 0.031328, loss_ce: 0.013161
2021-12-13 00:58:45,908 Training Data Eval:
2021-12-13 00:58:53,438   Average segmentation loss on training set: 0.0171
2021-12-13 00:58:53,438 Validation Data Eval:
2021-12-13 00:58:56,038   Average segmentation loss on validation set: 0.0755
2021-12-13 00:59:02,423 Found new lowest validation loss at iteration 4589! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/TU_3seeds/TU_SGD_best_val_loss_seed2.pth
2021-12-13 00:59:03,834 iteration 4590 : loss : 0.031099, loss_ce: 0.015933
 68%|██████████████████▏        | 270/400 [2:03:45<1:07:04, 30.96s/it]2021-12-13 00:59:05,378 iteration 4591 : loss : 0.040143, loss_ce: 0.012840
2021-12-13 00:59:06,731 iteration 4592 : loss : 0.033422, loss_ce: 0.014850
2021-12-13 00:59:08,090 iteration 4593 : loss : 0.035918, loss_ce: 0.013170
2021-12-13 00:59:09,488 iteration 4594 : loss : 0.025626, loss_ce: 0.011338
2021-12-13 00:59:11,109 iteration 4595 : loss : 0.026608, loss_ce: 0.011561
2021-12-13 00:59:12,681 iteration 4596 : loss : 0.031210, loss_ce: 0.012895
2021-12-13 00:59:14,098 iteration 4597 : loss : 0.030892, loss_ce: 0.009200
2021-12-13 00:59:15,483 iteration 4598 : loss : 0.025061, loss_ce: 0.007993
2021-12-13 00:59:16,920 iteration 4599 : loss : 0.026813, loss_ce: 0.011285
2021-12-13 00:59:18,403 iteration 4600 : loss : 0.023443, loss_ce: 0.009561
2021-12-13 00:59:19,899 iteration 4601 : loss : 0.027985, loss_ce: 0.015112
2021-12-13 00:59:21,456 iteration 4602 : loss : 0.034040, loss_ce: 0.013625
2021-12-13 00:59:23,008 iteration 4603 : loss : 0.036945, loss_ce: 0.014611
2021-12-13 00:59:24,433 iteration 4604 : loss : 0.029652, loss_ce: 0.010639
2021-12-13 00:59:25,898 iteration 4605 : loss : 0.025116, loss_ce: 0.008090
2021-12-13 00:59:27,348 iteration 4606 : loss : 0.030716, loss_ce: 0.011319
2021-12-13 00:59:28,798 iteration 4607 : loss : 0.030119, loss_ce: 0.011570
 68%|██████████████████▎        | 271/400 [2:04:10<1:02:41, 29.16s/it]2021-12-13 00:59:30,338 iteration 4608 : loss : 0.028687, loss_ce: 0.012108
2021-12-13 00:59:31,834 iteration 4609 : loss : 0.025929, loss_ce: 0.008618
2021-12-13 00:59:33,323 iteration 4610 : loss : 0.029431, loss_ce: 0.008804
2021-12-13 00:59:34,844 iteration 4611 : loss : 0.040652, loss_ce: 0.017615
2021-12-13 00:59:36,329 iteration 4612 : loss : 0.034958, loss_ce: 0.015810
2021-12-13 00:59:37,813 iteration 4613 : loss : 0.032495, loss_ce: 0.011744
2021-12-13 00:59:39,290 iteration 4614 : loss : 0.028781, loss_ce: 0.009809
2021-12-13 00:59:40,880 iteration 4615 : loss : 0.036198, loss_ce: 0.014900
2021-12-13 00:59:42,294 iteration 4616 : loss : 0.027809, loss_ce: 0.012140
2021-12-13 00:59:43,794 iteration 4617 : loss : 0.031099, loss_ce: 0.011474
2021-12-13 00:59:45,238 iteration 4618 : loss : 0.021676, loss_ce: 0.008215
2021-12-13 00:59:46,729 iteration 4619 : loss : 0.033854, loss_ce: 0.013886
2021-12-13 00:59:48,180 iteration 4620 : loss : 0.025352, loss_ce: 0.010350
2021-12-13 00:59:49,638 iteration 4621 : loss : 0.027335, loss_ce: 0.009708
2021-12-13 00:59:51,124 iteration 4622 : loss : 0.027810, loss_ce: 0.010740
2021-12-13 00:59:52,608 iteration 4623 : loss : 0.034062, loss_ce: 0.014517
2021-12-13 00:59:54,046 iteration 4624 : loss : 0.035487, loss_ce: 0.011756
 68%|███████████████████▋         | 272/400 [2:04:36<59:42, 27.99s/it]2021-12-13 00:59:55,629 iteration 4625 : loss : 0.043333, loss_ce: 0.013268
2021-12-13 00:59:57,141 iteration 4626 : loss : 0.038026, loss_ce: 0.012566
2021-12-13 00:59:58,601 iteration 4627 : loss : 0.031930, loss_ce: 0.014087
2021-12-13 01:00:00,072 iteration 4628 : loss : 0.033908, loss_ce: 0.012667
2021-12-13 01:00:01,488 iteration 4629 : loss : 0.035054, loss_ce: 0.006987
2021-12-13 01:00:02,969 iteration 4630 : loss : 0.027781, loss_ce: 0.016243
2021-12-13 01:00:04,418 iteration 4631 : loss : 0.031739, loss_ce: 0.012846
2021-12-13 01:00:05,906 iteration 4632 : loss : 0.029524, loss_ce: 0.009743
2021-12-13 01:00:07,400 iteration 4633 : loss : 0.022998, loss_ce: 0.007894
2021-12-13 01:00:08,946 iteration 4634 : loss : 0.032328, loss_ce: 0.013402
2021-12-13 01:00:10,303 iteration 4635 : loss : 0.020011, loss_ce: 0.007247
2021-12-13 01:00:11,707 iteration 4636 : loss : 0.020727, loss_ce: 0.008087
2021-12-13 01:00:13,166 iteration 4637 : loss : 0.044005, loss_ce: 0.015403
2021-12-13 01:00:14,633 iteration 4638 : loss : 0.030593, loss_ce: 0.013794
2021-12-13 01:00:16,136 iteration 4639 : loss : 0.026314, loss_ce: 0.009593
2021-12-13 01:00:17,644 iteration 4640 : loss : 0.040835, loss_ce: 0.017681
2021-12-13 01:00:19,118 iteration 4641 : loss : 0.032272, loss_ce: 0.012190
 68%|███████████████████▊         | 273/400 [2:05:01<57:23, 27.11s/it]2021-12-13 01:00:20,627 iteration 4642 : loss : 0.033545, loss_ce: 0.013032
2021-12-13 01:00:22,102 iteration 4643 : loss : 0.033984, loss_ce: 0.013646
2021-12-13 01:00:23,587 iteration 4644 : loss : 0.034739, loss_ce: 0.016149
2021-12-13 01:00:25,019 iteration 4645 : loss : 0.031767, loss_ce: 0.011218
2021-12-13 01:00:26,483 iteration 4646 : loss : 0.024764, loss_ce: 0.009904
2021-12-13 01:00:27,968 iteration 4647 : loss : 0.026886, loss_ce: 0.011247
2021-12-13 01:00:29,397 iteration 4648 : loss : 0.023571, loss_ce: 0.009872
2021-12-13 01:00:30,992 iteration 4649 : loss : 0.036718, loss_ce: 0.014371
2021-12-13 01:00:32,346 iteration 4650 : loss : 0.023456, loss_ce: 0.009699
2021-12-13 01:00:33,833 iteration 4651 : loss : 0.031959, loss_ce: 0.012116
2021-12-13 01:00:35,289 iteration 4652 : loss : 0.031067, loss_ce: 0.011472
2021-12-13 01:00:36,678 iteration 4653 : loss : 0.022612, loss_ce: 0.009382
2021-12-13 01:00:38,081 iteration 4654 : loss : 0.025249, loss_ce: 0.007571
2021-12-13 01:00:39,602 iteration 4655 : loss : 0.037579, loss_ce: 0.012997
2021-12-13 01:00:41,059 iteration 4656 : loss : 0.031120, loss_ce: 0.010132
2021-12-13 01:00:42,533 iteration 4657 : loss : 0.030059, loss_ce: 0.013846
2021-12-13 01:00:43,998 iteration 4658 : loss : 0.019353, loss_ce: 0.007433
 68%|███████████████████▊         | 274/400 [2:05:25<55:31, 26.44s/it]2021-12-13 01:00:45,514 iteration 4659 : loss : 0.025365, loss_ce: 0.010228
2021-12-13 01:00:46,943 iteration 4660 : loss : 0.022982, loss_ce: 0.009674
2021-12-13 01:00:48,466 iteration 4661 : loss : 0.027641, loss_ce: 0.012207
2021-12-13 01:00:49,837 iteration 4662 : loss : 0.020956, loss_ce: 0.009662
2021-12-13 01:00:51,394 iteration 4663 : loss : 0.031542, loss_ce: 0.012307
2021-12-13 01:00:52,859 iteration 4664 : loss : 0.025221, loss_ce: 0.009158
2021-12-13 01:00:54,318 iteration 4665 : loss : 0.033345, loss_ce: 0.014160
2021-12-13 01:00:55,846 iteration 4666 : loss : 0.028601, loss_ce: 0.011907
2021-12-13 01:00:57,369 iteration 4667 : loss : 0.047060, loss_ce: 0.014734
2021-12-13 01:00:58,824 iteration 4668 : loss : 0.023560, loss_ce: 0.009631
2021-12-13 01:01:00,341 iteration 4669 : loss : 0.034554, loss_ce: 0.012517
2021-12-13 01:01:01,824 iteration 4670 : loss : 0.044254, loss_ce: 0.011736
2021-12-13 01:01:03,257 iteration 4671 : loss : 0.027108, loss_ce: 0.009614
2021-12-13 01:01:04,687 iteration 4672 : loss : 0.021440, loss_ce: 0.008146
2021-12-13 01:01:06,064 iteration 4673 : loss : 0.022418, loss_ce: 0.007982
2021-12-13 01:01:07,552 iteration 4674 : loss : 0.027748, loss_ce: 0.007270
2021-12-13 01:01:07,552 Training Data Eval:
2021-12-13 01:01:15,079   Average segmentation loss on training set: 0.0160
2021-12-13 01:01:15,079 Validation Data Eval:
2021-12-13 01:01:17,678   Average segmentation loss on validation set: 0.0826
2021-12-13 01:01:19,064 iteration 4675 : loss : 0.021942, loss_ce: 0.008713
 69%|██████████████████▌        | 275/400 [2:06:01<1:00:28, 29.03s/it]2021-12-13 01:01:20,576 iteration 4676 : loss : 0.025884, loss_ce: 0.010371
2021-12-13 01:01:22,010 iteration 4677 : loss : 0.030171, loss_ce: 0.012444
2021-12-13 01:01:23,515 iteration 4678 : loss : 0.027803, loss_ce: 0.009486
2021-12-13 01:01:25,072 iteration 4679 : loss : 0.038174, loss_ce: 0.014455
2021-12-13 01:01:26,471 iteration 4680 : loss : 0.027960, loss_ce: 0.010877
2021-12-13 01:01:27,929 iteration 4681 : loss : 0.027728, loss_ce: 0.011814
2021-12-13 01:01:29,372 iteration 4682 : loss : 0.026888, loss_ce: 0.011079
2021-12-13 01:01:30,800 iteration 4683 : loss : 0.028905, loss_ce: 0.009717
2021-12-13 01:01:32,264 iteration 4684 : loss : 0.036624, loss_ce: 0.013299
2021-12-13 01:01:33,772 iteration 4685 : loss : 0.026022, loss_ce: 0.011626
2021-12-13 01:01:35,186 iteration 4686 : loss : 0.030204, loss_ce: 0.010886
2021-12-13 01:01:36,653 iteration 4687 : loss : 0.042804, loss_ce: 0.011804
2021-12-13 01:01:38,031 iteration 4688 : loss : 0.017783, loss_ce: 0.008452
2021-12-13 01:01:39,516 iteration 4689 : loss : 0.031009, loss_ce: 0.011821
2021-12-13 01:01:40,891 iteration 4690 : loss : 0.026554, loss_ce: 0.010029
2021-12-13 01:01:42,345 iteration 4691 : loss : 0.033473, loss_ce: 0.011489
2021-12-13 01:01:43,913 iteration 4692 : loss : 0.025659, loss_ce: 0.009515
 69%|████████████████████         | 276/400 [2:06:25<57:24, 27.78s/it]2021-12-13 01:01:45,402 iteration 4693 : loss : 0.030329, loss_ce: 0.012448
2021-12-13 01:01:46,857 iteration 4694 : loss : 0.032366, loss_ce: 0.010193
2021-12-13 01:01:48,343 iteration 4695 : loss : 0.037029, loss_ce: 0.015289
2021-12-13 01:01:49,832 iteration 4696 : loss : 0.033259, loss_ce: 0.011515
2021-12-13 01:01:51,246 iteration 4697 : loss : 0.028746, loss_ce: 0.013021
2021-12-13 01:01:52,671 iteration 4698 : loss : 0.027961, loss_ce: 0.009993
2021-12-13 01:01:54,131 iteration 4699 : loss : 0.029397, loss_ce: 0.008918
2021-12-13 01:01:55,586 iteration 4700 : loss : 0.031841, loss_ce: 0.011582
2021-12-13 01:01:57,028 iteration 4701 : loss : 0.026708, loss_ce: 0.009001
2021-12-13 01:01:58,544 iteration 4702 : loss : 0.031812, loss_ce: 0.011347
2021-12-13 01:02:00,020 iteration 4703 : loss : 0.034925, loss_ce: 0.017136
2021-12-13 01:02:01,508 iteration 4704 : loss : 0.035056, loss_ce: 0.008358
2021-12-13 01:02:02,996 iteration 4705 : loss : 0.042095, loss_ce: 0.012153
2021-12-13 01:02:04,382 iteration 4706 : loss : 0.020653, loss_ce: 0.008331
2021-12-13 01:02:05,821 iteration 4707 : loss : 0.028048, loss_ce: 0.009259
2021-12-13 01:02:07,276 iteration 4708 : loss : 0.028218, loss_ce: 0.013413
2021-12-13 01:02:08,713 iteration 4709 : loss : 0.037619, loss_ce: 0.015324
 69%|████████████████████         | 277/400 [2:06:50<55:06, 26.88s/it]2021-12-13 01:02:10,186 iteration 4710 : loss : 0.024723, loss_ce: 0.009589
2021-12-13 01:02:11,593 iteration 4711 : loss : 0.025749, loss_ce: 0.008382
2021-12-13 01:02:12,971 iteration 4712 : loss : 0.023888, loss_ce: 0.008756
2021-12-13 01:02:14,429 iteration 4713 : loss : 0.039745, loss_ce: 0.014007
2021-12-13 01:02:15,822 iteration 4714 : loss : 0.023672, loss_ce: 0.007960
2021-12-13 01:02:17,295 iteration 4715 : loss : 0.031019, loss_ce: 0.015073
2021-12-13 01:02:18,805 iteration 4716 : loss : 0.036554, loss_ce: 0.013942
2021-12-13 01:02:20,269 iteration 4717 : loss : 0.029259, loss_ce: 0.010673
2021-12-13 01:02:21,741 iteration 4718 : loss : 0.030032, loss_ce: 0.011648
2021-12-13 01:02:23,181 iteration 4719 : loss : 0.025247, loss_ce: 0.009681
2021-12-13 01:02:24,635 iteration 4720 : loss : 0.030339, loss_ce: 0.014618
2021-12-13 01:02:26,079 iteration 4721 : loss : 0.027986, loss_ce: 0.009937
2021-12-13 01:02:27,608 iteration 4722 : loss : 0.030461, loss_ce: 0.013456
2021-12-13 01:02:29,155 iteration 4723 : loss : 0.032795, loss_ce: 0.010923
2021-12-13 01:02:30,712 iteration 4724 : loss : 0.039189, loss_ce: 0.023113
2021-12-13 01:02:32,139 iteration 4725 : loss : 0.030720, loss_ce: 0.011182
2021-12-13 01:02:33,639 iteration 4726 : loss : 0.031342, loss_ce: 0.009691
 70%|████████████████████▏        | 278/400 [2:07:15<53:28, 26.30s/it]2021-12-13 01:02:35,166 iteration 4727 : loss : 0.029898, loss_ce: 0.009746
2021-12-13 01:02:36,651 iteration 4728 : loss : 0.025351, loss_ce: 0.009387
2021-12-13 01:02:38,084 iteration 4729 : loss : 0.028574, loss_ce: 0.009501
2021-12-13 01:02:39,556 iteration 4730 : loss : 0.028315, loss_ce: 0.011508
2021-12-13 01:02:41,026 iteration 4731 : loss : 0.040326, loss_ce: 0.011762
2021-12-13 01:02:42,503 iteration 4732 : loss : 0.029428, loss_ce: 0.011934
2021-12-13 01:02:43,913 iteration 4733 : loss : 0.026407, loss_ce: 0.008536
2021-12-13 01:02:45,315 iteration 4734 : loss : 0.020063, loss_ce: 0.007475
2021-12-13 01:02:46,844 iteration 4735 : loss : 0.034381, loss_ce: 0.018341
2021-12-13 01:02:48,348 iteration 4736 : loss : 0.027104, loss_ce: 0.011311
2021-12-13 01:02:49,902 iteration 4737 : loss : 0.050217, loss_ce: 0.015094
2021-12-13 01:02:51,433 iteration 4738 : loss : 0.053284, loss_ce: 0.009470
2021-12-13 01:02:52,881 iteration 4739 : loss : 0.024505, loss_ce: 0.009302
2021-12-13 01:02:54,291 iteration 4740 : loss : 0.022974, loss_ce: 0.010202
2021-12-13 01:02:55,739 iteration 4741 : loss : 0.033171, loss_ce: 0.019092
2021-12-13 01:02:57,118 iteration 4742 : loss : 0.023881, loss_ce: 0.009448
2021-12-13 01:02:58,583 iteration 4743 : loss : 0.023726, loss_ce: 0.008260
 70%|████████████████████▏        | 279/400 [2:07:40<52:12, 25.89s/it]2021-12-13 01:03:00,104 iteration 4744 : loss : 0.028812, loss_ce: 0.012597
2021-12-13 01:03:01,579 iteration 4745 : loss : 0.028326, loss_ce: 0.011415
2021-12-13 01:03:03,036 iteration 4746 : loss : 0.027964, loss_ce: 0.012215
2021-12-13 01:03:04,556 iteration 4747 : loss : 0.027522, loss_ce: 0.011804
2021-12-13 01:03:06,124 iteration 4748 : loss : 0.031385, loss_ce: 0.012216
2021-12-13 01:03:07,648 iteration 4749 : loss : 0.028181, loss_ce: 0.008801
2021-12-13 01:03:09,110 iteration 4750 : loss : 0.027615, loss_ce: 0.010922
2021-12-13 01:03:10,518 iteration 4751 : loss : 0.029306, loss_ce: 0.011048
2021-12-13 01:03:11,984 iteration 4752 : loss : 0.032476, loss_ce: 0.009198
2021-12-13 01:03:13,478 iteration 4753 : loss : 0.027064, loss_ce: 0.013527
2021-12-13 01:03:14,961 iteration 4754 : loss : 0.036238, loss_ce: 0.010227
2021-12-13 01:03:16,471 iteration 4755 : loss : 0.031911, loss_ce: 0.011828
2021-12-13 01:03:17,946 iteration 4756 : loss : 0.028086, loss_ce: 0.012092
2021-12-13 01:03:19,421 iteration 4757 : loss : 0.026576, loss_ce: 0.010167
2021-12-13 01:03:20,992 iteration 4758 : loss : 0.033358, loss_ce: 0.011249
2021-12-13 01:03:22,411 iteration 4759 : loss : 0.022325, loss_ce: 0.008960
2021-12-13 01:03:22,411 Training Data Eval:
2021-12-13 01:03:29,942   Average segmentation loss on training set: 0.0166
2021-12-13 01:03:29,942 Validation Data Eval:
2021-12-13 01:03:32,544   Average segmentation loss on validation set: 0.0819
2021-12-13 01:03:34,005 iteration 4760 : loss : 0.036032, loss_ce: 0.011139
 70%|████████████████████▎        | 280/400 [2:08:15<57:30, 28.75s/it]2021-12-13 01:03:35,525 iteration 4761 : loss : 0.024721, loss_ce: 0.009892
2021-12-13 01:03:37,038 iteration 4762 : loss : 0.034312, loss_ce: 0.009264
2021-12-13 01:03:38,540 iteration 4763 : loss : 0.028833, loss_ce: 0.010105
2021-12-13 01:03:40,079 iteration 4764 : loss : 0.027490, loss_ce: 0.010099
2021-12-13 01:03:41,592 iteration 4765 : loss : 0.033996, loss_ce: 0.012967
2021-12-13 01:03:43,174 iteration 4766 : loss : 0.033678, loss_ce: 0.008034
2021-12-13 01:03:44,771 iteration 4767 : loss : 0.031751, loss_ce: 0.016269
2021-12-13 01:03:46,270 iteration 4768 : loss : 0.031420, loss_ce: 0.011511
2021-12-13 01:03:47,675 iteration 4769 : loss : 0.024764, loss_ce: 0.009077
2021-12-13 01:03:49,184 iteration 4770 : loss : 0.033293, loss_ce: 0.015710
2021-12-13 01:03:50,651 iteration 4771 : loss : 0.032142, loss_ce: 0.011487
2021-12-13 01:03:52,077 iteration 4772 : loss : 0.023188, loss_ce: 0.009332
2021-12-13 01:03:53,474 iteration 4773 : loss : 0.023642, loss_ce: 0.010599
2021-12-13 01:03:54,978 iteration 4774 : loss : 0.031707, loss_ce: 0.011225
2021-12-13 01:03:56,379 iteration 4775 : loss : 0.021018, loss_ce: 0.008527
2021-12-13 01:03:57,835 iteration 4776 : loss : 0.034114, loss_ce: 0.012769
2021-12-13 01:03:59,287 iteration 4777 : loss : 0.020593, loss_ce: 0.007026
 70%|████████████████████▎        | 281/400 [2:08:41<54:57, 27.71s/it]2021-12-13 01:04:00,809 iteration 4778 : loss : 0.024446, loss_ce: 0.012290
2021-12-13 01:04:02,239 iteration 4779 : loss : 0.021785, loss_ce: 0.009537
2021-12-13 01:04:03,664 iteration 4780 : loss : 0.023914, loss_ce: 0.010031
2021-12-13 01:04:05,160 iteration 4781 : loss : 0.037833, loss_ce: 0.013231
2021-12-13 01:04:06,684 iteration 4782 : loss : 0.032587, loss_ce: 0.012710
2021-12-13 01:04:08,138 iteration 4783 : loss : 0.025126, loss_ce: 0.011200
2021-12-13 01:04:09,663 iteration 4784 : loss : 0.036057, loss_ce: 0.010986
2021-12-13 01:04:11,130 iteration 4785 : loss : 0.021790, loss_ce: 0.007728
2021-12-13 01:04:12,597 iteration 4786 : loss : 0.023497, loss_ce: 0.009921
2021-12-13 01:04:14,048 iteration 4787 : loss : 0.042159, loss_ce: 0.014299
2021-12-13 01:04:15,537 iteration 4788 : loss : 0.039805, loss_ce: 0.013453
2021-12-13 01:04:16,902 iteration 4789 : loss : 0.023578, loss_ce: 0.009099
2021-12-13 01:04:18,263 iteration 4790 : loss : 0.023108, loss_ce: 0.009265
2021-12-13 01:04:19,741 iteration 4791 : loss : 0.036463, loss_ce: 0.016376
2021-12-13 01:04:21,219 iteration 4792 : loss : 0.029717, loss_ce: 0.012205
2021-12-13 01:04:22,759 iteration 4793 : loss : 0.031967, loss_ce: 0.010136
2021-12-13 01:04:24,207 iteration 4794 : loss : 0.024736, loss_ce: 0.008290
 70%|████████████████████▍        | 282/400 [2:09:06<52:51, 26.87s/it]2021-12-13 01:04:25,744 iteration 4795 : loss : 0.033358, loss_ce: 0.012065
2021-12-13 01:04:27,245 iteration 4796 : loss : 0.029302, loss_ce: 0.008916
2021-12-13 01:04:28,742 iteration 4797 : loss : 0.023383, loss_ce: 0.008707
2021-12-13 01:04:30,235 iteration 4798 : loss : 0.028087, loss_ce: 0.010461
2021-12-13 01:04:31,677 iteration 4799 : loss : 0.026446, loss_ce: 0.007765
2021-12-13 01:04:33,166 iteration 4800 : loss : 0.027610, loss_ce: 0.011278
2021-12-13 01:04:34,618 iteration 4801 : loss : 0.033465, loss_ce: 0.015200
2021-12-13 01:04:36,126 iteration 4802 : loss : 0.026300, loss_ce: 0.010339
2021-12-13 01:04:37,591 iteration 4803 : loss : 0.027173, loss_ce: 0.010789
2021-12-13 01:04:39,086 iteration 4804 : loss : 0.025367, loss_ce: 0.009948
2021-12-13 01:04:40,641 iteration 4805 : loss : 0.036117, loss_ce: 0.014708
2021-12-13 01:04:42,146 iteration 4806 : loss : 0.031933, loss_ce: 0.008029
2021-12-13 01:04:43,563 iteration 4807 : loss : 0.028747, loss_ce: 0.009244
2021-12-13 01:04:45,082 iteration 4808 : loss : 0.030351, loss_ce: 0.011500
2021-12-13 01:04:46,504 iteration 4809 : loss : 0.022940, loss_ce: 0.011408
2021-12-13 01:04:47,968 iteration 4810 : loss : 0.036519, loss_ce: 0.012848
2021-12-13 01:04:49,469 iteration 4811 : loss : 0.033895, loss_ce: 0.013073
 71%|████████████████████▌        | 283/400 [2:09:31<51:27, 26.39s/it]2021-12-13 01:04:50,971 iteration 4812 : loss : 0.036994, loss_ce: 0.011706
2021-12-13 01:04:52,399 iteration 4813 : loss : 0.021620, loss_ce: 0.009907
2021-12-13 01:04:53,992 iteration 4814 : loss : 0.041306, loss_ce: 0.015772
2021-12-13 01:04:55,451 iteration 4815 : loss : 0.025543, loss_ce: 0.009737
2021-12-13 01:04:56,877 iteration 4816 : loss : 0.025992, loss_ce: 0.010298
2021-12-13 01:04:58,286 iteration 4817 : loss : 0.020865, loss_ce: 0.008747
2021-12-13 01:04:59,716 iteration 4818 : loss : 0.032876, loss_ce: 0.013097
2021-12-13 01:05:01,202 iteration 4819 : loss : 0.029370, loss_ce: 0.009951
2021-12-13 01:05:02,627 iteration 4820 : loss : 0.028310, loss_ce: 0.012564
2021-12-13 01:05:04,093 iteration 4821 : loss : 0.029711, loss_ce: 0.012402
2021-12-13 01:05:05,616 iteration 4822 : loss : 0.037607, loss_ce: 0.012537
2021-12-13 01:05:07,091 iteration 4823 : loss : 0.033384, loss_ce: 0.008209
2021-12-13 01:05:08,526 iteration 4824 : loss : 0.031529, loss_ce: 0.009851
2021-12-13 01:05:10,041 iteration 4825 : loss : 0.025326, loss_ce: 0.012572
2021-12-13 01:05:11,689 iteration 4826 : loss : 0.039022, loss_ce: 0.017353
2021-12-13 01:05:13,126 iteration 4827 : loss : 0.028662, loss_ce: 0.014892
2021-12-13 01:05:14,544 iteration 4828 : loss : 0.022669, loss_ce: 0.008461
 71%|████████████████████▌        | 284/400 [2:09:56<50:15, 25.99s/it]2021-12-13 01:05:16,023 iteration 4829 : loss : 0.022191, loss_ce: 0.011474
2021-12-13 01:05:17,543 iteration 4830 : loss : 0.032515, loss_ce: 0.013797
2021-12-13 01:05:19,040 iteration 4831 : loss : 0.031741, loss_ce: 0.015635
2021-12-13 01:05:20,540 iteration 4832 : loss : 0.024861, loss_ce: 0.009511
2021-12-13 01:05:22,000 iteration 4833 : loss : 0.037700, loss_ce: 0.017496
2021-12-13 01:05:23,551 iteration 4834 : loss : 0.028552, loss_ce: 0.010173
2021-12-13 01:05:25,005 iteration 4835 : loss : 0.029562, loss_ce: 0.012351
2021-12-13 01:05:26,439 iteration 4836 : loss : 0.028530, loss_ce: 0.008857
2021-12-13 01:05:27,919 iteration 4837 : loss : 0.028518, loss_ce: 0.008321
2021-12-13 01:05:29,414 iteration 4838 : loss : 0.034791, loss_ce: 0.013066
2021-12-13 01:05:30,790 iteration 4839 : loss : 0.028751, loss_ce: 0.010551
2021-12-13 01:05:32,228 iteration 4840 : loss : 0.034158, loss_ce: 0.013153
2021-12-13 01:05:33,738 iteration 4841 : loss : 0.029324, loss_ce: 0.011588
2021-12-13 01:05:35,225 iteration 4842 : loss : 0.033113, loss_ce: 0.015018
2021-12-13 01:05:36,677 iteration 4843 : loss : 0.027536, loss_ce: 0.010714
2021-12-13 01:05:38,201 iteration 4844 : loss : 0.025205, loss_ce: 0.007757
2021-12-13 01:05:38,201 Training Data Eval:
2021-12-13 01:05:45,728   Average segmentation loss on training set: 0.0159
2021-12-13 01:05:45,729 Validation Data Eval:
2021-12-13 01:05:48,336   Average segmentation loss on validation set: 0.0796
2021-12-13 01:05:49,752 iteration 4845 : loss : 0.028471, loss_ce: 0.011057
 71%|████████████████████▋        | 285/400 [2:10:31<55:07, 28.76s/it]2021-12-13 01:05:51,255 iteration 4846 : loss : 0.026695, loss_ce: 0.010722
2021-12-13 01:05:52,662 iteration 4847 : loss : 0.020716, loss_ce: 0.007467
2021-12-13 01:05:54,213 iteration 4848 : loss : 0.035057, loss_ce: 0.014516
2021-12-13 01:05:55,656 iteration 4849 : loss : 0.025175, loss_ce: 0.009045
2021-12-13 01:05:57,052 iteration 4850 : loss : 0.022895, loss_ce: 0.010837
2021-12-13 01:05:58,611 iteration 4851 : loss : 0.039313, loss_ce: 0.013485
2021-12-13 01:06:00,065 iteration 4852 : loss : 0.031847, loss_ce: 0.015227
2021-12-13 01:06:01,564 iteration 4853 : loss : 0.039546, loss_ce: 0.009938
2021-12-13 01:06:03,203 iteration 4854 : loss : 0.034135, loss_ce: 0.012445
2021-12-13 01:06:04,696 iteration 4855 : loss : 0.038266, loss_ce: 0.014755
2021-12-13 01:06:06,100 iteration 4856 : loss : 0.024050, loss_ce: 0.007616
2021-12-13 01:06:07,628 iteration 4857 : loss : 0.025668, loss_ce: 0.011369
2021-12-13 01:06:09,142 iteration 4858 : loss : 0.040826, loss_ce: 0.015210
2021-12-13 01:06:10,615 iteration 4859 : loss : 0.026554, loss_ce: 0.011370
2021-12-13 01:06:12,113 iteration 4860 : loss : 0.036500, loss_ce: 0.014396
2021-12-13 01:06:13,586 iteration 4861 : loss : 0.026921, loss_ce: 0.011369
2021-12-13 01:06:15,016 iteration 4862 : loss : 0.023293, loss_ce: 0.009905
 72%|████████████████████▋        | 286/400 [2:10:56<52:38, 27.71s/it]2021-12-13 01:06:16,475 iteration 4863 : loss : 0.024876, loss_ce: 0.008816
2021-12-13 01:06:17,997 iteration 4864 : loss : 0.036291, loss_ce: 0.013597
2021-12-13 01:06:19,557 iteration 4865 : loss : 0.037711, loss_ce: 0.010150
2021-12-13 01:06:21,070 iteration 4866 : loss : 0.022494, loss_ce: 0.009263
2021-12-13 01:06:22,547 iteration 4867 : loss : 0.030078, loss_ce: 0.012677
2021-12-13 01:06:23,980 iteration 4868 : loss : 0.021952, loss_ce: 0.010632
2021-12-13 01:06:25,415 iteration 4869 : loss : 0.026322, loss_ce: 0.010640
2021-12-13 01:06:26,973 iteration 4870 : loss : 0.035229, loss_ce: 0.011589
2021-12-13 01:06:28,466 iteration 4871 : loss : 0.024065, loss_ce: 0.009826
2021-12-13 01:06:29,877 iteration 4872 : loss : 0.028268, loss_ce: 0.012973
2021-12-13 01:06:31,262 iteration 4873 : loss : 0.031537, loss_ce: 0.010725
2021-12-13 01:06:32,636 iteration 4874 : loss : 0.022764, loss_ce: 0.010433
2021-12-13 01:06:34,096 iteration 4875 : loss : 0.022205, loss_ce: 0.007215
2021-12-13 01:06:35,499 iteration 4876 : loss : 0.032116, loss_ce: 0.010333
2021-12-13 01:06:37,075 iteration 4877 : loss : 0.033735, loss_ce: 0.014232
2021-12-13 01:06:38,535 iteration 4878 : loss : 0.027394, loss_ce: 0.009492
2021-12-13 01:06:39,994 iteration 4879 : loss : 0.025877, loss_ce: 0.010765
 72%|████████████████████▊        | 287/400 [2:11:21<50:38, 26.89s/it]2021-12-13 01:06:41,626 iteration 4880 : loss : 0.034546, loss_ce: 0.017581
2021-12-13 01:06:43,079 iteration 4881 : loss : 0.038214, loss_ce: 0.012555
2021-12-13 01:06:44,537 iteration 4882 : loss : 0.030120, loss_ce: 0.008073
2021-12-13 01:06:46,012 iteration 4883 : loss : 0.036496, loss_ce: 0.011749
2021-12-13 01:06:47,489 iteration 4884 : loss : 0.022617, loss_ce: 0.011933
2021-12-13 01:06:49,105 iteration 4885 : loss : 0.037613, loss_ce: 0.011732
2021-12-13 01:06:50,631 iteration 4886 : loss : 0.037121, loss_ce: 0.013573
2021-12-13 01:06:52,176 iteration 4887 : loss : 0.034239, loss_ce: 0.012609
2021-12-13 01:06:53,638 iteration 4888 : loss : 0.037416, loss_ce: 0.010027
2021-12-13 01:06:55,101 iteration 4889 : loss : 0.023652, loss_ce: 0.009079
2021-12-13 01:06:56,632 iteration 4890 : loss : 0.041907, loss_ce: 0.014295
2021-12-13 01:06:58,166 iteration 4891 : loss : 0.033588, loss_ce: 0.018459
2021-12-13 01:06:59,574 iteration 4892 : loss : 0.024910, loss_ce: 0.010278
2021-12-13 01:07:01,010 iteration 4893 : loss : 0.024450, loss_ce: 0.011882
2021-12-13 01:07:02,467 iteration 4894 : loss : 0.033714, loss_ce: 0.008581
2021-12-13 01:07:03,896 iteration 4895 : loss : 0.031138, loss_ce: 0.011715
2021-12-13 01:07:05,374 iteration 4896 : loss : 0.030108, loss_ce: 0.010831
 72%|████████████████████▉        | 288/400 [2:11:47<49:20, 26.44s/it]2021-12-13 01:07:06,864 iteration 4897 : loss : 0.027895, loss_ce: 0.009676
2021-12-13 01:07:08,365 iteration 4898 : loss : 0.032158, loss_ce: 0.012323
2021-12-13 01:07:09,696 iteration 4899 : loss : 0.023449, loss_ce: 0.010490
2021-12-13 01:07:11,268 iteration 4900 : loss : 0.027671, loss_ce: 0.010026
2021-12-13 01:07:12,710 iteration 4901 : loss : 0.024373, loss_ce: 0.006520
2021-12-13 01:07:14,240 iteration 4902 : loss : 0.040083, loss_ce: 0.016014
2021-12-13 01:07:15,807 iteration 4903 : loss : 0.037789, loss_ce: 0.017278
2021-12-13 01:07:17,366 iteration 4904 : loss : 0.036981, loss_ce: 0.018790
2021-12-13 01:07:18,864 iteration 4905 : loss : 0.039819, loss_ce: 0.012711
2021-12-13 01:07:20,362 iteration 4906 : loss : 0.031816, loss_ce: 0.012597
2021-12-13 01:07:21,742 iteration 4907 : loss : 0.025501, loss_ce: 0.010519
2021-12-13 01:07:23,164 iteration 4908 : loss : 0.025600, loss_ce: 0.010822
2021-12-13 01:07:24,626 iteration 4909 : loss : 0.032393, loss_ce: 0.011055
2021-12-13 01:07:26,089 iteration 4910 : loss : 0.029639, loss_ce: 0.010754
2021-12-13 01:07:27,510 iteration 4911 : loss : 0.025759, loss_ce: 0.008572
2021-12-13 01:07:29,016 iteration 4912 : loss : 0.034460, loss_ce: 0.013305
2021-12-13 01:07:30,483 iteration 4913 : loss : 0.027820, loss_ce: 0.009033
 72%|████████████████████▉        | 289/400 [2:12:12<48:10, 26.04s/it]2021-12-13 01:07:31,930 iteration 4914 : loss : 0.023477, loss_ce: 0.009605
2021-12-13 01:07:33,422 iteration 4915 : loss : 0.026721, loss_ce: 0.012479
2021-12-13 01:07:34,942 iteration 4916 : loss : 0.038963, loss_ce: 0.012426
2021-12-13 01:07:36,406 iteration 4917 : loss : 0.022797, loss_ce: 0.007748
2021-12-13 01:07:37,885 iteration 4918 : loss : 0.025337, loss_ce: 0.010776
2021-12-13 01:07:39,352 iteration 4919 : loss : 0.030539, loss_ce: 0.016014
2021-12-13 01:07:40,885 iteration 4920 : loss : 0.030407, loss_ce: 0.010182
2021-12-13 01:07:42,291 iteration 4921 : loss : 0.030102, loss_ce: 0.011006
2021-12-13 01:07:43,792 iteration 4922 : loss : 0.026342, loss_ce: 0.009390
2021-12-13 01:07:45,268 iteration 4923 : loss : 0.028887, loss_ce: 0.011116
2021-12-13 01:07:46,758 iteration 4924 : loss : 0.026310, loss_ce: 0.011558
2021-12-13 01:07:48,209 iteration 4925 : loss : 0.026829, loss_ce: 0.010542
2021-12-13 01:07:49,576 iteration 4926 : loss : 0.025461, loss_ce: 0.012017
2021-12-13 01:07:51,039 iteration 4927 : loss : 0.021674, loss_ce: 0.007835
2021-12-13 01:07:52,530 iteration 4928 : loss : 0.025477, loss_ce: 0.011882
2021-12-13 01:07:53,951 iteration 4929 : loss : 0.031540, loss_ce: 0.009142
2021-12-13 01:07:53,951 Training Data Eval:
2021-12-13 01:08:01,488   Average segmentation loss on training set: 0.0160
2021-12-13 01:08:01,489 Validation Data Eval:
2021-12-13 01:08:04,090   Average segmentation loss on validation set: 0.0807
2021-12-13 01:08:05,578 iteration 4930 : loss : 0.025635, loss_ce: 0.008590
 72%|█████████████████████        | 290/400 [2:12:47<52:43, 28.76s/it]2021-12-13 01:08:07,125 iteration 4931 : loss : 0.037290, loss_ce: 0.017218
2021-12-13 01:08:08,640 iteration 4932 : loss : 0.034052, loss_ce: 0.009525
2021-12-13 01:08:10,050 iteration 4933 : loss : 0.026769, loss_ce: 0.011148
2021-12-13 01:08:11,533 iteration 4934 : loss : 0.022496, loss_ce: 0.008191
2021-12-13 01:08:12,977 iteration 4935 : loss : 0.021195, loss_ce: 0.006250
2021-12-13 01:08:14,473 iteration 4936 : loss : 0.023779, loss_ce: 0.008896
2021-12-13 01:08:15,904 iteration 4937 : loss : 0.027732, loss_ce: 0.009478
2021-12-13 01:08:17,316 iteration 4938 : loss : 0.024973, loss_ce: 0.010146
2021-12-13 01:08:18,879 iteration 4939 : loss : 0.033332, loss_ce: 0.013093
2021-12-13 01:08:20,302 iteration 4940 : loss : 0.029377, loss_ce: 0.011468
2021-12-13 01:08:21,775 iteration 4941 : loss : 0.032335, loss_ce: 0.014001
2021-12-13 01:08:23,411 iteration 4942 : loss : 0.035888, loss_ce: 0.012456
2021-12-13 01:08:24,855 iteration 4943 : loss : 0.026324, loss_ce: 0.011395
2021-12-13 01:08:26,294 iteration 4944 : loss : 0.027837, loss_ce: 0.013940
2021-12-13 01:08:27,758 iteration 4945 : loss : 0.026824, loss_ce: 0.010814
2021-12-13 01:08:29,157 iteration 4946 : loss : 0.028598, loss_ce: 0.010641
2021-12-13 01:08:30,685 iteration 4947 : loss : 0.029502, loss_ce: 0.010529
 73%|█████████████████████        | 291/400 [2:13:12<50:14, 27.66s/it]2021-12-13 01:08:32,222 iteration 4948 : loss : 0.041218, loss_ce: 0.014541
2021-12-13 01:08:33,814 iteration 4949 : loss : 0.038754, loss_ce: 0.015983
2021-12-13 01:08:35,241 iteration 4950 : loss : 0.025253, loss_ce: 0.013001
2021-12-13 01:08:36,701 iteration 4951 : loss : 0.035852, loss_ce: 0.014330
2021-12-13 01:08:38,165 iteration 4952 : loss : 0.028648, loss_ce: 0.010611
2021-12-13 01:08:39,721 iteration 4953 : loss : 0.037164, loss_ce: 0.010741
2021-12-13 01:08:41,100 iteration 4954 : loss : 0.026546, loss_ce: 0.008400
2021-12-13 01:08:42,525 iteration 4955 : loss : 0.024032, loss_ce: 0.012015
2021-12-13 01:08:44,030 iteration 4956 : loss : 0.029134, loss_ce: 0.008898
2021-12-13 01:08:45,505 iteration 4957 : loss : 0.024149, loss_ce: 0.010544
2021-12-13 01:08:47,122 iteration 4958 : loss : 0.034749, loss_ce: 0.014003
2021-12-13 01:08:48,672 iteration 4959 : loss : 0.035587, loss_ce: 0.014190
2021-12-13 01:08:50,274 iteration 4960 : loss : 0.041472, loss_ce: 0.016464
2021-12-13 01:08:51,731 iteration 4961 : loss : 0.031015, loss_ce: 0.008152
2021-12-13 01:08:53,203 iteration 4962 : loss : 0.030784, loss_ce: 0.013911
2021-12-13 01:08:54,713 iteration 4963 : loss : 0.029763, loss_ce: 0.011606
2021-12-13 01:08:56,224 iteration 4964 : loss : 0.022533, loss_ce: 0.007603
 73%|█████████████████████▏       | 292/400 [2:13:38<48:38, 27.02s/it]2021-12-13 01:08:57,705 iteration 4965 : loss : 0.038152, loss_ce: 0.011920
2021-12-13 01:08:59,178 iteration 4966 : loss : 0.032527, loss_ce: 0.011671
2021-12-13 01:09:00,652 iteration 4967 : loss : 0.034263, loss_ce: 0.010703
2021-12-13 01:09:02,114 iteration 4968 : loss : 0.054602, loss_ce: 0.014219
2021-12-13 01:09:03,600 iteration 4969 : loss : 0.035177, loss_ce: 0.013624
2021-12-13 01:09:05,113 iteration 4970 : loss : 0.029792, loss_ce: 0.016152
2021-12-13 01:09:06,564 iteration 4971 : loss : 0.024224, loss_ce: 0.009811
2021-12-13 01:09:07,986 iteration 4972 : loss : 0.027797, loss_ce: 0.008994
2021-12-13 01:09:09,428 iteration 4973 : loss : 0.024263, loss_ce: 0.008775
2021-12-13 01:09:10,923 iteration 4974 : loss : 0.024477, loss_ce: 0.012205
2021-12-13 01:09:12,479 iteration 4975 : loss : 0.024340, loss_ce: 0.008638
2021-12-13 01:09:13,918 iteration 4976 : loss : 0.024074, loss_ce: 0.009359
2021-12-13 01:09:15,374 iteration 4977 : loss : 0.025629, loss_ce: 0.011265
2021-12-13 01:09:16,850 iteration 4978 : loss : 0.029745, loss_ce: 0.011927
2021-12-13 01:09:18,279 iteration 4979 : loss : 0.023127, loss_ce: 0.008534
2021-12-13 01:09:19,675 iteration 4980 : loss : 0.020390, loss_ce: 0.007432
2021-12-13 01:09:21,127 iteration 4981 : loss : 0.030380, loss_ce: 0.010093
 73%|█████████████████████▏       | 293/400 [2:14:03<47:03, 26.39s/it]2021-12-13 01:09:22,657 iteration 4982 : loss : 0.045617, loss_ce: 0.010274
2021-12-13 01:09:24,048 iteration 4983 : loss : 0.023896, loss_ce: 0.008075
2021-12-13 01:09:25,525 iteration 4984 : loss : 0.025095, loss_ce: 0.007570
2021-12-13 01:09:26,916 iteration 4985 : loss : 0.030566, loss_ce: 0.008940
2021-12-13 01:09:28,334 iteration 4986 : loss : 0.028002, loss_ce: 0.010410
2021-12-13 01:09:29,802 iteration 4987 : loss : 0.024506, loss_ce: 0.011410
2021-12-13 01:09:31,284 iteration 4988 : loss : 0.025700, loss_ce: 0.014241
2021-12-13 01:09:32,733 iteration 4989 : loss : 0.030620, loss_ce: 0.012557
2021-12-13 01:09:34,224 iteration 4990 : loss : 0.028865, loss_ce: 0.012782
2021-12-13 01:09:35,675 iteration 4991 : loss : 0.027595, loss_ce: 0.009394
2021-12-13 01:09:37,150 iteration 4992 : loss : 0.034248, loss_ce: 0.010935
2021-12-13 01:09:38,626 iteration 4993 : loss : 0.029810, loss_ce: 0.012998
2021-12-13 01:09:40,223 iteration 4994 : loss : 0.033822, loss_ce: 0.013051
2021-12-13 01:09:41,747 iteration 4995 : loss : 0.035802, loss_ce: 0.016478
2021-12-13 01:09:43,176 iteration 4996 : loss : 0.026248, loss_ce: 0.007943
2021-12-13 01:09:44,659 iteration 4997 : loss : 0.032331, loss_ce: 0.012192
2021-12-13 01:09:46,140 iteration 4998 : loss : 0.026626, loss_ce: 0.010545
 74%|█████████████████████▎       | 294/400 [2:14:28<45:53, 25.98s/it]2021-12-13 01:09:47,646 iteration 4999 : loss : 0.025163, loss_ce: 0.010141
2021-12-13 01:09:49,048 iteration 5000 : loss : 0.027384, loss_ce: 0.009407
2021-12-13 01:09:50,549 iteration 5001 : loss : 0.029035, loss_ce: 0.008322
2021-12-13 01:09:52,103 iteration 5002 : loss : 0.041078, loss_ce: 0.014055
2021-12-13 01:09:53,678 iteration 5003 : loss : 0.033046, loss_ce: 0.014908
2021-12-13 01:09:55,166 iteration 5004 : loss : 0.024611, loss_ce: 0.010893
2021-12-13 01:09:56,680 iteration 5005 : loss : 0.026635, loss_ce: 0.010883
2021-12-13 01:09:58,109 iteration 5006 : loss : 0.027909, loss_ce: 0.010544
2021-12-13 01:09:59,622 iteration 5007 : loss : 0.035400, loss_ce: 0.008870
2021-12-13 01:10:01,053 iteration 5008 : loss : 0.028361, loss_ce: 0.010024
2021-12-13 01:10:02,480 iteration 5009 : loss : 0.022308, loss_ce: 0.011905
2021-12-13 01:10:04,002 iteration 5010 : loss : 0.025988, loss_ce: 0.011685
2021-12-13 01:10:05,432 iteration 5011 : loss : 0.023100, loss_ce: 0.009248
2021-12-13 01:10:06,888 iteration 5012 : loss : 0.044227, loss_ce: 0.010943
2021-12-13 01:10:08,455 iteration 5013 : loss : 0.029780, loss_ce: 0.014085
2021-12-13 01:10:09,862 iteration 5014 : loss : 0.030199, loss_ce: 0.012052
2021-12-13 01:10:09,863 Training Data Eval:
2021-12-13 01:10:17,456   Average segmentation loss on training set: 0.0160
2021-12-13 01:10:17,456 Validation Data Eval:
2021-12-13 01:10:20,066   Average segmentation loss on validation set: 0.0848
2021-12-13 01:10:21,525 iteration 5015 : loss : 0.032345, loss_ce: 0.010854
 74%|█████████████████████▍       | 295/400 [2:15:03<50:23, 28.80s/it]2021-12-13 01:10:23,080 iteration 5016 : loss : 0.025614, loss_ce: 0.010767
2021-12-13 01:10:24,461 iteration 5017 : loss : 0.022252, loss_ce: 0.009096
2021-12-13 01:10:26,047 iteration 5018 : loss : 0.027436, loss_ce: 0.012194
2021-12-13 01:10:27,456 iteration 5019 : loss : 0.026443, loss_ce: 0.009612
2021-12-13 01:10:28,992 iteration 5020 : loss : 0.036141, loss_ce: 0.011064
2021-12-13 01:10:30,470 iteration 5021 : loss : 0.032338, loss_ce: 0.012231
2021-12-13 01:10:31,943 iteration 5022 : loss : 0.028159, loss_ce: 0.009526
2021-12-13 01:10:33,432 iteration 5023 : loss : 0.027272, loss_ce: 0.011703
2021-12-13 01:10:34,984 iteration 5024 : loss : 0.038520, loss_ce: 0.016117
2021-12-13 01:10:36,477 iteration 5025 : loss : 0.028616, loss_ce: 0.010489
2021-12-13 01:10:38,025 iteration 5026 : loss : 0.037391, loss_ce: 0.015780
2021-12-13 01:10:39,460 iteration 5027 : loss : 0.028799, loss_ce: 0.010469
2021-12-13 01:10:40,866 iteration 5028 : loss : 0.021654, loss_ce: 0.009278
2021-12-13 01:10:42,407 iteration 5029 : loss : 0.031717, loss_ce: 0.013730
2021-12-13 01:10:43,860 iteration 5030 : loss : 0.022427, loss_ce: 0.010812
2021-12-13 01:10:45,389 iteration 5031 : loss : 0.045032, loss_ce: 0.015674
2021-12-13 01:10:46,795 iteration 5032 : loss : 0.024519, loss_ce: 0.009599
 74%|█████████████████████▍       | 296/400 [2:15:28<48:04, 27.74s/it]2021-12-13 01:10:48,247 iteration 5033 : loss : 0.026593, loss_ce: 0.009876
2021-12-13 01:10:49,673 iteration 5034 : loss : 0.034241, loss_ce: 0.011711
2021-12-13 01:10:51,139 iteration 5035 : loss : 0.033928, loss_ce: 0.012137
2021-12-13 01:10:52,565 iteration 5036 : loss : 0.027883, loss_ce: 0.011136
2021-12-13 01:10:54,026 iteration 5037 : loss : 0.026657, loss_ce: 0.009542
2021-12-13 01:10:55,466 iteration 5038 : loss : 0.026326, loss_ce: 0.009395
2021-12-13 01:10:56,954 iteration 5039 : loss : 0.027576, loss_ce: 0.009821
2021-12-13 01:10:58,468 iteration 5040 : loss : 0.026680, loss_ce: 0.010568
2021-12-13 01:10:59,931 iteration 5041 : loss : 0.028115, loss_ce: 0.011884
2021-12-13 01:11:01,504 iteration 5042 : loss : 0.034552, loss_ce: 0.011583
2021-12-13 01:11:02,880 iteration 5043 : loss : 0.029067, loss_ce: 0.011538
2021-12-13 01:11:04,396 iteration 5044 : loss : 0.031482, loss_ce: 0.011475
2021-12-13 01:11:05,897 iteration 5045 : loss : 0.039540, loss_ce: 0.018985
2021-12-13 01:11:07,383 iteration 5046 : loss : 0.036319, loss_ce: 0.009009
2021-12-13 01:11:08,796 iteration 5047 : loss : 0.020891, loss_ce: 0.006856
2021-12-13 01:11:10,195 iteration 5048 : loss : 0.018361, loss_ce: 0.009180
2021-12-13 01:11:11,579 iteration 5049 : loss : 0.022267, loss_ce: 0.009952
 74%|█████████████████████▌       | 297/400 [2:15:53<46:05, 26.85s/it]2021-12-13 01:11:13,117 iteration 5050 : loss : 0.023599, loss_ce: 0.007875
2021-12-13 01:11:14,654 iteration 5051 : loss : 0.040464, loss_ce: 0.018185
2021-12-13 01:11:16,228 iteration 5052 : loss : 0.028977, loss_ce: 0.011884
2021-12-13 01:11:17,790 iteration 5053 : loss : 0.036855, loss_ce: 0.011503
2021-12-13 01:11:19,241 iteration 5054 : loss : 0.025902, loss_ce: 0.007345
2021-12-13 01:11:20,719 iteration 5055 : loss : 0.045495, loss_ce: 0.018158
2021-12-13 01:11:22,202 iteration 5056 : loss : 0.030973, loss_ce: 0.012235
2021-12-13 01:11:23,746 iteration 5057 : loss : 0.028652, loss_ce: 0.011522
2021-12-13 01:11:25,301 iteration 5058 : loss : 0.047466, loss_ce: 0.019615
2021-12-13 01:11:26,755 iteration 5059 : loss : 0.026393, loss_ce: 0.011325
2021-12-13 01:11:28,264 iteration 5060 : loss : 0.027246, loss_ce: 0.013046
2021-12-13 01:11:29,786 iteration 5061 : loss : 0.031861, loss_ce: 0.013536
2021-12-13 01:11:31,341 iteration 5062 : loss : 0.037174, loss_ce: 0.012278
2021-12-13 01:11:32,890 iteration 5063 : loss : 0.038628, loss_ce: 0.014001
2021-12-13 01:11:34,354 iteration 5064 : loss : 0.035850, loss_ce: 0.013609
2021-12-13 01:11:35,873 iteration 5065 : loss : 0.026345, loss_ce: 0.012705
2021-12-13 01:11:37,292 iteration 5066 : loss : 0.022696, loss_ce: 0.009712
 74%|█████████████████████▌       | 298/400 [2:16:19<45:03, 26.51s/it]2021-12-13 01:11:38,679 iteration 5067 : loss : 0.025233, loss_ce: 0.009330
2021-12-13 01:11:40,193 iteration 5068 : loss : 0.038223, loss_ce: 0.010399
2021-12-13 01:11:41,673 iteration 5069 : loss : 0.027128, loss_ce: 0.013049
2021-12-13 01:11:43,081 iteration 5070 : loss : 0.029234, loss_ce: 0.010187
2021-12-13 01:11:44,583 iteration 5071 : loss : 0.036113, loss_ce: 0.014799
2021-12-13 01:11:45,975 iteration 5072 : loss : 0.024600, loss_ce: 0.009445
2021-12-13 01:11:47,518 iteration 5073 : loss : 0.031624, loss_ce: 0.013048
2021-12-13 01:11:48,959 iteration 5074 : loss : 0.021296, loss_ce: 0.008848
2021-12-13 01:11:50,403 iteration 5075 : loss : 0.034416, loss_ce: 0.013928
2021-12-13 01:11:51,888 iteration 5076 : loss : 0.047136, loss_ce: 0.009798
2021-12-13 01:11:53,355 iteration 5077 : loss : 0.028643, loss_ce: 0.009672
2021-12-13 01:11:54,775 iteration 5078 : loss : 0.036058, loss_ce: 0.017651
2021-12-13 01:11:56,182 iteration 5079 : loss : 0.022006, loss_ce: 0.009358
2021-12-13 01:11:57,609 iteration 5080 : loss : 0.027936, loss_ce: 0.011311
2021-12-13 01:11:59,103 iteration 5081 : loss : 0.037530, loss_ce: 0.012886
2021-12-13 01:12:00,549 iteration 5082 : loss : 0.028168, loss_ce: 0.011879
2021-12-13 01:12:02,028 iteration 5083 : loss : 0.033274, loss_ce: 0.007363
 75%|█████████████████████▋       | 299/400 [2:16:43<43:43, 25.98s/it]2021-12-13 01:12:03,563 iteration 5084 : loss : 0.029523, loss_ce: 0.013756
2021-12-13 01:12:05,119 iteration 5085 : loss : 0.031476, loss_ce: 0.012386
2021-12-13 01:12:06,624 iteration 5086 : loss : 0.022430, loss_ce: 0.007684
2021-12-13 01:12:08,036 iteration 5087 : loss : 0.030134, loss_ce: 0.012954
2021-12-13 01:12:09,456 iteration 5088 : loss : 0.032005, loss_ce: 0.013661
2021-12-13 01:12:10,961 iteration 5089 : loss : 0.026381, loss_ce: 0.007968
2021-12-13 01:12:12,434 iteration 5090 : loss : 0.029006, loss_ce: 0.006758
2021-12-13 01:12:13,971 iteration 5091 : loss : 0.036625, loss_ce: 0.012265
2021-12-13 01:12:15,456 iteration 5092 : loss : 0.033115, loss_ce: 0.013319
2021-12-13 01:12:16,887 iteration 5093 : loss : 0.029223, loss_ce: 0.008785
2021-12-13 01:12:18,386 iteration 5094 : loss : 0.036765, loss_ce: 0.014240
2021-12-13 01:12:19,799 iteration 5095 : loss : 0.021576, loss_ce: 0.009211
2021-12-13 01:12:21,254 iteration 5096 : loss : 0.031195, loss_ce: 0.013416
2021-12-13 01:12:22,647 iteration 5097 : loss : 0.029723, loss_ce: 0.013599
2021-12-13 01:12:24,183 iteration 5098 : loss : 0.037818, loss_ce: 0.012327
2021-12-13 01:12:25,678 iteration 5099 : loss : 0.035143, loss_ce: 0.012107
2021-12-13 01:12:25,679 Training Data Eval:
2021-12-13 01:12:33,185   Average segmentation loss on training set: 0.0167
2021-12-13 01:12:33,186 Validation Data Eval:
2021-12-13 01:12:35,782   Average segmentation loss on validation set: 0.0808
2021-12-13 01:12:37,314 iteration 5100 : loss : 0.032885, loss_ce: 0.009690
 75%|█████████████████████▊       | 300/400 [2:17:19<47:57, 28.77s/it]2021-12-13 01:12:38,915 iteration 5101 : loss : 0.030744, loss_ce: 0.011175
2021-12-13 01:12:40,374 iteration 5102 : loss : 0.031814, loss_ce: 0.012355
2021-12-13 01:12:41,848 iteration 5103 : loss : 0.033846, loss_ce: 0.017289
2021-12-13 01:12:43,383 iteration 5104 : loss : 0.029933, loss_ce: 0.008851
2021-12-13 01:12:44,824 iteration 5105 : loss : 0.029481, loss_ce: 0.013304
2021-12-13 01:12:46,264 iteration 5106 : loss : 0.025352, loss_ce: 0.009825
2021-12-13 01:12:47,796 iteration 5107 : loss : 0.031081, loss_ce: 0.009250
2021-12-13 01:12:49,297 iteration 5108 : loss : 0.032960, loss_ce: 0.013834
2021-12-13 01:12:50,771 iteration 5109 : loss : 0.036263, loss_ce: 0.014649
2021-12-13 01:12:52,192 iteration 5110 : loss : 0.019107, loss_ce: 0.006580
2021-12-13 01:12:53,688 iteration 5111 : loss : 0.033108, loss_ce: 0.012559
2021-12-13 01:12:55,271 iteration 5112 : loss : 0.038607, loss_ce: 0.015355
2021-12-13 01:12:56,766 iteration 5113 : loss : 0.030561, loss_ce: 0.008932
2021-12-13 01:12:58,311 iteration 5114 : loss : 0.034435, loss_ce: 0.012920
2021-12-13 01:12:59,782 iteration 5115 : loss : 0.034855, loss_ce: 0.012548
2021-12-13 01:13:01,245 iteration 5116 : loss : 0.029266, loss_ce: 0.012440
2021-12-13 01:13:02,747 iteration 5117 : loss : 0.031391, loss_ce: 0.013654
 75%|█████████████████████▊       | 301/400 [2:17:44<45:49, 27.77s/it]2021-12-13 01:13:04,295 iteration 5118 : loss : 0.038415, loss_ce: 0.010738
2021-12-13 01:13:05,756 iteration 5119 : loss : 0.023932, loss_ce: 0.010733
2021-12-13 01:13:07,169 iteration 5120 : loss : 0.024635, loss_ce: 0.010056
2021-12-13 01:13:08,691 iteration 5121 : loss : 0.024815, loss_ce: 0.007715
2021-12-13 01:13:10,254 iteration 5122 : loss : 0.028362, loss_ce: 0.011884
2021-12-13 01:13:11,808 iteration 5123 : loss : 0.042135, loss_ce: 0.013870
2021-12-13 01:13:13,227 iteration 5124 : loss : 0.027749, loss_ce: 0.013126
2021-12-13 01:13:14,641 iteration 5125 : loss : 0.025160, loss_ce: 0.008936
2021-12-13 01:13:16,127 iteration 5126 : loss : 0.032658, loss_ce: 0.011268
2021-12-13 01:13:17,586 iteration 5127 : loss : 0.033068, loss_ce: 0.015364
2021-12-13 01:13:19,014 iteration 5128 : loss : 0.026665, loss_ce: 0.009056
2021-12-13 01:13:20,493 iteration 5129 : loss : 0.034242, loss_ce: 0.014960
2021-12-13 01:13:21,957 iteration 5130 : loss : 0.033004, loss_ce: 0.013615
2021-12-13 01:13:23,457 iteration 5131 : loss : 0.032314, loss_ce: 0.012772
2021-12-13 01:13:24,918 iteration 5132 : loss : 0.039176, loss_ce: 0.014286
2021-12-13 01:13:26,455 iteration 5133 : loss : 0.034860, loss_ce: 0.013252
2021-12-13 01:13:27,916 iteration 5134 : loss : 0.037363, loss_ce: 0.010126
 76%|█████████████████████▉       | 302/400 [2:18:09<44:04, 26.99s/it]2021-12-13 01:13:29,410 iteration 5135 : loss : 0.031606, loss_ce: 0.017246
2021-12-13 01:13:30,870 iteration 5136 : loss : 0.022256, loss_ce: 0.007836
2021-12-13 01:13:32,283 iteration 5137 : loss : 0.023909, loss_ce: 0.009209
2021-12-13 01:13:33,780 iteration 5138 : loss : 0.028076, loss_ce: 0.012905
2021-12-13 01:13:35,347 iteration 5139 : loss : 0.031505, loss_ce: 0.012508
2021-12-13 01:13:36,885 iteration 5140 : loss : 0.034978, loss_ce: 0.012425
2021-12-13 01:13:38,309 iteration 5141 : loss : 0.029214, loss_ce: 0.011556
2021-12-13 01:13:39,797 iteration 5142 : loss : 0.028047, loss_ce: 0.009124
2021-12-13 01:13:41,255 iteration 5143 : loss : 0.022899, loss_ce: 0.011390
2021-12-13 01:13:42,804 iteration 5144 : loss : 0.028171, loss_ce: 0.011816
2021-12-13 01:13:44,413 iteration 5145 : loss : 0.021762, loss_ce: 0.007039
2021-12-13 01:13:45,926 iteration 5146 : loss : 0.037477, loss_ce: 0.011755
2021-12-13 01:13:47,337 iteration 5147 : loss : 0.027153, loss_ce: 0.006883
2021-12-13 01:13:48,796 iteration 5148 : loss : 0.027432, loss_ce: 0.010776
2021-12-13 01:13:50,245 iteration 5149 : loss : 0.026483, loss_ce: 0.009605
2021-12-13 01:13:51,712 iteration 5150 : loss : 0.026039, loss_ce: 0.013543
2021-12-13 01:13:53,226 iteration 5151 : loss : 0.031837, loss_ce: 0.015377
 76%|█████████████████████▉       | 303/400 [2:18:35<42:49, 26.49s/it]2021-12-13 01:13:54,718 iteration 5152 : loss : 0.029512, loss_ce: 0.012213
2021-12-13 01:13:56,196 iteration 5153 : loss : 0.028195, loss_ce: 0.011261
2021-12-13 01:13:57,594 iteration 5154 : loss : 0.024339, loss_ce: 0.008212
2021-12-13 01:13:59,007 iteration 5155 : loss : 0.024409, loss_ce: 0.008748
2021-12-13 01:14:00,464 iteration 5156 : loss : 0.034930, loss_ce: 0.009907
2021-12-13 01:14:01,879 iteration 5157 : loss : 0.020536, loss_ce: 0.008222
2021-12-13 01:14:03,308 iteration 5158 : loss : 0.028330, loss_ce: 0.010229
2021-12-13 01:14:04,792 iteration 5159 : loss : 0.026960, loss_ce: 0.010007
2021-12-13 01:14:06,274 iteration 5160 : loss : 0.029864, loss_ce: 0.013232
2021-12-13 01:14:07,779 iteration 5161 : loss : 0.028941, loss_ce: 0.011685
2021-12-13 01:14:09,320 iteration 5162 : loss : 0.028179, loss_ce: 0.009090
2021-12-13 01:14:10,818 iteration 5163 : loss : 0.027894, loss_ce: 0.014009
2021-12-13 01:14:12,238 iteration 5164 : loss : 0.021907, loss_ce: 0.008727
2021-12-13 01:14:13,783 iteration 5165 : loss : 0.028956, loss_ce: 0.009861
2021-12-13 01:14:15,272 iteration 5166 : loss : 0.025818, loss_ce: 0.010090
2021-12-13 01:14:16,793 iteration 5167 : loss : 0.031634, loss_ce: 0.009206
2021-12-13 01:14:18,174 iteration 5168 : loss : 0.024534, loss_ce: 0.011596
 76%|██████████████████████       | 304/400 [2:19:00<41:38, 26.02s/it]2021-12-13 01:14:19,733 iteration 5169 : loss : 0.032741, loss_ce: 0.009207
2021-12-13 01:14:21,182 iteration 5170 : loss : 0.021872, loss_ce: 0.010911
2021-12-13 01:14:22,657 iteration 5171 : loss : 0.034286, loss_ce: 0.011165
2021-12-13 01:14:24,145 iteration 5172 : loss : 0.035572, loss_ce: 0.012250
2021-12-13 01:14:25,697 iteration 5173 : loss : 0.038247, loss_ce: 0.014575
2021-12-13 01:14:27,175 iteration 5174 : loss : 0.019070, loss_ce: 0.006199
2021-12-13 01:14:28,684 iteration 5175 : loss : 0.027951, loss_ce: 0.010003
2021-12-13 01:14:30,240 iteration 5176 : loss : 0.027338, loss_ce: 0.009151
2021-12-13 01:14:31,726 iteration 5177 : loss : 0.023836, loss_ce: 0.009243
2021-12-13 01:14:33,219 iteration 5178 : loss : 0.019881, loss_ce: 0.008695
2021-12-13 01:14:34,668 iteration 5179 : loss : 0.026486, loss_ce: 0.011500
2021-12-13 01:14:36,083 iteration 5180 : loss : 0.025116, loss_ce: 0.010715
2021-12-13 01:14:37,512 iteration 5181 : loss : 0.027761, loss_ce: 0.008448
2021-12-13 01:14:38,964 iteration 5182 : loss : 0.030736, loss_ce: 0.013643
2021-12-13 01:14:40,408 iteration 5183 : loss : 0.024870, loss_ce: 0.009026
2021-12-13 01:14:41,827 iteration 5184 : loss : 0.024648, loss_ce: 0.011793
2021-12-13 01:14:41,827 Training Data Eval:
2021-12-13 01:14:49,349   Average segmentation loss on training set: 0.0155
2021-12-13 01:14:49,349 Validation Data Eval:
2021-12-13 01:14:51,949   Average segmentation loss on validation set: 0.0769
2021-12-13 01:14:53,388 iteration 5185 : loss : 0.023388, loss_ce: 0.009076
 76%|██████████████████████       | 305/400 [2:19:35<45:34, 28.78s/it]2021-12-13 01:14:54,939 iteration 5186 : loss : 0.034005, loss_ce: 0.009928
2021-12-13 01:14:56,351 iteration 5187 : loss : 0.023960, loss_ce: 0.009875
2021-12-13 01:14:57,813 iteration 5188 : loss : 0.025423, loss_ce: 0.008676
2021-12-13 01:14:59,294 iteration 5189 : loss : 0.034999, loss_ce: 0.010698
2021-12-13 01:15:00,863 iteration 5190 : loss : 0.030476, loss_ce: 0.011366
2021-12-13 01:15:02,325 iteration 5191 : loss : 0.029203, loss_ce: 0.011432
2021-12-13 01:15:03,789 iteration 5192 : loss : 0.029898, loss_ce: 0.010879
2021-12-13 01:15:05,302 iteration 5193 : loss : 0.026829, loss_ce: 0.012072
2021-12-13 01:15:06,799 iteration 5194 : loss : 0.029973, loss_ce: 0.009726
2021-12-13 01:15:08,264 iteration 5195 : loss : 0.027591, loss_ce: 0.008437
2021-12-13 01:15:09,836 iteration 5196 : loss : 0.041382, loss_ce: 0.013527
2021-12-13 01:15:11,305 iteration 5197 : loss : 0.033773, loss_ce: 0.010012
2021-12-13 01:15:12,734 iteration 5198 : loss : 0.024417, loss_ce: 0.014070
2021-12-13 01:15:14,324 iteration 5199 : loss : 0.030677, loss_ce: 0.011546
2021-12-13 01:15:15,716 iteration 5200 : loss : 0.030912, loss_ce: 0.013599
2021-12-13 01:15:17,121 iteration 5201 : loss : 0.026545, loss_ce: 0.011080
2021-12-13 01:15:18,573 iteration 5202 : loss : 0.031686, loss_ce: 0.011178
 76%|██████████████████████▏      | 306/400 [2:20:00<43:24, 27.70s/it]2021-12-13 01:15:20,062 iteration 5203 : loss : 0.026554, loss_ce: 0.010977
2021-12-13 01:15:21,586 iteration 5204 : loss : 0.028371, loss_ce: 0.011296
2021-12-13 01:15:23,102 iteration 5205 : loss : 0.040938, loss_ce: 0.010730
2021-12-13 01:15:24,714 iteration 5206 : loss : 0.031424, loss_ce: 0.012769
2021-12-13 01:15:26,246 iteration 5207 : loss : 0.071433, loss_ce: 0.013496
2021-12-13 01:15:27,731 iteration 5208 : loss : 0.022527, loss_ce: 0.009889
2021-12-13 01:15:29,260 iteration 5209 : loss : 0.027969, loss_ce: 0.010970
2021-12-13 01:15:30,786 iteration 5210 : loss : 0.033066, loss_ce: 0.016754
2021-12-13 01:15:32,254 iteration 5211 : loss : 0.024812, loss_ce: 0.008742
2021-12-13 01:15:33,778 iteration 5212 : loss : 0.047190, loss_ce: 0.012686
2021-12-13 01:15:35,244 iteration 5213 : loss : 0.030854, loss_ce: 0.011244
2021-12-13 01:15:36,714 iteration 5214 : loss : 0.026840, loss_ce: 0.012152
2021-12-13 01:15:38,102 iteration 5215 : loss : 0.025317, loss_ce: 0.009404
2021-12-13 01:15:39,540 iteration 5216 : loss : 0.037638, loss_ce: 0.011795
2021-12-13 01:15:41,082 iteration 5217 : loss : 0.039493, loss_ce: 0.016157
2021-12-13 01:15:42,505 iteration 5218 : loss : 0.020358, loss_ce: 0.007805
2021-12-13 01:15:43,980 iteration 5219 : loss : 0.027978, loss_ce: 0.010840
 77%|██████████████████████▎      | 307/400 [2:20:25<41:52, 27.02s/it]2021-12-13 01:15:45,406 iteration 5220 : loss : 0.020323, loss_ce: 0.009005
2021-12-13 01:15:46,807 iteration 5221 : loss : 0.030236, loss_ce: 0.008140
2021-12-13 01:15:48,315 iteration 5222 : loss : 0.040398, loss_ce: 0.012309
2021-12-13 01:15:49,772 iteration 5223 : loss : 0.027449, loss_ce: 0.011710
2021-12-13 01:15:51,322 iteration 5224 : loss : 0.045690, loss_ce: 0.011193
2021-12-13 01:15:52,775 iteration 5225 : loss : 0.030239, loss_ce: 0.013224
2021-12-13 01:15:54,260 iteration 5226 : loss : 0.024132, loss_ce: 0.010649
2021-12-13 01:15:55,751 iteration 5227 : loss : 0.035174, loss_ce: 0.012800
2021-12-13 01:15:57,147 iteration 5228 : loss : 0.020813, loss_ce: 0.007209
2021-12-13 01:15:58,663 iteration 5229 : loss : 0.036045, loss_ce: 0.015035
2021-12-13 01:16:00,072 iteration 5230 : loss : 0.020626, loss_ce: 0.007498
2021-12-13 01:16:01,553 iteration 5231 : loss : 0.023917, loss_ce: 0.008387
2021-12-13 01:16:03,110 iteration 5232 : loss : 0.035605, loss_ce: 0.011941
2021-12-13 01:16:04,463 iteration 5233 : loss : 0.026112, loss_ce: 0.010794
2021-12-13 01:16:05,928 iteration 5234 : loss : 0.028049, loss_ce: 0.011413
2021-12-13 01:16:07,432 iteration 5235 : loss : 0.035393, loss_ce: 0.017332
2021-12-13 01:16:08,991 iteration 5236 : loss : 0.041088, loss_ce: 0.016361
 77%|██████████████████████▎      | 308/400 [2:20:50<40:29, 26.41s/it]2021-12-13 01:16:10,418 iteration 5237 : loss : 0.020006, loss_ce: 0.009580
2021-12-13 01:16:11,876 iteration 5238 : loss : 0.026822, loss_ce: 0.011868
2021-12-13 01:16:13,329 iteration 5239 : loss : 0.024110, loss_ce: 0.008404
2021-12-13 01:16:14,870 iteration 5240 : loss : 0.053661, loss_ce: 0.010814
2021-12-13 01:16:16,361 iteration 5241 : loss : 0.033192, loss_ce: 0.011853
2021-12-13 01:16:17,936 iteration 5242 : loss : 0.032087, loss_ce: 0.014549
2021-12-13 01:16:19,446 iteration 5243 : loss : 0.039259, loss_ce: 0.016463
2021-12-13 01:16:20,920 iteration 5244 : loss : 0.023016, loss_ce: 0.007762
2021-12-13 01:16:22,452 iteration 5245 : loss : 0.037157, loss_ce: 0.014417
2021-12-13 01:16:23,946 iteration 5246 : loss : 0.052850, loss_ce: 0.020470
2021-12-13 01:16:25,403 iteration 5247 : loss : 0.031116, loss_ce: 0.010957
2021-12-13 01:16:26,955 iteration 5248 : loss : 0.032573, loss_ce: 0.014560
2021-12-13 01:16:28,401 iteration 5249 : loss : 0.023856, loss_ce: 0.008292
2021-12-13 01:16:29,880 iteration 5250 : loss : 0.026589, loss_ce: 0.011006
2021-12-13 01:16:31,411 iteration 5251 : loss : 0.024496, loss_ce: 0.009903
2021-12-13 01:16:32,873 iteration 5252 : loss : 0.024085, loss_ce: 0.011611
2021-12-13 01:16:34,320 iteration 5253 : loss : 0.027697, loss_ce: 0.009938
 77%|██████████████████████▍      | 309/400 [2:21:16<39:33, 26.09s/it]2021-12-13 01:16:35,814 iteration 5254 : loss : 0.028804, loss_ce: 0.012500
2021-12-13 01:16:37,338 iteration 5255 : loss : 0.031513, loss_ce: 0.009445
2021-12-13 01:16:38,822 iteration 5256 : loss : 0.034180, loss_ce: 0.015106
2021-12-13 01:16:40,321 iteration 5257 : loss : 0.029720, loss_ce: 0.010798
2021-12-13 01:16:41,717 iteration 5258 : loss : 0.022620, loss_ce: 0.009597
2021-12-13 01:16:43,161 iteration 5259 : loss : 0.038074, loss_ce: 0.012013
2021-12-13 01:16:44,718 iteration 5260 : loss : 0.037610, loss_ce: 0.011235
2021-12-13 01:16:46,180 iteration 5261 : loss : 0.026342, loss_ce: 0.010883
2021-12-13 01:16:47,620 iteration 5262 : loss : 0.032831, loss_ce: 0.014454
2021-12-13 01:16:49,138 iteration 5263 : loss : 0.034373, loss_ce: 0.013678
2021-12-13 01:16:50,641 iteration 5264 : loss : 0.032899, loss_ce: 0.012502
2021-12-13 01:16:52,157 iteration 5265 : loss : 0.028995, loss_ce: 0.012282
2021-12-13 01:16:53,603 iteration 5266 : loss : 0.028544, loss_ce: 0.010776
2021-12-13 01:16:55,168 iteration 5267 : loss : 0.032024, loss_ce: 0.015236
2021-12-13 01:16:56,509 iteration 5268 : loss : 0.021889, loss_ce: 0.005710
2021-12-13 01:16:57,874 iteration 5269 : loss : 0.025290, loss_ce: 0.009593
2021-12-13 01:16:57,874 Training Data Eval:
2021-12-13 01:17:05,404   Average segmentation loss on training set: 0.0168
2021-12-13 01:17:05,405 Validation Data Eval:
2021-12-13 01:17:08,007   Average segmentation loss on validation set: 0.0792
2021-12-13 01:17:09,448 iteration 5270 : loss : 0.044720, loss_ce: 0.008104
 78%|██████████████████████▍      | 310/400 [2:21:51<43:12, 28.80s/it]2021-12-13 01:17:11,070 iteration 5271 : loss : 0.032690, loss_ce: 0.011619
2021-12-13 01:17:12,623 iteration 5272 : loss : 0.033801, loss_ce: 0.011762
2021-12-13 01:17:14,105 iteration 5273 : loss : 0.030511, loss_ce: 0.013104
2021-12-13 01:17:15,588 iteration 5274 : loss : 0.032862, loss_ce: 0.013342
2021-12-13 01:17:17,027 iteration 5275 : loss : 0.027680, loss_ce: 0.011712
2021-12-13 01:17:18,461 iteration 5276 : loss : 0.036497, loss_ce: 0.012816
2021-12-13 01:17:20,039 iteration 5277 : loss : 0.033588, loss_ce: 0.013516
2021-12-13 01:17:21,563 iteration 5278 : loss : 0.028392, loss_ce: 0.008087
2021-12-13 01:17:23,077 iteration 5279 : loss : 0.036974, loss_ce: 0.011938
2021-12-13 01:17:24,489 iteration 5280 : loss : 0.025441, loss_ce: 0.007853
2021-12-13 01:17:25,932 iteration 5281 : loss : 0.024573, loss_ce: 0.011346
2021-12-13 01:17:27,368 iteration 5282 : loss : 0.026040, loss_ce: 0.010552
2021-12-13 01:17:28,794 iteration 5283 : loss : 0.027674, loss_ce: 0.012360
2021-12-13 01:17:30,269 iteration 5284 : loss : 0.024956, loss_ce: 0.009585
2021-12-13 01:17:31,720 iteration 5285 : loss : 0.025952, loss_ce: 0.009676
2021-12-13 01:17:33,136 iteration 5286 : loss : 0.026382, loss_ce: 0.012634
2021-12-13 01:17:34,616 iteration 5287 : loss : 0.025382, loss_ce: 0.008725
 78%|██████████████████████▌      | 311/400 [2:22:16<41:06, 27.71s/it]2021-12-13 01:17:36,129 iteration 5288 : loss : 0.027078, loss_ce: 0.012837
2021-12-13 01:17:37,548 iteration 5289 : loss : 0.031420, loss_ce: 0.012375
2021-12-13 01:17:39,145 iteration 5290 : loss : 0.026430, loss_ce: 0.007498
2021-12-13 01:17:40,622 iteration 5291 : loss : 0.035890, loss_ce: 0.012866
2021-12-13 01:17:42,124 iteration 5292 : loss : 0.028772, loss_ce: 0.007936
2021-12-13 01:17:43,540 iteration 5293 : loss : 0.031915, loss_ce: 0.010868
2021-12-13 01:17:45,053 iteration 5294 : loss : 0.041416, loss_ce: 0.011844
2021-12-13 01:17:46,535 iteration 5295 : loss : 0.025936, loss_ce: 0.008634
2021-12-13 01:17:47,941 iteration 5296 : loss : 0.026910, loss_ce: 0.008377
2021-12-13 01:17:49,399 iteration 5297 : loss : 0.032443, loss_ce: 0.010452
2021-12-13 01:17:50,824 iteration 5298 : loss : 0.024580, loss_ce: 0.011253
2021-12-13 01:17:52,261 iteration 5299 : loss : 0.030130, loss_ce: 0.007128
2021-12-13 01:17:53,686 iteration 5300 : loss : 0.025146, loss_ce: 0.010831
2021-12-13 01:17:55,129 iteration 5301 : loss : 0.026919, loss_ce: 0.006901
2021-12-13 01:17:56,660 iteration 5302 : loss : 0.035529, loss_ce: 0.014057
2021-12-13 01:17:58,167 iteration 5303 : loss : 0.025126, loss_ce: 0.012314
2021-12-13 01:17:59,629 iteration 5304 : loss : 0.029668, loss_ce: 0.014931
 78%|██████████████████████▌      | 312/400 [2:22:41<39:27, 26.90s/it]2021-12-13 01:18:01,063 iteration 5305 : loss : 0.015073, loss_ce: 0.006156
2021-12-13 01:18:02,573 iteration 5306 : loss : 0.029173, loss_ce: 0.012184
2021-12-13 01:18:04,065 iteration 5307 : loss : 0.028510, loss_ce: 0.010385
2021-12-13 01:18:05,521 iteration 5308 : loss : 0.022567, loss_ce: 0.007769
2021-12-13 01:18:07,006 iteration 5309 : loss : 0.024569, loss_ce: 0.012004
2021-12-13 01:18:08,589 iteration 5310 : loss : 0.023959, loss_ce: 0.008885
2021-12-13 01:18:10,055 iteration 5311 : loss : 0.030713, loss_ce: 0.010776
2021-12-13 01:18:11,613 iteration 5312 : loss : 0.037381, loss_ce: 0.016061
2021-12-13 01:18:13,062 iteration 5313 : loss : 0.028367, loss_ce: 0.014239
2021-12-13 01:18:14,529 iteration 5314 : loss : 0.025044, loss_ce: 0.008941
2021-12-13 01:18:15,965 iteration 5315 : loss : 0.030977, loss_ce: 0.010624
2021-12-13 01:18:17,420 iteration 5316 : loss : 0.025311, loss_ce: 0.008516
2021-12-13 01:18:18,862 iteration 5317 : loss : 0.026504, loss_ce: 0.009140
2021-12-13 01:18:20,384 iteration 5318 : loss : 0.032967, loss_ce: 0.013441
2021-12-13 01:18:21,839 iteration 5319 : loss : 0.036250, loss_ce: 0.013108
2021-12-13 01:18:23,260 iteration 5320 : loss : 0.028590, loss_ce: 0.010239
2021-12-13 01:18:24,690 iteration 5321 : loss : 0.030274, loss_ce: 0.012322
 78%|██████████████████████▋      | 313/400 [2:23:06<38:12, 26.35s/it]2021-12-13 01:18:26,135 iteration 5322 : loss : 0.023319, loss_ce: 0.009297
2021-12-13 01:18:27,648 iteration 5323 : loss : 0.034135, loss_ce: 0.010415
2021-12-13 01:18:29,092 iteration 5324 : loss : 0.028175, loss_ce: 0.010225
2021-12-13 01:18:30,615 iteration 5325 : loss : 0.028293, loss_ce: 0.011807
2021-12-13 01:18:32,126 iteration 5326 : loss : 0.029613, loss_ce: 0.011871
2021-12-13 01:18:33,612 iteration 5327 : loss : 0.031015, loss_ce: 0.013369
2021-12-13 01:18:35,110 iteration 5328 : loss : 0.023233, loss_ce: 0.008397
2021-12-13 01:18:36,612 iteration 5329 : loss : 0.026834, loss_ce: 0.013585
2021-12-13 01:18:38,135 iteration 5330 : loss : 0.025329, loss_ce: 0.008330
2021-12-13 01:18:39,547 iteration 5331 : loss : 0.030696, loss_ce: 0.010859
2021-12-13 01:18:40,975 iteration 5332 : loss : 0.026006, loss_ce: 0.010058
2021-12-13 01:18:42,433 iteration 5333 : loss : 0.029050, loss_ce: 0.009075
2021-12-13 01:18:43,874 iteration 5334 : loss : 0.027840, loss_ce: 0.009347
2021-12-13 01:18:45,438 iteration 5335 : loss : 0.040650, loss_ce: 0.014657
2021-12-13 01:18:46,920 iteration 5336 : loss : 0.038385, loss_ce: 0.012372
2021-12-13 01:18:48,390 iteration 5337 : loss : 0.024883, loss_ce: 0.009573
2021-12-13 01:18:49,780 iteration 5338 : loss : 0.023961, loss_ce: 0.008960
 78%|██████████████████████▊      | 314/400 [2:23:31<37:13, 25.97s/it]2021-12-13 01:18:51,275 iteration 5339 : loss : 0.037337, loss_ce: 0.012855
2021-12-13 01:18:52,747 iteration 5340 : loss : 0.024208, loss_ce: 0.014697
2021-12-13 01:18:54,241 iteration 5341 : loss : 0.027665, loss_ce: 0.011041
2021-12-13 01:18:55,760 iteration 5342 : loss : 0.034869, loss_ce: 0.010944
2021-12-13 01:18:57,197 iteration 5343 : loss : 0.049433, loss_ce: 0.017202
2021-12-13 01:18:58,639 iteration 5344 : loss : 0.025817, loss_ce: 0.012355
2021-12-13 01:19:00,048 iteration 5345 : loss : 0.025331, loss_ce: 0.007972
2021-12-13 01:19:01,494 iteration 5346 : loss : 0.032156, loss_ce: 0.011762
2021-12-13 01:19:03,050 iteration 5347 : loss : 0.029020, loss_ce: 0.012731
2021-12-13 01:19:04,547 iteration 5348 : loss : 0.028366, loss_ce: 0.011763
2021-12-13 01:19:06,018 iteration 5349 : loss : 0.024601, loss_ce: 0.011200
2021-12-13 01:19:07,423 iteration 5350 : loss : 0.021619, loss_ce: 0.007981
2021-12-13 01:19:08,935 iteration 5351 : loss : 0.039638, loss_ce: 0.008405
2021-12-13 01:19:10,411 iteration 5352 : loss : 0.024116, loss_ce: 0.009118
2021-12-13 01:19:11,943 iteration 5353 : loss : 0.029860, loss_ce: 0.013079
2021-12-13 01:19:13,364 iteration 5354 : loss : 0.027855, loss_ce: 0.010430
2021-12-13 01:19:13,364 Training Data Eval:
2021-12-13 01:19:20,896   Average segmentation loss on training set: 0.0153
2021-12-13 01:19:20,897 Validation Data Eval:
2021-12-13 01:19:23,493   Average segmentation loss on validation set: 0.0783
2021-12-13 01:19:24,897 iteration 5355 : loss : 0.025625, loss_ce: 0.010230
 79%|██████████████████████▊      | 315/400 [2:24:06<40:40, 28.72s/it]2021-12-13 01:19:26,462 iteration 5356 : loss : 0.033849, loss_ce: 0.013538
2021-12-13 01:19:27,847 iteration 5357 : loss : 0.020237, loss_ce: 0.006514
2021-12-13 01:19:29,308 iteration 5358 : loss : 0.022103, loss_ce: 0.006474
2021-12-13 01:19:30,743 iteration 5359 : loss : 0.028779, loss_ce: 0.015973
2021-12-13 01:19:32,197 iteration 5360 : loss : 0.025040, loss_ce: 0.009101
2021-12-13 01:19:33,722 iteration 5361 : loss : 0.029453, loss_ce: 0.008887
2021-12-13 01:19:35,237 iteration 5362 : loss : 0.034322, loss_ce: 0.021312
2021-12-13 01:19:36,711 iteration 5363 : loss : 0.024491, loss_ce: 0.010041
2021-12-13 01:19:38,089 iteration 5364 : loss : 0.028687, loss_ce: 0.005384
2021-12-13 01:19:39,602 iteration 5365 : loss : 0.028881, loss_ce: 0.009878
2021-12-13 01:19:41,002 iteration 5366 : loss : 0.038364, loss_ce: 0.012838
2021-12-13 01:19:42,494 iteration 5367 : loss : 0.032190, loss_ce: 0.008643
2021-12-13 01:19:44,066 iteration 5368 : loss : 0.028886, loss_ce: 0.010673
2021-12-13 01:19:45,550 iteration 5369 : loss : 0.029641, loss_ce: 0.011811
2021-12-13 01:19:47,038 iteration 5370 : loss : 0.037469, loss_ce: 0.013140
2021-12-13 01:19:48,583 iteration 5371 : loss : 0.027074, loss_ce: 0.007776
2021-12-13 01:19:50,042 iteration 5372 : loss : 0.029499, loss_ce: 0.012347
 79%|██████████████████████▉      | 316/400 [2:24:32<38:42, 27.65s/it]2021-12-13 01:19:51,471 iteration 5373 : loss : 0.022331, loss_ce: 0.010180
2021-12-13 01:19:52,958 iteration 5374 : loss : 0.048136, loss_ce: 0.013880
2021-12-13 01:19:54,384 iteration 5375 : loss : 0.024973, loss_ce: 0.008848
2021-12-13 01:19:55,790 iteration 5376 : loss : 0.022214, loss_ce: 0.008051
2021-12-13 01:19:57,147 iteration 5377 : loss : 0.035444, loss_ce: 0.006289
2021-12-13 01:19:58,505 iteration 5378 : loss : 0.022791, loss_ce: 0.008818
2021-12-13 01:19:59,986 iteration 5379 : loss : 0.031848, loss_ce: 0.010259
2021-12-13 01:20:01,414 iteration 5380 : loss : 0.021308, loss_ce: 0.009442
2021-12-13 01:20:02,881 iteration 5381 : loss : 0.030403, loss_ce: 0.012281
2021-12-13 01:20:04,387 iteration 5382 : loss : 0.029053, loss_ce: 0.009425
2021-12-13 01:20:05,903 iteration 5383 : loss : 0.027253, loss_ce: 0.011341
2021-12-13 01:20:07,359 iteration 5384 : loss : 0.024690, loss_ce: 0.011896
2021-12-13 01:20:08,821 iteration 5385 : loss : 0.031355, loss_ce: 0.014490
2021-12-13 01:20:10,353 iteration 5386 : loss : 0.025171, loss_ce: 0.009861
2021-12-13 01:20:11,829 iteration 5387 : loss : 0.029631, loss_ce: 0.012868
2021-12-13 01:20:13,212 iteration 5388 : loss : 0.023477, loss_ce: 0.009319
2021-12-13 01:20:14,655 iteration 5389 : loss : 0.028682, loss_ce: 0.010862
 79%|██████████████████████▉      | 317/400 [2:24:56<36:58, 26.73s/it]2021-12-13 01:20:16,248 iteration 5390 : loss : 0.034102, loss_ce: 0.010213
2021-12-13 01:20:17,618 iteration 5391 : loss : 0.024171, loss_ce: 0.008400
2021-12-13 01:20:19,115 iteration 5392 : loss : 0.033708, loss_ce: 0.014199
2021-12-13 01:20:20,619 iteration 5393 : loss : 0.044668, loss_ce: 0.015055
2021-12-13 01:20:22,078 iteration 5394 : loss : 0.021922, loss_ce: 0.009358
2021-12-13 01:20:23,482 iteration 5395 : loss : 0.023794, loss_ce: 0.011181
2021-12-13 01:20:24,996 iteration 5396 : loss : 0.034556, loss_ce: 0.009702
2021-12-13 01:20:26,480 iteration 5397 : loss : 0.032711, loss_ce: 0.012279
2021-12-13 01:20:27,841 iteration 5398 : loss : 0.021575, loss_ce: 0.010783
2021-12-13 01:20:29,275 iteration 5399 : loss : 0.025315, loss_ce: 0.011338
2021-12-13 01:20:30,816 iteration 5400 : loss : 0.041585, loss_ce: 0.015069
2021-12-13 01:20:32,329 iteration 5401 : loss : 0.029751, loss_ce: 0.009999
2021-12-13 01:20:33,785 iteration 5402 : loss : 0.027599, loss_ce: 0.010358
2021-12-13 01:20:35,289 iteration 5403 : loss : 0.034343, loss_ce: 0.010374
2021-12-13 01:20:36,718 iteration 5404 : loss : 0.024507, loss_ce: 0.011748
2021-12-13 01:20:38,122 iteration 5405 : loss : 0.020547, loss_ce: 0.007964
2021-12-13 01:20:39,488 iteration 5406 : loss : 0.026792, loss_ce: 0.007127
 80%|███████████████████████      | 318/400 [2:25:21<35:45, 26.17s/it]2021-12-13 01:20:41,060 iteration 5407 : loss : 0.030525, loss_ce: 0.009308
2021-12-13 01:20:42,517 iteration 5408 : loss : 0.032097, loss_ce: 0.009716
2021-12-13 01:20:43,926 iteration 5409 : loss : 0.020803, loss_ce: 0.009894
2021-12-13 01:20:45,352 iteration 5410 : loss : 0.031343, loss_ce: 0.009924
2021-12-13 01:20:46,844 iteration 5411 : loss : 0.032084, loss_ce: 0.010908
2021-12-13 01:20:48,351 iteration 5412 : loss : 0.031018, loss_ce: 0.014123
2021-12-13 01:20:49,761 iteration 5413 : loss : 0.025847, loss_ce: 0.010208
2021-12-13 01:20:51,274 iteration 5414 : loss : 0.033877, loss_ce: 0.012983
2021-12-13 01:20:52,730 iteration 5415 : loss : 0.028003, loss_ce: 0.009839
2021-12-13 01:20:54,246 iteration 5416 : loss : 0.030465, loss_ce: 0.013149
2021-12-13 01:20:55,677 iteration 5417 : loss : 0.037207, loss_ce: 0.014101
2021-12-13 01:20:57,128 iteration 5418 : loss : 0.029599, loss_ce: 0.009822
2021-12-13 01:20:58,578 iteration 5419 : loss : 0.024939, loss_ce: 0.011247
2021-12-13 01:21:00,049 iteration 5420 : loss : 0.024848, loss_ce: 0.011223
2021-12-13 01:21:01,543 iteration 5421 : loss : 0.035077, loss_ce: 0.010696
2021-12-13 01:21:03,020 iteration 5422 : loss : 0.029913, loss_ce: 0.010845
2021-12-13 01:21:04,544 iteration 5423 : loss : 0.039904, loss_ce: 0.013230
 80%|███████████████████████▏     | 319/400 [2:25:46<34:52, 25.83s/it]2021-12-13 01:21:06,080 iteration 5424 : loss : 0.032504, loss_ce: 0.013690
2021-12-13 01:21:07,566 iteration 5425 : loss : 0.033504, loss_ce: 0.013826
2021-12-13 01:21:09,065 iteration 5426 : loss : 0.026481, loss_ce: 0.008371
2021-12-13 01:21:10,663 iteration 5427 : loss : 0.034418, loss_ce: 0.011415
2021-12-13 01:21:12,200 iteration 5428 : loss : 0.052490, loss_ce: 0.021536
2021-12-13 01:21:13,627 iteration 5429 : loss : 0.026572, loss_ce: 0.011135
2021-12-13 01:21:15,007 iteration 5430 : loss : 0.022680, loss_ce: 0.010198
2021-12-13 01:21:16,534 iteration 5431 : loss : 0.031644, loss_ce: 0.011164
2021-12-13 01:21:17,966 iteration 5432 : loss : 0.030042, loss_ce: 0.010661
2021-12-13 01:21:19,551 iteration 5433 : loss : 0.044884, loss_ce: 0.016828
2021-12-13 01:21:21,106 iteration 5434 : loss : 0.032806, loss_ce: 0.012727
2021-12-13 01:21:22,612 iteration 5435 : loss : 0.027915, loss_ce: 0.012440
2021-12-13 01:21:24,128 iteration 5436 : loss : 0.035900, loss_ce: 0.016233
2021-12-13 01:21:25,563 iteration 5437 : loss : 0.033043, loss_ce: 0.007958
2021-12-13 01:21:27,037 iteration 5438 : loss : 0.028134, loss_ce: 0.012443
2021-12-13 01:21:28,537 iteration 5439 : loss : 0.036724, loss_ce: 0.012554
2021-12-13 01:21:28,538 Training Data Eval:
2021-12-13 01:21:36,072   Average segmentation loss on training set: 0.0155
2021-12-13 01:21:36,073 Validation Data Eval:
2021-12-13 01:21:38,679   Average segmentation loss on validation set: 0.0831
2021-12-13 01:21:40,152 iteration 5440 : loss : 0.027776, loss_ce: 0.010495
 80%|███████████████████████▏     | 320/400 [2:26:22<38:21, 28.77s/it]2021-12-13 01:21:41,597 iteration 5441 : loss : 0.027823, loss_ce: 0.011629
2021-12-13 01:21:43,186 iteration 5442 : loss : 0.038379, loss_ce: 0.013744
2021-12-13 01:21:44,693 iteration 5443 : loss : 0.030535, loss_ce: 0.011146
2021-12-13 01:21:46,147 iteration 5444 : loss : 0.027901, loss_ce: 0.014028
2021-12-13 01:21:47,592 iteration 5445 : loss : 0.026610, loss_ce: 0.011221
2021-12-13 01:21:49,058 iteration 5446 : loss : 0.033163, loss_ce: 0.012772
2021-12-13 01:21:50,452 iteration 5447 : loss : 0.030438, loss_ce: 0.006335
2021-12-13 01:21:51,943 iteration 5448 : loss : 0.030671, loss_ce: 0.010884
2021-12-13 01:21:53,393 iteration 5449 : loss : 0.028838, loss_ce: 0.008019
2021-12-13 01:21:54,828 iteration 5450 : loss : 0.026707, loss_ce: 0.008938
2021-12-13 01:21:56,305 iteration 5451 : loss : 0.022657, loss_ce: 0.007052
2021-12-13 01:21:57,785 iteration 5452 : loss : 0.020959, loss_ce: 0.008661
2021-12-13 01:21:59,295 iteration 5453 : loss : 0.028293, loss_ce: 0.010801
2021-12-13 01:22:00,780 iteration 5454 : loss : 0.036845, loss_ce: 0.015805
2021-12-13 01:22:02,256 iteration 5455 : loss : 0.026349, loss_ce: 0.013045
2021-12-13 01:22:03,753 iteration 5456 : loss : 0.030624, loss_ce: 0.009396
2021-12-13 01:22:05,241 iteration 5457 : loss : 0.027173, loss_ce: 0.010262
 80%|███████████████████████▎     | 321/400 [2:26:47<36:25, 27.66s/it]2021-12-13 01:22:06,825 iteration 5458 : loss : 0.028742, loss_ce: 0.009632
2021-12-13 01:22:08,248 iteration 5459 : loss : 0.024090, loss_ce: 0.009637
2021-12-13 01:22:09,722 iteration 5460 : loss : 0.035419, loss_ce: 0.015214
2021-12-13 01:22:11,217 iteration 5461 : loss : 0.029844, loss_ce: 0.012508
2021-12-13 01:22:12,728 iteration 5462 : loss : 0.028770, loss_ce: 0.011505
2021-12-13 01:22:14,163 iteration 5463 : loss : 0.022857, loss_ce: 0.007470
2021-12-13 01:22:15,768 iteration 5464 : loss : 0.035574, loss_ce: 0.013046
2021-12-13 01:22:17,202 iteration 5465 : loss : 0.026378, loss_ce: 0.009906
2021-12-13 01:22:18,638 iteration 5466 : loss : 0.022910, loss_ce: 0.008814
2021-12-13 01:22:20,174 iteration 5467 : loss : 0.025993, loss_ce: 0.008426
2021-12-13 01:22:21,699 iteration 5468 : loss : 0.027783, loss_ce: 0.011917
2021-12-13 01:22:23,242 iteration 5469 : loss : 0.035167, loss_ce: 0.013541
2021-12-13 01:22:24,690 iteration 5470 : loss : 0.026441, loss_ce: 0.011742
2021-12-13 01:22:26,131 iteration 5471 : loss : 0.026603, loss_ce: 0.012402
2021-12-13 01:22:27,668 iteration 5472 : loss : 0.035572, loss_ce: 0.015651
2021-12-13 01:22:29,135 iteration 5473 : loss : 0.026357, loss_ce: 0.007703
2021-12-13 01:22:30,660 iteration 5474 : loss : 0.025208, loss_ce: 0.008144
 80%|███████████████████████▎     | 322/400 [2:27:12<35:05, 26.99s/it]2021-12-13 01:22:32,134 iteration 5475 : loss : 0.027009, loss_ce: 0.010717
2021-12-13 01:22:33,587 iteration 5476 : loss : 0.024347, loss_ce: 0.011231
2021-12-13 01:22:35,113 iteration 5477 : loss : 0.026503, loss_ce: 0.010699
2021-12-13 01:22:36,640 iteration 5478 : loss : 0.035701, loss_ce: 0.016469
2021-12-13 01:22:38,080 iteration 5479 : loss : 0.040303, loss_ce: 0.012146
2021-12-13 01:22:39,549 iteration 5480 : loss : 0.036071, loss_ce: 0.009765
2021-12-13 01:22:41,036 iteration 5481 : loss : 0.032651, loss_ce: 0.013378
2021-12-13 01:22:42,510 iteration 5482 : loss : 0.032085, loss_ce: 0.012340
2021-12-13 01:22:43,926 iteration 5483 : loss : 0.028585, loss_ce: 0.010376
2021-12-13 01:22:45,456 iteration 5484 : loss : 0.031985, loss_ce: 0.013187
2021-12-13 01:22:46,860 iteration 5485 : loss : 0.023477, loss_ce: 0.011461
2021-12-13 01:22:48,444 iteration 5486 : loss : 0.030333, loss_ce: 0.008574
2021-12-13 01:22:49,861 iteration 5487 : loss : 0.024539, loss_ce: 0.013022
2021-12-13 01:22:51,372 iteration 5488 : loss : 0.037408, loss_ce: 0.011150
2021-12-13 01:22:52,789 iteration 5489 : loss : 0.026303, loss_ce: 0.007450
2021-12-13 01:22:54,294 iteration 5490 : loss : 0.030612, loss_ce: 0.012646
2021-12-13 01:22:55,725 iteration 5491 : loss : 0.022418, loss_ce: 0.008856
 81%|███████████████████████▍     | 323/400 [2:27:37<33:53, 26.41s/it]2021-12-13 01:22:57,275 iteration 5492 : loss : 0.034577, loss_ce: 0.016087
2021-12-13 01:22:58,682 iteration 5493 : loss : 0.023026, loss_ce: 0.007880
2021-12-13 01:23:00,123 iteration 5494 : loss : 0.030296, loss_ce: 0.013386
2021-12-13 01:23:01,657 iteration 5495 : loss : 0.047095, loss_ce: 0.009185
2021-12-13 01:23:03,074 iteration 5496 : loss : 0.026756, loss_ce: 0.009180
2021-12-13 01:23:04,549 iteration 5497 : loss : 0.026479, loss_ce: 0.011916
2021-12-13 01:23:06,069 iteration 5498 : loss : 0.029026, loss_ce: 0.012856
2021-12-13 01:23:07,541 iteration 5499 : loss : 0.032874, loss_ce: 0.011605
2021-12-13 01:23:09,012 iteration 5500 : loss : 0.021457, loss_ce: 0.007678
2021-12-13 01:23:10,450 iteration 5501 : loss : 0.020203, loss_ce: 0.007713
2021-12-13 01:23:11,888 iteration 5502 : loss : 0.026017, loss_ce: 0.013384
2021-12-13 01:23:13,500 iteration 5503 : loss : 0.037350, loss_ce: 0.012227
2021-12-13 01:23:14,989 iteration 5504 : loss : 0.031487, loss_ce: 0.013269
2021-12-13 01:23:16,387 iteration 5505 : loss : 0.021203, loss_ce: 0.008164
2021-12-13 01:23:17,816 iteration 5506 : loss : 0.023680, loss_ce: 0.009232
2021-12-13 01:23:19,383 iteration 5507 : loss : 0.028459, loss_ce: 0.010751
2021-12-13 01:23:20,890 iteration 5508 : loss : 0.028790, loss_ce: 0.013079
 81%|███████████████████████▍     | 324/400 [2:28:02<32:58, 26.04s/it]2021-12-13 01:23:22,437 iteration 5509 : loss : 0.035307, loss_ce: 0.016114
2021-12-13 01:23:23,884 iteration 5510 : loss : 0.031533, loss_ce: 0.011833
2021-12-13 01:23:25,388 iteration 5511 : loss : 0.036825, loss_ce: 0.012403
2021-12-13 01:23:26,845 iteration 5512 : loss : 0.024651, loss_ce: 0.010416
2021-12-13 01:23:28,307 iteration 5513 : loss : 0.022909, loss_ce: 0.011659
2021-12-13 01:23:29,834 iteration 5514 : loss : 0.042582, loss_ce: 0.018961
2021-12-13 01:23:31,297 iteration 5515 : loss : 0.023202, loss_ce: 0.008742
2021-12-13 01:23:32,758 iteration 5516 : loss : 0.026385, loss_ce: 0.012816
2021-12-13 01:23:34,255 iteration 5517 : loss : 0.032123, loss_ce: 0.010513
2021-12-13 01:23:35,651 iteration 5518 : loss : 0.022167, loss_ce: 0.008062
2021-12-13 01:23:37,198 iteration 5519 : loss : 0.044712, loss_ce: 0.013901
2021-12-13 01:23:38,660 iteration 5520 : loss : 0.024863, loss_ce: 0.005891
2021-12-13 01:23:40,224 iteration 5521 : loss : 0.026724, loss_ce: 0.010523
2021-12-13 01:23:41,691 iteration 5522 : loss : 0.027002, loss_ce: 0.010067
2021-12-13 01:23:43,211 iteration 5523 : loss : 0.039164, loss_ce: 0.014276
2021-12-13 01:23:44,747 iteration 5524 : loss : 0.035322, loss_ce: 0.011889
2021-12-13 01:23:44,747 Training Data Eval:
2021-12-13 01:23:52,273   Average segmentation loss on training set: 0.0154
2021-12-13 01:23:52,273 Validation Data Eval:
2021-12-13 01:23:54,868   Average segmentation loss on validation set: 0.0774
2021-12-13 01:23:56,430 iteration 5525 : loss : 0.032894, loss_ce: 0.013614
 81%|███████████████████████▌     | 325/400 [2:28:38<36:06, 28.89s/it]2021-12-13 01:23:57,935 iteration 5526 : loss : 0.037526, loss_ce: 0.012594
2021-12-13 01:23:59,338 iteration 5527 : loss : 0.021353, loss_ce: 0.008378
2021-12-13 01:24:00,876 iteration 5528 : loss : 0.042828, loss_ce: 0.012959
2021-12-13 01:24:02,317 iteration 5529 : loss : 0.027892, loss_ce: 0.011151
2021-12-13 01:24:03,735 iteration 5530 : loss : 0.025888, loss_ce: 0.011019
2021-12-13 01:24:05,112 iteration 5531 : loss : 0.020261, loss_ce: 0.007107
2021-12-13 01:24:06,517 iteration 5532 : loss : 0.025404, loss_ce: 0.009483
2021-12-13 01:24:08,017 iteration 5533 : loss : 0.026718, loss_ce: 0.012894
2021-12-13 01:24:09,411 iteration 5534 : loss : 0.019782, loss_ce: 0.007392
2021-12-13 01:24:10,845 iteration 5535 : loss : 0.025544, loss_ce: 0.012298
2021-12-13 01:24:12,358 iteration 5536 : loss : 0.025790, loss_ce: 0.008280
2021-12-13 01:24:13,865 iteration 5537 : loss : 0.029292, loss_ce: 0.012906
2021-12-13 01:24:15,424 iteration 5538 : loss : 0.036942, loss_ce: 0.010781
2021-12-13 01:24:16,901 iteration 5539 : loss : 0.026110, loss_ce: 0.009382
2021-12-13 01:24:18,304 iteration 5540 : loss : 0.027767, loss_ce: 0.011411
2021-12-13 01:24:19,884 iteration 5541 : loss : 0.036769, loss_ce: 0.014729
2021-12-13 01:24:21,369 iteration 5542 : loss : 0.033104, loss_ce: 0.014583
 82%|███████████████████████▋     | 326/400 [2:29:03<34:10, 27.70s/it]2021-12-13 01:24:22,932 iteration 5543 : loss : 0.031484, loss_ce: 0.014702
2021-12-13 01:24:24,370 iteration 5544 : loss : 0.021191, loss_ce: 0.007884
2021-12-13 01:24:25,879 iteration 5545 : loss : 0.030993, loss_ce: 0.013247
2021-12-13 01:24:27,441 iteration 5546 : loss : 0.061191, loss_ce: 0.015461
2021-12-13 01:24:28,959 iteration 5547 : loss : 0.027241, loss_ce: 0.011651
2021-12-13 01:24:30,409 iteration 5548 : loss : 0.023516, loss_ce: 0.006624
2021-12-13 01:24:31,856 iteration 5549 : loss : 0.024285, loss_ce: 0.007180
2021-12-13 01:24:33,347 iteration 5550 : loss : 0.031302, loss_ce: 0.010793
2021-12-13 01:24:34,789 iteration 5551 : loss : 0.032576, loss_ce: 0.014864
2021-12-13 01:24:36,142 iteration 5552 : loss : 0.021248, loss_ce: 0.007068
2021-12-13 01:24:37,624 iteration 5553 : loss : 0.024798, loss_ce: 0.010583
2021-12-13 01:24:39,075 iteration 5554 : loss : 0.028663, loss_ce: 0.011677
2021-12-13 01:24:40,461 iteration 5555 : loss : 0.023053, loss_ce: 0.010093
2021-12-13 01:24:41,983 iteration 5556 : loss : 0.034198, loss_ce: 0.014233
2021-12-13 01:24:43,482 iteration 5557 : loss : 0.022626, loss_ce: 0.010004
2021-12-13 01:24:44,955 iteration 5558 : loss : 0.034475, loss_ce: 0.011583
2021-12-13 01:24:46,416 iteration 5559 : loss : 0.027588, loss_ce: 0.009070
 82%|███████████████████████▋     | 327/400 [2:29:28<32:44, 26.91s/it]2021-12-13 01:24:47,942 iteration 5560 : loss : 0.030463, loss_ce: 0.011016
2021-12-13 01:24:49,383 iteration 5561 : loss : 0.032398, loss_ce: 0.011874
2021-12-13 01:24:50,838 iteration 5562 : loss : 0.028280, loss_ce: 0.011999
2021-12-13 01:24:52,287 iteration 5563 : loss : 0.028992, loss_ce: 0.011984
2021-12-13 01:24:53,808 iteration 5564 : loss : 0.027390, loss_ce: 0.011444
2021-12-13 01:24:55,317 iteration 5565 : loss : 0.029693, loss_ce: 0.014257
2021-12-13 01:24:56,798 iteration 5566 : loss : 0.023687, loss_ce: 0.010876
2021-12-13 01:24:58,304 iteration 5567 : loss : 0.028230, loss_ce: 0.014083
2021-12-13 01:24:59,770 iteration 5568 : loss : 0.035213, loss_ce: 0.012082
2021-12-13 01:25:01,243 iteration 5569 : loss : 0.034081, loss_ce: 0.011921
2021-12-13 01:25:02,664 iteration 5570 : loss : 0.022508, loss_ce: 0.006618
2021-12-13 01:25:04,026 iteration 5571 : loss : 0.019469, loss_ce: 0.007597
2021-12-13 01:25:05,445 iteration 5572 : loss : 0.030096, loss_ce: 0.010650
2021-12-13 01:25:06,836 iteration 5573 : loss : 0.019066, loss_ce: 0.006266
2021-12-13 01:25:08,293 iteration 5574 : loss : 0.025345, loss_ce: 0.008591
2021-12-13 01:25:09,866 iteration 5575 : loss : 0.041252, loss_ce: 0.013786
2021-12-13 01:25:11,359 iteration 5576 : loss : 0.030000, loss_ce: 0.011553
 82%|███████████████████████▊     | 328/400 [2:29:53<31:34, 26.32s/it]2021-12-13 01:25:12,881 iteration 5577 : loss : 0.027345, loss_ce: 0.011446
2021-12-13 01:25:14,391 iteration 5578 : loss : 0.031324, loss_ce: 0.011862
2021-12-13 01:25:15,942 iteration 5579 : loss : 0.032430, loss_ce: 0.014768
2021-12-13 01:25:17,388 iteration 5580 : loss : 0.040282, loss_ce: 0.017222
2021-12-13 01:25:18,807 iteration 5581 : loss : 0.022820, loss_ce: 0.009111
2021-12-13 01:25:20,284 iteration 5582 : loss : 0.022246, loss_ce: 0.006939
2021-12-13 01:25:21,745 iteration 5583 : loss : 0.020089, loss_ce: 0.007963
2021-12-13 01:25:23,260 iteration 5584 : loss : 0.028015, loss_ce: 0.012281
2021-12-13 01:25:24,709 iteration 5585 : loss : 0.028113, loss_ce: 0.008578
2021-12-13 01:25:26,241 iteration 5586 : loss : 0.040957, loss_ce: 0.014543
2021-12-13 01:25:27,653 iteration 5587 : loss : 0.027961, loss_ce: 0.010066
2021-12-13 01:25:29,100 iteration 5588 : loss : 0.026264, loss_ce: 0.010489
2021-12-13 01:25:30,502 iteration 5589 : loss : 0.020864, loss_ce: 0.006616
2021-12-13 01:25:31,938 iteration 5590 : loss : 0.021992, loss_ce: 0.006695
2021-12-13 01:25:33,375 iteration 5591 : loss : 0.023502, loss_ce: 0.009542
2021-12-13 01:25:34,908 iteration 5592 : loss : 0.028877, loss_ce: 0.010000
2021-12-13 01:25:36,406 iteration 5593 : loss : 0.030240, loss_ce: 0.012496
 82%|███████████████████████▊     | 329/400 [2:30:18<30:41, 25.94s/it]2021-12-13 01:25:37,884 iteration 5594 : loss : 0.030710, loss_ce: 0.009801
2021-12-13 01:25:39,390 iteration 5595 : loss : 0.031457, loss_ce: 0.013501
2021-12-13 01:25:40,835 iteration 5596 : loss : 0.022801, loss_ce: 0.009082
2021-12-13 01:25:42,361 iteration 5597 : loss : 0.023499, loss_ce: 0.009281
2021-12-13 01:25:43,773 iteration 5598 : loss : 0.020309, loss_ce: 0.008847
2021-12-13 01:25:45,232 iteration 5599 : loss : 0.031446, loss_ce: 0.013318
2021-12-13 01:25:46,687 iteration 5600 : loss : 0.023004, loss_ce: 0.009468
2021-12-13 01:25:48,121 iteration 5601 : loss : 0.018970, loss_ce: 0.008246
2021-12-13 01:25:49,602 iteration 5602 : loss : 0.051466, loss_ce: 0.021355
2021-12-13 01:25:51,014 iteration 5603 : loss : 0.020927, loss_ce: 0.008815
2021-12-13 01:25:52,505 iteration 5604 : loss : 0.028135, loss_ce: 0.007016
2021-12-13 01:25:54,024 iteration 5605 : loss : 0.033431, loss_ce: 0.013422
2021-12-13 01:25:55,506 iteration 5606 : loss : 0.034447, loss_ce: 0.010568
2021-12-13 01:25:56,972 iteration 5607 : loss : 0.028196, loss_ce: 0.009264
2021-12-13 01:25:58,435 iteration 5608 : loss : 0.024620, loss_ce: 0.008757
2021-12-13 01:25:59,960 iteration 5609 : loss : 0.025674, loss_ce: 0.011284
2021-12-13 01:25:59,961 Training Data Eval:
2021-12-13 01:26:07,489   Average segmentation loss on training set: 0.0161
2021-12-13 01:26:07,490 Validation Data Eval:
2021-12-13 01:26:10,087   Average segmentation loss on validation set: 0.0796
2021-12-13 01:26:11,507 iteration 5610 : loss : 0.023308, loss_ce: 0.008558
 82%|███████████████████████▉     | 330/400 [2:30:53<33:27, 28.68s/it]2021-12-13 01:26:12,997 iteration 5611 : loss : 0.030812, loss_ce: 0.010845
2021-12-13 01:26:14,480 iteration 5612 : loss : 0.043686, loss_ce: 0.011131
2021-12-13 01:26:15,964 iteration 5613 : loss : 0.025061, loss_ce: 0.010082
2021-12-13 01:26:17,425 iteration 5614 : loss : 0.029634, loss_ce: 0.011288
2021-12-13 01:26:18,810 iteration 5615 : loss : 0.017048, loss_ce: 0.007805
2021-12-13 01:26:20,305 iteration 5616 : loss : 0.025455, loss_ce: 0.011519
2021-12-13 01:26:21,832 iteration 5617 : loss : 0.022917, loss_ce: 0.009437
2021-12-13 01:26:23,324 iteration 5618 : loss : 0.026810, loss_ce: 0.011182
2021-12-13 01:26:24,763 iteration 5619 : loss : 0.027717, loss_ce: 0.008724
2021-12-13 01:26:26,292 iteration 5620 : loss : 0.027275, loss_ce: 0.011365
2021-12-13 01:26:27,689 iteration 5621 : loss : 0.027911, loss_ce: 0.009631
2021-12-13 01:26:29,160 iteration 5622 : loss : 0.025708, loss_ce: 0.010258
2021-12-13 01:26:30,712 iteration 5623 : loss : 0.037117, loss_ce: 0.013142
2021-12-13 01:26:32,126 iteration 5624 : loss : 0.030447, loss_ce: 0.008878
2021-12-13 01:26:33,529 iteration 5625 : loss : 0.026347, loss_ce: 0.011944
2021-12-13 01:26:34,967 iteration 5626 : loss : 0.030099, loss_ce: 0.008599
2021-12-13 01:26:36,460 iteration 5627 : loss : 0.027318, loss_ce: 0.011249
 83%|███████████████████████▉     | 331/400 [2:31:18<31:42, 27.57s/it]2021-12-13 01:26:38,090 iteration 5628 : loss : 0.036422, loss_ce: 0.017075
2021-12-13 01:26:39,515 iteration 5629 : loss : 0.025228, loss_ce: 0.010937
2021-12-13 01:26:41,013 iteration 5630 : loss : 0.036859, loss_ce: 0.015572
2021-12-13 01:26:42,478 iteration 5631 : loss : 0.030013, loss_ce: 0.010272
2021-12-13 01:26:43,994 iteration 5632 : loss : 0.036608, loss_ce: 0.017828
2021-12-13 01:26:45,528 iteration 5633 : loss : 0.034091, loss_ce: 0.013864
2021-12-13 01:26:47,015 iteration 5634 : loss : 0.022968, loss_ce: 0.009456
2021-12-13 01:26:48,472 iteration 5635 : loss : 0.028081, loss_ce: 0.010130
2021-12-13 01:26:49,954 iteration 5636 : loss : 0.026407, loss_ce: 0.006951
2021-12-13 01:26:51,412 iteration 5637 : loss : 0.029197, loss_ce: 0.009045
2021-12-13 01:26:52,887 iteration 5638 : loss : 0.028860, loss_ce: 0.011730
2021-12-13 01:26:54,378 iteration 5639 : loss : 0.022606, loss_ce: 0.008239
2021-12-13 01:26:55,870 iteration 5640 : loss : 0.034180, loss_ce: 0.014699
2021-12-13 01:26:57,273 iteration 5641 : loss : 0.030250, loss_ce: 0.009013
2021-12-13 01:26:58,692 iteration 5642 : loss : 0.024108, loss_ce: 0.009473
2021-12-13 01:27:00,158 iteration 5643 : loss : 0.024549, loss_ce: 0.008675
2021-12-13 01:27:01,598 iteration 5644 : loss : 0.027088, loss_ce: 0.010934
 83%|████████████████████████     | 332/400 [2:31:43<30:25, 26.84s/it]2021-12-13 01:27:03,076 iteration 5645 : loss : 0.029962, loss_ce: 0.008977
2021-12-13 01:27:04,538 iteration 5646 : loss : 0.023879, loss_ce: 0.007749
2021-12-13 01:27:06,060 iteration 5647 : loss : 0.033721, loss_ce: 0.011687
2021-12-13 01:27:07,539 iteration 5648 : loss : 0.032212, loss_ce: 0.009986
2021-12-13 01:27:09,002 iteration 5649 : loss : 0.022082, loss_ce: 0.007910
2021-12-13 01:27:10,518 iteration 5650 : loss : 0.034135, loss_ce: 0.009871
2021-12-13 01:27:11,974 iteration 5651 : loss : 0.023455, loss_ce: 0.010969
2021-12-13 01:27:13,407 iteration 5652 : loss : 0.024226, loss_ce: 0.010308
2021-12-13 01:27:14,853 iteration 5653 : loss : 0.027398, loss_ce: 0.010588
2021-12-13 01:27:16,395 iteration 5654 : loss : 0.027867, loss_ce: 0.011304
2021-12-13 01:27:17,850 iteration 5655 : loss : 0.028469, loss_ce: 0.010850
2021-12-13 01:27:19,343 iteration 5656 : loss : 0.034009, loss_ce: 0.014565
2021-12-13 01:27:20,792 iteration 5657 : loss : 0.031116, loss_ce: 0.016119
2021-12-13 01:27:22,327 iteration 5658 : loss : 0.034636, loss_ce: 0.011419
2021-12-13 01:27:23,886 iteration 5659 : loss : 0.026410, loss_ce: 0.011687
2021-12-13 01:27:25,268 iteration 5660 : loss : 0.019037, loss_ce: 0.007788
2021-12-13 01:27:26,766 iteration 5661 : loss : 0.039288, loss_ce: 0.014171
 83%|████████████████████████▏    | 333/400 [2:32:08<29:24, 26.34s/it]2021-12-13 01:27:28,244 iteration 5662 : loss : 0.024876, loss_ce: 0.010352
2021-12-13 01:27:29,757 iteration 5663 : loss : 0.025710, loss_ce: 0.011195
2021-12-13 01:27:31,284 iteration 5664 : loss : 0.040318, loss_ce: 0.014034
2021-12-13 01:27:32,733 iteration 5665 : loss : 0.021982, loss_ce: 0.006153
2021-12-13 01:27:34,288 iteration 5666 : loss : 0.025530, loss_ce: 0.009659
2021-12-13 01:27:35,782 iteration 5667 : loss : 0.027315, loss_ce: 0.008920
2021-12-13 01:27:37,276 iteration 5668 : loss : 0.036865, loss_ce: 0.012638
2021-12-13 01:27:38,826 iteration 5669 : loss : 0.028113, loss_ce: 0.014597
2021-12-13 01:27:40,321 iteration 5670 : loss : 0.029417, loss_ce: 0.010910
2021-12-13 01:27:41,856 iteration 5671 : loss : 0.036425, loss_ce: 0.009945
2021-12-13 01:27:43,241 iteration 5672 : loss : 0.026799, loss_ce: 0.008586
2021-12-13 01:27:44,697 iteration 5673 : loss : 0.026283, loss_ce: 0.011653
2021-12-13 01:27:46,112 iteration 5674 : loss : 0.030703, loss_ce: 0.010650
2021-12-13 01:27:47,694 iteration 5675 : loss : 0.034384, loss_ce: 0.012634
2021-12-13 01:27:49,162 iteration 5676 : loss : 0.029612, loss_ce: 0.015855
2021-12-13 01:27:50,599 iteration 5677 : loss : 0.029221, loss_ce: 0.011192
2021-12-13 01:27:52,054 iteration 5678 : loss : 0.042936, loss_ce: 0.019143
 84%|████████████████████████▏    | 334/400 [2:32:34<28:37, 26.02s/it]2021-12-13 01:27:53,582 iteration 5679 : loss : 0.028692, loss_ce: 0.009861
2021-12-13 01:27:55,042 iteration 5680 : loss : 0.026769, loss_ce: 0.011868
2021-12-13 01:27:56,542 iteration 5681 : loss : 0.032088, loss_ce: 0.009697
2021-12-13 01:27:57,935 iteration 5682 : loss : 0.023239, loss_ce: 0.008802
2021-12-13 01:27:59,318 iteration 5683 : loss : 0.019318, loss_ce: 0.008780
2021-12-13 01:28:00,846 iteration 5684 : loss : 0.027929, loss_ce: 0.015584
2021-12-13 01:28:02,350 iteration 5685 : loss : 0.030737, loss_ce: 0.010292
2021-12-13 01:28:03,818 iteration 5686 : loss : 0.024944, loss_ce: 0.009697
2021-12-13 01:28:05,318 iteration 5687 : loss : 0.025314, loss_ce: 0.008419
2021-12-13 01:28:06,864 iteration 5688 : loss : 0.042136, loss_ce: 0.015514
2021-12-13 01:28:08,328 iteration 5689 : loss : 0.026568, loss_ce: 0.011246
2021-12-13 01:28:09,737 iteration 5690 : loss : 0.023352, loss_ce: 0.008478
2021-12-13 01:28:11,223 iteration 5691 : loss : 0.021996, loss_ce: 0.009658
2021-12-13 01:28:12,684 iteration 5692 : loss : 0.025831, loss_ce: 0.007906
2021-12-13 01:28:14,029 iteration 5693 : loss : 0.022192, loss_ce: 0.009433
2021-12-13 01:28:15,506 iteration 5694 : loss : 0.029710, loss_ce: 0.012473
2021-12-13 01:28:15,507 Training Data Eval:
2021-12-13 01:28:23,043   Average segmentation loss on training set: 0.0148
2021-12-13 01:28:23,044 Validation Data Eval:
2021-12-13 01:28:25,639   Average segmentation loss on validation set: 0.0752
2021-12-13 01:28:32,139 Found new lowest validation loss at iteration 5694! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/TU_3seeds/TU_SGD_best_val_loss_seed2.pth
2021-12-13 01:28:33,484 iteration 5695 : loss : 0.029270, loss_ce: 0.011880
 84%|████████████████████████▎    | 335/400 [2:33:15<33:11, 30.64s/it]2021-12-13 01:28:34,890 iteration 5696 : loss : 0.032758, loss_ce: 0.010636
2021-12-13 01:28:36,196 iteration 5697 : loss : 0.022592, loss_ce: 0.007607
2021-12-13 01:28:37,603 iteration 5698 : loss : 0.033241, loss_ce: 0.012990
2021-12-13 01:28:39,031 iteration 5699 : loss : 0.036022, loss_ce: 0.010659
2021-12-13 01:28:40,305 iteration 5700 : loss : 0.019742, loss_ce: 0.008946
2021-12-13 01:28:41,788 iteration 5701 : loss : 0.045139, loss_ce: 0.008526
2021-12-13 01:28:43,262 iteration 5702 : loss : 0.024903, loss_ce: 0.009840
2021-12-13 01:28:44,799 iteration 5703 : loss : 0.035017, loss_ce: 0.016314
2021-12-13 01:28:46,234 iteration 5704 : loss : 0.026864, loss_ce: 0.011399
2021-12-13 01:28:47,668 iteration 5705 : loss : 0.023210, loss_ce: 0.009979
2021-12-13 01:28:49,089 iteration 5706 : loss : 0.024832, loss_ce: 0.009092
2021-12-13 01:28:50,598 iteration 5707 : loss : 0.034932, loss_ce: 0.009365
2021-12-13 01:28:52,062 iteration 5708 : loss : 0.023690, loss_ce: 0.011060
2021-12-13 01:28:53,480 iteration 5709 : loss : 0.024839, loss_ce: 0.008775
2021-12-13 01:28:54,926 iteration 5710 : loss : 0.023718, loss_ce: 0.011797
2021-12-13 01:28:56,399 iteration 5711 : loss : 0.024122, loss_ce: 0.010738
2021-12-13 01:28:57,867 iteration 5712 : loss : 0.029219, loss_ce: 0.012730
 84%|████████████████████████▎    | 336/400 [2:33:39<30:41, 28.77s/it]2021-12-13 01:28:59,388 iteration 5713 : loss : 0.021684, loss_ce: 0.009885
2021-12-13 01:29:00,885 iteration 5714 : loss : 0.035360, loss_ce: 0.010269
2021-12-13 01:29:02,299 iteration 5715 : loss : 0.025216, loss_ce: 0.009613
2021-12-13 01:29:03,806 iteration 5716 : loss : 0.030299, loss_ce: 0.011099
2021-12-13 01:29:05,205 iteration 5717 : loss : 0.020804, loss_ce: 0.008348
2021-12-13 01:29:06,633 iteration 5718 : loss : 0.026950, loss_ce: 0.013213
2021-12-13 01:29:08,138 iteration 5719 : loss : 0.030539, loss_ce: 0.009322
2021-12-13 01:29:09,658 iteration 5720 : loss : 0.040059, loss_ce: 0.017637
2021-12-13 01:29:11,070 iteration 5721 : loss : 0.026438, loss_ce: 0.008259
2021-12-13 01:29:12,585 iteration 5722 : loss : 0.029673, loss_ce: 0.011186
2021-12-13 01:29:14,118 iteration 5723 : loss : 0.032981, loss_ce: 0.012739
2021-12-13 01:29:15,608 iteration 5724 : loss : 0.023203, loss_ce: 0.010012
2021-12-13 01:29:17,057 iteration 5725 : loss : 0.025178, loss_ce: 0.010688
2021-12-13 01:29:18,567 iteration 5726 : loss : 0.024018, loss_ce: 0.010442
2021-12-13 01:29:20,053 iteration 5727 : loss : 0.032646, loss_ce: 0.016982
2021-12-13 01:29:21,486 iteration 5728 : loss : 0.030183, loss_ce: 0.010026
2021-12-13 01:29:22,878 iteration 5729 : loss : 0.026412, loss_ce: 0.008146
 84%|████████████████████████▍    | 337/400 [2:34:04<29:01, 27.64s/it]2021-12-13 01:29:24,470 iteration 5730 : loss : 0.038840, loss_ce: 0.013276
2021-12-13 01:29:26,007 iteration 5731 : loss : 0.038499, loss_ce: 0.014423
2021-12-13 01:29:27,522 iteration 5732 : loss : 0.030866, loss_ce: 0.007797
2021-12-13 01:29:28,991 iteration 5733 : loss : 0.029210, loss_ce: 0.011197
2021-12-13 01:29:30,427 iteration 5734 : loss : 0.022511, loss_ce: 0.009210
2021-12-13 01:29:31,992 iteration 5735 : loss : 0.037454, loss_ce: 0.012257
2021-12-13 01:29:33,529 iteration 5736 : loss : 0.026073, loss_ce: 0.010797
2021-12-13 01:29:34,995 iteration 5737 : loss : 0.032986, loss_ce: 0.011740
2021-12-13 01:29:36,430 iteration 5738 : loss : 0.026265, loss_ce: 0.011946
2021-12-13 01:29:37,914 iteration 5739 : loss : 0.024302, loss_ce: 0.008154
2021-12-13 01:29:39,447 iteration 5740 : loss : 0.030554, loss_ce: 0.013487
2021-12-13 01:29:40,925 iteration 5741 : loss : 0.025076, loss_ce: 0.011222
2021-12-13 01:29:42,368 iteration 5742 : loss : 0.054039, loss_ce: 0.009073
2021-12-13 01:29:43,847 iteration 5743 : loss : 0.036179, loss_ce: 0.011350
2021-12-13 01:29:45,284 iteration 5744 : loss : 0.026843, loss_ce: 0.012157
2021-12-13 01:29:46,786 iteration 5745 : loss : 0.022087, loss_ce: 0.007839
2021-12-13 01:29:48,220 iteration 5746 : loss : 0.030603, loss_ce: 0.014261
 84%|████████████████████████▌    | 338/400 [2:34:30<27:51, 26.95s/it]2021-12-13 01:29:49,768 iteration 5747 : loss : 0.034918, loss_ce: 0.013031
2021-12-13 01:29:51,211 iteration 5748 : loss : 0.027600, loss_ce: 0.011598
2021-12-13 01:29:52,728 iteration 5749 : loss : 0.032612, loss_ce: 0.015181
2021-12-13 01:29:54,213 iteration 5750 : loss : 0.031217, loss_ce: 0.009248
2021-12-13 01:29:55,743 iteration 5751 : loss : 0.031298, loss_ce: 0.013156
2021-12-13 01:29:57,226 iteration 5752 : loss : 0.030870, loss_ce: 0.010812
2021-12-13 01:29:58,738 iteration 5753 : loss : 0.030390, loss_ce: 0.015013
2021-12-13 01:30:00,195 iteration 5754 : loss : 0.026974, loss_ce: 0.010062
2021-12-13 01:30:01,647 iteration 5755 : loss : 0.035459, loss_ce: 0.011041
2021-12-13 01:30:03,083 iteration 5756 : loss : 0.033793, loss_ce: 0.017452
2021-12-13 01:30:04,572 iteration 5757 : loss : 0.028691, loss_ce: 0.010369
2021-12-13 01:30:05,976 iteration 5758 : loss : 0.019604, loss_ce: 0.006437
2021-12-13 01:30:07,506 iteration 5759 : loss : 0.036266, loss_ce: 0.010963
2021-12-13 01:30:08,985 iteration 5760 : loss : 0.028542, loss_ce: 0.011254
2021-12-13 01:30:10,481 iteration 5761 : loss : 0.028755, loss_ce: 0.010028
2021-12-13 01:30:12,021 iteration 5762 : loss : 0.028179, loss_ce: 0.013792
2021-12-13 01:30:13,525 iteration 5763 : loss : 0.031686, loss_ce: 0.013958
 85%|████████████████████████▌    | 339/400 [2:34:55<26:53, 26.46s/it]2021-12-13 01:30:15,116 iteration 5764 : loss : 0.028745, loss_ce: 0.012318
2021-12-13 01:30:16,601 iteration 5765 : loss : 0.040297, loss_ce: 0.012417
2021-12-13 01:30:18,041 iteration 5766 : loss : 0.024547, loss_ce: 0.009364
2021-12-13 01:30:19,559 iteration 5767 : loss : 0.025402, loss_ce: 0.010320
2021-12-13 01:30:21,089 iteration 5768 : loss : 0.045792, loss_ce: 0.015590
2021-12-13 01:30:22,587 iteration 5769 : loss : 0.026625, loss_ce: 0.007747
2021-12-13 01:30:24,090 iteration 5770 : loss : 0.036687, loss_ce: 0.014263
2021-12-13 01:30:25,486 iteration 5771 : loss : 0.020011, loss_ce: 0.008652
2021-12-13 01:30:26,976 iteration 5772 : loss : 0.028587, loss_ce: 0.010950
2021-12-13 01:30:28,373 iteration 5773 : loss : 0.022912, loss_ce: 0.008676
2021-12-13 01:30:29,802 iteration 5774 : loss : 0.023407, loss_ce: 0.009407
2021-12-13 01:30:31,295 iteration 5775 : loss : 0.043255, loss_ce: 0.018380
2021-12-13 01:30:32,661 iteration 5776 : loss : 0.030244, loss_ce: 0.011632
2021-12-13 01:30:34,102 iteration 5777 : loss : 0.024064, loss_ce: 0.009183
2021-12-13 01:30:35,597 iteration 5778 : loss : 0.022377, loss_ce: 0.008200
2021-12-13 01:30:37,081 iteration 5779 : loss : 0.021433, loss_ce: 0.009528
2021-12-13 01:30:37,081 Training Data Eval:
2021-12-13 01:30:44,601   Average segmentation loss on training set: 0.0151
2021-12-13 01:30:44,602 Validation Data Eval:
2021-12-13 01:30:47,200   Average segmentation loss on validation set: 0.0804
2021-12-13 01:30:48,646 iteration 5780 : loss : 0.026663, loss_ce: 0.011005
 85%|████████████████████████▋    | 340/400 [2:35:30<29:03, 29.06s/it]2021-12-13 01:30:50,156 iteration 5781 : loss : 0.030613, loss_ce: 0.010390
2021-12-13 01:30:51,538 iteration 5782 : loss : 0.019507, loss_ce: 0.007369
2021-12-13 01:30:53,021 iteration 5783 : loss : 0.028844, loss_ce: 0.009959
2021-12-13 01:30:54,515 iteration 5784 : loss : 0.026170, loss_ce: 0.008498
2021-12-13 01:30:55,998 iteration 5785 : loss : 0.024788, loss_ce: 0.011483
2021-12-13 01:30:57,525 iteration 5786 : loss : 0.030474, loss_ce: 0.012532
2021-12-13 01:30:58,991 iteration 5787 : loss : 0.033312, loss_ce: 0.011565
2021-12-13 01:31:00,469 iteration 5788 : loss : 0.028461, loss_ce: 0.012408
2021-12-13 01:31:01,944 iteration 5789 : loss : 0.030451, loss_ce: 0.010450
2021-12-13 01:31:03,447 iteration 5790 : loss : 0.037098, loss_ce: 0.017167
2021-12-13 01:31:04,955 iteration 5791 : loss : 0.025272, loss_ce: 0.010551
2021-12-13 01:31:06,493 iteration 5792 : loss : 0.033043, loss_ce: 0.009988
2021-12-13 01:31:07,926 iteration 5793 : loss : 0.025230, loss_ce: 0.010458
2021-12-13 01:31:09,369 iteration 5794 : loss : 0.027300, loss_ce: 0.009671
2021-12-13 01:31:10,814 iteration 5795 : loss : 0.027671, loss_ce: 0.012663
2021-12-13 01:31:12,264 iteration 5796 : loss : 0.025638, loss_ce: 0.010174
2021-12-13 01:31:13,700 iteration 5797 : loss : 0.032085, loss_ce: 0.013803
 85%|████████████████████████▋    | 341/400 [2:35:55<27:23, 27.85s/it]2021-12-13 01:31:15,158 iteration 5798 : loss : 0.038680, loss_ce: 0.012995
2021-12-13 01:31:16,583 iteration 5799 : loss : 0.023455, loss_ce: 0.009199
2021-12-13 01:31:17,944 iteration 5800 : loss : 0.017994, loss_ce: 0.007511
2021-12-13 01:31:19,422 iteration 5801 : loss : 0.027177, loss_ce: 0.012600
2021-12-13 01:31:20,832 iteration 5802 : loss : 0.023630, loss_ce: 0.010044
2021-12-13 01:31:22,326 iteration 5803 : loss : 0.031866, loss_ce: 0.011532
2021-12-13 01:31:23,743 iteration 5804 : loss : 0.032036, loss_ce: 0.010129
2021-12-13 01:31:25,154 iteration 5805 : loss : 0.022240, loss_ce: 0.008609
2021-12-13 01:31:26,550 iteration 5806 : loss : 0.022090, loss_ce: 0.010007
2021-12-13 01:31:28,034 iteration 5807 : loss : 0.031127, loss_ce: 0.011662
2021-12-13 01:31:29,561 iteration 5808 : loss : 0.032530, loss_ce: 0.010621
2021-12-13 01:31:31,069 iteration 5809 : loss : 0.029522, loss_ce: 0.011290
2021-12-13 01:31:32,617 iteration 5810 : loss : 0.031646, loss_ce: 0.008804
2021-12-13 01:31:34,133 iteration 5811 : loss : 0.029357, loss_ce: 0.011612
2021-12-13 01:31:35,585 iteration 5812 : loss : 0.025916, loss_ce: 0.011518
2021-12-13 01:31:37,007 iteration 5813 : loss : 0.027616, loss_ce: 0.009935
2021-12-13 01:31:38,446 iteration 5814 : loss : 0.037390, loss_ce: 0.011906
 86%|████████████████████████▊    | 342/400 [2:36:20<26:01, 26.92s/it]2021-12-13 01:31:40,012 iteration 5815 : loss : 0.033455, loss_ce: 0.012601
2021-12-13 01:31:41,480 iteration 5816 : loss : 0.025597, loss_ce: 0.010171
2021-12-13 01:31:43,015 iteration 5817 : loss : 0.036558, loss_ce: 0.016147
2021-12-13 01:31:44,519 iteration 5818 : loss : 0.029749, loss_ce: 0.012311
2021-12-13 01:31:45,970 iteration 5819 : loss : 0.021789, loss_ce: 0.006588
2021-12-13 01:31:47,403 iteration 5820 : loss : 0.034104, loss_ce: 0.013389
2021-12-13 01:31:48,883 iteration 5821 : loss : 0.025396, loss_ce: 0.010039
2021-12-13 01:31:50,423 iteration 5822 : loss : 0.034590, loss_ce: 0.011140
2021-12-13 01:31:51,835 iteration 5823 : loss : 0.023085, loss_ce: 0.011332
2021-12-13 01:31:53,380 iteration 5824 : loss : 0.041942, loss_ce: 0.010358
2021-12-13 01:31:54,860 iteration 5825 : loss : 0.022012, loss_ce: 0.008449
2021-12-13 01:31:56,338 iteration 5826 : loss : 0.027377, loss_ce: 0.012200
2021-12-13 01:31:57,749 iteration 5827 : loss : 0.023522, loss_ce: 0.009913
2021-12-13 01:31:59,291 iteration 5828 : loss : 0.046856, loss_ce: 0.011495
2021-12-13 01:32:00,751 iteration 5829 : loss : 0.028158, loss_ce: 0.010551
2021-12-13 01:32:02,169 iteration 5830 : loss : 0.026041, loss_ce: 0.009363
2021-12-13 01:32:03,717 iteration 5831 : loss : 0.031376, loss_ce: 0.013188
 86%|████████████████████████▊    | 343/400 [2:36:45<25:06, 26.43s/it]2021-12-13 01:32:05,257 iteration 5832 : loss : 0.027515, loss_ce: 0.012122
2021-12-13 01:32:06,789 iteration 5833 : loss : 0.039635, loss_ce: 0.013104
2021-12-13 01:32:08,252 iteration 5834 : loss : 0.026267, loss_ce: 0.011744
2021-12-13 01:32:09,723 iteration 5835 : loss : 0.027068, loss_ce: 0.010102
2021-12-13 01:32:11,168 iteration 5836 : loss : 0.036380, loss_ce: 0.012241
2021-12-13 01:32:12,704 iteration 5837 : loss : 0.027849, loss_ce: 0.011169
2021-12-13 01:32:14,180 iteration 5838 : loss : 0.027218, loss_ce: 0.008790
2021-12-13 01:32:15,657 iteration 5839 : loss : 0.026155, loss_ce: 0.009461
2021-12-13 01:32:17,117 iteration 5840 : loss : 0.022212, loss_ce: 0.008287
2021-12-13 01:32:18,636 iteration 5841 : loss : 0.026961, loss_ce: 0.009203
2021-12-13 01:32:20,051 iteration 5842 : loss : 0.022768, loss_ce: 0.007566
2021-12-13 01:32:21,466 iteration 5843 : loss : 0.022621, loss_ce: 0.008876
2021-12-13 01:32:22,933 iteration 5844 : loss : 0.034587, loss_ce: 0.014640
2021-12-13 01:32:24,347 iteration 5845 : loss : 0.020705, loss_ce: 0.007821
2021-12-13 01:32:25,778 iteration 5846 : loss : 0.021224, loss_ce: 0.009020
2021-12-13 01:32:27,204 iteration 5847 : loss : 0.023723, loss_ce: 0.009010
2021-12-13 01:32:28,641 iteration 5848 : loss : 0.025807, loss_ce: 0.009868
 86%|████████████████████████▉    | 344/400 [2:37:10<24:14, 25.98s/it]2021-12-13 01:32:30,151 iteration 5849 : loss : 0.028138, loss_ce: 0.009132
2021-12-13 01:32:31,682 iteration 5850 : loss : 0.032883, loss_ce: 0.014349
2021-12-13 01:32:33,184 iteration 5851 : loss : 0.023798, loss_ce: 0.006184
2021-12-13 01:32:34,666 iteration 5852 : loss : 0.028031, loss_ce: 0.013288
2021-12-13 01:32:36,089 iteration 5853 : loss : 0.034712, loss_ce: 0.011181
2021-12-13 01:32:37,598 iteration 5854 : loss : 0.030897, loss_ce: 0.010340
2021-12-13 01:32:39,056 iteration 5855 : loss : 0.032072, loss_ce: 0.016282
2021-12-13 01:32:40,521 iteration 5856 : loss : 0.030804, loss_ce: 0.013068
2021-12-13 01:32:42,015 iteration 5857 : loss : 0.028144, loss_ce: 0.010958
2021-12-13 01:32:43,519 iteration 5858 : loss : 0.024169, loss_ce: 0.007627
2021-12-13 01:32:45,076 iteration 5859 : loss : 0.043816, loss_ce: 0.015798
2021-12-13 01:32:46,563 iteration 5860 : loss : 0.024910, loss_ce: 0.009110
2021-12-13 01:32:48,012 iteration 5861 : loss : 0.024568, loss_ce: 0.011241
2021-12-13 01:32:49,492 iteration 5862 : loss : 0.023687, loss_ce: 0.010169
2021-12-13 01:32:50,969 iteration 5863 : loss : 0.034698, loss_ce: 0.012848
2021-12-13 01:32:52,534 iteration 5864 : loss : 0.029458, loss_ce: 0.012321
2021-12-13 01:32:52,535 Training Data Eval:
2021-12-13 01:33:00,062   Average segmentation loss on training set: 0.0151
2021-12-13 01:33:00,063 Validation Data Eval:
2021-12-13 01:33:02,661   Average segmentation loss on validation set: 0.0794
2021-12-13 01:33:04,218 iteration 5865 : loss : 0.041542, loss_ce: 0.012343
 86%|█████████████████████████    | 345/400 [2:37:46<26:27, 28.85s/it]2021-12-13 01:33:05,670 iteration 5866 : loss : 0.029802, loss_ce: 0.009661
2021-12-13 01:33:07,109 iteration 5867 : loss : 0.023370, loss_ce: 0.010235
2021-12-13 01:33:08,593 iteration 5868 : loss : 0.025310, loss_ce: 0.009955
2021-12-13 01:33:10,045 iteration 5869 : loss : 0.026762, loss_ce: 0.008204
2021-12-13 01:33:11,617 iteration 5870 : loss : 0.036714, loss_ce: 0.014304
2021-12-13 01:33:13,073 iteration 5871 : loss : 0.026372, loss_ce: 0.009501
2021-12-13 01:33:14,509 iteration 5872 : loss : 0.027579, loss_ce: 0.010549
2021-12-13 01:33:16,000 iteration 5873 : loss : 0.030349, loss_ce: 0.017831
2021-12-13 01:33:17,478 iteration 5874 : loss : 0.028638, loss_ce: 0.010169
2021-12-13 01:33:18,959 iteration 5875 : loss : 0.023518, loss_ce: 0.010867
2021-12-13 01:33:20,513 iteration 5876 : loss : 0.033353, loss_ce: 0.012893
2021-12-13 01:33:22,043 iteration 5877 : loss : 0.030509, loss_ce: 0.011660
2021-12-13 01:33:23,455 iteration 5878 : loss : 0.023554, loss_ce: 0.008121
2021-12-13 01:33:24,916 iteration 5879 : loss : 0.034750, loss_ce: 0.012561
2021-12-13 01:33:26,405 iteration 5880 : loss : 0.032357, loss_ce: 0.008750
2021-12-13 01:33:27,835 iteration 5881 : loss : 0.028036, loss_ce: 0.011095
2021-12-13 01:33:29,239 iteration 5882 : loss : 0.025256, loss_ce: 0.009407
 86%|█████████████████████████    | 346/400 [2:38:11<24:55, 27.70s/it]2021-12-13 01:33:30,709 iteration 5883 : loss : 0.025952, loss_ce: 0.008782
2021-12-13 01:33:32,101 iteration 5884 : loss : 0.020585, loss_ce: 0.008119
2021-12-13 01:33:33,619 iteration 5885 : loss : 0.029887, loss_ce: 0.009044
2021-12-13 01:33:35,070 iteration 5886 : loss : 0.032270, loss_ce: 0.010452
2021-12-13 01:33:36,575 iteration 5887 : loss : 0.025583, loss_ce: 0.010215
2021-12-13 01:33:38,043 iteration 5888 : loss : 0.018047, loss_ce: 0.007481
2021-12-13 01:33:39,572 iteration 5889 : loss : 0.028940, loss_ce: 0.009393
2021-12-13 01:33:41,028 iteration 5890 : loss : 0.029162, loss_ce: 0.011961
2021-12-13 01:33:42,491 iteration 5891 : loss : 0.035983, loss_ce: 0.010513
2021-12-13 01:33:43,983 iteration 5892 : loss : 0.036509, loss_ce: 0.010906
2021-12-13 01:33:45,428 iteration 5893 : loss : 0.035504, loss_ce: 0.015268
2021-12-13 01:33:46,838 iteration 5894 : loss : 0.033536, loss_ce: 0.014532
2021-12-13 01:33:48,252 iteration 5895 : loss : 0.020701, loss_ce: 0.008567
2021-12-13 01:33:49,666 iteration 5896 : loss : 0.028413, loss_ce: 0.011517
2021-12-13 01:33:51,126 iteration 5897 : loss : 0.025683, loss_ce: 0.012101
2021-12-13 01:33:52,548 iteration 5898 : loss : 0.028794, loss_ce: 0.009890
2021-12-13 01:33:54,047 iteration 5899 : loss : 0.031173, loss_ce: 0.012467
 87%|█████████████████████████▏   | 347/400 [2:38:35<23:42, 26.83s/it]2021-12-13 01:33:55,477 iteration 5900 : loss : 0.029428, loss_ce: 0.010265
2021-12-13 01:33:57,045 iteration 5901 : loss : 0.029964, loss_ce: 0.012898
2021-12-13 01:33:58,593 iteration 5902 : loss : 0.030713, loss_ce: 0.013585
2021-12-13 01:34:00,047 iteration 5903 : loss : 0.030002, loss_ce: 0.010284
2021-12-13 01:34:01,525 iteration 5904 : loss : 0.028584, loss_ce: 0.012374
2021-12-13 01:34:02,933 iteration 5905 : loss : 0.028017, loss_ce: 0.010595
2021-12-13 01:34:04,395 iteration 5906 : loss : 0.030724, loss_ce: 0.012239
2021-12-13 01:34:05,876 iteration 5907 : loss : 0.027336, loss_ce: 0.009974
2021-12-13 01:34:07,333 iteration 5908 : loss : 0.031982, loss_ce: 0.011074
2021-12-13 01:34:08,752 iteration 5909 : loss : 0.023309, loss_ce: 0.009695
2021-12-13 01:34:10,190 iteration 5910 : loss : 0.023176, loss_ce: 0.010658
2021-12-13 01:34:11,635 iteration 5911 : loss : 0.025138, loss_ce: 0.009115
2021-12-13 01:34:13,218 iteration 5912 : loss : 0.056701, loss_ce: 0.010606
2021-12-13 01:34:14,614 iteration 5913 : loss : 0.024344, loss_ce: 0.008567
2021-12-13 01:34:16,152 iteration 5914 : loss : 0.027100, loss_ce: 0.009410
2021-12-13 01:34:17,660 iteration 5915 : loss : 0.032452, loss_ce: 0.014290
2021-12-13 01:34:19,127 iteration 5916 : loss : 0.027906, loss_ce: 0.011201
 87%|█████████████████████████▏   | 348/400 [2:39:01<22:48, 26.31s/it]2021-12-13 01:34:20,618 iteration 5917 : loss : 0.037359, loss_ce: 0.008867
2021-12-13 01:34:22,171 iteration 5918 : loss : 0.031953, loss_ce: 0.012467
2021-12-13 01:34:23,593 iteration 5919 : loss : 0.025473, loss_ce: 0.014557
2021-12-13 01:34:25,167 iteration 5920 : loss : 0.032607, loss_ce: 0.015067
2021-12-13 01:34:26,624 iteration 5921 : loss : 0.026246, loss_ce: 0.008051
2021-12-13 01:34:28,128 iteration 5922 : loss : 0.025547, loss_ce: 0.012418
2021-12-13 01:34:29,573 iteration 5923 : loss : 0.031625, loss_ce: 0.007988
2021-12-13 01:34:30,996 iteration 5924 : loss : 0.020862, loss_ce: 0.008904
2021-12-13 01:34:32,454 iteration 5925 : loss : 0.026058, loss_ce: 0.008904
2021-12-13 01:34:33,909 iteration 5926 : loss : 0.024294, loss_ce: 0.009254
2021-12-13 01:34:35,445 iteration 5927 : loss : 0.029617, loss_ce: 0.011280
2021-12-13 01:34:36,823 iteration 5928 : loss : 0.021688, loss_ce: 0.009830
2021-12-13 01:34:38,238 iteration 5929 : loss : 0.033396, loss_ce: 0.008888
2021-12-13 01:34:39,708 iteration 5930 : loss : 0.034899, loss_ce: 0.013274
2021-12-13 01:34:41,185 iteration 5931 : loss : 0.030464, loss_ce: 0.013910
2021-12-13 01:34:42,631 iteration 5932 : loss : 0.029072, loss_ce: 0.011240
2021-12-13 01:34:44,053 iteration 5933 : loss : 0.020543, loss_ce: 0.008363
 87%|█████████████████████████▎   | 349/400 [2:39:26<22:00, 25.90s/it]2021-12-13 01:34:45,492 iteration 5934 : loss : 0.021886, loss_ce: 0.007826
2021-12-13 01:34:46,890 iteration 5935 : loss : 0.025464, loss_ce: 0.012307
2021-12-13 01:34:48,280 iteration 5936 : loss : 0.023898, loss_ce: 0.009517
2021-12-13 01:34:49,767 iteration 5937 : loss : 0.032429, loss_ce: 0.013558
2021-12-13 01:34:51,255 iteration 5938 : loss : 0.027427, loss_ce: 0.013758
2021-12-13 01:34:52,779 iteration 5939 : loss : 0.037505, loss_ce: 0.014398
2021-12-13 01:34:54,210 iteration 5940 : loss : 0.020524, loss_ce: 0.007805
2021-12-13 01:34:55,714 iteration 5941 : loss : 0.031699, loss_ce: 0.012687
2021-12-13 01:34:57,188 iteration 5942 : loss : 0.023252, loss_ce: 0.008971
2021-12-13 01:34:58,706 iteration 5943 : loss : 0.031659, loss_ce: 0.012631
2021-12-13 01:35:00,084 iteration 5944 : loss : 0.029407, loss_ce: 0.011703
2021-12-13 01:35:01,662 iteration 5945 : loss : 0.030992, loss_ce: 0.009854
2021-12-13 01:35:03,143 iteration 5946 : loss : 0.023177, loss_ce: 0.009361
2021-12-13 01:35:04,732 iteration 5947 : loss : 0.031334, loss_ce: 0.010418
2021-12-13 01:35:06,262 iteration 5948 : loss : 0.035302, loss_ce: 0.012162
2021-12-13 01:35:07,719 iteration 5949 : loss : 0.052506, loss_ce: 0.013730
2021-12-13 01:35:07,720 Training Data Eval:
2021-12-13 01:35:15,239   Average segmentation loss on training set: 0.0147
2021-12-13 01:35:15,240 Validation Data Eval:
2021-12-13 01:35:17,842   Average segmentation loss on validation set: 0.0807
2021-12-13 01:35:19,247 iteration 5950 : loss : 0.019249, loss_ce: 0.006728
 88%|█████████████████████████▍   | 350/400 [2:40:01<23:54, 28.69s/it]2021-12-13 01:35:20,692 iteration 5951 : loss : 0.031753, loss_ce: 0.010250
2021-12-13 01:35:22,165 iteration 5952 : loss : 0.027307, loss_ce: 0.012843
2021-12-13 01:35:23,733 iteration 5953 : loss : 0.039334, loss_ce: 0.017672
2021-12-13 01:35:25,172 iteration 5954 : loss : 0.030100, loss_ce: 0.009065
2021-12-13 01:35:26,758 iteration 5955 : loss : 0.033446, loss_ce: 0.011292
2021-12-13 01:35:28,201 iteration 5956 : loss : 0.031850, loss_ce: 0.008384
2021-12-13 01:35:29,707 iteration 5957 : loss : 0.027892, loss_ce: 0.012192
2021-12-13 01:35:31,221 iteration 5958 : loss : 0.034436, loss_ce: 0.014145
2021-12-13 01:35:32,733 iteration 5959 : loss : 0.025100, loss_ce: 0.007694
2021-12-13 01:35:34,170 iteration 5960 : loss : 0.033901, loss_ce: 0.008419
2021-12-13 01:35:35,674 iteration 5961 : loss : 0.031559, loss_ce: 0.016072
2021-12-13 01:35:37,172 iteration 5962 : loss : 0.028943, loss_ce: 0.009905
2021-12-13 01:35:38,604 iteration 5963 : loss : 0.027180, loss_ce: 0.010562
2021-12-13 01:35:40,124 iteration 5964 : loss : 0.038343, loss_ce: 0.016590
2021-12-13 01:35:41,614 iteration 5965 : loss : 0.021520, loss_ce: 0.010147
2021-12-13 01:35:43,055 iteration 5966 : loss : 0.020415, loss_ce: 0.007479
2021-12-13 01:35:44,601 iteration 5967 : loss : 0.029377, loss_ce: 0.010378
 88%|█████████████████████████▍   | 351/400 [2:40:26<22:36, 27.68s/it]2021-12-13 01:35:46,089 iteration 5968 : loss : 0.029003, loss_ce: 0.011477
2021-12-13 01:35:47,540 iteration 5969 : loss : 0.025872, loss_ce: 0.012612
2021-12-13 01:35:49,035 iteration 5970 : loss : 0.026905, loss_ce: 0.011009
2021-12-13 01:35:50,460 iteration 5971 : loss : 0.022916, loss_ce: 0.010418
2021-12-13 01:35:51,870 iteration 5972 : loss : 0.024544, loss_ce: 0.007044
2021-12-13 01:35:53,285 iteration 5973 : loss : 0.029198, loss_ce: 0.010687
2021-12-13 01:35:54,738 iteration 5974 : loss : 0.030543, loss_ce: 0.009840
2021-12-13 01:35:56,209 iteration 5975 : loss : 0.028279, loss_ce: 0.016443
2021-12-13 01:35:57,702 iteration 5976 : loss : 0.027081, loss_ce: 0.009107
2021-12-13 01:35:59,115 iteration 5977 : loss : 0.023355, loss_ce: 0.008223
2021-12-13 01:36:00,559 iteration 5978 : loss : 0.026432, loss_ce: 0.010322
2021-12-13 01:36:02,018 iteration 5979 : loss : 0.027695, loss_ce: 0.008583
2021-12-13 01:36:03,544 iteration 5980 : loss : 0.038723, loss_ce: 0.009361
2021-12-13 01:36:05,097 iteration 5981 : loss : 0.026858, loss_ce: 0.011548
2021-12-13 01:36:06,576 iteration 5982 : loss : 0.030855, loss_ce: 0.013348
2021-12-13 01:36:08,057 iteration 5983 : loss : 0.030103, loss_ce: 0.008530
2021-12-13 01:36:09,596 iteration 5984 : loss : 0.026279, loss_ce: 0.009118
 88%|█████████████████████████▌   | 352/400 [2:40:51<21:30, 26.88s/it]2021-12-13 01:36:11,149 iteration 5985 : loss : 0.032691, loss_ce: 0.012490
2021-12-13 01:36:12,523 iteration 5986 : loss : 0.020656, loss_ce: 0.009224
2021-12-13 01:36:14,038 iteration 5987 : loss : 0.038299, loss_ce: 0.009893
2021-12-13 01:36:15,434 iteration 5988 : loss : 0.022171, loss_ce: 0.009679
2021-12-13 01:36:16,921 iteration 5989 : loss : 0.024325, loss_ce: 0.009560
2021-12-13 01:36:18,370 iteration 5990 : loss : 0.033714, loss_ce: 0.011326
2021-12-13 01:36:19,907 iteration 5991 : loss : 0.031096, loss_ce: 0.008434
2021-12-13 01:36:21,430 iteration 5992 : loss : 0.038458, loss_ce: 0.009997
2021-12-13 01:36:22,881 iteration 5993 : loss : 0.027210, loss_ce: 0.010412
2021-12-13 01:36:24,265 iteration 5994 : loss : 0.022926, loss_ce: 0.010369
2021-12-13 01:36:25,813 iteration 5995 : loss : 0.030825, loss_ce: 0.010898
2021-12-13 01:36:27,310 iteration 5996 : loss : 0.021374, loss_ce: 0.010824
2021-12-13 01:36:28,733 iteration 5997 : loss : 0.027070, loss_ce: 0.008638
2021-12-13 01:36:30,310 iteration 5998 : loss : 0.029974, loss_ce: 0.010261
2021-12-13 01:36:31,758 iteration 5999 : loss : 0.029809, loss_ce: 0.010358
2021-12-13 01:36:33,343 iteration 6000 : loss : 0.032316, loss_ce: 0.013097
2021-12-13 01:36:34,759 iteration 6001 : loss : 0.022256, loss_ce: 0.008453
 88%|█████████████████████████▌   | 353/400 [2:41:16<20:39, 26.36s/it]2021-12-13 01:36:36,206 iteration 6002 : loss : 0.029555, loss_ce: 0.011936
2021-12-13 01:36:37,693 iteration 6003 : loss : 0.024049, loss_ce: 0.010844
2021-12-13 01:36:39,154 iteration 6004 : loss : 0.028328, loss_ce: 0.010642
2021-12-13 01:36:40,587 iteration 6005 : loss : 0.026442, loss_ce: 0.010273
2021-12-13 01:36:42,103 iteration 6006 : loss : 0.026383, loss_ce: 0.008566
2021-12-13 01:36:43,528 iteration 6007 : loss : 0.022467, loss_ce: 0.009329
2021-12-13 01:36:44,981 iteration 6008 : loss : 0.033136, loss_ce: 0.011552
2021-12-13 01:36:46,487 iteration 6009 : loss : 0.027573, loss_ce: 0.009234
2021-12-13 01:36:47,905 iteration 6010 : loss : 0.026672, loss_ce: 0.006834
2021-12-13 01:36:49,399 iteration 6011 : loss : 0.027941, loss_ce: 0.009527
2021-12-13 01:36:50,930 iteration 6012 : loss : 0.030619, loss_ce: 0.013617
2021-12-13 01:36:52,380 iteration 6013 : loss : 0.030447, loss_ce: 0.010922
2021-12-13 01:36:53,803 iteration 6014 : loss : 0.026746, loss_ce: 0.009598
2021-12-13 01:36:55,193 iteration 6015 : loss : 0.020551, loss_ce: 0.010289
2021-12-13 01:36:56,626 iteration 6016 : loss : 0.020582, loss_ce: 0.006979
2021-12-13 01:36:58,096 iteration 6017 : loss : 0.021456, loss_ce: 0.007846
2021-12-13 01:36:59,478 iteration 6018 : loss : 0.021634, loss_ce: 0.009623
 88%|█████████████████████████▋   | 354/400 [2:41:41<19:50, 25.87s/it]2021-12-13 01:37:01,025 iteration 6019 : loss : 0.025725, loss_ce: 0.009830
2021-12-13 01:37:02,509 iteration 6020 : loss : 0.033567, loss_ce: 0.010204
2021-12-13 01:37:03,932 iteration 6021 : loss : 0.019609, loss_ce: 0.007205
2021-12-13 01:37:05,431 iteration 6022 : loss : 0.024547, loss_ce: 0.009932
2021-12-13 01:37:06,938 iteration 6023 : loss : 0.023507, loss_ce: 0.010369
2021-12-13 01:37:08,408 iteration 6024 : loss : 0.021007, loss_ce: 0.008495
2021-12-13 01:37:09,818 iteration 6025 : loss : 0.043129, loss_ce: 0.009661
2021-12-13 01:37:11,272 iteration 6026 : loss : 0.026588, loss_ce: 0.009937
2021-12-13 01:37:12,784 iteration 6027 : loss : 0.021385, loss_ce: 0.009561
2021-12-13 01:37:14,206 iteration 6028 : loss : 0.024836, loss_ce: 0.011512
2021-12-13 01:37:15,675 iteration 6029 : loss : 0.032331, loss_ce: 0.013536
2021-12-13 01:37:17,206 iteration 6030 : loss : 0.030395, loss_ce: 0.011997
2021-12-13 01:37:18,712 iteration 6031 : loss : 0.037686, loss_ce: 0.011960
2021-12-13 01:37:20,185 iteration 6032 : loss : 0.034940, loss_ce: 0.010104
2021-12-13 01:37:21,643 iteration 6033 : loss : 0.028484, loss_ce: 0.011490
2021-12-13 01:37:23,058 iteration 6034 : loss : 0.019437, loss_ce: 0.007585
2021-12-13 01:37:23,058 Training Data Eval:
2021-12-13 01:37:30,583   Average segmentation loss on training set: 0.0151
2021-12-13 01:37:30,584 Validation Data Eval:
2021-12-13 01:37:33,184   Average segmentation loss on validation set: 0.0783
2021-12-13 01:37:34,593 iteration 6035 : loss : 0.026340, loss_ce: 0.011022
 89%|█████████████████████████▋   | 355/400 [2:42:16<21:29, 28.64s/it]2021-12-13 01:37:36,110 iteration 6036 : loss : 0.022823, loss_ce: 0.010634
2021-12-13 01:37:37,514 iteration 6037 : loss : 0.020044, loss_ce: 0.008577
2021-12-13 01:37:38,935 iteration 6038 : loss : 0.022248, loss_ce: 0.008987
2021-12-13 01:37:40,299 iteration 6039 : loss : 0.022846, loss_ce: 0.008156
2021-12-13 01:37:41,720 iteration 6040 : loss : 0.028023, loss_ce: 0.009572
2021-12-13 01:37:43,226 iteration 6041 : loss : 0.031889, loss_ce: 0.013277
2021-12-13 01:37:44,631 iteration 6042 : loss : 0.025128, loss_ce: 0.007099
2021-12-13 01:37:46,014 iteration 6043 : loss : 0.022754, loss_ce: 0.006438
2021-12-13 01:37:47,510 iteration 6044 : loss : 0.026375, loss_ce: 0.008437
2021-12-13 01:37:48,936 iteration 6045 : loss : 0.022525, loss_ce: 0.010685
2021-12-13 01:37:50,396 iteration 6046 : loss : 0.028789, loss_ce: 0.011558
2021-12-13 01:37:51,826 iteration 6047 : loss : 0.027165, loss_ce: 0.010129
2021-12-13 01:37:53,320 iteration 6048 : loss : 0.027748, loss_ce: 0.013013
2021-12-13 01:37:54,762 iteration 6049 : loss : 0.025895, loss_ce: 0.013160
2021-12-13 01:37:56,222 iteration 6050 : loss : 0.025655, loss_ce: 0.009104
2021-12-13 01:37:57,788 iteration 6051 : loss : 0.026487, loss_ce: 0.010009
2021-12-13 01:37:59,232 iteration 6052 : loss : 0.027075, loss_ce: 0.012092
 89%|█████████████████████████▊   | 356/400 [2:42:41<20:07, 27.44s/it]2021-12-13 01:38:00,688 iteration 6053 : loss : 0.032318, loss_ce: 0.011185
2021-12-13 01:38:02,082 iteration 6054 : loss : 0.024372, loss_ce: 0.012383
2021-12-13 01:38:03,600 iteration 6055 : loss : 0.033064, loss_ce: 0.011645
2021-12-13 01:38:05,044 iteration 6056 : loss : 0.027684, loss_ce: 0.009964
2021-12-13 01:38:06,460 iteration 6057 : loss : 0.022201, loss_ce: 0.007676
2021-12-13 01:38:07,936 iteration 6058 : loss : 0.034430, loss_ce: 0.011060
2021-12-13 01:38:09,462 iteration 6059 : loss : 0.031231, loss_ce: 0.015042
2021-12-13 01:38:11,067 iteration 6060 : loss : 0.055443, loss_ce: 0.020551
2021-12-13 01:38:12,535 iteration 6061 : loss : 0.022853, loss_ce: 0.009519
2021-12-13 01:38:14,080 iteration 6062 : loss : 0.034231, loss_ce: 0.011385
2021-12-13 01:38:15,521 iteration 6063 : loss : 0.031857, loss_ce: 0.008881
2021-12-13 01:38:17,053 iteration 6064 : loss : 0.027544, loss_ce: 0.012545
2021-12-13 01:38:18,463 iteration 6065 : loss : 0.019193, loss_ce: 0.007921
2021-12-13 01:38:19,883 iteration 6066 : loss : 0.017578, loss_ce: 0.006305
2021-12-13 01:38:21,335 iteration 6067 : loss : 0.025951, loss_ce: 0.011737
2021-12-13 01:38:22,754 iteration 6068 : loss : 0.021774, loss_ce: 0.006558
2021-12-13 01:38:24,201 iteration 6069 : loss : 0.024842, loss_ce: 0.010202
 89%|█████████████████████████▉   | 357/400 [2:43:06<19:08, 26.70s/it]2021-12-13 01:38:25,714 iteration 6070 : loss : 0.020468, loss_ce: 0.010715
2021-12-13 01:38:27,126 iteration 6071 : loss : 0.025941, loss_ce: 0.008981
2021-12-13 01:38:28,554 iteration 6072 : loss : 0.022466, loss_ce: 0.011219
2021-12-13 01:38:30,020 iteration 6073 : loss : 0.021752, loss_ce: 0.007385
2021-12-13 01:38:31,511 iteration 6074 : loss : 0.031501, loss_ce: 0.012941
2021-12-13 01:38:32,885 iteration 6075 : loss : 0.023197, loss_ce: 0.010627
2021-12-13 01:38:34,325 iteration 6076 : loss : 0.023801, loss_ce: 0.006872
2021-12-13 01:38:35,802 iteration 6077 : loss : 0.026930, loss_ce: 0.010133
2021-12-13 01:38:37,317 iteration 6078 : loss : 0.025744, loss_ce: 0.009211
2021-12-13 01:38:38,891 iteration 6079 : loss : 0.029457, loss_ce: 0.011432
2021-12-13 01:38:40,370 iteration 6080 : loss : 0.029154, loss_ce: 0.010789
2021-12-13 01:38:41,872 iteration 6081 : loss : 0.029381, loss_ce: 0.011664
2021-12-13 01:38:43,252 iteration 6082 : loss : 0.030006, loss_ce: 0.009252
2021-12-13 01:38:44,664 iteration 6083 : loss : 0.022178, loss_ce: 0.007014
2021-12-13 01:38:46,124 iteration 6084 : loss : 0.034756, loss_ce: 0.008828
2021-12-13 01:38:47,568 iteration 6085 : loss : 0.036671, loss_ce: 0.012304
2021-12-13 01:38:49,004 iteration 6086 : loss : 0.022777, loss_ce: 0.008268
 90%|█████████████████████████▉   | 358/400 [2:43:30<18:17, 26.13s/it]2021-12-13 01:38:50,447 iteration 6087 : loss : 0.027920, loss_ce: 0.009320
2021-12-13 01:38:51,943 iteration 6088 : loss : 0.023525, loss_ce: 0.009572
2021-12-13 01:38:53,387 iteration 6089 : loss : 0.034644, loss_ce: 0.011635
2021-12-13 01:38:54,741 iteration 6090 : loss : 0.021497, loss_ce: 0.009476
2021-12-13 01:38:56,219 iteration 6091 : loss : 0.024245, loss_ce: 0.008843
2021-12-13 01:38:57,708 iteration 6092 : loss : 0.032635, loss_ce: 0.009627
2021-12-13 01:38:59,160 iteration 6093 : loss : 0.026363, loss_ce: 0.010951
2021-12-13 01:39:00,575 iteration 6094 : loss : 0.024112, loss_ce: 0.008774
2021-12-13 01:39:01,995 iteration 6095 : loss : 0.023729, loss_ce: 0.008316
2021-12-13 01:39:03,469 iteration 6096 : loss : 0.036985, loss_ce: 0.012207
2021-12-13 01:39:04,947 iteration 6097 : loss : 0.020177, loss_ce: 0.007696
2021-12-13 01:39:06,503 iteration 6098 : loss : 0.027678, loss_ce: 0.011544
2021-12-13 01:39:08,018 iteration 6099 : loss : 0.026158, loss_ce: 0.011354
2021-12-13 01:39:09,507 iteration 6100 : loss : 0.025111, loss_ce: 0.013116
2021-12-13 01:39:10,982 iteration 6101 : loss : 0.035971, loss_ce: 0.014851
2021-12-13 01:39:12,488 iteration 6102 : loss : 0.033263, loss_ce: 0.017339
2021-12-13 01:39:14,012 iteration 6103 : loss : 0.037011, loss_ce: 0.012355
 90%|██████████████████████████   | 359/400 [2:43:55<17:37, 25.80s/it]2021-12-13 01:39:15,580 iteration 6104 : loss : 0.037323, loss_ce: 0.015878
2021-12-13 01:39:17,102 iteration 6105 : loss : 0.028834, loss_ce: 0.014911
2021-12-13 01:39:18,594 iteration 6106 : loss : 0.030480, loss_ce: 0.014423
2021-12-13 01:39:20,066 iteration 6107 : loss : 0.026770, loss_ce: 0.010821
2021-12-13 01:39:21,507 iteration 6108 : loss : 0.026391, loss_ce: 0.010599
2021-12-13 01:39:22,959 iteration 6109 : loss : 0.030355, loss_ce: 0.007575
2021-12-13 01:39:24,392 iteration 6110 : loss : 0.022967, loss_ce: 0.009172
2021-12-13 01:39:25,840 iteration 6111 : loss : 0.032730, loss_ce: 0.012602
2021-12-13 01:39:27,293 iteration 6112 : loss : 0.030254, loss_ce: 0.009678
2021-12-13 01:39:28,757 iteration 6113 : loss : 0.023332, loss_ce: 0.010035
2021-12-13 01:39:30,259 iteration 6114 : loss : 0.031936, loss_ce: 0.009819
2021-12-13 01:39:31,715 iteration 6115 : loss : 0.023833, loss_ce: 0.009543
2021-12-13 01:39:33,191 iteration 6116 : loss : 0.039413, loss_ce: 0.012410
2021-12-13 01:39:34,614 iteration 6117 : loss : 0.029625, loss_ce: 0.013635
2021-12-13 01:39:36,033 iteration 6118 : loss : 0.018998, loss_ce: 0.006547
2021-12-13 01:39:37,586 iteration 6119 : loss : 0.036975, loss_ce: 0.016789
2021-12-13 01:39:37,586 Training Data Eval:
2021-12-13 01:39:45,108   Average segmentation loss on training set: 0.0146
2021-12-13 01:39:45,109 Validation Data Eval:
2021-12-13 01:39:47,702   Average segmentation loss on validation set: 0.0817
2021-12-13 01:39:49,148 iteration 6120 : loss : 0.024748, loss_ce: 0.008929
 90%|██████████████████████████   | 360/400 [2:44:31<19:03, 28.60s/it]2021-12-13 01:39:50,634 iteration 6121 : loss : 0.028946, loss_ce: 0.009340
2021-12-13 01:39:52,108 iteration 6122 : loss : 0.027231, loss_ce: 0.011322
2021-12-13 01:39:53,564 iteration 6123 : loss : 0.035326, loss_ce: 0.012814
2021-12-13 01:39:54,974 iteration 6124 : loss : 0.019880, loss_ce: 0.007439
2021-12-13 01:39:56,433 iteration 6125 : loss : 0.048283, loss_ce: 0.017892
2021-12-13 01:39:57,852 iteration 6126 : loss : 0.024638, loss_ce: 0.013952
2021-12-13 01:39:59,345 iteration 6127 : loss : 0.026587, loss_ce: 0.009604
2021-12-13 01:40:00,787 iteration 6128 : loss : 0.026023, loss_ce: 0.009306
2021-12-13 01:40:02,350 iteration 6129 : loss : 0.025633, loss_ce: 0.009133
2021-12-13 01:40:03,782 iteration 6130 : loss : 0.027481, loss_ce: 0.008438
2021-12-13 01:40:05,332 iteration 6131 : loss : 0.024507, loss_ce: 0.012154
2021-12-13 01:40:06,778 iteration 6132 : loss : 0.027447, loss_ce: 0.016100
2021-12-13 01:40:08,282 iteration 6133 : loss : 0.028388, loss_ce: 0.009185
2021-12-13 01:40:09,752 iteration 6134 : loss : 0.029624, loss_ce: 0.009963
2021-12-13 01:40:11,316 iteration 6135 : loss : 0.049040, loss_ce: 0.017535
2021-12-13 01:40:12,780 iteration 6136 : loss : 0.026843, loss_ce: 0.008409
2021-12-13 01:40:14,220 iteration 6137 : loss : 0.029174, loss_ce: 0.011107
 90%|██████████████████████████▏  | 361/400 [2:44:56<17:54, 27.54s/it]2021-12-13 01:40:15,686 iteration 6138 : loss : 0.034201, loss_ce: 0.011481
2021-12-13 01:40:17,145 iteration 6139 : loss : 0.029764, loss_ce: 0.011779
2021-12-13 01:40:18,580 iteration 6140 : loss : 0.029320, loss_ce: 0.014246
2021-12-13 01:40:19,961 iteration 6141 : loss : 0.028684, loss_ce: 0.011736
2021-12-13 01:40:21,329 iteration 6142 : loss : 0.021821, loss_ce: 0.009096
2021-12-13 01:40:22,839 iteration 6143 : loss : 0.030201, loss_ce: 0.008159
2021-12-13 01:40:24,303 iteration 6144 : loss : 0.029878, loss_ce: 0.010949
2021-12-13 01:40:25,736 iteration 6145 : loss : 0.022525, loss_ce: 0.010187
2021-12-13 01:40:27,151 iteration 6146 : loss : 0.024451, loss_ce: 0.007280
2021-12-13 01:40:28,596 iteration 6147 : loss : 0.023035, loss_ce: 0.010378
2021-12-13 01:40:30,099 iteration 6148 : loss : 0.024168, loss_ce: 0.009256
2021-12-13 01:40:31,591 iteration 6149 : loss : 0.033369, loss_ce: 0.011512
2021-12-13 01:40:33,134 iteration 6150 : loss : 0.031361, loss_ce: 0.010982
2021-12-13 01:40:34,670 iteration 6151 : loss : 0.029157, loss_ce: 0.007960
2021-12-13 01:40:36,089 iteration 6152 : loss : 0.024079, loss_ce: 0.009955
2021-12-13 01:40:37,564 iteration 6153 : loss : 0.049950, loss_ce: 0.010281
2021-12-13 01:40:39,060 iteration 6154 : loss : 0.029565, loss_ce: 0.012525
 90%|██████████████████████████▏  | 362/400 [2:45:21<16:55, 26.73s/it]2021-12-13 01:40:40,615 iteration 6155 : loss : 0.034414, loss_ce: 0.012255
2021-12-13 01:40:42,112 iteration 6156 : loss : 0.030817, loss_ce: 0.013222
2021-12-13 01:40:43,589 iteration 6157 : loss : 0.028493, loss_ce: 0.011527
2021-12-13 01:40:45,132 iteration 6158 : loss : 0.030433, loss_ce: 0.008892
2021-12-13 01:40:46,566 iteration 6159 : loss : 0.020791, loss_ce: 0.007580
2021-12-13 01:40:48,008 iteration 6160 : loss : 0.027580, loss_ce: 0.010877
2021-12-13 01:40:49,504 iteration 6161 : loss : 0.041430, loss_ce: 0.011276
2021-12-13 01:40:51,036 iteration 6162 : loss : 0.035061, loss_ce: 0.011133
2021-12-13 01:40:52,525 iteration 6163 : loss : 0.028764, loss_ce: 0.011580
2021-12-13 01:40:53,913 iteration 6164 : loss : 0.031544, loss_ce: 0.009666
2021-12-13 01:40:55,435 iteration 6165 : loss : 0.036865, loss_ce: 0.012598
2021-12-13 01:40:56,871 iteration 6166 : loss : 0.026646, loss_ce: 0.010301
2021-12-13 01:40:58,410 iteration 6167 : loss : 0.033312, loss_ce: 0.016382
2021-12-13 01:40:59,891 iteration 6168 : loss : 0.029051, loss_ce: 0.011814
2021-12-13 01:41:01,348 iteration 6169 : loss : 0.031719, loss_ce: 0.009421
2021-12-13 01:41:02,765 iteration 6170 : loss : 0.025368, loss_ce: 0.012600
2021-12-13 01:41:04,200 iteration 6171 : loss : 0.027538, loss_ce: 0.013547
 91%|██████████████████████████▎  | 363/400 [2:45:46<16:11, 26.25s/it]2021-12-13 01:41:05,680 iteration 6172 : loss : 0.032155, loss_ce: 0.011086
2021-12-13 01:41:07,225 iteration 6173 : loss : 0.050644, loss_ce: 0.014242
2021-12-13 01:41:08,712 iteration 6174 : loss : 0.027699, loss_ce: 0.011387
2021-12-13 01:41:10,285 iteration 6175 : loss : 0.028734, loss_ce: 0.009217
2021-12-13 01:41:11,774 iteration 6176 : loss : 0.030840, loss_ce: 0.010823
2021-12-13 01:41:13,237 iteration 6177 : loss : 0.023069, loss_ce: 0.010722
2021-12-13 01:41:14,721 iteration 6178 : loss : 0.030810, loss_ce: 0.012525
2021-12-13 01:41:16,149 iteration 6179 : loss : 0.031736, loss_ce: 0.010573
2021-12-13 01:41:17,663 iteration 6180 : loss : 0.031501, loss_ce: 0.013836
2021-12-13 01:41:19,092 iteration 6181 : loss : 0.020560, loss_ce: 0.007100
2021-12-13 01:41:20,529 iteration 6182 : loss : 0.022478, loss_ce: 0.007031
2021-12-13 01:41:22,041 iteration 6183 : loss : 0.035106, loss_ce: 0.013393
2021-12-13 01:41:23,531 iteration 6184 : loss : 0.025886, loss_ce: 0.012409
2021-12-13 01:41:25,058 iteration 6185 : loss : 0.040544, loss_ce: 0.012912
2021-12-13 01:41:26,509 iteration 6186 : loss : 0.026942, loss_ce: 0.010369
2021-12-13 01:41:27,991 iteration 6187 : loss : 0.030490, loss_ce: 0.014776
2021-12-13 01:41:29,545 iteration 6188 : loss : 0.030808, loss_ce: 0.014716
 91%|██████████████████████████▍  | 364/400 [2:46:11<15:35, 25.98s/it]2021-12-13 01:41:31,121 iteration 6189 : loss : 0.031483, loss_ce: 0.007713
2021-12-13 01:41:32,663 iteration 6190 : loss : 0.030274, loss_ce: 0.009416
2021-12-13 01:41:34,105 iteration 6191 : loss : 0.028368, loss_ce: 0.014346
2021-12-13 01:41:35,515 iteration 6192 : loss : 0.019885, loss_ce: 0.007933
2021-12-13 01:41:36,970 iteration 6193 : loss : 0.028392, loss_ce: 0.009592
2021-12-13 01:41:38,378 iteration 6194 : loss : 0.027152, loss_ce: 0.011276
2021-12-13 01:41:39,924 iteration 6195 : loss : 0.024159, loss_ce: 0.008722
2021-12-13 01:41:41,381 iteration 6196 : loss : 0.026941, loss_ce: 0.009765
2021-12-13 01:41:42,802 iteration 6197 : loss : 0.025077, loss_ce: 0.011557
2021-12-13 01:41:44,380 iteration 6198 : loss : 0.045097, loss_ce: 0.014040
2021-12-13 01:41:45,835 iteration 6199 : loss : 0.027698, loss_ce: 0.011885
2021-12-13 01:41:47,277 iteration 6200 : loss : 0.026724, loss_ce: 0.011973
2021-12-13 01:41:48,770 iteration 6201 : loss : 0.029389, loss_ce: 0.010571
2021-12-13 01:41:50,173 iteration 6202 : loss : 0.022722, loss_ce: 0.007933
2021-12-13 01:41:51,790 iteration 6203 : loss : 0.036447, loss_ce: 0.016746
2021-12-13 01:41:53,198 iteration 6204 : loss : 0.024331, loss_ce: 0.010615
2021-12-13 01:41:53,199 Training Data Eval:
2021-12-13 01:42:00,726   Average segmentation loss on training set: 0.0148
2021-12-13 01:42:00,727 Validation Data Eval:
2021-12-13 01:42:03,326   Average segmentation loss on validation set: 0.0811
2021-12-13 01:42:04,858 iteration 6205 : loss : 0.027355, loss_ce: 0.010735
 91%|██████████████████████████▍  | 365/400 [2:46:46<16:47, 28.78s/it]2021-12-13 01:42:06,389 iteration 6206 : loss : 0.037060, loss_ce: 0.016864
2021-12-13 01:42:07,882 iteration 6207 : loss : 0.023362, loss_ce: 0.009882
2021-12-13 01:42:09,394 iteration 6208 : loss : 0.036840, loss_ce: 0.013277
2021-12-13 01:42:10,882 iteration 6209 : loss : 0.027254, loss_ce: 0.010138
2021-12-13 01:42:12,363 iteration 6210 : loss : 0.018828, loss_ce: 0.007509
2021-12-13 01:42:13,817 iteration 6211 : loss : 0.027174, loss_ce: 0.012973
2021-12-13 01:42:15,247 iteration 6212 : loss : 0.028320, loss_ce: 0.010600
2021-12-13 01:42:16,621 iteration 6213 : loss : 0.023214, loss_ce: 0.008607
2021-12-13 01:42:18,158 iteration 6214 : loss : 0.035858, loss_ce: 0.012457
2021-12-13 01:42:19,618 iteration 6215 : loss : 0.030690, loss_ce: 0.009474
2021-12-13 01:42:21,096 iteration 6216 : loss : 0.032497, loss_ce: 0.011517
2021-12-13 01:42:22,593 iteration 6217 : loss : 0.036876, loss_ce: 0.014953
2021-12-13 01:42:24,006 iteration 6218 : loss : 0.023926, loss_ce: 0.009581
2021-12-13 01:42:25,492 iteration 6219 : loss : 0.035695, loss_ce: 0.012777
2021-12-13 01:42:26,878 iteration 6220 : loss : 0.024921, loss_ce: 0.007553
2021-12-13 01:42:28,419 iteration 6221 : loss : 0.029730, loss_ce: 0.010098
2021-12-13 01:42:29,893 iteration 6222 : loss : 0.027971, loss_ce: 0.011415
 92%|██████████████████████████▌  | 366/400 [2:47:11<15:40, 27.66s/it]2021-12-13 01:42:31,420 iteration 6223 : loss : 0.029076, loss_ce: 0.013158
2021-12-13 01:42:32,931 iteration 6224 : loss : 0.025194, loss_ce: 0.010881
2021-12-13 01:42:34,423 iteration 6225 : loss : 0.024078, loss_ce: 0.011507
2021-12-13 01:42:35,889 iteration 6226 : loss : 0.022998, loss_ce: 0.008883
2021-12-13 01:42:37,439 iteration 6227 : loss : 0.021320, loss_ce: 0.007441
2021-12-13 01:42:38,897 iteration 6228 : loss : 0.030866, loss_ce: 0.011889
2021-12-13 01:42:40,396 iteration 6229 : loss : 0.029442, loss_ce: 0.010400
2021-12-13 01:42:41,916 iteration 6230 : loss : 0.040326, loss_ce: 0.009173
2021-12-13 01:42:43,333 iteration 6231 : loss : 0.023877, loss_ce: 0.010703
2021-12-13 01:42:44,777 iteration 6232 : loss : 0.029715, loss_ce: 0.010799
2021-12-13 01:42:46,318 iteration 6233 : loss : 0.040283, loss_ce: 0.013518
2021-12-13 01:42:47,777 iteration 6234 : loss : 0.031988, loss_ce: 0.013366
2021-12-13 01:42:49,249 iteration 6235 : loss : 0.028223, loss_ce: 0.010125
2021-12-13 01:42:50,763 iteration 6236 : loss : 0.035882, loss_ce: 0.013709
2021-12-13 01:42:52,252 iteration 6237 : loss : 0.030425, loss_ce: 0.009871
2021-12-13 01:42:53,780 iteration 6238 : loss : 0.028708, loss_ce: 0.012008
2021-12-13 01:42:55,335 iteration 6239 : loss : 0.030851, loss_ce: 0.013161
 92%|██████████████████████████▌  | 367/400 [2:47:37<14:50, 26.99s/it]2021-12-13 01:42:56,801 iteration 6240 : loss : 0.034638, loss_ce: 0.012396
2021-12-13 01:42:58,217 iteration 6241 : loss : 0.037335, loss_ce: 0.015553
2021-12-13 01:42:59,714 iteration 6242 : loss : 0.024968, loss_ce: 0.010839
2021-12-13 01:43:01,191 iteration 6243 : loss : 0.023386, loss_ce: 0.009114
2021-12-13 01:43:02,701 iteration 6244 : loss : 0.026033, loss_ce: 0.009391
2021-12-13 01:43:04,194 iteration 6245 : loss : 0.025182, loss_ce: 0.010568
2021-12-13 01:43:05,643 iteration 6246 : loss : 0.024083, loss_ce: 0.009102
2021-12-13 01:43:07,072 iteration 6247 : loss : 0.024714, loss_ce: 0.008720
2021-12-13 01:43:08,563 iteration 6248 : loss : 0.042389, loss_ce: 0.011521
2021-12-13 01:43:10,073 iteration 6249 : loss : 0.031049, loss_ce: 0.010654
2021-12-13 01:43:11,444 iteration 6250 : loss : 0.030057, loss_ce: 0.007951
2021-12-13 01:43:12,957 iteration 6251 : loss : 0.032259, loss_ce: 0.017648
2021-12-13 01:43:14,352 iteration 6252 : loss : 0.025494, loss_ce: 0.008167
2021-12-13 01:43:15,911 iteration 6253 : loss : 0.034730, loss_ce: 0.013568
2021-12-13 01:43:17,308 iteration 6254 : loss : 0.017460, loss_ce: 0.007544
2021-12-13 01:43:18,913 iteration 6255 : loss : 0.049074, loss_ce: 0.014609
2021-12-13 01:43:20,349 iteration 6256 : loss : 0.026724, loss_ce: 0.010461
 92%|██████████████████████████▋  | 368/400 [2:48:02<14:04, 26.40s/it]2021-12-13 01:43:21,897 iteration 6257 : loss : 0.034816, loss_ce: 0.013053
2021-12-13 01:43:23,359 iteration 6258 : loss : 0.023238, loss_ce: 0.012129
2021-12-13 01:43:24,847 iteration 6259 : loss : 0.035628, loss_ce: 0.016221
2021-12-13 01:43:26,309 iteration 6260 : loss : 0.029741, loss_ce: 0.009087
2021-12-13 01:43:27,736 iteration 6261 : loss : 0.022766, loss_ce: 0.009849
2021-12-13 01:43:29,238 iteration 6262 : loss : 0.027298, loss_ce: 0.010507
2021-12-13 01:43:30,751 iteration 6263 : loss : 0.034655, loss_ce: 0.009616
2021-12-13 01:43:32,203 iteration 6264 : loss : 0.024523, loss_ce: 0.011989
2021-12-13 01:43:33,625 iteration 6265 : loss : 0.025144, loss_ce: 0.010680
2021-12-13 01:43:35,095 iteration 6266 : loss : 0.022230, loss_ce: 0.009384
2021-12-13 01:43:36,556 iteration 6267 : loss : 0.035127, loss_ce: 0.013670
2021-12-13 01:43:38,013 iteration 6268 : loss : 0.030212, loss_ce: 0.010904
2021-12-13 01:43:39,458 iteration 6269 : loss : 0.036883, loss_ce: 0.011192
2021-12-13 01:43:40,947 iteration 6270 : loss : 0.029245, loss_ce: 0.009175
2021-12-13 01:43:42,412 iteration 6271 : loss : 0.029701, loss_ce: 0.008165
2021-12-13 01:43:43,863 iteration 6272 : loss : 0.024082, loss_ce: 0.007423
2021-12-13 01:43:45,247 iteration 6273 : loss : 0.021768, loss_ce: 0.009112
 92%|██████████████████████████▊  | 369/400 [2:48:27<13:24, 25.95s/it]2021-12-13 01:43:46,726 iteration 6274 : loss : 0.031005, loss_ce: 0.009531
2021-12-13 01:43:48,188 iteration 6275 : loss : 0.026929, loss_ce: 0.011437
2021-12-13 01:43:49,634 iteration 6276 : loss : 0.026261, loss_ce: 0.009164
2021-12-13 01:43:51,147 iteration 6277 : loss : 0.033826, loss_ce: 0.009906
2021-12-13 01:43:52,679 iteration 6278 : loss : 0.029820, loss_ce: 0.012005
2021-12-13 01:43:54,268 iteration 6279 : loss : 0.038624, loss_ce: 0.011279
2021-12-13 01:43:55,751 iteration 6280 : loss : 0.023935, loss_ce: 0.010575
2021-12-13 01:43:57,207 iteration 6281 : loss : 0.022610, loss_ce: 0.007759
2021-12-13 01:43:58,639 iteration 6282 : loss : 0.027145, loss_ce: 0.010612
2021-12-13 01:44:00,163 iteration 6283 : loss : 0.037189, loss_ce: 0.010766
2021-12-13 01:44:01,711 iteration 6284 : loss : 0.024315, loss_ce: 0.011202
2021-12-13 01:44:03,181 iteration 6285 : loss : 0.025076, loss_ce: 0.008987
2021-12-13 01:44:04,645 iteration 6286 : loss : 0.032805, loss_ce: 0.015956
2021-12-13 01:44:06,162 iteration 6287 : loss : 0.026459, loss_ce: 0.010377
2021-12-13 01:44:07,705 iteration 6288 : loss : 0.032869, loss_ce: 0.010595
2021-12-13 01:44:09,152 iteration 6289 : loss : 0.026876, loss_ce: 0.009713
2021-12-13 01:44:09,152 Training Data Eval:
2021-12-13 01:44:16,686   Average segmentation loss on training set: 0.0149
2021-12-13 01:44:16,687 Validation Data Eval:
2021-12-13 01:44:19,297   Average segmentation loss on validation set: 0.0856
2021-12-13 01:44:20,724 iteration 6290 : loss : 0.020789, loss_ce: 0.008259
 92%|██████████████████████████▊  | 370/400 [2:49:02<14:24, 28.81s/it]2021-12-13 01:44:22,226 iteration 6291 : loss : 0.030612, loss_ce: 0.008197
2021-12-13 01:44:23,791 iteration 6292 : loss : 0.029853, loss_ce: 0.011320
2021-12-13 01:44:25,240 iteration 6293 : loss : 0.019974, loss_ce: 0.008706
2021-12-13 01:44:26,726 iteration 6294 : loss : 0.030088, loss_ce: 0.011730
2021-12-13 01:44:28,221 iteration 6295 : loss : 0.031722, loss_ce: 0.011646
2021-12-13 01:44:29,679 iteration 6296 : loss : 0.023942, loss_ce: 0.009374
2021-12-13 01:44:31,143 iteration 6297 : loss : 0.033034, loss_ce: 0.009633
2021-12-13 01:44:32,583 iteration 6298 : loss : 0.026027, loss_ce: 0.008833
2021-12-13 01:44:34,094 iteration 6299 : loss : 0.039761, loss_ce: 0.016211
2021-12-13 01:44:35,567 iteration 6300 : loss : 0.031620, loss_ce: 0.011988
2021-12-13 01:44:36,997 iteration 6301 : loss : 0.023450, loss_ce: 0.009790
2021-12-13 01:44:38,417 iteration 6302 : loss : 0.025493, loss_ce: 0.010841
2021-12-13 01:44:39,896 iteration 6303 : loss : 0.028270, loss_ce: 0.012297
2021-12-13 01:44:41,332 iteration 6304 : loss : 0.022700, loss_ce: 0.009590
2021-12-13 01:44:42,725 iteration 6305 : loss : 0.021209, loss_ce: 0.009489
2021-12-13 01:44:44,129 iteration 6306 : loss : 0.021843, loss_ce: 0.007897
2021-12-13 01:44:45,680 iteration 6307 : loss : 0.024372, loss_ce: 0.008706
 93%|██████████████████████████▉  | 371/400 [2:49:27<13:21, 27.65s/it]2021-12-13 01:44:47,153 iteration 6308 : loss : 0.023315, loss_ce: 0.008999
2021-12-13 01:44:48,651 iteration 6309 : loss : 0.038639, loss_ce: 0.015077
2021-12-13 01:44:50,131 iteration 6310 : loss : 0.024271, loss_ce: 0.008596
2021-12-13 01:44:51,569 iteration 6311 : loss : 0.026521, loss_ce: 0.007914
2021-12-13 01:44:53,068 iteration 6312 : loss : 0.029614, loss_ce: 0.010670
2021-12-13 01:44:54,513 iteration 6313 : loss : 0.022549, loss_ce: 0.006197
2021-12-13 01:44:56,014 iteration 6314 : loss : 0.034220, loss_ce: 0.015348
2021-12-13 01:44:57,536 iteration 6315 : loss : 0.033759, loss_ce: 0.011452
2021-12-13 01:44:58,993 iteration 6316 : loss : 0.026158, loss_ce: 0.013249
2021-12-13 01:45:00,488 iteration 6317 : loss : 0.023339, loss_ce: 0.009215
2021-12-13 01:45:02,035 iteration 6318 : loss : 0.028915, loss_ce: 0.012691
2021-12-13 01:45:03,599 iteration 6319 : loss : 0.028395, loss_ce: 0.009891
2021-12-13 01:45:05,161 iteration 6320 : loss : 0.028487, loss_ce: 0.012008
2021-12-13 01:45:06,681 iteration 6321 : loss : 0.041955, loss_ce: 0.017383
2021-12-13 01:45:08,225 iteration 6322 : loss : 0.033475, loss_ce: 0.013373
2021-12-13 01:45:09,569 iteration 6323 : loss : 0.019443, loss_ce: 0.008942
2021-12-13 01:45:11,044 iteration 6324 : loss : 0.025858, loss_ce: 0.007568
 93%|██████████████████████████▉  | 372/400 [2:49:53<12:35, 26.97s/it]2021-12-13 01:45:12,496 iteration 6325 : loss : 0.028347, loss_ce: 0.010371
2021-12-13 01:45:13,889 iteration 6326 : loss : 0.018602, loss_ce: 0.008398
2021-12-13 01:45:15,272 iteration 6327 : loss : 0.020441, loss_ce: 0.008120
2021-12-13 01:45:16,801 iteration 6328 : loss : 0.028363, loss_ce: 0.012371
2021-12-13 01:45:18,373 iteration 6329 : loss : 0.027021, loss_ce: 0.009575
2021-12-13 01:45:19,863 iteration 6330 : loss : 0.024661, loss_ce: 0.009323
2021-12-13 01:45:21,393 iteration 6331 : loss : 0.030595, loss_ce: 0.014211
2021-12-13 01:45:22,843 iteration 6332 : loss : 0.023224, loss_ce: 0.008849
2021-12-13 01:45:24,296 iteration 6333 : loss : 0.025231, loss_ce: 0.010352
2021-12-13 01:45:25,785 iteration 6334 : loss : 0.022024, loss_ce: 0.008761
2021-12-13 01:45:27,397 iteration 6335 : loss : 0.029948, loss_ce: 0.012482
2021-12-13 01:45:28,909 iteration 6336 : loss : 0.025971, loss_ce: 0.009534
2021-12-13 01:45:30,304 iteration 6337 : loss : 0.026827, loss_ce: 0.011445
2021-12-13 01:45:31,852 iteration 6338 : loss : 0.026349, loss_ce: 0.009376
2021-12-13 01:45:33,294 iteration 6339 : loss : 0.020950, loss_ce: 0.007571
2021-12-13 01:45:34,778 iteration 6340 : loss : 0.030706, loss_ce: 0.013800
2021-12-13 01:45:36,292 iteration 6341 : loss : 0.028648, loss_ce: 0.008235
 93%|███████████████████████████  | 373/400 [2:50:18<11:54, 26.45s/it]2021-12-13 01:45:37,912 iteration 6342 : loss : 0.036523, loss_ce: 0.014310
2021-12-13 01:45:39,377 iteration 6343 : loss : 0.025680, loss_ce: 0.008579
2021-12-13 01:45:40,858 iteration 6344 : loss : 0.033701, loss_ce: 0.016226
2021-12-13 01:45:42,339 iteration 6345 : loss : 0.032541, loss_ce: 0.014373
2021-12-13 01:45:43,765 iteration 6346 : loss : 0.022733, loss_ce: 0.007467
2021-12-13 01:45:45,230 iteration 6347 : loss : 0.025504, loss_ce: 0.009977
2021-12-13 01:45:46,793 iteration 6348 : loss : 0.028229, loss_ce: 0.010619
2021-12-13 01:45:48,215 iteration 6349 : loss : 0.022910, loss_ce: 0.010024
2021-12-13 01:45:49,657 iteration 6350 : loss : 0.024716, loss_ce: 0.007882
2021-12-13 01:45:51,107 iteration 6351 : loss : 0.024819, loss_ce: 0.009077
2021-12-13 01:45:52,638 iteration 6352 : loss : 0.025782, loss_ce: 0.011203
2021-12-13 01:45:54,159 iteration 6353 : loss : 0.025973, loss_ce: 0.010894
2021-12-13 01:45:55,725 iteration 6354 : loss : 0.036810, loss_ce: 0.013600
2021-12-13 01:45:57,158 iteration 6355 : loss : 0.023624, loss_ce: 0.011755
2021-12-13 01:45:58,668 iteration 6356 : loss : 0.029407, loss_ce: 0.015313
2021-12-13 01:46:00,128 iteration 6357 : loss : 0.028468, loss_ce: 0.010080
2021-12-13 01:46:01,686 iteration 6358 : loss : 0.029608, loss_ce: 0.010289
 94%|███████████████████████████  | 374/400 [2:50:43<11:19, 26.14s/it]2021-12-13 01:46:03,221 iteration 6359 : loss : 0.028670, loss_ce: 0.010117
2021-12-13 01:46:04,660 iteration 6360 : loss : 0.032560, loss_ce: 0.009960
2021-12-13 01:46:06,159 iteration 6361 : loss : 0.040604, loss_ce: 0.013225
2021-12-13 01:46:07,675 iteration 6362 : loss : 0.027037, loss_ce: 0.013181
2021-12-13 01:46:09,243 iteration 6363 : loss : 0.039028, loss_ce: 0.016681
2021-12-13 01:46:10,674 iteration 6364 : loss : 0.020638, loss_ce: 0.008138
2021-12-13 01:46:12,090 iteration 6365 : loss : 0.026245, loss_ce: 0.010150
2021-12-13 01:46:13,613 iteration 6366 : loss : 0.032895, loss_ce: 0.013117
2021-12-13 01:46:15,080 iteration 6367 : loss : 0.023282, loss_ce: 0.010388
2021-12-13 01:46:16,531 iteration 6368 : loss : 0.029505, loss_ce: 0.010901
2021-12-13 01:46:18,036 iteration 6369 : loss : 0.025203, loss_ce: 0.011954
2021-12-13 01:46:19,559 iteration 6370 : loss : 0.054802, loss_ce: 0.016372
2021-12-13 01:46:21,081 iteration 6371 : loss : 0.031876, loss_ce: 0.012408
2021-12-13 01:46:22,578 iteration 6372 : loss : 0.027956, loss_ce: 0.013139
2021-12-13 01:46:23,931 iteration 6373 : loss : 0.017442, loss_ce: 0.005303
2021-12-13 01:46:25,367 iteration 6374 : loss : 0.019682, loss_ce: 0.008527
2021-12-13 01:46:25,368 Training Data Eval:
2021-12-13 01:46:32,923   Average segmentation loss on training set: 0.0144
2021-12-13 01:46:32,924 Validation Data Eval:
2021-12-13 01:46:35,521   Average segmentation loss on validation set: 0.0790
2021-12-13 01:46:36,982 iteration 6375 : loss : 0.027550, loss_ce: 0.010023
 94%|███████████████████████████▏ | 375/400 [2:51:18<12:02, 28.88s/it]2021-12-13 01:46:38,708 iteration 6376 : loss : 0.047162, loss_ce: 0.019436
2021-12-13 01:46:40,194 iteration 6377 : loss : 0.022090, loss_ce: 0.007983
2021-12-13 01:46:41,644 iteration 6378 : loss : 0.030478, loss_ce: 0.010756
2021-12-13 01:46:43,161 iteration 6379 : loss : 0.027770, loss_ce: 0.007210
2021-12-13 01:46:44,560 iteration 6380 : loss : 0.021007, loss_ce: 0.009879
2021-12-13 01:46:45,959 iteration 6381 : loss : 0.028273, loss_ce: 0.009460
2021-12-13 01:46:47,457 iteration 6382 : loss : 0.043998, loss_ce: 0.019129
2021-12-13 01:46:48,975 iteration 6383 : loss : 0.028409, loss_ce: 0.011205
2021-12-13 01:46:50,436 iteration 6384 : loss : 0.023458, loss_ce: 0.008751
2021-12-13 01:46:51,998 iteration 6385 : loss : 0.041651, loss_ce: 0.017767
2021-12-13 01:46:53,478 iteration 6386 : loss : 0.031057, loss_ce: 0.012062
2021-12-13 01:46:55,075 iteration 6387 : loss : 0.030676, loss_ce: 0.015226
2021-12-13 01:46:56,530 iteration 6388 : loss : 0.020676, loss_ce: 0.007715
2021-12-13 01:46:57,905 iteration 6389 : loss : 0.021445, loss_ce: 0.007723
2021-12-13 01:46:59,367 iteration 6390 : loss : 0.028734, loss_ce: 0.010698
2021-12-13 01:47:00,949 iteration 6391 : loss : 0.038636, loss_ce: 0.010950
2021-12-13 01:47:02,361 iteration 6392 : loss : 0.021152, loss_ce: 0.008941
 94%|███████████████████████████▎ | 376/400 [2:51:44<11:07, 27.83s/it]2021-12-13 01:47:03,874 iteration 6393 : loss : 0.020276, loss_ce: 0.006769
2021-12-13 01:47:05,370 iteration 6394 : loss : 0.036280, loss_ce: 0.012074
2021-12-13 01:47:06,812 iteration 6395 : loss : 0.021681, loss_ce: 0.010566
2021-12-13 01:47:08,378 iteration 6396 : loss : 0.028277, loss_ce: 0.013240
2021-12-13 01:47:09,822 iteration 6397 : loss : 0.027957, loss_ce: 0.011496
2021-12-13 01:47:11,235 iteration 6398 : loss : 0.027081, loss_ce: 0.009188
2021-12-13 01:47:12,719 iteration 6399 : loss : 0.026666, loss_ce: 0.008061
2021-12-13 01:47:14,201 iteration 6400 : loss : 0.022728, loss_ce: 0.011080
2021-12-13 01:47:15,599 iteration 6401 : loss : 0.023416, loss_ce: 0.009532
2021-12-13 01:47:17,061 iteration 6402 : loss : 0.031416, loss_ce: 0.012222
2021-12-13 01:47:18,655 iteration 6403 : loss : 0.038354, loss_ce: 0.013244
2021-12-13 01:47:20,108 iteration 6404 : loss : 0.030464, loss_ce: 0.010180
2021-12-13 01:47:21,561 iteration 6405 : loss : 0.030452, loss_ce: 0.012097
2021-12-13 01:47:23,177 iteration 6406 : loss : 0.026708, loss_ce: 0.013185
2021-12-13 01:47:24,582 iteration 6407 : loss : 0.029267, loss_ce: 0.008818
2021-12-13 01:47:26,048 iteration 6408 : loss : 0.024877, loss_ce: 0.007335
2021-12-13 01:47:27,483 iteration 6409 : loss : 0.034538, loss_ce: 0.014750
 94%|███████████████████████████▎ | 377/400 [2:52:09<10:21, 27.02s/it]2021-12-13 01:47:29,102 iteration 6410 : loss : 0.034992, loss_ce: 0.013270
2021-12-13 01:47:30,651 iteration 6411 : loss : 0.039167, loss_ce: 0.016470
2021-12-13 01:47:32,138 iteration 6412 : loss : 0.023564, loss_ce: 0.010576
2021-12-13 01:47:33,617 iteration 6413 : loss : 0.018072, loss_ce: 0.006560
2021-12-13 01:47:35,116 iteration 6414 : loss : 0.032476, loss_ce: 0.013802
2021-12-13 01:47:36,556 iteration 6415 : loss : 0.028565, loss_ce: 0.009122
2021-12-13 01:47:38,013 iteration 6416 : loss : 0.037764, loss_ce: 0.010744
2021-12-13 01:47:39,508 iteration 6417 : loss : 0.028610, loss_ce: 0.013410
2021-12-13 01:47:41,014 iteration 6418 : loss : 0.031892, loss_ce: 0.012001
2021-12-13 01:47:42,476 iteration 6419 : loss : 0.033877, loss_ce: 0.010458
2021-12-13 01:47:43,976 iteration 6420 : loss : 0.030880, loss_ce: 0.010857
2021-12-13 01:47:45,448 iteration 6421 : loss : 0.025397, loss_ce: 0.010003
2021-12-13 01:47:46,846 iteration 6422 : loss : 0.025172, loss_ce: 0.010784
2021-12-13 01:47:48,347 iteration 6423 : loss : 0.045887, loss_ce: 0.014049
2021-12-13 01:47:49,860 iteration 6424 : loss : 0.023837, loss_ce: 0.011187
2021-12-13 01:47:51,249 iteration 6425 : loss : 0.024501, loss_ce: 0.008435
2021-12-13 01:47:52,749 iteration 6426 : loss : 0.025986, loss_ce: 0.011948
 94%|███████████████████████████▍ | 378/400 [2:52:34<09:42, 26.49s/it]2021-12-13 01:47:54,281 iteration 6427 : loss : 0.026208, loss_ce: 0.011908
2021-12-13 01:47:55,674 iteration 6428 : loss : 0.024497, loss_ce: 0.012400
2021-12-13 01:47:57,177 iteration 6429 : loss : 0.029987, loss_ce: 0.010562
2021-12-13 01:47:58,586 iteration 6430 : loss : 0.025788, loss_ce: 0.007807
2021-12-13 01:48:00,064 iteration 6431 : loss : 0.026258, loss_ce: 0.008275
2021-12-13 01:48:01,542 iteration 6432 : loss : 0.024631, loss_ce: 0.009355
2021-12-13 01:48:03,081 iteration 6433 : loss : 0.026300, loss_ce: 0.009701
2021-12-13 01:48:04,461 iteration 6434 : loss : 0.022279, loss_ce: 0.007960
2021-12-13 01:48:05,926 iteration 6435 : loss : 0.024405, loss_ce: 0.012593
2021-12-13 01:48:07,376 iteration 6436 : loss : 0.024151, loss_ce: 0.009950
2021-12-13 01:48:08,877 iteration 6437 : loss : 0.039587, loss_ce: 0.009522
2021-12-13 01:48:10,399 iteration 6438 : loss : 0.027717, loss_ce: 0.010993
2021-12-13 01:48:11,898 iteration 6439 : loss : 0.025862, loss_ce: 0.009996
2021-12-13 01:48:13,438 iteration 6440 : loss : 0.034956, loss_ce: 0.013402
2021-12-13 01:48:14,926 iteration 6441 : loss : 0.029766, loss_ce: 0.008795
2021-12-13 01:48:16,410 iteration 6442 : loss : 0.029807, loss_ce: 0.012656
2021-12-13 01:48:17,908 iteration 6443 : loss : 0.033770, loss_ce: 0.013729
 95%|███████████████████████████▍ | 379/400 [2:52:59<09:07, 26.09s/it]2021-12-13 01:48:19,465 iteration 6444 : loss : 0.028482, loss_ce: 0.013526
2021-12-13 01:48:21,015 iteration 6445 : loss : 0.031376, loss_ce: 0.013173
2021-12-13 01:48:22,502 iteration 6446 : loss : 0.031361, loss_ce: 0.009216
2021-12-13 01:48:23,970 iteration 6447 : loss : 0.027302, loss_ce: 0.015094
2021-12-13 01:48:25,440 iteration 6448 : loss : 0.023403, loss_ce: 0.010632
2021-12-13 01:48:26,970 iteration 6449 : loss : 0.028816, loss_ce: 0.010150
2021-12-13 01:48:28,413 iteration 6450 : loss : 0.023327, loss_ce: 0.010630
2021-12-13 01:48:29,818 iteration 6451 : loss : 0.027431, loss_ce: 0.010304
2021-12-13 01:48:31,316 iteration 6452 : loss : 0.024829, loss_ce: 0.010969
2021-12-13 01:48:32,795 iteration 6453 : loss : 0.027424, loss_ce: 0.011051
2021-12-13 01:48:34,246 iteration 6454 : loss : 0.032492, loss_ce: 0.011306
2021-12-13 01:48:35,696 iteration 6455 : loss : 0.022729, loss_ce: 0.008296
2021-12-13 01:48:37,269 iteration 6456 : loss : 0.035562, loss_ce: 0.014246
2021-12-13 01:48:38,746 iteration 6457 : loss : 0.023962, loss_ce: 0.007863
2021-12-13 01:48:40,181 iteration 6458 : loss : 0.025411, loss_ce: 0.008167
2021-12-13 01:48:41,593 iteration 6459 : loss : 0.025236, loss_ce: 0.008564
2021-12-13 01:48:41,593 Training Data Eval:
2021-12-13 01:48:49,121   Average segmentation loss on training set: 0.0144
2021-12-13 01:48:49,121 Validation Data Eval:
2021-12-13 01:48:51,714   Average segmentation loss on validation set: 0.0845
2021-12-13 01:48:53,213 iteration 6460 : loss : 0.032739, loss_ce: 0.009397
 95%|███████████████████████████▌ | 380/400 [2:53:35<09:37, 28.86s/it]2021-12-13 01:48:54,752 iteration 6461 : loss : 0.035173, loss_ce: 0.009920
2021-12-13 01:48:56,236 iteration 6462 : loss : 0.032614, loss_ce: 0.010546
2021-12-13 01:48:57,659 iteration 6463 : loss : 0.018915, loss_ce: 0.006040
2021-12-13 01:48:59,077 iteration 6464 : loss : 0.023599, loss_ce: 0.007688
2021-12-13 01:49:00,529 iteration 6465 : loss : 0.036774, loss_ce: 0.011512
2021-12-13 01:49:02,023 iteration 6466 : loss : 0.025501, loss_ce: 0.010558
2021-12-13 01:49:03,545 iteration 6467 : loss : 0.023804, loss_ce: 0.010578
2021-12-13 01:49:05,085 iteration 6468 : loss : 0.032571, loss_ce: 0.016289
2021-12-13 01:49:06,554 iteration 6469 : loss : 0.033365, loss_ce: 0.015302
2021-12-13 01:49:07,999 iteration 6470 : loss : 0.034527, loss_ce: 0.010227
2021-12-13 01:49:09,445 iteration 6471 : loss : 0.024436, loss_ce: 0.008800
2021-12-13 01:49:10,911 iteration 6472 : loss : 0.029110, loss_ce: 0.008951
2021-12-13 01:49:12,317 iteration 6473 : loss : 0.025759, loss_ce: 0.013071
2021-12-13 01:49:13,844 iteration 6474 : loss : 0.026017, loss_ce: 0.012687
2021-12-13 01:49:15,244 iteration 6475 : loss : 0.020494, loss_ce: 0.007458
2021-12-13 01:49:16,677 iteration 6476 : loss : 0.024099, loss_ce: 0.009092
2021-12-13 01:49:18,076 iteration 6477 : loss : 0.023501, loss_ce: 0.009052
 95%|███████████████████████████▌ | 381/400 [2:54:00<08:45, 27.66s/it]2021-12-13 01:49:19,622 iteration 6478 : loss : 0.026218, loss_ce: 0.010682
2021-12-13 01:49:21,246 iteration 6479 : loss : 0.036896, loss_ce: 0.017310
2021-12-13 01:49:22,751 iteration 6480 : loss : 0.041927, loss_ce: 0.011451
2021-12-13 01:49:24,245 iteration 6481 : loss : 0.028718, loss_ce: 0.012050
2021-12-13 01:49:25,740 iteration 6482 : loss : 0.032063, loss_ce: 0.013904
2021-12-13 01:49:27,186 iteration 6483 : loss : 0.027001, loss_ce: 0.010564
2021-12-13 01:49:28,647 iteration 6484 : loss : 0.024842, loss_ce: 0.007774
2021-12-13 01:49:30,137 iteration 6485 : loss : 0.035025, loss_ce: 0.014705
2021-12-13 01:49:31,694 iteration 6486 : loss : 0.034562, loss_ce: 0.010774
2021-12-13 01:49:33,198 iteration 6487 : loss : 0.028458, loss_ce: 0.009801
2021-12-13 01:49:34,575 iteration 6488 : loss : 0.022182, loss_ce: 0.009320
2021-12-13 01:49:36,095 iteration 6489 : loss : 0.033428, loss_ce: 0.009890
2021-12-13 01:49:37,474 iteration 6490 : loss : 0.025676, loss_ce: 0.009746
2021-12-13 01:49:38,984 iteration 6491 : loss : 0.034983, loss_ce: 0.009741
2021-12-13 01:49:40,428 iteration 6492 : loss : 0.021806, loss_ce: 0.008185
2021-12-13 01:49:41,930 iteration 6493 : loss : 0.036760, loss_ce: 0.010230
2021-12-13 01:49:43,396 iteration 6494 : loss : 0.030073, loss_ce: 0.011570
 96%|███████████████████████████▋ | 382/400 [2:54:25<08:05, 26.96s/it]2021-12-13 01:49:44,951 iteration 6495 : loss : 0.025011, loss_ce: 0.007915
2021-12-13 01:49:46,404 iteration 6496 : loss : 0.027618, loss_ce: 0.010454
2021-12-13 01:49:47,913 iteration 6497 : loss : 0.022539, loss_ce: 0.008227
2021-12-13 01:49:49,401 iteration 6498 : loss : 0.039889, loss_ce: 0.019590
2021-12-13 01:49:50,979 iteration 6499 : loss : 0.042273, loss_ce: 0.015234
2021-12-13 01:49:52,496 iteration 6500 : loss : 0.036148, loss_ce: 0.014945
2021-12-13 01:49:54,040 iteration 6501 : loss : 0.030063, loss_ce: 0.007840
2021-12-13 01:49:55,568 iteration 6502 : loss : 0.032619, loss_ce: 0.013767
2021-12-13 01:49:57,148 iteration 6503 : loss : 0.032922, loss_ce: 0.012109
2021-12-13 01:49:58,573 iteration 6504 : loss : 0.022048, loss_ce: 0.011053
2021-12-13 01:50:00,028 iteration 6505 : loss : 0.023105, loss_ce: 0.006862
2021-12-13 01:50:01,490 iteration 6506 : loss : 0.027039, loss_ce: 0.009065
2021-12-13 01:50:02,950 iteration 6507 : loss : 0.032571, loss_ce: 0.013635
2021-12-13 01:50:04,425 iteration 6508 : loss : 0.024184, loss_ce: 0.008422
2021-12-13 01:50:05,893 iteration 6509 : loss : 0.024069, loss_ce: 0.009831
2021-12-13 01:50:07,355 iteration 6510 : loss : 0.027454, loss_ce: 0.009501
2021-12-13 01:50:08,825 iteration 6511 : loss : 0.026931, loss_ce: 0.012786
 96%|███████████████████████████▊ | 383/400 [2:54:50<07:30, 26.50s/it]2021-12-13 01:50:10,338 iteration 6512 : loss : 0.030238, loss_ce: 0.012575
2021-12-13 01:50:11,749 iteration 6513 : loss : 0.027332, loss_ce: 0.010436
2021-12-13 01:50:13,206 iteration 6514 : loss : 0.030087, loss_ce: 0.008220
2021-12-13 01:50:14,672 iteration 6515 : loss : 0.026342, loss_ce: 0.008922
2021-12-13 01:50:16,143 iteration 6516 : loss : 0.024228, loss_ce: 0.007989
2021-12-13 01:50:17,688 iteration 6517 : loss : 0.030784, loss_ce: 0.014549
2021-12-13 01:50:19,100 iteration 6518 : loss : 0.028229, loss_ce: 0.012372
2021-12-13 01:50:20,641 iteration 6519 : loss : 0.025293, loss_ce: 0.009100
2021-12-13 01:50:22,044 iteration 6520 : loss : 0.022809, loss_ce: 0.011112
2021-12-13 01:50:23,573 iteration 6521 : loss : 0.020327, loss_ce: 0.008980
2021-12-13 01:50:25,031 iteration 6522 : loss : 0.031608, loss_ce: 0.013152
2021-12-13 01:50:26,442 iteration 6523 : loss : 0.030769, loss_ce: 0.009828
2021-12-13 01:50:27,918 iteration 6524 : loss : 0.032001, loss_ce: 0.012839
2021-12-13 01:50:29,367 iteration 6525 : loss : 0.021532, loss_ce: 0.007631
2021-12-13 01:50:30,860 iteration 6526 : loss : 0.023855, loss_ce: 0.009721
2021-12-13 01:50:32,391 iteration 6527 : loss : 0.028244, loss_ce: 0.010393
2021-12-13 01:50:33,887 iteration 6528 : loss : 0.030471, loss_ce: 0.011859
 96%|███████████████████████████▊ | 384/400 [2:55:15<06:57, 26.07s/it]2021-12-13 01:50:35,355 iteration 6529 : loss : 0.025242, loss_ce: 0.009908
2021-12-13 01:50:36,746 iteration 6530 : loss : 0.018849, loss_ce: 0.008581
2021-12-13 01:50:38,224 iteration 6531 : loss : 0.024161, loss_ce: 0.005743
2021-12-13 01:50:39,766 iteration 6532 : loss : 0.030539, loss_ce: 0.010248
2021-12-13 01:50:41,203 iteration 6533 : loss : 0.030408, loss_ce: 0.012321
2021-12-13 01:50:42,711 iteration 6534 : loss : 0.033144, loss_ce: 0.010469
2021-12-13 01:50:44,195 iteration 6535 : loss : 0.027950, loss_ce: 0.011423
2021-12-13 01:50:45,726 iteration 6536 : loss : 0.028081, loss_ce: 0.011096
2021-12-13 01:50:47,310 iteration 6537 : loss : 0.038285, loss_ce: 0.012820
2021-12-13 01:50:48,742 iteration 6538 : loss : 0.026210, loss_ce: 0.009535
2021-12-13 01:50:50,343 iteration 6539 : loss : 0.033311, loss_ce: 0.012477
2021-12-13 01:50:51,788 iteration 6540 : loss : 0.031832, loss_ce: 0.014113
2021-12-13 01:50:53,183 iteration 6541 : loss : 0.026100, loss_ce: 0.011650
2021-12-13 01:50:54,638 iteration 6542 : loss : 0.033571, loss_ce: 0.012321
2021-12-13 01:50:56,182 iteration 6543 : loss : 0.034868, loss_ce: 0.013456
2021-12-13 01:50:57,647 iteration 6544 : loss : 0.030622, loss_ce: 0.012678
2021-12-13 01:50:57,647 Training Data Eval:
2021-12-13 01:51:05,174   Average segmentation loss on training set: 0.0148
2021-12-13 01:51:05,174 Validation Data Eval:
2021-12-13 01:51:07,770   Average segmentation loss on validation set: 0.0817
2021-12-13 01:51:09,235 iteration 6545 : loss : 0.020026, loss_ce: 0.005914
 96%|███████████████████████████▉ | 385/400 [2:55:51<07:12, 28.85s/it]2021-12-13 01:51:10,815 iteration 6546 : loss : 0.025594, loss_ce: 0.009421
2021-12-13 01:51:12,227 iteration 6547 : loss : 0.028340, loss_ce: 0.007874
2021-12-13 01:51:13,712 iteration 6548 : loss : 0.039511, loss_ce: 0.011145
2021-12-13 01:51:15,270 iteration 6549 : loss : 0.035114, loss_ce: 0.011015
2021-12-13 01:51:16,737 iteration 6550 : loss : 0.029004, loss_ce: 0.013071
2021-12-13 01:51:18,271 iteration 6551 : loss : 0.038781, loss_ce: 0.014967
2021-12-13 01:51:19,849 iteration 6552 : loss : 0.043302, loss_ce: 0.014962
2021-12-13 01:51:21,316 iteration 6553 : loss : 0.032413, loss_ce: 0.012263
2021-12-13 01:51:22,919 iteration 6554 : loss : 0.040495, loss_ce: 0.012605
2021-12-13 01:51:24,355 iteration 6555 : loss : 0.027625, loss_ce: 0.010264
2021-12-13 01:51:25,850 iteration 6556 : loss : 0.034689, loss_ce: 0.012729
2021-12-13 01:51:27,252 iteration 6557 : loss : 0.019866, loss_ce: 0.007658
2021-12-13 01:51:28,781 iteration 6558 : loss : 0.035895, loss_ce: 0.014331
2021-12-13 01:51:30,191 iteration 6559 : loss : 0.022286, loss_ce: 0.008903
2021-12-13 01:51:31,616 iteration 6560 : loss : 0.022532, loss_ce: 0.010642
2021-12-13 01:51:33,105 iteration 6561 : loss : 0.033453, loss_ce: 0.011378
2021-12-13 01:51:34,577 iteration 6562 : loss : 0.029278, loss_ce: 0.012852
 96%|███████████████████████████▉ | 386/400 [2:56:16<06:29, 27.80s/it]2021-12-13 01:51:36,120 iteration 6563 : loss : 0.029476, loss_ce: 0.013002
2021-12-13 01:51:37,662 iteration 6564 : loss : 0.028927, loss_ce: 0.010171
2021-12-13 01:51:39,098 iteration 6565 : loss : 0.031477, loss_ce: 0.009499
2021-12-13 01:51:40,645 iteration 6566 : loss : 0.045272, loss_ce: 0.016630
2021-12-13 01:51:42,135 iteration 6567 : loss : 0.039119, loss_ce: 0.011484
2021-12-13 01:51:43,603 iteration 6568 : loss : 0.018138, loss_ce: 0.006978
2021-12-13 01:51:45,051 iteration 6569 : loss : 0.029207, loss_ce: 0.009638
2021-12-13 01:51:46,623 iteration 6570 : loss : 0.029584, loss_ce: 0.013533
2021-12-13 01:51:48,024 iteration 6571 : loss : 0.021799, loss_ce: 0.009527
2021-12-13 01:51:49,458 iteration 6572 : loss : 0.027680, loss_ce: 0.010444
2021-12-13 01:51:50,876 iteration 6573 : loss : 0.025498, loss_ce: 0.008492
2021-12-13 01:51:52,369 iteration 6574 : loss : 0.025977, loss_ce: 0.010394
2021-12-13 01:51:53,744 iteration 6575 : loss : 0.020543, loss_ce: 0.008527
2021-12-13 01:51:55,222 iteration 6576 : loss : 0.030364, loss_ce: 0.013029
2021-12-13 01:51:56,728 iteration 6577 : loss : 0.029897, loss_ce: 0.011074
2021-12-13 01:51:58,226 iteration 6578 : loss : 0.039892, loss_ce: 0.020944
2021-12-13 01:51:59,687 iteration 6579 : loss : 0.027039, loss_ce: 0.007419
 97%|████████████████████████████ | 387/400 [2:56:41<05:50, 26.99s/it]2021-12-13 01:52:01,243 iteration 6580 : loss : 0.025938, loss_ce: 0.010069
2021-12-13 01:52:02,763 iteration 6581 : loss : 0.045160, loss_ce: 0.013230
2021-12-13 01:52:04,299 iteration 6582 : loss : 0.033212, loss_ce: 0.013967
2021-12-13 01:52:05,778 iteration 6583 : loss : 0.018905, loss_ce: 0.007852
2021-12-13 01:52:07,273 iteration 6584 : loss : 0.030643, loss_ce: 0.011855
2021-12-13 01:52:08,701 iteration 6585 : loss : 0.025963, loss_ce: 0.008791
2021-12-13 01:52:10,186 iteration 6586 : loss : 0.029378, loss_ce: 0.011782
2021-12-13 01:52:11,596 iteration 6587 : loss : 0.029256, loss_ce: 0.011896
2021-12-13 01:52:13,120 iteration 6588 : loss : 0.024820, loss_ce: 0.009805
2021-12-13 01:52:14,596 iteration 6589 : loss : 0.027019, loss_ce: 0.009551
2021-12-13 01:52:16,046 iteration 6590 : loss : 0.027111, loss_ce: 0.010654
2021-12-13 01:52:17,474 iteration 6591 : loss : 0.034079, loss_ce: 0.014187
2021-12-13 01:52:18,949 iteration 6592 : loss : 0.027593, loss_ce: 0.011318
2021-12-13 01:52:20,488 iteration 6593 : loss : 0.033171, loss_ce: 0.015138
2021-12-13 01:52:21,933 iteration 6594 : loss : 0.025489, loss_ce: 0.009765
2021-12-13 01:52:23,337 iteration 6595 : loss : 0.024797, loss_ce: 0.008678
2021-12-13 01:52:24,762 iteration 6596 : loss : 0.016049, loss_ce: 0.006700
 97%|████████████████████████████▏| 388/400 [2:57:06<05:17, 26.42s/it]2021-12-13 01:52:26,335 iteration 6597 : loss : 0.030119, loss_ce: 0.013850
2021-12-13 01:52:27,868 iteration 6598 : loss : 0.036152, loss_ce: 0.010116
2021-12-13 01:52:29,291 iteration 6599 : loss : 0.024968, loss_ce: 0.009542
2021-12-13 01:52:30,803 iteration 6600 : loss : 0.028102, loss_ce: 0.010266
2021-12-13 01:52:32,216 iteration 6601 : loss : 0.022409, loss_ce: 0.009286
2021-12-13 01:52:33,584 iteration 6602 : loss : 0.022169, loss_ce: 0.008047
2021-12-13 01:52:35,079 iteration 6603 : loss : 0.040066, loss_ce: 0.013398
2021-12-13 01:52:36,648 iteration 6604 : loss : 0.026308, loss_ce: 0.009441
2021-12-13 01:52:38,146 iteration 6605 : loss : 0.034842, loss_ce: 0.015320
2021-12-13 01:52:39,636 iteration 6606 : loss : 0.030923, loss_ce: 0.014502
2021-12-13 01:52:41,071 iteration 6607 : loss : 0.028835, loss_ce: 0.011785
2021-12-13 01:52:42,579 iteration 6608 : loss : 0.031233, loss_ce: 0.012706
2021-12-13 01:52:44,115 iteration 6609 : loss : 0.025939, loss_ce: 0.010530
2021-12-13 01:52:45,571 iteration 6610 : loss : 0.029797, loss_ce: 0.008464
2021-12-13 01:52:46,944 iteration 6611 : loss : 0.022601, loss_ce: 0.010269
2021-12-13 01:52:48,421 iteration 6612 : loss : 0.023717, loss_ce: 0.009485
2021-12-13 01:52:49,939 iteration 6613 : loss : 0.046505, loss_ce: 0.013081
 97%|████████████████████████████▏| 389/400 [2:57:31<04:46, 26.05s/it]2021-12-13 01:52:51,350 iteration 6614 : loss : 0.021764, loss_ce: 0.008702
2021-12-13 01:52:52,860 iteration 6615 : loss : 0.030292, loss_ce: 0.012129
2021-12-13 01:52:54,359 iteration 6616 : loss : 0.025380, loss_ce: 0.010459
2021-12-13 01:52:55,793 iteration 6617 : loss : 0.027738, loss_ce: 0.006665
2021-12-13 01:52:57,272 iteration 6618 : loss : 0.026364, loss_ce: 0.008736
2021-12-13 01:52:58,797 iteration 6619 : loss : 0.026503, loss_ce: 0.009470
2021-12-13 01:53:00,271 iteration 6620 : loss : 0.030778, loss_ce: 0.010667
2021-12-13 01:53:01,673 iteration 6621 : loss : 0.023431, loss_ce: 0.010381
2021-12-13 01:53:03,029 iteration 6622 : loss : 0.021774, loss_ce: 0.007322
2021-12-13 01:53:04,498 iteration 6623 : loss : 0.026103, loss_ce: 0.013298
2021-12-13 01:53:05,852 iteration 6624 : loss : 0.022351, loss_ce: 0.008490
2021-12-13 01:53:07,211 iteration 6625 : loss : 0.020385, loss_ce: 0.008624
2021-12-13 01:53:08,669 iteration 6626 : loss : 0.032072, loss_ce: 0.012187
2021-12-13 01:53:10,077 iteration 6627 : loss : 0.021212, loss_ce: 0.007686
2021-12-13 01:53:11,578 iteration 6628 : loss : 0.035654, loss_ce: 0.013145
2021-12-13 01:53:13,007 iteration 6629 : loss : 0.026212, loss_ce: 0.011070
2021-12-13 01:53:13,007 Training Data Eval:
2021-12-13 01:53:20,541   Average segmentation loss on training set: 0.0144
2021-12-13 01:53:20,541 Validation Data Eval:
2021-12-13 01:53:23,143   Average segmentation loss on validation set: 0.0817
2021-12-13 01:53:24,616 iteration 6630 : loss : 0.031594, loss_ce: 0.011818
 98%|████████████████████████████▎| 390/400 [2:58:06<04:46, 28.63s/it]2021-12-13 01:53:26,025 iteration 6631 : loss : 0.022357, loss_ce: 0.008646
2021-12-13 01:53:27,518 iteration 6632 : loss : 0.025859, loss_ce: 0.006468
2021-12-13 01:53:28,982 iteration 6633 : loss : 0.026560, loss_ce: 0.009734
2021-12-13 01:53:30,399 iteration 6634 : loss : 0.029905, loss_ce: 0.013210
2021-12-13 01:53:31,906 iteration 6635 : loss : 0.024858, loss_ce: 0.009161
2021-12-13 01:53:33,331 iteration 6636 : loss : 0.024968, loss_ce: 0.012970
2021-12-13 01:53:34,820 iteration 6637 : loss : 0.029238, loss_ce: 0.010096
2021-12-13 01:53:36,302 iteration 6638 : loss : 0.020454, loss_ce: 0.007099
2021-12-13 01:53:37,782 iteration 6639 : loss : 0.033850, loss_ce: 0.010927
2021-12-13 01:53:39,273 iteration 6640 : loss : 0.030781, loss_ce: 0.009429
2021-12-13 01:53:40,726 iteration 6641 : loss : 0.024024, loss_ce: 0.010059
2021-12-13 01:53:42,184 iteration 6642 : loss : 0.026290, loss_ce: 0.008895
2021-12-13 01:53:43,722 iteration 6643 : loss : 0.029391, loss_ce: 0.013793
2021-12-13 01:53:45,282 iteration 6644 : loss : 0.032026, loss_ce: 0.014293
2021-12-13 01:53:46,742 iteration 6645 : loss : 0.025828, loss_ce: 0.011363
2021-12-13 01:53:48,208 iteration 6646 : loss : 0.031708, loss_ce: 0.014493
2021-12-13 01:53:49,682 iteration 6647 : loss : 0.041095, loss_ce: 0.011543
 98%|████████████████████████████▎| 391/400 [2:58:31<04:08, 27.56s/it]2021-12-13 01:53:51,234 iteration 6648 : loss : 0.026627, loss_ce: 0.010208
2021-12-13 01:53:52,747 iteration 6649 : loss : 0.031524, loss_ce: 0.010067
2021-12-13 01:53:54,163 iteration 6650 : loss : 0.025577, loss_ce: 0.010294
2021-12-13 01:53:55,611 iteration 6651 : loss : 0.027802, loss_ce: 0.013537
2021-12-13 01:53:57,123 iteration 6652 : loss : 0.044860, loss_ce: 0.014907
2021-12-13 01:53:58,654 iteration 6653 : loss : 0.027561, loss_ce: 0.009202
2021-12-13 01:54:00,246 iteration 6654 : loss : 0.029472, loss_ce: 0.010099
2021-12-13 01:54:01,702 iteration 6655 : loss : 0.022046, loss_ce: 0.009978
2021-12-13 01:54:03,272 iteration 6656 : loss : 0.030702, loss_ce: 0.011992
2021-12-13 01:54:04,762 iteration 6657 : loss : 0.031126, loss_ce: 0.010732
2021-12-13 01:54:06,293 iteration 6658 : loss : 0.030347, loss_ce: 0.011561
2021-12-13 01:54:07,779 iteration 6659 : loss : 0.033958, loss_ce: 0.011333
2021-12-13 01:54:09,258 iteration 6660 : loss : 0.024378, loss_ce: 0.010966
2021-12-13 01:54:10,686 iteration 6661 : loss : 0.023818, loss_ce: 0.009162
2021-12-13 01:54:12,193 iteration 6662 : loss : 0.032384, loss_ce: 0.013357
2021-12-13 01:54:13,633 iteration 6663 : loss : 0.023453, loss_ce: 0.009568
2021-12-13 01:54:15,147 iteration 6664 : loss : 0.025245, loss_ce: 0.011760
 98%|████████████████████████████▍| 392/400 [2:58:57<03:35, 26.94s/it]2021-12-13 01:54:16,676 iteration 6665 : loss : 0.040271, loss_ce: 0.013224
2021-12-13 01:54:18,189 iteration 6666 : loss : 0.021849, loss_ce: 0.007343
2021-12-13 01:54:19,663 iteration 6667 : loss : 0.031509, loss_ce: 0.012490
2021-12-13 01:54:21,277 iteration 6668 : loss : 0.035585, loss_ce: 0.016399
2021-12-13 01:54:22,698 iteration 6669 : loss : 0.028869, loss_ce: 0.011038
2021-12-13 01:54:24,124 iteration 6670 : loss : 0.021676, loss_ce: 0.008731
2021-12-13 01:54:25,566 iteration 6671 : loss : 0.026194, loss_ce: 0.011408
2021-12-13 01:54:26,954 iteration 6672 : loss : 0.019646, loss_ce: 0.006476
2021-12-13 01:54:28,455 iteration 6673 : loss : 0.031167, loss_ce: 0.011354
2021-12-13 01:54:29,918 iteration 6674 : loss : 0.023931, loss_ce: 0.011129
2021-12-13 01:54:31,446 iteration 6675 : loss : 0.028223, loss_ce: 0.009165
2021-12-13 01:54:32,863 iteration 6676 : loss : 0.020626, loss_ce: 0.006924
2021-12-13 01:54:34,313 iteration 6677 : loss : 0.026408, loss_ce: 0.007893
2021-12-13 01:54:35,664 iteration 6678 : loss : 0.020301, loss_ce: 0.008541
2021-12-13 01:54:37,244 iteration 6679 : loss : 0.027225, loss_ce: 0.011772
2021-12-13 01:54:38,714 iteration 6680 : loss : 0.032843, loss_ce: 0.011838
2021-12-13 01:54:40,228 iteration 6681 : loss : 0.027234, loss_ce: 0.012590
 98%|████████████████████████████▍| 393/400 [2:59:22<03:04, 26.38s/it]2021-12-13 01:54:41,747 iteration 6682 : loss : 0.024783, loss_ce: 0.011234
2021-12-13 01:54:43,318 iteration 6683 : loss : 0.025803, loss_ce: 0.009002
2021-12-13 01:54:44,747 iteration 6684 : loss : 0.025712, loss_ce: 0.008533
2021-12-13 01:54:46,274 iteration 6685 : loss : 0.033456, loss_ce: 0.014023
2021-12-13 01:54:47,692 iteration 6686 : loss : 0.031504, loss_ce: 0.012020
2021-12-13 01:54:49,155 iteration 6687 : loss : 0.029383, loss_ce: 0.007172
2021-12-13 01:54:50,675 iteration 6688 : loss : 0.033597, loss_ce: 0.013314
2021-12-13 01:54:52,122 iteration 6689 : loss : 0.022157, loss_ce: 0.008593
2021-12-13 01:54:53,571 iteration 6690 : loss : 0.026481, loss_ce: 0.011617
2021-12-13 01:54:55,099 iteration 6691 : loss : 0.034193, loss_ce: 0.013102
2021-12-13 01:54:56,596 iteration 6692 : loss : 0.035106, loss_ce: 0.011054
2021-12-13 01:54:58,126 iteration 6693 : loss : 0.024931, loss_ce: 0.008598
2021-12-13 01:54:59,639 iteration 6694 : loss : 0.026427, loss_ce: 0.010657
2021-12-13 01:55:01,166 iteration 6695 : loss : 0.028760, loss_ce: 0.012486
2021-12-13 01:55:02,583 iteration 6696 : loss : 0.026012, loss_ce: 0.011926
2021-12-13 01:55:04,112 iteration 6697 : loss : 0.031888, loss_ce: 0.012262
2021-12-13 01:55:05,610 iteration 6698 : loss : 0.022809, loss_ce: 0.007899
 98%|████████████████████████████▌| 394/400 [2:59:47<02:36, 26.08s/it]2021-12-13 01:55:07,087 iteration 6699 : loss : 0.024619, loss_ce: 0.013313
2021-12-13 01:55:08,627 iteration 6700 : loss : 0.039557, loss_ce: 0.016957
2021-12-13 01:55:10,085 iteration 6701 : loss : 0.028632, loss_ce: 0.012077
2021-12-13 01:55:11,538 iteration 6702 : loss : 0.033386, loss_ce: 0.010526
2021-12-13 01:55:12,995 iteration 6703 : loss : 0.024569, loss_ce: 0.007846
2021-12-13 01:55:14,510 iteration 6704 : loss : 0.032376, loss_ce: 0.011018
2021-12-13 01:55:15,948 iteration 6705 : loss : 0.032843, loss_ce: 0.011039
2021-12-13 01:55:17,377 iteration 6706 : loss : 0.021013, loss_ce: 0.010095
2021-12-13 01:55:18,806 iteration 6707 : loss : 0.028966, loss_ce: 0.008333
2021-12-13 01:55:20,194 iteration 6708 : loss : 0.020748, loss_ce: 0.007959
2021-12-13 01:55:21,632 iteration 6709 : loss : 0.026095, loss_ce: 0.009503
2021-12-13 01:55:23,060 iteration 6710 : loss : 0.021311, loss_ce: 0.008227
2021-12-13 01:55:24,487 iteration 6711 : loss : 0.031230, loss_ce: 0.006281
2021-12-13 01:55:25,978 iteration 6712 : loss : 0.029819, loss_ce: 0.011794
2021-12-13 01:55:27,521 iteration 6713 : loss : 0.032363, loss_ce: 0.013515
2021-12-13 01:55:29,011 iteration 6714 : loss : 0.030031, loss_ce: 0.014303
2021-12-13 01:55:29,011 Training Data Eval:
2021-12-13 01:55:36,535   Average segmentation loss on training set: 0.0143
2021-12-13 01:55:36,536 Validation Data Eval:
2021-12-13 01:55:39,132   Average segmentation loss on validation set: 0.0879
2021-12-13 01:55:40,645 iteration 6715 : loss : 0.024435, loss_ce: 0.009682
 99%|████████████████████████████▋| 395/400 [3:00:22<02:23, 28.77s/it]2021-12-13 01:55:42,165 iteration 6716 : loss : 0.017161, loss_ce: 0.006772
2021-12-13 01:55:43,640 iteration 6717 : loss : 0.033810, loss_ce: 0.013862
2021-12-13 01:55:45,045 iteration 6718 : loss : 0.021986, loss_ce: 0.007967
2021-12-13 01:55:46,494 iteration 6719 : loss : 0.025483, loss_ce: 0.008714
2021-12-13 01:55:47,953 iteration 6720 : loss : 0.022947, loss_ce: 0.008554
2021-12-13 01:55:49,458 iteration 6721 : loss : 0.031554, loss_ce: 0.011674
2021-12-13 01:55:50,970 iteration 6722 : loss : 0.033769, loss_ce: 0.009440
2021-12-13 01:55:52,434 iteration 6723 : loss : 0.034786, loss_ce: 0.010850
2021-12-13 01:55:53,879 iteration 6724 : loss : 0.026459, loss_ce: 0.011157
2021-12-13 01:55:55,382 iteration 6725 : loss : 0.021634, loss_ce: 0.009004
2021-12-13 01:55:56,860 iteration 6726 : loss : 0.032158, loss_ce: 0.009843
2021-12-13 01:55:58,363 iteration 6727 : loss : 0.034144, loss_ce: 0.015715
2021-12-13 01:55:59,880 iteration 6728 : loss : 0.025810, loss_ce: 0.013115
2021-12-13 01:56:01,293 iteration 6729 : loss : 0.025583, loss_ce: 0.008096
2021-12-13 01:56:02,734 iteration 6730 : loss : 0.028756, loss_ce: 0.009744
2021-12-13 01:56:04,169 iteration 6731 : loss : 0.028713, loss_ce: 0.010829
2021-12-13 01:56:05,636 iteration 6732 : loss : 0.024601, loss_ce: 0.012187
 99%|████████████████████████████▋| 396/400 [3:00:47<01:50, 27.63s/it]2021-12-13 01:56:07,188 iteration 6733 : loss : 0.029716, loss_ce: 0.012776
2021-12-13 01:56:08,611 iteration 6734 : loss : 0.015074, loss_ce: 0.005441
2021-12-13 01:56:10,088 iteration 6735 : loss : 0.029773, loss_ce: 0.014898
2021-12-13 01:56:11,556 iteration 6736 : loss : 0.024548, loss_ce: 0.008267
2021-12-13 01:56:12,986 iteration 6737 : loss : 0.019261, loss_ce: 0.009118
2021-12-13 01:56:14,444 iteration 6738 : loss : 0.023415, loss_ce: 0.008604
2021-12-13 01:56:15,960 iteration 6739 : loss : 0.030005, loss_ce: 0.012279
2021-12-13 01:56:17,502 iteration 6740 : loss : 0.027174, loss_ce: 0.010871
2021-12-13 01:56:18,915 iteration 6741 : loss : 0.020961, loss_ce: 0.009087
2021-12-13 01:56:20,431 iteration 6742 : loss : 0.029950, loss_ce: 0.012357
2021-12-13 01:56:21,943 iteration 6743 : loss : 0.030795, loss_ce: 0.009924
2021-12-13 01:56:23,495 iteration 6744 : loss : 0.028433, loss_ce: 0.010275
2021-12-13 01:56:24,934 iteration 6745 : loss : 0.029186, loss_ce: 0.008966
2021-12-13 01:56:26,375 iteration 6746 : loss : 0.029027, loss_ce: 0.014949
2021-12-13 01:56:27,834 iteration 6747 : loss : 0.033012, loss_ce: 0.011130
2021-12-13 01:56:29,312 iteration 6748 : loss : 0.024689, loss_ce: 0.009225
2021-12-13 01:56:30,818 iteration 6749 : loss : 0.031998, loss_ce: 0.012126
 99%|████████████████████████████▊| 397/400 [3:01:12<01:20, 26.90s/it]2021-12-13 01:56:32,307 iteration 6750 : loss : 0.022315, loss_ce: 0.008497
2021-12-13 01:56:33,821 iteration 6751 : loss : 0.039234, loss_ce: 0.018770
2021-12-13 01:56:35,329 iteration 6752 : loss : 0.035119, loss_ce: 0.017622
2021-12-13 01:56:36,806 iteration 6753 : loss : 0.028133, loss_ce: 0.011187
2021-12-13 01:56:38,324 iteration 6754 : loss : 0.031658, loss_ce: 0.009863
2021-12-13 01:56:39,791 iteration 6755 : loss : 0.018853, loss_ce: 0.006010
2021-12-13 01:56:41,267 iteration 6756 : loss : 0.019972, loss_ce: 0.008044
2021-12-13 01:56:42,750 iteration 6757 : loss : 0.032057, loss_ce: 0.013808
2021-12-13 01:56:44,175 iteration 6758 : loss : 0.019158, loss_ce: 0.007665
2021-12-13 01:56:45,678 iteration 6759 : loss : 0.027677, loss_ce: 0.009680
2021-12-13 01:56:47,136 iteration 6760 : loss : 0.024345, loss_ce: 0.010064
2021-12-13 01:56:48,648 iteration 6761 : loss : 0.026519, loss_ce: 0.011549
2021-12-13 01:56:50,024 iteration 6762 : loss : 0.019837, loss_ce: 0.007656
2021-12-13 01:56:51,495 iteration 6763 : loss : 0.031122, loss_ce: 0.008919
2021-12-13 01:56:52,942 iteration 6764 : loss : 0.025760, loss_ce: 0.009573
2021-12-13 01:56:54,365 iteration 6765 : loss : 0.023921, loss_ce: 0.008634
2021-12-13 01:56:55,809 iteration 6766 : loss : 0.031243, loss_ce: 0.011996
100%|████████████████████████████▊| 398/400 [3:01:37<00:52, 26.33s/it]2021-12-13 01:56:57,426 iteration 6767 : loss : 0.024467, loss_ce: 0.008290
2021-12-13 01:56:58,837 iteration 6768 : loss : 0.029423, loss_ce: 0.013995
2021-12-13 01:57:00,311 iteration 6769 : loss : 0.027120, loss_ce: 0.009065
2021-12-13 01:57:01,715 iteration 6770 : loss : 0.019960, loss_ce: 0.008205
2021-12-13 01:57:03,170 iteration 6771 : loss : 0.024357, loss_ce: 0.007480
2021-12-13 01:57:04,705 iteration 6772 : loss : 0.044284, loss_ce: 0.012689
2021-12-13 01:57:06,207 iteration 6773 : loss : 0.022302, loss_ce: 0.009945
2021-12-13 01:57:07,671 iteration 6774 : loss : 0.026826, loss_ce: 0.011018
2021-12-13 01:57:09,122 iteration 6775 : loss : 0.032153, loss_ce: 0.011749
2021-12-13 01:57:10,644 iteration 6776 : loss : 0.034739, loss_ce: 0.014780
2021-12-13 01:57:12,117 iteration 6777 : loss : 0.027118, loss_ce: 0.010743
2021-12-13 01:57:13,544 iteration 6778 : loss : 0.021217, loss_ce: 0.007185
2021-12-13 01:57:14,987 iteration 6779 : loss : 0.024300, loss_ce: 0.008644
2021-12-13 01:57:16,375 iteration 6780 : loss : 0.023337, loss_ce: 0.007882
2021-12-13 01:57:17,789 iteration 6781 : loss : 0.022305, loss_ce: 0.010471
2021-12-13 01:57:19,253 iteration 6782 : loss : 0.020276, loss_ce: 0.008808
2021-12-13 01:57:20,721 iteration 6783 : loss : 0.022311, loss_ce: 0.009120
100%|████████████████████████████▉| 399/400 [3:02:02<00:25, 25.90s/it]2021-12-13 01:57:22,340 iteration 6784 : loss : 0.039126, loss_ce: 0.012566
2021-12-13 01:57:23,744 iteration 6785 : loss : 0.030430, loss_ce: 0.013946
2021-12-13 01:57:25,116 iteration 6786 : loss : 0.023574, loss_ce: 0.010248
2021-12-13 01:57:26,601 iteration 6787 : loss : 0.024181, loss_ce: 0.008233
2021-12-13 01:57:27,996 iteration 6788 : loss : 0.034228, loss_ce: 0.009224
2021-12-13 01:57:29,475 iteration 6789 : loss : 0.021403, loss_ce: 0.010066
2021-12-13 01:57:30,967 iteration 6790 : loss : 0.025279, loss_ce: 0.009239
2021-12-13 01:57:32,499 iteration 6791 : loss : 0.051618, loss_ce: 0.014692
2021-12-13 01:57:34,005 iteration 6792 : loss : 0.023195, loss_ce: 0.008635
2021-12-13 01:57:35,474 iteration 6793 : loss : 0.022471, loss_ce: 0.008437
2021-12-13 01:57:36,964 iteration 6794 : loss : 0.023357, loss_ce: 0.008815
2021-12-13 01:57:38,435 iteration 6795 : loss : 0.023325, loss_ce: 0.009201
2021-12-13 01:57:39,899 iteration 6796 : loss : 0.023660, loss_ce: 0.009496
2021-12-13 01:57:41,319 iteration 6797 : loss : 0.025521, loss_ce: 0.009463
2021-12-13 01:57:42,705 iteration 6798 : loss : 0.027331, loss_ce: 0.010162
2021-12-13 01:57:44,165 iteration 6799 : loss : 0.031410, loss_ce: 0.016212
2021-12-13 01:57:44,165 Training Data Eval:
2021-12-13 01:57:51,695   Average segmentation loss on training set: 0.0146
2021-12-13 01:57:51,695 Validation Data Eval:
2021-12-13 01:57:54,291   Average segmentation loss on validation set: 0.0800
2021-12-13 01:57:55,739 iteration 6800 : loss : 0.032190, loss_ce: 0.013913
100%|█████████████████████████████| 400/400 [3:02:37<00:00, 28.64s/it]100%|█████████████████████████████| 400/400 [3:02:37<00:00, 27.39s/it]
