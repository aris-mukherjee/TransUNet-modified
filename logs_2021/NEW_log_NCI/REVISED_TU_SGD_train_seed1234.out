2021-12-14 01:05:03,048 Logging directory: /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/TransUNet/log_dir/trRUNMC_cv1_r3/i2i2l/
2021-12-14 01:05:03,048 Tensorboard directory: /scratch_net/biwidl217_second/arismu/Tensorboard/trRUNMC_cv1_r3/i2i2l/
2021-12-14 01:05:03,048 ============================================================
2021-12-14 01:05:03,048 EXPERIMENT NAME: trRUNMC_cv1_r3/i2i2l/
2021-12-14 01:05:03,048 ============================================================
2021-12-14 01:05:03,048 Loading data...
2021-12-14 01:05:03,048 Reading NCI - RUNMC images...
2021-12-14 01:05:03,049 Data root directory: /itet-stor/arismu/bmicdatasets-originals/Originals/Challenge_Datasets/NCI_Prostate/
2021-12-14 01:05:03,049 Already preprocessed this configuration. Loading now!
2021-12-14 01:05:03,065 Training Images: (256, 256, 286)
2021-12-14 01:05:03,065 Training Labels: (256, 256, 286)
2021-12-14 01:05:03,065 Validation Images: (256, 256, 98)
2021-12-14 01:05:03,065 Validation Labels: (256, 256, 98)
2021-12-14 01:05:03,065 ============================================================
2021-12-14 01:05:03,094 17 iterations per epoch. 6800 max iterations 
  0%|                                         | 0/400 [00:00<?, ?it/s]2021-12-14 01:05:05,513 iteration 1 : loss : 0.985389, loss_ce: 1.214448
2021-12-14 01:05:06,907 iteration 2 : loss : 0.979759, loss_ce: 1.206514
2021-12-14 01:05:08,412 iteration 3 : loss : 0.973046, loss_ce: 1.191330
2021-12-14 01:05:09,832 iteration 4 : loss : 0.961804, loss_ce: 1.167880
2021-12-14 01:05:11,247 iteration 5 : loss : 0.941915, loss_ce: 1.141417
2021-12-14 01:05:12,677 iteration 6 : loss : 0.923493, loss_ce: 1.105120
2021-12-14 01:05:14,168 iteration 7 : loss : 0.893787, loss_ce: 1.067267
2021-12-14 01:05:15,682 iteration 8 : loss : 0.887656, loss_ce: 1.028527
2021-12-14 01:05:17,233 iteration 9 : loss : 0.838446, loss_ce: 0.992880
2021-12-14 01:05:18,813 iteration 10 : loss : 0.837703, loss_ce: 0.944495
2021-12-14 01:05:20,437 iteration 11 : loss : 0.795725, loss_ce: 0.903839
2021-12-14 01:05:21,971 iteration 12 : loss : 0.772375, loss_ce: 0.858058
2021-12-14 01:05:23,513 iteration 13 : loss : 0.753478, loss_ce: 0.818148
2021-12-14 01:05:25,030 iteration 14 : loss : 0.725994, loss_ce: 0.780108
2021-12-14 01:05:26,618 iteration 15 : loss : 0.701172, loss_ce: 0.740063
2021-12-14 01:05:28,190 iteration 16 : loss : 0.686049, loss_ce: 0.708113
2021-12-14 01:05:29,751 iteration 17 : loss : 0.646195, loss_ce: 0.665636
  0%|                               | 1/400 [00:26<2:57:43, 26.73s/it]2021-12-14 01:05:31,413 iteration 18 : loss : 0.647282, loss_ce: 0.624692
2021-12-14 01:05:32,918 iteration 19 : loss : 0.615936, loss_ce: 0.596133
2021-12-14 01:05:34,549 iteration 20 : loss : 0.592135, loss_ce: 0.561981
2021-12-14 01:05:36,094 iteration 21 : loss : 0.591123, loss_ce: 0.531041
2021-12-14 01:05:37,658 iteration 22 : loss : 0.557582, loss_ce: 0.515968
2021-12-14 01:05:39,308 iteration 23 : loss : 0.554334, loss_ce: 0.472860
2021-12-14 01:05:40,887 iteration 24 : loss : 0.532812, loss_ce: 0.458109
2021-12-14 01:05:42,519 iteration 25 : loss : 0.514680, loss_ce: 0.456354
2021-12-14 01:05:44,073 iteration 26 : loss : 0.501971, loss_ce: 0.418552
2021-12-14 01:05:45,573 iteration 27 : loss : 0.493483, loss_ce: 0.407857
2021-12-14 01:05:47,089 iteration 28 : loss : 0.479602, loss_ce: 0.376570
2021-12-14 01:05:48,704 iteration 29 : loss : 0.478758, loss_ce: 0.367004
2021-12-14 01:05:50,305 iteration 30 : loss : 0.457987, loss_ce: 0.349336
2021-12-14 01:05:51,820 iteration 31 : loss : 0.454050, loss_ce: 0.347359
2021-12-14 01:05:53,449 iteration 32 : loss : 0.445908, loss_ce: 0.344651
2021-12-14 01:05:55,056 iteration 33 : loss : 0.435168, loss_ce: 0.323265
2021-12-14 01:05:56,683 iteration 34 : loss : 0.429583, loss_ce: 0.323820
  0%|▏                              | 2/400 [00:53<2:58:00, 26.84s/it]2021-12-14 01:05:58,332 iteration 35 : loss : 0.425054, loss_ce: 0.287683
2021-12-14 01:05:59,958 iteration 36 : loss : 0.422140, loss_ce: 0.286871
2021-12-14 01:06:01,593 iteration 37 : loss : 0.413946, loss_ce: 0.263535
2021-12-14 01:06:03,145 iteration 38 : loss : 0.397483, loss_ce: 0.271216
2021-12-14 01:06:04,727 iteration 39 : loss : 0.397015, loss_ce: 0.266267
2021-12-14 01:06:06,359 iteration 40 : loss : 0.398284, loss_ce: 0.261997
2021-12-14 01:06:07,981 iteration 41 : loss : 0.404437, loss_ce: 0.263164
2021-12-14 01:06:09,576 iteration 42 : loss : 0.401137, loss_ce: 0.250846
2021-12-14 01:06:11,082 iteration 43 : loss : 0.388013, loss_ce: 0.232759
2021-12-14 01:06:12,727 iteration 44 : loss : 0.371616, loss_ce: 0.231179
2021-12-14 01:06:14,305 iteration 45 : loss : 0.370677, loss_ce: 0.230612
2021-12-14 01:06:15,898 iteration 46 : loss : 0.368886, loss_ce: 0.211671
2021-12-14 01:06:17,529 iteration 47 : loss : 0.355943, loss_ce: 0.207150
2021-12-14 01:06:19,135 iteration 48 : loss : 0.358867, loss_ce: 0.211505
2021-12-14 01:06:20,772 iteration 49 : loss : 0.383447, loss_ce: 0.223575
2021-12-14 01:06:22,311 iteration 50 : loss : 0.380715, loss_ce: 0.210946
2021-12-14 01:06:23,849 iteration 51 : loss : 0.364660, loss_ce: 0.210818
  1%|▏                              | 3/400 [01:20<2:58:33, 26.99s/it]2021-12-14 01:06:25,523 iteration 52 : loss : 0.365866, loss_ce: 0.220943
2021-12-14 01:06:27,135 iteration 53 : loss : 0.358084, loss_ce: 0.205292
2021-12-14 01:06:28,718 iteration 54 : loss : 0.350508, loss_ce: 0.181528
2021-12-14 01:06:30,315 iteration 55 : loss : 0.368852, loss_ce: 0.216248
2021-12-14 01:06:31,894 iteration 56 : loss : 0.350586, loss_ce: 0.190043
2021-12-14 01:06:33,494 iteration 57 : loss : 0.333934, loss_ce: 0.178476
2021-12-14 01:06:35,102 iteration 58 : loss : 0.345517, loss_ce: 0.182119
2021-12-14 01:06:36,676 iteration 59 : loss : 0.341797, loss_ce: 0.196049
2021-12-14 01:06:38,284 iteration 60 : loss : 0.355399, loss_ce: 0.193132
2021-12-14 01:06:39,875 iteration 61 : loss : 0.345683, loss_ce: 0.194721
2021-12-14 01:06:41,450 iteration 62 : loss : 0.369408, loss_ce: 0.163710
2021-12-14 01:06:42,956 iteration 63 : loss : 0.344375, loss_ce: 0.189785
2021-12-14 01:06:44,519 iteration 64 : loss : 0.389153, loss_ce: 0.196684
2021-12-14 01:06:46,035 iteration 65 : loss : 0.332262, loss_ce: 0.162072
2021-12-14 01:06:47,591 iteration 66 : loss : 0.320816, loss_ce: 0.177903
2021-12-14 01:06:49,222 iteration 67 : loss : 0.326132, loss_ce: 0.155437
2021-12-14 01:06:50,789 iteration 68 : loss : 0.319155, loss_ce: 0.180408
  1%|▎                              | 4/400 [01:47<2:58:00, 26.97s/it]2021-12-14 01:06:52,440 iteration 69 : loss : 0.312469, loss_ce: 0.165910
2021-12-14 01:06:54,099 iteration 70 : loss : 0.320348, loss_ce: 0.166024
2021-12-14 01:06:55,646 iteration 71 : loss : 0.314999, loss_ce: 0.162481
2021-12-14 01:06:57,238 iteration 72 : loss : 0.307481, loss_ce: 0.157512
2021-12-14 01:06:58,777 iteration 73 : loss : 0.314280, loss_ce: 0.172782
2021-12-14 01:07:00,283 iteration 74 : loss : 0.302159, loss_ce: 0.154099
2021-12-14 01:07:01,822 iteration 75 : loss : 0.307982, loss_ce: 0.154571
2021-12-14 01:07:03,355 iteration 76 : loss : 0.300615, loss_ce: 0.150618
2021-12-14 01:07:04,807 iteration 77 : loss : 0.310120, loss_ce: 0.157494
2021-12-14 01:07:06,361 iteration 78 : loss : 0.314396, loss_ce: 0.159555
2021-12-14 01:07:07,888 iteration 79 : loss : 0.326249, loss_ce: 0.151897
2021-12-14 01:07:09,401 iteration 80 : loss : 0.318754, loss_ce: 0.171062
2021-12-14 01:07:10,904 iteration 81 : loss : 0.294202, loss_ce: 0.143679
2021-12-14 01:07:12,435 iteration 82 : loss : 0.300311, loss_ce: 0.140368
2021-12-14 01:07:13,961 iteration 83 : loss : 0.300115, loss_ce: 0.136258
2021-12-14 01:07:15,577 iteration 84 : loss : 0.333705, loss_ce: 0.192105
2021-12-14 01:07:15,577 Training Data Eval:
2021-12-14 01:07:23,665   Average segmentation loss on training set: 0.3144
2021-12-14 01:07:23,665 Validation Data Eval:
2021-12-14 01:07:26,604   Average segmentation loss on validation set: 0.2921
2021-12-14 01:07:32,941 Found new lowest validation loss at iteration 84! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/TU_3seeds/REVISED_SGD_best_val_loss_seed1234.pth
2021-12-14 01:07:34,388 iteration 85 : loss : 0.309582, loss_ce: 0.146309
  1%|▍                              | 5/400 [02:31<3:37:01, 32.97s/it]2021-12-14 01:07:35,892 iteration 86 : loss : 0.291398, loss_ce: 0.127834
2021-12-14 01:07:37,567 iteration 87 : loss : 0.289359, loss_ce: 0.142907
2021-12-14 01:07:39,085 iteration 88 : loss : 0.283934, loss_ce: 0.143802
2021-12-14 01:07:40,681 iteration 89 : loss : 0.281419, loss_ce: 0.139608
2021-12-14 01:07:42,263 iteration 90 : loss : 0.294957, loss_ce: 0.144012
2021-12-14 01:07:43,906 iteration 91 : loss : 0.287090, loss_ce: 0.155931
2021-12-14 01:07:45,405 iteration 92 : loss : 0.283034, loss_ce: 0.137248
2021-12-14 01:07:46,952 iteration 93 : loss : 0.290351, loss_ce: 0.126432
2021-12-14 01:07:48,518 iteration 94 : loss : 0.286366, loss_ce: 0.133297
2021-12-14 01:07:50,194 iteration 95 : loss : 0.298384, loss_ce: 0.150284
2021-12-14 01:07:51,729 iteration 96 : loss : 0.277503, loss_ce: 0.138790
2021-12-14 01:07:53,271 iteration 97 : loss : 0.287187, loss_ce: 0.139921
2021-12-14 01:07:54,828 iteration 98 : loss : 0.292164, loss_ce: 0.139747
2021-12-14 01:07:56,463 iteration 99 : loss : 0.260955, loss_ce: 0.126861
2021-12-14 01:07:58,051 iteration 100 : loss : 0.270066, loss_ce: 0.136420
2021-12-14 01:07:59,619 iteration 101 : loss : 0.247303, loss_ce: 0.117433
2021-12-14 01:08:01,115 iteration 102 : loss : 0.273112, loss_ce: 0.128656
  2%|▍                              | 6/400 [02:58<3:22:34, 30.85s/it]2021-12-14 01:08:02,826 iteration 103 : loss : 0.257416, loss_ce: 0.125813
2021-12-14 01:08:04,465 iteration 104 : loss : 0.276779, loss_ce: 0.130244
2021-12-14 01:08:06,160 iteration 105 : loss : 0.290427, loss_ce: 0.128888
2021-12-14 01:08:07,689 iteration 106 : loss : 0.289897, loss_ce: 0.131018
2021-12-14 01:08:09,397 iteration 107 : loss : 0.265938, loss_ce: 0.129670
2021-12-14 01:08:10,902 iteration 108 : loss : 0.297038, loss_ce: 0.136386
2021-12-14 01:08:12,440 iteration 109 : loss : 0.251245, loss_ce: 0.128072
2021-12-14 01:08:13,928 iteration 110 : loss : 0.254250, loss_ce: 0.120570
2021-12-14 01:08:15,507 iteration 111 : loss : 0.269961, loss_ce: 0.127206
2021-12-14 01:08:16,999 iteration 112 : loss : 0.256414, loss_ce: 0.119654
2021-12-14 01:08:18,561 iteration 113 : loss : 0.276481, loss_ce: 0.149241
2021-12-14 01:08:20,086 iteration 114 : loss : 0.269387, loss_ce: 0.115245
2021-12-14 01:08:21,633 iteration 115 : loss : 0.268272, loss_ce: 0.129446
2021-12-14 01:08:23,234 iteration 116 : loss : 0.272655, loss_ce: 0.126927
2021-12-14 01:08:24,835 iteration 117 : loss : 0.245495, loss_ce: 0.118956
2021-12-14 01:08:26,399 iteration 118 : loss : 0.277178, loss_ce: 0.129332
2021-12-14 01:08:27,975 iteration 119 : loss : 0.254891, loss_ce: 0.111288
  2%|▌                              | 7/400 [03:24<3:13:29, 29.54s/it]2021-12-14 01:08:29,539 iteration 120 : loss : 0.318434, loss_ce: 0.158437
2021-12-14 01:08:31,041 iteration 121 : loss : 0.256204, loss_ce: 0.119805
2021-12-14 01:08:32,648 iteration 122 : loss : 0.256751, loss_ce: 0.113836
2021-12-14 01:08:34,221 iteration 123 : loss : 0.259600, loss_ce: 0.113666
2021-12-14 01:08:35,771 iteration 124 : loss : 0.236847, loss_ce: 0.101804
2021-12-14 01:08:37,285 iteration 125 : loss : 0.254980, loss_ce: 0.129169
2021-12-14 01:08:38,857 iteration 126 : loss : 0.254033, loss_ce: 0.106479
2021-12-14 01:08:40,366 iteration 127 : loss : 0.266365, loss_ce: 0.123873
2021-12-14 01:08:41,896 iteration 128 : loss : 0.230653, loss_ce: 0.108871
2021-12-14 01:08:43,500 iteration 129 : loss : 0.259257, loss_ce: 0.112403
2021-12-14 01:08:45,045 iteration 130 : loss : 0.249080, loss_ce: 0.107942
2021-12-14 01:08:46,691 iteration 131 : loss : 0.276724, loss_ce: 0.134705
2021-12-14 01:08:48,360 iteration 132 : loss : 0.251126, loss_ce: 0.095248
2021-12-14 01:08:49,901 iteration 133 : loss : 0.230133, loss_ce: 0.099442
2021-12-14 01:08:51,537 iteration 134 : loss : 0.246494, loss_ce: 0.110431
2021-12-14 01:08:53,178 iteration 135 : loss : 0.247527, loss_ce: 0.119954
2021-12-14 01:08:54,733 iteration 136 : loss : 0.241674, loss_ce: 0.115450
  2%|▌                              | 8/400 [03:51<3:07:11, 28.65s/it]2021-12-14 01:08:56,397 iteration 137 : loss : 0.240616, loss_ce: 0.098109
2021-12-14 01:08:57,929 iteration 138 : loss : 0.264007, loss_ce: 0.137515
2021-12-14 01:08:59,517 iteration 139 : loss : 0.254509, loss_ce: 0.110845
2021-12-14 01:09:01,082 iteration 140 : loss : 0.221160, loss_ce: 0.089193
2021-12-14 01:09:02,694 iteration 141 : loss : 0.243652, loss_ce: 0.118370
2021-12-14 01:09:04,319 iteration 142 : loss : 0.255788, loss_ce: 0.112245
2021-12-14 01:09:05,972 iteration 143 : loss : 0.233252, loss_ce: 0.101522
2021-12-14 01:09:07,588 iteration 144 : loss : 0.250436, loss_ce: 0.106900
2021-12-14 01:09:09,148 iteration 145 : loss : 0.237325, loss_ce: 0.102183
2021-12-14 01:09:10,746 iteration 146 : loss : 0.226055, loss_ce: 0.108236
2021-12-14 01:09:12,355 iteration 147 : loss : 0.228260, loss_ce: 0.098217
2021-12-14 01:09:13,839 iteration 148 : loss : 0.245712, loss_ce: 0.111006
2021-12-14 01:09:15,389 iteration 149 : loss : 0.277373, loss_ce: 0.125304
2021-12-14 01:09:16,915 iteration 150 : loss : 0.237170, loss_ce: 0.089875
2021-12-14 01:09:18,448 iteration 151 : loss : 0.237452, loss_ce: 0.104917
2021-12-14 01:09:19,991 iteration 152 : loss : 0.238538, loss_ce: 0.089609
2021-12-14 01:09:21,578 iteration 153 : loss : 0.277403, loss_ce: 0.126051
  2%|▋                              | 9/400 [04:18<3:03:02, 28.09s/it]2021-12-14 01:09:23,126 iteration 154 : loss : 0.253216, loss_ce: 0.110725
2021-12-14 01:09:24,698 iteration 155 : loss : 0.224832, loss_ce: 0.089142
2021-12-14 01:09:26,343 iteration 156 : loss : 0.214076, loss_ce: 0.091665
2021-12-14 01:09:27,924 iteration 157 : loss : 0.241846, loss_ce: 0.095777
2021-12-14 01:09:29,617 iteration 158 : loss : 0.219623, loss_ce: 0.100608
2021-12-14 01:09:31,072 iteration 159 : loss : 0.210821, loss_ce: 0.091268
2021-12-14 01:09:32,717 iteration 160 : loss : 0.199048, loss_ce: 0.078484
2021-12-14 01:09:34,356 iteration 161 : loss : 0.256516, loss_ce: 0.104574
2021-12-14 01:09:35,997 iteration 162 : loss : 0.228500, loss_ce: 0.106680
2021-12-14 01:09:37,567 iteration 163 : loss : 0.233053, loss_ce: 0.102521
2021-12-14 01:09:39,156 iteration 164 : loss : 0.223731, loss_ce: 0.089542
2021-12-14 01:09:40,714 iteration 165 : loss : 0.229354, loss_ce: 0.104093
2021-12-14 01:09:42,255 iteration 166 : loss : 0.233771, loss_ce: 0.101983
2021-12-14 01:09:43,812 iteration 167 : loss : 0.224470, loss_ce: 0.096847
2021-12-14 01:09:45,411 iteration 168 : loss : 0.226948, loss_ce: 0.109583
2021-12-14 01:09:46,987 iteration 169 : loss : 0.218297, loss_ce: 0.101268
2021-12-14 01:09:46,987 Training Data Eval:
2021-12-14 01:09:55,063   Average segmentation loss on training set: 0.2212
2021-12-14 01:09:55,063 Validation Data Eval:
2021-12-14 01:09:57,852   Average segmentation loss on validation set: 0.2044
2021-12-14 01:10:04,313 Found new lowest validation loss at iteration 169! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/TU_3seeds/REVISED_SGD_best_val_loss_seed1234.pth
2021-12-14 01:10:05,845 iteration 170 : loss : 0.206475, loss_ce: 0.090067
  2%|▊                             | 10/400 [05:02<3:35:03, 33.08s/it]2021-12-14 01:10:07,393 iteration 171 : loss : 0.231458, loss_ce: 0.098794
2021-12-14 01:10:08,953 iteration 172 : loss : 0.221171, loss_ce: 0.098641
2021-12-14 01:10:10,571 iteration 173 : loss : 0.207400, loss_ce: 0.089559
2021-12-14 01:10:12,102 iteration 174 : loss : 0.222786, loss_ce: 0.098458
2021-12-14 01:10:13,619 iteration 175 : loss : 0.248934, loss_ce: 0.102159
2021-12-14 01:10:15,212 iteration 176 : loss : 0.225673, loss_ce: 0.105958
2021-12-14 01:10:16,779 iteration 177 : loss : 0.210035, loss_ce: 0.084930
2021-12-14 01:10:18,346 iteration 178 : loss : 0.187473, loss_ce: 0.087384
2021-12-14 01:10:19,914 iteration 179 : loss : 0.218483, loss_ce: 0.093919
2021-12-14 01:10:21,460 iteration 180 : loss : 0.213226, loss_ce: 0.089748
2021-12-14 01:10:23,062 iteration 181 : loss : 0.205987, loss_ce: 0.089756
2021-12-14 01:10:24,601 iteration 182 : loss : 0.187686, loss_ce: 0.079941
2021-12-14 01:10:26,120 iteration 183 : loss : 0.223931, loss_ce: 0.086869
2021-12-14 01:10:27,596 iteration 184 : loss : 0.194996, loss_ce: 0.074938
2021-12-14 01:10:29,191 iteration 185 : loss : 0.217818, loss_ce: 0.083151
2021-12-14 01:10:30,790 iteration 186 : loss : 0.232123, loss_ce: 0.104984
2021-12-14 01:10:32,423 iteration 187 : loss : 0.213504, loss_ce: 0.089331
  3%|▊                             | 11/400 [05:29<3:21:35, 31.09s/it]2021-12-14 01:10:34,074 iteration 188 : loss : 0.236290, loss_ce: 0.101417
2021-12-14 01:10:35,660 iteration 189 : loss : 0.207312, loss_ce: 0.090638
2021-12-14 01:10:37,247 iteration 190 : loss : 0.199130, loss_ce: 0.079316
2021-12-14 01:10:38,789 iteration 191 : loss : 0.185223, loss_ce: 0.076256
2021-12-14 01:10:40,287 iteration 192 : loss : 0.206311, loss_ce: 0.091236
2021-12-14 01:10:41,906 iteration 193 : loss : 0.222691, loss_ce: 0.094027
2021-12-14 01:10:43,453 iteration 194 : loss : 0.233488, loss_ce: 0.082182
2021-12-14 01:10:44,977 iteration 195 : loss : 0.226273, loss_ce: 0.100663
2021-12-14 01:10:46,460 iteration 196 : loss : 0.206922, loss_ce: 0.076704
2021-12-14 01:10:48,030 iteration 197 : loss : 0.214025, loss_ce: 0.082990
2021-12-14 01:10:49,629 iteration 198 : loss : 0.198956, loss_ce: 0.085543
2021-12-14 01:10:51,155 iteration 199 : loss : 0.201896, loss_ce: 0.082510
2021-12-14 01:10:52,699 iteration 200 : loss : 0.200341, loss_ce: 0.085168
2021-12-14 01:10:54,281 iteration 201 : loss : 0.180172, loss_ce: 0.075663
2021-12-14 01:10:55,884 iteration 202 : loss : 0.199131, loss_ce: 0.084226
2021-12-14 01:10:57,407 iteration 203 : loss : 0.187159, loss_ce: 0.078273
2021-12-14 01:10:59,057 iteration 204 : loss : 0.221242, loss_ce: 0.086576
  3%|▉                             | 12/400 [05:56<3:12:18, 29.74s/it]2021-12-14 01:11:00,645 iteration 205 : loss : 0.193528, loss_ce: 0.077193
2021-12-14 01:11:02,202 iteration 206 : loss : 0.203367, loss_ce: 0.073950
2021-12-14 01:11:03,781 iteration 207 : loss : 0.185866, loss_ce: 0.077806
2021-12-14 01:11:05,322 iteration 208 : loss : 0.206444, loss_ce: 0.074594
2021-12-14 01:11:06,960 iteration 209 : loss : 0.225629, loss_ce: 0.104883
2021-12-14 01:11:08,434 iteration 210 : loss : 0.195516, loss_ce: 0.071852
2021-12-14 01:11:10,035 iteration 211 : loss : 0.217941, loss_ce: 0.096088
2021-12-14 01:11:11,618 iteration 212 : loss : 0.208516, loss_ce: 0.075776
2021-12-14 01:11:13,297 iteration 213 : loss : 0.205536, loss_ce: 0.094622
2021-12-14 01:11:14,871 iteration 214 : loss : 0.207062, loss_ce: 0.075708
2021-12-14 01:11:16,448 iteration 215 : loss : 0.221053, loss_ce: 0.087118
2021-12-14 01:11:18,178 iteration 216 : loss : 0.200105, loss_ce: 0.073746
2021-12-14 01:11:19,837 iteration 217 : loss : 0.188335, loss_ce: 0.073842
2021-12-14 01:11:21,424 iteration 218 : loss : 0.183587, loss_ce: 0.082089
2021-12-14 01:11:22,895 iteration 219 : loss : 0.175339, loss_ce: 0.070999
2021-12-14 01:11:24,482 iteration 220 : loss : 0.169711, loss_ce: 0.073530
2021-12-14 01:11:26,053 iteration 221 : loss : 0.224713, loss_ce: 0.084471
  3%|▉                             | 13/400 [06:23<3:06:26, 28.91s/it]2021-12-14 01:11:27,695 iteration 222 : loss : 0.227396, loss_ce: 0.106685
2021-12-14 01:11:29,344 iteration 223 : loss : 0.177832, loss_ce: 0.073481
2021-12-14 01:11:30,921 iteration 224 : loss : 0.213926, loss_ce: 0.088385
2021-12-14 01:11:32,591 iteration 225 : loss : 0.274446, loss_ce: 0.082697
2021-12-14 01:11:34,153 iteration 226 : loss : 0.178198, loss_ce: 0.065125
2021-12-14 01:11:35,763 iteration 227 : loss : 0.220202, loss_ce: 0.098202
2021-12-14 01:11:37,329 iteration 228 : loss : 0.202830, loss_ce: 0.082714
2021-12-14 01:11:38,850 iteration 229 : loss : 0.187471, loss_ce: 0.072558
2021-12-14 01:11:40,427 iteration 230 : loss : 0.173555, loss_ce: 0.069057
2021-12-14 01:11:42,039 iteration 231 : loss : 0.197129, loss_ce: 0.072514
2021-12-14 01:11:43,645 iteration 232 : loss : 0.163365, loss_ce: 0.064662
2021-12-14 01:11:45,171 iteration 233 : loss : 0.226780, loss_ce: 0.095076
2021-12-14 01:11:46,804 iteration 234 : loss : 0.190719, loss_ce: 0.075546
2021-12-14 01:11:48,355 iteration 235 : loss : 0.203982, loss_ce: 0.090663
2021-12-14 01:11:49,954 iteration 236 : loss : 0.197246, loss_ce: 0.080534
2021-12-14 01:11:51,509 iteration 237 : loss : 0.178455, loss_ce: 0.072537
2021-12-14 01:11:53,081 iteration 238 : loss : 0.157805, loss_ce: 0.065890
  4%|█                             | 14/400 [06:50<3:02:19, 28.34s/it]2021-12-14 01:11:54,657 iteration 239 : loss : 0.197760, loss_ce: 0.068161
2021-12-14 01:11:56,265 iteration 240 : loss : 0.185899, loss_ce: 0.081545
2021-12-14 01:11:57,881 iteration 241 : loss : 0.202204, loss_ce: 0.075318
2021-12-14 01:11:59,473 iteration 242 : loss : 0.220254, loss_ce: 0.107533
2021-12-14 01:12:01,191 iteration 243 : loss : 0.202438, loss_ce: 0.086220
2021-12-14 01:12:02,715 iteration 244 : loss : 0.231083, loss_ce: 0.075415
2021-12-14 01:12:04,303 iteration 245 : loss : 0.186167, loss_ce: 0.084602
2021-12-14 01:12:05,925 iteration 246 : loss : 0.177794, loss_ce: 0.074394
2021-12-14 01:12:07,485 iteration 247 : loss : 0.186948, loss_ce: 0.069841
2021-12-14 01:12:09,044 iteration 248 : loss : 0.181676, loss_ce: 0.060165
2021-12-14 01:12:10,584 iteration 249 : loss : 0.230499, loss_ce: 0.112139
2021-12-14 01:12:12,144 iteration 250 : loss : 0.219099, loss_ce: 0.089519
2021-12-14 01:12:13,701 iteration 251 : loss : 0.184854, loss_ce: 0.065795
2021-12-14 01:12:15,256 iteration 252 : loss : 0.164561, loss_ce: 0.064668
2021-12-14 01:12:16,846 iteration 253 : loss : 0.210567, loss_ce: 0.087042
2021-12-14 01:12:18,504 iteration 254 : loss : 0.255964, loss_ce: 0.085014
2021-12-14 01:12:18,504 Training Data Eval:
2021-12-14 01:12:26,576   Average segmentation loss on training set: 0.2075
2021-12-14 01:12:26,577 Validation Data Eval:
2021-12-14 01:12:29,371   Average segmentation loss on validation set: 0.1925
2021-12-14 01:12:35,621 Found new lowest validation loss at iteration 254! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/TU_3seeds/REVISED_SGD_best_val_loss_seed1234.pth
2021-12-14 01:12:37,065 iteration 255 : loss : 0.193862, loss_ce: 0.076326
  4%|█▏                            | 15/400 [07:34<3:32:05, 33.05s/it]2021-12-14 01:12:38,579 iteration 256 : loss : 0.178988, loss_ce: 0.072563
2021-12-14 01:12:40,195 iteration 257 : loss : 0.166874, loss_ce: 0.062552
2021-12-14 01:12:41,874 iteration 258 : loss : 0.184849, loss_ce: 0.070315
2021-12-14 01:12:43,375 iteration 259 : loss : 0.159365, loss_ce: 0.065294
2021-12-14 01:12:45,017 iteration 260 : loss : 0.171405, loss_ce: 0.069499
2021-12-14 01:12:46,610 iteration 261 : loss : 0.204886, loss_ce: 0.070145
2021-12-14 01:12:48,289 iteration 262 : loss : 0.172752, loss_ce: 0.069623
2021-12-14 01:12:49,868 iteration 263 : loss : 0.202664, loss_ce: 0.079692
2021-12-14 01:12:51,478 iteration 264 : loss : 0.208297, loss_ce: 0.092091
2021-12-14 01:12:53,019 iteration 265 : loss : 0.167257, loss_ce: 0.066509
2021-12-14 01:12:54,629 iteration 266 : loss : 0.167707, loss_ce: 0.065830
2021-12-14 01:12:56,203 iteration 267 : loss : 0.161003, loss_ce: 0.052403
2021-12-14 01:12:57,794 iteration 268 : loss : 0.215523, loss_ce: 0.093647
2021-12-14 01:12:59,574 iteration 269 : loss : 0.185796, loss_ce: 0.067552
2021-12-14 01:13:01,255 iteration 270 : loss : 0.179898, loss_ce: 0.068228
2021-12-14 01:13:02,713 iteration 271 : loss : 0.183833, loss_ce: 0.060749
2021-12-14 01:13:04,292 iteration 272 : loss : 0.179329, loss_ce: 0.075590
  4%|█▏                            | 16/400 [08:01<3:20:18, 31.30s/it]2021-12-14 01:13:05,859 iteration 273 : loss : 0.177038, loss_ce: 0.066437
2021-12-14 01:13:07,371 iteration 274 : loss : 0.159389, loss_ce: 0.060687
2021-12-14 01:13:08,892 iteration 275 : loss : 0.167692, loss_ce: 0.064123
2021-12-14 01:13:10,470 iteration 276 : loss : 0.153653, loss_ce: 0.062713
2021-12-14 01:13:12,072 iteration 277 : loss : 0.180371, loss_ce: 0.065870
2021-12-14 01:13:13,522 iteration 278 : loss : 0.188953, loss_ce: 0.064459
2021-12-14 01:13:15,039 iteration 279 : loss : 0.197367, loss_ce: 0.066788
2021-12-14 01:13:16,551 iteration 280 : loss : 0.187561, loss_ce: 0.072657
2021-12-14 01:13:18,128 iteration 281 : loss : 0.174530, loss_ce: 0.064866
2021-12-14 01:13:19,682 iteration 282 : loss : 0.182933, loss_ce: 0.064670
2021-12-14 01:13:21,214 iteration 283 : loss : 0.196525, loss_ce: 0.084856
2021-12-14 01:13:22,846 iteration 284 : loss : 0.180672, loss_ce: 0.072937
2021-12-14 01:13:24,355 iteration 285 : loss : 0.173738, loss_ce: 0.061571
2021-12-14 01:13:25,883 iteration 286 : loss : 0.170342, loss_ce: 0.070390
2021-12-14 01:13:27,535 iteration 287 : loss : 0.157313, loss_ce: 0.058923
2021-12-14 01:13:29,160 iteration 288 : loss : 0.190699, loss_ce: 0.077021
2021-12-14 01:13:30,706 iteration 289 : loss : 0.165729, loss_ce: 0.062954
  4%|█▎                            | 17/400 [08:27<3:10:24, 29.83s/it]2021-12-14 01:13:32,327 iteration 290 : loss : 0.152028, loss_ce: 0.051605
2021-12-14 01:13:33,858 iteration 291 : loss : 0.167396, loss_ce: 0.057943
2021-12-14 01:13:35,397 iteration 292 : loss : 0.168016, loss_ce: 0.065343
2021-12-14 01:13:36,939 iteration 293 : loss : 0.195469, loss_ce: 0.075647
2021-12-14 01:13:38,512 iteration 294 : loss : 0.187891, loss_ce: 0.069997
2021-12-14 01:13:40,180 iteration 295 : loss : 0.179553, loss_ce: 0.065959
2021-12-14 01:13:41,720 iteration 296 : loss : 0.154735, loss_ce: 0.050095
2021-12-14 01:13:43,292 iteration 297 : loss : 0.184095, loss_ce: 0.060816
2021-12-14 01:13:44,827 iteration 298 : loss : 0.157951, loss_ce: 0.056837
2021-12-14 01:13:46,391 iteration 299 : loss : 0.178651, loss_ce: 0.068132
2021-12-14 01:13:47,959 iteration 300 : loss : 0.182735, loss_ce: 0.065494
2021-12-14 01:13:49,539 iteration 301 : loss : 0.190205, loss_ce: 0.084588
2021-12-14 01:13:51,178 iteration 302 : loss : 0.177366, loss_ce: 0.065286
2021-12-14 01:13:52,794 iteration 303 : loss : 0.182622, loss_ce: 0.068835
2021-12-14 01:13:54,386 iteration 304 : loss : 0.195463, loss_ce: 0.081485
2021-12-14 01:13:56,011 iteration 305 : loss : 0.166933, loss_ce: 0.064812
2021-12-14 01:13:57,630 iteration 306 : loss : 0.169852, loss_ce: 0.071946
  4%|█▎                            | 18/400 [08:54<3:04:21, 28.96s/it]2021-12-14 01:13:59,258 iteration 307 : loss : 0.184370, loss_ce: 0.064347
2021-12-14 01:14:00,792 iteration 308 : loss : 0.157087, loss_ce: 0.066436
2021-12-14 01:14:02,382 iteration 309 : loss : 0.230246, loss_ce: 0.089634
2021-12-14 01:14:03,995 iteration 310 : loss : 0.187553, loss_ce: 0.073800
2021-12-14 01:14:05,526 iteration 311 : loss : 0.169139, loss_ce: 0.052440
2021-12-14 01:14:07,091 iteration 312 : loss : 0.164128, loss_ce: 0.070118
2021-12-14 01:14:08,672 iteration 313 : loss : 0.175468, loss_ce: 0.081412
2021-12-14 01:14:10,174 iteration 314 : loss : 0.174513, loss_ce: 0.073392
2021-12-14 01:14:11,725 iteration 315 : loss : 0.176492, loss_ce: 0.060146
2021-12-14 01:14:13,311 iteration 316 : loss : 0.163307, loss_ce: 0.054021
2021-12-14 01:14:14,883 iteration 317 : loss : 0.178504, loss_ce: 0.061341
2021-12-14 01:14:16,478 iteration 318 : loss : 0.177226, loss_ce: 0.070388
2021-12-14 01:14:17,990 iteration 319 : loss : 0.152389, loss_ce: 0.054035
2021-12-14 01:14:19,643 iteration 320 : loss : 0.161288, loss_ce: 0.051714
2021-12-14 01:14:21,256 iteration 321 : loss : 0.203581, loss_ce: 0.065764
2021-12-14 01:14:22,830 iteration 322 : loss : 0.192834, loss_ce: 0.068898
2021-12-14 01:14:24,461 iteration 323 : loss : 0.179278, loss_ce: 0.056854
  5%|█▍                            | 19/400 [09:21<2:59:49, 28.32s/it]2021-12-14 01:14:26,066 iteration 324 : loss : 0.177477, loss_ce: 0.064572
2021-12-14 01:14:27,639 iteration 325 : loss : 0.191640, loss_ce: 0.065249
2021-12-14 01:14:29,239 iteration 326 : loss : 0.153904, loss_ce: 0.059062
2021-12-14 01:14:30,922 iteration 327 : loss : 0.179414, loss_ce: 0.067349
2021-12-14 01:14:32,489 iteration 328 : loss : 0.164691, loss_ce: 0.059351
2021-12-14 01:14:34,100 iteration 329 : loss : 0.169883, loss_ce: 0.072623
2021-12-14 01:14:35,725 iteration 330 : loss : 0.156956, loss_ce: 0.056518
2021-12-14 01:14:37,256 iteration 331 : loss : 0.152412, loss_ce: 0.059706
2021-12-14 01:14:38,816 iteration 332 : loss : 0.185421, loss_ce: 0.064014
2021-12-14 01:14:40,419 iteration 333 : loss : 0.176207, loss_ce: 0.073729
2021-12-14 01:14:42,002 iteration 334 : loss : 0.164953, loss_ce: 0.061022
2021-12-14 01:14:43,553 iteration 335 : loss : 0.193075, loss_ce: 0.066233
2021-12-14 01:14:45,173 iteration 336 : loss : 0.155001, loss_ce: 0.056388
2021-12-14 01:14:46,741 iteration 337 : loss : 0.166339, loss_ce: 0.052495
2021-12-14 01:14:48,270 iteration 338 : loss : 0.195121, loss_ce: 0.088620
2021-12-14 01:14:49,806 iteration 339 : loss : 0.165821, loss_ce: 0.054522
2021-12-14 01:14:49,806 Training Data Eval:
2021-12-14 01:14:57,882   Average segmentation loss on training set: 0.1424
2021-12-14 01:14:57,883 Validation Data Eval:
2021-12-14 01:15:00,675   Average segmentation loss on validation set: 0.1725
2021-12-14 01:15:06,450 Found new lowest validation loss at iteration 339! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/TU_3seeds/REVISED_SGD_best_val_loss_seed1234.pth
2021-12-14 01:15:07,995 iteration 340 : loss : 0.168652, loss_ce: 0.063737
  5%|█▌                            | 20/400 [10:04<3:28:17, 32.89s/it]2021-12-14 01:15:09,558 iteration 341 : loss : 0.153384, loss_ce: 0.056826
2021-12-14 01:15:11,159 iteration 342 : loss : 0.149795, loss_ce: 0.045742
2021-12-14 01:15:12,729 iteration 343 : loss : 0.159127, loss_ce: 0.052263
2021-12-14 01:15:14,337 iteration 344 : loss : 0.182739, loss_ce: 0.067624
2021-12-14 01:15:15,902 iteration 345 : loss : 0.151743, loss_ce: 0.048193
2021-12-14 01:15:17,537 iteration 346 : loss : 0.165188, loss_ce: 0.059763
2021-12-14 01:15:19,059 iteration 347 : loss : 0.171894, loss_ce: 0.071136
2021-12-14 01:15:20,657 iteration 348 : loss : 0.165634, loss_ce: 0.048681
2021-12-14 01:15:22,367 iteration 349 : loss : 0.174111, loss_ce: 0.071686
2021-12-14 01:15:23,940 iteration 350 : loss : 0.162936, loss_ce: 0.056011
2021-12-14 01:15:25,568 iteration 351 : loss : 0.161654, loss_ce: 0.065917
2021-12-14 01:15:27,175 iteration 352 : loss : 0.174887, loss_ce: 0.067882
2021-12-14 01:15:28,697 iteration 353 : loss : 0.165695, loss_ce: 0.058205
2021-12-14 01:15:30,274 iteration 354 : loss : 0.184424, loss_ce: 0.059885
2021-12-14 01:15:31,901 iteration 355 : loss : 0.163389, loss_ce: 0.061933
2021-12-14 01:15:33,604 iteration 356 : loss : 0.168428, loss_ce: 0.063088
2021-12-14 01:15:35,116 iteration 357 : loss : 0.146912, loss_ce: 0.051966
  5%|█▌                            | 21/400 [10:32<3:16:48, 31.16s/it]2021-12-14 01:15:36,784 iteration 358 : loss : 0.141804, loss_ce: 0.052993
2021-12-14 01:15:38,441 iteration 359 : loss : 0.156026, loss_ce: 0.051635
2021-12-14 01:15:39,964 iteration 360 : loss : 0.138976, loss_ce: 0.042876
2021-12-14 01:15:41,579 iteration 361 : loss : 0.154030, loss_ce: 0.044998
2021-12-14 01:15:43,240 iteration 362 : loss : 0.162730, loss_ce: 0.042304
2021-12-14 01:15:44,893 iteration 363 : loss : 0.166503, loss_ce: 0.054642
2021-12-14 01:15:46,498 iteration 364 : loss : 0.146168, loss_ce: 0.053076
2021-12-14 01:15:47,982 iteration 365 : loss : 0.149132, loss_ce: 0.060775
2021-12-14 01:15:49,592 iteration 366 : loss : 0.148744, loss_ce: 0.057572
2021-12-14 01:15:51,101 iteration 367 : loss : 0.153030, loss_ce: 0.058786
2021-12-14 01:15:52,721 iteration 368 : loss : 0.166014, loss_ce: 0.046778
2021-12-14 01:15:54,379 iteration 369 : loss : 0.167662, loss_ce: 0.049534
2021-12-14 01:15:56,023 iteration 370 : loss : 0.154419, loss_ce: 0.067695
2021-12-14 01:15:57,620 iteration 371 : loss : 0.199159, loss_ce: 0.059238
2021-12-14 01:15:59,223 iteration 372 : loss : 0.191978, loss_ce: 0.079465
2021-12-14 01:16:00,753 iteration 373 : loss : 0.158922, loss_ce: 0.049573
2021-12-14 01:16:02,310 iteration 374 : loss : 0.158280, loss_ce: 0.056697
  6%|█▋                            | 22/400 [10:59<3:08:49, 29.97s/it]2021-12-14 01:16:04,004 iteration 375 : loss : 0.190343, loss_ce: 0.067523
2021-12-14 01:16:05,534 iteration 376 : loss : 0.138699, loss_ce: 0.044635
2021-12-14 01:16:07,094 iteration 377 : loss : 0.151500, loss_ce: 0.047713
2021-12-14 01:16:08,743 iteration 378 : loss : 0.154901, loss_ce: 0.052893
2021-12-14 01:16:10,237 iteration 379 : loss : 0.147394, loss_ce: 0.055285
2021-12-14 01:16:11,841 iteration 380 : loss : 0.159437, loss_ce: 0.055433
2021-12-14 01:16:13,416 iteration 381 : loss : 0.150134, loss_ce: 0.046838
2021-12-14 01:16:14,908 iteration 382 : loss : 0.154509, loss_ce: 0.060958
2021-12-14 01:16:16,477 iteration 383 : loss : 0.157730, loss_ce: 0.055119
2021-12-14 01:16:18,076 iteration 384 : loss : 0.149152, loss_ce: 0.054151
2021-12-14 01:16:19,655 iteration 385 : loss : 0.147459, loss_ce: 0.057030
2021-12-14 01:16:21,242 iteration 386 : loss : 0.158181, loss_ce: 0.051557
2021-12-14 01:16:22,846 iteration 387 : loss : 0.181216, loss_ce: 0.059934
2021-12-14 01:16:24,464 iteration 388 : loss : 0.157199, loss_ce: 0.054758
2021-12-14 01:16:26,071 iteration 389 : loss : 0.193680, loss_ce: 0.077259
2021-12-14 01:16:27,629 iteration 390 : loss : 0.137215, loss_ce: 0.048148
2021-12-14 01:16:29,185 iteration 391 : loss : 0.176197, loss_ce: 0.083301
  6%|█▋                            | 23/400 [11:26<3:02:26, 29.04s/it]2021-12-14 01:16:30,837 iteration 392 : loss : 0.144209, loss_ce: 0.055566
2021-12-14 01:16:32,375 iteration 393 : loss : 0.148249, loss_ce: 0.049633
2021-12-14 01:16:33,996 iteration 394 : loss : 0.150594, loss_ce: 0.048768
2021-12-14 01:16:35,597 iteration 395 : loss : 0.159917, loss_ce: 0.060054
2021-12-14 01:16:37,144 iteration 396 : loss : 0.163803, loss_ce: 0.050408
2021-12-14 01:16:38,715 iteration 397 : loss : 0.161687, loss_ce: 0.053916
2021-12-14 01:16:40,312 iteration 398 : loss : 0.127016, loss_ce: 0.041370
2021-12-14 01:16:41,786 iteration 399 : loss : 0.156466, loss_ce: 0.055182
2021-12-14 01:16:43,367 iteration 400 : loss : 0.144432, loss_ce: 0.046426
2021-12-14 01:16:45,003 iteration 401 : loss : 0.156973, loss_ce: 0.059291
2021-12-14 01:16:46,562 iteration 402 : loss : 0.142561, loss_ce: 0.052747
2021-12-14 01:16:48,118 iteration 403 : loss : 0.154123, loss_ce: 0.050558
2021-12-14 01:16:49,728 iteration 404 : loss : 0.139720, loss_ce: 0.049742
2021-12-14 01:16:51,382 iteration 405 : loss : 0.184552, loss_ce: 0.062516
2021-12-14 01:16:52,940 iteration 406 : loss : 0.150418, loss_ce: 0.049689
2021-12-14 01:16:54,460 iteration 407 : loss : 0.147092, loss_ce: 0.048704
2021-12-14 01:16:56,025 iteration 408 : loss : 0.163369, loss_ce: 0.056058
  6%|█▊                            | 24/400 [11:52<2:57:51, 28.38s/it]2021-12-14 01:16:57,688 iteration 409 : loss : 0.146478, loss_ce: 0.057863
2021-12-14 01:16:59,285 iteration 410 : loss : 0.161522, loss_ce: 0.059483
2021-12-14 01:17:00,853 iteration 411 : loss : 0.180705, loss_ce: 0.049467
2021-12-14 01:17:02,333 iteration 412 : loss : 0.150521, loss_ce: 0.050873
2021-12-14 01:17:03,901 iteration 413 : loss : 0.145422, loss_ce: 0.046140
2021-12-14 01:17:05,416 iteration 414 : loss : 0.158904, loss_ce: 0.059113
2021-12-14 01:17:06,881 iteration 415 : loss : 0.137206, loss_ce: 0.045695
2021-12-14 01:17:08,438 iteration 416 : loss : 0.164730, loss_ce: 0.068145
2021-12-14 01:17:09,968 iteration 417 : loss : 0.173405, loss_ce: 0.054400
2021-12-14 01:17:11,598 iteration 418 : loss : 0.164405, loss_ce: 0.062810
2021-12-14 01:17:13,138 iteration 419 : loss : 0.165781, loss_ce: 0.069455
2021-12-14 01:17:14,719 iteration 420 : loss : 0.134840, loss_ce: 0.043043
2021-12-14 01:17:16,238 iteration 421 : loss : 0.164362, loss_ce: 0.059092
2021-12-14 01:17:17,756 iteration 422 : loss : 0.171219, loss_ce: 0.062514
2021-12-14 01:17:19,285 iteration 423 : loss : 0.142557, loss_ce: 0.046799
2021-12-14 01:17:20,867 iteration 424 : loss : 0.174378, loss_ce: 0.062163
2021-12-14 01:17:20,867 Training Data Eval:
2021-12-14 01:17:28,962   Average segmentation loss on training set: 0.1597
2021-12-14 01:17:28,963 Validation Data Eval:
2021-12-14 01:17:31,761   Average segmentation loss on validation set: 0.1595
2021-12-14 01:17:37,931 Found new lowest validation loss at iteration 424! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/TU_3seeds/REVISED_SGD_best_val_loss_seed1234.pth
2021-12-14 01:17:39,384 iteration 425 : loss : 0.144018, loss_ce: 0.047639
  6%|█▉                            | 25/400 [12:36<3:25:26, 32.87s/it]2021-12-14 01:17:40,830 iteration 426 : loss : 0.140111, loss_ce: 0.045450
2021-12-14 01:17:42,433 iteration 427 : loss : 0.128843, loss_ce: 0.039277
2021-12-14 01:17:44,007 iteration 428 : loss : 0.177503, loss_ce: 0.062309
2021-12-14 01:17:45,526 iteration 429 : loss : 0.183898, loss_ce: 0.082226
2021-12-14 01:17:47,036 iteration 430 : loss : 0.159045, loss_ce: 0.051213
2021-12-14 01:17:48,573 iteration 431 : loss : 0.212980, loss_ce: 0.069502
2021-12-14 01:17:50,167 iteration 432 : loss : 0.136116, loss_ce: 0.046727
2021-12-14 01:17:51,796 iteration 433 : loss : 0.138292, loss_ce: 0.049532
2021-12-14 01:17:53,372 iteration 434 : loss : 0.138518, loss_ce: 0.043372
2021-12-14 01:17:54,884 iteration 435 : loss : 0.122814, loss_ce: 0.040726
2021-12-14 01:17:56,428 iteration 436 : loss : 0.145261, loss_ce: 0.051377
2021-12-14 01:17:57,978 iteration 437 : loss : 0.158570, loss_ce: 0.063970
2021-12-14 01:17:59,478 iteration 438 : loss : 0.145993, loss_ce: 0.042612
2021-12-14 01:18:01,048 iteration 439 : loss : 0.177133, loss_ce: 0.052971
2021-12-14 01:18:02,599 iteration 440 : loss : 0.186894, loss_ce: 0.065081
2021-12-14 01:18:04,206 iteration 441 : loss : 0.145979, loss_ce: 0.051144
2021-12-14 01:18:05,794 iteration 442 : loss : 0.156854, loss_ce: 0.062884
  6%|█▉                            | 26/400 [13:02<3:12:48, 30.93s/it]2021-12-14 01:18:07,381 iteration 443 : loss : 0.166630, loss_ce: 0.066059
2021-12-14 01:18:08,899 iteration 444 : loss : 0.141350, loss_ce: 0.047504
2021-12-14 01:18:10,453 iteration 445 : loss : 0.149788, loss_ce: 0.042747
2021-12-14 01:18:12,143 iteration 446 : loss : 0.162913, loss_ce: 0.056555
2021-12-14 01:18:13,775 iteration 447 : loss : 0.166128, loss_ce: 0.078040
2021-12-14 01:18:15,390 iteration 448 : loss : 0.204786, loss_ce: 0.052950
2021-12-14 01:18:16,963 iteration 449 : loss : 0.159788, loss_ce: 0.065398
2021-12-14 01:18:18,523 iteration 450 : loss : 0.142116, loss_ce: 0.044217
2021-12-14 01:18:20,174 iteration 451 : loss : 0.127246, loss_ce: 0.043295
2021-12-14 01:18:21,780 iteration 452 : loss : 0.134558, loss_ce: 0.046157
2021-12-14 01:18:23,377 iteration 453 : loss : 0.171457, loss_ce: 0.059584
2021-12-14 01:18:24,977 iteration 454 : loss : 0.151824, loss_ce: 0.048438
2021-12-14 01:18:26,609 iteration 455 : loss : 0.143097, loss_ce: 0.050700
2021-12-14 01:18:28,203 iteration 456 : loss : 0.153716, loss_ce: 0.053960
2021-12-14 01:18:29,791 iteration 457 : loss : 0.147882, loss_ce: 0.052322
2021-12-14 01:18:31,447 iteration 458 : loss : 0.205219, loss_ce: 0.086855
2021-12-14 01:18:32,966 iteration 459 : loss : 0.125342, loss_ce: 0.038553
  7%|██                            | 27/400 [13:29<3:05:18, 29.81s/it]2021-12-14 01:18:34,621 iteration 460 : loss : 0.138863, loss_ce: 0.049844
2021-12-14 01:18:36,214 iteration 461 : loss : 0.147214, loss_ce: 0.054372
2021-12-14 01:18:37,777 iteration 462 : loss : 0.146912, loss_ce: 0.049828
2021-12-14 01:18:39,415 iteration 463 : loss : 0.131498, loss_ce: 0.039953
2021-12-14 01:18:40,998 iteration 464 : loss : 0.130731, loss_ce: 0.046291
2021-12-14 01:18:42,528 iteration 465 : loss : 0.147187, loss_ce: 0.040091
2021-12-14 01:18:44,091 iteration 466 : loss : 0.167058, loss_ce: 0.048936
2021-12-14 01:18:45,639 iteration 467 : loss : 0.149394, loss_ce: 0.047666
2021-12-14 01:18:47,313 iteration 468 : loss : 0.143834, loss_ce: 0.047191
2021-12-14 01:18:48,871 iteration 469 : loss : 0.129857, loss_ce: 0.037957
2021-12-14 01:18:50,446 iteration 470 : loss : 0.156814, loss_ce: 0.054554
2021-12-14 01:18:52,016 iteration 471 : loss : 0.149509, loss_ce: 0.047506
2021-12-14 01:18:53,644 iteration 472 : loss : 0.140778, loss_ce: 0.045493
2021-12-14 01:18:55,367 iteration 473 : loss : 0.198602, loss_ce: 0.082975
2021-12-14 01:18:57,433 iteration 474 : loss : 0.192521, loss_ce: 0.077026
2021-12-14 01:18:58,994 iteration 475 : loss : 0.142954, loss_ce: 0.046292
2021-12-14 01:19:00,633 iteration 476 : loss : 0.151363, loss_ce: 0.059230
  7%|██                            | 28/400 [13:57<3:00:49, 29.17s/it]2021-12-14 01:19:02,269 iteration 477 : loss : 0.133809, loss_ce: 0.039121
2021-12-14 01:19:03,902 iteration 478 : loss : 0.134034, loss_ce: 0.041185
2021-12-14 01:19:05,480 iteration 479 : loss : 0.177784, loss_ce: 0.064644
2021-12-14 01:19:07,086 iteration 480 : loss : 0.143562, loss_ce: 0.052749
2021-12-14 01:19:08,593 iteration 481 : loss : 0.156495, loss_ce: 0.055376
2021-12-14 01:19:10,193 iteration 482 : loss : 0.155991, loss_ce: 0.041102
2021-12-14 01:19:11,804 iteration 483 : loss : 0.172485, loss_ce: 0.059361
2021-12-14 01:19:13,430 iteration 484 : loss : 0.173422, loss_ce: 0.065088
2021-12-14 01:19:14,998 iteration 485 : loss : 0.128055, loss_ce: 0.045324
2021-12-14 01:19:16,551 iteration 486 : loss : 0.150683, loss_ce: 0.044820
2021-12-14 01:19:18,186 iteration 487 : loss : 0.132273, loss_ce: 0.043945
2021-12-14 01:19:19,712 iteration 488 : loss : 0.138045, loss_ce: 0.047535
2021-12-14 01:19:21,293 iteration 489 : loss : 0.152966, loss_ce: 0.053154
2021-12-14 01:19:22,769 iteration 490 : loss : 0.120262, loss_ce: 0.035613
2021-12-14 01:19:24,359 iteration 491 : loss : 0.141781, loss_ce: 0.049091
2021-12-14 01:19:25,922 iteration 492 : loss : 0.122420, loss_ce: 0.040166
2021-12-14 01:19:27,527 iteration 493 : loss : 0.144704, loss_ce: 0.053206
  7%|██▏                           | 29/400 [14:24<2:56:07, 28.48s/it]2021-12-14 01:19:29,157 iteration 494 : loss : 0.142686, loss_ce: 0.053762
2021-12-14 01:19:30,773 iteration 495 : loss : 0.137651, loss_ce: 0.041789
2021-12-14 01:19:32,351 iteration 496 : loss : 0.162618, loss_ce: 0.066696
2021-12-14 01:19:33,963 iteration 497 : loss : 0.149089, loss_ce: 0.053048
2021-12-14 01:19:35,611 iteration 498 : loss : 0.140426, loss_ce: 0.054366
2021-12-14 01:19:37,131 iteration 499 : loss : 0.133560, loss_ce: 0.048198
2021-12-14 01:19:38,667 iteration 500 : loss : 0.143910, loss_ce: 0.041734
2021-12-14 01:19:40,204 iteration 501 : loss : 0.162889, loss_ce: 0.052969
2021-12-14 01:19:41,849 iteration 502 : loss : 0.134677, loss_ce: 0.047288
2021-12-14 01:19:43,390 iteration 503 : loss : 0.161470, loss_ce: 0.045525
2021-12-14 01:19:44,996 iteration 504 : loss : 0.139958, loss_ce: 0.039195
2021-12-14 01:19:46,530 iteration 505 : loss : 0.120325, loss_ce: 0.037507
2021-12-14 01:19:48,201 iteration 506 : loss : 0.137993, loss_ce: 0.041892
2021-12-14 01:19:49,788 iteration 507 : loss : 0.159563, loss_ce: 0.048762
2021-12-14 01:19:51,370 iteration 508 : loss : 0.167972, loss_ce: 0.060110
2021-12-14 01:19:52,996 iteration 509 : loss : 0.125969, loss_ce: 0.039682
2021-12-14 01:19:52,996 Training Data Eval:
2021-12-14 01:20:01,179   Average segmentation loss on training set: 0.1206
2021-12-14 01:20:01,180 Validation Data Eval:
2021-12-14 01:20:04,123   Average segmentation loss on validation set: 0.1438
2021-12-14 01:20:11,414 Found new lowest validation loss at iteration 509! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/TU_3seeds/REVISED_SGD_best_val_loss_seed1234.pth
2021-12-14 01:20:12,941 iteration 510 : loss : 0.122327, loss_ce: 0.038276
  8%|██▎                           | 30/400 [15:09<3:26:57, 33.56s/it]2021-12-14 01:20:14,464 iteration 511 : loss : 0.170017, loss_ce: 0.058238
2021-12-14 01:20:15,951 iteration 512 : loss : 0.172091, loss_ce: 0.057648
2021-12-14 01:20:17,510 iteration 513 : loss : 0.116981, loss_ce: 0.031281
2021-12-14 01:20:19,091 iteration 514 : loss : 0.131796, loss_ce: 0.042819
2021-12-14 01:20:20,648 iteration 515 : loss : 0.168736, loss_ce: 0.060010
2021-12-14 01:20:22,258 iteration 516 : loss : 0.163051, loss_ce: 0.052186
2021-12-14 01:20:23,893 iteration 517 : loss : 0.154068, loss_ce: 0.059903
2021-12-14 01:20:25,419 iteration 518 : loss : 0.161478, loss_ce: 0.048405
2021-12-14 01:20:26,998 iteration 519 : loss : 0.137862, loss_ce: 0.050283
2021-12-14 01:20:28,523 iteration 520 : loss : 0.124478, loss_ce: 0.038777
2021-12-14 01:20:30,099 iteration 521 : loss : 0.141887, loss_ce: 0.039409
2021-12-14 01:20:31,713 iteration 522 : loss : 0.133152, loss_ce: 0.043104
2021-12-14 01:20:33,366 iteration 523 : loss : 0.138264, loss_ce: 0.049849
2021-12-14 01:20:35,038 iteration 524 : loss : 0.140621, loss_ce: 0.044731
2021-12-14 01:20:36,620 iteration 525 : loss : 0.147669, loss_ce: 0.054474
2021-12-14 01:20:38,198 iteration 526 : loss : 0.148038, loss_ce: 0.048769
2021-12-14 01:20:39,779 iteration 527 : loss : 0.128391, loss_ce: 0.035882
  8%|██▎                           | 31/400 [15:36<3:14:00, 31.55s/it]2021-12-14 01:20:41,393 iteration 528 : loss : 0.135606, loss_ce: 0.049454
2021-12-14 01:20:42,986 iteration 529 : loss : 0.139117, loss_ce: 0.039332
2021-12-14 01:20:44,527 iteration 530 : loss : 0.158520, loss_ce: 0.045762
2021-12-14 01:20:46,053 iteration 531 : loss : 0.126167, loss_ce: 0.034910
2021-12-14 01:20:47,597 iteration 532 : loss : 0.150929, loss_ce: 0.057904
2021-12-14 01:20:49,273 iteration 533 : loss : 0.122945, loss_ce: 0.038925
2021-12-14 01:20:50,799 iteration 534 : loss : 0.120832, loss_ce: 0.043065
2021-12-14 01:20:52,415 iteration 535 : loss : 0.135919, loss_ce: 0.040652
2021-12-14 01:20:54,063 iteration 536 : loss : 0.150814, loss_ce: 0.059007
2021-12-14 01:20:55,732 iteration 537 : loss : 0.143750, loss_ce: 0.039990
2021-12-14 01:20:57,340 iteration 538 : loss : 0.138376, loss_ce: 0.046587
2021-12-14 01:20:58,906 iteration 539 : loss : 0.129783, loss_ce: 0.042216
2021-12-14 01:21:00,512 iteration 540 : loss : 0.146998, loss_ce: 0.045008
2021-12-14 01:21:02,074 iteration 541 : loss : 0.126184, loss_ce: 0.044084
2021-12-14 01:21:03,653 iteration 542 : loss : 0.140028, loss_ce: 0.051685
2021-12-14 01:21:05,182 iteration 543 : loss : 0.111712, loss_ce: 0.031398
2021-12-14 01:21:06,744 iteration 544 : loss : 0.124794, loss_ce: 0.035858
  8%|██▍                           | 32/400 [16:03<3:05:03, 30.17s/it]2021-12-14 01:21:08,401 iteration 545 : loss : 0.127730, loss_ce: 0.050489
2021-12-14 01:21:09,979 iteration 546 : loss : 0.134401, loss_ce: 0.040989
2021-12-14 01:21:11,552 iteration 547 : loss : 0.134904, loss_ce: 0.044909
2021-12-14 01:21:13,112 iteration 548 : loss : 0.156029, loss_ce: 0.047228
2021-12-14 01:21:14,712 iteration 549 : loss : 0.126101, loss_ce: 0.042707
2021-12-14 01:21:16,264 iteration 550 : loss : 0.144324, loss_ce: 0.046861
2021-12-14 01:21:17,831 iteration 551 : loss : 0.126806, loss_ce: 0.041841
2021-12-14 01:21:19,376 iteration 552 : loss : 0.129152, loss_ce: 0.041735
2021-12-14 01:21:20,985 iteration 553 : loss : 0.121415, loss_ce: 0.035591
2021-12-14 01:21:22,503 iteration 554 : loss : 0.130816, loss_ce: 0.051457
2021-12-14 01:21:24,067 iteration 555 : loss : 0.142263, loss_ce: 0.034585
2021-12-14 01:21:25,680 iteration 556 : loss : 0.135065, loss_ce: 0.048002
2021-12-14 01:21:27,181 iteration 557 : loss : 0.133821, loss_ce: 0.042621
2021-12-14 01:21:28,790 iteration 558 : loss : 0.158573, loss_ce: 0.041340
2021-12-14 01:21:30,365 iteration 559 : loss : 0.137363, loss_ce: 0.046723
2021-12-14 01:21:31,961 iteration 560 : loss : 0.140509, loss_ce: 0.031125
2021-12-14 01:21:33,582 iteration 561 : loss : 0.169396, loss_ce: 0.077105
  8%|██▍                           | 33/400 [16:30<2:58:26, 29.17s/it]2021-12-14 01:21:35,328 iteration 562 : loss : 0.152528, loss_ce: 0.053704
2021-12-14 01:21:36,815 iteration 563 : loss : 0.131941, loss_ce: 0.044221
2021-12-14 01:21:38,411 iteration 564 : loss : 0.135834, loss_ce: 0.051162
2021-12-14 01:21:40,008 iteration 565 : loss : 0.149913, loss_ce: 0.051945
2021-12-14 01:21:41,640 iteration 566 : loss : 0.142393, loss_ce: 0.053237
2021-12-14 01:21:43,193 iteration 567 : loss : 0.125189, loss_ce: 0.033974
2021-12-14 01:21:44,737 iteration 568 : loss : 0.148350, loss_ce: 0.042159
2021-12-14 01:21:46,303 iteration 569 : loss : 0.149336, loss_ce: 0.046520
2021-12-14 01:21:47,905 iteration 570 : loss : 0.142503, loss_ce: 0.052482
2021-12-14 01:21:49,456 iteration 571 : loss : 0.178597, loss_ce: 0.053155
2021-12-14 01:21:51,045 iteration 572 : loss : 0.125893, loss_ce: 0.036804
2021-12-14 01:21:52,588 iteration 573 : loss : 0.135321, loss_ce: 0.044030
2021-12-14 01:21:54,164 iteration 574 : loss : 0.137827, loss_ce: 0.041538
2021-12-14 01:21:55,807 iteration 575 : loss : 0.123434, loss_ce: 0.035692
2021-12-14 01:21:57,436 iteration 576 : loss : 0.138584, loss_ce: 0.044430
2021-12-14 01:21:59,023 iteration 577 : loss : 0.118974, loss_ce: 0.037732
2021-12-14 01:22:00,562 iteration 578 : loss : 0.126057, loss_ce: 0.040123
  8%|██▌                           | 34/400 [16:57<2:53:55, 28.51s/it]2021-12-14 01:22:02,361 iteration 579 : loss : 0.135963, loss_ce: 0.043133
2021-12-14 01:22:03,956 iteration 580 : loss : 0.139196, loss_ce: 0.044542
2021-12-14 01:22:05,583 iteration 581 : loss : 0.147874, loss_ce: 0.036986
2021-12-14 01:22:07,154 iteration 582 : loss : 0.141438, loss_ce: 0.049659
2021-12-14 01:22:08,745 iteration 583 : loss : 0.150994, loss_ce: 0.038625
2021-12-14 01:22:10,299 iteration 584 : loss : 0.120939, loss_ce: 0.041040
2021-12-14 01:22:11,934 iteration 585 : loss : 0.126418, loss_ce: 0.037096
2021-12-14 01:22:13,478 iteration 586 : loss : 0.128096, loss_ce: 0.041687
2021-12-14 01:22:15,017 iteration 587 : loss : 0.124388, loss_ce: 0.043238
2021-12-14 01:22:16,623 iteration 588 : loss : 0.141685, loss_ce: 0.041256
2021-12-14 01:22:18,191 iteration 589 : loss : 0.119817, loss_ce: 0.038083
2021-12-14 01:22:19,768 iteration 590 : loss : 0.124222, loss_ce: 0.035310
2021-12-14 01:22:21,352 iteration 591 : loss : 0.132850, loss_ce: 0.042814
2021-12-14 01:22:22,933 iteration 592 : loss : 0.138086, loss_ce: 0.047154
2021-12-14 01:22:24,541 iteration 593 : loss : 0.135106, loss_ce: 0.045595
2021-12-14 01:22:26,134 iteration 594 : loss : 0.122845, loss_ce: 0.041054
2021-12-14 01:22:26,134 Training Data Eval:
2021-12-14 01:22:34,316   Average segmentation loss on training set: 0.1317
2021-12-14 01:22:34,317 Validation Data Eval:
2021-12-14 01:22:37,119   Average segmentation loss on validation set: 0.1497
2021-12-14 01:22:38,763 iteration 595 : loss : 0.152237, loss_ce: 0.064593
  9%|██▋                           | 35/400 [17:35<3:11:08, 31.42s/it]2021-12-14 01:22:40,415 iteration 596 : loss : 0.122350, loss_ce: 0.037505
2021-12-14 01:22:41,968 iteration 597 : loss : 0.151468, loss_ce: 0.040016
2021-12-14 01:22:43,508 iteration 598 : loss : 0.115926, loss_ce: 0.033244
2021-12-14 01:22:45,074 iteration 599 : loss : 0.146366, loss_ce: 0.046799
2021-12-14 01:22:46,638 iteration 600 : loss : 0.138013, loss_ce: 0.047983
2021-12-14 01:22:48,229 iteration 601 : loss : 0.129514, loss_ce: 0.039962
2021-12-14 01:22:49,826 iteration 602 : loss : 0.122191, loss_ce: 0.041322
2021-12-14 01:22:51,339 iteration 603 : loss : 0.136977, loss_ce: 0.037108
2021-12-14 01:22:52,893 iteration 604 : loss : 0.140813, loss_ce: 0.042446
2021-12-14 01:22:54,408 iteration 605 : loss : 0.125578, loss_ce: 0.037362
2021-12-14 01:22:56,109 iteration 606 : loss : 0.128158, loss_ce: 0.043432
2021-12-14 01:22:57,674 iteration 607 : loss : 0.142484, loss_ce: 0.043918
2021-12-14 01:22:59,242 iteration 608 : loss : 0.141190, loss_ce: 0.050952
2021-12-14 01:23:00,733 iteration 609 : loss : 0.116574, loss_ce: 0.037480
2021-12-14 01:23:02,345 iteration 610 : loss : 0.139502, loss_ce: 0.045770
2021-12-14 01:23:04,017 iteration 611 : loss : 0.136134, loss_ce: 0.052727
2021-12-14 01:23:05,613 iteration 612 : loss : 0.130179, loss_ce: 0.034381
  9%|██▋                           | 36/400 [18:02<3:02:18, 30.05s/it]2021-12-14 01:23:07,285 iteration 613 : loss : 0.131706, loss_ce: 0.041432
2021-12-14 01:23:08,831 iteration 614 : loss : 0.129039, loss_ce: 0.032926
2021-12-14 01:23:10,367 iteration 615 : loss : 0.138639, loss_ce: 0.049490
2021-12-14 01:23:12,024 iteration 616 : loss : 0.124731, loss_ce: 0.042861
2021-12-14 01:23:13,567 iteration 617 : loss : 0.136947, loss_ce: 0.052027
2021-12-14 01:23:15,194 iteration 618 : loss : 0.172735, loss_ce: 0.039993
2021-12-14 01:23:16,782 iteration 619 : loss : 0.161530, loss_ce: 0.059557
2021-12-14 01:23:18,456 iteration 620 : loss : 0.156762, loss_ce: 0.035556
2021-12-14 01:23:20,040 iteration 621 : loss : 0.119485, loss_ce: 0.036529
2021-12-14 01:23:21,740 iteration 622 : loss : 0.134993, loss_ce: 0.044022
2021-12-14 01:23:23,419 iteration 623 : loss : 0.184014, loss_ce: 0.082818
2021-12-14 01:23:24,988 iteration 624 : loss : 0.140002, loss_ce: 0.039946
2021-12-14 01:23:26,519 iteration 625 : loss : 0.120613, loss_ce: 0.038877
2021-12-14 01:23:28,141 iteration 626 : loss : 0.119019, loss_ce: 0.036999
2021-12-14 01:23:29,770 iteration 627 : loss : 0.147628, loss_ce: 0.046869
2021-12-14 01:23:31,445 iteration 628 : loss : 0.133753, loss_ce: 0.040715
2021-12-14 01:23:33,011 iteration 629 : loss : 0.120980, loss_ce: 0.038992
  9%|██▊                           | 37/400 [18:29<2:56:57, 29.25s/it]2021-12-14 01:23:34,668 iteration 630 : loss : 0.121846, loss_ce: 0.042055
2021-12-14 01:23:36,222 iteration 631 : loss : 0.108238, loss_ce: 0.033707
2021-12-14 01:23:37,775 iteration 632 : loss : 0.133250, loss_ce: 0.041047
2021-12-14 01:23:39,427 iteration 633 : loss : 0.122557, loss_ce: 0.039062
2021-12-14 01:23:41,014 iteration 634 : loss : 0.137571, loss_ce: 0.040503
2021-12-14 01:23:42,688 iteration 635 : loss : 0.139584, loss_ce: 0.050312
2021-12-14 01:23:44,293 iteration 636 : loss : 0.135531, loss_ce: 0.043666
2021-12-14 01:23:45,810 iteration 637 : loss : 0.134016, loss_ce: 0.045999
2021-12-14 01:23:47,475 iteration 638 : loss : 0.164089, loss_ce: 0.047215
2021-12-14 01:23:49,018 iteration 639 : loss : 0.129205, loss_ce: 0.044953
2021-12-14 01:23:50,535 iteration 640 : loss : 0.169062, loss_ce: 0.045295
2021-12-14 01:23:52,056 iteration 641 : loss : 0.119910, loss_ce: 0.040412
2021-12-14 01:23:53,584 iteration 642 : loss : 0.117573, loss_ce: 0.031157
2021-12-14 01:23:55,141 iteration 643 : loss : 0.129762, loss_ce: 0.041232
2021-12-14 01:23:56,711 iteration 644 : loss : 0.134660, loss_ce: 0.050939
2021-12-14 01:23:58,241 iteration 645 : loss : 0.135259, loss_ce: 0.036082
2021-12-14 01:23:59,881 iteration 646 : loss : 0.116223, loss_ce: 0.035897
 10%|██▊                           | 38/400 [18:56<2:52:09, 28.53s/it]2021-12-14 01:24:01,480 iteration 647 : loss : 0.131031, loss_ce: 0.042933
2021-12-14 01:24:03,056 iteration 648 : loss : 0.141910, loss_ce: 0.048350
2021-12-14 01:24:04,661 iteration 649 : loss : 0.124592, loss_ce: 0.039929
2021-12-14 01:24:06,312 iteration 650 : loss : 0.134892, loss_ce: 0.042131
2021-12-14 01:24:07,884 iteration 651 : loss : 0.116197, loss_ce: 0.036188
2021-12-14 01:24:09,360 iteration 652 : loss : 0.105924, loss_ce: 0.028345
2021-12-14 01:24:11,006 iteration 653 : loss : 0.131363, loss_ce: 0.040086
2021-12-14 01:24:12,533 iteration 654 : loss : 0.130489, loss_ce: 0.037102
2021-12-14 01:24:14,113 iteration 655 : loss : 0.136644, loss_ce: 0.038844
2021-12-14 01:24:15,694 iteration 656 : loss : 0.125436, loss_ce: 0.040061
2021-12-14 01:24:17,343 iteration 657 : loss : 0.119110, loss_ce: 0.033153
2021-12-14 01:24:18,947 iteration 658 : loss : 0.120665, loss_ce: 0.031835
2021-12-14 01:24:20,554 iteration 659 : loss : 0.122608, loss_ce: 0.038860
2021-12-14 01:24:22,102 iteration 660 : loss : 0.126683, loss_ce: 0.044370
2021-12-14 01:24:23,705 iteration 661 : loss : 0.135134, loss_ce: 0.046079
2021-12-14 01:24:25,382 iteration 662 : loss : 0.157081, loss_ce: 0.041908
2021-12-14 01:24:26,968 iteration 663 : loss : 0.120036, loss_ce: 0.041795
 10%|██▉                           | 39/400 [19:23<2:49:03, 28.10s/it]2021-12-14 01:24:28,611 iteration 664 : loss : 0.123433, loss_ce: 0.037856
2021-12-14 01:24:30,117 iteration 665 : loss : 0.123024, loss_ce: 0.042095
2021-12-14 01:24:31,683 iteration 666 : loss : 0.111157, loss_ce: 0.028012
2021-12-14 01:24:33,294 iteration 667 : loss : 0.113029, loss_ce: 0.034031
2021-12-14 01:24:34,876 iteration 668 : loss : 0.142214, loss_ce: 0.050780
2021-12-14 01:24:36,429 iteration 669 : loss : 0.124316, loss_ce: 0.033894
2021-12-14 01:24:38,132 iteration 670 : loss : 0.126072, loss_ce: 0.038700
2021-12-14 01:24:39,691 iteration 671 : loss : 0.120955, loss_ce: 0.032733
2021-12-14 01:24:41,337 iteration 672 : loss : 0.117746, loss_ce: 0.033318
2021-12-14 01:24:42,957 iteration 673 : loss : 0.121231, loss_ce: 0.039417
2021-12-14 01:24:44,561 iteration 674 : loss : 0.123495, loss_ce: 0.047549
2021-12-14 01:24:46,196 iteration 675 : loss : 0.157819, loss_ce: 0.052310
2021-12-14 01:24:47,763 iteration 676 : loss : 0.120829, loss_ce: 0.033274
2021-12-14 01:24:49,348 iteration 677 : loss : 0.115143, loss_ce: 0.038552
2021-12-14 01:24:50,961 iteration 678 : loss : 0.131743, loss_ce: 0.036141
2021-12-14 01:24:52,550 iteration 679 : loss : 0.125372, loss_ce: 0.043586
2021-12-14 01:24:52,550 Training Data Eval:
2021-12-14 01:25:00,727   Average segmentation loss on training set: 0.1109
2021-12-14 01:25:00,727 Validation Data Eval:
2021-12-14 01:25:03,522   Average segmentation loss on validation set: 0.1379
2021-12-14 01:25:09,790 Found new lowest validation loss at iteration 679! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/TU_3seeds/REVISED_SGD_best_val_loss_seed1234.pth
2021-12-14 01:25:11,274 iteration 680 : loss : 0.123864, loss_ce: 0.036607
 10%|███                           | 40/400 [20:08<3:17:48, 32.97s/it]2021-12-14 01:25:12,805 iteration 681 : loss : 0.113665, loss_ce: 0.032661
2021-12-14 01:25:14,295 iteration 682 : loss : 0.139151, loss_ce: 0.035349
2021-12-14 01:25:15,874 iteration 683 : loss : 0.126709, loss_ce: 0.043931
2021-12-14 01:25:17,421 iteration 684 : loss : 0.126245, loss_ce: 0.037251
2021-12-14 01:25:19,060 iteration 685 : loss : 0.117556, loss_ce: 0.035472
2021-12-14 01:25:20,639 iteration 686 : loss : 0.159079, loss_ce: 0.059079
2021-12-14 01:25:22,255 iteration 687 : loss : 0.122701, loss_ce: 0.040934
2021-12-14 01:25:23,810 iteration 688 : loss : 0.120861, loss_ce: 0.030647
2021-12-14 01:25:25,412 iteration 689 : loss : 0.127118, loss_ce: 0.040864
2021-12-14 01:25:26,979 iteration 690 : loss : 0.112317, loss_ce: 0.031091
2021-12-14 01:25:28,561 iteration 691 : loss : 0.121957, loss_ce: 0.035014
2021-12-14 01:25:30,194 iteration 692 : loss : 0.119313, loss_ce: 0.034663
2021-12-14 01:25:31,712 iteration 693 : loss : 0.120442, loss_ce: 0.043783
2021-12-14 01:25:33,301 iteration 694 : loss : 0.133184, loss_ce: 0.045123
2021-12-14 01:25:34,838 iteration 695 : loss : 0.127314, loss_ce: 0.042276
2021-12-14 01:25:36,477 iteration 696 : loss : 0.116695, loss_ce: 0.032949
2021-12-14 01:25:38,058 iteration 697 : loss : 0.129154, loss_ce: 0.041708
 10%|███                           | 41/400 [20:35<3:06:10, 31.11s/it]2021-12-14 01:25:39,664 iteration 698 : loss : 0.136085, loss_ce: 0.034614
2021-12-14 01:25:41,286 iteration 699 : loss : 0.129020, loss_ce: 0.043937
2021-12-14 01:25:42,841 iteration 700 : loss : 0.124904, loss_ce: 0.041752
2021-12-14 01:25:44,402 iteration 701 : loss : 0.143338, loss_ce: 0.057268
2021-12-14 01:25:46,014 iteration 702 : loss : 0.134456, loss_ce: 0.037247
2021-12-14 01:25:47,678 iteration 703 : loss : 0.104965, loss_ce: 0.034174
2021-12-14 01:25:49,200 iteration 704 : loss : 0.113170, loss_ce: 0.035051
2021-12-14 01:25:50,776 iteration 705 : loss : 0.120926, loss_ce: 0.031369
2021-12-14 01:25:52,364 iteration 706 : loss : 0.130555, loss_ce: 0.041297
2021-12-14 01:25:53,878 iteration 707 : loss : 0.114821, loss_ce: 0.035403
2021-12-14 01:25:55,449 iteration 708 : loss : 0.111602, loss_ce: 0.032663
2021-12-14 01:25:57,021 iteration 709 : loss : 0.127285, loss_ce: 0.042213
2021-12-14 01:25:58,628 iteration 710 : loss : 0.114698, loss_ce: 0.034690
2021-12-14 01:26:00,230 iteration 711 : loss : 0.131759, loss_ce: 0.043352
2021-12-14 01:26:01,903 iteration 712 : loss : 0.113241, loss_ce: 0.031405
2021-12-14 01:26:03,477 iteration 713 : loss : 0.126060, loss_ce: 0.042919
2021-12-14 01:26:05,119 iteration 714 : loss : 0.116336, loss_ce: 0.031675
 10%|███▏                          | 42/400 [21:02<2:58:23, 29.90s/it]2021-12-14 01:26:06,811 iteration 715 : loss : 0.110335, loss_ce: 0.031979
2021-12-14 01:26:08,446 iteration 716 : loss : 0.117195, loss_ce: 0.036171
2021-12-14 01:26:10,029 iteration 717 : loss : 0.156311, loss_ce: 0.042559
2021-12-14 01:26:11,625 iteration 718 : loss : 0.122516, loss_ce: 0.041303
2021-12-14 01:26:13,269 iteration 719 : loss : 0.118900, loss_ce: 0.034823
2021-12-14 01:26:14,852 iteration 720 : loss : 0.111954, loss_ce: 0.033714
2021-12-14 01:26:16,436 iteration 721 : loss : 0.152484, loss_ce: 0.038570
2021-12-14 01:26:18,005 iteration 722 : loss : 0.129759, loss_ce: 0.036084
2021-12-14 01:26:19,627 iteration 723 : loss : 0.128111, loss_ce: 0.047013
2021-12-14 01:26:21,188 iteration 724 : loss : 0.148960, loss_ce: 0.050759
2021-12-14 01:26:22,828 iteration 725 : loss : 0.119334, loss_ce: 0.033501
2021-12-14 01:26:24,404 iteration 726 : loss : 0.130749, loss_ce: 0.045541
2021-12-14 01:26:25,918 iteration 727 : loss : 0.113302, loss_ce: 0.034651
2021-12-14 01:26:27,532 iteration 728 : loss : 0.122801, loss_ce: 0.037526
2021-12-14 01:26:29,156 iteration 729 : loss : 0.117356, loss_ce: 0.037201
2021-12-14 01:26:30,753 iteration 730 : loss : 0.117662, loss_ce: 0.036610
2021-12-14 01:26:32,250 iteration 731 : loss : 0.104399, loss_ce: 0.029007
 11%|███▏                          | 43/400 [21:29<2:52:57, 29.07s/it]2021-12-14 01:26:33,828 iteration 732 : loss : 0.119212, loss_ce: 0.043735
2021-12-14 01:26:35,333 iteration 733 : loss : 0.119872, loss_ce: 0.043436
2021-12-14 01:26:36,948 iteration 734 : loss : 0.104970, loss_ce: 0.030025
2021-12-14 01:26:38,518 iteration 735 : loss : 0.124220, loss_ce: 0.037840
2021-12-14 01:26:40,061 iteration 736 : loss : 0.113879, loss_ce: 0.032459
2021-12-14 01:26:41,757 iteration 737 : loss : 0.125730, loss_ce: 0.040964
2021-12-14 01:26:43,254 iteration 738 : loss : 0.119621, loss_ce: 0.038564
2021-12-14 01:26:44,859 iteration 739 : loss : 0.133751, loss_ce: 0.037986
2021-12-14 01:26:46,420 iteration 740 : loss : 0.120240, loss_ce: 0.034075
2021-12-14 01:26:47,962 iteration 741 : loss : 0.113810, loss_ce: 0.034066
2021-12-14 01:26:49,466 iteration 742 : loss : 0.125943, loss_ce: 0.044262
2021-12-14 01:26:51,048 iteration 743 : loss : 0.103543, loss_ce: 0.029288
2021-12-14 01:26:52,661 iteration 744 : loss : 0.123934, loss_ce: 0.041425
2021-12-14 01:26:54,199 iteration 745 : loss : 0.126705, loss_ce: 0.023820
2021-12-14 01:26:55,744 iteration 746 : loss : 0.110598, loss_ce: 0.031496
2021-12-14 01:26:57,286 iteration 747 : loss : 0.122359, loss_ce: 0.036201
2021-12-14 01:26:58,817 iteration 748 : loss : 0.107095, loss_ce: 0.032366
 11%|███▎                          | 44/400 [21:55<2:48:01, 28.32s/it]2021-12-14 01:27:00,392 iteration 749 : loss : 0.135951, loss_ce: 0.021735
2021-12-14 01:27:01,947 iteration 750 : loss : 0.122604, loss_ce: 0.033388
2021-12-14 01:27:03,538 iteration 751 : loss : 0.102816, loss_ce: 0.022490
2021-12-14 01:27:05,097 iteration 752 : loss : 0.136803, loss_ce: 0.051162
2021-12-14 01:27:06,622 iteration 753 : loss : 0.131822, loss_ce: 0.043761
2021-12-14 01:27:08,154 iteration 754 : loss : 0.134478, loss_ce: 0.043641
2021-12-14 01:27:09,643 iteration 755 : loss : 0.128930, loss_ce: 0.048882
2021-12-14 01:27:11,138 iteration 756 : loss : 0.107441, loss_ce: 0.028482
2021-12-14 01:27:12,700 iteration 757 : loss : 0.128456, loss_ce: 0.045594
2021-12-14 01:27:14,352 iteration 758 : loss : 0.127116, loss_ce: 0.043805
2021-12-14 01:27:16,056 iteration 759 : loss : 0.125881, loss_ce: 0.039797
2021-12-14 01:27:17,612 iteration 760 : loss : 0.135034, loss_ce: 0.052385
2021-12-14 01:27:19,207 iteration 761 : loss : 0.119701, loss_ce: 0.038463
2021-12-14 01:27:20,822 iteration 762 : loss : 0.118928, loss_ce: 0.036959
2021-12-14 01:27:22,444 iteration 763 : loss : 0.112314, loss_ce: 0.031815
2021-12-14 01:27:23,993 iteration 764 : loss : 0.121202, loss_ce: 0.037446
2021-12-14 01:27:23,993 Training Data Eval:
2021-12-14 01:27:32,169   Average segmentation loss on training set: 0.1467
2021-12-14 01:27:32,170 Validation Data Eval:
2021-12-14 01:27:34,964   Average segmentation loss on validation set: 0.1535
2021-12-14 01:27:36,699 iteration 765 : loss : 0.131951, loss_ce: 0.042949
 11%|███▍                          | 45/400 [22:33<3:04:31, 31.19s/it]2021-12-14 01:27:38,388 iteration 766 : loss : 0.153147, loss_ce: 0.055933
2021-12-14 01:27:39,998 iteration 767 : loss : 0.113330, loss_ce: 0.032952
2021-12-14 01:27:41,599 iteration 768 : loss : 0.109698, loss_ce: 0.030284
2021-12-14 01:27:43,217 iteration 769 : loss : 0.120913, loss_ce: 0.039682
2021-12-14 01:27:44,718 iteration 770 : loss : 0.115202, loss_ce: 0.034195
2021-12-14 01:27:46,301 iteration 771 : loss : 0.146221, loss_ce: 0.031182
2021-12-14 01:27:47,893 iteration 772 : loss : 0.124511, loss_ce: 0.037889
2021-12-14 01:27:49,499 iteration 773 : loss : 0.143818, loss_ce: 0.031948
2021-12-14 01:27:51,185 iteration 774 : loss : 0.123345, loss_ce: 0.041559
2021-12-14 01:27:52,743 iteration 775 : loss : 0.131492, loss_ce: 0.047050
2021-12-14 01:27:54,280 iteration 776 : loss : 0.138879, loss_ce: 0.042415
2021-12-14 01:27:56,031 iteration 777 : loss : 0.147957, loss_ce: 0.053991
2021-12-14 01:27:57,540 iteration 778 : loss : 0.131464, loss_ce: 0.037999
2021-12-14 01:27:59,171 iteration 779 : loss : 0.136005, loss_ce: 0.049367
2021-12-14 01:28:00,808 iteration 780 : loss : 0.128420, loss_ce: 0.034878
2021-12-14 01:28:02,344 iteration 781 : loss : 0.127111, loss_ce: 0.048405
2021-12-14 01:28:03,837 iteration 782 : loss : 0.116941, loss_ce: 0.041636
 12%|███▍                          | 46/400 [23:00<2:56:49, 29.97s/it]2021-12-14 01:28:05,454 iteration 783 : loss : 0.136498, loss_ce: 0.049258
2021-12-14 01:28:06,995 iteration 784 : loss : 0.119322, loss_ce: 0.036284
2021-12-14 01:28:08,574 iteration 785 : loss : 0.140722, loss_ce: 0.049904
2021-12-14 01:28:10,126 iteration 786 : loss : 0.125944, loss_ce: 0.034615
2021-12-14 01:28:11,688 iteration 787 : loss : 0.126546, loss_ce: 0.038553
2021-12-14 01:28:13,317 iteration 788 : loss : 0.136620, loss_ce: 0.044098
2021-12-14 01:28:14,808 iteration 789 : loss : 0.124790, loss_ce: 0.031970
2021-12-14 01:28:16,431 iteration 790 : loss : 0.114956, loss_ce: 0.028236
2021-12-14 01:28:18,002 iteration 791 : loss : 0.106809, loss_ce: 0.030806
2021-12-14 01:28:19,522 iteration 792 : loss : 0.116338, loss_ce: 0.035804
2021-12-14 01:28:21,157 iteration 793 : loss : 0.134259, loss_ce: 0.053282
2021-12-14 01:28:22,643 iteration 794 : loss : 0.106920, loss_ce: 0.033421
2021-12-14 01:28:24,156 iteration 795 : loss : 0.122373, loss_ce: 0.037743
2021-12-14 01:28:25,668 iteration 796 : loss : 0.134082, loss_ce: 0.050898
2021-12-14 01:28:27,276 iteration 797 : loss : 0.145467, loss_ce: 0.043244
2021-12-14 01:28:28,824 iteration 798 : loss : 0.119190, loss_ce: 0.032847
2021-12-14 01:28:30,326 iteration 799 : loss : 0.115068, loss_ce: 0.039061
 12%|███▌                          | 47/400 [23:27<2:50:11, 28.93s/it]2021-12-14 01:28:32,057 iteration 800 : loss : 0.130829, loss_ce: 0.033725
2021-12-14 01:28:33,652 iteration 801 : loss : 0.116995, loss_ce: 0.038068
2021-12-14 01:28:35,234 iteration 802 : loss : 0.148298, loss_ce: 0.044343
2021-12-14 01:28:36,824 iteration 803 : loss : 0.125967, loss_ce: 0.051021
2021-12-14 01:28:38,482 iteration 804 : loss : 0.154174, loss_ce: 0.057116
2021-12-14 01:28:40,203 iteration 805 : loss : 0.105325, loss_ce: 0.029978
2021-12-14 01:28:41,758 iteration 806 : loss : 0.118842, loss_ce: 0.040518
2021-12-14 01:28:43,282 iteration 807 : loss : 0.117851, loss_ce: 0.035277
2021-12-14 01:28:44,891 iteration 808 : loss : 0.121321, loss_ce: 0.044568
2021-12-14 01:28:46,475 iteration 809 : loss : 0.132138, loss_ce: 0.039734
2021-12-14 01:28:48,020 iteration 810 : loss : 0.137883, loss_ce: 0.038739
2021-12-14 01:28:49,530 iteration 811 : loss : 0.141621, loss_ce: 0.058516
2021-12-14 01:28:51,068 iteration 812 : loss : 0.122443, loss_ce: 0.039345
2021-12-14 01:28:52,636 iteration 813 : loss : 0.128045, loss_ce: 0.034184
2021-12-14 01:28:54,318 iteration 814 : loss : 0.126390, loss_ce: 0.036496
2021-12-14 01:28:55,956 iteration 815 : loss : 0.129971, loss_ce: 0.041113
2021-12-14 01:28:57,547 iteration 816 : loss : 0.121037, loss_ce: 0.036088
 12%|███▌                          | 48/400 [23:54<2:46:41, 28.41s/it]2021-12-14 01:28:59,171 iteration 817 : loss : 0.119488, loss_ce: 0.037944
2021-12-14 01:29:00,688 iteration 818 : loss : 0.108448, loss_ce: 0.034587
2021-12-14 01:29:02,263 iteration 819 : loss : 0.107520, loss_ce: 0.028915
2021-12-14 01:29:03,767 iteration 820 : loss : 0.115258, loss_ce: 0.035027
2021-12-14 01:29:05,402 iteration 821 : loss : 0.103560, loss_ce: 0.027763
2021-12-14 01:29:07,008 iteration 822 : loss : 0.121370, loss_ce: 0.031198
2021-12-14 01:29:08,530 iteration 823 : loss : 0.114140, loss_ce: 0.032691
2021-12-14 01:29:10,049 iteration 824 : loss : 0.116534, loss_ce: 0.038156
2021-12-14 01:29:11,611 iteration 825 : loss : 0.114470, loss_ce: 0.034162
2021-12-14 01:29:13,162 iteration 826 : loss : 0.122608, loss_ce: 0.026964
2021-12-14 01:29:14,723 iteration 827 : loss : 0.140843, loss_ce: 0.040426
2021-12-14 01:29:16,284 iteration 828 : loss : 0.119038, loss_ce: 0.036231
2021-12-14 01:29:17,868 iteration 829 : loss : 0.126508, loss_ce: 0.037217
2021-12-14 01:29:19,490 iteration 830 : loss : 0.117545, loss_ce: 0.033923
2021-12-14 01:29:21,058 iteration 831 : loss : 0.141886, loss_ce: 0.054680
2021-12-14 01:29:22,602 iteration 832 : loss : 0.105050, loss_ce: 0.030892
2021-12-14 01:29:24,221 iteration 833 : loss : 0.120966, loss_ce: 0.044445
 12%|███▋                          | 49/400 [24:21<2:43:10, 27.89s/it]2021-12-14 01:29:25,851 iteration 834 : loss : 0.119777, loss_ce: 0.036980
2021-12-14 01:29:27,333 iteration 835 : loss : 0.106565, loss_ce: 0.025952
2021-12-14 01:29:28,908 iteration 836 : loss : 0.105292, loss_ce: 0.033803
2021-12-14 01:29:30,424 iteration 837 : loss : 0.112101, loss_ce: 0.041560
2021-12-14 01:29:31,918 iteration 838 : loss : 0.112947, loss_ce: 0.034683
2021-12-14 01:29:33,507 iteration 839 : loss : 0.119116, loss_ce: 0.041219
2021-12-14 01:29:35,063 iteration 840 : loss : 0.118124, loss_ce: 0.031349
2021-12-14 01:29:36,582 iteration 841 : loss : 0.112632, loss_ce: 0.036027
2021-12-14 01:29:38,135 iteration 842 : loss : 0.112155, loss_ce: 0.034632
2021-12-14 01:29:39,791 iteration 843 : loss : 0.121325, loss_ce: 0.034432
2021-12-14 01:29:41,343 iteration 844 : loss : 0.113864, loss_ce: 0.029883
2021-12-14 01:29:42,938 iteration 845 : loss : 0.116886, loss_ce: 0.031786
2021-12-14 01:29:44,627 iteration 846 : loss : 0.121323, loss_ce: 0.043318
2021-12-14 01:29:46,215 iteration 847 : loss : 0.108729, loss_ce: 0.033262
2021-12-14 01:29:47,695 iteration 848 : loss : 0.106006, loss_ce: 0.032504
2021-12-14 01:29:49,284 iteration 849 : loss : 0.114851, loss_ce: 0.032311
2021-12-14 01:29:49,284 Training Data Eval:
2021-12-14 01:29:57,466   Average segmentation loss on training set: 0.1004
2021-12-14 01:29:57,467 Validation Data Eval:
2021-12-14 01:30:00,256   Average segmentation loss on validation set: 0.1337
2021-12-14 01:30:06,505 Found new lowest validation loss at iteration 849! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/TU_3seeds/REVISED_SGD_best_val_loss_seed1234.pth
2021-12-14 01:30:08,041 iteration 850 : loss : 0.110839, loss_ce: 0.028719
 12%|███▊                          | 50/400 [25:04<3:10:33, 32.67s/it]2021-12-14 01:30:09,554 iteration 851 : loss : 0.106190, loss_ce: 0.028999
2021-12-14 01:30:11,098 iteration 852 : loss : 0.104210, loss_ce: 0.027942
2021-12-14 01:30:12,761 iteration 853 : loss : 0.135492, loss_ce: 0.051199
2021-12-14 01:30:14,372 iteration 854 : loss : 0.098773, loss_ce: 0.024582
2021-12-14 01:30:15,973 iteration 855 : loss : 0.118840, loss_ce: 0.037542
2021-12-14 01:30:17,595 iteration 856 : loss : 0.117533, loss_ce: 0.030653
2021-12-14 01:30:19,142 iteration 857 : loss : 0.113357, loss_ce: 0.038083
2021-12-14 01:30:20,626 iteration 858 : loss : 0.106543, loss_ce: 0.035228
2021-12-14 01:30:22,186 iteration 859 : loss : 0.116140, loss_ce: 0.034128
2021-12-14 01:30:23,702 iteration 860 : loss : 0.117897, loss_ce: 0.027909
2021-12-14 01:30:25,345 iteration 861 : loss : 0.116237, loss_ce: 0.037778
2021-12-14 01:30:26,848 iteration 862 : loss : 0.110514, loss_ce: 0.029493
2021-12-14 01:30:28,498 iteration 863 : loss : 0.140108, loss_ce: 0.047263
2021-12-14 01:30:30,115 iteration 864 : loss : 0.117704, loss_ce: 0.042048
2021-12-14 01:30:31,613 iteration 865 : loss : 0.108297, loss_ce: 0.034659
2021-12-14 01:30:33,248 iteration 866 : loss : 0.129030, loss_ce: 0.049352
2021-12-14 01:30:34,760 iteration 867 : loss : 0.100690, loss_ce: 0.027086
 13%|███▊                          | 51/400 [25:31<2:59:37, 30.88s/it]2021-12-14 01:30:36,420 iteration 868 : loss : 0.123060, loss_ce: 0.033170
2021-12-14 01:30:37,995 iteration 869 : loss : 0.114212, loss_ce: 0.031332
2021-12-14 01:30:39,477 iteration 870 : loss : 0.097310, loss_ce: 0.027148
2021-12-14 01:30:41,000 iteration 871 : loss : 0.104623, loss_ce: 0.030633
2021-12-14 01:30:42,547 iteration 872 : loss : 0.107541, loss_ce: 0.038221
2021-12-14 01:30:44,197 iteration 873 : loss : 0.107539, loss_ce: 0.026222
2021-12-14 01:30:45,689 iteration 874 : loss : 0.100819, loss_ce: 0.032469
2021-12-14 01:30:47,411 iteration 875 : loss : 0.126486, loss_ce: 0.035025
2021-12-14 01:30:48,994 iteration 876 : loss : 0.098643, loss_ce: 0.031058
2021-12-14 01:30:50,470 iteration 877 : loss : 0.107971, loss_ce: 0.029461
2021-12-14 01:30:52,087 iteration 878 : loss : 0.110303, loss_ce: 0.035409
2021-12-14 01:30:53,634 iteration 879 : loss : 0.107868, loss_ce: 0.029943
2021-12-14 01:30:55,236 iteration 880 : loss : 0.097161, loss_ce: 0.024903
2021-12-14 01:30:56,775 iteration 881 : loss : 0.126960, loss_ce: 0.039574
2021-12-14 01:30:58,401 iteration 882 : loss : 0.113827, loss_ce: 0.033350
2021-12-14 01:30:59,972 iteration 883 : loss : 0.111918, loss_ce: 0.035256
2021-12-14 01:31:01,648 iteration 884 : loss : 0.122133, loss_ce: 0.040214
 13%|███▉                          | 52/400 [25:58<2:52:10, 29.69s/it]2021-12-14 01:31:03,304 iteration 885 : loss : 0.119029, loss_ce: 0.037813
2021-12-14 01:31:04,923 iteration 886 : loss : 0.111707, loss_ce: 0.031937
2021-12-14 01:31:06,544 iteration 887 : loss : 0.132220, loss_ce: 0.047213
2021-12-14 01:31:08,135 iteration 888 : loss : 0.104408, loss_ce: 0.028818
2021-12-14 01:31:09,788 iteration 889 : loss : 0.110684, loss_ce: 0.026782
2021-12-14 01:31:11,478 iteration 890 : loss : 0.121918, loss_ce: 0.032042
2021-12-14 01:31:13,076 iteration 891 : loss : 0.094373, loss_ce: 0.023848
2021-12-14 01:31:14,661 iteration 892 : loss : 0.121254, loss_ce: 0.043508
2021-12-14 01:31:16,224 iteration 893 : loss : 0.122532, loss_ce: 0.033264
2021-12-14 01:31:17,919 iteration 894 : loss : 0.119083, loss_ce: 0.035066
2021-12-14 01:31:19,470 iteration 895 : loss : 0.127981, loss_ce: 0.031237
2021-12-14 01:31:21,114 iteration 896 : loss : 0.124091, loss_ce: 0.040074
2021-12-14 01:31:22,789 iteration 897 : loss : 0.121074, loss_ce: 0.041502
2021-12-14 01:31:24,354 iteration 898 : loss : 0.112129, loss_ce: 0.039919
2021-12-14 01:31:25,918 iteration 899 : loss : 0.122750, loss_ce: 0.039917
2021-12-14 01:31:27,440 iteration 900 : loss : 0.104714, loss_ce: 0.033284
2021-12-14 01:31:28,985 iteration 901 : loss : 0.110053, loss_ce: 0.028614
 13%|███▉                          | 53/400 [26:25<2:47:36, 28.98s/it]2021-12-14 01:31:30,659 iteration 902 : loss : 0.112474, loss_ce: 0.035762
2021-12-14 01:31:32,336 iteration 903 : loss : 0.108144, loss_ce: 0.028986
2021-12-14 01:31:33,954 iteration 904 : loss : 0.122442, loss_ce: 0.033598
2021-12-14 01:31:35,559 iteration 905 : loss : 0.137882, loss_ce: 0.049978
2021-12-14 01:31:37,141 iteration 906 : loss : 0.111782, loss_ce: 0.032138
2021-12-14 01:31:38,788 iteration 907 : loss : 0.125357, loss_ce: 0.030126
2021-12-14 01:31:40,272 iteration 908 : loss : 0.103651, loss_ce: 0.028107
2021-12-14 01:31:41,883 iteration 909 : loss : 0.110474, loss_ce: 0.035422
2021-12-14 01:31:43,393 iteration 910 : loss : 0.125134, loss_ce: 0.039372
2021-12-14 01:31:44,966 iteration 911 : loss : 0.104145, loss_ce: 0.030283
2021-12-14 01:31:46,529 iteration 912 : loss : 0.113831, loss_ce: 0.032358
2021-12-14 01:31:48,077 iteration 913 : loss : 0.111555, loss_ce: 0.029544
2021-12-14 01:31:49,642 iteration 914 : loss : 0.134300, loss_ce: 0.045639
2021-12-14 01:31:51,184 iteration 915 : loss : 0.121445, loss_ce: 0.031627
2021-12-14 01:31:52,729 iteration 916 : loss : 0.100556, loss_ce: 0.029019
2021-12-14 01:31:54,335 iteration 917 : loss : 0.132759, loss_ce: 0.044018
2021-12-14 01:31:55,954 iteration 918 : loss : 0.118353, loss_ce: 0.033560
 14%|████                          | 54/400 [26:52<2:43:38, 28.38s/it]2021-12-14 01:31:57,641 iteration 919 : loss : 0.105827, loss_ce: 0.032765
2021-12-14 01:31:59,243 iteration 920 : loss : 0.122676, loss_ce: 0.042165
2021-12-14 01:32:00,869 iteration 921 : loss : 0.108016, loss_ce: 0.032032
2021-12-14 01:32:02,511 iteration 922 : loss : 0.111191, loss_ce: 0.040661
2021-12-14 01:32:04,068 iteration 923 : loss : 0.107160, loss_ce: 0.035359
2021-12-14 01:32:05,705 iteration 924 : loss : 0.116921, loss_ce: 0.028524
2021-12-14 01:32:07,248 iteration 925 : loss : 0.100579, loss_ce: 0.024906
2021-12-14 01:32:08,882 iteration 926 : loss : 0.105972, loss_ce: 0.033193
2021-12-14 01:32:10,390 iteration 927 : loss : 0.112055, loss_ce: 0.029837
2021-12-14 01:32:11,962 iteration 928 : loss : 0.109011, loss_ce: 0.035398
2021-12-14 01:32:13,603 iteration 929 : loss : 0.134974, loss_ce: 0.040097
2021-12-14 01:32:15,207 iteration 930 : loss : 0.112547, loss_ce: 0.036392
2021-12-14 01:32:16,816 iteration 931 : loss : 0.116838, loss_ce: 0.026602
2021-12-14 01:32:18,398 iteration 932 : loss : 0.112395, loss_ce: 0.029353
2021-12-14 01:32:19,950 iteration 933 : loss : 0.111522, loss_ce: 0.034889
2021-12-14 01:32:21,524 iteration 934 : loss : 0.106041, loss_ce: 0.033705
2021-12-14 01:32:21,525 Training Data Eval:
2021-12-14 01:32:29,707   Average segmentation loss on training set: 0.0963
2021-12-14 01:32:29,707 Validation Data Eval:
2021-12-14 01:32:32,501   Average segmentation loss on validation set: 0.1339
2021-12-14 01:32:34,165 iteration 935 : loss : 0.135583, loss_ce: 0.034705
 14%|████▏                         | 55/400 [27:31<3:00:07, 31.33s/it]2021-12-14 01:32:35,773 iteration 936 : loss : 0.101326, loss_ce: 0.029011
2021-12-14 01:32:37,362 iteration 937 : loss : 0.107675, loss_ce: 0.026567
2021-12-14 01:32:38,975 iteration 938 : loss : 0.106214, loss_ce: 0.028768
2021-12-14 01:32:40,506 iteration 939 : loss : 0.106924, loss_ce: 0.029092
2021-12-14 01:32:42,091 iteration 940 : loss : 0.112490, loss_ce: 0.038657
2021-12-14 01:32:43,761 iteration 941 : loss : 0.117098, loss_ce: 0.034068
2021-12-14 01:32:45,291 iteration 942 : loss : 0.099750, loss_ce: 0.027687
2021-12-14 01:32:46,844 iteration 943 : loss : 0.114731, loss_ce: 0.040252
2021-12-14 01:32:48,369 iteration 944 : loss : 0.109872, loss_ce: 0.031055
2021-12-14 01:32:49,909 iteration 945 : loss : 0.102688, loss_ce: 0.028204
2021-12-14 01:32:51,445 iteration 946 : loss : 0.100277, loss_ce: 0.028890
2021-12-14 01:32:52,970 iteration 947 : loss : 0.107127, loss_ce: 0.027422
2021-12-14 01:32:54,498 iteration 948 : loss : 0.107447, loss_ce: 0.030864
2021-12-14 01:32:56,059 iteration 949 : loss : 0.102268, loss_ce: 0.029587
2021-12-14 01:32:57,610 iteration 950 : loss : 0.122386, loss_ce: 0.041347
2021-12-14 01:32:59,216 iteration 951 : loss : 0.106910, loss_ce: 0.036064
2021-12-14 01:33:00,735 iteration 952 : loss : 0.110106, loss_ce: 0.033923
 14%|████▏                         | 56/400 [27:57<2:51:25, 29.90s/it]2021-12-14 01:33:02,380 iteration 953 : loss : 0.109122, loss_ce: 0.030780
2021-12-14 01:33:04,002 iteration 954 : loss : 0.108143, loss_ce: 0.035283
2021-12-14 01:33:05,506 iteration 955 : loss : 0.096573, loss_ce: 0.028533
2021-12-14 01:33:07,115 iteration 956 : loss : 0.110171, loss_ce: 0.032708
2021-12-14 01:33:08,708 iteration 957 : loss : 0.108976, loss_ce: 0.030419
2021-12-14 01:33:10,310 iteration 958 : loss : 0.105150, loss_ce: 0.028595
2021-12-14 01:33:11,981 iteration 959 : loss : 0.117870, loss_ce: 0.044068
2021-12-14 01:33:13,712 iteration 960 : loss : 0.116267, loss_ce: 0.038647
2021-12-14 01:33:15,261 iteration 961 : loss : 0.108784, loss_ce: 0.026060
2021-12-14 01:33:16,773 iteration 962 : loss : 0.105820, loss_ce: 0.023659
2021-12-14 01:33:18,423 iteration 963 : loss : 0.115993, loss_ce: 0.034237
2021-12-14 01:33:20,032 iteration 964 : loss : 0.105729, loss_ce: 0.037658
2021-12-14 01:33:21,582 iteration 965 : loss : 0.111608, loss_ce: 0.036558
2021-12-14 01:33:23,157 iteration 966 : loss : 0.109978, loss_ce: 0.034774
2021-12-14 01:33:24,746 iteration 967 : loss : 0.107563, loss_ce: 0.030938
2021-12-14 01:33:26,271 iteration 968 : loss : 0.127659, loss_ce: 0.032668
2021-12-14 01:33:27,865 iteration 969 : loss : 0.106436, loss_ce: 0.033519
 14%|████▎                         | 57/400 [28:24<2:46:11, 29.07s/it]2021-12-14 01:33:29,480 iteration 970 : loss : 0.114166, loss_ce: 0.041837
2021-12-14 01:33:31,083 iteration 971 : loss : 0.120483, loss_ce: 0.028936
2021-12-14 01:33:32,598 iteration 972 : loss : 0.099883, loss_ce: 0.034417
2021-12-14 01:33:34,197 iteration 973 : loss : 0.110810, loss_ce: 0.028006
2021-12-14 01:33:35,718 iteration 974 : loss : 0.112112, loss_ce: 0.038308
2021-12-14 01:33:37,345 iteration 975 : loss : 0.122373, loss_ce: 0.032092
2021-12-14 01:33:38,898 iteration 976 : loss : 0.103502, loss_ce: 0.032395
2021-12-14 01:33:40,461 iteration 977 : loss : 0.103910, loss_ce: 0.026082
2021-12-14 01:33:42,050 iteration 978 : loss : 0.094569, loss_ce: 0.025592
2021-12-14 01:33:43,596 iteration 979 : loss : 0.126409, loss_ce: 0.042903
2021-12-14 01:33:45,146 iteration 980 : loss : 0.089540, loss_ce: 0.023402
2021-12-14 01:33:46,811 iteration 981 : loss : 0.101724, loss_ce: 0.033845
2021-12-14 01:33:48,356 iteration 982 : loss : 0.107606, loss_ce: 0.038682
2021-12-14 01:33:49,981 iteration 983 : loss : 0.133974, loss_ce: 0.035017
2021-12-14 01:33:51,479 iteration 984 : loss : 0.112477, loss_ce: 0.039586
2021-12-14 01:33:53,050 iteration 985 : loss : 0.102735, loss_ce: 0.026273
2021-12-14 01:33:54,681 iteration 986 : loss : 0.127860, loss_ce: 0.039614
 14%|████▎                         | 58/400 [28:51<2:41:51, 28.40s/it]2021-12-14 01:33:56,382 iteration 987 : loss : 0.105766, loss_ce: 0.036423
2021-12-14 01:33:57,987 iteration 988 : loss : 0.110823, loss_ce: 0.036887
2021-12-14 01:33:59,574 iteration 989 : loss : 0.108765, loss_ce: 0.028266
2021-12-14 01:34:01,145 iteration 990 : loss : 0.110311, loss_ce: 0.035126
2021-12-14 01:34:02,708 iteration 991 : loss : 0.100389, loss_ce: 0.030401
2021-12-14 01:34:04,363 iteration 992 : loss : 0.109085, loss_ce: 0.036536
2021-12-14 01:34:05,974 iteration 993 : loss : 0.096529, loss_ce: 0.025506
2021-12-14 01:34:07,668 iteration 994 : loss : 0.110516, loss_ce: 0.033537
2021-12-14 01:34:09,265 iteration 995 : loss : 0.121206, loss_ce: 0.032057
2021-12-14 01:34:10,904 iteration 996 : loss : 0.106881, loss_ce: 0.033887
2021-12-14 01:34:12,537 iteration 997 : loss : 0.120733, loss_ce: 0.038673
2021-12-14 01:34:14,063 iteration 998 : loss : 0.127456, loss_ce: 0.032262
2021-12-14 01:34:15,693 iteration 999 : loss : 0.099135, loss_ce: 0.028346
2021-12-14 01:34:17,232 iteration 1000 : loss : 0.114356, loss_ce: 0.029979
2021-12-14 01:34:18,783 iteration 1001 : loss : 0.120087, loss_ce: 0.026421
2021-12-14 01:34:20,463 iteration 1002 : loss : 0.100872, loss_ce: 0.030453
2021-12-14 01:34:22,124 iteration 1003 : loss : 0.130817, loss_ce: 0.043539
 15%|████▍                         | 59/400 [29:19<2:39:45, 28.11s/it]2021-12-14 01:34:23,765 iteration 1004 : loss : 0.142548, loss_ce: 0.044073
2021-12-14 01:34:25,333 iteration 1005 : loss : 0.114868, loss_ce: 0.036456
2021-12-14 01:34:26,992 iteration 1006 : loss : 0.127845, loss_ce: 0.047787
2021-12-14 01:34:28,531 iteration 1007 : loss : 0.108489, loss_ce: 0.042255
2021-12-14 01:34:30,056 iteration 1008 : loss : 0.128778, loss_ce: 0.039842
2021-12-14 01:34:31,593 iteration 1009 : loss : 0.116321, loss_ce: 0.032082
2021-12-14 01:34:33,127 iteration 1010 : loss : 0.114747, loss_ce: 0.034903
2021-12-14 01:34:34,786 iteration 1011 : loss : 0.107469, loss_ce: 0.034254
2021-12-14 01:34:36,348 iteration 1012 : loss : 0.089651, loss_ce: 0.023052
2021-12-14 01:34:37,863 iteration 1013 : loss : 0.093513, loss_ce: 0.023974
2021-12-14 01:34:39,450 iteration 1014 : loss : 0.128265, loss_ce: 0.041060
2021-12-14 01:34:40,957 iteration 1015 : loss : 0.108366, loss_ce: 0.034158
2021-12-14 01:34:42,538 iteration 1016 : loss : 0.103832, loss_ce: 0.033832
2021-12-14 01:34:44,015 iteration 1017 : loss : 0.104067, loss_ce: 0.027021
2021-12-14 01:34:45,493 iteration 1018 : loss : 0.107941, loss_ce: 0.029238
2021-12-14 01:34:47,048 iteration 1019 : loss : 0.108978, loss_ce: 0.032627
2021-12-14 01:34:47,048 Training Data Eval:
2021-12-14 01:34:55,219   Average segmentation loss on training set: 0.1023
2021-12-14 01:34:55,220 Validation Data Eval:
2021-12-14 01:34:58,006   Average segmentation loss on validation set: 0.1257
2021-12-14 01:35:04,522 Found new lowest validation loss at iteration 1019! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/TU_3seeds/REVISED_SGD_best_val_loss_seed1234.pth
2021-12-14 01:35:05,951 iteration 1020 : loss : 0.097878, loss_ce: 0.025802
 15%|████▌                         | 60/400 [30:02<3:06:00, 32.82s/it]2021-12-14 01:35:07,522 iteration 1021 : loss : 0.121882, loss_ce: 0.027490
2021-12-14 01:35:09,056 iteration 1022 : loss : 0.097315, loss_ce: 0.030477
2021-12-14 01:35:10,639 iteration 1023 : loss : 0.141248, loss_ce: 0.037382
2021-12-14 01:35:12,281 iteration 1024 : loss : 0.098318, loss_ce: 0.028640
2021-12-14 01:35:13,901 iteration 1025 : loss : 0.098332, loss_ce: 0.029942
2021-12-14 01:35:15,388 iteration 1026 : loss : 0.097599, loss_ce: 0.027887
2021-12-14 01:35:17,008 iteration 1027 : loss : 0.118398, loss_ce: 0.029652
2021-12-14 01:35:18,614 iteration 1028 : loss : 0.125315, loss_ce: 0.042728
2021-12-14 01:35:20,172 iteration 1029 : loss : 0.097296, loss_ce: 0.028629
2021-12-14 01:35:21,742 iteration 1030 : loss : 0.106239, loss_ce: 0.027557
2021-12-14 01:35:23,369 iteration 1031 : loss : 0.126118, loss_ce: 0.041350
2021-12-14 01:35:24,966 iteration 1032 : loss : 0.138176, loss_ce: 0.048531
2021-12-14 01:35:26,511 iteration 1033 : loss : 0.106585, loss_ce: 0.027952
2021-12-14 01:35:28,154 iteration 1034 : loss : 0.109239, loss_ce: 0.031184
2021-12-14 01:35:29,755 iteration 1035 : loss : 0.093297, loss_ce: 0.028156
2021-12-14 01:35:31,353 iteration 1036 : loss : 0.107168, loss_ce: 0.033786
2021-12-14 01:35:32,902 iteration 1037 : loss : 0.105871, loss_ce: 0.026833
 15%|████▌                         | 61/400 [30:29<2:55:28, 31.06s/it]2021-12-14 01:35:34,552 iteration 1038 : loss : 0.094404, loss_ce: 0.025745
2021-12-14 01:35:36,129 iteration 1039 : loss : 0.109464, loss_ce: 0.039569
2021-12-14 01:35:37,742 iteration 1040 : loss : 0.119199, loss_ce: 0.041997
2021-12-14 01:35:39,338 iteration 1041 : loss : 0.102803, loss_ce: 0.032030
2021-12-14 01:35:40,942 iteration 1042 : loss : 0.102369, loss_ce: 0.033223
2021-12-14 01:35:42,536 iteration 1043 : loss : 0.111877, loss_ce: 0.031449
2021-12-14 01:35:44,142 iteration 1044 : loss : 0.107046, loss_ce: 0.032108
2021-12-14 01:35:45,634 iteration 1045 : loss : 0.099219, loss_ce: 0.030904
2021-12-14 01:35:47,159 iteration 1046 : loss : 0.119269, loss_ce: 0.024125
2021-12-14 01:35:48,776 iteration 1047 : loss : 0.131881, loss_ce: 0.037376
2021-12-14 01:35:50,353 iteration 1048 : loss : 0.105940, loss_ce: 0.029780
2021-12-14 01:35:51,935 iteration 1049 : loss : 0.131283, loss_ce: 0.036175
2021-12-14 01:35:53,573 iteration 1050 : loss : 0.112495, loss_ce: 0.029248
2021-12-14 01:35:55,151 iteration 1051 : loss : 0.103468, loss_ce: 0.032288
2021-12-14 01:35:56,731 iteration 1052 : loss : 0.115985, loss_ce: 0.037937
2021-12-14 01:35:58,236 iteration 1053 : loss : 0.110995, loss_ce: 0.028576
2021-12-14 01:35:59,889 iteration 1054 : loss : 0.106271, loss_ce: 0.033210
 16%|████▋                         | 62/400 [30:56<2:48:04, 29.84s/it]2021-12-14 01:36:01,517 iteration 1055 : loss : 0.098840, loss_ce: 0.023695
2021-12-14 01:36:03,069 iteration 1056 : loss : 0.108987, loss_ce: 0.039537
2021-12-14 01:36:04,626 iteration 1057 : loss : 0.120766, loss_ce: 0.042781
2021-12-14 01:36:06,196 iteration 1058 : loss : 0.123321, loss_ce: 0.044186
2021-12-14 01:36:07,686 iteration 1059 : loss : 0.097595, loss_ce: 0.025046
2021-12-14 01:36:09,251 iteration 1060 : loss : 0.092905, loss_ce: 0.025386
2021-12-14 01:36:10,853 iteration 1061 : loss : 0.099745, loss_ce: 0.027842
2021-12-14 01:36:12,444 iteration 1062 : loss : 0.106036, loss_ce: 0.032117
2021-12-14 01:36:14,083 iteration 1063 : loss : 0.142205, loss_ce: 0.038744
2021-12-14 01:36:15,653 iteration 1064 : loss : 0.111014, loss_ce: 0.027662
2021-12-14 01:36:17,169 iteration 1065 : loss : 0.096958, loss_ce: 0.025027
2021-12-14 01:36:18,780 iteration 1066 : loss : 0.107490, loss_ce: 0.031776
2021-12-14 01:36:20,336 iteration 1067 : loss : 0.116904, loss_ce: 0.025246
2021-12-14 01:36:21,962 iteration 1068 : loss : 0.112079, loss_ce: 0.042835
2021-12-14 01:36:23,564 iteration 1069 : loss : 0.109434, loss_ce: 0.034156
2021-12-14 01:36:25,134 iteration 1070 : loss : 0.095830, loss_ce: 0.030594
2021-12-14 01:36:26,696 iteration 1071 : loss : 0.098575, loss_ce: 0.031936
 16%|████▋                         | 63/400 [31:23<2:42:29, 28.93s/it]2021-12-14 01:36:28,434 iteration 1072 : loss : 0.094171, loss_ce: 0.024750
2021-12-14 01:36:30,001 iteration 1073 : loss : 0.121640, loss_ce: 0.023003
2021-12-14 01:36:31,569 iteration 1074 : loss : 0.101724, loss_ce: 0.030052
2021-12-14 01:36:33,181 iteration 1075 : loss : 0.109974, loss_ce: 0.029324
2021-12-14 01:36:34,701 iteration 1076 : loss : 0.098735, loss_ce: 0.027795
2021-12-14 01:36:36,264 iteration 1077 : loss : 0.105977, loss_ce: 0.027436
2021-12-14 01:36:37,902 iteration 1078 : loss : 0.128689, loss_ce: 0.054769
2021-12-14 01:36:39,438 iteration 1079 : loss : 0.098454, loss_ce: 0.027518
2021-12-14 01:36:40,964 iteration 1080 : loss : 0.099829, loss_ce: 0.032259
2021-12-14 01:36:42,565 iteration 1081 : loss : 0.097431, loss_ce: 0.021756
2021-12-14 01:36:44,159 iteration 1082 : loss : 0.114027, loss_ce: 0.042065
2021-12-14 01:36:45,780 iteration 1083 : loss : 0.123846, loss_ce: 0.040925
2021-12-14 01:36:47,334 iteration 1084 : loss : 0.114010, loss_ce: 0.042511
2021-12-14 01:36:48,982 iteration 1085 : loss : 0.109551, loss_ce: 0.030561
2021-12-14 01:36:50,539 iteration 1086 : loss : 0.107892, loss_ce: 0.032908
2021-12-14 01:36:52,110 iteration 1087 : loss : 0.108872, loss_ce: 0.033637
2021-12-14 01:36:53,747 iteration 1088 : loss : 0.111978, loss_ce: 0.039467
 16%|████▊                         | 64/400 [31:50<2:38:51, 28.37s/it]2021-12-14 01:36:55,360 iteration 1089 : loss : 0.106652, loss_ce: 0.034900
2021-12-14 01:36:56,918 iteration 1090 : loss : 0.093627, loss_ce: 0.031776
2021-12-14 01:36:58,501 iteration 1091 : loss : 0.093580, loss_ce: 0.030491
2021-12-14 01:37:00,082 iteration 1092 : loss : 0.100690, loss_ce: 0.032118
2021-12-14 01:37:01,677 iteration 1093 : loss : 0.102880, loss_ce: 0.028113
2021-12-14 01:37:03,321 iteration 1094 : loss : 0.095251, loss_ce: 0.026831
2021-12-14 01:37:04,849 iteration 1095 : loss : 0.099424, loss_ce: 0.031176
2021-12-14 01:37:06,521 iteration 1096 : loss : 0.108505, loss_ce: 0.031625
2021-12-14 01:37:08,119 iteration 1097 : loss : 0.122763, loss_ce: 0.036494
2021-12-14 01:37:09,655 iteration 1098 : loss : 0.091088, loss_ce: 0.027948
2021-12-14 01:37:11,257 iteration 1099 : loss : 0.103384, loss_ce: 0.028200
2021-12-14 01:37:12,920 iteration 1100 : loss : 0.107844, loss_ce: 0.029901
2021-12-14 01:37:14,498 iteration 1101 : loss : 0.098631, loss_ce: 0.025948
2021-12-14 01:37:16,161 iteration 1102 : loss : 0.124179, loss_ce: 0.031940
2021-12-14 01:37:17,721 iteration 1103 : loss : 0.112693, loss_ce: 0.032871
2021-12-14 01:37:19,281 iteration 1104 : loss : 0.105459, loss_ce: 0.032227
2021-12-14 01:37:19,281 Training Data Eval:
2021-12-14 01:37:27,472   Average segmentation loss on training set: 0.0883
2021-12-14 01:37:27,472 Validation Data Eval:
2021-12-14 01:37:30,271   Average segmentation loss on validation set: 0.1259
2021-12-14 01:37:31,895 iteration 1105 : loss : 0.111613, loss_ce: 0.028163
 16%|████▉                         | 65/400 [32:28<2:54:45, 31.30s/it]2021-12-14 01:37:33,455 iteration 1106 : loss : 0.114405, loss_ce: 0.032582
2021-12-14 01:37:35,006 iteration 1107 : loss : 0.102278, loss_ce: 0.038733
2021-12-14 01:37:36,588 iteration 1108 : loss : 0.117176, loss_ce: 0.024190
2021-12-14 01:37:38,103 iteration 1109 : loss : 0.101776, loss_ce: 0.030739
2021-12-14 01:37:39,682 iteration 1110 : loss : 0.115320, loss_ce: 0.042411
2021-12-14 01:37:41,232 iteration 1111 : loss : 0.098683, loss_ce: 0.032274
2021-12-14 01:37:42,784 iteration 1112 : loss : 0.100433, loss_ce: 0.029339
2021-12-14 01:37:44,326 iteration 1113 : loss : 0.098477, loss_ce: 0.025701
2021-12-14 01:37:45,960 iteration 1114 : loss : 0.113864, loss_ce: 0.041124
2021-12-14 01:37:47,669 iteration 1115 : loss : 0.110010, loss_ce: 0.036156
2021-12-14 01:37:49,295 iteration 1116 : loss : 0.104229, loss_ce: 0.026890
2021-12-14 01:37:50,989 iteration 1117 : loss : 0.100283, loss_ce: 0.025197
2021-12-14 01:37:52,613 iteration 1118 : loss : 0.108611, loss_ce: 0.026603
2021-12-14 01:37:54,162 iteration 1119 : loss : 0.096671, loss_ce: 0.029561
2021-12-14 01:37:55,703 iteration 1120 : loss : 0.097481, loss_ce: 0.026737
2021-12-14 01:37:57,293 iteration 1121 : loss : 0.108965, loss_ce: 0.026521
2021-12-14 01:37:58,897 iteration 1122 : loss : 0.110266, loss_ce: 0.038950
 16%|████▉                         | 66/400 [32:55<2:47:03, 30.01s/it]2021-12-14 01:38:00,490 iteration 1123 : loss : 0.134363, loss_ce: 0.038628
2021-12-14 01:38:02,099 iteration 1124 : loss : 0.104625, loss_ce: 0.035227
2021-12-14 01:38:03,671 iteration 1125 : loss : 0.087901, loss_ce: 0.019350
2021-12-14 01:38:05,235 iteration 1126 : loss : 0.100584, loss_ce: 0.024562
2021-12-14 01:38:06,785 iteration 1127 : loss : 0.111464, loss_ce: 0.035057
2021-12-14 01:38:08,417 iteration 1128 : loss : 0.108041, loss_ce: 0.034297
2021-12-14 01:38:10,057 iteration 1129 : loss : 0.103396, loss_ce: 0.027143
2021-12-14 01:38:11,615 iteration 1130 : loss : 0.108388, loss_ce: 0.037549
2021-12-14 01:38:13,175 iteration 1131 : loss : 0.113578, loss_ce: 0.037842
2021-12-14 01:38:14,786 iteration 1132 : loss : 0.096282, loss_ce: 0.029499
2021-12-14 01:38:16,302 iteration 1133 : loss : 0.100318, loss_ce: 0.035024
2021-12-14 01:38:17,874 iteration 1134 : loss : 0.099528, loss_ce: 0.025748
2021-12-14 01:38:19,414 iteration 1135 : loss : 0.105833, loss_ce: 0.034443
2021-12-14 01:38:20,978 iteration 1136 : loss : 0.088429, loss_ce: 0.023130
2021-12-14 01:38:22,524 iteration 1137 : loss : 0.115748, loss_ce: 0.036997
2021-12-14 01:38:24,137 iteration 1138 : loss : 0.110343, loss_ce: 0.038213
2021-12-14 01:38:25,727 iteration 1139 : loss : 0.105711, loss_ce: 0.023993
 17%|█████                         | 67/400 [33:22<2:41:15, 29.06s/it]2021-12-14 01:38:27,357 iteration 1140 : loss : 0.107655, loss_ce: 0.031066
2021-12-14 01:38:28,891 iteration 1141 : loss : 0.098525, loss_ce: 0.027870
2021-12-14 01:38:30,522 iteration 1142 : loss : 0.103354, loss_ce: 0.032725
2021-12-14 01:38:32,094 iteration 1143 : loss : 0.096650, loss_ce: 0.029105
2021-12-14 01:38:33,703 iteration 1144 : loss : 0.106270, loss_ce: 0.037674
2021-12-14 01:38:35,232 iteration 1145 : loss : 0.110041, loss_ce: 0.030826
2021-12-14 01:38:36,821 iteration 1146 : loss : 0.111262, loss_ce: 0.039007
2021-12-14 01:38:38,312 iteration 1147 : loss : 0.101491, loss_ce: 0.031525
2021-12-14 01:38:39,935 iteration 1148 : loss : 0.092298, loss_ce: 0.020601
2021-12-14 01:38:41,457 iteration 1149 : loss : 0.106593, loss_ce: 0.037436
2021-12-14 01:38:43,031 iteration 1150 : loss : 0.096075, loss_ce: 0.027984
2021-12-14 01:38:44,646 iteration 1151 : loss : 0.100732, loss_ce: 0.027446
2021-12-14 01:38:46,349 iteration 1152 : loss : 0.116547, loss_ce: 0.033053
2021-12-14 01:38:47,842 iteration 1153 : loss : 0.103647, loss_ce: 0.029118
2021-12-14 01:38:49,460 iteration 1154 : loss : 0.102361, loss_ce: 0.029214
2021-12-14 01:38:51,001 iteration 1155 : loss : 0.108360, loss_ce: 0.029829
2021-12-14 01:38:52,627 iteration 1156 : loss : 0.121464, loss_ce: 0.047631
 17%|█████                         | 68/400 [33:49<2:37:11, 28.41s/it]2021-12-14 01:38:54,241 iteration 1157 : loss : 0.122376, loss_ce: 0.024598
2021-12-14 01:38:55,831 iteration 1158 : loss : 0.100189, loss_ce: 0.026915
2021-12-14 01:38:57,484 iteration 1159 : loss : 0.100715, loss_ce: 0.025164
2021-12-14 01:38:59,183 iteration 1160 : loss : 0.121429, loss_ce: 0.039934
2021-12-14 01:39:00,821 iteration 1161 : loss : 0.116574, loss_ce: 0.038412
2021-12-14 01:39:02,433 iteration 1162 : loss : 0.096818, loss_ce: 0.027760
2021-12-14 01:39:03,990 iteration 1163 : loss : 0.116994, loss_ce: 0.038171
2021-12-14 01:39:05,558 iteration 1164 : loss : 0.101734, loss_ce: 0.029192
2021-12-14 01:39:07,132 iteration 1165 : loss : 0.100657, loss_ce: 0.031632
2021-12-14 01:39:08,776 iteration 1166 : loss : 0.085258, loss_ce: 0.019345
2021-12-14 01:39:10,318 iteration 1167 : loss : 0.099773, loss_ce: 0.033724
2021-12-14 01:39:11,874 iteration 1168 : loss : 0.096680, loss_ce: 0.030767
2021-12-14 01:39:13,414 iteration 1169 : loss : 0.098060, loss_ce: 0.028846
2021-12-14 01:39:14,958 iteration 1170 : loss : 0.109168, loss_ce: 0.033811
2021-12-14 01:39:16,543 iteration 1171 : loss : 0.094026, loss_ce: 0.025087
2021-12-14 01:39:18,122 iteration 1172 : loss : 0.096804, loss_ce: 0.032269
2021-12-14 01:39:19,725 iteration 1173 : loss : 0.103178, loss_ce: 0.026913
 17%|█████▏                        | 69/400 [34:16<2:34:32, 28.01s/it]2021-12-14 01:39:21,329 iteration 1174 : loss : 0.114630, loss_ce: 0.029011
2021-12-14 01:39:22,905 iteration 1175 : loss : 0.094935, loss_ce: 0.027882
2021-12-14 01:39:24,474 iteration 1176 : loss : 0.095182, loss_ce: 0.029154
2021-12-14 01:39:26,011 iteration 1177 : loss : 0.100101, loss_ce: 0.028631
2021-12-14 01:39:27,621 iteration 1178 : loss : 0.090069, loss_ce: 0.021842
2021-12-14 01:39:29,285 iteration 1179 : loss : 0.108878, loss_ce: 0.036765
2021-12-14 01:39:30,838 iteration 1180 : loss : 0.092161, loss_ce: 0.030193
2021-12-14 01:39:32,413 iteration 1181 : loss : 0.099467, loss_ce: 0.026809
2021-12-14 01:39:34,007 iteration 1182 : loss : 0.102119, loss_ce: 0.031394
2021-12-14 01:39:35,540 iteration 1183 : loss : 0.099535, loss_ce: 0.026487
2021-12-14 01:39:37,078 iteration 1184 : loss : 0.093890, loss_ce: 0.030166
2021-12-14 01:39:38,689 iteration 1185 : loss : 0.102917, loss_ce: 0.028193
2021-12-14 01:39:40,232 iteration 1186 : loss : 0.106318, loss_ce: 0.036347
2021-12-14 01:39:41,877 iteration 1187 : loss : 0.099836, loss_ce: 0.026528
2021-12-14 01:39:43,415 iteration 1188 : loss : 0.108253, loss_ce: 0.032068
2021-12-14 01:39:45,068 iteration 1189 : loss : 0.104194, loss_ce: 0.031445
2021-12-14 01:39:45,068 Training Data Eval:
2021-12-14 01:39:53,257   Average segmentation loss on training set: 0.0988
2021-12-14 01:39:53,257 Validation Data Eval:
2021-12-14 01:39:56,055   Average segmentation loss on validation set: 0.1181
2021-12-14 01:40:02,503 Found new lowest validation loss at iteration 1189! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/TU_3seeds/REVISED_SGD_best_val_loss_seed1234.pth
2021-12-14 01:40:03,981 iteration 1190 : loss : 0.103312, loss_ce: 0.033972
 18%|█████▎                        | 70/400 [35:00<3:00:53, 32.89s/it]2021-12-14 01:40:05,558 iteration 1191 : loss : 0.122760, loss_ce: 0.043388
2021-12-14 01:40:07,067 iteration 1192 : loss : 0.092071, loss_ce: 0.029677
2021-12-14 01:40:08,719 iteration 1193 : loss : 0.100821, loss_ce: 0.026356
2021-12-14 01:40:10,283 iteration 1194 : loss : 0.104770, loss_ce: 0.025365
2021-12-14 01:40:11,810 iteration 1195 : loss : 0.100149, loss_ce: 0.034275
2021-12-14 01:40:13,337 iteration 1196 : loss : 0.099711, loss_ce: 0.031618
2021-12-14 01:40:14,828 iteration 1197 : loss : 0.095436, loss_ce: 0.027408
2021-12-14 01:40:16,447 iteration 1198 : loss : 0.094722, loss_ce: 0.030413
2021-12-14 01:40:18,027 iteration 1199 : loss : 0.098565, loss_ce: 0.027800
2021-12-14 01:40:19,580 iteration 1200 : loss : 0.107927, loss_ce: 0.025834
2021-12-14 01:40:21,102 iteration 1201 : loss : 0.095759, loss_ce: 0.029635
2021-12-14 01:40:22,698 iteration 1202 : loss : 0.093773, loss_ce: 0.023654
2021-12-14 01:40:24,286 iteration 1203 : loss : 0.103277, loss_ce: 0.026959
2021-12-14 01:40:25,860 iteration 1204 : loss : 0.105987, loss_ce: 0.028205
2021-12-14 01:40:27,441 iteration 1205 : loss : 0.108694, loss_ce: 0.036054
2021-12-14 01:40:29,025 iteration 1206 : loss : 0.103245, loss_ce: 0.031225
2021-12-14 01:40:30,649 iteration 1207 : loss : 0.098278, loss_ce: 0.022068
 18%|█████▎                        | 71/400 [35:27<2:50:07, 31.02s/it]2021-12-14 01:40:32,311 iteration 1208 : loss : 0.108825, loss_ce: 0.037488
2021-12-14 01:40:33,891 iteration 1209 : loss : 0.096383, loss_ce: 0.029193
2021-12-14 01:40:35,468 iteration 1210 : loss : 0.101404, loss_ce: 0.029672
2021-12-14 01:40:36,991 iteration 1211 : loss : 0.085705, loss_ce: 0.023793
2021-12-14 01:40:38,498 iteration 1212 : loss : 0.100471, loss_ce: 0.026121
2021-12-14 01:40:40,188 iteration 1213 : loss : 0.097491, loss_ce: 0.032272
2021-12-14 01:40:41,768 iteration 1214 : loss : 0.093436, loss_ce: 0.027290
2021-12-14 01:40:43,354 iteration 1215 : loss : 0.101156, loss_ce: 0.029883
2021-12-14 01:40:45,052 iteration 1216 : loss : 0.108042, loss_ce: 0.032999
2021-12-14 01:40:46,638 iteration 1217 : loss : 0.098342, loss_ce: 0.027057
2021-12-14 01:40:48,173 iteration 1218 : loss : 0.091330, loss_ce: 0.026962
2021-12-14 01:40:49,676 iteration 1219 : loss : 0.091322, loss_ce: 0.021472
2021-12-14 01:40:51,238 iteration 1220 : loss : 0.098053, loss_ce: 0.026857
2021-12-14 01:40:52,773 iteration 1221 : loss : 0.102004, loss_ce: 0.029516
2021-12-14 01:40:54,405 iteration 1222 : loss : 0.103830, loss_ce: 0.028484
2021-12-14 01:40:55,955 iteration 1223 : loss : 0.093972, loss_ce: 0.027304
2021-12-14 01:40:57,568 iteration 1224 : loss : 0.122228, loss_ce: 0.039768
 18%|█████▍                        | 72/400 [35:54<2:42:51, 29.79s/it]2021-12-14 01:40:59,169 iteration 1225 : loss : 0.103793, loss_ce: 0.030178
2021-12-14 01:41:00,777 iteration 1226 : loss : 0.114805, loss_ce: 0.038935
2021-12-14 01:41:02,298 iteration 1227 : loss : 0.090275, loss_ce: 0.022560
2021-12-14 01:41:03,853 iteration 1228 : loss : 0.093223, loss_ce: 0.025115
2021-12-14 01:41:05,356 iteration 1229 : loss : 0.098510, loss_ce: 0.020962
2021-12-14 01:41:06,883 iteration 1230 : loss : 0.097874, loss_ce: 0.027750
2021-12-14 01:41:08,482 iteration 1231 : loss : 0.097775, loss_ce: 0.032584
2021-12-14 01:41:10,009 iteration 1232 : loss : 0.098144, loss_ce: 0.028846
2021-12-14 01:41:11,545 iteration 1233 : loss : 0.088300, loss_ce: 0.026408
2021-12-14 01:41:13,146 iteration 1234 : loss : 0.094762, loss_ce: 0.029491
2021-12-14 01:41:14,747 iteration 1235 : loss : 0.138213, loss_ce: 0.039460
2021-12-14 01:41:16,278 iteration 1236 : loss : 0.096704, loss_ce: 0.027204
2021-12-14 01:41:17,761 iteration 1237 : loss : 0.114452, loss_ce: 0.033207
2021-12-14 01:41:19,370 iteration 1238 : loss : 0.094300, loss_ce: 0.022197
2021-12-14 01:41:20,882 iteration 1239 : loss : 0.084360, loss_ce: 0.024835
2021-12-14 01:41:22,407 iteration 1240 : loss : 0.084837, loss_ce: 0.022849
2021-12-14 01:41:23,930 iteration 1241 : loss : 0.096331, loss_ce: 0.032236
 18%|█████▍                        | 73/400 [36:20<2:36:44, 28.76s/it]2021-12-14 01:41:25,568 iteration 1242 : loss : 0.108203, loss_ce: 0.041249
2021-12-14 01:41:27,098 iteration 1243 : loss : 0.100832, loss_ce: 0.024046
2021-12-14 01:41:28,636 iteration 1244 : loss : 0.091745, loss_ce: 0.025753
2021-12-14 01:41:30,215 iteration 1245 : loss : 0.114748, loss_ce: 0.037832
2021-12-14 01:41:31,789 iteration 1246 : loss : 0.094062, loss_ce: 0.025781
2021-12-14 01:41:33,323 iteration 1247 : loss : 0.094405, loss_ce: 0.030204
2021-12-14 01:41:34,912 iteration 1248 : loss : 0.090088, loss_ce: 0.020500
2021-12-14 01:41:36,438 iteration 1249 : loss : 0.085368, loss_ce: 0.019128
2021-12-14 01:41:38,102 iteration 1250 : loss : 0.107897, loss_ce: 0.033175
2021-12-14 01:41:39,803 iteration 1251 : loss : 0.109685, loss_ce: 0.044166
2021-12-14 01:41:41,411 iteration 1252 : loss : 0.092197, loss_ce: 0.028160
2021-12-14 01:41:42,908 iteration 1253 : loss : 0.089031, loss_ce: 0.022629
2021-12-14 01:41:44,485 iteration 1254 : loss : 0.090785, loss_ce: 0.029123
2021-12-14 01:41:46,074 iteration 1255 : loss : 0.092811, loss_ce: 0.024754
2021-12-14 01:41:47,631 iteration 1256 : loss : 0.104388, loss_ce: 0.033247
2021-12-14 01:41:49,199 iteration 1257 : loss : 0.095132, loss_ce: 0.022310
2021-12-14 01:41:50,786 iteration 1258 : loss : 0.107474, loss_ce: 0.040516
 18%|█████▌                        | 74/400 [36:47<2:33:09, 28.19s/it]2021-12-14 01:41:52,368 iteration 1259 : loss : 0.092074, loss_ce: 0.029544
2021-12-14 01:41:53,984 iteration 1260 : loss : 0.090292, loss_ce: 0.026995
2021-12-14 01:41:55,533 iteration 1261 : loss : 0.093567, loss_ce: 0.023055
2021-12-14 01:41:57,181 iteration 1262 : loss : 0.093893, loss_ce: 0.027449
2021-12-14 01:41:58,857 iteration 1263 : loss : 0.124106, loss_ce: 0.041212
2021-12-14 01:42:00,415 iteration 1264 : loss : 0.091672, loss_ce: 0.029112
2021-12-14 01:42:02,050 iteration 1265 : loss : 0.097666, loss_ce: 0.037965
2021-12-14 01:42:03,682 iteration 1266 : loss : 0.101521, loss_ce: 0.028237
2021-12-14 01:42:05,281 iteration 1267 : loss : 0.103161, loss_ce: 0.031862
2021-12-14 01:42:06,823 iteration 1268 : loss : 0.095631, loss_ce: 0.026442
2021-12-14 01:42:08,467 iteration 1269 : loss : 0.115110, loss_ce: 0.024473
2021-12-14 01:42:10,077 iteration 1270 : loss : 0.099453, loss_ce: 0.030521
2021-12-14 01:42:11,645 iteration 1271 : loss : 0.099727, loss_ce: 0.034727
2021-12-14 01:42:13,138 iteration 1272 : loss : 0.100485, loss_ce: 0.025127
2021-12-14 01:42:14,682 iteration 1273 : loss : 0.093413, loss_ce: 0.023979
2021-12-14 01:42:16,250 iteration 1274 : loss : 0.089935, loss_ce: 0.020599
2021-12-14 01:42:16,250 Training Data Eval:
2021-12-14 01:42:24,440   Average segmentation loss on training set: 0.0849
2021-12-14 01:42:24,440 Validation Data Eval:
2021-12-14 01:42:27,241   Average segmentation loss on validation set: 0.1158
2021-12-14 01:42:33,453 Found new lowest validation loss at iteration 1274! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/TU_3seeds/REVISED_SGD_best_val_loss_seed1234.pth
2021-12-14 01:42:34,918 iteration 1275 : loss : 0.094932, loss_ce: 0.025519
 19%|█████▋                        | 75/400 [37:31<2:58:36, 32.97s/it]2021-12-14 01:42:36,336 iteration 1276 : loss : 0.091571, loss_ce: 0.027880
2021-12-14 01:42:38,003 iteration 1277 : loss : 0.091759, loss_ce: 0.026044
2021-12-14 01:42:39,535 iteration 1278 : loss : 0.090773, loss_ce: 0.024526
2021-12-14 01:42:41,194 iteration 1279 : loss : 0.096467, loss_ce: 0.023739
2021-12-14 01:42:42,794 iteration 1280 : loss : 0.109175, loss_ce: 0.036173
2021-12-14 01:42:44,384 iteration 1281 : loss : 0.113398, loss_ce: 0.039722
2021-12-14 01:42:45,902 iteration 1282 : loss : 0.084595, loss_ce: 0.026463
2021-12-14 01:42:47,530 iteration 1283 : loss : 0.115069, loss_ce: 0.025496
2021-12-14 01:42:49,065 iteration 1284 : loss : 0.101378, loss_ce: 0.031270
2021-12-14 01:42:50,708 iteration 1285 : loss : 0.090747, loss_ce: 0.023743
2021-12-14 01:42:52,377 iteration 1286 : loss : 0.117808, loss_ce: 0.025602
2021-12-14 01:42:53,933 iteration 1287 : loss : 0.094686, loss_ce: 0.036338
2021-12-14 01:42:55,469 iteration 1288 : loss : 0.099203, loss_ce: 0.033934
2021-12-14 01:42:57,042 iteration 1289 : loss : 0.108243, loss_ce: 0.034326
2021-12-14 01:42:58,651 iteration 1290 : loss : 0.108612, loss_ce: 0.030508
2021-12-14 01:43:00,269 iteration 1291 : loss : 0.120171, loss_ce: 0.045733
2021-12-14 01:43:01,898 iteration 1292 : loss : 0.097108, loss_ce: 0.029453
 19%|█████▋                        | 76/400 [37:58<2:48:20, 31.18s/it]2021-12-14 01:43:03,558 iteration 1293 : loss : 0.086058, loss_ce: 0.021746
2021-12-14 01:43:05,196 iteration 1294 : loss : 0.104379, loss_ce: 0.031130
2021-12-14 01:43:06,855 iteration 1295 : loss : 0.100527, loss_ce: 0.022028
2021-12-14 01:43:08,461 iteration 1296 : loss : 0.108879, loss_ce: 0.028410
2021-12-14 01:43:10,002 iteration 1297 : loss : 0.097086, loss_ce: 0.033372
2021-12-14 01:43:11,515 iteration 1298 : loss : 0.085950, loss_ce: 0.025764
2021-12-14 01:43:13,098 iteration 1299 : loss : 0.094076, loss_ce: 0.031731
2021-12-14 01:43:14,665 iteration 1300 : loss : 0.099758, loss_ce: 0.025153
2021-12-14 01:43:16,269 iteration 1301 : loss : 0.083540, loss_ce: 0.022216
2021-12-14 01:43:17,820 iteration 1302 : loss : 0.112991, loss_ce: 0.038319
2021-12-14 01:43:19,373 iteration 1303 : loss : 0.094328, loss_ce: 0.028498
2021-12-14 01:43:20,956 iteration 1304 : loss : 0.090361, loss_ce: 0.026299
2021-12-14 01:43:22,527 iteration 1305 : loss : 0.097289, loss_ce: 0.030125
2021-12-14 01:43:24,136 iteration 1306 : loss : 0.127209, loss_ce: 0.030022
2021-12-14 01:43:25,749 iteration 1307 : loss : 0.087962, loss_ce: 0.031109
2021-12-14 01:43:27,335 iteration 1308 : loss : 0.107574, loss_ce: 0.023154
2021-12-14 01:43:28,850 iteration 1309 : loss : 0.092812, loss_ce: 0.024764
 19%|█████▊                        | 77/400 [38:25<2:41:00, 29.91s/it]2021-12-14 01:43:30,550 iteration 1310 : loss : 0.092764, loss_ce: 0.024401
2021-12-14 01:43:32,109 iteration 1311 : loss : 0.090230, loss_ce: 0.029893
2021-12-14 01:43:33,651 iteration 1312 : loss : 0.083636, loss_ce: 0.022032
2021-12-14 01:43:35,195 iteration 1313 : loss : 0.116139, loss_ce: 0.025417
2021-12-14 01:43:36,774 iteration 1314 : loss : 0.102988, loss_ce: 0.031601
2021-12-14 01:43:38,378 iteration 1315 : loss : 0.106760, loss_ce: 0.030032
2021-12-14 01:43:40,068 iteration 1316 : loss : 0.096703, loss_ce: 0.031397
2021-12-14 01:43:41,635 iteration 1317 : loss : 0.111689, loss_ce: 0.045240
2021-12-14 01:43:43,292 iteration 1318 : loss : 0.133666, loss_ce: 0.021872
2021-12-14 01:43:44,908 iteration 1319 : loss : 0.098562, loss_ce: 0.033116
2021-12-14 01:43:46,465 iteration 1320 : loss : 0.092278, loss_ce: 0.022867
2021-12-14 01:43:48,057 iteration 1321 : loss : 0.097069, loss_ce: 0.020199
2021-12-14 01:43:49,577 iteration 1322 : loss : 0.111145, loss_ce: 0.041721
2021-12-14 01:43:51,134 iteration 1323 : loss : 0.119785, loss_ce: 0.032841
2021-12-14 01:43:52,732 iteration 1324 : loss : 0.111685, loss_ce: 0.036849
2021-12-14 01:43:54,369 iteration 1325 : loss : 0.102069, loss_ce: 0.030599
2021-12-14 01:43:55,852 iteration 1326 : loss : 0.091851, loss_ce: 0.026336
 20%|█████▊                        | 78/400 [38:52<2:35:48, 29.03s/it]2021-12-14 01:43:57,435 iteration 1327 : loss : 0.111124, loss_ce: 0.027277
2021-12-14 01:43:59,041 iteration 1328 : loss : 0.118253, loss_ce: 0.042049
2021-12-14 01:44:00,622 iteration 1329 : loss : 0.090290, loss_ce: 0.027332
2021-12-14 01:44:02,172 iteration 1330 : loss : 0.110469, loss_ce: 0.027438
2021-12-14 01:44:03,685 iteration 1331 : loss : 0.092230, loss_ce: 0.035276
2021-12-14 01:44:05,214 iteration 1332 : loss : 0.095476, loss_ce: 0.023873
2021-12-14 01:44:06,769 iteration 1333 : loss : 0.092000, loss_ce: 0.022634
2021-12-14 01:44:08,340 iteration 1334 : loss : 0.092578, loss_ce: 0.029477
2021-12-14 01:44:09,883 iteration 1335 : loss : 0.086017, loss_ce: 0.021116
2021-12-14 01:44:11,435 iteration 1336 : loss : 0.086204, loss_ce: 0.025385
2021-12-14 01:44:13,068 iteration 1337 : loss : 0.099095, loss_ce: 0.032009
2021-12-14 01:44:14,679 iteration 1338 : loss : 0.092346, loss_ce: 0.022844
2021-12-14 01:44:16,286 iteration 1339 : loss : 0.091404, loss_ce: 0.032702
2021-12-14 01:44:17,891 iteration 1340 : loss : 0.089376, loss_ce: 0.027364
2021-12-14 01:44:19,476 iteration 1341 : loss : 0.088160, loss_ce: 0.024093
2021-12-14 01:44:21,040 iteration 1342 : loss : 0.110605, loss_ce: 0.035483
2021-12-14 01:44:22,559 iteration 1343 : loss : 0.091989, loss_ce: 0.026994
 20%|█████▉                        | 79/400 [39:19<2:31:36, 28.34s/it]2021-12-14 01:44:24,191 iteration 1344 : loss : 0.096901, loss_ce: 0.027206
2021-12-14 01:44:25,836 iteration 1345 : loss : 0.102471, loss_ce: 0.027585
2021-12-14 01:44:27,393 iteration 1346 : loss : 0.146066, loss_ce: 0.056631
2021-12-14 01:44:29,035 iteration 1347 : loss : 0.100844, loss_ce: 0.034196
2021-12-14 01:44:30,721 iteration 1348 : loss : 0.107102, loss_ce: 0.033666
2021-12-14 01:44:32,309 iteration 1349 : loss : 0.099858, loss_ce: 0.032703
2021-12-14 01:44:33,893 iteration 1350 : loss : 0.093448, loss_ce: 0.028481
2021-12-14 01:44:35,473 iteration 1351 : loss : 0.095562, loss_ce: 0.032645
2021-12-14 01:44:37,106 iteration 1352 : loss : 0.093776, loss_ce: 0.032754
2021-12-14 01:44:38,712 iteration 1353 : loss : 0.091616, loss_ce: 0.024887
2021-12-14 01:44:40,332 iteration 1354 : loss : 0.110377, loss_ce: 0.030020
2021-12-14 01:44:42,014 iteration 1355 : loss : 0.156764, loss_ce: 0.026257
2021-12-14 01:44:43,616 iteration 1356 : loss : 0.093605, loss_ce: 0.028926
2021-12-14 01:44:45,230 iteration 1357 : loss : 0.090130, loss_ce: 0.028178
2021-12-14 01:44:46,860 iteration 1358 : loss : 0.096716, loss_ce: 0.028627
2021-12-14 01:44:48,445 iteration 1359 : loss : 0.101951, loss_ce: 0.031949
2021-12-14 01:44:48,445 Training Data Eval:
2021-12-14 01:44:56,638   Average segmentation loss on training set: 0.0852
2021-12-14 01:44:56,638 Validation Data Eval:
2021-12-14 01:44:59,434   Average segmentation loss on validation set: 0.1197
2021-12-14 01:45:01,069 iteration 1360 : loss : 0.093391, loss_ce: 0.021581
 20%|██████                        | 80/400 [39:58<2:47:24, 31.39s/it]2021-12-14 01:45:02,799 iteration 1361 : loss : 0.117277, loss_ce: 0.041985
2021-12-14 01:45:04,401 iteration 1362 : loss : 0.094439, loss_ce: 0.026341
2021-12-14 01:45:06,146 iteration 1363 : loss : 0.119101, loss_ce: 0.042177
2021-12-14 01:45:07,605 iteration 1364 : loss : 0.106654, loss_ce: 0.026522
2021-12-14 01:45:09,253 iteration 1365 : loss : 0.098609, loss_ce: 0.033213
2021-12-14 01:45:10,854 iteration 1366 : loss : 0.113131, loss_ce: 0.040276
2021-12-14 01:45:12,424 iteration 1367 : loss : 0.095570, loss_ce: 0.027544
2021-12-14 01:45:14,012 iteration 1368 : loss : 0.086440, loss_ce: 0.028714
2021-12-14 01:45:15,562 iteration 1369 : loss : 0.099731, loss_ce: 0.025975
2021-12-14 01:45:17,181 iteration 1370 : loss : 0.110283, loss_ce: 0.042276
2021-12-14 01:45:18,732 iteration 1371 : loss : 0.086534, loss_ce: 0.021718
2021-12-14 01:45:20,302 iteration 1372 : loss : 0.092306, loss_ce: 0.025075
2021-12-14 01:45:21,836 iteration 1373 : loss : 0.097812, loss_ce: 0.028487
2021-12-14 01:45:23,424 iteration 1374 : loss : 0.089423, loss_ce: 0.023222
2021-12-14 01:45:25,022 iteration 1375 : loss : 0.096191, loss_ce: 0.034281
2021-12-14 01:45:26,609 iteration 1376 : loss : 0.091441, loss_ce: 0.022176
2021-12-14 01:45:28,176 iteration 1377 : loss : 0.077087, loss_ce: 0.019602
 20%|██████                        | 81/400 [40:25<2:40:02, 30.10s/it]2021-12-14 01:45:29,731 iteration 1378 : loss : 0.091458, loss_ce: 0.028660
2021-12-14 01:45:31,356 iteration 1379 : loss : 0.098104, loss_ce: 0.028574
2021-12-14 01:45:32,952 iteration 1380 : loss : 0.094977, loss_ce: 0.029116
2021-12-14 01:45:34,619 iteration 1381 : loss : 0.087490, loss_ce: 0.023563
2021-12-14 01:45:36,125 iteration 1382 : loss : 0.091407, loss_ce: 0.027065
2021-12-14 01:45:37,775 iteration 1383 : loss : 0.094306, loss_ce: 0.026684
2021-12-14 01:45:39,361 iteration 1384 : loss : 0.094161, loss_ce: 0.026619
2021-12-14 01:45:40,878 iteration 1385 : loss : 0.099284, loss_ce: 0.023852
2021-12-14 01:45:42,427 iteration 1386 : loss : 0.089423, loss_ce: 0.025501
2021-12-14 01:45:43,987 iteration 1387 : loss : 0.085887, loss_ce: 0.022769
2021-12-14 01:45:45,560 iteration 1388 : loss : 0.100073, loss_ce: 0.026027
2021-12-14 01:45:47,134 iteration 1389 : loss : 0.104595, loss_ce: 0.034708
2021-12-14 01:45:48,753 iteration 1390 : loss : 0.086688, loss_ce: 0.024682
2021-12-14 01:45:50,395 iteration 1391 : loss : 0.097613, loss_ce: 0.026740
2021-12-14 01:45:52,015 iteration 1392 : loss : 0.114839, loss_ce: 0.040783
2021-12-14 01:45:53,570 iteration 1393 : loss : 0.098601, loss_ce: 0.026776
2021-12-14 01:45:55,215 iteration 1394 : loss : 0.087555, loss_ce: 0.029338
 20%|██████▏                       | 82/400 [40:52<2:34:39, 29.18s/it]2021-12-14 01:45:56,825 iteration 1395 : loss : 0.090026, loss_ce: 0.025638
2021-12-14 01:45:58,382 iteration 1396 : loss : 0.101538, loss_ce: 0.036640
2021-12-14 01:46:00,020 iteration 1397 : loss : 0.093276, loss_ce: 0.027530
2021-12-14 01:46:01,665 iteration 1398 : loss : 0.099086, loss_ce: 0.033610
2021-12-14 01:46:03,169 iteration 1399 : loss : 0.093598, loss_ce: 0.030673
2021-12-14 01:46:04,667 iteration 1400 : loss : 0.098779, loss_ce: 0.029585
2021-12-14 01:46:06,299 iteration 1401 : loss : 0.091804, loss_ce: 0.025440
2021-12-14 01:46:07,894 iteration 1402 : loss : 0.099358, loss_ce: 0.032201
2021-12-14 01:46:09,421 iteration 1403 : loss : 0.098810, loss_ce: 0.027514
2021-12-14 01:46:10,941 iteration 1404 : loss : 0.084167, loss_ce: 0.027456
2021-12-14 01:46:12,515 iteration 1405 : loss : 0.104678, loss_ce: 0.029723
2021-12-14 01:46:14,097 iteration 1406 : loss : 0.092441, loss_ce: 0.025106
2021-12-14 01:46:15,713 iteration 1407 : loss : 0.083427, loss_ce: 0.023882
2021-12-14 01:46:17,287 iteration 1408 : loss : 0.089248, loss_ce: 0.025404
2021-12-14 01:46:18,873 iteration 1409 : loss : 0.123728, loss_ce: 0.037442
2021-12-14 01:46:20,530 iteration 1410 : loss : 0.092592, loss_ce: 0.026589
2021-12-14 01:46:22,088 iteration 1411 : loss : 0.092861, loss_ce: 0.023777
 21%|██████▏                       | 83/400 [41:19<2:30:31, 28.49s/it]2021-12-14 01:46:23,677 iteration 1412 : loss : 0.102186, loss_ce: 0.032066
2021-12-14 01:46:25,319 iteration 1413 : loss : 0.106824, loss_ce: 0.027402
2021-12-14 01:46:26,879 iteration 1414 : loss : 0.096685, loss_ce: 0.026132
2021-12-14 01:46:28,505 iteration 1415 : loss : 0.088594, loss_ce: 0.019766
2021-12-14 01:46:30,069 iteration 1416 : loss : 0.091377, loss_ce: 0.028291
2021-12-14 01:46:31,624 iteration 1417 : loss : 0.097572, loss_ce: 0.025379
2021-12-14 01:46:33,170 iteration 1418 : loss : 0.099260, loss_ce: 0.033295
2021-12-14 01:46:34,697 iteration 1419 : loss : 0.094064, loss_ce: 0.026006
2021-12-14 01:46:36,320 iteration 1420 : loss : 0.093692, loss_ce: 0.025976
2021-12-14 01:46:37,979 iteration 1421 : loss : 0.097798, loss_ce: 0.031752
2021-12-14 01:46:39,596 iteration 1422 : loss : 0.082332, loss_ce: 0.019083
2021-12-14 01:46:41,112 iteration 1423 : loss : 0.093421, loss_ce: 0.028761
2021-12-14 01:46:42,714 iteration 1424 : loss : 0.092484, loss_ce: 0.030855
2021-12-14 01:46:44,312 iteration 1425 : loss : 0.082295, loss_ce: 0.023546
2021-12-14 01:46:45,844 iteration 1426 : loss : 0.095412, loss_ce: 0.032062
2021-12-14 01:46:47,412 iteration 1427 : loss : 0.105368, loss_ce: 0.033114
2021-12-14 01:46:48,894 iteration 1428 : loss : 0.111555, loss_ce: 0.033036
 21%|██████▎                       | 84/400 [41:45<2:27:25, 27.99s/it]2021-12-14 01:46:50,606 iteration 1429 : loss : 0.093582, loss_ce: 0.031960
2021-12-14 01:46:52,142 iteration 1430 : loss : 0.112359, loss_ce: 0.019017
2021-12-14 01:46:53,715 iteration 1431 : loss : 0.148323, loss_ce: 0.064106
2021-12-14 01:46:55,311 iteration 1432 : loss : 0.095748, loss_ce: 0.031851
2021-12-14 01:46:56,950 iteration 1433 : loss : 0.105271, loss_ce: 0.029073
2021-12-14 01:46:58,512 iteration 1434 : loss : 0.113800, loss_ce: 0.039476
2021-12-14 01:47:00,119 iteration 1435 : loss : 0.092505, loss_ce: 0.028213
2021-12-14 01:47:01,735 iteration 1436 : loss : 0.095757, loss_ce: 0.030017
2021-12-14 01:47:03,366 iteration 1437 : loss : 0.088846, loss_ce: 0.021961
2021-12-14 01:47:04,953 iteration 1438 : loss : 0.091753, loss_ce: 0.032025
2021-12-14 01:47:06,582 iteration 1439 : loss : 0.092260, loss_ce: 0.029000
2021-12-14 01:47:08,199 iteration 1440 : loss : 0.094523, loss_ce: 0.032817
2021-12-14 01:47:09,770 iteration 1441 : loss : 0.093176, loss_ce: 0.031784
2021-12-14 01:47:11,365 iteration 1442 : loss : 0.093765, loss_ce: 0.030810
2021-12-14 01:47:12,985 iteration 1443 : loss : 0.098975, loss_ce: 0.027235
2021-12-14 01:47:14,574 iteration 1444 : loss : 0.113712, loss_ce: 0.025442
2021-12-14 01:47:14,575 Training Data Eval:
2021-12-14 01:47:22,760   Average segmentation loss on training set: 0.0917
2021-12-14 01:47:22,760 Validation Data Eval:
2021-12-14 01:47:25,548   Average segmentation loss on validation set: 0.1170
2021-12-14 01:47:27,124 iteration 1445 : loss : 0.092937, loss_ce: 0.023738
 21%|██████▍                       | 85/400 [42:24<2:43:03, 31.06s/it]2021-12-14 01:47:28,837 iteration 1446 : loss : 0.084056, loss_ce: 0.021021
2021-12-14 01:47:30,400 iteration 1447 : loss : 0.090670, loss_ce: 0.024128
2021-12-14 01:47:31,922 iteration 1448 : loss : 0.096588, loss_ce: 0.039358
2021-12-14 01:47:33,526 iteration 1449 : loss : 0.087972, loss_ce: 0.024203
2021-12-14 01:47:35,208 iteration 1450 : loss : 0.094330, loss_ce: 0.034540
2021-12-14 01:47:36,903 iteration 1451 : loss : 0.098751, loss_ce: 0.029961
2021-12-14 01:47:38,453 iteration 1452 : loss : 0.083453, loss_ce: 0.019751
2021-12-14 01:47:40,014 iteration 1453 : loss : 0.087539, loss_ce: 0.028662
2021-12-14 01:47:41,619 iteration 1454 : loss : 0.107106, loss_ce: 0.027915
2021-12-14 01:47:43,163 iteration 1455 : loss : 0.083884, loss_ce: 0.026360
2021-12-14 01:47:44,820 iteration 1456 : loss : 0.110461, loss_ce: 0.025866
2021-12-14 01:47:46,396 iteration 1457 : loss : 0.098195, loss_ce: 0.035400
2021-12-14 01:47:47,959 iteration 1458 : loss : 0.093150, loss_ce: 0.021574
2021-12-14 01:47:49,493 iteration 1459 : loss : 0.086451, loss_ce: 0.017927
2021-12-14 01:47:51,137 iteration 1460 : loss : 0.107605, loss_ce: 0.039261
2021-12-14 01:47:52,730 iteration 1461 : loss : 0.099466, loss_ce: 0.033016
2021-12-14 01:47:54,361 iteration 1462 : loss : 0.090152, loss_ce: 0.027390
 22%|██████▍                       | 86/400 [42:51<2:36:33, 29.92s/it]2021-12-14 01:47:55,992 iteration 1463 : loss : 0.091917, loss_ce: 0.031512
2021-12-14 01:47:57,548 iteration 1464 : loss : 0.088376, loss_ce: 0.026160
2021-12-14 01:47:59,160 iteration 1465 : loss : 0.093727, loss_ce: 0.020788
2021-12-14 01:48:00,771 iteration 1466 : loss : 0.090446, loss_ce: 0.029973
2021-12-14 01:48:02,364 iteration 1467 : loss : 0.091255, loss_ce: 0.029389
2021-12-14 01:48:03,923 iteration 1468 : loss : 0.087895, loss_ce: 0.030034
2021-12-14 01:48:05,500 iteration 1469 : loss : 0.087026, loss_ce: 0.025930
2021-12-14 01:48:07,110 iteration 1470 : loss : 0.119986, loss_ce: 0.033648
2021-12-14 01:48:08,713 iteration 1471 : loss : 0.099452, loss_ce: 0.039394
2021-12-14 01:48:10,194 iteration 1472 : loss : 0.084132, loss_ce: 0.020906
2021-12-14 01:48:11,878 iteration 1473 : loss : 0.089491, loss_ce: 0.025582
2021-12-14 01:48:13,511 iteration 1474 : loss : 0.108121, loss_ce: 0.026859
2021-12-14 01:48:15,097 iteration 1475 : loss : 0.091502, loss_ce: 0.028456
2021-12-14 01:48:16,768 iteration 1476 : loss : 0.116696, loss_ce: 0.032171
2021-12-14 01:48:18,394 iteration 1477 : loss : 0.088534, loss_ce: 0.022913
2021-12-14 01:48:20,050 iteration 1478 : loss : 0.091854, loss_ce: 0.027295
2021-12-14 01:48:21,593 iteration 1479 : loss : 0.101611, loss_ce: 0.027511
 22%|██████▌                       | 87/400 [43:18<2:31:50, 29.11s/it]2021-12-14 01:48:23,219 iteration 1480 : loss : 0.103368, loss_ce: 0.029743
2021-12-14 01:48:24,774 iteration 1481 : loss : 0.086019, loss_ce: 0.026706
2021-12-14 01:48:26,350 iteration 1482 : loss : 0.091492, loss_ce: 0.028132
2021-12-14 01:48:28,019 iteration 1483 : loss : 0.098775, loss_ce: 0.029447
2021-12-14 01:48:29,739 iteration 1484 : loss : 0.092192, loss_ce: 0.023133
2021-12-14 01:48:31,391 iteration 1485 : loss : 0.093396, loss_ce: 0.033124
2021-12-14 01:48:32,958 iteration 1486 : loss : 0.091437, loss_ce: 0.027045
2021-12-14 01:48:34,539 iteration 1487 : loss : 0.084789, loss_ce: 0.027048
2021-12-14 01:48:36,137 iteration 1488 : loss : 0.101038, loss_ce: 0.030426
2021-12-14 01:48:37,745 iteration 1489 : loss : 0.081780, loss_ce: 0.022321
2021-12-14 01:48:39,373 iteration 1490 : loss : 0.112886, loss_ce: 0.038108
2021-12-14 01:48:41,034 iteration 1491 : loss : 0.092811, loss_ce: 0.030491
2021-12-14 01:48:42,587 iteration 1492 : loss : 0.083374, loss_ce: 0.024351
2021-12-14 01:48:44,217 iteration 1493 : loss : 0.087669, loss_ce: 0.024530
2021-12-14 01:48:45,776 iteration 1494 : loss : 0.090530, loss_ce: 0.027423
2021-12-14 01:48:47,340 iteration 1495 : loss : 0.092216, loss_ce: 0.030245
2021-12-14 01:48:48,926 iteration 1496 : loss : 0.092153, loss_ce: 0.022555
 22%|██████▌                       | 88/400 [43:45<2:28:34, 28.57s/it]2021-12-14 01:48:50,503 iteration 1497 : loss : 0.122123, loss_ce: 0.051798
2021-12-14 01:48:52,054 iteration 1498 : loss : 0.087365, loss_ce: 0.022033
2021-12-14 01:48:53,668 iteration 1499 : loss : 0.105625, loss_ce: 0.038135
2021-12-14 01:48:55,181 iteration 1500 : loss : 0.093029, loss_ce: 0.023942
2021-12-14 01:48:56,744 iteration 1501 : loss : 0.081409, loss_ce: 0.020159
2021-12-14 01:48:58,355 iteration 1502 : loss : 0.089623, loss_ce: 0.025788
2021-12-14 01:48:59,916 iteration 1503 : loss : 0.074245, loss_ce: 0.024180
2021-12-14 01:49:01,478 iteration 1504 : loss : 0.083521, loss_ce: 0.021095
2021-12-14 01:49:02,999 iteration 1505 : loss : 0.083300, loss_ce: 0.022365
2021-12-14 01:49:04,570 iteration 1506 : loss : 0.083113, loss_ce: 0.022298
2021-12-14 01:49:06,147 iteration 1507 : loss : 0.111258, loss_ce: 0.032196
2021-12-14 01:49:07,692 iteration 1508 : loss : 0.092170, loss_ce: 0.028371
2021-12-14 01:49:09,257 iteration 1509 : loss : 0.095100, loss_ce: 0.024841
2021-12-14 01:49:10,788 iteration 1510 : loss : 0.080064, loss_ce: 0.020950
2021-12-14 01:49:12,383 iteration 1511 : loss : 0.098850, loss_ce: 0.035447
2021-12-14 01:49:13,921 iteration 1512 : loss : 0.085689, loss_ce: 0.023876
2021-12-14 01:49:15,519 iteration 1513 : loss : 0.087188, loss_ce: 0.028421
 22%|██████▋                       | 89/400 [44:12<2:25:01, 27.98s/it]2021-12-14 01:49:17,119 iteration 1514 : loss : 0.101249, loss_ce: 0.023334
2021-12-14 01:49:18,700 iteration 1515 : loss : 0.096834, loss_ce: 0.032773
2021-12-14 01:49:20,305 iteration 1516 : loss : 0.088578, loss_ce: 0.026706
2021-12-14 01:49:21,877 iteration 1517 : loss : 0.090933, loss_ce: 0.030537
2021-12-14 01:49:23,484 iteration 1518 : loss : 0.083939, loss_ce: 0.020070
2021-12-14 01:49:25,040 iteration 1519 : loss : 0.085127, loss_ce: 0.024626
2021-12-14 01:49:26,586 iteration 1520 : loss : 0.087514, loss_ce: 0.023432
2021-12-14 01:49:28,141 iteration 1521 : loss : 0.103757, loss_ce: 0.028271
2021-12-14 01:49:29,821 iteration 1522 : loss : 0.085625, loss_ce: 0.023092
2021-12-14 01:49:31,348 iteration 1523 : loss : 0.089095, loss_ce: 0.027929
2021-12-14 01:49:32,943 iteration 1524 : loss : 0.102090, loss_ce: 0.029979
2021-12-14 01:49:34,494 iteration 1525 : loss : 0.083526, loss_ce: 0.025580
2021-12-14 01:49:36,132 iteration 1526 : loss : 0.090986, loss_ce: 0.024964
2021-12-14 01:49:37,775 iteration 1527 : loss : 0.092634, loss_ce: 0.032026
2021-12-14 01:49:39,405 iteration 1528 : loss : 0.100842, loss_ce: 0.032596
2021-12-14 01:49:40,960 iteration 1529 : loss : 0.087458, loss_ce: 0.026783
2021-12-14 01:49:40,961 Training Data Eval:
2021-12-14 01:49:49,149   Average segmentation loss on training set: 0.0752
2021-12-14 01:49:49,150 Validation Data Eval:
2021-12-14 01:49:51,939   Average segmentation loss on validation set: 0.1073
2021-12-14 01:49:58,115 Found new lowest validation loss at iteration 1529! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/TU_3seeds/REVISED_SGD_best_val_loss_seed1234.pth
2021-12-14 01:49:59,570 iteration 1530 : loss : 0.095022, loss_ce: 0.032005
 22%|██████▊                       | 90/400 [44:56<2:49:28, 32.80s/it]2021-12-14 01:50:01,179 iteration 1531 : loss : 0.090695, loss_ce: 0.026425
2021-12-14 01:50:02,791 iteration 1532 : loss : 0.084806, loss_ce: 0.022878
2021-12-14 01:50:04,337 iteration 1533 : loss : 0.081009, loss_ce: 0.024742
2021-12-14 01:50:05,973 iteration 1534 : loss : 0.092948, loss_ce: 0.023860
2021-12-14 01:50:07,535 iteration 1535 : loss : 0.085492, loss_ce: 0.025107
2021-12-14 01:50:09,082 iteration 1536 : loss : 0.107436, loss_ce: 0.050473
2021-12-14 01:50:10,623 iteration 1537 : loss : 0.093566, loss_ce: 0.021614
2021-12-14 01:50:12,149 iteration 1538 : loss : 0.133608, loss_ce: 0.025564
2021-12-14 01:50:13,713 iteration 1539 : loss : 0.093986, loss_ce: 0.028942
2021-12-14 01:50:15,285 iteration 1540 : loss : 0.097969, loss_ce: 0.033761
2021-12-14 01:50:16,779 iteration 1541 : loss : 0.079202, loss_ce: 0.019718
2021-12-14 01:50:18,358 iteration 1542 : loss : 0.086804, loss_ce: 0.029030
2021-12-14 01:50:19,909 iteration 1543 : loss : 0.094284, loss_ce: 0.022287
2021-12-14 01:50:21,423 iteration 1544 : loss : 0.088252, loss_ce: 0.025897
2021-12-14 01:50:22,986 iteration 1545 : loss : 0.090035, loss_ce: 0.029948
2021-12-14 01:50:24,540 iteration 1546 : loss : 0.096718, loss_ce: 0.033894
2021-12-14 01:50:26,091 iteration 1547 : loss : 0.110270, loss_ce: 0.033151
 23%|██████▊                       | 91/400 [45:23<2:39:13, 30.92s/it]2021-12-14 01:50:27,704 iteration 1548 : loss : 0.086503, loss_ce: 0.023957
2021-12-14 01:50:29,222 iteration 1549 : loss : 0.082854, loss_ce: 0.025157
2021-12-14 01:50:30,885 iteration 1550 : loss : 0.106886, loss_ce: 0.032462
2021-12-14 01:50:32,457 iteration 1551 : loss : 0.092010, loss_ce: 0.027834
2021-12-14 01:50:34,036 iteration 1552 : loss : 0.080084, loss_ce: 0.023499
2021-12-14 01:50:35,527 iteration 1553 : loss : 0.080113, loss_ce: 0.028856
2021-12-14 01:50:37,056 iteration 1554 : loss : 0.104691, loss_ce: 0.031720
2021-12-14 01:50:38,681 iteration 1555 : loss : 0.085264, loss_ce: 0.023498
2021-12-14 01:50:40,383 iteration 1556 : loss : 0.094763, loss_ce: 0.028795
2021-12-14 01:50:42,030 iteration 1557 : loss : 0.106188, loss_ce: 0.021610
2021-12-14 01:50:43,619 iteration 1558 : loss : 0.099732, loss_ce: 0.022233
2021-12-14 01:50:45,296 iteration 1559 : loss : 0.105136, loss_ce: 0.037925
2021-12-14 01:50:46,852 iteration 1560 : loss : 0.085807, loss_ce: 0.020051
2021-12-14 01:50:48,413 iteration 1561 : loss : 0.093767, loss_ce: 0.026004
2021-12-14 01:50:49,996 iteration 1562 : loss : 0.083883, loss_ce: 0.026689
2021-12-14 01:50:51,558 iteration 1563 : loss : 0.092950, loss_ce: 0.033756
2021-12-14 01:50:53,142 iteration 1564 : loss : 0.084758, loss_ce: 0.022136
 23%|██████▉                       | 92/400 [45:50<2:32:45, 29.76s/it]2021-12-14 01:50:54,784 iteration 1565 : loss : 0.080448, loss_ce: 0.021731
2021-12-14 01:50:56,345 iteration 1566 : loss : 0.091201, loss_ce: 0.029994
2021-12-14 01:50:57,964 iteration 1567 : loss : 0.096219, loss_ce: 0.021007
2021-12-14 01:50:59,654 iteration 1568 : loss : 0.087734, loss_ce: 0.025987
2021-12-14 01:51:01,212 iteration 1569 : loss : 0.102865, loss_ce: 0.033060
2021-12-14 01:51:02,803 iteration 1570 : loss : 0.083230, loss_ce: 0.022643
2021-12-14 01:51:04,367 iteration 1571 : loss : 0.094857, loss_ce: 0.031101
2021-12-14 01:51:05,940 iteration 1572 : loss : 0.104945, loss_ce: 0.036810
2021-12-14 01:51:07,529 iteration 1573 : loss : 0.096585, loss_ce: 0.022244
2021-12-14 01:51:09,112 iteration 1574 : loss : 0.092942, loss_ce: 0.034946
2021-12-14 01:51:10,713 iteration 1575 : loss : 0.094937, loss_ce: 0.030824
2021-12-14 01:51:12,275 iteration 1576 : loss : 0.091902, loss_ce: 0.021867
2021-12-14 01:51:13,805 iteration 1577 : loss : 0.089936, loss_ce: 0.021101
2021-12-14 01:51:15,287 iteration 1578 : loss : 0.075899, loss_ce: 0.021868
2021-12-14 01:51:16,846 iteration 1579 : loss : 0.080769, loss_ce: 0.022718
2021-12-14 01:51:18,440 iteration 1580 : loss : 0.082980, loss_ce: 0.021705
2021-12-14 01:51:20,037 iteration 1581 : loss : 0.087145, loss_ce: 0.028806
 23%|██████▉                       | 93/400 [46:16<2:27:52, 28.90s/it]2021-12-14 01:51:21,699 iteration 1582 : loss : 0.082627, loss_ce: 0.028710
2021-12-14 01:51:23,293 iteration 1583 : loss : 0.091389, loss_ce: 0.020564
2021-12-14 01:51:24,832 iteration 1584 : loss : 0.078777, loss_ce: 0.021290
2021-12-14 01:51:26,395 iteration 1585 : loss : 0.079592, loss_ce: 0.024282
2021-12-14 01:51:27,898 iteration 1586 : loss : 0.079123, loss_ce: 0.024342
2021-12-14 01:51:29,449 iteration 1587 : loss : 0.097833, loss_ce: 0.029123
2021-12-14 01:51:31,003 iteration 1588 : loss : 0.084817, loss_ce: 0.020822
2021-12-14 01:51:32,574 iteration 1589 : loss : 0.091523, loss_ce: 0.029401
2021-12-14 01:51:34,223 iteration 1590 : loss : 0.104745, loss_ce: 0.027715
2021-12-14 01:51:35,778 iteration 1591 : loss : 0.081884, loss_ce: 0.026105
2021-12-14 01:51:37,275 iteration 1592 : loss : 0.077646, loss_ce: 0.024478
2021-12-14 01:51:38,855 iteration 1593 : loss : 0.094299, loss_ce: 0.025662
2021-12-14 01:51:40,422 iteration 1594 : loss : 0.086172, loss_ce: 0.022259
2021-12-14 01:51:41,948 iteration 1595 : loss : 0.082388, loss_ce: 0.031240
2021-12-14 01:51:43,441 iteration 1596 : loss : 0.100431, loss_ce: 0.027217
2021-12-14 01:51:45,027 iteration 1597 : loss : 0.094358, loss_ce: 0.023530
2021-12-14 01:51:46,637 iteration 1598 : loss : 0.095326, loss_ce: 0.028158
 24%|███████                       | 94/400 [46:43<2:23:51, 28.21s/it]2021-12-14 01:51:48,297 iteration 1599 : loss : 0.074584, loss_ce: 0.024319
2021-12-14 01:51:49,857 iteration 1600 : loss : 0.084275, loss_ce: 0.026888
2021-12-14 01:51:51,466 iteration 1601 : loss : 0.099708, loss_ce: 0.029967
2021-12-14 01:51:53,052 iteration 1602 : loss : 0.090527, loss_ce: 0.022043
2021-12-14 01:51:54,614 iteration 1603 : loss : 0.077729, loss_ce: 0.021483
2021-12-14 01:51:56,164 iteration 1604 : loss : 0.092396, loss_ce: 0.020000
2021-12-14 01:51:57,722 iteration 1605 : loss : 0.094566, loss_ce: 0.030776
2021-12-14 01:51:59,302 iteration 1606 : loss : 0.080369, loss_ce: 0.024569
2021-12-14 01:52:00,869 iteration 1607 : loss : 0.095503, loss_ce: 0.028574
2021-12-14 01:52:02,519 iteration 1608 : loss : 0.102162, loss_ce: 0.034204
2021-12-14 01:52:04,075 iteration 1609 : loss : 0.083598, loss_ce: 0.023060
2021-12-14 01:52:05,739 iteration 1610 : loss : 0.086057, loss_ce: 0.024796
2021-12-14 01:52:07,405 iteration 1611 : loss : 0.091644, loss_ce: 0.032807
2021-12-14 01:52:09,086 iteration 1612 : loss : 0.082542, loss_ce: 0.022881
2021-12-14 01:52:10,672 iteration 1613 : loss : 0.082669, loss_ce: 0.021921
2021-12-14 01:52:12,309 iteration 1614 : loss : 0.093368, loss_ce: 0.032314
2021-12-14 01:52:12,309 Training Data Eval:
2021-12-14 01:52:20,487   Average segmentation loss on training set: 0.0765
2021-12-14 01:52:20,488 Validation Data Eval:
2021-12-14 01:52:23,286   Average segmentation loss on validation set: 0.1073
2021-12-14 01:52:24,912 iteration 1615 : loss : 0.096858, loss_ce: 0.026459
 24%|███████▏                      | 95/400 [47:21<2:38:46, 31.23s/it]2021-12-14 01:52:26,558 iteration 1616 : loss : 0.091599, loss_ce: 0.027476
2021-12-14 01:52:28,125 iteration 1617 : loss : 0.090233, loss_ce: 0.029469
2021-12-14 01:52:29,650 iteration 1618 : loss : 0.092366, loss_ce: 0.024290
2021-12-14 01:52:31,223 iteration 1619 : loss : 0.091130, loss_ce: 0.039027
2021-12-14 01:52:32,918 iteration 1620 : loss : 0.089717, loss_ce: 0.022313
2021-12-14 01:52:34,607 iteration 1621 : loss : 0.083939, loss_ce: 0.023537
2021-12-14 01:52:36,180 iteration 1622 : loss : 0.088489, loss_ce: 0.027855
2021-12-14 01:52:37,712 iteration 1623 : loss : 0.091695, loss_ce: 0.023364
2021-12-14 01:52:39,306 iteration 1624 : loss : 0.092304, loss_ce: 0.029912
2021-12-14 01:52:40,818 iteration 1625 : loss : 0.083308, loss_ce: 0.022138
2021-12-14 01:52:42,370 iteration 1626 : loss : 0.078798, loss_ce: 0.024433
2021-12-14 01:52:44,060 iteration 1627 : loss : 0.098784, loss_ce: 0.031175
2021-12-14 01:52:45,738 iteration 1628 : loss : 0.083068, loss_ce: 0.026399
2021-12-14 01:52:47,298 iteration 1629 : loss : 0.076948, loss_ce: 0.018589
2021-12-14 01:52:48,835 iteration 1630 : loss : 0.073056, loss_ce: 0.019916
2021-12-14 01:52:50,372 iteration 1631 : loss : 0.094252, loss_ce: 0.025116
2021-12-14 01:52:51,925 iteration 1632 : loss : 0.083312, loss_ce: 0.025012
 24%|███████▏                      | 96/400 [47:48<2:31:49, 29.97s/it]2021-12-14 01:52:53,562 iteration 1633 : loss : 0.077665, loss_ce: 0.019689
2021-12-14 01:52:55,159 iteration 1634 : loss : 0.096354, loss_ce: 0.030176
2021-12-14 01:52:56,709 iteration 1635 : loss : 0.093840, loss_ce: 0.021664
2021-12-14 01:52:58,215 iteration 1636 : loss : 0.088785, loss_ce: 0.032108
2021-12-14 01:52:59,807 iteration 1637 : loss : 0.094538, loss_ce: 0.022280
2021-12-14 01:53:01,376 iteration 1638 : loss : 0.089130, loss_ce: 0.029962
2021-12-14 01:53:03,006 iteration 1639 : loss : 0.088771, loss_ce: 0.031782
2021-12-14 01:53:04,552 iteration 1640 : loss : 0.084624, loss_ce: 0.023238
2021-12-14 01:53:06,203 iteration 1641 : loss : 0.099954, loss_ce: 0.030157
2021-12-14 01:53:07,730 iteration 1642 : loss : 0.082099, loss_ce: 0.023634
2021-12-14 01:53:09,239 iteration 1643 : loss : 0.082006, loss_ce: 0.021745
2021-12-14 01:53:10,866 iteration 1644 : loss : 0.084537, loss_ce: 0.025085
2021-12-14 01:53:12,533 iteration 1645 : loss : 0.078969, loss_ce: 0.024577
2021-12-14 01:53:14,072 iteration 1646 : loss : 0.090064, loss_ce: 0.023717
2021-12-14 01:53:15,627 iteration 1647 : loss : 0.095847, loss_ce: 0.023560
2021-12-14 01:53:17,134 iteration 1648 : loss : 0.077453, loss_ce: 0.024268
2021-12-14 01:53:18,643 iteration 1649 : loss : 0.073813, loss_ce: 0.020969
 24%|███████▎                      | 97/400 [48:15<2:26:24, 28.99s/it]2021-12-14 01:53:20,388 iteration 1650 : loss : 0.083872, loss_ce: 0.029907
2021-12-14 01:53:21,953 iteration 1651 : loss : 0.098245, loss_ce: 0.022217
2021-12-14 01:53:23,552 iteration 1652 : loss : 0.096758, loss_ce: 0.025638
2021-12-14 01:53:25,105 iteration 1653 : loss : 0.080961, loss_ce: 0.019873
2021-12-14 01:53:26,671 iteration 1654 : loss : 0.083906, loss_ce: 0.021790
2021-12-14 01:53:28,206 iteration 1655 : loss : 0.088493, loss_ce: 0.023960
2021-12-14 01:53:29,828 iteration 1656 : loss : 0.087673, loss_ce: 0.025143
2021-12-14 01:53:31,391 iteration 1657 : loss : 0.084603, loss_ce: 0.026441
2021-12-14 01:53:33,015 iteration 1658 : loss : 0.122664, loss_ce: 0.063670
2021-12-14 01:53:34,667 iteration 1659 : loss : 0.096108, loss_ce: 0.032185
2021-12-14 01:53:36,251 iteration 1660 : loss : 0.075987, loss_ce: 0.021464
2021-12-14 01:53:37,770 iteration 1661 : loss : 0.083277, loss_ce: 0.020068
2021-12-14 01:53:39,383 iteration 1662 : loss : 0.092318, loss_ce: 0.026321
2021-12-14 01:53:41,022 iteration 1663 : loss : 0.078490, loss_ce: 0.025380
2021-12-14 01:53:42,603 iteration 1664 : loss : 0.099969, loss_ce: 0.027922
2021-12-14 01:53:44,166 iteration 1665 : loss : 0.084071, loss_ce: 0.027832
2021-12-14 01:53:45,760 iteration 1666 : loss : 0.085551, loss_ce: 0.019598
 24%|███████▎                      | 98/400 [48:42<2:23:04, 28.43s/it]2021-12-14 01:53:47,346 iteration 1667 : loss : 0.079916, loss_ce: 0.028044
2021-12-14 01:53:49,004 iteration 1668 : loss : 0.107946, loss_ce: 0.031711
2021-12-14 01:53:50,617 iteration 1669 : loss : 0.100615, loss_ce: 0.030258
2021-12-14 01:53:52,121 iteration 1670 : loss : 0.078057, loss_ce: 0.019881
2021-12-14 01:53:53,644 iteration 1671 : loss : 0.073915, loss_ce: 0.023539
2021-12-14 01:53:55,282 iteration 1672 : loss : 0.100702, loss_ce: 0.034245
2021-12-14 01:53:56,892 iteration 1673 : loss : 0.096812, loss_ce: 0.021778
2021-12-14 01:53:58,561 iteration 1674 : loss : 0.086474, loss_ce: 0.025019
2021-12-14 01:54:00,115 iteration 1675 : loss : 0.083398, loss_ce: 0.019065
2021-12-14 01:54:01,754 iteration 1676 : loss : 0.085158, loss_ce: 0.025715
2021-12-14 01:54:03,362 iteration 1677 : loss : 0.095788, loss_ce: 0.023093
2021-12-14 01:54:04,989 iteration 1678 : loss : 0.097695, loss_ce: 0.031248
2021-12-14 01:54:06,557 iteration 1679 : loss : 0.119317, loss_ce: 0.043825
2021-12-14 01:54:08,169 iteration 1680 : loss : 0.093921, loss_ce: 0.035396
2021-12-14 01:54:09,734 iteration 1681 : loss : 0.082915, loss_ce: 0.024076
2021-12-14 01:54:11,315 iteration 1682 : loss : 0.083978, loss_ce: 0.026268
2021-12-14 01:54:12,859 iteration 1683 : loss : 0.089281, loss_ce: 0.031784
 25%|███████▍                      | 99/400 [49:09<2:20:37, 28.03s/it]2021-12-14 01:54:14,522 iteration 1684 : loss : 0.102258, loss_ce: 0.028289
2021-12-14 01:54:16,058 iteration 1685 : loss : 0.085641, loss_ce: 0.031968
2021-12-14 01:54:17,564 iteration 1686 : loss : 0.081602, loss_ce: 0.020936
2021-12-14 01:54:19,110 iteration 1687 : loss : 0.089302, loss_ce: 0.027415
2021-12-14 01:54:20,690 iteration 1688 : loss : 0.085710, loss_ce: 0.027819
2021-12-14 01:54:22,222 iteration 1689 : loss : 0.090559, loss_ce: 0.027185
2021-12-14 01:54:23,819 iteration 1690 : loss : 0.135753, loss_ce: 0.046377
2021-12-14 01:54:25,380 iteration 1691 : loss : 0.077816, loss_ce: 0.022416
2021-12-14 01:54:26,995 iteration 1692 : loss : 0.092997, loss_ce: 0.026103
2021-12-14 01:54:28,637 iteration 1693 : loss : 0.086623, loss_ce: 0.028219
2021-12-14 01:54:30,249 iteration 1694 : loss : 0.083194, loss_ce: 0.022430
2021-12-14 01:54:31,753 iteration 1695 : loss : 0.076236, loss_ce: 0.020347
2021-12-14 01:54:33,318 iteration 1696 : loss : 0.092505, loss_ce: 0.026282
2021-12-14 01:54:34,939 iteration 1697 : loss : 0.088874, loss_ce: 0.022398
2021-12-14 01:54:36,501 iteration 1698 : loss : 0.082200, loss_ce: 0.023119
2021-12-14 01:54:37,978 iteration 1699 : loss : 0.084121, loss_ce: 0.031141
2021-12-14 01:54:37,978 Training Data Eval:
2021-12-14 01:54:46,165   Average segmentation loss on training set: 0.0725
2021-12-14 01:54:46,165 Validation Data Eval:
2021-12-14 01:54:48,961   Average segmentation loss on validation set: 0.1132
2021-12-14 01:54:50,553 iteration 1700 : loss : 0.080077, loss_ce: 0.017872
 25%|███████▎                     | 100/400 [49:47<2:34:38, 30.93s/it]2021-12-14 01:54:52,219 iteration 1701 : loss : 0.085637, loss_ce: 0.027771
2021-12-14 01:54:53,802 iteration 1702 : loss : 0.090838, loss_ce: 0.030619
2021-12-14 01:54:55,325 iteration 1703 : loss : 0.087781, loss_ce: 0.029089
2021-12-14 01:54:56,967 iteration 1704 : loss : 0.088487, loss_ce: 0.025655
2021-12-14 01:54:58,541 iteration 1705 : loss : 0.088183, loss_ce: 0.031976
2021-12-14 01:55:00,133 iteration 1706 : loss : 0.102167, loss_ce: 0.039115
2021-12-14 01:55:01,707 iteration 1707 : loss : 0.080314, loss_ce: 0.020754
2021-12-14 01:55:03,314 iteration 1708 : loss : 0.085150, loss_ce: 0.023483
2021-12-14 01:55:04,827 iteration 1709 : loss : 0.089999, loss_ce: 0.031561
2021-12-14 01:55:06,321 iteration 1710 : loss : 0.076501, loss_ce: 0.023828
2021-12-14 01:55:07,898 iteration 1711 : loss : 0.085963, loss_ce: 0.025160
2021-12-14 01:55:09,421 iteration 1712 : loss : 0.078557, loss_ce: 0.019359
2021-12-14 01:55:10,933 iteration 1713 : loss : 0.078229, loss_ce: 0.020977
2021-12-14 01:55:12,585 iteration 1714 : loss : 0.098109, loss_ce: 0.024679
2021-12-14 01:55:14,191 iteration 1715 : loss : 0.097111, loss_ce: 0.021242
2021-12-14 01:55:15,845 iteration 1716 : loss : 0.097245, loss_ce: 0.025705
2021-12-14 01:55:17,427 iteration 1717 : loss : 0.077734, loss_ce: 0.020658
 25%|███████▎                     | 101/400 [50:14<2:28:03, 29.71s/it]2021-12-14 01:55:19,024 iteration 1718 : loss : 0.081359, loss_ce: 0.021146
2021-12-14 01:55:20,625 iteration 1719 : loss : 0.083958, loss_ce: 0.026158
2021-12-14 01:55:22,112 iteration 1720 : loss : 0.072347, loss_ce: 0.018167
2021-12-14 01:55:23,684 iteration 1721 : loss : 0.079037, loss_ce: 0.028829
2021-12-14 01:55:25,313 iteration 1722 : loss : 0.089963, loss_ce: 0.022279
2021-12-14 01:55:26,890 iteration 1723 : loss : 0.094635, loss_ce: 0.027721
2021-12-14 01:55:28,496 iteration 1724 : loss : 0.088300, loss_ce: 0.022679
2021-12-14 01:55:30,187 iteration 1725 : loss : 0.106840, loss_ce: 0.029759
2021-12-14 01:55:31,836 iteration 1726 : loss : 0.084759, loss_ce: 0.018535
2021-12-14 01:55:33,428 iteration 1727 : loss : 0.086177, loss_ce: 0.032033
2021-12-14 01:55:34,997 iteration 1728 : loss : 0.089484, loss_ce: 0.023342
2021-12-14 01:55:36,574 iteration 1729 : loss : 0.076866, loss_ce: 0.025460
2021-12-14 01:55:38,176 iteration 1730 : loss : 0.096186, loss_ce: 0.028190
2021-12-14 01:55:39,826 iteration 1731 : loss : 0.080122, loss_ce: 0.022553
2021-12-14 01:55:41,410 iteration 1732 : loss : 0.074441, loss_ce: 0.025319
2021-12-14 01:55:43,065 iteration 1733 : loss : 0.102182, loss_ce: 0.035712
2021-12-14 01:55:44,603 iteration 1734 : loss : 0.075326, loss_ce: 0.020189
 26%|███████▍                     | 102/400 [50:41<2:23:46, 28.95s/it]2021-12-14 01:55:46,184 iteration 1735 : loss : 0.085190, loss_ce: 0.023998
2021-12-14 01:55:47,747 iteration 1736 : loss : 0.074681, loss_ce: 0.021656
2021-12-14 01:55:49,322 iteration 1737 : loss : 0.080621, loss_ce: 0.023113
2021-12-14 01:55:50,868 iteration 1738 : loss : 0.078660, loss_ce: 0.020338
2021-12-14 01:55:52,535 iteration 1739 : loss : 0.088689, loss_ce: 0.029622
2021-12-14 01:55:54,157 iteration 1740 : loss : 0.102978, loss_ce: 0.032650
2021-12-14 01:55:55,734 iteration 1741 : loss : 0.077955, loss_ce: 0.018824
2021-12-14 01:55:57,419 iteration 1742 : loss : 0.089477, loss_ce: 0.029561
2021-12-14 01:55:58,988 iteration 1743 : loss : 0.090199, loss_ce: 0.021432
2021-12-14 01:56:00,592 iteration 1744 : loss : 0.080490, loss_ce: 0.023483
2021-12-14 01:56:02,308 iteration 1745 : loss : 0.099414, loss_ce: 0.039082
2021-12-14 01:56:03,874 iteration 1746 : loss : 0.081991, loss_ce: 0.023411
2021-12-14 01:56:05,433 iteration 1747 : loss : 0.072032, loss_ce: 0.022421
2021-12-14 01:56:07,017 iteration 1748 : loss : 0.090351, loss_ce: 0.029619
2021-12-14 01:56:08,601 iteration 1749 : loss : 0.083372, loss_ce: 0.020270
2021-12-14 01:56:10,128 iteration 1750 : loss : 0.079191, loss_ce: 0.024506
2021-12-14 01:56:11,803 iteration 1751 : loss : 0.086281, loss_ce: 0.025944
 26%|███████▍                     | 103/400 [51:08<2:20:41, 28.42s/it]2021-12-14 01:56:13,402 iteration 1752 : loss : 0.076518, loss_ce: 0.021558
2021-12-14 01:56:14,947 iteration 1753 : loss : 0.090799, loss_ce: 0.032266
2021-12-14 01:56:16,508 iteration 1754 : loss : 0.080168, loss_ce: 0.025214
2021-12-14 01:56:18,084 iteration 1755 : loss : 0.079915, loss_ce: 0.022731
2021-12-14 01:56:19,679 iteration 1756 : loss : 0.104244, loss_ce: 0.038196
2021-12-14 01:56:21,324 iteration 1757 : loss : 0.085181, loss_ce: 0.031389
2021-12-14 01:56:22,939 iteration 1758 : loss : 0.098792, loss_ce: 0.031049
2021-12-14 01:56:24,447 iteration 1759 : loss : 0.097914, loss_ce: 0.024441
2021-12-14 01:56:26,008 iteration 1760 : loss : 0.093553, loss_ce: 0.028819
2021-12-14 01:56:27,541 iteration 1761 : loss : 0.076539, loss_ce: 0.021827
2021-12-14 01:56:29,109 iteration 1762 : loss : 0.085670, loss_ce: 0.024421
2021-12-14 01:56:30,606 iteration 1763 : loss : 0.078288, loss_ce: 0.024772
2021-12-14 01:56:32,267 iteration 1764 : loss : 0.077938, loss_ce: 0.018648
2021-12-14 01:56:33,849 iteration 1765 : loss : 0.101897, loss_ce: 0.027854
2021-12-14 01:56:35,488 iteration 1766 : loss : 0.077111, loss_ce: 0.021494
2021-12-14 01:56:37,087 iteration 1767 : loss : 0.079412, loss_ce: 0.023259
2021-12-14 01:56:38,655 iteration 1768 : loss : 0.098347, loss_ce: 0.031045
 26%|███████▌                     | 104/400 [51:35<2:17:54, 27.95s/it]2021-12-14 01:56:40,307 iteration 1769 : loss : 0.077618, loss_ce: 0.023701
2021-12-14 01:56:41,876 iteration 1770 : loss : 0.079092, loss_ce: 0.021630
2021-12-14 01:56:43,417 iteration 1771 : loss : 0.071322, loss_ce: 0.016913
2021-12-14 01:56:45,053 iteration 1772 : loss : 0.095508, loss_ce: 0.034158
2021-12-14 01:56:46,649 iteration 1773 : loss : 0.095583, loss_ce: 0.029174
2021-12-14 01:56:48,199 iteration 1774 : loss : 0.079649, loss_ce: 0.019920
2021-12-14 01:56:49,757 iteration 1775 : loss : 0.084401, loss_ce: 0.022177
2021-12-14 01:56:51,305 iteration 1776 : loss : 0.084410, loss_ce: 0.022759
2021-12-14 01:56:52,830 iteration 1777 : loss : 0.079868, loss_ce: 0.024880
2021-12-14 01:56:54,449 iteration 1778 : loss : 0.089709, loss_ce: 0.030868
2021-12-14 01:56:56,034 iteration 1779 : loss : 0.083356, loss_ce: 0.029890
2021-12-14 01:56:57,634 iteration 1780 : loss : 0.107272, loss_ce: 0.028455
2021-12-14 01:56:59,236 iteration 1781 : loss : 0.094300, loss_ce: 0.029083
2021-12-14 01:57:00,745 iteration 1782 : loss : 0.081948, loss_ce: 0.018183
2021-12-14 01:57:02,287 iteration 1783 : loss : 0.085502, loss_ce: 0.028995
2021-12-14 01:57:03,886 iteration 1784 : loss : 0.087946, loss_ce: 0.035235
2021-12-14 01:57:03,886 Training Data Eval:
2021-12-14 01:57:12,074   Average segmentation loss on training set: 0.0704
2021-12-14 01:57:12,074 Validation Data Eval:
2021-12-14 01:57:14,866   Average segmentation loss on validation set: 0.1143
2021-12-14 01:57:16,442 iteration 1785 : loss : 0.080415, loss_ce: 0.025594
 26%|███████▌                     | 105/400 [52:13<2:31:56, 30.90s/it]2021-12-14 01:57:18,105 iteration 1786 : loss : 0.085210, loss_ce: 0.021464
2021-12-14 01:57:19,636 iteration 1787 : loss : 0.082811, loss_ce: 0.017472
2021-12-14 01:57:21,228 iteration 1788 : loss : 0.084465, loss_ce: 0.024527
2021-12-14 01:57:22,823 iteration 1789 : loss : 0.081144, loss_ce: 0.029123
2021-12-14 01:57:24,537 iteration 1790 : loss : 0.068343, loss_ce: 0.015236
2021-12-14 01:57:26,132 iteration 1791 : loss : 0.083043, loss_ce: 0.025157
2021-12-14 01:57:27,734 iteration 1792 : loss : 0.077782, loss_ce: 0.019956
2021-12-14 01:57:29,349 iteration 1793 : loss : 0.123821, loss_ce: 0.052238
2021-12-14 01:57:30,922 iteration 1794 : loss : 0.090761, loss_ce: 0.036061
2021-12-14 01:57:32,405 iteration 1795 : loss : 0.075910, loss_ce: 0.020776
2021-12-14 01:57:34,056 iteration 1796 : loss : 0.085055, loss_ce: 0.029624
2021-12-14 01:57:35,597 iteration 1797 : loss : 0.082832, loss_ce: 0.026538
2021-12-14 01:57:37,191 iteration 1798 : loss : 0.076558, loss_ce: 0.022061
2021-12-14 01:57:38,841 iteration 1799 : loss : 0.080887, loss_ce: 0.026020
2021-12-14 01:57:40,368 iteration 1800 : loss : 0.079133, loss_ce: 0.019141
2021-12-14 01:57:41,949 iteration 1801 : loss : 0.121700, loss_ce: 0.031180
2021-12-14 01:57:43,577 iteration 1802 : loss : 0.082654, loss_ce: 0.023130
 26%|███████▋                     | 106/400 [52:40<2:25:53, 29.77s/it]2021-12-14 01:57:45,257 iteration 1803 : loss : 0.087558, loss_ce: 0.027318
2021-12-14 01:57:46,772 iteration 1804 : loss : 0.077922, loss_ce: 0.020358
2021-12-14 01:57:48,470 iteration 1805 : loss : 0.083392, loss_ce: 0.023294
2021-12-14 01:57:50,137 iteration 1806 : loss : 0.099816, loss_ce: 0.038647
2021-12-14 01:57:51,721 iteration 1807 : loss : 0.085869, loss_ce: 0.027780
2021-12-14 01:57:53,345 iteration 1808 : loss : 0.070467, loss_ce: 0.021097
2021-12-14 01:57:54,902 iteration 1809 : loss : 0.080207, loss_ce: 0.027107
2021-12-14 01:57:56,508 iteration 1810 : loss : 0.079569, loss_ce: 0.027746
2021-12-14 01:57:58,069 iteration 1811 : loss : 0.092244, loss_ce: 0.026616
2021-12-14 01:57:59,621 iteration 1812 : loss : 0.082523, loss_ce: 0.020758
2021-12-14 01:58:01,199 iteration 1813 : loss : 0.082156, loss_ce: 0.029617
2021-12-14 01:58:02,754 iteration 1814 : loss : 0.088727, loss_ce: 0.022410
2021-12-14 01:58:04,403 iteration 1815 : loss : 0.098403, loss_ce: 0.025590
2021-12-14 01:58:05,995 iteration 1816 : loss : 0.083842, loss_ce: 0.026176
2021-12-14 01:58:07,653 iteration 1817 : loss : 0.097075, loss_ce: 0.031945
2021-12-14 01:58:09,186 iteration 1818 : loss : 0.068051, loss_ce: 0.017083
2021-12-14 01:58:10,820 iteration 1819 : loss : 0.086153, loss_ce: 0.022944
 27%|███████▊                     | 107/400 [53:07<2:21:41, 29.02s/it]2021-12-14 01:58:12,359 iteration 1820 : loss : 0.073878, loss_ce: 0.022818
2021-12-14 01:58:14,050 iteration 1821 : loss : 0.085768, loss_ce: 0.024695
2021-12-14 01:58:15,680 iteration 1822 : loss : 0.086012, loss_ce: 0.030567
2021-12-14 01:58:17,335 iteration 1823 : loss : 0.090093, loss_ce: 0.028840
2021-12-14 01:58:18,944 iteration 1824 : loss : 0.099693, loss_ce: 0.023155
2021-12-14 01:58:20,482 iteration 1825 : loss : 0.085668, loss_ce: 0.026746
2021-12-14 01:58:22,125 iteration 1826 : loss : 0.078965, loss_ce: 0.017816
2021-12-14 01:58:23,664 iteration 1827 : loss : 0.072347, loss_ce: 0.019686
2021-12-14 01:58:25,259 iteration 1828 : loss : 0.079131, loss_ce: 0.023819
2021-12-14 01:58:26,812 iteration 1829 : loss : 0.096756, loss_ce: 0.034444
2021-12-14 01:58:28,478 iteration 1830 : loss : 0.089696, loss_ce: 0.024187
2021-12-14 01:58:30,076 iteration 1831 : loss : 0.079633, loss_ce: 0.025382
2021-12-14 01:58:31,633 iteration 1832 : loss : 0.083045, loss_ce: 0.026821
2021-12-14 01:58:33,157 iteration 1833 : loss : 0.083076, loss_ce: 0.026522
2021-12-14 01:58:34,732 iteration 1834 : loss : 0.077880, loss_ce: 0.021977
2021-12-14 01:58:36,319 iteration 1835 : loss : 0.077406, loss_ce: 0.023155
2021-12-14 01:58:37,861 iteration 1836 : loss : 0.094223, loss_ce: 0.026341
 27%|███████▊                     | 108/400 [53:34<2:18:19, 28.42s/it]2021-12-14 01:58:39,529 iteration 1837 : loss : 0.083131, loss_ce: 0.024013
2021-12-14 01:58:41,033 iteration 1838 : loss : 0.072150, loss_ce: 0.020766
2021-12-14 01:58:42,572 iteration 1839 : loss : 0.087805, loss_ce: 0.028917
2021-12-14 01:58:44,184 iteration 1840 : loss : 0.083098, loss_ce: 0.026517
2021-12-14 01:58:45,703 iteration 1841 : loss : 0.084479, loss_ce: 0.026918
2021-12-14 01:58:47,267 iteration 1842 : loss : 0.070412, loss_ce: 0.015648
2021-12-14 01:58:48,865 iteration 1843 : loss : 0.073460, loss_ce: 0.025023
2021-12-14 01:58:50,425 iteration 1844 : loss : 0.092201, loss_ce: 0.024012
2021-12-14 01:58:51,976 iteration 1845 : loss : 0.067561, loss_ce: 0.013971
2021-12-14 01:58:53,625 iteration 1846 : loss : 0.085832, loss_ce: 0.027098
2021-12-14 01:58:55,169 iteration 1847 : loss : 0.076937, loss_ce: 0.019600
2021-12-14 01:58:56,736 iteration 1848 : loss : 0.092300, loss_ce: 0.030208
2021-12-14 01:58:58,281 iteration 1849 : loss : 0.088207, loss_ce: 0.034363
2021-12-14 01:58:59,989 iteration 1850 : loss : 0.101093, loss_ce: 0.028649
2021-12-14 01:59:01,575 iteration 1851 : loss : 0.117710, loss_ce: 0.031849
2021-12-14 01:59:03,178 iteration 1852 : loss : 0.088429, loss_ce: 0.030172
2021-12-14 01:59:04,730 iteration 1853 : loss : 0.081658, loss_ce: 0.027109
 27%|███████▉                     | 109/400 [54:01<2:15:36, 27.96s/it]2021-12-14 01:59:06,342 iteration 1854 : loss : 0.072661, loss_ce: 0.020269
2021-12-14 01:59:07,969 iteration 1855 : loss : 0.086095, loss_ce: 0.026585
2021-12-14 01:59:09,603 iteration 1856 : loss : 0.088544, loss_ce: 0.027325
2021-12-14 01:59:11,244 iteration 1857 : loss : 0.075712, loss_ce: 0.019233
2021-12-14 01:59:12,845 iteration 1858 : loss : 0.087012, loss_ce: 0.027203
2021-12-14 01:59:14,449 iteration 1859 : loss : 0.081056, loss_ce: 0.025894
2021-12-14 01:59:15,998 iteration 1860 : loss : 0.083328, loss_ce: 0.023844
2021-12-14 01:59:17,642 iteration 1861 : loss : 0.074993, loss_ce: 0.021718
2021-12-14 01:59:19,182 iteration 1862 : loss : 0.076317, loss_ce: 0.025769
2021-12-14 01:59:20,766 iteration 1863 : loss : 0.099407, loss_ce: 0.037784
2021-12-14 01:59:22,380 iteration 1864 : loss : 0.128360, loss_ce: 0.027321
2021-12-14 01:59:23,871 iteration 1865 : loss : 0.078789, loss_ce: 0.025373
2021-12-14 01:59:25,521 iteration 1866 : loss : 0.073783, loss_ce: 0.024000
2021-12-14 01:59:27,106 iteration 1867 : loss : 0.065825, loss_ce: 0.020181
2021-12-14 01:59:28,648 iteration 1868 : loss : 0.085374, loss_ce: 0.028719
2021-12-14 01:59:30,186 iteration 1869 : loss : 0.087280, loss_ce: 0.020702
2021-12-14 01:59:30,187 Training Data Eval:
2021-12-14 01:59:38,373   Average segmentation loss on training set: 0.0714
2021-12-14 01:59:38,374 Validation Data Eval:
2021-12-14 01:59:41,178   Average segmentation loss on validation set: 0.1039
2021-12-14 01:59:47,409 Found new lowest validation loss at iteration 1869! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/TU_3seeds/REVISED_SGD_best_val_loss_seed1234.pth
2021-12-14 01:59:48,926 iteration 1870 : loss : 0.073969, loss_ce: 0.020047
 28%|███████▉                     | 110/400 [54:45<2:38:41, 32.83s/it]2021-12-14 01:59:50,491 iteration 1871 : loss : 0.070117, loss_ce: 0.019459
2021-12-14 01:59:52,167 iteration 1872 : loss : 0.091566, loss_ce: 0.020376
2021-12-14 01:59:53,703 iteration 1873 : loss : 0.083293, loss_ce: 0.025804
2021-12-14 01:59:55,356 iteration 1874 : loss : 0.084733, loss_ce: 0.030228
2021-12-14 01:59:56,861 iteration 1875 : loss : 0.089801, loss_ce: 0.021532
2021-12-14 01:59:58,518 iteration 1876 : loss : 0.092595, loss_ce: 0.025829
2021-12-14 02:00:00,140 iteration 1877 : loss : 0.101247, loss_ce: 0.031544
2021-12-14 02:00:01,691 iteration 1878 : loss : 0.080143, loss_ce: 0.024472
2021-12-14 02:00:03,237 iteration 1879 : loss : 0.076312, loss_ce: 0.021308
2021-12-14 02:00:04,791 iteration 1880 : loss : 0.084053, loss_ce: 0.032082
2021-12-14 02:00:06,370 iteration 1881 : loss : 0.113583, loss_ce: 0.029838
2021-12-14 02:00:07,904 iteration 1882 : loss : 0.082360, loss_ce: 0.022901
2021-12-14 02:00:09,402 iteration 1883 : loss : 0.081458, loss_ce: 0.021241
2021-12-14 02:00:11,013 iteration 1884 : loss : 0.093211, loss_ce: 0.028677
2021-12-14 02:00:12,505 iteration 1885 : loss : 0.076627, loss_ce: 0.024553
2021-12-14 02:00:14,163 iteration 1886 : loss : 0.078363, loss_ce: 0.025095
2021-12-14 02:00:15,808 iteration 1887 : loss : 0.093720, loss_ce: 0.034596
 28%|████████                     | 111/400 [55:12<2:29:31, 31.04s/it]2021-12-14 02:00:17,419 iteration 1888 : loss : 0.084501, loss_ce: 0.027447
2021-12-14 02:00:19,055 iteration 1889 : loss : 0.089410, loss_ce: 0.027301
2021-12-14 02:00:20,675 iteration 1890 : loss : 0.088849, loss_ce: 0.026418
2021-12-14 02:00:22,305 iteration 1891 : loss : 0.079513, loss_ce: 0.022817
2021-12-14 02:00:23,905 iteration 1892 : loss : 0.095934, loss_ce: 0.034403
2021-12-14 02:00:25,509 iteration 1893 : loss : 0.089286, loss_ce: 0.036768
2021-12-14 02:00:27,084 iteration 1894 : loss : 0.097933, loss_ce: 0.031189
2021-12-14 02:00:28,647 iteration 1895 : loss : 0.083631, loss_ce: 0.020183
2021-12-14 02:00:30,346 iteration 1896 : loss : 0.097063, loss_ce: 0.037320
2021-12-14 02:00:31,913 iteration 1897 : loss : 0.084811, loss_ce: 0.020649
2021-12-14 02:00:33,553 iteration 1898 : loss : 0.087207, loss_ce: 0.024657
2021-12-14 02:00:35,132 iteration 1899 : loss : 0.087261, loss_ce: 0.034520
2021-12-14 02:00:36,635 iteration 1900 : loss : 0.071978, loss_ce: 0.021366
2021-12-14 02:00:38,212 iteration 1901 : loss : 0.076215, loss_ce: 0.020541
2021-12-14 02:00:39,821 iteration 1902 : loss : 0.084797, loss_ce: 0.030865
2021-12-14 02:00:41,455 iteration 1903 : loss : 0.091998, loss_ce: 0.023819
2021-12-14 02:00:43,140 iteration 1904 : loss : 0.087662, loss_ce: 0.024867
 28%|████████                     | 112/400 [55:40<2:23:40, 29.93s/it]2021-12-14 02:00:44,726 iteration 1905 : loss : 0.081086, loss_ce: 0.029119
2021-12-14 02:00:46,363 iteration 1906 : loss : 0.079470, loss_ce: 0.022087
2021-12-14 02:00:48,059 iteration 1907 : loss : 0.085643, loss_ce: 0.025567
2021-12-14 02:00:49,687 iteration 1908 : loss : 0.078176, loss_ce: 0.024051
2021-12-14 02:00:51,344 iteration 1909 : loss : 0.085511, loss_ce: 0.031316
2021-12-14 02:00:52,983 iteration 1910 : loss : 0.074517, loss_ce: 0.024341
2021-12-14 02:00:54,688 iteration 1911 : loss : 0.077413, loss_ce: 0.021302
2021-12-14 02:00:56,315 iteration 1912 : loss : 0.075035, loss_ce: 0.016454
2021-12-14 02:00:57,896 iteration 1913 : loss : 0.079809, loss_ce: 0.023202
2021-12-14 02:00:59,445 iteration 1914 : loss : 0.069542, loss_ce: 0.022497
2021-12-14 02:01:01,039 iteration 1915 : loss : 0.090033, loss_ce: 0.023160
2021-12-14 02:01:02,636 iteration 1916 : loss : 0.079192, loss_ce: 0.022436
2021-12-14 02:01:04,255 iteration 1917 : loss : 0.091399, loss_ce: 0.024591
2021-12-14 02:01:05,803 iteration 1918 : loss : 0.092298, loss_ce: 0.028929
2021-12-14 02:01:07,373 iteration 1919 : loss : 0.075119, loss_ce: 0.023172
2021-12-14 02:01:08,949 iteration 1920 : loss : 0.075614, loss_ce: 0.020621
2021-12-14 02:01:10,567 iteration 1921 : loss : 0.080889, loss_ce: 0.023082
 28%|████████▏                    | 113/400 [56:07<2:19:33, 29.17s/it]2021-12-14 02:01:12,143 iteration 1922 : loss : 0.087345, loss_ce: 0.024065
2021-12-14 02:01:13,653 iteration 1923 : loss : 0.070209, loss_ce: 0.021955
2021-12-14 02:01:15,257 iteration 1924 : loss : 0.114913, loss_ce: 0.057635
2021-12-14 02:01:16,785 iteration 1925 : loss : 0.091674, loss_ce: 0.032710
2021-12-14 02:01:18,329 iteration 1926 : loss : 0.076751, loss_ce: 0.024684
2021-12-14 02:01:19,951 iteration 1927 : loss : 0.097707, loss_ce: 0.029841
2021-12-14 02:01:21,579 iteration 1928 : loss : 0.070148, loss_ce: 0.019546
2021-12-14 02:01:23,135 iteration 1929 : loss : 0.076072, loss_ce: 0.024308
2021-12-14 02:01:24,712 iteration 1930 : loss : 0.075501, loss_ce: 0.016915
2021-12-14 02:01:26,263 iteration 1931 : loss : 0.080239, loss_ce: 0.017702
2021-12-14 02:01:27,840 iteration 1932 : loss : 0.081653, loss_ce: 0.020566
2021-12-14 02:01:29,424 iteration 1933 : loss : 0.081715, loss_ce: 0.023491
2021-12-14 02:01:30,888 iteration 1934 : loss : 0.073439, loss_ce: 0.025476
2021-12-14 02:01:32,435 iteration 1935 : loss : 0.077227, loss_ce: 0.026568
2021-12-14 02:01:34,054 iteration 1936 : loss : 0.070632, loss_ce: 0.020863
2021-12-14 02:01:35,667 iteration 1937 : loss : 0.072031, loss_ce: 0.020992
2021-12-14 02:01:37,285 iteration 1938 : loss : 0.082077, loss_ce: 0.020231
 28%|████████▎                    | 114/400 [56:34<2:15:34, 28.44s/it]2021-12-14 02:01:38,850 iteration 1939 : loss : 0.071731, loss_ce: 0.021337
2021-12-14 02:01:40,410 iteration 1940 : loss : 0.069849, loss_ce: 0.020445
2021-12-14 02:01:42,047 iteration 1941 : loss : 0.074838, loss_ce: 0.023931
2021-12-14 02:01:43,620 iteration 1942 : loss : 0.087350, loss_ce: 0.022606
2021-12-14 02:01:45,124 iteration 1943 : loss : 0.093042, loss_ce: 0.024077
2021-12-14 02:01:46,669 iteration 1944 : loss : 0.067981, loss_ce: 0.019921
2021-12-14 02:01:48,232 iteration 1945 : loss : 0.082321, loss_ce: 0.027581
2021-12-14 02:01:49,799 iteration 1946 : loss : 0.077228, loss_ce: 0.024745
2021-12-14 02:01:51,355 iteration 1947 : loss : 0.083818, loss_ce: 0.027791
2021-12-14 02:01:52,906 iteration 1948 : loss : 0.074875, loss_ce: 0.024197
2021-12-14 02:01:54,410 iteration 1949 : loss : 0.076297, loss_ce: 0.029424
2021-12-14 02:01:56,027 iteration 1950 : loss : 0.084602, loss_ce: 0.024209
2021-12-14 02:01:57,712 iteration 1951 : loss : 0.080481, loss_ce: 0.023222
2021-12-14 02:01:59,238 iteration 1952 : loss : 0.086984, loss_ce: 0.020404
2021-12-14 02:02:00,828 iteration 1953 : loss : 0.088842, loss_ce: 0.035443
2021-12-14 02:02:02,477 iteration 1954 : loss : 0.078695, loss_ce: 0.019484
2021-12-14 02:02:02,478 Training Data Eval:
2021-12-14 02:02:10,664   Average segmentation loss on training set: 0.0641
2021-12-14 02:02:10,664 Validation Data Eval:
2021-12-14 02:02:13,463   Average segmentation loss on validation set: 0.1010
2021-12-14 02:02:19,910 Found new lowest validation loss at iteration 1954! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/TU_3seeds/REVISED_SGD_best_val_loss_seed1234.pth
2021-12-14 02:02:21,365 iteration 1955 : loss : 0.070837, loss_ce: 0.021944
 29%|████████▎                    | 115/400 [57:18<2:37:22, 33.13s/it]2021-12-14 02:02:22,909 iteration 1956 : loss : 0.090770, loss_ce: 0.025260
2021-12-14 02:02:24,424 iteration 1957 : loss : 0.074023, loss_ce: 0.022597
2021-12-14 02:02:25,982 iteration 1958 : loss : 0.084510, loss_ce: 0.028469
2021-12-14 02:02:27,637 iteration 1959 : loss : 0.110230, loss_ce: 0.022700
2021-12-14 02:02:29,190 iteration 1960 : loss : 0.089631, loss_ce: 0.024336
2021-12-14 02:02:30,771 iteration 1961 : loss : 0.089434, loss_ce: 0.029630
2021-12-14 02:02:32,334 iteration 1962 : loss : 0.070024, loss_ce: 0.021064
2021-12-14 02:02:33,928 iteration 1963 : loss : 0.082052, loss_ce: 0.026945
2021-12-14 02:02:35,485 iteration 1964 : loss : 0.074309, loss_ce: 0.018181
2021-12-14 02:02:37,024 iteration 1965 : loss : 0.077647, loss_ce: 0.028205
2021-12-14 02:02:38,555 iteration 1966 : loss : 0.081529, loss_ce: 0.028973
2021-12-14 02:02:40,079 iteration 1967 : loss : 0.078387, loss_ce: 0.020888
2021-12-14 02:02:41,582 iteration 1968 : loss : 0.079040, loss_ce: 0.029281
2021-12-14 02:02:43,183 iteration 1969 : loss : 0.076329, loss_ce: 0.020246
2021-12-14 02:02:44,887 iteration 1970 : loss : 0.083356, loss_ce: 0.022861
2021-12-14 02:02:46,375 iteration 1971 : loss : 0.067130, loss_ce: 0.016866
2021-12-14 02:02:48,054 iteration 1972 : loss : 0.096068, loss_ce: 0.028594
 29%|████████▍                    | 116/400 [57:45<2:27:40, 31.20s/it]2021-12-14 02:02:49,589 iteration 1973 : loss : 0.067497, loss_ce: 0.018961
2021-12-14 02:02:51,097 iteration 1974 : loss : 0.089327, loss_ce: 0.030340
2021-12-14 02:02:52,743 iteration 1975 : loss : 0.077316, loss_ce: 0.022982
2021-12-14 02:02:54,240 iteration 1976 : loss : 0.076354, loss_ce: 0.023776
2021-12-14 02:02:55,896 iteration 1977 : loss : 0.098367, loss_ce: 0.032989
2021-12-14 02:02:57,439 iteration 1978 : loss : 0.071972, loss_ce: 0.020115
2021-12-14 02:02:58,992 iteration 1979 : loss : 0.083584, loss_ce: 0.031207
2021-12-14 02:03:00,611 iteration 1980 : loss : 0.090813, loss_ce: 0.026571
2021-12-14 02:03:02,150 iteration 1981 : loss : 0.076599, loss_ce: 0.023046
2021-12-14 02:03:03,788 iteration 1982 : loss : 0.080838, loss_ce: 0.022766
2021-12-14 02:03:05,453 iteration 1983 : loss : 0.082200, loss_ce: 0.025608
2021-12-14 02:03:06,990 iteration 1984 : loss : 0.081830, loss_ce: 0.020268
2021-12-14 02:03:08,542 iteration 1985 : loss : 0.077786, loss_ce: 0.021246
2021-12-14 02:03:10,075 iteration 1986 : loss : 0.076594, loss_ce: 0.020548
2021-12-14 02:03:11,602 iteration 1987 : loss : 0.063503, loss_ce: 0.017621
2021-12-14 02:03:13,258 iteration 1988 : loss : 0.073820, loss_ce: 0.022878
2021-12-14 02:03:14,834 iteration 1989 : loss : 0.072046, loss_ce: 0.024726
 29%|████████▍                    | 117/400 [58:11<2:20:53, 29.87s/it]2021-12-14 02:03:16,445 iteration 1990 : loss : 0.083971, loss_ce: 0.025790
2021-12-14 02:03:17,936 iteration 1991 : loss : 0.079563, loss_ce: 0.027722
2021-12-14 02:03:19,542 iteration 1992 : loss : 0.081221, loss_ce: 0.027788
2021-12-14 02:03:21,101 iteration 1993 : loss : 0.087507, loss_ce: 0.018154
2021-12-14 02:03:22,707 iteration 1994 : loss : 0.074731, loss_ce: 0.023662
2021-12-14 02:03:24,281 iteration 1995 : loss : 0.098096, loss_ce: 0.026315
2021-12-14 02:03:25,863 iteration 1996 : loss : 0.079603, loss_ce: 0.028240
2021-12-14 02:03:27,447 iteration 1997 : loss : 0.069237, loss_ce: 0.020808
2021-12-14 02:03:29,077 iteration 1998 : loss : 0.089408, loss_ce: 0.032150
2021-12-14 02:03:30,677 iteration 1999 : loss : 0.079472, loss_ce: 0.026621
2021-12-14 02:03:32,380 iteration 2000 : loss : 0.082263, loss_ce: 0.018041
2021-12-14 02:03:33,965 iteration 2001 : loss : 0.069830, loss_ce: 0.019506
2021-12-14 02:03:35,471 iteration 2002 : loss : 0.083604, loss_ce: 0.027123
2021-12-14 02:03:36,925 iteration 2003 : loss : 0.066082, loss_ce: 0.023307
2021-12-14 02:03:38,459 iteration 2004 : loss : 0.086167, loss_ce: 0.020354
2021-12-14 02:03:40,074 iteration 2005 : loss : 0.068063, loss_ce: 0.017257
2021-12-14 02:03:41,679 iteration 2006 : loss : 0.087594, loss_ce: 0.024919
 30%|████████▌                    | 118/400 [58:38<2:16:08, 28.97s/it]2021-12-14 02:03:43,367 iteration 2007 : loss : 0.082714, loss_ce: 0.024103
2021-12-14 02:03:45,063 iteration 2008 : loss : 0.097964, loss_ce: 0.027223
2021-12-14 02:03:46,644 iteration 2009 : loss : 0.074625, loss_ce: 0.023170
2021-12-14 02:03:48,213 iteration 2010 : loss : 0.077931, loss_ce: 0.022689
2021-12-14 02:03:49,881 iteration 2011 : loss : 0.077360, loss_ce: 0.023843
2021-12-14 02:03:51,478 iteration 2012 : loss : 0.073671, loss_ce: 0.025856
2021-12-14 02:03:52,992 iteration 2013 : loss : 0.070343, loss_ce: 0.021899
2021-12-14 02:03:54,553 iteration 2014 : loss : 0.082612, loss_ce: 0.020900
2021-12-14 02:03:56,175 iteration 2015 : loss : 0.082010, loss_ce: 0.026360
2021-12-14 02:03:57,744 iteration 2016 : loss : 0.078181, loss_ce: 0.020746
2021-12-14 02:03:59,367 iteration 2017 : loss : 0.071565, loss_ce: 0.018366
2021-12-14 02:04:01,047 iteration 2018 : loss : 0.083864, loss_ce: 0.028397
2021-12-14 02:04:02,613 iteration 2019 : loss : 0.078614, loss_ce: 0.021354
2021-12-14 02:04:04,159 iteration 2020 : loss : 0.069711, loss_ce: 0.018996
2021-12-14 02:04:05,755 iteration 2021 : loss : 0.079143, loss_ce: 0.020570
2021-12-14 02:04:07,357 iteration 2022 : loss : 0.071261, loss_ce: 0.022475
2021-12-14 02:04:09,008 iteration 2023 : loss : 0.083297, loss_ce: 0.026469
 30%|████████▋                    | 119/400 [59:05<2:13:21, 28.47s/it]2021-12-14 02:04:10,604 iteration 2024 : loss : 0.079156, loss_ce: 0.022096
2021-12-14 02:04:12,204 iteration 2025 : loss : 0.069093, loss_ce: 0.023409
2021-12-14 02:04:13,837 iteration 2026 : loss : 0.077782, loss_ce: 0.023044
2021-12-14 02:04:15,399 iteration 2027 : loss : 0.072651, loss_ce: 0.017320
2021-12-14 02:04:16,924 iteration 2028 : loss : 0.069280, loss_ce: 0.022156
2021-12-14 02:04:18,475 iteration 2029 : loss : 0.075468, loss_ce: 0.024920
2021-12-14 02:04:20,013 iteration 2030 : loss : 0.096001, loss_ce: 0.029712
2021-12-14 02:04:21,587 iteration 2031 : loss : 0.071159, loss_ce: 0.019055
2021-12-14 02:04:23,244 iteration 2032 : loss : 0.097884, loss_ce: 0.035383
2021-12-14 02:04:24,932 iteration 2033 : loss : 0.088507, loss_ce: 0.028763
2021-12-14 02:04:26,476 iteration 2034 : loss : 0.072743, loss_ce: 0.022945
2021-12-14 02:04:28,062 iteration 2035 : loss : 0.066784, loss_ce: 0.017569
2021-12-14 02:04:29,693 iteration 2036 : loss : 0.077929, loss_ce: 0.027951
2021-12-14 02:04:31,276 iteration 2037 : loss : 0.096751, loss_ce: 0.023225
2021-12-14 02:04:32,903 iteration 2038 : loss : 0.078049, loss_ce: 0.021382
2021-12-14 02:04:34,574 iteration 2039 : loss : 0.092181, loss_ce: 0.026414
2021-12-14 02:04:34,574 Training Data Eval:
2021-12-14 02:04:42,753   Average segmentation loss on training set: 0.0660
2021-12-14 02:04:42,753 Validation Data Eval:
2021-12-14 02:04:45,543   Average segmentation loss on validation set: 0.1010
2021-12-14 02:04:47,190 iteration 2040 : loss : 0.081273, loss_ce: 0.025779
 30%|████████▋                    | 120/400 [59:44<2:26:29, 31.39s/it]2021-12-14 02:04:48,885 iteration 2041 : loss : 0.086957, loss_ce: 0.018998
2021-12-14 02:04:50,448 iteration 2042 : loss : 0.081017, loss_ce: 0.022874
2021-12-14 02:04:52,007 iteration 2043 : loss : 0.068926, loss_ce: 0.018350
2021-12-14 02:04:53,584 iteration 2044 : loss : 0.073007, loss_ce: 0.023698
2021-12-14 02:04:55,132 iteration 2045 : loss : 0.067639, loss_ce: 0.018856
2021-12-14 02:04:56,721 iteration 2046 : loss : 0.088592, loss_ce: 0.030689
2021-12-14 02:04:58,276 iteration 2047 : loss : 0.073815, loss_ce: 0.023475
2021-12-14 02:04:59,859 iteration 2048 : loss : 0.076612, loss_ce: 0.023001
2021-12-14 02:05:01,408 iteration 2049 : loss : 0.080646, loss_ce: 0.016648
2021-12-14 02:05:03,005 iteration 2050 : loss : 0.088916, loss_ce: 0.029323
2021-12-14 02:05:04,599 iteration 2051 : loss : 0.075071, loss_ce: 0.025190
2021-12-14 02:05:06,119 iteration 2052 : loss : 0.091022, loss_ce: 0.025913
2021-12-14 02:05:07,703 iteration 2053 : loss : 0.077899, loss_ce: 0.019829
2021-12-14 02:05:09,253 iteration 2054 : loss : 0.073809, loss_ce: 0.023502
2021-12-14 02:05:10,833 iteration 2055 : loss : 0.090169, loss_ce: 0.022170
2021-12-14 02:05:12,447 iteration 2056 : loss : 0.080630, loss_ce: 0.025305
2021-12-14 02:05:13,977 iteration 2057 : loss : 0.078225, loss_ce: 0.028011
 30%|████████▏                  | 121/400 [1:00:10<2:19:30, 30.00s/it]2021-12-14 02:05:15,595 iteration 2058 : loss : 0.072096, loss_ce: 0.023742
2021-12-14 02:05:17,229 iteration 2059 : loss : 0.085993, loss_ce: 0.026271
2021-12-14 02:05:18,721 iteration 2060 : loss : 0.073256, loss_ce: 0.020321
2021-12-14 02:05:20,328 iteration 2061 : loss : 0.091940, loss_ce: 0.028780
2021-12-14 02:05:21,889 iteration 2062 : loss : 0.083669, loss_ce: 0.026170
2021-12-14 02:05:23,457 iteration 2063 : loss : 0.086990, loss_ce: 0.019365
2021-12-14 02:05:24,980 iteration 2064 : loss : 0.066944, loss_ce: 0.018036
2021-12-14 02:05:26,532 iteration 2065 : loss : 0.078096, loss_ce: 0.019087
2021-12-14 02:05:28,107 iteration 2066 : loss : 0.086897, loss_ce: 0.027656
2021-12-14 02:05:29,718 iteration 2067 : loss : 0.067029, loss_ce: 0.019193
2021-12-14 02:05:31,364 iteration 2068 : loss : 0.079966, loss_ce: 0.028413
2021-12-14 02:05:32,919 iteration 2069 : loss : 0.084819, loss_ce: 0.019748
2021-12-14 02:05:34,545 iteration 2070 : loss : 0.080366, loss_ce: 0.027777
2021-12-14 02:05:36,184 iteration 2071 : loss : 0.075574, loss_ce: 0.022712
2021-12-14 02:05:37,770 iteration 2072 : loss : 0.102714, loss_ce: 0.034159
2021-12-14 02:05:39,398 iteration 2073 : loss : 0.080849, loss_ce: 0.020188
2021-12-14 02:05:41,016 iteration 2074 : loss : 0.083509, loss_ce: 0.033203
 30%|████████▏                  | 122/400 [1:00:37<2:14:54, 29.12s/it]2021-12-14 02:05:42,616 iteration 2075 : loss : 0.070840, loss_ce: 0.019739
2021-12-14 02:05:44,207 iteration 2076 : loss : 0.076388, loss_ce: 0.019814
2021-12-14 02:05:45,818 iteration 2077 : loss : 0.085679, loss_ce: 0.031580
2021-12-14 02:05:47,526 iteration 2078 : loss : 0.080164, loss_ce: 0.021734
2021-12-14 02:05:49,088 iteration 2079 : loss : 0.081758, loss_ce: 0.022243
2021-12-14 02:05:50,719 iteration 2080 : loss : 0.076886, loss_ce: 0.022106
2021-12-14 02:05:52,210 iteration 2081 : loss : 0.097319, loss_ce: 0.032331
2021-12-14 02:05:53,685 iteration 2082 : loss : 0.063729, loss_ce: 0.017326
2021-12-14 02:05:55,243 iteration 2083 : loss : 0.079588, loss_ce: 0.030943
2021-12-14 02:05:56,803 iteration 2084 : loss : 0.082655, loss_ce: 0.029723
2021-12-14 02:05:58,329 iteration 2085 : loss : 0.075957, loss_ce: 0.017150
2021-12-14 02:05:59,893 iteration 2086 : loss : 0.083400, loss_ce: 0.028056
2021-12-14 02:06:01,428 iteration 2087 : loss : 0.074856, loss_ce: 0.022608
2021-12-14 02:06:03,065 iteration 2088 : loss : 0.072250, loss_ce: 0.021022
2021-12-14 02:06:04,683 iteration 2089 : loss : 0.075959, loss_ce: 0.027609
2021-12-14 02:06:06,195 iteration 2090 : loss : 0.065345, loss_ce: 0.019341
2021-12-14 02:06:07,804 iteration 2091 : loss : 0.078206, loss_ce: 0.027337
 31%|████████▎                  | 123/400 [1:01:04<2:11:11, 28.42s/it]2021-12-14 02:06:09,352 iteration 2092 : loss : 0.070476, loss_ce: 0.021958
2021-12-14 02:06:10,902 iteration 2093 : loss : 0.071341, loss_ce: 0.019571
2021-12-14 02:06:12,478 iteration 2094 : loss : 0.071348, loss_ce: 0.014036
2021-12-14 02:06:13,996 iteration 2095 : loss : 0.062614, loss_ce: 0.019411
2021-12-14 02:06:15,648 iteration 2096 : loss : 0.078811, loss_ce: 0.028129
2021-12-14 02:06:17,252 iteration 2097 : loss : 0.098083, loss_ce: 0.027871
2021-12-14 02:06:18,840 iteration 2098 : loss : 0.081271, loss_ce: 0.024282
2021-12-14 02:06:20,443 iteration 2099 : loss : 0.070253, loss_ce: 0.018479
2021-12-14 02:06:22,062 iteration 2100 : loss : 0.089909, loss_ce: 0.038060
2021-12-14 02:06:23,666 iteration 2101 : loss : 0.071881, loss_ce: 0.019203
2021-12-14 02:06:25,290 iteration 2102 : loss : 0.074673, loss_ce: 0.024529
2021-12-14 02:06:26,791 iteration 2103 : loss : 0.073272, loss_ce: 0.023486
2021-12-14 02:06:28,310 iteration 2104 : loss : 0.084022, loss_ce: 0.020279
2021-12-14 02:06:29,981 iteration 2105 : loss : 0.095521, loss_ce: 0.024271
2021-12-14 02:06:31,526 iteration 2106 : loss : 0.064286, loss_ce: 0.020193
2021-12-14 02:06:33,181 iteration 2107 : loss : 0.068744, loss_ce: 0.016724
2021-12-14 02:06:34,779 iteration 2108 : loss : 0.084894, loss_ce: 0.027197
 31%|████████▎                  | 124/400 [1:01:31<2:08:43, 27.99s/it]2021-12-14 02:06:36,400 iteration 2109 : loss : 0.085047, loss_ce: 0.027797
2021-12-14 02:06:38,026 iteration 2110 : loss : 0.075112, loss_ce: 0.019966
2021-12-14 02:06:39,699 iteration 2111 : loss : 0.073726, loss_ce: 0.013356
2021-12-14 02:06:41,294 iteration 2112 : loss : 0.078835, loss_ce: 0.026265
2021-12-14 02:06:42,840 iteration 2113 : loss : 0.083661, loss_ce: 0.031850
2021-12-14 02:06:44,448 iteration 2114 : loss : 0.073742, loss_ce: 0.027053
2021-12-14 02:06:46,051 iteration 2115 : loss : 0.076811, loss_ce: 0.018152
2021-12-14 02:06:47,650 iteration 2116 : loss : 0.080057, loss_ce: 0.023378
2021-12-14 02:06:49,239 iteration 2117 : loss : 0.065790, loss_ce: 0.019279
2021-12-14 02:06:50,859 iteration 2118 : loss : 0.082761, loss_ce: 0.018059
2021-12-14 02:06:52,480 iteration 2119 : loss : 0.079811, loss_ce: 0.023178
2021-12-14 02:06:54,069 iteration 2120 : loss : 0.090254, loss_ce: 0.022460
2021-12-14 02:06:55,594 iteration 2121 : loss : 0.073933, loss_ce: 0.021359
2021-12-14 02:06:57,151 iteration 2122 : loss : 0.071520, loss_ce: 0.019513
2021-12-14 02:06:58,788 iteration 2123 : loss : 0.094367, loss_ce: 0.034069
2021-12-14 02:07:00,454 iteration 2124 : loss : 0.092240, loss_ce: 0.030479
2021-12-14 02:07:00,455 Training Data Eval:
2021-12-14 02:07:08,657   Average segmentation loss on training set: 0.0614
2021-12-14 02:07:08,657 Validation Data Eval:
2021-12-14 02:07:11,448   Average segmentation loss on validation set: 0.1079
2021-12-14 02:07:13,043 iteration 2125 : loss : 0.080165, loss_ce: 0.032359
 31%|████████▍                  | 125/400 [1:02:10<2:22:25, 31.07s/it]2021-12-14 02:07:14,725 iteration 2126 : loss : 0.086860, loss_ce: 0.025385
2021-12-14 02:07:16,343 iteration 2127 : loss : 0.088455, loss_ce: 0.035078
2021-12-14 02:07:17,953 iteration 2128 : loss : 0.079791, loss_ce: 0.022626
2021-12-14 02:07:19,508 iteration 2129 : loss : 0.072427, loss_ce: 0.020336
2021-12-14 02:07:21,131 iteration 2130 : loss : 0.099275, loss_ce: 0.026489
2021-12-14 02:07:22,697 iteration 2131 : loss : 0.079229, loss_ce: 0.019016
2021-12-14 02:07:24,278 iteration 2132 : loss : 0.071956, loss_ce: 0.020989
2021-12-14 02:07:25,925 iteration 2133 : loss : 0.096079, loss_ce: 0.025456
2021-12-14 02:07:27,437 iteration 2134 : loss : 0.075776, loss_ce: 0.028214
2021-12-14 02:07:29,015 iteration 2135 : loss : 0.072442, loss_ce: 0.021507
2021-12-14 02:07:30,583 iteration 2136 : loss : 0.074877, loss_ce: 0.023781
2021-12-14 02:07:32,162 iteration 2137 : loss : 0.091556, loss_ce: 0.029860
2021-12-14 02:07:33,698 iteration 2138 : loss : 0.080922, loss_ce: 0.025488
2021-12-14 02:07:35,313 iteration 2139 : loss : 0.075364, loss_ce: 0.025897
2021-12-14 02:07:36,888 iteration 2140 : loss : 0.084614, loss_ce: 0.034190
2021-12-14 02:07:38,532 iteration 2141 : loss : 0.085492, loss_ce: 0.021724
2021-12-14 02:07:40,073 iteration 2142 : loss : 0.072355, loss_ce: 0.020355
 32%|████████▌                  | 126/400 [1:02:37<2:16:21, 29.86s/it]2021-12-14 02:07:41,638 iteration 2143 : loss : 0.076502, loss_ce: 0.020429
2021-12-14 02:07:43,243 iteration 2144 : loss : 0.077619, loss_ce: 0.018036
2021-12-14 02:07:44,858 iteration 2145 : loss : 0.074992, loss_ce: 0.018324
2021-12-14 02:07:46,389 iteration 2146 : loss : 0.061052, loss_ce: 0.018626
2021-12-14 02:07:47,995 iteration 2147 : loss : 0.085545, loss_ce: 0.022049
2021-12-14 02:07:49,554 iteration 2148 : loss : 0.079723, loss_ce: 0.025189
2021-12-14 02:07:51,141 iteration 2149 : loss : 0.084200, loss_ce: 0.025621
2021-12-14 02:07:52,701 iteration 2150 : loss : 0.078712, loss_ce: 0.025367
2021-12-14 02:07:54,348 iteration 2151 : loss : 0.083891, loss_ce: 0.028341
2021-12-14 02:07:55,883 iteration 2152 : loss : 0.072862, loss_ce: 0.023725
2021-12-14 02:07:57,407 iteration 2153 : loss : 0.068875, loss_ce: 0.020389
2021-12-14 02:07:59,113 iteration 2154 : loss : 0.083769, loss_ce: 0.021678
2021-12-14 02:08:00,693 iteration 2155 : loss : 0.068288, loss_ce: 0.021167
2021-12-14 02:08:02,223 iteration 2156 : loss : 0.084483, loss_ce: 0.029229
2021-12-14 02:08:03,943 iteration 2157 : loss : 0.120346, loss_ce: 0.029365
2021-12-14 02:08:05,626 iteration 2158 : loss : 0.091559, loss_ce: 0.032996
2021-12-14 02:08:07,237 iteration 2159 : loss : 0.077146, loss_ce: 0.017075
 32%|████████▌                  | 127/400 [1:03:04<2:12:10, 29.05s/it]2021-12-14 02:08:08,835 iteration 2160 : loss : 0.075290, loss_ce: 0.021619
2021-12-14 02:08:10,359 iteration 2161 : loss : 0.067156, loss_ce: 0.016153
2021-12-14 02:08:11,917 iteration 2162 : loss : 0.077553, loss_ce: 0.022676
2021-12-14 02:08:13,462 iteration 2163 : loss : 0.069567, loss_ce: 0.019974
2021-12-14 02:08:15,077 iteration 2164 : loss : 0.073774, loss_ce: 0.027556
2021-12-14 02:08:16,666 iteration 2165 : loss : 0.089909, loss_ce: 0.026050
2021-12-14 02:08:18,193 iteration 2166 : loss : 0.077140, loss_ce: 0.029679
2021-12-14 02:08:19,696 iteration 2167 : loss : 0.069279, loss_ce: 0.020695
2021-12-14 02:08:21,243 iteration 2168 : loss : 0.061082, loss_ce: 0.019307
2021-12-14 02:08:22,836 iteration 2169 : loss : 0.074999, loss_ce: 0.021589
2021-12-14 02:08:24,305 iteration 2170 : loss : 0.068504, loss_ce: 0.017116
2021-12-14 02:08:25,855 iteration 2171 : loss : 0.078525, loss_ce: 0.024820
2021-12-14 02:08:27,396 iteration 2172 : loss : 0.087433, loss_ce: 0.023628
2021-12-14 02:08:28,931 iteration 2173 : loss : 0.074816, loss_ce: 0.016387
2021-12-14 02:08:30,505 iteration 2174 : loss : 0.081485, loss_ce: 0.026848
2021-12-14 02:08:32,160 iteration 2175 : loss : 0.066992, loss_ce: 0.020804
2021-12-14 02:08:33,632 iteration 2176 : loss : 0.065480, loss_ce: 0.020106
 32%|████████▋                  | 128/400 [1:03:30<2:08:05, 28.26s/it]2021-12-14 02:08:35,205 iteration 2177 : loss : 0.089241, loss_ce: 0.037763
2021-12-14 02:08:36,778 iteration 2178 : loss : 0.065250, loss_ce: 0.016081
2021-12-14 02:08:38,424 iteration 2179 : loss : 0.074251, loss_ce: 0.019206
2021-12-14 02:08:40,038 iteration 2180 : loss : 0.066806, loss_ce: 0.018877
2021-12-14 02:08:41,547 iteration 2181 : loss : 0.069200, loss_ce: 0.020063
2021-12-14 02:08:43,118 iteration 2182 : loss : 0.075281, loss_ce: 0.022103
2021-12-14 02:08:44,705 iteration 2183 : loss : 0.083155, loss_ce: 0.017767
2021-12-14 02:08:46,221 iteration 2184 : loss : 0.088612, loss_ce: 0.036940
2021-12-14 02:08:47,745 iteration 2185 : loss : 0.067167, loss_ce: 0.019560
2021-12-14 02:08:49,393 iteration 2186 : loss : 0.077913, loss_ce: 0.024133
2021-12-14 02:08:51,058 iteration 2187 : loss : 0.078962, loss_ce: 0.022000
2021-12-14 02:08:52,789 iteration 2188 : loss : 0.089283, loss_ce: 0.034579
2021-12-14 02:08:54,508 iteration 2189 : loss : 0.087191, loss_ce: 0.026069
2021-12-14 02:08:56,100 iteration 2190 : loss : 0.069230, loss_ce: 0.022379
2021-12-14 02:08:57,707 iteration 2191 : loss : 0.065056, loss_ce: 0.017672
2021-12-14 02:08:59,250 iteration 2192 : loss : 0.066154, loss_ce: 0.018375
2021-12-14 02:09:00,843 iteration 2193 : loss : 0.064884, loss_ce: 0.016954
 32%|████████▋                  | 129/400 [1:03:57<2:06:12, 27.94s/it]2021-12-14 02:09:02,517 iteration 2194 : loss : 0.071478, loss_ce: 0.020017
2021-12-14 02:09:04,125 iteration 2195 : loss : 0.077722, loss_ce: 0.027653
2021-12-14 02:09:05,763 iteration 2196 : loss : 0.068589, loss_ce: 0.024566
2021-12-14 02:09:07,431 iteration 2197 : loss : 0.089098, loss_ce: 0.023067
2021-12-14 02:09:09,014 iteration 2198 : loss : 0.094313, loss_ce: 0.026056
2021-12-14 02:09:10,602 iteration 2199 : loss : 0.075473, loss_ce: 0.025957
2021-12-14 02:09:12,260 iteration 2200 : loss : 0.122288, loss_ce: 0.021112
2021-12-14 02:09:13,786 iteration 2201 : loss : 0.070258, loss_ce: 0.020187
2021-12-14 02:09:15,477 iteration 2202 : loss : 0.090755, loss_ce: 0.030817
2021-12-14 02:09:17,093 iteration 2203 : loss : 0.082488, loss_ce: 0.022103
2021-12-14 02:09:18,615 iteration 2204 : loss : 0.062497, loss_ce: 0.015514
2021-12-14 02:09:20,214 iteration 2205 : loss : 0.077811, loss_ce: 0.027873
2021-12-14 02:09:21,882 iteration 2206 : loss : 0.080630, loss_ce: 0.025834
2021-12-14 02:09:23,495 iteration 2207 : loss : 0.086595, loss_ce: 0.021917
2021-12-14 02:09:25,136 iteration 2208 : loss : 0.097168, loss_ce: 0.024635
2021-12-14 02:09:26,723 iteration 2209 : loss : 0.073613, loss_ce: 0.021883
2021-12-14 02:09:26,723 Training Data Eval:
2021-12-14 02:09:34,895   Average segmentation loss on training set: 0.0605
2021-12-14 02:09:34,895 Validation Data Eval:
2021-12-14 02:09:37,694   Average segmentation loss on validation set: 0.0987
2021-12-14 02:09:43,161 Found new lowest validation loss at iteration 2209! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/TU_3seeds/REVISED_SGD_best_val_loss_seed1234.pth
2021-12-14 02:09:44,658 iteration 2210 : loss : 0.088936, loss_ce: 0.036676
 32%|████████▊                  | 130/400 [1:04:41<2:27:10, 32.70s/it]2021-12-14 02:09:46,212 iteration 2211 : loss : 0.081139, loss_ce: 0.019226
2021-12-14 02:09:47,749 iteration 2212 : loss : 0.071588, loss_ce: 0.023270
2021-12-14 02:09:49,333 iteration 2213 : loss : 0.090757, loss_ce: 0.019482
2021-12-14 02:09:50,835 iteration 2214 : loss : 0.070180, loss_ce: 0.018050
2021-12-14 02:09:52,336 iteration 2215 : loss : 0.062417, loss_ce: 0.017540
2021-12-14 02:09:53,882 iteration 2216 : loss : 0.088448, loss_ce: 0.030808
2021-12-14 02:09:55,406 iteration 2217 : loss : 0.073330, loss_ce: 0.028111
2021-12-14 02:09:56,962 iteration 2218 : loss : 0.061742, loss_ce: 0.016673
2021-12-14 02:09:58,569 iteration 2219 : loss : 0.076746, loss_ce: 0.027801
2021-12-14 02:10:00,228 iteration 2220 : loss : 0.073077, loss_ce: 0.027477
2021-12-14 02:10:01,878 iteration 2221 : loss : 0.084193, loss_ce: 0.021609
2021-12-14 02:10:03,376 iteration 2222 : loss : 0.073859, loss_ce: 0.021644
2021-12-14 02:10:04,899 iteration 2223 : loss : 0.076498, loss_ce: 0.022635
2021-12-14 02:10:06,540 iteration 2224 : loss : 0.071945, loss_ce: 0.022260
2021-12-14 02:10:08,139 iteration 2225 : loss : 0.078210, loss_ce: 0.021446
2021-12-14 02:10:09,789 iteration 2226 : loss : 0.077126, loss_ce: 0.028844
2021-12-14 02:10:11,421 iteration 2227 : loss : 0.085318, loss_ce: 0.022030
 33%|████████▊                  | 131/400 [1:05:08<2:18:36, 30.92s/it]2021-12-14 02:10:13,120 iteration 2228 : loss : 0.079263, loss_ce: 0.028963
2021-12-14 02:10:14,716 iteration 2229 : loss : 0.075937, loss_ce: 0.021774
2021-12-14 02:10:16,438 iteration 2230 : loss : 0.090417, loss_ce: 0.029463
2021-12-14 02:10:18,014 iteration 2231 : loss : 0.095509, loss_ce: 0.044986
2021-12-14 02:10:19,583 iteration 2232 : loss : 0.079053, loss_ce: 0.030286
2021-12-14 02:10:21,360 iteration 2233 : loss : 0.128158, loss_ce: 0.026782
2021-12-14 02:10:22,986 iteration 2234 : loss : 0.073697, loss_ce: 0.017225
2021-12-14 02:10:24,576 iteration 2235 : loss : 0.078207, loss_ce: 0.025306
2021-12-14 02:10:26,144 iteration 2236 : loss : 0.067091, loss_ce: 0.020818
2021-12-14 02:10:27,743 iteration 2237 : loss : 0.078511, loss_ce: 0.026021
2021-12-14 02:10:29,278 iteration 2238 : loss : 0.084986, loss_ce: 0.023008
2021-12-14 02:10:30,838 iteration 2239 : loss : 0.061015, loss_ce: 0.012946
2021-12-14 02:10:32,340 iteration 2240 : loss : 0.088700, loss_ce: 0.021191
2021-12-14 02:10:33,912 iteration 2241 : loss : 0.074462, loss_ce: 0.019066
2021-12-14 02:10:35,549 iteration 2242 : loss : 0.095252, loss_ce: 0.028426
2021-12-14 02:10:37,163 iteration 2243 : loss : 0.100106, loss_ce: 0.038285
2021-12-14 02:10:38,728 iteration 2244 : loss : 0.069296, loss_ce: 0.018960
 33%|████████▉                  | 132/400 [1:05:35<2:13:15, 29.83s/it]2021-12-14 02:10:40,339 iteration 2245 : loss : 0.063276, loss_ce: 0.015316
2021-12-14 02:10:41,828 iteration 2246 : loss : 0.066058, loss_ce: 0.015593
2021-12-14 02:10:43,416 iteration 2247 : loss : 0.069929, loss_ce: 0.023036
2021-12-14 02:10:45,071 iteration 2248 : loss : 0.091180, loss_ce: 0.032405
2021-12-14 02:10:46,661 iteration 2249 : loss : 0.064785, loss_ce: 0.021438
2021-12-14 02:10:48,255 iteration 2250 : loss : 0.065807, loss_ce: 0.016417
2021-12-14 02:10:49,872 iteration 2251 : loss : 0.074026, loss_ce: 0.023727
2021-12-14 02:10:51,458 iteration 2252 : loss : 0.081687, loss_ce: 0.021158
2021-12-14 02:10:53,135 iteration 2253 : loss : 0.085330, loss_ce: 0.027456
2021-12-14 02:10:54,767 iteration 2254 : loss : 0.073412, loss_ce: 0.025318
2021-12-14 02:10:56,347 iteration 2255 : loss : 0.065260, loss_ce: 0.019647
2021-12-14 02:10:57,914 iteration 2256 : loss : 0.067317, loss_ce: 0.019873
2021-12-14 02:10:59,448 iteration 2257 : loss : 0.077379, loss_ce: 0.020211
2021-12-14 02:11:00,974 iteration 2258 : loss : 0.084196, loss_ce: 0.024398
2021-12-14 02:11:02,613 iteration 2259 : loss : 0.072802, loss_ce: 0.022171
2021-12-14 02:11:04,129 iteration 2260 : loss : 0.070240, loss_ce: 0.022213
2021-12-14 02:11:05,728 iteration 2261 : loss : 0.077129, loss_ce: 0.028664
 33%|████████▉                  | 133/400 [1:06:02<2:08:58, 28.98s/it]2021-12-14 02:11:07,303 iteration 2262 : loss : 0.067795, loss_ce: 0.025767
2021-12-14 02:11:08,956 iteration 2263 : loss : 0.092920, loss_ce: 0.029011
2021-12-14 02:11:10,629 iteration 2264 : loss : 0.074733, loss_ce: 0.018937
2021-12-14 02:11:12,242 iteration 2265 : loss : 0.069793, loss_ce: 0.021322
2021-12-14 02:11:13,795 iteration 2266 : loss : 0.067452, loss_ce: 0.021676
2021-12-14 02:11:15,352 iteration 2267 : loss : 0.068156, loss_ce: 0.020234
2021-12-14 02:11:16,931 iteration 2268 : loss : 0.073416, loss_ce: 0.021378
2021-12-14 02:11:18,473 iteration 2269 : loss : 0.070421, loss_ce: 0.026822
2021-12-14 02:11:20,050 iteration 2270 : loss : 0.080400, loss_ce: 0.023651
2021-12-14 02:11:21,600 iteration 2271 : loss : 0.082334, loss_ce: 0.023883
2021-12-14 02:11:23,165 iteration 2272 : loss : 0.082986, loss_ce: 0.032902
2021-12-14 02:11:24,765 iteration 2273 : loss : 0.065261, loss_ce: 0.016564
2021-12-14 02:11:26,365 iteration 2274 : loss : 0.072079, loss_ce: 0.020124
2021-12-14 02:11:28,012 iteration 2275 : loss : 0.091702, loss_ce: 0.026610
2021-12-14 02:11:29,543 iteration 2276 : loss : 0.062639, loss_ce: 0.017969
2021-12-14 02:11:31,135 iteration 2277 : loss : 0.074410, loss_ce: 0.020954
2021-12-14 02:11:32,671 iteration 2278 : loss : 0.062232, loss_ce: 0.018128
 34%|█████████                  | 134/400 [1:06:29<2:05:46, 28.37s/it]2021-12-14 02:11:34,229 iteration 2279 : loss : 0.107553, loss_ce: 0.030631
2021-12-14 02:11:35,817 iteration 2280 : loss : 0.073767, loss_ce: 0.025182
2021-12-14 02:11:37,398 iteration 2281 : loss : 0.088565, loss_ce: 0.017908
2021-12-14 02:11:39,010 iteration 2282 : loss : 0.070336, loss_ce: 0.020504
2021-12-14 02:11:40,662 iteration 2283 : loss : 0.082359, loss_ce: 0.027404
2021-12-14 02:11:42,220 iteration 2284 : loss : 0.076582, loss_ce: 0.025285
2021-12-14 02:11:43,783 iteration 2285 : loss : 0.061507, loss_ce: 0.016608
2021-12-14 02:11:45,344 iteration 2286 : loss : 0.067955, loss_ce: 0.019373
2021-12-14 02:11:46,907 iteration 2287 : loss : 0.073106, loss_ce: 0.023310
2021-12-14 02:11:48,518 iteration 2288 : loss : 0.065515, loss_ce: 0.018122
2021-12-14 02:11:50,054 iteration 2289 : loss : 0.067249, loss_ce: 0.014408
2021-12-14 02:11:51,684 iteration 2290 : loss : 0.080462, loss_ce: 0.030201
2021-12-14 02:11:53,254 iteration 2291 : loss : 0.060011, loss_ce: 0.016743
2021-12-14 02:11:54,813 iteration 2292 : loss : 0.089099, loss_ce: 0.032617
2021-12-14 02:11:56,316 iteration 2293 : loss : 0.076114, loss_ce: 0.029653
2021-12-14 02:11:57,925 iteration 2294 : loss : 0.087734, loss_ce: 0.026444
2021-12-14 02:11:57,926 Training Data Eval:
2021-12-14 02:12:06,122   Average segmentation loss on training set: 0.0619
2021-12-14 02:12:06,122 Validation Data Eval:
2021-12-14 02:12:08,920   Average segmentation loss on validation set: 0.1000
2021-12-14 02:12:10,578 iteration 2295 : loss : 0.077122, loss_ce: 0.023201
 34%|█████████                  | 135/400 [1:07:07<2:17:57, 31.24s/it]2021-12-14 02:12:12,138 iteration 2296 : loss : 0.065096, loss_ce: 0.019517
2021-12-14 02:12:13,705 iteration 2297 : loss : 0.066051, loss_ce: 0.019764
2021-12-14 02:12:15,273 iteration 2298 : loss : 0.064127, loss_ce: 0.019710
2021-12-14 02:12:16,920 iteration 2299 : loss : 0.089301, loss_ce: 0.033829
2021-12-14 02:12:18,466 iteration 2300 : loss : 0.065817, loss_ce: 0.020785
2021-12-14 02:12:20,117 iteration 2301 : loss : 0.065763, loss_ce: 0.016352
2021-12-14 02:12:21,735 iteration 2302 : loss : 0.079995, loss_ce: 0.023427
2021-12-14 02:12:23,329 iteration 2303 : loss : 0.077288, loss_ce: 0.023126
2021-12-14 02:12:24,997 iteration 2304 : loss : 0.076180, loss_ce: 0.020382
2021-12-14 02:12:26,623 iteration 2305 : loss : 0.072881, loss_ce: 0.022909
2021-12-14 02:12:28,310 iteration 2306 : loss : 0.075127, loss_ce: 0.027794
2021-12-14 02:12:29,873 iteration 2307 : loss : 0.087768, loss_ce: 0.023957
2021-12-14 02:12:31,407 iteration 2308 : loss : 0.065729, loss_ce: 0.019994
2021-12-14 02:12:32,962 iteration 2309 : loss : 0.068639, loss_ce: 0.023359
2021-12-14 02:12:34,607 iteration 2310 : loss : 0.074248, loss_ce: 0.023944
2021-12-14 02:12:36,112 iteration 2311 : loss : 0.075319, loss_ce: 0.021480
2021-12-14 02:12:37,700 iteration 2312 : loss : 0.073789, loss_ce: 0.023817
 34%|█████████▏                 | 136/400 [1:07:34<2:11:58, 29.99s/it]2021-12-14 02:12:39,361 iteration 2313 : loss : 0.076269, loss_ce: 0.023005
2021-12-14 02:12:40,842 iteration 2314 : loss : 0.062550, loss_ce: 0.016544
2021-12-14 02:12:42,372 iteration 2315 : loss : 0.063373, loss_ce: 0.016967
2021-12-14 02:12:44,030 iteration 2316 : loss : 0.074353, loss_ce: 0.024339
2021-12-14 02:12:45,546 iteration 2317 : loss : 0.064532, loss_ce: 0.017224
2021-12-14 02:12:47,096 iteration 2318 : loss : 0.074839, loss_ce: 0.028591
2021-12-14 02:12:48,670 iteration 2319 : loss : 0.083878, loss_ce: 0.026115
2021-12-14 02:12:50,327 iteration 2320 : loss : 0.079127, loss_ce: 0.026979
2021-12-14 02:12:51,907 iteration 2321 : loss : 0.071606, loss_ce: 0.023699
2021-12-14 02:12:53,500 iteration 2322 : loss : 0.067919, loss_ce: 0.022749
2021-12-14 02:12:54,994 iteration 2323 : loss : 0.066143, loss_ce: 0.018563
2021-12-14 02:12:56,560 iteration 2324 : loss : 0.072103, loss_ce: 0.024757
2021-12-14 02:12:58,025 iteration 2325 : loss : 0.062681, loss_ce: 0.020801
2021-12-14 02:12:59,583 iteration 2326 : loss : 0.082425, loss_ce: 0.016264
2021-12-14 02:13:01,117 iteration 2327 : loss : 0.069917, loss_ce: 0.021512
2021-12-14 02:13:02,691 iteration 2328 : loss : 0.075489, loss_ce: 0.028153
2021-12-14 02:13:04,213 iteration 2329 : loss : 0.069324, loss_ce: 0.021201
 34%|█████████▏                 | 137/400 [1:08:01<2:06:55, 28.95s/it]2021-12-14 02:13:05,847 iteration 2330 : loss : 0.079423, loss_ce: 0.026650
2021-12-14 02:13:07,380 iteration 2331 : loss : 0.064443, loss_ce: 0.019532
2021-12-14 02:13:09,040 iteration 2332 : loss : 0.072577, loss_ce: 0.020989
2021-12-14 02:13:10,619 iteration 2333 : loss : 0.102384, loss_ce: 0.041147
2021-12-14 02:13:12,318 iteration 2334 : loss : 0.063560, loss_ce: 0.018721
2021-12-14 02:13:14,004 iteration 2335 : loss : 0.071877, loss_ce: 0.022402
2021-12-14 02:13:15,663 iteration 2336 : loss : 0.070456, loss_ce: 0.024624
2021-12-14 02:13:17,256 iteration 2337 : loss : 0.074262, loss_ce: 0.020141
2021-12-14 02:13:18,879 iteration 2338 : loss : 0.076101, loss_ce: 0.025806
2021-12-14 02:13:20,489 iteration 2339 : loss : 0.076894, loss_ce: 0.019805
2021-12-14 02:13:22,013 iteration 2340 : loss : 0.066516, loss_ce: 0.018714
2021-12-14 02:13:23,608 iteration 2341 : loss : 0.073210, loss_ce: 0.022025
2021-12-14 02:13:25,211 iteration 2342 : loss : 0.066097, loss_ce: 0.018765
2021-12-14 02:13:26,914 iteration 2343 : loss : 0.071907, loss_ce: 0.021197
2021-12-14 02:13:28,451 iteration 2344 : loss : 0.085469, loss_ce: 0.019849
2021-12-14 02:13:29,997 iteration 2345 : loss : 0.078446, loss_ce: 0.030816
2021-12-14 02:13:31,560 iteration 2346 : loss : 0.072839, loss_ce: 0.025199
 34%|█████████▎                 | 138/400 [1:08:28<2:04:19, 28.47s/it]2021-12-14 02:13:33,274 iteration 2347 : loss : 0.085261, loss_ce: 0.032168
2021-12-14 02:13:34,878 iteration 2348 : loss : 0.072960, loss_ce: 0.023113
2021-12-14 02:13:36,436 iteration 2349 : loss : 0.066142, loss_ce: 0.018244
2021-12-14 02:13:37,999 iteration 2350 : loss : 0.091088, loss_ce: 0.022619
2021-12-14 02:13:39,652 iteration 2351 : loss : 0.081848, loss_ce: 0.027788
2021-12-14 02:13:41,204 iteration 2352 : loss : 0.063839, loss_ce: 0.023629
2021-12-14 02:13:42,752 iteration 2353 : loss : 0.066564, loss_ce: 0.022571
2021-12-14 02:13:44,287 iteration 2354 : loss : 0.061677, loss_ce: 0.020887
2021-12-14 02:13:45,832 iteration 2355 : loss : 0.070864, loss_ce: 0.019825
2021-12-14 02:13:47,467 iteration 2356 : loss : 0.073169, loss_ce: 0.022364
2021-12-14 02:13:49,063 iteration 2357 : loss : 0.089812, loss_ce: 0.022747
2021-12-14 02:13:50,653 iteration 2358 : loss : 0.077984, loss_ce: 0.025812
2021-12-14 02:13:52,205 iteration 2359 : loss : 0.087697, loss_ce: 0.025255
2021-12-14 02:13:53,736 iteration 2360 : loss : 0.079165, loss_ce: 0.019314
2021-12-14 02:13:55,307 iteration 2361 : loss : 0.073199, loss_ce: 0.020219
2021-12-14 02:13:57,005 iteration 2362 : loss : 0.076649, loss_ce: 0.024508
2021-12-14 02:13:58,595 iteration 2363 : loss : 0.068833, loss_ce: 0.023637
 35%|█████████▍                 | 139/400 [1:08:55<2:01:58, 28.04s/it]2021-12-14 02:14:00,300 iteration 2364 : loss : 0.060744, loss_ce: 0.017264
2021-12-14 02:14:01,978 iteration 2365 : loss : 0.070768, loss_ce: 0.021834
2021-12-14 02:14:03,606 iteration 2366 : loss : 0.071684, loss_ce: 0.022456
2021-12-14 02:14:05,132 iteration 2367 : loss : 0.066525, loss_ce: 0.013414
2021-12-14 02:14:06,660 iteration 2368 : loss : 0.064421, loss_ce: 0.020507
2021-12-14 02:14:08,243 iteration 2369 : loss : 0.075473, loss_ce: 0.017807
2021-12-14 02:14:09,808 iteration 2370 : loss : 0.081933, loss_ce: 0.024673
2021-12-14 02:14:11,419 iteration 2371 : loss : 0.069528, loss_ce: 0.023019
2021-12-14 02:14:12,954 iteration 2372 : loss : 0.070607, loss_ce: 0.018532
2021-12-14 02:14:14,511 iteration 2373 : loss : 0.072100, loss_ce: 0.021138
2021-12-14 02:14:16,031 iteration 2374 : loss : 0.067385, loss_ce: 0.021898
2021-12-14 02:14:17,572 iteration 2375 : loss : 0.067957, loss_ce: 0.018996
2021-12-14 02:14:19,160 iteration 2376 : loss : 0.073707, loss_ce: 0.025949
2021-12-14 02:14:20,746 iteration 2377 : loss : 0.066523, loss_ce: 0.020559
2021-12-14 02:14:22,333 iteration 2378 : loss : 0.068693, loss_ce: 0.021089
2021-12-14 02:14:23,950 iteration 2379 : loss : 0.082781, loss_ce: 0.029933
2021-12-14 02:14:23,950 Training Data Eval:
2021-12-14 02:14:32,142   Average segmentation loss on training set: 0.0582
2021-12-14 02:14:32,143 Validation Data Eval:
2021-12-14 02:14:34,941   Average segmentation loss on validation set: 0.0953
2021-12-14 02:14:41,157 Found new lowest validation loss at iteration 2379! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/TU_3seeds/REVISED_SGD_best_val_loss_seed1234.pth
2021-12-14 02:14:42,589 iteration 2380 : loss : 0.063350, loss_ce: 0.021288
 35%|█████████▍                 | 140/400 [1:09:39<2:22:14, 32.82s/it]2021-12-14 02:14:44,028 iteration 2381 : loss : 0.073828, loss_ce: 0.021843
2021-12-14 02:14:45,624 iteration 2382 : loss : 0.079809, loss_ce: 0.021725
2021-12-14 02:14:47,157 iteration 2383 : loss : 0.069352, loss_ce: 0.017641
2021-12-14 02:14:48,782 iteration 2384 : loss : 0.068301, loss_ce: 0.019087
2021-12-14 02:14:50,426 iteration 2385 : loss : 0.076454, loss_ce: 0.021221
2021-12-14 02:14:52,001 iteration 2386 : loss : 0.078432, loss_ce: 0.019677
2021-12-14 02:14:53,551 iteration 2387 : loss : 0.075494, loss_ce: 0.020485
2021-12-14 02:14:55,135 iteration 2388 : loss : 0.072508, loss_ce: 0.023092
2021-12-14 02:14:56,652 iteration 2389 : loss : 0.053822, loss_ce: 0.014140
2021-12-14 02:14:58,245 iteration 2390 : loss : 0.073292, loss_ce: 0.026181
2021-12-14 02:14:59,810 iteration 2391 : loss : 0.072658, loss_ce: 0.030610
2021-12-14 02:15:01,417 iteration 2392 : loss : 0.073895, loss_ce: 0.018401
2021-12-14 02:15:03,023 iteration 2393 : loss : 0.075095, loss_ce: 0.020623
2021-12-14 02:15:04,517 iteration 2394 : loss : 0.065080, loss_ce: 0.016886
2021-12-14 02:15:06,144 iteration 2395 : loss : 0.067634, loss_ce: 0.019749
2021-12-14 02:15:07,679 iteration 2396 : loss : 0.066249, loss_ce: 0.023250
2021-12-14 02:15:09,280 iteration 2397 : loss : 0.067952, loss_ce: 0.020238
 35%|█████████▌                 | 141/400 [1:10:06<2:13:45, 30.99s/it]2021-12-14 02:15:10,891 iteration 2398 : loss : 0.081253, loss_ce: 0.024276
2021-12-14 02:15:12,436 iteration 2399 : loss : 0.084585, loss_ce: 0.019836
2021-12-14 02:15:14,069 iteration 2400 : loss : 0.071060, loss_ce: 0.024426
2021-12-14 02:15:15,650 iteration 2401 : loss : 0.059093, loss_ce: 0.014786
2021-12-14 02:15:17,284 iteration 2402 : loss : 0.070436, loss_ce: 0.026022
2021-12-14 02:15:18,831 iteration 2403 : loss : 0.069964, loss_ce: 0.023562
2021-12-14 02:15:20,353 iteration 2404 : loss : 0.065985, loss_ce: 0.020526
2021-12-14 02:15:21,848 iteration 2405 : loss : 0.068603, loss_ce: 0.019493
2021-12-14 02:15:23,556 iteration 2406 : loss : 0.075186, loss_ce: 0.018986
2021-12-14 02:15:25,075 iteration 2407 : loss : 0.071234, loss_ce: 0.028815
2021-12-14 02:15:26,595 iteration 2408 : loss : 0.060475, loss_ce: 0.020777
2021-12-14 02:15:28,219 iteration 2409 : loss : 0.072950, loss_ce: 0.023405
2021-12-14 02:15:29,855 iteration 2410 : loss : 0.077040, loss_ce: 0.023896
2021-12-14 02:15:31,468 iteration 2411 : loss : 0.096861, loss_ce: 0.028285
2021-12-14 02:15:33,003 iteration 2412 : loss : 0.059234, loss_ce: 0.015739
2021-12-14 02:15:34,650 iteration 2413 : loss : 0.077527, loss_ce: 0.025541
2021-12-14 02:15:36,238 iteration 2414 : loss : 0.064208, loss_ce: 0.019423
 36%|█████████▌                 | 142/400 [1:10:33<2:08:02, 29.78s/it]2021-12-14 02:15:37,874 iteration 2415 : loss : 0.067783, loss_ce: 0.017883
2021-12-14 02:15:39,431 iteration 2416 : loss : 0.064344, loss_ce: 0.017279
2021-12-14 02:15:41,006 iteration 2417 : loss : 0.057985, loss_ce: 0.014509
2021-12-14 02:15:42,674 iteration 2418 : loss : 0.077889, loss_ce: 0.023054
2021-12-14 02:15:44,273 iteration 2419 : loss : 0.085537, loss_ce: 0.033836
2021-12-14 02:15:45,963 iteration 2420 : loss : 0.074462, loss_ce: 0.025790
2021-12-14 02:15:47,622 iteration 2421 : loss : 0.077158, loss_ce: 0.021640
2021-12-14 02:15:49,257 iteration 2422 : loss : 0.070856, loss_ce: 0.020846
2021-12-14 02:15:50,843 iteration 2423 : loss : 0.079551, loss_ce: 0.025444
2021-12-14 02:15:52,405 iteration 2424 : loss : 0.071080, loss_ce: 0.022855
2021-12-14 02:15:54,094 iteration 2425 : loss : 0.071153, loss_ce: 0.020052
2021-12-14 02:15:55,663 iteration 2426 : loss : 0.069437, loss_ce: 0.017985
2021-12-14 02:15:57,156 iteration 2427 : loss : 0.067665, loss_ce: 0.023026
2021-12-14 02:15:58,700 iteration 2428 : loss : 0.065696, loss_ce: 0.015017
2021-12-14 02:16:00,243 iteration 2429 : loss : 0.077382, loss_ce: 0.023910
2021-12-14 02:16:01,786 iteration 2430 : loss : 0.058162, loss_ce: 0.017172
2021-12-14 02:16:03,366 iteration 2431 : loss : 0.079683, loss_ce: 0.034258
 36%|█████████▋                 | 143/400 [1:11:00<2:04:09, 28.98s/it]2021-12-14 02:16:04,959 iteration 2432 : loss : 0.068496, loss_ce: 0.019523
2021-12-14 02:16:06,525 iteration 2433 : loss : 0.068888, loss_ce: 0.020817
2021-12-14 02:16:08,105 iteration 2434 : loss : 0.069652, loss_ce: 0.019206
2021-12-14 02:16:09,781 iteration 2435 : loss : 0.089164, loss_ce: 0.037733
2021-12-14 02:16:11,278 iteration 2436 : loss : 0.065377, loss_ce: 0.020900
2021-12-14 02:16:12,894 iteration 2437 : loss : 0.068584, loss_ce: 0.017912
2021-12-14 02:16:14,523 iteration 2438 : loss : 0.074802, loss_ce: 0.019567
2021-12-14 02:16:16,139 iteration 2439 : loss : 0.067862, loss_ce: 0.018306
2021-12-14 02:16:17,766 iteration 2440 : loss : 0.085171, loss_ce: 0.025957
2021-12-14 02:16:19,329 iteration 2441 : loss : 0.077175, loss_ce: 0.023076
2021-12-14 02:16:20,884 iteration 2442 : loss : 0.064794, loss_ce: 0.018472
2021-12-14 02:16:22,391 iteration 2443 : loss : 0.066651, loss_ce: 0.019500
2021-12-14 02:16:23,962 iteration 2444 : loss : 0.074411, loss_ce: 0.020886
2021-12-14 02:16:25,549 iteration 2445 : loss : 0.067437, loss_ce: 0.022668
2021-12-14 02:16:27,220 iteration 2446 : loss : 0.082375, loss_ce: 0.027003
2021-12-14 02:16:28,746 iteration 2447 : loss : 0.060418, loss_ce: 0.016988
2021-12-14 02:16:30,376 iteration 2448 : loss : 0.064163, loss_ce: 0.019666
 36%|█████████▋                 | 144/400 [1:11:27<2:01:08, 28.39s/it]2021-12-14 02:16:31,949 iteration 2449 : loss : 0.081359, loss_ce: 0.023411
2021-12-14 02:16:33,468 iteration 2450 : loss : 0.062063, loss_ce: 0.023100
2021-12-14 02:16:35,024 iteration 2451 : loss : 0.061189, loss_ce: 0.014244
2021-12-14 02:16:36,560 iteration 2452 : loss : 0.068892, loss_ce: 0.018109
2021-12-14 02:16:38,150 iteration 2453 : loss : 0.073377, loss_ce: 0.019585
2021-12-14 02:16:39,709 iteration 2454 : loss : 0.066759, loss_ce: 0.019250
2021-12-14 02:16:41,241 iteration 2455 : loss : 0.078800, loss_ce: 0.032108
2021-12-14 02:16:42,756 iteration 2456 : loss : 0.071240, loss_ce: 0.024595
2021-12-14 02:16:44,311 iteration 2457 : loss : 0.067906, loss_ce: 0.019919
2021-12-14 02:16:45,842 iteration 2458 : loss : 0.058776, loss_ce: 0.016425
2021-12-14 02:16:47,322 iteration 2459 : loss : 0.057857, loss_ce: 0.018378
2021-12-14 02:16:48,862 iteration 2460 : loss : 0.081638, loss_ce: 0.021785
2021-12-14 02:16:50,502 iteration 2461 : loss : 0.071975, loss_ce: 0.021557
2021-12-14 02:16:52,103 iteration 2462 : loss : 0.083206, loss_ce: 0.021909
2021-12-14 02:16:53,660 iteration 2463 : loss : 0.065948, loss_ce: 0.022484
2021-12-14 02:16:55,263 iteration 2464 : loss : 0.063861, loss_ce: 0.018577
2021-12-14 02:16:55,263 Training Data Eval:
2021-12-14 02:17:03,465   Average segmentation loss on training set: 0.0548
2021-12-14 02:17:03,465 Validation Data Eval:
2021-12-14 02:17:06,267   Average segmentation loss on validation set: 0.1026
2021-12-14 02:17:07,820 iteration 2465 : loss : 0.080493, loss_ce: 0.026260
 36%|█████████▊                 | 145/400 [1:12:04<2:12:12, 31.11s/it]2021-12-14 02:17:09,512 iteration 2466 : loss : 0.079182, loss_ce: 0.025022
2021-12-14 02:17:11,159 iteration 2467 : loss : 0.066409, loss_ce: 0.022462
2021-12-14 02:17:12,711 iteration 2468 : loss : 0.072461, loss_ce: 0.021289
2021-12-14 02:17:14,232 iteration 2469 : loss : 0.063815, loss_ce: 0.021298
2021-12-14 02:17:15,790 iteration 2470 : loss : 0.067443, loss_ce: 0.017359
2021-12-14 02:17:17,452 iteration 2471 : loss : 0.078623, loss_ce: 0.022616
2021-12-14 02:17:18,994 iteration 2472 : loss : 0.082144, loss_ce: 0.024379
2021-12-14 02:17:20,625 iteration 2473 : loss : 0.069372, loss_ce: 0.022403
2021-12-14 02:17:22,166 iteration 2474 : loss : 0.062195, loss_ce: 0.016466
2021-12-14 02:17:23,748 iteration 2475 : loss : 0.062263, loss_ce: 0.017103
2021-12-14 02:17:25,272 iteration 2476 : loss : 0.069278, loss_ce: 0.026568
2021-12-14 02:17:26,933 iteration 2477 : loss : 0.074838, loss_ce: 0.024080
2021-12-14 02:17:28,542 iteration 2478 : loss : 0.068052, loss_ce: 0.019905
2021-12-14 02:17:30,032 iteration 2479 : loss : 0.062132, loss_ce: 0.015598
2021-12-14 02:17:31,610 iteration 2480 : loss : 0.067209, loss_ce: 0.020029
2021-12-14 02:17:33,243 iteration 2481 : loss : 0.078308, loss_ce: 0.021467
2021-12-14 02:17:34,786 iteration 2482 : loss : 0.060943, loss_ce: 0.020852
 36%|█████████▊                 | 146/400 [1:12:31<2:06:25, 29.86s/it]2021-12-14 02:17:36,496 iteration 2483 : loss : 0.073127, loss_ce: 0.023625
2021-12-14 02:17:38,097 iteration 2484 : loss : 0.077419, loss_ce: 0.016137
2021-12-14 02:17:39,637 iteration 2485 : loss : 0.063732, loss_ce: 0.021808
2021-12-14 02:17:41,200 iteration 2486 : loss : 0.063077, loss_ce: 0.020797
2021-12-14 02:17:42,756 iteration 2487 : loss : 0.081311, loss_ce: 0.021543
2021-12-14 02:17:44,385 iteration 2488 : loss : 0.072276, loss_ce: 0.022553
2021-12-14 02:17:45,947 iteration 2489 : loss : 0.070043, loss_ce: 0.023751
2021-12-14 02:17:47,572 iteration 2490 : loss : 0.090005, loss_ce: 0.032437
2021-12-14 02:17:49,233 iteration 2491 : loss : 0.068144, loss_ce: 0.022102
2021-12-14 02:17:50,722 iteration 2492 : loss : 0.059681, loss_ce: 0.017011
2021-12-14 02:17:52,316 iteration 2493 : loss : 0.080235, loss_ce: 0.028544
2021-12-14 02:17:53,877 iteration 2494 : loss : 0.074373, loss_ce: 0.017693
2021-12-14 02:17:55,433 iteration 2495 : loss : 0.072520, loss_ce: 0.028625
2021-12-14 02:17:57,188 iteration 2496 : loss : 0.091068, loss_ce: 0.023235
2021-12-14 02:17:58,806 iteration 2497 : loss : 0.073311, loss_ce: 0.019836
2021-12-14 02:18:00,440 iteration 2498 : loss : 0.072172, loss_ce: 0.025000
2021-12-14 02:18:01,962 iteration 2499 : loss : 0.066854, loss_ce: 0.016376
 37%|█████████▉                 | 147/400 [1:12:58<2:02:31, 29.06s/it]2021-12-14 02:18:03,572 iteration 2500 : loss : 0.068816, loss_ce: 0.020051
2021-12-14 02:18:05,143 iteration 2501 : loss : 0.060240, loss_ce: 0.014418
2021-12-14 02:18:06,790 iteration 2502 : loss : 0.078554, loss_ce: 0.022967
2021-12-14 02:18:08,314 iteration 2503 : loss : 0.068273, loss_ce: 0.021492
2021-12-14 02:18:09,854 iteration 2504 : loss : 0.069126, loss_ce: 0.020995
2021-12-14 02:18:11,468 iteration 2505 : loss : 0.076935, loss_ce: 0.026020
2021-12-14 02:18:13,041 iteration 2506 : loss : 0.066444, loss_ce: 0.016027
2021-12-14 02:18:14,572 iteration 2507 : loss : 0.067490, loss_ce: 0.022412
2021-12-14 02:18:16,124 iteration 2508 : loss : 0.065699, loss_ce: 0.017258
2021-12-14 02:18:17,683 iteration 2509 : loss : 0.062078, loss_ce: 0.018009
2021-12-14 02:18:19,227 iteration 2510 : loss : 0.068702, loss_ce: 0.024229
2021-12-14 02:18:20,816 iteration 2511 : loss : 0.067659, loss_ce: 0.022976
2021-12-14 02:18:22,411 iteration 2512 : loss : 0.068124, loss_ce: 0.017349
2021-12-14 02:18:24,038 iteration 2513 : loss : 0.072383, loss_ce: 0.017751
2021-12-14 02:18:25,621 iteration 2514 : loss : 0.070205, loss_ce: 0.019309
2021-12-14 02:18:27,185 iteration 2515 : loss : 0.061493, loss_ce: 0.024429
2021-12-14 02:18:28,735 iteration 2516 : loss : 0.060628, loss_ce: 0.021362
 37%|█████████▉                 | 148/400 [1:13:25<1:59:10, 28.37s/it]2021-12-14 02:18:30,339 iteration 2517 : loss : 0.063026, loss_ce: 0.019704
2021-12-14 02:18:31,913 iteration 2518 : loss : 0.081904, loss_ce: 0.021308
2021-12-14 02:18:33,511 iteration 2519 : loss : 0.071349, loss_ce: 0.023557
2021-12-14 02:18:35,080 iteration 2520 : loss : 0.072340, loss_ce: 0.024077
2021-12-14 02:18:36,637 iteration 2521 : loss : 0.078253, loss_ce: 0.024995
2021-12-14 02:18:38,218 iteration 2522 : loss : 0.064327, loss_ce: 0.023914
2021-12-14 02:18:39,842 iteration 2523 : loss : 0.063948, loss_ce: 0.013575
2021-12-14 02:18:41,401 iteration 2524 : loss : 0.071163, loss_ce: 0.023661
2021-12-14 02:18:42,985 iteration 2525 : loss : 0.065818, loss_ce: 0.020342
2021-12-14 02:18:44,587 iteration 2526 : loss : 0.070422, loss_ce: 0.020264
2021-12-14 02:18:46,166 iteration 2527 : loss : 0.062993, loss_ce: 0.018313
2021-12-14 02:18:47,768 iteration 2528 : loss : 0.064612, loss_ce: 0.017344
2021-12-14 02:18:49,358 iteration 2529 : loss : 0.083818, loss_ce: 0.027016
2021-12-14 02:18:50,954 iteration 2530 : loss : 0.072965, loss_ce: 0.028158
2021-12-14 02:18:52,611 iteration 2531 : loss : 0.065754, loss_ce: 0.019001
2021-12-14 02:18:54,184 iteration 2532 : loss : 0.082788, loss_ce: 0.022221
2021-12-14 02:18:55,772 iteration 2533 : loss : 0.069576, loss_ce: 0.017072
 37%|██████████                 | 149/400 [1:13:52<1:57:00, 27.97s/it]2021-12-14 02:18:57,337 iteration 2534 : loss : 0.067047, loss_ce: 0.022563
2021-12-14 02:18:58,980 iteration 2535 : loss : 0.083574, loss_ce: 0.024617
2021-12-14 02:19:00,521 iteration 2536 : loss : 0.066428, loss_ce: 0.024880
2021-12-14 02:19:02,068 iteration 2537 : loss : 0.062387, loss_ce: 0.018544
2021-12-14 02:19:03,545 iteration 2538 : loss : 0.056075, loss_ce: 0.017500
2021-12-14 02:19:05,135 iteration 2539 : loss : 0.068472, loss_ce: 0.020744
2021-12-14 02:19:06,660 iteration 2540 : loss : 0.062341, loss_ce: 0.016716
2021-12-14 02:19:08,208 iteration 2541 : loss : 0.063093, loss_ce: 0.020921
2021-12-14 02:19:09,717 iteration 2542 : loss : 0.053638, loss_ce: 0.013321
2021-12-14 02:19:11,232 iteration 2543 : loss : 0.064021, loss_ce: 0.016539
2021-12-14 02:19:12,801 iteration 2544 : loss : 0.073751, loss_ce: 0.021918
2021-12-14 02:19:14,483 iteration 2545 : loss : 0.069820, loss_ce: 0.024324
2021-12-14 02:19:16,177 iteration 2546 : loss : 0.075144, loss_ce: 0.026467
2021-12-14 02:19:17,694 iteration 2547 : loss : 0.059750, loss_ce: 0.020486
2021-12-14 02:19:19,300 iteration 2548 : loss : 0.065369, loss_ce: 0.021759
2021-12-14 02:19:20,888 iteration 2549 : loss : 0.074063, loss_ce: 0.016116
2021-12-14 02:19:20,888 Training Data Eval:
2021-12-14 02:19:29,062   Average segmentation loss on training set: 0.0547
2021-12-14 02:19:29,063 Validation Data Eval:
2021-12-14 02:19:31,855   Average segmentation loss on validation set: 0.0985
2021-12-14 02:19:33,399 iteration 2550 : loss : 0.066461, loss_ce: 0.017637
 38%|██████████▏                | 150/400 [1:14:30<2:08:37, 30.87s/it]2021-12-14 02:19:35,011 iteration 2551 : loss : 0.061775, loss_ce: 0.023956
2021-12-14 02:19:36,644 iteration 2552 : loss : 0.061296, loss_ce: 0.019825
2021-12-14 02:19:38,149 iteration 2553 : loss : 0.056441, loss_ce: 0.014470
2021-12-14 02:19:39,722 iteration 2554 : loss : 0.068037, loss_ce: 0.019417
2021-12-14 02:19:41,277 iteration 2555 : loss : 0.076847, loss_ce: 0.017398
2021-12-14 02:19:42,898 iteration 2556 : loss : 0.070241, loss_ce: 0.023872
2021-12-14 02:19:44,457 iteration 2557 : loss : 0.065442, loss_ce: 0.024003
2021-12-14 02:19:46,038 iteration 2558 : loss : 0.068888, loss_ce: 0.024484
2021-12-14 02:19:47,709 iteration 2559 : loss : 0.070597, loss_ce: 0.022002
2021-12-14 02:19:49,280 iteration 2560 : loss : 0.063948, loss_ce: 0.023679
2021-12-14 02:19:50,946 iteration 2561 : loss : 0.066544, loss_ce: 0.017901
2021-12-14 02:19:52,545 iteration 2562 : loss : 0.069732, loss_ce: 0.020813
2021-12-14 02:19:54,157 iteration 2563 : loss : 0.071713, loss_ce: 0.025055
2021-12-14 02:19:55,695 iteration 2564 : loss : 0.069403, loss_ce: 0.021064
2021-12-14 02:19:57,233 iteration 2565 : loss : 0.064808, loss_ce: 0.017958
2021-12-14 02:19:58,790 iteration 2566 : loss : 0.070210, loss_ce: 0.020367
2021-12-14 02:20:00,376 iteration 2567 : loss : 0.078365, loss_ce: 0.016530
 38%|██████████▏                | 151/400 [1:14:57<2:03:15, 29.70s/it]2021-12-14 02:20:02,034 iteration 2568 : loss : 0.067497, loss_ce: 0.023976
2021-12-14 02:20:03,585 iteration 2569 : loss : 0.068989, loss_ce: 0.024432
2021-12-14 02:20:05,142 iteration 2570 : loss : 0.085932, loss_ce: 0.027963
2021-12-14 02:20:06,703 iteration 2571 : loss : 0.056326, loss_ce: 0.016107
2021-12-14 02:20:08,217 iteration 2572 : loss : 0.065822, loss_ce: 0.017718
2021-12-14 02:20:09,738 iteration 2573 : loss : 0.075899, loss_ce: 0.030407
2021-12-14 02:20:11,290 iteration 2574 : loss : 0.079184, loss_ce: 0.024215
2021-12-14 02:20:12,972 iteration 2575 : loss : 0.088854, loss_ce: 0.026138
2021-12-14 02:20:14,562 iteration 2576 : loss : 0.064119, loss_ce: 0.019012
2021-12-14 02:20:16,143 iteration 2577 : loss : 0.088438, loss_ce: 0.027307
2021-12-14 02:20:17,731 iteration 2578 : loss : 0.083105, loss_ce: 0.023736
2021-12-14 02:20:19,248 iteration 2579 : loss : 0.057905, loss_ce: 0.012008
2021-12-14 02:20:20,877 iteration 2580 : loss : 0.070831, loss_ce: 0.014828
2021-12-14 02:20:22,500 iteration 2581 : loss : 0.067258, loss_ce: 0.021575
2021-12-14 02:20:24,158 iteration 2582 : loss : 0.073400, loss_ce: 0.021387
2021-12-14 02:20:25,724 iteration 2583 : loss : 0.058046, loss_ce: 0.016591
2021-12-14 02:20:27,211 iteration 2584 : loss : 0.059250, loss_ce: 0.019856
 38%|██████████▎                | 152/400 [1:15:24<1:59:13, 28.84s/it]2021-12-14 02:20:28,843 iteration 2585 : loss : 0.072371, loss_ce: 0.019660
2021-12-14 02:20:30,433 iteration 2586 : loss : 0.079539, loss_ce: 0.022370
2021-12-14 02:20:31,949 iteration 2587 : loss : 0.069420, loss_ce: 0.020222
2021-12-14 02:20:33,501 iteration 2588 : loss : 0.065187, loss_ce: 0.023812
2021-12-14 02:20:35,117 iteration 2589 : loss : 0.062692, loss_ce: 0.017049
2021-12-14 02:20:36,741 iteration 2590 : loss : 0.065258, loss_ce: 0.021293
2021-12-14 02:20:38,279 iteration 2591 : loss : 0.061372, loss_ce: 0.015972
2021-12-14 02:20:39,819 iteration 2592 : loss : 0.063788, loss_ce: 0.017984
2021-12-14 02:20:41,367 iteration 2593 : loss : 0.066731, loss_ce: 0.023761
2021-12-14 02:20:43,061 iteration 2594 : loss : 0.070973, loss_ce: 0.023014
2021-12-14 02:20:44,671 iteration 2595 : loss : 0.070429, loss_ce: 0.020291
2021-12-14 02:20:46,207 iteration 2596 : loss : 0.061921, loss_ce: 0.021746
2021-12-14 02:20:47,725 iteration 2597 : loss : 0.062687, loss_ce: 0.017469
2021-12-14 02:20:49,273 iteration 2598 : loss : 0.061781, loss_ce: 0.019709
2021-12-14 02:20:50,830 iteration 2599 : loss : 0.063306, loss_ce: 0.012069
2021-12-14 02:20:52,390 iteration 2600 : loss : 0.065579, loss_ce: 0.016524
2021-12-14 02:20:53,907 iteration 2601 : loss : 0.070143, loss_ce: 0.023479
 38%|██████████▎                | 153/400 [1:15:50<1:56:05, 28.20s/it]2021-12-14 02:20:55,560 iteration 2602 : loss : 0.058901, loss_ce: 0.018329
2021-12-14 02:20:57,064 iteration 2603 : loss : 0.061798, loss_ce: 0.017703
2021-12-14 02:20:58,617 iteration 2604 : loss : 0.056964, loss_ce: 0.013557
2021-12-14 02:21:00,306 iteration 2605 : loss : 0.065494, loss_ce: 0.018010
2021-12-14 02:21:01,881 iteration 2606 : loss : 0.065877, loss_ce: 0.022937
2021-12-14 02:21:03,467 iteration 2607 : loss : 0.073140, loss_ce: 0.022952
2021-12-14 02:21:04,991 iteration 2608 : loss : 0.063890, loss_ce: 0.021521
2021-12-14 02:21:06,526 iteration 2609 : loss : 0.064819, loss_ce: 0.016785
2021-12-14 02:21:08,212 iteration 2610 : loss : 0.069871, loss_ce: 0.024515
2021-12-14 02:21:09,763 iteration 2611 : loss : 0.065683, loss_ce: 0.017456
2021-12-14 02:21:11,245 iteration 2612 : loss : 0.059359, loss_ce: 0.022829
2021-12-14 02:21:12,787 iteration 2613 : loss : 0.060760, loss_ce: 0.015671
2021-12-14 02:21:14,416 iteration 2614 : loss : 0.087694, loss_ce: 0.024118
2021-12-14 02:21:15,958 iteration 2615 : loss : 0.063760, loss_ce: 0.020202
2021-12-14 02:21:17,506 iteration 2616 : loss : 0.066015, loss_ce: 0.018445
2021-12-14 02:21:19,157 iteration 2617 : loss : 0.074621, loss_ce: 0.016370
2021-12-14 02:21:20,744 iteration 2618 : loss : 0.079663, loss_ce: 0.032975
 38%|██████████▍                | 154/400 [1:16:17<1:53:56, 27.79s/it]2021-12-14 02:21:22,424 iteration 2619 : loss : 0.073368, loss_ce: 0.017913
2021-12-14 02:21:23,969 iteration 2620 : loss : 0.071941, loss_ce: 0.023633
2021-12-14 02:21:25,563 iteration 2621 : loss : 0.060855, loss_ce: 0.018039
2021-12-14 02:21:27,161 iteration 2622 : loss : 0.068753, loss_ce: 0.025872
2021-12-14 02:21:28,773 iteration 2623 : loss : 0.089993, loss_ce: 0.034673
2021-12-14 02:21:30,305 iteration 2624 : loss : 0.067442, loss_ce: 0.017055
2021-12-14 02:21:31,861 iteration 2625 : loss : 0.060743, loss_ce: 0.019981
2021-12-14 02:21:33,493 iteration 2626 : loss : 0.062374, loss_ce: 0.022841
2021-12-14 02:21:35,099 iteration 2627 : loss : 0.068794, loss_ce: 0.016974
2021-12-14 02:21:36,634 iteration 2628 : loss : 0.070835, loss_ce: 0.022379
2021-12-14 02:21:38,273 iteration 2629 : loss : 0.078670, loss_ce: 0.021098
2021-12-14 02:21:39,790 iteration 2630 : loss : 0.057815, loss_ce: 0.015519
2021-12-14 02:21:41,383 iteration 2631 : loss : 0.066695, loss_ce: 0.025252
2021-12-14 02:21:42,981 iteration 2632 : loss : 0.063553, loss_ce: 0.018969
2021-12-14 02:21:44,520 iteration 2633 : loss : 0.061319, loss_ce: 0.021564
2021-12-14 02:21:46,108 iteration 2634 : loss : 0.060307, loss_ce: 0.017323
2021-12-14 02:21:46,109 Training Data Eval:
2021-12-14 02:21:54,292   Average segmentation loss on training set: 0.0534
2021-12-14 02:21:54,293 Validation Data Eval:
2021-12-14 02:21:57,090   Average segmentation loss on validation set: 0.1016
2021-12-14 02:21:58,732 iteration 2635 : loss : 0.073838, loss_ce: 0.026350
 39%|██████████▍                | 155/400 [1:16:55<2:05:56, 30.84s/it]2021-12-14 02:22:00,304 iteration 2636 : loss : 0.056744, loss_ce: 0.014411
2021-12-14 02:22:02,014 iteration 2637 : loss : 0.068284, loss_ce: 0.019206
2021-12-14 02:22:03,605 iteration 2638 : loss : 0.063740, loss_ce: 0.016775
2021-12-14 02:22:05,074 iteration 2639 : loss : 0.055688, loss_ce: 0.016374
2021-12-14 02:22:06,602 iteration 2640 : loss : 0.066781, loss_ce: 0.022089
2021-12-14 02:22:08,256 iteration 2641 : loss : 0.070248, loss_ce: 0.024623
2021-12-14 02:22:09,881 iteration 2642 : loss : 0.065790, loss_ce: 0.016160
2021-12-14 02:22:11,523 iteration 2643 : loss : 0.059633, loss_ce: 0.014819
2021-12-14 02:22:13,063 iteration 2644 : loss : 0.070863, loss_ce: 0.019108
2021-12-14 02:22:14,605 iteration 2645 : loss : 0.068423, loss_ce: 0.028303
2021-12-14 02:22:16,156 iteration 2646 : loss : 0.071355, loss_ce: 0.018667
2021-12-14 02:22:17,774 iteration 2647 : loss : 0.076771, loss_ce: 0.027132
2021-12-14 02:22:19,268 iteration 2648 : loss : 0.056130, loss_ce: 0.019299
2021-12-14 02:22:20,872 iteration 2649 : loss : 0.070942, loss_ce: 0.025932
2021-12-14 02:22:22,474 iteration 2650 : loss : 0.069670, loss_ce: 0.025710
2021-12-14 02:22:24,020 iteration 2651 : loss : 0.068123, loss_ce: 0.019014
2021-12-14 02:22:25,592 iteration 2652 : loss : 0.064373, loss_ce: 0.023017
 39%|██████████▌                | 156/400 [1:17:22<2:00:34, 29.65s/it]2021-12-14 02:22:27,298 iteration 2653 : loss : 0.071653, loss_ce: 0.019370
2021-12-14 02:22:28,873 iteration 2654 : loss : 0.065371, loss_ce: 0.022201
2021-12-14 02:22:30,388 iteration 2655 : loss : 0.057976, loss_ce: 0.016173
2021-12-14 02:22:31,885 iteration 2656 : loss : 0.058986, loss_ce: 0.020339
2021-12-14 02:22:33,401 iteration 2657 : loss : 0.056705, loss_ce: 0.016072
2021-12-14 02:22:34,936 iteration 2658 : loss : 0.063251, loss_ce: 0.019757
2021-12-14 02:22:36,617 iteration 2659 : loss : 0.071064, loss_ce: 0.024693
2021-12-14 02:22:38,183 iteration 2660 : loss : 0.060788, loss_ce: 0.017030
2021-12-14 02:22:39,672 iteration 2661 : loss : 0.064591, loss_ce: 0.020225
2021-12-14 02:22:41,287 iteration 2662 : loss : 0.068439, loss_ce: 0.022480
2021-12-14 02:22:42,808 iteration 2663 : loss : 0.064572, loss_ce: 0.019783
2021-12-14 02:22:44,432 iteration 2664 : loss : 0.063833, loss_ce: 0.015270
2021-12-14 02:22:45,986 iteration 2665 : loss : 0.062169, loss_ce: 0.018453
2021-12-14 02:22:47,568 iteration 2666 : loss : 0.061972, loss_ce: 0.016520
2021-12-14 02:22:49,172 iteration 2667 : loss : 0.059885, loss_ce: 0.018957
2021-12-14 02:22:50,775 iteration 2668 : loss : 0.074450, loss_ce: 0.023071
2021-12-14 02:22:52,399 iteration 2669 : loss : 0.064303, loss_ce: 0.019213
 39%|██████████▌                | 157/400 [1:17:49<1:56:37, 28.80s/it]2021-12-14 02:22:54,037 iteration 2670 : loss : 0.109395, loss_ce: 0.028486
2021-12-14 02:22:55,624 iteration 2671 : loss : 0.074492, loss_ce: 0.016665
2021-12-14 02:22:57,226 iteration 2672 : loss : 0.056472, loss_ce: 0.015959
2021-12-14 02:22:58,851 iteration 2673 : loss : 0.092307, loss_ce: 0.034790
2021-12-14 02:23:00,387 iteration 2674 : loss : 0.063662, loss_ce: 0.022672
2021-12-14 02:23:02,012 iteration 2675 : loss : 0.073589, loss_ce: 0.022904
2021-12-14 02:23:03,601 iteration 2676 : loss : 0.063972, loss_ce: 0.015313
2021-12-14 02:23:05,116 iteration 2677 : loss : 0.061324, loss_ce: 0.020532
2021-12-14 02:23:06,613 iteration 2678 : loss : 0.060809, loss_ce: 0.016020
2021-12-14 02:23:08,202 iteration 2679 : loss : 0.066908, loss_ce: 0.023296
2021-12-14 02:23:09,833 iteration 2680 : loss : 0.076810, loss_ce: 0.026965
2021-12-14 02:23:11,399 iteration 2681 : loss : 0.063280, loss_ce: 0.022431
2021-12-14 02:23:12,916 iteration 2682 : loss : 0.064760, loss_ce: 0.019982
2021-12-14 02:23:14,497 iteration 2683 : loss : 0.069075, loss_ce: 0.023489
2021-12-14 02:23:16,070 iteration 2684 : loss : 0.067096, loss_ce: 0.014505
2021-12-14 02:23:17,648 iteration 2685 : loss : 0.066286, loss_ce: 0.024931
2021-12-14 02:23:19,215 iteration 2686 : loss : 0.066968, loss_ce: 0.022749
 40%|██████████▋                | 158/400 [1:18:16<1:53:46, 28.21s/it]2021-12-14 02:23:20,825 iteration 2687 : loss : 0.054101, loss_ce: 0.018235
2021-12-14 02:23:22,382 iteration 2688 : loss : 0.071588, loss_ce: 0.022035
2021-12-14 02:23:23,848 iteration 2689 : loss : 0.060879, loss_ce: 0.019033
2021-12-14 02:23:25,402 iteration 2690 : loss : 0.064027, loss_ce: 0.019292
2021-12-14 02:23:26,989 iteration 2691 : loss : 0.058273, loss_ce: 0.015278
2021-12-14 02:23:28,554 iteration 2692 : loss : 0.066253, loss_ce: 0.017457
2021-12-14 02:23:30,088 iteration 2693 : loss : 0.069924, loss_ce: 0.023639
2021-12-14 02:23:31,571 iteration 2694 : loss : 0.062029, loss_ce: 0.018174
2021-12-14 02:23:33,188 iteration 2695 : loss : 0.065117, loss_ce: 0.020536
2021-12-14 02:23:34,866 iteration 2696 : loss : 0.071457, loss_ce: 0.023506
2021-12-14 02:23:36,499 iteration 2697 : loss : 0.070390, loss_ce: 0.028630
2021-12-14 02:23:38,019 iteration 2698 : loss : 0.054236, loss_ce: 0.016445
2021-12-14 02:23:39,552 iteration 2699 : loss : 0.064155, loss_ce: 0.018579
2021-12-14 02:23:41,084 iteration 2700 : loss : 0.075160, loss_ce: 0.019999
2021-12-14 02:23:42,662 iteration 2701 : loss : 0.073053, loss_ce: 0.024671
2021-12-14 02:23:44,262 iteration 2702 : loss : 0.070706, loss_ce: 0.014634
2021-12-14 02:23:45,871 iteration 2703 : loss : 0.070113, loss_ce: 0.019296
 40%|██████████▋                | 159/400 [1:18:42<1:51:25, 27.74s/it]2021-12-14 02:23:47,441 iteration 2704 : loss : 0.062940, loss_ce: 0.017307
2021-12-14 02:23:48,958 iteration 2705 : loss : 0.062830, loss_ce: 0.017229
2021-12-14 02:23:50,554 iteration 2706 : loss : 0.079167, loss_ce: 0.033619
2021-12-14 02:23:52,115 iteration 2707 : loss : 0.059320, loss_ce: 0.016712
2021-12-14 02:23:53,662 iteration 2708 : loss : 0.071841, loss_ce: 0.019914
2021-12-14 02:23:55,296 iteration 2709 : loss : 0.069618, loss_ce: 0.018823
2021-12-14 02:23:56,915 iteration 2710 : loss : 0.089263, loss_ce: 0.033089
2021-12-14 02:23:58,460 iteration 2711 : loss : 0.066216, loss_ce: 0.020124
2021-12-14 02:24:00,018 iteration 2712 : loss : 0.074895, loss_ce: 0.021883
2021-12-14 02:24:01,598 iteration 2713 : loss : 0.058555, loss_ce: 0.016172
2021-12-14 02:24:03,179 iteration 2714 : loss : 0.071301, loss_ce: 0.023932
2021-12-14 02:24:04,738 iteration 2715 : loss : 0.083261, loss_ce: 0.034872
2021-12-14 02:24:06,291 iteration 2716 : loss : 0.060338, loss_ce: 0.012814
2021-12-14 02:24:07,801 iteration 2717 : loss : 0.057793, loss_ce: 0.016885
2021-12-14 02:24:09,395 iteration 2718 : loss : 0.068740, loss_ce: 0.021556
2021-12-14 02:24:10,933 iteration 2719 : loss : 0.056655, loss_ce: 0.017233
2021-12-14 02:24:10,933 Training Data Eval:
2021-12-14 02:24:19,109   Average segmentation loss on training set: 0.0554
2021-12-14 02:24:19,109 Validation Data Eval:
2021-12-14 02:24:21,903   Average segmentation loss on validation set: 0.0961
2021-12-14 02:24:23,452 iteration 2720 : loss : 0.064284, loss_ce: 0.022695
 40%|██████████▊                | 160/400 [1:19:20<2:02:45, 30.69s/it]2021-12-14 02:24:25,079 iteration 2721 : loss : 0.060196, loss_ce: 0.016944
2021-12-14 02:24:26,671 iteration 2722 : loss : 0.062445, loss_ce: 0.021498
2021-12-14 02:24:28,312 iteration 2723 : loss : 0.069429, loss_ce: 0.024920
2021-12-14 02:24:29,828 iteration 2724 : loss : 0.068139, loss_ce: 0.020396
2021-12-14 02:24:31,379 iteration 2725 : loss : 0.067112, loss_ce: 0.016551
2021-12-14 02:24:33,012 iteration 2726 : loss : 0.057907, loss_ce: 0.017336
2021-12-14 02:24:34,576 iteration 2727 : loss : 0.069501, loss_ce: 0.020921
2021-12-14 02:24:36,188 iteration 2728 : loss : 0.069516, loss_ce: 0.021959
2021-12-14 02:24:37,789 iteration 2729 : loss : 0.067104, loss_ce: 0.023160
2021-12-14 02:24:39,426 iteration 2730 : loss : 0.073649, loss_ce: 0.022539
2021-12-14 02:24:40,985 iteration 2731 : loss : 0.065893, loss_ce: 0.019763
2021-12-14 02:24:42,465 iteration 2732 : loss : 0.060886, loss_ce: 0.018657
2021-12-14 02:24:44,023 iteration 2733 : loss : 0.058389, loss_ce: 0.020470
2021-12-14 02:24:45,601 iteration 2734 : loss : 0.083458, loss_ce: 0.017475
2021-12-14 02:24:47,175 iteration 2735 : loss : 0.064560, loss_ce: 0.025722
2021-12-14 02:24:48,725 iteration 2736 : loss : 0.060433, loss_ce: 0.015541
2021-12-14 02:24:50,274 iteration 2737 : loss : 0.071158, loss_ce: 0.015719
 40%|██████████▊                | 161/400 [1:19:47<1:57:37, 29.53s/it]2021-12-14 02:24:51,946 iteration 2738 : loss : 0.076689, loss_ce: 0.029079
2021-12-14 02:24:53,464 iteration 2739 : loss : 0.062305, loss_ce: 0.014893
2021-12-14 02:24:55,111 iteration 2740 : loss : 0.071787, loss_ce: 0.021355
2021-12-14 02:24:56,677 iteration 2741 : loss : 0.062788, loss_ce: 0.021984
2021-12-14 02:24:58,259 iteration 2742 : loss : 0.067821, loss_ce: 0.022701
2021-12-14 02:24:59,770 iteration 2743 : loss : 0.061242, loss_ce: 0.019394
2021-12-14 02:25:01,330 iteration 2744 : loss : 0.054026, loss_ce: 0.014858
2021-12-14 02:25:02,856 iteration 2745 : loss : 0.060383, loss_ce: 0.018124
2021-12-14 02:25:04,521 iteration 2746 : loss : 0.102932, loss_ce: 0.023860
2021-12-14 02:25:06,058 iteration 2747 : loss : 0.059370, loss_ce: 0.017695
2021-12-14 02:25:07,667 iteration 2748 : loss : 0.074293, loss_ce: 0.018569
2021-12-14 02:25:09,332 iteration 2749 : loss : 0.070752, loss_ce: 0.020135
2021-12-14 02:25:10,888 iteration 2750 : loss : 0.075283, loss_ce: 0.025888
2021-12-14 02:25:12,458 iteration 2751 : loss : 0.072510, loss_ce: 0.018169
2021-12-14 02:25:14,124 iteration 2752 : loss : 0.065261, loss_ce: 0.019046
2021-12-14 02:25:15,801 iteration 2753 : loss : 0.069980, loss_ce: 0.024480
2021-12-14 02:25:17,391 iteration 2754 : loss : 0.061200, loss_ce: 0.025137
 40%|██████████▉                | 162/400 [1:20:14<1:54:15, 28.81s/it]2021-12-14 02:25:18,900 iteration 2755 : loss : 0.052939, loss_ce: 0.012991
2021-12-14 02:25:20,478 iteration 2756 : loss : 0.066783, loss_ce: 0.022219
2021-12-14 02:25:22,049 iteration 2757 : loss : 0.054125, loss_ce: 0.016981
2021-12-14 02:25:23,615 iteration 2758 : loss : 0.060496, loss_ce: 0.017980
2021-12-14 02:25:25,183 iteration 2759 : loss : 0.063037, loss_ce: 0.018327
2021-12-14 02:25:26,753 iteration 2760 : loss : 0.067970, loss_ce: 0.022099
2021-12-14 02:25:28,362 iteration 2761 : loss : 0.063214, loss_ce: 0.019207
2021-12-14 02:25:29,926 iteration 2762 : loss : 0.063954, loss_ce: 0.020547
2021-12-14 02:25:31,520 iteration 2763 : loss : 0.072691, loss_ce: 0.019413
2021-12-14 02:25:33,033 iteration 2764 : loss : 0.057887, loss_ce: 0.018601
2021-12-14 02:25:34,700 iteration 2765 : loss : 0.058413, loss_ce: 0.014906
2021-12-14 02:25:36,197 iteration 2766 : loss : 0.056517, loss_ce: 0.015856
2021-12-14 02:25:37,774 iteration 2767 : loss : 0.067793, loss_ce: 0.023774
2021-12-14 02:25:39,317 iteration 2768 : loss : 0.069668, loss_ce: 0.016580
2021-12-14 02:25:40,815 iteration 2769 : loss : 0.057156, loss_ce: 0.020301
2021-12-14 02:25:42,346 iteration 2770 : loss : 0.070492, loss_ce: 0.024877
2021-12-14 02:25:43,904 iteration 2771 : loss : 0.057504, loss_ce: 0.018376
 41%|███████████                | 163/400 [1:20:40<1:51:04, 28.12s/it]2021-12-14 02:25:45,459 iteration 2772 : loss : 0.065787, loss_ce: 0.017102
2021-12-14 02:25:47,035 iteration 2773 : loss : 0.057380, loss_ce: 0.018294
2021-12-14 02:25:48,608 iteration 2774 : loss : 0.071349, loss_ce: 0.014634
2021-12-14 02:25:50,190 iteration 2775 : loss : 0.068246, loss_ce: 0.023859
2021-12-14 02:25:51,744 iteration 2776 : loss : 0.059396, loss_ce: 0.018693
2021-12-14 02:25:53,369 iteration 2777 : loss : 0.054435, loss_ce: 0.016221
2021-12-14 02:25:54,896 iteration 2778 : loss : 0.056404, loss_ce: 0.015268
2021-12-14 02:25:56,432 iteration 2779 : loss : 0.057954, loss_ce: 0.019278
2021-12-14 02:25:57,985 iteration 2780 : loss : 0.061871, loss_ce: 0.022525
2021-12-14 02:25:59,664 iteration 2781 : loss : 0.068707, loss_ce: 0.021521
2021-12-14 02:26:01,306 iteration 2782 : loss : 0.061676, loss_ce: 0.020098
2021-12-14 02:26:02,863 iteration 2783 : loss : 0.061954, loss_ce: 0.015779
2021-12-14 02:26:04,331 iteration 2784 : loss : 0.071139, loss_ce: 0.017664
2021-12-14 02:26:05,848 iteration 2785 : loss : 0.062626, loss_ce: 0.022398
2021-12-14 02:26:07,357 iteration 2786 : loss : 0.056724, loss_ce: 0.017388
2021-12-14 02:26:08,889 iteration 2787 : loss : 0.056874, loss_ce: 0.016757
2021-12-14 02:26:10,580 iteration 2788 : loss : 0.062858, loss_ce: 0.020855
 41%|███████████                | 164/400 [1:21:07<1:48:54, 27.69s/it]2021-12-14 02:26:12,224 iteration 2789 : loss : 0.058319, loss_ce: 0.014774
2021-12-14 02:26:13,881 iteration 2790 : loss : 0.072680, loss_ce: 0.023404
2021-12-14 02:26:15,397 iteration 2791 : loss : 0.059271, loss_ce: 0.015480
2021-12-14 02:26:16,950 iteration 2792 : loss : 0.062778, loss_ce: 0.020672
2021-12-14 02:26:18,513 iteration 2793 : loss : 0.059697, loss_ce: 0.016427
2021-12-14 02:26:20,137 iteration 2794 : loss : 0.069819, loss_ce: 0.026764
2021-12-14 02:26:21,698 iteration 2795 : loss : 0.067410, loss_ce: 0.020994
2021-12-14 02:26:23,238 iteration 2796 : loss : 0.069114, loss_ce: 0.020687
2021-12-14 02:26:24,848 iteration 2797 : loss : 0.063466, loss_ce: 0.022571
2021-12-14 02:26:26,437 iteration 2798 : loss : 0.065027, loss_ce: 0.017179
2021-12-14 02:26:28,091 iteration 2799 : loss : 0.069719, loss_ce: 0.021438
2021-12-14 02:26:29,679 iteration 2800 : loss : 0.060781, loss_ce: 0.022878
2021-12-14 02:26:31,165 iteration 2801 : loss : 0.100690, loss_ce: 0.019019
2021-12-14 02:26:32,690 iteration 2802 : loss : 0.052983, loss_ce: 0.013185
2021-12-14 02:26:34,273 iteration 2803 : loss : 0.068432, loss_ce: 0.020502
2021-12-14 02:26:35,758 iteration 2804 : loss : 0.070227, loss_ce: 0.023775
2021-12-14 02:26:35,759 Training Data Eval:
2021-12-14 02:26:43,948   Average segmentation loss on training set: 0.0521
2021-12-14 02:26:43,949 Validation Data Eval:
2021-12-14 02:26:46,739   Average segmentation loss on validation set: 0.1009
2021-12-14 02:26:48,401 iteration 2805 : loss : 0.070503, loss_ce: 0.021755
 41%|███████████▏               | 165/400 [1:21:45<2:00:21, 30.73s/it]2021-12-14 02:26:50,102 iteration 2806 : loss : 0.073559, loss_ce: 0.027104
2021-12-14 02:26:51,753 iteration 2807 : loss : 0.082146, loss_ce: 0.019293
2021-12-14 02:26:53,372 iteration 2808 : loss : 0.060744, loss_ce: 0.015705
2021-12-14 02:26:54,970 iteration 2809 : loss : 0.063582, loss_ce: 0.020206
2021-12-14 02:26:56,479 iteration 2810 : loss : 0.066422, loss_ce: 0.020243
2021-12-14 02:26:58,098 iteration 2811 : loss : 0.061361, loss_ce: 0.022257
2021-12-14 02:26:59,602 iteration 2812 : loss : 0.050769, loss_ce: 0.015537
2021-12-14 02:27:01,234 iteration 2813 : loss : 0.072713, loss_ce: 0.025168
2021-12-14 02:27:02,822 iteration 2814 : loss : 0.064384, loss_ce: 0.019759
2021-12-14 02:27:04,391 iteration 2815 : loss : 0.062578, loss_ce: 0.020583
2021-12-14 02:27:05,965 iteration 2816 : loss : 0.066840, loss_ce: 0.019412
2021-12-14 02:27:07,614 iteration 2817 : loss : 0.074227, loss_ce: 0.013701
2021-12-14 02:27:09,245 iteration 2818 : loss : 0.071296, loss_ce: 0.025032
2021-12-14 02:27:10,796 iteration 2819 : loss : 0.077152, loss_ce: 0.029122
2021-12-14 02:27:12,470 iteration 2820 : loss : 0.074396, loss_ce: 0.020861
2021-12-14 02:27:14,119 iteration 2821 : loss : 0.078616, loss_ce: 0.025289
2021-12-14 02:27:15,734 iteration 2822 : loss : 0.064200, loss_ce: 0.016952
 42%|███████████▏               | 166/400 [1:22:12<1:55:51, 29.71s/it]2021-12-14 02:27:17,471 iteration 2823 : loss : 0.071601, loss_ce: 0.026938
2021-12-14 02:27:19,017 iteration 2824 : loss : 0.055312, loss_ce: 0.018674
2021-12-14 02:27:20,607 iteration 2825 : loss : 0.065037, loss_ce: 0.022583
2021-12-14 02:27:22,282 iteration 2826 : loss : 0.064653, loss_ce: 0.020558
2021-12-14 02:27:23,979 iteration 2827 : loss : 0.068604, loss_ce: 0.018711
2021-12-14 02:27:25,584 iteration 2828 : loss : 0.077169, loss_ce: 0.022853
2021-12-14 02:27:27,160 iteration 2829 : loss : 0.068097, loss_ce: 0.025995
2021-12-14 02:27:28,723 iteration 2830 : loss : 0.074966, loss_ce: 0.023538
2021-12-14 02:27:30,204 iteration 2831 : loss : 0.053522, loss_ce: 0.017971
2021-12-14 02:27:31,903 iteration 2832 : loss : 0.067981, loss_ce: 0.021660
2021-12-14 02:27:33,462 iteration 2833 : loss : 0.058231, loss_ce: 0.016618
2021-12-14 02:27:35,097 iteration 2834 : loss : 0.072335, loss_ce: 0.019857
2021-12-14 02:27:36,708 iteration 2835 : loss : 0.065881, loss_ce: 0.017590
2021-12-14 02:27:38,277 iteration 2836 : loss : 0.069761, loss_ce: 0.023600
2021-12-14 02:27:39,911 iteration 2837 : loss : 0.066957, loss_ce: 0.021260
2021-12-14 02:27:41,425 iteration 2838 : loss : 0.060181, loss_ce: 0.018886
2021-12-14 02:27:43,030 iteration 2839 : loss : 0.065656, loss_ce: 0.018668
 42%|███████████▎               | 167/400 [1:22:39<1:52:33, 28.98s/it]2021-12-14 02:27:44,719 iteration 2840 : loss : 0.062823, loss_ce: 0.019501
2021-12-14 02:27:46,289 iteration 2841 : loss : 0.062920, loss_ce: 0.017666
2021-12-14 02:27:47,852 iteration 2842 : loss : 0.058099, loss_ce: 0.015905
2021-12-14 02:27:49,472 iteration 2843 : loss : 0.062936, loss_ce: 0.015074
2021-12-14 02:27:51,065 iteration 2844 : loss : 0.062284, loss_ce: 0.021043
2021-12-14 02:27:52,637 iteration 2845 : loss : 0.062962, loss_ce: 0.020093
2021-12-14 02:27:54,221 iteration 2846 : loss : 0.054149, loss_ce: 0.014992
2021-12-14 02:27:55,677 iteration 2847 : loss : 0.053579, loss_ce: 0.020510
2021-12-14 02:27:57,258 iteration 2848 : loss : 0.066350, loss_ce: 0.020728
2021-12-14 02:27:58,885 iteration 2849 : loss : 0.066456, loss_ce: 0.017674
2021-12-14 02:28:00,498 iteration 2850 : loss : 0.069954, loss_ce: 0.018956
2021-12-14 02:28:02,124 iteration 2851 : loss : 0.063049, loss_ce: 0.019355
2021-12-14 02:28:03,723 iteration 2852 : loss : 0.067663, loss_ce: 0.016115
2021-12-14 02:28:05,359 iteration 2853 : loss : 0.056407, loss_ce: 0.016480
2021-12-14 02:28:06,966 iteration 2854 : loss : 0.064078, loss_ce: 0.018587
2021-12-14 02:28:08,510 iteration 2855 : loss : 0.060470, loss_ce: 0.020697
2021-12-14 02:28:10,121 iteration 2856 : loss : 0.067440, loss_ce: 0.027183
 42%|███████████▎               | 168/400 [1:23:07<1:49:52, 28.42s/it]2021-12-14 02:28:11,669 iteration 2857 : loss : 0.056287, loss_ce: 0.014078
2021-12-14 02:28:13,249 iteration 2858 : loss : 0.061796, loss_ce: 0.022712
2021-12-14 02:28:14,790 iteration 2859 : loss : 0.053619, loss_ce: 0.018062
2021-12-14 02:28:16,400 iteration 2860 : loss : 0.064961, loss_ce: 0.018203
2021-12-14 02:28:17,892 iteration 2861 : loss : 0.059630, loss_ce: 0.020711
2021-12-14 02:28:19,552 iteration 2862 : loss : 0.076159, loss_ce: 0.021358
2021-12-14 02:28:21,083 iteration 2863 : loss : 0.062512, loss_ce: 0.015366
2021-12-14 02:28:22,684 iteration 2864 : loss : 0.063031, loss_ce: 0.020961
2021-12-14 02:28:24,298 iteration 2865 : loss : 0.072361, loss_ce: 0.024701
2021-12-14 02:28:25,852 iteration 2866 : loss : 0.068240, loss_ce: 0.021066
2021-12-14 02:28:27,526 iteration 2867 : loss : 0.066119, loss_ce: 0.021227
2021-12-14 02:28:29,069 iteration 2868 : loss : 0.061133, loss_ce: 0.017928
2021-12-14 02:28:30,729 iteration 2869 : loss : 0.066659, loss_ce: 0.021460
2021-12-14 02:28:32,333 iteration 2870 : loss : 0.057751, loss_ce: 0.016872
2021-12-14 02:28:33,878 iteration 2871 : loss : 0.055271, loss_ce: 0.017330
2021-12-14 02:28:35,383 iteration 2872 : loss : 0.070956, loss_ce: 0.022554
2021-12-14 02:28:37,006 iteration 2873 : loss : 0.060037, loss_ce: 0.014247
 42%|███████████▍               | 169/400 [1:23:33<1:47:38, 27.96s/it]2021-12-14 02:28:38,679 iteration 2874 : loss : 0.069528, loss_ce: 0.017220
2021-12-14 02:28:40,274 iteration 2875 : loss : 0.062002, loss_ce: 0.019439
2021-12-14 02:28:41,858 iteration 2876 : loss : 0.067960, loss_ce: 0.023897
2021-12-14 02:28:43,490 iteration 2877 : loss : 0.078085, loss_ce: 0.019249
2021-12-14 02:28:45,071 iteration 2878 : loss : 0.063642, loss_ce: 0.025888
2021-12-14 02:28:46,696 iteration 2879 : loss : 0.064968, loss_ce: 0.019162
2021-12-14 02:28:48,340 iteration 2880 : loss : 0.065000, loss_ce: 0.017431
2021-12-14 02:28:49,933 iteration 2881 : loss : 0.058046, loss_ce: 0.020131
2021-12-14 02:28:51,567 iteration 2882 : loss : 0.068073, loss_ce: 0.028863
2021-12-14 02:28:53,116 iteration 2883 : loss : 0.091157, loss_ce: 0.035994
2021-12-14 02:28:54,680 iteration 2884 : loss : 0.065855, loss_ce: 0.023021
2021-12-14 02:28:56,279 iteration 2885 : loss : 0.059258, loss_ce: 0.019037
2021-12-14 02:28:57,773 iteration 2886 : loss : 0.067136, loss_ce: 0.016210
2021-12-14 02:28:59,421 iteration 2887 : loss : 0.077965, loss_ce: 0.031784
2021-12-14 02:29:01,021 iteration 2888 : loss : 0.078841, loss_ce: 0.017480
2021-12-14 02:29:02,706 iteration 2889 : loss : 0.069460, loss_ce: 0.022718
2021-12-14 02:29:02,706 Training Data Eval:
2021-12-14 02:29:10,878   Average segmentation loss on training set: 0.0533
2021-12-14 02:29:10,878 Validation Data Eval:
2021-12-14 02:29:13,665   Average segmentation loss on validation set: 0.0938
2021-12-14 02:29:20,002 Found new lowest validation loss at iteration 2889! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/TU_3seeds/REVISED_SGD_best_val_loss_seed1234.pth
2021-12-14 02:29:21,535 iteration 2890 : loss : 0.064258, loss_ce: 0.018569
 42%|███████████▍               | 170/400 [1:24:18<2:06:13, 32.93s/it]2021-12-14 02:29:23,071 iteration 2891 : loss : 0.067406, loss_ce: 0.023585
2021-12-14 02:29:24,719 iteration 2892 : loss : 0.086566, loss_ce: 0.019296
2021-12-14 02:29:26,259 iteration 2893 : loss : 0.067742, loss_ce: 0.017543
2021-12-14 02:29:27,917 iteration 2894 : loss : 0.082865, loss_ce: 0.023879
2021-12-14 02:29:29,556 iteration 2895 : loss : 0.070436, loss_ce: 0.027435
2021-12-14 02:29:31,105 iteration 2896 : loss : 0.055871, loss_ce: 0.014449
2021-12-14 02:29:32,692 iteration 2897 : loss : 0.065583, loss_ce: 0.022095
2021-12-14 02:29:34,218 iteration 2898 : loss : 0.065036, loss_ce: 0.025878
2021-12-14 02:29:35,830 iteration 2899 : loss : 0.072573, loss_ce: 0.021365
2021-12-14 02:29:37,400 iteration 2900 : loss : 0.057022, loss_ce: 0.015922
2021-12-14 02:29:38,992 iteration 2901 : loss : 0.071404, loss_ce: 0.018315
2021-12-14 02:29:40,503 iteration 2902 : loss : 0.073578, loss_ce: 0.020552
2021-12-14 02:29:42,038 iteration 2903 : loss : 0.060903, loss_ce: 0.022424
2021-12-14 02:29:43,571 iteration 2904 : loss : 0.060596, loss_ce: 0.019244
2021-12-14 02:29:45,077 iteration 2905 : loss : 0.063694, loss_ce: 0.022904
2021-12-14 02:29:46,689 iteration 2906 : loss : 0.068943, loss_ce: 0.029524
2021-12-14 02:29:48,228 iteration 2907 : loss : 0.064750, loss_ce: 0.018839
 43%|███████████▌               | 171/400 [1:24:45<1:58:32, 31.06s/it]2021-12-14 02:29:49,897 iteration 2908 : loss : 0.075854, loss_ce: 0.030766
2021-12-14 02:29:51,530 iteration 2909 : loss : 0.072101, loss_ce: 0.027220
2021-12-14 02:29:53,124 iteration 2910 : loss : 0.085738, loss_ce: 0.025686
2021-12-14 02:29:54,750 iteration 2911 : loss : 0.070789, loss_ce: 0.018741
2021-12-14 02:29:56,311 iteration 2912 : loss : 0.062132, loss_ce: 0.018191
2021-12-14 02:29:57,956 iteration 2913 : loss : 0.068252, loss_ce: 0.024913
2021-12-14 02:29:59,512 iteration 2914 : loss : 0.074304, loss_ce: 0.022820
2021-12-14 02:30:01,077 iteration 2915 : loss : 0.058203, loss_ce: 0.018479
2021-12-14 02:30:02,671 iteration 2916 : loss : 0.066284, loss_ce: 0.021866
2021-12-14 02:30:04,189 iteration 2917 : loss : 0.057920, loss_ce: 0.018980
2021-12-14 02:30:05,727 iteration 2918 : loss : 0.065843, loss_ce: 0.013951
2021-12-14 02:30:07,306 iteration 2919 : loss : 0.056050, loss_ce: 0.013677
2021-12-14 02:30:08,905 iteration 2920 : loss : 0.067460, loss_ce: 0.023069
2021-12-14 02:30:10,472 iteration 2921 : loss : 0.069229, loss_ce: 0.024125
2021-12-14 02:30:11,979 iteration 2922 : loss : 0.070590, loss_ce: 0.021003
2021-12-14 02:30:13,525 iteration 2923 : loss : 0.062717, loss_ce: 0.017728
2021-12-14 02:30:15,116 iteration 2924 : loss : 0.084572, loss_ce: 0.024037
 43%|███████████▌               | 172/400 [1:25:12<1:53:16, 29.81s/it]2021-12-14 02:30:16,663 iteration 2925 : loss : 0.060581, loss_ce: 0.022988
2021-12-14 02:30:18,333 iteration 2926 : loss : 0.079654, loss_ce: 0.029651
2021-12-14 02:30:19,920 iteration 2927 : loss : 0.057472, loss_ce: 0.019000
2021-12-14 02:30:21,382 iteration 2928 : loss : 0.064828, loss_ce: 0.017043
2021-12-14 02:30:22,939 iteration 2929 : loss : 0.059479, loss_ce: 0.019331
2021-12-14 02:30:24,607 iteration 2930 : loss : 0.061856, loss_ce: 0.023587
2021-12-14 02:30:26,165 iteration 2931 : loss : 0.062267, loss_ce: 0.018491
2021-12-14 02:30:27,705 iteration 2932 : loss : 0.066578, loss_ce: 0.020733
2021-12-14 02:30:29,363 iteration 2933 : loss : 0.067362, loss_ce: 0.016077
2021-12-14 02:30:30,945 iteration 2934 : loss : 0.056392, loss_ce: 0.014210
2021-12-14 02:30:32,542 iteration 2935 : loss : 0.062528, loss_ce: 0.017682
2021-12-14 02:30:34,118 iteration 2936 : loss : 0.052203, loss_ce: 0.012767
2021-12-14 02:30:35,728 iteration 2937 : loss : 0.060360, loss_ce: 0.021604
2021-12-14 02:30:37,360 iteration 2938 : loss : 0.077517, loss_ce: 0.023978
2021-12-14 02:30:38,995 iteration 2939 : loss : 0.061161, loss_ce: 0.017325
2021-12-14 02:30:40,690 iteration 2940 : loss : 0.085143, loss_ce: 0.036056
2021-12-14 02:30:42,226 iteration 2941 : loss : 0.056960, loss_ce: 0.015023
 43%|███████████▋               | 173/400 [1:25:39<1:49:42, 29.00s/it]2021-12-14 02:30:43,812 iteration 2942 : loss : 0.054565, loss_ce: 0.014892
2021-12-14 02:30:45,422 iteration 2943 : loss : 0.070734, loss_ce: 0.017373
2021-12-14 02:30:46,964 iteration 2944 : loss : 0.056839, loss_ce: 0.021532
2021-12-14 02:30:48,564 iteration 2945 : loss : 0.061877, loss_ce: 0.015710
2021-12-14 02:30:50,042 iteration 2946 : loss : 0.060477, loss_ce: 0.018937
2021-12-14 02:30:51,592 iteration 2947 : loss : 0.056969, loss_ce: 0.017255
2021-12-14 02:30:53,138 iteration 2948 : loss : 0.053277, loss_ce: 0.012621
2021-12-14 02:30:54,792 iteration 2949 : loss : 0.063632, loss_ce: 0.018695
2021-12-14 02:30:56,403 iteration 2950 : loss : 0.058591, loss_ce: 0.019331
2021-12-14 02:30:58,031 iteration 2951 : loss : 0.060115, loss_ce: 0.019325
2021-12-14 02:30:59,655 iteration 2952 : loss : 0.053755, loss_ce: 0.014306
2021-12-14 02:31:01,350 iteration 2953 : loss : 0.068749, loss_ce: 0.025879
2021-12-14 02:31:03,045 iteration 2954 : loss : 0.082745, loss_ce: 0.023074
2021-12-14 02:31:04,597 iteration 2955 : loss : 0.061378, loss_ce: 0.021209
2021-12-14 02:31:06,165 iteration 2956 : loss : 0.059189, loss_ce: 0.020328
2021-12-14 02:31:07,700 iteration 2957 : loss : 0.064374, loss_ce: 0.020246
2021-12-14 02:31:09,294 iteration 2958 : loss : 0.060594, loss_ce: 0.023676
 44%|███████████▋               | 174/400 [1:26:06<1:47:02, 28.42s/it]2021-12-14 02:31:10,908 iteration 2959 : loss : 0.051359, loss_ce: 0.013996
2021-12-14 02:31:12,469 iteration 2960 : loss : 0.064937, loss_ce: 0.024010
2021-12-14 02:31:14,066 iteration 2961 : loss : 0.057810, loss_ce: 0.017429
2021-12-14 02:31:15,815 iteration 2962 : loss : 0.060249, loss_ce: 0.017633
2021-12-14 02:31:17,429 iteration 2963 : loss : 0.085973, loss_ce: 0.025842
2021-12-14 02:31:18,922 iteration 2964 : loss : 0.058814, loss_ce: 0.016105
2021-12-14 02:31:20,518 iteration 2965 : loss : 0.063052, loss_ce: 0.024363
2021-12-14 02:31:22,143 iteration 2966 : loss : 0.064900, loss_ce: 0.020507
2021-12-14 02:31:23,719 iteration 2967 : loss : 0.082663, loss_ce: 0.029952
2021-12-14 02:31:25,319 iteration 2968 : loss : 0.066573, loss_ce: 0.020608
2021-12-14 02:31:26,886 iteration 2969 : loss : 0.059359, loss_ce: 0.020320
2021-12-14 02:31:28,486 iteration 2970 : loss : 0.068628, loss_ce: 0.021262
2021-12-14 02:31:30,056 iteration 2971 : loss : 0.063748, loss_ce: 0.019897
2021-12-14 02:31:31,633 iteration 2972 : loss : 0.059972, loss_ce: 0.021365
2021-12-14 02:31:33,163 iteration 2973 : loss : 0.055762, loss_ce: 0.013019
2021-12-14 02:31:34,799 iteration 2974 : loss : 0.077079, loss_ce: 0.018522
2021-12-14 02:31:34,799 Training Data Eval:
2021-12-14 02:31:42,985   Average segmentation loss on training set: 0.0504
2021-12-14 02:31:42,986 Validation Data Eval:
2021-12-14 02:31:45,788   Average segmentation loss on validation set: 0.0906
2021-12-14 02:31:52,203 Found new lowest validation loss at iteration 2974! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/TU_3seeds/REVISED_SGD_best_val_loss_seed1234.pth
2021-12-14 02:31:53,663 iteration 2975 : loss : 0.057357, loss_ce: 0.016156
 44%|███████████▊               | 175/400 [1:26:50<2:04:30, 33.20s/it]2021-12-14 02:31:55,090 iteration 2976 : loss : 0.055431, loss_ce: 0.018447
2021-12-14 02:31:56,706 iteration 2977 : loss : 0.066393, loss_ce: 0.024982
2021-12-14 02:31:58,301 iteration 2978 : loss : 0.056177, loss_ce: 0.015101
2021-12-14 02:31:59,940 iteration 2979 : loss : 0.061377, loss_ce: 0.016929
2021-12-14 02:32:01,567 iteration 2980 : loss : 0.067674, loss_ce: 0.016731
2021-12-14 02:32:03,264 iteration 2981 : loss : 0.090215, loss_ce: 0.033288
2021-12-14 02:32:04,857 iteration 2982 : loss : 0.050989, loss_ce: 0.014855
2021-12-14 02:32:06,455 iteration 2983 : loss : 0.059241, loss_ce: 0.017189
2021-12-14 02:32:08,053 iteration 2984 : loss : 0.067099, loss_ce: 0.020319
2021-12-14 02:32:09,674 iteration 2985 : loss : 0.067592, loss_ce: 0.022042
2021-12-14 02:32:11,193 iteration 2986 : loss : 0.059606, loss_ce: 0.020021
2021-12-14 02:32:12,783 iteration 2987 : loss : 0.063472, loss_ce: 0.018397
2021-12-14 02:32:14,432 iteration 2988 : loss : 0.062363, loss_ce: 0.020708
2021-12-14 02:32:16,064 iteration 2989 : loss : 0.071140, loss_ce: 0.019701
2021-12-14 02:32:17,590 iteration 2990 : loss : 0.051108, loss_ce: 0.016631
2021-12-14 02:32:19,174 iteration 2991 : loss : 0.055289, loss_ce: 0.017252
2021-12-14 02:32:20,838 iteration 2992 : loss : 0.061880, loss_ce: 0.020237
 44%|███████████▉               | 176/400 [1:27:17<1:57:12, 31.40s/it]2021-12-14 02:32:22,423 iteration 2993 : loss : 0.059884, loss_ce: 0.023190
2021-12-14 02:32:24,022 iteration 2994 : loss : 0.077597, loss_ce: 0.020122
2021-12-14 02:32:25,584 iteration 2995 : loss : 0.066963, loss_ce: 0.018516
2021-12-14 02:32:27,167 iteration 2996 : loss : 0.057454, loss_ce: 0.019180
2021-12-14 02:32:28,752 iteration 2997 : loss : 0.090161, loss_ce: 0.025862
2021-12-14 02:32:30,348 iteration 2998 : loss : 0.059268, loss_ce: 0.020519
2021-12-14 02:32:31,996 iteration 2999 : loss : 0.085772, loss_ce: 0.017037
2021-12-14 02:32:33,669 iteration 3000 : loss : 0.067061, loss_ce: 0.022940
2021-12-14 02:32:35,329 iteration 3001 : loss : 0.068420, loss_ce: 0.015167
2021-12-14 02:32:36,860 iteration 3002 : loss : 0.056866, loss_ce: 0.018991
2021-12-14 02:32:38,419 iteration 3003 : loss : 0.060235, loss_ce: 0.018247
2021-12-14 02:32:39,988 iteration 3004 : loss : 0.056833, loss_ce: 0.018714
2021-12-14 02:32:41,576 iteration 3005 : loss : 0.064660, loss_ce: 0.023919
2021-12-14 02:32:43,207 iteration 3006 : loss : 0.066127, loss_ce: 0.022255
2021-12-14 02:32:44,822 iteration 3007 : loss : 0.071344, loss_ce: 0.023849
2021-12-14 02:32:46,440 iteration 3008 : loss : 0.063030, loss_ce: 0.018410
2021-12-14 02:32:47,951 iteration 3009 : loss : 0.064319, loss_ce: 0.020750
 44%|███████████▉               | 177/400 [1:27:44<1:51:54, 30.11s/it]2021-12-14 02:32:49,715 iteration 3010 : loss : 0.062544, loss_ce: 0.017295
2021-12-14 02:32:51,344 iteration 3011 : loss : 0.058258, loss_ce: 0.021984
2021-12-14 02:32:52,889 iteration 3012 : loss : 0.057966, loss_ce: 0.020264
2021-12-14 02:32:54,412 iteration 3013 : loss : 0.067346, loss_ce: 0.016726
2021-12-14 02:32:56,008 iteration 3014 : loss : 0.058658, loss_ce: 0.017857
2021-12-14 02:32:57,590 iteration 3015 : loss : 0.064874, loss_ce: 0.014951
2021-12-14 02:32:59,162 iteration 3016 : loss : 0.065089, loss_ce: 0.020899
2021-12-14 02:33:00,705 iteration 3017 : loss : 0.060534, loss_ce: 0.026352
2021-12-14 02:33:02,250 iteration 3018 : loss : 0.052741, loss_ce: 0.018025
2021-12-14 02:33:03,755 iteration 3019 : loss : 0.063925, loss_ce: 0.016079
2021-12-14 02:33:05,348 iteration 3020 : loss : 0.064610, loss_ce: 0.019154
2021-12-14 02:33:06,944 iteration 3021 : loss : 0.053013, loss_ce: 0.015050
2021-12-14 02:33:08,493 iteration 3022 : loss : 0.058157, loss_ce: 0.013442
2021-12-14 02:33:10,070 iteration 3023 : loss : 0.059316, loss_ce: 0.017803
2021-12-14 02:33:11,723 iteration 3024 : loss : 0.084564, loss_ce: 0.031861
2021-12-14 02:33:13,351 iteration 3025 : loss : 0.067804, loss_ce: 0.022173
2021-12-14 02:33:14,880 iteration 3026 : loss : 0.057950, loss_ce: 0.018553
 44%|████████████               | 178/400 [1:28:11<1:47:52, 29.16s/it]2021-12-14 02:33:16,564 iteration 3027 : loss : 0.084129, loss_ce: 0.026997
2021-12-14 02:33:18,096 iteration 3028 : loss : 0.058560, loss_ce: 0.019088
2021-12-14 02:33:19,685 iteration 3029 : loss : 0.061040, loss_ce: 0.017820
2021-12-14 02:33:21,233 iteration 3030 : loss : 0.059962, loss_ce: 0.020560
2021-12-14 02:33:22,819 iteration 3031 : loss : 0.069202, loss_ce: 0.019362
2021-12-14 02:33:24,362 iteration 3032 : loss : 0.058188, loss_ce: 0.017351
2021-12-14 02:33:25,975 iteration 3033 : loss : 0.073076, loss_ce: 0.019415
2021-12-14 02:33:27,595 iteration 3034 : loss : 0.054283, loss_ce: 0.016798
2021-12-14 02:33:29,190 iteration 3035 : loss : 0.060005, loss_ce: 0.020158
2021-12-14 02:33:30,745 iteration 3036 : loss : 0.066143, loss_ce: 0.027062
2021-12-14 02:33:32,318 iteration 3037 : loss : 0.071754, loss_ce: 0.023121
2021-12-14 02:33:33,937 iteration 3038 : loss : 0.073524, loss_ce: 0.022279
2021-12-14 02:33:35,459 iteration 3039 : loss : 0.074340, loss_ce: 0.023393
2021-12-14 02:33:37,051 iteration 3040 : loss : 0.071350, loss_ce: 0.017904
2021-12-14 02:33:38,673 iteration 3041 : loss : 0.053331, loss_ce: 0.016859
2021-12-14 02:33:40,248 iteration 3042 : loss : 0.055970, loss_ce: 0.018483
2021-12-14 02:33:42,000 iteration 3043 : loss : 0.076532, loss_ce: 0.019039
 45%|████████████               | 179/400 [1:28:38<1:45:07, 28.54s/it]2021-12-14 02:33:43,643 iteration 3044 : loss : 0.074167, loss_ce: 0.023972
2021-12-14 02:33:45,173 iteration 3045 : loss : 0.058862, loss_ce: 0.018367
2021-12-14 02:33:46,727 iteration 3046 : loss : 0.058817, loss_ce: 0.017858
2021-12-14 02:33:48,414 iteration 3047 : loss : 0.070388, loss_ce: 0.030004
2021-12-14 02:33:49,951 iteration 3048 : loss : 0.060968, loss_ce: 0.016852
2021-12-14 02:33:51,529 iteration 3049 : loss : 0.078081, loss_ce: 0.028092
2021-12-14 02:33:53,136 iteration 3050 : loss : 0.067381, loss_ce: 0.024961
2021-12-14 02:33:54,724 iteration 3051 : loss : 0.062267, loss_ce: 0.013729
2021-12-14 02:33:56,295 iteration 3052 : loss : 0.062411, loss_ce: 0.018657
2021-12-14 02:33:57,966 iteration 3053 : loss : 0.052686, loss_ce: 0.016585
2021-12-14 02:33:59,506 iteration 3054 : loss : 0.063108, loss_ce: 0.015626
2021-12-14 02:34:01,109 iteration 3055 : loss : 0.079003, loss_ce: 0.024606
2021-12-14 02:34:02,657 iteration 3056 : loss : 0.053724, loss_ce: 0.016568
2021-12-14 02:34:04,175 iteration 3057 : loss : 0.064021, loss_ce: 0.024494
2021-12-14 02:34:05,765 iteration 3058 : loss : 0.054891, loss_ce: 0.017967
2021-12-14 02:34:07,374 iteration 3059 : loss : 0.060236, loss_ce: 0.014313
2021-12-14 02:34:07,374 Training Data Eval:
2021-12-14 02:34:15,549   Average segmentation loss on training set: 0.0518
2021-12-14 02:34:15,549 Validation Data Eval:
2021-12-14 02:34:18,351   Average segmentation loss on validation set: 0.0882
2021-12-14 02:34:24,754 Found new lowest validation loss at iteration 3059! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/TU_3seeds/REVISED_SGD_best_val_loss_seed1234.pth
2021-12-14 02:34:26,186 iteration 3060 : loss : 0.055297, loss_ce: 0.020834
 45%|████████████▏              | 180/400 [1:29:23<2:01:52, 33.24s/it]2021-12-14 02:34:27,609 iteration 3061 : loss : 0.062294, loss_ce: 0.018569
2021-12-14 02:34:29,178 iteration 3062 : loss : 0.058138, loss_ce: 0.017591
2021-12-14 02:34:30,793 iteration 3063 : loss : 0.059041, loss_ce: 0.017472
2021-12-14 02:34:32,412 iteration 3064 : loss : 0.057201, loss_ce: 0.019708
2021-12-14 02:34:33,895 iteration 3065 : loss : 0.052363, loss_ce: 0.014466
2021-12-14 02:34:35,435 iteration 3066 : loss : 0.062163, loss_ce: 0.024531
2021-12-14 02:34:37,037 iteration 3067 : loss : 0.063786, loss_ce: 0.023995
2021-12-14 02:34:38,625 iteration 3068 : loss : 0.064394, loss_ce: 0.016642
2021-12-14 02:34:40,200 iteration 3069 : loss : 0.072647, loss_ce: 0.021957
2021-12-14 02:34:41,783 iteration 3070 : loss : 0.053252, loss_ce: 0.014246
2021-12-14 02:34:43,304 iteration 3071 : loss : 0.057132, loss_ce: 0.017870
2021-12-14 02:34:44,821 iteration 3072 : loss : 0.060815, loss_ce: 0.018085
2021-12-14 02:34:46,379 iteration 3073 : loss : 0.056506, loss_ce: 0.016446
2021-12-14 02:34:48,017 iteration 3074 : loss : 0.087318, loss_ce: 0.028436
2021-12-14 02:34:49,618 iteration 3075 : loss : 0.068036, loss_ce: 0.022520
2021-12-14 02:34:51,257 iteration 3076 : loss : 0.072245, loss_ce: 0.019531
2021-12-14 02:34:52,787 iteration 3077 : loss : 0.062581, loss_ce: 0.018379
 45%|████████████▏              | 181/400 [1:29:49<1:54:02, 31.24s/it]2021-12-14 02:34:54,347 iteration 3078 : loss : 0.054458, loss_ce: 0.017122
2021-12-14 02:34:56,033 iteration 3079 : loss : 0.056330, loss_ce: 0.014521
2021-12-14 02:34:57,534 iteration 3080 : loss : 0.062363, loss_ce: 0.016805
2021-12-14 02:34:59,133 iteration 3081 : loss : 0.066436, loss_ce: 0.019274
2021-12-14 02:35:00,689 iteration 3082 : loss : 0.059353, loss_ce: 0.012688
2021-12-14 02:35:02,315 iteration 3083 : loss : 0.057366, loss_ce: 0.017828
2021-12-14 02:35:03,781 iteration 3084 : loss : 0.055689, loss_ce: 0.019889
2021-12-14 02:35:05,380 iteration 3085 : loss : 0.059166, loss_ce: 0.022596
2021-12-14 02:35:07,063 iteration 3086 : loss : 0.061736, loss_ce: 0.023021
2021-12-14 02:35:08,621 iteration 3087 : loss : 0.061723, loss_ce: 0.020169
2021-12-14 02:35:10,213 iteration 3088 : loss : 0.054930, loss_ce: 0.015495
2021-12-14 02:35:11,872 iteration 3089 : loss : 0.072999, loss_ce: 0.020372
2021-12-14 02:35:13,370 iteration 3090 : loss : 0.059568, loss_ce: 0.021399
2021-12-14 02:35:14,942 iteration 3091 : loss : 0.062747, loss_ce: 0.023255
2021-12-14 02:35:16,656 iteration 3092 : loss : 0.065570, loss_ce: 0.019189
2021-12-14 02:35:18,202 iteration 3093 : loss : 0.057125, loss_ce: 0.018118
2021-12-14 02:35:19,793 iteration 3094 : loss : 0.056497, loss_ce: 0.020527
 46%|████████████▎              | 182/400 [1:30:16<1:48:54, 29.97s/it]2021-12-14 02:35:21,413 iteration 3095 : loss : 0.059793, loss_ce: 0.020139
2021-12-14 02:35:23,010 iteration 3096 : loss : 0.066450, loss_ce: 0.023199
2021-12-14 02:35:24,574 iteration 3097 : loss : 0.058267, loss_ce: 0.016165
2021-12-14 02:35:26,110 iteration 3098 : loss : 0.056231, loss_ce: 0.018390
2021-12-14 02:35:27,687 iteration 3099 : loss : 0.053098, loss_ce: 0.015176
2021-12-14 02:35:29,212 iteration 3100 : loss : 0.056966, loss_ce: 0.015574
2021-12-14 02:35:30,838 iteration 3101 : loss : 0.055026, loss_ce: 0.016227
2021-12-14 02:35:32,412 iteration 3102 : loss : 0.056251, loss_ce: 0.017975
2021-12-14 02:35:33,999 iteration 3103 : loss : 0.070352, loss_ce: 0.023838
2021-12-14 02:35:35,535 iteration 3104 : loss : 0.057420, loss_ce: 0.020691
2021-12-14 02:35:37,045 iteration 3105 : loss : 0.054645, loss_ce: 0.020603
2021-12-14 02:35:38,606 iteration 3106 : loss : 0.062179, loss_ce: 0.023939
2021-12-14 02:35:40,159 iteration 3107 : loss : 0.048941, loss_ce: 0.010644
2021-12-14 02:35:41,748 iteration 3108 : loss : 0.062364, loss_ce: 0.018115
2021-12-14 02:35:43,352 iteration 3109 : loss : 0.060690, loss_ce: 0.017615
2021-12-14 02:35:44,961 iteration 3110 : loss : 0.075178, loss_ce: 0.026047
2021-12-14 02:35:46,549 iteration 3111 : loss : 0.076933, loss_ce: 0.023949
 46%|████████████▎              | 183/400 [1:30:43<1:44:54, 29.01s/it]2021-12-14 02:35:48,180 iteration 3112 : loss : 0.061561, loss_ce: 0.019334
2021-12-14 02:35:49,714 iteration 3113 : loss : 0.056965, loss_ce: 0.018221
2021-12-14 02:35:51,331 iteration 3114 : loss : 0.060515, loss_ce: 0.016443
2021-12-14 02:35:52,917 iteration 3115 : loss : 0.059190, loss_ce: 0.021046
2021-12-14 02:35:54,490 iteration 3116 : loss : 0.054521, loss_ce: 0.020872
2021-12-14 02:35:56,133 iteration 3117 : loss : 0.056817, loss_ce: 0.018068
2021-12-14 02:35:57,692 iteration 3118 : loss : 0.062266, loss_ce: 0.020245
2021-12-14 02:35:59,371 iteration 3119 : loss : 0.094233, loss_ce: 0.026197
2021-12-14 02:36:00,897 iteration 3120 : loss : 0.055841, loss_ce: 0.017425
2021-12-14 02:36:02,534 iteration 3121 : loss : 0.059918, loss_ce: 0.021552
2021-12-14 02:36:04,091 iteration 3122 : loss : 0.063985, loss_ce: 0.015853
2021-12-14 02:36:05,720 iteration 3123 : loss : 0.059072, loss_ce: 0.021626
2021-12-14 02:36:07,222 iteration 3124 : loss : 0.051581, loss_ce: 0.015223
2021-12-14 02:36:08,787 iteration 3125 : loss : 0.064602, loss_ce: 0.017711
2021-12-14 02:36:10,414 iteration 3126 : loss : 0.057126, loss_ce: 0.022419
2021-12-14 02:36:12,056 iteration 3127 : loss : 0.062292, loss_ce: 0.017881
2021-12-14 02:36:13,695 iteration 3128 : loss : 0.055305, loss_ce: 0.015417
 46%|████████████▍              | 184/400 [1:31:10<1:42:25, 28.45s/it]2021-12-14 02:36:15,287 iteration 3129 : loss : 0.057381, loss_ce: 0.016682
2021-12-14 02:36:16,959 iteration 3130 : loss : 0.065185, loss_ce: 0.023998
2021-12-14 02:36:18,524 iteration 3131 : loss : 0.060742, loss_ce: 0.015709
2021-12-14 02:36:20,097 iteration 3132 : loss : 0.054765, loss_ce: 0.013272
2021-12-14 02:36:21,671 iteration 3133 : loss : 0.073371, loss_ce: 0.020396
2021-12-14 02:36:23,217 iteration 3134 : loss : 0.055674, loss_ce: 0.019734
2021-12-14 02:36:24,788 iteration 3135 : loss : 0.065798, loss_ce: 0.024230
2021-12-14 02:36:26,338 iteration 3136 : loss : 0.056808, loss_ce: 0.020089
2021-12-14 02:36:28,017 iteration 3137 : loss : 0.058494, loss_ce: 0.019736
2021-12-14 02:36:29,654 iteration 3138 : loss : 0.068621, loss_ce: 0.023778
2021-12-14 02:36:31,170 iteration 3139 : loss : 0.069557, loss_ce: 0.021793
2021-12-14 02:36:32,693 iteration 3140 : loss : 0.061967, loss_ce: 0.021510
2021-12-14 02:36:34,281 iteration 3141 : loss : 0.068747, loss_ce: 0.025435
2021-12-14 02:36:35,833 iteration 3142 : loss : 0.065330, loss_ce: 0.018469
2021-12-14 02:36:37,452 iteration 3143 : loss : 0.062863, loss_ce: 0.016727
2021-12-14 02:36:39,021 iteration 3144 : loss : 0.060287, loss_ce: 0.019153
2021-12-14 02:36:39,021 Training Data Eval:
2021-12-14 02:36:47,203   Average segmentation loss on training set: 0.0478
2021-12-14 02:36:47,203 Validation Data Eval:
2021-12-14 02:36:50,006   Average segmentation loss on validation set: 0.0989
2021-12-14 02:36:51,545 iteration 3145 : loss : 0.051701, loss_ce: 0.015093
 46%|████████████▍              | 185/400 [1:31:48<1:52:03, 31.27s/it]2021-12-14 02:36:53,320 iteration 3146 : loss : 0.077559, loss_ce: 0.021453
2021-12-14 02:36:54,939 iteration 3147 : loss : 0.061075, loss_ce: 0.021827
2021-12-14 02:36:56,456 iteration 3148 : loss : 0.052249, loss_ce: 0.016459
2021-12-14 02:36:58,072 iteration 3149 : loss : 0.059942, loss_ce: 0.015809
2021-12-14 02:36:59,681 iteration 3150 : loss : 0.060248, loss_ce: 0.015631
2021-12-14 02:37:01,288 iteration 3151 : loss : 0.058406, loss_ce: 0.016951
2021-12-14 02:37:02,894 iteration 3152 : loss : 0.064403, loss_ce: 0.018609
2021-12-14 02:37:04,490 iteration 3153 : loss : 0.069089, loss_ce: 0.027881
2021-12-14 02:37:06,150 iteration 3154 : loss : 0.069057, loss_ce: 0.023684
2021-12-14 02:37:07,768 iteration 3155 : loss : 0.059091, loss_ce: 0.018339
2021-12-14 02:37:09,288 iteration 3156 : loss : 0.057660, loss_ce: 0.015370
2021-12-14 02:37:10,886 iteration 3157 : loss : 0.063277, loss_ce: 0.021685
2021-12-14 02:37:12,419 iteration 3158 : loss : 0.057739, loss_ce: 0.011115
2021-12-14 02:37:14,025 iteration 3159 : loss : 0.065641, loss_ce: 0.027660
2021-12-14 02:37:15,638 iteration 3160 : loss : 0.060498, loss_ce: 0.022446
2021-12-14 02:37:17,290 iteration 3161 : loss : 0.054799, loss_ce: 0.015927
2021-12-14 02:37:18,875 iteration 3162 : loss : 0.056622, loss_ce: 0.016237
 46%|████████████▌              | 186/400 [1:32:15<1:47:19, 30.09s/it]2021-12-14 02:37:20,461 iteration 3163 : loss : 0.066286, loss_ce: 0.018905
2021-12-14 02:37:22,151 iteration 3164 : loss : 0.072713, loss_ce: 0.027092
2021-12-14 02:37:23,790 iteration 3165 : loss : 0.055780, loss_ce: 0.018312
2021-12-14 02:37:25,336 iteration 3166 : loss : 0.065235, loss_ce: 0.022994
2021-12-14 02:37:26,966 iteration 3167 : loss : 0.059062, loss_ce: 0.016438
2021-12-14 02:37:28,545 iteration 3168 : loss : 0.055611, loss_ce: 0.017699
2021-12-14 02:37:30,152 iteration 3169 : loss : 0.058028, loss_ce: 0.020077
2021-12-14 02:37:31,734 iteration 3170 : loss : 0.064572, loss_ce: 0.023011
2021-12-14 02:37:33,203 iteration 3171 : loss : 0.057496, loss_ce: 0.014996
2021-12-14 02:37:34,743 iteration 3172 : loss : 0.058195, loss_ce: 0.018938
2021-12-14 02:37:36,322 iteration 3173 : loss : 0.067809, loss_ce: 0.018388
2021-12-14 02:37:37,868 iteration 3174 : loss : 0.062234, loss_ce: 0.023457
2021-12-14 02:37:39,381 iteration 3175 : loss : 0.070072, loss_ce: 0.018236
2021-12-14 02:37:41,034 iteration 3176 : loss : 0.085565, loss_ce: 0.023990
2021-12-14 02:37:42,614 iteration 3177 : loss : 0.058556, loss_ce: 0.016833
2021-12-14 02:37:44,283 iteration 3178 : loss : 0.055789, loss_ce: 0.015362
2021-12-14 02:37:45,872 iteration 3179 : loss : 0.067512, loss_ce: 0.026787
 47%|████████████▌              | 187/400 [1:32:42<1:43:31, 29.16s/it]2021-12-14 02:37:47,530 iteration 3180 : loss : 0.073422, loss_ce: 0.026029
2021-12-14 02:37:49,123 iteration 3181 : loss : 0.058224, loss_ce: 0.019101
2021-12-14 02:37:50,649 iteration 3182 : loss : 0.055725, loss_ce: 0.020104
2021-12-14 02:37:52,286 iteration 3183 : loss : 0.071432, loss_ce: 0.024137
2021-12-14 02:37:53,866 iteration 3184 : loss : 0.073994, loss_ce: 0.025090
2021-12-14 02:37:55,458 iteration 3185 : loss : 0.065914, loss_ce: 0.017728
2021-12-14 02:37:57,076 iteration 3186 : loss : 0.065869, loss_ce: 0.022171
2021-12-14 02:37:58,696 iteration 3187 : loss : 0.050049, loss_ce: 0.014190
2021-12-14 02:38:00,328 iteration 3188 : loss : 0.068346, loss_ce: 0.022953
2021-12-14 02:38:01,905 iteration 3189 : loss : 0.057794, loss_ce: 0.016099
2021-12-14 02:38:03,590 iteration 3190 : loss : 0.069674, loss_ce: 0.021835
2021-12-14 02:38:05,225 iteration 3191 : loss : 0.063556, loss_ce: 0.018987
2021-12-14 02:38:06,743 iteration 3192 : loss : 0.058470, loss_ce: 0.012216
2021-12-14 02:38:08,326 iteration 3193 : loss : 0.054993, loss_ce: 0.017554
2021-12-14 02:38:10,028 iteration 3194 : loss : 0.079204, loss_ce: 0.029771
2021-12-14 02:38:11,617 iteration 3195 : loss : 0.057492, loss_ce: 0.021347
2021-12-14 02:38:13,199 iteration 3196 : loss : 0.069402, loss_ce: 0.026616
 47%|████████████▋              | 188/400 [1:33:10<1:41:05, 28.61s/it]2021-12-14 02:38:14,827 iteration 3197 : loss : 0.058296, loss_ce: 0.019657
2021-12-14 02:38:16,453 iteration 3198 : loss : 0.069177, loss_ce: 0.027689
2021-12-14 02:38:18,070 iteration 3199 : loss : 0.053920, loss_ce: 0.010872
2021-12-14 02:38:19,705 iteration 3200 : loss : 0.065656, loss_ce: 0.017068
2021-12-14 02:38:21,334 iteration 3201 : loss : 0.058521, loss_ce: 0.018134
2021-12-14 02:38:22,968 iteration 3202 : loss : 0.071503, loss_ce: 0.019518
2021-12-14 02:38:24,477 iteration 3203 : loss : 0.053876, loss_ce: 0.017745
2021-12-14 02:38:25,976 iteration 3204 : loss : 0.054437, loss_ce: 0.018337
2021-12-14 02:38:27,475 iteration 3205 : loss : 0.066971, loss_ce: 0.020387
2021-12-14 02:38:28,941 iteration 3206 : loss : 0.048273, loss_ce: 0.011857
2021-12-14 02:38:30,550 iteration 3207 : loss : 0.066162, loss_ce: 0.021340
2021-12-14 02:38:32,128 iteration 3208 : loss : 0.058743, loss_ce: 0.019041
2021-12-14 02:38:33,684 iteration 3209 : loss : 0.057580, loss_ce: 0.016131
2021-12-14 02:38:35,296 iteration 3210 : loss : 0.055188, loss_ce: 0.020544
2021-12-14 02:38:36,821 iteration 3211 : loss : 0.055460, loss_ce: 0.013997
2021-12-14 02:38:38,474 iteration 3212 : loss : 0.067948, loss_ce: 0.021439
2021-12-14 02:38:40,136 iteration 3213 : loss : 0.060286, loss_ce: 0.017237
 47%|████████████▊              | 189/400 [1:33:37<1:38:50, 28.11s/it]2021-12-14 02:38:41,717 iteration 3214 : loss : 0.052416, loss_ce: 0.017298
2021-12-14 02:38:43,289 iteration 3215 : loss : 0.056250, loss_ce: 0.020712
2021-12-14 02:38:44,864 iteration 3216 : loss : 0.074594, loss_ce: 0.021160
2021-12-14 02:38:46,476 iteration 3217 : loss : 0.103724, loss_ce: 0.049024
2021-12-14 02:38:48,057 iteration 3218 : loss : 0.072777, loss_ce: 0.019259
2021-12-14 02:38:49,628 iteration 3219 : loss : 0.061220, loss_ce: 0.019526
2021-12-14 02:38:51,158 iteration 3220 : loss : 0.065039, loss_ce: 0.025002
2021-12-14 02:38:52,832 iteration 3221 : loss : 0.068632, loss_ce: 0.023624
2021-12-14 02:38:54,382 iteration 3222 : loss : 0.049360, loss_ce: 0.010330
2021-12-14 02:38:55,990 iteration 3223 : loss : 0.058182, loss_ce: 0.013719
2021-12-14 02:38:57,656 iteration 3224 : loss : 0.073574, loss_ce: 0.018756
2021-12-14 02:38:59,237 iteration 3225 : loss : 0.064332, loss_ce: 0.023356
2021-12-14 02:39:00,814 iteration 3226 : loss : 0.059327, loss_ce: 0.019399
2021-12-14 02:39:02,404 iteration 3227 : loss : 0.056784, loss_ce: 0.018573
2021-12-14 02:39:03,955 iteration 3228 : loss : 0.080028, loss_ce: 0.019187
2021-12-14 02:39:05,476 iteration 3229 : loss : 0.061594, loss_ce: 0.015501
2021-12-14 02:39:05,476 Training Data Eval:
2021-12-14 02:39:13,678   Average segmentation loss on training set: 0.0487
2021-12-14 02:39:13,678 Validation Data Eval:
2021-12-14 02:39:16,473   Average segmentation loss on validation set: 0.1058
2021-12-14 02:39:17,981 iteration 3230 : loss : 0.055187, loss_ce: 0.017390
 48%|████████████▊              | 190/400 [1:34:14<1:48:36, 31.03s/it]2021-12-14 02:39:19,602 iteration 3231 : loss : 0.069094, loss_ce: 0.012957
2021-12-14 02:39:21,158 iteration 3232 : loss : 0.056535, loss_ce: 0.017030
2021-12-14 02:39:22,741 iteration 3233 : loss : 0.067033, loss_ce: 0.025809
2021-12-14 02:39:24,345 iteration 3234 : loss : 0.055989, loss_ce: 0.013734
2021-12-14 02:39:25,938 iteration 3235 : loss : 0.076196, loss_ce: 0.021191
2021-12-14 02:39:27,457 iteration 3236 : loss : 0.055392, loss_ce: 0.022554
2021-12-14 02:39:29,126 iteration 3237 : loss : 0.067208, loss_ce: 0.023363
2021-12-14 02:39:30,719 iteration 3238 : loss : 0.068856, loss_ce: 0.030807
2021-12-14 02:39:32,304 iteration 3239 : loss : 0.054612, loss_ce: 0.017537
2021-12-14 02:39:33,836 iteration 3240 : loss : 0.068538, loss_ce: 0.017191
2021-12-14 02:39:35,341 iteration 3241 : loss : 0.065020, loss_ce: 0.012805
2021-12-14 02:39:36,926 iteration 3242 : loss : 0.060065, loss_ce: 0.018180
2021-12-14 02:39:38,440 iteration 3243 : loss : 0.058252, loss_ce: 0.016817
2021-12-14 02:39:40,041 iteration 3244 : loss : 0.060871, loss_ce: 0.018954
2021-12-14 02:39:41,582 iteration 3245 : loss : 0.050398, loss_ce: 0.018073
2021-12-14 02:39:43,225 iteration 3246 : loss : 0.076585, loss_ce: 0.034227
2021-12-14 02:39:44,772 iteration 3247 : loss : 0.059693, loss_ce: 0.019228
 48%|████████████▉              | 191/400 [1:34:41<1:43:39, 29.76s/it]2021-12-14 02:39:46,363 iteration 3248 : loss : 0.058911, loss_ce: 0.019534
2021-12-14 02:39:47,892 iteration 3249 : loss : 0.055222, loss_ce: 0.015904
2021-12-14 02:39:49,448 iteration 3250 : loss : 0.054138, loss_ce: 0.016086
2021-12-14 02:39:51,012 iteration 3251 : loss : 0.054038, loss_ce: 0.016702
2021-12-14 02:39:52,597 iteration 3252 : loss : 0.058132, loss_ce: 0.016196
2021-12-14 02:39:54,157 iteration 3253 : loss : 0.053611, loss_ce: 0.017801
2021-12-14 02:39:55,708 iteration 3254 : loss : 0.057293, loss_ce: 0.017973
2021-12-14 02:39:57,202 iteration 3255 : loss : 0.061625, loss_ce: 0.021291
2021-12-14 02:39:58,764 iteration 3256 : loss : 0.051966, loss_ce: 0.016241
2021-12-14 02:40:00,299 iteration 3257 : loss : 0.052611, loss_ce: 0.018732
2021-12-14 02:40:01,885 iteration 3258 : loss : 0.058396, loss_ce: 0.017939
2021-12-14 02:40:03,406 iteration 3259 : loss : 0.068244, loss_ce: 0.022572
2021-12-14 02:40:04,990 iteration 3260 : loss : 0.051584, loss_ce: 0.015985
2021-12-14 02:40:06,532 iteration 3261 : loss : 0.074854, loss_ce: 0.018030
2021-12-14 02:40:08,163 iteration 3262 : loss : 0.060709, loss_ce: 0.019008
2021-12-14 02:40:09,848 iteration 3263 : loss : 0.060849, loss_ce: 0.014021
2021-12-14 02:40:11,438 iteration 3264 : loss : 0.063985, loss_ce: 0.021168
 48%|████████████▉              | 192/400 [1:35:08<1:39:56, 28.83s/it]2021-12-14 02:40:12,995 iteration 3265 : loss : 0.052754, loss_ce: 0.018742
2021-12-14 02:40:14,615 iteration 3266 : loss : 0.055174, loss_ce: 0.019209
2021-12-14 02:40:16,207 iteration 3267 : loss : 0.058688, loss_ce: 0.017567
2021-12-14 02:40:17,739 iteration 3268 : loss : 0.050743, loss_ce: 0.016145
2021-12-14 02:40:19,362 iteration 3269 : loss : 0.066554, loss_ce: 0.025277
2021-12-14 02:40:21,018 iteration 3270 : loss : 0.062125, loss_ce: 0.015640
2021-12-14 02:40:22,645 iteration 3271 : loss : 0.059921, loss_ce: 0.015184
2021-12-14 02:40:24,279 iteration 3272 : loss : 0.061845, loss_ce: 0.020068
2021-12-14 02:40:25,800 iteration 3273 : loss : 0.054407, loss_ce: 0.013691
2021-12-14 02:40:27,368 iteration 3274 : loss : 0.052520, loss_ce: 0.020339
2021-12-14 02:40:29,003 iteration 3275 : loss : 0.064089, loss_ce: 0.013869
2021-12-14 02:40:30,551 iteration 3276 : loss : 0.077320, loss_ce: 0.025491
2021-12-14 02:40:32,153 iteration 3277 : loss : 0.058050, loss_ce: 0.023670
2021-12-14 02:40:33,731 iteration 3278 : loss : 0.062962, loss_ce: 0.020215
2021-12-14 02:40:35,269 iteration 3279 : loss : 0.055961, loss_ce: 0.016643
2021-12-14 02:40:36,831 iteration 3280 : loss : 0.054911, loss_ce: 0.015955
2021-12-14 02:40:38,345 iteration 3281 : loss : 0.050492, loss_ce: 0.012132
 48%|█████████████              | 193/400 [1:35:35<1:37:28, 28.25s/it]2021-12-14 02:40:40,001 iteration 3282 : loss : 0.069140, loss_ce: 0.024209
2021-12-14 02:40:41,571 iteration 3283 : loss : 0.056229, loss_ce: 0.016530
2021-12-14 02:40:43,141 iteration 3284 : loss : 0.061580, loss_ce: 0.021493
2021-12-14 02:40:44,700 iteration 3285 : loss : 0.058906, loss_ce: 0.017096
2021-12-14 02:40:46,258 iteration 3286 : loss : 0.047471, loss_ce: 0.014130
2021-12-14 02:40:47,843 iteration 3287 : loss : 0.071952, loss_ce: 0.021382
2021-12-14 02:40:49,363 iteration 3288 : loss : 0.071351, loss_ce: 0.031396
2021-12-14 02:40:50,891 iteration 3289 : loss : 0.066302, loss_ce: 0.017445
2021-12-14 02:40:52,509 iteration 3290 : loss : 0.055458, loss_ce: 0.013411
2021-12-14 02:40:54,142 iteration 3291 : loss : 0.062057, loss_ce: 0.017522
2021-12-14 02:40:55,738 iteration 3292 : loss : 0.056051, loss_ce: 0.013752
2021-12-14 02:40:57,316 iteration 3293 : loss : 0.060697, loss_ce: 0.018786
2021-12-14 02:40:58,867 iteration 3294 : loss : 0.056717, loss_ce: 0.020148
2021-12-14 02:41:00,533 iteration 3295 : loss : 0.064308, loss_ce: 0.020436
2021-12-14 02:41:02,137 iteration 3296 : loss : 0.065390, loss_ce: 0.016385
2021-12-14 02:41:03,645 iteration 3297 : loss : 0.055004, loss_ce: 0.019352
2021-12-14 02:41:05,263 iteration 3298 : loss : 0.059341, loss_ce: 0.020131
 48%|█████████████              | 194/400 [1:36:02<1:35:37, 27.85s/it]2021-12-14 02:41:06,828 iteration 3299 : loss : 0.056786, loss_ce: 0.019036
2021-12-14 02:41:08,369 iteration 3300 : loss : 0.074731, loss_ce: 0.021187
2021-12-14 02:41:09,997 iteration 3301 : loss : 0.059798, loss_ce: 0.022197
2021-12-14 02:41:11,568 iteration 3302 : loss : 0.062618, loss_ce: 0.022199
2021-12-14 02:41:13,121 iteration 3303 : loss : 0.052822, loss_ce: 0.018428
2021-12-14 02:41:14,699 iteration 3304 : loss : 0.062764, loss_ce: 0.018993
2021-12-14 02:41:16,296 iteration 3305 : loss : 0.055757, loss_ce: 0.015564
2021-12-14 02:41:17,915 iteration 3306 : loss : 0.065028, loss_ce: 0.020783
2021-12-14 02:41:19,460 iteration 3307 : loss : 0.057735, loss_ce: 0.016451
2021-12-14 02:41:21,039 iteration 3308 : loss : 0.067755, loss_ce: 0.023973
2021-12-14 02:41:22,606 iteration 3309 : loss : 0.067436, loss_ce: 0.015690
2021-12-14 02:41:24,255 iteration 3310 : loss : 0.096868, loss_ce: 0.039118
2021-12-14 02:41:25,929 iteration 3311 : loss : 0.052885, loss_ce: 0.015736
2021-12-14 02:41:27,456 iteration 3312 : loss : 0.059350, loss_ce: 0.016246
2021-12-14 02:41:28,995 iteration 3313 : loss : 0.053110, loss_ce: 0.016370
2021-12-14 02:41:30,641 iteration 3314 : loss : 0.051197, loss_ce: 0.014776
2021-12-14 02:41:30,641 Training Data Eval:
2021-12-14 02:41:38,836   Average segmentation loss on training set: 0.0464
2021-12-14 02:41:38,837 Validation Data Eval:
2021-12-14 02:41:41,647   Average segmentation loss on validation set: 0.0987
2021-12-14 02:41:43,171 iteration 3315 : loss : 0.051432, loss_ce: 0.018702
 49%|█████████████▏             | 195/400 [1:36:40<1:45:28, 30.87s/it]2021-12-14 02:41:44,755 iteration 3316 : loss : 0.045859, loss_ce: 0.013542
2021-12-14 02:41:46,298 iteration 3317 : loss : 0.061824, loss_ce: 0.019534
2021-12-14 02:41:47,961 iteration 3318 : loss : 0.073644, loss_ce: 0.024294
2021-12-14 02:41:49,506 iteration 3319 : loss : 0.058677, loss_ce: 0.017171
2021-12-14 02:41:51,061 iteration 3320 : loss : 0.048377, loss_ce: 0.013978
2021-12-14 02:41:52,638 iteration 3321 : loss : 0.048913, loss_ce: 0.012155
2021-12-14 02:41:54,218 iteration 3322 : loss : 0.070878, loss_ce: 0.026287
2021-12-14 02:41:55,743 iteration 3323 : loss : 0.057452, loss_ce: 0.016288
2021-12-14 02:41:57,393 iteration 3324 : loss : 0.068721, loss_ce: 0.024980
2021-12-14 02:41:58,920 iteration 3325 : loss : 0.061092, loss_ce: 0.017745
2021-12-14 02:42:00,526 iteration 3326 : loss : 0.056786, loss_ce: 0.018484
2021-12-14 02:42:02,202 iteration 3327 : loss : 0.066991, loss_ce: 0.020214
2021-12-14 02:42:03,788 iteration 3328 : loss : 0.061656, loss_ce: 0.019400
2021-12-14 02:42:05,332 iteration 3329 : loss : 0.061980, loss_ce: 0.020981
2021-12-14 02:42:06,899 iteration 3330 : loss : 0.058469, loss_ce: 0.015430
2021-12-14 02:42:08,494 iteration 3331 : loss : 0.052550, loss_ce: 0.017667
2021-12-14 02:42:09,988 iteration 3332 : loss : 0.048907, loss_ce: 0.016941
 49%|█████████████▏             | 196/400 [1:37:06<1:40:50, 29.66s/it]2021-12-14 02:42:11,599 iteration 3333 : loss : 0.051307, loss_ce: 0.016176
2021-12-14 02:42:13,189 iteration 3334 : loss : 0.050736, loss_ce: 0.017461
2021-12-14 02:42:14,686 iteration 3335 : loss : 0.049821, loss_ce: 0.017462
2021-12-14 02:42:16,258 iteration 3336 : loss : 0.064290, loss_ce: 0.020896
2021-12-14 02:42:17,882 iteration 3337 : loss : 0.065951, loss_ce: 0.023520
2021-12-14 02:42:19,550 iteration 3338 : loss : 0.061121, loss_ce: 0.023655
2021-12-14 02:42:21,118 iteration 3339 : loss : 0.065464, loss_ce: 0.016558
2021-12-14 02:42:22,662 iteration 3340 : loss : 0.053086, loss_ce: 0.013231
2021-12-14 02:42:24,231 iteration 3341 : loss : 0.051058, loss_ce: 0.016284
2021-12-14 02:42:25,852 iteration 3342 : loss : 0.078649, loss_ce: 0.030445
2021-12-14 02:42:27,456 iteration 3343 : loss : 0.057777, loss_ce: 0.018551
2021-12-14 02:42:29,050 iteration 3344 : loss : 0.059417, loss_ce: 0.016042
2021-12-14 02:42:30,609 iteration 3345 : loss : 0.048979, loss_ce: 0.013292
2021-12-14 02:42:32,197 iteration 3346 : loss : 0.057221, loss_ce: 0.020065
2021-12-14 02:42:33,810 iteration 3347 : loss : 0.066962, loss_ce: 0.015878
2021-12-14 02:42:35,473 iteration 3348 : loss : 0.060639, loss_ce: 0.016819
2021-12-14 02:42:37,071 iteration 3349 : loss : 0.058331, loss_ce: 0.016650
 49%|█████████████▎             | 197/400 [1:37:34<1:37:43, 28.88s/it]2021-12-14 02:42:38,663 iteration 3350 : loss : 0.061324, loss_ce: 0.021933
2021-12-14 02:42:40,189 iteration 3351 : loss : 0.057117, loss_ce: 0.017866
2021-12-14 02:42:41,738 iteration 3352 : loss : 0.052926, loss_ce: 0.015358
2021-12-14 02:42:43,329 iteration 3353 : loss : 0.053706, loss_ce: 0.016462
2021-12-14 02:42:44,917 iteration 3354 : loss : 0.062841, loss_ce: 0.017411
2021-12-14 02:42:46,567 iteration 3355 : loss : 0.062040, loss_ce: 0.027272
2021-12-14 02:42:48,189 iteration 3356 : loss : 0.064379, loss_ce: 0.015493
2021-12-14 02:42:49,827 iteration 3357 : loss : 0.058740, loss_ce: 0.014562
2021-12-14 02:42:51,477 iteration 3358 : loss : 0.058245, loss_ce: 0.014851
2021-12-14 02:42:53,085 iteration 3359 : loss : 0.062718, loss_ce: 0.021078
2021-12-14 02:42:54,751 iteration 3360 : loss : 0.064149, loss_ce: 0.022963
2021-12-14 02:42:56,286 iteration 3361 : loss : 0.068952, loss_ce: 0.016856
2021-12-14 02:42:57,824 iteration 3362 : loss : 0.056215, loss_ce: 0.018722
2021-12-14 02:42:59,355 iteration 3363 : loss : 0.049728, loss_ce: 0.017457
2021-12-14 02:43:00,949 iteration 3364 : loss : 0.060431, loss_ce: 0.018193
2021-12-14 02:43:02,482 iteration 3365 : loss : 0.052860, loss_ce: 0.021650
2021-12-14 02:43:04,044 iteration 3366 : loss : 0.055813, loss_ce: 0.016792
 50%|█████████████▎             | 198/400 [1:38:01<1:35:18, 28.31s/it]2021-12-14 02:43:05,671 iteration 3367 : loss : 0.056435, loss_ce: 0.015239
2021-12-14 02:43:07,238 iteration 3368 : loss : 0.061855, loss_ce: 0.025880
2021-12-14 02:43:08,838 iteration 3369 : loss : 0.059616, loss_ce: 0.015512
2021-12-14 02:43:10,444 iteration 3370 : loss : 0.061354, loss_ce: 0.021438
2021-12-14 02:43:11,941 iteration 3371 : loss : 0.044179, loss_ce: 0.012995
2021-12-14 02:43:13,507 iteration 3372 : loss : 0.070545, loss_ce: 0.028935
2021-12-14 02:43:15,078 iteration 3373 : loss : 0.052690, loss_ce: 0.018635
2021-12-14 02:43:16,600 iteration 3374 : loss : 0.052030, loss_ce: 0.018800
2021-12-14 02:43:18,132 iteration 3375 : loss : 0.055326, loss_ce: 0.017888
2021-12-14 02:43:19,674 iteration 3376 : loss : 0.063181, loss_ce: 0.019881
2021-12-14 02:43:21,292 iteration 3377 : loss : 0.073808, loss_ce: 0.019518
2021-12-14 02:43:22,863 iteration 3378 : loss : 0.056704, loss_ce: 0.017747
2021-12-14 02:43:24,358 iteration 3379 : loss : 0.057407, loss_ce: 0.020759
2021-12-14 02:43:25,992 iteration 3380 : loss : 0.070234, loss_ce: 0.024189
2021-12-14 02:43:27,503 iteration 3381 : loss : 0.080100, loss_ce: 0.013538
2021-12-14 02:43:29,079 iteration 3382 : loss : 0.070786, loss_ce: 0.022419
2021-12-14 02:43:30,637 iteration 3383 : loss : 0.059486, loss_ce: 0.019247
 50%|█████████████▍             | 199/400 [1:38:27<1:33:07, 27.80s/it]2021-12-14 02:43:32,234 iteration 3384 : loss : 0.054946, loss_ce: 0.014408
2021-12-14 02:43:33,861 iteration 3385 : loss : 0.052635, loss_ce: 0.017316
2021-12-14 02:43:35,496 iteration 3386 : loss : 0.058475, loss_ce: 0.021568
2021-12-14 02:43:37,105 iteration 3387 : loss : 0.058457, loss_ce: 0.019318
2021-12-14 02:43:38,618 iteration 3388 : loss : 0.057835, loss_ce: 0.018564
2021-12-14 02:43:40,214 iteration 3389 : loss : 0.061069, loss_ce: 0.021906
2021-12-14 02:43:41,719 iteration 3390 : loss : 0.060448, loss_ce: 0.013731
2021-12-14 02:43:43,387 iteration 3391 : loss : 0.060515, loss_ce: 0.016566
2021-12-14 02:43:44,996 iteration 3392 : loss : 0.052049, loss_ce: 0.016918
2021-12-14 02:43:46,599 iteration 3393 : loss : 0.055399, loss_ce: 0.018133
2021-12-14 02:43:48,086 iteration 3394 : loss : 0.053618, loss_ce: 0.016454
2021-12-14 02:43:49,766 iteration 3395 : loss : 0.080489, loss_ce: 0.025194
2021-12-14 02:43:51,364 iteration 3396 : loss : 0.063187, loss_ce: 0.019934
2021-12-14 02:43:52,925 iteration 3397 : loss : 0.051931, loss_ce: 0.016366
2021-12-14 02:43:54,542 iteration 3398 : loss : 0.054324, loss_ce: 0.015374
2021-12-14 02:43:56,139 iteration 3399 : loss : 0.052480, loss_ce: 0.017938
2021-12-14 02:43:56,139 Training Data Eval:
2021-12-14 02:44:04,314   Average segmentation loss on training set: 0.0452
2021-12-14 02:44:04,315 Validation Data Eval:
2021-12-14 02:44:07,108   Average segmentation loss on validation set: 0.0985
2021-12-14 02:44:08,679 iteration 3400 : loss : 0.060869, loss_ce: 0.015078
 50%|█████████████▌             | 200/400 [1:39:05<1:42:52, 30.86s/it]2021-12-14 02:44:10,423 iteration 3401 : loss : 0.063244, loss_ce: 0.020700
2021-12-14 02:44:12,061 iteration 3402 : loss : 0.067742, loss_ce: 0.021968
2021-12-14 02:44:13,621 iteration 3403 : loss : 0.064819, loss_ce: 0.025420
2021-12-14 02:44:15,181 iteration 3404 : loss : 0.053387, loss_ce: 0.014316
2021-12-14 02:44:16,743 iteration 3405 : loss : 0.064291, loss_ce: 0.021282
2021-12-14 02:44:18,372 iteration 3406 : loss : 0.067118, loss_ce: 0.022101
2021-12-14 02:44:19,959 iteration 3407 : loss : 0.059179, loss_ce: 0.020433
2021-12-14 02:44:21,555 iteration 3408 : loss : 0.057241, loss_ce: 0.018304
2021-12-14 02:44:23,165 iteration 3409 : loss : 0.067305, loss_ce: 0.024681
2021-12-14 02:44:24,761 iteration 3410 : loss : 0.058713, loss_ce: 0.018323
2021-12-14 02:44:26,396 iteration 3411 : loss : 0.054824, loss_ce: 0.017745
2021-12-14 02:44:27,920 iteration 3412 : loss : 0.058167, loss_ce: 0.016257
2021-12-14 02:44:29,430 iteration 3413 : loss : 0.048709, loss_ce: 0.017519
2021-12-14 02:44:31,024 iteration 3414 : loss : 0.066955, loss_ce: 0.015006
2021-12-14 02:44:32,642 iteration 3415 : loss : 0.054452, loss_ce: 0.015728
2021-12-14 02:44:34,268 iteration 3416 : loss : 0.051099, loss_ce: 0.013175
2021-12-14 02:44:35,935 iteration 3417 : loss : 0.075288, loss_ce: 0.025702
 50%|█████████████▌             | 201/400 [1:39:32<1:38:46, 29.78s/it]2021-12-14 02:44:37,568 iteration 3418 : loss : 0.051517, loss_ce: 0.018659
2021-12-14 02:44:39,179 iteration 3419 : loss : 0.054109, loss_ce: 0.014175
2021-12-14 02:44:40,851 iteration 3420 : loss : 0.067304, loss_ce: 0.017792
2021-12-14 02:44:42,458 iteration 3421 : loss : 0.064266, loss_ce: 0.020233
2021-12-14 02:44:43,984 iteration 3422 : loss : 0.047947, loss_ce: 0.013047
2021-12-14 02:44:45,560 iteration 3423 : loss : 0.052397, loss_ce: 0.017307
2021-12-14 02:44:47,139 iteration 3424 : loss : 0.060753, loss_ce: 0.023234
2021-12-14 02:44:48,667 iteration 3425 : loss : 0.056707, loss_ce: 0.022247
2021-12-14 02:44:50,252 iteration 3426 : loss : 0.057135, loss_ce: 0.016869
2021-12-14 02:44:51,860 iteration 3427 : loss : 0.058192, loss_ce: 0.017928
2021-12-14 02:44:53,468 iteration 3428 : loss : 0.057104, loss_ce: 0.018897
2021-12-14 02:44:55,101 iteration 3429 : loss : 0.054260, loss_ce: 0.017509
2021-12-14 02:44:56,736 iteration 3430 : loss : 0.066256, loss_ce: 0.023501
2021-12-14 02:44:58,242 iteration 3431 : loss : 0.053073, loss_ce: 0.017692
2021-12-14 02:44:59,782 iteration 3432 : loss : 0.058525, loss_ce: 0.015098
2021-12-14 02:45:01,321 iteration 3433 : loss : 0.053694, loss_ce: 0.016264
2021-12-14 02:45:02,946 iteration 3434 : loss : 0.064835, loss_ce: 0.019630
 50%|█████████████▋             | 202/400 [1:39:59<1:35:32, 28.95s/it]2021-12-14 02:45:04,485 iteration 3435 : loss : 0.055692, loss_ce: 0.015522
2021-12-14 02:45:06,029 iteration 3436 : loss : 0.047246, loss_ce: 0.014470
2021-12-14 02:45:07,702 iteration 3437 : loss : 0.057136, loss_ce: 0.020917
2021-12-14 02:45:09,348 iteration 3438 : loss : 0.050372, loss_ce: 0.017759
2021-12-14 02:45:10,976 iteration 3439 : loss : 0.058557, loss_ce: 0.019939
2021-12-14 02:45:12,526 iteration 3440 : loss : 0.050892, loss_ce: 0.015544
2021-12-14 02:45:14,121 iteration 3441 : loss : 0.061222, loss_ce: 0.020865
2021-12-14 02:45:15,814 iteration 3442 : loss : 0.075792, loss_ce: 0.020247
2021-12-14 02:45:17,444 iteration 3443 : loss : 0.055456, loss_ce: 0.015384
2021-12-14 02:45:19,072 iteration 3444 : loss : 0.060525, loss_ce: 0.021072
2021-12-14 02:45:20,657 iteration 3445 : loss : 0.072518, loss_ce: 0.020192
2021-12-14 02:45:22,230 iteration 3446 : loss : 0.060537, loss_ce: 0.022913
2021-12-14 02:45:23,791 iteration 3447 : loss : 0.056074, loss_ce: 0.016137
2021-12-14 02:45:25,421 iteration 3448 : loss : 0.071785, loss_ce: 0.014468
2021-12-14 02:45:27,026 iteration 3449 : loss : 0.060141, loss_ce: 0.022245
2021-12-14 02:45:28,609 iteration 3450 : loss : 0.062545, loss_ce: 0.023356
2021-12-14 02:45:30,277 iteration 3451 : loss : 0.064561, loss_ce: 0.019131
 51%|█████████████▋             | 203/400 [1:40:27<1:33:27, 28.46s/it]2021-12-14 02:45:31,900 iteration 3452 : loss : 0.057314, loss_ce: 0.019074
2021-12-14 02:45:33,467 iteration 3453 : loss : 0.059551, loss_ce: 0.019163
2021-12-14 02:45:35,013 iteration 3454 : loss : 0.048940, loss_ce: 0.013390
2021-12-14 02:45:36,669 iteration 3455 : loss : 0.066541, loss_ce: 0.024463
2021-12-14 02:45:38,209 iteration 3456 : loss : 0.048987, loss_ce: 0.011874
2021-12-14 02:45:39,884 iteration 3457 : loss : 0.056222, loss_ce: 0.015229
2021-12-14 02:45:41,502 iteration 3458 : loss : 0.057690, loss_ce: 0.018309
2021-12-14 02:45:43,082 iteration 3459 : loss : 0.056535, loss_ce: 0.018888
2021-12-14 02:45:44,655 iteration 3460 : loss : 0.057555, loss_ce: 0.019284
2021-12-14 02:45:46,231 iteration 3461 : loss : 0.054106, loss_ce: 0.016389
2021-12-14 02:45:47,791 iteration 3462 : loss : 0.056653, loss_ce: 0.020744
2021-12-14 02:45:49,415 iteration 3463 : loss : 0.053391, loss_ce: 0.015200
2021-12-14 02:45:50,949 iteration 3464 : loss : 0.048936, loss_ce: 0.014508
2021-12-14 02:45:52,583 iteration 3465 : loss : 0.059505, loss_ce: 0.016303
2021-12-14 02:45:54,180 iteration 3466 : loss : 0.049596, loss_ce: 0.013753
2021-12-14 02:45:55,764 iteration 3467 : loss : 0.063234, loss_ce: 0.026195
2021-12-14 02:45:57,335 iteration 3468 : loss : 0.062674, loss_ce: 0.021424
 51%|█████████████▊             | 204/400 [1:40:54<1:31:36, 28.04s/it]2021-12-14 02:45:58,919 iteration 3469 : loss : 0.061715, loss_ce: 0.014932
2021-12-14 02:46:00,548 iteration 3470 : loss : 0.066026, loss_ce: 0.015848
2021-12-14 02:46:02,053 iteration 3471 : loss : 0.056387, loss_ce: 0.016762
2021-12-14 02:46:03,656 iteration 3472 : loss : 0.056387, loss_ce: 0.022700
2021-12-14 02:46:05,351 iteration 3473 : loss : 0.062469, loss_ce: 0.019492
2021-12-14 02:46:06,934 iteration 3474 : loss : 0.052752, loss_ce: 0.013575
2021-12-14 02:46:08,586 iteration 3475 : loss : 0.085797, loss_ce: 0.019382
2021-12-14 02:46:10,139 iteration 3476 : loss : 0.056710, loss_ce: 0.014496
2021-12-14 02:46:11,751 iteration 3477 : loss : 0.062054, loss_ce: 0.016318
2021-12-14 02:46:13,332 iteration 3478 : loss : 0.051747, loss_ce: 0.015726
2021-12-14 02:46:14,874 iteration 3479 : loss : 0.059239, loss_ce: 0.020075
2021-12-14 02:46:16,371 iteration 3480 : loss : 0.059016, loss_ce: 0.019692
2021-12-14 02:46:17,943 iteration 3481 : loss : 0.055693, loss_ce: 0.016712
2021-12-14 02:46:19,520 iteration 3482 : loss : 0.068404, loss_ce: 0.021687
2021-12-14 02:46:21,190 iteration 3483 : loss : 0.058472, loss_ce: 0.022344
2021-12-14 02:46:22,684 iteration 3484 : loss : 0.058001, loss_ce: 0.019078
2021-12-14 02:46:22,684 Training Data Eval:
2021-12-14 02:46:30,867   Average segmentation loss on training set: 0.0445
2021-12-14 02:46:30,867 Validation Data Eval:
2021-12-14 02:46:33,672   Average segmentation loss on validation set: 0.1014
2021-12-14 02:46:35,338 iteration 3485 : loss : 0.076619, loss_ce: 0.031617
 51%|█████████████▊             | 205/400 [1:41:32<1:40:51, 31.03s/it]2021-12-14 02:46:36,957 iteration 3486 : loss : 0.054768, loss_ce: 0.018186
2021-12-14 02:46:38,481 iteration 3487 : loss : 0.051029, loss_ce: 0.017922
2021-12-14 02:46:40,036 iteration 3488 : loss : 0.059694, loss_ce: 0.018124
2021-12-14 02:46:41,606 iteration 3489 : loss : 0.064048, loss_ce: 0.020473
2021-12-14 02:46:43,214 iteration 3490 : loss : 0.062938, loss_ce: 0.019413
2021-12-14 02:46:44,856 iteration 3491 : loss : 0.061022, loss_ce: 0.021029
2021-12-14 02:46:46,375 iteration 3492 : loss : 0.064942, loss_ce: 0.018691
2021-12-14 02:46:48,060 iteration 3493 : loss : 0.065984, loss_ce: 0.022496
2021-12-14 02:46:49,664 iteration 3494 : loss : 0.053124, loss_ce: 0.014355
2021-12-14 02:46:51,233 iteration 3495 : loss : 0.064570, loss_ce: 0.017563
2021-12-14 02:46:52,838 iteration 3496 : loss : 0.054246, loss_ce: 0.018487
2021-12-14 02:46:54,444 iteration 3497 : loss : 0.066795, loss_ce: 0.019299
2021-12-14 02:46:56,174 iteration 3498 : loss : 0.056469, loss_ce: 0.016419
2021-12-14 02:46:57,726 iteration 3499 : loss : 0.053318, loss_ce: 0.016807
2021-12-14 02:46:59,224 iteration 3500 : loss : 0.046155, loss_ce: 0.012602
2021-12-14 02:47:00,757 iteration 3501 : loss : 0.053268, loss_ce: 0.013998
2021-12-14 02:47:02,347 iteration 3502 : loss : 0.059742, loss_ce: 0.018782
 52%|█████████████▉             | 206/400 [1:41:59<1:36:26, 29.83s/it]2021-12-14 02:47:03,996 iteration 3503 : loss : 0.055253, loss_ce: 0.016163
2021-12-14 02:47:05,588 iteration 3504 : loss : 0.056275, loss_ce: 0.016037
2021-12-14 02:47:07,070 iteration 3505 : loss : 0.050691, loss_ce: 0.017650
2021-12-14 02:47:08,666 iteration 3506 : loss : 0.063006, loss_ce: 0.017165
2021-12-14 02:47:10,227 iteration 3507 : loss : 0.061546, loss_ce: 0.017325
2021-12-14 02:47:11,916 iteration 3508 : loss : 0.062185, loss_ce: 0.022401
2021-12-14 02:47:13,513 iteration 3509 : loss : 0.050051, loss_ce: 0.014320
2021-12-14 02:47:15,039 iteration 3510 : loss : 0.056721, loss_ce: 0.020265
2021-12-14 02:47:16,556 iteration 3511 : loss : 0.047577, loss_ce: 0.017992
2021-12-14 02:47:18,199 iteration 3512 : loss : 0.061363, loss_ce: 0.015172
2021-12-14 02:47:19,782 iteration 3513 : loss : 0.051602, loss_ce: 0.012728
2021-12-14 02:47:21,475 iteration 3514 : loss : 0.067797, loss_ce: 0.028385
2021-12-14 02:47:23,033 iteration 3515 : loss : 0.053217, loss_ce: 0.014399
2021-12-14 02:47:24,582 iteration 3516 : loss : 0.048664, loss_ce: 0.015523
2021-12-14 02:47:26,137 iteration 3517 : loss : 0.052621, loss_ce: 0.016466
2021-12-14 02:47:27,693 iteration 3518 : loss : 0.060052, loss_ce: 0.024765
2021-12-14 02:47:29,288 iteration 3519 : loss : 0.055606, loss_ce: 0.015908
 52%|█████████████▉             | 207/400 [1:42:26<1:33:09, 28.96s/it]2021-12-14 02:47:30,944 iteration 3520 : loss : 0.058389, loss_ce: 0.019369
2021-12-14 02:47:32,498 iteration 3521 : loss : 0.065326, loss_ce: 0.024341
2021-12-14 02:47:34,013 iteration 3522 : loss : 0.053023, loss_ce: 0.020463
2021-12-14 02:47:35,576 iteration 3523 : loss : 0.050791, loss_ce: 0.014973
2021-12-14 02:47:37,189 iteration 3524 : loss : 0.054474, loss_ce: 0.019234
2021-12-14 02:47:38,867 iteration 3525 : loss : 0.063326, loss_ce: 0.020870
2021-12-14 02:47:40,466 iteration 3526 : loss : 0.055264, loss_ce: 0.017679
2021-12-14 02:47:42,088 iteration 3527 : loss : 0.063888, loss_ce: 0.016350
2021-12-14 02:47:43,802 iteration 3528 : loss : 0.058538, loss_ce: 0.018685
2021-12-14 02:47:45,422 iteration 3529 : loss : 0.055147, loss_ce: 0.011909
2021-12-14 02:47:47,040 iteration 3530 : loss : 0.046352, loss_ce: 0.015759
2021-12-14 02:47:48,579 iteration 3531 : loss : 0.065634, loss_ce: 0.017284
2021-12-14 02:47:50,236 iteration 3532 : loss : 0.061862, loss_ce: 0.024160
2021-12-14 02:47:51,799 iteration 3533 : loss : 0.054382, loss_ce: 0.013066
2021-12-14 02:47:53,405 iteration 3534 : loss : 0.067448, loss_ce: 0.023070
2021-12-14 02:47:55,057 iteration 3535 : loss : 0.059193, loss_ce: 0.017881
2021-12-14 02:47:56,680 iteration 3536 : loss : 0.061939, loss_ce: 0.021525
 52%|██████████████             | 208/400 [1:42:53<1:31:09, 28.49s/it]2021-12-14 02:47:58,242 iteration 3537 : loss : 0.053107, loss_ce: 0.018178
2021-12-14 02:47:59,749 iteration 3538 : loss : 0.061004, loss_ce: 0.020651
2021-12-14 02:48:01,273 iteration 3539 : loss : 0.044941, loss_ce: 0.015032
2021-12-14 02:48:02,744 iteration 3540 : loss : 0.049418, loss_ce: 0.011314
2021-12-14 02:48:04,390 iteration 3541 : loss : 0.067428, loss_ce: 0.023458
2021-12-14 02:48:05,970 iteration 3542 : loss : 0.055852, loss_ce: 0.019775
2021-12-14 02:48:07,666 iteration 3543 : loss : 0.078796, loss_ce: 0.020251
2021-12-14 02:48:09,179 iteration 3544 : loss : 0.045929, loss_ce: 0.014718
2021-12-14 02:48:10,757 iteration 3545 : loss : 0.053453, loss_ce: 0.019464
2021-12-14 02:48:12,272 iteration 3546 : loss : 0.049088, loss_ce: 0.015107
2021-12-14 02:48:13,855 iteration 3547 : loss : 0.055808, loss_ce: 0.020901
2021-12-14 02:48:15,385 iteration 3548 : loss : 0.054970, loss_ce: 0.015338
2021-12-14 02:48:16,974 iteration 3549 : loss : 0.056769, loss_ce: 0.017385
2021-12-14 02:48:18,595 iteration 3550 : loss : 0.056604, loss_ce: 0.020102
2021-12-14 02:48:20,242 iteration 3551 : loss : 0.069561, loss_ce: 0.020830
2021-12-14 02:48:21,885 iteration 3552 : loss : 0.081419, loss_ce: 0.024431
2021-12-14 02:48:23,528 iteration 3553 : loss : 0.065893, loss_ce: 0.024533
 52%|██████████████             | 209/400 [1:43:20<1:29:07, 28.00s/it]2021-12-14 02:48:25,180 iteration 3554 : loss : 0.062194, loss_ce: 0.024645
2021-12-14 02:48:26,740 iteration 3555 : loss : 0.054337, loss_ce: 0.016058
2021-12-14 02:48:28,299 iteration 3556 : loss : 0.055682, loss_ce: 0.020591
2021-12-14 02:48:29,968 iteration 3557 : loss : 0.066358, loss_ce: 0.016893
2021-12-14 02:48:31,503 iteration 3558 : loss : 0.062076, loss_ce: 0.014941
2021-12-14 02:48:33,068 iteration 3559 : loss : 0.060867, loss_ce: 0.015936
2021-12-14 02:48:34,541 iteration 3560 : loss : 0.050671, loss_ce: 0.019579
2021-12-14 02:48:36,188 iteration 3561 : loss : 0.059611, loss_ce: 0.018378
2021-12-14 02:48:37,734 iteration 3562 : loss : 0.050260, loss_ce: 0.015606
2021-12-14 02:48:39,344 iteration 3563 : loss : 0.053775, loss_ce: 0.015493
2021-12-14 02:48:40,935 iteration 3564 : loss : 0.057559, loss_ce: 0.016789
2021-12-14 02:48:42,623 iteration 3565 : loss : 0.068469, loss_ce: 0.019081
2021-12-14 02:48:44,213 iteration 3566 : loss : 0.053042, loss_ce: 0.016231
2021-12-14 02:48:45,876 iteration 3567 : loss : 0.063363, loss_ce: 0.023187
2021-12-14 02:48:47,521 iteration 3568 : loss : 0.056313, loss_ce: 0.016531
2021-12-14 02:48:49,161 iteration 3569 : loss : 0.092155, loss_ce: 0.016734
2021-12-14 02:48:49,161 Training Data Eval:
2021-12-14 02:48:57,344   Average segmentation loss on training set: 0.0436
2021-12-14 02:48:57,344 Validation Data Eval:
2021-12-14 02:49:00,144   Average segmentation loss on validation set: 0.0928
2021-12-14 02:49:01,747 iteration 3570 : loss : 0.058183, loss_ce: 0.017998
 52%|██████████████▏            | 210/400 [1:43:58<1:38:22, 31.06s/it]2021-12-14 02:49:03,380 iteration 3571 : loss : 0.058206, loss_ce: 0.020859
2021-12-14 02:49:04,975 iteration 3572 : loss : 0.049108, loss_ce: 0.012333
2021-12-14 02:49:06,554 iteration 3573 : loss : 0.060337, loss_ce: 0.019684
2021-12-14 02:49:08,104 iteration 3574 : loss : 0.049068, loss_ce: 0.015895
2021-12-14 02:49:09,659 iteration 3575 : loss : 0.055060, loss_ce: 0.017771
2021-12-14 02:49:11,249 iteration 3576 : loss : 0.062288, loss_ce: 0.019037
2021-12-14 02:49:12,880 iteration 3577 : loss : 0.048561, loss_ce: 0.017277
2021-12-14 02:49:14,517 iteration 3578 : loss : 0.060479, loss_ce: 0.020162
2021-12-14 02:49:16,080 iteration 3579 : loss : 0.051862, loss_ce: 0.015606
2021-12-14 02:49:17,695 iteration 3580 : loss : 0.053078, loss_ce: 0.013461
2021-12-14 02:49:19,239 iteration 3581 : loss : 0.084066, loss_ce: 0.018061
2021-12-14 02:49:20,810 iteration 3582 : loss : 0.049822, loss_ce: 0.016293
2021-12-14 02:49:22,425 iteration 3583 : loss : 0.055970, loss_ce: 0.016634
2021-12-14 02:49:23,968 iteration 3584 : loss : 0.054687, loss_ce: 0.019439
2021-12-14 02:49:25,529 iteration 3585 : loss : 0.047138, loss_ce: 0.013879
2021-12-14 02:49:27,046 iteration 3586 : loss : 0.056018, loss_ce: 0.018860
2021-12-14 02:49:28,612 iteration 3587 : loss : 0.069460, loss_ce: 0.027464
 53%|██████████████▏            | 211/400 [1:44:25<1:33:52, 29.80s/it]2021-12-14 02:49:30,156 iteration 3588 : loss : 0.054644, loss_ce: 0.014647
2021-12-14 02:49:31,766 iteration 3589 : loss : 0.064509, loss_ce: 0.019652
2021-12-14 02:49:33,338 iteration 3590 : loss : 0.056102, loss_ce: 0.018862
2021-12-14 02:49:34,894 iteration 3591 : loss : 0.051311, loss_ce: 0.013455
2021-12-14 02:49:36,524 iteration 3592 : loss : 0.053718, loss_ce: 0.017621
2021-12-14 02:49:38,117 iteration 3593 : loss : 0.064702, loss_ce: 0.015166
2021-12-14 02:49:39,707 iteration 3594 : loss : 0.050082, loss_ce: 0.012492
2021-12-14 02:49:41,420 iteration 3595 : loss : 0.083752, loss_ce: 0.017209
2021-12-14 02:49:42,937 iteration 3596 : loss : 0.051553, loss_ce: 0.018222
2021-12-14 02:49:44,599 iteration 3597 : loss : 0.058858, loss_ce: 0.017992
2021-12-14 02:49:46,179 iteration 3598 : loss : 0.060598, loss_ce: 0.023141
2021-12-14 02:49:47,774 iteration 3599 : loss : 0.062279, loss_ce: 0.020692
2021-12-14 02:49:49,334 iteration 3600 : loss : 0.052604, loss_ce: 0.019762
2021-12-14 02:49:50,909 iteration 3601 : loss : 0.061795, loss_ce: 0.022169
2021-12-14 02:49:52,460 iteration 3602 : loss : 0.064596, loss_ce: 0.021949
2021-12-14 02:49:53,993 iteration 3603 : loss : 0.053701, loss_ce: 0.016409
2021-12-14 02:49:55,517 iteration 3604 : loss : 0.047548, loss_ce: 0.014656
 53%|██████████████▎            | 212/400 [1:44:52<1:30:40, 28.94s/it]2021-12-14 02:49:57,137 iteration 3605 : loss : 0.052506, loss_ce: 0.018006
2021-12-14 02:49:58,709 iteration 3606 : loss : 0.061379, loss_ce: 0.019358
2021-12-14 02:50:00,218 iteration 3607 : loss : 0.050034, loss_ce: 0.014053
2021-12-14 02:50:01,733 iteration 3608 : loss : 0.061526, loss_ce: 0.021163
2021-12-14 02:50:03,331 iteration 3609 : loss : 0.054263, loss_ce: 0.014210
2021-12-14 02:50:04,872 iteration 3610 : loss : 0.063423, loss_ce: 0.022793
2021-12-14 02:50:06,474 iteration 3611 : loss : 0.061863, loss_ce: 0.023866
2021-12-14 02:50:08,099 iteration 3612 : loss : 0.053492, loss_ce: 0.015498
2021-12-14 02:50:09,683 iteration 3613 : loss : 0.062118, loss_ce: 0.015647
2021-12-14 02:50:11,304 iteration 3614 : loss : 0.053482, loss_ce: 0.014410
2021-12-14 02:50:12,852 iteration 3615 : loss : 0.060429, loss_ce: 0.017852
2021-12-14 02:50:14,503 iteration 3616 : loss : 0.053983, loss_ce: 0.011386
2021-12-14 02:50:16,061 iteration 3617 : loss : 0.058147, loss_ce: 0.021300
2021-12-14 02:50:17,628 iteration 3618 : loss : 0.053635, loss_ce: 0.019753
2021-12-14 02:50:19,188 iteration 3619 : loss : 0.050144, loss_ce: 0.016853
2021-12-14 02:50:20,820 iteration 3620 : loss : 0.057682, loss_ce: 0.019420
2021-12-14 02:50:22,390 iteration 3621 : loss : 0.059013, loss_ce: 0.021063
 53%|██████████████▍            | 213/400 [1:45:19<1:28:14, 28.31s/it]2021-12-14 02:50:24,070 iteration 3622 : loss : 0.059661, loss_ce: 0.018640
2021-12-14 02:50:25,649 iteration 3623 : loss : 0.059152, loss_ce: 0.021284
2021-12-14 02:50:27,297 iteration 3624 : loss : 0.048260, loss_ce: 0.013220
2021-12-14 02:50:28,944 iteration 3625 : loss : 0.078098, loss_ce: 0.027585
2021-12-14 02:50:30,527 iteration 3626 : loss : 0.060294, loss_ce: 0.018013
2021-12-14 02:50:32,147 iteration 3627 : loss : 0.064505, loss_ce: 0.026541
2021-12-14 02:50:33,746 iteration 3628 : loss : 0.058694, loss_ce: 0.015688
2021-12-14 02:50:35,407 iteration 3629 : loss : 0.056224, loss_ce: 0.018573
2021-12-14 02:50:36,991 iteration 3630 : loss : 0.051487, loss_ce: 0.017344
2021-12-14 02:50:38,502 iteration 3631 : loss : 0.048565, loss_ce: 0.016598
2021-12-14 02:50:40,017 iteration 3632 : loss : 0.047311, loss_ce: 0.015229
2021-12-14 02:50:41,650 iteration 3633 : loss : 0.063365, loss_ce: 0.019799
2021-12-14 02:50:43,222 iteration 3634 : loss : 0.055448, loss_ce: 0.018533
2021-12-14 02:50:44,756 iteration 3635 : loss : 0.051858, loss_ce: 0.014334
2021-12-14 02:50:46,290 iteration 3636 : loss : 0.052616, loss_ce: 0.016112
2021-12-14 02:50:47,921 iteration 3637 : loss : 0.062557, loss_ce: 0.017419
2021-12-14 02:50:49,439 iteration 3638 : loss : 0.051490, loss_ce: 0.013998
 54%|██████████████▍            | 214/400 [1:45:46<1:26:35, 27.93s/it]2021-12-14 02:50:51,035 iteration 3639 : loss : 0.059713, loss_ce: 0.022960
2021-12-14 02:50:52,652 iteration 3640 : loss : 0.068470, loss_ce: 0.022781
2021-12-14 02:50:54,236 iteration 3641 : loss : 0.065461, loss_ce: 0.017258
2021-12-14 02:50:55,857 iteration 3642 : loss : 0.061649, loss_ce: 0.022176
2021-12-14 02:50:57,434 iteration 3643 : loss : 0.060881, loss_ce: 0.023019
2021-12-14 02:50:59,002 iteration 3644 : loss : 0.051480, loss_ce: 0.020609
2021-12-14 02:51:00,547 iteration 3645 : loss : 0.054782, loss_ce: 0.019163
2021-12-14 02:51:02,139 iteration 3646 : loss : 0.047211, loss_ce: 0.013825
2021-12-14 02:51:03,766 iteration 3647 : loss : 0.060501, loss_ce: 0.021579
2021-12-14 02:51:05,455 iteration 3648 : loss : 0.069647, loss_ce: 0.022921
2021-12-14 02:51:07,055 iteration 3649 : loss : 0.077426, loss_ce: 0.019242
2021-12-14 02:51:08,631 iteration 3650 : loss : 0.055451, loss_ce: 0.015386
2021-12-14 02:51:10,228 iteration 3651 : loss : 0.050627, loss_ce: 0.015025
2021-12-14 02:51:11,775 iteration 3652 : loss : 0.053079, loss_ce: 0.019072
2021-12-14 02:51:13,415 iteration 3653 : loss : 0.067110, loss_ce: 0.014588
2021-12-14 02:51:15,006 iteration 3654 : loss : 0.059045, loss_ce: 0.015180
2021-12-14 02:51:15,006 Training Data Eval:
2021-12-14 02:51:23,184   Average segmentation loss on training set: 0.0428
2021-12-14 02:51:23,184 Validation Data Eval:
2021-12-14 02:51:25,980   Average segmentation loss on validation set: 0.0896
2021-12-14 02:51:27,468 iteration 3655 : loss : 0.046517, loss_ce: 0.010560
 54%|██████████████▌            | 215/400 [1:46:24<1:35:27, 30.96s/it]2021-12-14 02:51:29,143 iteration 3656 : loss : 0.078818, loss_ce: 0.015057
2021-12-14 02:51:30,695 iteration 3657 : loss : 0.074811, loss_ce: 0.031550
2021-12-14 02:51:32,279 iteration 3658 : loss : 0.056730, loss_ce: 0.021189
2021-12-14 02:51:33,894 iteration 3659 : loss : 0.067118, loss_ce: 0.013541
2021-12-14 02:51:35,569 iteration 3660 : loss : 0.068066, loss_ce: 0.020433
2021-12-14 02:51:37,256 iteration 3661 : loss : 0.063696, loss_ce: 0.023882
2021-12-14 02:51:38,760 iteration 3662 : loss : 0.050859, loss_ce: 0.014933
2021-12-14 02:51:40,301 iteration 3663 : loss : 0.048875, loss_ce: 0.014362
2021-12-14 02:51:41,854 iteration 3664 : loss : 0.059469, loss_ce: 0.015045
2021-12-14 02:51:43,420 iteration 3665 : loss : 0.062886, loss_ce: 0.022144
2021-12-14 02:51:45,108 iteration 3666 : loss : 0.068023, loss_ce: 0.025791
2021-12-14 02:51:46,739 iteration 3667 : loss : 0.061936, loss_ce: 0.020148
2021-12-14 02:51:48,369 iteration 3668 : loss : 0.050311, loss_ce: 0.015128
2021-12-14 02:51:49,964 iteration 3669 : loss : 0.059605, loss_ce: 0.024111
2021-12-14 02:51:51,518 iteration 3670 : loss : 0.062676, loss_ce: 0.017093
2021-12-14 02:51:53,136 iteration 3671 : loss : 0.072824, loss_ce: 0.020377
2021-12-14 02:51:54,666 iteration 3672 : loss : 0.060738, loss_ce: 0.021639
 54%|██████████████▌            | 216/400 [1:46:51<1:31:29, 29.83s/it]2021-12-14 02:51:56,264 iteration 3673 : loss : 0.058385, loss_ce: 0.023081
2021-12-14 02:51:57,843 iteration 3674 : loss : 0.056041, loss_ce: 0.020097
2021-12-14 02:51:59,402 iteration 3675 : loss : 0.048951, loss_ce: 0.019535
2021-12-14 02:52:00,958 iteration 3676 : loss : 0.051439, loss_ce: 0.013560
2021-12-14 02:52:02,519 iteration 3677 : loss : 0.065373, loss_ce: 0.027751
2021-12-14 02:52:04,167 iteration 3678 : loss : 0.077139, loss_ce: 0.021578
2021-12-14 02:52:05,732 iteration 3679 : loss : 0.055143, loss_ce: 0.017698
2021-12-14 02:52:07,281 iteration 3680 : loss : 0.069137, loss_ce: 0.017687
2021-12-14 02:52:08,909 iteration 3681 : loss : 0.061001, loss_ce: 0.019452
2021-12-14 02:52:10,471 iteration 3682 : loss : 0.054059, loss_ce: 0.018929
2021-12-14 02:52:12,097 iteration 3683 : loss : 0.092057, loss_ce: 0.017436
2021-12-14 02:52:13,652 iteration 3684 : loss : 0.047784, loss_ce: 0.013032
2021-12-14 02:52:15,215 iteration 3685 : loss : 0.069595, loss_ce: 0.028003
2021-12-14 02:52:16,815 iteration 3686 : loss : 0.065309, loss_ce: 0.023525
2021-12-14 02:52:18,399 iteration 3687 : loss : 0.054117, loss_ce: 0.014205
2021-12-14 02:52:19,968 iteration 3688 : loss : 0.065182, loss_ce: 0.025923
2021-12-14 02:52:21,480 iteration 3689 : loss : 0.052590, loss_ce: 0.015771
 54%|██████████████▋            | 217/400 [1:47:18<1:28:14, 28.93s/it]2021-12-14 02:52:23,061 iteration 3690 : loss : 0.046980, loss_ce: 0.009812
2021-12-14 02:52:24,711 iteration 3691 : loss : 0.068329, loss_ce: 0.013251
2021-12-14 02:52:26,291 iteration 3692 : loss : 0.050938, loss_ce: 0.018781
2021-12-14 02:52:27,935 iteration 3693 : loss : 0.070208, loss_ce: 0.023138
2021-12-14 02:52:29,518 iteration 3694 : loss : 0.053813, loss_ce: 0.019570
2021-12-14 02:52:31,048 iteration 3695 : loss : 0.054995, loss_ce: 0.019842
2021-12-14 02:52:32,663 iteration 3696 : loss : 0.060932, loss_ce: 0.026076
2021-12-14 02:52:34,227 iteration 3697 : loss : 0.059290, loss_ce: 0.013643
2021-12-14 02:52:35,807 iteration 3698 : loss : 0.057639, loss_ce: 0.019480
2021-12-14 02:52:37,455 iteration 3699 : loss : 0.073305, loss_ce: 0.025666
2021-12-14 02:52:39,038 iteration 3700 : loss : 0.059153, loss_ce: 0.022954
2021-12-14 02:52:40,595 iteration 3701 : loss : 0.049595, loss_ce: 0.015258
2021-12-14 02:52:42,146 iteration 3702 : loss : 0.076740, loss_ce: 0.023204
2021-12-14 02:52:43,832 iteration 3703 : loss : 0.062866, loss_ce: 0.023449
2021-12-14 02:52:45,376 iteration 3704 : loss : 0.057196, loss_ce: 0.014832
2021-12-14 02:52:46,907 iteration 3705 : loss : 0.048143, loss_ce: 0.013907
2021-12-14 02:52:48,434 iteration 3706 : loss : 0.047477, loss_ce: 0.011313
 55%|██████████████▋            | 218/400 [1:47:45<1:25:56, 28.33s/it]2021-12-14 02:52:50,040 iteration 3707 : loss : 0.070490, loss_ce: 0.025441
2021-12-14 02:52:51,620 iteration 3708 : loss : 0.053945, loss_ce: 0.018432
2021-12-14 02:52:53,200 iteration 3709 : loss : 0.052083, loss_ce: 0.014414
2021-12-14 02:52:54,823 iteration 3710 : loss : 0.064341, loss_ce: 0.019263
2021-12-14 02:52:56,379 iteration 3711 : loss : 0.048571, loss_ce: 0.013992
2021-12-14 02:52:57,981 iteration 3712 : loss : 0.063343, loss_ce: 0.016138
2021-12-14 02:52:59,514 iteration 3713 : loss : 0.054623, loss_ce: 0.017604
2021-12-14 02:53:01,058 iteration 3714 : loss : 0.049157, loss_ce: 0.013779
2021-12-14 02:53:02,639 iteration 3715 : loss : 0.059918, loss_ce: 0.021394
2021-12-14 02:53:04,176 iteration 3716 : loss : 0.053401, loss_ce: 0.015640
2021-12-14 02:53:05,764 iteration 3717 : loss : 0.054706, loss_ce: 0.018805
2021-12-14 02:53:07,400 iteration 3718 : loss : 0.052516, loss_ce: 0.018482
2021-12-14 02:53:08,931 iteration 3719 : loss : 0.054348, loss_ce: 0.014276
2021-12-14 02:53:10,531 iteration 3720 : loss : 0.050380, loss_ce: 0.019263
2021-12-14 02:53:12,118 iteration 3721 : loss : 0.055333, loss_ce: 0.019803
2021-12-14 02:53:13,688 iteration 3722 : loss : 0.050839, loss_ce: 0.016802
2021-12-14 02:53:15,237 iteration 3723 : loss : 0.060073, loss_ce: 0.016643
 55%|██████████████▊            | 219/400 [1:48:12<1:24:05, 27.88s/it]2021-12-14 02:53:16,792 iteration 3724 : loss : 0.055946, loss_ce: 0.023297
2021-12-14 02:53:18,332 iteration 3725 : loss : 0.052379, loss_ce: 0.018039
2021-12-14 02:53:19,970 iteration 3726 : loss : 0.056101, loss_ce: 0.020795
2021-12-14 02:53:21,557 iteration 3727 : loss : 0.073208, loss_ce: 0.021150
2021-12-14 02:53:23,150 iteration 3728 : loss : 0.061579, loss_ce: 0.015458
2021-12-14 02:53:24,686 iteration 3729 : loss : 0.049748, loss_ce: 0.011481
2021-12-14 02:53:26,245 iteration 3730 : loss : 0.054273, loss_ce: 0.020701
2021-12-14 02:53:27,797 iteration 3731 : loss : 0.047069, loss_ce: 0.013340
2021-12-14 02:53:29,399 iteration 3732 : loss : 0.059218, loss_ce: 0.017144
2021-12-14 02:53:30,927 iteration 3733 : loss : 0.049572, loss_ce: 0.016219
2021-12-14 02:53:32,514 iteration 3734 : loss : 0.048950, loss_ce: 0.016939
2021-12-14 02:53:34,090 iteration 3735 : loss : 0.053056, loss_ce: 0.012895
2021-12-14 02:53:35,718 iteration 3736 : loss : 0.057713, loss_ce: 0.022194
2021-12-14 02:53:37,256 iteration 3737 : loss : 0.051847, loss_ce: 0.014577
2021-12-14 02:53:38,820 iteration 3738 : loss : 0.047191, loss_ce: 0.012807
2021-12-14 02:53:40,348 iteration 3739 : loss : 0.060393, loss_ce: 0.021695
2021-12-14 02:53:40,348 Training Data Eval:
2021-12-14 02:53:48,519   Average segmentation loss on training set: 0.0427
2021-12-14 02:53:48,519 Validation Data Eval:
2021-12-14 02:53:51,318   Average segmentation loss on validation set: 0.0901
2021-12-14 02:53:53,043 iteration 3740 : loss : 0.070526, loss_ce: 0.027701
 55%|██████████████▊            | 220/400 [1:48:49<1:32:34, 30.86s/it]2021-12-14 02:53:54,802 iteration 3741 : loss : 0.065971, loss_ce: 0.016051
2021-12-14 02:53:56,371 iteration 3742 : loss : 0.067197, loss_ce: 0.030424
2021-12-14 02:53:57,944 iteration 3743 : loss : 0.057201, loss_ce: 0.022150
2021-12-14 02:53:59,565 iteration 3744 : loss : 0.071143, loss_ce: 0.022694
2021-12-14 02:54:01,211 iteration 3745 : loss : 0.053259, loss_ce: 0.014079
2021-12-14 02:54:02,871 iteration 3746 : loss : 0.060408, loss_ce: 0.018654
2021-12-14 02:54:04,445 iteration 3747 : loss : 0.053918, loss_ce: 0.014554
2021-12-14 02:54:06,005 iteration 3748 : loss : 0.053926, loss_ce: 0.021105
2021-12-14 02:54:07,637 iteration 3749 : loss : 0.061005, loss_ce: 0.017700
2021-12-14 02:54:09,295 iteration 3750 : loss : 0.055320, loss_ce: 0.017472
2021-12-14 02:54:10,899 iteration 3751 : loss : 0.066995, loss_ce: 0.020606
2021-12-14 02:54:12,458 iteration 3752 : loss : 0.054626, loss_ce: 0.013284
2021-12-14 02:54:13,994 iteration 3753 : loss : 0.063280, loss_ce: 0.018817
2021-12-14 02:54:15,576 iteration 3754 : loss : 0.061731, loss_ce: 0.017710
2021-12-14 02:54:17,201 iteration 3755 : loss : 0.048574, loss_ce: 0.017524
2021-12-14 02:54:18,712 iteration 3756 : loss : 0.054250, loss_ce: 0.019560
2021-12-14 02:54:20,243 iteration 3757 : loss : 0.047850, loss_ce: 0.017061
 55%|██████████████▉            | 221/400 [1:49:17<1:28:47, 29.76s/it]2021-12-14 02:54:21,947 iteration 3758 : loss : 0.053319, loss_ce: 0.014957
2021-12-14 02:54:23,485 iteration 3759 : loss : 0.050650, loss_ce: 0.014039
2021-12-14 02:54:25,045 iteration 3760 : loss : 0.049742, loss_ce: 0.017072
2021-12-14 02:54:26,669 iteration 3761 : loss : 0.056427, loss_ce: 0.017288
2021-12-14 02:54:28,314 iteration 3762 : loss : 0.062312, loss_ce: 0.026425
2021-12-14 02:54:29,991 iteration 3763 : loss : 0.057392, loss_ce: 0.017802
2021-12-14 02:54:31,565 iteration 3764 : loss : 0.065246, loss_ce: 0.018760
2021-12-14 02:54:33,096 iteration 3765 : loss : 0.051832, loss_ce: 0.017403
2021-12-14 02:54:34,723 iteration 3766 : loss : 0.066211, loss_ce: 0.022900
2021-12-14 02:54:36,295 iteration 3767 : loss : 0.044971, loss_ce: 0.012562
2021-12-14 02:54:37,834 iteration 3768 : loss : 0.061379, loss_ce: 0.016462
2021-12-14 02:54:39,380 iteration 3769 : loss : 0.052206, loss_ce: 0.019958
2021-12-14 02:54:40,987 iteration 3770 : loss : 0.072403, loss_ce: 0.013902
2021-12-14 02:54:42,690 iteration 3771 : loss : 0.056668, loss_ce: 0.016584
2021-12-14 02:54:44,339 iteration 3772 : loss : 0.059133, loss_ce: 0.015408
2021-12-14 02:54:45,950 iteration 3773 : loss : 0.046148, loss_ce: 0.013276
2021-12-14 02:54:47,598 iteration 3774 : loss : 0.080091, loss_ce: 0.034739
 56%|██████████████▉            | 222/400 [1:49:44<1:26:08, 29.04s/it]2021-12-14 02:54:49,212 iteration 3775 : loss : 0.055072, loss_ce: 0.018281
2021-12-14 02:54:50,717 iteration 3776 : loss : 0.056960, loss_ce: 0.020657
2021-12-14 02:54:52,278 iteration 3777 : loss : 0.056640, loss_ce: 0.011921
2021-12-14 02:54:53,820 iteration 3778 : loss : 0.052423, loss_ce: 0.016355
2021-12-14 02:54:55,357 iteration 3779 : loss : 0.049575, loss_ce: 0.018495
2021-12-14 02:54:56,942 iteration 3780 : loss : 0.060299, loss_ce: 0.017092
2021-12-14 02:54:58,523 iteration 3781 : loss : 0.065755, loss_ce: 0.023522
2021-12-14 02:55:00,120 iteration 3782 : loss : 0.081055, loss_ce: 0.015211
2021-12-14 02:55:01,716 iteration 3783 : loss : 0.044086, loss_ce: 0.015210
2021-12-14 02:55:03,324 iteration 3784 : loss : 0.059311, loss_ce: 0.023256
2021-12-14 02:55:04,876 iteration 3785 : loss : 0.055175, loss_ce: 0.020808
2021-12-14 02:55:06,423 iteration 3786 : loss : 0.049852, loss_ce: 0.015515
2021-12-14 02:55:07,962 iteration 3787 : loss : 0.055525, loss_ce: 0.015808
2021-12-14 02:55:09,609 iteration 3788 : loss : 0.065917, loss_ce: 0.014893
2021-12-14 02:55:11,188 iteration 3789 : loss : 0.055345, loss_ce: 0.013829
2021-12-14 02:55:12,807 iteration 3790 : loss : 0.053276, loss_ce: 0.017061
2021-12-14 02:55:14,411 iteration 3791 : loss : 0.051272, loss_ce: 0.018638
 56%|███████████████            | 223/400 [1:50:11<1:23:41, 28.37s/it]2021-12-14 02:55:16,013 iteration 3792 : loss : 0.046093, loss_ce: 0.012374
2021-12-14 02:55:17,634 iteration 3793 : loss : 0.054742, loss_ce: 0.015937
2021-12-14 02:55:19,235 iteration 3794 : loss : 0.054941, loss_ce: 0.019329
2021-12-14 02:55:20,815 iteration 3795 : loss : 0.046183, loss_ce: 0.013001
2021-12-14 02:55:22,301 iteration 3796 : loss : 0.051728, loss_ce: 0.014531
2021-12-14 02:55:23,852 iteration 3797 : loss : 0.054160, loss_ce: 0.016239
2021-12-14 02:55:25,362 iteration 3798 : loss : 0.049985, loss_ce: 0.016195
2021-12-14 02:55:26,918 iteration 3799 : loss : 0.055356, loss_ce: 0.015994
2021-12-14 02:55:28,472 iteration 3800 : loss : 0.054492, loss_ce: 0.013485
2021-12-14 02:55:30,026 iteration 3801 : loss : 0.074059, loss_ce: 0.015837
2021-12-14 02:55:31,568 iteration 3802 : loss : 0.060942, loss_ce: 0.022201
2021-12-14 02:55:33,132 iteration 3803 : loss : 0.047077, loss_ce: 0.012952
2021-12-14 02:55:34,698 iteration 3804 : loss : 0.057069, loss_ce: 0.017443
2021-12-14 02:55:36,244 iteration 3805 : loss : 0.064388, loss_ce: 0.022214
2021-12-14 02:55:37,786 iteration 3806 : loss : 0.061496, loss_ce: 0.026851
2021-12-14 02:55:39,387 iteration 3807 : loss : 0.047413, loss_ce: 0.014098
2021-12-14 02:55:40,967 iteration 3808 : loss : 0.049950, loss_ce: 0.015910
 56%|███████████████            | 224/400 [1:50:37<1:21:37, 27.83s/it]2021-12-14 02:55:42,536 iteration 3809 : loss : 0.045166, loss_ce: 0.012390
2021-12-14 02:55:44,080 iteration 3810 : loss : 0.045162, loss_ce: 0.014698
2021-12-14 02:55:45,641 iteration 3811 : loss : 0.052320, loss_ce: 0.012309
2021-12-14 02:55:47,222 iteration 3812 : loss : 0.062795, loss_ce: 0.026151
2021-12-14 02:55:48,779 iteration 3813 : loss : 0.053291, loss_ce: 0.020513
2021-12-14 02:55:50,381 iteration 3814 : loss : 0.054880, loss_ce: 0.016568
2021-12-14 02:55:51,952 iteration 3815 : loss : 0.055775, loss_ce: 0.015816
2021-12-14 02:55:53,544 iteration 3816 : loss : 0.058428, loss_ce: 0.020539
2021-12-14 02:55:55,073 iteration 3817 : loss : 0.053572, loss_ce: 0.017225
2021-12-14 02:55:56,682 iteration 3818 : loss : 0.057374, loss_ce: 0.022765
2021-12-14 02:55:58,311 iteration 3819 : loss : 0.055500, loss_ce: 0.020256
2021-12-14 02:55:59,921 iteration 3820 : loss : 0.060823, loss_ce: 0.018496
2021-12-14 02:56:01,533 iteration 3821 : loss : 0.056459, loss_ce: 0.018607
2021-12-14 02:56:03,079 iteration 3822 : loss : 0.062219, loss_ce: 0.017124
2021-12-14 02:56:04,734 iteration 3823 : loss : 0.048347, loss_ce: 0.010877
2021-12-14 02:56:06,321 iteration 3824 : loss : 0.052570, loss_ce: 0.015494
2021-12-14 02:56:06,321 Training Data Eval:
2021-12-14 02:56:14,508   Average segmentation loss on training set: 0.0429
2021-12-14 02:56:14,509 Validation Data Eval:
2021-12-14 02:56:17,310   Average segmentation loss on validation set: 0.0942
2021-12-14 02:56:18,966 iteration 3825 : loss : 0.052297, loss_ce: 0.015841
 56%|███████████████▏           | 225/400 [1:51:15<1:30:03, 30.88s/it]2021-12-14 02:56:20,621 iteration 3826 : loss : 0.053768, loss_ce: 0.020182
2021-12-14 02:56:22,153 iteration 3827 : loss : 0.054670, loss_ce: 0.016066
2021-12-14 02:56:23,750 iteration 3828 : loss : 0.050858, loss_ce: 0.015623
2021-12-14 02:56:25,333 iteration 3829 : loss : 0.050654, loss_ce: 0.013361
2021-12-14 02:56:26,874 iteration 3830 : loss : 0.047322, loss_ce: 0.013616
2021-12-14 02:56:28,406 iteration 3831 : loss : 0.052638, loss_ce: 0.017227
2021-12-14 02:56:29,930 iteration 3832 : loss : 0.055909, loss_ce: 0.014355
2021-12-14 02:56:31,503 iteration 3833 : loss : 0.052577, loss_ce: 0.020007
2021-12-14 02:56:33,110 iteration 3834 : loss : 0.055192, loss_ce: 0.020998
2021-12-14 02:56:34,697 iteration 3835 : loss : 0.054741, loss_ce: 0.017020
2021-12-14 02:56:36,278 iteration 3836 : loss : 0.062332, loss_ce: 0.019917
2021-12-14 02:56:37,880 iteration 3837 : loss : 0.049833, loss_ce: 0.014249
2021-12-14 02:56:39,540 iteration 3838 : loss : 0.055244, loss_ce: 0.016820
2021-12-14 02:56:41,111 iteration 3839 : loss : 0.052572, loss_ce: 0.019148
2021-12-14 02:56:42,700 iteration 3840 : loss : 0.059054, loss_ce: 0.012700
2021-12-14 02:56:44,249 iteration 3841 : loss : 0.052023, loss_ce: 0.015292
2021-12-14 02:56:45,855 iteration 3842 : loss : 0.062097, loss_ce: 0.023935
 56%|███████████████▎           | 226/400 [1:51:42<1:26:04, 29.68s/it]2021-12-14 02:56:47,453 iteration 3843 : loss : 0.051475, loss_ce: 0.018177
2021-12-14 02:56:49,077 iteration 3844 : loss : 0.057269, loss_ce: 0.015598
2021-12-14 02:56:50,683 iteration 3845 : loss : 0.052223, loss_ce: 0.019112
2021-12-14 02:56:52,225 iteration 3846 : loss : 0.045191, loss_ce: 0.013609
2021-12-14 02:56:53,783 iteration 3847 : loss : 0.051722, loss_ce: 0.015911
2021-12-14 02:56:55,405 iteration 3848 : loss : 0.053625, loss_ce: 0.021633
2021-12-14 02:56:57,081 iteration 3849 : loss : 0.055136, loss_ce: 0.020877
2021-12-14 02:56:58,742 iteration 3850 : loss : 0.085735, loss_ce: 0.016517
2021-12-14 02:57:00,340 iteration 3851 : loss : 0.051409, loss_ce: 0.018006
2021-12-14 02:57:01,952 iteration 3852 : loss : 0.050910, loss_ce: 0.013282
2021-12-14 02:57:03,497 iteration 3853 : loss : 0.047763, loss_ce: 0.013433
2021-12-14 02:57:05,103 iteration 3854 : loss : 0.054145, loss_ce: 0.014483
2021-12-14 02:57:06,813 iteration 3855 : loss : 0.063942, loss_ce: 0.019425
2021-12-14 02:57:08,277 iteration 3856 : loss : 0.052017, loss_ce: 0.019679
2021-12-14 02:57:09,838 iteration 3857 : loss : 0.055554, loss_ce: 0.022243
2021-12-14 02:57:11,327 iteration 3858 : loss : 0.051805, loss_ce: 0.017537
2021-12-14 02:57:12,901 iteration 3859 : loss : 0.049698, loss_ce: 0.017035
 57%|███████████████▎           | 227/400 [1:52:09<1:23:18, 28.89s/it]2021-12-14 02:57:14,534 iteration 3860 : loss : 0.065879, loss_ce: 0.020461
2021-12-14 02:57:16,185 iteration 3861 : loss : 0.078507, loss_ce: 0.031580
2021-12-14 02:57:17,789 iteration 3862 : loss : 0.051356, loss_ce: 0.017114
2021-12-14 02:57:19,384 iteration 3863 : loss : 0.054847, loss_ce: 0.016917
2021-12-14 02:57:21,001 iteration 3864 : loss : 0.052331, loss_ce: 0.016911
2021-12-14 02:57:22,576 iteration 3865 : loss : 0.051892, loss_ce: 0.015440
2021-12-14 02:57:24,268 iteration 3866 : loss : 0.065887, loss_ce: 0.019110
2021-12-14 02:57:25,847 iteration 3867 : loss : 0.053835, loss_ce: 0.017665
2021-12-14 02:57:27,487 iteration 3868 : loss : 0.065278, loss_ce: 0.017096
2021-12-14 02:57:29,103 iteration 3869 : loss : 0.053807, loss_ce: 0.020394
2021-12-14 02:57:30,728 iteration 3870 : loss : 0.052920, loss_ce: 0.016002
2021-12-14 02:57:32,337 iteration 3871 : loss : 0.050155, loss_ce: 0.012368
2021-12-14 02:57:33,882 iteration 3872 : loss : 0.053514, loss_ce: 0.015692
2021-12-14 02:57:35,423 iteration 3873 : loss : 0.053531, loss_ce: 0.021879
2021-12-14 02:57:37,020 iteration 3874 : loss : 0.059734, loss_ce: 0.019457
2021-12-14 02:57:38,614 iteration 3875 : loss : 0.051611, loss_ce: 0.017106
2021-12-14 02:57:40,215 iteration 3876 : loss : 0.055324, loss_ce: 0.014668
 57%|███████████████▍           | 228/400 [1:52:37<1:21:28, 28.42s/it]2021-12-14 02:57:41,827 iteration 3877 : loss : 0.053292, loss_ce: 0.017681
2021-12-14 02:57:43,439 iteration 3878 : loss : 0.053896, loss_ce: 0.016165
2021-12-14 02:57:45,003 iteration 3879 : loss : 0.048619, loss_ce: 0.015457
2021-12-14 02:57:46,617 iteration 3880 : loss : 0.053372, loss_ce: 0.019767
2021-12-14 02:57:48,175 iteration 3881 : loss : 0.050812, loss_ce: 0.018571
2021-12-14 02:57:49,843 iteration 3882 : loss : 0.091783, loss_ce: 0.017606
2021-12-14 02:57:51,474 iteration 3883 : loss : 0.060462, loss_ce: 0.014535
2021-12-14 02:57:53,077 iteration 3884 : loss : 0.056312, loss_ce: 0.019713
2021-12-14 02:57:54,705 iteration 3885 : loss : 0.091842, loss_ce: 0.017179
2021-12-14 02:57:56,335 iteration 3886 : loss : 0.055695, loss_ce: 0.018970
2021-12-14 02:57:57,874 iteration 3887 : loss : 0.045695, loss_ce: 0.013130
2021-12-14 02:57:59,503 iteration 3888 : loss : 0.058755, loss_ce: 0.024708
2021-12-14 02:58:01,102 iteration 3889 : loss : 0.048001, loss_ce: 0.016234
2021-12-14 02:58:02,796 iteration 3890 : loss : 0.067312, loss_ce: 0.021121
2021-12-14 02:58:04,354 iteration 3891 : loss : 0.054641, loss_ce: 0.017885
2021-12-14 02:58:05,942 iteration 3892 : loss : 0.052939, loss_ce: 0.017145
2021-12-14 02:58:07,555 iteration 3893 : loss : 0.061725, loss_ce: 0.019427
 57%|███████████████▍           | 229/400 [1:53:04<1:20:03, 28.09s/it]2021-12-14 02:58:09,162 iteration 3894 : loss : 0.051807, loss_ce: 0.013840
2021-12-14 02:58:10,701 iteration 3895 : loss : 0.047093, loss_ce: 0.015012
2021-12-14 02:58:12,281 iteration 3896 : loss : 0.072179, loss_ce: 0.027795
2021-12-14 02:58:13,910 iteration 3897 : loss : 0.057517, loss_ce: 0.020100
2021-12-14 02:58:15,524 iteration 3898 : loss : 0.055566, loss_ce: 0.015425
2021-12-14 02:58:17,045 iteration 3899 : loss : 0.053430, loss_ce: 0.016722
2021-12-14 02:58:18,594 iteration 3900 : loss : 0.055350, loss_ce: 0.017360
2021-12-14 02:58:20,128 iteration 3901 : loss : 0.054535, loss_ce: 0.018830
2021-12-14 02:58:21,667 iteration 3902 : loss : 0.054978, loss_ce: 0.015510
2021-12-14 02:58:23,171 iteration 3903 : loss : 0.053543, loss_ce: 0.014744
2021-12-14 02:58:24,726 iteration 3904 : loss : 0.060438, loss_ce: 0.015744
2021-12-14 02:58:26,287 iteration 3905 : loss : 0.057479, loss_ce: 0.013946
2021-12-14 02:58:27,779 iteration 3906 : loss : 0.045188, loss_ce: 0.015382
2021-12-14 02:58:29,262 iteration 3907 : loss : 0.049473, loss_ce: 0.016946
2021-12-14 02:58:30,764 iteration 3908 : loss : 0.048496, loss_ce: 0.015096
2021-12-14 02:58:32,333 iteration 3909 : loss : 0.078566, loss_ce: 0.038349
2021-12-14 02:58:32,333 Training Data Eval:
2021-12-14 02:58:40,516   Average segmentation loss on training set: 0.0416
2021-12-14 02:58:40,517 Validation Data Eval:
2021-12-14 02:58:43,307   Average segmentation loss on validation set: 0.0952
2021-12-14 02:58:44,942 iteration 3910 : loss : 0.054154, loss_ce: 0.016914
 57%|███████████████▌           | 230/400 [1:53:41<1:27:29, 30.88s/it]2021-12-14 02:58:46,512 iteration 3911 : loss : 0.046111, loss_ce: 0.014819
2021-12-14 02:58:48,113 iteration 3912 : loss : 0.071762, loss_ce: 0.023852
2021-12-14 02:58:49,679 iteration 3913 : loss : 0.045963, loss_ce: 0.013947
2021-12-14 02:58:51,240 iteration 3914 : loss : 0.049021, loss_ce: 0.017990
2021-12-14 02:58:52,797 iteration 3915 : loss : 0.056628, loss_ce: 0.020814
2021-12-14 02:58:54,323 iteration 3916 : loss : 0.046916, loss_ce: 0.015136
2021-12-14 02:58:55,925 iteration 3917 : loss : 0.059542, loss_ce: 0.021549
2021-12-14 02:58:57,524 iteration 3918 : loss : 0.061065, loss_ce: 0.015868
2021-12-14 02:58:59,227 iteration 3919 : loss : 0.053104, loss_ce: 0.015209
2021-12-14 02:59:00,768 iteration 3920 : loss : 0.052578, loss_ce: 0.017030
2021-12-14 02:59:02,343 iteration 3921 : loss : 0.055412, loss_ce: 0.019690
2021-12-14 02:59:03,958 iteration 3922 : loss : 0.055616, loss_ce: 0.017807
2021-12-14 02:59:05,513 iteration 3923 : loss : 0.044174, loss_ce: 0.016600
2021-12-14 02:59:07,039 iteration 3924 : loss : 0.057532, loss_ce: 0.014429
2021-12-14 02:59:08,686 iteration 3925 : loss : 0.061777, loss_ce: 0.020399
2021-12-14 02:59:10,307 iteration 3926 : loss : 0.043751, loss_ce: 0.012231
2021-12-14 02:59:11,879 iteration 3927 : loss : 0.056335, loss_ce: 0.019766
 58%|███████████████▌           | 231/400 [1:54:08<1:23:39, 29.70s/it]2021-12-14 02:59:13,560 iteration 3928 : loss : 0.069504, loss_ce: 0.023317
2021-12-14 02:59:15,143 iteration 3929 : loss : 0.054374, loss_ce: 0.021191
2021-12-14 02:59:16,781 iteration 3930 : loss : 0.054861, loss_ce: 0.018896
2021-12-14 02:59:18,408 iteration 3931 : loss : 0.048282, loss_ce: 0.014941
2021-12-14 02:59:20,029 iteration 3932 : loss : 0.058277, loss_ce: 0.016800
2021-12-14 02:59:21,687 iteration 3933 : loss : 0.051126, loss_ce: 0.016994
2021-12-14 02:59:23,296 iteration 3934 : loss : 0.044875, loss_ce: 0.014570
2021-12-14 02:59:24,803 iteration 3935 : loss : 0.050199, loss_ce: 0.017810
2021-12-14 02:59:26,502 iteration 3936 : loss : 0.048737, loss_ce: 0.015645
2021-12-14 02:59:28,045 iteration 3937 : loss : 0.052626, loss_ce: 0.017831
2021-12-14 02:59:29,677 iteration 3938 : loss : 0.117227, loss_ce: 0.024408
2021-12-14 02:59:31,187 iteration 3939 : loss : 0.083265, loss_ce: 0.028653
2021-12-14 02:59:32,735 iteration 3940 : loss : 0.053096, loss_ce: 0.015892
2021-12-14 02:59:34,310 iteration 3941 : loss : 0.048370, loss_ce: 0.015694
2021-12-14 02:59:35,944 iteration 3942 : loss : 0.075633, loss_ce: 0.027453
2021-12-14 02:59:37,494 iteration 3943 : loss : 0.051188, loss_ce: 0.010286
2021-12-14 02:59:39,137 iteration 3944 : loss : 0.062957, loss_ce: 0.021432
 58%|███████████████▋           | 232/400 [1:54:36<1:21:06, 28.97s/it]2021-12-14 02:59:40,799 iteration 3945 : loss : 0.058093, loss_ce: 0.021789
2021-12-14 02:59:42,291 iteration 3946 : loss : 0.048699, loss_ce: 0.019233
2021-12-14 02:59:43,857 iteration 3947 : loss : 0.045711, loss_ce: 0.012704
2021-12-14 02:59:45,557 iteration 3948 : loss : 0.073246, loss_ce: 0.026580
2021-12-14 02:59:47,175 iteration 3949 : loss : 0.056868, loss_ce: 0.018196
2021-12-14 02:59:48,825 iteration 3950 : loss : 0.052313, loss_ce: 0.013433
2021-12-14 02:59:50,347 iteration 3951 : loss : 0.047461, loss_ce: 0.015385
2021-12-14 02:59:51,974 iteration 3952 : loss : 0.058916, loss_ce: 0.019883
2021-12-14 02:59:53,615 iteration 3953 : loss : 0.068660, loss_ce: 0.022339
2021-12-14 02:59:55,190 iteration 3954 : loss : 0.051494, loss_ce: 0.014036
2021-12-14 02:59:56,757 iteration 3955 : loss : 0.044301, loss_ce: 0.013413
2021-12-14 02:59:58,455 iteration 3956 : loss : 0.068180, loss_ce: 0.022963
2021-12-14 02:59:59,998 iteration 3957 : loss : 0.052502, loss_ce: 0.017365
2021-12-14 03:00:01,549 iteration 3958 : loss : 0.052480, loss_ce: 0.016196
2021-12-14 03:00:03,210 iteration 3959 : loss : 0.063165, loss_ce: 0.019753
2021-12-14 03:00:04,776 iteration 3960 : loss : 0.052514, loss_ce: 0.020532
2021-12-14 03:00:06,349 iteration 3961 : loss : 0.052488, loss_ce: 0.016522
 58%|███████████████▋           | 233/400 [1:55:03<1:19:09, 28.44s/it]2021-12-14 03:00:08,021 iteration 3962 : loss : 0.052971, loss_ce: 0.017605
2021-12-14 03:00:09,602 iteration 3963 : loss : 0.058770, loss_ce: 0.021309
2021-12-14 03:00:11,271 iteration 3964 : loss : 0.054084, loss_ce: 0.019695
2021-12-14 03:00:12,807 iteration 3965 : loss : 0.049085, loss_ce: 0.011775
2021-12-14 03:00:14,436 iteration 3966 : loss : 0.055009, loss_ce: 0.017944
2021-12-14 03:00:16,023 iteration 3967 : loss : 0.051245, loss_ce: 0.015921
2021-12-14 03:00:17,507 iteration 3968 : loss : 0.057008, loss_ce: 0.015419
2021-12-14 03:00:19,099 iteration 3969 : loss : 0.061970, loss_ce: 0.016876
2021-12-14 03:00:20,665 iteration 3970 : loss : 0.058443, loss_ce: 0.015814
2021-12-14 03:00:22,141 iteration 3971 : loss : 0.048940, loss_ce: 0.017354
2021-12-14 03:00:23,746 iteration 3972 : loss : 0.058246, loss_ce: 0.012644
2021-12-14 03:00:25,275 iteration 3973 : loss : 0.064579, loss_ce: 0.027425
2021-12-14 03:00:26,766 iteration 3974 : loss : 0.045472, loss_ce: 0.011211
2021-12-14 03:00:28,355 iteration 3975 : loss : 0.047898, loss_ce: 0.015165
2021-12-14 03:00:29,995 iteration 3976 : loss : 0.058585, loss_ce: 0.020607
2021-12-14 03:00:31,634 iteration 3977 : loss : 0.052101, loss_ce: 0.017544
2021-12-14 03:00:33,292 iteration 3978 : loss : 0.053957, loss_ce: 0.016632
 58%|███████████████▊           | 234/400 [1:55:30<1:17:26, 27.99s/it]2021-12-14 03:00:34,927 iteration 3979 : loss : 0.061635, loss_ce: 0.018459
2021-12-14 03:00:36,540 iteration 3980 : loss : 0.056187, loss_ce: 0.014802
2021-12-14 03:00:38,104 iteration 3981 : loss : 0.064765, loss_ce: 0.019958
2021-12-14 03:00:39,579 iteration 3982 : loss : 0.046576, loss_ce: 0.015068
2021-12-14 03:00:41,076 iteration 3983 : loss : 0.050354, loss_ce: 0.019565
2021-12-14 03:00:42,611 iteration 3984 : loss : 0.049038, loss_ce: 0.017238
2021-12-14 03:00:44,201 iteration 3985 : loss : 0.063727, loss_ce: 0.026705
2021-12-14 03:00:45,867 iteration 3986 : loss : 0.058173, loss_ce: 0.020706
2021-12-14 03:00:47,481 iteration 3987 : loss : 0.059894, loss_ce: 0.019742
2021-12-14 03:00:49,065 iteration 3988 : loss : 0.051232, loss_ce: 0.018438
2021-12-14 03:00:50,623 iteration 3989 : loss : 0.053539, loss_ce: 0.010378
2021-12-14 03:00:52,181 iteration 3990 : loss : 0.061595, loss_ce: 0.017968
2021-12-14 03:00:53,815 iteration 3991 : loss : 0.051700, loss_ce: 0.010828
2021-12-14 03:00:55,406 iteration 3992 : loss : 0.062125, loss_ce: 0.017670
2021-12-14 03:00:57,030 iteration 3993 : loss : 0.066506, loss_ce: 0.017981
2021-12-14 03:00:58,584 iteration 3994 : loss : 0.048563, loss_ce: 0.018921
2021-12-14 03:00:58,584 Training Data Eval:
2021-12-14 03:01:06,765   Average segmentation loss on training set: 0.0413
2021-12-14 03:01:06,766 Validation Data Eval:
2021-12-14 03:01:09,568   Average segmentation loss on validation set: 0.0947
2021-12-14 03:01:11,087 iteration 3995 : loss : 0.047685, loss_ce: 0.015900
 59%|███████████████▊           | 235/400 [1:56:08<1:25:04, 30.93s/it]2021-12-14 03:01:12,780 iteration 3996 : loss : 0.052668, loss_ce: 0.015051
2021-12-14 03:01:14,298 iteration 3997 : loss : 0.058376, loss_ce: 0.015990
2021-12-14 03:01:15,893 iteration 3998 : loss : 0.045967, loss_ce: 0.017556
2021-12-14 03:01:17,455 iteration 3999 : loss : 0.045514, loss_ce: 0.009691
2021-12-14 03:01:19,089 iteration 4000 : loss : 0.052955, loss_ce: 0.020433
2021-12-14 03:01:20,607 iteration 4001 : loss : 0.046257, loss_ce: 0.015440
2021-12-14 03:01:22,190 iteration 4002 : loss : 0.045296, loss_ce: 0.015212
2021-12-14 03:01:23,781 iteration 4003 : loss : 0.057098, loss_ce: 0.020351
2021-12-14 03:01:25,396 iteration 4004 : loss : 0.053968, loss_ce: 0.011891
2021-12-14 03:01:26,981 iteration 4005 : loss : 0.061092, loss_ce: 0.025807
2021-12-14 03:01:28,508 iteration 4006 : loss : 0.050458, loss_ce: 0.017324
2021-12-14 03:01:30,134 iteration 4007 : loss : 0.051841, loss_ce: 0.014859
2021-12-14 03:01:31,670 iteration 4008 : loss : 0.047574, loss_ce: 0.012970
2021-12-14 03:01:33,237 iteration 4009 : loss : 0.049220, loss_ce: 0.016092
2021-12-14 03:01:34,872 iteration 4010 : loss : 0.080156, loss_ce: 0.032033
2021-12-14 03:01:36,396 iteration 4011 : loss : 0.055276, loss_ce: 0.014682
2021-12-14 03:01:38,041 iteration 4012 : loss : 0.051731, loss_ce: 0.017847
 59%|███████████████▉           | 236/400 [1:56:34<1:21:16, 29.74s/it]2021-12-14 03:01:39,740 iteration 4013 : loss : 0.074501, loss_ce: 0.022517
2021-12-14 03:01:41,269 iteration 4014 : loss : 0.057556, loss_ce: 0.017076
2021-12-14 03:01:42,893 iteration 4015 : loss : 0.058592, loss_ce: 0.019733
2021-12-14 03:01:44,514 iteration 4016 : loss : 0.060772, loss_ce: 0.021077
2021-12-14 03:01:46,153 iteration 4017 : loss : 0.049011, loss_ce: 0.013209
2021-12-14 03:01:47,697 iteration 4018 : loss : 0.061727, loss_ce: 0.018992
2021-12-14 03:01:49,266 iteration 4019 : loss : 0.064598, loss_ce: 0.025324
2021-12-14 03:01:50,793 iteration 4020 : loss : 0.051867, loss_ce: 0.023114
2021-12-14 03:01:52,343 iteration 4021 : loss : 0.055256, loss_ce: 0.020143
2021-12-14 03:01:53,950 iteration 4022 : loss : 0.058151, loss_ce: 0.024945
2021-12-14 03:01:55,525 iteration 4023 : loss : 0.048403, loss_ce: 0.014429
2021-12-14 03:01:57,040 iteration 4024 : loss : 0.046282, loss_ce: 0.012168
2021-12-14 03:01:58,574 iteration 4025 : loss : 0.044223, loss_ce: 0.013092
2021-12-14 03:02:00,179 iteration 4026 : loss : 0.051507, loss_ce: 0.016341
2021-12-14 03:02:01,778 iteration 4027 : loss : 0.056714, loss_ce: 0.016632
2021-12-14 03:02:03,404 iteration 4028 : loss : 0.060561, loss_ce: 0.015588
2021-12-14 03:02:04,940 iteration 4029 : loss : 0.046858, loss_ce: 0.014810
 59%|███████████████▉           | 237/400 [1:57:01<1:18:28, 28.88s/it]2021-12-14 03:02:06,617 iteration 4030 : loss : 0.053433, loss_ce: 0.018954
2021-12-14 03:02:08,216 iteration 4031 : loss : 0.070777, loss_ce: 0.016218
2021-12-14 03:02:09,785 iteration 4032 : loss : 0.058957, loss_ce: 0.022485
2021-12-14 03:02:11,360 iteration 4033 : loss : 0.061429, loss_ce: 0.017645
2021-12-14 03:02:12,872 iteration 4034 : loss : 0.053928, loss_ce: 0.015674
2021-12-14 03:02:14,444 iteration 4035 : loss : 0.048101, loss_ce: 0.013189
2021-12-14 03:02:16,048 iteration 4036 : loss : 0.066162, loss_ce: 0.022846
2021-12-14 03:02:17,576 iteration 4037 : loss : 0.047257, loss_ce: 0.019496
2021-12-14 03:02:19,219 iteration 4038 : loss : 0.054668, loss_ce: 0.015927
2021-12-14 03:02:20,886 iteration 4039 : loss : 0.054869, loss_ce: 0.016750
2021-12-14 03:02:22,545 iteration 4040 : loss : 0.059905, loss_ce: 0.021923
2021-12-14 03:02:24,183 iteration 4041 : loss : 0.055926, loss_ce: 0.015673
2021-12-14 03:02:25,726 iteration 4042 : loss : 0.044789, loss_ce: 0.014296
2021-12-14 03:02:27,312 iteration 4043 : loss : 0.187980, loss_ce: 0.014744
2021-12-14 03:02:28,855 iteration 4044 : loss : 0.053096, loss_ce: 0.018792
2021-12-14 03:02:30,421 iteration 4045 : loss : 0.050379, loss_ce: 0.019359
2021-12-14 03:02:32,045 iteration 4046 : loss : 0.062954, loss_ce: 0.027376
 60%|████████████████           | 238/400 [1:57:28<1:16:32, 28.35s/it]2021-12-14 03:02:33,747 iteration 4047 : loss : 0.052750, loss_ce: 0.020212
2021-12-14 03:02:35,373 iteration 4048 : loss : 0.062823, loss_ce: 0.021772
2021-12-14 03:02:36,920 iteration 4049 : loss : 0.047026, loss_ce: 0.015009
2021-12-14 03:02:38,535 iteration 4050 : loss : 0.071563, loss_ce: 0.024705
2021-12-14 03:02:40,216 iteration 4051 : loss : 0.070739, loss_ce: 0.011385
2021-12-14 03:02:41,738 iteration 4052 : loss : 0.054501, loss_ce: 0.017375
2021-12-14 03:02:43,230 iteration 4053 : loss : 0.052081, loss_ce: 0.015881
2021-12-14 03:02:44,760 iteration 4054 : loss : 0.064857, loss_ce: 0.017393
2021-12-14 03:02:46,320 iteration 4055 : loss : 0.051027, loss_ce: 0.018900
2021-12-14 03:02:47,911 iteration 4056 : loss : 0.053482, loss_ce: 0.019697
2021-12-14 03:02:49,441 iteration 4057 : loss : 0.052620, loss_ce: 0.011960
2021-12-14 03:02:51,005 iteration 4058 : loss : 0.048489, loss_ce: 0.014604
2021-12-14 03:02:52,680 iteration 4059 : loss : 0.066879, loss_ce: 0.025033
2021-12-14 03:02:54,268 iteration 4060 : loss : 0.051051, loss_ce: 0.018093
2021-12-14 03:02:55,846 iteration 4061 : loss : 0.056974, loss_ce: 0.021390
2021-12-14 03:02:57,454 iteration 4062 : loss : 0.055333, loss_ce: 0.019343
2021-12-14 03:02:59,046 iteration 4063 : loss : 0.066416, loss_ce: 0.018105
 60%|████████████████▏          | 239/400 [1:57:55<1:14:58, 27.94s/it]2021-12-14 03:03:00,643 iteration 4064 : loss : 0.056058, loss_ce: 0.012364
2021-12-14 03:03:02,191 iteration 4065 : loss : 0.042014, loss_ce: 0.012600
2021-12-14 03:03:03,836 iteration 4066 : loss : 0.059578, loss_ce: 0.018658
2021-12-14 03:03:05,383 iteration 4067 : loss : 0.051596, loss_ce: 0.017531
2021-12-14 03:03:06,961 iteration 4068 : loss : 0.055691, loss_ce: 0.019088
2021-12-14 03:03:08,570 iteration 4069 : loss : 0.047932, loss_ce: 0.016104
2021-12-14 03:03:10,175 iteration 4070 : loss : 0.051439, loss_ce: 0.016374
2021-12-14 03:03:11,815 iteration 4071 : loss : 0.061380, loss_ce: 0.016595
2021-12-14 03:03:13,384 iteration 4072 : loss : 0.050186, loss_ce: 0.013070
2021-12-14 03:03:14,934 iteration 4073 : loss : 0.045552, loss_ce: 0.012361
2021-12-14 03:03:16,503 iteration 4074 : loss : 0.053300, loss_ce: 0.020767
2021-12-14 03:03:18,120 iteration 4075 : loss : 0.048721, loss_ce: 0.013374
2021-12-14 03:03:19,651 iteration 4076 : loss : 0.058875, loss_ce: 0.019238
2021-12-14 03:03:21,214 iteration 4077 : loss : 0.044842, loss_ce: 0.012898
2021-12-14 03:03:22,838 iteration 4078 : loss : 0.066639, loss_ce: 0.021169
2021-12-14 03:03:24,445 iteration 4079 : loss : 0.056052, loss_ce: 0.022849
2021-12-14 03:03:24,445 Training Data Eval:
2021-12-14 03:03:32,612   Average segmentation loss on training set: 0.0398
2021-12-14 03:03:32,612 Validation Data Eval:
2021-12-14 03:03:35,402   Average segmentation loss on validation set: 0.0948
2021-12-14 03:03:37,034 iteration 4080 : loss : 0.051830, loss_ce: 0.018956
 60%|████████████████▏          | 240/400 [1:58:34<1:22:34, 30.96s/it]2021-12-14 03:03:38,703 iteration 4081 : loss : 0.061538, loss_ce: 0.019919
2021-12-14 03:03:40,296 iteration 4082 : loss : 0.053397, loss_ce: 0.017230
2021-12-14 03:03:41,826 iteration 4083 : loss : 0.048104, loss_ce: 0.016140
2021-12-14 03:03:43,404 iteration 4084 : loss : 0.051920, loss_ce: 0.013994
2021-12-14 03:03:44,939 iteration 4085 : loss : 0.052380, loss_ce: 0.014394
2021-12-14 03:03:46,634 iteration 4086 : loss : 0.083669, loss_ce: 0.027395
2021-12-14 03:03:48,238 iteration 4087 : loss : 0.072135, loss_ce: 0.013508
2021-12-14 03:03:49,750 iteration 4088 : loss : 0.060531, loss_ce: 0.025428
2021-12-14 03:03:51,320 iteration 4089 : loss : 0.052735, loss_ce: 0.015328
2021-12-14 03:03:52,804 iteration 4090 : loss : 0.050939, loss_ce: 0.014004
2021-12-14 03:03:54,367 iteration 4091 : loss : 0.060172, loss_ce: 0.021450
2021-12-14 03:03:55,950 iteration 4092 : loss : 0.052001, loss_ce: 0.015693
2021-12-14 03:03:57,539 iteration 4093 : loss : 0.055923, loss_ce: 0.018087
2021-12-14 03:03:59,087 iteration 4094 : loss : 0.050069, loss_ce: 0.016041
2021-12-14 03:04:00,675 iteration 4095 : loss : 0.063516, loss_ce: 0.023726
2021-12-14 03:04:02,230 iteration 4096 : loss : 0.052635, loss_ce: 0.024062
2021-12-14 03:04:03,796 iteration 4097 : loss : 0.055977, loss_ce: 0.017727
 60%|████████████████▎          | 241/400 [1:59:00<1:18:42, 29.70s/it]2021-12-14 03:04:05,393 iteration 4098 : loss : 0.056182, loss_ce: 0.017148
2021-12-14 03:04:06,933 iteration 4099 : loss : 0.054043, loss_ce: 0.012921
2021-12-14 03:04:08,509 iteration 4100 : loss : 0.052272, loss_ce: 0.014925
2021-12-14 03:04:10,125 iteration 4101 : loss : 0.063023, loss_ce: 0.018893
2021-12-14 03:04:11,738 iteration 4102 : loss : 0.065916, loss_ce: 0.025905
2021-12-14 03:04:13,340 iteration 4103 : loss : 0.071091, loss_ce: 0.027811
2021-12-14 03:04:14,928 iteration 4104 : loss : 0.061736, loss_ce: 0.022666
2021-12-14 03:04:16,523 iteration 4105 : loss : 0.048557, loss_ce: 0.015506
2021-12-14 03:04:18,088 iteration 4106 : loss : 0.059371, loss_ce: 0.020490
2021-12-14 03:04:19,650 iteration 4107 : loss : 0.050881, loss_ce: 0.015117
2021-12-14 03:04:21,232 iteration 4108 : loss : 0.048110, loss_ce: 0.017381
2021-12-14 03:04:22,755 iteration 4109 : loss : 0.049436, loss_ce: 0.014725
2021-12-14 03:04:24,365 iteration 4110 : loss : 0.056014, loss_ce: 0.015283
2021-12-14 03:04:26,090 iteration 4111 : loss : 0.062093, loss_ce: 0.027041
2021-12-14 03:04:27,638 iteration 4112 : loss : 0.061142, loss_ce: 0.018658
2021-12-14 03:04:29,250 iteration 4113 : loss : 0.058339, loss_ce: 0.015862
2021-12-14 03:04:30,816 iteration 4114 : loss : 0.051751, loss_ce: 0.019309
 60%|████████████████▎          | 242/400 [1:59:27<1:16:05, 28.90s/it]2021-12-14 03:04:32,405 iteration 4115 : loss : 0.050325, loss_ce: 0.020982
2021-12-14 03:04:34,044 iteration 4116 : loss : 0.059463, loss_ce: 0.020148
2021-12-14 03:04:35,570 iteration 4117 : loss : 0.048216, loss_ce: 0.014485
2021-12-14 03:04:37,204 iteration 4118 : loss : 0.055442, loss_ce: 0.019428
2021-12-14 03:04:38,903 iteration 4119 : loss : 0.071040, loss_ce: 0.019743
2021-12-14 03:04:40,510 iteration 4120 : loss : 0.052262, loss_ce: 0.012964
2021-12-14 03:04:42,052 iteration 4121 : loss : 0.055694, loss_ce: 0.015069
2021-12-14 03:04:43,621 iteration 4122 : loss : 0.074179, loss_ce: 0.019483
2021-12-14 03:04:45,144 iteration 4123 : loss : 0.041983, loss_ce: 0.013902
2021-12-14 03:04:46,754 iteration 4124 : loss : 0.061397, loss_ce: 0.023617
2021-12-14 03:04:48,353 iteration 4125 : loss : 0.054158, loss_ce: 0.020255
2021-12-14 03:04:49,939 iteration 4126 : loss : 0.047858, loss_ce: 0.016150
2021-12-14 03:04:51,472 iteration 4127 : loss : 0.042206, loss_ce: 0.016014
2021-12-14 03:04:53,146 iteration 4128 : loss : 0.065325, loss_ce: 0.016498
2021-12-14 03:04:54,667 iteration 4129 : loss : 0.057272, loss_ce: 0.013279
2021-12-14 03:04:56,172 iteration 4130 : loss : 0.048597, loss_ce: 0.013968
2021-12-14 03:04:57,727 iteration 4131 : loss : 0.050819, loss_ce: 0.018247
 61%|████████████████▍          | 243/400 [1:59:54<1:14:03, 28.30s/it]2021-12-14 03:04:59,401 iteration 4132 : loss : 0.056775, loss_ce: 0.014316
2021-12-14 03:05:00,999 iteration 4133 : loss : 0.064912, loss_ce: 0.019157
2021-12-14 03:05:02,617 iteration 4134 : loss : 0.062258, loss_ce: 0.021593
2021-12-14 03:05:04,122 iteration 4135 : loss : 0.050981, loss_ce: 0.019120
2021-12-14 03:05:05,693 iteration 4136 : loss : 0.060994, loss_ce: 0.025085
2021-12-14 03:05:07,204 iteration 4137 : loss : 0.046708, loss_ce: 0.013464
2021-12-14 03:05:08,807 iteration 4138 : loss : 0.051432, loss_ce: 0.020748
2021-12-14 03:05:10,408 iteration 4139 : loss : 0.055151, loss_ce: 0.020297
2021-12-14 03:05:12,008 iteration 4140 : loss : 0.045336, loss_ce: 0.015941
2021-12-14 03:05:13,610 iteration 4141 : loss : 0.053243, loss_ce: 0.016611
2021-12-14 03:05:15,258 iteration 4142 : loss : 0.069272, loss_ce: 0.023579
2021-12-14 03:05:16,746 iteration 4143 : loss : 0.048126, loss_ce: 0.013062
2021-12-14 03:05:18,257 iteration 4144 : loss : 0.047128, loss_ce: 0.009793
2021-12-14 03:05:19,883 iteration 4145 : loss : 0.052554, loss_ce: 0.018500
2021-12-14 03:05:21,428 iteration 4146 : loss : 0.049741, loss_ce: 0.019482
2021-12-14 03:05:23,013 iteration 4147 : loss : 0.049000, loss_ce: 0.015060
2021-12-14 03:05:24,555 iteration 4148 : loss : 0.045159, loss_ce: 0.013318
 61%|████████████████▍          | 244/400 [2:00:21<1:12:25, 27.86s/it]2021-12-14 03:05:26,090 iteration 4149 : loss : 0.051687, loss_ce: 0.015895
2021-12-14 03:05:27,676 iteration 4150 : loss : 0.049086, loss_ce: 0.013535
2021-12-14 03:05:29,294 iteration 4151 : loss : 0.057311, loss_ce: 0.014998
2021-12-14 03:05:30,875 iteration 4152 : loss : 0.049154, loss_ce: 0.015688
2021-12-14 03:05:32,379 iteration 4153 : loss : 0.047534, loss_ce: 0.015716
2021-12-14 03:05:33,962 iteration 4154 : loss : 0.049929, loss_ce: 0.014874
2021-12-14 03:05:35,522 iteration 4155 : loss : 0.051514, loss_ce: 0.015776
2021-12-14 03:05:37,036 iteration 4156 : loss : 0.042729, loss_ce: 0.012226
2021-12-14 03:05:38,675 iteration 4157 : loss : 0.060415, loss_ce: 0.028046
2021-12-14 03:05:40,212 iteration 4158 : loss : 0.044918, loss_ce: 0.015476
2021-12-14 03:05:41,764 iteration 4159 : loss : 0.041881, loss_ce: 0.014922
2021-12-14 03:05:43,439 iteration 4160 : loss : 0.061988, loss_ce: 0.020029
2021-12-14 03:05:45,094 iteration 4161 : loss : 0.067385, loss_ce: 0.020580
2021-12-14 03:05:46,754 iteration 4162 : loss : 0.069790, loss_ce: 0.020944
2021-12-14 03:05:48,393 iteration 4163 : loss : 0.057402, loss_ce: 0.021184
2021-12-14 03:05:49,984 iteration 4164 : loss : 0.050098, loss_ce: 0.017104
2021-12-14 03:05:49,984 Training Data Eval:
2021-12-14 03:05:58,170   Average segmentation loss on training set: 0.0411
2021-12-14 03:05:58,171 Validation Data Eval:
2021-12-14 03:06:00,963   Average segmentation loss on validation set: 0.0919
2021-12-14 03:06:02,564 iteration 4165 : loss : 0.065264, loss_ce: 0.017013
 61%|████████████████▌          | 245/400 [2:00:59<1:19:50, 30.90s/it]2021-12-14 03:06:04,185 iteration 4166 : loss : 0.050968, loss_ce: 0.018368
2021-12-14 03:06:05,684 iteration 4167 : loss : 0.045603, loss_ce: 0.011977
2021-12-14 03:06:07,217 iteration 4168 : loss : 0.051219, loss_ce: 0.017823
2021-12-14 03:06:08,746 iteration 4169 : loss : 0.046586, loss_ce: 0.017108
2021-12-14 03:06:10,421 iteration 4170 : loss : 0.060565, loss_ce: 0.024999
2021-12-14 03:06:11,922 iteration 4171 : loss : 0.049949, loss_ce: 0.014843
2021-12-14 03:06:13,483 iteration 4172 : loss : 0.051952, loss_ce: 0.019224
2021-12-14 03:06:15,088 iteration 4173 : loss : 0.050226, loss_ce: 0.012418
2021-12-14 03:06:16,639 iteration 4174 : loss : 0.051065, loss_ce: 0.012243
2021-12-14 03:06:18,159 iteration 4175 : loss : 0.044971, loss_ce: 0.013305
2021-12-14 03:06:19,712 iteration 4176 : loss : 0.044801, loss_ce: 0.015516
2021-12-14 03:06:21,324 iteration 4177 : loss : 0.053968, loss_ce: 0.015776
2021-12-14 03:06:22,849 iteration 4178 : loss : 0.048224, loss_ce: 0.015191
2021-12-14 03:06:24,398 iteration 4179 : loss : 0.051294, loss_ce: 0.018026
2021-12-14 03:06:25,939 iteration 4180 : loss : 0.045386, loss_ce: 0.012432
2021-12-14 03:06:27,495 iteration 4181 : loss : 0.059684, loss_ce: 0.019426
2021-12-14 03:06:29,062 iteration 4182 : loss : 0.044946, loss_ce: 0.009248
 62%|████████████████▌          | 246/400 [2:01:26<1:15:55, 29.58s/it]2021-12-14 03:06:30,699 iteration 4183 : loss : 0.066036, loss_ce: 0.023941
2021-12-14 03:06:32,312 iteration 4184 : loss : 0.046154, loss_ce: 0.017421
2021-12-14 03:06:33,890 iteration 4185 : loss : 0.052794, loss_ce: 0.020285
2021-12-14 03:06:35,447 iteration 4186 : loss : 0.043806, loss_ce: 0.010634
2021-12-14 03:06:37,066 iteration 4187 : loss : 0.071850, loss_ce: 0.022724
2021-12-14 03:06:38,612 iteration 4188 : loss : 0.055720, loss_ce: 0.015777
2021-12-14 03:06:40,289 iteration 4189 : loss : 0.054514, loss_ce: 0.018825
2021-12-14 03:06:41,920 iteration 4190 : loss : 0.066070, loss_ce: 0.027199
2021-12-14 03:06:43,559 iteration 4191 : loss : 0.056686, loss_ce: 0.018761
2021-12-14 03:06:45,044 iteration 4192 : loss : 0.042055, loss_ce: 0.012160
2021-12-14 03:06:46,630 iteration 4193 : loss : 0.055068, loss_ce: 0.022485
2021-12-14 03:06:48,244 iteration 4194 : loss : 0.047643, loss_ce: 0.014601
2021-12-14 03:06:49,803 iteration 4195 : loss : 0.061725, loss_ce: 0.016782
2021-12-14 03:06:51,410 iteration 4196 : loss : 0.048817, loss_ce: 0.016882
2021-12-14 03:06:52,968 iteration 4197 : loss : 0.052588, loss_ce: 0.015065
2021-12-14 03:06:54,528 iteration 4198 : loss : 0.048119, loss_ce: 0.016954
2021-12-14 03:06:56,043 iteration 4199 : loss : 0.049108, loss_ce: 0.015038
 62%|████████████████▋          | 247/400 [2:01:52<1:13:26, 28.80s/it]2021-12-14 03:06:57,653 iteration 4200 : loss : 0.053729, loss_ce: 0.017479
2021-12-14 03:06:59,256 iteration 4201 : loss : 0.058265, loss_ce: 0.021826
2021-12-14 03:07:00,856 iteration 4202 : loss : 0.044576, loss_ce: 0.015226
2021-12-14 03:07:02,533 iteration 4203 : loss : 0.055834, loss_ce: 0.019936
2021-12-14 03:07:04,101 iteration 4204 : loss : 0.045407, loss_ce: 0.015132
2021-12-14 03:07:05,672 iteration 4205 : loss : 0.054087, loss_ce: 0.020633
2021-12-14 03:07:07,365 iteration 4206 : loss : 0.052435, loss_ce: 0.016781
2021-12-14 03:07:08,984 iteration 4207 : loss : 0.055634, loss_ce: 0.019283
2021-12-14 03:07:10,475 iteration 4208 : loss : 0.043339, loss_ce: 0.014259
2021-12-14 03:07:12,016 iteration 4209 : loss : 0.051121, loss_ce: 0.018913
2021-12-14 03:07:13,559 iteration 4210 : loss : 0.047307, loss_ce: 0.014883
2021-12-14 03:07:15,149 iteration 4211 : loss : 0.056621, loss_ce: 0.021231
2021-12-14 03:07:16,768 iteration 4212 : loss : 0.059673, loss_ce: 0.018785
2021-12-14 03:07:18,311 iteration 4213 : loss : 0.054727, loss_ce: 0.012914
2021-12-14 03:07:19,922 iteration 4214 : loss : 0.060674, loss_ce: 0.015834
2021-12-14 03:07:21,490 iteration 4215 : loss : 0.051823, loss_ce: 0.014481
2021-12-14 03:07:23,048 iteration 4216 : loss : 0.063913, loss_ce: 0.017653
 62%|████████████████▋          | 248/400 [2:02:20<1:11:36, 28.26s/it]2021-12-14 03:07:24,712 iteration 4217 : loss : 0.054629, loss_ce: 0.016746
2021-12-14 03:07:26,269 iteration 4218 : loss : 0.058279, loss_ce: 0.018542
2021-12-14 03:07:27,808 iteration 4219 : loss : 0.047879, loss_ce: 0.016535
2021-12-14 03:07:29,291 iteration 4220 : loss : 0.055413, loss_ce: 0.013752
2021-12-14 03:07:31,005 iteration 4221 : loss : 0.053557, loss_ce: 0.019439
2021-12-14 03:07:32,676 iteration 4222 : loss : 0.057733, loss_ce: 0.016903
2021-12-14 03:07:34,232 iteration 4223 : loss : 0.047797, loss_ce: 0.014678
2021-12-14 03:07:35,865 iteration 4224 : loss : 0.055071, loss_ce: 0.014236
2021-12-14 03:07:37,462 iteration 4225 : loss : 0.055357, loss_ce: 0.014288
2021-12-14 03:07:39,086 iteration 4226 : loss : 0.049341, loss_ce: 0.019146
2021-12-14 03:07:40,688 iteration 4227 : loss : 0.049538, loss_ce: 0.017286
2021-12-14 03:07:42,220 iteration 4228 : loss : 0.051741, loss_ce: 0.017286
2021-12-14 03:07:43,787 iteration 4229 : loss : 0.062006, loss_ce: 0.023785
2021-12-14 03:07:45,347 iteration 4230 : loss : 0.067741, loss_ce: 0.027520
2021-12-14 03:07:46,969 iteration 4231 : loss : 0.048397, loss_ce: 0.015852
2021-12-14 03:07:48,595 iteration 4232 : loss : 0.057876, loss_ce: 0.015953
2021-12-14 03:07:50,171 iteration 4233 : loss : 0.065123, loss_ce: 0.026916
 62%|████████████████▊          | 249/400 [2:02:47<1:10:16, 27.92s/it]2021-12-14 03:07:51,726 iteration 4234 : loss : 0.055397, loss_ce: 0.011074
2021-12-14 03:07:53,242 iteration 4235 : loss : 0.039483, loss_ce: 0.011392
2021-12-14 03:07:54,847 iteration 4236 : loss : 0.048626, loss_ce: 0.014133
2021-12-14 03:07:56,381 iteration 4237 : loss : 0.047245, loss_ce: 0.016643
2021-12-14 03:07:57,951 iteration 4238 : loss : 0.060588, loss_ce: 0.028126
2021-12-14 03:07:59,659 iteration 4239 : loss : 0.056976, loss_ce: 0.020577
2021-12-14 03:08:01,250 iteration 4240 : loss : 0.052703, loss_ce: 0.013930
2021-12-14 03:08:02,745 iteration 4241 : loss : 0.048093, loss_ce: 0.018658
2021-12-14 03:08:04,321 iteration 4242 : loss : 0.057614, loss_ce: 0.014969
2021-12-14 03:08:05,869 iteration 4243 : loss : 0.060577, loss_ce: 0.018765
2021-12-14 03:08:07,366 iteration 4244 : loss : 0.042407, loss_ce: 0.015624
2021-12-14 03:08:08,984 iteration 4245 : loss : 0.055271, loss_ce: 0.019279
2021-12-14 03:08:10,635 iteration 4246 : loss : 0.062875, loss_ce: 0.015040
2021-12-14 03:08:12,241 iteration 4247 : loss : 0.049962, loss_ce: 0.017445
2021-12-14 03:08:13,760 iteration 4248 : loss : 0.050720, loss_ce: 0.016753
2021-12-14 03:08:15,398 iteration 4249 : loss : 0.054366, loss_ce: 0.015438
2021-12-14 03:08:15,399 Training Data Eval:
2021-12-14 03:08:23,583   Average segmentation loss on training set: 0.0386
2021-12-14 03:08:23,584 Validation Data Eval:
2021-12-14 03:08:26,379   Average segmentation loss on validation set: 0.0938
2021-12-14 03:08:27,951 iteration 4250 : loss : 0.064897, loss_ce: 0.018182
 62%|████████████████▉          | 250/400 [2:03:24<1:17:11, 30.88s/it]2021-12-14 03:08:29,639 iteration 4251 : loss : 0.057407, loss_ce: 0.014765
2021-12-14 03:08:31,259 iteration 4252 : loss : 0.050344, loss_ce: 0.020409
2021-12-14 03:08:32,837 iteration 4253 : loss : 0.052420, loss_ce: 0.016192
2021-12-14 03:08:34,454 iteration 4254 : loss : 0.046532, loss_ce: 0.014634
2021-12-14 03:08:36,080 iteration 4255 : loss : 0.048266, loss_ce: 0.015280
2021-12-14 03:08:37,570 iteration 4256 : loss : 0.049565, loss_ce: 0.018261
2021-12-14 03:08:39,142 iteration 4257 : loss : 0.050406, loss_ce: 0.015442
2021-12-14 03:08:40,648 iteration 4258 : loss : 0.050623, loss_ce: 0.013355
2021-12-14 03:08:42,239 iteration 4259 : loss : 0.051650, loss_ce: 0.017565
2021-12-14 03:08:43,837 iteration 4260 : loss : 0.054590, loss_ce: 0.014226
2021-12-14 03:08:45,440 iteration 4261 : loss : 0.046784, loss_ce: 0.015041
2021-12-14 03:08:46,978 iteration 4262 : loss : 0.045064, loss_ce: 0.017708
2021-12-14 03:08:48,578 iteration 4263 : loss : 0.057257, loss_ce: 0.020836
2021-12-14 03:08:50,215 iteration 4264 : loss : 0.058399, loss_ce: 0.019915
2021-12-14 03:08:51,789 iteration 4265 : loss : 0.062964, loss_ce: 0.015871
2021-12-14 03:08:53,396 iteration 4266 : loss : 0.059393, loss_ce: 0.019420
2021-12-14 03:08:55,024 iteration 4267 : loss : 0.050649, loss_ce: 0.016135
 63%|████████████████▉          | 251/400 [2:03:51<1:13:51, 29.74s/it]2021-12-14 03:08:56,665 iteration 4268 : loss : 0.056180, loss_ce: 0.011813
2021-12-14 03:08:58,227 iteration 4269 : loss : 0.056389, loss_ce: 0.017738
2021-12-14 03:08:59,764 iteration 4270 : loss : 0.056251, loss_ce: 0.024814
2021-12-14 03:09:01,265 iteration 4271 : loss : 0.045517, loss_ce: 0.014607
2021-12-14 03:09:02,843 iteration 4272 : loss : 0.050780, loss_ce: 0.018706
2021-12-14 03:09:04,350 iteration 4273 : loss : 0.043980, loss_ce: 0.014994
2021-12-14 03:09:06,004 iteration 4274 : loss : 0.056815, loss_ce: 0.021295
2021-12-14 03:09:07,557 iteration 4275 : loss : 0.044033, loss_ce: 0.013802
2021-12-14 03:09:09,179 iteration 4276 : loss : 0.049594, loss_ce: 0.012284
2021-12-14 03:09:10,804 iteration 4277 : loss : 0.050011, loss_ce: 0.014622
2021-12-14 03:09:12,429 iteration 4278 : loss : 0.054095, loss_ce: 0.015369
2021-12-14 03:09:13,998 iteration 4279 : loss : 0.053197, loss_ce: 0.023105
2021-12-14 03:09:15,592 iteration 4280 : loss : 0.054704, loss_ce: 0.014463
2021-12-14 03:09:17,182 iteration 4281 : loss : 0.052651, loss_ce: 0.014401
2021-12-14 03:09:18,698 iteration 4282 : loss : 0.049184, loss_ce: 0.014584
2021-12-14 03:09:20,266 iteration 4283 : loss : 0.057085, loss_ce: 0.015580
2021-12-14 03:09:21,809 iteration 4284 : loss : 0.049165, loss_ce: 0.016788
 63%|█████████████████          | 252/400 [2:04:18<1:11:09, 28.85s/it]2021-12-14 03:09:23,376 iteration 4285 : loss : 0.053566, loss_ce: 0.014389
2021-12-14 03:09:24,996 iteration 4286 : loss : 0.051748, loss_ce: 0.016835
2021-12-14 03:09:26,528 iteration 4287 : loss : 0.050752, loss_ce: 0.019838
2021-12-14 03:09:28,061 iteration 4288 : loss : 0.051396, loss_ce: 0.020571
2021-12-14 03:09:29,644 iteration 4289 : loss : 0.051173, loss_ce: 0.016871
2021-12-14 03:09:31,207 iteration 4290 : loss : 0.068646, loss_ce: 0.012102
2021-12-14 03:09:32,807 iteration 4291 : loss : 0.052753, loss_ce: 0.016594
2021-12-14 03:09:34,400 iteration 4292 : loss : 0.057221, loss_ce: 0.023055
2021-12-14 03:09:35,979 iteration 4293 : loss : 0.053805, loss_ce: 0.014515
2021-12-14 03:09:37,525 iteration 4294 : loss : 0.047687, loss_ce: 0.010916
2021-12-14 03:09:39,197 iteration 4295 : loss : 0.059231, loss_ce: 0.018937
2021-12-14 03:09:40,778 iteration 4296 : loss : 0.059531, loss_ce: 0.016315
2021-12-14 03:09:42,383 iteration 4297 : loss : 0.058796, loss_ce: 0.018341
2021-12-14 03:09:43,930 iteration 4298 : loss : 0.046753, loss_ce: 0.018979
2021-12-14 03:09:45,560 iteration 4299 : loss : 0.049188, loss_ce: 0.018095
2021-12-14 03:09:47,218 iteration 4300 : loss : 0.057617, loss_ce: 0.020964
2021-12-14 03:09:48,866 iteration 4301 : loss : 0.049869, loss_ce: 0.016515
 63%|█████████████████          | 253/400 [2:04:45<1:09:22, 28.32s/it]2021-12-14 03:09:50,541 iteration 4302 : loss : 0.062514, loss_ce: 0.022031
2021-12-14 03:09:52,182 iteration 4303 : loss : 0.073425, loss_ce: 0.013003
2021-12-14 03:09:53,729 iteration 4304 : loss : 0.051552, loss_ce: 0.017886
2021-12-14 03:09:55,277 iteration 4305 : loss : 0.049258, loss_ce: 0.016736
2021-12-14 03:09:56,831 iteration 4306 : loss : 0.055254, loss_ce: 0.014660
2021-12-14 03:09:58,350 iteration 4307 : loss : 0.045560, loss_ce: 0.017874
2021-12-14 03:09:59,954 iteration 4308 : loss : 0.044971, loss_ce: 0.012479
2021-12-14 03:10:01,595 iteration 4309 : loss : 0.055698, loss_ce: 0.017172
2021-12-14 03:10:03,185 iteration 4310 : loss : 0.048178, loss_ce: 0.015501
2021-12-14 03:10:04,731 iteration 4311 : loss : 0.057391, loss_ce: 0.018657
2021-12-14 03:10:06,261 iteration 4312 : loss : 0.052104, loss_ce: 0.016333
2021-12-14 03:10:07,804 iteration 4313 : loss : 0.045041, loss_ce: 0.017957
2021-12-14 03:10:09,351 iteration 4314 : loss : 0.046788, loss_ce: 0.013178
2021-12-14 03:10:10,965 iteration 4315 : loss : 0.050744, loss_ce: 0.015765
2021-12-14 03:10:12,509 iteration 4316 : loss : 0.052861, loss_ce: 0.014866
2021-12-14 03:10:14,139 iteration 4317 : loss : 0.046492, loss_ce: 0.015761
2021-12-14 03:10:15,665 iteration 4318 : loss : 0.052491, loss_ce: 0.016287
 64%|█████████████████▏         | 254/400 [2:05:12<1:07:47, 27.86s/it]2021-12-14 03:10:17,340 iteration 4319 : loss : 0.046810, loss_ce: 0.013209
2021-12-14 03:10:18,953 iteration 4320 : loss : 0.063562, loss_ce: 0.022590
2021-12-14 03:10:20,433 iteration 4321 : loss : 0.043928, loss_ce: 0.011881
2021-12-14 03:10:22,006 iteration 4322 : loss : 0.042691, loss_ce: 0.011615
2021-12-14 03:10:23,526 iteration 4323 : loss : 0.047389, loss_ce: 0.018035
2021-12-14 03:10:25,208 iteration 4324 : loss : 0.067666, loss_ce: 0.027711
2021-12-14 03:10:26,789 iteration 4325 : loss : 0.063957, loss_ce: 0.022930
2021-12-14 03:10:28,343 iteration 4326 : loss : 0.048699, loss_ce: 0.018714
2021-12-14 03:10:29,951 iteration 4327 : loss : 0.067915, loss_ce: 0.018488
2021-12-14 03:10:31,490 iteration 4328 : loss : 0.070285, loss_ce: 0.022315
2021-12-14 03:10:33,131 iteration 4329 : loss : 0.063357, loss_ce: 0.013824
2021-12-14 03:10:34,746 iteration 4330 : loss : 0.047623, loss_ce: 0.017777
2021-12-14 03:10:36,412 iteration 4331 : loss : 0.060806, loss_ce: 0.016238
2021-12-14 03:10:38,030 iteration 4332 : loss : 0.064107, loss_ce: 0.021429
2021-12-14 03:10:39,681 iteration 4333 : loss : 0.056124, loss_ce: 0.019632
2021-12-14 03:10:41,264 iteration 4334 : loss : 0.051330, loss_ce: 0.021082
2021-12-14 03:10:41,264 Training Data Eval:
2021-12-14 03:10:49,444   Average segmentation loss on training set: 0.0386
2021-12-14 03:10:49,445 Validation Data Eval:
2021-12-14 03:10:52,240   Average segmentation loss on validation set: 0.0984
2021-12-14 03:10:53,862 iteration 4335 : loss : 0.066872, loss_ce: 0.015297
 64%|█████████████████▏         | 255/400 [2:05:50<1:14:49, 30.96s/it]2021-12-14 03:10:55,390 iteration 4336 : loss : 0.043758, loss_ce: 0.017787
2021-12-14 03:10:57,048 iteration 4337 : loss : 0.052129, loss_ce: 0.019220
2021-12-14 03:10:58,630 iteration 4338 : loss : 0.046382, loss_ce: 0.014216
2021-12-14 03:11:00,166 iteration 4339 : loss : 0.049308, loss_ce: 0.014561
2021-12-14 03:11:01,786 iteration 4340 : loss : 0.057747, loss_ce: 0.021414
2021-12-14 03:11:03,315 iteration 4341 : loss : 0.043438, loss_ce: 0.012583
2021-12-14 03:11:04,940 iteration 4342 : loss : 0.061123, loss_ce: 0.017996
2021-12-14 03:11:06,554 iteration 4343 : loss : 0.060016, loss_ce: 0.016128
2021-12-14 03:11:08,160 iteration 4344 : loss : 0.062159, loss_ce: 0.024642
2021-12-14 03:11:09,824 iteration 4345 : loss : 0.059904, loss_ce: 0.021726
2021-12-14 03:11:11,338 iteration 4346 : loss : 0.053352, loss_ce: 0.012473
2021-12-14 03:11:12,914 iteration 4347 : loss : 0.052450, loss_ce: 0.020326
2021-12-14 03:11:14,441 iteration 4348 : loss : 0.045094, loss_ce: 0.018011
2021-12-14 03:11:15,922 iteration 4349 : loss : 0.044659, loss_ce: 0.010966
2021-12-14 03:11:17,406 iteration 4350 : loss : 0.050151, loss_ce: 0.014592
2021-12-14 03:11:18,992 iteration 4351 : loss : 0.054766, loss_ce: 0.015349
2021-12-14 03:11:20,574 iteration 4352 : loss : 0.049617, loss_ce: 0.017887
 64%|█████████████████▎         | 256/400 [2:06:17<1:11:14, 29.69s/it]2021-12-14 03:11:22,157 iteration 4353 : loss : 0.059900, loss_ce: 0.018489
2021-12-14 03:11:23,805 iteration 4354 : loss : 0.064465, loss_ce: 0.025604
2021-12-14 03:11:25,434 iteration 4355 : loss : 0.051305, loss_ce: 0.017512
2021-12-14 03:11:27,102 iteration 4356 : loss : 0.060147, loss_ce: 0.014153
2021-12-14 03:11:28,725 iteration 4357 : loss : 0.051529, loss_ce: 0.020236
2021-12-14 03:11:30,367 iteration 4358 : loss : 0.059826, loss_ce: 0.020850
2021-12-14 03:11:31,969 iteration 4359 : loss : 0.059726, loss_ce: 0.019510
2021-12-14 03:11:33,535 iteration 4360 : loss : 0.061708, loss_ce: 0.024191
2021-12-14 03:11:35,165 iteration 4361 : loss : 0.056846, loss_ce: 0.018549
2021-12-14 03:11:36,746 iteration 4362 : loss : 0.051599, loss_ce: 0.019595
2021-12-14 03:11:38,328 iteration 4363 : loss : 0.045013, loss_ce: 0.015099
2021-12-14 03:11:39,938 iteration 4364 : loss : 0.050515, loss_ce: 0.015839
2021-12-14 03:11:41,618 iteration 4365 : loss : 0.056077, loss_ce: 0.020769
2021-12-14 03:11:43,149 iteration 4366 : loss : 0.048799, loss_ce: 0.013005
2021-12-14 03:11:44,627 iteration 4367 : loss : 0.053041, loss_ce: 0.019239
2021-12-14 03:11:46,140 iteration 4368 : loss : 0.054733, loss_ce: 0.016778
2021-12-14 03:11:47,733 iteration 4369 : loss : 0.046746, loss_ce: 0.015108
 64%|█████████████████▎         | 257/400 [2:06:44<1:08:56, 28.93s/it]2021-12-14 03:11:49,373 iteration 4370 : loss : 0.054179, loss_ce: 0.015015
2021-12-14 03:11:50,971 iteration 4371 : loss : 0.054749, loss_ce: 0.022039
2021-12-14 03:11:52,575 iteration 4372 : loss : 0.049727, loss_ce: 0.015766
2021-12-14 03:11:54,173 iteration 4373 : loss : 0.045577, loss_ce: 0.019497
2021-12-14 03:11:55,779 iteration 4374 : loss : 0.053298, loss_ce: 0.014841
2021-12-14 03:11:57,389 iteration 4375 : loss : 0.052620, loss_ce: 0.020252
2021-12-14 03:11:58,941 iteration 4376 : loss : 0.069964, loss_ce: 0.023263
2021-12-14 03:12:00,496 iteration 4377 : loss : 0.044906, loss_ce: 0.011347
2021-12-14 03:12:02,007 iteration 4378 : loss : 0.045800, loss_ce: 0.014610
2021-12-14 03:12:03,528 iteration 4379 : loss : 0.053701, loss_ce: 0.015593
2021-12-14 03:12:05,021 iteration 4380 : loss : 0.049541, loss_ce: 0.014519
2021-12-14 03:12:06,618 iteration 4381 : loss : 0.058937, loss_ce: 0.016860
2021-12-14 03:12:08,189 iteration 4382 : loss : 0.088761, loss_ce: 0.015537
2021-12-14 03:12:09,736 iteration 4383 : loss : 0.060970, loss_ce: 0.018527
2021-12-14 03:12:11,368 iteration 4384 : loss : 0.054840, loss_ce: 0.018236
2021-12-14 03:12:13,005 iteration 4385 : loss : 0.056479, loss_ce: 0.017805
2021-12-14 03:12:14,549 iteration 4386 : loss : 0.057513, loss_ce: 0.022591
 64%|█████████████████▍         | 258/400 [2:07:11<1:06:58, 28.30s/it]2021-12-14 03:12:16,125 iteration 4387 : loss : 0.054599, loss_ce: 0.014428
2021-12-14 03:12:17,713 iteration 4388 : loss : 0.051736, loss_ce: 0.018974
2021-12-14 03:12:19,298 iteration 4389 : loss : 0.060526, loss_ce: 0.019510
2021-12-14 03:12:20,827 iteration 4390 : loss : 0.051873, loss_ce: 0.014446
2021-12-14 03:12:22,426 iteration 4391 : loss : 0.062881, loss_ce: 0.018259
2021-12-14 03:12:23,993 iteration 4392 : loss : 0.042905, loss_ce: 0.011475
2021-12-14 03:12:25,635 iteration 4393 : loss : 0.075000, loss_ce: 0.028675
2021-12-14 03:12:27,259 iteration 4394 : loss : 0.049173, loss_ce: 0.016286
2021-12-14 03:12:28,939 iteration 4395 : loss : 0.053429, loss_ce: 0.017049
2021-12-14 03:12:30,487 iteration 4396 : loss : 0.050325, loss_ce: 0.014631
2021-12-14 03:12:32,167 iteration 4397 : loss : 0.057865, loss_ce: 0.026050
2021-12-14 03:12:33,699 iteration 4398 : loss : 0.048621, loss_ce: 0.016946
2021-12-14 03:12:35,328 iteration 4399 : loss : 0.057059, loss_ce: 0.020713
2021-12-14 03:12:36,929 iteration 4400 : loss : 0.068740, loss_ce: 0.020086
2021-12-14 03:12:38,652 iteration 4401 : loss : 0.065511, loss_ce: 0.022119
2021-12-14 03:12:40,247 iteration 4402 : loss : 0.053921, loss_ce: 0.015346
2021-12-14 03:12:41,847 iteration 4403 : loss : 0.048599, loss_ce: 0.014614
 65%|█████████████████▍         | 259/400 [2:07:38<1:05:47, 28.00s/it]2021-12-14 03:12:43,454 iteration 4404 : loss : 0.047007, loss_ce: 0.016564
2021-12-14 03:12:45,071 iteration 4405 : loss : 0.046991, loss_ce: 0.018220
2021-12-14 03:12:46,677 iteration 4406 : loss : 0.048221, loss_ce: 0.015817
2021-12-14 03:12:48,331 iteration 4407 : loss : 0.057717, loss_ce: 0.018270
2021-12-14 03:12:49,902 iteration 4408 : loss : 0.048327, loss_ce: 0.017993
2021-12-14 03:12:51,519 iteration 4409 : loss : 0.055057, loss_ce: 0.018553
2021-12-14 03:12:53,248 iteration 4410 : loss : 0.072297, loss_ce: 0.025232
2021-12-14 03:12:54,881 iteration 4411 : loss : 0.057673, loss_ce: 0.020433
2021-12-14 03:12:56,468 iteration 4412 : loss : 0.059225, loss_ce: 0.018564
2021-12-14 03:12:58,083 iteration 4413 : loss : 0.046722, loss_ce: 0.014318
2021-12-14 03:12:59,610 iteration 4414 : loss : 0.045795, loss_ce: 0.013072
2021-12-14 03:13:01,233 iteration 4415 : loss : 0.049534, loss_ce: 0.014122
2021-12-14 03:13:02,883 iteration 4416 : loss : 0.062107, loss_ce: 0.019399
2021-12-14 03:13:04,470 iteration 4417 : loss : 0.048771, loss_ce: 0.013786
2021-12-14 03:13:06,065 iteration 4418 : loss : 0.046695, loss_ce: 0.016929
2021-12-14 03:13:07,697 iteration 4419 : loss : 0.048952, loss_ce: 0.014195
2021-12-14 03:13:07,697 Training Data Eval:
2021-12-14 03:13:15,871   Average segmentation loss on training set: 0.0379
2021-12-14 03:13:15,872 Validation Data Eval:
2021-12-14 03:13:18,664   Average segmentation loss on validation set: 0.0971
2021-12-14 03:13:20,184 iteration 4420 : loss : 0.046075, loss_ce: 0.017641
 65%|█████████████████▌         | 260/400 [2:08:17<1:12:33, 31.10s/it]2021-12-14 03:13:21,790 iteration 4421 : loss : 0.045779, loss_ce: 0.013241
2021-12-14 03:13:23,387 iteration 4422 : loss : 0.052992, loss_ce: 0.018630
2021-12-14 03:13:25,031 iteration 4423 : loss : 0.056182, loss_ce: 0.018476
2021-12-14 03:13:26,560 iteration 4424 : loss : 0.046408, loss_ce: 0.012083
2021-12-14 03:13:28,077 iteration 4425 : loss : 0.045352, loss_ce: 0.013217
2021-12-14 03:13:29,716 iteration 4426 : loss : 0.046457, loss_ce: 0.014861
2021-12-14 03:13:31,248 iteration 4427 : loss : 0.048408, loss_ce: 0.018954
2021-12-14 03:13:32,733 iteration 4428 : loss : 0.042247, loss_ce: 0.015942
2021-12-14 03:13:34,236 iteration 4429 : loss : 0.058827, loss_ce: 0.016258
2021-12-14 03:13:35,739 iteration 4430 : loss : 0.044683, loss_ce: 0.015534
2021-12-14 03:13:37,326 iteration 4431 : loss : 0.058242, loss_ce: 0.021374
2021-12-14 03:13:38,948 iteration 4432 : loss : 0.054165, loss_ce: 0.017178
2021-12-14 03:13:40,501 iteration 4433 : loss : 0.067326, loss_ce: 0.015534
2021-12-14 03:13:42,019 iteration 4434 : loss : 0.042553, loss_ce: 0.014803
2021-12-14 03:13:43,592 iteration 4435 : loss : 0.072483, loss_ce: 0.017945
2021-12-14 03:13:45,164 iteration 4436 : loss : 0.048212, loss_ce: 0.017008
2021-12-14 03:13:46,800 iteration 4437 : loss : 0.052255, loss_ce: 0.015380
 65%|█████████████████▌         | 261/400 [2:08:43<1:08:56, 29.76s/it]2021-12-14 03:13:48,497 iteration 4438 : loss : 0.064886, loss_ce: 0.016956
2021-12-14 03:13:50,102 iteration 4439 : loss : 0.049278, loss_ce: 0.014579
2021-12-14 03:13:51,691 iteration 4440 : loss : 0.047683, loss_ce: 0.014666
2021-12-14 03:13:53,378 iteration 4441 : loss : 0.044706, loss_ce: 0.010999
2021-12-14 03:13:55,023 iteration 4442 : loss : 0.045141, loss_ce: 0.016948
2021-12-14 03:13:56,633 iteration 4443 : loss : 0.055834, loss_ce: 0.018936
2021-12-14 03:13:58,150 iteration 4444 : loss : 0.070788, loss_ce: 0.021160
2021-12-14 03:13:59,715 iteration 4445 : loss : 0.065125, loss_ce: 0.020897
2021-12-14 03:14:01,332 iteration 4446 : loss : 0.051538, loss_ce: 0.018050
2021-12-14 03:14:02,894 iteration 4447 : loss : 0.048466, loss_ce: 0.015548
2021-12-14 03:14:04,503 iteration 4448 : loss : 0.068233, loss_ce: 0.021431
2021-12-14 03:14:06,088 iteration 4449 : loss : 0.049707, loss_ce: 0.019281
2021-12-14 03:14:07,728 iteration 4450 : loss : 0.056977, loss_ce: 0.015400
2021-12-14 03:14:09,286 iteration 4451 : loss : 0.048868, loss_ce: 0.016112
2021-12-14 03:14:10,881 iteration 4452 : loss : 0.043613, loss_ce: 0.015314
2021-12-14 03:14:12,432 iteration 4453 : loss : 0.049881, loss_ce: 0.014873
2021-12-14 03:14:13,984 iteration 4454 : loss : 0.050797, loss_ce: 0.017317
 66%|█████████████████▋         | 262/400 [2:09:10<1:06:39, 28.98s/it]2021-12-14 03:14:15,637 iteration 4455 : loss : 0.052151, loss_ce: 0.013255
2021-12-14 03:14:17,134 iteration 4456 : loss : 0.046745, loss_ce: 0.014434
2021-12-14 03:14:18,728 iteration 4457 : loss : 0.052561, loss_ce: 0.017810
2021-12-14 03:14:20,409 iteration 4458 : loss : 0.084213, loss_ce: 0.031088
2021-12-14 03:14:22,157 iteration 4459 : loss : 0.051855, loss_ce: 0.018991
2021-12-14 03:14:23,707 iteration 4460 : loss : 0.048050, loss_ce: 0.014094
2021-12-14 03:14:25,296 iteration 4461 : loss : 0.051221, loss_ce: 0.014598
2021-12-14 03:14:26,922 iteration 4462 : loss : 0.049382, loss_ce: 0.018696
2021-12-14 03:14:28,492 iteration 4463 : loss : 0.059925, loss_ce: 0.018055
2021-12-14 03:14:30,046 iteration 4464 : loss : 0.052841, loss_ce: 0.017163
2021-12-14 03:14:31,551 iteration 4465 : loss : 0.054884, loss_ce: 0.012190
2021-12-14 03:14:33,079 iteration 4466 : loss : 0.046544, loss_ce: 0.012432
2021-12-14 03:14:34,656 iteration 4467 : loss : 0.068038, loss_ce: 0.026934
2021-12-14 03:14:36,265 iteration 4468 : loss : 0.053269, loss_ce: 0.018572
2021-12-14 03:14:37,912 iteration 4469 : loss : 0.053736, loss_ce: 0.021849
2021-12-14 03:14:39,549 iteration 4470 : loss : 0.052825, loss_ce: 0.017657
2021-12-14 03:14:41,216 iteration 4471 : loss : 0.065022, loss_ce: 0.016953
 66%|█████████████████▊         | 263/400 [2:09:38<1:04:58, 28.45s/it]2021-12-14 03:14:42,823 iteration 4472 : loss : 0.048299, loss_ce: 0.016965
2021-12-14 03:14:44,361 iteration 4473 : loss : 0.050993, loss_ce: 0.018603
2021-12-14 03:14:45,952 iteration 4474 : loss : 0.049159, loss_ce: 0.020911
2021-12-14 03:14:47,528 iteration 4475 : loss : 0.057596, loss_ce: 0.015884
2021-12-14 03:14:49,070 iteration 4476 : loss : 0.044210, loss_ce: 0.012379
2021-12-14 03:14:50,627 iteration 4477 : loss : 0.064635, loss_ce: 0.021267
2021-12-14 03:14:52,314 iteration 4478 : loss : 0.064757, loss_ce: 0.027769
2021-12-14 03:14:53,893 iteration 4479 : loss : 0.055293, loss_ce: 0.014681
2021-12-14 03:14:55,485 iteration 4480 : loss : 0.048584, loss_ce: 0.015651
2021-12-14 03:14:57,017 iteration 4481 : loss : 0.047230, loss_ce: 0.015049
2021-12-14 03:14:58,541 iteration 4482 : loss : 0.048246, loss_ce: 0.013249
2021-12-14 03:15:00,081 iteration 4483 : loss : 0.060381, loss_ce: 0.020726
2021-12-14 03:15:01,655 iteration 4484 : loss : 0.044839, loss_ce: 0.013530
2021-12-14 03:15:03,161 iteration 4485 : loss : 0.044882, loss_ce: 0.014850
2021-12-14 03:15:04,804 iteration 4486 : loss : 0.044897, loss_ce: 0.014176
2021-12-14 03:15:06,407 iteration 4487 : loss : 0.049699, loss_ce: 0.019096
2021-12-14 03:15:07,933 iteration 4488 : loss : 0.043952, loss_ce: 0.014806
 66%|█████████████████▊         | 264/400 [2:10:04<1:03:18, 27.93s/it]2021-12-14 03:15:09,607 iteration 4489 : loss : 0.070029, loss_ce: 0.026044
2021-12-14 03:15:11,187 iteration 4490 : loss : 0.055645, loss_ce: 0.021513
2021-12-14 03:15:12,872 iteration 4491 : loss : 0.053935, loss_ce: 0.018528
2021-12-14 03:15:14,423 iteration 4492 : loss : 0.052298, loss_ce: 0.012622
2021-12-14 03:15:16,087 iteration 4493 : loss : 0.057113, loss_ce: 0.028045
2021-12-14 03:15:17,633 iteration 4494 : loss : 0.058651, loss_ce: 0.017576
2021-12-14 03:15:19,222 iteration 4495 : loss : 0.052922, loss_ce: 0.012662
2021-12-14 03:15:20,816 iteration 4496 : loss : 0.051240, loss_ce: 0.013376
2021-12-14 03:15:22,292 iteration 4497 : loss : 0.054526, loss_ce: 0.021199
2021-12-14 03:15:23,859 iteration 4498 : loss : 0.048179, loss_ce: 0.013923
2021-12-14 03:15:25,403 iteration 4499 : loss : 0.046553, loss_ce: 0.016712
2021-12-14 03:15:26,976 iteration 4500 : loss : 0.052997, loss_ce: 0.016148
2021-12-14 03:15:28,522 iteration 4501 : loss : 0.051299, loss_ce: 0.018376
2021-12-14 03:15:30,076 iteration 4502 : loss : 0.055008, loss_ce: 0.016693
2021-12-14 03:15:31,728 iteration 4503 : loss : 0.049530, loss_ce: 0.014488
2021-12-14 03:15:33,219 iteration 4504 : loss : 0.046959, loss_ce: 0.016290
2021-12-14 03:15:33,219 Training Data Eval:
2021-12-14 03:15:41,390   Average segmentation loss on training set: 0.0377
2021-12-14 03:15:41,391 Validation Data Eval:
2021-12-14 03:15:44,191   Average segmentation loss on validation set: 0.0938
2021-12-14 03:15:45,772 iteration 4505 : loss : 0.046472, loss_ce: 0.014514
 66%|█████████████████▉         | 265/400 [2:10:42<1:09:32, 30.91s/it]2021-12-14 03:15:47,430 iteration 4506 : loss : 0.055441, loss_ce: 0.018789
2021-12-14 03:15:49,074 iteration 4507 : loss : 0.057865, loss_ce: 0.021291
2021-12-14 03:15:50,657 iteration 4508 : loss : 0.049802, loss_ce: 0.013980
2021-12-14 03:15:52,173 iteration 4509 : loss : 0.041576, loss_ce: 0.012310
2021-12-14 03:15:53,757 iteration 4510 : loss : 0.046945, loss_ce: 0.011910
2021-12-14 03:15:55,430 iteration 4511 : loss : 0.063636, loss_ce: 0.022401
2021-12-14 03:15:56,922 iteration 4512 : loss : 0.046569, loss_ce: 0.014357
2021-12-14 03:15:58,474 iteration 4513 : loss : 0.044550, loss_ce: 0.014130
2021-12-14 03:16:00,016 iteration 4514 : loss : 0.053728, loss_ce: 0.019422
2021-12-14 03:16:01,579 iteration 4515 : loss : 0.044529, loss_ce: 0.015979
2021-12-14 03:16:03,165 iteration 4516 : loss : 0.047711, loss_ce: 0.018287
2021-12-14 03:16:04,770 iteration 4517 : loss : 0.052377, loss_ce: 0.018079
2021-12-14 03:16:06,320 iteration 4518 : loss : 0.051005, loss_ce: 0.017859
2021-12-14 03:16:07,827 iteration 4519 : loss : 0.070919, loss_ce: 0.018336
2021-12-14 03:16:09,403 iteration 4520 : loss : 0.050427, loss_ce: 0.011443
2021-12-14 03:16:10,995 iteration 4521 : loss : 0.048662, loss_ce: 0.018494
2021-12-14 03:16:12,625 iteration 4522 : loss : 0.071205, loss_ce: 0.024724
 66%|█████████████████▉         | 266/400 [2:11:09<1:06:18, 29.69s/it]2021-12-14 03:16:14,339 iteration 4523 : loss : 0.051211, loss_ce: 0.018928
2021-12-14 03:16:15,940 iteration 4524 : loss : 0.049811, loss_ce: 0.017305
2021-12-14 03:16:17,555 iteration 4525 : loss : 0.054348, loss_ce: 0.020851
2021-12-14 03:16:19,132 iteration 4526 : loss : 0.047405, loss_ce: 0.013490
2021-12-14 03:16:20,633 iteration 4527 : loss : 0.051378, loss_ce: 0.015175
2021-12-14 03:16:22,176 iteration 4528 : loss : 0.046307, loss_ce: 0.013309
2021-12-14 03:16:23,773 iteration 4529 : loss : 0.051652, loss_ce: 0.017885
2021-12-14 03:16:25,315 iteration 4530 : loss : 0.061199, loss_ce: 0.014817
2021-12-14 03:16:26,900 iteration 4531 : loss : 0.054802, loss_ce: 0.018082
2021-12-14 03:16:28,505 iteration 4532 : loss : 0.041955, loss_ce: 0.012652
2021-12-14 03:16:30,057 iteration 4533 : loss : 0.051173, loss_ce: 0.017344
2021-12-14 03:16:31,617 iteration 4534 : loss : 0.052353, loss_ce: 0.013705
2021-12-14 03:16:33,225 iteration 4535 : loss : 0.043038, loss_ce: 0.013660
2021-12-14 03:16:34,825 iteration 4536 : loss : 0.052730, loss_ce: 0.016517
2021-12-14 03:16:36,402 iteration 4537 : loss : 0.060085, loss_ce: 0.021756
2021-12-14 03:16:37,974 iteration 4538 : loss : 0.056440, loss_ce: 0.018602
2021-12-14 03:16:39,546 iteration 4539 : loss : 0.049418, loss_ce: 0.016531
 67%|██████████████████         | 267/400 [2:11:36<1:03:58, 28.86s/it]2021-12-14 03:16:41,153 iteration 4540 : loss : 0.038494, loss_ce: 0.011626
2021-12-14 03:16:42,766 iteration 4541 : loss : 0.058094, loss_ce: 0.022376
2021-12-14 03:16:44,298 iteration 4542 : loss : 0.055257, loss_ce: 0.019183
2021-12-14 03:16:45,854 iteration 4543 : loss : 0.049738, loss_ce: 0.015487
2021-12-14 03:16:47,387 iteration 4544 : loss : 0.056796, loss_ce: 0.015714
2021-12-14 03:16:49,032 iteration 4545 : loss : 0.050046, loss_ce: 0.017314
2021-12-14 03:16:50,727 iteration 4546 : loss : 0.067370, loss_ce: 0.023940
2021-12-14 03:16:52,400 iteration 4547 : loss : 0.051267, loss_ce: 0.019331
2021-12-14 03:16:53,917 iteration 4548 : loss : 0.047733, loss_ce: 0.015582
2021-12-14 03:16:55,444 iteration 4549 : loss : 0.056129, loss_ce: 0.012469
2021-12-14 03:16:57,028 iteration 4550 : loss : 0.053731, loss_ce: 0.018676
2021-12-14 03:16:58,628 iteration 4551 : loss : 0.056910, loss_ce: 0.021591
2021-12-14 03:17:00,285 iteration 4552 : loss : 0.070038, loss_ce: 0.017956
2021-12-14 03:17:01,882 iteration 4553 : loss : 0.049108, loss_ce: 0.014454
2021-12-14 03:17:03,418 iteration 4554 : loss : 0.047362, loss_ce: 0.017430
2021-12-14 03:17:04,983 iteration 4555 : loss : 0.051560, loss_ce: 0.017520
2021-12-14 03:17:06,542 iteration 4556 : loss : 0.047468, loss_ce: 0.012747
 67%|██████████████████         | 268/400 [2:12:03<1:02:15, 28.30s/it]2021-12-14 03:17:08,144 iteration 4557 : loss : 0.048960, loss_ce: 0.017112
2021-12-14 03:17:09,756 iteration 4558 : loss : 0.057631, loss_ce: 0.018354
2021-12-14 03:17:11,415 iteration 4559 : loss : 0.057091, loss_ce: 0.018686
2021-12-14 03:17:13,029 iteration 4560 : loss : 0.054204, loss_ce: 0.023225
2021-12-14 03:17:14,570 iteration 4561 : loss : 0.045980, loss_ce: 0.013445
2021-12-14 03:17:16,160 iteration 4562 : loss : 0.056730, loss_ce: 0.019730
2021-12-14 03:17:17,718 iteration 4563 : loss : 0.049696, loss_ce: 0.013728
2021-12-14 03:17:19,267 iteration 4564 : loss : 0.042894, loss_ce: 0.015021
2021-12-14 03:17:20,829 iteration 4565 : loss : 0.047729, loss_ce: 0.015933
2021-12-14 03:17:22,416 iteration 4566 : loss : 0.049690, loss_ce: 0.015520
2021-12-14 03:17:23,986 iteration 4567 : loss : 0.050998, loss_ce: 0.017825
2021-12-14 03:17:25,484 iteration 4568 : loss : 0.049163, loss_ce: 0.015143
2021-12-14 03:17:27,004 iteration 4569 : loss : 0.054498, loss_ce: 0.018024
2021-12-14 03:17:28,535 iteration 4570 : loss : 0.048862, loss_ce: 0.016235
2021-12-14 03:17:30,143 iteration 4571 : loss : 0.047307, loss_ce: 0.018199
2021-12-14 03:17:31,744 iteration 4572 : loss : 0.052823, loss_ce: 0.017050
2021-12-14 03:17:33,366 iteration 4573 : loss : 0.059542, loss_ce: 0.018607
 67%|██████████████████▏        | 269/400 [2:12:30<1:00:49, 27.86s/it]2021-12-14 03:17:34,940 iteration 4574 : loss : 0.041300, loss_ce: 0.012272
2021-12-14 03:17:36,533 iteration 4575 : loss : 0.059504, loss_ce: 0.013852
2021-12-14 03:17:38,035 iteration 4576 : loss : 0.050965, loss_ce: 0.017668
2021-12-14 03:17:39,554 iteration 4577 : loss : 0.045646, loss_ce: 0.018557
2021-12-14 03:17:41,121 iteration 4578 : loss : 0.045198, loss_ce: 0.014758
2021-12-14 03:17:42,651 iteration 4579 : loss : 0.039857, loss_ce: 0.013654
2021-12-14 03:17:44,197 iteration 4580 : loss : 0.049185, loss_ce: 0.016619
2021-12-14 03:17:45,765 iteration 4581 : loss : 0.070247, loss_ce: 0.025569
2021-12-14 03:17:47,331 iteration 4582 : loss : 0.046935, loss_ce: 0.014916
2021-12-14 03:17:48,887 iteration 4583 : loss : 0.052524, loss_ce: 0.016673
2021-12-14 03:17:50,440 iteration 4584 : loss : 0.047871, loss_ce: 0.014853
2021-12-14 03:17:52,030 iteration 4585 : loss : 0.072054, loss_ce: 0.023246
2021-12-14 03:17:53,548 iteration 4586 : loss : 0.046879, loss_ce: 0.017898
2021-12-14 03:17:55,085 iteration 4587 : loss : 0.048967, loss_ce: 0.014317
2021-12-14 03:17:56,624 iteration 4588 : loss : 0.058085, loss_ce: 0.016542
2021-12-14 03:17:58,207 iteration 4589 : loss : 0.060530, loss_ce: 0.017172
2021-12-14 03:17:58,208 Training Data Eval:
2021-12-14 03:18:06,390   Average segmentation loss on training set: 0.0379
2021-12-14 03:18:06,391 Validation Data Eval:
2021-12-14 03:18:09,191   Average segmentation loss on validation set: 0.0869
2021-12-14 03:18:15,497 Found new lowest validation loss at iteration 4589! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/TU_3seeds/REVISED_SGD_best_val_loss_seed1234.pth
2021-12-14 03:18:16,961 iteration 4590 : loss : 0.049482, loss_ce: 0.018162
 68%|██████████████████▏        | 270/400 [2:13:13<1:10:35, 32.58s/it]2021-12-14 03:18:18,470 iteration 4591 : loss : 0.059024, loss_ce: 0.012138
2021-12-14 03:18:20,068 iteration 4592 : loss : 0.051237, loss_ce: 0.014866
2021-12-14 03:18:21,668 iteration 4593 : loss : 0.051804, loss_ce: 0.021278
2021-12-14 03:18:23,310 iteration 4594 : loss : 0.076678, loss_ce: 0.019194
2021-12-14 03:18:24,882 iteration 4595 : loss : 0.051152, loss_ce: 0.015270
2021-12-14 03:18:26,434 iteration 4596 : loss : 0.045104, loss_ce: 0.011714
2021-12-14 03:18:28,026 iteration 4597 : loss : 0.045173, loss_ce: 0.016694
2021-12-14 03:18:29,662 iteration 4598 : loss : 0.061282, loss_ce: 0.021434
2021-12-14 03:18:31,277 iteration 4599 : loss : 0.056346, loss_ce: 0.021892
2021-12-14 03:18:32,838 iteration 4600 : loss : 0.043266, loss_ce: 0.010553
2021-12-14 03:18:34,435 iteration 4601 : loss : 0.056112, loss_ce: 0.022251
2021-12-14 03:18:36,111 iteration 4602 : loss : 0.058166, loss_ce: 0.014315
2021-12-14 03:18:37,710 iteration 4603 : loss : 0.054205, loss_ce: 0.017696
2021-12-14 03:18:39,333 iteration 4604 : loss : 0.052990, loss_ce: 0.019591
2021-12-14 03:18:40,971 iteration 4605 : loss : 0.102598, loss_ce: 0.022275
2021-12-14 03:18:42,597 iteration 4606 : loss : 0.050396, loss_ce: 0.017297
2021-12-14 03:18:44,224 iteration 4607 : loss : 0.056778, loss_ce: 0.025586
 68%|██████████████████▎        | 271/400 [2:13:41<1:06:37, 30.99s/it]2021-12-14 03:18:45,816 iteration 4608 : loss : 0.041713, loss_ce: 0.013003
2021-12-14 03:18:47,400 iteration 4609 : loss : 0.057818, loss_ce: 0.019901
2021-12-14 03:18:48,929 iteration 4610 : loss : 0.051902, loss_ce: 0.014002
2021-12-14 03:18:50,452 iteration 4611 : loss : 0.056233, loss_ce: 0.021060
2021-12-14 03:18:51,952 iteration 4612 : loss : 0.051206, loss_ce: 0.014912
2021-12-14 03:18:53,528 iteration 4613 : loss : 0.046706, loss_ce: 0.014243
2021-12-14 03:18:55,106 iteration 4614 : loss : 0.050056, loss_ce: 0.017106
2021-12-14 03:18:56,725 iteration 4615 : loss : 0.049775, loss_ce: 0.013980
2021-12-14 03:18:58,416 iteration 4616 : loss : 0.050383, loss_ce: 0.018879
2021-12-14 03:19:00,016 iteration 4617 : loss : 0.049253, loss_ce: 0.013494
2021-12-14 03:19:01,548 iteration 4618 : loss : 0.044540, loss_ce: 0.012029
2021-12-14 03:19:03,095 iteration 4619 : loss : 0.038189, loss_ce: 0.013676
2021-12-14 03:19:04,729 iteration 4620 : loss : 0.058169, loss_ce: 0.015239
2021-12-14 03:19:06,298 iteration 4621 : loss : 0.053258, loss_ce: 0.023187
2021-12-14 03:19:07,880 iteration 4622 : loss : 0.068306, loss_ce: 0.024076
2021-12-14 03:19:09,449 iteration 4623 : loss : 0.048989, loss_ce: 0.013769
2021-12-14 03:19:11,037 iteration 4624 : loss : 0.052103, loss_ce: 0.020677
 68%|██████████████████▎        | 272/400 [2:14:07<1:03:25, 29.73s/it]2021-12-14 03:19:12,711 iteration 4625 : loss : 0.050312, loss_ce: 0.016823
2021-12-14 03:19:14,351 iteration 4626 : loss : 0.050091, loss_ce: 0.019010
2021-12-14 03:19:16,031 iteration 4627 : loss : 0.053322, loss_ce: 0.018344
2021-12-14 03:19:17,594 iteration 4628 : loss : 0.058962, loss_ce: 0.016522
2021-12-14 03:19:19,109 iteration 4629 : loss : 0.045703, loss_ce: 0.013588
2021-12-14 03:19:20,678 iteration 4630 : loss : 0.041956, loss_ce: 0.013068
2021-12-14 03:19:22,271 iteration 4631 : loss : 0.052615, loss_ce: 0.016479
2021-12-14 03:19:23,855 iteration 4632 : loss : 0.058318, loss_ce: 0.016434
2021-12-14 03:19:25,417 iteration 4633 : loss : 0.044555, loss_ce: 0.012977
2021-12-14 03:19:26,963 iteration 4634 : loss : 0.041595, loss_ce: 0.014388
2021-12-14 03:19:28,465 iteration 4635 : loss : 0.040848, loss_ce: 0.012779
2021-12-14 03:19:30,126 iteration 4636 : loss : 0.052665, loss_ce: 0.018751
2021-12-14 03:19:31,681 iteration 4637 : loss : 0.063281, loss_ce: 0.018541
2021-12-14 03:19:33,372 iteration 4638 : loss : 0.058424, loss_ce: 0.021514
2021-12-14 03:19:34,993 iteration 4639 : loss : 0.061267, loss_ce: 0.017870
2021-12-14 03:19:36,692 iteration 4640 : loss : 0.066988, loss_ce: 0.020653
2021-12-14 03:19:38,322 iteration 4641 : loss : 0.051806, loss_ce: 0.016719
 68%|██████████████████▍        | 273/400 [2:14:35<1:01:22, 29.00s/it]2021-12-14 03:19:39,955 iteration 4642 : loss : 0.058277, loss_ce: 0.012689
2021-12-14 03:19:41,541 iteration 4643 : loss : 0.043733, loss_ce: 0.014201
2021-12-14 03:19:43,179 iteration 4644 : loss : 0.047814, loss_ce: 0.013867
2021-12-14 03:19:44,822 iteration 4645 : loss : 0.060603, loss_ce: 0.025251
2021-12-14 03:19:46,433 iteration 4646 : loss : 0.055078, loss_ce: 0.013199
2021-12-14 03:19:47,945 iteration 4647 : loss : 0.052201, loss_ce: 0.015866
2021-12-14 03:19:49,492 iteration 4648 : loss : 0.073789, loss_ce: 0.023060
2021-12-14 03:19:51,081 iteration 4649 : loss : 0.051789, loss_ce: 0.018981
2021-12-14 03:19:52,711 iteration 4650 : loss : 0.075563, loss_ce: 0.020332
2021-12-14 03:19:54,239 iteration 4651 : loss : 0.043267, loss_ce: 0.016064
2021-12-14 03:19:55,900 iteration 4652 : loss : 0.056814, loss_ce: 0.017092
2021-12-14 03:19:57,463 iteration 4653 : loss : 0.053979, loss_ce: 0.019970
2021-12-14 03:19:59,030 iteration 4654 : loss : 0.044623, loss_ce: 0.012154
2021-12-14 03:20:00,710 iteration 4655 : loss : 0.058251, loss_ce: 0.021116
2021-12-14 03:20:02,383 iteration 4656 : loss : 0.051990, loss_ce: 0.018154
2021-12-14 03:20:04,007 iteration 4657 : loss : 0.057759, loss_ce: 0.024195
2021-12-14 03:20:05,631 iteration 4658 : loss : 0.070729, loss_ce: 0.026894
 68%|███████████████████▊         | 274/400 [2:15:02<59:49, 28.49s/it]2021-12-14 03:20:07,311 iteration 4659 : loss : 0.051656, loss_ce: 0.019285
2021-12-14 03:20:08,953 iteration 4660 : loss : 0.065023, loss_ce: 0.025346
2021-12-14 03:20:10,571 iteration 4661 : loss : 0.051900, loss_ce: 0.016516
2021-12-14 03:20:12,112 iteration 4662 : loss : 0.044862, loss_ce: 0.013172
2021-12-14 03:20:13,721 iteration 4663 : loss : 0.053320, loss_ce: 0.018018
2021-12-14 03:20:15,279 iteration 4664 : loss : 0.041626, loss_ce: 0.012487
2021-12-14 03:20:16,846 iteration 4665 : loss : 0.050417, loss_ce: 0.016165
2021-12-14 03:20:18,326 iteration 4666 : loss : 0.041647, loss_ce: 0.011459
2021-12-14 03:20:19,865 iteration 4667 : loss : 0.047484, loss_ce: 0.017366
2021-12-14 03:20:21,564 iteration 4668 : loss : 0.067656, loss_ce: 0.027300
2021-12-14 03:20:23,100 iteration 4669 : loss : 0.043920, loss_ce: 0.015301
2021-12-14 03:20:24,645 iteration 4670 : loss : 0.052673, loss_ce: 0.019288
2021-12-14 03:20:26,171 iteration 4671 : loss : 0.056733, loss_ce: 0.015273
2021-12-14 03:20:27,841 iteration 4672 : loss : 0.061396, loss_ce: 0.019674
2021-12-14 03:20:29,479 iteration 4673 : loss : 0.047863, loss_ce: 0.016469
2021-12-14 03:20:30,995 iteration 4674 : loss : 0.041916, loss_ce: 0.011018
2021-12-14 03:20:30,995 Training Data Eval:
2021-12-14 03:20:39,178   Average segmentation loss on training set: 0.0380
2021-12-14 03:20:39,178 Validation Data Eval:
2021-12-14 03:20:41,982   Average segmentation loss on validation set: 0.0890
2021-12-14 03:20:43,620 iteration 4675 : loss : 0.044908, loss_ce: 0.014889
 69%|██████████████████▌        | 275/400 [2:15:40<1:05:17, 31.34s/it]2021-12-14 03:20:45,355 iteration 4676 : loss : 0.051516, loss_ce: 0.013576
2021-12-14 03:20:46,917 iteration 4677 : loss : 0.057601, loss_ce: 0.017611
2021-12-14 03:20:48,518 iteration 4678 : loss : 0.057879, loss_ce: 0.014576
2021-12-14 03:20:50,170 iteration 4679 : loss : 0.069152, loss_ce: 0.018001
2021-12-14 03:20:51,748 iteration 4680 : loss : 0.045748, loss_ce: 0.015434
2021-12-14 03:20:53,314 iteration 4681 : loss : 0.060439, loss_ce: 0.015928
2021-12-14 03:20:54,864 iteration 4682 : loss : 0.051930, loss_ce: 0.016866
2021-12-14 03:20:56,345 iteration 4683 : loss : 0.048804, loss_ce: 0.011776
2021-12-14 03:20:57,970 iteration 4684 : loss : 0.050518, loss_ce: 0.020541
2021-12-14 03:20:59,581 iteration 4685 : loss : 0.057553, loss_ce: 0.018090
2021-12-14 03:21:01,163 iteration 4686 : loss : 0.050349, loss_ce: 0.012919
2021-12-14 03:21:02,719 iteration 4687 : loss : 0.048979, loss_ce: 0.018448
2021-12-14 03:21:04,224 iteration 4688 : loss : 0.039942, loss_ce: 0.013195
2021-12-14 03:21:05,731 iteration 4689 : loss : 0.041637, loss_ce: 0.015996
2021-12-14 03:21:07,263 iteration 4690 : loss : 0.051484, loss_ce: 0.017965
2021-12-14 03:21:08,879 iteration 4691 : loss : 0.070942, loss_ce: 0.028957
2021-12-14 03:21:10,438 iteration 4692 : loss : 0.043097, loss_ce: 0.011390
 69%|██████████████████▋        | 276/400 [2:16:07<1:01:57, 29.98s/it]2021-12-14 03:21:12,142 iteration 4693 : loss : 0.055534, loss_ce: 0.017541
2021-12-14 03:21:13,752 iteration 4694 : loss : 0.056478, loss_ce: 0.016374
2021-12-14 03:21:15,198 iteration 4695 : loss : 0.039306, loss_ce: 0.010490
2021-12-14 03:21:16,849 iteration 4696 : loss : 0.056165, loss_ce: 0.018037
2021-12-14 03:21:18,397 iteration 4697 : loss : 0.046159, loss_ce: 0.014886
2021-12-14 03:21:19,980 iteration 4698 : loss : 0.051916, loss_ce: 0.019994
2021-12-14 03:21:21,615 iteration 4699 : loss : 0.045856, loss_ce: 0.017140
2021-12-14 03:21:23,146 iteration 4700 : loss : 0.051860, loss_ce: 0.020199
2021-12-14 03:21:24,819 iteration 4701 : loss : 0.058768, loss_ce: 0.022550
2021-12-14 03:21:26,376 iteration 4702 : loss : 0.063829, loss_ce: 0.024995
2021-12-14 03:21:27,914 iteration 4703 : loss : 0.044073, loss_ce: 0.011347
2021-12-14 03:21:29,486 iteration 4704 : loss : 0.048552, loss_ce: 0.015046
2021-12-14 03:21:30,935 iteration 4705 : loss : 0.040629, loss_ce: 0.014359
2021-12-14 03:21:32,503 iteration 4706 : loss : 0.049203, loss_ce: 0.012293
2021-12-14 03:21:34,127 iteration 4707 : loss : 0.053128, loss_ce: 0.017686
2021-12-14 03:21:35,765 iteration 4708 : loss : 0.051998, loss_ce: 0.014015
2021-12-14 03:21:37,382 iteration 4709 : loss : 0.059594, loss_ce: 0.017816
 69%|████████████████████         | 277/400 [2:16:34<59:35, 29.07s/it]2021-12-14 03:21:39,053 iteration 4710 : loss : 0.057245, loss_ce: 0.013230
2021-12-14 03:21:40,776 iteration 4711 : loss : 0.049027, loss_ce: 0.015714
2021-12-14 03:21:42,338 iteration 4712 : loss : 0.050634, loss_ce: 0.017386
2021-12-14 03:21:43,908 iteration 4713 : loss : 0.041970, loss_ce: 0.013805
2021-12-14 03:21:45,496 iteration 4714 : loss : 0.052130, loss_ce: 0.015711
2021-12-14 03:21:47,137 iteration 4715 : loss : 0.053012, loss_ce: 0.016497
2021-12-14 03:21:48,746 iteration 4716 : loss : 0.051014, loss_ce: 0.013879
2021-12-14 03:21:50,321 iteration 4717 : loss : 0.052167, loss_ce: 0.015803
2021-12-14 03:21:51,841 iteration 4718 : loss : 0.041908, loss_ce: 0.014409
2021-12-14 03:21:53,362 iteration 4719 : loss : 0.051088, loss_ce: 0.019532
2021-12-14 03:21:54,899 iteration 4720 : loss : 0.042997, loss_ce: 0.014095
2021-12-14 03:21:56,459 iteration 4721 : loss : 0.044986, loss_ce: 0.015976
2021-12-14 03:21:58,095 iteration 4722 : loss : 0.065973, loss_ce: 0.021872
2021-12-14 03:21:59,676 iteration 4723 : loss : 0.041101, loss_ce: 0.012620
2021-12-14 03:22:01,195 iteration 4724 : loss : 0.043158, loss_ce: 0.012957
2021-12-14 03:22:02,709 iteration 4725 : loss : 0.048343, loss_ce: 0.018471
2021-12-14 03:22:04,291 iteration 4726 : loss : 0.051642, loss_ce: 0.018385
 70%|████████████████████▏        | 278/400 [2:17:01<57:47, 28.42s/it]2021-12-14 03:22:05,988 iteration 4727 : loss : 0.052932, loss_ce: 0.015195
2021-12-14 03:22:07,519 iteration 4728 : loss : 0.044879, loss_ce: 0.014867
2021-12-14 03:22:09,056 iteration 4729 : loss : 0.046713, loss_ce: 0.013868
2021-12-14 03:22:10,593 iteration 4730 : loss : 0.055774, loss_ce: 0.015715
2021-12-14 03:22:12,227 iteration 4731 : loss : 0.051577, loss_ce: 0.015531
2021-12-14 03:22:13,815 iteration 4732 : loss : 0.050765, loss_ce: 0.014367
2021-12-14 03:22:15,396 iteration 4733 : loss : 0.043060, loss_ce: 0.013950
2021-12-14 03:22:16,950 iteration 4734 : loss : 0.049481, loss_ce: 0.016058
2021-12-14 03:22:18,613 iteration 4735 : loss : 0.053764, loss_ce: 0.016262
2021-12-14 03:22:20,123 iteration 4736 : loss : 0.056372, loss_ce: 0.021767
2021-12-14 03:22:21,766 iteration 4737 : loss : 0.052451, loss_ce: 0.016975
2021-12-14 03:22:23,337 iteration 4738 : loss : 0.048712, loss_ce: 0.015142
2021-12-14 03:22:24,906 iteration 4739 : loss : 0.047575, loss_ce: 0.015654
2021-12-14 03:22:26,528 iteration 4740 : loss : 0.049223, loss_ce: 0.019111
2021-12-14 03:22:28,087 iteration 4741 : loss : 0.044088, loss_ce: 0.012639
2021-12-14 03:22:29,658 iteration 4742 : loss : 0.058969, loss_ce: 0.025361
2021-12-14 03:22:31,321 iteration 4743 : loss : 0.062572, loss_ce: 0.018713
 70%|████████████████████▏        | 279/400 [2:17:28<56:28, 28.01s/it]2021-12-14 03:22:33,011 iteration 4744 : loss : 0.049408, loss_ce: 0.012650
2021-12-14 03:22:34,591 iteration 4745 : loss : 0.059939, loss_ce: 0.016520
2021-12-14 03:22:36,126 iteration 4746 : loss : 0.051732, loss_ce: 0.020434
2021-12-14 03:22:37,677 iteration 4747 : loss : 0.054985, loss_ce: 0.017819
2021-12-14 03:22:39,273 iteration 4748 : loss : 0.053803, loss_ce: 0.015555
2021-12-14 03:22:40,863 iteration 4749 : loss : 0.075705, loss_ce: 0.023126
2021-12-14 03:22:42,492 iteration 4750 : loss : 0.053872, loss_ce: 0.018938
2021-12-14 03:22:44,045 iteration 4751 : loss : 0.053627, loss_ce: 0.018558
2021-12-14 03:22:45,649 iteration 4752 : loss : 0.044084, loss_ce: 0.013843
2021-12-14 03:22:47,282 iteration 4753 : loss : 0.049730, loss_ce: 0.015080
2021-12-14 03:22:48,889 iteration 4754 : loss : 0.047699, loss_ce: 0.014356
2021-12-14 03:22:50,581 iteration 4755 : loss : 0.053791, loss_ce: 0.013793
2021-12-14 03:22:52,134 iteration 4756 : loss : 0.048664, loss_ce: 0.021072
2021-12-14 03:22:53,701 iteration 4757 : loss : 0.053497, loss_ce: 0.020299
2021-12-14 03:22:55,243 iteration 4758 : loss : 0.046827, loss_ce: 0.013250
2021-12-14 03:22:56,818 iteration 4759 : loss : 0.042031, loss_ce: 0.012557
2021-12-14 03:22:56,818 Training Data Eval:
2021-12-14 03:23:04,999   Average segmentation loss on training set: 0.0367
2021-12-14 03:23:05,000 Validation Data Eval:
2021-12-14 03:23:07,788   Average segmentation loss on validation set: 0.0906
2021-12-14 03:23:09,331 iteration 4760 : loss : 0.048958, loss_ce: 0.019025
 70%|██████████████████▉        | 280/400 [2:18:06<1:02:00, 31.01s/it]2021-12-14 03:23:10,950 iteration 4761 : loss : 0.052443, loss_ce: 0.012500
2021-12-14 03:23:12,556 iteration 4762 : loss : 0.062225, loss_ce: 0.016909
2021-12-14 03:23:14,079 iteration 4763 : loss : 0.042082, loss_ce: 0.014892
2021-12-14 03:23:15,685 iteration 4764 : loss : 0.047717, loss_ce: 0.014732
2021-12-14 03:23:17,242 iteration 4765 : loss : 0.051139, loss_ce: 0.020470
2021-12-14 03:23:18,888 iteration 4766 : loss : 0.056621, loss_ce: 0.017498
2021-12-14 03:23:20,495 iteration 4767 : loss : 0.047736, loss_ce: 0.015835
2021-12-14 03:23:22,034 iteration 4768 : loss : 0.055978, loss_ce: 0.016129
2021-12-14 03:23:23,661 iteration 4769 : loss : 0.053454, loss_ce: 0.017997
2021-12-14 03:23:25,285 iteration 4770 : loss : 0.051389, loss_ce: 0.017281
2021-12-14 03:23:26,801 iteration 4771 : loss : 0.047743, loss_ce: 0.013346
2021-12-14 03:23:28,423 iteration 4772 : loss : 0.050894, loss_ce: 0.018963
2021-12-14 03:23:30,029 iteration 4773 : loss : 0.059594, loss_ce: 0.019249
2021-12-14 03:23:31,627 iteration 4774 : loss : 0.048548, loss_ce: 0.015034
2021-12-14 03:23:33,172 iteration 4775 : loss : 0.051136, loss_ce: 0.014708
2021-12-14 03:23:34,738 iteration 4776 : loss : 0.048337, loss_ce: 0.022377
2021-12-14 03:23:36,456 iteration 4777 : loss : 0.048449, loss_ce: 0.016605
 70%|████████████████████▎        | 281/400 [2:18:33<59:11, 29.84s/it]2021-12-14 03:23:38,032 iteration 4778 : loss : 0.040656, loss_ce: 0.010901
2021-12-14 03:23:39,598 iteration 4779 : loss : 0.056822, loss_ce: 0.018074
2021-12-14 03:23:41,107 iteration 4780 : loss : 0.039854, loss_ce: 0.011251
2021-12-14 03:23:42,660 iteration 4781 : loss : 0.058775, loss_ce: 0.012446
2021-12-14 03:23:44,292 iteration 4782 : loss : 0.061541, loss_ce: 0.023166
2021-12-14 03:23:45,875 iteration 4783 : loss : 0.039546, loss_ce: 0.015155
2021-12-14 03:23:47,394 iteration 4784 : loss : 0.041407, loss_ce: 0.014950
2021-12-14 03:23:49,044 iteration 4785 : loss : 0.049360, loss_ce: 0.014907
2021-12-14 03:23:50,645 iteration 4786 : loss : 0.048750, loss_ce: 0.014858
2021-12-14 03:23:52,246 iteration 4787 : loss : 0.055524, loss_ce: 0.015591
2021-12-14 03:23:53,856 iteration 4788 : loss : 0.049211, loss_ce: 0.014318
2021-12-14 03:23:55,373 iteration 4789 : loss : 0.040487, loss_ce: 0.016393
2021-12-14 03:23:57,037 iteration 4790 : loss : 0.060379, loss_ce: 0.018881
2021-12-14 03:23:58,594 iteration 4791 : loss : 0.050668, loss_ce: 0.019795
2021-12-14 03:24:00,223 iteration 4792 : loss : 0.059952, loss_ce: 0.016169
2021-12-14 03:24:01,763 iteration 4793 : loss : 0.046217, loss_ce: 0.014278
2021-12-14 03:24:03,254 iteration 4794 : loss : 0.047943, loss_ce: 0.012895
 70%|████████████████████▍        | 282/400 [2:19:00<56:53, 28.93s/it]2021-12-14 03:24:04,915 iteration 4795 : loss : 0.054570, loss_ce: 0.016022
2021-12-14 03:24:06,513 iteration 4796 : loss : 0.043096, loss_ce: 0.012291
2021-12-14 03:24:08,122 iteration 4797 : loss : 0.049590, loss_ce: 0.014927
2021-12-14 03:24:09,775 iteration 4798 : loss : 0.057743, loss_ce: 0.016285
2021-12-14 03:24:11,356 iteration 4799 : loss : 0.048409, loss_ce: 0.014719
2021-12-14 03:24:12,940 iteration 4800 : loss : 0.054736, loss_ce: 0.013651
2021-12-14 03:24:14,597 iteration 4801 : loss : 0.052357, loss_ce: 0.019495
2021-12-14 03:24:16,109 iteration 4802 : loss : 0.042461, loss_ce: 0.014947
2021-12-14 03:24:17,660 iteration 4803 : loss : 0.044893, loss_ce: 0.017010
2021-12-14 03:24:19,305 iteration 4804 : loss : 0.072287, loss_ce: 0.017160
2021-12-14 03:24:20,959 iteration 4805 : loss : 0.056578, loss_ce: 0.018352
2021-12-14 03:24:22,603 iteration 4806 : loss : 0.047320, loss_ce: 0.016281
2021-12-14 03:24:24,119 iteration 4807 : loss : 0.054127, loss_ce: 0.022115
2021-12-14 03:24:25,621 iteration 4808 : loss : 0.045005, loss_ce: 0.015754
2021-12-14 03:24:27,209 iteration 4809 : loss : 0.055581, loss_ce: 0.023219
2021-12-14 03:24:28,780 iteration 4810 : loss : 0.056641, loss_ce: 0.014482
2021-12-14 03:24:30,370 iteration 4811 : loss : 0.041964, loss_ce: 0.012662
 71%|████████████████████▌        | 283/400 [2:19:27<55:20, 28.38s/it]2021-12-14 03:24:31,947 iteration 4812 : loss : 0.052241, loss_ce: 0.018208
2021-12-14 03:24:33,539 iteration 4813 : loss : 0.047652, loss_ce: 0.012005
2021-12-14 03:24:35,160 iteration 4814 : loss : 0.056374, loss_ce: 0.015870
2021-12-14 03:24:36,676 iteration 4815 : loss : 0.047732, loss_ce: 0.016515
2021-12-14 03:24:38,352 iteration 4816 : loss : 0.050468, loss_ce: 0.017851
2021-12-14 03:24:39,917 iteration 4817 : loss : 0.052227, loss_ce: 0.016619
2021-12-14 03:24:41,474 iteration 4818 : loss : 0.048137, loss_ce: 0.015317
2021-12-14 03:24:42,964 iteration 4819 : loss : 0.048176, loss_ce: 0.015905
2021-12-14 03:24:44,503 iteration 4820 : loss : 0.061088, loss_ce: 0.021365
2021-12-14 03:24:46,162 iteration 4821 : loss : 0.055962, loss_ce: 0.022055
2021-12-14 03:24:47,815 iteration 4822 : loss : 0.057582, loss_ce: 0.018725
2021-12-14 03:24:49,387 iteration 4823 : loss : 0.048209, loss_ce: 0.017546
2021-12-14 03:24:50,990 iteration 4824 : loss : 0.047663, loss_ce: 0.016077
2021-12-14 03:24:52,542 iteration 4825 : loss : 0.048900, loss_ce: 0.016636
2021-12-14 03:24:54,093 iteration 4826 : loss : 0.042629, loss_ce: 0.012248
2021-12-14 03:24:55,652 iteration 4827 : loss : 0.042743, loss_ce: 0.014473
2021-12-14 03:24:57,191 iteration 4828 : loss : 0.051756, loss_ce: 0.018164
 71%|████████████████████▌        | 284/400 [2:19:54<53:58, 27.92s/it]2021-12-14 03:24:58,766 iteration 4829 : loss : 0.052615, loss_ce: 0.015212
2021-12-14 03:25:00,375 iteration 4830 : loss : 0.044761, loss_ce: 0.015509
2021-12-14 03:25:01,971 iteration 4831 : loss : 0.049217, loss_ce: 0.018239
2021-12-14 03:25:03,535 iteration 4832 : loss : 0.063621, loss_ce: 0.017463
2021-12-14 03:25:05,151 iteration 4833 : loss : 0.051301, loss_ce: 0.017771
2021-12-14 03:25:06,673 iteration 4834 : loss : 0.043165, loss_ce: 0.013694
2021-12-14 03:25:08,357 iteration 4835 : loss : 0.047373, loss_ce: 0.018030
2021-12-14 03:25:09,946 iteration 4836 : loss : 0.055942, loss_ce: 0.017391
2021-12-14 03:25:11,577 iteration 4837 : loss : 0.057199, loss_ce: 0.014026
2021-12-14 03:25:13,134 iteration 4838 : loss : 0.042025, loss_ce: 0.012250
2021-12-14 03:25:14,736 iteration 4839 : loss : 0.051494, loss_ce: 0.018368
2021-12-14 03:25:16,314 iteration 4840 : loss : 0.048193, loss_ce: 0.019750
2021-12-14 03:25:17,820 iteration 4841 : loss : 0.041234, loss_ce: 0.011796
2021-12-14 03:25:19,401 iteration 4842 : loss : 0.044232, loss_ce: 0.014207
2021-12-14 03:25:21,063 iteration 4843 : loss : 0.055365, loss_ce: 0.015482
2021-12-14 03:25:22,636 iteration 4844 : loss : 0.050936, loss_ce: 0.017081
2021-12-14 03:25:22,636 Training Data Eval:
2021-12-14 03:25:30,810   Average segmentation loss on training set: 0.0358
2021-12-14 03:25:30,810 Validation Data Eval:
2021-12-14 03:25:33,608   Average segmentation loss on validation set: 0.0944
2021-12-14 03:25:35,222 iteration 4845 : loss : 0.054393, loss_ce: 0.020671
 71%|████████████████████▋        | 285/400 [2:20:32<59:19, 30.95s/it]2021-12-14 03:25:36,826 iteration 4846 : loss : 0.045193, loss_ce: 0.014803
2021-12-14 03:25:38,368 iteration 4847 : loss : 0.045646, loss_ce: 0.014636
2021-12-14 03:25:39,988 iteration 4848 : loss : 0.054724, loss_ce: 0.022782
2021-12-14 03:25:41,594 iteration 4849 : loss : 0.045783, loss_ce: 0.009917
2021-12-14 03:25:43,140 iteration 4850 : loss : 0.047359, loss_ce: 0.013371
2021-12-14 03:25:44,826 iteration 4851 : loss : 0.049192, loss_ce: 0.014720
2021-12-14 03:25:46,392 iteration 4852 : loss : 0.043893, loss_ce: 0.012767
2021-12-14 03:25:47,978 iteration 4853 : loss : 0.049298, loss_ce: 0.019388
2021-12-14 03:25:49,565 iteration 4854 : loss : 0.056764, loss_ce: 0.017594
2021-12-14 03:25:51,113 iteration 4855 : loss : 0.058701, loss_ce: 0.015660
2021-12-14 03:25:52,783 iteration 4856 : loss : 0.053474, loss_ce: 0.017233
2021-12-14 03:25:54,330 iteration 4857 : loss : 0.038124, loss_ce: 0.011285
2021-12-14 03:25:55,984 iteration 4858 : loss : 0.051477, loss_ce: 0.017823
2021-12-14 03:25:57,503 iteration 4859 : loss : 0.038379, loss_ce: 0.013244
2021-12-14 03:25:59,119 iteration 4860 : loss : 0.077864, loss_ce: 0.032197
2021-12-14 03:26:00,666 iteration 4861 : loss : 0.052788, loss_ce: 0.016447
2021-12-14 03:26:02,283 iteration 4862 : loss : 0.048029, loss_ce: 0.018512
 72%|████████████████████▋        | 286/400 [2:20:59<56:34, 29.78s/it]2021-12-14 03:26:03,983 iteration 4863 : loss : 0.046090, loss_ce: 0.011842
2021-12-14 03:26:05,559 iteration 4864 : loss : 0.044879, loss_ce: 0.014093
2021-12-14 03:26:07,112 iteration 4865 : loss : 0.046147, loss_ce: 0.017417
2021-12-14 03:26:08,755 iteration 4866 : loss : 0.045421, loss_ce: 0.013028
2021-12-14 03:26:10,343 iteration 4867 : loss : 0.046258, loss_ce: 0.013201
2021-12-14 03:26:11,827 iteration 4868 : loss : 0.045072, loss_ce: 0.016232
2021-12-14 03:26:13,500 iteration 4869 : loss : 0.060042, loss_ce: 0.025902
2021-12-14 03:26:15,072 iteration 4870 : loss : 0.046782, loss_ce: 0.013859
2021-12-14 03:26:16,750 iteration 4871 : loss : 0.058355, loss_ce: 0.018055
2021-12-14 03:26:18,263 iteration 4872 : loss : 0.046198, loss_ce: 0.014239
2021-12-14 03:26:19,936 iteration 4873 : loss : 0.043789, loss_ce: 0.013743
2021-12-14 03:26:21,546 iteration 4874 : loss : 0.068101, loss_ce: 0.018635
2021-12-14 03:26:23,110 iteration 4875 : loss : 0.051431, loss_ce: 0.016793
2021-12-14 03:26:24,601 iteration 4876 : loss : 0.047063, loss_ce: 0.013425
2021-12-14 03:26:26,229 iteration 4877 : loss : 0.052947, loss_ce: 0.022222
2021-12-14 03:26:27,880 iteration 4878 : loss : 0.067221, loss_ce: 0.021269
2021-12-14 03:26:29,454 iteration 4879 : loss : 0.041275, loss_ce: 0.013665
 72%|████████████████████▊        | 287/400 [2:21:26<54:36, 29.00s/it]2021-12-14 03:26:31,049 iteration 4880 : loss : 0.045057, loss_ce: 0.015576
2021-12-14 03:26:32,573 iteration 4881 : loss : 0.047627, loss_ce: 0.017879
2021-12-14 03:26:34,061 iteration 4882 : loss : 0.044821, loss_ce: 0.015905
2021-12-14 03:26:35,658 iteration 4883 : loss : 0.043164, loss_ce: 0.016070
2021-12-14 03:26:37,273 iteration 4884 : loss : 0.058275, loss_ce: 0.014514
2021-12-14 03:26:38,743 iteration 4885 : loss : 0.044130, loss_ce: 0.015054
2021-12-14 03:26:40,308 iteration 4886 : loss : 0.048976, loss_ce: 0.011324
2021-12-14 03:26:41,817 iteration 4887 : loss : 0.042044, loss_ce: 0.011765
2021-12-14 03:26:43,411 iteration 4888 : loss : 0.074994, loss_ce: 0.018405
2021-12-14 03:26:44,988 iteration 4889 : loss : 0.066040, loss_ce: 0.027109
2021-12-14 03:26:46,516 iteration 4890 : loss : 0.049540, loss_ce: 0.020939
2021-12-14 03:26:47,980 iteration 4891 : loss : 0.039845, loss_ce: 0.012597
2021-12-14 03:26:49,590 iteration 4892 : loss : 0.043622, loss_ce: 0.014256
2021-12-14 03:26:51,169 iteration 4893 : loss : 0.047863, loss_ce: 0.018062
2021-12-14 03:26:52,724 iteration 4894 : loss : 0.044699, loss_ce: 0.017283
2021-12-14 03:26:54,269 iteration 4895 : loss : 0.049073, loss_ce: 0.010974
2021-12-14 03:26:55,802 iteration 4896 : loss : 0.065321, loss_ce: 0.019132
 72%|████████████████████▉        | 288/400 [2:21:52<52:39, 28.21s/it]2021-12-14 03:26:57,402 iteration 4897 : loss : 0.049634, loss_ce: 0.015713
2021-12-14 03:26:59,031 iteration 4898 : loss : 0.056720, loss_ce: 0.021191
2021-12-14 03:27:00,606 iteration 4899 : loss : 0.050526, loss_ce: 0.013008
2021-12-14 03:27:02,140 iteration 4900 : loss : 0.050474, loss_ce: 0.016690
2021-12-14 03:27:03,689 iteration 4901 : loss : 0.056208, loss_ce: 0.013637
2021-12-14 03:27:05,235 iteration 4902 : loss : 0.040933, loss_ce: 0.012636
2021-12-14 03:27:06,824 iteration 4903 : loss : 0.046026, loss_ce: 0.017359
2021-12-14 03:27:08,296 iteration 4904 : loss : 0.048921, loss_ce: 0.010881
2021-12-14 03:27:09,821 iteration 4905 : loss : 0.048562, loss_ce: 0.012997
2021-12-14 03:27:11,414 iteration 4906 : loss : 0.054931, loss_ce: 0.018830
2021-12-14 03:27:12,945 iteration 4907 : loss : 0.053790, loss_ce: 0.016854
2021-12-14 03:27:14,582 iteration 4908 : loss : 0.055359, loss_ce: 0.019786
2021-12-14 03:27:16,178 iteration 4909 : loss : 0.044132, loss_ce: 0.013100
2021-12-14 03:27:17,704 iteration 4910 : loss : 0.042923, loss_ce: 0.016447
2021-12-14 03:27:19,246 iteration 4911 : loss : 0.038191, loss_ce: 0.012099
2021-12-14 03:27:20,816 iteration 4912 : loss : 0.046147, loss_ce: 0.017475
2021-12-14 03:27:22,377 iteration 4913 : loss : 0.049249, loss_ce: 0.016851
 72%|████████████████████▉        | 289/400 [2:22:19<51:16, 27.71s/it]2021-12-14 03:27:24,034 iteration 4914 : loss : 0.059505, loss_ce: 0.017803
2021-12-14 03:27:25,568 iteration 4915 : loss : 0.052200, loss_ce: 0.017333
2021-12-14 03:27:27,110 iteration 4916 : loss : 0.044295, loss_ce: 0.010184
2021-12-14 03:27:28,678 iteration 4917 : loss : 0.040283, loss_ce: 0.011318
2021-12-14 03:27:30,271 iteration 4918 : loss : 0.045772, loss_ce: 0.013171
2021-12-14 03:27:31,994 iteration 4919 : loss : 0.062675, loss_ce: 0.025161
2021-12-14 03:27:33,554 iteration 4920 : loss : 0.040665, loss_ce: 0.012706
2021-12-14 03:27:35,082 iteration 4921 : loss : 0.041079, loss_ce: 0.016091
2021-12-14 03:27:36,589 iteration 4922 : loss : 0.043489, loss_ce: 0.009865
2021-12-14 03:27:38,207 iteration 4923 : loss : 0.051493, loss_ce: 0.016719
2021-12-14 03:27:39,849 iteration 4924 : loss : 0.063035, loss_ce: 0.028781
2021-12-14 03:27:41,445 iteration 4925 : loss : 0.044449, loss_ce: 0.014245
2021-12-14 03:27:43,075 iteration 4926 : loss : 0.048038, loss_ce: 0.019809
2021-12-14 03:27:44,636 iteration 4927 : loss : 0.044724, loss_ce: 0.012758
2021-12-14 03:27:46,266 iteration 4928 : loss : 0.059610, loss_ce: 0.018708
2021-12-14 03:27:47,927 iteration 4929 : loss : 0.064918, loss_ce: 0.024968
2021-12-14 03:27:47,927 Training Data Eval:
2021-12-14 03:27:56,098   Average segmentation loss on training set: 0.0362
2021-12-14 03:27:56,098 Validation Data Eval:
2021-12-14 03:27:58,895   Average segmentation loss on validation set: 0.0891
2021-12-14 03:28:00,473 iteration 4930 : loss : 0.046109, loss_ce: 0.012172
 72%|█████████████████████        | 290/400 [2:22:57<56:31, 30.83s/it]2021-12-14 03:28:02,093 iteration 4931 : loss : 0.047079, loss_ce: 0.018115
2021-12-14 03:28:03,693 iteration 4932 : loss : 0.053206, loss_ce: 0.022175
2021-12-14 03:28:05,211 iteration 4933 : loss : 0.044451, loss_ce: 0.017589
2021-12-14 03:28:06,848 iteration 4934 : loss : 0.047288, loss_ce: 0.011338
2021-12-14 03:28:08,423 iteration 4935 : loss : 0.042721, loss_ce: 0.012188
2021-12-14 03:28:10,023 iteration 4936 : loss : 0.047408, loss_ce: 0.015783
2021-12-14 03:28:11,610 iteration 4937 : loss : 0.043096, loss_ce: 0.013492
2021-12-14 03:28:13,237 iteration 4938 : loss : 0.082568, loss_ce: 0.025647
2021-12-14 03:28:14,865 iteration 4939 : loss : 0.057321, loss_ce: 0.018586
2021-12-14 03:28:16,429 iteration 4940 : loss : 0.054996, loss_ce: 0.021409
2021-12-14 03:28:18,018 iteration 4941 : loss : 0.049795, loss_ce: 0.019384
2021-12-14 03:28:19,610 iteration 4942 : loss : 0.049324, loss_ce: 0.015024
2021-12-14 03:28:21,285 iteration 4943 : loss : 0.059383, loss_ce: 0.012554
2021-12-14 03:28:22,864 iteration 4944 : loss : 0.052649, loss_ce: 0.015435
2021-12-14 03:28:24,485 iteration 4945 : loss : 0.044124, loss_ce: 0.014235
2021-12-14 03:28:26,123 iteration 4946 : loss : 0.090322, loss_ce: 0.028149
2021-12-14 03:28:27,689 iteration 4947 : loss : 0.050205, loss_ce: 0.015100
 73%|█████████████████████        | 291/400 [2:23:24<54:02, 29.75s/it]2021-12-14 03:28:29,352 iteration 4948 : loss : 0.070125, loss_ce: 0.020774
2021-12-14 03:28:30,909 iteration 4949 : loss : 0.049825, loss_ce: 0.018297
2021-12-14 03:28:32,527 iteration 4950 : loss : 0.053184, loss_ce: 0.018057
2021-12-14 03:28:34,131 iteration 4951 : loss : 0.044774, loss_ce: 0.012409
2021-12-14 03:28:35,731 iteration 4952 : loss : 0.046782, loss_ce: 0.020001
2021-12-14 03:28:37,351 iteration 4953 : loss : 0.045379, loss_ce: 0.015081
2021-12-14 03:28:38,905 iteration 4954 : loss : 0.042003, loss_ce: 0.011970
2021-12-14 03:28:40,418 iteration 4955 : loss : 0.076103, loss_ce: 0.026367
2021-12-14 03:28:41,983 iteration 4956 : loss : 0.044566, loss_ce: 0.012450
2021-12-14 03:28:43,469 iteration 4957 : loss : 0.050238, loss_ce: 0.017824
2021-12-14 03:28:45,057 iteration 4958 : loss : 0.054680, loss_ce: 0.024239
2021-12-14 03:28:46,642 iteration 4959 : loss : 0.057693, loss_ce: 0.018523
2021-12-14 03:28:48,146 iteration 4960 : loss : 0.044117, loss_ce: 0.013688
2021-12-14 03:28:49,731 iteration 4961 : loss : 0.047207, loss_ce: 0.016232
2021-12-14 03:28:51,250 iteration 4962 : loss : 0.068122, loss_ce: 0.013817
2021-12-14 03:28:52,801 iteration 4963 : loss : 0.050203, loss_ce: 0.016733
2021-12-14 03:28:54,423 iteration 4964 : loss : 0.053841, loss_ce: 0.017149
 73%|█████████████████████▏       | 292/400 [2:23:51<51:55, 28.84s/it]2021-12-14 03:28:56,124 iteration 4965 : loss : 0.053984, loss_ce: 0.020065
2021-12-14 03:28:57,761 iteration 4966 : loss : 0.054002, loss_ce: 0.018218
2021-12-14 03:28:59,351 iteration 4967 : loss : 0.057290, loss_ce: 0.021146
2021-12-14 03:29:00,963 iteration 4968 : loss : 0.050746, loss_ce: 0.021170
2021-12-14 03:29:02,662 iteration 4969 : loss : 0.082380, loss_ce: 0.022325
2021-12-14 03:29:04,198 iteration 4970 : loss : 0.043763, loss_ce: 0.015165
2021-12-14 03:29:05,752 iteration 4971 : loss : 0.052693, loss_ce: 0.021684
2021-12-14 03:29:07,364 iteration 4972 : loss : 0.053721, loss_ce: 0.019264
2021-12-14 03:29:08,949 iteration 4973 : loss : 0.042412, loss_ce: 0.014193
2021-12-14 03:29:10,649 iteration 4974 : loss : 0.046325, loss_ce: 0.013394
2021-12-14 03:29:12,218 iteration 4975 : loss : 0.044052, loss_ce: 0.011924
2021-12-14 03:29:13,734 iteration 4976 : loss : 0.045138, loss_ce: 0.014472
2021-12-14 03:29:15,339 iteration 4977 : loss : 0.063312, loss_ce: 0.013773
2021-12-14 03:29:16,903 iteration 4978 : loss : 0.040967, loss_ce: 0.010684
2021-12-14 03:29:18,476 iteration 4979 : loss : 0.066393, loss_ce: 0.021902
2021-12-14 03:29:20,061 iteration 4980 : loss : 0.048375, loss_ce: 0.012009
2021-12-14 03:29:21,633 iteration 4981 : loss : 0.054205, loss_ce: 0.016631
 73%|█████████████████████▏       | 293/400 [2:24:18<50:33, 28.35s/it]2021-12-14 03:29:23,251 iteration 4982 : loss : 0.045386, loss_ce: 0.017691
2021-12-14 03:29:24,805 iteration 4983 : loss : 0.044247, loss_ce: 0.014769
2021-12-14 03:29:26,475 iteration 4984 : loss : 0.054875, loss_ce: 0.017134
2021-12-14 03:29:27,989 iteration 4985 : loss : 0.045304, loss_ce: 0.011943
2021-12-14 03:29:29,646 iteration 4986 : loss : 0.052222, loss_ce: 0.020068
2021-12-14 03:29:31,174 iteration 4987 : loss : 0.046377, loss_ce: 0.013162
2021-12-14 03:29:32,765 iteration 4988 : loss : 0.047127, loss_ce: 0.013321
2021-12-14 03:29:34,397 iteration 4989 : loss : 0.055594, loss_ce: 0.017642
2021-12-14 03:29:36,059 iteration 4990 : loss : 0.052615, loss_ce: 0.021026
2021-12-14 03:29:37,653 iteration 4991 : loss : 0.057758, loss_ce: 0.016079
2021-12-14 03:29:39,152 iteration 4992 : loss : 0.047599, loss_ce: 0.020212
2021-12-14 03:29:40,709 iteration 4993 : loss : 0.048748, loss_ce: 0.016253
2021-12-14 03:29:42,234 iteration 4994 : loss : 0.046733, loss_ce: 0.012324
2021-12-14 03:29:43,774 iteration 4995 : loss : 0.047168, loss_ce: 0.018182
2021-12-14 03:29:45,404 iteration 4996 : loss : 0.053270, loss_ce: 0.013511
2021-12-14 03:29:46,910 iteration 4997 : loss : 0.049790, loss_ce: 0.013967
2021-12-14 03:29:48,427 iteration 4998 : loss : 0.044603, loss_ce: 0.014235
 74%|█████████████████████▎       | 294/400 [2:24:45<49:16, 27.89s/it]2021-12-14 03:29:50,026 iteration 4999 : loss : 0.040754, loss_ce: 0.013071
2021-12-14 03:29:51,582 iteration 5000 : loss : 0.045676, loss_ce: 0.015470
2021-12-14 03:29:53,141 iteration 5001 : loss : 0.045757, loss_ce: 0.015642
2021-12-14 03:29:54,690 iteration 5002 : loss : 0.038391, loss_ce: 0.011245
2021-12-14 03:29:56,285 iteration 5003 : loss : 0.062695, loss_ce: 0.012730
2021-12-14 03:29:57,849 iteration 5004 : loss : 0.056627, loss_ce: 0.018221
2021-12-14 03:29:59,419 iteration 5005 : loss : 0.057362, loss_ce: 0.021739
2021-12-14 03:30:01,046 iteration 5006 : loss : 0.054261, loss_ce: 0.019592
2021-12-14 03:30:02,665 iteration 5007 : loss : 0.053477, loss_ce: 0.019683
2021-12-14 03:30:04,283 iteration 5008 : loss : 0.062308, loss_ce: 0.022492
2021-12-14 03:30:05,906 iteration 5009 : loss : 0.050674, loss_ce: 0.012543
2021-12-14 03:30:07,510 iteration 5010 : loss : 0.054788, loss_ce: 0.017869
2021-12-14 03:30:09,069 iteration 5011 : loss : 0.044665, loss_ce: 0.017415
2021-12-14 03:30:10,662 iteration 5012 : loss : 0.046056, loss_ce: 0.014810
2021-12-14 03:30:12,188 iteration 5013 : loss : 0.041676, loss_ce: 0.013687
2021-12-14 03:30:13,754 iteration 5014 : loss : 0.052167, loss_ce: 0.016409
2021-12-14 03:30:13,754 Training Data Eval:
2021-12-14 03:30:21,931   Average segmentation loss on training set: 0.0351
2021-12-14 03:30:21,931 Validation Data Eval:
2021-12-14 03:30:24,730   Average segmentation loss on validation set: 0.0891
2021-12-14 03:30:26,296 iteration 5015 : loss : 0.046724, loss_ce: 0.013399
 74%|█████████████████████▍       | 295/400 [2:25:23<54:02, 30.88s/it]2021-12-14 03:30:27,919 iteration 5016 : loss : 0.055268, loss_ce: 0.024046
2021-12-14 03:30:29,468 iteration 5017 : loss : 0.038893, loss_ce: 0.011821
2021-12-14 03:30:31,033 iteration 5018 : loss : 0.048532, loss_ce: 0.017505
2021-12-14 03:30:32,620 iteration 5019 : loss : 0.045388, loss_ce: 0.013757
2021-12-14 03:30:34,219 iteration 5020 : loss : 0.053085, loss_ce: 0.015772
2021-12-14 03:30:35,841 iteration 5021 : loss : 0.053368, loss_ce: 0.022920
2021-12-14 03:30:37,366 iteration 5022 : loss : 0.042943, loss_ce: 0.011918
2021-12-14 03:30:38,939 iteration 5023 : loss : 0.052536, loss_ce: 0.012982
2021-12-14 03:30:40,609 iteration 5024 : loss : 0.052329, loss_ce: 0.010938
2021-12-14 03:30:42,252 iteration 5025 : loss : 0.064061, loss_ce: 0.013828
2021-12-14 03:30:43,839 iteration 5026 : loss : 0.044990, loss_ce: 0.015081
2021-12-14 03:30:45,395 iteration 5027 : loss : 0.044653, loss_ce: 0.016072
2021-12-14 03:30:46,956 iteration 5028 : loss : 0.062531, loss_ce: 0.024141
2021-12-14 03:30:48,635 iteration 5029 : loss : 0.069027, loss_ce: 0.014484
2021-12-14 03:30:50,223 iteration 5030 : loss : 0.053104, loss_ce: 0.023214
2021-12-14 03:30:51,877 iteration 5031 : loss : 0.047565, loss_ce: 0.016737
2021-12-14 03:30:53,473 iteration 5032 : loss : 0.049978, loss_ce: 0.020009
 74%|█████████████████████▍       | 296/400 [2:25:50<51:36, 29.77s/it]2021-12-14 03:30:55,243 iteration 5033 : loss : 0.061235, loss_ce: 0.018215
2021-12-14 03:30:56,817 iteration 5034 : loss : 0.054114, loss_ce: 0.017006
2021-12-14 03:30:58,371 iteration 5035 : loss : 0.045908, loss_ce: 0.016060
2021-12-14 03:30:59,939 iteration 5036 : loss : 0.052374, loss_ce: 0.018048
2021-12-14 03:31:01,535 iteration 5037 : loss : 0.056305, loss_ce: 0.019689
2021-12-14 03:31:03,092 iteration 5038 : loss : 0.054322, loss_ce: 0.014083
2021-12-14 03:31:04,774 iteration 5039 : loss : 0.057783, loss_ce: 0.025829
2021-12-14 03:31:06,370 iteration 5040 : loss : 0.042994, loss_ce: 0.011944
2021-12-14 03:31:08,035 iteration 5041 : loss : 0.053133, loss_ce: 0.015627
2021-12-14 03:31:09,590 iteration 5042 : loss : 0.048130, loss_ce: 0.017712
2021-12-14 03:31:11,180 iteration 5043 : loss : 0.049599, loss_ce: 0.021742
2021-12-14 03:31:12,778 iteration 5044 : loss : 0.051525, loss_ce: 0.019922
2021-12-14 03:31:14,420 iteration 5045 : loss : 0.052728, loss_ce: 0.020629
2021-12-14 03:31:16,032 iteration 5046 : loss : 0.060412, loss_ce: 0.016044
2021-12-14 03:31:17,611 iteration 5047 : loss : 0.053263, loss_ce: 0.014220
2021-12-14 03:31:19,173 iteration 5048 : loss : 0.045932, loss_ce: 0.015913
2021-12-14 03:31:20,735 iteration 5049 : loss : 0.056151, loss_ce: 0.022913
 74%|█████████████████████▌       | 297/400 [2:26:17<49:48, 29.02s/it]2021-12-14 03:31:22,386 iteration 5050 : loss : 0.061760, loss_ce: 0.017739
2021-12-14 03:31:23,955 iteration 5051 : loss : 0.061307, loss_ce: 0.019733
2021-12-14 03:31:25,536 iteration 5052 : loss : 0.043536, loss_ce: 0.016384
2021-12-14 03:31:27,099 iteration 5053 : loss : 0.041206, loss_ce: 0.013232
2021-12-14 03:31:28,688 iteration 5054 : loss : 0.042724, loss_ce: 0.012633
2021-12-14 03:31:30,255 iteration 5055 : loss : 0.048456, loss_ce: 0.015630
2021-12-14 03:31:31,810 iteration 5056 : loss : 0.050302, loss_ce: 0.012628
2021-12-14 03:31:33,447 iteration 5057 : loss : 0.043943, loss_ce: 0.018635
2021-12-14 03:31:35,106 iteration 5058 : loss : 0.049590, loss_ce: 0.017329
2021-12-14 03:31:36,585 iteration 5059 : loss : 0.048253, loss_ce: 0.011609
2021-12-14 03:31:38,173 iteration 5060 : loss : 0.059346, loss_ce: 0.014196
2021-12-14 03:31:39,791 iteration 5061 : loss : 0.048756, loss_ce: 0.017142
2021-12-14 03:31:41,396 iteration 5062 : loss : 0.061765, loss_ce: 0.016150
2021-12-14 03:31:43,048 iteration 5063 : loss : 0.067195, loss_ce: 0.024911
2021-12-14 03:31:44,601 iteration 5064 : loss : 0.048982, loss_ce: 0.015377
2021-12-14 03:31:46,155 iteration 5065 : loss : 0.050874, loss_ce: 0.016280
2021-12-14 03:31:47,748 iteration 5066 : loss : 0.040463, loss_ce: 0.016092
 74%|█████████████████████▌       | 298/400 [2:26:44<48:18, 28.41s/it]2021-12-14 03:31:49,491 iteration 5067 : loss : 0.050652, loss_ce: 0.015242
2021-12-14 03:31:51,105 iteration 5068 : loss : 0.048035, loss_ce: 0.017169
2021-12-14 03:31:52,717 iteration 5069 : loss : 0.049415, loss_ce: 0.014766
2021-12-14 03:31:54,294 iteration 5070 : loss : 0.048735, loss_ce: 0.014186
2021-12-14 03:31:55,954 iteration 5071 : loss : 0.054428, loss_ce: 0.019668
2021-12-14 03:31:57,424 iteration 5072 : loss : 0.042093, loss_ce: 0.013424
2021-12-14 03:31:59,002 iteration 5073 : loss : 0.050473, loss_ce: 0.021532
2021-12-14 03:32:00,630 iteration 5074 : loss : 0.047482, loss_ce: 0.013441
2021-12-14 03:32:02,217 iteration 5075 : loss : 0.040273, loss_ce: 0.013828
2021-12-14 03:32:03,855 iteration 5076 : loss : 0.042770, loss_ce: 0.015215
2021-12-14 03:32:05,434 iteration 5077 : loss : 0.048573, loss_ce: 0.016368
2021-12-14 03:32:07,031 iteration 5078 : loss : 0.049378, loss_ce: 0.013805
2021-12-14 03:32:08,601 iteration 5079 : loss : 0.043732, loss_ce: 0.014627
2021-12-14 03:32:10,207 iteration 5080 : loss : 0.043842, loss_ce: 0.013556
2021-12-14 03:32:11,826 iteration 5081 : loss : 0.047274, loss_ce: 0.017624
2021-12-14 03:32:13,477 iteration 5082 : loss : 0.060226, loss_ce: 0.025788
2021-12-14 03:32:15,099 iteration 5083 : loss : 0.053108, loss_ce: 0.015914
 75%|█████████████████████▋       | 299/400 [2:27:12<47:17, 28.10s/it]2021-12-14 03:32:16,724 iteration 5084 : loss : 0.041940, loss_ce: 0.012442
2021-12-14 03:32:18,312 iteration 5085 : loss : 0.048482, loss_ce: 0.015261
2021-12-14 03:32:19,875 iteration 5086 : loss : 0.043192, loss_ce: 0.013242
2021-12-14 03:32:21,514 iteration 5087 : loss : 0.059804, loss_ce: 0.019081
2021-12-14 03:32:23,125 iteration 5088 : loss : 0.050145, loss_ce: 0.016396
2021-12-14 03:32:24,667 iteration 5089 : loss : 0.044917, loss_ce: 0.012519
2021-12-14 03:32:26,224 iteration 5090 : loss : 0.045877, loss_ce: 0.014337
2021-12-14 03:32:27,913 iteration 5091 : loss : 0.061123, loss_ce: 0.023965
2021-12-14 03:32:29,505 iteration 5092 : loss : 0.038563, loss_ce: 0.013076
2021-12-14 03:32:31,058 iteration 5093 : loss : 0.053462, loss_ce: 0.020423
2021-12-14 03:32:32,587 iteration 5094 : loss : 0.042360, loss_ce: 0.014415
2021-12-14 03:32:34,218 iteration 5095 : loss : 0.058663, loss_ce: 0.017780
2021-12-14 03:32:35,756 iteration 5096 : loss : 0.040697, loss_ce: 0.012763
2021-12-14 03:32:37,312 iteration 5097 : loss : 0.045143, loss_ce: 0.016260
2021-12-14 03:32:38,915 iteration 5098 : loss : 0.061441, loss_ce: 0.018460
2021-12-14 03:32:40,489 iteration 5099 : loss : 0.044657, loss_ce: 0.012352
2021-12-14 03:32:40,489 Training Data Eval:
2021-12-14 03:32:48,664   Average segmentation loss on training set: 0.0356
2021-12-14 03:32:48,664 Validation Data Eval:
2021-12-14 03:32:51,455   Average segmentation loss on validation set: 0.0886
2021-12-14 03:32:53,037 iteration 5100 : loss : 0.039287, loss_ce: 0.014957
 75%|█████████████████████▊       | 300/400 [2:27:49<51:44, 31.05s/it]2021-12-14 03:32:54,697 iteration 5101 : loss : 0.048254, loss_ce: 0.017445
2021-12-14 03:32:56,250 iteration 5102 : loss : 0.037818, loss_ce: 0.011142
2021-12-14 03:32:57,827 iteration 5103 : loss : 0.051027, loss_ce: 0.017661
2021-12-14 03:32:59,483 iteration 5104 : loss : 0.045155, loss_ce: 0.016938
2021-12-14 03:33:01,015 iteration 5105 : loss : 0.049393, loss_ce: 0.015356
2021-12-14 03:33:02,674 iteration 5106 : loss : 0.049617, loss_ce: 0.017483
2021-12-14 03:33:04,206 iteration 5107 : loss : 0.044020, loss_ce: 0.015514
2021-12-14 03:33:05,820 iteration 5108 : loss : 0.056810, loss_ce: 0.017202
2021-12-14 03:33:07,418 iteration 5109 : loss : 0.056405, loss_ce: 0.016115
2021-12-14 03:33:08,997 iteration 5110 : loss : 0.051610, loss_ce: 0.019391
2021-12-14 03:33:10,616 iteration 5111 : loss : 0.048552, loss_ce: 0.015831
2021-12-14 03:33:12,153 iteration 5112 : loss : 0.054300, loss_ce: 0.015152
2021-12-14 03:33:13,806 iteration 5113 : loss : 0.077801, loss_ce: 0.014439
2021-12-14 03:33:15,378 iteration 5114 : loss : 0.043028, loss_ce: 0.017736
2021-12-14 03:33:16,925 iteration 5115 : loss : 0.050653, loss_ce: 0.012012
2021-12-14 03:33:18,480 iteration 5116 : loss : 0.041860, loss_ce: 0.014005
2021-12-14 03:33:20,134 iteration 5117 : loss : 0.049210, loss_ce: 0.019145
 75%|█████████████████████▊       | 301/400 [2:28:17<49:16, 29.86s/it]2021-12-14 03:33:21,792 iteration 5118 : loss : 0.039671, loss_ce: 0.012251
2021-12-14 03:33:23,395 iteration 5119 : loss : 0.049217, loss_ce: 0.013840
2021-12-14 03:33:24,950 iteration 5120 : loss : 0.085383, loss_ce: 0.024119
2021-12-14 03:33:26,538 iteration 5121 : loss : 0.053758, loss_ce: 0.022057
2021-12-14 03:33:28,080 iteration 5122 : loss : 0.052829, loss_ce: 0.016294
2021-12-14 03:33:29,643 iteration 5123 : loss : 0.047851, loss_ce: 0.011863
2021-12-14 03:33:31,235 iteration 5124 : loss : 0.043318, loss_ce: 0.014891
2021-12-14 03:33:32,717 iteration 5125 : loss : 0.050015, loss_ce: 0.022099
2021-12-14 03:33:34,234 iteration 5126 : loss : 0.052402, loss_ce: 0.016043
2021-12-14 03:33:35,854 iteration 5127 : loss : 0.060773, loss_ce: 0.017216
2021-12-14 03:33:37,398 iteration 5128 : loss : 0.041170, loss_ce: 0.014760
2021-12-14 03:33:38,991 iteration 5129 : loss : 0.045256, loss_ce: 0.012991
2021-12-14 03:33:40,566 iteration 5130 : loss : 0.048783, loss_ce: 0.014098
2021-12-14 03:33:42,059 iteration 5131 : loss : 0.037621, loss_ce: 0.011713
2021-12-14 03:33:43,618 iteration 5132 : loss : 0.046754, loss_ce: 0.018297
2021-12-14 03:33:45,151 iteration 5133 : loss : 0.054283, loss_ce: 0.014192
2021-12-14 03:33:46,669 iteration 5134 : loss : 0.047682, loss_ce: 0.017680
 76%|█████████████████████▉       | 302/400 [2:28:43<47:08, 28.87s/it]2021-12-14 03:33:48,439 iteration 5135 : loss : 0.057706, loss_ce: 0.022063
2021-12-14 03:33:50,008 iteration 5136 : loss : 0.053220, loss_ce: 0.015546
2021-12-14 03:33:51,635 iteration 5137 : loss : 0.062758, loss_ce: 0.016987
2021-12-14 03:33:53,179 iteration 5138 : loss : 0.046633, loss_ce: 0.016578
2021-12-14 03:33:54,758 iteration 5139 : loss : 0.047582, loss_ce: 0.017164
2021-12-14 03:33:56,427 iteration 5140 : loss : 0.045303, loss_ce: 0.017019
2021-12-14 03:33:57,968 iteration 5141 : loss : 0.048467, loss_ce: 0.016274
2021-12-14 03:33:59,558 iteration 5142 : loss : 0.062434, loss_ce: 0.018878
2021-12-14 03:34:01,058 iteration 5143 : loss : 0.046006, loss_ce: 0.015378
2021-12-14 03:34:02,660 iteration 5144 : loss : 0.050873, loss_ce: 0.023134
2021-12-14 03:34:04,154 iteration 5145 : loss : 0.040355, loss_ce: 0.012785
2021-12-14 03:34:05,794 iteration 5146 : loss : 0.052055, loss_ce: 0.020807
2021-12-14 03:34:07,434 iteration 5147 : loss : 0.043550, loss_ce: 0.011792
2021-12-14 03:34:08,996 iteration 5148 : loss : 0.050257, loss_ce: 0.018596
2021-12-14 03:34:10,558 iteration 5149 : loss : 0.053553, loss_ce: 0.013106
2021-12-14 03:34:12,116 iteration 5150 : loss : 0.040195, loss_ce: 0.013670
2021-12-14 03:34:13,703 iteration 5151 : loss : 0.072264, loss_ce: 0.014760
 76%|█████████████████████▉       | 303/400 [2:29:10<45:46, 28.32s/it]2021-12-14 03:34:15,288 iteration 5152 : loss : 0.054253, loss_ce: 0.010457
2021-12-14 03:34:16,771 iteration 5153 : loss : 0.042253, loss_ce: 0.014211
2021-12-14 03:34:18,406 iteration 5154 : loss : 0.051330, loss_ce: 0.020412
2021-12-14 03:34:19,919 iteration 5155 : loss : 0.039180, loss_ce: 0.012012
2021-12-14 03:34:21,472 iteration 5156 : loss : 0.049117, loss_ce: 0.018287
2021-12-14 03:34:22,976 iteration 5157 : loss : 0.052278, loss_ce: 0.015352
2021-12-14 03:34:24,524 iteration 5158 : loss : 0.044006, loss_ce: 0.013956
2021-12-14 03:34:26,147 iteration 5159 : loss : 0.049364, loss_ce: 0.014397
2021-12-14 03:34:27,660 iteration 5160 : loss : 0.045644, loss_ce: 0.014449
2021-12-14 03:34:29,217 iteration 5161 : loss : 0.045730, loss_ce: 0.014420
2021-12-14 03:34:30,730 iteration 5162 : loss : 0.047647, loss_ce: 0.018509
2021-12-14 03:34:32,322 iteration 5163 : loss : 0.044839, loss_ce: 0.017207
2021-12-14 03:34:33,910 iteration 5164 : loss : 0.048390, loss_ce: 0.021242
2021-12-14 03:34:35,417 iteration 5165 : loss : 0.044008, loss_ce: 0.012664
2021-12-14 03:34:36,984 iteration 5166 : loss : 0.041692, loss_ce: 0.015539
2021-12-14 03:34:38,566 iteration 5167 : loss : 0.050623, loss_ce: 0.014298
2021-12-14 03:34:40,193 iteration 5168 : loss : 0.049528, loss_ce: 0.014546
 76%|██████████████████████       | 304/400 [2:29:37<44:25, 27.76s/it]2021-12-14 03:34:41,918 iteration 5169 : loss : 0.059832, loss_ce: 0.023330
2021-12-14 03:34:43,442 iteration 5170 : loss : 0.046002, loss_ce: 0.012275
2021-12-14 03:34:45,078 iteration 5171 : loss : 0.046545, loss_ce: 0.015578
2021-12-14 03:34:46,579 iteration 5172 : loss : 0.051504, loss_ce: 0.016518
2021-12-14 03:34:48,027 iteration 5173 : loss : 0.042415, loss_ce: 0.016456
2021-12-14 03:34:49,666 iteration 5174 : loss : 0.047286, loss_ce: 0.014765
2021-12-14 03:34:51,203 iteration 5175 : loss : 0.047311, loss_ce: 0.019266
2021-12-14 03:34:52,896 iteration 5176 : loss : 0.055176, loss_ce: 0.017914
2021-12-14 03:34:54,427 iteration 5177 : loss : 0.048731, loss_ce: 0.016179
2021-12-14 03:34:55,983 iteration 5178 : loss : 0.041344, loss_ce: 0.010602
2021-12-14 03:34:57,605 iteration 5179 : loss : 0.042457, loss_ce: 0.011941
2021-12-14 03:34:59,176 iteration 5180 : loss : 0.047541, loss_ce: 0.014844
2021-12-14 03:35:00,701 iteration 5181 : loss : 0.055213, loss_ce: 0.012564
2021-12-14 03:35:02,267 iteration 5182 : loss : 0.044902, loss_ce: 0.015641
2021-12-14 03:35:03,811 iteration 5183 : loss : 0.045332, loss_ce: 0.016788
2021-12-14 03:35:05,342 iteration 5184 : loss : 0.051414, loss_ce: 0.015038
2021-12-14 03:35:05,342 Training Data Eval:
2021-12-14 03:35:13,507   Average segmentation loss on training set: 0.0356
2021-12-14 03:35:13,508 Validation Data Eval:
2021-12-14 03:35:16,299   Average segmentation loss on validation set: 0.0866
2021-12-14 03:35:22,732 Found new lowest validation loss at iteration 5184! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/TU_3seeds/REVISED_SGD_best_val_loss_seed1234.pth
2021-12-14 03:35:24,185 iteration 5185 : loss : 0.045588, loss_ce: 0.014638
 76%|██████████████████████       | 305/400 [2:30:21<51:40, 32.63s/it]2021-12-14 03:35:25,686 iteration 5186 : loss : 0.042627, loss_ce: 0.016767
2021-12-14 03:35:27,187 iteration 5187 : loss : 0.043809, loss_ce: 0.014470
2021-12-14 03:35:28,717 iteration 5188 : loss : 0.044879, loss_ce: 0.016360
2021-12-14 03:35:30,274 iteration 5189 : loss : 0.048478, loss_ce: 0.016277
2021-12-14 03:35:31,790 iteration 5190 : loss : 0.045631, loss_ce: 0.017308
2021-12-14 03:35:33,416 iteration 5191 : loss : 0.057269, loss_ce: 0.017814
2021-12-14 03:35:35,023 iteration 5192 : loss : 0.047581, loss_ce: 0.012814
2021-12-14 03:35:36,547 iteration 5193 : loss : 0.039603, loss_ce: 0.011611
2021-12-14 03:35:38,147 iteration 5194 : loss : 0.049372, loss_ce: 0.018437
2021-12-14 03:35:39,690 iteration 5195 : loss : 0.043047, loss_ce: 0.013321
2021-12-14 03:35:41,168 iteration 5196 : loss : 0.035059, loss_ce: 0.008636
2021-12-14 03:35:42,677 iteration 5197 : loss : 0.040458, loss_ce: 0.011621
2021-12-14 03:35:44,200 iteration 5198 : loss : 0.043996, loss_ce: 0.016768
2021-12-14 03:35:45,794 iteration 5199 : loss : 0.039859, loss_ce: 0.012066
2021-12-14 03:35:47,360 iteration 5200 : loss : 0.055493, loss_ce: 0.016042
2021-12-14 03:35:48,945 iteration 5201 : loss : 0.047180, loss_ce: 0.014389
2021-12-14 03:35:50,600 iteration 5202 : loss : 0.056610, loss_ce: 0.023434
 76%|██████████████████████▏      | 306/400 [2:30:47<48:12, 30.77s/it]2021-12-14 03:35:52,188 iteration 5203 : loss : 0.043763, loss_ce: 0.013583
2021-12-14 03:35:53,735 iteration 5204 : loss : 0.045188, loss_ce: 0.015819
2021-12-14 03:35:55,450 iteration 5205 : loss : 0.049534, loss_ce: 0.017168
2021-12-14 03:35:57,017 iteration 5206 : loss : 0.049546, loss_ce: 0.015693
2021-12-14 03:35:58,594 iteration 5207 : loss : 0.046514, loss_ce: 0.017679
2021-12-14 03:36:00,239 iteration 5208 : loss : 0.050836, loss_ce: 0.016688
2021-12-14 03:36:01,765 iteration 5209 : loss : 0.044376, loss_ce: 0.015735
2021-12-14 03:36:03,381 iteration 5210 : loss : 0.054386, loss_ce: 0.018961
2021-12-14 03:36:04,973 iteration 5211 : loss : 0.044088, loss_ce: 0.015359
2021-12-14 03:36:06,552 iteration 5212 : loss : 0.049452, loss_ce: 0.015461
2021-12-14 03:36:08,023 iteration 5213 : loss : 0.042142, loss_ce: 0.013836
2021-12-14 03:36:09,685 iteration 5214 : loss : 0.057157, loss_ce: 0.021824
2021-12-14 03:36:11,296 iteration 5215 : loss : 0.044449, loss_ce: 0.014171
2021-12-14 03:36:12,926 iteration 5216 : loss : 0.045596, loss_ce: 0.012826
2021-12-14 03:36:14,583 iteration 5217 : loss : 0.046298, loss_ce: 0.013616
2021-12-14 03:36:16,119 iteration 5218 : loss : 0.059839, loss_ce: 0.011828
2021-12-14 03:36:17,785 iteration 5219 : loss : 0.047418, loss_ce: 0.012153
 77%|██████████████████████▎      | 307/400 [2:31:14<46:01, 29.69s/it]2021-12-14 03:36:19,387 iteration 5220 : loss : 0.048078, loss_ce: 0.013219
2021-12-14 03:36:20,949 iteration 5221 : loss : 0.060015, loss_ce: 0.018022
2021-12-14 03:36:22,472 iteration 5222 : loss : 0.049124, loss_ce: 0.015642
2021-12-14 03:36:24,088 iteration 5223 : loss : 0.045294, loss_ce: 0.015664
2021-12-14 03:36:25,652 iteration 5224 : loss : 0.051400, loss_ce: 0.015796
2021-12-14 03:36:27,280 iteration 5225 : loss : 0.045416, loss_ce: 0.012452
2021-12-14 03:36:28,846 iteration 5226 : loss : 0.044452, loss_ce: 0.015157
2021-12-14 03:36:30,509 iteration 5227 : loss : 0.050007, loss_ce: 0.018779
2021-12-14 03:36:32,057 iteration 5228 : loss : 0.048015, loss_ce: 0.013426
2021-12-14 03:36:33,752 iteration 5229 : loss : 0.048343, loss_ce: 0.015921
2021-12-14 03:36:35,226 iteration 5230 : loss : 0.039177, loss_ce: 0.015053
2021-12-14 03:36:36,823 iteration 5231 : loss : 0.063959, loss_ce: 0.022983
2021-12-14 03:36:38,406 iteration 5232 : loss : 0.045756, loss_ce: 0.011768
2021-12-14 03:36:40,019 iteration 5233 : loss : 0.043389, loss_ce: 0.014240
2021-12-14 03:36:41,565 iteration 5234 : loss : 0.049946, loss_ce: 0.020084
2021-12-14 03:36:43,151 iteration 5235 : loss : 0.045133, loss_ce: 0.014495
2021-12-14 03:36:44,771 iteration 5236 : loss : 0.054179, loss_ce: 0.019383
 77%|██████████████████████▎      | 308/400 [2:31:41<44:16, 28.88s/it]2021-12-14 03:36:46,272 iteration 5237 : loss : 0.041615, loss_ce: 0.015673
2021-12-14 03:36:47,876 iteration 5238 : loss : 0.044009, loss_ce: 0.015864
2021-12-14 03:36:49,468 iteration 5239 : loss : 0.045374, loss_ce: 0.012137
2021-12-14 03:36:51,084 iteration 5240 : loss : 0.181289, loss_ce: 0.010989
2021-12-14 03:36:52,631 iteration 5241 : loss : 0.044951, loss_ce: 0.015559
2021-12-14 03:36:54,207 iteration 5242 : loss : 0.048716, loss_ce: 0.017800
2021-12-14 03:36:55,875 iteration 5243 : loss : 0.051470, loss_ce: 0.015916
2021-12-14 03:36:57,489 iteration 5244 : loss : 0.040992, loss_ce: 0.014108
2021-12-14 03:36:59,082 iteration 5245 : loss : 0.049389, loss_ce: 0.016257
2021-12-14 03:37:00,685 iteration 5246 : loss : 0.049007, loss_ce: 0.012792
2021-12-14 03:37:02,187 iteration 5247 : loss : 0.038499, loss_ce: 0.012953
2021-12-14 03:37:03,799 iteration 5248 : loss : 0.039160, loss_ce: 0.011179
2021-12-14 03:37:05,458 iteration 5249 : loss : 0.053194, loss_ce: 0.017169
2021-12-14 03:37:07,065 iteration 5250 : loss : 0.052625, loss_ce: 0.022214
2021-12-14 03:37:08,566 iteration 5251 : loss : 0.039374, loss_ce: 0.011658
2021-12-14 03:37:10,144 iteration 5252 : loss : 0.044153, loss_ce: 0.015388
2021-12-14 03:37:11,752 iteration 5253 : loss : 0.068652, loss_ce: 0.013829
 77%|██████████████████████▍      | 309/400 [2:32:08<42:56, 28.31s/it]2021-12-14 03:37:13,366 iteration 5254 : loss : 0.035967, loss_ce: 0.010648
2021-12-14 03:37:14,937 iteration 5255 : loss : 0.054456, loss_ce: 0.026571
2021-12-14 03:37:16,449 iteration 5256 : loss : 0.044848, loss_ce: 0.014199
2021-12-14 03:37:18,029 iteration 5257 : loss : 0.046173, loss_ce: 0.016258
2021-12-14 03:37:19,646 iteration 5258 : loss : 0.037291, loss_ce: 0.009562
2021-12-14 03:37:21,173 iteration 5259 : loss : 0.051090, loss_ce: 0.012064
2021-12-14 03:37:22,767 iteration 5260 : loss : 0.039527, loss_ce: 0.012411
2021-12-14 03:37:24,370 iteration 5261 : loss : 0.049891, loss_ce: 0.016279
2021-12-14 03:37:25,956 iteration 5262 : loss : 0.038412, loss_ce: 0.012652
2021-12-14 03:37:27,544 iteration 5263 : loss : 0.051394, loss_ce: 0.019062
2021-12-14 03:37:29,072 iteration 5264 : loss : 0.040599, loss_ce: 0.013169
2021-12-14 03:37:30,696 iteration 5265 : loss : 0.048937, loss_ce: 0.015822
2021-12-14 03:37:32,354 iteration 5266 : loss : 0.052113, loss_ce: 0.015501
2021-12-14 03:37:33,931 iteration 5267 : loss : 0.061043, loss_ce: 0.015992
2021-12-14 03:37:35,521 iteration 5268 : loss : 0.051275, loss_ce: 0.013469
2021-12-14 03:37:37,213 iteration 5269 : loss : 0.057754, loss_ce: 0.014737
2021-12-14 03:37:37,213 Training Data Eval:
2021-12-14 03:37:45,391   Average segmentation loss on training set: 0.0344
2021-12-14 03:37:45,391 Validation Data Eval:
2021-12-14 03:37:48,186   Average segmentation loss on validation set: 0.0927
2021-12-14 03:37:49,765 iteration 5270 : loss : 0.047466, loss_ce: 0.017442
 78%|██████████████████████▍      | 310/400 [2:32:46<46:50, 31.22s/it]2021-12-14 03:37:51,374 iteration 5271 : loss : 0.074754, loss_ce: 0.022780
2021-12-14 03:37:52,978 iteration 5272 : loss : 0.048482, loss_ce: 0.019086
2021-12-14 03:37:54,522 iteration 5273 : loss : 0.044338, loss_ce: 0.011889
2021-12-14 03:37:56,081 iteration 5274 : loss : 0.041788, loss_ce: 0.014032
2021-12-14 03:37:57,582 iteration 5275 : loss : 0.041503, loss_ce: 0.015305
2021-12-14 03:37:59,186 iteration 5276 : loss : 0.051329, loss_ce: 0.018136
2021-12-14 03:38:00,771 iteration 5277 : loss : 0.044142, loss_ce: 0.015054
2021-12-14 03:38:02,267 iteration 5278 : loss : 0.039191, loss_ce: 0.013655
2021-12-14 03:38:03,844 iteration 5279 : loss : 0.042861, loss_ce: 0.016184
2021-12-14 03:38:05,547 iteration 5280 : loss : 0.065736, loss_ce: 0.021090
2021-12-14 03:38:07,107 iteration 5281 : loss : 0.049335, loss_ce: 0.017319
2021-12-14 03:38:08,617 iteration 5282 : loss : 0.039878, loss_ce: 0.011874
2021-12-14 03:38:10,195 iteration 5283 : loss : 0.057021, loss_ce: 0.016048
2021-12-14 03:38:11,785 iteration 5284 : loss : 0.050276, loss_ce: 0.012215
2021-12-14 03:38:13,351 iteration 5285 : loss : 0.042630, loss_ce: 0.015891
2021-12-14 03:38:14,841 iteration 5286 : loss : 0.039522, loss_ce: 0.014768
2021-12-14 03:38:16,397 iteration 5287 : loss : 0.044867, loss_ce: 0.008758
 78%|██████████████████████▌      | 311/400 [2:33:13<44:16, 29.85s/it]2021-12-14 03:38:18,057 iteration 5288 : loss : 0.042816, loss_ce: 0.015259
2021-12-14 03:38:19,663 iteration 5289 : loss : 0.043362, loss_ce: 0.011373
2021-12-14 03:38:21,226 iteration 5290 : loss : 0.049381, loss_ce: 0.010782
2021-12-14 03:38:22,774 iteration 5291 : loss : 0.057129, loss_ce: 0.018746
2021-12-14 03:38:24,384 iteration 5292 : loss : 0.049924, loss_ce: 0.017927
2021-12-14 03:38:25,980 iteration 5293 : loss : 0.051114, loss_ce: 0.019567
2021-12-14 03:38:27,628 iteration 5294 : loss : 0.057095, loss_ce: 0.021544
2021-12-14 03:38:29,302 iteration 5295 : loss : 0.054491, loss_ce: 0.018879
2021-12-14 03:38:30,923 iteration 5296 : loss : 0.052578, loss_ce: 0.011212
2021-12-14 03:38:32,543 iteration 5297 : loss : 0.042873, loss_ce: 0.011115
2021-12-14 03:38:34,167 iteration 5298 : loss : 0.049540, loss_ce: 0.017508
2021-12-14 03:38:35,787 iteration 5299 : loss : 0.053786, loss_ce: 0.018757
2021-12-14 03:38:37,426 iteration 5300 : loss : 0.056374, loss_ce: 0.017009
2021-12-14 03:38:38,949 iteration 5301 : loss : 0.044151, loss_ce: 0.015154
2021-12-14 03:38:40,473 iteration 5302 : loss : 0.042959, loss_ce: 0.017078
2021-12-14 03:38:42,001 iteration 5303 : loss : 0.042837, loss_ce: 0.015538
2021-12-14 03:38:43,505 iteration 5304 : loss : 0.055691, loss_ce: 0.017290
 78%|██████████████████████▌      | 312/400 [2:33:40<42:34, 29.02s/it]2021-12-14 03:38:45,149 iteration 5305 : loss : 0.048042, loss_ce: 0.014961
2021-12-14 03:38:46,833 iteration 5306 : loss : 0.064451, loss_ce: 0.025390
2021-12-14 03:38:48,531 iteration 5307 : loss : 0.049032, loss_ce: 0.015929
2021-12-14 03:38:50,184 iteration 5308 : loss : 0.093952, loss_ce: 0.022877
2021-12-14 03:38:51,824 iteration 5309 : loss : 0.047161, loss_ce: 0.013238
2021-12-14 03:38:53,375 iteration 5310 : loss : 0.044070, loss_ce: 0.018087
2021-12-14 03:38:54,918 iteration 5311 : loss : 0.056122, loss_ce: 0.013535
2021-12-14 03:38:56,557 iteration 5312 : loss : 0.043845, loss_ce: 0.016183
2021-12-14 03:38:58,249 iteration 5313 : loss : 0.053637, loss_ce: 0.013238
2021-12-14 03:38:59,850 iteration 5314 : loss : 0.049260, loss_ce: 0.016016
2021-12-14 03:39:01,502 iteration 5315 : loss : 0.051000, loss_ce: 0.010491
2021-12-14 03:39:03,135 iteration 5316 : loss : 0.040575, loss_ce: 0.011974
2021-12-14 03:39:04,712 iteration 5317 : loss : 0.039637, loss_ce: 0.014563
2021-12-14 03:39:06,260 iteration 5318 : loss : 0.047841, loss_ce: 0.015356
2021-12-14 03:39:07,893 iteration 5319 : loss : 0.053714, loss_ce: 0.018863
2021-12-14 03:39:09,517 iteration 5320 : loss : 0.052237, loss_ce: 0.019060
2021-12-14 03:39:11,173 iteration 5321 : loss : 0.067296, loss_ce: 0.023801
 78%|██████████████████████▋      | 313/400 [2:34:08<41:29, 28.61s/it]2021-12-14 03:39:12,729 iteration 5322 : loss : 0.041466, loss_ce: 0.014731
2021-12-14 03:39:14,331 iteration 5323 : loss : 0.051154, loss_ce: 0.019704
2021-12-14 03:39:15,853 iteration 5324 : loss : 0.040420, loss_ce: 0.011689
2021-12-14 03:39:17,404 iteration 5325 : loss : 0.053852, loss_ce: 0.010449
2021-12-14 03:39:19,024 iteration 5326 : loss : 0.046814, loss_ce: 0.014835
2021-12-14 03:39:20,570 iteration 5327 : loss : 0.050186, loss_ce: 0.014865
2021-12-14 03:39:22,132 iteration 5328 : loss : 0.055831, loss_ce: 0.022746
2021-12-14 03:39:23,760 iteration 5329 : loss : 0.057152, loss_ce: 0.017826
2021-12-14 03:39:25,364 iteration 5330 : loss : 0.048643, loss_ce: 0.015226
2021-12-14 03:39:26,938 iteration 5331 : loss : 0.046277, loss_ce: 0.013052
2021-12-14 03:39:28,531 iteration 5332 : loss : 0.055899, loss_ce: 0.016281
2021-12-14 03:39:30,148 iteration 5333 : loss : 0.048696, loss_ce: 0.019016
2021-12-14 03:39:31,747 iteration 5334 : loss : 0.071896, loss_ce: 0.026558
2021-12-14 03:39:33,375 iteration 5335 : loss : 0.053205, loss_ce: 0.014423
2021-12-14 03:39:34,978 iteration 5336 : loss : 0.045043, loss_ce: 0.014198
2021-12-14 03:39:36,532 iteration 5337 : loss : 0.042398, loss_ce: 0.013417
2021-12-14 03:39:38,088 iteration 5338 : loss : 0.043978, loss_ce: 0.015576
 78%|██████████████████████▊      | 314/400 [2:34:35<40:16, 28.10s/it]2021-12-14 03:39:39,873 iteration 5339 : loss : 0.054046, loss_ce: 0.020374
2021-12-14 03:39:41,513 iteration 5340 : loss : 0.061864, loss_ce: 0.029656
2021-12-14 03:39:43,120 iteration 5341 : loss : 0.057265, loss_ce: 0.008911
2021-12-14 03:39:44,719 iteration 5342 : loss : 0.049613, loss_ce: 0.020981
2021-12-14 03:39:46,273 iteration 5343 : loss : 0.043161, loss_ce: 0.012675
2021-12-14 03:39:47,880 iteration 5344 : loss : 0.049084, loss_ce: 0.015014
2021-12-14 03:39:49,459 iteration 5345 : loss : 0.043507, loss_ce: 0.013240
2021-12-14 03:39:51,089 iteration 5346 : loss : 0.051247, loss_ce: 0.016091
2021-12-14 03:39:52,718 iteration 5347 : loss : 0.046451, loss_ce: 0.011999
2021-12-14 03:39:54,355 iteration 5348 : loss : 0.050549, loss_ce: 0.012574
2021-12-14 03:39:55,952 iteration 5349 : loss : 0.046992, loss_ce: 0.015944
2021-12-14 03:39:57,465 iteration 5350 : loss : 0.041101, loss_ce: 0.013946
2021-12-14 03:39:58,988 iteration 5351 : loss : 0.064767, loss_ce: 0.020722
2021-12-14 03:40:00,612 iteration 5352 : loss : 0.055115, loss_ce: 0.020400
2021-12-14 03:40:02,239 iteration 5353 : loss : 0.041913, loss_ce: 0.012891
2021-12-14 03:40:03,788 iteration 5354 : loss : 0.044686, loss_ce: 0.017857
2021-12-14 03:40:03,788 Training Data Eval:
2021-12-14 03:40:11,961   Average segmentation loss on training set: 0.0357
2021-12-14 03:40:11,961 Validation Data Eval:
2021-12-14 03:40:14,761   Average segmentation loss on validation set: 0.0899
2021-12-14 03:40:16,277 iteration 5355 : loss : 0.049361, loss_ce: 0.016003
 79%|██████████████████████▊      | 315/400 [2:35:13<44:06, 31.13s/it]2021-12-14 03:40:17,916 iteration 5356 : loss : 0.054745, loss_ce: 0.019981
2021-12-14 03:40:19,437 iteration 5357 : loss : 0.052785, loss_ce: 0.013119
2021-12-14 03:40:21,155 iteration 5358 : loss : 0.054533, loss_ce: 0.019789
2021-12-14 03:40:22,666 iteration 5359 : loss : 0.048370, loss_ce: 0.015637
2021-12-14 03:40:24,268 iteration 5360 : loss : 0.051373, loss_ce: 0.019154
2021-12-14 03:40:25,869 iteration 5361 : loss : 0.051442, loss_ce: 0.018017
2021-12-14 03:40:27,481 iteration 5362 : loss : 0.050786, loss_ce: 0.013175
2021-12-14 03:40:29,064 iteration 5363 : loss : 0.047141, loss_ce: 0.015503
2021-12-14 03:40:30,646 iteration 5364 : loss : 0.075354, loss_ce: 0.015853
2021-12-14 03:40:32,211 iteration 5365 : loss : 0.040286, loss_ce: 0.014313
2021-12-14 03:40:33,809 iteration 5366 : loss : 0.048195, loss_ce: 0.017841
2021-12-14 03:40:35,434 iteration 5367 : loss : 0.043457, loss_ce: 0.014748
2021-12-14 03:40:37,003 iteration 5368 : loss : 0.039365, loss_ce: 0.014592
2021-12-14 03:40:38,598 iteration 5369 : loss : 0.040004, loss_ce: 0.013254
2021-12-14 03:40:40,164 iteration 5370 : loss : 0.038194, loss_ce: 0.013213
2021-12-14 03:40:41,755 iteration 5371 : loss : 0.048535, loss_ce: 0.019228
2021-12-14 03:40:43,312 iteration 5372 : loss : 0.045430, loss_ce: 0.012649
 79%|██████████████████████▉      | 316/400 [2:35:40<41:52, 29.91s/it]2021-12-14 03:40:44,961 iteration 5373 : loss : 0.045108, loss_ce: 0.018182
2021-12-14 03:40:46,514 iteration 5374 : loss : 0.048319, loss_ce: 0.016649
2021-12-14 03:40:48,125 iteration 5375 : loss : 0.037594, loss_ce: 0.009720
2021-12-14 03:40:49,692 iteration 5376 : loss : 0.066455, loss_ce: 0.023274
2021-12-14 03:40:51,244 iteration 5377 : loss : 0.037851, loss_ce: 0.010743
2021-12-14 03:40:52,829 iteration 5378 : loss : 0.042940, loss_ce: 0.013630
2021-12-14 03:40:54,347 iteration 5379 : loss : 0.043643, loss_ce: 0.013466
2021-12-14 03:40:55,931 iteration 5380 : loss : 0.048577, loss_ce: 0.016353
2021-12-14 03:40:57,483 iteration 5381 : loss : 0.047084, loss_ce: 0.017938
2021-12-14 03:40:59,083 iteration 5382 : loss : 0.042121, loss_ce: 0.012344
2021-12-14 03:41:00,747 iteration 5383 : loss : 0.051472, loss_ce: 0.018846
2021-12-14 03:41:02,490 iteration 5384 : loss : 0.055985, loss_ce: 0.019064
2021-12-14 03:41:04,054 iteration 5385 : loss : 0.044012, loss_ce: 0.016098
2021-12-14 03:41:05,553 iteration 5386 : loss : 0.037920, loss_ce: 0.011336
2021-12-14 03:41:07,104 iteration 5387 : loss : 0.043829, loss_ce: 0.016235
2021-12-14 03:41:08,735 iteration 5388 : loss : 0.046035, loss_ce: 0.012019
2021-12-14 03:41:10,436 iteration 5389 : loss : 0.061273, loss_ce: 0.019593
 79%|██████████████████████▉      | 317/400 [2:36:07<40:13, 29.07s/it]2021-12-14 03:41:12,056 iteration 5390 : loss : 0.059007, loss_ce: 0.017568
2021-12-14 03:41:13,682 iteration 5391 : loss : 0.053870, loss_ce: 0.016943
2021-12-14 03:41:15,319 iteration 5392 : loss : 0.047055, loss_ce: 0.019032
2021-12-14 03:41:16,904 iteration 5393 : loss : 0.050340, loss_ce: 0.013485
2021-12-14 03:41:18,457 iteration 5394 : loss : 0.045612, loss_ce: 0.017880
2021-12-14 03:41:20,068 iteration 5395 : loss : 0.048227, loss_ce: 0.015142
2021-12-14 03:41:21,604 iteration 5396 : loss : 0.047877, loss_ce: 0.021216
2021-12-14 03:41:23,253 iteration 5397 : loss : 0.049876, loss_ce: 0.014215
2021-12-14 03:41:24,854 iteration 5398 : loss : 0.043113, loss_ce: 0.013210
2021-12-14 03:41:26,375 iteration 5399 : loss : 0.051113, loss_ce: 0.014025
2021-12-14 03:41:28,050 iteration 5400 : loss : 0.056545, loss_ce: 0.015857
2021-12-14 03:41:29,667 iteration 5401 : loss : 0.057424, loss_ce: 0.024011
2021-12-14 03:41:31,258 iteration 5402 : loss : 0.045004, loss_ce: 0.013284
2021-12-14 03:41:32,810 iteration 5403 : loss : 0.050749, loss_ce: 0.018922
2021-12-14 03:41:34,348 iteration 5404 : loss : 0.045522, loss_ce: 0.011646
2021-12-14 03:41:35,902 iteration 5405 : loss : 0.042446, loss_ce: 0.015736
2021-12-14 03:41:37,524 iteration 5406 : loss : 0.054909, loss_ce: 0.016320
 80%|███████████████████████      | 318/400 [2:36:34<38:54, 28.47s/it]2021-12-14 03:41:39,199 iteration 5407 : loss : 0.052559, loss_ce: 0.018371
2021-12-14 03:41:40,780 iteration 5408 : loss : 0.052985, loss_ce: 0.014128
2021-12-14 03:41:42,444 iteration 5409 : loss : 0.052463, loss_ce: 0.020756
2021-12-14 03:41:43,998 iteration 5410 : loss : 0.050269, loss_ce: 0.018316
2021-12-14 03:41:45,582 iteration 5411 : loss : 0.041050, loss_ce: 0.012783
2021-12-14 03:41:47,178 iteration 5412 : loss : 0.049984, loss_ce: 0.016521
2021-12-14 03:41:48,734 iteration 5413 : loss : 0.047389, loss_ce: 0.020340
2021-12-14 03:41:50,323 iteration 5414 : loss : 0.046732, loss_ce: 0.016564
2021-12-14 03:41:51,991 iteration 5415 : loss : 0.063318, loss_ce: 0.022131
2021-12-14 03:41:53,510 iteration 5416 : loss : 0.037217, loss_ce: 0.011545
2021-12-14 03:41:55,120 iteration 5417 : loss : 0.041770, loss_ce: 0.011188
2021-12-14 03:41:56,684 iteration 5418 : loss : 0.055463, loss_ce: 0.019992
2021-12-14 03:41:58,291 iteration 5419 : loss : 0.050291, loss_ce: 0.013532
2021-12-14 03:41:59,943 iteration 5420 : loss : 0.048236, loss_ce: 0.014507
2021-12-14 03:42:01,555 iteration 5421 : loss : 0.052635, loss_ce: 0.022686
2021-12-14 03:42:03,032 iteration 5422 : loss : 0.036887, loss_ce: 0.012890
2021-12-14 03:42:04,651 iteration 5423 : loss : 0.065144, loss_ce: 0.013953
 80%|███████████████████████▏     | 319/400 [2:37:01<37:53, 28.07s/it]2021-12-14 03:42:06,353 iteration 5424 : loss : 0.055121, loss_ce: 0.018269
2021-12-14 03:42:07,899 iteration 5425 : loss : 0.041623, loss_ce: 0.012153
2021-12-14 03:42:09,473 iteration 5426 : loss : 0.056672, loss_ce: 0.014964
2021-12-14 03:42:10,966 iteration 5427 : loss : 0.049861, loss_ce: 0.016858
2021-12-14 03:42:12,518 iteration 5428 : loss : 0.048352, loss_ce: 0.015991
2021-12-14 03:42:14,113 iteration 5429 : loss : 0.043220, loss_ce: 0.013352
2021-12-14 03:42:15,696 iteration 5430 : loss : 0.041417, loss_ce: 0.014335
2021-12-14 03:42:17,210 iteration 5431 : loss : 0.045196, loss_ce: 0.014121
2021-12-14 03:42:18,871 iteration 5432 : loss : 0.049581, loss_ce: 0.020609
2021-12-14 03:42:20,506 iteration 5433 : loss : 0.048004, loss_ce: 0.017478
2021-12-14 03:42:22,035 iteration 5434 : loss : 0.044745, loss_ce: 0.016844
2021-12-14 03:42:23,681 iteration 5435 : loss : 0.055201, loss_ce: 0.021021
2021-12-14 03:42:25,288 iteration 5436 : loss : 0.049803, loss_ce: 0.017393
2021-12-14 03:42:26,921 iteration 5437 : loss : 0.087655, loss_ce: 0.016859
2021-12-14 03:42:28,553 iteration 5438 : loss : 0.046471, loss_ce: 0.017128
2021-12-14 03:42:30,121 iteration 5439 : loss : 0.047956, loss_ce: 0.016971
2021-12-14 03:42:30,121 Training Data Eval:
2021-12-14 03:42:38,302   Average segmentation loss on training set: 0.0345
2021-12-14 03:42:38,303 Validation Data Eval:
2021-12-14 03:42:41,093   Average segmentation loss on validation set: 0.0916
2021-12-14 03:42:42,615 iteration 5440 : loss : 0.043936, loss_ce: 0.012120
 80%|███████████████████████▏     | 320/400 [2:37:39<41:23, 31.04s/it]2021-12-14 03:42:44,228 iteration 5441 : loss : 0.040308, loss_ce: 0.011311
2021-12-14 03:42:45,756 iteration 5442 : loss : 0.045401, loss_ce: 0.014105
2021-12-14 03:42:47,318 iteration 5443 : loss : 0.046422, loss_ce: 0.013784
2021-12-14 03:42:48,816 iteration 5444 : loss : 0.044598, loss_ce: 0.013022
2021-12-14 03:42:50,403 iteration 5445 : loss : 0.055399, loss_ce: 0.018204
2021-12-14 03:42:51,937 iteration 5446 : loss : 0.050216, loss_ce: 0.020808
2021-12-14 03:42:53,593 iteration 5447 : loss : 0.064471, loss_ce: 0.018507
2021-12-14 03:42:55,119 iteration 5448 : loss : 0.047441, loss_ce: 0.016259
2021-12-14 03:42:56,706 iteration 5449 : loss : 0.055220, loss_ce: 0.025704
2021-12-14 03:42:58,275 iteration 5450 : loss : 0.042705, loss_ce: 0.014309
2021-12-14 03:42:59,786 iteration 5451 : loss : 0.043735, loss_ce: 0.012176
2021-12-14 03:43:01,369 iteration 5452 : loss : 0.048901, loss_ce: 0.017183
2021-12-14 03:43:02,897 iteration 5453 : loss : 0.044843, loss_ce: 0.015061
2021-12-14 03:43:04,523 iteration 5454 : loss : 0.061292, loss_ce: 0.027978
2021-12-14 03:43:06,122 iteration 5455 : loss : 0.050112, loss_ce: 0.014451
2021-12-14 03:43:07,701 iteration 5456 : loss : 0.046103, loss_ce: 0.008457
2021-12-14 03:43:09,233 iteration 5457 : loss : 0.043065, loss_ce: 0.011238
 80%|███████████████████████▎     | 321/400 [2:38:06<39:07, 29.72s/it]2021-12-14 03:43:10,849 iteration 5458 : loss : 0.052410, loss_ce: 0.014803
2021-12-14 03:43:12,365 iteration 5459 : loss : 0.044628, loss_ce: 0.016284
2021-12-14 03:43:13,940 iteration 5460 : loss : 0.041315, loss_ce: 0.012671
2021-12-14 03:43:15,510 iteration 5461 : loss : 0.047704, loss_ce: 0.015586
2021-12-14 03:43:17,072 iteration 5462 : loss : 0.040172, loss_ce: 0.012600
2021-12-14 03:43:18,664 iteration 5463 : loss : 0.053811, loss_ce: 0.015238
2021-12-14 03:43:20,253 iteration 5464 : loss : 0.046590, loss_ce: 0.018089
2021-12-14 03:43:21,902 iteration 5465 : loss : 0.052140, loss_ce: 0.019059
2021-12-14 03:43:23,541 iteration 5466 : loss : 0.045821, loss_ce: 0.013789
2021-12-14 03:43:25,144 iteration 5467 : loss : 0.057581, loss_ce: 0.018323
2021-12-14 03:43:26,744 iteration 5468 : loss : 0.043066, loss_ce: 0.015011
2021-12-14 03:43:28,256 iteration 5469 : loss : 0.044926, loss_ce: 0.013866
2021-12-14 03:43:29,816 iteration 5470 : loss : 0.032997, loss_ce: 0.009840
2021-12-14 03:43:31,377 iteration 5471 : loss : 0.054903, loss_ce: 0.013035
2021-12-14 03:43:32,975 iteration 5472 : loss : 0.059292, loss_ce: 0.021256
2021-12-14 03:43:34,493 iteration 5473 : loss : 0.041088, loss_ce: 0.012550
2021-12-14 03:43:36,021 iteration 5474 : loss : 0.047676, loss_ce: 0.013819
 80%|███████████████████████▎     | 322/400 [2:38:32<37:29, 28.83s/it]2021-12-14 03:43:37,665 iteration 5475 : loss : 0.048293, loss_ce: 0.012796
2021-12-14 03:43:39,299 iteration 5476 : loss : 0.052808, loss_ce: 0.020396
2021-12-14 03:43:40,876 iteration 5477 : loss : 0.080383, loss_ce: 0.012930
2021-12-14 03:43:42,376 iteration 5478 : loss : 0.046433, loss_ce: 0.013280
2021-12-14 03:43:43,942 iteration 5479 : loss : 0.045468, loss_ce: 0.016855
2021-12-14 03:43:45,507 iteration 5480 : loss : 0.043441, loss_ce: 0.012431
2021-12-14 03:43:47,046 iteration 5481 : loss : 0.044578, loss_ce: 0.015168
2021-12-14 03:43:48,720 iteration 5482 : loss : 0.059776, loss_ce: 0.013369
2021-12-14 03:43:50,224 iteration 5483 : loss : 0.042540, loss_ce: 0.014635
2021-12-14 03:43:51,823 iteration 5484 : loss : 0.050877, loss_ce: 0.016365
2021-12-14 03:43:53,400 iteration 5485 : loss : 0.046527, loss_ce: 0.015126
2021-12-14 03:43:54,978 iteration 5486 : loss : 0.049744, loss_ce: 0.018388
2021-12-14 03:43:56,566 iteration 5487 : loss : 0.049624, loss_ce: 0.016939
2021-12-14 03:43:58,104 iteration 5488 : loss : 0.047045, loss_ce: 0.019187
2021-12-14 03:43:59,635 iteration 5489 : loss : 0.048481, loss_ce: 0.021958
2021-12-14 03:44:01,285 iteration 5490 : loss : 0.051130, loss_ce: 0.017839
2021-12-14 03:44:02,840 iteration 5491 : loss : 0.039550, loss_ce: 0.010205
 81%|███████████████████████▍     | 323/400 [2:38:59<36:13, 28.23s/it]2021-12-14 03:44:04,381 iteration 5492 : loss : 0.043096, loss_ce: 0.014021
2021-12-14 03:44:05,984 iteration 5493 : loss : 0.044847, loss_ce: 0.012434
2021-12-14 03:44:07,519 iteration 5494 : loss : 0.044876, loss_ce: 0.012363
2021-12-14 03:44:09,102 iteration 5495 : loss : 0.038227, loss_ce: 0.010810
2021-12-14 03:44:10,694 iteration 5496 : loss : 0.043218, loss_ce: 0.011469
2021-12-14 03:44:12,283 iteration 5497 : loss : 0.047573, loss_ce: 0.016326
2021-12-14 03:44:13,907 iteration 5498 : loss : 0.072124, loss_ce: 0.022330
2021-12-14 03:44:15,513 iteration 5499 : loss : 0.060440, loss_ce: 0.028119
2021-12-14 03:44:17,026 iteration 5500 : loss : 0.041236, loss_ce: 0.014940
2021-12-14 03:44:18,603 iteration 5501 : loss : 0.046066, loss_ce: 0.016249
2021-12-14 03:44:20,136 iteration 5502 : loss : 0.036979, loss_ce: 0.013420
2021-12-14 03:44:21,703 iteration 5503 : loss : 0.050530, loss_ce: 0.014419
2021-12-14 03:44:23,240 iteration 5504 : loss : 0.044279, loss_ce: 0.014154
2021-12-14 03:44:24,808 iteration 5505 : loss : 0.057449, loss_ce: 0.019867
2021-12-14 03:44:26,408 iteration 5506 : loss : 0.042060, loss_ce: 0.013774
2021-12-14 03:44:27,972 iteration 5507 : loss : 0.052639, loss_ce: 0.018564
2021-12-14 03:44:29,553 iteration 5508 : loss : 0.058763, loss_ce: 0.016883
 81%|███████████████████████▍     | 324/400 [2:39:26<35:10, 27.77s/it]2021-12-14 03:44:31,179 iteration 5509 : loss : 0.046178, loss_ce: 0.012248
2021-12-14 03:44:32,848 iteration 5510 : loss : 0.044747, loss_ce: 0.014057
2021-12-14 03:44:34,414 iteration 5511 : loss : 0.043208, loss_ce: 0.013894
2021-12-14 03:44:36,043 iteration 5512 : loss : 0.052557, loss_ce: 0.016614
2021-12-14 03:44:37,598 iteration 5513 : loss : 0.038785, loss_ce: 0.013507
2021-12-14 03:44:39,110 iteration 5514 : loss : 0.038636, loss_ce: 0.012210
2021-12-14 03:44:40,745 iteration 5515 : loss : 0.075444, loss_ce: 0.016684
2021-12-14 03:44:42,298 iteration 5516 : loss : 0.046313, loss_ce: 0.015043
2021-12-14 03:44:43,882 iteration 5517 : loss : 0.043355, loss_ce: 0.016035
2021-12-14 03:44:45,460 iteration 5518 : loss : 0.051173, loss_ce: 0.014583
2021-12-14 03:44:47,056 iteration 5519 : loss : 0.055379, loss_ce: 0.019744
2021-12-14 03:44:48,631 iteration 5520 : loss : 0.044519, loss_ce: 0.017050
2021-12-14 03:44:50,223 iteration 5521 : loss : 0.050204, loss_ce: 0.019092
2021-12-14 03:44:51,795 iteration 5522 : loss : 0.054079, loss_ce: 0.015750
2021-12-14 03:44:53,340 iteration 5523 : loss : 0.035449, loss_ce: 0.009847
2021-12-14 03:44:54,887 iteration 5524 : loss : 0.049142, loss_ce: 0.017431
2021-12-14 03:44:54,887 Training Data Eval:
2021-12-14 03:45:03,066   Average segmentation loss on training set: 0.0349
2021-12-14 03:45:03,067 Validation Data Eval:
2021-12-14 03:45:05,866   Average segmentation loss on validation set: 0.0869
2021-12-14 03:45:07,436 iteration 5525 : loss : 0.055098, loss_ce: 0.023285
 81%|███████████████████████▌     | 325/400 [2:40:04<38:30, 30.81s/it]2021-12-14 03:45:09,100 iteration 5526 : loss : 0.050209, loss_ce: 0.015479
2021-12-14 03:45:10,687 iteration 5527 : loss : 0.046390, loss_ce: 0.017825
2021-12-14 03:45:12,259 iteration 5528 : loss : 0.050581, loss_ce: 0.014698
2021-12-14 03:45:13,863 iteration 5529 : loss : 0.057937, loss_ce: 0.021042
2021-12-14 03:45:15,390 iteration 5530 : loss : 0.041493, loss_ce: 0.015254
2021-12-14 03:45:16,937 iteration 5531 : loss : 0.047010, loss_ce: 0.017820
2021-12-14 03:45:18,469 iteration 5532 : loss : 0.036901, loss_ce: 0.012315
2021-12-14 03:45:20,097 iteration 5533 : loss : 0.047678, loss_ce: 0.011685
2021-12-14 03:45:21,667 iteration 5534 : loss : 0.039568, loss_ce: 0.011612
2021-12-14 03:45:23,302 iteration 5535 : loss : 0.046648, loss_ce: 0.015478
2021-12-14 03:45:24,974 iteration 5536 : loss : 0.042563, loss_ce: 0.016910
2021-12-14 03:45:26,590 iteration 5537 : loss : 0.047437, loss_ce: 0.013736
2021-12-14 03:45:28,183 iteration 5538 : loss : 0.051376, loss_ce: 0.017372
2021-12-14 03:45:29,861 iteration 5539 : loss : 0.057930, loss_ce: 0.013579
2021-12-14 03:45:31,409 iteration 5540 : loss : 0.038519, loss_ce: 0.014963
2021-12-14 03:45:32,993 iteration 5541 : loss : 0.040482, loss_ce: 0.010936
2021-12-14 03:45:34,548 iteration 5542 : loss : 0.039263, loss_ce: 0.011500
 82%|███████████████████████▋     | 326/400 [2:40:31<36:37, 29.70s/it]2021-12-14 03:45:36,193 iteration 5543 : loss : 0.046789, loss_ce: 0.014799
2021-12-14 03:45:37,780 iteration 5544 : loss : 0.045198, loss_ce: 0.017796
2021-12-14 03:45:39,332 iteration 5545 : loss : 0.050828, loss_ce: 0.017914
2021-12-14 03:45:40,858 iteration 5546 : loss : 0.046491, loss_ce: 0.014445
2021-12-14 03:45:42,451 iteration 5547 : loss : 0.045190, loss_ce: 0.013901
2021-12-14 03:45:44,078 iteration 5548 : loss : 0.063944, loss_ce: 0.020213
2021-12-14 03:45:45,594 iteration 5549 : loss : 0.043310, loss_ce: 0.014492
2021-12-14 03:45:47,146 iteration 5550 : loss : 0.041613, loss_ce: 0.012858
2021-12-14 03:45:48,722 iteration 5551 : loss : 0.045232, loss_ce: 0.015527
2021-12-14 03:45:50,239 iteration 5552 : loss : 0.042768, loss_ce: 0.013759
2021-12-14 03:45:51,825 iteration 5553 : loss : 0.051072, loss_ce: 0.018101
2021-12-14 03:45:53,450 iteration 5554 : loss : 0.041600, loss_ce: 0.012054
2021-12-14 03:45:55,081 iteration 5555 : loss : 0.061293, loss_ce: 0.016443
2021-12-14 03:45:56,591 iteration 5556 : loss : 0.045502, loss_ce: 0.015214
2021-12-14 03:45:58,233 iteration 5557 : loss : 0.056427, loss_ce: 0.014521
2021-12-14 03:45:59,829 iteration 5558 : loss : 0.042449, loss_ce: 0.012222
2021-12-14 03:46:01,327 iteration 5559 : loss : 0.051423, loss_ce: 0.018933
 82%|███████████████████████▋     | 327/400 [2:40:58<35:03, 28.82s/it]2021-12-14 03:46:03,120 iteration 5560 : loss : 0.064241, loss_ce: 0.021300
2021-12-14 03:46:04,682 iteration 5561 : loss : 0.042181, loss_ce: 0.012486
2021-12-14 03:46:06,250 iteration 5562 : loss : 0.053122, loss_ce: 0.015362
2021-12-14 03:46:07,818 iteration 5563 : loss : 0.043627, loss_ce: 0.014874
2021-12-14 03:46:09,481 iteration 5564 : loss : 0.044973, loss_ce: 0.012907
2021-12-14 03:46:11,065 iteration 5565 : loss : 0.046219, loss_ce: 0.016311
2021-12-14 03:46:12,693 iteration 5566 : loss : 0.045197, loss_ce: 0.014590
2021-12-14 03:46:14,378 iteration 5567 : loss : 0.047785, loss_ce: 0.020013
2021-12-14 03:46:15,964 iteration 5568 : loss : 0.060301, loss_ce: 0.017801
2021-12-14 03:46:17,587 iteration 5569 : loss : 0.052472, loss_ce: 0.020737
2021-12-14 03:46:19,186 iteration 5570 : loss : 0.044949, loss_ce: 0.013886
2021-12-14 03:46:20,809 iteration 5571 : loss : 0.043974, loss_ce: 0.016160
2021-12-14 03:46:22,391 iteration 5572 : loss : 0.038965, loss_ce: 0.014208
2021-12-14 03:46:23,957 iteration 5573 : loss : 0.050668, loss_ce: 0.012752
2021-12-14 03:46:25,643 iteration 5574 : loss : 0.062714, loss_ce: 0.019665
2021-12-14 03:46:27,123 iteration 5575 : loss : 0.038770, loss_ce: 0.014454
2021-12-14 03:46:28,584 iteration 5576 : loss : 0.046064, loss_ce: 0.012029
 82%|███████████████████████▊     | 328/400 [2:41:25<34:01, 28.35s/it]2021-12-14 03:46:30,192 iteration 5577 : loss : 0.052890, loss_ce: 0.017609
2021-12-14 03:46:31,737 iteration 5578 : loss : 0.045457, loss_ce: 0.011153
2021-12-14 03:46:33,306 iteration 5579 : loss : 0.042184, loss_ce: 0.011627
2021-12-14 03:46:34,935 iteration 5580 : loss : 0.053749, loss_ce: 0.021302
2021-12-14 03:46:36,501 iteration 5581 : loss : 0.040577, loss_ce: 0.012468
2021-12-14 03:46:38,129 iteration 5582 : loss : 0.040871, loss_ce: 0.011599
2021-12-14 03:46:39,693 iteration 5583 : loss : 0.052872, loss_ce: 0.013945
2021-12-14 03:46:41,361 iteration 5584 : loss : 0.046415, loss_ce: 0.018215
2021-12-14 03:46:42,919 iteration 5585 : loss : 0.044294, loss_ce: 0.015339
2021-12-14 03:46:44,493 iteration 5586 : loss : 0.060224, loss_ce: 0.022968
2021-12-14 03:46:46,071 iteration 5587 : loss : 0.059827, loss_ce: 0.023322
2021-12-14 03:46:47,721 iteration 5588 : loss : 0.048096, loss_ce: 0.013971
2021-12-14 03:46:49,354 iteration 5589 : loss : 0.052288, loss_ce: 0.021506
2021-12-14 03:46:50,951 iteration 5590 : loss : 0.051417, loss_ce: 0.019058
2021-12-14 03:46:52,545 iteration 5591 : loss : 0.043573, loss_ce: 0.016707
2021-12-14 03:46:54,122 iteration 5592 : loss : 0.040848, loss_ce: 0.011392
2021-12-14 03:46:55,696 iteration 5593 : loss : 0.043247, loss_ce: 0.020747
 82%|███████████████████████▊     | 329/400 [2:41:52<33:06, 27.98s/it]2021-12-14 03:46:57,353 iteration 5594 : loss : 0.041049, loss_ce: 0.012898
2021-12-14 03:46:58,907 iteration 5595 : loss : 0.042744, loss_ce: 0.015793
2021-12-14 03:47:00,464 iteration 5596 : loss : 0.040067, loss_ce: 0.009847
2021-12-14 03:47:02,065 iteration 5597 : loss : 0.045529, loss_ce: 0.016125
2021-12-14 03:47:03,716 iteration 5598 : loss : 0.080162, loss_ce: 0.026641
2021-12-14 03:47:05,339 iteration 5599 : loss : 0.044337, loss_ce: 0.013336
2021-12-14 03:47:06,959 iteration 5600 : loss : 0.045180, loss_ce: 0.017058
2021-12-14 03:47:08,589 iteration 5601 : loss : 0.044710, loss_ce: 0.012652
2021-12-14 03:47:10,144 iteration 5602 : loss : 0.051822, loss_ce: 0.010811
2021-12-14 03:47:11,782 iteration 5603 : loss : 0.051828, loss_ce: 0.018064
2021-12-14 03:47:13,334 iteration 5604 : loss : 0.049364, loss_ce: 0.019629
2021-12-14 03:47:14,888 iteration 5605 : loss : 0.040794, loss_ce: 0.011494
2021-12-14 03:47:16,539 iteration 5606 : loss : 0.058482, loss_ce: 0.016730
2021-12-14 03:47:18,120 iteration 5607 : loss : 0.050003, loss_ce: 0.016744
2021-12-14 03:47:19,820 iteration 5608 : loss : 0.059491, loss_ce: 0.025254
2021-12-14 03:47:21,369 iteration 5609 : loss : 0.041447, loss_ce: 0.015169
2021-12-14 03:47:21,369 Training Data Eval:
2021-12-14 03:47:29,542   Average segmentation loss on training set: 0.0341
2021-12-14 03:47:29,543 Validation Data Eval:
2021-12-14 03:47:32,335   Average segmentation loss on validation set: 0.0865
2021-12-14 03:47:38,895 Found new lowest validation loss at iteration 5609! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/TU_3seeds/REVISED_SGD_best_val_loss_seed1234.pth
2021-12-14 03:47:40,374 iteration 5610 : loss : 0.044240, loss_ce: 0.015805
 82%|███████████████████████▉     | 330/400 [2:42:37<38:29, 32.99s/it]2021-12-14 03:47:41,924 iteration 5611 : loss : 0.047288, loss_ce: 0.017834
2021-12-14 03:47:43,491 iteration 5612 : loss : 0.052388, loss_ce: 0.014599
2021-12-14 03:47:45,065 iteration 5613 : loss : 0.053129, loss_ce: 0.021255
2021-12-14 03:47:46,638 iteration 5614 : loss : 0.045745, loss_ce: 0.015046
2021-12-14 03:47:48,240 iteration 5615 : loss : 0.045398, loss_ce: 0.013653
2021-12-14 03:47:49,862 iteration 5616 : loss : 0.053360, loss_ce: 0.020594
2021-12-14 03:47:51,446 iteration 5617 : loss : 0.044532, loss_ce: 0.014742
2021-12-14 03:47:52,978 iteration 5618 : loss : 0.042701, loss_ce: 0.015923
2021-12-14 03:47:54,594 iteration 5619 : loss : 0.062843, loss_ce: 0.022791
2021-12-14 03:47:56,231 iteration 5620 : loss : 0.048608, loss_ce: 0.013232
2021-12-14 03:47:57,790 iteration 5621 : loss : 0.056392, loss_ce: 0.022394
2021-12-14 03:47:59,461 iteration 5622 : loss : 0.070833, loss_ce: 0.030189
2021-12-14 03:48:01,008 iteration 5623 : loss : 0.050529, loss_ce: 0.013096
2021-12-14 03:48:02,615 iteration 5624 : loss : 0.049079, loss_ce: 0.017271
2021-12-14 03:48:04,233 iteration 5625 : loss : 0.072353, loss_ce: 0.028650
2021-12-14 03:48:05,814 iteration 5626 : loss : 0.050287, loss_ce: 0.016631
2021-12-14 03:48:07,382 iteration 5627 : loss : 0.046974, loss_ce: 0.013693
 83%|███████████████████████▉     | 331/400 [2:43:04<35:52, 31.20s/it]2021-12-14 03:48:08,916 iteration 5628 : loss : 0.042791, loss_ce: 0.013772
2021-12-14 03:48:10,519 iteration 5629 : loss : 0.047265, loss_ce: 0.018288
2021-12-14 03:48:12,094 iteration 5630 : loss : 0.039996, loss_ce: 0.010527
2021-12-14 03:48:13,778 iteration 5631 : loss : 0.053673, loss_ce: 0.025449
2021-12-14 03:48:15,282 iteration 5632 : loss : 0.051400, loss_ce: 0.018414
2021-12-14 03:48:16,914 iteration 5633 : loss : 0.056771, loss_ce: 0.020272
2021-12-14 03:48:18,455 iteration 5634 : loss : 0.047195, loss_ce: 0.015184
2021-12-14 03:48:20,067 iteration 5635 : loss : 0.047715, loss_ce: 0.011044
2021-12-14 03:48:21,598 iteration 5636 : loss : 0.038759, loss_ce: 0.014309
2021-12-14 03:48:23,205 iteration 5637 : loss : 0.045903, loss_ce: 0.016572
2021-12-14 03:48:24,686 iteration 5638 : loss : 0.045586, loss_ce: 0.013421
2021-12-14 03:48:26,216 iteration 5639 : loss : 0.048168, loss_ce: 0.013459
2021-12-14 03:48:27,780 iteration 5640 : loss : 0.046209, loss_ce: 0.019352
2021-12-14 03:48:29,399 iteration 5641 : loss : 0.043978, loss_ce: 0.019248
2021-12-14 03:48:30,964 iteration 5642 : loss : 0.065846, loss_ce: 0.013038
2021-12-14 03:48:32,595 iteration 5643 : loss : 0.043642, loss_ce: 0.010417
2021-12-14 03:48:34,199 iteration 5644 : loss : 0.049476, loss_ce: 0.017282
 83%|████████████████████████     | 332/400 [2:43:31<33:52, 29.89s/it]2021-12-14 03:48:35,942 iteration 5645 : loss : 0.051956, loss_ce: 0.019036
2021-12-14 03:48:37,491 iteration 5646 : loss : 0.057599, loss_ce: 0.017645
2021-12-14 03:48:39,066 iteration 5647 : loss : 0.065979, loss_ce: 0.027389
2021-12-14 03:48:40,691 iteration 5648 : loss : 0.063576, loss_ce: 0.017821
2021-12-14 03:48:42,320 iteration 5649 : loss : 0.052339, loss_ce: 0.022756
2021-12-14 03:48:43,914 iteration 5650 : loss : 0.054825, loss_ce: 0.019232
2021-12-14 03:48:45,492 iteration 5651 : loss : 0.053684, loss_ce: 0.022726
2021-12-14 03:48:47,004 iteration 5652 : loss : 0.047429, loss_ce: 0.015106
2021-12-14 03:48:48,567 iteration 5653 : loss : 0.053774, loss_ce: 0.016389
2021-12-14 03:48:50,091 iteration 5654 : loss : 0.041799, loss_ce: 0.011101
2021-12-14 03:48:51,695 iteration 5655 : loss : 0.052300, loss_ce: 0.017618
2021-12-14 03:48:53,274 iteration 5656 : loss : 0.041781, loss_ce: 0.012235
2021-12-14 03:48:54,854 iteration 5657 : loss : 0.040899, loss_ce: 0.015144
2021-12-14 03:48:56,435 iteration 5658 : loss : 0.055317, loss_ce: 0.027863
2021-12-14 03:48:57,991 iteration 5659 : loss : 0.049478, loss_ce: 0.012479
2021-12-14 03:48:59,514 iteration 5660 : loss : 0.037510, loss_ce: 0.011742
2021-12-14 03:49:01,180 iteration 5661 : loss : 0.048448, loss_ce: 0.015750
 83%|████████████████████████▏    | 333/400 [2:43:58<32:23, 29.01s/it]2021-12-14 03:49:02,812 iteration 5662 : loss : 0.042539, loss_ce: 0.010193
2021-12-14 03:49:04,387 iteration 5663 : loss : 0.042511, loss_ce: 0.015055
2021-12-14 03:49:05,985 iteration 5664 : loss : 0.057087, loss_ce: 0.016326
2021-12-14 03:49:07,481 iteration 5665 : loss : 0.039441, loss_ce: 0.012925
2021-12-14 03:49:09,081 iteration 5666 : loss : 0.044629, loss_ce: 0.013449
2021-12-14 03:49:10,701 iteration 5667 : loss : 0.047989, loss_ce: 0.016090
2021-12-14 03:49:12,277 iteration 5668 : loss : 0.043678, loss_ce: 0.017140
2021-12-14 03:49:13,898 iteration 5669 : loss : 0.053539, loss_ce: 0.023383
2021-12-14 03:49:15,502 iteration 5670 : loss : 0.038989, loss_ce: 0.011474
2021-12-14 03:49:17,094 iteration 5671 : loss : 0.047542, loss_ce: 0.014913
2021-12-14 03:49:18,674 iteration 5672 : loss : 0.051554, loss_ce: 0.013182
2021-12-14 03:49:20,223 iteration 5673 : loss : 0.044351, loss_ce: 0.012916
2021-12-14 03:49:21,876 iteration 5674 : loss : 0.041713, loss_ce: 0.016391
2021-12-14 03:49:23,429 iteration 5675 : loss : 0.048205, loss_ce: 0.019943
2021-12-14 03:49:25,070 iteration 5676 : loss : 0.045920, loss_ce: 0.013976
2021-12-14 03:49:26,695 iteration 5677 : loss : 0.039300, loss_ce: 0.014562
2021-12-14 03:49:28,295 iteration 5678 : loss : 0.062724, loss_ce: 0.021031
 84%|████████████████████████▏    | 334/400 [2:44:25<31:16, 28.44s/it]2021-12-14 03:49:29,983 iteration 5679 : loss : 0.057186, loss_ce: 0.021475
2021-12-14 03:49:31,465 iteration 5680 : loss : 0.038687, loss_ce: 0.009252
2021-12-14 03:49:33,095 iteration 5681 : loss : 0.045945, loss_ce: 0.012373
2021-12-14 03:49:34,728 iteration 5682 : loss : 0.054828, loss_ce: 0.023032
2021-12-14 03:49:36,287 iteration 5683 : loss : 0.039002, loss_ce: 0.011382
2021-12-14 03:49:37,854 iteration 5684 : loss : 0.037416, loss_ce: 0.014716
2021-12-14 03:49:39,458 iteration 5685 : loss : 0.051109, loss_ce: 0.022037
2021-12-14 03:49:41,020 iteration 5686 : loss : 0.038901, loss_ce: 0.011890
2021-12-14 03:49:42,596 iteration 5687 : loss : 0.041755, loss_ce: 0.015036
2021-12-14 03:49:44,263 iteration 5688 : loss : 0.051672, loss_ce: 0.016641
2021-12-14 03:49:45,849 iteration 5689 : loss : 0.045352, loss_ce: 0.010828
2021-12-14 03:49:47,441 iteration 5690 : loss : 0.047833, loss_ce: 0.018574
2021-12-14 03:49:49,052 iteration 5691 : loss : 0.049107, loss_ce: 0.018406
2021-12-14 03:49:50,661 iteration 5692 : loss : 0.043548, loss_ce: 0.015086
2021-12-14 03:49:52,254 iteration 5693 : loss : 0.048667, loss_ce: 0.012728
2021-12-14 03:49:53,820 iteration 5694 : loss : 0.051454, loss_ce: 0.020635
2021-12-14 03:49:53,821 Training Data Eval:
2021-12-14 03:50:01,995   Average segmentation loss on training set: 0.0348
2021-12-14 03:50:01,995 Validation Data Eval:
2021-12-14 03:50:04,789   Average segmentation loss on validation set: 0.0885
2021-12-14 03:50:06,318 iteration 5695 : loss : 0.041038, loss_ce: 0.011412
 84%|████████████████████████▎    | 335/400 [2:45:03<33:55, 31.32s/it]2021-12-14 03:50:07,903 iteration 5696 : loss : 0.043870, loss_ce: 0.018904
2021-12-14 03:50:09,430 iteration 5697 : loss : 0.041183, loss_ce: 0.016754
2021-12-14 03:50:11,054 iteration 5698 : loss : 0.066864, loss_ce: 0.024794
2021-12-14 03:50:12,578 iteration 5699 : loss : 0.044327, loss_ce: 0.016777
2021-12-14 03:50:14,132 iteration 5700 : loss : 0.039922, loss_ce: 0.011940
2021-12-14 03:50:15,655 iteration 5701 : loss : 0.039574, loss_ce: 0.014516
2021-12-14 03:50:17,330 iteration 5702 : loss : 0.049695, loss_ce: 0.015247
2021-12-14 03:50:18,941 iteration 5703 : loss : 0.053910, loss_ce: 0.020473
2021-12-14 03:50:20,530 iteration 5704 : loss : 0.050573, loss_ce: 0.016094
2021-12-14 03:50:22,131 iteration 5705 : loss : 0.047896, loss_ce: 0.013410
2021-12-14 03:50:23,621 iteration 5706 : loss : 0.043280, loss_ce: 0.013074
2021-12-14 03:50:25,176 iteration 5707 : loss : 0.047206, loss_ce: 0.015065
2021-12-14 03:50:26,702 iteration 5708 : loss : 0.048625, loss_ce: 0.016332
2021-12-14 03:50:28,283 iteration 5709 : loss : 0.046478, loss_ce: 0.013292
2021-12-14 03:50:29,852 iteration 5710 : loss : 0.053140, loss_ce: 0.016065
2021-12-14 03:50:31,359 iteration 5711 : loss : 0.044845, loss_ce: 0.013978
2021-12-14 03:50:32,951 iteration 5712 : loss : 0.058883, loss_ce: 0.019982
 84%|████████████████████████▎    | 336/400 [2:45:29<31:54, 29.91s/it]2021-12-14 03:50:34,623 iteration 5713 : loss : 0.054016, loss_ce: 0.016956
2021-12-14 03:50:36,246 iteration 5714 : loss : 0.058918, loss_ce: 0.020388
2021-12-14 03:50:37,885 iteration 5715 : loss : 0.043153, loss_ce: 0.014165
2021-12-14 03:50:39,450 iteration 5716 : loss : 0.042226, loss_ce: 0.016292
2021-12-14 03:50:41,120 iteration 5717 : loss : 0.045849, loss_ce: 0.015209
2021-12-14 03:50:42,653 iteration 5718 : loss : 0.039293, loss_ce: 0.011718
2021-12-14 03:50:44,208 iteration 5719 : loss : 0.047386, loss_ce: 0.016052
2021-12-14 03:50:45,830 iteration 5720 : loss : 0.047034, loss_ce: 0.017083
2021-12-14 03:50:47,422 iteration 5721 : loss : 0.064568, loss_ce: 0.028971
2021-12-14 03:50:49,020 iteration 5722 : loss : 0.047375, loss_ce: 0.016857
2021-12-14 03:50:50,608 iteration 5723 : loss : 0.045299, loss_ce: 0.013424
2021-12-14 03:50:52,227 iteration 5724 : loss : 0.047411, loss_ce: 0.013475
2021-12-14 03:50:53,814 iteration 5725 : loss : 0.040089, loss_ce: 0.012772
2021-12-14 03:50:55,346 iteration 5726 : loss : 0.048256, loss_ce: 0.010851
2021-12-14 03:50:56,935 iteration 5727 : loss : 0.048939, loss_ce: 0.014377
2021-12-14 03:50:58,490 iteration 5728 : loss : 0.054562, loss_ce: 0.013856
2021-12-14 03:51:00,132 iteration 5729 : loss : 0.053033, loss_ce: 0.019397
 84%|████████████████████████▍    | 337/400 [2:45:57<30:32, 29.09s/it]2021-12-14 03:51:01,705 iteration 5730 : loss : 0.040807, loss_ce: 0.015593
2021-12-14 03:51:03,352 iteration 5731 : loss : 0.046872, loss_ce: 0.019148
2021-12-14 03:51:04,888 iteration 5732 : loss : 0.042237, loss_ce: 0.013923
2021-12-14 03:51:06,529 iteration 5733 : loss : 0.065439, loss_ce: 0.016209
2021-12-14 03:51:08,162 iteration 5734 : loss : 0.051710, loss_ce: 0.017213
2021-12-14 03:51:09,714 iteration 5735 : loss : 0.056212, loss_ce: 0.015308
2021-12-14 03:51:11,262 iteration 5736 : loss : 0.051741, loss_ce: 0.020013
2021-12-14 03:51:12,915 iteration 5737 : loss : 0.058987, loss_ce: 0.019140
2021-12-14 03:51:14,459 iteration 5738 : loss : 0.051106, loss_ce: 0.014502
2021-12-14 03:51:15,997 iteration 5739 : loss : 0.045074, loss_ce: 0.015474
2021-12-14 03:51:17,564 iteration 5740 : loss : 0.044868, loss_ce: 0.013695
2021-12-14 03:51:19,140 iteration 5741 : loss : 0.044197, loss_ce: 0.018351
2021-12-14 03:51:20,729 iteration 5742 : loss : 0.044758, loss_ce: 0.010504
2021-12-14 03:51:22,331 iteration 5743 : loss : 0.042975, loss_ce: 0.015432
2021-12-14 03:51:23,964 iteration 5744 : loss : 0.056592, loss_ce: 0.022322
2021-12-14 03:51:25,605 iteration 5745 : loss : 0.048834, loss_ce: 0.019103
2021-12-14 03:51:27,148 iteration 5746 : loss : 0.048435, loss_ce: 0.011932
 84%|████████████████████████▌    | 338/400 [2:46:24<29:25, 28.47s/it]2021-12-14 03:51:28,795 iteration 5747 : loss : 0.050121, loss_ce: 0.017595
2021-12-14 03:51:30,402 iteration 5748 : loss : 0.050734, loss_ce: 0.016451
2021-12-14 03:51:32,020 iteration 5749 : loss : 0.050353, loss_ce: 0.017189
2021-12-14 03:51:33,596 iteration 5750 : loss : 0.046190, loss_ce: 0.013711
2021-12-14 03:51:35,115 iteration 5751 : loss : 0.049495, loss_ce: 0.014778
2021-12-14 03:51:36,676 iteration 5752 : loss : 0.043940, loss_ce: 0.012782
2021-12-14 03:51:38,300 iteration 5753 : loss : 0.043519, loss_ce: 0.013184
2021-12-14 03:51:39,930 iteration 5754 : loss : 0.046244, loss_ce: 0.013331
2021-12-14 03:51:41,507 iteration 5755 : loss : 0.041305, loss_ce: 0.012288
2021-12-14 03:51:43,057 iteration 5756 : loss : 0.047694, loss_ce: 0.014759
2021-12-14 03:51:44,531 iteration 5757 : loss : 0.038086, loss_ce: 0.013465
2021-12-14 03:51:46,158 iteration 5758 : loss : 0.052334, loss_ce: 0.017860
2021-12-14 03:51:47,784 iteration 5759 : loss : 0.048900, loss_ce: 0.020382
2021-12-14 03:51:49,450 iteration 5760 : loss : 0.043187, loss_ce: 0.018505
2021-12-14 03:51:51,132 iteration 5761 : loss : 0.053578, loss_ce: 0.019877
2021-12-14 03:51:52,665 iteration 5762 : loss : 0.040533, loss_ce: 0.015914
2021-12-14 03:51:54,289 iteration 5763 : loss : 0.041489, loss_ce: 0.014103
 85%|████████████████████████▌    | 339/400 [2:46:51<28:32, 28.07s/it]2021-12-14 03:51:55,931 iteration 5764 : loss : 0.051671, loss_ce: 0.016720
2021-12-14 03:51:57,572 iteration 5765 : loss : 0.056357, loss_ce: 0.013176
2021-12-14 03:51:59,177 iteration 5766 : loss : 0.058047, loss_ce: 0.028697
2021-12-14 03:52:00,757 iteration 5767 : loss : 0.045388, loss_ce: 0.020639
2021-12-14 03:52:02,446 iteration 5768 : loss : 0.053156, loss_ce: 0.019042
2021-12-14 03:52:04,087 iteration 5769 : loss : 0.044426, loss_ce: 0.011865
2021-12-14 03:52:05,637 iteration 5770 : loss : 0.039774, loss_ce: 0.012431
2021-12-14 03:52:07,241 iteration 5771 : loss : 0.043270, loss_ce: 0.014247
2021-12-14 03:52:08,815 iteration 5772 : loss : 0.042954, loss_ce: 0.013280
2021-12-14 03:52:10,328 iteration 5773 : loss : 0.043209, loss_ce: 0.012271
2021-12-14 03:52:11,827 iteration 5774 : loss : 0.050472, loss_ce: 0.012483
2021-12-14 03:52:13,423 iteration 5775 : loss : 0.048650, loss_ce: 0.017867
2021-12-14 03:52:15,078 iteration 5776 : loss : 0.054319, loss_ce: 0.020560
2021-12-14 03:52:16,577 iteration 5777 : loss : 0.043494, loss_ce: 0.016141
2021-12-14 03:52:18,127 iteration 5778 : loss : 0.046092, loss_ce: 0.012357
2021-12-14 03:52:19,693 iteration 5779 : loss : 0.045647, loss_ce: 0.014059
2021-12-14 03:52:19,693 Training Data Eval:
2021-12-14 03:52:27,871   Average segmentation loss on training set: 0.0340
2021-12-14 03:52:27,871 Validation Data Eval:
2021-12-14 03:52:30,665   Average segmentation loss on validation set: 0.0872
2021-12-14 03:52:32,232 iteration 5780 : loss : 0.042830, loss_ce: 0.013220
 85%|████████████████████████▋    | 340/400 [2:47:29<31:01, 31.03s/it]2021-12-14 03:52:33,831 iteration 5781 : loss : 0.054189, loss_ce: 0.012907
2021-12-14 03:52:35,466 iteration 5782 : loss : 0.052017, loss_ce: 0.016703
2021-12-14 03:52:37,035 iteration 5783 : loss : 0.046105, loss_ce: 0.014967
2021-12-14 03:52:38,657 iteration 5784 : loss : 0.048591, loss_ce: 0.023583
2021-12-14 03:52:40,197 iteration 5785 : loss : 0.039507, loss_ce: 0.012530
2021-12-14 03:52:41,741 iteration 5786 : loss : 0.042854, loss_ce: 0.015975
2021-12-14 03:52:43,282 iteration 5787 : loss : 0.041420, loss_ce: 0.014025
2021-12-14 03:52:44,987 iteration 5788 : loss : 0.060588, loss_ce: 0.018544
2021-12-14 03:52:46,589 iteration 5789 : loss : 0.043210, loss_ce: 0.012788
2021-12-14 03:52:48,180 iteration 5790 : loss : 0.041169, loss_ce: 0.010192
2021-12-14 03:52:49,717 iteration 5791 : loss : 0.043693, loss_ce: 0.014583
2021-12-14 03:52:51,331 iteration 5792 : loss : 0.044747, loss_ce: 0.015508
2021-12-14 03:52:53,021 iteration 5793 : loss : 0.053225, loss_ce: 0.016654
2021-12-14 03:52:54,621 iteration 5794 : loss : 0.039884, loss_ce: 0.013673
2021-12-14 03:52:56,198 iteration 5795 : loss : 0.041508, loss_ce: 0.013762
2021-12-14 03:52:57,733 iteration 5796 : loss : 0.042085, loss_ce: 0.012040
2021-12-14 03:52:59,334 iteration 5797 : loss : 0.042189, loss_ce: 0.013588
 85%|████████████████████████▋    | 341/400 [2:47:56<29:21, 29.85s/it]2021-12-14 03:53:00,991 iteration 5798 : loss : 0.050516, loss_ce: 0.017582
2021-12-14 03:53:02,582 iteration 5799 : loss : 0.052856, loss_ce: 0.019728
2021-12-14 03:53:04,154 iteration 5800 : loss : 0.040902, loss_ce: 0.015057
2021-12-14 03:53:05,726 iteration 5801 : loss : 0.050484, loss_ce: 0.016275
2021-12-14 03:53:07,242 iteration 5802 : loss : 0.039370, loss_ce: 0.012792
2021-12-14 03:53:08,787 iteration 5803 : loss : 0.043237, loss_ce: 0.017207
2021-12-14 03:53:10,362 iteration 5804 : loss : 0.043640, loss_ce: 0.013087
2021-12-14 03:53:12,031 iteration 5805 : loss : 0.042171, loss_ce: 0.012737
2021-12-14 03:53:13,599 iteration 5806 : loss : 0.050091, loss_ce: 0.013132
2021-12-14 03:53:15,260 iteration 5807 : loss : 0.058885, loss_ce: 0.019739
2021-12-14 03:53:16,867 iteration 5808 : loss : 0.053353, loss_ce: 0.022845
2021-12-14 03:53:18,392 iteration 5809 : loss : 0.040237, loss_ce: 0.010731
2021-12-14 03:53:19,935 iteration 5810 : loss : 0.051296, loss_ce: 0.015070
2021-12-14 03:53:21,451 iteration 5811 : loss : 0.035739, loss_ce: 0.008970
2021-12-14 03:53:23,031 iteration 5812 : loss : 0.052102, loss_ce: 0.015677
2021-12-14 03:53:24,554 iteration 5813 : loss : 0.042886, loss_ce: 0.016101
2021-12-14 03:53:26,145 iteration 5814 : loss : 0.045549, loss_ce: 0.017089
 86%|████████████████████████▊    | 342/400 [2:48:23<27:58, 28.94s/it]2021-12-14 03:53:27,699 iteration 5815 : loss : 0.035499, loss_ce: 0.010414
2021-12-14 03:53:29,257 iteration 5816 : loss : 0.037846, loss_ce: 0.015321
2021-12-14 03:53:30,804 iteration 5817 : loss : 0.038551, loss_ce: 0.012977
2021-12-14 03:53:32,291 iteration 5818 : loss : 0.048305, loss_ce: 0.017416
2021-12-14 03:53:33,924 iteration 5819 : loss : 0.051271, loss_ce: 0.015216
2021-12-14 03:53:35,573 iteration 5820 : loss : 0.051356, loss_ce: 0.020612
2021-12-14 03:53:37,084 iteration 5821 : loss : 0.040637, loss_ce: 0.011640
2021-12-14 03:53:38,622 iteration 5822 : loss : 0.035913, loss_ce: 0.013615
2021-12-14 03:53:40,296 iteration 5823 : loss : 0.045017, loss_ce: 0.015850
2021-12-14 03:53:41,872 iteration 5824 : loss : 0.048090, loss_ce: 0.014222
2021-12-14 03:53:43,490 iteration 5825 : loss : 0.053957, loss_ce: 0.017655
2021-12-14 03:53:45,111 iteration 5826 : loss : 0.045592, loss_ce: 0.011240
2021-12-14 03:53:46,691 iteration 5827 : loss : 0.047441, loss_ce: 0.013309
2021-12-14 03:53:48,376 iteration 5828 : loss : 0.046143, loss_ce: 0.014536
2021-12-14 03:53:49,958 iteration 5829 : loss : 0.043240, loss_ce: 0.015340
2021-12-14 03:53:51,505 iteration 5830 : loss : 0.047090, loss_ce: 0.016426
2021-12-14 03:53:53,065 iteration 5831 : loss : 0.043820, loss_ce: 0.014118
 86%|████████████████████████▊    | 343/400 [2:48:50<26:55, 28.34s/it]2021-12-14 03:53:54,695 iteration 5832 : loss : 0.043014, loss_ce: 0.012519
2021-12-14 03:53:56,308 iteration 5833 : loss : 0.043565, loss_ce: 0.015756
2021-12-14 03:53:57,828 iteration 5834 : loss : 0.041578, loss_ce: 0.013065
2021-12-14 03:53:59,356 iteration 5835 : loss : 0.046788, loss_ce: 0.012159
2021-12-14 03:54:00,980 iteration 5836 : loss : 0.064523, loss_ce: 0.033272
2021-12-14 03:54:02,557 iteration 5837 : loss : 0.048267, loss_ce: 0.010228
2021-12-14 03:54:04,044 iteration 5838 : loss : 0.039342, loss_ce: 0.010569
2021-12-14 03:54:05,607 iteration 5839 : loss : 0.042609, loss_ce: 0.012428
2021-12-14 03:54:07,222 iteration 5840 : loss : 0.050965, loss_ce: 0.017117
2021-12-14 03:54:08,769 iteration 5841 : loss : 0.044569, loss_ce: 0.015484
2021-12-14 03:54:10,318 iteration 5842 : loss : 0.037973, loss_ce: 0.012802
2021-12-14 03:54:11,862 iteration 5843 : loss : 0.044566, loss_ce: 0.014945
2021-12-14 03:54:13,569 iteration 5844 : loss : 0.052856, loss_ce: 0.014449
2021-12-14 03:54:15,143 iteration 5845 : loss : 0.050898, loss_ce: 0.017284
2021-12-14 03:54:16,733 iteration 5846 : loss : 0.049627, loss_ce: 0.017651
2021-12-14 03:54:18,326 iteration 5847 : loss : 0.050653, loss_ce: 0.018224
2021-12-14 03:54:19,905 iteration 5848 : loss : 0.049118, loss_ce: 0.015660
 86%|████████████████████████▉    | 344/400 [2:49:16<26:01, 27.89s/it]2021-12-14 03:54:21,535 iteration 5849 : loss : 0.055313, loss_ce: 0.018984
2021-12-14 03:54:23,058 iteration 5850 : loss : 0.039754, loss_ce: 0.013342
2021-12-14 03:54:24,639 iteration 5851 : loss : 0.044637, loss_ce: 0.017334
2021-12-14 03:54:26,196 iteration 5852 : loss : 0.040828, loss_ce: 0.013991
2021-12-14 03:54:27,697 iteration 5853 : loss : 0.038724, loss_ce: 0.011289
2021-12-14 03:54:29,244 iteration 5854 : loss : 0.057132, loss_ce: 0.018954
2021-12-14 03:54:30,891 iteration 5855 : loss : 0.045003, loss_ce: 0.017103
2021-12-14 03:54:32,476 iteration 5856 : loss : 0.044233, loss_ce: 0.016437
2021-12-14 03:54:34,070 iteration 5857 : loss : 0.042323, loss_ce: 0.012115
2021-12-14 03:54:35,574 iteration 5858 : loss : 0.037722, loss_ce: 0.012392
2021-12-14 03:54:37,198 iteration 5859 : loss : 0.051136, loss_ce: 0.018723
2021-12-14 03:54:38,816 iteration 5860 : loss : 0.042532, loss_ce: 0.010215
2021-12-14 03:54:40,367 iteration 5861 : loss : 0.051642, loss_ce: 0.013905
2021-12-14 03:54:41,963 iteration 5862 : loss : 0.042557, loss_ce: 0.017128
2021-12-14 03:54:43,450 iteration 5863 : loss : 0.039403, loss_ce: 0.012139
2021-12-14 03:54:45,024 iteration 5864 : loss : 0.052813, loss_ce: 0.015332
2021-12-14 03:54:45,024 Training Data Eval:
2021-12-14 03:54:53,220   Average segmentation loss on training set: 0.0336
2021-12-14 03:54:53,221 Validation Data Eval:
2021-12-14 03:54:56,021   Average segmentation loss on validation set: 0.0869
2021-12-14 03:54:57,534 iteration 5865 : loss : 0.051730, loss_ce: 0.013191
 86%|█████████████████████████    | 345/400 [2:49:54<28:14, 30.81s/it]2021-12-14 03:54:59,224 iteration 5866 : loss : 0.044044, loss_ce: 0.016709
2021-12-14 03:55:00,858 iteration 5867 : loss : 0.049065, loss_ce: 0.014916
2021-12-14 03:55:02,483 iteration 5868 : loss : 0.057269, loss_ce: 0.018422
2021-12-14 03:55:03,986 iteration 5869 : loss : 0.047039, loss_ce: 0.015087
2021-12-14 03:55:05,644 iteration 5870 : loss : 0.070976, loss_ce: 0.023755
2021-12-14 03:55:07,247 iteration 5871 : loss : 0.043716, loss_ce: 0.012205
2021-12-14 03:55:08,860 iteration 5872 : loss : 0.060746, loss_ce: 0.019171
2021-12-14 03:55:10,558 iteration 5873 : loss : 0.057673, loss_ce: 0.019018
2021-12-14 03:55:12,097 iteration 5874 : loss : 0.044264, loss_ce: 0.014008
2021-12-14 03:55:13,654 iteration 5875 : loss : 0.044275, loss_ce: 0.018666
2021-12-14 03:55:15,239 iteration 5876 : loss : 0.047683, loss_ce: 0.015741
2021-12-14 03:55:16,826 iteration 5877 : loss : 0.053951, loss_ce: 0.015954
2021-12-14 03:55:18,434 iteration 5878 : loss : 0.052240, loss_ce: 0.020214
2021-12-14 03:55:19,979 iteration 5879 : loss : 0.042651, loss_ce: 0.016572
2021-12-14 03:55:21,659 iteration 5880 : loss : 0.053651, loss_ce: 0.014744
2021-12-14 03:55:23,180 iteration 5881 : loss : 0.038152, loss_ce: 0.012090
2021-12-14 03:55:24,736 iteration 5882 : loss : 0.042090, loss_ce: 0.015771
 86%|█████████████████████████    | 346/400 [2:50:21<26:45, 29.73s/it]2021-12-14 03:55:26,341 iteration 5883 : loss : 0.039704, loss_ce: 0.011358
2021-12-14 03:55:27,888 iteration 5884 : loss : 0.048819, loss_ce: 0.017252
2021-12-14 03:55:29,584 iteration 5885 : loss : 0.071875, loss_ce: 0.024083
2021-12-14 03:55:31,105 iteration 5886 : loss : 0.043257, loss_ce: 0.011663
2021-12-14 03:55:32,652 iteration 5887 : loss : 0.047025, loss_ce: 0.017111
2021-12-14 03:55:34,315 iteration 5888 : loss : 0.055488, loss_ce: 0.016488
2021-12-14 03:55:35,981 iteration 5889 : loss : 0.046384, loss_ce: 0.015428
2021-12-14 03:55:37,585 iteration 5890 : loss : 0.036969, loss_ce: 0.011749
2021-12-14 03:55:39,228 iteration 5891 : loss : 0.049266, loss_ce: 0.014743
2021-12-14 03:55:40,908 iteration 5892 : loss : 0.051727, loss_ce: 0.017503
2021-12-14 03:55:42,459 iteration 5893 : loss : 0.037247, loss_ce: 0.011069
2021-12-14 03:55:44,116 iteration 5894 : loss : 0.054574, loss_ce: 0.018668
2021-12-14 03:55:45,729 iteration 5895 : loss : 0.061551, loss_ce: 0.017755
2021-12-14 03:55:47,306 iteration 5896 : loss : 0.045206, loss_ce: 0.018191
2021-12-14 03:55:48,960 iteration 5897 : loss : 0.069924, loss_ce: 0.031370
2021-12-14 03:55:50,591 iteration 5898 : loss : 0.041949, loss_ce: 0.012978
2021-12-14 03:55:52,144 iteration 5899 : loss : 0.044097, loss_ce: 0.014671
 87%|█████████████████████████▏   | 347/400 [2:50:49<25:38, 29.03s/it]2021-12-14 03:55:53,796 iteration 5900 : loss : 0.039725, loss_ce: 0.011897
2021-12-14 03:55:55,497 iteration 5901 : loss : 0.044915, loss_ce: 0.013034
2021-12-14 03:55:57,079 iteration 5902 : loss : 0.048010, loss_ce: 0.016429
2021-12-14 03:55:58,726 iteration 5903 : loss : 0.055716, loss_ce: 0.020507
2021-12-14 03:56:00,298 iteration 5904 : loss : 0.046929, loss_ce: 0.015454
2021-12-14 03:56:01,931 iteration 5905 : loss : 0.063389, loss_ce: 0.014600
2021-12-14 03:56:03,470 iteration 5906 : loss : 0.041045, loss_ce: 0.013915
2021-12-14 03:56:05,106 iteration 5907 : loss : 0.036902, loss_ce: 0.010602
2021-12-14 03:56:06,702 iteration 5908 : loss : 0.044427, loss_ce: 0.011248
2021-12-14 03:56:08,202 iteration 5909 : loss : 0.049347, loss_ce: 0.012462
2021-12-14 03:56:09,794 iteration 5910 : loss : 0.050236, loss_ce: 0.015626
2021-12-14 03:56:11,424 iteration 5911 : loss : 0.053293, loss_ce: 0.018226
2021-12-14 03:56:12,950 iteration 5912 : loss : 0.043746, loss_ce: 0.013369
2021-12-14 03:56:14,511 iteration 5913 : loss : 0.046282, loss_ce: 0.019243
2021-12-14 03:56:16,102 iteration 5914 : loss : 0.052672, loss_ce: 0.016626
2021-12-14 03:56:17,605 iteration 5915 : loss : 0.046302, loss_ce: 0.015989
2021-12-14 03:56:19,230 iteration 5916 : loss : 0.046961, loss_ce: 0.016504
 87%|█████████████████████████▏   | 348/400 [2:51:16<24:39, 28.44s/it]2021-12-14 03:56:20,822 iteration 5917 : loss : 0.041709, loss_ce: 0.011411
2021-12-14 03:56:22,339 iteration 5918 : loss : 0.042366, loss_ce: 0.014303
2021-12-14 03:56:23,950 iteration 5919 : loss : 0.048554, loss_ce: 0.019549
2021-12-14 03:56:25,578 iteration 5920 : loss : 0.056204, loss_ce: 0.024730
2021-12-14 03:56:27,306 iteration 5921 : loss : 0.071374, loss_ce: 0.022390
2021-12-14 03:56:28,878 iteration 5922 : loss : 0.055443, loss_ce: 0.015412
2021-12-14 03:56:30,481 iteration 5923 : loss : 0.041254, loss_ce: 0.012510
2021-12-14 03:56:32,173 iteration 5924 : loss : 0.053207, loss_ce: 0.011977
2021-12-14 03:56:33,767 iteration 5925 : loss : 0.040720, loss_ce: 0.012307
2021-12-14 03:56:35,346 iteration 5926 : loss : 0.047503, loss_ce: 0.015235
2021-12-14 03:56:36,946 iteration 5927 : loss : 0.046974, loss_ce: 0.016379
2021-12-14 03:56:38,468 iteration 5928 : loss : 0.040796, loss_ce: 0.009776
2021-12-14 03:56:39,987 iteration 5929 : loss : 0.045097, loss_ce: 0.018855
2021-12-14 03:56:41,505 iteration 5930 : loss : 0.045994, loss_ce: 0.016356
2021-12-14 03:56:43,096 iteration 5931 : loss : 0.063866, loss_ce: 0.013525
2021-12-14 03:56:44,722 iteration 5932 : loss : 0.043047, loss_ce: 0.013055
2021-12-14 03:56:46,288 iteration 5933 : loss : 0.044272, loss_ce: 0.014400
 87%|█████████████████████████▎   | 349/400 [2:51:43<23:49, 28.03s/it]2021-12-14 03:56:47,863 iteration 5934 : loss : 0.043280, loss_ce: 0.011850
2021-12-14 03:56:49,580 iteration 5935 : loss : 0.048452, loss_ce: 0.015123
2021-12-14 03:56:51,173 iteration 5936 : loss : 0.039925, loss_ce: 0.014219
2021-12-14 03:56:52,728 iteration 5937 : loss : 0.046374, loss_ce: 0.013474
2021-12-14 03:56:54,233 iteration 5938 : loss : 0.036487, loss_ce: 0.011968
2021-12-14 03:56:55,850 iteration 5939 : loss : 0.047182, loss_ce: 0.017718
2021-12-14 03:56:57,377 iteration 5940 : loss : 0.039789, loss_ce: 0.013921
2021-12-14 03:56:58,922 iteration 5941 : loss : 0.046868, loss_ce: 0.016636
2021-12-14 03:57:00,473 iteration 5942 : loss : 0.043677, loss_ce: 0.016819
2021-12-14 03:57:02,064 iteration 5943 : loss : 0.053676, loss_ce: 0.013951
2021-12-14 03:57:03,651 iteration 5944 : loss : 0.047019, loss_ce: 0.018738
2021-12-14 03:57:05,206 iteration 5945 : loss : 0.045073, loss_ce: 0.010056
2021-12-14 03:57:06,877 iteration 5946 : loss : 0.058920, loss_ce: 0.019998
2021-12-14 03:57:08,487 iteration 5947 : loss : 0.048537, loss_ce: 0.016108
2021-12-14 03:57:10,042 iteration 5948 : loss : 0.051402, loss_ce: 0.016699
2021-12-14 03:57:11,690 iteration 5949 : loss : 0.047079, loss_ce: 0.013585
2021-12-14 03:57:11,690 Training Data Eval:
2021-12-14 03:57:19,876   Average segmentation loss on training set: 0.0337
2021-12-14 03:57:19,877 Validation Data Eval:
2021-12-14 03:57:22,680   Average segmentation loss on validation set: 0.0894
2021-12-14 03:57:24,277 iteration 5950 : loss : 0.043148, loss_ce: 0.012145
 88%|█████████████████████████▍   | 350/400 [2:52:21<25:51, 31.02s/it]2021-12-14 03:57:25,856 iteration 5951 : loss : 0.043028, loss_ce: 0.012355
2021-12-14 03:57:27,439 iteration 5952 : loss : 0.046197, loss_ce: 0.013724
2021-12-14 03:57:29,020 iteration 5953 : loss : 0.053814, loss_ce: 0.020181
2021-12-14 03:57:30,565 iteration 5954 : loss : 0.044758, loss_ce: 0.014765
2021-12-14 03:57:32,140 iteration 5955 : loss : 0.039581, loss_ce: 0.011593
2021-12-14 03:57:33,741 iteration 5956 : loss : 0.046747, loss_ce: 0.021773
2021-12-14 03:57:35,330 iteration 5957 : loss : 0.042598, loss_ce: 0.015658
2021-12-14 03:57:36,872 iteration 5958 : loss : 0.038966, loss_ce: 0.013155
2021-12-14 03:57:38,439 iteration 5959 : loss : 0.045099, loss_ce: 0.015744
2021-12-14 03:57:39,969 iteration 5960 : loss : 0.044895, loss_ce: 0.013285
2021-12-14 03:57:41,492 iteration 5961 : loss : 0.053170, loss_ce: 0.012743
2021-12-14 03:57:43,056 iteration 5962 : loss : 0.058078, loss_ce: 0.014422
2021-12-14 03:57:44,662 iteration 5963 : loss : 0.043581, loss_ce: 0.014991
2021-12-14 03:57:46,210 iteration 5964 : loss : 0.041332, loss_ce: 0.015662
2021-12-14 03:57:47,723 iteration 5965 : loss : 0.041097, loss_ce: 0.015921
2021-12-14 03:57:49,345 iteration 5966 : loss : 0.061482, loss_ce: 0.014837
2021-12-14 03:57:50,935 iteration 5967 : loss : 0.041237, loss_ce: 0.014397
 88%|█████████████████████████▍   | 351/400 [2:52:47<24:15, 29.71s/it]2021-12-14 03:57:52,627 iteration 5968 : loss : 0.046600, loss_ce: 0.015279
2021-12-14 03:57:54,182 iteration 5969 : loss : 0.052090, loss_ce: 0.019654
2021-12-14 03:57:55,797 iteration 5970 : loss : 0.044894, loss_ce: 0.016510
2021-12-14 03:57:57,307 iteration 5971 : loss : 0.039620, loss_ce: 0.011500
2021-12-14 03:57:58,795 iteration 5972 : loss : 0.039177, loss_ce: 0.011191
2021-12-14 03:58:00,373 iteration 5973 : loss : 0.049618, loss_ce: 0.020203
2021-12-14 03:58:02,048 iteration 5974 : loss : 0.057957, loss_ce: 0.022618
2021-12-14 03:58:03,580 iteration 5975 : loss : 0.046790, loss_ce: 0.015222
2021-12-14 03:58:05,134 iteration 5976 : loss : 0.044891, loss_ce: 0.013499
2021-12-14 03:58:06,662 iteration 5977 : loss : 0.054618, loss_ce: 0.015338
2021-12-14 03:58:08,182 iteration 5978 : loss : 0.044620, loss_ce: 0.017586
2021-12-14 03:58:09,751 iteration 5979 : loss : 0.041686, loss_ce: 0.014308
2021-12-14 03:58:11,372 iteration 5980 : loss : 0.039770, loss_ce: 0.011663
2021-12-14 03:58:12,916 iteration 5981 : loss : 0.053670, loss_ce: 0.020043
2021-12-14 03:58:14,492 iteration 5982 : loss : 0.045683, loss_ce: 0.015974
2021-12-14 03:58:16,132 iteration 5983 : loss : 0.053883, loss_ce: 0.018189
2021-12-14 03:58:17,680 iteration 5984 : loss : 0.051252, loss_ce: 0.016987
 88%|█████████████████████████▌   | 352/400 [2:53:14<23:03, 28.82s/it]2021-12-14 03:58:19,299 iteration 5985 : loss : 0.040020, loss_ce: 0.010421
2021-12-14 03:58:20,789 iteration 5986 : loss : 0.050960, loss_ce: 0.014872
2021-12-14 03:58:22,391 iteration 5987 : loss : 0.045919, loss_ce: 0.016442
2021-12-14 03:58:24,017 iteration 5988 : loss : 0.067507, loss_ce: 0.026008
2021-12-14 03:58:25,606 iteration 5989 : loss : 0.042614, loss_ce: 0.014449
2021-12-14 03:58:27,157 iteration 5990 : loss : 0.046516, loss_ce: 0.016387
2021-12-14 03:58:28,749 iteration 5991 : loss : 0.042746, loss_ce: 0.011818
2021-12-14 03:58:30,334 iteration 5992 : loss : 0.051342, loss_ce: 0.017916
2021-12-14 03:58:31,900 iteration 5993 : loss : 0.040523, loss_ce: 0.014459
2021-12-14 03:58:33,519 iteration 5994 : loss : 0.059376, loss_ce: 0.022322
2021-12-14 03:58:35,087 iteration 5995 : loss : 0.042664, loss_ce: 0.011020
2021-12-14 03:58:36,617 iteration 5996 : loss : 0.042264, loss_ce: 0.012372
2021-12-14 03:58:38,215 iteration 5997 : loss : 0.056931, loss_ce: 0.018025
2021-12-14 03:58:39,872 iteration 5998 : loss : 0.043521, loss_ce: 0.013965
2021-12-14 03:58:41,557 iteration 5999 : loss : 0.053475, loss_ce: 0.014928
2021-12-14 03:58:43,151 iteration 6000 : loss : 0.063778, loss_ce: 0.028345
2021-12-14 03:58:44,652 iteration 6001 : loss : 0.048956, loss_ce: 0.019367
 88%|█████████████████████████▌   | 353/400 [2:53:41<22:08, 28.27s/it]2021-12-14 03:58:46,283 iteration 6002 : loss : 0.045942, loss_ce: 0.015301
2021-12-14 03:58:47,825 iteration 6003 : loss : 0.049666, loss_ce: 0.016498
2021-12-14 03:58:49,450 iteration 6004 : loss : 0.051742, loss_ce: 0.020082
2021-12-14 03:58:51,053 iteration 6005 : loss : 0.048801, loss_ce: 0.016621
2021-12-14 03:58:52,740 iteration 6006 : loss : 0.042343, loss_ce: 0.014371
2021-12-14 03:58:54,348 iteration 6007 : loss : 0.038869, loss_ce: 0.013819
2021-12-14 03:58:55,942 iteration 6008 : loss : 0.046025, loss_ce: 0.013758
2021-12-14 03:58:57,443 iteration 6009 : loss : 0.042856, loss_ce: 0.017562
2021-12-14 03:58:58,969 iteration 6010 : loss : 0.040509, loss_ce: 0.014592
2021-12-14 03:59:00,586 iteration 6011 : loss : 0.047768, loss_ce: 0.012229
2021-12-14 03:59:02,232 iteration 6012 : loss : 0.049322, loss_ce: 0.012219
2021-12-14 03:59:03,846 iteration 6013 : loss : 0.045073, loss_ce: 0.012408
2021-12-14 03:59:05,454 iteration 6014 : loss : 0.047792, loss_ce: 0.012362
2021-12-14 03:59:06,999 iteration 6015 : loss : 0.048902, loss_ce: 0.017584
2021-12-14 03:59:08,573 iteration 6016 : loss : 0.047661, loss_ce: 0.016743
2021-12-14 03:59:10,145 iteration 6017 : loss : 0.041893, loss_ce: 0.015598
2021-12-14 03:59:11,745 iteration 6018 : loss : 0.059123, loss_ce: 0.019571
 88%|█████████████████████████▋   | 354/400 [2:54:08<21:24, 27.91s/it]2021-12-14 03:59:13,383 iteration 6019 : loss : 0.048216, loss_ce: 0.020901
2021-12-14 03:59:14,949 iteration 6020 : loss : 0.042362, loss_ce: 0.016904
2021-12-14 03:59:16,541 iteration 6021 : loss : 0.067068, loss_ce: 0.013897
2021-12-14 03:59:18,064 iteration 6022 : loss : 0.041182, loss_ce: 0.014328
2021-12-14 03:59:19,694 iteration 6023 : loss : 0.042558, loss_ce: 0.015357
2021-12-14 03:59:21,252 iteration 6024 : loss : 0.044905, loss_ce: 0.013012
2021-12-14 03:59:22,796 iteration 6025 : loss : 0.053227, loss_ce: 0.018476
2021-12-14 03:59:24,394 iteration 6026 : loss : 0.049627, loss_ce: 0.016407
2021-12-14 03:59:25,985 iteration 6027 : loss : 0.054399, loss_ce: 0.018901
2021-12-14 03:59:27,601 iteration 6028 : loss : 0.044056, loss_ce: 0.013561
2021-12-14 03:59:29,162 iteration 6029 : loss : 0.052250, loss_ce: 0.015521
2021-12-14 03:59:30,671 iteration 6030 : loss : 0.040951, loss_ce: 0.016216
2021-12-14 03:59:32,270 iteration 6031 : loss : 0.041189, loss_ce: 0.016070
2021-12-14 03:59:33,800 iteration 6032 : loss : 0.048019, loss_ce: 0.014121
2021-12-14 03:59:35,423 iteration 6033 : loss : 0.045598, loss_ce: 0.014043
2021-12-14 03:59:37,002 iteration 6034 : loss : 0.059984, loss_ce: 0.020182
2021-12-14 03:59:37,002 Training Data Eval:
2021-12-14 03:59:45,178   Average segmentation loss on training set: 0.0331
2021-12-14 03:59:45,178 Validation Data Eval:
2021-12-14 03:59:47,964   Average segmentation loss on validation set: 0.0859
2021-12-14 03:59:54,166 Found new lowest validation loss at iteration 6034! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/TU_3seeds/REVISED_SGD_best_val_loss_seed1234.pth
2021-12-14 03:59:55,535 iteration 6035 : loss : 0.038748, loss_ce: 0.013143
 89%|█████████████████████████▋   | 355/400 [2:54:52<24:30, 32.68s/it]2021-12-14 03:59:57,121 iteration 6036 : loss : 0.073921, loss_ce: 0.020816
2021-12-14 03:59:58,733 iteration 6037 : loss : 0.046411, loss_ce: 0.012370
2021-12-14 04:00:00,297 iteration 6038 : loss : 0.043750, loss_ce: 0.014117
2021-12-14 04:00:01,847 iteration 6039 : loss : 0.046268, loss_ce: 0.015921
2021-12-14 04:00:03,434 iteration 6040 : loss : 0.046107, loss_ce: 0.016091
2021-12-14 04:00:04,977 iteration 6041 : loss : 0.036239, loss_ce: 0.010955
2021-12-14 04:00:06,570 iteration 6042 : loss : 0.039320, loss_ce: 0.014776
2021-12-14 04:00:08,096 iteration 6043 : loss : 0.042976, loss_ce: 0.016682
2021-12-14 04:00:09,608 iteration 6044 : loss : 0.038706, loss_ce: 0.013179
2021-12-14 04:00:11,254 iteration 6045 : loss : 0.045305, loss_ce: 0.016132
2021-12-14 04:00:12,770 iteration 6046 : loss : 0.045449, loss_ce: 0.017309
2021-12-14 04:00:14,288 iteration 6047 : loss : 0.035813, loss_ce: 0.011763
2021-12-14 04:00:15,926 iteration 6048 : loss : 0.042212, loss_ce: 0.011722
2021-12-14 04:00:17,433 iteration 6049 : loss : 0.041485, loss_ce: 0.013346
2021-12-14 04:00:18,938 iteration 6050 : loss : 0.045688, loss_ce: 0.011382
2021-12-14 04:00:20,446 iteration 6051 : loss : 0.040997, loss_ce: 0.014956
2021-12-14 04:00:22,045 iteration 6052 : loss : 0.050173, loss_ce: 0.018598
 89%|█████████████████████████▊   | 356/400 [2:55:18<22:36, 30.83s/it]2021-12-14 04:00:23,634 iteration 6053 : loss : 0.047791, loss_ce: 0.013212
2021-12-14 04:00:25,172 iteration 6054 : loss : 0.040786, loss_ce: 0.012034
2021-12-14 04:00:26,765 iteration 6055 : loss : 0.048408, loss_ce: 0.019030
2021-12-14 04:00:28,322 iteration 6056 : loss : 0.040852, loss_ce: 0.012143
2021-12-14 04:00:29,815 iteration 6057 : loss : 0.043354, loss_ce: 0.015116
2021-12-14 04:00:31,332 iteration 6058 : loss : 0.039242, loss_ce: 0.017253
2021-12-14 04:00:32,965 iteration 6059 : loss : 0.050386, loss_ce: 0.011543
2021-12-14 04:00:34,553 iteration 6060 : loss : 0.041915, loss_ce: 0.011332
2021-12-14 04:00:36,080 iteration 6061 : loss : 0.046422, loss_ce: 0.018614
2021-12-14 04:00:37,780 iteration 6062 : loss : 0.053292, loss_ce: 0.016063
2021-12-14 04:00:39,306 iteration 6063 : loss : 0.050102, loss_ce: 0.017737
2021-12-14 04:00:40,842 iteration 6064 : loss : 0.042985, loss_ce: 0.014395
2021-12-14 04:00:42,438 iteration 6065 : loss : 0.067454, loss_ce: 0.024040
2021-12-14 04:00:43,952 iteration 6066 : loss : 0.041926, loss_ce: 0.014806
2021-12-14 04:00:45,541 iteration 6067 : loss : 0.064728, loss_ce: 0.019372
2021-12-14 04:00:47,112 iteration 6068 : loss : 0.048487, loss_ce: 0.009872
2021-12-14 04:00:48,759 iteration 6069 : loss : 0.071334, loss_ce: 0.029372
 89%|█████████████████████████▉   | 357/400 [2:55:45<21:12, 29.60s/it]2021-12-14 04:00:50,402 iteration 6070 : loss : 0.048040, loss_ce: 0.018413
2021-12-14 04:00:51,986 iteration 6071 : loss : 0.055461, loss_ce: 0.020151
2021-12-14 04:00:53,552 iteration 6072 : loss : 0.041773, loss_ce: 0.012620
2021-12-14 04:00:55,134 iteration 6073 : loss : 0.047782, loss_ce: 0.013483
2021-12-14 04:00:56,626 iteration 6074 : loss : 0.041984, loss_ce: 0.014601
2021-12-14 04:00:58,234 iteration 6075 : loss : 0.052920, loss_ce: 0.021070
2021-12-14 04:00:59,811 iteration 6076 : loss : 0.037724, loss_ce: 0.013157
2021-12-14 04:01:01,285 iteration 6077 : loss : 0.039814, loss_ce: 0.013056
2021-12-14 04:01:02,839 iteration 6078 : loss : 0.048532, loss_ce: 0.022625
2021-12-14 04:01:04,483 iteration 6079 : loss : 0.048219, loss_ce: 0.018605
2021-12-14 04:01:05,992 iteration 6080 : loss : 0.037341, loss_ce: 0.011460
2021-12-14 04:01:07,649 iteration 6081 : loss : 0.051522, loss_ce: 0.018506
2021-12-14 04:01:09,218 iteration 6082 : loss : 0.053910, loss_ce: 0.011342
2021-12-14 04:01:10,835 iteration 6083 : loss : 0.043632, loss_ce: 0.012464
2021-12-14 04:01:12,365 iteration 6084 : loss : 0.051837, loss_ce: 0.013074
2021-12-14 04:01:13,896 iteration 6085 : loss : 0.042334, loss_ce: 0.013516
2021-12-14 04:01:15,621 iteration 6086 : loss : 0.053320, loss_ce: 0.013956
 90%|█████████████████████████▉   | 358/400 [2:56:12<20:08, 28.78s/it]2021-12-14 04:01:17,202 iteration 6087 : loss : 0.041275, loss_ce: 0.014401
2021-12-14 04:01:18,782 iteration 6088 : loss : 0.043002, loss_ce: 0.015841
2021-12-14 04:01:20,339 iteration 6089 : loss : 0.044367, loss_ce: 0.019291
2021-12-14 04:01:21,899 iteration 6090 : loss : 0.044677, loss_ce: 0.010223
2021-12-14 04:01:23,465 iteration 6091 : loss : 0.039478, loss_ce: 0.013800
2021-12-14 04:01:25,046 iteration 6092 : loss : 0.036976, loss_ce: 0.012253
2021-12-14 04:01:26,543 iteration 6093 : loss : 0.039216, loss_ce: 0.011821
2021-12-14 04:01:28,061 iteration 6094 : loss : 0.043040, loss_ce: 0.011890
2021-12-14 04:01:29,653 iteration 6095 : loss : 0.046356, loss_ce: 0.016652
2021-12-14 04:01:31,255 iteration 6096 : loss : 0.046913, loss_ce: 0.012188
2021-12-14 04:01:32,755 iteration 6097 : loss : 0.041656, loss_ce: 0.016888
2021-12-14 04:01:34,329 iteration 6098 : loss : 0.056907, loss_ce: 0.019828
2021-12-14 04:01:35,943 iteration 6099 : loss : 0.068354, loss_ce: 0.017801
2021-12-14 04:01:37,600 iteration 6100 : loss : 0.051612, loss_ce: 0.015365
2021-12-14 04:01:39,227 iteration 6101 : loss : 0.037777, loss_ce: 0.011618
2021-12-14 04:01:40,764 iteration 6102 : loss : 0.047299, loss_ce: 0.014417
2021-12-14 04:01:42,233 iteration 6103 : loss : 0.038352, loss_ce: 0.014027
 90%|██████████████████████████   | 359/400 [2:56:39<19:13, 28.13s/it]2021-12-14 04:01:43,906 iteration 6104 : loss : 0.052093, loss_ce: 0.014982
2021-12-14 04:01:45,428 iteration 6105 : loss : 0.049276, loss_ce: 0.014141
2021-12-14 04:01:46,920 iteration 6106 : loss : 0.038211, loss_ce: 0.011033
2021-12-14 04:01:48,441 iteration 6107 : loss : 0.041265, loss_ce: 0.011604
2021-12-14 04:01:50,061 iteration 6108 : loss : 0.041699, loss_ce: 0.011576
2021-12-14 04:01:51,607 iteration 6109 : loss : 0.040978, loss_ce: 0.013014
2021-12-14 04:01:53,195 iteration 6110 : loss : 0.043113, loss_ce: 0.016647
2021-12-14 04:01:54,821 iteration 6111 : loss : 0.047705, loss_ce: 0.016121
2021-12-14 04:01:56,427 iteration 6112 : loss : 0.039927, loss_ce: 0.012573
2021-12-14 04:01:58,060 iteration 6113 : loss : 0.055351, loss_ce: 0.016422
2021-12-14 04:01:59,612 iteration 6114 : loss : 0.047583, loss_ce: 0.018620
2021-12-14 04:02:01,270 iteration 6115 : loss : 0.069151, loss_ce: 0.022273
2021-12-14 04:02:02,877 iteration 6116 : loss : 0.046048, loss_ce: 0.017564
2021-12-14 04:02:04,425 iteration 6117 : loss : 0.049447, loss_ce: 0.018909
2021-12-14 04:02:06,038 iteration 6118 : loss : 0.054941, loss_ce: 0.021163
2021-12-14 04:02:07,604 iteration 6119 : loss : 0.044636, loss_ce: 0.013313
2021-12-14 04:02:07,604 Training Data Eval:
2021-12-14 04:02:15,786   Average segmentation loss on training set: 0.0329
2021-12-14 04:02:15,786 Validation Data Eval:
2021-12-14 04:02:18,579   Average segmentation loss on validation set: 0.0911
2021-12-14 04:02:20,135 iteration 6120 : loss : 0.041019, loss_ce: 0.013348
 90%|██████████████████████████   | 360/400 [2:57:17<20:42, 31.06s/it]2021-12-14 04:02:21,775 iteration 6121 : loss : 0.049440, loss_ce: 0.019234
2021-12-14 04:02:23,391 iteration 6122 : loss : 0.044361, loss_ce: 0.014488
2021-12-14 04:02:25,042 iteration 6123 : loss : 0.041444, loss_ce: 0.014899
2021-12-14 04:02:26,633 iteration 6124 : loss : 0.044743, loss_ce: 0.012931
2021-12-14 04:02:28,309 iteration 6125 : loss : 0.051673, loss_ce: 0.014719
2021-12-14 04:02:29,879 iteration 6126 : loss : 0.067832, loss_ce: 0.013914
2021-12-14 04:02:31,429 iteration 6127 : loss : 0.042334, loss_ce: 0.014156
2021-12-14 04:02:33,084 iteration 6128 : loss : 0.039304, loss_ce: 0.011373
2021-12-14 04:02:34,669 iteration 6129 : loss : 0.040666, loss_ce: 0.014271
2021-12-14 04:02:36,330 iteration 6130 : loss : 0.052093, loss_ce: 0.014895
2021-12-14 04:02:37,924 iteration 6131 : loss : 0.051989, loss_ce: 0.023324
2021-12-14 04:02:39,514 iteration 6132 : loss : 0.065478, loss_ce: 0.015508
2021-12-14 04:02:41,050 iteration 6133 : loss : 0.040958, loss_ce: 0.017170
2021-12-14 04:02:42,549 iteration 6134 : loss : 0.036025, loss_ce: 0.013884
2021-12-14 04:02:44,053 iteration 6135 : loss : 0.037886, loss_ce: 0.011228
2021-12-14 04:02:45,640 iteration 6136 : loss : 0.043505, loss_ce: 0.012336
2021-12-14 04:02:47,194 iteration 6137 : loss : 0.041050, loss_ce: 0.013333
 90%|██████████████████████████▏  | 361/400 [2:57:44<19:24, 29.86s/it]2021-12-14 04:02:48,775 iteration 6138 : loss : 0.041406, loss_ce: 0.013673
2021-12-14 04:02:50,376 iteration 6139 : loss : 0.043031, loss_ce: 0.015157
2021-12-14 04:02:51,939 iteration 6140 : loss : 0.040648, loss_ce: 0.013802
2021-12-14 04:02:53,544 iteration 6141 : loss : 0.043517, loss_ce: 0.014748
2021-12-14 04:02:55,268 iteration 6142 : loss : 0.065383, loss_ce: 0.020276
2021-12-14 04:02:56,788 iteration 6143 : loss : 0.045283, loss_ce: 0.018281
2021-12-14 04:02:58,386 iteration 6144 : loss : 0.041673, loss_ce: 0.013927
2021-12-14 04:02:59,980 iteration 6145 : loss : 0.052678, loss_ce: 0.014822
2021-12-14 04:03:01,549 iteration 6146 : loss : 0.044024, loss_ce: 0.016182
2021-12-14 04:03:03,114 iteration 6147 : loss : 0.037461, loss_ce: 0.009206
2021-12-14 04:03:04,640 iteration 6148 : loss : 0.035309, loss_ce: 0.010050
2021-12-14 04:03:06,158 iteration 6149 : loss : 0.057523, loss_ce: 0.021261
2021-12-14 04:03:07,706 iteration 6150 : loss : 0.049699, loss_ce: 0.013077
2021-12-14 04:03:09,272 iteration 6151 : loss : 0.054397, loss_ce: 0.013561
2021-12-14 04:03:10,800 iteration 6152 : loss : 0.047025, loss_ce: 0.016617
2021-12-14 04:03:12,433 iteration 6153 : loss : 0.048765, loss_ce: 0.017446
2021-12-14 04:03:14,098 iteration 6154 : loss : 0.046773, loss_ce: 0.017324
 90%|██████████████████████████▏  | 362/400 [2:58:11<18:20, 28.97s/it]2021-12-14 04:03:15,699 iteration 6155 : loss : 0.053695, loss_ce: 0.020777
2021-12-14 04:03:17,263 iteration 6156 : loss : 0.035943, loss_ce: 0.013183
2021-12-14 04:03:18,882 iteration 6157 : loss : 0.043123, loss_ce: 0.012735
2021-12-14 04:03:20,431 iteration 6158 : loss : 0.048061, loss_ce: 0.014595
2021-12-14 04:03:21,919 iteration 6159 : loss : 0.037643, loss_ce: 0.012537
2021-12-14 04:03:23,679 iteration 6160 : loss : 0.077395, loss_ce: 0.034569
2021-12-14 04:03:25,183 iteration 6161 : loss : 0.055685, loss_ce: 0.016148
2021-12-14 04:03:26,778 iteration 6162 : loss : 0.040901, loss_ce: 0.012764
2021-12-14 04:03:28,348 iteration 6163 : loss : 0.038271, loss_ce: 0.012012
2021-12-14 04:03:29,887 iteration 6164 : loss : 0.042083, loss_ce: 0.011045
2021-12-14 04:03:31,475 iteration 6165 : loss : 0.041194, loss_ce: 0.012928
2021-12-14 04:03:33,083 iteration 6166 : loss : 0.043064, loss_ce: 0.014713
2021-12-14 04:03:34,579 iteration 6167 : loss : 0.037987, loss_ce: 0.011800
2021-12-14 04:03:36,257 iteration 6168 : loss : 0.061149, loss_ce: 0.018179
2021-12-14 04:03:37,821 iteration 6169 : loss : 0.038364, loss_ce: 0.013436
2021-12-14 04:03:39,447 iteration 6170 : loss : 0.038835, loss_ce: 0.014078
2021-12-14 04:03:41,015 iteration 6171 : loss : 0.046432, loss_ce: 0.012738
 91%|██████████████████████████▎  | 363/400 [2:58:37<17:29, 28.36s/it]2021-12-14 04:03:42,635 iteration 6172 : loss : 0.044650, loss_ce: 0.012673
2021-12-14 04:03:44,112 iteration 6173 : loss : 0.036996, loss_ce: 0.011715
2021-12-14 04:03:45,656 iteration 6174 : loss : 0.046780, loss_ce: 0.018165
2021-12-14 04:03:47,163 iteration 6175 : loss : 0.037442, loss_ce: 0.009738
2021-12-14 04:03:48,751 iteration 6176 : loss : 0.046632, loss_ce: 0.021177
2021-12-14 04:03:50,417 iteration 6177 : loss : 0.081734, loss_ce: 0.034402
2021-12-14 04:03:52,053 iteration 6178 : loss : 0.042178, loss_ce: 0.012468
2021-12-14 04:03:53,670 iteration 6179 : loss : 0.048979, loss_ce: 0.014438
2021-12-14 04:03:55,285 iteration 6180 : loss : 0.078597, loss_ce: 0.013147
2021-12-14 04:03:56,835 iteration 6181 : loss : 0.046639, loss_ce: 0.016496
2021-12-14 04:03:58,429 iteration 6182 : loss : 0.040141, loss_ce: 0.013142
2021-12-14 04:03:59,965 iteration 6183 : loss : 0.054108, loss_ce: 0.017733
2021-12-14 04:04:01,493 iteration 6184 : loss : 0.042452, loss_ce: 0.014339
2021-12-14 04:04:03,108 iteration 6185 : loss : 0.058448, loss_ce: 0.013654
2021-12-14 04:04:04,622 iteration 6186 : loss : 0.037436, loss_ce: 0.012299
2021-12-14 04:04:06,148 iteration 6187 : loss : 0.047609, loss_ce: 0.013704
2021-12-14 04:04:07,670 iteration 6188 : loss : 0.047373, loss_ce: 0.013560
 91%|██████████████████████████▍  | 364/400 [2:59:04<16:42, 27.85s/it]2021-12-14 04:04:09,380 iteration 6189 : loss : 0.059066, loss_ce: 0.020982
2021-12-14 04:04:10,962 iteration 6190 : loss : 0.047632, loss_ce: 0.016604
2021-12-14 04:04:12,604 iteration 6191 : loss : 0.043847, loss_ce: 0.011849
2021-12-14 04:04:14,217 iteration 6192 : loss : 0.053393, loss_ce: 0.017091
2021-12-14 04:04:15,752 iteration 6193 : loss : 0.039674, loss_ce: 0.011457
2021-12-14 04:04:17,374 iteration 6194 : loss : 0.044636, loss_ce: 0.016563
2021-12-14 04:04:19,025 iteration 6195 : loss : 0.050151, loss_ce: 0.015814
2021-12-14 04:04:20,566 iteration 6196 : loss : 0.053332, loss_ce: 0.012761
2021-12-14 04:04:22,227 iteration 6197 : loss : 0.048119, loss_ce: 0.014899
2021-12-14 04:04:23,895 iteration 6198 : loss : 0.051802, loss_ce: 0.020053
2021-12-14 04:04:25,469 iteration 6199 : loss : 0.039790, loss_ce: 0.013818
2021-12-14 04:04:27,076 iteration 6200 : loss : 0.050556, loss_ce: 0.019964
2021-12-14 04:04:28,655 iteration 6201 : loss : 0.044133, loss_ce: 0.014997
2021-12-14 04:04:30,215 iteration 6202 : loss : 0.040164, loss_ce: 0.010652
2021-12-14 04:04:31,767 iteration 6203 : loss : 0.049620, loss_ce: 0.014699
2021-12-14 04:04:33,382 iteration 6204 : loss : 0.045138, loss_ce: 0.016347
2021-12-14 04:04:33,383 Training Data Eval:
2021-12-14 04:04:41,571   Average segmentation loss on training set: 0.0331
2021-12-14 04:04:41,571 Validation Data Eval:
2021-12-14 04:04:44,367   Average segmentation loss on validation set: 0.0862
2021-12-14 04:04:46,041 iteration 6205 : loss : 0.053470, loss_ce: 0.024801
 91%|██████████████████████████▍  | 365/400 [2:59:42<18:04, 31.00s/it]2021-12-14 04:04:47,681 iteration 6206 : loss : 0.042357, loss_ce: 0.014931
2021-12-14 04:04:49,262 iteration 6207 : loss : 0.050646, loss_ce: 0.023655
2021-12-14 04:04:50,861 iteration 6208 : loss : 0.044669, loss_ce: 0.015083
2021-12-14 04:04:52,457 iteration 6209 : loss : 0.060175, loss_ce: 0.018871
2021-12-14 04:04:54,012 iteration 6210 : loss : 0.049688, loss_ce: 0.017026
2021-12-14 04:04:55,526 iteration 6211 : loss : 0.036226, loss_ce: 0.011241
2021-12-14 04:04:57,075 iteration 6212 : loss : 0.044861, loss_ce: 0.013506
2021-12-14 04:04:58,650 iteration 6213 : loss : 0.039352, loss_ce: 0.013752
2021-12-14 04:05:00,205 iteration 6214 : loss : 0.049686, loss_ce: 0.018130
2021-12-14 04:05:01,829 iteration 6215 : loss : 0.046178, loss_ce: 0.013446
2021-12-14 04:05:03,390 iteration 6216 : loss : 0.039725, loss_ce: 0.013372
2021-12-14 04:05:04,894 iteration 6217 : loss : 0.051249, loss_ce: 0.015315
2021-12-14 04:05:06,470 iteration 6218 : loss : 0.052200, loss_ce: 0.018743
2021-12-14 04:05:08,031 iteration 6219 : loss : 0.042700, loss_ce: 0.013805
2021-12-14 04:05:09,568 iteration 6220 : loss : 0.048251, loss_ce: 0.010668
2021-12-14 04:05:11,158 iteration 6221 : loss : 0.054385, loss_ce: 0.013196
2021-12-14 04:05:12,683 iteration 6222 : loss : 0.038522, loss_ce: 0.015650
 92%|██████████████████████████▌  | 366/400 [3:00:09<16:49, 29.69s/it]2021-12-14 04:05:14,328 iteration 6223 : loss : 0.056702, loss_ce: 0.022550
2021-12-14 04:05:15,897 iteration 6224 : loss : 0.043293, loss_ce: 0.016201
2021-12-14 04:05:17,485 iteration 6225 : loss : 0.058738, loss_ce: 0.016307
2021-12-14 04:05:19,026 iteration 6226 : loss : 0.057142, loss_ce: 0.021497
2021-12-14 04:05:20,542 iteration 6227 : loss : 0.040336, loss_ce: 0.013609
2021-12-14 04:05:22,125 iteration 6228 : loss : 0.040358, loss_ce: 0.012185
2021-12-14 04:05:23,712 iteration 6229 : loss : 0.039592, loss_ce: 0.014331
2021-12-14 04:05:25,321 iteration 6230 : loss : 0.054208, loss_ce: 0.015615
2021-12-14 04:05:26,946 iteration 6231 : loss : 0.057251, loss_ce: 0.022059
2021-12-14 04:05:28,539 iteration 6232 : loss : 0.042821, loss_ce: 0.015520
2021-12-14 04:05:30,109 iteration 6233 : loss : 0.045461, loss_ce: 0.016859
2021-12-14 04:05:31,657 iteration 6234 : loss : 0.047900, loss_ce: 0.009879
2021-12-14 04:05:33,184 iteration 6235 : loss : 0.042974, loss_ce: 0.018480
2021-12-14 04:05:34,761 iteration 6236 : loss : 0.047467, loss_ce: 0.019561
2021-12-14 04:05:36,353 iteration 6237 : loss : 0.058239, loss_ce: 0.023438
2021-12-14 04:05:37,996 iteration 6238 : loss : 0.052095, loss_ce: 0.013244
2021-12-14 04:05:39,583 iteration 6239 : loss : 0.050454, loss_ce: 0.014801
 92%|██████████████████████████▌  | 367/400 [3:00:36<15:52, 28.86s/it]2021-12-14 04:05:41,187 iteration 6240 : loss : 0.037102, loss_ce: 0.010455
2021-12-14 04:05:42,715 iteration 6241 : loss : 0.039090, loss_ce: 0.015818
2021-12-14 04:05:44,363 iteration 6242 : loss : 0.052095, loss_ce: 0.015515
2021-12-14 04:05:45,927 iteration 6243 : loss : 0.039374, loss_ce: 0.013855
2021-12-14 04:05:47,587 iteration 6244 : loss : 0.041706, loss_ce: 0.014813
2021-12-14 04:05:49,155 iteration 6245 : loss : 0.043550, loss_ce: 0.013890
2021-12-14 04:05:50,715 iteration 6246 : loss : 0.045742, loss_ce: 0.016413
2021-12-14 04:05:52,313 iteration 6247 : loss : 0.045097, loss_ce: 0.010659
2021-12-14 04:05:53,879 iteration 6248 : loss : 0.037264, loss_ce: 0.011678
2021-12-14 04:05:55,439 iteration 6249 : loss : 0.044147, loss_ce: 0.012299
2021-12-14 04:05:57,042 iteration 6250 : loss : 0.048271, loss_ce: 0.016351
2021-12-14 04:05:58,705 iteration 6251 : loss : 0.046243, loss_ce: 0.015085
2021-12-14 04:06:00,239 iteration 6252 : loss : 0.038850, loss_ce: 0.014462
2021-12-14 04:06:01,858 iteration 6253 : loss : 0.042470, loss_ce: 0.012338
2021-12-14 04:06:03,409 iteration 6254 : loss : 0.042448, loss_ce: 0.017485
2021-12-14 04:06:04,999 iteration 6255 : loss : 0.044926, loss_ce: 0.015332
2021-12-14 04:06:06,645 iteration 6256 : loss : 0.050636, loss_ce: 0.019086
 92%|██████████████████████████▋  | 368/400 [3:01:03<15:06, 28.32s/it]2021-12-14 04:06:08,308 iteration 6257 : loss : 0.047113, loss_ce: 0.013341
2021-12-14 04:06:09,941 iteration 6258 : loss : 0.039957, loss_ce: 0.012340
2021-12-14 04:06:11,593 iteration 6259 : loss : 0.041608, loss_ce: 0.015156
2021-12-14 04:06:13,160 iteration 6260 : loss : 0.044658, loss_ce: 0.015037
2021-12-14 04:06:14,720 iteration 6261 : loss : 0.044420, loss_ce: 0.014871
2021-12-14 04:06:16,317 iteration 6262 : loss : 0.052653, loss_ce: 0.012977
2021-12-14 04:06:17,911 iteration 6263 : loss : 0.044721, loss_ce: 0.010015
2021-12-14 04:06:19,513 iteration 6264 : loss : 0.040448, loss_ce: 0.013162
2021-12-14 04:06:21,104 iteration 6265 : loss : 0.043487, loss_ce: 0.015338
2021-12-14 04:06:22,657 iteration 6266 : loss : 0.051664, loss_ce: 0.021041
2021-12-14 04:06:24,198 iteration 6267 : loss : 0.043374, loss_ce: 0.017018
2021-12-14 04:06:25,771 iteration 6268 : loss : 0.044092, loss_ce: 0.014695
2021-12-14 04:06:27,219 iteration 6269 : loss : 0.033981, loss_ce: 0.010642
2021-12-14 04:06:28,774 iteration 6270 : loss : 0.040254, loss_ce: 0.015652
2021-12-14 04:06:30,333 iteration 6271 : loss : 0.045500, loss_ce: 0.011839
2021-12-14 04:06:31,944 iteration 6272 : loss : 0.047493, loss_ce: 0.015721
2021-12-14 04:06:33,546 iteration 6273 : loss : 0.041608, loss_ce: 0.014418
 92%|██████████████████████████▊  | 369/400 [3:01:30<14:24, 27.89s/it]2021-12-14 04:06:35,295 iteration 6274 : loss : 0.068864, loss_ce: 0.021969
2021-12-14 04:06:36,909 iteration 6275 : loss : 0.044905, loss_ce: 0.019758
2021-12-14 04:06:38,503 iteration 6276 : loss : 0.048694, loss_ce: 0.017391
2021-12-14 04:06:40,045 iteration 6277 : loss : 0.037252, loss_ce: 0.008841
2021-12-14 04:06:41,635 iteration 6278 : loss : 0.046146, loss_ce: 0.014148
2021-12-14 04:06:43,206 iteration 6279 : loss : 0.047481, loss_ce: 0.018240
2021-12-14 04:06:44,750 iteration 6280 : loss : 0.056801, loss_ce: 0.019639
2021-12-14 04:06:46,439 iteration 6281 : loss : 0.049791, loss_ce: 0.011651
2021-12-14 04:06:48,003 iteration 6282 : loss : 0.036180, loss_ce: 0.011156
2021-12-14 04:06:49,546 iteration 6283 : loss : 0.038176, loss_ce: 0.013593
2021-12-14 04:06:51,124 iteration 6284 : loss : 0.043783, loss_ce: 0.015565
2021-12-14 04:06:52,741 iteration 6285 : loss : 0.043204, loss_ce: 0.012906
2021-12-14 04:06:54,292 iteration 6286 : loss : 0.042351, loss_ce: 0.010979
2021-12-14 04:06:55,839 iteration 6287 : loss : 0.049594, loss_ce: 0.012736
2021-12-14 04:06:57,328 iteration 6288 : loss : 0.045556, loss_ce: 0.015062
2021-12-14 04:06:58,914 iteration 6289 : loss : 0.039533, loss_ce: 0.014265
2021-12-14 04:06:58,914 Training Data Eval:
2021-12-14 04:07:07,095   Average segmentation loss on training set: 0.0330
2021-12-14 04:07:07,095 Validation Data Eval:
2021-12-14 04:07:09,890   Average segmentation loss on validation set: 0.0860
2021-12-14 04:07:11,499 iteration 6290 : loss : 0.048198, loss_ce: 0.018430
 92%|██████████████████████████▊  | 370/400 [3:02:08<15:27, 30.91s/it]2021-12-14 04:07:13,122 iteration 6291 : loss : 0.038583, loss_ce: 0.013831
2021-12-14 04:07:14,702 iteration 6292 : loss : 0.044750, loss_ce: 0.013205
2021-12-14 04:07:16,313 iteration 6293 : loss : 0.055684, loss_ce: 0.022559
2021-12-14 04:07:17,932 iteration 6294 : loss : 0.053221, loss_ce: 0.014118
2021-12-14 04:07:19,507 iteration 6295 : loss : 0.037209, loss_ce: 0.013323
2021-12-14 04:07:21,152 iteration 6296 : loss : 0.052892, loss_ce: 0.017924
2021-12-14 04:07:22,738 iteration 6297 : loss : 0.048130, loss_ce: 0.014524
2021-12-14 04:07:24,357 iteration 6298 : loss : 0.049664, loss_ce: 0.016371
2021-12-14 04:07:25,928 iteration 6299 : loss : 0.047863, loss_ce: 0.014417
2021-12-14 04:07:27,472 iteration 6300 : loss : 0.042692, loss_ce: 0.014305
2021-12-14 04:07:29,016 iteration 6301 : loss : 0.044184, loss_ce: 0.021999
2021-12-14 04:07:30,609 iteration 6302 : loss : 0.045525, loss_ce: 0.014285
2021-12-14 04:07:32,101 iteration 6303 : loss : 0.040092, loss_ce: 0.008451
2021-12-14 04:07:33,603 iteration 6304 : loss : 0.049702, loss_ce: 0.012641
2021-12-14 04:07:35,193 iteration 6305 : loss : 0.051338, loss_ce: 0.020130
2021-12-14 04:07:36,745 iteration 6306 : loss : 0.057045, loss_ce: 0.013722
2021-12-14 04:07:38,306 iteration 6307 : loss : 0.040518, loss_ce: 0.015441
 93%|██████████████████████████▉  | 371/400 [3:02:35<14:20, 29.68s/it]2021-12-14 04:07:39,873 iteration 6308 : loss : 0.044252, loss_ce: 0.009900
2021-12-14 04:07:41,456 iteration 6309 : loss : 0.047989, loss_ce: 0.016994
2021-12-14 04:07:43,017 iteration 6310 : loss : 0.041150, loss_ce: 0.015970
2021-12-14 04:07:44,599 iteration 6311 : loss : 0.041055, loss_ce: 0.014821
2021-12-14 04:07:46,194 iteration 6312 : loss : 0.054045, loss_ce: 0.015820
2021-12-14 04:07:47,835 iteration 6313 : loss : 0.055463, loss_ce: 0.020949
2021-12-14 04:07:49,422 iteration 6314 : loss : 0.039644, loss_ce: 0.011698
2021-12-14 04:07:50,964 iteration 6315 : loss : 0.044878, loss_ce: 0.014144
2021-12-14 04:07:52,538 iteration 6316 : loss : 0.038807, loss_ce: 0.012217
2021-12-14 04:07:54,100 iteration 6317 : loss : 0.042405, loss_ce: 0.011129
2021-12-14 04:07:55,735 iteration 6318 : loss : 0.048782, loss_ce: 0.015947
2021-12-14 04:07:57,336 iteration 6319 : loss : 0.044204, loss_ce: 0.014835
2021-12-14 04:07:58,897 iteration 6320 : loss : 0.048543, loss_ce: 0.013814
2021-12-14 04:08:00,520 iteration 6321 : loss : 0.056844, loss_ce: 0.025782
2021-12-14 04:08:02,151 iteration 6322 : loss : 0.048849, loss_ce: 0.018037
2021-12-14 04:08:03,860 iteration 6323 : loss : 0.061243, loss_ce: 0.017925
2021-12-14 04:08:05,519 iteration 6324 : loss : 0.047474, loss_ce: 0.019974
 93%|██████████████████████████▉  | 372/400 [3:03:02<13:30, 28.94s/it]2021-12-14 04:08:07,189 iteration 6325 : loss : 0.048476, loss_ce: 0.012285
2021-12-14 04:08:08,743 iteration 6326 : loss : 0.042841, loss_ce: 0.015073
2021-12-14 04:08:10,318 iteration 6327 : loss : 0.053327, loss_ce: 0.015490
2021-12-14 04:08:11,947 iteration 6328 : loss : 0.038074, loss_ce: 0.013998
2021-12-14 04:08:13,461 iteration 6329 : loss : 0.041686, loss_ce: 0.018009
2021-12-14 04:08:15,024 iteration 6330 : loss : 0.044916, loss_ce: 0.015137
2021-12-14 04:08:16,656 iteration 6331 : loss : 0.041765, loss_ce: 0.013179
2021-12-14 04:08:18,262 iteration 6332 : loss : 0.038824, loss_ce: 0.011140
2021-12-14 04:08:19,840 iteration 6333 : loss : 0.037291, loss_ce: 0.014710
2021-12-14 04:08:21,414 iteration 6334 : loss : 0.065880, loss_ce: 0.016952
2021-12-14 04:08:23,082 iteration 6335 : loss : 0.038306, loss_ce: 0.011779
2021-12-14 04:08:24,633 iteration 6336 : loss : 0.047696, loss_ce: 0.017149
2021-12-14 04:08:26,236 iteration 6337 : loss : 0.047062, loss_ce: 0.014086
2021-12-14 04:08:27,824 iteration 6338 : loss : 0.055227, loss_ce: 0.015284
2021-12-14 04:08:29,403 iteration 6339 : loss : 0.046998, loss_ce: 0.015658
2021-12-14 04:08:30,985 iteration 6340 : loss : 0.050153, loss_ce: 0.020924
2021-12-14 04:08:32,492 iteration 6341 : loss : 0.038965, loss_ce: 0.012184
 93%|███████████████████████████  | 373/400 [3:03:29<12:45, 28.35s/it]2021-12-14 04:08:34,166 iteration 6342 : loss : 0.064045, loss_ce: 0.018056
2021-12-14 04:08:35,723 iteration 6343 : loss : 0.039828, loss_ce: 0.012122
2021-12-14 04:08:37,278 iteration 6344 : loss : 0.060626, loss_ce: 0.017012
2021-12-14 04:08:38,820 iteration 6345 : loss : 0.097008, loss_ce: 0.009625
2021-12-14 04:08:40,407 iteration 6346 : loss : 0.055678, loss_ce: 0.018141
2021-12-14 04:08:41,987 iteration 6347 : loss : 0.040535, loss_ce: 0.013591
2021-12-14 04:08:43,470 iteration 6348 : loss : 0.034752, loss_ce: 0.012952
2021-12-14 04:08:45,049 iteration 6349 : loss : 0.054923, loss_ce: 0.022719
2021-12-14 04:08:46,731 iteration 6350 : loss : 0.062794, loss_ce: 0.020563
2021-12-14 04:08:48,364 iteration 6351 : loss : 0.043289, loss_ce: 0.016857
2021-12-14 04:08:49,950 iteration 6352 : loss : 0.046139, loss_ce: 0.013968
2021-12-14 04:08:51,536 iteration 6353 : loss : 0.048404, loss_ce: 0.017395
2021-12-14 04:08:53,119 iteration 6354 : loss : 0.043971, loss_ce: 0.017349
2021-12-14 04:08:54,678 iteration 6355 : loss : 0.044343, loss_ce: 0.013373
2021-12-14 04:08:56,324 iteration 6356 : loss : 0.050440, loss_ce: 0.012735
2021-12-14 04:08:57,875 iteration 6357 : loss : 0.051748, loss_ce: 0.016638
2021-12-14 04:08:59,558 iteration 6358 : loss : 0.046790, loss_ce: 0.017117
 94%|███████████████████████████  | 374/400 [3:03:56<12:07, 27.97s/it]2021-12-14 04:09:01,252 iteration 6359 : loss : 0.049802, loss_ce: 0.012510
2021-12-14 04:09:02,784 iteration 6360 : loss : 0.045140, loss_ce: 0.015744
2021-12-14 04:09:04,390 iteration 6361 : loss : 0.044594, loss_ce: 0.013508
2021-12-14 04:09:06,003 iteration 6362 : loss : 0.046210, loss_ce: 0.017124
2021-12-14 04:09:07,645 iteration 6363 : loss : 0.061073, loss_ce: 0.019480
2021-12-14 04:09:09,194 iteration 6364 : loss : 0.043620, loss_ce: 0.010804
2021-12-14 04:09:10,790 iteration 6365 : loss : 0.057436, loss_ce: 0.025367
2021-12-14 04:09:12,459 iteration 6366 : loss : 0.041979, loss_ce: 0.013130
2021-12-14 04:09:14,150 iteration 6367 : loss : 0.053238, loss_ce: 0.018486
2021-12-14 04:09:15,778 iteration 6368 : loss : 0.047112, loss_ce: 0.017609
2021-12-14 04:09:17,370 iteration 6369 : loss : 0.040429, loss_ce: 0.013455
2021-12-14 04:09:18,967 iteration 6370 : loss : 0.043569, loss_ce: 0.013530
2021-12-14 04:09:20,652 iteration 6371 : loss : 0.051606, loss_ce: 0.016435
2021-12-14 04:09:22,199 iteration 6372 : loss : 0.032174, loss_ce: 0.010105
2021-12-14 04:09:23,736 iteration 6373 : loss : 0.035614, loss_ce: 0.011563
2021-12-14 04:09:25,319 iteration 6374 : loss : 0.048800, loss_ce: 0.018019
2021-12-14 04:09:25,319 Training Data Eval:
2021-12-14 04:09:33,492   Average segmentation loss on training set: 0.0323
2021-12-14 04:09:33,493 Validation Data Eval:
2021-12-14 04:09:36,285   Average segmentation loss on validation set: 0.0866
2021-12-14 04:09:37,867 iteration 6375 : loss : 0.052983, loss_ce: 0.015230
 94%|███████████████████████████▏ | 375/400 [3:04:34<12:56, 31.06s/it]2021-12-14 04:09:39,521 iteration 6376 : loss : 0.045391, loss_ce: 0.011849
2021-12-14 04:09:41,112 iteration 6377 : loss : 0.048142, loss_ce: 0.014970
2021-12-14 04:09:42,597 iteration 6378 : loss : 0.037739, loss_ce: 0.013362
2021-12-14 04:09:44,161 iteration 6379 : loss : 0.050080, loss_ce: 0.012677
2021-12-14 04:09:45,704 iteration 6380 : loss : 0.045340, loss_ce: 0.015679
2021-12-14 04:09:47,237 iteration 6381 : loss : 0.037349, loss_ce: 0.009774
2021-12-14 04:09:48,716 iteration 6382 : loss : 0.046903, loss_ce: 0.015715
2021-12-14 04:09:50,326 iteration 6383 : loss : 0.048224, loss_ce: 0.017103
2021-12-14 04:09:51,867 iteration 6384 : loss : 0.041322, loss_ce: 0.013177
2021-12-14 04:09:53,470 iteration 6385 : loss : 0.044760, loss_ce: 0.012096
2021-12-14 04:09:55,089 iteration 6386 : loss : 0.055389, loss_ce: 0.015216
2021-12-14 04:09:56,765 iteration 6387 : loss : 0.047496, loss_ce: 0.019734
2021-12-14 04:09:58,389 iteration 6388 : loss : 0.044142, loss_ce: 0.015437
2021-12-14 04:09:59,864 iteration 6389 : loss : 0.043476, loss_ce: 0.014139
2021-12-14 04:10:01,443 iteration 6390 : loss : 0.050040, loss_ce: 0.020764
2021-12-14 04:10:02,981 iteration 6391 : loss : 0.045046, loss_ce: 0.020675
2021-12-14 04:10:04,626 iteration 6392 : loss : 0.063553, loss_ce: 0.017164
 94%|███████████████████████████▎ | 376/400 [3:05:01<11:54, 29.78s/it]2021-12-14 04:10:06,242 iteration 6393 : loss : 0.044672, loss_ce: 0.015492
2021-12-14 04:10:07,867 iteration 6394 : loss : 0.049925, loss_ce: 0.017504
2021-12-14 04:10:09,431 iteration 6395 : loss : 0.039729, loss_ce: 0.011130
2021-12-14 04:10:11,003 iteration 6396 : loss : 0.050308, loss_ce: 0.013782
2021-12-14 04:10:12,600 iteration 6397 : loss : 0.044374, loss_ce: 0.014009
2021-12-14 04:10:14,201 iteration 6398 : loss : 0.045950, loss_ce: 0.016625
2021-12-14 04:10:15,772 iteration 6399 : loss : 0.049509, loss_ce: 0.014104
2021-12-14 04:10:17,327 iteration 6400 : loss : 0.039625, loss_ce: 0.014210
2021-12-14 04:10:18,932 iteration 6401 : loss : 0.041974, loss_ce: 0.013844
2021-12-14 04:10:20,494 iteration 6402 : loss : 0.047350, loss_ce: 0.020501
2021-12-14 04:10:22,149 iteration 6403 : loss : 0.043397, loss_ce: 0.015764
2021-12-14 04:10:23,713 iteration 6404 : loss : 0.039250, loss_ce: 0.015270
2021-12-14 04:10:25,258 iteration 6405 : loss : 0.057829, loss_ce: 0.015536
2021-12-14 04:10:26,987 iteration 6406 : loss : 0.077765, loss_ce: 0.018477
2021-12-14 04:10:28,593 iteration 6407 : loss : 0.042593, loss_ce: 0.010516
2021-12-14 04:10:30,068 iteration 6408 : loss : 0.039864, loss_ce: 0.012498
2021-12-14 04:10:31,626 iteration 6409 : loss : 0.047476, loss_ce: 0.016019
 94%|███████████████████████████▎ | 377/400 [3:05:28<11:05, 28.94s/it]2021-12-14 04:10:33,209 iteration 6410 : loss : 0.038881, loss_ce: 0.011024
2021-12-14 04:10:34,806 iteration 6411 : loss : 0.046018, loss_ce: 0.016952
2021-12-14 04:10:36,408 iteration 6412 : loss : 0.057366, loss_ce: 0.016830
2021-12-14 04:10:37,969 iteration 6413 : loss : 0.045680, loss_ce: 0.016781
2021-12-14 04:10:39,515 iteration 6414 : loss : 0.046393, loss_ce: 0.014887
2021-12-14 04:10:41,037 iteration 6415 : loss : 0.036900, loss_ce: 0.010738
2021-12-14 04:10:42,616 iteration 6416 : loss : 0.037644, loss_ce: 0.012113
2021-12-14 04:10:44,129 iteration 6417 : loss : 0.041517, loss_ce: 0.015206
2021-12-14 04:10:45,674 iteration 6418 : loss : 0.041924, loss_ce: 0.014154
2021-12-14 04:10:47,334 iteration 6419 : loss : 0.052484, loss_ce: 0.017698
2021-12-14 04:10:48,987 iteration 6420 : loss : 0.048609, loss_ce: 0.011490
2021-12-14 04:10:50,607 iteration 6421 : loss : 0.042320, loss_ce: 0.014558
2021-12-14 04:10:52,196 iteration 6422 : loss : 0.042262, loss_ce: 0.011370
2021-12-14 04:10:53,810 iteration 6423 : loss : 0.041377, loss_ce: 0.014349
2021-12-14 04:10:55,483 iteration 6424 : loss : 0.061083, loss_ce: 0.023653
2021-12-14 04:10:57,048 iteration 6425 : loss : 0.045668, loss_ce: 0.012400
2021-12-14 04:10:58,691 iteration 6426 : loss : 0.049076, loss_ce: 0.015800
 94%|███████████████████████████▍ | 378/400 [3:05:55<10:24, 28.38s/it]2021-12-14 04:11:00,352 iteration 6427 : loss : 0.045767, loss_ce: 0.013250
2021-12-14 04:11:01,943 iteration 6428 : loss : 0.053854, loss_ce: 0.014155
2021-12-14 04:11:03,539 iteration 6429 : loss : 0.049587, loss_ce: 0.014140
2021-12-14 04:11:05,175 iteration 6430 : loss : 0.050743, loss_ce: 0.018980
2021-12-14 04:11:06,696 iteration 6431 : loss : 0.048915, loss_ce: 0.015626
2021-12-14 04:11:08,288 iteration 6432 : loss : 0.039354, loss_ce: 0.013272
2021-12-14 04:11:09,863 iteration 6433 : loss : 0.043329, loss_ce: 0.012227
2021-12-14 04:11:11,408 iteration 6434 : loss : 0.042436, loss_ce: 0.015196
2021-12-14 04:11:12,972 iteration 6435 : loss : 0.049842, loss_ce: 0.017264
2021-12-14 04:11:14,532 iteration 6436 : loss : 0.036467, loss_ce: 0.013256
2021-12-14 04:11:16,115 iteration 6437 : loss : 0.040637, loss_ce: 0.012743
2021-12-14 04:11:17,727 iteration 6438 : loss : 0.043537, loss_ce: 0.011693
2021-12-14 04:11:19,262 iteration 6439 : loss : 0.041686, loss_ce: 0.015147
2021-12-14 04:11:20,877 iteration 6440 : loss : 0.047182, loss_ce: 0.018341
2021-12-14 04:11:22,395 iteration 6441 : loss : 0.039748, loss_ce: 0.013775
2021-12-14 04:11:23,982 iteration 6442 : loss : 0.039390, loss_ce: 0.011677
2021-12-14 04:11:25,483 iteration 6443 : loss : 0.043390, loss_ce: 0.012826
 95%|███████████████████████████▍ | 379/400 [3:06:22<09:45, 27.90s/it]2021-12-14 04:11:27,113 iteration 6444 : loss : 0.042243, loss_ce: 0.016593
2021-12-14 04:11:28,688 iteration 6445 : loss : 0.040665, loss_ce: 0.014437
2021-12-14 04:11:30,278 iteration 6446 : loss : 0.057376, loss_ce: 0.023805
2021-12-14 04:11:31,881 iteration 6447 : loss : 0.064463, loss_ce: 0.011897
2021-12-14 04:11:33,496 iteration 6448 : loss : 0.042558, loss_ce: 0.013158
2021-12-14 04:11:35,054 iteration 6449 : loss : 0.038880, loss_ce: 0.008477
2021-12-14 04:11:36,582 iteration 6450 : loss : 0.044470, loss_ce: 0.017019
2021-12-14 04:11:38,165 iteration 6451 : loss : 0.044662, loss_ce: 0.013153
2021-12-14 04:11:39,816 iteration 6452 : loss : 0.061914, loss_ce: 0.019803
2021-12-14 04:11:41,378 iteration 6453 : loss : 0.053228, loss_ce: 0.017337
2021-12-14 04:11:42,898 iteration 6454 : loss : 0.053444, loss_ce: 0.019403
2021-12-14 04:11:44,523 iteration 6455 : loss : 0.039130, loss_ce: 0.014903
2021-12-14 04:11:46,097 iteration 6456 : loss : 0.042711, loss_ce: 0.013362
2021-12-14 04:11:47,698 iteration 6457 : loss : 0.055829, loss_ce: 0.016710
2021-12-14 04:11:49,225 iteration 6458 : loss : 0.042057, loss_ce: 0.014064
2021-12-14 04:11:50,781 iteration 6459 : loss : 0.040987, loss_ce: 0.009954
2021-12-14 04:11:50,782 Training Data Eval:
2021-12-14 04:11:58,965   Average segmentation loss on training set: 0.0326
2021-12-14 04:11:58,965 Validation Data Eval:
2021-12-14 04:12:01,746   Average segmentation loss on validation set: 0.0927
2021-12-14 04:12:03,357 iteration 6460 : loss : 0.045802, loss_ce: 0.017373
 95%|███████████████████████████▌ | 380/400 [3:07:00<10:17, 30.89s/it]2021-12-14 04:12:05,036 iteration 6461 : loss : 0.055048, loss_ce: 0.020307
2021-12-14 04:12:06,582 iteration 6462 : loss : 0.040564, loss_ce: 0.013778
2021-12-14 04:12:08,216 iteration 6463 : loss : 0.059613, loss_ce: 0.022000
2021-12-14 04:12:09,800 iteration 6464 : loss : 0.057994, loss_ce: 0.014199
2021-12-14 04:12:11,424 iteration 6465 : loss : 0.046584, loss_ce: 0.015207
2021-12-14 04:12:12,952 iteration 6466 : loss : 0.044998, loss_ce: 0.014200
2021-12-14 04:12:14,509 iteration 6467 : loss : 0.051785, loss_ce: 0.018293
2021-12-14 04:12:16,148 iteration 6468 : loss : 0.050777, loss_ce: 0.016764
2021-12-14 04:12:17,710 iteration 6469 : loss : 0.040303, loss_ce: 0.014630
2021-12-14 04:12:19,251 iteration 6470 : loss : 0.038441, loss_ce: 0.010119
2021-12-14 04:12:20,827 iteration 6471 : loss : 0.041584, loss_ce: 0.013529
2021-12-14 04:12:22,415 iteration 6472 : loss : 0.044984, loss_ce: 0.013711
2021-12-14 04:12:23,961 iteration 6473 : loss : 0.043114, loss_ce: 0.013049
2021-12-14 04:12:25,597 iteration 6474 : loss : 0.045325, loss_ce: 0.018492
2021-12-14 04:12:27,193 iteration 6475 : loss : 0.049723, loss_ce: 0.023092
2021-12-14 04:12:28,662 iteration 6476 : loss : 0.044370, loss_ce: 0.015020
2021-12-14 04:12:30,320 iteration 6477 : loss : 0.068448, loss_ce: 0.022775
 95%|███████████████████████████▌ | 381/400 [3:07:27<09:24, 29.71s/it]2021-12-14 04:12:32,002 iteration 6478 : loss : 0.047062, loss_ce: 0.012829
2021-12-14 04:12:33,567 iteration 6479 : loss : 0.047817, loss_ce: 0.014841
2021-12-14 04:12:35,137 iteration 6480 : loss : 0.037508, loss_ce: 0.013174
2021-12-14 04:12:36,745 iteration 6481 : loss : 0.041399, loss_ce: 0.016087
2021-12-14 04:12:38,262 iteration 6482 : loss : 0.040827, loss_ce: 0.012936
2021-12-14 04:12:39,870 iteration 6483 : loss : 0.056815, loss_ce: 0.013683
2021-12-14 04:12:41,408 iteration 6484 : loss : 0.036151, loss_ce: 0.012615
2021-12-14 04:12:42,977 iteration 6485 : loss : 0.049015, loss_ce: 0.017848
2021-12-14 04:12:44,606 iteration 6486 : loss : 0.038776, loss_ce: 0.012311
2021-12-14 04:12:46,282 iteration 6487 : loss : 0.054194, loss_ce: 0.019114
2021-12-14 04:12:47,892 iteration 6488 : loss : 0.050891, loss_ce: 0.016593
2021-12-14 04:12:49,428 iteration 6489 : loss : 0.041565, loss_ce: 0.016016
2021-12-14 04:12:51,015 iteration 6490 : loss : 0.045905, loss_ce: 0.012859
2021-12-14 04:12:52,563 iteration 6491 : loss : 0.047478, loss_ce: 0.014359
2021-12-14 04:12:54,215 iteration 6492 : loss : 0.045229, loss_ce: 0.014783
2021-12-14 04:12:55,813 iteration 6493 : loss : 0.059833, loss_ce: 0.019976
2021-12-14 04:12:57,287 iteration 6494 : loss : 0.034690, loss_ce: 0.011915
 96%|███████████████████████████▋ | 382/400 [3:07:54<08:40, 28.89s/it]2021-12-14 04:12:58,873 iteration 6495 : loss : 0.044289, loss_ce: 0.015674
2021-12-14 04:13:00,447 iteration 6496 : loss : 0.047825, loss_ce: 0.011738
2021-12-14 04:13:02,059 iteration 6497 : loss : 0.040399, loss_ce: 0.012669
2021-12-14 04:13:03,682 iteration 6498 : loss : 0.050044, loss_ce: 0.016300
2021-12-14 04:13:05,303 iteration 6499 : loss : 0.054621, loss_ce: 0.016813
2021-12-14 04:13:06,872 iteration 6500 : loss : 0.037645, loss_ce: 0.011196
2021-12-14 04:13:08,474 iteration 6501 : loss : 0.050699, loss_ce: 0.016221
2021-12-14 04:13:10,108 iteration 6502 : loss : 0.048488, loss_ce: 0.022080
2021-12-14 04:13:11,657 iteration 6503 : loss : 0.041282, loss_ce: 0.009892
2021-12-14 04:13:13,177 iteration 6504 : loss : 0.045536, loss_ce: 0.013722
2021-12-14 04:13:14,633 iteration 6505 : loss : 0.039083, loss_ce: 0.015482
2021-12-14 04:13:16,190 iteration 6506 : loss : 0.050984, loss_ce: 0.013437
2021-12-14 04:13:17,833 iteration 6507 : loss : 0.056138, loss_ce: 0.025522
2021-12-14 04:13:19,441 iteration 6508 : loss : 0.049876, loss_ce: 0.018715
2021-12-14 04:13:21,027 iteration 6509 : loss : 0.050476, loss_ce: 0.017032
2021-12-14 04:13:22,618 iteration 6510 : loss : 0.045856, loss_ce: 0.012514
2021-12-14 04:13:24,120 iteration 6511 : loss : 0.043970, loss_ce: 0.014109
 96%|███████████████████████████▊ | 383/400 [3:08:21<08:00, 28.27s/it]2021-12-14 04:13:25,701 iteration 6512 : loss : 0.051328, loss_ce: 0.014886
2021-12-14 04:13:27,276 iteration 6513 : loss : 0.048393, loss_ce: 0.015806
2021-12-14 04:13:28,953 iteration 6514 : loss : 0.040727, loss_ce: 0.011655
2021-12-14 04:13:30,597 iteration 6515 : loss : 0.047942, loss_ce: 0.014528
2021-12-14 04:13:32,210 iteration 6516 : loss : 0.046709, loss_ce: 0.018264
2021-12-14 04:13:33,780 iteration 6517 : loss : 0.051453, loss_ce: 0.009737
2021-12-14 04:13:35,362 iteration 6518 : loss : 0.041675, loss_ce: 0.013913
2021-12-14 04:13:36,935 iteration 6519 : loss : 0.050380, loss_ce: 0.015696
2021-12-14 04:13:38,554 iteration 6520 : loss : 0.043843, loss_ce: 0.013761
2021-12-14 04:13:40,094 iteration 6521 : loss : 0.048508, loss_ce: 0.018855
2021-12-14 04:13:41,686 iteration 6522 : loss : 0.036152, loss_ce: 0.011740
2021-12-14 04:13:43,192 iteration 6523 : loss : 0.038072, loss_ce: 0.012499
2021-12-14 04:13:44,812 iteration 6524 : loss : 0.051350, loss_ce: 0.022327
2021-12-14 04:13:46,403 iteration 6525 : loss : 0.047069, loss_ce: 0.017684
2021-12-14 04:13:47,983 iteration 6526 : loss : 0.054438, loss_ce: 0.018863
2021-12-14 04:13:49,487 iteration 6527 : loss : 0.039215, loss_ce: 0.014409
2021-12-14 04:13:51,018 iteration 6528 : loss : 0.047284, loss_ce: 0.013115
 96%|███████████████████████████▊ | 384/400 [3:08:47<07:25, 27.86s/it]2021-12-14 04:13:52,682 iteration 6529 : loss : 0.054958, loss_ce: 0.018877
2021-12-14 04:13:54,287 iteration 6530 : loss : 0.040006, loss_ce: 0.012929
2021-12-14 04:13:55,807 iteration 6531 : loss : 0.039574, loss_ce: 0.009517
2021-12-14 04:13:57,411 iteration 6532 : loss : 0.041650, loss_ce: 0.014846
2021-12-14 04:13:58,917 iteration 6533 : loss : 0.035569, loss_ce: 0.011930
2021-12-14 04:14:00,500 iteration 6534 : loss : 0.050425, loss_ce: 0.019902
2021-12-14 04:14:02,093 iteration 6535 : loss : 0.043924, loss_ce: 0.014473
2021-12-14 04:14:03,698 iteration 6536 : loss : 0.042532, loss_ce: 0.013808
2021-12-14 04:14:05,299 iteration 6537 : loss : 0.047713, loss_ce: 0.012113
2021-12-14 04:14:06,907 iteration 6538 : loss : 0.043734, loss_ce: 0.013093
2021-12-14 04:14:08,531 iteration 6539 : loss : 0.043180, loss_ce: 0.016193
2021-12-14 04:14:10,031 iteration 6540 : loss : 0.038867, loss_ce: 0.014722
2021-12-14 04:14:11,569 iteration 6541 : loss : 0.054235, loss_ce: 0.024435
2021-12-14 04:14:13,233 iteration 6542 : loss : 0.040833, loss_ce: 0.010242
2021-12-14 04:14:14,777 iteration 6543 : loss : 0.041146, loss_ce: 0.012011
2021-12-14 04:14:16,386 iteration 6544 : loss : 0.044968, loss_ce: 0.016663
2021-12-14 04:14:16,387 Training Data Eval:
2021-12-14 04:14:24,576   Average segmentation loss on training set: 0.0325
2021-12-14 04:14:24,577 Validation Data Eval:
2021-12-14 04:14:27,384   Average segmentation loss on validation set: 0.0926
2021-12-14 04:14:29,042 iteration 6545 : loss : 0.053569, loss_ce: 0.019909
 96%|███████████████████████████▉ | 385/400 [3:09:25<07:43, 30.91s/it]2021-12-14 04:14:30,802 iteration 6546 : loss : 0.039911, loss_ce: 0.014997
2021-12-14 04:14:32,377 iteration 6547 : loss : 0.040881, loss_ce: 0.014178
2021-12-14 04:14:33,981 iteration 6548 : loss : 0.038494, loss_ce: 0.011937
2021-12-14 04:14:35,522 iteration 6549 : loss : 0.054525, loss_ce: 0.018503
2021-12-14 04:14:37,161 iteration 6550 : loss : 0.054272, loss_ce: 0.017885
2021-12-14 04:14:38,800 iteration 6551 : loss : 0.053484, loss_ce: 0.018393
2021-12-14 04:14:40,487 iteration 6552 : loss : 0.050999, loss_ce: 0.017162
2021-12-14 04:14:42,200 iteration 6553 : loss : 0.062585, loss_ce: 0.019523
2021-12-14 04:14:43,808 iteration 6554 : loss : 0.043339, loss_ce: 0.013184
2021-12-14 04:14:45,394 iteration 6555 : loss : 0.038359, loss_ce: 0.013065
2021-12-14 04:14:46,973 iteration 6556 : loss : 0.041139, loss_ce: 0.009752
2021-12-14 04:14:48,453 iteration 6557 : loss : 0.034072, loss_ce: 0.011201
2021-12-14 04:14:50,020 iteration 6558 : loss : 0.045936, loss_ce: 0.013580
2021-12-14 04:14:51,517 iteration 6559 : loss : 0.038734, loss_ce: 0.012074
2021-12-14 04:14:53,088 iteration 6560 : loss : 0.041627, loss_ce: 0.016656
2021-12-14 04:14:54,700 iteration 6561 : loss : 0.054024, loss_ce: 0.013558
2021-12-14 04:14:56,235 iteration 6562 : loss : 0.040500, loss_ce: 0.013317
 96%|███████████████████████████▉ | 386/400 [3:09:53<06:57, 29.80s/it]2021-12-14 04:14:57,981 iteration 6563 : loss : 0.048034, loss_ce: 0.019414
2021-12-14 04:14:59,546 iteration 6564 : loss : 0.049608, loss_ce: 0.020050
2021-12-14 04:15:01,073 iteration 6565 : loss : 0.047548, loss_ce: 0.010931
2021-12-14 04:15:02,590 iteration 6566 : loss : 0.048587, loss_ce: 0.017170
2021-12-14 04:15:04,090 iteration 6567 : loss : 0.042499, loss_ce: 0.014144
2021-12-14 04:15:05,637 iteration 6568 : loss : 0.050292, loss_ce: 0.020063
2021-12-14 04:15:07,209 iteration 6569 : loss : 0.041181, loss_ce: 0.015021
2021-12-14 04:15:08,730 iteration 6570 : loss : 0.038512, loss_ce: 0.014041
2021-12-14 04:15:10,282 iteration 6571 : loss : 0.049269, loss_ce: 0.013817
2021-12-14 04:15:11,773 iteration 6572 : loss : 0.038556, loss_ce: 0.014290
2021-12-14 04:15:13,405 iteration 6573 : loss : 0.045674, loss_ce: 0.013711
2021-12-14 04:15:15,054 iteration 6574 : loss : 0.037478, loss_ce: 0.013010
2021-12-14 04:15:16,711 iteration 6575 : loss : 0.067164, loss_ce: 0.016779
2021-12-14 04:15:18,254 iteration 6576 : loss : 0.061231, loss_ce: 0.024796
2021-12-14 04:15:19,854 iteration 6577 : loss : 0.068282, loss_ce: 0.014522
2021-12-14 04:15:21,386 iteration 6578 : loss : 0.041399, loss_ce: 0.014707
2021-12-14 04:15:22,974 iteration 6579 : loss : 0.045312, loss_ce: 0.014334
 97%|████████████████████████████ | 387/400 [3:10:19<06:15, 28.88s/it]2021-12-14 04:15:24,607 iteration 6580 : loss : 0.046271, loss_ce: 0.011945
2021-12-14 04:15:26,158 iteration 6581 : loss : 0.041411, loss_ce: 0.012166
2021-12-14 04:15:27,800 iteration 6582 : loss : 0.040264, loss_ce: 0.011902
2021-12-14 04:15:29,383 iteration 6583 : loss : 0.052319, loss_ce: 0.017344
2021-12-14 04:15:30,977 iteration 6584 : loss : 0.042807, loss_ce: 0.016622
2021-12-14 04:15:32,608 iteration 6585 : loss : 0.046277, loss_ce: 0.011591
2021-12-14 04:15:34,223 iteration 6586 : loss : 0.055164, loss_ce: 0.016562
2021-12-14 04:15:35,796 iteration 6587 : loss : 0.047384, loss_ce: 0.015960
2021-12-14 04:15:37,393 iteration 6588 : loss : 0.044534, loss_ce: 0.017189
2021-12-14 04:15:38,917 iteration 6589 : loss : 0.041436, loss_ce: 0.013271
2021-12-14 04:15:40,561 iteration 6590 : loss : 0.045239, loss_ce: 0.018067
2021-12-14 04:15:42,199 iteration 6591 : loss : 0.050265, loss_ce: 0.017970
2021-12-14 04:15:43,746 iteration 6592 : loss : 0.039356, loss_ce: 0.015159
2021-12-14 04:15:45,392 iteration 6593 : loss : 0.050824, loss_ce: 0.009733
2021-12-14 04:15:46,959 iteration 6594 : loss : 0.044099, loss_ce: 0.019291
2021-12-14 04:15:48,511 iteration 6595 : loss : 0.036966, loss_ce: 0.010239
2021-12-14 04:15:50,137 iteration 6596 : loss : 0.057367, loss_ce: 0.018597
 97%|████████████████████████████▏| 388/400 [3:10:47<05:40, 28.36s/it]2021-12-14 04:15:51,753 iteration 6597 : loss : 0.046673, loss_ce: 0.018060
2021-12-14 04:15:53,274 iteration 6598 : loss : 0.059449, loss_ce: 0.012490
2021-12-14 04:15:54,871 iteration 6599 : loss : 0.050302, loss_ce: 0.018954
2021-12-14 04:15:56,338 iteration 6600 : loss : 0.039256, loss_ce: 0.013817
2021-12-14 04:15:57,898 iteration 6601 : loss : 0.039130, loss_ce: 0.011508
2021-12-14 04:15:59,431 iteration 6602 : loss : 0.045575, loss_ce: 0.014441
2021-12-14 04:16:01,001 iteration 6603 : loss : 0.046254, loss_ce: 0.014317
2021-12-14 04:16:02,491 iteration 6604 : loss : 0.034110, loss_ce: 0.011538
2021-12-14 04:16:04,062 iteration 6605 : loss : 0.043968, loss_ce: 0.013913
2021-12-14 04:16:05,662 iteration 6606 : loss : 0.046754, loss_ce: 0.018267
2021-12-14 04:16:07,266 iteration 6607 : loss : 0.042359, loss_ce: 0.016236
2021-12-14 04:16:08,868 iteration 6608 : loss : 0.039984, loss_ce: 0.013766
2021-12-14 04:16:10,405 iteration 6609 : loss : 0.041416, loss_ce: 0.013819
2021-12-14 04:16:11,954 iteration 6610 : loss : 0.043174, loss_ce: 0.014644
2021-12-14 04:16:13,500 iteration 6611 : loss : 0.040016, loss_ce: 0.009508
2021-12-14 04:16:15,112 iteration 6612 : loss : 0.054321, loss_ce: 0.020229
2021-12-14 04:16:16,576 iteration 6613 : loss : 0.043163, loss_ce: 0.014897
 97%|████████████████████████████▏| 389/400 [3:11:13<05:05, 27.79s/it]2021-12-14 04:16:18,194 iteration 6614 : loss : 0.047645, loss_ce: 0.016875
2021-12-14 04:16:19,784 iteration 6615 : loss : 0.043540, loss_ce: 0.015958
2021-12-14 04:16:21,346 iteration 6616 : loss : 0.047863, loss_ce: 0.014050
2021-12-14 04:16:23,057 iteration 6617 : loss : 0.043818, loss_ce: 0.014162
2021-12-14 04:16:24,658 iteration 6618 : loss : 0.046460, loss_ce: 0.011431
2021-12-14 04:16:26,322 iteration 6619 : loss : 0.054795, loss_ce: 0.020456
2021-12-14 04:16:27,947 iteration 6620 : loss : 0.057365, loss_ce: 0.022088
2021-12-14 04:16:29,507 iteration 6621 : loss : 0.060602, loss_ce: 0.020717
2021-12-14 04:16:31,065 iteration 6622 : loss : 0.049014, loss_ce: 0.020090
2021-12-14 04:16:32,629 iteration 6623 : loss : 0.048792, loss_ce: 0.014192
2021-12-14 04:16:34,243 iteration 6624 : loss : 0.074552, loss_ce: 0.026126
2021-12-14 04:16:35,884 iteration 6625 : loss : 0.042940, loss_ce: 0.015081
2021-12-14 04:16:37,462 iteration 6626 : loss : 0.058370, loss_ce: 0.017156
2021-12-14 04:16:38,961 iteration 6627 : loss : 0.040484, loss_ce: 0.012125
2021-12-14 04:16:40,530 iteration 6628 : loss : 0.047305, loss_ce: 0.018161
2021-12-14 04:16:42,098 iteration 6629 : loss : 0.041642, loss_ce: 0.017359
2021-12-14 04:16:42,098 Training Data Eval:
2021-12-14 04:16:50,270   Average segmentation loss on training set: 0.0327
2021-12-14 04:16:50,270 Validation Data Eval:
2021-12-14 04:16:53,062   Average segmentation loss on validation set: 0.0881
2021-12-14 04:16:54,675 iteration 6630 : loss : 0.047107, loss_ce: 0.014003
 98%|████████████████████████████▎| 390/400 [3:11:51<05:08, 30.88s/it]2021-12-14 04:16:56,376 iteration 6631 : loss : 0.049882, loss_ce: 0.016443
2021-12-14 04:16:57,962 iteration 6632 : loss : 0.048922, loss_ce: 0.018015
2021-12-14 04:16:59,543 iteration 6633 : loss : 0.042818, loss_ce: 0.010931
2021-12-14 04:17:00,998 iteration 6634 : loss : 0.041261, loss_ce: 0.012327
2021-12-14 04:17:02,524 iteration 6635 : loss : 0.047288, loss_ce: 0.011910
2021-12-14 04:17:04,146 iteration 6636 : loss : 0.043985, loss_ce: 0.015763
2021-12-14 04:17:05,743 iteration 6637 : loss : 0.042446, loss_ce: 0.015681
2021-12-14 04:17:07,365 iteration 6638 : loss : 0.050983, loss_ce: 0.015731
2021-12-14 04:17:09,020 iteration 6639 : loss : 0.060646, loss_ce: 0.019759
2021-12-14 04:17:10,593 iteration 6640 : loss : 0.045985, loss_ce: 0.012406
2021-12-14 04:17:12,136 iteration 6641 : loss : 0.044168, loss_ce: 0.019850
2021-12-14 04:17:13,790 iteration 6642 : loss : 0.043222, loss_ce: 0.015823
2021-12-14 04:17:15,387 iteration 6643 : loss : 0.045832, loss_ce: 0.015989
2021-12-14 04:17:16,965 iteration 6644 : loss : 0.047227, loss_ce: 0.015547
2021-12-14 04:17:18,482 iteration 6645 : loss : 0.040656, loss_ce: 0.011674
2021-12-14 04:17:20,032 iteration 6646 : loss : 0.045211, loss_ce: 0.017589
2021-12-14 04:17:21,515 iteration 6647 : loss : 0.043068, loss_ce: 0.013267
 98%|████████████████████████████▎| 391/400 [3:12:18<04:27, 29.67s/it]2021-12-14 04:17:23,099 iteration 6648 : loss : 0.045667, loss_ce: 0.013690
2021-12-14 04:17:24,734 iteration 6649 : loss : 0.047154, loss_ce: 0.017789
2021-12-14 04:17:26,245 iteration 6650 : loss : 0.051358, loss_ce: 0.018561
2021-12-14 04:17:27,777 iteration 6651 : loss : 0.042499, loss_ce: 0.013078
2021-12-14 04:17:29,421 iteration 6652 : loss : 0.056475, loss_ce: 0.018830
2021-12-14 04:17:31,052 iteration 6653 : loss : 0.055521, loss_ce: 0.020732
2021-12-14 04:17:32,591 iteration 6654 : loss : 0.042057, loss_ce: 0.013983
2021-12-14 04:17:34,184 iteration 6655 : loss : 0.041000, loss_ce: 0.014371
2021-12-14 04:17:35,792 iteration 6656 : loss : 0.036685, loss_ce: 0.013132
2021-12-14 04:17:37,469 iteration 6657 : loss : 0.062611, loss_ce: 0.022375
2021-12-14 04:17:39,072 iteration 6658 : loss : 0.051844, loss_ce: 0.018663
2021-12-14 04:17:40,697 iteration 6659 : loss : 0.043810, loss_ce: 0.013491
2021-12-14 04:17:42,234 iteration 6660 : loss : 0.035003, loss_ce: 0.010235
2021-12-14 04:17:43,727 iteration 6661 : loss : 0.035787, loss_ce: 0.011696
2021-12-14 04:17:45,321 iteration 6662 : loss : 0.040082, loss_ce: 0.011506
2021-12-14 04:17:46,950 iteration 6663 : loss : 0.045701, loss_ce: 0.015466
2021-12-14 04:17:48,516 iteration 6664 : loss : 0.039267, loss_ce: 0.010175
 98%|████████████████████████████▍| 392/400 [3:12:45<03:50, 28.87s/it]2021-12-14 04:17:50,166 iteration 6665 : loss : 0.045945, loss_ce: 0.014949
2021-12-14 04:17:51,760 iteration 6666 : loss : 0.048359, loss_ce: 0.016318
2021-12-14 04:17:53,301 iteration 6667 : loss : 0.048311, loss_ce: 0.015644
2021-12-14 04:17:54,774 iteration 6668 : loss : 0.034236, loss_ce: 0.012033
2021-12-14 04:17:56,359 iteration 6669 : loss : 0.050228, loss_ce: 0.015828
2021-12-14 04:17:57,871 iteration 6670 : loss : 0.041478, loss_ce: 0.014080
2021-12-14 04:17:59,516 iteration 6671 : loss : 0.040212, loss_ce: 0.012759
2021-12-14 04:18:01,111 iteration 6672 : loss : 0.050429, loss_ce: 0.021060
2021-12-14 04:18:02,763 iteration 6673 : loss : 0.045566, loss_ce: 0.018322
2021-12-14 04:18:04,409 iteration 6674 : loss : 0.047872, loss_ce: 0.016381
2021-12-14 04:18:05,960 iteration 6675 : loss : 0.042955, loss_ce: 0.011948
2021-12-14 04:18:07,467 iteration 6676 : loss : 0.036351, loss_ce: 0.011141
2021-12-14 04:18:09,061 iteration 6677 : loss : 0.038717, loss_ce: 0.008300
2021-12-14 04:18:10,735 iteration 6678 : loss : 0.049766, loss_ce: 0.017305
2021-12-14 04:18:12,340 iteration 6679 : loss : 0.045963, loss_ce: 0.013679
2021-12-14 04:18:13,900 iteration 6680 : loss : 0.059491, loss_ce: 0.021333
2021-12-14 04:18:15,426 iteration 6681 : loss : 0.044402, loss_ce: 0.012912
 98%|████████████████████████████▍| 393/400 [3:13:12<03:17, 28.28s/it]2021-12-14 04:18:17,051 iteration 6682 : loss : 0.050553, loss_ce: 0.015132
2021-12-14 04:18:18,676 iteration 6683 : loss : 0.048450, loss_ce: 0.014068
2021-12-14 04:18:20,271 iteration 6684 : loss : 0.064590, loss_ce: 0.011587
2021-12-14 04:18:21,829 iteration 6685 : loss : 0.041690, loss_ce: 0.013243
2021-12-14 04:18:23,419 iteration 6686 : loss : 0.048127, loss_ce: 0.013581
2021-12-14 04:18:25,010 iteration 6687 : loss : 0.044442, loss_ce: 0.016281
2021-12-14 04:18:26,602 iteration 6688 : loss : 0.042468, loss_ce: 0.012686
2021-12-14 04:18:28,155 iteration 6689 : loss : 0.050138, loss_ce: 0.019294
2021-12-14 04:18:29,797 iteration 6690 : loss : 0.044326, loss_ce: 0.014359
2021-12-14 04:18:31,322 iteration 6691 : loss : 0.041696, loss_ce: 0.014004
2021-12-14 04:18:32,842 iteration 6692 : loss : 0.039893, loss_ce: 0.016672
2021-12-14 04:18:34,437 iteration 6693 : loss : 0.038833, loss_ce: 0.012485
2021-12-14 04:18:35,948 iteration 6694 : loss : 0.040095, loss_ce: 0.013968
2021-12-14 04:18:37,505 iteration 6695 : loss : 0.044215, loss_ce: 0.012443
2021-12-14 04:18:39,087 iteration 6696 : loss : 0.046632, loss_ce: 0.022631
2021-12-14 04:18:40,666 iteration 6697 : loss : 0.049118, loss_ce: 0.017790
2021-12-14 04:18:42,167 iteration 6698 : loss : 0.049978, loss_ce: 0.014818
 98%|████████████████████████████▌| 394/400 [3:13:39<02:46, 27.82s/it]2021-12-14 04:18:43,800 iteration 6699 : loss : 0.046787, loss_ce: 0.010777
2021-12-14 04:18:45,432 iteration 6700 : loss : 0.044577, loss_ce: 0.017099
2021-12-14 04:18:47,089 iteration 6701 : loss : 0.053672, loss_ce: 0.018771
2021-12-14 04:18:48,634 iteration 6702 : loss : 0.045017, loss_ce: 0.013658
2021-12-14 04:18:50,302 iteration 6703 : loss : 0.048260, loss_ce: 0.013355
2021-12-14 04:18:51,886 iteration 6704 : loss : 0.046209, loss_ce: 0.019518
2021-12-14 04:18:53,403 iteration 6705 : loss : 0.041205, loss_ce: 0.010757
2021-12-14 04:18:54,949 iteration 6706 : loss : 0.044122, loss_ce: 0.015514
2021-12-14 04:18:56,513 iteration 6707 : loss : 0.042714, loss_ce: 0.014457
2021-12-14 04:18:58,003 iteration 6708 : loss : 0.039502, loss_ce: 0.010785
2021-12-14 04:18:59,522 iteration 6709 : loss : 0.044282, loss_ce: 0.012099
2021-12-14 04:19:01,098 iteration 6710 : loss : 0.040704, loss_ce: 0.013229
2021-12-14 04:19:02,662 iteration 6711 : loss : 0.042874, loss_ce: 0.015343
2021-12-14 04:19:04,270 iteration 6712 : loss : 0.045049, loss_ce: 0.016191
2021-12-14 04:19:05,813 iteration 6713 : loss : 0.043314, loss_ce: 0.012960
2021-12-14 04:19:07,370 iteration 6714 : loss : 0.040595, loss_ce: 0.013975
2021-12-14 04:19:07,370 Training Data Eval:
2021-12-14 04:19:15,531   Average segmentation loss on training set: 0.0328
2021-12-14 04:19:15,531 Validation Data Eval:
2021-12-14 04:19:18,327   Average segmentation loss on validation set: 0.0892
2021-12-14 04:19:19,856 iteration 6715 : loss : 0.037794, loss_ce: 0.010658
 99%|████████████████████████████▋| 395/400 [3:14:16<02:33, 30.78s/it]2021-12-14 04:19:21,404 iteration 6716 : loss : 0.037706, loss_ce: 0.012186
2021-12-14 04:19:23,004 iteration 6717 : loss : 0.046896, loss_ce: 0.014221
2021-12-14 04:19:24,648 iteration 6718 : loss : 0.056785, loss_ce: 0.026362
2021-12-14 04:19:26,274 iteration 6719 : loss : 0.054399, loss_ce: 0.017812
2021-12-14 04:19:27,878 iteration 6720 : loss : 0.061950, loss_ce: 0.011244
2021-12-14 04:19:29,486 iteration 6721 : loss : 0.049681, loss_ce: 0.019406
2021-12-14 04:19:31,042 iteration 6722 : loss : 0.042826, loss_ce: 0.013354
2021-12-14 04:19:32,624 iteration 6723 : loss : 0.046113, loss_ce: 0.015606
2021-12-14 04:19:34,147 iteration 6724 : loss : 0.048025, loss_ce: 0.015521
2021-12-14 04:19:35,713 iteration 6725 : loss : 0.041659, loss_ce: 0.013345
2021-12-14 04:19:37,212 iteration 6726 : loss : 0.035916, loss_ce: 0.009832
2021-12-14 04:19:38,873 iteration 6727 : loss : 0.058895, loss_ce: 0.018503
2021-12-14 04:19:40,405 iteration 6728 : loss : 0.048844, loss_ce: 0.016118
2021-12-14 04:19:42,022 iteration 6729 : loss : 0.046896, loss_ce: 0.013565
2021-12-14 04:19:43,688 iteration 6730 : loss : 0.047101, loss_ce: 0.017734
2021-12-14 04:19:45,309 iteration 6731 : loss : 0.055298, loss_ce: 0.018008
2021-12-14 04:19:46,886 iteration 6732 : loss : 0.036763, loss_ce: 0.012847
 99%|████████████████████████████▋| 396/400 [3:14:43<01:58, 29.66s/it]2021-12-14 04:19:48,476 iteration 6733 : loss : 0.037094, loss_ce: 0.012946
2021-12-14 04:19:50,042 iteration 6734 : loss : 0.053367, loss_ce: 0.013283
2021-12-14 04:19:51,651 iteration 6735 : loss : 0.046059, loss_ce: 0.014522
2021-12-14 04:19:53,217 iteration 6736 : loss : 0.042553, loss_ce: 0.016796
2021-12-14 04:19:54,744 iteration 6737 : loss : 0.043825, loss_ce: 0.018960
2021-12-14 04:19:56,255 iteration 6738 : loss : 0.043024, loss_ce: 0.013270
2021-12-14 04:19:57,836 iteration 6739 : loss : 0.039617, loss_ce: 0.014793
2021-12-14 04:19:59,448 iteration 6740 : loss : 0.061708, loss_ce: 0.015832
2021-12-14 04:20:01,038 iteration 6741 : loss : 0.048964, loss_ce: 0.018763
2021-12-14 04:20:02,590 iteration 6742 : loss : 0.040629, loss_ce: 0.017618
2021-12-14 04:20:04,104 iteration 6743 : loss : 0.043908, loss_ce: 0.010807
2021-12-14 04:20:05,720 iteration 6744 : loss : 0.045700, loss_ce: 0.015896
2021-12-14 04:20:07,285 iteration 6745 : loss : 0.044662, loss_ce: 0.017607
2021-12-14 04:20:08,788 iteration 6746 : loss : 0.034114, loss_ce: 0.008518
2021-12-14 04:20:10,319 iteration 6747 : loss : 0.039482, loss_ce: 0.012068
2021-12-14 04:20:11,913 iteration 6748 : loss : 0.037208, loss_ce: 0.013955
2021-12-14 04:20:13,467 iteration 6749 : loss : 0.043357, loss_ce: 0.011722
 99%|████████████████████████████▊| 397/400 [3:15:10<01:26, 28.73s/it]2021-12-14 04:20:15,083 iteration 6750 : loss : 0.038155, loss_ce: 0.015583
2021-12-14 04:20:16,717 iteration 6751 : loss : 0.041240, loss_ce: 0.011613
2021-12-14 04:20:18,218 iteration 6752 : loss : 0.037115, loss_ce: 0.010611
2021-12-14 04:20:19,786 iteration 6753 : loss : 0.042445, loss_ce: 0.015531
2021-12-14 04:20:21,384 iteration 6754 : loss : 0.042182, loss_ce: 0.012866
2021-12-14 04:20:22,917 iteration 6755 : loss : 0.045533, loss_ce: 0.013612
2021-12-14 04:20:24,450 iteration 6756 : loss : 0.044047, loss_ce: 0.015890
2021-12-14 04:20:26,080 iteration 6757 : loss : 0.040595, loss_ce: 0.011505
2021-12-14 04:20:27,616 iteration 6758 : loss : 0.040247, loss_ce: 0.016052
2021-12-14 04:20:29,196 iteration 6759 : loss : 0.045107, loss_ce: 0.018133
2021-12-14 04:20:30,839 iteration 6760 : loss : 0.058767, loss_ce: 0.010730
2021-12-14 04:20:32,417 iteration 6761 : loss : 0.044088, loss_ce: 0.014635
2021-12-14 04:20:33,974 iteration 6762 : loss : 0.048559, loss_ce: 0.014725
2021-12-14 04:20:35,606 iteration 6763 : loss : 0.047871, loss_ce: 0.017244
2021-12-14 04:20:37,150 iteration 6764 : loss : 0.053372, loss_ce: 0.018662
2021-12-14 04:20:38,780 iteration 6765 : loss : 0.046473, loss_ce: 0.016343
2021-12-14 04:20:40,325 iteration 6766 : loss : 0.040294, loss_ce: 0.016143
100%|████████████████████████████▊| 398/400 [3:15:37<00:56, 28.17s/it]2021-12-14 04:20:41,945 iteration 6767 : loss : 0.073380, loss_ce: 0.021148
2021-12-14 04:20:43,597 iteration 6768 : loss : 0.056371, loss_ce: 0.016669
2021-12-14 04:20:45,187 iteration 6769 : loss : 0.041970, loss_ce: 0.015663
2021-12-14 04:20:46,740 iteration 6770 : loss : 0.044995, loss_ce: 0.019161
2021-12-14 04:20:48,414 iteration 6771 : loss : 0.058180, loss_ce: 0.014790
2021-12-14 04:20:49,960 iteration 6772 : loss : 0.044052, loss_ce: 0.015463
2021-12-14 04:20:51,407 iteration 6773 : loss : 0.041954, loss_ce: 0.012334
2021-12-14 04:20:52,998 iteration 6774 : loss : 0.060045, loss_ce: 0.015867
2021-12-14 04:20:54,599 iteration 6775 : loss : 0.051711, loss_ce: 0.013412
2021-12-14 04:20:56,162 iteration 6776 : loss : 0.047199, loss_ce: 0.012285
2021-12-14 04:20:57,813 iteration 6777 : loss : 0.045971, loss_ce: 0.019859
2021-12-14 04:20:59,379 iteration 6778 : loss : 0.059017, loss_ce: 0.014615
2021-12-14 04:21:01,041 iteration 6779 : loss : 0.045033, loss_ce: 0.016037
2021-12-14 04:21:02,634 iteration 6780 : loss : 0.045148, loss_ce: 0.017911
2021-12-14 04:21:04,255 iteration 6781 : loss : 0.048279, loss_ce: 0.017663
2021-12-14 04:21:05,876 iteration 6782 : loss : 0.045410, loss_ce: 0.015985
2021-12-14 04:21:07,424 iteration 6783 : loss : 0.042931, loss_ce: 0.013839
100%|████████████████████████████▉| 399/400 [3:16:04<00:27, 27.85s/it]2021-12-14 04:21:09,131 iteration 6784 : loss : 0.051868, loss_ce: 0.016476
2021-12-14 04:21:10,744 iteration 6785 : loss : 0.054580, loss_ce: 0.018007
2021-12-14 04:21:12,279 iteration 6786 : loss : 0.041286, loss_ce: 0.015049
2021-12-14 04:21:13,826 iteration 6787 : loss : 0.040285, loss_ce: 0.012106
2021-12-14 04:21:15,423 iteration 6788 : loss : 0.045027, loss_ce: 0.016626
2021-12-14 04:21:17,008 iteration 6789 : loss : 0.048225, loss_ce: 0.015321
2021-12-14 04:21:18,563 iteration 6790 : loss : 0.040525, loss_ce: 0.015515
2021-12-14 04:21:20,161 iteration 6791 : loss : 0.048097, loss_ce: 0.015932
2021-12-14 04:21:21,686 iteration 6792 : loss : 0.040827, loss_ce: 0.014181
2021-12-14 04:21:23,325 iteration 6793 : loss : 0.050908, loss_ce: 0.014991
2021-12-14 04:21:24,903 iteration 6794 : loss : 0.054460, loss_ce: 0.017291
2021-12-14 04:21:26,515 iteration 6795 : loss : 0.052441, loss_ce: 0.017750
2021-12-14 04:21:28,141 iteration 6796 : loss : 0.052193, loss_ce: 0.023719
2021-12-14 04:21:29,634 iteration 6797 : loss : 0.039024, loss_ce: 0.011081
2021-12-14 04:21:31,242 iteration 6798 : loss : 0.039701, loss_ce: 0.012228
2021-12-14 04:21:32,908 iteration 6799 : loss : 0.042849, loss_ce: 0.015983
2021-12-14 04:21:32,908 Training Data Eval:
2021-12-14 04:21:41,077   Average segmentation loss on training set: 0.0324
2021-12-14 04:21:41,078 Validation Data Eval:
2021-12-14 04:21:43,866   Average segmentation loss on validation set: 0.0860
2021-12-14 04:21:45,390 iteration 6800 : loss : 0.037460, loss_ce: 0.008649
100%|█████████████████████████████| 400/400 [3:16:42<00:00, 30.88s/it]100%|█████████████████████████████| 400/400 [3:16:42<00:00, 29.51s/it]
