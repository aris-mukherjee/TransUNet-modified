2021-12-16 14:19:54,133 Logging directory: /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/TransUNet/log_dir/trRUNMC_cv1_r3/i2i2l/
2021-12-16 14:19:54,134 Tensorboard directory: /scratch_net/biwidl217_second/arismu/Tensorboard/trRUNMC_cv1_r3/i2i2l/
2021-12-16 14:19:54,134 ============================================================
2021-12-16 14:19:54,134 EXPERIMENT NAME: trRUNMC_cv1_r3/i2i2l/
2021-12-16 14:19:54,134 ============================================================
2021-12-16 14:19:54,134 Loading data...
2021-12-16 14:19:54,134 Reading NCI - RUNMC images...
2021-12-16 14:19:54,134 Data root directory: /itet-stor/arismu/bmicdatasets-originals/Originals/Challenge_Datasets/NCI_Prostate/
2021-12-16 14:19:54,137 Already preprocessed this configuration. Loading now!
2021-12-16 14:19:54,167 Training Images: (256, 256, 286)
2021-12-16 14:19:54,167 Training Labels: (256, 256, 286)
2021-12-16 14:19:54,167 Validation Images: (256, 256, 98)
2021-12-16 14:19:54,167 Validation Labels: (256, 256, 98)
2021-12-16 14:19:54,167 ============================================================
2021-12-16 14:19:54,218 17 iterations per epoch. 6800 max iterations 
  0%|                                         | 0/400 [00:00<?, ?it/s]2021-12-16 14:19:56,910 iteration 1 : loss : 0.909259, loss_ce: 1.086344
2021-12-16 14:19:58,224 iteration 2 : loss : 0.903478, loss_ce: 1.075905
2021-12-16 14:19:59,623 iteration 3 : loss : 0.899539, loss_ce: 1.064465
2021-12-16 14:20:00,937 iteration 4 : loss : 0.891132, loss_ce: 1.043746
2021-12-16 14:20:02,256 iteration 5 : loss : 0.871839, loss_ce: 1.021419
2021-12-16 14:20:03,586 iteration 6 : loss : 0.861239, loss_ce: 0.991313
2021-12-16 14:20:04,967 iteration 7 : loss : 0.831750, loss_ce: 0.957555
2021-12-16 14:20:06,301 iteration 8 : loss : 0.830108, loss_ce: 0.923131
2021-12-16 14:20:07,660 iteration 9 : loss : 0.780159, loss_ce: 0.893778
2021-12-16 14:20:09,043 iteration 10 : loss : 0.785662, loss_ce: 0.851652
2021-12-16 14:20:10,477 iteration 11 : loss : 0.752657, loss_ce: 0.821162
2021-12-16 14:20:11,802 iteration 12 : loss : 0.733731, loss_ce: 0.781816
2021-12-16 14:20:13,113 iteration 13 : loss : 0.715556, loss_ce: 0.747106
2021-12-16 14:20:14,398 iteration 14 : loss : 0.689119, loss_ce: 0.711765
2021-12-16 14:20:15,754 iteration 15 : loss : 0.669767, loss_ce: 0.678901
2021-12-16 14:20:17,089 iteration 16 : loss : 0.653251, loss_ce: 0.646397
2021-12-16 14:20:18,421 iteration 17 : loss : 0.625339, loss_ce: 0.615441
  0%|                               | 1/400 [00:24<2:41:27, 24.28s/it]2021-12-16 14:20:19,866 iteration 18 : loss : 0.619344, loss_ce: 0.570857
2021-12-16 14:20:21,130 iteration 19 : loss : 0.597090, loss_ce: 0.548143
2021-12-16 14:20:22,526 iteration 20 : loss : 0.581958, loss_ce: 0.522483
2021-12-16 14:20:23,830 iteration 21 : loss : 0.569745, loss_ce: 0.483865
2021-12-16 14:20:25,159 iteration 22 : loss : 0.548257, loss_ce: 0.482689
2021-12-16 14:20:26,563 iteration 23 : loss : 0.540119, loss_ce: 0.436544
2021-12-16 14:20:27,898 iteration 24 : loss : 0.526388, loss_ce: 0.430971
2021-12-16 14:20:29,283 iteration 25 : loss : 0.517778, loss_ce: 0.436700
2021-12-16 14:20:30,599 iteration 26 : loss : 0.507324, loss_ce: 0.401642
2021-12-16 14:20:31,860 iteration 27 : loss : 0.496799, loss_ce: 0.392663
2021-12-16 14:20:33,136 iteration 28 : loss : 0.490924, loss_ce: 0.371093
2021-12-16 14:20:34,507 iteration 29 : loss : 0.479283, loss_ce: 0.351119
2021-12-16 14:20:35,868 iteration 30 : loss : 0.478503, loss_ce: 0.349719
2021-12-16 14:20:37,148 iteration 31 : loss : 0.471999, loss_ce: 0.350619
2021-12-16 14:20:38,531 iteration 32 : loss : 0.472342, loss_ce: 0.359601
2021-12-16 14:20:39,905 iteration 33 : loss : 0.460698, loss_ce: 0.330507
2021-12-16 14:20:41,278 iteration 34 : loss : 0.460555, loss_ce: 0.336475
  0%|▏                              | 2/400 [00:47<2:35:23, 23.43s/it]2021-12-16 14:20:42,687 iteration 35 : loss : 0.449748, loss_ce: 0.295414
2021-12-16 14:20:44,077 iteration 36 : loss : 0.446809, loss_ce: 0.296800
2021-12-16 14:20:45,471 iteration 37 : loss : 0.438092, loss_ce: 0.269218
2021-12-16 14:20:46,787 iteration 38 : loss : 0.440577, loss_ce: 0.292046
2021-12-16 14:20:48,109 iteration 39 : loss : 0.441265, loss_ce: 0.290610
2021-12-16 14:20:49,503 iteration 40 : loss : 0.440185, loss_ce: 0.297458
2021-12-16 14:20:50,906 iteration 41 : loss : 0.434043, loss_ce: 0.276747
2021-12-16 14:20:52,280 iteration 42 : loss : 0.432213, loss_ce: 0.274188
2021-12-16 14:20:53,628 iteration 43 : loss : 0.423637, loss_ce: 0.248765
2021-12-16 14:20:55,152 iteration 44 : loss : 0.425856, loss_ce: 0.265404
2021-12-16 14:20:56,611 iteration 45 : loss : 0.424989, loss_ce: 0.260390
2021-12-16 14:20:58,076 iteration 46 : loss : 0.416402, loss_ce: 0.234710
2021-12-16 14:20:59,577 iteration 47 : loss : 0.416393, loss_ce: 0.236039
2021-12-16 14:21:01,047 iteration 48 : loss : 0.416129, loss_ce: 0.242321
2021-12-16 14:21:02,560 iteration 49 : loss : 0.418768, loss_ce: 0.248516
2021-12-16 14:21:03,979 iteration 50 : loss : 0.409864, loss_ce: 0.222525
2021-12-16 14:21:05,381 iteration 51 : loss : 0.414994, loss_ce: 0.239152
  1%|▏                              | 3/400 [01:11<2:37:02, 23.73s/it]2021-12-16 14:21:06,919 iteration 52 : loss : 0.417598, loss_ce: 0.248860
2021-12-16 14:21:08,383 iteration 53 : loss : 0.418160, loss_ce: 0.241017
2021-12-16 14:21:09,822 iteration 54 : loss : 0.403549, loss_ce: 0.211259
2021-12-16 14:21:11,264 iteration 55 : loss : 0.419785, loss_ce: 0.252175
2021-12-16 14:21:12,684 iteration 56 : loss : 0.407437, loss_ce: 0.219614
2021-12-16 14:21:14,130 iteration 57 : loss : 0.397809, loss_ce: 0.209010
2021-12-16 14:21:15,577 iteration 58 : loss : 0.404980, loss_ce: 0.214915
2021-12-16 14:21:17,003 iteration 59 : loss : 0.409589, loss_ce: 0.233386
2021-12-16 14:21:18,473 iteration 60 : loss : 0.404410, loss_ce: 0.218201
2021-12-16 14:21:19,940 iteration 61 : loss : 0.415658, loss_ce: 0.238822
2021-12-16 14:21:21,397 iteration 62 : loss : 0.395128, loss_ce: 0.177127
2021-12-16 14:21:22,782 iteration 63 : loss : 0.400695, loss_ce: 0.218386
2021-12-16 14:21:24,216 iteration 64 : loss : 0.395306, loss_ce: 0.190553
2021-12-16 14:21:25,611 iteration 65 : loss : 0.397366, loss_ce: 0.193953
2021-12-16 14:21:27,033 iteration 66 : loss : 0.402724, loss_ce: 0.218550
2021-12-16 14:21:28,513 iteration 67 : loss : 0.391373, loss_ce: 0.186220
2021-12-16 14:21:29,949 iteration 68 : loss : 0.409926, loss_ce: 0.234411
  1%|▎                              | 4/400 [01:35<2:38:48, 24.06s/it]2021-12-16 14:21:31,465 iteration 69 : loss : 0.402125, loss_ce: 0.215195
2021-12-16 14:21:32,974 iteration 70 : loss : 0.400043, loss_ce: 0.210701
2021-12-16 14:21:34,383 iteration 71 : loss : 0.391807, loss_ce: 0.198209
2021-12-16 14:21:35,842 iteration 72 : loss : 0.395520, loss_ce: 0.202817
2021-12-16 14:21:37,244 iteration 73 : loss : 0.404973, loss_ce: 0.220377
2021-12-16 14:21:38,626 iteration 74 : loss : 0.395441, loss_ce: 0.200761
2021-12-16 14:21:40,038 iteration 75 : loss : 0.398723, loss_ce: 0.205455
2021-12-16 14:21:41,448 iteration 76 : loss : 0.391479, loss_ce: 0.197560
2021-12-16 14:21:42,784 iteration 77 : loss : 0.396242, loss_ce: 0.202341
2021-12-16 14:21:44,208 iteration 78 : loss : 0.400330, loss_ce: 0.209007
2021-12-16 14:21:45,603 iteration 79 : loss : 0.388150, loss_ce: 0.182011
2021-12-16 14:21:47,001 iteration 80 : loss : 0.415160, loss_ce: 0.232230
2021-12-16 14:21:48,389 iteration 81 : loss : 0.394415, loss_ce: 0.196234
2021-12-16 14:21:49,803 iteration 82 : loss : 0.391481, loss_ce: 0.183134
2021-12-16 14:21:51,212 iteration 83 : loss : 0.386686, loss_ce: 0.178889
2021-12-16 14:21:52,696 iteration 84 : loss : 0.415748, loss_ce: 0.243688
2021-12-16 14:21:52,697 Training Data Eval:
2021-12-16 14:22:00,165   Average segmentation loss on training set: 0.3891
2021-12-16 14:22:00,165 Validation Data Eval:
2021-12-16 14:22:03,732   Average segmentation loss on validation set: 0.4211
2021-12-16 14:22:10,031 Found new lowest validation loss at iteration 84! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/TU_3seeds/TU_RESNET_no_pretraining_SGD_best_val_loss_seed1234.pth
2021-12-16 14:22:11,368 iteration 85 : loss : 0.387745, loss_ce: 0.182201
  1%|▍                              | 5/400 [02:17<3:19:36, 30.32s/it]2021-12-16 14:22:12,765 iteration 86 : loss : 0.382150, loss_ce: 0.163088
2021-12-16 14:22:14,217 iteration 87 : loss : 0.389016, loss_ce: 0.193706
2021-12-16 14:22:15,502 iteration 88 : loss : 0.405696, loss_ce: 0.221581
2021-12-16 14:22:16,861 iteration 89 : loss : 0.393608, loss_ce: 0.195286
2021-12-16 14:22:18,213 iteration 90 : loss : 0.388227, loss_ce: 0.190044
2021-12-16 14:22:19,626 iteration 91 : loss : 0.411976, loss_ce: 0.234047
2021-12-16 14:22:20,901 iteration 92 : loss : 0.395665, loss_ce: 0.197268
2021-12-16 14:22:22,219 iteration 93 : loss : 0.381622, loss_ce: 0.167517
2021-12-16 14:22:23,546 iteration 94 : loss : 0.386877, loss_ce: 0.185902
2021-12-16 14:22:24,995 iteration 95 : loss : 0.399839, loss_ce: 0.205035
2021-12-16 14:22:26,325 iteration 96 : loss : 0.394057, loss_ce: 0.200520
2021-12-16 14:22:27,727 iteration 97 : loss : 0.392597, loss_ce: 0.193153
2021-12-16 14:22:29,173 iteration 98 : loss : 0.389631, loss_ce: 0.187796
2021-12-16 14:22:30,697 iteration 99 : loss : 0.397152, loss_ce: 0.205602
2021-12-16 14:22:32,174 iteration 100 : loss : 0.400786, loss_ce: 0.212984
2021-12-16 14:22:33,623 iteration 101 : loss : 0.384942, loss_ce: 0.188668
2021-12-16 14:22:35,009 iteration 102 : loss : 0.385139, loss_ce: 0.183992
  2%|▍                              | 6/400 [02:40<3:04:12, 28.05s/it]2021-12-16 14:22:36,587 iteration 103 : loss : 0.393443, loss_ce: 0.202937
2021-12-16 14:22:38,114 iteration 104 : loss : 0.389117, loss_ce: 0.186942
2021-12-16 14:22:39,681 iteration 105 : loss : 0.381615, loss_ce: 0.168786
2021-12-16 14:22:41,092 iteration 106 : loss : 0.381217, loss_ce: 0.176854
2021-12-16 14:22:42,675 iteration 107 : loss : 0.391106, loss_ce: 0.205771
2021-12-16 14:22:44,065 iteration 108 : loss : 0.380884, loss_ce: 0.176688
2021-12-16 14:22:45,488 iteration 109 : loss : 0.397581, loss_ce: 0.214769
2021-12-16 14:22:46,859 iteration 110 : loss : 0.388338, loss_ce: 0.190289
2021-12-16 14:22:48,327 iteration 111 : loss : 0.386059, loss_ce: 0.189922
2021-12-16 14:22:49,709 iteration 112 : loss : 0.384998, loss_ce: 0.182385
2021-12-16 14:22:51,156 iteration 113 : loss : 0.394733, loss_ce: 0.220724
2021-12-16 14:22:52,568 iteration 114 : loss : 0.370540, loss_ce: 0.165425
2021-12-16 14:22:53,999 iteration 115 : loss : 0.386644, loss_ce: 0.198306
2021-12-16 14:22:55,486 iteration 116 : loss : 0.388802, loss_ce: 0.188187
2021-12-16 14:22:56,962 iteration 117 : loss : 0.401646, loss_ce: 0.215944
2021-12-16 14:22:58,410 iteration 118 : loss : 0.389043, loss_ce: 0.195177
2021-12-16 14:22:59,867 iteration 119 : loss : 0.379646, loss_ce: 0.169812
  2%|▌                              | 7/400 [03:05<2:56:54, 27.01s/it]2021-12-16 14:23:01,322 iteration 120 : loss : 0.385655, loss_ce: 0.191566
2021-12-16 14:23:02,711 iteration 121 : loss : 0.389512, loss_ce: 0.195081
2021-12-16 14:23:04,208 iteration 122 : loss : 0.380466, loss_ce: 0.188890
2021-12-16 14:23:05,668 iteration 123 : loss : 0.379440, loss_ce: 0.181083
2021-12-16 14:23:07,102 iteration 124 : loss : 0.378415, loss_ce: 0.176645
2021-12-16 14:23:08,497 iteration 125 : loss : 0.393444, loss_ce: 0.212932
2021-12-16 14:23:09,955 iteration 126 : loss : 0.379198, loss_ce: 0.173743
2021-12-16 14:23:11,347 iteration 127 : loss : 0.380225, loss_ce: 0.186267
2021-12-16 14:23:12,763 iteration 128 : loss : 0.383090, loss_ce: 0.192044
2021-12-16 14:23:14,246 iteration 129 : loss : 0.377203, loss_ce: 0.171593
2021-12-16 14:23:15,683 iteration 130 : loss : 0.374549, loss_ce: 0.174048
2021-12-16 14:23:17,193 iteration 131 : loss : 0.393276, loss_ce: 0.200570
2021-12-16 14:23:18,709 iteration 132 : loss : 0.375305, loss_ce: 0.150970
2021-12-16 14:23:20,104 iteration 133 : loss : 0.381147, loss_ce: 0.181817
2021-12-16 14:23:21,589 iteration 134 : loss : 0.386107, loss_ce: 0.190290
2021-12-16 14:23:23,102 iteration 135 : loss : 0.391881, loss_ce: 0.210318
2021-12-16 14:23:24,527 iteration 136 : loss : 0.384129, loss_ce: 0.196713
  2%|▌                              | 8/400 [03:30<2:51:33, 26.26s/it]2021-12-16 14:23:26,057 iteration 137 : loss : 0.372190, loss_ce: 0.163843
2021-12-16 14:23:27,464 iteration 138 : loss : 0.395873, loss_ce: 0.214906
2021-12-16 14:23:28,929 iteration 139 : loss : 0.375834, loss_ce: 0.178260
2021-12-16 14:23:30,358 iteration 140 : loss : 0.376560, loss_ce: 0.171159
2021-12-16 14:23:31,841 iteration 141 : loss : 0.389581, loss_ce: 0.200777
2021-12-16 14:23:33,345 iteration 142 : loss : 0.376172, loss_ce: 0.183395
2021-12-16 14:23:34,866 iteration 143 : loss : 0.382518, loss_ce: 0.180187
2021-12-16 14:23:36,339 iteration 144 : loss : 0.373292, loss_ce: 0.171732
2021-12-16 14:23:37,773 iteration 145 : loss : 0.385320, loss_ce: 0.184680
2021-12-16 14:23:39,256 iteration 146 : loss : 0.394275, loss_ce: 0.208361
2021-12-16 14:23:40,726 iteration 147 : loss : 0.373149, loss_ce: 0.177230
2021-12-16 14:23:42,083 iteration 148 : loss : 0.380934, loss_ce: 0.187363
2021-12-16 14:23:43,514 iteration 149 : loss : 0.372834, loss_ce: 0.173906
2021-12-16 14:23:44,920 iteration 150 : loss : 0.359176, loss_ce: 0.152967
2021-12-16 14:23:46,339 iteration 151 : loss : 0.384010, loss_ce: 0.198958
2021-12-16 14:23:47,759 iteration 152 : loss : 0.366000, loss_ce: 0.156531
2021-12-16 14:23:49,218 iteration 153 : loss : 0.383201, loss_ce: 0.193746
  2%|▋                              | 9/400 [03:55<2:47:56, 25.77s/it]2021-12-16 14:23:50,642 iteration 154 : loss : 0.387939, loss_ce: 0.196284
2021-12-16 14:23:52,090 iteration 155 : loss : 0.364433, loss_ce: 0.156162
2021-12-16 14:23:53,617 iteration 156 : loss : 0.372979, loss_ce: 0.169814
2021-12-16 14:23:55,066 iteration 157 : loss : 0.370466, loss_ce: 0.161493
2021-12-16 14:23:56,627 iteration 158 : loss : 0.373679, loss_ce: 0.186380
2021-12-16 14:23:57,969 iteration 159 : loss : 0.369527, loss_ce: 0.171427
2021-12-16 14:23:59,478 iteration 160 : loss : 0.361729, loss_ce: 0.153049
2021-12-16 14:24:00,983 iteration 161 : loss : 0.368519, loss_ce: 0.160696
2021-12-16 14:24:02,480 iteration 162 : loss : 0.380988, loss_ce: 0.195044
2021-12-16 14:24:03,958 iteration 163 : loss : 0.369726, loss_ce: 0.168271
2021-12-16 14:24:05,422 iteration 164 : loss : 0.361896, loss_ce: 0.154568
2021-12-16 14:24:06,862 iteration 165 : loss : 0.369751, loss_ce: 0.180391
2021-12-16 14:24:08,288 iteration 166 : loss : 0.372345, loss_ce: 0.175441
2021-12-16 14:24:09,730 iteration 167 : loss : 0.367876, loss_ce: 0.171500
2021-12-16 14:24:11,212 iteration 168 : loss : 0.386957, loss_ce: 0.208940
2021-12-16 14:24:12,663 iteration 169 : loss : 0.384189, loss_ce: 0.210042
2021-12-16 14:24:12,664 Training Data Eval:
2021-12-16 14:24:20,112   Average segmentation loss on training set: 0.3673
2021-12-16 14:24:20,112 Validation Data Eval:
2021-12-16 14:24:22,688   Average segmentation loss on validation set: 0.3915
2021-12-16 14:24:28,984 Found new lowest validation loss at iteration 169! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/TU_3seeds/TU_RESNET_no_pretraining_SGD_best_val_loss_seed1234.pth
2021-12-16 14:24:30,406 iteration 170 : loss : 0.374642, loss_ce: 0.183112
  2%|▊                             | 10/400 [04:36<3:18:25, 30.53s/it]2021-12-16 14:24:31,799 iteration 171 : loss : 0.374369, loss_ce: 0.169417
2021-12-16 14:24:33,165 iteration 172 : loss : 0.377922, loss_ce: 0.191322
2021-12-16 14:24:34,545 iteration 173 : loss : 0.373696, loss_ce: 0.179899
2021-12-16 14:24:35,840 iteration 174 : loss : 0.374103, loss_ce: 0.185572
2021-12-16 14:24:37,128 iteration 175 : loss : 0.366019, loss_ce: 0.163278
2021-12-16 14:24:38,485 iteration 176 : loss : 0.378455, loss_ce: 0.202504
2021-12-16 14:24:39,814 iteration 177 : loss : 0.362000, loss_ce: 0.153963
2021-12-16 14:24:41,147 iteration 178 : loss : 0.379712, loss_ce: 0.201507
2021-12-16 14:24:42,477 iteration 179 : loss : 0.364708, loss_ce: 0.173899
2021-12-16 14:24:43,814 iteration 180 : loss : 0.363807, loss_ce: 0.153972
2021-12-16 14:24:45,262 iteration 181 : loss : 0.364692, loss_ce: 0.174667
2021-12-16 14:24:46,686 iteration 182 : loss : 0.366201, loss_ce: 0.179858
2021-12-16 14:24:48,088 iteration 183 : loss : 0.362163, loss_ce: 0.155978
2021-12-16 14:24:49,453 iteration 184 : loss : 0.360037, loss_ce: 0.165520
2021-12-16 14:24:50,931 iteration 185 : loss : 0.362997, loss_ce: 0.156681
2021-12-16 14:24:52,414 iteration 186 : loss : 0.378160, loss_ce: 0.191499
2021-12-16 14:24:53,924 iteration 187 : loss : 0.372462, loss_ce: 0.177508
  3%|▊                             | 11/400 [04:59<3:04:00, 28.38s/it]2021-12-16 14:24:55,441 iteration 188 : loss : 0.364495, loss_ce: 0.157277
2021-12-16 14:24:56,912 iteration 189 : loss : 0.366864, loss_ce: 0.181299
2021-12-16 14:24:58,388 iteration 190 : loss : 0.355708, loss_ce: 0.159645
2021-12-16 14:24:59,814 iteration 191 : loss : 0.363905, loss_ce: 0.175808
2021-12-16 14:25:01,204 iteration 192 : loss : 0.366814, loss_ce: 0.185274
2021-12-16 14:25:02,705 iteration 193 : loss : 0.370910, loss_ce: 0.183063
2021-12-16 14:25:04,158 iteration 194 : loss : 0.353833, loss_ce: 0.133510
2021-12-16 14:25:05,577 iteration 195 : loss : 0.372506, loss_ce: 0.181523
2021-12-16 14:25:06,945 iteration 196 : loss : 0.361375, loss_ce: 0.150756
2021-12-16 14:25:08,399 iteration 197 : loss : 0.365640, loss_ce: 0.167647
2021-12-16 14:25:09,876 iteration 198 : loss : 0.369285, loss_ce: 0.183858
2021-12-16 14:25:11,289 iteration 199 : loss : 0.368664, loss_ce: 0.170883
2021-12-16 14:25:12,719 iteration 200 : loss : 0.364273, loss_ce: 0.173703
2021-12-16 14:25:14,171 iteration 201 : loss : 0.363653, loss_ce: 0.171818
2021-12-16 14:25:15,628 iteration 202 : loss : 0.370745, loss_ce: 0.195686
2021-12-16 14:25:17,034 iteration 203 : loss : 0.360619, loss_ce: 0.169407
2021-12-16 14:25:18,564 iteration 204 : loss : 0.348684, loss_ce: 0.152204
  3%|▉                             | 12/400 [05:24<2:56:10, 27.24s/it]2021-12-16 14:25:20,022 iteration 205 : loss : 0.356740, loss_ce: 0.159817
2021-12-16 14:25:21,465 iteration 206 : loss : 0.353479, loss_ce: 0.147814
2021-12-16 14:25:22,932 iteration 207 : loss : 0.361751, loss_ce: 0.185218
2021-12-16 14:25:24,362 iteration 208 : loss : 0.356495, loss_ce: 0.138925
2021-12-16 14:25:25,860 iteration 209 : loss : 0.372944, loss_ce: 0.197493
2021-12-16 14:25:27,213 iteration 210 : loss : 0.355339, loss_ce: 0.153671
2021-12-16 14:25:28,689 iteration 211 : loss : 0.371876, loss_ce: 0.190835
2021-12-16 14:25:30,150 iteration 212 : loss : 0.354136, loss_ce: 0.149907
2021-12-16 14:25:31,694 iteration 213 : loss : 0.369627, loss_ce: 0.190507
2021-12-16 14:25:33,145 iteration 214 : loss : 0.358764, loss_ce: 0.148661
2021-12-16 14:25:34,601 iteration 215 : loss : 0.352952, loss_ce: 0.160944
2021-12-16 14:25:36,199 iteration 216 : loss : 0.354530, loss_ce: 0.159431
2021-12-16 14:25:37,710 iteration 217 : loss : 0.355481, loss_ce: 0.168160
2021-12-16 14:25:39,129 iteration 218 : loss : 0.364641, loss_ce: 0.184566
2021-12-16 14:25:40,466 iteration 219 : loss : 0.361624, loss_ce: 0.176065
2021-12-16 14:25:41,942 iteration 220 : loss : 0.374820, loss_ce: 0.193634
2021-12-16 14:25:43,399 iteration 221 : loss : 0.351913, loss_ce: 0.147663
  3%|▉                             | 13/400 [05:49<2:51:01, 26.51s/it]2021-12-16 14:25:44,904 iteration 222 : loss : 0.357386, loss_ce: 0.179172
2021-12-16 14:25:46,387 iteration 223 : loss : 0.351041, loss_ce: 0.168359
2021-12-16 14:25:47,844 iteration 224 : loss : 0.361491, loss_ce: 0.166403
2021-12-16 14:25:49,381 iteration 225 : loss : 0.347402, loss_ce: 0.126439
2021-12-16 14:25:50,813 iteration 226 : loss : 0.345004, loss_ce: 0.150556
2021-12-16 14:25:52,290 iteration 227 : loss : 0.366936, loss_ce: 0.187866
2021-12-16 14:25:53,723 iteration 228 : loss : 0.356987, loss_ce: 0.170830
2021-12-16 14:25:55,126 iteration 229 : loss : 0.343188, loss_ce: 0.153109
2021-12-16 14:25:56,566 iteration 230 : loss : 0.359236, loss_ce: 0.170353
2021-12-16 14:25:58,048 iteration 231 : loss : 0.363472, loss_ce: 0.161913
2021-12-16 14:25:59,616 iteration 232 : loss : 0.357688, loss_ce: 0.173120
2021-12-16 14:26:01,021 iteration 233 : loss : 0.361390, loss_ce: 0.168978
2021-12-16 14:26:02,534 iteration 234 : loss : 0.352607, loss_ce: 0.162002
2021-12-16 14:26:03,964 iteration 235 : loss : 0.360786, loss_ce: 0.170308
2021-12-16 14:26:05,431 iteration 236 : loss : 0.364395, loss_ce: 0.164947
2021-12-16 14:26:06,851 iteration 237 : loss : 0.349727, loss_ce: 0.167752
2021-12-16 14:26:08,293 iteration 238 : loss : 0.356481, loss_ce: 0.179995
  4%|█                             | 14/400 [06:14<2:47:26, 26.03s/it]2021-12-16 14:26:09,736 iteration 239 : loss : 0.349804, loss_ce: 0.140918
2021-12-16 14:26:11,217 iteration 240 : loss : 0.355927, loss_ce: 0.182225
2021-12-16 14:26:12,692 iteration 241 : loss : 0.344609, loss_ce: 0.148058
2021-12-16 14:26:14,135 iteration 242 : loss : 0.367822, loss_ce: 0.192004
2021-12-16 14:26:15,700 iteration 243 : loss : 0.366334, loss_ce: 0.180621
2021-12-16 14:26:17,089 iteration 244 : loss : 0.342705, loss_ce: 0.127401
2021-12-16 14:26:18,562 iteration 245 : loss : 0.358741, loss_ce: 0.183930
2021-12-16 14:26:20,071 iteration 246 : loss : 0.356945, loss_ce: 0.168250
2021-12-16 14:26:21,510 iteration 247 : loss : 0.332375, loss_ce: 0.145824
2021-12-16 14:26:22,944 iteration 248 : loss : 0.341611, loss_ce: 0.135407
2021-12-16 14:26:24,365 iteration 249 : loss : 0.367799, loss_ce: 0.193680
2021-12-16 14:26:25,809 iteration 250 : loss : 0.344527, loss_ce: 0.154668
2021-12-16 14:26:27,195 iteration 251 : loss : 0.341411, loss_ce: 0.142962
2021-12-16 14:26:28,636 iteration 252 : loss : 0.346470, loss_ce: 0.162834
2021-12-16 14:26:30,109 iteration 253 : loss : 0.356401, loss_ce: 0.170157
2021-12-16 14:26:31,621 iteration 254 : loss : 0.355811, loss_ce: 0.144376
2021-12-16 14:26:31,621 Training Data Eval:
2021-12-16 14:26:39,083   Average segmentation loss on training set: 0.3441
2021-12-16 14:26:39,084 Validation Data Eval:
2021-12-16 14:26:41,665   Average segmentation loss on validation set: 0.3591
2021-12-16 14:26:48,288 Found new lowest validation loss at iteration 254! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/TU_3seeds/TU_RESNET_no_pretraining_SGD_best_val_loss_seed1234.pth
2021-12-16 14:26:49,622 iteration 255 : loss : 0.344874, loss_ce: 0.151393
  4%|█▏                            | 15/400 [06:55<3:16:36, 30.64s/it]2021-12-16 14:26:51,024 iteration 256 : loss : 0.347463, loss_ce: 0.161172
2021-12-16 14:26:52,418 iteration 257 : loss : 0.340449, loss_ce: 0.162416
2021-12-16 14:26:53,855 iteration 258 : loss : 0.344876, loss_ce: 0.162079
2021-12-16 14:26:55,121 iteration 259 : loss : 0.352212, loss_ce: 0.175745
2021-12-16 14:26:56,528 iteration 260 : loss : 0.350604, loss_ce: 0.173715
2021-12-16 14:26:57,891 iteration 261 : loss : 0.333075, loss_ce: 0.144229
2021-12-16 14:26:59,338 iteration 262 : loss : 0.351221, loss_ce: 0.168701
2021-12-16 14:27:00,690 iteration 263 : loss : 0.362814, loss_ce: 0.149686
2021-12-16 14:27:02,070 iteration 264 : loss : 0.367430, loss_ce: 0.188594
2021-12-16 14:27:03,385 iteration 265 : loss : 0.337253, loss_ce: 0.160659
2021-12-16 14:27:04,805 iteration 266 : loss : 0.348770, loss_ce: 0.162927
2021-12-16 14:27:06,246 iteration 267 : loss : 0.335055, loss_ce: 0.132179
2021-12-16 14:27:07,715 iteration 268 : loss : 0.339058, loss_ce: 0.155164
2021-12-16 14:27:09,355 iteration 269 : loss : 0.353510, loss_ce: 0.153656
2021-12-16 14:27:10,897 iteration 270 : loss : 0.338636, loss_ce: 0.159892
2021-12-16 14:27:12,233 iteration 271 : loss : 0.335122, loss_ce: 0.133210
2021-12-16 14:27:13,699 iteration 272 : loss : 0.359593, loss_ce: 0.184162
  4%|█▏                            | 16/400 [07:19<3:03:27, 28.66s/it]2021-12-16 14:27:15,154 iteration 273 : loss : 0.353272, loss_ce: 0.157907
2021-12-16 14:27:16,554 iteration 274 : loss : 0.347326, loss_ce: 0.163561
2021-12-16 14:27:17,963 iteration 275 : loss : 0.333340, loss_ce: 0.153522
2021-12-16 14:27:19,425 iteration 276 : loss : 0.348969, loss_ce: 0.176335
2021-12-16 14:27:20,912 iteration 277 : loss : 0.331704, loss_ce: 0.140575
2021-12-16 14:27:22,247 iteration 278 : loss : 0.337107, loss_ce: 0.143209
2021-12-16 14:27:23,646 iteration 279 : loss : 0.337908, loss_ce: 0.134692
2021-12-16 14:27:25,045 iteration 280 : loss : 0.340188, loss_ce: 0.154953
2021-12-16 14:27:26,503 iteration 281 : loss : 0.345186, loss_ce: 0.153879
2021-12-16 14:27:27,937 iteration 282 : loss : 0.341713, loss_ce: 0.150915
2021-12-16 14:27:29,365 iteration 283 : loss : 0.340772, loss_ce: 0.159177
2021-12-16 14:27:30,883 iteration 284 : loss : 0.348284, loss_ce: 0.180807
2021-12-16 14:27:32,276 iteration 285 : loss : 0.324196, loss_ce: 0.143936
2021-12-16 14:27:33,698 iteration 286 : loss : 0.354231, loss_ce: 0.172003
2021-12-16 14:27:35,233 iteration 287 : loss : 0.338395, loss_ce: 0.160191
2021-12-16 14:27:36,747 iteration 288 : loss : 0.319555, loss_ce: 0.140232
2021-12-16 14:27:38,189 iteration 289 : loss : 0.324125, loss_ce: 0.138439
  4%|█▎                            | 17/400 [07:44<2:54:57, 27.41s/it]2021-12-16 14:27:39,704 iteration 290 : loss : 0.326890, loss_ce: 0.139881
2021-12-16 14:27:41,124 iteration 291 : loss : 0.335553, loss_ce: 0.141570
2021-12-16 14:27:42,553 iteration 292 : loss : 0.342724, loss_ce: 0.154238
2021-12-16 14:27:43,987 iteration 293 : loss : 0.335705, loss_ce: 0.151888
2021-12-16 14:27:45,459 iteration 294 : loss : 0.336808, loss_ce: 0.152883
2021-12-16 14:27:47,011 iteration 295 : loss : 0.323622, loss_ce: 0.139376
2021-12-16 14:27:48,432 iteration 296 : loss : 0.325401, loss_ce: 0.141444
2021-12-16 14:27:49,902 iteration 297 : loss : 0.336036, loss_ce: 0.144713
2021-12-16 14:27:51,330 iteration 298 : loss : 0.321169, loss_ce: 0.139122
2021-12-16 14:27:52,796 iteration 299 : loss : 0.331164, loss_ce: 0.150785
2021-12-16 14:27:54,234 iteration 300 : loss : 0.331768, loss_ce: 0.142154
2021-12-16 14:27:55,698 iteration 301 : loss : 0.345214, loss_ce: 0.176878
2021-12-16 14:27:57,188 iteration 302 : loss : 0.346122, loss_ce: 0.158391
2021-12-16 14:27:58,664 iteration 303 : loss : 0.324841, loss_ce: 0.160248
2021-12-16 14:28:00,141 iteration 304 : loss : 0.345290, loss_ce: 0.162057
2021-12-16 14:28:01,638 iteration 305 : loss : 0.341805, loss_ce: 0.153421
2021-12-16 14:28:03,120 iteration 306 : loss : 0.324535, loss_ce: 0.161159
  4%|█▎                            | 18/400 [08:08<2:49:45, 26.66s/it]2021-12-16 14:28:04,606 iteration 307 : loss : 0.343432, loss_ce: 0.141579
2021-12-16 14:28:06,013 iteration 308 : loss : 0.340351, loss_ce: 0.170674
2021-12-16 14:28:07,481 iteration 309 : loss : 0.339275, loss_ce: 0.134031
2021-12-16 14:28:08,992 iteration 310 : loss : 0.317206, loss_ce: 0.140713
2021-12-16 14:28:10,410 iteration 311 : loss : 0.329369, loss_ce: 0.134739
2021-12-16 14:28:11,867 iteration 312 : loss : 0.334079, loss_ce: 0.170142
2021-12-16 14:28:13,311 iteration 313 : loss : 0.325881, loss_ce: 0.172540
2021-12-16 14:28:14,695 iteration 314 : loss : 0.344885, loss_ce: 0.165597
2021-12-16 14:28:16,144 iteration 315 : loss : 0.327925, loss_ce: 0.133491
2021-12-16 14:28:17,619 iteration 316 : loss : 0.310641, loss_ce: 0.134366
2021-12-16 14:28:19,062 iteration 317 : loss : 0.335853, loss_ce: 0.150096
2021-12-16 14:28:20,508 iteration 318 : loss : 0.334239, loss_ce: 0.169321
2021-12-16 14:28:21,895 iteration 319 : loss : 0.306698, loss_ce: 0.133209
2021-12-16 14:28:23,434 iteration 320 : loss : 0.332459, loss_ce: 0.128178
2021-12-16 14:28:24,931 iteration 321 : loss : 0.324269, loss_ce: 0.129497
2021-12-16 14:28:26,373 iteration 322 : loss : 0.339094, loss_ce: 0.166804
2021-12-16 14:28:27,870 iteration 323 : loss : 0.316371, loss_ce: 0.128577
  5%|█▍                            | 19/400 [08:33<2:45:40, 26.09s/it]2021-12-16 14:28:29,334 iteration 324 : loss : 0.327617, loss_ce: 0.156707
2021-12-16 14:28:30,767 iteration 325 : loss : 0.332298, loss_ce: 0.137830
2021-12-16 14:28:32,242 iteration 326 : loss : 0.330037, loss_ce: 0.160145
2021-12-16 14:28:33,811 iteration 327 : loss : 0.330612, loss_ce: 0.150668
2021-12-16 14:28:35,239 iteration 328 : loss : 0.314951, loss_ce: 0.138627
2021-12-16 14:28:36,717 iteration 329 : loss : 0.320738, loss_ce: 0.156521
2021-12-16 14:28:38,210 iteration 330 : loss : 0.316930, loss_ce: 0.139938
2021-12-16 14:28:39,623 iteration 331 : loss : 0.322739, loss_ce: 0.148150
2021-12-16 14:28:41,069 iteration 332 : loss : 0.300090, loss_ce: 0.126263
2021-12-16 14:28:42,556 iteration 333 : loss : 0.330943, loss_ce: 0.158904
2021-12-16 14:28:44,016 iteration 334 : loss : 0.329704, loss_ce: 0.138482
2021-12-16 14:28:45,440 iteration 335 : loss : 0.316843, loss_ce: 0.132296
2021-12-16 14:28:46,916 iteration 336 : loss : 0.314572, loss_ce: 0.128318
2021-12-16 14:28:48,345 iteration 337 : loss : 0.325515, loss_ce: 0.122191
2021-12-16 14:28:49,737 iteration 338 : loss : 0.329696, loss_ce: 0.167261
2021-12-16 14:28:51,164 iteration 339 : loss : 0.312957, loss_ce: 0.127323
2021-12-16 14:28:51,165 Training Data Eval:
2021-12-16 14:28:58,653   Average segmentation loss on training set: 0.3629
2021-12-16 14:28:58,653 Validation Data Eval:
2021-12-16 14:29:01,238   Average segmentation loss on validation set: 0.3524
2021-12-16 14:29:07,468 Found new lowest validation loss at iteration 339! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/TU_3seeds/TU_RESNET_no_pretraining_SGD_best_val_loss_seed1234.pth
2021-12-16 14:29:08,891 iteration 340 : loss : 0.315511, loss_ce: 0.141576
  5%|█▌                            | 20/400 [09:14<3:13:36, 30.57s/it]2021-12-16 14:29:10,345 iteration 341 : loss : 0.315878, loss_ce: 0.136021
2021-12-16 14:29:11,737 iteration 342 : loss : 0.311243, loss_ce: 0.118057
2021-12-16 14:29:13,102 iteration 343 : loss : 0.306883, loss_ce: 0.129441
2021-12-16 14:29:14,506 iteration 344 : loss : 0.311964, loss_ce: 0.143282
2021-12-16 14:29:15,864 iteration 345 : loss : 0.317335, loss_ce: 0.134030
2021-12-16 14:29:17,294 iteration 346 : loss : 0.324624, loss_ce: 0.150252
2021-12-16 14:29:18,606 iteration 347 : loss : 0.328654, loss_ce: 0.172406
2021-12-16 14:29:19,998 iteration 348 : loss : 0.310950, loss_ce: 0.123481
2021-12-16 14:29:21,502 iteration 349 : loss : 0.312057, loss_ce: 0.152986
2021-12-16 14:29:22,859 iteration 350 : loss : 0.324482, loss_ce: 0.145594
2021-12-16 14:29:24,314 iteration 351 : loss : 0.330514, loss_ce: 0.166308
2021-12-16 14:29:25,805 iteration 352 : loss : 0.311513, loss_ce: 0.135774
2021-12-16 14:29:27,238 iteration 353 : loss : 0.307780, loss_ce: 0.123575
2021-12-16 14:29:28,718 iteration 354 : loss : 0.323816, loss_ce: 0.126791
2021-12-16 14:29:30,251 iteration 355 : loss : 0.320725, loss_ce: 0.142687
2021-12-16 14:29:31,859 iteration 356 : loss : 0.321123, loss_ce: 0.148739
2021-12-16 14:29:33,261 iteration 357 : loss : 0.311836, loss_ce: 0.133882
  5%|█▌                            | 21/400 [09:39<3:01:20, 28.71s/it]2021-12-16 14:29:34,786 iteration 358 : loss : 0.309943, loss_ce: 0.147278
2021-12-16 14:29:36,313 iteration 359 : loss : 0.315497, loss_ce: 0.141085
2021-12-16 14:29:37,708 iteration 360 : loss : 0.304436, loss_ce: 0.117526
2021-12-16 14:29:39,200 iteration 361 : loss : 0.323636, loss_ce: 0.126650
2021-12-16 14:29:40,752 iteration 362 : loss : 0.303108, loss_ce: 0.117311
2021-12-16 14:29:42,295 iteration 363 : loss : 0.305475, loss_ce: 0.134454
2021-12-16 14:29:43,792 iteration 364 : loss : 0.317976, loss_ce: 0.151177
2021-12-16 14:29:45,165 iteration 365 : loss : 0.310882, loss_ce: 0.157088
2021-12-16 14:29:46,672 iteration 366 : loss : 0.327930, loss_ce: 0.156429
2021-12-16 14:29:48,065 iteration 367 : loss : 0.310852, loss_ce: 0.143274
2021-12-16 14:29:49,574 iteration 368 : loss : 0.338588, loss_ce: 0.129019
2021-12-16 14:29:51,107 iteration 369 : loss : 0.304178, loss_ce: 0.111176
2021-12-16 14:29:52,606 iteration 370 : loss : 0.312578, loss_ce: 0.167739
2021-12-16 14:29:54,065 iteration 371 : loss : 0.309539, loss_ce: 0.107374
2021-12-16 14:29:55,521 iteration 372 : loss : 0.319572, loss_ce: 0.151707
2021-12-16 14:29:56,907 iteration 373 : loss : 0.310702, loss_ce: 0.115301
2021-12-16 14:29:58,346 iteration 374 : loss : 0.306574, loss_ce: 0.135940
  6%|█▋                            | 22/400 [10:04<2:54:01, 27.62s/it]2021-12-16 14:29:59,887 iteration 375 : loss : 0.304019, loss_ce: 0.125262
2021-12-16 14:30:01,284 iteration 376 : loss : 0.287668, loss_ce: 0.117170
2021-12-16 14:30:02,711 iteration 377 : loss : 0.313324, loss_ce: 0.124444
2021-12-16 14:30:04,230 iteration 378 : loss : 0.308241, loss_ce: 0.131396
2021-12-16 14:30:05,600 iteration 379 : loss : 0.310385, loss_ce: 0.143036
2021-12-16 14:30:07,071 iteration 380 : loss : 0.304754, loss_ce: 0.130372
2021-12-16 14:30:08,518 iteration 381 : loss : 0.315097, loss_ce: 0.117537
2021-12-16 14:30:09,897 iteration 382 : loss : 0.315839, loss_ce: 0.139276
2021-12-16 14:30:11,336 iteration 383 : loss : 0.307046, loss_ce: 0.127774
2021-12-16 14:30:12,796 iteration 384 : loss : 0.315890, loss_ce: 0.140646
2021-12-16 14:30:14,250 iteration 385 : loss : 0.307529, loss_ce: 0.142945
2021-12-16 14:30:15,719 iteration 386 : loss : 0.314148, loss_ce: 0.122302
2021-12-16 14:30:17,191 iteration 387 : loss : 0.281191, loss_ce: 0.106994
2021-12-16 14:30:18,660 iteration 388 : loss : 0.303132, loss_ce: 0.136481
2021-12-16 14:30:20,114 iteration 389 : loss : 0.300399, loss_ce: 0.140869
2021-12-16 14:30:21,540 iteration 390 : loss : 0.303303, loss_ce: 0.142260
2021-12-16 14:30:22,960 iteration 391 : loss : 0.302920, loss_ce: 0.157475
  6%|█▋                            | 23/400 [10:28<2:47:52, 26.72s/it]2021-12-16 14:30:24,466 iteration 392 : loss : 0.299730, loss_ce: 0.137388
2021-12-16 14:30:25,873 iteration 393 : loss : 0.302557, loss_ce: 0.127426
2021-12-16 14:30:27,365 iteration 394 : loss : 0.305464, loss_ce: 0.118865
2021-12-16 14:30:28,836 iteration 395 : loss : 0.307995, loss_ce: 0.149029
2021-12-16 14:30:30,250 iteration 396 : loss : 0.302256, loss_ce: 0.117540
2021-12-16 14:30:31,711 iteration 397 : loss : 0.325540, loss_ce: 0.153793
2021-12-16 14:30:33,186 iteration 398 : loss : 0.296009, loss_ce: 0.126712
2021-12-16 14:30:34,538 iteration 399 : loss : 0.311760, loss_ce: 0.139411
2021-12-16 14:30:36,017 iteration 400 : loss : 0.302851, loss_ce: 0.123698
2021-12-16 14:30:37,508 iteration 401 : loss : 0.290917, loss_ce: 0.126222
2021-12-16 14:30:38,911 iteration 402 : loss : 0.302721, loss_ce: 0.140612
2021-12-16 14:30:40,324 iteration 403 : loss : 0.272322, loss_ce: 0.115928
2021-12-16 14:30:41,796 iteration 404 : loss : 0.282860, loss_ce: 0.126930
2021-12-16 14:30:43,307 iteration 405 : loss : 0.311026, loss_ce: 0.129635
2021-12-16 14:30:44,728 iteration 406 : loss : 0.294026, loss_ce: 0.128044
2021-12-16 14:30:46,104 iteration 407 : loss : 0.290686, loss_ce: 0.122602
2021-12-16 14:30:47,534 iteration 408 : loss : 0.293735, loss_ce: 0.126542
  6%|█▊                            | 24/400 [10:53<2:43:24, 26.08s/it]2021-12-16 14:30:49,047 iteration 409 : loss : 0.298632, loss_ce: 0.148655
2021-12-16 14:30:50,511 iteration 410 : loss : 0.286314, loss_ce: 0.122354
2021-12-16 14:30:51,964 iteration 411 : loss : 0.322790, loss_ce: 0.113432
2021-12-16 14:30:53,319 iteration 412 : loss : 0.285356, loss_ce: 0.115865
2021-12-16 14:30:54,748 iteration 413 : loss : 0.279950, loss_ce: 0.113670
2021-12-16 14:30:56,148 iteration 414 : loss : 0.276774, loss_ce: 0.132255
2021-12-16 14:30:57,499 iteration 415 : loss : 0.290672, loss_ce: 0.123978
2021-12-16 14:30:58,931 iteration 416 : loss : 0.294710, loss_ce: 0.148189
2021-12-16 14:31:00,337 iteration 417 : loss : 0.291912, loss_ce: 0.110294
2021-12-16 14:31:01,846 iteration 418 : loss : 0.303814, loss_ce: 0.141386
2021-12-16 14:31:03,252 iteration 419 : loss : 0.287085, loss_ce: 0.142967
2021-12-16 14:31:04,701 iteration 420 : loss : 0.279260, loss_ce: 0.110034
2021-12-16 14:31:06,098 iteration 421 : loss : 0.289798, loss_ce: 0.121253
2021-12-16 14:31:07,491 iteration 422 : loss : 0.290338, loss_ce: 0.132456
2021-12-16 14:31:08,882 iteration 423 : loss : 0.280304, loss_ce: 0.117508
2021-12-16 14:31:10,325 iteration 424 : loss : 0.309789, loss_ce: 0.118864
2021-12-16 14:31:10,325 Training Data Eval:
2021-12-16 14:31:17,786   Average segmentation loss on training set: 0.3192
2021-12-16 14:31:17,787 Validation Data Eval:
2021-12-16 14:31:20,375   Average segmentation loss on validation set: 0.3075
2021-12-16 14:31:25,397 Found new lowest validation loss at iteration 424! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/TU_3seeds/TU_RESNET_no_pretraining_SGD_best_val_loss_seed1234.pth
2021-12-16 14:31:26,742 iteration 425 : loss : 0.296961, loss_ce: 0.121867
  6%|█▉                            | 25/400 [11:32<3:07:36, 30.02s/it]2021-12-16 14:31:28,075 iteration 426 : loss : 0.270185, loss_ce: 0.105000
2021-12-16 14:31:29,460 iteration 427 : loss : 0.269999, loss_ce: 0.106666
2021-12-16 14:31:30,812 iteration 428 : loss : 0.290281, loss_ce: 0.109530
2021-12-16 14:31:32,111 iteration 429 : loss : 0.296258, loss_ce: 0.139597
2021-12-16 14:31:33,402 iteration 430 : loss : 0.286889, loss_ce: 0.118801
2021-12-16 14:31:34,717 iteration 431 : loss : 0.293037, loss_ce: 0.114413
2021-12-16 14:31:36,098 iteration 432 : loss : 0.275036, loss_ce: 0.122265
2021-12-16 14:31:37,512 iteration 433 : loss : 0.283300, loss_ce: 0.119906
2021-12-16 14:31:38,876 iteration 434 : loss : 0.290253, loss_ce: 0.126287
2021-12-16 14:31:40,210 iteration 435 : loss : 0.301281, loss_ce: 0.125371
2021-12-16 14:31:41,629 iteration 436 : loss : 0.283169, loss_ce: 0.126083
2021-12-16 14:31:43,078 iteration 437 : loss : 0.292195, loss_ce: 0.142491
2021-12-16 14:31:44,474 iteration 438 : loss : 0.251153, loss_ce: 0.095336
2021-12-16 14:31:45,938 iteration 439 : loss : 0.282830, loss_ce: 0.105527
2021-12-16 14:31:47,374 iteration 440 : loss : 0.309123, loss_ce: 0.124544
2021-12-16 14:31:48,853 iteration 441 : loss : 0.281829, loss_ce: 0.121879
2021-12-16 14:31:50,314 iteration 442 : loss : 0.274041, loss_ce: 0.131887
  6%|█▉                            | 26/400 [11:56<2:55:03, 28.08s/it]2021-12-16 14:31:51,783 iteration 443 : loss : 0.295513, loss_ce: 0.143887
2021-12-16 14:31:53,180 iteration 444 : loss : 0.269427, loss_ce: 0.112659
2021-12-16 14:31:54,621 iteration 445 : loss : 0.285853, loss_ce: 0.106364
2021-12-16 14:31:56,172 iteration 446 : loss : 0.258018, loss_ce: 0.110839
2021-12-16 14:31:57,658 iteration 447 : loss : 0.286574, loss_ce: 0.147085
2021-12-16 14:31:59,137 iteration 448 : loss : 0.305653, loss_ce: 0.110276
2021-12-16 14:32:00,580 iteration 449 : loss : 0.263007, loss_ce: 0.124776
2021-12-16 14:32:02,019 iteration 450 : loss : 0.274242, loss_ce: 0.108962
2021-12-16 14:32:03,553 iteration 451 : loss : 0.282740, loss_ce: 0.121964
2021-12-16 14:32:05,029 iteration 452 : loss : 0.284712, loss_ce: 0.125554
2021-12-16 14:32:06,490 iteration 453 : loss : 0.282020, loss_ce: 0.111239
2021-12-16 14:32:07,950 iteration 454 : loss : 0.285995, loss_ce: 0.102668
2021-12-16 14:32:09,431 iteration 455 : loss : 0.272957, loss_ce: 0.115027
2021-12-16 14:32:10,881 iteration 456 : loss : 0.256455, loss_ce: 0.103344
2021-12-16 14:32:12,320 iteration 457 : loss : 0.304901, loss_ce: 0.137404
2021-12-16 14:32:13,821 iteration 458 : loss : 0.314872, loss_ce: 0.149698
2021-12-16 14:32:15,205 iteration 459 : loss : 0.272926, loss_ce: 0.108353
  7%|██                            | 27/400 [12:21<2:48:37, 27.12s/it]2021-12-16 14:32:16,709 iteration 460 : loss : 0.271026, loss_ce: 0.125114
2021-12-16 14:32:18,164 iteration 461 : loss : 0.268450, loss_ce: 0.118446
2021-12-16 14:32:19,586 iteration 462 : loss : 0.276066, loss_ce: 0.117701
2021-12-16 14:32:21,087 iteration 463 : loss : 0.259311, loss_ce: 0.100202
2021-12-16 14:32:22,533 iteration 464 : loss : 0.254878, loss_ce: 0.108549
2021-12-16 14:32:23,931 iteration 465 : loss : 0.271886, loss_ce: 0.094384
2021-12-16 14:32:25,374 iteration 466 : loss : 0.269444, loss_ce: 0.098862
2021-12-16 14:32:26,801 iteration 467 : loss : 0.273174, loss_ce: 0.107452
2021-12-16 14:32:28,334 iteration 468 : loss : 0.276266, loss_ce: 0.108646
2021-12-16 14:32:29,732 iteration 469 : loss : 0.261715, loss_ce: 0.098242
2021-12-16 14:32:31,149 iteration 470 : loss : 0.267216, loss_ce: 0.116968
2021-12-16 14:32:32,569 iteration 471 : loss : 0.272442, loss_ce: 0.110400
2021-12-16 14:32:34,056 iteration 472 : loss : 0.265355, loss_ce: 0.114219
2021-12-16 14:32:35,623 iteration 473 : loss : 0.281012, loss_ce: 0.124832
2021-12-16 14:32:37,140 iteration 474 : loss : 0.264366, loss_ce: 0.119535
2021-12-16 14:32:38,537 iteration 475 : loss : 0.270346, loss_ce: 0.107114
2021-12-16 14:32:40,021 iteration 476 : loss : 0.277141, loss_ce: 0.138311
  7%|██                            | 28/400 [12:45<2:43:52, 26.43s/it]2021-12-16 14:32:41,488 iteration 477 : loss : 0.256701, loss_ce: 0.100379
2021-12-16 14:32:42,973 iteration 478 : loss : 0.284422, loss_ce: 0.112286
2021-12-16 14:32:44,413 iteration 479 : loss : 0.270806, loss_ce: 0.107351
2021-12-16 14:32:45,864 iteration 480 : loss : 0.259180, loss_ce: 0.122323
2021-12-16 14:32:47,226 iteration 481 : loss : 0.260026, loss_ce: 0.110213
2021-12-16 14:32:48,696 iteration 482 : loss : 0.279608, loss_ce: 0.089273
2021-12-16 14:32:50,161 iteration 483 : loss : 0.283086, loss_ce: 0.116441
2021-12-16 14:32:51,631 iteration 484 : loss : 0.289420, loss_ce: 0.138670
2021-12-16 14:32:53,043 iteration 485 : loss : 0.278436, loss_ce: 0.130096
2021-12-16 14:32:54,444 iteration 486 : loss : 0.255880, loss_ce: 0.099767
2021-12-16 14:32:55,926 iteration 487 : loss : 0.249471, loss_ce: 0.105919
2021-12-16 14:32:57,308 iteration 488 : loss : 0.261145, loss_ce: 0.116874
2021-12-16 14:32:58,750 iteration 489 : loss : 0.252571, loss_ce: 0.112662
2021-12-16 14:33:00,084 iteration 490 : loss : 0.279004, loss_ce: 0.114294
2021-12-16 14:33:01,523 iteration 491 : loss : 0.276571, loss_ce: 0.122450
2021-12-16 14:33:02,925 iteration 492 : loss : 0.249170, loss_ce: 0.108030
2021-12-16 14:33:04,360 iteration 493 : loss : 0.238456, loss_ce: 0.108098
  7%|██▏                           | 29/400 [13:10<2:39:33, 25.80s/it]2021-12-16 14:33:05,812 iteration 494 : loss : 0.259222, loss_ce: 0.119070
2021-12-16 14:33:07,274 iteration 495 : loss : 0.239038, loss_ce: 0.088407
2021-12-16 14:33:08,703 iteration 496 : loss : 0.273587, loss_ce: 0.130196
2021-12-16 14:33:10,168 iteration 497 : loss : 0.290568, loss_ce: 0.125639
2021-12-16 14:33:11,698 iteration 498 : loss : 0.259091, loss_ce: 0.118890
2021-12-16 14:33:13,067 iteration 499 : loss : 0.254002, loss_ce: 0.117928
2021-12-16 14:33:14,466 iteration 500 : loss : 0.252000, loss_ce: 0.094996
2021-12-16 14:33:15,866 iteration 501 : loss : 0.263625, loss_ce: 0.100795
2021-12-16 14:33:17,355 iteration 502 : loss : 0.262169, loss_ce: 0.109444
2021-12-16 14:33:18,771 iteration 503 : loss : 0.250085, loss_ce: 0.089142
2021-12-16 14:33:20,250 iteration 504 : loss : 0.266811, loss_ce: 0.098887
2021-12-16 14:33:21,644 iteration 505 : loss : 0.234503, loss_ce: 0.094580
2021-12-16 14:33:23,147 iteration 506 : loss : 0.258293, loss_ce: 0.104225
2021-12-16 14:33:24,579 iteration 507 : loss : 0.263136, loss_ce: 0.104655
2021-12-16 14:33:26,018 iteration 508 : loss : 0.259068, loss_ce: 0.107759
2021-12-16 14:33:27,520 iteration 509 : loss : 0.252563, loss_ce: 0.096488
2021-12-16 14:33:27,520 Training Data Eval:
2021-12-16 14:33:35,000   Average segmentation loss on training set: 0.3031
2021-12-16 14:33:35,000 Validation Data Eval:
2021-12-16 14:33:37,602   Average segmentation loss on validation set: 0.2906
2021-12-16 14:33:45,905 Found new lowest validation loss at iteration 509! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/TU_3seeds/TU_RESNET_no_pretraining_SGD_best_val_loss_seed1234.pth
2021-12-16 14:33:48,086 iteration 510 : loss : 0.250525, loss_ce: 0.103934
  8%|██▎                           | 30/400 [13:53<3:12:16, 31.18s/it]2021-12-16 14:33:49,507 iteration 511 : loss : 0.262730, loss_ce: 0.113435
2021-12-16 14:33:50,823 iteration 512 : loss : 0.263188, loss_ce: 0.106721
2021-12-16 14:33:52,140 iteration 513 : loss : 0.244753, loss_ce: 0.088198
2021-12-16 14:33:53,497 iteration 514 : loss : 0.265331, loss_ce: 0.112123
2021-12-16 14:33:54,825 iteration 515 : loss : 0.264581, loss_ce: 0.112240
2021-12-16 14:33:56,180 iteration 516 : loss : 0.245917, loss_ce: 0.087430
2021-12-16 14:33:57,577 iteration 517 : loss : 0.239613, loss_ce: 0.104067
2021-12-16 14:33:58,866 iteration 518 : loss : 0.272263, loss_ce: 0.098513
2021-12-16 14:34:00,208 iteration 519 : loss : 0.258419, loss_ce: 0.117398
2021-12-16 14:34:01,497 iteration 520 : loss : 0.224046, loss_ce: 0.088714
2021-12-16 14:34:02,833 iteration 521 : loss : 0.267003, loss_ce: 0.095782
2021-12-16 14:34:04,205 iteration 522 : loss : 0.242897, loss_ce: 0.101446
2021-12-16 14:34:05,612 iteration 523 : loss : 0.259402, loss_ce: 0.118860
2021-12-16 14:34:07,066 iteration 524 : loss : 0.244342, loss_ce: 0.104492
2021-12-16 14:34:08,467 iteration 525 : loss : 0.259994, loss_ce: 0.125724
2021-12-16 14:34:09,907 iteration 526 : loss : 0.244519, loss_ce: 0.103539
2021-12-16 14:34:11,360 iteration 527 : loss : 0.234860, loss_ce: 0.083222
  8%|██▎                           | 31/400 [14:17<2:57:10, 28.81s/it]2021-12-16 14:34:12,833 iteration 528 : loss : 0.266878, loss_ce: 0.128471
2021-12-16 14:34:14,301 iteration 529 : loss : 0.246434, loss_ce: 0.101437
2021-12-16 14:34:15,716 iteration 530 : loss : 0.270031, loss_ce: 0.099728
2021-12-16 14:34:17,116 iteration 531 : loss : 0.243377, loss_ce: 0.094141
2021-12-16 14:34:18,531 iteration 532 : loss : 0.237022, loss_ce: 0.110590
2021-12-16 14:34:20,071 iteration 533 : loss : 0.240278, loss_ce: 0.090913
2021-12-16 14:34:21,475 iteration 534 : loss : 0.229679, loss_ce: 0.103604
2021-12-16 14:34:22,974 iteration 535 : loss : 0.250176, loss_ce: 0.100506
2021-12-16 14:34:24,495 iteration 536 : loss : 0.235332, loss_ce: 0.105133
2021-12-16 14:34:26,006 iteration 537 : loss : 0.268257, loss_ce: 0.098774
2021-12-16 14:34:27,447 iteration 538 : loss : 0.235280, loss_ce: 0.100224
2021-12-16 14:34:28,879 iteration 539 : loss : 0.240818, loss_ce: 0.098542
2021-12-16 14:34:30,355 iteration 540 : loss : 0.247544, loss_ce: 0.093201
2021-12-16 14:34:31,789 iteration 541 : loss : 0.232672, loss_ce: 0.098883
2021-12-16 14:34:33,239 iteration 542 : loss : 0.245605, loss_ce: 0.103650
2021-12-16 14:34:34,632 iteration 543 : loss : 0.204759, loss_ce: 0.076239
2021-12-16 14:34:36,066 iteration 544 : loss : 0.243669, loss_ce: 0.094335
  8%|██▍                           | 32/400 [14:41<2:49:08, 27.58s/it]2021-12-16 14:34:37,579 iteration 545 : loss : 0.221612, loss_ce: 0.101679
2021-12-16 14:34:39,020 iteration 546 : loss : 0.240472, loss_ce: 0.097976
2021-12-16 14:34:40,451 iteration 547 : loss : 0.229048, loss_ce: 0.099405
2021-12-16 14:34:41,883 iteration 548 : loss : 0.227774, loss_ce: 0.083026
2021-12-16 14:34:43,345 iteration 549 : loss : 0.238108, loss_ce: 0.107611
2021-12-16 14:34:44,767 iteration 550 : loss : 0.217068, loss_ce: 0.077451
2021-12-16 14:34:46,212 iteration 551 : loss : 0.235953, loss_ce: 0.096181
2021-12-16 14:34:47,636 iteration 552 : loss : 0.226402, loss_ce: 0.092262
2021-12-16 14:34:49,120 iteration 553 : loss : 0.245729, loss_ce: 0.093197
2021-12-16 14:34:50,504 iteration 554 : loss : 0.220587, loss_ce: 0.103039
2021-12-16 14:34:51,942 iteration 555 : loss : 0.248176, loss_ce: 0.082904
2021-12-16 14:34:53,430 iteration 556 : loss : 0.234977, loss_ce: 0.103417
2021-12-16 14:34:54,796 iteration 557 : loss : 0.253970, loss_ce: 0.094854
2021-12-16 14:34:56,272 iteration 558 : loss : 0.244993, loss_ce: 0.084533
2021-12-16 14:34:57,717 iteration 559 : loss : 0.224321, loss_ce: 0.090897
2021-12-16 14:34:59,181 iteration 560 : loss : 0.224901, loss_ce: 0.072276
2021-12-16 14:35:00,667 iteration 561 : loss : 0.262924, loss_ce: 0.133378
  8%|██▍                           | 33/400 [15:06<2:43:13, 26.69s/it]2021-12-16 14:35:02,256 iteration 562 : loss : 0.230871, loss_ce: 0.098540
2021-12-16 14:35:03,610 iteration 563 : loss : 0.225378, loss_ce: 0.096754
2021-12-16 14:35:05,065 iteration 564 : loss : 0.236925, loss_ce: 0.108597
2021-12-16 14:35:06,535 iteration 565 : loss : 0.228665, loss_ce: 0.099547
2021-12-16 14:35:08,033 iteration 566 : loss : 0.252047, loss_ce: 0.109287
2021-12-16 14:35:09,454 iteration 567 : loss : 0.219635, loss_ce: 0.078778
2021-12-16 14:35:10,872 iteration 568 : loss : 0.259040, loss_ce: 0.089660
2021-12-16 14:35:12,308 iteration 569 : loss : 0.238155, loss_ce: 0.090796
2021-12-16 14:35:13,783 iteration 570 : loss : 0.226873, loss_ce: 0.095289
2021-12-16 14:35:15,215 iteration 571 : loss : 0.238984, loss_ce: 0.080043
2021-12-16 14:35:16,661 iteration 572 : loss : 0.229911, loss_ce: 0.091948
2021-12-16 14:35:18,065 iteration 573 : loss : 0.234095, loss_ce: 0.092423
2021-12-16 14:35:19,494 iteration 574 : loss : 0.248099, loss_ce: 0.091098
2021-12-16 14:35:21,003 iteration 575 : loss : 0.254553, loss_ce: 0.093265
2021-12-16 14:35:22,484 iteration 576 : loss : 0.227862, loss_ce: 0.091999
2021-12-16 14:35:23,939 iteration 577 : loss : 0.208702, loss_ce: 0.087191
2021-12-16 14:35:25,349 iteration 578 : loss : 0.239467, loss_ce: 0.097156
  8%|██▌                           | 34/400 [15:31<2:39:06, 26.08s/it]2021-12-16 14:35:26,987 iteration 579 : loss : 0.225135, loss_ce: 0.085950
2021-12-16 14:35:28,440 iteration 580 : loss : 0.265517, loss_ce: 0.113988
2021-12-16 14:35:29,941 iteration 581 : loss : 0.228639, loss_ce: 0.074315
2021-12-16 14:35:31,372 iteration 582 : loss : 0.234127, loss_ce: 0.100379
2021-12-16 14:35:32,804 iteration 583 : loss : 0.225201, loss_ce: 0.070052
2021-12-16 14:35:34,224 iteration 584 : loss : 0.223537, loss_ce: 0.094397
2021-12-16 14:35:35,737 iteration 585 : loss : 0.224215, loss_ce: 0.080232
2021-12-16 14:35:37,140 iteration 586 : loss : 0.238869, loss_ce: 0.096937
2021-12-16 14:35:38,555 iteration 587 : loss : 0.204551, loss_ce: 0.081384
2021-12-16 14:35:40,045 iteration 588 : loss : 0.230669, loss_ce: 0.089406
2021-12-16 14:35:41,476 iteration 589 : loss : 0.205834, loss_ce: 0.078764
2021-12-16 14:35:42,931 iteration 590 : loss : 0.206485, loss_ce: 0.077058
2021-12-16 14:35:44,396 iteration 591 : loss : 0.214742, loss_ce: 0.088621
2021-12-16 14:35:45,864 iteration 592 : loss : 0.225016, loss_ce: 0.092026
2021-12-16 14:35:47,351 iteration 593 : loss : 0.198123, loss_ce: 0.078692
2021-12-16 14:35:48,811 iteration 594 : loss : 0.224180, loss_ce: 0.096436
2021-12-16 14:35:48,812 Training Data Eval:
2021-12-16 14:35:56,290   Average segmentation loss on training set: 0.2204
2021-12-16 14:35:56,290 Validation Data Eval:
2021-12-16 14:35:59,000   Average segmentation loss on validation set: 0.2312
2021-12-16 14:36:05,363 Found new lowest validation loss at iteration 594! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/TU_3seeds/TU_RESNET_no_pretraining_SGD_best_val_loss_seed1234.pth
2021-12-16 14:36:06,801 iteration 595 : loss : 0.215871, loss_ce: 0.098795
  9%|██▋                           | 35/400 [16:12<3:06:43, 30.69s/it]2021-12-16 14:36:08,195 iteration 596 : loss : 0.200090, loss_ce: 0.082331
2021-12-16 14:36:09,511 iteration 597 : loss : 0.217608, loss_ce: 0.075716
2021-12-16 14:36:10,819 iteration 598 : loss : 0.187764, loss_ce: 0.068458
2021-12-16 14:36:12,149 iteration 599 : loss : 0.227076, loss_ce: 0.087816
2021-12-16 14:36:13,480 iteration 600 : loss : 0.221182, loss_ce: 0.098464
2021-12-16 14:36:14,837 iteration 601 : loss : 0.212951, loss_ce: 0.081080
2021-12-16 14:36:16,215 iteration 602 : loss : 0.207089, loss_ce: 0.084067
2021-12-16 14:36:17,500 iteration 603 : loss : 0.211155, loss_ce: 0.071697
2021-12-16 14:36:18,801 iteration 604 : loss : 0.224853, loss_ce: 0.083273
2021-12-16 14:36:20,094 iteration 605 : loss : 0.213572, loss_ce: 0.085086
2021-12-16 14:36:21,619 iteration 606 : loss : 0.205629, loss_ce: 0.081525
2021-12-16 14:36:23,050 iteration 607 : loss : 0.264823, loss_ce: 0.100173
2021-12-16 14:36:24,507 iteration 608 : loss : 0.216464, loss_ce: 0.092343
2021-12-16 14:36:25,889 iteration 609 : loss : 0.205134, loss_ce: 0.080270
2021-12-16 14:36:27,393 iteration 610 : loss : 0.216060, loss_ce: 0.090940
2021-12-16 14:36:28,950 iteration 611 : loss : 0.206674, loss_ce: 0.093766
2021-12-16 14:36:30,428 iteration 612 : loss : 0.198112, loss_ce: 0.071637
  9%|██▋                           | 36/400 [16:36<2:53:21, 28.58s/it]2021-12-16 14:36:31,961 iteration 613 : loss : 0.217510, loss_ce: 0.084860
2021-12-16 14:36:33,391 iteration 614 : loss : 0.227277, loss_ce: 0.082084
2021-12-16 14:36:34,816 iteration 615 : loss : 0.220223, loss_ce: 0.091479
2021-12-16 14:36:36,340 iteration 616 : loss : 0.206499, loss_ce: 0.088845
2021-12-16 14:36:37,756 iteration 617 : loss : 0.209951, loss_ce: 0.090360
2021-12-16 14:36:39,207 iteration 618 : loss : 0.204925, loss_ce: 0.065064
2021-12-16 14:36:40,655 iteration 619 : loss : 0.238140, loss_ce: 0.102781
2021-12-16 14:36:42,189 iteration 620 : loss : 0.274223, loss_ce: 0.076547
2021-12-16 14:36:43,647 iteration 621 : loss : 0.197988, loss_ce: 0.071045
2021-12-16 14:36:45,212 iteration 622 : loss : 0.222183, loss_ce: 0.092897
2021-12-16 14:36:46,745 iteration 623 : loss : 0.217577, loss_ce: 0.098886
2021-12-16 14:36:48,177 iteration 624 : loss : 0.217119, loss_ce: 0.075711
2021-12-16 14:36:49,583 iteration 625 : loss : 0.180716, loss_ce: 0.068213
2021-12-16 14:36:51,081 iteration 626 : loss : 0.202325, loss_ce: 0.073645
2021-12-16 14:36:52,577 iteration 627 : loss : 0.237172, loss_ce: 0.085987
2021-12-16 14:36:54,128 iteration 628 : loss : 0.207136, loss_ce: 0.074759
2021-12-16 14:36:55,548 iteration 629 : loss : 0.195589, loss_ce: 0.072356
  9%|██▊                           | 37/400 [17:01<2:46:36, 27.54s/it]2021-12-16 14:36:57,077 iteration 630 : loss : 0.203979, loss_ce: 0.086134
2021-12-16 14:36:58,506 iteration 631 : loss : 0.189842, loss_ce: 0.073651
2021-12-16 14:36:59,934 iteration 632 : loss : 0.202637, loss_ce: 0.077052
2021-12-16 14:37:01,476 iteration 633 : loss : 0.192216, loss_ce: 0.073173
2021-12-16 14:37:02,917 iteration 634 : loss : 0.221558, loss_ce: 0.079574
2021-12-16 14:37:04,465 iteration 635 : loss : 0.212719, loss_ce: 0.087899
2021-12-16 14:37:05,944 iteration 636 : loss : 0.223332, loss_ce: 0.085139
2021-12-16 14:37:07,353 iteration 637 : loss : 0.191633, loss_ce: 0.079325
2021-12-16 14:37:09,973 iteration 638 : loss : 0.206450, loss_ce: 0.064648
2021-12-16 14:37:11,308 iteration 639 : loss : 0.204574, loss_ce: 0.081569
2021-12-16 14:37:12,664 iteration 640 : loss : 0.225754, loss_ce: 0.064910
2021-12-16 14:37:14,042 iteration 641 : loss : 0.194251, loss_ce: 0.082126
2021-12-16 14:37:15,446 iteration 642 : loss : 0.222943, loss_ce: 0.070891
2021-12-16 14:37:16,871 iteration 643 : loss : 0.201238, loss_ce: 0.079569
2021-12-16 14:37:18,298 iteration 644 : loss : 0.193027, loss_ce: 0.082558
2021-12-16 14:37:19,721 iteration 645 : loss : 0.194863, loss_ce: 0.061598
2021-12-16 14:37:21,237 iteration 646 : loss : 0.194649, loss_ce: 0.075283
 10%|██▊                           | 38/400 [17:27<2:42:47, 26.98s/it]2021-12-16 14:37:22,688 iteration 647 : loss : 0.214200, loss_ce: 0.088761
2021-12-16 14:37:24,133 iteration 648 : loss : 0.206719, loss_ce: 0.081856
2021-12-16 14:37:25,613 iteration 649 : loss : 0.192853, loss_ce: 0.075768
2021-12-16 14:37:27,107 iteration 650 : loss : 0.200835, loss_ce: 0.072747
2021-12-16 14:37:28,535 iteration 651 : loss : 0.186517, loss_ce: 0.069242
2021-12-16 14:37:29,884 iteration 652 : loss : 0.166127, loss_ce: 0.055647
2021-12-16 14:37:31,377 iteration 653 : loss : 0.199959, loss_ce: 0.074203
2021-12-16 14:37:32,769 iteration 654 : loss : 0.199929, loss_ce: 0.068510
2021-12-16 14:37:34,217 iteration 655 : loss : 0.205583, loss_ce: 0.071261
2021-12-16 14:37:35,678 iteration 656 : loss : 0.188185, loss_ce: 0.071665
2021-12-16 14:37:37,176 iteration 657 : loss : 0.182802, loss_ce: 0.061556
2021-12-16 14:37:38,623 iteration 658 : loss : 0.203345, loss_ce: 0.071009
2021-12-16 14:37:40,113 iteration 659 : loss : 0.192605, loss_ce: 0.076338
2021-12-16 14:37:41,560 iteration 660 : loss : 0.205299, loss_ce: 0.087085
2021-12-16 14:37:43,043 iteration 661 : loss : 0.189509, loss_ce: 0.072827
2021-12-16 14:37:44,605 iteration 662 : loss : 0.201599, loss_ce: 0.063594
2021-12-16 14:37:46,086 iteration 663 : loss : 0.186519, loss_ce: 0.076190
 10%|██▉                           | 39/400 [17:51<2:38:29, 26.34s/it]2021-12-16 14:37:47,604 iteration 664 : loss : 0.193984, loss_ce: 0.071938
2021-12-16 14:37:48,971 iteration 665 : loss : 0.202427, loss_ce: 0.084737
2021-12-16 14:37:50,413 iteration 666 : loss : 0.196871, loss_ce: 0.064040
2021-12-16 14:37:51,896 iteration 667 : loss : 0.179575, loss_ce: 0.069511
2021-12-16 14:37:53,339 iteration 668 : loss : 0.219134, loss_ce: 0.092186
2021-12-16 14:37:54,759 iteration 669 : loss : 0.194337, loss_ce: 0.064295
2021-12-16 14:37:56,337 iteration 670 : loss : 0.199373, loss_ce: 0.075398
2021-12-16 14:37:57,770 iteration 671 : loss : 0.197270, loss_ce: 0.069502
2021-12-16 14:37:59,280 iteration 672 : loss : 0.187107, loss_ce: 0.065964
2021-12-16 14:38:00,771 iteration 673 : loss : 0.181822, loss_ce: 0.073585
2021-12-16 14:38:02,260 iteration 674 : loss : 0.174862, loss_ce: 0.074108
2021-12-16 14:38:03,753 iteration 675 : loss : 0.202397, loss_ce: 0.072091
2021-12-16 14:38:05,177 iteration 676 : loss : 0.191675, loss_ce: 0.064493
2021-12-16 14:38:06,627 iteration 677 : loss : 0.177823, loss_ce: 0.071237
2021-12-16 14:38:08,111 iteration 678 : loss : 0.190646, loss_ce: 0.063735
2021-12-16 14:38:09,566 iteration 679 : loss : 0.203546, loss_ce: 0.086004
2021-12-16 14:38:09,566 Training Data Eval:
2021-12-16 14:38:17,042   Average segmentation loss on training set: 0.2137
2021-12-16 14:38:17,042 Validation Data Eval:
2021-12-16 14:38:19,749   Average segmentation loss on validation set: 0.2202
2021-12-16 14:38:26,388 Found new lowest validation loss at iteration 679! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/TU_3seeds/TU_RESNET_no_pretraining_SGD_best_val_loss_seed1234.pth
2021-12-16 14:38:27,759 iteration 680 : loss : 0.168951, loss_ce: 0.058795
 10%|███                           | 40/400 [18:33<3:05:39, 30.94s/it]2021-12-16 14:38:29,171 iteration 681 : loss : 0.170843, loss_ce: 0.057546
2021-12-16 14:38:30,445 iteration 682 : loss : 0.198529, loss_ce: 0.060778
2021-12-16 14:38:31,790 iteration 683 : loss : 0.188383, loss_ce: 0.077783
2021-12-16 14:38:33,111 iteration 684 : loss : 0.198043, loss_ce: 0.072079
2021-12-16 14:38:34,522 iteration 685 : loss : 0.177489, loss_ce: 0.063247
2021-12-16 14:38:35,877 iteration 686 : loss : 0.210200, loss_ce: 0.076631
2021-12-16 14:38:37,223 iteration 687 : loss : 0.191853, loss_ce: 0.078908
2021-12-16 14:38:38,550 iteration 688 : loss : 0.198772, loss_ce: 0.063463
2021-12-16 14:38:39,950 iteration 689 : loss : 0.180759, loss_ce: 0.066277
2021-12-16 14:38:41,313 iteration 690 : loss : 0.172849, loss_ce: 0.062561
2021-12-16 14:38:42,675 iteration 691 : loss : 0.218203, loss_ce: 0.086648
2021-12-16 14:38:44,126 iteration 692 : loss : 0.196872, loss_ce: 0.070115
2021-12-16 14:38:45,520 iteration 693 : loss : 0.190644, loss_ce: 0.079819
2021-12-16 14:38:46,996 iteration 694 : loss : 0.207398, loss_ce: 0.082749
2021-12-16 14:38:48,422 iteration 695 : loss : 0.168683, loss_ce: 0.064258
2021-12-16 14:38:49,945 iteration 696 : loss : 0.194653, loss_ce: 0.076757
2021-12-16 14:38:51,409 iteration 697 : loss : 0.173453, loss_ce: 0.066753
 10%|███                           | 41/400 [18:57<2:52:03, 28.76s/it]2021-12-16 14:38:52,880 iteration 698 : loss : 0.190634, loss_ce: 0.060841
2021-12-16 14:38:54,383 iteration 699 : loss : 0.184270, loss_ce: 0.073033
2021-12-16 14:38:55,829 iteration 700 : loss : 0.184602, loss_ce: 0.074770
2021-12-16 14:38:57,263 iteration 701 : loss : 0.189896, loss_ce: 0.086585
2021-12-16 14:38:58,760 iteration 702 : loss : 0.183490, loss_ce: 0.061396
2021-12-16 14:39:00,314 iteration 703 : loss : 0.171354, loss_ce: 0.071122
2021-12-16 14:39:01,711 iteration 704 : loss : 0.181734, loss_ce: 0.071384
2021-12-16 14:39:03,169 iteration 705 : loss : 0.195129, loss_ce: 0.065942
2021-12-16 14:39:04,629 iteration 706 : loss : 0.178425, loss_ce: 0.063783
2021-12-16 14:39:06,022 iteration 707 : loss : 0.172716, loss_ce: 0.066603
2021-12-16 14:39:07,464 iteration 708 : loss : 0.164023, loss_ce: 0.060005
2021-12-16 14:39:08,906 iteration 709 : loss : 0.186723, loss_ce: 0.078524
2021-12-16 14:39:10,374 iteration 710 : loss : 0.165664, loss_ce: 0.061787
2021-12-16 14:39:11,835 iteration 711 : loss : 0.171467, loss_ce: 0.063870
2021-12-16 14:39:13,375 iteration 712 : loss : 0.207713, loss_ce: 0.081707
2021-12-16 14:39:14,824 iteration 713 : loss : 0.185269, loss_ce: 0.077649
2021-12-16 14:39:16,338 iteration 714 : loss : 0.207704, loss_ce: 0.076663
 10%|███▏                          | 42/400 [19:22<2:44:43, 27.61s/it]2021-12-16 14:39:17,870 iteration 715 : loss : 0.170148, loss_ce: 0.061254
2021-12-16 14:39:19,340 iteration 716 : loss : 0.165835, loss_ce: 0.064689
2021-12-16 14:39:20,776 iteration 717 : loss : 0.185963, loss_ce: 0.063009
2021-12-16 14:39:22,231 iteration 718 : loss : 0.209655, loss_ce: 0.101136
2021-12-16 14:39:23,736 iteration 719 : loss : 0.181192, loss_ce: 0.067602
2021-12-16 14:39:25,195 iteration 720 : loss : 0.172066, loss_ce: 0.066309
2021-12-16 14:39:26,644 iteration 721 : loss : 0.212070, loss_ce: 0.077192
2021-12-16 14:39:28,088 iteration 722 : loss : 0.184397, loss_ce: 0.063698
2021-12-16 14:39:29,577 iteration 723 : loss : 0.190136, loss_ce: 0.088469
2021-12-16 14:39:31,000 iteration 724 : loss : 0.194858, loss_ce: 0.083937
2021-12-16 14:39:32,496 iteration 725 : loss : 0.167441, loss_ce: 0.057088
2021-12-16 14:39:33,921 iteration 726 : loss : 0.181825, loss_ce: 0.073509
2021-12-16 14:39:35,309 iteration 727 : loss : 0.150334, loss_ce: 0.055033
2021-12-16 14:39:36,789 iteration 728 : loss : 0.160316, loss_ce: 0.065944
2021-12-16 14:39:38,284 iteration 729 : loss : 0.170616, loss_ce: 0.068817
2021-12-16 14:39:39,751 iteration 730 : loss : 0.176358, loss_ce: 0.071681
2021-12-16 14:39:41,129 iteration 731 : loss : 0.138129, loss_ce: 0.055040
 11%|███▏                          | 43/400 [19:46<2:39:14, 26.76s/it]2021-12-16 14:39:42,565 iteration 732 : loss : 0.175703, loss_ce: 0.076650
2021-12-16 14:39:43,947 iteration 733 : loss : 0.180404, loss_ce: 0.078950
2021-12-16 14:39:45,435 iteration 734 : loss : 0.156168, loss_ce: 0.061403
2021-12-16 14:39:46,876 iteration 735 : loss : 0.186463, loss_ce: 0.075918
2021-12-16 14:39:48,293 iteration 736 : loss : 0.165550, loss_ce: 0.063814
2021-12-16 14:39:49,853 iteration 737 : loss : 0.182940, loss_ce: 0.078555
2021-12-16 14:39:51,220 iteration 738 : loss : 0.151582, loss_ce: 0.069125
2021-12-16 14:39:52,704 iteration 739 : loss : 0.190852, loss_ce: 0.063668
2021-12-16 14:39:54,132 iteration 740 : loss : 0.164175, loss_ce: 0.059300
2021-12-16 14:39:55,552 iteration 741 : loss : 0.155764, loss_ce: 0.062146
2021-12-16 14:39:56,933 iteration 742 : loss : 0.143341, loss_ce: 0.061724
2021-12-16 14:39:58,390 iteration 743 : loss : 0.170958, loss_ce: 0.069769
2021-12-16 14:39:59,867 iteration 744 : loss : 0.170130, loss_ce: 0.067908
2021-12-16 14:40:01,283 iteration 745 : loss : 0.191820, loss_ce: 0.049154
2021-12-16 14:40:02,706 iteration 746 : loss : 0.152173, loss_ce: 0.060373
2021-12-16 14:40:04,127 iteration 747 : loss : 0.168402, loss_ce: 0.071499
2021-12-16 14:40:05,534 iteration 748 : loss : 0.132827, loss_ce: 0.059150
 11%|███▎                          | 44/400 [20:11<2:34:35, 26.06s/it]2021-12-16 14:40:06,972 iteration 749 : loss : 0.219875, loss_ce: 0.046348
2021-12-16 14:40:08,431 iteration 750 : loss : 0.145601, loss_ce: 0.056677
2021-12-16 14:40:09,890 iteration 751 : loss : 0.151614, loss_ce: 0.046995
2021-12-16 14:40:11,320 iteration 752 : loss : 0.155511, loss_ce: 0.073569
2021-12-16 14:40:12,716 iteration 753 : loss : 0.182105, loss_ce: 0.075041
2021-12-16 14:40:14,125 iteration 754 : loss : 0.173628, loss_ce: 0.069848
2021-12-16 14:40:15,492 iteration 755 : loss : 0.158369, loss_ce: 0.080102
2021-12-16 14:40:16,864 iteration 756 : loss : 0.118700, loss_ce: 0.046591
2021-12-16 14:40:18,302 iteration 757 : loss : 0.170680, loss_ce: 0.078896
2021-12-16 14:40:19,821 iteration 758 : loss : 0.188651, loss_ce: 0.081893
2021-12-16 14:40:21,374 iteration 759 : loss : 0.148310, loss_ce: 0.060587
2021-12-16 14:40:22,777 iteration 760 : loss : 0.137972, loss_ce: 0.066494
2021-12-16 14:40:24,241 iteration 761 : loss : 0.153816, loss_ce: 0.069343
2021-12-16 14:40:25,727 iteration 762 : loss : 0.171381, loss_ce: 0.077922
2021-12-16 14:40:27,221 iteration 763 : loss : 0.136968, loss_ce: 0.055979
2021-12-16 14:40:28,639 iteration 764 : loss : 0.142666, loss_ce: 0.061894
2021-12-16 14:40:28,639 Training Data Eval:
2021-12-16 14:40:36,109   Average segmentation loss on training set: 0.1569
2021-12-16 14:40:36,109 Validation Data Eval:
2021-12-16 14:40:38,693   Average segmentation loss on validation set: 0.1814
2021-12-16 14:40:45,053 Found new lowest validation loss at iteration 764! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/TU_3seeds/TU_RESNET_no_pretraining_SGD_best_val_loss_seed1234.pth
2021-12-16 14:40:46,596 iteration 765 : loss : 0.158208, loss_ce: 0.058628
 11%|███▍                          | 45/400 [20:52<3:00:47, 30.56s/it]2021-12-16 14:40:48,026 iteration 766 : loss : 0.180597, loss_ce: 0.084911
2021-12-16 14:40:49,399 iteration 767 : loss : 0.152041, loss_ce: 0.060673
2021-12-16 14:40:50,759 iteration 768 : loss : 0.179668, loss_ce: 0.067592
2021-12-16 14:40:52,135 iteration 769 : loss : 0.160935, loss_ce: 0.070938
2021-12-16 14:40:53,403 iteration 770 : loss : 0.125173, loss_ce: 0.054240
2021-12-16 14:40:54,752 iteration 771 : loss : 0.198004, loss_ce: 0.055492
2021-12-16 14:40:56,106 iteration 772 : loss : 0.123819, loss_ce: 0.054470
2021-12-16 14:40:57,474 iteration 773 : loss : 0.147054, loss_ce: 0.043491
2021-12-16 14:40:58,923 iteration 774 : loss : 0.147838, loss_ce: 0.066400
2021-12-16 14:41:00,280 iteration 775 : loss : 0.158794, loss_ce: 0.076159
2021-12-16 14:41:01,671 iteration 776 : loss : 0.142220, loss_ce: 0.058982
2021-12-16 14:41:03,293 iteration 777 : loss : 0.195581, loss_ce: 0.090499
2021-12-16 14:41:04,680 iteration 778 : loss : 0.179609, loss_ce: 0.071219
2021-12-16 14:41:06,189 iteration 779 : loss : 0.161324, loss_ce: 0.073258
2021-12-16 14:41:07,705 iteration 780 : loss : 0.158113, loss_ce: 0.062023
2021-12-16 14:41:09,124 iteration 781 : loss : 0.151770, loss_ce: 0.078320
2021-12-16 14:41:10,500 iteration 782 : loss : 0.131860, loss_ce: 0.066384
 12%|███▍                          | 46/400 [21:16<2:48:30, 28.56s/it]2021-12-16 14:41:11,972 iteration 783 : loss : 0.149963, loss_ce: 0.071909
2021-12-16 14:41:13,389 iteration 784 : loss : 0.131771, loss_ce: 0.059290
2021-12-16 14:41:14,850 iteration 785 : loss : 0.130570, loss_ce: 0.062150
2021-12-16 14:41:16,279 iteration 786 : loss : 0.162409, loss_ce: 0.062697
2021-12-16 14:41:17,711 iteration 787 : loss : 0.142980, loss_ce: 0.060269
2021-12-16 14:41:19,209 iteration 788 : loss : 0.144679, loss_ce: 0.062508
2021-12-16 14:41:20,567 iteration 789 : loss : 0.125191, loss_ce: 0.046048
2021-12-16 14:41:22,053 iteration 790 : loss : 0.166593, loss_ce: 0.058764
2021-12-16 14:41:23,488 iteration 791 : loss : 0.156891, loss_ce: 0.066248
2021-12-16 14:41:24,879 iteration 792 : loss : 0.118548, loss_ce: 0.053106
2021-12-16 14:41:26,385 iteration 793 : loss : 0.126347, loss_ce: 0.068931
2021-12-16 14:41:27,751 iteration 794 : loss : 0.113052, loss_ce: 0.053598
2021-12-16 14:41:29,142 iteration 795 : loss : 0.135040, loss_ce: 0.058213
2021-12-16 14:41:30,535 iteration 796 : loss : 0.149904, loss_ce: 0.072067
2021-12-16 14:41:32,022 iteration 797 : loss : 0.152723, loss_ce: 0.057039
2021-12-16 14:41:33,450 iteration 798 : loss : 0.147888, loss_ce: 0.057090
2021-12-16 14:41:34,828 iteration 799 : loss : 0.123895, loss_ce: 0.059034
 12%|███▌                          | 47/400 [21:40<2:40:34, 27.29s/it]2021-12-16 14:41:36,407 iteration 800 : loss : 0.162311, loss_ce: 0.062519
2021-12-16 14:41:37,873 iteration 801 : loss : 0.155293, loss_ce: 0.065717
2021-12-16 14:41:39,327 iteration 802 : loss : 0.159608, loss_ce: 0.060578
2021-12-16 14:41:40,794 iteration 803 : loss : 0.112813, loss_ce: 0.061425
2021-12-16 14:41:42,306 iteration 804 : loss : 0.180949, loss_ce: 0.076474
2021-12-16 14:41:43,882 iteration 805 : loss : 0.129678, loss_ce: 0.054928
2021-12-16 14:41:45,309 iteration 806 : loss : 0.108934, loss_ce: 0.052118
2021-12-16 14:41:46,706 iteration 807 : loss : 0.132109, loss_ce: 0.057720
2021-12-16 14:41:48,185 iteration 808 : loss : 0.152961, loss_ce: 0.079013
2021-12-16 14:41:49,644 iteration 809 : loss : 0.114302, loss_ce: 0.049926
2021-12-16 14:41:51,056 iteration 810 : loss : 0.157243, loss_ce: 0.058793
2021-12-16 14:41:52,445 iteration 811 : loss : 0.118031, loss_ce: 0.064430
2021-12-16 14:41:53,862 iteration 812 : loss : 0.109366, loss_ce: 0.057424
2021-12-16 14:41:55,309 iteration 813 : loss : 0.144986, loss_ce: 0.053125
2021-12-16 14:41:56,857 iteration 814 : loss : 0.155247, loss_ce: 0.059393
2021-12-16 14:41:58,344 iteration 815 : loss : 0.181680, loss_ce: 0.091472
2021-12-16 14:41:59,792 iteration 816 : loss : 0.147970, loss_ce: 0.068224
 12%|███▌                          | 48/400 [22:05<2:36:00, 26.59s/it]2021-12-16 14:42:01,265 iteration 817 : loss : 0.107079, loss_ce: 0.052714
2021-12-16 14:42:02,656 iteration 818 : loss : 0.114673, loss_ce: 0.051171
2021-12-16 14:42:04,105 iteration 819 : loss : 0.120975, loss_ce: 0.051462
2021-12-16 14:42:05,486 iteration 820 : loss : 0.099724, loss_ce: 0.046914
2021-12-16 14:42:06,981 iteration 821 : loss : 0.150061, loss_ce: 0.064011
2021-12-16 14:42:08,466 iteration 822 : loss : 0.178490, loss_ce: 0.070084
2021-12-16 14:42:09,859 iteration 823 : loss : 0.115024, loss_ce: 0.048869
2021-12-16 14:42:11,254 iteration 824 : loss : 0.151930, loss_ce: 0.069710
2021-12-16 14:42:12,685 iteration 825 : loss : 0.121182, loss_ce: 0.049751
2021-12-16 14:42:14,115 iteration 826 : loss : 0.148880, loss_ce: 0.046599
2021-12-16 14:42:15,551 iteration 827 : loss : 0.175832, loss_ce: 0.069691
2021-12-16 14:42:16,989 iteration 828 : loss : 0.123358, loss_ce: 0.054351
2021-12-16 14:42:18,444 iteration 829 : loss : 0.131010, loss_ce: 0.055658
2021-12-16 14:42:19,943 iteration 830 : loss : 0.115030, loss_ce: 0.050177
2021-12-16 14:42:21,378 iteration 831 : loss : 0.143331, loss_ce: 0.072530
2021-12-16 14:42:22,794 iteration 832 : loss : 0.093655, loss_ce: 0.043328
2021-12-16 14:42:24,287 iteration 833 : loss : 0.139966, loss_ce: 0.068821
 12%|███▋                          | 49/400 [22:30<2:31:53, 25.96s/it]2021-12-16 14:42:25,757 iteration 834 : loss : 0.114580, loss_ce: 0.049494
2021-12-16 14:42:27,108 iteration 835 : loss : 0.131115, loss_ce: 0.047045
2021-12-16 14:42:28,549 iteration 836 : loss : 0.112750, loss_ce: 0.053028
2021-12-16 14:42:29,933 iteration 837 : loss : 0.099902, loss_ce: 0.055415
2021-12-16 14:42:31,312 iteration 838 : loss : 0.125196, loss_ce: 0.054433
2021-12-16 14:42:32,796 iteration 839 : loss : 0.121135, loss_ce: 0.057253
2021-12-16 14:42:34,251 iteration 840 : loss : 0.134661, loss_ce: 0.053156
2021-12-16 14:42:35,657 iteration 841 : loss : 0.134198, loss_ce: 0.058808
2021-12-16 14:42:37,093 iteration 842 : loss : 0.134701, loss_ce: 0.058253
2021-12-16 14:42:38,625 iteration 843 : loss : 0.124325, loss_ce: 0.052284
2021-12-16 14:42:40,041 iteration 844 : loss : 0.130391, loss_ce: 0.050659
2021-12-16 14:42:41,494 iteration 845 : loss : 0.128326, loss_ce: 0.054031
2021-12-16 14:42:43,035 iteration 846 : loss : 0.111580, loss_ce: 0.057915
2021-12-16 14:42:44,491 iteration 847 : loss : 0.119818, loss_ce: 0.057034
2021-12-16 14:42:45,833 iteration 848 : loss : 0.108014, loss_ce: 0.051115
2021-12-16 14:42:47,292 iteration 849 : loss : 0.121094, loss_ce: 0.052618
2021-12-16 14:42:47,292 Training Data Eval:
2021-12-16 14:42:54,767   Average segmentation loss on training set: 0.1051
2021-12-16 14:42:54,767 Validation Data Eval:
2021-12-16 14:42:57,350   Average segmentation loss on validation set: 0.1668
2021-12-16 14:43:03,687 Found new lowest validation loss at iteration 849! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/TU_3seeds/TU_RESNET_no_pretraining_SGD_best_val_loss_seed1234.pth
2021-12-16 14:43:05,082 iteration 850 : loss : 0.119803, loss_ce: 0.048349
 12%|███▊                          | 50/400 [23:10<2:57:24, 30.41s/it]2021-12-16 14:43:06,482 iteration 851 : loss : 0.124140, loss_ce: 0.059403
2021-12-16 14:43:07,801 iteration 852 : loss : 0.121889, loss_ce: 0.054879
2021-12-16 14:43:09,215 iteration 853 : loss : 0.132954, loss_ce: 0.061112
2021-12-16 14:43:10,585 iteration 854 : loss : 0.105921, loss_ce: 0.041302
2021-12-16 14:43:11,945 iteration 855 : loss : 0.117690, loss_ce: 0.058736
2021-12-16 14:43:13,327 iteration 856 : loss : 0.134274, loss_ce: 0.054533
2021-12-16 14:43:14,639 iteration 857 : loss : 0.111565, loss_ce: 0.053315
2021-12-16 14:43:15,890 iteration 858 : loss : 0.102017, loss_ce: 0.049196
2021-12-16 14:43:17,215 iteration 859 : loss : 0.136335, loss_ce: 0.051116
2021-12-16 14:43:18,509 iteration 860 : loss : 0.118835, loss_ce: 0.044902
2021-12-16 14:43:19,969 iteration 861 : loss : 0.134729, loss_ce: 0.065151
2021-12-16 14:43:21,347 iteration 862 : loss : 0.115445, loss_ce: 0.047268
2021-12-16 14:43:22,880 iteration 863 : loss : 0.119988, loss_ce: 0.047938
2021-12-16 14:43:24,365 iteration 864 : loss : 0.121451, loss_ce: 0.058334
2021-12-16 14:43:25,747 iteration 865 : loss : 0.106078, loss_ce: 0.052234
2021-12-16 14:43:27,259 iteration 866 : loss : 0.141618, loss_ce: 0.072294
2021-12-16 14:43:28,652 iteration 867 : loss : 0.068132, loss_ce: 0.032136
 13%|███▊                          | 51/400 [23:34<2:44:57, 28.36s/it]2021-12-16 14:43:30,204 iteration 868 : loss : 0.176796, loss_ce: 0.066429
2021-12-16 14:43:31,674 iteration 869 : loss : 0.124828, loss_ce: 0.055996
2021-12-16 14:43:33,038 iteration 870 : loss : 0.093113, loss_ce: 0.042789
2021-12-16 14:43:34,443 iteration 871 : loss : 0.088165, loss_ce: 0.042746
2021-12-16 14:43:35,881 iteration 872 : loss : 0.088371, loss_ce: 0.048760
2021-12-16 14:43:37,386 iteration 873 : loss : 0.116470, loss_ce: 0.046189
2021-12-16 14:43:38,754 iteration 874 : loss : 0.081629, loss_ce: 0.045451
2021-12-16 14:43:40,325 iteration 875 : loss : 0.145025, loss_ce: 0.061902
2021-12-16 14:43:41,778 iteration 876 : loss : 0.084165, loss_ce: 0.044443
2021-12-16 14:43:43,137 iteration 877 : loss : 0.104029, loss_ce: 0.044726
2021-12-16 14:43:44,617 iteration 878 : loss : 0.109085, loss_ce: 0.055301
2021-12-16 14:43:46,028 iteration 879 : loss : 0.113907, loss_ce: 0.052316
2021-12-16 14:43:47,493 iteration 880 : loss : 0.097057, loss_ce: 0.035438
2021-12-16 14:43:48,916 iteration 881 : loss : 0.127922, loss_ce: 0.054301
2021-12-16 14:43:50,420 iteration 882 : loss : 0.103518, loss_ce: 0.045521
2021-12-16 14:43:52,683 iteration 883 : loss : 0.109986, loss_ce: 0.054685
2021-12-16 14:43:54,156 iteration 884 : loss : 0.124715, loss_ce: 0.048733
 13%|███▉                          | 52/400 [23:59<2:39:31, 27.50s/it]2021-12-16 14:43:55,636 iteration 885 : loss : 0.110471, loss_ce: 0.046204
2021-12-16 14:43:57,091 iteration 886 : loss : 0.105132, loss_ce: 0.042814
2021-12-16 14:43:58,541 iteration 887 : loss : 0.126381, loss_ce: 0.062408
2021-12-16 14:44:00,003 iteration 888 : loss : 0.108655, loss_ce: 0.045296
2021-12-16 14:44:01,539 iteration 889 : loss : 0.135942, loss_ce: 0.049254
2021-12-16 14:44:03,106 iteration 890 : loss : 0.133109, loss_ce: 0.052352
2021-12-16 14:44:04,597 iteration 891 : loss : 0.091734, loss_ce: 0.038923
2021-12-16 14:44:06,043 iteration 892 : loss : 0.093939, loss_ce: 0.049059
2021-12-16 14:44:07,467 iteration 893 : loss : 0.090789, loss_ce: 0.039323
2021-12-16 14:44:09,007 iteration 894 : loss : 0.120029, loss_ce: 0.049911
2021-12-16 14:44:10,409 iteration 895 : loss : 0.121752, loss_ce: 0.041635
2021-12-16 14:44:11,931 iteration 896 : loss : 0.167085, loss_ce: 0.068213
2021-12-16 14:44:13,444 iteration 897 : loss : 0.157136, loss_ce: 0.068882
2021-12-16 14:44:14,869 iteration 898 : loss : 0.094136, loss_ce: 0.051960
2021-12-16 14:44:16,303 iteration 899 : loss : 0.095886, loss_ce: 0.047566
2021-12-16 14:44:17,703 iteration 900 : loss : 0.096189, loss_ce: 0.048199
2021-12-16 14:44:19,119 iteration 901 : loss : 0.129814, loss_ce: 0.053325
 13%|███▉                          | 53/400 [24:24<2:34:38, 26.74s/it]2021-12-16 14:44:20,631 iteration 902 : loss : 0.135054, loss_ce: 0.069577
2021-12-16 14:44:22,142 iteration 903 : loss : 0.113597, loss_ce: 0.046487
2021-12-16 14:44:23,599 iteration 904 : loss : 0.143511, loss_ce: 0.050384
2021-12-16 14:44:25,040 iteration 905 : loss : 0.125222, loss_ce: 0.058371
2021-12-16 14:44:26,465 iteration 906 : loss : 0.099588, loss_ce: 0.045024
2021-12-16 14:44:27,955 iteration 907 : loss : 0.155153, loss_ce: 0.055468
2021-12-16 14:44:29,294 iteration 908 : loss : 0.101718, loss_ce: 0.044302
2021-12-16 14:44:30,766 iteration 909 : loss : 0.099206, loss_ce: 0.047313
2021-12-16 14:44:32,149 iteration 910 : loss : 0.108752, loss_ce: 0.050912
2021-12-16 14:44:33,591 iteration 911 : loss : 0.089580, loss_ce: 0.042913
2021-12-16 14:44:35,026 iteration 912 : loss : 0.100694, loss_ce: 0.043578
2021-12-16 14:44:36,439 iteration 913 : loss : 0.119047, loss_ce: 0.045988
2021-12-16 14:44:37,871 iteration 914 : loss : 0.164046, loss_ce: 0.076667
2021-12-16 14:44:39,280 iteration 915 : loss : 0.166409, loss_ce: 0.052738
2021-12-16 14:44:40,683 iteration 916 : loss : 0.089197, loss_ce: 0.043368
2021-12-16 14:44:42,131 iteration 917 : loss : 0.134341, loss_ce: 0.070091
2021-12-16 14:44:43,600 iteration 918 : loss : 0.124045, loss_ce: 0.054146
 14%|████                          | 54/400 [24:49<2:30:17, 26.06s/it]2021-12-16 14:44:45,107 iteration 919 : loss : 0.099767, loss_ce: 0.050840
2021-12-16 14:44:46,568 iteration 920 : loss : 0.118175, loss_ce: 0.055502
2021-12-16 14:44:48,037 iteration 921 : loss : 0.138828, loss_ce: 0.055129
2021-12-16 14:44:49,523 iteration 922 : loss : 0.132637, loss_ce: 0.064039
2021-12-16 14:44:50,926 iteration 923 : loss : 0.083413, loss_ce: 0.042577
2021-12-16 14:44:52,394 iteration 924 : loss : 0.166575, loss_ce: 0.054930
2021-12-16 14:44:53,795 iteration 925 : loss : 0.098811, loss_ce: 0.042220
2021-12-16 14:44:55,290 iteration 926 : loss : 0.096173, loss_ce: 0.047220
2021-12-16 14:44:56,664 iteration 927 : loss : 0.098435, loss_ce: 0.040883
2021-12-16 14:44:58,095 iteration 928 : loss : 0.096293, loss_ce: 0.043957
2021-12-16 14:44:59,577 iteration 929 : loss : 0.121470, loss_ce: 0.047996
2021-12-16 14:45:01,024 iteration 930 : loss : 0.109756, loss_ce: 0.048064
2021-12-16 14:45:02,483 iteration 931 : loss : 0.129172, loss_ce: 0.037031
2021-12-16 14:45:03,943 iteration 932 : loss : 0.088232, loss_ce: 0.036147
2021-12-16 14:45:05,363 iteration 933 : loss : 0.113226, loss_ce: 0.050353
2021-12-16 14:45:06,799 iteration 934 : loss : 0.098630, loss_ce: 0.044694
2021-12-16 14:45:06,799 Training Data Eval:
2021-12-16 14:45:14,270   Average segmentation loss on training set: 0.0788
2021-12-16 14:45:14,271 Validation Data Eval:
2021-12-16 14:45:17,132   Average segmentation loss on validation set: 0.1618
2021-12-16 14:45:26,213 Found new lowest validation loss at iteration 934! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/TU_3seeds/TU_RESNET_no_pretraining_SGD_best_val_loss_seed1234.pth
2021-12-16 14:45:27,674 iteration 935 : loss : 0.170861, loss_ce: 0.058337
 14%|████▏                         | 55/400 [25:33<3:00:55, 31.47s/it]2021-12-16 14:45:29,040 iteration 936 : loss : 0.111031, loss_ce: 0.044670
2021-12-16 14:45:30,419 iteration 937 : loss : 0.110664, loss_ce: 0.042362
2021-12-16 14:45:31,843 iteration 938 : loss : 0.094316, loss_ce: 0.040553
2021-12-16 14:45:33,155 iteration 939 : loss : 0.083917, loss_ce: 0.035345
2021-12-16 14:45:34,524 iteration 940 : loss : 0.127133, loss_ce: 0.059734
2021-12-16 14:45:35,963 iteration 941 : loss : 0.112103, loss_ce: 0.046095
2021-12-16 14:45:37,277 iteration 942 : loss : 0.111622, loss_ce: 0.045846
2021-12-16 14:45:38,601 iteration 943 : loss : 0.112835, loss_ce: 0.056238
2021-12-16 14:45:39,904 iteration 944 : loss : 0.096352, loss_ce: 0.039107
2021-12-16 14:45:41,220 iteration 945 : loss : 0.088488, loss_ce: 0.041172
2021-12-16 14:45:42,531 iteration 946 : loss : 0.086621, loss_ce: 0.043938
2021-12-16 14:45:43,834 iteration 947 : loss : 0.102575, loss_ce: 0.041665
2021-12-16 14:45:45,142 iteration 948 : loss : 0.103803, loss_ce: 0.046337
2021-12-16 14:45:46,534 iteration 949 : loss : 0.093854, loss_ce: 0.039963
2021-12-16 14:45:47,969 iteration 950 : loss : 0.106389, loss_ce: 0.052041
2021-12-16 14:45:49,467 iteration 951 : loss : 0.082117, loss_ce: 0.043010
2021-12-16 14:45:50,878 iteration 952 : loss : 0.111967, loss_ce: 0.054429
 14%|████▏                         | 56/400 [25:56<2:46:11, 28.99s/it]2021-12-16 14:45:52,399 iteration 953 : loss : 0.118105, loss_ce: 0.048078
2021-12-16 14:45:53,899 iteration 954 : loss : 0.094580, loss_ce: 0.042750
2021-12-16 14:45:55,289 iteration 955 : loss : 0.072430, loss_ce: 0.034703
2021-12-16 14:45:56,780 iteration 956 : loss : 0.106345, loss_ce: 0.048748
2021-12-16 14:45:58,256 iteration 957 : loss : 0.091228, loss_ce: 0.037079
2021-12-16 14:45:59,737 iteration 958 : loss : 0.101483, loss_ce: 0.036854
2021-12-16 14:46:01,290 iteration 959 : loss : 0.132735, loss_ce: 0.063815
2021-12-16 14:46:02,891 iteration 960 : loss : 0.117484, loss_ce: 0.052072
2021-12-16 14:46:04,313 iteration 961 : loss : 0.153082, loss_ce: 0.056832
2021-12-16 14:46:05,707 iteration 962 : loss : 0.134933, loss_ce: 0.044386
2021-12-16 14:46:07,228 iteration 963 : loss : 0.095166, loss_ce: 0.042839
2021-12-16 14:46:08,718 iteration 964 : loss : 0.097020, loss_ce: 0.054014
2021-12-16 14:46:10,147 iteration 965 : loss : 0.099248, loss_ce: 0.052506
2021-12-16 14:46:11,597 iteration 966 : loss : 0.089964, loss_ce: 0.043682
2021-12-16 14:46:13,052 iteration 967 : loss : 0.104032, loss_ce: 0.044127
2021-12-16 14:46:14,453 iteration 968 : loss : 0.143724, loss_ce: 0.052711
2021-12-16 14:46:15,929 iteration 969 : loss : 0.079535, loss_ce: 0.038315
 14%|████▎                         | 57/400 [26:21<2:38:57, 27.81s/it]2021-12-16 14:46:17,400 iteration 970 : loss : 0.119980, loss_ce: 0.062999
2021-12-16 14:46:18,880 iteration 971 : loss : 0.110265, loss_ce: 0.036853
2021-12-16 14:46:20,276 iteration 972 : loss : 0.092460, loss_ce: 0.046663
2021-12-16 14:46:21,739 iteration 973 : loss : 0.107998, loss_ce: 0.043657
2021-12-16 14:46:23,142 iteration 974 : loss : 0.087932, loss_ce: 0.039372
2021-12-16 14:46:24,645 iteration 975 : loss : 0.149834, loss_ce: 0.056400
2021-12-16 14:46:26,078 iteration 976 : loss : 0.081464, loss_ce: 0.037093
2021-12-16 14:46:27,516 iteration 977 : loss : 0.078541, loss_ce: 0.031691
2021-12-16 14:46:28,983 iteration 978 : loss : 0.070611, loss_ce: 0.033060
2021-12-16 14:46:30,409 iteration 979 : loss : 0.111108, loss_ce: 0.057584
2021-12-16 14:46:31,845 iteration 980 : loss : 0.089597, loss_ce: 0.043794
2021-12-16 14:46:33,385 iteration 981 : loss : 0.091066, loss_ce: 0.047669
2021-12-16 14:46:34,799 iteration 982 : loss : 0.090141, loss_ce: 0.046696
2021-12-16 14:46:36,286 iteration 983 : loss : 0.138690, loss_ce: 0.051668
2021-12-16 14:46:37,660 iteration 984 : loss : 0.100559, loss_ce: 0.054594
2021-12-16 14:46:39,097 iteration 985 : loss : 0.103736, loss_ce: 0.043105
2021-12-16 14:46:40,588 iteration 986 : loss : 0.124834, loss_ce: 0.053567
 14%|████▎                         | 58/400 [26:46<2:33:07, 26.86s/it]2021-12-16 14:46:42,144 iteration 987 : loss : 0.098404, loss_ce: 0.049453
2021-12-16 14:46:43,610 iteration 988 : loss : 0.100453, loss_ce: 0.052524
2021-12-16 14:46:45,052 iteration 989 : loss : 0.125509, loss_ce: 0.050588
2021-12-16 14:46:46,503 iteration 990 : loss : 0.102166, loss_ce: 0.050197
2021-12-16 14:46:47,945 iteration 991 : loss : 0.091239, loss_ce: 0.042767
2021-12-16 14:46:49,483 iteration 992 : loss : 0.090500, loss_ce: 0.045493
2021-12-16 14:46:50,953 iteration 993 : loss : 0.078873, loss_ce: 0.035100
2021-12-16 14:46:52,499 iteration 994 : loss : 0.097888, loss_ce: 0.053304
2021-12-16 14:46:53,956 iteration 995 : loss : 0.159839, loss_ce: 0.059901
2021-12-16 14:46:55,463 iteration 996 : loss : 0.083392, loss_ce: 0.042689
2021-12-16 14:46:56,962 iteration 997 : loss : 0.097294, loss_ce: 0.042326
2021-12-16 14:46:58,358 iteration 998 : loss : 0.091737, loss_ce: 0.033498
2021-12-16 14:46:59,855 iteration 999 : loss : 0.097196, loss_ce: 0.043533
2021-12-16 14:47:01,269 iteration 1000 : loss : 0.116374, loss_ce: 0.042660
2021-12-16 14:47:02,699 iteration 1001 : loss : 0.129181, loss_ce: 0.041088
2021-12-16 14:47:04,247 iteration 1002 : loss : 0.084700, loss_ce: 0.035548
2021-12-16 14:47:05,757 iteration 1003 : loss : 0.116168, loss_ce: 0.051438
 15%|████▍                         | 59/400 [27:11<2:29:47, 26.36s/it]2021-12-16 14:47:07,229 iteration 1004 : loss : 0.113711, loss_ce: 0.047618
2021-12-16 14:47:08,661 iteration 1005 : loss : 0.113873, loss_ce: 0.055392
2021-12-16 14:47:10,191 iteration 1006 : loss : 0.103322, loss_ce: 0.048519
2021-12-16 14:47:11,594 iteration 1007 : loss : 0.089796, loss_ce: 0.052225
2021-12-16 14:47:12,993 iteration 1008 : loss : 0.117785, loss_ce: 0.049732
2021-12-16 14:47:14,406 iteration 1009 : loss : 0.111242, loss_ce: 0.051057
2021-12-16 14:47:15,825 iteration 1010 : loss : 0.083073, loss_ce: 0.036065
2021-12-16 14:47:17,324 iteration 1011 : loss : 0.088134, loss_ce: 0.043332
2021-12-16 14:47:18,746 iteration 1012 : loss : 0.074872, loss_ce: 0.031639
2021-12-16 14:47:20,139 iteration 1013 : loss : 0.099366, loss_ce: 0.039114
2021-12-16 14:47:21,596 iteration 1014 : loss : 0.150202, loss_ce: 0.066947
2021-12-16 14:47:22,969 iteration 1015 : loss : 0.085016, loss_ce: 0.034968
2021-12-16 14:47:24,444 iteration 1016 : loss : 0.081759, loss_ce: 0.038875
2021-12-16 14:47:25,812 iteration 1017 : loss : 0.066920, loss_ce: 0.029372
2021-12-16 14:47:27,182 iteration 1018 : loss : 0.093899, loss_ce: 0.038298
2021-12-16 14:47:28,619 iteration 1019 : loss : 0.096407, loss_ce: 0.043552
2021-12-16 14:47:28,619 Training Data Eval:
2021-12-16 14:47:36,121   Average segmentation loss on training set: 0.0661
2021-12-16 14:47:36,121 Validation Data Eval:
2021-12-16 14:47:38,719   Average segmentation loss on validation set: 0.1479
2021-12-16 14:47:46,481 Found new lowest validation loss at iteration 1019! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/TU_3seeds/TU_RESNET_no_pretraining_SGD_best_val_loss_seed1234.pth
2021-12-16 14:47:47,778 iteration 1020 : loss : 0.073767, loss_ce: 0.032751
 15%|████▌                         | 60/400 [27:53<2:55:58, 31.06s/it]2021-12-16 14:47:49,240 iteration 1021 : loss : 0.126171, loss_ce: 0.042311
2021-12-16 14:47:50,568 iteration 1022 : loss : 0.127598, loss_ce: 0.050586
2021-12-16 14:47:51,915 iteration 1023 : loss : 0.135679, loss_ce: 0.041013
2021-12-16 14:47:53,322 iteration 1024 : loss : 0.081454, loss_ce: 0.035599
2021-12-16 14:47:54,721 iteration 1025 : loss : 0.084775, loss_ce: 0.042334
2021-12-16 14:47:55,977 iteration 1026 : loss : 0.069775, loss_ce: 0.033183
2021-12-16 14:47:57,369 iteration 1027 : loss : 0.122816, loss_ce: 0.048284
2021-12-16 14:47:58,751 iteration 1028 : loss : 0.119394, loss_ce: 0.054809
2021-12-16 14:48:00,081 iteration 1029 : loss : 0.069377, loss_ce: 0.033289
2021-12-16 14:48:01,425 iteration 1030 : loss : 0.081242, loss_ce: 0.036875
2021-12-16 14:48:02,830 iteration 1031 : loss : 0.105173, loss_ce: 0.048170
2021-12-16 14:48:04,243 iteration 1032 : loss : 0.094332, loss_ce: 0.049486
2021-12-16 14:48:05,663 iteration 1033 : loss : 0.078384, loss_ce: 0.031286
2021-12-16 14:48:07,178 iteration 1034 : loss : 0.106426, loss_ce: 0.045821
2021-12-16 14:48:08,658 iteration 1035 : loss : 0.081753, loss_ce: 0.037040
2021-12-16 14:48:10,144 iteration 1036 : loss : 0.092096, loss_ce: 0.046363
2021-12-16 14:48:11,572 iteration 1037 : loss : 0.116676, loss_ce: 0.043293
 15%|████▌                         | 61/400 [28:17<2:43:08, 28.87s/it]2021-12-16 14:48:13,081 iteration 1038 : loss : 0.078754, loss_ce: 0.036956
2021-12-16 14:48:14,514 iteration 1039 : loss : 0.074582, loss_ce: 0.040138
2021-12-16 14:48:15,986 iteration 1040 : loss : 0.106190, loss_ce: 0.051362
2021-12-16 14:48:17,451 iteration 1041 : loss : 0.112449, loss_ce: 0.053406
2021-12-16 14:48:18,933 iteration 1042 : loss : 0.089967, loss_ce: 0.042700
2021-12-16 14:48:20,399 iteration 1043 : loss : 0.124976, loss_ce: 0.043773
2021-12-16 14:48:21,862 iteration 1044 : loss : 0.086483, loss_ce: 0.040230
2021-12-16 14:48:23,220 iteration 1045 : loss : 0.063409, loss_ce: 0.033787
2021-12-16 14:48:24,624 iteration 1046 : loss : 0.100508, loss_ce: 0.033993
2021-12-16 14:48:26,130 iteration 1047 : loss : 0.096883, loss_ce: 0.040113
2021-12-16 14:48:27,582 iteration 1048 : loss : 0.115568, loss_ce: 0.050107
2021-12-16 14:48:29,026 iteration 1049 : loss : 0.086880, loss_ce: 0.033240
2021-12-16 14:48:30,512 iteration 1050 : loss : 0.117155, loss_ce: 0.043418
2021-12-16 14:48:31,952 iteration 1051 : loss : 0.095917, loss_ce: 0.045037
2021-12-16 14:48:33,407 iteration 1052 : loss : 0.104650, loss_ce: 0.041410
2021-12-16 14:48:34,792 iteration 1053 : loss : 0.098944, loss_ce: 0.039418
2021-12-16 14:48:36,300 iteration 1054 : loss : 0.108445, loss_ce: 0.049733
 16%|████▋                         | 62/400 [28:42<2:35:39, 27.63s/it]2021-12-16 14:48:37,796 iteration 1055 : loss : 0.087287, loss_ce: 0.033239
2021-12-16 14:48:39,215 iteration 1056 : loss : 0.097028, loss_ce: 0.051126
2021-12-16 14:48:40,643 iteration 1057 : loss : 0.120197, loss_ce: 0.056911
2021-12-16 14:48:42,083 iteration 1058 : loss : 0.084910, loss_ce: 0.043523
2021-12-16 14:48:43,448 iteration 1059 : loss : 0.080049, loss_ce: 0.035364
2021-12-16 14:48:44,894 iteration 1060 : loss : 0.078391, loss_ce: 0.033477
2021-12-16 14:48:46,367 iteration 1061 : loss : 0.074337, loss_ce: 0.032038
2021-12-16 14:48:47,832 iteration 1062 : loss : 0.115882, loss_ce: 0.061703
2021-12-16 14:48:49,339 iteration 1063 : loss : 0.127187, loss_ce: 0.043320
2021-12-16 14:48:50,763 iteration 1064 : loss : 0.112132, loss_ce: 0.037371
2021-12-16 14:48:52,145 iteration 1065 : loss : 0.100157, loss_ce: 0.044400
2021-12-16 14:48:53,635 iteration 1066 : loss : 0.106425, loss_ce: 0.047231
2021-12-16 14:48:55,046 iteration 1067 : loss : 0.136970, loss_ce: 0.043964
2021-12-16 14:48:56,534 iteration 1068 : loss : 0.091271, loss_ce: 0.050102
2021-12-16 14:48:58,003 iteration 1069 : loss : 0.125544, loss_ce: 0.059362
2021-12-16 14:48:59,443 iteration 1070 : loss : 0.065338, loss_ce: 0.033031
2021-12-16 14:49:00,880 iteration 1071 : loss : 0.080017, loss_ce: 0.038988
 16%|████▋                         | 63/400 [29:06<2:30:03, 26.72s/it]2021-12-16 14:49:02,464 iteration 1072 : loss : 0.102934, loss_ce: 0.044118
2021-12-16 14:49:03,857 iteration 1073 : loss : 0.156262, loss_ce: 0.041056
2021-12-16 14:49:05,277 iteration 1074 : loss : 0.089822, loss_ce: 0.042371
2021-12-16 14:49:06,741 iteration 1075 : loss : 0.139302, loss_ce: 0.050851
2021-12-16 14:49:08,125 iteration 1076 : loss : 0.065867, loss_ce: 0.030032
2021-12-16 14:49:09,559 iteration 1077 : loss : 0.083995, loss_ce: 0.033539
2021-12-16 14:49:11,080 iteration 1078 : loss : 0.102875, loss_ce: 0.059811
2021-12-16 14:49:12,490 iteration 1079 : loss : 0.079699, loss_ce: 0.034982
2021-12-16 14:49:13,874 iteration 1080 : loss : 0.079677, loss_ce: 0.039386
2021-12-16 14:49:15,335 iteration 1081 : loss : 0.082273, loss_ce: 0.029813
2021-12-16 14:49:16,798 iteration 1082 : loss : 0.088352, loss_ce: 0.049984
2021-12-16 14:49:18,287 iteration 1083 : loss : 0.097199, loss_ce: 0.045087
2021-12-16 14:49:19,710 iteration 1084 : loss : 0.087072, loss_ce: 0.047599
2021-12-16 14:49:21,217 iteration 1085 : loss : 0.081724, loss_ce: 0.033165
2021-12-16 14:49:22,633 iteration 1086 : loss : 0.089148, loss_ce: 0.041162
2021-12-16 14:49:24,076 iteration 1087 : loss : 0.095762, loss_ce: 0.043827
2021-12-16 14:49:25,561 iteration 1088 : loss : 0.085628, loss_ce: 0.043550
 16%|████▊                         | 64/400 [29:31<2:26:12, 26.11s/it]2021-12-16 14:49:27,003 iteration 1089 : loss : 0.105355, loss_ce: 0.043578
2021-12-16 14:49:28,419 iteration 1090 : loss : 0.100067, loss_ce: 0.053893
2021-12-16 14:49:29,862 iteration 1091 : loss : 0.074207, loss_ce: 0.037289
2021-12-16 14:49:31,306 iteration 1092 : loss : 0.073253, loss_ce: 0.035118
2021-12-16 14:49:32,765 iteration 1093 : loss : 0.097118, loss_ce: 0.041262
2021-12-16 14:49:34,281 iteration 1094 : loss : 0.072792, loss_ce: 0.031233
2021-12-16 14:49:35,682 iteration 1095 : loss : 0.066894, loss_ce: 0.034209
2021-12-16 14:49:37,224 iteration 1096 : loss : 0.094933, loss_ce: 0.041778
2021-12-16 14:49:38,684 iteration 1097 : loss : 0.121102, loss_ce: 0.051932
2021-12-16 14:49:40,090 iteration 1098 : loss : 0.075290, loss_ce: 0.039608
2021-12-16 14:49:41,550 iteration 1099 : loss : 0.089436, loss_ce: 0.034135
2021-12-16 14:49:43,058 iteration 1100 : loss : 0.092924, loss_ce: 0.039974
2021-12-16 14:49:44,488 iteration 1101 : loss : 0.083606, loss_ce: 0.036205
2021-12-16 14:49:46,001 iteration 1102 : loss : 0.144701, loss_ce: 0.050468
2021-12-16 14:49:47,422 iteration 1103 : loss : 0.107362, loss_ce: 0.044604
2021-12-16 14:49:48,852 iteration 1104 : loss : 0.075660, loss_ce: 0.035974
2021-12-16 14:49:48,853 Training Data Eval:
2021-12-16 14:49:56,323   Average segmentation loss on training set: 0.0599
2021-12-16 14:49:56,324 Validation Data Eval:
2021-12-16 14:49:58,917   Average segmentation loss on validation set: 0.1370
2021-12-16 14:50:05,165 Found new lowest validation loss at iteration 1104! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/TU_3seeds/TU_RESNET_no_pretraining_SGD_best_val_loss_seed1234.pth
2021-12-16 14:50:06,582 iteration 1105 : loss : 0.104795, loss_ce: 0.034632
 16%|████▉                         | 65/400 [30:12<2:50:44, 30.58s/it]2021-12-16 14:50:07,902 iteration 1106 : loss : 0.082463, loss_ce: 0.035009
2021-12-16 14:50:09,225 iteration 1107 : loss : 0.097348, loss_ce: 0.052023
2021-12-16 14:50:10,575 iteration 1108 : loss : 0.106779, loss_ce: 0.033279
2021-12-16 14:50:11,863 iteration 1109 : loss : 0.071214, loss_ce: 0.032743
2021-12-16 14:50:13,217 iteration 1110 : loss : 0.098962, loss_ce: 0.045835
2021-12-16 14:50:14,539 iteration 1111 : loss : 0.068897, loss_ce: 0.033670
2021-12-16 14:50:15,867 iteration 1112 : loss : 0.086622, loss_ce: 0.039522
2021-12-16 14:50:17,174 iteration 1113 : loss : 0.097506, loss_ce: 0.038266
2021-12-16 14:50:18,570 iteration 1114 : loss : 0.128784, loss_ce: 0.071106
2021-12-16 14:50:20,045 iteration 1115 : loss : 0.085543, loss_ce: 0.042970
2021-12-16 14:50:21,465 iteration 1116 : loss : 0.103342, loss_ce: 0.037398
2021-12-16 14:50:23,012 iteration 1117 : loss : 0.092316, loss_ce: 0.040454
2021-12-16 14:50:24,519 iteration 1118 : loss : 0.094015, loss_ce: 0.034324
2021-12-16 14:50:25,955 iteration 1119 : loss : 0.065687, loss_ce: 0.031374
2021-12-16 14:50:27,384 iteration 1120 : loss : 0.094090, loss_ce: 0.037647
2021-12-16 14:50:28,871 iteration 1121 : loss : 0.086116, loss_ce: 0.032640
2021-12-16 14:50:30,339 iteration 1122 : loss : 0.090261, loss_ce: 0.044295
 16%|████▉                         | 66/400 [30:36<2:38:50, 28.53s/it]2021-12-16 14:50:31,799 iteration 1123 : loss : 0.095074, loss_ce: 0.037196
2021-12-16 14:50:33,304 iteration 1124 : loss : 0.073722, loss_ce: 0.037123
2021-12-16 14:50:34,760 iteration 1125 : loss : 0.070819, loss_ce: 0.028046
2021-12-16 14:50:36,185 iteration 1126 : loss : 0.087009, loss_ce: 0.038012
2021-12-16 14:50:37,599 iteration 1127 : loss : 0.085426, loss_ce: 0.036811
2021-12-16 14:50:39,091 iteration 1128 : loss : 0.112743, loss_ce: 0.048940
2021-12-16 14:50:40,596 iteration 1129 : loss : 0.093675, loss_ce: 0.039846
2021-12-16 14:50:42,038 iteration 1130 : loss : 0.072133, loss_ce: 0.036600
2021-12-16 14:50:43,480 iteration 1131 : loss : 0.087878, loss_ce: 0.039913
2021-12-16 14:50:44,975 iteration 1132 : loss : 0.084367, loss_ce: 0.038555
2021-12-16 14:50:46,363 iteration 1133 : loss : 0.067037, loss_ce: 0.035450
2021-12-16 14:50:47,815 iteration 1134 : loss : 0.080612, loss_ce: 0.031394
2021-12-16 14:50:49,239 iteration 1135 : loss : 0.088469, loss_ce: 0.039803
2021-12-16 14:50:50,695 iteration 1136 : loss : 0.060636, loss_ce: 0.027104
2021-12-16 14:50:52,129 iteration 1137 : loss : 0.111947, loss_ce: 0.047910
2021-12-16 14:50:53,632 iteration 1138 : loss : 0.081276, loss_ce: 0.037331
2021-12-16 14:50:55,084 iteration 1139 : loss : 0.091664, loss_ce: 0.034141
 17%|█████                         | 67/400 [31:00<2:32:03, 27.40s/it]2021-12-16 14:50:56,563 iteration 1140 : loss : 0.073781, loss_ce: 0.031439
2021-12-16 14:50:57,965 iteration 1141 : loss : 0.099585, loss_ce: 0.044561
2021-12-16 14:50:59,482 iteration 1142 : loss : 0.091481, loss_ce: 0.043635
2021-12-16 14:51:00,911 iteration 1143 : loss : 0.089209, loss_ce: 0.040225
2021-12-16 14:51:02,405 iteration 1144 : loss : 0.100667, loss_ce: 0.051477
2021-12-16 14:51:03,801 iteration 1145 : loss : 0.070773, loss_ce: 0.031913
2021-12-16 14:51:05,264 iteration 1146 : loss : 0.111778, loss_ce: 0.053631
2021-12-16 14:51:06,624 iteration 1147 : loss : 0.077423, loss_ce: 0.033629
2021-12-16 14:51:08,140 iteration 1148 : loss : 0.096727, loss_ce: 0.037347
2021-12-16 14:51:09,535 iteration 1149 : loss : 0.069465, loss_ce: 0.037477
2021-12-16 14:51:10,989 iteration 1150 : loss : 0.067551, loss_ce: 0.031412
2021-12-16 14:51:12,474 iteration 1151 : loss : 0.104824, loss_ce: 0.040834
2021-12-16 14:51:14,033 iteration 1152 : loss : 0.110425, loss_ce: 0.046722
2021-12-16 14:51:15,399 iteration 1153 : loss : 0.072955, loss_ce: 0.029332
2021-12-16 14:51:16,889 iteration 1154 : loss : 0.100922, loss_ce: 0.038710
2021-12-16 14:51:18,312 iteration 1155 : loss : 0.107880, loss_ce: 0.044959
2021-12-16 14:51:19,835 iteration 1156 : loss : 0.104639, loss_ce: 0.056006
 17%|█████                         | 68/400 [31:25<2:27:11, 26.60s/it]2021-12-16 14:51:21,310 iteration 1157 : loss : 0.148757, loss_ce: 0.046849
2021-12-16 14:51:22,761 iteration 1158 : loss : 0.089300, loss_ce: 0.037240
2021-12-16 14:51:24,296 iteration 1159 : loss : 0.079099, loss_ce: 0.032476
2021-12-16 14:51:25,861 iteration 1160 : loss : 0.096465, loss_ce: 0.042974
2021-12-16 14:51:27,359 iteration 1161 : loss : 0.070487, loss_ce: 0.033625
2021-12-16 14:51:28,804 iteration 1162 : loss : 0.086605, loss_ce: 0.037258
2021-12-16 14:51:30,229 iteration 1163 : loss : 0.104396, loss_ce: 0.048237
2021-12-16 14:51:31,678 iteration 1164 : loss : 0.101162, loss_ce: 0.043184
2021-12-16 14:51:33,140 iteration 1165 : loss : 0.070855, loss_ce: 0.034674
2021-12-16 14:51:34,685 iteration 1166 : loss : 0.079242, loss_ce: 0.035017
2021-12-16 14:51:36,110 iteration 1167 : loss : 0.081721, loss_ce: 0.043923
2021-12-16 14:51:37,542 iteration 1168 : loss : 0.067933, loss_ce: 0.035357
2021-12-16 14:51:38,966 iteration 1169 : loss : 0.076413, loss_ce: 0.033441
2021-12-16 14:51:40,400 iteration 1170 : loss : 0.083226, loss_ce: 0.037180
2021-12-16 14:51:41,875 iteration 1171 : loss : 0.087834, loss_ce: 0.033442
2021-12-16 14:51:43,337 iteration 1172 : loss : 0.085215, loss_ce: 0.041087
2021-12-16 14:51:44,808 iteration 1173 : loss : 0.083474, loss_ce: 0.038007
 17%|█████▏                        | 69/400 [31:50<2:24:03, 26.11s/it]2021-12-16 14:51:46,274 iteration 1174 : loss : 0.090781, loss_ce: 0.033669
2021-12-16 14:51:47,718 iteration 1175 : loss : 0.081645, loss_ce: 0.037910
2021-12-16 14:51:49,145 iteration 1176 : loss : 0.078151, loss_ce: 0.036313
2021-12-16 14:51:50,545 iteration 1177 : loss : 0.072318, loss_ce: 0.033954
2021-12-16 14:51:52,024 iteration 1178 : loss : 0.061711, loss_ce: 0.023305
2021-12-16 14:51:53,557 iteration 1179 : loss : 0.102709, loss_ce: 0.048452
2021-12-16 14:51:54,977 iteration 1180 : loss : 0.096587, loss_ce: 0.046457
2021-12-16 14:51:56,434 iteration 1181 : loss : 0.079026, loss_ce: 0.038509
2021-12-16 14:51:57,902 iteration 1182 : loss : 0.098297, loss_ce: 0.040726
2021-12-16 14:51:59,311 iteration 1183 : loss : 0.075268, loss_ce: 0.032792
2021-12-16 14:52:00,722 iteration 1184 : loss : 0.057278, loss_ce: 0.030478
2021-12-16 14:52:02,221 iteration 1185 : loss : 0.076074, loss_ce: 0.033092
2021-12-16 14:52:03,634 iteration 1186 : loss : 0.078988, loss_ce: 0.039236
2021-12-16 14:52:05,165 iteration 1187 : loss : 0.076487, loss_ce: 0.031457
2021-12-16 14:52:06,555 iteration 1188 : loss : 0.080758, loss_ce: 0.036240
2021-12-16 14:52:08,087 iteration 1189 : loss : 0.099205, loss_ce: 0.047384
2021-12-16 14:52:08,087 Training Data Eval:
2021-12-16 14:52:15,611   Average segmentation loss on training set: 0.0610
2021-12-16 14:52:15,612 Validation Data Eval:
2021-12-16 14:52:18,207   Average segmentation loss on validation set: 0.1269
2021-12-16 14:52:24,701 Found new lowest validation loss at iteration 1189! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/TU_3seeds/TU_RESNET_no_pretraining_SGD_best_val_loss_seed1234.pth
2021-12-16 14:52:26,086 iteration 1190 : loss : 0.085511, loss_ce: 0.041880
 18%|█████▎                        | 70/400 [32:31<2:48:39, 30.67s/it]2021-12-16 14:52:27,539 iteration 1191 : loss : 0.075819, loss_ce: 0.032305
2021-12-16 14:52:28,844 iteration 1192 : loss : 0.073540, loss_ce: 0.039819
2021-12-16 14:52:30,278 iteration 1193 : loss : 0.102936, loss_ce: 0.041416
2021-12-16 14:52:31,612 iteration 1194 : loss : 0.082779, loss_ce: 0.031803
2021-12-16 14:52:32,908 iteration 1195 : loss : 0.076992, loss_ce: 0.040464
2021-12-16 14:52:34,209 iteration 1196 : loss : 0.057688, loss_ce: 0.028528
2021-12-16 14:52:35,470 iteration 1197 : loss : 0.068255, loss_ce: 0.031195
2021-12-16 14:52:36,872 iteration 1198 : loss : 0.067093, loss_ce: 0.035859
2021-12-16 14:52:38,238 iteration 1199 : loss : 0.093176, loss_ce: 0.040922
2021-12-16 14:52:39,572 iteration 1200 : loss : 0.115459, loss_ce: 0.043112
2021-12-16 14:52:40,911 iteration 1201 : loss : 0.071347, loss_ce: 0.033628
2021-12-16 14:52:42,379 iteration 1202 : loss : 0.069058, loss_ce: 0.029417
2021-12-16 14:52:43,860 iteration 1203 : loss : 0.108642, loss_ce: 0.043430
2021-12-16 14:52:45,319 iteration 1204 : loss : 0.083803, loss_ce: 0.040678
2021-12-16 14:52:46,794 iteration 1205 : loss : 0.114961, loss_ce: 0.052942
2021-12-16 14:52:48,275 iteration 1206 : loss : 0.055489, loss_ce: 0.026495
2021-12-16 14:52:49,783 iteration 1207 : loss : 0.060387, loss_ce: 0.024140
 18%|█████▎                        | 71/400 [32:55<2:36:41, 28.58s/it]2021-12-16 14:52:51,349 iteration 1208 : loss : 0.075247, loss_ce: 0.041409
2021-12-16 14:52:52,816 iteration 1209 : loss : 0.077681, loss_ce: 0.037845
2021-12-16 14:52:54,279 iteration 1210 : loss : 0.085189, loss_ce: 0.038924
2021-12-16 14:52:55,679 iteration 1211 : loss : 0.051479, loss_ce: 0.025400
2021-12-16 14:52:57,068 iteration 1212 : loss : 0.092001, loss_ce: 0.032552
2021-12-16 14:52:58,658 iteration 1213 : loss : 0.078285, loss_ce: 0.039122
2021-12-16 14:53:00,121 iteration 1214 : loss : 0.063219, loss_ce: 0.029309
2021-12-16 14:53:01,589 iteration 1215 : loss : 0.077094, loss_ce: 0.031449
2021-12-16 14:53:03,155 iteration 1216 : loss : 0.101089, loss_ce: 0.036972
2021-12-16 14:53:04,627 iteration 1217 : loss : 0.065599, loss_ce: 0.027873
2021-12-16 14:53:06,061 iteration 1218 : loss : 0.060575, loss_ce: 0.027075
2021-12-16 14:53:07,445 iteration 1219 : loss : 0.064109, loss_ce: 0.026034
2021-12-16 14:53:08,893 iteration 1220 : loss : 0.072594, loss_ce: 0.031045
2021-12-16 14:53:10,325 iteration 1221 : loss : 0.077726, loss_ce: 0.035975
2021-12-16 14:53:11,851 iteration 1222 : loss : 0.098859, loss_ce: 0.037773
2021-12-16 14:53:13,275 iteration 1223 : loss : 0.083304, loss_ce: 0.044289
2021-12-16 14:53:14,780 iteration 1224 : loss : 0.102228, loss_ce: 0.041667
 18%|█████▍                        | 72/400 [33:20<2:30:20, 27.50s/it]2021-12-16 14:53:16,247 iteration 1225 : loss : 0.074875, loss_ce: 0.031364
2021-12-16 14:53:17,763 iteration 1226 : loss : 0.082821, loss_ce: 0.040857
2021-12-16 14:53:19,166 iteration 1227 : loss : 0.063546, loss_ce: 0.026338
2021-12-16 14:53:20,611 iteration 1228 : loss : 0.065899, loss_ce: 0.028808
2021-12-16 14:53:21,991 iteration 1229 : loss : 0.079018, loss_ce: 0.028843
2021-12-16 14:53:23,416 iteration 1230 : loss : 0.084960, loss_ce: 0.033201
2021-12-16 14:53:24,906 iteration 1231 : loss : 0.085942, loss_ce: 0.042053
2021-12-16 14:53:26,309 iteration 1232 : loss : 0.054643, loss_ce: 0.025276
2021-12-16 14:53:27,736 iteration 1233 : loss : 0.058667, loss_ce: 0.028272
2021-12-16 14:53:29,235 iteration 1234 : loss : 0.074505, loss_ce: 0.035517
2021-12-16 14:53:30,715 iteration 1235 : loss : 0.090148, loss_ce: 0.029861
2021-12-16 14:53:32,136 iteration 1236 : loss : 0.075633, loss_ce: 0.034044
2021-12-16 14:53:33,516 iteration 1237 : loss : 0.078642, loss_ce: 0.035929
2021-12-16 14:53:35,027 iteration 1238 : loss : 0.082777, loss_ce: 0.036300
2021-12-16 14:53:36,423 iteration 1239 : loss : 0.051727, loss_ce: 0.024316
2021-12-16 14:53:37,833 iteration 1240 : loss : 0.050386, loss_ce: 0.022940
2021-12-16 14:53:39,255 iteration 1241 : loss : 0.071229, loss_ce: 0.040970
 18%|█████▍                        | 73/400 [33:45<2:24:55, 26.59s/it]2021-12-16 14:53:40,782 iteration 1242 : loss : 0.082082, loss_ce: 0.042183
2021-12-16 14:53:42,184 iteration 1243 : loss : 0.066015, loss_ce: 0.028316
2021-12-16 14:53:43,600 iteration 1244 : loss : 0.070774, loss_ce: 0.031081
2021-12-16 14:53:45,074 iteration 1245 : loss : 0.081258, loss_ce: 0.034928
2021-12-16 14:53:46,543 iteration 1246 : loss : 0.065286, loss_ce: 0.025723
2021-12-16 14:53:47,958 iteration 1247 : loss : 0.069539, loss_ce: 0.032336
2021-12-16 14:53:49,414 iteration 1248 : loss : 0.093985, loss_ce: 0.035519
2021-12-16 14:53:50,836 iteration 1249 : loss : 0.065860, loss_ce: 0.026975
2021-12-16 14:53:52,388 iteration 1250 : loss : 0.103854, loss_ce: 0.046965
2021-12-16 14:53:53,940 iteration 1251 : loss : 0.093215, loss_ce: 0.047483
2021-12-16 14:53:55,407 iteration 1252 : loss : 0.074400, loss_ce: 0.034358
2021-12-16 14:53:56,775 iteration 1253 : loss : 0.064650, loss_ce: 0.027185
2021-12-16 14:53:58,213 iteration 1254 : loss : 0.064256, loss_ce: 0.034807
2021-12-16 14:53:59,653 iteration 1255 : loss : 0.080958, loss_ce: 0.035276
2021-12-16 14:54:01,086 iteration 1256 : loss : 0.076768, loss_ce: 0.037595
2021-12-16 14:54:02,523 iteration 1257 : loss : 0.080755, loss_ce: 0.030385
2021-12-16 14:54:03,963 iteration 1258 : loss : 0.065580, loss_ce: 0.034350
 18%|█████▌                        | 74/400 [34:09<2:21:24, 26.03s/it]2021-12-16 14:54:05,402 iteration 1259 : loss : 0.065168, loss_ce: 0.033032
2021-12-16 14:54:06,888 iteration 1260 : loss : 0.067845, loss_ce: 0.031670
2021-12-16 14:54:08,301 iteration 1261 : loss : 0.053266, loss_ce: 0.020752
2021-12-16 14:54:09,798 iteration 1262 : loss : 0.080665, loss_ce: 0.034732
2021-12-16 14:54:11,319 iteration 1263 : loss : 0.115703, loss_ce: 0.046677
2021-12-16 14:54:12,731 iteration 1264 : loss : 0.069918, loss_ce: 0.035360
2021-12-16 14:54:14,212 iteration 1265 : loss : 0.079599, loss_ce: 0.045417
2021-12-16 14:54:15,699 iteration 1266 : loss : 0.084497, loss_ce: 0.031222
2021-12-16 14:54:17,162 iteration 1267 : loss : 0.082289, loss_ce: 0.035773
2021-12-16 14:54:18,572 iteration 1268 : loss : 0.084558, loss_ce: 0.037390
2021-12-16 14:54:20,078 iteration 1269 : loss : 0.109376, loss_ce: 0.031063
2021-12-16 14:54:21,532 iteration 1270 : loss : 0.070718, loss_ce: 0.033671
2021-12-16 14:54:22,947 iteration 1271 : loss : 0.069886, loss_ce: 0.036203
2021-12-16 14:54:24,305 iteration 1272 : loss : 0.076778, loss_ce: 0.030469
2021-12-16 14:54:25,732 iteration 1273 : loss : 0.081985, loss_ce: 0.031893
2021-12-16 14:54:27,176 iteration 1274 : loss : 0.068027, loss_ce: 0.026552
2021-12-16 14:54:27,176 Training Data Eval:
2021-12-16 14:54:34,696   Average segmentation loss on training set: 0.0454
2021-12-16 14:54:34,696 Validation Data Eval:
2021-12-16 14:54:37,294   Average segmentation loss on validation set: 0.1277
2021-12-16 14:54:38,741 iteration 1275 : loss : 0.066862, loss_ce: 0.027617
 19%|█████▋                        | 75/400 [34:44<2:35:11, 28.65s/it]2021-12-16 14:54:40,148 iteration 1276 : loss : 0.060882, loss_ce: 0.027774
2021-12-16 14:54:41,697 iteration 1277 : loss : 0.070874, loss_ce: 0.033493
2021-12-16 14:54:43,116 iteration 1278 : loss : 0.049286, loss_ce: 0.022004
2021-12-16 14:54:44,659 iteration 1279 : loss : 0.083273, loss_ce: 0.031731
2021-12-16 14:54:46,130 iteration 1280 : loss : 0.090924, loss_ce: 0.045310
2021-12-16 14:54:47,593 iteration 1281 : loss : 0.100231, loss_ce: 0.046306
2021-12-16 14:54:49,006 iteration 1282 : loss : 0.046335, loss_ce: 0.025448
2021-12-16 14:54:50,503 iteration 1283 : loss : 0.097019, loss_ce: 0.035450
2021-12-16 14:54:51,902 iteration 1284 : loss : 0.077270, loss_ce: 0.033224
2021-12-16 14:54:53,403 iteration 1285 : loss : 0.078680, loss_ce: 0.031170
2021-12-16 14:54:54,938 iteration 1286 : loss : 0.116016, loss_ce: 0.036459
2021-12-16 14:54:56,370 iteration 1287 : loss : 0.065711, loss_ce: 0.038085
2021-12-16 14:54:57,765 iteration 1288 : loss : 0.069604, loss_ce: 0.035526
2021-12-16 14:54:59,201 iteration 1289 : loss : 0.064514, loss_ce: 0.031323
2021-12-16 14:55:00,673 iteration 1290 : loss : 0.090681, loss_ce: 0.034288
2021-12-16 14:55:02,159 iteration 1291 : loss : 0.088655, loss_ce: 0.046032
2021-12-16 14:55:03,657 iteration 1292 : loss : 0.082572, loss_ce: 0.035523
 19%|█████▋                        | 76/400 [35:09<2:28:40, 27.53s/it]2021-12-16 14:55:05,159 iteration 1293 : loss : 0.059891, loss_ce: 0.024525
2021-12-16 14:55:06,627 iteration 1294 : loss : 0.068835, loss_ce: 0.030152
2021-12-16 14:55:08,138 iteration 1295 : loss : 0.078865, loss_ce: 0.024433
2021-12-16 14:55:09,601 iteration 1296 : loss : 0.087219, loss_ce: 0.033355
2021-12-16 14:55:11,015 iteration 1297 : loss : 0.071261, loss_ce: 0.040270
2021-12-16 14:55:12,406 iteration 1298 : loss : 0.049976, loss_ce: 0.024418
2021-12-16 14:55:13,869 iteration 1299 : loss : 0.093250, loss_ce: 0.049886
2021-12-16 14:55:15,302 iteration 1300 : loss : 0.089831, loss_ce: 0.028972
2021-12-16 14:55:16,759 iteration 1301 : loss : 0.047611, loss_ce: 0.022206
2021-12-16 14:55:18,181 iteration 1302 : loss : 0.061373, loss_ce: 0.032291
2021-12-16 14:55:19,608 iteration 1303 : loss : 0.066105, loss_ce: 0.031782
2021-12-16 14:55:21,074 iteration 1304 : loss : 0.072707, loss_ce: 0.035313
2021-12-16 14:55:22,501 iteration 1305 : loss : 0.081275, loss_ce: 0.039373
2021-12-16 14:55:23,967 iteration 1306 : loss : 0.070805, loss_ce: 0.025309
2021-12-16 14:55:25,433 iteration 1307 : loss : 0.086254, loss_ce: 0.049142
2021-12-16 14:55:26,902 iteration 1308 : loss : 0.085945, loss_ce: 0.029372
2021-12-16 14:55:28,294 iteration 1309 : loss : 0.073050, loss_ce: 0.027602
 19%|█████▊                        | 77/400 [35:34<2:23:32, 26.66s/it]2021-12-16 14:55:29,842 iteration 1310 : loss : 0.082070, loss_ce: 0.035115
2021-12-16 14:55:31,260 iteration 1311 : loss : 0.088261, loss_ce: 0.049509
2021-12-16 14:55:32,657 iteration 1312 : loss : 0.057814, loss_ce: 0.026819
2021-12-16 14:55:34,071 iteration 1313 : loss : 0.074158, loss_ce: 0.025144
2021-12-16 14:55:35,526 iteration 1314 : loss : 0.065254, loss_ce: 0.033060
2021-12-16 14:55:37,001 iteration 1315 : loss : 0.082465, loss_ce: 0.037895
2021-12-16 14:55:38,537 iteration 1316 : loss : 0.085448, loss_ce: 0.039120
2021-12-16 14:55:39,949 iteration 1317 : loss : 0.083322, loss_ce: 0.045169
2021-12-16 14:55:41,449 iteration 1318 : loss : 0.156119, loss_ce: 0.026520
2021-12-16 14:55:42,926 iteration 1319 : loss : 0.082229, loss_ce: 0.042950
2021-12-16 14:55:44,346 iteration 1320 : loss : 0.059092, loss_ce: 0.026688
2021-12-16 14:55:45,806 iteration 1321 : loss : 0.118632, loss_ce: 0.042456
2021-12-16 14:55:47,197 iteration 1322 : loss : 0.079137, loss_ce: 0.038843
2021-12-16 14:55:48,625 iteration 1323 : loss : 0.082178, loss_ce: 0.035808
2021-12-16 14:55:50,104 iteration 1324 : loss : 0.095512, loss_ce: 0.045421
2021-12-16 14:55:51,596 iteration 1325 : loss : 0.084102, loss_ce: 0.035576
2021-12-16 14:55:52,942 iteration 1326 : loss : 0.066046, loss_ce: 0.027902
 20%|█████▊                        | 78/400 [35:58<2:19:50, 26.06s/it]2021-12-16 14:55:54,405 iteration 1327 : loss : 0.076688, loss_ce: 0.026182
2021-12-16 14:55:55,866 iteration 1328 : loss : 0.092714, loss_ce: 0.048978
2021-12-16 14:55:57,299 iteration 1329 : loss : 0.059953, loss_ce: 0.029850
2021-12-16 14:55:58,697 iteration 1330 : loss : 0.138161, loss_ce: 0.039856
2021-12-16 14:56:00,083 iteration 1331 : loss : 0.060959, loss_ce: 0.032499
2021-12-16 14:56:01,485 iteration 1332 : loss : 0.058040, loss_ce: 0.023628
2021-12-16 14:56:02,909 iteration 1333 : loss : 0.056193, loss_ce: 0.023399
2021-12-16 14:56:04,346 iteration 1334 : loss : 0.054309, loss_ce: 0.024552
2021-12-16 14:56:05,763 iteration 1335 : loss : 0.062521, loss_ce: 0.025552
2021-12-16 14:56:07,178 iteration 1336 : loss : 0.058106, loss_ce: 0.029338
2021-12-16 14:56:08,672 iteration 1337 : loss : 0.105984, loss_ce: 0.051743
2021-12-16 14:56:10,125 iteration 1338 : loss : 0.087903, loss_ce: 0.038174
2021-12-16 14:56:11,590 iteration 1339 : loss : 0.060555, loss_ce: 0.033251
2021-12-16 14:56:13,056 iteration 1340 : loss : 0.069434, loss_ce: 0.034684
2021-12-16 14:56:14,518 iteration 1341 : loss : 0.069713, loss_ce: 0.030915
2021-12-16 14:56:15,945 iteration 1342 : loss : 0.080916, loss_ce: 0.035077
2021-12-16 14:56:17,320 iteration 1343 : loss : 0.054229, loss_ce: 0.025098
 20%|█████▉                        | 79/400 [36:23<2:16:42, 25.55s/it]2021-12-16 14:56:18,797 iteration 1344 : loss : 0.078791, loss_ce: 0.036984
2021-12-16 14:56:20,285 iteration 1345 : loss : 0.103639, loss_ce: 0.046432
2021-12-16 14:56:21,694 iteration 1346 : loss : 0.084467, loss_ce: 0.038918
2021-12-16 14:56:23,187 iteration 1347 : loss : 0.054411, loss_ce: 0.027171
2021-12-16 14:56:24,703 iteration 1348 : loss : 0.112382, loss_ce: 0.048675
2021-12-16 14:56:26,140 iteration 1349 : loss : 0.082700, loss_ce: 0.037776
2021-12-16 14:56:27,583 iteration 1350 : loss : 0.070337, loss_ce: 0.032491
2021-12-16 14:56:29,023 iteration 1351 : loss : 0.057441, loss_ce: 0.031491
2021-12-16 14:56:30,501 iteration 1352 : loss : 0.073931, loss_ce: 0.037996
2021-12-16 14:56:31,952 iteration 1353 : loss : 0.089228, loss_ce: 0.036396
2021-12-16 14:56:33,416 iteration 1354 : loss : 0.081235, loss_ce: 0.033875
2021-12-16 14:56:34,946 iteration 1355 : loss : 0.151737, loss_ce: 0.040168
2021-12-16 14:56:36,410 iteration 1356 : loss : 0.084125, loss_ce: 0.041903
2021-12-16 14:56:37,865 iteration 1357 : loss : 0.059179, loss_ce: 0.029334
2021-12-16 14:56:39,340 iteration 1358 : loss : 0.083612, loss_ce: 0.037933
2021-12-16 14:56:40,771 iteration 1359 : loss : 0.082325, loss_ce: 0.038058
2021-12-16 14:56:40,772 Training Data Eval:
2021-12-16 14:56:48,231   Average segmentation loss on training set: 0.0467
2021-12-16 14:56:48,232 Validation Data Eval:
2021-12-16 14:56:50,812   Average segmentation loss on validation set: 0.1264
2021-12-16 14:56:57,153 Found new lowest validation loss at iteration 1359! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/TU_3seeds/TU_RESNET_no_pretraining_SGD_best_val_loss_seed1234.pth
2021-12-16 14:56:58,599 iteration 1360 : loss : 0.075252, loss_ce: 0.024807
 20%|██████                        | 80/400 [37:04<2:41:26, 30.27s/it]2021-12-16 14:57:00,073 iteration 1361 : loss : 0.081844, loss_ce: 0.038149
2021-12-16 14:57:01,420 iteration 1362 : loss : 0.077232, loss_ce: 0.028337
2021-12-16 14:57:02,916 iteration 1363 : loss : 0.121737, loss_ce: 0.055310
2021-12-16 14:57:04,141 iteration 1364 : loss : 0.073792, loss_ce: 0.024290
2021-12-16 14:57:05,544 iteration 1365 : loss : 0.070737, loss_ce: 0.032264
2021-12-16 14:57:06,903 iteration 1366 : loss : 0.076951, loss_ce: 0.035703
2021-12-16 14:57:08,238 iteration 1367 : loss : 0.067068, loss_ce: 0.031695
2021-12-16 14:57:09,590 iteration 1368 : loss : 0.051705, loss_ce: 0.026370
2021-12-16 14:57:10,903 iteration 1369 : loss : 0.090776, loss_ce: 0.036688
2021-12-16 14:57:12,285 iteration 1370 : loss : 0.065916, loss_ce: 0.034544
2021-12-16 14:57:13,634 iteration 1371 : loss : 0.070405, loss_ce: 0.027572
2021-12-16 14:57:15,031 iteration 1372 : loss : 0.069889, loss_ce: 0.031572
2021-12-16 14:57:16,448 iteration 1373 : loss : 0.081817, loss_ce: 0.035212
2021-12-16 14:57:17,907 iteration 1374 : loss : 0.080780, loss_ce: 0.031893
2021-12-16 14:57:19,386 iteration 1375 : loss : 0.073868, loss_ce: 0.037630
2021-12-16 14:57:20,849 iteration 1376 : loss : 0.081418, loss_ce: 0.029413
2021-12-16 14:57:22,292 iteration 1377 : loss : 0.047208, loss_ce: 0.021158
 20%|██████                        | 81/400 [37:28<2:30:27, 28.30s/it]2021-12-16 14:57:23,727 iteration 1378 : loss : 0.076370, loss_ce: 0.035006
2021-12-16 14:57:25,216 iteration 1379 : loss : 0.060896, loss_ce: 0.024576
2021-12-16 14:57:26,674 iteration 1380 : loss : 0.073965, loss_ce: 0.033522
2021-12-16 14:57:28,207 iteration 1381 : loss : 0.079722, loss_ce: 0.034613
2021-12-16 14:57:29,592 iteration 1382 : loss : 0.057456, loss_ce: 0.025867
2021-12-16 14:57:31,111 iteration 1383 : loss : 0.076760, loss_ce: 0.030340
2021-12-16 14:57:32,551 iteration 1384 : loss : 0.066716, loss_ce: 0.029838
2021-12-16 14:57:33,940 iteration 1385 : loss : 0.078709, loss_ce: 0.037423
2021-12-16 14:57:35,363 iteration 1386 : loss : 0.056789, loss_ce: 0.026509
2021-12-16 14:57:36,786 iteration 1387 : loss : 0.065731, loss_ce: 0.028554
2021-12-16 14:57:38,233 iteration 1388 : loss : 0.078354, loss_ce: 0.029467
2021-12-16 14:57:39,683 iteration 1389 : loss : 0.079736, loss_ce: 0.036670
2021-12-16 14:57:41,166 iteration 1390 : loss : 0.071759, loss_ce: 0.033523
2021-12-16 14:57:42,658 iteration 1391 : loss : 0.073845, loss_ce: 0.034027
2021-12-16 14:57:44,123 iteration 1392 : loss : 0.077017, loss_ce: 0.040002
2021-12-16 14:57:45,544 iteration 1393 : loss : 0.074079, loss_ce: 0.028439
2021-12-16 14:57:47,044 iteration 1394 : loss : 0.058098, loss_ce: 0.028474
 20%|██████▏                       | 82/400 [37:52<2:24:20, 27.23s/it]2021-12-16 14:57:48,506 iteration 1395 : loss : 0.062306, loss_ce: 0.029499
2021-12-16 14:57:49,910 iteration 1396 : loss : 0.069911, loss_ce: 0.036044
2021-12-16 14:57:51,402 iteration 1397 : loss : 0.088527, loss_ce: 0.032794
2021-12-16 14:57:52,900 iteration 1398 : loss : 0.090867, loss_ce: 0.046509
2021-12-16 14:57:54,264 iteration 1399 : loss : 0.067186, loss_ce: 0.034899
2021-12-16 14:57:55,629 iteration 1400 : loss : 0.061863, loss_ce: 0.027372
2021-12-16 14:57:57,135 iteration 1401 : loss : 0.086610, loss_ce: 0.033790
2021-12-16 14:57:58,579 iteration 1402 : loss : 0.088275, loss_ce: 0.040102
2021-12-16 14:57:59,977 iteration 1403 : loss : 0.060763, loss_ce: 0.024869
2021-12-16 14:58:01,375 iteration 1404 : loss : 0.046772, loss_ce: 0.026427
2021-12-16 14:58:02,810 iteration 1405 : loss : 0.074988, loss_ce: 0.033068
2021-12-16 14:58:04,260 iteration 1406 : loss : 0.082871, loss_ce: 0.033534
2021-12-16 14:58:05,753 iteration 1407 : loss : 0.056214, loss_ce: 0.027371
2021-12-16 14:58:07,182 iteration 1408 : loss : 0.065736, loss_ce: 0.027604
2021-12-16 14:58:08,619 iteration 1409 : loss : 0.111694, loss_ce: 0.035245
2021-12-16 14:58:10,110 iteration 1410 : loss : 0.060984, loss_ce: 0.026612
2021-12-16 14:58:11,519 iteration 1411 : loss : 0.075075, loss_ce: 0.027168
 21%|██████▏                       | 83/400 [38:17<2:19:30, 26.41s/it]2021-12-16 14:58:12,964 iteration 1412 : loss : 0.068351, loss_ce: 0.027947
2021-12-16 14:58:14,497 iteration 1413 : loss : 0.093726, loss_ce: 0.034076
2021-12-16 14:58:15,921 iteration 1414 : loss : 0.053278, loss_ce: 0.022950
2021-12-16 14:58:17,389 iteration 1415 : loss : 0.087271, loss_ce: 0.027001
2021-12-16 14:58:18,803 iteration 1416 : loss : 0.070947, loss_ce: 0.033858
2021-12-16 14:58:20,223 iteration 1417 : loss : 0.085486, loss_ce: 0.028600
2021-12-16 14:58:21,648 iteration 1418 : loss : 0.072091, loss_ce: 0.035919
2021-12-16 14:58:23,043 iteration 1419 : loss : 0.059198, loss_ce: 0.022686
2021-12-16 14:58:24,520 iteration 1420 : loss : 0.063543, loss_ce: 0.028026
2021-12-16 14:58:26,020 iteration 1421 : loss : 0.093629, loss_ce: 0.042175
2021-12-16 14:58:27,468 iteration 1422 : loss : 0.058563, loss_ce: 0.023656
2021-12-16 14:58:28,853 iteration 1423 : loss : 0.074188, loss_ce: 0.034707
2021-12-16 14:58:30,324 iteration 1424 : loss : 0.065738, loss_ce: 0.029798
2021-12-16 14:58:31,789 iteration 1425 : loss : 0.051216, loss_ce: 0.025222
2021-12-16 14:58:33,188 iteration 1426 : loss : 0.062678, loss_ce: 0.031165
2021-12-16 14:58:34,623 iteration 1427 : loss : 0.070974, loss_ce: 0.031892
2021-12-16 14:58:35,977 iteration 1428 : loss : 0.064666, loss_ce: 0.027612
 21%|██████▎                       | 84/400 [38:41<2:16:00, 25.82s/it]2021-12-16 14:58:37,539 iteration 1429 : loss : 0.066089, loss_ce: 0.036713
2021-12-16 14:58:38,930 iteration 1430 : loss : 0.182587, loss_ce: 0.042018
2021-12-16 14:58:40,359 iteration 1431 : loss : 0.074762, loss_ce: 0.038549
2021-12-16 14:58:41,797 iteration 1432 : loss : 0.079200, loss_ce: 0.040786
2021-12-16 14:58:43,272 iteration 1433 : loss : 0.072885, loss_ce: 0.030136
2021-12-16 14:58:44,691 iteration 1434 : loss : 0.072338, loss_ce: 0.034738
2021-12-16 14:58:46,151 iteration 1435 : loss : 0.082632, loss_ce: 0.034025
2021-12-16 14:58:47,630 iteration 1436 : loss : 0.078884, loss_ce: 0.034462
2021-12-16 14:58:49,115 iteration 1437 : loss : 0.107342, loss_ce: 0.046781
2021-12-16 14:58:50,575 iteration 1438 : loss : 0.067527, loss_ce: 0.036419
2021-12-16 14:58:52,068 iteration 1439 : loss : 0.079289, loss_ce: 0.036055
2021-12-16 14:58:53,529 iteration 1440 : loss : 0.064688, loss_ce: 0.033354
2021-12-16 14:58:54,937 iteration 1441 : loss : 0.054585, loss_ce: 0.026516
2021-12-16 14:58:56,368 iteration 1442 : loss : 0.060281, loss_ce: 0.027602
2021-12-16 14:58:57,831 iteration 1443 : loss : 0.073925, loss_ce: 0.030984
2021-12-16 14:58:59,288 iteration 1444 : loss : 0.107176, loss_ce: 0.031551
2021-12-16 14:58:59,288 Training Data Eval:
2021-12-16 14:59:06,752   Average segmentation loss on training set: 0.0410
2021-12-16 14:59:06,752 Validation Data Eval:
2021-12-16 14:59:09,324   Average segmentation loss on validation set: 0.1208
2021-12-16 14:59:14,431 Found new lowest validation loss at iteration 1444! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/TU_3seeds/TU_RESNET_no_pretraining_SGD_best_val_loss_seed1234.pth
2021-12-16 14:59:15,814 iteration 1445 : loss : 0.066697, loss_ce: 0.025066
 21%|██████▍                       | 85/400 [39:21<2:37:38, 30.03s/it]2021-12-16 14:59:17,310 iteration 1446 : loss : 0.076259, loss_ce: 0.029092
2021-12-16 14:59:18,638 iteration 1447 : loss : 0.072390, loss_ce: 0.028872
2021-12-16 14:59:19,920 iteration 1448 : loss : 0.061642, loss_ce: 0.035371
2021-12-16 14:59:21,283 iteration 1449 : loss : 0.058605, loss_ce: 0.023719
2021-12-16 14:59:22,719 iteration 1450 : loss : 0.072146, loss_ce: 0.039559
2021-12-16 14:59:24,168 iteration 1451 : loss : 0.083632, loss_ce: 0.031576
2021-12-16 14:59:25,481 iteration 1452 : loss : 0.052571, loss_ce: 0.021649
2021-12-16 14:59:26,801 iteration 1453 : loss : 0.070609, loss_ce: 0.029028
2021-12-16 14:59:28,171 iteration 1454 : loss : 0.074026, loss_ce: 0.028877
2021-12-16 14:59:29,526 iteration 1455 : loss : 0.069074, loss_ce: 0.034887
2021-12-16 14:59:31,042 iteration 1456 : loss : 0.103854, loss_ce: 0.028884
2021-12-16 14:59:32,498 iteration 1457 : loss : 0.065747, loss_ce: 0.029233
2021-12-16 14:59:33,941 iteration 1458 : loss : 0.065115, loss_ce: 0.024356
2021-12-16 14:59:35,355 iteration 1459 : loss : 0.051757, loss_ce: 0.017395
2021-12-16 14:59:36,874 iteration 1460 : loss : 0.107621, loss_ce: 0.057887
2021-12-16 14:59:38,337 iteration 1461 : loss : 0.078829, loss_ce: 0.040660
2021-12-16 14:59:39,834 iteration 1462 : loss : 0.065872, loss_ce: 0.031707
 22%|██████▍                       | 86/400 [39:45<2:27:42, 28.22s/it]2021-12-16 14:59:41,325 iteration 1463 : loss : 0.068419, loss_ce: 0.033893
2021-12-16 14:59:42,752 iteration 1464 : loss : 0.058003, loss_ce: 0.024727
2021-12-16 14:59:44,227 iteration 1465 : loss : 0.074723, loss_ce: 0.026435
2021-12-16 14:59:45,697 iteration 1466 : loss : 0.050574, loss_ce: 0.023119
2021-12-16 14:59:47,140 iteration 1467 : loss : 0.070249, loss_ce: 0.033284
2021-12-16 14:59:48,557 iteration 1468 : loss : 0.046835, loss_ce: 0.025215
2021-12-16 14:59:49,988 iteration 1469 : loss : 0.077069, loss_ce: 0.032917
2021-12-16 14:59:51,453 iteration 1470 : loss : 0.115630, loss_ce: 0.044233
2021-12-16 14:59:52,910 iteration 1471 : loss : 0.067255, loss_ce: 0.037141
2021-12-16 14:59:54,264 iteration 1472 : loss : 0.048568, loss_ce: 0.022532
2021-12-16 14:59:55,790 iteration 1473 : loss : 0.059445, loss_ce: 0.027091
2021-12-16 14:59:57,281 iteration 1474 : loss : 0.105238, loss_ce: 0.039905
2021-12-16 14:59:58,727 iteration 1475 : loss : 0.067791, loss_ce: 0.029801
2021-12-16 15:00:00,248 iteration 1476 : loss : 0.087956, loss_ce: 0.038259
2021-12-16 15:00:01,716 iteration 1477 : loss : 0.059873, loss_ce: 0.023989
2021-12-16 15:00:03,224 iteration 1478 : loss : 0.086510, loss_ce: 0.035899
2021-12-16 15:00:04,615 iteration 1479 : loss : 0.074176, loss_ce: 0.028503
 22%|██████▌                       | 87/400 [40:10<2:21:51, 27.19s/it]2021-12-16 15:00:06,110 iteration 1480 : loss : 0.064566, loss_ce: 0.028974
2021-12-16 15:00:07,529 iteration 1481 : loss : 0.053747, loss_ce: 0.025718
2021-12-16 15:00:08,970 iteration 1482 : loss : 0.064150, loss_ce: 0.029587
2021-12-16 15:00:10,473 iteration 1483 : loss : 0.078761, loss_ce: 0.033918
2021-12-16 15:00:12,023 iteration 1484 : loss : 0.078771, loss_ce: 0.028133
2021-12-16 15:00:13,517 iteration 1485 : loss : 0.061045, loss_ce: 0.029868
2021-12-16 15:00:14,931 iteration 1486 : loss : 0.068634, loss_ce: 0.031958
2021-12-16 15:00:16,365 iteration 1487 : loss : 0.062495, loss_ce: 0.034546
2021-12-16 15:00:17,828 iteration 1488 : loss : 0.056934, loss_ce: 0.025565
2021-12-16 15:00:19,281 iteration 1489 : loss : 0.051968, loss_ce: 0.023706
2021-12-16 15:00:20,744 iteration 1490 : loss : 0.081660, loss_ce: 0.035803
2021-12-16 15:00:22,249 iteration 1491 : loss : 0.069056, loss_ce: 0.032319
2021-12-16 15:00:23,663 iteration 1492 : loss : 0.061086, loss_ce: 0.029258
2021-12-16 15:00:25,141 iteration 1493 : loss : 0.075798, loss_ce: 0.031845
2021-12-16 15:00:26,551 iteration 1494 : loss : 0.047256, loss_ce: 0.021621
2021-12-16 15:00:27,972 iteration 1495 : loss : 0.062825, loss_ce: 0.027601
2021-12-16 15:00:29,417 iteration 1496 : loss : 0.073218, loss_ce: 0.025838
 22%|██████▌                       | 88/400 [40:35<2:17:39, 26.47s/it]2021-12-16 15:00:30,866 iteration 1497 : loss : 0.062243, loss_ce: 0.028466
2021-12-16 15:00:32,292 iteration 1498 : loss : 0.057729, loss_ce: 0.020810
2021-12-16 15:00:33,778 iteration 1499 : loss : 0.066431, loss_ce: 0.032743
2021-12-16 15:00:35,162 iteration 1500 : loss : 0.072955, loss_ce: 0.027194
2021-12-16 15:00:36,597 iteration 1501 : loss : 0.084919, loss_ce: 0.037454
2021-12-16 15:00:38,066 iteration 1502 : loss : 0.058448, loss_ce: 0.024643
2021-12-16 15:00:39,491 iteration 1503 : loss : 0.051103, loss_ce: 0.027626
2021-12-16 15:00:40,913 iteration 1504 : loss : 0.057132, loss_ce: 0.024996
2021-12-16 15:00:42,304 iteration 1505 : loss : 0.054480, loss_ce: 0.023498
2021-12-16 15:00:43,736 iteration 1506 : loss : 0.087559, loss_ce: 0.037555
2021-12-16 15:00:45,181 iteration 1507 : loss : 0.075310, loss_ce: 0.029505
2021-12-16 15:00:46,592 iteration 1508 : loss : 0.062393, loss_ce: 0.031024
2021-12-16 15:00:48,024 iteration 1509 : loss : 0.072498, loss_ce: 0.026238
2021-12-16 15:00:49,425 iteration 1510 : loss : 0.052333, loss_ce: 0.021471
2021-12-16 15:00:50,870 iteration 1511 : loss : 0.062660, loss_ce: 0.030469
2021-12-16 15:00:52,255 iteration 1512 : loss : 0.057120, loss_ce: 0.025233
2021-12-16 15:00:53,694 iteration 1513 : loss : 0.102279, loss_ce: 0.061274
 22%|██████▋                       | 89/400 [40:59<2:13:48, 25.81s/it]2021-12-16 15:00:55,159 iteration 1514 : loss : 0.051431, loss_ce: 0.020620
2021-12-16 15:00:56,610 iteration 1515 : loss : 0.073759, loss_ce: 0.033595
2021-12-16 15:00:58,090 iteration 1516 : loss : 0.069702, loss_ce: 0.031707
2021-12-16 15:00:59,541 iteration 1517 : loss : 0.067464, loss_ce: 0.030493
2021-12-16 15:01:01,031 iteration 1518 : loss : 0.069916, loss_ce: 0.024403
2021-12-16 15:01:02,449 iteration 1519 : loss : 0.057143, loss_ce: 0.024644
2021-12-16 15:01:03,864 iteration 1520 : loss : 0.058406, loss_ce: 0.023842
2021-12-16 15:01:05,303 iteration 1521 : loss : 0.073284, loss_ce: 0.029600
2021-12-16 15:01:06,859 iteration 1522 : loss : 0.075445, loss_ce: 0.029110
2021-12-16 15:01:08,248 iteration 1523 : loss : 0.063362, loss_ce: 0.030976
2021-12-16 15:01:09,727 iteration 1524 : loss : 0.083455, loss_ce: 0.034535
2021-12-16 15:01:11,164 iteration 1525 : loss : 0.047190, loss_ce: 0.024906
2021-12-16 15:01:12,677 iteration 1526 : loss : 0.053603, loss_ce: 0.023635
2021-12-16 15:01:14,184 iteration 1527 : loss : 0.091439, loss_ce: 0.045202
2021-12-16 15:01:15,676 iteration 1528 : loss : 0.068897, loss_ce: 0.029890
2021-12-16 15:01:17,109 iteration 1529 : loss : 0.066014, loss_ce: 0.028667
2021-12-16 15:01:17,109 Training Data Eval:
2021-12-16 15:01:24,638   Average segmentation loss on training set: 0.0377
2021-12-16 15:01:24,639 Validation Data Eval:
2021-12-16 15:01:27,234   Average segmentation loss on validation set: 0.1190
2021-12-16 15:01:33,642 Found new lowest validation loss at iteration 1529! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/TU_3seeds/TU_RESNET_no_pretraining_SGD_best_val_loss_seed1234.pth
2021-12-16 15:01:35,010 iteration 1530 : loss : 0.073624, loss_ce: 0.033770
 22%|██████▊                       | 90/400 [41:40<2:37:24, 30.47s/it]2021-12-16 15:01:36,544 iteration 1531 : loss : 0.077678, loss_ce: 0.034072
2021-12-16 15:01:37,954 iteration 1532 : loss : 0.074068, loss_ce: 0.028447
2021-12-16 15:01:39,273 iteration 1533 : loss : 0.051680, loss_ce: 0.026940
2021-12-16 15:01:40,689 iteration 1534 : loss : 0.078352, loss_ce: 0.030695
2021-12-16 15:01:42,038 iteration 1535 : loss : 0.070357, loss_ce: 0.030401
2021-12-16 15:01:43,365 iteration 1536 : loss : 0.095238, loss_ce: 0.054461
2021-12-16 15:01:44,705 iteration 1537 : loss : 0.087208, loss_ce: 0.034880
2021-12-16 15:01:46,008 iteration 1538 : loss : 0.151910, loss_ce: 0.034098
2021-12-16 15:01:47,359 iteration 1539 : loss : 0.064654, loss_ce: 0.027418
2021-12-16 15:01:48,714 iteration 1540 : loss : 0.064944, loss_ce: 0.033480
2021-12-16 15:01:49,982 iteration 1541 : loss : 0.056185, loss_ce: 0.024907
2021-12-16 15:01:51,402 iteration 1542 : loss : 0.074393, loss_ce: 0.039572
2021-12-16 15:01:52,840 iteration 1543 : loss : 0.059508, loss_ce: 0.022899
2021-12-16 15:01:54,249 iteration 1544 : loss : 0.065014, loss_ce: 0.028853
2021-12-16 15:01:55,712 iteration 1545 : loss : 0.061121, loss_ce: 0.029381
2021-12-16 15:01:57,163 iteration 1546 : loss : 0.069383, loss_ce: 0.034928
2021-12-16 15:01:58,618 iteration 1547 : loss : 0.070117, loss_ce: 0.028741
 23%|██████▊                       | 91/400 [42:04<2:26:18, 28.41s/it]2021-12-16 15:02:00,124 iteration 1548 : loss : 0.074131, loss_ce: 0.030316
2021-12-16 15:02:01,537 iteration 1549 : loss : 0.045042, loss_ce: 0.023318
2021-12-16 15:02:03,088 iteration 1550 : loss : 0.076333, loss_ce: 0.035747
2021-12-16 15:02:04,532 iteration 1551 : loss : 0.084635, loss_ce: 0.034915
2021-12-16 15:02:05,985 iteration 1552 : loss : 0.057458, loss_ce: 0.027985
2021-12-16 15:02:07,365 iteration 1553 : loss : 0.051562, loss_ce: 0.029198
2021-12-16 15:02:08,791 iteration 1554 : loss : 0.069282, loss_ce: 0.029560
2021-12-16 15:02:10,309 iteration 1555 : loss : 0.067307, loss_ce: 0.028366
2021-12-16 15:02:11,877 iteration 1556 : loss : 0.081340, loss_ce: 0.035730
2021-12-16 15:02:13,389 iteration 1557 : loss : 0.107938, loss_ce: 0.028762
2021-12-16 15:02:14,854 iteration 1558 : loss : 0.071288, loss_ce: 0.024973
2021-12-16 15:02:16,421 iteration 1559 : loss : 0.074466, loss_ce: 0.036956
2021-12-16 15:02:17,850 iteration 1560 : loss : 0.068521, loss_ce: 0.023187
2021-12-16 15:02:19,283 iteration 1561 : loss : 0.086865, loss_ce: 0.038968
2021-12-16 15:02:20,743 iteration 1562 : loss : 0.070823, loss_ce: 0.034811
2021-12-16 15:02:22,177 iteration 1563 : loss : 0.063207, loss_ce: 0.036319
2021-12-16 15:02:23,634 iteration 1564 : loss : 0.071168, loss_ce: 0.029963
 23%|██████▉                       | 92/400 [42:29<2:20:36, 27.39s/it]2021-12-16 15:02:25,156 iteration 1565 : loss : 0.069233, loss_ce: 0.030066
2021-12-16 15:02:26,606 iteration 1566 : loss : 0.077561, loss_ce: 0.033554
2021-12-16 15:02:28,099 iteration 1567 : loss : 0.085576, loss_ce: 0.026900
2021-12-16 15:02:29,645 iteration 1568 : loss : 0.052195, loss_ce: 0.025816
2021-12-16 15:02:31,066 iteration 1569 : loss : 0.052307, loss_ce: 0.025729
2021-12-16 15:02:32,545 iteration 1570 : loss : 0.058665, loss_ce: 0.028391
2021-12-16 15:02:33,997 iteration 1571 : loss : 0.073973, loss_ce: 0.036126
2021-12-16 15:02:35,432 iteration 1572 : loss : 0.063394, loss_ce: 0.032226
2021-12-16 15:02:36,879 iteration 1573 : loss : 0.079237, loss_ce: 0.025667
2021-12-16 15:02:38,343 iteration 1574 : loss : 0.076182, loss_ce: 0.040872
2021-12-16 15:02:39,792 iteration 1575 : loss : 0.084123, loss_ce: 0.040040
2021-12-16 15:02:41,205 iteration 1576 : loss : 0.046066, loss_ce: 0.019355
2021-12-16 15:02:42,608 iteration 1577 : loss : 0.087410, loss_ce: 0.029641
2021-12-16 15:02:43,970 iteration 1578 : loss : 0.058602, loss_ce: 0.032550
2021-12-16 15:02:45,419 iteration 1579 : loss : 0.065212, loss_ce: 0.027291
2021-12-16 15:02:46,896 iteration 1580 : loss : 0.046695, loss_ce: 0.018852
2021-12-16 15:02:48,343 iteration 1581 : loss : 0.052127, loss_ce: 0.025903
 23%|██████▉                       | 93/400 [42:54<2:16:02, 26.59s/it]2021-12-16 15:02:49,858 iteration 1582 : loss : 0.062166, loss_ce: 0.029925
2021-12-16 15:02:51,297 iteration 1583 : loss : 0.104438, loss_ce: 0.030855
2021-12-16 15:02:52,676 iteration 1584 : loss : 0.064928, loss_ce: 0.026788
2021-12-16 15:02:54,109 iteration 1585 : loss : 0.043308, loss_ce: 0.023021
2021-12-16 15:02:55,494 iteration 1586 : loss : 0.056356, loss_ce: 0.027623
2021-12-16 15:02:56,921 iteration 1587 : loss : 0.054563, loss_ce: 0.022497
2021-12-16 15:02:58,344 iteration 1588 : loss : 0.053301, loss_ce: 0.021358
2021-12-16 15:02:59,796 iteration 1589 : loss : 0.059886, loss_ce: 0.026935
2021-12-16 15:03:01,314 iteration 1590 : loss : 0.092666, loss_ce: 0.034651
2021-12-16 15:03:02,716 iteration 1591 : loss : 0.063639, loss_ce: 0.036098
2021-12-16 15:03:04,086 iteration 1592 : loss : 0.041586, loss_ce: 0.021576
2021-12-16 15:03:05,563 iteration 1593 : loss : 0.062475, loss_ce: 0.023062
2021-12-16 15:03:07,001 iteration 1594 : loss : 0.056892, loss_ce: 0.023989
2021-12-16 15:03:08,392 iteration 1595 : loss : 0.066631, loss_ce: 0.040032
2021-12-16 15:03:09,759 iteration 1596 : loss : 0.060861, loss_ce: 0.026798
2021-12-16 15:03:11,222 iteration 1597 : loss : 0.093803, loss_ce: 0.027903
2021-12-16 15:03:12,702 iteration 1598 : loss : 0.088591, loss_ce: 0.034884
 24%|███████                       | 94/400 [43:18<2:12:10, 25.92s/it]2021-12-16 15:03:14,210 iteration 1599 : loss : 0.062034, loss_ce: 0.032395
2021-12-16 15:03:15,615 iteration 1600 : loss : 0.050078, loss_ce: 0.024214
2021-12-16 15:03:17,087 iteration 1601 : loss : 0.057727, loss_ce: 0.025115
2021-12-16 15:03:18,541 iteration 1602 : loss : 0.076900, loss_ce: 0.025500
2021-12-16 15:03:19,967 iteration 1603 : loss : 0.051137, loss_ce: 0.024082
2021-12-16 15:03:21,373 iteration 1604 : loss : 0.074652, loss_ce: 0.027105
2021-12-16 15:03:22,789 iteration 1605 : loss : 0.074614, loss_ce: 0.032296
2021-12-16 15:03:24,232 iteration 1606 : loss : 0.059108, loss_ce: 0.027828
2021-12-16 15:03:25,668 iteration 1607 : loss : 0.082537, loss_ce: 0.038315
2021-12-16 15:03:27,188 iteration 1608 : loss : 0.083379, loss_ce: 0.038029
2021-12-16 15:03:28,624 iteration 1609 : loss : 0.056647, loss_ce: 0.024552
2021-12-16 15:03:30,138 iteration 1610 : loss : 0.066020, loss_ce: 0.028788
2021-12-16 15:03:31,644 iteration 1611 : loss : 0.070254, loss_ce: 0.039435
2021-12-16 15:03:33,170 iteration 1612 : loss : 0.060871, loss_ce: 0.026941
2021-12-16 15:03:34,614 iteration 1613 : loss : 0.075559, loss_ce: 0.032491
2021-12-16 15:03:36,122 iteration 1614 : loss : 0.064130, loss_ce: 0.029746
2021-12-16 15:03:36,122 Training Data Eval:
2021-12-16 15:03:43,580   Average segmentation loss on training set: 0.0368
2021-12-16 15:03:43,581 Validation Data Eval:
2021-12-16 15:03:46,167   Average segmentation loss on validation set: 0.1290
2021-12-16 15:03:47,688 iteration 1615 : loss : 0.070858, loss_ce: 0.029796
 24%|███████▏                      | 95/400 [43:53<2:25:34, 28.64s/it]2021-12-16 15:03:49,191 iteration 1616 : loss : 0.062273, loss_ce: 0.026049
2021-12-16 15:03:50,624 iteration 1617 : loss : 0.086304, loss_ce: 0.040783
2021-12-16 15:03:52,016 iteration 1618 : loss : 0.065564, loss_ce: 0.026876
2021-12-16 15:03:53,461 iteration 1619 : loss : 0.066060, loss_ce: 0.039933
2021-12-16 15:03:55,014 iteration 1620 : loss : 0.063530, loss_ce: 0.024281
2021-12-16 15:03:56,549 iteration 1621 : loss : 0.071543, loss_ce: 0.029604
2021-12-16 15:03:57,978 iteration 1622 : loss : 0.057458, loss_ce: 0.025489
2021-12-16 15:03:59,378 iteration 1623 : loss : 0.053590, loss_ce: 0.020492
2021-12-16 15:04:00,865 iteration 1624 : loss : 0.059426, loss_ce: 0.027278
2021-12-16 15:04:02,256 iteration 1625 : loss : 0.056779, loss_ce: 0.022973
2021-12-16 15:04:03,683 iteration 1626 : loss : 0.052674, loss_ce: 0.025280
2021-12-16 15:04:05,225 iteration 1627 : loss : 0.082111, loss_ce: 0.039084
2021-12-16 15:04:06,735 iteration 1628 : loss : 0.062874, loss_ce: 0.031053
2021-12-16 15:04:08,147 iteration 1629 : loss : 0.041138, loss_ce: 0.017545
2021-12-16 15:04:09,560 iteration 1630 : loss : 0.043655, loss_ce: 0.019686
2021-12-16 15:04:10,983 iteration 1631 : loss : 0.069119, loss_ce: 0.025328
2021-12-16 15:04:12,402 iteration 1632 : loss : 0.048967, loss_ce: 0.022377
 24%|███████▏                      | 96/400 [44:18<2:19:08, 27.46s/it]2021-12-16 15:04:13,896 iteration 1633 : loss : 0.061050, loss_ce: 0.022700
2021-12-16 15:04:15,361 iteration 1634 : loss : 0.085937, loss_ce: 0.037329
2021-12-16 15:04:16,789 iteration 1635 : loss : 0.074036, loss_ce: 0.024010
2021-12-16 15:04:18,168 iteration 1636 : loss : 0.059209, loss_ce: 0.029722
2021-12-16 15:04:19,642 iteration 1637 : loss : 0.080126, loss_ce: 0.029337
2021-12-16 15:04:21,078 iteration 1638 : loss : 0.069474, loss_ce: 0.034123
2021-12-16 15:04:22,574 iteration 1639 : loss : 0.066777, loss_ce: 0.032893
2021-12-16 15:04:23,979 iteration 1640 : loss : 0.063903, loss_ce: 0.023243
2021-12-16 15:04:25,483 iteration 1641 : loss : 0.092340, loss_ce: 0.040074
2021-12-16 15:04:26,870 iteration 1642 : loss : 0.051609, loss_ce: 0.022474
2021-12-16 15:04:28,236 iteration 1643 : loss : 0.056843, loss_ce: 0.022849
2021-12-16 15:04:29,739 iteration 1644 : loss : 0.062075, loss_ce: 0.027992
2021-12-16 15:04:31,273 iteration 1645 : loss : 0.062258, loss_ce: 0.030354
2021-12-16 15:04:32,693 iteration 1646 : loss : 0.076785, loss_ce: 0.033250
2021-12-16 15:04:34,139 iteration 1647 : loss : 0.107576, loss_ce: 0.037763
2021-12-16 15:04:35,490 iteration 1648 : loss : 0.044862, loss_ce: 0.022118
2021-12-16 15:04:36,869 iteration 1649 : loss : 0.053255, loss_ce: 0.023673
 24%|███████▎                      | 97/400 [44:42<2:14:08, 26.56s/it]2021-12-16 15:04:38,454 iteration 1650 : loss : 0.080189, loss_ce: 0.047320
2021-12-16 15:04:39,877 iteration 1651 : loss : 0.088121, loss_ce: 0.029049
2021-12-16 15:04:41,331 iteration 1652 : loss : 0.093553, loss_ce: 0.028746
2021-12-16 15:04:42,745 iteration 1653 : loss : 0.054722, loss_ce: 0.021008
2021-12-16 15:04:44,181 iteration 1654 : loss : 0.064525, loss_ce: 0.025381
2021-12-16 15:04:45,572 iteration 1655 : loss : 0.061682, loss_ce: 0.026282
2021-12-16 15:04:47,048 iteration 1656 : loss : 0.074600, loss_ce: 0.037314
2021-12-16 15:04:48,483 iteration 1657 : loss : 0.044144, loss_ce: 0.022327
2021-12-16 15:04:49,975 iteration 1658 : loss : 0.111970, loss_ce: 0.067250
2021-12-16 15:04:51,475 iteration 1659 : loss : 0.062179, loss_ce: 0.029506
2021-12-16 15:04:52,917 iteration 1660 : loss : 0.052533, loss_ce: 0.022543
2021-12-16 15:04:54,306 iteration 1661 : loss : 0.057390, loss_ce: 0.021992
2021-12-16 15:04:55,770 iteration 1662 : loss : 0.078654, loss_ce: 0.028793
2021-12-16 15:04:57,249 iteration 1663 : loss : 0.050690, loss_ce: 0.026132
2021-12-16 15:04:58,673 iteration 1664 : loss : 0.064116, loss_ce: 0.026650
2021-12-16 15:05:00,083 iteration 1665 : loss : 0.065119, loss_ce: 0.028807
2021-12-16 15:05:01,531 iteration 1666 : loss : 0.048592, loss_ce: 0.017571
 24%|███████▎                      | 98/400 [45:07<2:10:49, 25.99s/it]2021-12-16 15:05:02,965 iteration 1667 : loss : 0.052146, loss_ce: 0.028031
2021-12-16 15:05:04,473 iteration 1668 : loss : 0.062229, loss_ce: 0.025355
2021-12-16 15:05:05,957 iteration 1669 : loss : 0.053088, loss_ce: 0.020224
2021-12-16 15:05:07,336 iteration 1670 : loss : 0.036096, loss_ce: 0.015376
2021-12-16 15:05:08,740 iteration 1671 : loss : 0.042003, loss_ce: 0.021194
2021-12-16 15:05:10,255 iteration 1672 : loss : 0.061500, loss_ce: 0.027385
2021-12-16 15:05:11,720 iteration 1673 : loss : 0.043057, loss_ce: 0.015604
2021-12-16 15:05:13,260 iteration 1674 : loss : 0.080257, loss_ce: 0.033884
2021-12-16 15:05:14,682 iteration 1675 : loss : 0.090860, loss_ce: 0.034200
2021-12-16 15:05:16,172 iteration 1676 : loss : 0.062620, loss_ce: 0.031492
2021-12-16 15:05:17,615 iteration 1677 : loss : 0.073106, loss_ce: 0.024508
2021-12-16 15:05:19,078 iteration 1678 : loss : 0.058882, loss_ce: 0.029735
2021-12-16 15:05:20,534 iteration 1679 : loss : 0.064191, loss_ce: 0.028702
2021-12-16 15:05:22,005 iteration 1680 : loss : 0.054879, loss_ce: 0.027641
2021-12-16 15:05:23,433 iteration 1681 : loss : 0.071059, loss_ce: 0.029522
2021-12-16 15:05:24,862 iteration 1682 : loss : 0.081385, loss_ce: 0.038863
2021-12-16 15:05:26,265 iteration 1683 : loss : 0.059778, loss_ce: 0.029981
 25%|███████▍                      | 99/400 [45:32<2:08:30, 25.62s/it]2021-12-16 15:05:27,771 iteration 1684 : loss : 0.072192, loss_ce: 0.029846
2021-12-16 15:05:29,168 iteration 1685 : loss : 0.050074, loss_ce: 0.027861
2021-12-16 15:05:30,548 iteration 1686 : loss : 0.045130, loss_ce: 0.019887
2021-12-16 15:05:31,979 iteration 1687 : loss : 0.062354, loss_ce: 0.026909
2021-12-16 15:05:33,451 iteration 1688 : loss : 0.051719, loss_ce: 0.027435
2021-12-16 15:05:34,857 iteration 1689 : loss : 0.058249, loss_ce: 0.024692
2021-12-16 15:05:36,340 iteration 1690 : loss : 0.088561, loss_ce: 0.034656
2021-12-16 15:05:37,775 iteration 1691 : loss : 0.043442, loss_ce: 0.021160
2021-12-16 15:05:39,250 iteration 1692 : loss : 0.069431, loss_ce: 0.028672
2021-12-16 15:05:40,754 iteration 1693 : loss : 0.060220, loss_ce: 0.032043
2021-12-16 15:05:42,215 iteration 1694 : loss : 0.060904, loss_ce: 0.022492
2021-12-16 15:05:43,575 iteration 1695 : loss : 0.054957, loss_ce: 0.020935
2021-12-16 15:05:45,014 iteration 1696 : loss : 0.064599, loss_ce: 0.024501
2021-12-16 15:05:46,506 iteration 1697 : loss : 0.068227, loss_ce: 0.027659
2021-12-16 15:05:47,935 iteration 1698 : loss : 0.057486, loss_ce: 0.022545
2021-12-16 15:05:49,287 iteration 1699 : loss : 0.050875, loss_ce: 0.026165
2021-12-16 15:05:49,288 Training Data Eval:
2021-12-16 15:05:56,772   Average segmentation loss on training set: 0.0355
2021-12-16 15:05:56,773 Validation Data Eval:
2021-12-16 15:05:59,360   Average segmentation loss on validation set: 0.1264
2021-12-16 15:06:00,832 iteration 1700 : loss : 0.056053, loss_ce: 0.020278
 25%|███████▎                     | 100/400 [46:06<2:21:29, 28.30s/it]2021-12-16 15:06:02,356 iteration 1701 : loss : 0.058251, loss_ce: 0.033308
2021-12-16 15:06:03,799 iteration 1702 : loss : 0.063112, loss_ce: 0.029207
2021-12-16 15:06:05,193 iteration 1703 : loss : 0.051414, loss_ce: 0.025614
2021-12-16 15:06:06,716 iteration 1704 : loss : 0.068895, loss_ce: 0.029006
2021-12-16 15:06:08,167 iteration 1705 : loss : 0.059403, loss_ce: 0.030647
2021-12-16 15:06:09,641 iteration 1706 : loss : 0.055763, loss_ce: 0.027179
2021-12-16 15:06:11,090 iteration 1707 : loss : 0.062845, loss_ce: 0.025536
2021-12-16 15:06:12,555 iteration 1708 : loss : 0.056037, loss_ce: 0.022305
2021-12-16 15:06:13,937 iteration 1709 : loss : 0.043287, loss_ce: 0.020198
2021-12-16 15:06:15,317 iteration 1710 : loss : 0.052816, loss_ce: 0.023208
2021-12-16 15:06:16,792 iteration 1711 : loss : 0.050570, loss_ce: 0.021832
2021-12-16 15:06:18,201 iteration 1712 : loss : 0.048926, loss_ce: 0.019833
2021-12-16 15:06:19,586 iteration 1713 : loss : 0.044420, loss_ce: 0.018556
2021-12-16 15:06:21,099 iteration 1714 : loss : 0.092616, loss_ce: 0.034181
2021-12-16 15:06:22,584 iteration 1715 : loss : 0.080191, loss_ce: 0.025662
2021-12-16 15:06:24,110 iteration 1716 : loss : 0.088371, loss_ce: 0.032926
2021-12-16 15:06:25,539 iteration 1717 : loss : 0.072376, loss_ce: 0.033615
 25%|███████▎                     | 101/400 [46:31<2:15:39, 27.22s/it]2021-12-16 15:06:26,983 iteration 1718 : loss : 0.062732, loss_ce: 0.023516
2021-12-16 15:06:28,446 iteration 1719 : loss : 0.062650, loss_ce: 0.030950
2021-12-16 15:06:29,801 iteration 1720 : loss : 0.056860, loss_ce: 0.022065
2021-12-16 15:06:31,235 iteration 1721 : loss : 0.051328, loss_ce: 0.027287
2021-12-16 15:06:32,713 iteration 1722 : loss : 0.053491, loss_ce: 0.021256
2021-12-16 15:06:34,136 iteration 1723 : loss : 0.086687, loss_ce: 0.038373
2021-12-16 15:06:35,603 iteration 1724 : loss : 0.055060, loss_ce: 0.022835
2021-12-16 15:06:37,147 iteration 1725 : loss : 0.109700, loss_ce: 0.034207
2021-12-16 15:06:38,647 iteration 1726 : loss : 0.095500, loss_ce: 0.028481
2021-12-16 15:06:40,089 iteration 1727 : loss : 0.047688, loss_ce: 0.024705
2021-12-16 15:06:41,519 iteration 1728 : loss : 0.062975, loss_ce: 0.023197
2021-12-16 15:06:42,953 iteration 1729 : loss : 0.048162, loss_ce: 0.026536
2021-12-16 15:06:44,398 iteration 1730 : loss : 0.050083, loss_ce: 0.021212
2021-12-16 15:06:45,891 iteration 1731 : loss : 0.100794, loss_ce: 0.043489
2021-12-16 15:06:47,327 iteration 1732 : loss : 0.041203, loss_ce: 0.022663
2021-12-16 15:06:48,844 iteration 1733 : loss : 0.060240, loss_ce: 0.026699
2021-12-16 15:06:50,251 iteration 1734 : loss : 0.051956, loss_ce: 0.021942
 26%|███████▍                     | 102/400 [46:56<2:11:27, 26.47s/it]2021-12-16 15:06:51,687 iteration 1735 : loss : 0.061878, loss_ce: 0.029021
2021-12-16 15:06:53,113 iteration 1736 : loss : 0.056668, loss_ce: 0.024984
2021-12-16 15:06:54,544 iteration 1737 : loss : 0.061024, loss_ce: 0.025512
2021-12-16 15:06:55,937 iteration 1738 : loss : 0.068092, loss_ce: 0.027192
2021-12-16 15:06:57,458 iteration 1739 : loss : 0.052608, loss_ce: 0.026768
2021-12-16 15:06:58,932 iteration 1740 : loss : 0.076963, loss_ce: 0.032881
2021-12-16 15:07:00,372 iteration 1741 : loss : 0.059906, loss_ce: 0.022765
2021-12-16 15:07:01,928 iteration 1742 : loss : 0.068709, loss_ce: 0.032109
2021-12-16 15:07:03,349 iteration 1743 : loss : 0.063364, loss_ce: 0.024529
2021-12-16 15:07:04,785 iteration 1744 : loss : 0.058880, loss_ce: 0.025585
2021-12-16 15:07:06,348 iteration 1745 : loss : 0.060899, loss_ce: 0.031939
2021-12-16 15:07:07,777 iteration 1746 : loss : 0.049346, loss_ce: 0.022046
2021-12-16 15:07:09,208 iteration 1747 : loss : 0.054966, loss_ce: 0.027453
2021-12-16 15:07:10,663 iteration 1748 : loss : 0.042181, loss_ce: 0.018982
2021-12-16 15:07:12,120 iteration 1749 : loss : 0.080236, loss_ce: 0.026565
2021-12-16 15:07:13,522 iteration 1750 : loss : 0.049281, loss_ce: 0.024218
2021-12-16 15:07:15,057 iteration 1751 : loss : 0.057702, loss_ce: 0.025013
 26%|███████▍                     | 103/400 [47:20<2:08:32, 25.97s/it]2021-12-16 15:07:16,509 iteration 1752 : loss : 0.057413, loss_ce: 0.022603
2021-12-16 15:07:17,897 iteration 1753 : loss : 0.066348, loss_ce: 0.033629
2021-12-16 15:07:19,313 iteration 1754 : loss : 0.045976, loss_ce: 0.022165
2021-12-16 15:07:20,742 iteration 1755 : loss : 0.050870, loss_ce: 0.022996
2021-12-16 15:07:22,191 iteration 1756 : loss : 0.070310, loss_ce: 0.034118
2021-12-16 15:07:23,684 iteration 1757 : loss : 0.099916, loss_ce: 0.052965
2021-12-16 15:07:25,153 iteration 1758 : loss : 0.061246, loss_ce: 0.026385
2021-12-16 15:07:26,544 iteration 1759 : loss : 0.065934, loss_ce: 0.022657
2021-12-16 15:07:27,981 iteration 1760 : loss : 0.061199, loss_ce: 0.026073
2021-12-16 15:07:29,384 iteration 1761 : loss : 0.058012, loss_ce: 0.022983
2021-12-16 15:07:30,814 iteration 1762 : loss : 0.054418, loss_ce: 0.024758
2021-12-16 15:07:32,192 iteration 1763 : loss : 0.048798, loss_ce: 0.023677
2021-12-16 15:07:33,726 iteration 1764 : loss : 0.046685, loss_ce: 0.017091
2021-12-16 15:07:35,186 iteration 1765 : loss : 0.078055, loss_ce: 0.031517
2021-12-16 15:07:36,689 iteration 1766 : loss : 0.053156, loss_ce: 0.025012
2021-12-16 15:07:38,145 iteration 1767 : loss : 0.052444, loss_ce: 0.023797
2021-12-16 15:07:39,568 iteration 1768 : loss : 0.075069, loss_ce: 0.031546
 26%|███████▌                     | 104/400 [47:45<2:05:58, 25.53s/it]2021-12-16 15:07:41,076 iteration 1769 : loss : 0.051593, loss_ce: 0.021934
2021-12-16 15:07:42,489 iteration 1770 : loss : 0.062742, loss_ce: 0.026061
2021-12-16 15:07:43,889 iteration 1771 : loss : 0.059971, loss_ce: 0.023156
2021-12-16 15:07:45,384 iteration 1772 : loss : 0.083100, loss_ce: 0.038002
2021-12-16 15:07:46,850 iteration 1773 : loss : 0.057089, loss_ce: 0.025538
2021-12-16 15:07:48,231 iteration 1774 : loss : 0.052827, loss_ce: 0.019138
2021-12-16 15:07:49,653 iteration 1775 : loss : 0.059746, loss_ce: 0.023597
2021-12-16 15:07:51,070 iteration 1776 : loss : 0.066142, loss_ce: 0.026392
2021-12-16 15:07:52,458 iteration 1777 : loss : 0.055697, loss_ce: 0.024124
2021-12-16 15:07:53,933 iteration 1778 : loss : 0.054987, loss_ce: 0.027138
2021-12-16 15:07:55,371 iteration 1779 : loss : 0.067268, loss_ce: 0.035482
2021-12-16 15:07:56,832 iteration 1780 : loss : 0.081355, loss_ce: 0.026315
2021-12-16 15:07:58,287 iteration 1781 : loss : 0.061168, loss_ce: 0.024481
2021-12-16 15:07:59,652 iteration 1782 : loss : 0.061207, loss_ce: 0.022578
2021-12-16 15:08:01,073 iteration 1783 : loss : 0.053363, loss_ce: 0.026698
2021-12-16 15:08:02,539 iteration 1784 : loss : 0.061720, loss_ce: 0.033458
2021-12-16 15:08:02,539 Training Data Eval:
2021-12-16 15:08:10,016   Average segmentation loss on training set: 0.0342
2021-12-16 15:08:10,016 Validation Data Eval:
2021-12-16 15:08:12,605   Average segmentation loss on validation set: 0.1350
2021-12-16 15:08:14,060 iteration 1785 : loss : 0.062790, loss_ce: 0.036472
 26%|███████▌                     | 105/400 [48:19<2:18:45, 28.22s/it]2021-12-16 15:08:15,594 iteration 1786 : loss : 0.072076, loss_ce: 0.025716
2021-12-16 15:08:16,995 iteration 1787 : loss : 0.062220, loss_ce: 0.017446
2021-12-16 15:08:18,460 iteration 1788 : loss : 0.060548, loss_ce: 0.026590
2021-12-16 15:08:19,918 iteration 1789 : loss : 0.058039, loss_ce: 0.032116
2021-12-16 15:08:21,473 iteration 1790 : loss : 0.047778, loss_ce: 0.019522
2021-12-16 15:08:22,949 iteration 1791 : loss : 0.053650, loss_ce: 0.027143
2021-12-16 15:08:24,413 iteration 1792 : loss : 0.055978, loss_ce: 0.024582
2021-12-16 15:08:25,878 iteration 1793 : loss : 0.074009, loss_ce: 0.033146
2021-12-16 15:08:27,292 iteration 1794 : loss : 0.055504, loss_ce: 0.031204
2021-12-16 15:08:28,631 iteration 1795 : loss : 0.043567, loss_ce: 0.019576
2021-12-16 15:08:30,138 iteration 1796 : loss : 0.069521, loss_ce: 0.035584
2021-12-16 15:08:31,535 iteration 1797 : loss : 0.050194, loss_ce: 0.024313
2021-12-16 15:08:32,979 iteration 1798 : loss : 0.055168, loss_ce: 0.023341
2021-12-16 15:08:34,468 iteration 1799 : loss : 0.058963, loss_ce: 0.026333
2021-12-16 15:08:35,856 iteration 1800 : loss : 0.065336, loss_ce: 0.020667
2021-12-16 15:08:37,288 iteration 1801 : loss : 0.076520, loss_ce: 0.029374
2021-12-16 15:08:38,773 iteration 1802 : loss : 0.102400, loss_ce: 0.040933
 26%|███████▋                     | 106/400 [48:44<2:13:06, 27.17s/it]2021-12-16 15:08:40,286 iteration 1803 : loss : 0.060684, loss_ce: 0.024445
2021-12-16 15:08:41,648 iteration 1804 : loss : 0.048439, loss_ce: 0.020591
2021-12-16 15:08:43,182 iteration 1805 : loss : 0.070890, loss_ce: 0.027415
2021-12-16 15:08:44,690 iteration 1806 : loss : 0.064885, loss_ce: 0.034184
2021-12-16 15:08:46,119 iteration 1807 : loss : 0.059082, loss_ce: 0.028300
2021-12-16 15:08:47,586 iteration 1808 : loss : 0.053507, loss_ce: 0.024087
2021-12-16 15:08:48,996 iteration 1809 : loss : 0.062904, loss_ce: 0.031390
2021-12-16 15:08:50,458 iteration 1810 : loss : 0.085465, loss_ce: 0.042534
2021-12-16 15:08:51,871 iteration 1811 : loss : 0.059954, loss_ce: 0.024746
2021-12-16 15:08:53,281 iteration 1812 : loss : 0.058481, loss_ce: 0.022631
2021-12-16 15:08:54,729 iteration 1813 : loss : 0.071241, loss_ce: 0.038486
2021-12-16 15:08:56,162 iteration 1814 : loss : 0.053836, loss_ce: 0.021073
2021-12-16 15:08:57,654 iteration 1815 : loss : 0.084437, loss_ce: 0.030171
2021-12-16 15:08:59,078 iteration 1816 : loss : 0.056522, loss_ce: 0.027565
2021-12-16 15:09:00,559 iteration 1817 : loss : 0.081578, loss_ce: 0.033211
2021-12-16 15:09:01,931 iteration 1818 : loss : 0.040831, loss_ce: 0.017243
2021-12-16 15:09:03,413 iteration 1819 : loss : 0.065026, loss_ce: 0.023332
 27%|███████▊                     | 107/400 [49:09<2:08:58, 26.41s/it]2021-12-16 15:09:04,802 iteration 1820 : loss : 0.045861, loss_ce: 0.022728
2021-12-16 15:09:06,336 iteration 1821 : loss : 0.080496, loss_ce: 0.029763
2021-12-16 15:09:07,809 iteration 1822 : loss : 0.064339, loss_ce: 0.032772
2021-12-16 15:09:09,306 iteration 1823 : loss : 0.066161, loss_ce: 0.026128
2021-12-16 15:09:10,757 iteration 1824 : loss : 0.082007, loss_ce: 0.024469
2021-12-16 15:09:12,148 iteration 1825 : loss : 0.062472, loss_ce: 0.026440
2021-12-16 15:09:13,646 iteration 1826 : loss : 0.057623, loss_ce: 0.020744
2021-12-16 15:09:15,021 iteration 1827 : loss : 0.050908, loss_ce: 0.023545
2021-12-16 15:09:16,467 iteration 1828 : loss : 0.059261, loss_ce: 0.027686
2021-12-16 15:09:17,883 iteration 1829 : loss : 0.060073, loss_ce: 0.030766
2021-12-16 15:09:19,424 iteration 1830 : loss : 0.058105, loss_ce: 0.021553
2021-12-16 15:09:20,872 iteration 1831 : loss : 0.052630, loss_ce: 0.024297
2021-12-16 15:09:22,290 iteration 1832 : loss : 0.060085, loss_ce: 0.026479
2021-12-16 15:09:23,714 iteration 1833 : loss : 0.068632, loss_ce: 0.031138
2021-12-16 15:09:25,169 iteration 1834 : loss : 0.058424, loss_ce: 0.022933
2021-12-16 15:09:26,616 iteration 1835 : loss : 0.054984, loss_ce: 0.024970
2021-12-16 15:09:28,035 iteration 1836 : loss : 0.066164, loss_ce: 0.023539
 27%|███████▊                     | 108/400 [49:33<2:05:55, 25.87s/it]2021-12-16 15:09:29,574 iteration 1837 : loss : 0.048765, loss_ce: 0.021360
2021-12-16 15:09:30,942 iteration 1838 : loss : 0.055970, loss_ce: 0.024593
2021-12-16 15:09:32,361 iteration 1839 : loss : 0.056357, loss_ce: 0.025314
2021-12-16 15:09:33,854 iteration 1840 : loss : 0.052875, loss_ce: 0.025234
2021-12-16 15:09:35,251 iteration 1841 : loss : 0.047090, loss_ce: 0.022449
2021-12-16 15:09:36,679 iteration 1842 : loss : 0.045802, loss_ce: 0.017307
2021-12-16 15:09:38,151 iteration 1843 : loss : 0.049929, loss_ce: 0.027895
2021-12-16 15:09:39,579 iteration 1844 : loss : 0.043714, loss_ce: 0.016214
2021-12-16 15:09:41,002 iteration 1845 : loss : 0.050714, loss_ce: 0.016242
2021-12-16 15:09:42,532 iteration 1846 : loss : 0.057672, loss_ce: 0.027740
2021-12-16 15:09:43,942 iteration 1847 : loss : 0.070463, loss_ce: 0.026885
2021-12-16 15:09:45,372 iteration 1848 : loss : 0.070174, loss_ce: 0.032309
2021-12-16 15:09:46,787 iteration 1849 : loss : 0.074036, loss_ce: 0.031387
2021-12-16 15:09:48,348 iteration 1850 : loss : 0.076890, loss_ce: 0.032971
2021-12-16 15:09:49,789 iteration 1851 : loss : 0.095775, loss_ce: 0.033278
2021-12-16 15:09:51,262 iteration 1852 : loss : 0.065799, loss_ce: 0.031480
2021-12-16 15:09:52,693 iteration 1853 : loss : 0.056758, loss_ce: 0.026849
 27%|███████▉                     | 109/400 [49:58<2:03:43, 25.51s/it]2021-12-16 15:09:54,157 iteration 1854 : loss : 0.054044, loss_ce: 0.029705
2021-12-16 15:09:55,655 iteration 1855 : loss : 0.050626, loss_ce: 0.022963
2021-12-16 15:09:57,163 iteration 1856 : loss : 0.065155, loss_ce: 0.024601
2021-12-16 15:09:58,669 iteration 1857 : loss : 0.059755, loss_ce: 0.023384
2021-12-16 15:10:00,119 iteration 1858 : loss : 0.062242, loss_ce: 0.028794
2021-12-16 15:10:01,576 iteration 1859 : loss : 0.080435, loss_ce: 0.036608
2021-12-16 15:10:02,983 iteration 1860 : loss : 0.058892, loss_ce: 0.024246
2021-12-16 15:10:04,491 iteration 1861 : loss : 0.048769, loss_ce: 0.021076
2021-12-16 15:10:05,897 iteration 1862 : loss : 0.047767, loss_ce: 0.025457
2021-12-16 15:10:07,347 iteration 1863 : loss : 0.056805, loss_ce: 0.026011
2021-12-16 15:10:08,833 iteration 1864 : loss : 0.102053, loss_ce: 0.029332
2021-12-16 15:10:10,199 iteration 1865 : loss : 0.050965, loss_ce: 0.025844
2021-12-16 15:10:11,714 iteration 1866 : loss : 0.043307, loss_ce: 0.022336
2021-12-16 15:10:13,164 iteration 1867 : loss : 0.040311, loss_ce: 0.019727
2021-12-16 15:10:14,578 iteration 1868 : loss : 0.059738, loss_ce: 0.030124
2021-12-16 15:10:15,995 iteration 1869 : loss : 0.093456, loss_ce: 0.030869
2021-12-16 15:10:15,995 Training Data Eval:
2021-12-16 15:10:23,508   Average segmentation loss on training set: 0.0413
2021-12-16 15:10:23,509 Validation Data Eval:
2021-12-16 15:10:26,116   Average segmentation loss on validation set: 0.1171
2021-12-16 15:10:34,409 Found new lowest validation loss at iteration 1869! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/TU_3seeds/TU_RESNET_no_pretraining_SGD_best_val_loss_seed1234.pth
2021-12-16 15:10:35,829 iteration 1870 : loss : 0.086928, loss_ce: 0.035246
 28%|███████▉                     | 110/400 [50:41<2:28:51, 30.80s/it]2021-12-16 15:10:37,285 iteration 1871 : loss : 0.048205, loss_ce: 0.019545
2021-12-16 15:10:38,764 iteration 1872 : loss : 0.094764, loss_ce: 0.029765
2021-12-16 15:10:40,074 iteration 1873 : loss : 0.056540, loss_ce: 0.025128
2021-12-16 15:10:41,510 iteration 1874 : loss : 0.072793, loss_ce: 0.035405
2021-12-16 15:10:42,788 iteration 1875 : loss : 0.055506, loss_ce: 0.019606
2021-12-16 15:10:44,226 iteration 1876 : loss : 0.062290, loss_ce: 0.020475
2021-12-16 15:10:45,642 iteration 1877 : loss : 0.076763, loss_ce: 0.035944
2021-12-16 15:10:46,983 iteration 1878 : loss : 0.056412, loss_ce: 0.028947
2021-12-16 15:10:48,311 iteration 1879 : loss : 0.053739, loss_ce: 0.022859
2021-12-16 15:10:49,633 iteration 1880 : loss : 0.042191, loss_ce: 0.022759
2021-12-16 15:10:50,997 iteration 1881 : loss : 0.062112, loss_ce: 0.025370
2021-12-16 15:10:52,313 iteration 1882 : loss : 0.059592, loss_ce: 0.023318
2021-12-16 15:10:53,588 iteration 1883 : loss : 0.050666, loss_ce: 0.019070
2021-12-16 15:10:54,995 iteration 1884 : loss : 0.068943, loss_ce: 0.028975
2021-12-16 15:10:56,328 iteration 1885 : loss : 0.044058, loss_ce: 0.020879
2021-12-16 15:10:57,904 iteration 1886 : loss : 0.068958, loss_ce: 0.035248
2021-12-16 15:10:59,458 iteration 1887 : loss : 0.069470, loss_ce: 0.035169
 28%|████████                     | 111/400 [51:05<2:17:58, 28.65s/it]2021-12-16 15:11:00,957 iteration 1888 : loss : 0.055443, loss_ce: 0.027276
2021-12-16 15:11:02,489 iteration 1889 : loss : 0.063038, loss_ce: 0.027104
2021-12-16 15:11:04,005 iteration 1890 : loss : 0.068903, loss_ce: 0.028089
2021-12-16 15:11:05,524 iteration 1891 : loss : 0.046610, loss_ce: 0.020162
2021-12-16 15:11:07,011 iteration 1892 : loss : 0.057953, loss_ce: 0.027547
2021-12-16 15:11:08,483 iteration 1893 : loss : 0.058682, loss_ce: 0.033559
2021-12-16 15:11:09,931 iteration 1894 : loss : 0.065005, loss_ce: 0.031826
2021-12-16 15:11:11,375 iteration 1895 : loss : 0.062676, loss_ce: 0.021487
2021-12-16 15:11:12,955 iteration 1896 : loss : 0.065629, loss_ce: 0.032239
2021-12-16 15:11:14,398 iteration 1897 : loss : 0.080340, loss_ce: 0.027161
2021-12-16 15:11:15,923 iteration 1898 : loss : 0.061113, loss_ce: 0.023377
2021-12-16 15:11:17,385 iteration 1899 : loss : 0.063784, loss_ce: 0.034266
2021-12-16 15:11:18,768 iteration 1900 : loss : 0.058565, loss_ce: 0.031337
2021-12-16 15:11:20,222 iteration 1901 : loss : 0.055767, loss_ce: 0.024310
2021-12-16 15:11:21,704 iteration 1902 : loss : 0.052140, loss_ce: 0.024986
2021-12-16 15:11:23,208 iteration 1903 : loss : 0.092168, loss_ce: 0.030546
2021-12-16 15:11:24,763 iteration 1904 : loss : 0.077344, loss_ce: 0.031878
 28%|████████                     | 112/400 [51:30<2:12:41, 27.64s/it]2021-12-16 15:11:26,213 iteration 1905 : loss : 0.040783, loss_ce: 0.020759
2021-12-16 15:11:27,737 iteration 1906 : loss : 0.056505, loss_ce: 0.024005
2021-12-16 15:11:29,303 iteration 1907 : loss : 0.083854, loss_ce: 0.028561
2021-12-16 15:11:30,793 iteration 1908 : loss : 0.068499, loss_ce: 0.030160
2021-12-16 15:11:32,304 iteration 1909 : loss : 0.060968, loss_ce: 0.033261
2021-12-16 15:11:33,815 iteration 1910 : loss : 0.051324, loss_ce: 0.024541
2021-12-16 15:11:35,398 iteration 1911 : loss : 0.056244, loss_ce: 0.023426
2021-12-16 15:11:36,895 iteration 1912 : loss : 0.047458, loss_ce: 0.017124
2021-12-16 15:11:38,339 iteration 1913 : loss : 0.041231, loss_ce: 0.016279
2021-12-16 15:11:39,761 iteration 1914 : loss : 0.043125, loss_ce: 0.021760
2021-12-16 15:11:41,237 iteration 1915 : loss : 0.059033, loss_ce: 0.022687
2021-12-16 15:11:42,697 iteration 1916 : loss : 0.066695, loss_ce: 0.029658
2021-12-16 15:11:44,182 iteration 1917 : loss : 0.061000, loss_ce: 0.025127
2021-12-16 15:11:45,586 iteration 1918 : loss : 0.056910, loss_ce: 0.027889
2021-12-16 15:11:47,017 iteration 1919 : loss : 0.050008, loss_ce: 0.025954
2021-12-16 15:11:48,453 iteration 1920 : loss : 0.042900, loss_ce: 0.020044
2021-12-16 15:11:49,951 iteration 1921 : loss : 0.056872, loss_ce: 0.024157
 28%|████████▏                    | 113/400 [51:55<2:08:42, 26.91s/it]2021-12-16 15:11:51,415 iteration 1922 : loss : 0.055743, loss_ce: 0.022993
2021-12-16 15:11:52,809 iteration 1923 : loss : 0.034697, loss_ce: 0.017991
2021-12-16 15:11:54,308 iteration 1924 : loss : 0.075118, loss_ce: 0.043672
2021-12-16 15:11:55,723 iteration 1925 : loss : 0.051619, loss_ce: 0.024418
2021-12-16 15:11:57,158 iteration 1926 : loss : 0.066254, loss_ce: 0.033638
2021-12-16 15:11:58,653 iteration 1927 : loss : 0.060166, loss_ce: 0.027726
2021-12-16 15:12:00,158 iteration 1928 : loss : 0.058755, loss_ce: 0.024244
2021-12-16 15:12:01,595 iteration 1929 : loss : 0.058027, loss_ce: 0.027142
2021-12-16 15:12:03,049 iteration 1930 : loss : 0.082883, loss_ce: 0.033650
2021-12-16 15:12:04,478 iteration 1931 : loss : 0.049969, loss_ce: 0.016621
2021-12-16 15:12:05,939 iteration 1932 : loss : 0.049698, loss_ce: 0.018854
2021-12-16 15:12:07,414 iteration 1933 : loss : 0.066901, loss_ce: 0.027926
2021-12-16 15:12:08,767 iteration 1934 : loss : 0.037094, loss_ce: 0.018577
2021-12-16 15:12:10,190 iteration 1935 : loss : 0.043352, loss_ce: 0.022863
2021-12-16 15:12:11,680 iteration 1936 : loss : 0.049617, loss_ce: 0.022829
2021-12-16 15:12:13,174 iteration 1937 : loss : 0.043345, loss_ce: 0.021070
2021-12-16 15:12:14,657 iteration 1938 : loss : 0.055912, loss_ce: 0.020669
 28%|████████▎                    | 114/400 [52:20<2:05:07, 26.25s/it]2021-12-16 15:12:16,078 iteration 1939 : loss : 0.040701, loss_ce: 0.021083
2021-12-16 15:12:17,507 iteration 1940 : loss : 0.043806, loss_ce: 0.018235
2021-12-16 15:12:19,014 iteration 1941 : loss : 0.051807, loss_ce: 0.026299
2021-12-16 15:12:20,468 iteration 1942 : loss : 0.086771, loss_ce: 0.023750
2021-12-16 15:12:21,866 iteration 1943 : loss : 0.040887, loss_ce: 0.017463
2021-12-16 15:12:23,298 iteration 1944 : loss : 0.047204, loss_ce: 0.020685
2021-12-16 15:12:24,733 iteration 1945 : loss : 0.049019, loss_ce: 0.025834
2021-12-16 15:12:26,169 iteration 1946 : loss : 0.061699, loss_ce: 0.024489
2021-12-16 15:12:27,600 iteration 1947 : loss : 0.060696, loss_ce: 0.028763
2021-12-16 15:12:29,036 iteration 1948 : loss : 0.056103, loss_ce: 0.025872
2021-12-16 15:12:30,421 iteration 1949 : loss : 0.050596, loss_ce: 0.028601
2021-12-16 15:12:31,902 iteration 1950 : loss : 0.049844, loss_ce: 0.019940
2021-12-16 15:12:33,414 iteration 1951 : loss : 0.071655, loss_ce: 0.029406
2021-12-16 15:12:34,794 iteration 1952 : loss : 0.067460, loss_ce: 0.022311
2021-12-16 15:12:36,246 iteration 1953 : loss : 0.059435, loss_ce: 0.032877
2021-12-16 15:12:37,754 iteration 1954 : loss : 0.078238, loss_ce: 0.031970
2021-12-16 15:12:37,754 Training Data Eval:
2021-12-16 15:12:45,207   Average segmentation loss on training set: 0.0303
2021-12-16 15:12:45,207 Validation Data Eval:
2021-12-16 15:12:47,787   Average segmentation loss on validation set: 0.1118
2021-12-16 15:12:54,137 Found new lowest validation loss at iteration 1954! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/TU_3seeds/TU_RESNET_no_pretraining_SGD_best_val_loss_seed1234.pth
2021-12-16 15:12:55,490 iteration 1955 : loss : 0.053832, loss_ce: 0.025361
 29%|████████▎                    | 115/400 [53:01<2:25:27, 30.62s/it]2021-12-16 15:12:56,910 iteration 1956 : loss : 0.055874, loss_ce: 0.026325
2021-12-16 15:12:58,191 iteration 1957 : loss : 0.042471, loss_ce: 0.020771
2021-12-16 15:12:59,504 iteration 1958 : loss : 0.047260, loss_ce: 0.024388
2021-12-16 15:13:00,915 iteration 1959 : loss : 0.084114, loss_ce: 0.021827
2021-12-16 15:13:02,228 iteration 1960 : loss : 0.073468, loss_ce: 0.026921
2021-12-16 15:13:03,570 iteration 1961 : loss : 0.066734, loss_ce: 0.026549
2021-12-16 15:13:04,896 iteration 1962 : loss : 0.043471, loss_ce: 0.020137
2021-12-16 15:13:06,254 iteration 1963 : loss : 0.056046, loss_ce: 0.027198
2021-12-16 15:13:07,576 iteration 1964 : loss : 0.043085, loss_ce: 0.015101
2021-12-16 15:13:08,884 iteration 1965 : loss : 0.057739, loss_ce: 0.029282
2021-12-16 15:13:10,231 iteration 1966 : loss : 0.045428, loss_ce: 0.023162
2021-12-16 15:13:11,618 iteration 1967 : loss : 0.041173, loss_ce: 0.015149
2021-12-16 15:13:13,002 iteration 1968 : loss : 0.060348, loss_ce: 0.031494
2021-12-16 15:13:14,483 iteration 1969 : loss : 0.054474, loss_ce: 0.021810
2021-12-16 15:13:16,053 iteration 1970 : loss : 0.051445, loss_ce: 0.022640
2021-12-16 15:13:17,418 iteration 1971 : loss : 0.038358, loss_ce: 0.015858
2021-12-16 15:13:18,970 iteration 1972 : loss : 0.086027, loss_ce: 0.030030
 29%|████████▍                    | 116/400 [53:24<2:14:48, 28.48s/it]2021-12-16 15:13:20,383 iteration 1973 : loss : 0.040561, loss_ce: 0.018335
2021-12-16 15:13:21,768 iteration 1974 : loss : 0.047295, loss_ce: 0.023525
2021-12-16 15:13:23,278 iteration 1975 : loss : 0.080199, loss_ce: 0.036787
2021-12-16 15:13:24,649 iteration 1976 : loss : 0.045551, loss_ce: 0.021970
2021-12-16 15:13:26,163 iteration 1977 : loss : 0.083819, loss_ce: 0.040046
2021-12-16 15:13:27,569 iteration 1978 : loss : 0.050952, loss_ce: 0.021603
2021-12-16 15:13:28,999 iteration 1979 : loss : 0.043638, loss_ce: 0.023929
2021-12-16 15:13:30,479 iteration 1980 : loss : 0.059402, loss_ce: 0.025115
2021-12-16 15:13:31,878 iteration 1981 : loss : 0.053436, loss_ce: 0.023156
2021-12-16 15:13:33,362 iteration 1982 : loss : 0.049149, loss_ce: 0.021568
2021-12-16 15:13:34,887 iteration 1983 : loss : 0.050670, loss_ce: 0.024409
2021-12-16 15:13:36,304 iteration 1984 : loss : 0.052368, loss_ce: 0.018353
2021-12-16 15:13:37,724 iteration 1985 : loss : 0.044231, loss_ce: 0.018163
2021-12-16 15:13:39,134 iteration 1986 : loss : 0.059289, loss_ce: 0.023042
2021-12-16 15:13:40,541 iteration 1987 : loss : 0.037382, loss_ce: 0.018406
2021-12-16 15:13:42,061 iteration 1988 : loss : 0.056326, loss_ce: 0.024687
2021-12-16 15:13:43,502 iteration 1989 : loss : 0.047949, loss_ce: 0.024621
 29%|████████▍                    | 117/400 [53:49<2:08:43, 27.29s/it]2021-12-16 15:13:44,964 iteration 1990 : loss : 0.067880, loss_ce: 0.026289
2021-12-16 15:13:46,321 iteration 1991 : loss : 0.043857, loss_ce: 0.021511
2021-12-16 15:13:47,802 iteration 1992 : loss : 0.053885, loss_ce: 0.025658
2021-12-16 15:13:49,227 iteration 1993 : loss : 0.057107, loss_ce: 0.015854
2021-12-16 15:13:50,687 iteration 1994 : loss : 0.036967, loss_ce: 0.017850
2021-12-16 15:13:52,123 iteration 1995 : loss : 0.087994, loss_ce: 0.034162
2021-12-16 15:13:53,563 iteration 1996 : loss : 0.064827, loss_ce: 0.033194
2021-12-16 15:13:55,000 iteration 1997 : loss : 0.063590, loss_ce: 0.030835
2021-12-16 15:13:56,460 iteration 1998 : loss : 0.059951, loss_ce: 0.027711
2021-12-16 15:13:57,914 iteration 1999 : loss : 0.059320, loss_ce: 0.026853
2021-12-16 15:13:59,451 iteration 2000 : loss : 0.091426, loss_ce: 0.028047
2021-12-16 15:14:00,888 iteration 2001 : loss : 0.043731, loss_ce: 0.019745
2021-12-16 15:14:02,267 iteration 2002 : loss : 0.061918, loss_ce: 0.027421
2021-12-16 15:14:03,604 iteration 2003 : loss : 0.030544, loss_ce: 0.018032
2021-12-16 15:14:05,013 iteration 2004 : loss : 0.058560, loss_ce: 0.021717
2021-12-16 15:14:06,490 iteration 2005 : loss : 0.048196, loss_ce: 0.019653
2021-12-16 15:14:07,949 iteration 2006 : loss : 0.061725, loss_ce: 0.023397
 30%|████████▌                    | 118/400 [54:13<2:04:15, 26.44s/it]2021-12-16 15:14:09,480 iteration 2007 : loss : 0.066050, loss_ce: 0.025681
2021-12-16 15:14:11,021 iteration 2008 : loss : 0.081285, loss_ce: 0.031086
2021-12-16 15:14:12,447 iteration 2009 : loss : 0.053012, loss_ce: 0.025178
2021-12-16 15:14:13,874 iteration 2010 : loss : 0.059957, loss_ce: 0.029119
2021-12-16 15:14:15,391 iteration 2011 : loss : 0.059795, loss_ce: 0.028268
2021-12-16 15:14:16,846 iteration 2012 : loss : 0.046908, loss_ce: 0.024169
2021-12-16 15:14:18,230 iteration 2013 : loss : 0.057198, loss_ce: 0.025227
2021-12-16 15:14:19,649 iteration 2014 : loss : 0.051711, loss_ce: 0.020634
2021-12-16 15:14:21,127 iteration 2015 : loss : 0.056766, loss_ce: 0.029353
2021-12-16 15:14:22,551 iteration 2016 : loss : 0.060151, loss_ce: 0.022210
2021-12-16 15:14:24,038 iteration 2017 : loss : 0.037903, loss_ce: 0.014966
2021-12-16 15:14:25,566 iteration 2018 : loss : 0.063731, loss_ce: 0.028596
2021-12-16 15:14:26,975 iteration 2019 : loss : 0.054514, loss_ce: 0.022363
2021-12-16 15:14:28,378 iteration 2020 : loss : 0.034360, loss_ce: 0.014751
2021-12-16 15:14:29,835 iteration 2021 : loss : 0.052971, loss_ce: 0.020281
2021-12-16 15:14:31,300 iteration 2022 : loss : 0.048035, loss_ce: 0.023778
2021-12-16 15:14:32,805 iteration 2023 : loss : 0.083874, loss_ce: 0.033460
 30%|████████▋                    | 119/400 [54:38<2:01:35, 25.96s/it]2021-12-16 15:14:34,254 iteration 2024 : loss : 0.052817, loss_ce: 0.019040
2021-12-16 15:14:35,711 iteration 2025 : loss : 0.055026, loss_ce: 0.029365
2021-12-16 15:14:37,191 iteration 2026 : loss : 0.055196, loss_ce: 0.024146
2021-12-16 15:14:38,606 iteration 2027 : loss : 0.038593, loss_ce: 0.012814
2021-12-16 15:14:40,002 iteration 2028 : loss : 0.034372, loss_ce: 0.018760
2021-12-16 15:14:41,434 iteration 2029 : loss : 0.059150, loss_ce: 0.026172
2021-12-16 15:14:42,851 iteration 2030 : loss : 0.052025, loss_ce: 0.023075
2021-12-16 15:14:44,300 iteration 2031 : loss : 0.058515, loss_ce: 0.029306
2021-12-16 15:14:45,819 iteration 2032 : loss : 0.067775, loss_ce: 0.033316
2021-12-16 15:14:47,363 iteration 2033 : loss : 0.073343, loss_ce: 0.038426
2021-12-16 15:14:48,774 iteration 2034 : loss : 0.046112, loss_ce: 0.020897
2021-12-16 15:14:50,229 iteration 2035 : loss : 0.059553, loss_ce: 0.020216
2021-12-16 15:14:51,721 iteration 2036 : loss : 0.053231, loss_ce: 0.025503
2021-12-16 15:14:53,158 iteration 2037 : loss : 0.099018, loss_ce: 0.025107
2021-12-16 15:14:54,624 iteration 2038 : loss : 0.068897, loss_ce: 0.031801
2021-12-16 15:14:56,146 iteration 2039 : loss : 0.066495, loss_ce: 0.028702
2021-12-16 15:14:56,146 Training Data Eval:
2021-12-16 15:15:03,608   Average segmentation loss on training set: 0.0286
2021-12-16 15:15:03,608 Validation Data Eval:
2021-12-16 15:15:06,186   Average segmentation loss on validation set: 0.1211
2021-12-16 15:15:07,709 iteration 2040 : loss : 0.062017, loss_ce: 0.026689
 30%|████████▋                    | 120/400 [55:13<2:13:41, 28.65s/it]2021-12-16 15:15:09,234 iteration 2041 : loss : 0.068068, loss_ce: 0.020149
2021-12-16 15:15:10,669 iteration 2042 : loss : 0.060321, loss_ce: 0.025200
2021-12-16 15:15:12,099 iteration 2043 : loss : 0.056136, loss_ce: 0.022354
2021-12-16 15:15:13,545 iteration 2044 : loss : 0.058422, loss_ce: 0.025888
2021-12-16 15:15:14,965 iteration 2045 : loss : 0.038885, loss_ce: 0.016548
2021-12-16 15:15:16,426 iteration 2046 : loss : 0.059736, loss_ce: 0.030254
2021-12-16 15:15:17,843 iteration 2047 : loss : 0.061409, loss_ce: 0.030068
2021-12-16 15:15:19,302 iteration 2048 : loss : 0.073095, loss_ce: 0.031053
2021-12-16 15:15:20,720 iteration 2049 : loss : 0.056825, loss_ce: 0.016946
2021-12-16 15:15:22,177 iteration 2050 : loss : 0.072112, loss_ce: 0.032168
2021-12-16 15:15:23,632 iteration 2051 : loss : 0.053951, loss_ce: 0.032296
2021-12-16 15:15:25,024 iteration 2052 : loss : 0.052670, loss_ce: 0.021962
2021-12-16 15:15:26,482 iteration 2053 : loss : 0.053481, loss_ce: 0.020351
2021-12-16 15:15:27,908 iteration 2054 : loss : 0.046571, loss_ce: 0.021553
2021-12-16 15:15:29,347 iteration 2055 : loss : 0.081144, loss_ce: 0.025158
2021-12-16 15:15:30,830 iteration 2056 : loss : 0.068906, loss_ce: 0.031597
2021-12-16 15:15:32,229 iteration 2057 : loss : 0.041555, loss_ce: 0.019622
 30%|████████▊                    | 121/400 [55:38<2:07:26, 27.41s/it]2021-12-16 15:15:33,714 iteration 2058 : loss : 0.045802, loss_ce: 0.023107
2021-12-16 15:15:35,193 iteration 2059 : loss : 0.065854, loss_ce: 0.027917
2021-12-16 15:15:36,560 iteration 2060 : loss : 0.050128, loss_ce: 0.021817
2021-12-16 15:15:38,030 iteration 2061 : loss : 0.068217, loss_ce: 0.029010
2021-12-16 15:15:39,443 iteration 2062 : loss : 0.053932, loss_ce: 0.022523
2021-12-16 15:15:40,871 iteration 2063 : loss : 0.095108, loss_ce: 0.028637
2021-12-16 15:15:42,265 iteration 2064 : loss : 0.037865, loss_ce: 0.016324
2021-12-16 15:15:43,688 iteration 2065 : loss : 0.058596, loss_ce: 0.023337
2021-12-16 15:15:45,137 iteration 2066 : loss : 0.054307, loss_ce: 0.022665
2021-12-16 15:15:46,602 iteration 2067 : loss : 0.041376, loss_ce: 0.018613
2021-12-16 15:15:48,080 iteration 2068 : loss : 0.043598, loss_ce: 0.021970
2021-12-16 15:15:49,481 iteration 2069 : loss : 0.047750, loss_ce: 0.016288
2021-12-16 15:15:50,953 iteration 2070 : loss : 0.059079, loss_ce: 0.027980
2021-12-16 15:15:52,444 iteration 2071 : loss : 0.057395, loss_ce: 0.026070
2021-12-16 15:15:53,899 iteration 2072 : loss : 0.053575, loss_ce: 0.023274
2021-12-16 15:15:55,402 iteration 2073 : loss : 0.073098, loss_ce: 0.029030
2021-12-16 15:15:56,871 iteration 2074 : loss : 0.055529, loss_ce: 0.032016
 30%|████████▊                    | 122/400 [56:02<2:03:09, 26.58s/it]2021-12-16 15:15:58,309 iteration 2075 : loss : 0.037188, loss_ce: 0.014813
2021-12-16 15:15:59,737 iteration 2076 : loss : 0.067572, loss_ce: 0.025195
2021-12-16 15:16:01,199 iteration 2077 : loss : 0.057265, loss_ce: 0.027059
2021-12-16 15:16:02,750 iteration 2078 : loss : 0.068302, loss_ce: 0.028319
2021-12-16 15:16:04,174 iteration 2079 : loss : 0.043283, loss_ce: 0.017724
2021-12-16 15:16:05,649 iteration 2080 : loss : 0.073740, loss_ce: 0.026056
2021-12-16 15:16:06,997 iteration 2081 : loss : 0.049307, loss_ce: 0.021737
2021-12-16 15:16:08,355 iteration 2082 : loss : 0.032050, loss_ce: 0.014778
2021-12-16 15:16:09,783 iteration 2083 : loss : 0.063648, loss_ce: 0.035371
2021-12-16 15:16:11,214 iteration 2084 : loss : 0.054965, loss_ce: 0.027454
2021-12-16 15:16:12,619 iteration 2085 : loss : 0.060414, loss_ce: 0.020312
2021-12-16 15:16:14,059 iteration 2086 : loss : 0.051920, loss_ce: 0.024406
2021-12-16 15:16:15,461 iteration 2087 : loss : 0.041930, loss_ce: 0.020430
2021-12-16 15:16:16,967 iteration 2088 : loss : 0.044067, loss_ce: 0.020868
2021-12-16 15:16:18,451 iteration 2089 : loss : 0.046013, loss_ce: 0.023873
2021-12-16 15:16:19,832 iteration 2090 : loss : 0.046345, loss_ce: 0.020767
2021-12-16 15:16:21,307 iteration 2091 : loss : 0.057096, loss_ce: 0.026747
 31%|████████▉                    | 123/400 [56:27<1:59:44, 25.94s/it]2021-12-16 15:16:22,733 iteration 2092 : loss : 0.045268, loss_ce: 0.024388
2021-12-16 15:16:24,148 iteration 2093 : loss : 0.074030, loss_ce: 0.030214
2021-12-16 15:16:25,578 iteration 2094 : loss : 0.066510, loss_ce: 0.019266
2021-12-16 15:16:26,964 iteration 2095 : loss : 0.033569, loss_ce: 0.016994
2021-12-16 15:16:28,478 iteration 2096 : loss : 0.049737, loss_ce: 0.025202
2021-12-16 15:16:29,939 iteration 2097 : loss : 0.070415, loss_ce: 0.024394
2021-12-16 15:16:31,396 iteration 2098 : loss : 0.065779, loss_ce: 0.028668
2021-12-16 15:16:32,851 iteration 2099 : loss : 0.060038, loss_ce: 0.024146
2021-12-16 15:16:34,312 iteration 2100 : loss : 0.058067, loss_ce: 0.030456
2021-12-16 15:16:35,757 iteration 2101 : loss : 0.048383, loss_ce: 0.019701
2021-12-16 15:16:37,225 iteration 2102 : loss : 0.048204, loss_ce: 0.025067
2021-12-16 15:16:38,588 iteration 2103 : loss : 0.040741, loss_ce: 0.020977
2021-12-16 15:16:39,987 iteration 2104 : loss : 0.069322, loss_ce: 0.023506
2021-12-16 15:16:41,517 iteration 2105 : loss : 0.071988, loss_ce: 0.030120
2021-12-16 15:16:42,931 iteration 2106 : loss : 0.043215, loss_ce: 0.020847
2021-12-16 15:16:44,451 iteration 2107 : loss : 0.063018, loss_ce: 0.023396
2021-12-16 15:16:45,902 iteration 2108 : loss : 0.064399, loss_ce: 0.026027
 31%|████████▉                    | 124/400 [56:51<1:57:27, 25.54s/it]2021-12-16 15:16:47,392 iteration 2109 : loss : 0.061967, loss_ce: 0.028553
2021-12-16 15:16:48,868 iteration 2110 : loss : 0.057434, loss_ce: 0.025115
2021-12-16 15:16:50,375 iteration 2111 : loss : 0.057548, loss_ce: 0.019154
2021-12-16 15:16:51,815 iteration 2112 : loss : 0.059623, loss_ce: 0.027366
2021-12-16 15:16:53,214 iteration 2113 : loss : 0.060603, loss_ce: 0.034365
2021-12-16 15:16:54,680 iteration 2114 : loss : 0.052409, loss_ce: 0.026419
2021-12-16 15:16:56,145 iteration 2115 : loss : 0.044514, loss_ce: 0.017618
2021-12-16 15:16:57,623 iteration 2116 : loss : 0.054123, loss_ce: 0.020600
2021-12-16 15:16:59,090 iteration 2117 : loss : 0.056929, loss_ce: 0.023514
2021-12-16 15:17:00,563 iteration 2118 : loss : 0.053160, loss_ce: 0.019020
2021-12-16 15:17:02,036 iteration 2119 : loss : 0.062379, loss_ce: 0.022009
2021-12-16 15:17:03,470 iteration 2120 : loss : 0.074409, loss_ce: 0.026058
2021-12-16 15:17:04,827 iteration 2121 : loss : 0.039052, loss_ce: 0.017467
2021-12-16 15:17:06,265 iteration 2122 : loss : 0.046503, loss_ce: 0.019264
2021-12-16 15:17:07,760 iteration 2123 : loss : 0.075841, loss_ce: 0.038129
2021-12-16 15:17:09,260 iteration 2124 : loss : 0.055450, loss_ce: 0.027055
2021-12-16 15:17:09,261 Training Data Eval:
2021-12-16 15:17:16,720   Average segmentation loss on training set: 0.0338
2021-12-16 15:17:16,720 Validation Data Eval:
2021-12-16 15:17:19,301   Average segmentation loss on validation set: 0.1163
2021-12-16 15:17:20,773 iteration 2125 : loss : 0.055685, loss_ce: 0.030708
 31%|█████████                    | 125/400 [57:26<2:09:52, 28.34s/it]2021-12-16 15:17:22,316 iteration 2126 : loss : 0.058322, loss_ce: 0.024413
2021-12-16 15:17:23,794 iteration 2127 : loss : 0.062742, loss_ce: 0.032168
2021-12-16 15:17:25,271 iteration 2128 : loss : 0.062061, loss_ce: 0.024499
2021-12-16 15:17:26,692 iteration 2129 : loss : 0.049780, loss_ce: 0.021323
2021-12-16 15:17:28,183 iteration 2130 : loss : 0.081383, loss_ce: 0.033194
2021-12-16 15:17:29,607 iteration 2131 : loss : 0.045962, loss_ce: 0.018685
2021-12-16 15:17:31,051 iteration 2132 : loss : 0.035644, loss_ce: 0.015231
2021-12-16 15:17:32,547 iteration 2133 : loss : 0.052444, loss_ce: 0.019341
2021-12-16 15:17:33,921 iteration 2134 : loss : 0.041417, loss_ce: 0.021815
2021-12-16 15:17:35,370 iteration 2135 : loss : 0.049687, loss_ce: 0.021703
2021-12-16 15:17:36,811 iteration 2136 : loss : 0.058713, loss_ce: 0.030553
2021-12-16 15:17:38,242 iteration 2137 : loss : 0.072979, loss_ce: 0.033274
2021-12-16 15:17:39,650 iteration 2138 : loss : 0.055249, loss_ce: 0.025528
2021-12-16 15:17:41,136 iteration 2139 : loss : 0.056082, loss_ce: 0.031439
2021-12-16 15:17:42,585 iteration 2140 : loss : 0.051551, loss_ce: 0.027063
2021-12-16 15:17:44,090 iteration 2141 : loss : 0.062483, loss_ce: 0.019339
2021-12-16 15:17:45,502 iteration 2142 : loss : 0.037020, loss_ce: 0.014619
 32%|█████████▏                   | 126/400 [57:51<2:04:27, 27.25s/it]2021-12-16 15:17:46,932 iteration 2143 : loss : 0.045778, loss_ce: 0.021798
2021-12-16 15:17:48,395 iteration 2144 : loss : 0.054638, loss_ce: 0.019725
2021-12-16 15:17:49,870 iteration 2145 : loss : 0.061333, loss_ce: 0.021312
2021-12-16 15:17:51,261 iteration 2146 : loss : 0.028491, loss_ce: 0.014499
2021-12-16 15:17:52,718 iteration 2147 : loss : 0.066251, loss_ce: 0.023707
2021-12-16 15:17:54,136 iteration 2148 : loss : 0.063132, loss_ce: 0.025363
2021-12-16 15:17:55,580 iteration 2149 : loss : 0.050168, loss_ce: 0.021258
2021-12-16 15:17:56,994 iteration 2150 : loss : 0.039057, loss_ce: 0.016878
2021-12-16 15:17:58,494 iteration 2151 : loss : 0.050989, loss_ce: 0.024895
2021-12-16 15:17:59,899 iteration 2152 : loss : 0.050049, loss_ce: 0.022903
2021-12-16 15:18:01,303 iteration 2153 : loss : 0.036735, loss_ce: 0.016717
2021-12-16 15:18:02,866 iteration 2154 : loss : 0.057753, loss_ce: 0.020910
2021-12-16 15:18:04,291 iteration 2155 : loss : 0.046347, loss_ce: 0.020724
2021-12-16 15:18:05,686 iteration 2156 : loss : 0.054656, loss_ce: 0.027508
2021-12-16 15:18:07,262 iteration 2157 : loss : 0.080280, loss_ce: 0.026416
2021-12-16 15:18:08,778 iteration 2158 : loss : 0.059715, loss_ce: 0.032063
2021-12-16 15:18:10,228 iteration 2159 : loss : 0.071619, loss_ce: 0.023248
 32%|█████████▏                   | 127/400 [58:16<2:00:32, 26.49s/it]2021-12-16 15:18:11,653 iteration 2160 : loss : 0.060785, loss_ce: 0.025961
2021-12-16 15:18:13,040 iteration 2161 : loss : 0.039165, loss_ce: 0.015389
2021-12-16 15:18:14,475 iteration 2162 : loss : 0.053463, loss_ce: 0.024581
2021-12-16 15:18:15,894 iteration 2163 : loss : 0.040290, loss_ce: 0.018912
2021-12-16 15:18:17,359 iteration 2164 : loss : 0.042067, loss_ce: 0.024289
2021-12-16 15:18:18,810 iteration 2165 : loss : 0.055895, loss_ce: 0.021923
2021-12-16 15:18:20,206 iteration 2166 : loss : 0.048861, loss_ce: 0.023914
2021-12-16 15:18:21,582 iteration 2167 : loss : 0.048602, loss_ce: 0.021098
2021-12-16 15:18:23,006 iteration 2168 : loss : 0.038644, loss_ce: 0.018132
2021-12-16 15:18:24,464 iteration 2169 : loss : 0.069620, loss_ce: 0.033086
2021-12-16 15:18:25,803 iteration 2170 : loss : 0.045744, loss_ce: 0.017138
2021-12-16 15:18:27,213 iteration 2171 : loss : 0.052607, loss_ce: 0.022086
2021-12-16 15:18:28,625 iteration 2172 : loss : 0.055544, loss_ce: 0.023378
2021-12-16 15:18:30,032 iteration 2173 : loss : 0.046424, loss_ce: 0.014556
2021-12-16 15:18:31,478 iteration 2174 : loss : 0.055840, loss_ce: 0.024132
2021-12-16 15:18:32,980 iteration 2175 : loss : 0.038047, loss_ce: 0.020238
2021-12-16 15:18:34,305 iteration 2176 : loss : 0.039688, loss_ce: 0.019773
 32%|█████████▎                   | 128/400 [58:40<1:56:49, 25.77s/it]2021-12-16 15:18:35,723 iteration 2177 : loss : 0.065622, loss_ce: 0.036587
2021-12-16 15:18:37,168 iteration 2178 : loss : 0.043796, loss_ce: 0.019150
2021-12-16 15:18:38,660 iteration 2179 : loss : 0.057603, loss_ce: 0.021596
2021-12-16 15:18:40,119 iteration 2180 : loss : 0.059892, loss_ce: 0.032347
2021-12-16 15:18:41,482 iteration 2181 : loss : 0.046453, loss_ce: 0.019528
2021-12-16 15:18:42,917 iteration 2182 : loss : 0.050550, loss_ce: 0.021153
2021-12-16 15:18:44,361 iteration 2183 : loss : 0.065258, loss_ce: 0.022168
2021-12-16 15:18:45,749 iteration 2184 : loss : 0.064467, loss_ce: 0.035678
2021-12-16 15:18:47,153 iteration 2185 : loss : 0.049267, loss_ce: 0.021010
2021-12-16 15:18:48,676 iteration 2186 : loss : 0.069183, loss_ce: 0.030838
2021-12-16 15:18:50,191 iteration 2187 : loss : 0.065806, loss_ce: 0.026278
2021-12-16 15:18:51,760 iteration 2188 : loss : 0.074968, loss_ce: 0.041932
2021-12-16 15:18:53,316 iteration 2189 : loss : 0.078725, loss_ce: 0.029370
2021-12-16 15:18:54,759 iteration 2190 : loss : 0.051365, loss_ce: 0.026424
2021-12-16 15:18:56,224 iteration 2191 : loss : 0.041241, loss_ce: 0.017853
2021-12-16 15:18:57,631 iteration 2192 : loss : 0.047008, loss_ce: 0.020867
2021-12-16 15:18:59,078 iteration 2193 : loss : 0.051949, loss_ce: 0.019993
 32%|█████████▎                   | 129/400 [59:04<1:55:02, 25.47s/it]2021-12-16 15:19:00,580 iteration 2194 : loss : 0.050134, loss_ce: 0.024052
2021-12-16 15:19:02,025 iteration 2195 : loss : 0.050722, loss_ce: 0.026527
2021-12-16 15:19:03,502 iteration 2196 : loss : 0.062494, loss_ce: 0.028073
2021-12-16 15:19:05,028 iteration 2197 : loss : 0.051081, loss_ce: 0.022822
2021-12-16 15:19:06,455 iteration 2198 : loss : 0.065410, loss_ce: 0.021677
2021-12-16 15:19:07,897 iteration 2199 : loss : 0.058268, loss_ce: 0.029365
2021-12-16 15:19:09,423 iteration 2200 : loss : 0.094124, loss_ce: 0.022682
2021-12-16 15:19:10,819 iteration 2201 : loss : 0.046598, loss_ce: 0.022748
2021-12-16 15:19:12,366 iteration 2202 : loss : 0.077313, loss_ce: 0.038543
2021-12-16 15:19:13,838 iteration 2203 : loss : 0.052115, loss_ce: 0.017143
2021-12-16 15:19:15,216 iteration 2204 : loss : 0.036721, loss_ce: 0.014927
2021-12-16 15:19:16,676 iteration 2205 : loss : 0.061907, loss_ce: 0.029524
2021-12-16 15:19:18,191 iteration 2206 : loss : 0.085784, loss_ce: 0.036174
2021-12-16 15:19:19,647 iteration 2207 : loss : 0.088263, loss_ce: 0.022208
2021-12-16 15:19:21,133 iteration 2208 : loss : 0.073577, loss_ce: 0.024869
2021-12-16 15:19:22,578 iteration 2209 : loss : 0.047972, loss_ce: 0.021292
2021-12-16 15:19:22,578 Training Data Eval:
2021-12-16 15:19:30,015   Average segmentation loss on training set: 0.0281
2021-12-16 15:19:30,015 Validation Data Eval:
2021-12-16 15:19:32,599   Average segmentation loss on validation set: 0.1068
2021-12-16 15:19:39,028 Found new lowest validation loss at iteration 2209! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/TU_3seeds/TU_RESNET_no_pretraining_SGD_best_val_loss_seed1234.pth
2021-12-16 15:19:40,439 iteration 2210 : loss : 0.056491, loss_ce: 0.029299
 32%|█████████▍                   | 130/400 [59:46<2:16:04, 30.24s/it]2021-12-16 15:19:41,823 iteration 2211 : loss : 0.066262, loss_ce: 0.020925
2021-12-16 15:19:43,120 iteration 2212 : loss : 0.050019, loss_ce: 0.022494
2021-12-16 15:19:44,468 iteration 2213 : loss : 0.074785, loss_ce: 0.022478
2021-12-16 15:19:45,733 iteration 2214 : loss : 0.053831, loss_ce: 0.019955
2021-12-16 15:19:46,995 iteration 2215 : loss : 0.041478, loss_ce: 0.017121
2021-12-16 15:19:48,300 iteration 2216 : loss : 0.051389, loss_ce: 0.024925
2021-12-16 15:19:49,585 iteration 2217 : loss : 0.045079, loss_ce: 0.023741
2021-12-16 15:19:50,900 iteration 2218 : loss : 0.040574, loss_ce: 0.016263
2021-12-16 15:19:52,264 iteration 2219 : loss : 0.057404, loss_ce: 0.026936
2021-12-16 15:19:53,698 iteration 2220 : loss : 0.066351, loss_ce: 0.037869
2021-12-16 15:19:55,173 iteration 2221 : loss : 0.060515, loss_ce: 0.021022
2021-12-16 15:19:56,547 iteration 2222 : loss : 0.044834, loss_ce: 0.020825
2021-12-16 15:19:57,954 iteration 2223 : loss : 0.048027, loss_ce: 0.019844
2021-12-16 15:19:59,463 iteration 2224 : loss : 0.069709, loss_ce: 0.030427
2021-12-16 15:20:00,937 iteration 2225 : loss : 0.055333, loss_ce: 0.022132
2021-12-16 15:20:02,450 iteration 2226 : loss : 0.068883, loss_ce: 0.032418
2021-12-16 15:20:03,923 iteration 2227 : loss : 0.064177, loss_ce: 0.022091
 33%|████████▊                  | 131/400 [1:00:09<2:06:29, 28.21s/it]2021-12-16 15:20:05,477 iteration 2228 : loss : 0.076691, loss_ce: 0.035968
2021-12-16 15:20:06,940 iteration 2229 : loss : 0.045153, loss_ce: 0.020121
2021-12-16 15:20:08,519 iteration 2230 : loss : 0.059064, loss_ce: 0.024537
2021-12-16 15:20:09,940 iteration 2231 : loss : 0.047038, loss_ce: 0.026523
2021-12-16 15:20:11,357 iteration 2232 : loss : 0.052856, loss_ce: 0.026118
2021-12-16 15:20:12,960 iteration 2233 : loss : 0.101711, loss_ce: 0.033698
2021-12-16 15:20:14,431 iteration 2234 : loss : 0.054213, loss_ce: 0.017023
2021-12-16 15:20:15,879 iteration 2235 : loss : 0.043110, loss_ce: 0.019378
2021-12-16 15:20:17,299 iteration 2236 : loss : 0.035957, loss_ce: 0.017518
2021-12-16 15:20:18,762 iteration 2237 : loss : 0.046623, loss_ce: 0.023409
2021-12-16 15:20:20,159 iteration 2238 : loss : 0.048413, loss_ce: 0.017223
2021-12-16 15:20:21,578 iteration 2239 : loss : 0.048030, loss_ce: 0.015769
2021-12-16 15:20:22,957 iteration 2240 : loss : 0.071995, loss_ce: 0.022249
2021-12-16 15:20:24,406 iteration 2241 : loss : 0.041795, loss_ce: 0.017011
2021-12-16 15:20:25,922 iteration 2242 : loss : 0.072695, loss_ce: 0.027108
2021-12-16 15:20:27,389 iteration 2243 : loss : 0.053878, loss_ce: 0.025274
2021-12-16 15:20:28,805 iteration 2244 : loss : 0.035688, loss_ce: 0.015619
 33%|████████▉                  | 132/400 [1:00:34<2:01:33, 27.21s/it]2021-12-16 15:20:30,270 iteration 2245 : loss : 0.049819, loss_ce: 0.017602
2021-12-16 15:20:31,621 iteration 2246 : loss : 0.035169, loss_ce: 0.014003
2021-12-16 15:20:33,081 iteration 2247 : loss : 0.051203, loss_ce: 0.026901
2021-12-16 15:20:34,590 iteration 2248 : loss : 0.074219, loss_ce: 0.036604
2021-12-16 15:20:36,021 iteration 2249 : loss : 0.037318, loss_ce: 0.020379
2021-12-16 15:20:37,447 iteration 2250 : loss : 0.040606, loss_ce: 0.017015
2021-12-16 15:20:38,902 iteration 2251 : loss : 0.050168, loss_ce: 0.022529
2021-12-16 15:20:40,337 iteration 2252 : loss : 0.078398, loss_ce: 0.031294
2021-12-16 15:20:41,861 iteration 2253 : loss : 0.071084, loss_ce: 0.032854
2021-12-16 15:20:43,361 iteration 2254 : loss : 0.051076, loss_ce: 0.021703
2021-12-16 15:20:44,803 iteration 2255 : loss : 0.042584, loss_ce: 0.019207
2021-12-16 15:20:46,223 iteration 2256 : loss : 0.034212, loss_ce: 0.015856
2021-12-16 15:20:47,625 iteration 2257 : loss : 0.063608, loss_ce: 0.023764
2021-12-16 15:20:49,031 iteration 2258 : loss : 0.059519, loss_ce: 0.023745
2021-12-16 15:20:50,543 iteration 2259 : loss : 0.043134, loss_ce: 0.020957
2021-12-16 15:20:51,924 iteration 2260 : loss : 0.045381, loss_ce: 0.020618
2021-12-16 15:20:53,386 iteration 2261 : loss : 0.063825, loss_ce: 0.030099
 33%|████████▉                  | 133/400 [1:00:59<1:57:35, 26.42s/it]2021-12-16 15:20:54,821 iteration 2262 : loss : 0.044338, loss_ce: 0.025788
2021-12-16 15:20:56,318 iteration 2263 : loss : 0.070345, loss_ce: 0.025988
2021-12-16 15:20:57,837 iteration 2264 : loss : 0.045566, loss_ce: 0.016156
2021-12-16 15:20:59,310 iteration 2265 : loss : 0.052790, loss_ce: 0.021557
2021-12-16 15:21:00,726 iteration 2266 : loss : 0.054469, loss_ce: 0.023965
2021-12-16 15:21:02,138 iteration 2267 : loss : 0.036029, loss_ce: 0.015019
2021-12-16 15:21:03,582 iteration 2268 : loss : 0.050561, loss_ce: 0.021453
2021-12-16 15:21:04,995 iteration 2269 : loss : 0.052090, loss_ce: 0.029418
2021-12-16 15:21:06,446 iteration 2270 : loss : 0.043693, loss_ce: 0.017306
2021-12-16 15:21:07,860 iteration 2271 : loss : 0.048614, loss_ce: 0.021896
2021-12-16 15:21:09,287 iteration 2272 : loss : 0.059454, loss_ce: 0.029718
2021-12-16 15:21:10,751 iteration 2273 : loss : 0.046390, loss_ce: 0.018582
2021-12-16 15:21:12,214 iteration 2274 : loss : 0.062913, loss_ce: 0.024956
2021-12-16 15:21:13,704 iteration 2275 : loss : 0.054334, loss_ce: 0.024675
2021-12-16 15:21:15,095 iteration 2276 : loss : 0.039025, loss_ce: 0.018606
2021-12-16 15:21:16,541 iteration 2277 : loss : 0.064974, loss_ce: 0.027007
2021-12-16 15:21:17,927 iteration 2278 : loss : 0.041511, loss_ce: 0.018866
 34%|█████████                  | 134/400 [1:01:23<1:54:37, 25.86s/it]2021-12-16 15:21:19,349 iteration 2279 : loss : 0.046673, loss_ce: 0.018303
2021-12-16 15:21:20,795 iteration 2280 : loss : 0.046613, loss_ce: 0.021658
2021-12-16 15:21:22,236 iteration 2281 : loss : 0.070475, loss_ce: 0.020882
2021-12-16 15:21:23,710 iteration 2282 : loss : 0.041235, loss_ce: 0.018084
2021-12-16 15:21:25,220 iteration 2283 : loss : 0.053841, loss_ce: 0.025339
2021-12-16 15:21:26,627 iteration 2284 : loss : 0.056077, loss_ce: 0.025811
2021-12-16 15:21:28,044 iteration 2285 : loss : 0.036529, loss_ce: 0.015755
2021-12-16 15:21:29,468 iteration 2286 : loss : 0.047678, loss_ce: 0.021137
2021-12-16 15:21:30,880 iteration 2287 : loss : 0.042660, loss_ce: 0.020241
2021-12-16 15:21:32,340 iteration 2288 : loss : 0.055539, loss_ce: 0.020288
2021-12-16 15:21:33,728 iteration 2289 : loss : 0.043590, loss_ce: 0.013569
2021-12-16 15:21:35,207 iteration 2290 : loss : 0.067135, loss_ce: 0.033378
2021-12-16 15:21:36,629 iteration 2291 : loss : 0.038090, loss_ce: 0.017187
2021-12-16 15:21:38,055 iteration 2292 : loss : 0.060605, loss_ce: 0.029668
2021-12-16 15:21:39,424 iteration 2293 : loss : 0.039411, loss_ce: 0.023235
2021-12-16 15:21:40,906 iteration 2294 : loss : 0.080457, loss_ce: 0.025089
2021-12-16 15:21:40,906 Training Data Eval:
2021-12-16 15:21:48,372   Average segmentation loss on training set: 0.0261
2021-12-16 15:21:48,373 Validation Data Eval:
2021-12-16 15:21:50,952   Average segmentation loss on validation set: 0.1147
2021-12-16 15:21:52,473 iteration 2295 : loss : 0.077101, loss_ce: 0.026592
 34%|█████████                  | 135/400 [1:01:58<2:05:43, 28.46s/it]2021-12-16 15:21:53,897 iteration 2296 : loss : 0.035198, loss_ce: 0.015885
2021-12-16 15:21:55,336 iteration 2297 : loss : 0.037146, loss_ce: 0.017593
2021-12-16 15:21:56,776 iteration 2298 : loss : 0.034289, loss_ce: 0.018583
2021-12-16 15:21:58,295 iteration 2299 : loss : 0.068427, loss_ce: 0.032264
2021-12-16 15:21:59,709 iteration 2300 : loss : 0.043704, loss_ce: 0.021306
2021-12-16 15:22:01,204 iteration 2301 : loss : 0.033966, loss_ce: 0.012413
2021-12-16 15:22:02,654 iteration 2302 : loss : 0.071910, loss_ce: 0.032756
2021-12-16 15:22:04,097 iteration 2303 : loss : 0.042705, loss_ce: 0.015749
2021-12-16 15:22:05,605 iteration 2304 : loss : 0.072003, loss_ce: 0.025835
2021-12-16 15:22:07,087 iteration 2305 : loss : 0.045615, loss_ce: 0.021102
2021-12-16 15:22:08,615 iteration 2306 : loss : 0.048829, loss_ce: 0.025291
2021-12-16 15:22:10,019 iteration 2307 : loss : 0.062962, loss_ce: 0.023743
2021-12-16 15:22:11,396 iteration 2308 : loss : 0.055420, loss_ce: 0.023048
2021-12-16 15:22:12,807 iteration 2309 : loss : 0.046157, loss_ce: 0.024236
2021-12-16 15:22:14,309 iteration 2310 : loss : 0.048334, loss_ce: 0.022651
2021-12-16 15:22:15,671 iteration 2311 : loss : 0.058603, loss_ce: 0.023703
2021-12-16 15:22:17,131 iteration 2312 : loss : 0.055706, loss_ce: 0.022140
 34%|█████████▏                 | 136/400 [1:02:22<2:00:12, 27.32s/it]2021-12-16 15:22:18,648 iteration 2313 : loss : 0.052643, loss_ce: 0.021876
2021-12-16 15:22:19,995 iteration 2314 : loss : 0.036272, loss_ce: 0.015884
2021-12-16 15:22:21,397 iteration 2315 : loss : 0.029967, loss_ce: 0.012420
2021-12-16 15:22:22,921 iteration 2316 : loss : 0.044066, loss_ce: 0.021162
2021-12-16 15:22:24,294 iteration 2317 : loss : 0.050208, loss_ce: 0.019446
2021-12-16 15:22:25,695 iteration 2318 : loss : 0.045368, loss_ce: 0.024315
2021-12-16 15:22:27,133 iteration 2319 : loss : 0.057807, loss_ce: 0.021701
2021-12-16 15:22:28,646 iteration 2320 : loss : 0.064113, loss_ce: 0.029553
2021-12-16 15:22:30,078 iteration 2321 : loss : 0.049891, loss_ce: 0.023092
2021-12-16 15:22:31,515 iteration 2322 : loss : 0.045261, loss_ce: 0.021562
2021-12-16 15:22:32,865 iteration 2323 : loss : 0.032112, loss_ce: 0.014650
2021-12-16 15:22:34,298 iteration 2324 : loss : 0.038569, loss_ce: 0.019467
2021-12-16 15:22:35,637 iteration 2325 : loss : 0.035226, loss_ce: 0.017771
2021-12-16 15:22:37,054 iteration 2326 : loss : 0.081345, loss_ce: 0.019874
2021-12-16 15:22:38,457 iteration 2327 : loss : 0.044600, loss_ce: 0.019217
2021-12-16 15:22:39,900 iteration 2328 : loss : 0.053180, loss_ce: 0.026512
2021-12-16 15:22:41,288 iteration 2329 : loss : 0.037327, loss_ce: 0.018026
 34%|█████████▏                 | 137/400 [1:02:47<1:55:36, 26.38s/it]2021-12-16 15:22:42,769 iteration 2330 : loss : 0.054781, loss_ce: 0.026265
2021-12-16 15:22:44,141 iteration 2331 : loss : 0.034735, loss_ce: 0.015672
2021-12-16 15:22:45,618 iteration 2332 : loss : 0.051707, loss_ce: 0.022821
2021-12-16 15:22:47,030 iteration 2333 : loss : 0.048407, loss_ce: 0.022900
2021-12-16 15:22:48,570 iteration 2334 : loss : 0.050870, loss_ce: 0.019476
2021-12-16 15:22:50,110 iteration 2335 : loss : 0.080788, loss_ce: 0.037602
2021-12-16 15:22:51,611 iteration 2336 : loss : 0.047334, loss_ce: 0.022181
2021-12-16 15:22:53,037 iteration 2337 : loss : 0.065236, loss_ce: 0.025915
2021-12-16 15:22:54,492 iteration 2338 : loss : 0.066827, loss_ce: 0.028437
2021-12-16 15:22:55,943 iteration 2339 : loss : 0.059573, loss_ce: 0.024787
2021-12-16 15:22:57,325 iteration 2340 : loss : 0.048567, loss_ce: 0.020822
2021-12-16 15:22:58,763 iteration 2341 : loss : 0.051876, loss_ce: 0.022327
2021-12-16 15:23:00,217 iteration 2342 : loss : 0.042493, loss_ce: 0.021721
2021-12-16 15:23:01,768 iteration 2343 : loss : 0.056244, loss_ce: 0.025145
2021-12-16 15:23:03,162 iteration 2344 : loss : 0.081910, loss_ce: 0.023579
2021-12-16 15:23:04,583 iteration 2345 : loss : 0.048028, loss_ce: 0.027409
2021-12-16 15:23:06,025 iteration 2346 : loss : 0.052165, loss_ce: 0.025510
 34%|█████████▎                 | 138/400 [1:03:11<1:53:01, 25.88s/it]2021-12-16 15:23:07,578 iteration 2347 : loss : 0.084697, loss_ce: 0.041020
2021-12-16 15:23:09,022 iteration 2348 : loss : 0.039027, loss_ce: 0.017509
2021-12-16 15:23:10,423 iteration 2349 : loss : 0.045502, loss_ce: 0.020281
2021-12-16 15:23:11,831 iteration 2350 : loss : 0.051925, loss_ce: 0.019463
2021-12-16 15:23:13,327 iteration 2351 : loss : 0.069319, loss_ce: 0.031813
2021-12-16 15:23:14,707 iteration 2352 : loss : 0.040061, loss_ce: 0.021102
2021-12-16 15:23:16,111 iteration 2353 : loss : 0.042682, loss_ce: 0.020261
2021-12-16 15:23:17,519 iteration 2354 : loss : 0.039703, loss_ce: 0.019847
2021-12-16 15:23:18,938 iteration 2355 : loss : 0.041818, loss_ce: 0.017360
2021-12-16 15:23:20,425 iteration 2356 : loss : 0.049725, loss_ce: 0.022052
2021-12-16 15:23:21,865 iteration 2357 : loss : 0.084300, loss_ce: 0.029740
2021-12-16 15:23:23,308 iteration 2358 : loss : 0.052030, loss_ce: 0.023947
2021-12-16 15:23:24,711 iteration 2359 : loss : 0.058102, loss_ce: 0.022380
2021-12-16 15:23:26,107 iteration 2360 : loss : 0.057407, loss_ce: 0.022124
2021-12-16 15:23:27,546 iteration 2361 : loss : 0.049706, loss_ce: 0.020143
2021-12-16 15:23:29,083 iteration 2362 : loss : 0.076977, loss_ce: 0.037172
2021-12-16 15:23:30,528 iteration 2363 : loss : 0.041433, loss_ce: 0.020676
 35%|█████████▍                 | 139/400 [1:03:36<1:50:47, 25.47s/it]2021-12-16 15:23:32,092 iteration 2364 : loss : 0.031565, loss_ce: 0.013281
2021-12-16 15:23:33,624 iteration 2365 : loss : 0.041595, loss_ce: 0.018018
2021-12-16 15:23:35,121 iteration 2366 : loss : 0.054741, loss_ce: 0.022536
2021-12-16 15:23:36,514 iteration 2367 : loss : 0.039825, loss_ce: 0.012994
2021-12-16 15:23:37,907 iteration 2368 : loss : 0.043619, loss_ce: 0.022784
2021-12-16 15:23:39,360 iteration 2369 : loss : 0.051369, loss_ce: 0.017073
2021-12-16 15:23:40,790 iteration 2370 : loss : 0.055282, loss_ce: 0.021981
2021-12-16 15:23:42,278 iteration 2371 : loss : 0.047712, loss_ce: 0.021430
2021-12-16 15:23:43,704 iteration 2372 : loss : 0.055721, loss_ce: 0.022575
2021-12-16 15:23:45,162 iteration 2373 : loss : 0.064243, loss_ce: 0.035336
2021-12-16 15:23:46,582 iteration 2374 : loss : 0.041320, loss_ce: 0.019727
2021-12-16 15:23:48,018 iteration 2375 : loss : 0.049113, loss_ce: 0.020081
2021-12-16 15:23:49,497 iteration 2376 : loss : 0.048485, loss_ce: 0.025544
2021-12-16 15:23:50,952 iteration 2377 : loss : 0.047279, loss_ce: 0.024146
2021-12-16 15:23:52,393 iteration 2378 : loss : 0.032909, loss_ce: 0.016087
2021-12-16 15:23:53,864 iteration 2379 : loss : 0.053976, loss_ce: 0.024579
2021-12-16 15:23:53,864 Training Data Eval:
2021-12-16 15:24:01,390   Average segmentation loss on training set: 0.0258
2021-12-16 15:24:01,390 Validation Data Eval:
2021-12-16 15:24:03,984   Average segmentation loss on validation set: 0.1233
2021-12-16 15:24:05,408 iteration 2380 : loss : 0.058401, loss_ce: 0.032779
 35%|█████████▍                 | 140/400 [1:04:11<2:02:34, 28.29s/it]2021-12-16 15:24:06,858 iteration 2381 : loss : 0.040973, loss_ce: 0.016960
2021-12-16 15:24:08,354 iteration 2382 : loss : 0.040151, loss_ce: 0.015267
2021-12-16 15:24:09,755 iteration 2383 : loss : 0.035644, loss_ce: 0.014265
2021-12-16 15:24:11,233 iteration 2384 : loss : 0.049002, loss_ce: 0.020646
2021-12-16 15:24:12,724 iteration 2385 : loss : 0.065242, loss_ce: 0.027943
2021-12-16 15:24:14,147 iteration 2386 : loss : 0.048424, loss_ce: 0.018439
2021-12-16 15:24:15,553 iteration 2387 : loss : 0.063244, loss_ce: 0.024356
2021-12-16 15:24:16,997 iteration 2388 : loss : 0.042451, loss_ce: 0.019570
2021-12-16 15:24:18,382 iteration 2389 : loss : 0.027877, loss_ce: 0.011766
2021-12-16 15:24:19,836 iteration 2390 : loss : 0.059395, loss_ce: 0.032467
2021-12-16 15:24:21,265 iteration 2391 : loss : 0.048928, loss_ce: 0.028640
2021-12-16 15:24:22,721 iteration 2392 : loss : 0.047199, loss_ce: 0.021211
2021-12-16 15:24:24,165 iteration 2393 : loss : 0.063694, loss_ce: 0.029704
2021-12-16 15:24:25,514 iteration 2394 : loss : 0.033822, loss_ce: 0.014691
2021-12-16 15:24:27,019 iteration 2395 : loss : 0.051420, loss_ce: 0.024908
2021-12-16 15:24:28,419 iteration 2396 : loss : 0.038166, loss_ce: 0.020230
2021-12-16 15:24:29,897 iteration 2397 : loss : 0.055075, loss_ce: 0.023217
 35%|█████████▌                 | 141/400 [1:04:35<1:57:12, 27.15s/it]2021-12-16 15:24:31,369 iteration 2398 : loss : 0.051358, loss_ce: 0.020790
2021-12-16 15:24:32,774 iteration 2399 : loss : 0.054693, loss_ce: 0.017754
2021-12-16 15:24:34,275 iteration 2400 : loss : 0.046861, loss_ce: 0.023029
2021-12-16 15:24:35,730 iteration 2401 : loss : 0.032765, loss_ce: 0.014270
2021-12-16 15:24:37,218 iteration 2402 : loss : 0.042549, loss_ce: 0.023830
2021-12-16 15:24:38,624 iteration 2403 : loss : 0.045442, loss_ce: 0.022274
2021-12-16 15:24:40,014 iteration 2404 : loss : 0.041117, loss_ce: 0.022546
2021-12-16 15:24:41,369 iteration 2405 : loss : 0.040663, loss_ce: 0.018774
2021-12-16 15:24:42,930 iteration 2406 : loss : 0.064909, loss_ce: 0.022606
2021-12-16 15:24:44,307 iteration 2407 : loss : 0.040722, loss_ce: 0.021641
2021-12-16 15:24:45,696 iteration 2408 : loss : 0.039166, loss_ce: 0.019775
2021-12-16 15:24:47,179 iteration 2409 : loss : 0.031298, loss_ce: 0.012805
2021-12-16 15:24:48,685 iteration 2410 : loss : 0.052103, loss_ce: 0.022465
2021-12-16 15:24:50,165 iteration 2411 : loss : 0.052145, loss_ce: 0.019249
2021-12-16 15:24:51,546 iteration 2412 : loss : 0.035854, loss_ce: 0.016007
2021-12-16 15:24:53,050 iteration 2413 : loss : 0.059530, loss_ce: 0.029179
2021-12-16 15:24:54,489 iteration 2414 : loss : 0.037487, loss_ce: 0.017313
 36%|█████████▌                 | 142/400 [1:05:00<1:53:26, 26.38s/it]2021-12-16 15:24:55,977 iteration 2415 : loss : 0.061245, loss_ce: 0.021003
2021-12-16 15:24:57,404 iteration 2416 : loss : 0.032354, loss_ce: 0.014618
2021-12-16 15:24:58,847 iteration 2417 : loss : 0.052474, loss_ce: 0.020478
2021-12-16 15:25:00,379 iteration 2418 : loss : 0.049294, loss_ce: 0.019843
2021-12-16 15:25:01,825 iteration 2419 : loss : 0.053940, loss_ce: 0.029630
2021-12-16 15:25:03,370 iteration 2420 : loss : 0.060914, loss_ce: 0.032023
2021-12-16 15:25:04,888 iteration 2421 : loss : 0.061875, loss_ce: 0.021877
2021-12-16 15:25:06,370 iteration 2422 : loss : 0.073731, loss_ce: 0.030719
2021-12-16 15:25:07,793 iteration 2423 : loss : 0.050548, loss_ce: 0.020307
2021-12-16 15:25:09,209 iteration 2424 : loss : 0.040703, loss_ce: 0.019411
2021-12-16 15:25:10,752 iteration 2425 : loss : 0.075901, loss_ce: 0.024753
2021-12-16 15:25:12,179 iteration 2426 : loss : 0.048327, loss_ce: 0.018549
2021-12-16 15:25:13,538 iteration 2427 : loss : 0.038649, loss_ce: 0.020772
2021-12-16 15:25:14,956 iteration 2428 : loss : 0.049845, loss_ce: 0.017367
2021-12-16 15:25:16,369 iteration 2429 : loss : 0.044743, loss_ce: 0.020181
2021-12-16 15:25:17,793 iteration 2430 : loss : 0.026535, loss_ce: 0.012462
2021-12-16 15:25:19,250 iteration 2431 : loss : 0.050635, loss_ce: 0.027975
 36%|█████████▋                 | 143/400 [1:05:25<1:50:54, 25.89s/it]2021-12-16 15:25:20,685 iteration 2432 : loss : 0.039525, loss_ce: 0.014463
2021-12-16 15:25:22,111 iteration 2433 : loss : 0.055261, loss_ce: 0.023813
2021-12-16 15:25:23,554 iteration 2434 : loss : 0.046207, loss_ce: 0.018753
2021-12-16 15:25:25,075 iteration 2435 : loss : 0.053212, loss_ce: 0.028505
2021-12-16 15:25:26,445 iteration 2436 : loss : 0.036883, loss_ce: 0.017356
2021-12-16 15:25:27,936 iteration 2437 : loss : 0.038540, loss_ce: 0.014616
2021-12-16 15:25:29,441 iteration 2438 : loss : 0.057721, loss_ce: 0.020123
2021-12-16 15:25:30,940 iteration 2439 : loss : 0.047976, loss_ce: 0.020066
2021-12-16 15:25:32,432 iteration 2440 : loss : 0.054341, loss_ce: 0.025939
2021-12-16 15:25:33,855 iteration 2441 : loss : 0.058324, loss_ce: 0.025131
2021-12-16 15:25:35,270 iteration 2442 : loss : 0.041961, loss_ce: 0.018564
2021-12-16 15:25:36,638 iteration 2443 : loss : 0.040246, loss_ce: 0.018003
2021-12-16 15:25:38,067 iteration 2444 : loss : 0.053393, loss_ce: 0.024185
2021-12-16 15:25:39,492 iteration 2445 : loss : 0.047702, loss_ce: 0.022705
2021-12-16 15:25:41,012 iteration 2446 : loss : 0.054030, loss_ce: 0.029055
2021-12-16 15:25:42,397 iteration 2447 : loss : 0.053470, loss_ce: 0.019651
2021-12-16 15:25:43,890 iteration 2448 : loss : 0.044814, loss_ce: 0.018177
 36%|█████████▋                 | 144/400 [1:05:49<1:48:52, 25.52s/it]2021-12-16 15:25:45,327 iteration 2449 : loss : 0.061298, loss_ce: 0.029421
2021-12-16 15:25:46,715 iteration 2450 : loss : 0.036008, loss_ce: 0.019751
2021-12-16 15:25:48,129 iteration 2451 : loss : 0.035196, loss_ce: 0.014195
2021-12-16 15:25:49,528 iteration 2452 : loss : 0.047153, loss_ce: 0.019219
2021-12-16 15:25:50,982 iteration 2453 : loss : 0.051613, loss_ce: 0.020695
2021-12-16 15:25:52,396 iteration 2454 : loss : 0.035553, loss_ce: 0.015784
2021-12-16 15:25:53,795 iteration 2455 : loss : 0.045235, loss_ce: 0.023432
2021-12-16 15:25:55,185 iteration 2456 : loss : 0.048679, loss_ce: 0.021047
2021-12-16 15:25:56,617 iteration 2457 : loss : 0.044378, loss_ce: 0.019887
2021-12-16 15:25:58,025 iteration 2458 : loss : 0.042377, loss_ce: 0.018364
2021-12-16 15:25:59,388 iteration 2459 : loss : 0.027845, loss_ce: 0.013061
2021-12-16 15:26:00,806 iteration 2460 : loss : 0.045770, loss_ce: 0.016579
2021-12-16 15:26:02,330 iteration 2461 : loss : 0.044177, loss_ce: 0.019173
2021-12-16 15:26:03,819 iteration 2462 : loss : 0.047025, loss_ce: 0.018603
2021-12-16 15:26:05,240 iteration 2463 : loss : 0.049452, loss_ce: 0.023800
2021-12-16 15:26:06,718 iteration 2464 : loss : 0.037758, loss_ce: 0.017189
2021-12-16 15:26:06,719 Training Data Eval:
2021-12-16 15:26:14,166   Average segmentation loss on training set: 0.0265
2021-12-16 15:26:14,166 Validation Data Eval:
2021-12-16 15:26:16,754   Average segmentation loss on validation set: 0.1103
2021-12-16 15:26:18,198 iteration 2465 : loss : 0.054437, loss_ce: 0.022437
 36%|█████████▊                 | 145/400 [1:06:24<1:59:39, 28.16s/it]2021-12-16 15:26:19,758 iteration 2466 : loss : 0.059137, loss_ce: 0.024772
2021-12-16 15:26:21,282 iteration 2467 : loss : 0.050910, loss_ce: 0.023565
2021-12-16 15:26:22,690 iteration 2468 : loss : 0.060781, loss_ce: 0.026716
2021-12-16 15:26:24,078 iteration 2469 : loss : 0.038512, loss_ce: 0.018715
2021-12-16 15:26:25,520 iteration 2470 : loss : 0.051691, loss_ce: 0.021385
2021-12-16 15:26:27,055 iteration 2471 : loss : 0.069015, loss_ce: 0.027042
2021-12-16 15:26:28,450 iteration 2472 : loss : 0.058899, loss_ce: 0.025455
2021-12-16 15:26:29,933 iteration 2473 : loss : 0.055287, loss_ce: 0.024546
2021-12-16 15:26:31,344 iteration 2474 : loss : 0.036531, loss_ce: 0.013979
2021-12-16 15:26:32,799 iteration 2475 : loss : 0.042322, loss_ce: 0.018128
2021-12-16 15:26:34,208 iteration 2476 : loss : 0.040702, loss_ce: 0.022528
2021-12-16 15:26:35,740 iteration 2477 : loss : 0.051289, loss_ce: 0.023121
2021-12-16 15:26:37,212 iteration 2478 : loss : 0.041663, loss_ce: 0.017570
2021-12-16 15:26:38,573 iteration 2479 : loss : 0.041814, loss_ce: 0.016525
2021-12-16 15:26:40,027 iteration 2480 : loss : 0.050159, loss_ce: 0.021606
2021-12-16 15:26:41,539 iteration 2481 : loss : 0.045378, loss_ce: 0.019096
2021-12-16 15:26:42,943 iteration 2482 : loss : 0.034135, loss_ce: 0.017854
 36%|█████████▊                 | 146/400 [1:06:48<1:54:51, 27.13s/it]2021-12-16 15:26:44,503 iteration 2483 : loss : 0.048167, loss_ce: 0.021487
2021-12-16 15:26:45,979 iteration 2484 : loss : 0.052994, loss_ce: 0.014982
2021-12-16 15:26:47,392 iteration 2485 : loss : 0.049775, loss_ce: 0.021994
2021-12-16 15:26:48,823 iteration 2486 : loss : 0.032505, loss_ce: 0.015152
2021-12-16 15:26:50,268 iteration 2487 : loss : 0.050994, loss_ce: 0.019074
2021-12-16 15:26:51,767 iteration 2488 : loss : 0.040418, loss_ce: 0.018728
2021-12-16 15:26:53,192 iteration 2489 : loss : 0.053335, loss_ce: 0.024889
2021-12-16 15:26:54,669 iteration 2490 : loss : 0.056739, loss_ce: 0.028169
2021-12-16 15:26:56,174 iteration 2491 : loss : 0.047558, loss_ce: 0.026802
2021-12-16 15:26:57,513 iteration 2492 : loss : 0.036999, loss_ce: 0.016967
2021-12-16 15:26:58,972 iteration 2493 : loss : 0.060891, loss_ce: 0.028972
2021-12-16 15:27:00,396 iteration 2494 : loss : 0.069316, loss_ce: 0.022769
2021-12-16 15:27:01,835 iteration 2495 : loss : 0.054462, loss_ce: 0.021726
2021-12-16 15:27:03,459 iteration 2496 : loss : 0.098412, loss_ce: 0.030792
2021-12-16 15:27:04,933 iteration 2497 : loss : 0.063099, loss_ce: 0.022772
2021-12-16 15:27:06,420 iteration 2498 : loss : 0.045843, loss_ce: 0.020505
2021-12-16 15:27:07,793 iteration 2499 : loss : 0.043561, loss_ce: 0.014752
 37%|█████████▉                 | 147/400 [1:07:13<1:51:31, 26.45s/it]2021-12-16 15:27:09,245 iteration 2500 : loss : 0.049165, loss_ce: 0.019812
2021-12-16 15:27:10,680 iteration 2501 : loss : 0.041837, loss_ce: 0.014726
2021-12-16 15:27:12,215 iteration 2502 : loss : 0.066376, loss_ce: 0.028041
2021-12-16 15:27:13,610 iteration 2503 : loss : 0.036250, loss_ce: 0.017616
2021-12-16 15:27:15,029 iteration 2504 : loss : 0.036430, loss_ce: 0.015406
2021-12-16 15:27:16,515 iteration 2505 : loss : 0.052398, loss_ce: 0.022814
2021-12-16 15:27:17,968 iteration 2506 : loss : 0.059492, loss_ce: 0.022027
2021-12-16 15:27:19,357 iteration 2507 : loss : 0.050617, loss_ce: 0.024420
2021-12-16 15:27:20,798 iteration 2508 : loss : 0.046082, loss_ce: 0.017641
2021-12-16 15:27:22,228 iteration 2509 : loss : 0.046000, loss_ce: 0.017999
2021-12-16 15:27:23,651 iteration 2510 : loss : 0.031401, loss_ce: 0.015955
2021-12-16 15:27:25,114 iteration 2511 : loss : 0.036993, loss_ce: 0.018224
2021-12-16 15:27:26,584 iteration 2512 : loss : 0.045763, loss_ce: 0.018321
2021-12-16 15:27:28,074 iteration 2513 : loss : 0.053624, loss_ce: 0.017235
2021-12-16 15:27:29,506 iteration 2514 : loss : 0.045858, loss_ce: 0.017400
2021-12-16 15:27:30,958 iteration 2515 : loss : 0.034190, loss_ce: 0.021269
2021-12-16 15:27:32,381 iteration 2516 : loss : 0.050323, loss_ce: 0.029143
 37%|█████████▉                 | 148/400 [1:07:38<1:48:44, 25.89s/it]2021-12-16 15:27:33,825 iteration 2517 : loss : 0.045239, loss_ce: 0.019315
2021-12-16 15:27:35,263 iteration 2518 : loss : 0.076815, loss_ce: 0.028112
2021-12-16 15:27:36,729 iteration 2519 : loss : 0.049250, loss_ce: 0.021679
2021-12-16 15:27:38,182 iteration 2520 : loss : 0.060684, loss_ce: 0.029006
2021-12-16 15:27:39,618 iteration 2521 : loss : 0.038172, loss_ce: 0.017359
2021-12-16 15:27:41,086 iteration 2522 : loss : 0.039119, loss_ce: 0.020935
2021-12-16 15:27:42,596 iteration 2523 : loss : 0.072257, loss_ce: 0.019369
2021-12-16 15:27:44,032 iteration 2524 : loss : 0.041996, loss_ce: 0.021893
2021-12-16 15:27:45,478 iteration 2525 : loss : 0.042902, loss_ce: 0.019426
2021-12-16 15:27:46,925 iteration 2526 : loss : 0.048398, loss_ce: 0.018549
2021-12-16 15:27:48,351 iteration 2527 : loss : 0.042956, loss_ce: 0.018385
2021-12-16 15:27:49,820 iteration 2528 : loss : 0.051726, loss_ce: 0.020470
2021-12-16 15:27:51,281 iteration 2529 : loss : 0.057331, loss_ce: 0.026141
2021-12-16 15:27:52,755 iteration 2530 : loss : 0.043268, loss_ce: 0.022065
2021-12-16 15:27:54,288 iteration 2531 : loss : 0.055669, loss_ce: 0.025461
2021-12-16 15:27:55,727 iteration 2532 : loss : 0.071223, loss_ce: 0.028555
2021-12-16 15:27:57,187 iteration 2533 : loss : 0.050346, loss_ce: 0.018320
 37%|██████████                 | 149/400 [1:08:02<1:46:56, 25.56s/it]2021-12-16 15:27:58,602 iteration 2534 : loss : 0.050021, loss_ce: 0.022792
2021-12-16 15:28:00,108 iteration 2535 : loss : 0.059370, loss_ce: 0.023358
2021-12-16 15:28:01,513 iteration 2536 : loss : 0.045194, loss_ce: 0.022212
2021-12-16 15:28:02,937 iteration 2537 : loss : 0.046148, loss_ce: 0.022563
2021-12-16 15:28:04,290 iteration 2538 : loss : 0.030027, loss_ce: 0.015816
2021-12-16 15:28:05,751 iteration 2539 : loss : 0.035330, loss_ce: 0.016124
2021-12-16 15:28:07,140 iteration 2540 : loss : 0.031120, loss_ce: 0.012550
2021-12-16 15:28:08,560 iteration 2541 : loss : 0.043239, loss_ce: 0.021926
2021-12-16 15:28:09,959 iteration 2542 : loss : 0.027389, loss_ce: 0.012285
2021-12-16 15:28:11,366 iteration 2543 : loss : 0.037266, loss_ce: 0.016279
2021-12-16 15:28:12,826 iteration 2544 : loss : 0.051283, loss_ce: 0.019850
2021-12-16 15:28:14,400 iteration 2545 : loss : 0.040817, loss_ce: 0.019010
2021-12-16 15:28:15,957 iteration 2546 : loss : 0.077223, loss_ce: 0.035517
2021-12-16 15:28:17,340 iteration 2547 : loss : 0.038783, loss_ce: 0.020474
2021-12-16 15:28:18,824 iteration 2548 : loss : 0.046101, loss_ce: 0.026172
2021-12-16 15:28:20,286 iteration 2549 : loss : 0.067699, loss_ce: 0.018988
2021-12-16 15:28:20,286 Training Data Eval:
2021-12-16 15:28:27,760   Average segmentation loss on training set: 0.0255
2021-12-16 15:28:27,761 Validation Data Eval:
2021-12-16 15:28:30,349   Average segmentation loss on validation set: 0.1137
2021-12-16 15:28:31,782 iteration 2550 : loss : 0.042479, loss_ce: 0.016328
 38%|██████████▏                | 150/400 [1:08:37<1:57:49, 28.28s/it]2021-12-16 15:28:33,246 iteration 2551 : loss : 0.038818, loss_ce: 0.020590
2021-12-16 15:28:34,751 iteration 2552 : loss : 0.037696, loss_ce: 0.017159
2021-12-16 15:28:36,145 iteration 2553 : loss : 0.027832, loss_ce: 0.011747
2021-12-16 15:28:37,618 iteration 2554 : loss : 0.052222, loss_ce: 0.021750
2021-12-16 15:28:39,057 iteration 2555 : loss : 0.039394, loss_ce: 0.013371
2021-12-16 15:28:40,554 iteration 2556 : loss : 0.035649, loss_ce: 0.016134
2021-12-16 15:28:41,991 iteration 2557 : loss : 0.041423, loss_ce: 0.021403
2021-12-16 15:28:43,450 iteration 2558 : loss : 0.057053, loss_ce: 0.032234
2021-12-16 15:28:44,996 iteration 2559 : loss : 0.054348, loss_ce: 0.024633
2021-12-16 15:28:46,432 iteration 2560 : loss : 0.038985, loss_ce: 0.021817
2021-12-16 15:28:47,958 iteration 2561 : loss : 0.044466, loss_ce: 0.019855
2021-12-16 15:28:49,415 iteration 2562 : loss : 0.039889, loss_ce: 0.017712
2021-12-16 15:28:50,888 iteration 2563 : loss : 0.052574, loss_ce: 0.023400
2021-12-16 15:28:52,297 iteration 2564 : loss : 0.043062, loss_ce: 0.022054
2021-12-16 15:28:53,690 iteration 2565 : loss : 0.040104, loss_ce: 0.016783
2021-12-16 15:28:55,118 iteration 2566 : loss : 0.041263, loss_ce: 0.018455
2021-12-16 15:28:56,587 iteration 2567 : loss : 0.062850, loss_ce: 0.020543
 38%|██████████▏                | 151/400 [1:09:02<1:53:00, 27.23s/it]2021-12-16 15:28:58,102 iteration 2568 : loss : 0.056615, loss_ce: 0.031967
2021-12-16 15:28:59,534 iteration 2569 : loss : 0.049062, loss_ce: 0.021557
2021-12-16 15:29:00,967 iteration 2570 : loss : 0.059426, loss_ce: 0.031580
2021-12-16 15:29:02,417 iteration 2571 : loss : 0.033695, loss_ce: 0.015161
2021-12-16 15:29:03,816 iteration 2572 : loss : 0.044330, loss_ce: 0.015235
2021-12-16 15:29:05,225 iteration 2573 : loss : 0.033101, loss_ce: 0.015351
2021-12-16 15:29:06,658 iteration 2574 : loss : 0.042433, loss_ce: 0.016951
2021-12-16 15:29:08,229 iteration 2575 : loss : 0.074105, loss_ce: 0.033568
2021-12-16 15:29:09,684 iteration 2576 : loss : 0.039616, loss_ce: 0.016905
2021-12-16 15:29:11,127 iteration 2577 : loss : 0.059190, loss_ce: 0.022926
2021-12-16 15:29:12,585 iteration 2578 : loss : 0.046549, loss_ce: 0.018413
2021-12-16 15:29:13,979 iteration 2579 : loss : 0.042484, loss_ce: 0.012446
2021-12-16 15:29:15,482 iteration 2580 : loss : 0.065901, loss_ce: 0.018503
2021-12-16 15:29:16,983 iteration 2581 : loss : 0.052811, loss_ce: 0.023343
2021-12-16 15:29:18,508 iteration 2582 : loss : 0.044506, loss_ce: 0.019640
2021-12-16 15:29:19,921 iteration 2583 : loss : 0.032947, loss_ce: 0.014632
2021-12-16 15:29:21,264 iteration 2584 : loss : 0.030791, loss_ce: 0.014636
 38%|██████████▎                | 152/400 [1:09:27<1:49:24, 26.47s/it]2021-12-16 15:29:22,743 iteration 2585 : loss : 0.042749, loss_ce: 0.016263
2021-12-16 15:29:24,206 iteration 2586 : loss : 0.055912, loss_ce: 0.024266
2021-12-16 15:29:25,608 iteration 2587 : loss : 0.037879, loss_ce: 0.017387
2021-12-16 15:29:27,036 iteration 2588 : loss : 0.047851, loss_ce: 0.028180
2021-12-16 15:29:28,516 iteration 2589 : loss : 0.060742, loss_ce: 0.023641
2021-12-16 15:29:30,012 iteration 2590 : loss : 0.052500, loss_ce: 0.024484
2021-12-16 15:29:31,439 iteration 2591 : loss : 0.033582, loss_ce: 0.013847
2021-12-16 15:29:32,853 iteration 2592 : loss : 0.046246, loss_ce: 0.018609
2021-12-16 15:29:34,285 iteration 2593 : loss : 0.046068, loss_ce: 0.022167
2021-12-16 15:29:35,861 iteration 2594 : loss : 0.071279, loss_ce: 0.035268
2021-12-16 15:29:37,337 iteration 2595 : loss : 0.055967, loss_ce: 0.024233
2021-12-16 15:29:38,736 iteration 2596 : loss : 0.040145, loss_ce: 0.020572
2021-12-16 15:29:40,133 iteration 2597 : loss : 0.038091, loss_ce: 0.015922
2021-12-16 15:29:41,571 iteration 2598 : loss : 0.038462, loss_ce: 0.019995
2021-12-16 15:29:43,005 iteration 2599 : loss : 0.048657, loss_ce: 0.015527
2021-12-16 15:29:44,449 iteration 2600 : loss : 0.053039, loss_ce: 0.022338
2021-12-16 15:29:45,851 iteration 2601 : loss : 0.033417, loss_ce: 0.016181
 38%|██████████▎                | 153/400 [1:09:51<1:46:38, 25.90s/it]2021-12-16 15:29:47,365 iteration 2602 : loss : 0.049808, loss_ce: 0.024110
2021-12-16 15:29:48,725 iteration 2603 : loss : 0.036433, loss_ce: 0.016127
2021-12-16 15:29:50,154 iteration 2604 : loss : 0.041043, loss_ce: 0.018046
2021-12-16 15:29:51,722 iteration 2605 : loss : 0.051209, loss_ce: 0.020002
2021-12-16 15:29:53,166 iteration 2606 : loss : 0.043243, loss_ce: 0.020410
2021-12-16 15:29:54,631 iteration 2607 : loss : 0.059756, loss_ce: 0.023812
2021-12-16 15:29:56,033 iteration 2608 : loss : 0.049317, loss_ce: 0.025250
2021-12-16 15:29:57,441 iteration 2609 : loss : 0.044748, loss_ce: 0.015386
2021-12-16 15:29:59,016 iteration 2610 : loss : 0.069175, loss_ce: 0.030400
2021-12-16 15:30:00,427 iteration 2611 : loss : 0.060787, loss_ce: 0.023302
2021-12-16 15:30:01,784 iteration 2612 : loss : 0.036695, loss_ce: 0.018685
2021-12-16 15:30:03,207 iteration 2613 : loss : 0.039884, loss_ce: 0.015066
2021-12-16 15:30:04,735 iteration 2614 : loss : 0.057682, loss_ce: 0.021485
2021-12-16 15:30:06,156 iteration 2615 : loss : 0.052489, loss_ce: 0.022177
2021-12-16 15:30:07,582 iteration 2616 : loss : 0.039935, loss_ce: 0.017883
2021-12-16 15:30:09,094 iteration 2617 : loss : 0.057086, loss_ce: 0.019693
2021-12-16 15:30:10,536 iteration 2618 : loss : 0.064888, loss_ce: 0.032401
 38%|██████████▍                | 154/400 [1:10:16<1:44:42, 25.54s/it]2021-12-16 15:30:12,066 iteration 2619 : loss : 0.050311, loss_ce: 0.015353
2021-12-16 15:30:13,482 iteration 2620 : loss : 0.045800, loss_ce: 0.019752
2021-12-16 15:30:14,965 iteration 2621 : loss : 0.055082, loss_ce: 0.021327
2021-12-16 15:30:16,417 iteration 2622 : loss : 0.045270, loss_ce: 0.022725
2021-12-16 15:30:17,869 iteration 2623 : loss : 0.064910, loss_ce: 0.029334
2021-12-16 15:30:19,267 iteration 2624 : loss : 0.043604, loss_ce: 0.015673
2021-12-16 15:30:20,699 iteration 2625 : loss : 0.033612, loss_ce: 0.015986
2021-12-16 15:30:22,211 iteration 2626 : loss : 0.067812, loss_ce: 0.035892
2021-12-16 15:30:23,698 iteration 2627 : loss : 0.075547, loss_ce: 0.022790
2021-12-16 15:30:25,108 iteration 2628 : loss : 0.044540, loss_ce: 0.018557
2021-12-16 15:30:26,644 iteration 2629 : loss : 0.052525, loss_ce: 0.020887
2021-12-16 15:30:28,049 iteration 2630 : loss : 0.039388, loss_ce: 0.014774
2021-12-16 15:30:29,510 iteration 2631 : loss : 0.050400, loss_ce: 0.024828
2021-12-16 15:30:30,974 iteration 2632 : loss : 0.041236, loss_ce: 0.019039
2021-12-16 15:30:32,367 iteration 2633 : loss : 0.047528, loss_ce: 0.023945
2021-12-16 15:30:33,821 iteration 2634 : loss : 0.051179, loss_ce: 0.021059
2021-12-16 15:30:33,822 Training Data Eval:
2021-12-16 15:30:41,318   Average segmentation loss on training set: 0.0257
2021-12-16 15:30:41,318 Validation Data Eval:
2021-12-16 15:30:43,910   Average segmentation loss on validation set: 0.1155
2021-12-16 15:30:45,448 iteration 2635 : loss : 0.061206, loss_ce: 0.028868
 39%|██████████▍                | 155/400 [1:10:51<1:55:45, 28.35s/it]2021-12-16 15:30:46,915 iteration 2636 : loss : 0.040627, loss_ce: 0.016694
2021-12-16 15:30:48,506 iteration 2637 : loss : 0.079047, loss_ce: 0.029878
2021-12-16 15:30:49,961 iteration 2638 : loss : 0.041746, loss_ce: 0.018637
2021-12-16 15:30:51,302 iteration 2639 : loss : 0.029971, loss_ce: 0.013328
2021-12-16 15:30:52,706 iteration 2640 : loss : 0.045704, loss_ce: 0.022647
2021-12-16 15:30:54,235 iteration 2641 : loss : 0.050844, loss_ce: 0.023601
2021-12-16 15:30:55,735 iteration 2642 : loss : 0.064972, loss_ce: 0.019511
2021-12-16 15:30:57,213 iteration 2643 : loss : 0.046257, loss_ce: 0.016626
2021-12-16 15:30:58,618 iteration 2644 : loss : 0.042972, loss_ce: 0.016275
2021-12-16 15:31:00,029 iteration 2645 : loss : 0.054155, loss_ce: 0.032029
2021-12-16 15:31:01,460 iteration 2646 : loss : 0.051466, loss_ce: 0.018792
2021-12-16 15:31:02,966 iteration 2647 : loss : 0.041908, loss_ce: 0.018899
2021-12-16 15:31:04,335 iteration 2648 : loss : 0.023747, loss_ce: 0.014032
2021-12-16 15:31:05,806 iteration 2649 : loss : 0.047114, loss_ce: 0.022454
2021-12-16 15:31:07,281 iteration 2650 : loss : 0.050963, loss_ce: 0.026873
2021-12-16 15:31:08,708 iteration 2651 : loss : 0.050299, loss_ce: 0.021141
2021-12-16 15:31:10,183 iteration 2652 : loss : 0.048938, loss_ce: 0.023519
 39%|██████████▌                | 156/400 [1:11:16<1:50:53, 27.27s/it]2021-12-16 15:31:11,770 iteration 2653 : loss : 0.064408, loss_ce: 0.025529
2021-12-16 15:31:13,196 iteration 2654 : loss : 0.041915, loss_ce: 0.018606
2021-12-16 15:31:14,559 iteration 2655 : loss : 0.037490, loss_ce: 0.016833
2021-12-16 15:31:15,932 iteration 2656 : loss : 0.034520, loss_ce: 0.016726
2021-12-16 15:31:17,342 iteration 2657 : loss : 0.027630, loss_ce: 0.013009
2021-12-16 15:31:18,764 iteration 2658 : loss : 0.032922, loss_ce: 0.014560
2021-12-16 15:31:20,333 iteration 2659 : loss : 0.061937, loss_ce: 0.032194
2021-12-16 15:31:21,762 iteration 2660 : loss : 0.047444, loss_ce: 0.023950
2021-12-16 15:31:23,126 iteration 2661 : loss : 0.034414, loss_ce: 0.015631
2021-12-16 15:31:24,614 iteration 2662 : loss : 0.053169, loss_ce: 0.023636
2021-12-16 15:31:26,018 iteration 2663 : loss : 0.047768, loss_ce: 0.023412
2021-12-16 15:31:27,551 iteration 2664 : loss : 0.047086, loss_ce: 0.019030
2021-12-16 15:31:28,996 iteration 2665 : loss : 0.037823, loss_ce: 0.015668
2021-12-16 15:31:30,471 iteration 2666 : loss : 0.062011, loss_ce: 0.022963
2021-12-16 15:31:31,960 iteration 2667 : loss : 0.039084, loss_ce: 0.017145
2021-12-16 15:31:33,415 iteration 2668 : loss : 0.053706, loss_ce: 0.019689
2021-12-16 15:31:34,888 iteration 2669 : loss : 0.044600, loss_ce: 0.022564
 39%|██████████▌                | 157/400 [1:11:40<1:47:19, 26.50s/it]2021-12-16 15:31:36,373 iteration 2670 : loss : 0.057854, loss_ce: 0.018027
2021-12-16 15:31:37,844 iteration 2671 : loss : 0.046336, loss_ce: 0.016568
2021-12-16 15:31:39,337 iteration 2672 : loss : 0.033238, loss_ce: 0.015173
2021-12-16 15:31:40,841 iteration 2673 : loss : 0.071922, loss_ce: 0.031415
2021-12-16 15:31:42,262 iteration 2674 : loss : 0.045351, loss_ce: 0.020174
2021-12-16 15:31:43,762 iteration 2675 : loss : 0.051024, loss_ce: 0.020938
2021-12-16 15:31:45,230 iteration 2676 : loss : 0.050983, loss_ce: 0.018551
2021-12-16 15:31:46,621 iteration 2677 : loss : 0.039043, loss_ce: 0.018749
2021-12-16 15:31:48,000 iteration 2678 : loss : 0.026605, loss_ce: 0.011237
2021-12-16 15:31:49,482 iteration 2679 : loss : 0.054301, loss_ce: 0.025416
2021-12-16 15:31:50,996 iteration 2680 : loss : 0.051845, loss_ce: 0.028688
2021-12-16 15:31:52,421 iteration 2681 : loss : 0.037319, loss_ce: 0.020121
2021-12-16 15:31:53,811 iteration 2682 : loss : 0.031659, loss_ce: 0.015350
2021-12-16 15:31:55,288 iteration 2683 : loss : 0.040991, loss_ce: 0.022585
2021-12-16 15:31:56,724 iteration 2684 : loss : 0.068077, loss_ce: 0.019229
2021-12-16 15:31:58,159 iteration 2685 : loss : 0.049119, loss_ce: 0.024781
2021-12-16 15:31:59,589 iteration 2686 : loss : 0.037170, loss_ce: 0.016133
 40%|██████████▋                | 158/400 [1:12:05<1:44:42, 25.96s/it]2021-12-16 15:32:01,055 iteration 2687 : loss : 0.027305, loss_ce: 0.014361
2021-12-16 15:32:02,493 iteration 2688 : loss : 0.046971, loss_ce: 0.019873
2021-12-16 15:32:03,835 iteration 2689 : loss : 0.034834, loss_ce: 0.015739
2021-12-16 15:32:05,276 iteration 2690 : loss : 0.034758, loss_ce: 0.017201
2021-12-16 15:32:06,751 iteration 2691 : loss : 0.030250, loss_ce: 0.012554
2021-12-16 15:32:08,196 iteration 2692 : loss : 0.046555, loss_ce: 0.017160
2021-12-16 15:32:09,605 iteration 2693 : loss : 0.048044, loss_ce: 0.022575
2021-12-16 15:32:10,966 iteration 2694 : loss : 0.047657, loss_ce: 0.020893
2021-12-16 15:32:12,472 iteration 2695 : loss : 0.060281, loss_ce: 0.023759
2021-12-16 15:32:14,012 iteration 2696 : loss : 0.069724, loss_ce: 0.027127
2021-12-16 15:32:15,492 iteration 2697 : loss : 0.055168, loss_ce: 0.028544
2021-12-16 15:32:16,862 iteration 2698 : loss : 0.031257, loss_ce: 0.014217
2021-12-16 15:32:18,268 iteration 2699 : loss : 0.043943, loss_ce: 0.018068
2021-12-16 15:32:19,678 iteration 2700 : loss : 0.043684, loss_ce: 0.015496
2021-12-16 15:32:21,143 iteration 2701 : loss : 0.046324, loss_ce: 0.021392
2021-12-16 15:32:22,640 iteration 2702 : loss : 0.082064, loss_ce: 0.021812
2021-12-16 15:32:24,127 iteration 2703 : loss : 0.083880, loss_ce: 0.031993
 40%|██████████▋                | 159/400 [1:12:29<1:42:33, 25.53s/it]2021-12-16 15:32:25,548 iteration 2704 : loss : 0.034726, loss_ce: 0.012788
2021-12-16 15:32:26,952 iteration 2705 : loss : 0.039543, loss_ce: 0.017351
2021-12-16 15:32:28,450 iteration 2706 : loss : 0.058804, loss_ce: 0.032003
2021-12-16 15:32:29,897 iteration 2707 : loss : 0.032381, loss_ce: 0.014539
2021-12-16 15:32:31,329 iteration 2708 : loss : 0.050590, loss_ce: 0.019931
2021-12-16 15:32:32,839 iteration 2709 : loss : 0.043317, loss_ce: 0.014920
2021-12-16 15:32:34,318 iteration 2710 : loss : 0.054171, loss_ce: 0.026322
2021-12-16 15:32:35,708 iteration 2711 : loss : 0.034429, loss_ce: 0.013920
2021-12-16 15:32:37,134 iteration 2712 : loss : 0.068732, loss_ce: 0.027711
2021-12-16 15:32:38,600 iteration 2713 : loss : 0.036270, loss_ce: 0.015364
2021-12-16 15:32:40,046 iteration 2714 : loss : 0.054622, loss_ce: 0.025215
2021-12-16 15:32:41,468 iteration 2715 : loss : 0.056475, loss_ce: 0.030459
2021-12-16 15:32:42,881 iteration 2716 : loss : 0.049319, loss_ce: 0.014990
2021-12-16 15:32:44,260 iteration 2717 : loss : 0.033806, loss_ce: 0.015278
2021-12-16 15:32:45,748 iteration 2718 : loss : 0.045433, loss_ce: 0.018004
2021-12-16 15:32:47,168 iteration 2719 : loss : 0.029476, loss_ce: 0.013876
2021-12-16 15:32:47,168 Training Data Eval:
2021-12-16 15:32:54,656   Average segmentation loss on training set: 0.0236
2021-12-16 15:32:54,657 Validation Data Eval:
2021-12-16 15:32:57,250   Average segmentation loss on validation set: 0.1084
2021-12-16 15:32:58,736 iteration 2720 : loss : 0.032515, loss_ce: 0.016756
 40%|██████████▊                | 160/400 [1:13:04<1:53:00, 28.25s/it]2021-12-16 15:33:00,246 iteration 2721 : loss : 0.042514, loss_ce: 0.016870
2021-12-16 15:33:01,719 iteration 2722 : loss : 0.040970, loss_ce: 0.021437
2021-12-16 15:33:03,245 iteration 2723 : loss : 0.053388, loss_ce: 0.029099
2021-12-16 15:33:04,646 iteration 2724 : loss : 0.037477, loss_ce: 0.015188
2021-12-16 15:33:06,086 iteration 2725 : loss : 0.045931, loss_ce: 0.017746
2021-12-16 15:33:07,609 iteration 2726 : loss : 0.059006, loss_ce: 0.024114
2021-12-16 15:33:09,034 iteration 2727 : loss : 0.047205, loss_ce: 0.019458
2021-12-16 15:33:10,505 iteration 2728 : loss : 0.053966, loss_ce: 0.023653
2021-12-16 15:33:11,963 iteration 2729 : loss : 0.074304, loss_ce: 0.044008
2021-12-16 15:33:13,468 iteration 2730 : loss : 0.044776, loss_ce: 0.020072
2021-12-16 15:33:14,914 iteration 2731 : loss : 0.058212, loss_ce: 0.024157
2021-12-16 15:33:16,281 iteration 2732 : loss : 0.034477, loss_ce: 0.015801
2021-12-16 15:33:17,728 iteration 2733 : loss : 0.035783, loss_ce: 0.019895
2021-12-16 15:33:19,187 iteration 2734 : loss : 0.063074, loss_ce: 0.020195
2021-12-16 15:33:20,652 iteration 2735 : loss : 0.046270, loss_ce: 0.026240
2021-12-16 15:33:22,090 iteration 2736 : loss : 0.038995, loss_ce: 0.014557
2021-12-16 15:33:23,518 iteration 2737 : loss : 0.049767, loss_ce: 0.016385
 40%|██████████▊                | 161/400 [1:13:29<1:48:23, 27.21s/it]2021-12-16 15:33:25,035 iteration 2738 : loss : 0.046007, loss_ce: 0.022106
2021-12-16 15:33:26,408 iteration 2739 : loss : 0.056712, loss_ce: 0.018407
2021-12-16 15:33:27,924 iteration 2740 : loss : 0.052744, loss_ce: 0.027846
2021-12-16 15:33:29,348 iteration 2741 : loss : 0.048710, loss_ce: 0.023204
2021-12-16 15:33:30,806 iteration 2742 : loss : 0.051940, loss_ce: 0.023847
2021-12-16 15:33:32,208 iteration 2743 : loss : 0.036866, loss_ce: 0.016075
2021-12-16 15:33:33,657 iteration 2744 : loss : 0.030156, loss_ce: 0.012392
2021-12-16 15:33:35,055 iteration 2745 : loss : 0.031791, loss_ce: 0.011851
2021-12-16 15:33:36,596 iteration 2746 : loss : 0.101158, loss_ce: 0.026123
2021-12-16 15:33:38,010 iteration 2747 : loss : 0.045727, loss_ce: 0.020408
2021-12-16 15:33:39,516 iteration 2748 : loss : 0.045733, loss_ce: 0.015109
2021-12-16 15:33:41,022 iteration 2749 : loss : 0.055587, loss_ce: 0.025663
2021-12-16 15:33:42,437 iteration 2750 : loss : 0.046477, loss_ce: 0.024577
2021-12-16 15:33:43,873 iteration 2751 : loss : 0.060342, loss_ce: 0.019646
2021-12-16 15:33:45,414 iteration 2752 : loss : 0.064648, loss_ce: 0.025182
2021-12-16 15:33:46,969 iteration 2753 : loss : 0.054933, loss_ce: 0.025043
2021-12-16 15:33:48,421 iteration 2754 : loss : 0.035286, loss_ce: 0.020451
 40%|██████████▉                | 162/400 [1:13:54<1:45:11, 26.52s/it]2021-12-16 15:33:49,759 iteration 2755 : loss : 0.028013, loss_ce: 0.010437
2021-12-16 15:33:51,217 iteration 2756 : loss : 0.035187, loss_ce: 0.016048
2021-12-16 15:33:52,675 iteration 2757 : loss : 0.035599, loss_ce: 0.017931
2021-12-16 15:33:54,111 iteration 2758 : loss : 0.037553, loss_ce: 0.015858
2021-12-16 15:33:55,536 iteration 2759 : loss : 0.049323, loss_ce: 0.020605
2021-12-16 15:33:56,982 iteration 2760 : loss : 0.046434, loss_ce: 0.021153
2021-12-16 15:33:58,462 iteration 2761 : loss : 0.058152, loss_ce: 0.021535
2021-12-16 15:33:59,884 iteration 2762 : loss : 0.043843, loss_ce: 0.019645
2021-12-16 15:34:01,361 iteration 2763 : loss : 0.081282, loss_ce: 0.029892
2021-12-16 15:34:02,761 iteration 2764 : loss : 0.028202, loss_ce: 0.012704
2021-12-16 15:34:04,318 iteration 2765 : loss : 0.037365, loss_ce: 0.016008
2021-12-16 15:34:05,692 iteration 2766 : loss : 0.043532, loss_ce: 0.016722
2021-12-16 15:34:07,143 iteration 2767 : loss : 0.052039, loss_ce: 0.026016
2021-12-16 15:34:08,568 iteration 2768 : loss : 0.043766, loss_ce: 0.015292
2021-12-16 15:34:09,951 iteration 2769 : loss : 0.035461, loss_ce: 0.017040
2021-12-16 15:34:11,367 iteration 2770 : loss : 0.032866, loss_ce: 0.016921
2021-12-16 15:34:12,820 iteration 2771 : loss : 0.039368, loss_ce: 0.019082
 41%|███████████                | 163/400 [1:14:18<1:42:14, 25.88s/it]2021-12-16 15:34:14,245 iteration 2772 : loss : 0.042040, loss_ce: 0.016601
2021-12-16 15:34:15,693 iteration 2773 : loss : 0.039512, loss_ce: 0.016665
2021-12-16 15:34:17,134 iteration 2774 : loss : 0.050132, loss_ce: 0.015561
2021-12-16 15:34:18,607 iteration 2775 : loss : 0.052032, loss_ce: 0.022575
2021-12-16 15:34:20,045 iteration 2776 : loss : 0.040371, loss_ce: 0.017012
2021-12-16 15:34:21,541 iteration 2777 : loss : 0.030598, loss_ce: 0.013037
2021-12-16 15:34:22,936 iteration 2778 : loss : 0.042640, loss_ce: 0.015726
2021-12-16 15:34:24,356 iteration 2779 : loss : 0.036494, loss_ce: 0.016383
2021-12-16 15:34:25,828 iteration 2780 : loss : 0.046183, loss_ce: 0.022756
2021-12-16 15:34:27,375 iteration 2781 : loss : 0.060938, loss_ce: 0.028917
2021-12-16 15:34:28,873 iteration 2782 : loss : 0.037608, loss_ce: 0.018772
2021-12-16 15:34:30,292 iteration 2783 : loss : 0.037485, loss_ce: 0.014279
2021-12-16 15:34:31,635 iteration 2784 : loss : 0.034274, loss_ce: 0.011815
2021-12-16 15:34:33,081 iteration 2785 : loss : 0.037840, loss_ce: 0.019050
2021-12-16 15:34:34,453 iteration 2786 : loss : 0.041437, loss_ce: 0.017760
2021-12-16 15:34:35,862 iteration 2787 : loss : 0.036043, loss_ce: 0.015699
2021-12-16 15:34:37,438 iteration 2788 : loss : 0.052149, loss_ce: 0.022323
 41%|███████████                | 164/400 [1:14:43<1:40:19, 25.50s/it]2021-12-16 15:34:38,969 iteration 2789 : loss : 0.041205, loss_ce: 0.014733
2021-12-16 15:34:40,492 iteration 2790 : loss : 0.068460, loss_ce: 0.034461
2021-12-16 15:34:41,867 iteration 2791 : loss : 0.038839, loss_ce: 0.015207
2021-12-16 15:34:43,283 iteration 2792 : loss : 0.037749, loss_ce: 0.016663
2021-12-16 15:34:44,712 iteration 2793 : loss : 0.044581, loss_ce: 0.018010
2021-12-16 15:34:46,212 iteration 2794 : loss : 0.042470, loss_ce: 0.022384
2021-12-16 15:34:47,644 iteration 2795 : loss : 0.046721, loss_ce: 0.020471
2021-12-16 15:34:49,047 iteration 2796 : loss : 0.050056, loss_ce: 0.020533
2021-12-16 15:34:50,519 iteration 2797 : loss : 0.049858, loss_ce: 0.023748
2021-12-16 15:34:51,984 iteration 2798 : loss : 0.045741, loss_ce: 0.015787
2021-12-16 15:34:53,525 iteration 2799 : loss : 0.056444, loss_ce: 0.025101
2021-12-16 15:34:54,980 iteration 2800 : loss : 0.049423, loss_ce: 0.025974
2021-12-16 15:34:56,323 iteration 2801 : loss : 0.077362, loss_ce: 0.021755
2021-12-16 15:34:57,719 iteration 2802 : loss : 0.028664, loss_ce: 0.011772
2021-12-16 15:34:59,189 iteration 2803 : loss : 0.041207, loss_ce: 0.017210
2021-12-16 15:35:00,554 iteration 2804 : loss : 0.038559, loss_ce: 0.016994
2021-12-16 15:35:00,554 Training Data Eval:
2021-12-16 15:35:08,057   Average segmentation loss on training set: 0.0229
2021-12-16 15:35:08,058 Validation Data Eval:
2021-12-16 15:35:10,643   Average segmentation loss on validation set: 0.1102
2021-12-16 15:35:12,203 iteration 2805 : loss : 0.064026, loss_ce: 0.025469
 41%|███████████▏               | 165/400 [1:15:18<1:50:46, 28.28s/it]2021-12-16 15:35:13,783 iteration 2806 : loss : 0.040373, loss_ce: 0.017815
2021-12-16 15:35:15,321 iteration 2807 : loss : 0.081469, loss_ce: 0.023153
2021-12-16 15:35:16,818 iteration 2808 : loss : 0.040177, loss_ce: 0.015660
2021-12-16 15:35:18,274 iteration 2809 : loss : 0.047059, loss_ce: 0.020728
2021-12-16 15:35:19,653 iteration 2810 : loss : 0.041616, loss_ce: 0.016668
2021-12-16 15:35:21,163 iteration 2811 : loss : 0.052179, loss_ce: 0.027166
2021-12-16 15:35:22,550 iteration 2812 : loss : 0.028943, loss_ce: 0.012976
2021-12-16 15:35:24,060 iteration 2813 : loss : 0.051381, loss_ce: 0.025255
2021-12-16 15:35:25,518 iteration 2814 : loss : 0.037046, loss_ce: 0.014846
2021-12-16 15:35:26,958 iteration 2815 : loss : 0.040663, loss_ce: 0.019450
2021-12-16 15:35:28,398 iteration 2816 : loss : 0.037156, loss_ce: 0.016048
2021-12-16 15:35:29,929 iteration 2817 : loss : 0.072825, loss_ce: 0.018708
2021-12-16 15:35:31,421 iteration 2818 : loss : 0.063607, loss_ce: 0.030832
2021-12-16 15:35:32,836 iteration 2819 : loss : 0.045322, loss_ce: 0.022816
2021-12-16 15:35:34,378 iteration 2820 : loss : 0.068282, loss_ce: 0.025655
2021-12-16 15:35:35,901 iteration 2821 : loss : 0.061476, loss_ce: 0.027055
2021-12-16 15:35:37,383 iteration 2822 : loss : 0.046717, loss_ce: 0.016575
 42%|███████████▏               | 166/400 [1:15:43<1:46:40, 27.35s/it]2021-12-16 15:35:38,974 iteration 2823 : loss : 0.056120, loss_ce: 0.026744
2021-12-16 15:35:40,372 iteration 2824 : loss : 0.036833, loss_ce: 0.020144
2021-12-16 15:35:41,823 iteration 2825 : loss : 0.050315, loss_ce: 0.020579
2021-12-16 15:35:43,376 iteration 2826 : loss : 0.102715, loss_ce: 0.045178
2021-12-16 15:35:44,937 iteration 2827 : loss : 0.063524, loss_ce: 0.023448
2021-12-16 15:35:46,390 iteration 2828 : loss : 0.057195, loss_ce: 0.022080
2021-12-16 15:35:47,820 iteration 2829 : loss : 0.051905, loss_ce: 0.029919
2021-12-16 15:35:49,239 iteration 2830 : loss : 0.041628, loss_ce: 0.015834
2021-12-16 15:35:50,579 iteration 2831 : loss : 0.034642, loss_ce: 0.016411
2021-12-16 15:35:52,176 iteration 2832 : loss : 0.051968, loss_ce: 0.023519
2021-12-16 15:35:53,610 iteration 2833 : loss : 0.032647, loss_ce: 0.013610
2021-12-16 15:35:55,127 iteration 2834 : loss : 0.068699, loss_ce: 0.026154
2021-12-16 15:35:56,603 iteration 2835 : loss : 0.052674, loss_ce: 0.019183
2021-12-16 15:35:58,043 iteration 2836 : loss : 0.047031, loss_ce: 0.021189
2021-12-16 15:35:59,539 iteration 2837 : loss : 0.044535, loss_ce: 0.017286
2021-12-16 15:36:00,907 iteration 2838 : loss : 0.030863, loss_ce: 0.014149
2021-12-16 15:36:02,385 iteration 2839 : loss : 0.042551, loss_ce: 0.019224
 42%|███████████▎               | 167/400 [1:16:08<1:43:28, 26.65s/it]2021-12-16 15:36:03,920 iteration 2840 : loss : 0.056774, loss_ce: 0.022808
2021-12-16 15:36:05,339 iteration 2841 : loss : 0.043780, loss_ce: 0.017352
2021-12-16 15:36:06,772 iteration 2842 : loss : 0.044254, loss_ce: 0.017262
2021-12-16 15:36:08,268 iteration 2843 : loss : 0.053065, loss_ce: 0.016951
2021-12-16 15:36:09,728 iteration 2844 : loss : 0.041257, loss_ce: 0.019774
2021-12-16 15:36:11,177 iteration 2845 : loss : 0.064573, loss_ce: 0.027332
2021-12-16 15:36:12,639 iteration 2846 : loss : 0.037788, loss_ce: 0.016931
2021-12-16 15:36:13,980 iteration 2847 : loss : 0.025001, loss_ce: 0.014814
2021-12-16 15:36:15,467 iteration 2848 : loss : 0.039870, loss_ce: 0.015667
2021-12-16 15:36:16,960 iteration 2849 : loss : 0.054711, loss_ce: 0.021382
2021-12-16 15:36:18,457 iteration 2850 : loss : 0.049403, loss_ce: 0.024131
2021-12-16 15:36:19,950 iteration 2851 : loss : 0.053112, loss_ce: 0.024251
2021-12-16 15:36:21,410 iteration 2852 : loss : 0.086218, loss_ce: 0.026594
2021-12-16 15:36:22,945 iteration 2853 : loss : 0.041398, loss_ce: 0.018255
2021-12-16 15:36:24,420 iteration 2854 : loss : 0.058816, loss_ce: 0.023844
2021-12-16 15:36:25,834 iteration 2855 : loss : 0.046689, loss_ce: 0.025818
2021-12-16 15:36:27,320 iteration 2856 : loss : 0.048374, loss_ce: 0.025070
 42%|███████████▎               | 168/400 [1:16:33<1:41:02, 26.13s/it]2021-12-16 15:36:28,717 iteration 2857 : loss : 0.032121, loss_ce: 0.013410
2021-12-16 15:36:30,206 iteration 2858 : loss : 0.050115, loss_ce: 0.024481
2021-12-16 15:36:31,610 iteration 2859 : loss : 0.033911, loss_ce: 0.015313
2021-12-16 15:36:33,095 iteration 2860 : loss : 0.057445, loss_ce: 0.022165
2021-12-16 15:36:34,462 iteration 2861 : loss : 0.034856, loss_ce: 0.017666
2021-12-16 15:36:35,991 iteration 2862 : loss : 0.073581, loss_ce: 0.023111
2021-12-16 15:36:37,428 iteration 2863 : loss : 0.041864, loss_ce: 0.015400
2021-12-16 15:36:38,897 iteration 2864 : loss : 0.047860, loss_ce: 0.022547
2021-12-16 15:36:40,384 iteration 2865 : loss : 0.043777, loss_ce: 0.021791
2021-12-16 15:36:41,809 iteration 2866 : loss : 0.049665, loss_ce: 0.021193
2021-12-16 15:36:43,362 iteration 2867 : loss : 0.062322, loss_ce: 0.028969
2021-12-16 15:36:44,786 iteration 2868 : loss : 0.031909, loss_ce: 0.014070
2021-12-16 15:36:46,320 iteration 2869 : loss : 0.049412, loss_ce: 0.021660
2021-12-16 15:36:47,770 iteration 2870 : loss : 0.036351, loss_ce: 0.016751
2021-12-16 15:36:49,168 iteration 2871 : loss : 0.032904, loss_ce: 0.014309
2021-12-16 15:36:50,532 iteration 2872 : loss : 0.044671, loss_ce: 0.020933
2021-12-16 15:36:52,039 iteration 2873 : loss : 0.042065, loss_ce: 0.016207
 42%|███████████▍               | 169/400 [1:16:57<1:38:59, 25.71s/it]2021-12-16 15:36:53,561 iteration 2874 : loss : 0.045652, loss_ce: 0.018876
2021-12-16 15:36:55,010 iteration 2875 : loss : 0.043650, loss_ce: 0.018267
2021-12-16 15:36:56,466 iteration 2876 : loss : 0.041894, loss_ce: 0.022311
2021-12-16 15:36:57,976 iteration 2877 : loss : 0.058727, loss_ce: 0.018350
2021-12-16 15:36:59,428 iteration 2878 : loss : 0.050139, loss_ce: 0.026525
2021-12-16 15:37:00,920 iteration 2879 : loss : 0.043689, loss_ce: 0.016325
2021-12-16 15:37:02,406 iteration 2880 : loss : 0.056844, loss_ce: 0.020441
2021-12-16 15:37:03,861 iteration 2881 : loss : 0.049536, loss_ce: 0.023577
2021-12-16 15:37:05,383 iteration 2882 : loss : 0.048380, loss_ce: 0.024980
2021-12-16 15:37:06,814 iteration 2883 : loss : 0.040615, loss_ce: 0.019512
2021-12-16 15:37:08,270 iteration 2884 : loss : 0.042757, loss_ce: 0.021876
2021-12-16 15:37:09,734 iteration 2885 : loss : 0.041914, loss_ce: 0.019744
2021-12-16 15:37:11,085 iteration 2886 : loss : 0.062194, loss_ce: 0.025337
2021-12-16 15:37:12,604 iteration 2887 : loss : 0.051433, loss_ce: 0.027614
2021-12-16 15:37:14,075 iteration 2888 : loss : 0.077888, loss_ce: 0.023792
2021-12-16 15:37:15,636 iteration 2889 : loss : 0.041320, loss_ce: 0.017277
2021-12-16 15:37:15,636 Training Data Eval:
2021-12-16 15:37:23,098   Average segmentation loss on training set: 0.0234
2021-12-16 15:37:23,098 Validation Data Eval:
2021-12-16 15:37:25,684   Average segmentation loss on validation set: 0.1103
2021-12-16 15:37:27,208 iteration 2890 : loss : 0.047749, loss_ce: 0.019996
 42%|███████████▍               | 170/400 [1:17:33<1:49:25, 28.54s/it]2021-12-16 15:37:28,747 iteration 2891 : loss : 0.045567, loss_ce: 0.020994
2021-12-16 15:37:30,283 iteration 2892 : loss : 0.057803, loss_ce: 0.018525
2021-12-16 15:37:31,704 iteration 2893 : loss : 0.031941, loss_ce: 0.012328
2021-12-16 15:37:33,230 iteration 2894 : loss : 0.063328, loss_ce: 0.024833
2021-12-16 15:37:34,738 iteration 2895 : loss : 0.053943, loss_ce: 0.026480
2021-12-16 15:37:36,140 iteration 2896 : loss : 0.039942, loss_ce: 0.015142
2021-12-16 15:37:37,568 iteration 2897 : loss : 0.049919, loss_ce: 0.023618
2021-12-16 15:37:38,955 iteration 2898 : loss : 0.034649, loss_ce: 0.018303
2021-12-16 15:37:40,435 iteration 2899 : loss : 0.058685, loss_ce: 0.021614
2021-12-16 15:37:41,873 iteration 2900 : loss : 0.041889, loss_ce: 0.017445
2021-12-16 15:37:43,329 iteration 2901 : loss : 0.045887, loss_ce: 0.015794
2021-12-16 15:37:44,723 iteration 2902 : loss : 0.037640, loss_ce: 0.014331
2021-12-16 15:37:46,144 iteration 2903 : loss : 0.037451, loss_ce: 0.019574
2021-12-16 15:37:47,557 iteration 2904 : loss : 0.046909, loss_ce: 0.022608
2021-12-16 15:37:48,942 iteration 2905 : loss : 0.043706, loss_ce: 0.021862
2021-12-16 15:37:50,448 iteration 2906 : loss : 0.063336, loss_ce: 0.034324
2021-12-16 15:37:51,869 iteration 2907 : loss : 0.046289, loss_ce: 0.021499
 43%|███████████▌               | 171/400 [1:17:57<1:44:30, 27.38s/it]2021-12-16 15:37:53,399 iteration 2908 : loss : 0.061957, loss_ce: 0.031265
2021-12-16 15:37:54,901 iteration 2909 : loss : 0.057033, loss_ce: 0.031756
2021-12-16 15:37:56,356 iteration 2910 : loss : 0.043144, loss_ce: 0.017624
2021-12-16 15:37:57,834 iteration 2911 : loss : 0.055923, loss_ce: 0.020625
2021-12-16 15:37:59,240 iteration 2912 : loss : 0.038520, loss_ce: 0.015954
2021-12-16 15:38:00,744 iteration 2913 : loss : 0.046336, loss_ce: 0.022499
2021-12-16 15:38:02,149 iteration 2914 : loss : 0.044834, loss_ce: 0.018453
2021-12-16 15:38:03,556 iteration 2915 : loss : 0.032738, loss_ce: 0.015452
2021-12-16 15:38:05,006 iteration 2916 : loss : 0.046232, loss_ce: 0.022000
2021-12-16 15:38:06,385 iteration 2917 : loss : 0.035665, loss_ce: 0.017527
2021-12-16 15:38:07,814 iteration 2918 : loss : 0.063594, loss_ce: 0.019692
2021-12-16 15:38:09,281 iteration 2919 : loss : 0.036951, loss_ce: 0.016671
2021-12-16 15:38:10,752 iteration 2920 : loss : 0.044237, loss_ce: 0.019578
2021-12-16 15:38:12,188 iteration 2921 : loss : 0.034115, loss_ce: 0.016369
2021-12-16 15:38:13,560 iteration 2922 : loss : 0.050141, loss_ce: 0.019934
2021-12-16 15:38:14,991 iteration 2923 : loss : 0.054346, loss_ce: 0.020780
2021-12-16 15:38:16,457 iteration 2924 : loss : 0.070021, loss_ce: 0.030346
 43%|███████████▌               | 172/400 [1:18:22<1:40:51, 26.54s/it]2021-12-16 15:38:17,850 iteration 2925 : loss : 0.035972, loss_ce: 0.020020
2021-12-16 15:38:19,402 iteration 2926 : loss : 0.086449, loss_ce: 0.043602
2021-12-16 15:38:20,834 iteration 2927 : loss : 0.052748, loss_ce: 0.027113
2021-12-16 15:38:22,172 iteration 2928 : loss : 0.036014, loss_ce: 0.014226
2021-12-16 15:38:23,607 iteration 2929 : loss : 0.035888, loss_ce: 0.016684
2021-12-16 15:38:25,129 iteration 2930 : loss : 0.054627, loss_ce: 0.026945
2021-12-16 15:38:26,541 iteration 2931 : loss : 0.043632, loss_ce: 0.018089
2021-12-16 15:38:27,933 iteration 2932 : loss : 0.045642, loss_ce: 0.019176
2021-12-16 15:38:29,444 iteration 2933 : loss : 0.057053, loss_ce: 0.016482
2021-12-16 15:38:30,892 iteration 2934 : loss : 0.039119, loss_ce: 0.014965
2021-12-16 15:38:32,356 iteration 2935 : loss : 0.037221, loss_ce: 0.015675
2021-12-16 15:38:33,796 iteration 2936 : loss : 0.035585, loss_ce: 0.015096
2021-12-16 15:38:35,269 iteration 2937 : loss : 0.033440, loss_ce: 0.017427
2021-12-16 15:38:36,744 iteration 2938 : loss : 0.059824, loss_ce: 0.025301
2021-12-16 15:38:38,216 iteration 2939 : loss : 0.046934, loss_ce: 0.017319
2021-12-16 15:38:39,745 iteration 2940 : loss : 0.085250, loss_ce: 0.040446
2021-12-16 15:38:41,135 iteration 2941 : loss : 0.032159, loss_ce: 0.013695
 43%|███████████▋               | 173/400 [1:18:46<1:38:18, 25.99s/it]2021-12-16 15:38:42,579 iteration 2942 : loss : 0.031080, loss_ce: 0.011875
2021-12-16 15:38:44,070 iteration 2943 : loss : 0.048542, loss_ce: 0.018374
2021-12-16 15:38:45,490 iteration 2944 : loss : 0.036221, loss_ce: 0.019799
2021-12-16 15:38:46,943 iteration 2945 : loss : 0.036912, loss_ce: 0.013368
2021-12-16 15:38:48,289 iteration 2946 : loss : 0.041647, loss_ce: 0.019390
2021-12-16 15:38:49,727 iteration 2947 : loss : 0.048017, loss_ce: 0.021230
2021-12-16 15:38:51,137 iteration 2948 : loss : 0.029863, loss_ce: 0.010004
2021-12-16 15:38:52,633 iteration 2949 : loss : 0.044462, loss_ce: 0.017715
2021-12-16 15:38:54,087 iteration 2950 : loss : 0.038665, loss_ce: 0.019199
2021-12-16 15:38:55,570 iteration 2951 : loss : 0.039038, loss_ce: 0.019833
2021-12-16 15:38:57,054 iteration 2952 : loss : 0.039024, loss_ce: 0.014961
2021-12-16 15:38:58,570 iteration 2953 : loss : 0.057184, loss_ce: 0.028706
2021-12-16 15:39:00,118 iteration 2954 : loss : 0.082980, loss_ce: 0.029559
2021-12-16 15:39:01,511 iteration 2955 : loss : 0.039452, loss_ce: 0.020126
2021-12-16 15:39:02,931 iteration 2956 : loss : 0.035961, loss_ce: 0.015473
2021-12-16 15:39:04,340 iteration 2957 : loss : 0.045068, loss_ce: 0.020615
2021-12-16 15:39:05,802 iteration 2958 : loss : 0.043417, loss_ce: 0.023526
 44%|███████████▋               | 174/400 [1:19:11<1:36:22, 25.59s/it]2021-12-16 15:39:07,258 iteration 2959 : loss : 0.037609, loss_ce: 0.014622
2021-12-16 15:39:08,680 iteration 2960 : loss : 0.039845, loss_ce: 0.020536
2021-12-16 15:39:10,128 iteration 2961 : loss : 0.046666, loss_ce: 0.019205
2021-12-16 15:39:11,710 iteration 2962 : loss : 0.046676, loss_ce: 0.019528
2021-12-16 15:39:13,169 iteration 2963 : loss : 0.073164, loss_ce: 0.032708
2021-12-16 15:39:14,528 iteration 2964 : loss : 0.034050, loss_ce: 0.013569
2021-12-16 15:39:16,011 iteration 2965 : loss : 0.037930, loss_ce: 0.020989
2021-12-16 15:39:17,496 iteration 2966 : loss : 0.051564, loss_ce: 0.021321
2021-12-16 15:39:18,912 iteration 2967 : loss : 0.046918, loss_ce: 0.019992
2021-12-16 15:39:20,354 iteration 2968 : loss : 0.046521, loss_ce: 0.020501
2021-12-16 15:39:21,793 iteration 2969 : loss : 0.047903, loss_ce: 0.021988
2021-12-16 15:39:23,265 iteration 2970 : loss : 0.058429, loss_ce: 0.024603
2021-12-16 15:39:24,689 iteration 2971 : loss : 0.034712, loss_ce: 0.014793
2021-12-16 15:39:26,113 iteration 2972 : loss : 0.044177, loss_ce: 0.021632
2021-12-16 15:39:27,507 iteration 2973 : loss : 0.037933, loss_ce: 0.011517
2021-12-16 15:39:29,017 iteration 2974 : loss : 0.074211, loss_ce: 0.027693
2021-12-16 15:39:29,018 Training Data Eval:
2021-12-16 15:39:36,497   Average segmentation loss on training set: 0.0222
2021-12-16 15:39:36,497 Validation Data Eval:
2021-12-16 15:39:39,086   Average segmentation loss on validation set: 0.1023
2021-12-16 15:39:46,342 Found new lowest validation loss at iteration 2974! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/TU_3seeds/TU_RESNET_no_pretraining_SGD_best_val_loss_seed1234.pth
2021-12-16 15:39:47,689 iteration 2975 : loss : 0.033949, loss_ce: 0.015337
 44%|███████████▊               | 175/400 [1:19:53<1:54:17, 30.48s/it]2021-12-16 15:39:48,999 iteration 2976 : loss : 0.029007, loss_ce: 0.014676
2021-12-16 15:39:50,399 iteration 2977 : loss : 0.041454, loss_ce: 0.021298
2021-12-16 15:39:51,774 iteration 2978 : loss : 0.037155, loss_ce: 0.013754
2021-12-16 15:39:53,222 iteration 2979 : loss : 0.043340, loss_ce: 0.017090
2021-12-16 15:39:54,612 iteration 2980 : loss : 0.047770, loss_ce: 0.019772
2021-12-16 15:39:56,070 iteration 2981 : loss : 0.065487, loss_ce: 0.028542
2021-12-16 15:39:57,431 iteration 2982 : loss : 0.038410, loss_ce: 0.017188
2021-12-16 15:39:58,800 iteration 2983 : loss : 0.038877, loss_ce: 0.015698
2021-12-16 15:40:00,171 iteration 2984 : loss : 0.062491, loss_ce: 0.020950
2021-12-16 15:40:01,570 iteration 2985 : loss : 0.042765, loss_ce: 0.018219
2021-12-16 15:40:02,869 iteration 2986 : loss : 0.039282, loss_ce: 0.018000
2021-12-16 15:40:04,269 iteration 2987 : loss : 0.047434, loss_ce: 0.018585
2021-12-16 15:40:05,766 iteration 2988 : loss : 0.051539, loss_ce: 0.025111
2021-12-16 15:40:07,279 iteration 2989 : loss : 0.062845, loss_ce: 0.027356
2021-12-16 15:40:08,689 iteration 2990 : loss : 0.036488, loss_ce: 0.016390
2021-12-16 15:40:10,147 iteration 2991 : loss : 0.035888, loss_ce: 0.015575
2021-12-16 15:40:11,679 iteration 2992 : loss : 0.040426, loss_ce: 0.018293
 44%|███████████▉               | 176/400 [1:20:17<1:46:31, 28.53s/it]2021-12-16 15:40:13,131 iteration 2993 : loss : 0.048577, loss_ce: 0.027382
2021-12-16 15:40:14,605 iteration 2994 : loss : 0.067028, loss_ce: 0.021128
2021-12-16 15:40:16,045 iteration 2995 : loss : 0.048365, loss_ce: 0.018119
2021-12-16 15:40:17,484 iteration 2996 : loss : 0.034756, loss_ce: 0.017394
2021-12-16 15:40:18,919 iteration 2997 : loss : 0.058604, loss_ce: 0.023494
2021-12-16 15:40:20,382 iteration 2998 : loss : 0.053776, loss_ce: 0.025059
2021-12-16 15:40:21,890 iteration 2999 : loss : 0.091650, loss_ce: 0.021529
2021-12-16 15:40:23,414 iteration 3000 : loss : 0.081906, loss_ce: 0.034080
2021-12-16 15:40:24,930 iteration 3001 : loss : 0.063880, loss_ce: 0.017520
2021-12-16 15:40:26,334 iteration 3002 : loss : 0.049699, loss_ce: 0.022242
2021-12-16 15:40:27,752 iteration 3003 : loss : 0.045510, loss_ce: 0.017654
2021-12-16 15:40:29,198 iteration 3004 : loss : 0.034301, loss_ce: 0.016182
2021-12-16 15:40:30,651 iteration 3005 : loss : 0.042756, loss_ce: 0.021974
2021-12-16 15:40:32,146 iteration 3006 : loss : 0.040632, loss_ce: 0.019083
2021-12-16 15:40:33,637 iteration 3007 : loss : 0.040956, loss_ce: 0.019545
2021-12-16 15:40:35,131 iteration 3008 : loss : 0.054598, loss_ce: 0.021505
2021-12-16 15:40:36,517 iteration 3009 : loss : 0.040139, loss_ce: 0.018485
 44%|███████████▉               | 177/400 [1:20:42<1:41:55, 27.42s/it]2021-12-16 15:40:38,129 iteration 3010 : loss : 0.070736, loss_ce: 0.029805
2021-12-16 15:40:39,608 iteration 3011 : loss : 0.034659, loss_ce: 0.016536
2021-12-16 15:40:41,006 iteration 3012 : loss : 0.030260, loss_ce: 0.014815
2021-12-16 15:40:42,394 iteration 3013 : loss : 0.042360, loss_ce: 0.016010
2021-12-16 15:40:43,870 iteration 3014 : loss : 0.051915, loss_ce: 0.023458
2021-12-16 15:40:45,328 iteration 3015 : loss : 0.062585, loss_ce: 0.021104
2021-12-16 15:40:46,781 iteration 3016 : loss : 0.057161, loss_ce: 0.026391
2021-12-16 15:40:48,208 iteration 3017 : loss : 0.043149, loss_ce: 0.025039
2021-12-16 15:40:49,636 iteration 3018 : loss : 0.030772, loss_ce: 0.016434
2021-12-16 15:40:51,022 iteration 3019 : loss : 0.030736, loss_ce: 0.013512
2021-12-16 15:40:52,508 iteration 3020 : loss : 0.052095, loss_ce: 0.020495
2021-12-16 15:40:53,970 iteration 3021 : loss : 0.031050, loss_ce: 0.012986
2021-12-16 15:40:55,392 iteration 3022 : loss : 0.029806, loss_ce: 0.013579
2021-12-16 15:40:56,839 iteration 3023 : loss : 0.046010, loss_ce: 0.016653
2021-12-16 15:40:58,364 iteration 3024 : loss : 0.045315, loss_ce: 0.020192
2021-12-16 15:40:59,886 iteration 3025 : loss : 0.052249, loss_ce: 0.024053
2021-12-16 15:41:01,309 iteration 3026 : loss : 0.031170, loss_ce: 0.014055
 44%|████████████               | 178/400 [1:21:07<1:38:32, 26.63s/it]2021-12-16 15:41:02,863 iteration 3027 : loss : 0.066305, loss_ce: 0.027494
2021-12-16 15:41:04,283 iteration 3028 : loss : 0.045557, loss_ce: 0.021815
2021-12-16 15:41:05,775 iteration 3029 : loss : 0.048157, loss_ce: 0.022885
2021-12-16 15:41:07,214 iteration 3030 : loss : 0.056966, loss_ce: 0.026251
2021-12-16 15:41:08,672 iteration 3031 : loss : 0.046914, loss_ce: 0.020564
2021-12-16 15:41:10,073 iteration 3032 : loss : 0.035002, loss_ce: 0.014675
2021-12-16 15:41:11,550 iteration 3033 : loss : 0.065321, loss_ce: 0.025496
2021-12-16 15:41:13,039 iteration 3034 : loss : 0.035569, loss_ce: 0.015418
2021-12-16 15:41:14,499 iteration 3035 : loss : 0.039703, loss_ce: 0.019530
2021-12-16 15:41:15,925 iteration 3036 : loss : 0.051220, loss_ce: 0.027086
2021-12-16 15:41:17,376 iteration 3037 : loss : 0.040475, loss_ce: 0.016890
2021-12-16 15:41:18,869 iteration 3038 : loss : 0.045829, loss_ce: 0.019508
2021-12-16 15:41:20,251 iteration 3039 : loss : 0.043694, loss_ce: 0.016869
2021-12-16 15:41:21,721 iteration 3040 : loss : 0.060814, loss_ce: 0.018179
2021-12-16 15:41:23,231 iteration 3041 : loss : 0.046479, loss_ce: 0.021608
2021-12-16 15:41:24,685 iteration 3042 : loss : 0.033748, loss_ce: 0.017089
2021-12-16 15:41:26,321 iteration 3043 : loss : 0.059610, loss_ce: 0.024098
 45%|████████████               | 179/400 [1:21:32<1:36:18, 26.15s/it]2021-12-16 15:41:27,804 iteration 3044 : loss : 0.040124, loss_ce: 0.018911
2021-12-16 15:41:29,206 iteration 3045 : loss : 0.036410, loss_ce: 0.015927
2021-12-16 15:41:30,619 iteration 3046 : loss : 0.030160, loss_ce: 0.012604
2021-12-16 15:41:32,171 iteration 3047 : loss : 0.054613, loss_ce: 0.031047
2021-12-16 15:41:33,592 iteration 3048 : loss : 0.037599, loss_ce: 0.014772
2021-12-16 15:41:35,070 iteration 3049 : loss : 0.046943, loss_ce: 0.021900
2021-12-16 15:41:36,563 iteration 3050 : loss : 0.047012, loss_ce: 0.023988
2021-12-16 15:41:38,034 iteration 3051 : loss : 0.067891, loss_ce: 0.018969
2021-12-16 15:41:39,478 iteration 3052 : loss : 0.034956, loss_ce: 0.014461
2021-12-16 15:41:41,020 iteration 3053 : loss : 0.033863, loss_ce: 0.017074
2021-12-16 15:41:42,420 iteration 3054 : loss : 0.035956, loss_ce: 0.012523
2021-12-16 15:41:43,907 iteration 3055 : loss : 0.053861, loss_ce: 0.020926
2021-12-16 15:41:45,330 iteration 3056 : loss : 0.040600, loss_ce: 0.018812
2021-12-16 15:41:46,721 iteration 3057 : loss : 0.047836, loss_ce: 0.021475
2021-12-16 15:41:48,198 iteration 3058 : loss : 0.039155, loss_ce: 0.019484
2021-12-16 15:41:49,703 iteration 3059 : loss : 0.041686, loss_ce: 0.015339
2021-12-16 15:41:49,703 Training Data Eval:
2021-12-16 15:41:57,202   Average segmentation loss on training set: 0.0216
2021-12-16 15:41:57,202 Validation Data Eval:
2021-12-16 15:41:59,801   Average segmentation loss on validation set: 0.1045
2021-12-16 15:42:01,230 iteration 3060 : loss : 0.037673, loss_ce: 0.021341
 45%|████████████▏              | 180/400 [1:22:07<1:45:31, 28.78s/it]2021-12-16 15:42:02,663 iteration 3061 : loss : 0.045995, loss_ce: 0.018422
2021-12-16 15:42:04,133 iteration 3062 : loss : 0.059387, loss_ce: 0.024482
2021-12-16 15:42:05,644 iteration 3063 : loss : 0.053236, loss_ce: 0.021480
2021-12-16 15:42:07,155 iteration 3064 : loss : 0.032329, loss_ce: 0.015717
2021-12-16 15:42:08,522 iteration 3065 : loss : 0.024521, loss_ce: 0.010543
2021-12-16 15:42:09,948 iteration 3066 : loss : 0.041512, loss_ce: 0.022519
2021-12-16 15:42:11,423 iteration 3067 : loss : 0.044158, loss_ce: 0.021313
2021-12-16 15:42:12,885 iteration 3068 : loss : 0.049444, loss_ce: 0.018888
2021-12-16 15:42:14,343 iteration 3069 : loss : 0.040847, loss_ce: 0.014197
2021-12-16 15:42:15,806 iteration 3070 : loss : 0.048198, loss_ce: 0.022073
2021-12-16 15:42:17,212 iteration 3071 : loss : 0.033255, loss_ce: 0.014688
2021-12-16 15:42:18,621 iteration 3072 : loss : 0.040203, loss_ce: 0.016647
2021-12-16 15:42:20,063 iteration 3073 : loss : 0.034698, loss_ce: 0.015341
2021-12-16 15:42:21,608 iteration 3074 : loss : 0.052975, loss_ce: 0.021575
2021-12-16 15:42:23,092 iteration 3075 : loss : 0.061880, loss_ce: 0.027847
2021-12-16 15:42:24,611 iteration 3076 : loss : 0.053787, loss_ce: 0.027282
2021-12-16 15:42:26,010 iteration 3077 : loss : 0.042344, loss_ce: 0.017548
 45%|████████████▏              | 181/400 [1:22:31<1:40:39, 27.58s/it]2021-12-16 15:42:27,454 iteration 3078 : loss : 0.032663, loss_ce: 0.015104
2021-12-16 15:42:29,022 iteration 3079 : loss : 0.039954, loss_ce: 0.016737
2021-12-16 15:42:30,396 iteration 3080 : loss : 0.044550, loss_ce: 0.015251
2021-12-16 15:42:31,863 iteration 3081 : loss : 0.040128, loss_ce: 0.015265
2021-12-16 15:42:33,288 iteration 3082 : loss : 0.076031, loss_ce: 0.018787
2021-12-16 15:42:34,793 iteration 3083 : loss : 0.039156, loss_ce: 0.019561
2021-12-16 15:42:36,147 iteration 3084 : loss : 0.025643, loss_ce: 0.013118
2021-12-16 15:42:37,626 iteration 3085 : loss : 0.034795, loss_ce: 0.016371
2021-12-16 15:42:39,175 iteration 3086 : loss : 0.040946, loss_ce: 0.021891
2021-12-16 15:42:40,601 iteration 3087 : loss : 0.038040, loss_ce: 0.017604
2021-12-16 15:42:42,072 iteration 3088 : loss : 0.044901, loss_ce: 0.015892
2021-12-16 15:42:43,603 iteration 3089 : loss : 0.061948, loss_ce: 0.022617
2021-12-16 15:42:44,982 iteration 3090 : loss : 0.034541, loss_ce: 0.018055
2021-12-16 15:42:46,441 iteration 3091 : loss : 0.034757, loss_ce: 0.018499
2021-12-16 15:42:48,025 iteration 3092 : loss : 0.066131, loss_ce: 0.031502
2021-12-16 15:42:49,427 iteration 3093 : loss : 0.036703, loss_ce: 0.018188
2021-12-16 15:42:50,901 iteration 3094 : loss : 0.056963, loss_ce: 0.029494
 46%|████████████▎              | 182/400 [1:22:56<1:37:16, 26.77s/it]2021-12-16 15:42:52,404 iteration 3095 : loss : 0.037938, loss_ce: 0.016642
2021-12-16 15:42:53,885 iteration 3096 : loss : 0.038510, loss_ce: 0.020247
2021-12-16 15:42:55,319 iteration 3097 : loss : 0.035075, loss_ce: 0.013558
2021-12-16 15:42:56,716 iteration 3098 : loss : 0.035788, loss_ce: 0.017276
2021-12-16 15:42:58,174 iteration 3099 : loss : 0.035399, loss_ce: 0.013618
2021-12-16 15:42:59,585 iteration 3100 : loss : 0.048702, loss_ce: 0.018126
2021-12-16 15:43:01,094 iteration 3101 : loss : 0.035319, loss_ce: 0.014792
2021-12-16 15:43:02,560 iteration 3102 : loss : 0.046790, loss_ce: 0.022106
2021-12-16 15:43:04,016 iteration 3103 : loss : 0.052646, loss_ce: 0.022615
2021-12-16 15:43:05,429 iteration 3104 : loss : 0.034526, loss_ce: 0.017752
2021-12-16 15:43:06,823 iteration 3105 : loss : 0.031713, loss_ce: 0.016826
2021-12-16 15:43:08,270 iteration 3106 : loss : 0.040892, loss_ce: 0.021504
2021-12-16 15:43:09,716 iteration 3107 : loss : 0.036961, loss_ce: 0.014541
2021-12-16 15:43:11,193 iteration 3108 : loss : 0.051832, loss_ce: 0.020367
2021-12-16 15:43:12,669 iteration 3109 : loss : 0.042478, loss_ce: 0.016549
2021-12-16 15:43:14,143 iteration 3110 : loss : 0.054767, loss_ce: 0.026073
2021-12-16 15:43:15,610 iteration 3111 : loss : 0.040541, loss_ce: 0.017540
 46%|████████████▎              | 183/400 [1:23:21<1:34:34, 26.15s/it]2021-12-16 15:43:17,115 iteration 3112 : loss : 0.047834, loss_ce: 0.019581
2021-12-16 15:43:18,528 iteration 3113 : loss : 0.041387, loss_ce: 0.018490
2021-12-16 15:43:20,014 iteration 3114 : loss : 0.036641, loss_ce: 0.014600
2021-12-16 15:43:21,463 iteration 3115 : loss : 0.044873, loss_ce: 0.019552
2021-12-16 15:43:22,896 iteration 3116 : loss : 0.035300, loss_ce: 0.017582
2021-12-16 15:43:24,423 iteration 3117 : loss : 0.035108, loss_ce: 0.015756
2021-12-16 15:43:25,861 iteration 3118 : loss : 0.052360, loss_ce: 0.022631
2021-12-16 15:43:27,421 iteration 3119 : loss : 0.055780, loss_ce: 0.019061
2021-12-16 15:43:28,809 iteration 3120 : loss : 0.036683, loss_ce: 0.017207
2021-12-16 15:43:30,316 iteration 3121 : loss : 0.042850, loss_ce: 0.019529
2021-12-16 15:43:31,755 iteration 3122 : loss : 0.045508, loss_ce: 0.015046
2021-12-16 15:43:33,277 iteration 3123 : loss : 0.037178, loss_ce: 0.018730
2021-12-16 15:43:34,664 iteration 3124 : loss : 0.029648, loss_ce: 0.012097
2021-12-16 15:43:36,120 iteration 3125 : loss : 0.042284, loss_ce: 0.017197
2021-12-16 15:43:37,635 iteration 3126 : loss : 0.029073, loss_ce: 0.015725
2021-12-16 15:43:39,153 iteration 3127 : loss : 0.047634, loss_ce: 0.021249
2021-12-16 15:43:40,657 iteration 3128 : loss : 0.051720, loss_ce: 0.019176
 46%|████████████▍              | 184/400 [1:23:46<1:32:57, 25.82s/it]2021-12-16 15:43:42,109 iteration 3129 : loss : 0.040611, loss_ce: 0.017681
2021-12-16 15:43:43,653 iteration 3130 : loss : 0.037781, loss_ce: 0.017971
2021-12-16 15:43:45,089 iteration 3131 : loss : 0.052586, loss_ce: 0.020610
2021-12-16 15:43:46,557 iteration 3132 : loss : 0.034224, loss_ce: 0.012000
2021-12-16 15:43:48,026 iteration 3133 : loss : 0.049414, loss_ce: 0.021705
2021-12-16 15:43:49,449 iteration 3134 : loss : 0.028949, loss_ce: 0.015527
2021-12-16 15:43:50,898 iteration 3135 : loss : 0.033654, loss_ce: 0.017141
2021-12-16 15:43:52,347 iteration 3136 : loss : 0.039874, loss_ce: 0.020281
2021-12-16 15:43:53,910 iteration 3137 : loss : 0.044819, loss_ce: 0.022997
2021-12-16 15:43:55,404 iteration 3138 : loss : 0.052508, loss_ce: 0.024578
2021-12-16 15:43:56,783 iteration 3139 : loss : 0.033629, loss_ce: 0.013601
2021-12-16 15:43:58,193 iteration 3140 : loss : 0.043443, loss_ce: 0.021314
2021-12-16 15:43:59,671 iteration 3141 : loss : 0.063129, loss_ce: 0.031449
2021-12-16 15:44:01,106 iteration 3142 : loss : 0.040418, loss_ce: 0.014380
2021-12-16 15:44:02,608 iteration 3143 : loss : 0.044529, loss_ce: 0.018287
2021-12-16 15:44:04,042 iteration 3144 : loss : 0.032241, loss_ce: 0.014170
2021-12-16 15:44:04,043 Training Data Eval:
2021-12-16 15:44:11,551   Average segmentation loss on training set: 0.0203
2021-12-16 15:44:11,551 Validation Data Eval:
2021-12-16 15:44:14,146   Average segmentation loss on validation set: 0.1107
2021-12-16 15:44:15,567 iteration 3145 : loss : 0.028015, loss_ce: 0.013632
 46%|████████████▍              | 185/400 [1:24:21<1:42:17, 28.55s/it]2021-12-16 15:44:17,219 iteration 3146 : loss : 0.071196, loss_ce: 0.023763
2021-12-16 15:44:18,732 iteration 3147 : loss : 0.039358, loss_ce: 0.017780
2021-12-16 15:44:20,127 iteration 3148 : loss : 0.029655, loss_ce: 0.013176
2021-12-16 15:44:21,628 iteration 3149 : loss : 0.042626, loss_ce: 0.014915
2021-12-16 15:44:23,119 iteration 3150 : loss : 0.040908, loss_ce: 0.014460
2021-12-16 15:44:24,616 iteration 3151 : loss : 0.057607, loss_ce: 0.023430
2021-12-16 15:44:26,111 iteration 3152 : loss : 0.054868, loss_ce: 0.021100
2021-12-16 15:44:27,572 iteration 3153 : loss : 0.048264, loss_ce: 0.023962
2021-12-16 15:44:29,104 iteration 3154 : loss : 0.083192, loss_ce: 0.034252
2021-12-16 15:44:30,606 iteration 3155 : loss : 0.031990, loss_ce: 0.013340
2021-12-16 15:44:32,005 iteration 3156 : loss : 0.041355, loss_ce: 0.016568
2021-12-16 15:44:33,479 iteration 3157 : loss : 0.057068, loss_ce: 0.022810
2021-12-16 15:44:34,890 iteration 3158 : loss : 0.068448, loss_ce: 0.018059
2021-12-16 15:44:36,359 iteration 3159 : loss : 0.055495, loss_ce: 0.029630
2021-12-16 15:44:37,827 iteration 3160 : loss : 0.035380, loss_ce: 0.014580
2021-12-16 15:44:39,357 iteration 3161 : loss : 0.037179, loss_ce: 0.014955
2021-12-16 15:44:40,828 iteration 3162 : loss : 0.043253, loss_ce: 0.015182
 46%|████████████▌              | 186/400 [1:24:46<1:38:18, 27.56s/it]2021-12-16 15:44:42,284 iteration 3163 : loss : 0.039853, loss_ce: 0.015218
2021-12-16 15:44:43,847 iteration 3164 : loss : 0.055968, loss_ce: 0.026541
2021-12-16 15:44:45,351 iteration 3165 : loss : 0.059751, loss_ce: 0.022414
2021-12-16 15:44:46,772 iteration 3166 : loss : 0.038175, loss_ce: 0.016852
2021-12-16 15:44:48,276 iteration 3167 : loss : 0.041023, loss_ce: 0.016499
2021-12-16 15:44:49,724 iteration 3168 : loss : 0.040898, loss_ce: 0.018982
2021-12-16 15:44:51,198 iteration 3169 : loss : 0.042698, loss_ce: 0.022082
2021-12-16 15:44:52,667 iteration 3170 : loss : 0.034097, loss_ce: 0.016837
2021-12-16 15:44:54,012 iteration 3171 : loss : 0.037195, loss_ce: 0.013311
2021-12-16 15:44:55,424 iteration 3172 : loss : 0.036750, loss_ce: 0.015871
2021-12-16 15:44:56,875 iteration 3173 : loss : 0.058924, loss_ce: 0.021184
2021-12-16 15:44:58,298 iteration 3174 : loss : 0.043471, loss_ce: 0.019850
2021-12-16 15:44:59,693 iteration 3175 : loss : 0.041680, loss_ce: 0.017352
2021-12-16 15:45:01,234 iteration 3176 : loss : 0.059403, loss_ce: 0.017998
2021-12-16 15:45:02,712 iteration 3177 : loss : 0.047264, loss_ce: 0.017527
2021-12-16 15:45:04,253 iteration 3178 : loss : 0.053352, loss_ce: 0.019405
2021-12-16 15:45:05,693 iteration 3179 : loss : 0.055308, loss_ce: 0.026429
 47%|████████████▌              | 187/400 [1:25:11<1:34:58, 26.75s/it]2021-12-16 15:45:07,178 iteration 3180 : loss : 0.055843, loss_ce: 0.024966
2021-12-16 15:45:08,602 iteration 3181 : loss : 0.033449, loss_ce: 0.017497
2021-12-16 15:45:10,011 iteration 3182 : loss : 0.044424, loss_ce: 0.026815
2021-12-16 15:45:11,536 iteration 3183 : loss : 0.054752, loss_ce: 0.021379
2021-12-16 15:45:13,007 iteration 3184 : loss : 0.038675, loss_ce: 0.014614
2021-12-16 15:45:14,484 iteration 3185 : loss : 0.032470, loss_ce: 0.011501
2021-12-16 15:45:15,984 iteration 3186 : loss : 0.044497, loss_ce: 0.022717
2021-12-16 15:45:17,478 iteration 3187 : loss : 0.035987, loss_ce: 0.015736
2021-12-16 15:45:18,969 iteration 3188 : loss : 0.042218, loss_ce: 0.018196
2021-12-16 15:45:20,387 iteration 3189 : loss : 0.043175, loss_ce: 0.017385
2021-12-16 15:45:21,926 iteration 3190 : loss : 0.041033, loss_ce: 0.017385
2021-12-16 15:45:23,430 iteration 3191 : loss : 0.044419, loss_ce: 0.018346
2021-12-16 15:45:24,837 iteration 3192 : loss : 0.060875, loss_ce: 0.014246
2021-12-16 15:45:26,309 iteration 3193 : loss : 0.034568, loss_ce: 0.015688
2021-12-16 15:45:27,891 iteration 3194 : loss : 0.067548, loss_ce: 0.032399
2021-12-16 15:45:29,351 iteration 3195 : loss : 0.039340, loss_ce: 0.018793
2021-12-16 15:45:30,807 iteration 3196 : loss : 0.043579, loss_ce: 0.020972
 47%|████████████▋              | 188/400 [1:25:36<1:32:47, 26.26s/it]2021-12-16 15:45:32,281 iteration 3197 : loss : 0.025843, loss_ce: 0.011881
2021-12-16 15:45:33,764 iteration 3198 : loss : 0.057033, loss_ce: 0.026963
2021-12-16 15:45:35,242 iteration 3199 : loss : 0.061985, loss_ce: 0.017540
2021-12-16 15:45:36,753 iteration 3200 : loss : 0.049345, loss_ce: 0.016858
2021-12-16 15:45:38,247 iteration 3201 : loss : 0.049407, loss_ce: 0.019887
2021-12-16 15:45:39,742 iteration 3202 : loss : 0.057381, loss_ce: 0.020800
2021-12-16 15:45:41,131 iteration 3203 : loss : 0.033493, loss_ce: 0.018996
2021-12-16 15:45:42,513 iteration 3204 : loss : 0.038544, loss_ce: 0.016828
2021-12-16 15:45:43,899 iteration 3205 : loss : 0.048018, loss_ce: 0.016643
2021-12-16 15:45:45,250 iteration 3206 : loss : 0.036108, loss_ce: 0.013123
2021-12-16 15:45:46,754 iteration 3207 : loss : 0.071136, loss_ce: 0.029827
2021-12-16 15:45:48,216 iteration 3208 : loss : 0.041668, loss_ce: 0.017423
2021-12-16 15:45:49,641 iteration 3209 : loss : 0.048676, loss_ce: 0.017472
2021-12-16 15:45:51,112 iteration 3210 : loss : 0.038450, loss_ce: 0.019683
2021-12-16 15:45:52,508 iteration 3211 : loss : 0.036074, loss_ce: 0.014278
2021-12-16 15:45:54,024 iteration 3212 : loss : 0.069157, loss_ce: 0.038512
2021-12-16 15:45:55,564 iteration 3213 : loss : 0.046840, loss_ce: 0.017853
 47%|████████████▊              | 189/400 [1:26:01<1:30:45, 25.81s/it]2021-12-16 15:45:57,012 iteration 3214 : loss : 0.033235, loss_ce: 0.016749
2021-12-16 15:45:58,474 iteration 3215 : loss : 0.031501, loss_ce: 0.015422
2021-12-16 15:45:59,913 iteration 3216 : loss : 0.050945, loss_ce: 0.016556
2021-12-16 15:46:01,376 iteration 3217 : loss : 0.041858, loss_ce: 0.020531
2021-12-16 15:46:02,834 iteration 3218 : loss : 0.049694, loss_ce: 0.019296
2021-12-16 15:46:04,273 iteration 3219 : loss : 0.048383, loss_ce: 0.019386
2021-12-16 15:46:05,689 iteration 3220 : loss : 0.031493, loss_ce: 0.014243
2021-12-16 15:46:07,247 iteration 3221 : loss : 0.048805, loss_ce: 0.024284
2021-12-16 15:46:08,676 iteration 3222 : loss : 0.030992, loss_ce: 0.010337
2021-12-16 15:46:10,142 iteration 3223 : loss : 0.029436, loss_ce: 0.012570
2021-12-16 15:46:11,685 iteration 3224 : loss : 0.073332, loss_ce: 0.023613
2021-12-16 15:46:13,151 iteration 3225 : loss : 0.060006, loss_ce: 0.026202
2021-12-16 15:46:14,611 iteration 3226 : loss : 0.048343, loss_ce: 0.022034
2021-12-16 15:46:16,071 iteration 3227 : loss : 0.053955, loss_ce: 0.024243
2021-12-16 15:46:17,495 iteration 3228 : loss : 0.050010, loss_ce: 0.017634
2021-12-16 15:46:18,896 iteration 3229 : loss : 0.049600, loss_ce: 0.015491
2021-12-16 15:46:18,897 Training Data Eval:
2021-12-16 15:46:26,396   Average segmentation loss on training set: 0.0208
2021-12-16 15:46:26,397 Validation Data Eval:
2021-12-16 15:46:28,989   Average segmentation loss on validation set: 0.1062
2021-12-16 15:46:30,388 iteration 3230 : loss : 0.034081, loss_ce: 0.013828
 48%|████████████▊              | 190/400 [1:26:36<1:39:47, 28.51s/it]2021-12-16 15:46:31,855 iteration 3231 : loss : 0.057726, loss_ce: 0.016292
2021-12-16 15:46:33,302 iteration 3232 : loss : 0.038557, loss_ce: 0.015652
2021-12-16 15:46:34,767 iteration 3233 : loss : 0.037571, loss_ce: 0.019417
2021-12-16 15:46:36,245 iteration 3234 : loss : 0.031277, loss_ce: 0.010862
2021-12-16 15:46:37,704 iteration 3235 : loss : 0.072848, loss_ce: 0.025876
2021-12-16 15:46:39,103 iteration 3236 : loss : 0.032200, loss_ce: 0.017807
2021-12-16 15:46:40,644 iteration 3237 : loss : 0.063138, loss_ce: 0.030248
2021-12-16 15:46:42,097 iteration 3238 : loss : 0.031959, loss_ce: 0.018072
2021-12-16 15:46:43,545 iteration 3239 : loss : 0.042553, loss_ce: 0.018080
2021-12-16 15:46:44,941 iteration 3240 : loss : 0.039742, loss_ce: 0.012320
2021-12-16 15:46:46,332 iteration 3241 : loss : 0.044024, loss_ce: 0.012263
2021-12-16 15:46:47,815 iteration 3242 : loss : 0.055195, loss_ce: 0.025291
2021-12-16 15:46:49,217 iteration 3243 : loss : 0.051013, loss_ce: 0.019257
2021-12-16 15:46:50,699 iteration 3244 : loss : 0.058314, loss_ce: 0.024784
2021-12-16 15:46:52,114 iteration 3245 : loss : 0.024426, loss_ce: 0.012747
2021-12-16 15:46:53,620 iteration 3246 : loss : 0.052087, loss_ce: 0.027334
2021-12-16 15:46:55,028 iteration 3247 : loss : 0.036834, loss_ce: 0.016702
 48%|████████████▉              | 191/400 [1:27:00<1:35:16, 27.35s/it]2021-12-16 15:46:56,462 iteration 3248 : loss : 0.032505, loss_ce: 0.013340
2021-12-16 15:46:57,870 iteration 3249 : loss : 0.023818, loss_ce: 0.010865
2021-12-16 15:46:59,318 iteration 3250 : loss : 0.047689, loss_ce: 0.017914
2021-12-16 15:47:00,763 iteration 3251 : loss : 0.039703, loss_ce: 0.017541
2021-12-16 15:47:02,216 iteration 3252 : loss : 0.039147, loss_ce: 0.016243
2021-12-16 15:47:03,651 iteration 3253 : loss : 0.037024, loss_ce: 0.018758
2021-12-16 15:47:05,103 iteration 3254 : loss : 0.035207, loss_ce: 0.014636
2021-12-16 15:47:06,475 iteration 3255 : loss : 0.050941, loss_ce: 0.023885
2021-12-16 15:47:07,910 iteration 3256 : loss : 0.024414, loss_ce: 0.010290
2021-12-16 15:47:09,311 iteration 3257 : loss : 0.028892, loss_ce: 0.014138
2021-12-16 15:47:10,768 iteration 3258 : loss : 0.042851, loss_ce: 0.019540
2021-12-16 15:47:12,157 iteration 3259 : loss : 0.037784, loss_ce: 0.017740
2021-12-16 15:47:13,629 iteration 3260 : loss : 0.033964, loss_ce: 0.015816
2021-12-16 15:47:15,062 iteration 3261 : loss : 0.050017, loss_ce: 0.015375
2021-12-16 15:47:16,564 iteration 3262 : loss : 0.058083, loss_ce: 0.022345
2021-12-16 15:47:18,120 iteration 3263 : loss : 0.066697, loss_ce: 0.020500
2021-12-16 15:47:19,568 iteration 3264 : loss : 0.043493, loss_ce: 0.021621
 48%|████████████▉              | 192/400 [1:27:25<1:31:54, 26.51s/it]2021-12-16 15:47:20,990 iteration 3265 : loss : 0.029236, loss_ce: 0.013634
2021-12-16 15:47:22,486 iteration 3266 : loss : 0.059625, loss_ce: 0.027662
2021-12-16 15:47:23,949 iteration 3267 : loss : 0.061039, loss_ce: 0.024460
2021-12-16 15:47:25,339 iteration 3268 : loss : 0.026737, loss_ce: 0.011786
2021-12-16 15:47:26,830 iteration 3269 : loss : 0.049183, loss_ce: 0.021789
2021-12-16 15:47:28,358 iteration 3270 : loss : 0.065783, loss_ce: 0.026585
2021-12-16 15:47:29,848 iteration 3271 : loss : 0.066478, loss_ce: 0.023610
2021-12-16 15:47:31,349 iteration 3272 : loss : 0.044385, loss_ce: 0.019481
2021-12-16 15:47:32,755 iteration 3273 : loss : 0.041436, loss_ce: 0.015456
2021-12-16 15:47:34,190 iteration 3274 : loss : 0.034298, loss_ce: 0.019664
2021-12-16 15:47:35,693 iteration 3275 : loss : 0.042575, loss_ce: 0.012713
2021-12-16 15:47:37,108 iteration 3276 : loss : 0.046720, loss_ce: 0.020443
2021-12-16 15:47:38,581 iteration 3277 : loss : 0.040553, loss_ce: 0.023272
2021-12-16 15:47:40,041 iteration 3278 : loss : 0.050421, loss_ce: 0.021112
2021-12-16 15:47:41,455 iteration 3279 : loss : 0.036405, loss_ce: 0.015030
2021-12-16 15:47:42,881 iteration 3280 : loss : 0.034230, loss_ce: 0.013328
2021-12-16 15:47:44,303 iteration 3281 : loss : 0.034784, loss_ce: 0.013251
 48%|█████████████              | 193/400 [1:27:50<1:29:36, 25.98s/it]2021-12-16 15:47:45,820 iteration 3282 : loss : 0.060076, loss_ce: 0.029545
2021-12-16 15:47:47,251 iteration 3283 : loss : 0.027395, loss_ce: 0.010745
2021-12-16 15:47:48,676 iteration 3284 : loss : 0.037441, loss_ce: 0.017496
2021-12-16 15:47:50,094 iteration 3285 : loss : 0.054033, loss_ce: 0.024310
2021-12-16 15:47:51,546 iteration 3286 : loss : 0.025890, loss_ce: 0.011628
2021-12-16 15:47:53,001 iteration 3287 : loss : 0.040316, loss_ce: 0.018287
2021-12-16 15:47:54,402 iteration 3288 : loss : 0.047325, loss_ce: 0.028002
2021-12-16 15:47:55,813 iteration 3289 : loss : 0.042726, loss_ce: 0.016094
2021-12-16 15:47:57,312 iteration 3290 : loss : 0.054499, loss_ce: 0.017211
2021-12-16 15:47:58,837 iteration 3291 : loss : 0.063985, loss_ce: 0.024343
2021-12-16 15:48:00,312 iteration 3292 : loss : 0.036203, loss_ce: 0.012130
2021-12-16 15:48:01,746 iteration 3293 : loss : 0.039756, loss_ce: 0.020470
2021-12-16 15:48:03,157 iteration 3294 : loss : 0.030403, loss_ce: 0.015256
2021-12-16 15:48:04,685 iteration 3295 : loss : 0.060782, loss_ce: 0.026619
2021-12-16 15:48:06,141 iteration 3296 : loss : 0.082241, loss_ce: 0.027614
2021-12-16 15:48:07,544 iteration 3297 : loss : 0.026777, loss_ce: 0.013402
2021-12-16 15:48:09,019 iteration 3298 : loss : 0.052974, loss_ce: 0.024118
 48%|█████████████              | 194/400 [1:28:14<1:27:53, 25.60s/it]2021-12-16 15:48:10,442 iteration 3299 : loss : 0.033080, loss_ce: 0.016088
2021-12-16 15:48:11,863 iteration 3300 : loss : 0.053491, loss_ce: 0.021959
2021-12-16 15:48:13,362 iteration 3301 : loss : 0.046436, loss_ce: 0.024869
2021-12-16 15:48:14,853 iteration 3302 : loss : 0.059761, loss_ce: 0.027512
2021-12-16 15:48:16,274 iteration 3303 : loss : 0.028752, loss_ce: 0.013781
2021-12-16 15:48:17,726 iteration 3304 : loss : 0.036945, loss_ce: 0.016496
2021-12-16 15:48:19,192 iteration 3305 : loss : 0.034906, loss_ce: 0.015267
2021-12-16 15:48:20,689 iteration 3306 : loss : 0.044259, loss_ce: 0.018070
2021-12-16 15:48:22,131 iteration 3307 : loss : 0.044733, loss_ce: 0.017530
2021-12-16 15:48:23,579 iteration 3308 : loss : 0.040359, loss_ce: 0.018907
2021-12-16 15:48:25,025 iteration 3309 : loss : 0.062824, loss_ce: 0.021614
2021-12-16 15:48:26,533 iteration 3310 : loss : 0.074767, loss_ce: 0.025910
2021-12-16 15:48:28,056 iteration 3311 : loss : 0.044033, loss_ce: 0.017647
2021-12-16 15:48:29,443 iteration 3312 : loss : 0.034670, loss_ce: 0.014282
2021-12-16 15:48:30,851 iteration 3313 : loss : 0.030269, loss_ce: 0.012897
2021-12-16 15:48:32,373 iteration 3314 : loss : 0.041611, loss_ce: 0.017996
2021-12-16 15:48:32,374 Training Data Eval:
2021-12-16 15:48:39,850   Average segmentation loss on training set: 0.0222
2021-12-16 15:48:39,851 Validation Data Eval:
2021-12-16 15:48:42,451   Average segmentation loss on validation set: 0.1086
2021-12-16 15:48:43,861 iteration 3315 : loss : 0.030489, loss_ce: 0.015057
 49%|█████████████▏             | 195/400 [1:28:49<1:36:56, 28.37s/it]2021-12-16 15:48:45,317 iteration 3316 : loss : 0.023956, loss_ce: 0.011072
2021-12-16 15:48:46,742 iteration 3317 : loss : 0.041334, loss_ce: 0.017719
2021-12-16 15:48:48,293 iteration 3318 : loss : 0.047635, loss_ce: 0.023048
2021-12-16 15:48:49,699 iteration 3319 : loss : 0.036977, loss_ce: 0.015190
2021-12-16 15:48:51,138 iteration 3320 : loss : 0.029438, loss_ce: 0.014301
2021-12-16 15:48:52,626 iteration 3321 : loss : 0.033933, loss_ce: 0.011622
2021-12-16 15:48:54,064 iteration 3322 : loss : 0.051027, loss_ce: 0.024377
2021-12-16 15:48:55,443 iteration 3323 : loss : 0.030649, loss_ce: 0.011697
2021-12-16 15:48:56,961 iteration 3324 : loss : 0.053524, loss_ce: 0.024498
2021-12-16 15:48:58,369 iteration 3325 : loss : 0.033579, loss_ce: 0.012839
2021-12-16 15:48:59,895 iteration 3326 : loss : 0.044080, loss_ce: 0.020250
2021-12-16 15:49:01,441 iteration 3327 : loss : 0.057971, loss_ce: 0.021923
2021-12-16 15:49:02,882 iteration 3328 : loss : 0.041429, loss_ce: 0.018631
2021-12-16 15:49:04,285 iteration 3329 : loss : 0.047820, loss_ce: 0.027062
2021-12-16 15:49:05,708 iteration 3330 : loss : 0.062443, loss_ce: 0.024373
2021-12-16 15:49:07,174 iteration 3331 : loss : 0.053588, loss_ce: 0.024627
2021-12-16 15:49:08,540 iteration 3332 : loss : 0.024901, loss_ce: 0.013264
 49%|█████████████▏             | 196/400 [1:29:14<1:32:42, 27.27s/it]2021-12-16 15:49:10,010 iteration 3333 : loss : 0.031912, loss_ce: 0.015480
2021-12-16 15:49:11,464 iteration 3334 : loss : 0.027697, loss_ce: 0.013751
2021-12-16 15:49:12,828 iteration 3335 : loss : 0.024808, loss_ce: 0.012100
2021-12-16 15:49:14,282 iteration 3336 : loss : 0.049576, loss_ce: 0.019859
2021-12-16 15:49:15,790 iteration 3337 : loss : 0.040925, loss_ce: 0.018496
2021-12-16 15:49:17,341 iteration 3338 : loss : 0.057540, loss_ce: 0.033507
2021-12-16 15:49:18,777 iteration 3339 : loss : 0.069328, loss_ce: 0.024659
2021-12-16 15:49:20,196 iteration 3340 : loss : 0.029185, loss_ce: 0.011489
2021-12-16 15:49:21,644 iteration 3341 : loss : 0.033294, loss_ce: 0.015411
2021-12-16 15:49:23,136 iteration 3342 : loss : 0.041313, loss_ce: 0.021783
2021-12-16 15:49:24,595 iteration 3343 : loss : 0.043836, loss_ce: 0.016860
2021-12-16 15:49:26,046 iteration 3344 : loss : 0.047433, loss_ce: 0.020602
2021-12-16 15:49:27,465 iteration 3345 : loss : 0.042279, loss_ce: 0.016536
2021-12-16 15:49:28,922 iteration 3346 : loss : 0.061674, loss_ce: 0.033855
2021-12-16 15:49:30,408 iteration 3347 : loss : 0.050949, loss_ce: 0.016545
2021-12-16 15:49:31,946 iteration 3348 : loss : 0.040219, loss_ce: 0.015944
2021-12-16 15:49:33,406 iteration 3349 : loss : 0.040033, loss_ce: 0.016107
 49%|█████████████▎             | 197/400 [1:29:39<1:29:48, 26.54s/it]2021-12-16 15:49:34,854 iteration 3350 : loss : 0.039163, loss_ce: 0.018189
2021-12-16 15:49:36,256 iteration 3351 : loss : 0.034375, loss_ce: 0.016006
2021-12-16 15:49:37,662 iteration 3352 : loss : 0.036554, loss_ce: 0.015971
2021-12-16 15:49:39,108 iteration 3353 : loss : 0.056160, loss_ce: 0.025687
2021-12-16 15:49:40,557 iteration 3354 : loss : 0.036193, loss_ce: 0.014306
2021-12-16 15:49:42,061 iteration 3355 : loss : 0.042309, loss_ce: 0.025429
2021-12-16 15:49:43,539 iteration 3356 : loss : 0.048265, loss_ce: 0.015826
2021-12-16 15:49:45,031 iteration 3357 : loss : 0.030190, loss_ce: 0.012424
2021-12-16 15:49:46,541 iteration 3358 : loss : 0.043975, loss_ce: 0.017991
2021-12-16 15:49:48,024 iteration 3359 : loss : 0.042263, loss_ce: 0.018654
2021-12-16 15:49:49,564 iteration 3360 : loss : 0.045612, loss_ce: 0.021671
2021-12-16 15:49:50,949 iteration 3361 : loss : 0.031734, loss_ce: 0.011326
2021-12-16 15:49:52,362 iteration 3362 : loss : 0.043563, loss_ce: 0.018650
2021-12-16 15:49:53,774 iteration 3363 : loss : 0.030675, loss_ce: 0.015152
2021-12-16 15:49:55,252 iteration 3364 : loss : 0.038977, loss_ce: 0.015498
2021-12-16 15:49:56,654 iteration 3365 : loss : 0.031881, loss_ce: 0.018127
2021-12-16 15:49:58,077 iteration 3366 : loss : 0.033882, loss_ce: 0.014501
 50%|█████████████▎             | 198/400 [1:30:03<1:27:28, 25.98s/it]2021-12-16 15:49:59,550 iteration 3367 : loss : 0.050603, loss_ce: 0.020170
2021-12-16 15:50:00,984 iteration 3368 : loss : 0.053677, loss_ce: 0.029172
2021-12-16 15:50:02,453 iteration 3369 : loss : 0.040245, loss_ce: 0.016543
2021-12-16 15:50:03,931 iteration 3370 : loss : 0.045802, loss_ce: 0.021915
2021-12-16 15:50:05,305 iteration 3371 : loss : 0.020264, loss_ce: 0.009741
2021-12-16 15:50:06,737 iteration 3372 : loss : 0.034112, loss_ce: 0.019239
2021-12-16 15:50:08,171 iteration 3373 : loss : 0.031387, loss_ce: 0.017083
2021-12-16 15:50:09,571 iteration 3374 : loss : 0.025437, loss_ce: 0.012453
2021-12-16 15:50:10,972 iteration 3375 : loss : 0.040284, loss_ce: 0.017763
2021-12-16 15:50:12,389 iteration 3376 : loss : 0.060070, loss_ce: 0.023771
2021-12-16 15:50:13,866 iteration 3377 : loss : 0.051349, loss_ce: 0.019034
2021-12-16 15:50:15,296 iteration 3378 : loss : 0.041112, loss_ce: 0.017022
2021-12-16 15:50:16,651 iteration 3379 : loss : 0.027024, loss_ce: 0.013912
2021-12-16 15:50:18,185 iteration 3380 : loss : 0.046276, loss_ce: 0.019679
2021-12-16 15:50:19,570 iteration 3381 : loss : 0.119284, loss_ce: 0.023695
2021-12-16 15:50:21,012 iteration 3382 : loss : 0.056316, loss_ce: 0.023809
2021-12-16 15:50:22,432 iteration 3383 : loss : 0.039666, loss_ce: 0.016681
 50%|█████████████▍             | 199/400 [1:30:28<1:25:24, 25.49s/it]2021-12-16 15:50:23,861 iteration 3384 : loss : 0.041505, loss_ce: 0.014973
2021-12-16 15:50:25,345 iteration 3385 : loss : 0.041975, loss_ce: 0.020621
2021-12-16 15:50:26,831 iteration 3386 : loss : 0.059513, loss_ce: 0.029701
2021-12-16 15:50:28,291 iteration 3387 : loss : 0.044026, loss_ce: 0.018292
2021-12-16 15:50:29,672 iteration 3388 : loss : 0.032979, loss_ce: 0.015782
2021-12-16 15:50:31,141 iteration 3389 : loss : 0.052307, loss_ce: 0.023721
2021-12-16 15:50:32,522 iteration 3390 : loss : 0.042726, loss_ce: 0.014949
2021-12-16 15:50:34,078 iteration 3391 : loss : 0.053124, loss_ce: 0.017839
2021-12-16 15:50:35,576 iteration 3392 : loss : 0.042940, loss_ce: 0.017311
2021-12-16 15:50:37,059 iteration 3393 : loss : 0.051957, loss_ce: 0.022344
2021-12-16 15:50:38,422 iteration 3394 : loss : 0.031444, loss_ce: 0.013733
2021-12-16 15:50:39,975 iteration 3395 : loss : 0.058364, loss_ce: 0.023639
2021-12-16 15:50:41,423 iteration 3396 : loss : 0.052131, loss_ce: 0.019683
2021-12-16 15:50:42,832 iteration 3397 : loss : 0.038233, loss_ce: 0.018331
2021-12-16 15:50:44,311 iteration 3398 : loss : 0.035524, loss_ce: 0.013386
2021-12-16 15:50:45,763 iteration 3399 : loss : 0.037653, loss_ce: 0.016840
2021-12-16 15:50:45,763 Training Data Eval:
2021-12-16 15:50:53,255   Average segmentation loss on training set: 0.0212
2021-12-16 15:50:53,255 Validation Data Eval:
2021-12-16 15:50:55,849   Average segmentation loss on validation set: 0.1153
2021-12-16 15:50:57,315 iteration 3400 : loss : 0.036648, loss_ce: 0.011941
 50%|█████████████▌             | 200/400 [1:31:03<1:34:22, 28.31s/it]2021-12-16 15:50:58,931 iteration 3401 : loss : 0.047664, loss_ce: 0.022599
2021-12-16 15:51:00,423 iteration 3402 : loss : 0.050651, loss_ce: 0.021161
2021-12-16 15:51:01,826 iteration 3403 : loss : 0.035954, loss_ce: 0.018500
2021-12-16 15:51:03,246 iteration 3404 : loss : 0.032258, loss_ce: 0.015530
2021-12-16 15:51:04,676 iteration 3405 : loss : 0.042619, loss_ce: 0.019326
2021-12-16 15:51:06,181 iteration 3406 : loss : 0.049052, loss_ce: 0.019762
2021-12-16 15:51:07,629 iteration 3407 : loss : 0.047433, loss_ce: 0.021294
2021-12-16 15:51:09,089 iteration 3408 : loss : 0.037671, loss_ce: 0.016698
2021-12-16 15:51:10,572 iteration 3409 : loss : 0.039419, loss_ce: 0.018738
2021-12-16 15:51:12,030 iteration 3410 : loss : 0.049947, loss_ce: 0.018966
2021-12-16 15:51:13,531 iteration 3411 : loss : 0.052978, loss_ce: 0.022954
2021-12-16 15:51:14,922 iteration 3412 : loss : 0.036746, loss_ce: 0.015175
2021-12-16 15:51:16,304 iteration 3413 : loss : 0.030556, loss_ce: 0.015054
2021-12-16 15:51:17,791 iteration 3414 : loss : 0.051125, loss_ce: 0.016560
2021-12-16 15:51:19,292 iteration 3415 : loss : 0.040466, loss_ce: 0.016749
2021-12-16 15:51:20,800 iteration 3416 : loss : 0.035721, loss_ce: 0.014393
2021-12-16 15:51:22,331 iteration 3417 : loss : 0.059347, loss_ce: 0.025405
 50%|█████████████▌             | 201/400 [1:31:28<1:30:36, 27.32s/it]2021-12-16 15:51:23,814 iteration 3418 : loss : 0.038816, loss_ce: 0.019357
2021-12-16 15:51:25,302 iteration 3419 : loss : 0.047984, loss_ce: 0.017678
2021-12-16 15:51:26,831 iteration 3420 : loss : 0.067243, loss_ce: 0.025246
2021-12-16 15:51:28,277 iteration 3421 : loss : 0.057906, loss_ce: 0.021159
2021-12-16 15:51:29,642 iteration 3422 : loss : 0.032178, loss_ce: 0.012756
2021-12-16 15:51:31,089 iteration 3423 : loss : 0.032623, loss_ce: 0.015408
2021-12-16 15:51:32,533 iteration 3424 : loss : 0.045990, loss_ce: 0.020645
2021-12-16 15:51:33,936 iteration 3425 : loss : 0.044834, loss_ce: 0.023112
2021-12-16 15:51:35,390 iteration 3426 : loss : 0.041364, loss_ce: 0.016131
2021-12-16 15:51:36,855 iteration 3427 : loss : 0.042264, loss_ce: 0.015169
2021-12-16 15:51:38,329 iteration 3428 : loss : 0.054064, loss_ce: 0.022585
2021-12-16 15:51:39,829 iteration 3429 : loss : 0.040017, loss_ce: 0.016015
2021-12-16 15:51:41,324 iteration 3430 : loss : 0.049277, loss_ce: 0.023021
2021-12-16 15:51:42,689 iteration 3431 : loss : 0.028665, loss_ce: 0.014054
2021-12-16 15:51:44,108 iteration 3432 : loss : 0.043511, loss_ce: 0.017320
2021-12-16 15:51:45,528 iteration 3433 : loss : 0.040062, loss_ce: 0.017422
2021-12-16 15:51:47,035 iteration 3434 : loss : 0.053607, loss_ce: 0.018178
 50%|█████████████▋             | 202/400 [1:31:52<1:27:34, 26.54s/it]2021-12-16 15:51:48,455 iteration 3435 : loss : 0.027877, loss_ce: 0.011149
2021-12-16 15:51:49,894 iteration 3436 : loss : 0.029389, loss_ce: 0.012976
2021-12-16 15:51:51,465 iteration 3437 : loss : 0.058158, loss_ce: 0.031627
2021-12-16 15:51:52,980 iteration 3438 : loss : 0.032582, loss_ce: 0.016004
2021-12-16 15:51:54,467 iteration 3439 : loss : 0.048264, loss_ce: 0.018426
2021-12-16 15:51:55,866 iteration 3440 : loss : 0.026716, loss_ce: 0.011752
2021-12-16 15:51:57,308 iteration 3441 : loss : 0.041378, loss_ce: 0.017136
2021-12-16 15:51:58,868 iteration 3442 : loss : 0.059730, loss_ce: 0.023264
2021-12-16 15:52:00,348 iteration 3443 : loss : 0.047772, loss_ce: 0.017129
2021-12-16 15:52:01,825 iteration 3444 : loss : 0.049380, loss_ce: 0.020023
2021-12-16 15:52:03,274 iteration 3445 : loss : 0.068591, loss_ce: 0.022502
2021-12-16 15:52:04,703 iteration 3446 : loss : 0.046859, loss_ce: 0.025094
2021-12-16 15:52:06,129 iteration 3447 : loss : 0.038759, loss_ce: 0.015046
2021-12-16 15:52:07,637 iteration 3448 : loss : 0.047229, loss_ce: 0.016104
2021-12-16 15:52:09,139 iteration 3449 : loss : 0.050335, loss_ce: 0.023247
2021-12-16 15:52:10,611 iteration 3450 : loss : 0.051189, loss_ce: 0.024543
2021-12-16 15:52:12,144 iteration 3451 : loss : 0.044827, loss_ce: 0.019083
 51%|█████████████▋             | 203/400 [1:32:17<1:25:43, 26.11s/it]2021-12-16 15:52:13,607 iteration 3452 : loss : 0.029410, loss_ce: 0.013520
2021-12-16 15:52:15,020 iteration 3453 : loss : 0.044342, loss_ce: 0.020751
2021-12-16 15:52:16,433 iteration 3454 : loss : 0.028611, loss_ce: 0.012458
2021-12-16 15:52:17,976 iteration 3455 : loss : 0.041706, loss_ce: 0.020600
2021-12-16 15:52:19,396 iteration 3456 : loss : 0.026388, loss_ce: 0.010004
2021-12-16 15:52:20,949 iteration 3457 : loss : 0.040347, loss_ce: 0.016539
2021-12-16 15:52:22,437 iteration 3458 : loss : 0.059855, loss_ce: 0.023776
2021-12-16 15:52:23,881 iteration 3459 : loss : 0.041281, loss_ce: 0.018616
2021-12-16 15:52:25,322 iteration 3460 : loss : 0.041243, loss_ce: 0.019453
2021-12-16 15:52:26,778 iteration 3461 : loss : 0.042090, loss_ce: 0.018808
2021-12-16 15:52:28,215 iteration 3462 : loss : 0.036338, loss_ce: 0.017680
2021-12-16 15:52:29,706 iteration 3463 : loss : 0.042202, loss_ce: 0.018598
2021-12-16 15:52:31,092 iteration 3464 : loss : 0.026880, loss_ce: 0.011550
2021-12-16 15:52:32,572 iteration 3465 : loss : 0.066764, loss_ce: 0.023936
2021-12-16 15:52:34,018 iteration 3466 : loss : 0.027312, loss_ce: 0.010730
2021-12-16 15:52:35,462 iteration 3467 : loss : 0.043299, loss_ce: 0.024917
2021-12-16 15:52:36,906 iteration 3468 : loss : 0.051632, loss_ce: 0.024233
 51%|█████████████▊             | 204/400 [1:32:42<1:23:57, 25.70s/it]2021-12-16 15:52:38,361 iteration 3469 : loss : 0.036689, loss_ce: 0.012209
2021-12-16 15:52:39,862 iteration 3470 : loss : 0.062325, loss_ce: 0.022030
2021-12-16 15:52:41,224 iteration 3471 : loss : 0.035733, loss_ce: 0.016101
2021-12-16 15:52:42,687 iteration 3472 : loss : 0.051807, loss_ce: 0.027021
2021-12-16 15:52:44,250 iteration 3473 : loss : 0.040377, loss_ce: 0.017138
2021-12-16 15:52:45,692 iteration 3474 : loss : 0.045483, loss_ce: 0.014341
2021-12-16 15:52:47,204 iteration 3475 : loss : 0.082898, loss_ce: 0.024702
2021-12-16 15:52:48,612 iteration 3476 : loss : 0.041627, loss_ce: 0.014791
2021-12-16 15:52:50,099 iteration 3477 : loss : 0.049888, loss_ce: 0.017495
2021-12-16 15:52:51,558 iteration 3478 : loss : 0.031397, loss_ce: 0.013026
2021-12-16 15:52:52,977 iteration 3479 : loss : 0.032967, loss_ce: 0.014938
2021-12-16 15:52:54,353 iteration 3480 : loss : 0.036634, loss_ce: 0.017981
2021-12-16 15:52:55,802 iteration 3481 : loss : 0.054293, loss_ce: 0.023849
2021-12-16 15:52:57,254 iteration 3482 : loss : 0.073889, loss_ce: 0.034422
2021-12-16 15:52:58,749 iteration 3483 : loss : 0.046149, loss_ce: 0.019820
2021-12-16 15:53:00,107 iteration 3484 : loss : 0.034725, loss_ce: 0.015925
2021-12-16 15:53:00,107 Training Data Eval:
2021-12-16 15:53:07,610   Average segmentation loss on training set: 0.0196
2021-12-16 15:53:07,610 Validation Data Eval:
2021-12-16 15:53:10,213   Average segmentation loss on validation set: 0.1054
2021-12-16 15:53:11,778 iteration 3485 : loss : 0.060520, loss_ce: 0.030064
 51%|█████████████▊             | 205/400 [1:33:17<1:32:28, 28.46s/it]2021-12-16 15:53:13,277 iteration 3486 : loss : 0.037051, loss_ce: 0.017459
2021-12-16 15:53:14,675 iteration 3487 : loss : 0.030484, loss_ce: 0.014609
2021-12-16 15:53:16,113 iteration 3488 : loss : 0.035087, loss_ce: 0.013835
2021-12-16 15:53:17,559 iteration 3489 : loss : 0.047119, loss_ce: 0.021539
2021-12-16 15:53:19,040 iteration 3490 : loss : 0.043498, loss_ce: 0.018442
2021-12-16 15:53:20,543 iteration 3491 : loss : 0.045137, loss_ce: 0.018751
2021-12-16 15:53:21,940 iteration 3492 : loss : 0.049381, loss_ce: 0.018864
2021-12-16 15:53:23,490 iteration 3493 : loss : 0.051955, loss_ce: 0.023186
2021-12-16 15:53:24,956 iteration 3494 : loss : 0.040220, loss_ce: 0.013885
2021-12-16 15:53:26,384 iteration 3495 : loss : 0.038678, loss_ce: 0.014240
2021-12-16 15:53:27,863 iteration 3496 : loss : 0.049512, loss_ce: 0.027893
2021-12-16 15:53:29,328 iteration 3497 : loss : 0.046873, loss_ce: 0.019072
2021-12-16 15:53:30,886 iteration 3498 : loss : 0.041643, loss_ce: 0.019513
2021-12-16 15:53:32,301 iteration 3499 : loss : 0.035784, loss_ce: 0.015934
2021-12-16 15:53:33,673 iteration 3500 : loss : 0.024343, loss_ce: 0.009732
2021-12-16 15:53:35,088 iteration 3501 : loss : 0.041212, loss_ce: 0.019889
2021-12-16 15:53:36,576 iteration 3502 : loss : 0.043058, loss_ce: 0.016773
 52%|█████████████▉             | 206/400 [1:33:42<1:28:27, 27.36s/it]2021-12-16 15:53:38,081 iteration 3503 : loss : 0.043841, loss_ce: 0.018787
2021-12-16 15:53:39,495 iteration 3504 : loss : 0.029773, loss_ce: 0.011123
2021-12-16 15:53:40,834 iteration 3505 : loss : 0.029340, loss_ce: 0.015262
2021-12-16 15:53:42,313 iteration 3506 : loss : 0.049844, loss_ce: 0.017331
2021-12-16 15:53:43,757 iteration 3507 : loss : 0.051124, loss_ce: 0.017632
2021-12-16 15:53:45,335 iteration 3508 : loss : 0.052122, loss_ce: 0.024751
2021-12-16 15:53:46,810 iteration 3509 : loss : 0.041394, loss_ce: 0.016354
2021-12-16 15:53:48,211 iteration 3510 : loss : 0.036377, loss_ce: 0.017690
2021-12-16 15:53:49,605 iteration 3511 : loss : 0.026311, loss_ce: 0.013782
2021-12-16 15:53:51,124 iteration 3512 : loss : 0.044990, loss_ce: 0.014357
2021-12-16 15:53:52,580 iteration 3513 : loss : 0.048068, loss_ce: 0.018181
2021-12-16 15:53:54,153 iteration 3514 : loss : 0.067909, loss_ce: 0.037338
2021-12-16 15:53:55,580 iteration 3515 : loss : 0.040733, loss_ce: 0.015087
2021-12-16 15:53:57,008 iteration 3516 : loss : 0.041591, loss_ce: 0.018724
2021-12-16 15:53:58,432 iteration 3517 : loss : 0.053466, loss_ce: 0.024507
2021-12-16 15:53:59,886 iteration 3518 : loss : 0.039147, loss_ce: 0.020244
2021-12-16 15:54:01,362 iteration 3519 : loss : 0.031887, loss_ce: 0.013768
 52%|█████████████▉             | 207/400 [1:34:07<1:25:31, 26.59s/it]2021-12-16 15:54:02,862 iteration 3520 : loss : 0.043137, loss_ce: 0.018052
2021-12-16 15:54:04,263 iteration 3521 : loss : 0.057030, loss_ce: 0.028977
2021-12-16 15:54:05,645 iteration 3522 : loss : 0.033321, loss_ce: 0.017955
2021-12-16 15:54:07,103 iteration 3523 : loss : 0.031933, loss_ce: 0.013610
2021-12-16 15:54:08,594 iteration 3524 : loss : 0.037414, loss_ce: 0.016074
2021-12-16 15:54:10,133 iteration 3525 : loss : 0.041341, loss_ce: 0.016897
2021-12-16 15:54:11,603 iteration 3526 : loss : 0.038801, loss_ce: 0.016740
2021-12-16 15:54:13,100 iteration 3527 : loss : 0.062887, loss_ce: 0.021873
2021-12-16 15:54:14,673 iteration 3528 : loss : 0.070892, loss_ce: 0.032573
2021-12-16 15:54:16,130 iteration 3529 : loss : 0.045991, loss_ce: 0.014644
2021-12-16 15:54:17,583 iteration 3530 : loss : 0.022718, loss_ce: 0.010537
2021-12-16 15:54:18,969 iteration 3531 : loss : 0.048767, loss_ce: 0.017130
2021-12-16 15:54:20,491 iteration 3532 : loss : 0.055011, loss_ce: 0.028679
2021-12-16 15:54:21,924 iteration 3533 : loss : 0.039765, loss_ce: 0.014893
2021-12-16 15:54:23,412 iteration 3534 : loss : 0.038526, loss_ce: 0.017744
2021-12-16 15:54:24,957 iteration 3535 : loss : 0.052463, loss_ce: 0.028112
2021-12-16 15:54:26,444 iteration 3536 : loss : 0.035538, loss_ce: 0.017457
 52%|██████████████             | 208/400 [1:34:32<1:23:37, 26.13s/it]2021-12-16 15:54:27,851 iteration 3537 : loss : 0.030474, loss_ce: 0.014091
2021-12-16 15:54:29,216 iteration 3538 : loss : 0.035838, loss_ce: 0.015794
2021-12-16 15:54:30,605 iteration 3539 : loss : 0.028714, loss_ce: 0.014942
2021-12-16 15:54:31,957 iteration 3540 : loss : 0.025913, loss_ce: 0.008846
2021-12-16 15:54:33,494 iteration 3541 : loss : 0.047814, loss_ce: 0.020233
2021-12-16 15:54:34,959 iteration 3542 : loss : 0.043924, loss_ce: 0.021580
2021-12-16 15:54:36,522 iteration 3543 : loss : 0.062241, loss_ce: 0.024624
2021-12-16 15:54:37,904 iteration 3544 : loss : 0.026115, loss_ce: 0.012202
2021-12-16 15:54:39,347 iteration 3545 : loss : 0.030376, loss_ce: 0.015064
2021-12-16 15:54:40,734 iteration 3546 : loss : 0.030383, loss_ce: 0.014004
2021-12-16 15:54:42,186 iteration 3547 : loss : 0.036228, loss_ce: 0.017722
2021-12-16 15:54:43,585 iteration 3548 : loss : 0.040662, loss_ce: 0.016364
2021-12-16 15:54:45,034 iteration 3549 : loss : 0.033545, loss_ce: 0.015787
2021-12-16 15:54:46,511 iteration 3550 : loss : 0.047443, loss_ce: 0.021662
2021-12-16 15:54:48,013 iteration 3551 : loss : 0.056416, loss_ce: 0.021386
2021-12-16 15:54:49,531 iteration 3552 : loss : 0.058788, loss_ce: 0.021739
2021-12-16 15:54:51,049 iteration 3553 : loss : 0.047066, loss_ce: 0.022885
 52%|██████████████             | 209/400 [1:34:56<1:21:44, 25.68s/it]2021-12-16 15:54:52,542 iteration 3554 : loss : 0.039961, loss_ce: 0.018987
2021-12-16 15:54:53,963 iteration 3555 : loss : 0.034465, loss_ce: 0.014562
2021-12-16 15:54:55,386 iteration 3556 : loss : 0.030747, loss_ce: 0.015375
2021-12-16 15:54:56,919 iteration 3557 : loss : 0.032779, loss_ce: 0.011829
2021-12-16 15:54:58,318 iteration 3558 : loss : 0.048126, loss_ce: 0.014186
2021-12-16 15:54:59,764 iteration 3559 : loss : 0.028926, loss_ce: 0.011212
2021-12-16 15:55:01,109 iteration 3560 : loss : 0.033091, loss_ce: 0.018620
2021-12-16 15:55:02,645 iteration 3561 : loss : 0.049598, loss_ce: 0.021155
2021-12-16 15:55:04,071 iteration 3562 : loss : 0.031051, loss_ce: 0.013813
2021-12-16 15:55:05,559 iteration 3563 : loss : 0.035585, loss_ce: 0.014009
2021-12-16 15:55:07,013 iteration 3564 : loss : 0.051244, loss_ce: 0.020246
2021-12-16 15:55:08,570 iteration 3565 : loss : 0.054958, loss_ce: 0.023264
2021-12-16 15:55:10,012 iteration 3566 : loss : 0.043319, loss_ce: 0.017648
2021-12-16 15:55:11,537 iteration 3567 : loss : 0.052497, loss_ce: 0.026333
2021-12-16 15:55:13,048 iteration 3568 : loss : 0.055201, loss_ce: 0.025352
2021-12-16 15:55:14,535 iteration 3569 : loss : 0.075508, loss_ce: 0.020960
2021-12-16 15:55:14,536 Training Data Eval:
2021-12-16 15:55:22,003   Average segmentation loss on training set: 0.0192
2021-12-16 15:55:22,003 Validation Data Eval:
2021-12-16 15:55:24,600   Average segmentation loss on validation set: 0.1091
2021-12-16 15:55:26,087 iteration 3570 : loss : 0.049756, loss_ce: 0.019541
 52%|██████████████▏            | 210/400 [1:35:31<1:30:11, 28.48s/it]2021-12-16 15:55:27,598 iteration 3571 : loss : 0.046845, loss_ce: 0.022232
2021-12-16 15:55:29,075 iteration 3572 : loss : 0.039176, loss_ce: 0.015602
2021-12-16 15:55:30,543 iteration 3573 : loss : 0.059285, loss_ce: 0.028930
2021-12-16 15:55:31,953 iteration 3574 : loss : 0.023421, loss_ce: 0.011923
2021-12-16 15:55:33,379 iteration 3575 : loss : 0.043043, loss_ce: 0.019260
2021-12-16 15:55:34,840 iteration 3576 : loss : 0.056745, loss_ce: 0.022397
2021-12-16 15:55:36,344 iteration 3577 : loss : 0.033407, loss_ce: 0.018276
2021-12-16 15:55:37,852 iteration 3578 : loss : 0.045618, loss_ce: 0.022223
2021-12-16 15:55:39,293 iteration 3579 : loss : 0.038240, loss_ce: 0.015559
2021-12-16 15:55:40,772 iteration 3580 : loss : 0.053876, loss_ce: 0.022612
2021-12-16 15:55:42,180 iteration 3581 : loss : 0.046545, loss_ce: 0.014208
2021-12-16 15:55:43,620 iteration 3582 : loss : 0.036260, loss_ce: 0.015965
2021-12-16 15:55:45,093 iteration 3583 : loss : 0.039091, loss_ce: 0.017271
2021-12-16 15:55:46,490 iteration 3584 : loss : 0.037450, loss_ce: 0.018078
2021-12-16 15:55:47,934 iteration 3585 : loss : 0.027480, loss_ce: 0.011835
2021-12-16 15:55:49,339 iteration 3586 : loss : 0.038268, loss_ce: 0.016601
2021-12-16 15:55:50,781 iteration 3587 : loss : 0.038065, loss_ce: 0.017761
 53%|██████████████▏            | 211/400 [1:35:56<1:26:08, 27.35s/it]2021-12-16 15:55:52,184 iteration 3588 : loss : 0.028029, loss_ce: 0.011954
2021-12-16 15:55:53,679 iteration 3589 : loss : 0.052245, loss_ce: 0.018994
2021-12-16 15:55:55,137 iteration 3590 : loss : 0.056424, loss_ce: 0.024303
2021-12-16 15:55:56,576 iteration 3591 : loss : 0.028306, loss_ce: 0.012705
2021-12-16 15:55:58,095 iteration 3592 : loss : 0.035420, loss_ce: 0.015796
2021-12-16 15:55:59,564 iteration 3593 : loss : 0.054294, loss_ce: 0.020907
2021-12-16 15:56:01,022 iteration 3594 : loss : 0.033272, loss_ce: 0.012248
2021-12-16 15:56:02,595 iteration 3595 : loss : 0.067080, loss_ce: 0.016882
2021-12-16 15:56:03,975 iteration 3596 : loss : 0.033979, loss_ce: 0.016152
2021-12-16 15:56:05,514 iteration 3597 : loss : 0.058948, loss_ce: 0.025267
2021-12-16 15:56:06,962 iteration 3598 : loss : 0.046861, loss_ce: 0.024424
2021-12-16 15:56:08,415 iteration 3599 : loss : 0.048216, loss_ce: 0.020757
2021-12-16 15:56:09,847 iteration 3600 : loss : 0.033233, loss_ce: 0.016367
2021-12-16 15:56:11,298 iteration 3601 : loss : 0.043609, loss_ce: 0.021206
2021-12-16 15:56:12,723 iteration 3602 : loss : 0.038438, loss_ce: 0.019160
2021-12-16 15:56:14,137 iteration 3603 : loss : 0.037225, loss_ce: 0.013965
2021-12-16 15:56:15,551 iteration 3604 : loss : 0.026230, loss_ce: 0.011062
 53%|██████████████▎            | 212/400 [1:36:21<1:23:16, 26.58s/it]2021-12-16 15:56:17,032 iteration 3605 : loss : 0.036606, loss_ce: 0.016977
2021-12-16 15:56:18,474 iteration 3606 : loss : 0.036597, loss_ce: 0.015411
2021-12-16 15:56:19,870 iteration 3607 : loss : 0.026788, loss_ce: 0.011118
2021-12-16 15:56:21,270 iteration 3608 : loss : 0.033571, loss_ce: 0.015668
2021-12-16 15:56:22,752 iteration 3609 : loss : 0.028777, loss_ce: 0.010754
2021-12-16 15:56:24,175 iteration 3610 : loss : 0.038345, loss_ce: 0.017705
2021-12-16 15:56:25,659 iteration 3611 : loss : 0.039572, loss_ce: 0.018780
2021-12-16 15:56:27,168 iteration 3612 : loss : 0.046574, loss_ce: 0.019351
2021-12-16 15:56:28,635 iteration 3613 : loss : 0.036280, loss_ce: 0.013382
2021-12-16 15:56:30,132 iteration 3614 : loss : 0.035385, loss_ce: 0.013825
2021-12-16 15:56:31,547 iteration 3615 : loss : 0.043565, loss_ce: 0.018444
2021-12-16 15:56:33,060 iteration 3616 : loss : 0.043789, loss_ce: 0.014963
2021-12-16 15:56:34,500 iteration 3617 : loss : 0.041945, loss_ce: 0.019065
2021-12-16 15:56:35,955 iteration 3618 : loss : 0.046210, loss_ce: 0.024458
2021-12-16 15:56:37,396 iteration 3619 : loss : 0.035926, loss_ce: 0.018838
2021-12-16 15:56:38,876 iteration 3620 : loss : 0.034245, loss_ce: 0.016324
2021-12-16 15:56:40,306 iteration 3621 : loss : 0.042167, loss_ce: 0.020447
 53%|██████████████▍            | 213/400 [1:36:46<1:21:07, 26.03s/it]2021-12-16 15:56:41,861 iteration 3622 : loss : 0.079663, loss_ce: 0.029550
2021-12-16 15:56:43,307 iteration 3623 : loss : 0.031566, loss_ce: 0.013848
2021-12-16 15:56:44,827 iteration 3624 : loss : 0.033524, loss_ce: 0.012378
2021-12-16 15:56:46,347 iteration 3625 : loss : 0.059719, loss_ce: 0.030565
2021-12-16 15:56:47,794 iteration 3626 : loss : 0.038425, loss_ce: 0.015310
2021-12-16 15:56:49,288 iteration 3627 : loss : 0.054213, loss_ce: 0.032017
2021-12-16 15:56:50,746 iteration 3628 : loss : 0.038207, loss_ce: 0.014571
2021-12-16 15:56:52,257 iteration 3629 : loss : 0.037951, loss_ce: 0.019631
2021-12-16 15:56:53,682 iteration 3630 : loss : 0.038073, loss_ce: 0.016090
2021-12-16 15:56:55,063 iteration 3631 : loss : 0.034383, loss_ce: 0.015686
2021-12-16 15:56:56,467 iteration 3632 : loss : 0.029087, loss_ce: 0.013922
2021-12-16 15:56:57,991 iteration 3633 : loss : 0.060742, loss_ce: 0.026931
2021-12-16 15:56:59,437 iteration 3634 : loss : 0.042007, loss_ce: 0.016941
2021-12-16 15:57:00,859 iteration 3635 : loss : 0.039284, loss_ce: 0.017388
2021-12-16 15:57:02,275 iteration 3636 : loss : 0.041768, loss_ce: 0.017663
2021-12-16 15:57:03,783 iteration 3637 : loss : 0.048606, loss_ce: 0.017714
2021-12-16 15:57:05,182 iteration 3638 : loss : 0.033709, loss_ce: 0.014060
 54%|██████████████▍            | 214/400 [1:37:11<1:19:37, 25.68s/it]2021-12-16 15:57:06,657 iteration 3639 : loss : 0.037000, loss_ce: 0.019162
2021-12-16 15:57:08,155 iteration 3640 : loss : 0.034115, loss_ce: 0.013811
2021-12-16 15:57:09,615 iteration 3641 : loss : 0.071396, loss_ce: 0.022116
2021-12-16 15:57:11,109 iteration 3642 : loss : 0.051126, loss_ce: 0.025145
2021-12-16 15:57:12,547 iteration 3643 : loss : 0.047300, loss_ce: 0.024433
2021-12-16 15:57:13,971 iteration 3644 : loss : 0.035770, loss_ce: 0.017774
2021-12-16 15:57:15,375 iteration 3645 : loss : 0.026646, loss_ce: 0.011791
2021-12-16 15:57:16,830 iteration 3646 : loss : 0.032209, loss_ce: 0.012864
2021-12-16 15:57:18,323 iteration 3647 : loss : 0.036043, loss_ce: 0.016420
2021-12-16 15:57:19,873 iteration 3648 : loss : 0.055413, loss_ce: 0.024163
2021-12-16 15:57:21,329 iteration 3649 : loss : 0.048110, loss_ce: 0.016638
2021-12-16 15:57:22,761 iteration 3650 : loss : 0.042684, loss_ce: 0.015673
2021-12-16 15:57:24,220 iteration 3651 : loss : 0.049026, loss_ce: 0.019509
2021-12-16 15:57:25,645 iteration 3652 : loss : 0.031258, loss_ce: 0.015730
2021-12-16 15:57:27,163 iteration 3653 : loss : 0.070908, loss_ce: 0.020643
2021-12-16 15:57:28,637 iteration 3654 : loss : 0.038735, loss_ce: 0.013368
2021-12-16 15:57:28,637 Training Data Eval:
2021-12-16 15:57:36,128   Average segmentation loss on training set: 0.0199
2021-12-16 15:57:36,129 Validation Data Eval:
2021-12-16 15:57:38,718   Average segmentation loss on validation set: 0.1062
2021-12-16 15:57:40,088 iteration 3655 : loss : 0.037844, loss_ce: 0.011920
 54%|██████████████▌            | 215/400 [1:37:45<1:27:43, 28.45s/it]2021-12-16 15:57:41,655 iteration 3656 : loss : 0.064731, loss_ce: 0.016732
2021-12-16 15:57:43,097 iteration 3657 : loss : 0.055374, loss_ce: 0.029413
2021-12-16 15:57:44,571 iteration 3658 : loss : 0.039846, loss_ce: 0.017849
2021-12-16 15:57:46,086 iteration 3659 : loss : 0.051749, loss_ce: 0.016103
2021-12-16 15:57:47,639 iteration 3660 : loss : 0.059662, loss_ce: 0.021689
2021-12-16 15:57:49,199 iteration 3661 : loss : 0.053132, loss_ce: 0.027165
2021-12-16 15:57:50,570 iteration 3662 : loss : 0.025885, loss_ce: 0.011275
2021-12-16 15:57:52,000 iteration 3663 : loss : 0.031207, loss_ce: 0.011146
2021-12-16 15:57:53,438 iteration 3664 : loss : 0.039584, loss_ce: 0.014815
2021-12-16 15:57:54,895 iteration 3665 : loss : 0.033614, loss_ce: 0.016274
2021-12-16 15:57:56,465 iteration 3666 : loss : 0.078638, loss_ce: 0.040269
2021-12-16 15:57:57,958 iteration 3667 : loss : 0.042903, loss_ce: 0.019064
2021-12-16 15:57:59,441 iteration 3668 : loss : 0.049677, loss_ce: 0.024846
2021-12-16 15:58:00,904 iteration 3669 : loss : 0.037780, loss_ce: 0.019011
2021-12-16 15:58:02,347 iteration 3670 : loss : 0.048341, loss_ce: 0.017838
2021-12-16 15:58:03,870 iteration 3671 : loss : 0.042924, loss_ce: 0.017789
2021-12-16 15:58:05,276 iteration 3672 : loss : 0.031295, loss_ce: 0.014329
 54%|██████████████▌            | 216/400 [1:38:11<1:24:14, 27.47s/it]2021-12-16 15:58:06,734 iteration 3673 : loss : 0.034073, loss_ce: 0.017014
2021-12-16 15:58:08,181 iteration 3674 : loss : 0.040450, loss_ce: 0.019092
2021-12-16 15:58:09,609 iteration 3675 : loss : 0.031367, loss_ce: 0.018084
2021-12-16 15:58:11,051 iteration 3676 : loss : 0.028912, loss_ce: 0.011887
2021-12-16 15:58:12,481 iteration 3677 : loss : 0.034011, loss_ce: 0.017800
2021-12-16 15:58:14,001 iteration 3678 : loss : 0.058746, loss_ce: 0.022296
2021-12-16 15:58:15,431 iteration 3679 : loss : 0.035212, loss_ce: 0.015457
2021-12-16 15:58:16,868 iteration 3680 : loss : 0.059919, loss_ce: 0.019703
2021-12-16 15:58:18,380 iteration 3681 : loss : 0.041994, loss_ce: 0.015764
2021-12-16 15:58:19,818 iteration 3682 : loss : 0.036476, loss_ce: 0.018660
2021-12-16 15:58:21,316 iteration 3683 : loss : 0.080024, loss_ce: 0.013499
2021-12-16 15:58:22,738 iteration 3684 : loss : 0.027994, loss_ce: 0.010582
2021-12-16 15:58:24,160 iteration 3685 : loss : 0.047085, loss_ce: 0.025444
2021-12-16 15:58:25,622 iteration 3686 : loss : 0.038114, loss_ce: 0.016474
2021-12-16 15:58:27,061 iteration 3687 : loss : 0.037537, loss_ce: 0.013069
2021-12-16 15:58:28,490 iteration 3688 : loss : 0.056864, loss_ce: 0.026888
2021-12-16 15:58:29,886 iteration 3689 : loss : 0.049534, loss_ce: 0.018881
 54%|██████████████▋            | 217/400 [1:38:35<1:21:10, 26.61s/it]2021-12-16 15:58:31,354 iteration 3690 : loss : 0.027364, loss_ce: 0.008348
2021-12-16 15:58:32,898 iteration 3691 : loss : 0.085140, loss_ce: 0.019825
2021-12-16 15:58:34,363 iteration 3692 : loss : 0.046544, loss_ce: 0.022495
2021-12-16 15:58:35,874 iteration 3693 : loss : 0.063148, loss_ce: 0.025161
2021-12-16 15:58:37,320 iteration 3694 : loss : 0.029368, loss_ce: 0.014321
2021-12-16 15:58:38,722 iteration 3695 : loss : 0.034337, loss_ce: 0.015269
2021-12-16 15:58:40,201 iteration 3696 : loss : 0.045898, loss_ce: 0.025442
2021-12-16 15:58:41,642 iteration 3697 : loss : 0.039480, loss_ce: 0.013237
2021-12-16 15:58:43,087 iteration 3698 : loss : 0.039913, loss_ce: 0.017557
2021-12-16 15:58:44,613 iteration 3699 : loss : 0.061681, loss_ce: 0.022719
2021-12-16 15:58:46,076 iteration 3700 : loss : 0.043241, loss_ce: 0.020402
2021-12-16 15:58:47,507 iteration 3701 : loss : 0.036031, loss_ce: 0.014503
2021-12-16 15:58:48,921 iteration 3702 : loss : 0.059483, loss_ce: 0.022014
2021-12-16 15:58:50,485 iteration 3703 : loss : 0.058426, loss_ce: 0.030029
2021-12-16 15:58:51,901 iteration 3704 : loss : 0.028263, loss_ce: 0.011695
2021-12-16 15:58:53,295 iteration 3705 : loss : 0.030838, loss_ce: 0.012582
2021-12-16 15:58:54,684 iteration 3706 : loss : 0.034468, loss_ce: 0.011123
 55%|██████████████▋            | 218/400 [1:39:00<1:19:04, 26.07s/it]2021-12-16 15:58:56,162 iteration 3707 : loss : 0.069575, loss_ce: 0.036067
2021-12-16 15:58:57,615 iteration 3708 : loss : 0.036490, loss_ce: 0.017865
2021-12-16 15:58:59,073 iteration 3709 : loss : 0.033647, loss_ce: 0.012242
2021-12-16 15:59:00,588 iteration 3710 : loss : 0.052304, loss_ce: 0.020676
2021-12-16 15:59:02,023 iteration 3711 : loss : 0.026913, loss_ce: 0.012713
2021-12-16 15:59:03,489 iteration 3712 : loss : 0.038931, loss_ce: 0.015250
2021-12-16 15:59:04,882 iteration 3713 : loss : 0.065064, loss_ce: 0.024339
2021-12-16 15:59:06,305 iteration 3714 : loss : 0.033272, loss_ce: 0.014236
2021-12-16 15:59:07,779 iteration 3715 : loss : 0.048603, loss_ce: 0.021593
2021-12-16 15:59:09,194 iteration 3716 : loss : 0.040179, loss_ce: 0.014337
2021-12-16 15:59:10,664 iteration 3717 : loss : 0.048327, loss_ce: 0.019376
2021-12-16 15:59:12,174 iteration 3718 : loss : 0.033969, loss_ce: 0.015764
2021-12-16 15:59:13,561 iteration 3719 : loss : 0.026114, loss_ce: 0.009063
2021-12-16 15:59:15,021 iteration 3720 : loss : 0.032778, loss_ce: 0.018443
2021-12-16 15:59:16,481 iteration 3721 : loss : 0.033656, loss_ce: 0.016153
2021-12-16 15:59:17,930 iteration 3722 : loss : 0.037270, loss_ce: 0.018006
2021-12-16 15:59:19,365 iteration 3723 : loss : 0.041435, loss_ce: 0.015948
 55%|██████████████▊            | 219/400 [1:39:25<1:17:23, 25.65s/it]2021-12-16 15:59:20,801 iteration 3724 : loss : 0.027600, loss_ce: 0.014015
2021-12-16 15:59:22,221 iteration 3725 : loss : 0.043864, loss_ce: 0.024548
2021-12-16 15:59:23,720 iteration 3726 : loss : 0.052315, loss_ce: 0.027302
2021-12-16 15:59:25,167 iteration 3727 : loss : 0.036928, loss_ce: 0.015648
2021-12-16 15:59:26,623 iteration 3728 : loss : 0.039555, loss_ce: 0.013981
2021-12-16 15:59:28,038 iteration 3729 : loss : 0.036985, loss_ce: 0.011798
2021-12-16 15:59:29,486 iteration 3730 : loss : 0.030071, loss_ce: 0.014453
2021-12-16 15:59:30,934 iteration 3731 : loss : 0.034824, loss_ce: 0.013455
2021-12-16 15:59:32,428 iteration 3732 : loss : 0.035625, loss_ce: 0.014117
2021-12-16 15:59:33,819 iteration 3733 : loss : 0.038876, loss_ce: 0.016648
2021-12-16 15:59:35,265 iteration 3734 : loss : 0.040649, loss_ce: 0.021265
2021-12-16 15:59:36,686 iteration 3735 : loss : 0.042419, loss_ce: 0.014986
2021-12-16 15:59:38,179 iteration 3736 : loss : 0.042563, loss_ce: 0.023929
2021-12-16 15:59:39,585 iteration 3737 : loss : 0.030675, loss_ce: 0.012235
2021-12-16 15:59:41,020 iteration 3738 : loss : 0.029965, loss_ce: 0.013190
2021-12-16 15:59:42,415 iteration 3739 : loss : 0.040888, loss_ce: 0.016836
2021-12-16 15:59:42,415 Training Data Eval:
2021-12-16 15:59:49,921   Average segmentation loss on training set: 0.0196
2021-12-16 15:59:49,921 Validation Data Eval:
2021-12-16 15:59:52,521   Average segmentation loss on validation set: 0.1023
2021-12-16 15:59:58,962 Found new lowest validation loss at iteration 3739! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/TU_3seeds/TU_RESNET_no_pretraining_SGD_best_val_loss_seed1234.pth
2021-12-16 16:00:00,521 iteration 3740 : loss : 0.056946, loss_ce: 0.029516
 55%|██████████████▊            | 220/400 [1:40:06<1:30:54, 30.30s/it]2021-12-16 16:00:02,067 iteration 3741 : loss : 0.056449, loss_ce: 0.019143
2021-12-16 16:00:03,426 iteration 3742 : loss : 0.046038, loss_ce: 0.027094
2021-12-16 16:00:04,791 iteration 3743 : loss : 0.037420, loss_ce: 0.017293
2021-12-16 16:00:06,220 iteration 3744 : loss : 0.050817, loss_ce: 0.020420
2021-12-16 16:00:07,662 iteration 3745 : loss : 0.047188, loss_ce: 0.018792
2021-12-16 16:00:09,106 iteration 3746 : loss : 0.039902, loss_ce: 0.016593
2021-12-16 16:00:10,462 iteration 3747 : loss : 0.048180, loss_ce: 0.020256
2021-12-16 16:00:11,801 iteration 3748 : loss : 0.035019, loss_ce: 0.017828
2021-12-16 16:00:13,218 iteration 3749 : loss : 0.045554, loss_ce: 0.015589
2021-12-16 16:00:14,672 iteration 3750 : loss : 0.046480, loss_ce: 0.018592
2021-12-16 16:00:16,077 iteration 3751 : loss : 0.051688, loss_ce: 0.017804
2021-12-16 16:00:17,460 iteration 3752 : loss : 0.056728, loss_ce: 0.016611
2021-12-16 16:00:18,868 iteration 3753 : loss : 0.037358, loss_ce: 0.013225
2021-12-16 16:00:20,361 iteration 3754 : loss : 0.039129, loss_ce: 0.016330
2021-12-16 16:00:21,908 iteration 3755 : loss : 0.035728, loss_ce: 0.017713
2021-12-16 16:00:23,321 iteration 3756 : loss : 0.038028, loss_ce: 0.021085
2021-12-16 16:00:24,752 iteration 3757 : loss : 0.034446, loss_ce: 0.016614
 55%|██████████████▉            | 221/400 [1:40:30<1:24:58, 28.48s/it]2021-12-16 16:00:26,337 iteration 3758 : loss : 0.035873, loss_ce: 0.013444
2021-12-16 16:00:27,764 iteration 3759 : loss : 0.037599, loss_ce: 0.015479
2021-12-16 16:00:29,222 iteration 3760 : loss : 0.033848, loss_ce: 0.015708
2021-12-16 16:00:30,737 iteration 3761 : loss : 0.049032, loss_ce: 0.021436
2021-12-16 16:00:32,307 iteration 3762 : loss : 0.039304, loss_ce: 0.021761
2021-12-16 16:00:33,869 iteration 3763 : loss : 0.066052, loss_ce: 0.025045
2021-12-16 16:00:35,303 iteration 3764 : loss : 0.043933, loss_ce: 0.017714
2021-12-16 16:00:36,702 iteration 3765 : loss : 0.030512, loss_ce: 0.014550
2021-12-16 16:00:38,215 iteration 3766 : loss : 0.071844, loss_ce: 0.019927
2021-12-16 16:00:39,717 iteration 3767 : loss : 0.026311, loss_ce: 0.011318
2021-12-16 16:00:41,156 iteration 3768 : loss : 0.039244, loss_ce: 0.014903
2021-12-16 16:00:42,597 iteration 3769 : loss : 0.027807, loss_ce: 0.013560
2021-12-16 16:00:44,088 iteration 3770 : loss : 0.054515, loss_ce: 0.013103
2021-12-16 16:00:45,670 iteration 3771 : loss : 0.040454, loss_ce: 0.018336
2021-12-16 16:00:47,208 iteration 3772 : loss : 0.034515, loss_ce: 0.012546
2021-12-16 16:00:48,704 iteration 3773 : loss : 0.030568, loss_ce: 0.014185
2021-12-16 16:00:50,242 iteration 3774 : loss : 0.056191, loss_ce: 0.029608
 56%|██████████████▉            | 222/400 [1:40:56<1:21:49, 27.58s/it]2021-12-16 16:00:51,711 iteration 3775 : loss : 0.038351, loss_ce: 0.016009
2021-12-16 16:00:53,077 iteration 3776 : loss : 0.045965, loss_ce: 0.019490
2021-12-16 16:00:54,516 iteration 3777 : loss : 0.028828, loss_ce: 0.010518
2021-12-16 16:00:55,935 iteration 3778 : loss : 0.032543, loss_ce: 0.014860
2021-12-16 16:00:57,360 iteration 3779 : loss : 0.030530, loss_ce: 0.015582
2021-12-16 16:00:58,825 iteration 3780 : loss : 0.049202, loss_ce: 0.018261
2021-12-16 16:01:00,277 iteration 3781 : loss : 0.040758, loss_ce: 0.019352
2021-12-16 16:01:01,749 iteration 3782 : loss : 0.097120, loss_ce: 0.020277
2021-12-16 16:01:03,279 iteration 3783 : loss : 0.038045, loss_ce: 0.018123
2021-12-16 16:01:04,787 iteration 3784 : loss : 0.042197, loss_ce: 0.021591
2021-12-16 16:01:06,218 iteration 3785 : loss : 0.039548, loss_ce: 0.020820
2021-12-16 16:01:07,646 iteration 3786 : loss : 0.028735, loss_ce: 0.014036
2021-12-16 16:01:09,066 iteration 3787 : loss : 0.040969, loss_ce: 0.017817
2021-12-16 16:01:10,602 iteration 3788 : loss : 0.052871, loss_ce: 0.015473
2021-12-16 16:01:12,073 iteration 3789 : loss : 0.037868, loss_ce: 0.013040
2021-12-16 16:01:13,557 iteration 3790 : loss : 0.047043, loss_ce: 0.019653
2021-12-16 16:01:15,037 iteration 3791 : loss : 0.031025, loss_ce: 0.015916
 56%|███████████████            | 223/400 [1:41:20<1:18:54, 26.75s/it]2021-12-16 16:01:16,500 iteration 3792 : loss : 0.031233, loss_ce: 0.011160
2021-12-16 16:01:18,032 iteration 3793 : loss : 0.043224, loss_ce: 0.016948
2021-12-16 16:01:19,524 iteration 3794 : loss : 0.032273, loss_ce: 0.015332
2021-12-16 16:01:20,972 iteration 3795 : loss : 0.029529, loss_ce: 0.010813
2021-12-16 16:01:22,321 iteration 3796 : loss : 0.027461, loss_ce: 0.010828
2021-12-16 16:01:23,764 iteration 3797 : loss : 0.035693, loss_ce: 0.015880
2021-12-16 16:01:25,163 iteration 3798 : loss : 0.030292, loss_ce: 0.013769
2021-12-16 16:01:26,623 iteration 3799 : loss : 0.039520, loss_ce: 0.016050
2021-12-16 16:01:28,082 iteration 3800 : loss : 0.027781, loss_ce: 0.010376
2021-12-16 16:01:29,519 iteration 3801 : loss : 0.041589, loss_ce: 0.012160
2021-12-16 16:01:30,940 iteration 3802 : loss : 0.030795, loss_ce: 0.015534
2021-12-16 16:01:32,387 iteration 3803 : loss : 0.026607, loss_ce: 0.010503
2021-12-16 16:01:33,831 iteration 3804 : loss : 0.042788, loss_ce: 0.017926
2021-12-16 16:01:35,246 iteration 3805 : loss : 0.039146, loss_ce: 0.017233
2021-12-16 16:01:36,678 iteration 3806 : loss : 0.050154, loss_ce: 0.027463
2021-12-16 16:01:38,185 iteration 3807 : loss : 0.059830, loss_ce: 0.024096
2021-12-16 16:01:39,668 iteration 3808 : loss : 0.037738, loss_ce: 0.017868
 56%|███████████████            | 224/400 [1:41:45<1:16:35, 26.11s/it]2021-12-16 16:01:41,121 iteration 3809 : loss : 0.029445, loss_ce: 0.011708
2021-12-16 16:01:42,573 iteration 3810 : loss : 0.035099, loss_ce: 0.014822
2021-12-16 16:01:44,033 iteration 3811 : loss : 0.030806, loss_ce: 0.010456
2021-12-16 16:01:45,497 iteration 3812 : loss : 0.037896, loss_ce: 0.021578
2021-12-16 16:01:46,934 iteration 3813 : loss : 0.037037, loss_ce: 0.020344
2021-12-16 16:01:48,414 iteration 3814 : loss : 0.054049, loss_ce: 0.021713
2021-12-16 16:01:49,868 iteration 3815 : loss : 0.046971, loss_ce: 0.016565
2021-12-16 16:01:51,344 iteration 3816 : loss : 0.038121, loss_ce: 0.019139
2021-12-16 16:01:52,751 iteration 3817 : loss : 0.036278, loss_ce: 0.017652
2021-12-16 16:01:54,247 iteration 3818 : loss : 0.035747, loss_ce: 0.018142
2021-12-16 16:01:55,743 iteration 3819 : loss : 0.041896, loss_ce: 0.020748
2021-12-16 16:01:57,210 iteration 3820 : loss : 0.045704, loss_ce: 0.019255
2021-12-16 16:01:58,696 iteration 3821 : loss : 0.041165, loss_ce: 0.018792
2021-12-16 16:02:00,130 iteration 3822 : loss : 0.044818, loss_ce: 0.017661
2021-12-16 16:02:01,711 iteration 3823 : loss : 0.040657, loss_ce: 0.013519
2021-12-16 16:02:03,178 iteration 3824 : loss : 0.040322, loss_ce: 0.016808
2021-12-16 16:02:03,204 Training Data Eval:
2021-12-16 16:02:10,698   Average segmentation loss on training set: 0.0209
2021-12-16 16:02:10,699 Validation Data Eval:
2021-12-16 16:02:13,309   Average segmentation loss on validation set: 0.0937
2021-12-16 16:02:23,075 Found new lowest validation loss at iteration 3824! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/TU_3seeds/TU_RESNET_no_pretraining_SGD_best_val_loss_seed1234.pth
2021-12-16 16:02:24,533 iteration 3825 : loss : 0.039428, loss_ce: 0.016946
 56%|███████████████▏           | 225/400 [1:42:30<1:32:33, 31.74s/it]2021-12-16 16:02:25,956 iteration 3826 : loss : 0.035047, loss_ce: 0.017286
2021-12-16 16:02:27,272 iteration 3827 : loss : 0.032163, loss_ce: 0.012193
2021-12-16 16:02:28,655 iteration 3828 : loss : 0.043895, loss_ce: 0.019553
2021-12-16 16:02:30,031 iteration 3829 : loss : 0.046887, loss_ce: 0.015533
2021-12-16 16:02:31,364 iteration 3830 : loss : 0.027107, loss_ce: 0.012271
2021-12-16 16:02:32,677 iteration 3831 : loss : 0.030240, loss_ce: 0.013065
2021-12-16 16:02:33,986 iteration 3832 : loss : 0.034491, loss_ce: 0.011300
2021-12-16 16:02:35,342 iteration 3833 : loss : 0.031276, loss_ce: 0.015697
2021-12-16 16:02:36,738 iteration 3834 : loss : 0.053106, loss_ce: 0.027963
2021-12-16 16:02:38,120 iteration 3835 : loss : 0.062310, loss_ce: 0.025700
2021-12-16 16:02:39,486 iteration 3836 : loss : 0.030946, loss_ce: 0.013382
2021-12-16 16:02:40,879 iteration 3837 : loss : 0.055263, loss_ce: 0.021486
2021-12-16 16:02:42,375 iteration 3838 : loss : 0.048234, loss_ce: 0.020538
2021-12-16 16:02:43,764 iteration 3839 : loss : 0.033948, loss_ce: 0.015673
2021-12-16 16:02:45,225 iteration 3840 : loss : 0.043735, loss_ce: 0.012760
2021-12-16 16:02:46,672 iteration 3841 : loss : 0.044384, loss_ce: 0.016596
2021-12-16 16:02:48,176 iteration 3842 : loss : 0.055939, loss_ce: 0.030424
 56%|███████████████▎           | 226/400 [1:42:53<1:24:59, 29.31s/it]2021-12-16 16:02:49,655 iteration 3843 : loss : 0.035941, loss_ce: 0.017375
2021-12-16 16:02:51,176 iteration 3844 : loss : 0.042411, loss_ce: 0.015351
2021-12-16 16:02:52,687 iteration 3845 : loss : 0.028845, loss_ce: 0.014601
2021-12-16 16:02:54,126 iteration 3846 : loss : 0.025313, loss_ce: 0.011091
2021-12-16 16:02:55,579 iteration 3847 : loss : 0.041550, loss_ce: 0.018466
2021-12-16 16:02:57,100 iteration 3848 : loss : 0.032479, loss_ce: 0.020080
2021-12-16 16:02:58,690 iteration 3849 : loss : 0.041396, loss_ce: 0.020819
2021-12-16 16:03:00,247 iteration 3850 : loss : 0.078634, loss_ce: 0.023282
2021-12-16 16:03:01,726 iteration 3851 : loss : 0.037696, loss_ce: 0.019150
2021-12-16 16:03:03,227 iteration 3852 : loss : 0.040334, loss_ce: 0.014590
2021-12-16 16:03:04,662 iteration 3853 : loss : 0.031845, loss_ce: 0.011569
2021-12-16 16:03:06,179 iteration 3854 : loss : 0.034986, loss_ce: 0.013126
2021-12-16 16:03:07,789 iteration 3855 : loss : 0.049165, loss_ce: 0.021878
2021-12-16 16:03:09,122 iteration 3856 : loss : 0.027972, loss_ce: 0.014531
2021-12-16 16:03:10,564 iteration 3857 : loss : 0.044407, loss_ce: 0.022408
2021-12-16 16:03:11,949 iteration 3858 : loss : 0.029212, loss_ce: 0.013362
2021-12-16 16:03:13,408 iteration 3859 : loss : 0.054863, loss_ce: 0.021695
 57%|███████████████▎           | 227/400 [1:43:19<1:20:58, 28.09s/it]2021-12-16 16:03:14,967 iteration 3860 : loss : 0.034801, loss_ce: 0.015014
2021-12-16 16:03:16,524 iteration 3861 : loss : 0.078522, loss_ce: 0.035424
2021-12-16 16:03:18,035 iteration 3862 : loss : 0.040200, loss_ce: 0.018442
2021-12-16 16:03:19,532 iteration 3863 : loss : 0.038233, loss_ce: 0.016230
2021-12-16 16:03:21,038 iteration 3864 : loss : 0.038448, loss_ce: 0.016299
2021-12-16 16:03:22,518 iteration 3865 : loss : 0.041483, loss_ce: 0.016647
2021-12-16 16:03:24,086 iteration 3866 : loss : 0.038353, loss_ce: 0.015624
2021-12-16 16:03:25,527 iteration 3867 : loss : 0.041570, loss_ce: 0.015881
2021-12-16 16:03:27,056 iteration 3868 : loss : 0.060757, loss_ce: 0.019822
2021-12-16 16:03:28,557 iteration 3869 : loss : 0.035734, loss_ce: 0.018935
2021-12-16 16:03:30,109 iteration 3870 : loss : 0.028351, loss_ce: 0.013571
2021-12-16 16:03:31,607 iteration 3871 : loss : 0.058979, loss_ce: 0.020486
2021-12-16 16:03:33,037 iteration 3872 : loss : 0.038622, loss_ce: 0.014807
2021-12-16 16:03:34,472 iteration 3873 : loss : 0.035155, loss_ce: 0.019568
2021-12-16 16:03:35,973 iteration 3874 : loss : 0.040162, loss_ce: 0.018838
2021-12-16 16:03:37,467 iteration 3875 : loss : 0.042394, loss_ce: 0.019889
2021-12-16 16:03:38,957 iteration 3876 : loss : 0.042207, loss_ce: 0.014646
 57%|███████████████▍           | 228/400 [1:43:44<1:18:20, 27.33s/it]2021-12-16 16:03:40,429 iteration 3877 : loss : 0.031899, loss_ce: 0.013632
2021-12-16 16:03:41,919 iteration 3878 : loss : 0.035818, loss_ce: 0.014883
2021-12-16 16:03:43,366 iteration 3879 : loss : 0.024936, loss_ce: 0.011082
2021-12-16 16:03:44,880 iteration 3880 : loss : 0.039208, loss_ce: 0.019635
2021-12-16 16:03:46,332 iteration 3881 : loss : 0.031586, loss_ce: 0.016424
2021-12-16 16:03:47,904 iteration 3882 : loss : 0.065857, loss_ce: 0.018462
2021-12-16 16:03:49,434 iteration 3883 : loss : 0.053737, loss_ce: 0.021778
2021-12-16 16:03:50,922 iteration 3884 : loss : 0.048118, loss_ce: 0.023091
2021-12-16 16:03:52,455 iteration 3885 : loss : 0.079403, loss_ce: 0.018510
2021-12-16 16:03:53,973 iteration 3886 : loss : 0.047460, loss_ce: 0.020946
2021-12-16 16:03:55,374 iteration 3887 : loss : 0.025986, loss_ce: 0.011482
2021-12-16 16:03:56,877 iteration 3888 : loss : 0.038157, loss_ce: 0.018272
2021-12-16 16:03:58,360 iteration 3889 : loss : 0.031930, loss_ce: 0.013932
2021-12-16 16:03:59,946 iteration 3890 : loss : 0.071403, loss_ce: 0.021391
2021-12-16 16:04:01,399 iteration 3891 : loss : 0.045803, loss_ce: 0.021357
2021-12-16 16:04:02,894 iteration 3892 : loss : 0.039498, loss_ce: 0.019478
2021-12-16 16:04:04,401 iteration 3893 : loss : 0.063466, loss_ce: 0.023106
 57%|███████████████▍           | 229/400 [1:44:10<1:16:16, 26.76s/it]2021-12-16 16:04:05,881 iteration 3894 : loss : 0.038479, loss_ce: 0.012657
2021-12-16 16:04:07,305 iteration 3895 : loss : 0.036099, loss_ce: 0.016225
2021-12-16 16:04:08,787 iteration 3896 : loss : 0.042246, loss_ce: 0.019440
2021-12-16 16:04:10,314 iteration 3897 : loss : 0.037785, loss_ce: 0.018383
2021-12-16 16:04:11,831 iteration 3898 : loss : 0.041939, loss_ce: 0.015239
2021-12-16 16:04:13,235 iteration 3899 : loss : 0.034177, loss_ce: 0.013724
2021-12-16 16:04:14,667 iteration 3900 : loss : 0.031138, loss_ce: 0.013063
2021-12-16 16:04:16,089 iteration 3901 : loss : 0.043966, loss_ce: 0.020607
2021-12-16 16:04:17,527 iteration 3902 : loss : 0.042215, loss_ce: 0.019897
2021-12-16 16:04:18,929 iteration 3903 : loss : 0.031444, loss_ce: 0.012170
2021-12-16 16:04:20,381 iteration 3904 : loss : 0.038030, loss_ce: 0.014490
2021-12-16 16:04:21,827 iteration 3905 : loss : 0.038689, loss_ce: 0.015696
2021-12-16 16:04:23,219 iteration 3906 : loss : 0.028194, loss_ce: 0.014155
2021-12-16 16:04:24,592 iteration 3907 : loss : 0.025133, loss_ce: 0.011319
2021-12-16 16:04:25,991 iteration 3908 : loss : 0.030817, loss_ce: 0.013716
2021-12-16 16:04:27,453 iteration 3909 : loss : 0.042406, loss_ce: 0.024095
2021-12-16 16:04:27,453 Training Data Eval:
2021-12-16 16:04:35,003   Average segmentation loss on training set: 0.0181
2021-12-16 16:04:35,003 Validation Data Eval:
2021-12-16 16:04:37,607   Average segmentation loss on validation set: 0.1021
2021-12-16 16:04:39,160 iteration 3910 : loss : 0.035655, loss_ce: 0.013734
 57%|███████████████▌           | 230/400 [1:44:44<1:22:37, 29.16s/it]2021-12-16 16:04:40,626 iteration 3911 : loss : 0.028370, loss_ce: 0.013564
2021-12-16 16:04:42,133 iteration 3912 : loss : 0.055338, loss_ce: 0.021687
2021-12-16 16:04:43,608 iteration 3913 : loss : 0.037298, loss_ce: 0.017013
2021-12-16 16:04:45,073 iteration 3914 : loss : 0.025452, loss_ce: 0.013505
2021-12-16 16:04:46,531 iteration 3915 : loss : 0.043147, loss_ce: 0.018572
2021-12-16 16:04:47,948 iteration 3916 : loss : 0.031720, loss_ce: 0.013723
2021-12-16 16:04:49,437 iteration 3917 : loss : 0.037595, loss_ce: 0.015390
2021-12-16 16:04:50,936 iteration 3918 : loss : 0.053323, loss_ce: 0.019135
2021-12-16 16:04:52,542 iteration 3919 : loss : 0.071892, loss_ce: 0.023932
2021-12-16 16:04:53,945 iteration 3920 : loss : 0.034508, loss_ce: 0.015721
2021-12-16 16:04:55,400 iteration 3921 : loss : 0.040277, loss_ce: 0.017709
2021-12-16 16:04:56,913 iteration 3922 : loss : 0.036454, loss_ce: 0.015033
2021-12-16 16:04:58,372 iteration 3923 : loss : 0.031179, loss_ce: 0.017777
2021-12-16 16:04:59,796 iteration 3924 : loss : 0.044836, loss_ce: 0.013606
2021-12-16 16:05:01,342 iteration 3925 : loss : 0.065842, loss_ce: 0.029639
2021-12-16 16:05:02,865 iteration 3926 : loss : 0.043909, loss_ce: 0.016685
2021-12-16 16:05:04,338 iteration 3927 : loss : 0.041649, loss_ce: 0.017014
 58%|███████████████▌           | 231/400 [1:45:10<1:18:46, 27.97s/it]2021-12-16 16:05:05,883 iteration 3928 : loss : 0.055605, loss_ce: 0.027135
2021-12-16 16:05:07,343 iteration 3929 : loss : 0.033181, loss_ce: 0.016717
2021-12-16 16:05:08,867 iteration 3930 : loss : 0.042282, loss_ce: 0.019357
2021-12-16 16:05:10,372 iteration 3931 : loss : 0.028784, loss_ce: 0.013580
2021-12-16 16:05:11,873 iteration 3932 : loss : 0.055484, loss_ce: 0.022071
2021-12-16 16:05:13,419 iteration 3933 : loss : 0.044542, loss_ce: 0.018841
2021-12-16 16:05:14,911 iteration 3934 : loss : 0.028876, loss_ce: 0.014004
2021-12-16 16:05:16,325 iteration 3935 : loss : 0.034429, loss_ce: 0.016906
2021-12-16 16:05:17,921 iteration 3936 : loss : 0.054582, loss_ce: 0.021509
2021-12-16 16:05:19,329 iteration 3937 : loss : 0.034331, loss_ce: 0.016346
2021-12-16 16:05:20,835 iteration 3938 : loss : 0.115976, loss_ce: 0.026003
2021-12-16 16:05:22,230 iteration 3939 : loss : 0.042228, loss_ce: 0.014902
2021-12-16 16:05:23,679 iteration 3940 : loss : 0.037554, loss_ce: 0.015493
2021-12-16 16:05:25,150 iteration 3941 : loss : 0.056385, loss_ce: 0.023186
2021-12-16 16:05:26,676 iteration 3942 : loss : 0.049117, loss_ce: 0.022626
2021-12-16 16:05:28,100 iteration 3943 : loss : 0.038569, loss_ce: 0.012026
2021-12-16 16:05:29,627 iteration 3944 : loss : 0.054952, loss_ce: 0.023568
 58%|███████████████▋           | 232/400 [1:45:35<1:16:03, 27.16s/it]2021-12-16 16:05:31,164 iteration 3945 : loss : 0.046332, loss_ce: 0.021487
2021-12-16 16:05:32,535 iteration 3946 : loss : 0.037942, loss_ce: 0.019509
2021-12-16 16:05:33,992 iteration 3947 : loss : 0.026998, loss_ce: 0.009935
2021-12-16 16:05:35,580 iteration 3948 : loss : 0.065716, loss_ce: 0.026829
2021-12-16 16:05:37,070 iteration 3949 : loss : 0.063849, loss_ce: 0.028133
2021-12-16 16:05:38,595 iteration 3950 : loss : 0.042910, loss_ce: 0.015848
2021-12-16 16:05:40,001 iteration 3951 : loss : 0.028363, loss_ce: 0.013245
2021-12-16 16:05:41,511 iteration 3952 : loss : 0.031913, loss_ce: 0.013324
2021-12-16 16:05:43,035 iteration 3953 : loss : 0.066554, loss_ce: 0.025220
2021-12-16 16:05:44,480 iteration 3954 : loss : 0.041275, loss_ce: 0.017131
2021-12-16 16:05:45,938 iteration 3955 : loss : 0.024323, loss_ce: 0.010442
2021-12-16 16:05:47,533 iteration 3956 : loss : 0.048258, loss_ce: 0.023010
2021-12-16 16:05:48,953 iteration 3957 : loss : 0.034650, loss_ce: 0.016647
2021-12-16 16:05:50,401 iteration 3958 : loss : 0.047730, loss_ce: 0.019044
2021-12-16 16:05:51,937 iteration 3959 : loss : 0.055881, loss_ce: 0.021740
2021-12-16 16:05:53,347 iteration 3960 : loss : 0.038082, loss_ce: 0.020002
2021-12-16 16:05:54,779 iteration 3961 : loss : 0.043646, loss_ce: 0.022451
 58%|███████████████▋           | 233/400 [1:46:00<1:13:55, 26.56s/it]2021-12-16 16:05:56,342 iteration 3962 : loss : 0.040657, loss_ce: 0.017398
2021-12-16 16:05:57,803 iteration 3963 : loss : 0.038259, loss_ce: 0.019230
2021-12-16 16:05:59,369 iteration 3964 : loss : 0.047452, loss_ce: 0.022961
2021-12-16 16:06:00,799 iteration 3965 : loss : 0.036017, loss_ce: 0.013081
2021-12-16 16:06:02,321 iteration 3966 : loss : 0.045766, loss_ce: 0.018530
2021-12-16 16:06:03,825 iteration 3967 : loss : 0.044308, loss_ce: 0.018452
2021-12-16 16:06:05,191 iteration 3968 : loss : 0.032548, loss_ce: 0.013288
2021-12-16 16:06:06,661 iteration 3969 : loss : 0.049874, loss_ce: 0.015582
2021-12-16 16:06:08,092 iteration 3970 : loss : 0.044226, loss_ce: 0.015253
2021-12-16 16:06:09,450 iteration 3971 : loss : 0.033619, loss_ce: 0.015903
2021-12-16 16:06:10,946 iteration 3972 : loss : 0.043531, loss_ce: 0.014634
2021-12-16 16:06:12,371 iteration 3973 : loss : 0.039606, loss_ce: 0.021803
2021-12-16 16:06:13,753 iteration 3974 : loss : 0.027979, loss_ce: 0.011500
2021-12-16 16:06:15,245 iteration 3975 : loss : 0.029677, loss_ce: 0.013599
2021-12-16 16:06:16,773 iteration 3976 : loss : 0.036079, loss_ce: 0.015888
2021-12-16 16:06:18,291 iteration 3977 : loss : 0.039462, loss_ce: 0.017507
2021-12-16 16:06:19,837 iteration 3978 : loss : 0.051302, loss_ce: 0.021501
 58%|███████████████▊           | 234/400 [1:46:25<1:12:14, 26.11s/it]2021-12-16 16:06:21,340 iteration 3979 : loss : 0.071984, loss_ce: 0.029457
2021-12-16 16:06:22,836 iteration 3980 : loss : 0.045834, loss_ce: 0.016912
2021-12-16 16:06:24,265 iteration 3981 : loss : 0.045360, loss_ce: 0.021297
2021-12-16 16:06:25,629 iteration 3982 : loss : 0.026420, loss_ce: 0.011246
2021-12-16 16:06:27,019 iteration 3983 : loss : 0.029424, loss_ce: 0.015509
2021-12-16 16:06:28,488 iteration 3984 : loss : 0.028166, loss_ce: 0.013485
2021-12-16 16:06:29,977 iteration 3985 : loss : 0.066613, loss_ce: 0.042416
2021-12-16 16:06:31,524 iteration 3986 : loss : 0.051513, loss_ce: 0.026558
2021-12-16 16:06:33,002 iteration 3987 : loss : 0.037088, loss_ce: 0.016509
2021-12-16 16:06:34,453 iteration 3988 : loss : 0.041939, loss_ce: 0.023330
2021-12-16 16:06:35,922 iteration 3989 : loss : 0.037811, loss_ce: 0.011441
2021-12-16 16:06:37,346 iteration 3990 : loss : 0.042187, loss_ce: 0.015563
2021-12-16 16:06:38,868 iteration 3991 : loss : 0.044001, loss_ce: 0.012986
2021-12-16 16:06:40,354 iteration 3992 : loss : 0.046004, loss_ce: 0.017092
2021-12-16 16:06:41,875 iteration 3993 : loss : 0.086923, loss_ce: 0.037822
2021-12-16 16:06:43,302 iteration 3994 : loss : 0.029801, loss_ce: 0.015570
2021-12-16 16:06:43,302 Training Data Eval:
2021-12-16 16:06:50,809   Average segmentation loss on training set: 0.0193
2021-12-16 16:06:50,809 Validation Data Eval:
2021-12-16 16:06:53,413   Average segmentation loss on validation set: 0.1064
2021-12-16 16:06:54,831 iteration 3995 : loss : 0.030664, loss_ce: 0.015243
 59%|███████████████▊           | 235/400 [1:47:00<1:19:07, 28.78s/it]2021-12-16 16:06:56,411 iteration 3996 : loss : 0.034095, loss_ce: 0.012443
2021-12-16 16:06:57,825 iteration 3997 : loss : 0.031028, loss_ce: 0.011081
2021-12-16 16:06:59,315 iteration 3998 : loss : 0.037638, loss_ce: 0.017548
2021-12-16 16:07:00,806 iteration 3999 : loss : 0.036582, loss_ce: 0.012164
2021-12-16 16:07:02,316 iteration 4000 : loss : 0.032871, loss_ce: 0.018018
2021-12-16 16:07:03,700 iteration 4001 : loss : 0.033254, loss_ce: 0.013961
2021-12-16 16:07:05,170 iteration 4002 : loss : 0.045641, loss_ce: 0.019784
2021-12-16 16:07:06,638 iteration 4003 : loss : 0.036074, loss_ce: 0.018466
2021-12-16 16:07:08,156 iteration 4004 : loss : 0.052807, loss_ce: 0.014616
2021-12-16 16:07:09,640 iteration 4005 : loss : 0.047161, loss_ce: 0.026692
2021-12-16 16:07:11,052 iteration 4006 : loss : 0.037963, loss_ce: 0.017652
2021-12-16 16:07:12,570 iteration 4007 : loss : 0.040916, loss_ce: 0.016580
2021-12-16 16:07:13,982 iteration 4008 : loss : 0.036383, loss_ce: 0.014181
2021-12-16 16:07:15,444 iteration 4009 : loss : 0.040732, loss_ce: 0.021313
2021-12-16 16:07:16,976 iteration 4010 : loss : 0.045452, loss_ce: 0.022485
2021-12-16 16:07:18,390 iteration 4011 : loss : 0.029600, loss_ce: 0.010889
2021-12-16 16:07:19,931 iteration 4012 : loss : 0.035360, loss_ce: 0.016908
 59%|███████████████▉           | 236/400 [1:47:25<1:15:38, 27.67s/it]2021-12-16 16:07:21,518 iteration 4013 : loss : 0.044630, loss_ce: 0.014962
2021-12-16 16:07:22,919 iteration 4014 : loss : 0.049065, loss_ce: 0.017504
2021-12-16 16:07:24,431 iteration 4015 : loss : 0.062681, loss_ce: 0.028321
2021-12-16 16:07:25,913 iteration 4016 : loss : 0.035164, loss_ce: 0.015644
2021-12-16 16:07:27,410 iteration 4017 : loss : 0.040513, loss_ce: 0.015959
2021-12-16 16:07:28,826 iteration 4018 : loss : 0.036888, loss_ce: 0.015087
2021-12-16 16:07:30,267 iteration 4019 : loss : 0.037167, loss_ce: 0.018101
2021-12-16 16:07:31,684 iteration 4020 : loss : 0.027721, loss_ce: 0.015491
2021-12-16 16:07:33,170 iteration 4021 : loss : 0.028777, loss_ce: 0.014419
2021-12-16 16:07:34,668 iteration 4022 : loss : 0.053708, loss_ce: 0.029068
2021-12-16 16:07:36,116 iteration 4023 : loss : 0.035812, loss_ce: 0.014729
2021-12-16 16:07:37,503 iteration 4024 : loss : 0.027981, loss_ce: 0.012342
2021-12-16 16:07:38,919 iteration 4025 : loss : 0.028535, loss_ce: 0.011503
2021-12-16 16:07:40,410 iteration 4026 : loss : 0.028804, loss_ce: 0.014011
2021-12-16 16:07:41,881 iteration 4027 : loss : 0.043133, loss_ce: 0.015919
2021-12-16 16:07:43,389 iteration 4028 : loss : 0.045798, loss_ce: 0.016227
2021-12-16 16:07:44,812 iteration 4029 : loss : 0.025828, loss_ce: 0.012363
 59%|███████████████▉           | 237/400 [1:47:50<1:12:54, 26.84s/it]2021-12-16 16:07:46,374 iteration 4030 : loss : 0.043195, loss_ce: 0.020166
2021-12-16 16:07:47,849 iteration 4031 : loss : 0.060587, loss_ce: 0.022578
2021-12-16 16:07:49,298 iteration 4032 : loss : 0.048407, loss_ce: 0.024897
2021-12-16 16:07:50,770 iteration 4033 : loss : 0.044547, loss_ce: 0.016536
2021-12-16 16:07:52,166 iteration 4034 : loss : 0.042439, loss_ce: 0.016171
2021-12-16 16:07:53,613 iteration 4035 : loss : 0.036667, loss_ce: 0.013323
2021-12-16 16:07:55,129 iteration 4036 : loss : 0.040152, loss_ce: 0.014176
2021-12-16 16:07:56,544 iteration 4037 : loss : 0.027445, loss_ce: 0.014103
2021-12-16 16:07:58,060 iteration 4038 : loss : 0.045902, loss_ce: 0.014860
2021-12-16 16:07:59,583 iteration 4039 : loss : 0.041346, loss_ce: 0.017121
2021-12-16 16:08:01,103 iteration 4040 : loss : 0.048419, loss_ce: 0.021360
2021-12-16 16:08:02,606 iteration 4041 : loss : 0.037804, loss_ce: 0.014118
2021-12-16 16:08:04,033 iteration 4042 : loss : 0.030901, loss_ce: 0.012813
2021-12-16 16:08:05,526 iteration 4043 : loss : 0.185162, loss_ce: 0.012412
2021-12-16 16:08:06,973 iteration 4044 : loss : 0.032315, loss_ce: 0.015019
2021-12-16 16:08:08,443 iteration 4045 : loss : 0.037557, loss_ce: 0.019659
2021-12-16 16:08:10,000 iteration 4046 : loss : 0.042963, loss_ce: 0.021374
 60%|████████████████           | 238/400 [1:48:15<1:11:06, 26.34s/it]2021-12-16 16:08:11,589 iteration 4047 : loss : 0.047786, loss_ce: 0.022553
2021-12-16 16:08:13,099 iteration 4048 : loss : 0.042028, loss_ce: 0.020674
2021-12-16 16:08:14,532 iteration 4049 : loss : 0.032213, loss_ce: 0.014950
2021-12-16 16:08:16,030 iteration 4050 : loss : 0.059619, loss_ce: 0.024803
2021-12-16 16:08:17,593 iteration 4051 : loss : 0.078596, loss_ce: 0.016873
2021-12-16 16:08:18,985 iteration 4052 : loss : 0.035303, loss_ce: 0.015325
2021-12-16 16:08:20,392 iteration 4053 : loss : 0.034472, loss_ce: 0.014581
2021-12-16 16:08:21,792 iteration 4054 : loss : 0.038722, loss_ce: 0.012764
2021-12-16 16:08:23,224 iteration 4055 : loss : 0.034236, loss_ce: 0.016881
2021-12-16 16:08:24,688 iteration 4056 : loss : 0.048919, loss_ce: 0.024336
2021-12-16 16:08:26,095 iteration 4057 : loss : 0.029055, loss_ce: 0.009179
2021-12-16 16:08:27,539 iteration 4058 : loss : 0.038190, loss_ce: 0.014377
2021-12-16 16:08:29,106 iteration 4059 : loss : 0.050804, loss_ce: 0.023753
2021-12-16 16:08:30,575 iteration 4060 : loss : 0.061537, loss_ce: 0.028619
2021-12-16 16:08:32,033 iteration 4061 : loss : 0.042408, loss_ce: 0.021101
2021-12-16 16:08:33,519 iteration 4062 : loss : 0.072553, loss_ce: 0.033332
2021-12-16 16:08:34,998 iteration 4063 : loss : 0.060925, loss_ce: 0.021101
 60%|████████████████▏          | 239/400 [1:48:40<1:09:35, 25.94s/it]2021-12-16 16:08:36,493 iteration 4064 : loss : 0.038146, loss_ce: 0.011449
2021-12-16 16:08:37,928 iteration 4065 : loss : 0.033066, loss_ce: 0.014391
2021-12-16 16:08:39,451 iteration 4066 : loss : 0.062733, loss_ce: 0.021974
2021-12-16 16:08:40,866 iteration 4067 : loss : 0.035171, loss_ce: 0.017264
2021-12-16 16:08:42,316 iteration 4068 : loss : 0.040594, loss_ce: 0.017894
2021-12-16 16:08:43,798 iteration 4069 : loss : 0.030117, loss_ce: 0.013636
2021-12-16 16:08:45,311 iteration 4070 : loss : 0.036717, loss_ce: 0.015146
2021-12-16 16:08:46,838 iteration 4071 : loss : 0.052840, loss_ce: 0.019912
2021-12-16 16:08:48,291 iteration 4072 : loss : 0.031276, loss_ce: 0.010959
2021-12-16 16:08:49,710 iteration 4073 : loss : 0.029192, loss_ce: 0.011454
2021-12-16 16:08:51,163 iteration 4074 : loss : 0.044872, loss_ce: 0.024234
2021-12-16 16:08:52,693 iteration 4075 : loss : 0.031582, loss_ce: 0.013570
2021-12-16 16:08:54,117 iteration 4076 : loss : 0.058149, loss_ce: 0.026701
2021-12-16 16:08:55,571 iteration 4077 : loss : 0.029584, loss_ce: 0.012520
2021-12-16 16:08:57,072 iteration 4078 : loss : 0.052161, loss_ce: 0.020655
2021-12-16 16:08:58,561 iteration 4079 : loss : 0.027729, loss_ce: 0.013886
2021-12-16 16:08:58,561 Training Data Eval:
2021-12-16 16:09:06,082   Average segmentation loss on training set: 0.0182
2021-12-16 16:09:06,083 Validation Data Eval:
2021-12-16 16:09:08,686   Average segmentation loss on validation set: 0.0966
2021-12-16 16:09:10,245 iteration 4080 : loss : 0.040463, loss_ce: 0.018569
 60%|████████████████▏          | 240/400 [1:49:16<1:16:37, 28.73s/it]2021-12-16 16:09:11,794 iteration 4081 : loss : 0.062315, loss_ce: 0.027184
2021-12-16 16:09:13,269 iteration 4082 : loss : 0.046226, loss_ce: 0.022382
2021-12-16 16:09:14,711 iteration 4083 : loss : 0.028796, loss_ce: 0.014215
2021-12-16 16:09:16,197 iteration 4084 : loss : 0.028795, loss_ce: 0.010125
2021-12-16 16:09:17,648 iteration 4085 : loss : 0.030149, loss_ce: 0.010631
2021-12-16 16:09:19,231 iteration 4086 : loss : 0.061242, loss_ce: 0.024344
2021-12-16 16:09:20,704 iteration 4087 : loss : 0.071023, loss_ce: 0.015469
2021-12-16 16:09:22,085 iteration 4088 : loss : 0.031462, loss_ce: 0.016431
2021-12-16 16:09:23,553 iteration 4089 : loss : 0.047162, loss_ce: 0.017728
2021-12-16 16:09:24,925 iteration 4090 : loss : 0.029994, loss_ce: 0.011237
2021-12-16 16:09:26,381 iteration 4091 : loss : 0.054103, loss_ce: 0.022586
2021-12-16 16:09:27,872 iteration 4092 : loss : 0.026775, loss_ce: 0.012122
2021-12-16 16:09:29,354 iteration 4093 : loss : 0.058196, loss_ce: 0.023390
2021-12-16 16:09:30,792 iteration 4094 : loss : 0.043200, loss_ce: 0.016380
2021-12-16 16:09:32,263 iteration 4095 : loss : 0.065453, loss_ce: 0.033783
2021-12-16 16:09:33,673 iteration 4096 : loss : 0.033845, loss_ce: 0.019882
2021-12-16 16:09:35,108 iteration 4097 : loss : 0.039045, loss_ce: 0.018250
 60%|████████████████▎          | 241/400 [1:49:40<1:13:03, 27.57s/it]2021-12-16 16:09:36,583 iteration 4098 : loss : 0.030230, loss_ce: 0.012965
2021-12-16 16:09:38,010 iteration 4099 : loss : 0.039376, loss_ce: 0.013034
2021-12-16 16:09:39,472 iteration 4100 : loss : 0.032695, loss_ce: 0.012657
2021-12-16 16:09:40,973 iteration 4101 : loss : 0.044796, loss_ce: 0.016001
2021-12-16 16:09:42,493 iteration 4102 : loss : 0.058385, loss_ce: 0.024791
2021-12-16 16:09:43,977 iteration 4103 : loss : 0.045323, loss_ce: 0.019773
2021-12-16 16:09:45,465 iteration 4104 : loss : 0.057947, loss_ce: 0.029147
2021-12-16 16:09:46,944 iteration 4105 : loss : 0.032052, loss_ce: 0.014786
2021-12-16 16:09:48,384 iteration 4106 : loss : 0.045637, loss_ce: 0.022358
2021-12-16 16:09:49,849 iteration 4107 : loss : 0.025510, loss_ce: 0.012099
2021-12-16 16:09:51,289 iteration 4108 : loss : 0.034355, loss_ce: 0.014844
2021-12-16 16:09:52,676 iteration 4109 : loss : 0.032925, loss_ce: 0.012409
2021-12-16 16:09:54,168 iteration 4110 : loss : 0.053623, loss_ce: 0.022849
2021-12-16 16:09:55,778 iteration 4111 : loss : 0.049953, loss_ce: 0.025396
2021-12-16 16:09:57,217 iteration 4112 : loss : 0.036336, loss_ce: 0.014124
2021-12-16 16:09:58,719 iteration 4113 : loss : 0.054119, loss_ce: 0.019366
2021-12-16 16:10:00,160 iteration 4114 : loss : 0.026756, loss_ce: 0.013224
 60%|████████████████▎          | 242/400 [1:50:05<1:10:36, 26.81s/it]2021-12-16 16:10:01,621 iteration 4115 : loss : 0.034297, loss_ce: 0.017720
2021-12-16 16:10:03,162 iteration 4116 : loss : 0.037420, loss_ce: 0.016735
2021-12-16 16:10:04,568 iteration 4117 : loss : 0.026677, loss_ce: 0.012357
2021-12-16 16:10:06,092 iteration 4118 : loss : 0.065955, loss_ce: 0.025474
2021-12-16 16:10:07,665 iteration 4119 : loss : 0.053948, loss_ce: 0.018325
2021-12-16 16:10:09,128 iteration 4120 : loss : 0.046316, loss_ce: 0.015237
2021-12-16 16:10:10,524 iteration 4121 : loss : 0.028747, loss_ce: 0.011988
2021-12-16 16:10:11,947 iteration 4122 : loss : 0.056242, loss_ce: 0.018946
2021-12-16 16:10:13,355 iteration 4123 : loss : 0.019549, loss_ce: 0.009713
2021-12-16 16:10:14,876 iteration 4124 : loss : 0.039478, loss_ce: 0.020632
2021-12-16 16:10:16,356 iteration 4125 : loss : 0.047831, loss_ce: 0.027597
2021-12-16 16:10:17,830 iteration 4126 : loss : 0.034489, loss_ce: 0.015432
2021-12-16 16:10:19,261 iteration 4127 : loss : 0.023538, loss_ce: 0.012561
2021-12-16 16:10:20,837 iteration 4128 : loss : 0.074844, loss_ce: 0.020527
2021-12-16 16:10:22,225 iteration 4129 : loss : 0.041496, loss_ce: 0.012336
2021-12-16 16:10:23,603 iteration 4130 : loss : 0.026367, loss_ce: 0.010345
2021-12-16 16:10:25,045 iteration 4131 : loss : 0.034214, loss_ce: 0.019251
 61%|████████████████▍          | 243/400 [1:50:30<1:08:39, 26.24s/it]2021-12-16 16:10:26,596 iteration 4132 : loss : 0.043614, loss_ce: 0.015977
2021-12-16 16:10:28,085 iteration 4133 : loss : 0.036648, loss_ce: 0.013456
2021-12-16 16:10:29,587 iteration 4134 : loss : 0.054257, loss_ce: 0.024415
2021-12-16 16:10:30,958 iteration 4135 : loss : 0.032773, loss_ce: 0.015342
2021-12-16 16:10:32,412 iteration 4136 : loss : 0.051678, loss_ce: 0.026232
2021-12-16 16:10:33,799 iteration 4137 : loss : 0.025020, loss_ce: 0.011138
2021-12-16 16:10:35,294 iteration 4138 : loss : 0.035564, loss_ce: 0.016543
2021-12-16 16:10:36,785 iteration 4139 : loss : 0.034816, loss_ce: 0.017425
2021-12-16 16:10:38,252 iteration 4140 : loss : 0.024922, loss_ce: 0.012566
2021-12-16 16:10:39,723 iteration 4141 : loss : 0.026258, loss_ce: 0.010922
2021-12-16 16:10:41,260 iteration 4142 : loss : 0.046836, loss_ce: 0.016576
2021-12-16 16:10:42,633 iteration 4143 : loss : 0.035538, loss_ce: 0.012725
2021-12-16 16:10:44,021 iteration 4144 : loss : 0.026549, loss_ce: 0.007650
2021-12-16 16:10:45,530 iteration 4145 : loss : 0.044036, loss_ce: 0.019856
2021-12-16 16:10:46,996 iteration 4146 : loss : 0.031285, loss_ce: 0.014188
2021-12-16 16:10:48,474 iteration 4147 : loss : 0.037873, loss_ce: 0.016258
2021-12-16 16:10:49,902 iteration 4148 : loss : 0.035747, loss_ce: 0.014474
 61%|████████████████▍          | 244/400 [1:50:55<1:07:08, 25.82s/it]2021-12-16 16:10:51,303 iteration 4149 : loss : 0.030862, loss_ce: 0.012980
2021-12-16 16:10:52,767 iteration 4150 : loss : 0.030808, loss_ce: 0.011599
2021-12-16 16:10:54,273 iteration 4151 : loss : 0.051502, loss_ce: 0.020871
2021-12-16 16:10:55,738 iteration 4152 : loss : 0.034444, loss_ce: 0.015618
2021-12-16 16:10:57,127 iteration 4153 : loss : 0.028964, loss_ce: 0.012798
2021-12-16 16:10:58,606 iteration 4154 : loss : 0.034081, loss_ce: 0.014816
2021-12-16 16:11:00,058 iteration 4155 : loss : 0.028499, loss_ce: 0.010610
2021-12-16 16:11:01,459 iteration 4156 : loss : 0.024108, loss_ce: 0.010241
2021-12-16 16:11:02,977 iteration 4157 : loss : 0.040013, loss_ce: 0.021933
2021-12-16 16:11:04,407 iteration 4158 : loss : 0.029284, loss_ce: 0.012523
2021-12-16 16:11:05,840 iteration 4159 : loss : 0.033686, loss_ce: 0.015493
2021-12-16 16:11:07,408 iteration 4160 : loss : 0.041482, loss_ce: 0.017489
2021-12-16 16:11:08,934 iteration 4161 : loss : 0.039889, loss_ce: 0.014406
2021-12-16 16:11:10,467 iteration 4162 : loss : 0.052965, loss_ce: 0.020199
2021-12-16 16:11:11,963 iteration 4163 : loss : 0.040591, loss_ce: 0.018645
2021-12-16 16:11:13,407 iteration 4164 : loss : 0.026591, loss_ce: 0.012056
2021-12-16 16:11:13,407 Training Data Eval:
2021-12-16 16:11:20,916   Average segmentation loss on training set: 0.0187
2021-12-16 16:11:20,917 Validation Data Eval:
2021-12-16 16:11:23,516   Average segmentation loss on validation set: 0.1000
2021-12-16 16:11:25,030 iteration 4165 : loss : 0.047749, loss_ce: 0.017692
 61%|████████████████▌          | 245/400 [1:51:30<1:13:55, 28.61s/it]2021-12-16 16:11:26,526 iteration 4166 : loss : 0.025332, loss_ce: 0.011294
2021-12-16 16:11:27,911 iteration 4167 : loss : 0.036473, loss_ce: 0.012549
2021-12-16 16:11:29,330 iteration 4168 : loss : 0.027037, loss_ce: 0.012201
2021-12-16 16:11:30,754 iteration 4169 : loss : 0.027295, loss_ce: 0.014685
2021-12-16 16:11:32,342 iteration 4170 : loss : 0.044516, loss_ce: 0.022543
2021-12-16 16:11:33,739 iteration 4171 : loss : 0.034371, loss_ce: 0.012187
2021-12-16 16:11:35,186 iteration 4172 : loss : 0.039478, loss_ce: 0.020475
2021-12-16 16:11:36,687 iteration 4173 : loss : 0.032496, loss_ce: 0.011292
2021-12-16 16:11:38,133 iteration 4174 : loss : 0.032063, loss_ce: 0.011122
2021-12-16 16:11:39,547 iteration 4175 : loss : 0.029023, loss_ce: 0.013659
2021-12-16 16:11:40,995 iteration 4176 : loss : 0.037484, loss_ce: 0.018143
2021-12-16 16:11:42,494 iteration 4177 : loss : 0.032650, loss_ce: 0.011138
2021-12-16 16:11:43,907 iteration 4178 : loss : 0.038167, loss_ce: 0.016552
2021-12-16 16:11:45,341 iteration 4179 : loss : 0.040854, loss_ce: 0.018665
2021-12-16 16:11:46,768 iteration 4180 : loss : 0.031113, loss_ce: 0.011401
2021-12-16 16:11:48,215 iteration 4181 : loss : 0.050637, loss_ce: 0.026499
2021-12-16 16:11:49,663 iteration 4182 : loss : 0.034948, loss_ce: 0.011306
 62%|████████████████▌          | 246/400 [1:51:55<1:10:22, 27.42s/it]2021-12-16 16:11:51,171 iteration 4183 : loss : 0.038122, loss_ce: 0.015696
2021-12-16 16:11:52,658 iteration 4184 : loss : 0.039263, loss_ce: 0.018061
2021-12-16 16:11:54,112 iteration 4185 : loss : 0.037995, loss_ce: 0.019231
2021-12-16 16:11:55,545 iteration 4186 : loss : 0.046642, loss_ce: 0.017567
2021-12-16 16:11:57,049 iteration 4187 : loss : 0.047660, loss_ce: 0.018088
2021-12-16 16:11:58,462 iteration 4188 : loss : 0.037680, loss_ce: 0.014624
2021-12-16 16:12:00,018 iteration 4189 : loss : 0.033041, loss_ce: 0.014718
2021-12-16 16:12:01,525 iteration 4190 : loss : 0.042388, loss_ce: 0.020541
2021-12-16 16:12:03,044 iteration 4191 : loss : 0.043124, loss_ce: 0.020835
2021-12-16 16:12:04,397 iteration 4192 : loss : 0.024861, loss_ce: 0.009793
2021-12-16 16:12:05,867 iteration 4193 : loss : 0.050326, loss_ce: 0.026903
2021-12-16 16:12:07,363 iteration 4194 : loss : 0.033918, loss_ce: 0.013283
2021-12-16 16:12:08,797 iteration 4195 : loss : 0.039574, loss_ce: 0.013732
2021-12-16 16:12:10,292 iteration 4196 : loss : 0.030736, loss_ce: 0.015113
2021-12-16 16:12:11,744 iteration 4197 : loss : 0.035077, loss_ce: 0.012102
2021-12-16 16:12:13,195 iteration 4198 : loss : 0.029387, loss_ce: 0.013227
2021-12-16 16:12:14,596 iteration 4199 : loss : 0.029321, loss_ce: 0.013295
 62%|████████████████▋          | 247/400 [1:52:20<1:08:01, 26.68s/it]2021-12-16 16:12:16,120 iteration 4200 : loss : 0.041328, loss_ce: 0.018018
2021-12-16 16:12:17,595 iteration 4201 : loss : 0.042284, loss_ce: 0.019117
2021-12-16 16:12:19,081 iteration 4202 : loss : 0.027406, loss_ce: 0.013978
2021-12-16 16:12:20,638 iteration 4203 : loss : 0.039433, loss_ce: 0.017546
2021-12-16 16:12:22,067 iteration 4204 : loss : 0.033600, loss_ce: 0.016946
2021-12-16 16:12:23,515 iteration 4205 : loss : 0.033832, loss_ce: 0.016096
2021-12-16 16:12:25,095 iteration 4206 : loss : 0.046082, loss_ce: 0.016220
2021-12-16 16:12:26,584 iteration 4207 : loss : 0.052038, loss_ce: 0.021393
2021-12-16 16:12:27,942 iteration 4208 : loss : 0.018792, loss_ce: 0.008701
2021-12-16 16:12:29,364 iteration 4209 : loss : 0.032929, loss_ce: 0.016835
2021-12-16 16:12:30,792 iteration 4210 : loss : 0.035236, loss_ce: 0.016474
2021-12-16 16:12:32,261 iteration 4211 : loss : 0.042951, loss_ce: 0.020287
2021-12-16 16:12:33,767 iteration 4212 : loss : 0.036271, loss_ce: 0.015748
2021-12-16 16:12:35,181 iteration 4213 : loss : 0.045243, loss_ce: 0.015095
2021-12-16 16:12:36,664 iteration 4214 : loss : 0.052058, loss_ce: 0.018051
2021-12-16 16:12:38,109 iteration 4215 : loss : 0.045052, loss_ce: 0.019780
2021-12-16 16:12:39,565 iteration 4216 : loss : 0.033503, loss_ce: 0.013855
 62%|████████████████▋          | 248/400 [1:52:45<1:06:16, 26.16s/it]2021-12-16 16:12:41,106 iteration 4217 : loss : 0.045343, loss_ce: 0.017756
2021-12-16 16:12:42,533 iteration 4218 : loss : 0.036996, loss_ce: 0.014887
2021-12-16 16:12:43,948 iteration 4219 : loss : 0.030750, loss_ce: 0.014499
2021-12-16 16:12:45,318 iteration 4220 : loss : 0.039407, loss_ce: 0.012385
2021-12-16 16:12:46,865 iteration 4221 : loss : 0.053011, loss_ce: 0.025680
2021-12-16 16:12:48,398 iteration 4222 : loss : 0.037253, loss_ce: 0.011820
2021-12-16 16:12:49,811 iteration 4223 : loss : 0.026267, loss_ce: 0.012150
2021-12-16 16:12:51,321 iteration 4224 : loss : 0.041491, loss_ce: 0.012830
2021-12-16 16:12:52,808 iteration 4225 : loss : 0.031849, loss_ce: 0.010407
2021-12-16 16:12:54,316 iteration 4226 : loss : 0.027382, loss_ce: 0.013389
2021-12-16 16:12:55,800 iteration 4227 : loss : 0.026148, loss_ce: 0.012297
2021-12-16 16:12:57,222 iteration 4228 : loss : 0.035543, loss_ce: 0.019201
2021-12-16 16:12:58,675 iteration 4229 : loss : 0.030287, loss_ce: 0.012897
2021-12-16 16:13:00,115 iteration 4230 : loss : 0.053164, loss_ce: 0.026405
2021-12-16 16:13:01,614 iteration 4231 : loss : 0.036396, loss_ce: 0.015405
2021-12-16 16:13:03,107 iteration 4232 : loss : 0.051901, loss_ce: 0.020562
2021-12-16 16:13:04,553 iteration 4233 : loss : 0.053666, loss_ce: 0.029456
 62%|████████████████▊          | 249/400 [1:53:10<1:04:57, 25.81s/it]2021-12-16 16:13:05,957 iteration 4234 : loss : 0.034742, loss_ce: 0.009990
2021-12-16 16:13:07,353 iteration 4235 : loss : 0.020359, loss_ce: 0.009148
2021-12-16 16:13:08,846 iteration 4236 : loss : 0.036774, loss_ce: 0.015696
2021-12-16 16:13:10,263 iteration 4237 : loss : 0.028128, loss_ce: 0.012388
2021-12-16 16:13:11,717 iteration 4238 : loss : 0.038527, loss_ce: 0.020929
2021-12-16 16:13:13,314 iteration 4239 : loss : 0.083972, loss_ce: 0.033075
2021-12-16 16:13:14,778 iteration 4240 : loss : 0.035079, loss_ce: 0.013559
2021-12-16 16:13:16,144 iteration 4241 : loss : 0.028970, loss_ce: 0.014676
2021-12-16 16:13:17,613 iteration 4242 : loss : 0.032038, loss_ce: 0.012021
2021-12-16 16:13:19,053 iteration 4243 : loss : 0.033324, loss_ce: 0.015477
2021-12-16 16:13:20,439 iteration 4244 : loss : 0.022929, loss_ce: 0.013477
2021-12-16 16:13:21,950 iteration 4245 : loss : 0.048565, loss_ce: 0.024863
2021-12-16 16:13:23,476 iteration 4246 : loss : 0.061308, loss_ce: 0.019666
2021-12-16 16:13:24,948 iteration 4247 : loss : 0.035582, loss_ce: 0.017303
2021-12-16 16:13:26,332 iteration 4248 : loss : 0.044719, loss_ce: 0.020626
2021-12-16 16:13:27,850 iteration 4249 : loss : 0.042841, loss_ce: 0.014704
2021-12-16 16:13:27,850 Training Data Eval:
2021-12-16 16:13:35,388   Average segmentation loss on training set: 0.0182
2021-12-16 16:13:35,389 Validation Data Eval:
2021-12-16 16:13:37,991   Average segmentation loss on validation set: 0.0979
2021-12-16 16:13:39,459 iteration 4250 : loss : 0.046152, loss_ce: 0.019366
 62%|████████████████▉          | 250/400 [1:53:45<1:11:20, 28.54s/it]2021-12-16 16:13:41,026 iteration 4251 : loss : 0.062328, loss_ce: 0.020302
2021-12-16 16:13:42,531 iteration 4252 : loss : 0.045491, loss_ce: 0.024453
2021-12-16 16:13:44,002 iteration 4253 : loss : 0.040236, loss_ce: 0.016841
2021-12-16 16:13:45,511 iteration 4254 : loss : 0.031775, loss_ce: 0.014289
2021-12-16 16:13:47,022 iteration 4255 : loss : 0.037951, loss_ce: 0.014804
2021-12-16 16:13:48,382 iteration 4256 : loss : 0.032080, loss_ce: 0.016100
2021-12-16 16:13:49,851 iteration 4257 : loss : 0.037982, loss_ce: 0.017239
2021-12-16 16:13:51,248 iteration 4258 : loss : 0.044492, loss_ce: 0.016617
2021-12-16 16:13:52,733 iteration 4259 : loss : 0.041869, loss_ce: 0.021116
2021-12-16 16:13:54,208 iteration 4260 : loss : 0.051335, loss_ce: 0.020025
2021-12-16 16:13:55,693 iteration 4261 : loss : 0.038153, loss_ce: 0.016815
2021-12-16 16:13:57,120 iteration 4262 : loss : 0.028236, loss_ce: 0.014060
2021-12-16 16:13:58,599 iteration 4263 : loss : 0.048296, loss_ce: 0.024639
2021-12-16 16:14:00,105 iteration 4264 : loss : 0.051825, loss_ce: 0.024288
2021-12-16 16:14:01,543 iteration 4265 : loss : 0.059633, loss_ce: 0.015376
2021-12-16 16:14:03,009 iteration 4266 : loss : 0.037184, loss_ce: 0.014393
2021-12-16 16:14:04,497 iteration 4267 : loss : 0.032617, loss_ce: 0.013039
 63%|████████████████▉          | 251/400 [1:54:10<1:08:15, 27.49s/it]2021-12-16 16:14:05,990 iteration 4268 : loss : 0.031522, loss_ce: 0.009547
2021-12-16 16:14:07,425 iteration 4269 : loss : 0.037121, loss_ce: 0.013186
2021-12-16 16:14:08,848 iteration 4270 : loss : 0.033631, loss_ce: 0.018432
2021-12-16 16:14:10,246 iteration 4271 : loss : 0.023168, loss_ce: 0.010690
2021-12-16 16:14:11,707 iteration 4272 : loss : 0.033352, loss_ce: 0.019052
2021-12-16 16:14:13,101 iteration 4273 : loss : 0.024129, loss_ce: 0.011527
2021-12-16 16:14:14,647 iteration 4274 : loss : 0.038745, loss_ce: 0.020055
2021-12-16 16:14:16,097 iteration 4275 : loss : 0.027463, loss_ce: 0.011835
2021-12-16 16:14:17,590 iteration 4276 : loss : 0.036009, loss_ce: 0.012396
2021-12-16 16:14:19,093 iteration 4277 : loss : 0.044244, loss_ce: 0.015368
2021-12-16 16:14:20,596 iteration 4278 : loss : 0.052440, loss_ce: 0.020635
2021-12-16 16:14:22,031 iteration 4279 : loss : 0.037632, loss_ce: 0.023051
2021-12-16 16:14:23,492 iteration 4280 : loss : 0.042549, loss_ce: 0.015836
2021-12-16 16:14:24,955 iteration 4281 : loss : 0.036215, loss_ce: 0.013164
2021-12-16 16:14:26,338 iteration 4282 : loss : 0.028220, loss_ce: 0.013312
2021-12-16 16:14:27,768 iteration 4283 : loss : 0.046349, loss_ce: 0.017005
2021-12-16 16:14:29,187 iteration 4284 : loss : 0.028851, loss_ce: 0.013751
 63%|█████████████████          | 252/400 [1:54:35<1:05:43, 26.65s/it]2021-12-16 16:14:30,631 iteration 4285 : loss : 0.037735, loss_ce: 0.013918
2021-12-16 16:14:32,144 iteration 4286 : loss : 0.035828, loss_ce: 0.016145
2021-12-16 16:14:33,555 iteration 4287 : loss : 0.036647, loss_ce: 0.019714
2021-12-16 16:14:34,952 iteration 4288 : loss : 0.040149, loss_ce: 0.023384
2021-12-16 16:14:36,406 iteration 4289 : loss : 0.032308, loss_ce: 0.015081
2021-12-16 16:14:37,842 iteration 4290 : loss : 0.049328, loss_ce: 0.012840
2021-12-16 16:14:39,319 iteration 4291 : loss : 0.045171, loss_ce: 0.018607
2021-12-16 16:14:40,842 iteration 4292 : loss : 0.039239, loss_ce: 0.019574
2021-12-16 16:14:42,304 iteration 4293 : loss : 0.047355, loss_ce: 0.016010
2021-12-16 16:14:43,721 iteration 4294 : loss : 0.036518, loss_ce: 0.012961
2021-12-16 16:14:45,270 iteration 4295 : loss : 0.037937, loss_ce: 0.015309
2021-12-16 16:14:46,728 iteration 4296 : loss : 0.035782, loss_ce: 0.012268
2021-12-16 16:14:48,211 iteration 4297 : loss : 0.047689, loss_ce: 0.017767
2021-12-16 16:14:49,647 iteration 4298 : loss : 0.031710, loss_ce: 0.016667
2021-12-16 16:14:51,153 iteration 4299 : loss : 0.037045, loss_ce: 0.021430
2021-12-16 16:14:52,697 iteration 4300 : loss : 0.058104, loss_ce: 0.025862
2021-12-16 16:14:54,229 iteration 4301 : loss : 0.033008, loss_ce: 0.014079
 63%|█████████████████          | 253/400 [1:55:00<1:04:06, 26.17s/it]2021-12-16 16:14:55,766 iteration 4302 : loss : 0.043384, loss_ce: 0.019032
2021-12-16 16:14:57,269 iteration 4303 : loss : 0.064382, loss_ce: 0.015593
2021-12-16 16:14:58,661 iteration 4304 : loss : 0.032575, loss_ce: 0.013684
2021-12-16 16:15:00,083 iteration 4305 : loss : 0.030520, loss_ce: 0.013163
2021-12-16 16:15:01,524 iteration 4306 : loss : 0.028634, loss_ce: 0.010716
2021-12-16 16:15:02,921 iteration 4307 : loss : 0.024263, loss_ce: 0.012044
2021-12-16 16:15:04,404 iteration 4308 : loss : 0.032786, loss_ce: 0.013808
2021-12-16 16:15:05,939 iteration 4309 : loss : 0.055792, loss_ce: 0.023280
2021-12-16 16:15:07,400 iteration 4310 : loss : 0.032490, loss_ce: 0.014112
2021-12-16 16:15:08,823 iteration 4311 : loss : 0.047794, loss_ce: 0.021836
2021-12-16 16:15:10,247 iteration 4312 : loss : 0.034344, loss_ce: 0.013165
2021-12-16 16:15:11,670 iteration 4313 : loss : 0.031711, loss_ce: 0.017906
2021-12-16 16:15:13,124 iteration 4314 : loss : 0.035117, loss_ce: 0.013714
2021-12-16 16:15:14,638 iteration 4315 : loss : 0.036138, loss_ce: 0.014506
2021-12-16 16:15:16,050 iteration 4316 : loss : 0.046434, loss_ce: 0.017337
2021-12-16 16:15:17,554 iteration 4317 : loss : 0.027578, loss_ce: 0.012429
2021-12-16 16:15:18,938 iteration 4318 : loss : 0.030331, loss_ce: 0.014255
 64%|█████████████████▏         | 254/400 [1:55:24<1:02:36, 25.73s/it]2021-12-16 16:15:20,454 iteration 4319 : loss : 0.045309, loss_ce: 0.016905
2021-12-16 16:15:21,939 iteration 4320 : loss : 0.048273, loss_ce: 0.021138
2021-12-16 16:15:23,297 iteration 4321 : loss : 0.029560, loss_ce: 0.011039
2021-12-16 16:15:24,753 iteration 4322 : loss : 0.031206, loss_ce: 0.013228
2021-12-16 16:15:26,150 iteration 4323 : loss : 0.032064, loss_ce: 0.017047
2021-12-16 16:15:27,719 iteration 4324 : loss : 0.048051, loss_ce: 0.023422
2021-12-16 16:15:29,183 iteration 4325 : loss : 0.034439, loss_ce: 0.015875
2021-12-16 16:15:30,624 iteration 4326 : loss : 0.038869, loss_ce: 0.020679
2021-12-16 16:15:32,111 iteration 4327 : loss : 0.038557, loss_ce: 0.014318
2021-12-16 16:15:33,510 iteration 4328 : loss : 0.030555, loss_ce: 0.011924
2021-12-16 16:15:35,008 iteration 4329 : loss : 0.073584, loss_ce: 0.020478
2021-12-16 16:15:36,497 iteration 4330 : loss : 0.029984, loss_ce: 0.014470
2021-12-16 16:15:38,071 iteration 4331 : loss : 0.071601, loss_ce: 0.024292
2021-12-16 16:15:39,561 iteration 4332 : loss : 0.048036, loss_ce: 0.019158
2021-12-16 16:15:41,091 iteration 4333 : loss : 0.043262, loss_ce: 0.022411
2021-12-16 16:15:42,552 iteration 4334 : loss : 0.034466, loss_ce: 0.021343
2021-12-16 16:15:42,553 Training Data Eval:
2021-12-16 16:15:50,077   Average segmentation loss on training set: 0.0189
2021-12-16 16:15:50,078 Validation Data Eval:
2021-12-16 16:15:52,679   Average segmentation loss on validation set: 0.0945
2021-12-16 16:15:54,205 iteration 4335 : loss : 0.076984, loss_ce: 0.019761
 64%|█████████████████▏         | 255/400 [1:56:00<1:09:05, 28.59s/it]2021-12-16 16:15:55,594 iteration 4336 : loss : 0.023733, loss_ce: 0.012893
2021-12-16 16:15:57,142 iteration 4337 : loss : 0.046352, loss_ce: 0.021508
2021-12-16 16:15:58,591 iteration 4338 : loss : 0.029348, loss_ce: 0.012127
2021-12-16 16:15:59,990 iteration 4339 : loss : 0.031182, loss_ce: 0.012816
2021-12-16 16:16:01,486 iteration 4340 : loss : 0.044417, loss_ce: 0.020596
2021-12-16 16:16:02,884 iteration 4341 : loss : 0.027380, loss_ce: 0.010917
2021-12-16 16:16:04,399 iteration 4342 : loss : 0.042230, loss_ce: 0.015347
2021-12-16 16:16:05,886 iteration 4343 : loss : 0.042739, loss_ce: 0.015638
2021-12-16 16:16:07,352 iteration 4344 : loss : 0.033744, loss_ce: 0.019590
2021-12-16 16:16:08,881 iteration 4345 : loss : 0.055631, loss_ce: 0.024606
2021-12-16 16:16:10,266 iteration 4346 : loss : 0.032435, loss_ce: 0.011581
2021-12-16 16:16:11,747 iteration 4347 : loss : 0.036818, loss_ce: 0.018203
2021-12-16 16:16:13,174 iteration 4348 : loss : 0.026727, loss_ce: 0.014582
2021-12-16 16:16:14,544 iteration 4349 : loss : 0.023204, loss_ce: 0.008060
2021-12-16 16:16:15,914 iteration 4350 : loss : 0.041475, loss_ce: 0.014925
2021-12-16 16:16:17,402 iteration 4351 : loss : 0.035579, loss_ce: 0.012646
2021-12-16 16:16:18,861 iteration 4352 : loss : 0.043547, loss_ce: 0.021579
 64%|█████████████████▎         | 256/400 [1:56:24<1:05:47, 27.41s/it]2021-12-16 16:16:20,316 iteration 4353 : loss : 0.040748, loss_ce: 0.015681
2021-12-16 16:16:21,849 iteration 4354 : loss : 0.040222, loss_ce: 0.019488
2021-12-16 16:16:23,331 iteration 4355 : loss : 0.029594, loss_ce: 0.014397
2021-12-16 16:16:24,854 iteration 4356 : loss : 0.056559, loss_ce: 0.024420
2021-12-16 16:16:26,328 iteration 4357 : loss : 0.031243, loss_ce: 0.015931
2021-12-16 16:16:27,850 iteration 4358 : loss : 0.048856, loss_ce: 0.019340
2021-12-16 16:16:29,335 iteration 4359 : loss : 0.052586, loss_ce: 0.019849
2021-12-16 16:16:30,789 iteration 4360 : loss : 0.053569, loss_ce: 0.026969
2021-12-16 16:16:32,299 iteration 4361 : loss : 0.028023, loss_ce: 0.012424
2021-12-16 16:16:33,740 iteration 4362 : loss : 0.033695, loss_ce: 0.017204
2021-12-16 16:16:35,176 iteration 4363 : loss : 0.028704, loss_ce: 0.013700
2021-12-16 16:16:36,644 iteration 4364 : loss : 0.028724, loss_ce: 0.013079
2021-12-16 16:16:38,185 iteration 4365 : loss : 0.038435, loss_ce: 0.021106
2021-12-16 16:16:39,584 iteration 4366 : loss : 0.027322, loss_ce: 0.010088
2021-12-16 16:16:40,941 iteration 4367 : loss : 0.028749, loss_ce: 0.014130
2021-12-16 16:16:42,331 iteration 4368 : loss : 0.034748, loss_ce: 0.013947
2021-12-16 16:16:43,807 iteration 4369 : loss : 0.032662, loss_ce: 0.016068
 64%|█████████████████▎         | 257/400 [1:56:49<1:03:33, 26.67s/it]2021-12-16 16:16:45,317 iteration 4370 : loss : 0.056971, loss_ce: 0.022277
2021-12-16 16:16:46,794 iteration 4371 : loss : 0.043677, loss_ce: 0.023843
2021-12-16 16:16:48,273 iteration 4372 : loss : 0.033928, loss_ce: 0.016982
2021-12-16 16:16:49,744 iteration 4373 : loss : 0.033518, loss_ce: 0.020013
2021-12-16 16:16:51,235 iteration 4374 : loss : 0.036506, loss_ce: 0.015293
2021-12-16 16:16:52,735 iteration 4375 : loss : 0.046277, loss_ce: 0.022114
2021-12-16 16:16:54,182 iteration 4376 : loss : 0.038529, loss_ce: 0.015174
2021-12-16 16:16:55,618 iteration 4377 : loss : 0.042660, loss_ce: 0.016324
2021-12-16 16:16:57,016 iteration 4378 : loss : 0.031790, loss_ce: 0.013465
2021-12-16 16:16:58,419 iteration 4379 : loss : 0.035593, loss_ce: 0.014509
2021-12-16 16:16:59,803 iteration 4380 : loss : 0.028348, loss_ce: 0.011835
2021-12-16 16:17:01,301 iteration 4381 : loss : 0.047814, loss_ce: 0.018186
2021-12-16 16:17:02,752 iteration 4382 : loss : 0.094028, loss_ce: 0.021669
2021-12-16 16:17:04,176 iteration 4383 : loss : 0.039681, loss_ce: 0.014401
2021-12-16 16:17:05,692 iteration 4384 : loss : 0.038101, loss_ce: 0.018036
2021-12-16 16:17:07,238 iteration 4385 : loss : 0.042378, loss_ce: 0.017694
2021-12-16 16:17:08,652 iteration 4386 : loss : 0.027843, loss_ce: 0.013741
 64%|█████████████████▍         | 258/400 [1:57:14<1:01:49, 26.12s/it]2021-12-16 16:17:10,098 iteration 4387 : loss : 0.026409, loss_ce: 0.010780
2021-12-16 16:17:11,566 iteration 4388 : loss : 0.051158, loss_ce: 0.025694
2021-12-16 16:17:13,042 iteration 4389 : loss : 0.044056, loss_ce: 0.019057
2021-12-16 16:17:14,457 iteration 4390 : loss : 0.028029, loss_ce: 0.011702
2021-12-16 16:17:15,924 iteration 4391 : loss : 0.045191, loss_ce: 0.016778
2021-12-16 16:17:17,354 iteration 4392 : loss : 0.029809, loss_ce: 0.009671
2021-12-16 16:17:18,875 iteration 4393 : loss : 0.047098, loss_ce: 0.021057
2021-12-16 16:17:20,375 iteration 4394 : loss : 0.033782, loss_ce: 0.014480
2021-12-16 16:17:21,940 iteration 4395 : loss : 0.040538, loss_ce: 0.017960
2021-12-16 16:17:23,367 iteration 4396 : loss : 0.036010, loss_ce: 0.012927
2021-12-16 16:17:24,927 iteration 4397 : loss : 0.039723, loss_ce: 0.021712
2021-12-16 16:17:26,320 iteration 4398 : loss : 0.030917, loss_ce: 0.014134
2021-12-16 16:17:27,820 iteration 4399 : loss : 0.035227, loss_ce: 0.014615
2021-12-16 16:17:29,287 iteration 4400 : loss : 0.049644, loss_ce: 0.019257
2021-12-16 16:17:30,896 iteration 4401 : loss : 0.048888, loss_ce: 0.018193
2021-12-16 16:17:32,360 iteration 4402 : loss : 0.042339, loss_ce: 0.014668
2021-12-16 16:17:33,838 iteration 4403 : loss : 0.036576, loss_ce: 0.014700
 65%|█████████████████▍         | 259/400 [1:57:39<1:00:43, 25.84s/it]2021-12-16 16:17:35,291 iteration 4404 : loss : 0.035021, loss_ce: 0.016930
2021-12-16 16:17:36,791 iteration 4405 : loss : 0.030406, loss_ce: 0.015013
2021-12-16 16:17:38,276 iteration 4406 : loss : 0.042472, loss_ce: 0.017378
2021-12-16 16:17:39,799 iteration 4407 : loss : 0.053740, loss_ce: 0.021221
2021-12-16 16:17:41,229 iteration 4408 : loss : 0.026866, loss_ce: 0.012574
2021-12-16 16:17:42,722 iteration 4409 : loss : 0.050879, loss_ce: 0.022360
2021-12-16 16:17:44,333 iteration 4410 : loss : 0.075742, loss_ce: 0.030353
2021-12-16 16:17:45,830 iteration 4411 : loss : 0.042469, loss_ce: 0.021015
2021-12-16 16:17:47,301 iteration 4412 : loss : 0.038986, loss_ce: 0.016378
2021-12-16 16:17:48,783 iteration 4413 : loss : 0.040833, loss_ce: 0.015558
2021-12-16 16:17:50,180 iteration 4414 : loss : 0.031073, loss_ce: 0.012463
2021-12-16 16:17:51,680 iteration 4415 : loss : 0.032077, loss_ce: 0.012459
2021-12-16 16:17:53,202 iteration 4416 : loss : 0.041568, loss_ce: 0.015764
2021-12-16 16:17:54,687 iteration 4417 : loss : 0.037581, loss_ce: 0.015133
2021-12-16 16:17:56,157 iteration 4418 : loss : 0.037209, loss_ce: 0.018895
2021-12-16 16:17:57,669 iteration 4419 : loss : 0.041324, loss_ce: 0.014644
2021-12-16 16:17:57,670 Training Data Eval:
2021-12-16 16:18:05,178   Average segmentation loss on training set: 0.0182
2021-12-16 16:18:05,178 Validation Data Eval:
2021-12-16 16:18:07,773   Average segmentation loss on validation set: 0.1077
2021-12-16 16:18:09,190 iteration 4420 : loss : 0.027699, loss_ce: 0.014682
 65%|█████████████████▌         | 260/400 [1:58:15<1:06:57, 28.70s/it]2021-12-16 16:18:10,660 iteration 4421 : loss : 0.031188, loss_ce: 0.013081
2021-12-16 16:18:12,149 iteration 4422 : loss : 0.043728, loss_ce: 0.019535
2021-12-16 16:18:13,683 iteration 4423 : loss : 0.046779, loss_ce: 0.020563
2021-12-16 16:18:15,070 iteration 4424 : loss : 0.026493, loss_ce: 0.010307
2021-12-16 16:18:16,466 iteration 4425 : loss : 0.027995, loss_ce: 0.011638
2021-12-16 16:18:17,999 iteration 4426 : loss : 0.029141, loss_ce: 0.013850
2021-12-16 16:18:19,409 iteration 4427 : loss : 0.032892, loss_ce: 0.016999
2021-12-16 16:18:20,773 iteration 4428 : loss : 0.019065, loss_ce: 0.010530
2021-12-16 16:18:22,170 iteration 4429 : loss : 0.037508, loss_ce: 0.015166
2021-12-16 16:18:23,570 iteration 4430 : loss : 0.034763, loss_ce: 0.017337
2021-12-16 16:18:25,038 iteration 4431 : loss : 0.044369, loss_ce: 0.020858
2021-12-16 16:18:26,545 iteration 4432 : loss : 0.051508, loss_ce: 0.022164
2021-12-16 16:18:27,996 iteration 4433 : loss : 0.032419, loss_ce: 0.011054
2021-12-16 16:18:29,394 iteration 4434 : loss : 0.025732, loss_ce: 0.013550
2021-12-16 16:18:30,857 iteration 4435 : loss : 0.048607, loss_ce: 0.013866
2021-12-16 16:18:32,311 iteration 4436 : loss : 0.027590, loss_ce: 0.013573
2021-12-16 16:18:33,822 iteration 4437 : loss : 0.045424, loss_ce: 0.017449
 65%|█████████████████▌         | 261/400 [1:58:39<1:03:39, 27.48s/it]2021-12-16 16:18:35,408 iteration 4438 : loss : 0.043929, loss_ce: 0.014584
2021-12-16 16:18:36,877 iteration 4439 : loss : 0.037054, loss_ce: 0.015879
2021-12-16 16:18:38,331 iteration 4440 : loss : 0.036155, loss_ce: 0.016197
2021-12-16 16:18:39,905 iteration 4441 : loss : 0.049519, loss_ce: 0.019412
2021-12-16 16:18:41,411 iteration 4442 : loss : 0.044492, loss_ce: 0.024296
2021-12-16 16:18:42,891 iteration 4443 : loss : 0.054036, loss_ce: 0.021171
2021-12-16 16:18:44,274 iteration 4444 : loss : 0.031977, loss_ce: 0.012581
2021-12-16 16:18:45,727 iteration 4445 : loss : 0.037311, loss_ce: 0.019436
2021-12-16 16:18:47,223 iteration 4446 : loss : 0.032817, loss_ce: 0.015318
2021-12-16 16:18:48,652 iteration 4447 : loss : 0.025767, loss_ce: 0.010575
2021-12-16 16:18:50,126 iteration 4448 : loss : 0.046663, loss_ce: 0.019437
2021-12-16 16:18:51,585 iteration 4449 : loss : 0.051351, loss_ce: 0.023197
2021-12-16 16:18:53,113 iteration 4450 : loss : 0.037085, loss_ce: 0.015520
2021-12-16 16:18:54,553 iteration 4451 : loss : 0.026827, loss_ce: 0.011921
2021-12-16 16:18:56,031 iteration 4452 : loss : 0.027347, loss_ce: 0.013204
2021-12-16 16:18:57,465 iteration 4453 : loss : 0.037753, loss_ce: 0.015245
2021-12-16 16:18:58,904 iteration 4454 : loss : 0.045384, loss_ce: 0.020340
 66%|█████████████████▋         | 262/400 [1:59:04<1:01:32, 26.76s/it]2021-12-16 16:19:00,420 iteration 4455 : loss : 0.034199, loss_ce: 0.011561
2021-12-16 16:19:01,787 iteration 4456 : loss : 0.027570, loss_ce: 0.012135
2021-12-16 16:19:03,268 iteration 4457 : loss : 0.031195, loss_ce: 0.014247
2021-12-16 16:19:04,820 iteration 4458 : loss : 0.066560, loss_ce: 0.027779
2021-12-16 16:19:06,424 iteration 4459 : loss : 0.064615, loss_ce: 0.030170
2021-12-16 16:19:07,838 iteration 4460 : loss : 0.036092, loss_ce: 0.013468
2021-12-16 16:19:09,302 iteration 4461 : loss : 0.045020, loss_ce: 0.016725
2021-12-16 16:19:10,806 iteration 4462 : loss : 0.040272, loss_ce: 0.020914
2021-12-16 16:19:12,256 iteration 4463 : loss : 0.040176, loss_ce: 0.018180
2021-12-16 16:19:13,681 iteration 4464 : loss : 0.029141, loss_ce: 0.011491
2021-12-16 16:19:15,072 iteration 4465 : loss : 0.035429, loss_ce: 0.010675
2021-12-16 16:19:16,499 iteration 4466 : loss : 0.034820, loss_ce: 0.012612
2021-12-16 16:19:17,947 iteration 4467 : loss : 0.059749, loss_ce: 0.032737
2021-12-16 16:19:19,425 iteration 4468 : loss : 0.045781, loss_ce: 0.022314
2021-12-16 16:19:20,939 iteration 4469 : loss : 0.045210, loss_ce: 0.025138
2021-12-16 16:19:22,442 iteration 4470 : loss : 0.039474, loss_ce: 0.016994
2021-12-16 16:19:23,978 iteration 4471 : loss : 0.061150, loss_ce: 0.020414
 66%|███████████████████          | 263/400 [1:59:29<59:56, 26.25s/it]2021-12-16 16:19:25,441 iteration 4472 : loss : 0.033127, loss_ce: 0.014696
2021-12-16 16:19:26,874 iteration 4473 : loss : 0.037127, loss_ce: 0.017073
2021-12-16 16:19:28,371 iteration 4474 : loss : 0.026309, loss_ce: 0.013793
2021-12-16 16:19:29,823 iteration 4475 : loss : 0.043163, loss_ce: 0.015005
2021-12-16 16:19:31,245 iteration 4476 : loss : 0.036343, loss_ce: 0.014778
2021-12-16 16:19:32,696 iteration 4477 : loss : 0.033695, loss_ce: 0.015361
2021-12-16 16:19:34,283 iteration 4478 : loss : 0.042560, loss_ce: 0.023535
2021-12-16 16:19:35,734 iteration 4479 : loss : 0.046001, loss_ce: 0.015933
2021-12-16 16:19:37,198 iteration 4480 : loss : 0.042900, loss_ce: 0.017330
2021-12-16 16:19:38,600 iteration 4481 : loss : 0.032576, loss_ce: 0.013846
2021-12-16 16:19:40,030 iteration 4482 : loss : 0.031177, loss_ce: 0.010735
2021-12-16 16:19:41,452 iteration 4483 : loss : 0.040101, loss_ce: 0.015493
2021-12-16 16:19:42,926 iteration 4484 : loss : 0.034878, loss_ce: 0.013561
2021-12-16 16:19:44,321 iteration 4485 : loss : 0.027937, loss_ce: 0.013716
2021-12-16 16:19:45,859 iteration 4486 : loss : 0.040441, loss_ce: 0.018154
2021-12-16 16:19:47,343 iteration 4487 : loss : 0.035101, loss_ce: 0.017685
2021-12-16 16:19:48,739 iteration 4488 : loss : 0.045109, loss_ce: 0.017975
 66%|███████████████████▏         | 264/400 [1:59:54<58:29, 25.80s/it]2021-12-16 16:19:50,267 iteration 4489 : loss : 0.033213, loss_ce: 0.016188
2021-12-16 16:19:51,704 iteration 4490 : loss : 0.033295, loss_ce: 0.018225
2021-12-16 16:19:53,258 iteration 4491 : loss : 0.053531, loss_ce: 0.020567
2021-12-16 16:19:54,674 iteration 4492 : loss : 0.032170, loss_ce: 0.009730
2021-12-16 16:19:56,211 iteration 4493 : loss : 0.055714, loss_ce: 0.033332
2021-12-16 16:19:57,638 iteration 4494 : loss : 0.039306, loss_ce: 0.015240
2021-12-16 16:19:59,123 iteration 4495 : loss : 0.038659, loss_ce: 0.012422
2021-12-16 16:20:00,596 iteration 4496 : loss : 0.040897, loss_ce: 0.014836
2021-12-16 16:20:01,942 iteration 4497 : loss : 0.040700, loss_ce: 0.019738
2021-12-16 16:20:03,406 iteration 4498 : loss : 0.035883, loss_ce: 0.013453
2021-12-16 16:20:04,858 iteration 4499 : loss : 0.031842, loss_ce: 0.014570
2021-12-16 16:20:06,310 iteration 4500 : loss : 0.048627, loss_ce: 0.018491
2021-12-16 16:20:07,724 iteration 4501 : loss : 0.040778, loss_ce: 0.020431
2021-12-16 16:20:09,160 iteration 4502 : loss : 0.032802, loss_ce: 0.013864
2021-12-16 16:20:10,703 iteration 4503 : loss : 0.045704, loss_ce: 0.019632
2021-12-16 16:20:12,065 iteration 4504 : loss : 0.028570, loss_ce: 0.012820
2021-12-16 16:20:12,066 Training Data Eval:
2021-12-16 16:20:19,588   Average segmentation loss on training set: 0.0172
2021-12-16 16:20:19,588 Validation Data Eval:
2021-12-16 16:20:22,198   Average segmentation loss on validation set: 0.1016
2021-12-16 16:20:23,682 iteration 4505 : loss : 0.040343, loss_ce: 0.018810
 66%|█████████████████▉         | 265/400 [2:00:29<1:04:14, 28.55s/it]2021-12-16 16:20:25,229 iteration 4506 : loss : 0.036553, loss_ce: 0.016226
2021-12-16 16:20:26,774 iteration 4507 : loss : 0.051142, loss_ce: 0.024015
2021-12-16 16:20:28,236 iteration 4508 : loss : 0.074584, loss_ce: 0.026479
2021-12-16 16:20:29,635 iteration 4509 : loss : 0.026005, loss_ce: 0.010381
2021-12-16 16:20:31,095 iteration 4510 : loss : 0.030553, loss_ce: 0.013356
2021-12-16 16:20:32,661 iteration 4511 : loss : 0.039722, loss_ce: 0.019921
2021-12-16 16:20:34,025 iteration 4512 : loss : 0.029508, loss_ce: 0.012409
2021-12-16 16:20:35,479 iteration 4513 : loss : 0.030295, loss_ce: 0.013172
2021-12-16 16:20:36,931 iteration 4514 : loss : 0.035836, loss_ce: 0.016462
2021-12-16 16:20:38,379 iteration 4515 : loss : 0.024172, loss_ce: 0.012024
2021-12-16 16:20:39,836 iteration 4516 : loss : 0.034136, loss_ce: 0.017619
2021-12-16 16:20:41,314 iteration 4517 : loss : 0.045988, loss_ce: 0.021518
2021-12-16 16:20:42,739 iteration 4518 : loss : 0.064142, loss_ce: 0.034516
2021-12-16 16:20:44,113 iteration 4519 : loss : 0.046349, loss_ce: 0.016987
2021-12-16 16:20:45,589 iteration 4520 : loss : 0.037013, loss_ce: 0.012442
2021-12-16 16:20:47,078 iteration 4521 : loss : 0.031843, loss_ce: 0.014780
2021-12-16 16:20:48,591 iteration 4522 : loss : 0.047808, loss_ce: 0.020388
 66%|█████████████████▉         | 266/400 [2:00:54<1:01:19, 27.46s/it]2021-12-16 16:20:50,150 iteration 4523 : loss : 0.040521, loss_ce: 0.019702
2021-12-16 16:20:51,612 iteration 4524 : loss : 0.039817, loss_ce: 0.015796
2021-12-16 16:20:53,102 iteration 4525 : loss : 0.055146, loss_ce: 0.027509
2021-12-16 16:20:54,560 iteration 4526 : loss : 0.036375, loss_ce: 0.012921
2021-12-16 16:20:55,949 iteration 4527 : loss : 0.034121, loss_ce: 0.015058
2021-12-16 16:20:57,384 iteration 4528 : loss : 0.031322, loss_ce: 0.012366
2021-12-16 16:20:58,864 iteration 4529 : loss : 0.055359, loss_ce: 0.027527
2021-12-16 16:21:00,280 iteration 4530 : loss : 0.041679, loss_ce: 0.012502
2021-12-16 16:21:01,763 iteration 4531 : loss : 0.035191, loss_ce: 0.013844
2021-12-16 16:21:03,253 iteration 4532 : loss : 0.026858, loss_ce: 0.010495
2021-12-16 16:21:04,685 iteration 4533 : loss : 0.038939, loss_ce: 0.018688
2021-12-16 16:21:06,135 iteration 4534 : loss : 0.033281, loss_ce: 0.011296
2021-12-16 16:21:07,626 iteration 4535 : loss : 0.030199, loss_ce: 0.012750
2021-12-16 16:21:09,105 iteration 4536 : loss : 0.050228, loss_ce: 0.022149
2021-12-16 16:21:10,562 iteration 4537 : loss : 0.056052, loss_ce: 0.026774
2021-12-16 16:21:12,013 iteration 4538 : loss : 0.042565, loss_ce: 0.018904
2021-12-16 16:21:13,459 iteration 4539 : loss : 0.038002, loss_ce: 0.015882
 67%|███████████████████▎         | 267/400 [2:01:19<59:08, 26.68s/it]2021-12-16 16:21:14,909 iteration 4540 : loss : 0.025836, loss_ce: 0.010831
2021-12-16 16:21:16,389 iteration 4541 : loss : 0.032923, loss_ce: 0.016205
2021-12-16 16:21:17,795 iteration 4542 : loss : 0.031360, loss_ce: 0.012693
2021-12-16 16:21:19,227 iteration 4543 : loss : 0.029340, loss_ce: 0.011629
2021-12-16 16:21:20,640 iteration 4544 : loss : 0.039981, loss_ce: 0.014948
2021-12-16 16:21:22,165 iteration 4545 : loss : 0.040491, loss_ce: 0.019605
2021-12-16 16:21:23,742 iteration 4546 : loss : 0.043902, loss_ce: 0.020378
2021-12-16 16:21:25,295 iteration 4547 : loss : 0.029122, loss_ce: 0.013436
2021-12-16 16:21:26,681 iteration 4548 : loss : 0.025153, loss_ce: 0.011004
2021-12-16 16:21:28,098 iteration 4549 : loss : 0.036058, loss_ce: 0.013177
2021-12-16 16:21:29,584 iteration 4550 : loss : 0.039257, loss_ce: 0.017489
2021-12-16 16:21:31,077 iteration 4551 : loss : 0.035808, loss_ce: 0.016367
2021-12-16 16:21:32,619 iteration 4552 : loss : 0.050394, loss_ce: 0.015786
2021-12-16 16:21:34,116 iteration 4553 : loss : 0.032293, loss_ce: 0.012976
2021-12-16 16:21:35,522 iteration 4554 : loss : 0.027287, loss_ce: 0.013190
2021-12-16 16:21:36,964 iteration 4555 : loss : 0.030865, loss_ce: 0.013641
2021-12-16 16:21:38,419 iteration 4556 : loss : 0.044164, loss_ce: 0.014623
 67%|███████████████████▍         | 268/400 [2:01:44<57:33, 26.16s/it]2021-12-16 16:21:39,888 iteration 4557 : loss : 0.025778, loss_ce: 0.012155
2021-12-16 16:21:41,369 iteration 4558 : loss : 0.055825, loss_ce: 0.019043
2021-12-16 16:21:42,882 iteration 4559 : loss : 0.044425, loss_ce: 0.018548
2021-12-16 16:21:44,369 iteration 4560 : loss : 0.043380, loss_ce: 0.025701
2021-12-16 16:21:45,782 iteration 4561 : loss : 0.030018, loss_ce: 0.010786
2021-12-16 16:21:47,247 iteration 4562 : loss : 0.035209, loss_ce: 0.016351
2021-12-16 16:21:48,685 iteration 4563 : loss : 0.030853, loss_ce: 0.013317
2021-12-16 16:21:50,119 iteration 4564 : loss : 0.029416, loss_ce: 0.013973
2021-12-16 16:21:51,578 iteration 4565 : loss : 0.031204, loss_ce: 0.014641
2021-12-16 16:21:53,036 iteration 4566 : loss : 0.029059, loss_ce: 0.012987
2021-12-16 16:21:54,462 iteration 4567 : loss : 0.038753, loss_ce: 0.016132
2021-12-16 16:21:55,826 iteration 4568 : loss : 0.022971, loss_ce: 0.009349
2021-12-16 16:21:57,234 iteration 4569 : loss : 0.037677, loss_ce: 0.017533
2021-12-16 16:21:58,689 iteration 4570 : loss : 0.029418, loss_ce: 0.012720
2021-12-16 16:22:00,187 iteration 4571 : loss : 0.034448, loss_ce: 0.017173
2021-12-16 16:22:01,665 iteration 4572 : loss : 0.039336, loss_ce: 0.015944
2021-12-16 16:22:03,162 iteration 4573 : loss : 0.048457, loss_ce: 0.019313
 67%|███████████████████▌         | 269/400 [2:02:08<56:11, 25.74s/it]2021-12-16 16:22:04,591 iteration 4574 : loss : 0.025109, loss_ce: 0.009606
2021-12-16 16:22:06,083 iteration 4575 : loss : 0.031152, loss_ce: 0.010209
2021-12-16 16:22:07,474 iteration 4576 : loss : 0.029595, loss_ce: 0.013397
2021-12-16 16:22:08,884 iteration 4577 : loss : 0.028206, loss_ce: 0.014513
2021-12-16 16:22:10,346 iteration 4578 : loss : 0.034653, loss_ce: 0.015594
2021-12-16 16:22:11,778 iteration 4579 : loss : 0.029132, loss_ce: 0.012767
2021-12-16 16:22:13,227 iteration 4580 : loss : 0.030466, loss_ce: 0.013898
2021-12-16 16:22:14,684 iteration 4581 : loss : 0.038256, loss_ce: 0.017614
2021-12-16 16:22:16,126 iteration 4582 : loss : 0.037874, loss_ce: 0.015424
2021-12-16 16:22:17,554 iteration 4583 : loss : 0.044817, loss_ce: 0.017228
2021-12-16 16:22:18,986 iteration 4584 : loss : 0.032028, loss_ce: 0.013697
2021-12-16 16:22:20,462 iteration 4585 : loss : 0.060519, loss_ce: 0.022353
2021-12-16 16:22:21,870 iteration 4586 : loss : 0.029014, loss_ce: 0.015253
2021-12-16 16:22:23,294 iteration 4587 : loss : 0.031130, loss_ce: 0.011821
2021-12-16 16:22:24,711 iteration 4588 : loss : 0.034393, loss_ce: 0.014345
2021-12-16 16:22:26,170 iteration 4589 : loss : 0.043440, loss_ce: 0.017706
2021-12-16 16:22:26,170 Training Data Eval:
2021-12-16 16:22:33,683   Average segmentation loss on training set: 0.0180
2021-12-16 16:22:33,683 Validation Data Eval:
2021-12-16 16:22:36,286   Average segmentation loss on validation set: 0.0970
2021-12-16 16:22:37,738 iteration 4590 : loss : 0.031786, loss_ce: 0.016037
 68%|██████████████████▏        | 270/400 [2:02:43<1:01:30, 28.39s/it]2021-12-16 16:22:39,259 iteration 4591 : loss : 0.066555, loss_ce: 0.031261
2021-12-16 16:22:40,780 iteration 4592 : loss : 0.037590, loss_ce: 0.014798
2021-12-16 16:22:42,263 iteration 4593 : loss : 0.030572, loss_ce: 0.014909
2021-12-16 16:22:43,793 iteration 4594 : loss : 0.072193, loss_ce: 0.026339
2021-12-16 16:22:45,233 iteration 4595 : loss : 0.045807, loss_ce: 0.019500
2021-12-16 16:22:46,655 iteration 4596 : loss : 0.038654, loss_ce: 0.013741
2021-12-16 16:22:48,110 iteration 4597 : loss : 0.024224, loss_ce: 0.012442
2021-12-16 16:22:49,627 iteration 4598 : loss : 0.057984, loss_ce: 0.024166
2021-12-16 16:22:51,137 iteration 4599 : loss : 0.029554, loss_ce: 0.015849
2021-12-16 16:22:52,586 iteration 4600 : loss : 0.037898, loss_ce: 0.017121
2021-12-16 16:22:54,098 iteration 4601 : loss : 0.055114, loss_ce: 0.025948
2021-12-16 16:22:55,653 iteration 4602 : loss : 0.049008, loss_ce: 0.016544
2021-12-16 16:22:57,103 iteration 4603 : loss : 0.036996, loss_ce: 0.014535
2021-12-16 16:22:58,586 iteration 4604 : loss : 0.026333, loss_ce: 0.012444
2021-12-16 16:23:00,108 iteration 4605 : loss : 0.087508, loss_ce: 0.020249
2021-12-16 16:23:01,615 iteration 4606 : loss : 0.037130, loss_ce: 0.016388
2021-12-16 16:23:03,124 iteration 4607 : loss : 0.050466, loss_ce: 0.031308
 68%|███████████████████▋         | 271/400 [2:03:08<59:06, 27.49s/it]2021-12-16 16:23:04,563 iteration 4608 : loss : 0.026439, loss_ce: 0.011401
2021-12-16 16:23:06,035 iteration 4609 : loss : 0.047286, loss_ce: 0.020462
2021-12-16 16:23:07,449 iteration 4610 : loss : 0.042833, loss_ce: 0.017273
2021-12-16 16:23:08,862 iteration 4611 : loss : 0.026470, loss_ce: 0.011641
2021-12-16 16:23:10,260 iteration 4612 : loss : 0.025568, loss_ce: 0.009360
2021-12-16 16:23:11,731 iteration 4613 : loss : 0.039639, loss_ce: 0.015483
2021-12-16 16:23:13,206 iteration 4614 : loss : 0.048923, loss_ce: 0.023872
2021-12-16 16:23:14,707 iteration 4615 : loss : 0.037202, loss_ce: 0.012255
2021-12-16 16:23:16,264 iteration 4616 : loss : 0.036866, loss_ce: 0.017378
2021-12-16 16:23:17,733 iteration 4617 : loss : 0.047074, loss_ce: 0.017244
2021-12-16 16:23:19,135 iteration 4618 : loss : 0.025303, loss_ce: 0.009938
2021-12-16 16:23:20,563 iteration 4619 : loss : 0.025593, loss_ce: 0.012190
2021-12-16 16:23:22,084 iteration 4620 : loss : 0.028477, loss_ce: 0.010232
2021-12-16 16:23:23,524 iteration 4621 : loss : 0.042235, loss_ce: 0.022835
2021-12-16 16:23:24,975 iteration 4622 : loss : 0.057349, loss_ce: 0.020894
2021-12-16 16:23:26,456 iteration 4623 : loss : 0.032352, loss_ce: 0.012882
2021-12-16 16:23:27,922 iteration 4624 : loss : 0.031215, loss_ce: 0.016983
 68%|███████████████████▋         | 272/400 [2:03:33<56:55, 26.68s/it]2021-12-16 16:23:29,474 iteration 4625 : loss : 0.031806, loss_ce: 0.016425
2021-12-16 16:23:30,998 iteration 4626 : loss : 0.042172, loss_ce: 0.021957
2021-12-16 16:23:32,566 iteration 4627 : loss : 0.034496, loss_ce: 0.014114
2021-12-16 16:23:33,977 iteration 4628 : loss : 0.036301, loss_ce: 0.013913
2021-12-16 16:23:35,361 iteration 4629 : loss : 0.027824, loss_ce: 0.011996
2021-12-16 16:23:36,819 iteration 4630 : loss : 0.031934, loss_ce: 0.013755
2021-12-16 16:23:38,278 iteration 4631 : loss : 0.029236, loss_ce: 0.011411
2021-12-16 16:23:39,730 iteration 4632 : loss : 0.035950, loss_ce: 0.012739
2021-12-16 16:23:41,157 iteration 4633 : loss : 0.034259, loss_ce: 0.012858
2021-12-16 16:23:42,568 iteration 4634 : loss : 0.028701, loss_ce: 0.015253
2021-12-16 16:23:43,952 iteration 4635 : loss : 0.026383, loss_ce: 0.011418
2021-12-16 16:23:45,513 iteration 4636 : loss : 0.042047, loss_ce: 0.019799
2021-12-16 16:23:46,947 iteration 4637 : loss : 0.037772, loss_ce: 0.013766
2021-12-16 16:23:48,523 iteration 4638 : loss : 0.068396, loss_ce: 0.033028
2021-12-16 16:23:50,025 iteration 4639 : loss : 0.042675, loss_ce: 0.018327
2021-12-16 16:23:51,599 iteration 4640 : loss : 0.045169, loss_ce: 0.019339
2021-12-16 16:23:53,092 iteration 4641 : loss : 0.041396, loss_ce: 0.018190
 68%|███████████████████▊         | 273/400 [2:03:58<55:31, 26.23s/it]2021-12-16 16:23:54,583 iteration 4642 : loss : 0.037830, loss_ce: 0.010839
2021-12-16 16:23:56,041 iteration 4643 : loss : 0.031144, loss_ce: 0.011939
2021-12-16 16:23:57,551 iteration 4644 : loss : 0.038848, loss_ce: 0.013882
2021-12-16 16:23:59,062 iteration 4645 : loss : 0.051395, loss_ce: 0.026724
2021-12-16 16:24:00,544 iteration 4646 : loss : 0.053608, loss_ce: 0.019840
2021-12-16 16:24:01,932 iteration 4647 : loss : 0.025665, loss_ce: 0.010163
2021-12-16 16:24:03,378 iteration 4648 : loss : 0.058224, loss_ce: 0.022466
2021-12-16 16:24:04,877 iteration 4649 : loss : 0.034295, loss_ce: 0.017095
2021-12-16 16:24:06,391 iteration 4650 : loss : 0.056748, loss_ce: 0.021129
2021-12-16 16:24:07,777 iteration 4651 : loss : 0.024932, loss_ce: 0.012171
2021-12-16 16:24:09,295 iteration 4652 : loss : 0.049012, loss_ce: 0.023154
2021-12-16 16:24:10,723 iteration 4653 : loss : 0.037764, loss_ce: 0.017343
2021-12-16 16:24:12,166 iteration 4654 : loss : 0.046037, loss_ce: 0.015011
2021-12-16 16:24:13,694 iteration 4655 : loss : 0.049894, loss_ce: 0.020044
2021-12-16 16:24:15,233 iteration 4656 : loss : 0.033874, loss_ce: 0.015184
2021-12-16 16:24:16,740 iteration 4657 : loss : 0.043352, loss_ce: 0.020902
2021-12-16 16:24:18,244 iteration 4658 : loss : 0.044961, loss_ce: 0.019922
 68%|███████████████████▊         | 274/400 [2:04:24<54:23, 25.90s/it]2021-12-16 16:24:19,791 iteration 4659 : loss : 0.040455, loss_ce: 0.018622
2021-12-16 16:24:21,311 iteration 4660 : loss : 0.044637, loss_ce: 0.021097
2021-12-16 16:24:22,798 iteration 4661 : loss : 0.041534, loss_ce: 0.017357
2021-12-16 16:24:24,202 iteration 4662 : loss : 0.027537, loss_ce: 0.012158
2021-12-16 16:24:25,691 iteration 4663 : loss : 0.039734, loss_ce: 0.017814
2021-12-16 16:24:27,121 iteration 4664 : loss : 0.026615, loss_ce: 0.012264
2021-12-16 16:24:28,568 iteration 4665 : loss : 0.042827, loss_ce: 0.018719
2021-12-16 16:24:29,929 iteration 4666 : loss : 0.026644, loss_ce: 0.010460
2021-12-16 16:24:31,357 iteration 4667 : loss : 0.024948, loss_ce: 0.011171
2021-12-16 16:24:32,943 iteration 4668 : loss : 0.067358, loss_ce: 0.036653
2021-12-16 16:24:34,342 iteration 4669 : loss : 0.027031, loss_ce: 0.013387
2021-12-16 16:24:35,761 iteration 4670 : loss : 0.041293, loss_ce: 0.017493
2021-12-16 16:24:37,176 iteration 4671 : loss : 0.030770, loss_ce: 0.011021
2021-12-16 16:24:38,754 iteration 4672 : loss : 0.051933, loss_ce: 0.019618
2021-12-16 16:24:40,306 iteration 4673 : loss : 0.027338, loss_ce: 0.012963
2021-12-16 16:24:41,681 iteration 4674 : loss : 0.023995, loss_ce: 0.008352
2021-12-16 16:24:41,681 Training Data Eval:
2021-12-16 16:24:49,198   Average segmentation loss on training set: 0.0176
2021-12-16 16:24:49,199 Validation Data Eval:
2021-12-16 16:24:51,799   Average segmentation loss on validation set: 0.0984
2021-12-16 16:24:53,337 iteration 4675 : loss : 0.039704, loss_ce: 0.016849
 69%|███████████████████▉         | 275/400 [2:04:59<59:42, 28.66s/it]2021-12-16 16:24:54,964 iteration 4676 : loss : 0.041214, loss_ce: 0.013717
2021-12-16 16:24:56,419 iteration 4677 : loss : 0.034132, loss_ce: 0.012549
2021-12-16 16:24:57,916 iteration 4678 : loss : 0.048122, loss_ce: 0.018208
2021-12-16 16:24:59,444 iteration 4679 : loss : 0.080828, loss_ce: 0.025029
2021-12-16 16:25:00,883 iteration 4680 : loss : 0.038014, loss_ce: 0.019053
2021-12-16 16:25:02,327 iteration 4681 : loss : 0.042706, loss_ce: 0.014626
2021-12-16 16:25:03,776 iteration 4682 : loss : 0.039699, loss_ce: 0.015813
2021-12-16 16:25:05,155 iteration 4683 : loss : 0.031933, loss_ce: 0.011375
2021-12-16 16:25:06,685 iteration 4684 : loss : 0.037000, loss_ce: 0.019002
2021-12-16 16:25:08,173 iteration 4685 : loss : 0.046201, loss_ce: 0.018871
2021-12-16 16:25:09,621 iteration 4686 : loss : 0.033831, loss_ce: 0.011120
2021-12-16 16:25:11,055 iteration 4687 : loss : 0.026068, loss_ce: 0.013509
2021-12-16 16:25:12,443 iteration 4688 : loss : 0.023317, loss_ce: 0.012722
2021-12-16 16:25:13,834 iteration 4689 : loss : 0.019984, loss_ce: 0.010358
2021-12-16 16:25:15,253 iteration 4690 : loss : 0.034455, loss_ce: 0.015446
2021-12-16 16:25:16,774 iteration 4691 : loss : 0.059942, loss_ce: 0.033322
2021-12-16 16:25:18,203 iteration 4692 : loss : 0.042096, loss_ce: 0.013869
 69%|████████████████████         | 276/400 [2:05:24<56:52, 27.52s/it]2021-12-16 16:25:19,756 iteration 4693 : loss : 0.031573, loss_ce: 0.012196
2021-12-16 16:25:21,230 iteration 4694 : loss : 0.051825, loss_ce: 0.021652
2021-12-16 16:25:22,545 iteration 4695 : loss : 0.019926, loss_ce: 0.008504
2021-12-16 16:25:24,094 iteration 4696 : loss : 0.035599, loss_ce: 0.016220
2021-12-16 16:25:25,516 iteration 4697 : loss : 0.030689, loss_ce: 0.012545
2021-12-16 16:25:26,970 iteration 4698 : loss : 0.037783, loss_ce: 0.021046
2021-12-16 16:25:28,473 iteration 4699 : loss : 0.034985, loss_ce: 0.018590
2021-12-16 16:25:29,871 iteration 4700 : loss : 0.034155, loss_ce: 0.016699
2021-12-16 16:25:31,430 iteration 4701 : loss : 0.048749, loss_ce: 0.022424
2021-12-16 16:25:32,868 iteration 4702 : loss : 0.032867, loss_ce: 0.015055
2021-12-16 16:25:34,289 iteration 4703 : loss : 0.031836, loss_ce: 0.011899
2021-12-16 16:25:35,769 iteration 4704 : loss : 0.039288, loss_ce: 0.014538
2021-12-16 16:25:37,105 iteration 4705 : loss : 0.022165, loss_ce: 0.010877
2021-12-16 16:25:38,574 iteration 4706 : loss : 0.040164, loss_ce: 0.014596
2021-12-16 16:25:40,091 iteration 4707 : loss : 0.037665, loss_ce: 0.015583
2021-12-16 16:25:41,612 iteration 4708 : loss : 0.034017, loss_ce: 0.013071
2021-12-16 16:25:43,104 iteration 4709 : loss : 0.045791, loss_ce: 0.017326
 69%|████████████████████         | 277/400 [2:05:48<54:48, 26.74s/it]2021-12-16 16:25:44,628 iteration 4710 : loss : 0.038124, loss_ce: 0.012210
2021-12-16 16:25:46,219 iteration 4711 : loss : 0.045726, loss_ce: 0.020423
2021-12-16 16:25:47,656 iteration 4712 : loss : 0.040896, loss_ce: 0.017827
2021-12-16 16:25:49,099 iteration 4713 : loss : 0.034028, loss_ce: 0.014961
2021-12-16 16:25:50,555 iteration 4714 : loss : 0.031138, loss_ce: 0.012390
2021-12-16 16:25:52,063 iteration 4715 : loss : 0.042189, loss_ce: 0.017023
2021-12-16 16:25:53,548 iteration 4716 : loss : 0.043187, loss_ce: 0.019147
2021-12-16 16:25:54,997 iteration 4717 : loss : 0.035215, loss_ce: 0.014011
2021-12-16 16:25:56,393 iteration 4718 : loss : 0.029716, loss_ce: 0.012466
2021-12-16 16:25:57,798 iteration 4719 : loss : 0.031968, loss_ce: 0.014113
2021-12-16 16:25:59,216 iteration 4720 : loss : 0.031531, loss_ce: 0.015656
2021-12-16 16:26:00,647 iteration 4721 : loss : 0.029992, loss_ce: 0.013516
2021-12-16 16:26:02,153 iteration 4722 : loss : 0.043031, loss_ce: 0.016580
2021-12-16 16:26:03,620 iteration 4723 : loss : 0.027545, loss_ce: 0.011921
2021-12-16 16:26:05,013 iteration 4724 : loss : 0.026852, loss_ce: 0.011737
2021-12-16 16:26:06,409 iteration 4725 : loss : 0.030835, loss_ce: 0.015151
2021-12-16 16:26:07,875 iteration 4726 : loss : 0.031997, loss_ce: 0.013725
 70%|████████████████████▏        | 278/400 [2:06:13<53:10, 26.15s/it]2021-12-16 16:26:09,432 iteration 4727 : loss : 0.029093, loss_ce: 0.013401
2021-12-16 16:26:10,818 iteration 4728 : loss : 0.027441, loss_ce: 0.012815
2021-12-16 16:26:12,229 iteration 4729 : loss : 0.028708, loss_ce: 0.011964
2021-12-16 16:26:13,656 iteration 4730 : loss : 0.024825, loss_ce: 0.010096
2021-12-16 16:26:15,170 iteration 4731 : loss : 0.042305, loss_ce: 0.016449
2021-12-16 16:26:16,636 iteration 4732 : loss : 0.040678, loss_ce: 0.016099
2021-12-16 16:26:18,089 iteration 4733 : loss : 0.032750, loss_ce: 0.015230
2021-12-16 16:26:19,533 iteration 4734 : loss : 0.031544, loss_ce: 0.013766
2021-12-16 16:26:21,082 iteration 4735 : loss : 0.080676, loss_ce: 0.030768
2021-12-16 16:26:22,454 iteration 4736 : loss : 0.031460, loss_ce: 0.014624
2021-12-16 16:26:23,964 iteration 4737 : loss : 0.056997, loss_ce: 0.021797
2021-12-16 16:26:25,398 iteration 4738 : loss : 0.037418, loss_ce: 0.015099
2021-12-16 16:26:26,829 iteration 4739 : loss : 0.029283, loss_ce: 0.012177
2021-12-16 16:26:28,319 iteration 4740 : loss : 0.032064, loss_ce: 0.014837
2021-12-16 16:26:29,748 iteration 4741 : loss : 0.036565, loss_ce: 0.013109
2021-12-16 16:26:31,200 iteration 4742 : loss : 0.034947, loss_ce: 0.020660
2021-12-16 16:26:32,781 iteration 4743 : loss : 0.041216, loss_ce: 0.014839
 70%|████████████████████▏        | 279/400 [2:06:38<51:58, 25.78s/it]2021-12-16 16:26:34,328 iteration 4744 : loss : 0.035533, loss_ce: 0.013491
2021-12-16 16:26:35,776 iteration 4745 : loss : 0.043854, loss_ce: 0.016366
2021-12-16 16:26:37,189 iteration 4746 : loss : 0.031167, loss_ce: 0.018166
2021-12-16 16:26:38,627 iteration 4747 : loss : 0.028043, loss_ce: 0.010891
2021-12-16 16:26:40,114 iteration 4748 : loss : 0.028851, loss_ce: 0.012459
2021-12-16 16:26:41,580 iteration 4749 : loss : 0.065408, loss_ce: 0.023517
2021-12-16 16:26:43,077 iteration 4750 : loss : 0.038503, loss_ce: 0.015763
2021-12-16 16:26:44,504 iteration 4751 : loss : 0.036916, loss_ce: 0.016182
2021-12-16 16:26:46,005 iteration 4752 : loss : 0.028902, loss_ce: 0.011464
2021-12-16 16:26:47,514 iteration 4753 : loss : 0.047920, loss_ce: 0.019935
2021-12-16 16:26:48,985 iteration 4754 : loss : 0.032849, loss_ce: 0.012770
2021-12-16 16:26:50,537 iteration 4755 : loss : 0.049792, loss_ce: 0.018794
2021-12-16 16:26:51,950 iteration 4756 : loss : 0.031743, loss_ce: 0.016342
2021-12-16 16:26:53,389 iteration 4757 : loss : 0.059027, loss_ce: 0.024563
2021-12-16 16:26:54,821 iteration 4758 : loss : 0.031399, loss_ce: 0.012287
2021-12-16 16:26:56,285 iteration 4759 : loss : 0.024084, loss_ce: 0.010094
2021-12-16 16:26:56,285 Training Data Eval:
2021-12-16 16:27:03,802   Average segmentation loss on training set: 0.0164
2021-12-16 16:27:03,802 Validation Data Eval:
2021-12-16 16:27:06,400   Average segmentation loss on validation set: 0.1050
2021-12-16 16:27:07,836 iteration 4760 : loss : 0.031737, loss_ce: 0.016724
 70%|████████████████████▎        | 280/400 [2:07:13<57:07, 28.56s/it]2021-12-16 16:27:09,319 iteration 4761 : loss : 0.027061, loss_ce: 0.010257
2021-12-16 16:27:10,817 iteration 4762 : loss : 0.055318, loss_ce: 0.018701
2021-12-16 16:27:12,231 iteration 4763 : loss : 0.033389, loss_ce: 0.016740
2021-12-16 16:27:13,738 iteration 4764 : loss : 0.036980, loss_ce: 0.015477
2021-12-16 16:27:15,178 iteration 4765 : loss : 0.046123, loss_ce: 0.020559
2021-12-16 16:27:16,711 iteration 4766 : loss : 0.039618, loss_ce: 0.014865
2021-12-16 16:27:18,200 iteration 4767 : loss : 0.036449, loss_ce: 0.016723
2021-12-16 16:27:19,626 iteration 4768 : loss : 0.038418, loss_ce: 0.016276
2021-12-16 16:27:21,138 iteration 4769 : loss : 0.050944, loss_ce: 0.023779
2021-12-16 16:27:22,633 iteration 4770 : loss : 0.026120, loss_ce: 0.011497
2021-12-16 16:27:24,025 iteration 4771 : loss : 0.030519, loss_ce: 0.011088
2021-12-16 16:27:25,529 iteration 4772 : loss : 0.037338, loss_ce: 0.017883
2021-12-16 16:27:27,014 iteration 4773 : loss : 0.043124, loss_ce: 0.017376
2021-12-16 16:27:28,488 iteration 4774 : loss : 0.034596, loss_ce: 0.016229
2021-12-16 16:27:29,914 iteration 4775 : loss : 0.055640, loss_ce: 0.019269
2021-12-16 16:27:31,359 iteration 4776 : loss : 0.030217, loss_ce: 0.016703
2021-12-16 16:27:32,949 iteration 4777 : loss : 0.049854, loss_ce: 0.029052
 70%|████████████████████▎        | 281/400 [2:07:38<54:35, 27.52s/it]2021-12-16 16:27:34,371 iteration 4778 : loss : 0.023080, loss_ce: 0.008503
2021-12-16 16:27:35,815 iteration 4779 : loss : 0.038193, loss_ce: 0.015541
2021-12-16 16:27:37,216 iteration 4780 : loss : 0.026216, loss_ce: 0.011085
2021-12-16 16:27:38,654 iteration 4781 : loss : 0.039321, loss_ce: 0.014541
2021-12-16 16:27:40,163 iteration 4782 : loss : 0.049361, loss_ce: 0.023530
2021-12-16 16:27:41,606 iteration 4783 : loss : 0.024906, loss_ce: 0.013568
2021-12-16 16:27:42,984 iteration 4784 : loss : 0.024299, loss_ce: 0.010970
2021-12-16 16:27:44,511 iteration 4785 : loss : 0.040349, loss_ce: 0.017030
2021-12-16 16:27:45,991 iteration 4786 : loss : 0.035400, loss_ce: 0.014349
2021-12-16 16:27:47,473 iteration 4787 : loss : 0.037824, loss_ce: 0.014053
2021-12-16 16:27:48,948 iteration 4788 : loss : 0.035191, loss_ce: 0.014171
2021-12-16 16:27:50,334 iteration 4789 : loss : 0.024593, loss_ce: 0.013463
2021-12-16 16:27:51,899 iteration 4790 : loss : 0.039735, loss_ce: 0.014698
2021-12-16 16:27:53,340 iteration 4791 : loss : 0.043255, loss_ce: 0.021847
2021-12-16 16:27:54,846 iteration 4792 : loss : 0.049615, loss_ce: 0.016045
2021-12-16 16:27:56,257 iteration 4793 : loss : 0.028346, loss_ce: 0.012476
2021-12-16 16:27:57,623 iteration 4794 : loss : 0.042322, loss_ce: 0.013310
 70%|████████████████████▍        | 282/400 [2:08:03<52:26, 26.67s/it]2021-12-16 16:27:59,154 iteration 4795 : loss : 0.029624, loss_ce: 0.011319
2021-12-16 16:28:00,621 iteration 4796 : loss : 0.023962, loss_ce: 0.009978
2021-12-16 16:28:02,138 iteration 4797 : loss : 0.049284, loss_ce: 0.024272
2021-12-16 16:28:03,655 iteration 4798 : loss : 0.051330, loss_ce: 0.020173
2021-12-16 16:28:05,099 iteration 4799 : loss : 0.024165, loss_ce: 0.009366
2021-12-16 16:28:06,558 iteration 4800 : loss : 0.047294, loss_ce: 0.015732
2021-12-16 16:28:08,108 iteration 4801 : loss : 0.041086, loss_ce: 0.019029
2021-12-16 16:28:09,515 iteration 4802 : loss : 0.027691, loss_ce: 0.014017
2021-12-16 16:28:10,955 iteration 4803 : loss : 0.030794, loss_ce: 0.015600
2021-12-16 16:28:12,480 iteration 4804 : loss : 0.061865, loss_ce: 0.018418
2021-12-16 16:28:13,975 iteration 4805 : loss : 0.072860, loss_ce: 0.031440
2021-12-16 16:28:15,489 iteration 4806 : loss : 0.036603, loss_ce: 0.016874
2021-12-16 16:28:16,878 iteration 4807 : loss : 0.032397, loss_ce: 0.015557
2021-12-16 16:28:18,279 iteration 4808 : loss : 0.024897, loss_ce: 0.012340
2021-12-16 16:28:19,749 iteration 4809 : loss : 0.037617, loss_ce: 0.018024
2021-12-16 16:28:21,189 iteration 4810 : loss : 0.031302, loss_ce: 0.010924
2021-12-16 16:28:22,656 iteration 4811 : loss : 0.031730, loss_ce: 0.013713
 71%|████████████████████▌        | 283/400 [2:08:28<51:02, 26.18s/it]2021-12-16 16:28:24,103 iteration 4812 : loss : 0.030495, loss_ce: 0.012888
2021-12-16 16:28:25,575 iteration 4813 : loss : 0.029445, loss_ce: 0.010431
2021-12-16 16:28:27,060 iteration 4814 : loss : 0.045569, loss_ce: 0.015262
2021-12-16 16:28:28,436 iteration 4815 : loss : 0.031614, loss_ce: 0.015526
2021-12-16 16:28:30,003 iteration 4816 : loss : 0.041022, loss_ce: 0.018877
2021-12-16 16:28:31,457 iteration 4817 : loss : 0.036646, loss_ce: 0.018904
2021-12-16 16:28:32,900 iteration 4818 : loss : 0.028145, loss_ce: 0.013501
2021-12-16 16:28:34,268 iteration 4819 : loss : 0.048298, loss_ce: 0.020057
2021-12-16 16:28:35,699 iteration 4820 : loss : 0.034929, loss_ce: 0.015476
2021-12-16 16:28:37,242 iteration 4821 : loss : 0.044087, loss_ce: 0.022416
2021-12-16 16:28:38,772 iteration 4822 : loss : 0.045717, loss_ce: 0.017452
2021-12-16 16:28:40,225 iteration 4823 : loss : 0.047076, loss_ce: 0.024554
2021-12-16 16:28:41,722 iteration 4824 : loss : 0.033434, loss_ce: 0.015557
2021-12-16 16:28:43,162 iteration 4825 : loss : 0.031931, loss_ce: 0.014083
2021-12-16 16:28:44,601 iteration 4826 : loss : 0.037052, loss_ce: 0.011650
2021-12-16 16:28:46,046 iteration 4827 : loss : 0.029237, loss_ce: 0.013087
2021-12-16 16:28:47,456 iteration 4828 : loss : 0.030772, loss_ce: 0.014134
 71%|████████████████████▌        | 284/400 [2:08:53<49:48, 25.77s/it]2021-12-16 16:28:48,893 iteration 4829 : loss : 0.030787, loss_ce: 0.012150
2021-12-16 16:28:50,392 iteration 4830 : loss : 0.039324, loss_ce: 0.022668
2021-12-16 16:28:51,862 iteration 4831 : loss : 0.032862, loss_ce: 0.014567
2021-12-16 16:28:53,289 iteration 4832 : loss : 0.034186, loss_ce: 0.012879
2021-12-16 16:28:54,789 iteration 4833 : loss : 0.050088, loss_ce: 0.021195
2021-12-16 16:28:56,198 iteration 4834 : loss : 0.025180, loss_ce: 0.010888
2021-12-16 16:28:57,780 iteration 4835 : loss : 0.041085, loss_ce: 0.024690
2021-12-16 16:28:59,239 iteration 4836 : loss : 0.040748, loss_ce: 0.017126
2021-12-16 16:29:00,720 iteration 4837 : loss : 0.044872, loss_ce: 0.015035
2021-12-16 16:29:02,132 iteration 4838 : loss : 0.026379, loss_ce: 0.010149
2021-12-16 16:29:03,612 iteration 4839 : loss : 0.047406, loss_ce: 0.020822
2021-12-16 16:29:05,065 iteration 4840 : loss : 0.037325, loss_ce: 0.018922
2021-12-16 16:29:06,447 iteration 4841 : loss : 0.019956, loss_ce: 0.008276
2021-12-16 16:29:07,932 iteration 4842 : loss : 0.029412, loss_ce: 0.011608
2021-12-16 16:29:09,492 iteration 4843 : loss : 0.037148, loss_ce: 0.014057
2021-12-16 16:29:10,936 iteration 4844 : loss : 0.052092, loss_ce: 0.020103
2021-12-16 16:29:10,937 Training Data Eval:
2021-12-16 16:29:18,442   Average segmentation loss on training set: 0.0162
2021-12-16 16:29:18,442 Validation Data Eval:
2021-12-16 16:29:21,052   Average segmentation loss on validation set: 0.0999
2021-12-16 16:29:22,579 iteration 4845 : loss : 0.042403, loss_ce: 0.024993
 71%|████████████████████▋        | 285/400 [2:09:28<54:45, 28.57s/it]2021-12-16 16:29:24,046 iteration 4846 : loss : 0.042457, loss_ce: 0.016682
2021-12-16 16:29:25,482 iteration 4847 : loss : 0.031773, loss_ce: 0.014214
2021-12-16 16:29:26,999 iteration 4848 : loss : 0.039580, loss_ce: 0.019796
2021-12-16 16:29:28,492 iteration 4849 : loss : 0.030263, loss_ce: 0.009240
2021-12-16 16:29:29,910 iteration 4850 : loss : 0.029979, loss_ce: 0.011009
2021-12-16 16:29:31,507 iteration 4851 : loss : 0.039010, loss_ce: 0.019719
2021-12-16 16:29:32,938 iteration 4852 : loss : 0.030002, loss_ce: 0.011368
2021-12-16 16:29:34,397 iteration 4853 : loss : 0.031461, loss_ce: 0.015393
2021-12-16 16:29:35,854 iteration 4854 : loss : 0.029852, loss_ce: 0.013912
2021-12-16 16:29:37,284 iteration 4855 : loss : 0.038132, loss_ce: 0.012244
2021-12-16 16:29:38,843 iteration 4856 : loss : 0.054670, loss_ce: 0.024667
2021-12-16 16:29:40,275 iteration 4857 : loss : 0.022645, loss_ce: 0.010233
2021-12-16 16:29:41,822 iteration 4858 : loss : 0.038830, loss_ce: 0.017530
2021-12-16 16:29:43,207 iteration 4859 : loss : 0.018749, loss_ce: 0.009521
2021-12-16 16:29:44,712 iteration 4860 : loss : 0.042147, loss_ce: 0.019423
2021-12-16 16:29:46,137 iteration 4861 : loss : 0.034944, loss_ce: 0.013307
2021-12-16 16:29:47,635 iteration 4862 : loss : 0.036466, loss_ce: 0.017357
 72%|████████████████████▋        | 286/400 [2:09:53<52:16, 27.52s/it]2021-12-16 16:29:49,203 iteration 4863 : loss : 0.043133, loss_ce: 0.017071
2021-12-16 16:29:50,637 iteration 4864 : loss : 0.031861, loss_ce: 0.013087
2021-12-16 16:29:52,048 iteration 4865 : loss : 0.029089, loss_ce: 0.015335
2021-12-16 16:29:53,562 iteration 4866 : loss : 0.027163, loss_ce: 0.010614
2021-12-16 16:29:55,048 iteration 4867 : loss : 0.036690, loss_ce: 0.016044
2021-12-16 16:29:56,426 iteration 4868 : loss : 0.027275, loss_ce: 0.013845
2021-12-16 16:29:58,005 iteration 4869 : loss : 0.046815, loss_ce: 0.022957
2021-12-16 16:29:59,451 iteration 4870 : loss : 0.026358, loss_ce: 0.011625
2021-12-16 16:30:01,000 iteration 4871 : loss : 0.048415, loss_ce: 0.017440
2021-12-16 16:30:02,378 iteration 4872 : loss : 0.023915, loss_ce: 0.008754
2021-12-16 16:30:03,944 iteration 4873 : loss : 0.036774, loss_ce: 0.016823
2021-12-16 16:30:05,416 iteration 4874 : loss : 0.048885, loss_ce: 0.016457
2021-12-16 16:30:06,850 iteration 4875 : loss : 0.039470, loss_ce: 0.017253
2021-12-16 16:30:08,217 iteration 4876 : loss : 0.035557, loss_ce: 0.013216
2021-12-16 16:30:09,726 iteration 4877 : loss : 0.039125, loss_ce: 0.022616
2021-12-16 16:30:11,256 iteration 4878 : loss : 0.054681, loss_ce: 0.020189
2021-12-16 16:30:12,698 iteration 4879 : loss : 0.032268, loss_ce: 0.013243
 72%|████████████████████▊        | 287/400 [2:10:18<50:26, 26.78s/it]2021-12-16 16:30:14,160 iteration 4880 : loss : 0.032285, loss_ce: 0.014538
2021-12-16 16:30:15,561 iteration 4881 : loss : 0.026674, loss_ce: 0.012494
2021-12-16 16:30:16,939 iteration 4882 : loss : 0.025667, loss_ce: 0.012376
2021-12-16 16:30:18,447 iteration 4883 : loss : 0.038758, loss_ce: 0.017340
2021-12-16 16:30:19,958 iteration 4884 : loss : 0.037785, loss_ce: 0.012770
2021-12-16 16:30:21,323 iteration 4885 : loss : 0.023559, loss_ce: 0.010092
2021-12-16 16:30:22,780 iteration 4886 : loss : 0.044696, loss_ce: 0.013161
2021-12-16 16:30:24,163 iteration 4887 : loss : 0.028447, loss_ce: 0.010659
2021-12-16 16:30:25,635 iteration 4888 : loss : 0.040951, loss_ce: 0.013963
2021-12-16 16:30:27,094 iteration 4889 : loss : 0.049153, loss_ce: 0.027667
2021-12-16 16:30:28,503 iteration 4890 : loss : 0.044424, loss_ce: 0.024872
2021-12-16 16:30:29,850 iteration 4891 : loss : 0.024197, loss_ce: 0.010166
2021-12-16 16:30:31,353 iteration 4892 : loss : 0.028890, loss_ce: 0.012978
2021-12-16 16:30:32,811 iteration 4893 : loss : 0.027853, loss_ce: 0.013478
2021-12-16 16:30:34,243 iteration 4894 : loss : 0.025040, loss_ce: 0.013426
2021-12-16 16:30:35,682 iteration 4895 : loss : 0.033397, loss_ce: 0.009986
2021-12-16 16:30:37,103 iteration 4896 : loss : 0.035223, loss_ce: 0.013426
 72%|████████████████████▉        | 288/400 [2:10:42<48:39, 26.07s/it]2021-12-16 16:30:38,565 iteration 4897 : loss : 0.037919, loss_ce: 0.015810
2021-12-16 16:30:40,087 iteration 4898 : loss : 0.048985, loss_ce: 0.024913
2021-12-16 16:30:41,550 iteration 4899 : loss : 0.024594, loss_ce: 0.008321
2021-12-16 16:30:42,963 iteration 4900 : loss : 0.047803, loss_ce: 0.019871
2021-12-16 16:30:44,401 iteration 4901 : loss : 0.033612, loss_ce: 0.011519
2021-12-16 16:30:45,839 iteration 4902 : loss : 0.031170, loss_ce: 0.013347
2021-12-16 16:30:47,309 iteration 4903 : loss : 0.028334, loss_ce: 0.014914
2021-12-16 16:30:48,647 iteration 4904 : loss : 0.031391, loss_ce: 0.010207
2021-12-16 16:30:50,066 iteration 4905 : loss : 0.033468, loss_ce: 0.011868
2021-12-16 16:30:51,565 iteration 4906 : loss : 0.034918, loss_ce: 0.015799
2021-12-16 16:30:52,976 iteration 4907 : loss : 0.034243, loss_ce: 0.016174
2021-12-16 16:30:54,505 iteration 4908 : loss : 0.040457, loss_ce: 0.017191
2021-12-16 16:30:55,990 iteration 4909 : loss : 0.030913, loss_ce: 0.011651
2021-12-16 16:30:57,382 iteration 4910 : loss : 0.031562, loss_ce: 0.016451
2021-12-16 16:30:58,803 iteration 4911 : loss : 0.020557, loss_ce: 0.009333
2021-12-16 16:31:00,251 iteration 4912 : loss : 0.033280, loss_ce: 0.017133
2021-12-16 16:31:01,688 iteration 4913 : loss : 0.030299, loss_ce: 0.013332
 72%|████████████████████▉        | 289/400 [2:11:07<47:24, 25.62s/it]2021-12-16 16:31:03,227 iteration 4914 : loss : 0.062655, loss_ce: 0.027380
2021-12-16 16:31:04,653 iteration 4915 : loss : 0.032571, loss_ce: 0.013041
2021-12-16 16:31:06,086 iteration 4916 : loss : 0.024209, loss_ce: 0.008678
2021-12-16 16:31:07,551 iteration 4917 : loss : 0.030832, loss_ce: 0.010630
2021-12-16 16:31:09,025 iteration 4918 : loss : 0.027862, loss_ce: 0.012555
2021-12-16 16:31:10,621 iteration 4919 : loss : 0.048267, loss_ce: 0.023021
2021-12-16 16:31:12,043 iteration 4920 : loss : 0.031666, loss_ce: 0.013301
2021-12-16 16:31:13,445 iteration 4921 : loss : 0.023440, loss_ce: 0.013032
2021-12-16 16:31:14,835 iteration 4922 : loss : 0.033055, loss_ce: 0.009921
2021-12-16 16:31:16,367 iteration 4923 : loss : 0.045269, loss_ce: 0.018445
2021-12-16 16:31:17,895 iteration 4924 : loss : 0.053860, loss_ce: 0.029238
2021-12-16 16:31:19,376 iteration 4925 : loss : 0.030797, loss_ce: 0.012880
2021-12-16 16:31:20,898 iteration 4926 : loss : 0.045464, loss_ce: 0.022477
2021-12-16 16:31:22,325 iteration 4927 : loss : 0.025253, loss_ce: 0.010137
2021-12-16 16:31:23,867 iteration 4928 : loss : 0.061040, loss_ce: 0.023739
2021-12-16 16:31:25,394 iteration 4929 : loss : 0.041490, loss_ce: 0.018031
2021-12-16 16:31:25,394 Training Data Eval:
2021-12-16 16:31:32,893   Average segmentation loss on training set: 0.0159
2021-12-16 16:31:32,893 Validation Data Eval:
2021-12-16 16:31:35,501   Average segmentation loss on validation set: 0.1009
2021-12-16 16:31:36,988 iteration 4930 : loss : 0.035678, loss_ce: 0.011842
 72%|█████████████████████        | 290/400 [2:11:42<52:17, 28.53s/it]2021-12-16 16:31:38,495 iteration 4931 : loss : 0.029377, loss_ce: 0.014367
2021-12-16 16:31:39,979 iteration 4932 : loss : 0.037627, loss_ce: 0.020563
2021-12-16 16:31:41,372 iteration 4933 : loss : 0.024158, loss_ce: 0.013519
2021-12-16 16:31:42,889 iteration 4934 : loss : 0.029397, loss_ce: 0.010260
2021-12-16 16:31:44,339 iteration 4935 : loss : 0.032880, loss_ce: 0.014468
2021-12-16 16:31:45,814 iteration 4936 : loss : 0.045184, loss_ce: 0.018612
2021-12-16 16:31:47,284 iteration 4937 : loss : 0.032588, loss_ce: 0.016553
2021-12-16 16:31:48,836 iteration 4938 : loss : 0.055905, loss_ce: 0.020614
2021-12-16 16:31:50,347 iteration 4939 : loss : 0.041837, loss_ce: 0.019756
2021-12-16 16:31:51,778 iteration 4940 : loss : 0.048245, loss_ce: 0.020468
2021-12-16 16:31:53,247 iteration 4941 : loss : 0.045542, loss_ce: 0.022874
2021-12-16 16:31:54,707 iteration 4942 : loss : 0.034327, loss_ce: 0.012554
2021-12-16 16:31:56,289 iteration 4943 : loss : 0.071507, loss_ce: 0.017207
2021-12-16 16:31:57,742 iteration 4944 : loss : 0.044633, loss_ce: 0.014871
2021-12-16 16:31:59,233 iteration 4945 : loss : 0.036416, loss_ce: 0.017390
2021-12-16 16:32:00,744 iteration 4946 : loss : 0.040218, loss_ce: 0.015295
2021-12-16 16:32:02,184 iteration 4947 : loss : 0.039096, loss_ce: 0.016449
 73%|█████████████████████        | 291/400 [2:12:08<50:00, 27.53s/it]2021-12-16 16:32:03,749 iteration 4948 : loss : 0.057798, loss_ce: 0.019967
2021-12-16 16:32:05,178 iteration 4949 : loss : 0.048359, loss_ce: 0.023024
2021-12-16 16:32:06,662 iteration 4950 : loss : 0.043230, loss_ce: 0.019025
2021-12-16 16:32:08,142 iteration 4951 : loss : 0.035407, loss_ce: 0.014189
2021-12-16 16:32:09,616 iteration 4952 : loss : 0.031339, loss_ce: 0.017835
2021-12-16 16:32:11,122 iteration 4953 : loss : 0.034101, loss_ce: 0.017984
2021-12-16 16:32:12,562 iteration 4954 : loss : 0.022101, loss_ce: 0.009301
2021-12-16 16:32:13,970 iteration 4955 : loss : 0.034749, loss_ce: 0.012804
2021-12-16 16:32:15,424 iteration 4956 : loss : 0.041954, loss_ce: 0.015928
2021-12-16 16:32:16,793 iteration 4957 : loss : 0.029006, loss_ce: 0.013286
2021-12-16 16:32:18,281 iteration 4958 : loss : 0.044237, loss_ce: 0.025559
2021-12-16 16:32:19,756 iteration 4959 : loss : 0.041266, loss_ce: 0.018809
2021-12-16 16:32:21,143 iteration 4960 : loss : 0.032847, loss_ce: 0.015804
2021-12-16 16:32:22,612 iteration 4961 : loss : 0.028600, loss_ce: 0.012751
2021-12-16 16:32:24,025 iteration 4962 : loss : 0.043607, loss_ce: 0.012556
2021-12-16 16:32:25,477 iteration 4963 : loss : 0.031919, loss_ce: 0.014986
2021-12-16 16:32:26,994 iteration 4964 : loss : 0.029366, loss_ce: 0.010515
 73%|█████████████████████▏       | 292/400 [2:12:32<48:04, 26.71s/it]2021-12-16 16:32:28,597 iteration 4965 : loss : 0.051657, loss_ce: 0.019641
2021-12-16 16:32:30,104 iteration 4966 : loss : 0.035940, loss_ce: 0.014787
2021-12-16 16:32:31,561 iteration 4967 : loss : 0.036281, loss_ce: 0.018021
2021-12-16 16:32:33,038 iteration 4968 : loss : 0.030354, loss_ce: 0.014830
2021-12-16 16:32:34,610 iteration 4969 : loss : 0.072811, loss_ce: 0.021825
2021-12-16 16:32:36,023 iteration 4970 : loss : 0.024489, loss_ce: 0.011077
2021-12-16 16:32:37,460 iteration 4971 : loss : 0.038934, loss_ce: 0.020721
2021-12-16 16:32:38,959 iteration 4972 : loss : 0.041204, loss_ce: 0.020020
2021-12-16 16:32:40,408 iteration 4973 : loss : 0.045862, loss_ce: 0.021385
2021-12-16 16:32:41,982 iteration 4974 : loss : 0.044369, loss_ce: 0.016472
2021-12-16 16:32:43,415 iteration 4975 : loss : 0.031185, loss_ce: 0.012682
2021-12-16 16:32:44,819 iteration 4976 : loss : 0.032159, loss_ce: 0.013184
2021-12-16 16:32:46,324 iteration 4977 : loss : 0.043730, loss_ce: 0.013054
2021-12-16 16:32:47,770 iteration 4978 : loss : 0.031829, loss_ce: 0.010357
2021-12-16 16:32:49,225 iteration 4979 : loss : 0.029728, loss_ce: 0.012625
2021-12-16 16:32:50,690 iteration 4980 : loss : 0.051856, loss_ce: 0.017775
2021-12-16 16:32:52,133 iteration 4981 : loss : 0.039491, loss_ce: 0.014628
 73%|█████████████████████▏       | 293/400 [2:12:57<46:47, 26.24s/it]2021-12-16 16:32:53,632 iteration 4982 : loss : 0.028702, loss_ce: 0.013937
2021-12-16 16:32:55,081 iteration 4983 : loss : 0.031672, loss_ce: 0.014952
2021-12-16 16:32:56,643 iteration 4984 : loss : 0.033372, loss_ce: 0.014664
2021-12-16 16:32:58,030 iteration 4985 : loss : 0.023385, loss_ce: 0.008366
2021-12-16 16:32:59,575 iteration 4986 : loss : 0.039335, loss_ce: 0.017641
2021-12-16 16:33:01,009 iteration 4987 : loss : 0.027476, loss_ce: 0.010321
2021-12-16 16:33:02,477 iteration 4988 : loss : 0.033866, loss_ce: 0.012468
2021-12-16 16:33:03,985 iteration 4989 : loss : 0.044184, loss_ce: 0.017046
2021-12-16 16:33:05,519 iteration 4990 : loss : 0.036994, loss_ce: 0.017704
2021-12-16 16:33:06,981 iteration 4991 : loss : 0.055965, loss_ce: 0.015546
2021-12-16 16:33:08,341 iteration 4992 : loss : 0.029731, loss_ce: 0.015874
2021-12-16 16:33:09,796 iteration 4993 : loss : 0.029093, loss_ce: 0.012087
2021-12-16 16:33:11,221 iteration 4994 : loss : 0.033176, loss_ce: 0.011292
2021-12-16 16:33:12,656 iteration 4995 : loss : 0.031823, loss_ce: 0.016587
2021-12-16 16:33:14,169 iteration 4996 : loss : 0.060450, loss_ce: 0.025312
2021-12-16 16:33:15,540 iteration 4997 : loss : 0.029028, loss_ce: 0.009953
2021-12-16 16:33:16,943 iteration 4998 : loss : 0.028344, loss_ce: 0.012323
 74%|█████████████████████▎       | 294/400 [2:13:22<45:36, 25.81s/it]2021-12-16 16:33:18,430 iteration 4999 : loss : 0.032201, loss_ce: 0.013745
2021-12-16 16:33:19,874 iteration 5000 : loss : 0.030004, loss_ce: 0.013675
2021-12-16 16:33:21,331 iteration 5001 : loss : 0.035895, loss_ce: 0.018530
2021-12-16 16:33:22,758 iteration 5002 : loss : 0.025943, loss_ce: 0.010633
2021-12-16 16:33:24,230 iteration 5003 : loss : 0.054414, loss_ce: 0.013886
2021-12-16 16:33:25,699 iteration 5004 : loss : 0.045303, loss_ce: 0.018284
2021-12-16 16:33:27,159 iteration 5005 : loss : 0.037488, loss_ce: 0.017727
2021-12-16 16:33:28,707 iteration 5006 : loss : 0.041512, loss_ce: 0.018362
2021-12-16 16:33:30,197 iteration 5007 : loss : 0.056337, loss_ce: 0.025464
2021-12-16 16:33:31,685 iteration 5008 : loss : 0.051135, loss_ce: 0.025066
2021-12-16 16:33:33,184 iteration 5009 : loss : 0.038680, loss_ce: 0.011873
2021-12-16 16:33:34,652 iteration 5010 : loss : 0.040364, loss_ce: 0.016454
2021-12-16 16:33:36,079 iteration 5011 : loss : 0.029441, loss_ce: 0.015578
2021-12-16 16:33:37,543 iteration 5012 : loss : 0.032345, loss_ce: 0.013518
2021-12-16 16:33:38,941 iteration 5013 : loss : 0.029235, loss_ce: 0.012777
2021-12-16 16:33:40,401 iteration 5014 : loss : 0.037601, loss_ce: 0.016669
2021-12-16 16:33:40,401 Training Data Eval:
2021-12-16 16:33:47,927   Average segmentation loss on training set: 0.0159
2021-12-16 16:33:47,928 Validation Data Eval:
2021-12-16 16:33:50,532   Average segmentation loss on validation set: 0.1001
2021-12-16 16:33:52,008 iteration 5015 : loss : 0.032708, loss_ce: 0.012931
 74%|█████████████████████▍       | 295/400 [2:13:57<50:01, 28.59s/it]2021-12-16 16:33:53,509 iteration 5016 : loss : 0.035890, loss_ce: 0.019201
2021-12-16 16:33:54,936 iteration 5017 : loss : 0.026873, loss_ce: 0.011788
2021-12-16 16:33:56,377 iteration 5018 : loss : 0.030926, loss_ce: 0.015299
2021-12-16 16:33:57,852 iteration 5019 : loss : 0.039351, loss_ce: 0.015016
2021-12-16 16:33:59,343 iteration 5020 : loss : 0.035879, loss_ce: 0.012207
2021-12-16 16:34:00,860 iteration 5021 : loss : 0.035229, loss_ce: 0.018205
2021-12-16 16:34:02,278 iteration 5022 : loss : 0.034811, loss_ce: 0.012680
2021-12-16 16:34:03,757 iteration 5023 : loss : 0.050008, loss_ce: 0.014672
2021-12-16 16:34:05,325 iteration 5024 : loss : 0.055819, loss_ce: 0.014910
2021-12-16 16:34:06,850 iteration 5025 : loss : 0.052657, loss_ce: 0.012582
2021-12-16 16:34:08,319 iteration 5026 : loss : 0.034132, loss_ce: 0.015179
2021-12-16 16:34:09,751 iteration 5027 : loss : 0.030359, loss_ce: 0.014646
2021-12-16 16:34:11,202 iteration 5028 : loss : 0.029386, loss_ce: 0.012482
2021-12-16 16:34:12,747 iteration 5029 : loss : 0.048819, loss_ce: 0.012373
2021-12-16 16:34:14,202 iteration 5030 : loss : 0.040978, loss_ce: 0.023542
2021-12-16 16:34:15,734 iteration 5031 : loss : 0.053171, loss_ce: 0.021123
2021-12-16 16:34:17,217 iteration 5032 : loss : 0.032277, loss_ce: 0.016569
 74%|█████████████████████▍       | 296/400 [2:14:23<47:47, 27.57s/it]2021-12-16 16:34:18,842 iteration 5033 : loss : 0.051798, loss_ce: 0.018499
2021-12-16 16:34:20,279 iteration 5034 : loss : 0.037049, loss_ce: 0.011812
2021-12-16 16:34:21,707 iteration 5035 : loss : 0.053641, loss_ce: 0.020336
2021-12-16 16:34:23,155 iteration 5036 : loss : 0.043368, loss_ce: 0.017401
2021-12-16 16:34:24,619 iteration 5037 : loss : 0.043130, loss_ce: 0.017166
2021-12-16 16:34:26,058 iteration 5038 : loss : 0.055674, loss_ce: 0.015364
2021-12-16 16:34:27,602 iteration 5039 : loss : 0.040748, loss_ce: 0.021120
2021-12-16 16:34:29,079 iteration 5040 : loss : 0.030156, loss_ce: 0.010926
2021-12-16 16:34:30,634 iteration 5041 : loss : 0.039305, loss_ce: 0.015897
2021-12-16 16:34:32,049 iteration 5042 : loss : 0.026293, loss_ce: 0.012649
2021-12-16 16:34:33,500 iteration 5043 : loss : 0.034829, loss_ce: 0.017788
2021-12-16 16:34:34,964 iteration 5044 : loss : 0.045788, loss_ce: 0.022676
2021-12-16 16:34:36,479 iteration 5045 : loss : 0.042097, loss_ce: 0.018528
2021-12-16 16:34:37,953 iteration 5046 : loss : 0.043456, loss_ce: 0.014278
2021-12-16 16:34:39,386 iteration 5047 : loss : 0.041891, loss_ce: 0.013870
2021-12-16 16:34:40,808 iteration 5048 : loss : 0.026013, loss_ce: 0.012169
2021-12-16 16:34:42,244 iteration 5049 : loss : 0.028097, loss_ce: 0.012637
 74%|█████████████████████▌       | 297/400 [2:14:48<46:01, 26.81s/it]2021-12-16 16:34:43,760 iteration 5050 : loss : 0.046429, loss_ce: 0.017577
2021-12-16 16:34:45,217 iteration 5051 : loss : 0.037179, loss_ce: 0.016023
2021-12-16 16:34:46,694 iteration 5052 : loss : 0.037247, loss_ce: 0.018335
2021-12-16 16:34:48,140 iteration 5053 : loss : 0.026395, loss_ce: 0.011952
2021-12-16 16:34:49,598 iteration 5054 : loss : 0.037286, loss_ce: 0.013833
2021-12-16 16:34:51,028 iteration 5055 : loss : 0.029693, loss_ce: 0.012256
2021-12-16 16:34:52,466 iteration 5056 : loss : 0.041747, loss_ce: 0.012933
2021-12-16 16:34:53,983 iteration 5057 : loss : 0.034616, loss_ce: 0.018171
2021-12-16 16:34:55,511 iteration 5058 : loss : 0.043863, loss_ce: 0.020512
2021-12-16 16:34:56,837 iteration 5059 : loss : 0.025285, loss_ce: 0.008459
2021-12-16 16:34:58,287 iteration 5060 : loss : 0.039306, loss_ce: 0.013224
2021-12-16 16:34:59,776 iteration 5061 : loss : 0.031549, loss_ce: 0.014250
2021-12-16 16:35:01,267 iteration 5062 : loss : 0.041851, loss_ce: 0.015428
2021-12-16 16:35:02,800 iteration 5063 : loss : 0.042817, loss_ce: 0.019129
2021-12-16 16:35:04,225 iteration 5064 : loss : 0.031178, loss_ce: 0.014214
2021-12-16 16:35:05,652 iteration 5065 : loss : 0.030110, loss_ce: 0.012902
2021-12-16 16:35:07,126 iteration 5066 : loss : 0.026172, loss_ce: 0.016185
 74%|█████████████████████▌       | 298/400 [2:15:12<44:35, 26.23s/it]2021-12-16 16:35:08,719 iteration 5067 : loss : 0.045122, loss_ce: 0.017870
2021-12-16 16:35:10,189 iteration 5068 : loss : 0.035011, loss_ce: 0.015771
2021-12-16 16:35:11,661 iteration 5069 : loss : 0.042614, loss_ce: 0.016331
2021-12-16 16:35:13,107 iteration 5070 : loss : 0.029893, loss_ce: 0.010656
2021-12-16 16:35:14,636 iteration 5071 : loss : 0.047178, loss_ce: 0.018914
2021-12-16 16:35:15,972 iteration 5072 : loss : 0.022454, loss_ce: 0.009080
2021-12-16 16:35:17,427 iteration 5073 : loss : 0.031007, loss_ce: 0.017637
2021-12-16 16:35:18,930 iteration 5074 : loss : 0.044500, loss_ce: 0.016567
2021-12-16 16:35:20,382 iteration 5075 : loss : 0.035265, loss_ce: 0.016331
2021-12-16 16:35:21,886 iteration 5076 : loss : 0.025304, loss_ce: 0.011787
2021-12-16 16:35:23,315 iteration 5077 : loss : 0.026778, loss_ce: 0.011147
2021-12-16 16:35:24,788 iteration 5078 : loss : 0.038392, loss_ce: 0.014196
2021-12-16 16:35:26,241 iteration 5079 : loss : 0.039412, loss_ce: 0.019069
2021-12-16 16:35:27,723 iteration 5080 : loss : 0.039370, loss_ce: 0.017878
2021-12-16 16:35:29,204 iteration 5081 : loss : 0.040047, loss_ce: 0.017798
2021-12-16 16:35:30,727 iteration 5082 : loss : 0.053253, loss_ce: 0.027045
2021-12-16 16:35:32,206 iteration 5083 : loss : 0.047024, loss_ce: 0.018121
 75%|█████████████████████▋       | 299/400 [2:15:38<43:34, 25.89s/it]2021-12-16 16:35:33,679 iteration 5084 : loss : 0.023466, loss_ce: 0.010859
2021-12-16 16:35:35,132 iteration 5085 : loss : 0.049225, loss_ce: 0.019901
2021-12-16 16:35:36,554 iteration 5086 : loss : 0.025859, loss_ce: 0.011320
2021-12-16 16:35:38,075 iteration 5087 : loss : 0.064169, loss_ce: 0.027295
2021-12-16 16:35:39,573 iteration 5088 : loss : 0.027232, loss_ce: 0.011025
2021-12-16 16:35:40,989 iteration 5089 : loss : 0.025803, loss_ce: 0.010396
2021-12-16 16:35:42,438 iteration 5090 : loss : 0.024116, loss_ce: 0.010003
2021-12-16 16:35:44,003 iteration 5091 : loss : 0.067206, loss_ce: 0.031895
2021-12-16 16:35:45,464 iteration 5092 : loss : 0.027579, loss_ce: 0.015142
2021-12-16 16:35:46,895 iteration 5093 : loss : 0.034395, loss_ce: 0.017647
2021-12-16 16:35:48,295 iteration 5094 : loss : 0.022920, loss_ce: 0.009986
2021-12-16 16:35:49,823 iteration 5095 : loss : 0.049594, loss_ce: 0.021721
2021-12-16 16:35:51,245 iteration 5096 : loss : 0.024488, loss_ce: 0.011619
2021-12-16 16:35:52,675 iteration 5097 : loss : 0.029520, loss_ce: 0.015480
2021-12-16 16:35:54,141 iteration 5098 : loss : 0.070444, loss_ce: 0.028692
2021-12-16 16:35:55,582 iteration 5099 : loss : 0.033363, loss_ce: 0.014080
2021-12-16 16:35:55,583 Training Data Eval:
2021-12-16 16:36:03,118   Average segmentation loss on training set: 0.0165
2021-12-16 16:36:03,119 Validation Data Eval:
2021-12-16 16:36:05,720   Average segmentation loss on validation set: 0.1018
2021-12-16 16:36:07,197 iteration 5100 : loss : 0.025144, loss_ce: 0.013341
 75%|█████████████████████▊       | 300/400 [2:16:13<47:41, 28.62s/it]2021-12-16 16:36:08,735 iteration 5101 : loss : 0.029172, loss_ce: 0.013966
2021-12-16 16:36:10,166 iteration 5102 : loss : 0.033199, loss_ce: 0.015543
2021-12-16 16:36:11,630 iteration 5103 : loss : 0.030909, loss_ce: 0.014034
2021-12-16 16:36:13,173 iteration 5104 : loss : 0.042596, loss_ce: 0.017779
2021-12-16 16:36:14,581 iteration 5105 : loss : 0.027705, loss_ce: 0.010630
2021-12-16 16:36:16,109 iteration 5106 : loss : 0.028834, loss_ce: 0.011800
2021-12-16 16:36:17,513 iteration 5107 : loss : 0.024772, loss_ce: 0.011006
2021-12-16 16:36:19,003 iteration 5108 : loss : 0.045274, loss_ce: 0.017606
2021-12-16 16:36:20,489 iteration 5109 : loss : 0.039187, loss_ce: 0.014902
2021-12-16 16:36:21,946 iteration 5110 : loss : 0.031428, loss_ce: 0.015844
2021-12-16 16:36:23,435 iteration 5111 : loss : 0.033493, loss_ce: 0.012653
2021-12-16 16:36:24,838 iteration 5112 : loss : 0.038365, loss_ce: 0.013375
2021-12-16 16:36:26,353 iteration 5113 : loss : 0.079029, loss_ce: 0.014847
2021-12-16 16:36:27,791 iteration 5114 : loss : 0.034867, loss_ce: 0.017977
2021-12-16 16:36:29,209 iteration 5115 : loss : 0.035877, loss_ce: 0.011742
2021-12-16 16:36:30,628 iteration 5116 : loss : 0.024676, loss_ce: 0.011382
2021-12-16 16:36:32,183 iteration 5117 : loss : 0.051419, loss_ce: 0.026843
 75%|█████████████████████▊       | 301/400 [2:16:38<45:25, 27.53s/it]2021-12-16 16:36:33,683 iteration 5118 : loss : 0.026529, loss_ce: 0.012050
2021-12-16 16:36:35,143 iteration 5119 : loss : 0.036762, loss_ce: 0.013257
2021-12-16 16:36:36,555 iteration 5120 : loss : 0.034767, loss_ce: 0.011159
2021-12-16 16:36:38,002 iteration 5121 : loss : 0.040973, loss_ce: 0.022599
2021-12-16 16:36:39,413 iteration 5122 : loss : 0.034063, loss_ce: 0.014471
2021-12-16 16:36:40,869 iteration 5123 : loss : 0.035433, loss_ce: 0.011924
2021-12-16 16:36:42,360 iteration 5124 : loss : 0.026345, loss_ce: 0.011631
2021-12-16 16:36:43,736 iteration 5125 : loss : 0.036886, loss_ce: 0.020151
2021-12-16 16:36:45,148 iteration 5126 : loss : 0.042443, loss_ce: 0.017254
2021-12-16 16:36:46,672 iteration 5127 : loss : 0.047725, loss_ce: 0.017609
2021-12-16 16:36:48,121 iteration 5128 : loss : 0.022433, loss_ce: 0.010444
2021-12-16 16:36:49,594 iteration 5129 : loss : 0.034517, loss_ce: 0.012504
2021-12-16 16:36:51,046 iteration 5130 : loss : 0.028778, loss_ce: 0.010292
2021-12-16 16:36:52,417 iteration 5131 : loss : 0.021648, loss_ce: 0.009359
2021-12-16 16:36:53,874 iteration 5132 : loss : 0.037011, loss_ce: 0.019356
2021-12-16 16:36:55,353 iteration 5133 : loss : 0.042466, loss_ce: 0.013184
2021-12-16 16:36:56,759 iteration 5134 : loss : 0.030544, loss_ce: 0.014712
 76%|█████████████████████▉       | 302/400 [2:17:02<43:31, 26.64s/it]2021-12-16 16:36:58,415 iteration 5135 : loss : 0.056893, loss_ce: 0.023716
2021-12-16 16:36:59,861 iteration 5136 : loss : 0.033955, loss_ce: 0.012194
2021-12-16 16:37:01,364 iteration 5137 : loss : 0.035787, loss_ce: 0.011959
2021-12-16 16:37:02,779 iteration 5138 : loss : 0.030778, loss_ce: 0.014939
2021-12-16 16:37:04,231 iteration 5139 : loss : 0.025424, loss_ce: 0.011392
2021-12-16 16:37:05,772 iteration 5140 : loss : 0.030080, loss_ce: 0.014009
2021-12-16 16:37:07,184 iteration 5141 : loss : 0.032980, loss_ce: 0.012774
2021-12-16 16:37:08,652 iteration 5142 : loss : 0.037602, loss_ce: 0.014873
2021-12-16 16:37:10,032 iteration 5143 : loss : 0.022514, loss_ce: 0.010539
2021-12-16 16:37:11,540 iteration 5144 : loss : 0.041162, loss_ce: 0.022956
2021-12-16 16:37:12,920 iteration 5145 : loss : 0.026517, loss_ce: 0.010895
2021-12-16 16:37:14,459 iteration 5146 : loss : 0.039033, loss_ce: 0.022080
2021-12-16 16:37:15,989 iteration 5147 : loss : 0.035531, loss_ce: 0.014221
2021-12-16 16:37:17,426 iteration 5148 : loss : 0.030511, loss_ce: 0.014925
2021-12-16 16:37:18,873 iteration 5149 : loss : 0.042922, loss_ce: 0.013120
2021-12-16 16:37:20,317 iteration 5150 : loss : 0.038489, loss_ce: 0.018657
2021-12-16 16:37:21,765 iteration 5151 : loss : 0.052178, loss_ce: 0.012149
 76%|█████████████████████▉       | 303/400 [2:17:27<42:16, 26.15s/it]2021-12-16 16:37:23,200 iteration 5152 : loss : 0.032434, loss_ce: 0.009522
2021-12-16 16:37:24,561 iteration 5153 : loss : 0.024983, loss_ce: 0.011657
2021-12-16 16:37:26,095 iteration 5154 : loss : 0.035626, loss_ce: 0.017642
2021-12-16 16:37:27,498 iteration 5155 : loss : 0.021945, loss_ce: 0.009356
2021-12-16 16:37:28,939 iteration 5156 : loss : 0.033892, loss_ce: 0.015578
2021-12-16 16:37:30,334 iteration 5157 : loss : 0.022940, loss_ce: 0.009039
2021-12-16 16:37:31,780 iteration 5158 : loss : 0.035595, loss_ce: 0.014101
2021-12-16 16:37:33,290 iteration 5159 : loss : 0.038044, loss_ce: 0.014486
2021-12-16 16:37:34,675 iteration 5160 : loss : 0.021182, loss_ce: 0.009089
2021-12-16 16:37:36,116 iteration 5161 : loss : 0.038526, loss_ce: 0.015571
2021-12-16 16:37:37,517 iteration 5162 : loss : 0.032457, loss_ce: 0.016435
2021-12-16 16:37:38,987 iteration 5163 : loss : 0.033209, loss_ce: 0.016379
2021-12-16 16:37:40,456 iteration 5164 : loss : 0.035711, loss_ce: 0.019073
2021-12-16 16:37:41,841 iteration 5165 : loss : 0.035822, loss_ce: 0.013195
2021-12-16 16:37:43,292 iteration 5166 : loss : 0.027826, loss_ce: 0.013699
2021-12-16 16:37:44,759 iteration 5167 : loss : 0.048689, loss_ce: 0.019835
2021-12-16 16:37:46,261 iteration 5168 : loss : 0.035312, loss_ce: 0.014345
 76%|██████████████████████       | 304/400 [2:17:52<41:02, 25.66s/it]2021-12-16 16:37:47,864 iteration 5169 : loss : 0.045328, loss_ce: 0.023141
2021-12-16 16:37:49,269 iteration 5170 : loss : 0.029519, loss_ce: 0.010344
2021-12-16 16:37:50,805 iteration 5171 : loss : 0.031001, loss_ce: 0.014130
2021-12-16 16:37:52,193 iteration 5172 : loss : 0.024544, loss_ce: 0.009164
2021-12-16 16:37:53,526 iteration 5173 : loss : 0.021985, loss_ce: 0.011069
2021-12-16 16:37:55,049 iteration 5174 : loss : 0.036048, loss_ce: 0.014736
2021-12-16 16:37:56,475 iteration 5175 : loss : 0.031058, loss_ce: 0.016140
2021-12-16 16:37:58,053 iteration 5176 : loss : 0.038409, loss_ce: 0.016718
2021-12-16 16:37:59,439 iteration 5177 : loss : 0.036608, loss_ce: 0.015514
2021-12-16 16:38:00,862 iteration 5178 : loss : 0.022164, loss_ce: 0.008533
2021-12-16 16:38:02,368 iteration 5179 : loss : 0.032578, loss_ce: 0.012599
2021-12-16 16:38:03,816 iteration 5180 : loss : 0.039797, loss_ce: 0.015965
2021-12-16 16:38:05,216 iteration 5181 : loss : 0.029723, loss_ce: 0.010372
2021-12-16 16:38:06,661 iteration 5182 : loss : 0.026607, loss_ce: 0.012180
2021-12-16 16:38:08,094 iteration 5183 : loss : 0.027245, loss_ce: 0.013627
2021-12-16 16:38:09,546 iteration 5184 : loss : 0.042791, loss_ce: 0.016836
2021-12-16 16:38:09,546 Training Data Eval:
2021-12-16 16:38:17,065   Average segmentation loss on training set: 0.0160
2021-12-16 16:38:17,066 Validation Data Eval:
2021-12-16 16:38:19,662   Average segmentation loss on validation set: 0.0959
2021-12-16 16:38:21,120 iteration 5185 : loss : 0.044001, loss_ce: 0.017725
 76%|██████████████████████       | 305/400 [2:18:26<44:59, 28.42s/it]2021-12-16 16:38:22,637 iteration 5186 : loss : 0.031276, loss_ce: 0.016431
2021-12-16 16:38:24,046 iteration 5187 : loss : 0.028915, loss_ce: 0.013204
2021-12-16 16:38:25,450 iteration 5188 : loss : 0.028663, loss_ce: 0.013578
2021-12-16 16:38:26,874 iteration 5189 : loss : 0.028230, loss_ce: 0.014454
2021-12-16 16:38:28,289 iteration 5190 : loss : 0.029749, loss_ce: 0.014799
2021-12-16 16:38:29,804 iteration 5191 : loss : 0.039094, loss_ce: 0.014311
2021-12-16 16:38:31,291 iteration 5192 : loss : 0.039082, loss_ce: 0.015571
2021-12-16 16:38:32,717 iteration 5193 : loss : 0.020209, loss_ce: 0.008188
2021-12-16 16:38:34,215 iteration 5194 : loss : 0.041058, loss_ce: 0.017656
2021-12-16 16:38:35,632 iteration 5195 : loss : 0.024471, loss_ce: 0.009792
2021-12-16 16:38:36,995 iteration 5196 : loss : 0.022414, loss_ce: 0.007714
2021-12-16 16:38:38,393 iteration 5197 : loss : 0.026473, loss_ce: 0.011353
2021-12-16 16:38:39,813 iteration 5198 : loss : 0.031044, loss_ce: 0.015309
2021-12-16 16:38:41,307 iteration 5199 : loss : 0.022058, loss_ce: 0.010140
2021-12-16 16:38:42,763 iteration 5200 : loss : 0.046295, loss_ce: 0.015646
2021-12-16 16:38:44,231 iteration 5201 : loss : 0.048833, loss_ce: 0.019814
2021-12-16 16:38:45,751 iteration 5202 : loss : 0.047892, loss_ce: 0.021953
 76%|██████████████████████▏      | 306/400 [2:18:51<42:44, 27.28s/it]2021-12-16 16:38:47,185 iteration 5203 : loss : 0.027325, loss_ce: 0.012237
2021-12-16 16:38:48,602 iteration 5204 : loss : 0.032664, loss_ce: 0.015239
2021-12-16 16:38:50,182 iteration 5205 : loss : 0.044150, loss_ce: 0.017944
2021-12-16 16:38:51,626 iteration 5206 : loss : 0.031504, loss_ce: 0.012913
2021-12-16 16:38:53,091 iteration 5207 : loss : 0.036672, loss_ce: 0.015560
2021-12-16 16:38:54,614 iteration 5208 : loss : 0.037329, loss_ce: 0.015764
2021-12-16 16:38:56,000 iteration 5209 : loss : 0.033151, loss_ce: 0.017669
2021-12-16 16:38:57,494 iteration 5210 : loss : 0.036905, loss_ce: 0.015888
2021-12-16 16:38:58,964 iteration 5211 : loss : 0.033035, loss_ce: 0.015483
2021-12-16 16:39:00,426 iteration 5212 : loss : 0.042185, loss_ce: 0.015668
2021-12-16 16:39:01,770 iteration 5213 : loss : 0.026602, loss_ce: 0.010865
2021-12-16 16:39:03,304 iteration 5214 : loss : 0.070347, loss_ce: 0.037111
2021-12-16 16:39:04,803 iteration 5215 : loss : 0.044405, loss_ce: 0.018624
2021-12-16 16:39:06,299 iteration 5216 : loss : 0.027693, loss_ce: 0.011290
2021-12-16 16:39:07,842 iteration 5217 : loss : 0.035646, loss_ce: 0.014762
2021-12-16 16:39:09,258 iteration 5218 : loss : 0.046422, loss_ce: 0.011781
2021-12-16 16:39:10,812 iteration 5219 : loss : 0.038456, loss_ce: 0.017186
 77%|██████████████████████▎      | 307/400 [2:19:16<41:15, 26.62s/it]2021-12-16 16:39:12,268 iteration 5220 : loss : 0.043867, loss_ce: 0.016423
2021-12-16 16:39:13,703 iteration 5221 : loss : 0.037594, loss_ce: 0.014005
2021-12-16 16:39:15,097 iteration 5222 : loss : 0.042316, loss_ce: 0.019235
2021-12-16 16:39:16,601 iteration 5223 : loss : 0.037072, loss_ce: 0.016502
2021-12-16 16:39:18,035 iteration 5224 : loss : 0.033694, loss_ce: 0.011736
2021-12-16 16:39:19,538 iteration 5225 : loss : 0.035710, loss_ce: 0.014981
2021-12-16 16:39:20,962 iteration 5226 : loss : 0.036903, loss_ce: 0.016315
2021-12-16 16:39:22,492 iteration 5227 : loss : 0.050584, loss_ce: 0.023194
2021-12-16 16:39:23,900 iteration 5228 : loss : 0.026477, loss_ce: 0.010331
2021-12-16 16:39:25,470 iteration 5229 : loss : 0.029051, loss_ce: 0.013623
2021-12-16 16:39:26,813 iteration 5230 : loss : 0.024793, loss_ce: 0.011829
2021-12-16 16:39:28,319 iteration 5231 : loss : 0.038423, loss_ce: 0.016091
2021-12-16 16:39:29,784 iteration 5232 : loss : 0.036642, loss_ce: 0.012224
2021-12-16 16:39:31,271 iteration 5233 : loss : 0.031627, loss_ce: 0.013842
2021-12-16 16:39:32,692 iteration 5234 : loss : 0.034710, loss_ce: 0.015812
2021-12-16 16:39:34,160 iteration 5235 : loss : 0.033942, loss_ce: 0.013701
2021-12-16 16:39:35,653 iteration 5236 : loss : 0.040498, loss_ce: 0.016955
 77%|██████████████████████▎      | 308/400 [2:19:41<39:59, 26.08s/it]2021-12-16 16:39:37,035 iteration 5237 : loss : 0.020164, loss_ce: 0.009718
2021-12-16 16:39:38,521 iteration 5238 : loss : 0.029567, loss_ce: 0.015313
2021-12-16 16:39:40,001 iteration 5239 : loss : 0.053808, loss_ce: 0.019152
2021-12-16 16:39:41,501 iteration 5240 : loss : 0.185514, loss_ce: 0.013709
2021-12-16 16:39:42,916 iteration 5241 : loss : 0.025791, loss_ce: 0.011594
2021-12-16 16:39:44,372 iteration 5242 : loss : 0.047376, loss_ce: 0.023360
2021-12-16 16:39:45,916 iteration 5243 : loss : 0.046594, loss_ce: 0.018517
2021-12-16 16:39:47,395 iteration 5244 : loss : 0.034817, loss_ce: 0.017509
2021-12-16 16:39:48,845 iteration 5245 : loss : 0.032953, loss_ce: 0.012601
2021-12-16 16:39:50,302 iteration 5246 : loss : 0.046717, loss_ce: 0.016033
2021-12-16 16:39:51,657 iteration 5247 : loss : 0.026787, loss_ce: 0.011441
2021-12-16 16:39:53,141 iteration 5248 : loss : 0.035124, loss_ce: 0.012902
2021-12-16 16:39:54,687 iteration 5249 : loss : 0.039466, loss_ce: 0.015313
2021-12-16 16:39:56,166 iteration 5250 : loss : 0.041954, loss_ce: 0.020974
2021-12-16 16:39:57,526 iteration 5251 : loss : 0.024954, loss_ce: 0.010178
2021-12-16 16:39:58,992 iteration 5252 : loss : 0.030781, loss_ce: 0.014370
2021-12-16 16:40:00,493 iteration 5253 : loss : 0.054590, loss_ce: 0.017722
 77%|██████████████████████▍      | 309/400 [2:20:06<38:59, 25.71s/it]2021-12-16 16:40:01,981 iteration 5254 : loss : 0.025606, loss_ce: 0.011912
2021-12-16 16:40:03,422 iteration 5255 : loss : 0.039939, loss_ce: 0.022294
2021-12-16 16:40:04,817 iteration 5256 : loss : 0.024301, loss_ce: 0.011529
2021-12-16 16:40:06,280 iteration 5257 : loss : 0.033120, loss_ce: 0.016737
2021-12-16 16:40:07,776 iteration 5258 : loss : 0.031027, loss_ce: 0.010235
2021-12-16 16:40:09,193 iteration 5259 : loss : 0.036708, loss_ce: 0.010068
2021-12-16 16:40:10,682 iteration 5260 : loss : 0.027173, loss_ce: 0.011773
2021-12-16 16:40:12,174 iteration 5261 : loss : 0.056074, loss_ce: 0.023597
2021-12-16 16:40:13,627 iteration 5262 : loss : 0.021929, loss_ce: 0.010077
2021-12-16 16:40:15,091 iteration 5263 : loss : 0.030063, loss_ce: 0.014769
2021-12-16 16:40:16,483 iteration 5264 : loss : 0.027119, loss_ce: 0.013384
2021-12-16 16:40:17,972 iteration 5265 : loss : 0.035805, loss_ce: 0.016421
2021-12-16 16:40:19,508 iteration 5266 : loss : 0.042602, loss_ce: 0.017707
2021-12-16 16:40:20,967 iteration 5267 : loss : 0.068951, loss_ce: 0.021186
2021-12-16 16:40:22,442 iteration 5268 : loss : 0.044125, loss_ce: 0.013134
2021-12-16 16:40:24,003 iteration 5269 : loss : 0.036013, loss_ce: 0.012878
2021-12-16 16:40:24,003 Training Data Eval:
2021-12-16 16:40:31,489   Average segmentation loss on training set: 0.0159
2021-12-16 16:40:31,489 Validation Data Eval:
2021-12-16 16:40:34,097   Average segmentation loss on validation set: 0.1022
2021-12-16 16:40:35,564 iteration 5270 : loss : 0.024971, loss_ce: 0.012949
 78%|██████████████████████▍      | 310/400 [2:20:41<42:46, 28.52s/it]2021-12-16 16:40:37,044 iteration 5271 : loss : 0.048302, loss_ce: 0.019157
2021-12-16 16:40:38,535 iteration 5272 : loss : 0.041718, loss_ce: 0.023271
2021-12-16 16:40:39,967 iteration 5273 : loss : 0.039457, loss_ce: 0.016280
2021-12-16 16:40:41,415 iteration 5274 : loss : 0.035420, loss_ce: 0.014705
2021-12-16 16:40:42,801 iteration 5275 : loss : 0.022953, loss_ce: 0.011781
2021-12-16 16:40:44,309 iteration 5276 : loss : 0.036895, loss_ce: 0.016798
2021-12-16 16:40:45,776 iteration 5277 : loss : 0.022734, loss_ce: 0.010334
2021-12-16 16:40:47,150 iteration 5278 : loss : 0.026093, loss_ce: 0.012524
2021-12-16 16:40:48,613 iteration 5279 : loss : 0.030814, loss_ce: 0.014985
2021-12-16 16:40:50,205 iteration 5280 : loss : 0.032582, loss_ce: 0.013417
2021-12-16 16:40:51,636 iteration 5281 : loss : 0.029776, loss_ce: 0.012636
2021-12-16 16:40:53,030 iteration 5282 : loss : 0.022445, loss_ce: 0.008492
2021-12-16 16:40:54,497 iteration 5283 : loss : 0.050990, loss_ce: 0.021945
2021-12-16 16:40:55,969 iteration 5284 : loss : 0.047862, loss_ce: 0.015097
2021-12-16 16:40:57,404 iteration 5285 : loss : 0.037154, loss_ce: 0.019506
2021-12-16 16:40:58,764 iteration 5286 : loss : 0.026911, loss_ce: 0.012396
2021-12-16 16:41:00,206 iteration 5287 : loss : 0.032300, loss_ce: 0.009815
 78%|██████████████████████▌      | 311/400 [2:21:06<40:34, 27.35s/it]2021-12-16 16:41:01,733 iteration 5288 : loss : 0.039480, loss_ce: 0.016993
2021-12-16 16:41:03,221 iteration 5289 : loss : 0.049612, loss_ce: 0.015986
2021-12-16 16:41:04,662 iteration 5290 : loss : 0.029994, loss_ce: 0.009294
2021-12-16 16:41:06,088 iteration 5291 : loss : 0.037849, loss_ce: 0.014778
2021-12-16 16:41:07,582 iteration 5292 : loss : 0.039583, loss_ce: 0.016607
2021-12-16 16:41:09,067 iteration 5293 : loss : 0.035594, loss_ce: 0.018392
2021-12-16 16:41:10,559 iteration 5294 : loss : 0.034009, loss_ce: 0.013931
2021-12-16 16:41:12,092 iteration 5295 : loss : 0.043606, loss_ce: 0.017867
2021-12-16 16:41:13,584 iteration 5296 : loss : 0.059847, loss_ce: 0.016747
2021-12-16 16:41:15,073 iteration 5297 : loss : 0.027075, loss_ce: 0.010797
2021-12-16 16:41:16,566 iteration 5298 : loss : 0.050633, loss_ce: 0.020557
2021-12-16 16:41:18,047 iteration 5299 : loss : 0.039797, loss_ce: 0.015182
2021-12-16 16:41:19,549 iteration 5300 : loss : 0.041082, loss_ce: 0.016131
2021-12-16 16:41:20,928 iteration 5301 : loss : 0.027089, loss_ce: 0.012362
2021-12-16 16:41:22,327 iteration 5302 : loss : 0.028122, loss_ce: 0.015663
2021-12-16 16:41:23,753 iteration 5303 : loss : 0.034821, loss_ce: 0.014401
2021-12-16 16:41:25,144 iteration 5304 : loss : 0.028514, loss_ce: 0.012464
 78%|██████████████████████▌      | 312/400 [2:21:30<39:03, 26.63s/it]2021-12-16 16:41:26,653 iteration 5305 : loss : 0.042237, loss_ce: 0.016120
2021-12-16 16:41:28,206 iteration 5306 : loss : 0.044632, loss_ce: 0.020539
2021-12-16 16:41:29,756 iteration 5307 : loss : 0.055706, loss_ce: 0.021312
2021-12-16 16:41:31,315 iteration 5308 : loss : 0.069251, loss_ce: 0.020609
2021-12-16 16:41:32,826 iteration 5309 : loss : 0.040792, loss_ce: 0.015926
2021-12-16 16:41:34,258 iteration 5310 : loss : 0.033108, loss_ce: 0.017285
2021-12-16 16:41:35,686 iteration 5311 : loss : 0.059029, loss_ce: 0.017932
2021-12-16 16:41:37,207 iteration 5312 : loss : 0.034412, loss_ce: 0.017908
2021-12-16 16:41:38,793 iteration 5313 : loss : 0.080875, loss_ce: 0.021581
2021-12-16 16:41:40,236 iteration 5314 : loss : 0.036256, loss_ce: 0.015642
2021-12-16 16:41:41,747 iteration 5315 : loss : 0.045268, loss_ce: 0.013064
2021-12-16 16:41:43,240 iteration 5316 : loss : 0.028750, loss_ce: 0.011723
2021-12-16 16:41:44,678 iteration 5317 : loss : 0.032977, loss_ce: 0.017062
2021-12-16 16:41:46,099 iteration 5318 : loss : 0.029174, loss_ce: 0.012227
2021-12-16 16:41:47,629 iteration 5319 : loss : 0.033938, loss_ce: 0.015041
2021-12-16 16:41:49,130 iteration 5320 : loss : 0.051471, loss_ce: 0.023668
2021-12-16 16:41:50,657 iteration 5321 : loss : 0.051767, loss_ce: 0.024489
 78%|██████████████████████▋      | 313/400 [2:21:56<38:07, 26.29s/it]2021-12-16 16:41:52,068 iteration 5322 : loss : 0.025563, loss_ce: 0.011609
2021-12-16 16:41:53,538 iteration 5323 : loss : 0.037024, loss_ce: 0.018184
2021-12-16 16:41:54,930 iteration 5324 : loss : 0.028017, loss_ce: 0.011197
2021-12-16 16:41:56,355 iteration 5325 : loss : 0.036622, loss_ce: 0.010278
2021-12-16 16:41:57,833 iteration 5326 : loss : 0.041085, loss_ce: 0.015759
2021-12-16 16:41:59,238 iteration 5327 : loss : 0.022004, loss_ce: 0.008824
2021-12-16 16:42:00,677 iteration 5328 : loss : 0.031867, loss_ce: 0.017208
2021-12-16 16:42:02,186 iteration 5329 : loss : 0.049183, loss_ce: 0.018203
2021-12-16 16:42:03,705 iteration 5330 : loss : 0.033363, loss_ce: 0.014899
2021-12-16 16:42:05,153 iteration 5331 : loss : 0.028447, loss_ce: 0.010310
2021-12-16 16:42:06,622 iteration 5332 : loss : 0.045737, loss_ce: 0.014764
2021-12-16 16:42:08,115 iteration 5333 : loss : 0.044461, loss_ce: 0.024024
2021-12-16 16:42:09,581 iteration 5334 : loss : 0.069422, loss_ce: 0.031576
2021-12-16 16:42:11,113 iteration 5335 : loss : 0.028988, loss_ce: 0.010932
2021-12-16 16:42:12,567 iteration 5336 : loss : 0.037707, loss_ce: 0.017416
2021-12-16 16:42:13,979 iteration 5337 : loss : 0.024815, loss_ce: 0.011202
2021-12-16 16:42:15,401 iteration 5338 : loss : 0.024030, loss_ce: 0.012048
 78%|██████████████████████▊      | 314/400 [2:22:21<37:01, 25.83s/it]2021-12-16 16:42:17,062 iteration 5339 : loss : 0.045754, loss_ce: 0.020404
2021-12-16 16:42:18,575 iteration 5340 : loss : 0.034697, loss_ce: 0.018995
2021-12-16 16:42:20,041 iteration 5341 : loss : 0.042039, loss_ce: 0.009432
2021-12-16 16:42:21,507 iteration 5342 : loss : 0.033124, loss_ce: 0.018971
2021-12-16 16:42:22,943 iteration 5343 : loss : 0.037182, loss_ce: 0.015022
2021-12-16 16:42:24,436 iteration 5344 : loss : 0.035337, loss_ce: 0.014954
2021-12-16 16:42:25,886 iteration 5345 : loss : 0.027742, loss_ce: 0.011550
2021-12-16 16:42:27,392 iteration 5346 : loss : 0.046591, loss_ce: 0.017741
2021-12-16 16:42:28,896 iteration 5347 : loss : 0.024184, loss_ce: 0.009676
2021-12-16 16:42:30,406 iteration 5348 : loss : 0.055706, loss_ce: 0.014754
2021-12-16 16:42:31,862 iteration 5349 : loss : 0.041469, loss_ce: 0.017968
2021-12-16 16:42:33,243 iteration 5350 : loss : 0.021945, loss_ce: 0.009818
2021-12-16 16:42:34,646 iteration 5351 : loss : 0.051998, loss_ce: 0.021157
2021-12-16 16:42:36,170 iteration 5352 : loss : 0.029258, loss_ce: 0.014592
2021-12-16 16:42:37,680 iteration 5353 : loss : 0.023887, loss_ce: 0.010211
2021-12-16 16:42:39,105 iteration 5354 : loss : 0.028174, loss_ce: 0.014446
2021-12-16 16:42:39,105 Training Data Eval:
2021-12-16 16:42:46,634   Average segmentation loss on training set: 0.0170
2021-12-16 16:42:46,635 Validation Data Eval:
2021-12-16 16:42:49,238   Average segmentation loss on validation set: 0.1055
2021-12-16 16:42:50,648 iteration 5355 : loss : 0.036732, loss_ce: 0.015408
 79%|██████████████████████▊      | 315/400 [2:22:56<40:35, 28.66s/it]2021-12-16 16:42:52,157 iteration 5356 : loss : 0.042278, loss_ce: 0.022452
2021-12-16 16:42:53,539 iteration 5357 : loss : 0.053972, loss_ce: 0.013709
2021-12-16 16:42:55,140 iteration 5358 : loss : 0.050664, loss_ce: 0.023985
2021-12-16 16:42:56,519 iteration 5359 : loss : 0.022350, loss_ce: 0.010075
2021-12-16 16:42:58,016 iteration 5360 : loss : 0.046984, loss_ce: 0.020561
2021-12-16 16:42:59,494 iteration 5361 : loss : 0.039731, loss_ce: 0.016115
2021-12-16 16:43:00,981 iteration 5362 : loss : 0.033198, loss_ce: 0.011178
2021-12-16 16:43:02,438 iteration 5363 : loss : 0.032838, loss_ce: 0.015348
2021-12-16 16:43:03,906 iteration 5364 : loss : 0.045491, loss_ce: 0.011800
2021-12-16 16:43:05,356 iteration 5365 : loss : 0.032126, loss_ce: 0.014664
2021-12-16 16:43:06,832 iteration 5366 : loss : 0.032823, loss_ce: 0.013637
2021-12-16 16:43:08,342 iteration 5367 : loss : 0.039694, loss_ce: 0.020627
2021-12-16 16:43:09,765 iteration 5368 : loss : 0.027188, loss_ce: 0.013616
2021-12-16 16:43:11,231 iteration 5369 : loss : 0.024088, loss_ce: 0.010213
2021-12-16 16:43:12,676 iteration 5370 : loss : 0.021541, loss_ce: 0.010288
2021-12-16 16:43:14,155 iteration 5371 : loss : 0.046477, loss_ce: 0.023896
2021-12-16 16:43:15,636 iteration 5372 : loss : 0.038492, loss_ce: 0.012846
 79%|██████████████████████▉      | 316/400 [2:23:21<38:34, 27.56s/it]2021-12-16 16:43:17,153 iteration 5373 : loss : 0.034497, loss_ce: 0.017833
2021-12-16 16:43:18,558 iteration 5374 : loss : 0.033919, loss_ce: 0.015192
2021-12-16 16:43:20,024 iteration 5375 : loss : 0.025742, loss_ce: 0.010072
2021-12-16 16:43:21,448 iteration 5376 : loss : 0.028467, loss_ce: 0.012349
2021-12-16 16:43:22,859 iteration 5377 : loss : 0.032060, loss_ce: 0.010658
2021-12-16 16:43:24,319 iteration 5378 : loss : 0.034860, loss_ce: 0.013983
2021-12-16 16:43:25,717 iteration 5379 : loss : 0.022565, loss_ce: 0.009727
2021-12-16 16:43:27,177 iteration 5380 : loss : 0.043457, loss_ce: 0.019057
2021-12-16 16:43:28,607 iteration 5381 : loss : 0.036252, loss_ce: 0.015383
2021-12-16 16:43:30,096 iteration 5382 : loss : 0.028475, loss_ce: 0.010564
2021-12-16 16:43:31,668 iteration 5383 : loss : 0.053000, loss_ce: 0.029321
2021-12-16 16:43:33,318 iteration 5384 : loss : 0.036122, loss_ce: 0.016214
2021-12-16 16:43:34,732 iteration 5385 : loss : 0.029655, loss_ce: 0.012778
2021-12-16 16:43:36,111 iteration 5386 : loss : 0.024729, loss_ce: 0.010657
2021-12-16 16:43:37,562 iteration 5387 : loss : 0.041622, loss_ce: 0.022498
2021-12-16 16:43:39,061 iteration 5388 : loss : 0.034689, loss_ce: 0.013024
2021-12-16 16:43:40,643 iteration 5389 : loss : 0.067119, loss_ce: 0.022208
 79%|██████████████████████▉      | 317/400 [2:23:46<37:03, 26.79s/it]2021-12-16 16:43:42,095 iteration 5390 : loss : 0.055504, loss_ce: 0.016616
2021-12-16 16:43:43,582 iteration 5391 : loss : 0.043649, loss_ce: 0.018940
2021-12-16 16:43:45,092 iteration 5392 : loss : 0.032859, loss_ce: 0.016401
2021-12-16 16:43:46,560 iteration 5393 : loss : 0.065903, loss_ce: 0.024026
2021-12-16 16:43:48,008 iteration 5394 : loss : 0.034756, loss_ce: 0.017734
2021-12-16 16:43:49,495 iteration 5395 : loss : 0.029373, loss_ce: 0.010903
2021-12-16 16:43:50,894 iteration 5396 : loss : 0.037183, loss_ce: 0.021213
2021-12-16 16:43:52,406 iteration 5397 : loss : 0.045697, loss_ce: 0.016707
2021-12-16 16:43:53,880 iteration 5398 : loss : 0.043891, loss_ce: 0.023342
2021-12-16 16:43:55,285 iteration 5399 : loss : 0.036053, loss_ce: 0.011597
2021-12-16 16:43:56,841 iteration 5400 : loss : 0.056835, loss_ce: 0.017867
2021-12-16 16:43:58,318 iteration 5401 : loss : 0.047564, loss_ce: 0.022818
2021-12-16 16:43:59,771 iteration 5402 : loss : 0.049002, loss_ce: 0.018806
2021-12-16 16:44:01,197 iteration 5403 : loss : 0.043280, loss_ce: 0.017910
2021-12-16 16:44:02,616 iteration 5404 : loss : 0.027865, loss_ce: 0.009374
2021-12-16 16:44:04,065 iteration 5405 : loss : 0.023904, loss_ce: 0.011865
2021-12-16 16:44:05,586 iteration 5406 : loss : 0.040672, loss_ce: 0.013855
 80%|███████████████████████      | 318/400 [2:24:11<35:51, 26.23s/it]2021-12-16 16:44:07,132 iteration 5407 : loss : 0.038677, loss_ce: 0.016914
2021-12-16 16:44:08,571 iteration 5408 : loss : 0.043120, loss_ce: 0.014089
2021-12-16 16:44:10,092 iteration 5409 : loss : 0.040985, loss_ce: 0.020439
2021-12-16 16:44:11,509 iteration 5410 : loss : 0.035321, loss_ce: 0.020559
2021-12-16 16:44:12,988 iteration 5411 : loss : 0.030141, loss_ce: 0.012963
2021-12-16 16:44:14,481 iteration 5412 : loss : 0.039191, loss_ce: 0.021173
2021-12-16 16:44:15,915 iteration 5413 : loss : 0.032334, loss_ce: 0.016454
2021-12-16 16:44:17,388 iteration 5414 : loss : 0.039393, loss_ce: 0.016367
2021-12-16 16:44:18,940 iteration 5415 : loss : 0.057865, loss_ce: 0.025447
2021-12-16 16:44:20,333 iteration 5416 : loss : 0.030201, loss_ce: 0.012238
2021-12-16 16:44:21,819 iteration 5417 : loss : 0.026118, loss_ce: 0.010137
2021-12-16 16:44:23,255 iteration 5418 : loss : 0.037444, loss_ce: 0.015848
2021-12-16 16:44:24,742 iteration 5419 : loss : 0.039454, loss_ce: 0.013371
2021-12-16 16:44:26,265 iteration 5420 : loss : 0.042637, loss_ce: 0.019624
2021-12-16 16:44:27,769 iteration 5421 : loss : 0.042356, loss_ce: 0.024304
2021-12-16 16:44:29,107 iteration 5422 : loss : 0.020408, loss_ce: 0.009971
2021-12-16 16:44:30,629 iteration 5423 : loss : 0.064663, loss_ce: 0.021981
 80%|███████████████████████▏     | 319/400 [2:24:36<34:55, 25.88s/it]2021-12-16 16:44:32,197 iteration 5424 : loss : 0.033629, loss_ce: 0.012732
2021-12-16 16:44:33,612 iteration 5425 : loss : 0.028894, loss_ce: 0.011145
2021-12-16 16:44:35,063 iteration 5426 : loss : 0.032146, loss_ce: 0.011942
2021-12-16 16:44:36,444 iteration 5427 : loss : 0.029305, loss_ce: 0.012785
2021-12-16 16:44:37,873 iteration 5428 : loss : 0.032826, loss_ce: 0.015023
2021-12-16 16:44:39,352 iteration 5429 : loss : 0.032907, loss_ce: 0.013805
2021-12-16 16:44:40,838 iteration 5430 : loss : 0.028279, loss_ce: 0.013933
2021-12-16 16:44:42,238 iteration 5431 : loss : 0.029732, loss_ce: 0.011816
2021-12-16 16:44:43,765 iteration 5432 : loss : 0.039905, loss_ce: 0.023801
2021-12-16 16:44:45,272 iteration 5433 : loss : 0.040418, loss_ce: 0.019024
2021-12-16 16:44:46,671 iteration 5434 : loss : 0.033074, loss_ce: 0.015524
2021-12-16 16:44:48,207 iteration 5435 : loss : 0.044260, loss_ce: 0.020767
2021-12-16 16:44:49,687 iteration 5436 : loss : 0.025526, loss_ce: 0.011142
2021-12-16 16:44:51,198 iteration 5437 : loss : 0.079188, loss_ce: 0.018216
2021-12-16 16:44:52,711 iteration 5438 : loss : 0.044698, loss_ce: 0.018631
2021-12-16 16:44:54,145 iteration 5439 : loss : 0.044339, loss_ce: 0.022130
2021-12-16 16:44:54,146 Training Data Eval:
2021-12-16 16:45:01,649   Average segmentation loss on training set: 0.0148
2021-12-16 16:45:01,649 Validation Data Eval:
2021-12-16 16:45:04,245   Average segmentation loss on validation set: 0.1070
2021-12-16 16:45:05,665 iteration 5440 : loss : 0.028497, loss_ce: 0.011021
 80%|███████████████████████▏     | 320/400 [2:25:11<38:10, 28.63s/it]2021-12-16 16:45:07,146 iteration 5441 : loss : 0.032232, loss_ce: 0.012646
2021-12-16 16:45:08,548 iteration 5442 : loss : 0.030342, loss_ce: 0.012684
2021-12-16 16:45:09,993 iteration 5443 : loss : 0.035780, loss_ce: 0.012891
2021-12-16 16:45:11,374 iteration 5444 : loss : 0.029265, loss_ce: 0.010301
2021-12-16 16:45:12,854 iteration 5445 : loss : 0.043804, loss_ce: 0.016991
2021-12-16 16:45:14,261 iteration 5446 : loss : 0.034011, loss_ce: 0.016983
2021-12-16 16:45:15,805 iteration 5447 : loss : 0.047482, loss_ce: 0.017016
2021-12-16 16:45:17,241 iteration 5448 : loss : 0.028032, loss_ce: 0.013512
2021-12-16 16:45:18,722 iteration 5449 : loss : 0.041488, loss_ce: 0.023742
2021-12-16 16:45:20,190 iteration 5450 : loss : 0.042402, loss_ce: 0.019311
2021-12-16 16:45:21,596 iteration 5451 : loss : 0.031676, loss_ce: 0.012604
2021-12-16 16:45:23,077 iteration 5452 : loss : 0.037015, loss_ce: 0.015007
2021-12-16 16:45:24,501 iteration 5453 : loss : 0.035952, loss_ce: 0.014461
2021-12-16 16:45:26,020 iteration 5454 : loss : 0.048074, loss_ce: 0.025790
2021-12-16 16:45:27,509 iteration 5455 : loss : 0.053198, loss_ce: 0.015676
2021-12-16 16:45:28,980 iteration 5456 : loss : 0.023670, loss_ce: 0.007171
2021-12-16 16:45:30,386 iteration 5457 : loss : 0.035210, loss_ce: 0.012897
 80%|███████████████████████▎     | 321/400 [2:25:36<36:09, 27.46s/it]2021-12-16 16:45:31,870 iteration 5458 : loss : 0.037031, loss_ce: 0.016159
2021-12-16 16:45:33,263 iteration 5459 : loss : 0.029774, loss_ce: 0.017088
2021-12-16 16:45:34,722 iteration 5460 : loss : 0.033859, loss_ce: 0.016004
2021-12-16 16:45:36,157 iteration 5461 : loss : 0.033219, loss_ce: 0.014902
2021-12-16 16:45:37,581 iteration 5462 : loss : 0.026793, loss_ce: 0.011182
2021-12-16 16:45:39,045 iteration 5463 : loss : 0.042770, loss_ce: 0.014402
2021-12-16 16:45:40,502 iteration 5464 : loss : 0.036454, loss_ce: 0.016898
2021-12-16 16:45:42,024 iteration 5465 : loss : 0.040079, loss_ce: 0.017849
2021-12-16 16:45:43,531 iteration 5466 : loss : 0.050664, loss_ce: 0.020893
2021-12-16 16:45:45,002 iteration 5467 : loss : 0.052946, loss_ce: 0.021777
2021-12-16 16:45:46,461 iteration 5468 : loss : 0.031967, loss_ce: 0.015097
2021-12-16 16:45:47,854 iteration 5469 : loss : 0.030231, loss_ce: 0.012764
2021-12-16 16:45:49,331 iteration 5470 : loss : 0.017978, loss_ce: 0.008554
2021-12-16 16:45:50,779 iteration 5471 : loss : 0.035996, loss_ce: 0.011304
2021-12-16 16:45:52,285 iteration 5472 : loss : 0.037563, loss_ce: 0.014112
2021-12-16 16:45:53,691 iteration 5473 : loss : 0.024242, loss_ce: 0.010408
2021-12-16 16:45:55,114 iteration 5474 : loss : 0.029774, loss_ce: 0.010843
 80%|███████████████████████▎     | 322/400 [2:26:00<34:37, 26.64s/it]2021-12-16 16:45:56,649 iteration 5475 : loss : 0.041612, loss_ce: 0.016131
2021-12-16 16:45:58,162 iteration 5476 : loss : 0.038370, loss_ce: 0.021788
2021-12-16 16:45:59,615 iteration 5477 : loss : 0.058618, loss_ce: 0.011237
2021-12-16 16:46:00,999 iteration 5478 : loss : 0.026381, loss_ce: 0.010644
2021-12-16 16:46:02,445 iteration 5479 : loss : 0.029298, loss_ce: 0.014566
2021-12-16 16:46:03,891 iteration 5480 : loss : 0.037550, loss_ce: 0.014341
2021-12-16 16:46:05,320 iteration 5481 : loss : 0.031031, loss_ce: 0.012677
2021-12-16 16:46:06,873 iteration 5482 : loss : 0.064395, loss_ce: 0.019123
2021-12-16 16:46:08,239 iteration 5483 : loss : 0.027183, loss_ce: 0.012090
2021-12-16 16:46:09,725 iteration 5484 : loss : 0.040211, loss_ce: 0.014995
2021-12-16 16:46:11,189 iteration 5485 : loss : 0.028566, loss_ce: 0.013559
2021-12-16 16:46:12,641 iteration 5486 : loss : 0.042243, loss_ce: 0.022123
2021-12-16 16:46:14,106 iteration 5487 : loss : 0.031387, loss_ce: 0.015378
2021-12-16 16:46:15,524 iteration 5488 : loss : 0.040153, loss_ce: 0.023504
2021-12-16 16:46:16,945 iteration 5489 : loss : 0.032862, loss_ce: 0.018546
2021-12-16 16:46:18,491 iteration 5490 : loss : 0.050033, loss_ce: 0.021381
2021-12-16 16:46:19,929 iteration 5491 : loss : 0.025742, loss_ce: 0.010770
 81%|███████████████████████▍     | 323/400 [2:26:25<33:28, 26.09s/it]2021-12-16 16:46:21,347 iteration 5492 : loss : 0.024283, loss_ce: 0.010493
2021-12-16 16:46:22,854 iteration 5493 : loss : 0.035650, loss_ce: 0.013556
2021-12-16 16:46:24,272 iteration 5494 : loss : 0.043627, loss_ce: 0.021164
2021-12-16 16:46:25,727 iteration 5495 : loss : 0.023545, loss_ce: 0.008879
2021-12-16 16:46:27,191 iteration 5496 : loss : 0.030327, loss_ce: 0.011161
2021-12-16 16:46:28,664 iteration 5497 : loss : 0.035123, loss_ce: 0.014720
2021-12-16 16:46:30,177 iteration 5498 : loss : 0.061044, loss_ce: 0.022057
2021-12-16 16:46:31,658 iteration 5499 : loss : 0.041936, loss_ce: 0.022571
2021-12-16 16:46:33,044 iteration 5500 : loss : 0.027419, loss_ce: 0.013718
2021-12-16 16:46:34,515 iteration 5501 : loss : 0.042694, loss_ce: 0.019950
2021-12-16 16:46:35,942 iteration 5502 : loss : 0.018581, loss_ce: 0.009034
2021-12-16 16:46:37,384 iteration 5503 : loss : 0.040068, loss_ce: 0.013529
2021-12-16 16:46:38,797 iteration 5504 : loss : 0.031138, loss_ce: 0.012787
2021-12-16 16:46:40,264 iteration 5505 : loss : 0.047716, loss_ce: 0.017974
2021-12-16 16:46:41,749 iteration 5506 : loss : 0.030639, loss_ce: 0.012640
2021-12-16 16:46:43,181 iteration 5507 : loss : 0.033740, loss_ce: 0.016424
2021-12-16 16:46:44,639 iteration 5508 : loss : 0.042381, loss_ce: 0.015344
 81%|███████████████████████▍     | 324/400 [2:26:50<32:31, 25.68s/it]2021-12-16 16:46:46,152 iteration 5509 : loss : 0.037835, loss_ce: 0.012736
2021-12-16 16:46:47,693 iteration 5510 : loss : 0.028319, loss_ce: 0.012428
2021-12-16 16:46:49,130 iteration 5511 : loss : 0.027013, loss_ce: 0.011356
2021-12-16 16:46:50,634 iteration 5512 : loss : 0.040237, loss_ce: 0.018222
2021-12-16 16:46:52,072 iteration 5513 : loss : 0.023643, loss_ce: 0.011699
2021-12-16 16:46:53,474 iteration 5514 : loss : 0.024112, loss_ce: 0.010143
2021-12-16 16:46:54,990 iteration 5515 : loss : 0.066313, loss_ce: 0.018413
2021-12-16 16:46:56,419 iteration 5516 : loss : 0.033798, loss_ce: 0.014737
2021-12-16 16:46:57,880 iteration 5517 : loss : 0.030130, loss_ce: 0.014002
2021-12-16 16:46:59,316 iteration 5518 : loss : 0.055988, loss_ce: 0.022256
2021-12-16 16:47:00,776 iteration 5519 : loss : 0.036182, loss_ce: 0.014368
2021-12-16 16:47:02,220 iteration 5520 : loss : 0.026836, loss_ce: 0.011945
2021-12-16 16:47:03,688 iteration 5521 : loss : 0.029554, loss_ce: 0.012369
2021-12-16 16:47:05,148 iteration 5522 : loss : 0.057680, loss_ce: 0.025066
2021-12-16 16:47:06,596 iteration 5523 : loss : 0.021565, loss_ce: 0.008977
2021-12-16 16:47:08,047 iteration 5524 : loss : 0.037399, loss_ce: 0.019641
2021-12-16 16:47:08,047 Training Data Eval:
2021-12-16 16:47:15,574   Average segmentation loss on training set: 0.0160
2021-12-16 16:47:15,575 Validation Data Eval:
2021-12-16 16:47:18,177   Average segmentation loss on validation set: 0.0942
2021-12-16 16:47:19,649 iteration 5525 : loss : 0.047789, loss_ce: 0.023547
 81%|███████████████████████▌     | 325/400 [2:27:25<35:35, 28.48s/it]2021-12-16 16:47:21,207 iteration 5526 : loss : 0.039874, loss_ce: 0.016118
2021-12-16 16:47:22,672 iteration 5527 : loss : 0.032177, loss_ce: 0.016107
2021-12-16 16:47:24,121 iteration 5528 : loss : 0.047558, loss_ce: 0.020914
2021-12-16 16:47:25,621 iteration 5529 : loss : 0.047486, loss_ce: 0.020158
2021-12-16 16:47:27,040 iteration 5530 : loss : 0.027476, loss_ce: 0.013617
2021-12-16 16:47:28,481 iteration 5531 : loss : 0.029563, loss_ce: 0.015612
2021-12-16 16:47:29,911 iteration 5532 : loss : 0.024553, loss_ce: 0.012657
2021-12-16 16:47:31,422 iteration 5533 : loss : 0.029180, loss_ce: 0.010863
2021-12-16 16:47:32,862 iteration 5534 : loss : 0.029272, loss_ce: 0.012515
2021-12-16 16:47:34,375 iteration 5535 : loss : 0.046045, loss_ce: 0.018943
2021-12-16 16:47:35,926 iteration 5536 : loss : 0.032002, loss_ce: 0.014968
2021-12-16 16:47:37,429 iteration 5537 : loss : 0.034686, loss_ce: 0.014089
2021-12-16 16:47:38,891 iteration 5538 : loss : 0.038481, loss_ce: 0.018069
2021-12-16 16:47:40,445 iteration 5539 : loss : 0.040818, loss_ce: 0.013389
2021-12-16 16:47:41,873 iteration 5540 : loss : 0.029923, loss_ce: 0.015726
2021-12-16 16:47:43,347 iteration 5541 : loss : 0.038892, loss_ce: 0.016244
2021-12-16 16:47:44,788 iteration 5542 : loss : 0.029406, loss_ce: 0.013331
 82%|███████████████████████▋     | 326/400 [2:27:50<33:53, 27.47s/it]2021-12-16 16:47:46,320 iteration 5543 : loss : 0.042035, loss_ce: 0.017260
2021-12-16 16:47:47,789 iteration 5544 : loss : 0.028557, loss_ce: 0.014226
2021-12-16 16:47:49,235 iteration 5545 : loss : 0.030521, loss_ce: 0.014990
2021-12-16 16:47:50,647 iteration 5546 : loss : 0.036948, loss_ce: 0.013898
2021-12-16 16:47:52,101 iteration 5547 : loss : 0.026685, loss_ce: 0.010878
2021-12-16 16:47:53,602 iteration 5548 : loss : 0.030979, loss_ce: 0.012689
2021-12-16 16:47:54,994 iteration 5549 : loss : 0.030725, loss_ce: 0.014419
2021-12-16 16:47:56,430 iteration 5550 : loss : 0.028153, loss_ce: 0.011575
2021-12-16 16:47:57,897 iteration 5551 : loss : 0.033682, loss_ce: 0.016251
2021-12-16 16:47:59,306 iteration 5552 : loss : 0.025215, loss_ce: 0.011501
2021-12-16 16:48:00,774 iteration 5553 : loss : 0.040049, loss_ce: 0.016598
2021-12-16 16:48:02,279 iteration 5554 : loss : 0.029409, loss_ce: 0.011451
2021-12-16 16:48:03,789 iteration 5555 : loss : 0.050555, loss_ce: 0.018111
2021-12-16 16:48:05,178 iteration 5556 : loss : 0.036720, loss_ce: 0.016112
2021-12-16 16:48:06,713 iteration 5557 : loss : 0.053850, loss_ce: 0.016619
2021-12-16 16:48:08,184 iteration 5558 : loss : 0.027468, loss_ce: 0.010714
2021-12-16 16:48:09,557 iteration 5559 : loss : 0.022697, loss_ce: 0.010587
 82%|███████████████████████▋     | 327/400 [2:28:15<32:26, 26.66s/it]2021-12-16 16:48:11,228 iteration 5560 : loss : 0.066693, loss_ce: 0.027531
2021-12-16 16:48:12,649 iteration 5561 : loss : 0.028638, loss_ce: 0.011168
2021-12-16 16:48:14,091 iteration 5562 : loss : 0.041011, loss_ce: 0.015461
2021-12-16 16:48:15,547 iteration 5563 : loss : 0.028190, loss_ce: 0.014145
2021-12-16 16:48:17,102 iteration 5564 : loss : 0.040279, loss_ce: 0.014891
2021-12-16 16:48:18,559 iteration 5565 : loss : 0.029310, loss_ce: 0.013289
2021-12-16 16:48:20,057 iteration 5566 : loss : 0.032460, loss_ce: 0.015377
2021-12-16 16:48:21,605 iteration 5567 : loss : 0.035540, loss_ce: 0.017873
2021-12-16 16:48:23,055 iteration 5568 : loss : 0.044675, loss_ce: 0.019027
2021-12-16 16:48:24,550 iteration 5569 : loss : 0.043971, loss_ce: 0.022684
2021-12-16 16:48:26,007 iteration 5570 : loss : 0.028691, loss_ce: 0.012561
2021-12-16 16:48:27,511 iteration 5571 : loss : 0.044079, loss_ce: 0.021673
2021-12-16 16:48:28,981 iteration 5572 : loss : 0.028924, loss_ce: 0.012342
2021-12-16 16:48:30,471 iteration 5573 : loss : 0.032494, loss_ce: 0.010747
2021-12-16 16:48:32,046 iteration 5574 : loss : 0.055920, loss_ce: 0.022452
2021-12-16 16:48:33,394 iteration 5575 : loss : 0.021724, loss_ce: 0.010574
2021-12-16 16:48:34,735 iteration 5576 : loss : 0.029612, loss_ce: 0.010330
 82%|███████████████████████▊     | 328/400 [2:28:40<31:27, 26.22s/it]2021-12-16 16:48:36,230 iteration 5577 : loss : 0.037075, loss_ce: 0.018458
2021-12-16 16:48:37,679 iteration 5578 : loss : 0.047513, loss_ce: 0.015563
2021-12-16 16:48:39,130 iteration 5579 : loss : 0.031915, loss_ce: 0.012751
2021-12-16 16:48:40,644 iteration 5580 : loss : 0.030726, loss_ce: 0.014967
2021-12-16 16:48:42,095 iteration 5581 : loss : 0.030635, loss_ce: 0.012501
2021-12-16 16:48:43,587 iteration 5582 : loss : 0.033231, loss_ce: 0.012796
2021-12-16 16:48:45,010 iteration 5583 : loss : 0.037465, loss_ce: 0.012109
2021-12-16 16:48:46,566 iteration 5584 : loss : 0.048282, loss_ce: 0.026159
2021-12-16 16:48:48,002 iteration 5585 : loss : 0.030000, loss_ce: 0.014612
2021-12-16 16:48:49,473 iteration 5586 : loss : 0.038246, loss_ce: 0.018595
2021-12-16 16:48:50,928 iteration 5587 : loss : 0.036706, loss_ce: 0.018177
2021-12-16 16:48:52,454 iteration 5588 : loss : 0.031197, loss_ce: 0.013264
2021-12-16 16:48:53,961 iteration 5589 : loss : 0.035975, loss_ce: 0.014939
2021-12-16 16:48:55,423 iteration 5590 : loss : 0.035681, loss_ce: 0.015425
2021-12-16 16:48:56,876 iteration 5591 : loss : 0.031346, loss_ce: 0.016176
2021-12-16 16:48:58,313 iteration 5592 : loss : 0.031791, loss_ce: 0.012717
2021-12-16 16:48:59,754 iteration 5593 : loss : 0.030731, loss_ce: 0.018735
 82%|███████████████████████▊     | 329/400 [2:29:05<30:35, 25.86s/it]2021-12-16 16:49:01,282 iteration 5594 : loss : 0.033482, loss_ce: 0.015160
2021-12-16 16:49:02,751 iteration 5595 : loss : 0.027909, loss_ce: 0.013745
2021-12-16 16:49:04,190 iteration 5596 : loss : 0.021965, loss_ce: 0.007915
2021-12-16 16:49:05,688 iteration 5597 : loss : 0.031181, loss_ce: 0.012480
2021-12-16 16:49:07,222 iteration 5598 : loss : 0.049458, loss_ce: 0.022921
2021-12-16 16:49:08,725 iteration 5599 : loss : 0.038985, loss_ce: 0.015068
2021-12-16 16:49:10,253 iteration 5600 : loss : 0.038261, loss_ce: 0.018921
2021-12-16 16:49:11,753 iteration 5601 : loss : 0.040935, loss_ce: 0.014607
2021-12-16 16:49:13,178 iteration 5602 : loss : 0.039761, loss_ce: 0.013109
2021-12-16 16:49:14,689 iteration 5603 : loss : 0.046330, loss_ce: 0.020600
2021-12-16 16:49:16,105 iteration 5604 : loss : 0.040619, loss_ce: 0.022145
2021-12-16 16:49:17,536 iteration 5605 : loss : 0.025227, loss_ce: 0.009879
2021-12-16 16:49:19,069 iteration 5606 : loss : 0.050610, loss_ce: 0.018599
2021-12-16 16:49:20,543 iteration 5607 : loss : 0.037954, loss_ce: 0.015743
2021-12-16 16:49:22,134 iteration 5608 : loss : 0.057598, loss_ce: 0.028524
2021-12-16 16:49:23,549 iteration 5609 : loss : 0.028242, loss_ce: 0.015214
2021-12-16 16:49:23,550 Training Data Eval:
2021-12-16 16:49:31,046   Average segmentation loss on training set: 0.0151
2021-12-16 16:49:31,047 Validation Data Eval:
2021-12-16 16:49:33,639   Average segmentation loss on validation set: 0.1018
2021-12-16 16:49:35,153 iteration 5610 : loss : 0.028842, loss_ce: 0.012354
 82%|███████████████████████▉     | 330/400 [2:29:40<33:30, 28.72s/it]2021-12-16 16:49:36,703 iteration 5611 : loss : 0.043189, loss_ce: 0.024460
2021-12-16 16:49:38,195 iteration 5612 : loss : 0.035908, loss_ce: 0.013893
2021-12-16 16:49:39,659 iteration 5613 : loss : 0.042874, loss_ce: 0.020582
2021-12-16 16:49:41,132 iteration 5614 : loss : 0.046640, loss_ce: 0.017795
2021-12-16 16:49:42,613 iteration 5615 : loss : 0.027529, loss_ce: 0.011185
2021-12-16 16:49:44,106 iteration 5616 : loss : 0.035878, loss_ce: 0.018079
2021-12-16 16:49:45,570 iteration 5617 : loss : 0.024731, loss_ce: 0.010312
2021-12-16 16:49:46,988 iteration 5618 : loss : 0.030447, loss_ce: 0.015527
2021-12-16 16:49:48,496 iteration 5619 : loss : 0.062001, loss_ce: 0.023660
2021-12-16 16:49:50,037 iteration 5620 : loss : 0.033957, loss_ce: 0.013542
2021-12-16 16:49:51,459 iteration 5621 : loss : 0.030438, loss_ce: 0.013439
2021-12-16 16:49:53,004 iteration 5622 : loss : 0.043415, loss_ce: 0.021480
2021-12-16 16:49:54,416 iteration 5623 : loss : 0.036112, loss_ce: 0.012819
2021-12-16 16:49:55,901 iteration 5624 : loss : 0.033844, loss_ce: 0.015104
2021-12-16 16:49:57,411 iteration 5625 : loss : 0.035544, loss_ce: 0.017208
2021-12-16 16:49:58,888 iteration 5626 : loss : 0.054588, loss_ce: 0.021825
2021-12-16 16:50:00,350 iteration 5627 : loss : 0.037919, loss_ce: 0.013177
 83%|███████████████████████▉     | 331/400 [2:30:06<31:48, 27.66s/it]2021-12-16 16:50:01,741 iteration 5628 : loss : 0.026953, loss_ce: 0.012121
2021-12-16 16:50:03,223 iteration 5629 : loss : 0.053881, loss_ce: 0.026223
2021-12-16 16:50:04,666 iteration 5630 : loss : 0.028448, loss_ce: 0.012438
2021-12-16 16:50:06,216 iteration 5631 : loss : 0.045042, loss_ce: 0.024955
2021-12-16 16:50:07,589 iteration 5632 : loss : 0.029846, loss_ce: 0.014492
2021-12-16 16:50:09,106 iteration 5633 : loss : 0.042341, loss_ce: 0.019495
2021-12-16 16:50:10,532 iteration 5634 : loss : 0.029428, loss_ce: 0.011801
2021-12-16 16:50:12,024 iteration 5635 : loss : 0.043445, loss_ce: 0.011897
2021-12-16 16:50:13,436 iteration 5636 : loss : 0.026545, loss_ce: 0.013832
2021-12-16 16:50:14,938 iteration 5637 : loss : 0.031170, loss_ce: 0.013476
2021-12-16 16:50:16,300 iteration 5638 : loss : 0.027196, loss_ce: 0.010919
2021-12-16 16:50:17,710 iteration 5639 : loss : 0.036608, loss_ce: 0.012409
2021-12-16 16:50:19,164 iteration 5640 : loss : 0.027957, loss_ce: 0.015540
2021-12-16 16:50:20,654 iteration 5641 : loss : 0.039001, loss_ce: 0.020015
2021-12-16 16:50:22,078 iteration 5642 : loss : 0.025845, loss_ce: 0.007236
2021-12-16 16:50:23,584 iteration 5643 : loss : 0.033884, loss_ce: 0.012468
2021-12-16 16:50:25,079 iteration 5644 : loss : 0.027484, loss_ce: 0.012480
 83%|████████████████████████     | 332/400 [2:30:30<30:21, 26.78s/it]2021-12-16 16:50:26,690 iteration 5645 : loss : 0.035747, loss_ce: 0.015169
2021-12-16 16:50:28,112 iteration 5646 : loss : 0.037282, loss_ce: 0.016306
2021-12-16 16:50:29,574 iteration 5647 : loss : 0.035832, loss_ce: 0.021142
2021-12-16 16:50:31,078 iteration 5648 : loss : 0.055574, loss_ce: 0.021285
2021-12-16 16:50:32,616 iteration 5649 : loss : 0.045792, loss_ce: 0.022993
2021-12-16 16:50:34,078 iteration 5650 : loss : 0.037963, loss_ce: 0.016138
2021-12-16 16:50:35,517 iteration 5651 : loss : 0.030327, loss_ce: 0.015898
2021-12-16 16:50:36,898 iteration 5652 : loss : 0.023828, loss_ce: 0.010149
2021-12-16 16:50:38,353 iteration 5653 : loss : 0.030110, loss_ce: 0.013260
2021-12-16 16:50:39,760 iteration 5654 : loss : 0.026158, loss_ce: 0.009630
2021-12-16 16:50:41,263 iteration 5655 : loss : 0.056283, loss_ce: 0.025259
2021-12-16 16:50:42,738 iteration 5656 : loss : 0.029777, loss_ce: 0.011802
2021-12-16 16:50:44,195 iteration 5657 : loss : 0.022262, loss_ce: 0.010097
2021-12-16 16:50:45,648 iteration 5658 : loss : 0.043479, loss_ce: 0.022358
2021-12-16 16:50:47,065 iteration 5659 : loss : 0.034977, loss_ce: 0.012232
2021-12-16 16:50:48,452 iteration 5660 : loss : 0.037094, loss_ce: 0.014089
2021-12-16 16:50:49,997 iteration 5661 : loss : 0.035545, loss_ce: 0.013524
 83%|████████████████████████▏    | 333/400 [2:30:55<29:17, 26.23s/it]2021-12-16 16:50:51,485 iteration 5662 : loss : 0.033606, loss_ce: 0.011105
2021-12-16 16:50:52,928 iteration 5663 : loss : 0.043161, loss_ce: 0.019130
2021-12-16 16:50:54,402 iteration 5664 : loss : 0.052390, loss_ce: 0.018326
2021-12-16 16:50:55,776 iteration 5665 : loss : 0.030477, loss_ce: 0.012719
2021-12-16 16:50:57,265 iteration 5666 : loss : 0.031098, loss_ce: 0.013361
2021-12-16 16:50:58,772 iteration 5667 : loss : 0.034706, loss_ce: 0.014776
2021-12-16 16:51:00,222 iteration 5668 : loss : 0.026095, loss_ce: 0.013004
2021-12-16 16:51:01,726 iteration 5669 : loss : 0.031582, loss_ce: 0.016524
2021-12-16 16:51:03,208 iteration 5670 : loss : 0.026858, loss_ce: 0.010359
2021-12-16 16:51:04,719 iteration 5671 : loss : 0.035086, loss_ce: 0.015232
2021-12-16 16:51:06,167 iteration 5672 : loss : 0.038527, loss_ce: 0.012614
2021-12-16 16:51:07,580 iteration 5673 : loss : 0.030676, loss_ce: 0.011706
2021-12-16 16:51:09,111 iteration 5674 : loss : 0.027518, loss_ce: 0.015765
2021-12-16 16:51:10,547 iteration 5675 : loss : 0.032854, loss_ce: 0.015734
2021-12-16 16:51:12,061 iteration 5676 : loss : 0.044291, loss_ce: 0.018074
2021-12-16 16:51:13,562 iteration 5677 : loss : 0.030119, loss_ce: 0.015057
2021-12-16 16:51:15,050 iteration 5678 : loss : 0.059129, loss_ce: 0.024517
 84%|████████████████████████▏    | 334/400 [2:31:20<28:27, 25.87s/it]2021-12-16 16:51:16,559 iteration 5679 : loss : 0.046953, loss_ce: 0.023826
2021-12-16 16:51:17,897 iteration 5680 : loss : 0.035288, loss_ce: 0.010693
2021-12-16 16:51:19,412 iteration 5681 : loss : 0.052074, loss_ce: 0.021913
2021-12-16 16:51:20,913 iteration 5682 : loss : 0.035251, loss_ce: 0.016622
2021-12-16 16:51:22,331 iteration 5683 : loss : 0.024537, loss_ce: 0.009824
2021-12-16 16:51:23,731 iteration 5684 : loss : 0.023106, loss_ce: 0.014003
2021-12-16 16:51:25,201 iteration 5685 : loss : 0.041588, loss_ce: 0.020809
2021-12-16 16:51:26,641 iteration 5686 : loss : 0.026556, loss_ce: 0.011430
2021-12-16 16:51:28,110 iteration 5687 : loss : 0.040140, loss_ce: 0.021944
2021-12-16 16:51:29,674 iteration 5688 : loss : 0.030234, loss_ce: 0.011851
2021-12-16 16:51:31,134 iteration 5689 : loss : 0.044556, loss_ce: 0.014451
2021-12-16 16:51:32,606 iteration 5690 : loss : 0.032174, loss_ce: 0.015198
2021-12-16 16:51:34,098 iteration 5691 : loss : 0.049316, loss_ce: 0.023180
2021-12-16 16:51:35,584 iteration 5692 : loss : 0.039294, loss_ce: 0.018225
2021-12-16 16:51:37,061 iteration 5693 : loss : 0.047153, loss_ce: 0.014703
2021-12-16 16:51:38,494 iteration 5694 : loss : 0.028939, loss_ce: 0.014755
2021-12-16 16:51:38,494 Training Data Eval:
2021-12-16 16:51:46,004   Average segmentation loss on training set: 0.0151
2021-12-16 16:51:46,004 Validation Data Eval:
2021-12-16 16:51:48,600   Average segmentation loss on validation set: 0.1006
2021-12-16 16:51:50,029 iteration 5695 : loss : 0.026489, loss_ce: 0.011145
 84%|████████████████████████▎    | 335/400 [2:31:55<30:59, 28.60s/it]2021-12-16 16:51:51,502 iteration 5696 : loss : 0.026343, loss_ce: 0.014353
2021-12-16 16:51:52,922 iteration 5697 : loss : 0.025898, loss_ce: 0.012095
2021-12-16 16:51:54,431 iteration 5698 : loss : 0.033164, loss_ce: 0.012216
2021-12-16 16:51:55,824 iteration 5699 : loss : 0.029041, loss_ce: 0.013644
2021-12-16 16:51:57,271 iteration 5700 : loss : 0.023628, loss_ce: 0.010302
2021-12-16 16:51:58,674 iteration 5701 : loss : 0.021146, loss_ce: 0.010439
2021-12-16 16:52:00,240 iteration 5702 : loss : 0.032097, loss_ce: 0.014928
2021-12-16 16:52:01,736 iteration 5703 : loss : 0.038663, loss_ce: 0.020614
2021-12-16 16:52:03,204 iteration 5704 : loss : 0.046285, loss_ce: 0.018071
2021-12-16 16:52:04,680 iteration 5705 : loss : 0.042561, loss_ce: 0.017780
2021-12-16 16:52:06,051 iteration 5706 : loss : 0.027457, loss_ce: 0.011277
2021-12-16 16:52:07,499 iteration 5707 : loss : 0.033949, loss_ce: 0.013490
2021-12-16 16:52:08,914 iteration 5708 : loss : 0.034995, loss_ce: 0.015623
2021-12-16 16:52:10,389 iteration 5709 : loss : 0.041785, loss_ce: 0.013837
2021-12-16 16:52:11,835 iteration 5710 : loss : 0.029505, loss_ce: 0.010701
2021-12-16 16:52:13,222 iteration 5711 : loss : 0.031942, loss_ce: 0.012344
2021-12-16 16:52:14,703 iteration 5712 : loss : 0.048081, loss_ce: 0.024634
 84%|████████████████████████▎    | 336/400 [2:32:20<29:15, 27.43s/it]2021-12-16 16:52:16,238 iteration 5713 : loss : 0.037930, loss_ce: 0.014230
2021-12-16 16:52:17,728 iteration 5714 : loss : 0.052145, loss_ce: 0.016867
2021-12-16 16:52:19,233 iteration 5715 : loss : 0.024751, loss_ce: 0.011410
2021-12-16 16:52:20,650 iteration 5716 : loss : 0.027380, loss_ce: 0.012984
2021-12-16 16:52:22,191 iteration 5717 : loss : 0.033504, loss_ce: 0.015165
2021-12-16 16:52:23,600 iteration 5718 : loss : 0.023414, loss_ce: 0.009889
2021-12-16 16:52:25,011 iteration 5719 : loss : 0.031280, loss_ce: 0.015997
2021-12-16 16:52:26,507 iteration 5720 : loss : 0.036133, loss_ce: 0.015581
2021-12-16 16:52:27,977 iteration 5721 : loss : 0.040019, loss_ce: 0.023577
2021-12-16 16:52:29,438 iteration 5722 : loss : 0.033295, loss_ce: 0.015474
2021-12-16 16:52:30,910 iteration 5723 : loss : 0.030255, loss_ce: 0.013563
2021-12-16 16:52:32,403 iteration 5724 : loss : 0.030940, loss_ce: 0.012727
2021-12-16 16:52:33,846 iteration 5725 : loss : 0.030324, loss_ce: 0.012812
2021-12-16 16:52:35,242 iteration 5726 : loss : 0.042801, loss_ce: 0.011356
2021-12-16 16:52:36,728 iteration 5727 : loss : 0.032420, loss_ce: 0.011972
2021-12-16 16:52:38,185 iteration 5728 : loss : 0.044713, loss_ce: 0.015400
2021-12-16 16:52:39,737 iteration 5729 : loss : 0.031122, loss_ce: 0.013814
 84%|████████████████████████▍    | 337/400 [2:32:45<28:02, 26.71s/it]2021-12-16 16:52:41,176 iteration 5730 : loss : 0.027289, loss_ce: 0.013938
2021-12-16 16:52:42,676 iteration 5731 : loss : 0.036701, loss_ce: 0.018632
2021-12-16 16:52:44,080 iteration 5732 : loss : 0.042511, loss_ce: 0.017124
2021-12-16 16:52:45,588 iteration 5733 : loss : 0.061362, loss_ce: 0.018670
2021-12-16 16:52:47,089 iteration 5734 : loss : 0.033296, loss_ce: 0.014381
2021-12-16 16:52:48,498 iteration 5735 : loss : 0.034220, loss_ce: 0.011502
2021-12-16 16:52:49,913 iteration 5736 : loss : 0.044553, loss_ce: 0.022872
2021-12-16 16:52:51,439 iteration 5737 : loss : 0.059226, loss_ce: 0.023274
2021-12-16 16:52:52,850 iteration 5738 : loss : 0.027364, loss_ce: 0.011061
2021-12-16 16:52:54,255 iteration 5739 : loss : 0.030823, loss_ce: 0.013692
2021-12-16 16:52:55,699 iteration 5740 : loss : 0.037816, loss_ce: 0.016417
2021-12-16 16:52:57,152 iteration 5741 : loss : 0.031869, loss_ce: 0.015975
2021-12-16 16:52:58,632 iteration 5742 : loss : 0.032187, loss_ce: 0.009388
2021-12-16 16:53:00,129 iteration 5743 : loss : 0.025835, loss_ce: 0.013424
2021-12-16 16:53:01,641 iteration 5744 : loss : 0.044478, loss_ce: 0.020928
2021-12-16 16:53:03,137 iteration 5745 : loss : 0.044728, loss_ce: 0.019269
2021-12-16 16:53:04,560 iteration 5746 : loss : 0.037369, loss_ce: 0.011530
 84%|████████████████████████▌    | 338/400 [2:33:10<27:00, 26.14s/it]2021-12-16 16:53:06,068 iteration 5747 : loss : 0.029636, loss_ce: 0.012371
2021-12-16 16:53:07,552 iteration 5748 : loss : 0.035713, loss_ce: 0.016427
2021-12-16 16:53:09,011 iteration 5749 : loss : 0.050827, loss_ce: 0.018463
2021-12-16 16:53:10,475 iteration 5750 : loss : 0.033124, loss_ce: 0.014800
2021-12-16 16:53:11,863 iteration 5751 : loss : 0.033016, loss_ce: 0.013389
2021-12-16 16:53:13,285 iteration 5752 : loss : 0.034221, loss_ce: 0.012393
2021-12-16 16:53:14,780 iteration 5753 : loss : 0.034312, loss_ce: 0.016034
2021-12-16 16:53:16,287 iteration 5754 : loss : 0.033899, loss_ce: 0.012430
2021-12-16 16:53:17,740 iteration 5755 : loss : 0.023321, loss_ce: 0.009641
2021-12-16 16:53:19,161 iteration 5756 : loss : 0.030169, loss_ce: 0.012352
2021-12-16 16:53:20,510 iteration 5757 : loss : 0.023291, loss_ce: 0.011065
2021-12-16 16:53:22,023 iteration 5758 : loss : 0.050340, loss_ce: 0.021392
2021-12-16 16:53:23,534 iteration 5759 : loss : 0.025642, loss_ce: 0.012245
2021-12-16 16:53:25,080 iteration 5760 : loss : 0.034262, loss_ce: 0.019377
2021-12-16 16:53:26,636 iteration 5761 : loss : 0.041893, loss_ce: 0.018721
2021-12-16 16:53:28,020 iteration 5762 : loss : 0.026356, loss_ce: 0.013718
2021-12-16 16:53:29,504 iteration 5763 : loss : 0.031791, loss_ce: 0.016153
 85%|████████████████████████▌    | 339/400 [2:33:35<26:12, 25.78s/it]2021-12-16 16:53:31,000 iteration 5764 : loss : 0.031098, loss_ce: 0.014582
2021-12-16 16:53:32,517 iteration 5765 : loss : 0.076419, loss_ce: 0.020465
2021-12-16 16:53:33,985 iteration 5766 : loss : 0.040546, loss_ce: 0.023369
2021-12-16 16:53:35,439 iteration 5767 : loss : 0.029039, loss_ce: 0.017192
2021-12-16 16:53:37,019 iteration 5768 : loss : 0.031080, loss_ce: 0.012317
2021-12-16 16:53:38,536 iteration 5769 : loss : 0.039359, loss_ce: 0.015362
2021-12-16 16:53:39,957 iteration 5770 : loss : 0.033221, loss_ce: 0.013947
2021-12-16 16:53:41,437 iteration 5771 : loss : 0.043166, loss_ce: 0.018095
2021-12-16 16:53:42,900 iteration 5772 : loss : 0.025851, loss_ce: 0.010857
2021-12-16 16:53:44,276 iteration 5773 : loss : 0.036921, loss_ce: 0.013901
2021-12-16 16:53:45,643 iteration 5774 : loss : 0.030374, loss_ce: 0.010921
2021-12-16 16:53:47,113 iteration 5775 : loss : 0.035772, loss_ce: 0.018515
2021-12-16 16:53:48,641 iteration 5776 : loss : 0.065365, loss_ce: 0.032938
2021-12-16 16:53:50,012 iteration 5777 : loss : 0.033325, loss_ce: 0.014704
2021-12-16 16:53:51,444 iteration 5778 : loss : 0.036837, loss_ce: 0.013452
2021-12-16 16:53:52,899 iteration 5779 : loss : 0.027812, loss_ce: 0.011655
2021-12-16 16:53:52,899 Training Data Eval:
2021-12-16 16:54:00,407   Average segmentation loss on training set: 0.0153
2021-12-16 16:54:00,408 Validation Data Eval:
2021-12-16 16:54:03,001   Average segmentation loss on validation set: 0.1011
2021-12-16 16:54:04,462 iteration 5780 : loss : 0.039771, loss_ce: 0.014415
 85%|████████████████████████▋    | 340/400 [2:34:10<28:32, 28.54s/it]2021-12-16 16:54:05,926 iteration 5781 : loss : 0.040940, loss_ce: 0.013587
2021-12-16 16:54:07,448 iteration 5782 : loss : 0.052240, loss_ce: 0.022500
2021-12-16 16:54:08,940 iteration 5783 : loss : 0.036193, loss_ce: 0.014609
2021-12-16 16:54:10,432 iteration 5784 : loss : 0.037720, loss_ce: 0.022778
2021-12-16 16:54:11,839 iteration 5785 : loss : 0.023739, loss_ce: 0.010846
2021-12-16 16:54:13,263 iteration 5786 : loss : 0.025597, loss_ce: 0.012235
2021-12-16 16:54:14,682 iteration 5787 : loss : 0.024866, loss_ce: 0.011783
2021-12-16 16:54:16,275 iteration 5788 : loss : 0.047562, loss_ce: 0.020491
2021-12-16 16:54:17,750 iteration 5789 : loss : 0.039619, loss_ce: 0.017340
2021-12-16 16:54:19,205 iteration 5790 : loss : 0.031657, loss_ce: 0.011697
2021-12-16 16:54:20,607 iteration 5791 : loss : 0.027873, loss_ce: 0.012168
2021-12-16 16:54:22,085 iteration 5792 : loss : 0.033226, loss_ce: 0.013885
2021-12-16 16:54:23,648 iteration 5793 : loss : 0.032218, loss_ce: 0.014512
2021-12-16 16:54:25,108 iteration 5794 : loss : 0.046481, loss_ce: 0.019356
2021-12-16 16:54:26,555 iteration 5795 : loss : 0.031265, loss_ce: 0.014081
2021-12-16 16:54:27,972 iteration 5796 : loss : 0.030171, loss_ce: 0.010804
2021-12-16 16:54:29,458 iteration 5797 : loss : 0.039992, loss_ce: 0.016620
 85%|████████████████████████▋    | 341/400 [2:34:35<27:00, 27.47s/it]2021-12-16 16:54:30,993 iteration 5798 : loss : 0.036639, loss_ce: 0.017830
2021-12-16 16:54:32,471 iteration 5799 : loss : 0.037520, loss_ce: 0.015467
2021-12-16 16:54:33,918 iteration 5800 : loss : 0.030275, loss_ce: 0.013796
2021-12-16 16:54:35,365 iteration 5801 : loss : 0.036757, loss_ce: 0.014171
2021-12-16 16:54:36,761 iteration 5802 : loss : 0.044899, loss_ce: 0.020483
2021-12-16 16:54:38,179 iteration 5803 : loss : 0.027787, loss_ce: 0.015592
2021-12-16 16:54:39,633 iteration 5804 : loss : 0.041112, loss_ce: 0.020290
2021-12-16 16:54:41,210 iteration 5805 : loss : 0.029570, loss_ce: 0.011359
2021-12-16 16:54:42,636 iteration 5806 : loss : 0.034936, loss_ce: 0.012329
2021-12-16 16:54:44,164 iteration 5807 : loss : 0.048606, loss_ce: 0.022279
2021-12-16 16:54:45,632 iteration 5808 : loss : 0.036789, loss_ce: 0.017503
2021-12-16 16:54:47,023 iteration 5809 : loss : 0.023589, loss_ce: 0.008041
2021-12-16 16:54:48,463 iteration 5810 : loss : 0.034119, loss_ce: 0.013080
2021-12-16 16:54:49,870 iteration 5811 : loss : 0.020988, loss_ce: 0.007784
2021-12-16 16:54:51,336 iteration 5812 : loss : 0.038854, loss_ce: 0.016052
2021-12-16 16:54:52,715 iteration 5813 : loss : 0.024101, loss_ce: 0.011909
2021-12-16 16:54:54,180 iteration 5814 : loss : 0.036167, loss_ce: 0.016667
 86%|████████████████████████▊    | 342/400 [2:35:00<25:45, 26.65s/it]2021-12-16 16:54:55,602 iteration 5815 : loss : 0.020519, loss_ce: 0.008345
2021-12-16 16:54:57,034 iteration 5816 : loss : 0.025351, loss_ce: 0.013756
2021-12-16 16:54:58,499 iteration 5817 : loss : 0.027829, loss_ce: 0.012959
2021-12-16 16:54:59,871 iteration 5818 : loss : 0.034815, loss_ce: 0.015584
2021-12-16 16:55:01,408 iteration 5819 : loss : 0.033868, loss_ce: 0.013410
2021-12-16 16:55:02,958 iteration 5820 : loss : 0.049342, loss_ce: 0.027016
2021-12-16 16:55:04,331 iteration 5821 : loss : 0.027922, loss_ce: 0.011908
2021-12-16 16:55:05,734 iteration 5822 : loss : 0.022797, loss_ce: 0.011465
2021-12-16 16:55:07,290 iteration 5823 : loss : 0.036406, loss_ce: 0.017271
2021-12-16 16:55:08,736 iteration 5824 : loss : 0.031830, loss_ce: 0.012495
2021-12-16 16:55:10,216 iteration 5825 : loss : 0.042156, loss_ce: 0.016767
2021-12-16 16:55:11,696 iteration 5826 : loss : 0.038000, loss_ce: 0.010721
2021-12-16 16:55:13,135 iteration 5827 : loss : 0.046737, loss_ce: 0.015895
2021-12-16 16:55:14,684 iteration 5828 : loss : 0.056547, loss_ce: 0.023099
2021-12-16 16:55:16,128 iteration 5829 : loss : 0.026675, loss_ce: 0.011667
2021-12-16 16:55:17,545 iteration 5830 : loss : 0.044145, loss_ce: 0.020690
2021-12-16 16:55:18,978 iteration 5831 : loss : 0.027296, loss_ce: 0.011836
 86%|████████████████████████▊    | 343/400 [2:35:24<24:47, 26.09s/it]2021-12-16 16:55:20,482 iteration 5832 : loss : 0.035841, loss_ce: 0.012620
2021-12-16 16:55:21,989 iteration 5833 : loss : 0.029004, loss_ce: 0.014728
2021-12-16 16:55:23,397 iteration 5834 : loss : 0.030193, loss_ce: 0.011663
2021-12-16 16:55:24,798 iteration 5835 : loss : 0.034454, loss_ce: 0.013326
2021-12-16 16:55:26,303 iteration 5836 : loss : 0.037782, loss_ce: 0.021673
2021-12-16 16:55:27,766 iteration 5837 : loss : 0.031831, loss_ce: 0.008995
2021-12-16 16:55:29,126 iteration 5838 : loss : 0.020729, loss_ce: 0.007752
2021-12-16 16:55:30,578 iteration 5839 : loss : 0.036761, loss_ce: 0.015867
2021-12-16 16:55:32,079 iteration 5840 : loss : 0.049442, loss_ce: 0.019607
2021-12-16 16:55:33,500 iteration 5841 : loss : 0.039419, loss_ce: 0.017098
2021-12-16 16:55:34,926 iteration 5842 : loss : 0.017099, loss_ce: 0.008087
2021-12-16 16:55:36,356 iteration 5843 : loss : 0.038073, loss_ce: 0.019499
2021-12-16 16:55:37,951 iteration 5844 : loss : 0.049013, loss_ce: 0.015504
2021-12-16 16:55:39,383 iteration 5845 : loss : 0.044650, loss_ce: 0.022254
2021-12-16 16:55:40,841 iteration 5846 : loss : 0.060769, loss_ce: 0.025956
2021-12-16 16:55:42,313 iteration 5847 : loss : 0.042145, loss_ce: 0.018015
2021-12-16 16:55:43,765 iteration 5848 : loss : 0.034855, loss_ce: 0.013354
 86%|████████████████████████▉    | 344/400 [2:35:49<23:59, 25.70s/it]2021-12-16 16:55:45,252 iteration 5849 : loss : 0.035503, loss_ce: 0.015939
2021-12-16 16:55:46,638 iteration 5850 : loss : 0.027159, loss_ce: 0.012882
2021-12-16 16:55:48,104 iteration 5851 : loss : 0.028046, loss_ce: 0.015534
2021-12-16 16:55:49,533 iteration 5852 : loss : 0.025137, loss_ce: 0.010839
2021-12-16 16:55:50,913 iteration 5853 : loss : 0.025995, loss_ce: 0.009784
2021-12-16 16:55:52,345 iteration 5854 : loss : 0.031441, loss_ce: 0.012577
2021-12-16 16:55:53,867 iteration 5855 : loss : 0.033398, loss_ce: 0.016624
2021-12-16 16:55:55,339 iteration 5856 : loss : 0.028763, loss_ce: 0.013018
2021-12-16 16:55:56,804 iteration 5857 : loss : 0.026001, loss_ce: 0.012210
2021-12-16 16:55:58,191 iteration 5858 : loss : 0.025784, loss_ce: 0.011273
2021-12-16 16:55:59,682 iteration 5859 : loss : 0.039107, loss_ce: 0.019997
2021-12-16 16:56:01,167 iteration 5860 : loss : 0.052987, loss_ce: 0.017011
2021-12-16 16:56:02,594 iteration 5861 : loss : 0.031386, loss_ce: 0.011886
2021-12-16 16:56:04,075 iteration 5862 : loss : 0.040428, loss_ce: 0.019633
2021-12-16 16:56:05,424 iteration 5863 : loss : 0.019733, loss_ce: 0.008477
2021-12-16 16:56:06,877 iteration 5864 : loss : 0.040833, loss_ce: 0.015094
2021-12-16 16:56:06,877 Training Data Eval:
2021-12-16 16:56:14,387   Average segmentation loss on training set: 0.0157
2021-12-16 16:56:14,387 Validation Data Eval:
2021-12-16 16:56:16,989   Average segmentation loss on validation set: 0.1024
2021-12-16 16:56:18,403 iteration 5865 : loss : 0.047968, loss_ce: 0.018412
 86%|█████████████████████████    | 345/400 [2:36:24<26:01, 28.38s/it]2021-12-16 16:56:20,004 iteration 5866 : loss : 0.034910, loss_ce: 0.016723
2021-12-16 16:56:21,522 iteration 5867 : loss : 0.042311, loss_ce: 0.014149
2021-12-16 16:56:23,014 iteration 5868 : loss : 0.030481, loss_ce: 0.012220
2021-12-16 16:56:24,391 iteration 5869 : loss : 0.037547, loss_ce: 0.016057
2021-12-16 16:56:25,930 iteration 5870 : loss : 0.051196, loss_ce: 0.017867
2021-12-16 16:56:27,451 iteration 5871 : loss : 0.051180, loss_ce: 0.017747
2021-12-16 16:56:28,942 iteration 5872 : loss : 0.058488, loss_ce: 0.022187
2021-12-16 16:56:30,529 iteration 5873 : loss : 0.046462, loss_ce: 0.016488
2021-12-16 16:56:31,937 iteration 5874 : loss : 0.026704, loss_ce: 0.010630
2021-12-16 16:56:33,373 iteration 5875 : loss : 0.028114, loss_ce: 0.014868
2021-12-16 16:56:34,830 iteration 5876 : loss : 0.030128, loss_ce: 0.012867
2021-12-16 16:56:36,283 iteration 5877 : loss : 0.037351, loss_ce: 0.014953
2021-12-16 16:56:37,767 iteration 5878 : loss : 0.024076, loss_ce: 0.010913
2021-12-16 16:56:39,187 iteration 5879 : loss : 0.028040, loss_ce: 0.013714
2021-12-16 16:56:40,765 iteration 5880 : loss : 0.039715, loss_ce: 0.013173
2021-12-16 16:56:42,154 iteration 5881 : loss : 0.024484, loss_ce: 0.012164
2021-12-16 16:56:43,588 iteration 5882 : loss : 0.026435, loss_ce: 0.012946
 86%|█████████████████████████    | 346/400 [2:36:49<24:40, 27.42s/it]2021-12-16 16:56:45,052 iteration 5883 : loss : 0.024215, loss_ce: 0.010370
2021-12-16 16:56:46,464 iteration 5884 : loss : 0.028943, loss_ce: 0.015059
2021-12-16 16:56:48,049 iteration 5885 : loss : 0.055599, loss_ce: 0.023529
2021-12-16 16:56:49,447 iteration 5886 : loss : 0.032071, loss_ce: 0.013823
2021-12-16 16:56:50,887 iteration 5887 : loss : 0.029210, loss_ce: 0.015305
2021-12-16 16:56:52,434 iteration 5888 : loss : 0.045003, loss_ce: 0.016842
2021-12-16 16:56:53,971 iteration 5889 : loss : 0.040824, loss_ce: 0.018174
2021-12-16 16:56:55,439 iteration 5890 : loss : 0.024647, loss_ce: 0.010528
2021-12-16 16:56:56,943 iteration 5891 : loss : 0.036440, loss_ce: 0.012789
2021-12-16 16:56:58,494 iteration 5892 : loss : 0.044794, loss_ce: 0.020425
2021-12-16 16:56:59,921 iteration 5893 : loss : 0.020678, loss_ce: 0.008640
2021-12-16 16:57:01,464 iteration 5894 : loss : 0.082542, loss_ce: 0.037433
2021-12-16 16:57:02,945 iteration 5895 : loss : 0.038852, loss_ce: 0.014168
2021-12-16 16:57:04,388 iteration 5896 : loss : 0.029589, loss_ce: 0.014997
2021-12-16 16:57:05,918 iteration 5897 : loss : 0.054870, loss_ce: 0.023570
2021-12-16 16:57:07,429 iteration 5898 : loss : 0.024179, loss_ce: 0.010731
2021-12-16 16:57:08,859 iteration 5899 : loss : 0.030659, loss_ce: 0.013447
 87%|█████████████████████████▏   | 347/400 [2:37:14<23:39, 26.78s/it]2021-12-16 16:57:10,376 iteration 5900 : loss : 0.034393, loss_ce: 0.013207
2021-12-16 16:57:11,923 iteration 5901 : loss : 0.044068, loss_ce: 0.016977
2021-12-16 16:57:13,383 iteration 5902 : loss : 0.036723, loss_ce: 0.016215
2021-12-16 16:57:14,940 iteration 5903 : loss : 0.034214, loss_ce: 0.015801
2021-12-16 16:57:16,372 iteration 5904 : loss : 0.043315, loss_ce: 0.019571
2021-12-16 16:57:17,872 iteration 5905 : loss : 0.050062, loss_ce: 0.016746
2021-12-16 16:57:19,258 iteration 5906 : loss : 0.036977, loss_ce: 0.015727
2021-12-16 16:57:20,746 iteration 5907 : loss : 0.023057, loss_ce: 0.009333
2021-12-16 16:57:22,224 iteration 5908 : loss : 0.029996, loss_ce: 0.012957
2021-12-16 16:57:23,614 iteration 5909 : loss : 0.032444, loss_ce: 0.010991
2021-12-16 16:57:25,080 iteration 5910 : loss : 0.033111, loss_ce: 0.013064
2021-12-16 16:57:26,586 iteration 5911 : loss : 0.049068, loss_ce: 0.020191
2021-12-16 16:57:27,991 iteration 5912 : loss : 0.028159, loss_ce: 0.010736
2021-12-16 16:57:29,449 iteration 5913 : loss : 0.028378, loss_ce: 0.014783
2021-12-16 16:57:30,918 iteration 5914 : loss : 0.037629, loss_ce: 0.015570
2021-12-16 16:57:32,288 iteration 5915 : loss : 0.029570, loss_ce: 0.013388
2021-12-16 16:57:33,785 iteration 5916 : loss : 0.043226, loss_ce: 0.016926
 87%|█████████████████████████▏   | 348/400 [2:37:39<22:43, 26.22s/it]2021-12-16 16:57:35,248 iteration 5917 : loss : 0.032434, loss_ce: 0.013791
2021-12-16 16:57:36,637 iteration 5918 : loss : 0.028693, loss_ce: 0.012993
2021-12-16 16:57:38,126 iteration 5919 : loss : 0.043071, loss_ce: 0.021542
2021-12-16 16:57:39,662 iteration 5920 : loss : 0.039598, loss_ce: 0.020915
2021-12-16 16:57:41,271 iteration 5921 : loss : 0.059843, loss_ce: 0.019423
2021-12-16 16:57:42,708 iteration 5922 : loss : 0.047686, loss_ce: 0.013700
2021-12-16 16:57:44,196 iteration 5923 : loss : 0.042622, loss_ce: 0.015753
2021-12-16 16:57:45,775 iteration 5924 : loss : 0.050294, loss_ce: 0.015542
2021-12-16 16:57:47,277 iteration 5925 : loss : 0.032442, loss_ce: 0.015415
2021-12-16 16:57:48,729 iteration 5926 : loss : 0.051419, loss_ce: 0.022969
2021-12-16 16:57:50,201 iteration 5927 : loss : 0.039138, loss_ce: 0.017447
2021-12-16 16:57:51,586 iteration 5928 : loss : 0.040022, loss_ce: 0.012572
2021-12-16 16:57:52,999 iteration 5929 : loss : 0.036054, loss_ce: 0.019288
2021-12-16 16:57:54,423 iteration 5930 : loss : 0.037921, loss_ce: 0.016799
2021-12-16 16:57:55,901 iteration 5931 : loss : 0.038268, loss_ce: 0.011772
2021-12-16 16:57:57,419 iteration 5932 : loss : 0.028449, loss_ce: 0.011422
2021-12-16 16:57:58,884 iteration 5933 : loss : 0.036592, loss_ce: 0.013839
 87%|█████████████████████████▎   | 349/400 [2:38:04<21:59, 25.88s/it]2021-12-16 16:58:00,345 iteration 5934 : loss : 0.032631, loss_ce: 0.012325
2021-12-16 16:58:01,942 iteration 5935 : loss : 0.041197, loss_ce: 0.017046
2021-12-16 16:58:03,408 iteration 5936 : loss : 0.025314, loss_ce: 0.013143
2021-12-16 16:58:04,849 iteration 5937 : loss : 0.028066, loss_ce: 0.011216
2021-12-16 16:58:06,240 iteration 5938 : loss : 0.018050, loss_ce: 0.008353
2021-12-16 16:58:07,744 iteration 5939 : loss : 0.030240, loss_ce: 0.015169
2021-12-16 16:58:09,140 iteration 5940 : loss : 0.034298, loss_ce: 0.016403
2021-12-16 16:58:10,565 iteration 5941 : loss : 0.031410, loss_ce: 0.013021
2021-12-16 16:58:12,016 iteration 5942 : loss : 0.031278, loss_ce: 0.015610
2021-12-16 16:58:13,495 iteration 5943 : loss : 0.031769, loss_ce: 0.011237
2021-12-16 16:58:14,956 iteration 5944 : loss : 0.036598, loss_ce: 0.019253
2021-12-16 16:58:16,381 iteration 5945 : loss : 0.037274, loss_ce: 0.011969
2021-12-16 16:58:17,940 iteration 5946 : loss : 0.040458, loss_ce: 0.016913
2021-12-16 16:58:19,439 iteration 5947 : loss : 0.061738, loss_ce: 0.027218
2021-12-16 16:58:20,865 iteration 5948 : loss : 0.036520, loss_ce: 0.016428
2021-12-16 16:58:22,401 iteration 5949 : loss : 0.024653, loss_ce: 0.009473
2021-12-16 16:58:22,402 Training Data Eval:
2021-12-16 16:58:29,934   Average segmentation loss on training set: 0.0151
2021-12-16 16:58:29,934 Validation Data Eval:
2021-12-16 16:58:32,538   Average segmentation loss on validation set: 0.0999
2021-12-16 16:58:34,028 iteration 5950 : loss : 0.032742, loss_ce: 0.013782
 88%|█████████████████████████▍   | 350/400 [2:38:39<23:53, 28.66s/it]2021-12-16 16:58:35,483 iteration 5951 : loss : 0.032221, loss_ce: 0.012438
2021-12-16 16:58:36,953 iteration 5952 : loss : 0.035909, loss_ce: 0.015964
2021-12-16 16:58:38,430 iteration 5953 : loss : 0.041036, loss_ce: 0.019541
2021-12-16 16:58:39,872 iteration 5954 : loss : 0.032862, loss_ce: 0.014088
2021-12-16 16:58:41,336 iteration 5955 : loss : 0.024430, loss_ce: 0.009268
2021-12-16 16:58:42,825 iteration 5956 : loss : 0.035559, loss_ce: 0.021343
2021-12-16 16:58:44,322 iteration 5957 : loss : 0.028694, loss_ce: 0.013167
2021-12-16 16:58:45,732 iteration 5958 : loss : 0.022796, loss_ce: 0.011046
2021-12-16 16:58:47,172 iteration 5959 : loss : 0.038532, loss_ce: 0.019078
2021-12-16 16:58:48,571 iteration 5960 : loss : 0.039620, loss_ce: 0.013957
2021-12-16 16:58:49,971 iteration 5961 : loss : 0.034453, loss_ce: 0.010113
2021-12-16 16:58:51,419 iteration 5962 : loss : 0.047445, loss_ce: 0.011758
2021-12-16 16:58:52,914 iteration 5963 : loss : 0.028871, loss_ce: 0.012826
2021-12-16 16:58:54,344 iteration 5964 : loss : 0.023161, loss_ce: 0.011212
2021-12-16 16:58:55,743 iteration 5965 : loss : 0.028086, loss_ce: 0.014071
2021-12-16 16:58:57,247 iteration 5966 : loss : 0.068309, loss_ce: 0.025507
2021-12-16 16:58:58,715 iteration 5967 : loss : 0.026072, loss_ce: 0.012154
 88%|█████████████████████████▍   | 351/400 [2:39:04<22:25, 27.47s/it]2021-12-16 16:59:00,293 iteration 5968 : loss : 0.043343, loss_ce: 0.015127
2021-12-16 16:59:01,726 iteration 5969 : loss : 0.031360, loss_ce: 0.014438
2021-12-16 16:59:03,226 iteration 5970 : loss : 0.031750, loss_ce: 0.015499
2021-12-16 16:59:04,626 iteration 5971 : loss : 0.035958, loss_ce: 0.012425
2021-12-16 16:59:05,995 iteration 5972 : loss : 0.023289, loss_ce: 0.009093
2021-12-16 16:59:07,454 iteration 5973 : loss : 0.036471, loss_ce: 0.018819
2021-12-16 16:59:09,041 iteration 5974 : loss : 0.039973, loss_ce: 0.020088
2021-12-16 16:59:10,437 iteration 5975 : loss : 0.032814, loss_ce: 0.013646
2021-12-16 16:59:11,875 iteration 5976 : loss : 0.032981, loss_ce: 0.011806
2021-12-16 16:59:13,279 iteration 5977 : loss : 0.029535, loss_ce: 0.009907
2021-12-16 16:59:14,677 iteration 5978 : loss : 0.023745, loss_ce: 0.012503
2021-12-16 16:59:16,145 iteration 5979 : loss : 0.025462, loss_ce: 0.012907
2021-12-16 16:59:17,656 iteration 5980 : loss : 0.023247, loss_ce: 0.009491
2021-12-16 16:59:19,060 iteration 5981 : loss : 0.057162, loss_ce: 0.025753
2021-12-16 16:59:20,495 iteration 5982 : loss : 0.040048, loss_ce: 0.017815
2021-12-16 16:59:21,999 iteration 5983 : loss : 0.036330, loss_ce: 0.015146
2021-12-16 16:59:23,421 iteration 5984 : loss : 0.036522, loss_ce: 0.014872
 88%|█████████████████████████▌   | 352/400 [2:39:29<21:18, 26.64s/it]2021-12-16 16:59:24,913 iteration 5985 : loss : 0.025462, loss_ce: 0.009284
2021-12-16 16:59:26,282 iteration 5986 : loss : 0.031554, loss_ce: 0.010589
2021-12-16 16:59:27,761 iteration 5987 : loss : 0.045764, loss_ce: 0.025174
2021-12-16 16:59:29,280 iteration 5988 : loss : 0.047678, loss_ce: 0.017271
2021-12-16 16:59:30,742 iteration 5989 : loss : 0.027279, loss_ce: 0.011805
2021-12-16 16:59:32,183 iteration 5990 : loss : 0.028086, loss_ce: 0.011093
2021-12-16 16:59:33,662 iteration 5991 : loss : 0.033803, loss_ce: 0.013987
2021-12-16 16:59:35,128 iteration 5992 : loss : 0.046782, loss_ce: 0.019958
2021-12-16 16:59:36,589 iteration 5993 : loss : 0.022644, loss_ce: 0.010753
2021-12-16 16:59:38,103 iteration 5994 : loss : 0.060862, loss_ce: 0.029787
2021-12-16 16:59:39,542 iteration 5995 : loss : 0.030198, loss_ce: 0.012127
2021-12-16 16:59:40,947 iteration 5996 : loss : 0.020927, loss_ce: 0.008307
2021-12-16 16:59:42,427 iteration 5997 : loss : 0.038976, loss_ce: 0.014722
2021-12-16 16:59:43,965 iteration 5998 : loss : 0.030686, loss_ce: 0.012654
2021-12-16 16:59:45,531 iteration 5999 : loss : 0.038498, loss_ce: 0.015293
2021-12-16 16:59:47,000 iteration 6000 : loss : 0.029518, loss_ce: 0.013998
2021-12-16 16:59:48,383 iteration 6001 : loss : 0.027907, loss_ce: 0.015225
 88%|█████████████████████████▌   | 353/400 [2:39:54<20:28, 26.14s/it]2021-12-16 16:59:49,893 iteration 6002 : loss : 0.027176, loss_ce: 0.010588
2021-12-16 16:59:51,314 iteration 6003 : loss : 0.030626, loss_ce: 0.012346
2021-12-16 16:59:52,830 iteration 6004 : loss : 0.028331, loss_ce: 0.013389
2021-12-16 16:59:54,315 iteration 6005 : loss : 0.040775, loss_ce: 0.017269
2021-12-16 16:59:55,865 iteration 6006 : loss : 0.038461, loss_ce: 0.019487
2021-12-16 16:59:57,324 iteration 6007 : loss : 0.024374, loss_ce: 0.011663
2021-12-16 16:59:58,779 iteration 6008 : loss : 0.031710, loss_ce: 0.013112
2021-12-16 17:00:00,162 iteration 6009 : loss : 0.024678, loss_ce: 0.012828
2021-12-16 17:00:01,574 iteration 6010 : loss : 0.022045, loss_ce: 0.010510
2021-12-16 17:00:03,080 iteration 6011 : loss : 0.041428, loss_ce: 0.014420
2021-12-16 17:00:04,608 iteration 6012 : loss : 0.071224, loss_ce: 0.020687
2021-12-16 17:00:06,110 iteration 6013 : loss : 0.039412, loss_ce: 0.013872
2021-12-16 17:00:07,601 iteration 6014 : loss : 0.045423, loss_ce: 0.015126
2021-12-16 17:00:09,029 iteration 6015 : loss : 0.035853, loss_ce: 0.015894
2021-12-16 17:00:10,488 iteration 6016 : loss : 0.025253, loss_ce: 0.011143
2021-12-16 17:00:11,934 iteration 6017 : loss : 0.030358, loss_ce: 0.014181
2021-12-16 17:00:13,429 iteration 6018 : loss : 0.037300, loss_ce: 0.014945
 88%|█████████████████████████▋   | 354/400 [2:40:19<19:47, 25.81s/it]2021-12-16 17:00:14,934 iteration 6019 : loss : 0.032836, loss_ce: 0.019849
2021-12-16 17:00:16,376 iteration 6020 : loss : 0.022261, loss_ce: 0.012093
2021-12-16 17:00:17,855 iteration 6021 : loss : 0.047150, loss_ce: 0.014863
2021-12-16 17:00:19,253 iteration 6022 : loss : 0.026787, loss_ce: 0.012519
2021-12-16 17:00:20,765 iteration 6023 : loss : 0.031719, loss_ce: 0.014560
2021-12-16 17:00:22,202 iteration 6024 : loss : 0.032573, loss_ce: 0.014786
2021-12-16 17:00:23,630 iteration 6025 : loss : 0.031080, loss_ce: 0.012403
2021-12-16 17:00:25,128 iteration 6026 : loss : 0.037649, loss_ce: 0.014963
2021-12-16 17:00:26,613 iteration 6027 : loss : 0.035239, loss_ce: 0.013097
2021-12-16 17:00:28,107 iteration 6028 : loss : 0.033302, loss_ce: 0.014959
2021-12-16 17:00:29,534 iteration 6029 : loss : 0.033354, loss_ce: 0.012722
2021-12-16 17:00:30,922 iteration 6030 : loss : 0.034700, loss_ce: 0.018682
2021-12-16 17:00:32,412 iteration 6031 : loss : 0.028375, loss_ce: 0.014844
2021-12-16 17:00:33,825 iteration 6032 : loss : 0.030046, loss_ce: 0.011607
2021-12-16 17:00:35,331 iteration 6033 : loss : 0.028920, loss_ce: 0.012783
2021-12-16 17:00:36,804 iteration 6034 : loss : 0.025937, loss_ce: 0.011531
2021-12-16 17:00:36,804 Training Data Eval:
2021-12-16 17:00:44,334   Average segmentation loss on training set: 0.0151
2021-12-16 17:00:44,335 Validation Data Eval:
2021-12-16 17:00:46,939   Average segmentation loss on validation set: 0.0975
2021-12-16 17:00:48,297 iteration 6035 : loss : 0.022776, loss_ce: 0.009965
 89%|█████████████████████████▋   | 355/400 [2:40:54<21:23, 28.53s/it]2021-12-16 17:00:49,901 iteration 6036 : loss : 0.036536, loss_ce: 0.011368
2021-12-16 17:00:51,408 iteration 6037 : loss : 0.045480, loss_ce: 0.016720
2021-12-16 17:00:52,844 iteration 6038 : loss : 0.031523, loss_ce: 0.013535
2021-12-16 17:00:54,274 iteration 6039 : loss : 0.044472, loss_ce: 0.015622
2021-12-16 17:00:55,739 iteration 6040 : loss : 0.063501, loss_ce: 0.021717
2021-12-16 17:00:57,154 iteration 6041 : loss : 0.020261, loss_ce: 0.009032
2021-12-16 17:00:58,636 iteration 6042 : loss : 0.024379, loss_ce: 0.012314
2021-12-16 17:01:00,042 iteration 6043 : loss : 0.024727, loss_ce: 0.012609
2021-12-16 17:01:01,434 iteration 6044 : loss : 0.023466, loss_ce: 0.011625
2021-12-16 17:01:02,971 iteration 6045 : loss : 0.048471, loss_ce: 0.022902
2021-12-16 17:01:04,364 iteration 6046 : loss : 0.029644, loss_ce: 0.014628
2021-12-16 17:01:05,762 iteration 6047 : loss : 0.020846, loss_ce: 0.010226
2021-12-16 17:01:07,290 iteration 6048 : loss : 0.041558, loss_ce: 0.013928
2021-12-16 17:01:08,694 iteration 6049 : loss : 0.028563, loss_ce: 0.011477
2021-12-16 17:01:10,086 iteration 6050 : loss : 0.046838, loss_ce: 0.013971
2021-12-16 17:01:11,487 iteration 6051 : loss : 0.023474, loss_ce: 0.011118
2021-12-16 17:01:12,985 iteration 6052 : loss : 0.029247, loss_ce: 0.011849
 89%|█████████████████████████▊   | 356/400 [2:41:18<20:04, 27.37s/it]2021-12-16 17:01:14,456 iteration 6053 : loss : 0.032647, loss_ce: 0.012278
2021-12-16 17:01:15,884 iteration 6054 : loss : 0.028023, loss_ce: 0.011332
2021-12-16 17:01:17,385 iteration 6055 : loss : 0.035355, loss_ce: 0.017002
2021-12-16 17:01:18,841 iteration 6056 : loss : 0.029483, loss_ce: 0.011334
2021-12-16 17:01:20,213 iteration 6057 : loss : 0.029131, loss_ce: 0.012503
2021-12-16 17:01:21,618 iteration 6058 : loss : 0.024370, loss_ce: 0.014007
2021-12-16 17:01:23,139 iteration 6059 : loss : 0.045029, loss_ce: 0.015218
2021-12-16 17:01:24,607 iteration 6060 : loss : 0.034060, loss_ce: 0.011923
2021-12-16 17:01:26,020 iteration 6061 : loss : 0.032394, loss_ce: 0.016760
2021-12-16 17:01:27,612 iteration 6062 : loss : 0.044661, loss_ce: 0.017058
2021-12-16 17:01:29,015 iteration 6063 : loss : 0.031432, loss_ce: 0.015527
2021-12-16 17:01:30,442 iteration 6064 : loss : 0.032647, loss_ce: 0.014835
2021-12-16 17:01:31,951 iteration 6065 : loss : 0.041378, loss_ce: 0.016218
2021-12-16 17:01:33,351 iteration 6066 : loss : 0.038299, loss_ce: 0.017523
2021-12-16 17:01:34,814 iteration 6067 : loss : 0.044197, loss_ce: 0.018901
2021-12-16 17:01:36,261 iteration 6068 : loss : 0.031047, loss_ce: 0.007158
2021-12-16 17:01:37,796 iteration 6069 : loss : 0.038464, loss_ce: 0.018392
 89%|█████████████████████████▉   | 357/400 [2:41:43<19:04, 26.61s/it]2021-12-16 17:01:39,300 iteration 6070 : loss : 0.051806, loss_ce: 0.028476
2021-12-16 17:01:40,779 iteration 6071 : loss : 0.032865, loss_ce: 0.015139
2021-12-16 17:01:42,211 iteration 6072 : loss : 0.026408, loss_ce: 0.010973
2021-12-16 17:01:43,673 iteration 6073 : loss : 0.033017, loss_ce: 0.010370
2021-12-16 17:01:45,044 iteration 6074 : loss : 0.025720, loss_ce: 0.012627
2021-12-16 17:01:46,534 iteration 6075 : loss : 0.043486, loss_ce: 0.022149
2021-12-16 17:01:47,986 iteration 6076 : loss : 0.026760, loss_ce: 0.012705
2021-12-16 17:01:49,330 iteration 6077 : loss : 0.021874, loss_ce: 0.009418
2021-12-16 17:01:50,774 iteration 6078 : loss : 0.029791, loss_ce: 0.016906
2021-12-16 17:01:52,290 iteration 6079 : loss : 0.028150, loss_ce: 0.012498
2021-12-16 17:01:53,679 iteration 6080 : loss : 0.032800, loss_ce: 0.015114
2021-12-16 17:01:55,211 iteration 6081 : loss : 0.045180, loss_ce: 0.020809
2021-12-16 17:01:56,648 iteration 6082 : loss : 0.034945, loss_ce: 0.011231
2021-12-16 17:01:58,170 iteration 6083 : loss : 0.029485, loss_ce: 0.011403
2021-12-16 17:01:59,571 iteration 6084 : loss : 0.031601, loss_ce: 0.011801
2021-12-16 17:02:00,986 iteration 6085 : loss : 0.037708, loss_ce: 0.014927
2021-12-16 17:02:02,608 iteration 6086 : loss : 0.052322, loss_ce: 0.015706
 90%|█████████████████████████▉   | 358/400 [2:42:08<18:14, 26.07s/it]2021-12-16 17:02:04,028 iteration 6087 : loss : 0.032933, loss_ce: 0.014065
2021-12-16 17:02:05,529 iteration 6088 : loss : 0.029065, loss_ce: 0.014283
2021-12-16 17:02:06,960 iteration 6089 : loss : 0.041596, loss_ce: 0.023080
2021-12-16 17:02:08,408 iteration 6090 : loss : 0.031560, loss_ce: 0.011087
2021-12-16 17:02:09,867 iteration 6091 : loss : 0.025015, loss_ce: 0.011935
2021-12-16 17:02:11,329 iteration 6092 : loss : 0.020059, loss_ce: 0.009595
2021-12-16 17:02:12,688 iteration 6093 : loss : 0.025521, loss_ce: 0.010546
2021-12-16 17:02:14,089 iteration 6094 : loss : 0.032255, loss_ce: 0.010988
2021-12-16 17:02:15,567 iteration 6095 : loss : 0.030281, loss_ce: 0.014012
2021-12-16 17:02:17,038 iteration 6096 : loss : 0.042095, loss_ce: 0.014802
2021-12-16 17:02:18,414 iteration 6097 : loss : 0.024939, loss_ce: 0.012181
2021-12-16 17:02:19,895 iteration 6098 : loss : 0.038521, loss_ce: 0.016833
2021-12-16 17:02:21,394 iteration 6099 : loss : 0.036986, loss_ce: 0.012080
2021-12-16 17:02:22,917 iteration 6100 : loss : 0.059529, loss_ce: 0.022358
2021-12-16 17:02:24,399 iteration 6101 : loss : 0.028605, loss_ce: 0.012828
2021-12-16 17:02:25,796 iteration 6102 : loss : 0.028823, loss_ce: 0.011046
2021-12-16 17:02:27,132 iteration 6103 : loss : 0.016797, loss_ce: 0.007684
 90%|██████████████████████████   | 359/400 [2:42:32<17:29, 25.61s/it]2021-12-16 17:02:28,677 iteration 6104 : loss : 0.043253, loss_ce: 0.015054
2021-12-16 17:02:30,075 iteration 6105 : loss : 0.033564, loss_ce: 0.013095
2021-12-16 17:02:31,445 iteration 6106 : loss : 0.038515, loss_ce: 0.013967
2021-12-16 17:02:32,850 iteration 6107 : loss : 0.027447, loss_ce: 0.009942
2021-12-16 17:02:34,361 iteration 6108 : loss : 0.029502, loss_ce: 0.010940
2021-12-16 17:02:35,800 iteration 6109 : loss : 0.028089, loss_ce: 0.010788
2021-12-16 17:02:37,287 iteration 6110 : loss : 0.027694, loss_ce: 0.012276
2021-12-16 17:02:38,794 iteration 6111 : loss : 0.042395, loss_ce: 0.018322
2021-12-16 17:02:40,270 iteration 6112 : loss : 0.048617, loss_ce: 0.023879
2021-12-16 17:02:41,788 iteration 6113 : loss : 0.039933, loss_ce: 0.016189
2021-12-16 17:02:43,216 iteration 6114 : loss : 0.030887, loss_ce: 0.014487
2021-12-16 17:02:44,744 iteration 6115 : loss : 0.055208, loss_ce: 0.021571
2021-12-16 17:02:46,223 iteration 6116 : loss : 0.046168, loss_ce: 0.022865
2021-12-16 17:02:47,639 iteration 6117 : loss : 0.037709, loss_ce: 0.017197
2021-12-16 17:02:49,142 iteration 6118 : loss : 0.029086, loss_ce: 0.013396
2021-12-16 17:02:50,574 iteration 6119 : loss : 0.036476, loss_ce: 0.012847
2021-12-16 17:02:50,574 Training Data Eval:
2021-12-16 17:02:58,074   Average segmentation loss on training set: 0.0146
2021-12-16 17:02:58,074 Validation Data Eval:
2021-12-16 17:03:00,674   Average segmentation loss on validation set: 0.1003
2021-12-16 17:03:02,135 iteration 6120 : loss : 0.024529, loss_ce: 0.012991
 90%|██████████████████████████   | 360/400 [2:43:07<18:57, 28.43s/it]2021-12-16 17:03:03,663 iteration 6121 : loss : 0.038829, loss_ce: 0.019375
2021-12-16 17:03:05,166 iteration 6122 : loss : 0.038486, loss_ce: 0.016001
2021-12-16 17:03:06,706 iteration 6123 : loss : 0.035460, loss_ce: 0.016591
2021-12-16 17:03:08,189 iteration 6124 : loss : 0.024859, loss_ce: 0.009092
2021-12-16 17:03:09,748 iteration 6125 : loss : 0.037650, loss_ce: 0.015320
2021-12-16 17:03:11,179 iteration 6126 : loss : 0.052147, loss_ce: 0.014475
2021-12-16 17:03:12,609 iteration 6127 : loss : 0.029815, loss_ce: 0.012743
2021-12-16 17:03:14,161 iteration 6128 : loss : 0.028411, loss_ce: 0.011484
2021-12-16 17:03:15,618 iteration 6129 : loss : 0.026841, loss_ce: 0.012328
2021-12-16 17:03:17,154 iteration 6130 : loss : 0.032925, loss_ce: 0.014973
2021-12-16 17:03:18,627 iteration 6131 : loss : 0.044776, loss_ce: 0.025192
2021-12-16 17:03:20,092 iteration 6132 : loss : 0.056545, loss_ce: 0.015644
2021-12-16 17:03:21,508 iteration 6133 : loss : 0.026852, loss_ce: 0.015563
2021-12-16 17:03:22,893 iteration 6134 : loss : 0.021122, loss_ce: 0.010418
2021-12-16 17:03:24,296 iteration 6135 : loss : 0.021062, loss_ce: 0.009962
2021-12-16 17:03:25,795 iteration 6136 : loss : 0.026596, loss_ce: 0.010533
2021-12-16 17:03:27,251 iteration 6137 : loss : 0.032191, loss_ce: 0.013631
 90%|██████████████████████████▏  | 361/400 [2:43:33<17:49, 27.43s/it]2021-12-16 17:03:28,684 iteration 6138 : loss : 0.025113, loss_ce: 0.010962
2021-12-16 17:03:30,146 iteration 6139 : loss : 0.037022, loss_ce: 0.016076
2021-12-16 17:03:31,565 iteration 6140 : loss : 0.020735, loss_ce: 0.009201
2021-12-16 17:03:33,028 iteration 6141 : loss : 0.026006, loss_ce: 0.011435
2021-12-16 17:03:34,620 iteration 6142 : loss : 0.035557, loss_ce: 0.013168
2021-12-16 17:03:36,006 iteration 6143 : loss : 0.034494, loss_ce: 0.018875
2021-12-16 17:03:37,473 iteration 6144 : loss : 0.030466, loss_ce: 0.014544
2021-12-16 17:03:38,949 iteration 6145 : loss : 0.035806, loss_ce: 0.014961
2021-12-16 17:03:40,404 iteration 6146 : loss : 0.038975, loss_ce: 0.018100
2021-12-16 17:03:41,856 iteration 6147 : loss : 0.033774, loss_ce: 0.012221
2021-12-16 17:03:43,261 iteration 6148 : loss : 0.024118, loss_ce: 0.009349
2021-12-16 17:03:44,661 iteration 6149 : loss : 0.033717, loss_ce: 0.012085
2021-12-16 17:03:46,103 iteration 6150 : loss : 0.028643, loss_ce: 0.010923
2021-12-16 17:03:47,549 iteration 6151 : loss : 0.035884, loss_ce: 0.011452
2021-12-16 17:03:48,939 iteration 6152 : loss : 0.039575, loss_ce: 0.016778
2021-12-16 17:03:50,451 iteration 6153 : loss : 0.037526, loss_ce: 0.018004
2021-12-16 17:03:51,998 iteration 6154 : loss : 0.043559, loss_ce: 0.020703
 90%|██████████████████████████▏  | 362/400 [2:43:57<16:51, 26.62s/it]2021-12-16 17:03:53,462 iteration 6155 : loss : 0.029836, loss_ce: 0.013488
2021-12-16 17:03:54,902 iteration 6156 : loss : 0.022379, loss_ce: 0.010746
2021-12-16 17:03:56,402 iteration 6157 : loss : 0.030897, loss_ce: 0.013619
2021-12-16 17:03:57,817 iteration 6158 : loss : 0.032500, loss_ce: 0.013326
2021-12-16 17:03:59,198 iteration 6159 : loss : 0.023809, loss_ce: 0.010733
2021-12-16 17:04:00,839 iteration 6160 : loss : 0.063990, loss_ce: 0.031475
2021-12-16 17:04:02,206 iteration 6161 : loss : 0.036311, loss_ce: 0.012100
2021-12-16 17:04:03,688 iteration 6162 : loss : 0.023648, loss_ce: 0.009929
2021-12-16 17:04:05,141 iteration 6163 : loss : 0.024963, loss_ce: 0.011062
2021-12-16 17:04:06,566 iteration 6164 : loss : 0.030385, loss_ce: 0.011844
2021-12-16 17:04:08,039 iteration 6165 : loss : 0.024011, loss_ce: 0.009801
2021-12-16 17:04:09,522 iteration 6166 : loss : 0.035602, loss_ce: 0.017612
2021-12-16 17:04:10,886 iteration 6167 : loss : 0.026215, loss_ce: 0.009799
2021-12-16 17:04:12,455 iteration 6168 : loss : 0.062676, loss_ce: 0.026984
2021-12-16 17:04:13,908 iteration 6169 : loss : 0.029159, loss_ce: 0.013218
2021-12-16 17:04:15,398 iteration 6170 : loss : 0.030954, loss_ce: 0.013353
2021-12-16 17:04:16,839 iteration 6171 : loss : 0.024962, loss_ce: 0.008669
 91%|██████████████████████████▎  | 363/400 [2:44:22<16:05, 26.09s/it]2021-12-16 17:04:18,315 iteration 6172 : loss : 0.040646, loss_ce: 0.015067
2021-12-16 17:04:19,658 iteration 6173 : loss : 0.022974, loss_ce: 0.010126
2021-12-16 17:04:21,076 iteration 6174 : loss : 0.035597, loss_ce: 0.018072
2021-12-16 17:04:22,471 iteration 6175 : loss : 0.022994, loss_ce: 0.008500
2021-12-16 17:04:23,954 iteration 6176 : loss : 0.032973, loss_ce: 0.017654
2021-12-16 17:04:25,511 iteration 6177 : loss : 0.039493, loss_ce: 0.019400
2021-12-16 17:04:27,006 iteration 6178 : loss : 0.053061, loss_ce: 0.019623
2021-12-16 17:04:28,479 iteration 6179 : loss : 0.033785, loss_ce: 0.013400
2021-12-16 17:04:29,951 iteration 6180 : loss : 0.070780, loss_ce: 0.011208
2021-12-16 17:04:31,387 iteration 6181 : loss : 0.029093, loss_ce: 0.012994
2021-12-16 17:04:32,834 iteration 6182 : loss : 0.023588, loss_ce: 0.010557
2021-12-16 17:04:34,234 iteration 6183 : loss : 0.043834, loss_ce: 0.017565
2021-12-16 17:04:35,642 iteration 6184 : loss : 0.026671, loss_ce: 0.011589
2021-12-16 17:04:37,131 iteration 6185 : loss : 0.042161, loss_ce: 0.015351
2021-12-16 17:04:38,525 iteration 6186 : loss : 0.026293, loss_ce: 0.011372
2021-12-16 17:04:39,952 iteration 6187 : loss : 0.027979, loss_ce: 0.011311
2021-12-16 17:04:41,371 iteration 6188 : loss : 0.031064, loss_ce: 0.011220
 91%|██████████████████████████▍  | 364/400 [2:44:47<15:22, 25.62s/it]2021-12-16 17:04:42,962 iteration 6189 : loss : 0.045769, loss_ce: 0.019606
2021-12-16 17:04:44,418 iteration 6190 : loss : 0.026780, loss_ce: 0.011954
2021-12-16 17:04:45,933 iteration 6191 : loss : 0.031283, loss_ce: 0.011384
2021-12-16 17:04:47,402 iteration 6192 : loss : 0.036113, loss_ce: 0.015428
2021-12-16 17:04:48,811 iteration 6193 : loss : 0.020997, loss_ce: 0.008261
2021-12-16 17:04:50,299 iteration 6194 : loss : 0.028697, loss_ce: 0.012184
2021-12-16 17:04:51,810 iteration 6195 : loss : 0.038794, loss_ce: 0.014730
2021-12-16 17:04:53,212 iteration 6196 : loss : 0.040047, loss_ce: 0.013022
2021-12-16 17:04:54,772 iteration 6197 : loss : 0.032537, loss_ce: 0.012786
2021-12-16 17:04:56,321 iteration 6198 : loss : 0.042067, loss_ce: 0.020293
2021-12-16 17:04:57,729 iteration 6199 : loss : 0.024990, loss_ce: 0.011460
2021-12-16 17:04:59,211 iteration 6200 : loss : 0.034783, loss_ce: 0.017737
2021-12-16 17:05:00,665 iteration 6201 : loss : 0.036690, loss_ce: 0.015672
2021-12-16 17:05:02,095 iteration 6202 : loss : 0.034984, loss_ce: 0.011241
2021-12-16 17:05:03,532 iteration 6203 : loss : 0.036135, loss_ce: 0.011868
2021-12-16 17:05:05,028 iteration 6204 : loss : 0.041955, loss_ce: 0.018017
2021-12-16 17:05:05,028 Training Data Eval:
2021-12-16 17:05:12,536   Average segmentation loss on training set: 0.0153
2021-12-16 17:05:12,536 Validation Data Eval:
2021-12-16 17:05:15,136   Average segmentation loss on validation set: 0.0976
2021-12-16 17:05:16,715 iteration 6205 : loss : 0.049619, loss_ce: 0.025443
 91%|██████████████████████████▍  | 365/400 [2:45:22<16:38, 28.54s/it]2021-12-16 17:05:18,243 iteration 6206 : loss : 0.034320, loss_ce: 0.019023
2021-12-16 17:05:19,704 iteration 6207 : loss : 0.029625, loss_ce: 0.016949
2021-12-16 17:05:21,184 iteration 6208 : loss : 0.036312, loss_ce: 0.014434
2021-12-16 17:05:22,654 iteration 6209 : loss : 0.035858, loss_ce: 0.014973
2021-12-16 17:05:24,074 iteration 6210 : loss : 0.029458, loss_ce: 0.012123
2021-12-16 17:05:25,462 iteration 6211 : loss : 0.025348, loss_ce: 0.011092
2021-12-16 17:05:26,894 iteration 6212 : loss : 0.035560, loss_ce: 0.014923
2021-12-16 17:05:28,353 iteration 6213 : loss : 0.025289, loss_ce: 0.011473
2021-12-16 17:05:29,793 iteration 6214 : loss : 0.021730, loss_ce: 0.010130
2021-12-16 17:05:31,305 iteration 6215 : loss : 0.044319, loss_ce: 0.017026
2021-12-16 17:05:32,743 iteration 6216 : loss : 0.028215, loss_ce: 0.015892
2021-12-16 17:05:34,128 iteration 6217 : loss : 0.035016, loss_ce: 0.012267
2021-12-16 17:05:35,587 iteration 6218 : loss : 0.039163, loss_ce: 0.016085
2021-12-16 17:05:37,042 iteration 6219 : loss : 0.024886, loss_ce: 0.010122
2021-12-16 17:05:38,470 iteration 6220 : loss : 0.025185, loss_ce: 0.008226
2021-12-16 17:05:39,951 iteration 6221 : loss : 0.036532, loss_ce: 0.011473
2021-12-16 17:05:41,358 iteration 6222 : loss : 0.023104, loss_ce: 0.012486
 92%|██████████████████████████▌  | 366/400 [2:45:47<15:30, 27.37s/it]2021-12-16 17:05:42,870 iteration 6223 : loss : 0.030350, loss_ce: 0.014097
2021-12-16 17:05:44,309 iteration 6224 : loss : 0.038852, loss_ce: 0.017285
2021-12-16 17:05:45,762 iteration 6225 : loss : 0.034930, loss_ce: 0.012220
2021-12-16 17:05:47,170 iteration 6226 : loss : 0.023403, loss_ce: 0.010239
2021-12-16 17:05:48,575 iteration 6227 : loss : 0.027905, loss_ce: 0.012526
2021-12-16 17:05:50,046 iteration 6228 : loss : 0.030261, loss_ce: 0.011417
2021-12-16 17:05:51,525 iteration 6229 : loss : 0.024089, loss_ce: 0.012822
2021-12-16 17:05:53,001 iteration 6230 : loss : 0.025964, loss_ce: 0.009983
2021-12-16 17:05:54,490 iteration 6231 : loss : 0.036380, loss_ce: 0.015306
2021-12-16 17:05:55,962 iteration 6232 : loss : 0.030073, loss_ce: 0.015637
2021-12-16 17:05:57,408 iteration 6233 : loss : 0.030078, loss_ce: 0.014504
2021-12-16 17:05:58,842 iteration 6234 : loss : 0.044250, loss_ce: 0.012811
2021-12-16 17:06:00,231 iteration 6235 : loss : 0.030937, loss_ce: 0.017821
2021-12-16 17:06:01,685 iteration 6236 : loss : 0.026238, loss_ce: 0.013737
2021-12-16 17:06:03,154 iteration 6237 : loss : 0.035023, loss_ce: 0.017585
2021-12-16 17:06:04,666 iteration 6238 : loss : 0.032381, loss_ce: 0.012006
2021-12-16 17:06:06,127 iteration 6239 : loss : 0.039947, loss_ce: 0.013819
 92%|██████████████████████████▌  | 367/400 [2:46:11<14:37, 26.59s/it]2021-12-16 17:06:07,604 iteration 6240 : loss : 0.029911, loss_ce: 0.012522
2021-12-16 17:06:09,002 iteration 6241 : loss : 0.023401, loss_ce: 0.012825
2021-12-16 17:06:10,517 iteration 6242 : loss : 0.039601, loss_ce: 0.013672
2021-12-16 17:06:11,935 iteration 6243 : loss : 0.020770, loss_ce: 0.010087
2021-12-16 17:06:13,464 iteration 6244 : loss : 0.030979, loss_ce: 0.014671
2021-12-16 17:06:14,902 iteration 6245 : loss : 0.030777, loss_ce: 0.012666
2021-12-16 17:06:16,338 iteration 6246 : loss : 0.030563, loss_ce: 0.016115
2021-12-16 17:06:17,810 iteration 6247 : loss : 0.034324, loss_ce: 0.010765
2021-12-16 17:06:19,246 iteration 6248 : loss : 0.021710, loss_ce: 0.009327
2021-12-16 17:06:20,685 iteration 6249 : loss : 0.031560, loss_ce: 0.010568
2021-12-16 17:06:22,168 iteration 6250 : loss : 0.027952, loss_ce: 0.011971
2021-12-16 17:06:23,723 iteration 6251 : loss : 0.039933, loss_ce: 0.017663
2021-12-16 17:06:25,112 iteration 6252 : loss : 0.029741, loss_ce: 0.017366
2021-12-16 17:06:26,612 iteration 6253 : loss : 0.030626, loss_ce: 0.012211
2021-12-16 17:06:28,050 iteration 6254 : loss : 0.036158, loss_ce: 0.017939
2021-12-16 17:06:29,519 iteration 6255 : loss : 0.038414, loss_ce: 0.018678
2021-12-16 17:06:31,076 iteration 6256 : loss : 0.035544, loss_ce: 0.014964
 92%|██████████████████████████▋  | 368/400 [2:46:36<13:55, 26.10s/it]2021-12-16 17:06:32,604 iteration 6257 : loss : 0.043609, loss_ce: 0.017398
2021-12-16 17:06:34,085 iteration 6258 : loss : 0.036722, loss_ce: 0.015367
2021-12-16 17:06:35,613 iteration 6259 : loss : 0.030128, loss_ce: 0.013914
2021-12-16 17:06:37,051 iteration 6260 : loss : 0.047629, loss_ce: 0.021347
2021-12-16 17:06:38,480 iteration 6261 : loss : 0.030913, loss_ce: 0.012589
2021-12-16 17:06:39,950 iteration 6262 : loss : 0.037403, loss_ce: 0.011547
2021-12-16 17:06:41,418 iteration 6263 : loss : 0.039168, loss_ce: 0.009954
2021-12-16 17:06:42,876 iteration 6264 : loss : 0.029630, loss_ce: 0.012084
2021-12-16 17:06:44,339 iteration 6265 : loss : 0.029550, loss_ce: 0.013113
2021-12-16 17:06:45,758 iteration 6266 : loss : 0.036024, loss_ce: 0.018607
2021-12-16 17:06:47,166 iteration 6267 : loss : 0.033859, loss_ce: 0.016879
2021-12-16 17:06:48,615 iteration 6268 : loss : 0.034555, loss_ce: 0.015968
2021-12-16 17:06:49,932 iteration 6269 : loss : 0.019184, loss_ce: 0.008692
2021-12-16 17:06:51,388 iteration 6270 : loss : 0.027344, loss_ce: 0.013312
2021-12-16 17:06:52,872 iteration 6271 : loss : 0.051160, loss_ce: 0.018401
2021-12-16 17:06:54,374 iteration 6272 : loss : 0.037099, loss_ce: 0.016007
2021-12-16 17:06:55,888 iteration 6273 : loss : 0.027289, loss_ce: 0.011643
 92%|██████████████████████████▊  | 369/400 [2:47:01<13:17, 25.71s/it]2021-12-16 17:06:57,515 iteration 6274 : loss : 0.046853, loss_ce: 0.017865
2021-12-16 17:06:58,994 iteration 6275 : loss : 0.041359, loss_ce: 0.022567
2021-12-16 17:07:00,462 iteration 6276 : loss : 0.026062, loss_ce: 0.011614
2021-12-16 17:07:01,872 iteration 6277 : loss : 0.037019, loss_ce: 0.012264
2021-12-16 17:07:03,362 iteration 6278 : loss : 0.034777, loss_ce: 0.013363
2021-12-16 17:07:04,786 iteration 6279 : loss : 0.046090, loss_ce: 0.022335
2021-12-16 17:07:06,197 iteration 6280 : loss : 0.035198, loss_ce: 0.014345
2021-12-16 17:07:07,774 iteration 6281 : loss : 0.037799, loss_ce: 0.011526
2021-12-16 17:07:09,217 iteration 6282 : loss : 0.022955, loss_ce: 0.011035
2021-12-16 17:07:10,641 iteration 6283 : loss : 0.027229, loss_ce: 0.014636
2021-12-16 17:07:12,113 iteration 6284 : loss : 0.034864, loss_ce: 0.016893
2021-12-16 17:07:13,612 iteration 6285 : loss : 0.032358, loss_ce: 0.012927
2021-12-16 17:07:15,029 iteration 6286 : loss : 0.035272, loss_ce: 0.013710
2021-12-16 17:07:16,444 iteration 6287 : loss : 0.034728, loss_ce: 0.011770
2021-12-16 17:07:17,804 iteration 6288 : loss : 0.022254, loss_ce: 0.009135
2021-12-16 17:07:19,270 iteration 6289 : loss : 0.034280, loss_ce: 0.016007
2021-12-16 17:07:19,270 Training Data Eval:
2021-12-16 17:07:26,781   Average segmentation loss on training set: 0.0146
2021-12-16 17:07:26,782 Validation Data Eval:
2021-12-16 17:07:29,383   Average segmentation loss on validation set: 0.0968
2021-12-16 17:07:30,891 iteration 6290 : loss : 0.033025, loss_ce: 0.017106
 92%|██████████████████████████▊  | 370/400 [2:47:36<14:14, 28.50s/it]2021-12-16 17:07:32,409 iteration 6291 : loss : 0.020131, loss_ce: 0.009415
2021-12-16 17:07:33,867 iteration 6292 : loss : 0.038450, loss_ce: 0.015285
2021-12-16 17:07:35,374 iteration 6293 : loss : 0.035312, loss_ce: 0.016828
2021-12-16 17:07:36,865 iteration 6294 : loss : 0.042472, loss_ce: 0.013757
2021-12-16 17:07:38,316 iteration 6295 : loss : 0.025067, loss_ce: 0.011697
2021-12-16 17:07:39,853 iteration 6296 : loss : 0.042361, loss_ce: 0.016863
2021-12-16 17:07:41,313 iteration 6297 : loss : 0.043335, loss_ce: 0.015976
2021-12-16 17:07:42,818 iteration 6298 : loss : 0.066943, loss_ce: 0.027862
2021-12-16 17:07:44,270 iteration 6299 : loss : 0.037160, loss_ce: 0.013853
2021-12-16 17:07:45,700 iteration 6300 : loss : 0.026115, loss_ce: 0.011589
2021-12-16 17:07:47,112 iteration 6301 : loss : 0.030295, loss_ce: 0.020103
2021-12-16 17:07:48,581 iteration 6302 : loss : 0.032270, loss_ce: 0.014279
2021-12-16 17:07:49,938 iteration 6303 : loss : 0.023894, loss_ce: 0.007424
2021-12-16 17:07:51,325 iteration 6304 : loss : 0.030196, loss_ce: 0.009513
2021-12-16 17:07:52,826 iteration 6305 : loss : 0.033635, loss_ce: 0.017420
2021-12-16 17:07:54,263 iteration 6306 : loss : 0.074766, loss_ce: 0.020178
2021-12-16 17:07:55,729 iteration 6307 : loss : 0.028917, loss_ce: 0.014591
 93%|██████████████████████████▉  | 371/400 [2:48:01<13:14, 27.40s/it]2021-12-16 17:07:57,180 iteration 6308 : loss : 0.035856, loss_ce: 0.009551
2021-12-16 17:07:58,635 iteration 6309 : loss : 0.036345, loss_ce: 0.015081
2021-12-16 17:08:00,096 iteration 6310 : loss : 0.030026, loss_ce: 0.014596
2021-12-16 17:08:01,542 iteration 6311 : loss : 0.025092, loss_ce: 0.011537
2021-12-16 17:08:03,017 iteration 6312 : loss : 0.040181, loss_ce: 0.013924
2021-12-16 17:08:04,541 iteration 6313 : loss : 0.039941, loss_ce: 0.020328
2021-12-16 17:08:05,974 iteration 6314 : loss : 0.025635, loss_ce: 0.010690
2021-12-16 17:08:07,373 iteration 6315 : loss : 0.030136, loss_ce: 0.013636
2021-12-16 17:08:08,814 iteration 6316 : loss : 0.028136, loss_ce: 0.011385
2021-12-16 17:08:10,251 iteration 6317 : loss : 0.028081, loss_ce: 0.009544
2021-12-16 17:08:11,765 iteration 6318 : loss : 0.037683, loss_ce: 0.015314
2021-12-16 17:08:13,228 iteration 6319 : loss : 0.032694, loss_ce: 0.012439
2021-12-16 17:08:14,659 iteration 6320 : loss : 0.031069, loss_ce: 0.011723
2021-12-16 17:08:16,159 iteration 6321 : loss : 0.046963, loss_ce: 0.029033
2021-12-16 17:08:17,668 iteration 6322 : loss : 0.041536, loss_ce: 0.023418
2021-12-16 17:08:19,259 iteration 6323 : loss : 0.043993, loss_ce: 0.016757
2021-12-16 17:08:20,770 iteration 6324 : loss : 0.048106, loss_ce: 0.026305
 93%|██████████████████████████▉  | 372/400 [2:48:26<12:27, 26.69s/it]2021-12-16 17:08:22,276 iteration 6325 : loss : 0.032515, loss_ce: 0.009898
2021-12-16 17:08:23,685 iteration 6326 : loss : 0.036108, loss_ce: 0.016921
2021-12-16 17:08:25,132 iteration 6327 : loss : 0.026681, loss_ce: 0.011652
2021-12-16 17:08:26,640 iteration 6328 : loss : 0.023017, loss_ce: 0.012161
2021-12-16 17:08:28,034 iteration 6329 : loss : 0.032489, loss_ce: 0.016908
2021-12-16 17:08:29,503 iteration 6330 : loss : 0.032568, loss_ce: 0.014895
2021-12-16 17:08:31,020 iteration 6331 : loss : 0.037157, loss_ce: 0.017525
2021-12-16 17:08:32,505 iteration 6332 : loss : 0.029453, loss_ce: 0.010389
2021-12-16 17:08:33,954 iteration 6333 : loss : 0.025204, loss_ce: 0.012641
2021-12-16 17:08:35,407 iteration 6334 : loss : 0.052138, loss_ce: 0.015643
2021-12-16 17:08:36,958 iteration 6335 : loss : 0.023797, loss_ce: 0.011157
2021-12-16 17:08:38,380 iteration 6336 : loss : 0.024726, loss_ce: 0.011310
2021-12-16 17:08:39,888 iteration 6337 : loss : 0.031424, loss_ce: 0.012355
2021-12-16 17:08:41,339 iteration 6338 : loss : 0.026658, loss_ce: 0.010415
2021-12-16 17:08:42,791 iteration 6339 : loss : 0.033211, loss_ce: 0.014558
2021-12-16 17:08:44,243 iteration 6340 : loss : 0.040172, loss_ce: 0.019298
2021-12-16 17:08:45,615 iteration 6341 : loss : 0.020742, loss_ce: 0.009199
 93%|███████████████████████████  | 373/400 [2:48:51<11:45, 26.14s/it]2021-12-16 17:08:47,161 iteration 6342 : loss : 0.043097, loss_ce: 0.015754
2021-12-16 17:08:48,591 iteration 6343 : loss : 0.026433, loss_ce: 0.011244
2021-12-16 17:08:50,016 iteration 6344 : loss : 0.047327, loss_ce: 0.015691
2021-12-16 17:08:51,430 iteration 6345 : loss : 0.050500, loss_ce: 0.007967
2021-12-16 17:08:52,900 iteration 6346 : loss : 0.050411, loss_ce: 0.017358
2021-12-16 17:08:54,367 iteration 6347 : loss : 0.030133, loss_ce: 0.012445
2021-12-16 17:08:55,727 iteration 6348 : loss : 0.018742, loss_ce: 0.008848
2021-12-16 17:08:57,216 iteration 6349 : loss : 0.032421, loss_ce: 0.017964
2021-12-16 17:08:58,786 iteration 6350 : loss : 0.059343, loss_ce: 0.024077
2021-12-16 17:09:00,285 iteration 6351 : loss : 0.027167, loss_ce: 0.013817
2021-12-16 17:09:01,723 iteration 6352 : loss : 0.038165, loss_ce: 0.013254
2021-12-16 17:09:03,181 iteration 6353 : loss : 0.033987, loss_ce: 0.014728
2021-12-16 17:09:04,633 iteration 6354 : loss : 0.026360, loss_ce: 0.012432
2021-12-16 17:09:06,054 iteration 6355 : loss : 0.037673, loss_ce: 0.014869
2021-12-16 17:09:07,577 iteration 6356 : loss : 0.055048, loss_ce: 0.015820
2021-12-16 17:09:09,015 iteration 6357 : loss : 0.031800, loss_ce: 0.012706
2021-12-16 17:09:10,578 iteration 6358 : loss : 0.047722, loss_ce: 0.022228
 94%|███████████████████████████  | 374/400 [2:49:16<11:10, 25.79s/it]2021-12-16 17:09:12,150 iteration 6359 : loss : 0.060126, loss_ce: 0.018666
2021-12-16 17:09:13,538 iteration 6360 : loss : 0.032626, loss_ce: 0.017098
2021-12-16 17:09:15,030 iteration 6361 : loss : 0.031831, loss_ce: 0.011724
2021-12-16 17:09:16,526 iteration 6362 : loss : 0.052210, loss_ce: 0.025147
2021-12-16 17:09:18,042 iteration 6363 : loss : 0.047705, loss_ce: 0.018670
2021-12-16 17:09:19,465 iteration 6364 : loss : 0.030752, loss_ce: 0.009974
2021-12-16 17:09:20,932 iteration 6365 : loss : 0.051794, loss_ce: 0.025776
2021-12-16 17:09:22,478 iteration 6366 : loss : 0.035033, loss_ce: 0.015108
2021-12-16 17:09:24,047 iteration 6367 : loss : 0.038296, loss_ce: 0.016423
2021-12-16 17:09:25,538 iteration 6368 : loss : 0.043166, loss_ce: 0.019530
2021-12-16 17:09:26,982 iteration 6369 : loss : 0.032177, loss_ce: 0.015184
2021-12-16 17:09:28,443 iteration 6370 : loss : 0.036756, loss_ce: 0.015117
2021-12-16 17:09:30,011 iteration 6371 : loss : 0.058781, loss_ce: 0.018780
2021-12-16 17:09:31,424 iteration 6372 : loss : 0.022209, loss_ce: 0.010879
2021-12-16 17:09:32,836 iteration 6373 : loss : 0.021931, loss_ce: 0.009793
2021-12-16 17:09:34,298 iteration 6374 : loss : 0.038227, loss_ce: 0.017756
2021-12-16 17:09:34,298 Training Data Eval:
2021-12-16 17:09:41,769   Average segmentation loss on training set: 0.0149
2021-12-16 17:09:41,770 Validation Data Eval:
2021-12-16 17:09:44,360   Average segmentation loss on validation set: 0.0943
2021-12-16 17:09:45,837 iteration 6375 : loss : 0.037850, loss_ce: 0.014116
 94%|███████████████████████████▏ | 375/400 [2:49:51<11:55, 28.63s/it]2021-12-16 17:09:47,365 iteration 6376 : loss : 0.066016, loss_ce: 0.023050
2021-12-16 17:09:48,825 iteration 6377 : loss : 0.033022, loss_ce: 0.013155
2021-12-16 17:09:50,186 iteration 6378 : loss : 0.035217, loss_ce: 0.017623
2021-12-16 17:09:51,652 iteration 6379 : loss : 0.036047, loss_ce: 0.011622
2021-12-16 17:09:53,085 iteration 6380 : loss : 0.036258, loss_ce: 0.015571
2021-12-16 17:09:54,533 iteration 6381 : loss : 0.023789, loss_ce: 0.009515
2021-12-16 17:09:55,893 iteration 6382 : loss : 0.026607, loss_ce: 0.011275
2021-12-16 17:09:57,394 iteration 6383 : loss : 0.039275, loss_ce: 0.015147
2021-12-16 17:09:58,811 iteration 6384 : loss : 0.024246, loss_ce: 0.010653
2021-12-16 17:10:00,338 iteration 6385 : loss : 0.042245, loss_ce: 0.014463
2021-12-16 17:10:01,833 iteration 6386 : loss : 0.038083, loss_ce: 0.013422
2021-12-16 17:10:03,377 iteration 6387 : loss : 0.040014, loss_ce: 0.021331
2021-12-16 17:10:04,843 iteration 6388 : loss : 0.027102, loss_ce: 0.012476
2021-12-16 17:10:06,172 iteration 6389 : loss : 0.024225, loss_ce: 0.010687
2021-12-16 17:10:07,625 iteration 6390 : loss : 0.035808, loss_ce: 0.018250
2021-12-16 17:10:09,036 iteration 6391 : loss : 0.029527, loss_ce: 0.016868
2021-12-16 17:10:10,553 iteration 6392 : loss : 0.038937, loss_ce: 0.012300
 94%|███████████████████████████▎ | 376/400 [2:50:16<10:58, 27.46s/it]2021-12-16 17:10:12,022 iteration 6393 : loss : 0.028447, loss_ce: 0.012254
2021-12-16 17:10:13,509 iteration 6394 : loss : 0.037287, loss_ce: 0.016594
2021-12-16 17:10:14,939 iteration 6395 : loss : 0.036324, loss_ce: 0.013278
2021-12-16 17:10:16,384 iteration 6396 : loss : 0.028126, loss_ce: 0.010637
2021-12-16 17:10:17,865 iteration 6397 : loss : 0.027015, loss_ce: 0.011514
2021-12-16 17:10:19,332 iteration 6398 : loss : 0.033513, loss_ce: 0.014033
2021-12-16 17:10:20,774 iteration 6399 : loss : 0.046443, loss_ce: 0.017197
2021-12-16 17:10:22,195 iteration 6400 : loss : 0.029754, loss_ce: 0.015018
2021-12-16 17:10:23,657 iteration 6401 : loss : 0.032739, loss_ce: 0.014297
2021-12-16 17:10:25,087 iteration 6402 : loss : 0.043768, loss_ce: 0.028273
2021-12-16 17:10:26,606 iteration 6403 : loss : 0.039569, loss_ce: 0.017887
2021-12-16 17:10:28,034 iteration 6404 : loss : 0.028578, loss_ce: 0.013768
2021-12-16 17:10:29,447 iteration 6405 : loss : 0.046340, loss_ce: 0.015029
2021-12-16 17:10:31,050 iteration 6406 : loss : 0.048695, loss_ce: 0.014392
2021-12-16 17:10:32,516 iteration 6407 : loss : 0.043113, loss_ce: 0.012930
2021-12-16 17:10:33,867 iteration 6408 : loss : 0.024738, loss_ce: 0.009992
2021-12-16 17:10:35,296 iteration 6409 : loss : 0.036228, loss_ce: 0.017982
 94%|███████████████████████████▎ | 377/400 [2:50:41<10:12, 26.64s/it]2021-12-16 17:10:36,747 iteration 6410 : loss : 0.031289, loss_ce: 0.012992
2021-12-16 17:10:38,221 iteration 6411 : loss : 0.036745, loss_ce: 0.017644
2021-12-16 17:10:39,695 iteration 6412 : loss : 0.033584, loss_ce: 0.013185
2021-12-16 17:10:41,133 iteration 6413 : loss : 0.039498, loss_ce: 0.018133
2021-12-16 17:10:42,570 iteration 6414 : loss : 0.025964, loss_ce: 0.011912
2021-12-16 17:10:43,955 iteration 6415 : loss : 0.028216, loss_ce: 0.010331
2021-12-16 17:10:45,403 iteration 6416 : loss : 0.027228, loss_ce: 0.011636
2021-12-16 17:10:46,785 iteration 6417 : loss : 0.026376, loss_ce: 0.012386
2021-12-16 17:10:48,213 iteration 6418 : loss : 0.034113, loss_ce: 0.016178
2021-12-16 17:10:49,756 iteration 6419 : loss : 0.041219, loss_ce: 0.018044
2021-12-16 17:10:51,272 iteration 6420 : loss : 0.050994, loss_ce: 0.016329
2021-12-16 17:10:52,741 iteration 6421 : loss : 0.025702, loss_ce: 0.011621
2021-12-16 17:10:54,192 iteration 6422 : loss : 0.029573, loss_ce: 0.010533
2021-12-16 17:10:55,663 iteration 6423 : loss : 0.032169, loss_ce: 0.013898
2021-12-16 17:10:57,196 iteration 6424 : loss : 0.048109, loss_ce: 0.030449
2021-12-16 17:10:58,620 iteration 6425 : loss : 0.031093, loss_ce: 0.011529
2021-12-16 17:11:00,119 iteration 6426 : loss : 0.045294, loss_ce: 0.015997
 94%|███████████████████████████▍ | 378/400 [2:51:05<09:34, 26.09s/it]2021-12-16 17:11:01,668 iteration 6427 : loss : 0.029914, loss_ce: 0.012272
2021-12-16 17:11:03,117 iteration 6428 : loss : 0.037989, loss_ce: 0.014871
2021-12-16 17:11:04,585 iteration 6429 : loss : 0.029486, loss_ce: 0.011032
2021-12-16 17:11:06,102 iteration 6430 : loss : 0.034416, loss_ce: 0.015408
2021-12-16 17:11:07,486 iteration 6431 : loss : 0.024761, loss_ce: 0.011070
2021-12-16 17:11:08,932 iteration 6432 : loss : 0.032127, loss_ce: 0.015385
2021-12-16 17:11:10,353 iteration 6433 : loss : 0.027037, loss_ce: 0.010123
2021-12-16 17:11:11,761 iteration 6434 : loss : 0.032955, loss_ce: 0.014652
2021-12-16 17:11:13,207 iteration 6435 : loss : 0.045566, loss_ce: 0.017896
2021-12-16 17:11:14,641 iteration 6436 : loss : 0.022451, loss_ce: 0.010926
2021-12-16 17:11:16,086 iteration 6437 : loss : 0.028777, loss_ce: 0.011271
2021-12-16 17:11:17,566 iteration 6438 : loss : 0.045498, loss_ce: 0.016193
2021-12-16 17:11:18,966 iteration 6439 : loss : 0.033139, loss_ce: 0.018970
2021-12-16 17:11:20,461 iteration 6440 : loss : 0.037177, loss_ce: 0.018765
2021-12-16 17:11:21,865 iteration 6441 : loss : 0.032033, loss_ce: 0.018604
2021-12-16 17:11:23,337 iteration 6442 : loss : 0.034959, loss_ce: 0.013874
2021-12-16 17:11:24,704 iteration 6443 : loss : 0.023699, loss_ce: 0.010543
 95%|███████████████████████████▍ | 379/400 [2:51:30<08:58, 25.64s/it]2021-12-16 17:11:26,201 iteration 6444 : loss : 0.033455, loss_ce: 0.017387
2021-12-16 17:11:27,649 iteration 6445 : loss : 0.035607, loss_ce: 0.017402
2021-12-16 17:11:29,104 iteration 6446 : loss : 0.032345, loss_ce: 0.015563
2021-12-16 17:11:30,584 iteration 6447 : loss : 0.073012, loss_ce: 0.015469
2021-12-16 17:11:32,061 iteration 6448 : loss : 0.041481, loss_ce: 0.021429
2021-12-16 17:11:33,477 iteration 6449 : loss : 0.027126, loss_ce: 0.009046
2021-12-16 17:11:34,877 iteration 6450 : loss : 0.031175, loss_ce: 0.015196
2021-12-16 17:11:36,346 iteration 6451 : loss : 0.027130, loss_ce: 0.010876
2021-12-16 17:11:37,875 iteration 6452 : loss : 0.052215, loss_ce: 0.023126
2021-12-16 17:11:39,306 iteration 6453 : loss : 0.029155, loss_ce: 0.012542
2021-12-16 17:11:40,694 iteration 6454 : loss : 0.034646, loss_ce: 0.013982
2021-12-16 17:11:42,176 iteration 6455 : loss : 0.025941, loss_ce: 0.013594
2021-12-16 17:11:43,625 iteration 6456 : loss : 0.038962, loss_ce: 0.017130
2021-12-16 17:11:45,122 iteration 6457 : loss : 0.038633, loss_ce: 0.014346
2021-12-16 17:11:46,525 iteration 6458 : loss : 0.028312, loss_ce: 0.011811
2021-12-16 17:11:47,960 iteration 6459 : loss : 0.023643, loss_ce: 0.007844
2021-12-16 17:11:47,960 Training Data Eval:
2021-12-16 17:11:55,431   Average segmentation loss on training set: 0.0146
2021-12-16 17:11:55,432 Validation Data Eval:
2021-12-16 17:11:58,010   Average segmentation loss on validation set: 0.0980
2021-12-16 17:11:59,511 iteration 6460 : loss : 0.035789, loss_ce: 0.020379
 95%|███████████████████████████▌ | 380/400 [2:52:05<09:27, 28.39s/it]2021-12-16 17:12:01,076 iteration 6461 : loss : 0.043058, loss_ce: 0.017815
2021-12-16 17:12:02,509 iteration 6462 : loss : 0.022716, loss_ce: 0.010849
2021-12-16 17:12:04,014 iteration 6463 : loss : 0.042288, loss_ce: 0.021245
2021-12-16 17:12:05,460 iteration 6464 : loss : 0.048683, loss_ce: 0.015195
2021-12-16 17:12:06,952 iteration 6465 : loss : 0.047756, loss_ce: 0.019885
2021-12-16 17:12:08,396 iteration 6466 : loss : 0.030536, loss_ce: 0.012864
2021-12-16 17:12:09,831 iteration 6467 : loss : 0.030636, loss_ce: 0.011759
2021-12-16 17:12:11,358 iteration 6468 : loss : 0.046683, loss_ce: 0.017011
2021-12-16 17:12:12,785 iteration 6469 : loss : 0.024030, loss_ce: 0.011330
2021-12-16 17:12:14,194 iteration 6470 : loss : 0.031969, loss_ce: 0.011413
2021-12-16 17:12:15,675 iteration 6471 : loss : 0.029842, loss_ce: 0.012889
2021-12-16 17:12:17,128 iteration 6472 : loss : 0.042122, loss_ce: 0.014962
2021-12-16 17:12:18,539 iteration 6473 : loss : 0.027139, loss_ce: 0.010646
2021-12-16 17:12:20,048 iteration 6474 : loss : 0.024651, loss_ce: 0.012445
2021-12-16 17:12:21,528 iteration 6475 : loss : 0.043342, loss_ce: 0.024501
2021-12-16 17:12:22,873 iteration 6476 : loss : 0.026070, loss_ce: 0.010900
2021-12-16 17:12:24,465 iteration 6477 : loss : 0.037282, loss_ce: 0.014969
 95%|███████████████████████████▌ | 381/400 [2:52:30<08:39, 27.36s/it]2021-12-16 17:12:25,996 iteration 6478 : loss : 0.043347, loss_ce: 0.017063
2021-12-16 17:12:27,404 iteration 6479 : loss : 0.034356, loss_ce: 0.013663
2021-12-16 17:12:28,824 iteration 6480 : loss : 0.030830, loss_ce: 0.015607
2021-12-16 17:12:30,294 iteration 6481 : loss : 0.042783, loss_ce: 0.022462
2021-12-16 17:12:31,717 iteration 6482 : loss : 0.030107, loss_ce: 0.012205
2021-12-16 17:12:33,212 iteration 6483 : loss : 0.046504, loss_ce: 0.013714
2021-12-16 17:12:34,635 iteration 6484 : loss : 0.035774, loss_ce: 0.016650
2021-12-16 17:12:36,084 iteration 6485 : loss : 0.033296, loss_ce: 0.014899
2021-12-16 17:12:37,586 iteration 6486 : loss : 0.028741, loss_ce: 0.012015
2021-12-16 17:12:39,130 iteration 6487 : loss : 0.049479, loss_ce: 0.022354
2021-12-16 17:12:40,602 iteration 6488 : loss : 0.045608, loss_ce: 0.017115
2021-12-16 17:12:42,007 iteration 6489 : loss : 0.024561, loss_ce: 0.012833
2021-12-16 17:12:43,472 iteration 6490 : loss : 0.030221, loss_ce: 0.010628
2021-12-16 17:12:44,904 iteration 6491 : loss : 0.037174, loss_ce: 0.015282
2021-12-16 17:12:46,432 iteration 6492 : loss : 0.039174, loss_ce: 0.016537
2021-12-16 17:12:47,891 iteration 6493 : loss : 0.052487, loss_ce: 0.020104
2021-12-16 17:12:49,234 iteration 6494 : loss : 0.019883, loss_ce: 0.009160
 96%|███████████████████████████▋ | 382/400 [2:52:55<07:58, 26.58s/it]2021-12-16 17:12:50,693 iteration 6495 : loss : 0.038336, loss_ce: 0.021202
2021-12-16 17:12:52,150 iteration 6496 : loss : 0.039469, loss_ce: 0.012570
2021-12-16 17:12:53,638 iteration 6497 : loss : 0.022432, loss_ce: 0.009767
2021-12-16 17:12:55,123 iteration 6498 : loss : 0.038770, loss_ce: 0.014776
2021-12-16 17:12:56,608 iteration 6499 : loss : 0.044510, loss_ce: 0.017770
2021-12-16 17:12:58,026 iteration 6500 : loss : 0.023926, loss_ce: 0.009688
2021-12-16 17:12:59,491 iteration 6501 : loss : 0.042680, loss_ce: 0.017098
2021-12-16 17:13:00,987 iteration 6502 : loss : 0.035285, loss_ce: 0.018641
2021-12-16 17:13:02,399 iteration 6503 : loss : 0.021018, loss_ce: 0.007666
2021-12-16 17:13:03,786 iteration 6504 : loss : 0.026721, loss_ce: 0.010433
2021-12-16 17:13:05,120 iteration 6505 : loss : 0.022265, loss_ce: 0.011900
2021-12-16 17:13:06,571 iteration 6506 : loss : 0.034719, loss_ce: 0.011005
2021-12-16 17:13:08,103 iteration 6507 : loss : 0.039046, loss_ce: 0.020273
2021-12-16 17:13:09,573 iteration 6508 : loss : 0.028522, loss_ce: 0.013266
2021-12-16 17:13:11,027 iteration 6509 : loss : 0.036352, loss_ce: 0.015475
2021-12-16 17:13:12,488 iteration 6510 : loss : 0.029963, loss_ce: 0.013706
2021-12-16 17:13:13,865 iteration 6511 : loss : 0.027079, loss_ce: 0.011970
 96%|███████████████████████████▊ | 383/400 [2:53:19<07:21, 26.00s/it]2021-12-16 17:13:15,320 iteration 6512 : loss : 0.032070, loss_ce: 0.012532
2021-12-16 17:13:16,777 iteration 6513 : loss : 0.035829, loss_ce: 0.014925
2021-12-16 17:13:18,325 iteration 6514 : loss : 0.029660, loss_ce: 0.010566
2021-12-16 17:13:19,817 iteration 6515 : loss : 0.035796, loss_ce: 0.014863
2021-12-16 17:13:21,281 iteration 6516 : loss : 0.039835, loss_ce: 0.018525
2021-12-16 17:13:22,714 iteration 6517 : loss : 0.067201, loss_ce: 0.013442
2021-12-16 17:13:24,166 iteration 6518 : loss : 0.026228, loss_ce: 0.010887
2021-12-16 17:13:25,615 iteration 6519 : loss : 0.031141, loss_ce: 0.011595
2021-12-16 17:13:27,116 iteration 6520 : loss : 0.047712, loss_ce: 0.017781
2021-12-16 17:13:28,533 iteration 6521 : loss : 0.039304, loss_ce: 0.019483
2021-12-16 17:13:29,986 iteration 6522 : loss : 0.020854, loss_ce: 0.009965
2021-12-16 17:13:31,353 iteration 6523 : loss : 0.021173, loss_ce: 0.010447
2021-12-16 17:13:32,856 iteration 6524 : loss : 0.043615, loss_ce: 0.023741
2021-12-16 17:13:34,323 iteration 6525 : loss : 0.031639, loss_ce: 0.014730
2021-12-16 17:13:35,776 iteration 6526 : loss : 0.031531, loss_ce: 0.013690
2021-12-16 17:13:37,149 iteration 6527 : loss : 0.026683, loss_ce: 0.012748
2021-12-16 17:13:38,569 iteration 6528 : loss : 0.026642, loss_ce: 0.009764
 96%|███████████████████████████▊ | 384/400 [2:53:44<06:49, 25.61s/it]2021-12-16 17:13:40,118 iteration 6529 : loss : 0.044007, loss_ce: 0.015912
2021-12-16 17:13:41,588 iteration 6530 : loss : 0.026755, loss_ce: 0.010823
2021-12-16 17:13:42,971 iteration 6531 : loss : 0.030542, loss_ce: 0.011102
2021-12-16 17:13:44,441 iteration 6532 : loss : 0.032191, loss_ce: 0.014061
2021-12-16 17:13:45,809 iteration 6533 : loss : 0.017268, loss_ce: 0.007931
2021-12-16 17:13:47,264 iteration 6534 : loss : 0.058074, loss_ce: 0.029661
2021-12-16 17:13:48,723 iteration 6535 : loss : 0.032438, loss_ce: 0.014576
2021-12-16 17:13:50,202 iteration 6536 : loss : 0.027609, loss_ce: 0.010947
2021-12-16 17:13:51,681 iteration 6537 : loss : 0.050374, loss_ce: 0.016099
2021-12-16 17:13:53,144 iteration 6538 : loss : 0.030952, loss_ce: 0.010619
2021-12-16 17:13:54,623 iteration 6539 : loss : 0.042270, loss_ce: 0.019080
2021-12-16 17:13:55,971 iteration 6540 : loss : 0.021973, loss_ce: 0.010780
2021-12-16 17:13:57,390 iteration 6541 : loss : 0.041050, loss_ce: 0.025673
2021-12-16 17:13:58,932 iteration 6542 : loss : 0.039059, loss_ce: 0.015909
2021-12-16 17:14:00,339 iteration 6543 : loss : 0.027681, loss_ce: 0.010033
2021-12-16 17:14:01,812 iteration 6544 : loss : 0.032819, loss_ce: 0.014464
2021-12-16 17:14:01,812 Training Data Eval:
2021-12-16 17:14:09,309   Average segmentation loss on training set: 0.0146
2021-12-16 17:14:09,310 Validation Data Eval:
2021-12-16 17:14:11,912   Average segmentation loss on validation set: 0.1058
2021-12-16 17:14:13,453 iteration 6545 : loss : 0.036297, loss_ce: 0.016684
 96%|███████████████████████████▉ | 385/400 [2:54:19<07:05, 28.39s/it]2021-12-16 17:14:15,086 iteration 6546 : loss : 0.035580, loss_ce: 0.016356
2021-12-16 17:14:16,550 iteration 6547 : loss : 0.038353, loss_ce: 0.018504
2021-12-16 17:14:18,024 iteration 6548 : loss : 0.029482, loss_ce: 0.011731
2021-12-16 17:14:19,455 iteration 6549 : loss : 0.032078, loss_ce: 0.013622
2021-12-16 17:14:20,954 iteration 6550 : loss : 0.034866, loss_ce: 0.014226
2021-12-16 17:14:22,462 iteration 6551 : loss : 0.048695, loss_ce: 0.021732
2021-12-16 17:14:24,025 iteration 6552 : loss : 0.042357, loss_ce: 0.020354
2021-12-16 17:14:25,628 iteration 6553 : loss : 0.045825, loss_ce: 0.015721
2021-12-16 17:14:27,099 iteration 6554 : loss : 0.035298, loss_ce: 0.013502
2021-12-16 17:14:28,545 iteration 6555 : loss : 0.022423, loss_ce: 0.010835
2021-12-16 17:14:29,978 iteration 6556 : loss : 0.039816, loss_ce: 0.011657
2021-12-16 17:14:31,313 iteration 6557 : loss : 0.019483, loss_ce: 0.009692
2021-12-16 17:14:32,797 iteration 6558 : loss : 0.030166, loss_ce: 0.010754
2021-12-16 17:14:34,177 iteration 6559 : loss : 0.023515, loss_ce: 0.009854
2021-12-16 17:14:35,641 iteration 6560 : loss : 0.031503, loss_ce: 0.016336
2021-12-16 17:14:37,152 iteration 6561 : loss : 0.030539, loss_ce: 0.010750
2021-12-16 17:14:38,576 iteration 6562 : loss : 0.030284, loss_ce: 0.013367
 96%|███████████████████████████▉ | 386/400 [2:54:44<06:23, 27.41s/it]2021-12-16 17:14:40,199 iteration 6563 : loss : 0.044797, loss_ce: 0.019675
2021-12-16 17:14:41,613 iteration 6564 : loss : 0.040688, loss_ce: 0.020756
2021-12-16 17:14:43,004 iteration 6565 : loss : 0.035578, loss_ce: 0.010455
2021-12-16 17:14:44,397 iteration 6566 : loss : 0.027064, loss_ce: 0.011473
2021-12-16 17:14:45,768 iteration 6567 : loss : 0.029029, loss_ce: 0.012944
2021-12-16 17:14:47,201 iteration 6568 : loss : 0.028105, loss_ce: 0.013677
2021-12-16 17:14:48,649 iteration 6569 : loss : 0.025624, loss_ce: 0.011912
2021-12-16 17:14:50,064 iteration 6570 : loss : 0.020904, loss_ce: 0.011081
2021-12-16 17:14:51,510 iteration 6571 : loss : 0.041523, loss_ce: 0.013744
2021-12-16 17:14:52,892 iteration 6572 : loss : 0.025950, loss_ce: 0.012324
2021-12-16 17:14:54,415 iteration 6573 : loss : 0.044667, loss_ce: 0.015985
2021-12-16 17:14:55,926 iteration 6574 : loss : 0.026930, loss_ce: 0.013334
2021-12-16 17:14:57,443 iteration 6575 : loss : 0.110483, loss_ce: 0.026584
2021-12-16 17:14:58,847 iteration 6576 : loss : 0.024064, loss_ce: 0.011493
2021-12-16 17:15:00,310 iteration 6577 : loss : 0.056692, loss_ce: 0.018415
2021-12-16 17:15:01,719 iteration 6578 : loss : 0.027104, loss_ce: 0.011650
2021-12-16 17:15:03,184 iteration 6579 : loss : 0.031342, loss_ce: 0.012512
 97%|████████████████████████████ | 387/400 [2:55:09<05:45, 26.57s/it]2021-12-16 17:15:04,679 iteration 6580 : loss : 0.046162, loss_ce: 0.017460
2021-12-16 17:15:06,094 iteration 6581 : loss : 0.031101, loss_ce: 0.011508
2021-12-16 17:15:07,606 iteration 6582 : loss : 0.033420, loss_ce: 0.012715
2021-12-16 17:15:09,063 iteration 6583 : loss : 0.030995, loss_ce: 0.014598
2021-12-16 17:15:10,538 iteration 6584 : loss : 0.032722, loss_ce: 0.015789
2021-12-16 17:15:12,034 iteration 6585 : loss : 0.046971, loss_ce: 0.017581
2021-12-16 17:15:13,505 iteration 6586 : loss : 0.040372, loss_ce: 0.013940
2021-12-16 17:15:14,943 iteration 6587 : loss : 0.024247, loss_ce: 0.011033
2021-12-16 17:15:16,403 iteration 6588 : loss : 0.034226, loss_ce: 0.015361
2021-12-16 17:15:17,804 iteration 6589 : loss : 0.045738, loss_ce: 0.023347
2021-12-16 17:15:19,317 iteration 6590 : loss : 0.047829, loss_ce: 0.028072
2021-12-16 17:15:20,817 iteration 6591 : loss : 0.039873, loss_ce: 0.016712
2021-12-16 17:15:22,225 iteration 6592 : loss : 0.023963, loss_ce: 0.010979
2021-12-16 17:15:23,742 iteration 6593 : loss : 0.061664, loss_ce: 0.016044
2021-12-16 17:15:25,177 iteration 6594 : loss : 0.033386, loss_ce: 0.019259
2021-12-16 17:15:26,592 iteration 6595 : loss : 0.027543, loss_ce: 0.011641
2021-12-16 17:15:28,100 iteration 6596 : loss : 0.046622, loss_ce: 0.016880
 97%|████████████████████████████▏| 388/400 [2:55:33<05:12, 26.07s/it]2021-12-16 17:15:29,592 iteration 6597 : loss : 0.034409, loss_ce: 0.019140
2021-12-16 17:15:30,994 iteration 6598 : loss : 0.040011, loss_ce: 0.011434
2021-12-16 17:15:32,467 iteration 6599 : loss : 0.029853, loss_ce: 0.013440
2021-12-16 17:15:33,814 iteration 6600 : loss : 0.020542, loss_ce: 0.010683
2021-12-16 17:15:35,271 iteration 6601 : loss : 0.028359, loss_ce: 0.011157
2021-12-16 17:15:36,689 iteration 6602 : loss : 0.037471, loss_ce: 0.016344
2021-12-16 17:15:38,156 iteration 6603 : loss : 0.037833, loss_ce: 0.015743
2021-12-16 17:15:39,529 iteration 6604 : loss : 0.018017, loss_ce: 0.008742
2021-12-16 17:15:40,983 iteration 6605 : loss : 0.022247, loss_ce: 0.009615
2021-12-16 17:15:42,454 iteration 6606 : loss : 0.038457, loss_ce: 0.020789
2021-12-16 17:15:43,938 iteration 6607 : loss : 0.037935, loss_ce: 0.016358
2021-12-16 17:15:45,413 iteration 6608 : loss : 0.028252, loss_ce: 0.013109
2021-12-16 17:15:46,823 iteration 6609 : loss : 0.027739, loss_ce: 0.011174
2021-12-16 17:15:48,252 iteration 6610 : loss : 0.032931, loss_ce: 0.015311
2021-12-16 17:15:49,674 iteration 6611 : loss : 0.025504, loss_ce: 0.008607
2021-12-16 17:15:51,154 iteration 6612 : loss : 0.042359, loss_ce: 0.018099
2021-12-16 17:15:52,487 iteration 6613 : loss : 0.026581, loss_ce: 0.012457
 97%|████████████████████████████▏| 389/400 [2:55:58<04:41, 25.57s/it]2021-12-16 17:15:53,998 iteration 6614 : loss : 0.034274, loss_ce: 0.013243
2021-12-16 17:15:55,451 iteration 6615 : loss : 0.025495, loss_ce: 0.012980
2021-12-16 17:15:56,859 iteration 6616 : loss : 0.041265, loss_ce: 0.013289
2021-12-16 17:15:58,421 iteration 6617 : loss : 0.040748, loss_ce: 0.015160
2021-12-16 17:15:59,894 iteration 6618 : loss : 0.034086, loss_ce: 0.011753
2021-12-16 17:16:01,424 iteration 6619 : loss : 0.046613, loss_ce: 0.023946
2021-12-16 17:16:02,920 iteration 6620 : loss : 0.048209, loss_ce: 0.024128
2021-12-16 17:16:04,375 iteration 6621 : loss : 0.032318, loss_ce: 0.011352
2021-12-16 17:16:05,823 iteration 6622 : loss : 0.043682, loss_ce: 0.022713
2021-12-16 17:16:07,279 iteration 6623 : loss : 0.042886, loss_ce: 0.016833
2021-12-16 17:16:08,772 iteration 6624 : loss : 0.058852, loss_ce: 0.025970
2021-12-16 17:16:10,276 iteration 6625 : loss : 0.028463, loss_ce: 0.012456
2021-12-16 17:16:11,716 iteration 6626 : loss : 0.063591, loss_ce: 0.020235
2021-12-16 17:16:13,085 iteration 6627 : loss : 0.030286, loss_ce: 0.011860
2021-12-16 17:16:14,512 iteration 6628 : loss : 0.031054, loss_ce: 0.017154
2021-12-16 17:16:15,938 iteration 6629 : loss : 0.025753, loss_ce: 0.014372
2021-12-16 17:16:15,938 Training Data Eval:
2021-12-16 17:16:23,429   Average segmentation loss on training set: 0.0144
2021-12-16 17:16:23,429 Validation Data Eval:
2021-12-16 17:16:26,028   Average segmentation loss on validation set: 0.0982
2021-12-16 17:16:27,533 iteration 6630 : loss : 0.035655, loss_ce: 0.013524
 98%|████████████████████████████▎| 390/400 [2:56:33<04:44, 28.41s/it]2021-12-16 17:16:29,115 iteration 6631 : loss : 0.043284, loss_ce: 0.015704
2021-12-16 17:16:30,586 iteration 6632 : loss : 0.031290, loss_ce: 0.014978
2021-12-16 17:16:32,052 iteration 6633 : loss : 0.034346, loss_ce: 0.011484
2021-12-16 17:16:33,389 iteration 6634 : loss : 0.024818, loss_ce: 0.008972
2021-12-16 17:16:34,806 iteration 6635 : loss : 0.038593, loss_ce: 0.011140
2021-12-16 17:16:36,318 iteration 6636 : loss : 0.026551, loss_ce: 0.012669
2021-12-16 17:16:37,809 iteration 6637 : loss : 0.035393, loss_ce: 0.018459
2021-12-16 17:16:39,311 iteration 6638 : loss : 0.041484, loss_ce: 0.017896
2021-12-16 17:16:40,858 iteration 6639 : loss : 0.040617, loss_ce: 0.016020
2021-12-16 17:16:42,280 iteration 6640 : loss : 0.029683, loss_ce: 0.010679
2021-12-16 17:16:43,693 iteration 6641 : loss : 0.031704, loss_ce: 0.019247
2021-12-16 17:16:45,227 iteration 6642 : loss : 0.031517, loss_ce: 0.015206
2021-12-16 17:16:46,699 iteration 6643 : loss : 0.041213, loss_ce: 0.021066
2021-12-16 17:16:48,149 iteration 6644 : loss : 0.028922, loss_ce: 0.010635
2021-12-16 17:16:49,544 iteration 6645 : loss : 0.025721, loss_ce: 0.011125
2021-12-16 17:16:50,971 iteration 6646 : loss : 0.030490, loss_ce: 0.014571
2021-12-16 17:16:52,342 iteration 6647 : loss : 0.026899, loss_ce: 0.010249
 98%|████████████████████████████▎| 391/400 [2:56:58<04:05, 27.33s/it]2021-12-16 17:16:53,798 iteration 6648 : loss : 0.031330, loss_ce: 0.011226
2021-12-16 17:16:55,309 iteration 6649 : loss : 0.042482, loss_ce: 0.019101
2021-12-16 17:16:56,720 iteration 6650 : loss : 0.035813, loss_ce: 0.013982
2021-12-16 17:16:58,128 iteration 6651 : loss : 0.023488, loss_ce: 0.010689
2021-12-16 17:16:59,649 iteration 6652 : loss : 0.046910, loss_ce: 0.021285
2021-12-16 17:17:01,158 iteration 6653 : loss : 0.036857, loss_ce: 0.017656
2021-12-16 17:17:02,556 iteration 6654 : loss : 0.022417, loss_ce: 0.009821
2021-12-16 17:17:04,046 iteration 6655 : loss : 0.030350, loss_ce: 0.012994
2021-12-16 17:17:05,524 iteration 6656 : loss : 0.026736, loss_ce: 0.012540
2021-12-16 17:17:07,065 iteration 6657 : loss : 0.044488, loss_ce: 0.019423
2021-12-16 17:17:08,516 iteration 6658 : loss : 0.047386, loss_ce: 0.021799
2021-12-16 17:17:09,998 iteration 6659 : loss : 0.036066, loss_ce: 0.014464
2021-12-16 17:17:11,405 iteration 6660 : loss : 0.025762, loss_ce: 0.011194
2021-12-16 17:17:12,783 iteration 6661 : loss : 0.020067, loss_ce: 0.009197
2021-12-16 17:17:14,270 iteration 6662 : loss : 0.029827, loss_ce: 0.012190
2021-12-16 17:17:15,771 iteration 6663 : loss : 0.039704, loss_ce: 0.016242
2021-12-16 17:17:17,197 iteration 6664 : loss : 0.034531, loss_ce: 0.013115
 98%|████████████████████████████▍| 392/400 [2:57:23<03:32, 26.59s/it]2021-12-16 17:17:18,711 iteration 6665 : loss : 0.040331, loss_ce: 0.016981
2021-12-16 17:17:20,193 iteration 6666 : loss : 0.030144, loss_ce: 0.013371
2021-12-16 17:17:21,620 iteration 6667 : loss : 0.031322, loss_ce: 0.012869
2021-12-16 17:17:22,976 iteration 6668 : loss : 0.017919, loss_ce: 0.009176
2021-12-16 17:17:24,460 iteration 6669 : loss : 0.030932, loss_ce: 0.012278
2021-12-16 17:17:25,856 iteration 6670 : loss : 0.033676, loss_ce: 0.012769
2021-12-16 17:17:27,409 iteration 6671 : loss : 0.034061, loss_ce: 0.015176
2021-12-16 17:17:28,838 iteration 6672 : loss : 0.032904, loss_ce: 0.019370
2021-12-16 17:17:30,343 iteration 6673 : loss : 0.030725, loss_ce: 0.015054
2021-12-16 17:17:31,837 iteration 6674 : loss : 0.036530, loss_ce: 0.015935
2021-12-16 17:17:33,237 iteration 6675 : loss : 0.029836, loss_ce: 0.010874
2021-12-16 17:17:34,621 iteration 6676 : loss : 0.021769, loss_ce: 0.008743
2021-12-16 17:17:36,086 iteration 6677 : loss : 0.024726, loss_ce: 0.007682
2021-12-16 17:17:37,627 iteration 6678 : loss : 0.032542, loss_ce: 0.015914
2021-12-16 17:17:39,089 iteration 6679 : loss : 0.032730, loss_ce: 0.012516
2021-12-16 17:17:40,522 iteration 6680 : loss : 0.040088, loss_ce: 0.017922
2021-12-16 17:17:41,931 iteration 6681 : loss : 0.034118, loss_ce: 0.013555
 98%|████████████████████████████▍| 393/400 [2:57:47<03:02, 26.03s/it]2021-12-16 17:17:43,426 iteration 6682 : loss : 0.031407, loss_ce: 0.011874
2021-12-16 17:17:44,911 iteration 6683 : loss : 0.031408, loss_ce: 0.012252
2021-12-16 17:17:46,380 iteration 6684 : loss : 0.088910, loss_ce: 0.011754
2021-12-16 17:17:47,821 iteration 6685 : loss : 0.031657, loss_ce: 0.013754
2021-12-16 17:17:49,291 iteration 6686 : loss : 0.032462, loss_ce: 0.012372
2021-12-16 17:17:50,757 iteration 6687 : loss : 0.041714, loss_ce: 0.018453
2021-12-16 17:17:52,218 iteration 6688 : loss : 0.031293, loss_ce: 0.012902
2021-12-16 17:17:53,641 iteration 6689 : loss : 0.034324, loss_ce: 0.016238
2021-12-16 17:17:55,157 iteration 6690 : loss : 0.033141, loss_ce: 0.014875
2021-12-16 17:17:56,556 iteration 6691 : loss : 0.027376, loss_ce: 0.011997
2021-12-16 17:17:57,953 iteration 6692 : loss : 0.028305, loss_ce: 0.018489
2021-12-16 17:17:59,400 iteration 6693 : loss : 0.025643, loss_ce: 0.012660
2021-12-16 17:18:00,769 iteration 6694 : loss : 0.019920, loss_ce: 0.009915
2021-12-16 17:18:02,176 iteration 6695 : loss : 0.024338, loss_ce: 0.009251
2021-12-16 17:18:03,608 iteration 6696 : loss : 0.035862, loss_ce: 0.022220
2021-12-16 17:18:05,065 iteration 6697 : loss : 0.026918, loss_ce: 0.011093
2021-12-16 17:18:06,427 iteration 6698 : loss : 0.031468, loss_ce: 0.011859
 98%|████████████████████████████▌| 394/400 [2:58:12<02:33, 25.57s/it]2021-12-16 17:18:07,933 iteration 6699 : loss : 0.039498, loss_ce: 0.013506
2021-12-16 17:18:09,445 iteration 6700 : loss : 0.055040, loss_ce: 0.029235
2021-12-16 17:18:10,981 iteration 6701 : loss : 0.054981, loss_ce: 0.023512
2021-12-16 17:18:12,383 iteration 6702 : loss : 0.034259, loss_ce: 0.011962
2021-12-16 17:18:13,920 iteration 6703 : loss : 0.030454, loss_ce: 0.012624
2021-12-16 17:18:15,370 iteration 6704 : loss : 0.033390, loss_ce: 0.018631
2021-12-16 17:18:16,766 iteration 6705 : loss : 0.022833, loss_ce: 0.009208
2021-12-16 17:18:18,185 iteration 6706 : loss : 0.035296, loss_ce: 0.015877
2021-12-16 17:18:19,632 iteration 6707 : loss : 0.028428, loss_ce: 0.011437
2021-12-16 17:18:21,002 iteration 6708 : loss : 0.029360, loss_ce: 0.009863
2021-12-16 17:18:22,407 iteration 6709 : loss : 0.028653, loss_ce: 0.009877
2021-12-16 17:18:23,876 iteration 6710 : loss : 0.046840, loss_ce: 0.021214
2021-12-16 17:18:25,321 iteration 6711 : loss : 0.029197, loss_ce: 0.014877
2021-12-16 17:18:26,802 iteration 6712 : loss : 0.031368, loss_ce: 0.013917
2021-12-16 17:18:28,203 iteration 6713 : loss : 0.031588, loss_ce: 0.011384
2021-12-16 17:18:29,632 iteration 6714 : loss : 0.034315, loss_ce: 0.015649
2021-12-16 17:18:29,633 Training Data Eval:
2021-12-16 17:18:37,113   Average segmentation loss on training set: 0.0147
2021-12-16 17:18:37,114 Validation Data Eval:
2021-12-16 17:18:39,706   Average segmentation loss on validation set: 0.0973
2021-12-16 17:18:41,132 iteration 6715 : loss : 0.022585, loss_ce: 0.008770
 99%|████████████████████████████▋| 395/400 [2:58:46<02:21, 28.31s/it]2021-12-16 17:18:42,557 iteration 6716 : loss : 0.023290, loss_ce: 0.009087
2021-12-16 17:18:44,041 iteration 6717 : loss : 0.033248, loss_ce: 0.012793
2021-12-16 17:18:45,553 iteration 6718 : loss : 0.061630, loss_ce: 0.031134
2021-12-16 17:18:47,041 iteration 6719 : loss : 0.071063, loss_ce: 0.027232
2021-12-16 17:18:48,505 iteration 6720 : loss : 0.062894, loss_ce: 0.013216
2021-12-16 17:18:49,996 iteration 6721 : loss : 0.045277, loss_ce: 0.021266
2021-12-16 17:18:51,448 iteration 6722 : loss : 0.032518, loss_ce: 0.016825
2021-12-16 17:18:52,923 iteration 6723 : loss : 0.036154, loss_ce: 0.016462
2021-12-16 17:18:54,328 iteration 6724 : loss : 0.027604, loss_ce: 0.012108
2021-12-16 17:18:55,778 iteration 6725 : loss : 0.027624, loss_ce: 0.010942
2021-12-16 17:18:57,150 iteration 6726 : loss : 0.022856, loss_ce: 0.009309
2021-12-16 17:18:58,691 iteration 6727 : loss : 0.048983, loss_ce: 0.020214
2021-12-16 17:19:00,093 iteration 6728 : loss : 0.036206, loss_ce: 0.017321
2021-12-16 17:19:01,577 iteration 6729 : loss : 0.039270, loss_ce: 0.014987
2021-12-16 17:19:03,101 iteration 6730 : loss : 0.036876, loss_ce: 0.017327
2021-12-16 17:19:04,586 iteration 6731 : loss : 0.039907, loss_ce: 0.014459
2021-12-16 17:19:06,036 iteration 6732 : loss : 0.026960, loss_ce: 0.015046
 99%|████████████████████████████▋| 396/400 [2:59:11<01:49, 27.29s/it]2021-12-16 17:19:07,482 iteration 6733 : loss : 0.020797, loss_ce: 0.010184
2021-12-16 17:19:08,930 iteration 6734 : loss : 0.031623, loss_ce: 0.010302
2021-12-16 17:19:10,409 iteration 6735 : loss : 0.046962, loss_ce: 0.017458
2021-12-16 17:19:11,832 iteration 6736 : loss : 0.039188, loss_ce: 0.020615
2021-12-16 17:19:13,207 iteration 6737 : loss : 0.032941, loss_ce: 0.018560
2021-12-16 17:19:14,572 iteration 6738 : loss : 0.027298, loss_ce: 0.009541
2021-12-16 17:19:16,021 iteration 6739 : loss : 0.027663, loss_ce: 0.013143
2021-12-16 17:19:17,521 iteration 6740 : loss : 0.044144, loss_ce: 0.016318
2021-12-16 17:19:18,988 iteration 6741 : loss : 0.032462, loss_ce: 0.014138
2021-12-16 17:19:20,408 iteration 6742 : loss : 0.025496, loss_ce: 0.013195
2021-12-16 17:19:21,802 iteration 6743 : loss : 0.025246, loss_ce: 0.007848
2021-12-16 17:19:23,293 iteration 6744 : loss : 0.047640, loss_ce: 0.018705
2021-12-16 17:19:24,720 iteration 6745 : loss : 0.029918, loss_ce: 0.014668
2021-12-16 17:19:26,104 iteration 6746 : loss : 0.018494, loss_ce: 0.006583
2021-12-16 17:19:27,530 iteration 6747 : loss : 0.033839, loss_ce: 0.014481
2021-12-16 17:19:29,002 iteration 6748 : loss : 0.023429, loss_ce: 0.011606
2021-12-16 17:19:30,436 iteration 6749 : loss : 0.027515, loss_ce: 0.009504
 99%|████████████████████████████▊| 397/400 [2:59:36<01:19, 26.42s/it]2021-12-16 17:19:31,904 iteration 6750 : loss : 0.024720, loss_ce: 0.012417
2021-12-16 17:19:33,396 iteration 6751 : loss : 0.024608, loss_ce: 0.011604
2021-12-16 17:19:34,750 iteration 6752 : loss : 0.021660, loss_ce: 0.008990
2021-12-16 17:19:36,193 iteration 6753 : loss : 0.032830, loss_ce: 0.016434
2021-12-16 17:19:37,664 iteration 6754 : loss : 0.042780, loss_ce: 0.018056
2021-12-16 17:19:39,075 iteration 6755 : loss : 0.028692, loss_ce: 0.010537
2021-12-16 17:19:40,496 iteration 6756 : loss : 0.029874, loss_ce: 0.014042
2021-12-16 17:19:42,015 iteration 6757 : loss : 0.042169, loss_ce: 0.017926
2021-12-16 17:19:43,423 iteration 6758 : loss : 0.033538, loss_ce: 0.017702
2021-12-16 17:19:44,889 iteration 6759 : loss : 0.027329, loss_ce: 0.012915
2021-12-16 17:19:46,396 iteration 6760 : loss : 0.056132, loss_ce: 0.011662
2021-12-16 17:19:47,830 iteration 6761 : loss : 0.039866, loss_ce: 0.018136
2021-12-16 17:19:49,248 iteration 6762 : loss : 0.041028, loss_ce: 0.014804
2021-12-16 17:19:50,743 iteration 6763 : loss : 0.057523, loss_ce: 0.030377
2021-12-16 17:19:52,148 iteration 6764 : loss : 0.044999, loss_ce: 0.018748
2021-12-16 17:19:53,646 iteration 6765 : loss : 0.040499, loss_ce: 0.016270
2021-12-16 17:19:55,057 iteration 6766 : loss : 0.030781, loss_ce: 0.017080
100%|████████████████████████████▊| 398/400 [3:00:00<00:51, 25.88s/it]2021-12-16 17:19:56,542 iteration 6767 : loss : 0.034776, loss_ce: 0.015104
2021-12-16 17:19:58,086 iteration 6768 : loss : 0.027208, loss_ce: 0.011161
2021-12-16 17:19:59,524 iteration 6769 : loss : 0.032969, loss_ce: 0.016104
2021-12-16 17:20:00,932 iteration 6770 : loss : 0.029701, loss_ce: 0.016463
2021-12-16 17:20:02,471 iteration 6771 : loss : 0.076694, loss_ce: 0.021811
2021-12-16 17:20:03,891 iteration 6772 : loss : 0.030304, loss_ce: 0.011816
2021-12-16 17:20:05,208 iteration 6773 : loss : 0.028156, loss_ce: 0.011164
2021-12-16 17:20:06,704 iteration 6774 : loss : 0.054163, loss_ce: 0.017914
2021-12-16 17:20:08,176 iteration 6775 : loss : 0.052649, loss_ce: 0.021042
2021-12-16 17:20:09,589 iteration 6776 : loss : 0.048098, loss_ce: 0.018315
2021-12-16 17:20:11,093 iteration 6777 : loss : 0.038700, loss_ce: 0.019497
2021-12-16 17:20:12,557 iteration 6778 : loss : 0.030292, loss_ce: 0.011687
2021-12-16 17:20:14,092 iteration 6779 : loss : 0.034981, loss_ce: 0.015847
2021-12-16 17:20:15,562 iteration 6780 : loss : 0.026753, loss_ce: 0.012933
2021-12-16 17:20:17,060 iteration 6781 : loss : 0.030611, loss_ce: 0.015380
2021-12-16 17:20:18,567 iteration 6782 : loss : 0.032615, loss_ce: 0.013812
2021-12-16 17:20:19,985 iteration 6783 : loss : 0.030947, loss_ce: 0.012565
100%|████████████████████████████▉| 399/400 [3:00:25<00:25, 25.59s/it]2021-12-16 17:20:21,548 iteration 6784 : loss : 0.035951, loss_ce: 0.012560
2021-12-16 17:20:23,025 iteration 6785 : loss : 0.038340, loss_ce: 0.014953
2021-12-16 17:20:24,426 iteration 6786 : loss : 0.026052, loss_ce: 0.012974
2021-12-16 17:20:25,847 iteration 6787 : loss : 0.026674, loss_ce: 0.010648
2021-12-16 17:20:27,320 iteration 6788 : loss : 0.041655, loss_ce: 0.017939
2021-12-16 17:20:28,762 iteration 6789 : loss : 0.028535, loss_ce: 0.010196
2021-12-16 17:20:30,173 iteration 6790 : loss : 0.036158, loss_ce: 0.018309
2021-12-16 17:20:31,637 iteration 6791 : loss : 0.032899, loss_ce: 0.012922
2021-12-16 17:20:33,023 iteration 6792 : loss : 0.026185, loss_ce: 0.012274
2021-12-16 17:20:34,543 iteration 6793 : loss : 0.051686, loss_ce: 0.019745
2021-12-16 17:20:35,994 iteration 6794 : loss : 0.058889, loss_ce: 0.021752
2021-12-16 17:20:37,477 iteration 6795 : loss : 0.032341, loss_ce: 0.012681
2021-12-16 17:20:38,982 iteration 6796 : loss : 0.031227, loss_ce: 0.018729
2021-12-16 17:20:40,360 iteration 6797 : loss : 0.030628, loss_ce: 0.013461
2021-12-16 17:20:41,854 iteration 6798 : loss : 0.037307, loss_ce: 0.013533
2021-12-16 17:20:43,407 iteration 6799 : loss : 0.032247, loss_ce: 0.016167
2021-12-16 17:20:43,407 Training Data Eval:
2021-12-16 17:20:50,878   Average segmentation loss on training set: 0.0144
2021-12-16 17:20:50,878 Validation Data Eval:
2021-12-16 17:20:53,472   Average segmentation loss on validation set: 0.0962
2021-12-16 17:20:54,890 iteration 6800 : loss : 0.023211, loss_ce: 0.007872
100%|█████████████████████████████| 400/400 [3:01:00<00:00, 28.39s/it]100%|█████████████████████████████| 400/400 [3:01:00<00:00, 27.15s/it]
