2021-12-17 15:43:48,052 Logging directory: /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/TransUNet/log_dir/trRUNMC_cv1_r3/i2i2l/
2021-12-17 15:43:48,053 Tensorboard directory: /scratch_net/biwidl217_second/arismu/Tensorboard/trRUNMC_cv1_r3/i2i2l/
2021-12-17 15:43:48,053 ============================================================
2021-12-17 15:43:48,053 EXPERIMENT NAME: trRUNMC_cv1_r3/i2i2l/
2021-12-17 15:43:48,053 ============================================================
2021-12-17 15:43:48,053 Loading data...
2021-12-17 15:43:48,053 Reading NCI - RUNMC images...
2021-12-17 15:43:48,053 Data root directory: /itet-stor/arismu/bmicdatasets-originals/Originals/Challenge_Datasets/NCI_Prostate/
2021-12-17 15:43:48,054 Already preprocessed this configuration. Loading now!
2021-12-17 15:43:48,078 Training Images: (256, 256, 286)
2021-12-17 15:43:48,078 Training Labels: (256, 256, 286)
2021-12-17 15:43:48,078 Validation Images: (256, 256, 98)
2021-12-17 15:43:48,078 Validation Labels: (256, 256, 98)
2021-12-17 15:43:48,078 ============================================================
2021-12-17 15:43:48,117 17 iterations per epoch. 6800 max iterations 
  0%|                                         | 0/400 [00:00<?, ?it/s]2021-12-17 15:43:50,586 iteration 1 : loss : 1.072505, loss_ce: 1.369662
2021-12-17 15:43:51,928 iteration 2 : loss : 1.058964, loss_ce: 1.355542
2021-12-17 15:43:53,348 iteration 3 : loss : 1.047074, loss_ce: 1.338003
2021-12-17 15:43:54,713 iteration 4 : loss : 1.047646, loss_ce: 1.314446
2021-12-17 15:43:55,995 iteration 5 : loss : 1.035555, loss_ce: 1.283122
2021-12-17 15:43:57,341 iteration 6 : loss : 1.013279, loss_ce: 1.247911
2021-12-17 15:43:58,721 iteration 7 : loss : 0.984404, loss_ce: 1.206465
2021-12-17 15:44:00,162 iteration 8 : loss : 0.960833, loss_ce: 1.163658
2021-12-17 15:44:01,461 iteration 9 : loss : 0.941819, loss_ce: 1.117017
2021-12-17 15:44:02,760 iteration 10 : loss : 0.905942, loss_ce: 1.067957
2021-12-17 15:44:04,050 iteration 11 : loss : 0.878836, loss_ce: 1.015080
2021-12-17 15:44:05,393 iteration 12 : loss : 0.843337, loss_ce: 0.968476
2021-12-17 15:44:06,799 iteration 13 : loss : 0.811274, loss_ce: 0.927799
2021-12-17 15:44:08,094 iteration 14 : loss : 0.785924, loss_ce: 0.877003
2021-12-17 15:44:09,491 iteration 15 : loss : 0.761683, loss_ce: 0.825619
2021-12-17 15:44:10,831 iteration 16 : loss : 0.733768, loss_ce: 0.780708
2021-12-17 15:44:12,160 iteration 17 : loss : 0.704166, loss_ce: 0.749775
  0%|                               | 1/400 [00:24<2:40:17, 24.10s/it]2021-12-17 15:44:13,543 iteration 18 : loss : 0.686245, loss_ce: 0.697442
2021-12-17 15:44:14,906 iteration 19 : loss : 0.663322, loss_ce: 0.663235
2021-12-17 15:44:16,253 iteration 20 : loss : 0.636251, loss_ce: 0.626009
2021-12-17 15:44:17,679 iteration 21 : loss : 0.623413, loss_ce: 0.599744
2021-12-17 15:44:19,021 iteration 22 : loss : 0.604018, loss_ce: 0.572078
2021-12-17 15:44:20,389 iteration 23 : loss : 0.589189, loss_ce: 0.534401
2021-12-17 15:44:21,689 iteration 24 : loss : 0.568821, loss_ce: 0.519370
2021-12-17 15:44:22,945 iteration 25 : loss : 0.555107, loss_ce: 0.482842
2021-12-17 15:44:24,243 iteration 26 : loss : 0.547167, loss_ce: 0.458254
2021-12-17 15:44:25,597 iteration 27 : loss : 0.532530, loss_ce: 0.452558
2021-12-17 15:44:26,933 iteration 28 : loss : 0.525280, loss_ce: 0.422567
2021-12-17 15:44:28,425 iteration 29 : loss : 0.516345, loss_ce: 0.423427
2021-12-17 15:44:29,825 iteration 30 : loss : 0.502641, loss_ce: 0.389775
2021-12-17 15:44:31,130 iteration 31 : loss : 0.497464, loss_ce: 0.393411
2021-12-17 15:44:32,462 iteration 32 : loss : 0.484350, loss_ce: 0.369301
2021-12-17 15:44:33,893 iteration 33 : loss : 0.489104, loss_ce: 0.376902
2021-12-17 15:44:35,220 iteration 34 : loss : 0.471441, loss_ce: 0.325807
  0%|▏                              | 2/400 [00:47<2:35:43, 23.48s/it]2021-12-17 15:44:36,669 iteration 35 : loss : 0.478798, loss_ce: 0.366486
2021-12-17 15:44:38,040 iteration 36 : loss : 0.462335, loss_ce: 0.328509
2021-12-17 15:44:39,449 iteration 37 : loss : 0.468554, loss_ce: 0.345707
2021-12-17 15:44:40,925 iteration 38 : loss : 0.454562, loss_ce: 0.299998
2021-12-17 15:44:42,298 iteration 39 : loss : 0.444396, loss_ce: 0.280480
2021-12-17 15:44:43,716 iteration 40 : loss : 0.459449, loss_ce: 0.330739
2021-12-17 15:44:45,030 iteration 41 : loss : 0.442436, loss_ce: 0.278193
2021-12-17 15:44:46,535 iteration 42 : loss : 0.445441, loss_ce: 0.295164
2021-12-17 15:44:47,848 iteration 43 : loss : 0.430583, loss_ce: 0.251909
2021-12-17 15:44:49,244 iteration 44 : loss : 0.430002, loss_ce: 0.262363
2021-12-17 15:44:50,662 iteration 45 : loss : 0.429288, loss_ce: 0.249731
2021-12-17 15:44:51,943 iteration 46 : loss : 0.426138, loss_ce: 0.252671
2021-12-17 15:44:53,296 iteration 47 : loss : 0.418828, loss_ce: 0.225968
2021-12-17 15:44:54,696 iteration 48 : loss : 0.435494, loss_ce: 0.279842
2021-12-17 15:44:56,084 iteration 49 : loss : 0.414258, loss_ce: 0.226158
2021-12-17 15:44:57,497 iteration 50 : loss : 0.417512, loss_ce: 0.231412
2021-12-17 15:44:58,880 iteration 51 : loss : 0.430381, loss_ce: 0.269356
  1%|▏                              | 3/400 [01:10<2:35:53, 23.56s/it]2021-12-17 15:45:00,200 iteration 52 : loss : 0.424820, loss_ce: 0.253916
2021-12-17 15:45:01,481 iteration 53 : loss : 0.420582, loss_ce: 0.252404
2021-12-17 15:45:02,892 iteration 54 : loss : 0.417105, loss_ce: 0.244553
2021-12-17 15:45:04,327 iteration 55 : loss : 0.409673, loss_ce: 0.221510
2021-12-17 15:45:05,806 iteration 56 : loss : 0.404482, loss_ce: 0.214673
2021-12-17 15:45:07,291 iteration 57 : loss : 0.405673, loss_ce: 0.207072
2021-12-17 15:45:08,757 iteration 58 : loss : 0.414014, loss_ce: 0.234556
2021-12-17 15:45:10,181 iteration 59 : loss : 0.410040, loss_ce: 0.216556
2021-12-17 15:45:11,674 iteration 60 : loss : 0.402177, loss_ce: 0.207925
2021-12-17 15:45:13,176 iteration 61 : loss : 0.411769, loss_ce: 0.234013
2021-12-17 15:45:14,606 iteration 62 : loss : 0.415849, loss_ce: 0.228790
2021-12-17 15:45:15,968 iteration 63 : loss : 0.416924, loss_ce: 0.248935
2021-12-17 15:45:17,394 iteration 64 : loss : 0.418976, loss_ce: 0.247870
2021-12-17 15:45:18,822 iteration 65 : loss : 0.395371, loss_ce: 0.193851
2021-12-17 15:45:20,309 iteration 66 : loss : 0.396050, loss_ce: 0.197760
2021-12-17 15:45:21,688 iteration 67 : loss : 0.408425, loss_ce: 0.224400
2021-12-17 15:45:23,109 iteration 68 : loss : 0.394813, loss_ce: 0.184084
  1%|▎                              | 4/400 [01:35<2:37:15, 23.83s/it]2021-12-17 15:45:24,565 iteration 69 : loss : 0.394725, loss_ce: 0.184511
2021-12-17 15:45:26,005 iteration 70 : loss : 0.408150, loss_ce: 0.219320
2021-12-17 15:45:27,397 iteration 71 : loss : 0.395985, loss_ce: 0.207125
2021-12-17 15:45:28,891 iteration 72 : loss : 0.404097, loss_ce: 0.206054
2021-12-17 15:45:30,325 iteration 73 : loss : 0.410170, loss_ce: 0.229133
2021-12-17 15:45:31,837 iteration 74 : loss : 0.403792, loss_ce: 0.212215
2021-12-17 15:45:33,280 iteration 75 : loss : 0.414167, loss_ce: 0.238355
2021-12-17 15:45:34,770 iteration 76 : loss : 0.403954, loss_ce: 0.213307
2021-12-17 15:45:36,298 iteration 77 : loss : 0.393760, loss_ce: 0.190932
2021-12-17 15:45:37,790 iteration 78 : loss : 0.411087, loss_ce: 0.236856
2021-12-17 15:45:39,179 iteration 79 : loss : 0.393615, loss_ce: 0.193817
2021-12-17 15:45:40,667 iteration 80 : loss : 0.384016, loss_ce: 0.164151
2021-12-17 15:45:42,079 iteration 81 : loss : 0.389412, loss_ce: 0.188401
2021-12-17 15:45:43,490 iteration 82 : loss : 0.405469, loss_ce: 0.220544
2021-12-17 15:45:44,979 iteration 83 : loss : 0.388860, loss_ce: 0.184389
2021-12-17 15:45:46,396 iteration 84 : loss : 0.399613, loss_ce: 0.206691
2021-12-17 15:45:46,396 Training Data Eval:
2021-12-17 15:45:53,848   Average segmentation loss on training set: 0.3909
2021-12-17 15:45:53,848 Validation Data Eval:
2021-12-17 15:45:56,573   Average segmentation loss on validation set: 0.4257
2021-12-17 15:46:04,408 Found new lowest validation loss at iteration 84! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/TU_3seeds/TU_RESNET_no_pretraining_SGD_best_val_loss_seed2.pth
2021-12-17 15:46:05,836 iteration 85 : loss : 0.403591, loss_ce: 0.216125
  1%|▍                              | 5/400 [02:17<3:21:42, 30.64s/it]2021-12-17 15:46:07,210 iteration 86 : loss : 0.386520, loss_ce: 0.180195
2021-12-17 15:46:08,484 iteration 87 : loss : 0.392429, loss_ce: 0.196711
2021-12-17 15:46:09,807 iteration 88 : loss : 0.393535, loss_ce: 0.188762
2021-12-17 15:46:11,235 iteration 89 : loss : 0.398939, loss_ce: 0.209289
2021-12-17 15:46:12,563 iteration 90 : loss : 0.401875, loss_ce: 0.215600
2021-12-17 15:46:13,949 iteration 91 : loss : 0.393118, loss_ce: 0.190606
2021-12-17 15:46:15,304 iteration 92 : loss : 0.392922, loss_ce: 0.200172
2021-12-17 15:46:16,733 iteration 93 : loss : 0.386391, loss_ce: 0.188223
2021-12-17 15:46:18,153 iteration 94 : loss : 0.400449, loss_ce: 0.219013
2021-12-17 15:46:19,492 iteration 95 : loss : 0.387985, loss_ce: 0.178845
2021-12-17 15:46:20,793 iteration 96 : loss : 0.383938, loss_ce: 0.175613
2021-12-17 15:46:22,099 iteration 97 : loss : 0.391948, loss_ce: 0.196304
2021-12-17 15:46:23,493 iteration 98 : loss : 0.380794, loss_ce: 0.179537
2021-12-17 15:46:25,054 iteration 99 : loss : 0.394637, loss_ce: 0.200016
2021-12-17 15:46:26,645 iteration 100 : loss : 0.400884, loss_ce: 0.207233
2021-12-17 15:46:28,082 iteration 101 : loss : 0.397914, loss_ce: 0.196473
2021-12-17 15:46:29,546 iteration 102 : loss : 0.386661, loss_ce: 0.180884
  2%|▍                              | 6/400 [02:41<3:05:45, 28.29s/it]2021-12-17 15:46:31,062 iteration 103 : loss : 0.392630, loss_ce: 0.193243
2021-12-17 15:46:32,574 iteration 104 : loss : 0.381298, loss_ce: 0.176481
2021-12-17 15:46:34,051 iteration 105 : loss : 0.393859, loss_ce: 0.199094
2021-12-17 15:46:35,518 iteration 106 : loss : 0.385495, loss_ce: 0.182154
2021-12-17 15:46:37,035 iteration 107 : loss : 0.387365, loss_ce: 0.188332
2021-12-17 15:46:38,476 iteration 108 : loss : 0.391200, loss_ce: 0.203091
2021-12-17 15:46:39,944 iteration 109 : loss : 0.385747, loss_ce: 0.187827
2021-12-17 15:46:41,451 iteration 110 : loss : 0.391678, loss_ce: 0.200250
2021-12-17 15:46:43,085 iteration 111 : loss : 0.380991, loss_ce: 0.176457
2021-12-17 15:46:44,499 iteration 112 : loss : 0.373418, loss_ce: 0.154776
2021-12-17 15:46:46,051 iteration 113 : loss : 0.381713, loss_ce: 0.180933
2021-12-17 15:46:47,506 iteration 114 : loss : 0.385582, loss_ce: 0.177604
2021-12-17 15:46:48,888 iteration 115 : loss : 0.389622, loss_ce: 0.183116
2021-12-17 15:46:50,332 iteration 116 : loss : 0.391420, loss_ce: 0.196335
2021-12-17 15:46:51,749 iteration 117 : loss : 0.386489, loss_ce: 0.189951
2021-12-17 15:46:53,254 iteration 118 : loss : 0.381706, loss_ce: 0.177178
2021-12-17 15:46:54,681 iteration 119 : loss : 0.395289, loss_ce: 0.199017
  2%|▌                              | 7/400 [03:06<2:58:31, 27.26s/it]2021-12-17 15:46:56,230 iteration 120 : loss : 0.398413, loss_ce: 0.206496
2021-12-17 15:46:57,714 iteration 121 : loss : 0.375111, loss_ce: 0.164966
2021-12-17 15:46:59,068 iteration 122 : loss : 0.372844, loss_ce: 0.171870
2021-12-17 15:47:00,533 iteration 123 : loss : 0.381006, loss_ce: 0.186887
2021-12-17 15:47:01,960 iteration 124 : loss : 0.379706, loss_ce: 0.174932
2021-12-17 15:47:03,404 iteration 125 : loss : 0.374519, loss_ce: 0.164142
2021-12-17 15:47:04,831 iteration 126 : loss : 0.389497, loss_ce: 0.197423
2021-12-17 15:47:06,269 iteration 127 : loss : 0.396272, loss_ce: 0.205580
2021-12-17 15:47:07,691 iteration 128 : loss : 0.374738, loss_ce: 0.166806
2021-12-17 15:47:09,180 iteration 129 : loss : 0.369453, loss_ce: 0.157665
2021-12-17 15:47:10,521 iteration 130 : loss : 0.381598, loss_ce: 0.185913
2021-12-17 15:47:11,944 iteration 131 : loss : 0.400416, loss_ce: 0.211154
2021-12-17 15:47:13,404 iteration 132 : loss : 0.366667, loss_ce: 0.161006
2021-12-17 15:47:14,876 iteration 133 : loss : 0.401061, loss_ce: 0.219264
2021-12-17 15:47:16,315 iteration 134 : loss : 0.378659, loss_ce: 0.176566
2021-12-17 15:47:17,735 iteration 135 : loss : 0.370254, loss_ce: 0.161888
2021-12-17 15:47:19,253 iteration 136 : loss : 0.373205, loss_ce: 0.174164
  2%|▌                              | 8/400 [03:31<2:52:28, 26.40s/it]2021-12-17 15:47:20,818 iteration 137 : loss : 0.364050, loss_ce: 0.150325
2021-12-17 15:47:22,206 iteration 138 : loss : 0.378118, loss_ce: 0.173378
2021-12-17 15:47:23,733 iteration 139 : loss : 0.364161, loss_ce: 0.138722
2021-12-17 15:47:25,158 iteration 140 : loss : 0.375019, loss_ce: 0.176844
2021-12-17 15:47:26,561 iteration 141 : loss : 0.381500, loss_ce: 0.177435
2021-12-17 15:47:27,997 iteration 142 : loss : 0.371414, loss_ce: 0.174724
2021-12-17 15:47:29,448 iteration 143 : loss : 0.377240, loss_ce: 0.164857
2021-12-17 15:47:30,886 iteration 144 : loss : 0.366369, loss_ce: 0.151294
2021-12-17 15:47:32,350 iteration 145 : loss : 0.399454, loss_ce: 0.220564
2021-12-17 15:47:33,846 iteration 146 : loss : 0.386727, loss_ce: 0.194816
2021-12-17 15:47:35,296 iteration 147 : loss : 0.389244, loss_ce: 0.203345
2021-12-17 15:47:36,849 iteration 148 : loss : 0.373277, loss_ce: 0.171534
2021-12-17 15:47:38,369 iteration 149 : loss : 0.366314, loss_ce: 0.161322
2021-12-17 15:47:39,866 iteration 150 : loss : 0.379743, loss_ce: 0.183466
2021-12-17 15:47:41,249 iteration 151 : loss : 0.395282, loss_ce: 0.217058
2021-12-17 15:47:42,607 iteration 152 : loss : 0.380969, loss_ce: 0.190829
2021-12-17 15:47:44,056 iteration 153 : loss : 0.381410, loss_ce: 0.184323
  2%|▋                              | 9/400 [03:55<2:48:46, 25.90s/it]2021-12-17 15:47:45,600 iteration 154 : loss : 0.371375, loss_ce: 0.180961
2021-12-17 15:47:47,038 iteration 155 : loss : 0.377025, loss_ce: 0.178356
2021-12-17 15:47:48,435 iteration 156 : loss : 0.384175, loss_ce: 0.193077
2021-12-17 15:47:49,833 iteration 157 : loss : 0.377997, loss_ce: 0.178110
2021-12-17 15:47:51,351 iteration 158 : loss : 0.377880, loss_ce: 0.177455
2021-12-17 15:47:52,876 iteration 159 : loss : 0.373629, loss_ce: 0.172761
2021-12-17 15:47:54,305 iteration 160 : loss : 0.357666, loss_ce: 0.161787
2021-12-17 15:47:55,835 iteration 161 : loss : 0.376201, loss_ce: 0.184050
2021-12-17 15:47:57,276 iteration 162 : loss : 0.362206, loss_ce: 0.154861
2021-12-17 15:47:58,738 iteration 163 : loss : 0.383254, loss_ce: 0.191980
2021-12-17 15:48:00,192 iteration 164 : loss : 0.365662, loss_ce: 0.152101
2021-12-17 15:48:01,580 iteration 165 : loss : 0.368737, loss_ce: 0.177286
2021-12-17 15:48:03,065 iteration 166 : loss : 0.397428, loss_ce: 0.229764
2021-12-17 15:48:04,626 iteration 167 : loss : 0.379755, loss_ce: 0.179898
2021-12-17 15:48:06,061 iteration 168 : loss : 0.363513, loss_ce: 0.152317
2021-12-17 15:48:07,525 iteration 169 : loss : 0.366579, loss_ce: 0.167314
2021-12-17 15:48:07,526 Training Data Eval:
2021-12-17 15:48:15,032   Average segmentation loss on training set: 0.3695
2021-12-17 15:48:15,032 Validation Data Eval:
2021-12-17 15:48:17,632   Average segmentation loss on validation set: 0.3953
2021-12-17 15:48:24,058 Found new lowest validation loss at iteration 169! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/TU_3seeds/TU_RESNET_no_pretraining_SGD_best_val_loss_seed2.pth
2021-12-17 15:48:25,526 iteration 170 : loss : 0.373130, loss_ce: 0.187121
  2%|▊                             | 10/400 [04:37<3:19:35, 30.71s/it]2021-12-17 15:48:27,002 iteration 171 : loss : 0.376025, loss_ce: 0.189214
2021-12-17 15:48:28,324 iteration 172 : loss : 0.373971, loss_ce: 0.189051
2021-12-17 15:48:29,760 iteration 173 : loss : 0.365874, loss_ce: 0.158870
2021-12-17 15:48:31,053 iteration 174 : loss : 0.387235, loss_ce: 0.204475
2021-12-17 15:48:32,403 iteration 175 : loss : 0.357580, loss_ce: 0.147081
2021-12-17 15:48:33,751 iteration 176 : loss : 0.368283, loss_ce: 0.172580
2021-12-17 15:48:35,155 iteration 177 : loss : 0.362979, loss_ce: 0.172722
2021-12-17 15:48:36,519 iteration 178 : loss : 0.368167, loss_ce: 0.177055
2021-12-17 15:48:37,819 iteration 179 : loss : 0.361089, loss_ce: 0.157619
2021-12-17 15:48:39,294 iteration 180 : loss : 0.373520, loss_ce: 0.179358
2021-12-17 15:48:40,738 iteration 181 : loss : 0.366467, loss_ce: 0.187116
2021-12-17 15:48:42,195 iteration 182 : loss : 0.372478, loss_ce: 0.182512
2021-12-17 15:48:43,696 iteration 183 : loss : 0.361464, loss_ce: 0.156675
2021-12-17 15:48:45,314 iteration 184 : loss : 0.366927, loss_ce: 0.161490
2021-12-17 15:48:46,884 iteration 185 : loss : 0.373845, loss_ce: 0.189176
2021-12-17 15:48:48,338 iteration 186 : loss : 0.366671, loss_ce: 0.152012
2021-12-17 15:48:49,828 iteration 187 : loss : 0.357850, loss_ce: 0.157127
  3%|▊                             | 11/400 [05:01<3:06:22, 28.75s/it]2021-12-17 15:48:51,292 iteration 188 : loss : 0.368384, loss_ce: 0.177509
2021-12-17 15:48:52,842 iteration 189 : loss : 0.374470, loss_ce: 0.188514
2021-12-17 15:48:54,335 iteration 190 : loss : 0.366115, loss_ce: 0.173649
2021-12-17 15:48:55,812 iteration 191 : loss : 0.365643, loss_ce: 0.164902
2021-12-17 15:48:57,265 iteration 192 : loss : 0.351959, loss_ce: 0.144234
2021-12-17 15:48:58,655 iteration 193 : loss : 0.366029, loss_ce: 0.175369
2021-12-17 15:49:00,138 iteration 194 : loss : 0.364130, loss_ce: 0.169646
2021-12-17 15:49:01,647 iteration 195 : loss : 0.350463, loss_ce: 0.152715
2021-12-17 15:49:03,099 iteration 196 : loss : 0.369096, loss_ce: 0.192419
2021-12-17 15:49:04,600 iteration 197 : loss : 0.354627, loss_ce: 0.158626
2021-12-17 15:49:06,087 iteration 198 : loss : 0.353036, loss_ce: 0.140666
2021-12-17 15:49:07,468 iteration 199 : loss : 0.350083, loss_ce: 0.147215
2021-12-17 15:49:08,924 iteration 200 : loss : 0.376199, loss_ce: 0.192747
2021-12-17 15:49:10,510 iteration 201 : loss : 0.369149, loss_ce: 0.185214
2021-12-17 15:49:11,936 iteration 202 : loss : 0.369804, loss_ce: 0.170388
2021-12-17 15:49:13,356 iteration 203 : loss : 0.385660, loss_ce: 0.217667
2021-12-17 15:49:14,747 iteration 204 : loss : 0.358745, loss_ce: 0.165738
  3%|▉                             | 12/400 [05:26<2:58:22, 27.58s/it]2021-12-17 15:49:16,198 iteration 205 : loss : 0.373709, loss_ce: 0.168899
2021-12-17 15:49:17,665 iteration 206 : loss : 0.362627, loss_ce: 0.178756
2021-12-17 15:49:19,222 iteration 207 : loss : 0.366566, loss_ce: 0.181038
2021-12-17 15:49:20,781 iteration 208 : loss : 0.354331, loss_ce: 0.162698
2021-12-17 15:49:22,194 iteration 209 : loss : 0.348442, loss_ce: 0.158708
2021-12-17 15:49:23,596 iteration 210 : loss : 0.354467, loss_ce: 0.159515
2021-12-17 15:49:25,067 iteration 211 : loss : 0.348953, loss_ce: 0.155546
2021-12-17 15:49:26,454 iteration 212 : loss : 0.349159, loss_ce: 0.145231
2021-12-17 15:49:27,972 iteration 213 : loss : 0.359968, loss_ce: 0.174237
2021-12-17 15:49:29,449 iteration 214 : loss : 0.351502, loss_ce: 0.145107
2021-12-17 15:49:30,851 iteration 215 : loss : 0.364853, loss_ce: 0.171359
2021-12-17 15:49:32,362 iteration 216 : loss : 0.360414, loss_ce: 0.161974
2021-12-17 15:49:33,779 iteration 217 : loss : 0.363661, loss_ce: 0.180629
2021-12-17 15:49:35,225 iteration 218 : loss : 0.349533, loss_ce: 0.160620
2021-12-17 15:49:36,671 iteration 219 : loss : 0.343419, loss_ce: 0.137533
2021-12-17 15:49:38,071 iteration 220 : loss : 0.369371, loss_ce: 0.194013
2021-12-17 15:49:39,512 iteration 221 : loss : 0.364195, loss_ce: 0.187520
  3%|▉                             | 13/400 [05:51<2:52:24, 26.73s/it]2021-12-17 15:49:41,138 iteration 222 : loss : 0.359047, loss_ce: 0.157174
2021-12-17 15:49:42,648 iteration 223 : loss : 0.353785, loss_ce: 0.148676
2021-12-17 15:49:44,007 iteration 224 : loss : 0.363186, loss_ce: 0.164118
2021-12-17 15:49:45,512 iteration 225 : loss : 0.340572, loss_ce: 0.140058
2021-12-17 15:49:47,021 iteration 226 : loss : 0.342663, loss_ce: 0.138255
2021-12-17 15:49:48,498 iteration 227 : loss : 0.341969, loss_ce: 0.157850
2021-12-17 15:49:49,970 iteration 228 : loss : 0.343331, loss_ce: 0.146050
2021-12-17 15:49:51,455 iteration 229 : loss : 0.361705, loss_ce: 0.191578
2021-12-17 15:49:52,905 iteration 230 : loss : 0.371504, loss_ce: 0.177566
2021-12-17 15:49:54,327 iteration 231 : loss : 0.343517, loss_ce: 0.143654
2021-12-17 15:49:55,871 iteration 232 : loss : 0.365355, loss_ce: 0.192320
2021-12-17 15:49:57,400 iteration 233 : loss : 0.364734, loss_ce: 0.191894
2021-12-17 15:49:58,893 iteration 234 : loss : 0.345336, loss_ce: 0.138316
2021-12-17 15:50:00,355 iteration 235 : loss : 0.345538, loss_ce: 0.151695
2021-12-17 15:50:01,790 iteration 236 : loss : 0.341453, loss_ce: 0.154864
2021-12-17 15:50:03,200 iteration 237 : loss : 0.347826, loss_ce: 0.158550
2021-12-17 15:50:04,555 iteration 238 : loss : 0.347189, loss_ce: 0.171067
  4%|█                             | 14/400 [06:16<2:48:39, 26.22s/it]2021-12-17 15:50:06,006 iteration 239 : loss : 0.340922, loss_ce: 0.146528
2021-12-17 15:50:07,533 iteration 240 : loss : 0.359727, loss_ce: 0.196699
2021-12-17 15:50:08,948 iteration 241 : loss : 0.343009, loss_ce: 0.135403
2021-12-17 15:50:10,464 iteration 242 : loss : 0.341756, loss_ce: 0.155034
2021-12-17 15:50:11,994 iteration 243 : loss : 0.358024, loss_ce: 0.180900
2021-12-17 15:50:13,508 iteration 244 : loss : 0.351614, loss_ce: 0.176871
2021-12-17 15:50:14,888 iteration 245 : loss : 0.336458, loss_ce: 0.136227
2021-12-17 15:50:16,360 iteration 246 : loss : 0.346408, loss_ce: 0.151917
2021-12-17 15:50:17,776 iteration 247 : loss : 0.343413, loss_ce: 0.162667
2021-12-17 15:50:19,152 iteration 248 : loss : 0.332885, loss_ce: 0.137422
2021-12-17 15:50:20,702 iteration 249 : loss : 0.354767, loss_ce: 0.153883
2021-12-17 15:50:22,204 iteration 250 : loss : 0.355714, loss_ce: 0.177160
2021-12-17 15:50:23,637 iteration 251 : loss : 0.357942, loss_ce: 0.163610
2021-12-17 15:50:25,086 iteration 252 : loss : 0.348677, loss_ce: 0.186492
2021-12-17 15:50:26,490 iteration 253 : loss : 0.342355, loss_ce: 0.145982
2021-12-17 15:50:27,901 iteration 254 : loss : 0.343578, loss_ce: 0.152304
2021-12-17 15:50:27,901 Training Data Eval:
2021-12-17 15:50:35,436   Average segmentation loss on training set: 0.3380
2021-12-17 15:50:35,436 Validation Data Eval:
2021-12-17 15:50:38,028   Average segmentation loss on validation set: 0.3562
2021-12-17 15:50:44,350 Found new lowest validation loss at iteration 254! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/TU_3seeds/TU_RESNET_no_pretraining_SGD_best_val_loss_seed2.pth
2021-12-17 15:50:45,736 iteration 255 : loss : 0.351952, loss_ce: 0.144021
  4%|█▏                            | 15/400 [06:57<3:17:10, 30.73s/it]2021-12-17 15:50:47,145 iteration 256 : loss : 0.346411, loss_ce: 0.151461
2021-12-17 15:50:48,493 iteration 257 : loss : 0.364243, loss_ce: 0.191450
2021-12-17 15:50:49,993 iteration 258 : loss : 0.341945, loss_ce: 0.138517
2021-12-17 15:50:51,305 iteration 259 : loss : 0.340360, loss_ce: 0.144234
2021-12-17 15:50:52,701 iteration 260 : loss : 0.352168, loss_ce: 0.172152
2021-12-17 15:50:54,114 iteration 261 : loss : 0.357320, loss_ce: 0.174844
2021-12-17 15:50:55,509 iteration 262 : loss : 0.350080, loss_ce: 0.173711
2021-12-17 15:50:56,839 iteration 263 : loss : 0.349038, loss_ce: 0.173902
2021-12-17 15:50:58,165 iteration 264 : loss : 0.331980, loss_ce: 0.136244
2021-12-17 15:50:59,580 iteration 265 : loss : 0.342564, loss_ce: 0.160233
2021-12-17 15:51:00,994 iteration 266 : loss : 0.340406, loss_ce: 0.133482
2021-12-17 15:51:02,409 iteration 267 : loss : 0.355393, loss_ce: 0.182117
2021-12-17 15:51:03,858 iteration 268 : loss : 0.339169, loss_ce: 0.162088
2021-12-17 15:51:05,295 iteration 269 : loss : 0.347883, loss_ce: 0.170466
2021-12-17 15:51:06,681 iteration 270 : loss : 0.331713, loss_ce: 0.127444
2021-12-17 15:51:08,163 iteration 271 : loss : 0.336056, loss_ce: 0.139618
2021-12-17 15:51:09,709 iteration 272 : loss : 0.327553, loss_ce: 0.144210
  4%|█▏                            | 16/400 [07:21<3:03:39, 28.70s/it]2021-12-17 15:51:11,210 iteration 273 : loss : 0.331792, loss_ce: 0.148528
2021-12-17 15:51:12,701 iteration 274 : loss : 0.349774, loss_ce: 0.167015
2021-12-17 15:51:14,178 iteration 275 : loss : 0.339743, loss_ce: 0.172643
2021-12-17 15:51:15,594 iteration 276 : loss : 0.345679, loss_ce: 0.166012
2021-12-17 15:51:17,142 iteration 277 : loss : 0.328520, loss_ce: 0.146317
2021-12-17 15:51:18,536 iteration 278 : loss : 0.334888, loss_ce: 0.139637
2021-12-17 15:51:19,984 iteration 279 : loss : 0.356870, loss_ce: 0.167104
2021-12-17 15:51:21,362 iteration 280 : loss : 0.338594, loss_ce: 0.157072
2021-12-17 15:51:22,840 iteration 281 : loss : 0.328242, loss_ce: 0.135275
2021-12-17 15:51:24,330 iteration 282 : loss : 0.336134, loss_ce: 0.162394
2021-12-17 15:51:25,804 iteration 283 : loss : 0.340273, loss_ce: 0.168389
2021-12-17 15:51:27,214 iteration 284 : loss : 0.322470, loss_ce: 0.149397
2021-12-17 15:51:28,693 iteration 285 : loss : 0.329944, loss_ce: 0.142055
2021-12-17 15:51:30,181 iteration 286 : loss : 0.329467, loss_ce: 0.141158
2021-12-17 15:51:31,591 iteration 287 : loss : 0.324004, loss_ce: 0.127689
2021-12-17 15:51:33,031 iteration 288 : loss : 0.328731, loss_ce: 0.148426
2021-12-17 15:51:34,491 iteration 289 : loss : 0.326552, loss_ce: 0.150369
  4%|█▎                            | 17/400 [07:46<2:55:40, 27.52s/it]2021-12-17 15:51:35,998 iteration 290 : loss : 0.345908, loss_ce: 0.146666
2021-12-17 15:51:37,448 iteration 291 : loss : 0.320393, loss_ce: 0.144980
2021-12-17 15:51:38,911 iteration 292 : loss : 0.326063, loss_ce: 0.151324
2021-12-17 15:51:40,504 iteration 293 : loss : 0.341264, loss_ce: 0.159599
2021-12-17 15:51:41,897 iteration 294 : loss : 0.329869, loss_ce: 0.137995
2021-12-17 15:51:43,305 iteration 295 : loss : 0.336429, loss_ce: 0.128717
2021-12-17 15:51:44,746 iteration 296 : loss : 0.336753, loss_ce: 0.143591
2021-12-17 15:51:46,272 iteration 297 : loss : 0.340990, loss_ce: 0.159818
2021-12-17 15:51:47,700 iteration 298 : loss : 0.310158, loss_ce: 0.125030
2021-12-17 15:51:49,198 iteration 299 : loss : 0.319570, loss_ce: 0.123775
2021-12-17 15:51:50,617 iteration 300 : loss : 0.322265, loss_ce: 0.134604
2021-12-17 15:51:52,066 iteration 301 : loss : 0.317629, loss_ce: 0.136955
2021-12-17 15:51:53,603 iteration 302 : loss : 0.351503, loss_ce: 0.196215
2021-12-17 15:51:55,093 iteration 303 : loss : 0.330439, loss_ce: 0.163218
2021-12-17 15:51:56,540 iteration 304 : loss : 0.322985, loss_ce: 0.146041
2021-12-17 15:51:58,009 iteration 305 : loss : 0.315188, loss_ce: 0.137730
2021-12-17 15:51:59,463 iteration 306 : loss : 0.342698, loss_ce: 0.151022
  4%|█▎                            | 18/400 [08:11<2:50:18, 26.75s/it]2021-12-17 15:52:00,936 iteration 307 : loss : 0.327838, loss_ce: 0.136854
2021-12-17 15:52:02,443 iteration 308 : loss : 0.327941, loss_ce: 0.140303
2021-12-17 15:52:03,903 iteration 309 : loss : 0.339635, loss_ce: 0.167720
2021-12-17 15:52:05,347 iteration 310 : loss : 0.324002, loss_ce: 0.124134
2021-12-17 15:52:06,779 iteration 311 : loss : 0.327428, loss_ce: 0.150222
2021-12-17 15:52:08,232 iteration 312 : loss : 0.323838, loss_ce: 0.108170
2021-12-17 15:52:09,719 iteration 313 : loss : 0.319647, loss_ce: 0.135422
2021-12-17 15:52:11,084 iteration 314 : loss : 0.327089, loss_ce: 0.151253
2021-12-17 15:52:12,523 iteration 315 : loss : 0.316472, loss_ce: 0.137781
2021-12-17 15:52:14,057 iteration 316 : loss : 0.324397, loss_ce: 0.143403
2021-12-17 15:52:15,599 iteration 317 : loss : 0.330179, loss_ce: 0.161837
2021-12-17 15:52:17,039 iteration 318 : loss : 0.323548, loss_ce: 0.154868
2021-12-17 15:52:18,502 iteration 319 : loss : 0.321255, loss_ce: 0.147575
2021-12-17 15:52:19,955 iteration 320 : loss : 0.316825, loss_ce: 0.131370
2021-12-17 15:52:21,383 iteration 321 : loss : 0.307460, loss_ce: 0.128645
2021-12-17 15:52:22,793 iteration 322 : loss : 0.332442, loss_ce: 0.153118
2021-12-17 15:52:24,237 iteration 323 : loss : 0.326602, loss_ce: 0.149541
  5%|█▍                            | 19/400 [08:36<2:46:06, 26.16s/it]2021-12-17 15:52:25,721 iteration 324 : loss : 0.323378, loss_ce: 0.134827
2021-12-17 15:52:27,121 iteration 325 : loss : 0.307085, loss_ce: 0.109474
2021-12-17 15:52:28,534 iteration 326 : loss : 0.322670, loss_ce: 0.127490
2021-12-17 15:52:29,931 iteration 327 : loss : 0.320428, loss_ce: 0.151690
2021-12-17 15:52:31,395 iteration 328 : loss : 0.323733, loss_ce: 0.129228
2021-12-17 15:52:32,908 iteration 329 : loss : 0.312144, loss_ce: 0.133461
2021-12-17 15:52:34,324 iteration 330 : loss : 0.330309, loss_ce: 0.163031
2021-12-17 15:52:35,772 iteration 331 : loss : 0.311259, loss_ce: 0.134920
2021-12-17 15:52:37,143 iteration 332 : loss : 0.308037, loss_ce: 0.136000
2021-12-17 15:52:38,655 iteration 333 : loss : 0.329194, loss_ce: 0.164043
2021-12-17 15:52:40,115 iteration 334 : loss : 0.314491, loss_ce: 0.138221
2021-12-17 15:52:41,638 iteration 335 : loss : 0.323048, loss_ce: 0.163432
2021-12-17 15:52:43,076 iteration 336 : loss : 0.317749, loss_ce: 0.139146
2021-12-17 15:52:44,487 iteration 337 : loss : 0.313603, loss_ce: 0.123736
2021-12-17 15:52:45,921 iteration 338 : loss : 0.314269, loss_ce: 0.149248
2021-12-17 15:52:47,337 iteration 339 : loss : 0.319895, loss_ce: 0.140757
2021-12-17 15:52:47,337 Training Data Eval:
2021-12-17 15:52:54,878   Average segmentation loss on training set: 0.3018
2021-12-17 15:52:54,878 Validation Data Eval:
2021-12-17 15:52:57,468   Average segmentation loss on validation set: 0.3197
2021-12-17 15:53:03,693 Found new lowest validation loss at iteration 339! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/TU_3seeds/TU_RESNET_no_pretraining_SGD_best_val_loss_seed2.pth
2021-12-17 15:53:05,125 iteration 340 : loss : 0.323207, loss_ce: 0.161172
  5%|█▌                            | 20/400 [09:17<3:13:40, 30.58s/it]2021-12-17 15:53:06,511 iteration 341 : loss : 0.316074, loss_ce: 0.155722
2021-12-17 15:53:07,929 iteration 342 : loss : 0.308666, loss_ce: 0.154683
2021-12-17 15:53:09,336 iteration 343 : loss : 0.304964, loss_ce: 0.134847
2021-12-17 15:53:10,689 iteration 344 : loss : 0.304297, loss_ce: 0.145576
2021-12-17 15:53:12,039 iteration 345 : loss : 0.307565, loss_ce: 0.135525
2021-12-17 15:53:13,469 iteration 346 : loss : 0.306505, loss_ce: 0.128236
2021-12-17 15:53:14,897 iteration 347 : loss : 0.311503, loss_ce: 0.140682
2021-12-17 15:53:16,253 iteration 348 : loss : 0.309005, loss_ce: 0.129496
2021-12-17 15:53:17,622 iteration 349 : loss : 0.308379, loss_ce: 0.126903
2021-12-17 15:53:19,025 iteration 350 : loss : 0.328812, loss_ce: 0.155730
2021-12-17 15:53:20,390 iteration 351 : loss : 0.307812, loss_ce: 0.133044
2021-12-17 15:53:21,894 iteration 352 : loss : 0.311260, loss_ce: 0.142782
2021-12-17 15:53:23,422 iteration 353 : loss : 0.330660, loss_ce: 0.147209
2021-12-17 15:53:24,869 iteration 354 : loss : 0.312007, loss_ce: 0.138406
2021-12-17 15:53:26,380 iteration 355 : loss : 0.321356, loss_ce: 0.124072
2021-12-17 15:53:27,856 iteration 356 : loss : 0.316506, loss_ce: 0.125148
2021-12-17 15:53:29,355 iteration 357 : loss : 0.283918, loss_ce: 0.120182
  5%|█▌                            | 21/400 [09:41<3:01:07, 28.67s/it]2021-12-17 15:53:30,970 iteration 358 : loss : 0.312171, loss_ce: 0.160914
2021-12-17 15:53:32,512 iteration 359 : loss : 0.312776, loss_ce: 0.133952
2021-12-17 15:53:33,944 iteration 360 : loss : 0.295374, loss_ce: 0.119830
2021-12-17 15:53:35,432 iteration 361 : loss : 0.307852, loss_ce: 0.125076
2021-12-17 15:53:36,913 iteration 362 : loss : 0.311521, loss_ce: 0.158142
2021-12-17 15:53:38,299 iteration 363 : loss : 0.320173, loss_ce: 0.152785
2021-12-17 15:53:39,779 iteration 364 : loss : 0.319004, loss_ce: 0.107010
2021-12-17 15:53:41,207 iteration 365 : loss : 0.310195, loss_ce: 0.136540
2021-12-17 15:53:42,645 iteration 366 : loss : 0.309312, loss_ce: 0.112977
2021-12-17 15:53:44,115 iteration 367 : loss : 0.306012, loss_ce: 0.128138
2021-12-17 15:53:45,556 iteration 368 : loss : 0.302350, loss_ce: 0.126877
2021-12-17 15:53:46,974 iteration 369 : loss : 0.294406, loss_ce: 0.124931
2021-12-17 15:53:48,430 iteration 370 : loss : 0.319887, loss_ce: 0.163418
2021-12-17 15:53:49,889 iteration 371 : loss : 0.293637, loss_ce: 0.122985
2021-12-17 15:53:51,297 iteration 372 : loss : 0.291031, loss_ce: 0.127097
2021-12-17 15:53:52,742 iteration 373 : loss : 0.312669, loss_ce: 0.129774
2021-12-17 15:53:54,236 iteration 374 : loss : 0.300635, loss_ce: 0.135392
  6%|█▋                            | 22/400 [10:06<2:53:28, 27.54s/it]2021-12-17 15:53:55,715 iteration 375 : loss : 0.302950, loss_ce: 0.130551
2021-12-17 15:53:57,142 iteration 376 : loss : 0.295638, loss_ce: 0.101057
2021-12-17 15:53:58,611 iteration 377 : loss : 0.294251, loss_ce: 0.116192
2021-12-17 15:54:00,152 iteration 378 : loss : 0.313130, loss_ce: 0.122947
2021-12-17 15:54:01,622 iteration 379 : loss : 0.321001, loss_ce: 0.132080
2021-12-17 15:54:03,051 iteration 380 : loss : 0.320190, loss_ce: 0.154076
2021-12-17 15:54:04,537 iteration 381 : loss : 0.284009, loss_ce: 0.126767
2021-12-17 15:54:05,941 iteration 382 : loss : 0.307662, loss_ce: 0.148390
2021-12-17 15:54:07,432 iteration 383 : loss : 0.309904, loss_ce: 0.108758
2021-12-17 15:54:08,887 iteration 384 : loss : 0.289173, loss_ce: 0.125705
2021-12-17 15:54:10,319 iteration 385 : loss : 0.303840, loss_ce: 0.145702
2021-12-17 15:54:11,774 iteration 386 : loss : 0.301613, loss_ce: 0.122770
2021-12-17 15:54:13,179 iteration 387 : loss : 0.283490, loss_ce: 0.118865
2021-12-17 15:54:14,661 iteration 388 : loss : 0.300727, loss_ce: 0.128928
2021-12-17 15:54:16,113 iteration 389 : loss : 0.296979, loss_ce: 0.126792
2021-12-17 15:54:17,583 iteration 390 : loss : 0.314007, loss_ce: 0.149217
2021-12-17 15:54:19,063 iteration 391 : loss : 0.283833, loss_ce: 0.120958
  6%|█▋                            | 23/400 [10:30<2:47:55, 26.72s/it]2021-12-17 15:54:20,615 iteration 392 : loss : 0.302444, loss_ce: 0.134305
2021-12-17 15:54:22,010 iteration 393 : loss : 0.315841, loss_ce: 0.150820
2021-12-17 15:54:23,471 iteration 394 : loss : 0.313942, loss_ce: 0.115527
2021-12-17 15:54:24,883 iteration 395 : loss : 0.297188, loss_ce: 0.118357
2021-12-17 15:54:26,326 iteration 396 : loss : 0.289581, loss_ce: 0.121458
2021-12-17 15:54:27,858 iteration 397 : loss : 0.284491, loss_ce: 0.122501
2021-12-17 15:54:29,282 iteration 398 : loss : 0.283020, loss_ce: 0.119188
2021-12-17 15:54:30,733 iteration 399 : loss : 0.309537, loss_ce: 0.134559
2021-12-17 15:54:32,164 iteration 400 : loss : 0.278595, loss_ce: 0.112873
2021-12-17 15:54:33,644 iteration 401 : loss : 0.284354, loss_ce: 0.136666
2021-12-17 15:54:35,197 iteration 402 : loss : 0.280858, loss_ce: 0.115250
2021-12-17 15:54:36,694 iteration 403 : loss : 0.281088, loss_ce: 0.116528
2021-12-17 15:54:38,128 iteration 404 : loss : 0.279198, loss_ce: 0.115784
2021-12-17 15:54:39,581 iteration 405 : loss : 0.293906, loss_ce: 0.135107
2021-12-17 15:54:41,075 iteration 406 : loss : 0.262649, loss_ce: 0.112688
2021-12-17 15:54:42,562 iteration 407 : loss : 0.301651, loss_ce: 0.130263
2021-12-17 15:54:43,926 iteration 408 : loss : 0.298279, loss_ce: 0.138860
  6%|█▊                            | 24/400 [10:55<2:43:58, 26.17s/it]2021-12-17 15:54:45,482 iteration 409 : loss : 0.275513, loss_ce: 0.107096
2021-12-17 15:54:46,937 iteration 410 : loss : 0.275648, loss_ce: 0.111776
2021-12-17 15:54:48,405 iteration 411 : loss : 0.293845, loss_ce: 0.121679
2021-12-17 15:54:49,833 iteration 412 : loss : 0.269797, loss_ce: 0.126446
2021-12-17 15:54:51,273 iteration 413 : loss : 0.292003, loss_ce: 0.117860
2021-12-17 15:54:52,685 iteration 414 : loss : 0.268971, loss_ce: 0.116373
2021-12-17 15:54:54,213 iteration 415 : loss : 0.291670, loss_ce: 0.121221
2021-12-17 15:54:55,628 iteration 416 : loss : 0.288817, loss_ce: 0.134245
2021-12-17 15:54:57,115 iteration 417 : loss : 0.281471, loss_ce: 0.107817
2021-12-17 15:54:58,497 iteration 418 : loss : 0.288256, loss_ce: 0.156585
2021-12-17 15:54:59,934 iteration 419 : loss : 0.276390, loss_ce: 0.108498
2021-12-17 15:55:01,387 iteration 420 : loss : 0.283238, loss_ce: 0.120558
2021-12-17 15:55:02,905 iteration 421 : loss : 0.307395, loss_ce: 0.139231
2021-12-17 15:55:04,330 iteration 422 : loss : 0.309887, loss_ce: 0.124343
2021-12-17 15:55:05,796 iteration 423 : loss : 0.262294, loss_ce: 0.109930
2021-12-17 15:55:07,288 iteration 424 : loss : 0.277600, loss_ce: 0.111236
2021-12-17 15:55:07,288 Training Data Eval:
2021-12-17 15:55:14,793   Average segmentation loss on training set: 0.2844
2021-12-17 15:55:14,793 Validation Data Eval:
2021-12-17 15:55:17,393   Average segmentation loss on validation set: 0.2847
2021-12-17 15:55:23,725 Found new lowest validation loss at iteration 424! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/TU_3seeds/TU_RESNET_no_pretraining_SGD_best_val_loss_seed2.pth
2021-12-17 15:55:25,178 iteration 425 : loss : 0.287728, loss_ce: 0.117497
  6%|█▉                            | 25/400 [11:37<3:11:48, 30.69s/it]2021-12-17 15:55:26,644 iteration 426 : loss : 0.291173, loss_ce: 0.123333
2021-12-17 15:55:28,018 iteration 427 : loss : 0.288450, loss_ce: 0.112322
2021-12-17 15:55:29,429 iteration 428 : loss : 0.288499, loss_ce: 0.123274
2021-12-17 15:55:30,749 iteration 429 : loss : 0.250159, loss_ce: 0.096363
2021-12-17 15:55:32,131 iteration 430 : loss : 0.284302, loss_ce: 0.109189
2021-12-17 15:55:33,429 iteration 431 : loss : 0.292766, loss_ce: 0.106472
2021-12-17 15:55:34,759 iteration 432 : loss : 0.252400, loss_ce: 0.095578
2021-12-17 15:55:36,135 iteration 433 : loss : 0.264581, loss_ce: 0.099596
2021-12-17 15:55:37,470 iteration 434 : loss : 0.244873, loss_ce: 0.094033
2021-12-17 15:55:38,823 iteration 435 : loss : 0.272657, loss_ce: 0.137275
2021-12-17 15:55:40,243 iteration 436 : loss : 0.305018, loss_ce: 0.127259
2021-12-17 15:55:41,648 iteration 437 : loss : 0.258794, loss_ce: 0.110735
2021-12-17 15:55:43,106 iteration 438 : loss : 0.280636, loss_ce: 0.141563
2021-12-17 15:55:44,586 iteration 439 : loss : 0.279706, loss_ce: 0.130717
2021-12-17 15:55:46,017 iteration 440 : loss : 0.268577, loss_ce: 0.110945
2021-12-17 15:55:47,469 iteration 441 : loss : 0.266958, loss_ce: 0.124190
2021-12-17 15:55:48,906 iteration 442 : loss : 0.291975, loss_ce: 0.107829
  6%|█▉                            | 26/400 [12:00<2:58:17, 28.60s/it]2021-12-17 15:55:50,427 iteration 443 : loss : 0.276615, loss_ce: 0.138151
2021-12-17 15:55:51,883 iteration 444 : loss : 0.260631, loss_ce: 0.107263
2021-12-17 15:55:53,515 iteration 445 : loss : 0.275880, loss_ce: 0.125011
2021-12-17 15:55:54,908 iteration 446 : loss : 0.292175, loss_ce: 0.103835
2021-12-17 15:55:56,448 iteration 447 : loss : 0.268315, loss_ce: 0.127969
2021-12-17 15:55:57,949 iteration 448 : loss : 0.278767, loss_ce: 0.121137
2021-12-17 15:55:59,379 iteration 449 : loss : 0.275224, loss_ce: 0.112515
2021-12-17 15:56:00,751 iteration 450 : loss : 0.266506, loss_ce: 0.120331
2021-12-17 15:56:02,198 iteration 451 : loss : 0.282472, loss_ce: 0.117643
2021-12-17 15:56:03,685 iteration 452 : loss : 0.259557, loss_ce: 0.109308
2021-12-17 15:56:05,161 iteration 453 : loss : 0.269667, loss_ce: 0.103346
2021-12-17 15:56:06,661 iteration 454 : loss : 0.253662, loss_ce: 0.093490
2021-12-17 15:56:08,188 iteration 455 : loss : 0.264557, loss_ce: 0.095442
2021-12-17 15:56:09,602 iteration 456 : loss : 0.267016, loss_ce: 0.104002
2021-12-17 15:56:11,019 iteration 457 : loss : 0.279901, loss_ce: 0.126499
2021-12-17 15:56:12,473 iteration 458 : loss : 0.262429, loss_ce: 0.120784
2021-12-17 15:56:13,951 iteration 459 : loss : 0.256724, loss_ce: 0.107032
  7%|██                            | 27/400 [12:25<2:51:11, 27.54s/it]2021-12-17 15:56:15,378 iteration 460 : loss : 0.271093, loss_ce: 0.103514
2021-12-17 15:56:16,856 iteration 461 : loss : 0.254836, loss_ce: 0.102078
2021-12-17 15:56:18,313 iteration 462 : loss : 0.264966, loss_ce: 0.089125
2021-12-17 15:56:19,681 iteration 463 : loss : 0.258366, loss_ce: 0.117119
2021-12-17 15:56:21,222 iteration 464 : loss : 0.274600, loss_ce: 0.110930
2021-12-17 15:56:22,663 iteration 465 : loss : 0.274719, loss_ce: 0.136481
2021-12-17 15:56:24,165 iteration 466 : loss : 0.248612, loss_ce: 0.101262
2021-12-17 15:56:25,584 iteration 467 : loss : 0.259886, loss_ce: 0.101635
2021-12-17 15:56:27,016 iteration 468 : loss : 0.280121, loss_ce: 0.113777
2021-12-17 15:56:28,414 iteration 469 : loss : 0.257549, loss_ce: 0.106958
2021-12-17 15:56:29,932 iteration 470 : loss : 0.272761, loss_ce: 0.121565
2021-12-17 15:56:31,357 iteration 471 : loss : 0.250402, loss_ce: 0.108176
2021-12-17 15:56:32,871 iteration 472 : loss : 0.263335, loss_ce: 0.109511
2021-12-17 15:56:34,368 iteration 473 : loss : 0.249777, loss_ce: 0.109747
2021-12-17 15:56:35,875 iteration 474 : loss : 0.256214, loss_ce: 0.102615
2021-12-17 15:56:37,338 iteration 475 : loss : 0.251445, loss_ce: 0.088194
2021-12-17 15:56:38,834 iteration 476 : loss : 0.256345, loss_ce: 0.121841
  7%|██                            | 28/400 [12:50<2:45:46, 26.74s/it]2021-12-17 15:56:40,302 iteration 477 : loss : 0.232739, loss_ce: 0.099937
2021-12-17 15:56:41,774 iteration 478 : loss : 0.242806, loss_ce: 0.095426
2021-12-17 15:56:43,156 iteration 479 : loss : 0.246112, loss_ce: 0.103019
2021-12-17 15:56:44,524 iteration 480 : loss : 0.249040, loss_ce: 0.105008
2021-12-17 15:56:45,973 iteration 481 : loss : 0.248820, loss_ce: 0.111891
2021-12-17 15:56:47,491 iteration 482 : loss : 0.260213, loss_ce: 0.102186
2021-12-17 15:56:48,956 iteration 483 : loss : 0.241235, loss_ce: 0.082725
2021-12-17 15:56:50,412 iteration 484 : loss : 0.244783, loss_ce: 0.099826
2021-12-17 15:56:51,805 iteration 485 : loss : 0.253627, loss_ce: 0.096546
2021-12-17 15:56:53,260 iteration 486 : loss : 0.293620, loss_ce: 0.100876
2021-12-17 15:56:54,756 iteration 487 : loss : 0.262876, loss_ce: 0.128595
2021-12-17 15:56:56,300 iteration 488 : loss : 0.278649, loss_ce: 0.120808
2021-12-17 15:56:57,773 iteration 489 : loss : 0.249489, loss_ce: 0.097948
2021-12-17 15:56:59,170 iteration 490 : loss : 0.260536, loss_ce: 0.104065
2021-12-17 15:57:00,667 iteration 491 : loss : 0.245138, loss_ce: 0.097353
2021-12-17 15:57:02,086 iteration 492 : loss : 0.253853, loss_ce: 0.114915
2021-12-17 15:57:03,520 iteration 493 : loss : 0.263738, loss_ce: 0.108411
  7%|██▏                           | 29/400 [13:15<2:41:31, 26.12s/it]2021-12-17 15:57:04,990 iteration 494 : loss : 0.283275, loss_ce: 0.109525
2021-12-17 15:57:06,455 iteration 495 : loss : 0.251845, loss_ce: 0.106411
2021-12-17 15:57:07,838 iteration 496 : loss : 0.255649, loss_ce: 0.116159
2021-12-17 15:57:09,346 iteration 497 : loss : 0.238901, loss_ce: 0.090245
2021-12-17 15:57:10,785 iteration 498 : loss : 0.264452, loss_ce: 0.117403
2021-12-17 15:57:12,316 iteration 499 : loss : 0.251920, loss_ce: 0.108004
2021-12-17 15:57:13,692 iteration 500 : loss : 0.242954, loss_ce: 0.097425
2021-12-17 15:57:15,156 iteration 501 : loss : 0.233505, loss_ce: 0.088376
2021-12-17 15:57:16,566 iteration 502 : loss : 0.265715, loss_ce: 0.094948
2021-12-17 15:57:17,995 iteration 503 : loss : 0.247883, loss_ce: 0.116557
2021-12-17 15:57:19,518 iteration 504 : loss : 0.236686, loss_ce: 0.095225
2021-12-17 15:57:21,049 iteration 505 : loss : 0.253327, loss_ce: 0.106731
2021-12-17 15:57:22,529 iteration 506 : loss : 0.260260, loss_ce: 0.123865
2021-12-17 15:57:23,973 iteration 507 : loss : 0.241284, loss_ce: 0.090569
2021-12-17 15:57:25,462 iteration 508 : loss : 0.236184, loss_ce: 0.082901
2021-12-17 15:57:26,966 iteration 509 : loss : 0.248178, loss_ce: 0.114616
2021-12-17 15:57:26,966 Training Data Eval:
2021-12-17 15:57:34,461   Average segmentation loss on training set: 0.2434
2021-12-17 15:57:34,461 Validation Data Eval:
2021-12-17 15:57:37,070   Average segmentation loss on validation set: 0.2468
2021-12-17 15:57:43,506 Found new lowest validation loss at iteration 509! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/TU_3seeds/TU_RESNET_no_pretraining_SGD_best_val_loss_seed2.pth
2021-12-17 15:57:44,870 iteration 510 : loss : 0.239885, loss_ce: 0.096659
  8%|██▎                           | 30/400 [13:56<3:09:16, 30.69s/it]2021-12-17 15:57:46,253 iteration 511 : loss : 0.218942, loss_ce: 0.083600
2021-12-17 15:57:47,613 iteration 512 : loss : 0.245547, loss_ce: 0.107403
2021-12-17 15:57:48,989 iteration 513 : loss : 0.234443, loss_ce: 0.096584
2021-12-17 15:57:50,396 iteration 514 : loss : 0.236058, loss_ce: 0.096829
2021-12-17 15:57:51,695 iteration 515 : loss : 0.249732, loss_ce: 0.107700
2021-12-17 15:57:52,958 iteration 516 : loss : 0.214208, loss_ce: 0.076964
2021-12-17 15:57:54,408 iteration 517 : loss : 0.252898, loss_ce: 0.114847
2021-12-17 15:57:55,876 iteration 518 : loss : 0.255292, loss_ce: 0.095864
2021-12-17 15:57:57,340 iteration 519 : loss : 0.262290, loss_ce: 0.122524
2021-12-17 15:57:58,730 iteration 520 : loss : 0.249987, loss_ce: 0.106272
2021-12-17 15:58:00,048 iteration 521 : loss : 0.219939, loss_ce: 0.082988
2021-12-17 15:58:01,526 iteration 522 : loss : 0.249558, loss_ce: 0.101406
2021-12-17 15:58:02,983 iteration 523 : loss : 0.242284, loss_ce: 0.080951
2021-12-17 15:58:04,434 iteration 524 : loss : 0.235261, loss_ce: 0.105933
2021-12-17 15:58:05,894 iteration 525 : loss : 0.219299, loss_ce: 0.092269
2021-12-17 15:58:07,388 iteration 526 : loss : 0.230022, loss_ce: 0.088520
2021-12-17 15:58:08,865 iteration 527 : loss : 0.259619, loss_ce: 0.102976
  8%|██▎                           | 31/400 [14:20<2:56:23, 28.68s/it]2021-12-17 15:58:10,345 iteration 528 : loss : 0.227519, loss_ce: 0.089656
2021-12-17 15:58:11,924 iteration 529 : loss : 0.237672, loss_ce: 0.076499
2021-12-17 15:58:13,369 iteration 530 : loss : 0.216737, loss_ce: 0.080361
2021-12-17 15:58:14,783 iteration 531 : loss : 0.225698, loss_ce: 0.088257
2021-12-17 15:58:16,274 iteration 532 : loss : 0.210689, loss_ce: 0.084272
2021-12-17 15:58:17,729 iteration 533 : loss : 0.217845, loss_ce: 0.086817
2021-12-17 15:58:19,163 iteration 534 : loss : 0.232780, loss_ce: 0.089130
2021-12-17 15:58:20,654 iteration 535 : loss : 0.240769, loss_ce: 0.096845
2021-12-17 15:58:22,116 iteration 536 : loss : 0.239286, loss_ce: 0.107492
2021-12-17 15:58:23,542 iteration 537 : loss : 0.216861, loss_ce: 0.086077
2021-12-17 15:58:24,987 iteration 538 : loss : 0.249165, loss_ce: 0.117017
2021-12-17 15:58:26,376 iteration 539 : loss : 0.231718, loss_ce: 0.094339
2021-12-17 15:58:27,958 iteration 540 : loss : 0.241320, loss_ce: 0.113280
2021-12-17 15:58:29,518 iteration 541 : loss : 0.239959, loss_ce: 0.106966
2021-12-17 15:58:30,934 iteration 542 : loss : 0.241003, loss_ce: 0.088443
2021-12-17 15:58:32,413 iteration 543 : loss : 0.242778, loss_ce: 0.101352
2021-12-17 15:58:33,874 iteration 544 : loss : 0.257649, loss_ce: 0.080678
  8%|██▍                           | 32/400 [14:45<2:49:09, 27.58s/it]2021-12-17 15:58:35,450 iteration 545 : loss : 0.221109, loss_ce: 0.089158
2021-12-17 15:58:36,957 iteration 546 : loss : 0.221509, loss_ce: 0.094950
2021-12-17 15:58:38,453 iteration 547 : loss : 0.244015, loss_ce: 0.094542
2021-12-17 15:58:39,838 iteration 548 : loss : 0.249721, loss_ce: 0.090204
2021-12-17 15:58:41,238 iteration 549 : loss : 0.223086, loss_ce: 0.091723
2021-12-17 15:58:42,660 iteration 550 : loss : 0.218447, loss_ce: 0.083096
2021-12-17 15:58:44,081 iteration 551 : loss : 0.231651, loss_ce: 0.076167
2021-12-17 15:58:45,575 iteration 552 : loss : 0.238124, loss_ce: 0.097170
2021-12-17 15:58:47,047 iteration 553 : loss : 0.222321, loss_ce: 0.086939
2021-12-17 15:58:48,512 iteration 554 : loss : 0.247823, loss_ce: 0.093131
2021-12-17 15:58:50,006 iteration 555 : loss : 0.219293, loss_ce: 0.075422
2021-12-17 15:58:51,537 iteration 556 : loss : 0.212444, loss_ce: 0.089172
2021-12-17 15:58:52,944 iteration 557 : loss : 0.213772, loss_ce: 0.097601
2021-12-17 15:58:54,336 iteration 558 : loss : 0.220660, loss_ce: 0.087367
2021-12-17 15:58:55,769 iteration 559 : loss : 0.243613, loss_ce: 0.094981
2021-12-17 15:58:57,285 iteration 560 : loss : 0.248978, loss_ce: 0.109460
2021-12-17 15:58:58,786 iteration 561 : loss : 0.234782, loss_ce: 0.106769
  8%|██▍                           | 33/400 [15:10<2:43:48, 26.78s/it]2021-12-17 15:59:00,320 iteration 562 : loss : 0.248779, loss_ce: 0.090056
2021-12-17 15:59:01,722 iteration 563 : loss : 0.203845, loss_ce: 0.091464
2021-12-17 15:59:03,150 iteration 564 : loss : 0.228355, loss_ce: 0.107494
2021-12-17 15:59:04,653 iteration 565 : loss : 0.228838, loss_ce: 0.098866
2021-12-17 15:59:06,127 iteration 566 : loss : 0.236812, loss_ce: 0.087804
2021-12-17 15:59:07,597 iteration 567 : loss : 0.253052, loss_ce: 0.091327
2021-12-17 15:59:09,054 iteration 568 : loss : 0.218985, loss_ce: 0.075307
2021-12-17 15:59:10,576 iteration 569 : loss : 0.251218, loss_ce: 0.075071
2021-12-17 15:59:12,042 iteration 570 : loss : 0.226724, loss_ce: 0.085983
2021-12-17 15:59:13,539 iteration 571 : loss : 0.233407, loss_ce: 0.100648
2021-12-17 15:59:15,056 iteration 572 : loss : 0.231262, loss_ce: 0.096920
2021-12-17 15:59:16,483 iteration 573 : loss : 0.211260, loss_ce: 0.085623
2021-12-17 15:59:18,028 iteration 574 : loss : 0.232873, loss_ce: 0.085235
2021-12-17 15:59:19,465 iteration 575 : loss : 0.207164, loss_ce: 0.066328
2021-12-17 15:59:20,858 iteration 576 : loss : 0.213419, loss_ce: 0.097489
2021-12-17 15:59:22,411 iteration 577 : loss : 0.230983, loss_ce: 0.099917
2021-12-17 15:59:23,890 iteration 578 : loss : 0.210594, loss_ce: 0.078954
  8%|██▌                           | 34/400 [15:35<2:40:16, 26.27s/it]2021-12-17 15:59:25,319 iteration 579 : loss : 0.204980, loss_ce: 0.083409
2021-12-17 15:59:26,826 iteration 580 : loss : 0.243003, loss_ce: 0.093650
2021-12-17 15:59:28,426 iteration 581 : loss : 0.210443, loss_ce: 0.083201
2021-12-17 15:59:29,821 iteration 582 : loss : 0.228003, loss_ce: 0.092784
2021-12-17 15:59:31,287 iteration 583 : loss : 0.215486, loss_ce: 0.094877
2021-12-17 15:59:32,781 iteration 584 : loss : 0.215082, loss_ce: 0.082146
2021-12-17 15:59:34,211 iteration 585 : loss : 0.234796, loss_ce: 0.085601
2021-12-17 15:59:35,693 iteration 586 : loss : 0.224263, loss_ce: 0.078794
2021-12-17 15:59:37,158 iteration 587 : loss : 0.220277, loss_ce: 0.095672
2021-12-17 15:59:38,581 iteration 588 : loss : 0.211777, loss_ce: 0.080342
2021-12-17 15:59:40,111 iteration 589 : loss : 0.214308, loss_ce: 0.094782
2021-12-17 15:59:41,542 iteration 590 : loss : 0.198326, loss_ce: 0.072786
2021-12-17 15:59:42,979 iteration 591 : loss : 0.224046, loss_ce: 0.087771
2021-12-17 15:59:44,473 iteration 592 : loss : 0.203708, loss_ce: 0.084848
2021-12-17 15:59:45,875 iteration 593 : loss : 0.226098, loss_ce: 0.095190
2021-12-17 15:59:47,383 iteration 594 : loss : 0.223078, loss_ce: 0.083534
2021-12-17 15:59:47,384 Training Data Eval:
2021-12-17 15:59:54,882   Average segmentation loss on training set: 0.1978
2021-12-17 15:59:54,883 Validation Data Eval:
2021-12-17 15:59:57,478   Average segmentation loss on validation set: 0.2279
2021-12-17 16:00:04,543 Found new lowest validation loss at iteration 594! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/TU_3seeds/TU_RESNET_no_pretraining_SGD_best_val_loss_seed2.pth
2021-12-17 16:00:05,945 iteration 595 : loss : 0.218337, loss_ce: 0.080497
  9%|██▋                           | 35/400 [16:17<3:08:38, 31.01s/it]2021-12-17 16:00:07,445 iteration 596 : loss : 0.201993, loss_ce: 0.079630
2021-12-17 16:00:08,819 iteration 597 : loss : 0.191672, loss_ce: 0.073346
2021-12-17 16:00:10,190 iteration 598 : loss : 0.221830, loss_ce: 0.077748
2021-12-17 16:00:11,619 iteration 599 : loss : 0.218629, loss_ce: 0.072354
2021-12-17 16:00:13,032 iteration 600 : loss : 0.213330, loss_ce: 0.074715
2021-12-17 16:00:14,432 iteration 601 : loss : 0.198160, loss_ce: 0.065675
2021-12-17 16:00:15,715 iteration 602 : loss : 0.228929, loss_ce: 0.089308
2021-12-17 16:00:17,068 iteration 603 : loss : 0.196444, loss_ce: 0.074946
2021-12-17 16:00:18,385 iteration 604 : loss : 0.236706, loss_ce: 0.074847
2021-12-17 16:00:19,839 iteration 605 : loss : 0.213317, loss_ce: 0.083926
2021-12-17 16:00:21,161 iteration 606 : loss : 0.189909, loss_ce: 0.074358
2021-12-17 16:00:22,487 iteration 607 : loss : 0.179586, loss_ce: 0.065416
2021-12-17 16:00:23,848 iteration 608 : loss : 0.190800, loss_ce: 0.077193
2021-12-17 16:00:25,257 iteration 609 : loss : 0.196949, loss_ce: 0.068339
2021-12-17 16:00:26,829 iteration 610 : loss : 0.223395, loss_ce: 0.098478
2021-12-17 16:00:28,290 iteration 611 : loss : 0.202347, loss_ce: 0.085839
2021-12-17 16:00:29,705 iteration 612 : loss : 0.178400, loss_ce: 0.068811
  9%|██▋                           | 36/400 [16:41<2:54:55, 28.83s/it]2021-12-17 16:00:31,218 iteration 613 : loss : 0.180883, loss_ce: 0.061713
2021-12-17 16:00:32,759 iteration 614 : loss : 0.177396, loss_ce: 0.071666
2021-12-17 16:00:34,244 iteration 615 : loss : 0.208253, loss_ce: 0.088393
2021-12-17 16:00:35,690 iteration 616 : loss : 0.223448, loss_ce: 0.074744
2021-12-17 16:00:37,171 iteration 617 : loss : 0.245340, loss_ce: 0.087570
2021-12-17 16:00:38,706 iteration 618 : loss : 0.199343, loss_ce: 0.083741
2021-12-17 16:00:40,199 iteration 619 : loss : 0.195356, loss_ce: 0.076081
2021-12-17 16:00:41,707 iteration 620 : loss : 0.187351, loss_ce: 0.070199
2021-12-17 16:00:43,078 iteration 621 : loss : 0.201610, loss_ce: 0.069713
2021-12-17 16:00:44,611 iteration 622 : loss : 0.196548, loss_ce: 0.073577
2021-12-17 16:00:46,140 iteration 623 : loss : 0.227584, loss_ce: 0.091736
2021-12-17 16:00:47,527 iteration 624 : loss : 0.207015, loss_ce: 0.080486
2021-12-17 16:00:49,094 iteration 625 : loss : 0.209649, loss_ce: 0.085453
2021-12-17 16:00:50,518 iteration 626 : loss : 0.233674, loss_ce: 0.089172
2021-12-17 16:00:51,903 iteration 627 : loss : 0.213126, loss_ce: 0.077395
2021-12-17 16:00:53,286 iteration 628 : loss : 0.214700, loss_ce: 0.077465
2021-12-17 16:00:54,779 iteration 629 : loss : 0.193289, loss_ce: 0.076072
  9%|██▊                           | 37/400 [17:06<2:47:37, 27.71s/it]2021-12-17 16:00:56,190 iteration 630 : loss : 0.194567, loss_ce: 0.081928
2021-12-17 16:00:57,649 iteration 631 : loss : 0.211401, loss_ce: 0.080668
2021-12-17 16:00:59,045 iteration 632 : loss : 0.191247, loss_ce: 0.073224
2021-12-17 16:01:00,536 iteration 633 : loss : 0.193955, loss_ce: 0.083488
2021-12-17 16:01:02,016 iteration 634 : loss : 0.184458, loss_ce: 0.070325
2021-12-17 16:01:03,509 iteration 635 : loss : 0.205386, loss_ce: 0.079708
2021-12-17 16:01:04,941 iteration 636 : loss : 0.220539, loss_ce: 0.067946
2021-12-17 16:01:06,356 iteration 637 : loss : 0.212139, loss_ce: 0.082516
2021-12-17 16:01:07,777 iteration 638 : loss : 0.190922, loss_ce: 0.076226
2021-12-17 16:01:09,267 iteration 639 : loss : 0.193324, loss_ce: 0.078607
2021-12-17 16:01:10,749 iteration 640 : loss : 0.213375, loss_ce: 0.071120
2021-12-17 16:01:12,145 iteration 641 : loss : 0.190349, loss_ce: 0.068804
2021-12-17 16:01:13,607 iteration 642 : loss : 0.180240, loss_ce: 0.060537
2021-12-17 16:01:15,045 iteration 643 : loss : 0.195780, loss_ce: 0.071750
2021-12-17 16:01:16,494 iteration 644 : loss : 0.184739, loss_ce: 0.058033
2021-12-17 16:01:17,928 iteration 645 : loss : 0.232176, loss_ce: 0.094343
2021-12-17 16:01:19,427 iteration 646 : loss : 0.217025, loss_ce: 0.086877
 10%|██▊                           | 38/400 [17:31<2:41:38, 26.79s/it]2021-12-17 16:01:20,891 iteration 647 : loss : 0.194264, loss_ce: 0.072455
2021-12-17 16:01:22,392 iteration 648 : loss : 0.234249, loss_ce: 0.096828
2021-12-17 16:01:23,864 iteration 649 : loss : 0.206856, loss_ce: 0.082448
2021-12-17 16:01:25,244 iteration 650 : loss : 0.193796, loss_ce: 0.082055
2021-12-17 16:01:26,701 iteration 651 : loss : 0.201219, loss_ce: 0.073749
2021-12-17 16:01:28,095 iteration 652 : loss : 0.196791, loss_ce: 0.068359
2021-12-17 16:01:29,548 iteration 653 : loss : 0.238868, loss_ce: 0.080061
2021-12-17 16:01:31,070 iteration 654 : loss : 0.207334, loss_ce: 0.073888
2021-12-17 16:01:32,562 iteration 655 : loss : 0.190351, loss_ce: 0.079461
2021-12-17 16:01:33,952 iteration 656 : loss : 0.187402, loss_ce: 0.071232
2021-12-17 16:01:35,406 iteration 657 : loss : 0.187646, loss_ce: 0.077812
2021-12-17 16:01:36,908 iteration 658 : loss : 0.242690, loss_ce: 0.071505
2021-12-17 16:01:38,404 iteration 659 : loss : 0.192183, loss_ce: 0.076766
2021-12-17 16:01:39,854 iteration 660 : loss : 0.203018, loss_ce: 0.066937
2021-12-17 16:01:41,291 iteration 661 : loss : 0.197015, loss_ce: 0.080889
2021-12-17 16:01:42,693 iteration 662 : loss : 0.183943, loss_ce: 0.077932
2021-12-17 16:01:44,141 iteration 663 : loss : 0.188577, loss_ce: 0.058548
 10%|██▉                           | 39/400 [17:56<2:37:26, 26.17s/it]2021-12-17 16:01:45,607 iteration 664 : loss : 0.205492, loss_ce: 0.089446
2021-12-17 16:01:47,048 iteration 665 : loss : 0.184830, loss_ce: 0.072689
2021-12-17 16:01:48,512 iteration 666 : loss : 0.189103, loss_ce: 0.073472
2021-12-17 16:01:49,920 iteration 667 : loss : 0.179947, loss_ce: 0.065682
2021-12-17 16:01:51,436 iteration 668 : loss : 0.182391, loss_ce: 0.065439
2021-12-17 16:01:52,858 iteration 669 : loss : 0.178600, loss_ce: 0.069252
2021-12-17 16:01:54,292 iteration 670 : loss : 0.190751, loss_ce: 0.075652
2021-12-17 16:01:55,792 iteration 671 : loss : 0.185308, loss_ce: 0.060113
2021-12-17 16:01:57,291 iteration 672 : loss : 0.170106, loss_ce: 0.056150
2021-12-17 16:01:58,691 iteration 673 : loss : 0.188637, loss_ce: 0.079055
2021-12-17 16:02:00,160 iteration 674 : loss : 0.198841, loss_ce: 0.071401
2021-12-17 16:02:01,646 iteration 675 : loss : 0.197207, loss_ce: 0.070132
2021-12-17 16:02:03,068 iteration 676 : loss : 0.190301, loss_ce: 0.060411
2021-12-17 16:02:04,519 iteration 677 : loss : 0.188779, loss_ce: 0.075518
2021-12-17 16:02:05,957 iteration 678 : loss : 0.193493, loss_ce: 0.065048
2021-12-17 16:02:07,351 iteration 679 : loss : 0.208928, loss_ce: 0.088545
2021-12-17 16:02:07,352 Training Data Eval:
2021-12-17 16:02:14,845   Average segmentation loss on training set: 0.1755
2021-12-17 16:02:14,845 Validation Data Eval:
2021-12-17 16:02:17,443   Average segmentation loss on validation set: 0.2055
2021-12-17 16:02:23,750 Found new lowest validation loss at iteration 679! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/TU_3seeds/TU_RESNET_no_pretraining_SGD_best_val_loss_seed2.pth
2021-12-17 16:02:25,170 iteration 680 : loss : 0.219539, loss_ce: 0.055513
 10%|███                           | 40/400 [18:37<3:03:44, 30.62s/it]2021-12-17 16:02:26,634 iteration 681 : loss : 0.207746, loss_ce: 0.085577
2021-12-17 16:02:27,951 iteration 682 : loss : 0.184974, loss_ce: 0.061791
2021-12-17 16:02:29,335 iteration 683 : loss : 0.183080, loss_ce: 0.073460
2021-12-17 16:02:30,728 iteration 684 : loss : 0.167329, loss_ce: 0.059388
2021-12-17 16:02:32,149 iteration 685 : loss : 0.183702, loss_ce: 0.065020
2021-12-17 16:02:33,426 iteration 686 : loss : 0.182359, loss_ce: 0.062532
2021-12-17 16:02:34,747 iteration 687 : loss : 0.169276, loss_ce: 0.060423
2021-12-17 16:02:36,177 iteration 688 : loss : 0.196269, loss_ce: 0.077520
2021-12-17 16:02:37,558 iteration 689 : loss : 0.178282, loss_ce: 0.069332
2021-12-17 16:02:38,885 iteration 690 : loss : 0.208272, loss_ce: 0.099842
2021-12-17 16:02:40,357 iteration 691 : loss : 0.192832, loss_ce: 0.077801
2021-12-17 16:02:41,842 iteration 692 : loss : 0.197271, loss_ce: 0.064265
2021-12-17 16:02:43,366 iteration 693 : loss : 0.194062, loss_ce: 0.075965
2021-12-17 16:02:44,851 iteration 694 : loss : 0.183210, loss_ce: 0.066840
2021-12-17 16:02:46,326 iteration 695 : loss : 0.179608, loss_ce: 0.059038
2021-12-17 16:02:47,790 iteration 696 : loss : 0.191697, loss_ce: 0.072931
2021-12-17 16:02:49,278 iteration 697 : loss : 0.201586, loss_ce: 0.067021
 10%|███                           | 41/400 [19:01<2:51:32, 28.67s/it]2021-12-17 16:02:50,743 iteration 698 : loss : 0.187083, loss_ce: 0.072361
2021-12-17 16:02:52,182 iteration 699 : loss : 0.181166, loss_ce: 0.058585
2021-12-17 16:02:53,638 iteration 700 : loss : 0.176664, loss_ce: 0.064141
2021-12-17 16:02:55,085 iteration 701 : loss : 0.164937, loss_ce: 0.061273
2021-12-17 16:02:56,580 iteration 702 : loss : 0.197511, loss_ce: 0.065460
2021-12-17 16:02:58,044 iteration 703 : loss : 0.176226, loss_ce: 0.062801
2021-12-17 16:02:59,508 iteration 704 : loss : 0.226472, loss_ce: 0.068167
2021-12-17 16:03:00,940 iteration 705 : loss : 0.200554, loss_ce: 0.077668
2021-12-17 16:03:02,457 iteration 706 : loss : 0.173043, loss_ce: 0.061413
2021-12-17 16:03:03,937 iteration 707 : loss : 0.183184, loss_ce: 0.072068
2021-12-17 16:03:05,400 iteration 708 : loss : 0.184358, loss_ce: 0.064735
2021-12-17 16:03:06,877 iteration 709 : loss : 0.179761, loss_ce: 0.066416
2021-12-17 16:03:08,337 iteration 710 : loss : 0.175809, loss_ce: 0.059368
2021-12-17 16:03:09,844 iteration 711 : loss : 0.202415, loss_ce: 0.072757
2021-12-17 16:03:11,362 iteration 712 : loss : 0.187112, loss_ce: 0.080174
2021-12-17 16:03:12,801 iteration 713 : loss : 0.181177, loss_ce: 0.071491
2021-12-17 16:03:14,257 iteration 714 : loss : 0.175789, loss_ce: 0.067023
 10%|███▏                          | 42/400 [19:26<2:44:28, 27.56s/it]2021-12-17 16:03:15,757 iteration 715 : loss : 0.175036, loss_ce: 0.069940
2021-12-17 16:03:17,215 iteration 716 : loss : 0.183381, loss_ce: 0.055551
2021-12-17 16:03:18,648 iteration 717 : loss : 0.175771, loss_ce: 0.061220
2021-12-17 16:03:20,011 iteration 718 : loss : 0.179422, loss_ce: 0.064125
2021-12-17 16:03:21,455 iteration 719 : loss : 0.189214, loss_ce: 0.075842
2021-12-17 16:03:22,824 iteration 720 : loss : 0.186206, loss_ce: 0.069438
2021-12-17 16:03:24,394 iteration 721 : loss : 0.187550, loss_ce: 0.061021
2021-12-17 16:03:25,846 iteration 722 : loss : 0.162114, loss_ce: 0.060957
2021-12-17 16:03:27,318 iteration 723 : loss : 0.184594, loss_ce: 0.063008
2021-12-17 16:03:28,848 iteration 724 : loss : 0.198145, loss_ce: 0.075178
2021-12-17 16:03:30,248 iteration 725 : loss : 0.175410, loss_ce: 0.062185
2021-12-17 16:03:31,713 iteration 726 : loss : 0.166418, loss_ce: 0.067402
2021-12-17 16:03:33,136 iteration 727 : loss : 0.167409, loss_ce: 0.059140
2021-12-17 16:03:34,575 iteration 728 : loss : 0.177049, loss_ce: 0.058705
2021-12-17 16:03:36,010 iteration 729 : loss : 0.198763, loss_ce: 0.083695
2021-12-17 16:03:37,485 iteration 730 : loss : 0.185368, loss_ce: 0.065368
2021-12-17 16:03:38,908 iteration 731 : loss : 0.200715, loss_ce: 0.067806
 11%|███▏                          | 43/400 [19:50<2:38:48, 26.69s/it]2021-12-17 16:03:40,416 iteration 732 : loss : 0.169013, loss_ce: 0.066315
2021-12-17 16:03:41,888 iteration 733 : loss : 0.179082, loss_ce: 0.065613
2021-12-17 16:03:43,375 iteration 734 : loss : 0.196477, loss_ce: 0.080518
2021-12-17 16:03:44,859 iteration 735 : loss : 0.180357, loss_ce: 0.061255
2021-12-17 16:03:46,323 iteration 736 : loss : 0.166911, loss_ce: 0.061345
2021-12-17 16:03:47,709 iteration 737 : loss : 0.165342, loss_ce: 0.053725
2021-12-17 16:03:49,236 iteration 738 : loss : 0.201614, loss_ce: 0.075128
2021-12-17 16:03:50,716 iteration 739 : loss : 0.195606, loss_ce: 0.085027
2021-12-17 16:03:52,169 iteration 740 : loss : 0.156210, loss_ce: 0.050407
2021-12-17 16:03:53,652 iteration 741 : loss : 0.186640, loss_ce: 0.074266
2021-12-17 16:03:55,119 iteration 742 : loss : 0.189506, loss_ce: 0.069340
2021-12-17 16:03:56,543 iteration 743 : loss : 0.174411, loss_ce: 0.056100
2021-12-17 16:03:58,012 iteration 744 : loss : 0.182014, loss_ce: 0.067427
2021-12-17 16:03:59,474 iteration 745 : loss : 0.156642, loss_ce: 0.053708
2021-12-17 16:04:00,901 iteration 746 : loss : 0.208323, loss_ce: 0.058372
2021-12-17 16:04:02,349 iteration 747 : loss : 0.180084, loss_ce: 0.074220
2021-12-17 16:04:03,822 iteration 748 : loss : 0.170166, loss_ce: 0.053831
 11%|███▎                          | 44/400 [20:15<2:35:10, 26.15s/it]2021-12-17 16:04:05,286 iteration 749 : loss : 0.195288, loss_ce: 0.066395
2021-12-17 16:04:06,709 iteration 750 : loss : 0.174834, loss_ce: 0.050249
2021-12-17 16:04:08,197 iteration 751 : loss : 0.181184, loss_ce: 0.064460
2021-12-17 16:04:09,617 iteration 752 : loss : 0.159524, loss_ce: 0.055929
2021-12-17 16:04:11,097 iteration 753 : loss : 0.176463, loss_ce: 0.063169
2021-12-17 16:04:12,539 iteration 754 : loss : 0.190509, loss_ce: 0.064904
2021-12-17 16:04:14,000 iteration 755 : loss : 0.181817, loss_ce: 0.066961
2021-12-17 16:04:15,374 iteration 756 : loss : 0.153085, loss_ce: 0.054178
2021-12-17 16:04:16,765 iteration 757 : loss : 0.166006, loss_ce: 0.056576
2021-12-17 16:04:18,220 iteration 758 : loss : 0.198630, loss_ce: 0.065490
2021-12-17 16:04:19,725 iteration 759 : loss : 0.197060, loss_ce: 0.064323
2021-12-17 16:04:21,205 iteration 760 : loss : 0.168684, loss_ce: 0.058160
2021-12-17 16:04:22,701 iteration 761 : loss : 0.164748, loss_ce: 0.055012
2021-12-17 16:04:24,074 iteration 762 : loss : 0.163501, loss_ce: 0.060234
2021-12-17 16:04:25,532 iteration 763 : loss : 0.173376, loss_ce: 0.069418
2021-12-17 16:04:26,909 iteration 764 : loss : 0.155833, loss_ce: 0.054632
2021-12-17 16:04:26,910 Training Data Eval:
2021-12-17 16:04:34,423   Average segmentation loss on training set: 0.1714
2021-12-17 16:04:34,423 Validation Data Eval:
2021-12-17 16:04:37,025   Average segmentation loss on validation set: 0.1983
2021-12-17 16:04:43,364 Found new lowest validation loss at iteration 764! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/TU_3seeds/TU_RESNET_no_pretraining_SGD_best_val_loss_seed2.pth
2021-12-17 16:04:44,658 iteration 765 : loss : 0.175376, loss_ce: 0.066912
 11%|███▍                          | 45/400 [20:56<3:00:48, 30.56s/it]2021-12-17 16:04:46,144 iteration 766 : loss : 0.169586, loss_ce: 0.061906
2021-12-17 16:04:47,661 iteration 767 : loss : 0.157057, loss_ce: 0.056530
2021-12-17 16:04:49,075 iteration 768 : loss : 0.185393, loss_ce: 0.067555
2021-12-17 16:04:50,492 iteration 769 : loss : 0.173010, loss_ce: 0.064300
2021-12-17 16:04:51,953 iteration 770 : loss : 0.171296, loss_ce: 0.069656
2021-12-17 16:04:53,361 iteration 771 : loss : 0.158047, loss_ce: 0.062650
2021-12-17 16:04:54,679 iteration 772 : loss : 0.170667, loss_ce: 0.063838
2021-12-17 16:04:56,049 iteration 773 : loss : 0.183304, loss_ce: 0.059794
2021-12-17 16:04:57,507 iteration 774 : loss : 0.155723, loss_ce: 0.052376
2021-12-17 16:04:58,816 iteration 775 : loss : 0.160897, loss_ce: 0.060417
2021-12-17 16:05:00,168 iteration 776 : loss : 0.173427, loss_ce: 0.045715
2021-12-17 16:05:01,668 iteration 777 : loss : 0.194968, loss_ce: 0.074340
2021-12-17 16:05:03,089 iteration 778 : loss : 0.180019, loss_ce: 0.061546
2021-12-17 16:05:04,547 iteration 779 : loss : 0.183406, loss_ce: 0.054715
2021-12-17 16:05:06,105 iteration 780 : loss : 0.192086, loss_ce: 0.064876
2021-12-17 16:05:07,604 iteration 781 : loss : 0.164871, loss_ce: 0.049754
2021-12-17 16:05:09,035 iteration 782 : loss : 0.166934, loss_ce: 0.052610
 12%|███▍                          | 46/400 [21:20<2:49:21, 28.70s/it]2021-12-17 16:05:10,525 iteration 783 : loss : 0.184429, loss_ce: 0.068768
2021-12-17 16:05:11,931 iteration 784 : loss : 0.161496, loss_ce: 0.049066
2021-12-17 16:05:13,439 iteration 785 : loss : 0.160524, loss_ce: 0.053335
2021-12-17 16:05:14,880 iteration 786 : loss : 0.166617, loss_ce: 0.056982
2021-12-17 16:05:16,368 iteration 787 : loss : 0.176211, loss_ce: 0.064124
2021-12-17 16:05:17,766 iteration 788 : loss : 0.161364, loss_ce: 0.063291
2021-12-17 16:05:19,264 iteration 789 : loss : 0.170579, loss_ce: 0.058210
2021-12-17 16:05:20,778 iteration 790 : loss : 0.171574, loss_ce: 0.060972
2021-12-17 16:05:22,178 iteration 791 : loss : 0.155601, loss_ce: 0.060276
2021-12-17 16:05:23,702 iteration 792 : loss : 0.159220, loss_ce: 0.054991
2021-12-17 16:05:25,168 iteration 793 : loss : 0.173734, loss_ce: 0.059457
2021-12-17 16:05:26,645 iteration 794 : loss : 0.157233, loss_ce: 0.055284
2021-12-17 16:05:28,147 iteration 795 : loss : 0.170345, loss_ce: 0.057629
2021-12-17 16:05:29,709 iteration 796 : loss : 0.173779, loss_ce: 0.062392
2021-12-17 16:05:31,152 iteration 797 : loss : 0.147405, loss_ce: 0.053071
2021-12-17 16:05:32,606 iteration 798 : loss : 0.161196, loss_ce: 0.056063
2021-12-17 16:05:34,154 iteration 799 : loss : 0.198648, loss_ce: 0.058998
 12%|███▌                          | 47/400 [21:46<2:42:33, 27.63s/it]2021-12-17 16:05:35,652 iteration 800 : loss : 0.162810, loss_ce: 0.067465
2021-12-17 16:05:37,067 iteration 801 : loss : 0.180391, loss_ce: 0.054779
2021-12-17 16:05:38,546 iteration 802 : loss : 0.171899, loss_ce: 0.070380
2021-12-17 16:05:39,920 iteration 803 : loss : 0.155465, loss_ce: 0.053744
2021-12-17 16:05:41,456 iteration 804 : loss : 0.184936, loss_ce: 0.049928
2021-12-17 16:05:42,908 iteration 805 : loss : 0.176697, loss_ce: 0.066493
2021-12-17 16:05:44,312 iteration 806 : loss : 0.169578, loss_ce: 0.058146
2021-12-17 16:05:45,793 iteration 807 : loss : 0.156752, loss_ce: 0.064457
2021-12-17 16:05:47,238 iteration 808 : loss : 0.175155, loss_ce: 0.045491
2021-12-17 16:05:48,734 iteration 809 : loss : 0.174545, loss_ce: 0.062856
2021-12-17 16:05:50,133 iteration 810 : loss : 0.149030, loss_ce: 0.045512
2021-12-17 16:05:51,595 iteration 811 : loss : 0.183110, loss_ce: 0.065165
2021-12-17 16:05:52,996 iteration 812 : loss : 0.166332, loss_ce: 0.065521
2021-12-17 16:05:54,521 iteration 813 : loss : 0.178010, loss_ce: 0.070770
2021-12-17 16:05:56,074 iteration 814 : loss : 0.224652, loss_ce: 0.056661
2021-12-17 16:05:57,397 iteration 815 : loss : 0.151705, loss_ce: 0.059246
2021-12-17 16:05:58,905 iteration 816 : loss : 0.167023, loss_ce: 0.063341
 12%|███▌                          | 48/400 [22:10<2:37:01, 26.77s/it]2021-12-17 16:06:00,357 iteration 817 : loss : 0.175921, loss_ce: 0.061485
2021-12-17 16:06:01,779 iteration 818 : loss : 0.179669, loss_ce: 0.071960
2021-12-17 16:06:03,337 iteration 819 : loss : 0.171063, loss_ce: 0.073407
2021-12-17 16:06:04,838 iteration 820 : loss : 0.175279, loss_ce: 0.060841
2021-12-17 16:06:06,336 iteration 821 : loss : 0.179598, loss_ce: 0.060938
2021-12-17 16:06:07,773 iteration 822 : loss : 0.159306, loss_ce: 0.057271
2021-12-17 16:06:09,234 iteration 823 : loss : 0.165230, loss_ce: 0.051419
2021-12-17 16:06:10,624 iteration 824 : loss : 0.172060, loss_ce: 0.049152
2021-12-17 16:06:12,078 iteration 825 : loss : 0.176284, loss_ce: 0.048772
2021-12-17 16:06:13,474 iteration 826 : loss : 0.153024, loss_ce: 0.047131
2021-12-17 16:06:14,929 iteration 827 : loss : 0.170321, loss_ce: 0.056562
2021-12-17 16:06:16,313 iteration 828 : loss : 0.155665, loss_ce: 0.048963
2021-12-17 16:06:17,841 iteration 829 : loss : 0.211733, loss_ce: 0.084791
2021-12-17 16:06:19,258 iteration 830 : loss : 0.173349, loss_ce: 0.064949
2021-12-17 16:06:20,750 iteration 831 : loss : 0.206214, loss_ce: 0.081708
2021-12-17 16:06:22,216 iteration 832 : loss : 0.167888, loss_ce: 0.047115
2021-12-17 16:06:23,671 iteration 833 : loss : 0.171903, loss_ce: 0.063775
 12%|███▋                          | 49/400 [22:35<2:33:04, 26.17s/it]2021-12-17 16:06:25,085 iteration 834 : loss : 0.165710, loss_ce: 0.058020
2021-12-17 16:06:26,464 iteration 835 : loss : 0.175020, loss_ce: 0.061635
2021-12-17 16:06:27,992 iteration 836 : loss : 0.161599, loss_ce: 0.052976
2021-12-17 16:06:29,408 iteration 837 : loss : 0.160499, loss_ce: 0.056598
2021-12-17 16:06:30,883 iteration 838 : loss : 0.193171, loss_ce: 0.077165
2021-12-17 16:06:32,249 iteration 839 : loss : 0.174077, loss_ce: 0.060849
2021-12-17 16:06:33,626 iteration 840 : loss : 0.154949, loss_ce: 0.057297
2021-12-17 16:06:35,013 iteration 841 : loss : 0.153433, loss_ce: 0.052493
2021-12-17 16:06:36,541 iteration 842 : loss : 0.200443, loss_ce: 0.066024
2021-12-17 16:06:37,959 iteration 843 : loss : 0.165341, loss_ce: 0.052503
2021-12-17 16:06:39,450 iteration 844 : loss : 0.155508, loss_ce: 0.052033
2021-12-17 16:06:40,876 iteration 845 : loss : 0.171480, loss_ce: 0.067680
2021-12-17 16:06:42,315 iteration 846 : loss : 0.183698, loss_ce: 0.072840
2021-12-17 16:06:43,840 iteration 847 : loss : 0.169929, loss_ce: 0.056290
2021-12-17 16:06:45,254 iteration 848 : loss : 0.169657, loss_ce: 0.062271
2021-12-17 16:06:46,658 iteration 849 : loss : 0.154306, loss_ce: 0.053409
2021-12-17 16:06:46,658 Training Data Eval:
2021-12-17 16:06:54,168   Average segmentation loss on training set: 0.1486
2021-12-17 16:06:54,168 Validation Data Eval:
2021-12-17 16:06:56,761   Average segmentation loss on validation set: 0.1914
2021-12-17 16:07:03,119 Found new lowest validation loss at iteration 849! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/TU_3seeds/TU_RESNET_no_pretraining_SGD_best_val_loss_seed2.pth
2021-12-17 16:07:04,444 iteration 850 : loss : 0.162752, loss_ce: 0.068535
 12%|███▊                          | 50/400 [23:16<2:58:11, 30.55s/it]2021-12-17 16:07:05,835 iteration 851 : loss : 0.154177, loss_ce: 0.057866
2021-12-17 16:07:07,185 iteration 852 : loss : 0.179421, loss_ce: 0.062593
2021-12-17 16:07:08,573 iteration 853 : loss : 0.162837, loss_ce: 0.047332
2021-12-17 16:07:09,969 iteration 854 : loss : 0.167053, loss_ce: 0.064878
2021-12-17 16:07:11,303 iteration 855 : loss : 0.140261, loss_ce: 0.050733
2021-12-17 16:07:12,707 iteration 856 : loss : 0.171552, loss_ce: 0.067173
2021-12-17 16:07:14,065 iteration 857 : loss : 0.189498, loss_ce: 0.076202
2021-12-17 16:07:15,530 iteration 858 : loss : 0.134098, loss_ce: 0.043302
2021-12-17 16:07:16,770 iteration 859 : loss : 0.141670, loss_ce: 0.041541
2021-12-17 16:07:18,120 iteration 860 : loss : 0.139680, loss_ce: 0.044868
2021-12-17 16:07:19,491 iteration 861 : loss : 0.147151, loss_ce: 0.042457
2021-12-17 16:07:20,921 iteration 862 : loss : 0.168258, loss_ce: 0.064811
2021-12-17 16:07:22,363 iteration 863 : loss : 0.198261, loss_ce: 0.060562
2021-12-17 16:07:23,804 iteration 864 : loss : 0.150860, loss_ce: 0.052697
2021-12-17 16:07:25,268 iteration 865 : loss : 0.149379, loss_ce: 0.047052
2021-12-17 16:07:26,680 iteration 866 : loss : 0.146238, loss_ce: 0.052092
2021-12-17 16:07:28,180 iteration 867 : loss : 0.156265, loss_ce: 0.052457
 13%|███▊                          | 51/400 [23:40<2:45:48, 28.51s/it]2021-12-17 16:07:29,676 iteration 868 : loss : 0.155691, loss_ce: 0.051419
2021-12-17 16:07:31,187 iteration 869 : loss : 0.184552, loss_ce: 0.073623
2021-12-17 16:07:32,554 iteration 870 : loss : 0.153842, loss_ce: 0.053718
2021-12-17 16:07:33,992 iteration 871 : loss : 0.166213, loss_ce: 0.060626
2021-12-17 16:07:35,433 iteration 872 : loss : 0.164288, loss_ce: 0.060902
2021-12-17 16:07:36,909 iteration 873 : loss : 0.163344, loss_ce: 0.059556
2021-12-17 16:07:38,361 iteration 874 : loss : 0.156106, loss_ce: 0.054439
2021-12-17 16:07:39,819 iteration 875 : loss : 0.152686, loss_ce: 0.043977
2021-12-17 16:07:41,295 iteration 876 : loss : 0.142801, loss_ce: 0.044364
2021-12-17 16:07:42,800 iteration 877 : loss : 0.148304, loss_ce: 0.048723
2021-12-17 16:07:44,204 iteration 878 : loss : 0.186299, loss_ce: 0.050879
2021-12-17 16:07:45,643 iteration 879 : loss : 0.199831, loss_ce: 0.051831
2021-12-17 16:07:47,061 iteration 880 : loss : 0.145227, loss_ce: 0.052158
2021-12-17 16:07:48,569 iteration 881 : loss : 0.174975, loss_ce: 0.055124
2021-12-17 16:07:50,048 iteration 882 : loss : 0.140885, loss_ce: 0.047517
2021-12-17 16:07:51,468 iteration 883 : loss : 0.143189, loss_ce: 0.043002
2021-12-17 16:07:52,966 iteration 884 : loss : 0.158869, loss_ce: 0.057733
 13%|███▉                          | 52/400 [24:04<2:38:51, 27.39s/it]2021-12-17 16:07:54,456 iteration 885 : loss : 0.165121, loss_ce: 0.060380
2021-12-17 16:07:55,890 iteration 886 : loss : 0.190941, loss_ce: 0.080454
2021-12-17 16:07:57,337 iteration 887 : loss : 0.161996, loss_ce: 0.058465
2021-12-17 16:07:58,791 iteration 888 : loss : 0.183762, loss_ce: 0.072738
2021-12-17 16:08:00,242 iteration 889 : loss : 0.183650, loss_ce: 0.044704
2021-12-17 16:08:01,673 iteration 890 : loss : 0.153902, loss_ce: 0.047303
2021-12-17 16:08:03,126 iteration 891 : loss : 0.160755, loss_ce: 0.070567
2021-12-17 16:08:04,580 iteration 892 : loss : 0.141768, loss_ce: 0.050630
2021-12-17 16:08:06,033 iteration 893 : loss : 0.150821, loss_ce: 0.058271
2021-12-17 16:08:07,479 iteration 894 : loss : 0.141128, loss_ce: 0.044131
2021-12-17 16:08:08,917 iteration 895 : loss : 0.144621, loss_ce: 0.039672
2021-12-17 16:08:10,326 iteration 896 : loss : 0.140285, loss_ce: 0.048063
2021-12-17 16:08:11,911 iteration 897 : loss : 0.198854, loss_ce: 0.067413
2021-12-17 16:08:13,335 iteration 898 : loss : 0.167992, loss_ce: 0.055494
2021-12-17 16:08:14,816 iteration 899 : loss : 0.176798, loss_ce: 0.057129
2021-12-17 16:08:16,299 iteration 900 : loss : 0.148506, loss_ce: 0.042645
2021-12-17 16:08:17,743 iteration 901 : loss : 0.161274, loss_ce: 0.051856
 13%|███▉                          | 53/400 [24:29<2:33:52, 26.61s/it]2021-12-17 16:08:19,322 iteration 902 : loss : 0.164867, loss_ce: 0.068731
2021-12-17 16:08:20,800 iteration 903 : loss : 0.170938, loss_ce: 0.050501
2021-12-17 16:08:22,232 iteration 904 : loss : 0.147844, loss_ce: 0.054183
2021-12-17 16:08:23,678 iteration 905 : loss : 0.171639, loss_ce: 0.064415
2021-12-17 16:08:25,216 iteration 906 : loss : 0.168542, loss_ce: 0.057254
2021-12-17 16:08:26,617 iteration 907 : loss : 0.142093, loss_ce: 0.050490
2021-12-17 16:08:28,033 iteration 908 : loss : 0.143837, loss_ce: 0.057610
2021-12-17 16:08:29,503 iteration 909 : loss : 0.173307, loss_ce: 0.067791
2021-12-17 16:08:31,013 iteration 910 : loss : 0.170458, loss_ce: 0.062004
2021-12-17 16:08:32,460 iteration 911 : loss : 0.152306, loss_ce: 0.050736
2021-12-17 16:08:33,950 iteration 912 : loss : 0.165537, loss_ce: 0.054138
2021-12-17 16:08:35,391 iteration 913 : loss : 0.154142, loss_ce: 0.044447
2021-12-17 16:08:36,767 iteration 914 : loss : 0.176410, loss_ce: 0.060570
2021-12-17 16:08:38,236 iteration 915 : loss : 0.178503, loss_ce: 0.064914
2021-12-17 16:08:39,737 iteration 916 : loss : 0.147390, loss_ce: 0.041690
2021-12-17 16:08:41,190 iteration 917 : loss : 0.153605, loss_ce: 0.056104
2021-12-17 16:08:42,698 iteration 918 : loss : 0.176977, loss_ce: 0.052591
 14%|████                          | 54/400 [24:54<2:30:34, 26.11s/it]2021-12-17 16:08:44,170 iteration 919 : loss : 0.150836, loss_ce: 0.045270
2021-12-17 16:08:45,690 iteration 920 : loss : 0.167132, loss_ce: 0.066948
2021-12-17 16:08:47,068 iteration 921 : loss : 0.141655, loss_ce: 0.050184
2021-12-17 16:08:48,531 iteration 922 : loss : 0.161423, loss_ce: 0.045366
2021-12-17 16:08:49,930 iteration 923 : loss : 0.136450, loss_ce: 0.040932
2021-12-17 16:08:51,407 iteration 924 : loss : 0.181599, loss_ce: 0.055750
2021-12-17 16:08:52,871 iteration 925 : loss : 0.154931, loss_ce: 0.040205
2021-12-17 16:08:54,350 iteration 926 : loss : 0.150349, loss_ce: 0.043350
2021-12-17 16:08:55,724 iteration 927 : loss : 0.156514, loss_ce: 0.042625
2021-12-17 16:08:57,229 iteration 928 : loss : 0.155328, loss_ce: 0.057208
2021-12-17 16:08:58,666 iteration 929 : loss : 0.144392, loss_ce: 0.045407
2021-12-17 16:09:00,052 iteration 930 : loss : 0.151440, loss_ce: 0.051305
2021-12-17 16:09:01,465 iteration 931 : loss : 0.187232, loss_ce: 0.085051
2021-12-17 16:09:02,913 iteration 932 : loss : 0.144781, loss_ce: 0.054304
2021-12-17 16:09:04,404 iteration 933 : loss : 0.167606, loss_ce: 0.065541
2021-12-17 16:09:05,832 iteration 934 : loss : 0.149671, loss_ce: 0.046157
2021-12-17 16:09:05,832 Training Data Eval:
2021-12-17 16:09:13,324   Average segmentation loss on training set: 0.1391
2021-12-17 16:09:13,325 Validation Data Eval:
2021-12-17 16:09:15,928   Average segmentation loss on validation set: 0.1854
2021-12-17 16:09:22,491 Found new lowest validation loss at iteration 934! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/TU_3seeds/TU_RESNET_no_pretraining_SGD_best_val_loss_seed2.pth
2021-12-17 16:09:23,898 iteration 935 : loss : 0.162765, loss_ce: 0.057872
 14%|████▏                         | 55/400 [25:35<2:56:09, 30.64s/it]2021-12-17 16:09:25,304 iteration 936 : loss : 0.147959, loss_ce: 0.049241
2021-12-17 16:09:26,661 iteration 937 : loss : 0.163790, loss_ce: 0.059686
2021-12-17 16:09:28,052 iteration 938 : loss : 0.152954, loss_ce: 0.053547
2021-12-17 16:09:29,506 iteration 939 : loss : 0.168185, loss_ce: 0.048437
2021-12-17 16:09:30,807 iteration 940 : loss : 0.158043, loss_ce: 0.058743
2021-12-17 16:09:32,152 iteration 941 : loss : 0.159449, loss_ce: 0.051539
2021-12-17 16:09:33,522 iteration 942 : loss : 0.139324, loss_ce: 0.051729
2021-12-17 16:09:34,904 iteration 943 : loss : 0.163853, loss_ce: 0.044871
2021-12-17 16:09:36,265 iteration 944 : loss : 0.174325, loss_ce: 0.054049
2021-12-17 16:09:37,653 iteration 945 : loss : 0.149776, loss_ce: 0.051021
2021-12-17 16:09:39,007 iteration 946 : loss : 0.162450, loss_ce: 0.056627
2021-12-17 16:09:40,435 iteration 947 : loss : 0.152500, loss_ce: 0.044843
2021-12-17 16:09:41,981 iteration 948 : loss : 0.155289, loss_ce: 0.055439
2021-12-17 16:09:43,526 iteration 949 : loss : 0.174603, loss_ce: 0.068584
2021-12-17 16:09:45,063 iteration 950 : loss : 0.166578, loss_ce: 0.056842
2021-12-17 16:09:46,501 iteration 951 : loss : 0.127914, loss_ce: 0.040651
2021-12-17 16:09:48,025 iteration 952 : loss : 0.155576, loss_ce: 0.048779
 14%|████▏                         | 56/400 [25:59<2:44:27, 28.69s/it]2021-12-17 16:09:49,510 iteration 953 : loss : 0.151176, loss_ce: 0.050022
2021-12-17 16:09:50,949 iteration 954 : loss : 0.148957, loss_ce: 0.048193
2021-12-17 16:09:52,433 iteration 955 : loss : 0.171059, loss_ce: 0.059745
2021-12-17 16:09:53,922 iteration 956 : loss : 0.147000, loss_ce: 0.045534
2021-12-17 16:09:55,369 iteration 957 : loss : 0.142579, loss_ce: 0.046228
2021-12-17 16:09:56,851 iteration 958 : loss : 0.149114, loss_ce: 0.047841
2021-12-17 16:09:58,391 iteration 959 : loss : 0.165423, loss_ce: 0.063618
2021-12-17 16:09:59,878 iteration 960 : loss : 0.150569, loss_ce: 0.053917
2021-12-17 16:10:01,376 iteration 961 : loss : 0.157301, loss_ce: 0.047020
2021-12-17 16:10:02,859 iteration 962 : loss : 0.160056, loss_ce: 0.048205
2021-12-17 16:10:04,255 iteration 963 : loss : 0.149836, loss_ce: 0.056551
2021-12-17 16:10:05,734 iteration 964 : loss : 0.148795, loss_ce: 0.047505
2021-12-17 16:10:07,153 iteration 965 : loss : 0.129064, loss_ce: 0.037175
2021-12-17 16:10:08,695 iteration 966 : loss : 0.143135, loss_ce: 0.043596
2021-12-17 16:10:10,177 iteration 967 : loss : 0.149517, loss_ce: 0.055444
2021-12-17 16:10:11,551 iteration 968 : loss : 0.152390, loss_ce: 0.051773
2021-12-17 16:10:13,020 iteration 969 : loss : 0.160943, loss_ce: 0.061700
 14%|████▎                         | 57/400 [26:24<2:37:38, 27.58s/it]2021-12-17 16:10:14,480 iteration 970 : loss : 0.152210, loss_ce: 0.059482
2021-12-17 16:10:15,970 iteration 971 : loss : 0.158580, loss_ce: 0.055577
2021-12-17 16:10:17,409 iteration 972 : loss : 0.139427, loss_ce: 0.045067
2021-12-17 16:10:18,870 iteration 973 : loss : 0.138298, loss_ce: 0.045716
2021-12-17 16:10:20,326 iteration 974 : loss : 0.170230, loss_ce: 0.063577
2021-12-17 16:10:21,748 iteration 975 : loss : 0.144918, loss_ce: 0.043004
2021-12-17 16:10:23,264 iteration 976 : loss : 0.156450, loss_ce: 0.056027
2021-12-17 16:10:24,718 iteration 977 : loss : 0.155669, loss_ce: 0.051564
2021-12-17 16:10:26,208 iteration 978 : loss : 0.131951, loss_ce: 0.040851
2021-12-17 16:10:27,634 iteration 979 : loss : 0.147148, loss_ce: 0.046814
2021-12-17 16:10:29,075 iteration 980 : loss : 0.148688, loss_ce: 0.049568
2021-12-17 16:10:30,516 iteration 981 : loss : 0.118233, loss_ce: 0.031214
2021-12-17 16:10:32,018 iteration 982 : loss : 0.166142, loss_ce: 0.044096
2021-12-17 16:10:33,530 iteration 983 : loss : 0.157780, loss_ce: 0.052942
2021-12-17 16:10:35,065 iteration 984 : loss : 0.166217, loss_ce: 0.059004
2021-12-17 16:10:36,552 iteration 985 : loss : 0.155342, loss_ce: 0.055615
2021-12-17 16:10:37,955 iteration 986 : loss : 0.136847, loss_ce: 0.036543
 14%|████▎                         | 58/400 [26:49<2:32:40, 26.78s/it]2021-12-17 16:10:39,350 iteration 987 : loss : 0.137591, loss_ce: 0.040787
2021-12-17 16:10:40,804 iteration 988 : loss : 0.141134, loss_ce: 0.046804
2021-12-17 16:10:42,253 iteration 989 : loss : 0.124505, loss_ce: 0.038030
2021-12-17 16:10:43,700 iteration 990 : loss : 0.137191, loss_ce: 0.042919
2021-12-17 16:10:45,152 iteration 991 : loss : 0.157713, loss_ce: 0.050550
2021-12-17 16:10:46,583 iteration 992 : loss : 0.143563, loss_ce: 0.049362
2021-12-17 16:10:47,971 iteration 993 : loss : 0.136656, loss_ce: 0.041801
2021-12-17 16:10:49,309 iteration 994 : loss : 0.135455, loss_ce: 0.041873
2021-12-17 16:10:50,850 iteration 995 : loss : 0.159089, loss_ce: 0.064569
2021-12-17 16:10:52,337 iteration 996 : loss : 0.136926, loss_ce: 0.048413
2021-12-17 16:10:53,838 iteration 997 : loss : 0.167085, loss_ce: 0.056910
2021-12-17 16:10:55,314 iteration 998 : loss : 0.136481, loss_ce: 0.042676
2021-12-17 16:10:56,719 iteration 999 : loss : 0.153199, loss_ce: 0.050444
2021-12-17 16:10:58,211 iteration 1000 : loss : 0.162765, loss_ce: 0.071115
2021-12-17 16:10:59,644 iteration 1001 : loss : 0.138194, loss_ce: 0.044112
2021-12-17 16:11:01,164 iteration 1002 : loss : 0.174375, loss_ce: 0.060937
2021-12-17 16:11:02,566 iteration 1003 : loss : 0.160217, loss_ce: 0.039563
 15%|████▍                         | 59/400 [27:14<2:28:30, 26.13s/it]2021-12-17 16:11:04,055 iteration 1004 : loss : 0.141380, loss_ce: 0.041271
2021-12-17 16:11:05,509 iteration 1005 : loss : 0.163240, loss_ce: 0.067419
2021-12-17 16:11:07,057 iteration 1006 : loss : 0.158374, loss_ce: 0.058639
2021-12-17 16:11:08,562 iteration 1007 : loss : 0.148680, loss_ce: 0.049668
2021-12-17 16:11:10,062 iteration 1008 : loss : 0.165018, loss_ce: 0.074554
2021-12-17 16:11:11,494 iteration 1009 : loss : 0.134639, loss_ce: 0.043007
2021-12-17 16:11:12,887 iteration 1010 : loss : 0.135068, loss_ce: 0.035893
2021-12-17 16:11:14,323 iteration 1011 : loss : 0.150795, loss_ce: 0.045138
2021-12-17 16:11:15,827 iteration 1012 : loss : 0.144997, loss_ce: 0.047317
2021-12-17 16:11:17,277 iteration 1013 : loss : 0.147474, loss_ce: 0.051504
2021-12-17 16:11:18,712 iteration 1014 : loss : 0.122418, loss_ce: 0.035308
2021-12-17 16:11:20,281 iteration 1015 : loss : 0.156230, loss_ce: 0.051672
2021-12-17 16:11:21,727 iteration 1016 : loss : 0.133430, loss_ce: 0.041738
2021-12-17 16:11:23,158 iteration 1017 : loss : 0.141885, loss_ce: 0.042840
2021-12-17 16:11:24,669 iteration 1018 : loss : 0.174624, loss_ce: 0.060130
2021-12-17 16:11:26,146 iteration 1019 : loss : 0.154743, loss_ce: 0.046436
2021-12-17 16:11:26,146 Training Data Eval:
2021-12-17 16:11:33,704   Average segmentation loss on training set: 0.1271
2021-12-17 16:11:33,704 Validation Data Eval:
2021-12-17 16:11:36,313   Average segmentation loss on validation set: 0.1866
2021-12-17 16:11:37,853 iteration 1020 : loss : 0.148604, loss_ce: 0.052218
 15%|████▌                         | 60/400 [27:49<2:43:39, 28.88s/it]2021-12-17 16:11:39,336 iteration 1021 : loss : 0.137608, loss_ce: 0.040996
2021-12-17 16:11:40,873 iteration 1022 : loss : 0.166197, loss_ce: 0.063320
2021-12-17 16:11:42,287 iteration 1023 : loss : 0.129936, loss_ce: 0.039996
2021-12-17 16:11:43,714 iteration 1024 : loss : 0.136228, loss_ce: 0.044496
2021-12-17 16:11:45,219 iteration 1025 : loss : 0.137314, loss_ce: 0.045008
2021-12-17 16:11:46,693 iteration 1026 : loss : 0.177298, loss_ce: 0.040558
2021-12-17 16:11:48,123 iteration 1027 : loss : 0.132339, loss_ce: 0.040370
2021-12-17 16:11:49,664 iteration 1028 : loss : 0.162810, loss_ce: 0.048352
2021-12-17 16:11:51,159 iteration 1029 : loss : 0.148097, loss_ce: 0.041078
2021-12-17 16:11:52,628 iteration 1030 : loss : 0.148089, loss_ce: 0.054225
2021-12-17 16:11:54,191 iteration 1031 : loss : 0.132547, loss_ce: 0.044666
2021-12-17 16:11:55,649 iteration 1032 : loss : 0.155418, loss_ce: 0.062934
2021-12-17 16:11:57,089 iteration 1033 : loss : 0.138505, loss_ce: 0.052168
2021-12-17 16:11:58,507 iteration 1034 : loss : 0.155805, loss_ce: 0.052346
2021-12-17 16:12:00,010 iteration 1035 : loss : 0.153867, loss_ce: 0.054405
2021-12-17 16:12:01,502 iteration 1036 : loss : 0.140453, loss_ce: 0.043140
2021-12-17 16:12:02,866 iteration 1037 : loss : 0.135294, loss_ce: 0.046772
 15%|████▌                         | 61/400 [28:14<2:36:36, 27.72s/it]2021-12-17 16:12:04,335 iteration 1038 : loss : 0.136449, loss_ce: 0.042957
2021-12-17 16:12:05,767 iteration 1039 : loss : 0.135786, loss_ce: 0.047520
2021-12-17 16:12:07,200 iteration 1040 : loss : 0.141938, loss_ce: 0.042953
2021-12-17 16:12:08,658 iteration 1041 : loss : 0.137649, loss_ce: 0.050026
2021-12-17 16:12:10,088 iteration 1042 : loss : 0.150710, loss_ce: 0.060848
2021-12-17 16:12:11,529 iteration 1043 : loss : 0.140884, loss_ce: 0.045410
2021-12-17 16:12:13,012 iteration 1044 : loss : 0.140003, loss_ce: 0.054447
2021-12-17 16:12:14,466 iteration 1045 : loss : 0.152519, loss_ce: 0.050795
2021-12-17 16:12:15,897 iteration 1046 : loss : 0.130075, loss_ce: 0.042902
2021-12-17 16:12:17,240 iteration 1047 : loss : 0.128577, loss_ce: 0.039622
2021-12-17 16:12:18,710 iteration 1048 : loss : 0.125946, loss_ce: 0.039737
2021-12-17 16:12:20,223 iteration 1049 : loss : 0.141861, loss_ce: 0.048089
2021-12-17 16:12:21,670 iteration 1050 : loss : 0.163484, loss_ce: 0.040712
2021-12-17 16:12:23,094 iteration 1051 : loss : 0.140117, loss_ce: 0.049317
2021-12-17 16:12:24,611 iteration 1052 : loss : 0.134318, loss_ce: 0.036130
2021-12-17 16:12:26,096 iteration 1053 : loss : 0.152974, loss_ce: 0.038177
2021-12-17 16:12:27,533 iteration 1054 : loss : 0.165144, loss_ce: 0.049766
 16%|████▋                         | 62/400 [28:39<2:30:59, 26.80s/it]2021-12-17 16:12:29,009 iteration 1055 : loss : 0.132469, loss_ce: 0.031802
2021-12-17 16:12:30,388 iteration 1056 : loss : 0.127267, loss_ce: 0.041328
2021-12-17 16:12:31,868 iteration 1057 : loss : 0.156136, loss_ce: 0.049568
2021-12-17 16:12:33,339 iteration 1058 : loss : 0.184666, loss_ce: 0.065400
2021-12-17 16:12:34,816 iteration 1059 : loss : 0.154813, loss_ce: 0.052659
2021-12-17 16:12:36,208 iteration 1060 : loss : 0.139122, loss_ce: 0.038013
2021-12-17 16:12:37,752 iteration 1061 : loss : 0.163081, loss_ce: 0.067474
2021-12-17 16:12:39,198 iteration 1062 : loss : 0.134349, loss_ce: 0.036792
2021-12-17 16:12:40,763 iteration 1063 : loss : 0.162842, loss_ce: 0.064737
2021-12-17 16:12:42,222 iteration 1064 : loss : 0.147745, loss_ce: 0.042000
2021-12-17 16:12:43,749 iteration 1065 : loss : 0.153552, loss_ce: 0.063960
2021-12-17 16:12:45,184 iteration 1066 : loss : 0.128818, loss_ce: 0.037633
2021-12-17 16:12:46,614 iteration 1067 : loss : 0.124903, loss_ce: 0.040254
2021-12-17 16:12:48,101 iteration 1068 : loss : 0.147472, loss_ce: 0.049795
2021-12-17 16:12:49,563 iteration 1069 : loss : 0.140938, loss_ce: 0.051574
2021-12-17 16:12:51,111 iteration 1070 : loss : 0.171429, loss_ce: 0.057352
2021-12-17 16:12:52,567 iteration 1071 : loss : 0.154492, loss_ce: 0.059166
 16%|████▋                         | 63/400 [29:04<2:27:34, 26.27s/it]2021-12-17 16:12:54,139 iteration 1072 : loss : 0.141332, loss_ce: 0.039020
2021-12-17 16:12:55,616 iteration 1073 : loss : 0.151525, loss_ce: 0.055748
2021-12-17 16:12:57,100 iteration 1074 : loss : 0.155698, loss_ce: 0.049518
2021-12-17 16:12:58,555 iteration 1075 : loss : 0.172229, loss_ce: 0.044292
2021-12-17 16:12:59,956 iteration 1076 : loss : 0.126454, loss_ce: 0.038990
2021-12-17 16:13:01,505 iteration 1077 : loss : 0.140663, loss_ce: 0.035253
2021-12-17 16:13:02,926 iteration 1078 : loss : 0.141862, loss_ce: 0.051337
2021-12-17 16:13:04,433 iteration 1079 : loss : 0.148043, loss_ce: 0.052326
2021-12-17 16:13:05,819 iteration 1080 : loss : 0.142161, loss_ce: 0.039405
2021-12-17 16:13:07,262 iteration 1081 : loss : 0.129942, loss_ce: 0.047012
2021-12-17 16:13:08,744 iteration 1082 : loss : 0.165461, loss_ce: 0.065951
2021-12-17 16:13:10,152 iteration 1083 : loss : 0.137123, loss_ce: 0.042089
2021-12-17 16:13:11,589 iteration 1084 : loss : 0.135893, loss_ce: 0.036675
2021-12-17 16:13:13,046 iteration 1085 : loss : 0.136677, loss_ce: 0.047610
2021-12-17 16:13:14,485 iteration 1086 : loss : 0.141321, loss_ce: 0.055564
2021-12-17 16:13:16,030 iteration 1087 : loss : 0.127944, loss_ce: 0.039513
2021-12-17 16:13:17,464 iteration 1088 : loss : 0.146674, loss_ce: 0.052162
 16%|████▊                         | 64/400 [29:29<2:24:48, 25.86s/it]2021-12-17 16:13:18,921 iteration 1089 : loss : 0.166303, loss_ce: 0.055355
2021-12-17 16:13:20,347 iteration 1090 : loss : 0.156738, loss_ce: 0.044337
2021-12-17 16:13:21,864 iteration 1091 : loss : 0.136710, loss_ce: 0.050174
2021-12-17 16:13:23,321 iteration 1092 : loss : 0.129283, loss_ce: 0.045668
2021-12-17 16:13:24,783 iteration 1093 : loss : 0.135281, loss_ce: 0.044143
2021-12-17 16:13:26,270 iteration 1094 : loss : 0.140183, loss_ce: 0.054749
2021-12-17 16:13:27,739 iteration 1095 : loss : 0.156622, loss_ce: 0.045106
2021-12-17 16:13:29,173 iteration 1096 : loss : 0.123280, loss_ce: 0.040756
2021-12-17 16:13:30,559 iteration 1097 : loss : 0.139716, loss_ce: 0.039272
2021-12-17 16:13:31,968 iteration 1098 : loss : 0.133240, loss_ce: 0.046637
2021-12-17 16:13:33,417 iteration 1099 : loss : 0.136175, loss_ce: 0.043735
2021-12-17 16:13:34,840 iteration 1100 : loss : 0.139399, loss_ce: 0.047727
2021-12-17 16:13:36,271 iteration 1101 : loss : 0.129925, loss_ce: 0.040063
2021-12-17 16:13:37,797 iteration 1102 : loss : 0.147589, loss_ce: 0.041172
2021-12-17 16:13:39,226 iteration 1103 : loss : 0.144227, loss_ce: 0.043155
2021-12-17 16:13:40,621 iteration 1104 : loss : 0.144064, loss_ce: 0.046700
2021-12-17 16:13:40,622 Training Data Eval:
2021-12-17 16:13:48,122   Average segmentation loss on training set: 0.1151
2021-12-17 16:13:48,122 Validation Data Eval:
2021-12-17 16:13:50,711   Average segmentation loss on validation set: 0.1840
2021-12-17 16:13:57,830 Found new lowest validation loss at iteration 1104! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/TU_3seeds/TU_RESNET_no_pretraining_SGD_best_val_loss_seed2.pth
2021-12-17 16:13:59,194 iteration 1105 : loss : 0.128766, loss_ce: 0.042726
 16%|████▉                         | 65/400 [30:11<2:50:57, 30.62s/it]2021-12-17 16:14:00,596 iteration 1106 : loss : 0.146177, loss_ce: 0.044928
2021-12-17 16:14:02,022 iteration 1107 : loss : 0.151275, loss_ce: 0.058034
2021-12-17 16:14:03,344 iteration 1108 : loss : 0.123002, loss_ce: 0.034484
2021-12-17 16:14:04,653 iteration 1109 : loss : 0.152130, loss_ce: 0.059117
2021-12-17 16:14:06,008 iteration 1110 : loss : 0.128491, loss_ce: 0.039601
2021-12-17 16:14:07,396 iteration 1111 : loss : 0.134485, loss_ce: 0.042067
2021-12-17 16:14:08,785 iteration 1112 : loss : 0.127500, loss_ce: 0.043972
2021-12-17 16:14:10,126 iteration 1113 : loss : 0.134294, loss_ce: 0.040231
2021-12-17 16:14:11,443 iteration 1114 : loss : 0.141494, loss_ce: 0.040447
2021-12-17 16:14:12,727 iteration 1115 : loss : 0.123717, loss_ce: 0.032906
2021-12-17 16:14:14,175 iteration 1116 : loss : 0.138835, loss_ce: 0.045054
2021-12-17 16:14:15,638 iteration 1117 : loss : 0.146137, loss_ce: 0.049315
2021-12-17 16:14:17,041 iteration 1118 : loss : 0.133332, loss_ce: 0.040508
2021-12-17 16:14:18,484 iteration 1119 : loss : 0.120539, loss_ce: 0.038125
2021-12-17 16:14:19,898 iteration 1120 : loss : 0.140834, loss_ce: 0.040935
2021-12-17 16:14:21,325 iteration 1121 : loss : 0.136857, loss_ce: 0.037653
2021-12-17 16:14:22,748 iteration 1122 : loss : 0.135305, loss_ce: 0.045511
 16%|████▉                         | 66/400 [30:34<2:38:40, 28.50s/it]2021-12-17 16:14:24,255 iteration 1123 : loss : 0.150860, loss_ce: 0.051976
2021-12-17 16:14:25,680 iteration 1124 : loss : 0.136044, loss_ce: 0.042776
2021-12-17 16:14:27,186 iteration 1125 : loss : 0.139951, loss_ce: 0.046827
2021-12-17 16:14:28,760 iteration 1126 : loss : 0.134605, loss_ce: 0.043659
2021-12-17 16:14:30,254 iteration 1127 : loss : 0.156873, loss_ce: 0.055186
2021-12-17 16:14:31,744 iteration 1128 : loss : 0.142296, loss_ce: 0.037585
2021-12-17 16:14:33,205 iteration 1129 : loss : 0.131981, loss_ce: 0.038952
2021-12-17 16:14:34,725 iteration 1130 : loss : 0.144577, loss_ce: 0.056365
2021-12-17 16:14:36,240 iteration 1131 : loss : 0.179953, loss_ce: 0.047584
2021-12-17 16:14:37,715 iteration 1132 : loss : 0.141515, loss_ce: 0.046148
2021-12-17 16:14:39,188 iteration 1133 : loss : 0.165358, loss_ce: 0.060653
2021-12-17 16:14:40,655 iteration 1134 : loss : 0.150325, loss_ce: 0.056730
2021-12-17 16:14:42,079 iteration 1135 : loss : 0.145037, loss_ce: 0.045879
2021-12-17 16:14:43,552 iteration 1136 : loss : 0.132911, loss_ce: 0.045074
2021-12-17 16:14:44,990 iteration 1137 : loss : 0.134882, loss_ce: 0.044765
2021-12-17 16:14:46,503 iteration 1138 : loss : 0.145187, loss_ce: 0.051336
2021-12-17 16:14:48,016 iteration 1139 : loss : 0.131246, loss_ce: 0.044118
 17%|█████                         | 67/400 [30:59<2:32:48, 27.53s/it]2021-12-17 16:14:49,491 iteration 1140 : loss : 0.134088, loss_ce: 0.042365
2021-12-17 16:14:50,945 iteration 1141 : loss : 0.125688, loss_ce: 0.041118
2021-12-17 16:14:52,371 iteration 1142 : loss : 0.120008, loss_ce: 0.039027
2021-12-17 16:14:53,849 iteration 1143 : loss : 0.152417, loss_ce: 0.046542
2021-12-17 16:14:55,345 iteration 1144 : loss : 0.151456, loss_ce: 0.050696
2021-12-17 16:14:56,785 iteration 1145 : loss : 0.130997, loss_ce: 0.036614
2021-12-17 16:14:58,272 iteration 1146 : loss : 0.136858, loss_ce: 0.041964
2021-12-17 16:14:59,673 iteration 1147 : loss : 0.118617, loss_ce: 0.035495
2021-12-17 16:15:01,137 iteration 1148 : loss : 0.122848, loss_ce: 0.035775
2021-12-17 16:15:02,640 iteration 1149 : loss : 0.128319, loss_ce: 0.043279
2021-12-17 16:15:04,095 iteration 1150 : loss : 0.129407, loss_ce: 0.044901
2021-12-17 16:15:05,540 iteration 1151 : loss : 0.131320, loss_ce: 0.035555
2021-12-17 16:15:07,016 iteration 1152 : loss : 0.150941, loss_ce: 0.031032
2021-12-17 16:15:08,468 iteration 1153 : loss : 0.127905, loss_ce: 0.036666
2021-12-17 16:15:09,874 iteration 1154 : loss : 0.117192, loss_ce: 0.040825
2021-12-17 16:15:11,420 iteration 1155 : loss : 0.143790, loss_ce: 0.045440
2021-12-17 16:15:12,910 iteration 1156 : loss : 0.155864, loss_ce: 0.041924
 17%|█████                         | 68/400 [31:24<2:27:57, 26.74s/it]2021-12-17 16:15:14,351 iteration 1157 : loss : 0.121445, loss_ce: 0.035452
2021-12-17 16:15:15,900 iteration 1158 : loss : 0.151232, loss_ce: 0.042091
2021-12-17 16:15:17,405 iteration 1159 : loss : 0.146985, loss_ce: 0.047835
2021-12-17 16:15:18,784 iteration 1160 : loss : 0.132900, loss_ce: 0.047276
2021-12-17 16:15:20,249 iteration 1161 : loss : 0.124981, loss_ce: 0.032061
2021-12-17 16:15:21,695 iteration 1162 : loss : 0.145105, loss_ce: 0.031731
2021-12-17 16:15:23,237 iteration 1163 : loss : 0.157563, loss_ce: 0.045337
2021-12-17 16:15:24,707 iteration 1164 : loss : 0.137376, loss_ce: 0.043013
2021-12-17 16:15:26,114 iteration 1165 : loss : 0.139530, loss_ce: 0.052490
2021-12-17 16:15:27,556 iteration 1166 : loss : 0.144312, loss_ce: 0.056583
2021-12-17 16:15:29,033 iteration 1167 : loss : 0.130963, loss_ce: 0.046413
2021-12-17 16:15:30,431 iteration 1168 : loss : 0.127566, loss_ce: 0.039859
2021-12-17 16:15:31,897 iteration 1169 : loss : 0.134983, loss_ce: 0.036632
2021-12-17 16:15:33,355 iteration 1170 : loss : 0.129588, loss_ce: 0.038775
2021-12-17 16:15:34,745 iteration 1171 : loss : 0.130655, loss_ce: 0.035317
2021-12-17 16:15:36,195 iteration 1172 : loss : 0.121852, loss_ce: 0.037887
2021-12-17 16:15:37,673 iteration 1173 : loss : 0.131348, loss_ce: 0.049503
 17%|█████▏                        | 69/400 [31:49<2:24:15, 26.15s/it]2021-12-17 16:15:39,187 iteration 1174 : loss : 0.120678, loss_ce: 0.029683
2021-12-17 16:15:40,612 iteration 1175 : loss : 0.128823, loss_ce: 0.042522
2021-12-17 16:15:42,116 iteration 1176 : loss : 0.149200, loss_ce: 0.061904
2021-12-17 16:15:43,653 iteration 1177 : loss : 0.145048, loss_ce: 0.053761
2021-12-17 16:15:45,119 iteration 1178 : loss : 0.148425, loss_ce: 0.051624
2021-12-17 16:15:46,493 iteration 1179 : loss : 0.126244, loss_ce: 0.043103
2021-12-17 16:15:47,989 iteration 1180 : loss : 0.139210, loss_ce: 0.041439
2021-12-17 16:15:49,369 iteration 1181 : loss : 0.120613, loss_ce: 0.035729
2021-12-17 16:15:50,918 iteration 1182 : loss : 0.145375, loss_ce: 0.042938
2021-12-17 16:15:52,360 iteration 1183 : loss : 0.145220, loss_ce: 0.049329
2021-12-17 16:15:53,749 iteration 1184 : loss : 0.125157, loss_ce: 0.039303
2021-12-17 16:15:55,231 iteration 1185 : loss : 0.131007, loss_ce: 0.036918
2021-12-17 16:15:56,646 iteration 1186 : loss : 0.131652, loss_ce: 0.038217
2021-12-17 16:15:58,111 iteration 1187 : loss : 0.141658, loss_ce: 0.048535
2021-12-17 16:15:59,520 iteration 1188 : loss : 0.116395, loss_ce: 0.032422
2021-12-17 16:16:00,975 iteration 1189 : loss : 0.143208, loss_ce: 0.047278
2021-12-17 16:16:00,976 Training Data Eval:
2021-12-17 16:16:08,499   Average segmentation loss on training set: 0.1169
2021-12-17 16:16:08,500 Validation Data Eval:
2021-12-17 16:16:11,091   Average segmentation loss on validation set: 0.1779
2021-12-17 16:16:17,703 Found new lowest validation loss at iteration 1189! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/TU_3seeds/TU_RESNET_no_pretraining_SGD_best_val_loss_seed2.pth
2021-12-17 16:16:19,096 iteration 1190 : loss : 0.129158, loss_ce: 0.042716
 18%|█████▎                        | 70/400 [32:31<2:49:00, 30.73s/it]2021-12-17 16:16:20,462 iteration 1191 : loss : 0.122071, loss_ce: 0.039192
2021-12-17 16:16:21,782 iteration 1192 : loss : 0.123187, loss_ce: 0.039509
2021-12-17 16:16:23,134 iteration 1193 : loss : 0.134145, loss_ce: 0.033691
2021-12-17 16:16:24,468 iteration 1194 : loss : 0.147049, loss_ce: 0.046370
2021-12-17 16:16:25,872 iteration 1195 : loss : 0.132445, loss_ce: 0.042565
2021-12-17 16:16:27,167 iteration 1196 : loss : 0.140257, loss_ce: 0.040830
2021-12-17 16:16:28,562 iteration 1197 : loss : 0.138200, loss_ce: 0.055521
2021-12-17 16:16:29,934 iteration 1198 : loss : 0.129480, loss_ce: 0.050950
2021-12-17 16:16:31,322 iteration 1199 : loss : 0.135496, loss_ce: 0.041143
2021-12-17 16:16:32,730 iteration 1200 : loss : 0.150120, loss_ce: 0.044130
2021-12-17 16:16:34,092 iteration 1201 : loss : 0.109355, loss_ce: 0.033667
2021-12-17 16:16:35,552 iteration 1202 : loss : 0.135832, loss_ce: 0.051339
2021-12-17 16:16:37,003 iteration 1203 : loss : 0.140021, loss_ce: 0.042307
2021-12-17 16:16:38,459 iteration 1204 : loss : 0.137231, loss_ce: 0.043288
2021-12-17 16:16:39,970 iteration 1205 : loss : 0.138156, loss_ce: 0.055703
2021-12-17 16:16:41,492 iteration 1206 : loss : 0.162478, loss_ce: 0.042114
2021-12-17 16:16:42,925 iteration 1207 : loss : 0.122933, loss_ce: 0.033467
 18%|█████▎                        | 71/400 [32:54<2:37:09, 28.66s/it]2021-12-17 16:16:44,374 iteration 1208 : loss : 0.122466, loss_ce: 0.042685
2021-12-17 16:16:45,827 iteration 1209 : loss : 0.130224, loss_ce: 0.036950
2021-12-17 16:16:47,214 iteration 1210 : loss : 0.123033, loss_ce: 0.033260
2021-12-17 16:16:48,705 iteration 1211 : loss : 0.152286, loss_ce: 0.045481
2021-12-17 16:16:50,133 iteration 1212 : loss : 0.116750, loss_ce: 0.035560
2021-12-17 16:16:51,605 iteration 1213 : loss : 0.162431, loss_ce: 0.041857
2021-12-17 16:16:53,098 iteration 1214 : loss : 0.127854, loss_ce: 0.046597
2021-12-17 16:16:54,538 iteration 1215 : loss : 0.140590, loss_ce: 0.050370
2021-12-17 16:16:55,967 iteration 1216 : loss : 0.120835, loss_ce: 0.036915
2021-12-17 16:16:57,466 iteration 1217 : loss : 0.142394, loss_ce: 0.051703
2021-12-17 16:16:58,835 iteration 1218 : loss : 0.116278, loss_ce: 0.041786
2021-12-17 16:17:00,323 iteration 1219 : loss : 0.140962, loss_ce: 0.042527
2021-12-17 16:17:01,753 iteration 1220 : loss : 0.135281, loss_ce: 0.041070
2021-12-17 16:17:03,302 iteration 1221 : loss : 0.130769, loss_ce: 0.041547
2021-12-17 16:17:04,780 iteration 1222 : loss : 0.131001, loss_ce: 0.034730
2021-12-17 16:17:06,199 iteration 1223 : loss : 0.135405, loss_ce: 0.044545
2021-12-17 16:17:07,680 iteration 1224 : loss : 0.121405, loss_ce: 0.040130
 18%|█████▍                        | 72/400 [33:19<2:30:15, 27.49s/it]2021-12-17 16:17:09,203 iteration 1225 : loss : 0.119756, loss_ce: 0.038400
2021-12-17 16:17:10,682 iteration 1226 : loss : 0.132138, loss_ce: 0.044287
2021-12-17 16:17:12,115 iteration 1227 : loss : 0.116997, loss_ce: 0.030710
2021-12-17 16:17:13,677 iteration 1228 : loss : 0.157592, loss_ce: 0.043674
2021-12-17 16:17:15,187 iteration 1229 : loss : 0.135146, loss_ce: 0.046035
2021-12-17 16:17:16,674 iteration 1230 : loss : 0.121140, loss_ce: 0.041403
2021-12-17 16:17:18,109 iteration 1231 : loss : 0.151208, loss_ce: 0.046775
2021-12-17 16:17:19,619 iteration 1232 : loss : 0.128667, loss_ce: 0.039527
2021-12-17 16:17:21,180 iteration 1233 : loss : 0.145392, loss_ce: 0.054016
2021-12-17 16:17:22,653 iteration 1234 : loss : 0.142028, loss_ce: 0.048960
2021-12-17 16:17:24,093 iteration 1235 : loss : 0.134530, loss_ce: 0.046347
2021-12-17 16:17:25,512 iteration 1236 : loss : 0.122698, loss_ce: 0.033821
2021-12-17 16:17:26,899 iteration 1237 : loss : 0.115933, loss_ce: 0.030160
2021-12-17 16:17:28,351 iteration 1238 : loss : 0.131271, loss_ce: 0.041396
2021-12-17 16:17:29,849 iteration 1239 : loss : 0.133186, loss_ce: 0.039264
2021-12-17 16:17:31,226 iteration 1240 : loss : 0.123173, loss_ce: 0.038772
2021-12-17 16:17:32,750 iteration 1241 : loss : 0.129170, loss_ce: 0.043835
 18%|█████▍                        | 73/400 [33:44<2:25:51, 26.76s/it]2021-12-17 16:17:34,163 iteration 1242 : loss : 0.128033, loss_ce: 0.042243
2021-12-17 16:17:35,548 iteration 1243 : loss : 0.109665, loss_ce: 0.032683
2021-12-17 16:17:36,944 iteration 1244 : loss : 0.116456, loss_ce: 0.035263
2021-12-17 16:17:38,374 iteration 1245 : loss : 0.134889, loss_ce: 0.043619
2021-12-17 16:17:39,827 iteration 1246 : loss : 0.121449, loss_ce: 0.040953
2021-12-17 16:17:41,317 iteration 1247 : loss : 0.151310, loss_ce: 0.047760
2021-12-17 16:17:42,734 iteration 1248 : loss : 0.117287, loss_ce: 0.035494
2021-12-17 16:17:44,196 iteration 1249 : loss : 0.123237, loss_ce: 0.035758
2021-12-17 16:17:45,616 iteration 1250 : loss : 0.134117, loss_ce: 0.044415
2021-12-17 16:17:47,080 iteration 1251 : loss : 0.124016, loss_ce: 0.039730
2021-12-17 16:17:48,556 iteration 1252 : loss : 0.143510, loss_ce: 0.033841
2021-12-17 16:17:50,020 iteration 1253 : loss : 0.130879, loss_ce: 0.040282
2021-12-17 16:17:51,455 iteration 1254 : loss : 0.162026, loss_ce: 0.065482
2021-12-17 16:17:52,946 iteration 1255 : loss : 0.112823, loss_ce: 0.035333
2021-12-17 16:17:54,447 iteration 1256 : loss : 0.127794, loss_ce: 0.031679
2021-12-17 16:17:55,906 iteration 1257 : loss : 0.120192, loss_ce: 0.038074
2021-12-17 16:17:57,431 iteration 1258 : loss : 0.125805, loss_ce: 0.042821
 18%|█████▌                        | 74/400 [34:09<2:22:00, 26.14s/it]2021-12-17 16:17:58,900 iteration 1259 : loss : 0.117561, loss_ce: 0.032471
2021-12-17 16:18:00,375 iteration 1260 : loss : 0.141692, loss_ce: 0.039717
2021-12-17 16:18:01,846 iteration 1261 : loss : 0.131535, loss_ce: 0.038787
2021-12-17 16:18:03,263 iteration 1262 : loss : 0.105305, loss_ce: 0.033676
2021-12-17 16:18:04,776 iteration 1263 : loss : 0.120801, loss_ce: 0.033689
2021-12-17 16:18:06,172 iteration 1264 : loss : 0.124360, loss_ce: 0.047546
2021-12-17 16:18:07,567 iteration 1265 : loss : 0.130001, loss_ce: 0.039199
2021-12-17 16:18:08,950 iteration 1266 : loss : 0.119232, loss_ce: 0.037842
2021-12-17 16:18:10,480 iteration 1267 : loss : 0.122036, loss_ce: 0.035218
2021-12-17 16:18:11,921 iteration 1268 : loss : 0.190572, loss_ce: 0.040267
2021-12-17 16:18:13,405 iteration 1269 : loss : 0.128447, loss_ce: 0.038357
2021-12-17 16:18:14,803 iteration 1270 : loss : 0.125120, loss_ce: 0.037085
2021-12-17 16:18:16,244 iteration 1271 : loss : 0.126600, loss_ce: 0.043346
2021-12-17 16:18:17,675 iteration 1272 : loss : 0.125269, loss_ce: 0.042452
2021-12-17 16:18:19,162 iteration 1273 : loss : 0.146437, loss_ce: 0.054626
2021-12-17 16:18:20,628 iteration 1274 : loss : 0.130639, loss_ce: 0.040576
2021-12-17 16:18:20,629 Training Data Eval:
2021-12-17 16:18:28,141   Average segmentation loss on training set: 0.1046
2021-12-17 16:18:28,142 Validation Data Eval:
2021-12-17 16:18:30,744   Average segmentation loss on validation set: 0.1762
2021-12-17 16:18:37,084 Found new lowest validation loss at iteration 1274! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/TU_3seeds/TU_RESNET_no_pretraining_SGD_best_val_loss_seed2.pth
2021-12-17 16:18:38,490 iteration 1275 : loss : 0.130467, loss_ce: 0.035182
 19%|█████▋                        | 75/400 [34:50<2:45:50, 30.62s/it]2021-12-17 16:18:39,988 iteration 1276 : loss : 0.159192, loss_ce: 0.035479
2021-12-17 16:18:41,304 iteration 1277 : loss : 0.128605, loss_ce: 0.037037
2021-12-17 16:18:42,699 iteration 1278 : loss : 0.123934, loss_ce: 0.042823
2021-12-17 16:18:43,962 iteration 1279 : loss : 0.123605, loss_ce: 0.047550
2021-12-17 16:18:45,234 iteration 1280 : loss : 0.127528, loss_ce: 0.043192
2021-12-17 16:18:46,651 iteration 1281 : loss : 0.131325, loss_ce: 0.045394
2021-12-17 16:18:47,965 iteration 1282 : loss : 0.141400, loss_ce: 0.060112
2021-12-17 16:18:49,300 iteration 1283 : loss : 0.128205, loss_ce: 0.041063
2021-12-17 16:18:50,661 iteration 1284 : loss : 0.118312, loss_ce: 0.037605
2021-12-17 16:18:52,183 iteration 1285 : loss : 0.143241, loss_ce: 0.037592
2021-12-17 16:18:53,626 iteration 1286 : loss : 0.127508, loss_ce: 0.036660
2021-12-17 16:18:55,028 iteration 1287 : loss : 0.126015, loss_ce: 0.037542
2021-12-17 16:18:56,510 iteration 1288 : loss : 0.124427, loss_ce: 0.039623
2021-12-17 16:18:58,056 iteration 1289 : loss : 0.124384, loss_ce: 0.039326
2021-12-17 16:18:59,485 iteration 1290 : loss : 0.132956, loss_ce: 0.035464
2021-12-17 16:19:00,955 iteration 1291 : loss : 0.136870, loss_ce: 0.044164
2021-12-17 16:19:02,368 iteration 1292 : loss : 0.120029, loss_ce: 0.035562
 19%|█████▋                        | 76/400 [35:14<2:34:23, 28.59s/it]2021-12-17 16:19:03,867 iteration 1293 : loss : 0.132563, loss_ce: 0.047001
2021-12-17 16:19:05,289 iteration 1294 : loss : 0.127821, loss_ce: 0.037648
2021-12-17 16:19:06,735 iteration 1295 : loss : 0.107598, loss_ce: 0.033833
2021-12-17 16:19:08,188 iteration 1296 : loss : 0.113778, loss_ce: 0.033338
2021-12-17 16:19:09,642 iteration 1297 : loss : 0.129744, loss_ce: 0.041575
2021-12-17 16:19:11,114 iteration 1298 : loss : 0.115335, loss_ce: 0.039486
2021-12-17 16:19:12,524 iteration 1299 : loss : 0.125801, loss_ce: 0.037640
2021-12-17 16:19:14,040 iteration 1300 : loss : 0.130794, loss_ce: 0.028188
2021-12-17 16:19:15,497 iteration 1301 : loss : 0.121694, loss_ce: 0.042375
2021-12-17 16:19:16,993 iteration 1302 : loss : 0.129038, loss_ce: 0.031756
2021-12-17 16:19:18,398 iteration 1303 : loss : 0.132503, loss_ce: 0.045312
2021-12-17 16:19:19,906 iteration 1304 : loss : 0.157119, loss_ce: 0.037815
2021-12-17 16:19:21,371 iteration 1305 : loss : 0.112365, loss_ce: 0.037288
2021-12-17 16:19:22,881 iteration 1306 : loss : 0.123065, loss_ce: 0.036521
2021-12-17 16:19:24,401 iteration 1307 : loss : 0.136268, loss_ce: 0.042579
2021-12-17 16:19:25,865 iteration 1308 : loss : 0.139948, loss_ce: 0.055292
2021-12-17 16:19:27,318 iteration 1309 : loss : 0.139599, loss_ce: 0.037119
 19%|█████▊                        | 77/400 [35:39<2:28:02, 27.50s/it]2021-12-17 16:19:28,824 iteration 1310 : loss : 0.115812, loss_ce: 0.036814
2021-12-17 16:19:30,334 iteration 1311 : loss : 0.138619, loss_ce: 0.042622
2021-12-17 16:19:31,771 iteration 1312 : loss : 0.142765, loss_ce: 0.062316
2021-12-17 16:19:33,170 iteration 1313 : loss : 0.111718, loss_ce: 0.033339
2021-12-17 16:19:34,645 iteration 1314 : loss : 0.110312, loss_ce: 0.034793
2021-12-17 16:19:36,110 iteration 1315 : loss : 0.128532, loss_ce: 0.037608
2021-12-17 16:19:37,539 iteration 1316 : loss : 0.124558, loss_ce: 0.040483
2021-12-17 16:19:39,026 iteration 1317 : loss : 0.131363, loss_ce: 0.047275
2021-12-17 16:19:40,516 iteration 1318 : loss : 0.125028, loss_ce: 0.042040
2021-12-17 16:19:41,954 iteration 1319 : loss : 0.121259, loss_ce: 0.036597
2021-12-17 16:19:43,417 iteration 1320 : loss : 0.135042, loss_ce: 0.041485
2021-12-17 16:19:44,867 iteration 1321 : loss : 0.138778, loss_ce: 0.045378
2021-12-17 16:19:46,404 iteration 1322 : loss : 0.133831, loss_ce: 0.041640
2021-12-17 16:19:47,884 iteration 1323 : loss : 0.112550, loss_ce: 0.032377
2021-12-17 16:19:49,357 iteration 1324 : loss : 0.125184, loss_ce: 0.035614
2021-12-17 16:19:50,848 iteration 1325 : loss : 0.133608, loss_ce: 0.037986
2021-12-17 16:19:52,250 iteration 1326 : loss : 0.120471, loss_ce: 0.033375
 20%|█████▊                        | 78/400 [36:04<2:23:27, 26.73s/it]2021-12-17 16:19:53,769 iteration 1327 : loss : 0.142893, loss_ce: 0.062969
2021-12-17 16:19:55,307 iteration 1328 : loss : 0.131785, loss_ce: 0.040426
2021-12-17 16:19:56,698 iteration 1329 : loss : 0.125361, loss_ce: 0.045697
2021-12-17 16:19:58,149 iteration 1330 : loss : 0.128911, loss_ce: 0.036746
2021-12-17 16:19:59,605 iteration 1331 : loss : 0.126129, loss_ce: 0.037567
2021-12-17 16:20:01,064 iteration 1332 : loss : 0.114616, loss_ce: 0.035125
2021-12-17 16:20:02,550 iteration 1333 : loss : 0.127355, loss_ce: 0.027933
2021-12-17 16:20:03,976 iteration 1334 : loss : 0.117981, loss_ce: 0.037831
2021-12-17 16:20:05,518 iteration 1335 : loss : 0.118388, loss_ce: 0.032317
2021-12-17 16:20:06,997 iteration 1336 : loss : 0.116732, loss_ce: 0.038861
2021-12-17 16:20:08,509 iteration 1337 : loss : 0.137097, loss_ce: 0.044661
2021-12-17 16:20:10,034 iteration 1338 : loss : 0.136394, loss_ce: 0.046724
2021-12-17 16:20:11,517 iteration 1339 : loss : 0.132994, loss_ce: 0.046297
2021-12-17 16:20:12,922 iteration 1340 : loss : 0.130309, loss_ce: 0.035773
2021-12-17 16:20:14,364 iteration 1341 : loss : 0.122896, loss_ce: 0.037632
2021-12-17 16:20:15,823 iteration 1342 : loss : 0.136654, loss_ce: 0.035152
2021-12-17 16:20:17,258 iteration 1343 : loss : 0.109818, loss_ce: 0.030819
 20%|█████▉                        | 79/400 [36:29<2:20:14, 26.21s/it]2021-12-17 16:20:18,721 iteration 1344 : loss : 0.110985, loss_ce: 0.031406
2021-12-17 16:20:20,126 iteration 1345 : loss : 0.114772, loss_ce: 0.039800
2021-12-17 16:20:21,532 iteration 1346 : loss : 0.107862, loss_ce: 0.025484
2021-12-17 16:20:23,047 iteration 1347 : loss : 0.157510, loss_ce: 0.035172
2021-12-17 16:20:24,571 iteration 1348 : loss : 0.119460, loss_ce: 0.037387
2021-12-17 16:20:26,049 iteration 1349 : loss : 0.143377, loss_ce: 0.049337
2021-12-17 16:20:27,550 iteration 1350 : loss : 0.128696, loss_ce: 0.044454
2021-12-17 16:20:28,953 iteration 1351 : loss : 0.114123, loss_ce: 0.031309
2021-12-17 16:20:30,492 iteration 1352 : loss : 0.121939, loss_ce: 0.037038
2021-12-17 16:20:31,882 iteration 1353 : loss : 0.121040, loss_ce: 0.039374
2021-12-17 16:20:33,360 iteration 1354 : loss : 0.108735, loss_ce: 0.033164
2021-12-17 16:20:34,754 iteration 1355 : loss : 0.121406, loss_ce: 0.029821
2021-12-17 16:20:36,244 iteration 1356 : loss : 0.130711, loss_ce: 0.037424
2021-12-17 16:20:37,651 iteration 1357 : loss : 0.127850, loss_ce: 0.053170
2021-12-17 16:20:39,103 iteration 1358 : loss : 0.129558, loss_ce: 0.035310
2021-12-17 16:20:40,500 iteration 1359 : loss : 0.130423, loss_ce: 0.053156
2021-12-17 16:20:40,500 Training Data Eval:
2021-12-17 16:20:48,010   Average segmentation loss on training set: 0.1059
2021-12-17 16:20:48,011 Validation Data Eval:
2021-12-17 16:20:50,600   Average segmentation loss on validation set: 0.1626
2021-12-17 16:20:56,855 Found new lowest validation loss at iteration 1359! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/TU_3seeds/TU_RESNET_no_pretraining_SGD_best_val_loss_seed2.pth
2021-12-17 16:20:58,208 iteration 1360 : loss : 0.135178, loss_ce: 0.035645
 20%|██████                        | 80/400 [37:10<2:43:22, 30.63s/it]2021-12-17 16:20:59,653 iteration 1361 : loss : 0.146474, loss_ce: 0.038894
2021-12-17 16:21:01,043 iteration 1362 : loss : 0.121273, loss_ce: 0.039597
2021-12-17 16:21:02,442 iteration 1363 : loss : 0.111221, loss_ce: 0.030865
2021-12-17 16:21:03,866 iteration 1364 : loss : 0.139352, loss_ce: 0.043008
2021-12-17 16:21:05,325 iteration 1365 : loss : 0.121378, loss_ce: 0.037354
2021-12-17 16:21:06,700 iteration 1366 : loss : 0.135397, loss_ce: 0.051355
2021-12-17 16:21:08,039 iteration 1367 : loss : 0.121351, loss_ce: 0.038136
2021-12-17 16:21:09,422 iteration 1368 : loss : 0.138474, loss_ce: 0.048939
2021-12-17 16:21:10,774 iteration 1369 : loss : 0.120590, loss_ce: 0.030186
2021-12-17 16:21:12,151 iteration 1370 : loss : 0.121893, loss_ce: 0.034864
2021-12-17 16:21:13,469 iteration 1371 : loss : 0.113887, loss_ce: 0.034701
2021-12-17 16:21:14,920 iteration 1372 : loss : 0.139249, loss_ce: 0.040579
2021-12-17 16:21:16,484 iteration 1373 : loss : 0.123099, loss_ce: 0.048971
2021-12-17 16:21:17,944 iteration 1374 : loss : 0.129257, loss_ce: 0.035621
2021-12-17 16:21:19,456 iteration 1375 : loss : 0.116529, loss_ce: 0.031394
2021-12-17 16:21:20,851 iteration 1376 : loss : 0.115561, loss_ce: 0.036814
2021-12-17 16:21:22,362 iteration 1377 : loss : 0.143805, loss_ce: 0.041371
 20%|██████                        | 81/400 [37:34<2:32:32, 28.69s/it]2021-12-17 16:21:23,937 iteration 1378 : loss : 0.129780, loss_ce: 0.047966
2021-12-17 16:21:25,468 iteration 1379 : loss : 0.139096, loss_ce: 0.039513
2021-12-17 16:21:26,927 iteration 1380 : loss : 0.109175, loss_ce: 0.036212
2021-12-17 16:21:28,397 iteration 1381 : loss : 0.108085, loss_ce: 0.034783
2021-12-17 16:21:29,847 iteration 1382 : loss : 0.113385, loss_ce: 0.034722
2021-12-17 16:21:31,312 iteration 1383 : loss : 0.130593, loss_ce: 0.029624
2021-12-17 16:21:32,852 iteration 1384 : loss : 0.138156, loss_ce: 0.052942
2021-12-17 16:21:34,241 iteration 1385 : loss : 0.108082, loss_ce: 0.030766
2021-12-17 16:21:35,802 iteration 1386 : loss : 0.145712, loss_ce: 0.057447
2021-12-17 16:21:37,222 iteration 1387 : loss : 0.135238, loss_ce: 0.033633
2021-12-17 16:21:38,705 iteration 1388 : loss : 0.130834, loss_ce: 0.028372
2021-12-17 16:21:40,184 iteration 1389 : loss : 0.139978, loss_ce: 0.054065
2021-12-17 16:21:41,581 iteration 1390 : loss : 0.121591, loss_ce: 0.042678
2021-12-17 16:21:43,069 iteration 1391 : loss : 0.130198, loss_ce: 0.033289
2021-12-17 16:21:44,528 iteration 1392 : loss : 0.115289, loss_ce: 0.043781
2021-12-17 16:21:45,986 iteration 1393 : loss : 0.130019, loss_ce: 0.033315
2021-12-17 16:21:47,428 iteration 1394 : loss : 0.140461, loss_ce: 0.034537
 20%|██████▏                       | 82/400 [37:59<2:26:17, 27.60s/it]2021-12-17 16:21:48,961 iteration 1395 : loss : 0.120833, loss_ce: 0.040200
2021-12-17 16:21:50,354 iteration 1396 : loss : 0.136744, loss_ce: 0.047728
2021-12-17 16:21:51,870 iteration 1397 : loss : 0.119113, loss_ce: 0.037836
2021-12-17 16:21:53,265 iteration 1398 : loss : 0.108187, loss_ce: 0.029832
2021-12-17 16:21:54,755 iteration 1399 : loss : 0.126185, loss_ce: 0.045615
2021-12-17 16:21:56,272 iteration 1400 : loss : 0.122283, loss_ce: 0.035229
2021-12-17 16:21:57,685 iteration 1401 : loss : 0.104609, loss_ce: 0.028203
2021-12-17 16:21:59,206 iteration 1402 : loss : 0.132850, loss_ce: 0.041318
2021-12-17 16:22:00,679 iteration 1403 : loss : 0.125582, loss_ce: 0.033760
2021-12-17 16:22:02,214 iteration 1404 : loss : 0.124471, loss_ce: 0.042696
2021-12-17 16:22:03,524 iteration 1405 : loss : 0.101844, loss_ce: 0.028177
2021-12-17 16:22:05,018 iteration 1406 : loss : 0.126172, loss_ce: 0.035982
2021-12-17 16:22:06,447 iteration 1407 : loss : 0.107562, loss_ce: 0.033382
2021-12-17 16:22:07,849 iteration 1408 : loss : 0.135264, loss_ce: 0.048382
2021-12-17 16:22:09,372 iteration 1409 : loss : 0.136959, loss_ce: 0.031748
2021-12-17 16:22:10,781 iteration 1410 : loss : 0.125932, loss_ce: 0.040241
2021-12-17 16:22:12,166 iteration 1411 : loss : 0.104190, loss_ce: 0.028995
 21%|██████▏                       | 83/400 [38:24<2:21:17, 26.74s/it]2021-12-17 16:22:13,696 iteration 1412 : loss : 0.115319, loss_ce: 0.037920
2021-12-17 16:22:15,079 iteration 1413 : loss : 0.121202, loss_ce: 0.034880
2021-12-17 16:22:16,565 iteration 1414 : loss : 0.110089, loss_ce: 0.035149
2021-12-17 16:22:17,953 iteration 1415 : loss : 0.122495, loss_ce: 0.038008
2021-12-17 16:22:19,394 iteration 1416 : loss : 0.114669, loss_ce: 0.036419
2021-12-17 16:22:20,870 iteration 1417 : loss : 0.124259, loss_ce: 0.035880
2021-12-17 16:22:22,341 iteration 1418 : loss : 0.117523, loss_ce: 0.034589
2021-12-17 16:22:23,728 iteration 1419 : loss : 0.104724, loss_ce: 0.031519
2021-12-17 16:22:25,177 iteration 1420 : loss : 0.109370, loss_ce: 0.026431
2021-12-17 16:22:26,629 iteration 1421 : loss : 0.135034, loss_ce: 0.059581
2021-12-17 16:22:28,092 iteration 1422 : loss : 0.127718, loss_ce: 0.040821
2021-12-17 16:22:29,507 iteration 1423 : loss : 0.116848, loss_ce: 0.030497
2021-12-17 16:22:30,883 iteration 1424 : loss : 0.099665, loss_ce: 0.030262
2021-12-17 16:22:32,363 iteration 1425 : loss : 0.114535, loss_ce: 0.029191
2021-12-17 16:22:33,848 iteration 1426 : loss : 0.139540, loss_ce: 0.058030
2021-12-17 16:22:35,298 iteration 1427 : loss : 0.147189, loss_ce: 0.033014
2021-12-17 16:22:36,854 iteration 1428 : loss : 0.130263, loss_ce: 0.041088
 21%|██████▎                       | 84/400 [38:48<2:17:36, 26.13s/it]2021-12-17 16:22:38,351 iteration 1429 : loss : 0.124990, loss_ce: 0.044075
2021-12-17 16:22:39,784 iteration 1430 : loss : 0.125338, loss_ce: 0.040837
2021-12-17 16:22:41,199 iteration 1431 : loss : 0.119446, loss_ce: 0.035144
2021-12-17 16:22:42,659 iteration 1432 : loss : 0.112334, loss_ce: 0.036684
2021-12-17 16:22:44,047 iteration 1433 : loss : 0.106640, loss_ce: 0.034343
2021-12-17 16:22:45,585 iteration 1434 : loss : 0.129700, loss_ce: 0.046256
2021-12-17 16:22:47,067 iteration 1435 : loss : 0.115842, loss_ce: 0.029776
2021-12-17 16:22:48,560 iteration 1436 : loss : 0.134398, loss_ce: 0.052221
2021-12-17 16:22:50,017 iteration 1437 : loss : 0.108275, loss_ce: 0.033783
2021-12-17 16:22:51,467 iteration 1438 : loss : 0.114659, loss_ce: 0.034722
2021-12-17 16:22:52,942 iteration 1439 : loss : 0.131493, loss_ce: 0.036712
2021-12-17 16:22:54,338 iteration 1440 : loss : 0.111367, loss_ce: 0.029100
2021-12-17 16:22:55,804 iteration 1441 : loss : 0.129506, loss_ce: 0.038094
2021-12-17 16:22:57,238 iteration 1442 : loss : 0.116783, loss_ce: 0.028983
2021-12-17 16:22:58,738 iteration 1443 : loss : 0.111548, loss_ce: 0.032638
2021-12-17 16:23:00,184 iteration 1444 : loss : 0.113463, loss_ce: 0.024027
2021-12-17 16:23:00,184 Training Data Eval:
2021-12-17 16:23:07,694   Average segmentation loss on training set: 0.1028
2021-12-17 16:23:07,694 Validation Data Eval:
2021-12-17 16:23:10,291   Average segmentation loss on validation set: 0.1627
2021-12-17 16:23:11,792 iteration 1445 : loss : 0.115070, loss_ce: 0.041104
 21%|██████▍                       | 85/400 [39:23<2:31:03, 28.77s/it]2021-12-17 16:23:13,209 iteration 1446 : loss : 0.120296, loss_ce: 0.032661
2021-12-17 16:23:14,591 iteration 1447 : loss : 0.111516, loss_ce: 0.032527
2021-12-17 16:23:16,103 iteration 1448 : loss : 0.110265, loss_ce: 0.026174
2021-12-17 16:23:17,598 iteration 1449 : loss : 0.118587, loss_ce: 0.032045
2021-12-17 16:23:19,032 iteration 1450 : loss : 0.107047, loss_ce: 0.028833
2021-12-17 16:23:20,512 iteration 1451 : loss : 0.112663, loss_ce: 0.028069
2021-12-17 16:23:21,964 iteration 1452 : loss : 0.128814, loss_ce: 0.055525
2021-12-17 16:23:23,439 iteration 1453 : loss : 0.109433, loss_ce: 0.035492
2021-12-17 16:23:24,889 iteration 1454 : loss : 0.110179, loss_ce: 0.028021
2021-12-17 16:23:26,356 iteration 1455 : loss : 0.118407, loss_ce: 0.031272
2021-12-17 16:23:27,755 iteration 1456 : loss : 0.106867, loss_ce: 0.026020
2021-12-17 16:23:29,257 iteration 1457 : loss : 0.118077, loss_ce: 0.039399
2021-12-17 16:23:30,736 iteration 1458 : loss : 0.100719, loss_ce: 0.028973
2021-12-17 16:23:32,167 iteration 1459 : loss : 0.114810, loss_ce: 0.029961
2021-12-17 16:23:33,609 iteration 1460 : loss : 0.106707, loss_ce: 0.031133
2021-12-17 16:23:35,013 iteration 1461 : loss : 0.119000, loss_ce: 0.034120
2021-12-17 16:23:36,521 iteration 1462 : loss : 0.108200, loss_ce: 0.034390
 22%|██████▍                       | 86/400 [39:48<2:24:13, 27.56s/it]2021-12-17 16:23:38,111 iteration 1463 : loss : 0.165592, loss_ce: 0.038048
2021-12-17 16:23:39,511 iteration 1464 : loss : 0.113399, loss_ce: 0.040001
2021-12-17 16:23:41,069 iteration 1465 : loss : 0.124284, loss_ce: 0.033534
2021-12-17 16:23:42,509 iteration 1466 : loss : 0.114747, loss_ce: 0.034548
2021-12-17 16:23:43,906 iteration 1467 : loss : 0.118115, loss_ce: 0.035560
2021-12-17 16:23:45,360 iteration 1468 : loss : 0.116151, loss_ce: 0.038577
2021-12-17 16:23:46,797 iteration 1469 : loss : 0.110789, loss_ce: 0.032050
2021-12-17 16:23:48,195 iteration 1470 : loss : 0.124395, loss_ce: 0.026105
2021-12-17 16:23:49,651 iteration 1471 : loss : 0.104506, loss_ce: 0.031569
2021-12-17 16:23:51,137 iteration 1472 : loss : 0.124675, loss_ce: 0.038465
2021-12-17 16:23:52,539 iteration 1473 : loss : 0.109225, loss_ce: 0.037460
2021-12-17 16:23:54,021 iteration 1474 : loss : 0.129455, loss_ce: 0.035698
2021-12-17 16:23:55,431 iteration 1475 : loss : 0.130209, loss_ce: 0.047335
2021-12-17 16:23:56,848 iteration 1476 : loss : 0.112605, loss_ce: 0.039712
2021-12-17 16:23:58,372 iteration 1477 : loss : 0.131893, loss_ce: 0.048785
2021-12-17 16:23:59,774 iteration 1478 : loss : 0.122130, loss_ce: 0.028870
2021-12-17 16:24:01,218 iteration 1479 : loss : 0.115502, loss_ce: 0.029443
 22%|██████▌                       | 87/400 [40:13<2:19:17, 26.70s/it]2021-12-17 16:24:02,587 iteration 1480 : loss : 0.099820, loss_ce: 0.028949
2021-12-17 16:24:04,126 iteration 1481 : loss : 0.114266, loss_ce: 0.036638
2021-12-17 16:24:05,577 iteration 1482 : loss : 0.126387, loss_ce: 0.039353
2021-12-17 16:24:07,096 iteration 1483 : loss : 0.126712, loss_ce: 0.037711
2021-12-17 16:24:08,574 iteration 1484 : loss : 0.119677, loss_ce: 0.033127
2021-12-17 16:24:10,048 iteration 1485 : loss : 0.112324, loss_ce: 0.040261
2021-12-17 16:24:11,475 iteration 1486 : loss : 0.109117, loss_ce: 0.029523
2021-12-17 16:24:12,917 iteration 1487 : loss : 0.111573, loss_ce: 0.032474
2021-12-17 16:24:14,318 iteration 1488 : loss : 0.110471, loss_ce: 0.035869
2021-12-17 16:24:15,741 iteration 1489 : loss : 0.128585, loss_ce: 0.046535
2021-12-17 16:24:17,215 iteration 1490 : loss : 0.113148, loss_ce: 0.031024
2021-12-17 16:24:18,574 iteration 1491 : loss : 0.112474, loss_ce: 0.030157
2021-12-17 16:24:19,960 iteration 1492 : loss : 0.124999, loss_ce: 0.045114
2021-12-17 16:24:21,434 iteration 1493 : loss : 0.113899, loss_ce: 0.036257
2021-12-17 16:24:22,868 iteration 1494 : loss : 0.117924, loss_ce: 0.034952
2021-12-17 16:24:24,257 iteration 1495 : loss : 0.097835, loss_ce: 0.021462
2021-12-17 16:24:25,738 iteration 1496 : loss : 0.130493, loss_ce: 0.044160
 22%|██████▌                       | 88/400 [40:37<2:15:26, 26.05s/it]2021-12-17 16:24:27,140 iteration 1497 : loss : 0.102996, loss_ce: 0.029734
2021-12-17 16:24:28,618 iteration 1498 : loss : 0.135035, loss_ce: 0.043047
2021-12-17 16:24:30,000 iteration 1499 : loss : 0.119534, loss_ce: 0.035142
2021-12-17 16:24:31,451 iteration 1500 : loss : 0.106992, loss_ce: 0.036130
2021-12-17 16:24:32,876 iteration 1501 : loss : 0.114262, loss_ce: 0.038766
2021-12-17 16:24:34,394 iteration 1502 : loss : 0.136830, loss_ce: 0.028021
2021-12-17 16:24:35,952 iteration 1503 : loss : 0.142640, loss_ce: 0.036002
2021-12-17 16:24:37,363 iteration 1504 : loss : 0.106984, loss_ce: 0.035730
2021-12-17 16:24:38,827 iteration 1505 : loss : 0.108369, loss_ce: 0.035438
2021-12-17 16:24:40,284 iteration 1506 : loss : 0.128081, loss_ce: 0.045782
2021-12-17 16:24:41,753 iteration 1507 : loss : 0.125317, loss_ce: 0.029460
2021-12-17 16:24:43,224 iteration 1508 : loss : 0.138187, loss_ce: 0.058155
2021-12-17 16:24:44,687 iteration 1509 : loss : 0.108073, loss_ce: 0.031093
2021-12-17 16:24:46,208 iteration 1510 : loss : 0.117669, loss_ce: 0.031198
2021-12-17 16:24:47,717 iteration 1511 : loss : 0.129729, loss_ce: 0.043254
2021-12-17 16:24:49,170 iteration 1512 : loss : 0.121536, loss_ce: 0.030009
2021-12-17 16:24:50,612 iteration 1513 : loss : 0.109516, loss_ce: 0.031610
 22%|██████▋                       | 89/400 [41:02<2:13:10, 25.69s/it]2021-12-17 16:24:52,125 iteration 1514 : loss : 0.117096, loss_ce: 0.031732
2021-12-17 16:24:53,512 iteration 1515 : loss : 0.107478, loss_ce: 0.034266
2021-12-17 16:24:54,958 iteration 1516 : loss : 0.122066, loss_ce: 0.037715
2021-12-17 16:24:56,326 iteration 1517 : loss : 0.102467, loss_ce: 0.030378
2021-12-17 16:24:57,804 iteration 1518 : loss : 0.099421, loss_ce: 0.025123
2021-12-17 16:24:59,321 iteration 1519 : loss : 0.113553, loss_ce: 0.028801
2021-12-17 16:25:00,813 iteration 1520 : loss : 0.122327, loss_ce: 0.039678
2021-12-17 16:25:02,264 iteration 1521 : loss : 0.127499, loss_ce: 0.030289
2021-12-17 16:25:03,689 iteration 1522 : loss : 0.114355, loss_ce: 0.033614
2021-12-17 16:25:05,104 iteration 1523 : loss : 0.103077, loss_ce: 0.024860
2021-12-17 16:25:06,551 iteration 1524 : loss : 0.105423, loss_ce: 0.030214
2021-12-17 16:25:07,919 iteration 1525 : loss : 0.111410, loss_ce: 0.030820
2021-12-17 16:25:09,391 iteration 1526 : loss : 0.129581, loss_ce: 0.047824
2021-12-17 16:25:10,881 iteration 1527 : loss : 0.128336, loss_ce: 0.050789
2021-12-17 16:25:12,283 iteration 1528 : loss : 0.107064, loss_ce: 0.032021
2021-12-17 16:25:13,682 iteration 1529 : loss : 0.106467, loss_ce: 0.030247
2021-12-17 16:25:13,683 Training Data Eval:
2021-12-17 16:25:21,175   Average segmentation loss on training set: 0.0928
2021-12-17 16:25:21,176 Validation Data Eval:
2021-12-17 16:25:23,779   Average segmentation loss on validation set: 0.1656
2021-12-17 16:25:25,268 iteration 1530 : loss : 0.121525, loss_ce: 0.038343
 22%|██████▊                       | 90/400 [41:37<2:26:38, 28.38s/it]2021-12-17 16:25:26,778 iteration 1531 : loss : 0.126424, loss_ce: 0.043978
2021-12-17 16:25:28,199 iteration 1532 : loss : 0.117143, loss_ce: 0.037628
2021-12-17 16:25:29,572 iteration 1533 : loss : 0.100899, loss_ce: 0.027935
2021-12-17 16:25:30,993 iteration 1534 : loss : 0.116046, loss_ce: 0.041050
2021-12-17 16:25:32,505 iteration 1535 : loss : 0.109925, loss_ce: 0.034090
2021-12-17 16:25:33,999 iteration 1536 : loss : 0.115607, loss_ce: 0.042853
2021-12-17 16:25:35,425 iteration 1537 : loss : 0.107360, loss_ce: 0.034255
2021-12-17 16:25:36,897 iteration 1538 : loss : 0.113364, loss_ce: 0.032978
2021-12-17 16:25:38,343 iteration 1539 : loss : 0.106841, loss_ce: 0.036113
2021-12-17 16:25:39,789 iteration 1540 : loss : 0.124722, loss_ce: 0.044134
2021-12-17 16:25:41,221 iteration 1541 : loss : 0.100104, loss_ce: 0.030970
2021-12-17 16:25:42,622 iteration 1542 : loss : 0.102894, loss_ce: 0.032329
2021-12-17 16:25:44,038 iteration 1543 : loss : 0.115501, loss_ce: 0.029405
2021-12-17 16:25:45,401 iteration 1544 : loss : 0.104012, loss_ce: 0.030080
2021-12-17 16:25:46,938 iteration 1545 : loss : 0.121855, loss_ce: 0.038538
2021-12-17 16:25:48,335 iteration 1546 : loss : 0.127457, loss_ce: 0.027384
2021-12-17 16:25:49,858 iteration 1547 : loss : 0.109753, loss_ce: 0.029147
 23%|██████▊                       | 91/400 [42:01<2:20:18, 27.25s/it]2021-12-17 16:25:51,361 iteration 1548 : loss : 0.120810, loss_ce: 0.040205
2021-12-17 16:25:52,725 iteration 1549 : loss : 0.097469, loss_ce: 0.028588
2021-12-17 16:25:54,142 iteration 1550 : loss : 0.109233, loss_ce: 0.031762
2021-12-17 16:25:55,488 iteration 1551 : loss : 0.097714, loss_ce: 0.026773
2021-12-17 16:25:56,940 iteration 1552 : loss : 0.106814, loss_ce: 0.029428
2021-12-17 16:25:58,420 iteration 1553 : loss : 0.113880, loss_ce: 0.035044
2021-12-17 16:25:59,876 iteration 1554 : loss : 0.107349, loss_ce: 0.033734
2021-12-17 16:26:01,294 iteration 1555 : loss : 0.127063, loss_ce: 0.041700
2021-12-17 16:26:02,759 iteration 1556 : loss : 0.115201, loss_ce: 0.032471
2021-12-17 16:26:04,174 iteration 1557 : loss : 0.115279, loss_ce: 0.034027
2021-12-17 16:26:05,616 iteration 1558 : loss : 0.114733, loss_ce: 0.042029
2021-12-17 16:26:07,060 iteration 1559 : loss : 0.124265, loss_ce: 0.038334
2021-12-17 16:26:08,451 iteration 1560 : loss : 0.104545, loss_ce: 0.035610
2021-12-17 16:26:09,933 iteration 1561 : loss : 0.109865, loss_ce: 0.031114
2021-12-17 16:26:11,343 iteration 1562 : loss : 0.116912, loss_ce: 0.025730
2021-12-17 16:26:12,822 iteration 1563 : loss : 0.118491, loss_ce: 0.038588
2021-12-17 16:26:14,294 iteration 1564 : loss : 0.109898, loss_ce: 0.036718
 23%|██████▉                       | 92/400 [42:26<2:15:31, 26.40s/it]2021-12-17 16:26:15,742 iteration 1565 : loss : 0.109433, loss_ce: 0.037880
2021-12-17 16:26:17,164 iteration 1566 : loss : 0.117769, loss_ce: 0.036295
2021-12-17 16:26:18,629 iteration 1567 : loss : 0.104483, loss_ce: 0.028873
2021-12-17 16:26:20,035 iteration 1568 : loss : 0.129121, loss_ce: 0.036547
2021-12-17 16:26:21,504 iteration 1569 : loss : 0.109078, loss_ce: 0.034603
2021-12-17 16:26:22,950 iteration 1570 : loss : 0.097668, loss_ce: 0.029952
2021-12-17 16:26:24,364 iteration 1571 : loss : 0.130897, loss_ce: 0.025482
2021-12-17 16:26:25,884 iteration 1572 : loss : 0.136861, loss_ce: 0.043076
2021-12-17 16:26:27,337 iteration 1573 : loss : 0.130126, loss_ce: 0.046686
2021-12-17 16:26:28,730 iteration 1574 : loss : 0.090203, loss_ce: 0.025440
2021-12-17 16:26:30,123 iteration 1575 : loss : 0.112953, loss_ce: 0.036066
2021-12-17 16:26:31,552 iteration 1576 : loss : 0.101392, loss_ce: 0.034906
2021-12-17 16:26:32,994 iteration 1577 : loss : 0.108105, loss_ce: 0.034265
2021-12-17 16:26:34,434 iteration 1578 : loss : 0.118655, loss_ce: 0.031805
2021-12-17 16:26:35,905 iteration 1579 : loss : 0.092060, loss_ce: 0.025630
2021-12-17 16:26:37,297 iteration 1580 : loss : 0.107103, loss_ce: 0.033048
2021-12-17 16:26:38,727 iteration 1581 : loss : 0.103063, loss_ce: 0.025745
 23%|██████▉                       | 93/400 [42:50<2:12:03, 25.81s/it]2021-12-17 16:26:40,264 iteration 1582 : loss : 0.109007, loss_ce: 0.030819
2021-12-17 16:26:41,675 iteration 1583 : loss : 0.117983, loss_ce: 0.028387
2021-12-17 16:26:43,125 iteration 1584 : loss : 0.112470, loss_ce: 0.038755
2021-12-17 16:26:44,543 iteration 1585 : loss : 0.094949, loss_ce: 0.026321
2021-12-17 16:26:45,964 iteration 1586 : loss : 0.123668, loss_ce: 0.039840
2021-12-17 16:26:47,317 iteration 1587 : loss : 0.095244, loss_ce: 0.030122
2021-12-17 16:26:48,795 iteration 1588 : loss : 0.121907, loss_ce: 0.043572
2021-12-17 16:26:50,238 iteration 1589 : loss : 0.109927, loss_ce: 0.037205
2021-12-17 16:26:51,789 iteration 1590 : loss : 0.117720, loss_ce: 0.035263
2021-12-17 16:26:53,168 iteration 1591 : loss : 0.098886, loss_ce: 0.024162
2021-12-17 16:26:54,601 iteration 1592 : loss : 0.113695, loss_ce: 0.033243
2021-12-17 16:26:56,129 iteration 1593 : loss : 0.125968, loss_ce: 0.041438
2021-12-17 16:26:57,637 iteration 1594 : loss : 0.136694, loss_ce: 0.043411
2021-12-17 16:26:59,057 iteration 1595 : loss : 0.091828, loss_ce: 0.021964
2021-12-17 16:27:00,499 iteration 1596 : loss : 0.130793, loss_ce: 0.050255
2021-12-17 16:27:01,932 iteration 1597 : loss : 0.123824, loss_ce: 0.039797
2021-12-17 16:27:03,384 iteration 1598 : loss : 0.122216, loss_ce: 0.040355
 24%|███████                       | 94/400 [43:15<2:09:52, 25.47s/it]2021-12-17 16:27:04,838 iteration 1599 : loss : 0.105097, loss_ce: 0.032534
2021-12-17 16:27:06,264 iteration 1600 : loss : 0.104113, loss_ce: 0.024889
2021-12-17 16:27:07,757 iteration 1601 : loss : 0.112862, loss_ce: 0.034410
2021-12-17 16:27:09,301 iteration 1602 : loss : 0.117388, loss_ce: 0.038258
2021-12-17 16:27:10,725 iteration 1603 : loss : 0.106485, loss_ce: 0.028756
2021-12-17 16:27:12,135 iteration 1604 : loss : 0.106402, loss_ce: 0.032966
2021-12-17 16:27:13,617 iteration 1605 : loss : 0.124687, loss_ce: 0.033894
2021-12-17 16:27:15,043 iteration 1606 : loss : 0.130342, loss_ce: 0.053080
2021-12-17 16:27:16,454 iteration 1607 : loss : 0.101810, loss_ce: 0.031228
2021-12-17 16:27:17,965 iteration 1608 : loss : 0.108025, loss_ce: 0.028993
2021-12-17 16:27:19,385 iteration 1609 : loss : 0.118771, loss_ce: 0.044566
2021-12-17 16:27:20,831 iteration 1610 : loss : 0.104371, loss_ce: 0.031318
2021-12-17 16:27:22,352 iteration 1611 : loss : 0.130512, loss_ce: 0.034636
2021-12-17 16:27:23,784 iteration 1612 : loss : 0.103136, loss_ce: 0.034618
2021-12-17 16:27:25,099 iteration 1613 : loss : 0.109936, loss_ce: 0.035466
2021-12-17 16:27:26,570 iteration 1614 : loss : 0.103652, loss_ce: 0.026273
2021-12-17 16:27:26,571 Training Data Eval:
2021-12-17 16:27:34,038   Average segmentation loss on training set: 0.0909
2021-12-17 16:27:34,038 Validation Data Eval:
2021-12-17 16:27:36,622   Average segmentation loss on validation set: 0.1715
2021-12-17 16:27:38,094 iteration 1615 : loss : 0.099532, loss_ce: 0.030147
 24%|███████▏                      | 95/400 [43:50<2:23:32, 28.24s/it]2021-12-17 16:27:39,609 iteration 1616 : loss : 0.109392, loss_ce: 0.033466
2021-12-17 16:27:41,074 iteration 1617 : loss : 0.110132, loss_ce: 0.026591
2021-12-17 16:27:42,447 iteration 1618 : loss : 0.106878, loss_ce: 0.030162
2021-12-17 16:27:43,833 iteration 1619 : loss : 0.095849, loss_ce: 0.025104
2021-12-17 16:27:45,187 iteration 1620 : loss : 0.097026, loss_ce: 0.023261
2021-12-17 16:27:46,628 iteration 1621 : loss : 0.121767, loss_ce: 0.051517
2021-12-17 16:27:48,183 iteration 1622 : loss : 0.142539, loss_ce: 0.045858
2021-12-17 16:27:49,606 iteration 1623 : loss : 0.118837, loss_ce: 0.038738
2021-12-17 16:27:51,007 iteration 1624 : loss : 0.111245, loss_ce: 0.033070
2021-12-17 16:27:52,444 iteration 1625 : loss : 0.108079, loss_ce: 0.032452
2021-12-17 16:27:53,859 iteration 1626 : loss : 0.099497, loss_ce: 0.031895
2021-12-17 16:27:55,276 iteration 1627 : loss : 0.114778, loss_ce: 0.033757
2021-12-17 16:27:56,778 iteration 1628 : loss : 0.120841, loss_ce: 0.036466
2021-12-17 16:27:58,192 iteration 1629 : loss : 0.104860, loss_ce: 0.032671
2021-12-17 16:27:59,573 iteration 1630 : loss : 0.105856, loss_ce: 0.031069
2021-12-17 16:28:01,117 iteration 1631 : loss : 0.112849, loss_ce: 0.039360
2021-12-17 16:28:02,625 iteration 1632 : loss : 0.126692, loss_ce: 0.039825
 24%|███████▏                      | 96/400 [44:14<2:17:25, 27.12s/it]2021-12-17 16:28:04,147 iteration 1633 : loss : 0.104709, loss_ce: 0.030573
2021-12-17 16:28:05,607 iteration 1634 : loss : 0.123705, loss_ce: 0.036388
2021-12-17 16:28:07,043 iteration 1635 : loss : 0.110083, loss_ce: 0.041795
2021-12-17 16:28:08,560 iteration 1636 : loss : 0.113538, loss_ce: 0.041993
2021-12-17 16:28:10,009 iteration 1637 : loss : 0.126753, loss_ce: 0.040067
2021-12-17 16:28:11,416 iteration 1638 : loss : 0.105703, loss_ce: 0.031772
2021-12-17 16:28:12,950 iteration 1639 : loss : 0.121829, loss_ce: 0.027275
2021-12-17 16:28:14,412 iteration 1640 : loss : 0.136352, loss_ce: 0.033684
2021-12-17 16:28:15,781 iteration 1641 : loss : 0.103981, loss_ce: 0.038607
2021-12-17 16:28:17,207 iteration 1642 : loss : 0.098459, loss_ce: 0.025770
2021-12-17 16:28:18,681 iteration 1643 : loss : 0.108522, loss_ce: 0.027437
2021-12-17 16:28:20,087 iteration 1644 : loss : 0.113675, loss_ce: 0.031692
2021-12-17 16:28:21,510 iteration 1645 : loss : 0.104521, loss_ce: 0.029750
2021-12-17 16:28:22,941 iteration 1646 : loss : 0.107638, loss_ce: 0.028303
2021-12-17 16:28:24,359 iteration 1647 : loss : 0.110816, loss_ce: 0.033851
2021-12-17 16:28:25,795 iteration 1648 : loss : 0.127858, loss_ce: 0.045148
2021-12-17 16:28:27,165 iteration 1649 : loss : 0.113052, loss_ce: 0.038429
 24%|███████▎                      | 97/400 [44:39<2:13:04, 26.35s/it]2021-12-17 16:28:28,660 iteration 1650 : loss : 0.109646, loss_ce: 0.038287
2021-12-17 16:28:30,215 iteration 1651 : loss : 0.144327, loss_ce: 0.039992
2021-12-17 16:28:31,600 iteration 1652 : loss : 0.108579, loss_ce: 0.027304
2021-12-17 16:28:32,984 iteration 1653 : loss : 0.110919, loss_ce: 0.028120
2021-12-17 16:28:34,461 iteration 1654 : loss : 0.134100, loss_ce: 0.030979
2021-12-17 16:28:35,966 iteration 1655 : loss : 0.128925, loss_ce: 0.039171
2021-12-17 16:28:37,398 iteration 1656 : loss : 0.105088, loss_ce: 0.031018
2021-12-17 16:28:38,943 iteration 1657 : loss : 0.114329, loss_ce: 0.028928
2021-12-17 16:28:40,419 iteration 1658 : loss : 0.139449, loss_ce: 0.062934
2021-12-17 16:28:41,806 iteration 1659 : loss : 0.093475, loss_ce: 0.022813
2021-12-17 16:28:43,351 iteration 1660 : loss : 0.129182, loss_ce: 0.046244
2021-12-17 16:28:44,867 iteration 1661 : loss : 0.106658, loss_ce: 0.025124
2021-12-17 16:28:46,302 iteration 1662 : loss : 0.122409, loss_ce: 0.040775
2021-12-17 16:28:47,637 iteration 1663 : loss : 0.090939, loss_ce: 0.031972
2021-12-17 16:28:49,155 iteration 1664 : loss : 0.109707, loss_ce: 0.033506
2021-12-17 16:28:50,615 iteration 1665 : loss : 0.109470, loss_ce: 0.031339
2021-12-17 16:28:52,106 iteration 1666 : loss : 0.103574, loss_ce: 0.036321
 24%|███████▎                      | 98/400 [45:04<2:10:30, 25.93s/it]2021-12-17 16:28:53,605 iteration 1667 : loss : 0.123510, loss_ce: 0.031690
2021-12-17 16:28:55,037 iteration 1668 : loss : 0.111691, loss_ce: 0.032090
2021-12-17 16:28:56,432 iteration 1669 : loss : 0.097134, loss_ce: 0.029319
2021-12-17 16:28:57,896 iteration 1670 : loss : 0.108050, loss_ce: 0.034457
2021-12-17 16:28:59,333 iteration 1671 : loss : 0.099534, loss_ce: 0.025637
2021-12-17 16:29:00,839 iteration 1672 : loss : 0.110291, loss_ce: 0.032425
2021-12-17 16:29:02,307 iteration 1673 : loss : 0.115774, loss_ce: 0.042209
2021-12-17 16:29:03,816 iteration 1674 : loss : 0.130901, loss_ce: 0.054104
2021-12-17 16:29:05,219 iteration 1675 : loss : 0.107745, loss_ce: 0.027501
2021-12-17 16:29:06,636 iteration 1676 : loss : 0.122134, loss_ce: 0.034460
2021-12-17 16:29:08,154 iteration 1677 : loss : 0.121740, loss_ce: 0.045758
2021-12-17 16:29:09,487 iteration 1678 : loss : 0.097613, loss_ce: 0.029992
2021-12-17 16:29:10,911 iteration 1679 : loss : 0.112917, loss_ce: 0.029364
2021-12-17 16:29:12,385 iteration 1680 : loss : 0.101469, loss_ce: 0.035058
2021-12-17 16:29:13,848 iteration 1681 : loss : 0.119656, loss_ce: 0.045826
2021-12-17 16:29:15,310 iteration 1682 : loss : 0.120726, loss_ce: 0.038023
2021-12-17 16:29:16,692 iteration 1683 : loss : 0.105135, loss_ce: 0.027495
 25%|███████▍                      | 99/400 [45:28<2:08:03, 25.53s/it]2021-12-17 16:29:18,200 iteration 1684 : loss : 0.099766, loss_ce: 0.028608
2021-12-17 16:29:19,631 iteration 1685 : loss : 0.102433, loss_ce: 0.024592
2021-12-17 16:29:21,040 iteration 1686 : loss : 0.096238, loss_ce: 0.027547
2021-12-17 16:29:22,415 iteration 1687 : loss : 0.107828, loss_ce: 0.030976
2021-12-17 16:29:23,974 iteration 1688 : loss : 0.113066, loss_ce: 0.039028
2021-12-17 16:29:25,425 iteration 1689 : loss : 0.114398, loss_ce: 0.038712
2021-12-17 16:29:26,907 iteration 1690 : loss : 0.106171, loss_ce: 0.034703
2021-12-17 16:29:28,281 iteration 1691 : loss : 0.133494, loss_ce: 0.029695
2021-12-17 16:29:29,782 iteration 1692 : loss : 0.143810, loss_ce: 0.044948
2021-12-17 16:29:31,116 iteration 1693 : loss : 0.098894, loss_ce: 0.030568
2021-12-17 16:29:32,584 iteration 1694 : loss : 0.099325, loss_ce: 0.030149
2021-12-17 16:29:34,075 iteration 1695 : loss : 0.110184, loss_ce: 0.034977
2021-12-17 16:29:35,575 iteration 1696 : loss : 0.115594, loss_ce: 0.033670
2021-12-17 16:29:36,998 iteration 1697 : loss : 0.106416, loss_ce: 0.030918
2021-12-17 16:29:38,478 iteration 1698 : loss : 0.108265, loss_ce: 0.029274
2021-12-17 16:29:39,918 iteration 1699 : loss : 0.113616, loss_ce: 0.045026
2021-12-17 16:29:39,918 Training Data Eval:
2021-12-17 16:29:47,385   Average segmentation loss on training set: 0.0871
2021-12-17 16:29:47,386 Validation Data Eval:
2021-12-17 16:29:49,977   Average segmentation loss on validation set: 0.1527
2021-12-17 16:29:57,835 Found new lowest validation loss at iteration 1699! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/TU_3seeds/TU_RESNET_no_pretraining_SGD_best_val_loss_seed2.pth
2021-12-17 16:29:59,195 iteration 1700 : loss : 0.106950, loss_ce: 0.027460
 25%|███████▎                     | 100/400 [46:11<2:33:05, 30.62s/it]2021-12-17 16:30:00,599 iteration 1701 : loss : 0.109000, loss_ce: 0.036496
2021-12-17 16:30:01,930 iteration 1702 : loss : 0.117943, loss_ce: 0.035401
2021-12-17 16:30:03,370 iteration 1703 : loss : 0.109040, loss_ce: 0.037198
2021-12-17 16:30:04,784 iteration 1704 : loss : 0.110886, loss_ce: 0.037318
2021-12-17 16:30:06,136 iteration 1705 : loss : 0.111769, loss_ce: 0.030804
2021-12-17 16:30:07,555 iteration 1706 : loss : 0.103160, loss_ce: 0.024576
2021-12-17 16:30:08,902 iteration 1707 : loss : 0.123408, loss_ce: 0.036502
2021-12-17 16:30:10,258 iteration 1708 : loss : 0.101538, loss_ce: 0.029770
2021-12-17 16:30:11,777 iteration 1709 : loss : 0.130907, loss_ce: 0.042351
2021-12-17 16:30:13,110 iteration 1710 : loss : 0.111384, loss_ce: 0.037349
2021-12-17 16:30:14,501 iteration 1711 : loss : 0.105517, loss_ce: 0.028058
2021-12-17 16:30:15,893 iteration 1712 : loss : 0.115320, loss_ce: 0.030621
2021-12-17 16:30:17,281 iteration 1713 : loss : 0.123970, loss_ce: 0.033069
2021-12-17 16:30:18,697 iteration 1714 : loss : 0.107186, loss_ce: 0.034065
2021-12-17 16:30:20,237 iteration 1715 : loss : 0.116488, loss_ce: 0.035894
2021-12-17 16:30:21,697 iteration 1716 : loss : 0.117625, loss_ce: 0.030345
2021-12-17 16:30:23,189 iteration 1717 : loss : 0.096116, loss_ce: 0.029360
 25%|███████▎                     | 101/400 [46:35<2:22:40, 28.63s/it]2021-12-17 16:30:24,735 iteration 1718 : loss : 0.116571, loss_ce: 0.032845
2021-12-17 16:30:26,286 iteration 1719 : loss : 0.098426, loss_ce: 0.024633
2021-12-17 16:30:27,792 iteration 1720 : loss : 0.104152, loss_ce: 0.031419
2021-12-17 16:30:29,258 iteration 1721 : loss : 0.113876, loss_ce: 0.037834
2021-12-17 16:30:30,679 iteration 1722 : loss : 0.097657, loss_ce: 0.027454
2021-12-17 16:30:32,124 iteration 1723 : loss : 0.107895, loss_ce: 0.033960
2021-12-17 16:30:33,520 iteration 1724 : loss : 0.096429, loss_ce: 0.029167
2021-12-17 16:30:34,931 iteration 1725 : loss : 0.098978, loss_ce: 0.031551
2021-12-17 16:30:36,503 iteration 1726 : loss : 0.115502, loss_ce: 0.032225
2021-12-17 16:30:38,016 iteration 1727 : loss : 0.098523, loss_ce: 0.024915
2021-12-17 16:30:39,565 iteration 1728 : loss : 0.133488, loss_ce: 0.049993
2021-12-17 16:30:40,975 iteration 1729 : loss : 0.105871, loss_ce: 0.029362
2021-12-17 16:30:42,457 iteration 1730 : loss : 0.096380, loss_ce: 0.026851
2021-12-17 16:30:43,884 iteration 1731 : loss : 0.100177, loss_ce: 0.031899
2021-12-17 16:30:45,368 iteration 1732 : loss : 0.104700, loss_ce: 0.031118
2021-12-17 16:30:46,838 iteration 1733 : loss : 0.104436, loss_ce: 0.028153
2021-12-17 16:30:48,271 iteration 1734 : loss : 0.116249, loss_ce: 0.029819
 26%|███████▍                     | 102/400 [47:00<2:16:54, 27.56s/it]2021-12-17 16:30:49,825 iteration 1735 : loss : 0.103441, loss_ce: 0.030011
2021-12-17 16:30:51,294 iteration 1736 : loss : 0.102678, loss_ce: 0.033049
2021-12-17 16:30:52,782 iteration 1737 : loss : 0.113305, loss_ce: 0.036314
2021-12-17 16:30:54,224 iteration 1738 : loss : 0.123795, loss_ce: 0.037204
2021-12-17 16:30:55,660 iteration 1739 : loss : 0.109438, loss_ce: 0.040725
2021-12-17 16:30:57,094 iteration 1740 : loss : 0.124014, loss_ce: 0.027566
2021-12-17 16:30:58,631 iteration 1741 : loss : 0.105361, loss_ce: 0.027632
2021-12-17 16:31:00,098 iteration 1742 : loss : 0.112779, loss_ce: 0.030491
2021-12-17 16:31:01,552 iteration 1743 : loss : 0.120285, loss_ce: 0.050531
2021-12-17 16:31:02,955 iteration 1744 : loss : 0.095295, loss_ce: 0.025211
2021-12-17 16:31:04,476 iteration 1745 : loss : 0.110900, loss_ce: 0.036250
2021-12-17 16:31:05,907 iteration 1746 : loss : 0.119845, loss_ce: 0.030184
2021-12-17 16:31:07,344 iteration 1747 : loss : 0.114840, loss_ce: 0.031237
2021-12-17 16:31:08,750 iteration 1748 : loss : 0.100824, loss_ce: 0.037224
2021-12-17 16:31:10,224 iteration 1749 : loss : 0.108369, loss_ce: 0.034436
2021-12-17 16:31:11,626 iteration 1750 : loss : 0.102305, loss_ce: 0.039060
2021-12-17 16:31:13,042 iteration 1751 : loss : 0.104118, loss_ce: 0.030596
 26%|███████▍                     | 103/400 [47:24<2:12:18, 26.73s/it]2021-12-17 16:31:14,546 iteration 1752 : loss : 0.109716, loss_ce: 0.039316
2021-12-17 16:31:16,074 iteration 1753 : loss : 0.110201, loss_ce: 0.038806
2021-12-17 16:31:17,548 iteration 1754 : loss : 0.096490, loss_ce: 0.032962
2021-12-17 16:31:19,021 iteration 1755 : loss : 0.109502, loss_ce: 0.028553
2021-12-17 16:31:20,531 iteration 1756 : loss : 0.103171, loss_ce: 0.034621
2021-12-17 16:31:22,000 iteration 1757 : loss : 0.122820, loss_ce: 0.024966
2021-12-17 16:31:23,474 iteration 1758 : loss : 0.099247, loss_ce: 0.028471
2021-12-17 16:31:24,921 iteration 1759 : loss : 0.117298, loss_ce: 0.034450
2021-12-17 16:31:26,427 iteration 1760 : loss : 0.111608, loss_ce: 0.037925
2021-12-17 16:31:27,823 iteration 1761 : loss : 0.094317, loss_ce: 0.029140
2021-12-17 16:31:29,340 iteration 1762 : loss : 0.134489, loss_ce: 0.045194
2021-12-17 16:31:30,767 iteration 1763 : loss : 0.101943, loss_ce: 0.027556
2021-12-17 16:31:32,268 iteration 1764 : loss : 0.125168, loss_ce: 0.028577
2021-12-17 16:31:33,749 iteration 1765 : loss : 0.135683, loss_ce: 0.032908
2021-12-17 16:31:35,149 iteration 1766 : loss : 0.100137, loss_ce: 0.034473
2021-12-17 16:31:36,591 iteration 1767 : loss : 0.106095, loss_ce: 0.033720
2021-12-17 16:31:38,110 iteration 1768 : loss : 0.134425, loss_ce: 0.038242
 26%|███████▌                     | 104/400 [47:50<2:09:23, 26.23s/it]2021-12-17 16:31:39,585 iteration 1769 : loss : 0.092353, loss_ce: 0.023507
2021-12-17 16:31:41,219 iteration 1770 : loss : 0.123882, loss_ce: 0.039756
2021-12-17 16:31:42,667 iteration 1771 : loss : 0.114468, loss_ce: 0.036241
2021-12-17 16:31:44,074 iteration 1772 : loss : 0.090269, loss_ce: 0.019585
2021-12-17 16:31:45,451 iteration 1773 : loss : 0.097226, loss_ce: 0.023040
2021-12-17 16:31:46,902 iteration 1774 : loss : 0.090647, loss_ce: 0.026616
2021-12-17 16:31:48,413 iteration 1775 : loss : 0.113612, loss_ce: 0.039033
2021-12-17 16:31:49,869 iteration 1776 : loss : 0.108821, loss_ce: 0.024921
2021-12-17 16:31:51,312 iteration 1777 : loss : 0.110475, loss_ce: 0.034319
2021-12-17 16:31:52,759 iteration 1778 : loss : 0.124112, loss_ce: 0.041555
2021-12-17 16:31:54,217 iteration 1779 : loss : 0.111608, loss_ce: 0.035489
2021-12-17 16:31:55,650 iteration 1780 : loss : 0.105137, loss_ce: 0.032419
2021-12-17 16:31:57,081 iteration 1781 : loss : 0.111219, loss_ce: 0.044685
2021-12-17 16:31:58,554 iteration 1782 : loss : 0.124376, loss_ce: 0.037059
2021-12-17 16:31:59,958 iteration 1783 : loss : 0.111461, loss_ce: 0.038754
2021-12-17 16:32:01,498 iteration 1784 : loss : 0.108745, loss_ce: 0.034678
2021-12-17 16:32:01,498 Training Data Eval:
2021-12-17 16:32:09,015   Average segmentation loss on training set: 0.0851
2021-12-17 16:32:09,016 Validation Data Eval:
2021-12-17 16:32:11,616   Average segmentation loss on validation set: 0.1583
2021-12-17 16:32:13,096 iteration 1785 : loss : 0.107267, loss_ce: 0.033620
 26%|███████▌                     | 105/400 [48:25<2:21:52, 28.86s/it]2021-12-17 16:32:14,732 iteration 1786 : loss : 0.112104, loss_ce: 0.042373
2021-12-17 16:32:16,284 iteration 1787 : loss : 0.120179, loss_ce: 0.037994
2021-12-17 16:32:17,759 iteration 1788 : loss : 0.110520, loss_ce: 0.033756
2021-12-17 16:32:19,210 iteration 1789 : loss : 0.099068, loss_ce: 0.024806
2021-12-17 16:32:20,646 iteration 1790 : loss : 0.095861, loss_ce: 0.030179
2021-12-17 16:32:22,049 iteration 1791 : loss : 0.092245, loss_ce: 0.029748
2021-12-17 16:32:23,547 iteration 1792 : loss : 0.109761, loss_ce: 0.030862
2021-12-17 16:32:25,048 iteration 1793 : loss : 0.098018, loss_ce: 0.034947
2021-12-17 16:32:26,471 iteration 1794 : loss : 0.099695, loss_ce: 0.035771
2021-12-17 16:32:27,954 iteration 1795 : loss : 0.102811, loss_ce: 0.032533
2021-12-17 16:32:29,433 iteration 1796 : loss : 0.112125, loss_ce: 0.030999
2021-12-17 16:32:30,966 iteration 1797 : loss : 0.100152, loss_ce: 0.027162
2021-12-17 16:32:32,402 iteration 1798 : loss : 0.121243, loss_ce: 0.034962
2021-12-17 16:32:33,883 iteration 1799 : loss : 0.110920, loss_ce: 0.028952
2021-12-17 16:32:35,360 iteration 1800 : loss : 0.128085, loss_ce: 0.049448
2021-12-17 16:32:36,843 iteration 1801 : loss : 0.104210, loss_ce: 0.030083
2021-12-17 16:32:38,215 iteration 1802 : loss : 0.112536, loss_ce: 0.024189
 26%|███████▋                     | 106/400 [48:50<2:15:54, 27.74s/it]2021-12-17 16:32:39,745 iteration 1803 : loss : 0.113431, loss_ce: 0.031727
2021-12-17 16:32:41,176 iteration 1804 : loss : 0.117535, loss_ce: 0.026785
2021-12-17 16:32:42,562 iteration 1805 : loss : 0.087941, loss_ce: 0.028431
2021-12-17 16:32:43,979 iteration 1806 : loss : 0.122735, loss_ce: 0.034387
2021-12-17 16:32:45,437 iteration 1807 : loss : 0.100965, loss_ce: 0.026866
2021-12-17 16:32:46,885 iteration 1808 : loss : 0.125112, loss_ce: 0.044213
2021-12-17 16:32:48,326 iteration 1809 : loss : 0.108378, loss_ce: 0.039112
2021-12-17 16:32:49,794 iteration 1810 : loss : 0.108167, loss_ce: 0.033966
2021-12-17 16:32:51,275 iteration 1811 : loss : 0.116106, loss_ce: 0.031636
2021-12-17 16:32:52,796 iteration 1812 : loss : 0.113916, loss_ce: 0.038503
2021-12-17 16:32:54,286 iteration 1813 : loss : 0.124670, loss_ce: 0.038530
2021-12-17 16:32:55,810 iteration 1814 : loss : 0.124293, loss_ce: 0.041879
2021-12-17 16:32:57,263 iteration 1815 : loss : 0.097274, loss_ce: 0.032665
2021-12-17 16:32:58,763 iteration 1816 : loss : 0.131320, loss_ce: 0.040006
2021-12-17 16:33:00,211 iteration 1817 : loss : 0.097313, loss_ce: 0.024306
2021-12-17 16:33:01,758 iteration 1818 : loss : 0.110312, loss_ce: 0.044766
2021-12-17 16:33:03,209 iteration 1819 : loss : 0.096205, loss_ce: 0.026916
 27%|███████▊                     | 107/400 [49:15<2:11:24, 26.91s/it]2021-12-17 16:33:04,765 iteration 1820 : loss : 0.122298, loss_ce: 0.034697
2021-12-17 16:33:06,175 iteration 1821 : loss : 0.109544, loss_ce: 0.026883
2021-12-17 16:33:07,582 iteration 1822 : loss : 0.098139, loss_ce: 0.034564
2021-12-17 16:33:09,069 iteration 1823 : loss : 0.104089, loss_ce: 0.030852
2021-12-17 16:33:10,520 iteration 1824 : loss : 0.093154, loss_ce: 0.024696
2021-12-17 16:33:12,004 iteration 1825 : loss : 0.096844, loss_ce: 0.027311
2021-12-17 16:33:13,395 iteration 1826 : loss : 0.093342, loss_ce: 0.028716
2021-12-17 16:33:14,814 iteration 1827 : loss : 0.120001, loss_ce: 0.029943
2021-12-17 16:33:16,301 iteration 1828 : loss : 0.100619, loss_ce: 0.033878
2021-12-17 16:33:17,783 iteration 1829 : loss : 0.115483, loss_ce: 0.026954
2021-12-17 16:33:19,222 iteration 1830 : loss : 0.099309, loss_ce: 0.030792
2021-12-17 16:33:20,653 iteration 1831 : loss : 0.108905, loss_ce: 0.038072
2021-12-17 16:33:22,085 iteration 1832 : loss : 0.092178, loss_ce: 0.025263
2021-12-17 16:33:23,509 iteration 1833 : loss : 0.093878, loss_ce: 0.034742
2021-12-17 16:33:25,025 iteration 1834 : loss : 0.108580, loss_ce: 0.034247
2021-12-17 16:33:26,395 iteration 1835 : loss : 0.089947, loss_ce: 0.023602
2021-12-17 16:33:27,811 iteration 1836 : loss : 0.107172, loss_ce: 0.037388
 27%|███████▊                     | 108/400 [49:39<2:07:36, 26.22s/it]2021-12-17 16:33:29,245 iteration 1837 : loss : 0.101335, loss_ce: 0.017834
2021-12-17 16:33:30,758 iteration 1838 : loss : 0.108237, loss_ce: 0.036371
2021-12-17 16:33:32,144 iteration 1839 : loss : 0.101458, loss_ce: 0.034186
2021-12-17 16:33:33,598 iteration 1840 : loss : 0.106262, loss_ce: 0.025251
2021-12-17 16:33:35,061 iteration 1841 : loss : 0.108078, loss_ce: 0.026949
2021-12-17 16:33:36,582 iteration 1842 : loss : 0.099775, loss_ce: 0.029844
2021-12-17 16:33:38,007 iteration 1843 : loss : 0.116236, loss_ce: 0.044367
2021-12-17 16:33:39,455 iteration 1844 : loss : 0.106222, loss_ce: 0.032333
2021-12-17 16:33:40,907 iteration 1845 : loss : 0.088420, loss_ce: 0.025528
2021-12-17 16:33:42,368 iteration 1846 : loss : 0.103871, loss_ce: 0.029575
2021-12-17 16:33:43,733 iteration 1847 : loss : 0.091794, loss_ce: 0.025266
2021-12-17 16:33:45,195 iteration 1848 : loss : 0.101039, loss_ce: 0.028729
2021-12-17 16:33:46,657 iteration 1849 : loss : 0.100477, loss_ce: 0.026119
2021-12-17 16:33:48,121 iteration 1850 : loss : 0.111958, loss_ce: 0.028986
2021-12-17 16:33:49,609 iteration 1851 : loss : 0.095686, loss_ce: 0.030284
2021-12-17 16:33:50,969 iteration 1852 : loss : 0.100646, loss_ce: 0.035796
2021-12-17 16:33:52,459 iteration 1853 : loss : 0.107514, loss_ce: 0.036998
 27%|███████▉                     | 109/400 [50:04<2:04:52, 25.75s/it]2021-12-17 16:33:53,971 iteration 1854 : loss : 0.103163, loss_ce: 0.026379
2021-12-17 16:33:55,463 iteration 1855 : loss : 0.107912, loss_ce: 0.033049
2021-12-17 16:33:56,821 iteration 1856 : loss : 0.099696, loss_ce: 0.031895
2021-12-17 16:33:58,199 iteration 1857 : loss : 0.090497, loss_ce: 0.030029
2021-12-17 16:33:59,605 iteration 1858 : loss : 0.092359, loss_ce: 0.031165
2021-12-17 16:34:01,066 iteration 1859 : loss : 0.098012, loss_ce: 0.030183
2021-12-17 16:34:02,551 iteration 1860 : loss : 0.116655, loss_ce: 0.037234
2021-12-17 16:34:04,007 iteration 1861 : loss : 0.102518, loss_ce: 0.039018
2021-12-17 16:34:05,473 iteration 1862 : loss : 0.104711, loss_ce: 0.038357
2021-12-17 16:34:06,951 iteration 1863 : loss : 0.121232, loss_ce: 0.034236
2021-12-17 16:34:08,417 iteration 1864 : loss : 0.092747, loss_ce: 0.026103
2021-12-17 16:34:09,874 iteration 1865 : loss : 0.111589, loss_ce: 0.027114
2021-12-17 16:34:11,331 iteration 1866 : loss : 0.083024, loss_ce: 0.021795
2021-12-17 16:34:12,692 iteration 1867 : loss : 0.080191, loss_ce: 0.018572
2021-12-17 16:34:14,120 iteration 1868 : loss : 0.093050, loss_ce: 0.026368
2021-12-17 16:34:15,533 iteration 1869 : loss : 0.099261, loss_ce: 0.033972
2021-12-17 16:34:15,533 Training Data Eval:
2021-12-17 16:34:23,066   Average segmentation loss on training set: 0.0857
2021-12-17 16:34:23,067 Validation Data Eval:
2021-12-17 16:34:25,669   Average segmentation loss on validation set: 0.1553
2021-12-17 16:34:27,155 iteration 1870 : loss : 0.116995, loss_ce: 0.034994
 28%|███████▉                     | 110/400 [50:39<2:17:25, 28.43s/it]2021-12-17 16:34:28,712 iteration 1871 : loss : 0.118811, loss_ce: 0.028783
2021-12-17 16:34:30,194 iteration 1872 : loss : 0.092205, loss_ce: 0.023462
2021-12-17 16:34:31,690 iteration 1873 : loss : 0.099540, loss_ce: 0.025604
2021-12-17 16:34:33,165 iteration 1874 : loss : 0.099523, loss_ce: 0.024112
2021-12-17 16:34:34,545 iteration 1875 : loss : 0.093061, loss_ce: 0.030219
2021-12-17 16:34:35,909 iteration 1876 : loss : 0.091500, loss_ce: 0.030628
2021-12-17 16:34:37,404 iteration 1877 : loss : 0.093573, loss_ce: 0.024293
2021-12-17 16:34:38,881 iteration 1878 : loss : 0.112163, loss_ce: 0.043995
2021-12-17 16:34:40,331 iteration 1879 : loss : 0.099034, loss_ce: 0.024887
2021-12-17 16:34:41,801 iteration 1880 : loss : 0.119598, loss_ce: 0.039710
2021-12-17 16:34:43,246 iteration 1881 : loss : 0.112756, loss_ce: 0.036770
2021-12-17 16:34:44,741 iteration 1882 : loss : 0.159114, loss_ce: 0.054291
2021-12-17 16:34:46,210 iteration 1883 : loss : 0.082526, loss_ce: 0.021290
2021-12-17 16:34:47,621 iteration 1884 : loss : 0.092211, loss_ce: 0.024505
2021-12-17 16:34:48,995 iteration 1885 : loss : 0.083128, loss_ce: 0.023794
2021-12-17 16:34:50,456 iteration 1886 : loss : 0.133892, loss_ce: 0.047052
2021-12-17 16:34:51,912 iteration 1887 : loss : 0.118843, loss_ce: 0.040594
 28%|████████                     | 111/400 [51:03<2:11:37, 27.33s/it]2021-12-17 16:34:53,497 iteration 1888 : loss : 0.113431, loss_ce: 0.028465
2021-12-17 16:34:54,876 iteration 1889 : loss : 0.101498, loss_ce: 0.025705
2021-12-17 16:34:56,262 iteration 1890 : loss : 0.092529, loss_ce: 0.031631
2021-12-17 16:34:57,669 iteration 1891 : loss : 0.100767, loss_ce: 0.030979
2021-12-17 16:34:59,111 iteration 1892 : loss : 0.090102, loss_ce: 0.031107
2021-12-17 16:35:00,577 iteration 1893 : loss : 0.096737, loss_ce: 0.023752
2021-12-17 16:35:02,023 iteration 1894 : loss : 0.095435, loss_ce: 0.029050
2021-12-17 16:35:03,404 iteration 1895 : loss : 0.096448, loss_ce: 0.030355
2021-12-17 16:35:04,911 iteration 1896 : loss : 0.119636, loss_ce: 0.039785
2021-12-17 16:35:06,368 iteration 1897 : loss : 0.126056, loss_ce: 0.038902
2021-12-17 16:35:07,892 iteration 1898 : loss : 0.113922, loss_ce: 0.039821
2021-12-17 16:35:09,345 iteration 1899 : loss : 0.108963, loss_ce: 0.027366
2021-12-17 16:35:10,751 iteration 1900 : loss : 0.120425, loss_ce: 0.040616
2021-12-17 16:35:12,141 iteration 1901 : loss : 0.102202, loss_ce: 0.026842
2021-12-17 16:35:13,583 iteration 1902 : loss : 0.110582, loss_ce: 0.040109
2021-12-17 16:35:15,052 iteration 1903 : loss : 0.105375, loss_ce: 0.032362
2021-12-17 16:35:16,536 iteration 1904 : loss : 0.097469, loss_ce: 0.026746
 28%|████████                     | 112/400 [51:28<2:07:17, 26.52s/it]2021-12-17 16:35:17,958 iteration 1905 : loss : 0.094460, loss_ce: 0.030435
2021-12-17 16:35:19,451 iteration 1906 : loss : 0.093195, loss_ce: 0.022558
2021-12-17 16:35:20,934 iteration 1907 : loss : 0.109031, loss_ce: 0.035626
2021-12-17 16:35:22,509 iteration 1908 : loss : 0.118859, loss_ce: 0.038492
2021-12-17 16:35:23,869 iteration 1909 : loss : 0.081393, loss_ce: 0.023688
2021-12-17 16:35:25,310 iteration 1910 : loss : 0.097470, loss_ce: 0.033231
2021-12-17 16:35:26,803 iteration 1911 : loss : 0.106690, loss_ce: 0.028004
2021-12-17 16:35:28,362 iteration 1912 : loss : 0.118850, loss_ce: 0.035559
2021-12-17 16:35:29,835 iteration 1913 : loss : 0.109504, loss_ce: 0.032715
2021-12-17 16:35:31,370 iteration 1914 : loss : 0.109647, loss_ce: 0.037800
2021-12-17 16:35:32,816 iteration 1915 : loss : 0.108959, loss_ce: 0.034530
2021-12-17 16:35:34,230 iteration 1916 : loss : 0.107977, loss_ce: 0.030844
2021-12-17 16:35:35,656 iteration 1917 : loss : 0.099132, loss_ce: 0.033761
2021-12-17 16:35:37,153 iteration 1918 : loss : 0.104814, loss_ce: 0.038190
2021-12-17 16:35:38,575 iteration 1919 : loss : 0.096801, loss_ce: 0.024909
2021-12-17 16:35:39,951 iteration 1920 : loss : 0.095582, loss_ce: 0.031313
2021-12-17 16:35:41,474 iteration 1921 : loss : 0.100121, loss_ce: 0.027139
 28%|████████▏                    | 113/400 [51:53<2:04:34, 26.04s/it]2021-12-17 16:35:43,021 iteration 1922 : loss : 0.125835, loss_ce: 0.045890
2021-12-17 16:35:44,425 iteration 1923 : loss : 0.094290, loss_ce: 0.027948
2021-12-17 16:35:45,925 iteration 1924 : loss : 0.110322, loss_ce: 0.031458
2021-12-17 16:35:47,311 iteration 1925 : loss : 0.104624, loss_ce: 0.024196
2021-12-17 16:35:48,822 iteration 1926 : loss : 0.110593, loss_ce: 0.036061
2021-12-17 16:35:50,329 iteration 1927 : loss : 0.112936, loss_ce: 0.042272
2021-12-17 16:35:51,721 iteration 1928 : loss : 0.091625, loss_ce: 0.021698
2021-12-17 16:35:53,309 iteration 1929 : loss : 0.121814, loss_ce: 0.049354
2021-12-17 16:35:54,752 iteration 1930 : loss : 0.099461, loss_ce: 0.034797
2021-12-17 16:35:56,251 iteration 1931 : loss : 0.108498, loss_ce: 0.031294
2021-12-17 16:35:57,727 iteration 1932 : loss : 0.131761, loss_ce: 0.040855
2021-12-17 16:35:59,195 iteration 1933 : loss : 0.093572, loss_ce: 0.025815
2021-12-17 16:36:00,622 iteration 1934 : loss : 0.107731, loss_ce: 0.027695
2021-12-17 16:36:02,065 iteration 1935 : loss : 0.100129, loss_ce: 0.029375
2021-12-17 16:36:03,480 iteration 1936 : loss : 0.090663, loss_ce: 0.027177
2021-12-17 16:36:04,874 iteration 1937 : loss : 0.093614, loss_ce: 0.025540
2021-12-17 16:36:06,352 iteration 1938 : loss : 0.108991, loss_ce: 0.036208
 28%|████████▎                    | 114/400 [52:18<2:02:28, 25.70s/it]2021-12-17 16:36:07,867 iteration 1939 : loss : 0.102533, loss_ce: 0.034355
2021-12-17 16:36:09,263 iteration 1940 : loss : 0.110822, loss_ce: 0.041876
2021-12-17 16:36:10,707 iteration 1941 : loss : 0.089029, loss_ce: 0.024800
2021-12-17 16:36:12,170 iteration 1942 : loss : 0.097645, loss_ce: 0.026049
2021-12-17 16:36:13,616 iteration 1943 : loss : 0.102292, loss_ce: 0.028766
2021-12-17 16:36:15,078 iteration 1944 : loss : 0.101315, loss_ce: 0.028031
2021-12-17 16:36:16,531 iteration 1945 : loss : 0.110420, loss_ce: 0.034585
2021-12-17 16:36:17,941 iteration 1946 : loss : 0.118387, loss_ce: 0.024828
2021-12-17 16:36:19,376 iteration 1947 : loss : 0.091938, loss_ce: 0.020262
2021-12-17 16:36:20,849 iteration 1948 : loss : 0.104868, loss_ce: 0.034028
2021-12-17 16:36:22,261 iteration 1949 : loss : 0.115358, loss_ce: 0.031860
2021-12-17 16:36:23,749 iteration 1950 : loss : 0.109473, loss_ce: 0.032161
2021-12-17 16:36:25,217 iteration 1951 : loss : 0.098757, loss_ce: 0.028112
2021-12-17 16:36:26,662 iteration 1952 : loss : 0.102555, loss_ce: 0.033187
2021-12-17 16:36:28,016 iteration 1953 : loss : 0.110127, loss_ce: 0.048363
2021-12-17 16:36:29,467 iteration 1954 : loss : 0.096329, loss_ce: 0.031412
2021-12-17 16:36:29,467 Training Data Eval:
2021-12-17 16:36:36,949   Average segmentation loss on training set: 0.0840
2021-12-17 16:36:36,949 Validation Data Eval:
2021-12-17 16:36:39,547   Average segmentation loss on validation set: 0.1502
2021-12-17 16:36:45,936 Found new lowest validation loss at iteration 1954! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/TU_3seeds/TU_RESNET_no_pretraining_SGD_best_val_loss_seed2.pth
2021-12-17 16:36:47,362 iteration 1955 : loss : 0.101172, loss_ce: 0.032770
 29%|████████▎                    | 115/400 [52:59<2:23:52, 30.29s/it]2021-12-17 16:36:48,753 iteration 1956 : loss : 0.110006, loss_ce: 0.034234
2021-12-17 16:36:50,176 iteration 1957 : loss : 0.109615, loss_ce: 0.041811
2021-12-17 16:36:51,535 iteration 1958 : loss : 0.123216, loss_ce: 0.027870
2021-12-17 16:36:52,878 iteration 1959 : loss : 0.098508, loss_ce: 0.023073
2021-12-17 16:36:54,153 iteration 1960 : loss : 0.089496, loss_ce: 0.024469
2021-12-17 16:36:55,402 iteration 1961 : loss : 0.085396, loss_ce: 0.024532
2021-12-17 16:36:56,809 iteration 1962 : loss : 0.100551, loss_ce: 0.031309
2021-12-17 16:36:58,124 iteration 1963 : loss : 0.091995, loss_ce: 0.027237
2021-12-17 16:36:59,526 iteration 1964 : loss : 0.100323, loss_ce: 0.026468
2021-12-17 16:37:00,808 iteration 1965 : loss : 0.096921, loss_ce: 0.033730
2021-12-17 16:37:02,195 iteration 1966 : loss : 0.097997, loss_ce: 0.026800
2021-12-17 16:37:03,749 iteration 1967 : loss : 0.101899, loss_ce: 0.031432
2021-12-17 16:37:05,355 iteration 1968 : loss : 0.117658, loss_ce: 0.041340
2021-12-17 16:37:06,852 iteration 1969 : loss : 0.117491, loss_ce: 0.034955
2021-12-17 16:37:08,238 iteration 1970 : loss : 0.095556, loss_ce: 0.031270
2021-12-17 16:37:09,709 iteration 1971 : loss : 0.093271, loss_ce: 0.024067
2021-12-17 16:37:11,175 iteration 1972 : loss : 0.101162, loss_ce: 0.024720
 29%|████████▍                    | 116/400 [53:23<2:14:10, 28.35s/it]2021-12-17 16:37:12,630 iteration 1973 : loss : 0.094187, loss_ce: 0.029641
2021-12-17 16:37:14,054 iteration 1974 : loss : 0.093118, loss_ce: 0.028674
2021-12-17 16:37:15,529 iteration 1975 : loss : 0.099807, loss_ce: 0.030381
2021-12-17 16:37:16,948 iteration 1976 : loss : 0.097091, loss_ce: 0.033217
2021-12-17 16:37:18,461 iteration 1977 : loss : 0.108589, loss_ce: 0.033336
2021-12-17 16:37:19,981 iteration 1978 : loss : 0.095740, loss_ce: 0.028051
2021-12-17 16:37:21,377 iteration 1979 : loss : 0.092202, loss_ce: 0.028838
2021-12-17 16:37:22,787 iteration 1980 : loss : 0.087054, loss_ce: 0.024523
2021-12-17 16:37:24,223 iteration 1981 : loss : 0.094148, loss_ce: 0.029746
2021-12-17 16:37:25,733 iteration 1982 : loss : 0.100657, loss_ce: 0.032098
2021-12-17 16:37:27,132 iteration 1983 : loss : 0.097917, loss_ce: 0.027450
2021-12-17 16:37:28,634 iteration 1984 : loss : 0.120713, loss_ce: 0.043968
2021-12-17 16:37:30,066 iteration 1985 : loss : 0.124600, loss_ce: 0.036099
2021-12-17 16:37:31,563 iteration 1986 : loss : 0.110704, loss_ce: 0.029584
2021-12-17 16:37:32,987 iteration 1987 : loss : 0.090937, loss_ce: 0.025262
2021-12-17 16:37:34,373 iteration 1988 : loss : 0.094412, loss_ce: 0.029802
2021-12-17 16:37:35,830 iteration 1989 : loss : 0.098836, loss_ce: 0.024958
 29%|████████▍                    | 117/400 [53:47<2:08:28, 27.24s/it]2021-12-17 16:37:37,322 iteration 1990 : loss : 0.107462, loss_ce: 0.023925
2021-12-17 16:37:38,698 iteration 1991 : loss : 0.087869, loss_ce: 0.026180
2021-12-17 16:37:40,177 iteration 1992 : loss : 0.090803, loss_ce: 0.024958
2021-12-17 16:37:41,661 iteration 1993 : loss : 0.097735, loss_ce: 0.030432
2021-12-17 16:37:43,183 iteration 1994 : loss : 0.103498, loss_ce: 0.035071
2021-12-17 16:37:44,618 iteration 1995 : loss : 0.099972, loss_ce: 0.030553
2021-12-17 16:37:46,100 iteration 1996 : loss : 0.100150, loss_ce: 0.030891
2021-12-17 16:37:47,494 iteration 1997 : loss : 0.098137, loss_ce: 0.028662
2021-12-17 16:37:48,952 iteration 1998 : loss : 0.100825, loss_ce: 0.031114
2021-12-17 16:37:50,431 iteration 1999 : loss : 0.095723, loss_ce: 0.027621
2021-12-17 16:37:51,886 iteration 2000 : loss : 0.098391, loss_ce: 0.036211
2021-12-17 16:37:53,286 iteration 2001 : loss : 0.101708, loss_ce: 0.028411
2021-12-17 16:37:54,791 iteration 2002 : loss : 0.100643, loss_ce: 0.029967
2021-12-17 16:37:56,195 iteration 2003 : loss : 0.097483, loss_ce: 0.022314
2021-12-17 16:37:57,678 iteration 2004 : loss : 0.101633, loss_ce: 0.038379
2021-12-17 16:37:59,096 iteration 2005 : loss : 0.094820, loss_ce: 0.032686
2021-12-17 16:38:00,548 iteration 2006 : loss : 0.096701, loss_ce: 0.026228
 30%|████████▌                    | 118/400 [54:12<2:04:27, 26.48s/it]2021-12-17 16:38:02,114 iteration 2007 : loss : 0.114891, loss_ce: 0.032131
2021-12-17 16:38:03,584 iteration 2008 : loss : 0.103874, loss_ce: 0.035719
2021-12-17 16:38:04,985 iteration 2009 : loss : 0.092269, loss_ce: 0.028050
2021-12-17 16:38:06,443 iteration 2010 : loss : 0.104344, loss_ce: 0.036037
2021-12-17 16:38:07,828 iteration 2011 : loss : 0.102149, loss_ce: 0.026080
2021-12-17 16:38:09,199 iteration 2012 : loss : 0.081303, loss_ce: 0.022487
2021-12-17 16:38:10,632 iteration 2013 : loss : 0.096883, loss_ce: 0.035475
2021-12-17 16:38:12,108 iteration 2014 : loss : 0.101221, loss_ce: 0.035082
2021-12-17 16:38:13,592 iteration 2015 : loss : 0.103609, loss_ce: 0.026129
2021-12-17 16:38:15,101 iteration 2016 : loss : 0.103121, loss_ce: 0.035197
2021-12-17 16:38:16,567 iteration 2017 : loss : 0.106185, loss_ce: 0.031287
2021-12-17 16:38:17,949 iteration 2018 : loss : 0.094766, loss_ce: 0.025128
2021-12-17 16:38:19,401 iteration 2019 : loss : 0.090200, loss_ce: 0.025468
2021-12-17 16:38:20,846 iteration 2020 : loss : 0.097204, loss_ce: 0.027876
2021-12-17 16:38:22,287 iteration 2021 : loss : 0.092835, loss_ce: 0.027106
2021-12-17 16:38:23,751 iteration 2022 : loss : 0.103484, loss_ce: 0.029244
2021-12-17 16:38:25,218 iteration 2023 : loss : 0.099914, loss_ce: 0.026346
 30%|████████▋                    | 119/400 [54:37<2:01:28, 25.94s/it]2021-12-17 16:38:26,740 iteration 2024 : loss : 0.110466, loss_ce: 0.042570
2021-12-17 16:38:28,331 iteration 2025 : loss : 0.129665, loss_ce: 0.040461
2021-12-17 16:38:29,734 iteration 2026 : loss : 0.099685, loss_ce: 0.025898
2021-12-17 16:38:31,215 iteration 2027 : loss : 0.092152, loss_ce: 0.025300
2021-12-17 16:38:32,576 iteration 2028 : loss : 0.098983, loss_ce: 0.031390
2021-12-17 16:38:33,972 iteration 2029 : loss : 0.091430, loss_ce: 0.021932
2021-12-17 16:38:35,452 iteration 2030 : loss : 0.110996, loss_ce: 0.030625
2021-12-17 16:38:36,916 iteration 2031 : loss : 0.103109, loss_ce: 0.030181
2021-12-17 16:38:38,363 iteration 2032 : loss : 0.087409, loss_ce: 0.027770
2021-12-17 16:38:39,739 iteration 2033 : loss : 0.081573, loss_ce: 0.025073
2021-12-17 16:38:41,153 iteration 2034 : loss : 0.099799, loss_ce: 0.027597
2021-12-17 16:38:42,642 iteration 2035 : loss : 0.094027, loss_ce: 0.026620
2021-12-17 16:38:44,053 iteration 2036 : loss : 0.098856, loss_ce: 0.035667
2021-12-17 16:38:45,449 iteration 2037 : loss : 0.091043, loss_ce: 0.027475
2021-12-17 16:38:46,999 iteration 2038 : loss : 0.103208, loss_ce: 0.022527
2021-12-17 16:38:48,481 iteration 2039 : loss : 0.092844, loss_ce: 0.026099
2021-12-17 16:38:48,481 Training Data Eval:
2021-12-17 16:38:55,996   Average segmentation loss on training set: 0.0784
2021-12-17 16:38:55,996 Validation Data Eval:
2021-12-17 16:38:58,588   Average segmentation loss on validation set: 0.1480
2021-12-17 16:39:04,880 Found new lowest validation loss at iteration 2039! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/TU_3seeds/TU_RESNET_no_pretraining_SGD_best_val_loss_seed2.pth
2021-12-17 16:39:06,320 iteration 2040 : loss : 0.103856, loss_ce: 0.035349
 30%|████████▋                    | 120/400 [55:18<2:22:16, 30.49s/it]2021-12-17 16:39:07,687 iteration 2041 : loss : 0.089785, loss_ce: 0.026937
2021-12-17 16:39:09,078 iteration 2042 : loss : 0.091647, loss_ce: 0.025198
2021-12-17 16:39:10,464 iteration 2043 : loss : 0.102857, loss_ce: 0.025301
2021-12-17 16:39:11,808 iteration 2044 : loss : 0.095489, loss_ce: 0.035800
2021-12-17 16:39:13,264 iteration 2045 : loss : 0.108857, loss_ce: 0.033562
2021-12-17 16:39:14,646 iteration 2046 : loss : 0.118538, loss_ce: 0.025110
2021-12-17 16:39:15,985 iteration 2047 : loss : 0.085052, loss_ce: 0.025364
2021-12-17 16:39:17,288 iteration 2048 : loss : 0.086887, loss_ce: 0.024968
2021-12-17 16:39:18,718 iteration 2049 : loss : 0.110520, loss_ce: 0.041180
2021-12-17 16:39:20,133 iteration 2050 : loss : 0.092984, loss_ce: 0.020885
2021-12-17 16:39:21,504 iteration 2051 : loss : 0.089276, loss_ce: 0.025899
2021-12-17 16:39:23,001 iteration 2052 : loss : 0.093069, loss_ce: 0.026304
2021-12-17 16:39:24,470 iteration 2053 : loss : 0.103136, loss_ce: 0.032354
2021-12-17 16:39:25,935 iteration 2054 : loss : 0.111543, loss_ce: 0.036288
2021-12-17 16:39:27,424 iteration 2055 : loss : 0.100835, loss_ce: 0.028766
2021-12-17 16:39:28,855 iteration 2056 : loss : 0.086102, loss_ce: 0.024799
2021-12-17 16:39:30,291 iteration 2057 : loss : 0.087432, loss_ce: 0.025506
 30%|████████▊                    | 121/400 [55:42<2:12:40, 28.53s/it]2021-12-17 16:39:31,775 iteration 2058 : loss : 0.102953, loss_ce: 0.036562
2021-12-17 16:39:33,274 iteration 2059 : loss : 0.105828, loss_ce: 0.029837
2021-12-17 16:39:34,788 iteration 2060 : loss : 0.104646, loss_ce: 0.029472
2021-12-17 16:39:36,238 iteration 2061 : loss : 0.100461, loss_ce: 0.038181
2021-12-17 16:39:37,650 iteration 2062 : loss : 0.092889, loss_ce: 0.027626
2021-12-17 16:39:39,271 iteration 2063 : loss : 0.113337, loss_ce: 0.040754
2021-12-17 16:39:40,736 iteration 2064 : loss : 0.093476, loss_ce: 0.027787
2021-12-17 16:39:42,257 iteration 2065 : loss : 0.115783, loss_ce: 0.040380
2021-12-17 16:39:43,706 iteration 2066 : loss : 0.095703, loss_ce: 0.027490
2021-12-17 16:39:45,204 iteration 2067 : loss : 0.101508, loss_ce: 0.030284
2021-12-17 16:39:46,619 iteration 2068 : loss : 0.092592, loss_ce: 0.026345
2021-12-17 16:39:48,101 iteration 2069 : loss : 0.094791, loss_ce: 0.030931
2021-12-17 16:39:49,615 iteration 2070 : loss : 0.086553, loss_ce: 0.024282
2021-12-17 16:39:51,019 iteration 2071 : loss : 0.085105, loss_ce: 0.024644
2021-12-17 16:39:52,414 iteration 2072 : loss : 0.095077, loss_ce: 0.033144
2021-12-17 16:39:53,911 iteration 2073 : loss : 0.103415, loss_ce: 0.030703
2021-12-17 16:39:55,301 iteration 2074 : loss : 0.087750, loss_ce: 0.021575
 30%|████████▊                    | 122/400 [56:07<2:07:18, 27.48s/it]2021-12-17 16:39:56,785 iteration 2075 : loss : 0.093449, loss_ce: 0.031064
2021-12-17 16:39:58,279 iteration 2076 : loss : 0.099433, loss_ce: 0.033486
2021-12-17 16:39:59,768 iteration 2077 : loss : 0.115467, loss_ce: 0.039196
2021-12-17 16:40:01,260 iteration 2078 : loss : 0.093976, loss_ce: 0.029017
2021-12-17 16:40:02,748 iteration 2079 : loss : 0.094716, loss_ce: 0.030702
2021-12-17 16:40:04,165 iteration 2080 : loss : 0.093021, loss_ce: 0.022285
2021-12-17 16:40:05,560 iteration 2081 : loss : 0.087245, loss_ce: 0.022765
2021-12-17 16:40:07,018 iteration 2082 : loss : 0.130955, loss_ce: 0.030202
2021-12-17 16:40:08,461 iteration 2083 : loss : 0.105268, loss_ce: 0.028953
2021-12-17 16:40:09,853 iteration 2084 : loss : 0.105393, loss_ce: 0.042945
2021-12-17 16:40:11,324 iteration 2085 : loss : 0.118883, loss_ce: 0.023205
2021-12-17 16:40:12,867 iteration 2086 : loss : 0.092986, loss_ce: 0.024306
2021-12-17 16:40:14,242 iteration 2087 : loss : 0.097988, loss_ce: 0.029441
2021-12-17 16:40:15,699 iteration 2088 : loss : 0.087760, loss_ce: 0.026053
2021-12-17 16:40:17,174 iteration 2089 : loss : 0.101524, loss_ce: 0.029389
2021-12-17 16:40:18,646 iteration 2090 : loss : 0.092133, loss_ce: 0.032432
2021-12-17 16:40:20,188 iteration 2091 : loss : 0.108236, loss_ce: 0.031802
 31%|████████▉                    | 123/400 [56:32<2:03:15, 26.70s/it]2021-12-17 16:40:21,663 iteration 2092 : loss : 0.097631, loss_ce: 0.025992
2021-12-17 16:40:23,058 iteration 2093 : loss : 0.082886, loss_ce: 0.024028
2021-12-17 16:40:24,552 iteration 2094 : loss : 0.092041, loss_ce: 0.025569
2021-12-17 16:40:26,161 iteration 2095 : loss : 0.092758, loss_ce: 0.024999
2021-12-17 16:40:27,594 iteration 2096 : loss : 0.087140, loss_ce: 0.026577
2021-12-17 16:40:29,044 iteration 2097 : loss : 0.105272, loss_ce: 0.023636
2021-12-17 16:40:30,448 iteration 2098 : loss : 0.098341, loss_ce: 0.029130
2021-12-17 16:40:31,894 iteration 2099 : loss : 0.083775, loss_ce: 0.024656
2021-12-17 16:40:33,389 iteration 2100 : loss : 0.101979, loss_ce: 0.030333
2021-12-17 16:40:34,744 iteration 2101 : loss : 0.085559, loss_ce: 0.019563
2021-12-17 16:40:36,229 iteration 2102 : loss : 0.097146, loss_ce: 0.034257
2021-12-17 16:40:37,644 iteration 2103 : loss : 0.086980, loss_ce: 0.031492
2021-12-17 16:40:39,024 iteration 2104 : loss : 0.096135, loss_ce: 0.025015
2021-12-17 16:40:40,505 iteration 2105 : loss : 0.106080, loss_ce: 0.037424
2021-12-17 16:40:41,973 iteration 2106 : loss : 0.094203, loss_ce: 0.028632
2021-12-17 16:40:43,378 iteration 2107 : loss : 0.084396, loss_ce: 0.021937
2021-12-17 16:40:44,776 iteration 2108 : loss : 0.097829, loss_ce: 0.031391
 31%|████████▉                    | 124/400 [56:56<1:59:54, 26.07s/it]2021-12-17 16:40:46,277 iteration 2109 : loss : 0.111405, loss_ce: 0.029848
2021-12-17 16:40:47,740 iteration 2110 : loss : 0.118392, loss_ce: 0.042924
2021-12-17 16:40:49,248 iteration 2111 : loss : 0.092843, loss_ce: 0.026243
2021-12-17 16:40:50,797 iteration 2112 : loss : 0.117009, loss_ce: 0.039395
2021-12-17 16:40:52,292 iteration 2113 : loss : 0.106598, loss_ce: 0.028105
2021-12-17 16:40:53,780 iteration 2114 : loss : 0.104750, loss_ce: 0.025994
2021-12-17 16:40:55,194 iteration 2115 : loss : 0.103380, loss_ce: 0.025747
2021-12-17 16:40:56,606 iteration 2116 : loss : 0.099134, loss_ce: 0.025561
2021-12-17 16:40:58,136 iteration 2117 : loss : 0.106185, loss_ce: 0.025720
2021-12-17 16:40:59,585 iteration 2118 : loss : 0.106186, loss_ce: 0.038446
2021-12-17 16:41:01,139 iteration 2119 : loss : 0.112491, loss_ce: 0.034083
2021-12-17 16:41:02,654 iteration 2120 : loss : 0.091037, loss_ce: 0.035146
2021-12-17 16:41:04,163 iteration 2121 : loss : 0.101366, loss_ce: 0.038403
2021-12-17 16:41:05,662 iteration 2122 : loss : 0.125423, loss_ce: 0.057937
2021-12-17 16:41:07,056 iteration 2123 : loss : 0.106923, loss_ce: 0.028131
2021-12-17 16:41:08,577 iteration 2124 : loss : 0.093772, loss_ce: 0.030558
2021-12-17 16:41:08,577 Training Data Eval:
2021-12-17 16:41:16,113   Average segmentation loss on training set: 0.0877
2021-12-17 16:41:16,113 Validation Data Eval:
2021-12-17 16:41:18,711   Average segmentation loss on validation set: 0.1410
2021-12-17 16:41:25,169 Found new lowest validation loss at iteration 2124! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/TU_3seeds/TU_RESNET_no_pretraining_SGD_best_val_loss_seed2.pth
2021-12-17 16:41:26,517 iteration 2125 : loss : 0.084780, loss_ce: 0.027312
 31%|█████████                    | 125/400 [57:38<2:21:01, 30.77s/it]2021-12-17 16:41:27,966 iteration 2126 : loss : 0.118295, loss_ce: 0.030851
2021-12-17 16:41:29,266 iteration 2127 : loss : 0.086256, loss_ce: 0.025539
2021-12-17 16:41:30,558 iteration 2128 : loss : 0.085589, loss_ce: 0.025454
2021-12-17 16:41:31,995 iteration 2129 : loss : 0.100105, loss_ce: 0.033591
2021-12-17 16:41:33,346 iteration 2130 : loss : 0.096604, loss_ce: 0.030163
2021-12-17 16:41:34,657 iteration 2131 : loss : 0.083347, loss_ce: 0.024738
2021-12-17 16:41:36,050 iteration 2132 : loss : 0.109010, loss_ce: 0.026175
2021-12-17 16:41:37,410 iteration 2133 : loss : 0.102848, loss_ce: 0.034579
2021-12-17 16:41:38,860 iteration 2134 : loss : 0.096303, loss_ce: 0.027630
2021-12-17 16:41:40,158 iteration 2135 : loss : 0.091114, loss_ce: 0.022096
2021-12-17 16:41:41,603 iteration 2136 : loss : 0.120149, loss_ce: 0.036740
2021-12-17 16:41:43,029 iteration 2137 : loss : 0.094701, loss_ce: 0.032490
2021-12-17 16:41:44,576 iteration 2138 : loss : 0.102273, loss_ce: 0.027808
2021-12-17 16:41:46,030 iteration 2139 : loss : 0.086628, loss_ce: 0.028009
2021-12-17 16:41:47,552 iteration 2140 : loss : 0.112641, loss_ce: 0.051881
2021-12-17 16:41:49,045 iteration 2141 : loss : 0.087850, loss_ce: 0.023685
2021-12-17 16:41:50,532 iteration 2142 : loss : 0.108165, loss_ce: 0.027228
 32%|█████████▏                   | 126/400 [58:02<2:11:15, 28.74s/it]2021-12-17 16:41:52,034 iteration 2143 : loss : 0.100672, loss_ce: 0.040993
2021-12-17 16:41:53,502 iteration 2144 : loss : 0.106812, loss_ce: 0.034555
2021-12-17 16:41:54,953 iteration 2145 : loss : 0.086460, loss_ce: 0.025871
2021-12-17 16:41:56,372 iteration 2146 : loss : 0.088768, loss_ce: 0.026388
2021-12-17 16:41:57,788 iteration 2147 : loss : 0.095467, loss_ce: 0.027829
2021-12-17 16:41:59,236 iteration 2148 : loss : 0.080222, loss_ce: 0.022616
2021-12-17 16:42:00,753 iteration 2149 : loss : 0.118160, loss_ce: 0.035678
2021-12-17 16:42:02,173 iteration 2150 : loss : 0.082780, loss_ce: 0.023346
2021-12-17 16:42:03,620 iteration 2151 : loss : 0.089353, loss_ce: 0.024766
2021-12-17 16:42:05,033 iteration 2152 : loss : 0.093661, loss_ce: 0.032107
2021-12-17 16:42:06,486 iteration 2153 : loss : 0.107338, loss_ce: 0.028541
2021-12-17 16:42:07,949 iteration 2154 : loss : 0.083519, loss_ce: 0.022886
2021-12-17 16:42:09,446 iteration 2155 : loss : 0.098400, loss_ce: 0.037128
2021-12-17 16:42:10,846 iteration 2156 : loss : 0.090893, loss_ce: 0.028120
2021-12-17 16:42:12,389 iteration 2157 : loss : 0.106671, loss_ce: 0.032990
2021-12-17 16:42:13,903 iteration 2158 : loss : 0.102791, loss_ce: 0.027140
2021-12-17 16:42:15,389 iteration 2159 : loss : 0.103784, loss_ce: 0.033099
 32%|█████████▏                   | 127/400 [58:27<2:05:27, 27.57s/it]2021-12-17 16:42:16,875 iteration 2160 : loss : 0.099456, loss_ce: 0.028084
2021-12-17 16:42:18,418 iteration 2161 : loss : 0.135433, loss_ce: 0.061047
2021-12-17 16:42:19,931 iteration 2162 : loss : 0.107087, loss_ce: 0.036969
2021-12-17 16:42:21,335 iteration 2163 : loss : 0.104189, loss_ce: 0.029674
2021-12-17 16:42:22,845 iteration 2164 : loss : 0.100984, loss_ce: 0.030019
2021-12-17 16:42:24,346 iteration 2165 : loss : 0.085507, loss_ce: 0.026374
2021-12-17 16:42:25,829 iteration 2166 : loss : 0.095194, loss_ce: 0.021564
2021-12-17 16:42:27,367 iteration 2167 : loss : 0.089409, loss_ce: 0.022978
2021-12-17 16:42:28,848 iteration 2168 : loss : 0.096967, loss_ce: 0.032937
2021-12-17 16:42:30,322 iteration 2169 : loss : 0.088569, loss_ce: 0.025612
2021-12-17 16:42:31,754 iteration 2170 : loss : 0.115055, loss_ce: 0.043742
2021-12-17 16:42:33,273 iteration 2171 : loss : 0.102755, loss_ce: 0.031848
2021-12-17 16:42:34,857 iteration 2172 : loss : 0.100626, loss_ce: 0.024975
2021-12-17 16:42:36,246 iteration 2173 : loss : 0.097585, loss_ce: 0.028780
2021-12-17 16:42:37,601 iteration 2174 : loss : 0.081808, loss_ce: 0.029724
2021-12-17 16:42:39,023 iteration 2175 : loss : 0.091372, loss_ce: 0.027874
2021-12-17 16:42:40,609 iteration 2176 : loss : 0.115868, loss_ce: 0.035593
 32%|█████████▎                   | 128/400 [58:52<2:01:49, 26.87s/it]2021-12-17 16:42:42,118 iteration 2177 : loss : 0.092836, loss_ce: 0.026363
2021-12-17 16:42:43,634 iteration 2178 : loss : 0.091005, loss_ce: 0.029827
2021-12-17 16:42:45,059 iteration 2179 : loss : 0.094348, loss_ce: 0.036351
2021-12-17 16:42:46,500 iteration 2180 : loss : 0.091497, loss_ce: 0.027821
2021-12-17 16:42:48,006 iteration 2181 : loss : 0.098559, loss_ce: 0.034290
2021-12-17 16:42:49,455 iteration 2182 : loss : 0.088397, loss_ce: 0.019237
2021-12-17 16:42:50,859 iteration 2183 : loss : 0.088975, loss_ce: 0.028056
2021-12-17 16:42:52,398 iteration 2184 : loss : 0.100250, loss_ce: 0.027532
2021-12-17 16:42:53,826 iteration 2185 : loss : 0.090678, loss_ce: 0.027707
2021-12-17 16:42:55,292 iteration 2186 : loss : 0.111526, loss_ce: 0.031140
2021-12-17 16:42:56,740 iteration 2187 : loss : 0.082584, loss_ce: 0.024196
2021-12-17 16:42:58,157 iteration 2188 : loss : 0.089061, loss_ce: 0.020777
2021-12-17 16:42:59,694 iteration 2189 : loss : 0.093411, loss_ce: 0.029678
2021-12-17 16:43:01,148 iteration 2190 : loss : 0.108629, loss_ce: 0.028335
2021-12-17 16:43:02,640 iteration 2191 : loss : 0.118948, loss_ce: 0.032689
2021-12-17 16:43:04,071 iteration 2192 : loss : 0.083360, loss_ce: 0.019661
2021-12-17 16:43:05,543 iteration 2193 : loss : 0.098136, loss_ce: 0.030422
 32%|█████████▎                   | 129/400 [59:17<1:58:44, 26.29s/it]2021-12-17 16:43:07,093 iteration 2194 : loss : 0.095639, loss_ce: 0.038058
2021-12-17 16:43:08,515 iteration 2195 : loss : 0.084267, loss_ce: 0.021230
2021-12-17 16:43:09,970 iteration 2196 : loss : 0.091708, loss_ce: 0.027074
2021-12-17 16:43:11,450 iteration 2197 : loss : 0.106179, loss_ce: 0.042859
2021-12-17 16:43:12,924 iteration 2198 : loss : 0.087557, loss_ce: 0.029801
2021-12-17 16:43:14,388 iteration 2199 : loss : 0.092613, loss_ce: 0.032089
2021-12-17 16:43:15,809 iteration 2200 : loss : 0.094069, loss_ce: 0.024501
2021-12-17 16:43:17,225 iteration 2201 : loss : 0.086966, loss_ce: 0.026665
2021-12-17 16:43:18,740 iteration 2202 : loss : 0.147245, loss_ce: 0.030189
2021-12-17 16:43:20,261 iteration 2203 : loss : 0.088064, loss_ce: 0.034445
2021-12-17 16:43:21,693 iteration 2204 : loss : 0.094237, loss_ce: 0.034241
2021-12-17 16:43:23,085 iteration 2205 : loss : 0.080571, loss_ce: 0.024668
2021-12-17 16:43:24,477 iteration 2206 : loss : 0.086827, loss_ce: 0.020189
2021-12-17 16:43:25,905 iteration 2207 : loss : 0.103294, loss_ce: 0.027335
2021-12-17 16:43:27,395 iteration 2208 : loss : 0.104147, loss_ce: 0.024946
2021-12-17 16:43:28,826 iteration 2209 : loss : 0.099382, loss_ce: 0.027520
2021-12-17 16:43:28,826 Training Data Eval:
2021-12-17 16:43:36,388   Average segmentation loss on training set: 0.0715
2021-12-17 16:43:36,388 Validation Data Eval:
2021-12-17 16:43:38,985   Average segmentation loss on validation set: 0.1503
2021-12-17 16:43:40,468 iteration 2210 : loss : 0.096395, loss_ce: 0.027340
 32%|█████████▍                   | 130/400 [59:52<2:09:57, 28.88s/it]2021-12-17 16:43:41,989 iteration 2211 : loss : 0.097254, loss_ce: 0.024850
2021-12-17 16:43:43,478 iteration 2212 : loss : 0.108346, loss_ce: 0.036745
2021-12-17 16:43:44,975 iteration 2213 : loss : 0.096903, loss_ce: 0.030091
2021-12-17 16:43:46,468 iteration 2214 : loss : 0.087117, loss_ce: 0.024105
2021-12-17 16:43:47,978 iteration 2215 : loss : 0.106239, loss_ce: 0.037186
2021-12-17 16:43:49,365 iteration 2216 : loss : 0.095910, loss_ce: 0.024951
2021-12-17 16:43:50,873 iteration 2217 : loss : 0.125063, loss_ce: 0.041328
2021-12-17 16:43:52,291 iteration 2218 : loss : 0.093967, loss_ce: 0.026628
2021-12-17 16:43:53,809 iteration 2219 : loss : 0.080602, loss_ce: 0.022585
2021-12-17 16:43:55,173 iteration 2220 : loss : 0.091101, loss_ce: 0.023614
2021-12-17 16:43:56,572 iteration 2221 : loss : 0.083935, loss_ce: 0.022316
2021-12-17 16:43:58,066 iteration 2222 : loss : 0.091908, loss_ce: 0.030165
2021-12-17 16:43:59,549 iteration 2223 : loss : 0.109614, loss_ce: 0.032832
2021-12-17 16:44:01,092 iteration 2224 : loss : 0.134783, loss_ce: 0.058118
2021-12-17 16:44:02,492 iteration 2225 : loss : 0.076114, loss_ce: 0.019842
2021-12-17 16:44:04,046 iteration 2226 : loss : 0.092839, loss_ce: 0.031376
2021-12-17 16:44:05,488 iteration 2227 : loss : 0.092165, loss_ce: 0.024229
 33%|████████▊                  | 131/400 [1:00:17<2:04:17, 27.72s/it]2021-12-17 16:44:07,042 iteration 2228 : loss : 0.086105, loss_ce: 0.028336
2021-12-17 16:44:08,484 iteration 2229 : loss : 0.099600, loss_ce: 0.032465
2021-12-17 16:44:09,964 iteration 2230 : loss : 0.094021, loss_ce: 0.027456
2021-12-17 16:44:11,323 iteration 2231 : loss : 0.083032, loss_ce: 0.024067
2021-12-17 16:44:12,739 iteration 2232 : loss : 0.097638, loss_ce: 0.030583
2021-12-17 16:44:14,171 iteration 2233 : loss : 0.091774, loss_ce: 0.026477
2021-12-17 16:44:15,606 iteration 2234 : loss : 0.109100, loss_ce: 0.035203
2021-12-17 16:44:17,035 iteration 2235 : loss : 0.110619, loss_ce: 0.021363
2021-12-17 16:44:18,620 iteration 2236 : loss : 0.114290, loss_ce: 0.033692
2021-12-17 16:44:20,068 iteration 2237 : loss : 0.089533, loss_ce: 0.028817
2021-12-17 16:44:21,530 iteration 2238 : loss : 0.111150, loss_ce: 0.042541
2021-12-17 16:44:22,983 iteration 2239 : loss : 0.083143, loss_ce: 0.021450
2021-12-17 16:44:24,472 iteration 2240 : loss : 0.098653, loss_ce: 0.028752
2021-12-17 16:44:25,995 iteration 2241 : loss : 0.092811, loss_ce: 0.023299
2021-12-17 16:44:27,502 iteration 2242 : loss : 0.101972, loss_ce: 0.037281
2021-12-17 16:44:29,059 iteration 2243 : loss : 0.104468, loss_ce: 0.028672
2021-12-17 16:44:30,519 iteration 2244 : loss : 0.095271, loss_ce: 0.030540
 33%|████████▉                  | 132/400 [1:00:42<2:00:12, 26.91s/it]2021-12-17 16:44:32,101 iteration 2245 : loss : 0.103163, loss_ce: 0.030117
2021-12-17 16:44:33,523 iteration 2246 : loss : 0.081798, loss_ce: 0.024147
2021-12-17 16:44:35,057 iteration 2247 : loss : 0.131724, loss_ce: 0.031353
2021-12-17 16:44:36,548 iteration 2248 : loss : 0.099419, loss_ce: 0.029959
2021-12-17 16:44:38,019 iteration 2249 : loss : 0.099349, loss_ce: 0.028575
2021-12-17 16:44:39,460 iteration 2250 : loss : 0.089765, loss_ce: 0.029088
2021-12-17 16:44:40,838 iteration 2251 : loss : 0.086183, loss_ce: 0.024298
2021-12-17 16:44:42,420 iteration 2252 : loss : 0.118651, loss_ce: 0.036403
2021-12-17 16:44:43,956 iteration 2253 : loss : 0.113930, loss_ce: 0.041026
2021-12-17 16:44:45,425 iteration 2254 : loss : 0.085710, loss_ce: 0.026945
2021-12-17 16:44:46,845 iteration 2255 : loss : 0.085433, loss_ce: 0.022308
2021-12-17 16:44:48,316 iteration 2256 : loss : 0.089989, loss_ce: 0.026633
2021-12-17 16:44:49,754 iteration 2257 : loss : 0.087346, loss_ce: 0.026240
2021-12-17 16:44:51,150 iteration 2258 : loss : 0.087287, loss_ce: 0.029277
2021-12-17 16:44:52,680 iteration 2259 : loss : 0.077996, loss_ce: 0.021347
2021-12-17 16:44:54,088 iteration 2260 : loss : 0.085102, loss_ce: 0.025385
2021-12-17 16:44:55,551 iteration 2261 : loss : 0.090917, loss_ce: 0.029298
 33%|████████▉                  | 133/400 [1:01:07<1:57:15, 26.35s/it]2021-12-17 16:44:57,076 iteration 2262 : loss : 0.114845, loss_ce: 0.037429
2021-12-17 16:44:58,548 iteration 2263 : loss : 0.087320, loss_ce: 0.027339
2021-12-17 16:45:00,049 iteration 2264 : loss : 0.103125, loss_ce: 0.033418
2021-12-17 16:45:01,489 iteration 2265 : loss : 0.078788, loss_ce: 0.022373
2021-12-17 16:45:02,921 iteration 2266 : loss : 0.096224, loss_ce: 0.025693
2021-12-17 16:45:04,311 iteration 2267 : loss : 0.077034, loss_ce: 0.021448
2021-12-17 16:45:05,750 iteration 2268 : loss : 0.089105, loss_ce: 0.029286
2021-12-17 16:45:07,164 iteration 2269 : loss : 0.097465, loss_ce: 0.034528
2021-12-17 16:45:08,565 iteration 2270 : loss : 0.077073, loss_ce: 0.022468
2021-12-17 16:45:10,017 iteration 2271 : loss : 0.122711, loss_ce: 0.037487
2021-12-17 16:45:11,515 iteration 2272 : loss : 0.103225, loss_ce: 0.029640
2021-12-17 16:45:13,020 iteration 2273 : loss : 0.093314, loss_ce: 0.025375
2021-12-17 16:45:14,454 iteration 2274 : loss : 0.099485, loss_ce: 0.032966
2021-12-17 16:45:15,897 iteration 2275 : loss : 0.099557, loss_ce: 0.025803
2021-12-17 16:45:17,298 iteration 2276 : loss : 0.091895, loss_ce: 0.029395
2021-12-17 16:45:18,735 iteration 2277 : loss : 0.076805, loss_ce: 0.016706
2021-12-17 16:45:20,214 iteration 2278 : loss : 0.093004, loss_ce: 0.026488
 34%|█████████                  | 134/400 [1:01:32<1:54:34, 25.84s/it]2021-12-17 16:45:21,638 iteration 2279 : loss : 0.079157, loss_ce: 0.022229
2021-12-17 16:45:23,031 iteration 2280 : loss : 0.093654, loss_ce: 0.031117
2021-12-17 16:45:24,492 iteration 2281 : loss : 0.091251, loss_ce: 0.024130
2021-12-17 16:45:25,878 iteration 2282 : loss : 0.096601, loss_ce: 0.026935
2021-12-17 16:45:27,328 iteration 2283 : loss : 0.104250, loss_ce: 0.024819
2021-12-17 16:45:28,706 iteration 2284 : loss : 0.100758, loss_ce: 0.034791
2021-12-17 16:45:30,197 iteration 2285 : loss : 0.094505, loss_ce: 0.029058
2021-12-17 16:45:31,601 iteration 2286 : loss : 0.107227, loss_ce: 0.042139
2021-12-17 16:45:33,034 iteration 2287 : loss : 0.084976, loss_ce: 0.018502
2021-12-17 16:45:34,476 iteration 2288 : loss : 0.117408, loss_ce: 0.025057
2021-12-17 16:45:35,937 iteration 2289 : loss : 0.077419, loss_ce: 0.018475
2021-12-17 16:45:37,387 iteration 2290 : loss : 0.110454, loss_ce: 0.034989
2021-12-17 16:45:38,947 iteration 2291 : loss : 0.099734, loss_ce: 0.030104
2021-12-17 16:45:40,427 iteration 2292 : loss : 0.095330, loss_ce: 0.028653
2021-12-17 16:45:41,867 iteration 2293 : loss : 0.098055, loss_ce: 0.031836
2021-12-17 16:45:43,294 iteration 2294 : loss : 0.097710, loss_ce: 0.038319
2021-12-17 16:45:43,294 Training Data Eval:
2021-12-17 16:45:50,812   Average segmentation loss on training set: 0.0706
2021-12-17 16:45:50,813 Validation Data Eval:
2021-12-17 16:45:53,411   Average segmentation loss on validation set: 0.1399
2021-12-17 16:46:00,424 Found new lowest validation loss at iteration 2294! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/TU_3seeds/TU_RESNET_no_pretraining_SGD_best_val_loss_seed2.pth
2021-12-17 16:46:01,819 iteration 2295 : loss : 0.111111, loss_ce: 0.025649
 34%|█████████                  | 135/400 [1:02:13<2:15:01, 30.57s/it]2021-12-17 16:46:03,160 iteration 2296 : loss : 0.080516, loss_ce: 0.025477
2021-12-17 16:46:04,585 iteration 2297 : loss : 0.097602, loss_ce: 0.026914
2021-12-17 16:46:05,972 iteration 2298 : loss : 0.082351, loss_ce: 0.021379
2021-12-17 16:46:07,369 iteration 2299 : loss : 0.101847, loss_ce: 0.027240
2021-12-17 16:46:08,713 iteration 2300 : loss : 0.080676, loss_ce: 0.024769
2021-12-17 16:46:10,094 iteration 2301 : loss : 0.093669, loss_ce: 0.033159
2021-12-17 16:46:11,536 iteration 2302 : loss : 0.120449, loss_ce: 0.040290
2021-12-17 16:46:12,945 iteration 2303 : loss : 0.099410, loss_ce: 0.025954
2021-12-17 16:46:14,344 iteration 2304 : loss : 0.094764, loss_ce: 0.029588
2021-12-17 16:46:15,701 iteration 2305 : loss : 0.093312, loss_ce: 0.031760
2021-12-17 16:46:17,044 iteration 2306 : loss : 0.086814, loss_ce: 0.025927
2021-12-17 16:46:18,483 iteration 2307 : loss : 0.083761, loss_ce: 0.025426
2021-12-17 16:46:19,826 iteration 2308 : loss : 0.083158, loss_ce: 0.026320
2021-12-17 16:46:21,334 iteration 2309 : loss : 0.104166, loss_ce: 0.037131
2021-12-17 16:46:22,836 iteration 2310 : loss : 0.105857, loss_ce: 0.031911
2021-12-17 16:46:24,264 iteration 2311 : loss : 0.096999, loss_ce: 0.028093
2021-12-17 16:46:25,676 iteration 2312 : loss : 0.085628, loss_ce: 0.023917
 34%|█████████▏                 | 136/400 [1:02:37<2:05:39, 28.56s/it]2021-12-17 16:46:27,178 iteration 2313 : loss : 0.093803, loss_ce: 0.025620
2021-12-17 16:46:28,673 iteration 2314 : loss : 0.095227, loss_ce: 0.027251
2021-12-17 16:46:30,229 iteration 2315 : loss : 0.108918, loss_ce: 0.033245
2021-12-17 16:46:31,623 iteration 2316 : loss : 0.083687, loss_ce: 0.023911
2021-12-17 16:46:33,154 iteration 2317 : loss : 0.102533, loss_ce: 0.026129
2021-12-17 16:46:34,647 iteration 2318 : loss : 0.096839, loss_ce: 0.031286
2021-12-17 16:46:36,128 iteration 2319 : loss : 0.099177, loss_ce: 0.033195
2021-12-17 16:46:37,650 iteration 2320 : loss : 0.101269, loss_ce: 0.037587
2021-12-17 16:46:39,061 iteration 2321 : loss : 0.094115, loss_ce: 0.024332
2021-12-17 16:46:40,508 iteration 2322 : loss : 0.085902, loss_ce: 0.027668
2021-12-17 16:46:41,953 iteration 2323 : loss : 0.100415, loss_ce: 0.034774
2021-12-17 16:46:43,436 iteration 2324 : loss : 0.092443, loss_ce: 0.024609
2021-12-17 16:46:44,873 iteration 2325 : loss : 0.084531, loss_ce: 0.025892
2021-12-17 16:46:46,349 iteration 2326 : loss : 0.093797, loss_ce: 0.034161
2021-12-17 16:46:47,789 iteration 2327 : loss : 0.083886, loss_ce: 0.023719
2021-12-17 16:46:49,273 iteration 2328 : loss : 0.105735, loss_ce: 0.039002
2021-12-17 16:46:50,690 iteration 2329 : loss : 0.085218, loss_ce: 0.024289
 34%|█████████▏                 | 137/400 [1:03:02<2:00:30, 27.49s/it]2021-12-17 16:46:52,156 iteration 2330 : loss : 0.087332, loss_ce: 0.025945
2021-12-17 16:46:53,600 iteration 2331 : loss : 0.103165, loss_ce: 0.036854
2021-12-17 16:46:55,102 iteration 2332 : loss : 0.094189, loss_ce: 0.027583
2021-12-17 16:46:56,604 iteration 2333 : loss : 0.090743, loss_ce: 0.034022
2021-12-17 16:46:58,030 iteration 2334 : loss : 0.080268, loss_ce: 0.025892
2021-12-17 16:46:59,461 iteration 2335 : loss : 0.093591, loss_ce: 0.021242
2021-12-17 16:47:00,954 iteration 2336 : loss : 0.125603, loss_ce: 0.030860
2021-12-17 16:47:02,445 iteration 2337 : loss : 0.082245, loss_ce: 0.026914
2021-12-17 16:47:03,882 iteration 2338 : loss : 0.090639, loss_ce: 0.025651
2021-12-17 16:47:05,365 iteration 2339 : loss : 0.087795, loss_ce: 0.023726
2021-12-17 16:47:06,873 iteration 2340 : loss : 0.095961, loss_ce: 0.034154
2021-12-17 16:47:08,254 iteration 2341 : loss : 0.073648, loss_ce: 0.015766
2021-12-17 16:47:09,709 iteration 2342 : loss : 0.086425, loss_ce: 0.028052
2021-12-17 16:47:11,231 iteration 2343 : loss : 0.101476, loss_ce: 0.033360
2021-12-17 16:47:12,715 iteration 2344 : loss : 0.086031, loss_ce: 0.026224
2021-12-17 16:47:14,217 iteration 2345 : loss : 0.094581, loss_ce: 0.026945
2021-12-17 16:47:15,679 iteration 2346 : loss : 0.082124, loss_ce: 0.028047
 34%|█████████▎                 | 138/400 [1:03:27<1:56:46, 26.74s/it]2021-12-17 16:47:17,175 iteration 2347 : loss : 0.092269, loss_ce: 0.023397
2021-12-17 16:47:18,617 iteration 2348 : loss : 0.089745, loss_ce: 0.025210
2021-12-17 16:47:20,115 iteration 2349 : loss : 0.085518, loss_ce: 0.027991
2021-12-17 16:47:21,550 iteration 2350 : loss : 0.084602, loss_ce: 0.025160
2021-12-17 16:47:23,011 iteration 2351 : loss : 0.126018, loss_ce: 0.017995
2021-12-17 16:47:24,475 iteration 2352 : loss : 0.080148, loss_ce: 0.020749
2021-12-17 16:47:25,980 iteration 2353 : loss : 0.105751, loss_ce: 0.036554
2021-12-17 16:47:27,498 iteration 2354 : loss : 0.103523, loss_ce: 0.034929
2021-12-17 16:47:28,863 iteration 2355 : loss : 0.077005, loss_ce: 0.022547
2021-12-17 16:47:30,320 iteration 2356 : loss : 0.085652, loss_ce: 0.026758
2021-12-17 16:47:31,783 iteration 2357 : loss : 0.094544, loss_ce: 0.025890
2021-12-17 16:47:33,263 iteration 2358 : loss : 0.106140, loss_ce: 0.041872
2021-12-17 16:47:34,818 iteration 2359 : loss : 0.087948, loss_ce: 0.024922
2021-12-17 16:47:36,244 iteration 2360 : loss : 0.084998, loss_ce: 0.026520
2021-12-17 16:47:37,733 iteration 2361 : loss : 0.096171, loss_ce: 0.024446
2021-12-17 16:47:39,297 iteration 2362 : loss : 0.112412, loss_ce: 0.038133
2021-12-17 16:47:40,695 iteration 2363 : loss : 0.077835, loss_ce: 0.024327
 35%|█████████▍                 | 139/400 [1:03:52<1:54:04, 26.23s/it]2021-12-17 16:47:42,114 iteration 2364 : loss : 0.100843, loss_ce: 0.016227
2021-12-17 16:47:43,524 iteration 2365 : loss : 0.088186, loss_ce: 0.019819
2021-12-17 16:47:44,996 iteration 2366 : loss : 0.102518, loss_ce: 0.035214
2021-12-17 16:47:46,428 iteration 2367 : loss : 0.097189, loss_ce: 0.037010
2021-12-17 16:47:47,854 iteration 2368 : loss : 0.094135, loss_ce: 0.024531
2021-12-17 16:47:49,327 iteration 2369 : loss : 0.091436, loss_ce: 0.029940
2021-12-17 16:47:50,799 iteration 2370 : loss : 0.091501, loss_ce: 0.026804
2021-12-17 16:47:52,293 iteration 2371 : loss : 0.105968, loss_ce: 0.035421
2021-12-17 16:47:53,729 iteration 2372 : loss : 0.085041, loss_ce: 0.026659
2021-12-17 16:47:55,141 iteration 2373 : loss : 0.085264, loss_ce: 0.026983
2021-12-17 16:47:56,575 iteration 2374 : loss : 0.075527, loss_ce: 0.022048
2021-12-17 16:47:58,054 iteration 2375 : loss : 0.102561, loss_ce: 0.026739
2021-12-17 16:47:59,548 iteration 2376 : loss : 0.087226, loss_ce: 0.024949
2021-12-17 16:48:00,975 iteration 2377 : loss : 0.081990, loss_ce: 0.023774
2021-12-17 16:48:02,408 iteration 2378 : loss : 0.088726, loss_ce: 0.024192
2021-12-17 16:48:03,863 iteration 2379 : loss : 0.094029, loss_ce: 0.034732
2021-12-17 16:48:03,863 Training Data Eval:
2021-12-17 16:48:11,360   Average segmentation loss on training set: 0.0720
2021-12-17 16:48:11,361 Validation Data Eval:
2021-12-17 16:48:13,957   Average segmentation loss on validation set: 0.1377
2021-12-17 16:48:20,604 Found new lowest validation loss at iteration 2379! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/TU_3seeds/TU_RESNET_no_pretraining_SGD_best_val_loss_seed2.pth
2021-12-17 16:48:21,945 iteration 2380 : loss : 0.081495, loss_ce: 0.026180
 35%|█████████▍                 | 140/400 [1:04:33<2:13:10, 30.73s/it]2021-12-17 16:48:23,450 iteration 2381 : loss : 0.105790, loss_ce: 0.026338
2021-12-17 16:48:24,834 iteration 2382 : loss : 0.087739, loss_ce: 0.026139
2021-12-17 16:48:26,189 iteration 2383 : loss : 0.091647, loss_ce: 0.029351
2021-12-17 16:48:27,505 iteration 2384 : loss : 0.079025, loss_ce: 0.019408
2021-12-17 16:48:28,875 iteration 2385 : loss : 0.088086, loss_ce: 0.024578
2021-12-17 16:48:30,287 iteration 2386 : loss : 0.094967, loss_ce: 0.024097
2021-12-17 16:48:31,708 iteration 2387 : loss : 0.081029, loss_ce: 0.023202
2021-12-17 16:48:33,102 iteration 2388 : loss : 0.089331, loss_ce: 0.033000
2021-12-17 16:48:34,481 iteration 2389 : loss : 0.084691, loss_ce: 0.021889
2021-12-17 16:48:35,815 iteration 2390 : loss : 0.084190, loss_ce: 0.025007
2021-12-17 16:48:37,114 iteration 2391 : loss : 0.081639, loss_ce: 0.022897
2021-12-17 16:48:38,673 iteration 2392 : loss : 0.092141, loss_ce: 0.019705
2021-12-17 16:48:40,193 iteration 2393 : loss : 0.100559, loss_ce: 0.031000
2021-12-17 16:48:41,679 iteration 2394 : loss : 0.090355, loss_ce: 0.026582
2021-12-17 16:48:43,207 iteration 2395 : loss : 0.094487, loss_ce: 0.030822
2021-12-17 16:48:44,634 iteration 2396 : loss : 0.103690, loss_ce: 0.032612
2021-12-17 16:48:46,162 iteration 2397 : loss : 0.104381, loss_ce: 0.045890
 35%|█████████▌                 | 141/400 [1:04:58<2:04:13, 28.78s/it]2021-12-17 16:48:47,639 iteration 2398 : loss : 0.083030, loss_ce: 0.028490
2021-12-17 16:48:49,180 iteration 2399 : loss : 0.093469, loss_ce: 0.029825
2021-12-17 16:48:50,629 iteration 2400 : loss : 0.098061, loss_ce: 0.028299
2021-12-17 16:48:52,221 iteration 2401 : loss : 0.107246, loss_ce: 0.032780
2021-12-17 16:48:53,683 iteration 2402 : loss : 0.102131, loss_ce: 0.030364
2021-12-17 16:48:55,130 iteration 2403 : loss : 0.079571, loss_ce: 0.024198
2021-12-17 16:48:56,564 iteration 2404 : loss : 0.082546, loss_ce: 0.023210
2021-12-17 16:48:58,082 iteration 2405 : loss : 0.098277, loss_ce: 0.028703
2021-12-17 16:48:59,483 iteration 2406 : loss : 0.084643, loss_ce: 0.027133
2021-12-17 16:49:00,925 iteration 2407 : loss : 0.076791, loss_ce: 0.020437
2021-12-17 16:49:02,519 iteration 2408 : loss : 0.095238, loss_ce: 0.027620
2021-12-17 16:49:03,942 iteration 2409 : loss : 0.083178, loss_ce: 0.025272
2021-12-17 16:49:05,367 iteration 2410 : loss : 0.085471, loss_ce: 0.023912
2021-12-17 16:49:06,786 iteration 2411 : loss : 0.080009, loss_ce: 0.025735
2021-12-17 16:49:08,218 iteration 2412 : loss : 0.084429, loss_ce: 0.023861
2021-12-17 16:49:09,630 iteration 2413 : loss : 0.090248, loss_ce: 0.028318
2021-12-17 16:49:11,036 iteration 2414 : loss : 0.077991, loss_ce: 0.025541
 36%|█████████▌                 | 142/400 [1:05:22<1:58:42, 27.61s/it]2021-12-17 16:49:12,581 iteration 2415 : loss : 0.101325, loss_ce: 0.029672
2021-12-17 16:49:14,002 iteration 2416 : loss : 0.080476, loss_ce: 0.025175
2021-12-17 16:49:15,459 iteration 2417 : loss : 0.082323, loss_ce: 0.028053
2021-12-17 16:49:16,862 iteration 2418 : loss : 0.082726, loss_ce: 0.020389
2021-12-17 16:49:18,319 iteration 2419 : loss : 0.101180, loss_ce: 0.026041
2021-12-17 16:49:19,849 iteration 2420 : loss : 0.085558, loss_ce: 0.030391
2021-12-17 16:49:21,309 iteration 2421 : loss : 0.087220, loss_ce: 0.031985
2021-12-17 16:49:22,759 iteration 2422 : loss : 0.086534, loss_ce: 0.028414
2021-12-17 16:49:24,140 iteration 2423 : loss : 0.095812, loss_ce: 0.035279
2021-12-17 16:49:25,589 iteration 2424 : loss : 0.085403, loss_ce: 0.026811
2021-12-17 16:49:27,079 iteration 2425 : loss : 0.076433, loss_ce: 0.017872
2021-12-17 16:49:28,517 iteration 2426 : loss : 0.093516, loss_ce: 0.026975
2021-12-17 16:49:29,912 iteration 2427 : loss : 0.080303, loss_ce: 0.025907
2021-12-17 16:49:31,357 iteration 2428 : loss : 0.091084, loss_ce: 0.027852
2021-12-17 16:49:32,779 iteration 2429 : loss : 0.097967, loss_ce: 0.027871
2021-12-17 16:49:34,233 iteration 2430 : loss : 0.081764, loss_ce: 0.026002
2021-12-17 16:49:35,693 iteration 2431 : loss : 0.100850, loss_ce: 0.024668
 36%|█████████▋                 | 143/400 [1:05:47<1:54:27, 26.72s/it]2021-12-17 16:49:37,112 iteration 2432 : loss : 0.080076, loss_ce: 0.020667
2021-12-17 16:49:38,537 iteration 2433 : loss : 0.091344, loss_ce: 0.038695
2021-12-17 16:49:40,029 iteration 2434 : loss : 0.092546, loss_ce: 0.029992
2021-12-17 16:49:41,473 iteration 2435 : loss : 0.086672, loss_ce: 0.031915
2021-12-17 16:49:42,993 iteration 2436 : loss : 0.082496, loss_ce: 0.023603
2021-12-17 16:49:44,454 iteration 2437 : loss : 0.086240, loss_ce: 0.024704
2021-12-17 16:49:45,855 iteration 2438 : loss : 0.073552, loss_ce: 0.021891
2021-12-17 16:49:47,288 iteration 2439 : loss : 0.091339, loss_ce: 0.026685
2021-12-17 16:49:48,735 iteration 2440 : loss : 0.085766, loss_ce: 0.026318
2021-12-17 16:49:50,288 iteration 2441 : loss : 0.106956, loss_ce: 0.032086
2021-12-17 16:49:51,757 iteration 2442 : loss : 0.079615, loss_ce: 0.020235
2021-12-17 16:49:53,245 iteration 2443 : loss : 0.093898, loss_ce: 0.032122
2021-12-17 16:49:54,737 iteration 2444 : loss : 0.090614, loss_ce: 0.031626
2021-12-17 16:49:56,286 iteration 2445 : loss : 0.080263, loss_ce: 0.022202
2021-12-17 16:49:57,699 iteration 2446 : loss : 0.091623, loss_ce: 0.031885
2021-12-17 16:49:59,200 iteration 2447 : loss : 0.103841, loss_ce: 0.032422
2021-12-17 16:50:00,599 iteration 2448 : loss : 0.090440, loss_ce: 0.034330
 36%|█████████▋                 | 144/400 [1:06:12<1:51:41, 26.18s/it]2021-12-17 16:50:02,091 iteration 2449 : loss : 0.081236, loss_ce: 0.019391
2021-12-17 16:50:03,481 iteration 2450 : loss : 0.085325, loss_ce: 0.022948
2021-12-17 16:50:04,883 iteration 2451 : loss : 0.076023, loss_ce: 0.021251
2021-12-17 16:50:06,304 iteration 2452 : loss : 0.095179, loss_ce: 0.032974
2021-12-17 16:50:07,736 iteration 2453 : loss : 0.084121, loss_ce: 0.028771
2021-12-17 16:50:09,158 iteration 2454 : loss : 0.096393, loss_ce: 0.026801
2021-12-17 16:50:10,684 iteration 2455 : loss : 0.099321, loss_ce: 0.033071
2021-12-17 16:50:12,152 iteration 2456 : loss : 0.080626, loss_ce: 0.024625
2021-12-17 16:50:13,574 iteration 2457 : loss : 0.086428, loss_ce: 0.031507
2021-12-17 16:50:15,057 iteration 2458 : loss : 0.090808, loss_ce: 0.023517
2021-12-17 16:50:16,505 iteration 2459 : loss : 0.076228, loss_ce: 0.021325
2021-12-17 16:50:18,005 iteration 2460 : loss : 0.105355, loss_ce: 0.023527
2021-12-17 16:50:19,479 iteration 2461 : loss : 0.085122, loss_ce: 0.019609
2021-12-17 16:50:21,016 iteration 2462 : loss : 0.102711, loss_ce: 0.035534
2021-12-17 16:50:22,424 iteration 2463 : loss : 0.079583, loss_ce: 0.023132
2021-12-17 16:50:23,863 iteration 2464 : loss : 0.101698, loss_ce: 0.047187
2021-12-17 16:50:23,864 Training Data Eval:
2021-12-17 16:50:31,376   Average segmentation loss on training set: 0.0668
2021-12-17 16:50:31,377 Validation Data Eval:
2021-12-17 16:50:33,977   Average segmentation loss on validation set: 0.1421
2021-12-17 16:50:35,448 iteration 2465 : loss : 0.091301, loss_ce: 0.035724
 36%|█████████▊                 | 145/400 [1:06:47<2:02:18, 28.78s/it]2021-12-17 16:50:36,977 iteration 2466 : loss : 0.099112, loss_ce: 0.030396
2021-12-17 16:50:38,409 iteration 2467 : loss : 0.078227, loss_ce: 0.021741
2021-12-17 16:50:39,921 iteration 2468 : loss : 0.109700, loss_ce: 0.036890
2021-12-17 16:50:41,310 iteration 2469 : loss : 0.082792, loss_ce: 0.026329
2021-12-17 16:50:42,801 iteration 2470 : loss : 0.107254, loss_ce: 0.039921
2021-12-17 16:50:44,281 iteration 2471 : loss : 0.089602, loss_ce: 0.033304
2021-12-17 16:50:45,752 iteration 2472 : loss : 0.085651, loss_ce: 0.024035
2021-12-17 16:50:47,194 iteration 2473 : loss : 0.076908, loss_ce: 0.021168
2021-12-17 16:50:48,552 iteration 2474 : loss : 0.072585, loss_ce: 0.021786
2021-12-17 16:50:50,035 iteration 2475 : loss : 0.099346, loss_ce: 0.044405
2021-12-17 16:50:51,494 iteration 2476 : loss : 0.100065, loss_ce: 0.024899
2021-12-17 16:50:52,937 iteration 2477 : loss : 0.085723, loss_ce: 0.022808
2021-12-17 16:50:54,360 iteration 2478 : loss : 0.090530, loss_ce: 0.025269
2021-12-17 16:50:55,850 iteration 2479 : loss : 0.104998, loss_ce: 0.027275
2021-12-17 16:50:57,279 iteration 2480 : loss : 0.072544, loss_ce: 0.019611
2021-12-17 16:50:58,693 iteration 2481 : loss : 0.083543, loss_ce: 0.025180
2021-12-17 16:51:00,242 iteration 2482 : loss : 0.115891, loss_ce: 0.038742
 36%|█████████▊                 | 146/400 [1:07:12<1:56:45, 27.58s/it]2021-12-17 16:51:01,697 iteration 2483 : loss : 0.094567, loss_ce: 0.034301
2021-12-17 16:51:03,157 iteration 2484 : loss : 0.106706, loss_ce: 0.020421
2021-12-17 16:51:04,614 iteration 2485 : loss : 0.112606, loss_ce: 0.034232
2021-12-17 16:51:06,065 iteration 2486 : loss : 0.091283, loss_ce: 0.029999
2021-12-17 16:51:07,458 iteration 2487 : loss : 0.073749, loss_ce: 0.022098
2021-12-17 16:51:08,967 iteration 2488 : loss : 0.092841, loss_ce: 0.037584
2021-12-17 16:51:10,447 iteration 2489 : loss : 0.094220, loss_ce: 0.033572
2021-12-17 16:51:11,953 iteration 2490 : loss : 0.094329, loss_ce: 0.033508
2021-12-17 16:51:13,399 iteration 2491 : loss : 0.085621, loss_ce: 0.019685
2021-12-17 16:51:14,854 iteration 2492 : loss : 0.104613, loss_ce: 0.030820
2021-12-17 16:51:16,240 iteration 2493 : loss : 0.078745, loss_ce: 0.019189
2021-12-17 16:51:17,687 iteration 2494 : loss : 0.082676, loss_ce: 0.023231
2021-12-17 16:51:19,216 iteration 2495 : loss : 0.075988, loss_ce: 0.024672
2021-12-17 16:51:20,563 iteration 2496 : loss : 0.071093, loss_ce: 0.022438
2021-12-17 16:51:21,972 iteration 2497 : loss : 0.077205, loss_ce: 0.019717
2021-12-17 16:51:23,534 iteration 2498 : loss : 0.090669, loss_ce: 0.024420
2021-12-17 16:51:24,986 iteration 2499 : loss : 0.090847, loss_ce: 0.031475
 37%|█████████▉                 | 147/400 [1:07:36<1:52:43, 26.73s/it]2021-12-17 16:51:26,492 iteration 2500 : loss : 0.083693, loss_ce: 0.024287
2021-12-17 16:51:27,957 iteration 2501 : loss : 0.079073, loss_ce: 0.023597
2021-12-17 16:51:29,422 iteration 2502 : loss : 0.094800, loss_ce: 0.035958
2021-12-17 16:51:30,839 iteration 2503 : loss : 0.073335, loss_ce: 0.021186
2021-12-17 16:51:32,319 iteration 2504 : loss : 0.086058, loss_ce: 0.026179
2021-12-17 16:51:33,769 iteration 2505 : loss : 0.083947, loss_ce: 0.022143
2021-12-17 16:51:35,232 iteration 2506 : loss : 0.075471, loss_ce: 0.023583
2021-12-17 16:51:36,632 iteration 2507 : loss : 0.082414, loss_ce: 0.027143
2021-12-17 16:51:37,997 iteration 2508 : loss : 0.079398, loss_ce: 0.025129
2021-12-17 16:51:39,422 iteration 2509 : loss : 0.081051, loss_ce: 0.025814
2021-12-17 16:51:40,806 iteration 2510 : loss : 0.104780, loss_ce: 0.024668
2021-12-17 16:51:42,240 iteration 2511 : loss : 0.085468, loss_ce: 0.029812
2021-12-17 16:51:43,663 iteration 2512 : loss : 0.083830, loss_ce: 0.025979
2021-12-17 16:51:45,104 iteration 2513 : loss : 0.085677, loss_ce: 0.027474
2021-12-17 16:51:46,556 iteration 2514 : loss : 0.102966, loss_ce: 0.033663
2021-12-17 16:51:47,975 iteration 2515 : loss : 0.084508, loss_ce: 0.022486
2021-12-17 16:51:49,376 iteration 2516 : loss : 0.088983, loss_ce: 0.031040
 37%|█████████▉                 | 148/400 [1:08:01<1:49:19, 26.03s/it]2021-12-17 16:51:50,838 iteration 2517 : loss : 0.076592, loss_ce: 0.019912
2021-12-17 16:51:52,359 iteration 2518 : loss : 0.099142, loss_ce: 0.032756
2021-12-17 16:51:53,784 iteration 2519 : loss : 0.093149, loss_ce: 0.028354
2021-12-17 16:51:55,178 iteration 2520 : loss : 0.071870, loss_ce: 0.018949
2021-12-17 16:51:56,635 iteration 2521 : loss : 0.083019, loss_ce: 0.028247
2021-12-17 16:51:58,017 iteration 2522 : loss : 0.079259, loss_ce: 0.023782
2021-12-17 16:51:59,363 iteration 2523 : loss : 0.080970, loss_ce: 0.016354
2021-12-17 16:52:00,859 iteration 2524 : loss : 0.086513, loss_ce: 0.031371
2021-12-17 16:52:02,278 iteration 2525 : loss : 0.081917, loss_ce: 0.026477
2021-12-17 16:52:03,688 iteration 2526 : loss : 0.095015, loss_ce: 0.025220
2021-12-17 16:52:05,169 iteration 2527 : loss : 0.088426, loss_ce: 0.026318
2021-12-17 16:52:06,568 iteration 2528 : loss : 0.095081, loss_ce: 0.030016
2021-12-17 16:52:08,043 iteration 2529 : loss : 0.085030, loss_ce: 0.025839
2021-12-17 16:52:09,490 iteration 2530 : loss : 0.085477, loss_ce: 0.023677
2021-12-17 16:52:10,914 iteration 2531 : loss : 0.093224, loss_ce: 0.025943
2021-12-17 16:52:12,372 iteration 2532 : loss : 0.097621, loss_ce: 0.026735
2021-12-17 16:52:13,819 iteration 2533 : loss : 0.080583, loss_ce: 0.032841
 37%|██████████                 | 149/400 [1:08:25<1:46:54, 25.55s/it]2021-12-17 16:52:15,244 iteration 2534 : loss : 0.069750, loss_ce: 0.022815
2021-12-17 16:52:16,708 iteration 2535 : loss : 0.076703, loss_ce: 0.019299
2021-12-17 16:52:18,192 iteration 2536 : loss : 0.083113, loss_ce: 0.028508
2021-12-17 16:52:19,678 iteration 2537 : loss : 0.116466, loss_ce: 0.036509
2021-12-17 16:52:21,190 iteration 2538 : loss : 0.098549, loss_ce: 0.030817
2021-12-17 16:52:22,578 iteration 2539 : loss : 0.079246, loss_ce: 0.022011
2021-12-17 16:52:24,010 iteration 2540 : loss : 0.086436, loss_ce: 0.022564
2021-12-17 16:52:25,561 iteration 2541 : loss : 0.098750, loss_ce: 0.023530
2021-12-17 16:52:26,935 iteration 2542 : loss : 0.080225, loss_ce: 0.022537
2021-12-17 16:52:28,368 iteration 2543 : loss : 0.084925, loss_ce: 0.024566
2021-12-17 16:52:29,872 iteration 2544 : loss : 0.116282, loss_ce: 0.037943
2021-12-17 16:52:31,362 iteration 2545 : loss : 0.110743, loss_ce: 0.048381
2021-12-17 16:52:32,751 iteration 2546 : loss : 0.075880, loss_ce: 0.020845
2021-12-17 16:52:34,189 iteration 2547 : loss : 0.099055, loss_ce: 0.019328
2021-12-17 16:52:35,628 iteration 2548 : loss : 0.087166, loss_ce: 0.027492
2021-12-17 16:52:37,124 iteration 2549 : loss : 0.095313, loss_ce: 0.029603
2021-12-17 16:52:37,124 Training Data Eval:
2021-12-17 16:52:44,617   Average segmentation loss on training set: 0.0645
2021-12-17 16:52:44,617 Validation Data Eval:
2021-12-17 16:52:47,204   Average segmentation loss on validation set: 0.1406
2021-12-17 16:52:48,639 iteration 2550 : loss : 0.089710, loss_ce: 0.035433
 38%|██████████▏                | 150/400 [1:09:00<1:58:02, 28.33s/it]2021-12-17 16:52:50,086 iteration 2551 : loss : 0.083796, loss_ce: 0.026044
2021-12-17 16:52:51,525 iteration 2552 : loss : 0.078675, loss_ce: 0.022095
2021-12-17 16:52:53,031 iteration 2553 : loss : 0.109561, loss_ce: 0.036706
2021-12-17 16:52:54,519 iteration 2554 : loss : 0.148906, loss_ce: 0.037867
2021-12-17 16:52:55,943 iteration 2555 : loss : 0.080514, loss_ce: 0.018949
2021-12-17 16:52:57,322 iteration 2556 : loss : 0.098191, loss_ce: 0.035110
2021-12-17 16:52:58,806 iteration 2557 : loss : 0.090101, loss_ce: 0.028419
2021-12-17 16:53:00,280 iteration 2558 : loss : 0.083152, loss_ce: 0.028118
2021-12-17 16:53:01,778 iteration 2559 : loss : 0.109602, loss_ce: 0.022239
2021-12-17 16:53:03,266 iteration 2560 : loss : 0.085853, loss_ce: 0.026180
2021-12-17 16:53:04,693 iteration 2561 : loss : 0.078509, loss_ce: 0.026271
2021-12-17 16:53:06,084 iteration 2562 : loss : 0.077369, loss_ce: 0.029996
2021-12-17 16:53:07,513 iteration 2563 : loss : 0.082315, loss_ce: 0.021118
2021-12-17 16:53:08,951 iteration 2564 : loss : 0.100445, loss_ce: 0.036039
2021-12-17 16:53:10,377 iteration 2565 : loss : 0.089361, loss_ce: 0.020429
2021-12-17 16:53:11,797 iteration 2566 : loss : 0.077196, loss_ce: 0.028289
2021-12-17 16:53:13,330 iteration 2567 : loss : 0.092418, loss_ce: 0.030129
 38%|██████████▏                | 151/400 [1:09:25<1:53:03, 27.24s/it]2021-12-17 16:53:14,803 iteration 2568 : loss : 0.077621, loss_ce: 0.025518
2021-12-17 16:53:16,239 iteration 2569 : loss : 0.090273, loss_ce: 0.027712
2021-12-17 16:53:17,646 iteration 2570 : loss : 0.084511, loss_ce: 0.019560
2021-12-17 16:53:19,102 iteration 2571 : loss : 0.092139, loss_ce: 0.029172
2021-12-17 16:53:20,492 iteration 2572 : loss : 0.076130, loss_ce: 0.019253
2021-12-17 16:53:21,906 iteration 2573 : loss : 0.081033, loss_ce: 0.025623
2021-12-17 16:53:23,330 iteration 2574 : loss : 0.108261, loss_ce: 0.038857
2021-12-17 16:53:24,795 iteration 2575 : loss : 0.089221, loss_ce: 0.025619
2021-12-17 16:53:26,344 iteration 2576 : loss : 0.082650, loss_ce: 0.028205
2021-12-17 16:53:27,741 iteration 2577 : loss : 0.078563, loss_ce: 0.023184
2021-12-17 16:53:29,195 iteration 2578 : loss : 0.093681, loss_ce: 0.040678
2021-12-17 16:53:30,614 iteration 2579 : loss : 0.085570, loss_ce: 0.021878
2021-12-17 16:53:32,091 iteration 2580 : loss : 0.083120, loss_ce: 0.021301
2021-12-17 16:53:33,639 iteration 2581 : loss : 0.087197, loss_ce: 0.025009
2021-12-17 16:53:34,988 iteration 2582 : loss : 0.085329, loss_ce: 0.028678
2021-12-17 16:53:36,467 iteration 2583 : loss : 0.077110, loss_ce: 0.021931
2021-12-17 16:53:37,891 iteration 2584 : loss : 0.069714, loss_ce: 0.018812
 38%|██████████▎                | 152/400 [1:09:49<1:49:15, 26.44s/it]2021-12-17 16:53:39,405 iteration 2585 : loss : 0.088644, loss_ce: 0.027420
2021-12-17 16:53:40,844 iteration 2586 : loss : 0.093592, loss_ce: 0.032208
2021-12-17 16:53:42,229 iteration 2587 : loss : 0.075163, loss_ce: 0.020557
2021-12-17 16:53:43,649 iteration 2588 : loss : 0.085502, loss_ce: 0.027839
2021-12-17 16:53:45,029 iteration 2589 : loss : 0.077032, loss_ce: 0.023205
2021-12-17 16:53:46,511 iteration 2590 : loss : 0.105301, loss_ce: 0.026903
2021-12-17 16:53:47,953 iteration 2591 : loss : 0.085128, loss_ce: 0.029548
2021-12-17 16:53:49,382 iteration 2592 : loss : 0.071364, loss_ce: 0.018052
2021-12-17 16:53:50,796 iteration 2593 : loss : 0.110862, loss_ce: 0.038799
2021-12-17 16:53:52,257 iteration 2594 : loss : 0.076145, loss_ce: 0.023287
2021-12-17 16:53:53,793 iteration 2595 : loss : 0.097747, loss_ce: 0.026638
2021-12-17 16:53:55,162 iteration 2596 : loss : 0.072453, loss_ce: 0.018794
2021-12-17 16:53:56,608 iteration 2597 : loss : 0.110681, loss_ce: 0.027746
2021-12-17 16:53:58,007 iteration 2598 : loss : 0.076798, loss_ce: 0.026648
2021-12-17 16:53:59,479 iteration 2599 : loss : 0.085231, loss_ce: 0.030391
2021-12-17 16:54:00,912 iteration 2600 : loss : 0.089038, loss_ce: 0.022840
2021-12-17 16:54:02,370 iteration 2601 : loss : 0.081109, loss_ce: 0.023950
 38%|██████████▎                | 153/400 [1:10:14<1:46:25, 25.85s/it]2021-12-17 16:54:03,860 iteration 2602 : loss : 0.099121, loss_ce: 0.028410
2021-12-17 16:54:05,372 iteration 2603 : loss : 0.082264, loss_ce: 0.023137
2021-12-17 16:54:06,811 iteration 2604 : loss : 0.079511, loss_ce: 0.025312
2021-12-17 16:54:08,137 iteration 2605 : loss : 0.067304, loss_ce: 0.015275
2021-12-17 16:54:09,702 iteration 2606 : loss : 0.107802, loss_ce: 0.031524
2021-12-17 16:54:11,159 iteration 2607 : loss : 0.085932, loss_ce: 0.023872
2021-12-17 16:54:12,585 iteration 2608 : loss : 0.090346, loss_ce: 0.033371
2021-12-17 16:54:14,121 iteration 2609 : loss : 0.103453, loss_ce: 0.029834
2021-12-17 16:54:15,609 iteration 2610 : loss : 0.082925, loss_ce: 0.024001
2021-12-17 16:54:17,078 iteration 2611 : loss : 0.087355, loss_ce: 0.026912
2021-12-17 16:54:18,578 iteration 2612 : loss : 0.102729, loss_ce: 0.038765
2021-12-17 16:54:19,963 iteration 2613 : loss : 0.082694, loss_ce: 0.024925
2021-12-17 16:54:21,464 iteration 2614 : loss : 0.093191, loss_ce: 0.026138
2021-12-17 16:54:22,870 iteration 2615 : loss : 0.093381, loss_ce: 0.026728
2021-12-17 16:54:24,356 iteration 2616 : loss : 0.082041, loss_ce: 0.029587
2021-12-17 16:54:25,792 iteration 2617 : loss : 0.095594, loss_ce: 0.026136
2021-12-17 16:54:27,187 iteration 2618 : loss : 0.083206, loss_ce: 0.026556
 38%|██████████▍                | 154/400 [1:10:39<1:44:42, 25.54s/it]2021-12-17 16:54:28,632 iteration 2619 : loss : 0.108505, loss_ce: 0.027054
2021-12-17 16:54:30,029 iteration 2620 : loss : 0.079639, loss_ce: 0.026910
2021-12-17 16:54:31,511 iteration 2621 : loss : 0.086293, loss_ce: 0.025864
2021-12-17 16:54:32,935 iteration 2622 : loss : 0.093887, loss_ce: 0.019485
2021-12-17 16:54:34,397 iteration 2623 : loss : 0.094320, loss_ce: 0.028258
2021-12-17 16:54:35,802 iteration 2624 : loss : 0.078491, loss_ce: 0.019762
2021-12-17 16:54:37,266 iteration 2625 : loss : 0.115811, loss_ce: 0.018856
2021-12-17 16:54:38,721 iteration 2626 : loss : 0.090771, loss_ce: 0.030470
2021-12-17 16:54:40,304 iteration 2627 : loss : 0.097677, loss_ce: 0.030615
2021-12-17 16:54:41,682 iteration 2628 : loss : 0.087616, loss_ce: 0.031812
2021-12-17 16:54:43,178 iteration 2629 : loss : 0.102408, loss_ce: 0.037167
2021-12-17 16:54:44,638 iteration 2630 : loss : 0.099248, loss_ce: 0.029812
2021-12-17 16:54:46,081 iteration 2631 : loss : 0.086673, loss_ce: 0.029524
2021-12-17 16:54:47,513 iteration 2632 : loss : 0.082888, loss_ce: 0.022833
2021-12-17 16:54:48,980 iteration 2633 : loss : 0.085879, loss_ce: 0.036814
2021-12-17 16:54:50,441 iteration 2634 : loss : 0.082869, loss_ce: 0.021216
2021-12-17 16:54:50,441 Training Data Eval:
2021-12-17 16:54:57,910   Average segmentation loss on training set: 0.0655
2021-12-17 16:54:57,911 Validation Data Eval:
2021-12-17 16:55:00,491   Average segmentation loss on validation set: 0.1288
2021-12-17 16:55:08,585 Found new lowest validation loss at iteration 2634! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/TU_3seeds/TU_RESNET_no_pretraining_SGD_best_val_loss_seed2.pth
2021-12-17 16:55:09,968 iteration 2635 : loss : 0.077273, loss_ce: 0.023200
 39%|██████████▍                | 155/400 [1:11:21<2:05:24, 30.71s/it]2021-12-17 16:55:11,366 iteration 2636 : loss : 0.091200, loss_ce: 0.027272
2021-12-17 16:55:12,798 iteration 2637 : loss : 0.087433, loss_ce: 0.026698
2021-12-17 16:55:14,132 iteration 2638 : loss : 0.086171, loss_ce: 0.023696
2021-12-17 16:55:15,438 iteration 2639 : loss : 0.081193, loss_ce: 0.027839
2021-12-17 16:55:16,770 iteration 2640 : loss : 0.091440, loss_ce: 0.027780
2021-12-17 16:55:18,116 iteration 2641 : loss : 0.082222, loss_ce: 0.026590
2021-12-17 16:55:19,434 iteration 2642 : loss : 0.075193, loss_ce: 0.020894
2021-12-17 16:55:20,910 iteration 2643 : loss : 0.078797, loss_ce: 0.023024
2021-12-17 16:55:22,257 iteration 2644 : loss : 0.084318, loss_ce: 0.029687
2021-12-17 16:55:23,578 iteration 2645 : loss : 0.070214, loss_ce: 0.019955
2021-12-17 16:55:25,105 iteration 2646 : loss : 0.082740, loss_ce: 0.024331
2021-12-17 16:55:26,544 iteration 2647 : loss : 0.112148, loss_ce: 0.035107
2021-12-17 16:55:27,934 iteration 2648 : loss : 0.085423, loss_ce: 0.026000
2021-12-17 16:55:29,395 iteration 2649 : loss : 0.096260, loss_ce: 0.030045
2021-12-17 16:55:30,916 iteration 2650 : loss : 0.081147, loss_ce: 0.022695
2021-12-17 16:55:32,411 iteration 2651 : loss : 0.082486, loss_ce: 0.027503
2021-12-17 16:55:33,826 iteration 2652 : loss : 0.075613, loss_ce: 0.023577
 39%|██████████▌                | 156/400 [1:11:45<1:56:32, 28.66s/it]2021-12-17 16:55:35,379 iteration 2653 : loss : 0.090961, loss_ce: 0.031244
2021-12-17 16:55:36,870 iteration 2654 : loss : 0.083190, loss_ce: 0.023950
2021-12-17 16:55:38,414 iteration 2655 : loss : 0.115552, loss_ce: 0.049671
2021-12-17 16:55:39,854 iteration 2656 : loss : 0.090611, loss_ce: 0.022401
2021-12-17 16:55:41,316 iteration 2657 : loss : 0.085158, loss_ce: 0.024900
2021-12-17 16:55:42,670 iteration 2658 : loss : 0.068000, loss_ce: 0.020862
2021-12-17 16:55:44,079 iteration 2659 : loss : 0.092183, loss_ce: 0.020060
2021-12-17 16:55:45,578 iteration 2660 : loss : 0.089358, loss_ce: 0.025524
2021-12-17 16:55:47,006 iteration 2661 : loss : 0.073307, loss_ce: 0.022197
2021-12-17 16:55:48,458 iteration 2662 : loss : 0.081810, loss_ce: 0.031025
2021-12-17 16:55:49,890 iteration 2663 : loss : 0.093357, loss_ce: 0.023996
2021-12-17 16:55:51,443 iteration 2664 : loss : 0.095904, loss_ce: 0.034635
2021-12-17 16:55:52,917 iteration 2665 : loss : 0.082284, loss_ce: 0.025906
2021-12-17 16:55:54,349 iteration 2666 : loss : 0.078427, loss_ce: 0.022723
2021-12-17 16:55:55,860 iteration 2667 : loss : 0.094132, loss_ce: 0.026174
2021-12-17 16:55:57,278 iteration 2668 : loss : 0.079944, loss_ce: 0.025192
2021-12-17 16:55:58,705 iteration 2669 : loss : 0.084131, loss_ce: 0.025711
 39%|██████████▌                | 157/400 [1:12:10<1:51:27, 27.52s/it]2021-12-17 16:56:00,238 iteration 2670 : loss : 0.091520, loss_ce: 0.033497
2021-12-17 16:56:01,808 iteration 2671 : loss : 0.100438, loss_ce: 0.027464
2021-12-17 16:56:03,291 iteration 2672 : loss : 0.099713, loss_ce: 0.029364
2021-12-17 16:56:04,692 iteration 2673 : loss : 0.076445, loss_ce: 0.028907
2021-12-17 16:56:06,173 iteration 2674 : loss : 0.088601, loss_ce: 0.030300
2021-12-17 16:56:07,525 iteration 2675 : loss : 0.072375, loss_ce: 0.021481
2021-12-17 16:56:09,098 iteration 2676 : loss : 0.086763, loss_ce: 0.018470
2021-12-17 16:56:10,575 iteration 2677 : loss : 0.081097, loss_ce: 0.024602
2021-12-17 16:56:12,017 iteration 2678 : loss : 0.087148, loss_ce: 0.030182
2021-12-17 16:56:13,486 iteration 2679 : loss : 0.098180, loss_ce: 0.027340
2021-12-17 16:56:14,931 iteration 2680 : loss : 0.068081, loss_ce: 0.019964
2021-12-17 16:56:16,400 iteration 2681 : loss : 0.080471, loss_ce: 0.022389
2021-12-17 16:56:17,872 iteration 2682 : loss : 0.096471, loss_ce: 0.025851
2021-12-17 16:56:19,324 iteration 2683 : loss : 0.110220, loss_ce: 0.024748
2021-12-17 16:56:20,733 iteration 2684 : loss : 0.086984, loss_ce: 0.031076
2021-12-17 16:56:22,203 iteration 2685 : loss : 0.099877, loss_ce: 0.036162
2021-12-17 16:56:23,610 iteration 2686 : loss : 0.092544, loss_ce: 0.034179
 40%|██████████▋                | 158/400 [1:12:35<1:47:50, 26.74s/it]2021-12-17 16:56:25,020 iteration 2687 : loss : 0.085857, loss_ce: 0.020281
2021-12-17 16:56:26,477 iteration 2688 : loss : 0.097408, loss_ce: 0.025534
2021-12-17 16:56:27,913 iteration 2689 : loss : 0.080729, loss_ce: 0.023601
2021-12-17 16:56:29,461 iteration 2690 : loss : 0.093993, loss_ce: 0.033844
2021-12-17 16:56:30,841 iteration 2691 : loss : 0.075299, loss_ce: 0.023763
2021-12-17 16:56:32,251 iteration 2692 : loss : 0.079590, loss_ce: 0.019206
2021-12-17 16:56:33,712 iteration 2693 : loss : 0.089414, loss_ce: 0.029645
2021-12-17 16:56:35,237 iteration 2694 : loss : 0.118543, loss_ce: 0.039631
2021-12-17 16:56:36,669 iteration 2695 : loss : 0.094197, loss_ce: 0.031582
2021-12-17 16:56:38,142 iteration 2696 : loss : 0.083301, loss_ce: 0.027999
2021-12-17 16:56:39,538 iteration 2697 : loss : 0.073884, loss_ce: 0.023269
2021-12-17 16:56:40,861 iteration 2698 : loss : 0.065225, loss_ce: 0.021610
2021-12-17 16:56:42,318 iteration 2699 : loss : 0.090905, loss_ce: 0.027714
2021-12-17 16:56:43,816 iteration 2700 : loss : 0.082458, loss_ce: 0.029834
2021-12-17 16:56:45,266 iteration 2701 : loss : 0.087041, loss_ce: 0.028941
2021-12-17 16:56:46,745 iteration 2702 : loss : 0.125600, loss_ce: 0.019730
2021-12-17 16:56:48,191 iteration 2703 : loss : 0.090876, loss_ce: 0.029152
 40%|██████████▋                | 159/400 [1:13:00<1:44:48, 26.09s/it]2021-12-17 16:56:49,783 iteration 2704 : loss : 0.092161, loss_ce: 0.031680
2021-12-17 16:56:51,179 iteration 2705 : loss : 0.080055, loss_ce: 0.020394
2021-12-17 16:56:52,575 iteration 2706 : loss : 0.081320, loss_ce: 0.030604
2021-12-17 16:56:54,092 iteration 2707 : loss : 0.100364, loss_ce: 0.027007
2021-12-17 16:56:55,476 iteration 2708 : loss : 0.062378, loss_ce: 0.018005
2021-12-17 16:56:56,920 iteration 2709 : loss : 0.086404, loss_ce: 0.022039
2021-12-17 16:56:58,309 iteration 2710 : loss : 0.083729, loss_ce: 0.023801
2021-12-17 16:56:59,856 iteration 2711 : loss : 0.098562, loss_ce: 0.030955
2021-12-17 16:57:01,259 iteration 2712 : loss : 0.071357, loss_ce: 0.020510
2021-12-17 16:57:02,800 iteration 2713 : loss : 0.098276, loss_ce: 0.027628
2021-12-17 16:57:04,190 iteration 2714 : loss : 0.082355, loss_ce: 0.023307
2021-12-17 16:57:05,653 iteration 2715 : loss : 0.101706, loss_ce: 0.040626
2021-12-17 16:57:07,082 iteration 2716 : loss : 0.077436, loss_ce: 0.022091
2021-12-17 16:57:08,481 iteration 2717 : loss : 0.076888, loss_ce: 0.029074
2021-12-17 16:57:09,888 iteration 2718 : loss : 0.085840, loss_ce: 0.024308
2021-12-17 16:57:11,389 iteration 2719 : loss : 0.110066, loss_ce: 0.024695
2021-12-17 16:57:11,389 Training Data Eval:
2021-12-17 16:57:18,929   Average segmentation loss on training set: 0.0628
2021-12-17 16:57:18,930 Validation Data Eval:
2021-12-17 16:57:21,524   Average segmentation loss on validation set: 0.1359
2021-12-17 16:57:22,918 iteration 2720 : loss : 0.085326, loss_ce: 0.028610
 40%|██████████▊                | 160/400 [1:13:34<1:54:43, 28.68s/it]2021-12-17 16:57:24,433 iteration 2721 : loss : 0.083274, loss_ce: 0.027223
2021-12-17 16:57:25,930 iteration 2722 : loss : 0.096488, loss_ce: 0.032650
2021-12-17 16:57:27,422 iteration 2723 : loss : 0.082734, loss_ce: 0.022748
2021-12-17 16:57:28,818 iteration 2724 : loss : 0.090836, loss_ce: 0.026628
2021-12-17 16:57:30,181 iteration 2725 : loss : 0.077933, loss_ce: 0.021864
2021-12-17 16:57:31,601 iteration 2726 : loss : 0.080650, loss_ce: 0.025188
2021-12-17 16:57:32,976 iteration 2727 : loss : 0.074169, loss_ce: 0.020767
2021-12-17 16:57:34,520 iteration 2728 : loss : 0.104529, loss_ce: 0.032839
2021-12-17 16:57:35,966 iteration 2729 : loss : 0.090732, loss_ce: 0.025033
2021-12-17 16:57:37,452 iteration 2730 : loss : 0.069448, loss_ce: 0.022167
2021-12-17 16:57:38,930 iteration 2731 : loss : 0.108257, loss_ce: 0.041101
2021-12-17 16:57:40,465 iteration 2732 : loss : 0.099563, loss_ce: 0.026905
2021-12-17 16:57:41,938 iteration 2733 : loss : 0.091447, loss_ce: 0.028445
2021-12-17 16:57:43,404 iteration 2734 : loss : 0.075169, loss_ce: 0.017321
2021-12-17 16:57:44,779 iteration 2735 : loss : 0.068724, loss_ce: 0.020314
2021-12-17 16:57:46,286 iteration 2736 : loss : 0.090916, loss_ce: 0.035956
2021-12-17 16:57:47,713 iteration 2737 : loss : 0.082584, loss_ce: 0.023734
 40%|██████████▊                | 161/400 [1:13:59<1:49:35, 27.51s/it]2021-12-17 16:57:49,191 iteration 2738 : loss : 0.074980, loss_ce: 0.025750
2021-12-17 16:57:50,615 iteration 2739 : loss : 0.081774, loss_ce: 0.030599
2021-12-17 16:57:52,093 iteration 2740 : loss : 0.083373, loss_ce: 0.024429
2021-12-17 16:57:53,566 iteration 2741 : loss : 0.075420, loss_ce: 0.019266
2021-12-17 16:57:54,948 iteration 2742 : loss : 0.077735, loss_ce: 0.025555
2021-12-17 16:57:56,415 iteration 2743 : loss : 0.094746, loss_ce: 0.038940
2021-12-17 16:57:57,894 iteration 2744 : loss : 0.074666, loss_ce: 0.022871
2021-12-17 16:57:59,346 iteration 2745 : loss : 0.085079, loss_ce: 0.027394
2021-12-17 16:58:00,736 iteration 2746 : loss : 0.089049, loss_ce: 0.020523
2021-12-17 16:58:02,184 iteration 2747 : loss : 0.071505, loss_ce: 0.018746
2021-12-17 16:58:03,662 iteration 2748 : loss : 0.082444, loss_ce: 0.021671
2021-12-17 16:58:05,041 iteration 2749 : loss : 0.077992, loss_ce: 0.027728
2021-12-17 16:58:06,505 iteration 2750 : loss : 0.085134, loss_ce: 0.020819
2021-12-17 16:58:07,907 iteration 2751 : loss : 0.069781, loss_ce: 0.022747
2021-12-17 16:58:09,273 iteration 2752 : loss : 0.076269, loss_ce: 0.015018
2021-12-17 16:58:10,813 iteration 2753 : loss : 0.101866, loss_ce: 0.038872
2021-12-17 16:58:12,296 iteration 2754 : loss : 0.069855, loss_ce: 0.022094
 40%|██████████▉                | 162/400 [1:14:24<1:45:39, 26.64s/it]2021-12-17 16:58:13,768 iteration 2755 : loss : 0.067823, loss_ce: 0.019246
2021-12-17 16:58:15,221 iteration 2756 : loss : 0.100608, loss_ce: 0.044401
2021-12-17 16:58:16,663 iteration 2757 : loss : 0.086834, loss_ce: 0.024825
2021-12-17 16:58:18,172 iteration 2758 : loss : 0.093316, loss_ce: 0.025909
2021-12-17 16:58:19,625 iteration 2759 : loss : 0.079949, loss_ce: 0.020858
2021-12-17 16:58:21,066 iteration 2760 : loss : 0.079227, loss_ce: 0.023682
2021-12-17 16:58:22,426 iteration 2761 : loss : 0.085472, loss_ce: 0.024807
2021-12-17 16:58:23,818 iteration 2762 : loss : 0.069819, loss_ce: 0.019566
2021-12-17 16:58:25,306 iteration 2763 : loss : 0.108188, loss_ce: 0.027994
2021-12-17 16:58:26,749 iteration 2764 : loss : 0.083395, loss_ce: 0.024399
2021-12-17 16:58:28,196 iteration 2765 : loss : 0.082472, loss_ce: 0.024674
2021-12-17 16:58:29,610 iteration 2766 : loss : 0.070997, loss_ce: 0.021741
2021-12-17 16:58:31,077 iteration 2767 : loss : 0.077460, loss_ce: 0.024599
2021-12-17 16:58:32,477 iteration 2768 : loss : 0.074902, loss_ce: 0.018151
2021-12-17 16:58:33,917 iteration 2769 : loss : 0.075882, loss_ce: 0.024775
2021-12-17 16:58:35,360 iteration 2770 : loss : 0.085917, loss_ce: 0.033672
2021-12-17 16:58:36,776 iteration 2771 : loss : 0.080905, loss_ce: 0.020799
 41%|███████████                | 163/400 [1:14:48<1:42:39, 25.99s/it]2021-12-17 16:58:38,306 iteration 2772 : loss : 0.081964, loss_ce: 0.026508
2021-12-17 16:58:39,672 iteration 2773 : loss : 0.075588, loss_ce: 0.023949
2021-12-17 16:58:41,043 iteration 2774 : loss : 0.098715, loss_ce: 0.021594
2021-12-17 16:58:42,473 iteration 2775 : loss : 0.077788, loss_ce: 0.023243
2021-12-17 16:58:43,882 iteration 2776 : loss : 0.066821, loss_ce: 0.019575
2021-12-17 16:58:45,322 iteration 2777 : loss : 0.069927, loss_ce: 0.018981
2021-12-17 16:58:46,838 iteration 2778 : loss : 0.083155, loss_ce: 0.026957
2021-12-17 16:58:48,374 iteration 2779 : loss : 0.088101, loss_ce: 0.029510
2021-12-17 16:58:49,757 iteration 2780 : loss : 0.075384, loss_ce: 0.019807
2021-12-17 16:58:51,233 iteration 2781 : loss : 0.102111, loss_ce: 0.028901
2021-12-17 16:58:52,662 iteration 2782 : loss : 0.079184, loss_ce: 0.023056
2021-12-17 16:58:54,055 iteration 2783 : loss : 0.078611, loss_ce: 0.027271
2021-12-17 16:58:55,594 iteration 2784 : loss : 0.091016, loss_ce: 0.023885
2021-12-17 16:58:57,102 iteration 2785 : loss : 0.089007, loss_ce: 0.020936
2021-12-17 16:58:58,572 iteration 2786 : loss : 0.085202, loss_ce: 0.028440
2021-12-17 16:59:00,048 iteration 2787 : loss : 0.073619, loss_ce: 0.023722
2021-12-17 16:59:01,452 iteration 2788 : loss : 0.085532, loss_ce: 0.036598
 41%|███████████                | 164/400 [1:15:13<1:40:40, 25.60s/it]2021-12-17 16:59:02,901 iteration 2789 : loss : 0.076283, loss_ce: 0.024033
2021-12-17 16:59:04,367 iteration 2790 : loss : 0.091547, loss_ce: 0.021773
2021-12-17 16:59:05,781 iteration 2791 : loss : 0.087328, loss_ce: 0.027749
2021-12-17 16:59:07,269 iteration 2792 : loss : 0.082210, loss_ce: 0.022657
2021-12-17 16:59:08,662 iteration 2793 : loss : 0.079237, loss_ce: 0.025009
2021-12-17 16:59:10,145 iteration 2794 : loss : 0.086705, loss_ce: 0.024178
2021-12-17 16:59:11,545 iteration 2795 : loss : 0.072261, loss_ce: 0.017223
2021-12-17 16:59:13,004 iteration 2796 : loss : 0.079856, loss_ce: 0.024460
2021-12-17 16:59:14,471 iteration 2797 : loss : 0.080678, loss_ce: 0.023949
2021-12-17 16:59:15,953 iteration 2798 : loss : 0.096767, loss_ce: 0.038875
2021-12-17 16:59:17,344 iteration 2799 : loss : 0.075624, loss_ce: 0.025216
2021-12-17 16:59:18,733 iteration 2800 : loss : 0.104732, loss_ce: 0.030146
2021-12-17 16:59:20,116 iteration 2801 : loss : 0.070159, loss_ce: 0.017770
2021-12-17 16:59:21,612 iteration 2802 : loss : 0.093711, loss_ce: 0.025196
2021-12-17 16:59:23,038 iteration 2803 : loss : 0.079807, loss_ce: 0.029904
2021-12-17 16:59:24,454 iteration 2804 : loss : 0.081501, loss_ce: 0.024660
2021-12-17 16:59:24,454 Training Data Eval:
2021-12-17 16:59:31,945   Average segmentation loss on training set: 0.0653
2021-12-17 16:59:31,945 Validation Data Eval:
2021-12-17 16:59:34,536   Average segmentation loss on validation set: 0.1271
2021-12-17 16:59:40,831 Found new lowest validation loss at iteration 2804! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/TU_3seeds/TU_RESNET_no_pretraining_SGD_best_val_loss_seed2.pth
2021-12-17 16:59:42,173 iteration 2805 : loss : 0.075719, loss_ce: 0.025077
 41%|███████████▏               | 165/400 [1:15:54<1:58:00, 30.13s/it]2021-12-17 16:59:43,679 iteration 2806 : loss : 0.088125, loss_ce: 0.031442
2021-12-17 16:59:44,966 iteration 2807 : loss : 0.087080, loss_ce: 0.027500
2021-12-17 16:59:46,275 iteration 2808 : loss : 0.072903, loss_ce: 0.022933
2021-12-17 16:59:47,662 iteration 2809 : loss : 0.074952, loss_ce: 0.021284
2021-12-17 16:59:49,008 iteration 2810 : loss : 0.097076, loss_ce: 0.034327
2021-12-17 16:59:50,456 iteration 2811 : loss : 0.083470, loss_ce: 0.022219
2021-12-17 16:59:51,916 iteration 2812 : loss : 0.083431, loss_ce: 0.023450
2021-12-17 16:59:53,198 iteration 2813 : loss : 0.070634, loss_ce: 0.021123
2021-12-17 16:59:54,580 iteration 2814 : loss : 0.091760, loss_ce: 0.037051
2021-12-17 16:59:55,987 iteration 2815 : loss : 0.086504, loss_ce: 0.029741
2021-12-17 16:59:57,327 iteration 2816 : loss : 0.074285, loss_ce: 0.022351
2021-12-17 16:59:58,712 iteration 2817 : loss : 0.082619, loss_ce: 0.024781
2021-12-17 17:00:00,265 iteration 2818 : loss : 0.086978, loss_ce: 0.025517
2021-12-17 17:00:01,790 iteration 2819 : loss : 0.067731, loss_ce: 0.022338
2021-12-17 17:00:03,234 iteration 2820 : loss : 0.078424, loss_ce: 0.024212
2021-12-17 17:00:04,711 iteration 2821 : loss : 0.064300, loss_ce: 0.019629
2021-12-17 17:00:06,215 iteration 2822 : loss : 0.123324, loss_ce: 0.024284
 42%|███████████▏               | 166/400 [1:16:18<1:50:23, 28.30s/it]2021-12-17 17:00:07,743 iteration 2823 : loss : 0.086648, loss_ce: 0.026403
2021-12-17 17:00:09,222 iteration 2824 : loss : 0.091019, loss_ce: 0.024533
2021-12-17 17:00:10,687 iteration 2825 : loss : 0.102700, loss_ce: 0.034383
2021-12-17 17:00:12,089 iteration 2826 : loss : 0.070711, loss_ce: 0.019614
2021-12-17 17:00:13,579 iteration 2827 : loss : 0.076264, loss_ce: 0.020664
2021-12-17 17:00:15,015 iteration 2828 : loss : 0.102307, loss_ce: 0.041238
2021-12-17 17:00:16,445 iteration 2829 : loss : 0.086485, loss_ce: 0.021817
2021-12-17 17:00:17,925 iteration 2830 : loss : 0.079805, loss_ce: 0.027416
2021-12-17 17:00:19,356 iteration 2831 : loss : 0.095626, loss_ce: 0.025383
2021-12-17 17:00:20,752 iteration 2832 : loss : 0.071608, loss_ce: 0.022718
2021-12-17 17:00:22,282 iteration 2833 : loss : 0.070440, loss_ce: 0.021585
2021-12-17 17:00:23,741 iteration 2834 : loss : 0.072814, loss_ce: 0.022469
2021-12-17 17:00:25,213 iteration 2835 : loss : 0.116515, loss_ce: 0.041344
2021-12-17 17:00:26,686 iteration 2836 : loss : 0.082275, loss_ce: 0.024875
2021-12-17 17:00:28,173 iteration 2837 : loss : 0.068697, loss_ce: 0.018402
2021-12-17 17:00:29,656 iteration 2838 : loss : 0.077417, loss_ce: 0.021834
2021-12-17 17:00:31,043 iteration 2839 : loss : 0.065801, loss_ce: 0.019259
 42%|███████████▎               | 167/400 [1:16:42<1:45:51, 27.26s/it]2021-12-17 17:00:32,522 iteration 2840 : loss : 0.080391, loss_ce: 0.022458
2021-12-17 17:00:33,926 iteration 2841 : loss : 0.071200, loss_ce: 0.024163
2021-12-17 17:00:35,300 iteration 2842 : loss : 0.066201, loss_ce: 0.018615
2021-12-17 17:00:36,739 iteration 2843 : loss : 0.073843, loss_ce: 0.017451
2021-12-17 17:00:38,235 iteration 2844 : loss : 0.076603, loss_ce: 0.026147
2021-12-17 17:00:39,745 iteration 2845 : loss : 0.073076, loss_ce: 0.019822
2021-12-17 17:00:41,177 iteration 2846 : loss : 0.080371, loss_ce: 0.023493
2021-12-17 17:00:42,650 iteration 2847 : loss : 0.087962, loss_ce: 0.032213
2021-12-17 17:00:44,184 iteration 2848 : loss : 0.095093, loss_ce: 0.035862
2021-12-17 17:00:45,604 iteration 2849 : loss : 0.071185, loss_ce: 0.020318
2021-12-17 17:00:47,015 iteration 2850 : loss : 0.072528, loss_ce: 0.019011
2021-12-17 17:00:48,467 iteration 2851 : loss : 0.076566, loss_ce: 0.024953
2021-12-17 17:00:49,923 iteration 2852 : loss : 0.109098, loss_ce: 0.040358
2021-12-17 17:00:51,345 iteration 2853 : loss : 0.074440, loss_ce: 0.021872
2021-12-17 17:00:52,830 iteration 2854 : loss : 0.083133, loss_ce: 0.028915
2021-12-17 17:00:54,265 iteration 2855 : loss : 0.086351, loss_ce: 0.028752
2021-12-17 17:00:55,760 iteration 2856 : loss : 0.083464, loss_ce: 0.027952
 42%|███████████▎               | 168/400 [1:17:07<1:42:27, 26.50s/it]2021-12-17 17:00:57,294 iteration 2857 : loss : 0.098162, loss_ce: 0.023744
2021-12-17 17:00:58,758 iteration 2858 : loss : 0.079627, loss_ce: 0.020596
2021-12-17 17:01:00,153 iteration 2859 : loss : 0.078197, loss_ce: 0.021452
2021-12-17 17:01:01,651 iteration 2860 : loss : 0.081449, loss_ce: 0.026054
2021-12-17 17:01:03,060 iteration 2861 : loss : 0.076623, loss_ce: 0.020316
2021-12-17 17:01:04,549 iteration 2862 : loss : 0.083669, loss_ce: 0.024642
2021-12-17 17:01:06,057 iteration 2863 : loss : 0.095205, loss_ce: 0.028489
2021-12-17 17:01:07,514 iteration 2864 : loss : 0.081004, loss_ce: 0.027262
2021-12-17 17:01:08,896 iteration 2865 : loss : 0.076632, loss_ce: 0.022932
2021-12-17 17:01:10,343 iteration 2866 : loss : 0.080749, loss_ce: 0.020923
2021-12-17 17:01:11,845 iteration 2867 : loss : 0.095676, loss_ce: 0.028106
2021-12-17 17:01:13,326 iteration 2868 : loss : 0.081215, loss_ce: 0.028735
2021-12-17 17:01:14,723 iteration 2869 : loss : 0.075731, loss_ce: 0.025208
2021-12-17 17:01:16,179 iteration 2870 : loss : 0.087557, loss_ce: 0.036642
2021-12-17 17:01:17,541 iteration 2871 : loss : 0.067097, loss_ce: 0.023657
2021-12-17 17:01:18,996 iteration 2872 : loss : 0.090699, loss_ce: 0.025429
2021-12-17 17:01:20,483 iteration 2873 : loss : 0.087919, loss_ce: 0.034004
 42%|███████████▍               | 169/400 [1:17:32<1:39:58, 25.97s/it]2021-12-17 17:01:21,937 iteration 2874 : loss : 0.071925, loss_ce: 0.015199
2021-12-17 17:01:23,302 iteration 2875 : loss : 0.062675, loss_ce: 0.018005
2021-12-17 17:01:24,725 iteration 2876 : loss : 0.073001, loss_ce: 0.023464
2021-12-17 17:01:26,191 iteration 2877 : loss : 0.076745, loss_ce: 0.019425
2021-12-17 17:01:27,662 iteration 2878 : loss : 0.094707, loss_ce: 0.027952
2021-12-17 17:01:29,053 iteration 2879 : loss : 0.070517, loss_ce: 0.024745
2021-12-17 17:01:30,563 iteration 2880 : loss : 0.107480, loss_ce: 0.038548
2021-12-17 17:01:31,996 iteration 2881 : loss : 0.086036, loss_ce: 0.029797
2021-12-17 17:01:33,516 iteration 2882 : loss : 0.099517, loss_ce: 0.024762
2021-12-17 17:01:35,024 iteration 2883 : loss : 0.084776, loss_ce: 0.031189
2021-12-17 17:01:36,540 iteration 2884 : loss : 0.077186, loss_ce: 0.021904
2021-12-17 17:01:38,003 iteration 2885 : loss : 0.075853, loss_ce: 0.028234
2021-12-17 17:01:39,428 iteration 2886 : loss : 0.077156, loss_ce: 0.016738
2021-12-17 17:01:40,869 iteration 2887 : loss : 0.073366, loss_ce: 0.021989
2021-12-17 17:01:42,399 iteration 2888 : loss : 0.077004, loss_ce: 0.021951
2021-12-17 17:01:43,840 iteration 2889 : loss : 0.078142, loss_ce: 0.024901
2021-12-17 17:01:43,840 Training Data Eval:
2021-12-17 17:01:51,322   Average segmentation loss on training set: 0.0612
2021-12-17 17:01:51,323 Validation Data Eval:
2021-12-17 17:01:53,916   Average segmentation loss on validation set: 0.1343
2021-12-17 17:01:55,421 iteration 2890 : loss : 0.081146, loss_ce: 0.025916
 42%|███████████▍               | 170/400 [1:18:07<1:49:51, 28.66s/it]2021-12-17 17:01:56,982 iteration 2891 : loss : 0.082220, loss_ce: 0.033651
2021-12-17 17:01:58,374 iteration 2892 : loss : 0.072949, loss_ce: 0.026379
2021-12-17 17:01:59,794 iteration 2893 : loss : 0.106151, loss_ce: 0.027237
2021-12-17 17:02:01,268 iteration 2894 : loss : 0.070273, loss_ce: 0.023137
2021-12-17 17:02:02,692 iteration 2895 : loss : 0.080602, loss_ce: 0.022719
2021-12-17 17:02:04,089 iteration 2896 : loss : 0.076222, loss_ce: 0.023832
2021-12-17 17:02:05,519 iteration 2897 : loss : 0.074940, loss_ce: 0.023436
2021-12-17 17:02:06,968 iteration 2898 : loss : 0.086471, loss_ce: 0.034066
2021-12-17 17:02:08,458 iteration 2899 : loss : 0.076324, loss_ce: 0.022419
2021-12-17 17:02:09,853 iteration 2900 : loss : 0.077499, loss_ce: 0.019227
2021-12-17 17:02:11,401 iteration 2901 : loss : 0.077168, loss_ce: 0.019936
2021-12-17 17:02:12,746 iteration 2902 : loss : 0.064481, loss_ce: 0.016151
2021-12-17 17:02:14,225 iteration 2903 : loss : 0.083224, loss_ce: 0.027590
2021-12-17 17:02:15,732 iteration 2904 : loss : 0.095302, loss_ce: 0.027335
2021-12-17 17:02:17,161 iteration 2905 : loss : 0.082226, loss_ce: 0.022316
2021-12-17 17:02:18,659 iteration 2906 : loss : 0.086193, loss_ce: 0.025646
2021-12-17 17:02:20,060 iteration 2907 : loss : 0.059919, loss_ce: 0.017622
 43%|███████████▌               | 171/400 [1:18:31<1:44:46, 27.45s/it]2021-12-17 17:02:21,536 iteration 2908 : loss : 0.079795, loss_ce: 0.024287
2021-12-17 17:02:22,906 iteration 2909 : loss : 0.075661, loss_ce: 0.015242
2021-12-17 17:02:24,383 iteration 2910 : loss : 0.085016, loss_ce: 0.023889
2021-12-17 17:02:25,828 iteration 2911 : loss : 0.090728, loss_ce: 0.029528
2021-12-17 17:02:27,257 iteration 2912 : loss : 0.070511, loss_ce: 0.019857
2021-12-17 17:02:28,735 iteration 2913 : loss : 0.090360, loss_ce: 0.028670
2021-12-17 17:02:30,196 iteration 2914 : loss : 0.092401, loss_ce: 0.032255
2021-12-17 17:02:31,692 iteration 2915 : loss : 0.068452, loss_ce: 0.018038
2021-12-17 17:02:33,093 iteration 2916 : loss : 0.070007, loss_ce: 0.028562
2021-12-17 17:02:34,613 iteration 2917 : loss : 0.077883, loss_ce: 0.025333
2021-12-17 17:02:36,084 iteration 2918 : loss : 0.080318, loss_ce: 0.023270
2021-12-17 17:02:37,569 iteration 2919 : loss : 0.103684, loss_ce: 0.040122
2021-12-17 17:02:39,038 iteration 2920 : loss : 0.098464, loss_ce: 0.023135
2021-12-17 17:02:40,559 iteration 2921 : loss : 0.076184, loss_ce: 0.018405
2021-12-17 17:02:41,973 iteration 2922 : loss : 0.085587, loss_ce: 0.029427
2021-12-17 17:02:43,450 iteration 2923 : loss : 0.078270, loss_ce: 0.025521
2021-12-17 17:02:44,885 iteration 2924 : loss : 0.070287, loss_ce: 0.018334
 43%|███████████▌               | 172/400 [1:18:56<1:41:19, 26.67s/it]2021-12-17 17:02:46,450 iteration 2925 : loss : 0.094919, loss_ce: 0.032056
2021-12-17 17:02:47,859 iteration 2926 : loss : 0.077201, loss_ce: 0.019789
2021-12-17 17:02:49,373 iteration 2927 : loss : 0.091289, loss_ce: 0.033273
2021-12-17 17:02:50,931 iteration 2928 : loss : 0.073416, loss_ce: 0.015451
2021-12-17 17:02:52,352 iteration 2929 : loss : 0.070603, loss_ce: 0.019459
2021-12-17 17:02:53,781 iteration 2930 : loss : 0.076321, loss_ce: 0.023807
2021-12-17 17:02:55,163 iteration 2931 : loss : 0.083535, loss_ce: 0.027822
2021-12-17 17:02:56,676 iteration 2932 : loss : 0.067539, loss_ce: 0.020378
2021-12-17 17:02:58,095 iteration 2933 : loss : 0.076133, loss_ce: 0.021830
2021-12-17 17:02:59,592 iteration 2934 : loss : 0.081996, loss_ce: 0.029676
2021-12-17 17:03:01,049 iteration 2935 : loss : 0.132128, loss_ce: 0.041985
2021-12-17 17:03:02,554 iteration 2936 : loss : 0.082850, loss_ce: 0.028275
2021-12-17 17:03:03,999 iteration 2937 : loss : 0.066634, loss_ce: 0.020160
2021-12-17 17:03:05,453 iteration 2938 : loss : 0.065991, loss_ce: 0.019566
2021-12-17 17:03:06,884 iteration 2939 : loss : 0.074052, loss_ce: 0.026578
2021-12-17 17:03:08,362 iteration 2940 : loss : 0.071255, loss_ce: 0.017847
2021-12-17 17:03:09,800 iteration 2941 : loss : 0.072973, loss_ce: 0.018338
 43%|███████████▋               | 173/400 [1:19:21<1:38:53, 26.14s/it]2021-12-17 17:03:11,301 iteration 2942 : loss : 0.082197, loss_ce: 0.027322
2021-12-17 17:03:12,657 iteration 2943 : loss : 0.069174, loss_ce: 0.021288
2021-12-17 17:03:14,054 iteration 2944 : loss : 0.086220, loss_ce: 0.023085
2021-12-17 17:03:15,557 iteration 2945 : loss : 0.094014, loss_ce: 0.035902
2021-12-17 17:03:16,964 iteration 2946 : loss : 0.073274, loss_ce: 0.025163
2021-12-17 17:03:18,357 iteration 2947 : loss : 0.065188, loss_ce: 0.016999
2021-12-17 17:03:19,799 iteration 2948 : loss : 0.104466, loss_ce: 0.036020
2021-12-17 17:03:21,266 iteration 2949 : loss : 0.072984, loss_ce: 0.020556
2021-12-17 17:03:22,714 iteration 2950 : loss : 0.092667, loss_ce: 0.031312
2021-12-17 17:03:24,112 iteration 2951 : loss : 0.072340, loss_ce: 0.020162
2021-12-17 17:03:25,561 iteration 2952 : loss : 0.081408, loss_ce: 0.019981
2021-12-17 17:03:27,003 iteration 2953 : loss : 0.105130, loss_ce: 0.035751
2021-12-17 17:03:28,469 iteration 2954 : loss : 0.126507, loss_ce: 0.038488
2021-12-17 17:03:29,866 iteration 2955 : loss : 0.072011, loss_ce: 0.023436
2021-12-17 17:03:31,299 iteration 2956 : loss : 0.068173, loss_ce: 0.022522
2021-12-17 17:03:32,731 iteration 2957 : loss : 0.082232, loss_ce: 0.017501
2021-12-17 17:03:34,165 iteration 2958 : loss : 0.078807, loss_ce: 0.022944
 44%|███████████▋               | 174/400 [1:19:46<1:36:27, 25.61s/it]2021-12-17 17:03:35,723 iteration 2959 : loss : 0.073404, loss_ce: 0.024895
2021-12-17 17:03:37,193 iteration 2960 : loss : 0.068825, loss_ce: 0.020152
2021-12-17 17:03:38,683 iteration 2961 : loss : 0.075612, loss_ce: 0.028316
2021-12-17 17:03:40,089 iteration 2962 : loss : 0.075927, loss_ce: 0.021002
2021-12-17 17:03:41,531 iteration 2963 : loss : 0.080371, loss_ce: 0.024826
2021-12-17 17:03:43,027 iteration 2964 : loss : 0.077747, loss_ce: 0.022208
2021-12-17 17:03:44,464 iteration 2965 : loss : 0.074617, loss_ce: 0.026721
2021-12-17 17:03:45,881 iteration 2966 : loss : 0.067471, loss_ce: 0.018139
2021-12-17 17:03:47,388 iteration 2967 : loss : 0.089746, loss_ce: 0.025903
2021-12-17 17:03:48,819 iteration 2968 : loss : 0.090792, loss_ce: 0.024504
2021-12-17 17:03:50,216 iteration 2969 : loss : 0.079685, loss_ce: 0.017872
2021-12-17 17:03:51,646 iteration 2970 : loss : 0.088301, loss_ce: 0.028148
2021-12-17 17:03:53,113 iteration 2971 : loss : 0.099361, loss_ce: 0.026060
2021-12-17 17:03:54,577 iteration 2972 : loss : 0.075137, loss_ce: 0.022218
2021-12-17 17:03:56,013 iteration 2973 : loss : 0.069701, loss_ce: 0.023378
2021-12-17 17:03:57,568 iteration 2974 : loss : 0.093608, loss_ce: 0.032504
2021-12-17 17:03:57,568 Training Data Eval:
2021-12-17 17:04:05,019   Average segmentation loss on training set: 0.0588
2021-12-17 17:04:05,019 Validation Data Eval:
2021-12-17 17:04:07,617   Average segmentation loss on validation set: 0.1282
2021-12-17 17:04:09,046 iteration 2975 : loss : 0.096041, loss_ce: 0.025114
 44%|███████████▊               | 175/400 [1:20:20<1:46:27, 28.39s/it]2021-12-17 17:04:10,565 iteration 2976 : loss : 0.104839, loss_ce: 0.036637
2021-12-17 17:04:12,131 iteration 2977 : loss : 0.088175, loss_ce: 0.024782
2021-12-17 17:04:13,580 iteration 2978 : loss : 0.089042, loss_ce: 0.029682
2021-12-17 17:04:15,083 iteration 2979 : loss : 0.125915, loss_ce: 0.034159
2021-12-17 17:04:16,661 iteration 2980 : loss : 0.095598, loss_ce: 0.035531
2021-12-17 17:04:18,104 iteration 2981 : loss : 0.070470, loss_ce: 0.024902
2021-12-17 17:04:19,550 iteration 2982 : loss : 0.072129, loss_ce: 0.021324
2021-12-17 17:04:21,028 iteration 2983 : loss : 0.089483, loss_ce: 0.020763
2021-12-17 17:04:22,489 iteration 2984 : loss : 0.068814, loss_ce: 0.022433
2021-12-17 17:04:23,938 iteration 2985 : loss : 0.070822, loss_ce: 0.022610
2021-12-17 17:04:25,359 iteration 2986 : loss : 0.085005, loss_ce: 0.028631
2021-12-17 17:04:26,768 iteration 2987 : loss : 0.073131, loss_ce: 0.021955
2021-12-17 17:04:28,227 iteration 2988 : loss : 0.089909, loss_ce: 0.028896
2021-12-17 17:04:29,643 iteration 2989 : loss : 0.068035, loss_ce: 0.018996
2021-12-17 17:04:31,103 iteration 2990 : loss : 0.089973, loss_ce: 0.033048
2021-12-17 17:04:32,510 iteration 2991 : loss : 0.071626, loss_ce: 0.017230
2021-12-17 17:04:33,970 iteration 2992 : loss : 0.074238, loss_ce: 0.025346
 44%|███████████▉               | 176/400 [1:20:45<1:42:06, 27.35s/it]2021-12-17 17:04:35,464 iteration 2993 : loss : 0.078547, loss_ce: 0.024423
2021-12-17 17:04:36,881 iteration 2994 : loss : 0.077470, loss_ce: 0.026990
2021-12-17 17:04:38,354 iteration 2995 : loss : 0.088946, loss_ce: 0.028792
2021-12-17 17:04:39,751 iteration 2996 : loss : 0.083237, loss_ce: 0.025426
2021-12-17 17:04:41,188 iteration 2997 : loss : 0.079380, loss_ce: 0.022389
2021-12-17 17:04:42,675 iteration 2998 : loss : 0.066790, loss_ce: 0.021384
2021-12-17 17:04:44,123 iteration 2999 : loss : 0.080444, loss_ce: 0.023484
2021-12-17 17:04:45,560 iteration 3000 : loss : 0.074291, loss_ce: 0.024872
2021-12-17 17:04:47,093 iteration 3001 : loss : 0.075933, loss_ce: 0.023411
2021-12-17 17:04:48,575 iteration 3002 : loss : 0.090565, loss_ce: 0.025984
2021-12-17 17:04:49,946 iteration 3003 : loss : 0.069441, loss_ce: 0.021075
2021-12-17 17:04:51,377 iteration 3004 : loss : 0.082863, loss_ce: 0.031767
2021-12-17 17:04:52,793 iteration 3005 : loss : 0.072240, loss_ce: 0.025954
2021-12-17 17:04:54,221 iteration 3006 : loss : 0.079533, loss_ce: 0.024365
2021-12-17 17:04:55,669 iteration 3007 : loss : 0.072682, loss_ce: 0.018642
2021-12-17 17:04:57,065 iteration 3008 : loss : 0.076469, loss_ce: 0.021405
2021-12-17 17:04:58,475 iteration 3009 : loss : 0.082226, loss_ce: 0.019315
 44%|███████████▉               | 177/400 [1:21:10<1:38:28, 26.50s/it]2021-12-17 17:05:00,048 iteration 3010 : loss : 0.088853, loss_ce: 0.023922
2021-12-17 17:05:01,451 iteration 3011 : loss : 0.074534, loss_ce: 0.017030
2021-12-17 17:05:02,846 iteration 3012 : loss : 0.075818, loss_ce: 0.020522
2021-12-17 17:05:04,354 iteration 3013 : loss : 0.075378, loss_ce: 0.018950
2021-12-17 17:05:05,811 iteration 3014 : loss : 0.076895, loss_ce: 0.025936
2021-12-17 17:05:07,274 iteration 3015 : loss : 0.079850, loss_ce: 0.022846
2021-12-17 17:05:08,659 iteration 3016 : loss : 0.068941, loss_ce: 0.019176
2021-12-17 17:05:10,159 iteration 3017 : loss : 0.080197, loss_ce: 0.033368
2021-12-17 17:05:11,665 iteration 3018 : loss : 0.079060, loss_ce: 0.029484
2021-12-17 17:05:13,225 iteration 3019 : loss : 0.095026, loss_ce: 0.032470
2021-12-17 17:05:14,633 iteration 3020 : loss : 0.072445, loss_ce: 0.018860
2021-12-17 17:05:16,073 iteration 3021 : loss : 0.078202, loss_ce: 0.024287
2021-12-17 17:05:17,447 iteration 3022 : loss : 0.072468, loss_ce: 0.027464
2021-12-17 17:05:18,856 iteration 3023 : loss : 0.064381, loss_ce: 0.018331
2021-12-17 17:05:20,302 iteration 3024 : loss : 0.079275, loss_ce: 0.027617
2021-12-17 17:05:21,741 iteration 3025 : loss : 0.076688, loss_ce: 0.025196
2021-12-17 17:05:23,139 iteration 3026 : loss : 0.078867, loss_ce: 0.019662
 44%|████████████               | 178/400 [1:21:35<1:35:59, 25.95s/it]2021-12-17 17:05:24,607 iteration 3027 : loss : 0.087249, loss_ce: 0.031498
2021-12-17 17:05:26,136 iteration 3028 : loss : 0.090996, loss_ce: 0.030159
2021-12-17 17:05:27,553 iteration 3029 : loss : 0.064594, loss_ce: 0.015653
2021-12-17 17:05:29,063 iteration 3030 : loss : 0.076101, loss_ce: 0.021236
2021-12-17 17:05:30,577 iteration 3031 : loss : 0.097994, loss_ce: 0.027593
2021-12-17 17:05:32,070 iteration 3032 : loss : 0.064905, loss_ce: 0.018770
2021-12-17 17:05:33,535 iteration 3033 : loss : 0.079878, loss_ce: 0.022395
2021-12-17 17:05:34,950 iteration 3034 : loss : 0.073876, loss_ce: 0.018917
2021-12-17 17:05:36,340 iteration 3035 : loss : 0.068607, loss_ce: 0.019807
2021-12-17 17:05:37,806 iteration 3036 : loss : 0.075909, loss_ce: 0.027228
2021-12-17 17:05:39,189 iteration 3037 : loss : 0.072570, loss_ce: 0.023375
2021-12-17 17:05:40,566 iteration 3038 : loss : 0.068173, loss_ce: 0.023594
2021-12-17 17:05:41,967 iteration 3039 : loss : 0.070947, loss_ce: 0.021150
2021-12-17 17:05:43,472 iteration 3040 : loss : 0.081146, loss_ce: 0.020942
2021-12-17 17:05:44,815 iteration 3041 : loss : 0.065440, loss_ce: 0.019325
2021-12-17 17:05:46,217 iteration 3042 : loss : 0.082073, loss_ce: 0.032155
2021-12-17 17:05:47,610 iteration 3043 : loss : 0.074317, loss_ce: 0.026484
 45%|████████████               | 179/400 [1:21:59<1:33:56, 25.50s/it]2021-12-17 17:05:49,128 iteration 3044 : loss : 0.081488, loss_ce: 0.023187
2021-12-17 17:05:50,495 iteration 3045 : loss : 0.075240, loss_ce: 0.019485
2021-12-17 17:05:52,029 iteration 3046 : loss : 0.091124, loss_ce: 0.034379
2021-12-17 17:05:53,559 iteration 3047 : loss : 0.072244, loss_ce: 0.019178
2021-12-17 17:05:55,014 iteration 3048 : loss : 0.079577, loss_ce: 0.024409
2021-12-17 17:05:56,468 iteration 3049 : loss : 0.071089, loss_ce: 0.019813
2021-12-17 17:05:57,934 iteration 3050 : loss : 0.109407, loss_ce: 0.025658
2021-12-17 17:05:59,447 iteration 3051 : loss : 0.075677, loss_ce: 0.021655
2021-12-17 17:06:00,959 iteration 3052 : loss : 0.090184, loss_ce: 0.034781
2021-12-17 17:06:02,320 iteration 3053 : loss : 0.058304, loss_ce: 0.015271
2021-12-17 17:06:03,721 iteration 3054 : loss : 0.075515, loss_ce: 0.026868
2021-12-17 17:06:05,095 iteration 3055 : loss : 0.077333, loss_ce: 0.020956
2021-12-17 17:06:06,470 iteration 3056 : loss : 0.074067, loss_ce: 0.020269
2021-12-17 17:06:08,038 iteration 3057 : loss : 0.084165, loss_ce: 0.026197
2021-12-17 17:06:09,437 iteration 3058 : loss : 0.075282, loss_ce: 0.024718
2021-12-17 17:06:10,840 iteration 3059 : loss : 0.066518, loss_ce: 0.025979
2021-12-17 17:06:10,841 Training Data Eval:
2021-12-17 17:06:18,314   Average segmentation loss on training set: 0.0562
2021-12-17 17:06:18,314 Validation Data Eval:
2021-12-17 17:06:20,897   Average segmentation loss on validation set: 0.1303
2021-12-17 17:06:22,392 iteration 3060 : loss : 0.075868, loss_ce: 0.023522
 45%|████████████▏              | 180/400 [1:22:34<1:43:42, 28.29s/it]2021-12-17 17:06:23,901 iteration 3061 : loss : 0.076180, loss_ce: 0.017851
2021-12-17 17:06:25,381 iteration 3062 : loss : 0.105344, loss_ce: 0.038572
2021-12-17 17:06:26,796 iteration 3063 : loss : 0.080335, loss_ce: 0.025056
2021-12-17 17:06:28,234 iteration 3064 : loss : 0.100346, loss_ce: 0.049636
2021-12-17 17:06:29,712 iteration 3065 : loss : 0.076896, loss_ce: 0.019022
2021-12-17 17:06:31,123 iteration 3066 : loss : 0.065186, loss_ce: 0.014796
2021-12-17 17:06:32,627 iteration 3067 : loss : 0.077212, loss_ce: 0.027121
2021-12-17 17:06:34,133 iteration 3068 : loss : 0.072650, loss_ce: 0.020363
2021-12-17 17:06:35,527 iteration 3069 : loss : 0.053088, loss_ce: 0.013181
2021-12-17 17:06:36,992 iteration 3070 : loss : 0.074114, loss_ce: 0.023661
2021-12-17 17:06:38,565 iteration 3071 : loss : 0.089789, loss_ce: 0.027131
2021-12-17 17:06:39,976 iteration 3072 : loss : 0.064505, loss_ce: 0.019334
2021-12-17 17:06:41,393 iteration 3073 : loss : 0.074274, loss_ce: 0.020961
2021-12-17 17:06:42,814 iteration 3074 : loss : 0.094330, loss_ce: 0.034687
2021-12-17 17:06:44,261 iteration 3075 : loss : 0.098311, loss_ce: 0.031366
2021-12-17 17:06:45,638 iteration 3076 : loss : 0.060712, loss_ce: 0.017237
2021-12-17 17:06:47,158 iteration 3077 : loss : 0.119400, loss_ce: 0.030534
 45%|████████████▏              | 181/400 [1:22:59<1:39:23, 27.23s/it]2021-12-17 17:06:48,671 iteration 3078 : loss : 0.103269, loss_ce: 0.017632
2021-12-17 17:06:50,091 iteration 3079 : loss : 0.078595, loss_ce: 0.023190
2021-12-17 17:06:51,522 iteration 3080 : loss : 0.073226, loss_ce: 0.019430
2021-12-17 17:06:52,985 iteration 3081 : loss : 0.072194, loss_ce: 0.022806
2021-12-17 17:06:54,428 iteration 3082 : loss : 0.069921, loss_ce: 0.020393
2021-12-17 17:06:55,877 iteration 3083 : loss : 0.086977, loss_ce: 0.026518
2021-12-17 17:06:57,346 iteration 3084 : loss : 0.077645, loss_ce: 0.025218
2021-12-17 17:06:58,726 iteration 3085 : loss : 0.070091, loss_ce: 0.022152
2021-12-17 17:07:00,153 iteration 3086 : loss : 0.073364, loss_ce: 0.028395
2021-12-17 17:07:01,625 iteration 3087 : loss : 0.081167, loss_ce: 0.026142
2021-12-17 17:07:03,046 iteration 3088 : loss : 0.113530, loss_ce: 0.039234
2021-12-17 17:07:04,557 iteration 3089 : loss : 0.095677, loss_ce: 0.028991
2021-12-17 17:07:05,932 iteration 3090 : loss : 0.068462, loss_ce: 0.021366
2021-12-17 17:07:07,409 iteration 3091 : loss : 0.076399, loss_ce: 0.025656
2021-12-17 17:07:08,814 iteration 3092 : loss : 0.086129, loss_ce: 0.030333
2021-12-17 17:07:10,209 iteration 3093 : loss : 0.062122, loss_ce: 0.019353
2021-12-17 17:07:11,647 iteration 3094 : loss : 0.085144, loss_ce: 0.018855
 46%|████████████▎              | 182/400 [1:23:23<1:35:56, 26.41s/it]2021-12-17 17:07:13,162 iteration 3095 : loss : 0.069808, loss_ce: 0.022806
2021-12-17 17:07:14,601 iteration 3096 : loss : 0.075535, loss_ce: 0.023576
2021-12-17 17:07:16,052 iteration 3097 : loss : 0.079572, loss_ce: 0.030409
2021-12-17 17:07:17,528 iteration 3098 : loss : 0.089730, loss_ce: 0.023670
2021-12-17 17:07:19,010 iteration 3099 : loss : 0.078030, loss_ce: 0.027038
2021-12-17 17:07:20,450 iteration 3100 : loss : 0.072515, loss_ce: 0.020190
2021-12-17 17:07:21,848 iteration 3101 : loss : 0.066110, loss_ce: 0.018786
2021-12-17 17:07:23,207 iteration 3102 : loss : 0.066850, loss_ce: 0.021048
2021-12-17 17:07:24,694 iteration 3103 : loss : 0.081636, loss_ce: 0.030933
2021-12-17 17:07:26,129 iteration 3104 : loss : 0.070993, loss_ce: 0.019327
2021-12-17 17:07:27,600 iteration 3105 : loss : 0.073937, loss_ce: 0.024857
2021-12-17 17:07:29,038 iteration 3106 : loss : 0.066708, loss_ce: 0.020205
2021-12-17 17:07:30,526 iteration 3107 : loss : 0.070093, loss_ce: 0.022231
2021-12-17 17:07:31,988 iteration 3108 : loss : 0.101994, loss_ce: 0.032402
2021-12-17 17:07:33,351 iteration 3109 : loss : 0.067190, loss_ce: 0.021768
2021-12-17 17:07:34,763 iteration 3110 : loss : 0.074398, loss_ce: 0.022409
2021-12-17 17:07:36,211 iteration 3111 : loss : 0.095248, loss_ce: 0.019798
 46%|████████████▎              | 183/400 [1:23:48<1:33:30, 25.86s/it]2021-12-17 17:07:37,649 iteration 3112 : loss : 0.065037, loss_ce: 0.019436
2021-12-17 17:07:39,100 iteration 3113 : loss : 0.066380, loss_ce: 0.019448
2021-12-17 17:07:40,496 iteration 3114 : loss : 0.074244, loss_ce: 0.028712
2021-12-17 17:07:41,959 iteration 3115 : loss : 0.069746, loss_ce: 0.021020
2021-12-17 17:07:43,336 iteration 3116 : loss : 0.066901, loss_ce: 0.021045
2021-12-17 17:07:44,850 iteration 3117 : loss : 0.095751, loss_ce: 0.021770
2021-12-17 17:07:46,284 iteration 3118 : loss : 0.073162, loss_ce: 0.027519
2021-12-17 17:07:47,725 iteration 3119 : loss : 0.072668, loss_ce: 0.025909
2021-12-17 17:07:49,103 iteration 3120 : loss : 0.065638, loss_ce: 0.017703
2021-12-17 17:07:50,582 iteration 3121 : loss : 0.103110, loss_ce: 0.030725
2021-12-17 17:07:52,021 iteration 3122 : loss : 0.079245, loss_ce: 0.029708
2021-12-17 17:07:53,572 iteration 3123 : loss : 0.101959, loss_ce: 0.025773
2021-12-17 17:07:54,978 iteration 3124 : loss : 0.067630, loss_ce: 0.019487
2021-12-17 17:07:56,384 iteration 3125 : loss : 0.060864, loss_ce: 0.018997
2021-12-17 17:07:57,786 iteration 3126 : loss : 0.066982, loss_ce: 0.018272
2021-12-17 17:07:59,210 iteration 3127 : loss : 0.073510, loss_ce: 0.024906
2021-12-17 17:08:00,634 iteration 3128 : loss : 0.081627, loss_ce: 0.017482
 46%|████████████▍              | 184/400 [1:24:12<1:31:32, 25.43s/it]2021-12-17 17:08:02,078 iteration 3129 : loss : 0.086847, loss_ce: 0.023234
2021-12-17 17:08:03,476 iteration 3130 : loss : 0.064101, loss_ce: 0.018036
2021-12-17 17:08:04,960 iteration 3131 : loss : 0.092748, loss_ce: 0.034044
2021-12-17 17:08:06,429 iteration 3132 : loss : 0.069176, loss_ce: 0.020430
2021-12-17 17:08:07,836 iteration 3133 : loss : 0.066366, loss_ce: 0.022315
2021-12-17 17:08:09,308 iteration 3134 : loss : 0.075506, loss_ce: 0.027660
2021-12-17 17:08:10,789 iteration 3135 : loss : 0.077937, loss_ce: 0.016728
2021-12-17 17:08:12,170 iteration 3136 : loss : 0.067254, loss_ce: 0.023931
2021-12-17 17:08:13,548 iteration 3137 : loss : 0.062465, loss_ce: 0.020504
2021-12-17 17:08:14,962 iteration 3138 : loss : 0.068923, loss_ce: 0.020986
2021-12-17 17:08:16,519 iteration 3139 : loss : 0.091777, loss_ce: 0.024639
2021-12-17 17:08:17,986 iteration 3140 : loss : 0.068192, loss_ce: 0.020293
2021-12-17 17:08:19,407 iteration 3141 : loss : 0.076946, loss_ce: 0.027836
2021-12-17 17:08:20,792 iteration 3142 : loss : 0.063251, loss_ce: 0.019067
2021-12-17 17:08:22,256 iteration 3143 : loss : 0.089497, loss_ce: 0.023942
2021-12-17 17:08:23,762 iteration 3144 : loss : 0.074905, loss_ce: 0.014289
2021-12-17 17:08:23,762 Training Data Eval:
2021-12-17 17:08:31,198   Average segmentation loss on training set: 0.0570
2021-12-17 17:08:31,198 Validation Data Eval:
2021-12-17 17:08:33,777   Average segmentation loss on validation set: 0.1282
2021-12-17 17:08:35,178 iteration 3145 : loss : 0.064039, loss_ce: 0.021513
 46%|████████████▍              | 185/400 [1:24:47<1:40:54, 28.16s/it]2021-12-17 17:08:36,744 iteration 3146 : loss : 0.087267, loss_ce: 0.028393
2021-12-17 17:08:38,237 iteration 3147 : loss : 0.085580, loss_ce: 0.028843
2021-12-17 17:08:39,625 iteration 3148 : loss : 0.066492, loss_ce: 0.021729
2021-12-17 17:08:41,072 iteration 3149 : loss : 0.082396, loss_ce: 0.020376
2021-12-17 17:08:42,509 iteration 3150 : loss : 0.084215, loss_ce: 0.019617
2021-12-17 17:08:43,868 iteration 3151 : loss : 0.067800, loss_ce: 0.023479
2021-12-17 17:08:45,370 iteration 3152 : loss : 0.074542, loss_ce: 0.027597
2021-12-17 17:08:46,797 iteration 3153 : loss : 0.075769, loss_ce: 0.027035
2021-12-17 17:08:48,253 iteration 3154 : loss : 0.077282, loss_ce: 0.018127
2021-12-17 17:08:49,705 iteration 3155 : loss : 0.069933, loss_ce: 0.020854
2021-12-17 17:08:51,168 iteration 3156 : loss : 0.069542, loss_ce: 0.021935
2021-12-17 17:08:52,537 iteration 3157 : loss : 0.072755, loss_ce: 0.016301
2021-12-17 17:08:54,041 iteration 3158 : loss : 0.076205, loss_ce: 0.024675
2021-12-17 17:08:55,469 iteration 3159 : loss : 0.087585, loss_ce: 0.032824
2021-12-17 17:08:56,888 iteration 3160 : loss : 0.066843, loss_ce: 0.022471
2021-12-17 17:08:58,412 iteration 3161 : loss : 0.095198, loss_ce: 0.035035
2021-12-17 17:08:59,940 iteration 3162 : loss : 0.088554, loss_ce: 0.035620
 46%|████████████▌              | 186/400 [1:25:11<1:36:48, 27.14s/it]2021-12-17 17:09:01,373 iteration 3163 : loss : 0.080868, loss_ce: 0.019717
2021-12-17 17:09:02,764 iteration 3164 : loss : 0.078169, loss_ce: 0.017551
2021-12-17 17:09:04,174 iteration 3165 : loss : 0.060085, loss_ce: 0.018906
2021-12-17 17:09:05,608 iteration 3166 : loss : 0.072553, loss_ce: 0.025515
2021-12-17 17:09:07,070 iteration 3167 : loss : 0.095965, loss_ce: 0.028017
2021-12-17 17:09:08,460 iteration 3168 : loss : 0.064659, loss_ce: 0.021573
2021-12-17 17:09:09,908 iteration 3169 : loss : 0.071992, loss_ce: 0.018505
2021-12-17 17:09:11,364 iteration 3170 : loss : 0.081386, loss_ce: 0.028715
2021-12-17 17:09:12,855 iteration 3171 : loss : 0.085040, loss_ce: 0.022845
2021-12-17 17:09:14,318 iteration 3172 : loss : 0.088788, loss_ce: 0.034178
2021-12-17 17:09:15,774 iteration 3173 : loss : 0.083726, loss_ce: 0.027834
2021-12-17 17:09:17,262 iteration 3174 : loss : 0.086747, loss_ce: 0.032290
2021-12-17 17:09:18,693 iteration 3175 : loss : 0.071981, loss_ce: 0.024068
2021-12-17 17:09:20,158 iteration 3176 : loss : 0.073766, loss_ce: 0.028955
2021-12-17 17:09:21,561 iteration 3177 : loss : 0.080987, loss_ce: 0.032849
2021-12-17 17:09:23,015 iteration 3178 : loss : 0.070595, loss_ce: 0.016657
2021-12-17 17:09:24,493 iteration 3179 : loss : 0.089112, loss_ce: 0.024144
 47%|████████████▌              | 187/400 [1:25:36<1:33:35, 26.37s/it]2021-12-17 17:09:26,035 iteration 3180 : loss : 0.070290, loss_ce: 0.022764
2021-12-17 17:09:27,463 iteration 3181 : loss : 0.080956, loss_ce: 0.027689
2021-12-17 17:09:28,930 iteration 3182 : loss : 0.072417, loss_ce: 0.022081
2021-12-17 17:09:30,407 iteration 3183 : loss : 0.078188, loss_ce: 0.028555
2021-12-17 17:09:31,761 iteration 3184 : loss : 0.068947, loss_ce: 0.022481
2021-12-17 17:09:33,157 iteration 3185 : loss : 0.076967, loss_ce: 0.027113
2021-12-17 17:09:34,566 iteration 3186 : loss : 0.075237, loss_ce: 0.027581
2021-12-17 17:09:35,962 iteration 3187 : loss : 0.066891, loss_ce: 0.019254
2021-12-17 17:09:37,408 iteration 3188 : loss : 0.069015, loss_ce: 0.017058
2021-12-17 17:09:38,786 iteration 3189 : loss : 0.059004, loss_ce: 0.019356
2021-12-17 17:09:40,258 iteration 3190 : loss : 0.096173, loss_ce: 0.030234
2021-12-17 17:09:41,726 iteration 3191 : loss : 0.066211, loss_ce: 0.018140
2021-12-17 17:09:43,162 iteration 3192 : loss : 0.062798, loss_ce: 0.020101
2021-12-17 17:09:44,559 iteration 3193 : loss : 0.066220, loss_ce: 0.021484
2021-12-17 17:09:45,931 iteration 3194 : loss : 0.072738, loss_ce: 0.017867
2021-12-17 17:09:47,358 iteration 3195 : loss : 0.072839, loss_ce: 0.019935
2021-12-17 17:09:48,833 iteration 3196 : loss : 0.063009, loss_ce: 0.013990
 47%|████████████▋              | 188/400 [1:26:00<1:31:00, 25.76s/it]2021-12-17 17:09:50,295 iteration 3197 : loss : 0.068497, loss_ce: 0.018743
2021-12-17 17:09:51,719 iteration 3198 : loss : 0.074791, loss_ce: 0.022258
2021-12-17 17:09:53,089 iteration 3199 : loss : 0.073274, loss_ce: 0.024183
2021-12-17 17:09:54,478 iteration 3200 : loss : 0.068561, loss_ce: 0.021502
2021-12-17 17:09:55,927 iteration 3201 : loss : 0.094977, loss_ce: 0.030424
2021-12-17 17:09:57,376 iteration 3202 : loss : 0.068221, loss_ce: 0.021120
2021-12-17 17:09:58,752 iteration 3203 : loss : 0.085641, loss_ce: 0.014088
2021-12-17 17:10:00,208 iteration 3204 : loss : 0.066200, loss_ce: 0.023678
2021-12-17 17:10:01,663 iteration 3205 : loss : 0.064949, loss_ce: 0.017869
2021-12-17 17:10:03,057 iteration 3206 : loss : 0.074558, loss_ce: 0.024296
2021-12-17 17:10:04,440 iteration 3207 : loss : 0.067241, loss_ce: 0.017249
2021-12-17 17:10:05,841 iteration 3208 : loss : 0.071237, loss_ce: 0.019003
2021-12-17 17:10:07,313 iteration 3209 : loss : 0.065984, loss_ce: 0.020026
2021-12-17 17:10:08,765 iteration 3210 : loss : 0.084123, loss_ce: 0.022088
2021-12-17 17:10:10,247 iteration 3211 : loss : 0.089985, loss_ce: 0.031316
2021-12-17 17:10:11,721 iteration 3212 : loss : 0.065370, loss_ce: 0.021001
2021-12-17 17:10:13,129 iteration 3213 : loss : 0.071543, loss_ce: 0.030509
 47%|████████████▊              | 189/400 [1:26:25<1:29:02, 25.32s/it]2021-12-17 17:10:14,580 iteration 3214 : loss : 0.079524, loss_ce: 0.025584
2021-12-17 17:10:15,970 iteration 3215 : loss : 0.070406, loss_ce: 0.025021
2021-12-17 17:10:17,389 iteration 3216 : loss : 0.080478, loss_ce: 0.026565
2021-12-17 17:10:18,863 iteration 3217 : loss : 0.090431, loss_ce: 0.023368
2021-12-17 17:10:20,253 iteration 3218 : loss : 0.065234, loss_ce: 0.022057
2021-12-17 17:10:21,654 iteration 3219 : loss : 0.068372, loss_ce: 0.018304
2021-12-17 17:10:23,106 iteration 3220 : loss : 0.083518, loss_ce: 0.034103
2021-12-17 17:10:24,566 iteration 3221 : loss : 0.071560, loss_ce: 0.020082
2021-12-17 17:10:25,948 iteration 3222 : loss : 0.059005, loss_ce: 0.017055
2021-12-17 17:10:27,402 iteration 3223 : loss : 0.083813, loss_ce: 0.017856
2021-12-17 17:10:28,830 iteration 3224 : loss : 0.071532, loss_ce: 0.021906
2021-12-17 17:10:30,196 iteration 3225 : loss : 0.063582, loss_ce: 0.018169
2021-12-17 17:10:31,623 iteration 3226 : loss : 0.067094, loss_ce: 0.023976
2021-12-17 17:10:33,059 iteration 3227 : loss : 0.067662, loss_ce: 0.019625
2021-12-17 17:10:34,489 iteration 3228 : loss : 0.089768, loss_ce: 0.032196
2021-12-17 17:10:35,949 iteration 3229 : loss : 0.078930, loss_ce: 0.020475
2021-12-17 17:10:35,949 Training Data Eval:
2021-12-17 17:10:43,407   Average segmentation loss on training set: 0.0564
2021-12-17 17:10:43,408 Validation Data Eval:
2021-12-17 17:10:45,995   Average segmentation loss on validation set: 0.1284
2021-12-17 17:10:47,410 iteration 3230 : loss : 0.073025, loss_ce: 0.027341
 48%|████████████▊              | 190/400 [1:26:59<1:38:01, 28.01s/it]2021-12-17 17:10:48,784 iteration 3231 : loss : 0.063000, loss_ce: 0.018118
2021-12-17 17:10:50,230 iteration 3232 : loss : 0.063085, loss_ce: 0.021529
2021-12-17 17:10:51,678 iteration 3233 : loss : 0.075281, loss_ce: 0.020572
2021-12-17 17:10:53,084 iteration 3234 : loss : 0.070997, loss_ce: 0.021732
2021-12-17 17:10:54,527 iteration 3235 : loss : 0.068279, loss_ce: 0.022046
2021-12-17 17:10:55,864 iteration 3236 : loss : 0.065611, loss_ce: 0.022644
2021-12-17 17:10:57,290 iteration 3237 : loss : 0.066385, loss_ce: 0.020854
2021-12-17 17:10:58,725 iteration 3238 : loss : 0.089908, loss_ce: 0.030449
2021-12-17 17:11:00,067 iteration 3239 : loss : 0.070635, loss_ce: 0.025234
2021-12-17 17:11:01,518 iteration 3240 : loss : 0.099990, loss_ce: 0.037930
2021-12-17 17:11:03,032 iteration 3241 : loss : 0.091247, loss_ce: 0.021179
2021-12-17 17:11:04,524 iteration 3242 : loss : 0.074157, loss_ce: 0.021097
2021-12-17 17:11:05,993 iteration 3243 : loss : 0.077198, loss_ce: 0.027166
2021-12-17 17:11:07,381 iteration 3244 : loss : 0.076958, loss_ce: 0.022422
2021-12-17 17:11:08,822 iteration 3245 : loss : 0.081410, loss_ce: 0.023590
2021-12-17 17:11:10,287 iteration 3246 : loss : 0.077285, loss_ce: 0.021835
2021-12-17 17:11:11,814 iteration 3247 : loss : 0.104730, loss_ce: 0.036606
 48%|████████████▉              | 191/400 [1:27:23<1:33:47, 26.93s/it]2021-12-17 17:11:13,339 iteration 3248 : loss : 0.089382, loss_ce: 0.020997
2021-12-17 17:11:14,810 iteration 3249 : loss : 0.072617, loss_ce: 0.020092
2021-12-17 17:11:16,242 iteration 3250 : loss : 0.077398, loss_ce: 0.020828
2021-12-17 17:11:17,685 iteration 3251 : loss : 0.068921, loss_ce: 0.018491
2021-12-17 17:11:19,023 iteration 3252 : loss : 0.060685, loss_ce: 0.022308
2021-12-17 17:11:20,434 iteration 3253 : loss : 0.076909, loss_ce: 0.021201
2021-12-17 17:11:21,897 iteration 3254 : loss : 0.087497, loss_ce: 0.033546
2021-12-17 17:11:23,332 iteration 3255 : loss : 0.069534, loss_ce: 0.019199
2021-12-17 17:11:24,799 iteration 3256 : loss : 0.069987, loss_ce: 0.021878
2021-12-17 17:11:26,247 iteration 3257 : loss : 0.077113, loss_ce: 0.024028
2021-12-17 17:11:27,624 iteration 3258 : loss : 0.064080, loss_ce: 0.014304
2021-12-17 17:11:29,070 iteration 3259 : loss : 0.090635, loss_ce: 0.028257
2021-12-17 17:11:30,524 iteration 3260 : loss : 0.067487, loss_ce: 0.021764
2021-12-17 17:11:31,955 iteration 3261 : loss : 0.076650, loss_ce: 0.023289
2021-12-17 17:11:33,471 iteration 3262 : loss : 0.091004, loss_ce: 0.034191
2021-12-17 17:11:34,875 iteration 3263 : loss : 0.071033, loss_ce: 0.021184
2021-12-17 17:11:36,368 iteration 3264 : loss : 0.076636, loss_ce: 0.020733
 48%|████████████▉              | 192/400 [1:27:48<1:30:52, 26.21s/it]2021-12-17 17:11:37,805 iteration 3265 : loss : 0.077836, loss_ce: 0.024592
2021-12-17 17:11:39,267 iteration 3266 : loss : 0.067160, loss_ce: 0.020324
2021-12-17 17:11:40,711 iteration 3267 : loss : 0.064275, loss_ce: 0.016660
2021-12-17 17:11:42,156 iteration 3268 : loss : 0.072890, loss_ce: 0.020495
2021-12-17 17:11:43,545 iteration 3269 : loss : 0.075569, loss_ce: 0.030546
2021-12-17 17:11:44,980 iteration 3270 : loss : 0.074962, loss_ce: 0.024192
2021-12-17 17:11:46,337 iteration 3271 : loss : 0.071761, loss_ce: 0.018422
2021-12-17 17:11:47,841 iteration 3272 : loss : 0.090927, loss_ce: 0.030789
2021-12-17 17:11:49,267 iteration 3273 : loss : 0.079310, loss_ce: 0.027179
2021-12-17 17:11:50,625 iteration 3274 : loss : 0.070445, loss_ce: 0.020974
2021-12-17 17:11:52,042 iteration 3275 : loss : 0.080578, loss_ce: 0.024125
2021-12-17 17:11:53,462 iteration 3276 : loss : 0.064153, loss_ce: 0.014886
2021-12-17 17:11:54,846 iteration 3277 : loss : 0.062194, loss_ce: 0.016909
2021-12-17 17:11:56,281 iteration 3278 : loss : 0.070383, loss_ce: 0.022032
2021-12-17 17:11:57,625 iteration 3279 : loss : 0.076694, loss_ce: 0.033145
2021-12-17 17:11:59,115 iteration 3280 : loss : 0.082636, loss_ce: 0.028142
2021-12-17 17:12:00,541 iteration 3281 : loss : 0.060131, loss_ce: 0.014523
 48%|█████████████              | 193/400 [1:28:12<1:28:19, 25.60s/it]2021-12-17 17:12:02,034 iteration 3282 : loss : 0.073606, loss_ce: 0.015036
2021-12-17 17:12:03,484 iteration 3283 : loss : 0.080449, loss_ce: 0.023338
2021-12-17 17:12:04,957 iteration 3284 : loss : 0.110833, loss_ce: 0.039109
2021-12-17 17:12:06,414 iteration 3285 : loss : 0.104008, loss_ce: 0.029725
2021-12-17 17:12:07,832 iteration 3286 : loss : 0.077788, loss_ce: 0.019797
2021-12-17 17:12:09,347 iteration 3287 : loss : 0.089567, loss_ce: 0.031617
2021-12-17 17:12:10,725 iteration 3288 : loss : 0.073983, loss_ce: 0.025978
2021-12-17 17:12:12,260 iteration 3289 : loss : 0.079224, loss_ce: 0.027740
2021-12-17 17:12:13,750 iteration 3290 : loss : 0.080014, loss_ce: 0.021965
2021-12-17 17:12:15,246 iteration 3291 : loss : 0.089413, loss_ce: 0.034838
2021-12-17 17:12:16,662 iteration 3292 : loss : 0.076483, loss_ce: 0.022481
2021-12-17 17:12:18,075 iteration 3293 : loss : 0.089738, loss_ce: 0.021908
2021-12-17 17:12:19,602 iteration 3294 : loss : 0.077415, loss_ce: 0.029919
2021-12-17 17:12:21,077 iteration 3295 : loss : 0.067660, loss_ce: 0.022640
2021-12-17 17:12:22,460 iteration 3296 : loss : 0.070885, loss_ce: 0.020551
2021-12-17 17:12:23,875 iteration 3297 : loss : 0.067384, loss_ce: 0.021235
2021-12-17 17:12:25,449 iteration 3298 : loss : 0.062411, loss_ce: 0.021032
 48%|█████████████              | 194/400 [1:28:37<1:27:11, 25.39s/it]2021-12-17 17:12:26,842 iteration 3299 : loss : 0.063199, loss_ce: 0.013943
2021-12-17 17:12:28,306 iteration 3300 : loss : 0.066902, loss_ce: 0.018710
2021-12-17 17:12:29,737 iteration 3301 : loss : 0.066716, loss_ce: 0.025369
2021-12-17 17:12:31,140 iteration 3302 : loss : 0.079385, loss_ce: 0.020358
2021-12-17 17:12:32,629 iteration 3303 : loss : 0.083547, loss_ce: 0.033540
2021-12-17 17:12:34,095 iteration 3304 : loss : 0.087976, loss_ce: 0.030500
2021-12-17 17:12:35,512 iteration 3305 : loss : 0.078411, loss_ce: 0.025475
2021-12-17 17:12:36,934 iteration 3306 : loss : 0.074701, loss_ce: 0.017839
2021-12-17 17:12:38,469 iteration 3307 : loss : 0.115843, loss_ce: 0.049043
2021-12-17 17:12:39,957 iteration 3308 : loss : 0.074813, loss_ce: 0.025401
2021-12-17 17:12:41,436 iteration 3309 : loss : 0.072369, loss_ce: 0.028382
2021-12-17 17:12:42,817 iteration 3310 : loss : 0.065888, loss_ce: 0.028022
2021-12-17 17:12:44,321 iteration 3311 : loss : 0.087094, loss_ce: 0.025884
2021-12-17 17:12:45,752 iteration 3312 : loss : 0.074403, loss_ce: 0.017948
2021-12-17 17:12:47,257 iteration 3313 : loss : 0.081166, loss_ce: 0.027156
2021-12-17 17:12:48,689 iteration 3314 : loss : 0.091924, loss_ce: 0.023844
2021-12-17 17:12:48,690 Training Data Eval:
2021-12-17 17:12:56,115   Average segmentation loss on training set: 0.0535
2021-12-17 17:12:56,116 Validation Data Eval:
2021-12-17 17:12:58,708   Average segmentation loss on validation set: 0.1251
2021-12-17 17:13:05,087 Found new lowest validation loss at iteration 3314! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/TU_3seeds/TU_RESNET_no_pretraining_SGD_best_val_loss_seed2.pth
2021-12-17 17:13:06,401 iteration 3315 : loss : 0.061314, loss_ce: 0.018888
 49%|█████████████▏             | 195/400 [1:29:18<1:42:42, 30.06s/it]2021-12-17 17:13:07,751 iteration 3316 : loss : 0.067851, loss_ce: 0.023665
2021-12-17 17:13:09,119 iteration 3317 : loss : 0.072458, loss_ce: 0.025553
2021-12-17 17:13:10,464 iteration 3318 : loss : 0.078541, loss_ce: 0.028258
2021-12-17 17:13:11,771 iteration 3319 : loss : 0.069823, loss_ce: 0.022665
2021-12-17 17:13:13,224 iteration 3320 : loss : 0.095232, loss_ce: 0.033803
2021-12-17 17:13:14,558 iteration 3321 : loss : 0.076478, loss_ce: 0.024026
2021-12-17 17:13:15,983 iteration 3322 : loss : 0.084567, loss_ce: 0.020593
2021-12-17 17:13:17,296 iteration 3323 : loss : 0.064776, loss_ce: 0.017933
2021-12-17 17:13:18,654 iteration 3324 : loss : 0.070908, loss_ce: 0.025625
2021-12-17 17:13:20,050 iteration 3325 : loss : 0.081079, loss_ce: 0.024944
2021-12-17 17:13:21,379 iteration 3326 : loss : 0.090037, loss_ce: 0.028277
2021-12-17 17:13:22,744 iteration 3327 : loss : 0.064965, loss_ce: 0.017524
2021-12-17 17:13:24,220 iteration 3328 : loss : 0.068346, loss_ce: 0.019803
2021-12-17 17:13:25,670 iteration 3329 : loss : 0.074916, loss_ce: 0.024706
2021-12-17 17:13:27,110 iteration 3330 : loss : 0.068814, loss_ce: 0.026307
2021-12-17 17:13:28,498 iteration 3331 : loss : 0.064273, loss_ce: 0.022137
2021-12-17 17:13:29,971 iteration 3332 : loss : 0.087724, loss_ce: 0.025325
 49%|█████████████▏             | 196/400 [1:29:41<1:35:35, 28.11s/it]2021-12-17 17:13:31,497 iteration 3333 : loss : 0.083225, loss_ce: 0.024291
2021-12-17 17:13:32,981 iteration 3334 : loss : 0.078904, loss_ce: 0.033472
2021-12-17 17:13:34,527 iteration 3335 : loss : 0.080685, loss_ce: 0.028932
2021-12-17 17:13:35,984 iteration 3336 : loss : 0.081004, loss_ce: 0.021522
2021-12-17 17:13:37,477 iteration 3337 : loss : 0.077299, loss_ce: 0.023251
2021-12-17 17:13:39,022 iteration 3338 : loss : 0.087528, loss_ce: 0.030419
2021-12-17 17:13:40,401 iteration 3339 : loss : 0.069211, loss_ce: 0.023000
2021-12-17 17:13:41,784 iteration 3340 : loss : 0.064827, loss_ce: 0.012839
2021-12-17 17:13:43,249 iteration 3341 : loss : 0.075954, loss_ce: 0.023451
2021-12-17 17:13:44,691 iteration 3342 : loss : 0.064201, loss_ce: 0.021588
2021-12-17 17:13:46,171 iteration 3343 : loss : 0.064929, loss_ce: 0.023490
2021-12-17 17:13:47,621 iteration 3344 : loss : 0.073006, loss_ce: 0.021677
2021-12-17 17:13:49,087 iteration 3345 : loss : 0.068679, loss_ce: 0.024035
2021-12-17 17:13:50,498 iteration 3346 : loss : 0.076957, loss_ce: 0.027712
2021-12-17 17:13:51,907 iteration 3347 : loss : 0.068965, loss_ce: 0.020547
2021-12-17 17:13:53,296 iteration 3348 : loss : 0.072783, loss_ce: 0.026152
2021-12-17 17:13:54,813 iteration 3349 : loss : 0.094149, loss_ce: 0.024254
 49%|█████████████▎             | 197/400 [1:30:06<1:31:47, 27.13s/it]2021-12-17 17:13:56,299 iteration 3350 : loss : 0.082265, loss_ce: 0.026078
2021-12-17 17:13:57,790 iteration 3351 : loss : 0.084184, loss_ce: 0.024646
2021-12-17 17:13:59,266 iteration 3352 : loss : 0.078213, loss_ce: 0.025904
2021-12-17 17:14:00,790 iteration 3353 : loss : 0.063746, loss_ce: 0.015836
2021-12-17 17:14:02,210 iteration 3354 : loss : 0.065778, loss_ce: 0.021966
2021-12-17 17:14:03,729 iteration 3355 : loss : 0.083062, loss_ce: 0.028030
2021-12-17 17:14:05,228 iteration 3356 : loss : 0.064661, loss_ce: 0.019545
2021-12-17 17:14:06,654 iteration 3357 : loss : 0.076330, loss_ce: 0.018389
2021-12-17 17:14:08,146 iteration 3358 : loss : 0.075276, loss_ce: 0.023373
2021-12-17 17:14:09,531 iteration 3359 : loss : 0.063919, loss_ce: 0.016915
2021-12-17 17:14:10,953 iteration 3360 : loss : 0.077331, loss_ce: 0.025361
2021-12-17 17:14:12,390 iteration 3361 : loss : 0.073108, loss_ce: 0.021851
2021-12-17 17:14:13,824 iteration 3362 : loss : 0.072112, loss_ce: 0.020628
2021-12-17 17:14:15,353 iteration 3363 : loss : 0.087108, loss_ce: 0.023097
2021-12-17 17:14:16,750 iteration 3364 : loss : 0.064986, loss_ce: 0.022118
2021-12-17 17:14:18,232 iteration 3365 : loss : 0.089586, loss_ce: 0.029282
2021-12-17 17:14:19,611 iteration 3366 : loss : 0.062176, loss_ce: 0.020695
 50%|█████████████▎             | 198/400 [1:30:31<1:28:59, 26.43s/it]2021-12-17 17:14:21,096 iteration 3367 : loss : 0.074191, loss_ce: 0.022309
2021-12-17 17:14:22,515 iteration 3368 : loss : 0.058354, loss_ce: 0.020188
2021-12-17 17:14:23,902 iteration 3369 : loss : 0.064259, loss_ce: 0.016561
2021-12-17 17:14:25,406 iteration 3370 : loss : 0.081419, loss_ce: 0.031520
2021-12-17 17:14:26,955 iteration 3371 : loss : 0.091996, loss_ce: 0.029202
2021-12-17 17:14:28,406 iteration 3372 : loss : 0.057168, loss_ce: 0.017848
2021-12-17 17:14:29,867 iteration 3373 : loss : 0.060412, loss_ce: 0.018012
2021-12-17 17:14:31,268 iteration 3374 : loss : 0.062873, loss_ce: 0.017088
2021-12-17 17:14:32,667 iteration 3375 : loss : 0.068364, loss_ce: 0.020121
2021-12-17 17:14:34,121 iteration 3376 : loss : 0.071795, loss_ce: 0.019684
2021-12-17 17:14:35,478 iteration 3377 : loss : 0.056617, loss_ce: 0.018759
2021-12-17 17:14:36,950 iteration 3378 : loss : 0.092592, loss_ce: 0.020243
2021-12-17 17:14:38,496 iteration 3379 : loss : 0.102357, loss_ce: 0.035126
2021-12-17 17:14:39,987 iteration 3380 : loss : 0.080839, loss_ce: 0.023942
2021-12-17 17:14:41,454 iteration 3381 : loss : 0.080629, loss_ce: 0.022875
2021-12-17 17:14:42,897 iteration 3382 : loss : 0.070965, loss_ce: 0.021734
2021-12-17 17:14:44,298 iteration 3383 : loss : 0.062692, loss_ce: 0.018374
 50%|█████████████▍             | 199/400 [1:30:56<1:26:47, 25.91s/it]2021-12-17 17:14:45,837 iteration 3384 : loss : 0.076845, loss_ce: 0.023598
2021-12-17 17:14:47,329 iteration 3385 : loss : 0.078762, loss_ce: 0.022488
2021-12-17 17:14:48,738 iteration 3386 : loss : 0.062876, loss_ce: 0.016937
2021-12-17 17:14:50,258 iteration 3387 : loss : 0.070845, loss_ce: 0.022374
2021-12-17 17:14:51,726 iteration 3388 : loss : 0.077137, loss_ce: 0.028427
2021-12-17 17:14:53,132 iteration 3389 : loss : 0.055003, loss_ce: 0.017421
2021-12-17 17:14:54,470 iteration 3390 : loss : 0.054345, loss_ce: 0.016090
2021-12-17 17:14:55,968 iteration 3391 : loss : 0.078580, loss_ce: 0.024640
2021-12-17 17:14:57,448 iteration 3392 : loss : 0.076864, loss_ce: 0.019294
2021-12-17 17:14:58,914 iteration 3393 : loss : 0.069164, loss_ce: 0.023863
2021-12-17 17:15:00,400 iteration 3394 : loss : 0.066020, loss_ce: 0.019630
2021-12-17 17:15:01,771 iteration 3395 : loss : 0.064472, loss_ce: 0.020982
2021-12-17 17:15:03,275 iteration 3396 : loss : 0.078738, loss_ce: 0.020084
2021-12-17 17:15:04,742 iteration 3397 : loss : 0.069650, loss_ce: 0.023185
2021-12-17 17:15:06,202 iteration 3398 : loss : 0.074623, loss_ce: 0.026481
2021-12-17 17:15:07,617 iteration 3399 : loss : 0.067355, loss_ce: 0.020046
2021-12-17 17:15:07,617 Training Data Eval:
2021-12-17 17:15:15,110   Average segmentation loss on training set: 0.0529
2021-12-17 17:15:15,111 Validation Data Eval:
2021-12-17 17:15:17,701   Average segmentation loss on validation set: 0.1350
2021-12-17 17:15:19,089 iteration 3400 : loss : 0.063821, loss_ce: 0.017129
 50%|█████████████▌             | 200/400 [1:31:31<1:35:14, 28.57s/it]2021-12-17 17:15:20,604 iteration 3401 : loss : 0.085408, loss_ce: 0.034410
2021-12-17 17:15:21,985 iteration 3402 : loss : 0.063805, loss_ce: 0.020305
2021-12-17 17:15:23,510 iteration 3403 : loss : 0.086029, loss_ce: 0.026752
2021-12-17 17:15:25,008 iteration 3404 : loss : 0.086839, loss_ce: 0.026141
2021-12-17 17:15:26,394 iteration 3405 : loss : 0.077760, loss_ce: 0.019595
2021-12-17 17:15:27,905 iteration 3406 : loss : 0.074025, loss_ce: 0.027504
2021-12-17 17:15:29,327 iteration 3407 : loss : 0.071148, loss_ce: 0.023754
2021-12-17 17:15:30,693 iteration 3408 : loss : 0.067803, loss_ce: 0.021024
2021-12-17 17:15:32,152 iteration 3409 : loss : 0.062928, loss_ce: 0.018402
2021-12-17 17:15:33,629 iteration 3410 : loss : 0.074907, loss_ce: 0.028021
2021-12-17 17:15:35,124 iteration 3411 : loss : 0.086747, loss_ce: 0.028871
2021-12-17 17:15:36,589 iteration 3412 : loss : 0.069723, loss_ce: 0.023652
2021-12-17 17:15:38,034 iteration 3413 : loss : 0.068481, loss_ce: 0.013748
2021-12-17 17:15:39,541 iteration 3414 : loss : 0.078792, loss_ce: 0.025501
2021-12-17 17:15:41,001 iteration 3415 : loss : 0.063878, loss_ce: 0.022212
2021-12-17 17:15:42,527 iteration 3416 : loss : 0.068552, loss_ce: 0.019182
2021-12-17 17:15:44,026 iteration 3417 : loss : 0.070654, loss_ce: 0.018087
 50%|█████████████▌             | 201/400 [1:31:55<1:31:08, 27.48s/it]2021-12-17 17:15:45,459 iteration 3418 : loss : 0.061089, loss_ce: 0.015947
2021-12-17 17:15:46,811 iteration 3419 : loss : 0.066783, loss_ce: 0.023493
2021-12-17 17:15:48,217 iteration 3420 : loss : 0.065557, loss_ce: 0.019787
2021-12-17 17:15:49,610 iteration 3421 : loss : 0.059329, loss_ce: 0.019194
2021-12-17 17:15:50,996 iteration 3422 : loss : 0.060903, loss_ce: 0.017794
2021-12-17 17:15:52,472 iteration 3423 : loss : 0.080895, loss_ce: 0.033124
2021-12-17 17:15:53,923 iteration 3424 : loss : 0.069972, loss_ce: 0.022236
2021-12-17 17:15:55,390 iteration 3425 : loss : 0.070312, loss_ce: 0.023491
2021-12-17 17:15:56,740 iteration 3426 : loss : 0.064152, loss_ce: 0.018035
2021-12-17 17:15:58,197 iteration 3427 : loss : 0.074340, loss_ce: 0.019397
2021-12-17 17:15:59,665 iteration 3428 : loss : 0.095536, loss_ce: 0.033574
2021-12-17 17:16:01,067 iteration 3429 : loss : 0.064697, loss_ce: 0.018538
2021-12-17 17:16:02,534 iteration 3430 : loss : 0.067916, loss_ce: 0.021041
2021-12-17 17:16:03,983 iteration 3431 : loss : 0.077846, loss_ce: 0.023339
2021-12-17 17:16:05,495 iteration 3432 : loss : 0.074352, loss_ce: 0.026019
2021-12-17 17:16:06,992 iteration 3433 : loss : 0.094045, loss_ce: 0.026064
2021-12-17 17:16:08,438 iteration 3434 : loss : 0.072351, loss_ce: 0.018954
 50%|█████████████▋             | 202/400 [1:32:20<1:27:39, 26.56s/it]2021-12-17 17:16:09,914 iteration 3435 : loss : 0.062167, loss_ce: 0.018355
2021-12-17 17:16:11,418 iteration 3436 : loss : 0.075720, loss_ce: 0.024935
2021-12-17 17:16:12,920 iteration 3437 : loss : 0.077011, loss_ce: 0.021846
2021-12-17 17:16:14,422 iteration 3438 : loss : 0.104468, loss_ce: 0.032198
2021-12-17 17:16:15,814 iteration 3439 : loss : 0.066186, loss_ce: 0.019912
2021-12-17 17:16:17,283 iteration 3440 : loss : 0.071173, loss_ce: 0.023146
2021-12-17 17:16:18,699 iteration 3441 : loss : 0.077209, loss_ce: 0.021072
2021-12-17 17:16:20,151 iteration 3442 : loss : 0.066774, loss_ce: 0.021421
2021-12-17 17:16:21,683 iteration 3443 : loss : 0.072145, loss_ce: 0.023178
2021-12-17 17:16:23,097 iteration 3444 : loss : 0.069246, loss_ce: 0.019116
2021-12-17 17:16:24,561 iteration 3445 : loss : 0.079338, loss_ce: 0.028157
2021-12-17 17:16:26,059 iteration 3446 : loss : 0.078384, loss_ce: 0.028313
2021-12-17 17:16:27,537 iteration 3447 : loss : 0.095682, loss_ce: 0.025563
2021-12-17 17:16:28,912 iteration 3448 : loss : 0.070529, loss_ce: 0.022642
2021-12-17 17:16:30,320 iteration 3449 : loss : 0.063617, loss_ce: 0.021782
2021-12-17 17:16:31,758 iteration 3450 : loss : 0.067092, loss_ce: 0.016930
2021-12-17 17:16:33,190 iteration 3451 : loss : 0.057211, loss_ce: 0.022158
 51%|█████████████▋             | 203/400 [1:32:45<1:25:26, 26.02s/it]2021-12-17 17:16:34,589 iteration 3452 : loss : 0.063480, loss_ce: 0.020396
2021-12-17 17:16:36,078 iteration 3453 : loss : 0.073682, loss_ce: 0.022299
2021-12-17 17:16:37,662 iteration 3454 : loss : 0.074763, loss_ce: 0.025388
2021-12-17 17:16:39,082 iteration 3455 : loss : 0.074649, loss_ce: 0.027503
2021-12-17 17:16:40,543 iteration 3456 : loss : 0.080146, loss_ce: 0.021212
2021-12-17 17:16:41,944 iteration 3457 : loss : 0.071602, loss_ce: 0.023961
2021-12-17 17:16:43,333 iteration 3458 : loss : 0.067262, loss_ce: 0.016321
2021-12-17 17:16:44,819 iteration 3459 : loss : 0.067879, loss_ce: 0.022396
2021-12-17 17:16:46,200 iteration 3460 : loss : 0.062392, loss_ce: 0.020894
2021-12-17 17:16:47,579 iteration 3461 : loss : 0.057499, loss_ce: 0.016167
2021-12-17 17:16:48,914 iteration 3462 : loss : 0.056428, loss_ce: 0.019598
2021-12-17 17:16:50,403 iteration 3463 : loss : 0.064042, loss_ce: 0.020934
2021-12-17 17:16:51,853 iteration 3464 : loss : 0.064171, loss_ce: 0.017856
2021-12-17 17:16:53,266 iteration 3465 : loss : 0.061255, loss_ce: 0.018328
2021-12-17 17:16:54,800 iteration 3466 : loss : 0.085024, loss_ce: 0.032206
2021-12-17 17:16:56,160 iteration 3467 : loss : 0.056693, loss_ce: 0.015026
2021-12-17 17:16:57,579 iteration 3468 : loss : 0.065548, loss_ce: 0.016029
 51%|█████████████▊             | 204/400 [1:33:09<1:23:23, 25.53s/it]2021-12-17 17:16:59,030 iteration 3469 : loss : 0.064574, loss_ce: 0.018062
2021-12-17 17:17:00,451 iteration 3470 : loss : 0.070547, loss_ce: 0.020132
2021-12-17 17:17:01,946 iteration 3471 : loss : 0.086881, loss_ce: 0.033069
2021-12-17 17:17:03,457 iteration 3472 : loss : 0.067769, loss_ce: 0.020439
2021-12-17 17:17:04,857 iteration 3473 : loss : 0.061604, loss_ce: 0.021189
2021-12-17 17:17:06,338 iteration 3474 : loss : 0.068311, loss_ce: 0.019163
2021-12-17 17:17:07,781 iteration 3475 : loss : 0.062122, loss_ce: 0.019570
2021-12-17 17:17:09,186 iteration 3476 : loss : 0.077804, loss_ce: 0.021474
2021-12-17 17:17:10,620 iteration 3477 : loss : 0.062545, loss_ce: 0.017564
2021-12-17 17:17:12,081 iteration 3478 : loss : 0.065828, loss_ce: 0.023214
2021-12-17 17:17:13,512 iteration 3479 : loss : 0.063879, loss_ce: 0.021810
2021-12-17 17:17:14,901 iteration 3480 : loss : 0.060995, loss_ce: 0.022660
2021-12-17 17:17:16,301 iteration 3481 : loss : 0.075886, loss_ce: 0.019169
2021-12-17 17:17:17,732 iteration 3482 : loss : 0.062468, loss_ce: 0.018503
2021-12-17 17:17:19,239 iteration 3483 : loss : 0.068410, loss_ce: 0.022838
2021-12-17 17:17:20,707 iteration 3484 : loss : 0.062985, loss_ce: 0.016346
2021-12-17 17:17:20,707 Training Data Eval:
2021-12-17 17:17:28,189   Average segmentation loss on training set: 0.0522
2021-12-17 17:17:28,189 Validation Data Eval:
2021-12-17 17:17:30,786   Average segmentation loss on validation set: 0.1317
2021-12-17 17:17:32,222 iteration 3485 : loss : 0.066910, loss_ce: 0.022944
 51%|█████████████▊             | 205/400 [1:33:44<1:31:51, 28.26s/it]2021-12-17 17:17:33,716 iteration 3486 : loss : 0.084375, loss_ce: 0.020893
2021-12-17 17:17:35,145 iteration 3487 : loss : 0.063882, loss_ce: 0.019942
2021-12-17 17:17:36,575 iteration 3488 : loss : 0.068982, loss_ce: 0.016779
2021-12-17 17:17:37,910 iteration 3489 : loss : 0.064089, loss_ce: 0.021096
2021-12-17 17:17:39,399 iteration 3490 : loss : 0.073265, loss_ce: 0.023401
2021-12-17 17:17:40,941 iteration 3491 : loss : 0.080435, loss_ce: 0.033921
2021-12-17 17:17:42,390 iteration 3492 : loss : 0.058494, loss_ce: 0.013401
2021-12-17 17:17:43,813 iteration 3493 : loss : 0.078389, loss_ce: 0.021806
2021-12-17 17:17:45,268 iteration 3494 : loss : 0.064171, loss_ce: 0.017627
2021-12-17 17:17:46,738 iteration 3495 : loss : 0.067380, loss_ce: 0.019114
2021-12-17 17:17:48,287 iteration 3496 : loss : 0.095460, loss_ce: 0.032829
2021-12-17 17:17:49,719 iteration 3497 : loss : 0.065533, loss_ce: 0.022840
2021-12-17 17:17:51,206 iteration 3498 : loss : 0.065185, loss_ce: 0.023289
2021-12-17 17:17:52,626 iteration 3499 : loss : 0.068491, loss_ce: 0.028466
2021-12-17 17:17:54,079 iteration 3500 : loss : 0.069171, loss_ce: 0.021102
2021-12-17 17:17:55,589 iteration 3501 : loss : 0.070301, loss_ce: 0.020314
2021-12-17 17:17:57,007 iteration 3502 : loss : 0.083485, loss_ce: 0.038272
 52%|█████████████▉             | 206/400 [1:34:08<1:28:00, 27.22s/it]2021-12-17 17:17:58,507 iteration 3503 : loss : 0.079220, loss_ce: 0.019201
2021-12-17 17:17:59,946 iteration 3504 : loss : 0.059386, loss_ce: 0.016883
2021-12-17 17:18:01,386 iteration 3505 : loss : 0.059814, loss_ce: 0.019543
2021-12-17 17:18:02,870 iteration 3506 : loss : 0.080147, loss_ce: 0.020141
2021-12-17 17:18:04,258 iteration 3507 : loss : 0.056543, loss_ce: 0.016440
2021-12-17 17:18:05,686 iteration 3508 : loss : 0.080192, loss_ce: 0.018851
2021-12-17 17:18:07,167 iteration 3509 : loss : 0.080417, loss_ce: 0.028621
2021-12-17 17:18:08,605 iteration 3510 : loss : 0.063966, loss_ce: 0.021350
2021-12-17 17:18:10,274 iteration 3511 : loss : 0.085155, loss_ce: 0.030793
2021-12-17 17:18:11,659 iteration 3512 : loss : 0.056036, loss_ce: 0.016124
2021-12-17 17:18:13,024 iteration 3513 : loss : 0.068111, loss_ce: 0.022412
2021-12-17 17:18:14,464 iteration 3514 : loss : 0.060758, loss_ce: 0.019524
2021-12-17 17:18:15,889 iteration 3515 : loss : 0.080719, loss_ce: 0.032448
2021-12-17 17:18:17,298 iteration 3516 : loss : 0.068489, loss_ce: 0.026555
2021-12-17 17:18:18,714 iteration 3517 : loss : 0.075483, loss_ce: 0.029474
2021-12-17 17:18:20,235 iteration 3518 : loss : 0.083978, loss_ce: 0.022659
2021-12-17 17:18:21,716 iteration 3519 : loss : 0.082908, loss_ce: 0.028249
 52%|█████████████▉             | 207/400 [1:34:33<1:25:08, 26.47s/it]2021-12-17 17:18:23,135 iteration 3520 : loss : 0.064492, loss_ce: 0.019427
2021-12-17 17:18:24,554 iteration 3521 : loss : 0.070565, loss_ce: 0.015755
2021-12-17 17:18:25,946 iteration 3522 : loss : 0.072339, loss_ce: 0.017187
2021-12-17 17:18:27,418 iteration 3523 : loss : 0.065142, loss_ce: 0.026781
2021-12-17 17:18:28,929 iteration 3524 : loss : 0.071811, loss_ce: 0.023088
2021-12-17 17:18:30,335 iteration 3525 : loss : 0.065792, loss_ce: 0.017839
2021-12-17 17:18:31,800 iteration 3526 : loss : 0.062799, loss_ce: 0.023187
2021-12-17 17:18:33,307 iteration 3527 : loss : 0.074036, loss_ce: 0.025791
2021-12-17 17:18:34,715 iteration 3528 : loss : 0.131718, loss_ce: 0.023382
2021-12-17 17:18:36,138 iteration 3529 : loss : 0.063862, loss_ce: 0.017694
2021-12-17 17:18:37,562 iteration 3530 : loss : 0.063147, loss_ce: 0.019031
2021-12-17 17:18:38,999 iteration 3531 : loss : 0.066174, loss_ce: 0.021456
2021-12-17 17:18:40,452 iteration 3532 : loss : 0.065229, loss_ce: 0.024259
2021-12-17 17:18:41,921 iteration 3533 : loss : 0.067723, loss_ce: 0.020143
2021-12-17 17:18:43,297 iteration 3534 : loss : 0.070589, loss_ce: 0.020165
2021-12-17 17:18:44,760 iteration 3535 : loss : 0.068215, loss_ce: 0.022059
2021-12-17 17:18:46,177 iteration 3536 : loss : 0.069168, loss_ce: 0.021871
 52%|██████████████             | 208/400 [1:34:58<1:22:45, 25.86s/it]2021-12-17 17:18:47,741 iteration 3537 : loss : 0.113317, loss_ce: 0.048849
2021-12-17 17:18:49,142 iteration 3538 : loss : 0.059754, loss_ce: 0.018053
2021-12-17 17:18:50,550 iteration 3539 : loss : 0.078973, loss_ce: 0.019668
2021-12-17 17:18:52,036 iteration 3540 : loss : 0.078807, loss_ce: 0.028567
2021-12-17 17:18:53,518 iteration 3541 : loss : 0.077514, loss_ce: 0.023779
2021-12-17 17:18:54,970 iteration 3542 : loss : 0.074330, loss_ce: 0.024843
2021-12-17 17:18:56,488 iteration 3543 : loss : 0.064613, loss_ce: 0.021606
2021-12-17 17:18:57,970 iteration 3544 : loss : 0.094997, loss_ce: 0.019847
2021-12-17 17:18:59,471 iteration 3545 : loss : 0.081646, loss_ce: 0.022902
2021-12-17 17:19:00,964 iteration 3546 : loss : 0.084245, loss_ce: 0.026171
2021-12-17 17:19:02,475 iteration 3547 : loss : 0.067085, loss_ce: 0.021587
2021-12-17 17:19:03,871 iteration 3548 : loss : 0.056175, loss_ce: 0.012124
2021-12-17 17:19:05,398 iteration 3549 : loss : 0.099493, loss_ce: 0.037335
2021-12-17 17:19:06,812 iteration 3550 : loss : 0.063774, loss_ce: 0.017849
2021-12-17 17:19:08,220 iteration 3551 : loss : 0.077738, loss_ce: 0.025345
2021-12-17 17:19:09,626 iteration 3552 : loss : 0.067656, loss_ce: 0.027461
2021-12-17 17:19:11,053 iteration 3553 : loss : 0.066387, loss_ce: 0.021160
 52%|██████████████             | 209/400 [1:35:22<1:21:23, 25.57s/it]2021-12-17 17:19:12,537 iteration 3554 : loss : 0.069984, loss_ce: 0.021938
2021-12-17 17:19:13,958 iteration 3555 : loss : 0.089213, loss_ce: 0.032827
2021-12-17 17:19:15,449 iteration 3556 : loss : 0.079369, loss_ce: 0.028373
2021-12-17 17:19:16,964 iteration 3557 : loss : 0.088541, loss_ce: 0.031971
2021-12-17 17:19:18,390 iteration 3558 : loss : 0.070062, loss_ce: 0.018837
2021-12-17 17:19:19,834 iteration 3559 : loss : 0.073165, loss_ce: 0.015411
2021-12-17 17:19:21,271 iteration 3560 : loss : 0.071917, loss_ce: 0.025218
2021-12-17 17:19:22,642 iteration 3561 : loss : 0.057130, loss_ce: 0.022170
2021-12-17 17:19:24,099 iteration 3562 : loss : 0.078478, loss_ce: 0.026859
2021-12-17 17:19:25,545 iteration 3563 : loss : 0.071079, loss_ce: 0.022615
2021-12-17 17:19:27,028 iteration 3564 : loss : 0.080944, loss_ce: 0.021277
2021-12-17 17:19:28,420 iteration 3565 : loss : 0.071629, loss_ce: 0.016192
2021-12-17 17:19:29,819 iteration 3566 : loss : 0.064801, loss_ce: 0.020652
2021-12-17 17:19:31,334 iteration 3567 : loss : 0.089656, loss_ce: 0.039112
2021-12-17 17:19:32,767 iteration 3568 : loss : 0.072839, loss_ce: 0.021719
2021-12-17 17:19:34,178 iteration 3569 : loss : 0.065367, loss_ce: 0.020330
2021-12-17 17:19:34,178 Training Data Eval:
2021-12-17 17:19:41,646   Average segmentation loss on training set: 0.0503
2021-12-17 17:19:41,647 Validation Data Eval:
2021-12-17 17:19:44,230   Average segmentation loss on validation set: 0.1357
2021-12-17 17:19:45,727 iteration 3570 : loss : 0.072033, loss_ce: 0.020550
 52%|██████████████▏            | 210/400 [1:35:57<1:29:37, 28.30s/it]2021-12-17 17:19:47,262 iteration 3571 : loss : 0.076716, loss_ce: 0.029928
2021-12-17 17:19:48,648 iteration 3572 : loss : 0.063085, loss_ce: 0.017491
2021-12-17 17:19:50,117 iteration 3573 : loss : 0.090900, loss_ce: 0.028896
2021-12-17 17:19:51,578 iteration 3574 : loss : 0.059338, loss_ce: 0.014588
2021-12-17 17:19:52,976 iteration 3575 : loss : 0.061554, loss_ce: 0.016963
2021-12-17 17:19:54,467 iteration 3576 : loss : 0.064331, loss_ce: 0.016792
2021-12-17 17:19:55,944 iteration 3577 : loss : 0.067131, loss_ce: 0.020670
2021-12-17 17:19:57,292 iteration 3578 : loss : 0.061462, loss_ce: 0.017744
2021-12-17 17:19:58,701 iteration 3579 : loss : 0.069521, loss_ce: 0.021768
2021-12-17 17:20:00,102 iteration 3580 : loss : 0.072149, loss_ce: 0.022078
2021-12-17 17:20:01,501 iteration 3581 : loss : 0.071153, loss_ce: 0.030416
2021-12-17 17:20:02,934 iteration 3582 : loss : 0.061123, loss_ce: 0.016599
2021-12-17 17:20:04,414 iteration 3583 : loss : 0.071259, loss_ce: 0.020595
2021-12-17 17:20:05,869 iteration 3584 : loss : 0.070718, loss_ce: 0.018537
2021-12-17 17:20:07,261 iteration 3585 : loss : 0.068366, loss_ce: 0.019133
2021-12-17 17:20:08,766 iteration 3586 : loss : 0.078891, loss_ce: 0.033836
2021-12-17 17:20:10,200 iteration 3587 : loss : 0.062036, loss_ce: 0.019293
 53%|██████████████▏            | 211/400 [1:36:22<1:25:31, 27.15s/it]2021-12-17 17:20:11,777 iteration 3588 : loss : 0.063981, loss_ce: 0.021257
2021-12-17 17:20:13,152 iteration 3589 : loss : 0.064439, loss_ce: 0.016736
2021-12-17 17:20:14,580 iteration 3590 : loss : 0.061772, loss_ce: 0.020348
2021-12-17 17:20:16,036 iteration 3591 : loss : 0.063752, loss_ce: 0.018033
2021-12-17 17:20:17,662 iteration 3592 : loss : 0.093234, loss_ce: 0.029490
2021-12-17 17:20:19,084 iteration 3593 : loss : 0.073042, loss_ce: 0.022111
2021-12-17 17:20:20,525 iteration 3594 : loss : 0.068667, loss_ce: 0.024272
2021-12-17 17:20:21,998 iteration 3595 : loss : 0.090617, loss_ce: 0.031273
2021-12-17 17:20:23,441 iteration 3596 : loss : 0.055699, loss_ce: 0.015186
2021-12-17 17:20:24,932 iteration 3597 : loss : 0.088310, loss_ce: 0.026891
2021-12-17 17:20:26,315 iteration 3598 : loss : 0.065464, loss_ce: 0.021471
2021-12-17 17:20:27,804 iteration 3599 : loss : 0.065098, loss_ce: 0.017246
2021-12-17 17:20:29,144 iteration 3600 : loss : 0.061623, loss_ce: 0.019027
2021-12-17 17:20:30,601 iteration 3601 : loss : 0.064112, loss_ce: 0.021317
2021-12-17 17:20:31,997 iteration 3602 : loss : 0.061764, loss_ce: 0.017614
2021-12-17 17:20:33,465 iteration 3603 : loss : 0.072806, loss_ce: 0.031127
2021-12-17 17:20:34,851 iteration 3604 : loss : 0.058805, loss_ce: 0.020701
 53%|██████████████▎            | 212/400 [1:36:46<1:22:43, 26.40s/it]2021-12-17 17:20:36,348 iteration 3605 : loss : 0.073283, loss_ce: 0.022171
2021-12-17 17:20:37,763 iteration 3606 : loss : 0.080595, loss_ce: 0.032162
2021-12-17 17:20:39,228 iteration 3607 : loss : 0.071651, loss_ce: 0.022501
2021-12-17 17:20:40,645 iteration 3608 : loss : 0.065042, loss_ce: 0.018810
2021-12-17 17:20:42,059 iteration 3609 : loss : 0.064522, loss_ce: 0.025396
2021-12-17 17:20:43,509 iteration 3610 : loss : 0.063127, loss_ce: 0.020128
2021-12-17 17:20:44,896 iteration 3611 : loss : 0.061821, loss_ce: 0.013165
2021-12-17 17:20:46,286 iteration 3612 : loss : 0.056583, loss_ce: 0.015124
2021-12-17 17:20:47,835 iteration 3613 : loss : 0.080292, loss_ce: 0.029288
2021-12-17 17:20:49,225 iteration 3614 : loss : 0.063008, loss_ce: 0.019903
2021-12-17 17:20:50,573 iteration 3615 : loss : 0.058820, loss_ce: 0.018131
2021-12-17 17:20:52,050 iteration 3616 : loss : 0.071166, loss_ce: 0.023682
2021-12-17 17:20:53,546 iteration 3617 : loss : 0.073088, loss_ce: 0.024769
2021-12-17 17:20:55,007 iteration 3618 : loss : 0.068309, loss_ce: 0.020153
2021-12-17 17:20:56,448 iteration 3619 : loss : 0.067752, loss_ce: 0.015902
2021-12-17 17:20:57,836 iteration 3620 : loss : 0.063614, loss_ce: 0.016110
2021-12-17 17:20:59,274 iteration 3621 : loss : 0.070774, loss_ce: 0.022335
 53%|██████████████▍            | 213/400 [1:37:11<1:20:25, 25.81s/it]2021-12-17 17:21:00,760 iteration 3622 : loss : 0.071961, loss_ce: 0.027161
2021-12-17 17:21:02,267 iteration 3623 : loss : 0.064916, loss_ce: 0.012328
2021-12-17 17:21:03,720 iteration 3624 : loss : 0.060067, loss_ce: 0.019558
2021-12-17 17:21:05,162 iteration 3625 : loss : 0.064574, loss_ce: 0.020457
2021-12-17 17:21:06,570 iteration 3626 : loss : 0.064586, loss_ce: 0.024094
2021-12-17 17:21:07,957 iteration 3627 : loss : 0.065438, loss_ce: 0.020129
2021-12-17 17:21:09,440 iteration 3628 : loss : 0.088949, loss_ce: 0.022644
2021-12-17 17:21:11,040 iteration 3629 : loss : 0.059589, loss_ce: 0.019103
2021-12-17 17:21:12,403 iteration 3630 : loss : 0.063078, loss_ce: 0.018404
2021-12-17 17:21:13,843 iteration 3631 : loss : 0.073998, loss_ce: 0.020263
2021-12-17 17:21:15,404 iteration 3632 : loss : 0.072764, loss_ce: 0.020548
2021-12-17 17:21:16,847 iteration 3633 : loss : 0.060969, loss_ce: 0.018013
2021-12-17 17:21:18,279 iteration 3634 : loss : 0.062564, loss_ce: 0.020927
2021-12-17 17:21:19,825 iteration 3635 : loss : 0.079629, loss_ce: 0.028977
2021-12-17 17:21:21,322 iteration 3636 : loss : 0.091009, loss_ce: 0.023685
2021-12-17 17:21:22,761 iteration 3637 : loss : 0.085188, loss_ce: 0.026386
2021-12-17 17:21:24,202 iteration 3638 : loss : 0.064467, loss_ce: 0.020607
 54%|██████████████▍            | 214/400 [1:37:36<1:19:11, 25.54s/it]2021-12-17 17:21:25,636 iteration 3639 : loss : 0.063710, loss_ce: 0.021316
2021-12-17 17:21:27,022 iteration 3640 : loss : 0.065382, loss_ce: 0.020832
2021-12-17 17:21:28,399 iteration 3641 : loss : 0.061269, loss_ce: 0.018270
2021-12-17 17:21:29,847 iteration 3642 : loss : 0.078212, loss_ce: 0.021507
2021-12-17 17:21:31,226 iteration 3643 : loss : 0.067222, loss_ce: 0.020437
2021-12-17 17:21:32,637 iteration 3644 : loss : 0.052355, loss_ce: 0.015304
2021-12-17 17:21:34,094 iteration 3645 : loss : 0.064028, loss_ce: 0.016683
2021-12-17 17:21:35,548 iteration 3646 : loss : 0.067184, loss_ce: 0.019528
2021-12-17 17:21:36,987 iteration 3647 : loss : 0.084159, loss_ce: 0.018502
2021-12-17 17:21:38,456 iteration 3648 : loss : 0.076792, loss_ce: 0.023999
2021-12-17 17:21:39,868 iteration 3649 : loss : 0.053576, loss_ce: 0.013426
2021-12-17 17:21:41,337 iteration 3650 : loss : 0.075306, loss_ce: 0.031400
2021-12-17 17:21:42,811 iteration 3651 : loss : 0.082507, loss_ce: 0.024273
2021-12-17 17:21:44,392 iteration 3652 : loss : 0.100666, loss_ce: 0.025803
2021-12-17 17:21:45,792 iteration 3653 : loss : 0.071542, loss_ce: 0.031915
2021-12-17 17:21:47,172 iteration 3654 : loss : 0.064360, loss_ce: 0.025610
2021-12-17 17:21:47,173 Training Data Eval:
2021-12-17 17:21:54,643   Average segmentation loss on training set: 0.0496
2021-12-17 17:21:54,643 Validation Data Eval:
2021-12-17 17:21:57,225   Average segmentation loss on validation set: 0.1344
2021-12-17 17:21:58,709 iteration 3655 : loss : 0.065562, loss_ce: 0.021144
 54%|██████████████▌            | 215/400 [1:38:10<1:27:03, 28.23s/it]2021-12-17 17:22:00,253 iteration 3656 : loss : 0.064270, loss_ce: 0.018341
2021-12-17 17:22:01,651 iteration 3657 : loss : 0.058299, loss_ce: 0.021449
2021-12-17 17:22:03,158 iteration 3658 : loss : 0.067528, loss_ce: 0.024634
2021-12-17 17:22:04,720 iteration 3659 : loss : 0.074039, loss_ce: 0.022972
2021-12-17 17:22:06,165 iteration 3660 : loss : 0.077638, loss_ce: 0.016502
2021-12-17 17:22:07,550 iteration 3661 : loss : 0.059757, loss_ce: 0.020534
2021-12-17 17:22:08,998 iteration 3662 : loss : 0.055334, loss_ce: 0.016488
2021-12-17 17:22:10,428 iteration 3663 : loss : 0.071201, loss_ce: 0.023152
2021-12-17 17:22:11,924 iteration 3664 : loss : 0.055719, loss_ce: 0.015802
2021-12-17 17:22:13,369 iteration 3665 : loss : 0.082364, loss_ce: 0.033433
2021-12-17 17:22:14,805 iteration 3666 : loss : 0.071694, loss_ce: 0.024511
2021-12-17 17:22:16,234 iteration 3667 : loss : 0.078290, loss_ce: 0.029184
2021-12-17 17:22:17,587 iteration 3668 : loss : 0.069264, loss_ce: 0.014166
2021-12-17 17:22:19,075 iteration 3669 : loss : 0.078331, loss_ce: 0.024033
2021-12-17 17:22:20,470 iteration 3670 : loss : 0.059612, loss_ce: 0.018138
2021-12-17 17:22:21,905 iteration 3671 : loss : 0.058732, loss_ce: 0.021831
2021-12-17 17:22:23,494 iteration 3672 : loss : 0.086365, loss_ce: 0.021118
 54%|██████████████▌            | 216/400 [1:38:35<1:23:24, 27.20s/it]2021-12-17 17:22:24,996 iteration 3673 : loss : 0.076939, loss_ce: 0.029273
2021-12-17 17:22:26,489 iteration 3674 : loss : 0.065785, loss_ce: 0.017383
2021-12-17 17:22:28,024 iteration 3675 : loss : 0.079557, loss_ce: 0.026276
2021-12-17 17:22:29,387 iteration 3676 : loss : 0.061464, loss_ce: 0.019366
2021-12-17 17:22:30,840 iteration 3677 : loss : 0.073157, loss_ce: 0.021697
2021-12-17 17:22:32,366 iteration 3678 : loss : 0.099165, loss_ce: 0.026057
2021-12-17 17:22:33,804 iteration 3679 : loss : 0.075535, loss_ce: 0.027972
2021-12-17 17:22:35,264 iteration 3680 : loss : 0.083873, loss_ce: 0.026400
2021-12-17 17:22:36,700 iteration 3681 : loss : 0.063098, loss_ce: 0.020658
2021-12-17 17:22:38,062 iteration 3682 : loss : 0.056257, loss_ce: 0.018594
2021-12-17 17:22:39,415 iteration 3683 : loss : 0.057046, loss_ce: 0.015850
2021-12-17 17:22:40,917 iteration 3684 : loss : 0.057458, loss_ce: 0.018859
2021-12-17 17:22:42,311 iteration 3685 : loss : 0.069073, loss_ce: 0.021769
2021-12-17 17:22:43,769 iteration 3686 : loss : 0.062516, loss_ce: 0.020285
2021-12-17 17:22:45,174 iteration 3687 : loss : 0.057111, loss_ce: 0.016238
2021-12-17 17:22:46,611 iteration 3688 : loss : 0.061543, loss_ce: 0.025637
2021-12-17 17:22:48,088 iteration 3689 : loss : 0.068158, loss_ce: 0.017723
 54%|██████████████▋            | 217/400 [1:39:00<1:20:34, 26.42s/it]2021-12-17 17:22:49,587 iteration 3690 : loss : 0.066836, loss_ce: 0.014470
2021-12-17 17:22:51,070 iteration 3691 : loss : 0.073738, loss_ce: 0.015413
2021-12-17 17:22:52,541 iteration 3692 : loss : 0.069161, loss_ce: 0.026850
2021-12-17 17:22:53,917 iteration 3693 : loss : 0.055638, loss_ce: 0.017870
2021-12-17 17:22:55,358 iteration 3694 : loss : 0.078941, loss_ce: 0.026609
2021-12-17 17:22:56,805 iteration 3695 : loss : 0.064794, loss_ce: 0.025485
2021-12-17 17:22:58,231 iteration 3696 : loss : 0.081605, loss_ce: 0.024582
2021-12-17 17:22:59,708 iteration 3697 : loss : 0.095483, loss_ce: 0.029661
2021-12-17 17:23:01,236 iteration 3698 : loss : 0.074692, loss_ce: 0.026575
2021-12-17 17:23:02,611 iteration 3699 : loss : 0.055863, loss_ce: 0.016981
2021-12-17 17:23:04,062 iteration 3700 : loss : 0.063839, loss_ce: 0.016557
2021-12-17 17:23:05,421 iteration 3701 : loss : 0.063162, loss_ce: 0.023251
2021-12-17 17:23:06,899 iteration 3702 : loss : 0.058125, loss_ce: 0.016497
2021-12-17 17:23:08,353 iteration 3703 : loss : 0.061941, loss_ce: 0.021020
2021-12-17 17:23:09,705 iteration 3704 : loss : 0.066496, loss_ce: 0.020313
2021-12-17 17:23:11,234 iteration 3705 : loss : 0.071906, loss_ce: 0.023278
2021-12-17 17:23:12,594 iteration 3706 : loss : 0.056053, loss_ce: 0.014387
 55%|██████████████▋            | 218/400 [1:39:24<1:18:23, 25.84s/it]2021-12-17 17:23:14,116 iteration 3707 : loss : 0.066866, loss_ce: 0.025412
2021-12-17 17:23:15,476 iteration 3708 : loss : 0.072404, loss_ce: 0.021934
2021-12-17 17:23:17,028 iteration 3709 : loss : 0.075479, loss_ce: 0.020071
2021-12-17 17:23:18,466 iteration 3710 : loss : 0.067467, loss_ce: 0.020023
2021-12-17 17:23:19,874 iteration 3711 : loss : 0.057090, loss_ce: 0.015761
2021-12-17 17:23:21,269 iteration 3712 : loss : 0.059410, loss_ce: 0.021479
2021-12-17 17:23:22,785 iteration 3713 : loss : 0.075871, loss_ce: 0.021564
2021-12-17 17:23:24,232 iteration 3714 : loss : 0.070336, loss_ce: 0.022289
2021-12-17 17:23:25,659 iteration 3715 : loss : 0.054512, loss_ce: 0.017930
2021-12-17 17:23:27,120 iteration 3716 : loss : 0.065593, loss_ce: 0.025295
2021-12-17 17:23:28,599 iteration 3717 : loss : 0.060871, loss_ce: 0.017639
2021-12-17 17:23:30,012 iteration 3718 : loss : 0.061756, loss_ce: 0.019769
2021-12-17 17:23:31,466 iteration 3719 : loss : 0.067136, loss_ce: 0.021564
2021-12-17 17:23:32,989 iteration 3720 : loss : 0.073246, loss_ce: 0.019943
2021-12-17 17:23:34,405 iteration 3721 : loss : 0.060058, loss_ce: 0.018988
2021-12-17 17:23:35,824 iteration 3722 : loss : 0.072521, loss_ce: 0.027567
2021-12-17 17:23:37,327 iteration 3723 : loss : 0.092853, loss_ce: 0.024048
 55%|██████████████▊            | 219/400 [1:39:49<1:16:57, 25.51s/it]2021-12-17 17:23:38,851 iteration 3724 : loss : 0.076389, loss_ce: 0.025973
2021-12-17 17:23:40,265 iteration 3725 : loss : 0.095040, loss_ce: 0.034861
2021-12-17 17:23:41,830 iteration 3726 : loss : 0.073472, loss_ce: 0.023017
2021-12-17 17:23:43,224 iteration 3727 : loss : 0.058973, loss_ce: 0.017355
2021-12-17 17:23:44,679 iteration 3728 : loss : 0.080732, loss_ce: 0.034074
2021-12-17 17:23:46,194 iteration 3729 : loss : 0.077638, loss_ce: 0.024843
2021-12-17 17:23:47,602 iteration 3730 : loss : 0.071434, loss_ce: 0.019733
2021-12-17 17:23:48,970 iteration 3731 : loss : 0.061496, loss_ce: 0.019321
2021-12-17 17:23:50,429 iteration 3732 : loss : 0.078655, loss_ce: 0.024395
2021-12-17 17:23:51,861 iteration 3733 : loss : 0.065468, loss_ce: 0.016844
2021-12-17 17:23:53,301 iteration 3734 : loss : 0.066220, loss_ce: 0.021299
2021-12-17 17:23:54,767 iteration 3735 : loss : 0.063565, loss_ce: 0.021910
2021-12-17 17:23:56,244 iteration 3736 : loss : 0.071233, loss_ce: 0.017880
2021-12-17 17:23:57,703 iteration 3737 : loss : 0.070318, loss_ce: 0.022147
2021-12-17 17:23:59,128 iteration 3738 : loss : 0.065455, loss_ce: 0.021030
2021-12-17 17:24:00,565 iteration 3739 : loss : 0.067243, loss_ce: 0.016863
2021-12-17 17:24:00,565 Training Data Eval:
2021-12-17 17:24:08,022   Average segmentation loss on training set: 0.0477
2021-12-17 17:24:08,022 Validation Data Eval:
2021-12-17 17:24:10,611   Average segmentation loss on validation set: 0.1441
2021-12-17 17:24:12,128 iteration 3740 : loss : 0.061516, loss_ce: 0.018250
 55%|██████████████▊            | 220/400 [1:40:24<1:24:53, 28.30s/it]2021-12-17 17:24:13,635 iteration 3741 : loss : 0.063859, loss_ce: 0.021631
2021-12-17 17:24:15,027 iteration 3742 : loss : 0.072491, loss_ce: 0.027957
2021-12-17 17:24:16,455 iteration 3743 : loss : 0.067433, loss_ce: 0.021510
2021-12-17 17:24:17,914 iteration 3744 : loss : 0.075023, loss_ce: 0.027866
2021-12-17 17:24:19,311 iteration 3745 : loss : 0.061178, loss_ce: 0.020622
2021-12-17 17:24:20,779 iteration 3746 : loss : 0.065531, loss_ce: 0.023996
2021-12-17 17:24:22,253 iteration 3747 : loss : 0.080006, loss_ce: 0.011563
2021-12-17 17:24:23,688 iteration 3748 : loss : 0.084560, loss_ce: 0.034319
2021-12-17 17:24:25,119 iteration 3749 : loss : 0.064454, loss_ce: 0.022658
2021-12-17 17:24:26,585 iteration 3750 : loss : 0.071613, loss_ce: 0.024194
2021-12-17 17:24:28,053 iteration 3751 : loss : 0.082311, loss_ce: 0.017696
2021-12-17 17:24:29,512 iteration 3752 : loss : 0.071359, loss_ce: 0.026157
2021-12-17 17:24:30,902 iteration 3753 : loss : 0.072054, loss_ce: 0.019036
2021-12-17 17:24:32,281 iteration 3754 : loss : 0.058489, loss_ce: 0.013815
2021-12-17 17:24:33,694 iteration 3755 : loss : 0.071983, loss_ce: 0.027938
2021-12-17 17:24:35,145 iteration 3756 : loss : 0.067789, loss_ce: 0.019942
2021-12-17 17:24:36,580 iteration 3757 : loss : 0.071896, loss_ce: 0.020753
 55%|██████████████▉            | 221/400 [1:40:48<1:20:58, 27.14s/it]2021-12-17 17:24:38,078 iteration 3758 : loss : 0.075378, loss_ce: 0.023900
2021-12-17 17:24:39,522 iteration 3759 : loss : 0.056585, loss_ce: 0.016951
2021-12-17 17:24:40,875 iteration 3760 : loss : 0.068965, loss_ce: 0.017301
2021-12-17 17:24:42,376 iteration 3761 : loss : 0.074280, loss_ce: 0.024915
2021-12-17 17:24:43,806 iteration 3762 : loss : 0.071658, loss_ce: 0.017300
2021-12-17 17:24:45,314 iteration 3763 : loss : 0.073487, loss_ce: 0.024379
2021-12-17 17:24:46,786 iteration 3764 : loss : 0.070989, loss_ce: 0.022431
2021-12-17 17:24:48,230 iteration 3765 : loss : 0.061694, loss_ce: 0.020695
2021-12-17 17:24:49,655 iteration 3766 : loss : 0.069772, loss_ce: 0.020406
2021-12-17 17:24:51,176 iteration 3767 : loss : 0.079577, loss_ce: 0.023800
2021-12-17 17:24:52,650 iteration 3768 : loss : 0.070642, loss_ce: 0.027361
2021-12-17 17:24:54,061 iteration 3769 : loss : 0.057176, loss_ce: 0.018579
2021-12-17 17:24:55,437 iteration 3770 : loss : 0.060002, loss_ce: 0.016375
2021-12-17 17:24:56,836 iteration 3771 : loss : 0.055904, loss_ce: 0.016700
2021-12-17 17:24:58,271 iteration 3772 : loss : 0.060100, loss_ce: 0.017227
2021-12-17 17:24:59,646 iteration 3773 : loss : 0.054142, loss_ce: 0.016695
2021-12-17 17:25:01,039 iteration 3774 : loss : 0.068650, loss_ce: 0.024117
 56%|██████████████▉            | 222/400 [1:41:12<1:18:07, 26.34s/it]2021-12-17 17:25:02,482 iteration 3775 : loss : 0.067586, loss_ce: 0.013611
2021-12-17 17:25:03,963 iteration 3776 : loss : 0.071684, loss_ce: 0.025621
2021-12-17 17:25:05,521 iteration 3777 : loss : 0.075482, loss_ce: 0.023073
2021-12-17 17:25:06,916 iteration 3778 : loss : 0.062657, loss_ce: 0.025107
2021-12-17 17:25:08,391 iteration 3779 : loss : 0.063301, loss_ce: 0.018551
2021-12-17 17:25:09,798 iteration 3780 : loss : 0.066834, loss_ce: 0.026374
2021-12-17 17:25:11,234 iteration 3781 : loss : 0.064230, loss_ce: 0.019489
2021-12-17 17:25:12,689 iteration 3782 : loss : 0.073458, loss_ce: 0.022675
2021-12-17 17:25:14,167 iteration 3783 : loss : 0.064579, loss_ce: 0.015731
2021-12-17 17:25:15,645 iteration 3784 : loss : 0.084126, loss_ce: 0.031433
2021-12-17 17:25:17,054 iteration 3785 : loss : 0.056807, loss_ce: 0.014703
2021-12-17 17:25:18,519 iteration 3786 : loss : 0.069622, loss_ce: 0.017728
2021-12-17 17:25:20,022 iteration 3787 : loss : 0.090295, loss_ce: 0.030940
2021-12-17 17:25:21,539 iteration 3788 : loss : 0.070910, loss_ce: 0.021441
2021-12-17 17:25:22,943 iteration 3789 : loss : 0.059970, loss_ce: 0.015601
2021-12-17 17:25:24,414 iteration 3790 : loss : 0.072676, loss_ce: 0.024519
2021-12-17 17:25:25,760 iteration 3791 : loss : 0.062141, loss_ce: 0.020710
 56%|███████████████            | 223/400 [1:41:37<1:16:15, 25.85s/it]2021-12-17 17:25:27,248 iteration 3792 : loss : 0.062676, loss_ce: 0.022976
2021-12-17 17:25:28,694 iteration 3793 : loss : 0.072904, loss_ce: 0.026154
2021-12-17 17:25:30,071 iteration 3794 : loss : 0.059415, loss_ce: 0.018566
2021-12-17 17:25:31,619 iteration 3795 : loss : 0.098425, loss_ce: 0.035367
2021-12-17 17:25:33,072 iteration 3796 : loss : 0.075920, loss_ce: 0.020206
2021-12-17 17:25:34,491 iteration 3797 : loss : 0.066368, loss_ce: 0.018398
2021-12-17 17:25:36,024 iteration 3798 : loss : 0.064202, loss_ce: 0.022328
2021-12-17 17:25:37,409 iteration 3799 : loss : 0.075116, loss_ce: 0.033197
2021-12-17 17:25:38,878 iteration 3800 : loss : 0.071048, loss_ce: 0.018884
2021-12-17 17:25:40,264 iteration 3801 : loss : 0.057358, loss_ce: 0.016837
2021-12-17 17:25:41,708 iteration 3802 : loss : 0.055652, loss_ce: 0.012584
2021-12-17 17:25:43,122 iteration 3803 : loss : 0.054154, loss_ce: 0.017123
2021-12-17 17:25:44,464 iteration 3804 : loss : 0.059196, loss_ce: 0.017257
2021-12-17 17:25:45,938 iteration 3805 : loss : 0.058689, loss_ce: 0.019917
2021-12-17 17:25:47,358 iteration 3806 : loss : 0.068866, loss_ce: 0.019215
2021-12-17 17:25:48,793 iteration 3807 : loss : 0.062717, loss_ce: 0.019173
2021-12-17 17:25:50,261 iteration 3808 : loss : 0.066555, loss_ce: 0.020402
 56%|███████████████            | 224/400 [1:42:02<1:14:38, 25.45s/it]2021-12-17 17:25:51,728 iteration 3809 : loss : 0.063762, loss_ce: 0.022975
2021-12-17 17:25:53,157 iteration 3810 : loss : 0.084439, loss_ce: 0.027585
2021-12-17 17:25:54,714 iteration 3811 : loss : 0.060423, loss_ce: 0.016669
2021-12-17 17:25:56,123 iteration 3812 : loss : 0.062807, loss_ce: 0.019212
2021-12-17 17:25:57,585 iteration 3813 : loss : 0.079232, loss_ce: 0.016638
2021-12-17 17:25:58,941 iteration 3814 : loss : 0.059564, loss_ce: 0.017919
2021-12-17 17:26:00,456 iteration 3815 : loss : 0.096460, loss_ce: 0.028232
2021-12-17 17:26:01,984 iteration 3816 : loss : 0.094904, loss_ce: 0.027274
2021-12-17 17:26:03,434 iteration 3817 : loss : 0.060237, loss_ce: 0.021808
2021-12-17 17:26:04,988 iteration 3818 : loss : 0.064866, loss_ce: 0.019628
2021-12-17 17:26:06,375 iteration 3819 : loss : 0.066890, loss_ce: 0.025126
2021-12-17 17:26:07,860 iteration 3820 : loss : 0.069207, loss_ce: 0.022599
2021-12-17 17:26:09,293 iteration 3821 : loss : 0.070513, loss_ce: 0.027892
2021-12-17 17:26:10,637 iteration 3822 : loss : 0.055586, loss_ce: 0.018669
2021-12-17 17:26:12,016 iteration 3823 : loss : 0.058382, loss_ce: 0.017275
2021-12-17 17:26:13,444 iteration 3824 : loss : 0.066175, loss_ce: 0.021010
2021-12-17 17:26:13,444 Training Data Eval:
2021-12-17 17:26:20,931   Average segmentation loss on training set: 0.0477
2021-12-17 17:26:20,932 Validation Data Eval:
2021-12-17 17:26:23,537   Average segmentation loss on validation set: 0.1255
2021-12-17 17:26:24,945 iteration 3825 : loss : 0.067710, loss_ce: 0.021435
 56%|███████████████▏           | 225/400 [1:42:36<1:22:18, 28.22s/it]2021-12-17 17:26:26,334 iteration 3826 : loss : 0.055059, loss_ce: 0.014987
2021-12-17 17:26:27,772 iteration 3827 : loss : 0.068085, loss_ce: 0.022167
2021-12-17 17:26:29,233 iteration 3828 : loss : 0.064538, loss_ce: 0.020140
2021-12-17 17:26:30,659 iteration 3829 : loss : 0.073077, loss_ce: 0.028986
2021-12-17 17:26:32,103 iteration 3830 : loss : 0.072627, loss_ce: 0.023230
2021-12-17 17:26:33,628 iteration 3831 : loss : 0.086221, loss_ce: 0.019976
2021-12-17 17:26:34,995 iteration 3832 : loss : 0.052932, loss_ce: 0.015681
2021-12-17 17:26:36,466 iteration 3833 : loss : 0.073660, loss_ce: 0.024001
2021-12-17 17:26:37,868 iteration 3834 : loss : 0.057332, loss_ce: 0.022222
2021-12-17 17:26:39,363 iteration 3835 : loss : 0.060227, loss_ce: 0.022564
2021-12-17 17:26:40,840 iteration 3836 : loss : 0.067242, loss_ce: 0.021874
2021-12-17 17:26:42,190 iteration 3837 : loss : 0.056840, loss_ce: 0.019734
2021-12-17 17:26:43,585 iteration 3838 : loss : 0.065479, loss_ce: 0.018224
2021-12-17 17:26:44,989 iteration 3839 : loss : 0.064637, loss_ce: 0.018507
2021-12-17 17:26:46,349 iteration 3840 : loss : 0.063195, loss_ce: 0.015982
2021-12-17 17:26:47,766 iteration 3841 : loss : 0.058324, loss_ce: 0.015789
2021-12-17 17:26:49,184 iteration 3842 : loss : 0.064396, loss_ce: 0.013751
 56%|███████████████▎           | 226/400 [1:43:01<1:18:21, 27.02s/it]2021-12-17 17:26:50,686 iteration 3843 : loss : 0.067433, loss_ce: 0.021839
2021-12-17 17:26:52,132 iteration 3844 : loss : 0.071640, loss_ce: 0.024913
2021-12-17 17:26:53,538 iteration 3845 : loss : 0.071753, loss_ce: 0.021692
2021-12-17 17:26:54,972 iteration 3846 : loss : 0.066279, loss_ce: 0.014837
2021-12-17 17:26:56,437 iteration 3847 : loss : 0.058835, loss_ce: 0.015645
2021-12-17 17:26:57,840 iteration 3848 : loss : 0.056656, loss_ce: 0.018889
2021-12-17 17:26:59,215 iteration 3849 : loss : 0.056538, loss_ce: 0.016789
2021-12-17 17:27:00,690 iteration 3850 : loss : 0.071788, loss_ce: 0.014142
2021-12-17 17:27:02,181 iteration 3851 : loss : 0.079944, loss_ce: 0.036154
2021-12-17 17:27:03,581 iteration 3852 : loss : 0.082151, loss_ce: 0.024391
2021-12-17 17:27:04,988 iteration 3853 : loss : 0.068234, loss_ce: 0.030972
2021-12-17 17:27:06,467 iteration 3854 : loss : 0.074850, loss_ce: 0.021742
2021-12-17 17:27:07,912 iteration 3855 : loss : 0.067769, loss_ce: 0.021149
2021-12-17 17:27:09,348 iteration 3856 : loss : 0.089549, loss_ce: 0.027696
2021-12-17 17:27:10,745 iteration 3857 : loss : 0.065998, loss_ce: 0.022476
2021-12-17 17:27:12,211 iteration 3858 : loss : 0.057022, loss_ce: 0.017241
2021-12-17 17:27:13,655 iteration 3859 : loss : 0.070595, loss_ce: 0.016845
 57%|███████████████▎           | 227/400 [1:43:25<1:15:42, 26.26s/it]2021-12-17 17:27:15,133 iteration 3860 : loss : 0.064579, loss_ce: 0.024136
2021-12-17 17:27:16,625 iteration 3861 : loss : 0.076015, loss_ce: 0.026938
2021-12-17 17:27:17,999 iteration 3862 : loss : 0.066536, loss_ce: 0.025898
2021-12-17 17:27:19,459 iteration 3863 : loss : 0.067719, loss_ce: 0.027407
2021-12-17 17:27:20,935 iteration 3864 : loss : 0.063832, loss_ce: 0.018658
2021-12-17 17:27:22,495 iteration 3865 : loss : 0.082407, loss_ce: 0.028026
2021-12-17 17:27:24,036 iteration 3866 : loss : 0.078242, loss_ce: 0.029963
2021-12-17 17:27:25,446 iteration 3867 : loss : 0.059495, loss_ce: 0.019559
2021-12-17 17:27:26,925 iteration 3868 : loss : 0.075260, loss_ce: 0.024701
2021-12-17 17:27:28,410 iteration 3869 : loss : 0.066222, loss_ce: 0.020181
2021-12-17 17:27:29,901 iteration 3870 : loss : 0.068783, loss_ce: 0.019300
2021-12-17 17:27:31,325 iteration 3871 : loss : 0.073546, loss_ce: 0.017575
2021-12-17 17:27:32,747 iteration 3872 : loss : 0.082586, loss_ce: 0.031996
2021-12-17 17:27:34,165 iteration 3873 : loss : 0.062302, loss_ce: 0.018489
2021-12-17 17:27:35,652 iteration 3874 : loss : 0.066267, loss_ce: 0.020690
2021-12-17 17:27:37,127 iteration 3875 : loss : 0.064991, loss_ce: 0.019805
2021-12-17 17:27:38,558 iteration 3876 : loss : 0.071333, loss_ce: 0.014828
 57%|███████████████▍           | 228/400 [1:43:50<1:14:06, 25.85s/it]2021-12-17 17:27:40,012 iteration 3877 : loss : 0.057598, loss_ce: 0.018778
2021-12-17 17:27:41,507 iteration 3878 : loss : 0.071975, loss_ce: 0.026529
2021-12-17 17:27:42,965 iteration 3879 : loss : 0.074135, loss_ce: 0.024795
2021-12-17 17:27:44,385 iteration 3880 : loss : 0.068510, loss_ce: 0.025174
2021-12-17 17:27:45,770 iteration 3881 : loss : 0.067651, loss_ce: 0.027840
2021-12-17 17:27:47,267 iteration 3882 : loss : 0.094009, loss_ce: 0.032342
2021-12-17 17:27:48,746 iteration 3883 : loss : 0.079967, loss_ce: 0.026783
2021-12-17 17:27:50,136 iteration 3884 : loss : 0.100784, loss_ce: 0.016278
2021-12-17 17:27:51,505 iteration 3885 : loss : 0.059109, loss_ce: 0.016700
2021-12-17 17:27:52,898 iteration 3886 : loss : 0.067038, loss_ce: 0.019174
2021-12-17 17:27:54,408 iteration 3887 : loss : 0.072002, loss_ce: 0.025390
2021-12-17 17:27:55,834 iteration 3888 : loss : 0.066116, loss_ce: 0.018260
2021-12-17 17:27:57,274 iteration 3889 : loss : 0.071097, loss_ce: 0.025807
2021-12-17 17:27:58,630 iteration 3890 : loss : 0.058643, loss_ce: 0.018931
2021-12-17 17:28:00,091 iteration 3891 : loss : 0.054359, loss_ce: 0.014339
2021-12-17 17:28:01,549 iteration 3892 : loss : 0.072145, loss_ce: 0.015907
2021-12-17 17:28:03,088 iteration 3893 : loss : 0.078789, loss_ce: 0.034464
 57%|███████████████▍           | 229/400 [1:44:15<1:12:32, 25.46s/it]2021-12-17 17:28:04,510 iteration 3894 : loss : 0.061171, loss_ce: 0.021723
2021-12-17 17:28:05,992 iteration 3895 : loss : 0.076177, loss_ce: 0.021333
2021-12-17 17:28:07,414 iteration 3896 : loss : 0.073500, loss_ce: 0.018045
2021-12-17 17:28:08,887 iteration 3897 : loss : 0.076002, loss_ce: 0.028159
2021-12-17 17:28:10,302 iteration 3898 : loss : 0.061433, loss_ce: 0.018265
2021-12-17 17:28:11,770 iteration 3899 : loss : 0.060758, loss_ce: 0.020694
2021-12-17 17:28:13,276 iteration 3900 : loss : 0.085851, loss_ce: 0.022906
2021-12-17 17:28:14,650 iteration 3901 : loss : 0.064327, loss_ce: 0.020009
2021-12-17 17:28:16,052 iteration 3902 : loss : 0.054293, loss_ce: 0.016979
2021-12-17 17:28:17,489 iteration 3903 : loss : 0.074358, loss_ce: 0.025035
2021-12-17 17:28:18,997 iteration 3904 : loss : 0.065605, loss_ce: 0.016756
2021-12-17 17:28:20,421 iteration 3905 : loss : 0.061884, loss_ce: 0.022436
2021-12-17 17:28:21,810 iteration 3906 : loss : 0.061995, loss_ce: 0.022785
2021-12-17 17:28:23,256 iteration 3907 : loss : 0.062080, loss_ce: 0.016207
2021-12-17 17:28:24,771 iteration 3908 : loss : 0.067535, loss_ce: 0.019683
2021-12-17 17:28:26,245 iteration 3909 : loss : 0.070152, loss_ce: 0.023030
2021-12-17 17:28:26,245 Training Data Eval:
2021-12-17 17:28:33,691   Average segmentation loss on training set: 0.0479
2021-12-17 17:28:33,691 Validation Data Eval:
2021-12-17 17:28:36,278   Average segmentation loss on validation set: 0.1346
2021-12-17 17:28:37,652 iteration 3910 : loss : 0.053548, loss_ce: 0.014124
 57%|███████████████▌           | 230/400 [1:44:49<1:19:51, 28.19s/it]2021-12-17 17:28:39,073 iteration 3911 : loss : 0.058489, loss_ce: 0.016414
2021-12-17 17:28:40,548 iteration 3912 : loss : 0.070111, loss_ce: 0.024575
2021-12-17 17:28:41,906 iteration 3913 : loss : 0.066240, loss_ce: 0.018145
2021-12-17 17:28:43,271 iteration 3914 : loss : 0.052383, loss_ce: 0.015359
2021-12-17 17:28:44,638 iteration 3915 : loss : 0.055119, loss_ce: 0.016275
2021-12-17 17:28:46,127 iteration 3916 : loss : 0.066819, loss_ce: 0.020059
2021-12-17 17:28:47,618 iteration 3917 : loss : 0.093714, loss_ce: 0.020719
2021-12-17 17:28:49,113 iteration 3918 : loss : 0.063911, loss_ce: 0.023808
2021-12-17 17:28:50,545 iteration 3919 : loss : 0.064428, loss_ce: 0.020767
2021-12-17 17:28:51,995 iteration 3920 : loss : 0.066552, loss_ce: 0.024840
2021-12-17 17:28:53,436 iteration 3921 : loss : 0.074913, loss_ce: 0.021990
2021-12-17 17:28:54,832 iteration 3922 : loss : 0.051902, loss_ce: 0.014192
2021-12-17 17:28:56,261 iteration 3923 : loss : 0.061811, loss_ce: 0.021635
2021-12-17 17:28:57,688 iteration 3924 : loss : 0.075266, loss_ce: 0.028261
2021-12-17 17:28:59,259 iteration 3925 : loss : 0.063500, loss_ce: 0.020281
2021-12-17 17:29:00,697 iteration 3926 : loss : 0.065126, loss_ce: 0.019477
2021-12-17 17:29:02,139 iteration 3927 : loss : 0.065060, loss_ce: 0.022469
 58%|███████████████▌           | 231/400 [1:45:14<1:16:16, 27.08s/it]2021-12-17 17:29:03,612 iteration 3928 : loss : 0.062666, loss_ce: 0.021039
2021-12-17 17:29:05,129 iteration 3929 : loss : 0.072653, loss_ce: 0.024277
2021-12-17 17:29:06,684 iteration 3930 : loss : 0.089430, loss_ce: 0.028972
2021-12-17 17:29:08,134 iteration 3931 : loss : 0.068351, loss_ce: 0.024831
2021-12-17 17:29:09,612 iteration 3932 : loss : 0.072183, loss_ce: 0.018286
2021-12-17 17:29:11,006 iteration 3933 : loss : 0.074814, loss_ce: 0.018467
2021-12-17 17:29:12,436 iteration 3934 : loss : 0.059830, loss_ce: 0.016396
2021-12-17 17:29:13,936 iteration 3935 : loss : 0.076873, loss_ce: 0.025250
2021-12-17 17:29:15,355 iteration 3936 : loss : 0.058023, loss_ce: 0.019876
2021-12-17 17:29:16,783 iteration 3937 : loss : 0.053946, loss_ce: 0.014237
2021-12-17 17:29:18,180 iteration 3938 : loss : 0.067283, loss_ce: 0.026404
2021-12-17 17:29:19,708 iteration 3939 : loss : 0.069844, loss_ce: 0.022279
2021-12-17 17:29:21,112 iteration 3940 : loss : 0.066337, loss_ce: 0.015630
2021-12-17 17:29:22,536 iteration 3941 : loss : 0.068020, loss_ce: 0.028390
2021-12-17 17:29:23,946 iteration 3942 : loss : 0.065468, loss_ce: 0.023984
2021-12-17 17:29:25,421 iteration 3943 : loss : 0.070493, loss_ce: 0.028763
2021-12-17 17:29:26,877 iteration 3944 : loss : 0.062021, loss_ce: 0.016801
 58%|███████████████▋           | 232/400 [1:45:38<1:13:50, 26.37s/it]2021-12-17 17:29:28,339 iteration 3945 : loss : 0.058723, loss_ce: 0.020275
2021-12-17 17:29:29,692 iteration 3946 : loss : 0.049594, loss_ce: 0.014152
2021-12-17 17:29:31,116 iteration 3947 : loss : 0.067789, loss_ce: 0.020256
2021-12-17 17:29:32,526 iteration 3948 : loss : 0.061542, loss_ce: 0.021789
2021-12-17 17:29:33,959 iteration 3949 : loss : 0.062948, loss_ce: 0.025243
2021-12-17 17:29:35,381 iteration 3950 : loss : 0.063377, loss_ce: 0.018703
2021-12-17 17:29:36,851 iteration 3951 : loss : 0.099202, loss_ce: 0.036494
2021-12-17 17:29:38,282 iteration 3952 : loss : 0.069709, loss_ce: 0.023448
2021-12-17 17:29:39,720 iteration 3953 : loss : 0.060380, loss_ce: 0.016773
2021-12-17 17:29:41,213 iteration 3954 : loss : 0.066110, loss_ce: 0.019522
2021-12-17 17:29:42,675 iteration 3955 : loss : 0.074539, loss_ce: 0.023625
2021-12-17 17:29:44,093 iteration 3956 : loss : 0.066986, loss_ce: 0.024037
2021-12-17 17:29:45,513 iteration 3957 : loss : 0.064560, loss_ce: 0.021827
2021-12-17 17:29:47,037 iteration 3958 : loss : 0.080805, loss_ce: 0.031691
2021-12-17 17:29:48,436 iteration 3959 : loss : 0.056238, loss_ce: 0.015660
2021-12-17 17:29:49,878 iteration 3960 : loss : 0.061462, loss_ce: 0.013217
2021-12-17 17:29:51,357 iteration 3961 : loss : 0.051860, loss_ce: 0.015089
 58%|███████████████▋           | 233/400 [1:46:03<1:11:49, 25.81s/it]2021-12-17 17:29:52,957 iteration 3962 : loss : 0.076826, loss_ce: 0.027405
2021-12-17 17:29:54,318 iteration 3963 : loss : 0.060301, loss_ce: 0.020363
2021-12-17 17:29:55,785 iteration 3964 : loss : 0.078267, loss_ce: 0.025931
2021-12-17 17:29:57,319 iteration 3965 : loss : 0.115402, loss_ce: 0.029615
2021-12-17 17:29:58,720 iteration 3966 : loss : 0.063318, loss_ce: 0.019964
2021-12-17 17:30:00,127 iteration 3967 : loss : 0.058102, loss_ce: 0.014701
2021-12-17 17:30:01,646 iteration 3968 : loss : 0.065567, loss_ce: 0.022449
2021-12-17 17:30:03,134 iteration 3969 : loss : 0.069111, loss_ce: 0.023274
2021-12-17 17:30:04,650 iteration 3970 : loss : 0.071849, loss_ce: 0.031079
2021-12-17 17:30:06,043 iteration 3971 : loss : 0.058106, loss_ce: 0.015423
2021-12-17 17:30:07,458 iteration 3972 : loss : 0.074017, loss_ce: 0.026313
2021-12-17 17:30:08,915 iteration 3973 : loss : 0.080621, loss_ce: 0.027046
2021-12-17 17:30:10,434 iteration 3974 : loss : 0.075761, loss_ce: 0.026761
2021-12-17 17:30:11,945 iteration 3975 : loss : 0.066100, loss_ce: 0.020330
2021-12-17 17:30:13,472 iteration 3976 : loss : 0.071546, loss_ce: 0.028737
2021-12-17 17:30:14,897 iteration 3977 : loss : 0.060971, loss_ce: 0.019178
2021-12-17 17:30:16,311 iteration 3978 : loss : 0.056995, loss_ce: 0.019165
 58%|███████████████▊           | 234/400 [1:46:28<1:10:41, 25.55s/it]2021-12-17 17:30:17,805 iteration 3979 : loss : 0.093335, loss_ce: 0.029731
2021-12-17 17:30:19,300 iteration 3980 : loss : 0.069971, loss_ce: 0.024474
2021-12-17 17:30:20,702 iteration 3981 : loss : 0.062077, loss_ce: 0.017494
2021-12-17 17:30:22,280 iteration 3982 : loss : 0.079622, loss_ce: 0.021272
2021-12-17 17:30:23,701 iteration 3983 : loss : 0.061875, loss_ce: 0.014416
2021-12-17 17:30:25,165 iteration 3984 : loss : 0.067878, loss_ce: 0.022606
2021-12-17 17:30:26,598 iteration 3985 : loss : 0.083054, loss_ce: 0.025937
2021-12-17 17:30:27,981 iteration 3986 : loss : 0.057478, loss_ce: 0.019963
2021-12-17 17:30:29,395 iteration 3987 : loss : 0.059787, loss_ce: 0.022060
2021-12-17 17:30:30,899 iteration 3988 : loss : 0.080059, loss_ce: 0.028231
2021-12-17 17:30:32,347 iteration 3989 : loss : 0.075312, loss_ce: 0.028675
2021-12-17 17:30:33,765 iteration 3990 : loss : 0.057681, loss_ce: 0.017557
2021-12-17 17:30:35,190 iteration 3991 : loss : 0.064580, loss_ce: 0.019841
2021-12-17 17:30:36,744 iteration 3992 : loss : 0.084306, loss_ce: 0.022229
2021-12-17 17:30:38,178 iteration 3993 : loss : 0.064460, loss_ce: 0.024856
2021-12-17 17:30:39,615 iteration 3994 : loss : 0.059653, loss_ce: 0.019435
2021-12-17 17:30:39,615 Training Data Eval:
2021-12-17 17:30:47,053   Average segmentation loss on training set: 0.0462
2021-12-17 17:30:47,054 Validation Data Eval:
2021-12-17 17:30:49,636   Average segmentation loss on validation set: 0.1283
2021-12-17 17:30:51,082 iteration 3995 : loss : 0.071260, loss_ce: 0.017007
 59%|███████████████▊           | 235/400 [1:47:03<1:17:52, 28.32s/it]2021-12-17 17:30:52,642 iteration 3996 : loss : 0.089155, loss_ce: 0.035829
2021-12-17 17:30:54,108 iteration 3997 : loss : 0.063214, loss_ce: 0.019254
2021-12-17 17:30:55,532 iteration 3998 : loss : 0.064040, loss_ce: 0.019247
2021-12-17 17:30:57,020 iteration 3999 : loss : 0.055300, loss_ce: 0.013345
2021-12-17 17:30:58,473 iteration 4000 : loss : 0.062556, loss_ce: 0.020476
2021-12-17 17:31:00,017 iteration 4001 : loss : 0.088679, loss_ce: 0.022975
2021-12-17 17:31:01,443 iteration 4002 : loss : 0.065439, loss_ce: 0.025852
2021-12-17 17:31:02,867 iteration 4003 : loss : 0.065654, loss_ce: 0.019367
2021-12-17 17:31:04,277 iteration 4004 : loss : 0.084389, loss_ce: 0.028949
2021-12-17 17:31:05,702 iteration 4005 : loss : 0.069839, loss_ce: 0.025674
2021-12-17 17:31:07,242 iteration 4006 : loss : 0.077485, loss_ce: 0.017628
2021-12-17 17:31:08,672 iteration 4007 : loss : 0.059931, loss_ce: 0.018656
2021-12-17 17:31:10,136 iteration 4008 : loss : 0.073238, loss_ce: 0.021806
2021-12-17 17:31:11,587 iteration 4009 : loss : 0.060927, loss_ce: 0.020304
2021-12-17 17:31:12,964 iteration 4010 : loss : 0.047277, loss_ce: 0.014712
2021-12-17 17:31:14,443 iteration 4011 : loss : 0.070205, loss_ce: 0.017460
2021-12-17 17:31:15,918 iteration 4012 : loss : 0.069628, loss_ce: 0.024632
 59%|███████████████▉           | 236/400 [1:47:27<1:14:32, 27.27s/it]2021-12-17 17:31:17,375 iteration 4013 : loss : 0.071393, loss_ce: 0.017666
2021-12-17 17:31:18,865 iteration 4014 : loss : 0.065450, loss_ce: 0.018160
2021-12-17 17:31:20,274 iteration 4015 : loss : 0.068190, loss_ce: 0.028190
2021-12-17 17:31:21,740 iteration 4016 : loss : 0.090573, loss_ce: 0.028001
2021-12-17 17:31:23,140 iteration 4017 : loss : 0.058849, loss_ce: 0.017620
2021-12-17 17:31:24,649 iteration 4018 : loss : 0.066411, loss_ce: 0.021879
2021-12-17 17:31:26,141 iteration 4019 : loss : 0.090511, loss_ce: 0.034521
2021-12-17 17:31:27,550 iteration 4020 : loss : 0.055199, loss_ce: 0.015706
2021-12-17 17:31:28,992 iteration 4021 : loss : 0.068036, loss_ce: 0.021571
2021-12-17 17:31:30,432 iteration 4022 : loss : 0.072374, loss_ce: 0.020055
2021-12-17 17:31:31,892 iteration 4023 : loss : 0.061458, loss_ce: 0.023467
2021-12-17 17:31:33,351 iteration 4024 : loss : 0.071517, loss_ce: 0.019561
2021-12-17 17:31:34,766 iteration 4025 : loss : 0.063767, loss_ce: 0.019493
2021-12-17 17:31:36,184 iteration 4026 : loss : 0.050137, loss_ce: 0.016239
2021-12-17 17:31:37,608 iteration 4027 : loss : 0.070679, loss_ce: 0.023547
2021-12-17 17:31:39,043 iteration 4028 : loss : 0.054328, loss_ce: 0.012759
2021-12-17 17:31:40,489 iteration 4029 : loss : 0.066628, loss_ce: 0.021805
 59%|███████████████▉           | 237/400 [1:47:52<1:11:52, 26.46s/it]2021-12-17 17:31:41,990 iteration 4030 : loss : 0.076266, loss_ce: 0.028916
2021-12-17 17:31:43,411 iteration 4031 : loss : 0.054253, loss_ce: 0.015966
2021-12-17 17:31:44,898 iteration 4032 : loss : 0.063263, loss_ce: 0.019592
2021-12-17 17:31:46,434 iteration 4033 : loss : 0.105271, loss_ce: 0.032228
2021-12-17 17:31:47,839 iteration 4034 : loss : 0.075202, loss_ce: 0.023613
2021-12-17 17:31:49,289 iteration 4035 : loss : 0.060803, loss_ce: 0.018308
2021-12-17 17:31:50,716 iteration 4036 : loss : 0.051272, loss_ce: 0.014308
2021-12-17 17:31:52,199 iteration 4037 : loss : 0.066320, loss_ce: 0.019077
2021-12-17 17:31:53,633 iteration 4038 : loss : 0.067719, loss_ce: 0.029476
2021-12-17 17:31:54,979 iteration 4039 : loss : 0.053676, loss_ce: 0.018946
2021-12-17 17:31:56,430 iteration 4040 : loss : 0.072946, loss_ce: 0.016648
2021-12-17 17:31:57,989 iteration 4041 : loss : 0.089732, loss_ce: 0.039791
2021-12-17 17:31:59,341 iteration 4042 : loss : 0.061577, loss_ce: 0.022714
2021-12-17 17:32:00,786 iteration 4043 : loss : 0.057899, loss_ce: 0.017734
2021-12-17 17:32:02,227 iteration 4044 : loss : 0.070590, loss_ce: 0.023002
2021-12-17 17:32:03,639 iteration 4045 : loss : 0.065501, loss_ce: 0.023037
2021-12-17 17:32:05,113 iteration 4046 : loss : 0.062908, loss_ce: 0.017578
 60%|████████████████           | 238/400 [1:48:17<1:09:57, 25.91s/it]2021-12-17 17:32:06,531 iteration 4047 : loss : 0.055486, loss_ce: 0.020227
2021-12-17 17:32:07,967 iteration 4048 : loss : 0.062559, loss_ce: 0.015524
2021-12-17 17:32:09,483 iteration 4049 : loss : 0.068948, loss_ce: 0.020244
2021-12-17 17:32:10,920 iteration 4050 : loss : 0.068255, loss_ce: 0.017000
2021-12-17 17:32:12,372 iteration 4051 : loss : 0.057488, loss_ce: 0.017582
2021-12-17 17:32:13,811 iteration 4052 : loss : 0.063763, loss_ce: 0.017905
2021-12-17 17:32:15,236 iteration 4053 : loss : 0.064255, loss_ce: 0.023938
2021-12-17 17:32:16,655 iteration 4054 : loss : 0.056615, loss_ce: 0.018505
2021-12-17 17:32:18,202 iteration 4055 : loss : 0.080973, loss_ce: 0.022060
2021-12-17 17:32:19,666 iteration 4056 : loss : 0.080315, loss_ce: 0.020798
2021-12-17 17:32:21,160 iteration 4057 : loss : 0.068789, loss_ce: 0.022983
2021-12-17 17:32:22,510 iteration 4058 : loss : 0.061486, loss_ce: 0.018742
2021-12-17 17:32:24,006 iteration 4059 : loss : 0.061988, loss_ce: 0.022620
2021-12-17 17:32:25,472 iteration 4060 : loss : 0.061115, loss_ce: 0.018647
2021-12-17 17:32:26,911 iteration 4061 : loss : 0.107570, loss_ce: 0.018894
2021-12-17 17:32:28,338 iteration 4062 : loss : 0.073262, loss_ce: 0.027670
2021-12-17 17:32:29,880 iteration 4063 : loss : 0.112089, loss_ce: 0.033527
 60%|████████████████▏          | 239/400 [1:48:41<1:08:36, 25.57s/it]2021-12-17 17:32:31,344 iteration 4064 : loss : 0.063079, loss_ce: 0.017562
2021-12-17 17:32:32,769 iteration 4065 : loss : 0.057475, loss_ce: 0.018160
2021-12-17 17:32:34,131 iteration 4066 : loss : 0.064683, loss_ce: 0.015922
2021-12-17 17:32:35,532 iteration 4067 : loss : 0.071926, loss_ce: 0.014319
2021-12-17 17:32:36,996 iteration 4068 : loss : 0.071580, loss_ce: 0.024632
2021-12-17 17:32:38,488 iteration 4069 : loss : 0.060245, loss_ce: 0.016321
2021-12-17 17:32:39,965 iteration 4070 : loss : 0.077911, loss_ce: 0.033272
2021-12-17 17:32:41,344 iteration 4071 : loss : 0.058884, loss_ce: 0.020786
2021-12-17 17:32:42,770 iteration 4072 : loss : 0.061455, loss_ce: 0.022502
2021-12-17 17:32:44,215 iteration 4073 : loss : 0.080317, loss_ce: 0.035287
2021-12-17 17:32:45,610 iteration 4074 : loss : 0.068335, loss_ce: 0.020364
2021-12-17 17:32:47,093 iteration 4075 : loss : 0.079801, loss_ce: 0.026488
2021-12-17 17:32:48,544 iteration 4076 : loss : 0.057344, loss_ce: 0.016453
2021-12-17 17:32:50,012 iteration 4077 : loss : 0.057088, loss_ce: 0.020471
2021-12-17 17:32:51,526 iteration 4078 : loss : 0.071586, loss_ce: 0.018018
2021-12-17 17:32:52,974 iteration 4079 : loss : 0.063267, loss_ce: 0.020266
2021-12-17 17:32:52,974 Training Data Eval:
2021-12-17 17:33:00,411   Average segmentation loss on training set: 0.0451
2021-12-17 17:33:00,411 Validation Data Eval:
2021-12-17 17:33:03,002   Average segmentation loss on validation set: 0.1254
2021-12-17 17:33:04,473 iteration 4080 : loss : 0.056374, loss_ce: 0.014403
 60%|████████████████▏          | 240/400 [1:49:16<1:15:23, 28.27s/it]2021-12-17 17:33:05,945 iteration 4081 : loss : 0.067371, loss_ce: 0.028128
2021-12-17 17:33:07,454 iteration 4082 : loss : 0.065197, loss_ce: 0.021759
2021-12-17 17:33:08,829 iteration 4083 : loss : 0.062563, loss_ce: 0.021541
2021-12-17 17:33:10,235 iteration 4084 : loss : 0.055698, loss_ce: 0.016810
2021-12-17 17:33:11,680 iteration 4085 : loss : 0.060939, loss_ce: 0.012608
2021-12-17 17:33:13,098 iteration 4086 : loss : 0.062944, loss_ce: 0.019181
2021-12-17 17:33:14,544 iteration 4087 : loss : 0.072727, loss_ce: 0.018791
2021-12-17 17:33:16,003 iteration 4088 : loss : 0.056315, loss_ce: 0.020107
2021-12-17 17:33:17,470 iteration 4089 : loss : 0.065030, loss_ce: 0.020677
2021-12-17 17:33:18,925 iteration 4090 : loss : 0.059580, loss_ce: 0.022293
2021-12-17 17:33:20,409 iteration 4091 : loss : 0.069362, loss_ce: 0.022278
2021-12-17 17:33:21,799 iteration 4092 : loss : 0.060710, loss_ce: 0.014969
2021-12-17 17:33:23,211 iteration 4093 : loss : 0.058710, loss_ce: 0.021478
2021-12-17 17:33:24,731 iteration 4094 : loss : 0.068766, loss_ce: 0.019790
2021-12-17 17:33:26,180 iteration 4095 : loss : 0.061333, loss_ce: 0.016067
2021-12-17 17:33:27,650 iteration 4096 : loss : 0.090437, loss_ce: 0.036186
2021-12-17 17:33:29,136 iteration 4097 : loss : 0.071005, loss_ce: 0.025009
 60%|████████████████▎          | 241/400 [1:49:41<1:12:03, 27.19s/it]2021-12-17 17:33:30,628 iteration 4098 : loss : 0.057908, loss_ce: 0.019944
2021-12-17 17:33:32,071 iteration 4099 : loss : 0.062315, loss_ce: 0.017085
2021-12-17 17:33:33,479 iteration 4100 : loss : 0.061189, loss_ce: 0.019230
2021-12-17 17:33:34,949 iteration 4101 : loss : 0.058322, loss_ce: 0.022873
2021-12-17 17:33:36,471 iteration 4102 : loss : 0.075906, loss_ce: 0.022737
2021-12-17 17:33:37,830 iteration 4103 : loss : 0.056601, loss_ce: 0.019218
2021-12-17 17:33:39,300 iteration 4104 : loss : 0.089824, loss_ce: 0.027065
2021-12-17 17:33:40,788 iteration 4105 : loss : 0.062848, loss_ce: 0.017852
2021-12-17 17:33:42,314 iteration 4106 : loss : 0.070413, loss_ce: 0.019379
2021-12-17 17:33:43,790 iteration 4107 : loss : 0.067140, loss_ce: 0.024861
2021-12-17 17:33:45,266 iteration 4108 : loss : 0.070868, loss_ce: 0.024911
2021-12-17 17:33:46,719 iteration 4109 : loss : 0.068506, loss_ce: 0.017278
2021-12-17 17:33:48,202 iteration 4110 : loss : 0.061123, loss_ce: 0.016344
2021-12-17 17:33:49,651 iteration 4111 : loss : 0.062733, loss_ce: 0.015652
2021-12-17 17:33:50,996 iteration 4112 : loss : 0.053384, loss_ce: 0.017733
2021-12-17 17:33:52,516 iteration 4113 : loss : 0.065111, loss_ce: 0.018829
2021-12-17 17:33:53,967 iteration 4114 : loss : 0.075174, loss_ce: 0.025233
 60%|████████████████▎          | 242/400 [1:50:05<1:09:44, 26.48s/it]2021-12-17 17:33:55,433 iteration 4115 : loss : 0.056915, loss_ce: 0.013626
2021-12-17 17:33:56,821 iteration 4116 : loss : 0.059570, loss_ce: 0.020403
2021-12-17 17:33:58,210 iteration 4117 : loss : 0.064796, loss_ce: 0.027553
2021-12-17 17:33:59,642 iteration 4118 : loss : 0.070483, loss_ce: 0.016371
2021-12-17 17:34:00,990 iteration 4119 : loss : 0.055266, loss_ce: 0.016477
2021-12-17 17:34:02,547 iteration 4120 : loss : 0.062667, loss_ce: 0.015889
2021-12-17 17:34:03,993 iteration 4121 : loss : 0.061182, loss_ce: 0.018695
2021-12-17 17:34:05,461 iteration 4122 : loss : 0.066378, loss_ce: 0.018295
2021-12-17 17:34:06,919 iteration 4123 : loss : 0.075348, loss_ce: 0.025898
2021-12-17 17:34:08,284 iteration 4124 : loss : 0.058727, loss_ce: 0.018146
2021-12-17 17:34:09,755 iteration 4125 : loss : 0.068405, loss_ce: 0.018809
2021-12-17 17:34:11,317 iteration 4126 : loss : 0.073998, loss_ce: 0.029910
2021-12-17 17:34:12,824 iteration 4127 : loss : 0.073590, loss_ce: 0.032035
2021-12-17 17:34:14,242 iteration 4128 : loss : 0.056243, loss_ce: 0.020991
2021-12-17 17:34:15,802 iteration 4129 : loss : 0.066363, loss_ce: 0.016119
2021-12-17 17:34:17,282 iteration 4130 : loss : 0.056917, loss_ce: 0.015720
2021-12-17 17:34:18,721 iteration 4131 : loss : 0.059580, loss_ce: 0.019039
 61%|████████████████▍          | 243/400 [1:50:30<1:07:56, 25.96s/it]2021-12-17 17:34:20,250 iteration 4132 : loss : 0.070915, loss_ce: 0.020312
2021-12-17 17:34:21,638 iteration 4133 : loss : 0.066919, loss_ce: 0.027507
2021-12-17 17:34:23,144 iteration 4134 : loss : 0.058817, loss_ce: 0.020408
2021-12-17 17:34:24,586 iteration 4135 : loss : 0.067117, loss_ce: 0.022518
2021-12-17 17:34:26,008 iteration 4136 : loss : 0.059486, loss_ce: 0.017214
2021-12-17 17:34:27,465 iteration 4137 : loss : 0.062952, loss_ce: 0.024888
2021-12-17 17:34:28,926 iteration 4138 : loss : 0.062246, loss_ce: 0.024734
2021-12-17 17:34:30,390 iteration 4139 : loss : 0.069080, loss_ce: 0.016015
2021-12-17 17:34:31,876 iteration 4140 : loss : 0.068241, loss_ce: 0.020759
2021-12-17 17:34:33,310 iteration 4141 : loss : 0.054331, loss_ce: 0.012030
2021-12-17 17:34:34,739 iteration 4142 : loss : 0.077691, loss_ce: 0.028400
2021-12-17 17:34:36,164 iteration 4143 : loss : 0.067806, loss_ce: 0.019617
2021-12-17 17:34:37,638 iteration 4144 : loss : 0.058756, loss_ce: 0.015356
2021-12-17 17:34:39,063 iteration 4145 : loss : 0.071258, loss_ce: 0.022341
2021-12-17 17:34:40,411 iteration 4146 : loss : 0.060633, loss_ce: 0.014996
2021-12-17 17:34:41,838 iteration 4147 : loss : 0.060172, loss_ce: 0.017844
2021-12-17 17:34:43,276 iteration 4148 : loss : 0.069713, loss_ce: 0.020371
 61%|████████████████▍          | 244/400 [1:50:55<1:06:24, 25.54s/it]2021-12-17 17:34:44,763 iteration 4149 : loss : 0.066172, loss_ce: 0.019819
2021-12-17 17:34:46,191 iteration 4150 : loss : 0.079804, loss_ce: 0.023747
2021-12-17 17:34:47,626 iteration 4151 : loss : 0.057197, loss_ce: 0.020717
2021-12-17 17:34:49,144 iteration 4152 : loss : 0.068507, loss_ce: 0.021573
2021-12-17 17:34:50,608 iteration 4153 : loss : 0.071390, loss_ce: 0.029622
2021-12-17 17:34:51,987 iteration 4154 : loss : 0.053655, loss_ce: 0.017500
2021-12-17 17:34:53,397 iteration 4155 : loss : 0.062874, loss_ce: 0.022584
2021-12-17 17:34:54,838 iteration 4156 : loss : 0.087198, loss_ce: 0.026154
2021-12-17 17:34:56,284 iteration 4157 : loss : 0.057938, loss_ce: 0.018028
2021-12-17 17:34:57,693 iteration 4158 : loss : 0.051808, loss_ce: 0.015278
2021-12-17 17:34:59,166 iteration 4159 : loss : 0.054131, loss_ce: 0.019166
2021-12-17 17:35:00,618 iteration 4160 : loss : 0.067722, loss_ce: 0.022060
2021-12-17 17:35:02,024 iteration 4161 : loss : 0.059832, loss_ce: 0.015000
2021-12-17 17:35:03,482 iteration 4162 : loss : 0.077640, loss_ce: 0.023701
2021-12-17 17:35:04,943 iteration 4163 : loss : 0.071344, loss_ce: 0.024849
2021-12-17 17:35:06,357 iteration 4164 : loss : 0.053520, loss_ce: 0.013776
2021-12-17 17:35:06,357 Training Data Eval:
2021-12-17 17:35:13,831   Average segmentation loss on training set: 0.0446
2021-12-17 17:35:13,832 Validation Data Eval:
2021-12-17 17:35:16,427   Average segmentation loss on validation set: 0.1264
2021-12-17 17:35:17,905 iteration 4165 : loss : 0.056186, loss_ce: 0.014473
 61%|████████████████▌          | 245/400 [1:51:29<1:13:01, 28.27s/it]2021-12-17 17:35:19,370 iteration 4166 : loss : 0.076705, loss_ce: 0.018413
2021-12-17 17:35:20,799 iteration 4167 : loss : 0.059386, loss_ce: 0.020467
2021-12-17 17:35:22,173 iteration 4168 : loss : 0.055323, loss_ce: 0.013250
2021-12-17 17:35:23,566 iteration 4169 : loss : 0.077949, loss_ce: 0.030825
2021-12-17 17:35:25,086 iteration 4170 : loss : 0.074937, loss_ce: 0.021151
2021-12-17 17:35:26,626 iteration 4171 : loss : 0.068374, loss_ce: 0.020570
2021-12-17 17:35:28,003 iteration 4172 : loss : 0.065432, loss_ce: 0.013438
2021-12-17 17:35:29,445 iteration 4173 : loss : 0.070647, loss_ce: 0.021048
2021-12-17 17:35:30,890 iteration 4174 : loss : 0.078105, loss_ce: 0.028891
2021-12-17 17:35:32,375 iteration 4175 : loss : 0.078078, loss_ce: 0.024404
2021-12-17 17:35:33,831 iteration 4176 : loss : 0.059624, loss_ce: 0.020466
2021-12-17 17:35:35,296 iteration 4177 : loss : 0.079523, loss_ce: 0.022117
2021-12-17 17:35:36,746 iteration 4178 : loss : 0.063065, loss_ce: 0.023049
2021-12-17 17:35:38,262 iteration 4179 : loss : 0.076814, loss_ce: 0.028422
2021-12-17 17:35:39,693 iteration 4180 : loss : 0.081887, loss_ce: 0.021360
2021-12-17 17:35:41,035 iteration 4181 : loss : 0.065675, loss_ce: 0.017746
2021-12-17 17:35:42,518 iteration 4182 : loss : 0.063309, loss_ce: 0.022489
 62%|████████████████▌          | 246/400 [1:51:54<1:09:44, 27.17s/it]2021-12-17 17:35:44,003 iteration 4183 : loss : 0.067034, loss_ce: 0.022675
2021-12-17 17:35:45,443 iteration 4184 : loss : 0.069022, loss_ce: 0.023064
2021-12-17 17:35:46,875 iteration 4185 : loss : 0.065301, loss_ce: 0.019991
2021-12-17 17:35:48,289 iteration 4186 : loss : 0.058042, loss_ce: 0.017319
2021-12-17 17:35:49,794 iteration 4187 : loss : 0.063010, loss_ce: 0.017737
2021-12-17 17:35:51,283 iteration 4188 : loss : 0.067681, loss_ce: 0.026972
2021-12-17 17:35:52,746 iteration 4189 : loss : 0.074762, loss_ce: 0.018886
2021-12-17 17:35:54,248 iteration 4190 : loss : 0.074713, loss_ce: 0.023480
2021-12-17 17:35:55,652 iteration 4191 : loss : 0.073283, loss_ce: 0.019858
2021-12-17 17:35:57,088 iteration 4192 : loss : 0.058582, loss_ce: 0.015059
2021-12-17 17:35:58,530 iteration 4193 : loss : 0.063700, loss_ce: 0.017949
2021-12-17 17:35:59,988 iteration 4194 : loss : 0.067376, loss_ce: 0.022107
2021-12-17 17:36:01,561 iteration 4195 : loss : 0.088336, loss_ce: 0.025271
2021-12-17 17:36:02,963 iteration 4196 : loss : 0.058368, loss_ce: 0.024594
2021-12-17 17:36:04,456 iteration 4197 : loss : 0.076575, loss_ce: 0.020192
2021-12-17 17:36:05,904 iteration 4198 : loss : 0.062369, loss_ce: 0.020867
2021-12-17 17:36:07,279 iteration 4199 : loss : 0.057029, loss_ce: 0.016434
 62%|████████████████▋          | 247/400 [1:52:19<1:07:26, 26.45s/it]2021-12-17 17:36:08,737 iteration 4200 : loss : 0.063445, loss_ce: 0.017083
2021-12-17 17:36:10,209 iteration 4201 : loss : 0.059574, loss_ce: 0.020671
2021-12-17 17:36:11,585 iteration 4202 : loss : 0.057608, loss_ce: 0.022269
2021-12-17 17:36:12,994 iteration 4203 : loss : 0.065700, loss_ce: 0.024695
2021-12-17 17:36:14,433 iteration 4204 : loss : 0.060465, loss_ce: 0.017104
2021-12-17 17:36:15,840 iteration 4205 : loss : 0.050561, loss_ce: 0.014847
2021-12-17 17:36:17,203 iteration 4206 : loss : 0.065827, loss_ce: 0.015658
2021-12-17 17:36:18,612 iteration 4207 : loss : 0.053232, loss_ce: 0.018304
2021-12-17 17:36:20,039 iteration 4208 : loss : 0.078683, loss_ce: 0.027901
2021-12-17 17:36:21,566 iteration 4209 : loss : 0.106446, loss_ce: 0.023493
2021-12-17 17:36:23,057 iteration 4210 : loss : 0.062132, loss_ce: 0.020921
2021-12-17 17:36:24,397 iteration 4211 : loss : 0.049426, loss_ce: 0.014842
2021-12-17 17:36:25,836 iteration 4212 : loss : 0.055724, loss_ce: 0.017112
2021-12-17 17:36:27,270 iteration 4213 : loss : 0.065712, loss_ce: 0.023358
2021-12-17 17:36:28,755 iteration 4214 : loss : 0.073225, loss_ce: 0.020000
2021-12-17 17:36:30,167 iteration 4215 : loss : 0.055534, loss_ce: 0.015989
2021-12-17 17:36:31,688 iteration 4216 : loss : 0.085416, loss_ce: 0.025859
 62%|████████████████▋          | 248/400 [1:52:43<1:05:27, 25.84s/it]2021-12-17 17:36:33,254 iteration 4217 : loss : 0.063435, loss_ce: 0.023204
2021-12-17 17:36:34,612 iteration 4218 : loss : 0.052353, loss_ce: 0.019622
2021-12-17 17:36:35,991 iteration 4219 : loss : 0.058319, loss_ce: 0.019979
2021-12-17 17:36:37,548 iteration 4220 : loss : 0.093441, loss_ce: 0.029038
2021-12-17 17:36:39,012 iteration 4221 : loss : 0.066860, loss_ce: 0.016612
2021-12-17 17:36:40,490 iteration 4222 : loss : 0.066485, loss_ce: 0.023553
2021-12-17 17:36:41,940 iteration 4223 : loss : 0.065786, loss_ce: 0.020181
2021-12-17 17:36:43,358 iteration 4224 : loss : 0.066822, loss_ce: 0.019528
2021-12-17 17:36:44,774 iteration 4225 : loss : 0.065609, loss_ce: 0.018823
2021-12-17 17:36:46,208 iteration 4226 : loss : 0.060402, loss_ce: 0.013229
2021-12-17 17:36:47,748 iteration 4227 : loss : 0.084403, loss_ce: 0.030167
2021-12-17 17:36:49,162 iteration 4228 : loss : 0.059340, loss_ce: 0.019448
2021-12-17 17:36:50,625 iteration 4229 : loss : 0.066648, loss_ce: 0.021492
2021-12-17 17:36:52,068 iteration 4230 : loss : 0.060638, loss_ce: 0.024049
2021-12-17 17:36:53,479 iteration 4231 : loss : 0.064312, loss_ce: 0.016749
2021-12-17 17:36:54,895 iteration 4232 : loss : 0.058509, loss_ce: 0.021307
2021-12-17 17:36:56,332 iteration 4233 : loss : 0.060963, loss_ce: 0.023271
 62%|████████████████▊          | 249/400 [1:53:08<1:04:07, 25.48s/it]2021-12-17 17:36:57,874 iteration 4234 : loss : 0.081780, loss_ce: 0.036218
2021-12-17 17:36:59,320 iteration 4235 : loss : 0.058477, loss_ce: 0.015429
2021-12-17 17:37:00,695 iteration 4236 : loss : 0.054253, loss_ce: 0.016492
2021-12-17 17:37:02,087 iteration 4237 : loss : 0.063184, loss_ce: 0.021502
2021-12-17 17:37:03,500 iteration 4238 : loss : 0.058520, loss_ce: 0.015474
2021-12-17 17:37:04,982 iteration 4239 : loss : 0.063760, loss_ce: 0.022083
2021-12-17 17:37:06,439 iteration 4240 : loss : 0.063175, loss_ce: 0.017660
2021-12-17 17:37:07,874 iteration 4241 : loss : 0.061875, loss_ce: 0.023277
2021-12-17 17:37:09,205 iteration 4242 : loss : 0.051792, loss_ce: 0.015536
2021-12-17 17:37:10,676 iteration 4243 : loss : 0.063379, loss_ce: 0.018842
2021-12-17 17:37:12,068 iteration 4244 : loss : 0.055230, loss_ce: 0.016153
2021-12-17 17:37:13,495 iteration 4245 : loss : 0.058646, loss_ce: 0.017318
2021-12-17 17:37:14,901 iteration 4246 : loss : 0.060257, loss_ce: 0.017484
2021-12-17 17:37:16,334 iteration 4247 : loss : 0.055417, loss_ce: 0.013927
2021-12-17 17:37:17,701 iteration 4248 : loss : 0.062336, loss_ce: 0.021372
2021-12-17 17:37:19,202 iteration 4249 : loss : 0.059535, loss_ce: 0.021675
2021-12-17 17:37:19,202 Training Data Eval:
2021-12-17 17:37:26,650   Average segmentation loss on training set: 0.0449
2021-12-17 17:37:26,650 Validation Data Eval:
2021-12-17 17:37:29,240   Average segmentation loss on validation set: 0.1221
2021-12-17 17:37:36,352 Found new lowest validation loss at iteration 4249! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/TU_3seeds/TU_RESNET_no_pretraining_SGD_best_val_loss_seed2.pth
2021-12-17 17:37:37,732 iteration 4250 : loss : 0.070256, loss_ce: 0.025178
 62%|████████████████▉          | 250/400 [1:53:49<1:15:38, 30.26s/it]2021-12-17 17:37:39,160 iteration 4251 : loss : 0.068257, loss_ce: 0.020069
2021-12-17 17:37:40,531 iteration 4252 : loss : 0.057378, loss_ce: 0.013937
2021-12-17 17:37:41,927 iteration 4253 : loss : 0.051811, loss_ce: 0.018975
2021-12-17 17:37:43,319 iteration 4254 : loss : 0.067586, loss_ce: 0.022830
2021-12-17 17:37:44,708 iteration 4255 : loss : 0.071385, loss_ce: 0.020119
2021-12-17 17:37:46,041 iteration 4256 : loss : 0.068315, loss_ce: 0.023749
2021-12-17 17:37:47,416 iteration 4257 : loss : 0.060102, loss_ce: 0.021942
2021-12-17 17:37:48,863 iteration 4258 : loss : 0.079203, loss_ce: 0.028233
2021-12-17 17:37:50,140 iteration 4259 : loss : 0.051160, loss_ce: 0.014879
2021-12-17 17:37:51,527 iteration 4260 : loss : 0.065516, loss_ce: 0.018379
2021-12-17 17:37:52,831 iteration 4261 : loss : 0.048176, loss_ce: 0.013264
2021-12-17 17:37:54,199 iteration 4262 : loss : 0.049572, loss_ce: 0.016346
2021-12-17 17:37:55,681 iteration 4263 : loss : 0.081047, loss_ce: 0.029078
2021-12-17 17:37:57,135 iteration 4264 : loss : 0.060946, loss_ce: 0.022556
2021-12-17 17:37:58,490 iteration 4265 : loss : 0.054184, loss_ce: 0.017688
2021-12-17 17:37:59,979 iteration 4266 : loss : 0.065574, loss_ce: 0.017760
2021-12-17 17:38:01,466 iteration 4267 : loss : 0.070660, loss_ce: 0.022814
 63%|████████████████▉          | 251/400 [1:54:13<1:10:16, 28.30s/it]2021-12-17 17:38:02,899 iteration 4268 : loss : 0.054308, loss_ce: 0.017926
2021-12-17 17:38:04,303 iteration 4269 : loss : 0.055727, loss_ce: 0.013334
2021-12-17 17:38:05,741 iteration 4270 : loss : 0.080171, loss_ce: 0.021836
2021-12-17 17:38:07,185 iteration 4271 : loss : 0.058165, loss_ce: 0.018151
2021-12-17 17:38:08,639 iteration 4272 : loss : 0.075440, loss_ce: 0.026863
2021-12-17 17:38:10,067 iteration 4273 : loss : 0.067920, loss_ce: 0.025203
2021-12-17 17:38:11,521 iteration 4274 : loss : 0.062876, loss_ce: 0.025073
2021-12-17 17:38:12,959 iteration 4275 : loss : 0.067354, loss_ce: 0.022727
2021-12-17 17:38:14,391 iteration 4276 : loss : 0.067528, loss_ce: 0.020135
2021-12-17 17:38:15,843 iteration 4277 : loss : 0.062199, loss_ce: 0.021084
2021-12-17 17:38:17,278 iteration 4278 : loss : 0.072172, loss_ce: 0.018735
2021-12-17 17:38:18,692 iteration 4279 : loss : 0.058456, loss_ce: 0.018734
2021-12-17 17:38:20,153 iteration 4280 : loss : 0.072329, loss_ce: 0.020206
2021-12-17 17:38:21,606 iteration 4281 : loss : 0.063640, loss_ce: 0.020453
2021-12-17 17:38:23,093 iteration 4282 : loss : 0.071026, loss_ce: 0.024432
2021-12-17 17:38:24,634 iteration 4283 : loss : 0.060939, loss_ce: 0.021842
2021-12-17 17:38:26,158 iteration 4284 : loss : 0.072292, loss_ce: 0.023872
 63%|█████████████████          | 252/400 [1:54:38<1:07:08, 27.22s/it]2021-12-17 17:38:27,594 iteration 4285 : loss : 0.054663, loss_ce: 0.020661
2021-12-17 17:38:29,025 iteration 4286 : loss : 0.055314, loss_ce: 0.016842
2021-12-17 17:38:30,497 iteration 4287 : loss : 0.068626, loss_ce: 0.022994
2021-12-17 17:38:31,904 iteration 4288 : loss : 0.050502, loss_ce: 0.012601
2021-12-17 17:38:33,311 iteration 4289 : loss : 0.054845, loss_ce: 0.019640
2021-12-17 17:38:34,773 iteration 4290 : loss : 0.057475, loss_ce: 0.017111
2021-12-17 17:38:36,277 iteration 4291 : loss : 0.060736, loss_ce: 0.023027
2021-12-17 17:38:37,761 iteration 4292 : loss : 0.064766, loss_ce: 0.024053
2021-12-17 17:38:39,129 iteration 4293 : loss : 0.055245, loss_ce: 0.016681
2021-12-17 17:38:40,548 iteration 4294 : loss : 0.060525, loss_ce: 0.024588
2021-12-17 17:38:42,126 iteration 4295 : loss : 0.065335, loss_ce: 0.020878
2021-12-17 17:38:43,562 iteration 4296 : loss : 0.052732, loss_ce: 0.014115
2021-12-17 17:38:44,990 iteration 4297 : loss : 0.051885, loss_ce: 0.013680
2021-12-17 17:38:46,509 iteration 4298 : loss : 0.062211, loss_ce: 0.017600
2021-12-17 17:38:47,988 iteration 4299 : loss : 0.058313, loss_ce: 0.013172
2021-12-17 17:38:49,528 iteration 4300 : loss : 0.082913, loss_ce: 0.023418
2021-12-17 17:38:50,977 iteration 4301 : loss : 0.078566, loss_ce: 0.025773
 63%|█████████████████          | 253/400 [1:55:02<1:04:54, 26.50s/it]2021-12-17 17:38:52,540 iteration 4302 : loss : 0.060832, loss_ce: 0.021677
2021-12-17 17:38:53,936 iteration 4303 : loss : 0.058859, loss_ce: 0.022545
2021-12-17 17:38:55,389 iteration 4304 : loss : 0.072866, loss_ce: 0.024276
2021-12-17 17:38:56,854 iteration 4305 : loss : 0.062338, loss_ce: 0.016834
2021-12-17 17:38:58,308 iteration 4306 : loss : 0.061993, loss_ce: 0.019137
2021-12-17 17:38:59,829 iteration 4307 : loss : 0.062944, loss_ce: 0.017733
2021-12-17 17:39:01,257 iteration 4308 : loss : 0.059250, loss_ce: 0.018904
2021-12-17 17:39:02,755 iteration 4309 : loss : 0.073593, loss_ce: 0.019758
2021-12-17 17:39:04,156 iteration 4310 : loss : 0.060591, loss_ce: 0.016339
2021-12-17 17:39:05,701 iteration 4311 : loss : 0.062460, loss_ce: 0.017309
2021-12-17 17:39:07,137 iteration 4312 : loss : 0.067461, loss_ce: 0.025871
2021-12-17 17:39:08,643 iteration 4313 : loss : 0.067603, loss_ce: 0.024199
2021-12-17 17:39:10,104 iteration 4314 : loss : 0.059515, loss_ce: 0.014192
2021-12-17 17:39:11,521 iteration 4315 : loss : 0.057362, loss_ce: 0.017566
2021-12-17 17:39:12,956 iteration 4316 : loss : 0.065137, loss_ce: 0.021734
2021-12-17 17:39:14,429 iteration 4317 : loss : 0.059272, loss_ce: 0.018872
2021-12-17 17:39:15,969 iteration 4318 : loss : 0.057509, loss_ce: 0.018326
 64%|█████████████████▏         | 254/400 [1:55:27<1:03:22, 26.05s/it]2021-12-17 17:39:17,429 iteration 4319 : loss : 0.051703, loss_ce: 0.016618
2021-12-17 17:39:18,781 iteration 4320 : loss : 0.057683, loss_ce: 0.020268
2021-12-17 17:39:20,373 iteration 4321 : loss : 0.088697, loss_ce: 0.032984
2021-12-17 17:39:21,809 iteration 4322 : loss : 0.066560, loss_ce: 0.020025
2021-12-17 17:39:23,251 iteration 4323 : loss : 0.074602, loss_ce: 0.023261
2021-12-17 17:39:24,735 iteration 4324 : loss : 0.050052, loss_ce: 0.016573
2021-12-17 17:39:26,173 iteration 4325 : loss : 0.076805, loss_ce: 0.022729
2021-12-17 17:39:27,674 iteration 4326 : loss : 0.078779, loss_ce: 0.023260
2021-12-17 17:39:29,214 iteration 4327 : loss : 0.057490, loss_ce: 0.018718
2021-12-17 17:39:30,698 iteration 4328 : loss : 0.059942, loss_ce: 0.021327
2021-12-17 17:39:32,120 iteration 4329 : loss : 0.062465, loss_ce: 0.019890
2021-12-17 17:39:33,517 iteration 4330 : loss : 0.056845, loss_ce: 0.022118
2021-12-17 17:39:34,960 iteration 4331 : loss : 0.056531, loss_ce: 0.018191
2021-12-17 17:39:36,369 iteration 4332 : loss : 0.051793, loss_ce: 0.014902
2021-12-17 17:39:37,724 iteration 4333 : loss : 0.048892, loss_ce: 0.016223
2021-12-17 17:39:39,187 iteration 4334 : loss : 0.063877, loss_ce: 0.017437
2021-12-17 17:39:39,188 Training Data Eval:
2021-12-17 17:39:46,702   Average segmentation loss on training set: 0.0433
2021-12-17 17:39:46,702 Validation Data Eval:
2021-12-17 17:39:49,298   Average segmentation loss on validation set: 0.1226
2021-12-17 17:39:50,792 iteration 4335 : loss : 0.098114, loss_ce: 0.023000
 64%|█████████████████▏         | 255/400 [1:56:02<1:09:18, 28.68s/it]2021-12-17 17:39:52,221 iteration 4336 : loss : 0.060454, loss_ce: 0.018485
2021-12-17 17:39:53,700 iteration 4337 : loss : 0.064996, loss_ce: 0.021786
2021-12-17 17:39:55,167 iteration 4338 : loss : 0.058715, loss_ce: 0.019034
2021-12-17 17:39:56,549 iteration 4339 : loss : 0.065599, loss_ce: 0.016103
2021-12-17 17:39:58,021 iteration 4340 : loss : 0.076112, loss_ce: 0.014817
2021-12-17 17:39:59,455 iteration 4341 : loss : 0.067615, loss_ce: 0.022531
2021-12-17 17:40:00,883 iteration 4342 : loss : 0.050646, loss_ce: 0.015183
2021-12-17 17:40:02,392 iteration 4343 : loss : 0.094755, loss_ce: 0.024844
2021-12-17 17:40:03,812 iteration 4344 : loss : 0.087981, loss_ce: 0.036151
2021-12-17 17:40:05,226 iteration 4345 : loss : 0.053428, loss_ce: 0.019649
2021-12-17 17:40:06,567 iteration 4346 : loss : 0.050806, loss_ce: 0.013809
2021-12-17 17:40:08,077 iteration 4347 : loss : 0.062215, loss_ce: 0.016394
2021-12-17 17:40:09,569 iteration 4348 : loss : 0.068312, loss_ce: 0.028977
2021-12-17 17:40:10,958 iteration 4349 : loss : 0.063884, loss_ce: 0.022463
2021-12-17 17:40:12,337 iteration 4350 : loss : 0.052597, loss_ce: 0.015067
2021-12-17 17:40:13,850 iteration 4351 : loss : 0.061751, loss_ce: 0.020396
2021-12-17 17:40:15,316 iteration 4352 : loss : 0.062207, loss_ce: 0.019440
 64%|█████████████████▎         | 256/400 [1:56:27<1:05:50, 27.43s/it]2021-12-17 17:40:16,763 iteration 4353 : loss : 0.067789, loss_ce: 0.019241
2021-12-17 17:40:18,276 iteration 4354 : loss : 0.064051, loss_ce: 0.017341
2021-12-17 17:40:19,745 iteration 4355 : loss : 0.056794, loss_ce: 0.016095
2021-12-17 17:40:21,152 iteration 4356 : loss : 0.052502, loss_ce: 0.015034
2021-12-17 17:40:22,671 iteration 4357 : loss : 0.075161, loss_ce: 0.023533
2021-12-17 17:40:24,093 iteration 4358 : loss : 0.057751, loss_ce: 0.018467
2021-12-17 17:40:25,593 iteration 4359 : loss : 0.075030, loss_ce: 0.020150
2021-12-17 17:40:26,980 iteration 4360 : loss : 0.055935, loss_ce: 0.018540
2021-12-17 17:40:28,488 iteration 4361 : loss : 0.077890, loss_ce: 0.025487
2021-12-17 17:40:29,885 iteration 4362 : loss : 0.056703, loss_ce: 0.015970
2021-12-17 17:40:31,359 iteration 4363 : loss : 0.066562, loss_ce: 0.022228
2021-12-17 17:40:32,792 iteration 4364 : loss : 0.057768, loss_ce: 0.020844
2021-12-17 17:40:34,281 iteration 4365 : loss : 0.065624, loss_ce: 0.017355
2021-12-17 17:40:35,681 iteration 4366 : loss : 0.051101, loss_ce: 0.017335
2021-12-17 17:40:37,064 iteration 4367 : loss : 0.056986, loss_ce: 0.020756
2021-12-17 17:40:38,487 iteration 4368 : loss : 0.047573, loss_ce: 0.013735
2021-12-17 17:40:39,985 iteration 4369 : loss : 0.098242, loss_ce: 0.034075
 64%|█████████████████▎         | 257/400 [1:56:51<1:03:24, 26.60s/it]2021-12-17 17:40:41,420 iteration 4370 : loss : 0.057359, loss_ce: 0.018849
2021-12-17 17:40:43,017 iteration 4371 : loss : 0.089386, loss_ce: 0.025165
2021-12-17 17:40:44,491 iteration 4372 : loss : 0.067514, loss_ce: 0.017235
2021-12-17 17:40:45,961 iteration 4373 : loss : 0.072934, loss_ce: 0.024972
2021-12-17 17:40:47,358 iteration 4374 : loss : 0.065686, loss_ce: 0.023362
2021-12-17 17:40:48,806 iteration 4375 : loss : 0.061556, loss_ce: 0.017652
2021-12-17 17:40:50,294 iteration 4376 : loss : 0.061560, loss_ce: 0.018882
2021-12-17 17:40:51,717 iteration 4377 : loss : 0.058901, loss_ce: 0.017576
2021-12-17 17:40:53,211 iteration 4378 : loss : 0.065849, loss_ce: 0.027870
2021-12-17 17:40:54,635 iteration 4379 : loss : 0.060651, loss_ce: 0.018705
2021-12-17 17:40:56,090 iteration 4380 : loss : 0.062641, loss_ce: 0.018988
2021-12-17 17:40:57,553 iteration 4381 : loss : 0.080896, loss_ce: 0.019782
2021-12-17 17:40:59,101 iteration 4382 : loss : 0.083730, loss_ce: 0.031613
2021-12-17 17:41:00,540 iteration 4383 : loss : 0.063011, loss_ce: 0.018994
2021-12-17 17:41:02,027 iteration 4384 : loss : 0.059318, loss_ce: 0.016868
2021-12-17 17:41:03,541 iteration 4385 : loss : 0.075029, loss_ce: 0.034578
2021-12-17 17:41:04,960 iteration 4386 : loss : 0.056501, loss_ce: 0.014675
 64%|█████████████████▍         | 258/400 [1:57:16<1:01:48, 26.11s/it]2021-12-17 17:41:06,504 iteration 4387 : loss : 0.078692, loss_ce: 0.017595
2021-12-17 17:41:07,970 iteration 4388 : loss : 0.060354, loss_ce: 0.023033
2021-12-17 17:41:09,443 iteration 4389 : loss : 0.065135, loss_ce: 0.024231
2021-12-17 17:41:10,929 iteration 4390 : loss : 0.058955, loss_ce: 0.019888
2021-12-17 17:41:12,447 iteration 4391 : loss : 0.074938, loss_ce: 0.023735
2021-12-17 17:41:13,907 iteration 4392 : loss : 0.061950, loss_ce: 0.022622
2021-12-17 17:41:15,433 iteration 4393 : loss : 0.063753, loss_ce: 0.024063
2021-12-17 17:41:16,803 iteration 4394 : loss : 0.050516, loss_ce: 0.015786
2021-12-17 17:41:18,255 iteration 4395 : loss : 0.051828, loss_ce: 0.019387
2021-12-17 17:41:19,705 iteration 4396 : loss : 0.085569, loss_ce: 0.029384
2021-12-17 17:41:21,079 iteration 4397 : loss : 0.052975, loss_ce: 0.013946
2021-12-17 17:41:22,531 iteration 4398 : loss : 0.061937, loss_ce: 0.018372
2021-12-17 17:41:23,986 iteration 4399 : loss : 0.067006, loss_ce: 0.016333
2021-12-17 17:41:25,391 iteration 4400 : loss : 0.053110, loss_ce: 0.014132
2021-12-17 17:41:26,882 iteration 4401 : loss : 0.063928, loss_ce: 0.026643
2021-12-17 17:41:28,260 iteration 4402 : loss : 0.059152, loss_ce: 0.016039
2021-12-17 17:41:29,718 iteration 4403 : loss : 0.060987, loss_ce: 0.017077
 65%|█████████████████▍         | 259/400 [1:57:41<1:00:24, 25.71s/it]2021-12-17 17:41:31,265 iteration 4404 : loss : 0.062531, loss_ce: 0.022176
2021-12-17 17:41:32,702 iteration 4405 : loss : 0.072412, loss_ce: 0.021862
2021-12-17 17:41:34,189 iteration 4406 : loss : 0.061235, loss_ce: 0.022397
2021-12-17 17:41:35,658 iteration 4407 : loss : 0.072171, loss_ce: 0.016626
2021-12-17 17:41:37,071 iteration 4408 : loss : 0.060993, loss_ce: 0.022860
2021-12-17 17:41:38,467 iteration 4409 : loss : 0.057223, loss_ce: 0.017478
2021-12-17 17:41:40,005 iteration 4410 : loss : 0.059646, loss_ce: 0.016748
2021-12-17 17:41:41,451 iteration 4411 : loss : 0.078746, loss_ce: 0.024672
2021-12-17 17:41:42,896 iteration 4412 : loss : 0.055412, loss_ce: 0.015689
2021-12-17 17:41:44,368 iteration 4413 : loss : 0.052997, loss_ce: 0.019257
2021-12-17 17:41:45,783 iteration 4414 : loss : 0.070477, loss_ce: 0.019647
2021-12-17 17:41:47,161 iteration 4415 : loss : 0.055318, loss_ce: 0.019917
2021-12-17 17:41:48,626 iteration 4416 : loss : 0.062037, loss_ce: 0.019177
2021-12-17 17:41:50,087 iteration 4417 : loss : 0.065206, loss_ce: 0.026227
2021-12-17 17:41:51,545 iteration 4418 : loss : 0.055088, loss_ce: 0.018440
2021-12-17 17:41:52,989 iteration 4419 : loss : 0.052638, loss_ce: 0.015133
2021-12-17 17:41:52,989 Training Data Eval:
2021-12-17 17:42:00,462   Average segmentation loss on training set: 0.0439
2021-12-17 17:42:00,462 Validation Data Eval:
2021-12-17 17:42:03,060   Average segmentation loss on validation set: 0.1173
2021-12-17 17:42:09,717 Found new lowest validation loss at iteration 4419! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/TU_3seeds/TU_RESNET_no_pretraining_SGD_best_val_loss_seed2.pth
2021-12-17 17:42:11,063 iteration 4420 : loss : 0.053379, loss_ce: 0.013796
 65%|█████████████████▌         | 260/400 [1:58:22<1:10:55, 30.40s/it]2021-12-17 17:42:12,454 iteration 4421 : loss : 0.088223, loss_ce: 0.023399
2021-12-17 17:42:13,792 iteration 4422 : loss : 0.051933, loss_ce: 0.015362
2021-12-17 17:42:15,127 iteration 4423 : loss : 0.050102, loss_ce: 0.014895
2021-12-17 17:42:16,534 iteration 4424 : loss : 0.061748, loss_ce: 0.019686
2021-12-17 17:42:17,894 iteration 4425 : loss : 0.063729, loss_ce: 0.016939
2021-12-17 17:42:19,242 iteration 4426 : loss : 0.056892, loss_ce: 0.014301
2021-12-17 17:42:20,614 iteration 4427 : loss : 0.058350, loss_ce: 0.021328
2021-12-17 17:42:22,013 iteration 4428 : loss : 0.069141, loss_ce: 0.024852
2021-12-17 17:42:23,278 iteration 4429 : loss : 0.062097, loss_ce: 0.022510
2021-12-17 17:42:24,661 iteration 4430 : loss : 0.070599, loss_ce: 0.026155
2021-12-17 17:42:26,077 iteration 4431 : loss : 0.073536, loss_ce: 0.020433
2021-12-17 17:42:27,529 iteration 4432 : loss : 0.076236, loss_ce: 0.028342
2021-12-17 17:42:28,979 iteration 4433 : loss : 0.057291, loss_ce: 0.014233
2021-12-17 17:42:30,480 iteration 4434 : loss : 0.066890, loss_ce: 0.021610
2021-12-17 17:42:31,903 iteration 4435 : loss : 0.057223, loss_ce: 0.015327
2021-12-17 17:42:33,353 iteration 4436 : loss : 0.074578, loss_ce: 0.030394
2021-12-17 17:42:34,809 iteration 4437 : loss : 0.059757, loss_ce: 0.018470
 65%|█████████████████▌         | 261/400 [1:58:46<1:05:48, 28.40s/it]2021-12-17 17:42:36,399 iteration 4438 : loss : 0.062093, loss_ce: 0.020573
2021-12-17 17:42:37,780 iteration 4439 : loss : 0.050323, loss_ce: 0.019011
2021-12-17 17:42:39,306 iteration 4440 : loss : 0.061171, loss_ce: 0.023202
2021-12-17 17:42:40,779 iteration 4441 : loss : 0.057698, loss_ce: 0.019577
2021-12-17 17:42:42,317 iteration 4442 : loss : 0.064641, loss_ce: 0.020747
2021-12-17 17:42:43,845 iteration 4443 : loss : 0.077571, loss_ce: 0.029506
2021-12-17 17:42:45,320 iteration 4444 : loss : 0.058916, loss_ce: 0.017844
2021-12-17 17:42:46,745 iteration 4445 : loss : 0.058897, loss_ce: 0.016295
2021-12-17 17:42:48,254 iteration 4446 : loss : 0.110438, loss_ce: 0.027056
2021-12-17 17:42:49,789 iteration 4447 : loss : 0.066444, loss_ce: 0.019404
2021-12-17 17:42:51,225 iteration 4448 : loss : 0.067135, loss_ce: 0.019734
2021-12-17 17:42:52,781 iteration 4449 : loss : 0.071712, loss_ce: 0.024078
2021-12-17 17:42:54,226 iteration 4450 : loss : 0.057542, loss_ce: 0.022559
2021-12-17 17:42:55,708 iteration 4451 : loss : 0.052276, loss_ce: 0.014961
2021-12-17 17:42:57,129 iteration 4452 : loss : 0.081889, loss_ce: 0.021557
2021-12-17 17:42:58,546 iteration 4453 : loss : 0.049031, loss_ce: 0.015099
2021-12-17 17:42:59,989 iteration 4454 : loss : 0.054169, loss_ce: 0.016000
 66%|█████████████████▋         | 262/400 [1:59:11<1:03:05, 27.43s/it]2021-12-17 17:43:01,451 iteration 4455 : loss : 0.066428, loss_ce: 0.020122
2021-12-17 17:43:02,832 iteration 4456 : loss : 0.060055, loss_ce: 0.016266
2021-12-17 17:43:04,290 iteration 4457 : loss : 0.057031, loss_ce: 0.018854
2021-12-17 17:43:05,717 iteration 4458 : loss : 0.057564, loss_ce: 0.017752
2021-12-17 17:43:07,206 iteration 4459 : loss : 0.101583, loss_ce: 0.024792
2021-12-17 17:43:08,618 iteration 4460 : loss : 0.046935, loss_ce: 0.015114
2021-12-17 17:43:10,051 iteration 4461 : loss : 0.051995, loss_ce: 0.019189
2021-12-17 17:43:11,574 iteration 4462 : loss : 0.080392, loss_ce: 0.024639
2021-12-17 17:43:12,962 iteration 4463 : loss : 0.048093, loss_ce: 0.013838
2021-12-17 17:43:14,380 iteration 4464 : loss : 0.052643, loss_ce: 0.019835
2021-12-17 17:43:15,924 iteration 4465 : loss : 0.077208, loss_ce: 0.020694
2021-12-17 17:43:17,294 iteration 4466 : loss : 0.049064, loss_ce: 0.015180
2021-12-17 17:43:18,763 iteration 4467 : loss : 0.068747, loss_ce: 0.025366
2021-12-17 17:43:20,220 iteration 4468 : loss : 0.083202, loss_ce: 0.023153
2021-12-17 17:43:21,680 iteration 4469 : loss : 0.056798, loss_ce: 0.013877
2021-12-17 17:43:23,130 iteration 4470 : loss : 0.061885, loss_ce: 0.021303
2021-12-17 17:43:24,628 iteration 4471 : loss : 0.068722, loss_ce: 0.016571
 66%|█████████████████▊         | 263/400 [1:59:36<1:00:43, 26.60s/it]2021-12-17 17:43:26,064 iteration 4472 : loss : 0.060958, loss_ce: 0.022753
2021-12-17 17:43:27,537 iteration 4473 : loss : 0.066331, loss_ce: 0.022782
2021-12-17 17:43:29,086 iteration 4474 : loss : 0.072169, loss_ce: 0.025895
2021-12-17 17:43:30,560 iteration 4475 : loss : 0.055161, loss_ce: 0.019234
2021-12-17 17:43:31,981 iteration 4476 : loss : 0.061880, loss_ce: 0.018568
2021-12-17 17:43:33,407 iteration 4477 : loss : 0.054667, loss_ce: 0.018337
2021-12-17 17:43:34,947 iteration 4478 : loss : 0.069462, loss_ce: 0.030402
2021-12-17 17:43:36,379 iteration 4479 : loss : 0.066862, loss_ce: 0.029288
2021-12-17 17:43:37,754 iteration 4480 : loss : 0.052957, loss_ce: 0.016961
2021-12-17 17:43:39,261 iteration 4481 : loss : 0.072782, loss_ce: 0.017908
2021-12-17 17:43:40,706 iteration 4482 : loss : 0.053471, loss_ce: 0.015067
2021-12-17 17:43:42,117 iteration 4483 : loss : 0.057764, loss_ce: 0.013935
2021-12-17 17:43:43,640 iteration 4484 : loss : 0.065462, loss_ce: 0.017362
2021-12-17 17:43:45,139 iteration 4485 : loss : 0.064169, loss_ce: 0.027664
2021-12-17 17:43:46,640 iteration 4486 : loss : 0.056076, loss_ce: 0.015518
2021-12-17 17:43:48,054 iteration 4487 : loss : 0.054837, loss_ce: 0.013022
2021-12-17 17:43:49,485 iteration 4488 : loss : 0.081941, loss_ce: 0.024061
 66%|███████████████████▏         | 264/400 [2:00:01<59:06, 26.07s/it]2021-12-17 17:43:51,015 iteration 4489 : loss : 0.061535, loss_ce: 0.022521
2021-12-17 17:43:52,413 iteration 4490 : loss : 0.055146, loss_ce: 0.022624
2021-12-17 17:43:53,906 iteration 4491 : loss : 0.071062, loss_ce: 0.021641
2021-12-17 17:43:55,435 iteration 4492 : loss : 0.055629, loss_ce: 0.018337
2021-12-17 17:43:56,853 iteration 4493 : loss : 0.074569, loss_ce: 0.025046
2021-12-17 17:43:58,303 iteration 4494 : loss : 0.056759, loss_ce: 0.016087
2021-12-17 17:43:59,758 iteration 4495 : loss : 0.092451, loss_ce: 0.032824
2021-12-17 17:44:01,175 iteration 4496 : loss : 0.057297, loss_ce: 0.021115
2021-12-17 17:44:02,690 iteration 4497 : loss : 0.072352, loss_ce: 0.026374
2021-12-17 17:44:04,132 iteration 4498 : loss : 0.074753, loss_ce: 0.018980
2021-12-17 17:44:05,601 iteration 4499 : loss : 0.064096, loss_ce: 0.017963
2021-12-17 17:44:06,988 iteration 4500 : loss : 0.054116, loss_ce: 0.016149
2021-12-17 17:44:08,401 iteration 4501 : loss : 0.047662, loss_ce: 0.010993
2021-12-17 17:44:09,821 iteration 4502 : loss : 0.057177, loss_ce: 0.014859
2021-12-17 17:44:11,355 iteration 4503 : loss : 0.067717, loss_ce: 0.024307
2021-12-17 17:44:12,795 iteration 4504 : loss : 0.073082, loss_ce: 0.026268
2021-12-17 17:44:12,795 Training Data Eval:
2021-12-17 17:44:20,287   Average segmentation loss on training set: 0.0423
2021-12-17 17:44:20,287 Validation Data Eval:
2021-12-17 17:44:22,890   Average segmentation loss on validation set: 0.1184
2021-12-17 17:44:24,383 iteration 4505 : loss : 0.056414, loss_ce: 0.018198
 66%|█████████████████▉         | 265/400 [2:00:36<1:04:37, 28.72s/it]2021-12-17 17:44:25,852 iteration 4506 : loss : 0.065802, loss_ce: 0.022318
2021-12-17 17:44:27,308 iteration 4507 : loss : 0.052159, loss_ce: 0.019018
2021-12-17 17:44:28,726 iteration 4508 : loss : 0.059577, loss_ce: 0.015182
2021-12-17 17:44:30,136 iteration 4509 : loss : 0.082086, loss_ce: 0.018267
2021-12-17 17:44:31,654 iteration 4510 : loss : 0.066992, loss_ce: 0.022415
2021-12-17 17:44:33,091 iteration 4511 : loss : 0.060906, loss_ce: 0.016786
2021-12-17 17:44:34,599 iteration 4512 : loss : 0.063816, loss_ce: 0.027254
2021-12-17 17:44:36,140 iteration 4513 : loss : 0.077505, loss_ce: 0.024190
2021-12-17 17:44:37,497 iteration 4514 : loss : 0.056870, loss_ce: 0.014958
2021-12-17 17:44:38,929 iteration 4515 : loss : 0.059500, loss_ce: 0.016768
2021-12-17 17:44:40,315 iteration 4516 : loss : 0.052893, loss_ce: 0.017137
2021-12-17 17:44:41,718 iteration 4517 : loss : 0.053449, loss_ce: 0.017882
2021-12-17 17:44:43,191 iteration 4518 : loss : 0.083369, loss_ce: 0.025047
2021-12-17 17:44:44,561 iteration 4519 : loss : 0.053050, loss_ce: 0.015411
2021-12-17 17:44:46,039 iteration 4520 : loss : 0.079549, loss_ce: 0.027439
2021-12-17 17:44:47,456 iteration 4521 : loss : 0.081749, loss_ce: 0.029464
2021-12-17 17:44:48,915 iteration 4522 : loss : 0.060141, loss_ce: 0.017816
 66%|█████████████████▉         | 266/400 [2:01:00<1:01:20, 27.47s/it]2021-12-17 17:44:50,477 iteration 4523 : loss : 0.061540, loss_ce: 0.021772
2021-12-17 17:44:51,869 iteration 4524 : loss : 0.058737, loss_ce: 0.017167
2021-12-17 17:44:53,230 iteration 4525 : loss : 0.049939, loss_ce: 0.018795
2021-12-17 17:44:54,661 iteration 4526 : loss : 0.063377, loss_ce: 0.015780
2021-12-17 17:44:56,080 iteration 4527 : loss : 0.049959, loss_ce: 0.017747
2021-12-17 17:44:57,518 iteration 4528 : loss : 0.059008, loss_ce: 0.021782
2021-12-17 17:44:58,895 iteration 4529 : loss : 0.059825, loss_ce: 0.018870
2021-12-17 17:45:00,344 iteration 4530 : loss : 0.061934, loss_ce: 0.021495
2021-12-17 17:45:01,874 iteration 4531 : loss : 0.075966, loss_ce: 0.022634
2021-12-17 17:45:03,242 iteration 4532 : loss : 0.048851, loss_ce: 0.015056
2021-12-17 17:45:04,832 iteration 4533 : loss : 0.077987, loss_ce: 0.026575
2021-12-17 17:45:06,233 iteration 4534 : loss : 0.050232, loss_ce: 0.018323
2021-12-17 17:45:07,695 iteration 4535 : loss : 0.069043, loss_ce: 0.026961
2021-12-17 17:45:09,137 iteration 4536 : loss : 0.061047, loss_ce: 0.017715
2021-12-17 17:45:10,535 iteration 4537 : loss : 0.074733, loss_ce: 0.019881
2021-12-17 17:45:11,959 iteration 4538 : loss : 0.056433, loss_ce: 0.019540
2021-12-17 17:45:13,309 iteration 4539 : loss : 0.047427, loss_ce: 0.014311
 67%|███████████████████▎         | 267/400 [2:01:25<58:50, 26.55s/it]2021-12-17 17:45:14,760 iteration 4540 : loss : 0.057316, loss_ce: 0.021785
2021-12-17 17:45:16,212 iteration 4541 : loss : 0.068598, loss_ce: 0.021856
2021-12-17 17:45:17,663 iteration 4542 : loss : 0.068155, loss_ce: 0.017099
2021-12-17 17:45:19,266 iteration 4543 : loss : 0.064502, loss_ce: 0.021108
2021-12-17 17:45:20,662 iteration 4544 : loss : 0.058830, loss_ce: 0.021229
2021-12-17 17:45:22,059 iteration 4545 : loss : 0.050054, loss_ce: 0.016018
2021-12-17 17:45:23,486 iteration 4546 : loss : 0.067068, loss_ce: 0.022057
2021-12-17 17:45:24,938 iteration 4547 : loss : 0.061355, loss_ce: 0.020459
2021-12-17 17:45:26,357 iteration 4548 : loss : 0.060271, loss_ce: 0.024273
2021-12-17 17:45:27,724 iteration 4549 : loss : 0.061657, loss_ce: 0.015583
2021-12-17 17:45:29,293 iteration 4550 : loss : 0.069216, loss_ce: 0.020334
2021-12-17 17:45:30,805 iteration 4551 : loss : 0.065681, loss_ce: 0.019011
2021-12-17 17:45:32,230 iteration 4552 : loss : 0.054437, loss_ce: 0.016146
2021-12-17 17:45:33,638 iteration 4553 : loss : 0.055108, loss_ce: 0.017020
2021-12-17 17:45:35,103 iteration 4554 : loss : 0.076632, loss_ce: 0.019591
2021-12-17 17:45:36,493 iteration 4555 : loss : 0.059610, loss_ce: 0.017944
2021-12-17 17:45:37,931 iteration 4556 : loss : 0.057323, loss_ce: 0.020112
 67%|███████████████████▍         | 268/400 [2:01:49<57:07, 25.97s/it]2021-12-17 17:45:39,396 iteration 4557 : loss : 0.048332, loss_ce: 0.019798
2021-12-17 17:45:40,853 iteration 4558 : loss : 0.071005, loss_ce: 0.026506
2021-12-17 17:45:42,335 iteration 4559 : loss : 0.061945, loss_ce: 0.017521
2021-12-17 17:45:43,781 iteration 4560 : loss : 0.067752, loss_ce: 0.019699
2021-12-17 17:45:45,280 iteration 4561 : loss : 0.073746, loss_ce: 0.018573
2021-12-17 17:45:46,686 iteration 4562 : loss : 0.053335, loss_ce: 0.013857
2021-12-17 17:45:48,154 iteration 4563 : loss : 0.060563, loss_ce: 0.022295
2021-12-17 17:45:49,632 iteration 4564 : loss : 0.101994, loss_ce: 0.034424
2021-12-17 17:45:51,151 iteration 4565 : loss : 0.066553, loss_ce: 0.019955
2021-12-17 17:45:52,642 iteration 4566 : loss : 0.069632, loss_ce: 0.028795
2021-12-17 17:45:54,079 iteration 4567 : loss : 0.063005, loss_ce: 0.021997
2021-12-17 17:45:55,521 iteration 4568 : loss : 0.058685, loss_ce: 0.016400
2021-12-17 17:45:57,056 iteration 4569 : loss : 0.106737, loss_ce: 0.017896
2021-12-17 17:45:58,586 iteration 4570 : loss : 0.073989, loss_ce: 0.028466
2021-12-17 17:46:00,007 iteration 4571 : loss : 0.068119, loss_ce: 0.025220
2021-12-17 17:46:01,386 iteration 4572 : loss : 0.057734, loss_ce: 0.019836
2021-12-17 17:46:02,858 iteration 4573 : loss : 0.085371, loss_ce: 0.033321
 67%|███████████████████▌         | 269/400 [2:02:14<56:00, 25.66s/it]2021-12-17 17:46:04,271 iteration 4574 : loss : 0.052426, loss_ce: 0.017587
2021-12-17 17:46:05,760 iteration 4575 : loss : 0.062745, loss_ce: 0.015612
2021-12-17 17:46:07,320 iteration 4576 : loss : 0.063059, loss_ce: 0.019916
2021-12-17 17:46:08,771 iteration 4577 : loss : 0.072342, loss_ce: 0.021339
2021-12-17 17:46:10,135 iteration 4578 : loss : 0.053510, loss_ce: 0.017915
2021-12-17 17:46:11,641 iteration 4579 : loss : 0.057784, loss_ce: 0.017665
2021-12-17 17:46:13,094 iteration 4580 : loss : 0.052479, loss_ce: 0.017103
2021-12-17 17:46:14,547 iteration 4581 : loss : 0.062712, loss_ce: 0.021536
2021-12-17 17:46:15,987 iteration 4582 : loss : 0.058640, loss_ce: 0.020460
2021-12-17 17:46:17,517 iteration 4583 : loss : 0.076688, loss_ce: 0.017386
2021-12-17 17:46:18,942 iteration 4584 : loss : 0.071973, loss_ce: 0.016456
2021-12-17 17:46:20,329 iteration 4585 : loss : 0.052217, loss_ce: 0.015250
2021-12-17 17:46:21,760 iteration 4586 : loss : 0.056255, loss_ce: 0.021673
2021-12-17 17:46:23,194 iteration 4587 : loss : 0.057211, loss_ce: 0.018920
2021-12-17 17:46:24,703 iteration 4588 : loss : 0.065950, loss_ce: 0.024384
2021-12-17 17:46:26,152 iteration 4589 : loss : 0.072185, loss_ce: 0.028188
2021-12-17 17:46:26,153 Training Data Eval:
2021-12-17 17:46:33,619   Average segmentation loss on training set: 0.0423
2021-12-17 17:46:33,619 Validation Data Eval:
2021-12-17 17:46:36,211   Average segmentation loss on validation set: 0.1221
2021-12-17 17:46:37,725 iteration 4590 : loss : 0.069351, loss_ce: 0.027383
 68%|██████████████████▏        | 270/400 [2:02:49<1:01:34, 28.42s/it]2021-12-17 17:46:39,355 iteration 4591 : loss : 0.073214, loss_ce: 0.021762
2021-12-17 17:46:40,789 iteration 4592 : loss : 0.066229, loss_ce: 0.028369
2021-12-17 17:46:42,238 iteration 4593 : loss : 0.068765, loss_ce: 0.023587
2021-12-17 17:46:43,695 iteration 4594 : loss : 0.062075, loss_ce: 0.019922
2021-12-17 17:46:45,137 iteration 4595 : loss : 0.053384, loss_ce: 0.017978
2021-12-17 17:46:46,679 iteration 4596 : loss : 0.066821, loss_ce: 0.022595
2021-12-17 17:46:48,064 iteration 4597 : loss : 0.075271, loss_ce: 0.019588
2021-12-17 17:46:49,433 iteration 4598 : loss : 0.051877, loss_ce: 0.012401
2021-12-17 17:46:50,857 iteration 4599 : loss : 0.077626, loss_ce: 0.031256
2021-12-17 17:46:52,318 iteration 4600 : loss : 0.061442, loss_ce: 0.021458
2021-12-17 17:46:53,790 iteration 4601 : loss : 0.067667, loss_ce: 0.030002
2021-12-17 17:46:55,308 iteration 4602 : loss : 0.066097, loss_ce: 0.024113
2021-12-17 17:46:56,833 iteration 4603 : loss : 0.074980, loss_ce: 0.021463
2021-12-17 17:46:58,213 iteration 4604 : loss : 0.058706, loss_ce: 0.019030
2021-12-17 17:46:59,658 iteration 4605 : loss : 0.057228, loss_ce: 0.015708
2021-12-17 17:47:01,091 iteration 4606 : loss : 0.062051, loss_ce: 0.019585
2021-12-17 17:47:02,530 iteration 4607 : loss : 0.062158, loss_ce: 0.020524
 68%|███████████████████▋         | 271/400 [2:03:14<58:45, 27.33s/it]2021-12-17 17:47:04,044 iteration 4608 : loss : 0.054026, loss_ce: 0.016478
2021-12-17 17:47:05,509 iteration 4609 : loss : 0.056112, loss_ce: 0.014859
2021-12-17 17:47:06,985 iteration 4610 : loss : 0.074955, loss_ce: 0.017820
2021-12-17 17:47:08,482 iteration 4611 : loss : 0.084585, loss_ce: 0.030033
2021-12-17 17:47:09,919 iteration 4612 : loss : 0.068593, loss_ce: 0.026635
2021-12-17 17:47:11,357 iteration 4613 : loss : 0.087574, loss_ce: 0.027434
2021-12-17 17:47:12,802 iteration 4614 : loss : 0.054942, loss_ce: 0.014948
2021-12-17 17:47:14,359 iteration 4615 : loss : 0.085805, loss_ce: 0.029459
2021-12-17 17:47:15,752 iteration 4616 : loss : 0.064601, loss_ce: 0.023460
2021-12-17 17:47:17,237 iteration 4617 : loss : 0.063732, loss_ce: 0.019078
2021-12-17 17:47:18,657 iteration 4618 : loss : 0.044817, loss_ce: 0.013533
2021-12-17 17:47:20,112 iteration 4619 : loss : 0.084639, loss_ce: 0.029022
2021-12-17 17:47:21,517 iteration 4620 : loss : 0.058933, loss_ce: 0.019081
2021-12-17 17:47:22,941 iteration 4621 : loss : 0.058853, loss_ce: 0.018215
2021-12-17 17:47:24,402 iteration 4622 : loss : 0.065576, loss_ce: 0.021764
2021-12-17 17:47:25,857 iteration 4623 : loss : 0.051570, loss_ce: 0.016931
2021-12-17 17:47:27,273 iteration 4624 : loss : 0.055934, loss_ce: 0.016236
 68%|███████████████████▋         | 272/400 [2:03:39<56:39, 26.56s/it]2021-12-17 17:47:28,834 iteration 4625 : loss : 0.069172, loss_ce: 0.018035
2021-12-17 17:47:30,313 iteration 4626 : loss : 0.070141, loss_ce: 0.020771
2021-12-17 17:47:31,741 iteration 4627 : loss : 0.054407, loss_ce: 0.022036
2021-12-17 17:47:33,192 iteration 4628 : loss : 0.068918, loss_ce: 0.020730
2021-12-17 17:47:34,588 iteration 4629 : loss : 0.071680, loss_ce: 0.014054
2021-12-17 17:47:36,058 iteration 4630 : loss : 0.054823, loss_ce: 0.023061
2021-12-17 17:47:37,488 iteration 4631 : loss : 0.066854, loss_ce: 0.025749
2021-12-17 17:47:38,950 iteration 4632 : loss : 0.065543, loss_ce: 0.019626
2021-12-17 17:47:40,411 iteration 4633 : loss : 0.053123, loss_ce: 0.016319
2021-12-17 17:47:41,909 iteration 4634 : loss : 0.064952, loss_ce: 0.020607
2021-12-17 17:47:43,240 iteration 4635 : loss : 0.049346, loss_ce: 0.013747
2021-12-17 17:47:44,628 iteration 4636 : loss : 0.046937, loss_ce: 0.014892
2021-12-17 17:47:46,073 iteration 4637 : loss : 0.068896, loss_ce: 0.018936
2021-12-17 17:47:47,507 iteration 4638 : loss : 0.060149, loss_ce: 0.025130
2021-12-17 17:47:48,985 iteration 4639 : loss : 0.063312, loss_ce: 0.020764
2021-12-17 17:47:50,471 iteration 4640 : loss : 0.077755, loss_ce: 0.029761
2021-12-17 17:47:51,920 iteration 4641 : loss : 0.079613, loss_ce: 0.025017
 68%|███████████████████▊         | 273/400 [2:04:03<54:59, 25.98s/it]2021-12-17 17:47:53,397 iteration 4642 : loss : 0.065798, loss_ce: 0.021658
2021-12-17 17:47:54,846 iteration 4643 : loss : 0.069078, loss_ce: 0.022740
2021-12-17 17:47:56,298 iteration 4644 : loss : 0.068252, loss_ce: 0.024784
2021-12-17 17:47:57,710 iteration 4645 : loss : 0.063475, loss_ce: 0.019568
2021-12-17 17:47:59,148 iteration 4646 : loss : 0.057192, loss_ce: 0.019943
2021-12-17 17:48:00,596 iteration 4647 : loss : 0.055934, loss_ce: 0.019389
2021-12-17 17:48:02,002 iteration 4648 : loss : 0.058733, loss_ce: 0.021203
2021-12-17 17:48:03,568 iteration 4649 : loss : 0.065967, loss_ce: 0.022372
2021-12-17 17:48:04,896 iteration 4650 : loss : 0.049576, loss_ce: 0.016330
2021-12-17 17:48:06,354 iteration 4651 : loss : 0.056196, loss_ce: 0.018007
2021-12-17 17:48:07,790 iteration 4652 : loss : 0.052182, loss_ce: 0.015873
2021-12-17 17:48:09,159 iteration 4653 : loss : 0.049240, loss_ce: 0.016157
2021-12-17 17:48:10,544 iteration 4654 : loss : 0.051064, loss_ce: 0.012896
2021-12-17 17:48:12,053 iteration 4655 : loss : 0.075263, loss_ce: 0.022073
2021-12-17 17:48:13,498 iteration 4656 : loss : 0.064464, loss_ce: 0.017245
2021-12-17 17:48:14,940 iteration 4657 : loss : 0.060474, loss_ce: 0.021713
2021-12-17 17:48:16,369 iteration 4658 : loss : 0.052474, loss_ce: 0.013747
 68%|███████████████████▊         | 274/400 [2:04:28<53:35, 25.52s/it]2021-12-17 17:48:17,864 iteration 4659 : loss : 0.054529, loss_ce: 0.016623
2021-12-17 17:48:19,260 iteration 4660 : loss : 0.050230, loss_ce: 0.015613
2021-12-17 17:48:20,747 iteration 4661 : loss : 0.060013, loss_ce: 0.021406
2021-12-17 17:48:22,089 iteration 4662 : loss : 0.056667, loss_ce: 0.021715
2021-12-17 17:48:23,618 iteration 4663 : loss : 0.071756, loss_ce: 0.025984
2021-12-17 17:48:25,046 iteration 4664 : loss : 0.053837, loss_ce: 0.015967
2021-12-17 17:48:26,463 iteration 4665 : loss : 0.068204, loss_ce: 0.022804
2021-12-17 17:48:27,945 iteration 4666 : loss : 0.082846, loss_ce: 0.028157
2021-12-17 17:48:29,437 iteration 4667 : loss : 0.073158, loss_ce: 0.020915
2021-12-17 17:48:30,863 iteration 4668 : loss : 0.053119, loss_ce: 0.017470
2021-12-17 17:48:32,355 iteration 4669 : loss : 0.062902, loss_ce: 0.020217
2021-12-17 17:48:33,818 iteration 4670 : loss : 0.066970, loss_ce: 0.018189
2021-12-17 17:48:35,235 iteration 4671 : loss : 0.059356, loss_ce: 0.017646
2021-12-17 17:48:36,648 iteration 4672 : loss : 0.045918, loss_ce: 0.014198
2021-12-17 17:48:38,011 iteration 4673 : loss : 0.052413, loss_ce: 0.014712
2021-12-17 17:48:39,473 iteration 4674 : loss : 0.059429, loss_ce: 0.013797
2021-12-17 17:48:39,473 Training Data Eval:
2021-12-17 17:48:46,956   Average segmentation loss on training set: 0.0411
2021-12-17 17:48:46,956 Validation Data Eval:
2021-12-17 17:48:49,545   Average segmentation loss on validation set: 0.1238
2021-12-17 17:48:50,927 iteration 4675 : loss : 0.048551, loss_ce: 0.015815
 69%|███████████████████▉         | 275/400 [2:05:02<58:49, 28.23s/it]2021-12-17 17:48:52,427 iteration 4676 : loss : 0.049043, loss_ce: 0.015091
2021-12-17 17:48:53,817 iteration 4677 : loss : 0.047356, loss_ce: 0.016015
2021-12-17 17:48:55,300 iteration 4678 : loss : 0.070433, loss_ce: 0.020928
2021-12-17 17:48:56,835 iteration 4679 : loss : 0.060963, loss_ce: 0.022779
2021-12-17 17:48:58,212 iteration 4680 : loss : 0.058733, loss_ce: 0.017710
2021-12-17 17:48:59,645 iteration 4681 : loss : 0.054316, loss_ce: 0.018559
2021-12-17 17:49:01,061 iteration 4682 : loss : 0.054475, loss_ce: 0.018402
2021-12-17 17:49:02,462 iteration 4683 : loss : 0.054018, loss_ce: 0.015424
2021-12-17 17:49:03,902 iteration 4684 : loss : 0.065071, loss_ce: 0.020823
2021-12-17 17:49:05,393 iteration 4685 : loss : 0.052430, loss_ce: 0.018096
2021-12-17 17:49:06,775 iteration 4686 : loss : 0.063722, loss_ce: 0.022170
2021-12-17 17:49:08,215 iteration 4687 : loss : 0.058088, loss_ce: 0.016169
2021-12-17 17:49:09,562 iteration 4688 : loss : 0.043855, loss_ce: 0.015747
2021-12-17 17:49:11,030 iteration 4689 : loss : 0.071910, loss_ce: 0.021417
2021-12-17 17:49:12,371 iteration 4690 : loss : 0.054090, loss_ce: 0.015105
2021-12-17 17:49:13,805 iteration 4691 : loss : 0.072932, loss_ce: 0.017003
2021-12-17 17:49:15,344 iteration 4692 : loss : 0.061025, loss_ce: 0.018751
 69%|████████████████████         | 276/400 [2:05:27<55:59, 27.09s/it]2021-12-17 17:49:16,813 iteration 4693 : loss : 0.062663, loss_ce: 0.022498
2021-12-17 17:49:18,238 iteration 4694 : loss : 0.064776, loss_ce: 0.018744
2021-12-17 17:49:19,695 iteration 4695 : loss : 0.068367, loss_ce: 0.022409
2021-12-17 17:49:21,149 iteration 4696 : loss : 0.060174, loss_ce: 0.020009
2021-12-17 17:49:22,530 iteration 4697 : loss : 0.066235, loss_ce: 0.022609
2021-12-17 17:49:23,924 iteration 4698 : loss : 0.061661, loss_ce: 0.018225
2021-12-17 17:49:25,328 iteration 4699 : loss : 0.057818, loss_ce: 0.015479
2021-12-17 17:49:26,738 iteration 4700 : loss : 0.068453, loss_ce: 0.022759
2021-12-17 17:49:28,142 iteration 4701 : loss : 0.049519, loss_ce: 0.012936
2021-12-17 17:49:29,624 iteration 4702 : loss : 0.062113, loss_ce: 0.019681
2021-12-17 17:49:31,075 iteration 4703 : loss : 0.062204, loss_ce: 0.024945
2021-12-17 17:49:32,546 iteration 4704 : loss : 0.074128, loss_ce: 0.015845
2021-12-17 17:49:34,019 iteration 4705 : loss : 0.081078, loss_ce: 0.018072
2021-12-17 17:49:35,378 iteration 4706 : loss : 0.061758, loss_ce: 0.019234
2021-12-17 17:49:36,785 iteration 4707 : loss : 0.059955, loss_ce: 0.017209
2021-12-17 17:49:38,205 iteration 4708 : loss : 0.065455, loss_ce: 0.025735
2021-12-17 17:49:39,613 iteration 4709 : loss : 0.064791, loss_ce: 0.022492
 69%|████████████████████         | 277/400 [2:05:51<53:47, 26.24s/it]2021-12-17 17:49:41,052 iteration 4710 : loss : 0.059886, loss_ce: 0.018364
2021-12-17 17:49:42,442 iteration 4711 : loss : 0.050681, loss_ce: 0.013246
2021-12-17 17:49:43,810 iteration 4712 : loss : 0.050577, loss_ce: 0.014942
2021-12-17 17:49:45,263 iteration 4713 : loss : 0.061460, loss_ce: 0.016872
2021-12-17 17:49:46,650 iteration 4714 : loss : 0.047931, loss_ce: 0.012998
2021-12-17 17:49:48,104 iteration 4715 : loss : 0.060616, loss_ce: 0.026682
2021-12-17 17:49:49,567 iteration 4716 : loss : 0.065995, loss_ce: 0.022688
2021-12-17 17:49:50,981 iteration 4717 : loss : 0.067550, loss_ce: 0.022644
2021-12-17 17:49:52,449 iteration 4718 : loss : 0.059643, loss_ce: 0.019431
2021-12-17 17:49:53,857 iteration 4719 : loss : 0.051192, loss_ce: 0.015134
2021-12-17 17:49:55,281 iteration 4720 : loss : 0.060337, loss_ce: 0.023260
2021-12-17 17:49:56,691 iteration 4721 : loss : 0.068526, loss_ce: 0.018790
2021-12-17 17:49:58,191 iteration 4722 : loss : 0.062974, loss_ce: 0.022486
2021-12-17 17:49:59,703 iteration 4723 : loss : 0.073259, loss_ce: 0.020537
2021-12-17 17:50:01,226 iteration 4724 : loss : 0.076249, loss_ce: 0.035892
2021-12-17 17:50:02,628 iteration 4725 : loss : 0.064587, loss_ce: 0.020219
2021-12-17 17:50:04,111 iteration 4726 : loss : 0.058995, loss_ce: 0.015667
 70%|████████████████████▏        | 278/400 [2:06:16<52:17, 25.72s/it]2021-12-17 17:50:05,596 iteration 4727 : loss : 0.052682, loss_ce: 0.014641
2021-12-17 17:50:07,056 iteration 4728 : loss : 0.050657, loss_ce: 0.015235
2021-12-17 17:50:08,456 iteration 4729 : loss : 0.061397, loss_ce: 0.016123
2021-12-17 17:50:09,901 iteration 4730 : loss : 0.063229, loss_ce: 0.020087
2021-12-17 17:50:11,332 iteration 4731 : loss : 0.062438, loss_ce: 0.015300
2021-12-17 17:50:12,773 iteration 4732 : loss : 0.069668, loss_ce: 0.021865
2021-12-17 17:50:14,168 iteration 4733 : loss : 0.061693, loss_ce: 0.019049
2021-12-17 17:50:15,566 iteration 4734 : loss : 0.046920, loss_ce: 0.014042
2021-12-17 17:50:17,066 iteration 4735 : loss : 0.064863, loss_ce: 0.026297
2021-12-17 17:50:18,517 iteration 4736 : loss : 0.052895, loss_ce: 0.018191
2021-12-17 17:50:20,036 iteration 4737 : loss : 0.081270, loss_ce: 0.027279
2021-12-17 17:50:21,530 iteration 4738 : loss : 0.081578, loss_ce: 0.014050
2021-12-17 17:50:22,955 iteration 4739 : loss : 0.049965, loss_ce: 0.014996
2021-12-17 17:50:24,334 iteration 4740 : loss : 0.052693, loss_ce: 0.017823
2021-12-17 17:50:25,746 iteration 4741 : loss : 0.068846, loss_ce: 0.031724
2021-12-17 17:50:27,100 iteration 4742 : loss : 0.051223, loss_ce: 0.016136
2021-12-17 17:50:28,542 iteration 4743 : loss : 0.049457, loss_ce: 0.014751
 70%|████████████████████▏        | 279/400 [2:06:40<51:05, 25.33s/it]2021-12-17 17:50:30,031 iteration 4744 : loss : 0.071432, loss_ce: 0.026100
2021-12-17 17:50:31,479 iteration 4745 : loss : 0.059764, loss_ce: 0.021962
2021-12-17 17:50:32,904 iteration 4746 : loss : 0.052450, loss_ce: 0.019165
2021-12-17 17:50:34,391 iteration 4747 : loss : 0.060438, loss_ce: 0.019981
2021-12-17 17:50:35,934 iteration 4748 : loss : 0.071472, loss_ce: 0.025420
2021-12-17 17:50:37,414 iteration 4749 : loss : 0.060096, loss_ce: 0.015880
2021-12-17 17:50:38,819 iteration 4750 : loss : 0.060246, loss_ce: 0.020991
2021-12-17 17:50:40,198 iteration 4751 : loss : 0.055093, loss_ce: 0.017376
2021-12-17 17:50:41,656 iteration 4752 : loss : 0.058262, loss_ce: 0.013556
2021-12-17 17:50:43,130 iteration 4753 : loss : 0.063466, loss_ce: 0.027671
2021-12-17 17:50:44,584 iteration 4754 : loss : 0.057102, loss_ce: 0.014697
2021-12-17 17:50:46,058 iteration 4755 : loss : 0.053463, loss_ce: 0.017279
2021-12-17 17:50:47,499 iteration 4756 : loss : 0.057039, loss_ce: 0.020600
2021-12-17 17:50:48,941 iteration 4757 : loss : 0.064183, loss_ce: 0.020934
2021-12-17 17:50:50,472 iteration 4758 : loss : 0.058418, loss_ce: 0.017008
2021-12-17 17:50:51,850 iteration 4759 : loss : 0.047951, loss_ce: 0.015169
2021-12-17 17:50:51,851 Training Data Eval:
2021-12-17 17:50:59,345   Average segmentation loss on training set: 0.0413
2021-12-17 17:50:59,345 Validation Data Eval:
2021-12-17 17:51:01,930   Average segmentation loss on validation set: 0.1232
2021-12-17 17:51:03,387 iteration 4760 : loss : 0.057603, loss_ce: 0.015748
 70%|████████████████████▎        | 280/400 [2:07:15<56:22, 28.19s/it]2021-12-17 17:51:04,890 iteration 4761 : loss : 0.049680, loss_ce: 0.017475
2021-12-17 17:51:06,376 iteration 4762 : loss : 0.066741, loss_ce: 0.016764
2021-12-17 17:51:07,834 iteration 4763 : loss : 0.082508, loss_ce: 0.028635
2021-12-17 17:51:09,349 iteration 4764 : loss : 0.060644, loss_ce: 0.017341
2021-12-17 17:51:10,807 iteration 4765 : loss : 0.054367, loss_ce: 0.017660
2021-12-17 17:51:12,340 iteration 4766 : loss : 0.060292, loss_ce: 0.014782
2021-12-17 17:51:13,883 iteration 4767 : loss : 0.072818, loss_ce: 0.029893
2021-12-17 17:51:15,340 iteration 4768 : loss : 0.063045, loss_ce: 0.022704
2021-12-17 17:51:16,710 iteration 4769 : loss : 0.048214, loss_ce: 0.014204
2021-12-17 17:51:18,194 iteration 4770 : loss : 0.056631, loss_ce: 0.023164
2021-12-17 17:51:19,620 iteration 4771 : loss : 0.067228, loss_ce: 0.018298
2021-12-17 17:51:21,006 iteration 4772 : loss : 0.052052, loss_ce: 0.015965
2021-12-17 17:51:22,377 iteration 4773 : loss : 0.054073, loss_ce: 0.018985
2021-12-17 17:51:23,859 iteration 4774 : loss : 0.062575, loss_ce: 0.018863
2021-12-17 17:51:25,243 iteration 4775 : loss : 0.052886, loss_ce: 0.016705
2021-12-17 17:51:26,689 iteration 4776 : loss : 0.066097, loss_ce: 0.022184
2021-12-17 17:51:28,112 iteration 4777 : loss : 0.048790, loss_ce: 0.012820
 70%|████████████████████▎        | 281/400 [2:07:40<53:50, 27.15s/it]2021-12-17 17:51:29,607 iteration 4778 : loss : 0.064750, loss_ce: 0.024023
2021-12-17 17:51:31,002 iteration 4779 : loss : 0.052988, loss_ce: 0.019772
2021-12-17 17:51:32,405 iteration 4780 : loss : 0.053504, loss_ce: 0.019429
2021-12-17 17:51:33,867 iteration 4781 : loss : 0.063813, loss_ce: 0.019537
2021-12-17 17:51:35,341 iteration 4782 : loss : 0.063285, loss_ce: 0.020923
2021-12-17 17:51:36,755 iteration 4783 : loss : 0.071104, loss_ce: 0.025642
2021-12-17 17:51:38,245 iteration 4784 : loss : 0.060602, loss_ce: 0.018526
2021-12-17 17:51:39,686 iteration 4785 : loss : 0.053540, loss_ce: 0.015610
2021-12-17 17:51:41,109 iteration 4786 : loss : 0.045715, loss_ce: 0.015182
2021-12-17 17:51:42,531 iteration 4787 : loss : 0.081003, loss_ce: 0.019416
2021-12-17 17:51:43,985 iteration 4788 : loss : 0.066575, loss_ce: 0.017416
2021-12-17 17:51:45,321 iteration 4789 : loss : 0.046329, loss_ce: 0.014244
2021-12-17 17:51:46,668 iteration 4790 : loss : 0.048913, loss_ce: 0.015804
2021-12-17 17:51:48,129 iteration 4791 : loss : 0.076529, loss_ce: 0.029594
2021-12-17 17:51:49,586 iteration 4792 : loss : 0.061974, loss_ce: 0.020276
2021-12-17 17:51:51,082 iteration 4793 : loss : 0.062742, loss_ce: 0.016079
2021-12-17 17:51:52,493 iteration 4794 : loss : 0.046582, loss_ce: 0.012020
 70%|████████████████████▍        | 282/400 [2:08:04<51:45, 26.32s/it]2021-12-17 17:51:53,998 iteration 4795 : loss : 0.059743, loss_ce: 0.017585
2021-12-17 17:51:55,461 iteration 4796 : loss : 0.052902, loss_ce: 0.012874
2021-12-17 17:51:56,897 iteration 4797 : loss : 0.049459, loss_ce: 0.014850
2021-12-17 17:51:58,359 iteration 4798 : loss : 0.053427, loss_ce: 0.016601
2021-12-17 17:51:59,780 iteration 4799 : loss : 0.050929, loss_ce: 0.010725
2021-12-17 17:52:01,244 iteration 4800 : loss : 0.057623, loss_ce: 0.017709
2021-12-17 17:52:02,661 iteration 4801 : loss : 0.059999, loss_ce: 0.022304
2021-12-17 17:52:04,144 iteration 4802 : loss : 0.052916, loss_ce: 0.016102
2021-12-17 17:52:05,582 iteration 4803 : loss : 0.065572, loss_ce: 0.020896
2021-12-17 17:52:07,059 iteration 4804 : loss : 0.056551, loss_ce: 0.018292
2021-12-17 17:52:08,580 iteration 4805 : loss : 0.079189, loss_ce: 0.026598
2021-12-17 17:52:10,051 iteration 4806 : loss : 0.076165, loss_ce: 0.014835
2021-12-17 17:52:11,431 iteration 4807 : loss : 0.063146, loss_ce: 0.015634
2021-12-17 17:52:12,911 iteration 4808 : loss : 0.061909, loss_ce: 0.018351
2021-12-17 17:52:14,299 iteration 4809 : loss : 0.048476, loss_ce: 0.017661
2021-12-17 17:52:15,731 iteration 4810 : loss : 0.059061, loss_ce: 0.018929
2021-12-17 17:52:17,205 iteration 4811 : loss : 0.070601, loss_ce: 0.025008
 71%|████████████████████▌        | 283/400 [2:08:29<50:22, 25.84s/it]2021-12-17 17:52:18,685 iteration 4812 : loss : 0.065623, loss_ce: 0.015780
2021-12-17 17:52:20,084 iteration 4813 : loss : 0.052483, loss_ce: 0.017597
2021-12-17 17:52:21,652 iteration 4814 : loss : 0.075682, loss_ce: 0.029270
2021-12-17 17:52:23,044 iteration 4815 : loss : 0.050847, loss_ce: 0.016768
2021-12-17 17:52:24,434 iteration 4816 : loss : 0.056676, loss_ce: 0.018960
2021-12-17 17:52:25,829 iteration 4817 : loss : 0.053073, loss_ce: 0.016785
2021-12-17 17:52:27,237 iteration 4818 : loss : 0.058559, loss_ce: 0.018319
2021-12-17 17:52:28,695 iteration 4819 : loss : 0.056959, loss_ce: 0.016512
2021-12-17 17:52:30,096 iteration 4820 : loss : 0.052623, loss_ce: 0.018651
2021-12-17 17:52:31,534 iteration 4821 : loss : 0.060580, loss_ce: 0.018093
2021-12-17 17:52:33,040 iteration 4822 : loss : 0.063370, loss_ce: 0.018219
2021-12-17 17:52:34,478 iteration 4823 : loss : 0.074818, loss_ce: 0.016789
2021-12-17 17:52:35,889 iteration 4824 : loss : 0.050606, loss_ce: 0.012729
2021-12-17 17:52:37,389 iteration 4825 : loss : 0.061713, loss_ce: 0.024317
2021-12-17 17:52:38,996 iteration 4826 : loss : 0.080248, loss_ce: 0.033841
2021-12-17 17:52:40,390 iteration 4827 : loss : 0.057808, loss_ce: 0.024764
2021-12-17 17:52:41,776 iteration 4828 : loss : 0.046850, loss_ce: 0.013451
 71%|████████████████████▌        | 284/400 [2:08:53<49:12, 25.45s/it]2021-12-17 17:52:43,230 iteration 4829 : loss : 0.052184, loss_ce: 0.020361
2021-12-17 17:52:44,713 iteration 4830 : loss : 0.061455, loss_ce: 0.022022
2021-12-17 17:52:46,174 iteration 4831 : loss : 0.063709, loss_ce: 0.028837
2021-12-17 17:52:47,648 iteration 4832 : loss : 0.053587, loss_ce: 0.017032
2021-12-17 17:52:49,074 iteration 4833 : loss : 0.065184, loss_ce: 0.026929
2021-12-17 17:52:50,580 iteration 4834 : loss : 0.049285, loss_ce: 0.014897
2021-12-17 17:52:51,991 iteration 4835 : loss : 0.062732, loss_ce: 0.023139
2021-12-17 17:52:53,387 iteration 4836 : loss : 0.053586, loss_ce: 0.013610
2021-12-17 17:52:54,829 iteration 4837 : loss : 0.048979, loss_ce: 0.011915
2021-12-17 17:52:56,279 iteration 4838 : loss : 0.061186, loss_ce: 0.020391
2021-12-17 17:52:57,624 iteration 4839 : loss : 0.052171, loss_ce: 0.014542
2021-12-17 17:52:59,051 iteration 4840 : loss : 0.064426, loss_ce: 0.018832
2021-12-17 17:53:00,543 iteration 4841 : loss : 0.059163, loss_ce: 0.021364
2021-12-17 17:53:02,000 iteration 4842 : loss : 0.092025, loss_ce: 0.032050
2021-12-17 17:53:03,415 iteration 4843 : loss : 0.055456, loss_ce: 0.016879
2021-12-17 17:53:04,899 iteration 4844 : loss : 0.070514, loss_ce: 0.019570
2021-12-17 17:53:04,899 Training Data Eval:
2021-12-17 17:53:12,363   Average segmentation loss on training set: 0.0406
2021-12-17 17:53:12,363 Validation Data Eval:
2021-12-17 17:53:14,959   Average segmentation loss on validation set: 0.1216
2021-12-17 17:53:16,356 iteration 4845 : loss : 0.055590, loss_ce: 0.017457
 71%|████████████████████▋        | 285/400 [2:09:28<54:02, 28.19s/it]2021-12-17 17:53:17,837 iteration 4846 : loss : 0.057404, loss_ce: 0.019230
2021-12-17 17:53:19,237 iteration 4847 : loss : 0.047392, loss_ce: 0.012730
2021-12-17 17:53:20,766 iteration 4848 : loss : 0.059904, loss_ce: 0.021201
2021-12-17 17:53:22,174 iteration 4849 : loss : 0.051777, loss_ce: 0.015240
2021-12-17 17:53:23,543 iteration 4850 : loss : 0.051999, loss_ce: 0.021031
2021-12-17 17:53:25,070 iteration 4851 : loss : 0.073764, loss_ce: 0.018053
2021-12-17 17:53:26,489 iteration 4852 : loss : 0.057715, loss_ce: 0.025517
2021-12-17 17:53:27,943 iteration 4853 : loss : 0.073784, loss_ce: 0.015850
2021-12-17 17:53:29,517 iteration 4854 : loss : 0.064908, loss_ce: 0.019127
2021-12-17 17:53:30,978 iteration 4855 : loss : 0.055727, loss_ce: 0.017233
2021-12-17 17:53:32,365 iteration 4856 : loss : 0.047718, loss_ce: 0.013599
2021-12-17 17:53:33,865 iteration 4857 : loss : 0.059209, loss_ce: 0.023099
2021-12-17 17:53:35,329 iteration 4858 : loss : 0.060489, loss_ce: 0.020490
2021-12-17 17:53:36,762 iteration 4859 : loss : 0.050907, loss_ce: 0.017241
2021-12-17 17:53:38,223 iteration 4860 : loss : 0.072578, loss_ce: 0.025088
2021-12-17 17:53:39,659 iteration 4861 : loss : 0.063736, loss_ce: 0.022299
2021-12-17 17:53:41,046 iteration 4862 : loss : 0.048342, loss_ce: 0.015331
 72%|████████████████████▋        | 286/400 [2:09:52<51:34, 27.14s/it]2021-12-17 17:53:42,486 iteration 4863 : loss : 0.051183, loss_ce: 0.014203
2021-12-17 17:53:43,976 iteration 4864 : loss : 0.061928, loss_ce: 0.018845
2021-12-17 17:53:45,499 iteration 4865 : loss : 0.078054, loss_ce: 0.017992
2021-12-17 17:53:46,922 iteration 4866 : loss : 0.046714, loss_ce: 0.015327
2021-12-17 17:53:48,372 iteration 4867 : loss : 0.054914, loss_ce: 0.018688
2021-12-17 17:53:49,782 iteration 4868 : loss : 0.049497, loss_ce: 0.019472
2021-12-17 17:53:51,196 iteration 4869 : loss : 0.054701, loss_ce: 0.018485
2021-12-17 17:53:52,722 iteration 4870 : loss : 0.066406, loss_ce: 0.019483
2021-12-17 17:53:54,186 iteration 4871 : loss : 0.052243, loss_ce: 0.016757
2021-12-17 17:53:55,562 iteration 4872 : loss : 0.055021, loss_ce: 0.019043
2021-12-17 17:53:56,930 iteration 4873 : loss : 0.054996, loss_ce: 0.016136
2021-12-17 17:53:58,290 iteration 4874 : loss : 0.047770, loss_ce: 0.016605
2021-12-17 17:53:59,725 iteration 4875 : loss : 0.052491, loss_ce: 0.014806
2021-12-17 17:54:01,099 iteration 4876 : loss : 0.052154, loss_ce: 0.015977
2021-12-17 17:54:02,639 iteration 4877 : loss : 0.059997, loss_ce: 0.020892
2021-12-17 17:54:04,062 iteration 4878 : loss : 0.062723, loss_ce: 0.017380
2021-12-17 17:54:05,475 iteration 4879 : loss : 0.054284, loss_ce: 0.017917
 72%|████████████████████▊        | 287/400 [2:10:17<49:34, 26.33s/it]2021-12-17 17:54:07,011 iteration 4880 : loss : 0.065753, loss_ce: 0.029577
2021-12-17 17:54:08,424 iteration 4881 : loss : 0.065734, loss_ce: 0.019720
2021-12-17 17:54:09,854 iteration 4882 : loss : 0.049665, loss_ce: 0.011181
2021-12-17 17:54:11,304 iteration 4883 : loss : 0.072250, loss_ce: 0.017522
2021-12-17 17:54:12,765 iteration 4884 : loss : 0.052527, loss_ce: 0.023454
2021-12-17 17:54:14,344 iteration 4885 : loss : 0.062716, loss_ce: 0.016037
2021-12-17 17:54:15,821 iteration 4886 : loss : 0.067622, loss_ce: 0.019285
2021-12-17 17:54:17,302 iteration 4887 : loss : 0.060183, loss_ce: 0.019119
2021-12-17 17:54:18,722 iteration 4888 : loss : 0.065529, loss_ce: 0.015553
2021-12-17 17:54:20,143 iteration 4889 : loss : 0.053833, loss_ce: 0.017973
2021-12-17 17:54:21,635 iteration 4890 : loss : 0.062126, loss_ce: 0.020189
2021-12-17 17:54:23,133 iteration 4891 : loss : 0.074630, loss_ce: 0.037304
2021-12-17 17:54:24,491 iteration 4892 : loss : 0.052482, loss_ce: 0.018906
2021-12-17 17:54:25,887 iteration 4893 : loss : 0.050375, loss_ce: 0.019239
2021-12-17 17:54:27,322 iteration 4894 : loss : 0.108080, loss_ce: 0.027621
2021-12-17 17:54:28,729 iteration 4895 : loss : 0.053586, loss_ce: 0.017140
2021-12-17 17:54:30,183 iteration 4896 : loss : 0.058406, loss_ce: 0.017530
 72%|████████████████████▉        | 288/400 [2:10:42<48:14, 25.84s/it]2021-12-17 17:54:31,651 iteration 4897 : loss : 0.058370, loss_ce: 0.017322
2021-12-17 17:54:33,114 iteration 4898 : loss : 0.085259, loss_ce: 0.017527
2021-12-17 17:54:34,405 iteration 4899 : loss : 0.052459, loss_ce: 0.019141
2021-12-17 17:54:35,917 iteration 4900 : loss : 0.069833, loss_ce: 0.024518
2021-12-17 17:54:37,326 iteration 4901 : loss : 0.047362, loss_ce: 0.010239
2021-12-17 17:54:38,837 iteration 4902 : loss : 0.070317, loss_ce: 0.024060
2021-12-17 17:54:40,368 iteration 4903 : loss : 0.075759, loss_ce: 0.027732
2021-12-17 17:54:41,861 iteration 4904 : loss : 0.064556, loss_ce: 0.027703
2021-12-17 17:54:43,305 iteration 4905 : loss : 0.068335, loss_ce: 0.016102
2021-12-17 17:54:44,753 iteration 4906 : loss : 0.071293, loss_ce: 0.025331
2021-12-17 17:54:46,092 iteration 4907 : loss : 0.047772, loss_ce: 0.016163
2021-12-17 17:54:47,495 iteration 4908 : loss : 0.054196, loss_ce: 0.017768
2021-12-17 17:54:48,938 iteration 4909 : loss : 0.053870, loss_ce: 0.015072
2021-12-17 17:54:50,377 iteration 4910 : loss : 0.065094, loss_ce: 0.021363
2021-12-17 17:54:51,771 iteration 4911 : loss : 0.051703, loss_ce: 0.013656
2021-12-17 17:54:53,246 iteration 4912 : loss : 0.068464, loss_ce: 0.018444
2021-12-17 17:54:54,676 iteration 4913 : loss : 0.056513, loss_ce: 0.016613
 72%|████████████████████▉        | 289/400 [2:11:06<47:03, 25.44s/it]2021-12-17 17:54:56,099 iteration 4914 : loss : 0.058179, loss_ce: 0.019843
2021-12-17 17:54:57,546 iteration 4915 : loss : 0.059949, loss_ce: 0.022715
2021-12-17 17:54:59,033 iteration 4916 : loss : 0.077526, loss_ce: 0.023638
2021-12-17 17:55:00,468 iteration 4917 : loss : 0.050980, loss_ce: 0.014379
2021-12-17 17:55:01,915 iteration 4918 : loss : 0.054762, loss_ce: 0.020523
2021-12-17 17:55:03,336 iteration 4919 : loss : 0.052269, loss_ce: 0.017327
2021-12-17 17:55:04,830 iteration 4920 : loss : 0.070918, loss_ce: 0.022837
2021-12-17 17:55:06,202 iteration 4921 : loss : 0.057361, loss_ce: 0.018710
2021-12-17 17:55:07,684 iteration 4922 : loss : 0.059820, loss_ce: 0.019385
2021-12-17 17:55:09,120 iteration 4923 : loss : 0.053627, loss_ce: 0.016698
2021-12-17 17:55:10,574 iteration 4924 : loss : 0.059470, loss_ce: 0.020117
2021-12-17 17:55:11,988 iteration 4925 : loss : 0.054999, loss_ce: 0.016861
2021-12-17 17:55:13,331 iteration 4926 : loss : 0.050340, loss_ce: 0.018500
2021-12-17 17:55:14,780 iteration 4927 : loss : 0.047362, loss_ce: 0.014918
2021-12-17 17:55:16,244 iteration 4928 : loss : 0.053403, loss_ce: 0.020619
2021-12-17 17:55:17,630 iteration 4929 : loss : 0.059425, loss_ce: 0.016341
2021-12-17 17:55:17,630 Training Data Eval:
2021-12-17 17:55:25,106   Average segmentation loss on training set: 0.0401
2021-12-17 17:55:25,106 Validation Data Eval:
2021-12-17 17:55:27,691   Average segmentation loss on validation set: 0.1198
2021-12-17 17:55:29,148 iteration 4930 : loss : 0.053604, loss_ce: 0.013258
 72%|█████████████████████        | 290/400 [2:11:41<51:36, 28.15s/it]2021-12-17 17:55:30,667 iteration 4931 : loss : 0.084447, loss_ce: 0.037014
2021-12-17 17:55:32,139 iteration 4932 : loss : 0.060635, loss_ce: 0.015534
2021-12-17 17:55:33,516 iteration 4933 : loss : 0.059609, loss_ce: 0.020895
2021-12-17 17:55:34,953 iteration 4934 : loss : 0.054470, loss_ce: 0.015562
2021-12-17 17:55:36,373 iteration 4935 : loss : 0.051219, loss_ce: 0.012748
2021-12-17 17:55:37,833 iteration 4936 : loss : 0.052658, loss_ce: 0.015024
2021-12-17 17:55:39,236 iteration 4937 : loss : 0.054219, loss_ce: 0.018643
2021-12-17 17:55:40,627 iteration 4938 : loss : 0.053603, loss_ce: 0.019163
2021-12-17 17:55:42,162 iteration 4939 : loss : 0.076048, loss_ce: 0.030891
2021-12-17 17:55:43,550 iteration 4940 : loss : 0.052191, loss_ce: 0.017022
2021-12-17 17:55:44,990 iteration 4941 : loss : 0.059230, loss_ce: 0.019380
2021-12-17 17:55:46,596 iteration 4942 : loss : 0.059577, loss_ce: 0.019975
2021-12-17 17:55:48,011 iteration 4943 : loss : 0.062406, loss_ce: 0.023136
2021-12-17 17:55:49,424 iteration 4944 : loss : 0.055727, loss_ce: 0.022441
2021-12-17 17:55:50,854 iteration 4945 : loss : 0.048434, loss_ce: 0.015607
2021-12-17 17:55:52,218 iteration 4946 : loss : 0.050244, loss_ce: 0.015813
2021-12-17 17:55:53,703 iteration 4947 : loss : 0.063212, loss_ce: 0.019226
 73%|█████████████████████        | 291/400 [2:12:05<49:10, 27.07s/it]2021-12-17 17:55:55,202 iteration 4948 : loss : 0.061173, loss_ce: 0.019580
2021-12-17 17:55:56,741 iteration 4949 : loss : 0.063646, loss_ce: 0.023907
2021-12-17 17:55:58,131 iteration 4950 : loss : 0.065130, loss_ce: 0.027714
2021-12-17 17:55:59,551 iteration 4951 : loss : 0.059035, loss_ce: 0.020281
2021-12-17 17:56:00,976 iteration 4952 : loss : 0.065639, loss_ce: 0.023695
2021-12-17 17:56:02,487 iteration 4953 : loss : 0.067304, loss_ce: 0.016074
2021-12-17 17:56:03,845 iteration 4954 : loss : 0.058462, loss_ce: 0.017071
2021-12-17 17:56:05,243 iteration 4955 : loss : 0.048653, loss_ce: 0.018005
2021-12-17 17:56:06,708 iteration 4956 : loss : 0.069561, loss_ce: 0.018449
2021-12-17 17:56:08,158 iteration 4957 : loss : 0.057997, loss_ce: 0.019016
2021-12-17 17:56:09,737 iteration 4958 : loss : 0.069149, loss_ce: 0.025979
2021-12-17 17:56:11,242 iteration 4959 : loss : 0.062085, loss_ce: 0.021305
2021-12-17 17:56:12,787 iteration 4960 : loss : 0.061528, loss_ce: 0.020992
2021-12-17 17:56:14,203 iteration 4961 : loss : 0.056329, loss_ce: 0.012566
2021-12-17 17:56:15,652 iteration 4962 : loss : 0.067407, loss_ce: 0.026478
2021-12-17 17:56:17,129 iteration 4963 : loss : 0.062241, loss_ce: 0.019807
2021-12-17 17:56:18,607 iteration 4964 : loss : 0.052977, loss_ce: 0.016021
 73%|█████████████████████▏       | 292/400 [2:12:30<47:33, 26.42s/it]2021-12-17 17:56:20,048 iteration 4965 : loss : 0.054886, loss_ce: 0.015819
2021-12-17 17:56:21,477 iteration 4966 : loss : 0.063138, loss_ce: 0.019178
2021-12-17 17:56:22,919 iteration 4967 : loss : 0.054680, loss_ce: 0.015496
2021-12-17 17:56:24,336 iteration 4968 : loss : 0.070601, loss_ce: 0.014644
2021-12-17 17:56:25,775 iteration 4969 : loss : 0.089380, loss_ce: 0.033648
2021-12-17 17:56:27,230 iteration 4970 : loss : 0.078157, loss_ce: 0.032347
2021-12-17 17:56:28,648 iteration 4971 : loss : 0.062191, loss_ce: 0.022620
2021-12-17 17:56:30,031 iteration 4972 : loss : 0.055047, loss_ce: 0.016713
2021-12-17 17:56:31,443 iteration 4973 : loss : 0.049274, loss_ce: 0.013582
2021-12-17 17:56:32,902 iteration 4974 : loss : 0.057220, loss_ce: 0.028423
2021-12-17 17:56:34,434 iteration 4975 : loss : 0.050465, loss_ce: 0.015162
2021-12-17 17:56:35,834 iteration 4976 : loss : 0.051900, loss_ce: 0.015715
2021-12-17 17:56:37,259 iteration 4977 : loss : 0.051943, loss_ce: 0.017580
2021-12-17 17:56:38,703 iteration 4978 : loss : 0.063772, loss_ce: 0.021451
2021-12-17 17:56:40,105 iteration 4979 : loss : 0.048318, loss_ce: 0.013627
2021-12-17 17:56:41,476 iteration 4980 : loss : 0.048015, loss_ce: 0.014205
2021-12-17 17:56:42,909 iteration 4981 : loss : 0.056831, loss_ce: 0.015714
 73%|█████████████████████▏       | 293/400 [2:12:54<45:59, 25.79s/it]2021-12-17 17:56:44,417 iteration 4982 : loss : 0.065913, loss_ce: 0.013443
2021-12-17 17:56:45,767 iteration 4983 : loss : 0.048864, loss_ce: 0.014061
2021-12-17 17:56:47,202 iteration 4984 : loss : 0.060081, loss_ce: 0.014539
2021-12-17 17:56:48,563 iteration 4985 : loss : 0.050274, loss_ce: 0.011750
2021-12-17 17:56:49,957 iteration 4986 : loss : 0.058179, loss_ce: 0.018959
2021-12-17 17:56:51,399 iteration 4987 : loss : 0.056129, loss_ce: 0.022416
2021-12-17 17:56:52,864 iteration 4988 : loss : 0.058507, loss_ce: 0.026125
2021-12-17 17:56:54,274 iteration 4989 : loss : 0.063268, loss_ce: 0.021306
2021-12-17 17:56:55,728 iteration 4990 : loss : 0.055829, loss_ce: 0.020119
2021-12-17 17:56:57,148 iteration 4991 : loss : 0.068812, loss_ce: 0.019893
2021-12-17 17:56:58,597 iteration 4992 : loss : 0.061095, loss_ce: 0.014946
2021-12-17 17:57:00,026 iteration 4993 : loss : 0.062834, loss_ce: 0.025845
2021-12-17 17:57:01,589 iteration 4994 : loss : 0.083811, loss_ce: 0.030266
2021-12-17 17:57:03,073 iteration 4995 : loss : 0.067093, loss_ce: 0.026539
2021-12-17 17:57:04,462 iteration 4996 : loss : 0.053845, loss_ce: 0.013775
2021-12-17 17:57:05,908 iteration 4997 : loss : 0.056108, loss_ce: 0.018172
2021-12-17 17:57:07,356 iteration 4998 : loss : 0.050023, loss_ce: 0.015883
 74%|█████████████████████▎       | 294/400 [2:13:19<44:50, 25.39s/it]2021-12-17 17:57:08,815 iteration 4999 : loss : 0.049740, loss_ce: 0.016635
2021-12-17 17:57:10,186 iteration 5000 : loss : 0.056963, loss_ce: 0.016273
2021-12-17 17:57:11,657 iteration 5001 : loss : 0.050160, loss_ce: 0.013212
2021-12-17 17:57:13,165 iteration 5002 : loss : 0.065378, loss_ce: 0.018812
2021-12-17 17:57:14,700 iteration 5003 : loss : 0.057259, loss_ce: 0.021730
2021-12-17 17:57:16,120 iteration 5004 : loss : 0.046943, loss_ce: 0.014769
2021-12-17 17:57:17,570 iteration 5005 : loss : 0.056055, loss_ce: 0.020594
2021-12-17 17:57:18,961 iteration 5006 : loss : 0.050415, loss_ce: 0.015220
2021-12-17 17:57:20,460 iteration 5007 : loss : 0.059973, loss_ce: 0.013658
2021-12-17 17:57:21,854 iteration 5008 : loss : 0.050629, loss_ce: 0.013675
2021-12-17 17:57:23,257 iteration 5009 : loss : 0.052026, loss_ce: 0.021230
2021-12-17 17:57:24,757 iteration 5010 : loss : 0.066231, loss_ce: 0.028435
2021-12-17 17:57:26,152 iteration 5011 : loss : 0.052087, loss_ce: 0.018655
2021-12-17 17:57:27,578 iteration 5012 : loss : 0.081833, loss_ce: 0.018025
2021-12-17 17:57:29,118 iteration 5013 : loss : 0.058604, loss_ce: 0.021854
2021-12-17 17:57:30,498 iteration 5014 : loss : 0.055388, loss_ce: 0.017288
2021-12-17 17:57:30,498 Training Data Eval:
2021-12-17 17:57:37,967   Average segmentation loss on training set: 0.0398
2021-12-17 17:57:37,967 Validation Data Eval:
2021-12-17 17:57:40,551   Average segmentation loss on validation set: 0.1221
2021-12-17 17:57:41,978 iteration 5015 : loss : 0.054150, loss_ce: 0.016436
 74%|█████████████████████▍       | 295/400 [2:13:53<49:16, 28.15s/it]2021-12-17 17:57:43,491 iteration 5016 : loss : 0.079415, loss_ce: 0.032744
2021-12-17 17:57:44,850 iteration 5017 : loss : 0.049526, loss_ce: 0.014817
2021-12-17 17:57:46,411 iteration 5018 : loss : 0.072430, loss_ce: 0.031468
2021-12-17 17:57:47,784 iteration 5019 : loss : 0.050134, loss_ce: 0.016180
2021-12-17 17:57:49,288 iteration 5020 : loss : 0.061840, loss_ce: 0.016204
2021-12-17 17:57:50,704 iteration 5021 : loss : 0.065293, loss_ce: 0.021666
2021-12-17 17:57:52,137 iteration 5022 : loss : 0.061507, loss_ce: 0.017691
2021-12-17 17:57:53,561 iteration 5023 : loss : 0.058369, loss_ce: 0.021206
2021-12-17 17:57:55,062 iteration 5024 : loss : 0.068246, loss_ce: 0.024905
2021-12-17 17:57:56,516 iteration 5025 : loss : 0.053541, loss_ce: 0.015341
2021-12-17 17:57:58,008 iteration 5026 : loss : 0.071180, loss_ce: 0.021866
2021-12-17 17:57:59,417 iteration 5027 : loss : 0.048022, loss_ce: 0.015578
2021-12-17 17:58:00,789 iteration 5028 : loss : 0.053320, loss_ce: 0.017885
2021-12-17 17:58:02,297 iteration 5029 : loss : 0.055516, loss_ce: 0.019551
2021-12-17 17:58:03,707 iteration 5030 : loss : 0.049483, loss_ce: 0.016327
2021-12-17 17:58:05,189 iteration 5031 : loss : 0.068215, loss_ce: 0.018826
2021-12-17 17:58:06,563 iteration 5032 : loss : 0.052423, loss_ce: 0.016787
 74%|█████████████████████▍       | 296/400 [2:14:18<46:56, 27.08s/it]2021-12-17 17:58:07,977 iteration 5033 : loss : 0.058593, loss_ce: 0.018609
2021-12-17 17:58:09,362 iteration 5034 : loss : 0.064926, loss_ce: 0.015364
2021-12-17 17:58:10,797 iteration 5035 : loss : 0.056336, loss_ce: 0.016736
2021-12-17 17:58:12,187 iteration 5036 : loss : 0.065661, loss_ce: 0.022613
2021-12-17 17:58:13,613 iteration 5037 : loss : 0.070153, loss_ce: 0.024842
2021-12-17 17:58:15,016 iteration 5038 : loss : 0.053229, loss_ce: 0.015722
2021-12-17 17:58:16,478 iteration 5039 : loss : 0.073194, loss_ce: 0.027681
2021-12-17 17:58:17,966 iteration 5040 : loss : 0.058565, loss_ce: 0.020732
2021-12-17 17:58:19,381 iteration 5041 : loss : 0.060292, loss_ce: 0.020115
2021-12-17 17:58:20,922 iteration 5042 : loss : 0.061272, loss_ce: 0.018873
2021-12-17 17:58:22,267 iteration 5043 : loss : 0.060200, loss_ce: 0.018285
2021-12-17 17:58:23,748 iteration 5044 : loss : 0.058751, loss_ce: 0.018438
2021-12-17 17:58:25,190 iteration 5045 : loss : 0.059268, loss_ce: 0.023462
2021-12-17 17:58:26,639 iteration 5046 : loss : 0.068318, loss_ce: 0.014554
2021-12-17 17:58:28,011 iteration 5047 : loss : 0.042859, loss_ce: 0.011100
2021-12-17 17:58:29,388 iteration 5048 : loss : 0.046788, loss_ce: 0.017768
2021-12-17 17:58:30,755 iteration 5049 : loss : 0.046905, loss_ce: 0.016936
 74%|█████████████████████▌       | 297/400 [2:14:42<45:00, 26.22s/it]2021-12-17 17:58:32,243 iteration 5050 : loss : 0.054531, loss_ce: 0.015475
2021-12-17 17:58:33,728 iteration 5051 : loss : 0.078617, loss_ce: 0.025567
2021-12-17 17:58:35,270 iteration 5052 : loss : 0.070696, loss_ce: 0.023780
2021-12-17 17:58:36,772 iteration 5053 : loss : 0.073074, loss_ce: 0.024186
2021-12-17 17:58:38,181 iteration 5054 : loss : 0.072119, loss_ce: 0.017313
2021-12-17 17:58:39,651 iteration 5055 : loss : 0.056523, loss_ce: 0.017674
2021-12-17 17:58:41,100 iteration 5056 : loss : 0.054252, loss_ce: 0.018790
2021-12-17 17:58:42,632 iteration 5057 : loss : 0.065122, loss_ce: 0.021622
2021-12-17 17:58:44,155 iteration 5058 : loss : 0.081174, loss_ce: 0.030188
2021-12-17 17:58:45,578 iteration 5059 : loss : 0.058101, loss_ce: 0.020075
2021-12-17 17:58:47,045 iteration 5060 : loss : 0.067846, loss_ce: 0.027556
2021-12-17 17:58:48,562 iteration 5061 : loss : 0.053649, loss_ce: 0.016462
2021-12-17 17:58:50,086 iteration 5062 : loss : 0.059528, loss_ce: 0.017792
2021-12-17 17:58:51,602 iteration 5063 : loss : 0.068102, loss_ce: 0.022598
2021-12-17 17:58:53,021 iteration 5064 : loss : 0.054103, loss_ce: 0.017447
2021-12-17 17:58:54,536 iteration 5065 : loss : 0.053906, loss_ce: 0.022801
2021-12-17 17:58:55,935 iteration 5066 : loss : 0.051928, loss_ce: 0.017358
 74%|█████████████████████▌       | 298/400 [2:15:07<44:02, 25.90s/it]2021-12-17 17:58:57,289 iteration 5067 : loss : 0.054937, loss_ce: 0.014808
2021-12-17 17:58:58,784 iteration 5068 : loss : 0.073565, loss_ce: 0.018127
2021-12-17 17:59:00,261 iteration 5069 : loss : 0.057318, loss_ce: 0.025038
2021-12-17 17:59:01,655 iteration 5070 : loss : 0.052214, loss_ce: 0.016090
2021-12-17 17:59:03,128 iteration 5071 : loss : 0.062418, loss_ce: 0.023372
2021-12-17 17:59:04,501 iteration 5072 : loss : 0.048729, loss_ce: 0.015473
2021-12-17 17:59:06,013 iteration 5073 : loss : 0.060819, loss_ce: 0.020302
2021-12-17 17:59:07,436 iteration 5074 : loss : 0.048965, loss_ce: 0.016148
2021-12-17 17:59:08,848 iteration 5075 : loss : 0.059393, loss_ce: 0.018973
2021-12-17 17:59:10,318 iteration 5076 : loss : 0.074732, loss_ce: 0.015846
2021-12-17 17:59:11,772 iteration 5077 : loss : 0.070048, loss_ce: 0.024221
2021-12-17 17:59:13,164 iteration 5078 : loss : 0.059810, loss_ce: 0.025346
2021-12-17 17:59:14,548 iteration 5079 : loss : 0.049679, loss_ce: 0.017901
2021-12-17 17:59:15,954 iteration 5080 : loss : 0.050981, loss_ce: 0.016915
2021-12-17 17:59:17,445 iteration 5081 : loss : 0.061059, loss_ce: 0.016156
2021-12-17 17:59:18,859 iteration 5082 : loss : 0.053394, loss_ce: 0.017936
2021-12-17 17:59:20,304 iteration 5083 : loss : 0.075317, loss_ce: 0.014724
 75%|█████████████████████▋       | 299/400 [2:15:32<42:49, 25.45s/it]2021-12-17 17:59:21,821 iteration 5084 : loss : 0.075467, loss_ce: 0.038750
2021-12-17 17:59:23,355 iteration 5085 : loss : 0.066101, loss_ce: 0.019609
2021-12-17 17:59:24,845 iteration 5086 : loss : 0.048903, loss_ce: 0.014572
2021-12-17 17:59:26,236 iteration 5087 : loss : 0.059531, loss_ce: 0.021643
2021-12-17 17:59:27,631 iteration 5088 : loss : 0.061304, loss_ce: 0.021387
2021-12-17 17:59:29,079 iteration 5089 : loss : 0.056968, loss_ce: 0.014529
2021-12-17 17:59:30,517 iteration 5090 : loss : 0.046639, loss_ce: 0.008917
2021-12-17 17:59:32,024 iteration 5091 : loss : 0.087755, loss_ce: 0.028367
2021-12-17 17:59:33,490 iteration 5092 : loss : 0.076690, loss_ce: 0.026021
2021-12-17 17:59:34,872 iteration 5093 : loss : 0.062376, loss_ce: 0.015233
2021-12-17 17:59:36,347 iteration 5094 : loss : 0.065175, loss_ce: 0.020208
2021-12-17 17:59:37,750 iteration 5095 : loss : 0.059556, loss_ce: 0.021859
2021-12-17 17:59:39,170 iteration 5096 : loss : 0.068759, loss_ce: 0.023496
2021-12-17 17:59:40,540 iteration 5097 : loss : 0.054697, loss_ce: 0.019760
2021-12-17 17:59:42,069 iteration 5098 : loss : 0.069451, loss_ce: 0.018619
2021-12-17 17:59:43,538 iteration 5099 : loss : 0.068243, loss_ce: 0.020399
2021-12-17 17:59:43,538 Training Data Eval:
2021-12-17 17:59:50,972   Average segmentation loss on training set: 0.0395
2021-12-17 17:59:50,973 Validation Data Eval:
2021-12-17 17:59:53,574   Average segmentation loss on validation set: 0.1135
2021-12-17 18:00:02,036 Found new lowest validation loss at iteration 5099! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/TU_3seeds/TU_RESNET_no_pretraining_SGD_best_val_loss_seed2.pth
2021-12-17 18:00:03,471 iteration 5100 : loss : 0.056202, loss_ce: 0.014092
 75%|█████████████████████▊       | 300/400 [2:16:15<51:16, 30.76s/it]2021-12-17 18:00:05,006 iteration 5101 : loss : 0.061211, loss_ce: 0.016958
2021-12-17 18:00:06,357 iteration 5102 : loss : 0.054574, loss_ce: 0.015429
2021-12-17 18:00:07,714 iteration 5103 : loss : 0.058356, loss_ce: 0.026572
2021-12-17 18:00:09,163 iteration 5104 : loss : 0.059146, loss_ce: 0.017645
2021-12-17 18:00:10,512 iteration 5105 : loss : 0.055703, loss_ce: 0.017828
2021-12-17 18:00:11,848 iteration 5106 : loss : 0.051987, loss_ce: 0.016505
2021-12-17 18:00:13,276 iteration 5107 : loss : 0.060428, loss_ce: 0.016636
2021-12-17 18:00:14,688 iteration 5108 : loss : 0.070685, loss_ce: 0.023767
2021-12-17 18:00:16,089 iteration 5109 : loss : 0.068530, loss_ce: 0.025410
2021-12-17 18:00:17,414 iteration 5110 : loss : 0.044167, loss_ce: 0.010466
2021-12-17 18:00:18,814 iteration 5111 : loss : 0.057819, loss_ce: 0.018858
2021-12-17 18:00:20,287 iteration 5112 : loss : 0.081916, loss_ce: 0.024554
2021-12-17 18:00:21,700 iteration 5113 : loss : 0.055755, loss_ce: 0.015007
2021-12-17 18:00:23,176 iteration 5114 : loss : 0.057761, loss_ce: 0.018384
2021-12-17 18:00:24,625 iteration 5115 : loss : 0.072661, loss_ce: 0.023095
2021-12-17 18:00:26,086 iteration 5116 : loss : 0.061937, loss_ce: 0.024301
2021-12-17 18:00:27,591 iteration 5117 : loss : 0.060082, loss_ce: 0.021129
 75%|█████████████████████▊       | 301/400 [2:16:39<47:28, 28.77s/it]2021-12-17 18:00:29,136 iteration 5118 : loss : 0.067199, loss_ce: 0.016821
2021-12-17 18:00:30,607 iteration 5119 : loss : 0.051619, loss_ce: 0.019011
2021-12-17 18:00:32,036 iteration 5120 : loss : 0.050866, loss_ce: 0.016637
2021-12-17 18:00:33,565 iteration 5121 : loss : 0.047373, loss_ce: 0.011846
2021-12-17 18:00:35,121 iteration 5122 : loss : 0.054478, loss_ce: 0.018532
2021-12-17 18:00:36,689 iteration 5123 : loss : 0.070703, loss_ce: 0.020315
2021-12-17 18:00:38,143 iteration 5124 : loss : 0.052231, loss_ce: 0.020459
2021-12-17 18:00:39,549 iteration 5125 : loss : 0.056695, loss_ce: 0.019551
2021-12-17 18:00:41,038 iteration 5126 : loss : 0.066239, loss_ce: 0.021093
2021-12-17 18:00:42,510 iteration 5127 : loss : 0.063172, loss_ce: 0.023700
2021-12-17 18:00:43,944 iteration 5128 : loss : 0.061126, loss_ce: 0.014753
2021-12-17 18:00:45,412 iteration 5129 : loss : 0.060940, loss_ce: 0.020465
2021-12-17 18:00:46,857 iteration 5130 : loss : 0.058079, loss_ce: 0.020245
2021-12-17 18:00:48,325 iteration 5131 : loss : 0.059479, loss_ce: 0.020657
2021-12-17 18:00:49,774 iteration 5132 : loss : 0.052153, loss_ce: 0.017069
2021-12-17 18:00:51,316 iteration 5133 : loss : 0.069349, loss_ce: 0.023086
2021-12-17 18:00:52,778 iteration 5134 : loss : 0.062920, loss_ce: 0.016327
 76%|█████████████████████▉       | 302/400 [2:17:04<45:13, 27.69s/it]2021-12-17 18:00:54,250 iteration 5135 : loss : 0.063000, loss_ce: 0.027386
2021-12-17 18:00:55,699 iteration 5136 : loss : 0.066111, loss_ce: 0.020349
2021-12-17 18:00:57,102 iteration 5137 : loss : 0.049168, loss_ce: 0.015012
2021-12-17 18:00:58,611 iteration 5138 : loss : 0.052625, loss_ce: 0.019100
2021-12-17 18:01:00,147 iteration 5139 : loss : 0.059759, loss_ce: 0.019564
2021-12-17 18:01:01,654 iteration 5140 : loss : 0.064667, loss_ce: 0.020512
2021-12-17 18:01:03,060 iteration 5141 : loss : 0.056984, loss_ce: 0.016453
2021-12-17 18:01:04,530 iteration 5142 : loss : 0.053580, loss_ce: 0.014724
2021-12-17 18:01:05,966 iteration 5143 : loss : 0.050834, loss_ce: 0.021557
2021-12-17 18:01:07,506 iteration 5144 : loss : 0.055345, loss_ce: 0.020824
2021-12-17 18:01:09,105 iteration 5145 : loss : 0.047372, loss_ce: 0.011850
2021-12-17 18:01:10,575 iteration 5146 : loss : 0.051733, loss_ce: 0.013989
2021-12-17 18:01:11,970 iteration 5147 : loss : 0.058282, loss_ce: 0.014273
2021-12-17 18:01:13,444 iteration 5148 : loss : 0.053502, loss_ce: 0.016915
2021-12-17 18:01:14,887 iteration 5149 : loss : 0.054539, loss_ce: 0.016565
2021-12-17 18:01:16,337 iteration 5150 : loss : 0.065317, loss_ce: 0.029459
2021-12-17 18:01:17,834 iteration 5151 : loss : 0.070221, loss_ce: 0.029016
 76%|█████████████████████▉       | 303/400 [2:17:29<43:29, 26.91s/it]2021-12-17 18:01:19,309 iteration 5152 : loss : 0.062527, loss_ce: 0.022937
2021-12-17 18:01:20,777 iteration 5153 : loss : 0.055893, loss_ce: 0.017783
2021-12-17 18:01:22,171 iteration 5154 : loss : 0.047456, loss_ce: 0.014348
2021-12-17 18:01:23,573 iteration 5155 : loss : 0.046591, loss_ce: 0.014850
2021-12-17 18:01:25,005 iteration 5156 : loss : 0.066616, loss_ce: 0.014989
2021-12-17 18:01:26,405 iteration 5157 : loss : 0.043759, loss_ce: 0.012913
2021-12-17 18:01:27,825 iteration 5158 : loss : 0.048343, loss_ce: 0.015519
2021-12-17 18:01:29,310 iteration 5159 : loss : 0.056149, loss_ce: 0.017452
2021-12-17 18:01:30,767 iteration 5160 : loss : 0.057370, loss_ce: 0.021186
2021-12-17 18:01:32,240 iteration 5161 : loss : 0.061721, loss_ce: 0.020194
2021-12-17 18:01:33,760 iteration 5162 : loss : 0.054410, loss_ce: 0.013576
2021-12-17 18:01:35,241 iteration 5163 : loss : 0.065163, loss_ce: 0.027318
2021-12-17 18:01:36,638 iteration 5164 : loss : 0.045828, loss_ce: 0.014279
2021-12-17 18:01:38,148 iteration 5165 : loss : 0.075973, loss_ce: 0.024900
2021-12-17 18:01:39,635 iteration 5166 : loss : 0.053099, loss_ce: 0.017610
2021-12-17 18:01:41,134 iteration 5167 : loss : 0.059552, loss_ce: 0.013730
2021-12-17 18:01:42,494 iteration 5168 : loss : 0.049443, loss_ce: 0.018062
 76%|██████████████████████       | 304/400 [2:17:54<41:58, 26.23s/it]2021-12-17 18:01:44,033 iteration 5169 : loss : 0.057933, loss_ce: 0.015355
2021-12-17 18:01:45,455 iteration 5170 : loss : 0.052290, loss_ce: 0.020509
2021-12-17 18:01:46,895 iteration 5171 : loss : 0.068210, loss_ce: 0.021471
2021-12-17 18:01:48,343 iteration 5172 : loss : 0.067458, loss_ce: 0.021959
2021-12-17 18:01:49,880 iteration 5173 : loss : 0.058034, loss_ce: 0.019629
2021-12-17 18:01:51,350 iteration 5174 : loss : 0.048523, loss_ce: 0.012635
2021-12-17 18:01:52,836 iteration 5175 : loss : 0.052991, loss_ce: 0.016653
2021-12-17 18:01:54,372 iteration 5176 : loss : 0.055829, loss_ce: 0.017126
2021-12-17 18:01:55,849 iteration 5177 : loss : 0.057702, loss_ce: 0.017712
2021-12-17 18:01:57,312 iteration 5178 : loss : 0.047627, loss_ce: 0.016330
2021-12-17 18:01:58,735 iteration 5179 : loss : 0.057342, loss_ce: 0.021365
2021-12-17 18:02:00,110 iteration 5180 : loss : 0.052780, loss_ce: 0.019828
2021-12-17 18:02:01,532 iteration 5181 : loss : 0.056516, loss_ce: 0.015353
2021-12-17 18:02:02,967 iteration 5182 : loss : 0.073393, loss_ce: 0.028746
2021-12-17 18:02:04,403 iteration 5183 : loss : 0.049543, loss_ce: 0.013715
2021-12-17 18:02:05,824 iteration 5184 : loss : 0.054163, loss_ce: 0.021486
2021-12-17 18:02:05,824 Training Data Eval:
2021-12-17 18:02:13,344   Average segmentation loss on training set: 0.0386
2021-12-17 18:02:13,345 Validation Data Eval:
2021-12-17 18:02:15,943   Average segmentation loss on validation set: 0.1211
2021-12-17 18:02:17,390 iteration 5185 : loss : 0.047446, loss_ce: 0.015144
 76%|██████████████████████       | 305/400 [2:18:29<45:38, 28.83s/it]2021-12-17 18:02:18,919 iteration 5186 : loss : 0.059264, loss_ce: 0.015719
2021-12-17 18:02:20,324 iteration 5187 : loss : 0.051357, loss_ce: 0.017259
2021-12-17 18:02:21,793 iteration 5188 : loss : 0.047413, loss_ce: 0.012734
2021-12-17 18:02:23,280 iteration 5189 : loss : 0.075890, loss_ce: 0.021070
2021-12-17 18:02:24,819 iteration 5190 : loss : 0.074552, loss_ce: 0.021067
2021-12-17 18:02:26,228 iteration 5191 : loss : 0.056216, loss_ce: 0.018816
2021-12-17 18:02:27,675 iteration 5192 : loss : 0.055396, loss_ce: 0.018172
2021-12-17 18:02:29,160 iteration 5193 : loss : 0.056426, loss_ce: 0.020238
2021-12-17 18:02:30,638 iteration 5194 : loss : 0.058929, loss_ce: 0.014699
2021-12-17 18:02:32,092 iteration 5195 : loss : 0.057455, loss_ce: 0.014066
2021-12-17 18:02:33,637 iteration 5196 : loss : 0.063798, loss_ce: 0.019416
2021-12-17 18:02:35,073 iteration 5197 : loss : 0.048755, loss_ce: 0.012537
2021-12-17 18:02:36,482 iteration 5198 : loss : 0.053119, loss_ce: 0.025935
2021-12-17 18:02:38,048 iteration 5199 : loss : 0.052544, loss_ce: 0.016192
2021-12-17 18:02:39,413 iteration 5200 : loss : 0.057604, loss_ce: 0.020874
2021-12-17 18:02:40,803 iteration 5201 : loss : 0.050899, loss_ce: 0.017835
2021-12-17 18:02:42,227 iteration 5202 : loss : 0.055414, loss_ce: 0.017882
 76%|██████████████████████▏      | 306/400 [2:18:54<43:17, 27.63s/it]2021-12-17 18:02:43,703 iteration 5203 : loss : 0.053295, loss_ce: 0.019150
2021-12-17 18:02:45,201 iteration 5204 : loss : 0.057856, loss_ce: 0.021477
2021-12-17 18:02:46,686 iteration 5205 : loss : 0.081071, loss_ce: 0.019952
2021-12-17 18:02:48,276 iteration 5206 : loss : 0.062167, loss_ce: 0.018762
2021-12-17 18:02:49,760 iteration 5207 : loss : 0.084665, loss_ce: 0.020380
2021-12-17 18:02:51,207 iteration 5208 : loss : 0.046990, loss_ce: 0.015198
2021-12-17 18:02:52,710 iteration 5209 : loss : 0.072400, loss_ce: 0.025021
2021-12-17 18:02:54,211 iteration 5210 : loss : 0.057674, loss_ce: 0.022000
2021-12-17 18:02:55,645 iteration 5211 : loss : 0.059061, loss_ce: 0.020036
2021-12-17 18:02:57,153 iteration 5212 : loss : 0.065992, loss_ce: 0.018700
2021-12-17 18:02:58,603 iteration 5213 : loss : 0.071145, loss_ce: 0.027787
2021-12-17 18:03:00,034 iteration 5214 : loss : 0.047041, loss_ce: 0.017330
2021-12-17 18:03:01,393 iteration 5215 : loss : 0.047041, loss_ce: 0.014116
2021-12-17 18:03:02,817 iteration 5216 : loss : 0.055576, loss_ce: 0.015399
2021-12-17 18:03:04,347 iteration 5217 : loss : 0.076099, loss_ce: 0.027853
2021-12-17 18:03:05,736 iteration 5218 : loss : 0.046422, loss_ce: 0.013255
2021-12-17 18:03:07,184 iteration 5219 : loss : 0.053419, loss_ce: 0.017388
 77%|██████████████████████▎      | 307/400 [2:19:19<41:35, 26.83s/it]2021-12-17 18:03:08,594 iteration 5220 : loss : 0.049007, loss_ce: 0.016901
2021-12-17 18:03:09,993 iteration 5221 : loss : 0.059106, loss_ce: 0.015361
2021-12-17 18:03:11,491 iteration 5222 : loss : 0.067143, loss_ce: 0.017886
2021-12-17 18:03:12,918 iteration 5223 : loss : 0.056268, loss_ce: 0.021255
2021-12-17 18:03:14,435 iteration 5224 : loss : 0.098959, loss_ce: 0.021367
2021-12-17 18:03:15,869 iteration 5225 : loss : 0.047272, loss_ce: 0.016720
2021-12-17 18:03:17,339 iteration 5226 : loss : 0.052736, loss_ce: 0.018875
2021-12-17 18:03:18,805 iteration 5227 : loss : 0.079148, loss_ce: 0.023290
2021-12-17 18:03:20,188 iteration 5228 : loss : 0.046888, loss_ce: 0.013402
2021-12-17 18:03:21,670 iteration 5229 : loss : 0.056688, loss_ce: 0.019268
2021-12-17 18:03:23,068 iteration 5230 : loss : 0.043684, loss_ce: 0.012175
2021-12-17 18:03:24,530 iteration 5231 : loss : 0.052287, loss_ce: 0.015171
2021-12-17 18:03:26,074 iteration 5232 : loss : 0.070166, loss_ce: 0.020721
2021-12-17 18:03:27,401 iteration 5233 : loss : 0.049043, loss_ce: 0.017149
2021-12-17 18:03:28,838 iteration 5234 : loss : 0.062101, loss_ce: 0.022094
2021-12-17 18:03:30,310 iteration 5235 : loss : 0.058355, loss_ce: 0.023739
2021-12-17 18:03:31,847 iteration 5236 : loss : 0.073313, loss_ce: 0.027477
 77%|██████████████████████▎      | 308/400 [2:19:43<40:08, 26.18s/it]2021-12-17 18:03:33,263 iteration 5237 : loss : 0.047241, loss_ce: 0.017792
2021-12-17 18:03:34,703 iteration 5238 : loss : 0.054679, loss_ce: 0.017526
2021-12-17 18:03:36,152 iteration 5239 : loss : 0.051004, loss_ce: 0.014617
2021-12-17 18:03:37,657 iteration 5240 : loss : 0.080084, loss_ce: 0.013518
2021-12-17 18:03:39,104 iteration 5241 : loss : 0.082256, loss_ce: 0.028845
2021-12-17 18:03:40,645 iteration 5242 : loss : 0.058125, loss_ce: 0.022935
2021-12-17 18:03:42,141 iteration 5243 : loss : 0.063181, loss_ce: 0.024080
2021-12-17 18:03:43,569 iteration 5244 : loss : 0.050967, loss_ce: 0.015028
2021-12-17 18:03:45,075 iteration 5245 : loss : 0.067925, loss_ce: 0.021579
2021-12-17 18:03:46,558 iteration 5246 : loss : 0.060725, loss_ce: 0.022056
2021-12-17 18:03:47,980 iteration 5247 : loss : 0.066966, loss_ce: 0.018647
2021-12-17 18:03:49,491 iteration 5248 : loss : 0.074883, loss_ce: 0.032161
2021-12-17 18:03:50,907 iteration 5249 : loss : 0.054618, loss_ce: 0.018853
2021-12-17 18:03:52,357 iteration 5250 : loss : 0.053809, loss_ce: 0.016854
2021-12-17 18:03:53,849 iteration 5251 : loss : 0.063601, loss_ce: 0.021010
2021-12-17 18:03:55,277 iteration 5252 : loss : 0.052690, loss_ce: 0.021373
2021-12-17 18:03:56,710 iteration 5253 : loss : 0.051195, loss_ce: 0.016220
 77%|██████████████████████▍      | 309/400 [2:20:08<39:06, 25.78s/it]2021-12-17 18:03:58,169 iteration 5254 : loss : 0.050803, loss_ce: 0.019175
2021-12-17 18:03:59,650 iteration 5255 : loss : 0.059096, loss_ce: 0.014254
2021-12-17 18:04:01,114 iteration 5256 : loss : 0.071970, loss_ce: 0.024650
2021-12-17 18:04:02,610 iteration 5257 : loss : 0.060352, loss_ce: 0.018778
2021-12-17 18:04:03,989 iteration 5258 : loss : 0.050590, loss_ce: 0.018193
2021-12-17 18:04:05,426 iteration 5259 : loss : 0.067960, loss_ce: 0.019185
2021-12-17 18:04:06,974 iteration 5260 : loss : 0.069512, loss_ce: 0.019290
2021-12-17 18:04:08,403 iteration 5261 : loss : 0.055090, loss_ce: 0.020432
2021-12-17 18:04:09,807 iteration 5262 : loss : 0.056308, loss_ce: 0.019911
2021-12-17 18:04:11,284 iteration 5263 : loss : 0.063637, loss_ce: 0.021429
2021-12-17 18:04:12,783 iteration 5264 : loss : 0.062621, loss_ce: 0.021939
2021-12-17 18:04:14,262 iteration 5265 : loss : 0.062562, loss_ce: 0.022700
2021-12-17 18:04:15,679 iteration 5266 : loss : 0.060415, loss_ce: 0.019032
2021-12-17 18:04:17,193 iteration 5267 : loss : 0.067517, loss_ce: 0.027671
2021-12-17 18:04:18,507 iteration 5268 : loss : 0.047594, loss_ce: 0.010650
2021-12-17 18:04:19,858 iteration 5269 : loss : 0.047668, loss_ce: 0.014637
2021-12-17 18:04:19,859 Training Data Eval:
2021-12-17 18:04:27,347   Average segmentation loss on training set: 0.0387
2021-12-17 18:04:27,347 Validation Data Eval:
2021-12-17 18:04:29,941   Average segmentation loss on validation set: 0.1140
2021-12-17 18:04:31,371 iteration 5270 : loss : 0.065978, loss_ce: 0.010146
 78%|██████████████████████▍      | 310/400 [2:20:43<42:40, 28.45s/it]2021-12-17 18:04:32,962 iteration 5271 : loss : 0.059591, loss_ce: 0.017359
2021-12-17 18:04:34,482 iteration 5272 : loss : 0.061279, loss_ce: 0.021283
2021-12-17 18:04:35,929 iteration 5273 : loss : 0.058108, loss_ce: 0.022218
2021-12-17 18:04:37,392 iteration 5274 : loss : 0.064852, loss_ce: 0.026766
2021-12-17 18:04:38,821 iteration 5275 : loss : 0.048847, loss_ce: 0.016454
2021-12-17 18:04:40,235 iteration 5276 : loss : 0.059736, loss_ce: 0.016096
2021-12-17 18:04:41,780 iteration 5277 : loss : 0.068541, loss_ce: 0.025042
2021-12-17 18:04:43,201 iteration 5278 : loss : 0.057452, loss_ce: 0.012070
2021-12-17 18:04:44,699 iteration 5279 : loss : 0.070507, loss_ce: 0.022841
2021-12-17 18:04:46,077 iteration 5280 : loss : 0.050956, loss_ce: 0.013010
2021-12-17 18:04:47,502 iteration 5281 : loss : 0.049844, loss_ce: 0.018912
2021-12-17 18:04:48,922 iteration 5282 : loss : 0.052691, loss_ce: 0.018523
2021-12-17 18:04:50,329 iteration 5283 : loss : 0.056119, loss_ce: 0.018360
2021-12-17 18:04:51,784 iteration 5284 : loss : 0.051148, loss_ce: 0.016678
2021-12-17 18:04:53,217 iteration 5285 : loss : 0.050828, loss_ce: 0.016283
2021-12-17 18:04:54,615 iteration 5286 : loss : 0.052011, loss_ce: 0.021857
2021-12-17 18:04:56,074 iteration 5287 : loss : 0.050921, loss_ce: 0.016684
 78%|██████████████████████▌      | 311/400 [2:21:08<40:31, 27.32s/it]2021-12-17 18:04:57,557 iteration 5288 : loss : 0.053188, loss_ce: 0.019730
2021-12-17 18:04:58,944 iteration 5289 : loss : 0.067957, loss_ce: 0.022427
2021-12-17 18:05:00,501 iteration 5290 : loss : 0.072313, loss_ce: 0.022244
2021-12-17 18:05:01,943 iteration 5291 : loss : 0.059248, loss_ce: 0.022278
2021-12-17 18:05:03,414 iteration 5292 : loss : 0.055416, loss_ce: 0.012280
2021-12-17 18:05:04,819 iteration 5293 : loss : 0.090507, loss_ce: 0.032079
2021-12-17 18:05:06,297 iteration 5294 : loss : 0.062553, loss_ce: 0.015005
2021-12-17 18:05:07,738 iteration 5295 : loss : 0.056200, loss_ce: 0.015542
2021-12-17 18:05:09,111 iteration 5296 : loss : 0.058517, loss_ce: 0.012756
2021-12-17 18:05:10,533 iteration 5297 : loss : 0.059091, loss_ce: 0.015755
2021-12-17 18:05:11,926 iteration 5298 : loss : 0.061613, loss_ce: 0.025156
2021-12-17 18:05:13,326 iteration 5299 : loss : 0.076538, loss_ce: 0.018061
2021-12-17 18:05:14,728 iteration 5300 : loss : 0.047169, loss_ce: 0.016567
2021-12-17 18:05:16,156 iteration 5301 : loss : 0.048585, loss_ce: 0.011109
2021-12-17 18:05:17,657 iteration 5302 : loss : 0.078158, loss_ce: 0.031924
2021-12-17 18:05:19,134 iteration 5303 : loss : 0.047122, loss_ce: 0.018777
2021-12-17 18:05:20,575 iteration 5304 : loss : 0.063235, loss_ce: 0.029720
 78%|██████████████████████▌      | 312/400 [2:21:32<38:49, 26.48s/it]2021-12-17 18:05:21,996 iteration 5305 : loss : 0.044651, loss_ce: 0.013383
2021-12-17 18:05:23,483 iteration 5306 : loss : 0.058727, loss_ce: 0.022194
2021-12-17 18:05:24,945 iteration 5307 : loss : 0.072103, loss_ce: 0.022711
2021-12-17 18:05:26,365 iteration 5308 : loss : 0.049119, loss_ce: 0.013170
2021-12-17 18:05:27,814 iteration 5309 : loss : 0.056774, loss_ce: 0.024292
2021-12-17 18:05:29,366 iteration 5310 : loss : 0.052474, loss_ce: 0.015555
2021-12-17 18:05:30,807 iteration 5311 : loss : 0.058587, loss_ce: 0.018334
2021-12-17 18:05:32,312 iteration 5312 : loss : 0.066033, loss_ce: 0.023784
2021-12-17 18:05:33,726 iteration 5313 : loss : 0.051011, loss_ce: 0.020987
2021-12-17 18:05:35,170 iteration 5314 : loss : 0.045840, loss_ce: 0.012640
2021-12-17 18:05:36,572 iteration 5315 : loss : 0.055468, loss_ce: 0.016146
2021-12-17 18:05:37,994 iteration 5316 : loss : 0.055885, loss_ce: 0.014117
2021-12-17 18:05:39,422 iteration 5317 : loss : 0.051492, loss_ce: 0.013662
2021-12-17 18:05:40,925 iteration 5318 : loss : 0.057077, loss_ce: 0.020966
2021-12-17 18:05:42,354 iteration 5319 : loss : 0.056781, loss_ce: 0.019465
2021-12-17 18:05:43,753 iteration 5320 : loss : 0.048086, loss_ce: 0.014207
2021-12-17 18:05:45,164 iteration 5321 : loss : 0.059875, loss_ce: 0.019237
 78%|██████████████████████▋      | 313/400 [2:21:57<37:34, 25.91s/it]2021-12-17 18:05:46,584 iteration 5322 : loss : 0.061552, loss_ce: 0.020270
2021-12-17 18:05:48,054 iteration 5323 : loss : 0.062307, loss_ce: 0.017764
2021-12-17 18:05:49,479 iteration 5324 : loss : 0.061544, loss_ce: 0.018291
2021-12-17 18:05:50,976 iteration 5325 : loss : 0.081832, loss_ce: 0.032320
2021-12-17 18:05:52,446 iteration 5326 : loss : 0.060500, loss_ce: 0.017487
2021-12-17 18:05:53,879 iteration 5327 : loss : 0.052564, loss_ce: 0.018649
2021-12-17 18:05:55,343 iteration 5328 : loss : 0.055255, loss_ce: 0.014796
2021-12-17 18:05:56,812 iteration 5329 : loss : 0.067494, loss_ce: 0.032477
2021-12-17 18:05:58,299 iteration 5330 : loss : 0.052397, loss_ce: 0.015518
2021-12-17 18:05:59,687 iteration 5331 : loss : 0.057197, loss_ce: 0.017997
2021-12-17 18:06:01,088 iteration 5332 : loss : 0.056375, loss_ce: 0.020089
2021-12-17 18:06:02,504 iteration 5333 : loss : 0.062515, loss_ce: 0.019307
2021-12-17 18:06:03,909 iteration 5334 : loss : 0.050430, loss_ce: 0.014016
2021-12-17 18:06:05,444 iteration 5335 : loss : 0.067219, loss_ce: 0.021057
2021-12-17 18:06:06,904 iteration 5336 : loss : 0.053407, loss_ce: 0.015912
2021-12-17 18:06:08,343 iteration 5337 : loss : 0.053286, loss_ce: 0.015854
2021-12-17 18:06:09,701 iteration 5338 : loss : 0.049523, loss_ce: 0.013848
 78%|██████████████████████▊      | 314/400 [2:22:21<36:32, 25.50s/it]2021-12-17 18:06:11,172 iteration 5339 : loss : 0.052799, loss_ce: 0.015514
2021-12-17 18:06:12,609 iteration 5340 : loss : 0.052746, loss_ce: 0.022643
2021-12-17 18:06:14,073 iteration 5341 : loss : 0.069198, loss_ce: 0.026350
2021-12-17 18:06:15,555 iteration 5342 : loss : 0.072273, loss_ce: 0.019837
2021-12-17 18:06:16,956 iteration 5343 : loss : 0.054751, loss_ce: 0.017053
2021-12-17 18:06:18,368 iteration 5344 : loss : 0.051640, loss_ce: 0.020049
2021-12-17 18:06:19,761 iteration 5345 : loss : 0.059590, loss_ce: 0.013995
2021-12-17 18:06:21,180 iteration 5346 : loss : 0.063250, loss_ce: 0.019410
2021-12-17 18:06:22,704 iteration 5347 : loss : 0.052568, loss_ce: 0.018282
2021-12-17 18:06:24,158 iteration 5348 : loss : 0.055737, loss_ce: 0.017872
2021-12-17 18:06:25,589 iteration 5349 : loss : 0.052603, loss_ce: 0.018188
2021-12-17 18:06:26,977 iteration 5350 : loss : 0.047367, loss_ce: 0.015492
2021-12-17 18:06:28,479 iteration 5351 : loss : 0.101094, loss_ce: 0.015775
2021-12-17 18:06:29,914 iteration 5352 : loss : 0.050706, loss_ce: 0.016760
2021-12-17 18:06:31,395 iteration 5353 : loss : 0.050037, loss_ce: 0.018351
2021-12-17 18:06:32,776 iteration 5354 : loss : 0.048540, loss_ce: 0.016467
2021-12-17 18:06:32,776 Training Data Eval:
2021-12-17 18:06:40,235   Average segmentation loss on training set: 0.0381
2021-12-17 18:06:40,236 Validation Data Eval:
2021-12-17 18:06:42,827   Average segmentation loss on validation set: 0.1207
2021-12-17 18:06:44,223 iteration 5355 : loss : 0.049705, loss_ce: 0.017190
 79%|██████████████████████▊      | 315/400 [2:22:56<39:57, 28.21s/it]2021-12-17 18:06:45,753 iteration 5356 : loss : 0.077797, loss_ce: 0.029055
2021-12-17 18:06:47,104 iteration 5357 : loss : 0.041784, loss_ce: 0.010565
2021-12-17 18:06:48,545 iteration 5358 : loss : 0.057248, loss_ce: 0.012114
2021-12-17 18:06:49,961 iteration 5359 : loss : 0.065046, loss_ce: 0.031214
2021-12-17 18:06:51,390 iteration 5360 : loss : 0.047556, loss_ce: 0.014915
2021-12-17 18:06:52,881 iteration 5361 : loss : 0.066958, loss_ce: 0.018899
2021-12-17 18:06:54,358 iteration 5362 : loss : 0.063617, loss_ce: 0.029727
2021-12-17 18:06:55,799 iteration 5363 : loss : 0.047597, loss_ce: 0.016495
2021-12-17 18:06:57,147 iteration 5364 : loss : 0.073305, loss_ce: 0.013074
2021-12-17 18:06:58,632 iteration 5365 : loss : 0.051501, loss_ce: 0.014573
2021-12-17 18:07:00,004 iteration 5366 : loss : 0.052901, loss_ce: 0.014392
2021-12-17 18:07:01,473 iteration 5367 : loss : 0.060051, loss_ce: 0.012753
2021-12-17 18:07:02,995 iteration 5368 : loss : 0.054546, loss_ce: 0.018400
2021-12-17 18:07:04,452 iteration 5369 : loss : 0.071538, loss_ce: 0.030739
2021-12-17 18:07:05,919 iteration 5370 : loss : 0.076455, loss_ce: 0.021264
2021-12-17 18:07:07,430 iteration 5371 : loss : 0.046437, loss_ce: 0.012108
2021-12-17 18:07:08,839 iteration 5372 : loss : 0.060365, loss_ce: 0.021049
 79%|██████████████████████▉      | 316/400 [2:23:20<37:58, 27.13s/it]2021-12-17 18:07:10,226 iteration 5373 : loss : 0.048864, loss_ce: 0.019561
2021-12-17 18:07:11,685 iteration 5374 : loss : 0.063407, loss_ce: 0.017221
2021-12-17 18:07:13,080 iteration 5375 : loss : 0.053472, loss_ce: 0.016192
2021-12-17 18:07:14,466 iteration 5376 : loss : 0.051590, loss_ce: 0.014716
2021-12-17 18:07:15,809 iteration 5377 : loss : 0.049131, loss_ce: 0.007642
2021-12-17 18:07:17,152 iteration 5378 : loss : 0.045162, loss_ce: 0.013681
2021-12-17 18:07:18,608 iteration 5379 : loss : 0.049536, loss_ce: 0.012657
2021-12-17 18:07:20,015 iteration 5380 : loss : 0.050838, loss_ce: 0.018044
2021-12-17 18:07:21,450 iteration 5381 : loss : 0.056526, loss_ce: 0.020183
2021-12-17 18:07:22,928 iteration 5382 : loss : 0.063894, loss_ce: 0.018104
2021-12-17 18:07:24,411 iteration 5383 : loss : 0.060424, loss_ce: 0.022474
2021-12-17 18:07:25,821 iteration 5384 : loss : 0.062243, loss_ce: 0.025355
2021-12-17 18:07:27,241 iteration 5385 : loss : 0.055246, loss_ce: 0.021177
2021-12-17 18:07:28,712 iteration 5386 : loss : 0.050773, loss_ce: 0.016782
2021-12-17 18:07:30,140 iteration 5387 : loss : 0.064710, loss_ce: 0.025101
2021-12-17 18:07:31,500 iteration 5388 : loss : 0.046691, loss_ce: 0.015402
2021-12-17 18:07:32,937 iteration 5389 : loss : 0.050272, loss_ce: 0.015970
 79%|██████████████████████▉      | 317/400 [2:23:44<36:16, 26.22s/it]2021-12-17 18:07:34,502 iteration 5390 : loss : 0.054263, loss_ce: 0.014624
2021-12-17 18:07:35,845 iteration 5391 : loss : 0.050139, loss_ce: 0.015581
2021-12-17 18:07:37,307 iteration 5392 : loss : 0.061980, loss_ce: 0.024332
2021-12-17 18:07:38,784 iteration 5393 : loss : 0.068960, loss_ce: 0.019756
2021-12-17 18:07:40,206 iteration 5394 : loss : 0.048558, loss_ce: 0.016295
2021-12-17 18:07:41,587 iteration 5395 : loss : 0.054962, loss_ce: 0.020548
2021-12-17 18:07:43,072 iteration 5396 : loss : 0.064196, loss_ce: 0.016042
2021-12-17 18:07:44,507 iteration 5397 : loss : 0.078370, loss_ce: 0.025750
2021-12-17 18:07:45,854 iteration 5398 : loss : 0.045026, loss_ce: 0.018109
2021-12-17 18:07:47,277 iteration 5399 : loss : 0.044950, loss_ce: 0.016053
2021-12-17 18:07:48,788 iteration 5400 : loss : 0.070116, loss_ce: 0.020985
2021-12-17 18:07:50,266 iteration 5401 : loss : 0.062321, loss_ce: 0.019025
2021-12-17 18:07:51,692 iteration 5402 : loss : 0.054940, loss_ce: 0.019052
2021-12-17 18:07:53,157 iteration 5403 : loss : 0.068429, loss_ce: 0.016914
2021-12-17 18:07:54,567 iteration 5404 : loss : 0.054546, loss_ce: 0.020260
2021-12-17 18:07:55,945 iteration 5405 : loss : 0.047633, loss_ce: 0.013957
2021-12-17 18:07:57,291 iteration 5406 : loss : 0.053597, loss_ce: 0.010905
 80%|███████████████████████      | 318/400 [2:24:09<35:04, 25.66s/it]2021-12-17 18:07:58,838 iteration 5407 : loss : 0.067644, loss_ce: 0.017178
2021-12-17 18:08:00,232 iteration 5408 : loss : 0.060056, loss_ce: 0.017841
2021-12-17 18:08:01,617 iteration 5409 : loss : 0.048315, loss_ce: 0.018714
2021-12-17 18:08:03,022 iteration 5410 : loss : 0.053306, loss_ce: 0.014749
2021-12-17 18:08:04,480 iteration 5411 : loss : 0.050339, loss_ce: 0.016442
2021-12-17 18:08:05,955 iteration 5412 : loss : 0.094709, loss_ce: 0.041520
2021-12-17 18:08:07,341 iteration 5413 : loss : 0.045508, loss_ce: 0.014477
2021-12-17 18:08:08,822 iteration 5414 : loss : 0.078485, loss_ce: 0.027241
2021-12-17 18:08:10,250 iteration 5415 : loss : 0.054687, loss_ce: 0.016262
2021-12-17 18:08:11,730 iteration 5416 : loss : 0.076254, loss_ce: 0.030426
2021-12-17 18:08:13,128 iteration 5417 : loss : 0.050500, loss_ce: 0.016201
2021-12-17 18:08:14,549 iteration 5418 : loss : 0.051994, loss_ce: 0.016861
2021-12-17 18:08:15,958 iteration 5419 : loss : 0.048747, loss_ce: 0.018584
2021-12-17 18:08:17,407 iteration 5420 : loss : 0.052806, loss_ce: 0.019753
2021-12-17 18:08:18,878 iteration 5421 : loss : 0.054635, loss_ce: 0.014445
2021-12-17 18:08:20,329 iteration 5422 : loss : 0.058503, loss_ce: 0.016719
2021-12-17 18:08:21,811 iteration 5423 : loss : 0.057481, loss_ce: 0.016570
 80%|███████████████████████▏     | 319/400 [2:24:33<34:10, 25.32s/it]2021-12-17 18:08:23,310 iteration 5424 : loss : 0.062108, loss_ce: 0.018069
2021-12-17 18:08:24,757 iteration 5425 : loss : 0.070211, loss_ce: 0.024841
2021-12-17 18:08:26,220 iteration 5426 : loss : 0.043758, loss_ce: 0.010884
2021-12-17 18:08:27,759 iteration 5427 : loss : 0.077491, loss_ce: 0.021727
2021-12-17 18:08:29,237 iteration 5428 : loss : 0.067290, loss_ce: 0.023463
2021-12-17 18:08:30,627 iteration 5429 : loss : 0.050386, loss_ce: 0.017795
2021-12-17 18:08:31,992 iteration 5430 : loss : 0.047875, loss_ce: 0.017445
2021-12-17 18:08:33,487 iteration 5431 : loss : 0.071908, loss_ce: 0.023172
2021-12-17 18:08:34,890 iteration 5432 : loss : 0.060961, loss_ce: 0.020119
2021-12-17 18:08:36,432 iteration 5433 : loss : 0.065858, loss_ce: 0.021270
2021-12-17 18:08:37,939 iteration 5434 : loss : 0.066481, loss_ce: 0.021449
2021-12-17 18:08:39,387 iteration 5435 : loss : 0.054567, loss_ce: 0.019359
2021-12-17 18:08:40,865 iteration 5436 : loss : 0.073045, loss_ce: 0.032162
2021-12-17 18:08:42,263 iteration 5437 : loss : 0.061429, loss_ce: 0.013753
2021-12-17 18:08:43,713 iteration 5438 : loss : 0.057968, loss_ce: 0.020873
2021-12-17 18:08:45,193 iteration 5439 : loss : 0.079442, loss_ce: 0.024897
2021-12-17 18:08:45,193 Training Data Eval:
2021-12-17 18:08:52,660   Average segmentation loss on training set: 0.0378
2021-12-17 18:08:52,660 Validation Data Eval:
2021-12-17 18:08:55,236   Average segmentation loss on validation set: 0.1254
2021-12-17 18:08:56,698 iteration 5440 : loss : 0.048125, loss_ce: 0.016099
 80%|███████████████████████▏     | 320/400 [2:25:08<37:35, 28.19s/it]2021-12-17 18:08:58,127 iteration 5441 : loss : 0.051307, loss_ce: 0.018923
2021-12-17 18:08:59,690 iteration 5442 : loss : 0.075311, loss_ce: 0.025563
2021-12-17 18:09:01,155 iteration 5443 : loss : 0.066538, loss_ce: 0.020792
2021-12-17 18:09:02,577 iteration 5444 : loss : 0.056852, loss_ce: 0.023607
2021-12-17 18:09:03,985 iteration 5445 : loss : 0.054531, loss_ce: 0.019619
2021-12-17 18:09:05,433 iteration 5446 : loss : 0.054394, loss_ce: 0.017248
2021-12-17 18:09:06,796 iteration 5447 : loss : 0.055107, loss_ce: 0.009087
2021-12-17 18:09:08,250 iteration 5448 : loss : 0.052986, loss_ce: 0.015968
2021-12-17 18:09:09,654 iteration 5449 : loss : 0.055778, loss_ce: 0.013640
2021-12-17 18:09:11,052 iteration 5450 : loss : 0.055687, loss_ce: 0.015886
2021-12-17 18:09:12,500 iteration 5451 : loss : 0.046363, loss_ce: 0.012737
2021-12-17 18:09:13,952 iteration 5452 : loss : 0.047342, loss_ce: 0.016624
2021-12-17 18:09:15,432 iteration 5453 : loss : 0.057545, loss_ce: 0.019042
2021-12-17 18:09:16,886 iteration 5454 : loss : 0.059415, loss_ce: 0.022369
2021-12-17 18:09:18,328 iteration 5455 : loss : 0.062578, loss_ce: 0.026154
2021-12-17 18:09:19,813 iteration 5456 : loss : 0.050547, loss_ce: 0.014019
2021-12-17 18:09:21,279 iteration 5457 : loss : 0.055019, loss_ce: 0.017631
 80%|███████████████████████▎     | 321/400 [2:25:33<35:41, 27.11s/it]2021-12-17 18:09:22,830 iteration 5458 : loss : 0.059969, loss_ce: 0.015467
2021-12-17 18:09:24,216 iteration 5459 : loss : 0.046218, loss_ce: 0.013811
2021-12-17 18:09:25,647 iteration 5460 : loss : 0.061502, loss_ce: 0.022902
2021-12-17 18:09:27,104 iteration 5461 : loss : 0.056433, loss_ce: 0.017744
2021-12-17 18:09:28,573 iteration 5462 : loss : 0.059387, loss_ce: 0.020818
2021-12-17 18:09:29,971 iteration 5463 : loss : 0.044585, loss_ce: 0.012787
2021-12-17 18:09:31,519 iteration 5464 : loss : 0.073315, loss_ce: 0.025874
2021-12-17 18:09:32,919 iteration 5465 : loss : 0.061930, loss_ce: 0.021275
2021-12-17 18:09:34,336 iteration 5466 : loss : 0.053624, loss_ce: 0.018167
2021-12-17 18:09:35,850 iteration 5467 : loss : 0.059719, loss_ce: 0.017217
2021-12-17 18:09:37,343 iteration 5468 : loss : 0.068304, loss_ce: 0.022827
2021-12-17 18:09:38,829 iteration 5469 : loss : 0.072225, loss_ce: 0.026352
2021-12-17 18:09:40,236 iteration 5470 : loss : 0.057741, loss_ce: 0.022081
2021-12-17 18:09:41,650 iteration 5471 : loss : 0.053392, loss_ce: 0.021275
2021-12-17 18:09:43,161 iteration 5472 : loss : 0.065694, loss_ce: 0.025815
2021-12-17 18:09:44,588 iteration 5473 : loss : 0.051499, loss_ce: 0.013259
2021-12-17 18:09:46,082 iteration 5474 : loss : 0.050855, loss_ce: 0.014644
 80%|███████████████████████▎     | 322/400 [2:25:58<34:20, 26.42s/it]2021-12-17 18:09:47,503 iteration 5475 : loss : 0.056910, loss_ce: 0.018539
2021-12-17 18:09:48,922 iteration 5476 : loss : 0.044299, loss_ce: 0.016766
2021-12-17 18:09:50,399 iteration 5477 : loss : 0.047002, loss_ce: 0.014516
2021-12-17 18:09:51,887 iteration 5478 : loss : 0.061890, loss_ce: 0.023165
2021-12-17 18:09:53,282 iteration 5479 : loss : 0.061254, loss_ce: 0.014634
2021-12-17 18:09:54,711 iteration 5480 : loss : 0.068433, loss_ce: 0.013510
2021-12-17 18:09:56,155 iteration 5481 : loss : 0.064324, loss_ce: 0.023945
2021-12-17 18:09:57,592 iteration 5482 : loss : 0.052788, loss_ce: 0.016467
2021-12-17 18:09:58,980 iteration 5483 : loss : 0.055281, loss_ce: 0.017579
2021-12-17 18:10:00,481 iteration 5484 : loss : 0.068099, loss_ce: 0.023949
2021-12-17 18:10:01,849 iteration 5485 : loss : 0.047055, loss_ce: 0.019092
2021-12-17 18:10:03,394 iteration 5486 : loss : 0.065683, loss_ce: 0.017736
2021-12-17 18:10:04,777 iteration 5487 : loss : 0.053984, loss_ce: 0.023433
2021-12-17 18:10:06,239 iteration 5488 : loss : 0.062682, loss_ce: 0.019057
2021-12-17 18:10:07,624 iteration 5489 : loss : 0.054234, loss_ce: 0.012374
2021-12-17 18:10:09,093 iteration 5490 : loss : 0.063777, loss_ce: 0.024073
2021-12-17 18:10:10,496 iteration 5491 : loss : 0.051060, loss_ce: 0.014400
 81%|███████████████████████▍     | 323/400 [2:26:22<33:07, 25.81s/it]2021-12-17 18:10:12,004 iteration 5492 : loss : 0.061252, loss_ce: 0.019456
2021-12-17 18:10:13,382 iteration 5493 : loss : 0.046896, loss_ce: 0.014721
2021-12-17 18:10:14,786 iteration 5494 : loss : 0.057665, loss_ce: 0.023582
2021-12-17 18:10:16,288 iteration 5495 : loss : 0.074102, loss_ce: 0.013813
2021-12-17 18:10:17,685 iteration 5496 : loss : 0.044183, loss_ce: 0.012331
2021-12-17 18:10:19,138 iteration 5497 : loss : 0.053559, loss_ce: 0.022175
2021-12-17 18:10:20,631 iteration 5498 : loss : 0.060950, loss_ce: 0.022937
2021-12-17 18:10:22,072 iteration 5499 : loss : 0.049407, loss_ce: 0.012465
2021-12-17 18:10:23,511 iteration 5500 : loss : 0.049860, loss_ce: 0.014610
2021-12-17 18:10:24,922 iteration 5501 : loss : 0.048954, loss_ce: 0.016357
2021-12-17 18:10:26,330 iteration 5502 : loss : 0.048545, loss_ce: 0.019555
2021-12-17 18:10:27,888 iteration 5503 : loss : 0.066491, loss_ce: 0.019135
2021-12-17 18:10:29,321 iteration 5504 : loss : 0.063649, loss_ce: 0.026019
2021-12-17 18:10:30,685 iteration 5505 : loss : 0.048036, loss_ce: 0.014347
2021-12-17 18:10:32,090 iteration 5506 : loss : 0.054399, loss_ce: 0.017601
2021-12-17 18:10:33,610 iteration 5507 : loss : 0.056330, loss_ce: 0.016739
2021-12-17 18:10:35,085 iteration 5508 : loss : 0.076330, loss_ce: 0.032266
 81%|███████████████████████▍     | 324/400 [2:26:47<32:13, 25.45s/it]2021-12-17 18:10:36,595 iteration 5509 : loss : 0.084565, loss_ce: 0.035888
2021-12-17 18:10:37,989 iteration 5510 : loss : 0.049445, loss_ce: 0.015894
2021-12-17 18:10:39,440 iteration 5511 : loss : 0.052061, loss_ce: 0.015862
2021-12-17 18:10:40,869 iteration 5512 : loss : 0.052850, loss_ce: 0.019343
2021-12-17 18:10:42,298 iteration 5513 : loss : 0.069644, loss_ce: 0.038879
2021-12-17 18:10:43,789 iteration 5514 : loss : 0.081557, loss_ce: 0.029962
2021-12-17 18:10:45,224 iteration 5515 : loss : 0.054945, loss_ce: 0.017805
2021-12-17 18:10:46,665 iteration 5516 : loss : 0.047698, loss_ce: 0.018996
2021-12-17 18:10:48,119 iteration 5517 : loss : 0.060701, loss_ce: 0.018972
2021-12-17 18:10:49,484 iteration 5518 : loss : 0.046572, loss_ce: 0.014360
2021-12-17 18:10:51,005 iteration 5519 : loss : 0.078335, loss_ce: 0.020674
2021-12-17 18:10:52,438 iteration 5520 : loss : 0.055597, loss_ce: 0.011110
2021-12-17 18:10:53,958 iteration 5521 : loss : 0.053490, loss_ce: 0.015442
2021-12-17 18:10:55,386 iteration 5522 : loss : 0.049233, loss_ce: 0.015411
2021-12-17 18:10:56,860 iteration 5523 : loss : 0.069441, loss_ce: 0.022644
2021-12-17 18:10:58,354 iteration 5524 : loss : 0.065174, loss_ce: 0.020649
2021-12-17 18:10:58,354 Training Data Eval:
2021-12-17 18:11:05,795   Average segmentation loss on training set: 0.0379
2021-12-17 18:11:05,796 Validation Data Eval:
2021-12-17 18:11:08,396   Average segmentation loss on validation set: 0.1131
2021-12-17 18:11:15,046 Found new lowest validation loss at iteration 5524! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/TU_3seeds/TU_RESNET_no_pretraining_SGD_best_val_loss_seed2.pth
2021-12-17 18:11:16,518 iteration 5525 : loss : 0.057606, loss_ce: 0.023082
 81%|███████████████████████▌     | 325/400 [2:27:28<37:48, 30.24s/it]2021-12-17 18:11:17,924 iteration 5526 : loss : 0.062885, loss_ce: 0.018104
2021-12-17 18:11:19,217 iteration 5527 : loss : 0.050230, loss_ce: 0.016820
2021-12-17 18:11:20,651 iteration 5528 : loss : 0.082107, loss_ce: 0.022741
2021-12-17 18:11:21,988 iteration 5529 : loss : 0.050049, loss_ce: 0.015566
2021-12-17 18:11:23,300 iteration 5530 : loss : 0.052402, loss_ce: 0.017826
2021-12-17 18:11:24,572 iteration 5531 : loss : 0.042853, loss_ce: 0.011114
2021-12-17 18:11:25,872 iteration 5532 : loss : 0.047778, loss_ce: 0.015561
2021-12-17 18:11:27,276 iteration 5533 : loss : 0.058980, loss_ce: 0.021683
2021-12-17 18:11:28,570 iteration 5534 : loss : 0.045408, loss_ce: 0.014492
2021-12-17 18:11:29,905 iteration 5535 : loss : 0.052483, loss_ce: 0.018653
2021-12-17 18:11:31,309 iteration 5536 : loss : 0.058210, loss_ce: 0.015224
2021-12-17 18:11:32,728 iteration 5537 : loss : 0.060141, loss_ce: 0.022847
2021-12-17 18:11:34,254 iteration 5538 : loss : 0.061265, loss_ce: 0.014231
2021-12-17 18:11:35,729 iteration 5539 : loss : 0.048687, loss_ce: 0.013813
2021-12-17 18:11:37,134 iteration 5540 : loss : 0.052314, loss_ce: 0.018485
2021-12-17 18:11:38,704 iteration 5541 : loss : 0.063213, loss_ce: 0.022838
2021-12-17 18:11:40,181 iteration 5542 : loss : 0.051969, loss_ce: 0.018749
 82%|███████████████████████▋     | 326/400 [2:27:52<34:51, 28.27s/it]2021-12-17 18:11:41,735 iteration 5543 : loss : 0.055506, loss_ce: 0.022346
2021-12-17 18:11:43,161 iteration 5544 : loss : 0.045218, loss_ce: 0.013765
2021-12-17 18:11:44,656 iteration 5545 : loss : 0.061957, loss_ce: 0.024842
2021-12-17 18:11:46,207 iteration 5546 : loss : 0.091186, loss_ce: 0.020109
2021-12-17 18:11:47,742 iteration 5547 : loss : 0.047591, loss_ce: 0.015255
2021-12-17 18:11:49,177 iteration 5548 : loss : 0.068677, loss_ce: 0.017016
2021-12-17 18:11:50,625 iteration 5549 : loss : 0.048354, loss_ce: 0.011842
2021-12-17 18:11:52,110 iteration 5550 : loss : 0.060091, loss_ce: 0.022181
2021-12-17 18:11:53,531 iteration 5551 : loss : 0.069637, loss_ce: 0.029427
2021-12-17 18:11:54,878 iteration 5552 : loss : 0.048468, loss_ce: 0.011025
2021-12-17 18:11:56,344 iteration 5553 : loss : 0.055589, loss_ce: 0.019133
2021-12-17 18:11:57,786 iteration 5554 : loss : 0.052726, loss_ce: 0.020667
2021-12-17 18:11:59,163 iteration 5555 : loss : 0.050392, loss_ce: 0.019158
2021-12-17 18:12:00,673 iteration 5556 : loss : 0.060971, loss_ce: 0.019170
2021-12-17 18:12:02,158 iteration 5557 : loss : 0.050612, loss_ce: 0.017229
2021-12-17 18:12:03,609 iteration 5558 : loss : 0.062720, loss_ce: 0.017393
2021-12-17 18:12:05,061 iteration 5559 : loss : 0.063226, loss_ce: 0.016875
 82%|███████████████████████▋     | 327/400 [2:28:16<33:09, 27.25s/it]2021-12-17 18:12:06,565 iteration 5560 : loss : 0.063365, loss_ce: 0.019768
2021-12-17 18:12:07,985 iteration 5561 : loss : 0.058762, loss_ce: 0.019221
2021-12-17 18:12:09,441 iteration 5562 : loss : 0.059317, loss_ce: 0.023836
2021-12-17 18:12:10,878 iteration 5563 : loss : 0.054658, loss_ce: 0.020154
2021-12-17 18:12:12,359 iteration 5564 : loss : 0.059204, loss_ce: 0.019824
2021-12-17 18:12:13,839 iteration 5565 : loss : 0.075372, loss_ce: 0.031397
2021-12-17 18:12:15,297 iteration 5566 : loss : 0.054993, loss_ce: 0.017554
2021-12-17 18:12:16,797 iteration 5567 : loss : 0.056606, loss_ce: 0.022659
2021-12-17 18:12:18,233 iteration 5568 : loss : 0.061954, loss_ce: 0.018603
2021-12-17 18:12:19,686 iteration 5569 : loss : 0.061276, loss_ce: 0.020369
2021-12-17 18:12:21,089 iteration 5570 : loss : 0.044330, loss_ce: 0.011320
2021-12-17 18:12:22,441 iteration 5571 : loss : 0.044424, loss_ce: 0.014095
2021-12-17 18:12:23,856 iteration 5572 : loss : 0.069563, loss_ce: 0.019371
2021-12-17 18:12:25,249 iteration 5573 : loss : 0.043482, loss_ce: 0.010641
2021-12-17 18:12:26,695 iteration 5574 : loss : 0.057747, loss_ce: 0.018731
2021-12-17 18:12:28,238 iteration 5575 : loss : 0.075220, loss_ce: 0.020125
2021-12-17 18:12:29,727 iteration 5576 : loss : 0.064151, loss_ce: 0.020262
 82%|███████████████████████▊     | 328/400 [2:28:41<31:46, 26.48s/it]2021-12-17 18:12:31,229 iteration 5577 : loss : 0.052890, loss_ce: 0.021482
2021-12-17 18:12:32,711 iteration 5578 : loss : 0.060296, loss_ce: 0.020910
2021-12-17 18:12:34,223 iteration 5579 : loss : 0.075057, loss_ce: 0.033351
2021-12-17 18:12:35,646 iteration 5580 : loss : 0.060258, loss_ce: 0.019141
2021-12-17 18:12:37,054 iteration 5581 : loss : 0.046883, loss_ce: 0.016158
2021-12-17 18:12:38,515 iteration 5582 : loss : 0.044455, loss_ce: 0.010942
2021-12-17 18:12:39,948 iteration 5583 : loss : 0.047690, loss_ce: 0.014322
2021-12-17 18:12:41,438 iteration 5584 : loss : 0.066266, loss_ce: 0.023790
2021-12-17 18:12:42,862 iteration 5585 : loss : 0.048494, loss_ce: 0.012579
2021-12-17 18:12:44,378 iteration 5586 : loss : 0.076946, loss_ce: 0.025471
2021-12-17 18:12:45,777 iteration 5587 : loss : 0.048335, loss_ce: 0.014470
2021-12-17 18:12:47,203 iteration 5588 : loss : 0.052884, loss_ce: 0.016435
2021-12-17 18:12:48,595 iteration 5589 : loss : 0.046908, loss_ce: 0.011995
2021-12-17 18:12:50,022 iteration 5590 : loss : 0.057445, loss_ce: 0.014603
2021-12-17 18:12:51,451 iteration 5591 : loss : 0.046744, loss_ce: 0.016286
2021-12-17 18:12:52,968 iteration 5592 : loss : 0.056831, loss_ce: 0.016482
2021-12-17 18:12:54,434 iteration 5593 : loss : 0.054125, loss_ce: 0.019050
 82%|███████████████████████▊     | 329/400 [2:29:06<30:42, 25.95s/it]2021-12-17 18:12:55,873 iteration 5594 : loss : 0.059552, loss_ce: 0.015101
2021-12-17 18:12:57,358 iteration 5595 : loss : 0.061153, loss_ce: 0.022831
2021-12-17 18:12:58,776 iteration 5596 : loss : 0.053896, loss_ce: 0.017860
2021-12-17 18:13:00,287 iteration 5597 : loss : 0.054793, loss_ce: 0.016629
2021-12-17 18:13:01,676 iteration 5598 : loss : 0.045092, loss_ce: 0.016065
2021-12-17 18:13:03,120 iteration 5599 : loss : 0.060845, loss_ce: 0.020492
2021-12-17 18:13:04,551 iteration 5600 : loss : 0.047503, loss_ce: 0.016748
2021-12-17 18:13:05,972 iteration 5601 : loss : 0.041159, loss_ce: 0.012630
2021-12-17 18:13:07,426 iteration 5602 : loss : 0.052394, loss_ce: 0.018865
2021-12-17 18:13:08,834 iteration 5603 : loss : 0.044448, loss_ce: 0.015037
2021-12-17 18:13:10,301 iteration 5604 : loss : 0.072772, loss_ce: 0.015007
2021-12-17 18:13:11,778 iteration 5605 : loss : 0.075660, loss_ce: 0.030494
2021-12-17 18:13:13,242 iteration 5606 : loss : 0.059868, loss_ce: 0.017205
2021-12-17 18:13:14,689 iteration 5607 : loss : 0.051154, loss_ce: 0.013264
2021-12-17 18:13:16,140 iteration 5608 : loss : 0.047398, loss_ce: 0.012828
2021-12-17 18:13:17,636 iteration 5609 : loss : 0.050459, loss_ce: 0.017472
2021-12-17 18:13:17,637 Training Data Eval:
2021-12-17 18:13:25,154   Average segmentation loss on training set: 0.0374
2021-12-17 18:13:25,154 Validation Data Eval:
2021-12-17 18:13:27,750   Average segmentation loss on validation set: 0.1110
2021-12-17 18:13:34,133 Found new lowest validation loss at iteration 5609! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/TU_3seeds/TU_RESNET_no_pretraining_SGD_best_val_loss_seed2.pth
2021-12-17 18:13:35,458 iteration 5610 : loss : 0.048311, loss_ce: 0.014709
 82%|███████████████████████▉     | 330/400 [2:29:47<35:32, 30.47s/it]2021-12-17 18:13:36,841 iteration 5611 : loss : 0.057434, loss_ce: 0.018703
2021-12-17 18:13:38,210 iteration 5612 : loss : 0.074943, loss_ce: 0.016862
2021-12-17 18:13:39,568 iteration 5613 : loss : 0.056702, loss_ce: 0.019251
2021-12-17 18:13:40,920 iteration 5614 : loss : 0.049355, loss_ce: 0.015884
2021-12-17 18:13:42,194 iteration 5615 : loss : 0.040974, loss_ce: 0.014623
2021-12-17 18:13:43,582 iteration 5616 : loss : 0.052072, loss_ce: 0.018805
2021-12-17 18:13:45,006 iteration 5617 : loss : 0.049479, loss_ce: 0.016871
2021-12-17 18:13:46,399 iteration 5618 : loss : 0.064188, loss_ce: 0.024165
2021-12-17 18:13:47,732 iteration 5619 : loss : 0.052125, loss_ce: 0.012869
2021-12-17 18:13:49,158 iteration 5620 : loss : 0.046898, loss_ce: 0.015644
2021-12-17 18:13:50,488 iteration 5621 : loss : 0.045947, loss_ce: 0.013692
2021-12-17 18:13:51,946 iteration 5622 : loss : 0.050433, loss_ce: 0.015311
2021-12-17 18:13:53,502 iteration 5623 : loss : 0.052820, loss_ce: 0.017237
2021-12-17 18:13:54,914 iteration 5624 : loss : 0.059028, loss_ce: 0.015782
2021-12-17 18:13:56,317 iteration 5625 : loss : 0.053627, loss_ce: 0.019031
2021-12-17 18:13:57,751 iteration 5626 : loss : 0.053799, loss_ce: 0.013955
2021-12-17 18:13:59,236 iteration 5627 : loss : 0.050894, loss_ce: 0.017941
 83%|███████████████████████▉     | 331/400 [2:30:11<32:43, 28.46s/it]2021-12-17 18:14:00,833 iteration 5628 : loss : 0.056937, loss_ce: 0.024490
2021-12-17 18:14:02,244 iteration 5629 : loss : 0.052379, loss_ce: 0.020175
2021-12-17 18:14:03,733 iteration 5630 : loss : 0.072848, loss_ce: 0.032766
2021-12-17 18:14:05,182 iteration 5631 : loss : 0.063270, loss_ce: 0.021547
2021-12-17 18:14:06,675 iteration 5632 : loss : 0.088624, loss_ce: 0.033821
2021-12-17 18:14:08,182 iteration 5633 : loss : 0.056236, loss_ce: 0.015356
2021-12-17 18:14:09,655 iteration 5634 : loss : 0.049605, loss_ce: 0.018437
2021-12-17 18:14:11,093 iteration 5635 : loss : 0.054681, loss_ce: 0.015381
2021-12-17 18:14:12,558 iteration 5636 : loss : 0.067335, loss_ce: 0.015558
2021-12-17 18:14:13,998 iteration 5637 : loss : 0.052945, loss_ce: 0.013822
2021-12-17 18:14:15,455 iteration 5638 : loss : 0.055022, loss_ce: 0.020030
2021-12-17 18:14:16,922 iteration 5639 : loss : 0.047679, loss_ce: 0.014785
2021-12-17 18:14:18,397 iteration 5640 : loss : 0.058000, loss_ce: 0.018637
2021-12-17 18:14:19,775 iteration 5641 : loss : 0.048806, loss_ce: 0.012447
2021-12-17 18:14:21,175 iteration 5642 : loss : 0.047697, loss_ce: 0.015736
2021-12-17 18:14:22,612 iteration 5643 : loss : 0.059553, loss_ce: 0.019486
2021-12-17 18:14:24,043 iteration 5644 : loss : 0.056126, loss_ce: 0.020859
 83%|████████████████████████     | 332/400 [2:30:35<31:00, 27.37s/it]2021-12-17 18:14:25,512 iteration 5645 : loss : 0.050190, loss_ce: 0.013248
2021-12-17 18:14:26,958 iteration 5646 : loss : 0.047367, loss_ce: 0.013157
2021-12-17 18:14:28,438 iteration 5647 : loss : 0.059020, loss_ce: 0.017306
2021-12-17 18:14:29,908 iteration 5648 : loss : 0.055497, loss_ce: 0.013736
2021-12-17 18:14:31,352 iteration 5649 : loss : 0.046459, loss_ce: 0.015481
2021-12-17 18:14:32,860 iteration 5650 : loss : 0.065095, loss_ce: 0.016562
2021-12-17 18:14:34,295 iteration 5651 : loss : 0.052877, loss_ce: 0.019931
2021-12-17 18:14:35,714 iteration 5652 : loss : 0.046492, loss_ce: 0.015830
2021-12-17 18:14:37,143 iteration 5653 : loss : 0.045258, loss_ce: 0.014350
2021-12-17 18:14:38,673 iteration 5654 : loss : 0.053060, loss_ce: 0.015838
2021-12-17 18:14:40,104 iteration 5655 : loss : 0.065875, loss_ce: 0.019124
2021-12-17 18:14:41,577 iteration 5656 : loss : 0.062036, loss_ce: 0.026761
2021-12-17 18:14:43,018 iteration 5657 : loss : 0.058872, loss_ce: 0.025728
2021-12-17 18:14:44,538 iteration 5658 : loss : 0.057101, loss_ce: 0.016513
2021-12-17 18:14:46,071 iteration 5659 : loss : 0.063638, loss_ce: 0.028813
2021-12-17 18:14:47,443 iteration 5660 : loss : 0.044416, loss_ce: 0.014834
2021-12-17 18:14:48,924 iteration 5661 : loss : 0.061020, loss_ce: 0.020839
 83%|████████████████████████▏    | 333/400 [2:31:00<29:43, 26.62s/it]2021-12-17 18:14:50,362 iteration 5662 : loss : 0.047766, loss_ce: 0.016479
2021-12-17 18:14:51,852 iteration 5663 : loss : 0.051154, loss_ce: 0.019495
2021-12-17 18:14:53,355 iteration 5664 : loss : 0.054534, loss_ce: 0.018099
2021-12-17 18:14:54,784 iteration 5665 : loss : 0.047195, loss_ce: 0.010046
2021-12-17 18:14:56,298 iteration 5666 : loss : 0.054705, loss_ce: 0.017582
2021-12-17 18:14:57,779 iteration 5667 : loss : 0.064874, loss_ce: 0.019963
2021-12-17 18:14:59,251 iteration 5668 : loss : 0.055053, loss_ce: 0.017223
2021-12-17 18:15:00,773 iteration 5669 : loss : 0.055983, loss_ce: 0.024604
2021-12-17 18:15:02,237 iteration 5670 : loss : 0.054626, loss_ce: 0.015724
2021-12-17 18:15:03,749 iteration 5671 : loss : 0.068586, loss_ce: 0.015823
2021-12-17 18:15:05,120 iteration 5672 : loss : 0.045750, loss_ce: 0.011266
2021-12-17 18:15:06,561 iteration 5673 : loss : 0.050237, loss_ce: 0.018211
2021-12-17 18:15:07,969 iteration 5674 : loss : 0.070877, loss_ce: 0.019885
2021-12-17 18:15:09,540 iteration 5675 : loss : 0.054344, loss_ce: 0.018171
2021-12-17 18:15:10,975 iteration 5676 : loss : 0.062420, loss_ce: 0.027867
2021-12-17 18:15:12,378 iteration 5677 : loss : 0.048733, loss_ce: 0.015337
2021-12-17 18:15:13,800 iteration 5678 : loss : 0.062100, loss_ce: 0.022949
 84%|████████████████████████▏    | 334/400 [2:31:25<28:42, 26.10s/it]2021-12-17 18:15:15,313 iteration 5679 : loss : 0.064566, loss_ce: 0.025215
2021-12-17 18:15:16,752 iteration 5680 : loss : 0.050455, loss_ce: 0.019154
2021-12-17 18:15:18,247 iteration 5681 : loss : 0.059939, loss_ce: 0.016103
2021-12-17 18:15:19,632 iteration 5682 : loss : 0.046095, loss_ce: 0.013920
2021-12-17 18:15:21,007 iteration 5683 : loss : 0.043666, loss_ce: 0.015658
2021-12-17 18:15:22,534 iteration 5684 : loss : 0.054673, loss_ce: 0.022824
2021-12-17 18:15:23,996 iteration 5685 : loss : 0.059526, loss_ce: 0.019511
2021-12-17 18:15:25,439 iteration 5686 : loss : 0.057286, loss_ce: 0.016935
2021-12-17 18:15:26,908 iteration 5687 : loss : 0.051595, loss_ce: 0.014986
2021-12-17 18:15:28,423 iteration 5688 : loss : 0.061251, loss_ce: 0.019184
2021-12-17 18:15:29,842 iteration 5689 : loss : 0.054956, loss_ce: 0.019849
2021-12-17 18:15:31,228 iteration 5690 : loss : 0.046811, loss_ce: 0.014239
2021-12-17 18:15:32,695 iteration 5691 : loss : 0.051314, loss_ce: 0.020368
2021-12-17 18:15:34,148 iteration 5692 : loss : 0.039320, loss_ce: 0.009499
2021-12-17 18:15:35,488 iteration 5693 : loss : 0.044627, loss_ce: 0.014759
2021-12-17 18:15:36,952 iteration 5694 : loss : 0.051692, loss_ce: 0.018054
2021-12-17 18:15:36,952 Training Data Eval:
2021-12-17 18:15:44,466   Average segmentation loss on training set: 0.0378
2021-12-17 18:15:44,466 Validation Data Eval:
2021-12-17 18:15:47,056   Average segmentation loss on validation set: 0.1182
2021-12-17 18:15:48,504 iteration 5695 : loss : 0.058063, loss_ce: 0.021444
 84%|████████████████████████▎    | 335/400 [2:32:00<31:04, 28.68s/it]2021-12-17 18:15:50,009 iteration 5696 : loss : 0.055398, loss_ce: 0.016062
2021-12-17 18:15:51,423 iteration 5697 : loss : 0.048533, loss_ce: 0.012647
2021-12-17 18:15:52,941 iteration 5698 : loss : 0.061018, loss_ce: 0.020139
2021-12-17 18:15:54,459 iteration 5699 : loss : 0.055278, loss_ce: 0.014039
2021-12-17 18:15:55,821 iteration 5700 : loss : 0.046955, loss_ce: 0.016523
2021-12-17 18:15:57,359 iteration 5701 : loss : 0.076054, loss_ce: 0.013198
2021-12-17 18:15:58,831 iteration 5702 : loss : 0.059427, loss_ce: 0.022905
2021-12-17 18:16:00,341 iteration 5703 : loss : 0.057586, loss_ce: 0.020372
2021-12-17 18:16:01,747 iteration 5704 : loss : 0.065026, loss_ce: 0.026880
2021-12-17 18:16:03,154 iteration 5705 : loss : 0.050804, loss_ce: 0.018861
2021-12-17 18:16:04,554 iteration 5706 : loss : 0.050966, loss_ce: 0.016641
2021-12-17 18:16:06,020 iteration 5707 : loss : 0.077766, loss_ce: 0.018620
2021-12-17 18:16:07,464 iteration 5708 : loss : 0.052199, loss_ce: 0.021658
2021-12-17 18:16:08,863 iteration 5709 : loss : 0.065037, loss_ce: 0.026947
2021-12-17 18:16:10,296 iteration 5710 : loss : 0.053975, loss_ce: 0.021534
2021-12-17 18:16:11,750 iteration 5711 : loss : 0.051871, loss_ce: 0.020299
2021-12-17 18:16:13,191 iteration 5712 : loss : 0.054330, loss_ce: 0.021073
 84%|████████████████████████▎    | 336/400 [2:32:25<29:18, 27.48s/it]2021-12-17 18:16:14,683 iteration 5713 : loss : 0.052435, loss_ce: 0.019649
2021-12-17 18:16:16,157 iteration 5714 : loss : 0.062700, loss_ce: 0.015808
2021-12-17 18:16:17,558 iteration 5715 : loss : 0.047125, loss_ce: 0.015629
2021-12-17 18:16:19,047 iteration 5716 : loss : 0.057566, loss_ce: 0.018708
2021-12-17 18:16:20,435 iteration 5717 : loss : 0.048032, loss_ce: 0.015299
2021-12-17 18:16:21,838 iteration 5718 : loss : 0.070280, loss_ce: 0.028309
2021-12-17 18:16:23,318 iteration 5719 : loss : 0.053499, loss_ce: 0.012957
2021-12-17 18:16:24,812 iteration 5720 : loss : 0.071201, loss_ce: 0.027968
2021-12-17 18:16:26,200 iteration 5721 : loss : 0.050962, loss_ce: 0.014088
2021-12-17 18:16:27,690 iteration 5722 : loss : 0.059323, loss_ce: 0.021427
2021-12-17 18:16:29,195 iteration 5723 : loss : 0.069645, loss_ce: 0.024411
2021-12-17 18:16:30,654 iteration 5724 : loss : 0.052318, loss_ce: 0.017958
2021-12-17 18:16:32,065 iteration 5725 : loss : 0.052132, loss_ce: 0.017938
2021-12-17 18:16:33,555 iteration 5726 : loss : 0.050717, loss_ce: 0.017181
2021-12-17 18:16:35,023 iteration 5727 : loss : 0.068632, loss_ce: 0.028950
2021-12-17 18:16:36,439 iteration 5728 : loss : 0.048172, loss_ce: 0.014111
2021-12-17 18:16:37,820 iteration 5729 : loss : 0.050301, loss_ce: 0.013241
 84%|████████████████████████▍    | 337/400 [2:32:49<27:57, 26.63s/it]2021-12-17 18:16:39,385 iteration 5730 : loss : 0.066190, loss_ce: 0.022117
2021-12-17 18:16:40,886 iteration 5731 : loss : 0.070377, loss_ce: 0.020595
2021-12-17 18:16:42,367 iteration 5732 : loss : 0.072638, loss_ce: 0.016251
2021-12-17 18:16:43,813 iteration 5733 : loss : 0.064209, loss_ce: 0.023362
2021-12-17 18:16:45,236 iteration 5734 : loss : 0.045391, loss_ce: 0.014652
2021-12-17 18:16:46,772 iteration 5735 : loss : 0.071944, loss_ce: 0.021986
2021-12-17 18:16:48,272 iteration 5736 : loss : 0.053215, loss_ce: 0.018791
2021-12-17 18:16:49,716 iteration 5737 : loss : 0.052671, loss_ce: 0.016904
2021-12-17 18:16:51,111 iteration 5738 : loss : 0.048230, loss_ce: 0.018703
2021-12-17 18:16:52,573 iteration 5739 : loss : 0.049207, loss_ce: 0.013833
2021-12-17 18:16:54,073 iteration 5740 : loss : 0.056820, loss_ce: 0.020805
2021-12-17 18:16:55,531 iteration 5741 : loss : 0.051103, loss_ce: 0.017891
2021-12-17 18:16:56,948 iteration 5742 : loss : 0.086671, loss_ce: 0.014289
2021-12-17 18:16:58,400 iteration 5743 : loss : 0.055798, loss_ce: 0.015868
2021-12-17 18:16:59,806 iteration 5744 : loss : 0.054158, loss_ce: 0.019669
2021-12-17 18:17:01,276 iteration 5745 : loss : 0.048611, loss_ce: 0.014438
2021-12-17 18:17:02,697 iteration 5746 : loss : 0.058961, loss_ce: 0.024745
 84%|████████████████████████▌    | 338/400 [2:33:14<26:58, 26.10s/it]2021-12-17 18:17:04,204 iteration 5747 : loss : 0.060873, loss_ce: 0.018929
2021-12-17 18:17:05,605 iteration 5748 : loss : 0.055785, loss_ce: 0.019338
2021-12-17 18:17:07,092 iteration 5749 : loss : 0.068321, loss_ce: 0.026616
2021-12-17 18:17:08,552 iteration 5750 : loss : 0.056045, loss_ce: 0.012795
2021-12-17 18:17:10,045 iteration 5751 : loss : 0.068006, loss_ce: 0.025457
2021-12-17 18:17:11,506 iteration 5752 : loss : 0.057454, loss_ce: 0.014704
2021-12-17 18:17:13,001 iteration 5753 : loss : 0.057022, loss_ce: 0.023868
2021-12-17 18:17:14,414 iteration 5754 : loss : 0.050364, loss_ce: 0.015527
2021-12-17 18:17:15,823 iteration 5755 : loss : 0.054719, loss_ce: 0.016053
2021-12-17 18:17:17,243 iteration 5756 : loss : 0.056473, loss_ce: 0.023909
2021-12-17 18:17:18,711 iteration 5757 : loss : 0.053857, loss_ce: 0.015719
2021-12-17 18:17:20,100 iteration 5758 : loss : 0.042066, loss_ce: 0.011339
2021-12-17 18:17:21,604 iteration 5759 : loss : 0.063185, loss_ce: 0.015479
2021-12-17 18:17:23,036 iteration 5760 : loss : 0.047128, loss_ce: 0.015719
2021-12-17 18:17:24,498 iteration 5761 : loss : 0.058186, loss_ce: 0.016627
2021-12-17 18:17:26,005 iteration 5762 : loss : 0.055710, loss_ce: 0.021319
2021-12-17 18:17:27,475 iteration 5763 : loss : 0.059593, loss_ce: 0.020139
 85%|████████████████████████▌    | 339/400 [2:33:39<26:07, 25.70s/it]2021-12-17 18:17:29,021 iteration 5764 : loss : 0.061264, loss_ce: 0.025975
2021-12-17 18:17:30,486 iteration 5765 : loss : 0.058718, loss_ce: 0.015917
2021-12-17 18:17:31,914 iteration 5766 : loss : 0.066552, loss_ce: 0.018328
2021-12-17 18:17:33,395 iteration 5767 : loss : 0.051277, loss_ce: 0.018088
2021-12-17 18:17:34,871 iteration 5768 : loss : 0.091686, loss_ce: 0.029743
2021-12-17 18:17:36,330 iteration 5769 : loss : 0.052460, loss_ce: 0.014194
2021-12-17 18:17:37,794 iteration 5770 : loss : 0.057742, loss_ce: 0.019905
2021-12-17 18:17:39,159 iteration 5771 : loss : 0.050798, loss_ce: 0.019671
2021-12-17 18:17:40,619 iteration 5772 : loss : 0.051418, loss_ce: 0.017762
2021-12-17 18:17:41,997 iteration 5773 : loss : 0.045681, loss_ce: 0.014136
2021-12-17 18:17:43,409 iteration 5774 : loss : 0.052185, loss_ce: 0.018129
2021-12-17 18:17:44,880 iteration 5775 : loss : 0.069609, loss_ce: 0.023993
2021-12-17 18:17:46,233 iteration 5776 : loss : 0.049781, loss_ce: 0.015878
2021-12-17 18:17:47,653 iteration 5777 : loss : 0.054681, loss_ce: 0.017683
2021-12-17 18:17:49,118 iteration 5778 : loss : 0.052756, loss_ce: 0.015516
2021-12-17 18:17:50,565 iteration 5779 : loss : 0.051716, loss_ce: 0.017038
2021-12-17 18:17:50,566 Training Data Eval:
2021-12-17 18:17:58,064   Average segmentation loss on training set: 0.0372
2021-12-17 18:17:58,064 Validation Data Eval:
2021-12-17 18:18:00,651   Average segmentation loss on validation set: 0.1205
2021-12-17 18:18:02,109 iteration 5780 : loss : 0.046001, loss_ce: 0.015957
 85%|████████████████████████▋    | 340/400 [2:34:14<28:23, 28.38s/it]2021-12-17 18:18:03,593 iteration 5781 : loss : 0.054094, loss_ce: 0.016708
2021-12-17 18:18:04,955 iteration 5782 : loss : 0.041948, loss_ce: 0.013536
2021-12-17 18:18:06,425 iteration 5783 : loss : 0.059993, loss_ce: 0.016875
2021-12-17 18:18:07,903 iteration 5784 : loss : 0.049063, loss_ce: 0.013675
2021-12-17 18:18:09,363 iteration 5785 : loss : 0.047687, loss_ce: 0.017967
2021-12-17 18:18:10,858 iteration 5786 : loss : 0.057105, loss_ce: 0.019736
2021-12-17 18:18:12,291 iteration 5787 : loss : 0.050226, loss_ce: 0.013903
2021-12-17 18:18:13,750 iteration 5788 : loss : 0.072670, loss_ce: 0.028600
2021-12-17 18:18:15,190 iteration 5789 : loss : 0.054234, loss_ce: 0.016712
2021-12-17 18:18:16,659 iteration 5790 : loss : 0.072889, loss_ce: 0.025212
2021-12-17 18:18:18,154 iteration 5791 : loss : 0.044584, loss_ce: 0.014882
2021-12-17 18:18:19,661 iteration 5792 : loss : 0.066952, loss_ce: 0.018046
2021-12-17 18:18:21,066 iteration 5793 : loss : 0.046902, loss_ce: 0.016055
2021-12-17 18:18:22,468 iteration 5794 : loss : 0.051840, loss_ce: 0.015567
2021-12-17 18:18:23,881 iteration 5795 : loss : 0.048125, loss_ce: 0.018694
2021-12-17 18:18:25,287 iteration 5796 : loss : 0.054786, loss_ce: 0.020475
2021-12-17 18:18:26,694 iteration 5797 : loss : 0.047410, loss_ce: 0.013275
 85%|████████████████████████▋    | 341/400 [2:34:38<26:47, 27.24s/it]2021-12-17 18:18:28,147 iteration 5798 : loss : 0.053277, loss_ce: 0.015433
2021-12-17 18:18:29,554 iteration 5799 : loss : 0.049240, loss_ce: 0.015663
2021-12-17 18:18:30,897 iteration 5800 : loss : 0.039633, loss_ce: 0.012811
2021-12-17 18:18:32,337 iteration 5801 : loss : 0.055049, loss_ce: 0.020464
2021-12-17 18:18:33,730 iteration 5802 : loss : 0.047545, loss_ce: 0.017512
2021-12-17 18:18:35,212 iteration 5803 : loss : 0.056000, loss_ce: 0.016354
2021-12-17 18:18:36,614 iteration 5804 : loss : 0.054730, loss_ce: 0.015310
2021-12-17 18:18:38,002 iteration 5805 : loss : 0.065412, loss_ce: 0.015513
2021-12-17 18:18:39,377 iteration 5806 : loss : 0.045624, loss_ce: 0.016927
2021-12-17 18:18:40,840 iteration 5807 : loss : 0.062596, loss_ce: 0.021580
2021-12-17 18:18:42,328 iteration 5808 : loss : 0.069562, loss_ce: 0.019337
2021-12-17 18:18:43,821 iteration 5809 : loss : 0.060042, loss_ce: 0.019896
2021-12-17 18:18:45,341 iteration 5810 : loss : 0.066473, loss_ce: 0.019400
2021-12-17 18:18:46,814 iteration 5811 : loss : 0.058119, loss_ce: 0.022432
2021-12-17 18:18:48,224 iteration 5812 : loss : 0.061671, loss_ce: 0.023027
2021-12-17 18:18:49,616 iteration 5813 : loss : 0.048308, loss_ce: 0.013617
2021-12-17 18:18:51,030 iteration 5814 : loss : 0.055175, loss_ce: 0.016318
 86%|████████████████████████▊    | 342/400 [2:35:02<25:29, 26.37s/it]2021-12-17 18:18:52,554 iteration 5815 : loss : 0.061750, loss_ce: 0.020372
2021-12-17 18:18:53,967 iteration 5816 : loss : 0.053932, loss_ce: 0.016842
2021-12-17 18:18:55,470 iteration 5817 : loss : 0.076553, loss_ce: 0.029071
2021-12-17 18:18:56,940 iteration 5818 : loss : 0.057815, loss_ce: 0.019720
2021-12-17 18:18:58,358 iteration 5819 : loss : 0.053371, loss_ce: 0.014470
2021-12-17 18:18:59,766 iteration 5820 : loss : 0.059236, loss_ce: 0.019163
2021-12-17 18:19:01,226 iteration 5821 : loss : 0.047744, loss_ce: 0.014991
2021-12-17 18:19:02,743 iteration 5822 : loss : 0.063323, loss_ce: 0.018720
2021-12-17 18:19:04,129 iteration 5823 : loss : 0.047993, loss_ce: 0.018178
2021-12-17 18:19:05,655 iteration 5824 : loss : 0.062648, loss_ce: 0.013840
2021-12-17 18:19:07,100 iteration 5825 : loss : 0.049170, loss_ce: 0.013968
2021-12-17 18:19:08,551 iteration 5826 : loss : 0.066649, loss_ce: 0.031007
2021-12-17 18:19:09,944 iteration 5827 : loss : 0.052589, loss_ce: 0.018117
2021-12-17 18:19:11,466 iteration 5828 : loss : 0.078258, loss_ce: 0.017136
2021-12-17 18:19:12,898 iteration 5829 : loss : 0.055830, loss_ce: 0.017369
2021-12-17 18:19:14,288 iteration 5830 : loss : 0.050224, loss_ce: 0.014987
2021-12-17 18:19:15,786 iteration 5831 : loss : 0.054607, loss_ce: 0.017838
 86%|████████████████████████▊    | 343/400 [2:35:27<24:35, 25.89s/it]2021-12-17 18:19:17,311 iteration 5832 : loss : 0.055384, loss_ce: 0.021771
2021-12-17 18:19:18,801 iteration 5833 : loss : 0.056951, loss_ce: 0.016649
2021-12-17 18:19:20,226 iteration 5834 : loss : 0.054335, loss_ce: 0.023609
2021-12-17 18:19:21,637 iteration 5835 : loss : 0.051880, loss_ce: 0.016849
2021-12-17 18:19:23,047 iteration 5836 : loss : 0.058745, loss_ce: 0.017835
2021-12-17 18:19:24,545 iteration 5837 : loss : 0.056781, loss_ce: 0.017303
2021-12-17 18:19:25,979 iteration 5838 : loss : 0.052719, loss_ce: 0.013947
2021-12-17 18:19:27,427 iteration 5839 : loss : 0.063072, loss_ce: 0.021284
2021-12-17 18:19:28,874 iteration 5840 : loss : 0.055393, loss_ce: 0.017588
2021-12-17 18:19:30,357 iteration 5841 : loss : 0.062586, loss_ce: 0.018198
2021-12-17 18:19:31,745 iteration 5842 : loss : 0.051133, loss_ce: 0.014446
2021-12-17 18:19:33,146 iteration 5843 : loss : 0.048434, loss_ce: 0.015964
2021-12-17 18:19:34,592 iteration 5844 : loss : 0.060743, loss_ce: 0.020956
2021-12-17 18:19:35,989 iteration 5845 : loss : 0.046694, loss_ce: 0.015201
2021-12-17 18:19:37,376 iteration 5846 : loss : 0.042951, loss_ce: 0.014847
2021-12-17 18:19:38,769 iteration 5847 : loss : 0.049678, loss_ce: 0.017052
2021-12-17 18:19:40,178 iteration 5848 : loss : 0.051137, loss_ce: 0.015543
 86%|████████████████████████▉    | 344/400 [2:35:52<23:44, 25.44s/it]2021-12-17 18:19:41,660 iteration 5849 : loss : 0.056886, loss_ce: 0.014814
2021-12-17 18:19:43,154 iteration 5850 : loss : 0.066091, loss_ce: 0.026425
2021-12-17 18:19:44,618 iteration 5851 : loss : 0.048193, loss_ce: 0.010837
2021-12-17 18:19:46,069 iteration 5852 : loss : 0.065956, loss_ce: 0.023221
2021-12-17 18:19:47,469 iteration 5853 : loss : 0.067585, loss_ce: 0.018044
2021-12-17 18:19:48,945 iteration 5854 : loss : 0.070111, loss_ce: 0.020376
2021-12-17 18:19:50,371 iteration 5855 : loss : 0.062069, loss_ce: 0.026612
2021-12-17 18:19:51,814 iteration 5856 : loss : 0.061388, loss_ce: 0.020303
2021-12-17 18:19:53,291 iteration 5857 : loss : 0.048932, loss_ce: 0.017102
2021-12-17 18:19:54,768 iteration 5858 : loss : 0.053145, loss_ce: 0.015164
2021-12-17 18:19:56,297 iteration 5859 : loss : 0.086756, loss_ce: 0.025601
2021-12-17 18:19:57,738 iteration 5860 : loss : 0.048918, loss_ce: 0.014714
2021-12-17 18:19:59,144 iteration 5861 : loss : 0.051437, loss_ce: 0.018918
2021-12-17 18:20:00,585 iteration 5862 : loss : 0.054848, loss_ce: 0.020705
2021-12-17 18:20:02,027 iteration 5863 : loss : 0.068641, loss_ce: 0.021306
2021-12-17 18:20:03,546 iteration 5864 : loss : 0.051292, loss_ce: 0.018230
2021-12-17 18:20:03,546 Training Data Eval:
2021-12-17 18:20:11,005   Average segmentation loss on training set: 0.0367
2021-12-17 18:20:11,005 Validation Data Eval:
2021-12-17 18:20:13,591   Average segmentation loss on validation set: 0.1195
2021-12-17 18:20:15,127 iteration 5865 : loss : 0.070187, loss_ce: 0.017813
 86%|█████████████████████████    | 345/400 [2:36:27<25:55, 28.29s/it]2021-12-17 18:20:16,544 iteration 5866 : loss : 0.050968, loss_ce: 0.012225
2021-12-17 18:20:17,960 iteration 5867 : loss : 0.048711, loss_ce: 0.016391
2021-12-17 18:20:19,413 iteration 5868 : loss : 0.053621, loss_ce: 0.017838
2021-12-17 18:20:20,848 iteration 5869 : loss : 0.055650, loss_ce: 0.016757
2021-12-17 18:20:22,378 iteration 5870 : loss : 0.066659, loss_ce: 0.025412
2021-12-17 18:20:23,816 iteration 5871 : loss : 0.049652, loss_ce: 0.016079
2021-12-17 18:20:25,236 iteration 5872 : loss : 0.065005, loss_ce: 0.018112
2021-12-17 18:20:26,684 iteration 5873 : loss : 0.063392, loss_ce: 0.030293
2021-12-17 18:20:28,124 iteration 5874 : loss : 0.058055, loss_ce: 0.017412
2021-12-17 18:20:29,577 iteration 5875 : loss : 0.051746, loss_ce: 0.019262
2021-12-17 18:20:31,096 iteration 5876 : loss : 0.060531, loss_ce: 0.021862
2021-12-17 18:20:32,574 iteration 5877 : loss : 0.065277, loss_ce: 0.025695
2021-12-17 18:20:33,958 iteration 5878 : loss : 0.053237, loss_ce: 0.015487
2021-12-17 18:20:35,386 iteration 5879 : loss : 0.064811, loss_ce: 0.021660
2021-12-17 18:20:36,835 iteration 5880 : loss : 0.054070, loss_ce: 0.013248
2021-12-17 18:20:38,233 iteration 5881 : loss : 0.049462, loss_ce: 0.016938
2021-12-17 18:20:39,617 iteration 5882 : loss : 0.049301, loss_ce: 0.014323
 86%|█████████████████████████    | 346/400 [2:36:51<24:26, 27.15s/it]2021-12-17 18:20:41,060 iteration 5883 : loss : 0.050781, loss_ce: 0.014056
2021-12-17 18:20:42,414 iteration 5884 : loss : 0.044190, loss_ce: 0.013058
2021-12-17 18:20:43,906 iteration 5885 : loss : 0.053307, loss_ce: 0.013281
2021-12-17 18:20:45,328 iteration 5886 : loss : 0.054187, loss_ce: 0.015832
2021-12-17 18:20:46,794 iteration 5887 : loss : 0.057977, loss_ce: 0.020226
2021-12-17 18:20:48,218 iteration 5888 : loss : 0.038931, loss_ce: 0.012373
2021-12-17 18:20:49,720 iteration 5889 : loss : 0.047418, loss_ce: 0.014306
2021-12-17 18:20:51,137 iteration 5890 : loss : 0.052151, loss_ce: 0.018764
2021-12-17 18:20:52,576 iteration 5891 : loss : 0.058650, loss_ce: 0.014244
2021-12-17 18:20:54,045 iteration 5892 : loss : 0.071155, loss_ce: 0.018305
2021-12-17 18:20:55,470 iteration 5893 : loss : 0.056749, loss_ce: 0.022219
2021-12-17 18:20:56,840 iteration 5894 : loss : 0.053161, loss_ce: 0.020233
2021-12-17 18:20:58,217 iteration 5895 : loss : 0.046035, loss_ce: 0.015882
2021-12-17 18:20:59,621 iteration 5896 : loss : 0.053772, loss_ce: 0.018737
2021-12-17 18:21:01,064 iteration 5897 : loss : 0.057421, loss_ce: 0.022347
2021-12-17 18:21:02,467 iteration 5898 : loss : 0.075106, loss_ce: 0.021659
2021-12-17 18:21:03,951 iteration 5899 : loss : 0.049860, loss_ce: 0.018641
 87%|█████████████████████████▏   | 347/400 [2:37:15<23:14, 26.30s/it]2021-12-17 18:21:05,359 iteration 5900 : loss : 0.053383, loss_ce: 0.015388
2021-12-17 18:21:06,896 iteration 5901 : loss : 0.063999, loss_ce: 0.021346
2021-12-17 18:21:08,413 iteration 5902 : loss : 0.058857, loss_ce: 0.023887
2021-12-17 18:21:09,837 iteration 5903 : loss : 0.054338, loss_ce: 0.015570
2021-12-17 18:21:11,285 iteration 5904 : loss : 0.054226, loss_ce: 0.018954
2021-12-17 18:21:12,666 iteration 5905 : loss : 0.048218, loss_ce: 0.015138
2021-12-17 18:21:14,089 iteration 5906 : loss : 0.065224, loss_ce: 0.022647
2021-12-17 18:21:15,545 iteration 5907 : loss : 0.054448, loss_ce: 0.017741
2021-12-17 18:21:16,975 iteration 5908 : loss : 0.067021, loss_ce: 0.020577
2021-12-17 18:21:18,350 iteration 5909 : loss : 0.039890, loss_ce: 0.013230
2021-12-17 18:21:19,752 iteration 5910 : loss : 0.046934, loss_ce: 0.017635
2021-12-17 18:21:21,182 iteration 5911 : loss : 0.044349, loss_ce: 0.012004
2021-12-17 18:21:22,752 iteration 5912 : loss : 0.119882, loss_ce: 0.023142
2021-12-17 18:21:24,128 iteration 5913 : loss : 0.047394, loss_ce: 0.014220
2021-12-17 18:21:25,643 iteration 5914 : loss : 0.058230, loss_ce: 0.021385
2021-12-17 18:21:27,122 iteration 5915 : loss : 0.060502, loss_ce: 0.023298
2021-12-17 18:21:28,549 iteration 5916 : loss : 0.051124, loss_ce: 0.017839
 87%|█████████████████████████▏   | 348/400 [2:37:40<22:21, 25.79s/it]2021-12-17 18:21:30,001 iteration 5917 : loss : 0.054325, loss_ce: 0.010641
2021-12-17 18:21:31,517 iteration 5918 : loss : 0.069531, loss_ce: 0.022270
2021-12-17 18:21:32,903 iteration 5919 : loss : 0.057108, loss_ce: 0.027861
2021-12-17 18:21:34,432 iteration 5920 : loss : 0.058703, loss_ce: 0.021921
2021-12-17 18:21:35,858 iteration 5921 : loss : 0.071218, loss_ce: 0.021198
2021-12-17 18:21:37,335 iteration 5922 : loss : 0.070891, loss_ce: 0.025860
2021-12-17 18:21:38,747 iteration 5923 : loss : 0.059574, loss_ce: 0.015625
2021-12-17 18:21:40,144 iteration 5924 : loss : 0.046752, loss_ce: 0.015926
2021-12-17 18:21:41,562 iteration 5925 : loss : 0.049316, loss_ce: 0.013790
2021-12-17 18:21:42,991 iteration 5926 : loss : 0.046737, loss_ce: 0.015288
2021-12-17 18:21:44,497 iteration 5927 : loss : 0.057935, loss_ce: 0.020743
2021-12-17 18:21:45,854 iteration 5928 : loss : 0.046348, loss_ce: 0.017185
2021-12-17 18:21:47,247 iteration 5929 : loss : 0.059105, loss_ce: 0.016065
2021-12-17 18:21:48,690 iteration 5930 : loss : 0.052098, loss_ce: 0.016332
2021-12-17 18:21:50,130 iteration 5931 : loss : 0.064983, loss_ce: 0.026085
2021-12-17 18:21:51,534 iteration 5932 : loss : 0.054171, loss_ce: 0.018368
2021-12-17 18:21:52,915 iteration 5933 : loss : 0.044972, loss_ce: 0.014265
 87%|█████████████████████████▎   | 349/400 [2:38:04<21:33, 25.37s/it]2021-12-17 18:21:54,335 iteration 5934 : loss : 0.045332, loss_ce: 0.012153
2021-12-17 18:21:55,724 iteration 5935 : loss : 0.055757, loss_ce: 0.022954
2021-12-17 18:21:57,102 iteration 5936 : loss : 0.055427, loss_ce: 0.019235
2021-12-17 18:21:58,566 iteration 5937 : loss : 0.056539, loss_ce: 0.020233
2021-12-17 18:22:00,023 iteration 5938 : loss : 0.048956, loss_ce: 0.017812
2021-12-17 18:22:01,503 iteration 5939 : loss : 0.074452, loss_ce: 0.021986
2021-12-17 18:22:02,898 iteration 5940 : loss : 0.039891, loss_ce: 0.012746
2021-12-17 18:22:04,364 iteration 5941 : loss : 0.055348, loss_ce: 0.018803
2021-12-17 18:22:05,808 iteration 5942 : loss : 0.047932, loss_ce: 0.016153
2021-12-17 18:22:07,292 iteration 5943 : loss : 0.052079, loss_ce: 0.016875
2021-12-17 18:22:08,638 iteration 5944 : loss : 0.049047, loss_ce: 0.016561
2021-12-17 18:22:10,183 iteration 5945 : loss : 0.064781, loss_ce: 0.020791
2021-12-17 18:22:11,627 iteration 5946 : loss : 0.050523, loss_ce: 0.017318
2021-12-17 18:22:13,159 iteration 5947 : loss : 0.059700, loss_ce: 0.016349
2021-12-17 18:22:14,648 iteration 5948 : loss : 0.062084, loss_ce: 0.017170
2021-12-17 18:22:16,058 iteration 5949 : loss : 0.067322, loss_ce: 0.014805
2021-12-17 18:22:16,058 Training Data Eval:
2021-12-17 18:22:23,509   Average segmentation loss on training set: 0.0361
2021-12-17 18:22:23,509 Validation Data Eval:
2021-12-17 18:22:26,088   Average segmentation loss on validation set: 0.1188
2021-12-17 18:22:27,477 iteration 5950 : loss : 0.045860, loss_ce: 0.013409
 88%|█████████████████████████▍   | 350/400 [2:38:39<23:26, 28.13s/it]2021-12-17 18:22:28,899 iteration 5951 : loss : 0.053457, loss_ce: 0.014261
2021-12-17 18:22:30,344 iteration 5952 : loss : 0.055342, loss_ce: 0.021381
2021-12-17 18:22:31,873 iteration 5953 : loss : 0.062666, loss_ce: 0.025599
2021-12-17 18:22:33,273 iteration 5954 : loss : 0.059926, loss_ce: 0.014605
2021-12-17 18:22:34,815 iteration 5955 : loss : 0.085540, loss_ce: 0.028354
2021-12-17 18:22:36,228 iteration 5956 : loss : 0.060259, loss_ce: 0.015496
2021-12-17 18:22:37,699 iteration 5957 : loss : 0.064430, loss_ce: 0.023154
2021-12-17 18:22:39,169 iteration 5958 : loss : 0.063970, loss_ce: 0.023394
2021-12-17 18:22:40,624 iteration 5959 : loss : 0.054446, loss_ce: 0.014092
2021-12-17 18:22:42,028 iteration 5960 : loss : 0.056315, loss_ce: 0.013144
2021-12-17 18:22:43,507 iteration 5961 : loss : 0.075795, loss_ce: 0.038677
2021-12-17 18:22:44,959 iteration 5962 : loss : 0.050064, loss_ce: 0.017128
2021-12-17 18:22:46,356 iteration 5963 : loss : 0.052391, loss_ce: 0.017545
2021-12-17 18:22:47,844 iteration 5964 : loss : 0.066324, loss_ce: 0.024954
2021-12-17 18:22:49,298 iteration 5965 : loss : 0.053375, loss_ce: 0.023682
2021-12-17 18:22:50,702 iteration 5966 : loss : 0.043000, loss_ce: 0.012825
2021-12-17 18:22:52,208 iteration 5967 : loss : 0.054753, loss_ce: 0.019115
 88%|█████████████████████████▍   | 351/400 [2:39:04<22:08, 27.10s/it]2021-12-17 18:22:53,665 iteration 5968 : loss : 0.048460, loss_ce: 0.015370
2021-12-17 18:22:55,088 iteration 5969 : loss : 0.054064, loss_ce: 0.022897
2021-12-17 18:22:56,547 iteration 5970 : loss : 0.056602, loss_ce: 0.018707
2021-12-17 18:22:57,944 iteration 5971 : loss : 0.043079, loss_ce: 0.015571
2021-12-17 18:22:59,331 iteration 5972 : loss : 0.051012, loss_ce: 0.014072
2021-12-17 18:23:00,719 iteration 5973 : loss : 0.050821, loss_ce: 0.015864
2021-12-17 18:23:02,146 iteration 5974 : loss : 0.063398, loss_ce: 0.017293
2021-12-17 18:23:03,594 iteration 5975 : loss : 0.056726, loss_ce: 0.028452
2021-12-17 18:23:05,056 iteration 5976 : loss : 0.055874, loss_ce: 0.016726
2021-12-17 18:23:06,437 iteration 5977 : loss : 0.044092, loss_ce: 0.013359
2021-12-17 18:23:07,855 iteration 5978 : loss : 0.052397, loss_ce: 0.014140
2021-12-17 18:23:09,292 iteration 5979 : loss : 0.063490, loss_ce: 0.015542
2021-12-17 18:23:10,777 iteration 5980 : loss : 0.075129, loss_ce: 0.018102
2021-12-17 18:23:12,277 iteration 5981 : loss : 0.063887, loss_ce: 0.023044
2021-12-17 18:23:13,730 iteration 5982 : loss : 0.066276, loss_ce: 0.026125
2021-12-17 18:23:15,177 iteration 5983 : loss : 0.075271, loss_ce: 0.020676
2021-12-17 18:23:16,676 iteration 5984 : loss : 0.050607, loss_ce: 0.015910
 88%|█████████████████████████▌   | 352/400 [2:39:28<21:03, 26.32s/it]2021-12-17 18:23:18,174 iteration 5985 : loss : 0.060046, loss_ce: 0.020487
2021-12-17 18:23:19,520 iteration 5986 : loss : 0.043600, loss_ce: 0.016951
2021-12-17 18:23:21,021 iteration 5987 : loss : 0.071654, loss_ce: 0.017257
2021-12-17 18:23:22,389 iteration 5988 : loss : 0.042888, loss_ce: 0.014868
2021-12-17 18:23:23,838 iteration 5989 : loss : 0.044716, loss_ce: 0.013701
2021-12-17 18:23:25,257 iteration 5990 : loss : 0.058341, loss_ce: 0.014788
2021-12-17 18:23:26,770 iteration 5991 : loss : 0.060444, loss_ce: 0.015228
2021-12-17 18:23:28,252 iteration 5992 : loss : 0.066501, loss_ce: 0.016804
2021-12-17 18:23:29,661 iteration 5993 : loss : 0.051311, loss_ce: 0.016761
2021-12-17 18:23:31,015 iteration 5994 : loss : 0.043917, loss_ce: 0.016436
2021-12-17 18:23:32,545 iteration 5995 : loss : 0.055559, loss_ce: 0.016376
2021-12-17 18:23:34,011 iteration 5996 : loss : 0.052075, loss_ce: 0.023977
2021-12-17 18:23:35,402 iteration 5997 : loss : 0.051311, loss_ce: 0.014344
2021-12-17 18:23:36,939 iteration 5998 : loss : 0.065002, loss_ce: 0.021605
2021-12-17 18:23:38,349 iteration 5999 : loss : 0.056675, loss_ce: 0.015263
2021-12-17 18:23:39,897 iteration 6000 : loss : 0.067180, loss_ce: 0.024850
2021-12-17 18:23:41,258 iteration 6001 : loss : 0.043800, loss_ce: 0.013995
 88%|█████████████████████████▌   | 353/400 [2:39:53<20:12, 25.79s/it]2021-12-17 18:23:42,674 iteration 6002 : loss : 0.048218, loss_ce: 0.015056
2021-12-17 18:23:44,138 iteration 6003 : loss : 0.048176, loss_ce: 0.018346
2021-12-17 18:23:45,558 iteration 6004 : loss : 0.047164, loss_ce: 0.015125
2021-12-17 18:23:46,967 iteration 6005 : loss : 0.058057, loss_ce: 0.020411
2021-12-17 18:23:48,451 iteration 6006 : loss : 0.059059, loss_ce: 0.015335
2021-12-17 18:23:49,853 iteration 6007 : loss : 0.044613, loss_ce: 0.015058
2021-12-17 18:23:51,288 iteration 6008 : loss : 0.059348, loss_ce: 0.019787
2021-12-17 18:23:52,749 iteration 6009 : loss : 0.055212, loss_ce: 0.014619
2021-12-17 18:23:54,135 iteration 6010 : loss : 0.046838, loss_ce: 0.010548
2021-12-17 18:23:55,600 iteration 6011 : loss : 0.073120, loss_ce: 0.018973
2021-12-17 18:23:57,087 iteration 6012 : loss : 0.069277, loss_ce: 0.031102
2021-12-17 18:23:58,496 iteration 6013 : loss : 0.050084, loss_ce: 0.015771
2021-12-17 18:23:59,883 iteration 6014 : loss : 0.050820, loss_ce: 0.015419
2021-12-17 18:24:01,241 iteration 6015 : loss : 0.048703, loss_ce: 0.020090
2021-12-17 18:24:02,649 iteration 6016 : loss : 0.051415, loss_ce: 0.013065
2021-12-17 18:24:04,083 iteration 6017 : loss : 0.051611, loss_ce: 0.014601
2021-12-17 18:24:05,432 iteration 6018 : loss : 0.057679, loss_ce: 0.021134
 88%|█████████████████████████▋   | 354/400 [2:40:17<19:24, 25.31s/it]2021-12-17 18:24:06,962 iteration 6019 : loss : 0.048893, loss_ce: 0.015221
2021-12-17 18:24:08,419 iteration 6020 : loss : 0.066354, loss_ce: 0.017903
2021-12-17 18:24:09,806 iteration 6021 : loss : 0.040716, loss_ce: 0.012492
2021-12-17 18:24:11,252 iteration 6022 : loss : 0.053998, loss_ce: 0.018337
2021-12-17 18:24:12,723 iteration 6023 : loss : 0.048768, loss_ce: 0.018129
2021-12-17 18:24:14,167 iteration 6024 : loss : 0.061190, loss_ce: 0.017986
2021-12-17 18:24:15,556 iteration 6025 : loss : 0.059125, loss_ce: 0.013320
2021-12-17 18:24:16,966 iteration 6026 : loss : 0.057439, loss_ce: 0.018182
2021-12-17 18:24:18,457 iteration 6027 : loss : 0.046552, loss_ce: 0.016081
2021-12-17 18:24:19,859 iteration 6028 : loss : 0.045637, loss_ce: 0.016297
2021-12-17 18:24:21,298 iteration 6029 : loss : 0.057291, loss_ce: 0.022590
2021-12-17 18:24:22,782 iteration 6030 : loss : 0.063153, loss_ce: 0.024994
2021-12-17 18:24:24,239 iteration 6031 : loss : 0.063192, loss_ce: 0.017651
2021-12-17 18:24:25,685 iteration 6032 : loss : 0.064421, loss_ce: 0.017565
2021-12-17 18:24:27,126 iteration 6033 : loss : 0.050944, loss_ce: 0.016677
2021-12-17 18:24:28,528 iteration 6034 : loss : 0.046417, loss_ce: 0.014016
2021-12-17 18:24:28,528 Training Data Eval:
2021-12-17 18:24:35,972   Average segmentation loss on training set: 0.0366
2021-12-17 18:24:35,972 Validation Data Eval:
2021-12-17 18:24:38,564   Average segmentation loss on validation set: 0.1190
2021-12-17 18:24:39,963 iteration 6035 : loss : 0.053393, loss_ce: 0.019539
 89%|█████████████████████████▋   | 355/400 [2:40:51<21:03, 28.08s/it]2021-12-17 18:24:41,452 iteration 6036 : loss : 0.052768, loss_ce: 0.021360
2021-12-17 18:24:42,839 iteration 6037 : loss : 0.042525, loss_ce: 0.014521
2021-12-17 18:24:44,246 iteration 6038 : loss : 0.046319, loss_ce: 0.014746
2021-12-17 18:24:45,590 iteration 6039 : loss : 0.044851, loss_ce: 0.012319
2021-12-17 18:24:46,990 iteration 6040 : loss : 0.054539, loss_ce: 0.013950
2021-12-17 18:24:48,466 iteration 6041 : loss : 0.055766, loss_ce: 0.019219
2021-12-17 18:24:49,853 iteration 6042 : loss : 0.048174, loss_ce: 0.012212
2021-12-17 18:24:51,224 iteration 6043 : loss : 0.047608, loss_ce: 0.011349
2021-12-17 18:24:52,693 iteration 6044 : loss : 0.048495, loss_ce: 0.012890
2021-12-17 18:24:54,093 iteration 6045 : loss : 0.044170, loss_ce: 0.013448
2021-12-17 18:24:55,521 iteration 6046 : loss : 0.059750, loss_ce: 0.025591
2021-12-17 18:24:56,907 iteration 6047 : loss : 0.046286, loss_ce: 0.015115
2021-12-17 18:24:58,364 iteration 6048 : loss : 0.053119, loss_ce: 0.019563
2021-12-17 18:24:59,782 iteration 6049 : loss : 0.048934, loss_ce: 0.019075
2021-12-17 18:25:01,215 iteration 6050 : loss : 0.055894, loss_ce: 0.019465
2021-12-17 18:25:02,749 iteration 6051 : loss : 0.051318, loss_ce: 0.016333
2021-12-17 18:25:04,168 iteration 6052 : loss : 0.061303, loss_ce: 0.026125
 89%|█████████████████████████▊   | 356/400 [2:41:16<19:44, 26.91s/it]2021-12-17 18:25:05,610 iteration 6053 : loss : 0.056756, loss_ce: 0.017131
2021-12-17 18:25:06,980 iteration 6054 : loss : 0.052213, loss_ce: 0.021515
2021-12-17 18:25:08,450 iteration 6055 : loss : 0.058722, loss_ce: 0.019043
2021-12-17 18:25:09,877 iteration 6056 : loss : 0.045171, loss_ce: 0.013083
2021-12-17 18:25:11,265 iteration 6057 : loss : 0.048936, loss_ce: 0.014355
2021-12-17 18:25:12,702 iteration 6058 : loss : 0.074430, loss_ce: 0.020302
2021-12-17 18:25:14,170 iteration 6059 : loss : 0.052161, loss_ce: 0.021287
2021-12-17 18:25:15,732 iteration 6060 : loss : 0.081895, loss_ce: 0.025100
2021-12-17 18:25:17,145 iteration 6061 : loss : 0.047331, loss_ce: 0.015319
2021-12-17 18:25:18,634 iteration 6062 : loss : 0.065284, loss_ce: 0.021582
2021-12-17 18:25:20,015 iteration 6063 : loss : 0.057779, loss_ce: 0.014658
2021-12-17 18:25:21,508 iteration 6064 : loss : 0.057438, loss_ce: 0.021147
2021-12-17 18:25:22,878 iteration 6065 : loss : 0.040929, loss_ce: 0.011251
2021-12-17 18:25:24,267 iteration 6066 : loss : 0.044337, loss_ce: 0.011707
2021-12-17 18:25:25,695 iteration 6067 : loss : 0.049552, loss_ce: 0.018628
2021-12-17 18:25:27,089 iteration 6068 : loss : 0.045597, loss_ce: 0.011023
2021-12-17 18:25:28,516 iteration 6069 : loss : 0.067903, loss_ce: 0.026652
 89%|█████████████████████████▉   | 357/400 [2:41:40<18:44, 26.15s/it]2021-12-17 18:25:30,001 iteration 6070 : loss : 0.044686, loss_ce: 0.018181
2021-12-17 18:25:31,388 iteration 6071 : loss : 0.049525, loss_ce: 0.012669
2021-12-17 18:25:32,788 iteration 6072 : loss : 0.049071, loss_ce: 0.021051
2021-12-17 18:25:34,224 iteration 6073 : loss : 0.051018, loss_ce: 0.015337
2021-12-17 18:25:35,686 iteration 6074 : loss : 0.051751, loss_ce: 0.016845
2021-12-17 18:25:37,035 iteration 6075 : loss : 0.043953, loss_ce: 0.015161
2021-12-17 18:25:38,441 iteration 6076 : loss : 0.044643, loss_ce: 0.009077
2021-12-17 18:25:39,870 iteration 6077 : loss : 0.050572, loss_ce: 0.016742
2021-12-17 18:25:41,352 iteration 6078 : loss : 0.061539, loss_ce: 0.019802
2021-12-17 18:25:42,888 iteration 6079 : loss : 0.050780, loss_ce: 0.017200
2021-12-17 18:25:44,324 iteration 6080 : loss : 0.055125, loss_ce: 0.017944
2021-12-17 18:25:45,783 iteration 6081 : loss : 0.070311, loss_ce: 0.021980
2021-12-17 18:25:47,138 iteration 6082 : loss : 0.047870, loss_ce: 0.011753
2021-12-17 18:25:48,525 iteration 6083 : loss : 0.066009, loss_ce: 0.017989
2021-12-17 18:25:49,960 iteration 6084 : loss : 0.071959, loss_ce: 0.015608
2021-12-17 18:25:51,377 iteration 6085 : loss : 0.084702, loss_ce: 0.023339
2021-12-17 18:25:52,788 iteration 6086 : loss : 0.049885, loss_ce: 0.015485
 90%|█████████████████████████▉   | 358/400 [2:42:04<17:54, 25.58s/it]2021-12-17 18:25:54,197 iteration 6087 : loss : 0.053868, loss_ce: 0.015152
2021-12-17 18:25:55,670 iteration 6088 : loss : 0.054099, loss_ce: 0.018271
2021-12-17 18:25:57,079 iteration 6089 : loss : 0.054607, loss_ce: 0.015929
2021-12-17 18:25:58,404 iteration 6090 : loss : 0.041523, loss_ce: 0.015309
2021-12-17 18:25:59,856 iteration 6091 : loss : 0.053387, loss_ce: 0.016234
2021-12-17 18:26:01,313 iteration 6092 : loss : 0.058423, loss_ce: 0.015062
2021-12-17 18:26:02,743 iteration 6093 : loss : 0.052700, loss_ce: 0.018817
2021-12-17 18:26:04,138 iteration 6094 : loss : 0.057559, loss_ce: 0.017915
2021-12-17 18:26:05,540 iteration 6095 : loss : 0.049111, loss_ce: 0.013646
2021-12-17 18:26:06,985 iteration 6096 : loss : 0.050704, loss_ce: 0.014484
2021-12-17 18:26:08,445 iteration 6097 : loss : 0.040873, loss_ce: 0.012970
2021-12-17 18:26:09,968 iteration 6098 : loss : 0.064528, loss_ce: 0.020657
2021-12-17 18:26:11,446 iteration 6099 : loss : 0.055296, loss_ce: 0.019916
2021-12-17 18:26:12,898 iteration 6100 : loss : 0.055886, loss_ce: 0.025047
2021-12-17 18:26:14,335 iteration 6101 : loss : 0.055960, loss_ce: 0.019571
2021-12-17 18:26:15,806 iteration 6102 : loss : 0.063855, loss_ce: 0.031739
2021-12-17 18:26:17,292 iteration 6103 : loss : 0.062487, loss_ce: 0.020625
 90%|██████████████████████████   | 359/400 [2:42:29<17:15, 25.26s/it]2021-12-17 18:26:18,821 iteration 6104 : loss : 0.061790, loss_ce: 0.022893
2021-12-17 18:26:20,313 iteration 6105 : loss : 0.069575, loss_ce: 0.029408
2021-12-17 18:26:21,770 iteration 6106 : loss : 0.057127, loss_ce: 0.021876
2021-12-17 18:26:23,214 iteration 6107 : loss : 0.050460, loss_ce: 0.017400
2021-12-17 18:26:24,628 iteration 6108 : loss : 0.053830, loss_ce: 0.019635
2021-12-17 18:26:26,052 iteration 6109 : loss : 0.061038, loss_ce: 0.013577
2021-12-17 18:26:27,455 iteration 6110 : loss : 0.046133, loss_ce: 0.015989
2021-12-17 18:26:28,860 iteration 6111 : loss : 0.049417, loss_ce: 0.014725
2021-12-17 18:26:30,285 iteration 6112 : loss : 0.065425, loss_ce: 0.015132
2021-12-17 18:26:31,710 iteration 6113 : loss : 0.049314, loss_ce: 0.017961
2021-12-17 18:26:33,196 iteration 6114 : loss : 0.065126, loss_ce: 0.018381
2021-12-17 18:26:34,629 iteration 6115 : loss : 0.055730, loss_ce: 0.018512
2021-12-17 18:26:36,081 iteration 6116 : loss : 0.058046, loss_ce: 0.016150
2021-12-17 18:26:37,473 iteration 6117 : loss : 0.052813, loss_ce: 0.019483
2021-12-17 18:26:38,839 iteration 6118 : loss : 0.046907, loss_ce: 0.013330
2021-12-17 18:26:40,353 iteration 6119 : loss : 0.067043, loss_ce: 0.028911
2021-12-17 18:26:40,353 Training Data Eval:
2021-12-17 18:26:47,811   Average segmentation loss on training set: 0.0358
2021-12-17 18:26:47,812 Validation Data Eval:
2021-12-17 18:26:50,385   Average segmentation loss on validation set: 0.1122
2021-12-17 18:26:51,821 iteration 6120 : loss : 0.056376, loss_ce: 0.015856
 90%|██████████████████████████   | 360/400 [2:43:03<18:41, 28.04s/it]2021-12-17 18:26:53,285 iteration 6121 : loss : 0.056494, loss_ce: 0.015438
2021-12-17 18:26:54,715 iteration 6122 : loss : 0.054117, loss_ce: 0.019537
2021-12-17 18:26:56,148 iteration 6123 : loss : 0.061763, loss_ce: 0.024371
2021-12-17 18:26:57,532 iteration 6124 : loss : 0.041081, loss_ce: 0.012546
2021-12-17 18:26:58,967 iteration 6125 : loss : 0.070428, loss_ce: 0.029572
2021-12-17 18:27:00,357 iteration 6126 : loss : 0.048769, loss_ce: 0.020083
2021-12-17 18:27:01,834 iteration 6127 : loss : 0.046690, loss_ce: 0.014638
2021-12-17 18:27:03,249 iteration 6128 : loss : 0.064471, loss_ce: 0.020565
2021-12-17 18:27:04,766 iteration 6129 : loss : 0.048754, loss_ce: 0.015112
2021-12-17 18:27:06,156 iteration 6130 : loss : 0.050298, loss_ce: 0.011417
2021-12-17 18:27:07,670 iteration 6131 : loss : 0.058678, loss_ce: 0.024759
2021-12-17 18:27:09,091 iteration 6132 : loss : 0.072599, loss_ce: 0.032845
2021-12-17 18:27:10,542 iteration 6133 : loss : 0.059060, loss_ce: 0.016493
2021-12-17 18:27:11,981 iteration 6134 : loss : 0.066884, loss_ce: 0.021960
2021-12-17 18:27:13,516 iteration 6135 : loss : 0.075175, loss_ce: 0.024904
2021-12-17 18:27:14,947 iteration 6136 : loss : 0.051191, loss_ce: 0.012586
2021-12-17 18:27:16,337 iteration 6137 : loss : 0.054113, loss_ce: 0.020074
 90%|██████████████████████████▏  | 361/400 [2:43:28<17:32, 26.98s/it]2021-12-17 18:27:17,777 iteration 6138 : loss : 0.052845, loss_ce: 0.015280
2021-12-17 18:27:19,192 iteration 6139 : loss : 0.050395, loss_ce: 0.017797
2021-12-17 18:27:20,598 iteration 6140 : loss : 0.055305, loss_ce: 0.021349
2021-12-17 18:27:21,964 iteration 6141 : loss : 0.045470, loss_ce: 0.014441
2021-12-17 18:27:23,319 iteration 6142 : loss : 0.044365, loss_ce: 0.014854
2021-12-17 18:27:24,808 iteration 6143 : loss : 0.048236, loss_ce: 0.011781
2021-12-17 18:27:26,218 iteration 6144 : loss : 0.051878, loss_ce: 0.019785
2021-12-17 18:27:27,609 iteration 6145 : loss : 0.046069, loss_ce: 0.016810
2021-12-17 18:27:28,990 iteration 6146 : loss : 0.057822, loss_ce: 0.015260
2021-12-17 18:27:30,414 iteration 6147 : loss : 0.059296, loss_ce: 0.023546
2021-12-17 18:27:31,894 iteration 6148 : loss : 0.053274, loss_ce: 0.018093
2021-12-17 18:27:33,362 iteration 6149 : loss : 0.066557, loss_ce: 0.022564
2021-12-17 18:27:34,862 iteration 6150 : loss : 0.060227, loss_ce: 0.018997
2021-12-17 18:27:36,354 iteration 6151 : loss : 0.060595, loss_ce: 0.012728
2021-12-17 18:27:37,740 iteration 6152 : loss : 0.045865, loss_ce: 0.015940
2021-12-17 18:27:39,195 iteration 6153 : loss : 0.077430, loss_ce: 0.014821
2021-12-17 18:27:40,646 iteration 6154 : loss : 0.055111, loss_ce: 0.019895
 90%|██████████████████████████▏  | 362/400 [2:43:52<16:34, 26.18s/it]2021-12-17 18:27:42,159 iteration 6155 : loss : 0.069315, loss_ce: 0.023474
2021-12-17 18:27:43,628 iteration 6156 : loss : 0.052689, loss_ce: 0.019746
2021-12-17 18:27:45,067 iteration 6157 : loss : 0.057221, loss_ce: 0.016975
2021-12-17 18:27:46,566 iteration 6158 : loss : 0.055070, loss_ce: 0.013547
2021-12-17 18:27:47,964 iteration 6159 : loss : 0.049168, loss_ce: 0.015147
2021-12-17 18:27:49,383 iteration 6160 : loss : 0.049260, loss_ce: 0.015303
2021-12-17 18:27:50,860 iteration 6161 : loss : 0.057711, loss_ce: 0.015902
2021-12-17 18:27:52,360 iteration 6162 : loss : 0.073061, loss_ce: 0.017968
2021-12-17 18:27:53,796 iteration 6163 : loss : 0.060769, loss_ce: 0.023673
2021-12-17 18:27:55,160 iteration 6164 : loss : 0.040979, loss_ce: 0.010504
2021-12-17 18:27:56,664 iteration 6165 : loss : 0.062389, loss_ce: 0.019770
2021-12-17 18:27:58,067 iteration 6166 : loss : 0.050466, loss_ce: 0.015065
2021-12-17 18:27:59,556 iteration 6167 : loss : 0.051700, loss_ce: 0.020478
2021-12-17 18:28:00,980 iteration 6168 : loss : 0.056852, loss_ce: 0.018485
2021-12-17 18:28:02,401 iteration 6169 : loss : 0.066284, loss_ce: 0.015823
2021-12-17 18:28:03,791 iteration 6170 : loss : 0.050442, loss_ce: 0.020069
2021-12-17 18:28:05,192 iteration 6171 : loss : 0.061837, loss_ce: 0.026272
 91%|██████████████████████████▎  | 363/400 [2:44:17<15:50, 25.69s/it]2021-12-17 18:28:06,655 iteration 6172 : loss : 0.058245, loss_ce: 0.017819
2021-12-17 18:28:08,156 iteration 6173 : loss : 0.083258, loss_ce: 0.020096
2021-12-17 18:28:09,590 iteration 6174 : loss : 0.058241, loss_ce: 0.020739
2021-12-17 18:28:11,134 iteration 6175 : loss : 0.066894, loss_ce: 0.015945
2021-12-17 18:28:12,602 iteration 6176 : loss : 0.051337, loss_ce: 0.016525
2021-12-17 18:28:14,024 iteration 6177 : loss : 0.049478, loss_ce: 0.020573
2021-12-17 18:28:15,472 iteration 6178 : loss : 0.047797, loss_ce: 0.014036
2021-12-17 18:28:16,874 iteration 6179 : loss : 0.054545, loss_ce: 0.015847
2021-12-17 18:28:18,362 iteration 6180 : loss : 0.056218, loss_ce: 0.021344
2021-12-17 18:28:19,756 iteration 6181 : loss : 0.049715, loss_ce: 0.013046
2021-12-17 18:28:21,164 iteration 6182 : loss : 0.052665, loss_ce: 0.014336
2021-12-17 18:28:22,646 iteration 6183 : loss : 0.056137, loss_ce: 0.021298
2021-12-17 18:28:24,098 iteration 6184 : loss : 0.049912, loss_ce: 0.018934
2021-12-17 18:28:25,585 iteration 6185 : loss : 0.071861, loss_ce: 0.017795
2021-12-17 18:28:26,992 iteration 6186 : loss : 0.047521, loss_ce: 0.015015
2021-12-17 18:28:28,435 iteration 6187 : loss : 0.053520, loss_ce: 0.023340
2021-12-17 18:28:29,941 iteration 6188 : loss : 0.069392, loss_ce: 0.027738
 91%|██████████████████████████▍  | 364/400 [2:44:41<15:14, 25.41s/it]2021-12-17 18:28:31,471 iteration 6189 : loss : 0.060873, loss_ce: 0.014144
2021-12-17 18:28:32,951 iteration 6190 : loss : 0.062870, loss_ce: 0.014618
2021-12-17 18:28:34,344 iteration 6191 : loss : 0.048585, loss_ce: 0.020091
2021-12-17 18:28:35,726 iteration 6192 : loss : 0.043078, loss_ce: 0.013238
2021-12-17 18:28:37,172 iteration 6193 : loss : 0.056579, loss_ce: 0.017082
2021-12-17 18:28:38,564 iteration 6194 : loss : 0.051655, loss_ce: 0.018193
2021-12-17 18:28:40,075 iteration 6195 : loss : 0.054109, loss_ce: 0.020344
2021-12-17 18:28:41,485 iteration 6196 : loss : 0.043243, loss_ce: 0.012733
2021-12-17 18:28:42,864 iteration 6197 : loss : 0.051176, loss_ce: 0.019623
2021-12-17 18:28:44,416 iteration 6198 : loss : 0.063713, loss_ce: 0.017452
2021-12-17 18:28:45,834 iteration 6199 : loss : 0.060201, loss_ce: 0.022514
2021-12-17 18:28:47,245 iteration 6200 : loss : 0.045573, loss_ce: 0.016694
2021-12-17 18:28:48,701 iteration 6201 : loss : 0.053483, loss_ce: 0.017452
2021-12-17 18:28:50,085 iteration 6202 : loss : 0.047719, loss_ce: 0.013759
2021-12-17 18:28:51,663 iteration 6203 : loss : 0.065559, loss_ce: 0.025019
2021-12-17 18:28:53,027 iteration 6204 : loss : 0.049346, loss_ce: 0.018878
2021-12-17 18:28:53,027 Training Data Eval:
2021-12-17 18:29:00,487   Average segmentation loss on training set: 0.0358
2021-12-17 18:29:00,487 Validation Data Eval:
2021-12-17 18:29:03,066   Average segmentation loss on validation set: 0.1154
2021-12-17 18:29:04,570 iteration 6205 : loss : 0.058851, loss_ce: 0.018084
 91%|██████████████████████████▍  | 365/400 [2:45:16<16:26, 28.18s/it]2021-12-17 18:29:06,066 iteration 6206 : loss : 0.069508, loss_ce: 0.029809
2021-12-17 18:29:07,531 iteration 6207 : loss : 0.057055, loss_ce: 0.019644
2021-12-17 18:29:09,012 iteration 6208 : loss : 0.072399, loss_ce: 0.019997
2021-12-17 18:29:10,446 iteration 6209 : loss : 0.056376, loss_ce: 0.020375
2021-12-17 18:29:11,900 iteration 6210 : loss : 0.051863, loss_ce: 0.017644
2021-12-17 18:29:13,315 iteration 6211 : loss : 0.064969, loss_ce: 0.025410
2021-12-17 18:29:14,718 iteration 6212 : loss : 0.051709, loss_ce: 0.016108
2021-12-17 18:29:16,071 iteration 6213 : loss : 0.047963, loss_ce: 0.013704
2021-12-17 18:29:17,582 iteration 6214 : loss : 0.070553, loss_ce: 0.024374
2021-12-17 18:29:19,011 iteration 6215 : loss : 0.050273, loss_ce: 0.013080
2021-12-17 18:29:20,454 iteration 6216 : loss : 0.061574, loss_ce: 0.017424
2021-12-17 18:29:21,914 iteration 6217 : loss : 0.063308, loss_ce: 0.024364
2021-12-17 18:29:23,299 iteration 6218 : loss : 0.056636, loss_ce: 0.018679
2021-12-17 18:29:24,751 iteration 6219 : loss : 0.061318, loss_ce: 0.018817
2021-12-17 18:29:26,117 iteration 6220 : loss : 0.046523, loss_ce: 0.012785
2021-12-17 18:29:27,642 iteration 6221 : loss : 0.047740, loss_ce: 0.013551
2021-12-17 18:29:29,074 iteration 6222 : loss : 0.046646, loss_ce: 0.017024
 92%|██████████████████████████▌  | 366/400 [2:45:40<15:20, 27.07s/it]2021-12-17 18:29:30,558 iteration 6223 : loss : 0.064386, loss_ce: 0.027597
2021-12-17 18:29:32,027 iteration 6224 : loss : 0.063614, loss_ce: 0.027087
2021-12-17 18:29:33,494 iteration 6225 : loss : 0.046735, loss_ce: 0.017803
2021-12-17 18:29:34,936 iteration 6226 : loss : 0.053241, loss_ce: 0.018790
2021-12-17 18:29:36,453 iteration 6227 : loss : 0.048328, loss_ce: 0.015669
2021-12-17 18:29:37,872 iteration 6228 : loss : 0.052286, loss_ce: 0.018151
2021-12-17 18:29:39,342 iteration 6229 : loss : 0.052525, loss_ce: 0.015750
2021-12-17 18:29:40,827 iteration 6230 : loss : 0.080580, loss_ce: 0.016918
2021-12-17 18:29:42,215 iteration 6231 : loss : 0.065617, loss_ce: 0.025907
2021-12-17 18:29:43,626 iteration 6232 : loss : 0.050214, loss_ce: 0.015407
2021-12-17 18:29:45,131 iteration 6233 : loss : 0.075185, loss_ce: 0.021590
2021-12-17 18:29:46,547 iteration 6234 : loss : 0.048334, loss_ce: 0.016835
2021-12-17 18:29:47,978 iteration 6235 : loss : 0.059805, loss_ce: 0.017455
2021-12-17 18:29:49,463 iteration 6236 : loss : 0.066154, loss_ce: 0.021044
2021-12-17 18:29:50,930 iteration 6237 : loss : 0.061787, loss_ce: 0.018401
2021-12-17 18:29:52,422 iteration 6238 : loss : 0.046603, loss_ce: 0.015938
2021-12-17 18:29:53,912 iteration 6239 : loss : 0.068353, loss_ce: 0.025910
 92%|██████████████████████████▌  | 367/400 [2:46:05<14:31, 26.40s/it]2021-12-17 18:29:55,327 iteration 6240 : loss : 0.063977, loss_ce: 0.020047
2021-12-17 18:29:56,701 iteration 6241 : loss : 0.063881, loss_ce: 0.024163
2021-12-17 18:29:58,163 iteration 6242 : loss : 0.046018, loss_ce: 0.017018
2021-12-17 18:29:59,589 iteration 6243 : loss : 0.057445, loss_ce: 0.018059
2021-12-17 18:30:01,029 iteration 6244 : loss : 0.059006, loss_ce: 0.019275
2021-12-17 18:30:02,485 iteration 6245 : loss : 0.051228, loss_ce: 0.018442
2021-12-17 18:30:03,899 iteration 6246 : loss : 0.048817, loss_ce: 0.015782
2021-12-17 18:30:05,300 iteration 6247 : loss : 0.052612, loss_ce: 0.016065
2021-12-17 18:30:06,768 iteration 6248 : loss : 0.075104, loss_ce: 0.016722
2021-12-17 18:30:08,236 iteration 6249 : loss : 0.052489, loss_ce: 0.017567
2021-12-17 18:30:09,578 iteration 6250 : loss : 0.062739, loss_ce: 0.012857
2021-12-17 18:30:11,066 iteration 6251 : loss : 0.076817, loss_ce: 0.032327
2021-12-17 18:30:12,444 iteration 6252 : loss : 0.043163, loss_ce: 0.013743
2021-12-17 18:30:13,978 iteration 6253 : loss : 0.071145, loss_ce: 0.024486
2021-12-17 18:30:15,329 iteration 6254 : loss : 0.041364, loss_ce: 0.013998
2021-12-17 18:30:16,918 iteration 6255 : loss : 0.071124, loss_ce: 0.019949
2021-12-17 18:30:18,321 iteration 6256 : loss : 0.067661, loss_ce: 0.027203
 92%|██████████████████████████▋  | 368/400 [2:46:30<13:45, 25.80s/it]2021-12-17 18:30:19,839 iteration 6257 : loss : 0.058584, loss_ce: 0.021566
2021-12-17 18:30:21,243 iteration 6258 : loss : 0.044210, loss_ce: 0.016856
2021-12-17 18:30:22,691 iteration 6259 : loss : 0.052779, loss_ce: 0.021056
2021-12-17 18:30:24,115 iteration 6260 : loss : 0.056428, loss_ce: 0.015110
2021-12-17 18:30:25,518 iteration 6261 : loss : 0.062936, loss_ce: 0.020497
2021-12-17 18:30:26,993 iteration 6262 : loss : 0.073708, loss_ce: 0.027609
2021-12-17 18:30:28,480 iteration 6263 : loss : 0.051645, loss_ce: 0.012370
2021-12-17 18:30:29,902 iteration 6264 : loss : 0.051271, loss_ce: 0.019770
2021-12-17 18:30:31,295 iteration 6265 : loss : 0.048582, loss_ce: 0.017284
2021-12-17 18:30:32,740 iteration 6266 : loss : 0.057005, loss_ce: 0.023845
2021-12-17 18:30:34,173 iteration 6267 : loss : 0.056623, loss_ce: 0.019412
2021-12-17 18:30:35,592 iteration 6268 : loss : 0.053293, loss_ce: 0.017265
2021-12-17 18:30:37,003 iteration 6269 : loss : 0.053858, loss_ce: 0.014747
2021-12-17 18:30:38,459 iteration 6270 : loss : 0.061541, loss_ce: 0.018326
2021-12-17 18:30:39,883 iteration 6271 : loss : 0.052720, loss_ce: 0.012396
2021-12-17 18:30:41,299 iteration 6272 : loss : 0.045358, loss_ce: 0.011280
2021-12-17 18:30:42,658 iteration 6273 : loss : 0.046301, loss_ce: 0.014869
 92%|██████████████████████████▊  | 369/400 [2:46:54<13:06, 25.36s/it]2021-12-17 18:30:44,112 iteration 6274 : loss : 0.052639, loss_ce: 0.014671
2021-12-17 18:30:45,550 iteration 6275 : loss : 0.053733, loss_ce: 0.019753
2021-12-17 18:30:46,972 iteration 6276 : loss : 0.051707, loss_ce: 0.017143
2021-12-17 18:30:48,453 iteration 6277 : loss : 0.059141, loss_ce: 0.015189
2021-12-17 18:30:49,961 iteration 6278 : loss : 0.060803, loss_ce: 0.019561
2021-12-17 18:30:51,497 iteration 6279 : loss : 0.072429, loss_ce: 0.022938
2021-12-17 18:30:52,942 iteration 6280 : loss : 0.051018, loss_ce: 0.020016
2021-12-17 18:30:54,360 iteration 6281 : loss : 0.065601, loss_ce: 0.018037
2021-12-17 18:30:55,765 iteration 6282 : loss : 0.048595, loss_ce: 0.015893
2021-12-17 18:30:57,252 iteration 6283 : loss : 0.057960, loss_ce: 0.016778
2021-12-17 18:30:58,751 iteration 6284 : loss : 0.049208, loss_ce: 0.019773
2021-12-17 18:31:00,169 iteration 6285 : loss : 0.060287, loss_ce: 0.019803
2021-12-17 18:31:01,597 iteration 6286 : loss : 0.050433, loss_ce: 0.019794
2021-12-17 18:31:03,071 iteration 6287 : loss : 0.046379, loss_ce: 0.013797
2021-12-17 18:31:04,570 iteration 6288 : loss : 0.065265, loss_ce: 0.019857
2021-12-17 18:31:05,988 iteration 6289 : loss : 0.052768, loss_ce: 0.015999
2021-12-17 18:31:05,988 Training Data Eval:
2021-12-17 18:31:13,427   Average segmentation loss on training set: 0.0367
2021-12-17 18:31:13,427 Validation Data Eval:
2021-12-17 18:31:16,032   Average segmentation loss on validation set: 0.1178
2021-12-17 18:31:17,439 iteration 6290 : loss : 0.048601, loss_ce: 0.015163
 92%|██████████████████████████▊  | 370/400 [2:47:29<14:05, 28.19s/it]2021-12-17 18:31:18,921 iteration 6291 : loss : 0.059422, loss_ce: 0.012737
2021-12-17 18:31:20,447 iteration 6292 : loss : 0.051647, loss_ce: 0.017310
2021-12-17 18:31:21,855 iteration 6293 : loss : 0.050004, loss_ce: 0.015630
2021-12-17 18:31:23,303 iteration 6294 : loss : 0.053208, loss_ce: 0.017660
2021-12-17 18:31:24,748 iteration 6295 : loss : 0.063553, loss_ce: 0.019315
2021-12-17 18:31:26,171 iteration 6296 : loss : 0.047098, loss_ce: 0.015751
2021-12-17 18:31:27,617 iteration 6297 : loss : 0.068838, loss_ce: 0.017002
2021-12-17 18:31:29,036 iteration 6298 : loss : 0.048192, loss_ce: 0.013745
2021-12-17 18:31:30,511 iteration 6299 : loss : 0.052980, loss_ce: 0.017990
2021-12-17 18:31:31,943 iteration 6300 : loss : 0.051222, loss_ce: 0.016608
2021-12-17 18:31:33,348 iteration 6301 : loss : 0.061834, loss_ce: 0.024349
2021-12-17 18:31:34,742 iteration 6302 : loss : 0.046896, loss_ce: 0.016783
2021-12-17 18:31:36,196 iteration 6303 : loss : 0.051932, loss_ce: 0.018966
2021-12-17 18:31:37,612 iteration 6304 : loss : 0.049587, loss_ce: 0.015401
2021-12-17 18:31:38,992 iteration 6305 : loss : 0.044602, loss_ce: 0.017696
2021-12-17 18:31:40,368 iteration 6306 : loss : 0.046822, loss_ce: 0.014358
2021-12-17 18:31:41,879 iteration 6307 : loss : 0.048791, loss_ce: 0.014476
 93%|██████████████████████████▉  | 371/400 [2:47:53<13:04, 27.07s/it]2021-12-17 18:31:43,330 iteration 6308 : loss : 0.053607, loss_ce: 0.018831
2021-12-17 18:31:44,788 iteration 6309 : loss : 0.052997, loss_ce: 0.017834
2021-12-17 18:31:46,240 iteration 6310 : loss : 0.059554, loss_ce: 0.023073
2021-12-17 18:31:47,643 iteration 6311 : loss : 0.052085, loss_ce: 0.013164
2021-12-17 18:31:49,113 iteration 6312 : loss : 0.049933, loss_ce: 0.015411
2021-12-17 18:31:50,528 iteration 6313 : loss : 0.045778, loss_ce: 0.008308
2021-12-17 18:31:52,003 iteration 6314 : loss : 0.059775, loss_ce: 0.022053
2021-12-17 18:31:53,506 iteration 6315 : loss : 0.058453, loss_ce: 0.018423
2021-12-17 18:31:54,925 iteration 6316 : loss : 0.054310, loss_ce: 0.021877
2021-12-17 18:31:56,385 iteration 6317 : loss : 0.043728, loss_ce: 0.014188
2021-12-17 18:31:57,893 iteration 6318 : loss : 0.056056, loss_ce: 0.022892
2021-12-17 18:31:59,414 iteration 6319 : loss : 0.068559, loss_ce: 0.021561
2021-12-17 18:32:00,923 iteration 6320 : loss : 0.064326, loss_ce: 0.021116
2021-12-17 18:32:02,400 iteration 6321 : loss : 0.077628, loss_ce: 0.025432
2021-12-17 18:32:03,911 iteration 6322 : loss : 0.054316, loss_ce: 0.017289
2021-12-17 18:32:05,228 iteration 6323 : loss : 0.043413, loss_ce: 0.015172
2021-12-17 18:32:06,683 iteration 6324 : loss : 0.052627, loss_ce: 0.012849
 93%|██████████████████████████▉  | 372/400 [2:48:18<12:18, 26.39s/it]2021-12-17 18:32:08,103 iteration 6325 : loss : 0.050496, loss_ce: 0.015103
2021-12-17 18:32:09,470 iteration 6326 : loss : 0.044743, loss_ce: 0.016117
2021-12-17 18:32:10,834 iteration 6327 : loss : 0.047384, loss_ce: 0.015162
2021-12-17 18:32:12,337 iteration 6328 : loss : 0.057294, loss_ce: 0.019483
2021-12-17 18:32:13,854 iteration 6329 : loss : 0.054284, loss_ce: 0.015930
2021-12-17 18:32:15,302 iteration 6330 : loss : 0.045890, loss_ce: 0.015317
2021-12-17 18:32:16,783 iteration 6331 : loss : 0.050896, loss_ce: 0.018229
2021-12-17 18:32:18,191 iteration 6332 : loss : 0.054707, loss_ce: 0.016849
2021-12-17 18:32:19,618 iteration 6333 : loss : 0.053044, loss_ce: 0.018117
2021-12-17 18:32:21,083 iteration 6334 : loss : 0.047716, loss_ce: 0.015952
2021-12-17 18:32:22,654 iteration 6335 : loss : 0.071521, loss_ce: 0.029793
2021-12-17 18:32:24,116 iteration 6336 : loss : 0.053300, loss_ce: 0.017988
2021-12-17 18:32:25,488 iteration 6337 : loss : 0.049882, loss_ce: 0.016982
2021-12-17 18:32:27,005 iteration 6338 : loss : 0.054116, loss_ce: 0.015855
2021-12-17 18:32:28,415 iteration 6339 : loss : 0.044407, loss_ce: 0.012051
2021-12-17 18:32:29,857 iteration 6340 : loss : 0.062163, loss_ce: 0.024052
2021-12-17 18:32:31,324 iteration 6341 : loss : 0.069995, loss_ce: 0.018796
 93%|███████████████████████████  | 373/400 [2:48:43<11:38, 25.86s/it]2021-12-17 18:32:32,898 iteration 6342 : loss : 0.052345, loss_ce: 0.017302
2021-12-17 18:32:34,326 iteration 6343 : loss : 0.053321, loss_ce: 0.013999
2021-12-17 18:32:35,767 iteration 6344 : loss : 0.064291, loss_ce: 0.023205
2021-12-17 18:32:37,216 iteration 6345 : loss : 0.053403, loss_ce: 0.020437
2021-12-17 18:32:38,618 iteration 6346 : loss : 0.048204, loss_ce: 0.012152
2021-12-17 18:32:40,059 iteration 6347 : loss : 0.050381, loss_ce: 0.016231
2021-12-17 18:32:41,602 iteration 6348 : loss : 0.066022, loss_ce: 0.022193
2021-12-17 18:32:42,981 iteration 6349 : loss : 0.048350, loss_ce: 0.017263
2021-12-17 18:32:44,394 iteration 6350 : loss : 0.050789, loss_ce: 0.012437
2021-12-17 18:32:45,805 iteration 6351 : loss : 0.049891, loss_ce: 0.015841
2021-12-17 18:32:47,281 iteration 6352 : loss : 0.048912, loss_ce: 0.017335
2021-12-17 18:32:48,769 iteration 6353 : loss : 0.052570, loss_ce: 0.018233
2021-12-17 18:32:50,289 iteration 6354 : loss : 0.055471, loss_ce: 0.015288
2021-12-17 18:32:51,676 iteration 6355 : loss : 0.049413, loss_ce: 0.019711
2021-12-17 18:32:53,137 iteration 6356 : loss : 0.055340, loss_ce: 0.024788
2021-12-17 18:32:54,556 iteration 6357 : loss : 0.058751, loss_ce: 0.018053
2021-12-17 18:32:56,058 iteration 6358 : loss : 0.059290, loss_ce: 0.018057
 94%|███████████████████████████  | 374/400 [2:49:07<11:03, 25.53s/it]2021-12-17 18:32:57,526 iteration 6359 : loss : 0.051438, loss_ce: 0.015575
2021-12-17 18:32:58,920 iteration 6360 : loss : 0.059629, loss_ce: 0.014443
2021-12-17 18:33:00,376 iteration 6361 : loss : 0.062206, loss_ce: 0.014765
2021-12-17 18:33:01,845 iteration 6362 : loss : 0.055492, loss_ce: 0.022421
2021-12-17 18:33:03,370 iteration 6363 : loss : 0.067604, loss_ce: 0.022474
2021-12-17 18:33:04,753 iteration 6364 : loss : 0.040714, loss_ce: 0.012952
2021-12-17 18:33:06,124 iteration 6365 : loss : 0.051981, loss_ce: 0.017212
2021-12-17 18:33:07,594 iteration 6366 : loss : 0.061743, loss_ce: 0.021470
2021-12-17 18:33:09,006 iteration 6367 : loss : 0.048823, loss_ce: 0.019087
2021-12-17 18:33:10,414 iteration 6368 : loss : 0.054543, loss_ce: 0.015458
2021-12-17 18:33:11,877 iteration 6369 : loss : 0.053130, loss_ce: 0.019243
2021-12-17 18:33:13,358 iteration 6370 : loss : 0.053951, loss_ce: 0.014508
2021-12-17 18:33:14,841 iteration 6371 : loss : 0.069949, loss_ce: 0.024088
2021-12-17 18:33:16,290 iteration 6372 : loss : 0.055961, loss_ce: 0.024512
2021-12-17 18:33:17,608 iteration 6373 : loss : 0.042916, loss_ce: 0.010435
2021-12-17 18:33:19,008 iteration 6374 : loss : 0.043276, loss_ce: 0.015747
2021-12-17 18:33:19,008 Training Data Eval:
2021-12-17 18:33:26,502   Average segmentation loss on training set: 0.0355
2021-12-17 18:33:26,502 Validation Data Eval:
2021-12-17 18:33:29,085   Average segmentation loss on validation set: 0.1162
2021-12-17 18:33:30,537 iteration 6375 : loss : 0.052516, loss_ce: 0.016350
 94%|███████████████████████████▏ | 375/400 [2:49:42<11:45, 28.21s/it]2021-12-17 18:33:32,208 iteration 6376 : loss : 0.060566, loss_ce: 0.021758
2021-12-17 18:33:33,632 iteration 6377 : loss : 0.052298, loss_ce: 0.016351
2021-12-17 18:33:35,026 iteration 6378 : loss : 0.051749, loss_ce: 0.017160
2021-12-17 18:33:36,491 iteration 6379 : loss : 0.056002, loss_ce: 0.011650
2021-12-17 18:33:37,859 iteration 6380 : loss : 0.045472, loss_ce: 0.016519
2021-12-17 18:33:39,237 iteration 6381 : loss : 0.050819, loss_ce: 0.014745
2021-12-17 18:33:40,705 iteration 6382 : loss : 0.060293, loss_ce: 0.022515
2021-12-17 18:33:42,189 iteration 6383 : loss : 0.052582, loss_ce: 0.018747
2021-12-17 18:33:43,605 iteration 6384 : loss : 0.046701, loss_ce: 0.014990
2021-12-17 18:33:45,111 iteration 6385 : loss : 0.064193, loss_ce: 0.024244
2021-12-17 18:33:46,540 iteration 6386 : loss : 0.051647, loss_ce: 0.017364
2021-12-17 18:33:48,078 iteration 6387 : loss : 0.086321, loss_ce: 0.038224
2021-12-17 18:33:49,486 iteration 6388 : loss : 0.041122, loss_ce: 0.012988
2021-12-17 18:33:50,843 iteration 6389 : loss : 0.046006, loss_ce: 0.011926
2021-12-17 18:33:52,273 iteration 6390 : loss : 0.056568, loss_ce: 0.019388
2021-12-17 18:33:53,811 iteration 6391 : loss : 0.081475, loss_ce: 0.020311
2021-12-17 18:33:55,189 iteration 6392 : loss : 0.043647, loss_ce: 0.014025
 94%|███████████████████████████▎ | 376/400 [2:50:07<10:51, 27.14s/it]2021-12-17 18:33:56,679 iteration 6393 : loss : 0.044525, loss_ce: 0.012677
2021-12-17 18:33:58,136 iteration 6394 : loss : 0.058973, loss_ce: 0.020029
2021-12-17 18:33:59,538 iteration 6395 : loss : 0.046072, loss_ce: 0.018481
2021-12-17 18:34:01,055 iteration 6396 : loss : 0.067254, loss_ce: 0.026971
2021-12-17 18:34:02,455 iteration 6397 : loss : 0.057992, loss_ce: 0.020931
2021-12-17 18:34:03,831 iteration 6398 : loss : 0.043901, loss_ce: 0.011736
2021-12-17 18:34:05,273 iteration 6399 : loss : 0.056332, loss_ce: 0.016717
2021-12-17 18:34:06,703 iteration 6400 : loss : 0.049259, loss_ce: 0.019337
2021-12-17 18:34:08,070 iteration 6401 : loss : 0.047978, loss_ce: 0.016343
2021-12-17 18:34:09,515 iteration 6402 : loss : 0.062232, loss_ce: 0.019879
2021-12-17 18:34:11,067 iteration 6403 : loss : 0.063548, loss_ce: 0.021178
2021-12-17 18:34:12,472 iteration 6404 : loss : 0.063823, loss_ce: 0.017141
2021-12-17 18:34:13,906 iteration 6405 : loss : 0.052064, loss_ce: 0.016956
2021-12-17 18:34:15,503 iteration 6406 : loss : 0.075089, loss_ce: 0.029201
2021-12-17 18:34:16,888 iteration 6407 : loss : 0.049185, loss_ce: 0.014031
2021-12-17 18:34:18,334 iteration 6408 : loss : 0.051453, loss_ce: 0.011066
2021-12-17 18:34:19,741 iteration 6409 : loss : 0.052083, loss_ce: 0.018647
 94%|███████████████████████████▎ | 377/400 [2:50:31<10:06, 26.37s/it]2021-12-17 18:34:21,330 iteration 6410 : loss : 0.076973, loss_ce: 0.025831
2021-12-17 18:34:22,834 iteration 6411 : loss : 0.055581, loss_ce: 0.019293
2021-12-17 18:34:24,287 iteration 6412 : loss : 0.055151, loss_ce: 0.021630
2021-12-17 18:34:25,721 iteration 6413 : loss : 0.047620, loss_ce: 0.015762
2021-12-17 18:34:27,181 iteration 6414 : loss : 0.059507, loss_ce: 0.021257
2021-12-17 18:34:28,600 iteration 6415 : loss : 0.058610, loss_ce: 0.017191
2021-12-17 18:34:30,040 iteration 6416 : loss : 0.062599, loss_ce: 0.015856
2021-12-17 18:34:31,509 iteration 6417 : loss : 0.053469, loss_ce: 0.018873
2021-12-17 18:34:32,958 iteration 6418 : loss : 0.049199, loss_ce: 0.016222
2021-12-17 18:34:34,382 iteration 6419 : loss : 0.049691, loss_ce: 0.014732
2021-12-17 18:34:35,883 iteration 6420 : loss : 0.057095, loss_ce: 0.017878
2021-12-17 18:34:37,349 iteration 6421 : loss : 0.051393, loss_ce: 0.016466
2021-12-17 18:34:38,726 iteration 6422 : loss : 0.046600, loss_ce: 0.016252
2021-12-17 18:34:40,215 iteration 6423 : loss : 0.052887, loss_ce: 0.015827
2021-12-17 18:34:41,721 iteration 6424 : loss : 0.054269, loss_ce: 0.022567
2021-12-17 18:34:43,084 iteration 6425 : loss : 0.045209, loss_ce: 0.012332
2021-12-17 18:34:44,572 iteration 6426 : loss : 0.052404, loss_ce: 0.017733
 94%|███████████████████████████▍ | 378/400 [2:50:56<09:29, 25.91s/it]2021-12-17 18:34:46,075 iteration 6427 : loss : 0.054394, loss_ce: 0.017509
2021-12-17 18:34:47,437 iteration 6428 : loss : 0.050523, loss_ce: 0.021157
2021-12-17 18:34:48,912 iteration 6429 : loss : 0.053229, loss_ce: 0.016437
2021-12-17 18:34:50,280 iteration 6430 : loss : 0.046997, loss_ce: 0.011972
2021-12-17 18:34:51,725 iteration 6431 : loss : 0.054744, loss_ce: 0.016157
2021-12-17 18:34:53,183 iteration 6432 : loss : 0.045706, loss_ce: 0.014983
2021-12-17 18:34:54,687 iteration 6433 : loss : 0.050321, loss_ce: 0.016302
2021-12-17 18:34:56,044 iteration 6434 : loss : 0.040122, loss_ce: 0.011661
2021-12-17 18:34:57,491 iteration 6435 : loss : 0.046487, loss_ce: 0.017571
2021-12-17 18:34:58,907 iteration 6436 : loss : 0.051453, loss_ce: 0.016536
2021-12-17 18:35:00,372 iteration 6437 : loss : 0.068503, loss_ce: 0.021306
2021-12-17 18:35:01,878 iteration 6438 : loss : 0.062804, loss_ce: 0.022814
2021-12-17 18:35:03,358 iteration 6439 : loss : 0.056743, loss_ce: 0.019849
2021-12-17 18:35:04,860 iteration 6440 : loss : 0.054263, loss_ce: 0.018595
2021-12-17 18:35:06,334 iteration 6441 : loss : 0.051465, loss_ce: 0.013767
2021-12-17 18:35:07,762 iteration 6442 : loss : 0.055478, loss_ce: 0.018691
2021-12-17 18:35:09,209 iteration 6443 : loss : 0.051245, loss_ce: 0.017932
 95%|███████████████████████████▍ | 379/400 [2:51:21<08:55, 25.52s/it]2021-12-17 18:35:10,744 iteration 6444 : loss : 0.053537, loss_ce: 0.019327
2021-12-17 18:35:12,257 iteration 6445 : loss : 0.055825, loss_ce: 0.020234
2021-12-17 18:35:13,706 iteration 6446 : loss : 0.053862, loss_ce: 0.013785
2021-12-17 18:35:15,143 iteration 6447 : loss : 0.056333, loss_ce: 0.025340
2021-12-17 18:35:16,592 iteration 6448 : loss : 0.047777, loss_ce: 0.019300
2021-12-17 18:35:18,102 iteration 6449 : loss : 0.050914, loss_ce: 0.014625
2021-12-17 18:35:19,492 iteration 6450 : loss : 0.047516, loss_ce: 0.018112
2021-12-17 18:35:20,864 iteration 6451 : loss : 0.049725, loss_ce: 0.014976
2021-12-17 18:35:22,345 iteration 6452 : loss : 0.046887, loss_ce: 0.017586
2021-12-17 18:35:23,791 iteration 6453 : loss : 0.053465, loss_ce: 0.019027
2021-12-17 18:35:25,208 iteration 6454 : loss : 0.055989, loss_ce: 0.016562
2021-12-17 18:35:26,633 iteration 6455 : loss : 0.051264, loss_ce: 0.013972
2021-12-17 18:35:28,188 iteration 6456 : loss : 0.061297, loss_ce: 0.021154
2021-12-17 18:35:29,640 iteration 6457 : loss : 0.049525, loss_ce: 0.013085
2021-12-17 18:35:31,046 iteration 6458 : loss : 0.046905, loss_ce: 0.011823
2021-12-17 18:35:32,444 iteration 6459 : loss : 0.048331, loss_ce: 0.014102
2021-12-17 18:35:32,444 Training Data Eval:
2021-12-17 18:35:39,909   Average segmentation loss on training set: 0.0354
2021-12-17 18:35:39,910 Validation Data Eval:
2021-12-17 18:35:42,494   Average segmentation loss on validation set: 0.1274
2021-12-17 18:35:43,972 iteration 6460 : loss : 0.066361, loss_ce: 0.017894
 95%|███████████████████████████▌ | 380/400 [2:51:55<09:25, 28.30s/it]2021-12-17 18:35:45,482 iteration 6461 : loss : 0.067388, loss_ce: 0.017586
2021-12-17 18:35:46,926 iteration 6462 : loss : 0.062545, loss_ce: 0.019221
2021-12-17 18:35:48,324 iteration 6463 : loss : 0.049760, loss_ce: 0.013356
2021-12-17 18:35:49,727 iteration 6464 : loss : 0.046237, loss_ce: 0.013332
2021-12-17 18:35:51,164 iteration 6465 : loss : 0.063732, loss_ce: 0.018321
2021-12-17 18:35:52,633 iteration 6466 : loss : 0.058790, loss_ce: 0.018701
2021-12-17 18:35:54,119 iteration 6467 : loss : 0.054331, loss_ce: 0.017805
2021-12-17 18:35:55,633 iteration 6468 : loss : 0.076042, loss_ce: 0.038011
2021-12-17 18:35:57,066 iteration 6469 : loss : 0.057663, loss_ce: 0.025814
2021-12-17 18:35:58,494 iteration 6470 : loss : 0.056676, loss_ce: 0.015704
2021-12-17 18:35:59,912 iteration 6471 : loss : 0.063546, loss_ce: 0.020144
2021-12-17 18:36:01,346 iteration 6472 : loss : 0.049704, loss_ce: 0.012895
2021-12-17 18:36:02,719 iteration 6473 : loss : 0.051444, loss_ce: 0.022327
2021-12-17 18:36:04,217 iteration 6474 : loss : 0.057784, loss_ce: 0.024395
2021-12-17 18:36:05,593 iteration 6475 : loss : 0.038381, loss_ce: 0.011380
2021-12-17 18:36:07,008 iteration 6476 : loss : 0.047256, loss_ce: 0.014740
2021-12-17 18:36:08,379 iteration 6477 : loss : 0.044564, loss_ce: 0.013664
 95%|███████████████████████████▌ | 381/400 [2:52:20<08:35, 27.13s/it]2021-12-17 18:36:09,890 iteration 6478 : loss : 0.050401, loss_ce: 0.017975
2021-12-17 18:36:11,484 iteration 6479 : loss : 0.065596, loss_ce: 0.032727
2021-12-17 18:36:12,944 iteration 6480 : loss : 0.064988, loss_ce: 0.014466
2021-12-17 18:36:14,403 iteration 6481 : loss : 0.059801, loss_ce: 0.021328
2021-12-17 18:36:15,867 iteration 6482 : loss : 0.057684, loss_ce: 0.019741
2021-12-17 18:36:17,295 iteration 6483 : loss : 0.053834, loss_ce: 0.018197
2021-12-17 18:36:18,731 iteration 6484 : loss : 0.050494, loss_ce: 0.013721
2021-12-17 18:36:20,189 iteration 6485 : loss : 0.050992, loss_ce: 0.018833
2021-12-17 18:36:21,707 iteration 6486 : loss : 0.053374, loss_ce: 0.016227
2021-12-17 18:36:23,174 iteration 6487 : loss : 0.055968, loss_ce: 0.015541
2021-12-17 18:36:24,521 iteration 6488 : loss : 0.044090, loss_ce: 0.016088
2021-12-17 18:36:26,017 iteration 6489 : loss : 0.066234, loss_ce: 0.016150
2021-12-17 18:36:27,374 iteration 6490 : loss : 0.043125, loss_ce: 0.013463
2021-12-17 18:36:28,864 iteration 6491 : loss : 0.057944, loss_ce: 0.016048
2021-12-17 18:36:30,269 iteration 6492 : loss : 0.048176, loss_ce: 0.016084
2021-12-17 18:36:31,741 iteration 6493 : loss : 0.067570, loss_ce: 0.020829
2021-12-17 18:36:33,182 iteration 6494 : loss : 0.050674, loss_ce: 0.014875
 96%|███████████████████████████▋ | 382/400 [2:52:45<07:55, 26.43s/it]2021-12-17 18:36:34,701 iteration 6495 : loss : 0.049904, loss_ce: 0.011636
2021-12-17 18:36:36,119 iteration 6496 : loss : 0.057769, loss_ce: 0.016294
2021-12-17 18:36:37,594 iteration 6497 : loss : 0.047329, loss_ce: 0.015356
2021-12-17 18:36:39,044 iteration 6498 : loss : 0.089770, loss_ce: 0.039815
2021-12-17 18:36:40,602 iteration 6499 : loss : 0.064196, loss_ce: 0.021080
2021-12-17 18:36:42,075 iteration 6500 : loss : 0.062910, loss_ce: 0.021432
2021-12-17 18:36:43,585 iteration 6501 : loss : 0.051972, loss_ce: 0.012589
2021-12-17 18:36:45,060 iteration 6502 : loss : 0.068595, loss_ce: 0.025732
2021-12-17 18:36:46,576 iteration 6503 : loss : 0.049733, loss_ce: 0.016748
2021-12-17 18:36:47,952 iteration 6504 : loss : 0.048370, loss_ce: 0.021023
2021-12-17 18:36:49,368 iteration 6505 : loss : 0.051358, loss_ce: 0.012950
2021-12-17 18:36:50,797 iteration 6506 : loss : 0.051901, loss_ce: 0.014998
2021-12-17 18:36:52,223 iteration 6507 : loss : 0.056437, loss_ce: 0.021110
2021-12-17 18:36:53,669 iteration 6508 : loss : 0.057621, loss_ce: 0.015132
2021-12-17 18:36:55,107 iteration 6509 : loss : 0.050077, loss_ce: 0.018732
2021-12-17 18:36:56,514 iteration 6510 : loss : 0.051250, loss_ce: 0.014546
2021-12-17 18:36:57,955 iteration 6511 : loss : 0.052319, loss_ce: 0.019868
 96%|███████████████████████████▊ | 383/400 [2:53:09<07:20, 25.93s/it]2021-12-17 18:36:59,444 iteration 6512 : loss : 0.058133, loss_ce: 0.021472
2021-12-17 18:37:00,824 iteration 6513 : loss : 0.065156, loss_ce: 0.021381
2021-12-17 18:37:02,242 iteration 6514 : loss : 0.052157, loss_ce: 0.012027
2021-12-17 18:37:03,685 iteration 6515 : loss : 0.047263, loss_ce: 0.013656
2021-12-17 18:37:05,140 iteration 6516 : loss : 0.049833, loss_ce: 0.014406
2021-12-17 18:37:06,669 iteration 6517 : loss : 0.066116, loss_ce: 0.028222
2021-12-17 18:37:08,048 iteration 6518 : loss : 0.059951, loss_ce: 0.020175
2021-12-17 18:37:09,552 iteration 6519 : loss : 0.066780, loss_ce: 0.018709
2021-12-17 18:37:10,921 iteration 6520 : loss : 0.047129, loss_ce: 0.019292
2021-12-17 18:37:12,406 iteration 6521 : loss : 0.043318, loss_ce: 0.015688
2021-12-17 18:37:13,834 iteration 6522 : loss : 0.062538, loss_ce: 0.023047
2021-12-17 18:37:15,227 iteration 6523 : loss : 0.057823, loss_ce: 0.014921
2021-12-17 18:37:16,668 iteration 6524 : loss : 0.053913, loss_ce: 0.017570
2021-12-17 18:37:18,093 iteration 6525 : loss : 0.046026, loss_ce: 0.013777
2021-12-17 18:37:19,548 iteration 6526 : loss : 0.050303, loss_ce: 0.016355
2021-12-17 18:37:21,056 iteration 6527 : loss : 0.057982, loss_ce: 0.016770
2021-12-17 18:37:22,509 iteration 6528 : loss : 0.053655, loss_ce: 0.017972
 96%|███████████████████████████▊ | 384/400 [2:53:34<06:48, 25.52s/it]2021-12-17 18:37:23,943 iteration 6529 : loss : 0.052436, loss_ce: 0.018943
2021-12-17 18:37:25,314 iteration 6530 : loss : 0.043890, loss_ce: 0.016535
2021-12-17 18:37:26,772 iteration 6531 : loss : 0.060338, loss_ce: 0.011831
2021-12-17 18:37:28,255 iteration 6532 : loss : 0.052510, loss_ce: 0.017230
2021-12-17 18:37:29,661 iteration 6533 : loss : 0.057569, loss_ce: 0.020584
2021-12-17 18:37:31,150 iteration 6534 : loss : 0.056670, loss_ce: 0.017087
2021-12-17 18:37:32,591 iteration 6535 : loss : 0.051149, loss_ce: 0.017711
2021-12-17 18:37:34,070 iteration 6536 : loss : 0.055281, loss_ce: 0.020249
2021-12-17 18:37:35,606 iteration 6537 : loss : 0.058931, loss_ce: 0.016869
2021-12-17 18:37:37,012 iteration 6538 : loss : 0.058221, loss_ce: 0.017121
2021-12-17 18:37:38,573 iteration 6539 : loss : 0.072186, loss_ce: 0.023633
2021-12-17 18:37:39,961 iteration 6540 : loss : 0.060358, loss_ce: 0.023927
2021-12-17 18:37:41,326 iteration 6541 : loss : 0.044143, loss_ce: 0.014586
2021-12-17 18:37:42,761 iteration 6542 : loss : 0.067005, loss_ce: 0.021371
2021-12-17 18:37:44,277 iteration 6543 : loss : 0.055315, loss_ce: 0.017276
2021-12-17 18:37:45,700 iteration 6544 : loss : 0.053192, loss_ce: 0.019633
2021-12-17 18:37:45,701 Training Data Eval:
2021-12-17 18:37:53,149   Average segmentation loss on training set: 0.0358
2021-12-17 18:37:53,150 Validation Data Eval:
2021-12-17 18:37:55,713   Average segmentation loss on validation set: 0.1188
2021-12-17 18:37:57,164 iteration 6545 : loss : 0.048878, loss_ce: 0.012242
 96%|███████████████████████████▉ | 385/400 [2:54:09<07:03, 28.26s/it]2021-12-17 18:37:58,732 iteration 6546 : loss : 0.049653, loss_ce: 0.015573
2021-12-17 18:38:00,115 iteration 6547 : loss : 0.043718, loss_ce: 0.009792
2021-12-17 18:38:01,577 iteration 6548 : loss : 0.063660, loss_ce: 0.015238
2021-12-17 18:38:03,121 iteration 6549 : loss : 0.064339, loss_ce: 0.020762
2021-12-17 18:38:04,536 iteration 6550 : loss : 0.055251, loss_ce: 0.020428
2021-12-17 18:38:06,041 iteration 6551 : loss : 0.083639, loss_ce: 0.033572
2021-12-17 18:38:07,575 iteration 6552 : loss : 0.071398, loss_ce: 0.022303
2021-12-17 18:38:09,010 iteration 6553 : loss : 0.054551, loss_ce: 0.017175
2021-12-17 18:38:10,578 iteration 6554 : loss : 0.069111, loss_ce: 0.019340
2021-12-17 18:38:11,981 iteration 6555 : loss : 0.067726, loss_ce: 0.021515
2021-12-17 18:38:13,445 iteration 6556 : loss : 0.050871, loss_ce: 0.015369
2021-12-17 18:38:14,802 iteration 6557 : loss : 0.040463, loss_ce: 0.012317
2021-12-17 18:38:16,299 iteration 6558 : loss : 0.064517, loss_ce: 0.024132
2021-12-17 18:38:17,681 iteration 6559 : loss : 0.042450, loss_ce: 0.013199
2021-12-17 18:38:19,085 iteration 6560 : loss : 0.045169, loss_ce: 0.018689
2021-12-17 18:38:20,542 iteration 6561 : loss : 0.061566, loss_ce: 0.018608
2021-12-17 18:38:21,981 iteration 6562 : loss : 0.055348, loss_ce: 0.019102
 96%|███████████████████████████▉ | 386/400 [2:54:33<06:21, 27.23s/it]2021-12-17 18:38:23,482 iteration 6563 : loss : 0.057189, loss_ce: 0.023715
2021-12-17 18:38:25,007 iteration 6564 : loss : 0.058822, loss_ce: 0.016229
2021-12-17 18:38:26,394 iteration 6565 : loss : 0.048372, loss_ce: 0.012192
2021-12-17 18:38:27,903 iteration 6566 : loss : 0.073645, loss_ce: 0.023054
2021-12-17 18:38:29,360 iteration 6567 : loss : 0.094680, loss_ce: 0.018814
2021-12-17 18:38:30,799 iteration 6568 : loss : 0.046517, loss_ce: 0.015681
2021-12-17 18:38:32,203 iteration 6569 : loss : 0.061442, loss_ce: 0.016359
2021-12-17 18:38:33,729 iteration 6570 : loss : 0.064769, loss_ce: 0.025562
2021-12-17 18:38:35,104 iteration 6571 : loss : 0.048609, loss_ce: 0.018025
2021-12-17 18:38:36,513 iteration 6572 : loss : 0.050999, loss_ce: 0.015113
2021-12-17 18:38:37,898 iteration 6573 : loss : 0.041925, loss_ce: 0.010852
2021-12-17 18:38:39,346 iteration 6574 : loss : 0.051821, loss_ce: 0.017601
2021-12-17 18:38:40,703 iteration 6575 : loss : 0.042214, loss_ce: 0.015267
2021-12-17 18:38:42,161 iteration 6576 : loss : 0.054332, loss_ce: 0.019421
2021-12-17 18:38:43,633 iteration 6577 : loss : 0.055154, loss_ce: 0.018494
2021-12-17 18:38:45,081 iteration 6578 : loss : 0.076538, loss_ce: 0.029042
2021-12-17 18:38:46,501 iteration 6579 : loss : 0.049344, loss_ce: 0.011782
 97%|████████████████████████████ | 387/400 [2:54:58<05:43, 26.42s/it]2021-12-17 18:38:48,023 iteration 6580 : loss : 0.057446, loss_ce: 0.019726
2021-12-17 18:38:49,499 iteration 6581 : loss : 0.061558, loss_ce: 0.016539
2021-12-17 18:38:51,007 iteration 6582 : loss : 0.068794, loss_ce: 0.030025
2021-12-17 18:38:52,453 iteration 6583 : loss : 0.049040, loss_ce: 0.017097
2021-12-17 18:38:53,911 iteration 6584 : loss : 0.053511, loss_ce: 0.016934
2021-12-17 18:38:55,309 iteration 6585 : loss : 0.050862, loss_ce: 0.015219
2021-12-17 18:38:56,776 iteration 6586 : loss : 0.052497, loss_ce: 0.017577
2021-12-17 18:38:58,153 iteration 6587 : loss : 0.051612, loss_ce: 0.018810
2021-12-17 18:38:59,641 iteration 6588 : loss : 0.058638, loss_ce: 0.018320
2021-12-17 18:39:01,096 iteration 6589 : loss : 0.056496, loss_ce: 0.019644
2021-12-17 18:39:02,513 iteration 6590 : loss : 0.045997, loss_ce: 0.015529
2021-12-17 18:39:03,918 iteration 6591 : loss : 0.055225, loss_ce: 0.022292
2021-12-17 18:39:05,363 iteration 6592 : loss : 0.059752, loss_ce: 0.019833
2021-12-17 18:39:06,858 iteration 6593 : loss : 0.064163, loss_ce: 0.025439
2021-12-17 18:39:08,261 iteration 6594 : loss : 0.046726, loss_ce: 0.015088
2021-12-17 18:39:09,639 iteration 6595 : loss : 0.044956, loss_ce: 0.012054
2021-12-17 18:39:11,042 iteration 6596 : loss : 0.038417, loss_ce: 0.011821
 97%|████████████████████████████▏| 388/400 [2:55:22<05:10, 25.85s/it]2021-12-17 18:39:12,586 iteration 6597 : loss : 0.057069, loss_ce: 0.023076
2021-12-17 18:39:14,083 iteration 6598 : loss : 0.080829, loss_ce: 0.020204
2021-12-17 18:39:15,466 iteration 6599 : loss : 0.046123, loss_ce: 0.015341
2021-12-17 18:39:16,956 iteration 6600 : loss : 0.062699, loss_ce: 0.020518
2021-12-17 18:39:18,341 iteration 6601 : loss : 0.045609, loss_ce: 0.016928
2021-12-17 18:39:19,684 iteration 6602 : loss : 0.041243, loss_ce: 0.011328
2021-12-17 18:39:21,147 iteration 6603 : loss : 0.076940, loss_ce: 0.018680
2021-12-17 18:39:22,681 iteration 6604 : loss : 0.052601, loss_ce: 0.016307
2021-12-17 18:39:24,147 iteration 6605 : loss : 0.057827, loss_ce: 0.020071
2021-12-17 18:39:25,595 iteration 6606 : loss : 0.055542, loss_ce: 0.023641
2021-12-17 18:39:27,006 iteration 6607 : loss : 0.054718, loss_ce: 0.017015
2021-12-17 18:39:28,492 iteration 6608 : loss : 0.058186, loss_ce: 0.016493
2021-12-17 18:39:29,982 iteration 6609 : loss : 0.058235, loss_ce: 0.022118
2021-12-17 18:39:31,388 iteration 6610 : loss : 0.070908, loss_ce: 0.018858
2021-12-17 18:39:32,743 iteration 6611 : loss : 0.048130, loss_ce: 0.017821
2021-12-17 18:39:34,207 iteration 6612 : loss : 0.053731, loss_ce: 0.019998
2021-12-17 18:39:35,720 iteration 6613 : loss : 0.080463, loss_ce: 0.019763
 97%|████████████████████████████▏| 389/400 [2:55:47<04:40, 25.50s/it]2021-12-17 18:39:37,087 iteration 6614 : loss : 0.045289, loss_ce: 0.015286
2021-12-17 18:39:38,557 iteration 6615 : loss : 0.093333, loss_ce: 0.038356
2021-12-17 18:39:40,029 iteration 6616 : loss : 0.048098, loss_ce: 0.016910
2021-12-17 18:39:41,438 iteration 6617 : loss : 0.063697, loss_ce: 0.013717
2021-12-17 18:39:42,881 iteration 6618 : loss : 0.051301, loss_ce: 0.014758
2021-12-17 18:39:44,377 iteration 6619 : loss : 0.048496, loss_ce: 0.015738
2021-12-17 18:39:45,814 iteration 6620 : loss : 0.057749, loss_ce: 0.018320
2021-12-17 18:39:47,183 iteration 6621 : loss : 0.049616, loss_ce: 0.018026
2021-12-17 18:39:48,525 iteration 6622 : loss : 0.040823, loss_ce: 0.011299
2021-12-17 18:39:49,987 iteration 6623 : loss : 0.061597, loss_ce: 0.026552
2021-12-17 18:39:51,331 iteration 6624 : loss : 0.041838, loss_ce: 0.013424
2021-12-17 18:39:52,670 iteration 6625 : loss : 0.040669, loss_ce: 0.014022
2021-12-17 18:39:54,116 iteration 6626 : loss : 0.060598, loss_ce: 0.020568
2021-12-17 18:39:55,495 iteration 6627 : loss : 0.047356, loss_ce: 0.014691
2021-12-17 18:39:56,968 iteration 6628 : loss : 0.056199, loss_ce: 0.020522
2021-12-17 18:39:58,356 iteration 6629 : loss : 0.047107, loss_ce: 0.014924
2021-12-17 18:39:58,356 Training Data Eval:
2021-12-17 18:40:05,834   Average segmentation loss on training set: 0.0355
2021-12-17 18:40:05,834 Validation Data Eval:
2021-12-17 18:40:08,466   Average segmentation loss on validation set: 0.1165
2021-12-17 18:40:09,929 iteration 6630 : loss : 0.056627, loss_ce: 0.018861
 98%|████████████████████████████▎| 390/400 [2:56:21<04:41, 28.11s/it]2021-12-17 18:40:11,301 iteration 6631 : loss : 0.044086, loss_ce: 0.014474
2021-12-17 18:40:12,753 iteration 6632 : loss : 0.061748, loss_ce: 0.014338
2021-12-17 18:40:14,179 iteration 6633 : loss : 0.068723, loss_ce: 0.022662
2021-12-17 18:40:15,583 iteration 6634 : loss : 0.047436, loss_ce: 0.015072
2021-12-17 18:40:17,063 iteration 6635 : loss : 0.050914, loss_ce: 0.015531
2021-12-17 18:40:18,470 iteration 6636 : loss : 0.047339, loss_ce: 0.020404
2021-12-17 18:40:19,930 iteration 6637 : loss : 0.057615, loss_ce: 0.018061
2021-12-17 18:40:21,392 iteration 6638 : loss : 0.040309, loss_ce: 0.010767
2021-12-17 18:40:22,839 iteration 6639 : loss : 0.056646, loss_ce: 0.015365
2021-12-17 18:40:24,297 iteration 6640 : loss : 0.050719, loss_ce: 0.012812
2021-12-17 18:40:25,728 iteration 6641 : loss : 0.055752, loss_ce: 0.020518
2021-12-17 18:40:27,161 iteration 6642 : loss : 0.047845, loss_ce: 0.013312
2021-12-17 18:40:28,661 iteration 6643 : loss : 0.058500, loss_ce: 0.023555
2021-12-17 18:40:30,173 iteration 6644 : loss : 0.067171, loss_ce: 0.025635
2021-12-17 18:40:31,610 iteration 6645 : loss : 0.056562, loss_ce: 0.020824
2021-12-17 18:40:33,049 iteration 6646 : loss : 0.050055, loss_ce: 0.019692
2021-12-17 18:40:34,480 iteration 6647 : loss : 0.051529, loss_ce: 0.010185
 98%|████████████████████████████▎| 391/400 [2:56:46<04:03, 27.04s/it]2021-12-17 18:40:35,971 iteration 6648 : loss : 0.080001, loss_ce: 0.028833
2021-12-17 18:40:37,445 iteration 6649 : loss : 0.066566, loss_ce: 0.015719
2021-12-17 18:40:38,832 iteration 6650 : loss : 0.042237, loss_ce: 0.013228
2021-12-17 18:40:40,244 iteration 6651 : loss : 0.049072, loss_ce: 0.017224
2021-12-17 18:40:41,727 iteration 6652 : loss : 0.061304, loss_ce: 0.018352
2021-12-17 18:40:43,218 iteration 6653 : loss : 0.056138, loss_ce: 0.017541
2021-12-17 18:40:44,800 iteration 6654 : loss : 0.069373, loss_ce: 0.023553
2021-12-17 18:40:46,207 iteration 6655 : loss : 0.048487, loss_ce: 0.018378
2021-12-17 18:40:47,739 iteration 6656 : loss : 0.061879, loss_ce: 0.021089
2021-12-17 18:40:49,191 iteration 6657 : loss : 0.056468, loss_ce: 0.015749
2021-12-17 18:40:50,697 iteration 6658 : loss : 0.079836, loss_ce: 0.029926
2021-12-17 18:40:52,147 iteration 6659 : loss : 0.069067, loss_ce: 0.019228
2021-12-17 18:40:53,583 iteration 6660 : loss : 0.046547, loss_ce: 0.015017
2021-12-17 18:40:54,987 iteration 6661 : loss : 0.051556, loss_ce: 0.017573
2021-12-17 18:40:56,465 iteration 6662 : loss : 0.059545, loss_ce: 0.020537
2021-12-17 18:40:57,888 iteration 6663 : loss : 0.044892, loss_ce: 0.014860
2021-12-17 18:40:59,365 iteration 6664 : loss : 0.047299, loss_ce: 0.017666
 98%|████████████████████████████▍| 392/400 [2:57:11<03:31, 26.40s/it]2021-12-17 18:41:00,852 iteration 6665 : loss : 0.061802, loss_ce: 0.021217
2021-12-17 18:41:02,340 iteration 6666 : loss : 0.041438, loss_ce: 0.012257
2021-12-17 18:41:03,780 iteration 6667 : loss : 0.050949, loss_ce: 0.017796
2021-12-17 18:41:05,319 iteration 6668 : loss : 0.056962, loss_ce: 0.023043
2021-12-17 18:41:06,688 iteration 6669 : loss : 0.057100, loss_ce: 0.019070
2021-12-17 18:41:08,093 iteration 6670 : loss : 0.047587, loss_ce: 0.015289
2021-12-17 18:41:09,513 iteration 6671 : loss : 0.053511, loss_ce: 0.018163
2021-12-17 18:41:10,878 iteration 6672 : loss : 0.045905, loss_ce: 0.011870
2021-12-17 18:41:12,350 iteration 6673 : loss : 0.064753, loss_ce: 0.023359
2021-12-17 18:41:13,773 iteration 6674 : loss : 0.046766, loss_ce: 0.016781
2021-12-17 18:41:15,239 iteration 6675 : loss : 0.052856, loss_ce: 0.016244
2021-12-17 18:41:16,624 iteration 6676 : loss : 0.044372, loss_ce: 0.012494
2021-12-17 18:41:18,039 iteration 6677 : loss : 0.065693, loss_ce: 0.017042
2021-12-17 18:41:19,374 iteration 6678 : loss : 0.041439, loss_ce: 0.014976
2021-12-17 18:41:20,926 iteration 6679 : loss : 0.049300, loss_ce: 0.018037
2021-12-17 18:41:22,380 iteration 6680 : loss : 0.058649, loss_ce: 0.019976
2021-12-17 18:41:23,867 iteration 6681 : loss : 0.054705, loss_ce: 0.019183
 98%|████████████████████████████▍| 393/400 [2:57:35<03:00, 25.83s/it]2021-12-17 18:41:25,365 iteration 6682 : loss : 0.048669, loss_ce: 0.018189
2021-12-17 18:41:26,881 iteration 6683 : loss : 0.054436, loss_ce: 0.017048
2021-12-17 18:41:28,261 iteration 6684 : loss : 0.046366, loss_ce: 0.013711
2021-12-17 18:41:29,740 iteration 6685 : loss : 0.060274, loss_ce: 0.021471
2021-12-17 18:41:31,134 iteration 6686 : loss : 0.052341, loss_ce: 0.018400
2021-12-17 18:41:32,578 iteration 6687 : loss : 0.071520, loss_ce: 0.015428
2021-12-17 18:41:34,070 iteration 6688 : loss : 0.048721, loss_ce: 0.016809
2021-12-17 18:41:35,482 iteration 6689 : loss : 0.048899, loss_ce: 0.013284
2021-12-17 18:41:36,881 iteration 6690 : loss : 0.051936, loss_ce: 0.017935
2021-12-17 18:41:38,387 iteration 6691 : loss : 0.064210, loss_ce: 0.024177
2021-12-17 18:41:39,856 iteration 6692 : loss : 0.051598, loss_ce: 0.014842
2021-12-17 18:41:41,361 iteration 6693 : loss : 0.067057, loss_ce: 0.021901
2021-12-17 18:41:42,816 iteration 6694 : loss : 0.051797, loss_ce: 0.017646
2021-12-17 18:41:44,292 iteration 6695 : loss : 0.057335, loss_ce: 0.021870
2021-12-17 18:41:45,671 iteration 6696 : loss : 0.050404, loss_ce: 0.019461
2021-12-17 18:41:47,152 iteration 6697 : loss : 0.054150, loss_ce: 0.016473
2021-12-17 18:41:48,604 iteration 6698 : loss : 0.050402, loss_ce: 0.016213
 98%|████████████████████████████▌| 394/400 [2:58:00<02:33, 25.50s/it]2021-12-17 18:41:50,043 iteration 6699 : loss : 0.050252, loss_ce: 0.021913
2021-12-17 18:41:51,561 iteration 6700 : loss : 0.057834, loss_ce: 0.022255
2021-12-17 18:41:52,980 iteration 6701 : loss : 0.054925, loss_ce: 0.019314
2021-12-17 18:41:54,388 iteration 6702 : loss : 0.064551, loss_ce: 0.019993
2021-12-17 18:41:55,801 iteration 6703 : loss : 0.055578, loss_ce: 0.014934
2021-12-17 18:41:57,292 iteration 6704 : loss : 0.065961, loss_ce: 0.019394
2021-12-17 18:41:58,705 iteration 6705 : loss : 0.052969, loss_ce: 0.016166
2021-12-17 18:42:00,122 iteration 6706 : loss : 0.045594, loss_ce: 0.016856
2021-12-17 18:42:01,525 iteration 6707 : loss : 0.053856, loss_ce: 0.014362
2021-12-17 18:42:02,895 iteration 6708 : loss : 0.047361, loss_ce: 0.015110
2021-12-17 18:42:04,291 iteration 6709 : loss : 0.041638, loss_ce: 0.011129
2021-12-17 18:42:05,707 iteration 6710 : loss : 0.049252, loss_ce: 0.016180
2021-12-17 18:42:07,118 iteration 6711 : loss : 0.069056, loss_ce: 0.014512
2021-12-17 18:42:08,599 iteration 6712 : loss : 0.055248, loss_ce: 0.019191
2021-12-17 18:42:10,098 iteration 6713 : loss : 0.055275, loss_ce: 0.017914
2021-12-17 18:42:11,545 iteration 6714 : loss : 0.051466, loss_ce: 0.019578
2021-12-17 18:42:11,546 Training Data Eval:
2021-12-17 18:42:18,993   Average segmentation loss on training set: 0.0351
2021-12-17 18:42:18,993 Validation Data Eval:
2021-12-17 18:42:21,588   Average segmentation loss on validation set: 0.1171
2021-12-17 18:42:23,076 iteration 6715 : loss : 0.056213, loss_ce: 0.016063
 99%|████████████████████████████▋| 395/400 [2:58:35<02:20, 28.19s/it]2021-12-17 18:42:24,583 iteration 6716 : loss : 0.041222, loss_ce: 0.012409
2021-12-17 18:42:26,037 iteration 6717 : loss : 0.058059, loss_ce: 0.019846
2021-12-17 18:42:27,416 iteration 6718 : loss : 0.041492, loss_ce: 0.012122
2021-12-17 18:42:28,851 iteration 6719 : loss : 0.048165, loss_ce: 0.015127
2021-12-17 18:42:30,282 iteration 6720 : loss : 0.046530, loss_ce: 0.015778
2021-12-17 18:42:31,771 iteration 6721 : loss : 0.052564, loss_ce: 0.017595
2021-12-17 18:42:33,248 iteration 6722 : loss : 0.059557, loss_ce: 0.014767
2021-12-17 18:42:34,679 iteration 6723 : loss : 0.054796, loss_ce: 0.014782
2021-12-17 18:42:36,082 iteration 6724 : loss : 0.046240, loss_ce: 0.016576
2021-12-17 18:42:37,563 iteration 6725 : loss : 0.059676, loss_ce: 0.024029
2021-12-17 18:42:39,004 iteration 6726 : loss : 0.061393, loss_ce: 0.018286
2021-12-17 18:42:40,487 iteration 6727 : loss : 0.052762, loss_ce: 0.019931
2021-12-17 18:42:41,948 iteration 6728 : loss : 0.059848, loss_ce: 0.023319
2021-12-17 18:42:43,338 iteration 6729 : loss : 0.049941, loss_ce: 0.012972
2021-12-17 18:42:44,756 iteration 6730 : loss : 0.048306, loss_ce: 0.014069
2021-12-17 18:42:46,150 iteration 6731 : loss : 0.075738, loss_ce: 0.030278
2021-12-17 18:42:47,585 iteration 6732 : loss : 0.053673, loss_ce: 0.021877
 99%|████████████████████████████▋| 396/400 [2:58:59<01:48, 27.08s/it]2021-12-17 18:42:49,101 iteration 6733 : loss : 0.054396, loss_ce: 0.019956
2021-12-17 18:42:50,517 iteration 6734 : loss : 0.036477, loss_ce: 0.009371
2021-12-17 18:42:51,965 iteration 6735 : loss : 0.052596, loss_ce: 0.021879
2021-12-17 18:42:53,417 iteration 6736 : loss : 0.051996, loss_ce: 0.015034
2021-12-17 18:42:54,830 iteration 6737 : loss : 0.051098, loss_ce: 0.018972
2021-12-17 18:42:56,283 iteration 6738 : loss : 0.044666, loss_ce: 0.013960
2021-12-17 18:42:57,749 iteration 6739 : loss : 0.056760, loss_ce: 0.020796
2021-12-17 18:42:59,267 iteration 6740 : loss : 0.046020, loss_ce: 0.014049
2021-12-17 18:43:00,636 iteration 6741 : loss : 0.043313, loss_ce: 0.015200
2021-12-17 18:43:02,100 iteration 6742 : loss : 0.054241, loss_ce: 0.020198
2021-12-17 18:43:03,569 iteration 6743 : loss : 0.071968, loss_ce: 0.018900
2021-12-17 18:43:05,082 iteration 6744 : loss : 0.067166, loss_ce: 0.019466
2021-12-17 18:43:06,497 iteration 6745 : loss : 0.058131, loss_ce: 0.015526
2021-12-17 18:43:07,905 iteration 6746 : loss : 0.063634, loss_ce: 0.021913
2021-12-17 18:43:09,339 iteration 6747 : loss : 0.058773, loss_ce: 0.016955
2021-12-17 18:43:10,793 iteration 6748 : loss : 0.063022, loss_ce: 0.021707
2021-12-17 18:43:12,287 iteration 6749 : loss : 0.059031, loss_ce: 0.018929
 99%|████████████████████████████▊| 397/400 [2:59:24<01:19, 26.37s/it]2021-12-17 18:43:13,744 iteration 6750 : loss : 0.048262, loss_ce: 0.015822
2021-12-17 18:43:15,239 iteration 6751 : loss : 0.058595, loss_ce: 0.023081
2021-12-17 18:43:16,710 iteration 6752 : loss : 0.057243, loss_ce: 0.023736
2021-12-17 18:43:18,161 iteration 6753 : loss : 0.059916, loss_ce: 0.024060
2021-12-17 18:43:19,636 iteration 6754 : loss : 0.071231, loss_ce: 0.016336
2021-12-17 18:43:21,063 iteration 6755 : loss : 0.040914, loss_ce: 0.011383
2021-12-17 18:43:22,529 iteration 6756 : loss : 0.056543, loss_ce: 0.021704
2021-12-17 18:43:23,979 iteration 6757 : loss : 0.059496, loss_ce: 0.024709
2021-12-17 18:43:25,375 iteration 6758 : loss : 0.039658, loss_ce: 0.012662
2021-12-17 18:43:26,839 iteration 6759 : loss : 0.055213, loss_ce: 0.017171
2021-12-17 18:43:28,277 iteration 6760 : loss : 0.052511, loss_ce: 0.019261
2021-12-17 18:43:29,751 iteration 6761 : loss : 0.054045, loss_ce: 0.018693
2021-12-17 18:43:31,088 iteration 6762 : loss : 0.043811, loss_ce: 0.014624
2021-12-17 18:43:32,524 iteration 6763 : loss : 0.061782, loss_ce: 0.015184
2021-12-17 18:43:33,950 iteration 6764 : loss : 0.049634, loss_ce: 0.016012
2021-12-17 18:43:35,343 iteration 6765 : loss : 0.052968, loss_ce: 0.014084
2021-12-17 18:43:36,767 iteration 6766 : loss : 0.051795, loss_ce: 0.016788
100%|████████████████████████████▊| 398/400 [2:59:48<00:51, 25.81s/it]2021-12-17 18:43:38,343 iteration 6767 : loss : 0.065113, loss_ce: 0.023835
2021-12-17 18:43:39,714 iteration 6768 : loss : 0.047540, loss_ce: 0.017909
2021-12-17 18:43:41,167 iteration 6769 : loss : 0.064744, loss_ce: 0.017873
2021-12-17 18:43:42,550 iteration 6770 : loss : 0.045691, loss_ce: 0.016077
2021-12-17 18:43:43,989 iteration 6771 : loss : 0.049902, loss_ce: 0.013214
2021-12-17 18:43:45,492 iteration 6772 : loss : 0.060027, loss_ce: 0.016472
2021-12-17 18:43:46,952 iteration 6773 : loss : 0.047689, loss_ce: 0.017021
2021-12-17 18:43:48,379 iteration 6774 : loss : 0.050572, loss_ce: 0.017057
2021-12-17 18:43:49,801 iteration 6775 : loss : 0.055692, loss_ce: 0.016617
2021-12-17 18:43:51,301 iteration 6776 : loss : 0.058090, loss_ce: 0.020870
2021-12-17 18:43:52,751 iteration 6777 : loss : 0.050577, loss_ce: 0.017758
2021-12-17 18:43:54,144 iteration 6778 : loss : 0.043601, loss_ce: 0.011827
2021-12-17 18:43:55,557 iteration 6779 : loss : 0.047467, loss_ce: 0.012698
2021-12-17 18:43:56,919 iteration 6780 : loss : 0.044653, loss_ce: 0.012661
2021-12-17 18:43:58,315 iteration 6781 : loss : 0.047494, loss_ce: 0.017638
2021-12-17 18:43:59,764 iteration 6782 : loss : 0.046135, loss_ce: 0.017353
2021-12-17 18:44:01,212 iteration 6783 : loss : 0.049251, loss_ce: 0.018136
100%|████████████████████████████▉| 399/400 [3:00:13<00:25, 25.40s/it]2021-12-17 18:44:02,803 iteration 6784 : loss : 0.064321, loss_ce: 0.019903
2021-12-17 18:44:04,155 iteration 6785 : loss : 0.052985, loss_ce: 0.020120
2021-12-17 18:44:05,506 iteration 6786 : loss : 0.044518, loss_ce: 0.015128
2021-12-17 18:44:06,973 iteration 6787 : loss : 0.067625, loss_ce: 0.020877
2021-12-17 18:44:08,345 iteration 6788 : loss : 0.071007, loss_ce: 0.017278
2021-12-17 18:44:09,801 iteration 6789 : loss : 0.043983, loss_ce: 0.015582
2021-12-17 18:44:11,288 iteration 6790 : loss : 0.053959, loss_ce: 0.014878
2021-12-17 18:44:12,776 iteration 6791 : loss : 0.072995, loss_ce: 0.019671
2021-12-17 18:44:14,256 iteration 6792 : loss : 0.048632, loss_ce: 0.015280
2021-12-17 18:44:15,685 iteration 6793 : loss : 0.072724, loss_ce: 0.020740
2021-12-17 18:44:17,124 iteration 6794 : loss : 0.048133, loss_ce: 0.015820
2021-12-17 18:44:18,551 iteration 6795 : loss : 0.050662, loss_ce: 0.016605
2021-12-17 18:44:19,987 iteration 6796 : loss : 0.055493, loss_ce: 0.015823
2021-12-17 18:44:21,395 iteration 6797 : loss : 0.048581, loss_ce: 0.014354
2021-12-17 18:44:22,760 iteration 6798 : loss : 0.046899, loss_ce: 0.015469
2021-12-17 18:44:24,210 iteration 6799 : loss : 0.058923, loss_ce: 0.021541
2021-12-17 18:44:24,210 Training Data Eval:
2021-12-17 18:44:31,705   Average segmentation loss on training set: 0.0354
2021-12-17 18:44:31,705 Validation Data Eval:
2021-12-17 18:44:34,305   Average segmentation loss on validation set: 0.1171
2021-12-17 18:44:35,760 iteration 6800 : loss : 0.054002, loss_ce: 0.020105
100%|█████████████████████████████| 400/400 [3:00:47<00:00, 28.14s/it]100%|█████████████████████████████| 400/400 [3:00:47<00:00, 27.12s/it]
