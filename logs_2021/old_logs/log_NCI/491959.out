/scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/TransUNet/utils.py:913: SyntaxWarning: "is" with a literal. Did you mean "=="?
  if mask_type is 'squares_jigsaw':
/scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/TransUNet/utils.py:920: SyntaxWarning: "is" with a literal. Did you mean "=="?
  elif mask_type is 'squares_zeros':
2021-12-03 13:52:40,527 Logging directory: /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/TransUNet/log_dir/trRUNMC_cv1_r3/i2i2l/
2021-12-03 13:52:40,528 Tensorboard directory: /scratch_net/biwidl217_second/arismu/Tensorboard/trRUNMC_cv1_r3/i2i2l/
2021-12-03 13:52:40,528 ============================================================
2021-12-03 13:52:40,528 EXPERIMENT NAME: trRUNMC_cv1_r3/i2i2l/
2021-12-03 13:52:40,528 ============================================================
2021-12-03 13:52:40,528 Loading data...
2021-12-03 13:52:40,528 Reading NCI - RUNMC images...
2021-12-03 13:52:40,528 Data root directory: /itet-stor/arismu/bmicdatasets-originals/Originals/Challenge_Datasets/NCI_Prostate/
2021-12-03 13:52:40,531 Already preprocessed this configuration. Loading now!
2021-12-03 13:52:40,562 Training Images: (256, 256, 286)
2021-12-03 13:52:40,562 Training Labels: (256, 256, 286)
2021-12-03 13:52:40,562 Validation Images: (256, 256, 98)
2021-12-03 13:52:40,562 Validation Labels: (256, 256, 98)
2021-12-03 13:52:40,562 ============================================================
2021-12-03 13:52:40,591 17 iterations per epoch. 2550 max iterations 
  0%|                                         | 0/150 [00:00<?, ?it/s]2021-12-03 13:52:43,392 iteration 1 : loss : 0.829311, loss_ce: 0.946766
2021-12-03 13:52:44,758 iteration 2 : loss : 0.793626, loss_ce: 0.903739
2021-12-03 13:52:46,213 iteration 3 : loss : 0.746766, loss_ce: 0.815686
2021-12-03 13:52:47,575 iteration 4 : loss : 0.710868, loss_ce: 0.752433
2021-12-03 13:52:48,946 iteration 5 : loss : 0.667787, loss_ce: 0.695518
2021-12-03 13:52:50,334 iteration 6 : loss : 0.634917, loss_ce: 0.628493
2021-12-03 13:52:51,772 iteration 7 : loss : 0.583765, loss_ce: 0.573337
2021-12-03 13:52:53,172 iteration 8 : loss : 0.562140, loss_ce: 0.509619
2021-12-03 13:52:54,584 iteration 9 : loss : 0.551236, loss_ce: 0.536030
2021-12-03 13:52:56,030 iteration 10 : loss : 0.534984, loss_ce: 0.470616
2021-12-03 13:52:57,531 iteration 11 : loss : 0.500421, loss_ce: 0.442964
2021-12-03 13:52:58,924 iteration 12 : loss : 0.494031, loss_ce: 0.421193
2021-12-03 13:53:00,295 iteration 13 : loss : 0.503137, loss_ce: 0.411039
2021-12-03 13:53:01,640 iteration 14 : loss : 0.459137, loss_ce: 0.378557
2021-12-03 13:53:03,072 iteration 15 : loss : 0.461441, loss_ce: 0.372328
2021-12-03 13:53:04,472 iteration 16 : loss : 0.489020, loss_ce: 0.389749
2021-12-03 13:53:05,893 iteration 17 : loss : 0.437553, loss_ce: 0.356841
  1%|▏                              | 1/150 [00:25<1:03:03, 25.39s/it]2021-12-03 13:53:07,418 iteration 18 : loss : 0.463964, loss_ce: 0.340148
2021-12-03 13:53:08,764 iteration 19 : loss : 0.460745, loss_ce: 0.351442
2021-12-03 13:53:10,237 iteration 20 : loss : 0.410328, loss_ce: 0.310385
2021-12-03 13:53:11,625 iteration 21 : loss : 0.445891, loss_ce: 0.313058
2021-12-03 13:53:13,163 iteration 22 : loss : 0.400831, loss_ce: 0.302392
2021-12-03 13:53:14,839 iteration 23 : loss : 0.407074, loss_ce: 0.276415
2021-12-03 13:53:16,394 iteration 24 : loss : 0.378965, loss_ce: 0.268308
2021-12-03 13:53:18,026 iteration 25 : loss : 0.428403, loss_ce: 0.323800
2021-12-03 13:53:19,575 iteration 26 : loss : 0.369782, loss_ce: 0.254991
2021-12-03 13:53:21,039 iteration 27 : loss : 0.352132, loss_ce: 0.250497
2021-12-03 13:53:22,533 iteration 28 : loss : 0.351043, loss_ce: 0.240979
2021-12-03 13:53:24,130 iteration 29 : loss : 0.341854, loss_ce: 0.231249
2021-12-03 13:53:25,716 iteration 30 : loss : 0.338480, loss_ce: 0.233358
2021-12-03 13:53:27,209 iteration 31 : loss : 0.322572, loss_ce: 0.225484
2021-12-03 13:53:28,850 iteration 32 : loss : 0.330593, loss_ce: 0.241536
2021-12-03 13:53:30,469 iteration 33 : loss : 0.324433, loss_ce: 0.236276
2021-12-03 13:53:32,062 iteration 34 : loss : 0.330364, loss_ce: 0.242373
  1%|▍                              | 2/150 [00:51<1:03:43, 25.84s/it]2021-12-03 13:53:33,723 iteration 35 : loss : 0.318592, loss_ce: 0.207654
2021-12-03 13:53:35,335 iteration 36 : loss : 0.330147, loss_ce: 0.219399
2021-12-03 13:53:36,989 iteration 37 : loss : 0.342165, loss_ce: 0.212228
2021-12-03 13:53:38,533 iteration 38 : loss : 0.287607, loss_ce: 0.189624
2021-12-03 13:53:40,088 iteration 39 : loss : 0.251500, loss_ce: 0.173491
2021-12-03 13:53:41,737 iteration 40 : loss : 0.292082, loss_ce: 0.191005
2021-12-03 13:53:43,373 iteration 41 : loss : 0.371817, loss_ce: 0.231629
2021-12-03 13:53:44,979 iteration 42 : loss : 0.308376, loss_ce: 0.190659
2021-12-03 13:53:46,470 iteration 43 : loss : 0.283272, loss_ce: 0.171995
2021-12-03 13:53:48,103 iteration 44 : loss : 0.271622, loss_ce: 0.169275
2021-12-03 13:53:49,636 iteration 45 : loss : 0.245886, loss_ce: 0.159679
2021-12-03 13:53:51,186 iteration 46 : loss : 0.290207, loss_ce: 0.163836
2021-12-03 13:53:52,762 iteration 47 : loss : 0.256999, loss_ce: 0.150449
2021-12-03 13:53:54,326 iteration 48 : loss : 0.248907, loss_ce: 0.152203
2021-12-03 13:53:55,971 iteration 49 : loss : 0.327728, loss_ce: 0.194064
2021-12-03 13:53:57,468 iteration 50 : loss : 0.345439, loss_ce: 0.195861
2021-12-03 13:53:58,946 iteration 51 : loss : 0.290238, loss_ce: 0.174899
  2%|▌                              | 3/150 [01:18<1:04:27, 26.31s/it]2021-12-03 13:54:00,594 iteration 52 : loss : 0.294399, loss_ce: 0.180591
2021-12-03 13:54:02,161 iteration 53 : loss : 0.292185, loss_ce: 0.166506
2021-12-03 13:54:03,701 iteration 54 : loss : 0.255162, loss_ce: 0.139388
2021-12-03 13:54:05,255 iteration 55 : loss : 0.310442, loss_ce: 0.184220
2021-12-03 13:54:06,785 iteration 56 : loss : 0.301985, loss_ce: 0.160815
2021-12-03 13:54:08,337 iteration 57 : loss : 0.237157, loss_ce: 0.127200
2021-12-03 13:54:09,894 iteration 58 : loss : 0.330814, loss_ce: 0.172334
2021-12-03 13:54:11,416 iteration 59 : loss : 0.238360, loss_ce: 0.142718
2021-12-03 13:54:12,977 iteration 60 : loss : 0.330870, loss_ce: 0.173830
2021-12-03 13:54:14,518 iteration 61 : loss : 0.271539, loss_ce: 0.156001
2021-12-03 13:54:16,051 iteration 62 : loss : 0.364006, loss_ce: 0.166171
2021-12-03 13:54:17,518 iteration 63 : loss : 0.316230, loss_ce: 0.181745
2021-12-03 13:54:19,039 iteration 64 : loss : 0.346078, loss_ce: 0.177254
2021-12-03 13:54:20,505 iteration 65 : loss : 0.287414, loss_ce: 0.143871
2021-12-03 13:54:22,018 iteration 66 : loss : 0.253337, loss_ce: 0.134987
2021-12-03 13:54:23,611 iteration 67 : loss : 0.266125, loss_ce: 0.120076
2021-12-03 13:54:25,140 iteration 68 : loss : 0.254554, loss_ce: 0.134916
  3%|▊                              | 4/150 [01:44<1:03:54, 26.26s/it]2021-12-03 13:54:26,756 iteration 69 : loss : 0.229395, loss_ce: 0.123492
2021-12-03 13:54:28,372 iteration 70 : loss : 0.237032, loss_ce: 0.126966
2021-12-03 13:54:29,868 iteration 71 : loss : 0.260239, loss_ce: 0.131172
2021-12-03 13:54:31,416 iteration 72 : loss : 0.225153, loss_ce: 0.120723
2021-12-03 13:54:32,906 iteration 73 : loss : 0.244868, loss_ce: 0.141226
2021-12-03 13:54:34,361 iteration 74 : loss : 0.242746, loss_ce: 0.127734
2021-12-03 13:54:35,855 iteration 75 : loss : 0.225251, loss_ce: 0.118713
2021-12-03 13:54:37,327 iteration 76 : loss : 0.265664, loss_ce: 0.142548
2021-12-03 13:54:38,726 iteration 77 : loss : 0.209105, loss_ce: 0.118564
2021-12-03 13:54:40,230 iteration 78 : loss : 0.263675, loss_ce: 0.140250
2021-12-03 13:54:41,704 iteration 79 : loss : 0.269219, loss_ce: 0.124673
2021-12-03 13:54:43,164 iteration 80 : loss : 0.265560, loss_ce: 0.143784
2021-12-03 13:54:44,618 iteration 81 : loss : 0.244297, loss_ce: 0.131156
2021-12-03 13:54:46,096 iteration 82 : loss : 0.256076, loss_ce: 0.118402
2021-12-03 13:54:47,567 iteration 83 : loss : 0.263037, loss_ce: 0.109482
2021-12-03 13:54:49,129 iteration 84 : loss : 0.237471, loss_ce: 0.139831
2021-12-03 13:54:49,130 Training Data Eval:
2021-12-03 13:54:56,668   Average segmentation loss on training set: 1.2451
2021-12-03 13:54:56,669 Validation Data Eval:
2021-12-03 13:54:59,419   Average segmentation loss on validation set: 1.2905
2021-12-03 13:55:00,908 iteration 85 : loss : 0.279832, loss_ce: 0.137130
  3%|█                              | 5/150 [02:20<1:11:44, 29.69s/it]2021-12-03 13:55:02,482 iteration 86 : loss : 0.330603, loss_ce: 0.148464
2021-12-03 13:55:04,121 iteration 87 : loss : 0.206571, loss_ce: 0.111215
2021-12-03 13:55:05,588 iteration 88 : loss : 0.238612, loss_ce: 0.122398
2021-12-03 13:55:07,121 iteration 89 : loss : 0.281789, loss_ce: 0.142654
2021-12-03 13:55:08,651 iteration 90 : loss : 0.242942, loss_ce: 0.116664
2021-12-03 13:55:10,246 iteration 91 : loss : 0.236680, loss_ce: 0.134964
2021-12-03 13:55:11,697 iteration 92 : loss : 0.208492, loss_ce: 0.105697
2021-12-03 13:55:13,200 iteration 93 : loss : 0.263212, loss_ce: 0.113070
2021-12-03 13:55:14,704 iteration 94 : loss : 0.229171, loss_ce: 0.106011
2021-12-03 13:55:16,344 iteration 95 : loss : 0.237477, loss_ce: 0.121831
2021-12-03 13:55:17,833 iteration 96 : loss : 0.225981, loss_ce: 0.113706
2021-12-03 13:55:19,331 iteration 97 : loss : 0.290163, loss_ce: 0.136160
2021-12-03 13:55:20,834 iteration 98 : loss : 0.257430, loss_ce: 0.123415
2021-12-03 13:55:22,434 iteration 99 : loss : 0.215645, loss_ce: 0.104851
2021-12-03 13:55:23,966 iteration 100 : loss : 0.230490, loss_ce: 0.109626
2021-12-03 13:55:25,489 iteration 101 : loss : 0.146991, loss_ce: 0.072143
2021-12-03 13:55:26,941 iteration 102 : loss : 0.232483, loss_ce: 0.108404
  4%|█▏                             | 6/150 [02:46<1:08:16, 28.45s/it]2021-12-03 13:55:28,615 iteration 103 : loss : 0.188913, loss_ce: 0.094202
2021-12-03 13:55:30,207 iteration 104 : loss : 0.241222, loss_ce: 0.118785
2021-12-03 13:55:31,843 iteration 105 : loss : 0.252625, loss_ce: 0.115716
2021-12-03 13:55:33,319 iteration 106 : loss : 0.243885, loss_ce: 0.116825
2021-12-03 13:55:34,979 iteration 107 : loss : 0.193067, loss_ce: 0.101392
2021-12-03 13:55:36,437 iteration 108 : loss : 0.250512, loss_ce: 0.119120
2021-12-03 13:55:37,925 iteration 109 : loss : 0.192988, loss_ce: 0.101814
2021-12-03 13:55:39,363 iteration 110 : loss : 0.182809, loss_ce: 0.092877
2021-12-03 13:55:40,917 iteration 111 : loss : 0.213538, loss_ce: 0.117334
2021-12-03 13:55:42,364 iteration 112 : loss : 0.175324, loss_ce: 0.080411
2021-12-03 13:55:43,895 iteration 113 : loss : 0.236985, loss_ce: 0.137732
2021-12-03 13:55:45,376 iteration 114 : loss : 0.231329, loss_ce: 0.091767
2021-12-03 13:55:46,875 iteration 115 : loss : 0.186836, loss_ce: 0.092355
2021-12-03 13:55:48,428 iteration 116 : loss : 0.227953, loss_ce: 0.109822
2021-12-03 13:55:49,982 iteration 117 : loss : 0.200308, loss_ce: 0.105074
2021-12-03 13:55:51,498 iteration 118 : loss : 0.230915, loss_ce: 0.110126
2021-12-03 13:55:53,027 iteration 119 : loss : 0.215430, loss_ce: 0.093155
  5%|█▍                             | 7/150 [03:12<1:05:57, 27.68s/it]2021-12-03 13:55:54,563 iteration 120 : loss : 0.307005, loss_ce: 0.162172
2021-12-03 13:55:56,043 iteration 121 : loss : 0.171428, loss_ce: 0.083099
2021-12-03 13:55:57,671 iteration 122 : loss : 0.233010, loss_ce: 0.102484
2021-12-03 13:55:59,228 iteration 123 : loss : 0.209528, loss_ce: 0.099386
2021-12-03 13:56:00,783 iteration 124 : loss : 0.206259, loss_ce: 0.088518
2021-12-03 13:56:02,287 iteration 125 : loss : 0.214201, loss_ce: 0.114168
2021-12-03 13:56:03,870 iteration 126 : loss : 0.216175, loss_ce: 0.090991
2021-12-03 13:56:05,371 iteration 127 : loss : 0.195093, loss_ce: 0.101236
2021-12-03 13:56:06,881 iteration 128 : loss : 0.193872, loss_ce: 0.093133
2021-12-03 13:56:08,479 iteration 129 : loss : 0.195913, loss_ce: 0.086956
2021-12-03 13:56:10,025 iteration 130 : loss : 0.176281, loss_ce: 0.081025
2021-12-03 13:56:11,686 iteration 131 : loss : 0.244957, loss_ce: 0.124303
2021-12-03 13:56:13,386 iteration 132 : loss : 0.177461, loss_ce: 0.065301
2021-12-03 13:56:14,908 iteration 133 : loss : 0.186103, loss_ce: 0.082451
2021-12-03 13:56:16,560 iteration 134 : loss : 0.194535, loss_ce: 0.087410
2021-12-03 13:56:18,202 iteration 135 : loss : 0.204903, loss_ce: 0.098675
2021-12-03 13:56:19,758 iteration 136 : loss : 0.157906, loss_ce: 0.080530
  5%|█▋                             | 8/150 [03:39<1:04:47, 27.37s/it]2021-12-03 13:56:21,448 iteration 137 : loss : 0.235973, loss_ce: 0.090103
2021-12-03 13:56:22,976 iteration 138 : loss : 0.193122, loss_ce: 0.104770
2021-12-03 13:56:24,579 iteration 139 : loss : 0.234270, loss_ce: 0.109540
2021-12-03 13:56:26,145 iteration 140 : loss : 0.194790, loss_ce: 0.084760
2021-12-03 13:56:27,770 iteration 141 : loss : 0.214449, loss_ce: 0.105441
2021-12-03 13:56:29,411 iteration 142 : loss : 0.219880, loss_ce: 0.098753
2021-12-03 13:56:31,016 iteration 143 : loss : 0.214677, loss_ce: 0.102407
2021-12-03 13:56:32,591 iteration 144 : loss : 0.194711, loss_ce: 0.089720
2021-12-03 13:56:34,111 iteration 145 : loss : 0.209259, loss_ce: 0.094170
2021-12-03 13:56:35,670 iteration 146 : loss : 0.168252, loss_ce: 0.087690
2021-12-03 13:56:37,242 iteration 147 : loss : 0.185424, loss_ce: 0.088557
2021-12-03 13:56:38,676 iteration 148 : loss : 0.196541, loss_ce: 0.092758
2021-12-03 13:56:40,189 iteration 149 : loss : 0.283801, loss_ce: 0.129482
2021-12-03 13:56:41,677 iteration 150 : loss : 0.215456, loss_ce: 0.082275
2021-12-03 13:56:43,180 iteration 151 : loss : 0.230884, loss_ce: 0.101571
2021-12-03 13:56:44,682 iteration 152 : loss : 0.223941, loss_ce: 0.082754
2021-12-03 13:56:46,256 iteration 153 : loss : 0.251607, loss_ce: 0.112918
  6%|█▊                             | 9/150 [04:05<1:03:41, 27.10s/it]2021-12-03 13:56:47,780 iteration 154 : loss : 0.217765, loss_ce: 0.095299
2021-12-03 13:56:49,333 iteration 155 : loss : 0.181085, loss_ce: 0.078131
2021-12-03 13:56:50,945 iteration 156 : loss : 0.164213, loss_ce: 0.073613
2021-12-03 13:56:52,526 iteration 157 : loss : 0.206497, loss_ce: 0.086083
2021-12-03 13:56:54,189 iteration 158 : loss : 0.196488, loss_ce: 0.090072
2021-12-03 13:56:55,604 iteration 159 : loss : 0.184046, loss_ce: 0.085999
2021-12-03 13:56:57,217 iteration 160 : loss : 0.160842, loss_ce: 0.064013
2021-12-03 13:56:58,827 iteration 161 : loss : 0.229947, loss_ce: 0.104904
2021-12-03 13:57:00,431 iteration 162 : loss : 0.216895, loss_ce: 0.102737
2021-12-03 13:57:01,964 iteration 163 : loss : 0.222667, loss_ce: 0.104423
2021-12-03 13:57:03,516 iteration 164 : loss : 0.187698, loss_ce: 0.074177
2021-12-03 13:57:05,047 iteration 165 : loss : 0.201147, loss_ce: 0.091119
2021-12-03 13:57:06,546 iteration 166 : loss : 0.214801, loss_ce: 0.090485
2021-12-03 13:57:08,092 iteration 167 : loss : 0.166832, loss_ce: 0.073657
2021-12-03 13:57:09,658 iteration 168 : loss : 0.206628, loss_ce: 0.106769
2021-12-03 13:57:11,205 iteration 169 : loss : 0.180599, loss_ce: 0.100226
2021-12-03 13:57:11,205 Training Data Eval:
2021-12-03 13:57:18,776   Average segmentation loss on training set: 0.1944
2021-12-03 13:57:18,776 Validation Data Eval:
2021-12-03 13:57:21,384   Average segmentation loss on validation set: 0.2760
2021-12-03 13:57:23,348 Found new lowest validation loss at iteration 169! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/UNET_RUNMC/1channel_best_val_loss.pth
2021-12-03 13:57:24,950 iteration 170 : loss : 0.176023, loss_ce: 0.075754
  7%|██                            | 10/150 [04:44<1:11:34, 30.68s/it]2021-12-03 13:57:26,553 iteration 171 : loss : 0.190870, loss_ce: 0.082982
2021-12-03 13:57:28,121 iteration 172 : loss : 0.200565, loss_ce: 0.096821
2021-12-03 13:57:29,688 iteration 173 : loss : 0.148038, loss_ce: 0.074341
2021-12-03 13:57:31,163 iteration 174 : loss : 0.205073, loss_ce: 0.096770
2021-12-03 13:57:32,631 iteration 175 : loss : 0.273378, loss_ce: 0.133550
2021-12-03 13:57:34,164 iteration 176 : loss : 0.169429, loss_ce: 0.089106
2021-12-03 13:57:35,673 iteration 177 : loss : 0.180759, loss_ce: 0.084500
2021-12-03 13:57:37,185 iteration 178 : loss : 0.167075, loss_ce: 0.082070
2021-12-03 13:57:38,691 iteration 179 : loss : 0.213796, loss_ce: 0.093678
2021-12-03 13:57:40,180 iteration 180 : loss : 0.153640, loss_ce: 0.063648
2021-12-03 13:57:41,721 iteration 181 : loss : 0.180862, loss_ce: 0.077939
2021-12-03 13:57:43,203 iteration 182 : loss : 0.145768, loss_ce: 0.063179
2021-12-03 13:57:44,666 iteration 183 : loss : 0.143125, loss_ce: 0.057613
2021-12-03 13:57:46,090 iteration 184 : loss : 0.180891, loss_ce: 0.069260
2021-12-03 13:57:47,633 iteration 185 : loss : 0.185331, loss_ce: 0.073910
2021-12-03 13:57:49,180 iteration 186 : loss : 0.172272, loss_ce: 0.075525
2021-12-03 13:57:50,759 iteration 187 : loss : 0.160080, loss_ce: 0.064845
  7%|██▏                           | 11/150 [05:10<1:07:36, 29.19s/it]2021-12-03 13:57:52,361 iteration 188 : loss : 0.221238, loss_ce: 0.090423
2021-12-03 13:57:53,899 iteration 189 : loss : 0.163350, loss_ce: 0.073768
2021-12-03 13:57:55,439 iteration 190 : loss : 0.163138, loss_ce: 0.069424
2021-12-03 13:57:56,936 iteration 191 : loss : 0.146662, loss_ce: 0.060209
2021-12-03 13:57:58,393 iteration 192 : loss : 0.174429, loss_ce: 0.081414
2021-12-03 13:57:59,962 iteration 193 : loss : 0.163743, loss_ce: 0.072879
2021-12-03 13:58:01,484 iteration 194 : loss : 0.221541, loss_ce: 0.075492
2021-12-03 13:58:02,963 iteration 195 : loss : 0.170874, loss_ce: 0.080741
2021-12-03 13:58:04,396 iteration 196 : loss : 0.154557, loss_ce: 0.061652
2021-12-03 13:58:05,915 iteration 197 : loss : 0.167514, loss_ce: 0.071568
2021-12-03 13:58:07,460 iteration 198 : loss : 0.148443, loss_ce: 0.072068
2021-12-03 13:58:08,934 iteration 199 : loss : 0.174776, loss_ce: 0.069781
2021-12-03 13:58:10,428 iteration 200 : loss : 0.194952, loss_ce: 0.086315
2021-12-03 13:58:11,963 iteration 201 : loss : 0.117741, loss_ce: 0.049833
2021-12-03 13:58:13,522 iteration 202 : loss : 0.174817, loss_ce: 0.078588
2021-12-03 13:58:14,994 iteration 203 : loss : 0.137195, loss_ce: 0.059297
2021-12-03 13:58:16,600 iteration 204 : loss : 0.215424, loss_ce: 0.093075
  8%|██▍                           | 12/150 [05:36<1:04:47, 28.17s/it]2021-12-03 13:58:18,135 iteration 205 : loss : 0.136841, loss_ce: 0.059338
2021-12-03 13:58:19,647 iteration 206 : loss : 0.160456, loss_ce: 0.065220
2021-12-03 13:58:21,179 iteration 207 : loss : 0.151842, loss_ce: 0.062747
2021-12-03 13:58:22,672 iteration 208 : loss : 0.196982, loss_ce: 0.068146
2021-12-03 13:58:24,254 iteration 209 : loss : 0.190686, loss_ce: 0.091394
2021-12-03 13:58:25,680 iteration 210 : loss : 0.142997, loss_ce: 0.058718
2021-12-03 13:58:27,264 iteration 211 : loss : 0.175524, loss_ce: 0.085386
2021-12-03 13:58:28,792 iteration 212 : loss : 0.217255, loss_ce: 0.079225
2021-12-03 13:58:30,420 iteration 213 : loss : 0.126471, loss_ce: 0.063876
2021-12-03 13:58:31,938 iteration 214 : loss : 0.175001, loss_ce: 0.060421
2021-12-03 13:58:33,459 iteration 215 : loss : 0.193777, loss_ce: 0.086022
2021-12-03 13:58:35,135 iteration 216 : loss : 0.145442, loss_ce: 0.063933
2021-12-03 13:58:36,745 iteration 217 : loss : 0.156674, loss_ce: 0.061053
2021-12-03 13:58:38,280 iteration 218 : loss : 0.191789, loss_ce: 0.097411
2021-12-03 13:58:39,706 iteration 219 : loss : 0.124480, loss_ce: 0.061826
2021-12-03 13:58:41,246 iteration 220 : loss : 0.115483, loss_ce: 0.053043
2021-12-03 13:58:42,770 iteration 221 : loss : 0.188615, loss_ce: 0.075791
  9%|██▌                           | 13/150 [06:02<1:02:56, 27.56s/it]2021-12-03 13:58:44,371 iteration 222 : loss : 0.166217, loss_ce: 0.088186
2021-12-03 13:58:45,935 iteration 223 : loss : 0.126036, loss_ce: 0.056836
2021-12-03 13:58:47,456 iteration 224 : loss : 0.171970, loss_ce: 0.092988
2021-12-03 13:58:49,085 iteration 225 : loss : 0.283191, loss_ce: 0.087076
2021-12-03 13:58:50,599 iteration 226 : loss : 0.179343, loss_ce: 0.068317
2021-12-03 13:58:52,179 iteration 227 : loss : 0.199908, loss_ce: 0.086505
2021-12-03 13:58:53,699 iteration 228 : loss : 0.150811, loss_ce: 0.066586
2021-12-03 13:58:55,187 iteration 229 : loss : 0.151491, loss_ce: 0.055189
2021-12-03 13:58:56,712 iteration 230 : loss : 0.177366, loss_ce: 0.068599
2021-12-03 13:58:58,291 iteration 231 : loss : 0.211130, loss_ce: 0.083026
2021-12-03 13:58:59,846 iteration 232 : loss : 0.149083, loss_ce: 0.057858
2021-12-03 13:59:01,322 iteration 233 : loss : 0.199109, loss_ce: 0.090221
2021-12-03 13:59:02,904 iteration 234 : loss : 0.172746, loss_ce: 0.076031
2021-12-03 13:59:04,407 iteration 235 : loss : 0.166851, loss_ce: 0.075021
2021-12-03 13:59:05,950 iteration 236 : loss : 0.116709, loss_ce: 0.048376
2021-12-03 13:59:07,452 iteration 237 : loss : 0.112245, loss_ce: 0.051754
2021-12-03 13:59:08,964 iteration 238 : loss : 0.133463, loss_ce: 0.062543
  9%|██▊                           | 14/150 [06:28<1:01:32, 27.15s/it]2021-12-03 13:59:10,490 iteration 239 : loss : 0.184634, loss_ce: 0.069998
2021-12-03 13:59:12,035 iteration 240 : loss : 0.136136, loss_ce: 0.063092
2021-12-03 13:59:13,589 iteration 241 : loss : 0.192810, loss_ce: 0.076316
2021-12-03 13:59:15,128 iteration 242 : loss : 0.166937, loss_ce: 0.090910
2021-12-03 13:59:16,797 iteration 243 : loss : 0.156934, loss_ce: 0.067634
2021-12-03 13:59:18,274 iteration 244 : loss : 0.220117, loss_ce: 0.068401
2021-12-03 13:59:19,819 iteration 245 : loss : 0.157635, loss_ce: 0.078326
2021-12-03 13:59:21,391 iteration 246 : loss : 0.154620, loss_ce: 0.067513
2021-12-03 13:59:22,903 iteration 247 : loss : 0.190479, loss_ce: 0.070718
2021-12-03 13:59:24,418 iteration 248 : loss : 0.144272, loss_ce: 0.048590
2021-12-03 13:59:25,909 iteration 249 : loss : 0.198396, loss_ce: 0.097468
2021-12-03 13:59:27,422 iteration 250 : loss : 0.155133, loss_ce: 0.060464
2021-12-03 13:59:28,877 iteration 251 : loss : 0.174827, loss_ce: 0.062499
2021-12-03 13:59:30,388 iteration 252 : loss : 0.099212, loss_ce: 0.046033
2021-12-03 13:59:31,926 iteration 253 : loss : 0.165898, loss_ce: 0.070363
2021-12-03 13:59:33,528 iteration 254 : loss : 0.258216, loss_ce: 0.088403
2021-12-03 13:59:33,528 Training Data Eval:
2021-12-03 13:59:41,056   Average segmentation loss on training set: 0.1916
2021-12-03 13:59:41,057 Validation Data Eval:
2021-12-03 13:59:43,653   Average segmentation loss on validation set: 0.2866
2021-12-03 13:59:45,135 iteration 255 : loss : 0.146625, loss_ce: 0.070103
 10%|███                           | 15/150 [07:04<1:07:12, 29.87s/it]2021-12-03 13:59:46,744 iteration 256 : loss : 0.154739, loss_ce: 0.063844
2021-12-03 13:59:48,315 iteration 257 : loss : 0.148450, loss_ce: 0.060939
2021-12-03 13:59:49,934 iteration 258 : loss : 0.167597, loss_ce: 0.069352
2021-12-03 13:59:51,384 iteration 259 : loss : 0.130377, loss_ce: 0.057551
2021-12-03 13:59:52,964 iteration 260 : loss : 0.141864, loss_ce: 0.063986
2021-12-03 13:59:54,505 iteration 261 : loss : 0.223654, loss_ce: 0.081777
2021-12-03 13:59:56,129 iteration 262 : loss : 0.122499, loss_ce: 0.054625
2021-12-03 13:59:57,658 iteration 263 : loss : 0.142960, loss_ce: 0.068625
2021-12-03 13:59:59,219 iteration 264 : loss : 0.150167, loss_ce: 0.071054
2021-12-03 14:00:00,718 iteration 265 : loss : 0.119095, loss_ce: 0.051866
2021-12-03 14:00:02,278 iteration 266 : loss : 0.117928, loss_ce: 0.059922
2021-12-03 14:00:03,798 iteration 267 : loss : 0.134088, loss_ce: 0.047025
2021-12-03 14:00:05,385 iteration 268 : loss : 0.166572, loss_ce: 0.078524
2021-12-03 14:00:07,111 iteration 269 : loss : 0.128665, loss_ce: 0.049435
2021-12-03 14:00:08,743 iteration 270 : loss : 0.123262, loss_ce: 0.055695
2021-12-03 14:00:10,150 iteration 271 : loss : 0.148532, loss_ce: 0.047274
2021-12-03 14:00:11,693 iteration 272 : loss : 0.132110, loss_ce: 0.065400
 11%|███▏                          | 16/150 [07:31<1:04:29, 28.87s/it]2021-12-03 14:00:13,227 iteration 273 : loss : 0.116689, loss_ce: 0.048097
2021-12-03 14:00:14,709 iteration 274 : loss : 0.090347, loss_ce: 0.037535
2021-12-03 14:00:16,181 iteration 275 : loss : 0.106201, loss_ce: 0.044900
2021-12-03 14:00:17,713 iteration 276 : loss : 0.118381, loss_ce: 0.054831
2021-12-03 14:00:19,262 iteration 277 : loss : 0.104427, loss_ce: 0.038874
2021-12-03 14:00:20,656 iteration 278 : loss : 0.135755, loss_ce: 0.047989
2021-12-03 14:00:22,114 iteration 279 : loss : 0.146921, loss_ce: 0.052746
2021-12-03 14:00:23,574 iteration 280 : loss : 0.137735, loss_ce: 0.056652
2021-12-03 14:00:25,095 iteration 281 : loss : 0.128823, loss_ce: 0.053549
2021-12-03 14:00:26,588 iteration 282 : loss : 0.162373, loss_ce: 0.068192
2021-12-03 14:00:28,061 iteration 283 : loss : 0.158564, loss_ce: 0.084963
2021-12-03 14:00:29,632 iteration 284 : loss : 0.171553, loss_ce: 0.075457
2021-12-03 14:00:31,090 iteration 285 : loss : 0.140811, loss_ce: 0.049434
2021-12-03 14:00:32,571 iteration 286 : loss : 0.101258, loss_ce: 0.046810
2021-12-03 14:00:34,167 iteration 287 : loss : 0.140500, loss_ce: 0.059433
2021-12-03 14:00:35,742 iteration 288 : loss : 0.188902, loss_ce: 0.075880
2021-12-03 14:00:37,236 iteration 289 : loss : 0.134106, loss_ce: 0.054272
 11%|███▍                          | 17/150 [07:56<1:01:46, 27.87s/it]2021-12-03 14:00:38,823 iteration 290 : loss : 0.131892, loss_ce: 0.054028
2021-12-03 14:00:40,310 iteration 291 : loss : 0.117159, loss_ce: 0.049938
2021-12-03 14:00:41,797 iteration 292 : loss : 0.095802, loss_ce: 0.044398
2021-12-03 14:00:43,309 iteration 293 : loss : 0.126055, loss_ce: 0.054295
2021-12-03 14:00:44,831 iteration 294 : loss : 0.124076, loss_ce: 0.050622
2021-12-03 14:00:46,466 iteration 295 : loss : 0.123048, loss_ce: 0.046935
2021-12-03 14:00:47,956 iteration 296 : loss : 0.105195, loss_ce: 0.038575
2021-12-03 14:00:49,476 iteration 297 : loss : 0.118329, loss_ce: 0.042880
2021-12-03 14:00:50,957 iteration 298 : loss : 0.110720, loss_ce: 0.041187
2021-12-03 14:00:52,474 iteration 299 : loss : 0.138533, loss_ce: 0.053725
2021-12-03 14:00:53,987 iteration 300 : loss : 0.137859, loss_ce: 0.050764
2021-12-03 14:00:55,513 iteration 301 : loss : 0.192096, loss_ce: 0.096629
2021-12-03 14:00:57,093 iteration 302 : loss : 0.116822, loss_ce: 0.053884
2021-12-03 14:00:58,662 iteration 303 : loss : 0.153615, loss_ce: 0.063620
2021-12-03 14:01:00,200 iteration 304 : loss : 0.137688, loss_ce: 0.059278
2021-12-03 14:01:01,773 iteration 305 : loss : 0.145730, loss_ce: 0.071089
2021-12-03 14:01:03,379 iteration 306 : loss : 0.129575, loss_ce: 0.064465
 12%|███▌                          | 18/150 [08:22<1:00:10, 27.35s/it]2021-12-03 14:01:04,977 iteration 307 : loss : 0.155156, loss_ce: 0.058113
2021-12-03 14:01:06,462 iteration 308 : loss : 0.105072, loss_ce: 0.049179
2021-12-03 14:01:08,003 iteration 309 : loss : 0.214334, loss_ce: 0.098518
2021-12-03 14:01:09,567 iteration 310 : loss : 0.157996, loss_ce: 0.076394
2021-12-03 14:01:11,046 iteration 311 : loss : 0.173189, loss_ce: 0.056991
2021-12-03 14:01:12,560 iteration 312 : loss : 0.160485, loss_ce: 0.082620
2021-12-03 14:01:14,081 iteration 313 : loss : 0.176594, loss_ce: 0.094842
2021-12-03 14:01:15,532 iteration 314 : loss : 0.113838, loss_ce: 0.050512
2021-12-03 14:01:17,039 iteration 315 : loss : 0.128423, loss_ce: 0.047456
2021-12-03 14:01:18,576 iteration 316 : loss : 0.140304, loss_ce: 0.061471
2021-12-03 14:01:20,095 iteration 317 : loss : 0.162733, loss_ce: 0.063087
2021-12-03 14:01:21,651 iteration 318 : loss : 0.136486, loss_ce: 0.062582
2021-12-03 14:01:23,113 iteration 319 : loss : 0.117115, loss_ce: 0.050855
2021-12-03 14:01:24,726 iteration 320 : loss : 0.121124, loss_ce: 0.046916
2021-12-03 14:01:26,282 iteration 321 : loss : 0.166868, loss_ce: 0.058204
2021-12-03 14:01:27,807 iteration 322 : loss : 0.197616, loss_ce: 0.089943
2021-12-03 14:01:29,383 iteration 323 : loss : 0.156980, loss_ce: 0.060835
 13%|████                            | 19/150 [08:48<58:50, 26.95s/it]2021-12-03 14:01:30,960 iteration 324 : loss : 0.132036, loss_ce: 0.058616
2021-12-03 14:01:32,485 iteration 325 : loss : 0.129484, loss_ce: 0.049402
2021-12-03 14:01:34,040 iteration 326 : loss : 0.106979, loss_ce: 0.048690
2021-12-03 14:01:35,667 iteration 327 : loss : 0.149898, loss_ce: 0.062769
2021-12-03 14:01:37,176 iteration 328 : loss : 0.125583, loss_ce: 0.052392
2021-12-03 14:01:38,731 iteration 329 : loss : 0.142889, loss_ce: 0.070799
2021-12-03 14:01:40,300 iteration 330 : loss : 0.119179, loss_ce: 0.044050
2021-12-03 14:01:41,774 iteration 331 : loss : 0.111662, loss_ce: 0.050744
2021-12-03 14:01:43,278 iteration 332 : loss : 0.096907, loss_ce: 0.037598
2021-12-03 14:01:44,823 iteration 333 : loss : 0.101379, loss_ce: 0.045639
2021-12-03 14:01:46,349 iteration 334 : loss : 0.126208, loss_ce: 0.053644
2021-12-03 14:01:47,847 iteration 335 : loss : 0.192635, loss_ce: 0.065858
2021-12-03 14:01:49,417 iteration 336 : loss : 0.118429, loss_ce: 0.048504
2021-12-03 14:01:50,936 iteration 337 : loss : 0.123669, loss_ce: 0.043419
2021-12-03 14:01:52,416 iteration 338 : loss : 0.133073, loss_ce: 0.063868
2021-12-03 14:01:53,899 iteration 339 : loss : 0.136887, loss_ce: 0.050777
2021-12-03 14:01:53,899 Training Data Eval:
2021-12-03 14:02:01,444   Average segmentation loss on training set: 0.0982
2021-12-03 14:02:01,445 Validation Data Eval:
2021-12-03 14:02:04,052   Average segmentation loss on validation set: 0.1661
2021-12-03 14:02:05,980 Found new lowest validation loss at iteration 339! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/UNET_RUNMC/1channel_best_val_loss.pth
2021-12-03 14:02:07,584 iteration 340 : loss : 0.175415, loss_ce: 0.078376
 13%|████                          | 20/150 [09:27<1:05:42, 30.32s/it]2021-12-03 14:02:09,214 iteration 341 : loss : 0.094449, loss_ce: 0.040877
2021-12-03 14:02:10,763 iteration 342 : loss : 0.133562, loss_ce: 0.046198
2021-12-03 14:02:12,282 iteration 343 : loss : 0.130317, loss_ce: 0.054937
2021-12-03 14:02:13,846 iteration 344 : loss : 0.127917, loss_ce: 0.048462
2021-12-03 14:02:15,362 iteration 345 : loss : 0.102180, loss_ce: 0.038279
2021-12-03 14:02:16,943 iteration 346 : loss : 0.157400, loss_ce: 0.067117
2021-12-03 14:02:18,415 iteration 347 : loss : 0.144905, loss_ce: 0.075307
2021-12-03 14:02:19,959 iteration 348 : loss : 0.131323, loss_ce: 0.057849
2021-12-03 14:02:21,609 iteration 349 : loss : 0.140287, loss_ce: 0.070188
2021-12-03 14:02:23,131 iteration 350 : loss : 0.135178, loss_ce: 0.054237
2021-12-03 14:02:24,707 iteration 351 : loss : 0.110535, loss_ce: 0.050099
2021-12-03 14:02:26,261 iteration 352 : loss : 0.119082, loss_ce: 0.050473
2021-12-03 14:02:27,735 iteration 353 : loss : 0.132525, loss_ce: 0.052789
2021-12-03 14:02:29,290 iteration 354 : loss : 0.140007, loss_ce: 0.051348
2021-12-03 14:02:30,862 iteration 355 : loss : 0.130313, loss_ce: 0.056839
2021-12-03 14:02:32,541 iteration 356 : loss : 0.130695, loss_ce: 0.061196
2021-12-03 14:02:34,006 iteration 357 : loss : 0.104733, loss_ce: 0.041117
 14%|████▏                         | 21/150 [09:53<1:02:40, 29.15s/it]2021-12-03 14:02:35,641 iteration 358 : loss : 0.133436, loss_ce: 0.057839
2021-12-03 14:02:37,233 iteration 359 : loss : 0.151501, loss_ce: 0.059820
2021-12-03 14:02:38,715 iteration 360 : loss : 0.091522, loss_ce: 0.032117
2021-12-03 14:02:40,277 iteration 361 : loss : 0.162120, loss_ce: 0.060218
2021-12-03 14:02:41,896 iteration 362 : loss : 0.142621, loss_ce: 0.045644
2021-12-03 14:02:43,498 iteration 363 : loss : 0.128083, loss_ce: 0.050044
2021-12-03 14:02:45,056 iteration 364 : loss : 0.116868, loss_ce: 0.047230
2021-12-03 14:02:46,490 iteration 365 : loss : 0.132539, loss_ce: 0.065987
2021-12-03 14:02:48,047 iteration 366 : loss : 0.130726, loss_ce: 0.059561
2021-12-03 14:02:49,504 iteration 367 : loss : 0.117532, loss_ce: 0.050103
2021-12-03 14:02:51,072 iteration 368 : loss : 0.108936, loss_ce: 0.041967
2021-12-03 14:02:52,672 iteration 369 : loss : 0.154994, loss_ce: 0.054860
2021-12-03 14:02:54,261 iteration 370 : loss : 0.146420, loss_ce: 0.073262
2021-12-03 14:02:55,806 iteration 371 : loss : 0.174861, loss_ce: 0.052724
2021-12-03 14:02:57,369 iteration 372 : loss : 0.159168, loss_ce: 0.071604
2021-12-03 14:02:58,843 iteration 373 : loss : 0.150137, loss_ce: 0.050352
2021-12-03 14:03:00,352 iteration 374 : loss : 0.130032, loss_ce: 0.050868
 15%|████▍                         | 22/150 [10:19<1:00:24, 28.31s/it]2021-12-03 14:03:01,996 iteration 375 : loss : 0.207803, loss_ce: 0.090387
2021-12-03 14:03:03,472 iteration 376 : loss : 0.092703, loss_ce: 0.034275
2021-12-03 14:03:04,982 iteration 377 : loss : 0.108950, loss_ce: 0.034163
2021-12-03 14:03:06,580 iteration 378 : loss : 0.123548, loss_ce: 0.046027
2021-12-03 14:03:08,025 iteration 379 : loss : 0.114663, loss_ce: 0.050007
2021-12-03 14:03:09,577 iteration 380 : loss : 0.089780, loss_ce: 0.035430
2021-12-03 14:03:11,097 iteration 381 : loss : 0.083491, loss_ce: 0.031574
2021-12-03 14:03:12,535 iteration 382 : loss : 0.128250, loss_ce: 0.064417
2021-12-03 14:03:14,083 iteration 383 : loss : 0.142427, loss_ce: 0.053251
2021-12-03 14:03:15,634 iteration 384 : loss : 0.095833, loss_ce: 0.043925
2021-12-03 14:03:17,170 iteration 385 : loss : 0.101912, loss_ce: 0.043340
2021-12-03 14:03:18,695 iteration 386 : loss : 0.141752, loss_ce: 0.055417
2021-12-03 14:03:20,246 iteration 387 : loss : 0.199572, loss_ce: 0.075992
2021-12-03 14:03:21,807 iteration 388 : loss : 0.113687, loss_ce: 0.046444
2021-12-03 14:03:23,365 iteration 389 : loss : 0.195567, loss_ce: 0.083335
2021-12-03 14:03:24,869 iteration 390 : loss : 0.094242, loss_ce: 0.040017
2021-12-03 14:03:26,375 iteration 391 : loss : 0.149941, loss_ce: 0.091300
 15%|████▉                           | 23/150 [10:45<58:27, 27.62s/it]2021-12-03 14:03:27,980 iteration 392 : loss : 0.118117, loss_ce: 0.066981
2021-12-03 14:03:29,467 iteration 393 : loss : 0.119423, loss_ce: 0.046788
2021-12-03 14:03:31,041 iteration 394 : loss : 0.093533, loss_ce: 0.036016
2021-12-03 14:03:32,589 iteration 395 : loss : 0.127408, loss_ce: 0.059813
2021-12-03 14:03:34,089 iteration 396 : loss : 0.121651, loss_ce: 0.043968
2021-12-03 14:03:35,616 iteration 397 : loss : 0.119577, loss_ce: 0.049314
2021-12-03 14:03:37,158 iteration 398 : loss : 0.077377, loss_ce: 0.031384
2021-12-03 14:03:38,581 iteration 399 : loss : 0.106809, loss_ce: 0.045260
2021-12-03 14:03:40,110 iteration 400 : loss : 0.091412, loss_ce: 0.034047
2021-12-03 14:03:41,693 iteration 401 : loss : 0.132987, loss_ce: 0.057019
2021-12-03 14:03:43,194 iteration 402 : loss : 0.112956, loss_ce: 0.055200
2021-12-03 14:03:44,693 iteration 403 : loss : 0.086097, loss_ce: 0.031887
2021-12-03 14:03:46,251 iteration 404 : loss : 0.088037, loss_ce: 0.039282
2021-12-03 14:03:47,842 iteration 405 : loss : 0.127518, loss_ce: 0.054736
2021-12-03 14:03:49,342 iteration 406 : loss : 0.123783, loss_ce: 0.044952
2021-12-03 14:03:50,808 iteration 407 : loss : 0.102538, loss_ce: 0.039371
2021-12-03 14:03:52,336 iteration 408 : loss : 0.139248, loss_ce: 0.053990
 16%|█████                           | 24/150 [11:11<56:57, 27.13s/it]2021-12-03 14:03:53,948 iteration 409 : loss : 0.103972, loss_ce: 0.051083
2021-12-03 14:03:55,508 iteration 410 : loss : 0.108164, loss_ce: 0.043937
2021-12-03 14:03:57,032 iteration 411 : loss : 0.168631, loss_ce: 0.050670
2021-12-03 14:03:58,461 iteration 412 : loss : 0.080439, loss_ce: 0.031768
2021-12-03 14:03:59,979 iteration 413 : loss : 0.111167, loss_ce: 0.039459
2021-12-03 14:04:01,450 iteration 414 : loss : 0.153370, loss_ce: 0.074960
2021-12-03 14:04:02,866 iteration 415 : loss : 0.074579, loss_ce: 0.030249
2021-12-03 14:04:04,364 iteration 416 : loss : 0.122970, loss_ce: 0.059664
2021-12-03 14:04:05,841 iteration 417 : loss : 0.127251, loss_ce: 0.050415
2021-12-03 14:04:07,414 iteration 418 : loss : 0.135128, loss_ce: 0.060432
2021-12-03 14:04:08,904 iteration 419 : loss : 0.085937, loss_ce: 0.047984
2021-12-03 14:04:10,430 iteration 420 : loss : 0.088215, loss_ce: 0.034682
2021-12-03 14:04:11,898 iteration 421 : loss : 0.136060, loss_ce: 0.054713
2021-12-03 14:04:13,363 iteration 422 : loss : 0.168825, loss_ce: 0.064285
2021-12-03 14:04:14,852 iteration 423 : loss : 0.115011, loss_ce: 0.039131
2021-12-03 14:04:16,377 iteration 424 : loss : 0.132886, loss_ce: 0.059872
2021-12-03 14:04:16,377 Training Data Eval:
2021-12-03 14:04:23,914   Average segmentation loss on training set: 0.1578
2021-12-03 14:04:23,914 Validation Data Eval:
2021-12-03 14:04:26,515   Average segmentation loss on validation set: 0.1553
2021-12-03 14:04:28,456 Found new lowest validation loss at iteration 424! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/UNET_RUNMC/1channel_best_val_loss.pth
2021-12-03 14:04:29,992 iteration 425 : loss : 0.083982, loss_ce: 0.037036
 17%|█████                         | 25/150 [11:49<1:03:05, 30.29s/it]2021-12-03 14:04:31,514 iteration 426 : loss : 0.086430, loss_ce: 0.032125
2021-12-03 14:04:33,072 iteration 427 : loss : 0.107192, loss_ce: 0.039912
2021-12-03 14:04:34,592 iteration 428 : loss : 0.097231, loss_ce: 0.035867
2021-12-03 14:04:36,050 iteration 429 : loss : 0.146252, loss_ce: 0.084778
2021-12-03 14:04:37,506 iteration 430 : loss : 0.133058, loss_ce: 0.051132
2021-12-03 14:04:38,991 iteration 431 : loss : 0.171349, loss_ce: 0.067836
2021-12-03 14:04:40,548 iteration 432 : loss : 0.083058, loss_ce: 0.035843
2021-12-03 14:04:42,127 iteration 433 : loss : 0.083850, loss_ce: 0.035080
2021-12-03 14:04:43,669 iteration 434 : loss : 0.085809, loss_ce: 0.034193
2021-12-03 14:04:45,134 iteration 435 : loss : 0.073724, loss_ce: 0.031741
2021-12-03 14:04:46,630 iteration 436 : loss : 0.077112, loss_ce: 0.034218
2021-12-03 14:04:48,134 iteration 437 : loss : 0.155453, loss_ce: 0.083029
2021-12-03 14:04:49,589 iteration 438 : loss : 0.119912, loss_ce: 0.042854
2021-12-03 14:04:51,122 iteration 439 : loss : 0.135715, loss_ce: 0.045052
2021-12-03 14:04:52,619 iteration 440 : loss : 0.088199, loss_ce: 0.034484
2021-12-03 14:04:54,174 iteration 441 : loss : 0.115090, loss_ce: 0.047399
2021-12-03 14:04:55,711 iteration 442 : loss : 0.111033, loss_ce: 0.052658
 17%|█████▌                          | 26/150 [12:15<59:45, 28.92s/it]2021-12-03 14:04:57,269 iteration 443 : loss : 0.125350, loss_ce: 0.059772
2021-12-03 14:04:58,734 iteration 444 : loss : 0.094887, loss_ce: 0.037316
2021-12-03 14:05:00,240 iteration 445 : loss : 0.159938, loss_ce: 0.060962
2021-12-03 14:05:01,873 iteration 446 : loss : 0.125831, loss_ce: 0.049863
2021-12-03 14:05:03,459 iteration 447 : loss : 0.086972, loss_ce: 0.045566
2021-12-03 14:05:05,021 iteration 448 : loss : 0.202975, loss_ce: 0.057558
2021-12-03 14:05:06,547 iteration 449 : loss : 0.110359, loss_ce: 0.050873
2021-12-03 14:05:08,051 iteration 450 : loss : 0.107846, loss_ce: 0.036757
2021-12-03 14:05:09,645 iteration 451 : loss : 0.084995, loss_ce: 0.038020
2021-12-03 14:05:11,201 iteration 452 : loss : 0.091397, loss_ce: 0.038491
2021-12-03 14:05:12,750 iteration 453 : loss : 0.118400, loss_ce: 0.046794
2021-12-03 14:05:14,292 iteration 454 : loss : 0.147233, loss_ce: 0.048943
2021-12-03 14:05:15,875 iteration 455 : loss : 0.076963, loss_ce: 0.034425
2021-12-03 14:05:17,412 iteration 456 : loss : 0.093677, loss_ce: 0.034313
2021-12-03 14:05:18,959 iteration 457 : loss : 0.110121, loss_ce: 0.046533
2021-12-03 14:05:20,556 iteration 458 : loss : 0.119046, loss_ce: 0.056964
2021-12-03 14:05:22,031 iteration 459 : loss : 0.068948, loss_ce: 0.025757
 18%|█████▊                          | 27/150 [12:41<57:40, 28.14s/it]2021-12-03 14:05:23,632 iteration 460 : loss : 0.125107, loss_ce: 0.061252
2021-12-03 14:05:25,197 iteration 461 : loss : 0.084633, loss_ce: 0.037639
2021-12-03 14:05:26,703 iteration 462 : loss : 0.087864, loss_ce: 0.040778
2021-12-03 14:05:28,297 iteration 463 : loss : 0.121861, loss_ce: 0.060391
2021-12-03 14:05:29,827 iteration 464 : loss : 0.088734, loss_ce: 0.036383
2021-12-03 14:05:31,304 iteration 465 : loss : 0.109493, loss_ce: 0.035747
2021-12-03 14:05:32,813 iteration 466 : loss : 0.090112, loss_ce: 0.029181
2021-12-03 14:05:34,311 iteration 467 : loss : 0.106965, loss_ce: 0.038507
2021-12-03 14:05:35,927 iteration 468 : loss : 0.129146, loss_ce: 0.053902
2021-12-03 14:05:37,428 iteration 469 : loss : 0.068549, loss_ce: 0.026714
2021-12-03 14:05:38,949 iteration 470 : loss : 0.121994, loss_ce: 0.047317
2021-12-03 14:05:40,463 iteration 471 : loss : 0.093412, loss_ce: 0.034073
2021-12-03 14:05:42,033 iteration 472 : loss : 0.101854, loss_ce: 0.042349
2021-12-03 14:05:43,702 iteration 473 : loss : 0.115265, loss_ce: 0.047761
2021-12-03 14:05:45,317 iteration 474 : loss : 0.140927, loss_ce: 0.060213
2021-12-03 14:05:46,820 iteration 475 : loss : 0.117510, loss_ce: 0.043566
2021-12-03 14:05:48,401 iteration 476 : loss : 0.120347, loss_ce: 0.061221
 19%|█████▉                          | 28/150 [13:07<56:07, 27.61s/it]2021-12-03 14:05:49,983 iteration 477 : loss : 0.106127, loss_ce: 0.033655
2021-12-03 14:05:51,555 iteration 478 : loss : 0.073744, loss_ce: 0.027482
2021-12-03 14:05:53,067 iteration 479 : loss : 0.106293, loss_ce: 0.044293
2021-12-03 14:05:54,607 iteration 480 : loss : 0.099845, loss_ce: 0.047477
2021-12-03 14:05:56,056 iteration 481 : loss : 0.114723, loss_ce: 0.046301
2021-12-03 14:05:57,591 iteration 482 : loss : 0.122105, loss_ce: 0.042283
2021-12-03 14:05:59,141 iteration 483 : loss : 0.113624, loss_ce: 0.040999
2021-12-03 14:06:00,709 iteration 484 : loss : 0.134319, loss_ce: 0.059761
2021-12-03 14:06:02,216 iteration 485 : loss : 0.072629, loss_ce: 0.031925
2021-12-03 14:06:03,727 iteration 486 : loss : 0.111898, loss_ce: 0.037058
2021-12-03 14:06:05,304 iteration 487 : loss : 0.084785, loss_ce: 0.034364
2021-12-03 14:06:06,816 iteration 488 : loss : 0.099498, loss_ce: 0.036734
2021-12-03 14:06:08,345 iteration 489 : loss : 0.104043, loss_ce: 0.043553
2021-12-03 14:06:09,771 iteration 490 : loss : 0.073120, loss_ce: 0.026954
2021-12-03 14:06:11,300 iteration 491 : loss : 0.087354, loss_ce: 0.040152
2021-12-03 14:06:12,811 iteration 492 : loss : 0.055782, loss_ce: 0.028138
2021-12-03 14:06:14,364 iteration 493 : loss : 0.104032, loss_ce: 0.046595
 19%|██████▏                         | 29/150 [13:33<54:40, 27.11s/it]2021-12-03 14:06:15,943 iteration 494 : loss : 0.083183, loss_ce: 0.038213
2021-12-03 14:06:17,568 iteration 495 : loss : 0.094627, loss_ce: 0.030556
2021-12-03 14:06:19,122 iteration 496 : loss : 0.092461, loss_ce: 0.043155
2021-12-03 14:06:20,726 iteration 497 : loss : 0.113764, loss_ce: 0.059654
2021-12-03 14:06:22,355 iteration 498 : loss : 0.107989, loss_ce: 0.050347
2021-12-03 14:06:23,843 iteration 499 : loss : 0.098644, loss_ce: 0.044363
2021-12-03 14:06:25,346 iteration 500 : loss : 0.077306, loss_ce: 0.027870
2021-12-03 14:06:26,850 iteration 501 : loss : 0.101350, loss_ce: 0.048265
2021-12-03 14:06:28,479 iteration 502 : loss : 0.097857, loss_ce: 0.042358
2021-12-03 14:06:30,017 iteration 503 : loss : 0.141767, loss_ce: 0.050773
2021-12-03 14:06:31,598 iteration 504 : loss : 0.101060, loss_ce: 0.035615
2021-12-03 14:06:33,122 iteration 505 : loss : 0.061181, loss_ce: 0.025989
2021-12-03 14:06:34,815 iteration 506 : loss : 0.064092, loss_ce: 0.027868
2021-12-03 14:06:36,388 iteration 507 : loss : 0.100021, loss_ce: 0.034161
2021-12-03 14:06:37,975 iteration 508 : loss : 0.090985, loss_ce: 0.040906
2021-12-03 14:06:39,613 iteration 509 : loss : 0.097676, loss_ce: 0.033246
2021-12-03 14:06:39,614 Training Data Eval:
2021-12-03 14:06:47,261   Average segmentation loss on training set: 0.0784
2021-12-03 14:06:47,262 Validation Data Eval:
2021-12-03 14:06:49,896   Average segmentation loss on validation set: 0.1442
2021-12-03 14:06:51,833 Found new lowest validation loss at iteration 509! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/UNET_RUNMC/1channel_best_val_loss.pth
2021-12-03 14:06:53,431 iteration 510 : loss : 0.073674, loss_ce: 0.030727
 20%|██████                        | 30/150 [14:12<1:01:23, 30.70s/it]2021-12-03 14:06:55,047 iteration 511 : loss : 0.113942, loss_ce: 0.048398
2021-12-03 14:06:56,531 iteration 512 : loss : 0.087469, loss_ce: 0.041026
2021-12-03 14:06:58,051 iteration 513 : loss : 0.059743, loss_ce: 0.020003
2021-12-03 14:06:59,574 iteration 514 : loss : 0.093903, loss_ce: 0.041812
2021-12-03 14:07:01,080 iteration 515 : loss : 0.140155, loss_ce: 0.068929
2021-12-03 14:07:02,636 iteration 516 : loss : 0.119366, loss_ce: 0.049254
2021-12-03 14:07:04,224 iteration 517 : loss : 0.110342, loss_ce: 0.059235
2021-12-03 14:07:05,703 iteration 518 : loss : 0.098800, loss_ce: 0.032331
2021-12-03 14:07:07,232 iteration 519 : loss : 0.081395, loss_ce: 0.036777
2021-12-03 14:07:08,716 iteration 520 : loss : 0.092535, loss_ce: 0.039269
2021-12-03 14:07:10,241 iteration 521 : loss : 0.093780, loss_ce: 0.033391
2021-12-03 14:07:11,808 iteration 522 : loss : 0.095575, loss_ce: 0.037145
2021-12-03 14:07:13,420 iteration 523 : loss : 0.105432, loss_ce: 0.048936
2021-12-03 14:07:15,049 iteration 524 : loss : 0.097518, loss_ce: 0.042751
2021-12-03 14:07:16,581 iteration 525 : loss : 0.123124, loss_ce: 0.062613
2021-12-03 14:07:18,105 iteration 526 : loss : 0.099833, loss_ce: 0.045084
2021-12-03 14:07:19,634 iteration 527 : loss : 0.099220, loss_ce: 0.036335
 21%|██████▌                         | 31/150 [14:39<58:12, 29.35s/it]2021-12-03 14:07:21,199 iteration 528 : loss : 0.085823, loss_ce: 0.040492
2021-12-03 14:07:22,740 iteration 529 : loss : 0.094716, loss_ce: 0.031915
2021-12-03 14:07:24,236 iteration 530 : loss : 0.119101, loss_ce: 0.046812
2021-12-03 14:07:25,706 iteration 531 : loss : 0.087383, loss_ce: 0.028921
2021-12-03 14:07:27,202 iteration 532 : loss : 0.106251, loss_ce: 0.043767
2021-12-03 14:07:28,826 iteration 533 : loss : 0.053626, loss_ce: 0.023968
2021-12-03 14:07:30,308 iteration 534 : loss : 0.092011, loss_ce: 0.039419
2021-12-03 14:07:31,878 iteration 535 : loss : 0.097900, loss_ce: 0.034788
2021-12-03 14:07:33,505 iteration 536 : loss : 0.136490, loss_ce: 0.061996
2021-12-03 14:07:35,129 iteration 537 : loss : 0.103740, loss_ce: 0.040200
2021-12-03 14:07:36,697 iteration 538 : loss : 0.076306, loss_ce: 0.034853
2021-12-03 14:07:38,209 iteration 539 : loss : 0.096321, loss_ce: 0.037502
2021-12-03 14:07:39,778 iteration 540 : loss : 0.085091, loss_ce: 0.028557
2021-12-03 14:07:41,288 iteration 541 : loss : 0.080745, loss_ce: 0.035532
2021-12-03 14:07:42,808 iteration 542 : loss : 0.088151, loss_ce: 0.037008
2021-12-03 14:07:44,275 iteration 543 : loss : 0.057441, loss_ce: 0.024598
2021-12-03 14:07:45,772 iteration 544 : loss : 0.073834, loss_ce: 0.028961
 21%|██████▊                         | 32/150 [15:05<55:49, 28.39s/it]2021-12-03 14:07:47,365 iteration 545 : loss : 0.076842, loss_ce: 0.039882
2021-12-03 14:07:48,884 iteration 546 : loss : 0.093804, loss_ce: 0.035907
2021-12-03 14:07:50,400 iteration 547 : loss : 0.086212, loss_ce: 0.038817
2021-12-03 14:07:51,909 iteration 548 : loss : 0.128606, loss_ce: 0.044702
2021-12-03 14:07:53,452 iteration 549 : loss : 0.077340, loss_ce: 0.032936
2021-12-03 14:07:54,941 iteration 550 : loss : 0.091751, loss_ce: 0.036846
2021-12-03 14:07:56,453 iteration 551 : loss : 0.098927, loss_ce: 0.040278
2021-12-03 14:07:57,943 iteration 552 : loss : 0.075104, loss_ce: 0.029751
2021-12-03 14:07:59,499 iteration 553 : loss : 0.082591, loss_ce: 0.036236
2021-12-03 14:08:00,968 iteration 554 : loss : 0.077985, loss_ce: 0.034918
2021-12-03 14:08:02,482 iteration 555 : loss : 0.094034, loss_ce: 0.024297
2021-12-03 14:08:04,039 iteration 556 : loss : 0.091385, loss_ce: 0.038839
2021-12-03 14:08:05,485 iteration 557 : loss : 0.069614, loss_ce: 0.028001
2021-12-03 14:08:07,033 iteration 558 : loss : 0.083616, loss_ce: 0.028447
2021-12-03 14:08:08,565 iteration 559 : loss : 0.110921, loss_ce: 0.040814
2021-12-03 14:08:10,104 iteration 560 : loss : 0.145936, loss_ce: 0.034855
2021-12-03 14:08:11,669 iteration 561 : loss : 0.138197, loss_ce: 0.074670
 22%|███████                         | 33/150 [15:31<53:54, 27.64s/it]2021-12-03 14:08:13,361 iteration 562 : loss : 0.127008, loss_ce: 0.058649
2021-12-03 14:08:14,815 iteration 563 : loss : 0.076106, loss_ce: 0.033493
2021-12-03 14:08:16,399 iteration 564 : loss : 0.082112, loss_ce: 0.045079
2021-12-03 14:08:17,982 iteration 565 : loss : 0.105273, loss_ce: 0.044468
2021-12-03 14:08:19,630 iteration 566 : loss : 0.098363, loss_ce: 0.041898
2021-12-03 14:08:21,159 iteration 567 : loss : 0.082582, loss_ce: 0.029445
2021-12-03 14:08:22,671 iteration 568 : loss : 0.161548, loss_ce: 0.057177
2021-12-03 14:08:24,220 iteration 569 : loss : 0.090293, loss_ce: 0.038749
2021-12-03 14:08:25,837 iteration 570 : loss : 0.083402, loss_ce: 0.040660
2021-12-03 14:08:27,369 iteration 571 : loss : 0.155694, loss_ce: 0.065715
2021-12-03 14:08:28,966 iteration 572 : loss : 0.112953, loss_ce: 0.037407
2021-12-03 14:08:30,494 iteration 573 : loss : 0.082257, loss_ce: 0.032398
2021-12-03 14:08:32,077 iteration 574 : loss : 0.099315, loss_ce: 0.034913
2021-12-03 14:08:33,731 iteration 575 : loss : 0.100467, loss_ce: 0.033024
2021-12-03 14:08:35,359 iteration 576 : loss : 0.128952, loss_ce: 0.053065
2021-12-03 14:08:36,910 iteration 577 : loss : 0.065785, loss_ce: 0.031103
2021-12-03 14:08:38,431 iteration 578 : loss : 0.087536, loss_ce: 0.035924
 23%|███████▎                        | 34/150 [15:57<52:55, 27.38s/it]2021-12-03 14:08:40,280 iteration 579 : loss : 0.113425, loss_ce: 0.051598
2021-12-03 14:08:41,885 iteration 580 : loss : 0.098595, loss_ce: 0.036273
2021-12-03 14:08:43,527 iteration 581 : loss : 0.108922, loss_ce: 0.031130
2021-12-03 14:08:45,083 iteration 582 : loss : 0.087247, loss_ce: 0.037970
2021-12-03 14:08:46,669 iteration 583 : loss : 0.112803, loss_ce: 0.029777
2021-12-03 14:08:48,175 iteration 584 : loss : 0.068192, loss_ce: 0.028060
2021-12-03 14:08:49,764 iteration 585 : loss : 0.078215, loss_ce: 0.029367
2021-12-03 14:08:51,258 iteration 586 : loss : 0.112481, loss_ce: 0.043997
2021-12-03 14:08:52,744 iteration 587 : loss : 0.068404, loss_ce: 0.030529
2021-12-03 14:08:54,302 iteration 588 : loss : 0.107385, loss_ce: 0.037684
2021-12-03 14:08:55,824 iteration 589 : loss : 0.086671, loss_ce: 0.035042
2021-12-03 14:08:57,353 iteration 590 : loss : 0.096445, loss_ce: 0.035214
2021-12-03 14:08:58,892 iteration 591 : loss : 0.082933, loss_ce: 0.033651
2021-12-03 14:09:00,427 iteration 592 : loss : 0.086360, loss_ce: 0.032395
2021-12-03 14:09:01,986 iteration 593 : loss : 0.072489, loss_ce: 0.026718
2021-12-03 14:09:03,539 iteration 594 : loss : 0.088468, loss_ce: 0.037634
2021-12-03 14:09:03,539 Training Data Eval:
2021-12-03 14:09:11,107   Average segmentation loss on training set: 0.0679
2021-12-03 14:09:11,107 Validation Data Eval:
2021-12-03 14:09:13,720   Average segmentation loss on validation set: 0.1192
2021-12-03 14:09:15,648 Found new lowest validation loss at iteration 594! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/UNET_RUNMC/1channel_best_val_loss.pth
2021-12-03 14:09:17,281 iteration 595 : loss : 0.102141, loss_ce: 0.049914
 23%|███████▍                        | 35/150 [16:36<59:04, 30.82s/it]2021-12-03 14:09:18,884 iteration 596 : loss : 0.092377, loss_ce: 0.036628
2021-12-03 14:09:20,421 iteration 597 : loss : 0.113462, loss_ce: 0.036750
2021-12-03 14:09:21,909 iteration 598 : loss : 0.063151, loss_ce: 0.022060
2021-12-03 14:09:23,420 iteration 599 : loss : 0.080033, loss_ce: 0.033002
2021-12-03 14:09:24,931 iteration 600 : loss : 0.074211, loss_ce: 0.033580
2021-12-03 14:09:26,471 iteration 601 : loss : 0.075813, loss_ce: 0.030288
2021-12-03 14:09:28,027 iteration 602 : loss : 0.068799, loss_ce: 0.029732
2021-12-03 14:09:29,492 iteration 603 : loss : 0.084271, loss_ce: 0.030099
2021-12-03 14:09:30,970 iteration 604 : loss : 0.076230, loss_ce: 0.027868
2021-12-03 14:09:32,436 iteration 605 : loss : 0.101946, loss_ce: 0.044183
2021-12-03 14:09:34,099 iteration 606 : loss : 0.105157, loss_ce: 0.043627
2021-12-03 14:09:35,619 iteration 607 : loss : 0.074844, loss_ce: 0.033959
2021-12-03 14:09:37,146 iteration 608 : loss : 0.093467, loss_ce: 0.043024
2021-12-03 14:09:38,594 iteration 609 : loss : 0.069209, loss_ce: 0.028791
2021-12-03 14:09:40,167 iteration 610 : loss : 0.071894, loss_ce: 0.030345
2021-12-03 14:09:41,813 iteration 611 : loss : 0.074304, loss_ce: 0.036813
2021-12-03 14:09:43,371 iteration 612 : loss : 0.093036, loss_ce: 0.034153
 24%|███████▋                        | 36/150 [17:02<55:51, 29.40s/it]2021-12-03 14:09:44,993 iteration 613 : loss : 0.071216, loss_ce: 0.030358
2021-12-03 14:09:46,490 iteration 614 : loss : 0.094598, loss_ce: 0.033818
2021-12-03 14:09:47,988 iteration 615 : loss : 0.104901, loss_ce: 0.049811
2021-12-03 14:09:49,582 iteration 616 : loss : 0.074201, loss_ce: 0.032493
2021-12-03 14:09:51,079 iteration 617 : loss : 0.102396, loss_ce: 0.046453
2021-12-03 14:09:52,607 iteration 618 : loss : 0.128365, loss_ce: 0.036115
2021-12-03 14:09:54,135 iteration 619 : loss : 0.121169, loss_ce: 0.047047
2021-12-03 14:09:55,758 iteration 620 : loss : 0.178847, loss_ce: 0.060613
2021-12-03 14:09:57,288 iteration 621 : loss : 0.081371, loss_ce: 0.030328
2021-12-03 14:09:58,933 iteration 622 : loss : 0.096046, loss_ce: 0.035326
2021-12-03 14:10:00,554 iteration 623 : loss : 0.099673, loss_ce: 0.048254
2021-12-03 14:10:02,068 iteration 624 : loss : 0.084968, loss_ce: 0.030340
2021-12-03 14:10:03,545 iteration 625 : loss : 0.089247, loss_ce: 0.035937
2021-12-03 14:10:05,109 iteration 626 : loss : 0.089388, loss_ce: 0.034644
2021-12-03 14:10:06,683 iteration 627 : loss : 0.133652, loss_ce: 0.045509
2021-12-03 14:10:08,302 iteration 628 : loss : 0.118613, loss_ce: 0.051037
2021-12-03 14:10:09,821 iteration 629 : loss : 0.064826, loss_ce: 0.026865
 25%|███████▉                        | 37/150 [17:29<53:42, 28.51s/it]2021-12-03 14:10:11,434 iteration 630 : loss : 0.097288, loss_ce: 0.045783
2021-12-03 14:10:12,936 iteration 631 : loss : 0.049701, loss_ce: 0.022711
2021-12-03 14:10:14,435 iteration 632 : loss : 0.109338, loss_ce: 0.050155
2021-12-03 14:10:16,034 iteration 633 : loss : 0.100334, loss_ce: 0.040099
2021-12-03 14:10:17,564 iteration 634 : loss : 0.117844, loss_ce: 0.041396
2021-12-03 14:10:19,185 iteration 635 : loss : 0.081284, loss_ce: 0.037112
2021-12-03 14:10:20,735 iteration 636 : loss : 0.087935, loss_ce: 0.034020
2021-12-03 14:10:22,195 iteration 637 : loss : 0.082646, loss_ce: 0.034281
2021-12-03 14:10:23,804 iteration 638 : loss : 0.119971, loss_ce: 0.041314
2021-12-03 14:10:25,297 iteration 639 : loss : 0.076812, loss_ce: 0.032362
2021-12-03 14:10:26,765 iteration 640 : loss : 0.123836, loss_ce: 0.037907
2021-12-03 14:10:28,232 iteration 641 : loss : 0.075867, loss_ce: 0.034130
2021-12-03 14:10:29,717 iteration 642 : loss : 0.107315, loss_ce: 0.032954
2021-12-03 14:10:31,218 iteration 643 : loss : 0.091679, loss_ce: 0.033746
2021-12-03 14:10:32,750 iteration 644 : loss : 0.109594, loss_ce: 0.049905
2021-12-03 14:10:34,228 iteration 645 : loss : 0.091192, loss_ce: 0.029792
2021-12-03 14:10:35,818 iteration 646 : loss : 0.086104, loss_ce: 0.041051
 25%|████████                        | 38/150 [17:55<51:48, 27.76s/it]2021-12-03 14:10:37,378 iteration 647 : loss : 0.102880, loss_ce: 0.042770
2021-12-03 14:10:38,906 iteration 648 : loss : 0.068388, loss_ce: 0.026299
2021-12-03 14:10:40,454 iteration 649 : loss : 0.091721, loss_ce: 0.036731
2021-12-03 14:10:42,050 iteration 650 : loss : 0.091583, loss_ce: 0.033800
2021-12-03 14:10:43,569 iteration 651 : loss : 0.057240, loss_ce: 0.020807
2021-12-03 14:10:44,986 iteration 652 : loss : 0.054336, loss_ce: 0.020963
2021-12-03 14:10:46,574 iteration 653 : loss : 0.090737, loss_ce: 0.034333
2021-12-03 14:10:48,043 iteration 654 : loss : 0.067757, loss_ce: 0.023757
2021-12-03 14:10:49,566 iteration 655 : loss : 0.086937, loss_ce: 0.030965
2021-12-03 14:10:51,099 iteration 656 : loss : 0.084224, loss_ce: 0.030191
2021-12-03 14:10:52,696 iteration 657 : loss : 0.049334, loss_ce: 0.020887
2021-12-03 14:10:54,246 iteration 658 : loss : 0.089671, loss_ce: 0.035452
2021-12-03 14:10:55,796 iteration 659 : loss : 0.084226, loss_ce: 0.032663
2021-12-03 14:10:57,288 iteration 660 : loss : 0.065920, loss_ce: 0.030456
2021-12-03 14:10:58,835 iteration 661 : loss : 0.083913, loss_ce: 0.037348
2021-12-03 14:11:00,462 iteration 662 : loss : 0.104149, loss_ce: 0.032277
2021-12-03 14:11:01,994 iteration 663 : loss : 0.072442, loss_ce: 0.029510
 26%|████████▎                       | 39/150 [18:21<50:28, 27.28s/it]2021-12-03 14:11:03,598 iteration 664 : loss : 0.089308, loss_ce: 0.037131
2021-12-03 14:11:05,058 iteration 665 : loss : 0.068997, loss_ce: 0.030529
2021-12-03 14:11:06,572 iteration 666 : loss : 0.059896, loss_ce: 0.019469
2021-12-03 14:11:08,154 iteration 667 : loss : 0.051745, loss_ce: 0.021972
2021-12-03 14:11:09,689 iteration 668 : loss : 0.088396, loss_ce: 0.041801
2021-12-03 14:11:11,208 iteration 669 : loss : 0.069748, loss_ce: 0.023857
2021-12-03 14:11:12,851 iteration 670 : loss : 0.084058, loss_ce: 0.031027
2021-12-03 14:11:14,377 iteration 671 : loss : 0.086167, loss_ce: 0.029714
2021-12-03 14:11:15,970 iteration 672 : loss : 0.075825, loss_ce: 0.026904
2021-12-03 14:11:17,554 iteration 673 : loss : 0.069551, loss_ce: 0.029975
2021-12-03 14:11:19,106 iteration 674 : loss : 0.072284, loss_ce: 0.039042
2021-12-03 14:11:20,686 iteration 675 : loss : 0.083248, loss_ce: 0.034660
2021-12-03 14:11:22,204 iteration 676 : loss : 0.076912, loss_ce: 0.033233
2021-12-03 14:11:23,737 iteration 677 : loss : 0.059223, loss_ce: 0.030029
2021-12-03 14:11:25,295 iteration 678 : loss : 0.080768, loss_ce: 0.032614
2021-12-03 14:11:26,832 iteration 679 : loss : 0.080048, loss_ce: 0.033444
2021-12-03 14:11:26,832 Training Data Eval:
2021-12-03 14:11:34,381   Average segmentation loss on training set: 0.0592
2021-12-03 14:11:34,381 Validation Data Eval:
2021-12-03 14:11:36,986   Average segmentation loss on validation set: 0.1551
2021-12-03 14:11:38,504 iteration 680 : loss : 0.091035, loss_ce: 0.032822
 27%|████████▌                       | 40/150 [18:57<55:05, 30.05s/it]2021-12-03 14:11:40,133 iteration 681 : loss : 0.049488, loss_ce: 0.019265
2021-12-03 14:11:41,586 iteration 682 : loss : 0.116146, loss_ce: 0.034687
2021-12-03 14:11:43,106 iteration 683 : loss : 0.072531, loss_ce: 0.032081
2021-12-03 14:11:44,585 iteration 684 : loss : 0.075067, loss_ce: 0.029446
2021-12-03 14:11:46,173 iteration 685 : loss : 0.080968, loss_ce: 0.032600
2021-12-03 14:11:47,699 iteration 686 : loss : 0.093127, loss_ce: 0.038072
2021-12-03 14:11:49,218 iteration 687 : loss : 0.082137, loss_ce: 0.037133
2021-12-03 14:11:50,725 iteration 688 : loss : 0.074329, loss_ce: 0.023286
2021-12-03 14:11:52,273 iteration 689 : loss : 0.069312, loss_ce: 0.031221
2021-12-03 14:11:53,791 iteration 690 : loss : 0.079104, loss_ce: 0.028277
2021-12-03 14:11:55,320 iteration 691 : loss : 0.089455, loss_ce: 0.033223
2021-12-03 14:11:56,904 iteration 692 : loss : 0.071913, loss_ce: 0.027464
2021-12-03 14:11:58,370 iteration 693 : loss : 0.096437, loss_ce: 0.050451
2021-12-03 14:11:59,906 iteration 694 : loss : 0.081051, loss_ce: 0.034529
2021-12-03 14:12:01,394 iteration 695 : loss : 0.084140, loss_ce: 0.034537
2021-12-03 14:12:02,983 iteration 696 : loss : 0.076694, loss_ce: 0.040299
2021-12-03 14:12:04,514 iteration 697 : loss : 0.062774, loss_ce: 0.024589
 27%|████████▋                       | 41/150 [19:23<52:23, 28.84s/it]2021-12-03 14:12:06,075 iteration 698 : loss : 0.069129, loss_ce: 0.022373
2021-12-03 14:12:07,644 iteration 699 : loss : 0.088101, loss_ce: 0.038232
2021-12-03 14:12:09,152 iteration 700 : loss : 0.082496, loss_ce: 0.038090
2021-12-03 14:12:10,654 iteration 701 : loss : 0.078583, loss_ce: 0.043743
2021-12-03 14:12:12,237 iteration 702 : loss : 0.116917, loss_ce: 0.040942
2021-12-03 14:12:13,846 iteration 703 : loss : 0.051083, loss_ce: 0.022358
2021-12-03 14:12:15,326 iteration 704 : loss : 0.052212, loss_ce: 0.021198
2021-12-03 14:12:16,850 iteration 705 : loss : 0.083565, loss_ce: 0.031144
2021-12-03 14:12:18,390 iteration 706 : loss : 0.067252, loss_ce: 0.024827
2021-12-03 14:12:19,848 iteration 707 : loss : 0.052006, loss_ce: 0.023007
2021-12-03 14:12:21,362 iteration 708 : loss : 0.053062, loss_ce: 0.020110
2021-12-03 14:12:22,879 iteration 709 : loss : 0.094847, loss_ce: 0.041316
2021-12-03 14:12:24,441 iteration 710 : loss : 0.082404, loss_ce: 0.030380
2021-12-03 14:12:25,989 iteration 711 : loss : 0.069500, loss_ce: 0.029207
2021-12-03 14:12:27,605 iteration 712 : loss : 0.057332, loss_ce: 0.021982
2021-12-03 14:12:29,121 iteration 713 : loss : 0.073215, loss_ce: 0.035937
2021-12-03 14:12:30,717 iteration 714 : loss : 0.113279, loss_ce: 0.041049
 28%|████████▉                       | 42/150 [19:50<50:29, 28.05s/it]2021-12-03 14:12:32,354 iteration 715 : loss : 0.067355, loss_ce: 0.024765
2021-12-03 14:12:33,932 iteration 716 : loss : 0.048297, loss_ce: 0.021936
2021-12-03 14:12:35,459 iteration 717 : loss : 0.079634, loss_ce: 0.027662
2021-12-03 14:12:37,003 iteration 718 : loss : 0.087930, loss_ce: 0.043414
2021-12-03 14:12:38,595 iteration 719 : loss : 0.100986, loss_ce: 0.032874
2021-12-03 14:12:40,121 iteration 720 : loss : 0.055161, loss_ce: 0.021083
2021-12-03 14:12:41,649 iteration 721 : loss : 0.078052, loss_ce: 0.024524
2021-12-03 14:12:43,167 iteration 722 : loss : 0.071501, loss_ce: 0.023127
2021-12-03 14:12:44,733 iteration 723 : loss : 0.081949, loss_ce: 0.040507
2021-12-03 14:12:46,242 iteration 724 : loss : 0.112678, loss_ce: 0.047437
2021-12-03 14:12:47,824 iteration 725 : loss : 0.074048, loss_ce: 0.028836
2021-12-03 14:12:49,348 iteration 726 : loss : 0.084572, loss_ce: 0.033177
2021-12-03 14:12:50,809 iteration 727 : loss : 0.066252, loss_ce: 0.025140
2021-12-03 14:12:52,363 iteration 728 : loss : 0.058726, loss_ce: 0.024607
2021-12-03 14:12:53,948 iteration 729 : loss : 0.082620, loss_ce: 0.034904
2021-12-03 14:12:55,491 iteration 730 : loss : 0.073489, loss_ce: 0.027861
2021-12-03 14:12:56,944 iteration 731 : loss : 0.057602, loss_ce: 0.020408
 29%|█████████▏                      | 43/150 [20:16<49:02, 27.50s/it]2021-12-03 14:12:58,470 iteration 732 : loss : 0.061442, loss_ce: 0.026660
2021-12-03 14:12:59,918 iteration 733 : loss : 0.062889, loss_ce: 0.029064
2021-12-03 14:13:01,484 iteration 734 : loss : 0.072488, loss_ce: 0.028980
2021-12-03 14:13:02,996 iteration 735 : loss : 0.094871, loss_ce: 0.035544
2021-12-03 14:13:04,484 iteration 736 : loss : 0.080343, loss_ce: 0.033142
2021-12-03 14:13:06,125 iteration 737 : loss : 0.068864, loss_ce: 0.032110
2021-12-03 14:13:07,562 iteration 738 : loss : 0.053830, loss_ce: 0.024443
2021-12-03 14:13:09,110 iteration 739 : loss : 0.066499, loss_ce: 0.025473
2021-12-03 14:13:10,617 iteration 740 : loss : 0.051539, loss_ce: 0.021060
2021-12-03 14:13:12,105 iteration 741 : loss : 0.066823, loss_ce: 0.026757
2021-12-03 14:13:13,550 iteration 742 : loss : 0.075667, loss_ce: 0.033335
2021-12-03 14:13:15,078 iteration 743 : loss : 0.063761, loss_ce: 0.023522
2021-12-03 14:13:16,629 iteration 744 : loss : 0.056795, loss_ce: 0.023277
2021-12-03 14:13:18,117 iteration 745 : loss : 0.135066, loss_ce: 0.034127
2021-12-03 14:13:19,606 iteration 746 : loss : 0.054610, loss_ce: 0.020200
2021-12-03 14:13:21,090 iteration 747 : loss : 0.081882, loss_ce: 0.034129
2021-12-03 14:13:22,584 iteration 748 : loss : 0.083927, loss_ce: 0.038531
 29%|█████████▍                      | 44/150 [20:42<47:36, 26.94s/it]2021-12-03 14:13:24,107 iteration 749 : loss : 0.163262, loss_ce: 0.035729
2021-12-03 14:13:25,608 iteration 750 : loss : 0.062387, loss_ce: 0.023465
2021-12-03 14:13:27,149 iteration 751 : loss : 0.051273, loss_ce: 0.014187
2021-12-03 14:13:28,649 iteration 752 : loss : 0.108837, loss_ce: 0.051071
2021-12-03 14:13:30,115 iteration 753 : loss : 0.079569, loss_ce: 0.036564
2021-12-03 14:13:31,598 iteration 754 : loss : 0.099201, loss_ce: 0.036598
2021-12-03 14:13:33,028 iteration 755 : loss : 0.082041, loss_ce: 0.041940
2021-12-03 14:13:34,469 iteration 756 : loss : 0.048173, loss_ce: 0.017724
2021-12-03 14:13:35,976 iteration 757 : loss : 0.096489, loss_ce: 0.045849
2021-12-03 14:13:37,573 iteration 758 : loss : 0.075778, loss_ce: 0.029829
2021-12-03 14:13:39,223 iteration 759 : loss : 0.099013, loss_ce: 0.037551
2021-12-03 14:13:40,724 iteration 760 : loss : 0.096435, loss_ce: 0.053214
2021-12-03 14:13:42,268 iteration 761 : loss : 0.052898, loss_ce: 0.022605
2021-12-03 14:13:43,827 iteration 762 : loss : 0.072395, loss_ce: 0.027566
2021-12-03 14:13:45,395 iteration 763 : loss : 0.065522, loss_ce: 0.025098
2021-12-03 14:13:46,890 iteration 764 : loss : 0.089125, loss_ce: 0.036192
2021-12-03 14:13:46,890 Training Data Eval:
2021-12-03 14:13:54,450   Average segmentation loss on training set: 0.1069
2021-12-03 14:13:54,450 Validation Data Eval:
2021-12-03 14:13:57,055   Average segmentation loss on validation set: 0.1570
2021-12-03 14:13:58,726 iteration 765 : loss : 0.109660, loss_ce: 0.040831
 30%|█████████▌                      | 45/150 [21:18<51:58, 29.70s/it]2021-12-03 14:14:00,361 iteration 766 : loss : 0.123119, loss_ce: 0.059282
2021-12-03 14:14:01,916 iteration 767 : loss : 0.088519, loss_ce: 0.033705
2021-12-03 14:14:03,461 iteration 768 : loss : 0.092921, loss_ce: 0.035595
2021-12-03 14:14:05,022 iteration 769 : loss : 0.084277, loss_ce: 0.035997
2021-12-03 14:14:06,473 iteration 770 : loss : 0.059181, loss_ce: 0.021555
2021-12-03 14:14:08,000 iteration 771 : loss : 0.128951, loss_ce: 0.041839
2021-12-03 14:14:09,542 iteration 772 : loss : 0.062635, loss_ce: 0.022841
2021-12-03 14:14:11,093 iteration 773 : loss : 0.103335, loss_ce: 0.027919
2021-12-03 14:14:12,726 iteration 774 : loss : 0.079599, loss_ce: 0.033478
2021-12-03 14:14:14,231 iteration 775 : loss : 0.088203, loss_ce: 0.047483
2021-12-03 14:14:15,713 iteration 776 : loss : 0.088920, loss_ce: 0.029916
2021-12-03 14:14:17,425 iteration 777 : loss : 0.137684, loss_ce: 0.077003
2021-12-03 14:14:18,885 iteration 778 : loss : 0.094939, loss_ce: 0.028689
2021-12-03 14:14:20,485 iteration 779 : loss : 0.088771, loss_ce: 0.043037
2021-12-03 14:14:22,065 iteration 780 : loss : 0.079019, loss_ce: 0.028982
2021-12-03 14:14:23,567 iteration 781 : loss : 0.078541, loss_ce: 0.039233
2021-12-03 14:14:25,008 iteration 782 : loss : 0.072385, loss_ce: 0.037829
 31%|█████████▊                      | 46/150 [21:44<49:42, 28.68s/it]2021-12-03 14:14:26,578 iteration 783 : loss : 0.075291, loss_ce: 0.035532
2021-12-03 14:14:28,065 iteration 784 : loss : 0.093563, loss_ce: 0.033357
2021-12-03 14:14:29,588 iteration 785 : loss : 0.081767, loss_ce: 0.038520
2021-12-03 14:14:31,091 iteration 786 : loss : 0.093926, loss_ce: 0.033053
2021-12-03 14:14:32,604 iteration 787 : loss : 0.072828, loss_ce: 0.028017
2021-12-03 14:14:34,182 iteration 788 : loss : 0.076460, loss_ce: 0.033247
2021-12-03 14:14:35,619 iteration 789 : loss : 0.077757, loss_ce: 0.024835
2021-12-03 14:14:37,186 iteration 790 : loss : 0.075235, loss_ce: 0.025631
2021-12-03 14:14:38,702 iteration 791 : loss : 0.050981, loss_ce: 0.022174
2021-12-03 14:14:40,165 iteration 792 : loss : 0.068121, loss_ce: 0.032206
2021-12-03 14:14:41,749 iteration 793 : loss : 0.104678, loss_ce: 0.053888
2021-12-03 14:14:43,186 iteration 794 : loss : 0.062265, loss_ce: 0.025627
2021-12-03 14:14:44,647 iteration 795 : loss : 0.073193, loss_ce: 0.029778
2021-12-03 14:14:46,105 iteration 796 : loss : 0.069503, loss_ce: 0.034166
2021-12-03 14:14:47,664 iteration 797 : loss : 0.085269, loss_ce: 0.032893
2021-12-03 14:14:49,176 iteration 798 : loss : 0.061187, loss_ce: 0.021963
2021-12-03 14:14:50,627 iteration 799 : loss : 0.051294, loss_ce: 0.025135
 31%|██████████                      | 47/150 [22:10<47:39, 27.76s/it]2021-12-03 14:14:52,311 iteration 800 : loss : 0.056900, loss_ce: 0.019042
2021-12-03 14:14:53,855 iteration 801 : loss : 0.060950, loss_ce: 0.025208
2021-12-03 14:14:55,376 iteration 802 : loss : 0.078495, loss_ce: 0.026901
2021-12-03 14:14:56,915 iteration 803 : loss : 0.078490, loss_ce: 0.041117
2021-12-03 14:14:58,515 iteration 804 : loss : 0.134076, loss_ce: 0.072510
2021-12-03 14:15:00,184 iteration 805 : loss : 0.055331, loss_ce: 0.018477
2021-12-03 14:15:01,690 iteration 806 : loss : 0.069520, loss_ce: 0.029191
2021-12-03 14:15:03,158 iteration 807 : loss : 0.058809, loss_ce: 0.021691
2021-12-03 14:15:04,736 iteration 808 : loss : 0.079759, loss_ce: 0.037252
2021-12-03 14:15:06,272 iteration 809 : loss : 0.089238, loss_ce: 0.029943
2021-12-03 14:15:07,761 iteration 810 : loss : 0.118286, loss_ce: 0.040562
2021-12-03 14:15:09,218 iteration 811 : loss : 0.089314, loss_ce: 0.045910
2021-12-03 14:15:10,704 iteration 812 : loss : 0.075099, loss_ce: 0.032135
2021-12-03 14:15:12,223 iteration 813 : loss : 0.073633, loss_ce: 0.024363
2021-12-03 14:15:13,848 iteration 814 : loss : 0.081168, loss_ce: 0.033243
2021-12-03 14:15:15,432 iteration 815 : loss : 0.083252, loss_ce: 0.034556
2021-12-03 14:15:16,973 iteration 816 : loss : 0.064470, loss_ce: 0.023471
 32%|██████████▏                     | 48/150 [22:36<46:28, 27.34s/it]2021-12-03 14:15:18,551 iteration 817 : loss : 0.084415, loss_ce: 0.042061
2021-12-03 14:15:20,017 iteration 818 : loss : 0.068147, loss_ce: 0.027606
2021-12-03 14:15:21,540 iteration 819 : loss : 0.066274, loss_ce: 0.025340
2021-12-03 14:15:22,987 iteration 820 : loss : 0.066688, loss_ce: 0.028820
2021-12-03 14:15:24,586 iteration 821 : loss : 0.059572, loss_ce: 0.020618
2021-12-03 14:15:26,136 iteration 822 : loss : 0.101443, loss_ce: 0.032805
2021-12-03 14:15:27,612 iteration 823 : loss : 0.042514, loss_ce: 0.016431
2021-12-03 14:15:29,076 iteration 824 : loss : 0.063509, loss_ce: 0.027723
2021-12-03 14:15:30,588 iteration 825 : loss : 0.079082, loss_ce: 0.031789
2021-12-03 14:15:32,085 iteration 826 : loss : 0.085155, loss_ce: 0.023300
2021-12-03 14:15:33,592 iteration 827 : loss : 0.091423, loss_ce: 0.035255
2021-12-03 14:15:35,105 iteration 828 : loss : 0.057365, loss_ce: 0.020359
2021-12-03 14:15:36,635 iteration 829 : loss : 0.081427, loss_ce: 0.028483
2021-12-03 14:15:38,203 iteration 830 : loss : 0.057390, loss_ce: 0.021955
2021-12-03 14:15:39,714 iteration 831 : loss : 0.083297, loss_ce: 0.034549
2021-12-03 14:15:41,205 iteration 832 : loss : 0.047970, loss_ce: 0.018074
2021-12-03 14:15:42,771 iteration 833 : loss : 0.081915, loss_ce: 0.040040
 33%|██████████▍                     | 49/150 [23:02<45:14, 26.87s/it]2021-12-03 14:15:44,348 iteration 834 : loss : 0.064750, loss_ce: 0.027249
2021-12-03 14:15:45,773 iteration 835 : loss : 0.068497, loss_ce: 0.020849
2021-12-03 14:15:47,301 iteration 836 : loss : 0.071030, loss_ce: 0.033894
2021-12-03 14:15:48,760 iteration 837 : loss : 0.054898, loss_ce: 0.030256
2021-12-03 14:15:50,208 iteration 838 : loss : 0.058699, loss_ce: 0.022783
2021-12-03 14:15:51,739 iteration 839 : loss : 0.062091, loss_ce: 0.027601
2021-12-03 14:15:53,259 iteration 840 : loss : 0.074546, loss_ce: 0.024369
2021-12-03 14:15:54,729 iteration 841 : loss : 0.072384, loss_ce: 0.030871
2021-12-03 14:15:56,226 iteration 842 : loss : 0.073552, loss_ce: 0.030758
2021-12-03 14:15:57,832 iteration 843 : loss : 0.068125, loss_ce: 0.025649
2021-12-03 14:15:59,338 iteration 844 : loss : 0.067099, loss_ce: 0.024207
2021-12-03 14:16:00,882 iteration 845 : loss : 0.073470, loss_ce: 0.026894
2021-12-03 14:16:02,526 iteration 846 : loss : 0.058311, loss_ce: 0.026190
2021-12-03 14:16:04,055 iteration 847 : loss : 0.068615, loss_ce: 0.028283
2021-12-03 14:16:05,490 iteration 848 : loss : 0.062170, loss_ce: 0.025454
2021-12-03 14:16:07,016 iteration 849 : loss : 0.056535, loss_ce: 0.021183
2021-12-03 14:16:07,017 Training Data Eval:
2021-12-03 14:16:14,563   Average segmentation loss on training set: 0.0553
2021-12-03 14:16:14,563 Validation Data Eval:
2021-12-03 14:16:17,162   Average segmentation loss on validation set: 0.1537
2021-12-03 14:16:18,720 iteration 850 : loss : 0.080973, loss_ce: 0.026962
2021-12-03 14:16:20,957 save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/UNET_RUNMC/1channelepoch_49.pth
 33%|██████████▋                     | 50/150 [23:40<50:24, 30.25s/it]2021-12-03 14:16:22,528 iteration 851 : loss : 0.053001, loss_ce: 0.019983
2021-12-03 14:16:24,023 iteration 852 : loss : 0.049902, loss_ce: 0.019784
2021-12-03 14:16:25,627 iteration 853 : loss : 0.073528, loss_ce: 0.029937
2021-12-03 14:16:27,168 iteration 854 : loss : 0.070453, loss_ce: 0.019450
2021-12-03 14:16:28,722 iteration 855 : loss : 0.062740, loss_ce: 0.029148
2021-12-03 14:16:30,280 iteration 856 : loss : 0.054454, loss_ce: 0.019970
2021-12-03 14:16:31,784 iteration 857 : loss : 0.059084, loss_ce: 0.025095
2021-12-03 14:16:33,212 iteration 858 : loss : 0.059378, loss_ce: 0.027247
2021-12-03 14:16:34,712 iteration 859 : loss : 0.057649, loss_ce: 0.022485
2021-12-03 14:16:36,169 iteration 860 : loss : 0.064705, loss_ce: 0.020293
2021-12-03 14:16:37,745 iteration 861 : loss : 0.056477, loss_ce: 0.023475
2021-12-03 14:16:39,187 iteration 862 : loss : 0.067165, loss_ce: 0.021793
2021-12-03 14:16:40,779 iteration 863 : loss : 0.063554, loss_ce: 0.024600
2021-12-03 14:16:42,334 iteration 864 : loss : 0.063943, loss_ce: 0.029728
2021-12-03 14:16:43,775 iteration 865 : loss : 0.044681, loss_ce: 0.018827
2021-12-03 14:16:45,350 iteration 866 : loss : 0.075306, loss_ce: 0.037364
2021-12-03 14:16:46,803 iteration 867 : loss : 0.036264, loss_ce: 0.014379
 34%|██████████▉                     | 51/150 [24:06<47:45, 28.95s/it]2021-12-03 14:16:48,409 iteration 868 : loss : 0.103108, loss_ce: 0.033288
2021-12-03 14:16:49,923 iteration 869 : loss : 0.056087, loss_ce: 0.022430
2021-12-03 14:16:51,346 iteration 870 : loss : 0.046788, loss_ce: 0.018653
2021-12-03 14:16:52,805 iteration 871 : loss : 0.056607, loss_ce: 0.022884
2021-12-03 14:16:54,304 iteration 872 : loss : 0.062013, loss_ce: 0.033961
2021-12-03 14:16:55,886 iteration 873 : loss : 0.062054, loss_ce: 0.021522
2021-12-03 14:16:57,325 iteration 874 : loss : 0.044069, loss_ce: 0.019276
2021-12-03 14:16:58,978 iteration 875 : loss : 0.099605, loss_ce: 0.042427
2021-12-03 14:17:00,496 iteration 876 : loss : 0.048360, loss_ce: 0.023580
2021-12-03 14:17:01,917 iteration 877 : loss : 0.062632, loss_ce: 0.026487
2021-12-03 14:17:03,477 iteration 878 : loss : 0.057170, loss_ce: 0.025341
2021-12-03 14:17:04,961 iteration 879 : loss : 0.055428, loss_ce: 0.023553
2021-12-03 14:17:06,499 iteration 880 : loss : 0.048200, loss_ce: 0.017779
2021-12-03 14:17:07,979 iteration 881 : loss : 0.067035, loss_ce: 0.029326
2021-12-03 14:17:09,534 iteration 882 : loss : 0.069350, loss_ce: 0.026578
2021-12-03 14:17:11,042 iteration 883 : loss : 0.079963, loss_ce: 0.035322
2021-12-03 14:17:12,646 iteration 884 : loss : 0.091720, loss_ce: 0.045578
 35%|███████████                     | 52/150 [24:32<45:45, 28.02s/it]2021-12-03 14:17:14,253 iteration 885 : loss : 0.055088, loss_ce: 0.023144
2021-12-03 14:17:15,810 iteration 886 : loss : 0.066456, loss_ce: 0.026254
2021-12-03 14:17:17,368 iteration 887 : loss : 0.084772, loss_ce: 0.037577
2021-12-03 14:17:18,892 iteration 888 : loss : 0.053620, loss_ce: 0.021472
2021-12-03 14:17:20,473 iteration 889 : loss : 0.070892, loss_ce: 0.025508
2021-12-03 14:17:22,105 iteration 890 : loss : 0.079181, loss_ce: 0.028703
2021-12-03 14:17:23,637 iteration 891 : loss : 0.047705, loss_ce: 0.015729
2021-12-03 14:17:25,158 iteration 892 : loss : 0.066203, loss_ce: 0.030812
2021-12-03 14:17:26,662 iteration 893 : loss : 0.048838, loss_ce: 0.016961
2021-12-03 14:17:28,287 iteration 894 : loss : 0.066304, loss_ce: 0.023391
2021-12-03 14:17:29,782 iteration 895 : loss : 0.072756, loss_ce: 0.021899
2021-12-03 14:17:31,359 iteration 896 : loss : 0.085566, loss_ce: 0.035503
2021-12-03 14:17:32,976 iteration 897 : loss : 0.074067, loss_ce: 0.035384
2021-12-03 14:17:34,479 iteration 898 : loss : 0.083475, loss_ce: 0.038329
2021-12-03 14:17:36,006 iteration 899 : loss : 0.061940, loss_ce: 0.026374
2021-12-03 14:17:37,470 iteration 900 : loss : 0.047234, loss_ce: 0.020695
2021-12-03 14:17:38,959 iteration 901 : loss : 0.072945, loss_ce: 0.023952
 35%|███████████▎                    | 53/150 [24:58<44:27, 27.50s/it]2021-12-03 14:17:40,562 iteration 902 : loss : 0.064898, loss_ce: 0.027523
2021-12-03 14:17:42,175 iteration 903 : loss : 0.062966, loss_ce: 0.021985
2021-12-03 14:17:43,731 iteration 904 : loss : 0.077217, loss_ce: 0.027793
2021-12-03 14:17:45,269 iteration 905 : loss : 0.072262, loss_ce: 0.028872
2021-12-03 14:17:46,785 iteration 906 : loss : 0.051591, loss_ce: 0.022657
2021-12-03 14:17:48,362 iteration 907 : loss : 0.073286, loss_ce: 0.024533
2021-12-03 14:17:49,793 iteration 908 : loss : 0.052328, loss_ce: 0.021109
2021-12-03 14:17:51,342 iteration 909 : loss : 0.068827, loss_ce: 0.029049
2021-12-03 14:17:52,793 iteration 910 : loss : 0.089083, loss_ce: 0.031654
2021-12-03 14:17:54,310 iteration 911 : loss : 0.056175, loss_ce: 0.022273
2021-12-03 14:17:55,812 iteration 912 : loss : 0.060990, loss_ce: 0.022910
2021-12-03 14:17:57,303 iteration 913 : loss : 0.065660, loss_ce: 0.023814
2021-12-03 14:17:58,808 iteration 914 : loss : 0.079745, loss_ce: 0.036296
2021-12-03 14:18:00,284 iteration 915 : loss : 0.123774, loss_ce: 0.043210
2021-12-03 14:18:01,774 iteration 916 : loss : 0.054603, loss_ce: 0.019408
2021-12-03 14:18:03,316 iteration 917 : loss : 0.082492, loss_ce: 0.035997
2021-12-03 14:18:04,892 iteration 918 : loss : 0.069298, loss_ce: 0.026471
 36%|███████████▌                    | 54/150 [25:24<43:14, 27.03s/it]2021-12-03 14:18:06,509 iteration 919 : loss : 0.052790, loss_ce: 0.022404
2021-12-03 14:18:08,068 iteration 920 : loss : 0.063876, loss_ce: 0.027072
2021-12-03 14:18:09,633 iteration 921 : loss : 0.074573, loss_ce: 0.031567
2021-12-03 14:18:11,237 iteration 922 : loss : 0.071838, loss_ce: 0.032540
2021-12-03 14:18:12,735 iteration 923 : loss : 0.065450, loss_ce: 0.032012
2021-12-03 14:18:14,318 iteration 924 : loss : 0.093599, loss_ce: 0.028869
2021-12-03 14:18:15,806 iteration 925 : loss : 0.041374, loss_ce: 0.015121
2021-12-03 14:18:17,378 iteration 926 : loss : 0.053990, loss_ce: 0.023547
2021-12-03 14:18:18,826 iteration 927 : loss : 0.073126, loss_ce: 0.025246
2021-12-03 14:18:20,333 iteration 928 : loss : 0.056499, loss_ce: 0.027402
2021-12-03 14:18:21,899 iteration 929 : loss : 0.068526, loss_ce: 0.026531
2021-12-03 14:18:23,439 iteration 930 : loss : 0.053718, loss_ce: 0.021218
2021-12-03 14:18:24,978 iteration 931 : loss : 0.103009, loss_ce: 0.026975
2021-12-03 14:18:26,500 iteration 932 : loss : 0.056712, loss_ce: 0.019272
2021-12-03 14:18:27,989 iteration 933 : loss : 0.097984, loss_ce: 0.037320
2021-12-03 14:18:29,507 iteration 934 : loss : 0.053277, loss_ce: 0.022224
2021-12-03 14:18:29,507 Training Data Eval:
2021-12-03 14:18:37,061   Average segmentation loss on training set: 0.0661
2021-12-03 14:18:37,062 Validation Data Eval:
2021-12-03 14:18:39,666   Average segmentation loss on validation set: 0.1695
2021-12-03 14:18:41,275 iteration 935 : loss : 0.089035, loss_ce: 0.027216
 37%|███████████▋                    | 55/150 [26:00<47:14, 29.84s/it]2021-12-03 14:18:42,824 iteration 936 : loss : 0.056531, loss_ce: 0.019612
2021-12-03 14:18:44,362 iteration 937 : loss : 0.060768, loss_ce: 0.020419
2021-12-03 14:18:45,930 iteration 938 : loss : 0.065802, loss_ce: 0.022759
2021-12-03 14:18:47,408 iteration 939 : loss : 0.071134, loss_ce: 0.021942
2021-12-03 14:18:48,943 iteration 940 : loss : 0.093085, loss_ce: 0.037744
2021-12-03 14:18:50,567 iteration 941 : loss : 0.065631, loss_ce: 0.024720
2021-12-03 14:18:52,048 iteration 942 : loss : 0.045489, loss_ce: 0.017333
2021-12-03 14:18:53,546 iteration 943 : loss : 0.070071, loss_ce: 0.032998
2021-12-03 14:18:55,028 iteration 944 : loss : 0.046283, loss_ce: 0.018318
2021-12-03 14:18:56,514 iteration 945 : loss : 0.065588, loss_ce: 0.023651
2021-12-03 14:18:57,999 iteration 946 : loss : 0.061680, loss_ce: 0.026646
2021-12-03 14:18:59,475 iteration 947 : loss : 0.058047, loss_ce: 0.023038
2021-12-03 14:19:00,941 iteration 948 : loss : 0.083496, loss_ce: 0.028576
2021-12-03 14:19:02,477 iteration 949 : loss : 0.051176, loss_ce: 0.020269
2021-12-03 14:19:03,967 iteration 950 : loss : 0.060892, loss_ce: 0.027736
2021-12-03 14:19:05,520 iteration 951 : loss : 0.062462, loss_ce: 0.032038
2021-12-03 14:19:06,987 iteration 952 : loss : 0.063950, loss_ce: 0.027154
 37%|███████████▉                    | 56/150 [26:26<44:48, 28.60s/it]2021-12-03 14:19:08,585 iteration 953 : loss : 0.066441, loss_ce: 0.024024
2021-12-03 14:19:10,148 iteration 954 : loss : 0.058454, loss_ce: 0.025326
2021-12-03 14:19:11,594 iteration 955 : loss : 0.039625, loss_ce: 0.017588
2021-12-03 14:19:13,142 iteration 956 : loss : 0.060671, loss_ce: 0.026568
2021-12-03 14:19:14,674 iteration 957 : loss : 0.060039, loss_ce: 0.020946
2021-12-03 14:19:16,218 iteration 958 : loss : 0.079463, loss_ce: 0.027991
2021-12-03 14:19:17,835 iteration 959 : loss : 0.072761, loss_ce: 0.036036
2021-12-03 14:19:19,504 iteration 960 : loss : 0.062359, loss_ce: 0.029584
2021-12-03 14:19:20,993 iteration 961 : loss : 0.076190, loss_ce: 0.025496
2021-12-03 14:19:22,449 iteration 962 : loss : 0.055763, loss_ce: 0.016438
2021-12-03 14:19:24,038 iteration 963 : loss : 0.057079, loss_ce: 0.022816
2021-12-03 14:19:25,596 iteration 964 : loss : 0.061239, loss_ce: 0.032435
2021-12-03 14:19:27,127 iteration 965 : loss : 0.058349, loss_ce: 0.025339
2021-12-03 14:19:28,694 iteration 966 : loss : 0.058931, loss_ce: 0.024118
2021-12-03 14:19:30,293 iteration 967 : loss : 0.043787, loss_ce: 0.019409
2021-12-03 14:19:31,815 iteration 968 : loss : 0.098035, loss_ce: 0.030892
2021-12-03 14:19:33,416 iteration 969 : loss : 0.071106, loss_ce: 0.028831
 38%|████████████▏                   | 57/150 [26:52<43:19, 27.96s/it]2021-12-03 14:19:35,041 iteration 970 : loss : 0.061085, loss_ce: 0.030234
2021-12-03 14:19:36,646 iteration 971 : loss : 0.077336, loss_ce: 0.026222
2021-12-03 14:19:38,149 iteration 972 : loss : 0.049526, loss_ce: 0.024174
2021-12-03 14:19:39,748 iteration 973 : loss : 0.066857, loss_ce: 0.021424
2021-12-03 14:19:41,252 iteration 974 : loss : 0.067021, loss_ce: 0.025557
2021-12-03 14:19:42,889 iteration 975 : loss : 0.061383, loss_ce: 0.021744
2021-12-03 14:19:44,434 iteration 976 : loss : 0.046148, loss_ce: 0.019860
2021-12-03 14:19:45,994 iteration 977 : loss : 0.043593, loss_ce: 0.015685
2021-12-03 14:19:47,589 iteration 978 : loss : 0.055474, loss_ce: 0.021350
2021-12-03 14:19:49,138 iteration 979 : loss : 0.061456, loss_ce: 0.030572
2021-12-03 14:19:50,670 iteration 980 : loss : 0.052316, loss_ce: 0.018349
2021-12-03 14:19:52,371 iteration 981 : loss : 0.063142, loss_ce: 0.031883
2021-12-03 14:19:53,893 iteration 982 : loss : 0.060220, loss_ce: 0.033190
2021-12-03 14:19:55,551 iteration 983 : loss : 0.077418, loss_ce: 0.025434
2021-12-03 14:19:57,027 iteration 984 : loss : 0.051585, loss_ce: 0.023698
2021-12-03 14:19:58,581 iteration 985 : loss : 0.047316, loss_ce: 0.015304
2021-12-03 14:20:00,211 iteration 986 : loss : 0.067998, loss_ce: 0.025925
 39%|████████████▎                   | 58/150 [27:19<42:19, 27.61s/it]2021-12-03 14:20:01,933 iteration 987 : loss : 0.044620, loss_ce: 0.020736
2021-12-03 14:20:03,509 iteration 988 : loss : 0.063413, loss_ce: 0.029256
2021-12-03 14:20:05,046 iteration 989 : loss : 0.071690, loss_ce: 0.028635
2021-12-03 14:20:06,592 iteration 990 : loss : 0.054813, loss_ce: 0.023864
2021-12-03 14:20:08,117 iteration 991 : loss : 0.049242, loss_ce: 0.020225
2021-12-03 14:20:09,748 iteration 992 : loss : 0.044793, loss_ce: 0.022124
2021-12-03 14:20:11,311 iteration 993 : loss : 0.047079, loss_ce: 0.019464
2021-12-03 14:20:12,975 iteration 994 : loss : 0.062195, loss_ce: 0.028181
2021-12-03 14:20:14,529 iteration 995 : loss : 0.077398, loss_ce: 0.026430
2021-12-03 14:20:16,141 iteration 996 : loss : 0.039581, loss_ce: 0.017468
2021-12-03 14:20:17,737 iteration 997 : loss : 0.057065, loss_ce: 0.021233
2021-12-03 14:20:19,224 iteration 998 : loss : 0.070141, loss_ce: 0.021134
2021-12-03 14:20:20,810 iteration 999 : loss : 0.053548, loss_ce: 0.021016
2021-12-03 14:20:22,303 iteration 1000 : loss : 0.049912, loss_ce: 0.017798
2021-12-03 14:20:23,811 iteration 1001 : loss : 0.087922, loss_ce: 0.019809
2021-12-03 14:20:25,446 iteration 1002 : loss : 0.066645, loss_ce: 0.027035
2021-12-03 14:20:27,071 iteration 1003 : loss : 0.073450, loss_ce: 0.029698
 39%|████████████▌                   | 59/150 [27:46<41:31, 27.38s/it]2021-12-03 14:20:28,675 iteration 1004 : loss : 0.116188, loss_ce: 0.055815
2021-12-03 14:20:30,202 iteration 1005 : loss : 0.061198, loss_ce: 0.026148
2021-12-03 14:20:31,826 iteration 1006 : loss : 0.065759, loss_ce: 0.027621
2021-12-03 14:20:33,318 iteration 1007 : loss : 0.060805, loss_ce: 0.031868
2021-12-03 14:20:34,814 iteration 1008 : loss : 0.115704, loss_ce: 0.042334
2021-12-03 14:20:36,352 iteration 1009 : loss : 0.071137, loss_ce: 0.024514
2021-12-03 14:20:37,883 iteration 1010 : loss : 0.052097, loss_ce: 0.019582
2021-12-03 14:20:39,528 iteration 1011 : loss : 0.069344, loss_ce: 0.029451
2021-12-03 14:20:41,093 iteration 1012 : loss : 0.040784, loss_ce: 0.015526
2021-12-03 14:20:42,591 iteration 1013 : loss : 0.047605, loss_ce: 0.016153
2021-12-03 14:20:44,170 iteration 1014 : loss : 0.071191, loss_ce: 0.030843
2021-12-03 14:20:45,651 iteration 1015 : loss : 0.049543, loss_ce: 0.018747
2021-12-03 14:20:47,220 iteration 1016 : loss : 0.051858, loss_ce: 0.021533
2021-12-03 14:20:48,668 iteration 1017 : loss : 0.035987, loss_ce: 0.012980
2021-12-03 14:20:50,113 iteration 1018 : loss : 0.065091, loss_ce: 0.023757
2021-12-03 14:20:51,658 iteration 1019 : loss : 0.059762, loss_ce: 0.022614
2021-12-03 14:20:51,658 Training Data Eval:
2021-12-03 14:20:59,293   Average segmentation loss on training set: 0.0388
2021-12-03 14:20:59,293 Validation Data Eval:
2021-12-03 14:21:01,917   Average segmentation loss on validation set: 0.1029
2021-12-03 14:21:03,997 Found new lowest validation loss at iteration 1019! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/UNET_RUNMC/1channel_best_val_loss.pth
2021-12-03 14:21:05,506 iteration 1020 : loss : 0.042472, loss_ce: 0.017146
 40%|████████████▊                   | 60/150 [28:24<46:02, 30.70s/it]2021-12-03 14:21:07,213 iteration 1021 : loss : 0.096183, loss_ce: 0.029536
2021-12-03 14:21:08,755 iteration 1022 : loss : 0.052459, loss_ce: 0.022865
2021-12-03 14:21:10,285 iteration 1023 : loss : 0.119475, loss_ce: 0.033807
2021-12-03 14:21:11,872 iteration 1024 : loss : 0.042764, loss_ce: 0.016724
2021-12-03 14:21:13,454 iteration 1025 : loss : 0.038242, loss_ce: 0.016109
2021-12-03 14:21:14,890 iteration 1026 : loss : 0.046102, loss_ce: 0.017037
2021-12-03 14:21:16,466 iteration 1027 : loss : 0.056672, loss_ce: 0.017866
2021-12-03 14:21:18,028 iteration 1028 : loss : 0.071454, loss_ce: 0.028052
2021-12-03 14:21:19,543 iteration 1029 : loss : 0.050241, loss_ce: 0.023715
2021-12-03 14:21:21,065 iteration 1030 : loss : 0.056021, loss_ce: 0.018901
2021-12-03 14:21:22,651 iteration 1031 : loss : 0.069535, loss_ce: 0.027862
2021-12-03 14:21:24,204 iteration 1032 : loss : 0.072256, loss_ce: 0.032591
2021-12-03 14:21:25,712 iteration 1033 : loss : 0.054746, loss_ce: 0.020532
2021-12-03 14:21:27,311 iteration 1034 : loss : 0.070283, loss_ce: 0.028384
2021-12-03 14:21:28,861 iteration 1035 : loss : 0.052072, loss_ce: 0.021850
2021-12-03 14:21:30,417 iteration 1036 : loss : 0.080450, loss_ce: 0.038733
2021-12-03 14:21:31,911 iteration 1037 : loss : 0.050910, loss_ce: 0.017045
 41%|█████████████                   | 61/150 [28:51<43:37, 29.40s/it]2021-12-03 14:21:33,518 iteration 1038 : loss : 0.042035, loss_ce: 0.016688
2021-12-03 14:21:35,050 iteration 1039 : loss : 0.047614, loss_ce: 0.023605
2021-12-03 14:21:36,627 iteration 1040 : loss : 0.069432, loss_ce: 0.032503
2021-12-03 14:21:38,178 iteration 1041 : loss : 0.058705, loss_ce: 0.027319
2021-12-03 14:21:39,743 iteration 1042 : loss : 0.057636, loss_ce: 0.023141
2021-12-03 14:21:41,282 iteration 1043 : loss : 0.070186, loss_ce: 0.024369
2021-12-03 14:21:42,868 iteration 1044 : loss : 0.050274, loss_ce: 0.018183
2021-12-03 14:21:44,303 iteration 1045 : loss : 0.045191, loss_ce: 0.021379
2021-12-03 14:21:45,779 iteration 1046 : loss : 0.092779, loss_ce: 0.023049
2021-12-03 14:21:47,352 iteration 1047 : loss : 0.070294, loss_ce: 0.024609
2021-12-03 14:21:48,882 iteration 1048 : loss : 0.066886, loss_ce: 0.022777
2021-12-03 14:21:50,416 iteration 1049 : loss : 0.055239, loss_ce: 0.019005
2021-12-03 14:21:52,004 iteration 1050 : loss : 0.072885, loss_ce: 0.021796
2021-12-03 14:21:53,533 iteration 1051 : loss : 0.048896, loss_ce: 0.020698
2021-12-03 14:21:55,065 iteration 1052 : loss : 0.049831, loss_ce: 0.019690
2021-12-03 14:21:56,518 iteration 1053 : loss : 0.062595, loss_ce: 0.019261
2021-12-03 14:21:58,120 iteration 1054 : loss : 0.063025, loss_ce: 0.029243
 41%|█████████████▏                  | 62/150 [29:17<41:43, 28.45s/it]2021-12-03 14:21:59,706 iteration 1055 : loss : 0.037244, loss_ce: 0.012963
2021-12-03 14:22:01,209 iteration 1056 : loss : 0.054468, loss_ce: 0.026439
2021-12-03 14:22:02,715 iteration 1057 : loss : 0.081329, loss_ce: 0.042564
2021-12-03 14:22:04,231 iteration 1058 : loss : 0.058921, loss_ce: 0.027138
2021-12-03 14:22:05,676 iteration 1059 : loss : 0.055459, loss_ce: 0.019104
2021-12-03 14:22:07,181 iteration 1060 : loss : 0.059633, loss_ce: 0.022791
2021-12-03 14:22:08,725 iteration 1061 : loss : 0.045440, loss_ce: 0.016186
2021-12-03 14:22:10,259 iteration 1062 : loss : 0.063739, loss_ce: 0.026666
2021-12-03 14:22:11,861 iteration 1063 : loss : 0.101611, loss_ce: 0.035441
2021-12-03 14:22:13,384 iteration 1064 : loss : 0.059119, loss_ce: 0.020244
2021-12-03 14:22:14,858 iteration 1065 : loss : 0.045653, loss_ce: 0.017992
2021-12-03 14:22:16,406 iteration 1066 : loss : 0.048877, loss_ce: 0.022665
2021-12-03 14:22:17,918 iteration 1067 : loss : 0.125760, loss_ce: 0.033571
2021-12-03 14:22:19,490 iteration 1068 : loss : 0.057685, loss_ce: 0.027255
2021-12-03 14:22:21,035 iteration 1069 : loss : 0.111162, loss_ce: 0.060902
2021-12-03 14:22:22,550 iteration 1070 : loss : 0.051505, loss_ce: 0.022011
2021-12-03 14:22:24,054 iteration 1071 : loss : 0.047458, loss_ce: 0.021458
 42%|█████████████▍                  | 63/150 [29:43<40:09, 27.69s/it]2021-12-03 14:22:25,737 iteration 1072 : loss : 0.065386, loss_ce: 0.022054
2021-12-03 14:22:27,243 iteration 1073 : loss : 0.102522, loss_ce: 0.028132
2021-12-03 14:22:28,750 iteration 1074 : loss : 0.068601, loss_ce: 0.035568
2021-12-03 14:22:30,294 iteration 1075 : loss : 0.056929, loss_ce: 0.021376
2021-12-03 14:22:31,759 iteration 1076 : loss : 0.053073, loss_ce: 0.018332
2021-12-03 14:22:33,263 iteration 1077 : loss : 0.044145, loss_ce: 0.016617
2021-12-03 14:22:34,844 iteration 1078 : loss : 0.062149, loss_ce: 0.035422
2021-12-03 14:22:36,322 iteration 1079 : loss : 0.049837, loss_ce: 0.017944
2021-12-03 14:22:37,791 iteration 1080 : loss : 0.040562, loss_ce: 0.017338
2021-12-03 14:22:39,329 iteration 1081 : loss : 0.059428, loss_ce: 0.019283
2021-12-03 14:22:40,862 iteration 1082 : loss : 0.057395, loss_ce: 0.027200
2021-12-03 14:22:42,429 iteration 1083 : loss : 0.058389, loss_ce: 0.023914
2021-12-03 14:22:43,931 iteration 1084 : loss : 0.061760, loss_ce: 0.030200
2021-12-03 14:22:45,524 iteration 1085 : loss : 0.064888, loss_ce: 0.026661
2021-12-03 14:22:47,028 iteration 1086 : loss : 0.060788, loss_ce: 0.023739
2021-12-03 14:22:48,547 iteration 1087 : loss : 0.048728, loss_ce: 0.020863
2021-12-03 14:22:50,159 iteration 1088 : loss : 0.062506, loss_ce: 0.026122
 43%|█████████████▋                  | 64/150 [30:09<39:00, 27.22s/it]2021-12-03 14:22:51,716 iteration 1089 : loss : 0.074171, loss_ce: 0.026787
2021-12-03 14:22:53,234 iteration 1090 : loss : 0.047883, loss_ce: 0.021729
2021-12-03 14:22:54,754 iteration 1091 : loss : 0.046334, loss_ce: 0.021128
2021-12-03 14:22:56,277 iteration 1092 : loss : 0.048663, loss_ce: 0.020284
2021-12-03 14:22:57,816 iteration 1093 : loss : 0.073910, loss_ce: 0.023297
2021-12-03 14:22:59,400 iteration 1094 : loss : 0.052061, loss_ce: 0.021787
2021-12-03 14:23:00,875 iteration 1095 : loss : 0.047503, loss_ce: 0.020273
2021-12-03 14:23:02,496 iteration 1096 : loss : 0.043180, loss_ce: 0.018619
2021-12-03 14:23:04,037 iteration 1097 : loss : 0.062833, loss_ce: 0.028386
2021-12-03 14:23:05,522 iteration 1098 : loss : 0.045575, loss_ce: 0.020381
2021-12-03 14:23:07,068 iteration 1099 : loss : 0.048402, loss_ce: 0.018013
2021-12-03 14:23:08,670 iteration 1100 : loss : 0.063362, loss_ce: 0.022164
2021-12-03 14:23:10,191 iteration 1101 : loss : 0.045398, loss_ce: 0.018811
2021-12-03 14:23:11,790 iteration 1102 : loss : 0.080145, loss_ce: 0.026877
2021-12-03 14:23:13,294 iteration 1103 : loss : 0.058223, loss_ce: 0.021517
2021-12-03 14:23:14,792 iteration 1104 : loss : 0.055663, loss_ce: 0.023168
2021-12-03 14:23:14,793 Training Data Eval:
2021-12-03 14:23:22,343   Average segmentation loss on training set: 0.0423
2021-12-03 14:23:22,343 Validation Data Eval:
2021-12-03 14:23:24,948   Average segmentation loss on validation set: 0.1300
2021-12-03 14:23:26,517 iteration 1105 : loss : 0.050737, loss_ce: 0.015676
 43%|█████████████▊                  | 65/150 [30:45<42:26, 29.96s/it]2021-12-03 14:23:28,032 iteration 1106 : loss : 0.051993, loss_ce: 0.018028
2021-12-03 14:23:29,529 iteration 1107 : loss : 0.059828, loss_ce: 0.029852
2021-12-03 14:23:31,056 iteration 1108 : loss : 0.067940, loss_ce: 0.015273
2021-12-03 14:23:32,523 iteration 1109 : loss : 0.049846, loss_ce: 0.020998
2021-12-03 14:23:34,049 iteration 1110 : loss : 0.060861, loss_ce: 0.029078
2021-12-03 14:23:35,553 iteration 1111 : loss : 0.046052, loss_ce: 0.019212
2021-12-03 14:23:37,056 iteration 1112 : loss : 0.043766, loss_ce: 0.016963
2021-12-03 14:23:38,541 iteration 1113 : loss : 0.045593, loss_ce: 0.015913
2021-12-03 14:23:40,113 iteration 1114 : loss : 0.064040, loss_ce: 0.032030
2021-12-03 14:23:41,757 iteration 1115 : loss : 0.059002, loss_ce: 0.030654
2021-12-03 14:23:43,324 iteration 1116 : loss : 0.061350, loss_ce: 0.020027
2021-12-03 14:23:44,963 iteration 1117 : loss : 0.061973, loss_ce: 0.022665
2021-12-03 14:23:46,538 iteration 1118 : loss : 0.084562, loss_ce: 0.023711
2021-12-03 14:23:48,035 iteration 1119 : loss : 0.044216, loss_ce: 0.019479
2021-12-03 14:23:49,522 iteration 1120 : loss : 0.047581, loss_ce: 0.017160
2021-12-03 14:23:51,073 iteration 1121 : loss : 0.065029, loss_ce: 0.021806
2021-12-03 14:23:52,594 iteration 1122 : loss : 0.055376, loss_ce: 0.026864
 44%|██████████████                  | 66/150 [31:12<40:18, 28.79s/it]2021-12-03 14:23:54,153 iteration 1123 : loss : 0.067510, loss_ce: 0.022364
2021-12-03 14:23:55,705 iteration 1124 : loss : 0.053224, loss_ce: 0.025309
2021-12-03 14:23:57,234 iteration 1125 : loss : 0.038725, loss_ce: 0.012368
2021-12-03 14:23:58,736 iteration 1126 : loss : 0.048818, loss_ce: 0.019195
2021-12-03 14:24:00,230 iteration 1127 : loss : 0.062789, loss_ce: 0.023787
2021-12-03 14:24:01,805 iteration 1128 : loss : 0.066022, loss_ce: 0.024969
2021-12-03 14:24:03,390 iteration 1129 : loss : 0.068599, loss_ce: 0.021092
2021-12-03 14:24:04,895 iteration 1130 : loss : 0.046156, loss_ce: 0.020698
2021-12-03 14:24:06,403 iteration 1131 : loss : 0.052494, loss_ce: 0.022183
2021-12-03 14:24:07,960 iteration 1132 : loss : 0.048047, loss_ce: 0.018446
2021-12-03 14:24:09,417 iteration 1133 : loss : 0.036727, loss_ce: 0.016294
2021-12-03 14:24:10,936 iteration 1134 : loss : 0.064525, loss_ce: 0.022005
2021-12-03 14:24:12,421 iteration 1135 : loss : 0.053091, loss_ce: 0.022158
2021-12-03 14:24:13,931 iteration 1136 : loss : 0.037124, loss_ce: 0.014063
2021-12-03 14:24:15,424 iteration 1137 : loss : 0.066650, loss_ce: 0.026494
2021-12-03 14:24:16,979 iteration 1138 : loss : 0.048306, loss_ce: 0.020904
2021-12-03 14:24:18,515 iteration 1139 : loss : 0.057297, loss_ce: 0.019411
 45%|██████████████▎                 | 67/150 [31:37<38:38, 27.93s/it]2021-12-03 14:24:20,095 iteration 1140 : loss : 0.059747, loss_ce: 0.021670
2021-12-03 14:24:21,575 iteration 1141 : loss : 0.043442, loss_ce: 0.016485
2021-12-03 14:24:23,167 iteration 1142 : loss : 0.052388, loss_ce: 0.024849
2021-12-03 14:24:24,689 iteration 1143 : loss : 0.050893, loss_ce: 0.020551
2021-12-03 14:24:26,264 iteration 1144 : loss : 0.057574, loss_ce: 0.030588
2021-12-03 14:24:27,738 iteration 1145 : loss : 0.048726, loss_ce: 0.019116
2021-12-03 14:24:29,279 iteration 1146 : loss : 0.063599, loss_ce: 0.029251
2021-12-03 14:24:30,716 iteration 1147 : loss : 0.057005, loss_ce: 0.022580
2021-12-03 14:24:32,283 iteration 1148 : loss : 0.045913, loss_ce: 0.017144
2021-12-03 14:24:33,750 iteration 1149 : loss : 0.046243, loss_ce: 0.022480
2021-12-03 14:24:35,274 iteration 1150 : loss : 0.044878, loss_ce: 0.017677
2021-12-03 14:24:36,823 iteration 1151 : loss : 0.053533, loss_ce: 0.019452
2021-12-03 14:24:38,458 iteration 1152 : loss : 0.063388, loss_ce: 0.023593
2021-12-03 14:24:39,896 iteration 1153 : loss : 0.046571, loss_ce: 0.016280
2021-12-03 14:24:41,451 iteration 1154 : loss : 0.052640, loss_ce: 0.018313
2021-12-03 14:24:42,930 iteration 1155 : loss : 0.051117, loss_ce: 0.017319
2021-12-03 14:24:44,498 iteration 1156 : loss : 0.070004, loss_ce: 0.037479
 45%|██████████████▌                 | 68/150 [32:03<37:22, 27.35s/it]2021-12-03 14:24:46,056 iteration 1157 : loss : 0.068941, loss_ce: 0.019104
2021-12-03 14:24:47,593 iteration 1158 : loss : 0.054011, loss_ce: 0.019010
2021-12-03 14:24:49,185 iteration 1159 : loss : 0.054846, loss_ce: 0.018409
2021-12-03 14:24:50,822 iteration 1160 : loss : 0.066895, loss_ce: 0.030730
2021-12-03 14:24:52,404 iteration 1161 : loss : 0.044626, loss_ce: 0.021323
2021-12-03 14:24:53,960 iteration 1162 : loss : 0.055378, loss_ce: 0.019437
2021-12-03 14:24:55,459 iteration 1163 : loss : 0.052763, loss_ce: 0.024474
2021-12-03 14:24:56,970 iteration 1164 : loss : 0.062007, loss_ce: 0.023347
2021-12-03 14:24:58,491 iteration 1165 : loss : 0.040200, loss_ce: 0.018083
2021-12-03 14:25:00,085 iteration 1166 : loss : 0.037848, loss_ce: 0.013232
2021-12-03 14:25:01,582 iteration 1167 : loss : 0.041395, loss_ce: 0.019341
2021-12-03 14:25:03,085 iteration 1168 : loss : 0.055059, loss_ce: 0.022798
2021-12-03 14:25:04,593 iteration 1169 : loss : 0.045282, loss_ce: 0.019189
2021-12-03 14:25:06,083 iteration 1170 : loss : 0.055023, loss_ce: 0.022713
2021-12-03 14:25:07,617 iteration 1171 : loss : 0.048584, loss_ce: 0.016933
2021-12-03 14:25:09,143 iteration 1172 : loss : 0.041147, loss_ce: 0.017621
2021-12-03 14:25:10,696 iteration 1173 : loss : 0.055717, loss_ce: 0.019618
 46%|██████████████▋                 | 69/150 [32:30<36:27, 27.00s/it]2021-12-03 14:25:12,251 iteration 1174 : loss : 0.049865, loss_ce: 0.015465
2021-12-03 14:25:13,774 iteration 1175 : loss : 0.042126, loss_ce: 0.018218
2021-12-03 14:25:15,287 iteration 1176 : loss : 0.046765, loss_ce: 0.018834
2021-12-03 14:25:16,768 iteration 1177 : loss : 0.043917, loss_ce: 0.019218
2021-12-03 14:25:18,316 iteration 1178 : loss : 0.050539, loss_ce: 0.017368
2021-12-03 14:25:19,918 iteration 1179 : loss : 0.087025, loss_ce: 0.036669
2021-12-03 14:25:21,411 iteration 1180 : loss : 0.054037, loss_ce: 0.023925
2021-12-03 14:25:22,930 iteration 1181 : loss : 0.044571, loss_ce: 0.017832
2021-12-03 14:25:24,461 iteration 1182 : loss : 0.047240, loss_ce: 0.018047
2021-12-03 14:25:25,934 iteration 1183 : loss : 0.053896, loss_ce: 0.020258
2021-12-03 14:25:27,416 iteration 1184 : loss : 0.035441, loss_ce: 0.016232
2021-12-03 14:25:28,978 iteration 1185 : loss : 0.045246, loss_ce: 0.017314
2021-12-03 14:25:30,460 iteration 1186 : loss : 0.052103, loss_ce: 0.025597
2021-12-03 14:25:32,043 iteration 1187 : loss : 0.049959, loss_ce: 0.019408
2021-12-03 14:25:33,530 iteration 1188 : loss : 0.052883, loss_ce: 0.019252
2021-12-03 14:25:35,124 iteration 1189 : loss : 0.074426, loss_ce: 0.035403
2021-12-03 14:25:35,125 Training Data Eval:
2021-12-03 14:25:42,678   Average segmentation loss on training set: 0.0360
2021-12-03 14:25:42,678 Validation Data Eval:
2021-12-03 14:25:45,290   Average segmentation loss on validation set: 0.1122
2021-12-03 14:25:46,811 iteration 1190 : loss : 0.066203, loss_ce: 0.031348
 47%|██████████████▉                 | 70/150 [33:06<39:39, 29.74s/it]2021-12-03 14:25:48,458 iteration 1191 : loss : 0.052484, loss_ce: 0.020817
2021-12-03 14:25:49,927 iteration 1192 : loss : 0.039949, loss_ce: 0.019126
2021-12-03 14:25:51,524 iteration 1193 : loss : 0.075674, loss_ce: 0.023570
2021-12-03 14:25:53,028 iteration 1194 : loss : 0.063831, loss_ce: 0.022108
2021-12-03 14:25:54,491 iteration 1195 : loss : 0.044652, loss_ce: 0.020150
2021-12-03 14:25:55,968 iteration 1196 : loss : 0.048069, loss_ce: 0.019669
2021-12-03 14:25:57,403 iteration 1197 : loss : 0.041014, loss_ce: 0.015625
2021-12-03 14:25:58,967 iteration 1198 : loss : 0.049712, loss_ce: 0.022355
2021-12-03 14:26:00,483 iteration 1199 : loss : 0.044398, loss_ce: 0.016289
2021-12-03 14:26:01,980 iteration 1200 : loss : 0.059649, loss_ce: 0.018972
2021-12-03 14:26:03,442 iteration 1201 : loss : 0.042855, loss_ce: 0.019310
2021-12-03 14:26:04,982 iteration 1202 : loss : 0.052438, loss_ce: 0.018896
2021-12-03 14:26:06,508 iteration 1203 : loss : 0.065614, loss_ce: 0.022414
2021-12-03 14:26:08,028 iteration 1204 : loss : 0.055836, loss_ce: 0.018935
2021-12-03 14:26:09,559 iteration 1205 : loss : 0.067284, loss_ce: 0.029086
2021-12-03 14:26:11,088 iteration 1206 : loss : 0.036382, loss_ce: 0.014867
2021-12-03 14:26:12,656 iteration 1207 : loss : 0.038094, loss_ce: 0.013626
 47%|███████████████▏                | 71/150 [33:32<37:37, 28.57s/it]2021-12-03 14:26:14,263 iteration 1208 : loss : 0.055163, loss_ce: 0.029890
2021-12-03 14:26:15,792 iteration 1209 : loss : 0.053016, loss_ce: 0.018917
2021-12-03 14:26:17,317 iteration 1210 : loss : 0.046928, loss_ce: 0.016218
2021-12-03 14:26:18,787 iteration 1211 : loss : 0.038760, loss_ce: 0.014634
2021-12-03 14:26:20,239 iteration 1212 : loss : 0.056298, loss_ce: 0.019260
2021-12-03 14:26:21,875 iteration 1213 : loss : 0.062279, loss_ce: 0.026243
2021-12-03 14:26:23,422 iteration 1214 : loss : 0.044219, loss_ce: 0.017903
2021-12-03 14:26:24,945 iteration 1215 : loss : 0.053113, loss_ce: 0.019691
2021-12-03 14:26:26,584 iteration 1216 : loss : 0.044425, loss_ce: 0.017495
2021-12-03 14:26:28,113 iteration 1217 : loss : 0.034474, loss_ce: 0.011218
2021-12-03 14:26:29,591 iteration 1218 : loss : 0.038841, loss_ce: 0.013801
2021-12-03 14:26:31,052 iteration 1219 : loss : 0.041157, loss_ce: 0.013355
2021-12-03 14:26:32,561 iteration 1220 : loss : 0.050545, loss_ce: 0.020568
2021-12-03 14:26:34,035 iteration 1221 : loss : 0.056623, loss_ce: 0.022313
2021-12-03 14:26:35,613 iteration 1222 : loss : 0.057830, loss_ce: 0.022111
2021-12-03 14:26:37,108 iteration 1223 : loss : 0.053738, loss_ce: 0.027112
2021-12-03 14:26:38,668 iteration 1224 : loss : 0.075974, loss_ce: 0.027604
 48%|███████████████▎                | 72/150 [33:58<36:08, 27.80s/it]2021-12-03 14:26:40,221 iteration 1225 : loss : 0.039850, loss_ce: 0.015230
2021-12-03 14:26:41,778 iteration 1226 : loss : 0.065211, loss_ce: 0.030265
2021-12-03 14:26:43,246 iteration 1227 : loss : 0.045586, loss_ce: 0.017346
2021-12-03 14:26:44,751 iteration 1228 : loss : 0.039806, loss_ce: 0.014800
2021-12-03 14:26:46,198 iteration 1229 : loss : 0.046044, loss_ce: 0.014333
2021-12-03 14:26:47,671 iteration 1230 : loss : 0.052332, loss_ce: 0.019514
2021-12-03 14:26:49,221 iteration 1231 : loss : 0.043158, loss_ce: 0.019437
2021-12-03 14:26:50,693 iteration 1232 : loss : 0.055203, loss_ce: 0.023295
2021-12-03 14:26:52,181 iteration 1233 : loss : 0.041072, loss_ce: 0.015786
2021-12-03 14:26:53,742 iteration 1234 : loss : 0.049981, loss_ce: 0.019748
2021-12-03 14:26:55,295 iteration 1235 : loss : 0.067519, loss_ce: 0.023030
2021-12-03 14:26:56,796 iteration 1236 : loss : 0.045250, loss_ce: 0.017466
2021-12-03 14:26:58,219 iteration 1237 : loss : 0.053750, loss_ce: 0.021107
2021-12-03 14:26:59,778 iteration 1238 : loss : 0.058762, loss_ce: 0.020012
2021-12-03 14:27:01,241 iteration 1239 : loss : 0.040925, loss_ce: 0.015839
2021-12-03 14:27:02,716 iteration 1240 : loss : 0.042735, loss_ce: 0.018611
2021-12-03 14:27:04,183 iteration 1241 : loss : 0.050103, loss_ce: 0.024830
 49%|███████████████▌                | 73/150 [34:23<34:47, 27.12s/it]2021-12-03 14:27:05,777 iteration 1242 : loss : 0.072904, loss_ce: 0.039918
2021-12-03 14:27:07,254 iteration 1243 : loss : 0.068344, loss_ce: 0.024675
2021-12-03 14:27:08,735 iteration 1244 : loss : 0.036142, loss_ce: 0.015070
2021-12-03 14:27:10,263 iteration 1245 : loss : 0.061737, loss_ce: 0.020150
2021-12-03 14:27:11,786 iteration 1246 : loss : 0.043315, loss_ce: 0.014920
2021-12-03 14:27:13,265 iteration 1247 : loss : 0.043952, loss_ce: 0.019936
2021-12-03 14:27:14,792 iteration 1248 : loss : 0.063262, loss_ce: 0.021792
2021-12-03 14:27:16,268 iteration 1249 : loss : 0.034159, loss_ce: 0.011043
2021-12-03 14:27:17,875 iteration 1250 : loss : 0.052703, loss_ce: 0.021514
2021-12-03 14:27:19,525 iteration 1251 : loss : 0.066851, loss_ce: 0.031315
2021-12-03 14:27:21,067 iteration 1252 : loss : 0.042784, loss_ce: 0.017633
2021-12-03 14:27:22,510 iteration 1253 : loss : 0.036022, loss_ce: 0.012431
2021-12-03 14:27:24,028 iteration 1254 : loss : 0.042304, loss_ce: 0.021973
2021-12-03 14:27:25,567 iteration 1255 : loss : 0.042252, loss_ce: 0.015909
2021-12-03 14:27:27,067 iteration 1256 : loss : 0.051532, loss_ce: 0.022936
2021-12-03 14:27:28,585 iteration 1257 : loss : 0.062339, loss_ce: 0.018297
2021-12-03 14:27:30,117 iteration 1258 : loss : 0.038488, loss_ce: 0.017376
 49%|███████████████▊                | 74/150 [34:49<33:53, 26.76s/it]2021-12-03 14:27:31,649 iteration 1259 : loss : 0.035336, loss_ce: 0.015862
2021-12-03 14:27:33,212 iteration 1260 : loss : 0.043361, loss_ce: 0.017927
2021-12-03 14:27:34,709 iteration 1261 : loss : 0.044724, loss_ce: 0.013125
2021-12-03 14:27:36,299 iteration 1262 : loss : 0.045167, loss_ce: 0.017322
2021-12-03 14:27:37,918 iteration 1263 : loss : 0.086372, loss_ce: 0.029506
2021-12-03 14:27:39,418 iteration 1264 : loss : 0.035565, loss_ce: 0.014881
2021-12-03 14:27:40,993 iteration 1265 : loss : 0.042995, loss_ce: 0.022259
2021-12-03 14:27:42,565 iteration 1266 : loss : 0.051506, loss_ce: 0.020089
2021-12-03 14:27:44,112 iteration 1267 : loss : 0.048356, loss_ce: 0.018656
2021-12-03 14:27:45,601 iteration 1268 : loss : 0.072739, loss_ce: 0.025203
2021-12-03 14:27:47,194 iteration 1269 : loss : 0.082613, loss_ce: 0.019139
2021-12-03 14:27:48,749 iteration 1270 : loss : 0.046336, loss_ce: 0.018894
2021-12-03 14:27:50,263 iteration 1271 : loss : 0.052505, loss_ce: 0.024646
2021-12-03 14:27:51,701 iteration 1272 : loss : 0.044507, loss_ce: 0.014431
2021-12-03 14:27:53,198 iteration 1273 : loss : 0.040877, loss_ce: 0.015707
2021-12-03 14:27:54,710 iteration 1274 : loss : 0.044256, loss_ce: 0.015131
2021-12-03 14:27:54,710 Training Data Eval:
2021-12-03 14:28:02,261   Average segmentation loss on training set: 0.0380
2021-12-03 14:28:02,262 Validation Data Eval:
2021-12-03 14:28:04,876   Average segmentation loss on validation set: 0.1276
2021-12-03 14:28:06,378 iteration 1275 : loss : 0.050701, loss_ce: 0.017746
 50%|████████████████                | 75/150 [35:25<37:00, 29.61s/it]2021-12-03 14:28:07,862 iteration 1276 : loss : 0.047269, loss_ce: 0.018146
2021-12-03 14:28:09,481 iteration 1277 : loss : 0.044996, loss_ce: 0.015840
2021-12-03 14:28:10,964 iteration 1278 : loss : 0.035546, loss_ce: 0.011971
2021-12-03 14:28:12,570 iteration 1279 : loss : 0.053083, loss_ce: 0.020096
2021-12-03 14:28:14,105 iteration 1280 : loss : 0.066180, loss_ce: 0.034036
2021-12-03 14:28:15,637 iteration 1281 : loss : 0.069022, loss_ce: 0.029050
2021-12-03 14:28:17,102 iteration 1282 : loss : 0.028847, loss_ce: 0.013313
2021-12-03 14:28:18,671 iteration 1283 : loss : 0.047168, loss_ce: 0.014524
2021-12-03 14:28:20,170 iteration 1284 : loss : 0.050687, loss_ce: 0.018603
2021-12-03 14:28:21,748 iteration 1285 : loss : 0.045000, loss_ce: 0.015408
2021-12-03 14:28:23,376 iteration 1286 : loss : 0.137644, loss_ce: 0.036161
2021-12-03 14:28:24,878 iteration 1287 : loss : 0.043684, loss_ce: 0.024859
2021-12-03 14:28:26,357 iteration 1288 : loss : 0.048602, loss_ce: 0.023397
2021-12-03 14:28:27,877 iteration 1289 : loss : 0.037129, loss_ce: 0.015520
2021-12-03 14:28:29,433 iteration 1290 : loss : 0.062008, loss_ce: 0.024391
2021-12-03 14:28:30,995 iteration 1291 : loss : 0.067987, loss_ce: 0.029688
2021-12-03 14:28:32,574 iteration 1292 : loss : 0.049736, loss_ce: 0.019670
 51%|████████████████▏               | 76/150 [35:52<35:15, 28.59s/it]2021-12-03 14:28:34,182 iteration 1293 : loss : 0.036730, loss_ce: 0.013547
2021-12-03 14:28:35,744 iteration 1294 : loss : 0.054367, loss_ce: 0.020188
2021-12-03 14:28:37,341 iteration 1295 : loss : 0.062185, loss_ce: 0.015829
2021-12-03 14:28:38,890 iteration 1296 : loss : 0.053044, loss_ce: 0.016477
2021-12-03 14:28:40,373 iteration 1297 : loss : 0.051735, loss_ce: 0.026522
2021-12-03 14:28:41,828 iteration 1298 : loss : 0.033890, loss_ce: 0.013348
2021-12-03 14:28:43,358 iteration 1299 : loss : 0.048150, loss_ce: 0.022027
2021-12-03 14:28:44,865 iteration 1300 : loss : 0.057821, loss_ce: 0.017663
2021-12-03 14:28:46,411 iteration 1301 : loss : 0.033877, loss_ce: 0.012786
2021-12-03 14:28:47,904 iteration 1302 : loss : 0.054626, loss_ce: 0.025320
2021-12-03 14:28:49,405 iteration 1303 : loss : 0.044164, loss_ce: 0.017395
2021-12-03 14:28:50,936 iteration 1304 : loss : 0.060814, loss_ce: 0.023982
2021-12-03 14:28:52,464 iteration 1305 : loss : 0.065622, loss_ce: 0.027870
2021-12-03 14:28:54,022 iteration 1306 : loss : 0.068745, loss_ce: 0.024709
2021-12-03 14:28:55,607 iteration 1307 : loss : 0.038089, loss_ce: 0.018424
2021-12-03 14:28:57,136 iteration 1308 : loss : 0.075109, loss_ce: 0.024161
2021-12-03 14:28:58,607 iteration 1309 : loss : 0.048163, loss_ce: 0.017931
 51%|████████████████▍               | 77/150 [36:18<33:51, 27.82s/it]2021-12-03 14:29:00,256 iteration 1310 : loss : 0.055510, loss_ce: 0.020127
2021-12-03 14:29:01,758 iteration 1311 : loss : 0.038676, loss_ce: 0.016670
2021-12-03 14:29:03,242 iteration 1312 : loss : 0.028873, loss_ce: 0.010558
2021-12-03 14:29:04,734 iteration 1313 : loss : 0.073266, loss_ce: 0.021567
2021-12-03 14:29:06,255 iteration 1314 : loss : 0.043237, loss_ce: 0.019391
2021-12-03 14:29:07,803 iteration 1315 : loss : 0.070030, loss_ce: 0.026957
2021-12-03 14:29:09,426 iteration 1316 : loss : 0.053487, loss_ce: 0.022764
2021-12-03 14:29:10,940 iteration 1317 : loss : 0.052931, loss_ce: 0.030064
2021-12-03 14:29:12,537 iteration 1318 : loss : 0.107355, loss_ce: 0.020216
2021-12-03 14:29:14,101 iteration 1319 : loss : 0.059173, loss_ce: 0.028839
2021-12-03 14:29:15,608 iteration 1320 : loss : 0.037789, loss_ce: 0.015471
2021-12-03 14:29:17,145 iteration 1321 : loss : 0.090793, loss_ce: 0.026455
2021-12-03 14:29:18,614 iteration 1322 : loss : 0.071667, loss_ce: 0.034208
2021-12-03 14:29:20,122 iteration 1323 : loss : 0.083793, loss_ce: 0.026198
2021-12-03 14:29:21,668 iteration 1324 : loss : 0.063405, loss_ce: 0.024293
2021-12-03 14:29:23,250 iteration 1325 : loss : 0.058878, loss_ce: 0.020173
2021-12-03 14:29:24,678 iteration 1326 : loss : 0.056471, loss_ce: 0.020634
 52%|████████████████▋               | 78/150 [36:44<32:45, 27.30s/it]2021-12-03 14:29:26,222 iteration 1327 : loss : 0.073286, loss_ce: 0.025617
2021-12-03 14:29:27,780 iteration 1328 : loss : 0.070766, loss_ce: 0.033144
2021-12-03 14:29:29,300 iteration 1329 : loss : 0.044001, loss_ce: 0.018323
2021-12-03 14:29:30,810 iteration 1330 : loss : 0.116215, loss_ce: 0.030564
2021-12-03 14:29:32,265 iteration 1331 : loss : 0.045337, loss_ce: 0.023280
2021-12-03 14:29:33,736 iteration 1332 : loss : 0.048623, loss_ce: 0.016479
2021-12-03 14:29:35,230 iteration 1333 : loss : 0.058202, loss_ce: 0.015450
2021-12-03 14:29:36,751 iteration 1334 : loss : 0.039943, loss_ce: 0.015983
2021-12-03 14:29:38,238 iteration 1335 : loss : 0.044027, loss_ce: 0.016455
2021-12-03 14:29:39,730 iteration 1336 : loss : 0.034564, loss_ce: 0.015447
2021-12-03 14:29:41,298 iteration 1337 : loss : 0.075311, loss_ce: 0.038145
2021-12-03 14:29:42,847 iteration 1338 : loss : 0.047844, loss_ce: 0.015980
2021-12-03 14:29:44,391 iteration 1339 : loss : 0.044925, loss_ce: 0.021757
2021-12-03 14:29:45,932 iteration 1340 : loss : 0.045546, loss_ce: 0.018611
2021-12-03 14:29:47,464 iteration 1341 : loss : 0.055731, loss_ce: 0.022107
2021-12-03 14:29:48,977 iteration 1342 : loss : 0.060829, loss_ce: 0.023533
2021-12-03 14:29:50,440 iteration 1343 : loss : 0.043267, loss_ce: 0.016621
 53%|████████████████▊               | 79/150 [37:09<31:45, 26.84s/it]2021-12-03 14:29:52,012 iteration 1344 : loss : 0.053496, loss_ce: 0.020538
2021-12-03 14:29:53,599 iteration 1345 : loss : 0.063540, loss_ce: 0.023037
2021-12-03 14:29:55,102 iteration 1346 : loss : 0.056861, loss_ce: 0.024920
2021-12-03 14:29:56,705 iteration 1347 : loss : 0.036988, loss_ce: 0.016592
2021-12-03 14:29:58,332 iteration 1348 : loss : 0.078425, loss_ce: 0.034720
2021-12-03 14:29:59,879 iteration 1349 : loss : 0.055058, loss_ce: 0.021887
2021-12-03 14:30:01,405 iteration 1350 : loss : 0.054527, loss_ce: 0.025078
2021-12-03 14:30:02,952 iteration 1351 : loss : 0.044158, loss_ce: 0.020578
2021-12-03 14:30:04,541 iteration 1352 : loss : 0.045741, loss_ce: 0.021546
2021-12-03 14:30:06,121 iteration 1353 : loss : 0.062984, loss_ce: 0.019973
2021-12-03 14:30:07,691 iteration 1354 : loss : 0.061575, loss_ce: 0.021159
2021-12-03 14:30:09,344 iteration 1355 : loss : 0.124769, loss_ce: 0.028450
2021-12-03 14:30:10,890 iteration 1356 : loss : 0.052792, loss_ce: 0.022820
2021-12-03 14:30:12,466 iteration 1357 : loss : 0.038457, loss_ce: 0.015762
2021-12-03 14:30:14,044 iteration 1358 : loss : 0.047132, loss_ce: 0.017782
2021-12-03 14:30:15,577 iteration 1359 : loss : 0.065503, loss_ce: 0.028837
2021-12-03 14:30:15,577 Training Data Eval:
2021-12-03 14:30:23,113   Average segmentation loss on training set: 0.0479
2021-12-03 14:30:23,113 Validation Data Eval:
2021-12-03 14:30:25,714   Average segmentation loss on validation set: 0.1709
2021-12-03 14:30:27,288 iteration 1360 : loss : 0.046979, loss_ce: 0.013550
 53%|█████████████████               | 80/150 [37:46<34:48, 29.84s/it]2021-12-03 14:30:28,963 iteration 1361 : loss : 0.063052, loss_ce: 0.023492
2021-12-03 14:30:30,499 iteration 1362 : loss : 0.045812, loss_ce: 0.014602
2021-12-03 14:30:32,185 iteration 1363 : loss : 0.085890, loss_ce: 0.036962
2021-12-03 14:30:33,593 iteration 1364 : loss : 0.056585, loss_ce: 0.013791
2021-12-03 14:30:35,214 iteration 1365 : loss : 0.049903, loss_ce: 0.021108
2021-12-03 14:30:36,756 iteration 1366 : loss : 0.060224, loss_ce: 0.027801
2021-12-03 14:30:38,287 iteration 1367 : loss : 0.042985, loss_ce: 0.015774
2021-12-03 14:30:39,819 iteration 1368 : loss : 0.041640, loss_ce: 0.018067
2021-12-03 14:30:41,330 iteration 1369 : loss : 0.046235, loss_ce: 0.016201
2021-12-03 14:30:42,895 iteration 1370 : loss : 0.053143, loss_ce: 0.025585
2021-12-03 14:30:44,394 iteration 1371 : loss : 0.043057, loss_ce: 0.016248
2021-12-03 14:30:45,884 iteration 1372 : loss : 0.041647, loss_ce: 0.015861
2021-12-03 14:30:47,369 iteration 1373 : loss : 0.055564, loss_ce: 0.021114
2021-12-03 14:30:48,898 iteration 1374 : loss : 0.038607, loss_ce: 0.014681
2021-12-03 14:30:50,451 iteration 1375 : loss : 0.046106, loss_ce: 0.021828
2021-12-03 14:30:51,978 iteration 1376 : loss : 0.050761, loss_ce: 0.015686
2021-12-03 14:30:53,493 iteration 1377 : loss : 0.027435, loss_ce: 0.010873
 54%|█████████████████▎              | 81/150 [38:12<33:03, 28.75s/it]2021-12-03 14:30:55,017 iteration 1378 : loss : 0.051195, loss_ce: 0.020193
2021-12-03 14:30:56,584 iteration 1379 : loss : 0.039534, loss_ce: 0.016387
2021-12-03 14:30:58,114 iteration 1380 : loss : 0.045963, loss_ce: 0.018268
2021-12-03 14:30:59,720 iteration 1381 : loss : 0.066910, loss_ce: 0.026979
2021-12-03 14:31:01,165 iteration 1382 : loss : 0.043326, loss_ce: 0.016590
2021-12-03 14:31:02,762 iteration 1383 : loss : 0.036606, loss_ce: 0.013532
2021-12-03 14:31:04,292 iteration 1384 : loss : 0.053555, loss_ce: 0.021328
2021-12-03 14:31:05,754 iteration 1385 : loss : 0.057496, loss_ce: 0.021731
2021-12-03 14:31:07,244 iteration 1386 : loss : 0.037733, loss_ce: 0.014786
2021-12-03 14:31:08,754 iteration 1387 : loss : 0.046470, loss_ce: 0.017464
2021-12-03 14:31:10,289 iteration 1388 : loss : 0.048005, loss_ce: 0.014751
2021-12-03 14:31:11,810 iteration 1389 : loss : 0.054174, loss_ce: 0.021815
2021-12-03 14:31:13,399 iteration 1390 : loss : 0.043891, loss_ce: 0.017905
2021-12-03 14:31:14,989 iteration 1391 : loss : 0.050365, loss_ce: 0.019007
2021-12-03 14:31:16,567 iteration 1392 : loss : 0.044642, loss_ce: 0.022680
2021-12-03 14:31:18,063 iteration 1393 : loss : 0.040044, loss_ce: 0.013915
2021-12-03 14:31:19,640 iteration 1394 : loss : 0.042146, loss_ce: 0.021234
 55%|█████████████████▍              | 82/150 [38:39<31:41, 27.97s/it]2021-12-03 14:31:21,208 iteration 1395 : loss : 0.058303, loss_ce: 0.022334
2021-12-03 14:31:22,700 iteration 1396 : loss : 0.047362, loss_ce: 0.023227
2021-12-03 14:31:24,280 iteration 1397 : loss : 0.049717, loss_ce: 0.021278
2021-12-03 14:31:25,868 iteration 1398 : loss : 0.048550, loss_ce: 0.023399
2021-12-03 14:31:27,334 iteration 1399 : loss : 0.054392, loss_ce: 0.029899
2021-12-03 14:31:28,783 iteration 1400 : loss : 0.038466, loss_ce: 0.013475
2021-12-03 14:31:30,360 iteration 1401 : loss : 0.041777, loss_ce: 0.014655
2021-12-03 14:31:31,897 iteration 1402 : loss : 0.053663, loss_ce: 0.020310
2021-12-03 14:31:33,378 iteration 1403 : loss : 0.042728, loss_ce: 0.014661
2021-12-03 14:31:34,846 iteration 1404 : loss : 0.028095, loss_ce: 0.013139
2021-12-03 14:31:36,366 iteration 1405 : loss : 0.052948, loss_ce: 0.023378
2021-12-03 14:31:37,900 iteration 1406 : loss : 0.044065, loss_ce: 0.015464
2021-12-03 14:31:39,468 iteration 1407 : loss : 0.030002, loss_ce: 0.012863
2021-12-03 14:31:40,987 iteration 1408 : loss : 0.048947, loss_ce: 0.020434
2021-12-03 14:31:42,528 iteration 1409 : loss : 0.079369, loss_ce: 0.025122
2021-12-03 14:31:44,124 iteration 1410 : loss : 0.039024, loss_ce: 0.014898
2021-12-03 14:31:45,634 iteration 1411 : loss : 0.037857, loss_ce: 0.012428
 55%|█████████████████▋              | 83/150 [39:05<30:34, 27.38s/it]2021-12-03 14:31:47,178 iteration 1412 : loss : 0.047109, loss_ce: 0.017348
2021-12-03 14:31:48,787 iteration 1413 : loss : 0.069097, loss_ce: 0.024905
2021-12-03 14:31:50,299 iteration 1414 : loss : 0.040242, loss_ce: 0.014057
2021-12-03 14:31:51,883 iteration 1415 : loss : 0.054447, loss_ce: 0.017169
2021-12-03 14:31:53,396 iteration 1416 : loss : 0.044269, loss_ce: 0.018080
2021-12-03 14:31:54,888 iteration 1417 : loss : 0.045200, loss_ce: 0.017760
2021-12-03 14:31:56,380 iteration 1418 : loss : 0.049953, loss_ce: 0.023617
2021-12-03 14:31:57,845 iteration 1419 : loss : 0.037238, loss_ce: 0.014190
2021-12-03 14:31:59,409 iteration 1420 : loss : 0.057612, loss_ce: 0.024203
2021-12-03 14:32:01,016 iteration 1421 : loss : 0.077014, loss_ce: 0.032650
2021-12-03 14:32:02,565 iteration 1422 : loss : 0.034731, loss_ce: 0.010958
2021-12-03 14:32:04,021 iteration 1423 : loss : 0.050317, loss_ce: 0.019731
2021-12-03 14:32:05,572 iteration 1424 : loss : 0.051268, loss_ce: 0.026232
2021-12-03 14:32:07,122 iteration 1425 : loss : 0.027761, loss_ce: 0.011419
2021-12-03 14:32:08,602 iteration 1426 : loss : 0.046596, loss_ce: 0.020062
2021-12-03 14:32:10,116 iteration 1427 : loss : 0.070873, loss_ce: 0.029933
2021-12-03 14:32:11,544 iteration 1428 : loss : 0.047514, loss_ce: 0.018352
 56%|█████████████████▉              | 84/150 [39:31<29:37, 26.94s/it]2021-12-03 14:32:13,192 iteration 1429 : loss : 0.046114, loss_ce: 0.020318
2021-12-03 14:32:14,672 iteration 1430 : loss : 0.134882, loss_ce: 0.036822
2021-12-03 14:32:16,191 iteration 1431 : loss : 0.069509, loss_ce: 0.034763
2021-12-03 14:32:17,741 iteration 1432 : loss : 0.053271, loss_ce: 0.023530
2021-12-03 14:32:19,315 iteration 1433 : loss : 0.049093, loss_ce: 0.019601
2021-12-03 14:32:20,837 iteration 1434 : loss : 0.048222, loss_ce: 0.019099
2021-12-03 14:32:22,382 iteration 1435 : loss : 0.043863, loss_ce: 0.016215
2021-12-03 14:32:23,969 iteration 1436 : loss : 0.050967, loss_ce: 0.020918
2021-12-03 14:32:25,540 iteration 1437 : loss : 0.054668, loss_ce: 0.016188
2021-12-03 14:32:27,087 iteration 1438 : loss : 0.044865, loss_ce: 0.021447
2021-12-03 14:32:28,660 iteration 1439 : loss : 0.040971, loss_ce: 0.016923
2021-12-03 14:32:30,227 iteration 1440 : loss : 0.047650, loss_ce: 0.023618
2021-12-03 14:32:31,739 iteration 1441 : loss : 0.033996, loss_ce: 0.013628
2021-12-03 14:32:33,304 iteration 1442 : loss : 0.039212, loss_ce: 0.016078
2021-12-03 14:32:34,905 iteration 1443 : loss : 0.052020, loss_ce: 0.020152
2021-12-03 14:32:36,484 iteration 1444 : loss : 0.092020, loss_ce: 0.029426
2021-12-03 14:32:36,484 Training Data Eval:
2021-12-03 14:32:44,121   Average segmentation loss on training set: 0.0302
2021-12-03 14:32:44,122 Validation Data Eval:
2021-12-03 14:32:46,736   Average segmentation loss on validation set: 0.1329
2021-12-03 14:32:48,298 iteration 1445 : loss : 0.036817, loss_ce: 0.011735
 57%|██████████████████▏             | 85/150 [40:07<32:22, 29.88s/it]2021-12-03 14:32:50,026 iteration 1446 : loss : 0.036804, loss_ce: 0.013115
2021-12-03 14:32:51,586 iteration 1447 : loss : 0.045688, loss_ce: 0.014937
2021-12-03 14:32:53,062 iteration 1448 : loss : 0.048908, loss_ce: 0.026203
2021-12-03 14:32:54,654 iteration 1449 : loss : 0.048842, loss_ce: 0.016219
2021-12-03 14:32:56,324 iteration 1450 : loss : 0.060880, loss_ce: 0.035110
2021-12-03 14:32:58,008 iteration 1451 : loss : 0.055395, loss_ce: 0.021612
2021-12-03 14:32:59,538 iteration 1452 : loss : 0.042286, loss_ce: 0.013469
2021-12-03 14:33:01,074 iteration 1453 : loss : 0.044876, loss_ce: 0.018621
2021-12-03 14:33:02,661 iteration 1454 : loss : 0.051983, loss_ce: 0.018648
2021-12-03 14:33:04,175 iteration 1455 : loss : 0.034157, loss_ce: 0.014841
2021-12-03 14:33:05,831 iteration 1456 : loss : 0.072969, loss_ce: 0.021214
2021-12-03 14:33:07,388 iteration 1457 : loss : 0.048241, loss_ce: 0.020669
2021-12-03 14:33:08,957 iteration 1458 : loss : 0.042314, loss_ce: 0.014179
2021-12-03 14:33:10,466 iteration 1459 : loss : 0.040606, loss_ce: 0.010340
2021-12-03 14:33:12,117 iteration 1460 : loss : 0.085348, loss_ce: 0.039550
2021-12-03 14:33:13,675 iteration 1461 : loss : 0.054551, loss_ce: 0.023623
2021-12-03 14:33:15,294 iteration 1462 : loss : 0.040395, loss_ce: 0.016432
 57%|██████████████████▎             | 86/150 [40:34<30:57, 29.02s/it]2021-12-03 14:33:16,890 iteration 1463 : loss : 0.051024, loss_ce: 0.022138
2021-12-03 14:33:18,422 iteration 1464 : loss : 0.039699, loss_ce: 0.016779
2021-12-03 14:33:19,997 iteration 1465 : loss : 0.045909, loss_ce: 0.014857
2021-12-03 14:33:21,586 iteration 1466 : loss : 0.031290, loss_ce: 0.014200
2021-12-03 14:33:23,138 iteration 1467 : loss : 0.039806, loss_ce: 0.017488
2021-12-03 14:33:24,664 iteration 1468 : loss : 0.040409, loss_ce: 0.018474
2021-12-03 14:33:26,209 iteration 1469 : loss : 0.044981, loss_ce: 0.017323
2021-12-03 14:33:27,785 iteration 1470 : loss : 0.076875, loss_ce: 0.026387
2021-12-03 14:33:29,356 iteration 1471 : loss : 0.064391, loss_ce: 0.039836
2021-12-03 14:33:30,791 iteration 1472 : loss : 0.042673, loss_ce: 0.015105
2021-12-03 14:33:32,421 iteration 1473 : loss : 0.035231, loss_ce: 0.013654
2021-12-03 14:33:34,008 iteration 1474 : loss : 0.056346, loss_ce: 0.021714
2021-12-03 14:33:35,541 iteration 1475 : loss : 0.040941, loss_ce: 0.015420
2021-12-03 14:33:37,175 iteration 1476 : loss : 0.068167, loss_ce: 0.023796
2021-12-03 14:33:38,760 iteration 1477 : loss : 0.046361, loss_ce: 0.016891
2021-12-03 14:33:40,393 iteration 1478 : loss : 0.045247, loss_ce: 0.018102
2021-12-03 14:33:41,892 iteration 1479 : loss : 0.056466, loss_ce: 0.018981
 58%|██████████████████▌             | 87/150 [41:01<29:42, 28.29s/it]2021-12-03 14:33:43,500 iteration 1480 : loss : 0.050703, loss_ce: 0.016833
2021-12-03 14:33:45,012 iteration 1481 : loss : 0.034298, loss_ce: 0.014694
2021-12-03 14:33:46,546 iteration 1482 : loss : 0.036127, loss_ce: 0.014685
2021-12-03 14:33:48,164 iteration 1483 : loss : 0.039908, loss_ce: 0.015366
2021-12-03 14:33:49,850 iteration 1484 : loss : 0.048044, loss_ce: 0.016203
2021-12-03 14:33:51,464 iteration 1485 : loss : 0.047829, loss_ce: 0.020407
2021-12-03 14:33:52,989 iteration 1486 : loss : 0.041069, loss_ce: 0.016575
2021-12-03 14:33:54,540 iteration 1487 : loss : 0.036538, loss_ce: 0.015765
2021-12-03 14:33:56,102 iteration 1488 : loss : 0.043114, loss_ce: 0.021317
2021-12-03 14:33:57,662 iteration 1489 : loss : 0.028515, loss_ce: 0.011112
2021-12-03 14:33:59,249 iteration 1490 : loss : 0.044514, loss_ce: 0.017583
2021-12-03 14:34:00,861 iteration 1491 : loss : 0.053867, loss_ce: 0.023614
2021-12-03 14:34:02,366 iteration 1492 : loss : 0.038090, loss_ce: 0.015278
2021-12-03 14:34:03,941 iteration 1493 : loss : 0.045601, loss_ce: 0.018368
2021-12-03 14:34:05,444 iteration 1494 : loss : 0.035906, loss_ce: 0.014441
2021-12-03 14:34:06,958 iteration 1495 : loss : 0.046874, loss_ce: 0.019732
2021-12-03 14:34:08,493 iteration 1496 : loss : 0.060233, loss_ce: 0.016942
 59%|██████████████████▊             | 88/150 [41:27<28:42, 27.78s/it]2021-12-03 14:34:10,037 iteration 1497 : loss : 0.040565, loss_ce: 0.017924
2021-12-03 14:34:11,544 iteration 1498 : loss : 0.032660, loss_ce: 0.011520
2021-12-03 14:34:13,117 iteration 1499 : loss : 0.050183, loss_ce: 0.023277
2021-12-03 14:34:14,572 iteration 1500 : loss : 0.045800, loss_ce: 0.015887
2021-12-03 14:34:16,089 iteration 1501 : loss : 0.042240, loss_ce: 0.013224
2021-12-03 14:34:17,641 iteration 1502 : loss : 0.045061, loss_ce: 0.014958
2021-12-03 14:34:19,143 iteration 1503 : loss : 0.028516, loss_ce: 0.011695
2021-12-03 14:34:20,651 iteration 1504 : loss : 0.051178, loss_ce: 0.017649
2021-12-03 14:34:22,114 iteration 1505 : loss : 0.045397, loss_ce: 0.017612
2021-12-03 14:34:23,628 iteration 1506 : loss : 0.038696, loss_ce: 0.015877
2021-12-03 14:34:25,145 iteration 1507 : loss : 0.053524, loss_ce: 0.018959
2021-12-03 14:34:26,638 iteration 1508 : loss : 0.039385, loss_ce: 0.015952
2021-12-03 14:34:28,147 iteration 1509 : loss : 0.041444, loss_ce: 0.014332
2021-12-03 14:34:29,624 iteration 1510 : loss : 0.027019, loss_ce: 0.009767
2021-12-03 14:34:31,165 iteration 1511 : loss : 0.038915, loss_ce: 0.018842
2021-12-03 14:34:32,649 iteration 1512 : loss : 0.041351, loss_ce: 0.017034
2021-12-03 14:34:34,184 iteration 1513 : loss : 0.045376, loss_ce: 0.021658
 59%|██████████████████▉             | 89/150 [41:53<27:36, 27.15s/it]2021-12-03 14:34:35,741 iteration 1514 : loss : 0.049603, loss_ce: 0.016210
2021-12-03 14:34:37,261 iteration 1515 : loss : 0.053090, loss_ce: 0.021898
2021-12-03 14:34:38,816 iteration 1516 : loss : 0.036648, loss_ce: 0.014980
2021-12-03 14:34:40,329 iteration 1517 : loss : 0.037697, loss_ce: 0.016976
2021-12-03 14:34:41,897 iteration 1518 : loss : 0.043722, loss_ce: 0.013183
2021-12-03 14:34:43,394 iteration 1519 : loss : 0.032886, loss_ce: 0.011760
2021-12-03 14:34:44,893 iteration 1520 : loss : 0.035815, loss_ce: 0.012653
2021-12-03 14:34:46,390 iteration 1521 : loss : 0.051355, loss_ce: 0.019371
2021-12-03 14:34:48,012 iteration 1522 : loss : 0.049636, loss_ce: 0.016895
2021-12-03 14:34:49,486 iteration 1523 : loss : 0.035665, loss_ce: 0.016960
2021-12-03 14:34:51,033 iteration 1524 : loss : 0.055232, loss_ce: 0.022196
2021-12-03 14:34:52,528 iteration 1525 : loss : 0.033847, loss_ce: 0.014918
2021-12-03 14:34:54,108 iteration 1526 : loss : 0.036195, loss_ce: 0.013522
2021-12-03 14:34:55,687 iteration 1527 : loss : 0.041333, loss_ce: 0.017254
2021-12-03 14:34:57,259 iteration 1528 : loss : 0.044455, loss_ce: 0.016198
2021-12-03 14:34:58,744 iteration 1529 : loss : 0.059858, loss_ce: 0.023395
2021-12-03 14:34:58,744 Training Data Eval:
2021-12-03 14:35:06,299   Average segmentation loss on training set: 0.0285
2021-12-03 14:35:06,299 Validation Data Eval:
2021-12-03 14:35:08,899   Average segmentation loss on validation set: 0.1242
2021-12-03 14:35:10,403 iteration 1530 : loss : 0.042159, loss_ce: 0.018428
 60%|███████████████████▏            | 90/150 [42:29<29:52, 29.88s/it]2021-12-03 14:35:12,108 iteration 1531 : loss : 0.049659, loss_ce: 0.019920
2021-12-03 14:35:13,673 iteration 1532 : loss : 0.044455, loss_ce: 0.015885
2021-12-03 14:35:15,155 iteration 1533 : loss : 0.029341, loss_ce: 0.012633
2021-12-03 14:35:16,731 iteration 1534 : loss : 0.055464, loss_ce: 0.019269
2021-12-03 14:35:18,238 iteration 1535 : loss : 0.040934, loss_ce: 0.015321
2021-12-03 14:35:19,728 iteration 1536 : loss : 0.051899, loss_ce: 0.028193
2021-12-03 14:35:21,219 iteration 1537 : loss : 0.056292, loss_ce: 0.019250
2021-12-03 14:35:22,687 iteration 1538 : loss : 0.131308, loss_ce: 0.026724
2021-12-03 14:35:24,194 iteration 1539 : loss : 0.037986, loss_ce: 0.015365
2021-12-03 14:35:25,711 iteration 1540 : loss : 0.054005, loss_ce: 0.025796
2021-12-03 14:35:27,149 iteration 1541 : loss : 0.032472, loss_ce: 0.010857
2021-12-03 14:35:28,675 iteration 1542 : loss : 0.050100, loss_ce: 0.020781
2021-12-03 14:35:30,181 iteration 1543 : loss : 0.043964, loss_ce: 0.014591
2021-12-03 14:35:31,630 iteration 1544 : loss : 0.043332, loss_ce: 0.016377
2021-12-03 14:35:33,157 iteration 1545 : loss : 0.053401, loss_ce: 0.027118
2021-12-03 14:35:34,660 iteration 1546 : loss : 0.039720, loss_ce: 0.016147
2021-12-03 14:35:36,160 iteration 1547 : loss : 0.050182, loss_ce: 0.017349
 61%|███████████████████▍            | 91/150 [42:55<28:09, 28.64s/it]2021-12-03 14:35:37,731 iteration 1548 : loss : 0.042534, loss_ce: 0.014350
2021-12-03 14:35:39,192 iteration 1549 : loss : 0.034694, loss_ce: 0.014052
2021-12-03 14:35:40,798 iteration 1550 : loss : 0.061127, loss_ce: 0.026379
2021-12-03 14:35:42,317 iteration 1551 : loss : 0.041250, loss_ce: 0.016001
2021-12-03 14:35:43,841 iteration 1552 : loss : 0.032705, loss_ce: 0.014910
2021-12-03 14:35:45,278 iteration 1553 : loss : 0.031805, loss_ce: 0.016743
2021-12-03 14:35:46,757 iteration 1554 : loss : 0.060897, loss_ce: 0.021868
2021-12-03 14:35:48,328 iteration 1555 : loss : 0.042405, loss_ce: 0.015569
2021-12-03 14:35:49,962 iteration 1556 : loss : 0.050798, loss_ce: 0.020330
2021-12-03 14:35:51,549 iteration 1557 : loss : 0.100361, loss_ce: 0.030647
2021-12-03 14:35:53,078 iteration 1558 : loss : 0.047002, loss_ce: 0.014427
2021-12-03 14:35:54,701 iteration 1559 : loss : 0.046612, loss_ce: 0.024096
2021-12-03 14:35:56,201 iteration 1560 : loss : 0.043860, loss_ce: 0.013550
2021-12-03 14:35:57,710 iteration 1561 : loss : 0.047973, loss_ce: 0.018421
2021-12-03 14:35:59,232 iteration 1562 : loss : 0.047167, loss_ce: 0.020426
2021-12-03 14:36:00,739 iteration 1563 : loss : 0.043226, loss_ce: 0.021254
2021-12-03 14:36:02,268 iteration 1564 : loss : 0.042298, loss_ce: 0.012855
 61%|███████████████████▋            | 92/150 [43:21<26:57, 27.88s/it]2021-12-03 14:36:03,872 iteration 1565 : loss : 0.055554, loss_ce: 0.019216
2021-12-03 14:36:05,372 iteration 1566 : loss : 0.059715, loss_ce: 0.025212
2021-12-03 14:36:06,922 iteration 1567 : loss : 0.055607, loss_ce: 0.014258
2021-12-03 14:36:08,559 iteration 1568 : loss : 0.043870, loss_ce: 0.018339
2021-12-03 14:36:10,052 iteration 1569 : loss : 0.043194, loss_ce: 0.017712
2021-12-03 14:36:11,610 iteration 1570 : loss : 0.036486, loss_ce: 0.014559
2021-12-03 14:36:13,111 iteration 1571 : loss : 0.035795, loss_ce: 0.015325
2021-12-03 14:36:14,632 iteration 1572 : loss : 0.060024, loss_ce: 0.027342
2021-12-03 14:36:16,163 iteration 1573 : loss : 0.083440, loss_ce: 0.023518
2021-12-03 14:36:17,690 iteration 1574 : loss : 0.044291, loss_ce: 0.021190
2021-12-03 14:36:19,244 iteration 1575 : loss : 0.062353, loss_ce: 0.027084
2021-12-03 14:36:20,753 iteration 1576 : loss : 0.043713, loss_ce: 0.015075
2021-12-03 14:36:22,230 iteration 1577 : loss : 0.050971, loss_ce: 0.015897
2021-12-03 14:36:23,661 iteration 1578 : loss : 0.043669, loss_ce: 0.017822
2021-12-03 14:36:25,159 iteration 1579 : loss : 0.042579, loss_ce: 0.018189
2021-12-03 14:36:26,700 iteration 1580 : loss : 0.049812, loss_ce: 0.016569
2021-12-03 14:36:28,237 iteration 1581 : loss : 0.037900, loss_ce: 0.014665
 62%|███████████████████▊            | 93/150 [43:47<25:56, 27.31s/it]2021-12-03 14:36:29,857 iteration 1582 : loss : 0.039562, loss_ce: 0.017170
2021-12-03 14:36:31,386 iteration 1583 : loss : 0.077254, loss_ce: 0.034338
2021-12-03 14:36:32,862 iteration 1584 : loss : 0.050158, loss_ce: 0.018645
2021-12-03 14:36:34,367 iteration 1585 : loss : 0.032102, loss_ce: 0.013913
2021-12-03 14:36:35,813 iteration 1586 : loss : 0.036258, loss_ce: 0.016722
2021-12-03 14:36:37,312 iteration 1587 : loss : 0.042090, loss_ce: 0.014999
2021-12-03 14:36:38,811 iteration 1588 : loss : 0.038964, loss_ce: 0.012229
2021-12-03 14:36:40,342 iteration 1589 : loss : 0.046126, loss_ce: 0.020776
2021-12-03 14:36:41,936 iteration 1590 : loss : 0.056565, loss_ce: 0.018367
2021-12-03 14:36:43,429 iteration 1591 : loss : 0.037053, loss_ce: 0.017325
2021-12-03 14:36:44,860 iteration 1592 : loss : 0.031318, loss_ce: 0.013315
2021-12-03 14:36:46,383 iteration 1593 : loss : 0.046623, loss_ce: 0.016702
2021-12-03 14:36:47,884 iteration 1594 : loss : 0.040094, loss_ce: 0.013046
2021-12-03 14:36:49,346 iteration 1595 : loss : 0.045554, loss_ce: 0.023221
2021-12-03 14:36:50,780 iteration 1596 : loss : 0.040912, loss_ce: 0.013606
2021-12-03 14:36:52,307 iteration 1597 : loss : 0.068632, loss_ce: 0.016930
2021-12-03 14:36:53,851 iteration 1598 : loss : 0.047598, loss_ce: 0.018296
 63%|████████████████████            | 94/150 [44:13<25:00, 26.80s/it]2021-12-03 14:36:55,469 iteration 1599 : loss : 0.044744, loss_ce: 0.021577
2021-12-03 14:36:56,968 iteration 1600 : loss : 0.034270, loss_ce: 0.015358
2021-12-03 14:36:58,520 iteration 1601 : loss : 0.040663, loss_ce: 0.014437
2021-12-03 14:37:00,049 iteration 1602 : loss : 0.059476, loss_ce: 0.023698
2021-12-03 14:37:01,556 iteration 1603 : loss : 0.035473, loss_ce: 0.012847
2021-12-03 14:37:03,047 iteration 1604 : loss : 0.056664, loss_ce: 0.017333
2021-12-03 14:37:04,545 iteration 1605 : loss : 0.050082, loss_ce: 0.020234
2021-12-03 14:37:06,098 iteration 1606 : loss : 0.033111, loss_ce: 0.013134
2021-12-03 14:37:07,605 iteration 1607 : loss : 0.037967, loss_ce: 0.014482
2021-12-03 14:37:09,215 iteration 1608 : loss : 0.042651, loss_ce: 0.018217
2021-12-03 14:37:10,711 iteration 1609 : loss : 0.036046, loss_ce: 0.015200
2021-12-03 14:37:12,314 iteration 1610 : loss : 0.047342, loss_ce: 0.020502
2021-12-03 14:37:13,916 iteration 1611 : loss : 0.042311, loss_ce: 0.021336
2021-12-03 14:37:15,534 iteration 1612 : loss : 0.038165, loss_ce: 0.013537
2021-12-03 14:37:17,065 iteration 1613 : loss : 0.037031, loss_ce: 0.013254
2021-12-03 14:37:18,644 iteration 1614 : loss : 0.054033, loss_ce: 0.023543
2021-12-03 14:37:18,644 Training Data Eval:
2021-12-03 14:37:26,172   Average segmentation loss on training set: 0.0288
2021-12-03 14:37:26,173 Validation Data Eval:
2021-12-03 14:37:28,774   Average segmentation loss on validation set: 0.1111
2021-12-03 14:37:30,338 iteration 1615 : loss : 0.046514, loss_ce: 0.015947
 63%|████████████████████▎           | 95/150 [44:49<27:13, 29.71s/it]2021-12-03 14:37:31,940 iteration 1616 : loss : 0.039961, loss_ce: 0.014217
2021-12-03 14:37:33,441 iteration 1617 : loss : 0.052621, loss_ce: 0.024593
2021-12-03 14:37:34,921 iteration 1618 : loss : 0.040092, loss_ce: 0.013717
2021-12-03 14:37:36,425 iteration 1619 : loss : 0.041802, loss_ce: 0.024831
2021-12-03 14:37:38,073 iteration 1620 : loss : 0.045784, loss_ce: 0.016818
2021-12-03 14:37:39,698 iteration 1621 : loss : 0.061105, loss_ce: 0.024716
2021-12-03 14:37:41,224 iteration 1622 : loss : 0.046783, loss_ce: 0.016716
2021-12-03 14:37:42,700 iteration 1623 : loss : 0.035957, loss_ce: 0.011880
2021-12-03 14:37:44,239 iteration 1624 : loss : 0.033564, loss_ce: 0.012585
2021-12-03 14:37:45,697 iteration 1625 : loss : 0.044559, loss_ce: 0.014253
2021-12-03 14:37:47,196 iteration 1626 : loss : 0.039086, loss_ce: 0.016295
2021-12-03 14:37:48,826 iteration 1627 : loss : 0.050229, loss_ce: 0.020239
2021-12-03 14:37:50,440 iteration 1628 : loss : 0.046248, loss_ce: 0.017644
2021-12-03 14:37:51,934 iteration 1629 : loss : 0.039309, loss_ce: 0.014598
2021-12-03 14:37:53,411 iteration 1630 : loss : 0.025348, loss_ce: 0.010375
2021-12-03 14:37:54,888 iteration 1631 : loss : 0.043436, loss_ce: 0.013773
2021-12-03 14:37:56,379 iteration 1632 : loss : 0.034400, loss_ce: 0.014024
 64%|████████████████████▍           | 96/150 [45:15<25:44, 28.60s/it]2021-12-03 14:37:57,957 iteration 1633 : loss : 0.047992, loss_ce: 0.016384
2021-12-03 14:37:59,499 iteration 1634 : loss : 0.059221, loss_ce: 0.024675
2021-12-03 14:38:00,997 iteration 1635 : loss : 0.045784, loss_ce: 0.015387
2021-12-03 14:38:02,446 iteration 1636 : loss : 0.034060, loss_ce: 0.016219
2021-12-03 14:38:03,992 iteration 1637 : loss : 0.036463, loss_ce: 0.013219
2021-12-03 14:38:05,506 iteration 1638 : loss : 0.039531, loss_ce: 0.018323
2021-12-03 14:38:07,103 iteration 1639 : loss : 0.040605, loss_ce: 0.018623
2021-12-03 14:38:08,588 iteration 1640 : loss : 0.040308, loss_ce: 0.013716
2021-12-03 14:38:10,200 iteration 1641 : loss : 0.042261, loss_ce: 0.015980
2021-12-03 14:38:11,666 iteration 1642 : loss : 0.037179, loss_ce: 0.013029
2021-12-03 14:38:13,125 iteration 1643 : loss : 0.043246, loss_ce: 0.014816
2021-12-03 14:38:14,698 iteration 1644 : loss : 0.044988, loss_ce: 0.018302
2021-12-03 14:38:16,303 iteration 1645 : loss : 0.038715, loss_ce: 0.016960
2021-12-03 14:38:17,788 iteration 1646 : loss : 0.044293, loss_ce: 0.014607
2021-12-03 14:38:19,287 iteration 1647 : loss : 0.051280, loss_ce: 0.016553
2021-12-03 14:38:20,718 iteration 1648 : loss : 0.031525, loss_ce: 0.012975
2021-12-03 14:38:22,176 iteration 1649 : loss : 0.028315, loss_ce: 0.011438
 65%|████████████████████▋           | 97/150 [45:41<24:31, 27.76s/it]2021-12-03 14:38:23,870 iteration 1650 : loss : 0.062887, loss_ce: 0.036211
2021-12-03 14:38:25,374 iteration 1651 : loss : 0.057341, loss_ce: 0.016075
2021-12-03 14:38:26,907 iteration 1652 : loss : 0.048239, loss_ce: 0.014585
2021-12-03 14:38:28,400 iteration 1653 : loss : 0.041542, loss_ce: 0.013055
2021-12-03 14:38:29,899 iteration 1654 : loss : 0.039651, loss_ce: 0.012950
2021-12-03 14:38:31,374 iteration 1655 : loss : 0.043967, loss_ce: 0.017534
2021-12-03 14:38:32,935 iteration 1656 : loss : 0.051131, loss_ce: 0.020753
2021-12-03 14:38:34,437 iteration 1657 : loss : 0.038887, loss_ce: 0.016228
2021-12-03 14:38:36,017 iteration 1658 : loss : 0.061438, loss_ce: 0.036274
2021-12-03 14:38:37,613 iteration 1659 : loss : 0.044819, loss_ce: 0.017922
2021-12-03 14:38:39,161 iteration 1660 : loss : 0.034835, loss_ce: 0.012824
2021-12-03 14:38:40,630 iteration 1661 : loss : 0.039958, loss_ce: 0.012425
2021-12-03 14:38:42,205 iteration 1662 : loss : 0.047702, loss_ce: 0.015368
2021-12-03 14:38:43,789 iteration 1663 : loss : 0.034361, loss_ce: 0.015160
2021-12-03 14:38:45,313 iteration 1664 : loss : 0.055341, loss_ce: 0.021010
2021-12-03 14:38:46,810 iteration 1665 : loss : 0.038316, loss_ce: 0.017482
2021-12-03 14:38:48,346 iteration 1666 : loss : 0.041729, loss_ce: 0.012771
 65%|████████████████████▉           | 98/150 [46:07<23:38, 27.28s/it]2021-12-03 14:38:49,875 iteration 1667 : loss : 0.034830, loss_ce: 0.016398
2021-12-03 14:38:51,473 iteration 1668 : loss : 0.049797, loss_ce: 0.017004
2021-12-03 14:38:53,028 iteration 1669 : loss : 0.048310, loss_ce: 0.018586
2021-12-03 14:38:54,479 iteration 1670 : loss : 0.027470, loss_ce: 0.009557
2021-12-03 14:38:55,935 iteration 1671 : loss : 0.033385, loss_ce: 0.014925
2021-12-03 14:38:57,511 iteration 1672 : loss : 0.039652, loss_ce: 0.013614
2021-12-03 14:38:59,072 iteration 1673 : loss : 0.045599, loss_ce: 0.012986
2021-12-03 14:39:00,686 iteration 1674 : loss : 0.046552, loss_ce: 0.017834
2021-12-03 14:39:02,179 iteration 1675 : loss : 0.045482, loss_ce: 0.013592
2021-12-03 14:39:03,762 iteration 1676 : loss : 0.048196, loss_ce: 0.026986
2021-12-03 14:39:05,304 iteration 1677 : loss : 0.075814, loss_ce: 0.019030
2021-12-03 14:39:06,875 iteration 1678 : loss : 0.041695, loss_ce: 0.020064
2021-12-03 14:39:08,380 iteration 1679 : loss : 0.070506, loss_ce: 0.034914
2021-12-03 14:39:09,928 iteration 1680 : loss : 0.056835, loss_ce: 0.030549
2021-12-03 14:39:11,436 iteration 1681 : loss : 0.038835, loss_ce: 0.015627
2021-12-03 14:39:12,967 iteration 1682 : loss : 0.051874, loss_ce: 0.025319
2021-12-03 14:39:14,464 iteration 1683 : loss : 0.043100, loss_ce: 0.021400
 66%|█████████████████████           | 99/150 [46:33<22:53, 26.94s/it]2021-12-03 14:39:16,070 iteration 1684 : loss : 0.074964, loss_ce: 0.030925
2021-12-03 14:39:17,577 iteration 1685 : loss : 0.048479, loss_ce: 0.023353
2021-12-03 14:39:19,024 iteration 1686 : loss : 0.033737, loss_ce: 0.012001
2021-12-03 14:39:20,510 iteration 1687 : loss : 0.034182, loss_ce: 0.013831
2021-12-03 14:39:22,032 iteration 1688 : loss : 0.039093, loss_ce: 0.017694
2021-12-03 14:39:23,511 iteration 1689 : loss : 0.038312, loss_ce: 0.012858
2021-12-03 14:39:25,054 iteration 1690 : loss : 0.064648, loss_ce: 0.026440
2021-12-03 14:39:26,558 iteration 1691 : loss : 0.033041, loss_ce: 0.014085
