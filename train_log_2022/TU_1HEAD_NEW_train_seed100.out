2022-01-15 19:10:52,056 Logging directory: /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/TransUNet/log_dir/trRUNMC_cv1_r3/i2i2l/
2022-01-15 19:10:52,056 Tensorboard directory: /scratch_net/biwidl217_second/arismu/Tensorboard/trRUNMC_cv1_r3/i2i2l/
2022-01-15 19:10:52,056 ============================================================
2022-01-15 19:10:52,056 EXPERIMENT NAME: trRUNMC_cv1_r3/i2i2l/
2022-01-15 19:10:52,056 ============================================================
2022-01-15 19:10:52,056 Loading data...
2022-01-15 19:10:52,056 Reading NCI - RUNMC images...
2022-01-15 19:10:52,056 Data root directory: /itet-stor/arismu/bmicdatasets-originals/Originals/Challenge_Datasets/NCI_Prostate/
2022-01-15 19:10:52,059 Already preprocessed this configuration. Loading now!
2022-01-15 19:10:52,083 Training Images: (256, 256, 286)
2022-01-15 19:10:52,083 Training Labels: (256, 256, 286)
2022-01-15 19:10:52,083 Validation Images: (256, 256, 98)
2022-01-15 19:10:52,083 Validation Labels: (256, 256, 98)
2022-01-15 19:10:52,084 ============================================================
2022-01-15 19:10:52,130 17 iterations per epoch. 6800 max iterations 
  0%|                                         | 0/400 [00:00<?, ?it/s]2022-01-15 19:10:55,471 iteration 1 : loss : 0.931038, loss_ce: 1.134971
2022-01-15 19:10:56,454 iteration 2 : loss : 0.905039, loss_ce: 1.076273
2022-01-15 19:10:57,403 iteration 3 : loss : 0.849848, loss_ce: 0.966534
2022-01-15 19:10:58,420 iteration 4 : loss : 0.775794, loss_ce: 0.881317
2022-01-15 19:10:59,337 iteration 5 : loss : 0.749187, loss_ce: 0.809597
2022-01-15 19:11:00,400 iteration 6 : loss : 0.702574, loss_ce: 0.737091
2022-01-15 19:11:01,420 iteration 7 : loss : 0.674381, loss_ce: 0.682567
2022-01-15 19:11:02,425 iteration 8 : loss : 0.619740, loss_ce: 0.609335
2022-01-15 19:11:03,299 iteration 9 : loss : 0.570898, loss_ce: 0.561429
2022-01-15 19:11:04,330 iteration 10 : loss : 0.545761, loss_ce: 0.508870
2022-01-15 19:11:05,374 iteration 11 : loss : 0.513235, loss_ce: 0.461053
2022-01-15 19:11:06,455 iteration 12 : loss : 0.488602, loss_ce: 0.431504
2022-01-15 19:11:07,416 iteration 13 : loss : 0.463984, loss_ce: 0.382742
2022-01-15 19:11:08,501 iteration 14 : loss : 0.443910, loss_ce: 0.356655
2022-01-15 19:11:09,497 iteration 15 : loss : 0.424944, loss_ce: 0.323331
2022-01-15 19:11:10,466 iteration 16 : loss : 0.420387, loss_ce: 0.308785
2022-01-15 19:11:11,398 iteration 17 : loss : 0.423476, loss_ce: 0.277010
  0%|                               | 1/400 [00:19<2:08:45, 19.36s/it]2022-01-15 19:11:12,519 iteration 18 : loss : 0.378465, loss_ce: 0.259549
2022-01-15 19:11:13,541 iteration 19 : loss : 0.384347, loss_ce: 0.227933
2022-01-15 19:11:14,678 iteration 20 : loss : 0.372627, loss_ce: 0.244858
2022-01-15 19:11:15,644 iteration 21 : loss : 0.383016, loss_ce: 0.221873
2022-01-15 19:11:16,544 iteration 22 : loss : 0.361648, loss_ce: 0.204011
2022-01-15 19:11:17,607 iteration 23 : loss : 0.347050, loss_ce: 0.194657
2022-01-15 19:11:18,660 iteration 24 : loss : 0.320596, loss_ce: 0.182060
2022-01-15 19:11:19,745 iteration 25 : loss : 0.365926, loss_ce: 0.223741
2022-01-15 19:11:20,731 iteration 26 : loss : 0.307599, loss_ce: 0.172824
2022-01-15 19:11:21,653 iteration 27 : loss : 0.322874, loss_ce: 0.168047
2022-01-15 19:11:22,557 iteration 28 : loss : 0.282123, loss_ce: 0.140554
2022-01-15 19:11:23,580 iteration 29 : loss : 0.328979, loss_ce: 0.176184
2022-01-15 19:11:24,519 iteration 30 : loss : 0.285684, loss_ce: 0.144992
2022-01-15 19:11:25,436 iteration 31 : loss : 0.275968, loss_ce: 0.122004
2022-01-15 19:11:26,405 iteration 32 : loss : 0.297615, loss_ce: 0.164750
2022-01-15 19:11:27,436 iteration 33 : loss : 0.288006, loss_ce: 0.144609
2022-01-15 19:11:28,549 iteration 34 : loss : 0.241628, loss_ce: 0.113751
  0%|▏                              | 2/400 [00:36<1:59:42, 18.05s/it]2022-01-15 19:11:29,646 iteration 35 : loss : 0.251308, loss_ce: 0.128107
2022-01-15 19:11:30,653 iteration 36 : loss : 0.282661, loss_ce: 0.106827
2022-01-15 19:11:31,690 iteration 37 : loss : 0.270209, loss_ce: 0.117906
2022-01-15 19:11:32,689 iteration 38 : loss : 0.274396, loss_ce: 0.125210
2022-01-15 19:11:33,564 iteration 39 : loss : 0.307775, loss_ce: 0.147013
2022-01-15 19:11:34,521 iteration 40 : loss : 0.323899, loss_ce: 0.159307
2022-01-15 19:11:35,385 iteration 41 : loss : 0.250952, loss_ce: 0.119530
2022-01-15 19:11:36,404 iteration 42 : loss : 0.315349, loss_ce: 0.158645
2022-01-15 19:11:37,396 iteration 43 : loss : 0.225043, loss_ce: 0.103772
2022-01-15 19:11:38,269 iteration 44 : loss : 0.275321, loss_ce: 0.146359
2022-01-15 19:11:39,336 iteration 45 : loss : 0.286484, loss_ce: 0.122871
2022-01-15 19:11:40,333 iteration 46 : loss : 0.255298, loss_ce: 0.118666
2022-01-15 19:11:41,324 iteration 47 : loss : 0.265513, loss_ce: 0.109736
2022-01-15 19:11:42,316 iteration 48 : loss : 0.236219, loss_ce: 0.112878
2022-01-15 19:11:43,374 iteration 49 : loss : 0.325037, loss_ce: 0.152275
2022-01-15 19:11:44,432 iteration 50 : loss : 0.247372, loss_ce: 0.109927
2022-01-15 19:11:45,508 iteration 51 : loss : 0.226908, loss_ce: 0.096028
  1%|▏                              | 3/400 [00:53<1:56:06, 17.55s/it]2022-01-15 19:11:46,492 iteration 52 : loss : 0.277569, loss_ce: 0.108871
2022-01-15 19:11:47,381 iteration 53 : loss : 0.240265, loss_ce: 0.112162
2022-01-15 19:11:48,441 iteration 54 : loss : 0.273798, loss_ce: 0.116125
2022-01-15 19:11:49,472 iteration 55 : loss : 0.323005, loss_ce: 0.127942
2022-01-15 19:11:50,512 iteration 56 : loss : 0.270752, loss_ce: 0.131843
2022-01-15 19:11:51,456 iteration 57 : loss : 0.290027, loss_ce: 0.146101
2022-01-15 19:11:52,344 iteration 58 : loss : 0.260920, loss_ce: 0.130047
2022-01-15 19:11:53,230 iteration 59 : loss : 0.257367, loss_ce: 0.118336
2022-01-15 19:11:54,147 iteration 60 : loss : 0.235507, loss_ce: 0.109991
2022-01-15 19:11:55,075 iteration 61 : loss : 0.244565, loss_ce: 0.112774
2022-01-15 19:11:56,091 iteration 62 : loss : 0.285742, loss_ce: 0.113606
2022-01-15 19:11:56,997 iteration 63 : loss : 0.263889, loss_ce: 0.125989
2022-01-15 19:11:57,983 iteration 64 : loss : 0.288844, loss_ce: 0.115698
2022-01-15 19:11:58,960 iteration 65 : loss : 0.268885, loss_ce: 0.100071
2022-01-15 19:11:59,994 iteration 66 : loss : 0.268970, loss_ce: 0.109232
2022-01-15 19:12:00,940 iteration 67 : loss : 0.231109, loss_ce: 0.101732
2022-01-15 19:12:01,833 iteration 68 : loss : 0.228228, loss_ce: 0.097525
  1%|▎                              | 4/400 [01:09<1:52:37, 17.06s/it]2022-01-15 19:12:02,913 iteration 69 : loss : 0.273565, loss_ce: 0.115339
2022-01-15 19:12:03,868 iteration 70 : loss : 0.270450, loss_ce: 0.108129
2022-01-15 19:12:04,845 iteration 71 : loss : 0.299135, loss_ce: 0.167233
2022-01-15 19:12:05,842 iteration 72 : loss : 0.244188, loss_ce: 0.114538
2022-01-15 19:12:06,843 iteration 73 : loss : 0.236042, loss_ce: 0.096207
2022-01-15 19:12:07,825 iteration 74 : loss : 0.221409, loss_ce: 0.096209
2022-01-15 19:12:08,770 iteration 75 : loss : 0.218225, loss_ce: 0.103538
2022-01-15 19:12:09,657 iteration 76 : loss : 0.236120, loss_ce: 0.104497
2022-01-15 19:12:10,655 iteration 77 : loss : 0.260860, loss_ce: 0.107858
2022-01-15 19:12:11,630 iteration 78 : loss : 0.243804, loss_ce: 0.091828
2022-01-15 19:12:12,630 iteration 79 : loss : 0.249731, loss_ce: 0.097288
2022-01-15 19:12:13,500 iteration 80 : loss : 0.247479, loss_ce: 0.091050
2022-01-15 19:12:14,543 iteration 81 : loss : 0.262718, loss_ce: 0.113559
2022-01-15 19:12:15,490 iteration 82 : loss : 0.279281, loss_ce: 0.098903
2022-01-15 19:12:16,418 iteration 83 : loss : 0.304369, loss_ce: 0.101228
2022-01-15 19:12:17,527 iteration 84 : loss : 0.315906, loss_ce: 0.146635
2022-01-15 19:12:17,527 Training Data Eval:
2022-01-15 19:12:22,257   Average segmentation loss on training set: 0.6176
2022-01-15 19:12:22,257 Validation Data Eval:
2022-01-15 19:12:24,083   Average segmentation loss on validation set: 0.6001
2022-01-15 19:12:24,967 Found new lowest validation loss at iteration 84! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_1HEAD_NEW_best_val_loss_seed100.pth
2022-01-15 19:12:25,879 iteration 85 : loss : 0.303813, loss_ce: 0.141105
  1%|▍                              | 5/400 [01:33<2:08:56, 19.59s/it]2022-01-15 19:12:26,982 iteration 86 : loss : 0.255301, loss_ce: 0.116006
2022-01-15 19:12:27,944 iteration 87 : loss : 0.229210, loss_ce: 0.094887
2022-01-15 19:12:28,879 iteration 88 : loss : 0.204801, loss_ce: 0.097547
2022-01-15 19:12:29,907 iteration 89 : loss : 0.282654, loss_ce: 0.111094
2022-01-15 19:12:30,903 iteration 90 : loss : 0.228804, loss_ce: 0.098379
2022-01-15 19:12:31,964 iteration 91 : loss : 0.227113, loss_ce: 0.103498
2022-01-15 19:12:33,038 iteration 92 : loss : 0.201762, loss_ce: 0.071562
2022-01-15 19:12:33,963 iteration 93 : loss : 0.217105, loss_ce: 0.074542
2022-01-15 19:12:35,009 iteration 94 : loss : 0.223761, loss_ce: 0.101618
2022-01-15 19:12:35,998 iteration 95 : loss : 0.270955, loss_ce: 0.134119
2022-01-15 19:12:37,073 iteration 96 : loss : 0.217465, loss_ce: 0.087596
2022-01-15 19:12:38,069 iteration 97 : loss : 0.264106, loss_ce: 0.105931
2022-01-15 19:12:39,118 iteration 98 : loss : 0.301474, loss_ce: 0.127659
2022-01-15 19:12:40,109 iteration 99 : loss : 0.249496, loss_ce: 0.101121
2022-01-15 19:12:41,147 iteration 100 : loss : 0.214665, loss_ce: 0.091096
2022-01-15 19:12:42,115 iteration 101 : loss : 0.236987, loss_ce: 0.096300
2022-01-15 19:12:43,085 iteration 102 : loss : 0.245210, loss_ce: 0.114275
  2%|▍                              | 6/400 [01:51<2:03:16, 18.77s/it]2022-01-15 19:12:44,195 iteration 103 : loss : 0.243843, loss_ce: 0.086573
2022-01-15 19:12:45,272 iteration 104 : loss : 0.217792, loss_ce: 0.088626
2022-01-15 19:12:46,339 iteration 105 : loss : 0.182428, loss_ce: 0.070071
2022-01-15 19:12:47,504 iteration 106 : loss : 0.235613, loss_ce: 0.093667
2022-01-15 19:12:48,563 iteration 107 : loss : 0.240260, loss_ce: 0.080011
2022-01-15 19:12:51,115 iteration 108 : loss : 0.249253, loss_ce: 0.080661
2022-01-15 19:12:52,018 iteration 109 : loss : 0.291236, loss_ce: 0.128472
2022-01-15 19:12:52,965 iteration 110 : loss : 0.217584, loss_ce: 0.095005
2022-01-15 19:12:54,035 iteration 111 : loss : 0.194901, loss_ce: 0.085977
2022-01-15 19:12:55,023 iteration 112 : loss : 0.217707, loss_ce: 0.080484
2022-01-15 19:12:55,937 iteration 113 : loss : 0.202550, loss_ce: 0.076082
2022-01-15 19:12:56,978 iteration 114 : loss : 0.213082, loss_ce: 0.078921
2022-01-15 19:12:57,943 iteration 115 : loss : 0.178888, loss_ce: 0.082177
2022-01-15 19:12:58,975 iteration 116 : loss : 0.236174, loss_ce: 0.111675
2022-01-15 19:12:59,924 iteration 117 : loss : 0.199593, loss_ce: 0.078524
2022-01-15 19:13:00,893 iteration 118 : loss : 0.259191, loss_ce: 0.119251
2022-01-15 19:13:01,891 iteration 119 : loss : 0.170060, loss_ce: 0.057012
  2%|▌                              | 7/400 [02:09<2:03:02, 18.79s/it]2022-01-15 19:13:03,042 iteration 120 : loss : 0.197827, loss_ce: 0.079154
2022-01-15 19:13:04,106 iteration 121 : loss : 0.255789, loss_ce: 0.104298
2022-01-15 19:13:05,044 iteration 122 : loss : 0.216426, loss_ce: 0.098809
2022-01-15 19:13:06,125 iteration 123 : loss : 0.222568, loss_ce: 0.101047
2022-01-15 19:13:07,201 iteration 124 : loss : 0.264636, loss_ce: 0.106521
2022-01-15 19:13:08,208 iteration 125 : loss : 0.192108, loss_ce: 0.093864
2022-01-15 19:13:09,277 iteration 126 : loss : 0.221972, loss_ce: 0.079857
2022-01-15 19:13:10,360 iteration 127 : loss : 0.197967, loss_ce: 0.079806
2022-01-15 19:13:11,454 iteration 128 : loss : 0.150352, loss_ce: 0.062781
2022-01-15 19:13:12,426 iteration 129 : loss : 0.208528, loss_ce: 0.077688
2022-01-15 19:13:13,509 iteration 130 : loss : 0.230406, loss_ce: 0.107922
2022-01-15 19:13:14,513 iteration 131 : loss : 0.221945, loss_ce: 0.105908
2022-01-15 19:13:15,467 iteration 132 : loss : 0.211887, loss_ce: 0.082645
2022-01-15 19:13:16,550 iteration 133 : loss : 0.225310, loss_ce: 0.079009
2022-01-15 19:13:17,566 iteration 134 : loss : 0.220577, loss_ce: 0.086209
2022-01-15 19:13:18,597 iteration 135 : loss : 0.222830, loss_ce: 0.096733
2022-01-15 19:13:19,588 iteration 136 : loss : 0.230616, loss_ce: 0.098881
  2%|▌                              | 8/400 [02:27<2:00:26, 18.44s/it]2022-01-15 19:13:20,573 iteration 137 : loss : 0.161499, loss_ce: 0.057860
2022-01-15 19:13:21,523 iteration 138 : loss : 0.209293, loss_ce: 0.107988
2022-01-15 19:13:22,623 iteration 139 : loss : 0.206954, loss_ce: 0.080524
2022-01-15 19:13:23,756 iteration 140 : loss : 0.233632, loss_ce: 0.093743
2022-01-15 19:13:24,776 iteration 141 : loss : 0.230688, loss_ce: 0.084165
2022-01-15 19:13:25,716 iteration 142 : loss : 0.189540, loss_ce: 0.068547
2022-01-15 19:13:26,664 iteration 143 : loss : 0.204247, loss_ce: 0.083587
2022-01-15 19:13:27,731 iteration 144 : loss : 0.241268, loss_ce: 0.087699
2022-01-15 19:13:28,971 iteration 145 : loss : 0.180423, loss_ce: 0.077360
2022-01-15 19:13:29,938 iteration 146 : loss : 0.201290, loss_ce: 0.077497
2022-01-15 19:13:30,929 iteration 147 : loss : 0.271707, loss_ce: 0.119823
2022-01-15 19:13:31,948 iteration 148 : loss : 0.239335, loss_ce: 0.112628
2022-01-15 19:13:32,991 iteration 149 : loss : 0.215237, loss_ce: 0.081961
2022-01-15 19:13:34,001 iteration 150 : loss : 0.244336, loss_ce: 0.132818
2022-01-15 19:13:35,022 iteration 151 : loss : 0.199658, loss_ce: 0.082572
2022-01-15 19:13:36,121 iteration 152 : loss : 0.189010, loss_ce: 0.081044
2022-01-15 19:13:37,219 iteration 153 : loss : 0.179875, loss_ce: 0.080546
  2%|▋                              | 9/400 [02:45<1:58:30, 18.18s/it]2022-01-15 19:13:38,287 iteration 154 : loss : 0.183421, loss_ce: 0.077218
2022-01-15 19:13:39,323 iteration 155 : loss : 0.227945, loss_ce: 0.097166
2022-01-15 19:13:40,348 iteration 156 : loss : 0.166929, loss_ce: 0.071092
2022-01-15 19:13:41,383 iteration 157 : loss : 0.235692, loss_ce: 0.086438
2022-01-15 19:13:42,408 iteration 158 : loss : 0.211952, loss_ce: 0.094948
2022-01-15 19:13:43,413 iteration 159 : loss : 0.201959, loss_ce: 0.077221
2022-01-15 19:13:44,411 iteration 160 : loss : 0.250367, loss_ce: 0.084681
2022-01-15 19:13:45,453 iteration 161 : loss : 0.180441, loss_ce: 0.077001
2022-01-15 19:13:46,569 iteration 162 : loss : 0.185646, loss_ce: 0.082291
2022-01-15 19:13:47,459 iteration 163 : loss : 0.159546, loss_ce: 0.065921
2022-01-15 19:13:48,530 iteration 164 : loss : 0.179928, loss_ce: 0.069093
2022-01-15 19:13:49,518 iteration 165 : loss : 0.161040, loss_ce: 0.053884
2022-01-15 19:13:50,602 iteration 166 : loss : 0.215144, loss_ce: 0.080126
2022-01-15 19:13:51,683 iteration 167 : loss : 0.179681, loss_ce: 0.073804
2022-01-15 19:13:52,751 iteration 168 : loss : 0.219639, loss_ce: 0.090063
2022-01-15 19:13:53,758 iteration 169 : loss : 0.195951, loss_ce: 0.080794
2022-01-15 19:13:53,758 Training Data Eval:
2022-01-15 19:13:58,482   Average segmentation loss on training set: 0.6520
2022-01-15 19:13:58,482 Validation Data Eval:
2022-01-15 19:14:01,085   Average segmentation loss on validation set: 0.6084
2022-01-15 19:14:02,016 iteration 170 : loss : 0.177081, loss_ce: 0.071637
  2%|▊                             | 10/400 [03:09<2:11:27, 20.23s/it]2022-01-15 19:14:03,098 iteration 171 : loss : 0.180338, loss_ce: 0.076723
2022-01-15 19:14:03,968 iteration 172 : loss : 0.269279, loss_ce: 0.107388
2022-01-15 19:14:04,902 iteration 173 : loss : 0.197112, loss_ce: 0.084751
2022-01-15 19:14:06,006 iteration 174 : loss : 0.261739, loss_ce: 0.115584
2022-01-15 19:14:06,988 iteration 175 : loss : 0.183462, loss_ce: 0.084725
2022-01-15 19:14:08,127 iteration 176 : loss : 0.193727, loss_ce: 0.078712
2022-01-15 19:14:09,152 iteration 177 : loss : 0.247901, loss_ce: 0.088263
2022-01-15 19:14:10,224 iteration 178 : loss : 0.217828, loss_ce: 0.073383
2022-01-15 19:14:11,271 iteration 179 : loss : 0.214536, loss_ce: 0.084573
2022-01-15 19:14:12,326 iteration 180 : loss : 0.220160, loss_ce: 0.072630
2022-01-15 19:14:13,389 iteration 181 : loss : 0.149900, loss_ce: 0.051081
2022-01-15 19:14:14,449 iteration 182 : loss : 0.160514, loss_ce: 0.059348
2022-01-15 19:14:15,524 iteration 183 : loss : 0.141423, loss_ce: 0.052242
2022-01-15 19:14:16,544 iteration 184 : loss : 0.157055, loss_ce: 0.068227
2022-01-15 19:14:17,510 iteration 185 : loss : 0.175860, loss_ce: 0.081043
2022-01-15 19:14:18,471 iteration 186 : loss : 0.186702, loss_ce: 0.083594
2022-01-15 19:14:19,418 iteration 187 : loss : 0.244533, loss_ce: 0.114159
  3%|▊                             | 11/400 [03:27<2:05:31, 19.36s/it]2022-01-15 19:14:20,513 iteration 188 : loss : 0.228092, loss_ce: 0.101436
2022-01-15 19:14:21,587 iteration 189 : loss : 0.187614, loss_ce: 0.075571
2022-01-15 19:14:22,675 iteration 190 : loss : 0.181246, loss_ce: 0.059534
2022-01-15 19:14:23,692 iteration 191 : loss : 0.181591, loss_ce: 0.072313
2022-01-15 19:14:24,585 iteration 192 : loss : 0.176093, loss_ce: 0.074091
2022-01-15 19:14:25,546 iteration 193 : loss : 0.244673, loss_ce: 0.092470
2022-01-15 19:14:26,495 iteration 194 : loss : 0.234212, loss_ce: 0.097154
2022-01-15 19:14:27,620 iteration 195 : loss : 0.164056, loss_ce: 0.059390
2022-01-15 19:14:28,681 iteration 196 : loss : 0.143585, loss_ce: 0.052632
2022-01-15 19:14:29,713 iteration 197 : loss : 0.170590, loss_ce: 0.070739
2022-01-15 19:14:30,774 iteration 198 : loss : 0.246163, loss_ce: 0.106891
2022-01-15 19:14:31,823 iteration 199 : loss : 0.183863, loss_ce: 0.087440
2022-01-15 19:14:32,810 iteration 200 : loss : 0.176114, loss_ce: 0.062150
2022-01-15 19:14:33,811 iteration 201 : loss : 0.193996, loss_ce: 0.079270
2022-01-15 19:14:34,683 iteration 202 : loss : 0.205574, loss_ce: 0.063800
2022-01-15 19:14:35,765 iteration 203 : loss : 0.192649, loss_ce: 0.070800
2022-01-15 19:14:36,758 iteration 204 : loss : 0.228079, loss_ce: 0.110809
  3%|▉                             | 12/400 [03:44<2:01:15, 18.75s/it]2022-01-15 19:14:37,944 iteration 205 : loss : 0.196297, loss_ce: 0.070466
2022-01-15 19:14:38,975 iteration 206 : loss : 0.308893, loss_ce: 0.124529
2022-01-15 19:14:40,085 iteration 207 : loss : 0.244290, loss_ce: 0.101952
2022-01-15 19:14:41,163 iteration 208 : loss : 0.191382, loss_ce: 0.086388
2022-01-15 19:14:42,205 iteration 209 : loss : 0.196265, loss_ce: 0.079706
2022-01-15 19:14:43,204 iteration 210 : loss : 0.188391, loss_ce: 0.089788
2022-01-15 19:14:44,233 iteration 211 : loss : 0.161894, loss_ce: 0.072946
2022-01-15 19:14:45,323 iteration 212 : loss : 0.171899, loss_ce: 0.071715
2022-01-15 19:14:46,410 iteration 213 : loss : 0.197802, loss_ce: 0.089999
2022-01-15 19:14:47,400 iteration 214 : loss : 0.210649, loss_ce: 0.079270
2022-01-15 19:14:48,363 iteration 215 : loss : 0.171287, loss_ce: 0.065252
2022-01-15 19:14:49,397 iteration 216 : loss : 0.180476, loss_ce: 0.067141
2022-01-15 19:14:50,444 iteration 217 : loss : 0.177273, loss_ce: 0.067940
2022-01-15 19:14:51,411 iteration 218 : loss : 0.198543, loss_ce: 0.081897
2022-01-15 19:14:52,379 iteration 219 : loss : 0.154576, loss_ce: 0.065366
2022-01-15 19:14:53,383 iteration 220 : loss : 0.134209, loss_ce: 0.049738
2022-01-15 19:14:54,411 iteration 221 : loss : 0.193301, loss_ce: 0.073102
  3%|▉                             | 13/400 [04:02<1:58:45, 18.41s/it]2022-01-15 19:14:55,467 iteration 222 : loss : 0.135161, loss_ce: 0.050984
2022-01-15 19:14:56,422 iteration 223 : loss : 0.278307, loss_ce: 0.123025
2022-01-15 19:14:57,381 iteration 224 : loss : 0.159434, loss_ce: 0.051185
2022-01-15 19:14:58,498 iteration 225 : loss : 0.143098, loss_ce: 0.063599
2022-01-15 19:14:59,513 iteration 226 : loss : 0.170918, loss_ce: 0.062907
2022-01-15 19:15:00,477 iteration 227 : loss : 0.157113, loss_ce: 0.058624
2022-01-15 19:15:01,444 iteration 228 : loss : 0.145718, loss_ce: 0.051185
2022-01-15 19:15:02,466 iteration 229 : loss : 0.205849, loss_ce: 0.074754
2022-01-15 19:15:03,405 iteration 230 : loss : 0.126198, loss_ce: 0.052233
2022-01-15 19:15:04,388 iteration 231 : loss : 0.131626, loss_ce: 0.052854
2022-01-15 19:15:05,356 iteration 232 : loss : 0.155997, loss_ce: 0.066420
2022-01-15 19:15:06,269 iteration 233 : loss : 0.176722, loss_ce: 0.080737
2022-01-15 19:15:07,242 iteration 234 : loss : 0.194996, loss_ce: 0.078445
2022-01-15 19:15:08,187 iteration 235 : loss : 0.177302, loss_ce: 0.072858
2022-01-15 19:15:09,174 iteration 236 : loss : 0.273868, loss_ce: 0.106221
2022-01-15 19:15:10,108 iteration 237 : loss : 0.228778, loss_ce: 0.108524
2022-01-15 19:15:11,172 iteration 238 : loss : 0.198960, loss_ce: 0.068990
  4%|█                             | 14/400 [04:19<1:55:16, 17.92s/it]2022-01-15 19:15:12,233 iteration 239 : loss : 0.188242, loss_ce: 0.065675
2022-01-15 19:15:13,321 iteration 240 : loss : 0.188454, loss_ce: 0.058174
2022-01-15 19:15:14,360 iteration 241 : loss : 0.182070, loss_ce: 0.060049
2022-01-15 19:15:15,340 iteration 242 : loss : 0.114173, loss_ce: 0.042484
2022-01-15 19:15:16,319 iteration 243 : loss : 0.138530, loss_ce: 0.050922
2022-01-15 19:15:17,303 iteration 244 : loss : 0.165346, loss_ce: 0.063997
2022-01-15 19:15:18,242 iteration 245 : loss : 0.165633, loss_ce: 0.052140
2022-01-15 19:15:19,223 iteration 246 : loss : 0.196949, loss_ce: 0.065291
2022-01-15 19:15:20,247 iteration 247 : loss : 0.189124, loss_ce: 0.083503
2022-01-15 19:15:21,275 iteration 248 : loss : 0.136803, loss_ce: 0.063982
2022-01-15 19:15:22,246 iteration 249 : loss : 0.158201, loss_ce: 0.061557
2022-01-15 19:15:23,225 iteration 250 : loss : 0.195031, loss_ce: 0.067000
2022-01-15 19:15:24,160 iteration 251 : loss : 0.142447, loss_ce: 0.058793
2022-01-15 19:15:25,249 iteration 252 : loss : 0.172387, loss_ce: 0.078396
2022-01-15 19:15:26,264 iteration 253 : loss : 0.126206, loss_ce: 0.045933
2022-01-15 19:15:27,249 iteration 254 : loss : 0.139447, loss_ce: 0.061608
2022-01-15 19:15:27,249 Training Data Eval:
2022-01-15 19:15:32,021   Average segmentation loss on training set: 0.2986
2022-01-15 19:15:32,021 Validation Data Eval:
2022-01-15 19:15:33,635   Average segmentation loss on validation set: 0.3662
2022-01-15 19:15:34,530 Found new lowest validation loss at iteration 254! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_1HEAD_NEW_best_val_loss_seed100.pth
2022-01-15 19:15:35,443 iteration 255 : loss : 0.198101, loss_ce: 0.092619
  4%|█▏                            | 15/400 [04:43<2:07:14, 19.83s/it]2022-01-15 19:15:36,396 iteration 256 : loss : 0.148184, loss_ce: 0.066313
2022-01-15 19:15:37,313 iteration 257 : loss : 0.154560, loss_ce: 0.064835
2022-01-15 19:15:38,336 iteration 258 : loss : 0.137770, loss_ce: 0.062643
2022-01-15 19:15:39,325 iteration 259 : loss : 0.182097, loss_ce: 0.075135
2022-01-15 19:15:40,268 iteration 260 : loss : 0.126195, loss_ce: 0.067370
2022-01-15 19:15:41,291 iteration 261 : loss : 0.167921, loss_ce: 0.068301
2022-01-15 19:15:42,322 iteration 262 : loss : 0.204098, loss_ce: 0.092455
2022-01-15 19:15:43,247 iteration 263 : loss : 0.159885, loss_ce: 0.064197
2022-01-15 19:15:44,282 iteration 264 : loss : 0.221867, loss_ce: 0.072075
2022-01-15 19:15:45,373 iteration 265 : loss : 0.209541, loss_ce: 0.096434
2022-01-15 19:15:46,375 iteration 266 : loss : 0.187622, loss_ce: 0.061535
2022-01-15 19:15:47,454 iteration 267 : loss : 0.155630, loss_ce: 0.048801
2022-01-15 19:15:48,453 iteration 268 : loss : 0.165986, loss_ce: 0.054749
2022-01-15 19:15:49,440 iteration 269 : loss : 0.233916, loss_ce: 0.097108
2022-01-15 19:15:50,410 iteration 270 : loss : 0.192832, loss_ce: 0.068911
2022-01-15 19:15:51,383 iteration 271 : loss : 0.154299, loss_ce: 0.065375
2022-01-15 19:15:52,330 iteration 272 : loss : 0.152481, loss_ce: 0.062266
  4%|█▏                            | 16/400 [05:00<2:01:15, 18.95s/it]2022-01-15 19:15:53,452 iteration 273 : loss : 0.195001, loss_ce: 0.076884
2022-01-15 19:15:54,437 iteration 274 : loss : 0.243091, loss_ce: 0.113376
2022-01-15 19:15:55,402 iteration 275 : loss : 0.240357, loss_ce: 0.070218
2022-01-15 19:15:56,367 iteration 276 : loss : 0.119367, loss_ce: 0.046522
2022-01-15 19:15:57,330 iteration 277 : loss : 0.137128, loss_ce: 0.051753
2022-01-15 19:15:58,329 iteration 278 : loss : 0.221501, loss_ce: 0.096677
2022-01-15 19:15:59,313 iteration 279 : loss : 0.187009, loss_ce: 0.077841
2022-01-15 19:16:00,293 iteration 280 : loss : 0.181653, loss_ce: 0.090895
2022-01-15 19:16:01,325 iteration 281 : loss : 0.155566, loss_ce: 0.071558
2022-01-15 19:16:02,332 iteration 282 : loss : 0.114361, loss_ce: 0.040938
2022-01-15 19:16:03,293 iteration 283 : loss : 0.145600, loss_ce: 0.054396
2022-01-15 19:16:04,301 iteration 284 : loss : 0.149578, loss_ce: 0.076496
2022-01-15 19:16:05,328 iteration 285 : loss : 0.157892, loss_ce: 0.051370
2022-01-15 19:16:06,209 iteration 286 : loss : 0.158703, loss_ce: 0.062446
2022-01-15 19:16:07,196 iteration 287 : loss : 0.148403, loss_ce: 0.057769
2022-01-15 19:16:08,208 iteration 288 : loss : 0.146246, loss_ce: 0.059146
2022-01-15 19:16:09,184 iteration 289 : loss : 0.154237, loss_ce: 0.056273
  4%|█▎                            | 17/400 [05:17<1:56:54, 18.32s/it]2022-01-15 19:16:10,279 iteration 290 : loss : 0.168812, loss_ce: 0.069212
2022-01-15 19:16:11,231 iteration 291 : loss : 0.164376, loss_ce: 0.065486
2022-01-15 19:16:12,171 iteration 292 : loss : 0.162946, loss_ce: 0.066954
2022-01-15 19:16:13,220 iteration 293 : loss : 0.134625, loss_ce: 0.049520
2022-01-15 19:16:14,196 iteration 294 : loss : 0.149603, loss_ce: 0.063897
2022-01-15 19:16:15,237 iteration 295 : loss : 0.150358, loss_ce: 0.066952
2022-01-15 19:16:16,290 iteration 296 : loss : 0.171131, loss_ce: 0.067895
2022-01-15 19:16:17,302 iteration 297 : loss : 0.150739, loss_ce: 0.071693
2022-01-15 19:16:18,277 iteration 298 : loss : 0.146565, loss_ce: 0.063693
2022-01-15 19:16:19,199 iteration 299 : loss : 0.203829, loss_ce: 0.082096
2022-01-15 19:16:20,162 iteration 300 : loss : 0.189298, loss_ce: 0.083375
2022-01-15 19:16:21,065 iteration 301 : loss : 0.177260, loss_ce: 0.068070
2022-01-15 19:16:22,121 iteration 302 : loss : 0.170360, loss_ce: 0.067385
2022-01-15 19:16:23,154 iteration 303 : loss : 0.141275, loss_ce: 0.047479
2022-01-15 19:16:24,186 iteration 304 : loss : 0.176229, loss_ce: 0.076129
2022-01-15 19:16:25,144 iteration 305 : loss : 0.109029, loss_ce: 0.045586
2022-01-15 19:16:26,120 iteration 306 : loss : 0.151841, loss_ce: 0.056278
  4%|█▎                            | 18/400 [05:34<1:53:58, 17.90s/it]2022-01-15 19:16:27,093 iteration 307 : loss : 0.179419, loss_ce: 0.067095
2022-01-15 19:16:27,994 iteration 308 : loss : 0.130615, loss_ce: 0.056965
2022-01-15 19:16:28,921 iteration 309 : loss : 0.149788, loss_ce: 0.062041
2022-01-15 19:16:29,923 iteration 310 : loss : 0.171444, loss_ce: 0.070584
2022-01-15 19:16:30,956 iteration 311 : loss : 0.162088, loss_ce: 0.070472
2022-01-15 19:16:32,004 iteration 312 : loss : 0.128330, loss_ce: 0.052297
2022-01-15 19:16:32,960 iteration 313 : loss : 0.152376, loss_ce: 0.060974
2022-01-15 19:16:33,960 iteration 314 : loss : 0.151055, loss_ce: 0.065987
2022-01-15 19:16:35,011 iteration 315 : loss : 0.215652, loss_ce: 0.088825
2022-01-15 19:16:36,013 iteration 316 : loss : 0.174626, loss_ce: 0.066154
2022-01-15 19:16:36,954 iteration 317 : loss : 0.151181, loss_ce: 0.052943
2022-01-15 19:16:37,923 iteration 318 : loss : 0.141947, loss_ce: 0.058625
2022-01-15 19:16:38,995 iteration 319 : loss : 0.127172, loss_ce: 0.048766
2022-01-15 19:16:39,977 iteration 320 : loss : 0.165737, loss_ce: 0.058725
2022-01-15 19:16:40,937 iteration 321 : loss : 0.170622, loss_ce: 0.089258
2022-01-15 19:16:41,957 iteration 322 : loss : 0.153612, loss_ce: 0.061042
2022-01-15 19:16:43,024 iteration 323 : loss : 0.153426, loss_ce: 0.065854
  5%|█▍                            | 19/400 [05:50<1:51:46, 17.60s/it]2022-01-15 19:16:44,044 iteration 324 : loss : 0.180840, loss_ce: 0.066941
2022-01-15 19:16:45,055 iteration 325 : loss : 0.136685, loss_ce: 0.049739
2022-01-15 19:16:46,065 iteration 326 : loss : 0.169806, loss_ce: 0.059928
2022-01-15 19:16:47,169 iteration 327 : loss : 0.167005, loss_ce: 0.063251
2022-01-15 19:16:48,221 iteration 328 : loss : 0.163798, loss_ce: 0.068012
2022-01-15 19:16:49,225 iteration 329 : loss : 0.142151, loss_ce: 0.057400
2022-01-15 19:16:50,126 iteration 330 : loss : 0.131387, loss_ce: 0.052737
2022-01-15 19:16:51,179 iteration 331 : loss : 0.121660, loss_ce: 0.044104
2022-01-15 19:16:52,224 iteration 332 : loss : 0.138351, loss_ce: 0.056173
2022-01-15 19:16:53,152 iteration 333 : loss : 0.148409, loss_ce: 0.056287
2022-01-15 19:16:54,187 iteration 334 : loss : 0.135372, loss_ce: 0.063026
2022-01-15 19:16:55,149 iteration 335 : loss : 0.157832, loss_ce: 0.054218
2022-01-15 19:16:56,191 iteration 336 : loss : 0.152219, loss_ce: 0.055689
2022-01-15 19:16:57,146 iteration 337 : loss : 0.166646, loss_ce: 0.061858
2022-01-15 19:16:58,056 iteration 338 : loss : 0.163435, loss_ce: 0.069613
2022-01-15 19:16:59,042 iteration 339 : loss : 0.141703, loss_ce: 0.048098
2022-01-15 19:16:59,042 Training Data Eval:
2022-01-15 19:17:03,769   Average segmentation loss on training set: 0.1456
2022-01-15 19:17:03,769 Validation Data Eval:
2022-01-15 19:17:05,364   Average segmentation loss on validation set: 0.1448
2022-01-15 19:17:06,249 Found new lowest validation loss at iteration 339! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_1HEAD_NEW_best_val_loss_seed100.pth
2022-01-15 19:17:07,189 iteration 340 : loss : 0.156648, loss_ce: 0.059904
  5%|█▌                            | 20/400 [06:15<2:03:57, 19.57s/it]2022-01-15 19:17:08,262 iteration 341 : loss : 0.169568, loss_ce: 0.069069
2022-01-15 19:17:09,298 iteration 342 : loss : 0.115882, loss_ce: 0.045555
2022-01-15 19:17:10,395 iteration 343 : loss : 0.184238, loss_ce: 0.089864
2022-01-15 19:17:11,351 iteration 344 : loss : 0.175377, loss_ce: 0.057243
2022-01-15 19:17:12,334 iteration 345 : loss : 0.159483, loss_ce: 0.055080
2022-01-15 19:17:13,384 iteration 346 : loss : 0.142922, loss_ce: 0.052812
2022-01-15 19:17:14,333 iteration 347 : loss : 0.141147, loss_ce: 0.060116
2022-01-15 19:17:15,433 iteration 348 : loss : 0.153198, loss_ce: 0.064803
2022-01-15 19:17:16,410 iteration 349 : loss : 0.130588, loss_ce: 0.054138
2022-01-15 19:17:17,305 iteration 350 : loss : 0.106752, loss_ce: 0.034897
2022-01-15 19:17:18,364 iteration 351 : loss : 0.133866, loss_ce: 0.037050
2022-01-15 19:17:19,353 iteration 352 : loss : 0.153105, loss_ce: 0.057803
2022-01-15 19:17:20,448 iteration 353 : loss : 0.138402, loss_ce: 0.044590
2022-01-15 19:17:21,466 iteration 354 : loss : 0.156162, loss_ce: 0.066817
2022-01-15 19:17:22,528 iteration 355 : loss : 0.154572, loss_ce: 0.057997
2022-01-15 19:17:23,469 iteration 356 : loss : 0.174888, loss_ce: 0.068924
2022-01-15 19:17:24,439 iteration 357 : loss : 0.173218, loss_ce: 0.074644
  5%|█▌                            | 21/400 [06:32<1:59:14, 18.88s/it]2022-01-15 19:17:25,591 iteration 358 : loss : 0.171623, loss_ce: 0.063135
2022-01-15 19:17:26,638 iteration 359 : loss : 0.109768, loss_ce: 0.051529
2022-01-15 19:17:27,632 iteration 360 : loss : 0.198948, loss_ce: 0.052899
2022-01-15 19:17:28,656 iteration 361 : loss : 0.166007, loss_ce: 0.056548
2022-01-15 19:17:29,556 iteration 362 : loss : 0.147791, loss_ce: 0.056730
2022-01-15 19:17:30,631 iteration 363 : loss : 0.239857, loss_ce: 0.127420
2022-01-15 19:17:31,636 iteration 364 : loss : 0.170522, loss_ce: 0.087605
2022-01-15 19:17:32,601 iteration 365 : loss : 0.128457, loss_ce: 0.051436
2022-01-15 19:17:33,577 iteration 366 : loss : 0.136117, loss_ce: 0.058166
2022-01-15 19:17:34,610 iteration 367 : loss : 0.164862, loss_ce: 0.074033
2022-01-15 19:17:35,536 iteration 368 : loss : 0.160073, loss_ce: 0.054181
2022-01-15 19:17:36,555 iteration 369 : loss : 0.135793, loss_ce: 0.065981
2022-01-15 19:17:37,459 iteration 370 : loss : 0.173352, loss_ce: 0.051197
2022-01-15 19:17:38,510 iteration 371 : loss : 0.163438, loss_ce: 0.074802
2022-01-15 19:17:39,551 iteration 372 : loss : 0.178123, loss_ce: 0.056136
2022-01-15 19:17:40,560 iteration 373 : loss : 0.135561, loss_ce: 0.047223
2022-01-15 19:17:41,524 iteration 374 : loss : 0.135250, loss_ce: 0.053860
  6%|█▋                            | 22/400 [06:49<1:55:31, 18.34s/it]2022-01-15 19:17:42,611 iteration 375 : loss : 0.157674, loss_ce: 0.056638
2022-01-15 19:17:43,632 iteration 376 : loss : 0.145160, loss_ce: 0.052504
2022-01-15 19:17:44,659 iteration 377 : loss : 0.168860, loss_ce: 0.053922
2022-01-15 19:17:45,672 iteration 378 : loss : 0.186428, loss_ce: 0.080435
2022-01-15 19:17:46,601 iteration 379 : loss : 0.178157, loss_ce: 0.067039
2022-01-15 19:17:47,631 iteration 380 : loss : 0.153866, loss_ce: 0.072243
2022-01-15 19:17:48,528 iteration 381 : loss : 0.101676, loss_ce: 0.035698
2022-01-15 19:17:49,633 iteration 382 : loss : 0.148383, loss_ce: 0.065671
2022-01-15 19:17:50,668 iteration 383 : loss : 0.139154, loss_ce: 0.055661
2022-01-15 19:17:51,652 iteration 384 : loss : 0.124904, loss_ce: 0.050215
2022-01-15 19:17:52,605 iteration 385 : loss : 0.116981, loss_ce: 0.045968
2022-01-15 19:17:53,634 iteration 386 : loss : 0.158967, loss_ce: 0.059763
2022-01-15 19:17:54,651 iteration 387 : loss : 0.194900, loss_ce: 0.072488
2022-01-15 19:17:55,701 iteration 388 : loss : 0.131509, loss_ce: 0.050417
2022-01-15 19:17:56,658 iteration 389 : loss : 0.157923, loss_ce: 0.048385
2022-01-15 19:17:57,684 iteration 390 : loss : 0.146534, loss_ce: 0.073744
2022-01-15 19:17:58,642 iteration 391 : loss : 0.121889, loss_ce: 0.040348
  6%|█▋                            | 23/400 [07:06<1:52:55, 17.97s/it]2022-01-15 19:17:59,827 iteration 392 : loss : 0.129944, loss_ce: 0.055012
2022-01-15 19:18:00,783 iteration 393 : loss : 0.150675, loss_ce: 0.064882
2022-01-15 19:18:01,801 iteration 394 : loss : 0.176985, loss_ce: 0.073215
2022-01-15 19:18:02,777 iteration 395 : loss : 0.149209, loss_ce: 0.064656
2022-01-15 19:18:03,822 iteration 396 : loss : 0.114698, loss_ce: 0.044521
2022-01-15 19:18:04,858 iteration 397 : loss : 0.114394, loss_ce: 0.043300
2022-01-15 19:18:05,883 iteration 398 : loss : 0.169282, loss_ce: 0.073869
2022-01-15 19:18:06,869 iteration 399 : loss : 0.096243, loss_ce: 0.028892
2022-01-15 19:18:07,928 iteration 400 : loss : 0.128251, loss_ce: 0.050673
2022-01-15 19:18:08,851 iteration 401 : loss : 0.142239, loss_ce: 0.037854
2022-01-15 19:18:09,920 iteration 402 : loss : 0.143120, loss_ce: 0.060394
2022-01-15 19:18:11,024 iteration 403 : loss : 0.142521, loss_ce: 0.055626
2022-01-15 19:18:12,040 iteration 404 : loss : 0.114263, loss_ce: 0.032856
2022-01-15 19:18:13,100 iteration 405 : loss : 0.155993, loss_ce: 0.053919
2022-01-15 19:18:14,069 iteration 406 : loss : 0.125250, loss_ce: 0.056697
2022-01-15 19:18:15,031 iteration 407 : loss : 0.129699, loss_ce: 0.046901
2022-01-15 19:18:15,993 iteration 408 : loss : 0.119954, loss_ce: 0.039053
  6%|█▊                            | 24/400 [07:23<1:51:26, 17.78s/it]2022-01-15 19:18:17,193 iteration 409 : loss : 0.114268, loss_ce: 0.044486
2022-01-15 19:18:18,180 iteration 410 : loss : 0.144859, loss_ce: 0.053540
2022-01-15 19:18:19,200 iteration 411 : loss : 0.109469, loss_ce: 0.040730
2022-01-15 19:18:20,180 iteration 412 : loss : 0.134605, loss_ce: 0.050211
2022-01-15 19:18:21,154 iteration 413 : loss : 0.113540, loss_ce: 0.044205
2022-01-15 19:18:22,166 iteration 414 : loss : 0.114083, loss_ce: 0.049653
2022-01-15 19:18:23,226 iteration 415 : loss : 0.158036, loss_ce: 0.083195
2022-01-15 19:18:24,089 iteration 416 : loss : 0.128431, loss_ce: 0.044036
2022-01-15 19:18:25,073 iteration 417 : loss : 0.159927, loss_ce: 0.052792
2022-01-15 19:18:26,079 iteration 418 : loss : 0.125449, loss_ce: 0.043809
2022-01-15 19:18:27,052 iteration 419 : loss : 0.196972, loss_ce: 0.085347
2022-01-15 19:18:28,055 iteration 420 : loss : 0.112174, loss_ce: 0.045342
2022-01-15 19:18:28,956 iteration 421 : loss : 0.150867, loss_ce: 0.043685
2022-01-15 19:18:29,996 iteration 422 : loss : 0.113270, loss_ce: 0.042234
2022-01-15 19:18:30,974 iteration 423 : loss : 0.131820, loss_ce: 0.052499
2022-01-15 19:18:31,951 iteration 424 : loss : 0.137808, loss_ce: 0.058744
2022-01-15 19:18:31,952 Training Data Eval:
2022-01-15 19:18:36,755   Average segmentation loss on training set: 0.1797
2022-01-15 19:18:36,756 Validation Data Eval:
2022-01-15 19:18:38,366   Average segmentation loss on validation set: 0.2527
2022-01-15 19:18:39,433 iteration 425 : loss : 0.166005, loss_ce: 0.073039
  6%|█▉                            | 25/400 [07:47<2:01:45, 19.48s/it]2022-01-15 19:18:40,538 iteration 426 : loss : 0.140332, loss_ce: 0.059175
2022-01-15 19:18:41,485 iteration 427 : loss : 0.120684, loss_ce: 0.050487
2022-01-15 19:18:42,580 iteration 428 : loss : 0.104556, loss_ce: 0.041031
2022-01-15 19:18:43,534 iteration 429 : loss : 0.113268, loss_ce: 0.036833
2022-01-15 19:18:44,440 iteration 430 : loss : 0.144205, loss_ce: 0.060399
2022-01-15 19:18:45,467 iteration 431 : loss : 0.109749, loss_ce: 0.050526
2022-01-15 19:18:46,468 iteration 432 : loss : 0.096122, loss_ce: 0.036430
2022-01-15 19:18:47,379 iteration 433 : loss : 0.114919, loss_ce: 0.043958
2022-01-15 19:18:48,320 iteration 434 : loss : 0.122425, loss_ce: 0.040710
2022-01-15 19:18:49,334 iteration 435 : loss : 0.113476, loss_ce: 0.039996
2022-01-15 19:18:50,364 iteration 436 : loss : 0.147244, loss_ce: 0.039589
2022-01-15 19:18:51,307 iteration 437 : loss : 0.153098, loss_ce: 0.057174
2022-01-15 19:18:52,256 iteration 438 : loss : 0.177122, loss_ce: 0.068146
2022-01-15 19:18:53,232 iteration 439 : loss : 0.140580, loss_ce: 0.054057
2022-01-15 19:18:54,367 iteration 440 : loss : 0.159563, loss_ce: 0.067082
2022-01-15 19:18:55,338 iteration 441 : loss : 0.112098, loss_ce: 0.050091
2022-01-15 19:18:56,292 iteration 442 : loss : 0.126262, loss_ce: 0.048454
  6%|█▉                            | 26/400 [08:04<1:56:32, 18.70s/it]2022-01-15 19:18:57,378 iteration 443 : loss : 0.131360, loss_ce: 0.058163
2022-01-15 19:18:58,324 iteration 444 : loss : 0.114261, loss_ce: 0.040897
2022-01-15 19:18:59,245 iteration 445 : loss : 0.132468, loss_ce: 0.051381
2022-01-15 19:19:00,217 iteration 446 : loss : 0.091240, loss_ce: 0.029823
2022-01-15 19:19:01,261 iteration 447 : loss : 0.087441, loss_ce: 0.030573
2022-01-15 19:19:02,170 iteration 448 : loss : 0.154785, loss_ce: 0.051250
2022-01-15 19:19:03,125 iteration 449 : loss : 0.119608, loss_ce: 0.030782
2022-01-15 19:19:04,041 iteration 450 : loss : 0.172131, loss_ce: 0.081380
2022-01-15 19:19:05,033 iteration 451 : loss : 0.159077, loss_ce: 0.064923
2022-01-15 19:19:06,034 iteration 452 : loss : 0.132983, loss_ce: 0.041970
2022-01-15 19:19:07,001 iteration 453 : loss : 0.102193, loss_ce: 0.036299
2022-01-15 19:19:08,097 iteration 454 : loss : 0.129136, loss_ce: 0.057057
2022-01-15 19:19:09,137 iteration 455 : loss : 0.127064, loss_ce: 0.055063
2022-01-15 19:19:10,122 iteration 456 : loss : 0.113824, loss_ce: 0.042222
2022-01-15 19:19:11,106 iteration 457 : loss : 0.130186, loss_ce: 0.062069
2022-01-15 19:19:12,087 iteration 458 : loss : 0.127062, loss_ce: 0.064307
2022-01-15 19:19:13,093 iteration 459 : loss : 0.134634, loss_ce: 0.060311
  7%|██                            | 27/400 [08:21<1:52:40, 18.13s/it]2022-01-15 19:19:14,085 iteration 460 : loss : 0.127047, loss_ce: 0.058758
2022-01-15 19:19:15,049 iteration 461 : loss : 0.104730, loss_ce: 0.046238
2022-01-15 19:19:16,118 iteration 462 : loss : 0.163198, loss_ce: 0.068156
2022-01-15 19:19:17,121 iteration 463 : loss : 0.162746, loss_ce: 0.051002
2022-01-15 19:19:18,258 iteration 464 : loss : 0.214534, loss_ce: 0.072451
2022-01-15 19:19:19,297 iteration 465 : loss : 0.147876, loss_ce: 0.053175
2022-01-15 19:19:20,265 iteration 466 : loss : 0.115940, loss_ce: 0.047242
2022-01-15 19:19:21,248 iteration 467 : loss : 0.123438, loss_ce: 0.052676
2022-01-15 19:19:22,208 iteration 468 : loss : 0.111797, loss_ce: 0.050992
2022-01-15 19:19:23,239 iteration 469 : loss : 0.113431, loss_ce: 0.051758
2022-01-15 19:19:24,227 iteration 470 : loss : 0.112028, loss_ce: 0.048139
2022-01-15 19:19:25,221 iteration 471 : loss : 0.221947, loss_ce: 0.119383
2022-01-15 19:19:26,253 iteration 472 : loss : 0.091090, loss_ce: 0.039753
2022-01-15 19:19:27,260 iteration 473 : loss : 0.118881, loss_ce: 0.048128
2022-01-15 19:19:28,212 iteration 474 : loss : 0.173912, loss_ce: 0.061288
2022-01-15 19:19:29,203 iteration 475 : loss : 0.167665, loss_ce: 0.053244
2022-01-15 19:19:30,284 iteration 476 : loss : 0.123999, loss_ce: 0.041440
  7%|██                            | 28/400 [08:38<1:50:38, 17.84s/it]2022-01-15 19:19:31,334 iteration 477 : loss : 0.096595, loss_ce: 0.040295
2022-01-15 19:19:32,252 iteration 478 : loss : 0.113283, loss_ce: 0.049734
2022-01-15 19:19:33,278 iteration 479 : loss : 0.120031, loss_ce: 0.039069
2022-01-15 19:19:34,292 iteration 480 : loss : 0.129633, loss_ce: 0.039830
2022-01-15 19:19:35,245 iteration 481 : loss : 0.112034, loss_ce: 0.036058
2022-01-15 19:19:36,330 iteration 482 : loss : 0.114407, loss_ce: 0.046263
2022-01-15 19:19:37,275 iteration 483 : loss : 0.167096, loss_ce: 0.074717
2022-01-15 19:19:38,293 iteration 484 : loss : 0.141153, loss_ce: 0.045937
2022-01-15 19:19:39,307 iteration 485 : loss : 0.146960, loss_ce: 0.077434
2022-01-15 19:19:40,426 iteration 486 : loss : 0.132968, loss_ce: 0.044937
2022-01-15 19:19:41,434 iteration 487 : loss : 0.182148, loss_ce: 0.051625
2022-01-15 19:19:42,360 iteration 488 : loss : 0.124394, loss_ce: 0.053468
2022-01-15 19:19:43,410 iteration 489 : loss : 0.118107, loss_ce: 0.055324
2022-01-15 19:19:44,421 iteration 490 : loss : 0.131679, loss_ce: 0.050887
2022-01-15 19:19:45,504 iteration 491 : loss : 0.216862, loss_ce: 0.088918
2022-01-15 19:19:46,497 iteration 492 : loss : 0.157473, loss_ce: 0.088202
2022-01-15 19:19:47,484 iteration 493 : loss : 0.116490, loss_ce: 0.053594
  7%|██▏                           | 29/400 [08:55<1:49:10, 17.66s/it]2022-01-15 19:19:48,571 iteration 494 : loss : 0.156399, loss_ce: 0.067184
2022-01-15 19:19:49,525 iteration 495 : loss : 0.156294, loss_ce: 0.053029
2022-01-15 19:19:50,560 iteration 496 : loss : 0.163595, loss_ce: 0.067959
2022-01-15 19:19:51,669 iteration 497 : loss : 0.186836, loss_ce: 0.074757
2022-01-15 19:19:52,822 iteration 498 : loss : 0.133888, loss_ce: 0.072268
2022-01-15 19:19:53,885 iteration 499 : loss : 0.163495, loss_ce: 0.044366
2022-01-15 19:19:55,049 iteration 500 : loss : 0.167876, loss_ce: 0.058779
2022-01-15 19:19:56,077 iteration 501 : loss : 0.129530, loss_ce: 0.039643
2022-01-15 19:19:57,051 iteration 502 : loss : 0.118253, loss_ce: 0.047437
2022-01-15 19:19:58,197 iteration 503 : loss : 0.120958, loss_ce: 0.038413
2022-01-15 19:19:59,360 iteration 504 : loss : 0.126231, loss_ce: 0.047419
2022-01-15 19:20:00,358 iteration 505 : loss : 0.099990, loss_ce: 0.040087
2022-01-15 19:20:01,415 iteration 506 : loss : 0.143009, loss_ce: 0.055293
2022-01-15 19:20:02,500 iteration 507 : loss : 0.088648, loss_ce: 0.033721
2022-01-15 19:20:03,527 iteration 508 : loss : 0.118083, loss_ce: 0.049112
2022-01-15 19:20:04,580 iteration 509 : loss : 0.124499, loss_ce: 0.052886
2022-01-15 19:20:04,580 Training Data Eval:
2022-01-15 19:20:09,450   Average segmentation loss on training set: 0.1261
2022-01-15 19:20:09,450 Validation Data Eval:
2022-01-15 19:20:11,081   Average segmentation loss on validation set: 0.1659
2022-01-15 19:20:11,998 iteration 510 : loss : 0.135972, loss_ce: 0.048264
  8%|██▎                           | 30/400 [09:19<2:01:32, 19.71s/it]2022-01-15 19:20:12,932 iteration 511 : loss : 0.095254, loss_ce: 0.039713
2022-01-15 19:20:14,107 iteration 512 : loss : 0.147548, loss_ce: 0.060188
2022-01-15 19:20:15,045 iteration 513 : loss : 0.148172, loss_ce: 0.074212
2022-01-15 19:20:16,070 iteration 514 : loss : 0.132410, loss_ce: 0.054042
2022-01-15 19:20:17,026 iteration 515 : loss : 0.096478, loss_ce: 0.035043
2022-01-15 19:20:17,932 iteration 516 : loss : 0.083687, loss_ce: 0.037274
2022-01-15 19:20:19,095 iteration 517 : loss : 0.093350, loss_ce: 0.034252
2022-01-15 19:20:20,126 iteration 518 : loss : 0.184271, loss_ce: 0.090645
2022-01-15 19:20:21,085 iteration 519 : loss : 0.105864, loss_ce: 0.038149
2022-01-15 19:20:22,039 iteration 520 : loss : 0.125853, loss_ce: 0.055201
2022-01-15 19:20:23,140 iteration 521 : loss : 0.176934, loss_ce: 0.040160
2022-01-15 19:20:24,099 iteration 522 : loss : 0.092232, loss_ce: 0.036972
2022-01-15 19:20:25,134 iteration 523 : loss : 0.104373, loss_ce: 0.040904
2022-01-15 19:20:26,021 iteration 524 : loss : 0.127507, loss_ce: 0.062330
2022-01-15 19:20:27,028 iteration 525 : loss : 0.113175, loss_ce: 0.041892
2022-01-15 19:20:28,082 iteration 526 : loss : 0.100689, loss_ce: 0.034739
2022-01-15 19:20:29,102 iteration 527 : loss : 0.120128, loss_ce: 0.052842
  8%|██▎                           | 31/400 [09:37<1:56:25, 18.93s/it]2022-01-15 19:20:30,239 iteration 528 : loss : 0.069548, loss_ce: 0.027275
2022-01-15 19:20:31,255 iteration 529 : loss : 0.098912, loss_ce: 0.041791
2022-01-15 19:20:32,249 iteration 530 : loss : 0.081869, loss_ce: 0.029007
2022-01-15 19:20:33,329 iteration 531 : loss : 0.180223, loss_ce: 0.065289
2022-01-15 19:20:34,276 iteration 532 : loss : 0.141021, loss_ce: 0.040952
2022-01-15 19:20:35,328 iteration 533 : loss : 0.120088, loss_ce: 0.050065
2022-01-15 19:20:36,363 iteration 534 : loss : 0.150044, loss_ce: 0.071765
2022-01-15 19:20:37,389 iteration 535 : loss : 0.111406, loss_ce: 0.044509
2022-01-15 19:20:38,335 iteration 536 : loss : 0.129593, loss_ce: 0.072685
2022-01-15 19:20:39,365 iteration 537 : loss : 0.130374, loss_ce: 0.052981
2022-01-15 19:20:40,380 iteration 538 : loss : 0.115947, loss_ce: 0.044116
2022-01-15 19:20:41,361 iteration 539 : loss : 0.147280, loss_ce: 0.055852
2022-01-15 19:20:42,323 iteration 540 : loss : 0.113063, loss_ce: 0.052316
2022-01-15 19:20:43,328 iteration 541 : loss : 0.136587, loss_ce: 0.067857
2022-01-15 19:20:44,270 iteration 542 : loss : 0.129532, loss_ce: 0.045421
2022-01-15 19:20:45,236 iteration 543 : loss : 0.147570, loss_ce: 0.039420
2022-01-15 19:20:46,242 iteration 544 : loss : 0.109374, loss_ce: 0.036669
  8%|██▍                           | 32/400 [09:54<1:52:49, 18.40s/it]2022-01-15 19:20:47,305 iteration 545 : loss : 0.151956, loss_ce: 0.063528
2022-01-15 19:20:48,322 iteration 546 : loss : 0.125423, loss_ce: 0.043205
2022-01-15 19:20:49,326 iteration 547 : loss : 0.155603, loss_ce: 0.075308
2022-01-15 19:20:50,283 iteration 548 : loss : 0.136494, loss_ce: 0.055998
2022-01-15 19:20:51,297 iteration 549 : loss : 0.115303, loss_ce: 0.049958
2022-01-15 19:20:52,406 iteration 550 : loss : 0.127364, loss_ce: 0.047947
2022-01-15 19:20:53,433 iteration 551 : loss : 0.116002, loss_ce: 0.037282
2022-01-15 19:20:54,479 iteration 552 : loss : 0.096819, loss_ce: 0.040022
2022-01-15 19:20:55,542 iteration 553 : loss : 0.122098, loss_ce: 0.050598
2022-01-15 19:20:56,469 iteration 554 : loss : 0.089990, loss_ce: 0.036093
2022-01-15 19:20:57,490 iteration 555 : loss : 0.097172, loss_ce: 0.044397
2022-01-15 19:20:58,581 iteration 556 : loss : 0.115686, loss_ce: 0.051292
2022-01-15 19:20:59,568 iteration 557 : loss : 0.115569, loss_ce: 0.054838
2022-01-15 19:21:00,515 iteration 558 : loss : 0.136980, loss_ce: 0.048948
2022-01-15 19:21:01,532 iteration 559 : loss : 0.136926, loss_ce: 0.053906
2022-01-15 19:21:02,561 iteration 560 : loss : 0.118856, loss_ce: 0.047094
2022-01-15 19:21:03,504 iteration 561 : loss : 0.164826, loss_ce: 0.046461
  8%|██▍                           | 33/400 [10:11<1:50:25, 18.05s/it]2022-01-15 19:21:04,538 iteration 562 : loss : 0.123401, loss_ce: 0.048138
2022-01-15 19:21:05,547 iteration 563 : loss : 0.107847, loss_ce: 0.042464
2022-01-15 19:21:06,588 iteration 564 : loss : 0.087314, loss_ce: 0.042943
2022-01-15 19:21:07,589 iteration 565 : loss : 0.162065, loss_ce: 0.076152
2022-01-15 19:21:08,491 iteration 566 : loss : 0.087355, loss_ce: 0.032139
2022-01-15 19:21:09,537 iteration 567 : loss : 0.107514, loss_ce: 0.033134
2022-01-15 19:21:10,496 iteration 568 : loss : 0.096246, loss_ce: 0.039573
2022-01-15 19:21:11,485 iteration 569 : loss : 0.088559, loss_ce: 0.029912
2022-01-15 19:21:12,552 iteration 570 : loss : 0.130280, loss_ce: 0.053587
2022-01-15 19:21:13,587 iteration 571 : loss : 0.100066, loss_ce: 0.038359
2022-01-15 19:21:14,602 iteration 572 : loss : 0.093914, loss_ce: 0.035133
2022-01-15 19:21:15,565 iteration 573 : loss : 0.116702, loss_ce: 0.043359
2022-01-15 19:21:16,536 iteration 574 : loss : 0.105111, loss_ce: 0.044255
2022-01-15 19:21:17,573 iteration 575 : loss : 0.129608, loss_ce: 0.052309
2022-01-15 19:21:18,559 iteration 576 : loss : 0.117048, loss_ce: 0.051877
2022-01-15 19:21:19,574 iteration 577 : loss : 0.176564, loss_ce: 0.058887
2022-01-15 19:21:20,593 iteration 578 : loss : 0.096875, loss_ce: 0.035737
  8%|██▌                           | 34/400 [10:28<1:48:20, 17.76s/it]2022-01-15 19:21:21,640 iteration 579 : loss : 0.070747, loss_ce: 0.025719
2022-01-15 19:21:22,632 iteration 580 : loss : 0.087478, loss_ce: 0.033448
2022-01-15 19:21:23,652 iteration 581 : loss : 0.096407, loss_ce: 0.038503
2022-01-15 19:21:24,680 iteration 582 : loss : 0.083961, loss_ce: 0.032393
2022-01-15 19:21:25,663 iteration 583 : loss : 0.184060, loss_ce: 0.100704
2022-01-15 19:21:26,566 iteration 584 : loss : 0.093024, loss_ce: 0.038790
2022-01-15 19:21:27,569 iteration 585 : loss : 0.078504, loss_ce: 0.029373
2022-01-15 19:21:28,620 iteration 586 : loss : 0.087295, loss_ce: 0.038578
2022-01-15 19:21:29,614 iteration 587 : loss : 0.092464, loss_ce: 0.035884
2022-01-15 19:21:30,666 iteration 588 : loss : 0.109078, loss_ce: 0.040283
2022-01-15 19:21:31,685 iteration 589 : loss : 0.092591, loss_ce: 0.034940
2022-01-15 19:21:32,658 iteration 590 : loss : 0.129756, loss_ce: 0.066541
2022-01-15 19:21:33,669 iteration 591 : loss : 0.081345, loss_ce: 0.031676
2022-01-15 19:21:34,674 iteration 592 : loss : 0.115292, loss_ce: 0.039581
2022-01-15 19:21:35,743 iteration 593 : loss : 0.097879, loss_ce: 0.035354
2022-01-15 19:21:36,825 iteration 594 : loss : 0.119383, loss_ce: 0.055248
2022-01-15 19:21:36,825 Training Data Eval:
2022-01-15 19:21:41,701   Average segmentation loss on training set: 0.1003
2022-01-15 19:21:41,701 Validation Data Eval:
2022-01-15 19:21:43,344   Average segmentation loss on validation set: 0.1269
2022-01-15 19:21:44,380 Found new lowest validation loss at iteration 594! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_1HEAD_NEW_best_val_loss_seed100.pth
2022-01-15 19:21:45,395 iteration 595 : loss : 0.139246, loss_ce: 0.049770
  9%|██▋                           | 35/400 [10:53<2:00:55, 19.88s/it]2022-01-15 19:21:46,364 iteration 596 : loss : 0.074358, loss_ce: 0.028742
2022-01-15 19:21:47,344 iteration 597 : loss : 0.121920, loss_ce: 0.052769
2022-01-15 19:21:48,346 iteration 598 : loss : 0.109671, loss_ce: 0.040354
2022-01-15 19:21:49,392 iteration 599 : loss : 0.078453, loss_ce: 0.030217
2022-01-15 19:21:50,297 iteration 600 : loss : 0.080864, loss_ce: 0.039640
2022-01-15 19:21:51,303 iteration 601 : loss : 0.098607, loss_ce: 0.038205
2022-01-15 19:21:52,363 iteration 602 : loss : 0.083385, loss_ce: 0.038426
2022-01-15 19:21:53,263 iteration 603 : loss : 0.125747, loss_ce: 0.046873
2022-01-15 19:21:54,245 iteration 604 : loss : 0.138215, loss_ce: 0.058454
2022-01-15 19:21:55,245 iteration 605 : loss : 0.116624, loss_ce: 0.047265
2022-01-15 19:21:56,209 iteration 606 : loss : 0.117637, loss_ce: 0.046929
2022-01-15 19:21:57,198 iteration 607 : loss : 0.097288, loss_ce: 0.036482
2022-01-15 19:21:58,312 iteration 608 : loss : 0.079275, loss_ce: 0.026838
2022-01-15 19:21:59,289 iteration 609 : loss : 0.086389, loss_ce: 0.029363
2022-01-15 19:22:00,343 iteration 610 : loss : 0.085472, loss_ce: 0.032467
2022-01-15 19:22:01,330 iteration 611 : loss : 0.118012, loss_ce: 0.043970
2022-01-15 19:22:02,331 iteration 612 : loss : 0.081174, loss_ce: 0.037005
  9%|██▋                           | 36/400 [11:10<1:55:12, 18.99s/it]2022-01-15 19:22:03,461 iteration 613 : loss : 0.107402, loss_ce: 0.044237
2022-01-15 19:22:04,574 iteration 614 : loss : 0.082776, loss_ce: 0.033124
2022-01-15 19:22:05,574 iteration 615 : loss : 0.115135, loss_ce: 0.038870
2022-01-15 19:22:06,522 iteration 616 : loss : 0.150921, loss_ce: 0.078002
2022-01-15 19:22:07,525 iteration 617 : loss : 0.121705, loss_ce: 0.054486
2022-01-15 19:22:08,479 iteration 618 : loss : 0.133093, loss_ce: 0.054535
2022-01-15 19:22:09,481 iteration 619 : loss : 0.102681, loss_ce: 0.034843
2022-01-15 19:22:10,597 iteration 620 : loss : 0.133086, loss_ce: 0.049502
2022-01-15 19:22:11,584 iteration 621 : loss : 0.101398, loss_ce: 0.032476
2022-01-15 19:22:12,630 iteration 622 : loss : 0.081606, loss_ce: 0.030265
2022-01-15 19:22:13,720 iteration 623 : loss : 0.106840, loss_ce: 0.027409
2022-01-15 19:22:14,720 iteration 624 : loss : 0.134032, loss_ce: 0.043796
2022-01-15 19:22:15,674 iteration 625 : loss : 0.154037, loss_ce: 0.059854
2022-01-15 19:22:16,636 iteration 626 : loss : 0.087612, loss_ce: 0.031170
2022-01-15 19:22:17,639 iteration 627 : loss : 0.110442, loss_ce: 0.036313
2022-01-15 19:22:18,648 iteration 628 : loss : 0.115977, loss_ce: 0.060717
2022-01-15 19:22:19,709 iteration 629 : loss : 0.091097, loss_ce: 0.035676
  9%|██▊                           | 37/400 [11:27<1:51:59, 18.51s/it]2022-01-15 19:22:20,780 iteration 630 : loss : 0.081159, loss_ce: 0.035167
2022-01-15 19:22:21,840 iteration 631 : loss : 0.109854, loss_ce: 0.056573
2022-01-15 19:22:22,861 iteration 632 : loss : 0.137231, loss_ce: 0.055565
2022-01-15 19:22:23,910 iteration 633 : loss : 0.105206, loss_ce: 0.042546
2022-01-15 19:22:24,980 iteration 634 : loss : 0.097576, loss_ce: 0.048933
2022-01-15 19:22:25,978 iteration 635 : loss : 0.155415, loss_ce: 0.054007
2022-01-15 19:22:27,069 iteration 636 : loss : 0.109854, loss_ce: 0.050338
2022-01-15 19:22:28,032 iteration 637 : loss : 0.094037, loss_ce: 0.031622
2022-01-15 19:22:29,004 iteration 638 : loss : 0.142489, loss_ce: 0.067198
2022-01-15 19:22:30,055 iteration 639 : loss : 0.080335, loss_ce: 0.030016
2022-01-15 19:22:31,036 iteration 640 : loss : 0.114050, loss_ce: 0.040089
2022-01-15 19:22:32,062 iteration 641 : loss : 0.080629, loss_ce: 0.028434
2022-01-15 19:22:33,087 iteration 642 : loss : 0.077005, loss_ce: 0.028550
2022-01-15 19:22:34,087 iteration 643 : loss : 0.126822, loss_ce: 0.056224
2022-01-15 19:22:35,083 iteration 644 : loss : 0.086374, loss_ce: 0.034643
2022-01-15 19:22:36,096 iteration 645 : loss : 0.164176, loss_ce: 0.081917
2022-01-15 19:22:37,081 iteration 646 : loss : 0.082810, loss_ce: 0.034215
 10%|██▊                           | 38/400 [11:45<1:49:36, 18.17s/it]2022-01-15 19:22:38,154 iteration 647 : loss : 0.127732, loss_ce: 0.039278
2022-01-15 19:22:39,109 iteration 648 : loss : 0.100830, loss_ce: 0.058493
2022-01-15 19:22:40,058 iteration 649 : loss : 0.113170, loss_ce: 0.053328
2022-01-15 19:22:41,100 iteration 650 : loss : 0.142522, loss_ce: 0.043517
2022-01-15 19:22:42,134 iteration 651 : loss : 0.150223, loss_ce: 0.070256
2022-01-15 19:22:43,086 iteration 652 : loss : 0.090115, loss_ce: 0.035974
2022-01-15 19:22:44,068 iteration 653 : loss : 0.081201, loss_ce: 0.033159
2022-01-15 19:22:45,084 iteration 654 : loss : 0.082768, loss_ce: 0.029841
2022-01-15 19:22:46,019 iteration 655 : loss : 0.131331, loss_ce: 0.050630
2022-01-15 19:22:47,071 iteration 656 : loss : 0.104002, loss_ce: 0.037935
2022-01-15 19:22:48,056 iteration 657 : loss : 0.115592, loss_ce: 0.042736
2022-01-15 19:22:49,046 iteration 658 : loss : 0.105234, loss_ce: 0.038857
2022-01-15 19:22:50,084 iteration 659 : loss : 0.098889, loss_ce: 0.030238
2022-01-15 19:22:51,100 iteration 660 : loss : 0.088066, loss_ce: 0.035851
2022-01-15 19:22:52,103 iteration 661 : loss : 0.067458, loss_ce: 0.031196
2022-01-15 19:22:53,120 iteration 662 : loss : 0.126077, loss_ce: 0.052784
2022-01-15 19:22:54,110 iteration 663 : loss : 0.149674, loss_ce: 0.074034
 10%|██▉                           | 39/400 [12:02<1:47:15, 17.83s/it]2022-01-15 19:22:55,113 iteration 664 : loss : 0.148663, loss_ce: 0.081978
2022-01-15 19:22:56,137 iteration 665 : loss : 0.108086, loss_ce: 0.041170
2022-01-15 19:22:57,141 iteration 666 : loss : 0.107255, loss_ce: 0.034771
2022-01-15 19:22:58,196 iteration 667 : loss : 0.102004, loss_ce: 0.035819
2022-01-15 19:22:59,175 iteration 668 : loss : 0.070670, loss_ce: 0.026851
2022-01-15 19:23:00,223 iteration 669 : loss : 0.106501, loss_ce: 0.045946
2022-01-15 19:23:01,251 iteration 670 : loss : 0.106068, loss_ce: 0.039569
2022-01-15 19:23:02,257 iteration 671 : loss : 0.113250, loss_ce: 0.040358
2022-01-15 19:23:03,163 iteration 672 : loss : 0.129366, loss_ce: 0.058921
2022-01-15 19:23:04,145 iteration 673 : loss : 0.086335, loss_ce: 0.031584
2022-01-15 19:23:05,300 iteration 674 : loss : 0.107384, loss_ce: 0.047902
2022-01-15 19:23:06,307 iteration 675 : loss : 0.098506, loss_ce: 0.033628
2022-01-15 19:23:07,287 iteration 676 : loss : 0.094692, loss_ce: 0.036866
2022-01-15 19:23:08,407 iteration 677 : loss : 0.079763, loss_ce: 0.032967
2022-01-15 19:23:09,437 iteration 678 : loss : 0.107652, loss_ce: 0.034368
2022-01-15 19:23:10,382 iteration 679 : loss : 0.095712, loss_ce: 0.038568
2022-01-15 19:23:10,382 Training Data Eval:
2022-01-15 19:23:15,211   Average segmentation loss on training set: 0.0805
2022-01-15 19:23:15,212 Validation Data Eval:
2022-01-15 19:23:16,862   Average segmentation loss on validation set: 0.1621
2022-01-15 19:23:17,849 iteration 680 : loss : 0.082233, loss_ce: 0.033488
 10%|███                           | 40/400 [12:25<1:57:36, 19.60s/it]2022-01-15 19:23:19,059 iteration 681 : loss : 0.101414, loss_ce: 0.037625
2022-01-15 19:23:20,052 iteration 682 : loss : 0.089701, loss_ce: 0.029535
2022-01-15 19:23:21,000 iteration 683 : loss : 0.098497, loss_ce: 0.028329
2022-01-15 19:23:22,061 iteration 684 : loss : 0.085161, loss_ce: 0.033573
2022-01-15 19:23:23,131 iteration 685 : loss : 0.092562, loss_ce: 0.032592
2022-01-15 19:23:24,164 iteration 686 : loss : 0.086950, loss_ce: 0.040436
2022-01-15 19:23:25,197 iteration 687 : loss : 0.078569, loss_ce: 0.035206
2022-01-15 19:23:26,256 iteration 688 : loss : 0.101009, loss_ce: 0.039746
2022-01-15 19:23:27,287 iteration 689 : loss : 0.097297, loss_ce: 0.042761
2022-01-15 19:23:28,285 iteration 690 : loss : 0.102713, loss_ce: 0.040268
2022-01-15 19:23:29,328 iteration 691 : loss : 0.124398, loss_ce: 0.048258
2022-01-15 19:23:30,256 iteration 692 : loss : 0.068623, loss_ce: 0.030464
2022-01-15 19:23:31,223 iteration 693 : loss : 0.089698, loss_ce: 0.032585
2022-01-15 19:23:32,220 iteration 694 : loss : 0.111900, loss_ce: 0.035051
2022-01-15 19:23:33,215 iteration 695 : loss : 0.110310, loss_ce: 0.040660
2022-01-15 19:23:34,165 iteration 696 : loss : 0.145184, loss_ce: 0.034022
2022-01-15 19:23:35,061 iteration 697 : loss : 0.080322, loss_ce: 0.035077
 10%|███                           | 41/400 [12:42<1:52:59, 18.88s/it]2022-01-15 19:23:36,133 iteration 698 : loss : 0.089142, loss_ce: 0.039506
2022-01-15 19:23:37,156 iteration 699 : loss : 0.085020, loss_ce: 0.032908
2022-01-15 19:23:38,111 iteration 700 : loss : 0.101219, loss_ce: 0.038130
2022-01-15 19:23:39,072 iteration 701 : loss : 0.119729, loss_ce: 0.039235
2022-01-15 19:23:40,109 iteration 702 : loss : 0.083443, loss_ce: 0.035120
2022-01-15 19:23:41,112 iteration 703 : loss : 0.123805, loss_ce: 0.041187
2022-01-15 19:23:42,197 iteration 704 : loss : 0.144324, loss_ce: 0.054657
2022-01-15 19:23:43,241 iteration 705 : loss : 0.088433, loss_ce: 0.040198
2022-01-15 19:23:44,288 iteration 706 : loss : 0.110357, loss_ce: 0.036462
2022-01-15 19:23:45,259 iteration 707 : loss : 0.102542, loss_ce: 0.040322
2022-01-15 19:23:46,270 iteration 708 : loss : 0.089175, loss_ce: 0.031369
2022-01-15 19:23:47,291 iteration 709 : loss : 0.104511, loss_ce: 0.040625
2022-01-15 19:23:48,235 iteration 710 : loss : 0.076857, loss_ce: 0.035248
2022-01-15 19:23:49,292 iteration 711 : loss : 0.083951, loss_ce: 0.035371
2022-01-15 19:23:50,282 iteration 712 : loss : 0.126821, loss_ce: 0.046818
2022-01-15 19:23:51,215 iteration 713 : loss : 0.105946, loss_ce: 0.046424
2022-01-15 19:23:52,167 iteration 714 : loss : 0.091385, loss_ce: 0.033046
 10%|███▏                          | 42/400 [13:00<1:49:29, 18.35s/it]2022-01-15 19:23:53,312 iteration 715 : loss : 0.092012, loss_ce: 0.041818
2022-01-15 19:23:54,297 iteration 716 : loss : 0.102277, loss_ce: 0.042524
2022-01-15 19:23:55,284 iteration 717 : loss : 0.104400, loss_ce: 0.036629
2022-01-15 19:23:56,285 iteration 718 : loss : 0.110987, loss_ce: 0.041073
2022-01-15 19:23:57,377 iteration 719 : loss : 0.088022, loss_ce: 0.033364
2022-01-15 19:23:58,359 iteration 720 : loss : 0.095549, loss_ce: 0.031812
2022-01-15 19:23:59,432 iteration 721 : loss : 0.089498, loss_ce: 0.030373
2022-01-15 19:24:00,472 iteration 722 : loss : 0.102224, loss_ce: 0.041131
2022-01-15 19:24:01,464 iteration 723 : loss : 0.068097, loss_ce: 0.023401
2022-01-15 19:24:02,601 iteration 724 : loss : 0.085028, loss_ce: 0.034431
2022-01-15 19:24:03,559 iteration 725 : loss : 0.075067, loss_ce: 0.028206
2022-01-15 19:24:04,596 iteration 726 : loss : 0.123291, loss_ce: 0.036782
2022-01-15 19:24:05,674 iteration 727 : loss : 0.127194, loss_ce: 0.038929
2022-01-15 19:24:06,866 iteration 728 : loss : 0.085540, loss_ce: 0.042060
2022-01-15 19:24:07,777 iteration 729 : loss : 0.053782, loss_ce: 0.022466
2022-01-15 19:24:08,821 iteration 730 : loss : 0.083901, loss_ce: 0.038561
2022-01-15 19:24:09,860 iteration 731 : loss : 0.096252, loss_ce: 0.037697
 11%|███▏                          | 43/400 [13:17<1:47:59, 18.15s/it]2022-01-15 19:24:11,057 iteration 732 : loss : 0.087777, loss_ce: 0.037943
2022-01-15 19:24:12,102 iteration 733 : loss : 0.154815, loss_ce: 0.072382
2022-01-15 19:24:13,064 iteration 734 : loss : 0.073955, loss_ce: 0.032113
2022-01-15 19:24:14,076 iteration 735 : loss : 0.083368, loss_ce: 0.032629
2022-01-15 19:24:15,105 iteration 736 : loss : 0.081664, loss_ce: 0.032311
2022-01-15 19:24:16,180 iteration 737 : loss : 0.090503, loss_ce: 0.033037
2022-01-15 19:24:17,206 iteration 738 : loss : 0.066041, loss_ce: 0.030692
2022-01-15 19:24:18,206 iteration 739 : loss : 0.111401, loss_ce: 0.045321
2022-01-15 19:24:19,205 iteration 740 : loss : 0.107475, loss_ce: 0.046356
2022-01-15 19:24:20,233 iteration 741 : loss : 0.075163, loss_ce: 0.034093
2022-01-15 19:24:21,330 iteration 742 : loss : 0.110026, loss_ce: 0.041996
2022-01-15 19:24:22,319 iteration 743 : loss : 0.095851, loss_ce: 0.037398
2022-01-15 19:24:23,349 iteration 744 : loss : 0.092853, loss_ce: 0.035067
2022-01-15 19:24:24,318 iteration 745 : loss : 0.069390, loss_ce: 0.032098
2022-01-15 19:24:25,332 iteration 746 : loss : 0.164235, loss_ce: 0.084241
2022-01-15 19:24:26,370 iteration 747 : loss : 0.104030, loss_ce: 0.034443
2022-01-15 19:24:27,284 iteration 748 : loss : 0.079326, loss_ce: 0.036181
 11%|███▎                          | 44/400 [13:35<1:46:25, 17.94s/it]2022-01-15 19:24:28,363 iteration 749 : loss : 0.121947, loss_ce: 0.053163
2022-01-15 19:24:29,419 iteration 750 : loss : 0.084021, loss_ce: 0.036602
2022-01-15 19:24:30,355 iteration 751 : loss : 0.063687, loss_ce: 0.027376
2022-01-15 19:24:31,369 iteration 752 : loss : 0.079786, loss_ce: 0.031315
2022-01-15 19:24:32,466 iteration 753 : loss : 0.113819, loss_ce: 0.043817
2022-01-15 19:24:33,442 iteration 754 : loss : 0.144367, loss_ce: 0.074684
2022-01-15 19:24:34,450 iteration 755 : loss : 0.059738, loss_ce: 0.022447
2022-01-15 19:24:35,399 iteration 756 : loss : 0.095661, loss_ce: 0.035953
2022-01-15 19:24:36,368 iteration 757 : loss : 0.072774, loss_ce: 0.029574
2022-01-15 19:24:37,387 iteration 758 : loss : 0.077844, loss_ce: 0.029898
2022-01-15 19:24:38,306 iteration 759 : loss : 0.069857, loss_ce: 0.028598
2022-01-15 19:24:39,339 iteration 760 : loss : 0.118192, loss_ce: 0.041581
2022-01-15 19:24:40,388 iteration 761 : loss : 0.089121, loss_ce: 0.032696
2022-01-15 19:24:41,412 iteration 762 : loss : 0.102281, loss_ce: 0.047833
2022-01-15 19:24:42,384 iteration 763 : loss : 0.070542, loss_ce: 0.030643
2022-01-15 19:24:43,325 iteration 764 : loss : 0.082955, loss_ce: 0.034491
2022-01-15 19:24:43,326 Training Data Eval:
2022-01-15 19:24:48,120   Average segmentation loss on training set: 0.0818
2022-01-15 19:24:48,121 Validation Data Eval:
2022-01-15 19:24:49,751   Average segmentation loss on validation set: 0.1065
2022-01-15 19:24:50,763 Found new lowest validation loss at iteration 764! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_1HEAD_NEW_best_val_loss_seed100.pth
2022-01-15 19:24:51,766 iteration 765 : loss : 0.093517, loss_ce: 0.041966
 11%|███▍                          | 45/400 [13:59<1:57:44, 19.90s/it]2022-01-15 19:24:52,763 iteration 766 : loss : 0.116753, loss_ce: 0.044974
2022-01-15 19:24:53,775 iteration 767 : loss : 0.113107, loss_ce: 0.043510
2022-01-15 19:24:54,660 iteration 768 : loss : 0.120281, loss_ce: 0.043774
2022-01-15 19:24:55,652 iteration 769 : loss : 0.206054, loss_ce: 0.043228
2022-01-15 19:24:56,596 iteration 770 : loss : 0.063071, loss_ce: 0.024102
2022-01-15 19:24:57,671 iteration 771 : loss : 0.078974, loss_ce: 0.028089
2022-01-15 19:24:58,734 iteration 772 : loss : 0.085895, loss_ce: 0.039991
2022-01-15 19:24:59,742 iteration 773 : loss : 0.090141, loss_ce: 0.037448
2022-01-15 19:25:00,739 iteration 774 : loss : 0.070229, loss_ce: 0.032861
2022-01-15 19:25:01,725 iteration 775 : loss : 0.075885, loss_ce: 0.029778
2022-01-15 19:25:02,641 iteration 776 : loss : 0.074163, loss_ce: 0.035596
2022-01-15 19:25:03,707 iteration 777 : loss : 0.083707, loss_ce: 0.036046
2022-01-15 19:25:04,721 iteration 778 : loss : 0.066270, loss_ce: 0.027488
2022-01-15 19:25:05,727 iteration 779 : loss : 0.080592, loss_ce: 0.040577
2022-01-15 19:25:06,665 iteration 780 : loss : 0.088271, loss_ce: 0.034895
2022-01-15 19:25:07,719 iteration 781 : loss : 0.075199, loss_ce: 0.032465
2022-01-15 19:25:08,761 iteration 782 : loss : 0.106403, loss_ce: 0.039492
 12%|███▍                          | 46/400 [14:16<1:52:14, 19.02s/it]2022-01-15 19:25:09,854 iteration 783 : loss : 0.063454, loss_ce: 0.029495
2022-01-15 19:25:10,842 iteration 784 : loss : 0.094556, loss_ce: 0.034493
2022-01-15 19:25:11,867 iteration 785 : loss : 0.063727, loss_ce: 0.027497
2022-01-15 19:25:12,844 iteration 786 : loss : 0.084547, loss_ce: 0.027450
2022-01-15 19:25:13,841 iteration 787 : loss : 0.080057, loss_ce: 0.033795
2022-01-15 19:25:14,863 iteration 788 : loss : 0.063766, loss_ce: 0.019928
2022-01-15 19:25:15,993 iteration 789 : loss : 0.152330, loss_ce: 0.093844
2022-01-15 19:25:17,045 iteration 790 : loss : 0.062743, loss_ce: 0.019561
2022-01-15 19:25:18,016 iteration 791 : loss : 0.078472, loss_ce: 0.026120
2022-01-15 19:25:19,043 iteration 792 : loss : 0.082374, loss_ce: 0.033730
2022-01-15 19:25:19,944 iteration 793 : loss : 0.104859, loss_ce: 0.035955
2022-01-15 19:25:20,926 iteration 794 : loss : 0.070563, loss_ce: 0.029262
2022-01-15 19:25:21,922 iteration 795 : loss : 0.082192, loss_ce: 0.033203
2022-01-15 19:25:22,910 iteration 796 : loss : 0.086858, loss_ce: 0.035946
2022-01-15 19:25:23,853 iteration 797 : loss : 0.057773, loss_ce: 0.026263
2022-01-15 19:25:24,810 iteration 798 : loss : 0.150392, loss_ce: 0.040844
2022-01-15 19:25:25,837 iteration 799 : loss : 0.062724, loss_ce: 0.023796
 12%|███▌                          | 47/400 [14:33<1:48:30, 18.44s/it]2022-01-15 19:25:26,946 iteration 800 : loss : 0.095767, loss_ce: 0.025048
2022-01-15 19:25:27,890 iteration 801 : loss : 0.090360, loss_ce: 0.030609
2022-01-15 19:25:28,866 iteration 802 : loss : 0.132118, loss_ce: 0.073069
2022-01-15 19:25:29,936 iteration 803 : loss : 0.131741, loss_ce: 0.073845
2022-01-15 19:25:30,866 iteration 804 : loss : 0.087103, loss_ce: 0.039274
2022-01-15 19:25:31,800 iteration 805 : loss : 0.156211, loss_ce: 0.039216
2022-01-15 19:25:32,812 iteration 806 : loss : 0.096274, loss_ce: 0.035165
2022-01-15 19:25:33,910 iteration 807 : loss : 0.112429, loss_ce: 0.058273
2022-01-15 19:25:34,963 iteration 808 : loss : 0.082441, loss_ce: 0.028567
2022-01-15 19:25:35,951 iteration 809 : loss : 0.171329, loss_ce: 0.052394
2022-01-15 19:25:37,003 iteration 810 : loss : 0.117406, loss_ce: 0.041104
2022-01-15 19:25:37,968 iteration 811 : loss : 0.070521, loss_ce: 0.028212
2022-01-15 19:25:39,040 iteration 812 : loss : 0.145752, loss_ce: 0.056114
2022-01-15 19:25:40,036 iteration 813 : loss : 0.071774, loss_ce: 0.027053
2022-01-15 19:25:41,062 iteration 814 : loss : 0.084813, loss_ce: 0.036183
2022-01-15 19:25:42,128 iteration 815 : loss : 0.078397, loss_ce: 0.027169
2022-01-15 19:25:43,021 iteration 816 : loss : 0.066527, loss_ce: 0.024674
 12%|███▌                          | 48/400 [14:50<1:45:59, 18.07s/it]2022-01-15 19:25:44,069 iteration 817 : loss : 0.083870, loss_ce: 0.031414
2022-01-15 19:25:45,119 iteration 818 : loss : 0.091447, loss_ce: 0.035457
2022-01-15 19:25:46,134 iteration 819 : loss : 0.075984, loss_ce: 0.029064
2022-01-15 19:25:47,257 iteration 820 : loss : 0.096477, loss_ce: 0.037710
2022-01-15 19:25:48,171 iteration 821 : loss : 0.120258, loss_ce: 0.049298
2022-01-15 19:25:49,207 iteration 822 : loss : 0.071336, loss_ce: 0.028803
2022-01-15 19:25:50,208 iteration 823 : loss : 0.091875, loss_ce: 0.038389
2022-01-15 19:25:51,193 iteration 824 : loss : 0.077434, loss_ce: 0.033456
2022-01-15 19:25:52,203 iteration 825 : loss : 0.085148, loss_ce: 0.025561
2022-01-15 19:25:53,247 iteration 826 : loss : 0.070807, loss_ce: 0.031120
2022-01-15 19:25:54,242 iteration 827 : loss : 0.133531, loss_ce: 0.040076
2022-01-15 19:25:55,305 iteration 828 : loss : 0.089740, loss_ce: 0.042136
2022-01-15 19:25:56,314 iteration 829 : loss : 0.099101, loss_ce: 0.031730
2022-01-15 19:25:57,430 iteration 830 : loss : 0.084667, loss_ce: 0.026947
2022-01-15 19:25:58,465 iteration 831 : loss : 0.085788, loss_ce: 0.034901
2022-01-15 19:25:59,470 iteration 832 : loss : 0.049267, loss_ce: 0.020170
2022-01-15 19:26:00,442 iteration 833 : loss : 0.060227, loss_ce: 0.028807
 12%|███▋                          | 49/400 [15:08<1:44:32, 17.87s/it]2022-01-15 19:26:01,477 iteration 834 : loss : 0.102049, loss_ce: 0.037170
2022-01-15 19:26:02,517 iteration 835 : loss : 0.081819, loss_ce: 0.034917
2022-01-15 19:26:03,546 iteration 836 : loss : 0.066006, loss_ce: 0.027553
2022-01-15 19:26:04,533 iteration 837 : loss : 0.078304, loss_ce: 0.035122
2022-01-15 19:26:05,511 iteration 838 : loss : 0.121439, loss_ce: 0.052000
2022-01-15 19:26:06,586 iteration 839 : loss : 0.069340, loss_ce: 0.022232
2022-01-15 19:26:07,603 iteration 840 : loss : 0.104337, loss_ce: 0.038579
2022-01-15 19:26:08,609 iteration 841 : loss : 0.082415, loss_ce: 0.042561
2022-01-15 19:26:09,731 iteration 842 : loss : 0.103398, loss_ce: 0.038648
2022-01-15 19:26:10,706 iteration 843 : loss : 0.055753, loss_ce: 0.019257
2022-01-15 19:26:11,737 iteration 844 : loss : 0.109199, loss_ce: 0.044799
2022-01-15 19:26:12,689 iteration 845 : loss : 0.067495, loss_ce: 0.025942
2022-01-15 19:26:13,677 iteration 846 : loss : 0.113917, loss_ce: 0.038759
2022-01-15 19:26:14,712 iteration 847 : loss : 0.088844, loss_ce: 0.036434
2022-01-15 19:26:15,613 iteration 848 : loss : 0.055198, loss_ce: 0.021203
2022-01-15 19:26:16,633 iteration 849 : loss : 0.084643, loss_ce: 0.032331
2022-01-15 19:26:16,633 Training Data Eval:
2022-01-15 19:26:21,391   Average segmentation loss on training set: 0.1439
2022-01-15 19:26:21,391 Validation Data Eval:
2022-01-15 19:26:22,985   Average segmentation loss on validation set: 0.1575
2022-01-15 19:26:24,059 iteration 850 : loss : 0.078278, loss_ce: 0.024679
 12%|███▊                          | 50/400 [15:31<1:54:18, 19.59s/it]2022-01-15 19:26:25,177 iteration 851 : loss : 0.069755, loss_ce: 0.033885
2022-01-15 19:26:26,199 iteration 852 : loss : 0.082356, loss_ce: 0.028473
2022-01-15 19:26:27,221 iteration 853 : loss : 0.093708, loss_ce: 0.035493
2022-01-15 19:26:28,182 iteration 854 : loss : 0.068521, loss_ce: 0.027457
2022-01-15 19:26:29,072 iteration 855 : loss : 0.067090, loss_ce: 0.027461
2022-01-15 19:26:30,021 iteration 856 : loss : 0.093634, loss_ce: 0.031636
2022-01-15 19:26:31,106 iteration 857 : loss : 0.078569, loss_ce: 0.037267
2022-01-15 19:26:32,085 iteration 858 : loss : 0.090127, loss_ce: 0.033292
2022-01-15 19:26:33,163 iteration 859 : loss : 0.069127, loss_ce: 0.029012
2022-01-15 19:26:34,195 iteration 860 : loss : 0.111400, loss_ce: 0.043996
2022-01-15 19:26:35,171 iteration 861 : loss : 0.085871, loss_ce: 0.029552
2022-01-15 19:26:36,157 iteration 862 : loss : 0.083603, loss_ce: 0.028404
2022-01-15 19:26:37,073 iteration 863 : loss : 0.097887, loss_ce: 0.044542
2022-01-15 19:26:38,059 iteration 864 : loss : 0.064689, loss_ce: 0.027932
2022-01-15 19:26:38,990 iteration 865 : loss : 0.073217, loss_ce: 0.034488
2022-01-15 19:26:39,938 iteration 866 : loss : 0.057023, loss_ce: 0.026361
2022-01-15 19:26:40,896 iteration 867 : loss : 0.098361, loss_ce: 0.040086
 13%|███▊                          | 51/400 [15:48<1:49:09, 18.77s/it]2022-01-15 19:26:41,981 iteration 868 : loss : 0.058047, loss_ce: 0.021893
2022-01-15 19:26:42,936 iteration 869 : loss : 0.071763, loss_ce: 0.032915
2022-01-15 19:26:43,946 iteration 870 : loss : 0.127010, loss_ce: 0.026666
2022-01-15 19:26:44,962 iteration 871 : loss : 0.090041, loss_ce: 0.027481
2022-01-15 19:26:45,887 iteration 872 : loss : 0.052516, loss_ce: 0.024749
2022-01-15 19:26:46,830 iteration 873 : loss : 0.054246, loss_ce: 0.018691
2022-01-15 19:26:47,848 iteration 874 : loss : 0.090291, loss_ce: 0.045314
2022-01-15 19:26:48,864 iteration 875 : loss : 0.089991, loss_ce: 0.048296
2022-01-15 19:26:49,852 iteration 876 : loss : 0.071129, loss_ce: 0.032563
2022-01-15 19:26:50,782 iteration 877 : loss : 0.064506, loss_ce: 0.022491
2022-01-15 19:26:51,727 iteration 878 : loss : 0.050797, loss_ce: 0.017085
2022-01-15 19:26:52,731 iteration 879 : loss : 0.080619, loss_ce: 0.030095
2022-01-15 19:26:53,688 iteration 880 : loss : 0.056954, loss_ce: 0.022442
2022-01-15 19:26:54,728 iteration 881 : loss : 0.080622, loss_ce: 0.031860
2022-01-15 19:26:55,687 iteration 882 : loss : 0.070265, loss_ce: 0.029938
2022-01-15 19:26:56,649 iteration 883 : loss : 0.095941, loss_ce: 0.034051
2022-01-15 19:26:57,761 iteration 884 : loss : 0.081802, loss_ce: 0.027579
 13%|███▉                          | 52/400 [16:05<1:45:31, 18.20s/it]2022-01-15 19:26:58,876 iteration 885 : loss : 0.091331, loss_ce: 0.040619
2022-01-15 19:26:59,837 iteration 886 : loss : 0.092690, loss_ce: 0.036818
2022-01-15 19:27:00,798 iteration 887 : loss : 0.086853, loss_ce: 0.042113
2022-01-15 19:27:01,789 iteration 888 : loss : 0.092946, loss_ce: 0.040401
2022-01-15 19:27:02,740 iteration 889 : loss : 0.075548, loss_ce: 0.024568
2022-01-15 19:27:03,787 iteration 890 : loss : 0.068154, loss_ce: 0.030376
2022-01-15 19:27:04,795 iteration 891 : loss : 0.073757, loss_ce: 0.037709
2022-01-15 19:27:05,787 iteration 892 : loss : 0.104932, loss_ce: 0.035601
2022-01-15 19:27:06,847 iteration 893 : loss : 0.084140, loss_ce: 0.038336
2022-01-15 19:27:07,833 iteration 894 : loss : 0.109772, loss_ce: 0.044470
2022-01-15 19:27:08,841 iteration 895 : loss : 0.091158, loss_ce: 0.035298
2022-01-15 19:27:09,885 iteration 896 : loss : 0.104350, loss_ce: 0.030633
2022-01-15 19:27:10,797 iteration 897 : loss : 0.052801, loss_ce: 0.021897
2022-01-15 19:27:11,902 iteration 898 : loss : 0.108469, loss_ce: 0.042033
2022-01-15 19:27:12,887 iteration 899 : loss : 0.085412, loss_ce: 0.030347
2022-01-15 19:27:13,902 iteration 900 : loss : 0.120919, loss_ce: 0.050769
2022-01-15 19:27:14,870 iteration 901 : loss : 0.072446, loss_ce: 0.036784
 13%|███▉                          | 53/400 [16:22<1:43:22, 17.87s/it]2022-01-15 19:27:15,924 iteration 902 : loss : 0.059265, loss_ce: 0.024165
2022-01-15 19:27:16,938 iteration 903 : loss : 0.069824, loss_ce: 0.024236
2022-01-15 19:27:17,899 iteration 904 : loss : 0.080384, loss_ce: 0.038106
2022-01-15 19:27:18,844 iteration 905 : loss : 0.116934, loss_ce: 0.032029
2022-01-15 19:27:19,792 iteration 906 : loss : 0.069707, loss_ce: 0.026459
2022-01-15 19:27:20,844 iteration 907 : loss : 0.058422, loss_ce: 0.029498
2022-01-15 19:27:21,787 iteration 908 : loss : 0.063836, loss_ce: 0.031356
2022-01-15 19:27:22,821 iteration 909 : loss : 0.102804, loss_ce: 0.052271
2022-01-15 19:27:23,833 iteration 910 : loss : 0.131423, loss_ce: 0.056304
2022-01-15 19:27:24,862 iteration 911 : loss : 0.087101, loss_ce: 0.032648
2022-01-15 19:27:25,791 iteration 912 : loss : 0.083295, loss_ce: 0.028870
2022-01-15 19:27:26,865 iteration 913 : loss : 0.081318, loss_ce: 0.031212
2022-01-15 19:27:27,854 iteration 914 : loss : 0.062822, loss_ce: 0.028574
2022-01-15 19:27:28,899 iteration 915 : loss : 0.081478, loss_ce: 0.039049
2022-01-15 19:27:29,886 iteration 916 : loss : 0.070307, loss_ce: 0.025577
2022-01-15 19:27:30,892 iteration 917 : loss : 0.088978, loss_ce: 0.037055
2022-01-15 19:27:31,896 iteration 918 : loss : 0.077292, loss_ce: 0.025735
 14%|████                          | 54/400 [16:39<1:41:35, 17.62s/it]2022-01-15 19:27:33,037 iteration 919 : loss : 0.064594, loss_ce: 0.027012
2022-01-15 19:27:33,982 iteration 920 : loss : 0.118819, loss_ce: 0.072478
2022-01-15 19:27:35,076 iteration 921 : loss : 0.053686, loss_ce: 0.021295
2022-01-15 19:27:35,976 iteration 922 : loss : 0.064778, loss_ce: 0.029807
2022-01-15 19:27:36,933 iteration 923 : loss : 0.084285, loss_ce: 0.031333
2022-01-15 19:27:37,938 iteration 924 : loss : 0.059660, loss_ce: 0.018331
2022-01-15 19:27:38,894 iteration 925 : loss : 0.047309, loss_ce: 0.017283
2022-01-15 19:27:39,843 iteration 926 : loss : 0.061091, loss_ce: 0.021436
2022-01-15 19:27:40,868 iteration 927 : loss : 0.096424, loss_ce: 0.047828
2022-01-15 19:27:41,830 iteration 928 : loss : 0.061071, loss_ce: 0.022347
2022-01-15 19:27:42,994 iteration 929 : loss : 0.077860, loss_ce: 0.033180
2022-01-15 19:27:44,005 iteration 930 : loss : 0.081049, loss_ce: 0.050902
2022-01-15 19:27:45,020 iteration 931 : loss : 0.060025, loss_ce: 0.023472
2022-01-15 19:27:46,025 iteration 932 : loss : 0.084464, loss_ce: 0.028260
2022-01-15 19:27:47,172 iteration 933 : loss : 0.111302, loss_ce: 0.038075
2022-01-15 19:27:48,158 iteration 934 : loss : 0.065942, loss_ce: 0.026329
2022-01-15 19:27:48,158 Training Data Eval:
2022-01-15 19:27:52,917   Average segmentation loss on training set: 0.0845
2022-01-15 19:27:52,917 Validation Data Eval:
2022-01-15 19:27:54,525   Average segmentation loss on validation set: 0.1701
2022-01-15 19:27:55,492 iteration 935 : loss : 0.062775, loss_ce: 0.023190
 14%|████▏                         | 55/400 [17:03<1:51:35, 19.41s/it]2022-01-15 19:27:56,519 iteration 936 : loss : 0.081502, loss_ce: 0.022947
2022-01-15 19:27:57,474 iteration 937 : loss : 0.075138, loss_ce: 0.028815
2022-01-15 19:27:58,476 iteration 938 : loss : 0.070855, loss_ce: 0.036091
2022-01-15 19:27:59,453 iteration 939 : loss : 0.096653, loss_ce: 0.043188
2022-01-15 19:28:00,392 iteration 940 : loss : 0.070535, loss_ce: 0.030891
2022-01-15 19:28:01,389 iteration 941 : loss : 0.104248, loss_ce: 0.034677
2022-01-15 19:28:02,356 iteration 942 : loss : 0.082875, loss_ce: 0.023790
2022-01-15 19:28:03,262 iteration 943 : loss : 0.130310, loss_ce: 0.040162
2022-01-15 19:28:04,217 iteration 944 : loss : 0.071023, loss_ce: 0.024600
2022-01-15 19:28:05,182 iteration 945 : loss : 0.091464, loss_ce: 0.047547
2022-01-15 19:28:06,175 iteration 946 : loss : 0.051881, loss_ce: 0.017827
2022-01-15 19:28:07,272 iteration 947 : loss : 0.077001, loss_ce: 0.032023
2022-01-15 19:28:08,224 iteration 948 : loss : 0.071205, loss_ce: 0.027525
2022-01-15 19:28:09,267 iteration 949 : loss : 0.048728, loss_ce: 0.018225
2022-01-15 19:28:10,277 iteration 950 : loss : 0.123571, loss_ce: 0.035836
2022-01-15 19:28:11,330 iteration 951 : loss : 0.070389, loss_ce: 0.030060
2022-01-15 19:28:12,260 iteration 952 : loss : 0.102092, loss_ce: 0.040256
 14%|████▏                         | 56/400 [17:20<1:46:44, 18.62s/it]2022-01-15 19:28:13,322 iteration 953 : loss : 0.058834, loss_ce: 0.019534
2022-01-15 19:28:14,422 iteration 954 : loss : 0.056801, loss_ce: 0.019486
2022-01-15 19:28:15,393 iteration 955 : loss : 0.051740, loss_ce: 0.019600
2022-01-15 19:28:16,369 iteration 956 : loss : 0.049315, loss_ce: 0.021146
2022-01-15 19:28:17,238 iteration 957 : loss : 0.099495, loss_ce: 0.037090
2022-01-15 19:28:18,211 iteration 958 : loss : 0.051444, loss_ce: 0.016597
2022-01-15 19:28:19,155 iteration 959 : loss : 0.070864, loss_ce: 0.032523
2022-01-15 19:28:20,111 iteration 960 : loss : 0.058192, loss_ce: 0.020976
2022-01-15 19:28:21,130 iteration 961 : loss : 0.099475, loss_ce: 0.036048
2022-01-15 19:28:22,109 iteration 962 : loss : 0.066323, loss_ce: 0.023643
2022-01-15 19:28:23,153 iteration 963 : loss : 0.072046, loss_ce: 0.026755
2022-01-15 19:28:24,179 iteration 964 : loss : 0.092978, loss_ce: 0.039637
2022-01-15 19:28:25,158 iteration 965 : loss : 0.049103, loss_ce: 0.019039
2022-01-15 19:28:26,245 iteration 966 : loss : 0.098889, loss_ce: 0.045136
2022-01-15 19:28:27,235 iteration 967 : loss : 0.085297, loss_ce: 0.033109
2022-01-15 19:28:28,243 iteration 968 : loss : 0.068124, loss_ce: 0.029828
2022-01-15 19:28:29,292 iteration 969 : loss : 0.065829, loss_ce: 0.022652
 14%|████▎                         | 57/400 [17:37<1:43:42, 18.14s/it]2022-01-15 19:28:30,326 iteration 970 : loss : 0.068903, loss_ce: 0.028645
2022-01-15 19:28:31,403 iteration 971 : loss : 0.096431, loss_ce: 0.035548
2022-01-15 19:28:32,331 iteration 972 : loss : 0.052210, loss_ce: 0.019981
2022-01-15 19:28:33,270 iteration 973 : loss : 0.073109, loss_ce: 0.027015
2022-01-15 19:28:34,264 iteration 974 : loss : 0.068281, loss_ce: 0.023067
2022-01-15 19:28:35,215 iteration 975 : loss : 0.077146, loss_ce: 0.027370
2022-01-15 19:28:36,181 iteration 976 : loss : 0.093237, loss_ce: 0.030975
2022-01-15 19:28:37,241 iteration 977 : loss : 0.064868, loss_ce: 0.020403
2022-01-15 19:28:38,282 iteration 978 : loss : 0.094915, loss_ce: 0.048345
2022-01-15 19:28:39,318 iteration 979 : loss : 0.060872, loss_ce: 0.029014
2022-01-15 19:28:40,248 iteration 980 : loss : 0.074449, loss_ce: 0.023769
2022-01-15 19:28:41,315 iteration 981 : loss : 0.080983, loss_ce: 0.028256
2022-01-15 19:28:42,251 iteration 982 : loss : 0.078682, loss_ce: 0.040321
2022-01-15 19:28:43,280 iteration 983 : loss : 0.067280, loss_ce: 0.028247
2022-01-15 19:28:44,277 iteration 984 : loss : 0.081580, loss_ce: 0.036441
2022-01-15 19:28:45,262 iteration 985 : loss : 0.084378, loss_ce: 0.028275
2022-01-15 19:28:46,237 iteration 986 : loss : 0.081488, loss_ce: 0.027223
 14%|████▎                         | 58/400 [17:54<1:41:21, 17.78s/it]2022-01-15 19:28:47,292 iteration 987 : loss : 0.061562, loss_ce: 0.024918
2022-01-15 19:28:48,363 iteration 988 : loss : 0.080760, loss_ce: 0.031980
2022-01-15 19:28:49,309 iteration 989 : loss : 0.053192, loss_ce: 0.018368
2022-01-15 19:28:50,366 iteration 990 : loss : 0.058686, loss_ce: 0.029630
2022-01-15 19:28:51,408 iteration 991 : loss : 0.077879, loss_ce: 0.037599
2022-01-15 19:28:52,348 iteration 992 : loss : 0.093444, loss_ce: 0.033693
2022-01-15 19:28:53,469 iteration 993 : loss : 0.070997, loss_ce: 0.027748
2022-01-15 19:28:54,510 iteration 994 : loss : 0.074474, loss_ce: 0.023311
2022-01-15 19:28:55,513 iteration 995 : loss : 0.070071, loss_ce: 0.024428
2022-01-15 19:28:56,466 iteration 996 : loss : 0.050339, loss_ce: 0.017411
2022-01-15 19:28:57,485 iteration 997 : loss : 0.105335, loss_ce: 0.051974
2022-01-15 19:28:58,483 iteration 998 : loss : 0.079663, loss_ce: 0.026931
2022-01-15 19:28:59,569 iteration 999 : loss : 0.056171, loss_ce: 0.021610
2022-01-15 19:29:00,577 iteration 1000 : loss : 0.062689, loss_ce: 0.027513
2022-01-15 19:29:01,584 iteration 1001 : loss : 0.080418, loss_ce: 0.030679
2022-01-15 19:29:02,513 iteration 1002 : loss : 0.058970, loss_ce: 0.016747
2022-01-15 19:29:03,470 iteration 1003 : loss : 0.076734, loss_ce: 0.031501
 15%|████▍                         | 59/400 [18:11<1:40:08, 17.62s/it]2022-01-15 19:29:04,503 iteration 1004 : loss : 0.067874, loss_ce: 0.029907
2022-01-15 19:29:05,592 iteration 1005 : loss : 0.084997, loss_ce: 0.031170
2022-01-15 19:29:06,582 iteration 1006 : loss : 0.089095, loss_ce: 0.042163
2022-01-15 19:29:07,603 iteration 1007 : loss : 0.062630, loss_ce: 0.022830
2022-01-15 19:29:08,615 iteration 1008 : loss : 0.108893, loss_ce: 0.028938
2022-01-15 19:29:09,639 iteration 1009 : loss : 0.082936, loss_ce: 0.035723
2022-01-15 19:29:10,610 iteration 1010 : loss : 0.053828, loss_ce: 0.020466
2022-01-15 19:29:11,607 iteration 1011 : loss : 0.044849, loss_ce: 0.017649
2022-01-15 19:29:12,701 iteration 1012 : loss : 0.128592, loss_ce: 0.045366
2022-01-15 19:29:13,678 iteration 1013 : loss : 0.086525, loss_ce: 0.025706
2022-01-15 19:29:14,719 iteration 1014 : loss : 0.067841, loss_ce: 0.026533
2022-01-15 19:29:15,711 iteration 1015 : loss : 0.065486, loss_ce: 0.029611
2022-01-15 19:29:16,638 iteration 1016 : loss : 0.055657, loss_ce: 0.028746
2022-01-15 19:29:17,757 iteration 1017 : loss : 0.068744, loss_ce: 0.023272
2022-01-15 19:29:18,829 iteration 1018 : loss : 0.055950, loss_ce: 0.021446
2022-01-15 19:29:19,914 iteration 1019 : loss : 0.069805, loss_ce: 0.026767
2022-01-15 19:29:19,915 Training Data Eval:
2022-01-15 19:29:24,760   Average segmentation loss on training set: 0.0493
2022-01-15 19:29:24,760 Validation Data Eval:
2022-01-15 19:29:26,395   Average segmentation loss on validation set: 0.0905
2022-01-15 19:29:27,362 Found new lowest validation loss at iteration 1019! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_1HEAD_NEW_best_val_loss_seed100.pth
2022-01-15 19:29:28,411 iteration 1020 : loss : 0.078189, loss_ce: 0.032067
 15%|████▌                         | 60/400 [18:36<1:52:18, 19.82s/it]2022-01-15 19:29:29,528 iteration 1021 : loss : 0.077578, loss_ce: 0.028616
2022-01-15 19:29:30,488 iteration 1022 : loss : 0.057269, loss_ce: 0.021439
2022-01-15 19:29:31,432 iteration 1023 : loss : 0.090468, loss_ce: 0.030888
2022-01-15 19:29:32,461 iteration 1024 : loss : 0.042386, loss_ce: 0.018968
2022-01-15 19:29:33,424 iteration 1025 : loss : 0.085079, loss_ce: 0.032726
2022-01-15 19:29:34,451 iteration 1026 : loss : 0.068383, loss_ce: 0.023405
2022-01-15 19:29:35,438 iteration 1027 : loss : 0.068366, loss_ce: 0.037332
2022-01-15 19:29:36,390 iteration 1028 : loss : 0.086154, loss_ce: 0.024484
2022-01-15 19:29:37,414 iteration 1029 : loss : 0.086755, loss_ce: 0.027108
2022-01-15 19:29:38,436 iteration 1030 : loss : 0.062919, loss_ce: 0.023829
2022-01-15 19:29:39,507 iteration 1031 : loss : 0.069249, loss_ce: 0.032792
2022-01-15 19:29:40,447 iteration 1032 : loss : 0.049522, loss_ce: 0.017922
2022-01-15 19:29:41,512 iteration 1033 : loss : 0.054644, loss_ce: 0.019763
2022-01-15 19:29:42,586 iteration 1034 : loss : 0.041425, loss_ce: 0.019824
2022-01-15 19:29:43,617 iteration 1035 : loss : 0.097670, loss_ce: 0.036987
2022-01-15 19:29:44,706 iteration 1036 : loss : 0.069551, loss_ce: 0.031557
2022-01-15 19:29:45,573 iteration 1037 : loss : 0.056680, loss_ce: 0.022246
 15%|████▌                         | 61/400 [18:53<1:47:27, 19.02s/it]2022-01-15 19:29:46,575 iteration 1038 : loss : 0.059397, loss_ce: 0.025401
2022-01-15 19:29:47,580 iteration 1039 : loss : 0.066837, loss_ce: 0.027286
2022-01-15 19:29:48,513 iteration 1040 : loss : 0.077613, loss_ce: 0.024460
2022-01-15 19:29:49,591 iteration 1041 : loss : 0.048843, loss_ce: 0.019290
2022-01-15 19:29:50,660 iteration 1042 : loss : 0.075931, loss_ce: 0.028379
2022-01-15 19:29:51,596 iteration 1043 : loss : 0.048919, loss_ce: 0.017283
2022-01-15 19:29:52,578 iteration 1044 : loss : 0.068581, loss_ce: 0.026703
2022-01-15 19:29:53,545 iteration 1045 : loss : 0.066494, loss_ce: 0.037609
2022-01-15 19:29:54,551 iteration 1046 : loss : 0.067587, loss_ce: 0.023765
2022-01-15 19:29:55,635 iteration 1047 : loss : 0.065996, loss_ce: 0.028688
2022-01-15 19:29:56,632 iteration 1048 : loss : 0.055565, loss_ce: 0.023634
2022-01-15 19:29:57,554 iteration 1049 : loss : 0.079676, loss_ce: 0.028213
2022-01-15 19:29:58,509 iteration 1050 : loss : 0.055636, loss_ce: 0.020068
2022-01-15 19:29:59,513 iteration 1051 : loss : 0.075184, loss_ce: 0.026159
2022-01-15 19:30:00,505 iteration 1052 : loss : 0.069851, loss_ce: 0.033524
2022-01-15 19:30:01,606 iteration 1053 : loss : 0.053067, loss_ce: 0.021606
2022-01-15 19:30:02,572 iteration 1054 : loss : 0.046334, loss_ce: 0.017155
 16%|████▋                         | 62/400 [19:10<1:43:42, 18.41s/it]2022-01-15 19:30:03,609 iteration 1055 : loss : 0.051884, loss_ce: 0.020342
2022-01-15 19:30:04,602 iteration 1056 : loss : 0.082516, loss_ce: 0.036772
2022-01-15 19:30:05,633 iteration 1057 : loss : 0.100537, loss_ce: 0.025165
2022-01-15 19:30:06,567 iteration 1058 : loss : 0.048682, loss_ce: 0.020616
2022-01-15 19:30:07,654 iteration 1059 : loss : 0.059254, loss_ce: 0.023484
2022-01-15 19:30:08,634 iteration 1060 : loss : 0.060338, loss_ce: 0.026169
2022-01-15 19:30:09,684 iteration 1061 : loss : 0.041776, loss_ce: 0.014631
2022-01-15 19:30:10,689 iteration 1062 : loss : 0.058060, loss_ce: 0.022939
2022-01-15 19:30:11,776 iteration 1063 : loss : 0.076227, loss_ce: 0.026769
2022-01-15 19:30:12,753 iteration 1064 : loss : 0.056655, loss_ce: 0.027608
2022-01-15 19:30:13,684 iteration 1065 : loss : 0.074811, loss_ce: 0.027017
2022-01-15 19:30:14,719 iteration 1066 : loss : 0.054988, loss_ce: 0.024513
2022-01-15 19:30:15,868 iteration 1067 : loss : 0.080741, loss_ce: 0.038871
2022-01-15 19:30:16,926 iteration 1068 : loss : 0.129913, loss_ce: 0.049195
2022-01-15 19:30:17,872 iteration 1069 : loss : 0.085169, loss_ce: 0.040135
2022-01-15 19:30:18,982 iteration 1070 : loss : 0.059462, loss_ce: 0.020371
2022-01-15 19:30:19,981 iteration 1071 : loss : 0.057354, loss_ce: 0.022984
 16%|████▋                         | 63/400 [19:27<1:41:43, 18.11s/it]2022-01-15 19:30:21,027 iteration 1072 : loss : 0.067539, loss_ce: 0.026747
2022-01-15 19:30:22,145 iteration 1073 : loss : 0.093286, loss_ce: 0.031959
2022-01-15 19:30:23,134 iteration 1074 : loss : 0.042236, loss_ce: 0.019531
2022-01-15 19:30:24,157 iteration 1075 : loss : 0.055784, loss_ce: 0.020298
2022-01-15 19:30:25,136 iteration 1076 : loss : 0.067502, loss_ce: 0.028947
2022-01-15 19:30:26,201 iteration 1077 : loss : 0.191788, loss_ce: 0.085250
2022-01-15 19:30:27,160 iteration 1078 : loss : 0.060849, loss_ce: 0.022651
2022-01-15 19:30:28,194 iteration 1079 : loss : 0.096784, loss_ce: 0.044310
2022-01-15 19:30:29,252 iteration 1080 : loss : 0.077370, loss_ce: 0.028066
2022-01-15 19:30:30,312 iteration 1081 : loss : 0.059811, loss_ce: 0.025494
2022-01-15 19:30:31,350 iteration 1082 : loss : 0.098709, loss_ce: 0.041467
2022-01-15 19:30:32,388 iteration 1083 : loss : 0.087766, loss_ce: 0.034363
2022-01-15 19:30:33,485 iteration 1084 : loss : 0.119067, loss_ce: 0.041791
2022-01-15 19:30:34,507 iteration 1085 : loss : 0.081811, loss_ce: 0.025978
2022-01-15 19:30:35,580 iteration 1086 : loss : 0.076745, loss_ce: 0.025842
2022-01-15 19:30:36,554 iteration 1087 : loss : 0.049750, loss_ce: 0.018604
2022-01-15 19:30:37,572 iteration 1088 : loss : 0.084209, loss_ce: 0.040423
 16%|████▊                         | 64/400 [19:45<1:40:33, 17.96s/it]2022-01-15 19:30:38,571 iteration 1089 : loss : 0.062328, loss_ce: 0.030842
2022-01-15 19:30:39,624 iteration 1090 : loss : 0.068472, loss_ce: 0.025474
2022-01-15 19:30:40,710 iteration 1091 : loss : 0.091760, loss_ce: 0.047344
2022-01-15 19:30:41,767 iteration 1092 : loss : 0.083056, loss_ce: 0.024824
2022-01-15 19:30:42,834 iteration 1093 : loss : 0.086539, loss_ce: 0.027583
2022-01-15 19:30:43,997 iteration 1094 : loss : 0.153101, loss_ce: 0.043779
2022-01-15 19:30:44,963 iteration 1095 : loss : 0.060222, loss_ce: 0.021933
2022-01-15 19:30:45,965 iteration 1096 : loss : 0.055326, loss_ce: 0.025045
2022-01-15 19:30:46,945 iteration 1097 : loss : 0.061883, loss_ce: 0.023905
2022-01-15 19:30:48,056 iteration 1098 : loss : 0.060678, loss_ce: 0.025905
2022-01-15 19:30:49,107 iteration 1099 : loss : 0.063307, loss_ce: 0.022974
2022-01-15 19:30:50,220 iteration 1100 : loss : 0.088357, loss_ce: 0.042791
2022-01-15 19:30:51,330 iteration 1101 : loss : 0.078293, loss_ce: 0.030941
2022-01-15 19:30:52,364 iteration 1102 : loss : 0.092008, loss_ce: 0.032666
2022-01-15 19:30:53,429 iteration 1103 : loss : 0.061001, loss_ce: 0.028181
2022-01-15 19:30:54,454 iteration 1104 : loss : 0.056228, loss_ce: 0.023920
2022-01-15 19:30:54,454 Training Data Eval:
2022-01-15 19:30:59,386   Average segmentation loss on training set: 0.0563
2022-01-15 19:30:59,387 Validation Data Eval:
2022-01-15 19:31:01,043   Average segmentation loss on validation set: 0.0947
2022-01-15 19:31:02,065 iteration 1105 : loss : 0.059564, loss_ce: 0.025228
 16%|████▉                         | 65/400 [20:09<1:51:12, 19.92s/it]2022-01-15 19:31:03,180 iteration 1106 : loss : 0.077170, loss_ce: 0.030764
2022-01-15 19:31:04,177 iteration 1107 : loss : 0.068647, loss_ce: 0.028223
2022-01-15 19:31:05,143 iteration 1108 : loss : 0.060975, loss_ce: 0.020186
2022-01-15 19:31:06,219 iteration 1109 : loss : 0.068994, loss_ce: 0.027045
2022-01-15 19:31:07,208 iteration 1110 : loss : 0.043455, loss_ce: 0.015297
2022-01-15 19:31:08,297 iteration 1111 : loss : 0.102443, loss_ce: 0.040600
2022-01-15 19:31:09,245 iteration 1112 : loss : 0.062396, loss_ce: 0.024363
2022-01-15 19:31:10,244 iteration 1113 : loss : 0.062081, loss_ce: 0.019653
2022-01-15 19:31:11,253 iteration 1114 : loss : 0.089101, loss_ce: 0.030712
2022-01-15 19:31:12,271 iteration 1115 : loss : 0.054877, loss_ce: 0.020018
2022-01-15 19:31:13,183 iteration 1116 : loss : 0.065047, loss_ce: 0.029560
2022-01-15 19:31:14,128 iteration 1117 : loss : 0.066680, loss_ce: 0.025143
2022-01-15 19:31:15,160 iteration 1118 : loss : 0.063968, loss_ce: 0.026733
2022-01-15 19:31:16,201 iteration 1119 : loss : 0.066212, loss_ce: 0.027270
2022-01-15 19:31:17,207 iteration 1120 : loss : 0.085962, loss_ce: 0.028647
2022-01-15 19:31:18,176 iteration 1121 : loss : 0.049458, loss_ce: 0.023493
2022-01-15 19:31:19,097 iteration 1122 : loss : 0.078515, loss_ce: 0.025139
 16%|████▉                         | 66/400 [20:27<1:46:03, 19.05s/it]2022-01-15 19:31:20,251 iteration 1123 : loss : 0.045044, loss_ce: 0.018505
2022-01-15 19:31:21,239 iteration 1124 : loss : 0.048378, loss_ce: 0.023090
2022-01-15 19:31:22,192 iteration 1125 : loss : 0.091558, loss_ce: 0.030217
2022-01-15 19:31:23,158 iteration 1126 : loss : 0.074507, loss_ce: 0.025030
2022-01-15 19:31:24,122 iteration 1127 : loss : 0.062908, loss_ce: 0.024844
2022-01-15 19:31:25,190 iteration 1128 : loss : 0.057600, loss_ce: 0.028966
2022-01-15 19:31:26,273 iteration 1129 : loss : 0.079196, loss_ce: 0.034737
2022-01-15 19:31:27,201 iteration 1130 : loss : 0.074520, loss_ce: 0.029944
2022-01-15 19:31:28,246 iteration 1131 : loss : 0.095665, loss_ce: 0.038716
2022-01-15 19:31:29,328 iteration 1132 : loss : 0.059375, loss_ce: 0.024902
2022-01-15 19:31:30,384 iteration 1133 : loss : 0.091403, loss_ce: 0.047708
2022-01-15 19:31:31,432 iteration 1134 : loss : 0.065633, loss_ce: 0.020570
2022-01-15 19:31:32,377 iteration 1135 : loss : 0.098073, loss_ce: 0.032506
2022-01-15 19:31:33,344 iteration 1136 : loss : 0.039183, loss_ce: 0.017691
2022-01-15 19:31:34,312 iteration 1137 : loss : 0.093649, loss_ce: 0.051935
2022-01-15 19:31:35,342 iteration 1138 : loss : 0.091232, loss_ce: 0.036781
2022-01-15 19:31:36,280 iteration 1139 : loss : 0.061274, loss_ce: 0.025383
 17%|█████                         | 67/400 [20:44<1:42:37, 18.49s/it]2022-01-15 19:31:37,336 iteration 1140 : loss : 0.057577, loss_ce: 0.022209
2022-01-15 19:31:38,350 iteration 1141 : loss : 0.071410, loss_ce: 0.032283
2022-01-15 19:31:39,466 iteration 1142 : loss : 0.053557, loss_ce: 0.021105
2022-01-15 19:31:40,476 iteration 1143 : loss : 0.065977, loss_ce: 0.024759
2022-01-15 19:31:41,500 iteration 1144 : loss : 0.098854, loss_ce: 0.034834
2022-01-15 19:31:42,496 iteration 1145 : loss : 0.069957, loss_ce: 0.023903
2022-01-15 19:31:43,455 iteration 1146 : loss : 0.047339, loss_ce: 0.019311
2022-01-15 19:31:44,421 iteration 1147 : loss : 0.052530, loss_ce: 0.018077
2022-01-15 19:31:45,379 iteration 1148 : loss : 0.055698, loss_ce: 0.023520
2022-01-15 19:31:46,370 iteration 1149 : loss : 0.061276, loss_ce: 0.031693
2022-01-15 19:31:47,324 iteration 1150 : loss : 0.064619, loss_ce: 0.024877
2022-01-15 19:31:48,296 iteration 1151 : loss : 0.057316, loss_ce: 0.023277
2022-01-15 19:31:49,242 iteration 1152 : loss : 0.075229, loss_ce: 0.028684
2022-01-15 19:31:50,324 iteration 1153 : loss : 0.080386, loss_ce: 0.023268
2022-01-15 19:31:51,348 iteration 1154 : loss : 0.056671, loss_ce: 0.018088
2022-01-15 19:31:52,386 iteration 1155 : loss : 0.066132, loss_ce: 0.023369
2022-01-15 19:31:53,495 iteration 1156 : loss : 0.074364, loss_ce: 0.025447
 17%|█████                         | 68/400 [21:01<1:40:10, 18.10s/it]2022-01-15 19:31:54,568 iteration 1157 : loss : 0.079574, loss_ce: 0.030138
2022-01-15 19:31:55,540 iteration 1158 : loss : 0.068614, loss_ce: 0.019829
2022-01-15 19:31:56,420 iteration 1159 : loss : 0.068496, loss_ce: 0.022723
2022-01-15 19:31:57,378 iteration 1160 : loss : 0.067215, loss_ce: 0.030813
2022-01-15 19:31:58,400 iteration 1161 : loss : 0.059273, loss_ce: 0.021743
2022-01-15 19:31:59,419 iteration 1162 : loss : 0.060283, loss_ce: 0.023845
2022-01-15 19:32:00,420 iteration 1163 : loss : 0.052104, loss_ce: 0.023744
2022-01-15 19:32:01,483 iteration 1164 : loss : 0.069716, loss_ce: 0.031387
2022-01-15 19:32:02,404 iteration 1165 : loss : 0.052325, loss_ce: 0.025265
2022-01-15 19:32:03,358 iteration 1166 : loss : 0.083764, loss_ce: 0.028159
2022-01-15 19:32:04,375 iteration 1167 : loss : 0.064779, loss_ce: 0.029850
2022-01-15 19:32:05,447 iteration 1168 : loss : 0.098911, loss_ce: 0.029648
2022-01-15 19:32:06,375 iteration 1169 : loss : 0.082563, loss_ce: 0.025622
2022-01-15 19:32:07,392 iteration 1170 : loss : 0.066442, loss_ce: 0.018295
2022-01-15 19:32:08,508 iteration 1171 : loss : 0.153665, loss_ce: 0.040206
2022-01-15 19:32:09,424 iteration 1172 : loss : 0.046343, loss_ce: 0.019558
2022-01-15 19:32:10,344 iteration 1173 : loss : 0.049059, loss_ce: 0.018155
 17%|█████▏                        | 69/400 [21:18<1:37:49, 17.73s/it]2022-01-15 19:32:11,430 iteration 1174 : loss : 0.056598, loss_ce: 0.021060
2022-01-15 19:32:12,504 iteration 1175 : loss : 0.065768, loss_ce: 0.032486
2022-01-15 19:32:13,458 iteration 1176 : loss : 0.059723, loss_ce: 0.023243
2022-01-15 19:32:14,421 iteration 1177 : loss : 0.112920, loss_ce: 0.061405
2022-01-15 19:32:15,347 iteration 1178 : loss : 0.106713, loss_ce: 0.046820
2022-01-15 19:32:16,396 iteration 1179 : loss : 0.061957, loss_ce: 0.023558
2022-01-15 19:32:17,412 iteration 1180 : loss : 0.068835, loss_ce: 0.027026
2022-01-15 19:32:18,334 iteration 1181 : loss : 0.091794, loss_ce: 0.032631
2022-01-15 19:32:19,304 iteration 1182 : loss : 0.068863, loss_ce: 0.027468
2022-01-15 19:32:20,290 iteration 1183 : loss : 0.069614, loss_ce: 0.033870
2022-01-15 19:32:21,298 iteration 1184 : loss : 0.104301, loss_ce: 0.042686
2022-01-15 19:32:22,283 iteration 1185 : loss : 0.060810, loss_ce: 0.033819
2022-01-15 19:32:23,299 iteration 1186 : loss : 0.056928, loss_ce: 0.019506
2022-01-15 19:32:24,244 iteration 1187 : loss : 0.047146, loss_ce: 0.021157
2022-01-15 19:32:25,287 iteration 1188 : loss : 0.093927, loss_ce: 0.034701
2022-01-15 19:32:26,332 iteration 1189 : loss : 0.139938, loss_ce: 0.035410
2022-01-15 19:32:26,332 Training Data Eval:
2022-01-15 19:32:31,111   Average segmentation loss on training set: 0.0730
2022-01-15 19:32:31,112 Validation Data Eval:
2022-01-15 19:32:32,747   Average segmentation loss on validation set: 0.1296
2022-01-15 19:32:33,722 iteration 1190 : loss : 0.076627, loss_ce: 0.024695
 18%|█████▎                        | 70/400 [21:41<1:46:49, 19.42s/it]2022-01-15 19:32:34,796 iteration 1191 : loss : 0.079213, loss_ce: 0.032644
2022-01-15 19:32:35,775 iteration 1192 : loss : 0.095189, loss_ce: 0.056049
2022-01-15 19:32:36,696 iteration 1193 : loss : 0.064804, loss_ce: 0.028626
2022-01-15 19:32:37,713 iteration 1194 : loss : 0.055993, loss_ce: 0.020367
2022-01-15 19:32:38,720 iteration 1195 : loss : 0.065035, loss_ce: 0.024328
2022-01-15 19:32:39,751 iteration 1196 : loss : 0.066499, loss_ce: 0.025411
2022-01-15 19:32:40,810 iteration 1197 : loss : 0.095673, loss_ce: 0.029393
2022-01-15 19:32:41,754 iteration 1198 : loss : 0.055755, loss_ce: 0.019879
2022-01-15 19:32:42,761 iteration 1199 : loss : 0.096219, loss_ce: 0.049646
2022-01-15 19:32:43,706 iteration 1200 : loss : 0.075433, loss_ce: 0.027762
2022-01-15 19:32:44,689 iteration 1201 : loss : 0.061431, loss_ce: 0.020041
2022-01-15 19:32:45,758 iteration 1202 : loss : 0.059219, loss_ce: 0.022960
2022-01-15 19:32:46,813 iteration 1203 : loss : 0.057036, loss_ce: 0.025165
2022-01-15 19:32:47,741 iteration 1204 : loss : 0.053043, loss_ce: 0.016758
2022-01-15 19:32:48,783 iteration 1205 : loss : 0.067343, loss_ce: 0.028849
2022-01-15 19:32:49,755 iteration 1206 : loss : 0.065996, loss_ce: 0.023433
2022-01-15 19:32:50,834 iteration 1207 : loss : 0.050785, loss_ce: 0.023752
 18%|█████▎                        | 71/400 [21:58<1:42:42, 18.73s/it]2022-01-15 19:32:51,882 iteration 1208 : loss : 0.058033, loss_ce: 0.023462
2022-01-15 19:32:52,899 iteration 1209 : loss : 0.059973, loss_ce: 0.022609
2022-01-15 19:32:53,829 iteration 1210 : loss : 0.056318, loss_ce: 0.021846
2022-01-15 19:32:54,931 iteration 1211 : loss : 0.060772, loss_ce: 0.027202
2022-01-15 19:32:55,918 iteration 1212 : loss : 0.048538, loss_ce: 0.019182
2022-01-15 19:32:56,818 iteration 1213 : loss : 0.039604, loss_ce: 0.014350
2022-01-15 19:32:57,911 iteration 1214 : loss : 0.067975, loss_ce: 0.028904
2022-01-15 19:32:58,903 iteration 1215 : loss : 0.051984, loss_ce: 0.021908
2022-01-15 19:32:59,893 iteration 1216 : loss : 0.055207, loss_ce: 0.021062
2022-01-15 19:33:01,026 iteration 1217 : loss : 0.103579, loss_ce: 0.039777
2022-01-15 19:33:01,961 iteration 1218 : loss : 0.081075, loss_ce: 0.033074
2022-01-15 19:33:03,118 iteration 1219 : loss : 0.074688, loss_ce: 0.036607
2022-01-15 19:33:04,111 iteration 1220 : loss : 0.051006, loss_ce: 0.019923
2022-01-15 19:33:05,181 iteration 1221 : loss : 0.058069, loss_ce: 0.021006
2022-01-15 19:33:06,139 iteration 1222 : loss : 0.063369, loss_ce: 0.021351
2022-01-15 19:33:07,102 iteration 1223 : loss : 0.068207, loss_ce: 0.023546
2022-01-15 19:33:08,081 iteration 1224 : loss : 0.140518, loss_ce: 0.071932
 18%|█████▍                        | 72/400 [22:16<1:39:57, 18.29s/it]2022-01-15 19:33:09,129 iteration 1225 : loss : 0.064570, loss_ce: 0.020127
2022-01-15 19:33:10,138 iteration 1226 : loss : 0.045924, loss_ce: 0.014652
2022-01-15 19:33:11,070 iteration 1227 : loss : 0.054973, loss_ce: 0.020458
2022-01-15 19:33:12,022 iteration 1228 : loss : 0.059778, loss_ce: 0.021181
2022-01-15 19:33:13,136 iteration 1229 : loss : 0.074245, loss_ce: 0.034258
2022-01-15 19:33:14,177 iteration 1230 : loss : 0.047614, loss_ce: 0.018930
2022-01-15 19:33:15,188 iteration 1231 : loss : 0.053284, loss_ce: 0.020402
2022-01-15 19:33:16,147 iteration 1232 : loss : 0.061208, loss_ce: 0.024679
2022-01-15 19:33:17,210 iteration 1233 : loss : 0.063448, loss_ce: 0.022047
2022-01-15 19:33:18,327 iteration 1234 : loss : 0.067575, loss_ce: 0.027396
2022-01-15 19:33:19,239 iteration 1235 : loss : 0.062495, loss_ce: 0.024079
2022-01-15 19:33:20,287 iteration 1236 : loss : 0.072605, loss_ce: 0.036411
2022-01-15 19:33:21,295 iteration 1237 : loss : 0.058058, loss_ce: 0.020774
2022-01-15 19:33:22,251 iteration 1238 : loss : 0.049225, loss_ce: 0.019553
2022-01-15 19:33:23,252 iteration 1239 : loss : 0.039037, loss_ce: 0.017351
2022-01-15 19:33:24,348 iteration 1240 : loss : 0.068405, loss_ce: 0.025776
2022-01-15 19:33:25,360 iteration 1241 : loss : 0.053805, loss_ce: 0.022707
 18%|█████▍                        | 73/400 [22:33<1:38:01, 17.99s/it]2022-01-15 19:33:26,490 iteration 1242 : loss : 0.057277, loss_ce: 0.028697
2022-01-15 19:33:27,510 iteration 1243 : loss : 0.055411, loss_ce: 0.019996
2022-01-15 19:33:28,622 iteration 1244 : loss : 0.055508, loss_ce: 0.024304
2022-01-15 19:33:29,711 iteration 1245 : loss : 0.056974, loss_ce: 0.021876
2022-01-15 19:33:30,718 iteration 1246 : loss : 0.060528, loss_ce: 0.026497
2022-01-15 19:33:31,918 iteration 1247 : loss : 0.085809, loss_ce: 0.033318
2022-01-15 19:33:32,901 iteration 1248 : loss : 0.063697, loss_ce: 0.021534
2022-01-15 19:33:33,924 iteration 1249 : loss : 0.059674, loss_ce: 0.026818
2022-01-15 19:33:34,965 iteration 1250 : loss : 0.107916, loss_ce: 0.026495
2022-01-15 19:33:36,061 iteration 1251 : loss : 0.059291, loss_ce: 0.023300
2022-01-15 19:33:37,017 iteration 1252 : loss : 0.075939, loss_ce: 0.023171
2022-01-15 19:33:38,022 iteration 1253 : loss : 0.048717, loss_ce: 0.019697
2022-01-15 19:33:39,040 iteration 1254 : loss : 0.062007, loss_ce: 0.020742
2022-01-15 19:33:40,174 iteration 1255 : loss : 0.064459, loss_ce: 0.023843
2022-01-15 19:33:41,170 iteration 1256 : loss : 0.048796, loss_ce: 0.016671
2022-01-15 19:33:42,072 iteration 1257 : loss : 0.046303, loss_ce: 0.016426
2022-01-15 19:33:42,986 iteration 1258 : loss : 0.053073, loss_ce: 0.024591
 18%|█████▌                        | 74/400 [22:50<1:37:07, 17.88s/it]2022-01-15 19:33:44,016 iteration 1259 : loss : 0.053794, loss_ce: 0.020155
2022-01-15 19:33:45,144 iteration 1260 : loss : 0.048300, loss_ce: 0.019895
2022-01-15 19:33:46,124 iteration 1261 : loss : 0.049624, loss_ce: 0.016964
2022-01-15 19:33:47,062 iteration 1262 : loss : 0.040554, loss_ce: 0.014323
2022-01-15 19:33:48,069 iteration 1263 : loss : 0.049204, loss_ce: 0.017541
2022-01-15 19:33:49,111 iteration 1264 : loss : 0.050543, loss_ce: 0.019758
2022-01-15 19:33:50,135 iteration 1265 : loss : 0.047437, loss_ce: 0.018424
2022-01-15 19:33:51,113 iteration 1266 : loss : 0.055950, loss_ce: 0.023900
2022-01-15 19:33:52,078 iteration 1267 : loss : 0.069505, loss_ce: 0.033274
2022-01-15 19:33:53,058 iteration 1268 : loss : 0.052552, loss_ce: 0.017583
2022-01-15 19:33:54,053 iteration 1269 : loss : 0.056942, loss_ce: 0.027162
2022-01-15 19:33:55,071 iteration 1270 : loss : 0.037727, loss_ce: 0.016202
2022-01-15 19:33:56,167 iteration 1271 : loss : 0.059312, loss_ce: 0.027261
2022-01-15 19:33:57,085 iteration 1272 : loss : 0.048052, loss_ce: 0.016882
2022-01-15 19:33:58,075 iteration 1273 : loss : 0.069870, loss_ce: 0.021680
2022-01-15 19:33:59,130 iteration 1274 : loss : 0.059680, loss_ce: 0.025428
2022-01-15 19:33:59,131 Training Data Eval:
2022-01-15 19:34:04,003   Average segmentation loss on training set: 0.0458
2022-01-15 19:34:04,003 Validation Data Eval:
2022-01-15 19:34:05,637   Average segmentation loss on validation set: 0.0956
2022-01-15 19:34:06,602 iteration 1275 : loss : 0.056572, loss_ce: 0.023404
 19%|█████▋                        | 75/400 [23:14<1:46:10, 19.60s/it]2022-01-15 19:34:07,654 iteration 1276 : loss : 0.045103, loss_ce: 0.021176
2022-01-15 19:34:08,783 iteration 1277 : loss : 0.070873, loss_ce: 0.029037
2022-01-15 19:34:09,785 iteration 1278 : loss : 0.084040, loss_ce: 0.037303
2022-01-15 19:34:10,771 iteration 1279 : loss : 0.071077, loss_ce: 0.025811
2022-01-15 19:34:11,803 iteration 1280 : loss : 0.046840, loss_ce: 0.020521
2022-01-15 19:34:12,757 iteration 1281 : loss : 0.066195, loss_ce: 0.029412
2022-01-15 19:34:13,751 iteration 1282 : loss : 0.040216, loss_ce: 0.017625
2022-01-15 19:34:14,676 iteration 1283 : loss : 0.081167, loss_ce: 0.018666
2022-01-15 19:34:15,672 iteration 1284 : loss : 0.058199, loss_ce: 0.020287
2022-01-15 19:34:16,624 iteration 1285 : loss : 0.038473, loss_ce: 0.011548
2022-01-15 19:34:17,708 iteration 1286 : loss : 0.088280, loss_ce: 0.028192
2022-01-15 19:34:18,775 iteration 1287 : loss : 0.042865, loss_ce: 0.018579
2022-01-15 19:34:19,742 iteration 1288 : loss : 0.058758, loss_ce: 0.021746
2022-01-15 19:34:20,755 iteration 1289 : loss : 0.079623, loss_ce: 0.030258
2022-01-15 19:34:21,729 iteration 1290 : loss : 0.122274, loss_ce: 0.039281
2022-01-15 19:34:22,700 iteration 1291 : loss : 0.075568, loss_ce: 0.029213
2022-01-15 19:34:23,679 iteration 1292 : loss : 0.068102, loss_ce: 0.037686
 19%|█████▋                        | 76/400 [23:31<1:41:44, 18.84s/it]2022-01-15 19:34:24,865 iteration 1293 : loss : 0.062423, loss_ce: 0.028916
2022-01-15 19:34:25,798 iteration 1294 : loss : 0.043188, loss_ce: 0.017260
2022-01-15 19:34:26,866 iteration 1295 : loss : 0.084986, loss_ce: 0.029078
2022-01-15 19:34:27,904 iteration 1296 : loss : 0.094518, loss_ce: 0.027271
2022-01-15 19:34:28,807 iteration 1297 : loss : 0.043567, loss_ce: 0.016588
2022-01-15 19:34:29,908 iteration 1298 : loss : 0.054584, loss_ce: 0.020867
2022-01-15 19:34:30,910 iteration 1299 : loss : 0.053662, loss_ce: 0.021770
2022-01-15 19:34:32,032 iteration 1300 : loss : 0.094728, loss_ce: 0.033677
2022-01-15 19:34:33,158 iteration 1301 : loss : 0.078975, loss_ce: 0.022395
2022-01-15 19:34:34,125 iteration 1302 : loss : 0.070607, loss_ce: 0.023738
2022-01-15 19:34:35,203 iteration 1303 : loss : 0.066978, loss_ce: 0.020269
2022-01-15 19:34:36,250 iteration 1304 : loss : 0.049396, loss_ce: 0.021626
2022-01-15 19:34:37,383 iteration 1305 : loss : 0.056902, loss_ce: 0.019325
2022-01-15 19:34:38,444 iteration 1306 : loss : 0.046240, loss_ce: 0.017322
2022-01-15 19:34:39,442 iteration 1307 : loss : 0.066168, loss_ce: 0.021926
2022-01-15 19:34:40,483 iteration 1308 : loss : 0.086092, loss_ce: 0.041021
2022-01-15 19:34:41,478 iteration 1309 : loss : 0.047117, loss_ce: 0.018316
 19%|█████▊                        | 77/400 [23:49<1:39:45, 18.53s/it]2022-01-15 19:34:42,533 iteration 1310 : loss : 0.066006, loss_ce: 0.023561
2022-01-15 19:34:43,652 iteration 1311 : loss : 0.073390, loss_ce: 0.024998
2022-01-15 19:34:44,660 iteration 1312 : loss : 0.063819, loss_ce: 0.020298
2022-01-15 19:34:45,662 iteration 1313 : loss : 0.051177, loss_ce: 0.019322
2022-01-15 19:34:46,741 iteration 1314 : loss : 0.068796, loss_ce: 0.030104
2022-01-15 19:34:47,835 iteration 1315 : loss : 0.052513, loss_ce: 0.028075
2022-01-15 19:34:48,810 iteration 1316 : loss : 0.052759, loss_ce: 0.022949
2022-01-15 19:34:49,768 iteration 1317 : loss : 0.054483, loss_ce: 0.019114
2022-01-15 19:34:50,737 iteration 1318 : loss : 0.052339, loss_ce: 0.019659
2022-01-15 19:34:51,805 iteration 1319 : loss : 0.060667, loss_ce: 0.021010
2022-01-15 19:34:52,779 iteration 1320 : loss : 0.052760, loss_ce: 0.021629
2022-01-15 19:34:53,825 iteration 1321 : loss : 0.054076, loss_ce: 0.023051
2022-01-15 19:34:54,839 iteration 1322 : loss : 0.051181, loss_ce: 0.018439
2022-01-15 19:34:55,924 iteration 1323 : loss : 0.053400, loss_ce: 0.017380
2022-01-15 19:34:57,032 iteration 1324 : loss : 0.045606, loss_ce: 0.017882
2022-01-15 19:34:58,038 iteration 1325 : loss : 0.066117, loss_ce: 0.026904
2022-01-15 19:34:59,052 iteration 1326 : loss : 0.059645, loss_ce: 0.021917
 20%|█████▊                        | 78/400 [24:06<1:37:53, 18.24s/it]2022-01-15 19:35:00,107 iteration 1327 : loss : 0.040416, loss_ce: 0.015039
2022-01-15 19:35:01,135 iteration 1328 : loss : 0.063832, loss_ce: 0.023337
2022-01-15 19:35:02,153 iteration 1329 : loss : 0.075506, loss_ce: 0.029691
2022-01-15 19:35:03,244 iteration 1330 : loss : 0.053091, loss_ce: 0.019014
2022-01-15 19:35:04,260 iteration 1331 : loss : 0.052170, loss_ce: 0.020690
2022-01-15 19:35:05,259 iteration 1332 : loss : 0.045928, loss_ce: 0.017968
2022-01-15 19:35:06,261 iteration 1333 : loss : 0.059267, loss_ce: 0.025636
2022-01-15 19:35:07,328 iteration 1334 : loss : 0.047736, loss_ce: 0.020339
2022-01-15 19:35:08,375 iteration 1335 : loss : 0.048030, loss_ce: 0.022178
2022-01-15 19:35:09,344 iteration 1336 : loss : 0.053053, loss_ce: 0.024848
2022-01-15 19:35:10,408 iteration 1337 : loss : 0.073017, loss_ce: 0.028289
2022-01-15 19:35:11,390 iteration 1338 : loss : 0.042066, loss_ce: 0.017164
2022-01-15 19:35:12,356 iteration 1339 : loss : 0.087876, loss_ce: 0.032209
2022-01-15 19:35:13,315 iteration 1340 : loss : 0.034770, loss_ce: 0.013851
2022-01-15 19:35:14,348 iteration 1341 : loss : 0.064153, loss_ce: 0.025477
2022-01-15 19:35:15,434 iteration 1342 : loss : 0.072963, loss_ce: 0.024635
2022-01-15 19:35:16,333 iteration 1343 : loss : 0.052158, loss_ce: 0.019091
 20%|█████▉                        | 79/400 [24:24<1:36:02, 17.95s/it]2022-01-15 19:35:17,415 iteration 1344 : loss : 0.050105, loss_ce: 0.016531
2022-01-15 19:35:18,369 iteration 1345 : loss : 0.047200, loss_ce: 0.012610
2022-01-15 19:35:19,403 iteration 1346 : loss : 0.048122, loss_ce: 0.017000
2022-01-15 19:35:20,392 iteration 1347 : loss : 0.051941, loss_ce: 0.022259
2022-01-15 19:35:21,334 iteration 1348 : loss : 0.061139, loss_ce: 0.026045
2022-01-15 19:35:22,318 iteration 1349 : loss : 0.090551, loss_ce: 0.034725
2022-01-15 19:35:23,296 iteration 1350 : loss : 0.072901, loss_ce: 0.022575
2022-01-15 19:35:24,382 iteration 1351 : loss : 0.080804, loss_ce: 0.032560
2022-01-15 19:35:25,315 iteration 1352 : loss : 0.053588, loss_ce: 0.024001
2022-01-15 19:35:26,307 iteration 1353 : loss : 0.054618, loss_ce: 0.027748
2022-01-15 19:35:27,305 iteration 1354 : loss : 0.059081, loss_ce: 0.020388
2022-01-15 19:35:28,219 iteration 1355 : loss : 0.060257, loss_ce: 0.018763
2022-01-15 19:35:29,294 iteration 1356 : loss : 0.062591, loss_ce: 0.022666
2022-01-15 19:35:30,216 iteration 1357 : loss : 0.047506, loss_ce: 0.022976
2022-01-15 19:35:31,171 iteration 1358 : loss : 0.053998, loss_ce: 0.025650
2022-01-15 19:35:32,253 iteration 1359 : loss : 0.059319, loss_ce: 0.030153
2022-01-15 19:35:32,253 Training Data Eval:
2022-01-15 19:35:37,104   Average segmentation loss on training set: 0.0491
2022-01-15 19:35:37,104 Validation Data Eval:
2022-01-15 19:35:38,750   Average segmentation loss on validation set: 0.0889
2022-01-15 19:35:39,656 Found new lowest validation loss at iteration 1359! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_1HEAD_NEW_best_val_loss_seed100.pth
2022-01-15 19:35:40,664 iteration 1360 : loss : 0.053274, loss_ce: 0.021809
 20%|██████                        | 80/400 [24:48<1:45:56, 19.87s/it]2022-01-15 19:35:41,754 iteration 1361 : loss : 0.074811, loss_ce: 0.020383
2022-01-15 19:35:42,707 iteration 1362 : loss : 0.078016, loss_ce: 0.023447
2022-01-15 19:35:43,695 iteration 1363 : loss : 0.048544, loss_ce: 0.019651
2022-01-15 19:35:44,593 iteration 1364 : loss : 0.063278, loss_ce: 0.031748
2022-01-15 19:35:45,539 iteration 1365 : loss : 0.058781, loss_ce: 0.019181
2022-01-15 19:35:46,618 iteration 1366 : loss : 0.078699, loss_ce: 0.027580
2022-01-15 19:35:47,634 iteration 1367 : loss : 0.061874, loss_ce: 0.031650
2022-01-15 19:35:48,824 iteration 1368 : loss : 0.065262, loss_ce: 0.024774
2022-01-15 19:35:49,807 iteration 1369 : loss : 0.063890, loss_ce: 0.020401
2022-01-15 19:35:50,762 iteration 1370 : loss : 0.042499, loss_ce: 0.016208
2022-01-15 19:35:51,755 iteration 1371 : loss : 0.054497, loss_ce: 0.021868
2022-01-15 19:35:52,909 iteration 1372 : loss : 0.068711, loss_ce: 0.027275
2022-01-15 19:35:53,881 iteration 1373 : loss : 0.049521, loss_ce: 0.021541
2022-01-15 19:35:54,833 iteration 1374 : loss : 0.047579, loss_ce: 0.017580
2022-01-15 19:35:55,837 iteration 1375 : loss : 0.041489, loss_ce: 0.016520
2022-01-15 19:35:56,841 iteration 1376 : loss : 0.038336, loss_ce: 0.011770
2022-01-15 19:35:57,913 iteration 1377 : loss : 0.056205, loss_ce: 0.034326
 20%|██████                        | 81/400 [25:05<1:41:27, 19.08s/it]2022-01-15 19:35:59,086 iteration 1378 : loss : 0.054848, loss_ce: 0.025996
2022-01-15 19:36:00,143 iteration 1379 : loss : 0.066732, loss_ce: 0.028477
2022-01-15 19:36:01,150 iteration 1380 : loss : 0.075308, loss_ce: 0.022984
2022-01-15 19:36:02,203 iteration 1381 : loss : 0.033108, loss_ce: 0.012456
2022-01-15 19:36:03,266 iteration 1382 : loss : 0.067834, loss_ce: 0.026748
2022-01-15 19:36:04,210 iteration 1383 : loss : 0.073211, loss_ce: 0.021554
2022-01-15 19:36:05,262 iteration 1384 : loss : 0.058768, loss_ce: 0.024882
2022-01-15 19:36:06,303 iteration 1385 : loss : 0.034341, loss_ce: 0.013137
2022-01-15 19:36:07,303 iteration 1386 : loss : 0.072148, loss_ce: 0.028975
2022-01-15 19:36:08,427 iteration 1387 : loss : 0.068355, loss_ce: 0.026423
2022-01-15 19:36:09,419 iteration 1388 : loss : 0.051171, loss_ce: 0.018941
2022-01-15 19:36:10,414 iteration 1389 : loss : 0.060122, loss_ce: 0.026621
2022-01-15 19:36:11,458 iteration 1390 : loss : 0.045351, loss_ce: 0.018504
2022-01-15 19:36:12,482 iteration 1391 : loss : 0.061835, loss_ce: 0.016927
2022-01-15 19:36:13,512 iteration 1392 : loss : 0.052512, loss_ce: 0.016494
2022-01-15 19:36:14,490 iteration 1393 : loss : 0.033718, loss_ce: 0.011542
2022-01-15 19:36:15,478 iteration 1394 : loss : 0.040669, loss_ce: 0.019211
 20%|██████▏                       | 82/400 [25:23<1:38:43, 18.63s/it]2022-01-15 19:36:16,538 iteration 1395 : loss : 0.043757, loss_ce: 0.018709
2022-01-15 19:36:17,505 iteration 1396 : loss : 0.044688, loss_ce: 0.017644
2022-01-15 19:36:18,523 iteration 1397 : loss : 0.059983, loss_ce: 0.018665
2022-01-15 19:36:19,618 iteration 1398 : loss : 0.048785, loss_ce: 0.021095
2022-01-15 19:36:20,647 iteration 1399 : loss : 0.090917, loss_ce: 0.049717
2022-01-15 19:36:21,621 iteration 1400 : loss : 0.071143, loss_ce: 0.034214
2022-01-15 19:36:22,596 iteration 1401 : loss : 0.078622, loss_ce: 0.024454
2022-01-15 19:36:23,519 iteration 1402 : loss : 0.046604, loss_ce: 0.018916
2022-01-15 19:36:24,646 iteration 1403 : loss : 0.049259, loss_ce: 0.017702
2022-01-15 19:36:25,712 iteration 1404 : loss : 0.046673, loss_ce: 0.016031
2022-01-15 19:36:26,756 iteration 1405 : loss : 0.046416, loss_ce: 0.021641
2022-01-15 19:36:27,777 iteration 1406 : loss : 0.068226, loss_ce: 0.022564
2022-01-15 19:36:28,730 iteration 1407 : loss : 0.048535, loss_ce: 0.025353
2022-01-15 19:36:29,716 iteration 1408 : loss : 0.077185, loss_ce: 0.022995
2022-01-15 19:36:30,829 iteration 1409 : loss : 0.059955, loss_ce: 0.022284
2022-01-15 19:36:31,883 iteration 1410 : loss : 0.061507, loss_ce: 0.021344
2022-01-15 19:36:32,883 iteration 1411 : loss : 0.054815, loss_ce: 0.025039
 21%|██████▏                       | 83/400 [25:40<1:36:27, 18.26s/it]2022-01-15 19:36:33,862 iteration 1412 : loss : 0.059055, loss_ce: 0.018916
2022-01-15 19:36:34,930 iteration 1413 : loss : 0.044850, loss_ce: 0.016702
2022-01-15 19:36:35,956 iteration 1414 : loss : 0.043785, loss_ce: 0.020408
2022-01-15 19:36:36,905 iteration 1415 : loss : 0.052393, loss_ce: 0.018514
2022-01-15 19:36:37,935 iteration 1416 : loss : 0.052486, loss_ce: 0.016122
2022-01-15 19:36:39,011 iteration 1417 : loss : 0.058334, loss_ce: 0.022161
2022-01-15 19:36:39,957 iteration 1418 : loss : 0.041530, loss_ce: 0.011989
2022-01-15 19:36:41,108 iteration 1419 : loss : 0.053038, loss_ce: 0.019960
2022-01-15 19:36:42,190 iteration 1420 : loss : 0.051068, loss_ce: 0.017890
2022-01-15 19:36:43,173 iteration 1421 : loss : 0.048920, loss_ce: 0.021336
2022-01-15 19:36:44,209 iteration 1422 : loss : 0.076462, loss_ce: 0.030830
2022-01-15 19:36:45,210 iteration 1423 : loss : 0.071943, loss_ce: 0.031270
2022-01-15 19:36:46,283 iteration 1424 : loss : 0.060538, loss_ce: 0.019705
2022-01-15 19:36:47,392 iteration 1425 : loss : 0.074429, loss_ce: 0.030394
2022-01-15 19:36:48,291 iteration 1426 : loss : 0.052085, loss_ce: 0.019515
2022-01-15 19:36:49,304 iteration 1427 : loss : 0.052941, loss_ce: 0.022191
2022-01-15 19:36:50,347 iteration 1428 : loss : 0.057298, loss_ce: 0.023340
 21%|██████▎                       | 84/400 [25:58<1:34:54, 18.02s/it]2022-01-15 19:36:51,547 iteration 1429 : loss : 0.064941, loss_ce: 0.024068
2022-01-15 19:36:52,515 iteration 1430 : loss : 0.059017, loss_ce: 0.018543
2022-01-15 19:36:53,521 iteration 1431 : loss : 0.050784, loss_ce: 0.025374
2022-01-15 19:36:54,551 iteration 1432 : loss : 0.061689, loss_ce: 0.023798
2022-01-15 19:36:55,664 iteration 1433 : loss : 0.075375, loss_ce: 0.035466
2022-01-15 19:36:56,741 iteration 1434 : loss : 0.050110, loss_ce: 0.017606
2022-01-15 19:36:57,649 iteration 1435 : loss : 0.061369, loss_ce: 0.017477
2022-01-15 19:36:58,733 iteration 1436 : loss : 0.086220, loss_ce: 0.042182
2022-01-15 19:36:59,663 iteration 1437 : loss : 0.098806, loss_ce: 0.020383
2022-01-15 19:37:00,572 iteration 1438 : loss : 0.052724, loss_ce: 0.024451
2022-01-15 19:37:01,579 iteration 1439 : loss : 0.035531, loss_ce: 0.010565
2022-01-15 19:37:02,664 iteration 1440 : loss : 0.057180, loss_ce: 0.025641
2022-01-15 19:37:03,634 iteration 1441 : loss : 0.036942, loss_ce: 0.015227
2022-01-15 19:37:04,581 iteration 1442 : loss : 0.065169, loss_ce: 0.021442
2022-01-15 19:37:05,610 iteration 1443 : loss : 0.052926, loss_ce: 0.019565
2022-01-15 19:37:06,674 iteration 1444 : loss : 0.036218, loss_ce: 0.016396
2022-01-15 19:37:06,674 Training Data Eval:
2022-01-15 19:37:11,466   Average segmentation loss on training set: 0.0510
2022-01-15 19:37:11,466 Validation Data Eval:
2022-01-15 19:37:13,105   Average segmentation loss on validation set: 0.0727
2022-01-15 19:37:14,009 Found new lowest validation loss at iteration 1444! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_1HEAD_NEW_best_val_loss_seed100.pth
2022-01-15 19:37:15,051 iteration 1445 : loss : 0.055486, loss_ce: 0.017809
 21%|██████▍                       | 85/400 [26:22<1:45:08, 20.03s/it]2022-01-15 19:37:16,145 iteration 1446 : loss : 0.068632, loss_ce: 0.026659
2022-01-15 19:37:17,173 iteration 1447 : loss : 0.072490, loss_ce: 0.030058
2022-01-15 19:37:18,147 iteration 1448 : loss : 0.055229, loss_ce: 0.027235
2022-01-15 19:37:19,157 iteration 1449 : loss : 0.071488, loss_ce: 0.027974
2022-01-15 19:37:20,072 iteration 1450 : loss : 0.053982, loss_ce: 0.022331
2022-01-15 19:37:21,041 iteration 1451 : loss : 0.046570, loss_ce: 0.016345
2022-01-15 19:37:22,085 iteration 1452 : loss : 0.077973, loss_ce: 0.017854
2022-01-15 19:37:23,181 iteration 1453 : loss : 0.045095, loss_ce: 0.013126
2022-01-15 19:37:24,159 iteration 1454 : loss : 0.049123, loss_ce: 0.020825
2022-01-15 19:37:25,140 iteration 1455 : loss : 0.058509, loss_ce: 0.025150
2022-01-15 19:37:26,160 iteration 1456 : loss : 0.065109, loss_ce: 0.021808
2022-01-15 19:37:27,180 iteration 1457 : loss : 0.058046, loss_ce: 0.025691
2022-01-15 19:37:28,184 iteration 1458 : loss : 0.040814, loss_ce: 0.015727
2022-01-15 19:37:29,094 iteration 1459 : loss : 0.041989, loss_ce: 0.018503
2022-01-15 19:37:30,163 iteration 1460 : loss : 0.103760, loss_ce: 0.057210
2022-01-15 19:37:31,161 iteration 1461 : loss : 0.063897, loss_ce: 0.024310
2022-01-15 19:37:32,163 iteration 1462 : loss : 0.051257, loss_ce: 0.022152
 22%|██████▍                       | 86/400 [26:40<1:40:13, 19.15s/it]2022-01-15 19:37:33,211 iteration 1463 : loss : 0.051312, loss_ce: 0.024177
2022-01-15 19:37:34,251 iteration 1464 : loss : 0.054168, loss_ce: 0.015776
2022-01-15 19:37:35,327 iteration 1465 : loss : 0.054981, loss_ce: 0.025939
2022-01-15 19:37:36,331 iteration 1466 : loss : 0.056950, loss_ce: 0.018787
2022-01-15 19:37:37,314 iteration 1467 : loss : 0.060323, loss_ce: 0.023592
2022-01-15 19:37:38,340 iteration 1468 : loss : 0.068027, loss_ce: 0.023881
2022-01-15 19:37:39,382 iteration 1469 : loss : 0.033452, loss_ce: 0.016006
2022-01-15 19:37:40,402 iteration 1470 : loss : 0.044863, loss_ce: 0.016743
2022-01-15 19:37:41,342 iteration 1471 : loss : 0.052308, loss_ce: 0.018092
2022-01-15 19:37:42,355 iteration 1472 : loss : 0.055587, loss_ce: 0.017278
2022-01-15 19:37:43,449 iteration 1473 : loss : 0.058992, loss_ce: 0.035812
2022-01-15 19:37:44,413 iteration 1474 : loss : 0.064029, loss_ce: 0.026193
2022-01-15 19:37:45,423 iteration 1475 : loss : 0.059793, loss_ce: 0.019821
2022-01-15 19:37:46,490 iteration 1476 : loss : 0.063550, loss_ce: 0.036108
2022-01-15 19:37:47,510 iteration 1477 : loss : 0.055429, loss_ce: 0.016746
2022-01-15 19:37:48,602 iteration 1478 : loss : 0.044224, loss_ce: 0.016549
2022-01-15 19:37:49,647 iteration 1479 : loss : 0.069575, loss_ce: 0.028211
 22%|██████▌                       | 87/400 [26:57<1:37:17, 18.65s/it]2022-01-15 19:37:50,724 iteration 1480 : loss : 0.060521, loss_ce: 0.031640
2022-01-15 19:37:51,822 iteration 1481 : loss : 0.055925, loss_ce: 0.027064
2022-01-15 19:37:52,821 iteration 1482 : loss : 0.055426, loss_ce: 0.024302
2022-01-15 19:37:53,776 iteration 1483 : loss : 0.047201, loss_ce: 0.019675
2022-01-15 19:37:54,750 iteration 1484 : loss : 0.046713, loss_ce: 0.020455
2022-01-15 19:37:55,748 iteration 1485 : loss : 0.059863, loss_ce: 0.023909
2022-01-15 19:37:56,763 iteration 1486 : loss : 0.070517, loss_ce: 0.024994
2022-01-15 19:37:57,871 iteration 1487 : loss : 0.101893, loss_ce: 0.061621
2022-01-15 19:37:58,877 iteration 1488 : loss : 0.037088, loss_ce: 0.014228
2022-01-15 19:37:59,931 iteration 1489 : loss : 0.037199, loss_ce: 0.015557
2022-01-15 19:38:00,965 iteration 1490 : loss : 0.040209, loss_ce: 0.016867
2022-01-15 19:38:01,935 iteration 1491 : loss : 0.062438, loss_ce: 0.022363
2022-01-15 19:38:03,002 iteration 1492 : loss : 0.051461, loss_ce: 0.020102
2022-01-15 19:38:04,145 iteration 1493 : loss : 0.084001, loss_ce: 0.036964
2022-01-15 19:38:05,194 iteration 1494 : loss : 0.062177, loss_ce: 0.022609
2022-01-15 19:38:06,203 iteration 1495 : loss : 0.053557, loss_ce: 0.018434
2022-01-15 19:38:07,212 iteration 1496 : loss : 0.054102, loss_ce: 0.019520
 22%|██████▌                       | 88/400 [27:15<1:35:17, 18.33s/it]2022-01-15 19:38:08,250 iteration 1497 : loss : 0.038405, loss_ce: 0.016742
2022-01-15 19:38:09,147 iteration 1498 : loss : 0.036497, loss_ce: 0.014140
2022-01-15 19:38:10,091 iteration 1499 : loss : 0.054459, loss_ce: 0.023674
2022-01-15 19:38:11,245 iteration 1500 : loss : 0.079118, loss_ce: 0.031059
2022-01-15 19:38:12,176 iteration 1501 : loss : 0.033944, loss_ce: 0.011700
2022-01-15 19:38:13,193 iteration 1502 : loss : 0.046114, loss_ce: 0.018701
2022-01-15 19:38:14,278 iteration 1503 : loss : 0.059388, loss_ce: 0.021356
2022-01-15 19:38:15,253 iteration 1504 : loss : 0.060268, loss_ce: 0.024124
2022-01-15 19:38:16,213 iteration 1505 : loss : 0.050315, loss_ce: 0.021507
2022-01-15 19:38:17,278 iteration 1506 : loss : 0.060893, loss_ce: 0.020129
2022-01-15 19:38:18,265 iteration 1507 : loss : 0.045182, loss_ce: 0.021937
2022-01-15 19:38:19,301 iteration 1508 : loss : 0.131567, loss_ce: 0.027725
2022-01-15 19:38:20,306 iteration 1509 : loss : 0.065945, loss_ce: 0.031336
2022-01-15 19:38:21,301 iteration 1510 : loss : 0.091789, loss_ce: 0.033872
2022-01-15 19:38:22,436 iteration 1511 : loss : 0.078133, loss_ce: 0.045670
2022-01-15 19:38:23,466 iteration 1512 : loss : 0.057459, loss_ce: 0.020461
2022-01-15 19:38:24,499 iteration 1513 : loss : 0.047353, loss_ce: 0.018607
 22%|██████▋                       | 89/400 [27:32<1:33:22, 18.01s/it]2022-01-15 19:38:25,600 iteration 1514 : loss : 0.061053, loss_ce: 0.022737
2022-01-15 19:38:26,613 iteration 1515 : loss : 0.039060, loss_ce: 0.016852
2022-01-15 19:38:27,657 iteration 1516 : loss : 0.056716, loss_ce: 0.030421
2022-01-15 19:38:28,633 iteration 1517 : loss : 0.055746, loss_ce: 0.024868
2022-01-15 19:38:29,569 iteration 1518 : loss : 0.044955, loss_ce: 0.019149
2022-01-15 19:38:30,562 iteration 1519 : loss : 0.051448, loss_ce: 0.019346
2022-01-15 19:38:31,725 iteration 1520 : loss : 0.070406, loss_ce: 0.031000
2022-01-15 19:38:32,688 iteration 1521 : loss : 0.043846, loss_ce: 0.015873
2022-01-15 19:38:33,758 iteration 1522 : loss : 0.044715, loss_ce: 0.015221
2022-01-15 19:38:34,771 iteration 1523 : loss : 0.053969, loss_ce: 0.021888
2022-01-15 19:38:35,717 iteration 1524 : loss : 0.051164, loss_ce: 0.017043
2022-01-15 19:38:36,714 iteration 1525 : loss : 0.049774, loss_ce: 0.021521
2022-01-15 19:38:37,713 iteration 1526 : loss : 0.063253, loss_ce: 0.020674
2022-01-15 19:38:38,818 iteration 1527 : loss : 0.037438, loss_ce: 0.015221
2022-01-15 19:38:39,873 iteration 1528 : loss : 0.049472, loss_ce: 0.017426
2022-01-15 19:38:40,872 iteration 1529 : loss : 0.059706, loss_ce: 0.018526
2022-01-15 19:38:40,872 Training Data Eval:
2022-01-15 19:38:45,765   Average segmentation loss on training set: 0.0409
2022-01-15 19:38:45,765 Validation Data Eval:
2022-01-15 19:38:47,414   Average segmentation loss on validation set: 0.1099
2022-01-15 19:38:48,401 iteration 1530 : loss : 0.052739, loss_ce: 0.025353
 22%|██████▊                       | 90/400 [27:56<1:42:12, 19.78s/it]2022-01-15 19:38:49,512 iteration 1531 : loss : 0.056266, loss_ce: 0.022160
2022-01-15 19:38:50,554 iteration 1532 : loss : 0.076445, loss_ce: 0.030611
2022-01-15 19:38:51,498 iteration 1533 : loss : 0.047050, loss_ce: 0.015290
2022-01-15 19:38:52,473 iteration 1534 : loss : 0.039671, loss_ce: 0.021711
2022-01-15 19:38:53,429 iteration 1535 : loss : 0.050905, loss_ce: 0.021351
2022-01-15 19:38:54,463 iteration 1536 : loss : 0.045246, loss_ce: 0.013956
2022-01-15 19:38:55,453 iteration 1537 : loss : 0.049152, loss_ce: 0.026263
2022-01-15 19:38:56,359 iteration 1538 : loss : 0.087578, loss_ce: 0.023577
2022-01-15 19:38:57,321 iteration 1539 : loss : 0.049479, loss_ce: 0.022222
2022-01-15 19:38:58,353 iteration 1540 : loss : 0.056135, loss_ce: 0.024391
2022-01-15 19:38:59,429 iteration 1541 : loss : 0.061416, loss_ce: 0.025655
2022-01-15 19:39:00,545 iteration 1542 : loss : 0.051077, loss_ce: 0.021894
2022-01-15 19:39:01,558 iteration 1543 : loss : 0.060501, loss_ce: 0.013955
2022-01-15 19:39:02,576 iteration 1544 : loss : 0.042424, loss_ce: 0.017969
2022-01-15 19:39:03,510 iteration 1545 : loss : 0.054122, loss_ce: 0.018145
2022-01-15 19:39:04,503 iteration 1546 : loss : 0.058306, loss_ce: 0.020153
2022-01-15 19:39:05,562 iteration 1547 : loss : 0.050176, loss_ce: 0.021670
 23%|██████▊                       | 91/400 [28:13<1:37:49, 19.00s/it]2022-01-15 19:39:06,637 iteration 1548 : loss : 0.060712, loss_ce: 0.021191
2022-01-15 19:39:07,584 iteration 1549 : loss : 0.078757, loss_ce: 0.030033
2022-01-15 19:39:08,652 iteration 1550 : loss : 0.060208, loss_ce: 0.018568
2022-01-15 19:39:09,690 iteration 1551 : loss : 0.074639, loss_ce: 0.025698
2022-01-15 19:39:10,684 iteration 1552 : loss : 0.044477, loss_ce: 0.013592
2022-01-15 19:39:11,743 iteration 1553 : loss : 0.066277, loss_ce: 0.031761
2022-01-15 19:39:12,663 iteration 1554 : loss : 0.094413, loss_ce: 0.052692
2022-01-15 19:39:13,647 iteration 1555 : loss : 0.051274, loss_ce: 0.016654
2022-01-15 19:39:14,769 iteration 1556 : loss : 0.072399, loss_ce: 0.030351
2022-01-15 19:39:15,770 iteration 1557 : loss : 0.056293, loss_ce: 0.017859
2022-01-15 19:39:16,723 iteration 1558 : loss : 0.064888, loss_ce: 0.022271
2022-01-15 19:39:17,825 iteration 1559 : loss : 0.061955, loss_ce: 0.023088
2022-01-15 19:39:18,808 iteration 1560 : loss : 0.057581, loss_ce: 0.031006
2022-01-15 19:39:19,815 iteration 1561 : loss : 0.056846, loss_ce: 0.021400
2022-01-15 19:39:20,820 iteration 1562 : loss : 0.072232, loss_ce: 0.035845
2022-01-15 19:39:21,846 iteration 1563 : loss : 0.061124, loss_ce: 0.021681
2022-01-15 19:39:22,819 iteration 1564 : loss : 0.050723, loss_ce: 0.018044
 23%|██████▉                       | 92/400 [28:30<1:34:50, 18.47s/it]2022-01-15 19:39:23,827 iteration 1565 : loss : 0.046362, loss_ce: 0.023621
2022-01-15 19:39:24,861 iteration 1566 : loss : 0.056757, loss_ce: 0.016845
2022-01-15 19:39:25,863 iteration 1567 : loss : 0.050974, loss_ce: 0.021323
2022-01-15 19:39:26,968 iteration 1568 : loss : 0.058335, loss_ce: 0.020773
2022-01-15 19:39:27,952 iteration 1569 : loss : 0.065718, loss_ce: 0.027463
2022-01-15 19:39:28,954 iteration 1570 : loss : 0.054543, loss_ce: 0.020343
2022-01-15 19:39:29,948 iteration 1571 : loss : 0.051309, loss_ce: 0.017332
2022-01-15 19:39:31,039 iteration 1572 : loss : 0.081146, loss_ce: 0.031205
2022-01-15 19:39:31,946 iteration 1573 : loss : 0.039016, loss_ce: 0.017108
2022-01-15 19:39:32,990 iteration 1574 : loss : 0.057907, loss_ce: 0.023978
2022-01-15 19:39:34,074 iteration 1575 : loss : 0.046161, loss_ce: 0.019122
2022-01-15 19:39:35,144 iteration 1576 : loss : 0.041964, loss_ce: 0.015773
2022-01-15 19:39:36,056 iteration 1577 : loss : 0.042444, loss_ce: 0.015536
2022-01-15 19:39:37,034 iteration 1578 : loss : 0.036189, loss_ce: 0.011632
2022-01-15 19:39:38,106 iteration 1579 : loss : 0.057159, loss_ce: 0.020075
2022-01-15 19:39:39,137 iteration 1580 : loss : 0.071858, loss_ce: 0.022650
2022-01-15 19:39:40,270 iteration 1581 : loss : 0.036241, loss_ce: 0.015452
 23%|██████▉                       | 93/400 [28:48<1:32:57, 18.17s/it]2022-01-15 19:39:41,347 iteration 1582 : loss : 0.032651, loss_ce: 0.011874
2022-01-15 19:39:42,362 iteration 1583 : loss : 0.057733, loss_ce: 0.029101
2022-01-15 19:39:43,274 iteration 1584 : loss : 0.052755, loss_ce: 0.016010
2022-01-15 19:39:44,278 iteration 1585 : loss : 0.073048, loss_ce: 0.018234
2022-01-15 19:39:45,344 iteration 1586 : loss : 0.053957, loss_ce: 0.015490
2022-01-15 19:39:46,345 iteration 1587 : loss : 0.048591, loss_ce: 0.014927
2022-01-15 19:39:47,404 iteration 1588 : loss : 0.041742, loss_ce: 0.021023
2022-01-15 19:39:48,395 iteration 1589 : loss : 0.058803, loss_ce: 0.017185
2022-01-15 19:39:49,418 iteration 1590 : loss : 0.065036, loss_ce: 0.029410
2022-01-15 19:39:50,374 iteration 1591 : loss : 0.078333, loss_ce: 0.042036
2022-01-15 19:39:51,351 iteration 1592 : loss : 0.062902, loss_ce: 0.031270
2022-01-15 19:39:52,441 iteration 1593 : loss : 0.042807, loss_ce: 0.014075
2022-01-15 19:39:53,481 iteration 1594 : loss : 0.050230, loss_ce: 0.026628
2022-01-15 19:39:54,521 iteration 1595 : loss : 0.053474, loss_ce: 0.021062
2022-01-15 19:39:55,543 iteration 1596 : loss : 0.043088, loss_ce: 0.019045
2022-01-15 19:39:56,528 iteration 1597 : loss : 0.044457, loss_ce: 0.015819
2022-01-15 19:39:57,629 iteration 1598 : loss : 0.052433, loss_ce: 0.024279
 24%|███████                       | 94/400 [29:05<1:31:24, 17.92s/it]2022-01-15 19:39:58,733 iteration 1599 : loss : 0.036954, loss_ce: 0.016256
2022-01-15 19:39:59,719 iteration 1600 : loss : 0.064767, loss_ce: 0.024202
2022-01-15 19:40:00,736 iteration 1601 : loss : 0.084440, loss_ce: 0.032698
2022-01-15 19:40:01,717 iteration 1602 : loss : 0.054006, loss_ce: 0.023748
2022-01-15 19:40:02,815 iteration 1603 : loss : 0.068067, loss_ce: 0.025350
2022-01-15 19:40:03,812 iteration 1604 : loss : 0.069908, loss_ce: 0.030821
2022-01-15 19:40:04,920 iteration 1605 : loss : 0.044605, loss_ce: 0.015826
2022-01-15 19:40:06,002 iteration 1606 : loss : 0.042641, loss_ce: 0.012835
2022-01-15 19:40:07,031 iteration 1607 : loss : 0.043733, loss_ce: 0.016444
2022-01-15 19:40:08,089 iteration 1608 : loss : 0.038438, loss_ce: 0.014481
2022-01-15 19:40:09,148 iteration 1609 : loss : 0.040107, loss_ce: 0.014643
2022-01-15 19:40:10,165 iteration 1610 : loss : 0.062787, loss_ce: 0.026278
2022-01-15 19:40:11,213 iteration 1611 : loss : 0.069234, loss_ce: 0.024118
2022-01-15 19:40:12,247 iteration 1612 : loss : 0.051814, loss_ce: 0.023848
2022-01-15 19:40:13,291 iteration 1613 : loss : 0.050717, loss_ce: 0.019752
2022-01-15 19:40:14,324 iteration 1614 : loss : 0.054825, loss_ce: 0.021138
2022-01-15 19:40:14,324 Training Data Eval:
2022-01-15 19:40:19,196   Average segmentation loss on training set: 0.0413
2022-01-15 19:40:19,196 Validation Data Eval:
2022-01-15 19:40:20,862   Average segmentation loss on validation set: 0.0727
2022-01-15 19:40:21,765 Found new lowest validation loss at iteration 1614! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_1HEAD_NEW_best_val_loss_seed100.pth
2022-01-15 19:40:22,813 iteration 1615 : loss : 0.061080, loss_ce: 0.024550
 24%|███████▏                      | 95/400 [29:30<1:42:11, 20.10s/it]2022-01-15 19:40:23,822 iteration 1616 : loss : 0.059188, loss_ce: 0.018689
2022-01-15 19:40:24,741 iteration 1617 : loss : 0.031659, loss_ce: 0.013763
2022-01-15 19:40:25,725 iteration 1618 : loss : 0.031276, loss_ce: 0.011629
2022-01-15 19:40:26,765 iteration 1619 : loss : 0.033741, loss_ce: 0.015947
2022-01-15 19:40:27,694 iteration 1620 : loss : 0.052178, loss_ce: 0.017185
2022-01-15 19:40:28,735 iteration 1621 : loss : 0.046862, loss_ce: 0.017651
2022-01-15 19:40:29,709 iteration 1622 : loss : 0.051742, loss_ce: 0.018237
2022-01-15 19:40:30,643 iteration 1623 : loss : 0.033945, loss_ce: 0.017350
2022-01-15 19:40:31,656 iteration 1624 : loss : 0.051405, loss_ce: 0.020324
2022-01-15 19:40:32,568 iteration 1625 : loss : 0.036518, loss_ce: 0.018270
2022-01-15 19:40:33,542 iteration 1626 : loss : 0.047045, loss_ce: 0.019563
2022-01-15 19:40:34,488 iteration 1627 : loss : 0.087867, loss_ce: 0.031977
2022-01-15 19:40:35,503 iteration 1628 : loss : 0.058234, loss_ce: 0.016629
2022-01-15 19:40:36,521 iteration 1629 : loss : 0.068618, loss_ce: 0.030027
2022-01-15 19:40:37,444 iteration 1630 : loss : 0.047785, loss_ce: 0.018975
2022-01-15 19:40:38,433 iteration 1631 : loss : 0.043825, loss_ce: 0.018455
2022-01-15 19:40:39,308 iteration 1632 : loss : 0.036747, loss_ce: 0.013138
 24%|███████▏                      | 96/400 [29:47<1:36:22, 19.02s/it]2022-01-15 19:40:40,428 iteration 1633 : loss : 0.041493, loss_ce: 0.014367
2022-01-15 19:40:41,442 iteration 1634 : loss : 0.040928, loss_ce: 0.016386
2022-01-15 19:40:42,408 iteration 1635 : loss : 0.051689, loss_ce: 0.023076
2022-01-15 19:40:43,293 iteration 1636 : loss : 0.041252, loss_ce: 0.015144
2022-01-15 19:40:44,353 iteration 1637 : loss : 0.050879, loss_ce: 0.016698
2022-01-15 19:40:45,371 iteration 1638 : loss : 0.044803, loss_ce: 0.016029
2022-01-15 19:40:46,433 iteration 1639 : loss : 0.045164, loss_ce: 0.016675
2022-01-15 19:40:47,411 iteration 1640 : loss : 0.044294, loss_ce: 0.018422
2022-01-15 19:40:48,427 iteration 1641 : loss : 0.047912, loss_ce: 0.019218
2022-01-15 19:40:49,525 iteration 1642 : loss : 0.077758, loss_ce: 0.024759
2022-01-15 19:40:50,545 iteration 1643 : loss : 0.028024, loss_ce: 0.011103
2022-01-15 19:40:51,562 iteration 1644 : loss : 0.054445, loss_ce: 0.022684
2022-01-15 19:40:52,457 iteration 1645 : loss : 0.042633, loss_ce: 0.014435
2022-01-15 19:40:53,433 iteration 1646 : loss : 0.039435, loss_ce: 0.017419
2022-01-15 19:40:54,503 iteration 1647 : loss : 0.047430, loss_ce: 0.025721
2022-01-15 19:40:55,472 iteration 1648 : loss : 0.059980, loss_ce: 0.028416
2022-01-15 19:40:56,548 iteration 1649 : loss : 0.069165, loss_ce: 0.019051
 24%|███████▎                      | 97/400 [30:04<1:33:21, 18.49s/it]2022-01-15 19:40:57,600 iteration 1650 : loss : 0.043662, loss_ce: 0.012743
2022-01-15 19:40:58,651 iteration 1651 : loss : 0.074576, loss_ce: 0.035026
2022-01-15 19:40:59,696 iteration 1652 : loss : 0.064200, loss_ce: 0.018511
2022-01-15 19:41:00,719 iteration 1653 : loss : 0.075845, loss_ce: 0.037645
2022-01-15 19:41:01,689 iteration 1654 : loss : 0.045408, loss_ce: 0.016920
2022-01-15 19:41:02,659 iteration 1655 : loss : 0.089016, loss_ce: 0.027594
2022-01-15 19:41:03,635 iteration 1656 : loss : 0.039362, loss_ce: 0.018662
2022-01-15 19:41:04,706 iteration 1657 : loss : 0.048507, loss_ce: 0.020306
2022-01-15 19:41:05,644 iteration 1658 : loss : 0.040007, loss_ce: 0.016652
2022-01-15 19:41:06,633 iteration 1659 : loss : 0.043529, loss_ce: 0.019294
2022-01-15 19:41:07,746 iteration 1660 : loss : 0.092021, loss_ce: 0.042352
2022-01-15 19:41:08,728 iteration 1661 : loss : 0.054729, loss_ce: 0.017743
2022-01-15 19:41:09,682 iteration 1662 : loss : 0.040489, loss_ce: 0.014518
2022-01-15 19:41:10,720 iteration 1663 : loss : 0.053197, loss_ce: 0.022564
2022-01-15 19:41:11,757 iteration 1664 : loss : 0.056129, loss_ce: 0.019106
2022-01-15 19:41:12,696 iteration 1665 : loss : 0.029463, loss_ce: 0.011355
2022-01-15 19:41:13,653 iteration 1666 : loss : 0.037609, loss_ce: 0.013830
 24%|███████▎                      | 98/400 [30:21<1:30:57, 18.07s/it]2022-01-15 19:41:14,710 iteration 1667 : loss : 0.037023, loss_ce: 0.015864
2022-01-15 19:41:15,757 iteration 1668 : loss : 0.059544, loss_ce: 0.029339
2022-01-15 19:41:16,733 iteration 1669 : loss : 0.034164, loss_ce: 0.015388
2022-01-15 19:41:17,714 iteration 1670 : loss : 0.051243, loss_ce: 0.020094
2022-01-15 19:41:18,740 iteration 1671 : loss : 0.053655, loss_ce: 0.019956
2022-01-15 19:41:19,725 iteration 1672 : loss : 0.050051, loss_ce: 0.017512
2022-01-15 19:41:20,669 iteration 1673 : loss : 0.033288, loss_ce: 0.013711
2022-01-15 19:41:21,729 iteration 1674 : loss : 0.043844, loss_ce: 0.017314
2022-01-15 19:41:22,701 iteration 1675 : loss : 0.036265, loss_ce: 0.014273
2022-01-15 19:41:23,748 iteration 1676 : loss : 0.039550, loss_ce: 0.017063
2022-01-15 19:41:24,805 iteration 1677 : loss : 0.044038, loss_ce: 0.018330
2022-01-15 19:41:25,838 iteration 1678 : loss : 0.052749, loss_ce: 0.016530
2022-01-15 19:41:26,889 iteration 1679 : loss : 0.039855, loss_ce: 0.011289
2022-01-15 19:41:27,916 iteration 1680 : loss : 0.039247, loss_ce: 0.018802
2022-01-15 19:41:28,922 iteration 1681 : loss : 0.058382, loss_ce: 0.016894
2022-01-15 19:41:29,903 iteration 1682 : loss : 0.052839, loss_ce: 0.025739
2022-01-15 19:41:30,956 iteration 1683 : loss : 0.056451, loss_ce: 0.024607
 25%|███████▍                      | 99/400 [30:38<1:29:30, 17.84s/it]2022-01-15 19:41:32,043 iteration 1684 : loss : 0.041843, loss_ce: 0.015368
2022-01-15 19:41:32,997 iteration 1685 : loss : 0.040979, loss_ce: 0.013685
2022-01-15 19:41:34,056 iteration 1686 : loss : 0.041428, loss_ce: 0.014895
2022-01-15 19:41:35,004 iteration 1687 : loss : 0.033540, loss_ce: 0.010637
2022-01-15 19:41:36,028 iteration 1688 : loss : 0.038762, loss_ce: 0.013879
2022-01-15 19:41:37,054 iteration 1689 : loss : 0.047747, loss_ce: 0.021912
2022-01-15 19:41:37,973 iteration 1690 : loss : 0.039744, loss_ce: 0.013377
2022-01-15 19:41:38,906 iteration 1691 : loss : 0.060411, loss_ce: 0.021369
2022-01-15 19:41:39,920 iteration 1692 : loss : 0.035649, loss_ce: 0.014565
2022-01-15 19:41:40,977 iteration 1693 : loss : 0.034860, loss_ce: 0.012779
2022-01-15 19:41:42,005 iteration 1694 : loss : 0.040261, loss_ce: 0.011389
2022-01-15 19:41:42,966 iteration 1695 : loss : 0.036384, loss_ce: 0.010970
2022-01-15 19:41:43,957 iteration 1696 : loss : 0.055238, loss_ce: 0.027415
2022-01-15 19:41:44,969 iteration 1697 : loss : 0.040046, loss_ce: 0.017051
2022-01-15 19:41:45,985 iteration 1698 : loss : 0.030908, loss_ce: 0.011321
2022-01-15 19:41:46,951 iteration 1699 : loss : 0.048303, loss_ce: 0.021245
2022-01-15 19:41:46,951 Training Data Eval:
2022-01-15 19:41:51,679   Average segmentation loss on training set: 0.0368
2022-01-15 19:41:51,679 Validation Data Eval:
2022-01-15 19:41:53,267   Average segmentation loss on validation set: 0.1214
2022-01-15 19:41:54,282 iteration 1700 : loss : 0.043244, loss_ce: 0.017476
 25%|███████▎                     | 100/400 [31:02<1:37:26, 19.49s/it]2022-01-15 19:41:55,326 iteration 1701 : loss : 0.037221, loss_ce: 0.014093
2022-01-15 19:41:56,313 iteration 1702 : loss : 0.037937, loss_ce: 0.014437
2022-01-15 19:41:57,365 iteration 1703 : loss : 0.052829, loss_ce: 0.021169
2022-01-15 19:41:58,341 iteration 1704 : loss : 0.044538, loss_ce: 0.024369
2022-01-15 19:41:59,364 iteration 1705 : loss : 0.044018, loss_ce: 0.015668
2022-01-15 19:42:00,418 iteration 1706 : loss : 0.071793, loss_ce: 0.033627
2022-01-15 19:42:01,375 iteration 1707 : loss : 0.047153, loss_ce: 0.020394
2022-01-15 19:42:02,356 iteration 1708 : loss : 0.073514, loss_ce: 0.020808
2022-01-15 19:42:03,358 iteration 1709 : loss : 0.048294, loss_ce: 0.022197
2022-01-15 19:42:04,385 iteration 1710 : loss : 0.044968, loss_ce: 0.014667
2022-01-15 19:42:05,376 iteration 1711 : loss : 0.066613, loss_ce: 0.033685
2022-01-15 19:42:06,309 iteration 1712 : loss : 0.030399, loss_ce: 0.012905
2022-01-15 19:42:07,343 iteration 1713 : loss : 0.062800, loss_ce: 0.020241
2022-01-15 19:42:08,437 iteration 1714 : loss : 0.051928, loss_ce: 0.013128
2022-01-15 19:42:09,505 iteration 1715 : loss : 0.054073, loss_ce: 0.021464
2022-01-15 19:42:10,428 iteration 1716 : loss : 0.059278, loss_ce: 0.019324
2022-01-15 19:42:11,478 iteration 1717 : loss : 0.058666, loss_ce: 0.016329
 25%|███████▎                     | 101/400 [31:19<1:33:40, 18.80s/it]2022-01-15 19:42:12,553 iteration 1718 : loss : 0.060082, loss_ce: 0.027989
2022-01-15 19:42:13,540 iteration 1719 : loss : 0.072402, loss_ce: 0.014788
2022-01-15 19:42:14,589 iteration 1720 : loss : 0.055194, loss_ce: 0.026194
2022-01-15 19:42:15,569 iteration 1721 : loss : 0.045890, loss_ce: 0.013943
2022-01-15 19:42:16,617 iteration 1722 : loss : 0.062152, loss_ce: 0.018705
2022-01-15 19:42:17,583 iteration 1723 : loss : 0.068366, loss_ce: 0.020230
2022-01-15 19:42:18,620 iteration 1724 : loss : 0.045559, loss_ce: 0.018949
2022-01-15 19:42:19,643 iteration 1725 : loss : 0.046683, loss_ce: 0.014417
2022-01-15 19:42:20,697 iteration 1726 : loss : 0.046348, loss_ce: 0.019412
2022-01-15 19:42:21,780 iteration 1727 : loss : 0.045459, loss_ce: 0.018211
2022-01-15 19:42:22,702 iteration 1728 : loss : 0.038927, loss_ce: 0.012749
2022-01-15 19:42:23,743 iteration 1729 : loss : 0.055291, loss_ce: 0.023147
2022-01-15 19:42:24,822 iteration 1730 : loss : 0.044681, loss_ce: 0.021303
2022-01-15 19:42:25,825 iteration 1731 : loss : 0.052532, loss_ce: 0.025555
2022-01-15 19:42:26,821 iteration 1732 : loss : 0.050293, loss_ce: 0.019790
2022-01-15 19:42:27,793 iteration 1733 : loss : 0.046908, loss_ce: 0.020608
2022-01-15 19:42:28,789 iteration 1734 : loss : 0.047433, loss_ce: 0.019576
 26%|███████▍                     | 102/400 [31:36<1:31:08, 18.35s/it]2022-01-15 19:42:30,000 iteration 1735 : loss : 0.034870, loss_ce: 0.015258
2022-01-15 19:42:30,975 iteration 1736 : loss : 0.055621, loss_ce: 0.021971
2022-01-15 19:42:32,113 iteration 1737 : loss : 0.064562, loss_ce: 0.029537
2022-01-15 19:42:33,114 iteration 1738 : loss : 0.042651, loss_ce: 0.022721
2022-01-15 19:42:34,058 iteration 1739 : loss : 0.038090, loss_ce: 0.014251
2022-01-15 19:42:35,123 iteration 1740 : loss : 0.037014, loss_ce: 0.015623
2022-01-15 19:42:36,178 iteration 1741 : loss : 0.036160, loss_ce: 0.012950
2022-01-15 19:42:37,243 iteration 1742 : loss : 0.044889, loss_ce: 0.015523
2022-01-15 19:42:38,179 iteration 1743 : loss : 0.050841, loss_ce: 0.016288
2022-01-15 19:42:39,270 iteration 1744 : loss : 0.071982, loss_ce: 0.028682
2022-01-15 19:42:40,348 iteration 1745 : loss : 0.050704, loss_ce: 0.019191
2022-01-15 19:42:41,365 iteration 1746 : loss : 0.057169, loss_ce: 0.026753
2022-01-15 19:42:42,338 iteration 1747 : loss : 0.050802, loss_ce: 0.021104
2022-01-15 19:42:43,378 iteration 1748 : loss : 0.045308, loss_ce: 0.015873
2022-01-15 19:42:44,296 iteration 1749 : loss : 0.041199, loss_ce: 0.012493
2022-01-15 19:42:45,337 iteration 1750 : loss : 0.108387, loss_ce: 0.024324
2022-01-15 19:42:46,459 iteration 1751 : loss : 0.038327, loss_ce: 0.013265
 26%|███████▍                     | 103/400 [31:54<1:29:50, 18.15s/it]2022-01-15 19:42:47,606 iteration 1752 : loss : 0.078061, loss_ce: 0.016880
2022-01-15 19:42:48,509 iteration 1753 : loss : 0.052320, loss_ce: 0.014435
2022-01-15 19:42:49,582 iteration 1754 : loss : 0.048505, loss_ce: 0.016002
2022-01-15 19:42:50,556 iteration 1755 : loss : 0.036498, loss_ce: 0.016686
2022-01-15 19:42:51,587 iteration 1756 : loss : 0.058957, loss_ce: 0.021397
2022-01-15 19:42:52,555 iteration 1757 : loss : 0.041767, loss_ce: 0.016481
2022-01-15 19:42:53,559 iteration 1758 : loss : 0.049376, loss_ce: 0.027582
2022-01-15 19:42:54,534 iteration 1759 : loss : 0.034310, loss_ce: 0.010257
2022-01-15 19:42:55,509 iteration 1760 : loss : 0.042495, loss_ce: 0.014576
2022-01-15 19:42:56,584 iteration 1761 : loss : 0.049283, loss_ce: 0.016065
2022-01-15 19:42:57,513 iteration 1762 : loss : 0.034043, loss_ce: 0.012721
2022-01-15 19:42:58,468 iteration 1763 : loss : 0.043558, loss_ce: 0.016667
2022-01-15 19:42:59,372 iteration 1764 : loss : 0.036987, loss_ce: 0.011356
2022-01-15 19:43:00,393 iteration 1765 : loss : 0.041945, loss_ce: 0.022070
2022-01-15 19:43:01,450 iteration 1766 : loss : 0.045316, loss_ce: 0.026031
2022-01-15 19:43:02,431 iteration 1767 : loss : 0.046136, loss_ce: 0.022507
2022-01-15 19:43:03,451 iteration 1768 : loss : 0.049437, loss_ce: 0.019587
 26%|███████▌                     | 104/400 [32:11<1:27:49, 17.80s/it]2022-01-15 19:43:04,512 iteration 1769 : loss : 0.049537, loss_ce: 0.019998
2022-01-15 19:43:05,467 iteration 1770 : loss : 0.042297, loss_ce: 0.016926
2022-01-15 19:43:06,376 iteration 1771 : loss : 0.062686, loss_ce: 0.025481
2022-01-15 19:43:07,332 iteration 1772 : loss : 0.037337, loss_ce: 0.018476
2022-01-15 19:43:08,383 iteration 1773 : loss : 0.071730, loss_ce: 0.022049
2022-01-15 19:43:09,395 iteration 1774 : loss : 0.030737, loss_ce: 0.009676
2022-01-15 19:43:10,431 iteration 1775 : loss : 0.038465, loss_ce: 0.015780
2022-01-15 19:43:11,389 iteration 1776 : loss : 0.036668, loss_ce: 0.017934
2022-01-15 19:43:12,338 iteration 1777 : loss : 0.035808, loss_ce: 0.012708
2022-01-15 19:43:13,271 iteration 1778 : loss : 0.044192, loss_ce: 0.014745
2022-01-15 19:43:14,323 iteration 1779 : loss : 0.060153, loss_ce: 0.017883
2022-01-15 19:43:15,322 iteration 1780 : loss : 0.058008, loss_ce: 0.025807
2022-01-15 19:43:16,249 iteration 1781 : loss : 0.044472, loss_ce: 0.019100
2022-01-15 19:43:17,267 iteration 1782 : loss : 0.052351, loss_ce: 0.020819
2022-01-15 19:43:18,275 iteration 1783 : loss : 0.043305, loss_ce: 0.016172
2022-01-15 19:43:19,239 iteration 1784 : loss : 0.046757, loss_ce: 0.017813
2022-01-15 19:43:19,239 Training Data Eval:
2022-01-15 19:43:24,001   Average segmentation loss on training set: 0.0359
2022-01-15 19:43:24,001 Validation Data Eval:
2022-01-15 19:43:25,620   Average segmentation loss on validation set: 0.0975
2022-01-15 19:43:26,671 iteration 1785 : loss : 0.043360, loss_ce: 0.016359
 26%|███████▌                     | 105/400 [32:34<1:35:30, 19.42s/it]2022-01-15 19:43:27,745 iteration 1786 : loss : 0.042591, loss_ce: 0.020420
2022-01-15 19:43:28,654 iteration 1787 : loss : 0.049215, loss_ce: 0.018470
2022-01-15 19:43:29,694 iteration 1788 : loss : 0.042841, loss_ce: 0.019678
2022-01-15 19:43:30,715 iteration 1789 : loss : 0.045532, loss_ce: 0.018654
2022-01-15 19:43:31,717 iteration 1790 : loss : 0.035785, loss_ce: 0.016668
2022-01-15 19:43:32,768 iteration 1791 : loss : 0.062433, loss_ce: 0.023761
2022-01-15 19:43:33,709 iteration 1792 : loss : 0.053611, loss_ce: 0.020542
2022-01-15 19:43:34,672 iteration 1793 : loss : 0.061447, loss_ce: 0.023369
2022-01-15 19:43:35,654 iteration 1794 : loss : 0.033166, loss_ce: 0.012907
2022-01-15 19:43:36,693 iteration 1795 : loss : 0.044345, loss_ce: 0.015963
2022-01-15 19:43:37,683 iteration 1796 : loss : 0.043360, loss_ce: 0.019568
2022-01-15 19:43:38,765 iteration 1797 : loss : 0.071701, loss_ce: 0.018603
2022-01-15 19:43:39,835 iteration 1798 : loss : 0.051632, loss_ce: 0.017969
2022-01-15 19:43:40,803 iteration 1799 : loss : 0.052534, loss_ce: 0.020923
2022-01-15 19:43:41,820 iteration 1800 : loss : 0.039544, loss_ce: 0.013877
2022-01-15 19:43:42,771 iteration 1801 : loss : 0.034119, loss_ce: 0.010656
2022-01-15 19:43:43,750 iteration 1802 : loss : 0.064134, loss_ce: 0.025991
 26%|███████▋                     | 106/400 [32:51<1:31:43, 18.72s/it]2022-01-15 19:43:44,892 iteration 1803 : loss : 0.056641, loss_ce: 0.024433
2022-01-15 19:43:45,966 iteration 1804 : loss : 0.063811, loss_ce: 0.024953
2022-01-15 19:43:46,945 iteration 1805 : loss : 0.076690, loss_ce: 0.027474
2022-01-15 19:43:47,924 iteration 1806 : loss : 0.059392, loss_ce: 0.033128
2022-01-15 19:43:48,909 iteration 1807 : loss : 0.061914, loss_ce: 0.022594
2022-01-15 19:43:49,914 iteration 1808 : loss : 0.042135, loss_ce: 0.014590
2022-01-15 19:43:50,892 iteration 1809 : loss : 0.036138, loss_ce: 0.013500
2022-01-15 19:43:51,808 iteration 1810 : loss : 0.033974, loss_ce: 0.011848
2022-01-15 19:43:52,877 iteration 1811 : loss : 0.044656, loss_ce: 0.021601
2022-01-15 19:43:53,968 iteration 1812 : loss : 0.054272, loss_ce: 0.019524
2022-01-15 19:43:55,111 iteration 1813 : loss : 0.053176, loss_ce: 0.019647
2022-01-15 19:43:56,150 iteration 1814 : loss : 0.038799, loss_ce: 0.017548
2022-01-15 19:43:57,104 iteration 1815 : loss : 0.051796, loss_ce: 0.016668
2022-01-15 19:43:58,034 iteration 1816 : loss : 0.036834, loss_ce: 0.015772
2022-01-15 19:43:59,126 iteration 1817 : loss : 0.046333, loss_ce: 0.017180
2022-01-15 19:44:00,150 iteration 1818 : loss : 0.061152, loss_ce: 0.025708
2022-01-15 19:44:01,220 iteration 1819 : loss : 0.052540, loss_ce: 0.022500
 27%|███████▊                     | 107/400 [33:09<1:29:36, 18.35s/it]2022-01-15 19:44:02,410 iteration 1820 : loss : 0.039577, loss_ce: 0.020338
2022-01-15 19:44:03,376 iteration 1821 : loss : 0.033277, loss_ce: 0.013901
2022-01-15 19:44:04,387 iteration 1822 : loss : 0.042222, loss_ce: 0.015934
2022-01-15 19:44:05,317 iteration 1823 : loss : 0.034454, loss_ce: 0.010730
2022-01-15 19:44:06,215 iteration 1824 : loss : 0.035652, loss_ce: 0.013850
2022-01-15 19:44:07,275 iteration 1825 : loss : 0.050815, loss_ce: 0.017938
2022-01-15 19:44:08,201 iteration 1826 : loss : 0.046261, loss_ce: 0.022411
2022-01-15 19:44:09,320 iteration 1827 : loss : 0.127046, loss_ce: 0.040627
2022-01-15 19:44:10,308 iteration 1828 : loss : 0.042522, loss_ce: 0.015626
2022-01-15 19:44:11,282 iteration 1829 : loss : 0.047501, loss_ce: 0.015218
2022-01-15 19:44:12,257 iteration 1830 : loss : 0.042530, loss_ce: 0.017151
2022-01-15 19:44:13,323 iteration 1831 : loss : 0.036049, loss_ce: 0.018057
2022-01-15 19:44:14,302 iteration 1832 : loss : 0.035459, loss_ce: 0.011545
2022-01-15 19:44:15,292 iteration 1833 : loss : 0.037449, loss_ce: 0.018998
2022-01-15 19:44:16,388 iteration 1834 : loss : 0.045232, loss_ce: 0.018130
2022-01-15 19:44:17,355 iteration 1835 : loss : 0.051236, loss_ce: 0.026551
2022-01-15 19:44:18,334 iteration 1836 : loss : 0.055358, loss_ce: 0.023199
 27%|███████▊                     | 108/400 [33:26<1:27:29, 17.98s/it]2022-01-15 19:44:19,435 iteration 1837 : loss : 0.051492, loss_ce: 0.024668
2022-01-15 19:44:20,474 iteration 1838 : loss : 0.052684, loss_ce: 0.023418
2022-01-15 19:44:21,438 iteration 1839 : loss : 0.051323, loss_ce: 0.021211
2022-01-15 19:44:22,347 iteration 1840 : loss : 0.042560, loss_ce: 0.019295
2022-01-15 19:44:23,379 iteration 1841 : loss : 0.072611, loss_ce: 0.032804
2022-01-15 19:44:24,437 iteration 1842 : loss : 0.052097, loss_ce: 0.021736
2022-01-15 19:44:25,366 iteration 1843 : loss : 0.033487, loss_ce: 0.014527
2022-01-15 19:44:26,368 iteration 1844 : loss : 0.052938, loss_ce: 0.018068
2022-01-15 19:44:27,294 iteration 1845 : loss : 0.035348, loss_ce: 0.014208
2022-01-15 19:44:28,390 iteration 1846 : loss : 0.051483, loss_ce: 0.019492
2022-01-15 19:44:29,427 iteration 1847 : loss : 0.076631, loss_ce: 0.033865
2022-01-15 19:44:30,416 iteration 1848 : loss : 0.031946, loss_ce: 0.013683
2022-01-15 19:44:31,311 iteration 1849 : loss : 0.027222, loss_ce: 0.012111
2022-01-15 19:44:32,310 iteration 1850 : loss : 0.068891, loss_ce: 0.022641
2022-01-15 19:44:33,339 iteration 1851 : loss : 0.084969, loss_ce: 0.054314
2022-01-15 19:44:34,343 iteration 1852 : loss : 0.043228, loss_ce: 0.016786
2022-01-15 19:44:35,346 iteration 1853 : loss : 0.046203, loss_ce: 0.010970
 27%|███████▉                     | 109/400 [33:43<1:25:47, 17.69s/it]2022-01-15 19:44:36,387 iteration 1854 : loss : 0.045024, loss_ce: 0.015012
2022-01-15 19:44:37,365 iteration 1855 : loss : 0.041587, loss_ce: 0.014058
2022-01-15 19:44:38,367 iteration 1856 : loss : 0.038339, loss_ce: 0.009911
2022-01-15 19:44:39,377 iteration 1857 : loss : 0.071823, loss_ce: 0.024138
2022-01-15 19:44:40,370 iteration 1858 : loss : 0.059203, loss_ce: 0.035384
2022-01-15 19:44:41,327 iteration 1859 : loss : 0.049300, loss_ce: 0.025847
2022-01-15 19:44:42,457 iteration 1860 : loss : 0.061673, loss_ce: 0.029974
2022-01-15 19:44:43,488 iteration 1861 : loss : 0.052328, loss_ce: 0.020049
2022-01-15 19:44:44,484 iteration 1862 : loss : 0.041984, loss_ce: 0.020591
2022-01-15 19:44:45,541 iteration 1863 : loss : 0.051191, loss_ce: 0.019762
2022-01-15 19:44:46,559 iteration 1864 : loss : 0.057782, loss_ce: 0.020933
2022-01-15 19:44:47,655 iteration 1865 : loss : 0.047276, loss_ce: 0.021314
2022-01-15 19:44:48,719 iteration 1866 : loss : 0.034380, loss_ce: 0.015977
2022-01-15 19:44:49,751 iteration 1867 : loss : 0.119618, loss_ce: 0.041571
2022-01-15 19:44:50,734 iteration 1868 : loss : 0.041690, loss_ce: 0.018736
2022-01-15 19:44:51,745 iteration 1869 : loss : 0.049356, loss_ce: 0.015676
2022-01-15 19:44:51,745 Training Data Eval:
2022-01-15 19:44:56,557   Average segmentation loss on training set: 0.0373
2022-01-15 19:44:56,557 Validation Data Eval:
2022-01-15 19:44:58,216   Average segmentation loss on validation set: 0.0825
2022-01-15 19:44:59,179 iteration 1870 : loss : 0.045686, loss_ce: 0.014103
 28%|███████▉                     | 110/400 [34:07<1:34:23, 19.53s/it]2022-01-15 19:45:00,238 iteration 1871 : loss : 0.043026, loss_ce: 0.018544
2022-01-15 19:45:01,206 iteration 1872 : loss : 0.044519, loss_ce: 0.015308
2022-01-15 19:45:02,233 iteration 1873 : loss : 0.057218, loss_ce: 0.022659
2022-01-15 19:45:03,295 iteration 1874 : loss : 0.048080, loss_ce: 0.019191
2022-01-15 19:45:04,377 iteration 1875 : loss : 0.043400, loss_ce: 0.022923
2022-01-15 19:45:05,456 iteration 1876 : loss : 0.055257, loss_ce: 0.014219
2022-01-15 19:45:06,512 iteration 1877 : loss : 0.037510, loss_ce: 0.012181
2022-01-15 19:45:07,464 iteration 1878 : loss : 0.040313, loss_ce: 0.014024
2022-01-15 19:45:08,438 iteration 1879 : loss : 0.040440, loss_ce: 0.018634
2022-01-15 19:45:09,418 iteration 1880 : loss : 0.037272, loss_ce: 0.012150
2022-01-15 19:45:10,393 iteration 1881 : loss : 0.034375, loss_ce: 0.011573
2022-01-15 19:45:11,428 iteration 1882 : loss : 0.052213, loss_ce: 0.012450
2022-01-15 19:45:12,388 iteration 1883 : loss : 0.035523, loss_ce: 0.013171
2022-01-15 19:45:13,479 iteration 1884 : loss : 0.037486, loss_ce: 0.015430
2022-01-15 19:45:14,434 iteration 1885 : loss : 0.032476, loss_ce: 0.012279
2022-01-15 19:45:15,464 iteration 1886 : loss : 0.059986, loss_ce: 0.032404
2022-01-15 19:45:16,433 iteration 1887 : loss : 0.044351, loss_ce: 0.015640
 28%|████████                     | 111/400 [34:24<1:30:47, 18.85s/it]2022-01-15 19:45:17,544 iteration 1888 : loss : 0.043339, loss_ce: 0.014001
2022-01-15 19:45:18,625 iteration 1889 : loss : 0.051404, loss_ce: 0.020939
2022-01-15 19:45:19,545 iteration 1890 : loss : 0.027540, loss_ce: 0.009513
2022-01-15 19:45:20,554 iteration 1891 : loss : 0.038878, loss_ce: 0.019284
2022-01-15 19:45:21,557 iteration 1892 : loss : 0.036695, loss_ce: 0.012775
2022-01-15 19:45:22,614 iteration 1893 : loss : 0.063065, loss_ce: 0.020896
2022-01-15 19:45:23,623 iteration 1894 : loss : 0.053353, loss_ce: 0.022631
2022-01-15 19:45:24,658 iteration 1895 : loss : 0.048331, loss_ce: 0.014416
2022-01-15 19:45:25,674 iteration 1896 : loss : 0.037006, loss_ce: 0.015158
2022-01-15 19:45:26,685 iteration 1897 : loss : 0.049659, loss_ce: 0.018768
2022-01-15 19:45:27,788 iteration 1898 : loss : 0.042839, loss_ce: 0.018839
2022-01-15 19:45:28,726 iteration 1899 : loss : 0.033067, loss_ce: 0.012493
2022-01-15 19:45:29,822 iteration 1900 : loss : 0.061417, loss_ce: 0.027357
2022-01-15 19:45:30,944 iteration 1901 : loss : 0.038173, loss_ce: 0.013352
2022-01-15 19:45:31,967 iteration 1902 : loss : 0.060055, loss_ce: 0.023042
2022-01-15 19:45:33,019 iteration 1903 : loss : 0.053056, loss_ce: 0.022342
2022-01-15 19:45:34,077 iteration 1904 : loss : 0.056813, loss_ce: 0.020030
 28%|████████                     | 112/400 [34:42<1:28:45, 18.49s/it]2022-01-15 19:45:35,196 iteration 1905 : loss : 0.043307, loss_ce: 0.017551
2022-01-15 19:45:36,203 iteration 1906 : loss : 0.047234, loss_ce: 0.014017
2022-01-15 19:45:37,189 iteration 1907 : loss : 0.030758, loss_ce: 0.011420
2022-01-15 19:45:38,313 iteration 1908 : loss : 0.055141, loss_ce: 0.020483
2022-01-15 19:45:39,333 iteration 1909 : loss : 0.041941, loss_ce: 0.014864
2022-01-15 19:45:40,369 iteration 1910 : loss : 0.079624, loss_ce: 0.016401
2022-01-15 19:45:41,431 iteration 1911 : loss : 0.037826, loss_ce: 0.012813
2022-01-15 19:45:42,356 iteration 1912 : loss : 0.037027, loss_ce: 0.014029
2022-01-15 19:45:43,366 iteration 1913 : loss : 0.042826, loss_ce: 0.019836
2022-01-15 19:45:44,385 iteration 1914 : loss : 0.040097, loss_ce: 0.017497
2022-01-15 19:45:45,417 iteration 1915 : loss : 0.035730, loss_ce: 0.017067
2022-01-15 19:45:46,414 iteration 1916 : loss : 0.048360, loss_ce: 0.019434
2022-01-15 19:45:47,414 iteration 1917 : loss : 0.041408, loss_ce: 0.018623
2022-01-15 19:45:48,450 iteration 1918 : loss : 0.037673, loss_ce: 0.013174
2022-01-15 19:45:49,425 iteration 1919 : loss : 0.035971, loss_ce: 0.012554
2022-01-15 19:45:50,415 iteration 1920 : loss : 0.045788, loss_ce: 0.018693
2022-01-15 19:45:51,511 iteration 1921 : loss : 0.056424, loss_ce: 0.026690
 28%|████████▏                    | 113/400 [34:59<1:26:55, 18.17s/it]2022-01-15 19:45:52,547 iteration 1922 : loss : 0.045648, loss_ce: 0.020043
2022-01-15 19:45:53,542 iteration 1923 : loss : 0.031543, loss_ce: 0.014941
2022-01-15 19:45:54,597 iteration 1924 : loss : 0.032624, loss_ce: 0.013713
2022-01-15 19:45:55,608 iteration 1925 : loss : 0.053244, loss_ce: 0.018707
2022-01-15 19:45:56,581 iteration 1926 : loss : 0.030253, loss_ce: 0.011394
2022-01-15 19:45:57,551 iteration 1927 : loss : 0.043569, loss_ce: 0.016570
2022-01-15 19:45:58,642 iteration 1928 : loss : 0.049054, loss_ce: 0.021850
2022-01-15 19:45:59,589 iteration 1929 : loss : 0.032006, loss_ce: 0.010547
2022-01-15 19:46:00,522 iteration 1930 : loss : 0.043013, loss_ce: 0.020299
2022-01-15 19:46:01,538 iteration 1931 : loss : 0.088330, loss_ce: 0.024205
2022-01-15 19:46:02,597 iteration 1932 : loss : 0.048873, loss_ce: 0.016622
2022-01-15 19:46:03,656 iteration 1933 : loss : 0.071922, loss_ce: 0.042195
2022-01-15 19:46:04,547 iteration 1934 : loss : 0.036466, loss_ce: 0.014009
2022-01-15 19:46:05,555 iteration 1935 : loss : 0.059468, loss_ce: 0.019725
2022-01-15 19:46:06,625 iteration 1936 : loss : 0.038777, loss_ce: 0.017472
2022-01-15 19:46:07,550 iteration 1937 : loss : 0.040405, loss_ce: 0.011431
2022-01-15 19:46:08,464 iteration 1938 : loss : 0.037345, loss_ce: 0.013366
 28%|████████▎                    | 114/400 [35:16<1:24:51, 17.80s/it]2022-01-15 19:46:09,486 iteration 1939 : loss : 0.034787, loss_ce: 0.011129
2022-01-15 19:46:10,591 iteration 1940 : loss : 0.040620, loss_ce: 0.018320
2022-01-15 19:46:11,674 iteration 1941 : loss : 0.051501, loss_ce: 0.024532
2022-01-15 19:46:12,684 iteration 1942 : loss : 0.071328, loss_ce: 0.027992
2022-01-15 19:46:13,640 iteration 1943 : loss : 0.049417, loss_ce: 0.017889
2022-01-15 19:46:14,627 iteration 1944 : loss : 0.035756, loss_ce: 0.013574
2022-01-15 19:46:15,573 iteration 1945 : loss : 0.052856, loss_ce: 0.018883
2022-01-15 19:46:16,571 iteration 1946 : loss : 0.038042, loss_ce: 0.013533
2022-01-15 19:46:17,595 iteration 1947 : loss : 0.059975, loss_ce: 0.025842
2022-01-15 19:46:18,582 iteration 1948 : loss : 0.051990, loss_ce: 0.016055
2022-01-15 19:46:19,538 iteration 1949 : loss : 0.030487, loss_ce: 0.012819
2022-01-15 19:46:20,467 iteration 1950 : loss : 0.032972, loss_ce: 0.014407
2022-01-15 19:46:21,519 iteration 1951 : loss : 0.060477, loss_ce: 0.025025
2022-01-15 19:46:22,536 iteration 1952 : loss : 0.044001, loss_ce: 0.013747
2022-01-15 19:46:23,591 iteration 1953 : loss : 0.050484, loss_ce: 0.023241
2022-01-15 19:46:24,594 iteration 1954 : loss : 0.030165, loss_ce: 0.014099
2022-01-15 19:46:24,594 Training Data Eval:
2022-01-15 19:46:29,305   Average segmentation loss on training set: 0.0292
2022-01-15 19:46:29,305 Validation Data Eval:
2022-01-15 19:46:30,899   Average segmentation loss on validation set: 0.1055
2022-01-15 19:46:31,919 iteration 1955 : loss : 0.046486, loss_ce: 0.013123
 29%|████████▎                    | 115/400 [35:39<1:32:38, 19.50s/it]2022-01-15 19:46:32,938 iteration 1956 : loss : 0.057892, loss_ce: 0.016542
2022-01-15 19:46:34,016 iteration 1957 : loss : 0.043817, loss_ce: 0.018118
2022-01-15 19:46:35,088 iteration 1958 : loss : 0.040862, loss_ce: 0.014921
2022-01-15 19:46:36,083 iteration 1959 : loss : 0.037346, loss_ce: 0.012585
2022-01-15 19:46:36,991 iteration 1960 : loss : 0.036881, loss_ce: 0.014604
2022-01-15 19:46:38,011 iteration 1961 : loss : 0.049448, loss_ce: 0.019996
2022-01-15 19:46:39,039 iteration 1962 : loss : 0.045896, loss_ce: 0.022166
2022-01-15 19:46:39,967 iteration 1963 : loss : 0.052341, loss_ce: 0.019868
2022-01-15 19:46:40,901 iteration 1964 : loss : 0.034836, loss_ce: 0.015044
2022-01-15 19:46:41,845 iteration 1965 : loss : 0.034607, loss_ce: 0.015034
2022-01-15 19:46:42,905 iteration 1966 : loss : 0.047389, loss_ce: 0.019079
2022-01-15 19:46:43,966 iteration 1967 : loss : 0.042928, loss_ce: 0.016060
2022-01-15 19:46:45,000 iteration 1968 : loss : 0.047342, loss_ce: 0.025894
2022-01-15 19:46:46,012 iteration 1969 : loss : 0.056241, loss_ce: 0.023476
2022-01-15 19:46:46,985 iteration 1970 : loss : 0.072029, loss_ce: 0.028338
2022-01-15 19:46:48,031 iteration 1971 : loss : 0.040107, loss_ce: 0.019279
2022-01-15 19:46:48,995 iteration 1972 : loss : 0.057625, loss_ce: 0.023165
 29%|████████▍                    | 116/400 [35:56<1:28:50, 18.77s/it]2022-01-15 19:46:49,919 iteration 1973 : loss : 0.035053, loss_ce: 0.014115
2022-01-15 19:46:50,943 iteration 1974 : loss : 0.050684, loss_ce: 0.021144
2022-01-15 19:46:51,933 iteration 1975 : loss : 0.044144, loss_ce: 0.013512
2022-01-15 19:46:53,007 iteration 1976 : loss : 0.034974, loss_ce: 0.015989
2022-01-15 19:46:54,012 iteration 1977 : loss : 0.048356, loss_ce: 0.013971
2022-01-15 19:46:54,932 iteration 1978 : loss : 0.032267, loss_ce: 0.013390
2022-01-15 19:46:55,860 iteration 1979 : loss : 0.034778, loss_ce: 0.012911
2022-01-15 19:46:56,892 iteration 1980 : loss : 0.048354, loss_ce: 0.021639
2022-01-15 19:46:57,865 iteration 1981 : loss : 0.041544, loss_ce: 0.012967
2022-01-15 19:46:58,791 iteration 1982 : loss : 0.049324, loss_ce: 0.016744
2022-01-15 19:46:59,882 iteration 1983 : loss : 0.038252, loss_ce: 0.019610
2022-01-15 19:47:00,829 iteration 1984 : loss : 0.042264, loss_ce: 0.011114
2022-01-15 19:47:01,856 iteration 1985 : loss : 0.032120, loss_ce: 0.012263
2022-01-15 19:47:02,883 iteration 1986 : loss : 0.051683, loss_ce: 0.025230
2022-01-15 19:47:03,945 iteration 1987 : loss : 0.032476, loss_ce: 0.013614
2022-01-15 19:47:04,883 iteration 1988 : loss : 0.042461, loss_ce: 0.013559
2022-01-15 19:47:05,871 iteration 1989 : loss : 0.047549, loss_ce: 0.021604
 29%|████████▍                    | 117/400 [36:13<1:25:52, 18.21s/it]2022-01-15 19:47:06,844 iteration 1990 : loss : 0.027279, loss_ce: 0.011682
2022-01-15 19:47:07,808 iteration 1991 : loss : 0.032117, loss_ce: 0.012528
2022-01-15 19:47:08,835 iteration 1992 : loss : 0.039802, loss_ce: 0.013966
2022-01-15 19:47:09,962 iteration 1993 : loss : 0.042700, loss_ce: 0.021385
2022-01-15 19:47:10,901 iteration 1994 : loss : 0.035454, loss_ce: 0.013630
2022-01-15 19:47:11,894 iteration 1995 : loss : 0.061248, loss_ce: 0.016941
2022-01-15 19:47:12,897 iteration 1996 : loss : 0.042396, loss_ce: 0.012643
2022-01-15 19:47:13,884 iteration 1997 : loss : 0.035805, loss_ce: 0.011655
2022-01-15 19:47:14,877 iteration 1998 : loss : 0.038125, loss_ce: 0.014691
2022-01-15 19:47:15,849 iteration 1999 : loss : 0.044298, loss_ce: 0.019459
2022-01-15 19:47:16,923 iteration 2000 : loss : 0.034582, loss_ce: 0.010269
2022-01-15 19:47:17,895 iteration 2001 : loss : 0.036309, loss_ce: 0.014298
2022-01-15 19:47:18,960 iteration 2002 : loss : 0.041356, loss_ce: 0.019687
2022-01-15 19:47:19,907 iteration 2003 : loss : 0.056896, loss_ce: 0.023983
2022-01-15 19:47:20,929 iteration 2004 : loss : 0.053374, loss_ce: 0.018163
2022-01-15 19:47:21,971 iteration 2005 : loss : 0.050797, loss_ce: 0.018555
2022-01-15 19:47:23,003 iteration 2006 : loss : 0.050718, loss_ce: 0.018492
 30%|████████▌                    | 118/400 [36:30<1:24:03, 17.88s/it]2022-01-15 19:47:24,087 iteration 2007 : loss : 0.044003, loss_ce: 0.019002
2022-01-15 19:47:25,031 iteration 2008 : loss : 0.040307, loss_ce: 0.015515
2022-01-15 19:47:26,013 iteration 2009 : loss : 0.061473, loss_ce: 0.018689
2022-01-15 19:47:26,941 iteration 2010 : loss : 0.042825, loss_ce: 0.016674
2022-01-15 19:47:27,915 iteration 2011 : loss : 0.037448, loss_ce: 0.015662
2022-01-15 19:47:28,925 iteration 2012 : loss : 0.056188, loss_ce: 0.017529
2022-01-15 19:47:29,973 iteration 2013 : loss : 0.048709, loss_ce: 0.017002
2022-01-15 19:47:31,010 iteration 2014 : loss : 0.033131, loss_ce: 0.011670
2022-01-15 19:47:31,935 iteration 2015 : loss : 0.034903, loss_ce: 0.012021
2022-01-15 19:47:32,928 iteration 2016 : loss : 0.044433, loss_ce: 0.014385
2022-01-15 19:47:33,831 iteration 2017 : loss : 0.029681, loss_ce: 0.012249
2022-01-15 19:47:34,852 iteration 2018 : loss : 0.042266, loss_ce: 0.016947
2022-01-15 19:47:35,803 iteration 2019 : loss : 0.037713, loss_ce: 0.015298
2022-01-15 19:47:36,827 iteration 2020 : loss : 0.043138, loss_ce: 0.018276
2022-01-15 19:47:37,870 iteration 2021 : loss : 0.043540, loss_ce: 0.016430
2022-01-15 19:47:38,937 iteration 2022 : loss : 0.052586, loss_ce: 0.024391
2022-01-15 19:47:39,933 iteration 2023 : loss : 0.053131, loss_ce: 0.014741
 30%|████████▋                    | 119/400 [36:47<1:22:24, 17.59s/it]2022-01-15 19:47:41,033 iteration 2024 : loss : 0.045836, loss_ce: 0.018900
2022-01-15 19:47:41,982 iteration 2025 : loss : 0.026231, loss_ce: 0.008362
2022-01-15 19:47:42,947 iteration 2026 : loss : 0.042196, loss_ce: 0.017352
2022-01-15 19:47:43,995 iteration 2027 : loss : 0.041904, loss_ce: 0.014084
2022-01-15 19:47:45,026 iteration 2028 : loss : 0.046497, loss_ce: 0.016723
2022-01-15 19:47:45,957 iteration 2029 : loss : 0.035418, loss_ce: 0.016973
2022-01-15 19:47:46,973 iteration 2030 : loss : 0.038790, loss_ce: 0.013622
2022-01-15 19:47:48,003 iteration 2031 : loss : 0.036929, loss_ce: 0.013284
2022-01-15 19:47:49,038 iteration 2032 : loss : 0.043514, loss_ce: 0.015995
2022-01-15 19:47:50,022 iteration 2033 : loss : 0.055358, loss_ce: 0.015451
2022-01-15 19:47:50,931 iteration 2034 : loss : 0.032010, loss_ce: 0.010430
2022-01-15 19:47:51,855 iteration 2035 : loss : 0.030621, loss_ce: 0.013988
2022-01-15 19:47:52,895 iteration 2036 : loss : 0.042426, loss_ce: 0.017865
2022-01-15 19:47:53,897 iteration 2037 : loss : 0.042563, loss_ce: 0.014782
2022-01-15 19:47:54,849 iteration 2038 : loss : 0.034377, loss_ce: 0.012404
2022-01-15 19:47:55,868 iteration 2039 : loss : 0.045834, loss_ce: 0.020333
2022-01-15 19:47:55,868 Training Data Eval:
2022-01-15 19:48:00,640   Average segmentation loss on training set: 0.0260
2022-01-15 19:48:00,640 Validation Data Eval:
2022-01-15 19:48:02,278   Average segmentation loss on validation set: 0.0748
2022-01-15 19:48:03,263 iteration 2040 : loss : 0.031629, loss_ce: 0.009875
 30%|████████▋                    | 120/400 [37:11<1:30:08, 19.32s/it]2022-01-15 19:48:04,323 iteration 2041 : loss : 0.030325, loss_ce: 0.012060
2022-01-15 19:48:05,306 iteration 2042 : loss : 0.029555, loss_ce: 0.013033
2022-01-15 19:48:06,305 iteration 2043 : loss : 0.026252, loss_ce: 0.012013
2022-01-15 19:48:07,359 iteration 2044 : loss : 0.034629, loss_ce: 0.014762
2022-01-15 19:48:08,426 iteration 2045 : loss : 0.036709, loss_ce: 0.016293
2022-01-15 19:48:09,443 iteration 2046 : loss : 0.046902, loss_ce: 0.019416
2022-01-15 19:48:10,448 iteration 2047 : loss : 0.043638, loss_ce: 0.014496
2022-01-15 19:48:11,358 iteration 2048 : loss : 0.037677, loss_ce: 0.012443
2022-01-15 19:48:12,323 iteration 2049 : loss : 0.044481, loss_ce: 0.019377
2022-01-15 19:48:13,342 iteration 2050 : loss : 0.043148, loss_ce: 0.012856
2022-01-15 19:48:14,367 iteration 2051 : loss : 0.042728, loss_ce: 0.014839
2022-01-15 19:48:15,309 iteration 2052 : loss : 0.029796, loss_ce: 0.014218
2022-01-15 19:48:16,250 iteration 2053 : loss : 0.031902, loss_ce: 0.010456
2022-01-15 19:48:17,251 iteration 2054 : loss : 0.042650, loss_ce: 0.014132
2022-01-15 19:48:18,273 iteration 2055 : loss : 0.059148, loss_ce: 0.027192
2022-01-15 19:48:19,295 iteration 2056 : loss : 0.044044, loss_ce: 0.019936
2022-01-15 19:48:20,343 iteration 2057 : loss : 0.040268, loss_ce: 0.016458
 30%|████████▊                    | 121/400 [37:28<1:26:42, 18.65s/it]2022-01-15 19:48:21,507 iteration 2058 : loss : 0.047766, loss_ce: 0.021030
2022-01-15 19:48:22,547 iteration 2059 : loss : 0.040165, loss_ce: 0.013212
2022-01-15 19:48:23,606 iteration 2060 : loss : 0.042468, loss_ce: 0.015748
2022-01-15 19:48:24,584 iteration 2061 : loss : 0.037582, loss_ce: 0.015901
2022-01-15 19:48:25,530 iteration 2062 : loss : 0.031783, loss_ce: 0.010378
2022-01-15 19:48:26,498 iteration 2063 : loss : 0.024742, loss_ce: 0.010674
2022-01-15 19:48:27,531 iteration 2064 : loss : 0.034839, loss_ce: 0.016832
2022-01-15 19:48:28,572 iteration 2065 : loss : 0.036608, loss_ce: 0.011129
2022-01-15 19:48:29,644 iteration 2066 : loss : 0.054197, loss_ce: 0.017466
2022-01-15 19:48:30,628 iteration 2067 : loss : 0.037313, loss_ce: 0.014370
2022-01-15 19:48:31,704 iteration 2068 : loss : 0.036635, loss_ce: 0.017569
2022-01-15 19:48:32,782 iteration 2069 : loss : 0.037381, loss_ce: 0.010109
2022-01-15 19:48:33,756 iteration 2070 : loss : 0.029557, loss_ce: 0.010561
2022-01-15 19:48:34,741 iteration 2071 : loss : 0.041325, loss_ce: 0.019143
2022-01-15 19:48:35,686 iteration 2072 : loss : 0.035688, loss_ce: 0.015630
2022-01-15 19:48:36,634 iteration 2073 : loss : 0.040002, loss_ce: 0.013049
2022-01-15 19:48:37,658 iteration 2074 : loss : 0.054536, loss_ce: 0.013758
 30%|████████▊                    | 122/400 [37:45<1:24:32, 18.25s/it]2022-01-15 19:48:38,744 iteration 2075 : loss : 0.038419, loss_ce: 0.012813
2022-01-15 19:48:39,809 iteration 2076 : loss : 0.047471, loss_ce: 0.014979
2022-01-15 19:48:40,823 iteration 2077 : loss : 0.046164, loss_ce: 0.016375
2022-01-15 19:48:41,765 iteration 2078 : loss : 0.030338, loss_ce: 0.012737
2022-01-15 19:48:42,733 iteration 2079 : loss : 0.030270, loss_ce: 0.010476
2022-01-15 19:48:43,793 iteration 2080 : loss : 0.046709, loss_ce: 0.016606
2022-01-15 19:48:44,813 iteration 2081 : loss : 0.047209, loss_ce: 0.020911
2022-01-15 19:48:45,801 iteration 2082 : loss : 0.052590, loss_ce: 0.022528
2022-01-15 19:48:46,777 iteration 2083 : loss : 0.027439, loss_ce: 0.009507
2022-01-15 19:48:47,761 iteration 2084 : loss : 0.043649, loss_ce: 0.015728
2022-01-15 19:48:48,713 iteration 2085 : loss : 0.037205, loss_ce: 0.015789
2022-01-15 19:48:49,691 iteration 2086 : loss : 0.030192, loss_ce: 0.013301
2022-01-15 19:48:50,627 iteration 2087 : loss : 0.045687, loss_ce: 0.012262
2022-01-15 19:48:51,739 iteration 2088 : loss : 0.087992, loss_ce: 0.048034
2022-01-15 19:48:52,702 iteration 2089 : loss : 0.035833, loss_ce: 0.012701
2022-01-15 19:48:53,737 iteration 2090 : loss : 0.034437, loss_ce: 0.011797
2022-01-15 19:48:54,727 iteration 2091 : loss : 0.029863, loss_ce: 0.012552
 31%|████████▉                    | 123/400 [38:02<1:22:35, 17.89s/it]2022-01-15 19:48:55,767 iteration 2092 : loss : 0.036447, loss_ce: 0.013647
2022-01-15 19:48:56,862 iteration 2093 : loss : 0.037568, loss_ce: 0.015653
2022-01-15 19:48:57,885 iteration 2094 : loss : 0.036610, loss_ce: 0.016743
2022-01-15 19:48:58,906 iteration 2095 : loss : 0.036534, loss_ce: 0.015703
2022-01-15 19:48:59,955 iteration 2096 : loss : 0.051681, loss_ce: 0.018967
2022-01-15 19:49:00,901 iteration 2097 : loss : 0.035475, loss_ce: 0.016629
2022-01-15 19:49:01,967 iteration 2098 : loss : 0.041351, loss_ce: 0.015158
2022-01-15 19:49:03,016 iteration 2099 : loss : 0.062519, loss_ce: 0.022049
2022-01-15 19:49:04,116 iteration 2100 : loss : 0.041766, loss_ce: 0.016816
2022-01-15 19:49:05,119 iteration 2101 : loss : 0.062405, loss_ce: 0.017717
2022-01-15 19:49:06,080 iteration 2102 : loss : 0.036508, loss_ce: 0.014983
2022-01-15 19:49:07,185 iteration 2103 : loss : 0.043995, loss_ce: 0.016606
2022-01-15 19:49:08,221 iteration 2104 : loss : 0.032313, loss_ce: 0.012260
2022-01-15 19:49:09,179 iteration 2105 : loss : 0.043157, loss_ce: 0.013524
2022-01-15 19:49:10,258 iteration 2106 : loss : 0.047814, loss_ce: 0.012431
2022-01-15 19:49:11,256 iteration 2107 : loss : 0.038911, loss_ce: 0.014704
2022-01-15 19:49:12,269 iteration 2108 : loss : 0.039787, loss_ce: 0.016492
 31%|████████▉                    | 124/400 [38:20<1:21:48, 17.79s/it]2022-01-15 19:49:13,323 iteration 2109 : loss : 0.054040, loss_ce: 0.020269
2022-01-15 19:49:14,303 iteration 2110 : loss : 0.042087, loss_ce: 0.012490
2022-01-15 19:49:15,431 iteration 2111 : loss : 0.050036, loss_ce: 0.016458
2022-01-15 19:49:16,573 iteration 2112 : loss : 0.039555, loss_ce: 0.017959
2022-01-15 19:49:17,540 iteration 2113 : loss : 0.038777, loss_ce: 0.014290
2022-01-15 19:49:18,522 iteration 2114 : loss : 0.046837, loss_ce: 0.017131
2022-01-15 19:49:19,410 iteration 2115 : loss : 0.056633, loss_ce: 0.015795
2022-01-15 19:49:20,455 iteration 2116 : loss : 0.040821, loss_ce: 0.017713
2022-01-15 19:49:21,549 iteration 2117 : loss : 0.064897, loss_ce: 0.019133
2022-01-15 19:49:22,552 iteration 2118 : loss : 0.047496, loss_ce: 0.018801
2022-01-15 19:49:23,591 iteration 2119 : loss : 0.056708, loss_ce: 0.023799
2022-01-15 19:49:24,607 iteration 2120 : loss : 0.049048, loss_ce: 0.017022
2022-01-15 19:49:25,718 iteration 2121 : loss : 0.038242, loss_ce: 0.015424
2022-01-15 19:49:26,675 iteration 2122 : loss : 0.043180, loss_ce: 0.017388
2022-01-15 19:49:27,652 iteration 2123 : loss : 0.047635, loss_ce: 0.024118
2022-01-15 19:49:28,709 iteration 2124 : loss : 0.049427, loss_ce: 0.018954
2022-01-15 19:49:28,709 Training Data Eval:
2022-01-15 19:49:33,550   Average segmentation loss on training set: 0.0272
2022-01-15 19:49:33,550 Validation Data Eval:
2022-01-15 19:49:35,181   Average segmentation loss on validation set: 0.0777
2022-01-15 19:49:36,216 iteration 2125 : loss : 0.027737, loss_ce: 0.008882
 31%|█████████                    | 125/400 [38:44<1:30:00, 19.64s/it]2022-01-15 19:49:37,284 iteration 2126 : loss : 0.028895, loss_ce: 0.010496
2022-01-15 19:49:38,371 iteration 2127 : loss : 0.038210, loss_ce: 0.015706
2022-01-15 19:49:39,330 iteration 2128 : loss : 0.031744, loss_ce: 0.015700
2022-01-15 19:49:40,357 iteration 2129 : loss : 0.029411, loss_ce: 0.012004
2022-01-15 19:49:41,310 iteration 2130 : loss : 0.043116, loss_ce: 0.012181
2022-01-15 19:49:42,416 iteration 2131 : loss : 0.063841, loss_ce: 0.027818
2022-01-15 19:49:43,518 iteration 2132 : loss : 0.044911, loss_ce: 0.016822
2022-01-15 19:49:44,581 iteration 2133 : loss : 0.045810, loss_ce: 0.017764
2022-01-15 19:49:45,642 iteration 2134 : loss : 0.070657, loss_ce: 0.019966
2022-01-15 19:49:46,663 iteration 2135 : loss : 0.042435, loss_ce: 0.014593
2022-01-15 19:49:47,679 iteration 2136 : loss : 0.042132, loss_ce: 0.014783
2022-01-15 19:49:48,691 iteration 2137 : loss : 0.047386, loss_ce: 0.013531
2022-01-15 19:49:49,655 iteration 2138 : loss : 0.050775, loss_ce: 0.016235
2022-01-15 19:49:50,580 iteration 2139 : loss : 0.033643, loss_ce: 0.015404
2022-01-15 19:49:51,555 iteration 2140 : loss : 0.032281, loss_ce: 0.010160
2022-01-15 19:49:52,568 iteration 2141 : loss : 0.047173, loss_ce: 0.019639
2022-01-15 19:49:53,567 iteration 2142 : loss : 0.060805, loss_ce: 0.028149
 32%|█████████▏                   | 126/400 [39:01<1:26:32, 18.95s/it]2022-01-15 19:49:54,656 iteration 2143 : loss : 0.036520, loss_ce: 0.010289
2022-01-15 19:49:55,636 iteration 2144 : loss : 0.040082, loss_ce: 0.013876
2022-01-15 19:49:56,536 iteration 2145 : loss : 0.029783, loss_ce: 0.015403
2022-01-15 19:49:57,691 iteration 2146 : loss : 0.054295, loss_ce: 0.023370
2022-01-15 19:49:58,701 iteration 2147 : loss : 0.031185, loss_ce: 0.012604
2022-01-15 19:49:59,693 iteration 2148 : loss : 0.040310, loss_ce: 0.015715
2022-01-15 19:50:00,702 iteration 2149 : loss : 0.055635, loss_ce: 0.023114
2022-01-15 19:50:01,756 iteration 2150 : loss : 0.040636, loss_ce: 0.014160
2022-01-15 19:50:02,813 iteration 2151 : loss : 0.054025, loss_ce: 0.019524
2022-01-15 19:50:03,746 iteration 2152 : loss : 0.027651, loss_ce: 0.010393
2022-01-15 19:50:04,721 iteration 2153 : loss : 0.038361, loss_ce: 0.011079
2022-01-15 19:50:05,647 iteration 2154 : loss : 0.030986, loss_ce: 0.014283
2022-01-15 19:50:06,605 iteration 2155 : loss : 0.037392, loss_ce: 0.014857
2022-01-15 19:50:07,646 iteration 2156 : loss : 0.044805, loss_ce: 0.015680
2022-01-15 19:50:08,665 iteration 2157 : loss : 0.038192, loss_ce: 0.013685
2022-01-15 19:50:09,635 iteration 2158 : loss : 0.033826, loss_ce: 0.014009
2022-01-15 19:50:10,682 iteration 2159 : loss : 0.064059, loss_ce: 0.024631
 32%|█████████▏                   | 127/400 [39:18<1:23:43, 18.40s/it]2022-01-15 19:50:11,650 iteration 2160 : loss : 0.029841, loss_ce: 0.009553
2022-01-15 19:50:12,654 iteration 2161 : loss : 0.033584, loss_ce: 0.013654
2022-01-15 19:50:13,639 iteration 2162 : loss : 0.059250, loss_ce: 0.024972
2022-01-15 19:50:14,526 iteration 2163 : loss : 0.041231, loss_ce: 0.011996
2022-01-15 19:50:15,532 iteration 2164 : loss : 0.037483, loss_ce: 0.015656
2022-01-15 19:50:16,521 iteration 2165 : loss : 0.026892, loss_ce: 0.008466
2022-01-15 19:50:17,575 iteration 2166 : loss : 0.095090, loss_ce: 0.050296
2022-01-15 19:50:18,568 iteration 2167 : loss : 0.040519, loss_ce: 0.018042
2022-01-15 19:50:19,548 iteration 2168 : loss : 0.030970, loss_ce: 0.010736
2022-01-15 19:50:20,555 iteration 2169 : loss : 0.040730, loss_ce: 0.015485
2022-01-15 19:50:21,515 iteration 2170 : loss : 0.040276, loss_ce: 0.014072
2022-01-15 19:50:22,494 iteration 2171 : loss : 0.027373, loss_ce: 0.009692
2022-01-15 19:50:23,375 iteration 2172 : loss : 0.037007, loss_ce: 0.018016
2022-01-15 19:50:24,371 iteration 2173 : loss : 0.048767, loss_ce: 0.017586
2022-01-15 19:50:25,405 iteration 2174 : loss : 0.047503, loss_ce: 0.015844
2022-01-15 19:50:26,340 iteration 2175 : loss : 0.043557, loss_ce: 0.013352
2022-01-15 19:50:27,298 iteration 2176 : loss : 0.044463, loss_ce: 0.020375
 32%|█████████▎                   | 128/400 [39:35<1:20:58, 17.86s/it]2022-01-15 19:50:28,412 iteration 2177 : loss : 0.065985, loss_ce: 0.019287
2022-01-15 19:50:29,340 iteration 2178 : loss : 0.033155, loss_ce: 0.013482
2022-01-15 19:50:30,314 iteration 2179 : loss : 0.032487, loss_ce: 0.012338
2022-01-15 19:50:31,339 iteration 2180 : loss : 0.035488, loss_ce: 0.012353
2022-01-15 19:50:32,306 iteration 2181 : loss : 0.035852, loss_ce: 0.011882
2022-01-15 19:50:33,274 iteration 2182 : loss : 0.034021, loss_ce: 0.011861
2022-01-15 19:50:34,231 iteration 2183 : loss : 0.049269, loss_ce: 0.017438
2022-01-15 19:50:35,158 iteration 2184 : loss : 0.050942, loss_ce: 0.025294
2022-01-15 19:50:36,060 iteration 2185 : loss : 0.034986, loss_ce: 0.014066
2022-01-15 19:50:37,178 iteration 2186 : loss : 0.069815, loss_ce: 0.029927
2022-01-15 19:50:38,108 iteration 2187 : loss : 0.037120, loss_ce: 0.017665
2022-01-15 19:50:39,159 iteration 2188 : loss : 0.038601, loss_ce: 0.015572
2022-01-15 19:50:40,117 iteration 2189 : loss : 0.045516, loss_ce: 0.016253
2022-01-15 19:50:41,187 iteration 2190 : loss : 0.037844, loss_ce: 0.013619
2022-01-15 19:50:42,116 iteration 2191 : loss : 0.032656, loss_ce: 0.013600
2022-01-15 19:50:43,126 iteration 2192 : loss : 0.048103, loss_ce: 0.017009
2022-01-15 19:50:44,211 iteration 2193 : loss : 0.051487, loss_ce: 0.020075
 32%|█████████▎                   | 129/400 [39:52<1:19:24, 17.58s/it]2022-01-15 19:50:45,247 iteration 2194 : loss : 0.042813, loss_ce: 0.017478
2022-01-15 19:50:46,213 iteration 2195 : loss : 0.032056, loss_ce: 0.011168
2022-01-15 19:50:47,231 iteration 2196 : loss : 0.037414, loss_ce: 0.015616
2022-01-15 19:50:48,276 iteration 2197 : loss : 0.050666, loss_ce: 0.018971
2022-01-15 19:50:49,257 iteration 2198 : loss : 0.033931, loss_ce: 0.016664
2022-01-15 19:50:50,438 iteration 2199 : loss : 0.050737, loss_ce: 0.023159
2022-01-15 19:50:51,440 iteration 2200 : loss : 0.031012, loss_ce: 0.011741
2022-01-15 19:50:52,451 iteration 2201 : loss : 0.049451, loss_ce: 0.013951
2022-01-15 19:50:53,441 iteration 2202 : loss : 0.045701, loss_ce: 0.012529
2022-01-15 19:50:54,485 iteration 2203 : loss : 0.029035, loss_ce: 0.008905
2022-01-15 19:50:55,541 iteration 2204 : loss : 0.037394, loss_ce: 0.012752
2022-01-15 19:50:56,440 iteration 2205 : loss : 0.037221, loss_ce: 0.015076
2022-01-15 19:50:57,383 iteration 2206 : loss : 0.032107, loss_ce: 0.015227
2022-01-15 19:50:58,397 iteration 2207 : loss : 0.053052, loss_ce: 0.023511
2022-01-15 19:50:59,386 iteration 2208 : loss : 0.037321, loss_ce: 0.015883
2022-01-15 19:51:00,455 iteration 2209 : loss : 0.040145, loss_ce: 0.018608
2022-01-15 19:51:00,455 Training Data Eval:
2022-01-15 19:51:05,188   Average segmentation loss on training set: 0.0356
2022-01-15 19:51:05,188 Validation Data Eval:
2022-01-15 19:51:06,794   Average segmentation loss on validation set: 0.0724
2022-01-15 19:51:07,680 Found new lowest validation loss at iteration 2209! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_1HEAD_NEW_best_val_loss_seed100.pth
2022-01-15 19:51:08,680 iteration 2210 : loss : 0.044866, loss_ce: 0.017948
 32%|█████████▍                   | 130/400 [40:16<1:28:24, 19.65s/it]2022-01-15 19:51:09,707 iteration 2211 : loss : 0.038287, loss_ce: 0.018748
2022-01-15 19:51:10,591 iteration 2212 : loss : 0.029942, loss_ce: 0.009943
2022-01-15 19:51:11,512 iteration 2213 : loss : 0.029530, loss_ce: 0.010808
2022-01-15 19:51:12,514 iteration 2214 : loss : 0.030136, loss_ce: 0.014188
2022-01-15 19:51:13,486 iteration 2215 : loss : 0.031169, loss_ce: 0.011492
2022-01-15 19:51:14,436 iteration 2216 : loss : 0.040894, loss_ce: 0.017942
2022-01-15 19:51:15,353 iteration 2217 : loss : 0.040536, loss_ce: 0.018679
2022-01-15 19:51:16,366 iteration 2218 : loss : 0.033924, loss_ce: 0.013282
2022-01-15 19:51:17,341 iteration 2219 : loss : 0.033737, loss_ce: 0.013935
2022-01-15 19:51:18,345 iteration 2220 : loss : 0.033783, loss_ce: 0.016381
2022-01-15 19:51:19,403 iteration 2221 : loss : 0.039929, loss_ce: 0.017706
2022-01-15 19:51:20,343 iteration 2222 : loss : 0.056522, loss_ce: 0.017852
2022-01-15 19:51:21,451 iteration 2223 : loss : 0.052022, loss_ce: 0.017374
2022-01-15 19:51:22,401 iteration 2224 : loss : 0.067800, loss_ce: 0.016242
2022-01-15 19:51:23,376 iteration 2225 : loss : 0.028012, loss_ce: 0.010751
2022-01-15 19:51:24,506 iteration 2226 : loss : 0.038004, loss_ce: 0.015837
2022-01-15 19:51:25,545 iteration 2227 : loss : 0.052675, loss_ce: 0.017749
 33%|█████████▍                   | 131/400 [40:33<1:24:20, 18.81s/it]2022-01-15 19:51:26,643 iteration 2228 : loss : 0.046777, loss_ce: 0.016165
2022-01-15 19:51:27,654 iteration 2229 : loss : 0.051674, loss_ce: 0.020359
2022-01-15 19:51:28,614 iteration 2230 : loss : 0.060149, loss_ce: 0.021561
2022-01-15 19:51:29,553 iteration 2231 : loss : 0.026231, loss_ce: 0.011395
2022-01-15 19:51:30,500 iteration 2232 : loss : 0.031402, loss_ce: 0.011896
2022-01-15 19:51:31,453 iteration 2233 : loss : 0.041142, loss_ce: 0.016546
2022-01-15 19:51:32,472 iteration 2234 : loss : 0.040051, loss_ce: 0.013584
2022-01-15 19:51:33,398 iteration 2235 : loss : 0.047791, loss_ce: 0.018888
2022-01-15 19:51:34,347 iteration 2236 : loss : 0.033640, loss_ce: 0.014306
2022-01-15 19:51:35,334 iteration 2237 : loss : 0.038125, loss_ce: 0.016710
2022-01-15 19:51:36,291 iteration 2238 : loss : 0.045841, loss_ce: 0.015120
2022-01-15 19:51:37,303 iteration 2239 : loss : 0.043558, loss_ce: 0.015197
2022-01-15 19:51:38,215 iteration 2240 : loss : 0.031716, loss_ce: 0.012362
2022-01-15 19:51:39,244 iteration 2241 : loss : 0.045068, loss_ce: 0.018872
2022-01-15 19:51:40,168 iteration 2242 : loss : 0.039385, loss_ce: 0.016893
2022-01-15 19:51:41,087 iteration 2243 : loss : 0.047625, loss_ce: 0.012067
2022-01-15 19:51:42,052 iteration 2244 : loss : 0.029410, loss_ce: 0.011698
 33%|█████████▌                   | 132/400 [40:49<1:20:55, 18.12s/it]2022-01-15 19:51:43,059 iteration 2245 : loss : 0.028569, loss_ce: 0.010848
2022-01-15 19:51:44,066 iteration 2246 : loss : 0.031446, loss_ce: 0.011730
2022-01-15 19:51:45,046 iteration 2247 : loss : 0.046060, loss_ce: 0.018478
2022-01-15 19:51:45,923 iteration 2248 : loss : 0.026070, loss_ce: 0.010942
2022-01-15 19:51:46,977 iteration 2249 : loss : 0.037305, loss_ce: 0.015627
2022-01-15 19:51:48,103 iteration 2250 : loss : 0.043017, loss_ce: 0.017057
2022-01-15 19:51:49,022 iteration 2251 : loss : 0.030450, loss_ce: 0.013503
2022-01-15 19:51:50,060 iteration 2252 : loss : 0.032042, loss_ce: 0.011230
2022-01-15 19:51:51,022 iteration 2253 : loss : 0.045002, loss_ce: 0.013588
2022-01-15 19:51:52,092 iteration 2254 : loss : 0.057326, loss_ce: 0.021928
2022-01-15 19:51:53,151 iteration 2255 : loss : 0.030324, loss_ce: 0.013683
2022-01-15 19:51:54,256 iteration 2256 : loss : 0.038753, loss_ce: 0.014341
2022-01-15 19:51:55,236 iteration 2257 : loss : 0.042520, loss_ce: 0.014695
2022-01-15 19:51:56,229 iteration 2258 : loss : 0.053082, loss_ce: 0.021601
2022-01-15 19:51:57,272 iteration 2259 : loss : 0.040569, loss_ce: 0.013222
2022-01-15 19:51:58,279 iteration 2260 : loss : 0.042028, loss_ce: 0.015987
2022-01-15 19:51:59,225 iteration 2261 : loss : 0.048016, loss_ce: 0.013931
 33%|█████████▋                   | 133/400 [41:07<1:19:22, 17.84s/it]2022-01-15 19:52:00,452 iteration 2262 : loss : 0.044697, loss_ce: 0.017600
2022-01-15 19:52:01,454 iteration 2263 : loss : 0.030164, loss_ce: 0.011235
2022-01-15 19:52:02,473 iteration 2264 : loss : 0.039551, loss_ce: 0.011136
2022-01-15 19:52:03,489 iteration 2265 : loss : 0.031888, loss_ce: 0.013477
2022-01-15 19:52:04,463 iteration 2266 : loss : 0.029447, loss_ce: 0.011008
2022-01-15 19:52:05,452 iteration 2267 : loss : 0.032035, loss_ce: 0.010193
2022-01-15 19:52:06,354 iteration 2268 : loss : 0.038270, loss_ce: 0.015375
2022-01-15 19:52:07,361 iteration 2269 : loss : 0.040392, loss_ce: 0.015946
2022-01-15 19:52:08,305 iteration 2270 : loss : 0.035549, loss_ce: 0.014043
2022-01-15 19:52:09,259 iteration 2271 : loss : 0.056414, loss_ce: 0.032693
2022-01-15 19:52:10,188 iteration 2272 : loss : 0.035323, loss_ce: 0.008922
2022-01-15 19:52:11,223 iteration 2273 : loss : 0.036032, loss_ce: 0.011114
2022-01-15 19:52:12,143 iteration 2274 : loss : 0.032937, loss_ce: 0.010555
2022-01-15 19:52:13,109 iteration 2275 : loss : 0.039764, loss_ce: 0.018225
2022-01-15 19:52:14,100 iteration 2276 : loss : 0.065803, loss_ce: 0.022571
2022-01-15 19:52:15,057 iteration 2277 : loss : 0.033576, loss_ce: 0.014075
2022-01-15 19:52:16,037 iteration 2278 : loss : 0.029671, loss_ce: 0.012859
 34%|█████████▋                   | 134/400 [41:23<1:17:43, 17.53s/it]2022-01-15 19:52:17,185 iteration 2279 : loss : 0.049340, loss_ce: 0.024941
2022-01-15 19:52:18,201 iteration 2280 : loss : 0.038129, loss_ce: 0.018185
2022-01-15 19:52:19,102 iteration 2281 : loss : 0.034769, loss_ce: 0.013219
2022-01-15 19:52:20,199 iteration 2282 : loss : 0.051347, loss_ce: 0.017387
2022-01-15 19:52:21,139 iteration 2283 : loss : 0.040579, loss_ce: 0.013910
2022-01-15 19:52:22,221 iteration 2284 : loss : 0.058017, loss_ce: 0.019440
2022-01-15 19:52:23,165 iteration 2285 : loss : 0.036672, loss_ce: 0.013929
2022-01-15 19:52:24,137 iteration 2286 : loss : 0.025847, loss_ce: 0.009268
2022-01-15 19:52:25,179 iteration 2287 : loss : 0.039042, loss_ce: 0.011217
2022-01-15 19:52:26,097 iteration 2288 : loss : 0.038131, loss_ce: 0.014462
2022-01-15 19:52:27,131 iteration 2289 : loss : 0.047150, loss_ce: 0.016971
2022-01-15 19:52:28,159 iteration 2290 : loss : 0.038447, loss_ce: 0.013498
2022-01-15 19:52:29,164 iteration 2291 : loss : 0.034932, loss_ce: 0.012187
2022-01-15 19:52:30,248 iteration 2292 : loss : 0.038628, loss_ce: 0.013283
2022-01-15 19:52:31,190 iteration 2293 : loss : 0.046909, loss_ce: 0.020501
2022-01-15 19:52:32,182 iteration 2294 : loss : 0.035350, loss_ce: 0.014748
2022-01-15 19:52:32,182 Training Data Eval:
2022-01-15 19:52:37,110   Average segmentation loss on training set: 0.0249
2022-01-15 19:52:37,110 Validation Data Eval:
2022-01-15 19:52:38,776   Average segmentation loss on validation set: 0.0791
2022-01-15 19:52:39,795 iteration 2295 : loss : 0.039977, loss_ce: 0.013990
 34%|█████████▊                   | 135/400 [41:47<1:25:39, 19.40s/it]2022-01-15 19:52:40,858 iteration 2296 : loss : 0.037232, loss_ce: 0.017083
2022-01-15 19:52:41,868 iteration 2297 : loss : 0.034144, loss_ce: 0.011196
2022-01-15 19:52:43,003 iteration 2298 : loss : 0.047366, loss_ce: 0.017517
2022-01-15 19:52:43,980 iteration 2299 : loss : 0.039184, loss_ce: 0.010773
2022-01-15 19:52:45,053 iteration 2300 : loss : 0.036638, loss_ce: 0.013744
2022-01-15 19:52:46,020 iteration 2301 : loss : 0.036783, loss_ce: 0.016611
2022-01-15 19:52:46,989 iteration 2302 : loss : 0.041718, loss_ce: 0.019555
2022-01-15 19:52:47,937 iteration 2303 : loss : 0.040472, loss_ce: 0.011799
2022-01-15 19:52:48,843 iteration 2304 : loss : 0.049675, loss_ce: 0.017580
2022-01-15 19:52:49,885 iteration 2305 : loss : 0.032166, loss_ce: 0.011998
2022-01-15 19:52:50,843 iteration 2306 : loss : 0.032986, loss_ce: 0.011681
2022-01-15 19:52:51,780 iteration 2307 : loss : 0.031685, loss_ce: 0.010341
2022-01-15 19:52:52,756 iteration 2308 : loss : 0.033889, loss_ce: 0.015148
2022-01-15 19:52:53,784 iteration 2309 : loss : 0.036345, loss_ce: 0.014962
2022-01-15 19:52:54,812 iteration 2310 : loss : 0.045773, loss_ce: 0.019207
2022-01-15 19:52:55,906 iteration 2311 : loss : 0.028921, loss_ce: 0.009903
2022-01-15 19:52:56,913 iteration 2312 : loss : 0.034502, loss_ce: 0.015281
 34%|█████████▊                   | 136/400 [42:04<1:22:20, 18.71s/it]2022-01-15 19:52:57,963 iteration 2313 : loss : 0.032854, loss_ce: 0.013839
2022-01-15 19:52:58,904 iteration 2314 : loss : 0.034627, loss_ce: 0.013335
2022-01-15 19:52:59,911 iteration 2315 : loss : 0.031361, loss_ce: 0.010889
2022-01-15 19:53:00,950 iteration 2316 : loss : 0.039823, loss_ce: 0.019762
2022-01-15 19:53:01,863 iteration 2317 : loss : 0.046293, loss_ce: 0.018452
2022-01-15 19:53:02,928 iteration 2318 : loss : 0.027297, loss_ce: 0.011878
2022-01-15 19:53:04,010 iteration 2319 : loss : 0.062084, loss_ce: 0.019458
2022-01-15 19:53:04,948 iteration 2320 : loss : 0.037700, loss_ce: 0.018489
2022-01-15 19:53:05,931 iteration 2321 : loss : 0.048647, loss_ce: 0.014285
2022-01-15 19:53:06,932 iteration 2322 : loss : 0.029419, loss_ce: 0.012244
2022-01-15 19:53:08,002 iteration 2323 : loss : 0.046549, loss_ce: 0.014629
2022-01-15 19:53:09,016 iteration 2324 : loss : 0.036781, loss_ce: 0.010019
2022-01-15 19:53:10,009 iteration 2325 : loss : 0.040960, loss_ce: 0.021611
2022-01-15 19:53:11,045 iteration 2326 : loss : 0.041492, loss_ce: 0.024747
2022-01-15 19:53:12,013 iteration 2327 : loss : 0.037922, loss_ce: 0.012588
2022-01-15 19:53:13,100 iteration 2328 : loss : 0.039491, loss_ce: 0.014941
2022-01-15 19:53:14,072 iteration 2329 : loss : 0.056951, loss_ce: 0.017363
 34%|█████████▉                   | 137/400 [42:22<1:19:58, 18.25s/it]2022-01-15 19:53:15,094 iteration 2330 : loss : 0.031166, loss_ce: 0.012362
2022-01-15 19:53:16,019 iteration 2331 : loss : 0.035193, loss_ce: 0.009077
2022-01-15 19:53:17,086 iteration 2332 : loss : 0.040436, loss_ce: 0.017238
2022-01-15 19:53:17,998 iteration 2333 : loss : 0.035388, loss_ce: 0.018633
2022-01-15 19:53:18,971 iteration 2334 : loss : 0.035347, loss_ce: 0.007243
2022-01-15 19:53:20,075 iteration 2335 : loss : 0.040765, loss_ce: 0.019539
2022-01-15 19:53:21,024 iteration 2336 : loss : 0.053538, loss_ce: 0.027511
2022-01-15 19:53:22,007 iteration 2337 : loss : 0.045704, loss_ce: 0.015065
2022-01-15 19:53:23,036 iteration 2338 : loss : 0.051374, loss_ce: 0.019712
2022-01-15 19:53:24,025 iteration 2339 : loss : 0.060390, loss_ce: 0.019561
2022-01-15 19:53:25,044 iteration 2340 : loss : 0.041371, loss_ce: 0.017489
2022-01-15 19:53:26,026 iteration 2341 : loss : 0.054247, loss_ce: 0.022175
2022-01-15 19:53:27,044 iteration 2342 : loss : 0.023841, loss_ce: 0.007824
2022-01-15 19:53:28,035 iteration 2343 : loss : 0.029960, loss_ce: 0.011143
2022-01-15 19:53:28,937 iteration 2344 : loss : 0.029076, loss_ce: 0.010451
2022-01-15 19:53:29,900 iteration 2345 : loss : 0.033830, loss_ce: 0.013635
2022-01-15 19:53:30,830 iteration 2346 : loss : 0.039245, loss_ce: 0.015052
 34%|██████████                   | 138/400 [42:38<1:17:43, 17.80s/it]2022-01-15 19:53:31,951 iteration 2347 : loss : 0.048200, loss_ce: 0.019423
2022-01-15 19:53:32,926 iteration 2348 : loss : 0.033681, loss_ce: 0.012840
2022-01-15 19:53:33,937 iteration 2349 : loss : 0.044370, loss_ce: 0.025076
2022-01-15 19:53:34,845 iteration 2350 : loss : 0.036555, loss_ce: 0.017968
2022-01-15 19:53:35,856 iteration 2351 : loss : 0.044178, loss_ce: 0.011898
2022-01-15 19:53:36,943 iteration 2352 : loss : 0.034918, loss_ce: 0.015466
2022-01-15 19:53:37,839 iteration 2353 : loss : 0.026632, loss_ce: 0.011630
2022-01-15 19:53:38,837 iteration 2354 : loss : 0.032652, loss_ce: 0.009561
2022-01-15 19:53:39,770 iteration 2355 : loss : 0.030336, loss_ce: 0.013479
2022-01-15 19:53:40,862 iteration 2356 : loss : 0.061023, loss_ce: 0.020652
2022-01-15 19:53:41,923 iteration 2357 : loss : 0.043283, loss_ce: 0.017513
2022-01-15 19:53:43,003 iteration 2358 : loss : 0.046989, loss_ce: 0.017672
2022-01-15 19:53:44,045 iteration 2359 : loss : 0.051866, loss_ce: 0.011570
2022-01-15 19:53:44,925 iteration 2360 : loss : 0.053153, loss_ce: 0.011777
2022-01-15 19:53:45,843 iteration 2361 : loss : 0.031538, loss_ce: 0.011095
2022-01-15 19:53:46,829 iteration 2362 : loss : 0.037729, loss_ce: 0.015782
2022-01-15 19:53:47,807 iteration 2363 : loss : 0.031337, loss_ce: 0.010695
 35%|██████████                   | 139/400 [42:55<1:16:21, 17.56s/it]2022-01-15 19:53:48,845 iteration 2364 : loss : 0.065505, loss_ce: 0.027651
2022-01-15 19:53:49,755 iteration 2365 : loss : 0.035521, loss_ce: 0.013257
2022-01-15 19:53:50,757 iteration 2366 : loss : 0.032794, loss_ce: 0.015225
2022-01-15 19:53:51,705 iteration 2367 : loss : 0.049992, loss_ce: 0.013078
2022-01-15 19:53:52,782 iteration 2368 : loss : 0.034069, loss_ce: 0.009278
2022-01-15 19:53:53,746 iteration 2369 : loss : 0.044156, loss_ce: 0.014763
2022-01-15 19:53:54,685 iteration 2370 : loss : 0.024798, loss_ce: 0.007890
2022-01-15 19:53:55,681 iteration 2371 : loss : 0.042172, loss_ce: 0.016701
2022-01-15 19:53:56,602 iteration 2372 : loss : 0.028942, loss_ce: 0.014147
2022-01-15 19:53:57,606 iteration 2373 : loss : 0.025089, loss_ce: 0.009415
2022-01-15 19:53:58,649 iteration 2374 : loss : 0.041512, loss_ce: 0.016790
2022-01-15 19:53:59,576 iteration 2375 : loss : 0.037272, loss_ce: 0.012894
2022-01-15 19:54:00,620 iteration 2376 : loss : 0.043160, loss_ce: 0.017811
2022-01-15 19:54:01,598 iteration 2377 : loss : 0.029456, loss_ce: 0.008105
2022-01-15 19:54:02,699 iteration 2378 : loss : 0.050304, loss_ce: 0.024947
2022-01-15 19:54:03,711 iteration 2379 : loss : 0.044486, loss_ce: 0.015023
2022-01-15 19:54:03,712 Training Data Eval:
2022-01-15 19:54:08,442   Average segmentation loss on training set: 0.0255
2022-01-15 19:54:08,442 Validation Data Eval:
2022-01-15 19:54:10,043   Average segmentation loss on validation set: 0.0721
2022-01-15 19:54:10,951 Found new lowest validation loss at iteration 2379! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_1HEAD_NEW_best_val_loss_seed100.pth
2022-01-15 19:54:12,059 iteration 2380 : loss : 0.027756, loss_ce: 0.009889
 35%|██████████▏                  | 140/400 [43:19<1:24:45, 19.56s/it]2022-01-15 19:54:13,024 iteration 2381 : loss : 0.037700, loss_ce: 0.011897
2022-01-15 19:54:14,049 iteration 2382 : loss : 0.049993, loss_ce: 0.022322
2022-01-15 19:54:15,074 iteration 2383 : loss : 0.035436, loss_ce: 0.013289
2022-01-15 19:54:16,050 iteration 2384 : loss : 0.039643, loss_ce: 0.011678
2022-01-15 19:54:17,053 iteration 2385 : loss : 0.041037, loss_ce: 0.020034
2022-01-15 19:54:18,125 iteration 2386 : loss : 0.038801, loss_ce: 0.013143
2022-01-15 19:54:19,067 iteration 2387 : loss : 0.037054, loss_ce: 0.012376
2022-01-15 19:54:20,070 iteration 2388 : loss : 0.031697, loss_ce: 0.012730
2022-01-15 19:54:20,998 iteration 2389 : loss : 0.039492, loss_ce: 0.014840
2022-01-15 19:54:21,994 iteration 2390 : loss : 0.026507, loss_ce: 0.010857
2022-01-15 19:54:22,928 iteration 2391 : loss : 0.034470, loss_ce: 0.011896
2022-01-15 19:54:23,842 iteration 2392 : loss : 0.032350, loss_ce: 0.012781
2022-01-15 19:54:24,764 iteration 2393 : loss : 0.034320, loss_ce: 0.014115
2022-01-15 19:54:25,758 iteration 2394 : loss : 0.073984, loss_ce: 0.016508
2022-01-15 19:54:26,884 iteration 2395 : loss : 0.036481, loss_ce: 0.011030
2022-01-15 19:54:27,940 iteration 2396 : loss : 0.047633, loss_ce: 0.023445
2022-01-15 19:54:28,922 iteration 2397 : loss : 0.041336, loss_ce: 0.013428
 35%|██████████▏                  | 141/400 [43:36<1:20:57, 18.75s/it]2022-01-15 19:54:30,083 iteration 2398 : loss : 0.037668, loss_ce: 0.018835
2022-01-15 19:54:30,985 iteration 2399 : loss : 0.030794, loss_ce: 0.011398
2022-01-15 19:54:31,942 iteration 2400 : loss : 0.031474, loss_ce: 0.008155
2022-01-15 19:54:32,928 iteration 2401 : loss : 0.036633, loss_ce: 0.013297
2022-01-15 19:54:33,883 iteration 2402 : loss : 0.031462, loss_ce: 0.012340
2022-01-15 19:54:34,872 iteration 2403 : loss : 0.028050, loss_ce: 0.010629
2022-01-15 19:54:35,824 iteration 2404 : loss : 0.037429, loss_ce: 0.018415
2022-01-15 19:54:36,804 iteration 2405 : loss : 0.032909, loss_ce: 0.012455
2022-01-15 19:54:37,853 iteration 2406 : loss : 0.051456, loss_ce: 0.027147
2022-01-15 19:54:38,776 iteration 2407 : loss : 0.030161, loss_ce: 0.010814
2022-01-15 19:54:39,753 iteration 2408 : loss : 0.034944, loss_ce: 0.013970
2022-01-15 19:54:40,739 iteration 2409 : loss : 0.040623, loss_ce: 0.015334
2022-01-15 19:54:41,763 iteration 2410 : loss : 0.069511, loss_ce: 0.017731
2022-01-15 19:54:42,679 iteration 2411 : loss : 0.030727, loss_ce: 0.010031
2022-01-15 19:54:43,716 iteration 2412 : loss : 0.051546, loss_ce: 0.019600
2022-01-15 19:54:44,790 iteration 2413 : loss : 0.045868, loss_ce: 0.022975
2022-01-15 19:54:45,819 iteration 2414 : loss : 0.042817, loss_ce: 0.017312
 36%|██████████▎                  | 142/400 [43:53<1:18:13, 18.19s/it]2022-01-15 19:54:46,871 iteration 2415 : loss : 0.038141, loss_ce: 0.011118
2022-01-15 19:54:47,841 iteration 2416 : loss : 0.036233, loss_ce: 0.017832
2022-01-15 19:54:48,836 iteration 2417 : loss : 0.029966, loss_ce: 0.009282
2022-01-15 19:54:49,850 iteration 2418 : loss : 0.045921, loss_ce: 0.013948
2022-01-15 19:54:50,832 iteration 2419 : loss : 0.067209, loss_ce: 0.032879
2022-01-15 19:54:51,755 iteration 2420 : loss : 0.034412, loss_ce: 0.012631
2022-01-15 19:54:52,866 iteration 2421 : loss : 0.031586, loss_ce: 0.008588
2022-01-15 19:54:53,890 iteration 2422 : loss : 0.037831, loss_ce: 0.011760
2022-01-15 19:54:54,892 iteration 2423 : loss : 0.037460, loss_ce: 0.015873
2022-01-15 19:54:55,816 iteration 2424 : loss : 0.051866, loss_ce: 0.017744
2022-01-15 19:54:56,883 iteration 2425 : loss : 0.038044, loss_ce: 0.019239
2022-01-15 19:54:57,853 iteration 2426 : loss : 0.034136, loss_ce: 0.012113
2022-01-15 19:54:58,951 iteration 2427 : loss : 0.073524, loss_ce: 0.020721
2022-01-15 19:55:00,020 iteration 2428 : loss : 0.052673, loss_ce: 0.018577
2022-01-15 19:55:01,099 iteration 2429 : loss : 0.039603, loss_ce: 0.016510
2022-01-15 19:55:02,096 iteration 2430 : loss : 0.038348, loss_ce: 0.015597
2022-01-15 19:55:03,036 iteration 2431 : loss : 0.025381, loss_ce: 0.011854
 36%|██████████▎                  | 143/400 [44:10<1:16:41, 17.91s/it]2022-01-15 19:55:04,141 iteration 2432 : loss : 0.030894, loss_ce: 0.013235
2022-01-15 19:55:05,150 iteration 2433 : loss : 0.058465, loss_ce: 0.022781
2022-01-15 19:55:06,146 iteration 2434 : loss : 0.027050, loss_ce: 0.007011
2022-01-15 19:55:07,269 iteration 2435 : loss : 0.041483, loss_ce: 0.021895
2022-01-15 19:55:08,167 iteration 2436 : loss : 0.034158, loss_ce: 0.013030
2022-01-15 19:55:09,103 iteration 2437 : loss : 0.031451, loss_ce: 0.011664
2022-01-15 19:55:10,273 iteration 2438 : loss : 0.044930, loss_ce: 0.017265
2022-01-15 19:55:11,318 iteration 2439 : loss : 0.047117, loss_ce: 0.018087
2022-01-15 19:55:12,311 iteration 2440 : loss : 0.040196, loss_ce: 0.013510
2022-01-15 19:55:13,289 iteration 2441 : loss : 0.047882, loss_ce: 0.017133
2022-01-15 19:55:14,252 iteration 2442 : loss : 0.038765, loss_ce: 0.013023
2022-01-15 19:55:15,198 iteration 2443 : loss : 0.028260, loss_ce: 0.011853
2022-01-15 19:55:16,254 iteration 2444 : loss : 0.036286, loss_ce: 0.013485
2022-01-15 19:55:17,157 iteration 2445 : loss : 0.047704, loss_ce: 0.010136
2022-01-15 19:55:18,269 iteration 2446 : loss : 0.031977, loss_ce: 0.011475
2022-01-15 19:55:19,353 iteration 2447 : loss : 0.041693, loss_ce: 0.019332
2022-01-15 19:55:20,363 iteration 2448 : loss : 0.049369, loss_ce: 0.018984
 36%|██████████▍                  | 144/400 [44:28<1:15:38, 17.73s/it]2022-01-15 19:55:21,401 iteration 2449 : loss : 0.039883, loss_ce: 0.016572
2022-01-15 19:55:22,474 iteration 2450 : loss : 0.059010, loss_ce: 0.017681
2022-01-15 19:55:23,544 iteration 2451 : loss : 0.050838, loss_ce: 0.022982
2022-01-15 19:55:24,469 iteration 2452 : loss : 0.024545, loss_ce: 0.010933
2022-01-15 19:55:25,467 iteration 2453 : loss : 0.048121, loss_ce: 0.015803
2022-01-15 19:55:26,519 iteration 2454 : loss : 0.035145, loss_ce: 0.015370
2022-01-15 19:55:27,562 iteration 2455 : loss : 0.037621, loss_ce: 0.018674
2022-01-15 19:55:28,724 iteration 2456 : loss : 0.063005, loss_ce: 0.033738
2022-01-15 19:55:29,731 iteration 2457 : loss : 0.036609, loss_ce: 0.012619
2022-01-15 19:55:30,816 iteration 2458 : loss : 0.028945, loss_ce: 0.009493
2022-01-15 19:55:31,772 iteration 2459 : loss : 0.055795, loss_ce: 0.021119
2022-01-15 19:55:32,770 iteration 2460 : loss : 0.039722, loss_ce: 0.010458
2022-01-15 19:55:33,795 iteration 2461 : loss : 0.057288, loss_ce: 0.024101
2022-01-15 19:55:34,781 iteration 2462 : loss : 0.027859, loss_ce: 0.011667
2022-01-15 19:55:35,818 iteration 2463 : loss : 0.026973, loss_ce: 0.009287
2022-01-15 19:55:36,924 iteration 2464 : loss : 0.035048, loss_ce: 0.014697
2022-01-15 19:55:36,924 Training Data Eval:
2022-01-15 19:55:41,824   Average segmentation loss on training set: 0.0259
2022-01-15 19:55:41,824 Validation Data Eval:
2022-01-15 19:55:43,489   Average segmentation loss on validation set: 0.1175
2022-01-15 19:55:44,488 iteration 2465 : loss : 0.034849, loss_ce: 0.012732
 36%|██████████▌                  | 145/400 [44:52<1:23:29, 19.65s/it]2022-01-15 19:55:45,544 iteration 2466 : loss : 0.030403, loss_ce: 0.012523
2022-01-15 19:55:46,607 iteration 2467 : loss : 0.062896, loss_ce: 0.037776
2022-01-15 19:55:47,571 iteration 2468 : loss : 0.033613, loss_ce: 0.015138
2022-01-15 19:55:48,500 iteration 2469 : loss : 0.020013, loss_ce: 0.009975
2022-01-15 19:55:49,605 iteration 2470 : loss : 0.048228, loss_ce: 0.018296
2022-01-15 19:55:50,663 iteration 2471 : loss : 0.038695, loss_ce: 0.015029
2022-01-15 19:55:51,768 iteration 2472 : loss : 0.039220, loss_ce: 0.015016
2022-01-15 19:55:52,691 iteration 2473 : loss : 0.036281, loss_ce: 0.013836
2022-01-15 19:55:53,724 iteration 2474 : loss : 0.057876, loss_ce: 0.023144
2022-01-15 19:55:54,653 iteration 2475 : loss : 0.023620, loss_ce: 0.010141
2022-01-15 19:55:55,736 iteration 2476 : loss : 0.045742, loss_ce: 0.012445
2022-01-15 19:55:56,725 iteration 2477 : loss : 0.038941, loss_ce: 0.015066
2022-01-15 19:55:57,715 iteration 2478 : loss : 0.033545, loss_ce: 0.008713
2022-01-15 19:55:58,842 iteration 2479 : loss : 0.040092, loss_ce: 0.010555
2022-01-15 19:55:59,913 iteration 2480 : loss : 0.062599, loss_ce: 0.023133
2022-01-15 19:56:00,884 iteration 2481 : loss : 0.030472, loss_ce: 0.012473
2022-01-15 19:56:01,893 iteration 2482 : loss : 0.045897, loss_ce: 0.016982
 36%|██████████▌                  | 146/400 [45:09<1:20:20, 18.98s/it]2022-01-15 19:56:02,978 iteration 2483 : loss : 0.030583, loss_ce: 0.011471
2022-01-15 19:56:04,055 iteration 2484 : loss : 0.038356, loss_ce: 0.013214
2022-01-15 19:56:05,164 iteration 2485 : loss : 0.041482, loss_ce: 0.015819
2022-01-15 19:56:06,126 iteration 2486 : loss : 0.031440, loss_ce: 0.013804
2022-01-15 19:56:07,118 iteration 2487 : loss : 0.037775, loss_ce: 0.012346
2022-01-15 19:56:08,193 iteration 2488 : loss : 0.029591, loss_ce: 0.009920
2022-01-15 19:56:09,274 iteration 2489 : loss : 0.033414, loss_ce: 0.013437
2022-01-15 19:56:10,256 iteration 2490 : loss : 0.034554, loss_ce: 0.014129
2022-01-15 19:56:11,283 iteration 2491 : loss : 0.039769, loss_ce: 0.015456
2022-01-15 19:56:12,251 iteration 2492 : loss : 0.036966, loss_ce: 0.012731
2022-01-15 19:56:13,228 iteration 2493 : loss : 0.037432, loss_ce: 0.010764
2022-01-15 19:56:14,170 iteration 2494 : loss : 0.033974, loss_ce: 0.014716
2022-01-15 19:56:15,154 iteration 2495 : loss : 0.042882, loss_ce: 0.012445
2022-01-15 19:56:16,233 iteration 2496 : loss : 0.031672, loss_ce: 0.009883
2022-01-15 19:56:17,209 iteration 2497 : loss : 0.041324, loss_ce: 0.016492
2022-01-15 19:56:18,112 iteration 2498 : loss : 0.044149, loss_ce: 0.019283
2022-01-15 19:56:19,165 iteration 2499 : loss : 0.034979, loss_ce: 0.016257
 37%|██████████▋                  | 147/400 [45:27<1:17:50, 18.46s/it]2022-01-15 19:56:20,297 iteration 2500 : loss : 0.036235, loss_ce: 0.012408
2022-01-15 19:56:21,234 iteration 2501 : loss : 0.027761, loss_ce: 0.009559
2022-01-15 19:56:22,214 iteration 2502 : loss : 0.039409, loss_ce: 0.013438
2022-01-15 19:56:23,219 iteration 2503 : loss : 0.034583, loss_ce: 0.016697
2022-01-15 19:56:24,238 iteration 2504 : loss : 0.040903, loss_ce: 0.014119
2022-01-15 19:56:25,161 iteration 2505 : loss : 0.030686, loss_ce: 0.014191
2022-01-15 19:56:26,153 iteration 2506 : loss : 0.056043, loss_ce: 0.014711
2022-01-15 19:56:27,179 iteration 2507 : loss : 0.026323, loss_ce: 0.009657
2022-01-15 19:56:28,144 iteration 2508 : loss : 0.027702, loss_ce: 0.013164
2022-01-15 19:56:29,185 iteration 2509 : loss : 0.041830, loss_ce: 0.017312
2022-01-15 19:56:30,138 iteration 2510 : loss : 0.041280, loss_ce: 0.015833
2022-01-15 19:56:31,060 iteration 2511 : loss : 0.035264, loss_ce: 0.019377
2022-01-15 19:56:32,110 iteration 2512 : loss : 0.031450, loss_ce: 0.009908
2022-01-15 19:56:33,061 iteration 2513 : loss : 0.040156, loss_ce: 0.020222
2022-01-15 19:56:34,079 iteration 2514 : loss : 0.033979, loss_ce: 0.011357
2022-01-15 19:56:35,024 iteration 2515 : loss : 0.032037, loss_ce: 0.015904
2022-01-15 19:56:36,180 iteration 2516 : loss : 0.047995, loss_ce: 0.021551
 37%|██████████▋                  | 148/400 [45:44<1:15:45, 18.04s/it]2022-01-15 19:56:37,287 iteration 2517 : loss : 0.053595, loss_ce: 0.025917
2022-01-15 19:56:38,309 iteration 2518 : loss : 0.032408, loss_ce: 0.009231
2022-01-15 19:56:39,217 iteration 2519 : loss : 0.027446, loss_ce: 0.010810
2022-01-15 19:56:40,248 iteration 2520 : loss : 0.031267, loss_ce: 0.015368
2022-01-15 19:56:41,258 iteration 2521 : loss : 0.043202, loss_ce: 0.019513
2022-01-15 19:56:42,281 iteration 2522 : loss : 0.035666, loss_ce: 0.013281
2022-01-15 19:56:43,285 iteration 2523 : loss : 0.040429, loss_ce: 0.012335
2022-01-15 19:56:44,331 iteration 2524 : loss : 0.035252, loss_ce: 0.014855
2022-01-15 19:56:45,290 iteration 2525 : loss : 0.035001, loss_ce: 0.011454
2022-01-15 19:56:46,216 iteration 2526 : loss : 0.031915, loss_ce: 0.011840
2022-01-15 19:56:47,230 iteration 2527 : loss : 0.072843, loss_ce: 0.044958
2022-01-15 19:56:48,210 iteration 2528 : loss : 0.038115, loss_ce: 0.019093
2022-01-15 19:56:49,227 iteration 2529 : loss : 0.040204, loss_ce: 0.016264
2022-01-15 19:56:50,131 iteration 2530 : loss : 0.026403, loss_ce: 0.009584
2022-01-15 19:56:51,143 iteration 2531 : loss : 0.046466, loss_ce: 0.017311
2022-01-15 19:56:52,229 iteration 2532 : loss : 0.055934, loss_ce: 0.028454
2022-01-15 19:56:53,157 iteration 2533 : loss : 0.039187, loss_ce: 0.010042
 37%|██████████▊                  | 149/400 [46:01<1:14:05, 17.71s/it]2022-01-15 19:56:54,214 iteration 2534 : loss : 0.025141, loss_ce: 0.009462
2022-01-15 19:56:55,096 iteration 2535 : loss : 0.036180, loss_ce: 0.015190
2022-01-15 19:56:56,056 iteration 2536 : loss : 0.021808, loss_ce: 0.010145
2022-01-15 19:56:57,159 iteration 2537 : loss : 0.039462, loss_ce: 0.018654
2022-01-15 19:56:58,029 iteration 2538 : loss : 0.032693, loss_ce: 0.012293
2022-01-15 19:56:58,949 iteration 2539 : loss : 0.030869, loss_ce: 0.012527
2022-01-15 19:56:59,941 iteration 2540 : loss : 0.032953, loss_ce: 0.014011
2022-01-15 19:57:01,017 iteration 2541 : loss : 0.040122, loss_ce: 0.015654
2022-01-15 19:57:02,004 iteration 2542 : loss : 0.040695, loss_ce: 0.013990
2022-01-15 19:57:03,090 iteration 2543 : loss : 0.035239, loss_ce: 0.011307
2022-01-15 19:57:04,164 iteration 2544 : loss : 0.045392, loss_ce: 0.018644
2022-01-15 19:57:05,102 iteration 2545 : loss : 0.029039, loss_ce: 0.012841
2022-01-15 19:57:06,293 iteration 2546 : loss : 0.043518, loss_ce: 0.015813
2022-01-15 19:57:07,337 iteration 2547 : loss : 0.041386, loss_ce: 0.013322
2022-01-15 19:57:08,413 iteration 2548 : loss : 0.047209, loss_ce: 0.019543
2022-01-15 19:57:09,395 iteration 2549 : loss : 0.040751, loss_ce: 0.015701
2022-01-15 19:57:09,395 Training Data Eval:
2022-01-15 19:57:14,256   Average segmentation loss on training set: 0.0229
2022-01-15 19:57:14,256 Validation Data Eval:
2022-01-15 19:57:15,902   Average segmentation loss on validation set: 0.0881
2022-01-15 19:57:16,924 iteration 2550 : loss : 0.030334, loss_ce: 0.007168
 38%|██████████▉                  | 150/400 [46:24<1:21:22, 19.53s/it]2022-01-15 19:57:18,000 iteration 2551 : loss : 0.037751, loss_ce: 0.012010
2022-01-15 19:57:19,022 iteration 2552 : loss : 0.026809, loss_ce: 0.011113
2022-01-15 19:57:20,037 iteration 2553 : loss : 0.030194, loss_ce: 0.011294
2022-01-15 19:57:21,028 iteration 2554 : loss : 0.038483, loss_ce: 0.014156
2022-01-15 19:57:22,008 iteration 2555 : loss : 0.036599, loss_ce: 0.014182
2022-01-15 19:57:23,020 iteration 2556 : loss : 0.030061, loss_ce: 0.012572
2022-01-15 19:57:24,019 iteration 2557 : loss : 0.031082, loss_ce: 0.012064
2022-01-15 19:57:24,997 iteration 2558 : loss : 0.026766, loss_ce: 0.008687
2022-01-15 19:57:25,940 iteration 2559 : loss : 0.034619, loss_ce: 0.016822
2022-01-15 19:57:27,050 iteration 2560 : loss : 0.032857, loss_ce: 0.010709
2022-01-15 19:57:28,045 iteration 2561 : loss : 0.040071, loss_ce: 0.015729
2022-01-15 19:57:29,068 iteration 2562 : loss : 0.027743, loss_ce: 0.010384
2022-01-15 19:57:29,994 iteration 2563 : loss : 0.036830, loss_ce: 0.014754
2022-01-15 19:57:30,948 iteration 2564 : loss : 0.031769, loss_ce: 0.013338
2022-01-15 19:57:31,896 iteration 2565 : loss : 0.026143, loss_ce: 0.009774
2022-01-15 19:57:32,817 iteration 2566 : loss : 0.028021, loss_ce: 0.009960
2022-01-15 19:57:33,800 iteration 2567 : loss : 0.050006, loss_ce: 0.011180
 38%|██████████▉                  | 151/400 [46:41<1:17:45, 18.74s/it]2022-01-15 19:57:34,845 iteration 2568 : loss : 0.024933, loss_ce: 0.009837
2022-01-15 19:57:35,822 iteration 2569 : loss : 0.023841, loss_ce: 0.009165
2022-01-15 19:57:36,901 iteration 2570 : loss : 0.035930, loss_ce: 0.012929
2022-01-15 19:57:37,874 iteration 2571 : loss : 0.029392, loss_ce: 0.008965
2022-01-15 19:57:38,785 iteration 2572 : loss : 0.027198, loss_ce: 0.009193
2022-01-15 19:57:39,750 iteration 2573 : loss : 0.029944, loss_ce: 0.011602
2022-01-15 19:57:40,695 iteration 2574 : loss : 0.031998, loss_ce: 0.012578
2022-01-15 19:57:41,614 iteration 2575 : loss : 0.026550, loss_ce: 0.008768
2022-01-15 19:57:42,541 iteration 2576 : loss : 0.027673, loss_ce: 0.007577
2022-01-15 19:57:43,575 iteration 2577 : loss : 0.041481, loss_ce: 0.022464
2022-01-15 19:57:44,537 iteration 2578 : loss : 0.035138, loss_ce: 0.011766
2022-01-15 19:57:45,541 iteration 2579 : loss : 0.032928, loss_ce: 0.011007
2022-01-15 19:57:46,470 iteration 2580 : loss : 0.031285, loss_ce: 0.009982
2022-01-15 19:57:47,476 iteration 2581 : loss : 0.029708, loss_ce: 0.012730
2022-01-15 19:57:48,526 iteration 2582 : loss : 0.025294, loss_ce: 0.011672
2022-01-15 19:57:49,479 iteration 2583 : loss : 0.028357, loss_ce: 0.012095
2022-01-15 19:57:50,451 iteration 2584 : loss : 0.025063, loss_ce: 0.007800
 38%|███████████                  | 152/400 [46:58<1:14:51, 18.11s/it]2022-01-15 19:57:51,508 iteration 2585 : loss : 0.030767, loss_ce: 0.010233
2022-01-15 19:57:52,692 iteration 2586 : loss : 0.049676, loss_ce: 0.015439
2022-01-15 19:57:53,756 iteration 2587 : loss : 0.040783, loss_ce: 0.012002
2022-01-15 19:57:54,742 iteration 2588 : loss : 0.040789, loss_ce: 0.014309
2022-01-15 19:57:55,644 iteration 2589 : loss : 0.042636, loss_ce: 0.011618
2022-01-15 19:57:56,677 iteration 2590 : loss : 0.040200, loss_ce: 0.013619
2022-01-15 19:57:57,663 iteration 2591 : loss : 0.024950, loss_ce: 0.009980
2022-01-15 19:57:58,602 iteration 2592 : loss : 0.025265, loss_ce: 0.012758
2022-01-15 19:57:59,490 iteration 2593 : loss : 0.032454, loss_ce: 0.015661
2022-01-15 19:58:00,486 iteration 2594 : loss : 0.060705, loss_ce: 0.026498
2022-01-15 19:58:01,406 iteration 2595 : loss : 0.027838, loss_ce: 0.009021
2022-01-15 19:58:02,356 iteration 2596 : loss : 0.032782, loss_ce: 0.010448
2022-01-15 19:58:03,364 iteration 2597 : loss : 0.035661, loss_ce: 0.013451
2022-01-15 19:58:04,353 iteration 2598 : loss : 0.036084, loss_ce: 0.014485
2022-01-15 19:58:05,347 iteration 2599 : loss : 0.028869, loss_ce: 0.011225
2022-01-15 19:58:06,292 iteration 2600 : loss : 0.037280, loss_ce: 0.015476
2022-01-15 19:58:07,217 iteration 2601 : loss : 0.030617, loss_ce: 0.012633
 38%|███████████                  | 153/400 [47:15<1:12:53, 17.71s/it]2022-01-15 19:58:08,245 iteration 2602 : loss : 0.044197, loss_ce: 0.015167
2022-01-15 19:58:09,240 iteration 2603 : loss : 0.047934, loss_ce: 0.011341
2022-01-15 19:58:10,214 iteration 2604 : loss : 0.030575, loss_ce: 0.011545
2022-01-15 19:58:11,186 iteration 2605 : loss : 0.034684, loss_ce: 0.014820
2022-01-15 19:58:12,176 iteration 2606 : loss : 0.025078, loss_ce: 0.009688
2022-01-15 19:58:13,177 iteration 2607 : loss : 0.027156, loss_ce: 0.012127
2022-01-15 19:58:14,097 iteration 2608 : loss : 0.040686, loss_ce: 0.015687
2022-01-15 19:58:15,113 iteration 2609 : loss : 0.041899, loss_ce: 0.017991
2022-01-15 19:58:16,116 iteration 2610 : loss : 0.031687, loss_ce: 0.010557
2022-01-15 19:58:17,160 iteration 2611 : loss : 0.038084, loss_ce: 0.016887
2022-01-15 19:58:18,183 iteration 2612 : loss : 0.072118, loss_ce: 0.024577
2022-01-15 19:58:19,238 iteration 2613 : loss : 0.034879, loss_ce: 0.011548
2022-01-15 19:58:20,267 iteration 2614 : loss : 0.031273, loss_ce: 0.012646
2022-01-15 19:58:21,268 iteration 2615 : loss : 0.036980, loss_ce: 0.016277
2022-01-15 19:58:22,317 iteration 2616 : loss : 0.029436, loss_ce: 0.012265
2022-01-15 19:58:23,314 iteration 2617 : loss : 0.033362, loss_ce: 0.011866
2022-01-15 19:58:24,349 iteration 2618 : loss : 0.038934, loss_ce: 0.012698
 38%|███████████▏                 | 154/400 [47:32<1:11:53, 17.53s/it]2022-01-15 19:58:25,536 iteration 2619 : loss : 0.035442, loss_ce: 0.015153
2022-01-15 19:58:26,545 iteration 2620 : loss : 0.040351, loss_ce: 0.013795
2022-01-15 19:58:27,417 iteration 2621 : loss : 0.030844, loss_ce: 0.012562
2022-01-15 19:58:28,430 iteration 2622 : loss : 0.042893, loss_ce: 0.014513
2022-01-15 19:58:29,384 iteration 2623 : loss : 0.026111, loss_ce: 0.010450
2022-01-15 19:58:30,430 iteration 2624 : loss : 0.046780, loss_ce: 0.015570
2022-01-15 19:58:31,479 iteration 2625 : loss : 0.031421, loss_ce: 0.013402
2022-01-15 19:58:32,503 iteration 2626 : loss : 0.038681, loss_ce: 0.016839
2022-01-15 19:58:33,430 iteration 2627 : loss : 0.026975, loss_ce: 0.013919
2022-01-15 19:58:34,386 iteration 2628 : loss : 0.027579, loss_ce: 0.010166
2022-01-15 19:58:35,316 iteration 2629 : loss : 0.038659, loss_ce: 0.010177
2022-01-15 19:58:36,371 iteration 2630 : loss : 0.097013, loss_ce: 0.014426
2022-01-15 19:58:37,312 iteration 2631 : loss : 0.045413, loss_ce: 0.022493
2022-01-15 19:58:38,273 iteration 2632 : loss : 0.032794, loss_ce: 0.011520
2022-01-15 19:58:39,301 iteration 2633 : loss : 0.020817, loss_ce: 0.007224
2022-01-15 19:58:40,285 iteration 2634 : loss : 0.036334, loss_ce: 0.012876
2022-01-15 19:58:40,286 Training Data Eval:
2022-01-15 19:58:45,085   Average segmentation loss on training set: 0.0324
2022-01-15 19:58:45,085 Validation Data Eval:
2022-01-15 19:58:46,693   Average segmentation loss on validation set: 0.1611
2022-01-15 19:58:47,653 iteration 2635 : loss : 0.044262, loss_ce: 0.019336
 39%|███████████▏                 | 155/400 [47:55<1:18:39, 19.26s/it]2022-01-15 19:58:48,650 iteration 2636 : loss : 0.026677, loss_ce: 0.009649
2022-01-15 19:58:49,617 iteration 2637 : loss : 0.034406, loss_ce: 0.016296
2022-01-15 19:58:50,695 iteration 2638 : loss : 0.049405, loss_ce: 0.018857
2022-01-15 19:58:51,661 iteration 2639 : loss : 0.037210, loss_ce: 0.015816
2022-01-15 19:58:52,660 iteration 2640 : loss : 0.056862, loss_ce: 0.024185
2022-01-15 19:58:53,634 iteration 2641 : loss : 0.042973, loss_ce: 0.017998
2022-01-15 19:58:54,647 iteration 2642 : loss : 0.049972, loss_ce: 0.018739
2022-01-15 19:58:55,620 iteration 2643 : loss : 0.038383, loss_ce: 0.015852
2022-01-15 19:58:56,631 iteration 2644 : loss : 0.049020, loss_ce: 0.020984
2022-01-15 19:58:57,555 iteration 2645 : loss : 0.035202, loss_ce: 0.014252
2022-01-15 19:58:58,506 iteration 2646 : loss : 0.034927, loss_ce: 0.009987
2022-01-15 19:58:59,581 iteration 2647 : loss : 0.070811, loss_ce: 0.034651
2022-01-15 19:59:00,544 iteration 2648 : loss : 0.042574, loss_ce: 0.015492
2022-01-15 19:59:01,538 iteration 2649 : loss : 0.042800, loss_ce: 0.013867
2022-01-15 19:59:02,646 iteration 2650 : loss : 0.052695, loss_ce: 0.018848
2022-01-15 19:59:03,608 iteration 2651 : loss : 0.041842, loss_ce: 0.016822
2022-01-15 19:59:04,682 iteration 2652 : loss : 0.033139, loss_ce: 0.012397
 39%|███████████▎                 | 156/400 [48:12<1:15:36, 18.59s/it]2022-01-15 19:59:05,799 iteration 2653 : loss : 0.067215, loss_ce: 0.026483
2022-01-15 19:59:06,712 iteration 2654 : loss : 0.034214, loss_ce: 0.014961
2022-01-15 19:59:07,672 iteration 2655 : loss : 0.038997, loss_ce: 0.015894
2022-01-15 19:59:08,634 iteration 2656 : loss : 0.037695, loss_ce: 0.019450
2022-01-15 19:59:09,651 iteration 2657 : loss : 0.045735, loss_ce: 0.018857
2022-01-15 19:59:10,708 iteration 2658 : loss : 0.079816, loss_ce: 0.025123
2022-01-15 19:59:11,723 iteration 2659 : loss : 0.033432, loss_ce: 0.012317
2022-01-15 19:59:12,805 iteration 2660 : loss : 0.041358, loss_ce: 0.017571
2022-01-15 19:59:13,704 iteration 2661 : loss : 0.038775, loss_ce: 0.012919
2022-01-15 19:59:14,780 iteration 2662 : loss : 0.026811, loss_ce: 0.009138
2022-01-15 19:59:15,839 iteration 2663 : loss : 0.043452, loss_ce: 0.017087
2022-01-15 19:59:16,778 iteration 2664 : loss : 0.053368, loss_ce: 0.018167
2022-01-15 19:59:17,750 iteration 2665 : loss : 0.020577, loss_ce: 0.008375
2022-01-15 19:59:18,849 iteration 2666 : loss : 0.034176, loss_ce: 0.011738
2022-01-15 19:59:19,815 iteration 2667 : loss : 0.040202, loss_ce: 0.015774
2022-01-15 19:59:20,909 iteration 2668 : loss : 0.056325, loss_ce: 0.026485
2022-01-15 19:59:21,892 iteration 2669 : loss : 0.037803, loss_ce: 0.009702
 39%|███████████▍                 | 157/400 [48:29<1:13:38, 18.18s/it]2022-01-15 19:59:22,877 iteration 2670 : loss : 0.030401, loss_ce: 0.011937
2022-01-15 19:59:23,811 iteration 2671 : loss : 0.043270, loss_ce: 0.020787
2022-01-15 19:59:24,802 iteration 2672 : loss : 0.044085, loss_ce: 0.016717
2022-01-15 19:59:25,789 iteration 2673 : loss : 0.030315, loss_ce: 0.009451
2022-01-15 19:59:26,840 iteration 2674 : loss : 0.034522, loss_ce: 0.009901
2022-01-15 19:59:27,908 iteration 2675 : loss : 0.030471, loss_ce: 0.010909
2022-01-15 19:59:28,894 iteration 2676 : loss : 0.034651, loss_ce: 0.011181
2022-01-15 19:59:29,890 iteration 2677 : loss : 0.036568, loss_ce: 0.012792
2022-01-15 19:59:30,829 iteration 2678 : loss : 0.025586, loss_ce: 0.011845
2022-01-15 19:59:31,858 iteration 2679 : loss : 0.037383, loss_ce: 0.015094
2022-01-15 19:59:32,984 iteration 2680 : loss : 0.045103, loss_ce: 0.021219
2022-01-15 19:59:34,005 iteration 2681 : loss : 0.037938, loss_ce: 0.012695
2022-01-15 19:59:35,056 iteration 2682 : loss : 0.062158, loss_ce: 0.038472
2022-01-15 19:59:36,034 iteration 2683 : loss : 0.048275, loss_ce: 0.025767
2022-01-15 19:59:37,061 iteration 2684 : loss : 0.033171, loss_ce: 0.014782
2022-01-15 19:59:38,119 iteration 2685 : loss : 0.043333, loss_ce: 0.019046
2022-01-15 19:59:39,172 iteration 2686 : loss : 0.078668, loss_ce: 0.016583
 40%|███████████▍                 | 158/400 [48:47<1:12:14, 17.91s/it]2022-01-15 19:59:40,209 iteration 2687 : loss : 0.046007, loss_ce: 0.019447
2022-01-15 19:59:41,186 iteration 2688 : loss : 0.039410, loss_ce: 0.016385
2022-01-15 19:59:42,137 iteration 2689 : loss : 0.042079, loss_ce: 0.016376
2022-01-15 19:59:43,189 iteration 2690 : loss : 0.074901, loss_ce: 0.019960
2022-01-15 19:59:44,136 iteration 2691 : loss : 0.038481, loss_ce: 0.016586
2022-01-15 19:59:45,097 iteration 2692 : loss : 0.049426, loss_ce: 0.020937
2022-01-15 19:59:46,040 iteration 2693 : loss : 0.030052, loss_ce: 0.012500
2022-01-15 19:59:47,055 iteration 2694 : loss : 0.033725, loss_ce: 0.014308
2022-01-15 19:59:48,040 iteration 2695 : loss : 0.039771, loss_ce: 0.020787
2022-01-15 19:59:49,027 iteration 2696 : loss : 0.039994, loss_ce: 0.018403
2022-01-15 19:59:49,969 iteration 2697 : loss : 0.035004, loss_ce: 0.015377
2022-01-15 19:59:50,913 iteration 2698 : loss : 0.055937, loss_ce: 0.021126
2022-01-15 19:59:51,885 iteration 2699 : loss : 0.029944, loss_ce: 0.013444
2022-01-15 19:59:52,823 iteration 2700 : loss : 0.044664, loss_ce: 0.016106
2022-01-15 19:59:53,927 iteration 2701 : loss : 0.064500, loss_ce: 0.021063
2022-01-15 19:59:54,945 iteration 2702 : loss : 0.032677, loss_ce: 0.016152
2022-01-15 19:59:55,996 iteration 2703 : loss : 0.050423, loss_ce: 0.020358
 40%|███████████▌                 | 159/400 [49:03<1:10:37, 17.58s/it]2022-01-15 19:59:57,146 iteration 2704 : loss : 0.047318, loss_ce: 0.015331
2022-01-15 19:59:58,074 iteration 2705 : loss : 0.033795, loss_ce: 0.015133
2022-01-15 19:59:59,105 iteration 2706 : loss : 0.046409, loss_ce: 0.017294
2022-01-15 20:00:00,076 iteration 2707 : loss : 0.036119, loss_ce: 0.019088
2022-01-15 20:00:01,106 iteration 2708 : loss : 0.033236, loss_ce: 0.013185
2022-01-15 20:00:02,091 iteration 2709 : loss : 0.037724, loss_ce: 0.014669
2022-01-15 20:00:03,013 iteration 2710 : loss : 0.029675, loss_ce: 0.011738
2022-01-15 20:00:04,042 iteration 2711 : loss : 0.028400, loss_ce: 0.011254
2022-01-15 20:00:05,073 iteration 2712 : loss : 0.039545, loss_ce: 0.012162
2022-01-15 20:00:06,026 iteration 2713 : loss : 0.029256, loss_ce: 0.016124
2022-01-15 20:00:07,094 iteration 2714 : loss : 0.031240, loss_ce: 0.011662
2022-01-15 20:00:08,141 iteration 2715 : loss : 0.049112, loss_ce: 0.017417
2022-01-15 20:00:09,194 iteration 2716 : loss : 0.029687, loss_ce: 0.010166
2022-01-15 20:00:10,193 iteration 2717 : loss : 0.037498, loss_ce: 0.015531
2022-01-15 20:00:11,260 iteration 2718 : loss : 0.072031, loss_ce: 0.028360
2022-01-15 20:00:12,253 iteration 2719 : loss : 0.031831, loss_ce: 0.010713
2022-01-15 20:00:12,253 Training Data Eval:
2022-01-15 20:00:17,155   Average segmentation loss on training set: 0.0227
2022-01-15 20:00:17,155 Validation Data Eval:
2022-01-15 20:00:18,817   Average segmentation loss on validation set: 0.0747
2022-01-15 20:00:19,787 iteration 2720 : loss : 0.030500, loss_ce: 0.010587
 40%|███████████▌                 | 160/400 [49:27<1:17:46, 19.44s/it]2022-01-15 20:00:20,892 iteration 2721 : loss : 0.030673, loss_ce: 0.012261
2022-01-15 20:00:21,911 iteration 2722 : loss : 0.046924, loss_ce: 0.018222
2022-01-15 20:00:22,958 iteration 2723 : loss : 0.026666, loss_ce: 0.010081
2022-01-15 20:00:23,969 iteration 2724 : loss : 0.048645, loss_ce: 0.016244
2022-01-15 20:00:24,947 iteration 2725 : loss : 0.037753, loss_ce: 0.011092
2022-01-15 20:00:26,103 iteration 2726 : loss : 0.052295, loss_ce: 0.020958
2022-01-15 20:00:27,163 iteration 2727 : loss : 0.045122, loss_ce: 0.018862
2022-01-15 20:00:28,170 iteration 2728 : loss : 0.028319, loss_ce: 0.010988
2022-01-15 20:00:29,168 iteration 2729 : loss : 0.043808, loss_ce: 0.019080
2022-01-15 20:00:30,104 iteration 2730 : loss : 0.022714, loss_ce: 0.008334
2022-01-15 20:00:31,133 iteration 2731 : loss : 0.036694, loss_ce: 0.012322
2022-01-15 20:00:32,219 iteration 2732 : loss : 0.036985, loss_ce: 0.015697
2022-01-15 20:00:33,244 iteration 2733 : loss : 0.049038, loss_ce: 0.019722
2022-01-15 20:00:34,249 iteration 2734 : loss : 0.032767, loss_ce: 0.010488
2022-01-15 20:00:35,348 iteration 2735 : loss : 0.041016, loss_ce: 0.012956
2022-01-15 20:00:36,336 iteration 2736 : loss : 0.024161, loss_ce: 0.010551
2022-01-15 20:00:37,368 iteration 2737 : loss : 0.052732, loss_ce: 0.021075
 40%|███████████▋                 | 161/400 [49:45<1:15:13, 18.89s/it]2022-01-15 20:00:38,354 iteration 2738 : loss : 0.021173, loss_ce: 0.008555
2022-01-15 20:00:39,415 iteration 2739 : loss : 0.038493, loss_ce: 0.015601
2022-01-15 20:00:40,489 iteration 2740 : loss : 0.054181, loss_ce: 0.027417
2022-01-15 20:00:41,445 iteration 2741 : loss : 0.037856, loss_ce: 0.014511
2022-01-15 20:00:42,362 iteration 2742 : loss : 0.040707, loss_ce: 0.013692
2022-01-15 20:00:43,381 iteration 2743 : loss : 0.051949, loss_ce: 0.016029
2022-01-15 20:00:44,533 iteration 2744 : loss : 0.072629, loss_ce: 0.025505
2022-01-15 20:00:45,514 iteration 2745 : loss : 0.028774, loss_ce: 0.009633
2022-01-15 20:00:46,478 iteration 2746 : loss : 0.029063, loss_ce: 0.009844
2022-01-15 20:00:47,579 iteration 2747 : loss : 0.046106, loss_ce: 0.018596
2022-01-15 20:00:48,528 iteration 2748 : loss : 0.025750, loss_ce: 0.010107
2022-01-15 20:00:49,526 iteration 2749 : loss : 0.052125, loss_ce: 0.022823
2022-01-15 20:00:50,500 iteration 2750 : loss : 0.047931, loss_ce: 0.015415
2022-01-15 20:00:51,467 iteration 2751 : loss : 0.029765, loss_ce: 0.008152
2022-01-15 20:00:52,410 iteration 2752 : loss : 0.029377, loss_ce: 0.011949
2022-01-15 20:00:53,382 iteration 2753 : loss : 0.035997, loss_ce: 0.014696
2022-01-15 20:00:54,390 iteration 2754 : loss : 0.046944, loss_ce: 0.016573
 40%|███████████▋                 | 162/400 [50:02<1:12:41, 18.33s/it]2022-01-15 20:00:55,435 iteration 2755 : loss : 0.029092, loss_ce: 0.011289
2022-01-15 20:00:56,431 iteration 2756 : loss : 0.029047, loss_ce: 0.013370
2022-01-15 20:00:57,370 iteration 2757 : loss : 0.031717, loss_ce: 0.012102
2022-01-15 20:00:58,348 iteration 2758 : loss : 0.038688, loss_ce: 0.015239
2022-01-15 20:00:59,324 iteration 2759 : loss : 0.029918, loss_ce: 0.011752
2022-01-15 20:01:00,366 iteration 2760 : loss : 0.040162, loss_ce: 0.010336
2022-01-15 20:01:01,362 iteration 2761 : loss : 0.027142, loss_ce: 0.010756
2022-01-15 20:01:02,348 iteration 2762 : loss : 0.035014, loss_ce: 0.012845
2022-01-15 20:01:03,329 iteration 2763 : loss : 0.032819, loss_ce: 0.013459
2022-01-15 20:01:04,257 iteration 2764 : loss : 0.029257, loss_ce: 0.012039
2022-01-15 20:01:05,245 iteration 2765 : loss : 0.042264, loss_ce: 0.017088
2022-01-15 20:01:06,293 iteration 2766 : loss : 0.036621, loss_ce: 0.013170
2022-01-15 20:01:07,213 iteration 2767 : loss : 0.032068, loss_ce: 0.007835
2022-01-15 20:01:08,334 iteration 2768 : loss : 0.031147, loss_ce: 0.012714
2022-01-15 20:01:09,310 iteration 2769 : loss : 0.031396, loss_ce: 0.009215
2022-01-15 20:01:10,248 iteration 2770 : loss : 0.029372, loss_ce: 0.014079
2022-01-15 20:01:11,245 iteration 2771 : loss : 0.035634, loss_ce: 0.015742
 41%|███████████▊                 | 163/400 [50:19<1:10:39, 17.89s/it]2022-01-15 20:01:12,407 iteration 2772 : loss : 0.058273, loss_ce: 0.019311
2022-01-15 20:01:13,337 iteration 2773 : loss : 0.036178, loss_ce: 0.011327
2022-01-15 20:01:14,313 iteration 2774 : loss : 0.036938, loss_ce: 0.016875
2022-01-15 20:01:15,328 iteration 2775 : loss : 0.029307, loss_ce: 0.011570
2022-01-15 20:01:16,385 iteration 2776 : loss : 0.040462, loss_ce: 0.019372
2022-01-15 20:01:17,440 iteration 2777 : loss : 0.037987, loss_ce: 0.015078
2022-01-15 20:01:18,365 iteration 2778 : loss : 0.030335, loss_ce: 0.011919
2022-01-15 20:01:19,414 iteration 2779 : loss : 0.035650, loss_ce: 0.015888
2022-01-15 20:01:20,510 iteration 2780 : loss : 0.046623, loss_ce: 0.019860
2022-01-15 20:01:21,422 iteration 2781 : loss : 0.033432, loss_ce: 0.013324
2022-01-15 20:01:22,465 iteration 2782 : loss : 0.031528, loss_ce: 0.013357
2022-01-15 20:01:23,555 iteration 2783 : loss : 0.029852, loss_ce: 0.010439
2022-01-15 20:01:24,682 iteration 2784 : loss : 0.038132, loss_ce: 0.016529
2022-01-15 20:01:25,613 iteration 2785 : loss : 0.024424, loss_ce: 0.008575
2022-01-15 20:01:26,638 iteration 2786 : loss : 0.037203, loss_ce: 0.012267
2022-01-15 20:01:27,733 iteration 2787 : loss : 0.045385, loss_ce: 0.010311
2022-01-15 20:01:28,765 iteration 2788 : loss : 0.041974, loss_ce: 0.013972
 41%|███████████▉                 | 164/400 [50:36<1:09:54, 17.77s/it]2022-01-15 20:01:29,836 iteration 2789 : loss : 0.028408, loss_ce: 0.014265
2022-01-15 20:01:30,801 iteration 2790 : loss : 0.036375, loss_ce: 0.009170
2022-01-15 20:01:31,826 iteration 2791 : loss : 0.035707, loss_ce: 0.010161
2022-01-15 20:01:32,884 iteration 2792 : loss : 0.039355, loss_ce: 0.009452
2022-01-15 20:01:33,880 iteration 2793 : loss : 0.046272, loss_ce: 0.021082
2022-01-15 20:01:34,886 iteration 2794 : loss : 0.034485, loss_ce: 0.012779
2022-01-15 20:01:35,951 iteration 2795 : loss : 0.037160, loss_ce: 0.013121
2022-01-15 20:01:37,045 iteration 2796 : loss : 0.040817, loss_ce: 0.012566
2022-01-15 20:01:38,086 iteration 2797 : loss : 0.039135, loss_ce: 0.017057
2022-01-15 20:01:39,175 iteration 2798 : loss : 0.061128, loss_ce: 0.018315
2022-01-15 20:01:40,235 iteration 2799 : loss : 0.030036, loss_ce: 0.010247
2022-01-15 20:01:41,275 iteration 2800 : loss : 0.026045, loss_ce: 0.012300
2022-01-15 20:01:42,260 iteration 2801 : loss : 0.035947, loss_ce: 0.015708
2022-01-15 20:01:43,224 iteration 2802 : loss : 0.024682, loss_ce: 0.009596
2022-01-15 20:01:44,333 iteration 2803 : loss : 0.053342, loss_ce: 0.017100
2022-01-15 20:01:45,336 iteration 2804 : loss : 0.041127, loss_ce: 0.016349
2022-01-15 20:01:45,337 Training Data Eval:
2022-01-15 20:01:50,107   Average segmentation loss on training set: 0.0306
2022-01-15 20:01:50,107 Validation Data Eval:
2022-01-15 20:01:51,724   Average segmentation loss on validation set: 0.0793
2022-01-15 20:01:52,704 iteration 2805 : loss : 0.042149, loss_ce: 0.013439
 41%|███████████▉                 | 165/400 [51:00<1:16:51, 19.62s/it]2022-01-15 20:01:53,808 iteration 2806 : loss : 0.040543, loss_ce: 0.013470
2022-01-15 20:01:54,971 iteration 2807 : loss : 0.045858, loss_ce: 0.016791
2022-01-15 20:01:55,858 iteration 2808 : loss : 0.029879, loss_ce: 0.015886
2022-01-15 20:01:56,844 iteration 2809 : loss : 0.053791, loss_ce: 0.023338
2022-01-15 20:01:57,876 iteration 2810 : loss : 0.045277, loss_ce: 0.015755
2022-01-15 20:01:58,828 iteration 2811 : loss : 0.031271, loss_ce: 0.011669
2022-01-15 20:01:59,817 iteration 2812 : loss : 0.043257, loss_ce: 0.018469
2022-01-15 20:02:00,841 iteration 2813 : loss : 0.029584, loss_ce: 0.008603
2022-01-15 20:02:01,837 iteration 2814 : loss : 0.033334, loss_ce: 0.013114
2022-01-15 20:02:02,788 iteration 2815 : loss : 0.025977, loss_ce: 0.011087
2022-01-15 20:02:03,739 iteration 2816 : loss : 0.028746, loss_ce: 0.011951
2022-01-15 20:02:04,696 iteration 2817 : loss : 0.027274, loss_ce: 0.008610
2022-01-15 20:02:05,770 iteration 2818 : loss : 0.041583, loss_ce: 0.012874
2022-01-15 20:02:06,802 iteration 2819 : loss : 0.035201, loss_ce: 0.014993
2022-01-15 20:02:07,903 iteration 2820 : loss : 0.033500, loss_ce: 0.013598
2022-01-15 20:02:08,878 iteration 2821 : loss : 0.043397, loss_ce: 0.019440
2022-01-15 20:02:09,823 iteration 2822 : loss : 0.027612, loss_ce: 0.009125
 42%|████████████                 | 166/400 [51:17<1:13:35, 18.87s/it]2022-01-15 20:02:10,958 iteration 2823 : loss : 0.066649, loss_ce: 0.023590
2022-01-15 20:02:11,889 iteration 2824 : loss : 0.020993, loss_ce: 0.007849
2022-01-15 20:02:12,907 iteration 2825 : loss : 0.044438, loss_ce: 0.020525
2022-01-15 20:02:13,849 iteration 2826 : loss : 0.027331, loss_ce: 0.011085
2022-01-15 20:02:14,860 iteration 2827 : loss : 0.035838, loss_ce: 0.016990
2022-01-15 20:02:15,850 iteration 2828 : loss : 0.039822, loss_ce: 0.016729
2022-01-15 20:02:16,947 iteration 2829 : loss : 0.029950, loss_ce: 0.010828
2022-01-15 20:02:17,856 iteration 2830 : loss : 0.028364, loss_ce: 0.011078
2022-01-15 20:02:18,843 iteration 2831 : loss : 0.039219, loss_ce: 0.016352
2022-01-15 20:02:19,873 iteration 2832 : loss : 0.036852, loss_ce: 0.009589
2022-01-15 20:02:20,930 iteration 2833 : loss : 0.048417, loss_ce: 0.020461
2022-01-15 20:02:21,907 iteration 2834 : loss : 0.056664, loss_ce: 0.021920
2022-01-15 20:02:22,935 iteration 2835 : loss : 0.050971, loss_ce: 0.013776
2022-01-15 20:02:23,986 iteration 2836 : loss : 0.033943, loss_ce: 0.014058
2022-01-15 20:02:24,971 iteration 2837 : loss : 0.035081, loss_ce: 0.008638
2022-01-15 20:02:25,888 iteration 2838 : loss : 0.022412, loss_ce: 0.007038
2022-01-15 20:02:26,915 iteration 2839 : loss : 0.048476, loss_ce: 0.018850
 42%|████████████                 | 167/400 [51:34<1:11:13, 18.34s/it]2022-01-15 20:02:27,950 iteration 2840 : loss : 0.029481, loss_ce: 0.013907
2022-01-15 20:02:28,952 iteration 2841 : loss : 0.034044, loss_ce: 0.012856
2022-01-15 20:02:29,948 iteration 2842 : loss : 0.049648, loss_ce: 0.013880
2022-01-15 20:02:30,855 iteration 2843 : loss : 0.028944, loss_ce: 0.012563
2022-01-15 20:02:31,749 iteration 2844 : loss : 0.020677, loss_ce: 0.007429
2022-01-15 20:02:32,714 iteration 2845 : loss : 0.035658, loss_ce: 0.015111
2022-01-15 20:02:33,809 iteration 2846 : loss : 0.053168, loss_ce: 0.017463
2022-01-15 20:02:34,832 iteration 2847 : loss : 0.051988, loss_ce: 0.017227
2022-01-15 20:02:35,813 iteration 2848 : loss : 0.054382, loss_ce: 0.015492
2022-01-15 20:02:36,860 iteration 2849 : loss : 0.032393, loss_ce: 0.011983
2022-01-15 20:02:37,884 iteration 2850 : loss : 0.029174, loss_ce: 0.013621
2022-01-15 20:02:38,961 iteration 2851 : loss : 0.030303, loss_ce: 0.012361
2022-01-15 20:02:39,940 iteration 2852 : loss : 0.033657, loss_ce: 0.009228
2022-01-15 20:02:40,944 iteration 2853 : loss : 0.032644, loss_ce: 0.009128
2022-01-15 20:02:41,868 iteration 2854 : loss : 0.029777, loss_ce: 0.007926
2022-01-15 20:02:42,822 iteration 2855 : loss : 0.025399, loss_ce: 0.011516
2022-01-15 20:02:43,721 iteration 2856 : loss : 0.022696, loss_ce: 0.011032
 42%|████████████▏                | 168/400 [51:51<1:09:08, 17.88s/it]2022-01-15 20:02:44,784 iteration 2857 : loss : 0.026833, loss_ce: 0.012274
2022-01-15 20:02:45,903 iteration 2858 : loss : 0.040722, loss_ce: 0.012754
2022-01-15 20:02:46,941 iteration 2859 : loss : 0.030501, loss_ce: 0.010882
2022-01-15 20:02:47,977 iteration 2860 : loss : 0.027845, loss_ce: 0.010517
2022-01-15 20:02:48,988 iteration 2861 : loss : 0.033549, loss_ce: 0.008970
2022-01-15 20:02:50,030 iteration 2862 : loss : 0.049680, loss_ce: 0.013427
2022-01-15 20:02:50,986 iteration 2863 : loss : 0.035121, loss_ce: 0.012049
2022-01-15 20:02:51,990 iteration 2864 : loss : 0.032563, loss_ce: 0.011674
2022-01-15 20:02:53,001 iteration 2865 : loss : 0.027578, loss_ce: 0.011564
2022-01-15 20:02:54,003 iteration 2866 : loss : 0.025749, loss_ce: 0.007847
2022-01-15 20:02:55,111 iteration 2867 : loss : 0.042805, loss_ce: 0.015227
2022-01-15 20:02:56,156 iteration 2868 : loss : 0.048523, loss_ce: 0.020397
2022-01-15 20:02:57,212 iteration 2869 : loss : 0.040505, loss_ce: 0.015514
2022-01-15 20:02:58,320 iteration 2870 : loss : 0.033786, loss_ce: 0.011560
2022-01-15 20:02:59,266 iteration 2871 : loss : 0.059784, loss_ce: 0.036781
2022-01-15 20:03:00,250 iteration 2872 : loss : 0.037652, loss_ce: 0.016610
2022-01-15 20:03:01,260 iteration 2873 : loss : 0.032431, loss_ce: 0.013707
 42%|████████████▎                | 169/400 [52:09<1:08:27, 17.78s/it]2022-01-15 20:03:02,344 iteration 2874 : loss : 0.022195, loss_ce: 0.008524
2022-01-15 20:03:03,438 iteration 2875 : loss : 0.027862, loss_ce: 0.011224
2022-01-15 20:03:04,424 iteration 2876 : loss : 0.038997, loss_ce: 0.013146
2022-01-15 20:03:05,372 iteration 2877 : loss : 0.031909, loss_ce: 0.011558
2022-01-15 20:03:06,380 iteration 2878 : loss : 0.028298, loss_ce: 0.009154
2022-01-15 20:03:07,320 iteration 2879 : loss : 0.024897, loss_ce: 0.011095
2022-01-15 20:03:08,375 iteration 2880 : loss : 0.040992, loss_ce: 0.020397
2022-01-15 20:03:09,329 iteration 2881 : loss : 0.026905, loss_ce: 0.012056
2022-01-15 20:03:10,320 iteration 2882 : loss : 0.043700, loss_ce: 0.016171
2022-01-15 20:03:11,389 iteration 2883 : loss : 0.039615, loss_ce: 0.012951
2022-01-15 20:03:12,470 iteration 2884 : loss : 0.041193, loss_ce: 0.017907
2022-01-15 20:03:13,517 iteration 2885 : loss : 0.024652, loss_ce: 0.009133
2022-01-15 20:03:14,508 iteration 2886 : loss : 0.026851, loss_ce: 0.008978
2022-01-15 20:03:15,502 iteration 2887 : loss : 0.027834, loss_ce: 0.009051
2022-01-15 20:03:16,567 iteration 2888 : loss : 0.024513, loss_ce: 0.010495
2022-01-15 20:03:17,589 iteration 2889 : loss : 0.033795, loss_ce: 0.013302
2022-01-15 20:03:17,589 Training Data Eval:
2022-01-15 20:03:22,504   Average segmentation loss on training set: 0.0212
2022-01-15 20:03:22,504 Validation Data Eval:
2022-01-15 20:03:24,167   Average segmentation loss on validation set: 0.0845
2022-01-15 20:03:25,168 iteration 2890 : loss : 0.032553, loss_ce: 0.015653
 42%|████████████▎                | 170/400 [52:33<1:15:12, 19.62s/it]2022-01-15 20:03:26,238 iteration 2891 : loss : 0.030538, loss_ce: 0.012281
2022-01-15 20:03:27,271 iteration 2892 : loss : 0.030539, loss_ce: 0.010601
2022-01-15 20:03:28,194 iteration 2893 : loss : 0.027856, loss_ce: 0.011071
2022-01-15 20:03:29,152 iteration 2894 : loss : 0.024420, loss_ce: 0.009518
2022-01-15 20:03:30,116 iteration 2895 : loss : 0.028056, loss_ce: 0.010087
2022-01-15 20:03:31,107 iteration 2896 : loss : 0.043811, loss_ce: 0.017560
2022-01-15 20:03:32,246 iteration 2897 : loss : 0.063675, loss_ce: 0.016521
2022-01-15 20:03:33,284 iteration 2898 : loss : 0.037404, loss_ce: 0.012785
2022-01-15 20:03:34,296 iteration 2899 : loss : 0.042525, loss_ce: 0.018371
2022-01-15 20:03:35,435 iteration 2900 : loss : 0.042924, loss_ce: 0.018811
2022-01-15 20:03:36,471 iteration 2901 : loss : 0.032559, loss_ce: 0.011107
2022-01-15 20:03:37,446 iteration 2902 : loss : 0.035014, loss_ce: 0.014857
2022-01-15 20:03:38,461 iteration 2903 : loss : 0.032522, loss_ce: 0.009069
2022-01-15 20:03:39,459 iteration 2904 : loss : 0.037608, loss_ce: 0.017690
2022-01-15 20:03:40,500 iteration 2905 : loss : 0.037207, loss_ce: 0.015765
2022-01-15 20:03:41,456 iteration 2906 : loss : 0.029963, loss_ce: 0.012758
2022-01-15 20:03:42,462 iteration 2907 : loss : 0.022106, loss_ce: 0.008876
 43%|████████████▍                | 171/400 [52:50<1:12:12, 18.92s/it]2022-01-15 20:03:43,593 iteration 2908 : loss : 0.033107, loss_ce: 0.012999
2022-01-15 20:03:44,649 iteration 2909 : loss : 0.035265, loss_ce: 0.012693
2022-01-15 20:03:45,692 iteration 2910 : loss : 0.020282, loss_ce: 0.007422
2022-01-15 20:03:46,749 iteration 2911 : loss : 0.039140, loss_ce: 0.014546
2022-01-15 20:03:47,703 iteration 2912 : loss : 0.024430, loss_ce: 0.009349
2022-01-15 20:03:48,713 iteration 2913 : loss : 0.029293, loss_ce: 0.010418
2022-01-15 20:03:49,748 iteration 2914 : loss : 0.038081, loss_ce: 0.016997
2022-01-15 20:03:50,757 iteration 2915 : loss : 0.041038, loss_ce: 0.022495
2022-01-15 20:03:51,754 iteration 2916 : loss : 0.034315, loss_ce: 0.014677
2022-01-15 20:03:52,762 iteration 2917 : loss : 0.035746, loss_ce: 0.014450
2022-01-15 20:03:53,682 iteration 2918 : loss : 0.028212, loss_ce: 0.013806
2022-01-15 20:03:54,691 iteration 2919 : loss : 0.029759, loss_ce: 0.010899
2022-01-15 20:03:55,678 iteration 2920 : loss : 0.031158, loss_ce: 0.013006
2022-01-15 20:03:56,676 iteration 2921 : loss : 0.028324, loss_ce: 0.012496
2022-01-15 20:03:57,656 iteration 2922 : loss : 0.038240, loss_ce: 0.011501
2022-01-15 20:03:58,731 iteration 2923 : loss : 0.031168, loss_ce: 0.009621
2022-01-15 20:03:59,766 iteration 2924 : loss : 0.023441, loss_ce: 0.009796
 43%|████████████▍                | 172/400 [53:07<1:10:03, 18.44s/it]2022-01-15 20:04:00,836 iteration 2925 : loss : 0.027316, loss_ce: 0.011987
2022-01-15 20:04:01,757 iteration 2926 : loss : 0.025091, loss_ce: 0.008741
2022-01-15 20:04:02,765 iteration 2927 : loss : 0.023373, loss_ce: 0.008321
2022-01-15 20:04:03,800 iteration 2928 : loss : 0.023837, loss_ce: 0.008609
2022-01-15 20:04:04,759 iteration 2929 : loss : 0.029453, loss_ce: 0.007312
2022-01-15 20:04:05,719 iteration 2930 : loss : 0.023406, loss_ce: 0.010429
2022-01-15 20:04:06,727 iteration 2931 : loss : 0.059180, loss_ce: 0.013413
2022-01-15 20:04:07,820 iteration 2932 : loss : 0.031735, loss_ce: 0.013544
2022-01-15 20:04:08,862 iteration 2933 : loss : 0.049401, loss_ce: 0.022508
2022-01-15 20:04:09,934 iteration 2934 : loss : 0.030537, loss_ce: 0.014741
2022-01-15 20:04:10,903 iteration 2935 : loss : 0.027787, loss_ce: 0.008890
2022-01-15 20:04:11,897 iteration 2936 : loss : 0.026164, loss_ce: 0.011124
2022-01-15 20:04:12,920 iteration 2937 : loss : 0.025980, loss_ce: 0.012346
2022-01-15 20:04:13,954 iteration 2938 : loss : 0.041064, loss_ce: 0.015883
2022-01-15 20:04:14,852 iteration 2939 : loss : 0.037158, loss_ce: 0.009917
2022-01-15 20:04:15,824 iteration 2940 : loss : 0.030376, loss_ce: 0.012917
2022-01-15 20:04:16,793 iteration 2941 : loss : 0.033700, loss_ce: 0.013679
 43%|████████████▌                | 173/400 [53:24<1:08:08, 18.01s/it]2022-01-15 20:04:17,945 iteration 2942 : loss : 0.030902, loss_ce: 0.013616
2022-01-15 20:04:18,971 iteration 2943 : loss : 0.023897, loss_ce: 0.009604
2022-01-15 20:04:19,969 iteration 2944 : loss : 0.050009, loss_ce: 0.016260
2022-01-15 20:04:20,950 iteration 2945 : loss : 0.036370, loss_ce: 0.015516
2022-01-15 20:04:22,000 iteration 2946 : loss : 0.037066, loss_ce: 0.013762
2022-01-15 20:04:22,952 iteration 2947 : loss : 0.027774, loss_ce: 0.009993
2022-01-15 20:04:23,964 iteration 2948 : loss : 0.024446, loss_ce: 0.009136
2022-01-15 20:04:24,923 iteration 2949 : loss : 0.040830, loss_ce: 0.018064
2022-01-15 20:04:25,820 iteration 2950 : loss : 0.023121, loss_ce: 0.008779
2022-01-15 20:04:26,798 iteration 2951 : loss : 0.022768, loss_ce: 0.006793
2022-01-15 20:04:27,699 iteration 2952 : loss : 0.096636, loss_ce: 0.017335
2022-01-15 20:04:28,761 iteration 2953 : loss : 0.028937, loss_ce: 0.010362
2022-01-15 20:04:29,758 iteration 2954 : loss : 0.037320, loss_ce: 0.018929
2022-01-15 20:04:30,750 iteration 2955 : loss : 0.066813, loss_ce: 0.014490
2022-01-15 20:04:31,678 iteration 2956 : loss : 0.045178, loss_ce: 0.030149
2022-01-15 20:04:32,598 iteration 2957 : loss : 0.029435, loss_ce: 0.010928
2022-01-15 20:04:33,596 iteration 2958 : loss : 0.043494, loss_ce: 0.020911
 44%|████████████▌                | 174/400 [53:41<1:06:28, 17.65s/it]2022-01-15 20:04:34,691 iteration 2959 : loss : 0.044099, loss_ce: 0.024407
2022-01-15 20:04:35,677 iteration 2960 : loss : 0.037545, loss_ce: 0.018470
2022-01-15 20:04:36,716 iteration 2961 : loss : 0.035830, loss_ce: 0.015551
2022-01-15 20:04:37,746 iteration 2962 : loss : 0.031109, loss_ce: 0.012523
2022-01-15 20:04:38,707 iteration 2963 : loss : 0.042697, loss_ce: 0.017215
2022-01-15 20:04:39,666 iteration 2964 : loss : 0.043227, loss_ce: 0.017682
2022-01-15 20:04:40,587 iteration 2965 : loss : 0.047184, loss_ce: 0.020611
2022-01-15 20:04:41,507 iteration 2966 : loss : 0.032553, loss_ce: 0.013315
2022-01-15 20:04:42,535 iteration 2967 : loss : 0.037280, loss_ce: 0.017927
2022-01-15 20:04:43,639 iteration 2968 : loss : 0.064738, loss_ce: 0.020291
2022-01-15 20:04:44,680 iteration 2969 : loss : 0.029266, loss_ce: 0.011437
2022-01-15 20:04:45,654 iteration 2970 : loss : 0.038222, loss_ce: 0.012049
2022-01-15 20:04:46,584 iteration 2971 : loss : 0.031683, loss_ce: 0.012820
2022-01-15 20:04:47,622 iteration 2972 : loss : 0.040267, loss_ce: 0.013020
2022-01-15 20:04:48,574 iteration 2973 : loss : 0.038006, loss_ce: 0.014487
2022-01-15 20:04:49,636 iteration 2974 : loss : 0.031281, loss_ce: 0.011725
2022-01-15 20:04:49,637 Training Data Eval:
2022-01-15 20:04:54,354   Average segmentation loss on training set: 0.0247
2022-01-15 20:04:54,355 Validation Data Eval:
2022-01-15 20:04:55,958   Average segmentation loss on validation set: 0.1032
2022-01-15 20:04:56,990 iteration 2975 : loss : 0.040837, loss_ce: 0.010483
 44%|████████████▋                | 175/400 [54:04<1:12:39, 19.37s/it]2022-01-15 20:04:58,135 iteration 2976 : loss : 0.037035, loss_ce: 0.020037
2022-01-15 20:04:59,037 iteration 2977 : loss : 0.028330, loss_ce: 0.011069
2022-01-15 20:04:59,925 iteration 2978 : loss : 0.024744, loss_ce: 0.009333
2022-01-15 20:05:00,944 iteration 2979 : loss : 0.031589, loss_ce: 0.010079
2022-01-15 20:05:02,072 iteration 2980 : loss : 0.030844, loss_ce: 0.011644
2022-01-15 20:05:03,068 iteration 2981 : loss : 0.037732, loss_ce: 0.010764
2022-01-15 20:05:04,141 iteration 2982 : loss : 0.033051, loss_ce: 0.013846
2022-01-15 20:05:05,112 iteration 2983 : loss : 0.029932, loss_ce: 0.014046
2022-01-15 20:05:06,156 iteration 2984 : loss : 0.034822, loss_ce: 0.013773
2022-01-15 20:05:07,155 iteration 2985 : loss : 0.052671, loss_ce: 0.015792
2022-01-15 20:05:08,195 iteration 2986 : loss : 0.032675, loss_ce: 0.013311
2022-01-15 20:05:09,124 iteration 2987 : loss : 0.029558, loss_ce: 0.013498
2022-01-15 20:05:10,080 iteration 2988 : loss : 0.027364, loss_ce: 0.008677
2022-01-15 20:05:11,084 iteration 2989 : loss : 0.024124, loss_ce: 0.006597
2022-01-15 20:05:12,098 iteration 2990 : loss : 0.045137, loss_ce: 0.015998
2022-01-15 20:05:13,177 iteration 2991 : loss : 0.042169, loss_ce: 0.016580
2022-01-15 20:05:14,311 iteration 2992 : loss : 0.029813, loss_ce: 0.011391
 44%|████████████▊                | 176/400 [54:22<1:10:00, 18.75s/it]2022-01-15 20:05:15,298 iteration 2993 : loss : 0.026782, loss_ce: 0.007828
2022-01-15 20:05:16,268 iteration 2994 : loss : 0.029837, loss_ce: 0.012280
2022-01-15 20:05:17,353 iteration 2995 : loss : 0.031869, loss_ce: 0.013248
2022-01-15 20:05:18,347 iteration 2996 : loss : 0.034397, loss_ce: 0.012471
2022-01-15 20:05:19,332 iteration 2997 : loss : 0.023299, loss_ce: 0.008137
2022-01-15 20:05:20,307 iteration 2998 : loss : 0.022264, loss_ce: 0.006347
2022-01-15 20:05:21,347 iteration 2999 : loss : 0.045874, loss_ce: 0.016941
2022-01-15 20:05:22,340 iteration 3000 : loss : 0.048519, loss_ce: 0.015334
2022-01-15 20:05:23,392 iteration 3001 : loss : 0.023879, loss_ce: 0.009046
2022-01-15 20:05:24,316 iteration 3002 : loss : 0.036409, loss_ce: 0.016991
2022-01-15 20:05:25,385 iteration 3003 : loss : 0.051640, loss_ce: 0.020862
2022-01-15 20:05:26,317 iteration 3004 : loss : 0.023827, loss_ce: 0.009067
2022-01-15 20:05:27,366 iteration 3005 : loss : 0.052187, loss_ce: 0.018236
2022-01-15 20:05:28,424 iteration 3006 : loss : 0.030035, loss_ce: 0.010683
2022-01-15 20:05:29,419 iteration 3007 : loss : 0.029896, loss_ce: 0.009883
2022-01-15 20:05:30,562 iteration 3008 : loss : 0.033935, loss_ce: 0.014140
2022-01-15 20:05:31,563 iteration 3009 : loss : 0.026028, loss_ce: 0.014232
 44%|████████████▊                | 177/400 [54:39<1:08:01, 18.30s/it]2022-01-15 20:05:32,619 iteration 3010 : loss : 0.026600, loss_ce: 0.010104
2022-01-15 20:05:33,607 iteration 3011 : loss : 0.035999, loss_ce: 0.012286
2022-01-15 20:05:34,571 iteration 3012 : loss : 0.043999, loss_ce: 0.014754
2022-01-15 20:05:35,535 iteration 3013 : loss : 0.025807, loss_ce: 0.012979
2022-01-15 20:05:36,615 iteration 3014 : loss : 0.045277, loss_ce: 0.018176
2022-01-15 20:05:37,623 iteration 3015 : loss : 0.022834, loss_ce: 0.008825
2022-01-15 20:05:38,603 iteration 3016 : loss : 0.025504, loss_ce: 0.009334
2022-01-15 20:05:39,576 iteration 3017 : loss : 0.035810, loss_ce: 0.011077
2022-01-15 20:05:40,512 iteration 3018 : loss : 0.021037, loss_ce: 0.005845
2022-01-15 20:05:41,481 iteration 3019 : loss : 0.043639, loss_ce: 0.019083
2022-01-15 20:05:42,347 iteration 3020 : loss : 0.038630, loss_ce: 0.022470
2022-01-15 20:05:43,254 iteration 3021 : loss : 0.022506, loss_ce: 0.007566
2022-01-15 20:05:44,226 iteration 3022 : loss : 0.030234, loss_ce: 0.008415
2022-01-15 20:05:45,198 iteration 3023 : loss : 0.028128, loss_ce: 0.014040
2022-01-15 20:05:46,185 iteration 3024 : loss : 0.039353, loss_ce: 0.014744
2022-01-15 20:05:47,067 iteration 3025 : loss : 0.027322, loss_ce: 0.010957
2022-01-15 20:05:48,088 iteration 3026 : loss : 0.034341, loss_ce: 0.016889
 44%|████████████▉                | 178/400 [54:56<1:05:45, 17.77s/it]2022-01-15 20:05:49,133 iteration 3027 : loss : 0.040762, loss_ce: 0.022418
2022-01-15 20:05:50,109 iteration 3028 : loss : 0.047439, loss_ce: 0.022667
2022-01-15 20:05:51,105 iteration 3029 : loss : 0.027854, loss_ce: 0.011815
2022-01-15 20:05:52,194 iteration 3030 : loss : 0.035531, loss_ce: 0.012530
2022-01-15 20:05:53,088 iteration 3031 : loss : 0.030100, loss_ce: 0.012252
2022-01-15 20:05:54,083 iteration 3032 : loss : 0.030705, loss_ce: 0.009736
2022-01-15 20:05:55,114 iteration 3033 : loss : 0.041331, loss_ce: 0.016976
2022-01-15 20:05:56,094 iteration 3034 : loss : 0.038513, loss_ce: 0.013384
2022-01-15 20:05:57,175 iteration 3035 : loss : 0.037597, loss_ce: 0.012323
2022-01-15 20:05:58,182 iteration 3036 : loss : 0.023172, loss_ce: 0.009878
2022-01-15 20:05:59,223 iteration 3037 : loss : 0.026461, loss_ce: 0.009806
2022-01-15 20:06:00,135 iteration 3038 : loss : 0.026007, loss_ce: 0.006650
2022-01-15 20:06:01,301 iteration 3039 : loss : 0.055353, loss_ce: 0.020495
2022-01-15 20:06:02,230 iteration 3040 : loss : 0.028553, loss_ce: 0.011601
2022-01-15 20:06:03,191 iteration 3041 : loss : 0.040021, loss_ce: 0.016034
2022-01-15 20:06:04,143 iteration 3042 : loss : 0.027747, loss_ce: 0.012340
2022-01-15 20:06:05,256 iteration 3043 : loss : 0.032176, loss_ce: 0.013349
 45%|████████████▉                | 179/400 [55:13<1:04:47, 17.59s/it]2022-01-15 20:06:06,347 iteration 3044 : loss : 0.036394, loss_ce: 0.013008
2022-01-15 20:06:07,324 iteration 3045 : loss : 0.029294, loss_ce: 0.013976
2022-01-15 20:06:08,285 iteration 3046 : loss : 0.034681, loss_ce: 0.013527
2022-01-15 20:06:09,406 iteration 3047 : loss : 0.028684, loss_ce: 0.011986
2022-01-15 20:06:10,465 iteration 3048 : loss : 0.043542, loss_ce: 0.018561
2022-01-15 20:06:11,424 iteration 3049 : loss : 0.026914, loss_ce: 0.010688
2022-01-15 20:06:12,528 iteration 3050 : loss : 0.038744, loss_ce: 0.017431
2022-01-15 20:06:13,567 iteration 3051 : loss : 0.058691, loss_ce: 0.012800
2022-01-15 20:06:14,664 iteration 3052 : loss : 0.038911, loss_ce: 0.015437
2022-01-15 20:06:15,694 iteration 3053 : loss : 0.030261, loss_ce: 0.012805
2022-01-15 20:06:16,719 iteration 3054 : loss : 0.064451, loss_ce: 0.023853
2022-01-15 20:06:17,764 iteration 3055 : loss : 0.031002, loss_ce: 0.010977
2022-01-15 20:06:18,814 iteration 3056 : loss : 0.030669, loss_ce: 0.010636
2022-01-15 20:06:19,786 iteration 3057 : loss : 0.023120, loss_ce: 0.007989
2022-01-15 20:06:20,885 iteration 3058 : loss : 0.036873, loss_ce: 0.011757
2022-01-15 20:06:21,988 iteration 3059 : loss : 0.052548, loss_ce: 0.020106
2022-01-15 20:06:21,988 Training Data Eval:
2022-01-15 20:06:26,865   Average segmentation loss on training set: 0.0269
2022-01-15 20:06:26,866 Validation Data Eval:
2022-01-15 20:06:28,503   Average segmentation loss on validation set: 0.1338
2022-01-15 20:06:29,512 iteration 3060 : loss : 0.033117, loss_ce: 0.012299
 45%|█████████████                | 180/400 [55:37<1:11:50, 19.59s/it]2022-01-15 20:06:30,559 iteration 3061 : loss : 0.033839, loss_ce: 0.013243
2022-01-15 20:06:31,600 iteration 3062 : loss : 0.031156, loss_ce: 0.009146
2022-01-15 20:06:32,586 iteration 3063 : loss : 0.035845, loss_ce: 0.013284
2022-01-15 20:06:33,657 iteration 3064 : loss : 0.052091, loss_ce: 0.031449
2022-01-15 20:06:34,658 iteration 3065 : loss : 0.045975, loss_ce: 0.012559
2022-01-15 20:06:35,653 iteration 3066 : loss : 0.025071, loss_ce: 0.006134
2022-01-15 20:06:36,680 iteration 3067 : loss : 0.027121, loss_ce: 0.012012
2022-01-15 20:06:37,765 iteration 3068 : loss : 0.020921, loss_ce: 0.007017
2022-01-15 20:06:38,837 iteration 3069 : loss : 0.049326, loss_ce: 0.012047
2022-01-15 20:06:39,776 iteration 3070 : loss : 0.027786, loss_ce: 0.010013
2022-01-15 20:06:40,869 iteration 3071 : loss : 0.028369, loss_ce: 0.011106
2022-01-15 20:06:41,909 iteration 3072 : loss : 0.021859, loss_ce: 0.010548
2022-01-15 20:06:42,875 iteration 3073 : loss : 0.031444, loss_ce: 0.012049
2022-01-15 20:06:43,995 iteration 3074 : loss : 0.037619, loss_ce: 0.016786
2022-01-15 20:06:45,053 iteration 3075 : loss : 0.026109, loss_ce: 0.009170
2022-01-15 20:06:46,046 iteration 3076 : loss : 0.035912, loss_ce: 0.015728
2022-01-15 20:06:47,143 iteration 3077 : loss : 0.041541, loss_ce: 0.018463
 45%|█████████████                | 181/400 [55:55<1:09:21, 19.00s/it]2022-01-15 20:06:48,096 iteration 3078 : loss : 0.018394, loss_ce: 0.007337
2022-01-15 20:06:49,170 iteration 3079 : loss : 0.063732, loss_ce: 0.020685
2022-01-15 20:06:50,195 iteration 3080 : loss : 0.026538, loss_ce: 0.009834
2022-01-15 20:06:51,195 iteration 3081 : loss : 0.043063, loss_ce: 0.015092
2022-01-15 20:06:52,231 iteration 3082 : loss : 0.024601, loss_ce: 0.009108
2022-01-15 20:06:53,266 iteration 3083 : loss : 0.036990, loss_ce: 0.015788
2022-01-15 20:06:54,266 iteration 3084 : loss : 0.025770, loss_ce: 0.010827
2022-01-15 20:06:55,284 iteration 3085 : loss : 0.065949, loss_ce: 0.009917
2022-01-15 20:06:56,256 iteration 3086 : loss : 0.024724, loss_ce: 0.009235
2022-01-15 20:06:57,206 iteration 3087 : loss : 0.034086, loss_ce: 0.011767
2022-01-15 20:06:58,142 iteration 3088 : loss : 0.029586, loss_ce: 0.010851
2022-01-15 20:06:59,082 iteration 3089 : loss : 0.028318, loss_ce: 0.010829
2022-01-15 20:07:00,101 iteration 3090 : loss : 0.037404, loss_ce: 0.013506
2022-01-15 20:07:01,051 iteration 3091 : loss : 0.036645, loss_ce: 0.012902
2022-01-15 20:07:01,963 iteration 3092 : loss : 0.027737, loss_ce: 0.012619
2022-01-15 20:07:02,941 iteration 3093 : loss : 0.025562, loss_ce: 0.008067
2022-01-15 20:07:03,896 iteration 3094 : loss : 0.039356, loss_ce: 0.018809
 46%|█████████████▏               | 182/400 [56:11<1:06:34, 18.32s/it]2022-01-15 20:07:05,019 iteration 3095 : loss : 0.022032, loss_ce: 0.006960
2022-01-15 20:07:05,984 iteration 3096 : loss : 0.021874, loss_ce: 0.008293
2022-01-15 20:07:06,951 iteration 3097 : loss : 0.038262, loss_ce: 0.014050
2022-01-15 20:07:07,891 iteration 3098 : loss : 0.026659, loss_ce: 0.009212
2022-01-15 20:07:08,954 iteration 3099 : loss : 0.039756, loss_ce: 0.013023
2022-01-15 20:07:09,881 iteration 3100 : loss : 0.026925, loss_ce: 0.008960
2022-01-15 20:07:10,863 iteration 3101 : loss : 0.027633, loss_ce: 0.012526
2022-01-15 20:07:11,902 iteration 3102 : loss : 0.035985, loss_ce: 0.014187
2022-01-15 20:07:12,867 iteration 3103 : loss : 0.034376, loss_ce: 0.009954
2022-01-15 20:07:13,855 iteration 3104 : loss : 0.039024, loss_ce: 0.016220
2022-01-15 20:07:14,814 iteration 3105 : loss : 0.021651, loss_ce: 0.007304
2022-01-15 20:07:15,959 iteration 3106 : loss : 0.029923, loss_ce: 0.011907
2022-01-15 20:07:16,940 iteration 3107 : loss : 0.035835, loss_ce: 0.013990
2022-01-15 20:07:17,851 iteration 3108 : loss : 0.025249, loss_ce: 0.008578
2022-01-15 20:07:18,902 iteration 3109 : loss : 0.031453, loss_ce: 0.018058
2022-01-15 20:07:19,957 iteration 3110 : loss : 0.045525, loss_ce: 0.024651
2022-01-15 20:07:20,901 iteration 3111 : loss : 0.033476, loss_ce: 0.010292
 46%|█████████████▎               | 183/400 [56:28<1:04:50, 17.93s/it]2022-01-15 20:07:21,905 iteration 3112 : loss : 0.024380, loss_ce: 0.009429
2022-01-15 20:07:22,891 iteration 3113 : loss : 0.028763, loss_ce: 0.013687
2022-01-15 20:07:23,999 iteration 3114 : loss : 0.048358, loss_ce: 0.011507
2022-01-15 20:07:25,032 iteration 3115 : loss : 0.041019, loss_ce: 0.019465
2022-01-15 20:07:26,029 iteration 3116 : loss : 0.028435, loss_ce: 0.011936
2022-01-15 20:07:27,004 iteration 3117 : loss : 0.028039, loss_ce: 0.011198
2022-01-15 20:07:28,059 iteration 3118 : loss : 0.035158, loss_ce: 0.015344
2022-01-15 20:07:29,088 iteration 3119 : loss : 0.036504, loss_ce: 0.013081
2022-01-15 20:07:30,084 iteration 3120 : loss : 0.022888, loss_ce: 0.007895
2022-01-15 20:07:31,092 iteration 3121 : loss : 0.039530, loss_ce: 0.013483
2022-01-15 20:07:32,151 iteration 3122 : loss : 0.033746, loss_ce: 0.010093
2022-01-15 20:07:33,146 iteration 3123 : loss : 0.022646, loss_ce: 0.008814
2022-01-15 20:07:34,161 iteration 3124 : loss : 0.026760, loss_ce: 0.010309
2022-01-15 20:07:35,166 iteration 3125 : loss : 0.043564, loss_ce: 0.019330
2022-01-15 20:07:36,081 iteration 3126 : loss : 0.028382, loss_ce: 0.010342
2022-01-15 20:07:37,090 iteration 3127 : loss : 0.026861, loss_ce: 0.011223
2022-01-15 20:07:38,006 iteration 3128 : loss : 0.023850, loss_ce: 0.008114
 46%|█████████████▎               | 184/400 [56:45<1:03:38, 17.68s/it]2022-01-15 20:07:39,097 iteration 3129 : loss : 0.032276, loss_ce: 0.011228
2022-01-15 20:07:40,114 iteration 3130 : loss : 0.033612, loss_ce: 0.011801
2022-01-15 20:07:41,179 iteration 3131 : loss : 0.036737, loss_ce: 0.013598
2022-01-15 20:07:42,152 iteration 3132 : loss : 0.027092, loss_ce: 0.010803
2022-01-15 20:07:43,071 iteration 3133 : loss : 0.025012, loss_ce: 0.008164
2022-01-15 20:07:44,063 iteration 3134 : loss : 0.023047, loss_ce: 0.007437
2022-01-15 20:07:45,049 iteration 3135 : loss : 0.034485, loss_ce: 0.012173
2022-01-15 20:07:46,097 iteration 3136 : loss : 0.052406, loss_ce: 0.021967
2022-01-15 20:07:47,103 iteration 3137 : loss : 0.036995, loss_ce: 0.018372
2022-01-15 20:07:48,131 iteration 3138 : loss : 0.033956, loss_ce: 0.016514
2022-01-15 20:07:49,194 iteration 3139 : loss : 0.035641, loss_ce: 0.012481
2022-01-15 20:07:50,228 iteration 3140 : loss : 0.032592, loss_ce: 0.011609
2022-01-15 20:07:51,265 iteration 3141 : loss : 0.034926, loss_ce: 0.011470
2022-01-15 20:07:52,248 iteration 3142 : loss : 0.025085, loss_ce: 0.008843
2022-01-15 20:07:53,297 iteration 3143 : loss : 0.024023, loss_ce: 0.009887
2022-01-15 20:07:54,358 iteration 3144 : loss : 0.024589, loss_ce: 0.011270
2022-01-15 20:07:54,359 Training Data Eval:
2022-01-15 20:07:59,064   Average segmentation loss on training set: 0.0189
2022-01-15 20:07:59,064 Validation Data Eval:
2022-01-15 20:08:00,682   Average segmentation loss on validation set: 0.0818
2022-01-15 20:08:01,579 iteration 3145 : loss : 0.022837, loss_ce: 0.008363
 46%|█████████████▍               | 185/400 [57:09<1:09:42, 19.45s/it]2022-01-15 20:08:02,541 iteration 3146 : loss : 0.022373, loss_ce: 0.007916
2022-01-15 20:08:03,506 iteration 3147 : loss : 0.023737, loss_ce: 0.010252
2022-01-15 20:08:04,479 iteration 3148 : loss : 0.025163, loss_ce: 0.008217
2022-01-15 20:08:05,427 iteration 3149 : loss : 0.021963, loss_ce: 0.007726
2022-01-15 20:08:06,395 iteration 3150 : loss : 0.025948, loss_ce: 0.012347
2022-01-15 20:08:07,340 iteration 3151 : loss : 0.033790, loss_ce: 0.008107
2022-01-15 20:08:08,300 iteration 3152 : loss : 0.026313, loss_ce: 0.010051
2022-01-15 20:08:09,296 iteration 3153 : loss : 0.035370, loss_ce: 0.011503
2022-01-15 20:08:10,235 iteration 3154 : loss : 0.023116, loss_ce: 0.011189
2022-01-15 20:08:11,198 iteration 3155 : loss : 0.023372, loss_ce: 0.007793
2022-01-15 20:08:12,250 iteration 3156 : loss : 0.030999, loss_ce: 0.013195
2022-01-15 20:08:13,260 iteration 3157 : loss : 0.027803, loss_ce: 0.009797
2022-01-15 20:08:14,206 iteration 3158 : loss : 0.031877, loss_ce: 0.014073
2022-01-15 20:08:15,173 iteration 3159 : loss : 0.023025, loss_ce: 0.008896
2022-01-15 20:08:16,154 iteration 3160 : loss : 0.025273, loss_ce: 0.010028
2022-01-15 20:08:17,084 iteration 3161 : loss : 0.028427, loss_ce: 0.009938
2022-01-15 20:08:18,156 iteration 3162 : loss : 0.025939, loss_ce: 0.008815
 46%|█████████████▍               | 186/400 [57:26<1:06:18, 18.59s/it]2022-01-15 20:08:19,281 iteration 3163 : loss : 0.028136, loss_ce: 0.012020
2022-01-15 20:08:20,304 iteration 3164 : loss : 0.024060, loss_ce: 0.009519
2022-01-15 20:08:21,274 iteration 3165 : loss : 0.023916, loss_ce: 0.009639
2022-01-15 20:08:22,328 iteration 3166 : loss : 0.023278, loss_ce: 0.008079
2022-01-15 20:08:23,317 iteration 3167 : loss : 0.020432, loss_ce: 0.008806
2022-01-15 20:08:24,434 iteration 3168 : loss : 0.066991, loss_ce: 0.032698
2022-01-15 20:08:25,514 iteration 3169 : loss : 0.040490, loss_ce: 0.020162
2022-01-15 20:08:26,472 iteration 3170 : loss : 0.027479, loss_ce: 0.012425
2022-01-15 20:08:27,391 iteration 3171 : loss : 0.021864, loss_ce: 0.009514
2022-01-15 20:08:28,428 iteration 3172 : loss : 0.025326, loss_ce: 0.009293
2022-01-15 20:08:29,493 iteration 3173 : loss : 0.031386, loss_ce: 0.011618
2022-01-15 20:08:30,492 iteration 3174 : loss : 0.040214, loss_ce: 0.016055
2022-01-15 20:08:31,595 iteration 3175 : loss : 0.044594, loss_ce: 0.014441
2022-01-15 20:08:32,591 iteration 3176 : loss : 0.030166, loss_ce: 0.009831
2022-01-15 20:08:33,647 iteration 3177 : loss : 0.048711, loss_ce: 0.017604
2022-01-15 20:08:34,590 iteration 3178 : loss : 0.026181, loss_ce: 0.008611
2022-01-15 20:08:35,583 iteration 3179 : loss : 0.038291, loss_ce: 0.010374
 47%|█████████████▌               | 187/400 [57:43<1:04:45, 18.24s/it]2022-01-15 20:08:36,724 iteration 3180 : loss : 0.040064, loss_ce: 0.015939
2022-01-15 20:08:37,697 iteration 3181 : loss : 0.026330, loss_ce: 0.009534
2022-01-15 20:08:38,733 iteration 3182 : loss : 0.032994, loss_ce: 0.011704
2022-01-15 20:08:39,724 iteration 3183 : loss : 0.027687, loss_ce: 0.007231
2022-01-15 20:08:40,755 iteration 3184 : loss : 0.058880, loss_ce: 0.021082
2022-01-15 20:08:41,821 iteration 3185 : loss : 0.035089, loss_ce: 0.013657
2022-01-15 20:08:42,768 iteration 3186 : loss : 0.032706, loss_ce: 0.017188
2022-01-15 20:08:43,816 iteration 3187 : loss : 0.019312, loss_ce: 0.007384
2022-01-15 20:08:44,840 iteration 3188 : loss : 0.024791, loss_ce: 0.010719
2022-01-15 20:08:45,888 iteration 3189 : loss : 0.033789, loss_ce: 0.013639
2022-01-15 20:08:46,907 iteration 3190 : loss : 0.024540, loss_ce: 0.009289
2022-01-15 20:08:48,055 iteration 3191 : loss : 0.036978, loss_ce: 0.011887
2022-01-15 20:08:49,024 iteration 3192 : loss : 0.029626, loss_ce: 0.009809
2022-01-15 20:08:50,093 iteration 3193 : loss : 0.029213, loss_ce: 0.013393
2022-01-15 20:08:51,158 iteration 3194 : loss : 0.042249, loss_ce: 0.011826
2022-01-15 20:08:52,177 iteration 3195 : loss : 0.026696, loss_ce: 0.012276
2022-01-15 20:08:53,182 iteration 3196 : loss : 0.029391, loss_ce: 0.012422
 47%|█████████████▋               | 188/400 [58:01<1:03:45, 18.05s/it]2022-01-15 20:08:54,171 iteration 3197 : loss : 0.025321, loss_ce: 0.009828
2022-01-15 20:08:55,153 iteration 3198 : loss : 0.027772, loss_ce: 0.013052
2022-01-15 20:08:56,164 iteration 3199 : loss : 0.028876, loss_ce: 0.011648
2022-01-15 20:08:57,284 iteration 3200 : loss : 0.036023, loss_ce: 0.021433
2022-01-15 20:08:58,325 iteration 3201 : loss : 0.037903, loss_ce: 0.009975
2022-01-15 20:08:59,334 iteration 3202 : loss : 0.032107, loss_ce: 0.010303
2022-01-15 20:09:00,449 iteration 3203 : loss : 0.027364, loss_ce: 0.011481
2022-01-15 20:09:01,442 iteration 3204 : loss : 0.041537, loss_ce: 0.015628
2022-01-15 20:09:02,512 iteration 3205 : loss : 0.049044, loss_ce: 0.017422
2022-01-15 20:09:03,530 iteration 3206 : loss : 0.027601, loss_ce: 0.012054
2022-01-15 20:09:04,637 iteration 3207 : loss : 0.031755, loss_ce: 0.013563
2022-01-15 20:09:05,585 iteration 3208 : loss : 0.033202, loss_ce: 0.010223
2022-01-15 20:09:06,550 iteration 3209 : loss : 0.042623, loss_ce: 0.023218
2022-01-15 20:09:07,473 iteration 3210 : loss : 0.021850, loss_ce: 0.009995
2022-01-15 20:09:08,483 iteration 3211 : loss : 0.031169, loss_ce: 0.008798
2022-01-15 20:09:09,473 iteration 3212 : loss : 0.037040, loss_ce: 0.014686
2022-01-15 20:09:10,493 iteration 3213 : loss : 0.036254, loss_ce: 0.011712
 47%|█████████████▋               | 189/400 [58:18<1:02:41, 17.83s/it]2022-01-15 20:09:11,585 iteration 3214 : loss : 0.028210, loss_ce: 0.012397
2022-01-15 20:09:12,707 iteration 3215 : loss : 0.028240, loss_ce: 0.010071
2022-01-15 20:09:13,785 iteration 3216 : loss : 0.038270, loss_ce: 0.013138
2022-01-15 20:09:14,867 iteration 3217 : loss : 0.047163, loss_ce: 0.009819
2022-01-15 20:09:15,905 iteration 3218 : loss : 0.030452, loss_ce: 0.011600
2022-01-15 20:09:16,893 iteration 3219 : loss : 0.023263, loss_ce: 0.008731
2022-01-15 20:09:17,949 iteration 3220 : loss : 0.034613, loss_ce: 0.013706
2022-01-15 20:09:18,925 iteration 3221 : loss : 0.035834, loss_ce: 0.016882
2022-01-15 20:09:19,943 iteration 3222 : loss : 0.036307, loss_ce: 0.021572
2022-01-15 20:09:20,982 iteration 3223 : loss : 0.026750, loss_ce: 0.007075
2022-01-15 20:09:22,049 iteration 3224 : loss : 0.042294, loss_ce: 0.014243
2022-01-15 20:09:23,032 iteration 3225 : loss : 0.029918, loss_ce: 0.010467
2022-01-15 20:09:24,133 iteration 3226 : loss : 0.035196, loss_ce: 0.010494
2022-01-15 20:09:25,162 iteration 3227 : loss : 0.027216, loss_ce: 0.010110
2022-01-15 20:09:26,081 iteration 3228 : loss : 0.023923, loss_ce: 0.010486
2022-01-15 20:09:27,162 iteration 3229 : loss : 0.023728, loss_ce: 0.009837
2022-01-15 20:09:27,162 Training Data Eval:
2022-01-15 20:09:32,028   Average segmentation loss on training set: 0.0195
2022-01-15 20:09:32,028 Validation Data Eval:
2022-01-15 20:09:33,693   Average segmentation loss on validation set: 0.0806
2022-01-15 20:09:34,831 iteration 3230 : loss : 0.039715, loss_ce: 0.013614
 48%|█████████████▊               | 190/400 [58:42<1:09:13, 19.78s/it]2022-01-15 20:09:35,877 iteration 3231 : loss : 0.037064, loss_ce: 0.013864
2022-01-15 20:09:36,884 iteration 3232 : loss : 0.026744, loss_ce: 0.011822
2022-01-15 20:09:37,881 iteration 3233 : loss : 0.025833, loss_ce: 0.007903
2022-01-15 20:09:38,838 iteration 3234 : loss : 0.035798, loss_ce: 0.012726
2022-01-15 20:09:39,812 iteration 3235 : loss : 0.025282, loss_ce: 0.007145
2022-01-15 20:09:40,850 iteration 3236 : loss : 0.024287, loss_ce: 0.010495
2022-01-15 20:09:41,905 iteration 3237 : loss : 0.020911, loss_ce: 0.008718
2022-01-15 20:09:42,930 iteration 3238 : loss : 0.041805, loss_ce: 0.008756
2022-01-15 20:09:43,930 iteration 3239 : loss : 0.026247, loss_ce: 0.010878
2022-01-15 20:09:44,955 iteration 3240 : loss : 0.028987, loss_ce: 0.009861
2022-01-15 20:09:46,010 iteration 3241 : loss : 0.026877, loss_ce: 0.010999
2022-01-15 20:09:47,115 iteration 3242 : loss : 0.028870, loss_ce: 0.013860
2022-01-15 20:09:48,077 iteration 3243 : loss : 0.026221, loss_ce: 0.012204
2022-01-15 20:09:49,072 iteration 3244 : loss : 0.067138, loss_ce: 0.011339
2022-01-15 20:09:50,041 iteration 3245 : loss : 0.025174, loss_ce: 0.010169
2022-01-15 20:09:51,113 iteration 3246 : loss : 0.033308, loss_ce: 0.014141
2022-01-15 20:09:52,138 iteration 3247 : loss : 0.024887, loss_ce: 0.009248
 48%|█████████████▊               | 191/400 [59:00<1:06:19, 19.04s/it]2022-01-15 20:09:53,369 iteration 3248 : loss : 0.050742, loss_ce: 0.023658
2022-01-15 20:09:54,274 iteration 3249 : loss : 0.023090, loss_ce: 0.006954
2022-01-15 20:09:55,296 iteration 3250 : loss : 0.044214, loss_ce: 0.015517
2022-01-15 20:09:56,291 iteration 3251 : loss : 0.030464, loss_ce: 0.007372
2022-01-15 20:09:57,224 iteration 3252 : loss : 0.025561, loss_ce: 0.010187
2022-01-15 20:09:58,243 iteration 3253 : loss : 0.035272, loss_ce: 0.014170
2022-01-15 20:09:59,242 iteration 3254 : loss : 0.031775, loss_ce: 0.009810
2022-01-15 20:10:00,283 iteration 3255 : loss : 0.027460, loss_ce: 0.010172
2022-01-15 20:10:01,221 iteration 3256 : loss : 0.025176, loss_ce: 0.013146
2022-01-15 20:10:02,207 iteration 3257 : loss : 0.042339, loss_ce: 0.013565
2022-01-15 20:10:03,288 iteration 3258 : loss : 0.034960, loss_ce: 0.014884
2022-01-15 20:10:04,280 iteration 3259 : loss : 0.030168, loss_ce: 0.011624
2022-01-15 20:10:05,237 iteration 3260 : loss : 0.028302, loss_ce: 0.012402
2022-01-15 20:10:06,290 iteration 3261 : loss : 0.044018, loss_ce: 0.016480
2022-01-15 20:10:07,264 iteration 3262 : loss : 0.044080, loss_ce: 0.018699
2022-01-15 20:10:08,231 iteration 3263 : loss : 0.041448, loss_ce: 0.013490
2022-01-15 20:10:09,196 iteration 3264 : loss : 0.030286, loss_ce: 0.010522
 48%|█████████████▉               | 192/400 [59:17<1:03:57, 18.45s/it]2022-01-15 20:10:10,124 iteration 3265 : loss : 0.025801, loss_ce: 0.009906
2022-01-15 20:10:11,142 iteration 3266 : loss : 0.025506, loss_ce: 0.010175
2022-01-15 20:10:12,086 iteration 3267 : loss : 0.023578, loss_ce: 0.009981
2022-01-15 20:10:13,199 iteration 3268 : loss : 0.042836, loss_ce: 0.017783
2022-01-15 20:10:14,127 iteration 3269 : loss : 0.037348, loss_ce: 0.018172
2022-01-15 20:10:15,062 iteration 3270 : loss : 0.024733, loss_ce: 0.009548
2022-01-15 20:10:16,132 iteration 3271 : loss : 0.030181, loss_ce: 0.009576
2022-01-15 20:10:17,096 iteration 3272 : loss : 0.026463, loss_ce: 0.008963
2022-01-15 20:10:18,051 iteration 3273 : loss : 0.056708, loss_ce: 0.020027
2022-01-15 20:10:19,092 iteration 3274 : loss : 0.029701, loss_ce: 0.010319
2022-01-15 20:10:20,048 iteration 3275 : loss : 0.020475, loss_ce: 0.008809
2022-01-15 20:10:21,049 iteration 3276 : loss : 0.027561, loss_ce: 0.009272
2022-01-15 20:10:22,119 iteration 3277 : loss : 0.027140, loss_ce: 0.011466
2022-01-15 20:10:23,131 iteration 3278 : loss : 0.031428, loss_ce: 0.012845
2022-01-15 20:10:24,196 iteration 3279 : loss : 0.045164, loss_ce: 0.016370
2022-01-15 20:10:25,227 iteration 3280 : loss : 0.030539, loss_ce: 0.014282
2022-01-15 20:10:26,243 iteration 3281 : loss : 0.022041, loss_ce: 0.006168
 48%|█████████████▉               | 193/400 [59:34<1:02:11, 18.02s/it]2022-01-15 20:10:27,279 iteration 3282 : loss : 0.024865, loss_ce: 0.010027
2022-01-15 20:10:28,397 iteration 3283 : loss : 0.035213, loss_ce: 0.013289
2022-01-15 20:10:29,363 iteration 3284 : loss : 0.025599, loss_ce: 0.011077
2022-01-15 20:10:30,273 iteration 3285 : loss : 0.024536, loss_ce: 0.008866
2022-01-15 20:10:31,336 iteration 3286 : loss : 0.034728, loss_ce: 0.008984
2022-01-15 20:10:32,376 iteration 3287 : loss : 0.034117, loss_ce: 0.014055
2022-01-15 20:10:33,385 iteration 3288 : loss : 0.025794, loss_ce: 0.009562
2022-01-15 20:10:34,394 iteration 3289 : loss : 0.036938, loss_ce: 0.011280
2022-01-15 20:10:35,335 iteration 3290 : loss : 0.023990, loss_ce: 0.007074
2022-01-15 20:10:36,395 iteration 3291 : loss : 0.039098, loss_ce: 0.013075
2022-01-15 20:10:37,373 iteration 3292 : loss : 0.024535, loss_ce: 0.011477
2022-01-15 20:10:38,307 iteration 3293 : loss : 0.022362, loss_ce: 0.008427
2022-01-15 20:10:39,265 iteration 3294 : loss : 0.024911, loss_ce: 0.009746
2022-01-15 20:10:40,272 iteration 3295 : loss : 0.034471, loss_ce: 0.016075
2022-01-15 20:10:41,297 iteration 3296 : loss : 0.033871, loss_ce: 0.011482
2022-01-15 20:10:42,264 iteration 3297 : loss : 0.034147, loss_ce: 0.013538
2022-01-15 20:10:43,186 iteration 3298 : loss : 0.024852, loss_ce: 0.009669
 48%|██████████████               | 194/400 [59:51<1:00:46, 17.70s/it]2022-01-15 20:10:44,203 iteration 3299 : loss : 0.019799, loss_ce: 0.007764
2022-01-15 20:10:45,172 iteration 3300 : loss : 0.025460, loss_ce: 0.010126
2022-01-15 20:10:46,216 iteration 3301 : loss : 0.032137, loss_ce: 0.010240
2022-01-15 20:10:47,150 iteration 3302 : loss : 0.028588, loss_ce: 0.008171
2022-01-15 20:10:48,207 iteration 3303 : loss : 0.032693, loss_ce: 0.010625
2022-01-15 20:10:49,233 iteration 3304 : loss : 0.027925, loss_ce: 0.014064
2022-01-15 20:10:50,274 iteration 3305 : loss : 0.031884, loss_ce: 0.010353
2022-01-15 20:10:51,238 iteration 3306 : loss : 0.022506, loss_ce: 0.007782
2022-01-15 20:10:52,333 iteration 3307 : loss : 0.034009, loss_ce: 0.015609
2022-01-15 20:10:53,422 iteration 3308 : loss : 0.031972, loss_ce: 0.013588
2022-01-15 20:10:54,450 iteration 3309 : loss : 0.021922, loss_ce: 0.008637
2022-01-15 20:10:55,528 iteration 3310 : loss : 0.032754, loss_ce: 0.010111
2022-01-15 20:10:56,528 iteration 3311 : loss : 0.040376, loss_ce: 0.010937
2022-01-15 20:10:57,490 iteration 3312 : loss : 0.023116, loss_ce: 0.011001
2022-01-15 20:10:58,571 iteration 3313 : loss : 0.037211, loss_ce: 0.014571
2022-01-15 20:10:59,474 iteration 3314 : loss : 0.023174, loss_ce: 0.009764
2022-01-15 20:10:59,475 Training Data Eval:
2022-01-15 20:11:04,427   Average segmentation loss on training set: 0.0198
2022-01-15 20:11:04,427 Validation Data Eval:
2022-01-15 20:11:06,099   Average segmentation loss on validation set: 0.1120
2022-01-15 20:11:07,084 iteration 3315 : loss : 0.028207, loss_ce: 0.010762
 49%|█████████████▏             | 195/400 [1:00:15<1:06:49, 19.56s/it]2022-01-15 20:11:08,159 iteration 3316 : loss : 0.028553, loss_ce: 0.007223
2022-01-15 20:11:09,199 iteration 3317 : loss : 0.035448, loss_ce: 0.011987
2022-01-15 20:11:10,229 iteration 3318 : loss : 0.030054, loss_ce: 0.012714
2022-01-15 20:11:11,191 iteration 3319 : loss : 0.021113, loss_ce: 0.008368
2022-01-15 20:11:12,322 iteration 3320 : loss : 0.032839, loss_ce: 0.010503
2022-01-15 20:11:13,264 iteration 3321 : loss : 0.021744, loss_ce: 0.009822
2022-01-15 20:11:14,183 iteration 3322 : loss : 0.028605, loss_ce: 0.010652
2022-01-15 20:11:15,221 iteration 3323 : loss : 0.040842, loss_ce: 0.017812
2022-01-15 20:11:16,242 iteration 3324 : loss : 0.030799, loss_ce: 0.009846
2022-01-15 20:11:17,315 iteration 3325 : loss : 0.035111, loss_ce: 0.012893
2022-01-15 20:11:18,324 iteration 3326 : loss : 0.020725, loss_ce: 0.007771
2022-01-15 20:11:19,468 iteration 3327 : loss : 0.044753, loss_ce: 0.012969
2022-01-15 20:11:20,410 iteration 3328 : loss : 0.024753, loss_ce: 0.011462
2022-01-15 20:11:21,365 iteration 3329 : loss : 0.024424, loss_ce: 0.008820
2022-01-15 20:11:22,382 iteration 3330 : loss : 0.025052, loss_ce: 0.011152
2022-01-15 20:11:23,288 iteration 3331 : loss : 0.021241, loss_ce: 0.008154
2022-01-15 20:11:24,181 iteration 3332 : loss : 0.021555, loss_ce: 0.006913
 49%|█████████████▏             | 196/400 [1:00:32<1:03:59, 18.82s/it]2022-01-15 20:11:25,238 iteration 3333 : loss : 0.026798, loss_ce: 0.011235
2022-01-15 20:11:26,252 iteration 3334 : loss : 0.025814, loss_ce: 0.009553
2022-01-15 20:11:27,312 iteration 3335 : loss : 0.031927, loss_ce: 0.012675
2022-01-15 20:11:28,248 iteration 3336 : loss : 0.023859, loss_ce: 0.008481
2022-01-15 20:11:29,172 iteration 3337 : loss : 0.025522, loss_ce: 0.009347
2022-01-15 20:11:30,197 iteration 3338 : loss : 0.025065, loss_ce: 0.008785
2022-01-15 20:11:31,232 iteration 3339 : loss : 0.040309, loss_ce: 0.012336
2022-01-15 20:11:32,224 iteration 3340 : loss : 0.030084, loss_ce: 0.011066
2022-01-15 20:11:33,178 iteration 3341 : loss : 0.024740, loss_ce: 0.011404
2022-01-15 20:11:34,133 iteration 3342 : loss : 0.024278, loss_ce: 0.013492
2022-01-15 20:11:35,116 iteration 3343 : loss : 0.023901, loss_ce: 0.009799
2022-01-15 20:11:36,174 iteration 3344 : loss : 0.029789, loss_ce: 0.008020
2022-01-15 20:11:37,240 iteration 3345 : loss : 0.022451, loss_ce: 0.010292
2022-01-15 20:11:38,252 iteration 3346 : loss : 0.047149, loss_ce: 0.016000
2022-01-15 20:11:39,229 iteration 3347 : loss : 0.022146, loss_ce: 0.007522
2022-01-15 20:11:40,305 iteration 3348 : loss : 0.027931, loss_ce: 0.011809
2022-01-15 20:11:41,235 iteration 3349 : loss : 0.040112, loss_ce: 0.008830
 49%|█████████████▎             | 197/400 [1:00:49<1:01:53, 18.29s/it]2022-01-15 20:11:42,238 iteration 3350 : loss : 0.019912, loss_ce: 0.009525
2022-01-15 20:11:43,264 iteration 3351 : loss : 0.022699, loss_ce: 0.008102
2022-01-15 20:11:44,220 iteration 3352 : loss : 0.028077, loss_ce: 0.010449
2022-01-15 20:11:45,228 iteration 3353 : loss : 0.025236, loss_ce: 0.008119
2022-01-15 20:11:46,193 iteration 3354 : loss : 0.020290, loss_ce: 0.005890
2022-01-15 20:11:47,198 iteration 3355 : loss : 0.024217, loss_ce: 0.008819
2022-01-15 20:11:48,148 iteration 3356 : loss : 0.046473, loss_ce: 0.019153
2022-01-15 20:11:49,106 iteration 3357 : loss : 0.019446, loss_ce: 0.007819
2022-01-15 20:11:50,106 iteration 3358 : loss : 0.021089, loss_ce: 0.006594
2022-01-15 20:11:51,079 iteration 3359 : loss : 0.027262, loss_ce: 0.012793
2022-01-15 20:11:52,121 iteration 3360 : loss : 0.021060, loss_ce: 0.006654
2022-01-15 20:11:53,114 iteration 3361 : loss : 0.030914, loss_ce: 0.012817
2022-01-15 20:11:54,066 iteration 3362 : loss : 0.031690, loss_ce: 0.011177
2022-01-15 20:11:54,959 iteration 3363 : loss : 0.028006, loss_ce: 0.009289
2022-01-15 20:11:56,008 iteration 3364 : loss : 0.026266, loss_ce: 0.010463
2022-01-15 20:11:56,982 iteration 3365 : loss : 0.020219, loss_ce: 0.008400
2022-01-15 20:11:57,959 iteration 3366 : loss : 0.024817, loss_ce: 0.009770
 50%|█████████████▎             | 198/400 [1:01:05<1:00:00, 17.82s/it]2022-01-15 20:11:59,134 iteration 3367 : loss : 0.029176, loss_ce: 0.012031
2022-01-15 20:12:00,114 iteration 3368 : loss : 0.030592, loss_ce: 0.014730
2022-01-15 20:12:01,113 iteration 3369 : loss : 0.035335, loss_ce: 0.014804
2022-01-15 20:12:02,055 iteration 3370 : loss : 0.026941, loss_ce: 0.008553
2022-01-15 20:12:03,039 iteration 3371 : loss : 0.025090, loss_ce: 0.009338
2022-01-15 20:12:04,091 iteration 3372 : loss : 0.035967, loss_ce: 0.009399
2022-01-15 20:12:05,091 iteration 3373 : loss : 0.036361, loss_ce: 0.012146
2022-01-15 20:12:06,163 iteration 3374 : loss : 0.023664, loss_ce: 0.010094
2022-01-15 20:12:07,262 iteration 3375 : loss : 0.034807, loss_ce: 0.011922
2022-01-15 20:12:08,169 iteration 3376 : loss : 0.018678, loss_ce: 0.006168
2022-01-15 20:12:09,223 iteration 3377 : loss : 0.035973, loss_ce: 0.014432
2022-01-15 20:12:10,178 iteration 3378 : loss : 0.024689, loss_ce: 0.007317
2022-01-15 20:12:11,216 iteration 3379 : loss : 0.025258, loss_ce: 0.008883
2022-01-15 20:12:12,165 iteration 3380 : loss : 0.023835, loss_ce: 0.007505
2022-01-15 20:12:13,187 iteration 3381 : loss : 0.027958, loss_ce: 0.014600
2022-01-15 20:12:14,232 iteration 3382 : loss : 0.024919, loss_ce: 0.008692
2022-01-15 20:12:15,222 iteration 3383 : loss : 0.024909, loss_ce: 0.010208
 50%|██████████████▍              | 199/400 [1:01:23<59:08, 17.65s/it]2022-01-15 20:12:16,285 iteration 3384 : loss : 0.024489, loss_ce: 0.009390
2022-01-15 20:12:17,247 iteration 3385 : loss : 0.026419, loss_ce: 0.010175
2022-01-15 20:12:18,203 iteration 3386 : loss : 0.027424, loss_ce: 0.008518
2022-01-15 20:12:19,147 iteration 3387 : loss : 0.031530, loss_ce: 0.009891
2022-01-15 20:12:20,195 iteration 3388 : loss : 0.034690, loss_ce: 0.012123
2022-01-15 20:12:21,137 iteration 3389 : loss : 0.027128, loss_ce: 0.011992
2022-01-15 20:12:22,151 iteration 3390 : loss : 0.025322, loss_ce: 0.009899
2022-01-15 20:12:23,258 iteration 3391 : loss : 0.042871, loss_ce: 0.034071
2022-01-15 20:12:24,300 iteration 3392 : loss : 0.028899, loss_ce: 0.010437
2022-01-15 20:12:25,236 iteration 3393 : loss : 0.035629, loss_ce: 0.016561
2022-01-15 20:12:26,228 iteration 3394 : loss : 0.024892, loss_ce: 0.008095
2022-01-15 20:12:27,247 iteration 3395 : loss : 0.028045, loss_ce: 0.012110
2022-01-15 20:12:28,263 iteration 3396 : loss : 0.028564, loss_ce: 0.011556
2022-01-15 20:12:29,200 iteration 3397 : loss : 0.030802, loss_ce: 0.014063
2022-01-15 20:12:30,353 iteration 3398 : loss : 0.032428, loss_ce: 0.012542
2022-01-15 20:12:31,364 iteration 3399 : loss : 0.030714, loss_ce: 0.014085
2022-01-15 20:12:31,364 Training Data Eval:
2022-01-15 20:12:36,121   Average segmentation loss on training set: 0.0191
2022-01-15 20:12:36,121 Validation Data Eval:
2022-01-15 20:12:37,761   Average segmentation loss on validation set: 0.0610
2022-01-15 20:12:38,657 Found new lowest validation loss at iteration 3399! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_1HEAD_NEW_best_val_loss_seed100.pth
2022-01-15 20:12:39,650 iteration 3400 : loss : 0.030476, loss_ce: 0.009206
 50%|█████████████▌             | 200/400 [1:01:47<1:05:36, 19.68s/it]2022-01-15 20:12:40,720 iteration 3401 : loss : 0.033885, loss_ce: 0.012759
2022-01-15 20:12:41,715 iteration 3402 : loss : 0.022145, loss_ce: 0.008300
2022-01-15 20:12:42,790 iteration 3403 : loss : 0.039697, loss_ce: 0.014413
2022-01-15 20:12:43,732 iteration 3404 : loss : 0.029477, loss_ce: 0.009514
2022-01-15 20:12:44,711 iteration 3405 : loss : 0.024830, loss_ce: 0.006278
2022-01-15 20:12:45,637 iteration 3406 : loss : 0.027937, loss_ce: 0.012248
2022-01-15 20:12:46,595 iteration 3407 : loss : 0.021000, loss_ce: 0.007064
2022-01-15 20:12:47,596 iteration 3408 : loss : 0.022488, loss_ce: 0.008810
2022-01-15 20:12:48,583 iteration 3409 : loss : 0.023874, loss_ce: 0.004805
2022-01-15 20:12:49,574 iteration 3410 : loss : 0.021975, loss_ce: 0.008232
2022-01-15 20:12:50,615 iteration 3411 : loss : 0.031177, loss_ce: 0.010360
2022-01-15 20:12:51,678 iteration 3412 : loss : 0.025534, loss_ce: 0.010703
2022-01-15 20:12:52,777 iteration 3413 : loss : 0.027957, loss_ce: 0.012761
2022-01-15 20:12:53,832 iteration 3414 : loss : 0.062228, loss_ce: 0.015546
2022-01-15 20:12:54,718 iteration 3415 : loss : 0.022271, loss_ce: 0.008830
2022-01-15 20:12:55,740 iteration 3416 : loss : 0.024369, loss_ce: 0.010127
2022-01-15 20:12:56,712 iteration 3417 : loss : 0.019831, loss_ce: 0.008126
 50%|█████████████▌             | 201/400 [1:02:04<1:02:41, 18.90s/it]2022-01-15 20:12:57,868 iteration 3418 : loss : 0.046199, loss_ce: 0.012890
2022-01-15 20:12:58,870 iteration 3419 : loss : 0.035255, loss_ce: 0.015201
2022-01-15 20:12:59,797 iteration 3420 : loss : 0.022622, loss_ce: 0.011258
2022-01-15 20:13:00,795 iteration 3421 : loss : 0.041768, loss_ce: 0.010733
2022-01-15 20:13:01,786 iteration 3422 : loss : 0.028327, loss_ce: 0.010342
2022-01-15 20:13:02,847 iteration 3423 : loss : 0.027549, loss_ce: 0.013433
2022-01-15 20:13:03,783 iteration 3424 : loss : 0.022268, loss_ce: 0.006846
2022-01-15 20:13:04,808 iteration 3425 : loss : 0.039200, loss_ce: 0.016660
2022-01-15 20:13:05,794 iteration 3426 : loss : 0.021363, loss_ce: 0.007321
2022-01-15 20:13:06,930 iteration 3427 : loss : 0.036331, loss_ce: 0.012004
2022-01-15 20:13:07,952 iteration 3428 : loss : 0.023187, loss_ce: 0.008983
2022-01-15 20:13:08,980 iteration 3429 : loss : 0.027651, loss_ce: 0.012542
2022-01-15 20:13:10,011 iteration 3430 : loss : 0.020745, loss_ce: 0.006881
2022-01-15 20:13:11,080 iteration 3431 : loss : 0.033726, loss_ce: 0.011973
2022-01-15 20:13:12,046 iteration 3432 : loss : 0.028863, loss_ce: 0.007792
2022-01-15 20:13:13,065 iteration 3433 : loss : 0.023518, loss_ce: 0.006698
2022-01-15 20:13:14,051 iteration 3434 : loss : 0.035245, loss_ce: 0.008711
 50%|█████████████▋             | 202/400 [1:02:21<1:00:49, 18.43s/it]2022-01-15 20:13:15,070 iteration 3435 : loss : 0.020674, loss_ce: 0.009669
2022-01-15 20:13:16,072 iteration 3436 : loss : 0.030539, loss_ce: 0.012979
2022-01-15 20:13:17,045 iteration 3437 : loss : 0.021109, loss_ce: 0.006518
2022-01-15 20:13:18,057 iteration 3438 : loss : 0.029388, loss_ce: 0.014858
2022-01-15 20:13:19,152 iteration 3439 : loss : 0.025239, loss_ce: 0.009383
2022-01-15 20:13:20,244 iteration 3440 : loss : 0.053513, loss_ce: 0.015347
2022-01-15 20:13:21,143 iteration 3441 : loss : 0.022677, loss_ce: 0.011332
2022-01-15 20:13:22,128 iteration 3442 : loss : 0.018953, loss_ce: 0.005843
2022-01-15 20:13:23,185 iteration 3443 : loss : 0.029648, loss_ce: 0.012270
2022-01-15 20:13:24,181 iteration 3444 : loss : 0.031020, loss_ce: 0.011072
2022-01-15 20:13:25,245 iteration 3445 : loss : 0.030128, loss_ce: 0.011030
2022-01-15 20:13:26,272 iteration 3446 : loss : 0.027351, loss_ce: 0.008577
2022-01-15 20:13:27,306 iteration 3447 : loss : 0.031448, loss_ce: 0.015477
2022-01-15 20:13:28,255 iteration 3448 : loss : 0.023375, loss_ce: 0.008457
2022-01-15 20:13:29,294 iteration 3449 : loss : 0.038595, loss_ce: 0.010748
2022-01-15 20:13:30,367 iteration 3450 : loss : 0.030001, loss_ce: 0.009157
2022-01-15 20:13:31,355 iteration 3451 : loss : 0.019418, loss_ce: 0.008061
 51%|██████████████▋              | 203/400 [1:02:39<59:24, 18.09s/it]2022-01-15 20:13:32,425 iteration 3452 : loss : 0.022950, loss_ce: 0.008539
2022-01-15 20:13:33,492 iteration 3453 : loss : 0.033540, loss_ce: 0.010336
2022-01-15 20:13:34,559 iteration 3454 : loss : 0.038062, loss_ce: 0.010725
2022-01-15 20:13:35,587 iteration 3455 : loss : 0.045478, loss_ce: 0.023206
2022-01-15 20:13:36,606 iteration 3456 : loss : 0.038735, loss_ce: 0.013795
2022-01-15 20:13:37,634 iteration 3457 : loss : 0.027196, loss_ce: 0.010775
2022-01-15 20:13:38,671 iteration 3458 : loss : 0.022999, loss_ce: 0.011915
2022-01-15 20:13:39,791 iteration 3459 : loss : 0.029178, loss_ce: 0.013447
2022-01-15 20:13:40,828 iteration 3460 : loss : 0.038618, loss_ce: 0.013989
2022-01-15 20:13:41,834 iteration 3461 : loss : 0.028032, loss_ce: 0.012056
2022-01-15 20:13:42,790 iteration 3462 : loss : 0.028909, loss_ce: 0.012291
2022-01-15 20:13:43,712 iteration 3463 : loss : 0.021847, loss_ce: 0.006751
2022-01-15 20:13:44,709 iteration 3464 : loss : 0.029379, loss_ce: 0.010384
2022-01-15 20:13:45,675 iteration 3465 : loss : 0.033308, loss_ce: 0.010322
2022-01-15 20:13:46,718 iteration 3466 : loss : 0.026333, loss_ce: 0.010116
2022-01-15 20:13:47,831 iteration 3467 : loss : 0.025378, loss_ce: 0.009658
2022-01-15 20:13:48,976 iteration 3468 : loss : 0.023169, loss_ce: 0.007426
 51%|██████████████▊              | 204/400 [1:02:56<58:38, 17.95s/it]2022-01-15 20:13:49,969 iteration 3469 : loss : 0.020524, loss_ce: 0.008963
2022-01-15 20:13:51,134 iteration 3470 : loss : 0.031395, loss_ce: 0.012637
2022-01-15 20:13:52,194 iteration 3471 : loss : 0.025253, loss_ce: 0.008982
2022-01-15 20:13:53,263 iteration 3472 : loss : 0.028391, loss_ce: 0.012035
2022-01-15 20:13:54,331 iteration 3473 : loss : 0.020915, loss_ce: 0.008981
2022-01-15 20:13:55,304 iteration 3474 : loss : 0.037158, loss_ce: 0.014703
2022-01-15 20:13:56,413 iteration 3475 : loss : 0.041187, loss_ce: 0.016200
2022-01-15 20:13:57,422 iteration 3476 : loss : 0.025154, loss_ce: 0.009025
2022-01-15 20:13:58,493 iteration 3477 : loss : 0.036705, loss_ce: 0.011590
2022-01-15 20:13:59,530 iteration 3478 : loss : 0.032748, loss_ce: 0.010482
2022-01-15 20:14:00,546 iteration 3479 : loss : 0.053543, loss_ce: 0.022875
2022-01-15 20:14:01,540 iteration 3480 : loss : 0.024457, loss_ce: 0.010166
2022-01-15 20:14:02,584 iteration 3481 : loss : 0.036136, loss_ce: 0.018777
2022-01-15 20:14:03,543 iteration 3482 : loss : 0.027962, loss_ce: 0.008584
2022-01-15 20:14:04,646 iteration 3483 : loss : 0.026712, loss_ce: 0.009957
2022-01-15 20:14:05,668 iteration 3484 : loss : 0.031778, loss_ce: 0.010192
2022-01-15 20:14:05,668 Training Data Eval:
2022-01-15 20:14:10,559   Average segmentation loss on training set: 0.0223
2022-01-15 20:14:10,560 Validation Data Eval:
2022-01-15 20:14:12,228   Average segmentation loss on validation set: 0.1586
2022-01-15 20:14:13,259 iteration 3485 : loss : 0.028495, loss_ce: 0.011550
 51%|█████████████▊             | 205/400 [1:03:21<1:04:30, 19.85s/it]2022-01-15 20:14:14,317 iteration 3486 : loss : 0.021922, loss_ce: 0.007612
2022-01-15 20:14:15,349 iteration 3487 : loss : 0.035645, loss_ce: 0.015044
2022-01-15 20:14:16,432 iteration 3488 : loss : 0.037666, loss_ce: 0.022663
2022-01-15 20:14:17,410 iteration 3489 : loss : 0.025263, loss_ce: 0.008335
2022-01-15 20:14:18,505 iteration 3490 : loss : 0.022901, loss_ce: 0.009121
2022-01-15 20:14:19,566 iteration 3491 : loss : 0.030697, loss_ce: 0.013995
2022-01-15 20:14:20,498 iteration 3492 : loss : 0.022360, loss_ce: 0.006712
2022-01-15 20:14:21,609 iteration 3493 : loss : 0.040121, loss_ce: 0.009800
2022-01-15 20:14:22,649 iteration 3494 : loss : 0.025095, loss_ce: 0.012998
2022-01-15 20:14:23,564 iteration 3495 : loss : 0.019233, loss_ce: 0.008261
2022-01-15 20:14:24,607 iteration 3496 : loss : 0.050478, loss_ce: 0.016896
2022-01-15 20:14:25,691 iteration 3497 : loss : 0.028769, loss_ce: 0.013814
2022-01-15 20:14:26,709 iteration 3498 : loss : 0.030226, loss_ce: 0.011479
2022-01-15 20:14:27,786 iteration 3499 : loss : 0.042068, loss_ce: 0.011607
2022-01-15 20:14:28,766 iteration 3500 : loss : 0.028733, loss_ce: 0.008698
2022-01-15 20:14:29,792 iteration 3501 : loss : 0.023587, loss_ce: 0.008672
2022-01-15 20:14:30,805 iteration 3502 : loss : 0.026194, loss_ce: 0.009136
 52%|█████████████▉             | 206/400 [1:03:38<1:01:56, 19.16s/it]2022-01-15 20:14:31,804 iteration 3503 : loss : 0.022647, loss_ce: 0.010251
2022-01-15 20:14:32,833 iteration 3504 : loss : 0.022279, loss_ce: 0.007311
2022-01-15 20:14:33,848 iteration 3505 : loss : 0.035211, loss_ce: 0.018619
2022-01-15 20:14:34,953 iteration 3506 : loss : 0.033021, loss_ce: 0.011476
2022-01-15 20:14:35,929 iteration 3507 : loss : 0.023792, loss_ce: 0.009795
2022-01-15 20:14:36,852 iteration 3508 : loss : 0.019090, loss_ce: 0.005964
2022-01-15 20:14:37,841 iteration 3509 : loss : 0.028558, loss_ce: 0.013732
2022-01-15 20:14:38,951 iteration 3510 : loss : 0.029146, loss_ce: 0.012909
2022-01-15 20:14:39,932 iteration 3511 : loss : 0.023852, loss_ce: 0.009883
2022-01-15 20:14:40,948 iteration 3512 : loss : 0.032010, loss_ce: 0.012299
2022-01-15 20:14:41,876 iteration 3513 : loss : 0.030884, loss_ce: 0.009887
2022-01-15 20:14:42,784 iteration 3514 : loss : 0.017490, loss_ce: 0.007455
2022-01-15 20:14:43,749 iteration 3515 : loss : 0.022662, loss_ce: 0.008604
2022-01-15 20:14:44,783 iteration 3516 : loss : 0.034249, loss_ce: 0.012355
2022-01-15 20:14:45,780 iteration 3517 : loss : 0.040697, loss_ce: 0.015060
2022-01-15 20:14:46,715 iteration 3518 : loss : 0.019226, loss_ce: 0.008490
2022-01-15 20:14:47,674 iteration 3519 : loss : 0.031591, loss_ce: 0.010002
 52%|███████████████              | 207/400 [1:03:55<59:25, 18.47s/it]2022-01-15 20:14:48,715 iteration 3520 : loss : 0.022585, loss_ce: 0.007655
2022-01-15 20:14:49,742 iteration 3521 : loss : 0.035140, loss_ce: 0.014823
2022-01-15 20:14:50,770 iteration 3522 : loss : 0.030367, loss_ce: 0.012251
2022-01-15 20:14:51,877 iteration 3523 : loss : 0.031996, loss_ce: 0.011457
2022-01-15 20:14:52,856 iteration 3524 : loss : 0.023868, loss_ce: 0.006730
2022-01-15 20:14:53,886 iteration 3525 : loss : 0.034196, loss_ce: 0.014211
2022-01-15 20:14:54,916 iteration 3526 : loss : 0.030150, loss_ce: 0.012772
2022-01-15 20:14:55,955 iteration 3527 : loss : 0.022193, loss_ce: 0.006654
2022-01-15 20:14:56,919 iteration 3528 : loss : 0.021423, loss_ce: 0.010573
2022-01-15 20:14:57,949 iteration 3529 : loss : 0.027968, loss_ce: 0.008706
2022-01-15 20:14:58,951 iteration 3530 : loss : 0.033087, loss_ce: 0.010707
2022-01-15 20:14:59,994 iteration 3531 : loss : 0.024921, loss_ce: 0.009093
2022-01-15 20:15:00,972 iteration 3532 : loss : 0.018760, loss_ce: 0.006821
2022-01-15 20:15:01,963 iteration 3533 : loss : 0.029069, loss_ce: 0.011363
2022-01-15 20:15:02,943 iteration 3534 : loss : 0.028834, loss_ce: 0.015273
2022-01-15 20:15:03,902 iteration 3535 : loss : 0.022581, loss_ce: 0.007613
2022-01-15 20:15:04,871 iteration 3536 : loss : 0.024969, loss_ce: 0.008164
 52%|███████████████              | 208/400 [1:04:12<57:53, 18.09s/it]2022-01-15 20:15:05,934 iteration 3537 : loss : 0.028456, loss_ce: 0.010395
2022-01-15 20:15:06,962 iteration 3538 : loss : 0.028008, loss_ce: 0.008273
2022-01-15 20:15:08,024 iteration 3539 : loss : 0.039405, loss_ce: 0.018020
2022-01-15 20:15:08,980 iteration 3540 : loss : 0.027176, loss_ce: 0.005310
2022-01-15 20:15:10,055 iteration 3541 : loss : 0.028655, loss_ce: 0.011881
2022-01-15 20:15:11,030 iteration 3542 : loss : 0.031926, loss_ce: 0.009050
2022-01-15 20:15:12,064 iteration 3543 : loss : 0.026480, loss_ce: 0.013014
2022-01-15 20:15:13,125 iteration 3544 : loss : 0.024822, loss_ce: 0.009235
2022-01-15 20:15:14,099 iteration 3545 : loss : 0.029734, loss_ce: 0.010164
2022-01-15 20:15:15,021 iteration 3546 : loss : 0.024025, loss_ce: 0.010829
2022-01-15 20:15:16,082 iteration 3547 : loss : 0.023014, loss_ce: 0.008145
2022-01-15 20:15:17,126 iteration 3548 : loss : 0.023245, loss_ce: 0.008076
2022-01-15 20:15:18,124 iteration 3549 : loss : 0.025500, loss_ce: 0.011780
2022-01-15 20:15:19,066 iteration 3550 : loss : 0.022131, loss_ce: 0.007104
2022-01-15 20:15:20,127 iteration 3551 : loss : 0.061251, loss_ce: 0.021391
2022-01-15 20:15:21,190 iteration 3552 : loss : 0.043925, loss_ce: 0.018622
2022-01-15 20:15:22,251 iteration 3553 : loss : 0.029085, loss_ce: 0.010268
 52%|███████████████▏             | 209/400 [1:04:30<56:53, 17.87s/it]2022-01-15 20:15:23,286 iteration 3554 : loss : 0.027106, loss_ce: 0.010358
2022-01-15 20:15:24,323 iteration 3555 : loss : 0.027474, loss_ce: 0.011719
2022-01-15 20:15:25,305 iteration 3556 : loss : 0.046096, loss_ce: 0.016976
2022-01-15 20:15:26,277 iteration 3557 : loss : 0.025182, loss_ce: 0.011378
2022-01-15 20:15:27,213 iteration 3558 : loss : 0.030787, loss_ce: 0.010227
2022-01-15 20:15:28,287 iteration 3559 : loss : 0.029995, loss_ce: 0.011294
2022-01-15 20:15:29,263 iteration 3560 : loss : 0.036637, loss_ce: 0.010763
2022-01-15 20:15:30,281 iteration 3561 : loss : 0.025100, loss_ce: 0.010664
2022-01-15 20:15:31,263 iteration 3562 : loss : 0.025875, loss_ce: 0.010570
2022-01-15 20:15:32,249 iteration 3563 : loss : 0.022475, loss_ce: 0.008547
2022-01-15 20:15:33,269 iteration 3564 : loss : 0.023980, loss_ce: 0.007861
2022-01-15 20:15:34,199 iteration 3565 : loss : 0.023923, loss_ce: 0.009796
2022-01-15 20:15:35,075 iteration 3566 : loss : 0.018855, loss_ce: 0.007139
2022-01-15 20:15:35,999 iteration 3567 : loss : 0.024758, loss_ce: 0.007734
2022-01-15 20:15:37,037 iteration 3568 : loss : 0.025549, loss_ce: 0.009334
2022-01-15 20:15:37,989 iteration 3569 : loss : 0.021616, loss_ce: 0.009085
2022-01-15 20:15:37,989 Training Data Eval:
2022-01-15 20:15:42,774   Average segmentation loss on training set: 0.0174
2022-01-15 20:15:42,774 Validation Data Eval:
2022-01-15 20:15:44,423   Average segmentation loss on validation set: 0.0697
2022-01-15 20:15:45,421 iteration 3570 : loss : 0.021317, loss_ce: 0.006324
 52%|██████████████▏            | 210/400 [1:04:53<1:01:38, 19.46s/it]2022-01-15 20:15:46,537 iteration 3571 : loss : 0.027378, loss_ce: 0.011221
2022-01-15 20:15:47,623 iteration 3572 : loss : 0.022483, loss_ce: 0.008558
2022-01-15 20:15:48,649 iteration 3573 : loss : 0.026706, loss_ce: 0.009611
2022-01-15 20:15:49,611 iteration 3574 : loss : 0.018502, loss_ce: 0.008372
2022-01-15 20:15:50,567 iteration 3575 : loss : 0.022429, loss_ce: 0.008751
2022-01-15 20:15:51,545 iteration 3576 : loss : 0.025621, loss_ce: 0.009742
2022-01-15 20:15:52,586 iteration 3577 : loss : 0.022989, loss_ce: 0.009163
2022-01-15 20:15:53,570 iteration 3578 : loss : 0.024901, loss_ce: 0.011350
2022-01-15 20:15:54,579 iteration 3579 : loss : 0.018969, loss_ce: 0.006873
2022-01-15 20:15:55,624 iteration 3580 : loss : 0.022797, loss_ce: 0.011125
2022-01-15 20:15:56,672 iteration 3581 : loss : 0.020963, loss_ce: 0.008398
2022-01-15 20:15:57,696 iteration 3582 : loss : 0.031323, loss_ce: 0.010777
2022-01-15 20:15:58,683 iteration 3583 : loss : 0.044257, loss_ce: 0.009870
2022-01-15 20:15:59,608 iteration 3584 : loss : 0.022672, loss_ce: 0.007988
2022-01-15 20:16:00,582 iteration 3585 : loss : 0.016785, loss_ce: 0.006592
2022-01-15 20:16:01,527 iteration 3586 : loss : 0.015988, loss_ce: 0.004921
2022-01-15 20:16:02,544 iteration 3587 : loss : 0.025150, loss_ce: 0.010778
 53%|███████████████▎             | 211/400 [1:05:10<59:05, 18.76s/it]2022-01-15 20:16:03,681 iteration 3588 : loss : 0.026058, loss_ce: 0.012525
2022-01-15 20:16:04,767 iteration 3589 : loss : 0.025002, loss_ce: 0.007747
2022-01-15 20:16:05,783 iteration 3590 : loss : 0.021668, loss_ce: 0.005991
2022-01-15 20:16:06,733 iteration 3591 : loss : 0.022478, loss_ce: 0.007690
2022-01-15 20:16:07,730 iteration 3592 : loss : 0.023894, loss_ce: 0.010993
2022-01-15 20:16:08,771 iteration 3593 : loss : 0.024900, loss_ce: 0.013027
2022-01-15 20:16:09,773 iteration 3594 : loss : 0.025828, loss_ce: 0.007055
2022-01-15 20:16:10,772 iteration 3595 : loss : 0.030049, loss_ce: 0.009845
2022-01-15 20:16:11,750 iteration 3596 : loss : 0.023889, loss_ce: 0.009770
2022-01-15 20:16:12,792 iteration 3597 : loss : 0.024041, loss_ce: 0.009404
2022-01-15 20:16:13,864 iteration 3598 : loss : 0.023828, loss_ce: 0.010841
2022-01-15 20:16:14,930 iteration 3599 : loss : 0.027234, loss_ce: 0.008556
2022-01-15 20:16:15,897 iteration 3600 : loss : 0.024729, loss_ce: 0.013466
2022-01-15 20:16:16,947 iteration 3601 : loss : 0.019764, loss_ce: 0.007604
2022-01-15 20:16:18,009 iteration 3602 : loss : 0.031253, loss_ce: 0.011321
2022-01-15 20:16:18,992 iteration 3603 : loss : 0.023893, loss_ce: 0.011974
2022-01-15 20:16:19,992 iteration 3604 : loss : 0.035471, loss_ce: 0.008491
 53%|███████████████▎             | 212/400 [1:05:27<57:33, 18.37s/it]2022-01-15 20:16:21,178 iteration 3605 : loss : 0.029921, loss_ce: 0.011031
2022-01-15 20:16:22,113 iteration 3606 : loss : 0.031264, loss_ce: 0.006507
2022-01-15 20:16:23,013 iteration 3607 : loss : 0.014365, loss_ce: 0.004707
2022-01-15 20:16:24,076 iteration 3608 : loss : 0.031731, loss_ce: 0.010582
2022-01-15 20:16:25,133 iteration 3609 : loss : 0.055402, loss_ce: 0.019952
2022-01-15 20:16:26,075 iteration 3610 : loss : 0.016470, loss_ce: 0.006047
2022-01-15 20:16:27,075 iteration 3611 : loss : 0.032950, loss_ce: 0.013283
2022-01-15 20:16:28,027 iteration 3612 : loss : 0.022162, loss_ce: 0.009534
2022-01-15 20:16:29,040 iteration 3613 : loss : 0.018929, loss_ce: 0.007300
2022-01-15 20:16:30,011 iteration 3614 : loss : 0.025455, loss_ce: 0.009500
2022-01-15 20:16:31,003 iteration 3615 : loss : 0.031741, loss_ce: 0.011540
2022-01-15 20:16:31,997 iteration 3616 : loss : 0.022176, loss_ce: 0.010212
2022-01-15 20:16:33,030 iteration 3617 : loss : 0.026401, loss_ce: 0.011691
2022-01-15 20:16:34,069 iteration 3618 : loss : 0.022946, loss_ce: 0.008165
2022-01-15 20:16:35,047 iteration 3619 : loss : 0.026796, loss_ce: 0.008509
2022-01-15 20:16:36,059 iteration 3620 : loss : 0.038709, loss_ce: 0.012958
2022-01-15 20:16:37,037 iteration 3621 : loss : 0.021947, loss_ce: 0.011053
 53%|███████████████▍             | 213/400 [1:05:44<56:00, 17.97s/it]2022-01-15 20:16:38,116 iteration 3622 : loss : 0.023928, loss_ce: 0.007385
2022-01-15 20:16:39,122 iteration 3623 : loss : 0.026450, loss_ce: 0.008555
2022-01-15 20:16:40,131 iteration 3624 : loss : 0.030903, loss_ce: 0.012345
2022-01-15 20:16:41,037 iteration 3625 : loss : 0.020641, loss_ce: 0.007618
2022-01-15 20:16:42,044 iteration 3626 : loss : 0.023471, loss_ce: 0.006418
2022-01-15 20:16:43,072 iteration 3627 : loss : 0.034863, loss_ce: 0.014160
2022-01-15 20:16:44,105 iteration 3628 : loss : 0.038184, loss_ce: 0.010916
2022-01-15 20:16:45,171 iteration 3629 : loss : 0.033049, loss_ce: 0.013110
2022-01-15 20:16:46,177 iteration 3630 : loss : 0.020437, loss_ce: 0.008569
2022-01-15 20:16:47,164 iteration 3631 : loss : 0.021506, loss_ce: 0.008012
2022-01-15 20:16:48,191 iteration 3632 : loss : 0.035185, loss_ce: 0.021252
2022-01-15 20:16:49,224 iteration 3633 : loss : 0.027720, loss_ce: 0.007928
2022-01-15 20:16:50,175 iteration 3634 : loss : 0.019880, loss_ce: 0.005753
2022-01-15 20:16:51,294 iteration 3635 : loss : 0.026730, loss_ce: 0.012883
2022-01-15 20:16:52,192 iteration 3636 : loss : 0.019136, loss_ce: 0.008458
2022-01-15 20:16:53,172 iteration 3637 : loss : 0.019806, loss_ce: 0.007095
2022-01-15 20:16:54,197 iteration 3638 : loss : 0.028618, loss_ce: 0.009123
 54%|███████████████▌             | 214/400 [1:06:02<54:57, 17.73s/it]2022-01-15 20:16:55,261 iteration 3639 : loss : 0.034757, loss_ce: 0.013068
2022-01-15 20:16:56,287 iteration 3640 : loss : 0.042678, loss_ce: 0.010295
2022-01-15 20:16:57,312 iteration 3641 : loss : 0.020315, loss_ce: 0.007530
2022-01-15 20:16:58,271 iteration 3642 : loss : 0.028128, loss_ce: 0.012747
2022-01-15 20:16:59,286 iteration 3643 : loss : 0.031402, loss_ce: 0.012673
2022-01-15 20:17:00,303 iteration 3644 : loss : 0.025195, loss_ce: 0.009079
2022-01-15 20:17:01,382 iteration 3645 : loss : 0.048873, loss_ce: 0.011695
2022-01-15 20:17:02,396 iteration 3646 : loss : 0.029535, loss_ce: 0.015676
2022-01-15 20:17:03,367 iteration 3647 : loss : 0.020385, loss_ce: 0.007853
2022-01-15 20:17:04,390 iteration 3648 : loss : 0.030509, loss_ce: 0.009903
2022-01-15 20:17:05,286 iteration 3649 : loss : 0.027284, loss_ce: 0.009909
2022-01-15 20:17:06,303 iteration 3650 : loss : 0.020932, loss_ce: 0.008333
2022-01-15 20:17:07,259 iteration 3651 : loss : 0.025089, loss_ce: 0.009194
2022-01-15 20:17:08,200 iteration 3652 : loss : 0.030974, loss_ce: 0.011957
2022-01-15 20:17:09,261 iteration 3653 : loss : 0.047392, loss_ce: 0.019855
2022-01-15 20:17:10,235 iteration 3654 : loss : 0.030450, loss_ce: 0.011807
2022-01-15 20:17:10,235 Training Data Eval:
2022-01-15 20:17:15,010   Average segmentation loss on training set: 0.0235
2022-01-15 20:17:15,010 Validation Data Eval:
2022-01-15 20:17:16,632   Average segmentation loss on validation set: 0.1379
2022-01-15 20:17:17,781 iteration 3655 : loss : 0.061291, loss_ce: 0.021926
 54%|██████████████▌            | 215/400 [1:06:25<1:00:03, 19.48s/it]2022-01-15 20:17:18,821 iteration 3656 : loss : 0.025631, loss_ce: 0.009068
2022-01-15 20:17:19,849 iteration 3657 : loss : 0.025456, loss_ce: 0.010715
2022-01-15 20:17:20,826 iteration 3658 : loss : 0.029498, loss_ce: 0.012557
2022-01-15 20:17:21,738 iteration 3659 : loss : 0.050567, loss_ce: 0.015477
2022-01-15 20:17:22,795 iteration 3660 : loss : 0.041030, loss_ce: 0.015102
2022-01-15 20:17:23,768 iteration 3661 : loss : 0.033883, loss_ce: 0.012818
2022-01-15 20:17:24,695 iteration 3662 : loss : 0.026550, loss_ce: 0.011917
2022-01-15 20:17:25,677 iteration 3663 : loss : 0.024731, loss_ce: 0.008546
2022-01-15 20:17:26,690 iteration 3664 : loss : 0.029545, loss_ce: 0.007731
2022-01-15 20:17:27,792 iteration 3665 : loss : 0.031113, loss_ce: 0.008690
2022-01-15 20:17:28,820 iteration 3666 : loss : 0.031237, loss_ce: 0.012060
2022-01-15 20:17:29,772 iteration 3667 : loss : 0.023576, loss_ce: 0.008507
2022-01-15 20:17:30,743 iteration 3668 : loss : 0.032167, loss_ce: 0.011023
2022-01-15 20:17:31,754 iteration 3669 : loss : 0.034931, loss_ce: 0.011618
2022-01-15 20:17:32,668 iteration 3670 : loss : 0.021852, loss_ce: 0.009490
2022-01-15 20:17:33,630 iteration 3671 : loss : 0.034986, loss_ce: 0.008669
2022-01-15 20:17:34,586 iteration 3672 : loss : 0.035292, loss_ce: 0.008909
 54%|███████████████▋             | 216/400 [1:06:42<57:17, 18.68s/it]2022-01-15 20:17:35,609 iteration 3673 : loss : 0.022800, loss_ce: 0.009381
2022-01-15 20:17:36,676 iteration 3674 : loss : 0.022300, loss_ce: 0.009559
2022-01-15 20:17:37,727 iteration 3675 : loss : 0.036439, loss_ce: 0.021262
2022-01-15 20:17:38,753 iteration 3676 : loss : 0.025690, loss_ce: 0.007700
2022-01-15 20:17:39,749 iteration 3677 : loss : 0.026706, loss_ce: 0.012874
2022-01-15 20:17:40,809 iteration 3678 : loss : 0.034038, loss_ce: 0.010428
2022-01-15 20:17:41,709 iteration 3679 : loss : 0.021566, loss_ce: 0.006982
2022-01-15 20:17:42,644 iteration 3680 : loss : 0.022317, loss_ce: 0.008418
2022-01-15 20:17:43,634 iteration 3681 : loss : 0.051679, loss_ce: 0.015916
2022-01-15 20:17:44,532 iteration 3682 : loss : 0.019193, loss_ce: 0.006015
2022-01-15 20:17:45,511 iteration 3683 : loss : 0.019621, loss_ce: 0.008753
2022-01-15 20:17:46,426 iteration 3684 : loss : 0.019992, loss_ce: 0.006371
2022-01-15 20:17:47,379 iteration 3685 : loss : 0.018596, loss_ce: 0.006659
2022-01-15 20:17:48,432 iteration 3686 : loss : 0.022084, loss_ce: 0.008844
2022-01-15 20:17:49,492 iteration 3687 : loss : 0.030154, loss_ce: 0.011336
2022-01-15 20:17:50,491 iteration 3688 : loss : 0.030933, loss_ce: 0.012077
2022-01-15 20:17:51,497 iteration 3689 : loss : 0.048732, loss_ce: 0.016803
 54%|███████████████▋             | 217/400 [1:06:59<55:21, 18.15s/it]2022-01-15 20:17:52,662 iteration 3690 : loss : 0.034072, loss_ce: 0.016920
2022-01-15 20:17:53,610 iteration 3691 : loss : 0.026622, loss_ce: 0.006270
2022-01-15 20:17:54,611 iteration 3692 : loss : 0.024822, loss_ce: 0.007062
2022-01-15 20:17:55,534 iteration 3693 : loss : 0.017408, loss_ce: 0.004701
2022-01-15 20:17:56,548 iteration 3694 : loss : 0.028389, loss_ce: 0.012066
2022-01-15 20:17:57,557 iteration 3695 : loss : 0.025547, loss_ce: 0.008924
2022-01-15 20:17:58,505 iteration 3696 : loss : 0.017297, loss_ce: 0.006875
2022-01-15 20:17:59,460 iteration 3697 : loss : 0.034123, loss_ce: 0.010168
2022-01-15 20:18:00,555 iteration 3698 : loss : 0.023567, loss_ce: 0.007323
2022-01-15 20:18:01,555 iteration 3699 : loss : 0.021005, loss_ce: 0.009999
2022-01-15 20:18:02,544 iteration 3700 : loss : 0.021775, loss_ce: 0.006727
2022-01-15 20:18:03,470 iteration 3701 : loss : 0.025543, loss_ce: 0.013349
2022-01-15 20:18:04,516 iteration 3702 : loss : 0.035741, loss_ce: 0.013294
2022-01-15 20:18:05,526 iteration 3703 : loss : 0.022519, loss_ce: 0.009150
2022-01-15 20:18:06,530 iteration 3704 : loss : 0.028944, loss_ce: 0.010838
2022-01-15 20:18:07,546 iteration 3705 : loss : 0.025796, loss_ce: 0.011922
2022-01-15 20:18:08,486 iteration 3706 : loss : 0.027681, loss_ce: 0.008758
 55%|███████████████▊             | 218/400 [1:07:16<53:59, 17.80s/it]2022-01-15 20:18:09,573 iteration 3707 : loss : 0.054551, loss_ce: 0.012394
2022-01-15 20:18:10,698 iteration 3708 : loss : 0.028369, loss_ce: 0.009340
2022-01-15 20:18:11,696 iteration 3709 : loss : 0.021686, loss_ce: 0.006994
2022-01-15 20:18:12,603 iteration 3710 : loss : 0.019414, loss_ce: 0.007509
2022-01-15 20:18:13,728 iteration 3711 : loss : 0.028805, loss_ce: 0.013170
2022-01-15 20:18:14,679 iteration 3712 : loss : 0.044747, loss_ce: 0.013460
2022-01-15 20:18:15,613 iteration 3713 : loss : 0.017842, loss_ce: 0.006269
2022-01-15 20:18:16,648 iteration 3714 : loss : 0.026632, loss_ce: 0.011537
2022-01-15 20:18:17,612 iteration 3715 : loss : 0.020147, loss_ce: 0.006954
2022-01-15 20:18:18,610 iteration 3716 : loss : 0.032549, loss_ce: 0.014204
2022-01-15 20:18:19,625 iteration 3717 : loss : 0.023320, loss_ce: 0.010964
2022-01-15 20:18:20,679 iteration 3718 : loss : 0.025549, loss_ce: 0.009238
2022-01-15 20:18:21,789 iteration 3719 : loss : 0.033519, loss_ce: 0.012542
2022-01-15 20:18:22,878 iteration 3720 : loss : 0.034829, loss_ce: 0.013462
2022-01-15 20:18:23,880 iteration 3721 : loss : 0.034095, loss_ce: 0.013532
2022-01-15 20:18:24,951 iteration 3722 : loss : 0.026483, loss_ce: 0.007732
2022-01-15 20:18:25,923 iteration 3723 : loss : 0.025828, loss_ce: 0.011256
 55%|███████████████▉             | 219/400 [1:07:33<53:21, 17.69s/it]2022-01-15 20:18:26,971 iteration 3724 : loss : 0.032231, loss_ce: 0.015178
2022-01-15 20:18:28,015 iteration 3725 : loss : 0.023850, loss_ce: 0.008838
2022-01-15 20:18:28,995 iteration 3726 : loss : 0.018488, loss_ce: 0.007957
2022-01-15 20:18:29,998 iteration 3727 : loss : 0.023179, loss_ce: 0.009009
2022-01-15 20:18:30,902 iteration 3728 : loss : 0.021192, loss_ce: 0.009798
2022-01-15 20:18:31,943 iteration 3729 : loss : 0.034256, loss_ce: 0.010210
2022-01-15 20:18:32,894 iteration 3730 : loss : 0.021694, loss_ce: 0.007965
2022-01-15 20:18:33,942 iteration 3731 : loss : 0.025016, loss_ce: 0.009002
2022-01-15 20:18:34,923 iteration 3732 : loss : 0.023124, loss_ce: 0.010653
2022-01-15 20:18:35,844 iteration 3733 : loss : 0.017342, loss_ce: 0.004957
2022-01-15 20:18:36,882 iteration 3734 : loss : 0.024465, loss_ce: 0.008870
2022-01-15 20:18:37,951 iteration 3735 : loss : 0.023665, loss_ce: 0.008032
2022-01-15 20:18:38,979 iteration 3736 : loss : 0.032024, loss_ce: 0.015230
2022-01-15 20:18:40,053 iteration 3737 : loss : 0.037865, loss_ce: 0.015223
2022-01-15 20:18:41,062 iteration 3738 : loss : 0.042565, loss_ce: 0.012068
2022-01-15 20:18:42,064 iteration 3739 : loss : 0.026487, loss_ce: 0.007411
2022-01-15 20:18:42,064 Training Data Eval:
2022-01-15 20:18:46,929   Average segmentation loss on training set: 0.0166
2022-01-15 20:18:46,929 Validation Data Eval:
2022-01-15 20:18:48,598   Average segmentation loss on validation set: 0.0794
2022-01-15 20:18:49,583 iteration 3740 : loss : 0.024291, loss_ce: 0.007475
 55%|███████████████▉             | 220/400 [1:07:57<58:27, 19.48s/it]2022-01-15 20:18:50,687 iteration 3741 : loss : 0.034180, loss_ce: 0.020122
2022-01-15 20:18:51,692 iteration 3742 : loss : 0.024811, loss_ce: 0.009850
2022-01-15 20:18:52,682 iteration 3743 : loss : 0.021202, loss_ce: 0.006097
2022-01-15 20:18:53,716 iteration 3744 : loss : 0.020426, loss_ce: 0.006730
2022-01-15 20:18:54,804 iteration 3745 : loss : 0.026814, loss_ce: 0.015240
2022-01-15 20:18:55,776 iteration 3746 : loss : 0.029542, loss_ce: 0.007724
2022-01-15 20:18:56,819 iteration 3747 : loss : 0.030482, loss_ce: 0.012778
2022-01-15 20:18:57,885 iteration 3748 : loss : 0.046532, loss_ce: 0.014905
2022-01-15 20:18:58,898 iteration 3749 : loss : 0.024506, loss_ce: 0.007686
2022-01-15 20:19:00,019 iteration 3750 : loss : 0.034352, loss_ce: 0.011921
2022-01-15 20:19:01,004 iteration 3751 : loss : 0.022013, loss_ce: 0.009245
2022-01-15 20:19:01,969 iteration 3752 : loss : 0.024186, loss_ce: 0.009519
2022-01-15 20:19:02,957 iteration 3753 : loss : 0.024477, loss_ce: 0.007503
2022-01-15 20:19:03,896 iteration 3754 : loss : 0.019981, loss_ce: 0.009798
2022-01-15 20:19:04,930 iteration 3755 : loss : 0.024059, loss_ce: 0.008662
2022-01-15 20:19:05,912 iteration 3756 : loss : 0.022693, loss_ce: 0.007968
2022-01-15 20:19:06,922 iteration 3757 : loss : 0.029757, loss_ce: 0.011231
 55%|████████████████             | 221/400 [1:08:14<56:12, 18.84s/it]2022-01-15 20:19:08,043 iteration 3758 : loss : 0.027100, loss_ce: 0.011124
2022-01-15 20:19:09,090 iteration 3759 : loss : 0.025625, loss_ce: 0.010333
2022-01-15 20:19:10,122 iteration 3760 : loss : 0.045929, loss_ce: 0.019258
2022-01-15 20:19:11,129 iteration 3761 : loss : 0.020791, loss_ce: 0.009548
2022-01-15 20:19:12,180 iteration 3762 : loss : 0.038421, loss_ce: 0.017331
2022-01-15 20:19:13,235 iteration 3763 : loss : 0.033569, loss_ce: 0.015698
2022-01-15 20:19:14,190 iteration 3764 : loss : 0.033879, loss_ce: 0.008598
2022-01-15 20:19:15,099 iteration 3765 : loss : 0.027725, loss_ce: 0.010475
2022-01-15 20:19:16,052 iteration 3766 : loss : 0.017561, loss_ce: 0.005876
2022-01-15 20:19:17,051 iteration 3767 : loss : 0.026789, loss_ce: 0.009802
2022-01-15 20:19:18,121 iteration 3768 : loss : 0.025059, loss_ce: 0.009674
2022-01-15 20:19:19,119 iteration 3769 : loss : 0.024761, loss_ce: 0.008675
2022-01-15 20:19:20,165 iteration 3770 : loss : 0.037458, loss_ce: 0.016663
2022-01-15 20:19:21,182 iteration 3771 : loss : 0.038562, loss_ce: 0.020015
2022-01-15 20:19:22,219 iteration 3772 : loss : 0.041676, loss_ce: 0.009042
2022-01-15 20:19:23,220 iteration 3773 : loss : 0.023960, loss_ce: 0.007836
2022-01-15 20:19:24,226 iteration 3774 : loss : 0.026607, loss_ce: 0.012272
 56%|████████████████             | 222/400 [1:08:32<54:31, 18.38s/it]2022-01-15 20:19:25,320 iteration 3775 : loss : 0.029599, loss_ce: 0.011344
2022-01-15 20:19:26,301 iteration 3776 : loss : 0.017325, loss_ce: 0.006420
2022-01-15 20:19:27,295 iteration 3777 : loss : 0.031107, loss_ce: 0.008922
2022-01-15 20:19:28,345 iteration 3778 : loss : 0.045386, loss_ce: 0.021656
2022-01-15 20:19:29,288 iteration 3779 : loss : 0.026655, loss_ce: 0.010255
2022-01-15 20:19:30,346 iteration 3780 : loss : 0.030347, loss_ce: 0.015493
2022-01-15 20:19:31,374 iteration 3781 : loss : 0.031666, loss_ce: 0.011320
2022-01-15 20:19:32,415 iteration 3782 : loss : 0.032712, loss_ce: 0.012585
2022-01-15 20:19:33,447 iteration 3783 : loss : 0.024003, loss_ce: 0.012514
2022-01-15 20:19:34,371 iteration 3784 : loss : 0.021265, loss_ce: 0.005515
2022-01-15 20:19:35,358 iteration 3785 : loss : 0.056712, loss_ce: 0.015882
2022-01-15 20:19:36,345 iteration 3786 : loss : 0.033428, loss_ce: 0.014773
2022-01-15 20:19:37,285 iteration 3787 : loss : 0.042757, loss_ce: 0.027019
2022-01-15 20:19:38,305 iteration 3788 : loss : 0.029685, loss_ce: 0.009458
2022-01-15 20:19:39,306 iteration 3789 : loss : 0.026707, loss_ce: 0.010766
2022-01-15 20:19:40,264 iteration 3790 : loss : 0.033059, loss_ce: 0.011927
2022-01-15 20:19:41,313 iteration 3791 : loss : 0.021700, loss_ce: 0.008727
 56%|████████████████▏            | 223/400 [1:08:49<53:04, 17.99s/it]2022-01-15 20:19:42,307 iteration 3792 : loss : 0.029315, loss_ce: 0.010738
2022-01-15 20:19:43,214 iteration 3793 : loss : 0.024020, loss_ce: 0.006313
2022-01-15 20:19:44,178 iteration 3794 : loss : 0.024197, loss_ce: 0.011078
2022-01-15 20:19:45,137 iteration 3795 : loss : 0.021262, loss_ce: 0.007254
2022-01-15 20:19:46,197 iteration 3796 : loss : 0.041047, loss_ce: 0.014213
2022-01-15 20:19:47,213 iteration 3797 : loss : 0.025572, loss_ce: 0.008715
2022-01-15 20:19:48,143 iteration 3798 : loss : 0.019417, loss_ce: 0.006857
2022-01-15 20:19:49,221 iteration 3799 : loss : 0.031087, loss_ce: 0.009333
2022-01-15 20:19:50,356 iteration 3800 : loss : 0.045780, loss_ce: 0.022921
2022-01-15 20:19:51,427 iteration 3801 : loss : 0.043453, loss_ce: 0.012198
2022-01-15 20:19:52,467 iteration 3802 : loss : 0.029480, loss_ce: 0.012679
2022-01-15 20:19:53,437 iteration 3803 : loss : 0.020738, loss_ce: 0.007435
2022-01-15 20:19:54,421 iteration 3804 : loss : 0.023346, loss_ce: 0.008330
2022-01-15 20:19:55,408 iteration 3805 : loss : 0.025472, loss_ce: 0.009605
2022-01-15 20:19:56,312 iteration 3806 : loss : 0.020947, loss_ce: 0.009383
2022-01-15 20:19:57,329 iteration 3807 : loss : 0.026078, loss_ce: 0.008785
2022-01-15 20:19:58,294 iteration 3808 : loss : 0.029908, loss_ce: 0.012311
 56%|████████████████▏            | 224/400 [1:09:06<51:53, 17.69s/it]2022-01-15 20:19:59,363 iteration 3809 : loss : 0.032782, loss_ce: 0.011985
2022-01-15 20:20:00,391 iteration 3810 : loss : 0.026383, loss_ce: 0.008949
2022-01-15 20:20:01,349 iteration 3811 : loss : 0.020708, loss_ce: 0.007365
2022-01-15 20:20:02,355 iteration 3812 : loss : 0.021867, loss_ce: 0.007407
2022-01-15 20:20:03,252 iteration 3813 : loss : 0.021797, loss_ce: 0.009553
2022-01-15 20:20:04,303 iteration 3814 : loss : 0.026758, loss_ce: 0.012487
2022-01-15 20:20:05,388 iteration 3815 : loss : 0.025386, loss_ce: 0.009697
2022-01-15 20:20:06,319 iteration 3816 : loss : 0.017798, loss_ce: 0.006421
2022-01-15 20:20:07,189 iteration 3817 : loss : 0.021120, loss_ce: 0.007518
2022-01-15 20:20:08,145 iteration 3818 : loss : 0.027881, loss_ce: 0.008136
2022-01-15 20:20:09,205 iteration 3819 : loss : 0.037103, loss_ce: 0.014000
2022-01-15 20:20:10,121 iteration 3820 : loss : 0.017662, loss_ce: 0.007843
2022-01-15 20:20:11,196 iteration 3821 : loss : 0.026556, loss_ce: 0.013982
2022-01-15 20:20:12,178 iteration 3822 : loss : 0.028518, loss_ce: 0.008792
2022-01-15 20:20:13,139 iteration 3823 : loss : 0.027758, loss_ce: 0.009782
2022-01-15 20:20:14,174 iteration 3824 : loss : 0.040198, loss_ce: 0.015338
2022-01-15 20:20:14,174 Training Data Eval:
2022-01-15 20:20:18,951   Average segmentation loss on training set: 0.0169
2022-01-15 20:20:18,952 Validation Data Eval:
2022-01-15 20:20:20,581   Average segmentation loss on validation set: 0.0957
2022-01-15 20:20:21,505 iteration 3825 : loss : 0.023349, loss_ce: 0.008176
 56%|████████████████▎            | 225/400 [1:09:29<56:25, 19.35s/it]2022-01-15 20:20:22,662 iteration 3826 : loss : 0.033210, loss_ce: 0.014405
2022-01-15 20:20:23,734 iteration 3827 : loss : 0.024363, loss_ce: 0.010616
2022-01-15 20:20:24,667 iteration 3828 : loss : 0.020158, loss_ce: 0.010267
2022-01-15 20:20:25,602 iteration 3829 : loss : 0.017570, loss_ce: 0.006399
2022-01-15 20:20:26,671 iteration 3830 : loss : 0.030145, loss_ce: 0.007991
2022-01-15 20:20:27,714 iteration 3831 : loss : 0.028253, loss_ce: 0.011814
2022-01-15 20:20:28,730 iteration 3832 : loss : 0.027076, loss_ce: 0.013331
2022-01-15 20:20:29,750 iteration 3833 : loss : 0.036305, loss_ce: 0.011140
2022-01-15 20:20:30,685 iteration 3834 : loss : 0.026367, loss_ce: 0.008919
2022-01-15 20:20:31,704 iteration 3835 : loss : 0.047299, loss_ce: 0.011739
2022-01-15 20:20:32,628 iteration 3836 : loss : 0.019564, loss_ce: 0.008259
2022-01-15 20:20:33,541 iteration 3837 : loss : 0.018539, loss_ce: 0.007488
2022-01-15 20:20:34,601 iteration 3838 : loss : 0.027077, loss_ce: 0.011508
2022-01-15 20:20:35,555 iteration 3839 : loss : 0.029283, loss_ce: 0.008130
2022-01-15 20:20:36,572 iteration 3840 : loss : 0.023321, loss_ce: 0.009028
2022-01-15 20:20:37,487 iteration 3841 : loss : 0.020384, loss_ce: 0.007824
2022-01-15 20:20:38,525 iteration 3842 : loss : 0.050331, loss_ce: 0.011945
 56%|████████████████▍            | 226/400 [1:09:46<54:04, 18.65s/it]2022-01-15 20:20:39,583 iteration 3843 : loss : 0.030698, loss_ce: 0.009077
2022-01-15 20:20:40,624 iteration 3844 : loss : 0.041582, loss_ce: 0.017915
2022-01-15 20:20:41,509 iteration 3845 : loss : 0.030620, loss_ce: 0.010064
2022-01-15 20:20:42,484 iteration 3846 : loss : 0.028335, loss_ce: 0.011405
2022-01-15 20:20:43,600 iteration 3847 : loss : 0.034533, loss_ce: 0.011271
2022-01-15 20:20:44,566 iteration 3848 : loss : 0.034235, loss_ce: 0.011943
2022-01-15 20:20:45,525 iteration 3849 : loss : 0.026524, loss_ce: 0.008893
2022-01-15 20:20:46,590 iteration 3850 : loss : 0.051782, loss_ce: 0.019244
2022-01-15 20:20:47,676 iteration 3851 : loss : 0.059185, loss_ce: 0.016702
2022-01-15 20:20:48,708 iteration 3852 : loss : 0.031102, loss_ce: 0.011068
2022-01-15 20:20:49,688 iteration 3853 : loss : 0.032210, loss_ce: 0.013527
2022-01-15 20:20:50,579 iteration 3854 : loss : 0.024172, loss_ce: 0.009951
2022-01-15 20:20:51,566 iteration 3855 : loss : 0.032005, loss_ce: 0.007748
2022-01-15 20:20:52,659 iteration 3856 : loss : 0.044472, loss_ce: 0.025842
2022-01-15 20:20:53,610 iteration 3857 : loss : 0.039389, loss_ce: 0.012524
2022-01-15 20:20:54,571 iteration 3858 : loss : 0.031430, loss_ce: 0.014678
2022-01-15 20:20:55,511 iteration 3859 : loss : 0.027776, loss_ce: 0.012911
 57%|████████████████▍            | 227/400 [1:10:03<52:19, 18.15s/it]2022-01-15 20:20:56,514 iteration 3860 : loss : 0.019052, loss_ce: 0.009477
2022-01-15 20:20:57,470 iteration 3861 : loss : 0.025697, loss_ce: 0.010581
2022-01-15 20:20:58,412 iteration 3862 : loss : 0.025570, loss_ce: 0.008098
2022-01-15 20:20:59,421 iteration 3863 : loss : 0.031477, loss_ce: 0.014957
2022-01-15 20:21:00,313 iteration 3864 : loss : 0.024290, loss_ce: 0.010529
2022-01-15 20:21:01,329 iteration 3865 : loss : 0.029983, loss_ce: 0.012809
2022-01-15 20:21:02,313 iteration 3866 : loss : 0.019768, loss_ce: 0.008992
2022-01-15 20:21:03,343 iteration 3867 : loss : 0.036797, loss_ce: 0.016123
2022-01-15 20:21:04,258 iteration 3868 : loss : 0.023642, loss_ce: 0.008906
2022-01-15 20:21:05,343 iteration 3869 : loss : 0.029056, loss_ce: 0.007189
2022-01-15 20:21:06,319 iteration 3870 : loss : 0.036544, loss_ce: 0.014171
2022-01-15 20:21:07,373 iteration 3871 : loss : 0.026434, loss_ce: 0.009496
2022-01-15 20:21:08,366 iteration 3872 : loss : 0.021054, loss_ce: 0.007316
2022-01-15 20:21:09,347 iteration 3873 : loss : 0.028327, loss_ce: 0.008415
2022-01-15 20:21:10,409 iteration 3874 : loss : 0.023551, loss_ce: 0.007360
2022-01-15 20:21:11,431 iteration 3875 : loss : 0.027983, loss_ce: 0.008044
2022-01-15 20:21:12,516 iteration 3876 : loss : 0.032232, loss_ce: 0.012384
 57%|████████████████▌            | 228/400 [1:10:20<51:02, 17.81s/it]2022-01-15 20:21:13,523 iteration 3877 : loss : 0.026861, loss_ce: 0.011970
2022-01-15 20:21:14,537 iteration 3878 : loss : 0.021943, loss_ce: 0.007655
2022-01-15 20:21:15,597 iteration 3879 : loss : 0.024172, loss_ce: 0.013510
2022-01-15 20:21:16,583 iteration 3880 : loss : 0.022348, loss_ce: 0.007693
2022-01-15 20:21:17,592 iteration 3881 : loss : 0.036289, loss_ce: 0.011773
2022-01-15 20:21:18,634 iteration 3882 : loss : 0.027261, loss_ce: 0.011919
2022-01-15 20:21:19,631 iteration 3883 : loss : 0.024672, loss_ce: 0.008680
2022-01-15 20:21:20,620 iteration 3884 : loss : 0.018069, loss_ce: 0.006224
2022-01-15 20:21:21,554 iteration 3885 : loss : 0.020852, loss_ce: 0.006687
2022-01-15 20:21:22,580 iteration 3886 : loss : 0.023400, loss_ce: 0.009532
2022-01-15 20:21:23,576 iteration 3887 : loss : 0.058776, loss_ce: 0.021529
2022-01-15 20:21:24,630 iteration 3888 : loss : 0.028816, loss_ce: 0.015261
2022-01-15 20:21:25,567 iteration 3889 : loss : 0.027729, loss_ce: 0.007502
2022-01-15 20:21:26,519 iteration 3890 : loss : 0.020028, loss_ce: 0.007379
2022-01-15 20:21:27,538 iteration 3891 : loss : 0.025384, loss_ce: 0.011605
2022-01-15 20:21:28,530 iteration 3892 : loss : 0.026451, loss_ce: 0.008833
2022-01-15 20:21:29,475 iteration 3893 : loss : 0.031183, loss_ce: 0.008708
 57%|████████████████▌            | 229/400 [1:10:37<50:01, 17.55s/it]2022-01-15 20:21:30,516 iteration 3894 : loss : 0.027769, loss_ce: 0.010221
2022-01-15 20:21:31,542 iteration 3895 : loss : 0.025530, loss_ce: 0.011759
2022-01-15 20:21:32,467 iteration 3896 : loss : 0.022921, loss_ce: 0.007127
2022-01-15 20:21:33,520 iteration 3897 : loss : 0.020808, loss_ce: 0.006583
2022-01-15 20:21:34,539 iteration 3898 : loss : 0.029797, loss_ce: 0.009302
2022-01-15 20:21:35,547 iteration 3899 : loss : 0.018261, loss_ce: 0.006212
2022-01-15 20:21:36,566 iteration 3900 : loss : 0.021744, loss_ce: 0.009429
2022-01-15 20:21:37,470 iteration 3901 : loss : 0.020488, loss_ce: 0.010526
2022-01-15 20:21:38,480 iteration 3902 : loss : 0.017828, loss_ce: 0.006013
2022-01-15 20:21:39,432 iteration 3903 : loss : 0.021865, loss_ce: 0.006654
2022-01-15 20:21:40,461 iteration 3904 : loss : 0.019233, loss_ce: 0.007376
2022-01-15 20:21:41,476 iteration 3905 : loss : 0.030253, loss_ce: 0.016345
2022-01-15 20:21:42,488 iteration 3906 : loss : 0.031849, loss_ce: 0.011830
2022-01-15 20:21:43,495 iteration 3907 : loss : 0.025308, loss_ce: 0.007329
2022-01-15 20:21:44,419 iteration 3908 : loss : 0.025488, loss_ce: 0.008216
2022-01-15 20:21:45,362 iteration 3909 : loss : 0.025326, loss_ce: 0.010379
2022-01-15 20:21:45,362 Training Data Eval:
2022-01-15 20:21:50,233   Average segmentation loss on training set: 0.0162
2022-01-15 20:21:50,233 Validation Data Eval:
2022-01-15 20:21:51,871   Average segmentation loss on validation set: 0.1186
2022-01-15 20:21:52,885 iteration 3910 : loss : 0.031538, loss_ce: 0.013444
 57%|████████████████▋            | 230/400 [1:11:00<54:42, 19.31s/it]2022-01-15 20:21:53,862 iteration 3911 : loss : 0.022084, loss_ce: 0.009968
2022-01-15 20:21:54,842 iteration 3912 : loss : 0.028115, loss_ce: 0.008981
2022-01-15 20:21:55,858 iteration 3913 : loss : 0.031216, loss_ce: 0.015603
2022-01-15 20:21:56,763 iteration 3914 : loss : 0.017427, loss_ce: 0.007374
2022-01-15 20:21:57,793 iteration 3915 : loss : 0.034415, loss_ce: 0.010417
2022-01-15 20:21:58,807 iteration 3916 : loss : 0.021406, loss_ce: 0.007652
2022-01-15 20:21:59,837 iteration 3917 : loss : 0.019346, loss_ce: 0.005949
2022-01-15 20:22:00,822 iteration 3918 : loss : 0.023293, loss_ce: 0.007395
2022-01-15 20:22:01,802 iteration 3919 : loss : 0.026315, loss_ce: 0.008458
2022-01-15 20:22:02,816 iteration 3920 : loss : 0.034560, loss_ce: 0.006235
2022-01-15 20:22:03,793 iteration 3921 : loss : 0.026938, loss_ce: 0.007693
2022-01-15 20:22:04,814 iteration 3922 : loss : 0.038086, loss_ce: 0.012038
2022-01-15 20:22:05,907 iteration 3923 : loss : 0.040248, loss_ce: 0.017386
2022-01-15 20:22:06,858 iteration 3924 : loss : 0.024664, loss_ce: 0.007891
2022-01-15 20:22:07,760 iteration 3925 : loss : 0.030262, loss_ce: 0.014681
2022-01-15 20:22:08,894 iteration 3926 : loss : 0.041613, loss_ce: 0.015993
2022-01-15 20:22:09,901 iteration 3927 : loss : 0.030440, loss_ce: 0.013484
 58%|████████████████▋            | 231/400 [1:11:17<52:26, 18.62s/it]2022-01-15 20:22:10,923 iteration 3928 : loss : 0.023806, loss_ce: 0.008140
2022-01-15 20:22:11,852 iteration 3929 : loss : 0.026487, loss_ce: 0.015272
2022-01-15 20:22:12,828 iteration 3930 : loss : 0.024537, loss_ce: 0.007381
2022-01-15 20:22:13,729 iteration 3931 : loss : 0.028849, loss_ce: 0.007044
2022-01-15 20:22:14,725 iteration 3932 : loss : 0.027008, loss_ce: 0.009277
2022-01-15 20:22:15,682 iteration 3933 : loss : 0.024554, loss_ce: 0.011070
2022-01-15 20:22:16,681 iteration 3934 : loss : 0.039340, loss_ce: 0.013950
2022-01-15 20:22:17,649 iteration 3935 : loss : 0.033718, loss_ce: 0.012383
2022-01-15 20:22:18,579 iteration 3936 : loss : 0.025988, loss_ce: 0.008857
2022-01-15 20:22:19,563 iteration 3937 : loss : 0.027662, loss_ce: 0.007776
2022-01-15 20:22:20,538 iteration 3938 : loss : 0.028415, loss_ce: 0.007068
2022-01-15 20:22:21,576 iteration 3939 : loss : 0.043114, loss_ce: 0.009236
2022-01-15 20:22:22,542 iteration 3940 : loss : 0.023828, loss_ce: 0.010912
2022-01-15 20:22:23,506 iteration 3941 : loss : 0.018651, loss_ce: 0.005088
2022-01-15 20:22:24,438 iteration 3942 : loss : 0.028681, loss_ce: 0.015367
2022-01-15 20:22:25,359 iteration 3943 : loss : 0.025052, loss_ce: 0.010559
2022-01-15 20:22:26,312 iteration 3944 : loss : 0.023886, loss_ce: 0.007913
 58%|████████████████▊            | 232/400 [1:11:34<50:17, 17.96s/it]2022-01-15 20:22:27,407 iteration 3945 : loss : 0.022394, loss_ce: 0.007750
2022-01-15 20:22:28,353 iteration 3946 : loss : 0.019876, loss_ce: 0.008008
2022-01-15 20:22:29,285 iteration 3947 : loss : 0.024695, loss_ce: 0.010130
2022-01-15 20:22:30,312 iteration 3948 : loss : 0.038132, loss_ce: 0.015795
2022-01-15 20:22:31,357 iteration 3949 : loss : 0.036486, loss_ce: 0.010220
2022-01-15 20:22:32,303 iteration 3950 : loss : 0.018483, loss_ce: 0.008643
2022-01-15 20:22:33,219 iteration 3951 : loss : 0.022863, loss_ce: 0.005077
2022-01-15 20:22:34,299 iteration 3952 : loss : 0.022459, loss_ce: 0.010292
2022-01-15 20:22:35,279 iteration 3953 : loss : 0.018412, loss_ce: 0.008180
2022-01-15 20:22:36,199 iteration 3954 : loss : 0.018403, loss_ce: 0.006556
2022-01-15 20:22:37,209 iteration 3955 : loss : 0.023045, loss_ce: 0.009598
2022-01-15 20:22:38,238 iteration 3956 : loss : 0.030931, loss_ce: 0.017161
2022-01-15 20:22:39,282 iteration 3957 : loss : 0.039465, loss_ce: 0.011311
2022-01-15 20:22:40,329 iteration 3958 : loss : 0.028882, loss_ce: 0.012489
2022-01-15 20:22:41,220 iteration 3959 : loss : 0.024126, loss_ce: 0.006014
2022-01-15 20:22:42,248 iteration 3960 : loss : 0.034151, loss_ce: 0.011885
2022-01-15 20:22:43,203 iteration 3961 : loss : 0.024469, loss_ce: 0.006583
 58%|████████████████▉            | 233/400 [1:11:51<49:05, 17.64s/it]2022-01-15 20:22:44,269 iteration 3962 : loss : 0.047218, loss_ce: 0.025601
2022-01-15 20:22:45,324 iteration 3963 : loss : 0.035955, loss_ce: 0.014330
2022-01-15 20:22:46,271 iteration 3964 : loss : 0.023586, loss_ce: 0.008103
2022-01-15 20:22:47,290 iteration 3965 : loss : 0.017844, loss_ce: 0.007639
2022-01-15 20:22:48,387 iteration 3966 : loss : 0.031069, loss_ce: 0.014233
2022-01-15 20:22:49,386 iteration 3967 : loss : 0.034644, loss_ce: 0.008371
2022-01-15 20:22:50,376 iteration 3968 : loss : 0.026992, loss_ce: 0.011447
2022-01-15 20:22:51,335 iteration 3969 : loss : 0.019787, loss_ce: 0.006519
2022-01-15 20:22:52,348 iteration 3970 : loss : 0.034815, loss_ce: 0.009738
2022-01-15 20:22:53,362 iteration 3971 : loss : 0.024898, loss_ce: 0.007155
2022-01-15 20:22:54,387 iteration 3972 : loss : 0.021528, loss_ce: 0.007940
2022-01-15 20:22:55,478 iteration 3973 : loss : 0.031187, loss_ce: 0.012051
2022-01-15 20:22:56,547 iteration 3974 : loss : 0.035593, loss_ce: 0.017691
2022-01-15 20:22:57,540 iteration 3975 : loss : 0.023089, loss_ce: 0.007403
2022-01-15 20:22:58,526 iteration 3976 : loss : 0.021282, loss_ce: 0.007693
2022-01-15 20:22:59,563 iteration 3977 : loss : 0.029418, loss_ce: 0.013075
2022-01-15 20:23:00,582 iteration 3978 : loss : 0.023758, loss_ce: 0.009411
 58%|████████████████▉            | 234/400 [1:12:08<48:34, 17.56s/it]2022-01-15 20:23:01,730 iteration 3979 : loss : 0.024237, loss_ce: 0.010566
2022-01-15 20:23:02,640 iteration 3980 : loss : 0.030492, loss_ce: 0.011045
2022-01-15 20:23:03,633 iteration 3981 : loss : 0.030620, loss_ce: 0.009125
2022-01-15 20:23:04,646 iteration 3982 : loss : 0.029236, loss_ce: 0.013567
2022-01-15 20:23:05,658 iteration 3983 : loss : 0.040835, loss_ce: 0.015391
2022-01-15 20:23:06,688 iteration 3984 : loss : 0.026371, loss_ce: 0.011986
2022-01-15 20:23:07,724 iteration 3985 : loss : 0.021473, loss_ce: 0.006999
2022-01-15 20:23:08,774 iteration 3986 : loss : 0.039799, loss_ce: 0.014646
2022-01-15 20:23:09,712 iteration 3987 : loss : 0.036351, loss_ce: 0.019242
2022-01-15 20:23:10,683 iteration 3988 : loss : 0.032398, loss_ce: 0.012387
2022-01-15 20:23:11,689 iteration 3989 : loss : 0.021811, loss_ce: 0.008676
2022-01-15 20:23:12,691 iteration 3990 : loss : 0.028335, loss_ce: 0.011997
2022-01-15 20:23:13,714 iteration 3991 : loss : 0.027021, loss_ce: 0.012505
2022-01-15 20:23:14,736 iteration 3992 : loss : 0.023145, loss_ce: 0.008614
2022-01-15 20:23:15,726 iteration 3993 : loss : 0.023830, loss_ce: 0.009923
2022-01-15 20:23:16,760 iteration 3994 : loss : 0.017769, loss_ce: 0.005895
2022-01-15 20:23:16,760 Training Data Eval:
2022-01-15 20:23:21,539   Average segmentation loss on training set: 0.0156
2022-01-15 20:23:21,540 Validation Data Eval:
2022-01-15 20:23:23,153   Average segmentation loss on validation set: 0.0899
2022-01-15 20:23:24,266 iteration 3995 : loss : 0.025831, loss_ce: 0.009349
 59%|█████████████████            | 235/400 [1:12:32<53:19, 19.39s/it]2022-01-15 20:23:25,298 iteration 3996 : loss : 0.020549, loss_ce: 0.009584
2022-01-15 20:23:26,233 iteration 3997 : loss : 0.023491, loss_ce: 0.011264
2022-01-15 20:23:27,150 iteration 3998 : loss : 0.030178, loss_ce: 0.008594
2022-01-15 20:23:28,216 iteration 3999 : loss : 0.029322, loss_ce: 0.008612
2022-01-15 20:23:29,216 iteration 4000 : loss : 0.018834, loss_ce: 0.007647
2022-01-15 20:23:30,254 iteration 4001 : loss : 0.024217, loss_ce: 0.011411
2022-01-15 20:23:31,162 iteration 4002 : loss : 0.023885, loss_ce: 0.007765
2022-01-15 20:23:32,218 iteration 4003 : loss : 0.040480, loss_ce: 0.013554
2022-01-15 20:23:33,260 iteration 4004 : loss : 0.026842, loss_ce: 0.011638
2022-01-15 20:23:34,270 iteration 4005 : loss : 0.020325, loss_ce: 0.007566
2022-01-15 20:23:35,204 iteration 4006 : loss : 0.028072, loss_ce: 0.009587
2022-01-15 20:23:36,194 iteration 4007 : loss : 0.023569, loss_ce: 0.007387
2022-01-15 20:23:37,170 iteration 4008 : loss : 0.027575, loss_ce: 0.011775
2022-01-15 20:23:38,172 iteration 4009 : loss : 0.014155, loss_ce: 0.004524
2022-01-15 20:23:39,191 iteration 4010 : loss : 0.037084, loss_ce: 0.016098
2022-01-15 20:23:40,175 iteration 4011 : loss : 0.023903, loss_ce: 0.008478
2022-01-15 20:23:41,186 iteration 4012 : loss : 0.023103, loss_ce: 0.009285
 59%|█████████████████            | 236/400 [1:12:49<50:59, 18.66s/it]2022-01-15 20:23:42,118 iteration 4013 : loss : 0.017266, loss_ce: 0.008347
2022-01-15 20:23:43,169 iteration 4014 : loss : 0.028015, loss_ce: 0.010227
2022-01-15 20:23:44,105 iteration 4015 : loss : 0.022281, loss_ce: 0.009884
2022-01-15 20:23:45,166 iteration 4016 : loss : 0.021207, loss_ce: 0.008038
2022-01-15 20:23:46,180 iteration 4017 : loss : 0.042290, loss_ce: 0.010848
2022-01-15 20:23:47,092 iteration 4018 : loss : 0.031305, loss_ce: 0.012495
2022-01-15 20:23:48,096 iteration 4019 : loss : 0.034049, loss_ce: 0.012005
2022-01-15 20:23:49,065 iteration 4020 : loss : 0.030863, loss_ce: 0.008487
2022-01-15 20:23:50,084 iteration 4021 : loss : 0.043433, loss_ce: 0.012352
2022-01-15 20:23:51,168 iteration 4022 : loss : 0.031899, loss_ce: 0.009700
2022-01-15 20:23:52,119 iteration 4023 : loss : 0.019237, loss_ce: 0.008422
2022-01-15 20:23:53,168 iteration 4024 : loss : 0.023674, loss_ce: 0.006622
2022-01-15 20:23:54,222 iteration 4025 : loss : 0.036580, loss_ce: 0.011059
2022-01-15 20:23:55,321 iteration 4026 : loss : 0.026604, loss_ce: 0.007850
2022-01-15 20:23:56,241 iteration 4027 : loss : 0.024627, loss_ce: 0.006885
2022-01-15 20:23:57,385 iteration 4028 : loss : 0.024405, loss_ce: 0.012456
2022-01-15 20:23:58,491 iteration 4029 : loss : 0.042469, loss_ce: 0.020914
 59%|█████████████████▏           | 237/400 [1:13:06<49:35, 18.25s/it]2022-01-15 20:23:59,531 iteration 4030 : loss : 0.024567, loss_ce: 0.008737
2022-01-15 20:24:00,511 iteration 4031 : loss : 0.035346, loss_ce: 0.016135
2022-01-15 20:24:01,428 iteration 4032 : loss : 0.019418, loss_ce: 0.006227
2022-01-15 20:24:02,380 iteration 4033 : loss : 0.023688, loss_ce: 0.009229
2022-01-15 20:24:03,419 iteration 4034 : loss : 0.027048, loss_ce: 0.012892
2022-01-15 20:24:04,457 iteration 4035 : loss : 0.038757, loss_ce: 0.012711
2022-01-15 20:24:05,472 iteration 4036 : loss : 0.026677, loss_ce: 0.011406
2022-01-15 20:24:06,423 iteration 4037 : loss : 0.020237, loss_ce: 0.010323
2022-01-15 20:24:07,409 iteration 4038 : loss : 0.023740, loss_ce: 0.009665
2022-01-15 20:24:08,413 iteration 4039 : loss : 0.032923, loss_ce: 0.009872
2022-01-15 20:24:09,384 iteration 4040 : loss : 0.035580, loss_ce: 0.012006
2022-01-15 20:24:10,423 iteration 4041 : loss : 0.028038, loss_ce: 0.010891
2022-01-15 20:24:11,447 iteration 4042 : loss : 0.033493, loss_ce: 0.012496
2022-01-15 20:24:12,445 iteration 4043 : loss : 0.025988, loss_ce: 0.012341
2022-01-15 20:24:13,431 iteration 4044 : loss : 0.025687, loss_ce: 0.011172
2022-01-15 20:24:14,438 iteration 4045 : loss : 0.024738, loss_ce: 0.006788
2022-01-15 20:24:15,483 iteration 4046 : loss : 0.037064, loss_ce: 0.013185
 60%|█████████████████▎           | 238/400 [1:13:23<48:14, 17.87s/it]2022-01-15 20:24:16,555 iteration 4047 : loss : 0.026021, loss_ce: 0.010268
2022-01-15 20:24:17,525 iteration 4048 : loss : 0.029760, loss_ce: 0.011069
2022-01-15 20:24:18,507 iteration 4049 : loss : 0.019364, loss_ce: 0.005761
2022-01-15 20:24:19,432 iteration 4050 : loss : 0.026106, loss_ce: 0.009183
2022-01-15 20:24:20,422 iteration 4051 : loss : 0.018818, loss_ce: 0.007272
2022-01-15 20:24:21,363 iteration 4052 : loss : 0.018557, loss_ce: 0.007017
2022-01-15 20:24:22,374 iteration 4053 : loss : 0.048551, loss_ce: 0.008142
2022-01-15 20:24:23,401 iteration 4054 : loss : 0.024878, loss_ce: 0.009477
2022-01-15 20:24:24,396 iteration 4055 : loss : 0.024137, loss_ce: 0.011092
2022-01-15 20:24:25,376 iteration 4056 : loss : 0.025229, loss_ce: 0.011323
2022-01-15 20:24:26,288 iteration 4057 : loss : 0.019172, loss_ce: 0.005954
2022-01-15 20:24:27,221 iteration 4058 : loss : 0.017000, loss_ce: 0.007179
2022-01-15 20:24:28,232 iteration 4059 : loss : 0.028331, loss_ce: 0.012331
2022-01-15 20:24:29,170 iteration 4060 : loss : 0.023811, loss_ce: 0.009644
2022-01-15 20:24:30,058 iteration 4061 : loss : 0.021391, loss_ce: 0.009553
2022-01-15 20:24:31,021 iteration 4062 : loss : 0.018942, loss_ce: 0.008285
2022-01-15 20:24:32,059 iteration 4063 : loss : 0.022546, loss_ce: 0.008671
 60%|█████████████████▎           | 239/400 [1:13:39<46:54, 17.48s/it]2022-01-15 20:24:33,096 iteration 4064 : loss : 0.020039, loss_ce: 0.007282
2022-01-15 20:24:34,035 iteration 4065 : loss : 0.026812, loss_ce: 0.006625
2022-01-15 20:24:35,009 iteration 4066 : loss : 0.018453, loss_ce: 0.006219
2022-01-15 20:24:35,981 iteration 4067 : loss : 0.022426, loss_ce: 0.008044
2022-01-15 20:24:36,999 iteration 4068 : loss : 0.032880, loss_ce: 0.012194
2022-01-15 20:24:38,022 iteration 4069 : loss : 0.034966, loss_ce: 0.016435
2022-01-15 20:24:38,972 iteration 4070 : loss : 0.021997, loss_ce: 0.006568
2022-01-15 20:24:39,977 iteration 4071 : loss : 0.020370, loss_ce: 0.007682
2022-01-15 20:24:40,985 iteration 4072 : loss : 0.026582, loss_ce: 0.010856
2022-01-15 20:24:42,019 iteration 4073 : loss : 0.020794, loss_ce: 0.008869
2022-01-15 20:24:43,028 iteration 4074 : loss : 0.022048, loss_ce: 0.009042
2022-01-15 20:24:44,126 iteration 4075 : loss : 0.024346, loss_ce: 0.008295
2022-01-15 20:24:45,140 iteration 4076 : loss : 0.015855, loss_ce: 0.006470
2022-01-15 20:24:46,191 iteration 4077 : loss : 0.036170, loss_ce: 0.017039
2022-01-15 20:24:47,248 iteration 4078 : loss : 0.025082, loss_ce: 0.009750
2022-01-15 20:24:48,209 iteration 4079 : loss : 0.022301, loss_ce: 0.008986
2022-01-15 20:24:48,209 Training Data Eval:
2022-01-15 20:24:52,992   Average segmentation loss on training set: 0.0151
2022-01-15 20:24:52,992 Validation Data Eval:
2022-01-15 20:24:54,610   Average segmentation loss on validation set: 0.0989
2022-01-15 20:24:55,698 iteration 4080 : loss : 0.029504, loss_ce: 0.012700
 60%|█████████████████▍           | 240/400 [1:14:03<51:33, 19.33s/it]2022-01-15 20:24:56,723 iteration 4081 : loss : 0.020000, loss_ce: 0.008840
2022-01-15 20:24:57,706 iteration 4082 : loss : 0.022785, loss_ce: 0.008800
2022-01-15 20:24:58,689 iteration 4083 : loss : 0.017944, loss_ce: 0.007779
2022-01-15 20:24:59,730 iteration 4084 : loss : 0.026832, loss_ce: 0.007640
2022-01-15 20:25:00,807 iteration 4085 : loss : 0.024477, loss_ce: 0.007810
2022-01-15 20:25:01,853 iteration 4086 : loss : 0.021515, loss_ce: 0.010118
2022-01-15 20:25:02,824 iteration 4087 : loss : 0.022742, loss_ce: 0.005961
2022-01-15 20:25:03,807 iteration 4088 : loss : 0.023416, loss_ce: 0.010626
2022-01-15 20:25:04,826 iteration 4089 : loss : 0.019955, loss_ce: 0.006744
2022-01-15 20:25:05,844 iteration 4090 : loss : 0.018533, loss_ce: 0.007124
2022-01-15 20:25:06,796 iteration 4091 : loss : 0.018698, loss_ce: 0.006028
2022-01-15 20:25:07,773 iteration 4092 : loss : 0.015562, loss_ce: 0.006022
2022-01-15 20:25:08,744 iteration 4093 : loss : 0.020679, loss_ce: 0.008213
2022-01-15 20:25:09,687 iteration 4094 : loss : 0.016295, loss_ce: 0.005382
2022-01-15 20:25:10,657 iteration 4095 : loss : 0.021351, loss_ce: 0.007923
2022-01-15 20:25:11,638 iteration 4096 : loss : 0.019842, loss_ce: 0.008598
2022-01-15 20:25:12,628 iteration 4097 : loss : 0.022114, loss_ce: 0.010895
 60%|█████████████████▍           | 241/400 [1:14:20<49:18, 18.61s/it]2022-01-15 20:25:13,702 iteration 4098 : loss : 0.022236, loss_ce: 0.008564
2022-01-15 20:25:14,655 iteration 4099 : loss : 0.071206, loss_ce: 0.015414
2022-01-15 20:25:15,572 iteration 4100 : loss : 0.018412, loss_ce: 0.007648
2022-01-15 20:25:16,523 iteration 4101 : loss : 0.015977, loss_ce: 0.006272
2022-01-15 20:25:17,526 iteration 4102 : loss : 0.020545, loss_ce: 0.007824
2022-01-15 20:25:18,483 iteration 4103 : loss : 0.018628, loss_ce: 0.007186
2022-01-15 20:25:19,410 iteration 4104 : loss : 0.018309, loss_ce: 0.007677
2022-01-15 20:25:20,407 iteration 4105 : loss : 0.016607, loss_ce: 0.006324
2022-01-15 20:25:21,341 iteration 4106 : loss : 0.024217, loss_ce: 0.005036
2022-01-15 20:25:22,435 iteration 4107 : loss : 0.028501, loss_ce: 0.015720
2022-01-15 20:25:23,451 iteration 4108 : loss : 0.033307, loss_ce: 0.012028
2022-01-15 20:25:24,361 iteration 4109 : loss : 0.018046, loss_ce: 0.003933
2022-01-15 20:25:25,354 iteration 4110 : loss : 0.022607, loss_ce: 0.009097
2022-01-15 20:25:26,403 iteration 4111 : loss : 0.027868, loss_ce: 0.010018
2022-01-15 20:25:27,359 iteration 4112 : loss : 0.035082, loss_ce: 0.014681
2022-01-15 20:25:28,366 iteration 4113 : loss : 0.024620, loss_ce: 0.009734
2022-01-15 20:25:29,441 iteration 4114 : loss : 0.030496, loss_ce: 0.013314
 60%|█████████████████▌           | 242/400 [1:14:37<47:35, 18.07s/it]2022-01-15 20:25:30,449 iteration 4115 : loss : 0.022526, loss_ce: 0.006456
2022-01-15 20:25:31,386 iteration 4116 : loss : 0.021019, loss_ce: 0.009822
2022-01-15 20:25:32,533 iteration 4117 : loss : 0.025164, loss_ce: 0.006610
2022-01-15 20:25:33,656 iteration 4118 : loss : 0.033217, loss_ce: 0.018888
2022-01-15 20:25:34,684 iteration 4119 : loss : 0.020943, loss_ce: 0.008818
2022-01-15 20:25:35,690 iteration 4120 : loss : 0.037538, loss_ce: 0.007098
2022-01-15 20:25:36,698 iteration 4121 : loss : 0.015749, loss_ce: 0.006960
2022-01-15 20:25:37,666 iteration 4122 : loss : 0.022060, loss_ce: 0.007434
2022-01-15 20:25:38,743 iteration 4123 : loss : 0.031343, loss_ce: 0.011448
2022-01-15 20:25:39,681 iteration 4124 : loss : 0.022838, loss_ce: 0.008139
2022-01-15 20:25:40,756 iteration 4125 : loss : 0.029240, loss_ce: 0.006746
2022-01-15 20:25:41,758 iteration 4126 : loss : 0.021627, loss_ce: 0.009220
2022-01-15 20:25:42,784 iteration 4127 : loss : 0.021478, loss_ce: 0.008796
2022-01-15 20:25:43,734 iteration 4128 : loss : 0.021775, loss_ce: 0.010805
2022-01-15 20:25:44,784 iteration 4129 : loss : 0.027674, loss_ce: 0.010299
2022-01-15 20:25:45,766 iteration 4130 : loss : 0.027692, loss_ce: 0.014690
2022-01-15 20:25:46,663 iteration 4131 : loss : 0.014805, loss_ce: 0.004079
 61%|█████████████████▌           | 243/400 [1:14:54<46:37, 17.82s/it]2022-01-15 20:25:47,765 iteration 4132 : loss : 0.022193, loss_ce: 0.008955
2022-01-15 20:25:48,808 iteration 4133 : loss : 0.027504, loss_ce: 0.011527
2022-01-15 20:25:49,705 iteration 4134 : loss : 0.020453, loss_ce: 0.008635
2022-01-15 20:25:50,743 iteration 4135 : loss : 0.021186, loss_ce: 0.008609
2022-01-15 20:25:51,723 iteration 4136 : loss : 0.023945, loss_ce: 0.011786
2022-01-15 20:25:52,674 iteration 4137 : loss : 0.037615, loss_ce: 0.022782
2022-01-15 20:25:53,610 iteration 4138 : loss : 0.020787, loss_ce: 0.009917
2022-01-15 20:25:54,628 iteration 4139 : loss : 0.034264, loss_ce: 0.009621
2022-01-15 20:25:55,676 iteration 4140 : loss : 0.031300, loss_ce: 0.010000
2022-01-15 20:25:56,654 iteration 4141 : loss : 0.034877, loss_ce: 0.009463
2022-01-15 20:25:57,664 iteration 4142 : loss : 0.038406, loss_ce: 0.011431
2022-01-15 20:25:58,700 iteration 4143 : loss : 0.025204, loss_ce: 0.006320
2022-01-15 20:25:59,662 iteration 4144 : loss : 0.024794, loss_ce: 0.009287
2022-01-15 20:26:00,618 iteration 4145 : loss : 0.017960, loss_ce: 0.004696
2022-01-15 20:26:01,602 iteration 4146 : loss : 0.028287, loss_ce: 0.010705
2022-01-15 20:26:02,567 iteration 4147 : loss : 0.029062, loss_ce: 0.010673
2022-01-15 20:26:03,462 iteration 4148 : loss : 0.018636, loss_ce: 0.006567
 61%|█████████████████▋           | 244/400 [1:15:11<45:31, 17.51s/it]2022-01-15 20:26:04,640 iteration 4149 : loss : 0.035041, loss_ce: 0.012103
2022-01-15 20:26:05,554 iteration 4150 : loss : 0.025678, loss_ce: 0.007083
2022-01-15 20:26:06,585 iteration 4151 : loss : 0.024463, loss_ce: 0.012664
2022-01-15 20:26:07,486 iteration 4152 : loss : 0.017740, loss_ce: 0.006627
2022-01-15 20:26:08,520 iteration 4153 : loss : 0.043529, loss_ce: 0.011486
2022-01-15 20:26:09,545 iteration 4154 : loss : 0.024630, loss_ce: 0.010336
2022-01-15 20:26:10,613 iteration 4155 : loss : 0.025187, loss_ce: 0.009116
2022-01-15 20:26:11,517 iteration 4156 : loss : 0.016305, loss_ce: 0.006624
2022-01-15 20:26:12,557 iteration 4157 : loss : 0.029201, loss_ce: 0.010418
2022-01-15 20:26:13,567 iteration 4158 : loss : 0.024276, loss_ce: 0.010463
2022-01-15 20:26:14,613 iteration 4159 : loss : 0.020485, loss_ce: 0.008532
2022-01-15 20:26:15,624 iteration 4160 : loss : 0.022773, loss_ce: 0.009565
2022-01-15 20:26:16,636 iteration 4161 : loss : 0.025184, loss_ce: 0.011161
2022-01-15 20:26:17,614 iteration 4162 : loss : 0.025532, loss_ce: 0.009720
2022-01-15 20:26:18,665 iteration 4163 : loss : 0.038923, loss_ce: 0.011739
2022-01-15 20:26:19,721 iteration 4164 : loss : 0.024765, loss_ce: 0.009736
2022-01-15 20:26:19,721 Training Data Eval:
2022-01-15 20:26:24,575   Average segmentation loss on training set: 0.0155
2022-01-15 20:26:24,576 Validation Data Eval:
2022-01-15 20:26:26,224   Average segmentation loss on validation set: 0.0990
2022-01-15 20:26:27,247 iteration 4165 : loss : 0.026638, loss_ce: 0.010940
 61%|█████████████████▊           | 245/400 [1:15:35<50:06, 19.40s/it]2022-01-15 20:26:28,261 iteration 4166 : loss : 0.022559, loss_ce: 0.009957
2022-01-15 20:26:29,275 iteration 4167 : loss : 0.034707, loss_ce: 0.008962
2022-01-15 20:26:30,310 iteration 4168 : loss : 0.021752, loss_ce: 0.008741
2022-01-15 20:26:31,315 iteration 4169 : loss : 0.038892, loss_ce: 0.015844
2022-01-15 20:26:32,343 iteration 4170 : loss : 0.043316, loss_ce: 0.015186
2022-01-15 20:26:33,292 iteration 4171 : loss : 0.021915, loss_ce: 0.011202
2022-01-15 20:26:34,265 iteration 4172 : loss : 0.022738, loss_ce: 0.008665
2022-01-15 20:26:35,164 iteration 4173 : loss : 0.022988, loss_ce: 0.007801
2022-01-15 20:26:36,203 iteration 4174 : loss : 0.026168, loss_ce: 0.008782
2022-01-15 20:26:37,216 iteration 4175 : loss : 0.020643, loss_ce: 0.005782
2022-01-15 20:26:38,258 iteration 4176 : loss : 0.029511, loss_ce: 0.010115
2022-01-15 20:26:39,184 iteration 4177 : loss : 0.021389, loss_ce: 0.009829
2022-01-15 20:26:40,164 iteration 4178 : loss : 0.017539, loss_ce: 0.007261
2022-01-15 20:26:41,198 iteration 4179 : loss : 0.024365, loss_ce: 0.009461
2022-01-15 20:26:42,273 iteration 4180 : loss : 0.024154, loss_ce: 0.007652
2022-01-15 20:26:43,282 iteration 4181 : loss : 0.022350, loss_ce: 0.009612
2022-01-15 20:26:44,326 iteration 4182 : loss : 0.026037, loss_ce: 0.010786
 62%|█████████████████▊           | 246/400 [1:15:52<47:59, 18.70s/it]2022-01-15 20:26:45,360 iteration 4183 : loss : 0.027772, loss_ce: 0.007518
2022-01-15 20:26:46,325 iteration 4184 : loss : 0.019107, loss_ce: 0.005697
2022-01-15 20:26:47,341 iteration 4185 : loss : 0.026261, loss_ce: 0.008011
2022-01-15 20:26:48,301 iteration 4186 : loss : 0.018978, loss_ce: 0.006717
2022-01-15 20:26:49,242 iteration 4187 : loss : 0.020562, loss_ce: 0.008068
2022-01-15 20:26:50,215 iteration 4188 : loss : 0.023967, loss_ce: 0.008872
2022-01-15 20:26:51,127 iteration 4189 : loss : 0.023802, loss_ce: 0.008354
2022-01-15 20:26:52,220 iteration 4190 : loss : 0.027514, loss_ce: 0.014089
2022-01-15 20:26:53,249 iteration 4191 : loss : 0.020781, loss_ce: 0.006018
2022-01-15 20:26:54,167 iteration 4192 : loss : 0.016939, loss_ce: 0.008540
2022-01-15 20:26:55,063 iteration 4193 : loss : 0.019049, loss_ce: 0.006063
2022-01-15 20:26:56,045 iteration 4194 : loss : 0.034441, loss_ce: 0.012700
2022-01-15 20:26:56,994 iteration 4195 : loss : 0.016720, loss_ce: 0.006852
2022-01-15 20:26:57,931 iteration 4196 : loss : 0.017442, loss_ce: 0.006637
2022-01-15 20:26:58,868 iteration 4197 : loss : 0.022433, loss_ce: 0.008732
2022-01-15 20:26:59,785 iteration 4198 : loss : 0.023979, loss_ce: 0.005395
2022-01-15 20:27:00,811 iteration 4199 : loss : 0.019311, loss_ce: 0.007997
 62%|█████████████████▉           | 247/400 [1:16:08<45:59, 18.03s/it]2022-01-15 20:27:01,843 iteration 4200 : loss : 0.020702, loss_ce: 0.006959
2022-01-15 20:27:02,861 iteration 4201 : loss : 0.030013, loss_ce: 0.016805
2022-01-15 20:27:03,921 iteration 4202 : loss : 0.016773, loss_ce: 0.006315
2022-01-15 20:27:04,987 iteration 4203 : loss : 0.024782, loss_ce: 0.009480
2022-01-15 20:27:06,012 iteration 4204 : loss : 0.021811, loss_ce: 0.009185
2022-01-15 20:27:06,838 iteration 4205 : loss : 0.013755, loss_ce: 0.004556
2022-01-15 20:27:07,795 iteration 4206 : loss : 0.017178, loss_ce: 0.005487
2022-01-15 20:27:08,754 iteration 4207 : loss : 0.017917, loss_ce: 0.008679
2022-01-15 20:27:09,795 iteration 4208 : loss : 0.019502, loss_ce: 0.006465
2022-01-15 20:27:10,766 iteration 4209 : loss : 0.020277, loss_ce: 0.006300
2022-01-15 20:27:11,726 iteration 4210 : loss : 0.015466, loss_ce: 0.005316
2022-01-15 20:27:12,730 iteration 4211 : loss : 0.017957, loss_ce: 0.007003
2022-01-15 20:27:13,682 iteration 4212 : loss : 0.015724, loss_ce: 0.006439
2022-01-15 20:27:14,734 iteration 4213 : loss : 0.018989, loss_ce: 0.005630
2022-01-15 20:27:15,773 iteration 4214 : loss : 0.023323, loss_ce: 0.010413
2022-01-15 20:27:16,790 iteration 4215 : loss : 0.029954, loss_ce: 0.009108
2022-01-15 20:27:17,760 iteration 4216 : loss : 0.020635, loss_ce: 0.006916
 62%|█████████████████▉           | 248/400 [1:16:25<44:51, 17.71s/it]2022-01-15 20:27:18,891 iteration 4217 : loss : 0.041533, loss_ce: 0.010687
2022-01-15 20:27:19,956 iteration 4218 : loss : 0.017930, loss_ce: 0.008667
2022-01-15 20:27:20,951 iteration 4219 : loss : 0.021049, loss_ce: 0.007974
2022-01-15 20:27:21,921 iteration 4220 : loss : 0.023691, loss_ce: 0.007859
2022-01-15 20:27:22,924 iteration 4221 : loss : 0.023806, loss_ce: 0.007589
2022-01-15 20:27:23,949 iteration 4222 : loss : 0.018210, loss_ce: 0.007580
2022-01-15 20:27:25,074 iteration 4223 : loss : 0.033678, loss_ce: 0.007813
2022-01-15 20:27:26,054 iteration 4224 : loss : 0.024893, loss_ce: 0.008142
2022-01-15 20:27:27,090 iteration 4225 : loss : 0.024659, loss_ce: 0.012832
2022-01-15 20:27:28,172 iteration 4226 : loss : 0.028239, loss_ce: 0.009993
2022-01-15 20:27:29,133 iteration 4227 : loss : 0.023900, loss_ce: 0.007178
2022-01-15 20:27:30,155 iteration 4228 : loss : 0.028431, loss_ce: 0.013939
2022-01-15 20:27:31,109 iteration 4229 : loss : 0.021325, loss_ce: 0.007639
2022-01-15 20:27:32,172 iteration 4230 : loss : 0.032966, loss_ce: 0.012624
2022-01-15 20:27:33,216 iteration 4231 : loss : 0.024148, loss_ce: 0.009545
2022-01-15 20:27:34,281 iteration 4232 : loss : 0.030669, loss_ce: 0.014550
2022-01-15 20:27:35,227 iteration 4233 : loss : 0.025772, loss_ce: 0.008812
 62%|██████████████████           | 249/400 [1:16:43<44:23, 17.64s/it]2022-01-15 20:27:36,344 iteration 4234 : loss : 0.025602, loss_ce: 0.010604
2022-01-15 20:27:37,288 iteration 4235 : loss : 0.017965, loss_ce: 0.006895
2022-01-15 20:27:38,340 iteration 4236 : loss : 0.032014, loss_ce: 0.014767
2022-01-15 20:27:39,329 iteration 4237 : loss : 0.019433, loss_ce: 0.009911
2022-01-15 20:27:40,408 iteration 4238 : loss : 0.040884, loss_ce: 0.014637
2022-01-15 20:27:41,334 iteration 4239 : loss : 0.023876, loss_ce: 0.007447
2022-01-15 20:27:42,437 iteration 4240 : loss : 0.027901, loss_ce: 0.010193
2022-01-15 20:27:43,433 iteration 4241 : loss : 0.022288, loss_ce: 0.007517
2022-01-15 20:27:44,409 iteration 4242 : loss : 0.028917, loss_ce: 0.009872
2022-01-15 20:27:45,417 iteration 4243 : loss : 0.021865, loss_ce: 0.009203
2022-01-15 20:27:46,491 iteration 4244 : loss : 0.021240, loss_ce: 0.007304
2022-01-15 20:27:47,519 iteration 4245 : loss : 0.033208, loss_ce: 0.009101
2022-01-15 20:27:48,509 iteration 4246 : loss : 0.021097, loss_ce: 0.009929
2022-01-15 20:27:49,504 iteration 4247 : loss : 0.021240, loss_ce: 0.004788
2022-01-15 20:27:50,561 iteration 4248 : loss : 0.023719, loss_ce: 0.008395
2022-01-15 20:27:51,578 iteration 4249 : loss : 0.028919, loss_ce: 0.015185
2022-01-15 20:27:51,579 Training Data Eval:
2022-01-15 20:27:56,488   Average segmentation loss on training set: 0.0160
2022-01-15 20:27:56,489 Validation Data Eval:
2022-01-15 20:27:58,141   Average segmentation loss on validation set: 0.1584
2022-01-15 20:27:59,188 iteration 4250 : loss : 0.028091, loss_ce: 0.009024
 62%|██████████████████▏          | 250/400 [1:17:07<48:50, 19.53s/it]2022-01-15 20:28:00,313 iteration 4251 : loss : 0.020061, loss_ce: 0.007237
2022-01-15 20:28:01,342 iteration 4252 : loss : 0.029071, loss_ce: 0.010365
2022-01-15 20:28:02,358 iteration 4253 : loss : 0.026647, loss_ce: 0.008753
2022-01-15 20:28:03,440 iteration 4254 : loss : 0.023112, loss_ce: 0.009881
2022-01-15 20:28:04,342 iteration 4255 : loss : 0.017065, loss_ce: 0.006406
2022-01-15 20:28:05,330 iteration 4256 : loss : 0.021816, loss_ce: 0.006291
2022-01-15 20:28:06,403 iteration 4257 : loss : 0.024409, loss_ce: 0.009392
2022-01-15 20:28:07,362 iteration 4258 : loss : 0.019467, loss_ce: 0.006419
2022-01-15 20:28:08,362 iteration 4259 : loss : 0.020835, loss_ce: 0.007728
2022-01-15 20:28:09,363 iteration 4260 : loss : 0.018833, loss_ce: 0.005774
2022-01-15 20:28:10,372 iteration 4261 : loss : 0.019764, loss_ce: 0.008172
2022-01-15 20:28:11,462 iteration 4262 : loss : 0.024173, loss_ce: 0.011762
2022-01-15 20:28:12,448 iteration 4263 : loss : 0.025033, loss_ce: 0.014467
2022-01-15 20:28:13,370 iteration 4264 : loss : 0.034991, loss_ce: 0.009528
2022-01-15 20:28:14,338 iteration 4265 : loss : 0.022768, loss_ce: 0.007738
2022-01-15 20:28:15,319 iteration 4266 : loss : 0.024190, loss_ce: 0.009751
2022-01-15 20:28:16,311 iteration 4267 : loss : 0.017911, loss_ce: 0.008224
 63%|██████████████████▏          | 251/400 [1:17:24<46:42, 18.81s/it]2022-01-15 20:28:17,351 iteration 4268 : loss : 0.023095, loss_ce: 0.009804
2022-01-15 20:28:18,280 iteration 4269 : loss : 0.017558, loss_ce: 0.006094
2022-01-15 20:28:19,228 iteration 4270 : loss : 0.026314, loss_ce: 0.003954
2022-01-15 20:28:20,170 iteration 4271 : loss : 0.025124, loss_ce: 0.015845
2022-01-15 20:28:21,207 iteration 4272 : loss : 0.021446, loss_ce: 0.007324
2022-01-15 20:28:22,219 iteration 4273 : loss : 0.025845, loss_ce: 0.013632
2022-01-15 20:28:23,246 iteration 4274 : loss : 0.028588, loss_ce: 0.014334
2022-01-15 20:28:24,108 iteration 4275 : loss : 0.016390, loss_ce: 0.006537
2022-01-15 20:28:25,064 iteration 4276 : loss : 0.022578, loss_ce: 0.007775
2022-01-15 20:28:26,035 iteration 4277 : loss : 0.013687, loss_ce: 0.005443
2022-01-15 20:28:27,016 iteration 4278 : loss : 0.032378, loss_ce: 0.009609
2022-01-15 20:28:27,954 iteration 4279 : loss : 0.019479, loss_ce: 0.005521
2022-01-15 20:28:28,909 iteration 4280 : loss : 0.021166, loss_ce: 0.005808
2022-01-15 20:28:30,052 iteration 4281 : loss : 0.029547, loss_ce: 0.016648
2022-01-15 20:28:31,072 iteration 4282 : loss : 0.022039, loss_ce: 0.008964
2022-01-15 20:28:31,980 iteration 4283 : loss : 0.016719, loss_ce: 0.006452
2022-01-15 20:28:32,969 iteration 4284 : loss : 0.022804, loss_ce: 0.010062
 63%|██████████████████▎          | 252/400 [1:17:40<44:48, 18.16s/it]2022-01-15 20:28:34,090 iteration 4285 : loss : 0.033317, loss_ce: 0.014712
2022-01-15 20:28:35,136 iteration 4286 : loss : 0.016070, loss_ce: 0.004249
2022-01-15 20:28:36,199 iteration 4287 : loss : 0.031290, loss_ce: 0.012984
2022-01-15 20:28:37,207 iteration 4288 : loss : 0.016256, loss_ce: 0.004963
2022-01-15 20:28:38,239 iteration 4289 : loss : 0.021799, loss_ce: 0.007937
2022-01-15 20:28:39,308 iteration 4290 : loss : 0.036078, loss_ce: 0.011987
2022-01-15 20:28:40,254 iteration 4291 : loss : 0.024047, loss_ce: 0.008151
2022-01-15 20:28:41,341 iteration 4292 : loss : 0.024071, loss_ce: 0.009510
2022-01-15 20:28:42,378 iteration 4293 : loss : 0.031191, loss_ce: 0.013309
2022-01-15 20:28:43,394 iteration 4294 : loss : 0.029129, loss_ce: 0.014670
2022-01-15 20:28:44,450 iteration 4295 : loss : 0.020607, loss_ce: 0.008961
2022-01-15 20:28:45,375 iteration 4296 : loss : 0.017189, loss_ce: 0.007237
2022-01-15 20:28:46,376 iteration 4297 : loss : 0.015947, loss_ce: 0.005797
2022-01-15 20:28:47,318 iteration 4298 : loss : 0.019684, loss_ce: 0.006599
2022-01-15 20:28:48,392 iteration 4299 : loss : 0.025668, loss_ce: 0.010529
2022-01-15 20:28:49,433 iteration 4300 : loss : 0.022644, loss_ce: 0.006540
2022-01-15 20:28:50,406 iteration 4301 : loss : 0.018872, loss_ce: 0.007035
 63%|██████████████████▎          | 253/400 [1:17:58<43:57, 17.94s/it]2022-01-15 20:28:51,479 iteration 4302 : loss : 0.019182, loss_ce: 0.008687
2022-01-15 20:28:52,522 iteration 4303 : loss : 0.020721, loss_ce: 0.006815
2022-01-15 20:28:53,442 iteration 4304 : loss : 0.016388, loss_ce: 0.005967
2022-01-15 20:28:54,464 iteration 4305 : loss : 0.028279, loss_ce: 0.008050
2022-01-15 20:28:55,432 iteration 4306 : loss : 0.019849, loss_ce: 0.007105
2022-01-15 20:28:56,402 iteration 4307 : loss : 0.017455, loss_ce: 0.006084
2022-01-15 20:28:57,456 iteration 4308 : loss : 0.023106, loss_ce: 0.007650
2022-01-15 20:28:58,407 iteration 4309 : loss : 0.024066, loss_ce: 0.007254
2022-01-15 20:28:59,431 iteration 4310 : loss : 0.026474, loss_ce: 0.013329
2022-01-15 20:29:00,437 iteration 4311 : loss : 0.018005, loss_ce: 0.007787
2022-01-15 20:29:01,542 iteration 4312 : loss : 0.029200, loss_ce: 0.011723
2022-01-15 20:29:02,529 iteration 4313 : loss : 0.020453, loss_ce: 0.007025
2022-01-15 20:29:03,508 iteration 4314 : loss : 0.025022, loss_ce: 0.008097
2022-01-15 20:29:04,471 iteration 4315 : loss : 0.018764, loss_ce: 0.007126
2022-01-15 20:29:05,538 iteration 4316 : loss : 0.018578, loss_ce: 0.006462
2022-01-15 20:29:06,524 iteration 4317 : loss : 0.021709, loss_ce: 0.007489
2022-01-15 20:29:07,522 iteration 4318 : loss : 0.018451, loss_ce: 0.008696
 64%|██████████████████▍          | 254/400 [1:18:15<43:03, 17.70s/it]2022-01-15 20:29:08,666 iteration 4319 : loss : 0.030538, loss_ce: 0.009301
2022-01-15 20:29:09,760 iteration 4320 : loss : 0.025165, loss_ce: 0.009875
2022-01-15 20:29:10,857 iteration 4321 : loss : 0.018668, loss_ce: 0.008419
2022-01-15 20:29:11,892 iteration 4322 : loss : 0.023605, loss_ce: 0.006886
2022-01-15 20:29:12,871 iteration 4323 : loss : 0.017437, loss_ce: 0.005624
2022-01-15 20:29:13,928 iteration 4324 : loss : 0.026455, loss_ce: 0.010199
2022-01-15 20:29:15,082 iteration 4325 : loss : 0.027416, loss_ce: 0.005686
2022-01-15 20:29:16,116 iteration 4326 : loss : 0.031389, loss_ce: 0.019515
2022-01-15 20:29:17,103 iteration 4327 : loss : 0.019383, loss_ce: 0.007297
2022-01-15 20:29:18,110 iteration 4328 : loss : 0.024457, loss_ce: 0.009973
2022-01-15 20:29:19,178 iteration 4329 : loss : 0.023436, loss_ce: 0.009278
2022-01-15 20:29:20,160 iteration 4330 : loss : 0.015995, loss_ce: 0.005587
2022-01-15 20:29:21,325 iteration 4331 : loss : 0.059741, loss_ce: 0.015136
2022-01-15 20:29:22,399 iteration 4332 : loss : 0.025753, loss_ce: 0.010268
2022-01-15 20:29:23,349 iteration 4333 : loss : 0.023881, loss_ce: 0.006175
2022-01-15 20:29:24,339 iteration 4334 : loss : 0.020459, loss_ce: 0.008513
2022-01-15 20:29:24,339 Training Data Eval:
2022-01-15 20:29:29,303   Average segmentation loss on training set: 0.0161
2022-01-15 20:29:29,303 Validation Data Eval:
2022-01-15 20:29:30,981   Average segmentation loss on validation set: 0.0866
2022-01-15 20:29:32,088 iteration 4335 : loss : 0.029082, loss_ce: 0.017949
 64%|██████████████████▍          | 255/400 [1:18:40<47:45, 19.76s/it]2022-01-15 20:29:33,167 iteration 4336 : loss : 0.023210, loss_ce: 0.009383
2022-01-15 20:29:34,205 iteration 4337 : loss : 0.026759, loss_ce: 0.010496
2022-01-15 20:29:35,321 iteration 4338 : loss : 0.023458, loss_ce: 0.008090
2022-01-15 20:29:36,298 iteration 4339 : loss : 0.029399, loss_ce: 0.008445
2022-01-15 20:29:37,327 iteration 4340 : loss : 0.022705, loss_ce: 0.008378
2022-01-15 20:29:38,373 iteration 4341 : loss : 0.021608, loss_ce: 0.008604
2022-01-15 20:29:39,371 iteration 4342 : loss : 0.024234, loss_ce: 0.007875
2022-01-15 20:29:40,396 iteration 4343 : loss : 0.015555, loss_ce: 0.004541
2022-01-15 20:29:41,369 iteration 4344 : loss : 0.021931, loss_ce: 0.007571
2022-01-15 20:29:42,384 iteration 4345 : loss : 0.025827, loss_ce: 0.008291
2022-01-15 20:29:43,366 iteration 4346 : loss : 0.017479, loss_ce: 0.007132
2022-01-15 20:29:44,424 iteration 4347 : loss : 0.032528, loss_ce: 0.010684
2022-01-15 20:29:45,449 iteration 4348 : loss : 0.024226, loss_ce: 0.012064
2022-01-15 20:29:46,469 iteration 4349 : loss : 0.031919, loss_ce: 0.011064
2022-01-15 20:29:47,454 iteration 4350 : loss : 0.019541, loss_ce: 0.007542
2022-01-15 20:29:48,402 iteration 4351 : loss : 0.017940, loss_ce: 0.008207
2022-01-15 20:29:49,389 iteration 4352 : loss : 0.015537, loss_ce: 0.006274
 64%|██████████████████▌          | 256/400 [1:18:57<45:39, 19.02s/it]2022-01-15 20:29:50,493 iteration 4353 : loss : 0.019795, loss_ce: 0.007078
2022-01-15 20:29:51,582 iteration 4354 : loss : 0.028368, loss_ce: 0.009608
2022-01-15 20:29:52,533 iteration 4355 : loss : 0.019322, loss_ce: 0.006507
2022-01-15 20:29:53,586 iteration 4356 : loss : 0.027189, loss_ce: 0.013944
2022-01-15 20:29:54,607 iteration 4357 : loss : 0.021017, loss_ce: 0.008547
2022-01-15 20:29:55,584 iteration 4358 : loss : 0.019904, loss_ce: 0.008517
2022-01-15 20:29:56,581 iteration 4359 : loss : 0.016232, loss_ce: 0.005496
2022-01-15 20:29:57,581 iteration 4360 : loss : 0.028840, loss_ce: 0.010775
2022-01-15 20:29:58,652 iteration 4361 : loss : 0.028060, loss_ce: 0.013298
2022-01-15 20:29:59,637 iteration 4362 : loss : 0.020440, loss_ce: 0.006382
2022-01-15 20:30:00,577 iteration 4363 : loss : 0.025591, loss_ce: 0.012291
2022-01-15 20:30:01,650 iteration 4364 : loss : 0.023150, loss_ce: 0.008761
2022-01-15 20:30:02,663 iteration 4365 : loss : 0.025470, loss_ce: 0.010819
2022-01-15 20:30:03,576 iteration 4366 : loss : 0.016341, loss_ce: 0.006543
2022-01-15 20:30:04,597 iteration 4367 : loss : 0.038961, loss_ce: 0.013312
2022-01-15 20:30:05,701 iteration 4368 : loss : 0.022228, loss_ce: 0.008317
2022-01-15 20:30:06,663 iteration 4369 : loss : 0.027885, loss_ce: 0.007401
 64%|██████████████████▋          | 257/400 [1:19:14<44:04, 18.50s/it]2022-01-15 20:30:07,809 iteration 4370 : loss : 0.030686, loss_ce: 0.007520
2022-01-15 20:30:08,823 iteration 4371 : loss : 0.026176, loss_ce: 0.010985
2022-01-15 20:30:09,753 iteration 4372 : loss : 0.015754, loss_ce: 0.007065
2022-01-15 20:30:10,805 iteration 4373 : loss : 0.020989, loss_ce: 0.007666
2022-01-15 20:30:11,796 iteration 4374 : loss : 0.018860, loss_ce: 0.007600
2022-01-15 20:30:12,729 iteration 4375 : loss : 0.020018, loss_ce: 0.009630
2022-01-15 20:30:13,707 iteration 4376 : loss : 0.022064, loss_ce: 0.007920
2022-01-15 20:30:14,813 iteration 4377 : loss : 0.021383, loss_ce: 0.006659
2022-01-15 20:30:15,856 iteration 4378 : loss : 0.027331, loss_ce: 0.011570
2022-01-15 20:30:16,956 iteration 4379 : loss : 0.028825, loss_ce: 0.013171
2022-01-15 20:30:17,975 iteration 4380 : loss : 0.020074, loss_ce: 0.009035
2022-01-15 20:30:19,015 iteration 4381 : loss : 0.032964, loss_ce: 0.016352
2022-01-15 20:30:20,004 iteration 4382 : loss : 0.030466, loss_ce: 0.013522
2022-01-15 20:30:20,991 iteration 4383 : loss : 0.022997, loss_ce: 0.006555
2022-01-15 20:30:21,993 iteration 4384 : loss : 0.028193, loss_ce: 0.010636
2022-01-15 20:30:22,896 iteration 4385 : loss : 0.017139, loss_ce: 0.007517
2022-01-15 20:30:23,915 iteration 4386 : loss : 0.028108, loss_ce: 0.012109
 64%|██████████████████▋          | 258/400 [1:19:31<42:53, 18.13s/it]2022-01-15 20:30:24,969 iteration 4387 : loss : 0.017525, loss_ce: 0.007468
2022-01-15 20:30:26,000 iteration 4388 : loss : 0.021433, loss_ce: 0.009652
2022-01-15 20:30:26,924 iteration 4389 : loss : 0.017567, loss_ce: 0.007527
2022-01-15 20:30:27,848 iteration 4390 : loss : 0.021500, loss_ce: 0.008097
2022-01-15 20:30:28,828 iteration 4391 : loss : 0.020022, loss_ce: 0.008085
2022-01-15 20:30:29,852 iteration 4392 : loss : 0.024410, loss_ce: 0.010994
2022-01-15 20:30:30,752 iteration 4393 : loss : 0.022296, loss_ce: 0.007644
2022-01-15 20:30:31,820 iteration 4394 : loss : 0.024159, loss_ce: 0.009747
2022-01-15 20:30:32,852 iteration 4395 : loss : 0.018788, loss_ce: 0.007033
2022-01-15 20:30:33,915 iteration 4396 : loss : 0.025160, loss_ce: 0.008853
2022-01-15 20:30:34,879 iteration 4397 : loss : 0.024766, loss_ce: 0.007520
2022-01-15 20:30:35,824 iteration 4398 : loss : 0.020822, loss_ce: 0.005679
2022-01-15 20:30:36,805 iteration 4399 : loss : 0.017113, loss_ce: 0.005968
2022-01-15 20:30:37,761 iteration 4400 : loss : 0.019364, loss_ce: 0.008262
2022-01-15 20:30:38,724 iteration 4401 : loss : 0.016338, loss_ce: 0.007075
2022-01-15 20:30:39,648 iteration 4402 : loss : 0.018069, loss_ce: 0.005660
2022-01-15 20:30:40,634 iteration 4403 : loss : 0.021154, loss_ce: 0.006362
 65%|██████████████████▊          | 259/400 [1:19:48<41:35, 17.70s/it]2022-01-15 20:30:41,626 iteration 4404 : loss : 0.014756, loss_ce: 0.006934
2022-01-15 20:30:42,646 iteration 4405 : loss : 0.021964, loss_ce: 0.006225
2022-01-15 20:30:43,645 iteration 4406 : loss : 0.023200, loss_ce: 0.009936
2022-01-15 20:30:44,575 iteration 4407 : loss : 0.023935, loss_ce: 0.009622
2022-01-15 20:30:45,478 iteration 4408 : loss : 0.025346, loss_ce: 0.005929
2022-01-15 20:30:46,481 iteration 4409 : loss : 0.014728, loss_ce: 0.005806
2022-01-15 20:30:47,475 iteration 4410 : loss : 0.026888, loss_ce: 0.008150
2022-01-15 20:30:48,529 iteration 4411 : loss : 0.016914, loss_ce: 0.007808
2022-01-15 20:30:49,449 iteration 4412 : loss : 0.024782, loss_ce: 0.009642
2022-01-15 20:30:50,504 iteration 4413 : loss : 0.023367, loss_ce: 0.007852
2022-01-15 20:30:51,389 iteration 4414 : loss : 0.019565, loss_ce: 0.007279
2022-01-15 20:30:52,392 iteration 4415 : loss : 0.022300, loss_ce: 0.009884
2022-01-15 20:30:53,350 iteration 4416 : loss : 0.024142, loss_ce: 0.005564
2022-01-15 20:30:54,340 iteration 4417 : loss : 0.020981, loss_ce: 0.006812
2022-01-15 20:30:55,342 iteration 4418 : loss : 0.029935, loss_ce: 0.015237
2022-01-15 20:30:56,351 iteration 4419 : loss : 0.020277, loss_ce: 0.006090
2022-01-15 20:30:56,352 Training Data Eval:
2022-01-15 20:31:01,163   Average segmentation loss on training set: 0.0138
2022-01-15 20:31:01,163 Validation Data Eval:
2022-01-15 20:31:02,808   Average segmentation loss on validation set: 0.0753
2022-01-15 20:31:03,777 iteration 4420 : loss : 0.016718, loss_ce: 0.006963
 65%|██████████████████▊          | 260/400 [1:20:11<45:06, 19.33s/it]2022-01-15 20:31:04,882 iteration 4421 : loss : 0.019812, loss_ce: 0.006699
2022-01-15 20:31:05,945 iteration 4422 : loss : 0.028694, loss_ce: 0.010339
2022-01-15 20:31:07,068 iteration 4423 : loss : 0.022335, loss_ce: 0.009291
2022-01-15 20:31:08,138 iteration 4424 : loss : 0.029653, loss_ce: 0.010473
2022-01-15 20:31:09,070 iteration 4425 : loss : 0.020169, loss_ce: 0.007139
2022-01-15 20:31:10,118 iteration 4426 : loss : 0.024200, loss_ce: 0.008783
2022-01-15 20:31:11,156 iteration 4427 : loss : 0.040271, loss_ce: 0.008295
2022-01-15 20:31:12,211 iteration 4428 : loss : 0.036815, loss_ce: 0.012014
2022-01-15 20:31:13,289 iteration 4429 : loss : 0.024647, loss_ce: 0.009022
2022-01-15 20:31:14,288 iteration 4430 : loss : 0.024935, loss_ce: 0.008804
2022-01-15 20:31:15,274 iteration 4431 : loss : 0.025277, loss_ce: 0.009511
2022-01-15 20:31:16,270 iteration 4432 : loss : 0.017415, loss_ce: 0.006201
2022-01-15 20:31:17,265 iteration 4433 : loss : 0.025215, loss_ce: 0.008999
2022-01-15 20:31:18,257 iteration 4434 : loss : 0.018755, loss_ce: 0.006779
2022-01-15 20:31:19,306 iteration 4435 : loss : 0.035422, loss_ce: 0.011167
2022-01-15 20:31:20,444 iteration 4436 : loss : 0.031012, loss_ce: 0.014592
2022-01-15 20:31:21,384 iteration 4437 : loss : 0.018970, loss_ce: 0.007174
 65%|██████████████████▉          | 261/400 [1:20:29<43:35, 18.81s/it]2022-01-15 20:31:22,515 iteration 4438 : loss : 0.025295, loss_ce: 0.010187
2022-01-15 20:31:23,476 iteration 4439 : loss : 0.027681, loss_ce: 0.009627
2022-01-15 20:31:24,532 iteration 4440 : loss : 0.026781, loss_ce: 0.008288
2022-01-15 20:31:25,589 iteration 4441 : loss : 0.022448, loss_ce: 0.009376
2022-01-15 20:31:26,552 iteration 4442 : loss : 0.019657, loss_ce: 0.008776
2022-01-15 20:31:27,569 iteration 4443 : loss : 0.017059, loss_ce: 0.007307
2022-01-15 20:31:28,531 iteration 4444 : loss : 0.022627, loss_ce: 0.007299
2022-01-15 20:31:29,539 iteration 4445 : loss : 0.021022, loss_ce: 0.008236
2022-01-15 20:31:30,568 iteration 4446 : loss : 0.025465, loss_ce: 0.009775
2022-01-15 20:31:31,586 iteration 4447 : loss : 0.021845, loss_ce: 0.008176
2022-01-15 20:31:32,563 iteration 4448 : loss : 0.027881, loss_ce: 0.007454
2022-01-15 20:31:33,571 iteration 4449 : loss : 0.022694, loss_ce: 0.010653
2022-01-15 20:31:34,631 iteration 4450 : loss : 0.021040, loss_ce: 0.007201
2022-01-15 20:31:35,549 iteration 4451 : loss : 0.020935, loss_ce: 0.006942
2022-01-15 20:31:36,555 iteration 4452 : loss : 0.028939, loss_ce: 0.012541
2022-01-15 20:31:37,641 iteration 4453 : loss : 0.026525, loss_ce: 0.011876
2022-01-15 20:31:38,659 iteration 4454 : loss : 0.020074, loss_ce: 0.009321
 66%|██████████████████▉          | 262/400 [1:20:46<42:13, 18.36s/it]2022-01-15 20:31:39,792 iteration 4455 : loss : 0.028845, loss_ce: 0.013345
2022-01-15 20:31:40,787 iteration 4456 : loss : 0.026114, loss_ce: 0.011272
2022-01-15 20:31:41,690 iteration 4457 : loss : 0.015442, loss_ce: 0.007392
2022-01-15 20:31:42,715 iteration 4458 : loss : 0.023725, loss_ce: 0.009682
2022-01-15 20:31:43,647 iteration 4459 : loss : 0.017302, loss_ce: 0.007236
2022-01-15 20:31:44,652 iteration 4460 : loss : 0.017503, loss_ce: 0.006078
2022-01-15 20:31:45,597 iteration 4461 : loss : 0.022065, loss_ce: 0.009610
2022-01-15 20:31:46,549 iteration 4462 : loss : 0.018142, loss_ce: 0.006657
2022-01-15 20:31:47,497 iteration 4463 : loss : 0.017604, loss_ce: 0.006199
2022-01-15 20:31:48,446 iteration 4464 : loss : 0.017721, loss_ce: 0.006186
2022-01-15 20:31:49,481 iteration 4465 : loss : 0.020273, loss_ce: 0.008146
2022-01-15 20:31:50,507 iteration 4466 : loss : 0.020493, loss_ce: 0.006604
2022-01-15 20:31:51,499 iteration 4467 : loss : 0.022561, loss_ce: 0.007915
2022-01-15 20:31:52,468 iteration 4468 : loss : 0.018739, loss_ce: 0.006013
2022-01-15 20:31:53,397 iteration 4469 : loss : 0.026217, loss_ce: 0.007029
2022-01-15 20:31:54,419 iteration 4470 : loss : 0.022898, loss_ce: 0.007372
2022-01-15 20:31:55,452 iteration 4471 : loss : 0.022812, loss_ce: 0.008711
 66%|███████████████████          | 263/400 [1:21:03<40:50, 17.89s/it]2022-01-15 20:31:56,466 iteration 4472 : loss : 0.025998, loss_ce: 0.016289
2022-01-15 20:31:57,435 iteration 4473 : loss : 0.019791, loss_ce: 0.007518
2022-01-15 20:31:58,454 iteration 4474 : loss : 0.018611, loss_ce: 0.006265
2022-01-15 20:31:59,402 iteration 4475 : loss : 0.018122, loss_ce: 0.007146
2022-01-15 20:32:00,292 iteration 4476 : loss : 0.019326, loss_ce: 0.007072
2022-01-15 20:32:01,286 iteration 4477 : loss : 0.020399, loss_ce: 0.007755
2022-01-15 20:32:02,280 iteration 4478 : loss : 0.023872, loss_ce: 0.008870
2022-01-15 20:32:03,264 iteration 4479 : loss : 0.037921, loss_ce: 0.006805
2022-01-15 20:32:04,197 iteration 4480 : loss : 0.016735, loss_ce: 0.006828
2022-01-15 20:32:05,124 iteration 4481 : loss : 0.017791, loss_ce: 0.008050
2022-01-15 20:32:06,171 iteration 4482 : loss : 0.028669, loss_ce: 0.011496
2022-01-15 20:32:07,255 iteration 4483 : loss : 0.029054, loss_ce: 0.012170
2022-01-15 20:32:08,303 iteration 4484 : loss : 0.031859, loss_ce: 0.011692
2022-01-15 20:32:09,246 iteration 4485 : loss : 0.019054, loss_ce: 0.005650
2022-01-15 20:32:10,341 iteration 4486 : loss : 0.025635, loss_ce: 0.009952
2022-01-15 20:32:11,282 iteration 4487 : loss : 0.022180, loss_ce: 0.010160
2022-01-15 20:32:12,253 iteration 4488 : loss : 0.022760, loss_ce: 0.008938
 66%|███████████████████▏         | 264/400 [1:21:20<39:48, 17.56s/it]2022-01-15 20:32:13,340 iteration 4489 : loss : 0.033754, loss_ce: 0.013797
2022-01-15 20:32:14,332 iteration 4490 : loss : 0.016967, loss_ce: 0.006612
2022-01-15 20:32:15,400 iteration 4491 : loss : 0.030576, loss_ce: 0.011419
2022-01-15 20:32:16,408 iteration 4492 : loss : 0.043910, loss_ce: 0.021473
2022-01-15 20:32:17,463 iteration 4493 : loss : 0.037358, loss_ce: 0.011011
2022-01-15 20:32:18,360 iteration 4494 : loss : 0.018510, loss_ce: 0.007072
2022-01-15 20:32:19,388 iteration 4495 : loss : 0.025769, loss_ce: 0.012003
2022-01-15 20:32:20,429 iteration 4496 : loss : 0.025643, loss_ce: 0.007575
2022-01-15 20:32:21,362 iteration 4497 : loss : 0.021074, loss_ce: 0.006499
2022-01-15 20:32:22,453 iteration 4498 : loss : 0.030891, loss_ce: 0.013170
2022-01-15 20:32:23,581 iteration 4499 : loss : 0.042073, loss_ce: 0.022942
2022-01-15 20:32:24,551 iteration 4500 : loss : 0.022996, loss_ce: 0.009014
2022-01-15 20:32:25,489 iteration 4501 : loss : 0.021890, loss_ce: 0.007809
2022-01-15 20:32:26,428 iteration 4502 : loss : 0.018888, loss_ce: 0.007310
2022-01-15 20:32:27,497 iteration 4503 : loss : 0.028471, loss_ce: 0.011928
2022-01-15 20:32:28,485 iteration 4504 : loss : 0.021777, loss_ce: 0.006809
2022-01-15 20:32:28,485 Training Data Eval:
2022-01-15 20:32:33,265   Average segmentation loss on training set: 0.0152
2022-01-15 20:32:33,265 Validation Data Eval:
2022-01-15 20:32:34,884   Average segmentation loss on validation set: 0.0735
2022-01-15 20:32:35,803 iteration 4505 : loss : 0.019786, loss_ce: 0.008392
 66%|███████████████████▏         | 265/400 [1:21:43<43:33, 19.36s/it]2022-01-15 20:32:36,919 iteration 4506 : loss : 0.034066, loss_ce: 0.011651
2022-01-15 20:32:37,867 iteration 4507 : loss : 0.013756, loss_ce: 0.004288
2022-01-15 20:32:38,913 iteration 4508 : loss : 0.027594, loss_ce: 0.007539
2022-01-15 20:32:39,920 iteration 4509 : loss : 0.023291, loss_ce: 0.007691
2022-01-15 20:32:40,900 iteration 4510 : loss : 0.017464, loss_ce: 0.005961
2022-01-15 20:32:41,831 iteration 4511 : loss : 0.022043, loss_ce: 0.008749
2022-01-15 20:32:42,798 iteration 4512 : loss : 0.017565, loss_ce: 0.007262
2022-01-15 20:32:43,801 iteration 4513 : loss : 0.019150, loss_ce: 0.009044
2022-01-15 20:32:44,708 iteration 4514 : loss : 0.019355, loss_ce: 0.006943
2022-01-15 20:32:45,675 iteration 4515 : loss : 0.037887, loss_ce: 0.012335
2022-01-15 20:32:46,778 iteration 4516 : loss : 0.024457, loss_ce: 0.010566
2022-01-15 20:32:47,741 iteration 4517 : loss : 0.019833, loss_ce: 0.008410
2022-01-15 20:32:48,751 iteration 4518 : loss : 0.022213, loss_ce: 0.007844
2022-01-15 20:32:49,735 iteration 4519 : loss : 0.024434, loss_ce: 0.012251
2022-01-15 20:32:50,656 iteration 4520 : loss : 0.020538, loss_ce: 0.006971
2022-01-15 20:32:51,656 iteration 4521 : loss : 0.024813, loss_ce: 0.008952
2022-01-15 20:32:52,578 iteration 4522 : loss : 0.018080, loss_ce: 0.008735
 66%|███████████████████▎         | 266/400 [1:22:00<41:30, 18.58s/it]2022-01-15 20:32:53,688 iteration 4523 : loss : 0.019049, loss_ce: 0.006575
2022-01-15 20:32:54,591 iteration 4524 : loss : 0.014976, loss_ce: 0.006021
2022-01-15 20:32:55,667 iteration 4525 : loss : 0.033286, loss_ce: 0.009034
2022-01-15 20:32:56,664 iteration 4526 : loss : 0.020890, loss_ce: 0.008461
2022-01-15 20:32:57,655 iteration 4527 : loss : 0.018493, loss_ce: 0.007574
2022-01-15 20:32:58,703 iteration 4528 : loss : 0.016855, loss_ce: 0.006149
2022-01-15 20:32:59,666 iteration 4529 : loss : 0.019128, loss_ce: 0.008620
2022-01-15 20:33:00,673 iteration 4530 : loss : 0.019933, loss_ce: 0.007837
2022-01-15 20:33:01,605 iteration 4531 : loss : 0.020480, loss_ce: 0.009031
2022-01-15 20:33:02,640 iteration 4532 : loss : 0.026440, loss_ce: 0.011593
2022-01-15 20:33:03,699 iteration 4533 : loss : 0.034333, loss_ce: 0.013954
2022-01-15 20:33:04,818 iteration 4534 : loss : 0.022543, loss_ce: 0.007840
2022-01-15 20:33:05,722 iteration 4535 : loss : 0.020304, loss_ce: 0.006794
2022-01-15 20:33:06,752 iteration 4536 : loss : 0.020173, loss_ce: 0.010802
2022-01-15 20:33:07,846 iteration 4537 : loss : 0.025690, loss_ce: 0.008791
2022-01-15 20:33:08,825 iteration 4538 : loss : 0.016975, loss_ce: 0.006071
2022-01-15 20:33:09,859 iteration 4539 : loss : 0.022789, loss_ce: 0.010007
 67%|███████████████████▎         | 267/400 [1:22:17<40:19, 18.19s/it]2022-01-15 20:33:10,979 iteration 4540 : loss : 0.018735, loss_ce: 0.006061
2022-01-15 20:33:11,912 iteration 4541 : loss : 0.015956, loss_ce: 0.005661
2022-01-15 20:33:12,932 iteration 4542 : loss : 0.023033, loss_ce: 0.006433
2022-01-15 20:33:13,852 iteration 4543 : loss : 0.019489, loss_ce: 0.007489
2022-01-15 20:33:14,900 iteration 4544 : loss : 0.024098, loss_ce: 0.011789
2022-01-15 20:33:15,978 iteration 4545 : loss : 0.043207, loss_ce: 0.018989
2022-01-15 20:33:17,012 iteration 4546 : loss : 0.026701, loss_ce: 0.010170
2022-01-15 20:33:18,042 iteration 4547 : loss : 0.019864, loss_ce: 0.009011
2022-01-15 20:33:19,057 iteration 4548 : loss : 0.022953, loss_ce: 0.008498
2022-01-15 20:33:20,169 iteration 4549 : loss : 0.026646, loss_ce: 0.011098
2022-01-15 20:33:21,263 iteration 4550 : loss : 0.044175, loss_ce: 0.013628
2022-01-15 20:33:22,334 iteration 4551 : loss : 0.036087, loss_ce: 0.006492
2022-01-15 20:33:23,258 iteration 4552 : loss : 0.013883, loss_ce: 0.005646
2022-01-15 20:33:24,214 iteration 4553 : loss : 0.022728, loss_ce: 0.008608
2022-01-15 20:33:25,202 iteration 4554 : loss : 0.018545, loss_ce: 0.006374
2022-01-15 20:33:26,259 iteration 4555 : loss : 0.024968, loss_ce: 0.009021
2022-01-15 20:33:27,260 iteration 4556 : loss : 0.017878, loss_ce: 0.007704
 67%|███████████████████▍         | 268/400 [1:22:35<39:29, 17.95s/it]2022-01-15 20:33:28,358 iteration 4557 : loss : 0.019599, loss_ce: 0.009020
2022-01-15 20:33:29,437 iteration 4558 : loss : 0.029341, loss_ce: 0.013316
2022-01-15 20:33:30,423 iteration 4559 : loss : 0.025958, loss_ce: 0.007313
2022-01-15 20:33:31,395 iteration 4560 : loss : 0.018098, loss_ce: 0.004954
2022-01-15 20:33:32,397 iteration 4561 : loss : 0.021733, loss_ce: 0.005659
2022-01-15 20:33:33,390 iteration 4562 : loss : 0.023421, loss_ce: 0.009238
2022-01-15 20:33:34,347 iteration 4563 : loss : 0.026669, loss_ce: 0.010124
2022-01-15 20:33:35,350 iteration 4564 : loss : 0.021412, loss_ce: 0.006413
2022-01-15 20:33:36,305 iteration 4565 : loss : 0.020818, loss_ce: 0.007701
2022-01-15 20:33:37,230 iteration 4566 : loss : 0.020882, loss_ce: 0.008663
2022-01-15 20:33:38,234 iteration 4567 : loss : 0.023356, loss_ce: 0.008916
2022-01-15 20:33:39,215 iteration 4568 : loss : 0.017302, loss_ce: 0.005106
2022-01-15 20:33:40,206 iteration 4569 : loss : 0.024844, loss_ce: 0.009834
2022-01-15 20:33:41,142 iteration 4570 : loss : 0.018214, loss_ce: 0.007468
2022-01-15 20:33:42,093 iteration 4571 : loss : 0.016969, loss_ce: 0.008016
2022-01-15 20:33:43,055 iteration 4572 : loss : 0.016848, loss_ce: 0.005570
2022-01-15 20:33:44,040 iteration 4573 : loss : 0.019744, loss_ce: 0.008184
 67%|███████████████████▌         | 269/400 [1:22:51<38:26, 17.60s/it]2022-01-15 20:33:45,080 iteration 4574 : loss : 0.021286, loss_ce: 0.006567
2022-01-15 20:33:46,018 iteration 4575 : loss : 0.016064, loss_ce: 0.006453
2022-01-15 20:33:47,036 iteration 4576 : loss : 0.018031, loss_ce: 0.009494
2022-01-15 20:33:48,074 iteration 4577 : loss : 0.021152, loss_ce: 0.007453
2022-01-15 20:33:49,054 iteration 4578 : loss : 0.019077, loss_ce: 0.008256
2022-01-15 20:33:50,011 iteration 4579 : loss : 0.025531, loss_ce: 0.011426
2022-01-15 20:33:50,972 iteration 4580 : loss : 0.017651, loss_ce: 0.007577
2022-01-15 20:33:52,059 iteration 4581 : loss : 0.027279, loss_ce: 0.008649
2022-01-15 20:33:53,053 iteration 4582 : loss : 0.023449, loss_ce: 0.011635
2022-01-15 20:33:54,049 iteration 4583 : loss : 0.021257, loss_ce: 0.007758
2022-01-15 20:33:55,003 iteration 4584 : loss : 0.017795, loss_ce: 0.006280
2022-01-15 20:33:56,018 iteration 4585 : loss : 0.023554, loss_ce: 0.007820
2022-01-15 20:33:56,978 iteration 4586 : loss : 0.016508, loss_ce: 0.007118
2022-01-15 20:33:58,062 iteration 4587 : loss : 0.027525, loss_ce: 0.009904
2022-01-15 20:33:59,018 iteration 4588 : loss : 0.015762, loss_ce: 0.003635
2022-01-15 20:33:59,991 iteration 4589 : loss : 0.020207, loss_ce: 0.009448
2022-01-15 20:33:59,992 Training Data Eval:
2022-01-15 20:34:04,765   Average segmentation loss on training set: 0.0134
2022-01-15 20:34:04,765 Validation Data Eval:
2022-01-15 20:34:06,363   Average segmentation loss on validation set: 0.0835
2022-01-15 20:34:07,493 iteration 4590 : loss : 0.032276, loss_ce: 0.009470
 68%|███████████████████▌         | 270/400 [1:23:15<41:56, 19.35s/it]2022-01-15 20:34:08,464 iteration 4591 : loss : 0.014728, loss_ce: 0.004110
2022-01-15 20:34:09,435 iteration 4592 : loss : 0.028203, loss_ce: 0.011250
2022-01-15 20:34:10,353 iteration 4593 : loss : 0.019178, loss_ce: 0.005920
2022-01-15 20:34:11,305 iteration 4594 : loss : 0.023134, loss_ce: 0.009180
2022-01-15 20:34:12,309 iteration 4595 : loss : 0.024446, loss_ce: 0.005294
2022-01-15 20:34:13,377 iteration 4596 : loss : 0.033881, loss_ce: 0.014733
2022-01-15 20:34:14,345 iteration 4597 : loss : 0.016221, loss_ce: 0.006595
2022-01-15 20:34:15,242 iteration 4598 : loss : 0.017562, loss_ce: 0.007825
2022-01-15 20:34:16,188 iteration 4599 : loss : 0.028980, loss_ce: 0.007933
2022-01-15 20:34:17,244 iteration 4600 : loss : 0.026892, loss_ce: 0.014637
2022-01-15 20:34:18,343 iteration 4601 : loss : 0.023512, loss_ce: 0.012217
2022-01-15 20:34:19,227 iteration 4602 : loss : 0.018041, loss_ce: 0.006591
2022-01-15 20:34:20,139 iteration 4603 : loss : 0.018603, loss_ce: 0.008469
2022-01-15 20:34:21,150 iteration 4604 : loss : 0.024305, loss_ce: 0.008325
2022-01-15 20:34:22,146 iteration 4605 : loss : 0.032175, loss_ce: 0.008917
2022-01-15 20:34:23,188 iteration 4606 : loss : 0.029468, loss_ce: 0.008927
2022-01-15 20:34:24,096 iteration 4607 : loss : 0.018037, loss_ce: 0.009728
 68%|███████████████████▋         | 271/400 [1:23:32<39:50, 18.53s/it]2022-01-15 20:34:25,188 iteration 4608 : loss : 0.022975, loss_ce: 0.007578
2022-01-15 20:34:26,245 iteration 4609 : loss : 0.023717, loss_ce: 0.011246
2022-01-15 20:34:27,270 iteration 4610 : loss : 0.028362, loss_ce: 0.006714
2022-01-15 20:34:28,249 iteration 4611 : loss : 0.024420, loss_ce: 0.009853
2022-01-15 20:34:29,158 iteration 4612 : loss : 0.017168, loss_ce: 0.006533
2022-01-15 20:34:30,171 iteration 4613 : loss : 0.019983, loss_ce: 0.008550
2022-01-15 20:34:31,191 iteration 4614 : loss : 0.032142, loss_ce: 0.009563
2022-01-15 20:34:32,215 iteration 4615 : loss : 0.038310, loss_ce: 0.013228
2022-01-15 20:34:33,279 iteration 4616 : loss : 0.020886, loss_ce: 0.007817
2022-01-15 20:34:34,204 iteration 4617 : loss : 0.020998, loss_ce: 0.008868
2022-01-15 20:34:35,240 iteration 4618 : loss : 0.033870, loss_ce: 0.012401
2022-01-15 20:34:36,306 iteration 4619 : loss : 0.028785, loss_ce: 0.009075
2022-01-15 20:34:37,346 iteration 4620 : loss : 0.025377, loss_ce: 0.007857
2022-01-15 20:34:38,412 iteration 4621 : loss : 0.032082, loss_ce: 0.012706
2022-01-15 20:34:39,406 iteration 4622 : loss : 0.020514, loss_ce: 0.007028
2022-01-15 20:34:40,372 iteration 4623 : loss : 0.026031, loss_ce: 0.008645
2022-01-15 20:34:41,367 iteration 4624 : loss : 0.019647, loss_ce: 0.008271
 68%|███████████████████▋         | 272/400 [1:23:49<38:43, 18.15s/it]2022-01-15 20:34:42,429 iteration 4625 : loss : 0.015430, loss_ce: 0.006439
2022-01-15 20:34:43,393 iteration 4626 : loss : 0.019239, loss_ce: 0.006718
2022-01-15 20:34:44,386 iteration 4627 : loss : 0.017954, loss_ce: 0.006573
2022-01-15 20:34:45,325 iteration 4628 : loss : 0.023578, loss_ce: 0.008738
2022-01-15 20:34:46,268 iteration 4629 : loss : 0.027262, loss_ce: 0.011846
2022-01-15 20:34:47,246 iteration 4630 : loss : 0.026140, loss_ce: 0.009143
2022-01-15 20:34:48,327 iteration 4631 : loss : 0.023444, loss_ce: 0.009013
2022-01-15 20:34:49,329 iteration 4632 : loss : 0.015660, loss_ce: 0.005032
2022-01-15 20:34:50,329 iteration 4633 : loss : 0.025000, loss_ce: 0.008373
2022-01-15 20:34:51,221 iteration 4634 : loss : 0.015702, loss_ce: 0.006901
2022-01-15 20:34:52,251 iteration 4635 : loss : 0.020182, loss_ce: 0.006067
2022-01-15 20:34:53,247 iteration 4636 : loss : 0.021364, loss_ce: 0.007523
2022-01-15 20:34:54,241 iteration 4637 : loss : 0.017749, loss_ce: 0.006258
2022-01-15 20:34:55,275 iteration 4638 : loss : 0.024890, loss_ce: 0.013127
2022-01-15 20:34:56,358 iteration 4639 : loss : 0.020044, loss_ce: 0.006449
2022-01-15 20:34:57,382 iteration 4640 : loss : 0.020859, loss_ce: 0.008605
2022-01-15 20:34:58,330 iteration 4641 : loss : 0.020913, loss_ce: 0.008995
 68%|███████████████████▊         | 273/400 [1:24:06<37:39, 17.80s/it]2022-01-15 20:34:59,420 iteration 4642 : loss : 0.027840, loss_ce: 0.007388
2022-01-15 20:35:00,440 iteration 4643 : loss : 0.030086, loss_ce: 0.011980
2022-01-15 20:35:01,455 iteration 4644 : loss : 0.020013, loss_ce: 0.008168
2022-01-15 20:35:02,621 iteration 4645 : loss : 0.025870, loss_ce: 0.010815
2022-01-15 20:35:03,571 iteration 4646 : loss : 0.017898, loss_ce: 0.008924
2022-01-15 20:35:04,522 iteration 4647 : loss : 0.017762, loss_ce: 0.006949
2022-01-15 20:35:05,413 iteration 4648 : loss : 0.015910, loss_ce: 0.006079
2022-01-15 20:35:06,427 iteration 4649 : loss : 0.025760, loss_ce: 0.012797
2022-01-15 20:35:07,394 iteration 4650 : loss : 0.019667, loss_ce: 0.006935
2022-01-15 20:35:08,395 iteration 4651 : loss : 0.024100, loss_ce: 0.009022
2022-01-15 20:35:09,392 iteration 4652 : loss : 0.021203, loss_ce: 0.008433
2022-01-15 20:35:10,377 iteration 4653 : loss : 0.023153, loss_ce: 0.008639
2022-01-15 20:35:11,371 iteration 4654 : loss : 0.019935, loss_ce: 0.009788
2022-01-15 20:35:12,378 iteration 4655 : loss : 0.020847, loss_ce: 0.007289
2022-01-15 20:35:13,448 iteration 4656 : loss : 0.050722, loss_ce: 0.013007
2022-01-15 20:35:14,414 iteration 4657 : loss : 0.045471, loss_ce: 0.006956
2022-01-15 20:35:15,356 iteration 4658 : loss : 0.022110, loss_ce: 0.005537
 68%|███████████████████▊         | 274/400 [1:24:23<36:53, 17.57s/it]2022-01-15 20:35:16,408 iteration 4659 : loss : 0.020708, loss_ce: 0.007960
2022-01-15 20:35:17,445 iteration 4660 : loss : 0.029113, loss_ce: 0.007094
2022-01-15 20:35:18,448 iteration 4661 : loss : 0.038074, loss_ce: 0.019675
2022-01-15 20:35:19,572 iteration 4662 : loss : 0.027578, loss_ce: 0.015457
2022-01-15 20:35:20,512 iteration 4663 : loss : 0.024787, loss_ce: 0.008491
2022-01-15 20:35:21,525 iteration 4664 : loss : 0.020522, loss_ce: 0.005552
2022-01-15 20:35:22,727 iteration 4665 : loss : 0.039403, loss_ce: 0.014540
2022-01-15 20:35:23,656 iteration 4666 : loss : 0.020144, loss_ce: 0.007353
2022-01-15 20:35:24,628 iteration 4667 : loss : 0.027015, loss_ce: 0.010309
2022-01-15 20:35:25,598 iteration 4668 : loss : 0.027264, loss_ce: 0.006073
2022-01-15 20:35:26,667 iteration 4669 : loss : 0.019198, loss_ce: 0.008194
2022-01-15 20:35:27,736 iteration 4670 : loss : 0.023935, loss_ce: 0.009332
2022-01-15 20:35:28,650 iteration 4671 : loss : 0.019233, loss_ce: 0.005922
2022-01-15 20:35:29,766 iteration 4672 : loss : 0.028459, loss_ce: 0.011442
2022-01-15 20:35:30,789 iteration 4673 : loss : 0.024697, loss_ce: 0.009476
2022-01-15 20:35:31,857 iteration 4674 : loss : 0.022491, loss_ce: 0.011320
2022-01-15 20:35:31,858 Training Data Eval:
2022-01-15 20:35:36,574   Average segmentation loss on training set: 0.0156
2022-01-15 20:35:36,574 Validation Data Eval:
2022-01-15 20:35:38,178   Average segmentation loss on validation set: 0.0781
2022-01-15 20:35:39,155 iteration 4675 : loss : 0.022684, loss_ce: 0.009341
 69%|███████████████████▉         | 275/400 [1:24:47<40:29, 19.44s/it]2022-01-15 20:35:40,299 iteration 4676 : loss : 0.035226, loss_ce: 0.016730
2022-01-15 20:35:41,271 iteration 4677 : loss : 0.025202, loss_ce: 0.010565
2022-01-15 20:35:42,258 iteration 4678 : loss : 0.045939, loss_ce: 0.013235
2022-01-15 20:35:43,263 iteration 4679 : loss : 0.021994, loss_ce: 0.012172
2022-01-15 20:35:44,221 iteration 4680 : loss : 0.020537, loss_ce: 0.006917
2022-01-15 20:35:45,236 iteration 4681 : loss : 0.021583, loss_ce: 0.007185
2022-01-15 20:35:46,180 iteration 4682 : loss : 0.022338, loss_ce: 0.005657
2022-01-15 20:35:47,192 iteration 4683 : loss : 0.030659, loss_ce: 0.011287
2022-01-15 20:35:48,258 iteration 4684 : loss : 0.028322, loss_ce: 0.012719
2022-01-15 20:35:49,293 iteration 4685 : loss : 0.021212, loss_ce: 0.009719
2022-01-15 20:35:50,227 iteration 4686 : loss : 0.019810, loss_ce: 0.006605
2022-01-15 20:35:51,296 iteration 4687 : loss : 0.022396, loss_ce: 0.009205
2022-01-15 20:35:52,380 iteration 4688 : loss : 0.023681, loss_ce: 0.008000
2022-01-15 20:35:53,459 iteration 4689 : loss : 0.038443, loss_ce: 0.019815
2022-01-15 20:35:54,442 iteration 4690 : loss : 0.020188, loss_ce: 0.005282
2022-01-15 20:35:55,392 iteration 4691 : loss : 0.020781, loss_ce: 0.007119
2022-01-15 20:35:56,378 iteration 4692 : loss : 0.021199, loss_ce: 0.008932
 69%|████████████████████         | 276/400 [1:25:04<38:47, 18.77s/it]2022-01-15 20:35:57,468 iteration 4693 : loss : 0.026287, loss_ce: 0.010636
2022-01-15 20:35:58,418 iteration 4694 : loss : 0.019403, loss_ce: 0.005719
2022-01-15 20:35:59,471 iteration 4695 : loss : 0.029133, loss_ce: 0.012776
2022-01-15 20:36:00,483 iteration 4696 : loss : 0.020410, loss_ce: 0.007991
2022-01-15 20:36:01,541 iteration 4697 : loss : 0.030650, loss_ce: 0.013855
2022-01-15 20:36:02,428 iteration 4698 : loss : 0.021203, loss_ce: 0.008780
2022-01-15 20:36:03,410 iteration 4699 : loss : 0.029434, loss_ce: 0.009574
2022-01-15 20:36:04,421 iteration 4700 : loss : 0.026967, loss_ce: 0.009370
2022-01-15 20:36:05,416 iteration 4701 : loss : 0.040672, loss_ce: 0.015148
2022-01-15 20:36:06,308 iteration 4702 : loss : 0.019121, loss_ce: 0.007125
2022-01-15 20:36:07,328 iteration 4703 : loss : 0.024420, loss_ce: 0.009086
2022-01-15 20:36:08,320 iteration 4704 : loss : 0.029136, loss_ce: 0.007370
2022-01-15 20:36:09,245 iteration 4705 : loss : 0.015701, loss_ce: 0.005929
2022-01-15 20:36:10,228 iteration 4706 : loss : 0.019419, loss_ce: 0.007986
2022-01-15 20:36:11,285 iteration 4707 : loss : 0.023361, loss_ce: 0.009691
2022-01-15 20:36:12,267 iteration 4708 : loss : 0.031325, loss_ce: 0.006991
2022-01-15 20:36:13,238 iteration 4709 : loss : 0.017902, loss_ce: 0.007008
 69%|████████████████████         | 277/400 [1:25:21<37:18, 18.20s/it]2022-01-15 20:36:14,377 iteration 4710 : loss : 0.030187, loss_ce: 0.010111
2022-01-15 20:36:15,344 iteration 4711 : loss : 0.022814, loss_ce: 0.010076
2022-01-15 20:36:16,354 iteration 4712 : loss : 0.026143, loss_ce: 0.011486
2022-01-15 20:36:17,324 iteration 4713 : loss : 0.014703, loss_ce: 0.005315
2022-01-15 20:36:18,298 iteration 4714 : loss : 0.016033, loss_ce: 0.006700
2022-01-15 20:36:19,400 iteration 4715 : loss : 0.026324, loss_ce: 0.008336
2022-01-15 20:36:20,412 iteration 4716 : loss : 0.015841, loss_ce: 0.006525
2022-01-15 20:36:21,424 iteration 4717 : loss : 0.030242, loss_ce: 0.008513
2022-01-15 20:36:22,422 iteration 4718 : loss : 0.015806, loss_ce: 0.005712
2022-01-15 20:36:23,401 iteration 4719 : loss : 0.016216, loss_ce: 0.005615
2022-01-15 20:36:24,486 iteration 4720 : loss : 0.017955, loss_ce: 0.006856
2022-01-15 20:36:25,502 iteration 4721 : loss : 0.023828, loss_ce: 0.007764
2022-01-15 20:36:26,523 iteration 4722 : loss : 0.025459, loss_ce: 0.010146
2022-01-15 20:36:27,592 iteration 4723 : loss : 0.038361, loss_ce: 0.010192
2022-01-15 20:36:28,566 iteration 4724 : loss : 0.021589, loss_ce: 0.012090
2022-01-15 20:36:29,571 iteration 4725 : loss : 0.021328, loss_ce: 0.009202
2022-01-15 20:36:30,551 iteration 4726 : loss : 0.027119, loss_ce: 0.009549
 70%|████████████████████▏        | 278/400 [1:25:38<36:27, 17.93s/it]2022-01-15 20:36:31,634 iteration 4727 : loss : 0.018952, loss_ce: 0.006515
2022-01-15 20:36:32,668 iteration 4728 : loss : 0.021317, loss_ce: 0.008344
2022-01-15 20:36:33,706 iteration 4729 : loss : 0.015354, loss_ce: 0.004527
2022-01-15 20:36:34,713 iteration 4730 : loss : 0.018007, loss_ce: 0.006290
2022-01-15 20:36:35,704 iteration 4731 : loss : 0.034941, loss_ce: 0.008978
2022-01-15 20:36:36,637 iteration 4732 : loss : 0.016641, loss_ce: 0.006844
2022-01-15 20:36:37,735 iteration 4733 : loss : 0.039704, loss_ce: 0.018505
2022-01-15 20:36:38,733 iteration 4734 : loss : 0.023659, loss_ce: 0.009947
2022-01-15 20:36:39,670 iteration 4735 : loss : 0.016581, loss_ce: 0.006656
2022-01-15 20:36:40,733 iteration 4736 : loss : 0.022393, loss_ce: 0.008845
2022-01-15 20:36:41,760 iteration 4737 : loss : 0.020645, loss_ce: 0.009800
2022-01-15 20:36:42,904 iteration 4738 : loss : 0.046462, loss_ce: 0.015140
2022-01-15 20:36:43,949 iteration 4739 : loss : 0.031378, loss_ce: 0.013670
2022-01-15 20:36:44,969 iteration 4740 : loss : 0.015418, loss_ce: 0.004041
2022-01-15 20:36:45,971 iteration 4741 : loss : 0.020396, loss_ce: 0.008916
2022-01-15 20:36:46,997 iteration 4742 : loss : 0.026858, loss_ce: 0.011736
2022-01-15 20:36:48,184 iteration 4743 : loss : 0.033782, loss_ce: 0.015517
 70%|████████████████████▏        | 279/400 [1:25:56<35:58, 17.84s/it]2022-01-15 20:36:49,301 iteration 4744 : loss : 0.020178, loss_ce: 0.006335
2022-01-15 20:36:50,316 iteration 4745 : loss : 0.026614, loss_ce: 0.011037
2022-01-15 20:36:51,307 iteration 4746 : loss : 0.028123, loss_ce: 0.009099
2022-01-15 20:36:52,230 iteration 4747 : loss : 0.026090, loss_ce: 0.015069
2022-01-15 20:36:53,327 iteration 4748 : loss : 0.021263, loss_ce: 0.008131
2022-01-15 20:36:54,255 iteration 4749 : loss : 0.027185, loss_ce: 0.011953
2022-01-15 20:36:55,269 iteration 4750 : loss : 0.033887, loss_ce: 0.011034
2022-01-15 20:36:56,293 iteration 4751 : loss : 0.027361, loss_ce: 0.011914
2022-01-15 20:36:57,289 iteration 4752 : loss : 0.030274, loss_ce: 0.008631
2022-01-15 20:36:58,256 iteration 4753 : loss : 0.013318, loss_ce: 0.004407
2022-01-15 20:36:59,263 iteration 4754 : loss : 0.019125, loss_ce: 0.009330
2022-01-15 20:37:00,349 iteration 4755 : loss : 0.038436, loss_ce: 0.010470
2022-01-15 20:37:01,378 iteration 4756 : loss : 0.022870, loss_ce: 0.006773
2022-01-15 20:37:02,378 iteration 4757 : loss : 0.017956, loss_ce: 0.009154
2022-01-15 20:37:03,452 iteration 4758 : loss : 0.021071, loss_ce: 0.008117
2022-01-15 20:37:04,431 iteration 4759 : loss : 0.024794, loss_ce: 0.014560
2022-01-15 20:37:04,432 Training Data Eval:
2022-01-15 20:37:09,168   Average segmentation loss on training set: 0.0134
2022-01-15 20:37:09,168 Validation Data Eval:
2022-01-15 20:37:10,773   Average segmentation loss on validation set: 0.0912
2022-01-15 20:37:11,800 iteration 4760 : loss : 0.024503, loss_ce: 0.007482
 70%|████████████████████▎        | 280/400 [1:26:19<39:08, 19.57s/it]2022-01-15 20:37:12,797 iteration 4761 : loss : 0.019410, loss_ce: 0.007765
2022-01-15 20:37:13,877 iteration 4762 : loss : 0.024930, loss_ce: 0.007435
2022-01-15 20:37:14,877 iteration 4763 : loss : 0.022421, loss_ce: 0.009223
2022-01-15 20:37:15,791 iteration 4764 : loss : 0.018452, loss_ce: 0.007351
2022-01-15 20:37:16,755 iteration 4765 : loss : 0.023048, loss_ce: 0.009230
2022-01-15 20:37:17,703 iteration 4766 : loss : 0.020144, loss_ce: 0.006256
2022-01-15 20:37:18,753 iteration 4767 : loss : 0.026202, loss_ce: 0.009831
2022-01-15 20:37:19,852 iteration 4768 : loss : 0.025212, loss_ce: 0.011580
2022-01-15 20:37:20,919 iteration 4769 : loss : 0.024693, loss_ce: 0.006677
2022-01-15 20:37:21,911 iteration 4770 : loss : 0.020935, loss_ce: 0.010576
2022-01-15 20:37:22,852 iteration 4771 : loss : 0.017261, loss_ce: 0.007386
2022-01-15 20:37:23,820 iteration 4772 : loss : 0.015953, loss_ce: 0.005019
2022-01-15 20:37:24,777 iteration 4773 : loss : 0.018157, loss_ce: 0.007164
2022-01-15 20:37:25,727 iteration 4774 : loss : 0.015903, loss_ce: 0.007058
2022-01-15 20:37:26,731 iteration 4775 : loss : 0.018801, loss_ce: 0.007446
2022-01-15 20:37:27,711 iteration 4776 : loss : 0.020386, loss_ce: 0.007587
2022-01-15 20:37:28,685 iteration 4777 : loss : 0.015943, loss_ce: 0.005500
 70%|████████████████████▎        | 281/400 [1:26:36<37:13, 18.77s/it]2022-01-15 20:37:29,802 iteration 4778 : loss : 0.021009, loss_ce: 0.006851
2022-01-15 20:37:30,741 iteration 4779 : loss : 0.015997, loss_ce: 0.005323
2022-01-15 20:37:31,686 iteration 4780 : loss : 0.023686, loss_ce: 0.006385
2022-01-15 20:37:32,633 iteration 4781 : loss : 0.017797, loss_ce: 0.008717
2022-01-15 20:37:33,670 iteration 4782 : loss : 0.021985, loss_ce: 0.007480
2022-01-15 20:37:34,584 iteration 4783 : loss : 0.017769, loss_ce: 0.004821
2022-01-15 20:37:35,637 iteration 4784 : loss : 0.018998, loss_ce: 0.006918
2022-01-15 20:37:36,705 iteration 4785 : loss : 0.024819, loss_ce: 0.011378
2022-01-15 20:37:37,689 iteration 4786 : loss : 0.016057, loss_ce: 0.005827
2022-01-15 20:37:38,722 iteration 4787 : loss : 0.048363, loss_ce: 0.007885
2022-01-15 20:37:39,732 iteration 4788 : loss : 0.017467, loss_ce: 0.007144
2022-01-15 20:37:40,745 iteration 4789 : loss : 0.016285, loss_ce: 0.006329
2022-01-15 20:37:41,744 iteration 4790 : loss : 0.020171, loss_ce: 0.008572
2022-01-15 20:37:42,710 iteration 4791 : loss : 0.017124, loss_ce: 0.006285
2022-01-15 20:37:43,703 iteration 4792 : loss : 0.032865, loss_ce: 0.014361
2022-01-15 20:37:44,738 iteration 4793 : loss : 0.021476, loss_ce: 0.013251
2022-01-15 20:37:45,725 iteration 4794 : loss : 0.028731, loss_ce: 0.006133
 70%|████████████████████▍        | 282/400 [1:26:53<35:53, 18.25s/it]2022-01-15 20:37:46,721 iteration 4795 : loss : 0.016414, loss_ce: 0.005091
2022-01-15 20:37:47,666 iteration 4796 : loss : 0.020051, loss_ce: 0.007847
2022-01-15 20:37:48,622 iteration 4797 : loss : 0.015809, loss_ce: 0.005790
2022-01-15 20:37:49,693 iteration 4798 : loss : 0.027726, loss_ce: 0.012919
2022-01-15 20:37:50,695 iteration 4799 : loss : 0.025659, loss_ce: 0.006934
2022-01-15 20:37:51,709 iteration 4800 : loss : 0.039652, loss_ce: 0.020464
2022-01-15 20:37:52,713 iteration 4801 : loss : 0.017398, loss_ce: 0.006951
2022-01-15 20:37:53,610 iteration 4802 : loss : 0.016820, loss_ce: 0.005305
2022-01-15 20:37:54,614 iteration 4803 : loss : 0.020532, loss_ce: 0.009173
2022-01-15 20:37:55,571 iteration 4804 : loss : 0.025048, loss_ce: 0.006772
2022-01-15 20:37:56,591 iteration 4805 : loss : 0.018952, loss_ce: 0.006371
2022-01-15 20:37:57,538 iteration 4806 : loss : 0.020316, loss_ce: 0.005224
2022-01-15 20:37:58,613 iteration 4807 : loss : 0.020892, loss_ce: 0.008079
2022-01-15 20:37:59,821 iteration 4808 : loss : 0.027332, loss_ce: 0.010747
2022-01-15 20:38:00,711 iteration 4809 : loss : 0.016032, loss_ce: 0.006832
2022-01-15 20:38:01,751 iteration 4810 : loss : 0.026328, loss_ce: 0.009188
2022-01-15 20:38:02,720 iteration 4811 : loss : 0.015592, loss_ce: 0.005922
 71%|████████████████████▌        | 283/400 [1:27:10<34:51, 17.87s/it]2022-01-15 20:38:03,735 iteration 4812 : loss : 0.018014, loss_ce: 0.006771
2022-01-15 20:38:04,736 iteration 4813 : loss : 0.018175, loss_ce: 0.006643
2022-01-15 20:38:05,680 iteration 4814 : loss : 0.018289, loss_ce: 0.009167
2022-01-15 20:38:06,684 iteration 4815 : loss : 0.017912, loss_ce: 0.006298
2022-01-15 20:38:07,639 iteration 4816 : loss : 0.018189, loss_ce: 0.006747
2022-01-15 20:38:08,505 iteration 4817 : loss : 0.016680, loss_ce: 0.005612
2022-01-15 20:38:09,543 iteration 4818 : loss : 0.030132, loss_ce: 0.015334
2022-01-15 20:38:10,553 iteration 4819 : loss : 0.025485, loss_ce: 0.008091
2022-01-15 20:38:11,607 iteration 4820 : loss : 0.020374, loss_ce: 0.009140
2022-01-15 20:38:12,581 iteration 4821 : loss : 0.013619, loss_ce: 0.005446
2022-01-15 20:38:13,597 iteration 4822 : loss : 0.021702, loss_ce: 0.006648
2022-01-15 20:38:14,562 iteration 4823 : loss : 0.019711, loss_ce: 0.007482
2022-01-15 20:38:15,633 iteration 4824 : loss : 0.020175, loss_ce: 0.006776
2022-01-15 20:38:16,629 iteration 4825 : loss : 0.012704, loss_ce: 0.003891
2022-01-15 20:38:17,605 iteration 4826 : loss : 0.025615, loss_ce: 0.008191
2022-01-15 20:38:18,719 iteration 4827 : loss : 0.019771, loss_ce: 0.006426
2022-01-15 20:38:19,784 iteration 4828 : loss : 0.021949, loss_ce: 0.008222
 71%|████████████████████▌        | 284/400 [1:27:27<34:05, 17.63s/it]2022-01-15 20:38:20,877 iteration 4829 : loss : 0.019563, loss_ce: 0.007310
2022-01-15 20:38:21,805 iteration 4830 : loss : 0.020012, loss_ce: 0.006366
2022-01-15 20:38:22,893 iteration 4831 : loss : 0.035003, loss_ce: 0.011529
2022-01-15 20:38:23,872 iteration 4832 : loss : 0.021246, loss_ce: 0.008817
2022-01-15 20:38:24,931 iteration 4833 : loss : 0.015685, loss_ce: 0.004213
2022-01-15 20:38:26,020 iteration 4834 : loss : 0.018106, loss_ce: 0.006756
2022-01-15 20:38:27,004 iteration 4835 : loss : 0.019308, loss_ce: 0.006981
2022-01-15 20:38:28,000 iteration 4836 : loss : 0.018535, loss_ce: 0.006351
2022-01-15 20:38:28,949 iteration 4837 : loss : 0.020772, loss_ce: 0.004854
2022-01-15 20:38:29,990 iteration 4838 : loss : 0.024500, loss_ce: 0.010369
2022-01-15 20:38:31,020 iteration 4839 : loss : 0.018824, loss_ce: 0.009110
2022-01-15 20:38:32,032 iteration 4840 : loss : 0.020322, loss_ce: 0.007445
2022-01-15 20:38:33,111 iteration 4841 : loss : 0.019431, loss_ce: 0.006656
2022-01-15 20:38:34,135 iteration 4842 : loss : 0.020016, loss_ce: 0.008590
2022-01-15 20:38:35,132 iteration 4843 : loss : 0.019331, loss_ce: 0.008273
2022-01-15 20:38:36,060 iteration 4844 : loss : 0.016020, loss_ce: 0.007525
2022-01-15 20:38:36,060 Training Data Eval:
2022-01-15 20:38:40,838   Average segmentation loss on training set: 0.0120
2022-01-15 20:38:40,838 Validation Data Eval:
2022-01-15 20:38:42,455   Average segmentation loss on validation set: 0.0685
2022-01-15 20:38:43,415 iteration 4845 : loss : 0.018683, loss_ce: 0.006435
 71%|████████████████████▋        | 285/400 [1:27:51<37:14, 19.43s/it]2022-01-15 20:38:44,489 iteration 4846 : loss : 0.016819, loss_ce: 0.005766
2022-01-15 20:38:45,452 iteration 4847 : loss : 0.025566, loss_ce: 0.008134
2022-01-15 20:38:46,538 iteration 4848 : loss : 0.022840, loss_ce: 0.010125
2022-01-15 20:38:47,497 iteration 4849 : loss : 0.018465, loss_ce: 0.007947
2022-01-15 20:38:48,520 iteration 4850 : loss : 0.031038, loss_ce: 0.007164
2022-01-15 20:38:49,544 iteration 4851 : loss : 0.016921, loss_ce: 0.007802
2022-01-15 20:38:50,499 iteration 4852 : loss : 0.020599, loss_ce: 0.008265
2022-01-15 20:38:51,458 iteration 4853 : loss : 0.017375, loss_ce: 0.006461
2022-01-15 20:38:52,371 iteration 4854 : loss : 0.021510, loss_ce: 0.007185
2022-01-15 20:38:53,368 iteration 4855 : loss : 0.018700, loss_ce: 0.007451
2022-01-15 20:38:54,383 iteration 4856 : loss : 0.020847, loss_ce: 0.008305
2022-01-15 20:38:55,416 iteration 4857 : loss : 0.019747, loss_ce: 0.010279
2022-01-15 20:38:56,413 iteration 4858 : loss : 0.020981, loss_ce: 0.008392
2022-01-15 20:38:57,342 iteration 4859 : loss : 0.014281, loss_ce: 0.005320
2022-01-15 20:38:58,310 iteration 4860 : loss : 0.017890, loss_ce: 0.004583
2022-01-15 20:38:59,228 iteration 4861 : loss : 0.020268, loss_ce: 0.005784
2022-01-15 20:39:00,312 iteration 4862 : loss : 0.019176, loss_ce: 0.006192
 72%|████████████████████▋        | 286/400 [1:28:08<35:28, 18.67s/it]2022-01-15 20:39:01,395 iteration 4863 : loss : 0.021876, loss_ce: 0.007569
2022-01-15 20:39:02,414 iteration 4864 : loss : 0.023571, loss_ce: 0.007558
2022-01-15 20:39:03,415 iteration 4865 : loss : 0.019186, loss_ce: 0.007175
2022-01-15 20:39:04,405 iteration 4866 : loss : 0.021444, loss_ce: 0.009192
2022-01-15 20:39:05,423 iteration 4867 : loss : 0.032861, loss_ce: 0.011776
2022-01-15 20:39:06,426 iteration 4868 : loss : 0.025323, loss_ce: 0.012909
2022-01-15 20:39:07,382 iteration 4869 : loss : 0.017618, loss_ce: 0.005876
2022-01-15 20:39:08,272 iteration 4870 : loss : 0.014326, loss_ce: 0.005328
2022-01-15 20:39:09,233 iteration 4871 : loss : 0.018928, loss_ce: 0.006131
2022-01-15 20:39:10,233 iteration 4872 : loss : 0.018080, loss_ce: 0.007497
2022-01-15 20:39:11,230 iteration 4873 : loss : 0.022120, loss_ce: 0.007573
2022-01-15 20:39:12,228 iteration 4874 : loss : 0.016816, loss_ce: 0.005969
2022-01-15 20:39:13,187 iteration 4875 : loss : 0.019113, loss_ce: 0.005636
2022-01-15 20:39:14,087 iteration 4876 : loss : 0.015545, loss_ce: 0.006537
2022-01-15 20:39:15,053 iteration 4877 : loss : 0.015552, loss_ce: 0.005106
2022-01-15 20:39:16,047 iteration 4878 : loss : 0.021991, loss_ce: 0.008541
2022-01-15 20:39:17,085 iteration 4879 : loss : 0.015497, loss_ce: 0.004833
 72%|████████████████████▊        | 287/400 [1:28:25<34:05, 18.10s/it]2022-01-15 20:39:18,154 iteration 4880 : loss : 0.016512, loss_ce: 0.005438
2022-01-15 20:39:19,066 iteration 4881 : loss : 0.022350, loss_ce: 0.007321
2022-01-15 20:39:19,980 iteration 4882 : loss : 0.016812, loss_ce: 0.004165
2022-01-15 20:39:20,994 iteration 4883 : loss : 0.020551, loss_ce: 0.010372
2022-01-15 20:39:21,931 iteration 4884 : loss : 0.018595, loss_ce: 0.008094
2022-01-15 20:39:22,921 iteration 4885 : loss : 0.016409, loss_ce: 0.004673
2022-01-15 20:39:23,943 iteration 4886 : loss : 0.017413, loss_ce: 0.005634
2022-01-15 20:39:24,895 iteration 4887 : loss : 0.018798, loss_ce: 0.007074
2022-01-15 20:39:25,888 iteration 4888 : loss : 0.031375, loss_ce: 0.009982
2022-01-15 20:39:26,855 iteration 4889 : loss : 0.014783, loss_ce: 0.005778
2022-01-15 20:39:27,855 iteration 4890 : loss : 0.022044, loss_ce: 0.008071
2022-01-15 20:39:28,853 iteration 4891 : loss : 0.021651, loss_ce: 0.010655
2022-01-15 20:39:29,857 iteration 4892 : loss : 0.018477, loss_ce: 0.009172
2022-01-15 20:39:31,021 iteration 4893 : loss : 0.026909, loss_ce: 0.010338
2022-01-15 20:39:32,001 iteration 4894 : loss : 0.018484, loss_ce: 0.008517
2022-01-15 20:39:33,001 iteration 4895 : loss : 0.018067, loss_ce: 0.007791
2022-01-15 20:39:33,970 iteration 4896 : loss : 0.018001, loss_ce: 0.006599
 72%|████████████████████▉        | 288/400 [1:28:41<33:06, 17.74s/it]2022-01-15 20:39:34,948 iteration 4897 : loss : 0.012441, loss_ce: 0.005969
2022-01-15 20:39:35,923 iteration 4898 : loss : 0.013464, loss_ce: 0.004703
2022-01-15 20:39:36,864 iteration 4899 : loss : 0.019810, loss_ce: 0.009336
2022-01-15 20:39:37,922 iteration 4900 : loss : 0.030391, loss_ce: 0.011733
2022-01-15 20:39:38,925 iteration 4901 : loss : 0.018373, loss_ce: 0.005872
2022-01-15 20:39:39,868 iteration 4902 : loss : 0.016467, loss_ce: 0.003212
2022-01-15 20:39:40,868 iteration 4903 : loss : 0.014897, loss_ce: 0.005781
2022-01-15 20:39:41,848 iteration 4904 : loss : 0.019952, loss_ce: 0.010102
2022-01-15 20:39:42,817 iteration 4905 : loss : 0.018789, loss_ce: 0.009248
2022-01-15 20:39:43,787 iteration 4906 : loss : 0.016770, loss_ce: 0.005793
2022-01-15 20:39:44,789 iteration 4907 : loss : 0.021926, loss_ce: 0.007935
2022-01-15 20:39:45,681 iteration 4908 : loss : 0.021702, loss_ce: 0.005500
2022-01-15 20:39:46,664 iteration 4909 : loss : 0.021929, loss_ce: 0.006683
2022-01-15 20:39:47,615 iteration 4910 : loss : 0.017703, loss_ce: 0.004134
2022-01-15 20:39:48,683 iteration 4911 : loss : 0.021296, loss_ce: 0.008429
2022-01-15 20:39:49,731 iteration 4912 : loss : 0.034825, loss_ce: 0.009120
2022-01-15 20:39:50,673 iteration 4913 : loss : 0.021983, loss_ce: 0.007223
 72%|████████████████████▉        | 289/400 [1:28:58<32:14, 17.43s/it]2022-01-15 20:39:51,646 iteration 4914 : loss : 0.020681, loss_ce: 0.006636
2022-01-15 20:39:52,672 iteration 4915 : loss : 0.024014, loss_ce: 0.009499
2022-01-15 20:39:53,676 iteration 4916 : loss : 0.024000, loss_ce: 0.006214
2022-01-15 20:39:54,654 iteration 4917 : loss : 0.015989, loss_ce: 0.005859
2022-01-15 20:39:55,591 iteration 4918 : loss : 0.026014, loss_ce: 0.012714
2022-01-15 20:39:56,524 iteration 4919 : loss : 0.016192, loss_ce: 0.006123
2022-01-15 20:39:57,535 iteration 4920 : loss : 0.017711, loss_ce: 0.008010
2022-01-15 20:39:58,491 iteration 4921 : loss : 0.019919, loss_ce: 0.004505
2022-01-15 20:39:59,457 iteration 4922 : loss : 0.024208, loss_ce: 0.004486
2022-01-15 20:40:00,446 iteration 4923 : loss : 0.030877, loss_ce: 0.010651
2022-01-15 20:40:01,462 iteration 4924 : loss : 0.025680, loss_ce: 0.009715
2022-01-15 20:40:02,583 iteration 4925 : loss : 0.023674, loss_ce: 0.010473
2022-01-15 20:40:03,540 iteration 4926 : loss : 0.019920, loss_ce: 0.007071
2022-01-15 20:40:04,591 iteration 4927 : loss : 0.020315, loss_ce: 0.007336
2022-01-15 20:40:05,654 iteration 4928 : loss : 0.034838, loss_ce: 0.018092
2022-01-15 20:40:06,700 iteration 4929 : loss : 0.028379, loss_ce: 0.009089
2022-01-15 20:40:06,700 Training Data Eval:
2022-01-15 20:40:11,452   Average segmentation loss on training set: 0.0127
2022-01-15 20:40:11,452 Validation Data Eval:
2022-01-15 20:40:13,084   Average segmentation loss on validation set: 0.0657
2022-01-15 20:40:14,100 iteration 4930 : loss : 0.014857, loss_ce: 0.005902
 72%|█████████████████████        | 290/400 [1:29:22<35:15, 19.23s/it]2022-01-15 20:40:15,206 iteration 4931 : loss : 0.021653, loss_ce: 0.009071
2022-01-15 20:40:16,156 iteration 4932 : loss : 0.016437, loss_ce: 0.006672
2022-01-15 20:40:17,092 iteration 4933 : loss : 0.020830, loss_ce: 0.007488
2022-01-15 20:40:18,092 iteration 4934 : loss : 0.019463, loss_ce: 0.009256
2022-01-15 20:40:19,125 iteration 4935 : loss : 0.023967, loss_ce: 0.007444
2022-01-15 20:40:20,119 iteration 4936 : loss : 0.018362, loss_ce: 0.008283
2022-01-15 20:40:21,132 iteration 4937 : loss : 0.019332, loss_ce: 0.007181
2022-01-15 20:40:22,112 iteration 4938 : loss : 0.022325, loss_ce: 0.007862
2022-01-15 20:40:23,149 iteration 4939 : loss : 0.021963, loss_ce: 0.009033
2022-01-15 20:40:24,074 iteration 4940 : loss : 0.026192, loss_ce: 0.007992
2022-01-15 20:40:25,050 iteration 4941 : loss : 0.015845, loss_ce: 0.005441
2022-01-15 20:40:26,081 iteration 4942 : loss : 0.018891, loss_ce: 0.007293
2022-01-15 20:40:27,027 iteration 4943 : loss : 0.012473, loss_ce: 0.003918
2022-01-15 20:40:28,014 iteration 4944 : loss : 0.028854, loss_ce: 0.011575
2022-01-15 20:40:29,092 iteration 4945 : loss : 0.021448, loss_ce: 0.005295
2022-01-15 20:40:30,131 iteration 4946 : loss : 0.034537, loss_ce: 0.018266
2022-01-15 20:40:31,219 iteration 4947 : loss : 0.037395, loss_ce: 0.013239
 73%|█████████████████████        | 291/400 [1:29:39<33:46, 18.60s/it]2022-01-15 20:40:32,331 iteration 4948 : loss : 0.019454, loss_ce: 0.006912
2022-01-15 20:40:33,281 iteration 4949 : loss : 0.015326, loss_ce: 0.005790
2022-01-15 20:40:34,213 iteration 4950 : loss : 0.016564, loss_ce: 0.005670
2022-01-15 20:40:35,185 iteration 4951 : loss : 0.024393, loss_ce: 0.008129
2022-01-15 20:40:36,092 iteration 4952 : loss : 0.020011, loss_ce: 0.007870
2022-01-15 20:40:37,136 iteration 4953 : loss : 0.018273, loss_ce: 0.008013
2022-01-15 20:40:38,069 iteration 4954 : loss : 0.017260, loss_ce: 0.006415
2022-01-15 20:40:39,041 iteration 4955 : loss : 0.016254, loss_ce: 0.006488
2022-01-15 20:40:40,008 iteration 4956 : loss : 0.019946, loss_ce: 0.006540
2022-01-15 20:40:40,992 iteration 4957 : loss : 0.014361, loss_ce: 0.005730
2022-01-15 20:40:41,998 iteration 4958 : loss : 0.027078, loss_ce: 0.012112
2022-01-15 20:40:42,904 iteration 4959 : loss : 0.015006, loss_ce: 0.004744
2022-01-15 20:40:43,902 iteration 4960 : loss : 0.021645, loss_ce: 0.006832
2022-01-15 20:40:44,854 iteration 4961 : loss : 0.017768, loss_ce: 0.006418
2022-01-15 20:40:45,901 iteration 4962 : loss : 0.020921, loss_ce: 0.008763
2022-01-15 20:40:46,846 iteration 4963 : loss : 0.023081, loss_ce: 0.009231
2022-01-15 20:40:47,937 iteration 4964 : loss : 0.028818, loss_ce: 0.009618
 73%|█████████████████████▏       | 292/400 [1:29:55<32:27, 18.03s/it]2022-01-15 20:40:49,084 iteration 4965 : loss : 0.024563, loss_ce: 0.008024
2022-01-15 20:40:50,203 iteration 4966 : loss : 0.023780, loss_ce: 0.006692
2022-01-15 20:40:51,128 iteration 4967 : loss : 0.014740, loss_ce: 0.006092
2022-01-15 20:40:52,120 iteration 4968 : loss : 0.016686, loss_ce: 0.006842
2022-01-15 20:40:53,085 iteration 4969 : loss : 0.015334, loss_ce: 0.003347
2022-01-15 20:40:54,035 iteration 4970 : loss : 0.016573, loss_ce: 0.007128
2022-01-15 20:40:55,076 iteration 4971 : loss : 0.022527, loss_ce: 0.008939
2022-01-15 20:40:56,129 iteration 4972 : loss : 0.019294, loss_ce: 0.006390
2022-01-15 20:40:57,089 iteration 4973 : loss : 0.015512, loss_ce: 0.005838
2022-01-15 20:40:58,047 iteration 4974 : loss : 0.021088, loss_ce: 0.007639
2022-01-15 20:40:59,017 iteration 4975 : loss : 0.023274, loss_ce: 0.007193
2022-01-15 20:40:59,989 iteration 4976 : loss : 0.040580, loss_ce: 0.016107
2022-01-15 20:41:01,086 iteration 4977 : loss : 0.027865, loss_ce: 0.016837
2022-01-15 20:41:02,073 iteration 4978 : loss : 0.035408, loss_ce: 0.009686
2022-01-15 20:41:03,070 iteration 4979 : loss : 0.019737, loss_ce: 0.009516
2022-01-15 20:41:03,957 iteration 4980 : loss : 0.014971, loss_ce: 0.005767
2022-01-15 20:41:04,947 iteration 4981 : loss : 0.033482, loss_ce: 0.010164
 73%|█████████████████████▏       | 293/400 [1:30:12<31:36, 17.72s/it]2022-01-15 20:41:05,977 iteration 4982 : loss : 0.019139, loss_ce: 0.008062
2022-01-15 20:41:06,932 iteration 4983 : loss : 0.018817, loss_ce: 0.006991
2022-01-15 20:41:07,987 iteration 4984 : loss : 0.026179, loss_ce: 0.009169
2022-01-15 20:41:08,990 iteration 4985 : loss : 0.018502, loss_ce: 0.005772
2022-01-15 20:41:10,064 iteration 4986 : loss : 0.025028, loss_ce: 0.012527
2022-01-15 20:41:11,017 iteration 4987 : loss : 0.020829, loss_ce: 0.008996
2022-01-15 20:41:11,977 iteration 4988 : loss : 0.021733, loss_ce: 0.010345
2022-01-15 20:41:12,938 iteration 4989 : loss : 0.022328, loss_ce: 0.008778
2022-01-15 20:41:14,020 iteration 4990 : loss : 0.021840, loss_ce: 0.007674
2022-01-15 20:41:15,014 iteration 4991 : loss : 0.025989, loss_ce: 0.007519
2022-01-15 20:41:16,011 iteration 4992 : loss : 0.018446, loss_ce: 0.007987
2022-01-15 20:41:17,075 iteration 4993 : loss : 0.018913, loss_ce: 0.007878
2022-01-15 20:41:18,171 iteration 4994 : loss : 0.023497, loss_ce: 0.006551
2022-01-15 20:41:19,161 iteration 4995 : loss : 0.030224, loss_ce: 0.011845
2022-01-15 20:41:20,144 iteration 4996 : loss : 0.023330, loss_ce: 0.008226
2022-01-15 20:41:21,221 iteration 4997 : loss : 0.026417, loss_ce: 0.011057
2022-01-15 20:41:22,163 iteration 4998 : loss : 0.017536, loss_ce: 0.006441
 74%|█████████████████████▎       | 294/400 [1:30:30<31:02, 17.58s/it]2022-01-15 20:41:23,264 iteration 4999 : loss : 0.019891, loss_ce: 0.009508
2022-01-15 20:41:24,186 iteration 5000 : loss : 0.014810, loss_ce: 0.004981
2022-01-15 20:41:25,153 iteration 5001 : loss : 0.031377, loss_ce: 0.010846
2022-01-15 20:41:26,190 iteration 5002 : loss : 0.020646, loss_ce: 0.008315
2022-01-15 20:41:27,159 iteration 5003 : loss : 0.021966, loss_ce: 0.006073
2022-01-15 20:41:28,238 iteration 5004 : loss : 0.024631, loss_ce: 0.009021
2022-01-15 20:41:29,207 iteration 5005 : loss : 0.015521, loss_ce: 0.005123
2022-01-15 20:41:30,261 iteration 5006 : loss : 0.015636, loss_ce: 0.004567
2022-01-15 20:41:31,246 iteration 5007 : loss : 0.017821, loss_ce: 0.007414
2022-01-15 20:41:32,197 iteration 5008 : loss : 0.019014, loss_ce: 0.006656
2022-01-15 20:41:33,214 iteration 5009 : loss : 0.048042, loss_ce: 0.013581
2022-01-15 20:41:34,349 iteration 5010 : loss : 0.040585, loss_ce: 0.016125
2022-01-15 20:41:35,382 iteration 5011 : loss : 0.017250, loss_ce: 0.010125
2022-01-15 20:41:36,477 iteration 5012 : loss : 0.022117, loss_ce: 0.009237
2022-01-15 20:41:37,679 iteration 5013 : loss : 0.017863, loss_ce: 0.006901
2022-01-15 20:41:38,606 iteration 5014 : loss : 0.017458, loss_ce: 0.006419
2022-01-15 20:41:38,606 Training Data Eval:
2022-01-15 20:41:43,559   Average segmentation loss on training set: 0.0128
2022-01-15 20:41:43,559 Validation Data Eval:
2022-01-15 20:41:45,248   Average segmentation loss on validation set: 0.0743
2022-01-15 20:41:46,267 iteration 5015 : loss : 0.017915, loss_ce: 0.003726
 74%|█████████████████████▍       | 295/400 [1:30:54<34:10, 19.53s/it]2022-01-15 20:41:47,314 iteration 5016 : loss : 0.019627, loss_ce: 0.007456
2022-01-15 20:41:48,309 iteration 5017 : loss : 0.017383, loss_ce: 0.005091
2022-01-15 20:41:49,489 iteration 5018 : loss : 0.030190, loss_ce: 0.010544
2022-01-15 20:41:50,442 iteration 5019 : loss : 0.019124, loss_ce: 0.005268
2022-01-15 20:41:51,473 iteration 5020 : loss : 0.015850, loss_ce: 0.006042
2022-01-15 20:41:52,567 iteration 5021 : loss : 0.017195, loss_ce: 0.005869
2022-01-15 20:41:53,646 iteration 5022 : loss : 0.025013, loss_ce: 0.012038
2022-01-15 20:41:54,689 iteration 5023 : loss : 0.016162, loss_ce: 0.006448
2022-01-15 20:41:55,671 iteration 5024 : loss : 0.013185, loss_ce: 0.004772
2022-01-15 20:41:56,641 iteration 5025 : loss : 0.015244, loss_ce: 0.005590
2022-01-15 20:41:57,657 iteration 5026 : loss : 0.023249, loss_ce: 0.009639
2022-01-15 20:41:58,669 iteration 5027 : loss : 0.017250, loss_ce: 0.006397
2022-01-15 20:41:59,701 iteration 5028 : loss : 0.022598, loss_ce: 0.009004
2022-01-15 20:42:00,666 iteration 5029 : loss : 0.017343, loss_ce: 0.007399
2022-01-15 20:42:01,711 iteration 5030 : loss : 0.021025, loss_ce: 0.006793
2022-01-15 20:42:02,810 iteration 5031 : loss : 0.023280, loss_ce: 0.009962
2022-01-15 20:42:03,901 iteration 5032 : loss : 0.016949, loss_ce: 0.006001
 74%|█████████████████████▍       | 296/400 [1:31:11<32:52, 18.97s/it]2022-01-15 20:42:05,017 iteration 5033 : loss : 0.019585, loss_ce: 0.009702
2022-01-15 20:42:06,004 iteration 5034 : loss : 0.022187, loss_ce: 0.005871
2022-01-15 20:42:06,977 iteration 5035 : loss : 0.017694, loss_ce: 0.005920
2022-01-15 20:42:07,910 iteration 5036 : loss : 0.014314, loss_ce: 0.005031
2022-01-15 20:42:08,887 iteration 5037 : loss : 0.014328, loss_ce: 0.005150
2022-01-15 20:42:10,043 iteration 5038 : loss : 0.022649, loss_ce: 0.010371
2022-01-15 20:42:11,012 iteration 5039 : loss : 0.016076, loss_ce: 0.004933
2022-01-15 20:42:12,051 iteration 5040 : loss : 0.024024, loss_ce: 0.009465
2022-01-15 20:42:13,038 iteration 5041 : loss : 0.014950, loss_ce: 0.005230
2022-01-15 20:42:14,015 iteration 5042 : loss : 0.018134, loss_ce: 0.006835
2022-01-15 20:42:14,969 iteration 5043 : loss : 0.017401, loss_ce: 0.005822
2022-01-15 20:42:15,971 iteration 5044 : loss : 0.013726, loss_ce: 0.004356
2022-01-15 20:42:16,865 iteration 5045 : loss : 0.017472, loss_ce: 0.004935
2022-01-15 20:42:17,874 iteration 5046 : loss : 0.020222, loss_ce: 0.006543
2022-01-15 20:42:18,842 iteration 5047 : loss : 0.017612, loss_ce: 0.006857
2022-01-15 20:42:19,775 iteration 5048 : loss : 0.015643, loss_ce: 0.005761
2022-01-15 20:42:20,848 iteration 5049 : loss : 0.019690, loss_ce: 0.008483
 74%|█████████████████████▌       | 297/400 [1:31:28<31:30, 18.36s/it]2022-01-15 20:42:21,881 iteration 5050 : loss : 0.021235, loss_ce: 0.006417
2022-01-15 20:42:22,801 iteration 5051 : loss : 0.014846, loss_ce: 0.006082
2022-01-15 20:42:23,825 iteration 5052 : loss : 0.017478, loss_ce: 0.008797
2022-01-15 20:42:24,757 iteration 5053 : loss : 0.015847, loss_ce: 0.005756
2022-01-15 20:42:25,772 iteration 5054 : loss : 0.013209, loss_ce: 0.005483
2022-01-15 20:42:26,731 iteration 5055 : loss : 0.013276, loss_ce: 0.004788
2022-01-15 20:42:27,703 iteration 5056 : loss : 0.024126, loss_ce: 0.007592
2022-01-15 20:42:28,690 iteration 5057 : loss : 0.018382, loss_ce: 0.007922
2022-01-15 20:42:29,651 iteration 5058 : loss : 0.029566, loss_ce: 0.014263
2022-01-15 20:42:30,647 iteration 5059 : loss : 0.016044, loss_ce: 0.007181
2022-01-15 20:42:31,705 iteration 5060 : loss : 0.021613, loss_ce: 0.005578
2022-01-15 20:42:32,710 iteration 5061 : loss : 0.016932, loss_ce: 0.007989
2022-01-15 20:42:33,782 iteration 5062 : loss : 0.016805, loss_ce: 0.006352
2022-01-15 20:42:34,752 iteration 5063 : loss : 0.015129, loss_ce: 0.005864
2022-01-15 20:42:35,771 iteration 5064 : loss : 0.029215, loss_ce: 0.007315
2022-01-15 20:42:36,853 iteration 5065 : loss : 0.028052, loss_ce: 0.008913
2022-01-15 20:42:37,736 iteration 5066 : loss : 0.016495, loss_ce: 0.006997
 74%|█████████████████████▌       | 298/400 [1:31:45<30:27, 17.91s/it]2022-01-15 20:42:38,917 iteration 5067 : loss : 0.016662, loss_ce: 0.005386
2022-01-15 20:42:39,897 iteration 5068 : loss : 0.016544, loss_ce: 0.005234
2022-01-15 20:42:40,853 iteration 5069 : loss : 0.022597, loss_ce: 0.007364
2022-01-15 20:42:41,828 iteration 5070 : loss : 0.016690, loss_ce: 0.008297
2022-01-15 20:42:42,884 iteration 5071 : loss : 0.020783, loss_ce: 0.009021
2022-01-15 20:42:43,908 iteration 5072 : loss : 0.018753, loss_ce: 0.005870
2022-01-15 20:42:44,959 iteration 5073 : loss : 0.038253, loss_ce: 0.008812
2022-01-15 20:42:45,982 iteration 5074 : loss : 0.023396, loss_ce: 0.009138
2022-01-15 20:42:46,889 iteration 5075 : loss : 0.018308, loss_ce: 0.008168
2022-01-15 20:42:47,805 iteration 5076 : loss : 0.016103, loss_ce: 0.005919
2022-01-15 20:42:48,859 iteration 5077 : loss : 0.030324, loss_ce: 0.011614
2022-01-15 20:42:49,852 iteration 5078 : loss : 0.023148, loss_ce: 0.007240
2022-01-15 20:42:50,819 iteration 5079 : loss : 0.012063, loss_ce: 0.004270
2022-01-15 20:42:51,834 iteration 5080 : loss : 0.016232, loss_ce: 0.006494
2022-01-15 20:42:52,852 iteration 5081 : loss : 0.019840, loss_ce: 0.008428
2022-01-15 20:42:53,808 iteration 5082 : loss : 0.017829, loss_ce: 0.004566
2022-01-15 20:42:54,759 iteration 5083 : loss : 0.024429, loss_ce: 0.009041
 75%|█████████████████████▋       | 299/400 [1:32:02<29:42, 17.65s/it]2022-01-15 20:42:55,822 iteration 5084 : loss : 0.018670, loss_ce: 0.008528
2022-01-15 20:42:56,916 iteration 5085 : loss : 0.021807, loss_ce: 0.009957
2022-01-15 20:42:57,816 iteration 5086 : loss : 0.012953, loss_ce: 0.003968
2022-01-15 20:42:58,823 iteration 5087 : loss : 0.017312, loss_ce: 0.003868
2022-01-15 20:42:59,743 iteration 5088 : loss : 0.011624, loss_ce: 0.005206
2022-01-15 20:43:00,722 iteration 5089 : loss : 0.018675, loss_ce: 0.007193
2022-01-15 20:43:01,746 iteration 5090 : loss : 0.023446, loss_ce: 0.009930
2022-01-15 20:43:02,784 iteration 5091 : loss : 0.024295, loss_ce: 0.009072
2022-01-15 20:43:03,773 iteration 5092 : loss : 0.020240, loss_ce: 0.004879
2022-01-15 20:43:04,788 iteration 5093 : loss : 0.020238, loss_ce: 0.006823
2022-01-15 20:43:05,825 iteration 5094 : loss : 0.017222, loss_ce: 0.005334
2022-01-15 20:43:06,864 iteration 5095 : loss : 0.016227, loss_ce: 0.007081
2022-01-15 20:43:07,960 iteration 5096 : loss : 0.020617, loss_ce: 0.005459
2022-01-15 20:43:09,026 iteration 5097 : loss : 0.022857, loss_ce: 0.010028
2022-01-15 20:43:10,039 iteration 5098 : loss : 0.018405, loss_ce: 0.007099
2022-01-15 20:43:11,099 iteration 5099 : loss : 0.024851, loss_ce: 0.010482
2022-01-15 20:43:11,099 Training Data Eval:
2022-01-15 20:43:15,927   Average segmentation loss on training set: 0.0115
2022-01-15 20:43:15,928 Validation Data Eval:
2022-01-15 20:43:17,550   Average segmentation loss on validation set: 0.0825
2022-01-15 20:43:18,524 iteration 5100 : loss : 0.019020, loss_ce: 0.005816
 75%|█████████████████████▊       | 300/400 [1:32:26<32:28, 19.49s/it]2022-01-15 20:43:19,620 iteration 5101 : loss : 0.020722, loss_ce: 0.007740
2022-01-15 20:43:20,694 iteration 5102 : loss : 0.025606, loss_ce: 0.015383
2022-01-15 20:43:21,636 iteration 5103 : loss : 0.018645, loss_ce: 0.006435
2022-01-15 20:43:22,622 iteration 5104 : loss : 0.029392, loss_ce: 0.008051
2022-01-15 20:43:23,591 iteration 5105 : loss : 0.026440, loss_ce: 0.010938
2022-01-15 20:43:24,590 iteration 5106 : loss : 0.026724, loss_ce: 0.012389
2022-01-15 20:43:25,605 iteration 5107 : loss : 0.022917, loss_ce: 0.008639
2022-01-15 20:43:26,621 iteration 5108 : loss : 0.019175, loss_ce: 0.007289
2022-01-15 20:43:27,602 iteration 5109 : loss : 0.018211, loss_ce: 0.008083
2022-01-15 20:43:28,488 iteration 5110 : loss : 0.016092, loss_ce: 0.006090
2022-01-15 20:43:29,503 iteration 5111 : loss : 0.018148, loss_ce: 0.005256
2022-01-15 20:43:30,431 iteration 5112 : loss : 0.014730, loss_ce: 0.005983
2022-01-15 20:43:31,504 iteration 5113 : loss : 0.019064, loss_ce: 0.006843
2022-01-15 20:43:32,441 iteration 5114 : loss : 0.016199, loss_ce: 0.006495
2022-01-15 20:43:33,398 iteration 5115 : loss : 0.015449, loss_ce: 0.006879
2022-01-15 20:43:34,407 iteration 5116 : loss : 0.018938, loss_ce: 0.006984
2022-01-15 20:43:35,418 iteration 5117 : loss : 0.017943, loss_ce: 0.006082
 75%|█████████████████████▊       | 301/400 [1:32:43<30:51, 18.71s/it]2022-01-15 20:43:36,496 iteration 5118 : loss : 0.020486, loss_ce: 0.009774
2022-01-15 20:43:37,494 iteration 5119 : loss : 0.024410, loss_ce: 0.008545
2022-01-15 20:43:38,588 iteration 5120 : loss : 0.014055, loss_ce: 0.003654
2022-01-15 20:43:39,546 iteration 5121 : loss : 0.017790, loss_ce: 0.006788
2022-01-15 20:43:40,515 iteration 5122 : loss : 0.023567, loss_ce: 0.006672
2022-01-15 20:43:41,510 iteration 5123 : loss : 0.019669, loss_ce: 0.010331
2022-01-15 20:43:42,468 iteration 5124 : loss : 0.023302, loss_ce: 0.006042
2022-01-15 20:43:43,488 iteration 5125 : loss : 0.019331, loss_ce: 0.006742
2022-01-15 20:43:44,461 iteration 5126 : loss : 0.015346, loss_ce: 0.005956
2022-01-15 20:43:45,480 iteration 5127 : loss : 0.019272, loss_ce: 0.006894
2022-01-15 20:43:46,579 iteration 5128 : loss : 0.023463, loss_ce: 0.007631
2022-01-15 20:43:47,641 iteration 5129 : loss : 0.029973, loss_ce: 0.009267
2022-01-15 20:43:48,559 iteration 5130 : loss : 0.017183, loss_ce: 0.006578
2022-01-15 20:43:49,574 iteration 5131 : loss : 0.016781, loss_ce: 0.004372
2022-01-15 20:43:50,574 iteration 5132 : loss : 0.019046, loss_ce: 0.008000
2022-01-15 20:43:51,510 iteration 5133 : loss : 0.017040, loss_ce: 0.007231
2022-01-15 20:43:52,443 iteration 5134 : loss : 0.011922, loss_ce: 0.004025
 76%|█████████████████████▉       | 302/400 [1:33:00<29:44, 18.20s/it]2022-01-15 20:43:53,485 iteration 5135 : loss : 0.016271, loss_ce: 0.005840
2022-01-15 20:43:54,558 iteration 5136 : loss : 0.018741, loss_ce: 0.007173
2022-01-15 20:43:55,627 iteration 5137 : loss : 0.018583, loss_ce: 0.006185
2022-01-15 20:43:56,721 iteration 5138 : loss : 0.023765, loss_ce: 0.011032
2022-01-15 20:43:57,636 iteration 5139 : loss : 0.011431, loss_ce: 0.003569
2022-01-15 20:43:58,695 iteration 5140 : loss : 0.022016, loss_ce: 0.009273
2022-01-15 20:43:59,631 iteration 5141 : loss : 0.015331, loss_ce: 0.007628
2022-01-15 20:44:00,739 iteration 5142 : loss : 0.020162, loss_ce: 0.006967
2022-01-15 20:44:01,683 iteration 5143 : loss : 0.012613, loss_ce: 0.004854
2022-01-15 20:44:02,617 iteration 5144 : loss : 0.014918, loss_ce: 0.006557
2022-01-15 20:44:03,648 iteration 5145 : loss : 0.025553, loss_ce: 0.010546
2022-01-15 20:44:04,797 iteration 5146 : loss : 0.029612, loss_ce: 0.007840
2022-01-15 20:44:05,806 iteration 5147 : loss : 0.016552, loss_ce: 0.008303
2022-01-15 20:44:06,830 iteration 5148 : loss : 0.018562, loss_ce: 0.006345
2022-01-15 20:44:07,791 iteration 5149 : loss : 0.016798, loss_ce: 0.005763
2022-01-15 20:44:08,758 iteration 5150 : loss : 0.016733, loss_ce: 0.006296
2022-01-15 20:44:09,691 iteration 5151 : loss : 0.015985, loss_ce: 0.005127
 76%|█████████████████████▉       | 303/400 [1:33:17<28:57, 17.92s/it]2022-01-15 20:44:10,792 iteration 5152 : loss : 0.022189, loss_ce: 0.007356
2022-01-15 20:44:11,714 iteration 5153 : loss : 0.013735, loss_ce: 0.006219
2022-01-15 20:44:12,764 iteration 5154 : loss : 0.023435, loss_ce: 0.008313
2022-01-15 20:44:13,705 iteration 5155 : loss : 0.012655, loss_ce: 0.004190
2022-01-15 20:44:14,693 iteration 5156 : loss : 0.015508, loss_ce: 0.005993
2022-01-15 20:44:15,757 iteration 5157 : loss : 0.017877, loss_ce: 0.006953
2022-01-15 20:44:16,780 iteration 5158 : loss : 0.019218, loss_ce: 0.006235
2022-01-15 20:44:17,835 iteration 5159 : loss : 0.022275, loss_ce: 0.006600
2022-01-15 20:44:18,896 iteration 5160 : loss : 0.019150, loss_ce: 0.008104
2022-01-15 20:44:19,942 iteration 5161 : loss : 0.015893, loss_ce: 0.006724
2022-01-15 20:44:20,897 iteration 5162 : loss : 0.013990, loss_ce: 0.003663
2022-01-15 20:44:21,875 iteration 5163 : loss : 0.022097, loss_ce: 0.009341
2022-01-15 20:44:22,801 iteration 5164 : loss : 0.018743, loss_ce: 0.009936
2022-01-15 20:44:23,814 iteration 5165 : loss : 0.013651, loss_ce: 0.004188
2022-01-15 20:44:24,824 iteration 5166 : loss : 0.015033, loss_ce: 0.006746
2022-01-15 20:44:25,776 iteration 5167 : loss : 0.015134, loss_ce: 0.006208
2022-01-15 20:44:26,847 iteration 5168 : loss : 0.020941, loss_ce: 0.008097
 76%|██████████████████████       | 304/400 [1:33:34<28:17, 17.69s/it]2022-01-15 20:44:27,872 iteration 5169 : loss : 0.017865, loss_ce: 0.006705
2022-01-15 20:44:28,889 iteration 5170 : loss : 0.015995, loss_ce: 0.007130
2022-01-15 20:44:29,865 iteration 5171 : loss : 0.019037, loss_ce: 0.005059
2022-01-15 20:44:30,886 iteration 5172 : loss : 0.021148, loss_ce: 0.007754
2022-01-15 20:44:31,859 iteration 5173 : loss : 0.024588, loss_ce: 0.011468
2022-01-15 20:44:32,900 iteration 5174 : loss : 0.017989, loss_ce: 0.006916
2022-01-15 20:44:33,999 iteration 5175 : loss : 0.024859, loss_ce: 0.008177
2022-01-15 20:44:35,008 iteration 5176 : loss : 0.017323, loss_ce: 0.005281
2022-01-15 20:44:36,153 iteration 5177 : loss : 0.029440, loss_ce: 0.014497
2022-01-15 20:44:37,150 iteration 5178 : loss : 0.021458, loss_ce: 0.004106
2022-01-15 20:44:38,232 iteration 5179 : loss : 0.017639, loss_ce: 0.007333
2022-01-15 20:44:39,259 iteration 5180 : loss : 0.021297, loss_ce: 0.008768
2022-01-15 20:44:40,334 iteration 5181 : loss : 0.018253, loss_ce: 0.007617
2022-01-15 20:44:41,411 iteration 5182 : loss : 0.020154, loss_ce: 0.007264
2022-01-15 20:44:42,490 iteration 5183 : loss : 0.018488, loss_ce: 0.005302
2022-01-15 20:44:43,613 iteration 5184 : loss : 0.041869, loss_ce: 0.019561
2022-01-15 20:44:43,614 Training Data Eval:
2022-01-15 20:44:48,520   Average segmentation loss on training set: 0.0142
2022-01-15 20:44:48,520 Validation Data Eval:
2022-01-15 20:44:50,188   Average segmentation loss on validation set: 0.0985
2022-01-15 20:44:51,244 iteration 5185 : loss : 0.015463, loss_ce: 0.007101
 76%|██████████████████████       | 305/400 [1:33:59<31:11, 19.70s/it]2022-01-15 20:44:52,329 iteration 5186 : loss : 0.016282, loss_ce: 0.006790
2022-01-15 20:44:53,384 iteration 5187 : loss : 0.018884, loss_ce: 0.007621
2022-01-15 20:44:54,305 iteration 5188 : loss : 0.022247, loss_ce: 0.007115
2022-01-15 20:44:55,316 iteration 5189 : loss : 0.020037, loss_ce: 0.008164
2022-01-15 20:44:56,244 iteration 5190 : loss : 0.016686, loss_ce: 0.007450
2022-01-15 20:44:57,202 iteration 5191 : loss : 0.020008, loss_ce: 0.008612
2022-01-15 20:44:58,261 iteration 5192 : loss : 0.053765, loss_ce: 0.013693
2022-01-15 20:44:59,283 iteration 5193 : loss : 0.025042, loss_ce: 0.010656
2022-01-15 20:45:00,282 iteration 5194 : loss : 0.023482, loss_ce: 0.010316
2022-01-15 20:45:01,292 iteration 5195 : loss : 0.028767, loss_ce: 0.007585
2022-01-15 20:45:02,419 iteration 5196 : loss : 0.064132, loss_ce: 0.021058
2022-01-15 20:45:03,316 iteration 5197 : loss : 0.018068, loss_ce: 0.005220
2022-01-15 20:45:04,372 iteration 5198 : loss : 0.027641, loss_ce: 0.010758
2022-01-15 20:45:05,419 iteration 5199 : loss : 0.031575, loss_ce: 0.014140
2022-01-15 20:45:06,446 iteration 5200 : loss : 0.017594, loss_ce: 0.006190
2022-01-15 20:45:07,409 iteration 5201 : loss : 0.018586, loss_ce: 0.006071
2022-01-15 20:45:08,393 iteration 5202 : loss : 0.026472, loss_ce: 0.011209
 76%|██████████████████████▏      | 306/400 [1:34:16<29:40, 18.94s/it]2022-01-15 20:45:09,340 iteration 5203 : loss : 0.016911, loss_ce: 0.004937
2022-01-15 20:45:10,365 iteration 5204 : loss : 0.024856, loss_ce: 0.008754
2022-01-15 20:45:11,371 iteration 5205 : loss : 0.019092, loss_ce: 0.007274
2022-01-15 20:45:12,299 iteration 5206 : loss : 0.020231, loss_ce: 0.007869
2022-01-15 20:45:13,276 iteration 5207 : loss : 0.015472, loss_ce: 0.006021
2022-01-15 20:45:14,354 iteration 5208 : loss : 0.043634, loss_ce: 0.017297
2022-01-15 20:45:15,364 iteration 5209 : loss : 0.023033, loss_ce: 0.008542
2022-01-15 20:45:16,338 iteration 5210 : loss : 0.020495, loss_ce: 0.006489
2022-01-15 20:45:17,289 iteration 5211 : loss : 0.023873, loss_ce: 0.006244
2022-01-15 20:45:18,309 iteration 5212 : loss : 0.021021, loss_ce: 0.006469
2022-01-15 20:45:19,364 iteration 5213 : loss : 0.028997, loss_ce: 0.008720
2022-01-15 20:45:20,370 iteration 5214 : loss : 0.024766, loss_ce: 0.013867
2022-01-15 20:45:21,360 iteration 5215 : loss : 0.057705, loss_ce: 0.024091
2022-01-15 20:45:22,356 iteration 5216 : loss : 0.022710, loss_ce: 0.009552
2022-01-15 20:45:23,308 iteration 5217 : loss : 0.018746, loss_ce: 0.006433
2022-01-15 20:45:24,301 iteration 5218 : loss : 0.038453, loss_ce: 0.022394
2022-01-15 20:45:25,348 iteration 5219 : loss : 0.033386, loss_ce: 0.017416
 77%|██████████████████████▎      | 307/400 [1:34:33<28:25, 18.34s/it]2022-01-15 20:45:26,511 iteration 5220 : loss : 0.033485, loss_ce: 0.011959
2022-01-15 20:45:27,494 iteration 5221 : loss : 0.017295, loss_ce: 0.007650
2022-01-15 20:45:28,411 iteration 5222 : loss : 0.033156, loss_ce: 0.013777
2022-01-15 20:45:29,402 iteration 5223 : loss : 0.027501, loss_ce: 0.012585
2022-01-15 20:45:30,496 iteration 5224 : loss : 0.030485, loss_ce: 0.011607
2022-01-15 20:45:31,427 iteration 5225 : loss : 0.014174, loss_ce: 0.003969
2022-01-15 20:45:32,571 iteration 5226 : loss : 0.029191, loss_ce: 0.010984
2022-01-15 20:45:33,471 iteration 5227 : loss : 0.019942, loss_ce: 0.007229
2022-01-15 20:45:34,392 iteration 5228 : loss : 0.016111, loss_ce: 0.007176
2022-01-15 20:45:35,354 iteration 5229 : loss : 0.022852, loss_ce: 0.009862
2022-01-15 20:45:36,386 iteration 5230 : loss : 0.024518, loss_ce: 0.012906
2022-01-15 20:45:37,424 iteration 5231 : loss : 0.062558, loss_ce: 0.030040
2022-01-15 20:45:38,378 iteration 5232 : loss : 0.018544, loss_ce: 0.008242
2022-01-15 20:45:39,421 iteration 5233 : loss : 0.027100, loss_ce: 0.012811
2022-01-15 20:45:40,331 iteration 5234 : loss : 0.014298, loss_ce: 0.005128
2022-01-15 20:45:41,435 iteration 5235 : loss : 0.031175, loss_ce: 0.009241
2022-01-15 20:45:42,419 iteration 5236 : loss : 0.022536, loss_ce: 0.007788
 77%|██████████████████████▎      | 308/400 [1:34:50<27:32, 17.96s/it]2022-01-15 20:45:43,505 iteration 5237 : loss : 0.024572, loss_ce: 0.008662
2022-01-15 20:45:44,509 iteration 5238 : loss : 0.022747, loss_ce: 0.010838
2022-01-15 20:45:45,514 iteration 5239 : loss : 0.018412, loss_ce: 0.005265
2022-01-15 20:45:46,614 iteration 5240 : loss : 0.032545, loss_ce: 0.010542
2022-01-15 20:45:47,646 iteration 5241 : loss : 0.025395, loss_ce: 0.011604
2022-01-15 20:45:48,674 iteration 5242 : loss : 0.025122, loss_ce: 0.009808
2022-01-15 20:45:49,681 iteration 5243 : loss : 0.020700, loss_ce: 0.008150
2022-01-15 20:45:50,699 iteration 5244 : loss : 0.033193, loss_ce: 0.011334
2022-01-15 20:45:51,699 iteration 5245 : loss : 0.025866, loss_ce: 0.010021
2022-01-15 20:45:52,582 iteration 5246 : loss : 0.014773, loss_ce: 0.006833
2022-01-15 20:45:53,578 iteration 5247 : loss : 0.018459, loss_ce: 0.007028
2022-01-15 20:45:54,614 iteration 5248 : loss : 0.020165, loss_ce: 0.007462
2022-01-15 20:45:55,584 iteration 5249 : loss : 0.030546, loss_ce: 0.011721
2022-01-15 20:45:56,572 iteration 5250 : loss : 0.024527, loss_ce: 0.011268
2022-01-15 20:45:57,615 iteration 5251 : loss : 0.020305, loss_ce: 0.007525
2022-01-15 20:45:58,585 iteration 5252 : loss : 0.018462, loss_ce: 0.005842
2022-01-15 20:45:59,601 iteration 5253 : loss : 0.013842, loss_ce: 0.005596
 77%|██████████████████████▍      | 309/400 [1:35:07<26:53, 17.73s/it]2022-01-15 20:46:00,565 iteration 5254 : loss : 0.017104, loss_ce: 0.006042
2022-01-15 20:46:01,608 iteration 5255 : loss : 0.019467, loss_ce: 0.006148
2022-01-15 20:46:02,617 iteration 5256 : loss : 0.016758, loss_ce: 0.006494
2022-01-15 20:46:03,694 iteration 5257 : loss : 0.021682, loss_ce: 0.006734
2022-01-15 20:46:04,639 iteration 5258 : loss : 0.026193, loss_ce: 0.010885
2022-01-15 20:46:05,667 iteration 5259 : loss : 0.036984, loss_ce: 0.010706
2022-01-15 20:46:06,625 iteration 5260 : loss : 0.017971, loss_ce: 0.007354
2022-01-15 20:46:07,607 iteration 5261 : loss : 0.017145, loss_ce: 0.007922
2022-01-15 20:46:08,530 iteration 5262 : loss : 0.013279, loss_ce: 0.006070
2022-01-15 20:46:09,539 iteration 5263 : loss : 0.018235, loss_ce: 0.006589
2022-01-15 20:46:10,512 iteration 5264 : loss : 0.015845, loss_ce: 0.005236
2022-01-15 20:46:11,423 iteration 5265 : loss : 0.015676, loss_ce: 0.005442
2022-01-15 20:46:12,425 iteration 5266 : loss : 0.022249, loss_ce: 0.009216
2022-01-15 20:46:13,357 iteration 5267 : loss : 0.022996, loss_ce: 0.009451
2022-01-15 20:46:14,423 iteration 5268 : loss : 0.020746, loss_ce: 0.008017
2022-01-15 20:46:15,518 iteration 5269 : loss : 0.029418, loss_ce: 0.013576
2022-01-15 20:46:15,518 Training Data Eval:
2022-01-15 20:46:20,335   Average segmentation loss on training set: 0.0121
2022-01-15 20:46:20,336 Validation Data Eval:
2022-01-15 20:46:21,956   Average segmentation loss on validation set: 0.1105
2022-01-15 20:46:23,021 iteration 5270 : loss : 0.021834, loss_ce: 0.010170
 78%|██████████████████████▍      | 310/400 [1:35:30<29:08, 19.43s/it]2022-01-15 20:46:24,121 iteration 5271 : loss : 0.017987, loss_ce: 0.007603
2022-01-15 20:46:25,105 iteration 5272 : loss : 0.027872, loss_ce: 0.010771
2022-01-15 20:46:26,084 iteration 5273 : loss : 0.020423, loss_ce: 0.008295
2022-01-15 20:46:27,022 iteration 5274 : loss : 0.016724, loss_ce: 0.006240
2022-01-15 20:46:28,046 iteration 5275 : loss : 0.038985, loss_ce: 0.011664
2022-01-15 20:46:29,065 iteration 5276 : loss : 0.019876, loss_ce: 0.005647
2022-01-15 20:46:29,982 iteration 5277 : loss : 0.020006, loss_ce: 0.005909
2022-01-15 20:46:31,117 iteration 5278 : loss : 0.019958, loss_ce: 0.008821
2022-01-15 20:46:32,092 iteration 5279 : loss : 0.018142, loss_ce: 0.005261
2022-01-15 20:46:33,155 iteration 5280 : loss : 0.024253, loss_ce: 0.009286
2022-01-15 20:46:34,142 iteration 5281 : loss : 0.020673, loss_ce: 0.010154
2022-01-15 20:46:35,157 iteration 5282 : loss : 0.018200, loss_ce: 0.006162
2022-01-15 20:46:36,145 iteration 5283 : loss : 0.015453, loss_ce: 0.005015
2022-01-15 20:46:37,172 iteration 5284 : loss : 0.016428, loss_ce: 0.007623
2022-01-15 20:46:38,196 iteration 5285 : loss : 0.034491, loss_ce: 0.016848
2022-01-15 20:46:39,252 iteration 5286 : loss : 0.013866, loss_ce: 0.005247
2022-01-15 20:46:40,367 iteration 5287 : loss : 0.028752, loss_ce: 0.013292
 78%|██████████████████████▌      | 311/400 [1:35:48<27:53, 18.81s/it]2022-01-15 20:46:41,371 iteration 5288 : loss : 0.024598, loss_ce: 0.011014
2022-01-15 20:46:42,371 iteration 5289 : loss : 0.016980, loss_ce: 0.006404
2022-01-15 20:46:43,418 iteration 5290 : loss : 0.022462, loss_ce: 0.009258
2022-01-15 20:46:44,472 iteration 5291 : loss : 0.015844, loss_ce: 0.006592
2022-01-15 20:46:45,510 iteration 5292 : loss : 0.014386, loss_ce: 0.005480
2022-01-15 20:46:46,483 iteration 5293 : loss : 0.021532, loss_ce: 0.006766
2022-01-15 20:46:47,557 iteration 5294 : loss : 0.020384, loss_ce: 0.009713
2022-01-15 20:46:48,513 iteration 5295 : loss : 0.016117, loss_ce: 0.005545
2022-01-15 20:46:49,516 iteration 5296 : loss : 0.025911, loss_ce: 0.008296
2022-01-15 20:46:50,606 iteration 5297 : loss : 0.022275, loss_ce: 0.008840
2022-01-15 20:46:51,555 iteration 5298 : loss : 0.015466, loss_ce: 0.006743
2022-01-15 20:46:52,633 iteration 5299 : loss : 0.017535, loss_ce: 0.007694
2022-01-15 20:46:53,558 iteration 5300 : loss : 0.016427, loss_ce: 0.006571
2022-01-15 20:46:54,572 iteration 5301 : loss : 0.020921, loss_ce: 0.006892
2022-01-15 20:46:55,551 iteration 5302 : loss : 0.016606, loss_ce: 0.007435
2022-01-15 20:46:56,458 iteration 5303 : loss : 0.014005, loss_ce: 0.005096
2022-01-15 20:46:57,537 iteration 5304 : loss : 0.024876, loss_ce: 0.011417
 78%|██████████████████████▌      | 312/400 [1:36:05<26:51, 18.32s/it]2022-01-15 20:46:58,617 iteration 5305 : loss : 0.023122, loss_ce: 0.007234
2022-01-15 20:46:59,646 iteration 5306 : loss : 0.032777, loss_ce: 0.009956
2022-01-15 20:47:00,643 iteration 5307 : loss : 0.016687, loss_ce: 0.006287
2022-01-15 20:47:01,684 iteration 5308 : loss : 0.015579, loss_ce: 0.006892
2022-01-15 20:47:02,673 iteration 5309 : loss : 0.013709, loss_ce: 0.005156
2022-01-15 20:47:03,665 iteration 5310 : loss : 0.018254, loss_ce: 0.008060
2022-01-15 20:47:04,675 iteration 5311 : loss : 0.017038, loss_ce: 0.006489
2022-01-15 20:47:05,670 iteration 5312 : loss : 0.017272, loss_ce: 0.006021
2022-01-15 20:47:06,705 iteration 5313 : loss : 0.022897, loss_ce: 0.008356
2022-01-15 20:47:07,652 iteration 5314 : loss : 0.015928, loss_ce: 0.006460
2022-01-15 20:47:08,679 iteration 5315 : loss : 0.023166, loss_ce: 0.009858
2022-01-15 20:47:09,545 iteration 5316 : loss : 0.012562, loss_ce: 0.005717
2022-01-15 20:47:10,558 iteration 5317 : loss : 0.017504, loss_ce: 0.006543
2022-01-15 20:47:11,594 iteration 5318 : loss : 0.021349, loss_ce: 0.007186
2022-01-15 20:47:12,640 iteration 5319 : loss : 0.025767, loss_ce: 0.008642
2022-01-15 20:47:13,674 iteration 5320 : loss : 0.024573, loss_ce: 0.011338
2022-01-15 20:47:14,598 iteration 5321 : loss : 0.023163, loss_ce: 0.005114
 78%|██████████████████████▋      | 313/400 [1:36:22<26:00, 17.94s/it]2022-01-15 20:47:15,702 iteration 5322 : loss : 0.018805, loss_ce: 0.008585
2022-01-15 20:47:16,762 iteration 5323 : loss : 0.026854, loss_ce: 0.011310
2022-01-15 20:47:17,755 iteration 5324 : loss : 0.015634, loss_ce: 0.006613
2022-01-15 20:47:18,753 iteration 5325 : loss : 0.028817, loss_ce: 0.010179
2022-01-15 20:47:19,834 iteration 5326 : loss : 0.021869, loss_ce: 0.005832
2022-01-15 20:47:20,848 iteration 5327 : loss : 0.019279, loss_ce: 0.007440
2022-01-15 20:47:21,830 iteration 5328 : loss : 0.021004, loss_ce: 0.008381
2022-01-15 20:47:22,830 iteration 5329 : loss : 0.017579, loss_ce: 0.006373
2022-01-15 20:47:23,818 iteration 5330 : loss : 0.025911, loss_ce: 0.010517
2022-01-15 20:47:24,734 iteration 5331 : loss : 0.012738, loss_ce: 0.004960
2022-01-15 20:47:25,921 iteration 5332 : loss : 0.023258, loss_ce: 0.009621
2022-01-15 20:47:26,901 iteration 5333 : loss : 0.019106, loss_ce: 0.006917
2022-01-15 20:47:27,776 iteration 5334 : loss : 0.012943, loss_ce: 0.003859
2022-01-15 20:47:28,777 iteration 5335 : loss : 0.026335, loss_ce: 0.009645
2022-01-15 20:47:29,757 iteration 5336 : loss : 0.019452, loss_ce: 0.006831
2022-01-15 20:47:30,751 iteration 5337 : loss : 0.018742, loss_ce: 0.008119
2022-01-15 20:47:31,755 iteration 5338 : loss : 0.021864, loss_ce: 0.009072
 78%|██████████████████████▊      | 314/400 [1:36:39<25:22, 17.71s/it]2022-01-15 20:47:32,786 iteration 5339 : loss : 0.017110, loss_ce: 0.006361
2022-01-15 20:47:33,734 iteration 5340 : loss : 0.020534, loss_ce: 0.007675
2022-01-15 20:47:34,794 iteration 5341 : loss : 0.025433, loss_ce: 0.006118
2022-01-15 20:47:35,824 iteration 5342 : loss : 0.018797, loss_ce: 0.005850
2022-01-15 20:47:36,828 iteration 5343 : loss : 0.022700, loss_ce: 0.008073
2022-01-15 20:47:37,776 iteration 5344 : loss : 0.021816, loss_ce: 0.009434
2022-01-15 20:47:38,751 iteration 5345 : loss : 0.017533, loss_ce: 0.008792
2022-01-15 20:47:39,713 iteration 5346 : loss : 0.017857, loss_ce: 0.006493
2022-01-15 20:47:40,732 iteration 5347 : loss : 0.016167, loss_ce: 0.007041
2022-01-15 20:47:41,682 iteration 5348 : loss : 0.015664, loss_ce: 0.005864
2022-01-15 20:47:42,655 iteration 5349 : loss : 0.022473, loss_ce: 0.007981
2022-01-15 20:47:43,650 iteration 5350 : loss : 0.017974, loss_ce: 0.005479
2022-01-15 20:47:44,593 iteration 5351 : loss : 0.013511, loss_ce: 0.004654
2022-01-15 20:47:45,673 iteration 5352 : loss : 0.015969, loss_ce: 0.006169
2022-01-15 20:47:46,701 iteration 5353 : loss : 0.016077, loss_ce: 0.006128
2022-01-15 20:47:47,664 iteration 5354 : loss : 0.014638, loss_ce: 0.006062
2022-01-15 20:47:47,665 Training Data Eval:
2022-01-15 20:47:52,525   Average segmentation loss on training set: 0.0111
2022-01-15 20:47:52,526 Validation Data Eval:
2022-01-15 20:47:54,179   Average segmentation loss on validation set: 0.0782
2022-01-15 20:47:55,204 iteration 5355 : loss : 0.018472, loss_ce: 0.007779
 79%|██████████████████████▊      | 315/400 [1:37:03<27:31, 19.43s/it]2022-01-15 20:47:56,326 iteration 5356 : loss : 0.024406, loss_ce: 0.010770
2022-01-15 20:47:57,279 iteration 5357 : loss : 0.010962, loss_ce: 0.003858
2022-01-15 20:47:58,224 iteration 5358 : loss : 0.017385, loss_ce: 0.006943
2022-01-15 20:47:59,175 iteration 5359 : loss : 0.017199, loss_ce: 0.005695
2022-01-15 20:48:00,230 iteration 5360 : loss : 0.019012, loss_ce: 0.007705
2022-01-15 20:48:01,212 iteration 5361 : loss : 0.016792, loss_ce: 0.007591
2022-01-15 20:48:02,242 iteration 5362 : loss : 0.016067, loss_ce: 0.005310
2022-01-15 20:48:03,402 iteration 5363 : loss : 0.018713, loss_ce: 0.007711
2022-01-15 20:48:04,392 iteration 5364 : loss : 0.022085, loss_ce: 0.005954
2022-01-15 20:48:05,409 iteration 5365 : loss : 0.022759, loss_ce: 0.007594
2022-01-15 20:48:06,380 iteration 5366 : loss : 0.018194, loss_ce: 0.006660
2022-01-15 20:48:07,276 iteration 5367 : loss : 0.014998, loss_ce: 0.005431
2022-01-15 20:48:08,392 iteration 5368 : loss : 0.032514, loss_ce: 0.009405
2022-01-15 20:48:09,355 iteration 5369 : loss : 0.011494, loss_ce: 0.004346
2022-01-15 20:48:10,314 iteration 5370 : loss : 0.017759, loss_ce: 0.008201
2022-01-15 20:48:11,277 iteration 5371 : loss : 0.014120, loss_ce: 0.003858
2022-01-15 20:48:12,172 iteration 5372 : loss : 0.015199, loss_ce: 0.005829
 79%|██████████████████████▉      | 316/400 [1:37:20<26:09, 18.69s/it]2022-01-15 20:48:13,203 iteration 5373 : loss : 0.018919, loss_ce: 0.007124
2022-01-15 20:48:14,159 iteration 5374 : loss : 0.018216, loss_ce: 0.004717
2022-01-15 20:48:15,159 iteration 5375 : loss : 0.016087, loss_ce: 0.006558
2022-01-15 20:48:16,159 iteration 5376 : loss : 0.015952, loss_ce: 0.006092
2022-01-15 20:48:17,161 iteration 5377 : loss : 0.021078, loss_ce: 0.005478
2022-01-15 20:48:18,155 iteration 5378 : loss : 0.022175, loss_ce: 0.006135
2022-01-15 20:48:19,116 iteration 5379 : loss : 0.018431, loss_ce: 0.006752
2022-01-15 20:48:20,031 iteration 5380 : loss : 0.014568, loss_ce: 0.006183
2022-01-15 20:48:21,100 iteration 5381 : loss : 0.017790, loss_ce: 0.007231
2022-01-15 20:48:22,080 iteration 5382 : loss : 0.018419, loss_ce: 0.006753
2022-01-15 20:48:23,048 iteration 5383 : loss : 0.022036, loss_ce: 0.010786
2022-01-15 20:48:24,009 iteration 5384 : loss : 0.015404, loss_ce: 0.007134
2022-01-15 20:48:25,013 iteration 5385 : loss : 0.018976, loss_ce: 0.006661
2022-01-15 20:48:25,957 iteration 5386 : loss : 0.015869, loss_ce: 0.006062
2022-01-15 20:48:27,041 iteration 5387 : loss : 0.019223, loss_ce: 0.006774
2022-01-15 20:48:28,057 iteration 5388 : loss : 0.012962, loss_ce: 0.003913
2022-01-15 20:48:29,116 iteration 5389 : loss : 0.017769, loss_ce: 0.007669
 79%|██████████████████████▉      | 317/400 [1:37:37<25:07, 18.17s/it]2022-01-15 20:48:30,113 iteration 5390 : loss : 0.012843, loss_ce: 0.004161
2022-01-15 20:48:31,179 iteration 5391 : loss : 0.019539, loss_ce: 0.007152
2022-01-15 20:48:32,136 iteration 5392 : loss : 0.020526, loss_ce: 0.006254
2022-01-15 20:48:33,072 iteration 5393 : loss : 0.015225, loss_ce: 0.005419
2022-01-15 20:48:34,053 iteration 5394 : loss : 0.014201, loss_ce: 0.004201
2022-01-15 20:48:35,038 iteration 5395 : loss : 0.017360, loss_ce: 0.005698
2022-01-15 20:48:35,988 iteration 5396 : loss : 0.017203, loss_ce: 0.006490
2022-01-15 20:48:37,020 iteration 5397 : loss : 0.018442, loss_ce: 0.007552
2022-01-15 20:48:38,156 iteration 5398 : loss : 0.026409, loss_ce: 0.007686
2022-01-15 20:48:39,180 iteration 5399 : loss : 0.020466, loss_ce: 0.006318
2022-01-15 20:48:40,130 iteration 5400 : loss : 0.018757, loss_ce: 0.008254
2022-01-15 20:48:41,146 iteration 5401 : loss : 0.015569, loss_ce: 0.008520
2022-01-15 20:48:42,111 iteration 5402 : loss : 0.012789, loss_ce: 0.006198
2022-01-15 20:48:43,104 iteration 5403 : loss : 0.016253, loss_ce: 0.006698
2022-01-15 20:48:44,125 iteration 5404 : loss : 0.013026, loss_ce: 0.005383
2022-01-15 20:48:45,229 iteration 5405 : loss : 0.029772, loss_ce: 0.009861
2022-01-15 20:48:46,160 iteration 5406 : loss : 0.014363, loss_ce: 0.006219
 80%|███████████████████████      | 318/400 [1:37:54<24:21, 17.83s/it]2022-01-15 20:48:47,175 iteration 5407 : loss : 0.014938, loss_ce: 0.006328
2022-01-15 20:48:48,131 iteration 5408 : loss : 0.015565, loss_ce: 0.005967
2022-01-15 20:48:49,023 iteration 5409 : loss : 0.013460, loss_ce: 0.004449
2022-01-15 20:48:50,026 iteration 5410 : loss : 0.018496, loss_ce: 0.006962
2022-01-15 20:48:50,959 iteration 5411 : loss : 0.012123, loss_ce: 0.004506
2022-01-15 20:48:51,963 iteration 5412 : loss : 0.018187, loss_ce: 0.006879
2022-01-15 20:48:52,924 iteration 5413 : loss : 0.016301, loss_ce: 0.006990
2022-01-15 20:48:53,932 iteration 5414 : loss : 0.014910, loss_ce: 0.005543
2022-01-15 20:48:55,040 iteration 5415 : loss : 0.021940, loss_ce: 0.007736
2022-01-15 20:48:55,996 iteration 5416 : loss : 0.016200, loss_ce: 0.005507
2022-01-15 20:48:56,993 iteration 5417 : loss : 0.013702, loss_ce: 0.004433
2022-01-15 20:48:58,082 iteration 5418 : loss : 0.015200, loss_ce: 0.005942
2022-01-15 20:48:59,021 iteration 5419 : loss : 0.016557, loss_ce: 0.007016
2022-01-15 20:48:59,957 iteration 5420 : loss : 0.014342, loss_ce: 0.005703
2022-01-15 20:49:01,006 iteration 5421 : loss : 0.019343, loss_ce: 0.007558
2022-01-15 20:49:02,087 iteration 5422 : loss : 0.026796, loss_ce: 0.005630
2022-01-15 20:49:03,150 iteration 5423 : loss : 0.020971, loss_ce: 0.009498
 80%|███████████████████████▏     | 319/400 [1:38:11<23:43, 17.58s/it]2022-01-15 20:49:04,214 iteration 5424 : loss : 0.027809, loss_ce: 0.009923
2022-01-15 20:49:05,183 iteration 5425 : loss : 0.017659, loss_ce: 0.004789
2022-01-15 20:49:06,259 iteration 5426 : loss : 0.025792, loss_ce: 0.010903
2022-01-15 20:49:07,189 iteration 5427 : loss : 0.014195, loss_ce: 0.004174
2022-01-15 20:49:08,170 iteration 5428 : loss : 0.014262, loss_ce: 0.004942
2022-01-15 20:49:09,164 iteration 5429 : loss : 0.022870, loss_ce: 0.008583
2022-01-15 20:49:10,300 iteration 5430 : loss : 0.023578, loss_ce: 0.008288
2022-01-15 20:49:11,298 iteration 5431 : loss : 0.020597, loss_ce: 0.007693
2022-01-15 20:49:12,282 iteration 5432 : loss : 0.014695, loss_ce: 0.006492
2022-01-15 20:49:13,357 iteration 5433 : loss : 0.021072, loss_ce: 0.008964
2022-01-15 20:49:14,347 iteration 5434 : loss : 0.016199, loss_ce: 0.006268
2022-01-15 20:49:15,473 iteration 5435 : loss : 0.026910, loss_ce: 0.012251
2022-01-15 20:49:16,479 iteration 5436 : loss : 0.013940, loss_ce: 0.005521
2022-01-15 20:49:17,363 iteration 5437 : loss : 0.012645, loss_ce: 0.004867
2022-01-15 20:49:18,483 iteration 5438 : loss : 0.018023, loss_ce: 0.007212
2022-01-15 20:49:19,449 iteration 5439 : loss : 0.013358, loss_ce: 0.004807
2022-01-15 20:49:19,450 Training Data Eval:
2022-01-15 20:49:24,248   Average segmentation loss on training set: 0.0111
2022-01-15 20:49:24,248 Validation Data Eval:
2022-01-15 20:49:25,868   Average segmentation loss on validation set: 0.0770
2022-01-15 20:49:26,917 iteration 5440 : loss : 0.029682, loss_ce: 0.008002
 80%|███████████████████████▏     | 320/400 [1:38:34<25:54, 19.43s/it]2022-01-15 20:49:27,858 iteration 5441 : loss : 0.014790, loss_ce: 0.004737
2022-01-15 20:49:28,842 iteration 5442 : loss : 0.023466, loss_ce: 0.007406
2022-01-15 20:49:29,862 iteration 5443 : loss : 0.014714, loss_ce: 0.004985
2022-01-15 20:49:30,867 iteration 5444 : loss : 0.015933, loss_ce: 0.006015
2022-01-15 20:49:31,950 iteration 5445 : loss : 0.022463, loss_ce: 0.008882
2022-01-15 20:49:32,899 iteration 5446 : loss : 0.019707, loss_ce: 0.006031
2022-01-15 20:49:33,885 iteration 5447 : loss : 0.025940, loss_ce: 0.012610
2022-01-15 20:49:34,893 iteration 5448 : loss : 0.019152, loss_ce: 0.006973
2022-01-15 20:49:35,870 iteration 5449 : loss : 0.029049, loss_ce: 0.010427
2022-01-15 20:49:36,930 iteration 5450 : loss : 0.020225, loss_ce: 0.009371
2022-01-15 20:49:37,923 iteration 5451 : loss : 0.017168, loss_ce: 0.007055
2022-01-15 20:49:38,981 iteration 5452 : loss : 0.019753, loss_ce: 0.008518
2022-01-15 20:49:39,984 iteration 5453 : loss : 0.014388, loss_ce: 0.005088
2022-01-15 20:49:40,862 iteration 5454 : loss : 0.011342, loss_ce: 0.005186
2022-01-15 20:49:41,972 iteration 5455 : loss : 0.026371, loss_ce: 0.010678
2022-01-15 20:49:43,039 iteration 5456 : loss : 0.016018, loss_ce: 0.006378
2022-01-15 20:49:44,026 iteration 5457 : loss : 0.019383, loss_ce: 0.006578
 80%|███████████████████████▎     | 321/400 [1:38:51<24:40, 18.74s/it]2022-01-15 20:49:45,043 iteration 5458 : loss : 0.016569, loss_ce: 0.006599
2022-01-15 20:49:45,987 iteration 5459 : loss : 0.014157, loss_ce: 0.005141
2022-01-15 20:49:47,006 iteration 5460 : loss : 0.024851, loss_ce: 0.009678
2022-01-15 20:49:48,033 iteration 5461 : loss : 0.018688, loss_ce: 0.007050
2022-01-15 20:49:49,030 iteration 5462 : loss : 0.017436, loss_ce: 0.004137
2022-01-15 20:49:49,988 iteration 5463 : loss : 0.018098, loss_ce: 0.007038
2022-01-15 20:49:50,952 iteration 5464 : loss : 0.023334, loss_ce: 0.011034
2022-01-15 20:49:51,886 iteration 5465 : loss : 0.020805, loss_ce: 0.007642
2022-01-15 20:49:52,966 iteration 5466 : loss : 0.018548, loss_ce: 0.007829
2022-01-15 20:49:53,928 iteration 5467 : loss : 0.013973, loss_ce: 0.006222
2022-01-15 20:49:54,914 iteration 5468 : loss : 0.023233, loss_ce: 0.010393
2022-01-15 20:49:55,829 iteration 5469 : loss : 0.013313, loss_ce: 0.004311
2022-01-15 20:49:56,865 iteration 5470 : loss : 0.026864, loss_ce: 0.010115
2022-01-15 20:49:57,865 iteration 5471 : loss : 0.016136, loss_ce: 0.005253
2022-01-15 20:49:58,907 iteration 5472 : loss : 0.025840, loss_ce: 0.010095
2022-01-15 20:49:59,933 iteration 5473 : loss : 0.020374, loss_ce: 0.006628
2022-01-15 20:50:00,964 iteration 5474 : loss : 0.020077, loss_ce: 0.008419
 80%|███████████████████████▎     | 322/400 [1:39:08<23:39, 18.20s/it]2022-01-15 20:50:01,995 iteration 5475 : loss : 0.012859, loss_ce: 0.003255
2022-01-15 20:50:02,952 iteration 5476 : loss : 0.024750, loss_ce: 0.007047
2022-01-15 20:50:03,899 iteration 5477 : loss : 0.014237, loss_ce: 0.005712
2022-01-15 20:50:04,878 iteration 5478 : loss : 0.014542, loss_ce: 0.006365
2022-01-15 20:50:05,970 iteration 5479 : loss : 0.019497, loss_ce: 0.009825
2022-01-15 20:50:07,039 iteration 5480 : loss : 0.031933, loss_ce: 0.011975
2022-01-15 20:50:08,034 iteration 5481 : loss : 0.019301, loss_ce: 0.006686
2022-01-15 20:50:09,020 iteration 5482 : loss : 0.014677, loss_ce: 0.004691
2022-01-15 20:50:10,025 iteration 5483 : loss : 0.019477, loss_ce: 0.008412
2022-01-15 20:50:10,982 iteration 5484 : loss : 0.017819, loss_ce: 0.007228
2022-01-15 20:50:11,875 iteration 5485 : loss : 0.013978, loss_ce: 0.004919
2022-01-15 20:50:12,967 iteration 5486 : loss : 0.025895, loss_ce: 0.012249
2022-01-15 20:50:14,114 iteration 5487 : loss : 0.022398, loss_ce: 0.008071
2022-01-15 20:50:15,106 iteration 5488 : loss : 0.020748, loss_ce: 0.008070
2022-01-15 20:50:16,100 iteration 5489 : loss : 0.015318, loss_ce: 0.005920
2022-01-15 20:50:17,071 iteration 5490 : loss : 0.031155, loss_ce: 0.010565
2022-01-15 20:50:18,064 iteration 5491 : loss : 0.018829, loss_ce: 0.007046
 81%|███████████████████████▍     | 323/400 [1:39:25<22:55, 17.86s/it]2022-01-15 20:50:19,134 iteration 5492 : loss : 0.020918, loss_ce: 0.007289
2022-01-15 20:50:20,094 iteration 5493 : loss : 0.017220, loss_ce: 0.007825
2022-01-15 20:50:21,029 iteration 5494 : loss : 0.020076, loss_ce: 0.005632
2022-01-15 20:50:22,089 iteration 5495 : loss : 0.062082, loss_ce: 0.009327
2022-01-15 20:50:23,032 iteration 5496 : loss : 0.014859, loss_ce: 0.005451
2022-01-15 20:50:24,021 iteration 5497 : loss : 0.015572, loss_ce: 0.004496
2022-01-15 20:50:25,041 iteration 5498 : loss : 0.027398, loss_ce: 0.015448
2022-01-15 20:50:26,028 iteration 5499 : loss : 0.027244, loss_ce: 0.010907
2022-01-15 20:50:27,049 iteration 5500 : loss : 0.031014, loss_ce: 0.012412
2022-01-15 20:50:28,143 iteration 5501 : loss : 0.028336, loss_ce: 0.012411
2022-01-15 20:50:29,169 iteration 5502 : loss : 0.025237, loss_ce: 0.010322
2022-01-15 20:50:30,124 iteration 5503 : loss : 0.024641, loss_ce: 0.008104
2022-01-15 20:50:31,138 iteration 5504 : loss : 0.039822, loss_ce: 0.019787
2022-01-15 20:50:32,136 iteration 5505 : loss : 0.028100, loss_ce: 0.010416
2022-01-15 20:50:33,080 iteration 5506 : loss : 0.035438, loss_ce: 0.015677
2022-01-15 20:50:34,102 iteration 5507 : loss : 0.035590, loss_ce: 0.012314
2022-01-15 20:50:35,101 iteration 5508 : loss : 0.025152, loss_ce: 0.010767
 81%|███████████████████████▍     | 324/400 [1:39:43<22:19, 17.62s/it]2022-01-15 20:50:36,133 iteration 5509 : loss : 0.023703, loss_ce: 0.008517
2022-01-15 20:50:37,248 iteration 5510 : loss : 0.035187, loss_ce: 0.013723
2022-01-15 20:50:38,229 iteration 5511 : loss : 0.035876, loss_ce: 0.018827
2022-01-15 20:50:39,273 iteration 5512 : loss : 0.023954, loss_ce: 0.004256
2022-01-15 20:50:40,216 iteration 5513 : loss : 0.024921, loss_ce: 0.006351
2022-01-15 20:50:41,251 iteration 5514 : loss : 0.023102, loss_ce: 0.009995
2022-01-15 20:50:42,322 iteration 5515 : loss : 0.026161, loss_ce: 0.007652
2022-01-15 20:50:43,250 iteration 5516 : loss : 0.015721, loss_ce: 0.005983
2022-01-15 20:50:44,274 iteration 5517 : loss : 0.022536, loss_ce: 0.008215
2022-01-15 20:50:45,243 iteration 5518 : loss : 0.019179, loss_ce: 0.008442
2022-01-15 20:50:46,201 iteration 5519 : loss : 0.026533, loss_ce: 0.009327
2022-01-15 20:50:47,223 iteration 5520 : loss : 0.036286, loss_ce: 0.014112
2022-01-15 20:50:48,350 iteration 5521 : loss : 0.027369, loss_ce: 0.009869
2022-01-15 20:50:49,264 iteration 5522 : loss : 0.016202, loss_ce: 0.007472
2022-01-15 20:50:50,273 iteration 5523 : loss : 0.028657, loss_ce: 0.012097
2022-01-15 20:50:51,295 iteration 5524 : loss : 0.029143, loss_ce: 0.012578
2022-01-15 20:50:51,296 Training Data Eval:
2022-01-15 20:50:56,028   Average segmentation loss on training set: 0.0128
2022-01-15 20:50:56,029 Validation Data Eval:
2022-01-15 20:50:57,638   Average segmentation loss on validation set: 0.0901
2022-01-15 20:50:58,702 iteration 5525 : loss : 0.029798, loss_ce: 0.012381
 81%|███████████████████████▌     | 325/400 [1:40:06<24:16, 19.41s/it]2022-01-15 20:50:59,867 iteration 5526 : loss : 0.021207, loss_ce: 0.009028
2022-01-15 20:51:00,809 iteration 5527 : loss : 0.026222, loss_ce: 0.010440
2022-01-15 20:51:01,822 iteration 5528 : loss : 0.023432, loss_ce: 0.007979
2022-01-15 20:51:02,781 iteration 5529 : loss : 0.016203, loss_ce: 0.005422
2022-01-15 20:51:03,713 iteration 5530 : loss : 0.016748, loss_ce: 0.004205
2022-01-15 20:51:04,719 iteration 5531 : loss : 0.016838, loss_ce: 0.006271
2022-01-15 20:51:05,617 iteration 5532 : loss : 0.016732, loss_ce: 0.005694
2022-01-15 20:51:06,640 iteration 5533 : loss : 0.033290, loss_ce: 0.012273
2022-01-15 20:51:07,646 iteration 5534 : loss : 0.023090, loss_ce: 0.008329
2022-01-15 20:51:08,658 iteration 5535 : loss : 0.019814, loss_ce: 0.007940
2022-01-15 20:51:09,639 iteration 5536 : loss : 0.023916, loss_ce: 0.006735
2022-01-15 20:51:10,620 iteration 5537 : loss : 0.020014, loss_ce: 0.007270
2022-01-15 20:51:11,597 iteration 5538 : loss : 0.016276, loss_ce: 0.008278
2022-01-15 20:51:12,613 iteration 5539 : loss : 0.018212, loss_ce: 0.007612
2022-01-15 20:51:13,638 iteration 5540 : loss : 0.015849, loss_ce: 0.005477
2022-01-15 20:51:14,556 iteration 5541 : loss : 0.033605, loss_ce: 0.012672
2022-01-15 20:51:15,518 iteration 5542 : loss : 0.020804, loss_ce: 0.009350
 82%|███████████████████████▋     | 326/400 [1:40:23<22:58, 18.63s/it]2022-01-15 20:51:16,634 iteration 5543 : loss : 0.022075, loss_ce: 0.010567
2022-01-15 20:51:17,726 iteration 5544 : loss : 0.034811, loss_ce: 0.010694
2022-01-15 20:51:18,771 iteration 5545 : loss : 0.030858, loss_ce: 0.011612
2022-01-15 20:51:19,675 iteration 5546 : loss : 0.011920, loss_ce: 0.005788
2022-01-15 20:51:20,695 iteration 5547 : loss : 0.014044, loss_ce: 0.005834
2022-01-15 20:51:21,646 iteration 5548 : loss : 0.018816, loss_ce: 0.006249
2022-01-15 20:51:22,656 iteration 5549 : loss : 0.018199, loss_ce: 0.007184
2022-01-15 20:51:23,672 iteration 5550 : loss : 0.021814, loss_ce: 0.008716
2022-01-15 20:51:24,686 iteration 5551 : loss : 0.018582, loss_ce: 0.004896
2022-01-15 20:51:25,776 iteration 5552 : loss : 0.029020, loss_ce: 0.008668
2022-01-15 20:51:26,790 iteration 5553 : loss : 0.022245, loss_ce: 0.008415
2022-01-15 20:51:27,879 iteration 5554 : loss : 0.026547, loss_ce: 0.006297
2022-01-15 20:51:28,941 iteration 5555 : loss : 0.015447, loss_ce: 0.006765
2022-01-15 20:51:29,975 iteration 5556 : loss : 0.015195, loss_ce: 0.006639
2022-01-15 20:51:31,004 iteration 5557 : loss : 0.022516, loss_ce: 0.006735
2022-01-15 20:51:31,962 iteration 5558 : loss : 0.017615, loss_ce: 0.005882
2022-01-15 20:51:32,870 iteration 5559 : loss : 0.016091, loss_ce: 0.005008
 82%|███████████████████████▋     | 327/400 [1:40:40<22:12, 18.25s/it]2022-01-15 20:51:33,918 iteration 5560 : loss : 0.019485, loss_ce: 0.007567
2022-01-15 20:51:34,998 iteration 5561 : loss : 0.017361, loss_ce: 0.004380
2022-01-15 20:51:36,001 iteration 5562 : loss : 0.014577, loss_ce: 0.004670
2022-01-15 20:51:37,051 iteration 5563 : loss : 0.035897, loss_ce: 0.012257
2022-01-15 20:51:37,952 iteration 5564 : loss : 0.020495, loss_ce: 0.006553
2022-01-15 20:51:38,970 iteration 5565 : loss : 0.020934, loss_ce: 0.005535
2022-01-15 20:51:39,916 iteration 5566 : loss : 0.015946, loss_ce: 0.005549
2022-01-15 20:51:40,965 iteration 5567 : loss : 0.017408, loss_ce: 0.009345
2022-01-15 20:51:42,017 iteration 5568 : loss : 0.027804, loss_ce: 0.014739
2022-01-15 20:51:43,065 iteration 5569 : loss : 0.022846, loss_ce: 0.008689
2022-01-15 20:51:44,046 iteration 5570 : loss : 0.015370, loss_ce: 0.007345
2022-01-15 20:51:45,017 iteration 5571 : loss : 0.033889, loss_ce: 0.009520
2022-01-15 20:51:45,895 iteration 5572 : loss : 0.014879, loss_ce: 0.005310
2022-01-15 20:51:46,928 iteration 5573 : loss : 0.024240, loss_ce: 0.008523
2022-01-15 20:51:47,875 iteration 5574 : loss : 0.020729, loss_ce: 0.009154
2022-01-15 20:51:48,801 iteration 5575 : loss : 0.014371, loss_ce: 0.005583
2022-01-15 20:51:49,691 iteration 5576 : loss : 0.018439, loss_ce: 0.005370
 82%|███████████████████████▊     | 328/400 [1:40:57<21:22, 17.82s/it]2022-01-15 20:51:50,802 iteration 5577 : loss : 0.021574, loss_ce: 0.008059
2022-01-15 20:51:51,788 iteration 5578 : loss : 0.015556, loss_ce: 0.005488
2022-01-15 20:51:52,878 iteration 5579 : loss : 0.021082, loss_ce: 0.005360
2022-01-15 20:51:53,921 iteration 5580 : loss : 0.026156, loss_ce: 0.008886
2022-01-15 20:51:54,923 iteration 5581 : loss : 0.018958, loss_ce: 0.008510
2022-01-15 20:51:55,884 iteration 5582 : loss : 0.017255, loss_ce: 0.006153
2022-01-15 20:51:56,810 iteration 5583 : loss : 0.012024, loss_ce: 0.003487
2022-01-15 20:51:57,771 iteration 5584 : loss : 0.018311, loss_ce: 0.006861
2022-01-15 20:51:58,683 iteration 5585 : loss : 0.017050, loss_ce: 0.006056
2022-01-15 20:51:59,620 iteration 5586 : loss : 0.016866, loss_ce: 0.006763
2022-01-15 20:52:00,694 iteration 5587 : loss : 0.022417, loss_ce: 0.009894
2022-01-15 20:52:01,670 iteration 5588 : loss : 0.022484, loss_ce: 0.009535
2022-01-15 20:52:02,727 iteration 5589 : loss : 0.021359, loss_ce: 0.006702
2022-01-15 20:52:03,652 iteration 5590 : loss : 0.014653, loss_ce: 0.006203
2022-01-15 20:52:04,676 iteration 5591 : loss : 0.027889, loss_ce: 0.009349
2022-01-15 20:52:05,682 iteration 5592 : loss : 0.020427, loss_ce: 0.008485
2022-01-15 20:52:06,585 iteration 5593 : loss : 0.015658, loss_ce: 0.007934
 82%|███████████████████████▊     | 329/400 [1:41:14<20:45, 17.54s/it]2022-01-15 20:52:07,645 iteration 5594 : loss : 0.018438, loss_ce: 0.006209
2022-01-15 20:52:08,583 iteration 5595 : loss : 0.015568, loss_ce: 0.006760
2022-01-15 20:52:09,663 iteration 5596 : loss : 0.025548, loss_ce: 0.007634
2022-01-15 20:52:10,683 iteration 5597 : loss : 0.013820, loss_ce: 0.005987
2022-01-15 20:52:11,810 iteration 5598 : loss : 0.023282, loss_ce: 0.010770
2022-01-15 20:52:12,897 iteration 5599 : loss : 0.024107, loss_ce: 0.008845
2022-01-15 20:52:13,834 iteration 5600 : loss : 0.014211, loss_ce: 0.005288
2022-01-15 20:52:14,853 iteration 5601 : loss : 0.018841, loss_ce: 0.006708
2022-01-15 20:52:15,871 iteration 5602 : loss : 0.019353, loss_ce: 0.007266
2022-01-15 20:52:16,894 iteration 5603 : loss : 0.021914, loss_ce: 0.010761
2022-01-15 20:52:17,919 iteration 5604 : loss : 0.025864, loss_ce: 0.008544
2022-01-15 20:52:18,888 iteration 5605 : loss : 0.019287, loss_ce: 0.009018
2022-01-15 20:52:19,937 iteration 5606 : loss : 0.037149, loss_ce: 0.011585
2022-01-15 20:52:20,892 iteration 5607 : loss : 0.018697, loss_ce: 0.008315
2022-01-15 20:52:21,936 iteration 5608 : loss : 0.016020, loss_ce: 0.007295
2022-01-15 20:52:22,905 iteration 5609 : loss : 0.017773, loss_ce: 0.006346
2022-01-15 20:52:22,906 Training Data Eval:
2022-01-15 20:52:27,815   Average segmentation loss on training set: 0.0114
2022-01-15 20:52:27,815 Validation Data Eval:
2022-01-15 20:52:29,486   Average segmentation loss on validation set: 0.0637
2022-01-15 20:52:30,558 iteration 5610 : loss : 0.025094, loss_ce: 0.011184
 82%|███████████████████████▉     | 330/400 [1:41:38<22:43, 19.47s/it]2022-01-15 20:52:31,589 iteration 5611 : loss : 0.010984, loss_ce: 0.004160
2022-01-15 20:52:32,665 iteration 5612 : loss : 0.025320, loss_ce: 0.008746
2022-01-15 20:52:33,642 iteration 5613 : loss : 0.014653, loss_ce: 0.002983
2022-01-15 20:52:34,623 iteration 5614 : loss : 0.018256, loss_ce: 0.006821
2022-01-15 20:52:35,629 iteration 5615 : loss : 0.021805, loss_ce: 0.009521
2022-01-15 20:52:36,642 iteration 5616 : loss : 0.015017, loss_ce: 0.004453
2022-01-15 20:52:37,814 iteration 5617 : loss : 0.021375, loss_ce: 0.006433
2022-01-15 20:52:38,870 iteration 5618 : loss : 0.021445, loss_ce: 0.005448
2022-01-15 20:52:39,885 iteration 5619 : loss : 0.013847, loss_ce: 0.006590
2022-01-15 20:52:40,843 iteration 5620 : loss : 0.017028, loss_ce: 0.006329
2022-01-15 20:52:41,790 iteration 5621 : loss : 0.016599, loss_ce: 0.006063
2022-01-15 20:52:42,710 iteration 5622 : loss : 0.013675, loss_ce: 0.005981
2022-01-15 20:52:43,786 iteration 5623 : loss : 0.013529, loss_ce: 0.005052
2022-01-15 20:52:44,779 iteration 5624 : loss : 0.017299, loss_ce: 0.006249
2022-01-15 20:52:45,775 iteration 5625 : loss : 0.017357, loss_ce: 0.007715
2022-01-15 20:52:46,806 iteration 5626 : loss : 0.017766, loss_ce: 0.006287
2022-01-15 20:52:47,808 iteration 5627 : loss : 0.015343, loss_ce: 0.006591
 83%|███████████████████████▉     | 331/400 [1:41:55<21:37, 18.81s/it]2022-01-15 20:52:48,876 iteration 5628 : loss : 0.015134, loss_ce: 0.005567
2022-01-15 20:52:49,894 iteration 5629 : loss : 0.019740, loss_ce: 0.007658
2022-01-15 20:52:50,933 iteration 5630 : loss : 0.024154, loss_ce: 0.008630
2022-01-15 20:52:51,974 iteration 5631 : loss : 0.017482, loss_ce: 0.008297
2022-01-15 20:52:53,065 iteration 5632 : loss : 0.023778, loss_ce: 0.008508
2022-01-15 20:52:53,975 iteration 5633 : loss : 0.018813, loss_ce: 0.004832
2022-01-15 20:52:55,044 iteration 5634 : loss : 0.024896, loss_ce: 0.006393
2022-01-15 20:52:56,035 iteration 5635 : loss : 0.014364, loss_ce: 0.005644
2022-01-15 20:52:56,953 iteration 5636 : loss : 0.023121, loss_ce: 0.005991
2022-01-15 20:52:58,043 iteration 5637 : loss : 0.017789, loss_ce: 0.007737
2022-01-15 20:52:59,038 iteration 5638 : loss : 0.018607, loss_ce: 0.007942
2022-01-15 20:53:00,053 iteration 5639 : loss : 0.017983, loss_ce: 0.005345
2022-01-15 20:53:01,050 iteration 5640 : loss : 0.023465, loss_ce: 0.008771
2022-01-15 20:53:02,003 iteration 5641 : loss : 0.013998, loss_ce: 0.004482
2022-01-15 20:53:03,135 iteration 5642 : loss : 0.019708, loss_ce: 0.009827
2022-01-15 20:53:04,048 iteration 5643 : loss : 0.017485, loss_ce: 0.008472
2022-01-15 20:53:05,045 iteration 5644 : loss : 0.020249, loss_ce: 0.009416
 83%|████████████████████████     | 332/400 [1:42:12<20:46, 18.34s/it]2022-01-15 20:53:06,055 iteration 5645 : loss : 0.013786, loss_ce: 0.004188
2022-01-15 20:53:07,036 iteration 5646 : loss : 0.026186, loss_ce: 0.007978
2022-01-15 20:53:07,967 iteration 5647 : loss : 0.013262, loss_ce: 0.004286
2022-01-15 20:53:08,969 iteration 5648 : loss : 0.016199, loss_ce: 0.007657
2022-01-15 20:53:09,933 iteration 5649 : loss : 0.013805, loss_ce: 0.004586
2022-01-15 20:53:11,004 iteration 5650 : loss : 0.020868, loss_ce: 0.007886
2022-01-15 20:53:11,994 iteration 5651 : loss : 0.014767, loss_ce: 0.006494
2022-01-15 20:53:13,001 iteration 5652 : loss : 0.016266, loss_ce: 0.004665
2022-01-15 20:53:13,993 iteration 5653 : loss : 0.018333, loss_ce: 0.005494
2022-01-15 20:53:14,984 iteration 5654 : loss : 0.015462, loss_ce: 0.006074
2022-01-15 20:53:15,885 iteration 5655 : loss : 0.015368, loss_ce: 0.007451
2022-01-15 20:53:16,978 iteration 5656 : loss : 0.020602, loss_ce: 0.006162
2022-01-15 20:53:18,037 iteration 5657 : loss : 0.021158, loss_ce: 0.007888
2022-01-15 20:53:19,094 iteration 5658 : loss : 0.021755, loss_ce: 0.009494
2022-01-15 20:53:20,048 iteration 5659 : loss : 0.018315, loss_ce: 0.006730
2022-01-15 20:53:21,073 iteration 5660 : loss : 0.025064, loss_ce: 0.007477
2022-01-15 20:53:22,062 iteration 5661 : loss : 0.016387, loss_ce: 0.008036
 83%|████████████████████████▏    | 333/400 [1:42:29<20:01, 17.94s/it]2022-01-15 20:53:23,108 iteration 5662 : loss : 0.019148, loss_ce: 0.007058
2022-01-15 20:53:24,053 iteration 5663 : loss : 0.016444, loss_ce: 0.005010
2022-01-15 20:53:25,045 iteration 5664 : loss : 0.016529, loss_ce: 0.007807
2022-01-15 20:53:25,979 iteration 5665 : loss : 0.011459, loss_ce: 0.004661
2022-01-15 20:53:26,989 iteration 5666 : loss : 0.022397, loss_ce: 0.005385
2022-01-15 20:53:28,031 iteration 5667 : loss : 0.015718, loss_ce: 0.005752
2022-01-15 20:53:29,034 iteration 5668 : loss : 0.015511, loss_ce: 0.005760
2022-01-15 20:53:29,964 iteration 5669 : loss : 0.019680, loss_ce: 0.007848
2022-01-15 20:53:30,930 iteration 5670 : loss : 0.017666, loss_ce: 0.005741
2022-01-15 20:53:31,873 iteration 5671 : loss : 0.016907, loss_ce: 0.006185
2022-01-15 20:53:32,970 iteration 5672 : loss : 0.020774, loss_ce: 0.009069
2022-01-15 20:53:33,935 iteration 5673 : loss : 0.020057, loss_ce: 0.007178
2022-01-15 20:53:34,922 iteration 5674 : loss : 0.023418, loss_ce: 0.007008
2022-01-15 20:53:35,867 iteration 5675 : loss : 0.013048, loss_ce: 0.006046
2022-01-15 20:53:36,918 iteration 5676 : loss : 0.028321, loss_ce: 0.010586
2022-01-15 20:53:37,892 iteration 5677 : loss : 0.021827, loss_ce: 0.005110
2022-01-15 20:53:38,982 iteration 5678 : loss : 0.019220, loss_ce: 0.007452
 84%|████████████████████████▏    | 334/400 [1:42:46<19:23, 17.63s/it]2022-01-15 20:53:40,072 iteration 5679 : loss : 0.017208, loss_ce: 0.006029
2022-01-15 20:53:41,014 iteration 5680 : loss : 0.018388, loss_ce: 0.008048
2022-01-15 20:53:42,024 iteration 5681 : loss : 0.013847, loss_ce: 0.005517
2022-01-15 20:53:43,004 iteration 5682 : loss : 0.026358, loss_ce: 0.010116
2022-01-15 20:53:44,038 iteration 5683 : loss : 0.024035, loss_ce: 0.009304
2022-01-15 20:53:45,115 iteration 5684 : loss : 0.022621, loss_ce: 0.007547
2022-01-15 20:53:46,157 iteration 5685 : loss : 0.013323, loss_ce: 0.003468
2022-01-15 20:53:47,143 iteration 5686 : loss : 0.018977, loss_ce: 0.007609
2022-01-15 20:53:48,102 iteration 5687 : loss : 0.013514, loss_ce: 0.003444
2022-01-15 20:53:49,098 iteration 5688 : loss : 0.016689, loss_ce: 0.005672
2022-01-15 20:53:50,084 iteration 5689 : loss : 0.016727, loss_ce: 0.007231
2022-01-15 20:53:51,115 iteration 5690 : loss : 0.020946, loss_ce: 0.011442
2022-01-15 20:53:52,090 iteration 5691 : loss : 0.012589, loss_ce: 0.003294
2022-01-15 20:53:53,047 iteration 5692 : loss : 0.013842, loss_ce: 0.004622
2022-01-15 20:53:54,077 iteration 5693 : loss : 0.030178, loss_ce: 0.014672
2022-01-15 20:53:55,132 iteration 5694 : loss : 0.023908, loss_ce: 0.008606
2022-01-15 20:53:55,132 Training Data Eval:
2022-01-15 20:53:59,905   Average segmentation loss on training set: 0.0102
2022-01-15 20:53:59,905 Validation Data Eval:
2022-01-15 20:54:01,531   Average segmentation loss on validation set: 0.0690
2022-01-15 20:54:02,513 iteration 5695 : loss : 0.016185, loss_ce: 0.005272
 84%|████████████████████████▎    | 335/400 [1:43:10<21:01, 19.40s/it]2022-01-15 20:54:03,566 iteration 5696 : loss : 0.013744, loss_ce: 0.004567
2022-01-15 20:54:04,633 iteration 5697 : loss : 0.018441, loss_ce: 0.007524
2022-01-15 20:54:05,635 iteration 5698 : loss : 0.023044, loss_ce: 0.007964
2022-01-15 20:54:06,709 iteration 5699 : loss : 0.020651, loss_ce: 0.006890
2022-01-15 20:54:07,705 iteration 5700 : loss : 0.018633, loss_ce: 0.007419
2022-01-15 20:54:08,678 iteration 5701 : loss : 0.015019, loss_ce: 0.007221
2022-01-15 20:54:09,689 iteration 5702 : loss : 0.010232, loss_ce: 0.003417
2022-01-15 20:54:10,673 iteration 5703 : loss : 0.012178, loss_ce: 0.005671
2022-01-15 20:54:11,711 iteration 5704 : loss : 0.019991, loss_ce: 0.008256
2022-01-15 20:54:12,734 iteration 5705 : loss : 0.027321, loss_ce: 0.008609
2022-01-15 20:54:13,693 iteration 5706 : loss : 0.016684, loss_ce: 0.003382
2022-01-15 20:54:14,830 iteration 5707 : loss : 0.021878, loss_ce: 0.007966
2022-01-15 20:54:15,808 iteration 5708 : loss : 0.024193, loss_ce: 0.009012
2022-01-15 20:54:16,831 iteration 5709 : loss : 0.019670, loss_ce: 0.009084
2022-01-15 20:54:17,926 iteration 5710 : loss : 0.028872, loss_ce: 0.009547
2022-01-15 20:54:18,889 iteration 5711 : loss : 0.019041, loss_ce: 0.009631
2022-01-15 20:54:19,861 iteration 5712 : loss : 0.019020, loss_ce: 0.008846
 84%|████████████████████████▎    | 336/400 [1:43:27<20:02, 18.79s/it]2022-01-15 20:54:20,870 iteration 5713 : loss : 0.015934, loss_ce: 0.004184
2022-01-15 20:54:21,837 iteration 5714 : loss : 0.021471, loss_ce: 0.009841
2022-01-15 20:54:22,810 iteration 5715 : loss : 0.013956, loss_ce: 0.005351
2022-01-15 20:54:23,834 iteration 5716 : loss : 0.014967, loss_ce: 0.006179
2022-01-15 20:54:24,883 iteration 5717 : loss : 0.018234, loss_ce: 0.006696
2022-01-15 20:54:25,805 iteration 5718 : loss : 0.016704, loss_ce: 0.004869
2022-01-15 20:54:26,832 iteration 5719 : loss : 0.012691, loss_ce: 0.004893
2022-01-15 20:54:27,794 iteration 5720 : loss : 0.018341, loss_ce: 0.007758
2022-01-15 20:54:28,687 iteration 5721 : loss : 0.012846, loss_ce: 0.003675
2022-01-15 20:54:29,672 iteration 5722 : loss : 0.015134, loss_ce: 0.005226
2022-01-15 20:54:30,652 iteration 5723 : loss : 0.017550, loss_ce: 0.006509
2022-01-15 20:54:31,550 iteration 5724 : loss : 0.010841, loss_ce: 0.003947
2022-01-15 20:54:32,585 iteration 5725 : loss : 0.014697, loss_ce: 0.006590
2022-01-15 20:54:33,519 iteration 5726 : loss : 0.015823, loss_ce: 0.006767
2022-01-15 20:54:34,503 iteration 5727 : loss : 0.016900, loss_ce: 0.006091
2022-01-15 20:54:35,475 iteration 5728 : loss : 0.016723, loss_ce: 0.007714
2022-01-15 20:54:36,506 iteration 5729 : loss : 0.014131, loss_ce: 0.005018
 84%|████████████████████████▍    | 337/400 [1:43:44<19:02, 18.14s/it]2022-01-15 20:54:37,576 iteration 5730 : loss : 0.021039, loss_ce: 0.005849
2022-01-15 20:54:38,614 iteration 5731 : loss : 0.011211, loss_ce: 0.004196
2022-01-15 20:54:39,588 iteration 5732 : loss : 0.020779, loss_ce: 0.006968
2022-01-15 20:54:40,540 iteration 5733 : loss : 0.017266, loss_ce: 0.005192
2022-01-15 20:54:41,549 iteration 5734 : loss : 0.021411, loss_ce: 0.006302
2022-01-15 20:54:42,573 iteration 5735 : loss : 0.015391, loss_ce: 0.007058
2022-01-15 20:54:43,572 iteration 5736 : loss : 0.015985, loss_ce: 0.008633
2022-01-15 20:54:44,568 iteration 5737 : loss : 0.019080, loss_ce: 0.007734
2022-01-15 20:54:45,559 iteration 5738 : loss : 0.010606, loss_ce: 0.004211
2022-01-15 20:54:46,513 iteration 5739 : loss : 0.014134, loss_ce: 0.005778
2022-01-15 20:54:47,556 iteration 5740 : loss : 0.031413, loss_ce: 0.010016
2022-01-15 20:54:48,581 iteration 5741 : loss : 0.017052, loss_ce: 0.008100
2022-01-15 20:54:49,606 iteration 5742 : loss : 0.038701, loss_ce: 0.026782
2022-01-15 20:54:50,585 iteration 5743 : loss : 0.015418, loss_ce: 0.006632
2022-01-15 20:54:51,650 iteration 5744 : loss : 0.014587, loss_ce: 0.005867
2022-01-15 20:54:52,662 iteration 5745 : loss : 0.016727, loss_ce: 0.005782
2022-01-15 20:54:53,588 iteration 5746 : loss : 0.013040, loss_ce: 0.003420
 84%|████████████████████████▌    | 338/400 [1:44:01<18:25, 17.83s/it]2022-01-15 20:54:54,692 iteration 5747 : loss : 0.018013, loss_ce: 0.006431
2022-01-15 20:54:55,733 iteration 5748 : loss : 0.026299, loss_ce: 0.008279
2022-01-15 20:54:56,787 iteration 5749 : loss : 0.015284, loss_ce: 0.006192
2022-01-15 20:54:57,883 iteration 5750 : loss : 0.018830, loss_ce: 0.005199
2022-01-15 20:54:58,815 iteration 5751 : loss : 0.014648, loss_ce: 0.005613
2022-01-15 20:54:59,842 iteration 5752 : loss : 0.020179, loss_ce: 0.006324
2022-01-15 20:55:00,823 iteration 5753 : loss : 0.019101, loss_ce: 0.006868
2022-01-15 20:55:01,752 iteration 5754 : loss : 0.012690, loss_ce: 0.004702
2022-01-15 20:55:02,754 iteration 5755 : loss : 0.022515, loss_ce: 0.011378
2022-01-15 20:55:03,754 iteration 5756 : loss : 0.017490, loss_ce: 0.005831
2022-01-15 20:55:04,727 iteration 5757 : loss : 0.014919, loss_ce: 0.007392
2022-01-15 20:55:05,718 iteration 5758 : loss : 0.016500, loss_ce: 0.003670
2022-01-15 20:55:06,715 iteration 5759 : loss : 0.017247, loss_ce: 0.008051
2022-01-15 20:55:07,787 iteration 5760 : loss : 0.017686, loss_ce: 0.007176
2022-01-15 20:55:08,685 iteration 5761 : loss : 0.012521, loss_ce: 0.004802
2022-01-15 20:55:09,862 iteration 5762 : loss : 0.021607, loss_ce: 0.008074
2022-01-15 20:55:10,844 iteration 5763 : loss : 0.014190, loss_ce: 0.005678
 85%|████████████████████████▌    | 339/400 [1:44:18<17:57, 17.66s/it]2022-01-15 20:55:11,919 iteration 5764 : loss : 0.015675, loss_ce: 0.005898
2022-01-15 20:55:12,949 iteration 5765 : loss : 0.016117, loss_ce: 0.004321
2022-01-15 20:55:13,952 iteration 5766 : loss : 0.013858, loss_ce: 0.005270
2022-01-15 20:55:14,968 iteration 5767 : loss : 0.019131, loss_ce: 0.007192
2022-01-15 20:55:16,086 iteration 5768 : loss : 0.025264, loss_ce: 0.007869
2022-01-15 20:55:17,068 iteration 5769 : loss : 0.013293, loss_ce: 0.005352
2022-01-15 20:55:18,053 iteration 5770 : loss : 0.014393, loss_ce: 0.005843
2022-01-15 20:55:19,046 iteration 5771 : loss : 0.016013, loss_ce: 0.007618
2022-01-15 20:55:20,058 iteration 5772 : loss : 0.018730, loss_ce: 0.007276
2022-01-15 20:55:21,151 iteration 5773 : loss : 0.018277, loss_ce: 0.008059
2022-01-15 20:55:22,237 iteration 5774 : loss : 0.025042, loss_ce: 0.011863
2022-01-15 20:55:23,339 iteration 5775 : loss : 0.017248, loss_ce: 0.006000
2022-01-15 20:55:24,302 iteration 5776 : loss : 0.016259, loss_ce: 0.005832
2022-01-15 20:55:25,276 iteration 5777 : loss : 0.014462, loss_ce: 0.005464
2022-01-15 20:55:26,328 iteration 5778 : loss : 0.019805, loss_ce: 0.005953
2022-01-15 20:55:27,343 iteration 5779 : loss : 0.018286, loss_ce: 0.007937
2022-01-15 20:55:27,343 Training Data Eval:
2022-01-15 20:55:32,269   Average segmentation loss on training set: 0.0098
2022-01-15 20:55:32,269 Validation Data Eval:
2022-01-15 20:55:33,932   Average segmentation loss on validation set: 0.0759
2022-01-15 20:55:35,018 iteration 5780 : loss : 0.014672, loss_ce: 0.005124
 85%|████████████████████████▋    | 340/400 [1:44:42<19:36, 19.61s/it]2022-01-15 20:55:36,243 iteration 5781 : loss : 0.029588, loss_ce: 0.008406
2022-01-15 20:55:37,156 iteration 5782 : loss : 0.014324, loss_ce: 0.007564
2022-01-15 20:55:38,107 iteration 5783 : loss : 0.016417, loss_ce: 0.006592
2022-01-15 20:55:39,073 iteration 5784 : loss : 0.014985, loss_ce: 0.005386
2022-01-15 20:55:40,008 iteration 5785 : loss : 0.013472, loss_ce: 0.005770
2022-01-15 20:55:41,027 iteration 5786 : loss : 0.024816, loss_ce: 0.005679
2022-01-15 20:55:42,011 iteration 5787 : loss : 0.017013, loss_ce: 0.006680
2022-01-15 20:55:42,901 iteration 5788 : loss : 0.013176, loss_ce: 0.005001
2022-01-15 20:55:43,822 iteration 5789 : loss : 0.011776, loss_ce: 0.004612
2022-01-15 20:55:44,847 iteration 5790 : loss : 0.012579, loss_ce: 0.004406
2022-01-15 20:55:45,836 iteration 5791 : loss : 0.012605, loss_ce: 0.006077
2022-01-15 20:55:46,779 iteration 5792 : loss : 0.013588, loss_ce: 0.005263
2022-01-15 20:55:47,825 iteration 5793 : loss : 0.018588, loss_ce: 0.007261
2022-01-15 20:55:48,896 iteration 5794 : loss : 0.018307, loss_ce: 0.007858
2022-01-15 20:55:49,849 iteration 5795 : loss : 0.011022, loss_ce: 0.004637
2022-01-15 20:55:50,865 iteration 5796 : loss : 0.015188, loss_ce: 0.006451
2022-01-15 20:55:51,879 iteration 5797 : loss : 0.020816, loss_ce: 0.007255
 85%|████████████████████████▋    | 341/400 [1:44:59<18:28, 18.79s/it]2022-01-15 20:55:53,043 iteration 5798 : loss : 0.015510, loss_ce: 0.004148
2022-01-15 20:55:54,026 iteration 5799 : loss : 0.014598, loss_ce: 0.004685
2022-01-15 20:55:55,013 iteration 5800 : loss : 0.015026, loss_ce: 0.004349
2022-01-15 20:55:55,931 iteration 5801 : loss : 0.011249, loss_ce: 0.003994
2022-01-15 20:55:56,982 iteration 5802 : loss : 0.014056, loss_ce: 0.006522
2022-01-15 20:55:57,936 iteration 5803 : loss : 0.012722, loss_ce: 0.004313
2022-01-15 20:55:59,074 iteration 5804 : loss : 0.019034, loss_ce: 0.006661
2022-01-15 20:56:00,061 iteration 5805 : loss : 0.018087, loss_ce: 0.008543
2022-01-15 20:56:01,023 iteration 5806 : loss : 0.014398, loss_ce: 0.005654
2022-01-15 20:56:02,061 iteration 5807 : loss : 0.012710, loss_ce: 0.004449
2022-01-15 20:56:03,046 iteration 5808 : loss : 0.029178, loss_ce: 0.011174
2022-01-15 20:56:04,159 iteration 5809 : loss : 0.021754, loss_ce: 0.006198
2022-01-15 20:56:05,095 iteration 5810 : loss : 0.017626, loss_ce: 0.004651
2022-01-15 20:56:06,097 iteration 5811 : loss : 0.013783, loss_ce: 0.005664
2022-01-15 20:56:07,148 iteration 5812 : loss : 0.015631, loss_ce: 0.006796
2022-01-15 20:56:08,122 iteration 5813 : loss : 0.024751, loss_ce: 0.007504
2022-01-15 20:56:09,153 iteration 5814 : loss : 0.020406, loss_ce: 0.007656
 86%|████████████████████████▊    | 342/400 [1:45:17<17:43, 18.33s/it]2022-01-15 20:56:10,359 iteration 5815 : loss : 0.021376, loss_ce: 0.009001
2022-01-15 20:56:11,302 iteration 5816 : loss : 0.014579, loss_ce: 0.004399
2022-01-15 20:56:12,325 iteration 5817 : loss : 0.016321, loss_ce: 0.004288
2022-01-15 20:56:13,313 iteration 5818 : loss : 0.014665, loss_ce: 0.004540
2022-01-15 20:56:14,426 iteration 5819 : loss : 0.018231, loss_ce: 0.007625
2022-01-15 20:56:15,427 iteration 5820 : loss : 0.014074, loss_ce: 0.005773
2022-01-15 20:56:16,414 iteration 5821 : loss : 0.019046, loss_ce: 0.007037
2022-01-15 20:56:17,489 iteration 5822 : loss : 0.026362, loss_ce: 0.010100
2022-01-15 20:56:18,504 iteration 5823 : loss : 0.011923, loss_ce: 0.003975
2022-01-15 20:56:19,497 iteration 5824 : loss : 0.016651, loss_ce: 0.005688
2022-01-15 20:56:20,483 iteration 5825 : loss : 0.018067, loss_ce: 0.008532
2022-01-15 20:56:21,435 iteration 5826 : loss : 0.017092, loss_ce: 0.004808
2022-01-15 20:56:22,373 iteration 5827 : loss : 0.018446, loss_ce: 0.004918
2022-01-15 20:56:23,271 iteration 5828 : loss : 0.010803, loss_ce: 0.004649
2022-01-15 20:56:24,260 iteration 5829 : loss : 0.014203, loss_ce: 0.005240
2022-01-15 20:56:25,273 iteration 5830 : loss : 0.016282, loss_ce: 0.006887
2022-01-15 20:56:26,323 iteration 5831 : loss : 0.014868, loss_ce: 0.005317
 86%|████████████████████████▊    | 343/400 [1:45:34<17:05, 17.98s/it]2022-01-15 20:56:27,464 iteration 5832 : loss : 0.027713, loss_ce: 0.009670
2022-01-15 20:56:28,414 iteration 5833 : loss : 0.011158, loss_ce: 0.003849
2022-01-15 20:56:29,488 iteration 5834 : loss : 0.023017, loss_ce: 0.009800
2022-01-15 20:56:30,642 iteration 5835 : loss : 0.027206, loss_ce: 0.010105
2022-01-15 20:56:31,605 iteration 5836 : loss : 0.016023, loss_ce: 0.006782
2022-01-15 20:56:32,675 iteration 5837 : loss : 0.021315, loss_ce: 0.009076
2022-01-15 20:56:33,736 iteration 5838 : loss : 0.028563, loss_ce: 0.007316
2022-01-15 20:56:34,642 iteration 5839 : loss : 0.016270, loss_ce: 0.005582
2022-01-15 20:56:35,842 iteration 5840 : loss : 0.018345, loss_ce: 0.007731
2022-01-15 20:56:36,821 iteration 5841 : loss : 0.012775, loss_ce: 0.004807
2022-01-15 20:56:37,887 iteration 5842 : loss : 0.022173, loss_ce: 0.009190
2022-01-15 20:56:38,963 iteration 5843 : loss : 0.016894, loss_ce: 0.005907
2022-01-15 20:56:39,985 iteration 5844 : loss : 0.022466, loss_ce: 0.005457
2022-01-15 20:56:41,036 iteration 5845 : loss : 0.019834, loss_ce: 0.006799
2022-01-15 20:56:42,042 iteration 5846 : loss : 0.015143, loss_ce: 0.006138
2022-01-15 20:56:43,021 iteration 5847 : loss : 0.011626, loss_ce: 0.003950
2022-01-15 20:56:43,928 iteration 5848 : loss : 0.011176, loss_ce: 0.003425
 86%|████████████████████████▉    | 344/400 [1:45:51<16:40, 17.87s/it]2022-01-15 20:56:44,920 iteration 5849 : loss : 0.012825, loss_ce: 0.004337
2022-01-15 20:56:45,982 iteration 5850 : loss : 0.021508, loss_ce: 0.006223
2022-01-15 20:56:46,923 iteration 5851 : loss : 0.012484, loss_ce: 0.004598
2022-01-15 20:56:47,886 iteration 5852 : loss : 0.014183, loss_ce: 0.004821
2022-01-15 20:56:48,817 iteration 5853 : loss : 0.019811, loss_ce: 0.006283
2022-01-15 20:56:49,815 iteration 5854 : loss : 0.016823, loss_ce: 0.006803
2022-01-15 20:56:50,796 iteration 5855 : loss : 0.019367, loss_ce: 0.005119
2022-01-15 20:56:51,731 iteration 5856 : loss : 0.016358, loss_ce: 0.007244
2022-01-15 20:56:52,769 iteration 5857 : loss : 0.015847, loss_ce: 0.006667
2022-01-15 20:56:53,747 iteration 5858 : loss : 0.015410, loss_ce: 0.003950
2022-01-15 20:56:54,783 iteration 5859 : loss : 0.018019, loss_ce: 0.009512
2022-01-15 20:56:55,818 iteration 5860 : loss : 0.014245, loss_ce: 0.006487
2022-01-15 20:56:56,855 iteration 5861 : loss : 0.017325, loss_ce: 0.008009
2022-01-15 20:56:57,853 iteration 5862 : loss : 0.011334, loss_ce: 0.004435
2022-01-15 20:56:58,851 iteration 5863 : loss : 0.015313, loss_ce: 0.005756
2022-01-15 20:56:59,841 iteration 5864 : loss : 0.016110, loss_ce: 0.006040
2022-01-15 20:56:59,842 Training Data Eval:
2022-01-15 20:57:04,750   Average segmentation loss on training set: 0.0094
2022-01-15 20:57:04,751 Validation Data Eval:
2022-01-15 20:57:06,426   Average segmentation loss on validation set: 0.0672
2022-01-15 20:57:07,417 iteration 5865 : loss : 0.012152, loss_ce: 0.004286
 86%|█████████████████████████    | 345/400 [1:46:15<17:55, 19.56s/it]2022-01-15 20:57:08,513 iteration 5866 : loss : 0.019896, loss_ce: 0.005907
2022-01-15 20:57:09,532 iteration 5867 : loss : 0.012986, loss_ce: 0.005418
2022-01-15 20:57:10,454 iteration 5868 : loss : 0.011236, loss_ce: 0.004468
2022-01-15 20:57:11,417 iteration 5869 : loss : 0.010897, loss_ce: 0.003749
2022-01-15 20:57:12,327 iteration 5870 : loss : 0.013756, loss_ce: 0.005076
2022-01-15 20:57:13,314 iteration 5871 : loss : 0.013608, loss_ce: 0.006192
2022-01-15 20:57:14,298 iteration 5872 : loss : 0.013739, loss_ce: 0.005994
2022-01-15 20:57:15,222 iteration 5873 : loss : 0.013673, loss_ce: 0.006153
2022-01-15 20:57:16,153 iteration 5874 : loss : 0.023444, loss_ce: 0.004865
2022-01-15 20:57:17,235 iteration 5875 : loss : 0.017072, loss_ce: 0.007462
2022-01-15 20:57:18,320 iteration 5876 : loss : 0.019812, loss_ce: 0.008787
2022-01-15 20:57:19,338 iteration 5877 : loss : 0.020796, loss_ce: 0.007698
2022-01-15 20:57:20,381 iteration 5878 : loss : 0.020418, loss_ce: 0.006060
2022-01-15 20:57:21,343 iteration 5879 : loss : 0.019932, loss_ce: 0.005690
2022-01-15 20:57:22,321 iteration 5880 : loss : 0.022108, loss_ce: 0.008377
2022-01-15 20:57:23,361 iteration 5881 : loss : 0.026456, loss_ce: 0.007327
2022-01-15 20:57:24,337 iteration 5882 : loss : 0.012987, loss_ce: 0.004387
 86%|█████████████████████████    | 346/400 [1:46:32<16:53, 18.76s/it]2022-01-15 20:57:25,520 iteration 5883 : loss : 0.017786, loss_ce: 0.005723
2022-01-15 20:57:26,466 iteration 5884 : loss : 0.013330, loss_ce: 0.005125
2022-01-15 20:57:27,524 iteration 5885 : loss : 0.020677, loss_ce: 0.004891
2022-01-15 20:57:28,484 iteration 5886 : loss : 0.010648, loss_ce: 0.003728
2022-01-15 20:57:29,462 iteration 5887 : loss : 0.032354, loss_ce: 0.008970
2022-01-15 20:57:30,368 iteration 5888 : loss : 0.013419, loss_ce: 0.005455
2022-01-15 20:57:31,354 iteration 5889 : loss : 0.015954, loss_ce: 0.006602
2022-01-15 20:57:32,403 iteration 5890 : loss : 0.015605, loss_ce: 0.006816
2022-01-15 20:57:33,446 iteration 5891 : loss : 0.015316, loss_ce: 0.004854
2022-01-15 20:57:34,511 iteration 5892 : loss : 0.016407, loss_ce: 0.007829
2022-01-15 20:57:35,414 iteration 5893 : loss : 0.014058, loss_ce: 0.004288
2022-01-15 20:57:36,358 iteration 5894 : loss : 0.011163, loss_ce: 0.003251
2022-01-15 20:57:37,386 iteration 5895 : loss : 0.016677, loss_ce: 0.007201
2022-01-15 20:57:38,286 iteration 5896 : loss : 0.013043, loss_ce: 0.004282
2022-01-15 20:57:39,300 iteration 5897 : loss : 0.015381, loss_ce: 0.006615
2022-01-15 20:57:40,353 iteration 5898 : loss : 0.017289, loss_ce: 0.006552
2022-01-15 20:57:41,319 iteration 5899 : loss : 0.017831, loss_ce: 0.005742
 87%|█████████████████████████▏   | 347/400 [1:46:49<16:06, 18.23s/it]2022-01-15 20:57:42,257 iteration 5900 : loss : 0.011002, loss_ce: 0.004305
2022-01-15 20:57:43,200 iteration 5901 : loss : 0.011170, loss_ce: 0.004555
2022-01-15 20:57:44,107 iteration 5902 : loss : 0.011287, loss_ce: 0.004320
2022-01-15 20:57:45,064 iteration 5903 : loss : 0.017609, loss_ce: 0.006946
2022-01-15 20:57:46,069 iteration 5904 : loss : 0.020662, loss_ce: 0.007234
2022-01-15 20:57:47,105 iteration 5905 : loss : 0.021416, loss_ce: 0.009392
2022-01-15 20:57:48,147 iteration 5906 : loss : 0.014412, loss_ce: 0.003359
2022-01-15 20:57:49,049 iteration 5907 : loss : 0.011292, loss_ce: 0.005113
2022-01-15 20:57:50,028 iteration 5908 : loss : 0.016234, loss_ce: 0.005648
2022-01-15 20:57:51,056 iteration 5909 : loss : 0.015701, loss_ce: 0.007834
2022-01-15 20:57:52,032 iteration 5910 : loss : 0.013020, loss_ce: 0.004042
2022-01-15 20:57:53,051 iteration 5911 : loss : 0.015169, loss_ce: 0.003843
2022-01-15 20:57:54,040 iteration 5912 : loss : 0.019412, loss_ce: 0.004626
2022-01-15 20:57:55,018 iteration 5913 : loss : 0.014851, loss_ce: 0.006051
2022-01-15 20:57:55,981 iteration 5914 : loss : 0.015965, loss_ce: 0.008401
2022-01-15 20:57:56,995 iteration 5915 : loss : 0.018898, loss_ce: 0.009786
2022-01-15 20:57:57,919 iteration 5916 : loss : 0.011575, loss_ce: 0.004066
 87%|█████████████████████████▏   | 348/400 [1:47:05<15:22, 17.74s/it]2022-01-15 20:57:58,907 iteration 5917 : loss : 0.012252, loss_ce: 0.004641
2022-01-15 20:57:59,968 iteration 5918 : loss : 0.021304, loss_ce: 0.010019
2022-01-15 20:58:01,030 iteration 5919 : loss : 0.018712, loss_ce: 0.007628
2022-01-15 20:58:02,096 iteration 5920 : loss : 0.015865, loss_ce: 0.005941
2022-01-15 20:58:03,057 iteration 5921 : loss : 0.017694, loss_ce: 0.005948
2022-01-15 20:58:04,087 iteration 5922 : loss : 0.015647, loss_ce: 0.007241
2022-01-15 20:58:05,091 iteration 5923 : loss : 0.015551, loss_ce: 0.006279
2022-01-15 20:58:05,988 iteration 5924 : loss : 0.013913, loss_ce: 0.005071
2022-01-15 20:58:06,960 iteration 5925 : loss : 0.013969, loss_ce: 0.004447
2022-01-15 20:58:08,013 iteration 5926 : loss : 0.019026, loss_ce: 0.006179
2022-01-15 20:58:08,946 iteration 5927 : loss : 0.011186, loss_ce: 0.004503
2022-01-15 20:58:09,990 iteration 5928 : loss : 0.012487, loss_ce: 0.004770
2022-01-15 20:58:11,006 iteration 5929 : loss : 0.019197, loss_ce: 0.008330
2022-01-15 20:58:12,065 iteration 5930 : loss : 0.017077, loss_ce: 0.005963
2022-01-15 20:58:12,996 iteration 5931 : loss : 0.015301, loss_ce: 0.006400
2022-01-15 20:58:13,998 iteration 5932 : loss : 0.014583, loss_ce: 0.004954
2022-01-15 20:58:15,034 iteration 5933 : loss : 0.022223, loss_ce: 0.005920
 87%|█████████████████████████▎   | 349/400 [1:47:22<14:55, 17.55s/it]2022-01-15 20:58:16,104 iteration 5934 : loss : 0.011239, loss_ce: 0.003773
2022-01-15 20:58:17,097 iteration 5935 : loss : 0.012668, loss_ce: 0.003863
2022-01-15 20:58:18,193 iteration 5936 : loss : 0.022270, loss_ce: 0.007907
2022-01-15 20:58:19,257 iteration 5937 : loss : 0.016613, loss_ce: 0.006764
2022-01-15 20:58:20,267 iteration 5938 : loss : 0.022612, loss_ce: 0.012065
2022-01-15 20:58:21,235 iteration 5939 : loss : 0.013107, loss_ce: 0.005421
2022-01-15 20:58:22,263 iteration 5940 : loss : 0.012772, loss_ce: 0.005359
2022-01-15 20:58:23,173 iteration 5941 : loss : 0.012027, loss_ce: 0.005505
2022-01-15 20:58:24,231 iteration 5942 : loss : 0.029248, loss_ce: 0.009613
2022-01-15 20:58:25,171 iteration 5943 : loss : 0.011062, loss_ce: 0.003996
2022-01-15 20:58:26,182 iteration 5944 : loss : 0.015806, loss_ce: 0.005639
2022-01-15 20:58:27,165 iteration 5945 : loss : 0.013177, loss_ce: 0.004242
2022-01-15 20:58:28,110 iteration 5946 : loss : 0.017132, loss_ce: 0.006385
2022-01-15 20:58:29,047 iteration 5947 : loss : 0.012097, loss_ce: 0.004574
2022-01-15 20:58:30,116 iteration 5948 : loss : 0.014958, loss_ce: 0.005966
2022-01-15 20:58:31,063 iteration 5949 : loss : 0.013296, loss_ce: 0.005553
2022-01-15 20:58:31,064 Training Data Eval:
2022-01-15 20:58:35,862   Average segmentation loss on training set: 0.0091
2022-01-15 20:58:35,862 Validation Data Eval:
2022-01-15 20:58:37,504   Average segmentation loss on validation set: 0.0798
2022-01-15 20:58:38,607 iteration 5950 : loss : 0.016143, loss_ce: 0.005303
 88%|█████████████████████████▍   | 350/400 [1:47:46<16:07, 19.36s/it]2022-01-15 20:58:39,649 iteration 5951 : loss : 0.019840, loss_ce: 0.008541
2022-01-15 20:58:40,656 iteration 5952 : loss : 0.013910, loss_ce: 0.007064
2022-01-15 20:58:41,675 iteration 5953 : loss : 0.017054, loss_ce: 0.008115
2022-01-15 20:58:42,753 iteration 5954 : loss : 0.024484, loss_ce: 0.008526
2022-01-15 20:58:43,729 iteration 5955 : loss : 0.016814, loss_ce: 0.005808
2022-01-15 20:58:44,796 iteration 5956 : loss : 0.018753, loss_ce: 0.006019
2022-01-15 20:58:45,761 iteration 5957 : loss : 0.021953, loss_ce: 0.005881
2022-01-15 20:58:46,702 iteration 5958 : loss : 0.012787, loss_ce: 0.005788
2022-01-15 20:58:47,682 iteration 5959 : loss : 0.013158, loss_ce: 0.004229
2022-01-15 20:58:48,624 iteration 5960 : loss : 0.009205, loss_ce: 0.002811
2022-01-15 20:58:49,637 iteration 5961 : loss : 0.017217, loss_ce: 0.006567
2022-01-15 20:58:50,687 iteration 5962 : loss : 0.016874, loss_ce: 0.007093
2022-01-15 20:58:51,595 iteration 5963 : loss : 0.012464, loss_ce: 0.005002
2022-01-15 20:58:52,778 iteration 5964 : loss : 0.034748, loss_ce: 0.013641
2022-01-15 20:58:53,725 iteration 5965 : loss : 0.013251, loss_ce: 0.004804
2022-01-15 20:58:54,758 iteration 5966 : loss : 0.017604, loss_ce: 0.006770
2022-01-15 20:58:55,735 iteration 5967 : loss : 0.022353, loss_ce: 0.007122
 88%|█████████████████████████▍   | 351/400 [1:48:03<15:15, 18.68s/it]2022-01-15 20:58:56,751 iteration 5968 : loss : 0.015805, loss_ce: 0.007777
2022-01-15 20:58:57,781 iteration 5969 : loss : 0.023400, loss_ce: 0.006324
2022-01-15 20:58:58,777 iteration 5970 : loss : 0.013828, loss_ce: 0.005100
2022-01-15 20:58:59,674 iteration 5971 : loss : 0.011284, loss_ce: 0.004494
2022-01-15 20:59:00,621 iteration 5972 : loss : 0.013736, loss_ce: 0.004876
2022-01-15 20:59:01,622 iteration 5973 : loss : 0.012080, loss_ce: 0.005023
2022-01-15 20:59:02,557 iteration 5974 : loss : 0.016522, loss_ce: 0.006108
2022-01-15 20:59:03,581 iteration 5975 : loss : 0.020281, loss_ce: 0.006581
2022-01-15 20:59:04,579 iteration 5976 : loss : 0.018886, loss_ce: 0.004375
2022-01-15 20:59:05,584 iteration 5977 : loss : 0.013516, loss_ce: 0.004658
2022-01-15 20:59:06,576 iteration 5978 : loss : 0.013756, loss_ce: 0.005766
2022-01-15 20:59:07,523 iteration 5979 : loss : 0.014092, loss_ce: 0.005443
2022-01-15 20:59:08,556 iteration 5980 : loss : 0.010621, loss_ce: 0.003475
2022-01-15 20:59:09,575 iteration 5981 : loss : 0.018081, loss_ce: 0.006922
2022-01-15 20:59:10,628 iteration 5982 : loss : 0.018413, loss_ce: 0.007210
2022-01-15 20:59:11,543 iteration 5983 : loss : 0.014665, loss_ce: 0.006993
2022-01-15 20:59:12,479 iteration 5984 : loss : 0.014379, loss_ce: 0.004436
 88%|█████████████████████████▌   | 352/400 [1:48:20<14:29, 18.11s/it]2022-01-15 20:59:13,656 iteration 5985 : loss : 0.024265, loss_ce: 0.011421
2022-01-15 20:59:14,604 iteration 5986 : loss : 0.014714, loss_ce: 0.006120
2022-01-15 20:59:15,654 iteration 5987 : loss : 0.028993, loss_ce: 0.006711
2022-01-15 20:59:16,738 iteration 5988 : loss : 0.016305, loss_ce: 0.008077
2022-01-15 20:59:17,735 iteration 5989 : loss : 0.015677, loss_ce: 0.006119
2022-01-15 20:59:18,782 iteration 5990 : loss : 0.016895, loss_ce: 0.009869
2022-01-15 20:59:19,711 iteration 5991 : loss : 0.012341, loss_ce: 0.004207
2022-01-15 20:59:20,777 iteration 5992 : loss : 0.015905, loss_ce: 0.005012
2022-01-15 20:59:21,742 iteration 5993 : loss : 0.009677, loss_ce: 0.003261
2022-01-15 20:59:22,747 iteration 5994 : loss : 0.021186, loss_ce: 0.007165
2022-01-15 20:59:23,790 iteration 5995 : loss : 0.020561, loss_ce: 0.007475
2022-01-15 20:59:24,890 iteration 5996 : loss : 0.023858, loss_ce: 0.009669
2022-01-15 20:59:25,968 iteration 5997 : loss : 0.016903, loss_ce: 0.007474
2022-01-15 20:59:26,921 iteration 5998 : loss : 0.023647, loss_ce: 0.009888
2022-01-15 20:59:27,952 iteration 5999 : loss : 0.026085, loss_ce: 0.007253
2022-01-15 20:59:28,980 iteration 6000 : loss : 0.016949, loss_ce: 0.006746
2022-01-15 20:59:30,052 iteration 6001 : loss : 0.023827, loss_ce: 0.008040
 88%|█████████████████████████▌   | 353/400 [1:48:37<14:03, 17.94s/it]2022-01-15 20:59:31,111 iteration 6002 : loss : 0.012425, loss_ce: 0.004991
2022-01-15 20:59:32,154 iteration 6003 : loss : 0.017128, loss_ce: 0.006058
2022-01-15 20:59:33,157 iteration 6004 : loss : 0.016487, loss_ce: 0.007896
2022-01-15 20:59:34,207 iteration 6005 : loss : 0.017247, loss_ce: 0.008418
2022-01-15 20:59:35,151 iteration 6006 : loss : 0.015472, loss_ce: 0.007752
2022-01-15 20:59:36,152 iteration 6007 : loss : 0.015612, loss_ce: 0.005032
2022-01-15 20:59:37,145 iteration 6008 : loss : 0.016006, loss_ce: 0.006305
2022-01-15 20:59:38,234 iteration 6009 : loss : 0.020713, loss_ce: 0.007444
2022-01-15 20:59:39,130 iteration 6010 : loss : 0.012678, loss_ce: 0.005332
2022-01-15 20:59:40,160 iteration 6011 : loss : 0.021312, loss_ce: 0.007738
2022-01-15 20:59:41,154 iteration 6012 : loss : 0.021856, loss_ce: 0.006680
2022-01-15 20:59:42,268 iteration 6013 : loss : 0.020878, loss_ce: 0.007769
2022-01-15 20:59:43,258 iteration 6014 : loss : 0.012989, loss_ce: 0.005132
2022-01-15 20:59:44,223 iteration 6015 : loss : 0.017515, loss_ce: 0.005727
2022-01-15 20:59:45,240 iteration 6016 : loss : 0.013790, loss_ce: 0.003933
2022-01-15 20:59:46,182 iteration 6017 : loss : 0.019062, loss_ce: 0.005099
2022-01-15 20:59:47,285 iteration 6018 : loss : 0.016464, loss_ce: 0.005464
 88%|█████████████████████████▋   | 354/400 [1:48:55<13:35, 17.74s/it]2022-01-15 20:59:48,392 iteration 6019 : loss : 0.022934, loss_ce: 0.007674
2022-01-15 20:59:49,375 iteration 6020 : loss : 0.016315, loss_ce: 0.006065
2022-01-15 20:59:50,354 iteration 6021 : loss : 0.016229, loss_ce: 0.005361
2022-01-15 20:59:51,362 iteration 6022 : loss : 0.013131, loss_ce: 0.004857
2022-01-15 20:59:52,269 iteration 6023 : loss : 0.012179, loss_ce: 0.004178
2022-01-15 20:59:53,327 iteration 6024 : loss : 0.018481, loss_ce: 0.007138
2022-01-15 20:59:54,374 iteration 6025 : loss : 0.024343, loss_ce: 0.008370
2022-01-15 20:59:55,406 iteration 6026 : loss : 0.027401, loss_ce: 0.008873
2022-01-15 20:59:56,350 iteration 6027 : loss : 0.015918, loss_ce: 0.006544
2022-01-15 20:59:57,287 iteration 6028 : loss : 0.017908, loss_ce: 0.007162
2022-01-15 20:59:58,323 iteration 6029 : loss : 0.018752, loss_ce: 0.007965
2022-01-15 20:59:59,254 iteration 6030 : loss : 0.013355, loss_ce: 0.004922
2022-01-15 21:00:00,341 iteration 6031 : loss : 0.025856, loss_ce: 0.006917
2022-01-15 21:00:01,366 iteration 6032 : loss : 0.016910, loss_ce: 0.005558
2022-01-15 21:00:02,394 iteration 6033 : loss : 0.015861, loss_ce: 0.007071
2022-01-15 21:00:03,469 iteration 6034 : loss : 0.019361, loss_ce: 0.006769
2022-01-15 21:00:03,469 Training Data Eval:
2022-01-15 21:00:08,191   Average segmentation loss on training set: 0.0092
2022-01-15 21:00:08,191 Validation Data Eval:
2022-01-15 21:00:09,819   Average segmentation loss on validation set: 0.0713
2022-01-15 21:00:10,768 iteration 6035 : loss : 0.017419, loss_ce: 0.004316
 89%|█████████████████████████▋   | 355/400 [1:49:18<14:35, 19.46s/it]2022-01-15 21:00:11,883 iteration 6036 : loss : 0.023426, loss_ce: 0.007775
2022-01-15 21:00:12,955 iteration 6037 : loss : 0.018704, loss_ce: 0.006913
2022-01-15 21:00:13,913 iteration 6038 : loss : 0.015847, loss_ce: 0.006428
2022-01-15 21:00:14,926 iteration 6039 : loss : 0.017476, loss_ce: 0.007799
2022-01-15 21:00:15,930 iteration 6040 : loss : 0.014274, loss_ce: 0.006158
2022-01-15 21:00:17,056 iteration 6041 : loss : 0.033500, loss_ce: 0.010203
2022-01-15 21:00:18,112 iteration 6042 : loss : 0.049162, loss_ce: 0.022436
2022-01-15 21:00:19,099 iteration 6043 : loss : 0.018768, loss_ce: 0.007926
2022-01-15 21:00:20,075 iteration 6044 : loss : 0.015720, loss_ce: 0.005093
2022-01-15 21:00:21,129 iteration 6045 : loss : 0.027167, loss_ce: 0.009377
2022-01-15 21:00:22,127 iteration 6046 : loss : 0.017461, loss_ce: 0.005503
2022-01-15 21:00:23,088 iteration 6047 : loss : 0.019782, loss_ce: 0.005422
2022-01-15 21:00:24,194 iteration 6048 : loss : 0.025556, loss_ce: 0.004738
2022-01-15 21:00:25,234 iteration 6049 : loss : 0.021043, loss_ce: 0.009159
2022-01-15 21:00:26,191 iteration 6050 : loss : 0.014030, loss_ce: 0.005926
2022-01-15 21:00:27,254 iteration 6051 : loss : 0.017761, loss_ce: 0.007301
2022-01-15 21:00:28,154 iteration 6052 : loss : 0.013239, loss_ce: 0.003229
 89%|█████████████████████████▊   | 356/400 [1:49:36<13:48, 18.83s/it]2022-01-15 21:00:29,171 iteration 6053 : loss : 0.015091, loss_ce: 0.006968
2022-01-15 21:00:30,252 iteration 6054 : loss : 0.021956, loss_ce: 0.008263
2022-01-15 21:00:31,207 iteration 6055 : loss : 0.013790, loss_ce: 0.004815
2022-01-15 21:00:32,148 iteration 6056 : loss : 0.013116, loss_ce: 0.004643
2022-01-15 21:00:33,092 iteration 6057 : loss : 0.022184, loss_ce: 0.006782
2022-01-15 21:00:34,136 iteration 6058 : loss : 0.013767, loss_ce: 0.005747
2022-01-15 21:00:35,055 iteration 6059 : loss : 0.011752, loss_ce: 0.004547
2022-01-15 21:00:36,108 iteration 6060 : loss : 0.012073, loss_ce: 0.005085
2022-01-15 21:00:37,032 iteration 6061 : loss : 0.016803, loss_ce: 0.007036
2022-01-15 21:00:38,117 iteration 6062 : loss : 0.020291, loss_ce: 0.009306
2022-01-15 21:00:39,184 iteration 6063 : loss : 0.026645, loss_ce: 0.008387
2022-01-15 21:00:40,172 iteration 6064 : loss : 0.022061, loss_ce: 0.005572
2022-01-15 21:00:41,251 iteration 6065 : loss : 0.020069, loss_ce: 0.009548
2022-01-15 21:00:42,216 iteration 6066 : loss : 0.014149, loss_ce: 0.005159
2022-01-15 21:00:43,153 iteration 6067 : loss : 0.043932, loss_ce: 0.006199
2022-01-15 21:00:44,239 iteration 6068 : loss : 0.026820, loss_ce: 0.009921
2022-01-15 21:00:45,203 iteration 6069 : loss : 0.035572, loss_ce: 0.009622
 89%|█████████████████████████▉   | 357/400 [1:49:53<13:06, 18.30s/it]2022-01-15 21:00:46,303 iteration 6070 : loss : 0.017464, loss_ce: 0.008940
2022-01-15 21:00:47,334 iteration 6071 : loss : 0.013846, loss_ce: 0.004037
2022-01-15 21:00:48,326 iteration 6072 : loss : 0.013353, loss_ce: 0.004294
2022-01-15 21:00:49,345 iteration 6073 : loss : 0.021565, loss_ce: 0.008359
2022-01-15 21:00:50,349 iteration 6074 : loss : 0.012266, loss_ce: 0.003557
2022-01-15 21:00:51,409 iteration 6075 : loss : 0.016052, loss_ce: 0.006949
2022-01-15 21:00:52,401 iteration 6076 : loss : 0.014035, loss_ce: 0.005608
2022-01-15 21:00:53,360 iteration 6077 : loss : 0.013875, loss_ce: 0.006095
2022-01-15 21:00:54,340 iteration 6078 : loss : 0.014413, loss_ce: 0.004788
2022-01-15 21:00:55,349 iteration 6079 : loss : 0.014098, loss_ce: 0.003611
2022-01-15 21:00:56,349 iteration 6080 : loss : 0.015592, loss_ce: 0.004533
2022-01-15 21:00:57,264 iteration 6081 : loss : 0.015138, loss_ce: 0.004661
2022-01-15 21:00:58,336 iteration 6082 : loss : 0.024838, loss_ce: 0.010497
2022-01-15 21:00:59,429 iteration 6083 : loss : 0.022422, loss_ce: 0.008928
2022-01-15 21:01:00,388 iteration 6084 : loss : 0.015621, loss_ce: 0.005705
2022-01-15 21:01:01,350 iteration 6085 : loss : 0.014514, loss_ce: 0.007340
2022-01-15 21:01:02,500 iteration 6086 : loss : 0.037683, loss_ce: 0.014453
 90%|█████████████████████████▉   | 358/400 [1:50:10<12:35, 18.00s/it]2022-01-15 21:01:03,575 iteration 6087 : loss : 0.019685, loss_ce: 0.006043
2022-01-15 21:01:04,582 iteration 6088 : loss : 0.015154, loss_ce: 0.005249
2022-01-15 21:01:05,651 iteration 6089 : loss : 0.021705, loss_ce: 0.009120
2022-01-15 21:01:06,631 iteration 6090 : loss : 0.013889, loss_ce: 0.004667
2022-01-15 21:01:07,587 iteration 6091 : loss : 0.009749, loss_ce: 0.002889
2022-01-15 21:01:08,685 iteration 6092 : loss : 0.023230, loss_ce: 0.009445
2022-01-15 21:01:09,816 iteration 6093 : loss : 0.021920, loss_ce: 0.009426
2022-01-15 21:01:10,902 iteration 6094 : loss : 0.020147, loss_ce: 0.010102
2022-01-15 21:01:11,844 iteration 6095 : loss : 0.014723, loss_ce: 0.004646
2022-01-15 21:01:12,948 iteration 6096 : loss : 0.022414, loss_ce: 0.005053
2022-01-15 21:01:13,917 iteration 6097 : loss : 0.013290, loss_ce: 0.006759
2022-01-15 21:01:14,966 iteration 6098 : loss : 0.016471, loss_ce: 0.009344
2022-01-15 21:01:15,991 iteration 6099 : loss : 0.015366, loss_ce: 0.006870
2022-01-15 21:01:17,044 iteration 6100 : loss : 0.018058, loss_ce: 0.005971
2022-01-15 21:01:18,152 iteration 6101 : loss : 0.019755, loss_ce: 0.007966
2022-01-15 21:01:19,113 iteration 6102 : loss : 0.013000, loss_ce: 0.005416
2022-01-15 21:01:20,150 iteration 6103 : loss : 0.017184, loss_ce: 0.004987
 90%|██████████████████████████   | 359/400 [1:50:28<12:13, 17.90s/it]2022-01-15 21:01:21,278 iteration 6104 : loss : 0.015688, loss_ce: 0.006489
2022-01-15 21:01:22,261 iteration 6105 : loss : 0.020357, loss_ce: 0.005748
2022-01-15 21:01:23,219 iteration 6106 : loss : 0.011588, loss_ce: 0.004702
2022-01-15 21:01:24,187 iteration 6107 : loss : 0.011796, loss_ce: 0.004776
2022-01-15 21:01:25,207 iteration 6108 : loss : 0.012946, loss_ce: 0.004437
2022-01-15 21:01:26,268 iteration 6109 : loss : 0.020740, loss_ce: 0.009704
2022-01-15 21:01:27,216 iteration 6110 : loss : 0.013477, loss_ce: 0.005988
2022-01-15 21:01:28,240 iteration 6111 : loss : 0.020227, loss_ce: 0.006949
2022-01-15 21:01:29,303 iteration 6112 : loss : 0.023863, loss_ce: 0.006205
2022-01-15 21:01:30,303 iteration 6113 : loss : 0.018348, loss_ce: 0.007252
2022-01-15 21:01:31,314 iteration 6114 : loss : 0.018804, loss_ce: 0.007372
2022-01-15 21:01:32,379 iteration 6115 : loss : 0.024527, loss_ce: 0.006518
2022-01-15 21:01:33,369 iteration 6116 : loss : 0.019272, loss_ce: 0.005931
2022-01-15 21:01:34,338 iteration 6117 : loss : 0.014725, loss_ce: 0.005139
2022-01-15 21:01:35,367 iteration 6118 : loss : 0.014839, loss_ce: 0.007398
2022-01-15 21:01:36,359 iteration 6119 : loss : 0.013479, loss_ce: 0.005514
2022-01-15 21:01:36,359 Training Data Eval:
2022-01-15 21:01:41,259   Average segmentation loss on training set: 0.0092
2022-01-15 21:01:41,259 Validation Data Eval:
2022-01-15 21:01:42,918   Average segmentation loss on validation set: 0.0702
2022-01-15 21:01:44,001 iteration 6120 : loss : 0.022197, loss_ce: 0.008338
 90%|██████████████████████████   | 360/400 [1:50:51<13:07, 19.68s/it]2022-01-15 21:01:45,117 iteration 6121 : loss : 0.013434, loss_ce: 0.004406
2022-01-15 21:01:46,135 iteration 6122 : loss : 0.017143, loss_ce: 0.007516
2022-01-15 21:01:47,131 iteration 6123 : loss : 0.015102, loss_ce: 0.005741
2022-01-15 21:01:48,231 iteration 6124 : loss : 0.025302, loss_ce: 0.008974
2022-01-15 21:01:49,250 iteration 6125 : loss : 0.013899, loss_ce: 0.004236
2022-01-15 21:01:50,381 iteration 6126 : loss : 0.018555, loss_ce: 0.006643
2022-01-15 21:01:51,502 iteration 6127 : loss : 0.021028, loss_ce: 0.010203
2022-01-15 21:01:52,490 iteration 6128 : loss : 0.012811, loss_ce: 0.004375
2022-01-15 21:01:53,433 iteration 6129 : loss : 0.013392, loss_ce: 0.004596
2022-01-15 21:01:54,452 iteration 6130 : loss : 0.019552, loss_ce: 0.007834
2022-01-15 21:01:55,408 iteration 6131 : loss : 0.019661, loss_ce: 0.006309
2022-01-15 21:01:56,472 iteration 6132 : loss : 0.016696, loss_ce: 0.005238
2022-01-15 21:01:57,505 iteration 6133 : loss : 0.015870, loss_ce: 0.006351
2022-01-15 21:01:58,467 iteration 6134 : loss : 0.013580, loss_ce: 0.004843
2022-01-15 21:01:59,402 iteration 6135 : loss : 0.013995, loss_ce: 0.006421
2022-01-15 21:02:00,363 iteration 6136 : loss : 0.011357, loss_ce: 0.003261
2022-01-15 21:02:01,328 iteration 6137 : loss : 0.020198, loss_ce: 0.005993
 90%|██████████████████████████▏  | 361/400 [1:51:09<12:20, 18.98s/it]2022-01-15 21:02:02,392 iteration 6138 : loss : 0.020436, loss_ce: 0.008353
2022-01-15 21:02:03,348 iteration 6139 : loss : 0.015560, loss_ce: 0.003597
2022-01-15 21:02:04,299 iteration 6140 : loss : 0.014218, loss_ce: 0.005032
2022-01-15 21:02:05,231 iteration 6141 : loss : 0.014274, loss_ce: 0.006308
2022-01-15 21:02:06,276 iteration 6142 : loss : 0.014573, loss_ce: 0.005948
2022-01-15 21:02:07,228 iteration 6143 : loss : 0.026086, loss_ce: 0.015152
2022-01-15 21:02:08,331 iteration 6144 : loss : 0.017016, loss_ce: 0.007295
2022-01-15 21:02:09,285 iteration 6145 : loss : 0.014336, loss_ce: 0.005834
2022-01-15 21:02:10,208 iteration 6146 : loss : 0.015508, loss_ce: 0.004763
2022-01-15 21:02:11,207 iteration 6147 : loss : 0.014523, loss_ce: 0.005408
2022-01-15 21:02:12,199 iteration 6148 : loss : 0.016218, loss_ce: 0.006890
2022-01-15 21:02:13,168 iteration 6149 : loss : 0.014871, loss_ce: 0.004737
2022-01-15 21:02:14,208 iteration 6150 : loss : 0.016210, loss_ce: 0.005536
2022-01-15 21:02:15,360 iteration 6151 : loss : 0.016880, loss_ce: 0.004301
2022-01-15 21:02:16,343 iteration 6152 : loss : 0.014571, loss_ce: 0.006286
2022-01-15 21:02:17,362 iteration 6153 : loss : 0.012951, loss_ce: 0.004878
2022-01-15 21:02:18,442 iteration 6154 : loss : 0.020848, loss_ce: 0.007544
 90%|██████████████████████████▏  | 362/400 [1:51:26<11:39, 18.42s/it]2022-01-15 21:02:19,584 iteration 6155 : loss : 0.019096, loss_ce: 0.007786
2022-01-15 21:02:20,518 iteration 6156 : loss : 0.012106, loss_ce: 0.005088
2022-01-15 21:02:21,498 iteration 6157 : loss : 0.011180, loss_ce: 0.003480
2022-01-15 21:02:22,513 iteration 6158 : loss : 0.014057, loss_ce: 0.004997
2022-01-15 21:02:23,453 iteration 6159 : loss : 0.014670, loss_ce: 0.004875
2022-01-15 21:02:24,432 iteration 6160 : loss : 0.015227, loss_ce: 0.006554
2022-01-15 21:02:25,426 iteration 6161 : loss : 0.015117, loss_ce: 0.004319
2022-01-15 21:02:26,457 iteration 6162 : loss : 0.017210, loss_ce: 0.003995
2022-01-15 21:02:27,460 iteration 6163 : loss : 0.016029, loss_ce: 0.006586
2022-01-15 21:02:28,509 iteration 6164 : loss : 0.028401, loss_ce: 0.016032
2022-01-15 21:02:29,495 iteration 6165 : loss : 0.016512, loss_ce: 0.006007
2022-01-15 21:02:30,469 iteration 6166 : loss : 0.013769, loss_ce: 0.005129
2022-01-15 21:02:31,417 iteration 6167 : loss : 0.015665, loss_ce: 0.006381
2022-01-15 21:02:32,450 iteration 6168 : loss : 0.029630, loss_ce: 0.011461
2022-01-15 21:02:33,459 iteration 6169 : loss : 0.015918, loss_ce: 0.004965
2022-01-15 21:02:34,420 iteration 6170 : loss : 0.014256, loss_ce: 0.005608
2022-01-15 21:02:35,365 iteration 6171 : loss : 0.014061, loss_ce: 0.005735
 91%|██████████████████████████▎  | 363/400 [1:51:43<11:04, 17.97s/it]2022-01-15 21:02:36,385 iteration 6172 : loss : 0.011256, loss_ce: 0.003888
2022-01-15 21:02:37,462 iteration 6173 : loss : 0.017525, loss_ce: 0.005972
2022-01-15 21:02:38,465 iteration 6174 : loss : 0.012953, loss_ce: 0.004935
2022-01-15 21:02:39,502 iteration 6175 : loss : 0.021864, loss_ce: 0.008929
2022-01-15 21:02:40,502 iteration 6176 : loss : 0.014238, loss_ce: 0.005557
2022-01-15 21:02:41,581 iteration 6177 : loss : 0.019403, loss_ce: 0.008088
2022-01-15 21:02:42,572 iteration 6178 : loss : 0.017442, loss_ce: 0.007390
2022-01-15 21:02:43,562 iteration 6179 : loss : 0.012436, loss_ce: 0.005596
2022-01-15 21:02:44,558 iteration 6180 : loss : 0.014320, loss_ce: 0.004943
2022-01-15 21:02:45,443 iteration 6181 : loss : 0.011440, loss_ce: 0.003690
2022-01-15 21:02:46,451 iteration 6182 : loss : 0.017393, loss_ce: 0.004759
2022-01-15 21:02:47,522 iteration 6183 : loss : 0.016356, loss_ce: 0.006675
2022-01-15 21:02:48,537 iteration 6184 : loss : 0.031174, loss_ce: 0.008666
2022-01-15 21:02:49,510 iteration 6185 : loss : 0.016198, loss_ce: 0.005503
2022-01-15 21:02:50,510 iteration 6186 : loss : 0.015455, loss_ce: 0.004964
2022-01-15 21:02:51,554 iteration 6187 : loss : 0.013775, loss_ce: 0.004621
2022-01-15 21:02:52,436 iteration 6188 : loss : 0.013476, loss_ce: 0.004466
 91%|██████████████████████████▍  | 364/400 [1:52:00<10:37, 17.70s/it]2022-01-15 21:02:53,412 iteration 6189 : loss : 0.012163, loss_ce: 0.003636
2022-01-15 21:02:54,296 iteration 6190 : loss : 0.014504, loss_ce: 0.005068
2022-01-15 21:02:55,434 iteration 6191 : loss : 0.020380, loss_ce: 0.007635
2022-01-15 21:02:56,467 iteration 6192 : loss : 0.013807, loss_ce: 0.004749
2022-01-15 21:02:57,320 iteration 6193 : loss : 0.009965, loss_ce: 0.003743
2022-01-15 21:02:58,298 iteration 6194 : loss : 0.015861, loss_ce: 0.006531
2022-01-15 21:02:59,329 iteration 6195 : loss : 0.017766, loss_ce: 0.008444
2022-01-15 21:03:00,361 iteration 6196 : loss : 0.015518, loss_ce: 0.007882
2022-01-15 21:03:01,364 iteration 6197 : loss : 0.014476, loss_ce: 0.006979
2022-01-15 21:03:02,344 iteration 6198 : loss : 0.018350, loss_ce: 0.006324
2022-01-15 21:03:03,324 iteration 6199 : loss : 0.017317, loss_ce: 0.005848
2022-01-15 21:03:04,221 iteration 6200 : loss : 0.011230, loss_ce: 0.005175
2022-01-15 21:03:05,244 iteration 6201 : loss : 0.023293, loss_ce: 0.009890
2022-01-15 21:03:06,186 iteration 6202 : loss : 0.015960, loss_ce: 0.006466
2022-01-15 21:03:07,141 iteration 6203 : loss : 0.015060, loss_ce: 0.003678
2022-01-15 21:03:08,159 iteration 6204 : loss : 0.013884, loss_ce: 0.005497
2022-01-15 21:03:08,160 Training Data Eval:
2022-01-15 21:03:12,933   Average segmentation loss on training set: 0.0090
2022-01-15 21:03:12,933 Validation Data Eval:
2022-01-15 21:03:14,557   Average segmentation loss on validation set: 0.0849
2022-01-15 21:03:15,583 iteration 6205 : loss : 0.016292, loss_ce: 0.005036
 91%|██████████████████████████▍  | 365/400 [1:52:23<11:16, 19.34s/it]2022-01-15 21:03:16,684 iteration 6206 : loss : 0.015206, loss_ce: 0.007411
2022-01-15 21:03:17,651 iteration 6207 : loss : 0.013008, loss_ce: 0.003595
2022-01-15 21:03:18,731 iteration 6208 : loss : 0.020916, loss_ce: 0.006785
2022-01-15 21:03:19,696 iteration 6209 : loss : 0.014048, loss_ce: 0.004252
2022-01-15 21:03:20,641 iteration 6210 : loss : 0.019889, loss_ce: 0.008994
2022-01-15 21:03:21,677 iteration 6211 : loss : 0.017133, loss_ce: 0.007161
2022-01-15 21:03:22,632 iteration 6212 : loss : 0.012901, loss_ce: 0.004402
2022-01-15 21:03:23,594 iteration 6213 : loss : 0.021573, loss_ce: 0.004839
2022-01-15 21:03:24,562 iteration 6214 : loss : 0.027865, loss_ce: 0.007085
2022-01-15 21:03:25,594 iteration 6215 : loss : 0.018783, loss_ce: 0.008956
2022-01-15 21:03:26,603 iteration 6216 : loss : 0.016620, loss_ce: 0.006040
2022-01-15 21:03:27,515 iteration 6217 : loss : 0.018016, loss_ce: 0.005667
2022-01-15 21:03:28,521 iteration 6218 : loss : 0.011865, loss_ce: 0.005047
2022-01-15 21:03:29,488 iteration 6219 : loss : 0.013626, loss_ce: 0.004844
2022-01-15 21:03:30,481 iteration 6220 : loss : 0.015302, loss_ce: 0.004198
2022-01-15 21:03:31,579 iteration 6221 : loss : 0.017048, loss_ce: 0.008191
2022-01-15 21:03:32,590 iteration 6222 : loss : 0.015484, loss_ce: 0.007519
 92%|██████████████████████████▌  | 366/400 [1:52:40<10:33, 18.64s/it]2022-01-15 21:03:33,672 iteration 6223 : loss : 0.021648, loss_ce: 0.004784
2022-01-15 21:03:34,632 iteration 6224 : loss : 0.015955, loss_ce: 0.004533
2022-01-15 21:03:35,612 iteration 6225 : loss : 0.018332, loss_ce: 0.007826
2022-01-15 21:03:36,688 iteration 6226 : loss : 0.018225, loss_ce: 0.006922
2022-01-15 21:03:37,681 iteration 6227 : loss : 0.013867, loss_ce: 0.003235
2022-01-15 21:03:38,690 iteration 6228 : loss : 0.017160, loss_ce: 0.007160
2022-01-15 21:03:39,612 iteration 6229 : loss : 0.013270, loss_ce: 0.005428
2022-01-15 21:03:40,568 iteration 6230 : loss : 0.023124, loss_ce: 0.010463
2022-01-15 21:03:41,583 iteration 6231 : loss : 0.013215, loss_ce: 0.005660
2022-01-15 21:03:42,593 iteration 6232 : loss : 0.016712, loss_ce: 0.006638
2022-01-15 21:03:43,566 iteration 6233 : loss : 0.014417, loss_ce: 0.006338
2022-01-15 21:03:44,583 iteration 6234 : loss : 0.013920, loss_ce: 0.005129
2022-01-15 21:03:45,662 iteration 6235 : loss : 0.023171, loss_ce: 0.005966
2022-01-15 21:03:46,559 iteration 6236 : loss : 0.011575, loss_ce: 0.004673
2022-01-15 21:03:47,535 iteration 6237 : loss : 0.014613, loss_ce: 0.005709
2022-01-15 21:03:48,460 iteration 6238 : loss : 0.019606, loss_ce: 0.006154
2022-01-15 21:03:49,417 iteration 6239 : loss : 0.011549, loss_ce: 0.004869
 92%|██████████████████████████▌  | 367/400 [1:52:57<09:57, 18.09s/it]2022-01-15 21:03:50,526 iteration 6240 : loss : 0.016203, loss_ce: 0.006592
2022-01-15 21:03:51,563 iteration 6241 : loss : 0.041452, loss_ce: 0.023857
2022-01-15 21:03:52,595 iteration 6242 : loss : 0.017366, loss_ce: 0.007440
2022-01-15 21:03:53,501 iteration 6243 : loss : 0.013000, loss_ce: 0.004748
2022-01-15 21:03:54,453 iteration 6244 : loss : 0.013004, loss_ce: 0.003942
2022-01-15 21:03:55,432 iteration 6245 : loss : 0.014785, loss_ce: 0.005411
2022-01-15 21:03:56,393 iteration 6246 : loss : 0.019023, loss_ce: 0.007324
2022-01-15 21:03:57,343 iteration 6247 : loss : 0.016260, loss_ce: 0.004388
2022-01-15 21:03:58,391 iteration 6248 : loss : 0.015936, loss_ce: 0.006773
2022-01-15 21:03:59,363 iteration 6249 : loss : 0.016169, loss_ce: 0.005787
2022-01-15 21:04:00,384 iteration 6250 : loss : 0.020934, loss_ce: 0.008717
2022-01-15 21:04:01,466 iteration 6251 : loss : 0.015339, loss_ce: 0.005495
2022-01-15 21:04:02,491 iteration 6252 : loss : 0.022469, loss_ce: 0.005004
2022-01-15 21:04:03,439 iteration 6253 : loss : 0.012956, loss_ce: 0.004273
2022-01-15 21:04:04,344 iteration 6254 : loss : 0.011542, loss_ce: 0.004788
2022-01-15 21:04:05,394 iteration 6255 : loss : 0.013205, loss_ce: 0.004666
2022-01-15 21:04:06,385 iteration 6256 : loss : 0.013982, loss_ce: 0.004880
 92%|██████████████████████████▋  | 368/400 [1:53:14<09:28, 17.75s/it]2022-01-15 21:04:07,468 iteration 6257 : loss : 0.012132, loss_ce: 0.003819
2022-01-15 21:04:08,394 iteration 6258 : loss : 0.011654, loss_ce: 0.003979
2022-01-15 21:04:09,438 iteration 6259 : loss : 0.013980, loss_ce: 0.005464
2022-01-15 21:04:10,565 iteration 6260 : loss : 0.023312, loss_ce: 0.005314
2022-01-15 21:04:11,562 iteration 6261 : loss : 0.016622, loss_ce: 0.008017
2022-01-15 21:04:12,605 iteration 6262 : loss : 0.016059, loss_ce: 0.005955
2022-01-15 21:04:13,556 iteration 6263 : loss : 0.014480, loss_ce: 0.004785
2022-01-15 21:04:14,484 iteration 6264 : loss : 0.014136, loss_ce: 0.005842
2022-01-15 21:04:15,479 iteration 6265 : loss : 0.015171, loss_ce: 0.006791
2022-01-15 21:04:16,436 iteration 6266 : loss : 0.011058, loss_ce: 0.003894
2022-01-15 21:04:17,607 iteration 6267 : loss : 0.025199, loss_ce: 0.012100
2022-01-15 21:04:18,580 iteration 6268 : loss : 0.014051, loss_ce: 0.004674
2022-01-15 21:04:19,567 iteration 6269 : loss : 0.015914, loss_ce: 0.005821
2022-01-15 21:04:20,532 iteration 6270 : loss : 0.015533, loss_ce: 0.007134
2022-01-15 21:04:21,617 iteration 6271 : loss : 0.016201, loss_ce: 0.007850
2022-01-15 21:04:22,568 iteration 6272 : loss : 0.020426, loss_ce: 0.005959
2022-01-15 21:04:23,665 iteration 6273 : loss : 0.019911, loss_ce: 0.006958
 92%|██████████████████████████▊  | 369/400 [1:53:31<09:05, 17.61s/it]2022-01-15 21:04:24,828 iteration 6274 : loss : 0.018584, loss_ce: 0.006480
2022-01-15 21:04:25,778 iteration 6275 : loss : 0.017863, loss_ce: 0.005202
2022-01-15 21:04:26,691 iteration 6276 : loss : 0.013462, loss_ce: 0.005644
2022-01-15 21:04:27,687 iteration 6277 : loss : 0.014529, loss_ce: 0.005116
2022-01-15 21:04:28,757 iteration 6278 : loss : 0.018476, loss_ce: 0.007104
2022-01-15 21:04:29,808 iteration 6279 : loss : 0.021135, loss_ce: 0.007566
2022-01-15 21:04:30,731 iteration 6280 : loss : 0.020292, loss_ce: 0.008168
2022-01-15 21:04:31,697 iteration 6281 : loss : 0.022071, loss_ce: 0.006192
2022-01-15 21:04:32,678 iteration 6282 : loss : 0.022105, loss_ce: 0.010948
2022-01-15 21:04:33,748 iteration 6283 : loss : 0.016922, loss_ce: 0.006368
2022-01-15 21:04:34,751 iteration 6284 : loss : 0.015736, loss_ce: 0.004925
2022-01-15 21:04:35,753 iteration 6285 : loss : 0.016937, loss_ce: 0.007558
2022-01-15 21:04:36,800 iteration 6286 : loss : 0.026949, loss_ce: 0.015207
2022-01-15 21:04:37,782 iteration 6287 : loss : 0.013353, loss_ce: 0.004799
2022-01-15 21:04:38,684 iteration 6288 : loss : 0.016215, loss_ce: 0.005198
2022-01-15 21:04:39,660 iteration 6289 : loss : 0.013051, loss_ce: 0.005186
2022-01-15 21:04:39,661 Training Data Eval:
2022-01-15 21:04:44,455   Average segmentation loss on training set: 0.0085
2022-01-15 21:04:44,455 Validation Data Eval:
2022-01-15 21:04:46,086   Average segmentation loss on validation set: 0.0761
2022-01-15 21:04:47,096 iteration 6290 : loss : 0.019762, loss_ce: 0.006776
 92%|██████████████████████████▊  | 370/400 [1:53:55<09:40, 19.36s/it]2022-01-15 21:04:48,133 iteration 6291 : loss : 0.014159, loss_ce: 0.004009
2022-01-15 21:04:49,032 iteration 6292 : loss : 0.014582, loss_ce: 0.004484
2022-01-15 21:04:49,987 iteration 6293 : loss : 0.013069, loss_ce: 0.003397
2022-01-15 21:04:51,085 iteration 6294 : loss : 0.021639, loss_ce: 0.007208
2022-01-15 21:04:52,077 iteration 6295 : loss : 0.014005, loss_ce: 0.005535
2022-01-15 21:04:52,995 iteration 6296 : loss : 0.012293, loss_ce: 0.004902
2022-01-15 21:04:54,062 iteration 6297 : loss : 0.020781, loss_ce: 0.010196
2022-01-15 21:04:55,058 iteration 6298 : loss : 0.015774, loss_ce: 0.007847
2022-01-15 21:04:56,048 iteration 6299 : loss : 0.015662, loss_ce: 0.005792
2022-01-15 21:04:57,096 iteration 6300 : loss : 0.015865, loss_ce: 0.003932
2022-01-15 21:04:58,112 iteration 6301 : loss : 0.014586, loss_ce: 0.007137
2022-01-15 21:04:59,185 iteration 6302 : loss : 0.022465, loss_ce: 0.007657
2022-01-15 21:05:00,148 iteration 6303 : loss : 0.012941, loss_ce: 0.005417
2022-01-15 21:05:01,170 iteration 6304 : loss : 0.022468, loss_ce: 0.011213
2022-01-15 21:05:02,140 iteration 6305 : loss : 0.013950, loss_ce: 0.004665
2022-01-15 21:05:03,150 iteration 6306 : loss : 0.018515, loss_ce: 0.010681
2022-01-15 21:05:04,132 iteration 6307 : loss : 0.015673, loss_ce: 0.005415
 93%|██████████████████████████▉  | 371/400 [1:54:12<09:01, 18.66s/it]2022-01-15 21:05:05,245 iteration 6308 : loss : 0.017133, loss_ce: 0.006243
2022-01-15 21:05:06,230 iteration 6309 : loss : 0.020040, loss_ce: 0.004661
2022-01-15 21:05:07,240 iteration 6310 : loss : 0.012533, loss_ce: 0.004836
2022-01-15 21:05:08,316 iteration 6311 : loss : 0.018641, loss_ce: 0.006134
2022-01-15 21:05:09,297 iteration 6312 : loss : 0.011580, loss_ce: 0.005150
2022-01-15 21:05:10,318 iteration 6313 : loss : 0.018067, loss_ce: 0.005033
2022-01-15 21:05:11,361 iteration 6314 : loss : 0.013570, loss_ce: 0.005133
2022-01-15 21:05:12,339 iteration 6315 : loss : 0.017608, loss_ce: 0.007866
2022-01-15 21:05:13,266 iteration 6316 : loss : 0.014077, loss_ce: 0.004000
2022-01-15 21:05:14,183 iteration 6317 : loss : 0.013462, loss_ce: 0.004694
2022-01-15 21:05:15,236 iteration 6318 : loss : 0.026537, loss_ce: 0.008661
2022-01-15 21:05:16,207 iteration 6319 : loss : 0.018851, loss_ce: 0.007024
2022-01-15 21:05:17,206 iteration 6320 : loss : 0.011473, loss_ce: 0.004878
2022-01-15 21:05:18,191 iteration 6321 : loss : 0.013261, loss_ce: 0.004789
2022-01-15 21:05:19,273 iteration 6322 : loss : 0.019188, loss_ce: 0.006713
2022-01-15 21:05:20,378 iteration 6323 : loss : 0.029714, loss_ce: 0.007152
2022-01-15 21:05:21,353 iteration 6324 : loss : 0.018481, loss_ce: 0.007750
 93%|██████████████████████████▉  | 372/400 [1:54:29<08:30, 18.23s/it]2022-01-15 21:05:22,358 iteration 6325 : loss : 0.013508, loss_ce: 0.006144
2022-01-15 21:05:23,286 iteration 6326 : loss : 0.010275, loss_ce: 0.004210
2022-01-15 21:05:24,341 iteration 6327 : loss : 0.017553, loss_ce: 0.007131
2022-01-15 21:05:25,326 iteration 6328 : loss : 0.011623, loss_ce: 0.003819
2022-01-15 21:05:26,260 iteration 6329 : loss : 0.013628, loss_ce: 0.003581
2022-01-15 21:05:27,251 iteration 6330 : loss : 0.012092, loss_ce: 0.003939
2022-01-15 21:05:28,449 iteration 6331 : loss : 0.019606, loss_ce: 0.006641
2022-01-15 21:05:29,396 iteration 6332 : loss : 0.014821, loss_ce: 0.006080
2022-01-15 21:05:30,423 iteration 6333 : loss : 0.011407, loss_ce: 0.002974
2022-01-15 21:05:31,441 iteration 6334 : loss : 0.014213, loss_ce: 0.006838
2022-01-15 21:05:32,540 iteration 6335 : loss : 0.021484, loss_ce: 0.009750
2022-01-15 21:05:33,460 iteration 6336 : loss : 0.008862, loss_ce: 0.003276
2022-01-15 21:05:34,481 iteration 6337 : loss : 0.032212, loss_ce: 0.012748
2022-01-15 21:05:35,591 iteration 6338 : loss : 0.027013, loss_ce: 0.004547
2022-01-15 21:05:36,556 iteration 6339 : loss : 0.018318, loss_ce: 0.007882
2022-01-15 21:05:37,518 iteration 6340 : loss : 0.012173, loss_ce: 0.006208
2022-01-15 21:05:38,539 iteration 6341 : loss : 0.016569, loss_ce: 0.006106
 93%|███████████████████████████  | 373/400 [1:54:46<08:03, 17.92s/it]2022-01-15 21:05:39,614 iteration 6342 : loss : 0.019255, loss_ce: 0.007038
2022-01-15 21:05:40,599 iteration 6343 : loss : 0.015063, loss_ce: 0.004550
2022-01-15 21:05:41,695 iteration 6344 : loss : 0.018292, loss_ce: 0.007735
2022-01-15 21:05:42,705 iteration 6345 : loss : 0.013069, loss_ce: 0.003673
2022-01-15 21:05:43,680 iteration 6346 : loss : 0.013972, loss_ce: 0.005414
2022-01-15 21:05:44,741 iteration 6347 : loss : 0.025142, loss_ce: 0.012800
2022-01-15 21:05:45,721 iteration 6348 : loss : 0.015113, loss_ce: 0.006206
2022-01-15 21:05:46,740 iteration 6349 : loss : 0.015557, loss_ce: 0.005140
2022-01-15 21:05:47,776 iteration 6350 : loss : 0.011847, loss_ce: 0.004284
2022-01-15 21:05:48,865 iteration 6351 : loss : 0.012757, loss_ce: 0.005693
2022-01-15 21:05:49,953 iteration 6352 : loss : 0.017184, loss_ce: 0.006038
2022-01-15 21:05:51,103 iteration 6353 : loss : 0.031908, loss_ce: 0.010019
2022-01-15 21:05:52,087 iteration 6354 : loss : 0.014770, loss_ce: 0.003794
2022-01-15 21:05:53,191 iteration 6355 : loss : 0.016118, loss_ce: 0.005426
2022-01-15 21:05:54,315 iteration 6356 : loss : 0.021959, loss_ce: 0.007488
2022-01-15 21:05:55,375 iteration 6357 : loss : 0.016081, loss_ce: 0.007579
2022-01-15 21:05:56,486 iteration 6358 : loss : 0.020437, loss_ce: 0.006216
 94%|███████████████████████████  | 374/400 [1:55:04<07:46, 17.93s/it]2022-01-15 21:05:57,585 iteration 6359 : loss : 0.014093, loss_ce: 0.004626
2022-01-15 21:05:58,513 iteration 6360 : loss : 0.009280, loss_ce: 0.003248
2022-01-15 21:05:59,637 iteration 6361 : loss : 0.018128, loss_ce: 0.008121
2022-01-15 21:06:00,692 iteration 6362 : loss : 0.014318, loss_ce: 0.005848
2022-01-15 21:06:01,836 iteration 6363 : loss : 0.026687, loss_ce: 0.007896
2022-01-15 21:06:02,913 iteration 6364 : loss : 0.011630, loss_ce: 0.003218
2022-01-15 21:06:03,942 iteration 6365 : loss : 0.019339, loss_ce: 0.007729
2022-01-15 21:06:04,962 iteration 6366 : loss : 0.020813, loss_ce: 0.007599
2022-01-15 21:06:06,050 iteration 6367 : loss : 0.025598, loss_ce: 0.009968
2022-01-15 21:06:07,101 iteration 6368 : loss : 0.021810, loss_ce: 0.005344
2022-01-15 21:06:08,110 iteration 6369 : loss : 0.017040, loss_ce: 0.004054
2022-01-15 21:06:09,161 iteration 6370 : loss : 0.015188, loss_ce: 0.007126
2022-01-15 21:06:10,119 iteration 6371 : loss : 0.011858, loss_ce: 0.004753
2022-01-15 21:06:11,152 iteration 6372 : loss : 0.015323, loss_ce: 0.005708
2022-01-15 21:06:12,115 iteration 6373 : loss : 0.011362, loss_ce: 0.004923
2022-01-15 21:06:13,042 iteration 6374 : loss : 0.010389, loss_ce: 0.003979
2022-01-15 21:06:13,043 Training Data Eval:
2022-01-15 21:06:17,944   Average segmentation loss on training set: 0.0085
2022-01-15 21:06:17,944 Validation Data Eval:
2022-01-15 21:06:19,592   Average segmentation loss on validation set: 0.0872
2022-01-15 21:06:20,650 iteration 6375 : loss : 0.012625, loss_ce: 0.006499
 94%|███████████████████████████▏ | 375/400 [1:55:28<08:14, 19.80s/it]2022-01-15 21:06:21,801 iteration 6376 : loss : 0.016795, loss_ce: 0.005896
2022-01-15 21:06:22,818 iteration 6377 : loss : 0.015896, loss_ce: 0.003601
2022-01-15 21:06:23,787 iteration 6378 : loss : 0.015507, loss_ce: 0.007670
2022-01-15 21:06:24,794 iteration 6379 : loss : 0.014209, loss_ce: 0.006157
2022-01-15 21:06:25,860 iteration 6380 : loss : 0.018619, loss_ce: 0.005406
2022-01-15 21:06:26,936 iteration 6381 : loss : 0.027596, loss_ce: 0.011271
2022-01-15 21:06:27,947 iteration 6382 : loss : 0.016462, loss_ce: 0.008472
2022-01-15 21:06:28,998 iteration 6383 : loss : 0.018658, loss_ce: 0.006858
2022-01-15 21:06:30,067 iteration 6384 : loss : 0.020298, loss_ce: 0.008213
2022-01-15 21:06:30,930 iteration 6385 : loss : 0.009710, loss_ce: 0.003806
2022-01-15 21:06:31,989 iteration 6386 : loss : 0.014545, loss_ce: 0.004584
2022-01-15 21:06:33,044 iteration 6387 : loss : 0.016404, loss_ce: 0.008031
2022-01-15 21:06:33,977 iteration 6388 : loss : 0.012943, loss_ce: 0.006124
2022-01-15 21:06:35,034 iteration 6389 : loss : 0.013637, loss_ce: 0.005380
2022-01-15 21:06:36,058 iteration 6390 : loss : 0.021499, loss_ce: 0.005660
2022-01-15 21:06:37,103 iteration 6391 : loss : 0.019031, loss_ce: 0.008724
2022-01-15 21:06:38,166 iteration 6392 : loss : 0.016168, loss_ce: 0.003759
 94%|███████████████████████████▎ | 376/400 [1:55:46<07:38, 19.11s/it]2022-01-15 21:06:39,176 iteration 6393 : loss : 0.012242, loss_ce: 0.005885
2022-01-15 21:06:40,148 iteration 6394 : loss : 0.013037, loss_ce: 0.005794
2022-01-15 21:06:41,094 iteration 6395 : loss : 0.011017, loss_ce: 0.003530
2022-01-15 21:06:42,120 iteration 6396 : loss : 0.016134, loss_ce: 0.005681
2022-01-15 21:06:43,168 iteration 6397 : loss : 0.017322, loss_ce: 0.005052
2022-01-15 21:06:44,225 iteration 6398 : loss : 0.018705, loss_ce: 0.008675
2022-01-15 21:06:45,134 iteration 6399 : loss : 0.017196, loss_ce: 0.004928
2022-01-15 21:06:46,096 iteration 6400 : loss : 0.011224, loss_ce: 0.004113
2022-01-15 21:06:47,008 iteration 6401 : loss : 0.009929, loss_ce: 0.003588
2022-01-15 21:06:48,048 iteration 6402 : loss : 0.014460, loss_ce: 0.006384
2022-01-15 21:06:49,010 iteration 6403 : loss : 0.013941, loss_ce: 0.006349
2022-01-15 21:06:49,945 iteration 6404 : loss : 0.011534, loss_ce: 0.005788
2022-01-15 21:06:51,097 iteration 6405 : loss : 0.020948, loss_ce: 0.008307
2022-01-15 21:06:52,023 iteration 6406 : loss : 0.010567, loss_ce: 0.004045
2022-01-15 21:06:53,042 iteration 6407 : loss : 0.016756, loss_ce: 0.006277
2022-01-15 21:06:54,072 iteration 6408 : loss : 0.015635, loss_ce: 0.005339
2022-01-15 21:06:54,997 iteration 6409 : loss : 0.010347, loss_ce: 0.003415
 94%|███████████████████████████▎ | 377/400 [1:56:02<07:03, 18.43s/it]2022-01-15 21:06:55,982 iteration 6410 : loss : 0.012010, loss_ce: 0.004224
2022-01-15 21:06:56,945 iteration 6411 : loss : 0.018313, loss_ce: 0.005902
2022-01-15 21:06:58,003 iteration 6412 : loss : 0.015000, loss_ce: 0.004201
2022-01-15 21:06:58,997 iteration 6413 : loss : 0.015499, loss_ce: 0.006581
2022-01-15 21:07:00,026 iteration 6414 : loss : 0.018660, loss_ce: 0.007115
2022-01-15 21:07:01,054 iteration 6415 : loss : 0.013814, loss_ce: 0.004625
2022-01-15 21:07:01,988 iteration 6416 : loss : 0.018117, loss_ce: 0.006476
2022-01-15 21:07:03,028 iteration 6417 : loss : 0.021314, loss_ce: 0.006659
2022-01-15 21:07:04,026 iteration 6418 : loss : 0.017649, loss_ce: 0.007228
2022-01-15 21:07:05,016 iteration 6419 : loss : 0.019135, loss_ce: 0.008297
2022-01-15 21:07:06,027 iteration 6420 : loss : 0.017903, loss_ce: 0.007285
2022-01-15 21:07:07,059 iteration 6421 : loss : 0.014948, loss_ce: 0.006022
2022-01-15 21:07:08,023 iteration 6422 : loss : 0.015174, loss_ce: 0.005941
2022-01-15 21:07:09,019 iteration 6423 : loss : 0.019804, loss_ce: 0.007963
2022-01-15 21:07:09,946 iteration 6424 : loss : 0.013053, loss_ce: 0.004081
2022-01-15 21:07:11,076 iteration 6425 : loss : 0.018723, loss_ce: 0.006561
2022-01-15 21:07:11,986 iteration 6426 : loss : 0.015327, loss_ce: 0.004904
 94%|███████████████████████████▍ | 378/400 [1:56:19<06:35, 18.00s/it]2022-01-15 21:07:13,059 iteration 6427 : loss : 0.017700, loss_ce: 0.007101
2022-01-15 21:07:14,097 iteration 6428 : loss : 0.019200, loss_ce: 0.005956
2022-01-15 21:07:15,065 iteration 6429 : loss : 0.011378, loss_ce: 0.004562
2022-01-15 21:07:16,122 iteration 6430 : loss : 0.017032, loss_ce: 0.007820
2022-01-15 21:07:17,099 iteration 6431 : loss : 0.016334, loss_ce: 0.004836
2022-01-15 21:07:18,087 iteration 6432 : loss : 0.015157, loss_ce: 0.005381
2022-01-15 21:07:19,092 iteration 6433 : loss : 0.011412, loss_ce: 0.002966
2022-01-15 21:07:20,111 iteration 6434 : loss : 0.019355, loss_ce: 0.007409
2022-01-15 21:07:21,025 iteration 6435 : loss : 0.010062, loss_ce: 0.003380
2022-01-15 21:07:21,985 iteration 6436 : loss : 0.011085, loss_ce: 0.005585
2022-01-15 21:07:22,934 iteration 6437 : loss : 0.011275, loss_ce: 0.004076
2022-01-15 21:07:23,873 iteration 6438 : loss : 0.010656, loss_ce: 0.004834
2022-01-15 21:07:24,954 iteration 6439 : loss : 0.016731, loss_ce: 0.005006
2022-01-15 21:07:25,977 iteration 6440 : loss : 0.013221, loss_ce: 0.005291
2022-01-15 21:07:27,008 iteration 6441 : loss : 0.012084, loss_ce: 0.004991
2022-01-15 21:07:28,014 iteration 6442 : loss : 0.013815, loss_ce: 0.006814
2022-01-15 21:07:28,996 iteration 6443 : loss : 0.013169, loss_ce: 0.004572
 95%|███████████████████████████▍ | 379/400 [1:56:36<06:11, 17.70s/it]2022-01-15 21:07:30,040 iteration 6444 : loss : 0.014059, loss_ce: 0.006191
2022-01-15 21:07:31,009 iteration 6445 : loss : 0.009458, loss_ce: 0.003498
2022-01-15 21:07:32,027 iteration 6446 : loss : 0.014941, loss_ce: 0.005680
2022-01-15 21:07:33,045 iteration 6447 : loss : 0.011980, loss_ce: 0.004966
2022-01-15 21:07:34,058 iteration 6448 : loss : 0.020355, loss_ce: 0.005534
2022-01-15 21:07:35,099 iteration 6449 : loss : 0.016212, loss_ce: 0.004849
2022-01-15 21:07:36,175 iteration 6450 : loss : 0.026661, loss_ce: 0.007071
2022-01-15 21:07:37,183 iteration 6451 : loss : 0.014692, loss_ce: 0.005094
2022-01-15 21:07:38,223 iteration 6452 : loss : 0.023541, loss_ce: 0.005652
2022-01-15 21:07:39,192 iteration 6453 : loss : 0.015080, loss_ce: 0.006875
2022-01-15 21:07:40,188 iteration 6454 : loss : 0.017077, loss_ce: 0.005493
2022-01-15 21:07:41,134 iteration 6455 : loss : 0.013758, loss_ce: 0.005481
2022-01-15 21:07:42,150 iteration 6456 : loss : 0.016558, loss_ce: 0.007978
2022-01-15 21:07:43,122 iteration 6457 : loss : 0.010843, loss_ce: 0.004700
2022-01-15 21:07:44,063 iteration 6458 : loss : 0.013570, loss_ce: 0.007593
2022-01-15 21:07:45,119 iteration 6459 : loss : 0.021111, loss_ce: 0.007987
2022-01-15 21:07:45,119 Training Data Eval:
2022-01-15 21:07:49,891   Average segmentation loss on training set: 0.0083
2022-01-15 21:07:49,891 Validation Data Eval:
2022-01-15 21:07:51,526   Average segmentation loss on validation set: 0.0771
2022-01-15 21:07:52,623 iteration 6460 : loss : 0.015301, loss_ce: 0.005297
 95%|███████████████████████████▌ | 380/400 [1:57:00<06:29, 19.48s/it]2022-01-15 21:07:53,653 iteration 6461 : loss : 0.014749, loss_ce: 0.005237
2022-01-15 21:07:54,644 iteration 6462 : loss : 0.013143, loss_ce: 0.005203
2022-01-15 21:07:55,571 iteration 6463 : loss : 0.012033, loss_ce: 0.005184
2022-01-15 21:07:56,536 iteration 6464 : loss : 0.015915, loss_ce: 0.005730
2022-01-15 21:07:57,519 iteration 6465 : loss : 0.010246, loss_ce: 0.003565
2022-01-15 21:07:58,498 iteration 6466 : loss : 0.016785, loss_ce: 0.006413
2022-01-15 21:07:59,483 iteration 6467 : loss : 0.016119, loss_ce: 0.006693
2022-01-15 21:08:00,408 iteration 6468 : loss : 0.012402, loss_ce: 0.003979
2022-01-15 21:08:01,446 iteration 6469 : loss : 0.020425, loss_ce: 0.005225
2022-01-15 21:08:02,461 iteration 6470 : loss : 0.013335, loss_ce: 0.006105
2022-01-15 21:08:03,454 iteration 6471 : loss : 0.018191, loss_ce: 0.007673
2022-01-15 21:08:04,381 iteration 6472 : loss : 0.014878, loss_ce: 0.005489
2022-01-15 21:08:05,417 iteration 6473 : loss : 0.015111, loss_ce: 0.006448
2022-01-15 21:08:06,440 iteration 6474 : loss : 0.014982, loss_ce: 0.005520
2022-01-15 21:08:07,481 iteration 6475 : loss : 0.016185, loss_ce: 0.005280
2022-01-15 21:08:08,495 iteration 6476 : loss : 0.015952, loss_ce: 0.005770
2022-01-15 21:08:09,499 iteration 6477 : loss : 0.016810, loss_ce: 0.006861
 95%|███████████████████████████▌ | 381/400 [1:57:17<05:55, 18.70s/it]2022-01-15 21:08:10,558 iteration 6478 : loss : 0.013477, loss_ce: 0.005492
2022-01-15 21:08:11,559 iteration 6479 : loss : 0.015437, loss_ce: 0.005426
2022-01-15 21:08:12,528 iteration 6480 : loss : 0.013804, loss_ce: 0.005836
2022-01-15 21:08:13,680 iteration 6481 : loss : 0.019787, loss_ce: 0.006583
2022-01-15 21:08:14,649 iteration 6482 : loss : 0.015042, loss_ce: 0.006373
2022-01-15 21:08:15,705 iteration 6483 : loss : 0.017394, loss_ce: 0.006383
2022-01-15 21:08:16,605 iteration 6484 : loss : 0.014876, loss_ce: 0.005166
2022-01-15 21:08:17,616 iteration 6485 : loss : 0.011005, loss_ce: 0.003089
2022-01-15 21:08:18,636 iteration 6486 : loss : 0.014848, loss_ce: 0.005122
2022-01-15 21:08:19,664 iteration 6487 : loss : 0.016742, loss_ce: 0.007500
2022-01-15 21:08:20,704 iteration 6488 : loss : 0.013543, loss_ce: 0.004332
2022-01-15 21:08:21,707 iteration 6489 : loss : 0.020586, loss_ce: 0.006056
2022-01-15 21:08:22,688 iteration 6490 : loss : 0.013456, loss_ce: 0.004838
2022-01-15 21:08:23,632 iteration 6491 : loss : 0.015260, loss_ce: 0.007105
2022-01-15 21:08:24,579 iteration 6492 : loss : 0.010438, loss_ce: 0.005508
2022-01-15 21:08:25,553 iteration 6493 : loss : 0.014216, loss_ce: 0.005413
2022-01-15 21:08:26,574 iteration 6494 : loss : 0.016631, loss_ce: 0.007074
 96%|███████████████████████████▋ | 382/400 [1:57:34<05:27, 18.21s/it]2022-01-15 21:08:27,559 iteration 6495 : loss : 0.012031, loss_ce: 0.005289
2022-01-15 21:08:28,533 iteration 6496 : loss : 0.013587, loss_ce: 0.004530
2022-01-15 21:08:29,557 iteration 6497 : loss : 0.011350, loss_ce: 0.005858
2022-01-15 21:08:30,508 iteration 6498 : loss : 0.017156, loss_ce: 0.004595
2022-01-15 21:08:31,495 iteration 6499 : loss : 0.021597, loss_ce: 0.004990
2022-01-15 21:08:32,607 iteration 6500 : loss : 0.032245, loss_ce: 0.008336
2022-01-15 21:08:33,677 iteration 6501 : loss : 0.013267, loss_ce: 0.006442
2022-01-15 21:08:34,696 iteration 6502 : loss : 0.013206, loss_ce: 0.004179
2022-01-15 21:08:35,718 iteration 6503 : loss : 0.023147, loss_ce: 0.008008
2022-01-15 21:08:36,752 iteration 6504 : loss : 0.018138, loss_ce: 0.007278
2022-01-15 21:08:37,692 iteration 6505 : loss : 0.010983, loss_ce: 0.004099
2022-01-15 21:08:38,721 iteration 6506 : loss : 0.019006, loss_ce: 0.005339
2022-01-15 21:08:39,683 iteration 6507 : loss : 0.014124, loss_ce: 0.005899
2022-01-15 21:08:40,583 iteration 6508 : loss : 0.013202, loss_ce: 0.004905
2022-01-15 21:08:41,576 iteration 6509 : loss : 0.013283, loss_ce: 0.004534
2022-01-15 21:08:42,465 iteration 6510 : loss : 0.009478, loss_ce: 0.003525
2022-01-15 21:08:43,494 iteration 6511 : loss : 0.013024, loss_ce: 0.005304
 96%|███████████████████████████▊ | 383/400 [1:57:51<05:02, 17.82s/it]2022-01-15 21:08:44,587 iteration 6512 : loss : 0.016137, loss_ce: 0.005177
2022-01-15 21:08:45,643 iteration 6513 : loss : 0.014465, loss_ce: 0.005094
2022-01-15 21:08:46,639 iteration 6514 : loss : 0.019861, loss_ce: 0.007261
2022-01-15 21:08:47,688 iteration 6515 : loss : 0.022359, loss_ce: 0.007514
2022-01-15 21:08:48,634 iteration 6516 : loss : 0.011575, loss_ce: 0.004525
2022-01-15 21:08:49,563 iteration 6517 : loss : 0.012669, loss_ce: 0.004581
2022-01-15 21:08:50,572 iteration 6518 : loss : 0.016314, loss_ce: 0.005961
2022-01-15 21:08:51,639 iteration 6519 : loss : 0.016445, loss_ce: 0.007342
2022-01-15 21:08:52,561 iteration 6520 : loss : 0.014891, loss_ce: 0.006410
2022-01-15 21:08:53,592 iteration 6521 : loss : 0.014532, loss_ce: 0.006189
2022-01-15 21:08:54,597 iteration 6522 : loss : 0.013141, loss_ce: 0.004459
2022-01-15 21:08:55,628 iteration 6523 : loss : 0.017700, loss_ce: 0.007895
2022-01-15 21:08:56,651 iteration 6524 : loss : 0.012593, loss_ce: 0.004740
2022-01-15 21:08:57,702 iteration 6525 : loss : 0.021934, loss_ce: 0.006447
2022-01-15 21:08:58,700 iteration 6526 : loss : 0.014259, loss_ce: 0.005476
2022-01-15 21:08:59,656 iteration 6527 : loss : 0.016182, loss_ce: 0.005627
2022-01-15 21:09:00,625 iteration 6528 : loss : 0.011476, loss_ce: 0.004648
 96%|███████████████████████████▊ | 384/400 [1:58:08<04:41, 17.62s/it]2022-01-15 21:09:01,884 iteration 6529 : loss : 0.018585, loss_ce: 0.008778
2022-01-15 21:09:02,869 iteration 6530 : loss : 0.016970, loss_ce: 0.007299
2022-01-15 21:09:03,960 iteration 6531 : loss : 0.019128, loss_ce: 0.006686
2022-01-15 21:09:04,966 iteration 6532 : loss : 0.023217, loss_ce: 0.009101
2022-01-15 21:09:06,027 iteration 6533 : loss : 0.035116, loss_ce: 0.007574
2022-01-15 21:09:07,186 iteration 6534 : loss : 0.017536, loss_ce: 0.004445
2022-01-15 21:09:08,114 iteration 6535 : loss : 0.022279, loss_ce: 0.003820
2022-01-15 21:09:09,116 iteration 6536 : loss : 0.020057, loss_ce: 0.008733
2022-01-15 21:09:10,127 iteration 6537 : loss : 0.017512, loss_ce: 0.007687
2022-01-15 21:09:11,156 iteration 6538 : loss : 0.017767, loss_ce: 0.009694
2022-01-15 21:09:12,271 iteration 6539 : loss : 0.023303, loss_ce: 0.008016
2022-01-15 21:09:13,271 iteration 6540 : loss : 0.013787, loss_ce: 0.005986
2022-01-15 21:09:14,248 iteration 6541 : loss : 0.013091, loss_ce: 0.005286
2022-01-15 21:09:15,313 iteration 6542 : loss : 0.023408, loss_ce: 0.010884
2022-01-15 21:09:16,348 iteration 6543 : loss : 0.019286, loss_ce: 0.008170
2022-01-15 21:09:17,270 iteration 6544 : loss : 0.010502, loss_ce: 0.003433
2022-01-15 21:09:17,270 Training Data Eval:
2022-01-15 21:09:22,171   Average segmentation loss on training set: 0.0082
2022-01-15 21:09:22,171 Validation Data Eval:
2022-01-15 21:09:23,827   Average segmentation loss on validation set: 0.0877
2022-01-15 21:09:24,736 iteration 6545 : loss : 0.009248, loss_ce: 0.002132
 96%|███████████████████████████▉ | 385/400 [1:58:32<04:53, 19.56s/it]2022-01-15 21:09:25,859 iteration 6546 : loss : 0.017227, loss_ce: 0.005170
2022-01-15 21:09:27,070 iteration 6547 : loss : 0.027066, loss_ce: 0.009192
2022-01-15 21:09:27,964 iteration 6548 : loss : 0.013432, loss_ce: 0.008038
2022-01-15 21:09:28,853 iteration 6549 : loss : 0.008069, loss_ce: 0.002699
2022-01-15 21:09:29,825 iteration 6550 : loss : 0.012207, loss_ce: 0.004530
2022-01-15 21:09:30,881 iteration 6551 : loss : 0.014128, loss_ce: 0.006733
2022-01-15 21:09:31,790 iteration 6552 : loss : 0.012276, loss_ce: 0.005714
2022-01-15 21:09:32,879 iteration 6553 : loss : 0.021047, loss_ce: 0.007933
2022-01-15 21:09:33,879 iteration 6554 : loss : 0.022757, loss_ce: 0.007423
2022-01-15 21:09:34,956 iteration 6555 : loss : 0.024206, loss_ce: 0.011223
2022-01-15 21:09:36,001 iteration 6556 : loss : 0.014852, loss_ce: 0.004230
2022-01-15 21:09:36,942 iteration 6557 : loss : 0.016394, loss_ce: 0.005392
2022-01-15 21:09:37,894 iteration 6558 : loss : 0.018675, loss_ce: 0.006108
2022-01-15 21:09:38,931 iteration 6559 : loss : 0.013653, loss_ce: 0.006541
2022-01-15 21:09:40,017 iteration 6560 : loss : 0.033679, loss_ce: 0.007748
2022-01-15 21:09:40,959 iteration 6561 : loss : 0.012240, loss_ce: 0.004826
2022-01-15 21:09:41,854 iteration 6562 : loss : 0.009510, loss_ce: 0.003030
 96%|███████████████████████████▉ | 386/400 [1:58:49<04:23, 18.83s/it]2022-01-15 21:09:42,914 iteration 6563 : loss : 0.013245, loss_ce: 0.005984
2022-01-15 21:09:43,870 iteration 6564 : loss : 0.031932, loss_ce: 0.008152
2022-01-15 21:09:44,789 iteration 6565 : loss : 0.010203, loss_ce: 0.002872
2022-01-15 21:09:45,760 iteration 6566 : loss : 0.010918, loss_ce: 0.004062
2022-01-15 21:09:46,801 iteration 6567 : loss : 0.020232, loss_ce: 0.007612
2022-01-15 21:09:47,818 iteration 6568 : loss : 0.015156, loss_ce: 0.005866
2022-01-15 21:09:48,878 iteration 6569 : loss : 0.020156, loss_ce: 0.007183
2022-01-15 21:09:49,871 iteration 6570 : loss : 0.016292, loss_ce: 0.004260
2022-01-15 21:09:51,007 iteration 6571 : loss : 0.021630, loss_ce: 0.010624
2022-01-15 21:09:51,923 iteration 6572 : loss : 0.011171, loss_ce: 0.004648
2022-01-15 21:09:52,984 iteration 6573 : loss : 0.023170, loss_ce: 0.006965
2022-01-15 21:09:53,954 iteration 6574 : loss : 0.010292, loss_ce: 0.002958
2022-01-15 21:09:55,031 iteration 6575 : loss : 0.022281, loss_ce: 0.007404
2022-01-15 21:09:56,035 iteration 6576 : loss : 0.022080, loss_ce: 0.007521
2022-01-15 21:09:56,998 iteration 6577 : loss : 0.012387, loss_ce: 0.004036
2022-01-15 21:09:58,039 iteration 6578 : loss : 0.013105, loss_ce: 0.005396
2022-01-15 21:09:59,014 iteration 6579 : loss : 0.015232, loss_ce: 0.006614
 97%|████████████████████████████ | 387/400 [1:59:06<03:58, 18.32s/it]2022-01-15 21:10:00,134 iteration 6580 : loss : 0.018134, loss_ce: 0.007087
2022-01-15 21:10:01,070 iteration 6581 : loss : 0.013461, loss_ce: 0.004479
2022-01-15 21:10:02,153 iteration 6582 : loss : 0.023152, loss_ce: 0.008775
2022-01-15 21:10:03,152 iteration 6583 : loss : 0.024913, loss_ce: 0.008343
2022-01-15 21:10:04,098 iteration 6584 : loss : 0.019402, loss_ce: 0.007126
2022-01-15 21:10:05,002 iteration 6585 : loss : 0.011812, loss_ce: 0.003640
2022-01-15 21:10:05,968 iteration 6586 : loss : 0.010333, loss_ce: 0.002099
2022-01-15 21:10:06,890 iteration 6587 : loss : 0.011788, loss_ce: 0.005814
2022-01-15 21:10:07,905 iteration 6588 : loss : 0.010545, loss_ce: 0.004757
2022-01-15 21:10:08,920 iteration 6589 : loss : 0.011416, loss_ce: 0.004724
2022-01-15 21:10:09,891 iteration 6590 : loss : 0.012174, loss_ce: 0.005241
2022-01-15 21:10:10,875 iteration 6591 : loss : 0.011566, loss_ce: 0.003756
2022-01-15 21:10:11,953 iteration 6592 : loss : 0.015119, loss_ce: 0.007669
2022-01-15 21:10:12,850 iteration 6593 : loss : 0.010642, loss_ce: 0.005549
2022-01-15 21:10:13,818 iteration 6594 : loss : 0.010807, loss_ce: 0.003698
2022-01-15 21:10:14,867 iteration 6595 : loss : 0.017842, loss_ce: 0.005201
2022-01-15 21:10:15,809 iteration 6596 : loss : 0.011829, loss_ce: 0.004019
 97%|████████████████████████████▏| 388/400 [1:59:23<03:34, 17.87s/it]2022-01-15 21:10:16,815 iteration 6597 : loss : 0.010486, loss_ce: 0.004520
2022-01-15 21:10:17,853 iteration 6598 : loss : 0.019420, loss_ce: 0.003685
2022-01-15 21:10:18,905 iteration 6599 : loss : 0.016832, loss_ce: 0.006088
2022-01-15 21:10:19,840 iteration 6600 : loss : 0.012614, loss_ce: 0.005354
2022-01-15 21:10:20,946 iteration 6601 : loss : 0.015259, loss_ce: 0.006358
2022-01-15 21:10:21,988 iteration 6602 : loss : 0.016746, loss_ce: 0.005991
2022-01-15 21:10:22,945 iteration 6603 : loss : 0.011903, loss_ce: 0.005403
2022-01-15 21:10:23,983 iteration 6604 : loss : 0.014676, loss_ce: 0.006169
2022-01-15 21:10:24,949 iteration 6605 : loss : 0.014541, loss_ce: 0.006850
2022-01-15 21:10:26,022 iteration 6606 : loss : 0.013833, loss_ce: 0.004761
2022-01-15 21:10:27,079 iteration 6607 : loss : 0.019650, loss_ce: 0.007149
2022-01-15 21:10:27,997 iteration 6608 : loss : 0.015427, loss_ce: 0.006841
2022-01-15 21:10:29,049 iteration 6609 : loss : 0.019598, loss_ce: 0.008482
2022-01-15 21:10:30,020 iteration 6610 : loss : 0.012056, loss_ce: 0.004500
2022-01-15 21:10:30,985 iteration 6611 : loss : 0.010456, loss_ce: 0.002714
2022-01-15 21:10:31,980 iteration 6612 : loss : 0.013834, loss_ce: 0.003833
2022-01-15 21:10:33,032 iteration 6613 : loss : 0.014181, loss_ce: 0.005057
 97%|████████████████████████████▏| 389/400 [1:59:40<03:14, 17.68s/it]2022-01-15 21:10:34,099 iteration 6614 : loss : 0.009253, loss_ce: 0.003204
2022-01-15 21:10:35,019 iteration 6615 : loss : 0.009814, loss_ce: 0.003762
2022-01-15 21:10:36,061 iteration 6616 : loss : 0.019647, loss_ce: 0.005971
2022-01-15 21:10:37,030 iteration 6617 : loss : 0.014493, loss_ce: 0.005215
2022-01-15 21:10:38,116 iteration 6618 : loss : 0.016873, loss_ce: 0.006827
2022-01-15 21:10:39,128 iteration 6619 : loss : 0.013465, loss_ce: 0.004522
2022-01-15 21:10:40,152 iteration 6620 : loss : 0.014674, loss_ce: 0.004753
2022-01-15 21:10:41,230 iteration 6621 : loss : 0.015861, loss_ce: 0.005716
2022-01-15 21:10:42,216 iteration 6622 : loss : 0.015417, loss_ce: 0.006821
2022-01-15 21:10:43,164 iteration 6623 : loss : 0.014615, loss_ce: 0.004685
2022-01-15 21:10:44,163 iteration 6624 : loss : 0.013252, loss_ce: 0.005284
2022-01-15 21:10:45,195 iteration 6625 : loss : 0.022692, loss_ce: 0.007412
2022-01-15 21:10:46,195 iteration 6626 : loss : 0.016109, loss_ce: 0.006265
2022-01-15 21:10:47,245 iteration 6627 : loss : 0.020764, loss_ce: 0.007060
2022-01-15 21:10:48,283 iteration 6628 : loss : 0.017454, loss_ce: 0.008019
2022-01-15 21:10:49,416 iteration 6629 : loss : 0.018698, loss_ce: 0.005066
2022-01-15 21:10:49,416 Training Data Eval:
2022-01-15 21:10:54,284   Average segmentation loss on training set: 0.0081
2022-01-15 21:10:54,284 Validation Data Eval:
2022-01-15 21:10:55,942   Average segmentation loss on validation set: 0.0864
2022-01-15 21:10:56,944 iteration 6630 : loss : 0.014439, loss_ce: 0.005353
 98%|████████████████████████████▎| 390/400 [2:00:04<03:15, 19.54s/it]2022-01-15 21:10:58,021 iteration 6631 : loss : 0.016050, loss_ce: 0.005745
2022-01-15 21:10:59,007 iteration 6632 : loss : 0.012477, loss_ce: 0.005980
2022-01-15 21:11:00,063 iteration 6633 : loss : 0.014746, loss_ce: 0.003974
2022-01-15 21:11:01,050 iteration 6634 : loss : 0.013064, loss_ce: 0.005211
2022-01-15 21:11:02,064 iteration 6635 : loss : 0.013744, loss_ce: 0.005605
2022-01-15 21:11:03,086 iteration 6636 : loss : 0.011606, loss_ce: 0.006381
2022-01-15 21:11:04,045 iteration 6637 : loss : 0.014332, loss_ce: 0.004955
2022-01-15 21:11:05,116 iteration 6638 : loss : 0.017648, loss_ce: 0.004097
2022-01-15 21:11:06,182 iteration 6639 : loss : 0.017680, loss_ce: 0.007078
2022-01-15 21:11:07,171 iteration 6640 : loss : 0.013244, loss_ce: 0.003751
2022-01-15 21:11:08,194 iteration 6641 : loss : 0.014437, loss_ce: 0.005335
2022-01-15 21:11:09,216 iteration 6642 : loss : 0.019407, loss_ce: 0.007706
2022-01-15 21:11:10,241 iteration 6643 : loss : 0.013566, loss_ce: 0.004914
2022-01-15 21:11:11,385 iteration 6644 : loss : 0.019273, loss_ce: 0.007176
2022-01-15 21:11:12,366 iteration 6645 : loss : 0.012637, loss_ce: 0.005774
2022-01-15 21:11:13,503 iteration 6646 : loss : 0.029094, loss_ce: 0.008668
2022-01-15 21:11:14,501 iteration 6647 : loss : 0.020038, loss_ce: 0.007077
 98%|████████████████████████████▎| 391/400 [2:00:22<02:50, 18.95s/it]2022-01-15 21:11:15,541 iteration 6648 : loss : 0.015304, loss_ce: 0.003488
2022-01-15 21:11:16,588 iteration 6649 : loss : 0.015113, loss_ce: 0.004053
2022-01-15 21:11:17,683 iteration 6650 : loss : 0.020565, loss_ce: 0.007982
2022-01-15 21:11:18,808 iteration 6651 : loss : 0.019223, loss_ce: 0.007667
2022-01-15 21:11:19,808 iteration 6652 : loss : 0.012678, loss_ce: 0.005224
2022-01-15 21:11:20,740 iteration 6653 : loss : 0.010058, loss_ce: 0.004011
2022-01-15 21:11:21,746 iteration 6654 : loss : 0.018427, loss_ce: 0.006633
2022-01-15 21:11:22,811 iteration 6655 : loss : 0.014640, loss_ce: 0.005323
2022-01-15 21:11:23,858 iteration 6656 : loss : 0.016775, loss_ce: 0.006728
2022-01-15 21:11:24,889 iteration 6657 : loss : 0.011947, loss_ce: 0.003295
2022-01-15 21:11:25,944 iteration 6658 : loss : 0.015420, loss_ce: 0.005810
2022-01-15 21:11:26,948 iteration 6659 : loss : 0.019416, loss_ce: 0.008688
2022-01-15 21:11:28,011 iteration 6660 : loss : 0.019304, loss_ce: 0.008777
2022-01-15 21:11:29,035 iteration 6661 : loss : 0.015991, loss_ce: 0.006166
2022-01-15 21:11:30,072 iteration 6662 : loss : 0.013969, loss_ce: 0.003612
2022-01-15 21:11:31,081 iteration 6663 : loss : 0.016031, loss_ce: 0.005539
2022-01-15 21:11:32,126 iteration 6664 : loss : 0.020916, loss_ce: 0.011009
 98%|████████████████████████████▍| 392/400 [2:00:40<02:28, 18.56s/it]2022-01-15 21:11:33,247 iteration 6665 : loss : 0.015656, loss_ce: 0.004750
2022-01-15 21:11:34,361 iteration 6666 : loss : 0.025622, loss_ce: 0.007074
2022-01-15 21:11:35,382 iteration 6667 : loss : 0.025846, loss_ce: 0.004038
2022-01-15 21:11:36,287 iteration 6668 : loss : 0.010810, loss_ce: 0.005445
2022-01-15 21:11:37,278 iteration 6669 : loss : 0.014448, loss_ce: 0.005613
2022-01-15 21:11:38,270 iteration 6670 : loss : 0.016352, loss_ce: 0.007871
2022-01-15 21:11:39,303 iteration 6671 : loss : 0.018656, loss_ce: 0.006298
2022-01-15 21:11:40,355 iteration 6672 : loss : 0.014319, loss_ce: 0.004219
2022-01-15 21:11:41,344 iteration 6673 : loss : 0.040075, loss_ce: 0.009891
2022-01-15 21:11:42,336 iteration 6674 : loss : 0.017097, loss_ce: 0.009464
2022-01-15 21:11:43,448 iteration 6675 : loss : 0.022832, loss_ce: 0.010945
2022-01-15 21:11:44,417 iteration 6676 : loss : 0.013149, loss_ce: 0.005113
2022-01-15 21:11:45,366 iteration 6677 : loss : 0.012431, loss_ce: 0.003958
2022-01-15 21:11:46,364 iteration 6678 : loss : 0.013297, loss_ce: 0.006989
2022-01-15 21:11:47,422 iteration 6679 : loss : 0.013712, loss_ce: 0.005594
2022-01-15 21:11:48,364 iteration 6680 : loss : 0.010486, loss_ce: 0.003605
2022-01-15 21:11:49,272 iteration 6681 : loss : 0.009506, loss_ce: 0.003114
 98%|████████████████████████████▍| 393/400 [2:00:57<02:06, 18.13s/it]2022-01-15 21:11:50,420 iteration 6682 : loss : 0.013517, loss_ce: 0.006126
2022-01-15 21:11:51,367 iteration 6683 : loss : 0.013667, loss_ce: 0.005373
2022-01-15 21:11:52,349 iteration 6684 : loss : 0.011563, loss_ce: 0.005036
2022-01-15 21:11:53,281 iteration 6685 : loss : 0.016582, loss_ce: 0.006262
2022-01-15 21:11:54,344 iteration 6686 : loss : 0.014136, loss_ce: 0.005809
2022-01-15 21:11:55,324 iteration 6687 : loss : 0.015180, loss_ce: 0.005106
2022-01-15 21:11:56,317 iteration 6688 : loss : 0.015561, loss_ce: 0.005607
2022-01-15 21:11:57,224 iteration 6689 : loss : 0.011044, loss_ce: 0.003777
2022-01-15 21:11:58,217 iteration 6690 : loss : 0.008209, loss_ce: 0.002424
2022-01-15 21:11:59,252 iteration 6691 : loss : 0.016584, loss_ce: 0.006144
2022-01-15 21:12:00,201 iteration 6692 : loss : 0.017056, loss_ce: 0.006468
2022-01-15 21:12:01,177 iteration 6693 : loss : 0.017579, loss_ce: 0.006416
2022-01-15 21:12:02,189 iteration 6694 : loss : 0.018694, loss_ce: 0.006210
2022-01-15 21:12:03,144 iteration 6695 : loss : 0.018657, loss_ce: 0.005754
2022-01-15 21:12:04,137 iteration 6696 : loss : 0.010573, loss_ce: 0.004210
2022-01-15 21:12:05,130 iteration 6697 : loss : 0.016563, loss_ce: 0.006184
2022-01-15 21:12:06,215 iteration 6698 : loss : 0.017421, loss_ce: 0.005551
 98%|████████████████████████████▌| 394/400 [2:01:14<01:46, 17.77s/it]2022-01-15 21:12:07,243 iteration 6699 : loss : 0.015429, loss_ce: 0.005128
2022-01-15 21:12:08,306 iteration 6700 : loss : 0.021594, loss_ce: 0.005685
2022-01-15 21:12:09,289 iteration 6701 : loss : 0.010843, loss_ce: 0.003598
2022-01-15 21:12:10,201 iteration 6702 : loss : 0.010350, loss_ce: 0.004920
2022-01-15 21:12:11,116 iteration 6703 : loss : 0.012594, loss_ce: 0.004287
2022-01-15 21:12:12,161 iteration 6704 : loss : 0.019008, loss_ce: 0.009998
2022-01-15 21:12:13,104 iteration 6705 : loss : 0.015109, loss_ce: 0.007289
2022-01-15 21:12:14,187 iteration 6706 : loss : 0.014393, loss_ce: 0.004959
2022-01-15 21:12:15,126 iteration 6707 : loss : 0.020952, loss_ce: 0.013384
2022-01-15 21:12:16,133 iteration 6708 : loss : 0.014579, loss_ce: 0.005721
2022-01-15 21:12:17,146 iteration 6709 : loss : 0.015540, loss_ce: 0.006194
2022-01-15 21:12:18,191 iteration 6710 : loss : 0.015329, loss_ce: 0.003990
2022-01-15 21:12:19,234 iteration 6711 : loss : 0.015585, loss_ce: 0.003929
2022-01-15 21:12:20,335 iteration 6712 : loss : 0.016208, loss_ce: 0.006894
2022-01-15 21:12:21,264 iteration 6713 : loss : 0.010423, loss_ce: 0.003758
2022-01-15 21:12:22,273 iteration 6714 : loss : 0.013007, loss_ce: 0.004276
2022-01-15 21:12:22,273 Training Data Eval:
2022-01-15 21:12:27,062   Average segmentation loss on training set: 0.0081
2022-01-15 21:12:27,063 Validation Data Eval:
2022-01-15 21:12:28,699   Average segmentation loss on validation set: 0.0753
2022-01-15 21:12:29,653 iteration 6715 : loss : 0.012126, loss_ce: 0.004741
 99%|████████████████████████████▋| 395/400 [2:01:37<01:37, 19.47s/it]2022-01-15 21:12:30,708 iteration 6716 : loss : 0.015638, loss_ce: 0.007215
2022-01-15 21:12:31,682 iteration 6717 : loss : 0.012690, loss_ce: 0.005702
2022-01-15 21:12:32,670 iteration 6718 : loss : 0.012638, loss_ce: 0.004748
2022-01-15 21:12:33,627 iteration 6719 : loss : 0.017288, loss_ce: 0.008221
2022-01-15 21:12:34,591 iteration 6720 : loss : 0.013250, loss_ce: 0.004566
2022-01-15 21:12:35,542 iteration 6721 : loss : 0.010626, loss_ce: 0.003665
2022-01-15 21:12:36,629 iteration 6722 : loss : 0.012089, loss_ce: 0.004521
2022-01-15 21:12:37,520 iteration 6723 : loss : 0.011964, loss_ce: 0.003992
2022-01-15 21:12:38,512 iteration 6724 : loss : 0.019020, loss_ce: 0.006170
2022-01-15 21:12:39,538 iteration 6725 : loss : 0.012212, loss_ce: 0.004063
2022-01-15 21:12:40,581 iteration 6726 : loss : 0.015189, loss_ce: 0.006301
2022-01-15 21:12:41,688 iteration 6727 : loss : 0.032076, loss_ce: 0.011685
2022-01-15 21:12:42,672 iteration 6728 : loss : 0.015028, loss_ce: 0.005197
2022-01-15 21:12:43,664 iteration 6729 : loss : 0.022245, loss_ce: 0.006052
2022-01-15 21:12:44,606 iteration 6730 : loss : 0.012848, loss_ce: 0.005959
2022-01-15 21:12:45,593 iteration 6731 : loss : 0.012346, loss_ce: 0.004626
2022-01-15 21:12:46,628 iteration 6732 : loss : 0.017780, loss_ce: 0.006799
 99%|████████████████████████████▋| 396/400 [2:01:54<01:14, 18.72s/it]2022-01-15 21:12:47,667 iteration 6733 : loss : 0.012486, loss_ce: 0.004438
2022-01-15 21:12:48,768 iteration 6734 : loss : 0.016071, loss_ce: 0.006122
2022-01-15 21:12:49,702 iteration 6735 : loss : 0.011213, loss_ce: 0.004492
2022-01-15 21:12:50,735 iteration 6736 : loss : 0.016571, loss_ce: 0.007008
2022-01-15 21:12:51,769 iteration 6737 : loss : 0.016813, loss_ce: 0.007036
2022-01-15 21:12:52,658 iteration 6738 : loss : 0.011447, loss_ce: 0.003136
2022-01-15 21:12:53,602 iteration 6739 : loss : 0.013833, loss_ce: 0.005218
2022-01-15 21:12:54,623 iteration 6740 : loss : 0.010319, loss_ce: 0.004197
2022-01-15 21:12:55,590 iteration 6741 : loss : 0.010531, loss_ce: 0.003769
2022-01-15 21:12:56,538 iteration 6742 : loss : 0.014713, loss_ce: 0.005096
2022-01-15 21:12:57,561 iteration 6743 : loss : 0.019363, loss_ce: 0.011582
2022-01-15 21:12:58,580 iteration 6744 : loss : 0.016682, loss_ce: 0.007148
2022-01-15 21:12:59,517 iteration 6745 : loss : 0.012732, loss_ce: 0.004737
2022-01-15 21:13:00,512 iteration 6746 : loss : 0.013978, loss_ce: 0.005278
2022-01-15 21:13:01,600 iteration 6747 : loss : 0.016519, loss_ce: 0.004439
2022-01-15 21:13:02,637 iteration 6748 : loss : 0.014086, loss_ce: 0.004355
2022-01-15 21:13:03,636 iteration 6749 : loss : 0.014447, loss_ce: 0.005981
 99%|████████████████████████████▊| 397/400 [2:02:11<00:54, 18.21s/it]2022-01-15 21:13:04,724 iteration 6750 : loss : 0.011514, loss_ce: 0.004497
2022-01-15 21:13:05,826 iteration 6751 : loss : 0.021748, loss_ce: 0.006812
2022-01-15 21:13:06,889 iteration 6752 : loss : 0.020556, loss_ce: 0.008197
2022-01-15 21:13:07,869 iteration 6753 : loss : 0.021581, loss_ce: 0.008567
2022-01-15 21:13:08,949 iteration 6754 : loss : 0.014002, loss_ce: 0.005894
2022-01-15 21:13:09,903 iteration 6755 : loss : 0.011043, loss_ce: 0.002733
2022-01-15 21:13:10,787 iteration 6756 : loss : 0.009222, loss_ce: 0.004249
2022-01-15 21:13:11,726 iteration 6757 : loss : 0.011256, loss_ce: 0.004441
2022-01-15 21:13:12,709 iteration 6758 : loss : 0.011454, loss_ce: 0.005675
2022-01-15 21:13:13,755 iteration 6759 : loss : 0.020323, loss_ce: 0.006351
2022-01-15 21:13:14,717 iteration 6760 : loss : 0.011347, loss_ce: 0.004426
2022-01-15 21:13:15,677 iteration 6761 : loss : 0.013558, loss_ce: 0.004618
2022-01-15 21:13:16,676 iteration 6762 : loss : 0.019244, loss_ce: 0.005391
2022-01-15 21:13:17,657 iteration 6763 : loss : 0.017212, loss_ce: 0.007473
2022-01-15 21:13:18,706 iteration 6764 : loss : 0.014677, loss_ce: 0.004777
2022-01-15 21:13:19,718 iteration 6765 : loss : 0.015435, loss_ce: 0.004292
2022-01-15 21:13:20,693 iteration 6766 : loss : 0.010365, loss_ce: 0.004705
100%|████████████████████████████▊| 398/400 [2:02:28<00:35, 17.86s/it]2022-01-15 21:13:21,806 iteration 6767 : loss : 0.021219, loss_ce: 0.009385
2022-01-15 21:13:22,767 iteration 6768 : loss : 0.015224, loss_ce: 0.004877
2022-01-15 21:13:23,734 iteration 6769 : loss : 0.010425, loss_ce: 0.003352
2022-01-15 21:13:24,742 iteration 6770 : loss : 0.018989, loss_ce: 0.005713
2022-01-15 21:13:25,713 iteration 6771 : loss : 0.017683, loss_ce: 0.007427
2022-01-15 21:13:26,722 iteration 6772 : loss : 0.014479, loss_ce: 0.007756
2022-01-15 21:13:27,649 iteration 6773 : loss : 0.010291, loss_ce: 0.003793
2022-01-15 21:13:28,641 iteration 6774 : loss : 0.014763, loss_ce: 0.004941
2022-01-15 21:13:29,597 iteration 6775 : loss : 0.016044, loss_ce: 0.004009
2022-01-15 21:13:30,598 iteration 6776 : loss : 0.014383, loss_ce: 0.005219
2022-01-15 21:13:31,616 iteration 6777 : loss : 0.016566, loss_ce: 0.006932
2022-01-15 21:13:32,565 iteration 6778 : loss : 0.013481, loss_ce: 0.004755
2022-01-15 21:13:33,549 iteration 6779 : loss : 0.012223, loss_ce: 0.006374
2022-01-15 21:13:34,596 iteration 6780 : loss : 0.013886, loss_ce: 0.005106
2022-01-15 21:13:35,596 iteration 6781 : loss : 0.012208, loss_ce: 0.004361
2022-01-15 21:13:36,549 iteration 6782 : loss : 0.012305, loss_ce: 0.004654
2022-01-15 21:13:37,598 iteration 6783 : loss : 0.018782, loss_ce: 0.006122
100%|████████████████████████████▉| 399/400 [2:02:45<00:17, 17.57s/it]2022-01-15 21:13:38,576 iteration 6784 : loss : 0.011916, loss_ce: 0.006156
2022-01-15 21:13:39,551 iteration 6785 : loss : 0.012962, loss_ce: 0.004056
2022-01-15 21:13:40,587 iteration 6786 : loss : 0.014291, loss_ce: 0.005220
2022-01-15 21:13:41,563 iteration 6787 : loss : 0.018648, loss_ce: 0.004782
2022-01-15 21:13:42,546 iteration 6788 : loss : 0.012793, loss_ce: 0.006212
2022-01-15 21:13:43,610 iteration 6789 : loss : 0.017703, loss_ce: 0.005481
2022-01-15 21:13:44,600 iteration 6790 : loss : 0.018417, loss_ce: 0.007968
2022-01-15 21:13:45,661 iteration 6791 : loss : 0.026650, loss_ce: 0.008158
2022-01-15 21:13:46,627 iteration 6792 : loss : 0.015409, loss_ce: 0.006624
2022-01-15 21:13:47,526 iteration 6793 : loss : 0.010365, loss_ce: 0.003907
2022-01-15 21:13:48,552 iteration 6794 : loss : 0.016851, loss_ce: 0.006684
2022-01-15 21:13:49,485 iteration 6795 : loss : 0.024467, loss_ce: 0.012719
2022-01-15 21:13:50,459 iteration 6796 : loss : 0.012113, loss_ce: 0.003021
2022-01-15 21:13:51,416 iteration 6797 : loss : 0.012501, loss_ce: 0.004755
2022-01-15 21:13:52,453 iteration 6798 : loss : 0.017792, loss_ce: 0.005571
2022-01-15 21:13:53,417 iteration 6799 : loss : 0.015430, loss_ce: 0.005239
2022-01-15 21:13:53,417 Training Data Eval:
2022-01-15 21:13:58,150   Average segmentation loss on training set: 0.0078
2022-01-15 21:13:58,151 Validation Data Eval:
2022-01-15 21:13:59,766   Average segmentation loss on validation set: 0.0827
2022-01-15 21:14:00,755 iteration 6800 : loss : 0.013604, loss_ce: 0.005517
100%|█████████████████████████████| 400/400 [2:03:08<00:00, 19.25s/it]100%|█████████████████████████████| 400/400 [2:03:08<00:00, 18.47s/it]
