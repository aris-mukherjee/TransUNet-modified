2022-01-14 11:34:34,105 Logging directory: /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/TransUNet/log_dir/trRUNMC_cv1_r3/i2i2l/
2022-01-14 11:34:34,106 Tensorboard directory: /scratch_net/biwidl217_second/arismu/Tensorboard/trRUNMC_cv1_r3/i2i2l/
2022-01-14 11:34:34,106 ============================================================
2022-01-14 11:34:34,106 EXPERIMENT NAME: trRUNMC_cv1_r3/i2i2l/
2022-01-14 11:34:34,106 ============================================================
2022-01-14 11:34:34,106 Loading data...
2022-01-14 11:34:34,106 Reading NCI - RUNMC images...
2022-01-14 11:34:34,106 Data root directory: /itet-stor/arismu/bmicdatasets-originals/Originals/Challenge_Datasets/NCI_Prostate/
2022-01-14 11:34:34,107 Already preprocessed this configuration. Loading now!
2022-01-14 11:34:34,123 Training Images: (256, 256, 286)
2022-01-14 11:34:34,123 Training Labels: (256, 256, 286)
2022-01-14 11:34:34,123 Validation Images: (256, 256, 98)
2022-01-14 11:34:34,123 Validation Labels: (256, 256, 98)
2022-01-14 11:34:34,123 ============================================================
2022-01-14 11:34:34,160 17 iterations per epoch. 6800 max iterations 
  0%|                                         | 0/400 [00:00<?, ?it/s]2022-01-14 11:34:36,808 iteration 1 : loss : 1.132674, loss_ce: 1.473716
2022-01-14 11:34:37,687 iteration 2 : loss : 1.052549, loss_ce: 1.351070
2022-01-14 11:34:38,651 iteration 3 : loss : 0.959295, loss_ce: 1.199588
2022-01-14 11:34:39,557 iteration 4 : loss : 0.940510, loss_ce: 1.135244
2022-01-14 11:34:40,391 iteration 5 : loss : 0.906061, loss_ce: 1.062730
2022-01-14 11:34:41,276 iteration 6 : loss : 0.866918, loss_ce: 1.005084
2022-01-14 11:34:42,195 iteration 7 : loss : 0.830985, loss_ce: 0.950411
2022-01-14 11:34:43,174 iteration 8 : loss : 0.796609, loss_ce: 0.891186
2022-01-14 11:34:44,020 iteration 9 : loss : 0.771766, loss_ce: 0.833159
2022-01-14 11:34:44,869 iteration 10 : loss : 0.725243, loss_ce: 0.772543
2022-01-14 11:34:45,704 iteration 11 : loss : 0.698281, loss_ce: 0.716101
2022-01-14 11:34:46,593 iteration 12 : loss : 0.663199, loss_ce: 0.674192
2022-01-14 11:34:47,533 iteration 13 : loss : 0.618048, loss_ce: 0.627614
2022-01-14 11:34:48,368 iteration 14 : loss : 0.591350, loss_ce: 0.576818
2022-01-14 11:34:49,301 iteration 15 : loss : 0.574151, loss_ce: 0.536600
2022-01-14 11:34:50,175 iteration 16 : loss : 0.557464, loss_ce: 0.503726
2022-01-14 11:34:51,039 iteration 17 : loss : 0.512219, loss_ce: 0.469488
  0%|                               | 1/400 [00:16<1:52:42, 16.95s/it]2022-01-14 11:34:51,974 iteration 18 : loss : 0.500020, loss_ce: 0.418407
2022-01-14 11:34:52,875 iteration 19 : loss : 0.475043, loss_ce: 0.392455
2022-01-14 11:34:53,760 iteration 20 : loss : 0.443673, loss_ce: 0.362272
2022-01-14 11:34:54,721 iteration 21 : loss : 0.437424, loss_ce: 0.338133
2022-01-14 11:34:55,594 iteration 22 : loss : 0.413604, loss_ce: 0.313094
2022-01-14 11:34:56,494 iteration 23 : loss : 0.383236, loss_ce: 0.273172
2022-01-14 11:34:57,328 iteration 24 : loss : 0.383940, loss_ce: 0.278417
2022-01-14 11:34:58,124 iteration 25 : loss : 0.384773, loss_ce: 0.251389
2022-01-14 11:34:58,962 iteration 26 : loss : 0.377730, loss_ce: 0.235344
2022-01-14 11:34:59,852 iteration 27 : loss : 0.328396, loss_ce: 0.215555
2022-01-14 11:35:00,725 iteration 28 : loss : 0.341491, loss_ce: 0.203516
2022-01-14 11:35:01,736 iteration 29 : loss : 0.327044, loss_ce: 0.200466
2022-01-14 11:35:02,670 iteration 30 : loss : 0.329776, loss_ce: 0.185052
2022-01-14 11:35:03,515 iteration 31 : loss : 0.292754, loss_ce: 0.173149
2022-01-14 11:35:04,381 iteration 32 : loss : 0.311504, loss_ce: 0.177058
2022-01-14 11:35:05,335 iteration 33 : loss : 0.287950, loss_ce: 0.172099
2022-01-14 11:35:06,197 iteration 34 : loss : 0.283218, loss_ce: 0.147918
  0%|▏                              | 2/400 [00:32<1:45:21, 15.88s/it]2022-01-14 11:35:07,181 iteration 35 : loss : 0.262745, loss_ce: 0.158380
2022-01-14 11:35:08,078 iteration 36 : loss : 0.290804, loss_ce: 0.162733
2022-01-14 11:35:09,011 iteration 37 : loss : 0.275591, loss_ce: 0.163097
2022-01-14 11:35:10,004 iteration 38 : loss : 0.255164, loss_ce: 0.132513
2022-01-14 11:35:10,907 iteration 39 : loss : 0.349314, loss_ce: 0.157592
2022-01-14 11:35:11,840 iteration 40 : loss : 0.266345, loss_ce: 0.154716
2022-01-14 11:35:12,684 iteration 41 : loss : 0.263462, loss_ce: 0.121194
2022-01-14 11:35:13,696 iteration 42 : loss : 0.260459, loss_ce: 0.135157
2022-01-14 11:35:14,539 iteration 43 : loss : 0.285996, loss_ce: 0.119340
2022-01-14 11:35:15,457 iteration 44 : loss : 0.244987, loss_ce: 0.116189
2022-01-14 11:35:16,397 iteration 45 : loss : 0.355898, loss_ce: 0.162262
2022-01-14 11:35:17,211 iteration 46 : loss : 0.245196, loss_ce: 0.111438
2022-01-14 11:35:18,088 iteration 47 : loss : 0.300978, loss_ce: 0.126438
2022-01-14 11:35:19,007 iteration 48 : loss : 0.209472, loss_ce: 0.106280
2022-01-14 11:35:19,913 iteration 49 : loss : 0.294076, loss_ce: 0.125416
2022-01-14 11:35:20,858 iteration 50 : loss : 0.237158, loss_ce: 0.096933
2022-01-14 11:35:21,769 iteration 51 : loss : 0.249902, loss_ce: 0.128216
  1%|▏                              | 3/400 [00:47<1:44:09, 15.74s/it]2022-01-14 11:35:22,645 iteration 52 : loss : 0.276877, loss_ce: 0.130953
2022-01-14 11:35:23,461 iteration 53 : loss : 0.255480, loss_ce: 0.122256
2022-01-14 11:35:24,382 iteration 54 : loss : 0.186089, loss_ce: 0.093713
2022-01-14 11:35:26,857 iteration 55 : loss : 0.332784, loss_ce: 0.144450
2022-01-14 11:35:27,788 iteration 56 : loss : 0.260579, loss_ce: 0.121886
2022-01-14 11:35:28,715 iteration 57 : loss : 0.230849, loss_ce: 0.096337
2022-01-14 11:35:29,626 iteration 58 : loss : 0.260220, loss_ce: 0.129620
2022-01-14 11:35:30,514 iteration 59 : loss : 0.240157, loss_ce: 0.100122
2022-01-14 11:35:31,514 iteration 60 : loss : 0.288488, loss_ce: 0.128455
2022-01-14 11:35:32,486 iteration 61 : loss : 0.265546, loss_ce: 0.117137
2022-01-14 11:35:33,388 iteration 62 : loss : 0.283283, loss_ce: 0.114985
2022-01-14 11:35:34,218 iteration 63 : loss : 0.226229, loss_ce: 0.112118
2022-01-14 11:35:35,141 iteration 64 : loss : 0.298145, loss_ce: 0.162728
2022-01-14 11:35:36,021 iteration 65 : loss : 0.292245, loss_ce: 0.126095
2022-01-14 11:35:36,960 iteration 66 : loss : 0.248135, loss_ce: 0.119078
2022-01-14 11:35:37,813 iteration 67 : loss : 0.306672, loss_ce: 0.164320
2022-01-14 11:35:38,698 iteration 68 : loss : 0.280982, loss_ce: 0.127218
  1%|▎                              | 4/400 [01:04<1:47:00, 16.21s/it]2022-01-14 11:35:39,654 iteration 69 : loss : 0.252980, loss_ce: 0.109109
2022-01-14 11:35:40,575 iteration 70 : loss : 0.307177, loss_ce: 0.145978
2022-01-14 11:35:41,427 iteration 71 : loss : 0.229792, loss_ce: 0.097554
2022-01-14 11:35:42,375 iteration 72 : loss : 0.258220, loss_ce: 0.103681
2022-01-14 11:35:43,264 iteration 73 : loss : 0.248565, loss_ce: 0.116308
2022-01-14 11:35:44,233 iteration 74 : loss : 0.255312, loss_ce: 0.109281
2022-01-14 11:35:45,141 iteration 75 : loss : 0.263517, loss_ce: 0.141751
2022-01-14 11:35:46,095 iteration 76 : loss : 0.235887, loss_ce: 0.107514
2022-01-14 11:35:47,071 iteration 77 : loss : 0.230745, loss_ce: 0.097045
2022-01-14 11:35:48,022 iteration 78 : loss : 0.206330, loss_ce: 0.111533
2022-01-14 11:35:48,879 iteration 79 : loss : 0.196708, loss_ce: 0.081972
2022-01-14 11:35:49,831 iteration 80 : loss : 0.299823, loss_ce: 0.123412
2022-01-14 11:35:50,723 iteration 81 : loss : 0.241457, loss_ce: 0.106851
2022-01-14 11:35:51,620 iteration 82 : loss : 0.262074, loss_ce: 0.137543
2022-01-14 11:35:52,576 iteration 83 : loss : 0.232270, loss_ce: 0.103532
2022-01-14 11:35:53,444 iteration 84 : loss : 0.253895, loss_ce: 0.126965
2022-01-14 11:35:53,444 Training Data Eval:
2022-01-14 11:35:57,705   Average segmentation loss on training set: 0.7556
2022-01-14 11:35:57,705 Validation Data Eval:
2022-01-14 11:35:59,391   Average segmentation loss on validation set: 0.7399
2022-01-14 11:36:00,569 Found new lowest validation loss at iteration 84! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_1BLOCK_best_val_loss_seed2.pth
2022-01-14 11:36:01,511 iteration 85 : loss : 0.222980, loss_ce: 0.108471
  1%|▍                              | 5/400 [01:27<2:02:23, 18.59s/it]2022-01-14 11:36:02,437 iteration 86 : loss : 0.296372, loss_ce: 0.123584
2022-01-14 11:36:03,244 iteration 87 : loss : 0.249037, loss_ce: 0.104926
2022-01-14 11:36:04,104 iteration 88 : loss : 0.231905, loss_ce: 0.089286
2022-01-14 11:36:05,053 iteration 89 : loss : 0.238651, loss_ce: 0.101288
2022-01-14 11:36:05,912 iteration 90 : loss : 0.216937, loss_ce: 0.096770
2022-01-14 11:36:06,823 iteration 91 : loss : 0.259873, loss_ce: 0.107219
2022-01-14 11:36:07,706 iteration 92 : loss : 0.282573, loss_ce: 0.132859
2022-01-14 11:36:08,668 iteration 93 : loss : 0.261314, loss_ce: 0.119788
2022-01-14 11:36:09,630 iteration 94 : loss : 0.258757, loss_ce: 0.141819
2022-01-14 11:36:10,513 iteration 95 : loss : 0.279393, loss_ce: 0.123559
2022-01-14 11:36:11,358 iteration 96 : loss : 0.274924, loss_ce: 0.118132
2022-01-14 11:36:12,205 iteration 97 : loss : 0.194431, loss_ce: 0.089481
2022-01-14 11:36:13,085 iteration 98 : loss : 0.282042, loss_ce: 0.126766
2022-01-14 11:36:14,096 iteration 99 : loss : 0.236260, loss_ce: 0.103124
2022-01-14 11:36:15,120 iteration 100 : loss : 0.254416, loss_ce: 0.106010
2022-01-14 11:36:15,995 iteration 101 : loss : 0.294969, loss_ce: 0.133011
2022-01-14 11:36:16,892 iteration 102 : loss : 0.252652, loss_ce: 0.099202
  2%|▍                              | 6/400 [01:42<1:54:56, 17.50s/it]2022-01-14 11:36:17,872 iteration 103 : loss : 0.288637, loss_ce: 0.114075
2022-01-14 11:36:18,821 iteration 104 : loss : 0.274625, loss_ce: 0.113582
2022-01-14 11:36:19,745 iteration 105 : loss : 0.254667, loss_ce: 0.108101
2022-01-14 11:36:20,674 iteration 106 : loss : 0.223252, loss_ce: 0.083077
2022-01-14 11:36:21,656 iteration 107 : loss : 0.238843, loss_ce: 0.103275
2022-01-14 11:36:22,549 iteration 108 : loss : 0.249830, loss_ce: 0.127379
2022-01-14 11:36:23,466 iteration 109 : loss : 0.159963, loss_ce: 0.071825
2022-01-14 11:36:24,413 iteration 110 : loss : 0.252663, loss_ce: 0.122284
2022-01-14 11:36:25,494 iteration 111 : loss : 0.213027, loss_ce: 0.092909
2022-01-14 11:36:26,374 iteration 112 : loss : 0.262936, loss_ce: 0.107306
2022-01-14 11:36:27,384 iteration 113 : loss : 0.214283, loss_ce: 0.087119
2022-01-14 11:36:28,307 iteration 114 : loss : 0.225113, loss_ce: 0.078139
2022-01-14 11:36:29,152 iteration 115 : loss : 0.193141, loss_ce: 0.078073
2022-01-14 11:36:30,061 iteration 116 : loss : 0.231887, loss_ce: 0.106741
2022-01-14 11:36:30,942 iteration 117 : loss : 0.157738, loss_ce: 0.072052
2022-01-14 11:36:31,905 iteration 118 : loss : 0.246062, loss_ce: 0.097489
2022-01-14 11:36:32,782 iteration 119 : loss : 0.253139, loss_ce: 0.110943
  2%|▌                              | 7/400 [01:58<1:51:10, 16.97s/it]2022-01-14 11:36:33,797 iteration 120 : loss : 0.220556, loss_ce: 0.103447
2022-01-14 11:36:34,745 iteration 121 : loss : 0.298851, loss_ce: 0.136922
2022-01-14 11:36:35,561 iteration 122 : loss : 0.201256, loss_ce: 0.085832
2022-01-14 11:36:36,476 iteration 123 : loss : 0.233783, loss_ce: 0.104084
2022-01-14 11:36:37,363 iteration 124 : loss : 0.231196, loss_ce: 0.096193
2022-01-14 11:36:38,256 iteration 125 : loss : 0.246225, loss_ce: 0.099930
2022-01-14 11:36:39,140 iteration 126 : loss : 0.195885, loss_ce: 0.084364
2022-01-14 11:36:40,045 iteration 127 : loss : 0.264433, loss_ce: 0.122764
2022-01-14 11:36:40,921 iteration 128 : loss : 0.207548, loss_ce: 0.078114
2022-01-14 11:36:41,890 iteration 129 : loss : 0.303758, loss_ce: 0.131759
2022-01-14 11:36:42,697 iteration 130 : loss : 0.211102, loss_ce: 0.085290
2022-01-14 11:36:43,579 iteration 131 : loss : 0.231045, loss_ce: 0.116889
2022-01-14 11:36:44,490 iteration 132 : loss : 0.269159, loss_ce: 0.108084
2022-01-14 11:36:45,404 iteration 133 : loss : 0.328357, loss_ce: 0.174858
2022-01-14 11:36:46,296 iteration 134 : loss : 0.205136, loss_ce: 0.082811
2022-01-14 11:36:47,179 iteration 135 : loss : 0.188032, loss_ce: 0.062536
2022-01-14 11:36:48,156 iteration 136 : loss : 0.207757, loss_ce: 0.093628
  2%|▌                              | 8/400 [02:14<1:47:34, 16.46s/it]2022-01-14 11:36:49,192 iteration 137 : loss : 0.200708, loss_ce: 0.079816
2022-01-14 11:36:50,044 iteration 138 : loss : 0.185229, loss_ce: 0.076714
2022-01-14 11:36:51,032 iteration 139 : loss : 0.244998, loss_ce: 0.075539
2022-01-14 11:36:51,927 iteration 140 : loss : 0.303826, loss_ce: 0.134598
2022-01-14 11:36:52,785 iteration 141 : loss : 0.268503, loss_ce: 0.113434
2022-01-14 11:36:53,674 iteration 142 : loss : 0.205564, loss_ce: 0.083863
2022-01-14 11:36:54,583 iteration 143 : loss : 0.230614, loss_ce: 0.094705
2022-01-14 11:36:55,466 iteration 144 : loss : 0.213305, loss_ce: 0.074778
2022-01-14 11:36:56,380 iteration 145 : loss : 0.237420, loss_ce: 0.124235
2022-01-14 11:36:57,324 iteration 146 : loss : 0.166586, loss_ce: 0.071258
2022-01-14 11:36:58,240 iteration 147 : loss : 0.262240, loss_ce: 0.126789
2022-01-14 11:36:59,239 iteration 148 : loss : 0.226864, loss_ce: 0.103802
2022-01-14 11:37:00,224 iteration 149 : loss : 0.229612, loss_ce: 0.108496
2022-01-14 11:37:01,207 iteration 150 : loss : 0.220508, loss_ce: 0.095365
2022-01-14 11:37:02,080 iteration 151 : loss : 0.209086, loss_ce: 0.116086
2022-01-14 11:37:02,904 iteration 152 : loss : 0.162809, loss_ce: 0.078816
2022-01-14 11:37:03,793 iteration 153 : loss : 0.178828, loss_ce: 0.070491
  2%|▋                              | 9/400 [02:29<1:45:35, 16.20s/it]2022-01-14 11:37:04,794 iteration 154 : loss : 0.240674, loss_ce: 0.112425
2022-01-14 11:37:05,694 iteration 155 : loss : 0.180868, loss_ce: 0.093099
2022-01-14 11:37:06,565 iteration 156 : loss : 0.226936, loss_ce: 0.102001
2022-01-14 11:37:07,434 iteration 157 : loss : 0.239897, loss_ce: 0.108513
2022-01-14 11:37:08,402 iteration 158 : loss : 0.260910, loss_ce: 0.109929
2022-01-14 11:37:09,363 iteration 159 : loss : 0.167987, loss_ce: 0.068921
2022-01-14 11:37:10,248 iteration 160 : loss : 0.174449, loss_ce: 0.067079
2022-01-14 11:37:11,236 iteration 161 : loss : 0.193416, loss_ce: 0.086695
2022-01-14 11:37:12,151 iteration 162 : loss : 0.211523, loss_ce: 0.081196
2022-01-14 11:37:13,065 iteration 163 : loss : 0.244100, loss_ce: 0.110222
2022-01-14 11:37:13,962 iteration 164 : loss : 0.257245, loss_ce: 0.090993
2022-01-14 11:37:14,806 iteration 165 : loss : 0.170324, loss_ce: 0.068928
2022-01-14 11:37:15,780 iteration 166 : loss : 0.239331, loss_ce: 0.129257
2022-01-14 11:37:16,791 iteration 167 : loss : 0.272187, loss_ce: 0.125410
2022-01-14 11:37:17,686 iteration 168 : loss : 0.225557, loss_ce: 0.083069
2022-01-14 11:37:18,616 iteration 169 : loss : 0.186301, loss_ce: 0.077394
2022-01-14 11:37:18,616 Training Data Eval:
2022-01-14 11:37:22,892   Average segmentation loss on training set: 0.2629
2022-01-14 11:37:22,892 Validation Data Eval:
2022-01-14 11:37:24,355   Average segmentation loss on validation set: 0.3147
2022-01-14 11:37:25,555 Found new lowest validation loss at iteration 169! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_1BLOCK_best_val_loss_seed2.pth
2022-01-14 11:37:26,546 iteration 170 : loss : 0.196006, loss_ce: 0.081915
  2%|▊                             | 10/400 [02:52<1:58:27, 18.23s/it]2022-01-14 11:37:27,566 iteration 171 : loss : 0.164659, loss_ce: 0.080167
2022-01-14 11:37:28,430 iteration 172 : loss : 0.190306, loss_ce: 0.096118
2022-01-14 11:37:29,397 iteration 173 : loss : 0.218831, loss_ce: 0.083474
2022-01-14 11:37:30,231 iteration 174 : loss : 0.205223, loss_ce: 0.108971
2022-01-14 11:37:31,112 iteration 175 : loss : 0.215359, loss_ce: 0.075809
2022-01-14 11:37:31,985 iteration 176 : loss : 0.192104, loss_ce: 0.086978
2022-01-14 11:37:32,915 iteration 177 : loss : 0.172612, loss_ce: 0.073794
2022-01-14 11:37:33,819 iteration 178 : loss : 0.211685, loss_ce: 0.091259
2022-01-14 11:37:34,655 iteration 179 : loss : 0.190019, loss_ce: 0.069158
2022-01-14 11:37:35,640 iteration 180 : loss : 0.204283, loss_ce: 0.090394
2022-01-14 11:37:36,578 iteration 181 : loss : 0.202338, loss_ce: 0.088942
2022-01-14 11:37:37,480 iteration 182 : loss : 0.234514, loss_ce: 0.100036
2022-01-14 11:37:38,408 iteration 183 : loss : 0.207059, loss_ce: 0.068280
2022-01-14 11:37:39,460 iteration 184 : loss : 0.238341, loss_ce: 0.087933
2022-01-14 11:37:40,500 iteration 185 : loss : 0.203629, loss_ce: 0.090815
2022-01-14 11:37:41,397 iteration 186 : loss : 0.203969, loss_ce: 0.074274
2022-01-14 11:37:42,326 iteration 187 : loss : 0.162392, loss_ce: 0.074125
  3%|▊                             | 11/400 [03:08<1:53:18, 17.48s/it]2022-01-14 11:37:43,256 iteration 188 : loss : 0.199511, loss_ce: 0.085233
2022-01-14 11:37:44,262 iteration 189 : loss : 0.216592, loss_ce: 0.093936
2022-01-14 11:37:45,211 iteration 190 : loss : 0.219013, loss_ce: 0.103848
2022-01-14 11:37:46,139 iteration 191 : loss : 0.172157, loss_ce: 0.066278
2022-01-14 11:37:47,046 iteration 192 : loss : 0.233518, loss_ce: 0.089414
2022-01-14 11:37:47,890 iteration 193 : loss : 0.196874, loss_ce: 0.084908
2022-01-14 11:37:48,833 iteration 194 : loss : 0.192480, loss_ce: 0.080031
2022-01-14 11:37:49,790 iteration 195 : loss : 0.195385, loss_ce: 0.072933
2022-01-14 11:37:50,685 iteration 196 : loss : 0.160553, loss_ce: 0.076894
2022-01-14 11:37:51,661 iteration 197 : loss : 0.196747, loss_ce: 0.069824
2022-01-14 11:37:52,585 iteration 198 : loss : 0.188649, loss_ce: 0.069538
2022-01-14 11:37:53,406 iteration 199 : loss : 0.232628, loss_ce: 0.073853
2022-01-14 11:37:54,298 iteration 200 : loss : 0.231739, loss_ce: 0.107089
2022-01-14 11:37:55,326 iteration 201 : loss : 0.193198, loss_ce: 0.084145
2022-01-14 11:37:56,211 iteration 202 : loss : 0.181762, loss_ce: 0.075238
2022-01-14 11:37:57,074 iteration 203 : loss : 0.231946, loss_ce: 0.118514
2022-01-14 11:37:57,907 iteration 204 : loss : 0.169109, loss_ce: 0.076831
  3%|▉                             | 12/400 [03:23<1:49:18, 16.90s/it]2022-01-14 11:37:58,812 iteration 205 : loss : 0.212801, loss_ce: 0.094498
2022-01-14 11:37:59,743 iteration 206 : loss : 0.250469, loss_ce: 0.116459
2022-01-14 11:38:00,746 iteration 207 : loss : 0.199071, loss_ce: 0.102263
2022-01-14 11:38:01,752 iteration 208 : loss : 0.168559, loss_ce: 0.068860
2022-01-14 11:38:02,664 iteration 209 : loss : 0.198487, loss_ce: 0.084242
2022-01-14 11:38:03,514 iteration 210 : loss : 0.140890, loss_ce: 0.056593
2022-01-14 11:38:04,417 iteration 211 : loss : 0.175984, loss_ce: 0.071515
2022-01-14 11:38:05,237 iteration 212 : loss : 0.197988, loss_ce: 0.068388
2022-01-14 11:38:06,187 iteration 213 : loss : 0.210344, loss_ce: 0.093883
2022-01-14 11:38:07,109 iteration 214 : loss : 0.220421, loss_ce: 0.060926
2022-01-14 11:38:07,959 iteration 215 : loss : 0.171737, loss_ce: 0.074866
2022-01-14 11:38:08,921 iteration 216 : loss : 0.198372, loss_ce: 0.088218
2022-01-14 11:38:09,798 iteration 217 : loss : 0.169738, loss_ce: 0.070029
2022-01-14 11:38:10,683 iteration 218 : loss : 0.135973, loss_ce: 0.055172
2022-01-14 11:38:11,571 iteration 219 : loss : 0.149819, loss_ce: 0.054212
2022-01-14 11:38:12,418 iteration 220 : loss : 0.224447, loss_ce: 0.116212
2022-01-14 11:38:13,307 iteration 221 : loss : 0.167918, loss_ce: 0.079430
  3%|▉                             | 13/400 [03:39<1:46:05, 16.45s/it]2022-01-14 11:38:14,388 iteration 222 : loss : 0.162070, loss_ce: 0.063019
2022-01-14 11:38:15,339 iteration 223 : loss : 0.116717, loss_ce: 0.043835
2022-01-14 11:38:16,161 iteration 224 : loss : 0.171861, loss_ce: 0.080480
2022-01-14 11:38:17,113 iteration 225 : loss : 0.228034, loss_ce: 0.086050
2022-01-14 11:38:18,073 iteration 226 : loss : 0.242176, loss_ce: 0.081442
2022-01-14 11:38:19,028 iteration 227 : loss : 0.172244, loss_ce: 0.075877
2022-01-14 11:38:19,963 iteration 228 : loss : 0.189222, loss_ce: 0.077974
2022-01-14 11:38:20,893 iteration 229 : loss : 0.150997, loss_ce: 0.064338
2022-01-14 11:38:21,806 iteration 230 : loss : 0.249861, loss_ce: 0.111071
2022-01-14 11:38:22,684 iteration 231 : loss : 0.217171, loss_ce: 0.081547
2022-01-14 11:38:23,679 iteration 232 : loss : 0.151266, loss_ce: 0.081647
2022-01-14 11:38:24,665 iteration 233 : loss : 0.175366, loss_ce: 0.090726
2022-01-14 11:38:25,620 iteration 234 : loss : 0.203967, loss_ce: 0.068289
2022-01-14 11:38:26,534 iteration 235 : loss : 0.148811, loss_ce: 0.058115
2022-01-14 11:38:27,429 iteration 236 : loss : 0.224950, loss_ce: 0.106933
2022-01-14 11:38:28,322 iteration 237 : loss : 0.143167, loss_ce: 0.055356
2022-01-14 11:38:29,141 iteration 238 : loss : 0.167600, loss_ce: 0.076776
  4%|█                             | 14/400 [03:55<1:44:35, 16.26s/it]2022-01-14 11:38:30,066 iteration 239 : loss : 0.154922, loss_ce: 0.060148
2022-01-14 11:38:31,039 iteration 240 : loss : 0.167833, loss_ce: 0.082927
2022-01-14 11:38:31,909 iteration 241 : loss : 0.249642, loss_ce: 0.090519
2022-01-14 11:38:32,879 iteration 242 : loss : 0.160527, loss_ce: 0.071947
2022-01-14 11:38:33,866 iteration 243 : loss : 0.177505, loss_ce: 0.078771
2022-01-14 11:38:34,833 iteration 244 : loss : 0.194983, loss_ce: 0.086970
2022-01-14 11:38:35,671 iteration 245 : loss : 0.142641, loss_ce: 0.049134
2022-01-14 11:38:36,589 iteration 246 : loss : 0.170057, loss_ce: 0.065779
2022-01-14 11:38:37,442 iteration 247 : loss : 0.146737, loss_ce: 0.064573
2022-01-14 11:38:38,269 iteration 248 : loss : 0.160175, loss_ce: 0.060200
2022-01-14 11:38:39,269 iteration 249 : loss : 0.152254, loss_ce: 0.052981
2022-01-14 11:38:40,234 iteration 250 : loss : 0.203845, loss_ce: 0.098403
2022-01-14 11:38:41,133 iteration 251 : loss : 0.140396, loss_ce: 0.060420
2022-01-14 11:38:42,050 iteration 252 : loss : 0.182985, loss_ce: 0.094241
2022-01-14 11:38:42,918 iteration 253 : loss : 0.210857, loss_ce: 0.074608
2022-01-14 11:38:43,787 iteration 254 : loss : 0.161409, loss_ce: 0.065215
2022-01-14 11:38:43,787 Training Data Eval:
2022-01-14 11:38:48,202   Average segmentation loss on training set: 0.2263
2022-01-14 11:38:48,202 Validation Data Eval:
2022-01-14 11:38:49,692   Average segmentation loss on validation set: 0.2831
2022-01-14 11:38:50,881 Found new lowest validation loss at iteration 254! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_1BLOCK_best_val_loss_seed2.pth
2022-01-14 11:38:51,783 iteration 255 : loss : 0.225121, loss_ce: 0.094436
  4%|█▏                            | 15/400 [04:17<1:56:40, 18.18s/it]2022-01-14 11:38:52,740 iteration 256 : loss : 0.170315, loss_ce: 0.067588
2022-01-14 11:38:53,622 iteration 257 : loss : 0.165079, loss_ce: 0.086440
2022-01-14 11:38:54,639 iteration 258 : loss : 0.178595, loss_ce: 0.063940
2022-01-14 11:38:55,487 iteration 259 : loss : 0.179703, loss_ce: 0.070661
2022-01-14 11:38:56,410 iteration 260 : loss : 0.172416, loss_ce: 0.074952
2022-01-14 11:38:57,347 iteration 261 : loss : 0.216006, loss_ce: 0.094665
2022-01-14 11:38:58,275 iteration 262 : loss : 0.264401, loss_ce: 0.136955
2022-01-14 11:38:59,140 iteration 263 : loss : 0.199775, loss_ce: 0.114338
2022-01-14 11:38:59,999 iteration 264 : loss : 0.203564, loss_ce: 0.081003
2022-01-14 11:39:00,940 iteration 265 : loss : 0.184732, loss_ce: 0.091395
2022-01-14 11:39:01,871 iteration 266 : loss : 0.199086, loss_ce: 0.073343
2022-01-14 11:39:02,767 iteration 267 : loss : 0.189220, loss_ce: 0.081428
2022-01-14 11:39:03,673 iteration 268 : loss : 0.143154, loss_ce: 0.069122
2022-01-14 11:39:04,554 iteration 269 : loss : 0.143991, loss_ce: 0.060693
2022-01-14 11:39:05,380 iteration 270 : loss : 0.167303, loss_ce: 0.066340
2022-01-14 11:39:06,300 iteration 271 : loss : 0.265243, loss_ce: 0.106253
2022-01-14 11:39:07,272 iteration 272 : loss : 0.193416, loss_ce: 0.089952
  4%|█▏                            | 16/400 [04:33<1:51:12, 17.38s/it]2022-01-14 11:39:08,233 iteration 273 : loss : 0.138649, loss_ce: 0.052201
2022-01-14 11:39:09,156 iteration 274 : loss : 0.224362, loss_ce: 0.089229
2022-01-14 11:39:10,061 iteration 275 : loss : 0.158949, loss_ce: 0.071437
2022-01-14 11:39:10,912 iteration 276 : loss : 0.185128, loss_ce: 0.090906
2022-01-14 11:39:11,893 iteration 277 : loss : 0.158924, loss_ce: 0.065668
2022-01-14 11:39:12,733 iteration 278 : loss : 0.323638, loss_ce: 0.130785
2022-01-14 11:39:13,637 iteration 279 : loss : 0.161970, loss_ce: 0.073056
2022-01-14 11:39:14,457 iteration 280 : loss : 0.182617, loss_ce: 0.094304
2022-01-14 11:39:15,375 iteration 281 : loss : 0.142600, loss_ce: 0.055136
2022-01-14 11:39:16,316 iteration 282 : loss : 0.158834, loss_ce: 0.073125
2022-01-14 11:39:17,236 iteration 283 : loss : 0.159050, loss_ce: 0.077483
2022-01-14 11:39:18,092 iteration 284 : loss : 0.109655, loss_ce: 0.046570
2022-01-14 11:39:19,007 iteration 285 : loss : 0.133180, loss_ce: 0.055748
2022-01-14 11:39:19,939 iteration 286 : loss : 0.103527, loss_ce: 0.040437
2022-01-14 11:39:20,797 iteration 287 : loss : 0.157192, loss_ce: 0.057740
2022-01-14 11:39:21,687 iteration 288 : loss : 0.126052, loss_ce: 0.059296
2022-01-14 11:39:22,582 iteration 289 : loss : 0.177584, loss_ce: 0.082882
  4%|█▎                            | 17/400 [04:48<1:46:57, 16.76s/it]2022-01-14 11:39:23,556 iteration 290 : loss : 0.145627, loss_ce: 0.064898
2022-01-14 11:39:24,464 iteration 291 : loss : 0.139378, loss_ce: 0.057509
2022-01-14 11:39:25,368 iteration 292 : loss : 0.124122, loss_ce: 0.050602
2022-01-14 11:39:26,406 iteration 293 : loss : 0.200158, loss_ce: 0.099226
2022-01-14 11:39:27,272 iteration 294 : loss : 0.175720, loss_ce: 0.080336
2022-01-14 11:39:28,144 iteration 295 : loss : 0.195292, loss_ce: 0.076635
2022-01-14 11:39:29,031 iteration 296 : loss : 0.177538, loss_ce: 0.074607
2022-01-14 11:39:29,995 iteration 297 : loss : 0.222692, loss_ce: 0.100377
2022-01-14 11:39:30,862 iteration 298 : loss : 0.176885, loss_ce: 0.073855
2022-01-14 11:39:31,794 iteration 299 : loss : 0.218592, loss_ce: 0.071463
2022-01-14 11:39:32,669 iteration 300 : loss : 0.153734, loss_ce: 0.059765
2022-01-14 11:39:33,570 iteration 301 : loss : 0.202615, loss_ce: 0.075137
2022-01-14 11:39:34,568 iteration 302 : loss : 0.263136, loss_ce: 0.152197
2022-01-14 11:39:35,510 iteration 303 : loss : 0.201550, loss_ce: 0.090808
2022-01-14 11:39:36,401 iteration 304 : loss : 0.136728, loss_ce: 0.057813
2022-01-14 11:39:37,313 iteration 305 : loss : 0.116866, loss_ce: 0.049326
2022-01-14 11:39:38,220 iteration 306 : loss : 0.163456, loss_ce: 0.068180
  4%|█▎                            | 18/400 [05:04<1:44:30, 16.41s/it]2022-01-14 11:39:39,158 iteration 307 : loss : 0.153721, loss_ce: 0.066549
2022-01-14 11:39:40,113 iteration 308 : loss : 0.203368, loss_ce: 0.077294
2022-01-14 11:39:41,032 iteration 309 : loss : 0.196791, loss_ce: 0.092971
2022-01-14 11:39:41,918 iteration 310 : loss : 0.145981, loss_ce: 0.053351
2022-01-14 11:39:42,792 iteration 311 : loss : 0.155922, loss_ce: 0.059949
2022-01-14 11:39:43,715 iteration 312 : loss : 0.179096, loss_ce: 0.052008
2022-01-14 11:39:44,666 iteration 313 : loss : 0.194999, loss_ce: 0.074191
2022-01-14 11:39:45,486 iteration 314 : loss : 0.187724, loss_ce: 0.073318
2022-01-14 11:39:46,370 iteration 315 : loss : 0.139063, loss_ce: 0.060858
2022-01-14 11:39:47,348 iteration 316 : loss : 0.189948, loss_ce: 0.070327
2022-01-14 11:39:48,333 iteration 317 : loss : 0.170568, loss_ce: 0.082412
2022-01-14 11:39:49,232 iteration 318 : loss : 0.195390, loss_ce: 0.103647
2022-01-14 11:39:50,150 iteration 319 : loss : 0.115114, loss_ce: 0.050855
2022-01-14 11:39:51,064 iteration 320 : loss : 0.150606, loss_ce: 0.054283
2022-01-14 11:39:51,938 iteration 321 : loss : 0.181256, loss_ce: 0.071209
2022-01-14 11:39:52,795 iteration 322 : loss : 0.119049, loss_ce: 0.052520
2022-01-14 11:39:53,684 iteration 323 : loss : 0.132310, loss_ce: 0.062463
  5%|█▍                            | 19/400 [05:19<1:42:26, 16.13s/it]2022-01-14 11:39:54,658 iteration 324 : loss : 0.114752, loss_ce: 0.044386
2022-01-14 11:39:55,532 iteration 325 : loss : 0.148614, loss_ce: 0.041323
2022-01-14 11:39:56,407 iteration 326 : loss : 0.249011, loss_ce: 0.106298
2022-01-14 11:39:57,265 iteration 327 : loss : 0.187852, loss_ce: 0.087268
2022-01-14 11:39:58,193 iteration 328 : loss : 0.139644, loss_ce: 0.047347
2022-01-14 11:39:59,164 iteration 329 : loss : 0.185858, loss_ce: 0.077611
2022-01-14 11:40:00,057 iteration 330 : loss : 0.150767, loss_ce: 0.070208
2022-01-14 11:40:00,956 iteration 331 : loss : 0.179014, loss_ce: 0.073923
2022-01-14 11:40:01,779 iteration 332 : loss : 0.110917, loss_ce: 0.048586
2022-01-14 11:40:02,737 iteration 333 : loss : 0.169234, loss_ce: 0.071818
2022-01-14 11:40:03,642 iteration 334 : loss : 0.152840, loss_ce: 0.068482
2022-01-14 11:40:04,606 iteration 335 : loss : 0.155937, loss_ce: 0.081826
2022-01-14 11:40:05,500 iteration 336 : loss : 0.167343, loss_ce: 0.080160
2022-01-14 11:40:06,383 iteration 337 : loss : 0.164426, loss_ce: 0.065594
2022-01-14 11:40:07,290 iteration 338 : loss : 0.131327, loss_ce: 0.057483
2022-01-14 11:40:08,167 iteration 339 : loss : 0.174779, loss_ce: 0.078557
2022-01-14 11:40:08,168 Training Data Eval:
2022-01-14 11:40:12,572   Average segmentation loss on training set: 0.1389
2022-01-14 11:40:12,573 Validation Data Eval:
2022-01-14 11:40:14,063   Average segmentation loss on validation set: 0.1892
2022-01-14 11:40:15,249 Found new lowest validation loss at iteration 339! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_1BLOCK_best_val_loss_seed2.pth
2022-01-14 11:40:16,205 iteration 340 : loss : 0.173690, loss_ce: 0.083549
  5%|█▌                            | 20/400 [05:42<1:54:18, 18.05s/it]2022-01-14 11:40:17,148 iteration 341 : loss : 0.097459, loss_ce: 0.044314
2022-01-14 11:40:18,101 iteration 342 : loss : 0.161051, loss_ce: 0.079868
2022-01-14 11:40:19,043 iteration 343 : loss : 0.156575, loss_ce: 0.071705
2022-01-14 11:40:19,926 iteration 344 : loss : 0.145527, loss_ce: 0.071000
2022-01-14 11:40:20,811 iteration 345 : loss : 0.149669, loss_ce: 0.068319
2022-01-14 11:40:21,754 iteration 346 : loss : 0.114613, loss_ce: 0.048943
2022-01-14 11:40:22,706 iteration 347 : loss : 0.173097, loss_ce: 0.081474
2022-01-14 11:40:23,599 iteration 348 : loss : 0.113479, loss_ce: 0.045878
2022-01-14 11:40:24,497 iteration 349 : loss : 0.145379, loss_ce: 0.058240
2022-01-14 11:40:25,429 iteration 350 : loss : 0.172296, loss_ce: 0.073003
2022-01-14 11:40:26,324 iteration 351 : loss : 0.150771, loss_ce: 0.054822
2022-01-14 11:40:27,319 iteration 352 : loss : 0.165190, loss_ce: 0.088756
2022-01-14 11:40:28,306 iteration 353 : loss : 0.192994, loss_ce: 0.082048
2022-01-14 11:40:29,191 iteration 354 : loss : 0.162268, loss_ce: 0.062971
2022-01-14 11:40:30,129 iteration 355 : loss : 0.154200, loss_ce: 0.052822
2022-01-14 11:40:31,043 iteration 356 : loss : 0.111161, loss_ce: 0.041300
2022-01-14 11:40:31,970 iteration 357 : loss : 0.103469, loss_ce: 0.040506
  5%|█▌                            | 21/400 [05:57<1:49:40, 17.36s/it]2022-01-14 11:40:33,035 iteration 358 : loss : 0.183937, loss_ce: 0.096453
2022-01-14 11:40:34,020 iteration 359 : loss : 0.131629, loss_ce: 0.058174
2022-01-14 11:40:34,903 iteration 360 : loss : 0.104315, loss_ce: 0.038534
2022-01-14 11:40:35,839 iteration 361 : loss : 0.183188, loss_ce: 0.075308
2022-01-14 11:40:36,777 iteration 362 : loss : 0.164222, loss_ce: 0.083469
2022-01-14 11:40:37,624 iteration 363 : loss : 0.133415, loss_ce: 0.061905
2022-01-14 11:40:38,541 iteration 364 : loss : 0.225111, loss_ce: 0.087401
2022-01-14 11:40:39,410 iteration 365 : loss : 0.104430, loss_ce: 0.044466
2022-01-14 11:40:40,302 iteration 366 : loss : 0.136169, loss_ce: 0.042258
2022-01-14 11:40:41,218 iteration 367 : loss : 0.163845, loss_ce: 0.071097
2022-01-14 11:40:42,109 iteration 368 : loss : 0.133084, loss_ce: 0.054305
2022-01-14 11:40:42,981 iteration 369 : loss : 0.126387, loss_ce: 0.051257
2022-01-14 11:40:43,887 iteration 370 : loss : 0.193672, loss_ce: 0.104007
2022-01-14 11:40:44,790 iteration 371 : loss : 0.159705, loss_ce: 0.068081
2022-01-14 11:40:45,699 iteration 372 : loss : 0.121119, loss_ce: 0.048506
2022-01-14 11:40:46,590 iteration 373 : loss : 0.095583, loss_ce: 0.040942
2022-01-14 11:40:47,530 iteration 374 : loss : 0.128658, loss_ce: 0.053916
  6%|█▋                            | 22/400 [06:13<1:45:58, 16.82s/it]2022-01-14 11:40:48,493 iteration 375 : loss : 0.132700, loss_ce: 0.059235
2022-01-14 11:40:49,386 iteration 376 : loss : 0.145718, loss_ce: 0.046747
2022-01-14 11:40:50,297 iteration 377 : loss : 0.100570, loss_ce: 0.039001
2022-01-14 11:40:51,285 iteration 378 : loss : 0.120067, loss_ce: 0.048015
2022-01-14 11:40:52,213 iteration 379 : loss : 0.116950, loss_ce: 0.048378
2022-01-14 11:40:53,091 iteration 380 : loss : 0.154127, loss_ce: 0.080645
2022-01-14 11:40:54,015 iteration 381 : loss : 0.127652, loss_ce: 0.056456
2022-01-14 11:40:54,860 iteration 382 : loss : 0.103932, loss_ce: 0.045731
2022-01-14 11:40:55,782 iteration 383 : loss : 0.159664, loss_ce: 0.044756
2022-01-14 11:40:56,688 iteration 384 : loss : 0.104165, loss_ce: 0.039616
2022-01-14 11:40:57,574 iteration 385 : loss : 0.114872, loss_ce: 0.052222
2022-01-14 11:40:58,488 iteration 386 : loss : 0.135160, loss_ce: 0.046804
2022-01-14 11:40:59,349 iteration 387 : loss : 0.082454, loss_ce: 0.032108
2022-01-14 11:41:00,286 iteration 388 : loss : 0.124674, loss_ce: 0.057453
2022-01-14 11:41:01,182 iteration 389 : loss : 0.139187, loss_ce: 0.057250
2022-01-14 11:41:02,092 iteration 390 : loss : 0.123104, loss_ce: 0.057099
2022-01-14 11:41:03,021 iteration 391 : loss : 0.098139, loss_ce: 0.041040
  6%|█▋                            | 23/400 [06:28<1:43:11, 16.42s/it]2022-01-14 11:41:04,040 iteration 392 : loss : 0.163563, loss_ce: 0.075006
2022-01-14 11:41:04,900 iteration 393 : loss : 0.127959, loss_ce: 0.064350
2022-01-14 11:41:05,811 iteration 394 : loss : 0.147399, loss_ce: 0.057753
2022-01-14 11:41:06,677 iteration 395 : loss : 0.109344, loss_ce: 0.048298
2022-01-14 11:41:07,575 iteration 396 : loss : 0.104950, loss_ce: 0.039989
2022-01-14 11:41:08,558 iteration 397 : loss : 0.119856, loss_ce: 0.051195
2022-01-14 11:41:09,451 iteration 398 : loss : 0.114920, loss_ce: 0.043312
2022-01-14 11:41:10,364 iteration 399 : loss : 0.147142, loss_ce: 0.056675
2022-01-14 11:41:11,244 iteration 400 : loss : 0.094473, loss_ce: 0.036565
2022-01-14 11:41:12,167 iteration 401 : loss : 0.108123, loss_ce: 0.049673
2022-01-14 11:41:13,172 iteration 402 : loss : 0.101790, loss_ce: 0.048853
2022-01-14 11:41:14,124 iteration 403 : loss : 0.104293, loss_ce: 0.039616
2022-01-14 11:41:15,012 iteration 404 : loss : 0.086029, loss_ce: 0.031949
2022-01-14 11:41:15,910 iteration 405 : loss : 0.129872, loss_ce: 0.059892
2022-01-14 11:41:16,860 iteration 406 : loss : 0.132606, loss_ce: 0.054786
2022-01-14 11:41:17,810 iteration 407 : loss : 0.123597, loss_ce: 0.048538
2022-01-14 11:41:18,645 iteration 408 : loss : 0.128307, loss_ce: 0.061990
  6%|█▊                            | 24/400 [06:44<1:41:25, 16.18s/it]2022-01-14 11:41:19,689 iteration 409 : loss : 0.153041, loss_ce: 0.049287
2022-01-14 11:41:20,639 iteration 410 : loss : 0.135154, loss_ce: 0.053626
2022-01-14 11:41:21,586 iteration 411 : loss : 0.188767, loss_ce: 0.065849
2022-01-14 11:41:22,478 iteration 412 : loss : 0.112623, loss_ce: 0.049205
2022-01-14 11:41:23,384 iteration 413 : loss : 0.116361, loss_ce: 0.036670
2022-01-14 11:41:24,250 iteration 414 : loss : 0.091303, loss_ce: 0.035744
2022-01-14 11:41:25,222 iteration 415 : loss : 0.149300, loss_ce: 0.069471
2022-01-14 11:41:26,101 iteration 416 : loss : 0.119093, loss_ce: 0.050384
2022-01-14 11:41:27,036 iteration 417 : loss : 0.101704, loss_ce: 0.037162
2022-01-14 11:41:27,878 iteration 418 : loss : 0.119212, loss_ce: 0.071000
2022-01-14 11:41:28,771 iteration 419 : loss : 0.167673, loss_ce: 0.058466
2022-01-14 11:41:29,677 iteration 420 : loss : 0.089317, loss_ce: 0.039726
2022-01-14 11:41:30,651 iteration 421 : loss : 0.168141, loss_ce: 0.089094
2022-01-14 11:41:31,540 iteration 422 : loss : 0.091714, loss_ce: 0.031007
2022-01-14 11:41:32,459 iteration 423 : loss : 0.126361, loss_ce: 0.046879
2022-01-14 11:41:33,409 iteration 424 : loss : 0.099352, loss_ce: 0.039911
2022-01-14 11:41:33,409 Training Data Eval:
2022-01-14 11:41:37,802   Average segmentation loss on training set: 0.1169
2022-01-14 11:41:37,802 Validation Data Eval:
2022-01-14 11:41:39,297   Average segmentation loss on validation set: 0.1891
2022-01-14 11:41:40,497 Found new lowest validation loss at iteration 424! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_1BLOCK_best_val_loss_seed2.pth
2022-01-14 11:41:41,457 iteration 425 : loss : 0.147977, loss_ce: 0.061261
  6%|█▉                            | 25/400 [07:07<1:53:33, 18.17s/it]2022-01-14 11:41:42,465 iteration 426 : loss : 0.136409, loss_ce: 0.056356
2022-01-14 11:41:43,381 iteration 427 : loss : 0.121742, loss_ce: 0.045324
2022-01-14 11:41:44,335 iteration 428 : loss : 0.114145, loss_ce: 0.048637
2022-01-14 11:41:45,214 iteration 429 : loss : 0.100792, loss_ce: 0.039829
2022-01-14 11:41:46,146 iteration 430 : loss : 0.132487, loss_ce: 0.050178
2022-01-14 11:41:46,997 iteration 431 : loss : 0.142835, loss_ce: 0.061482
2022-01-14 11:41:47,876 iteration 432 : loss : 0.077204, loss_ce: 0.034057
2022-01-14 11:41:48,795 iteration 433 : loss : 0.100816, loss_ce: 0.033189
2022-01-14 11:41:49,686 iteration 434 : loss : 0.125779, loss_ce: 0.052269
2022-01-14 11:41:50,577 iteration 435 : loss : 0.151622, loss_ce: 0.075316
2022-01-14 11:41:51,523 iteration 436 : loss : 0.169220, loss_ce: 0.062110
2022-01-14 11:41:52,433 iteration 437 : loss : 0.108460, loss_ce: 0.045066
2022-01-14 11:41:53,345 iteration 438 : loss : 0.161341, loss_ce: 0.089796
2022-01-14 11:41:54,247 iteration 439 : loss : 0.124929, loss_ce: 0.056576
2022-01-14 11:41:55,113 iteration 440 : loss : 0.083302, loss_ce: 0.034547
2022-01-14 11:41:56,012 iteration 441 : loss : 0.118647, loss_ce: 0.056743
2022-01-14 11:41:56,893 iteration 442 : loss : 0.177484, loss_ce: 0.065620
  6%|█▉                            | 26/400 [07:22<1:48:08, 17.35s/it]2022-01-14 11:41:57,867 iteration 443 : loss : 0.102342, loss_ce: 0.054240
2022-01-14 11:41:58,768 iteration 444 : loss : 0.140763, loss_ce: 0.057426
2022-01-14 11:41:59,855 iteration 445 : loss : 0.145967, loss_ce: 0.064485
2022-01-14 11:42:00,711 iteration 446 : loss : 0.167694, loss_ce: 0.059216
2022-01-14 11:42:01,696 iteration 447 : loss : 0.126861, loss_ce: 0.059115
2022-01-14 11:42:02,643 iteration 448 : loss : 0.084515, loss_ce: 0.037254
2022-01-14 11:42:03,542 iteration 449 : loss : 0.105896, loss_ce: 0.041832
2022-01-14 11:42:04,379 iteration 450 : loss : 0.119925, loss_ce: 0.050002
2022-01-14 11:42:05,286 iteration 451 : loss : 0.107854, loss_ce: 0.039486
2022-01-14 11:42:06,212 iteration 452 : loss : 0.089759, loss_ce: 0.037929
2022-01-14 11:42:07,127 iteration 453 : loss : 0.087064, loss_ce: 0.031227
2022-01-14 11:42:08,078 iteration 454 : loss : 0.148953, loss_ce: 0.049970
2022-01-14 11:42:09,059 iteration 455 : loss : 0.099219, loss_ce: 0.030814
2022-01-14 11:42:09,941 iteration 456 : loss : 0.152812, loss_ce: 0.051457
2022-01-14 11:42:10,824 iteration 457 : loss : 0.111784, loss_ce: 0.042799
2022-01-14 11:42:11,726 iteration 458 : loss : 0.122969, loss_ce: 0.050258
2022-01-14 11:42:12,643 iteration 459 : loss : 0.100183, loss_ce: 0.036604
  7%|██                            | 27/400 [07:38<1:44:53, 16.87s/it]2022-01-14 11:42:13,537 iteration 460 : loss : 0.120111, loss_ce: 0.041580
2022-01-14 11:42:14,469 iteration 461 : loss : 0.105753, loss_ce: 0.045579
2022-01-14 11:42:15,382 iteration 462 : loss : 0.118192, loss_ce: 0.034879
2022-01-14 11:42:16,207 iteration 463 : loss : 0.090912, loss_ce: 0.042249
2022-01-14 11:42:17,177 iteration 464 : loss : 0.097166, loss_ce: 0.040263
2022-01-14 11:42:18,068 iteration 465 : loss : 0.098379, loss_ce: 0.049011
2022-01-14 11:42:19,020 iteration 466 : loss : 0.087922, loss_ce: 0.038380
2022-01-14 11:42:19,898 iteration 467 : loss : 0.101451, loss_ce: 0.033396
2022-01-14 11:42:20,791 iteration 468 : loss : 0.086967, loss_ce: 0.031366
2022-01-14 11:42:21,656 iteration 469 : loss : 0.111710, loss_ce: 0.041362
2022-01-14 11:42:22,634 iteration 470 : loss : 0.103434, loss_ce: 0.046471
2022-01-14 11:42:23,500 iteration 471 : loss : 0.088470, loss_ce: 0.038185
2022-01-14 11:42:24,466 iteration 472 : loss : 0.119800, loss_ce: 0.045481
2022-01-14 11:42:25,414 iteration 473 : loss : 0.084293, loss_ce: 0.036810
2022-01-14 11:42:26,379 iteration 474 : loss : 0.095518, loss_ce: 0.038916
2022-01-14 11:42:27,302 iteration 475 : loss : 0.101499, loss_ce: 0.033612
2022-01-14 11:42:28,244 iteration 476 : loss : 0.090808, loss_ce: 0.041576
  7%|██                            | 28/400 [07:54<1:42:13, 16.49s/it]2022-01-14 11:42:29,202 iteration 477 : loss : 0.105799, loss_ce: 0.041087
2022-01-14 11:42:30,155 iteration 478 : loss : 0.120559, loss_ce: 0.045648
2022-01-14 11:42:31,010 iteration 479 : loss : 0.105841, loss_ce: 0.042891
2022-01-14 11:42:31,836 iteration 480 : loss : 0.103257, loss_ce: 0.043963
2022-01-14 11:42:32,758 iteration 481 : loss : 0.099501, loss_ce: 0.045408
2022-01-14 11:42:33,764 iteration 482 : loss : 0.088049, loss_ce: 0.034544
2022-01-14 11:42:34,736 iteration 483 : loss : 0.083074, loss_ce: 0.024514
2022-01-14 11:42:35,680 iteration 484 : loss : 0.081566, loss_ce: 0.030589
2022-01-14 11:42:36,556 iteration 485 : loss : 0.071434, loss_ce: 0.028741
2022-01-14 11:42:37,493 iteration 486 : loss : 0.236476, loss_ce: 0.083530
2022-01-14 11:42:38,480 iteration 487 : loss : 0.131732, loss_ce: 0.066500
2022-01-14 11:42:39,545 iteration 488 : loss : 0.113760, loss_ce: 0.045524
2022-01-14 11:42:40,542 iteration 489 : loss : 0.070584, loss_ce: 0.032340
2022-01-14 11:42:41,445 iteration 490 : loss : 0.091030, loss_ce: 0.037685
2022-01-14 11:42:42,455 iteration 491 : loss : 0.136167, loss_ce: 0.061390
2022-01-14 11:42:43,347 iteration 492 : loss : 0.110940, loss_ce: 0.047956
2022-01-14 11:42:44,273 iteration 493 : loss : 0.158467, loss_ce: 0.083596
  7%|██▏                           | 29/400 [08:10<1:41:06, 16.35s/it]2022-01-14 11:42:45,246 iteration 494 : loss : 0.114223, loss_ce: 0.047668
2022-01-14 11:42:46,183 iteration 495 : loss : 0.084823, loss_ce: 0.036636
2022-01-14 11:42:47,029 iteration 496 : loss : 0.099969, loss_ce: 0.044008
2022-01-14 11:42:48,029 iteration 497 : loss : 0.107549, loss_ce: 0.039178
2022-01-14 11:42:48,956 iteration 498 : loss : 0.121455, loss_ce: 0.048012
2022-01-14 11:42:49,978 iteration 499 : loss : 0.130994, loss_ce: 0.065528
2022-01-14 11:42:50,820 iteration 500 : loss : 0.096988, loss_ce: 0.039235
2022-01-14 11:42:51,759 iteration 501 : loss : 0.105790, loss_ce: 0.034297
2022-01-14 11:42:52,660 iteration 502 : loss : 0.111262, loss_ce: 0.037621
2022-01-14 11:42:53,601 iteration 503 : loss : 0.135507, loss_ce: 0.062367
2022-01-14 11:42:54,618 iteration 504 : loss : 0.071022, loss_ce: 0.027868
2022-01-14 11:42:55,640 iteration 505 : loss : 0.081744, loss_ce: 0.033879
2022-01-14 11:42:56,607 iteration 506 : loss : 0.121761, loss_ce: 0.058634
2022-01-14 11:42:57,534 iteration 507 : loss : 0.090871, loss_ce: 0.030513
2022-01-14 11:42:58,505 iteration 508 : loss : 0.100263, loss_ce: 0.032510
2022-01-14 11:42:59,502 iteration 509 : loss : 0.101401, loss_ce: 0.051402
2022-01-14 11:42:59,502 Training Data Eval:
2022-01-14 11:43:03,825   Average segmentation loss on training set: 0.0861
2022-01-14 11:43:03,826 Validation Data Eval:
2022-01-14 11:43:05,289   Average segmentation loss on validation set: 0.1119
2022-01-14 11:43:06,777 Found new lowest validation loss at iteration 509! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_1BLOCK_best_val_loss_seed2.pth
2022-01-14 11:43:07,676 iteration 510 : loss : 0.091374, loss_ce: 0.042384
  8%|██▎                           | 30/400 [08:33<1:53:54, 18.47s/it]2022-01-14 11:43:08,630 iteration 511 : loss : 0.089130, loss_ce: 0.031722
2022-01-14 11:43:09,549 iteration 512 : loss : 0.108568, loss_ce: 0.047596
2022-01-14 11:43:10,477 iteration 513 : loss : 0.104300, loss_ce: 0.045500
2022-01-14 11:43:11,437 iteration 514 : loss : 0.102008, loss_ce: 0.043151
2022-01-14 11:43:12,294 iteration 515 : loss : 0.076309, loss_ce: 0.034631
2022-01-14 11:43:13,109 iteration 516 : loss : 0.078117, loss_ce: 0.028309
2022-01-14 11:43:14,116 iteration 517 : loss : 0.083519, loss_ce: 0.040055
2022-01-14 11:43:15,138 iteration 518 : loss : 0.162668, loss_ce: 0.065146
2022-01-14 11:43:16,164 iteration 519 : loss : 0.102364, loss_ce: 0.045746
2022-01-14 11:43:17,103 iteration 520 : loss : 0.084401, loss_ce: 0.035118
2022-01-14 11:43:17,969 iteration 521 : loss : 0.068465, loss_ce: 0.027907
2022-01-14 11:43:18,956 iteration 522 : loss : 0.106717, loss_ce: 0.038984
2022-01-14 11:43:19,885 iteration 523 : loss : 0.084517, loss_ce: 0.028821
2022-01-14 11:43:20,799 iteration 524 : loss : 0.083533, loss_ce: 0.040556
2022-01-14 11:43:21,710 iteration 525 : loss : 0.073489, loss_ce: 0.030266
2022-01-14 11:43:22,685 iteration 526 : loss : 0.100377, loss_ce: 0.038959
2022-01-14 11:43:23,650 iteration 527 : loss : 0.116995, loss_ce: 0.045225
  8%|██▎                           | 31/400 [08:49<1:48:58, 17.72s/it]2022-01-14 11:43:24,624 iteration 528 : loss : 0.088508, loss_ce: 0.041807
2022-01-14 11:43:25,692 iteration 529 : loss : 0.107962, loss_ce: 0.037261
2022-01-14 11:43:26,596 iteration 530 : loss : 0.077200, loss_ce: 0.030562
2022-01-14 11:43:27,484 iteration 531 : loss : 0.080306, loss_ce: 0.032638
2022-01-14 11:43:28,435 iteration 532 : loss : 0.070276, loss_ce: 0.030411
2022-01-14 11:43:29,376 iteration 533 : loss : 0.084578, loss_ce: 0.034571
2022-01-14 11:43:30,290 iteration 534 : loss : 0.069262, loss_ce: 0.029419
2022-01-14 11:43:31,267 iteration 535 : loss : 0.083070, loss_ce: 0.030660
2022-01-14 11:43:32,200 iteration 536 : loss : 0.111762, loss_ce: 0.059237
2022-01-14 11:43:33,110 iteration 537 : loss : 0.093183, loss_ce: 0.038551
2022-01-14 11:43:34,045 iteration 538 : loss : 0.131493, loss_ce: 0.070069
2022-01-14 11:43:34,898 iteration 539 : loss : 0.087747, loss_ce: 0.032735
2022-01-14 11:43:35,975 iteration 540 : loss : 0.125771, loss_ce: 0.068249
2022-01-14 11:43:37,021 iteration 541 : loss : 0.134036, loss_ce: 0.059545
2022-01-14 11:43:37,892 iteration 542 : loss : 0.108319, loss_ce: 0.043472
2022-01-14 11:43:38,826 iteration 543 : loss : 0.078659, loss_ce: 0.032820
2022-01-14 11:43:39,811 iteration 544 : loss : 0.156523, loss_ce: 0.051822
  8%|██▍                           | 32/400 [09:05<1:45:49, 17.25s/it]2022-01-14 11:43:40,882 iteration 545 : loss : 0.127100, loss_ce: 0.057186
2022-01-14 11:43:41,895 iteration 546 : loss : 0.068187, loss_ce: 0.027699
2022-01-14 11:43:42,885 iteration 547 : loss : 0.104174, loss_ce: 0.044876
2022-01-14 11:43:43,749 iteration 548 : loss : 0.142904, loss_ce: 0.053893
2022-01-14 11:43:44,630 iteration 549 : loss : 0.133500, loss_ce: 0.049069
2022-01-14 11:43:45,519 iteration 550 : loss : 0.083823, loss_ce: 0.033182
2022-01-14 11:43:46,403 iteration 551 : loss : 0.080073, loss_ce: 0.023697
2022-01-14 11:43:47,376 iteration 552 : loss : 0.149829, loss_ce: 0.067885
2022-01-14 11:43:48,341 iteration 553 : loss : 0.089538, loss_ce: 0.033494
2022-01-14 11:43:49,298 iteration 554 : loss : 0.121147, loss_ce: 0.041932
2022-01-14 11:43:50,279 iteration 555 : loss : 0.075627, loss_ce: 0.022607
2022-01-14 11:43:51,299 iteration 556 : loss : 0.106771, loss_ce: 0.054007
2022-01-14 11:43:52,187 iteration 557 : loss : 0.126180, loss_ce: 0.062325
2022-01-14 11:43:53,049 iteration 558 : loss : 0.101319, loss_ce: 0.039465
2022-01-14 11:43:53,952 iteration 559 : loss : 0.100081, loss_ce: 0.043988
2022-01-14 11:43:54,960 iteration 560 : loss : 0.077204, loss_ce: 0.035331
2022-01-14 11:43:55,945 iteration 561 : loss : 0.061826, loss_ce: 0.028549
  8%|██▍                           | 33/400 [09:21<1:43:28, 16.92s/it]2022-01-14 11:43:56,978 iteration 562 : loss : 0.114545, loss_ce: 0.036124
2022-01-14 11:43:57,855 iteration 563 : loss : 0.067507, loss_ce: 0.033939
2022-01-14 11:43:58,729 iteration 564 : loss : 0.111414, loss_ce: 0.053814
2022-01-14 11:43:59,697 iteration 565 : loss : 0.104784, loss_ce: 0.052852
2022-01-14 11:44:00,649 iteration 566 : loss : 0.130219, loss_ce: 0.044866
2022-01-14 11:44:01,608 iteration 567 : loss : 0.127464, loss_ce: 0.054421
2022-01-14 11:44:02,556 iteration 568 : loss : 0.139008, loss_ce: 0.036895
2022-01-14 11:44:03,585 iteration 569 : loss : 0.136030, loss_ce: 0.040434
2022-01-14 11:44:04,522 iteration 570 : loss : 0.094293, loss_ce: 0.040681
2022-01-14 11:44:05,506 iteration 571 : loss : 0.094615, loss_ce: 0.040186
2022-01-14 11:44:06,512 iteration 572 : loss : 0.116811, loss_ce: 0.054371
2022-01-14 11:44:07,410 iteration 573 : loss : 0.111098, loss_ce: 0.051092
2022-01-14 11:44:08,437 iteration 574 : loss : 0.087799, loss_ce: 0.036239
2022-01-14 11:44:09,363 iteration 575 : loss : 0.137831, loss_ce: 0.043911
2022-01-14 11:44:10,231 iteration 576 : loss : 0.104289, loss_ce: 0.053274
2022-01-14 11:44:11,308 iteration 577 : loss : 0.112119, loss_ce: 0.052857
2022-01-14 11:44:12,289 iteration 578 : loss : 0.092110, loss_ce: 0.042952
  8%|██▌                           | 34/400 [09:38<1:42:07, 16.74s/it]2022-01-14 11:44:13,207 iteration 579 : loss : 0.091992, loss_ce: 0.046684
2022-01-14 11:44:14,197 iteration 580 : loss : 0.108100, loss_ce: 0.043665
2022-01-14 11:44:15,283 iteration 581 : loss : 0.080542, loss_ce: 0.037692
2022-01-14 11:44:16,161 iteration 582 : loss : 0.074529, loss_ce: 0.032240
2022-01-14 11:44:17,117 iteration 583 : loss : 0.101306, loss_ce: 0.049567
2022-01-14 11:44:18,097 iteration 584 : loss : 0.085344, loss_ce: 0.034790
2022-01-14 11:44:18,993 iteration 585 : loss : 0.075395, loss_ce: 0.026276
2022-01-14 11:44:19,958 iteration 586 : loss : 0.137706, loss_ce: 0.059564
2022-01-14 11:44:20,909 iteration 587 : loss : 0.063480, loss_ce: 0.030535
2022-01-14 11:44:21,797 iteration 588 : loss : 0.088754, loss_ce: 0.032538
2022-01-14 11:44:22,795 iteration 589 : loss : 0.124355, loss_ce: 0.055050
2022-01-14 11:44:23,711 iteration 590 : loss : 0.073605, loss_ce: 0.030166
2022-01-14 11:44:24,619 iteration 591 : loss : 0.103157, loss_ce: 0.036918
2022-01-14 11:44:25,596 iteration 592 : loss : 0.088546, loss_ce: 0.040391
2022-01-14 11:44:26,469 iteration 593 : loss : 0.120261, loss_ce: 0.047474
2022-01-14 11:44:27,452 iteration 594 : loss : 0.107917, loss_ce: 0.036635
2022-01-14 11:44:27,452 Training Data Eval:
2022-01-14 11:44:31,767   Average segmentation loss on training set: 0.0876
2022-01-14 11:44:31,767 Validation Data Eval:
2022-01-14 11:44:33,220   Average segmentation loss on validation set: 0.1079
2022-01-14 11:44:34,429 Found new lowest validation loss at iteration 594! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_1BLOCK_best_val_loss_seed2.pth
2022-01-14 11:44:35,378 iteration 595 : loss : 0.122694, loss_ce: 0.044481
  9%|██▋                           | 35/400 [10:01<1:53:25, 18.65s/it]2022-01-14 11:44:36,460 iteration 596 : loss : 0.129170, loss_ce: 0.051856
2022-01-14 11:44:37,392 iteration 597 : loss : 0.073488, loss_ce: 0.033596
2022-01-14 11:44:38,330 iteration 598 : loss : 0.079972, loss_ce: 0.033486
2022-01-14 11:44:39,307 iteration 599 : loss : 0.122542, loss_ce: 0.044704
2022-01-14 11:44:40,289 iteration 600 : loss : 0.074654, loss_ce: 0.026195
2022-01-14 11:44:41,262 iteration 601 : loss : 0.085911, loss_ce: 0.033079
2022-01-14 11:44:42,104 iteration 602 : loss : 0.086708, loss_ce: 0.036657
2022-01-14 11:44:43,039 iteration 603 : loss : 0.094402, loss_ce: 0.038163
2022-01-14 11:44:43,931 iteration 604 : loss : 0.131778, loss_ce: 0.042310
2022-01-14 11:44:44,988 iteration 605 : loss : 0.099398, loss_ce: 0.039335
2022-01-14 11:44:45,866 iteration 606 : loss : 0.085766, loss_ce: 0.038584
2022-01-14 11:44:46,748 iteration 607 : loss : 0.068868, loss_ce: 0.026752
2022-01-14 11:44:47,624 iteration 608 : loss : 0.056414, loss_ce: 0.026343
2022-01-14 11:44:48,504 iteration 609 : loss : 0.092745, loss_ce: 0.034406
2022-01-14 11:44:49,545 iteration 610 : loss : 0.135190, loss_ce: 0.073318
2022-01-14 11:44:50,460 iteration 611 : loss : 0.089092, loss_ce: 0.039370
2022-01-14 11:44:51,325 iteration 612 : loss : 0.062332, loss_ce: 0.025731
  9%|██▋                           | 36/400 [10:17<1:48:12, 17.84s/it]2022-01-14 11:44:52,313 iteration 613 : loss : 0.068820, loss_ce: 0.022083
2022-01-14 11:44:53,313 iteration 614 : loss : 0.066811, loss_ce: 0.027697
2022-01-14 11:44:54,263 iteration 615 : loss : 0.074971, loss_ce: 0.034247
2022-01-14 11:44:55,165 iteration 616 : loss : 0.082950, loss_ce: 0.028406
2022-01-14 11:44:56,141 iteration 617 : loss : 0.110636, loss_ce: 0.039225
2022-01-14 11:44:57,163 iteration 618 : loss : 0.071416, loss_ce: 0.034000
2022-01-14 11:44:58,125 iteration 619 : loss : 0.072630, loss_ce: 0.025772
2022-01-14 11:44:59,135 iteration 620 : loss : 0.085443, loss_ce: 0.038895
2022-01-14 11:44:59,979 iteration 621 : loss : 0.067552, loss_ce: 0.026785
2022-01-14 11:45:00,993 iteration 622 : loss : 0.085271, loss_ce: 0.034753
2022-01-14 11:45:02,009 iteration 623 : loss : 0.097221, loss_ce: 0.046379
2022-01-14 11:45:02,866 iteration 624 : loss : 0.077171, loss_ce: 0.031857
2022-01-14 11:45:03,942 iteration 625 : loss : 0.085671, loss_ce: 0.034101
2022-01-14 11:45:04,866 iteration 626 : loss : 0.070160, loss_ce: 0.026651
2022-01-14 11:45:05,731 iteration 627 : loss : 0.106755, loss_ce: 0.036035
2022-01-14 11:45:06,558 iteration 628 : loss : 0.129263, loss_ce: 0.049336
2022-01-14 11:45:07,513 iteration 629 : loss : 0.068197, loss_ce: 0.029474
  9%|██▊                           | 37/400 [10:33<1:44:55, 17.34s/it]2022-01-14 11:45:08,393 iteration 630 : loss : 0.069516, loss_ce: 0.030884
2022-01-14 11:45:09,310 iteration 631 : loss : 0.094247, loss_ce: 0.037185
2022-01-14 11:45:10,172 iteration 632 : loss : 0.068089, loss_ce: 0.026085
2022-01-14 11:45:11,131 iteration 633 : loss : 0.095741, loss_ce: 0.048248
2022-01-14 11:45:12,077 iteration 634 : loss : 0.059350, loss_ce: 0.027435
2022-01-14 11:45:13,047 iteration 635 : loss : 0.105338, loss_ce: 0.049408
2022-01-14 11:45:13,951 iteration 636 : loss : 0.151972, loss_ce: 0.045787
2022-01-14 11:45:14,843 iteration 637 : loss : 0.081956, loss_ce: 0.036619
2022-01-14 11:45:15,735 iteration 638 : loss : 0.061107, loss_ce: 0.028758
2022-01-14 11:45:16,715 iteration 639 : loss : 0.082098, loss_ce: 0.046289
2022-01-14 11:45:17,694 iteration 640 : loss : 0.080043, loss_ce: 0.027565
2022-01-14 11:45:18,573 iteration 641 : loss : 0.063544, loss_ce: 0.024453
2022-01-14 11:45:19,518 iteration 642 : loss : 0.066452, loss_ce: 0.025764
2022-01-14 11:45:20,421 iteration 643 : loss : 0.088652, loss_ce: 0.031541
2022-01-14 11:45:21,346 iteration 644 : loss : 0.066375, loss_ce: 0.023167
2022-01-14 11:45:22,242 iteration 645 : loss : 0.104003, loss_ce: 0.044841
2022-01-14 11:45:23,214 iteration 646 : loss : 0.072879, loss_ce: 0.029908
 10%|██▊                           | 38/400 [10:49<1:41:40, 16.85s/it]2022-01-14 11:45:24,184 iteration 647 : loss : 0.068652, loss_ce: 0.026258
2022-01-14 11:45:25,172 iteration 648 : loss : 0.094318, loss_ce: 0.041744
2022-01-14 11:45:26,136 iteration 649 : loss : 0.083861, loss_ce: 0.034867
2022-01-14 11:45:26,993 iteration 650 : loss : 0.067647, loss_ce: 0.034197
2022-01-14 11:45:27,929 iteration 651 : loss : 0.103203, loss_ce: 0.041703
2022-01-14 11:45:28,790 iteration 652 : loss : 0.098267, loss_ce: 0.030493
2022-01-14 11:45:29,726 iteration 653 : loss : 0.100452, loss_ce: 0.034643
2022-01-14 11:45:30,722 iteration 654 : loss : 0.090999, loss_ce: 0.027665
2022-01-14 11:45:31,683 iteration 655 : loss : 0.053982, loss_ce: 0.021227
2022-01-14 11:45:32,546 iteration 656 : loss : 0.054261, loss_ce: 0.023679
2022-01-14 11:45:33,483 iteration 657 : loss : 0.064250, loss_ce: 0.028126
2022-01-14 11:45:34,459 iteration 658 : loss : 0.118850, loss_ce: 0.042016
2022-01-14 11:45:35,457 iteration 659 : loss : 0.080555, loss_ce: 0.036197
2022-01-14 11:45:36,413 iteration 660 : loss : 0.088772, loss_ce: 0.032161
2022-01-14 11:45:37,359 iteration 661 : loss : 0.076187, loss_ce: 0.037813
2022-01-14 11:45:38,249 iteration 662 : loss : 0.062535, loss_ce: 0.030022
2022-01-14 11:45:39,182 iteration 663 : loss : 0.071187, loss_ce: 0.021953
 10%|██▉                           | 39/400 [11:05<1:39:47, 16.59s/it]2022-01-14 11:45:40,136 iteration 664 : loss : 0.096982, loss_ce: 0.057739
2022-01-14 11:45:41,050 iteration 665 : loss : 0.099164, loss_ce: 0.047169
2022-01-14 11:45:42,001 iteration 666 : loss : 0.100898, loss_ce: 0.043390
2022-01-14 11:45:42,883 iteration 667 : loss : 0.057713, loss_ce: 0.024619
2022-01-14 11:45:43,880 iteration 668 : loss : 0.093069, loss_ce: 0.038320
2022-01-14 11:45:44,763 iteration 669 : loss : 0.088489, loss_ce: 0.038647
2022-01-14 11:45:45,650 iteration 670 : loss : 0.085962, loss_ce: 0.038794
2022-01-14 11:45:46,625 iteration 671 : loss : 0.091387, loss_ce: 0.030046
2022-01-14 11:45:47,599 iteration 672 : loss : 0.083664, loss_ce: 0.034733
2022-01-14 11:45:48,480 iteration 673 : loss : 0.074203, loss_ce: 0.033860
2022-01-14 11:45:49,433 iteration 674 : loss : 0.094944, loss_ce: 0.037097
2022-01-14 11:45:50,409 iteration 675 : loss : 0.092087, loss_ce: 0.035126
2022-01-14 11:45:51,310 iteration 676 : loss : 0.096911, loss_ce: 0.032765
2022-01-14 11:45:52,253 iteration 677 : loss : 0.085289, loss_ce: 0.039534
2022-01-14 11:45:53,180 iteration 678 : loss : 0.078325, loss_ce: 0.031645
2022-01-14 11:45:54,058 iteration 679 : loss : 0.106562, loss_ce: 0.060383
2022-01-14 11:45:54,059 Training Data Eval:
2022-01-14 11:45:58,331   Average segmentation loss on training set: 0.1693
2022-01-14 11:45:58,331 Validation Data Eval:
2022-01-14 11:45:59,778   Average segmentation loss on validation set: 0.3152
2022-01-14 11:46:00,728 iteration 680 : loss : 0.125330, loss_ce: 0.027599
 10%|███                           | 40/400 [11:26<1:48:26, 18.07s/it]2022-01-14 11:46:01,779 iteration 681 : loss : 0.096505, loss_ce: 0.044022
2022-01-14 11:46:02,664 iteration 682 : loss : 0.056674, loss_ce: 0.020055
2022-01-14 11:46:03,610 iteration 683 : loss : 0.079571, loss_ce: 0.035304
2022-01-14 11:46:04,568 iteration 684 : loss : 0.101992, loss_ce: 0.039882
2022-01-14 11:46:05,562 iteration 685 : loss : 0.083581, loss_ce: 0.035528
2022-01-14 11:46:06,389 iteration 686 : loss : 0.092413, loss_ce: 0.028105
2022-01-14 11:46:07,269 iteration 687 : loss : 0.068932, loss_ce: 0.024213
2022-01-14 11:46:08,263 iteration 688 : loss : 0.085112, loss_ce: 0.035835
2022-01-14 11:46:09,198 iteration 689 : loss : 0.072006, loss_ce: 0.029543
2022-01-14 11:46:10,061 iteration 690 : loss : 0.100207, loss_ce: 0.051430
2022-01-14 11:46:11,084 iteration 691 : loss : 0.085772, loss_ce: 0.040073
2022-01-14 11:46:12,075 iteration 692 : loss : 0.102898, loss_ce: 0.037494
2022-01-14 11:46:13,050 iteration 693 : loss : 0.093546, loss_ce: 0.043861
2022-01-14 11:46:13,989 iteration 694 : loss : 0.091266, loss_ce: 0.037986
2022-01-14 11:46:14,932 iteration 695 : loss : 0.093537, loss_ce: 0.033071
2022-01-14 11:46:15,852 iteration 696 : loss : 0.077934, loss_ce: 0.034177
2022-01-14 11:46:16,799 iteration 697 : loss : 0.126863, loss_ce: 0.044237
 10%|███                           | 41/400 [11:42<1:44:32, 17.47s/it]2022-01-14 11:46:17,762 iteration 698 : loss : 0.080545, loss_ce: 0.032416
2022-01-14 11:46:18,684 iteration 699 : loss : 0.068538, loss_ce: 0.025520
2022-01-14 11:46:19,627 iteration 700 : loss : 0.076151, loss_ce: 0.030187
2022-01-14 11:46:20,536 iteration 701 : loss : 0.107774, loss_ce: 0.045408
2022-01-14 11:46:21,499 iteration 702 : loss : 0.087818, loss_ce: 0.029809
2022-01-14 11:46:22,422 iteration 703 : loss : 0.065602, loss_ce: 0.026242
2022-01-14 11:46:23,334 iteration 704 : loss : 0.104882, loss_ce: 0.032209
2022-01-14 11:46:24,222 iteration 705 : loss : 0.110638, loss_ce: 0.053455
2022-01-14 11:46:25,200 iteration 706 : loss : 0.082101, loss_ce: 0.036237
2022-01-14 11:46:26,168 iteration 707 : loss : 0.103158, loss_ce: 0.050910
2022-01-14 11:46:27,126 iteration 708 : loss : 0.093358, loss_ce: 0.034756
2022-01-14 11:46:28,099 iteration 709 : loss : 0.074577, loss_ce: 0.031103
2022-01-14 11:46:29,050 iteration 710 : loss : 0.089957, loss_ce: 0.030956
2022-01-14 11:46:30,045 iteration 711 : loss : 0.134281, loss_ce: 0.041577
2022-01-14 11:46:31,046 iteration 712 : loss : 0.078910, loss_ce: 0.037544
2022-01-14 11:46:31,936 iteration 713 : loss : 0.089162, loss_ce: 0.041902
2022-01-14 11:46:32,856 iteration 714 : loss : 0.064539, loss_ce: 0.031379
 10%|███▏                          | 42/400 [11:58<1:41:44, 17.05s/it]2022-01-14 11:46:33,840 iteration 715 : loss : 0.059660, loss_ce: 0.027911
2022-01-14 11:46:34,756 iteration 716 : loss : 0.133279, loss_ce: 0.042253
2022-01-14 11:46:35,658 iteration 717 : loss : 0.078406, loss_ce: 0.030135
2022-01-14 11:46:36,487 iteration 718 : loss : 0.067543, loss_ce: 0.025143
2022-01-14 11:46:37,412 iteration 719 : loss : 0.080267, loss_ce: 0.040921
2022-01-14 11:46:38,245 iteration 720 : loss : 0.073770, loss_ce: 0.032458
2022-01-14 11:46:39,316 iteration 721 : loss : 0.115011, loss_ce: 0.043761
2022-01-14 11:46:40,248 iteration 722 : loss : 0.070053, loss_ce: 0.033985
2022-01-14 11:46:41,190 iteration 723 : loss : 0.098297, loss_ce: 0.037662
2022-01-14 11:46:42,196 iteration 724 : loss : 0.076955, loss_ce: 0.030222
2022-01-14 11:46:43,073 iteration 725 : loss : 0.066702, loss_ce: 0.028970
2022-01-14 11:46:44,006 iteration 726 : loss : 0.110667, loss_ce: 0.063943
2022-01-14 11:46:44,900 iteration 727 : loss : 0.048356, loss_ce: 0.018351
2022-01-14 11:46:45,796 iteration 728 : loss : 0.086556, loss_ce: 0.024735
2022-01-14 11:46:46,704 iteration 729 : loss : 0.122400, loss_ce: 0.054817
2022-01-14 11:46:47,647 iteration 730 : loss : 0.062281, loss_ce: 0.025205
2022-01-14 11:46:48,539 iteration 731 : loss : 0.096269, loss_ce: 0.033760
 11%|███▏                          | 43/400 [12:14<1:39:00, 16.64s/it]2022-01-14 11:46:49,563 iteration 732 : loss : 0.074189, loss_ce: 0.029688
2022-01-14 11:46:50,519 iteration 733 : loss : 0.073865, loss_ce: 0.030659
2022-01-14 11:46:51,475 iteration 734 : loss : 0.129065, loss_ce: 0.064883
2022-01-14 11:46:52,443 iteration 735 : loss : 0.104346, loss_ce: 0.036129
2022-01-14 11:46:53,406 iteration 736 : loss : 0.057919, loss_ce: 0.023623
2022-01-14 11:46:54,328 iteration 737 : loss : 0.081644, loss_ce: 0.037908
2022-01-14 11:46:55,330 iteration 738 : loss : 0.083602, loss_ce: 0.037475
2022-01-14 11:46:56,282 iteration 739 : loss : 0.090911, loss_ce: 0.046069
2022-01-14 11:46:57,204 iteration 740 : loss : 0.059077, loss_ce: 0.025489
2022-01-14 11:46:58,144 iteration 741 : loss : 0.076877, loss_ce: 0.035751
2022-01-14 11:46:59,106 iteration 742 : loss : 0.055513, loss_ce: 0.021847
2022-01-14 11:47:00,015 iteration 743 : loss : 0.056042, loss_ce: 0.021829
2022-01-14 11:47:00,957 iteration 744 : loss : 0.079427, loss_ce: 0.033578
2022-01-14 11:47:01,880 iteration 745 : loss : 0.083581, loss_ce: 0.029101
2022-01-14 11:47:02,780 iteration 746 : loss : 0.140377, loss_ce: 0.041645
2022-01-14 11:47:03,689 iteration 747 : loss : 0.092592, loss_ce: 0.042285
2022-01-14 11:47:04,636 iteration 748 : loss : 0.092136, loss_ce: 0.035738
 11%|███▎                          | 44/400 [12:30<1:37:43, 16.47s/it]2022-01-14 11:47:05,582 iteration 749 : loss : 0.104681, loss_ce: 0.040356
2022-01-14 11:47:06,484 iteration 750 : loss : 0.042213, loss_ce: 0.013719
2022-01-14 11:47:07,449 iteration 751 : loss : 0.095429, loss_ce: 0.044827
2022-01-14 11:47:08,351 iteration 752 : loss : 0.099365, loss_ce: 0.046212
2022-01-14 11:47:09,326 iteration 753 : loss : 0.075704, loss_ce: 0.030836
2022-01-14 11:47:10,257 iteration 754 : loss : 0.064926, loss_ce: 0.022412
2022-01-14 11:47:11,214 iteration 755 : loss : 0.056968, loss_ce: 0.025995
2022-01-14 11:47:12,057 iteration 756 : loss : 0.072321, loss_ce: 0.030766
2022-01-14 11:47:12,915 iteration 757 : loss : 0.062218, loss_ce: 0.024887
2022-01-14 11:47:13,842 iteration 758 : loss : 0.094613, loss_ce: 0.037789
2022-01-14 11:47:14,818 iteration 759 : loss : 0.087535, loss_ce: 0.033562
2022-01-14 11:47:15,754 iteration 760 : loss : 0.062118, loss_ce: 0.020485
2022-01-14 11:47:16,737 iteration 761 : loss : 0.089194, loss_ce: 0.032286
2022-01-14 11:47:17,578 iteration 762 : loss : 0.069883, loss_ce: 0.030345
2022-01-14 11:47:18,496 iteration 763 : loss : 0.067677, loss_ce: 0.032048
2022-01-14 11:47:19,339 iteration 764 : loss : 0.075406, loss_ce: 0.026554
2022-01-14 11:47:19,339 Training Data Eval:
2022-01-14 11:47:23,620   Average segmentation loss on training set: 0.0658
2022-01-14 11:47:23,621 Validation Data Eval:
2022-01-14 11:47:25,079   Average segmentation loss on validation set: 0.1372
2022-01-14 11:47:25,913 iteration 765 : loss : 0.054146, loss_ce: 0.022801
 11%|███▍                          | 45/400 [12:51<1:45:59, 17.91s/it]2022-01-14 11:47:26,976 iteration 766 : loss : 0.068460, loss_ce: 0.026138
2022-01-14 11:47:28,060 iteration 767 : loss : 0.107517, loss_ce: 0.049475
2022-01-14 11:47:29,007 iteration 768 : loss : 0.075007, loss_ce: 0.030547
2022-01-14 11:47:29,984 iteration 769 : loss : 0.087250, loss_ce: 0.037122
2022-01-14 11:47:30,995 iteration 770 : loss : 0.072314, loss_ce: 0.037818
2022-01-14 11:47:31,951 iteration 771 : loss : 0.069183, loss_ce: 0.033947
2022-01-14 11:47:32,823 iteration 772 : loss : 0.068805, loss_ce: 0.032943
2022-01-14 11:47:33,725 iteration 773 : loss : 0.143872, loss_ce: 0.050290
2022-01-14 11:47:34,730 iteration 774 : loss : 0.076552, loss_ce: 0.033942
2022-01-14 11:47:35,595 iteration 775 : loss : 0.061812, loss_ce: 0.024727
2022-01-14 11:47:36,495 iteration 776 : loss : 0.135196, loss_ce: 0.038930
2022-01-14 11:47:37,549 iteration 777 : loss : 0.057854, loss_ce: 0.024203
2022-01-14 11:47:38,497 iteration 778 : loss : 0.077074, loss_ce: 0.029778
2022-01-14 11:47:39,420 iteration 779 : loss : 0.083851, loss_ce: 0.031942
2022-01-14 11:47:40,458 iteration 780 : loss : 0.093867, loss_ce: 0.038871
2022-01-14 11:47:41,446 iteration 781 : loss : 0.069569, loss_ce: 0.024017
2022-01-14 11:47:42,360 iteration 782 : loss : 0.054144, loss_ce: 0.021112
 12%|███▍                          | 46/400 [13:08<1:43:06, 17.48s/it]2022-01-14 11:47:43,347 iteration 783 : loss : 0.073061, loss_ce: 0.027007
2022-01-14 11:47:44,217 iteration 784 : loss : 0.043527, loss_ce: 0.015194
2022-01-14 11:47:45,230 iteration 785 : loss : 0.114322, loss_ce: 0.039988
2022-01-14 11:47:46,151 iteration 786 : loss : 0.088543, loss_ce: 0.031813
2022-01-14 11:47:47,111 iteration 787 : loss : 0.092415, loss_ce: 0.037630
2022-01-14 11:47:47,994 iteration 788 : loss : 0.096715, loss_ce: 0.040175
2022-01-14 11:47:48,966 iteration 789 : loss : 0.092641, loss_ce: 0.033978
2022-01-14 11:47:49,975 iteration 790 : loss : 0.063152, loss_ce: 0.024672
2022-01-14 11:47:50,838 iteration 791 : loss : 0.073242, loss_ce: 0.036555
2022-01-14 11:47:51,837 iteration 792 : loss : 0.076521, loss_ce: 0.030403
2022-01-14 11:47:52,805 iteration 793 : loss : 0.107917, loss_ce: 0.040520
2022-01-14 11:47:53,800 iteration 794 : loss : 0.069860, loss_ce: 0.028504
2022-01-14 11:47:54,752 iteration 795 : loss : 0.080422, loss_ce: 0.032891
2022-01-14 11:47:55,793 iteration 796 : loss : 0.086361, loss_ce: 0.036028
2022-01-14 11:47:56,725 iteration 797 : loss : 0.069865, loss_ce: 0.032685
2022-01-14 11:47:57,630 iteration 798 : loss : 0.074875, loss_ce: 0.030694
2022-01-14 11:47:58,687 iteration 799 : loss : 0.128498, loss_ce: 0.041198
 12%|███▌                          | 47/400 [13:24<1:40:46, 17.13s/it]2022-01-14 11:47:59,683 iteration 800 : loss : 0.074747, loss_ce: 0.037946
2022-01-14 11:48:00,597 iteration 801 : loss : 0.083559, loss_ce: 0.023336
2022-01-14 11:48:01,569 iteration 802 : loss : 0.086595, loss_ce: 0.044570
2022-01-14 11:48:02,428 iteration 803 : loss : 0.051733, loss_ce: 0.020145
2022-01-14 11:48:03,457 iteration 804 : loss : 0.096693, loss_ce: 0.030434
2022-01-14 11:48:04,349 iteration 805 : loss : 0.079539, loss_ce: 0.031819
2022-01-14 11:48:05,200 iteration 806 : loss : 0.077329, loss_ce: 0.025338
2022-01-14 11:48:06,122 iteration 807 : loss : 0.060378, loss_ce: 0.030426
2022-01-14 11:48:07,058 iteration 808 : loss : 0.091946, loss_ce: 0.027182
2022-01-14 11:48:08,057 iteration 809 : loss : 0.068455, loss_ce: 0.029819
2022-01-14 11:48:08,945 iteration 810 : loss : 0.051072, loss_ce: 0.016192
2022-01-14 11:48:09,905 iteration 811 : loss : 0.134212, loss_ce: 0.061836
2022-01-14 11:48:10,775 iteration 812 : loss : 0.088045, loss_ce: 0.039770
2022-01-14 11:48:11,776 iteration 813 : loss : 0.075398, loss_ce: 0.032710
2022-01-14 11:48:12,783 iteration 814 : loss : 0.154090, loss_ce: 0.040305
2022-01-14 11:48:13,573 iteration 815 : loss : 0.057418, loss_ce: 0.025479
2022-01-14 11:48:14,575 iteration 816 : loss : 0.092733, loss_ce: 0.043057
 12%|███▌                          | 48/400 [13:40<1:38:18, 16.76s/it]2022-01-14 11:48:15,519 iteration 817 : loss : 0.058148, loss_ce: 0.024180
2022-01-14 11:48:16,431 iteration 818 : loss : 0.074404, loss_ce: 0.037491
2022-01-14 11:48:17,481 iteration 819 : loss : 0.092898, loss_ce: 0.043548
2022-01-14 11:48:18,482 iteration 820 : loss : 0.091520, loss_ce: 0.035946
2022-01-14 11:48:19,451 iteration 821 : loss : 0.098914, loss_ce: 0.043498
2022-01-14 11:48:20,399 iteration 822 : loss : 0.071983, loss_ce: 0.029334
2022-01-14 11:48:21,347 iteration 823 : loss : 0.068143, loss_ce: 0.027911
2022-01-14 11:48:22,217 iteration 824 : loss : 0.071199, loss_ce: 0.025213
2022-01-14 11:48:23,139 iteration 825 : loss : 0.115069, loss_ce: 0.036173
2022-01-14 11:48:23,994 iteration 826 : loss : 0.066616, loss_ce: 0.028515
2022-01-14 11:48:24,905 iteration 827 : loss : 0.088577, loss_ce: 0.030206
2022-01-14 11:48:25,747 iteration 828 : loss : 0.061193, loss_ce: 0.022199
2022-01-14 11:48:26,754 iteration 829 : loss : 0.082378, loss_ce: 0.038534
2022-01-14 11:48:27,662 iteration 830 : loss : 0.095933, loss_ce: 0.046996
2022-01-14 11:48:28,632 iteration 831 : loss : 0.107625, loss_ce: 0.052783
2022-01-14 11:48:29,552 iteration 832 : loss : 0.077120, loss_ce: 0.025412
2022-01-14 11:48:30,494 iteration 833 : loss : 0.071563, loss_ce: 0.027920
 12%|███▋                          | 49/400 [13:56<1:36:33, 16.51s/it]2022-01-14 11:48:31,394 iteration 834 : loss : 0.067108, loss_ce: 0.022928
2022-01-14 11:48:32,231 iteration 835 : loss : 0.043575, loss_ce: 0.014607
2022-01-14 11:48:33,232 iteration 836 : loss : 0.079771, loss_ce: 0.026096
2022-01-14 11:48:34,141 iteration 837 : loss : 0.051651, loss_ce: 0.018953
2022-01-14 11:48:35,105 iteration 838 : loss : 0.091479, loss_ce: 0.048153
2022-01-14 11:48:35,947 iteration 839 : loss : 0.052478, loss_ce: 0.021484
2022-01-14 11:48:36,808 iteration 840 : loss : 0.049880, loss_ce: 0.022697
2022-01-14 11:48:37,676 iteration 841 : loss : 0.079352, loss_ce: 0.036034
2022-01-14 11:48:38,691 iteration 842 : loss : 0.102144, loss_ce: 0.038784
2022-01-14 11:48:39,577 iteration 843 : loss : 0.073750, loss_ce: 0.024041
2022-01-14 11:48:40,530 iteration 844 : loss : 0.054891, loss_ce: 0.019906
2022-01-14 11:48:41,446 iteration 845 : loss : 0.056588, loss_ce: 0.030041
2022-01-14 11:48:42,358 iteration 846 : loss : 0.055933, loss_ce: 0.030427
2022-01-14 11:48:43,359 iteration 847 : loss : 0.072025, loss_ce: 0.028984
2022-01-14 11:48:44,258 iteration 848 : loss : 0.059800, loss_ce: 0.026033
2022-01-14 11:48:45,158 iteration 849 : loss : 0.055059, loss_ce: 0.020214
2022-01-14 11:48:45,158 Training Data Eval:
2022-01-14 11:48:49,468   Average segmentation loss on training set: 0.0682
2022-01-14 11:48:49,469 Validation Data Eval:
2022-01-14 11:48:50,925   Average segmentation loss on validation set: 0.0947
2022-01-14 11:48:52,149 Found new lowest validation loss at iteration 849! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_1BLOCK_best_val_loss_seed2.pth
2022-01-14 11:48:52,997 iteration 850 : loss : 0.085240, loss_ce: 0.043843
 12%|███▊                          | 50/400 [14:18<1:46:46, 18.31s/it]2022-01-14 11:48:53,973 iteration 851 : loss : 0.060480, loss_ce: 0.023038
2022-01-14 11:48:54,866 iteration 852 : loss : 0.076156, loss_ce: 0.027338
2022-01-14 11:48:55,799 iteration 853 : loss : 0.058953, loss_ce: 0.023213
2022-01-14 11:48:56,749 iteration 854 : loss : 0.061088, loss_ce: 0.028871
2022-01-14 11:48:57,621 iteration 855 : loss : 0.067766, loss_ce: 0.032686
2022-01-14 11:48:58,588 iteration 856 : loss : 0.064858, loss_ce: 0.029258
2022-01-14 11:48:59,473 iteration 857 : loss : 0.081275, loss_ce: 0.034439
2022-01-14 11:49:00,491 iteration 858 : loss : 0.042479, loss_ce: 0.016291
2022-01-14 11:49:01,275 iteration 859 : loss : 0.053820, loss_ce: 0.017176
2022-01-14 11:49:02,186 iteration 860 : loss : 0.057931, loss_ce: 0.020836
2022-01-14 11:49:03,090 iteration 861 : loss : 0.085119, loss_ce: 0.025160
2022-01-14 11:49:04,028 iteration 862 : loss : 0.074003, loss_ce: 0.036108
2022-01-14 11:49:04,940 iteration 863 : loss : 0.095616, loss_ce: 0.038343
2022-01-14 11:49:05,845 iteration 864 : loss : 0.056903, loss_ce: 0.024760
2022-01-14 11:49:06,778 iteration 865 : loss : 0.055995, loss_ce: 0.021286
2022-01-14 11:49:07,644 iteration 866 : loss : 0.054172, loss_ce: 0.023363
2022-01-14 11:49:08,610 iteration 867 : loss : 0.079016, loss_ce: 0.034419
 13%|███▊                          | 51/400 [14:34<1:41:46, 17.50s/it]2022-01-14 11:49:09,591 iteration 868 : loss : 0.074067, loss_ce: 0.036739
2022-01-14 11:49:10,560 iteration 869 : loss : 0.058256, loss_ce: 0.027843
2022-01-14 11:49:11,389 iteration 870 : loss : 0.064741, loss_ce: 0.029474
2022-01-14 11:49:12,289 iteration 871 : loss : 0.078987, loss_ce: 0.039781
2022-01-14 11:49:13,178 iteration 872 : loss : 0.075451, loss_ce: 0.031067
2022-01-14 11:49:14,129 iteration 873 : loss : 0.078944, loss_ce: 0.034670
2022-01-14 11:49:15,060 iteration 874 : loss : 0.056299, loss_ce: 0.024256
2022-01-14 11:49:15,996 iteration 875 : loss : 0.085386, loss_ce: 0.031560
2022-01-14 11:49:16,938 iteration 876 : loss : 0.058415, loss_ce: 0.021617
2022-01-14 11:49:17,908 iteration 877 : loss : 0.071250, loss_ce: 0.030943
2022-01-14 11:49:18,795 iteration 878 : loss : 0.147658, loss_ce: 0.041522
2022-01-14 11:49:19,706 iteration 879 : loss : 0.106884, loss_ce: 0.029357
2022-01-14 11:49:20,582 iteration 880 : loss : 0.062015, loss_ce: 0.027685
2022-01-14 11:49:21,560 iteration 881 : loss : 0.069209, loss_ce: 0.024243
2022-01-14 11:49:22,530 iteration 882 : loss : 0.083253, loss_ce: 0.032975
2022-01-14 11:49:23,423 iteration 883 : loss : 0.072925, loss_ce: 0.024204
2022-01-14 11:49:24,404 iteration 884 : loss : 0.109587, loss_ce: 0.046706
 13%|███▉                          | 52/400 [14:50<1:38:31, 16.99s/it]2022-01-14 11:49:25,408 iteration 885 : loss : 0.062130, loss_ce: 0.027064
2022-01-14 11:49:26,337 iteration 886 : loss : 0.073696, loss_ce: 0.035114
2022-01-14 11:49:27,262 iteration 887 : loss : 0.088030, loss_ce: 0.034182
2022-01-14 11:49:28,187 iteration 888 : loss : 0.091870, loss_ce: 0.034002
2022-01-14 11:49:29,138 iteration 889 : loss : 0.150257, loss_ce: 0.040498
2022-01-14 11:49:30,037 iteration 890 : loss : 0.056815, loss_ce: 0.024040
2022-01-14 11:49:30,956 iteration 891 : loss : 0.056258, loss_ce: 0.033886
2022-01-14 11:49:31,897 iteration 892 : loss : 0.050208, loss_ce: 0.022052
2022-01-14 11:49:32,824 iteration 893 : loss : 0.044690, loss_ce: 0.020742
2022-01-14 11:49:33,730 iteration 894 : loss : 0.062450, loss_ce: 0.020822
2022-01-14 11:49:34,644 iteration 895 : loss : 0.080686, loss_ce: 0.030715
2022-01-14 11:49:35,510 iteration 896 : loss : 0.068397, loss_ce: 0.033579
2022-01-14 11:49:36,590 iteration 897 : loss : 0.087520, loss_ce: 0.031293
2022-01-14 11:49:37,497 iteration 898 : loss : 0.058064, loss_ce: 0.021399
2022-01-14 11:49:38,476 iteration 899 : loss : 0.074559, loss_ce: 0.027387
2022-01-14 11:49:39,437 iteration 900 : loss : 0.059399, loss_ce: 0.018943
2022-01-14 11:49:40,329 iteration 901 : loss : 0.067954, loss_ce: 0.026135
 13%|███▉                          | 53/400 [15:06<1:36:24, 16.67s/it]2022-01-14 11:49:41,371 iteration 902 : loss : 0.065340, loss_ce: 0.030947
2022-01-14 11:49:42,331 iteration 903 : loss : 0.069026, loss_ce: 0.019588
2022-01-14 11:49:43,247 iteration 904 : loss : 0.081497, loss_ce: 0.038649
2022-01-14 11:49:44,149 iteration 905 : loss : 0.050995, loss_ce: 0.022572
2022-01-14 11:49:45,178 iteration 906 : loss : 0.067917, loss_ce: 0.029617
2022-01-14 11:49:46,048 iteration 907 : loss : 0.056953, loss_ce: 0.022409
2022-01-14 11:49:46,942 iteration 908 : loss : 0.065309, loss_ce: 0.034622
2022-01-14 11:49:47,912 iteration 909 : loss : 0.073130, loss_ce: 0.032706
2022-01-14 11:49:48,931 iteration 910 : loss : 0.062060, loss_ce: 0.024248
2022-01-14 11:49:49,863 iteration 911 : loss : 0.047256, loss_ce: 0.017606
2022-01-14 11:49:50,838 iteration 912 : loss : 0.055388, loss_ce: 0.022940
2022-01-14 11:49:51,762 iteration 913 : loss : 0.071378, loss_ce: 0.026560
2022-01-14 11:49:52,620 iteration 914 : loss : 0.079339, loss_ce: 0.034323
2022-01-14 11:49:53,558 iteration 915 : loss : 0.074842, loss_ce: 0.026888
2022-01-14 11:49:54,560 iteration 916 : loss : 0.092335, loss_ce: 0.029095
2022-01-14 11:49:55,510 iteration 917 : loss : 0.066211, loss_ce: 0.025309
2022-01-14 11:49:56,526 iteration 918 : loss : 0.126127, loss_ce: 0.037450
 14%|████                          | 54/400 [15:22<1:35:18, 16.53s/it]2022-01-14 11:49:57,486 iteration 919 : loss : 0.072525, loss_ce: 0.026483
2022-01-14 11:49:58,457 iteration 920 : loss : 0.051620, loss_ce: 0.023421
2022-01-14 11:49:59,333 iteration 921 : loss : 0.056502, loss_ce: 0.022814
2022-01-14 11:50:00,292 iteration 922 : loss : 0.053820, loss_ce: 0.015776
2022-01-14 11:50:01,158 iteration 923 : loss : 0.047555, loss_ce: 0.017216
2022-01-14 11:50:02,113 iteration 924 : loss : 0.076596, loss_ce: 0.023033
2022-01-14 11:50:03,078 iteration 925 : loss : 0.080714, loss_ce: 0.025088
2022-01-14 11:50:04,028 iteration 926 : loss : 0.069219, loss_ce: 0.022099
2022-01-14 11:50:04,876 iteration 927 : loss : 0.087236, loss_ce: 0.026990
2022-01-14 11:50:05,878 iteration 928 : loss : 0.061231, loss_ce: 0.026541
2022-01-14 11:50:06,769 iteration 929 : loss : 0.063722, loss_ce: 0.024436
2022-01-14 11:50:07,640 iteration 930 : loss : 0.064737, loss_ce: 0.023873
2022-01-14 11:50:08,521 iteration 931 : loss : 0.086826, loss_ce: 0.041557
2022-01-14 11:50:09,457 iteration 932 : loss : 0.060025, loss_ce: 0.029115
2022-01-14 11:50:10,438 iteration 933 : loss : 0.056154, loss_ce: 0.029455
2022-01-14 11:50:11,335 iteration 934 : loss : 0.064078, loss_ce: 0.022103
2022-01-14 11:50:11,335 Training Data Eval:
2022-01-14 11:50:15,638   Average segmentation loss on training set: 0.0818
2022-01-14 11:50:15,638 Validation Data Eval:
2022-01-14 11:50:17,108   Average segmentation loss on validation set: 0.1016
2022-01-14 11:50:18,035 iteration 935 : loss : 0.051447, loss_ce: 0.023450
 14%|████▏                         | 55/400 [15:43<1:43:37, 18.02s/it]2022-01-14 11:50:19,034 iteration 936 : loss : 0.055698, loss_ce: 0.023822
2022-01-14 11:50:19,923 iteration 937 : loss : 0.087290, loss_ce: 0.031502
2022-01-14 11:50:20,869 iteration 938 : loss : 0.054781, loss_ce: 0.025296
2022-01-14 11:50:21,892 iteration 939 : loss : 0.091431, loss_ce: 0.028298
2022-01-14 11:50:22,758 iteration 940 : loss : 0.070007, loss_ce: 0.024633
2022-01-14 11:50:23,636 iteration 941 : loss : 0.067823, loss_ce: 0.023759
2022-01-14 11:50:24,562 iteration 942 : loss : 0.085028, loss_ce: 0.036487
2022-01-14 11:50:25,513 iteration 943 : loss : 0.092837, loss_ce: 0.029442
2022-01-14 11:50:26,445 iteration 944 : loss : 0.072610, loss_ce: 0.028214
2022-01-14 11:50:27,419 iteration 945 : loss : 0.065256, loss_ce: 0.027914
2022-01-14 11:50:28,333 iteration 946 : loss : 0.056834, loss_ce: 0.021848
2022-01-14 11:50:29,267 iteration 947 : loss : 0.051285, loss_ce: 0.017024
2022-01-14 11:50:30,272 iteration 948 : loss : 0.107939, loss_ce: 0.043244
2022-01-14 11:50:31,272 iteration 949 : loss : 0.082578, loss_ce: 0.037460
2022-01-14 11:50:32,295 iteration 950 : loss : 0.076681, loss_ce: 0.030694
2022-01-14 11:50:33,189 iteration 951 : loss : 0.064396, loss_ce: 0.027943
2022-01-14 11:50:34,159 iteration 952 : loss : 0.065788, loss_ce: 0.024410
 14%|████▏                         | 56/400 [16:00<1:40:03, 17.45s/it]2022-01-14 11:50:35,101 iteration 953 : loss : 0.072145, loss_ce: 0.028048
2022-01-14 11:50:36,004 iteration 954 : loss : 0.055414, loss_ce: 0.020476
2022-01-14 11:50:36,943 iteration 955 : loss : 0.065170, loss_ce: 0.023634
2022-01-14 11:50:37,900 iteration 956 : loss : 0.050088, loss_ce: 0.017106
2022-01-14 11:50:38,825 iteration 957 : loss : 0.074856, loss_ce: 0.031389
2022-01-14 11:50:39,790 iteration 958 : loss : 0.078175, loss_ce: 0.026489
2022-01-14 11:50:40,787 iteration 959 : loss : 0.076205, loss_ce: 0.034613
2022-01-14 11:50:41,769 iteration 960 : loss : 0.077762, loss_ce: 0.033891
2022-01-14 11:50:42,716 iteration 961 : loss : 0.064676, loss_ce: 0.023105
2022-01-14 11:50:43,685 iteration 962 : loss : 0.080888, loss_ce: 0.024769
2022-01-14 11:50:44,564 iteration 963 : loss : 0.056388, loss_ce: 0.024445
2022-01-14 11:50:45,517 iteration 964 : loss : 0.081161, loss_ce: 0.023530
2022-01-14 11:50:46,399 iteration 965 : loss : 0.046166, loss_ce: 0.016243
2022-01-14 11:50:47,425 iteration 966 : loss : 0.079818, loss_ce: 0.026311
2022-01-14 11:50:48,355 iteration 967 : loss : 0.063036, loss_ce: 0.029881
2022-01-14 11:50:49,203 iteration 968 : loss : 0.062097, loss_ce: 0.023877
2022-01-14 11:50:50,148 iteration 969 : loss : 0.058696, loss_ce: 0.026018
 14%|████▎                         | 57/400 [16:16<1:37:14, 17.01s/it]2022-01-14 11:50:51,086 iteration 970 : loss : 0.073111, loss_ce: 0.034302
2022-01-14 11:50:52,015 iteration 971 : loss : 0.069019, loss_ce: 0.030454
2022-01-14 11:50:52,942 iteration 972 : loss : 0.075783, loss_ce: 0.030112
2022-01-14 11:50:53,896 iteration 973 : loss : 0.055839, loss_ce: 0.021525
2022-01-14 11:50:54,827 iteration 974 : loss : 0.078228, loss_ce: 0.031682
2022-01-14 11:50:55,717 iteration 975 : loss : 0.076985, loss_ce: 0.024856
2022-01-14 11:50:56,718 iteration 976 : loss : 0.071333, loss_ce: 0.034643
2022-01-14 11:50:57,618 iteration 977 : loss : 0.055503, loss_ce: 0.020059
2022-01-14 11:50:58,570 iteration 978 : loss : 0.041339, loss_ce: 0.015962
2022-01-14 11:50:59,465 iteration 979 : loss : 0.046605, loss_ce: 0.019163
2022-01-14 11:51:00,367 iteration 980 : loss : 0.062926, loss_ce: 0.024887
2022-01-14 11:51:01,256 iteration 981 : loss : 0.027779, loss_ce: 0.010114
2022-01-14 11:51:02,214 iteration 982 : loss : 0.080050, loss_ce: 0.026562
2022-01-14 11:51:03,217 iteration 983 : loss : 0.074564, loss_ce: 0.028681
2022-01-14 11:51:04,224 iteration 984 : loss : 0.053475, loss_ce: 0.024283
2022-01-14 11:51:05,202 iteration 985 : loss : 0.055625, loss_ce: 0.021835
2022-01-14 11:51:06,094 iteration 986 : loss : 0.052276, loss_ce: 0.014611
 14%|████▎                         | 58/400 [16:31<1:35:08, 16.69s/it]2022-01-14 11:51:06,990 iteration 987 : loss : 0.055222, loss_ce: 0.019065
2022-01-14 11:51:07,912 iteration 988 : loss : 0.055994, loss_ce: 0.019141
2022-01-14 11:51:08,821 iteration 989 : loss : 0.039738, loss_ce: 0.014620
2022-01-14 11:51:09,746 iteration 990 : loss : 0.054819, loss_ce: 0.017058
2022-01-14 11:51:10,683 iteration 991 : loss : 0.062508, loss_ce: 0.022990
2022-01-14 11:51:11,575 iteration 992 : loss : 0.047070, loss_ce: 0.018183
2022-01-14 11:51:12,426 iteration 993 : loss : 0.044466, loss_ce: 0.015875
2022-01-14 11:51:13,216 iteration 994 : loss : 0.056865, loss_ce: 0.020924
2022-01-14 11:51:14,217 iteration 995 : loss : 0.073403, loss_ce: 0.035824
2022-01-14 11:51:15,166 iteration 996 : loss : 0.059072, loss_ce: 0.028316
2022-01-14 11:51:16,145 iteration 997 : loss : 0.060184, loss_ce: 0.024595
2022-01-14 11:51:17,108 iteration 998 : loss : 0.055484, loss_ce: 0.020955
2022-01-14 11:51:17,995 iteration 999 : loss : 0.056596, loss_ce: 0.023289
2022-01-14 11:51:18,985 iteration 1000 : loss : 0.068791, loss_ce: 0.036569
2022-01-14 11:51:19,891 iteration 1001 : loss : 0.043512, loss_ce: 0.018221
2022-01-14 11:51:20,885 iteration 1002 : loss : 0.071971, loss_ce: 0.026742
2022-01-14 11:51:21,746 iteration 1003 : loss : 0.146288, loss_ce: 0.042565
 15%|████▍                         | 59/400 [16:47<1:33:05, 16.38s/it]2022-01-14 11:51:22,709 iteration 1004 : loss : 0.070589, loss_ce: 0.022178
2022-01-14 11:51:23,632 iteration 1005 : loss : 0.067140, loss_ce: 0.033612
2022-01-14 11:51:24,661 iteration 1006 : loss : 0.058587, loss_ce: 0.027286
2022-01-14 11:51:25,634 iteration 1007 : loss : 0.087461, loss_ce: 0.048840
2022-01-14 11:51:26,624 iteration 1008 : loss : 0.072968, loss_ce: 0.043220
2022-01-14 11:51:27,524 iteration 1009 : loss : 0.048312, loss_ce: 0.018235
2022-01-14 11:51:28,372 iteration 1010 : loss : 0.041281, loss_ce: 0.013838
2022-01-14 11:51:29,275 iteration 1011 : loss : 0.058339, loss_ce: 0.023504
2022-01-14 11:51:30,263 iteration 1012 : loss : 0.048552, loss_ce: 0.020076
2022-01-14 11:51:31,199 iteration 1013 : loss : 0.053597, loss_ce: 0.022291
2022-01-14 11:51:32,111 iteration 1014 : loss : 0.050593, loss_ce: 0.017742
2022-01-14 11:51:33,158 iteration 1015 : loss : 0.080854, loss_ce: 0.026383
2022-01-14 11:51:34,081 iteration 1016 : loss : 0.048501, loss_ce: 0.018329
2022-01-14 11:51:34,968 iteration 1017 : loss : 0.053112, loss_ce: 0.021117
2022-01-14 11:51:36,031 iteration 1018 : loss : 0.069605, loss_ce: 0.025639
2022-01-14 11:51:36,997 iteration 1019 : loss : 0.058500, loss_ce: 0.021814
2022-01-14 11:51:36,997 Training Data Eval:
2022-01-14 11:51:41,308   Average segmentation loss on training set: 0.0395
2022-01-14 11:51:41,308 Validation Data Eval:
2022-01-14 11:51:42,767   Average segmentation loss on validation set: 0.0934
2022-01-14 11:51:43,959 Found new lowest validation loss at iteration 1019! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_1BLOCK_best_val_loss_seed2.pth
2022-01-14 11:51:44,964 iteration 1020 : loss : 0.068383, loss_ce: 0.030283
 15%|████▌                         | 60/400 [17:10<1:44:27, 18.43s/it]2022-01-14 11:51:45,944 iteration 1021 : loss : 0.053685, loss_ce: 0.022729
2022-01-14 11:51:46,953 iteration 1022 : loss : 0.060455, loss_ce: 0.029477
2022-01-14 11:51:47,837 iteration 1023 : loss : 0.041826, loss_ce: 0.015011
2022-01-14 11:51:48,730 iteration 1024 : loss : 0.040012, loss_ce: 0.014833
2022-01-14 11:51:49,702 iteration 1025 : loss : 0.053619, loss_ce: 0.023091
2022-01-14 11:51:50,652 iteration 1026 : loss : 0.083429, loss_ce: 0.019623
2022-01-14 11:51:51,563 iteration 1027 : loss : 0.054261, loss_ce: 0.017321
2022-01-14 11:51:52,585 iteration 1028 : loss : 0.074607, loss_ce: 0.027837
2022-01-14 11:51:53,567 iteration 1029 : loss : 0.074533, loss_ce: 0.026081
2022-01-14 11:51:54,483 iteration 1030 : loss : 0.060482, loss_ce: 0.026436
2022-01-14 11:51:55,545 iteration 1031 : loss : 0.060311, loss_ce: 0.024565
2022-01-14 11:51:56,502 iteration 1032 : loss : 0.059660, loss_ce: 0.026468
2022-01-14 11:51:57,395 iteration 1033 : loss : 0.060936, loss_ce: 0.027280
2022-01-14 11:51:58,284 iteration 1034 : loss : 0.053587, loss_ce: 0.020734
2022-01-14 11:51:59,263 iteration 1035 : loss : 0.071205, loss_ce: 0.030134
2022-01-14 11:52:00,287 iteration 1036 : loss : 0.067811, loss_ce: 0.026490
2022-01-14 11:52:01,142 iteration 1037 : loss : 0.045688, loss_ce: 0.018608
 15%|████▌                         | 61/400 [17:27<1:40:19, 17.76s/it]2022-01-14 11:52:02,130 iteration 1038 : loss : 0.046509, loss_ce: 0.019276
2022-01-14 11:52:03,036 iteration 1039 : loss : 0.047125, loss_ce: 0.019444
2022-01-14 11:52:03,951 iteration 1040 : loss : 0.071450, loss_ce: 0.023830
2022-01-14 11:52:04,871 iteration 1041 : loss : 0.057896, loss_ce: 0.027211
2022-01-14 11:52:05,771 iteration 1042 : loss : 0.057470, loss_ce: 0.028874
2022-01-14 11:52:06,673 iteration 1043 : loss : 0.056107, loss_ce: 0.020925
2022-01-14 11:52:07,674 iteration 1044 : loss : 0.061704, loss_ce: 0.027532
2022-01-14 11:52:08,634 iteration 1045 : loss : 0.064004, loss_ce: 0.026040
2022-01-14 11:52:09,532 iteration 1046 : loss : 0.046190, loss_ce: 0.022892
2022-01-14 11:52:10,345 iteration 1047 : loss : 0.047655, loss_ce: 0.019349
2022-01-14 11:52:11,284 iteration 1048 : loss : 0.044842, loss_ce: 0.020244
2022-01-14 11:52:12,269 iteration 1049 : loss : 0.061313, loss_ce: 0.024464
2022-01-14 11:52:13,182 iteration 1050 : loss : 0.108172, loss_ce: 0.022652
2022-01-14 11:52:14,079 iteration 1051 : loss : 0.053036, loss_ce: 0.021834
2022-01-14 11:52:15,050 iteration 1052 : loss : 0.085187, loss_ce: 0.028443
2022-01-14 11:52:16,017 iteration 1053 : loss : 0.090242, loss_ce: 0.030299
2022-01-14 11:52:16,961 iteration 1054 : loss : 0.053524, loss_ce: 0.022012
 16%|████▋                         | 62/400 [17:42<1:36:44, 17.17s/it]2022-01-14 11:52:17,948 iteration 1055 : loss : 0.040621, loss_ce: 0.012232
2022-01-14 11:52:18,793 iteration 1056 : loss : 0.050805, loss_ce: 0.022679
2022-01-14 11:52:19,756 iteration 1057 : loss : 0.082467, loss_ce: 0.027011
2022-01-14 11:52:20,696 iteration 1058 : loss : 0.089410, loss_ce: 0.032130
2022-01-14 11:52:21,640 iteration 1059 : loss : 0.068950, loss_ce: 0.029300
2022-01-14 11:52:22,492 iteration 1060 : loss : 0.041031, loss_ce: 0.013254
2022-01-14 11:52:23,525 iteration 1061 : loss : 0.098149, loss_ce: 0.050657
2022-01-14 11:52:24,485 iteration 1062 : loss : 0.071989, loss_ce: 0.022462
2022-01-14 11:52:25,538 iteration 1063 : loss : 0.056797, loss_ce: 0.024352
2022-01-14 11:52:26,506 iteration 1064 : loss : 0.080869, loss_ce: 0.024660
2022-01-14 11:52:27,518 iteration 1065 : loss : 0.087094, loss_ce: 0.044535
2022-01-14 11:52:28,420 iteration 1066 : loss : 0.057686, loss_ce: 0.025949
2022-01-14 11:52:29,314 iteration 1067 : loss : 0.044102, loss_ce: 0.017586
2022-01-14 11:52:30,283 iteration 1068 : loss : 0.054269, loss_ce: 0.020958
2022-01-14 11:52:31,230 iteration 1069 : loss : 0.044321, loss_ce: 0.019487
2022-01-14 11:52:32,303 iteration 1070 : loss : 0.115297, loss_ce: 0.032464
2022-01-14 11:52:33,245 iteration 1071 : loss : 0.058252, loss_ce: 0.026369
 16%|████▋                         | 63/400 [17:59<1:34:58, 16.91s/it]2022-01-14 11:52:34,349 iteration 1072 : loss : 0.058655, loss_ce: 0.019270
2022-01-14 11:52:35,315 iteration 1073 : loss : 0.061114, loss_ce: 0.025052
2022-01-14 11:52:36,280 iteration 1074 : loss : 0.069571, loss_ce: 0.026067
2022-01-14 11:52:37,239 iteration 1075 : loss : 0.083315, loss_ce: 0.024858
2022-01-14 11:52:38,143 iteration 1076 : loss : 0.055015, loss_ce: 0.021185
2022-01-14 11:52:39,157 iteration 1077 : loss : 0.058957, loss_ce: 0.019022
2022-01-14 11:52:40,069 iteration 1078 : loss : 0.060686, loss_ce: 0.025606
2022-01-14 11:52:41,067 iteration 1079 : loss : 0.063976, loss_ce: 0.031823
2022-01-14 11:52:41,924 iteration 1080 : loss : 0.032591, loss_ce: 0.010214
2022-01-14 11:52:42,858 iteration 1081 : loss : 0.058989, loss_ce: 0.033266
2022-01-14 11:52:43,838 iteration 1082 : loss : 0.085661, loss_ce: 0.048106
2022-01-14 11:52:44,733 iteration 1083 : loss : 0.059250, loss_ce: 0.024143
2022-01-14 11:52:45,649 iteration 1084 : loss : 0.056409, loss_ce: 0.017513
2022-01-14 11:52:46,607 iteration 1085 : loss : 0.055556, loss_ce: 0.023966
2022-01-14 11:52:47,540 iteration 1086 : loss : 0.067344, loss_ce: 0.033780
2022-01-14 11:52:48,528 iteration 1087 : loss : 0.040920, loss_ce: 0.015545
2022-01-14 11:52:49,466 iteration 1088 : loss : 0.045168, loss_ce: 0.020295
 16%|████▊                         | 64/400 [18:15<1:33:30, 16.70s/it]2022-01-14 11:52:50,398 iteration 1089 : loss : 0.076395, loss_ce: 0.028566
2022-01-14 11:52:51,307 iteration 1090 : loss : 0.059701, loss_ce: 0.020305
2022-01-14 11:52:52,305 iteration 1091 : loss : 0.046422, loss_ce: 0.023521
2022-01-14 11:52:53,229 iteration 1092 : loss : 0.048060, loss_ce: 0.020762
2022-01-14 11:52:54,170 iteration 1093 : loss : 0.047087, loss_ce: 0.020282
2022-01-14 11:52:55,136 iteration 1094 : loss : 0.051238, loss_ce: 0.024127
2022-01-14 11:52:56,111 iteration 1095 : loss : 0.111119, loss_ce: 0.039624
2022-01-14 11:52:57,053 iteration 1096 : loss : 0.047556, loss_ce: 0.022462
2022-01-14 11:52:57,944 iteration 1097 : loss : 0.083144, loss_ce: 0.029173
2022-01-14 11:52:58,841 iteration 1098 : loss : 0.047419, loss_ce: 0.022275
2022-01-14 11:52:59,770 iteration 1099 : loss : 0.044248, loss_ce: 0.020422
2022-01-14 11:53:00,681 iteration 1100 : loss : 0.077439, loss_ce: 0.029685
2022-01-14 11:53:01,571 iteration 1101 : loss : 0.060333, loss_ce: 0.023597
2022-01-14 11:53:02,601 iteration 1102 : loss : 0.063079, loss_ce: 0.017538
2022-01-14 11:53:03,522 iteration 1103 : loss : 0.052265, loss_ce: 0.017545
2022-01-14 11:53:04,395 iteration 1104 : loss : 0.058300, loss_ce: 0.022050
2022-01-14 11:53:04,396 Training Data Eval:
2022-01-14 11:53:08,693   Average segmentation loss on training set: 0.0442
2022-01-14 11:53:08,693 Validation Data Eval:
2022-01-14 11:53:10,142   Average segmentation loss on validation set: 0.1131
2022-01-14 11:53:11,070 iteration 1105 : loss : 0.046546, loss_ce: 0.020981
 16%|████▉                         | 65/400 [18:36<1:41:27, 18.17s/it]2022-01-14 11:53:12,070 iteration 1106 : loss : 0.046232, loss_ce: 0.015266
2022-01-14 11:53:13,066 iteration 1107 : loss : 0.069263, loss_ce: 0.030510
2022-01-14 11:53:13,951 iteration 1108 : loss : 0.044926, loss_ce: 0.016322
2022-01-14 11:53:14,822 iteration 1109 : loss : 0.082231, loss_ce: 0.036063
2022-01-14 11:53:15,739 iteration 1110 : loss : 0.049474, loss_ce: 0.023599
2022-01-14 11:53:16,676 iteration 1111 : loss : 0.047710, loss_ce: 0.020731
2022-01-14 11:53:17,605 iteration 1112 : loss : 0.066530, loss_ce: 0.032768
2022-01-14 11:53:18,505 iteration 1113 : loss : 0.054664, loss_ce: 0.019207
2022-01-14 11:53:19,364 iteration 1114 : loss : 0.048312, loss_ce: 0.019469
2022-01-14 11:53:20,199 iteration 1115 : loss : 0.045180, loss_ce: 0.014783
2022-01-14 11:53:21,175 iteration 1116 : loss : 0.087901, loss_ce: 0.034427
2022-01-14 11:53:22,194 iteration 1117 : loss : 0.055278, loss_ce: 0.022990
2022-01-14 11:53:23,066 iteration 1118 : loss : 0.037033, loss_ce: 0.016159
2022-01-14 11:53:23,950 iteration 1119 : loss : 0.037987, loss_ce: 0.014308
2022-01-14 11:53:24,818 iteration 1120 : loss : 0.068099, loss_ce: 0.025209
2022-01-14 11:53:25,695 iteration 1121 : loss : 0.039638, loss_ce: 0.012341
2022-01-14 11:53:26,558 iteration 1122 : loss : 0.046148, loss_ce: 0.020674
 16%|████▉                         | 66/400 [18:52<1:36:41, 17.37s/it]2022-01-14 11:53:27,547 iteration 1123 : loss : 0.050763, loss_ce: 0.022763
2022-01-14 11:53:28,434 iteration 1124 : loss : 0.066006, loss_ce: 0.028259
2022-01-14 11:53:29,385 iteration 1125 : loss : 0.067935, loss_ce: 0.023668
2022-01-14 11:53:30,436 iteration 1126 : loss : 0.083038, loss_ce: 0.036740
2022-01-14 11:53:31,375 iteration 1127 : loss : 0.067839, loss_ce: 0.028195
2022-01-14 11:53:32,336 iteration 1128 : loss : 0.050346, loss_ce: 0.015928
2022-01-14 11:53:33,249 iteration 1129 : loss : 0.051182, loss_ce: 0.016015
2022-01-14 11:53:34,239 iteration 1130 : loss : 0.069183, loss_ce: 0.033418
2022-01-14 11:53:35,253 iteration 1131 : loss : 0.147424, loss_ce: 0.050277
2022-01-14 11:53:36,206 iteration 1132 : loss : 0.063944, loss_ce: 0.027075
2022-01-14 11:53:37,165 iteration 1133 : loss : 0.060611, loss_ce: 0.023450
2022-01-14 11:53:38,117 iteration 1134 : loss : 0.063589, loss_ce: 0.026563
2022-01-14 11:53:39,004 iteration 1135 : loss : 0.050989, loss_ce: 0.018959
2022-01-14 11:53:39,951 iteration 1136 : loss : 0.050198, loss_ce: 0.020838
2022-01-14 11:53:40,855 iteration 1137 : loss : 0.058653, loss_ce: 0.021740
2022-01-14 11:53:41,868 iteration 1138 : loss : 0.070473, loss_ce: 0.036465
2022-01-14 11:53:42,876 iteration 1139 : loss : 0.056993, loss_ce: 0.026628
 17%|█████                         | 67/400 [19:08<1:34:39, 17.05s/it]2022-01-14 11:53:43,856 iteration 1140 : loss : 0.052487, loss_ce: 0.021451
2022-01-14 11:53:44,797 iteration 1141 : loss : 0.044085, loss_ce: 0.019353
2022-01-14 11:53:45,666 iteration 1142 : loss : 0.039630, loss_ce: 0.014978
2022-01-14 11:53:46,628 iteration 1143 : loss : 0.097010, loss_ce: 0.033466
2022-01-14 11:53:47,610 iteration 1144 : loss : 0.074138, loss_ce: 0.033777
2022-01-14 11:53:48,520 iteration 1145 : loss : 0.044039, loss_ce: 0.014817
2022-01-14 11:53:49,485 iteration 1146 : loss : 0.052913, loss_ce: 0.022945
2022-01-14 11:53:50,335 iteration 1147 : loss : 0.039456, loss_ce: 0.014141
2022-01-14 11:53:51,263 iteration 1148 : loss : 0.050029, loss_ce: 0.020082
2022-01-14 11:53:52,217 iteration 1149 : loss : 0.067925, loss_ce: 0.030723
2022-01-14 11:53:53,165 iteration 1150 : loss : 0.043983, loss_ce: 0.019804
2022-01-14 11:53:54,103 iteration 1151 : loss : 0.055727, loss_ce: 0.016931
2022-01-14 11:53:55,069 iteration 1152 : loss : 0.141054, loss_ce: 0.029759
2022-01-14 11:53:56,027 iteration 1153 : loss : 0.050917, loss_ce: 0.019991
2022-01-14 11:53:56,902 iteration 1154 : loss : 0.053864, loss_ce: 0.023756
2022-01-14 11:53:57,931 iteration 1155 : loss : 0.069426, loss_ce: 0.023363
2022-01-14 11:53:58,898 iteration 1156 : loss : 0.096770, loss_ce: 0.031013
 17%|█████                         | 68/400 [19:24<1:32:37, 16.74s/it]2022-01-14 11:53:59,838 iteration 1157 : loss : 0.045901, loss_ce: 0.021306
2022-01-14 11:54:00,884 iteration 1158 : loss : 0.066846, loss_ce: 0.022599
2022-01-14 11:54:01,895 iteration 1159 : loss : 0.088634, loss_ce: 0.034258
2022-01-14 11:54:02,744 iteration 1160 : loss : 0.048918, loss_ce: 0.022481
2022-01-14 11:54:03,671 iteration 1161 : loss : 0.046369, loss_ce: 0.016475
2022-01-14 11:54:04,598 iteration 1162 : loss : 0.069816, loss_ce: 0.019812
2022-01-14 11:54:05,647 iteration 1163 : loss : 0.073745, loss_ce: 0.024163
2022-01-14 11:54:06,608 iteration 1164 : loss : 0.055362, loss_ce: 0.021896
2022-01-14 11:54:07,487 iteration 1165 : loss : 0.053688, loss_ce: 0.027861
2022-01-14 11:54:08,417 iteration 1166 : loss : 0.045468, loss_ce: 0.019956
2022-01-14 11:54:09,375 iteration 1167 : loss : 0.077332, loss_ce: 0.037800
2022-01-14 11:54:10,215 iteration 1168 : loss : 0.044828, loss_ce: 0.015732
2022-01-14 11:54:11,145 iteration 1169 : loss : 0.070888, loss_ce: 0.023175
2022-01-14 11:54:12,077 iteration 1170 : loss : 0.060491, loss_ce: 0.022170
2022-01-14 11:54:12,934 iteration 1171 : loss : 0.058862, loss_ce: 0.019328
2022-01-14 11:54:13,852 iteration 1172 : loss : 0.057320, loss_ce: 0.024727
2022-01-14 11:54:14,805 iteration 1173 : loss : 0.068035, loss_ce: 0.042774
 17%|█████▏                        | 69/400 [19:40<1:30:59, 16.50s/it]2022-01-14 11:54:15,825 iteration 1174 : loss : 0.048048, loss_ce: 0.016546
2022-01-14 11:54:16,737 iteration 1175 : loss : 0.041690, loss_ce: 0.018008
2022-01-14 11:54:17,716 iteration 1176 : loss : 0.069722, loss_ce: 0.031396
2022-01-14 11:54:18,775 iteration 1177 : loss : 0.070666, loss_ce: 0.031952
2022-01-14 11:54:19,740 iteration 1178 : loss : 0.057713, loss_ce: 0.026859
2022-01-14 11:54:20,591 iteration 1179 : loss : 0.045286, loss_ce: 0.020903
2022-01-14 11:54:21,588 iteration 1180 : loss : 0.063568, loss_ce: 0.025690
2022-01-14 11:54:22,443 iteration 1181 : loss : 0.045087, loss_ce: 0.019972
2022-01-14 11:54:23,475 iteration 1182 : loss : 0.063270, loss_ce: 0.025038
2022-01-14 11:54:24,408 iteration 1183 : loss : 0.042578, loss_ce: 0.016930
2022-01-14 11:54:25,268 iteration 1184 : loss : 0.046449, loss_ce: 0.018987
2022-01-14 11:54:26,221 iteration 1185 : loss : 0.068779, loss_ce: 0.025667
2022-01-14 11:54:27,110 iteration 1186 : loss : 0.048694, loss_ce: 0.020013
2022-01-14 11:54:28,039 iteration 1187 : loss : 0.042497, loss_ce: 0.016485
2022-01-14 11:54:28,916 iteration 1188 : loss : 0.038654, loss_ce: 0.013727
2022-01-14 11:54:29,844 iteration 1189 : loss : 0.057148, loss_ce: 0.025069
2022-01-14 11:54:29,844 Training Data Eval:
2022-01-14 11:54:34,148   Average segmentation loss on training set: 0.0436
2022-01-14 11:54:34,207 Validation Data Eval:
2022-01-14 11:54:35,657   Average segmentation loss on validation set: 0.1073
2022-01-14 11:54:36,606 iteration 1190 : loss : 0.048231, loss_ce: 0.018223
 18%|█████▎                        | 70/400 [20:02<1:39:27, 18.08s/it]2022-01-14 11:54:37,560 iteration 1191 : loss : 0.079206, loss_ce: 0.037541
2022-01-14 11:54:38,453 iteration 1192 : loss : 0.048339, loss_ce: 0.020885
2022-01-14 11:54:39,388 iteration 1193 : loss : 0.060868, loss_ce: 0.019628
2022-01-14 11:54:40,272 iteration 1194 : loss : 0.074679, loss_ce: 0.026110
2022-01-14 11:54:41,241 iteration 1195 : loss : 0.075852, loss_ce: 0.027258
2022-01-14 11:54:42,095 iteration 1196 : loss : 0.053957, loss_ce: 0.018192
2022-01-14 11:54:43,056 iteration 1197 : loss : 0.046510, loss_ce: 0.023872
2022-01-14 11:54:43,972 iteration 1198 : loss : 0.041911, loss_ce: 0.022581
2022-01-14 11:54:44,920 iteration 1199 : loss : 0.064480, loss_ce: 0.025403
2022-01-14 11:54:45,865 iteration 1200 : loss : 0.058542, loss_ce: 0.020195
2022-01-14 11:54:46,782 iteration 1201 : loss : 0.045941, loss_ce: 0.020453
2022-01-14 11:54:47,753 iteration 1202 : loss : 0.040524, loss_ce: 0.018183
2022-01-14 11:54:48,655 iteration 1203 : loss : 0.043916, loss_ce: 0.016788
2022-01-14 11:54:49,577 iteration 1204 : loss : 0.053276, loss_ce: 0.021897
2022-01-14 11:54:50,548 iteration 1205 : loss : 0.061294, loss_ce: 0.034070
2022-01-14 11:54:51,535 iteration 1206 : loss : 0.097866, loss_ce: 0.027626
2022-01-14 11:54:52,425 iteration 1207 : loss : 0.065564, loss_ce: 0.024706
 18%|█████▎                        | 71/400 [20:18<1:35:26, 17.41s/it]2022-01-14 11:54:53,337 iteration 1208 : loss : 0.041340, loss_ce: 0.019211
2022-01-14 11:54:54,265 iteration 1209 : loss : 0.044004, loss_ce: 0.014639
2022-01-14 11:54:55,113 iteration 1210 : loss : 0.047602, loss_ce: 0.014500
2022-01-14 11:54:56,050 iteration 1211 : loss : 0.065783, loss_ce: 0.021925
2022-01-14 11:54:56,943 iteration 1212 : loss : 0.038415, loss_ce: 0.016301
2022-01-14 11:54:57,881 iteration 1213 : loss : 0.060781, loss_ce: 0.019410
2022-01-14 11:54:58,843 iteration 1214 : loss : 0.060764, loss_ce: 0.024539
2022-01-14 11:54:59,767 iteration 1215 : loss : 0.047735, loss_ce: 0.021632
2022-01-14 11:55:00,674 iteration 1216 : loss : 0.041157, loss_ce: 0.016640
2022-01-14 11:55:01,655 iteration 1217 : loss : 0.051046, loss_ce: 0.021967
2022-01-14 11:55:02,478 iteration 1218 : loss : 0.043399, loss_ce: 0.019789
2022-01-14 11:55:03,431 iteration 1219 : loss : 0.069733, loss_ce: 0.025699
2022-01-14 11:55:04,346 iteration 1220 : loss : 0.057023, loss_ce: 0.018733
2022-01-14 11:55:05,397 iteration 1221 : loss : 0.070578, loss_ce: 0.027822
2022-01-14 11:55:06,355 iteration 1222 : loss : 0.060564, loss_ce: 0.022836
2022-01-14 11:55:07,269 iteration 1223 : loss : 0.037621, loss_ce: 0.015475
2022-01-14 11:55:08,247 iteration 1224 : loss : 0.047555, loss_ce: 0.019493
 18%|█████▍                        | 72/400 [20:34<1:32:32, 16.93s/it]2022-01-14 11:55:09,266 iteration 1225 : loss : 0.044741, loss_ce: 0.019341
2022-01-14 11:55:10,183 iteration 1226 : loss : 0.066671, loss_ce: 0.026861
2022-01-14 11:55:11,073 iteration 1227 : loss : 0.047583, loss_ce: 0.015248
2022-01-14 11:55:12,128 iteration 1228 : loss : 0.121006, loss_ce: 0.040293
2022-01-14 11:55:13,133 iteration 1229 : loss : 0.063736, loss_ce: 0.027738
2022-01-14 11:55:14,109 iteration 1230 : loss : 0.046556, loss_ce: 0.020370
2022-01-14 11:55:15,027 iteration 1231 : loss : 0.070552, loss_ce: 0.026624
2022-01-14 11:55:16,012 iteration 1232 : loss : 0.052791, loss_ce: 0.021651
2022-01-14 11:55:17,074 iteration 1233 : loss : 0.061331, loss_ce: 0.026558
2022-01-14 11:55:18,036 iteration 1234 : loss : 0.047815, loss_ce: 0.019759
2022-01-14 11:55:18,957 iteration 1235 : loss : 0.069621, loss_ce: 0.031885
2022-01-14 11:55:19,855 iteration 1236 : loss : 0.042471, loss_ce: 0.013845
2022-01-14 11:55:20,698 iteration 1237 : loss : 0.054820, loss_ce: 0.023003
2022-01-14 11:55:21,630 iteration 1238 : loss : 0.052695, loss_ce: 0.023814
2022-01-14 11:55:22,616 iteration 1239 : loss : 0.046730, loss_ce: 0.018453
2022-01-14 11:55:23,461 iteration 1240 : loss : 0.037735, loss_ce: 0.014359
2022-01-14 11:55:24,478 iteration 1241 : loss : 0.050575, loss_ce: 0.021216
 18%|█████▍                        | 73/400 [20:50<1:31:08, 16.72s/it]2022-01-14 11:55:25,388 iteration 1242 : loss : 0.046822, loss_ce: 0.019274
2022-01-14 11:55:26,246 iteration 1243 : loss : 0.030732, loss_ce: 0.014745
2022-01-14 11:55:27,115 iteration 1244 : loss : 0.048449, loss_ce: 0.017678
2022-01-14 11:55:28,019 iteration 1245 : loss : 0.050642, loss_ce: 0.019955
2022-01-14 11:55:28,954 iteration 1246 : loss : 0.049016, loss_ce: 0.019750
2022-01-14 11:55:29,916 iteration 1247 : loss : 0.070338, loss_ce: 0.022854
2022-01-14 11:55:30,800 iteration 1248 : loss : 0.036856, loss_ce: 0.013442
2022-01-14 11:55:31,729 iteration 1249 : loss : 0.042189, loss_ce: 0.015800
2022-01-14 11:55:32,621 iteration 1250 : loss : 0.049889, loss_ce: 0.020220
2022-01-14 11:55:33,574 iteration 1251 : loss : 0.038719, loss_ce: 0.014964
2022-01-14 11:55:34,522 iteration 1252 : loss : 0.086485, loss_ce: 0.025765
2022-01-14 11:55:35,442 iteration 1253 : loss : 0.049155, loss_ce: 0.021881
2022-01-14 11:55:36,349 iteration 1254 : loss : 0.056653, loss_ce: 0.026137
2022-01-14 11:55:37,321 iteration 1255 : loss : 0.038878, loss_ce: 0.017610
2022-01-14 11:55:38,321 iteration 1256 : loss : 0.075399, loss_ce: 0.026963
2022-01-14 11:55:39,234 iteration 1257 : loss : 0.046167, loss_ce: 0.020881
2022-01-14 11:55:40,255 iteration 1258 : loss : 0.047492, loss_ce: 0.020663
 18%|█████▌                        | 74/400 [21:06<1:29:18, 16.44s/it]2022-01-14 11:55:41,222 iteration 1259 : loss : 0.043196, loss_ce: 0.015541
2022-01-14 11:55:42,214 iteration 1260 : loss : 0.047674, loss_ce: 0.015180
2022-01-14 11:55:43,169 iteration 1261 : loss : 0.056645, loss_ce: 0.024382
2022-01-14 11:55:44,055 iteration 1262 : loss : 0.032951, loss_ce: 0.014766
2022-01-14 11:55:45,057 iteration 1263 : loss : 0.034643, loss_ce: 0.009897
2022-01-14 11:55:45,918 iteration 1264 : loss : 0.039268, loss_ce: 0.019165
2022-01-14 11:55:46,779 iteration 1265 : loss : 0.041256, loss_ce: 0.015900
2022-01-14 11:55:47,630 iteration 1266 : loss : 0.036603, loss_ce: 0.016120
2022-01-14 11:55:48,650 iteration 1267 : loss : 0.046934, loss_ce: 0.016833
2022-01-14 11:55:49,573 iteration 1268 : loss : 0.125566, loss_ce: 0.029937
2022-01-14 11:55:50,542 iteration 1269 : loss : 0.056932, loss_ce: 0.019993
2022-01-14 11:55:51,417 iteration 1270 : loss : 0.061766, loss_ce: 0.020909
2022-01-14 11:55:52,339 iteration 1271 : loss : 0.054678, loss_ce: 0.023245
2022-01-14 11:55:53,247 iteration 1272 : loss : 0.077828, loss_ce: 0.034440
2022-01-14 11:55:54,203 iteration 1273 : loss : 0.057445, loss_ce: 0.028750
2022-01-14 11:55:55,147 iteration 1274 : loss : 0.040488, loss_ce: 0.013806
2022-01-14 11:55:55,147 Training Data Eval:
2022-01-14 11:55:59,446   Average segmentation loss on training set: 0.0394
2022-01-14 11:55:59,447 Validation Data Eval:
2022-01-14 11:56:00,903   Average segmentation loss on validation set: 0.1090
2022-01-14 11:56:01,851 iteration 1275 : loss : 0.063778, loss_ce: 0.020045
 19%|█████▋                        | 75/400 [21:27<1:37:25, 17.99s/it]2022-01-14 11:56:02,940 iteration 1276 : loss : 0.067169, loss_ce: 0.019510
2022-01-14 11:56:03,829 iteration 1277 : loss : 0.039919, loss_ce: 0.014603
2022-01-14 11:56:04,792 iteration 1278 : loss : 0.052303, loss_ce: 0.022773
2022-01-14 11:56:05,615 iteration 1279 : loss : 0.052598, loss_ce: 0.027598
2022-01-14 11:56:06,433 iteration 1280 : loss : 0.043786, loss_ce: 0.021603
2022-01-14 11:56:07,418 iteration 1281 : loss : 0.068530, loss_ce: 0.032602
2022-01-14 11:56:08,292 iteration 1282 : loss : 0.060376, loss_ce: 0.029521
2022-01-14 11:56:09,186 iteration 1283 : loss : 0.050440, loss_ce: 0.019124
2022-01-14 11:56:10,109 iteration 1284 : loss : 0.053790, loss_ce: 0.025475
2022-01-14 11:56:11,178 iteration 1285 : loss : 0.074737, loss_ce: 0.027012
2022-01-14 11:56:12,161 iteration 1286 : loss : 0.044090, loss_ce: 0.016259
2022-01-14 11:56:13,062 iteration 1287 : loss : 0.045778, loss_ce: 0.016902
2022-01-14 11:56:14,014 iteration 1288 : loss : 0.048138, loss_ce: 0.018354
2022-01-14 11:56:15,028 iteration 1289 : loss : 0.058794, loss_ce: 0.025046
2022-01-14 11:56:15,928 iteration 1290 : loss : 0.070517, loss_ce: 0.025527
2022-01-14 11:56:16,865 iteration 1291 : loss : 0.041323, loss_ce: 0.016389
2022-01-14 11:56:17,735 iteration 1292 : loss : 0.030134, loss_ce: 0.011557
 19%|█████▋                        | 76/400 [21:43<1:33:42, 17.35s/it]2022-01-14 11:56:18,728 iteration 1293 : loss : 0.054738, loss_ce: 0.026120
2022-01-14 11:56:19,611 iteration 1294 : loss : 0.050221, loss_ce: 0.018899
2022-01-14 11:56:20,509 iteration 1295 : loss : 0.040178, loss_ce: 0.016575
2022-01-14 11:56:21,426 iteration 1296 : loss : 0.045224, loss_ce: 0.016541
2022-01-14 11:56:22,313 iteration 1297 : loss : 0.046084, loss_ce: 0.018746
2022-01-14 11:56:23,250 iteration 1298 : loss : 0.042308, loss_ce: 0.019627
2022-01-14 11:56:24,110 iteration 1299 : loss : 0.054835, loss_ce: 0.019677
2022-01-14 11:56:25,097 iteration 1300 : loss : 0.128471, loss_ce: 0.046037
2022-01-14 11:56:26,020 iteration 1301 : loss : 0.071563, loss_ce: 0.038903
2022-01-14 11:56:27,012 iteration 1302 : loss : 0.055318, loss_ce: 0.015735
2022-01-14 11:56:27,898 iteration 1303 : loss : 0.050653, loss_ce: 0.020398
2022-01-14 11:56:28,846 iteration 1304 : loss : 0.067223, loss_ce: 0.020006
2022-01-14 11:56:29,787 iteration 1305 : loss : 0.076462, loss_ce: 0.037240
2022-01-14 11:56:30,795 iteration 1306 : loss : 0.063043, loss_ce: 0.022091
2022-01-14 11:56:31,793 iteration 1307 : loss : 0.058076, loss_ce: 0.023152
2022-01-14 11:56:32,739 iteration 1308 : loss : 0.060993, loss_ce: 0.037420
2022-01-14 11:56:33,679 iteration 1309 : loss : 0.055263, loss_ce: 0.021855
 19%|█████▊                        | 77/400 [21:59<1:31:08, 16.93s/it]2022-01-14 11:56:34,679 iteration 1310 : loss : 0.054594, loss_ce: 0.021884
2022-01-14 11:56:35,685 iteration 1311 : loss : 0.052155, loss_ce: 0.022650
2022-01-14 11:56:36,607 iteration 1312 : loss : 0.061488, loss_ce: 0.031880
2022-01-14 11:56:37,465 iteration 1313 : loss : 0.053680, loss_ce: 0.023765
2022-01-14 11:56:38,385 iteration 1314 : loss : 0.040505, loss_ce: 0.017061
2022-01-14 11:56:39,347 iteration 1315 : loss : 0.060294, loss_ce: 0.023097
2022-01-14 11:56:40,236 iteration 1316 : loss : 0.045676, loss_ce: 0.021066
2022-01-14 11:56:41,201 iteration 1317 : loss : 0.041814, loss_ce: 0.019244
2022-01-14 11:56:42,157 iteration 1318 : loss : 0.056347, loss_ce: 0.024896
2022-01-14 11:56:43,056 iteration 1319 : loss : 0.060454, loss_ce: 0.020976
2022-01-14 11:56:43,958 iteration 1320 : loss : 0.045385, loss_ce: 0.015388
2022-01-14 11:56:44,888 iteration 1321 : loss : 0.053006, loss_ce: 0.019331
2022-01-14 11:56:45,946 iteration 1322 : loss : 0.053441, loss_ce: 0.021977
2022-01-14 11:56:46,926 iteration 1323 : loss : 0.041809, loss_ce: 0.016477
2022-01-14 11:56:47,896 iteration 1324 : loss : 0.050076, loss_ce: 0.019105
2022-01-14 11:56:48,881 iteration 1325 : loss : 0.047765, loss_ce: 0.017428
2022-01-14 11:56:49,753 iteration 1326 : loss : 0.051155, loss_ce: 0.018098
 20%|█████▊                        | 78/400 [22:15<1:29:29, 16.68s/it]2022-01-14 11:56:50,782 iteration 1327 : loss : 0.050210, loss_ce: 0.026937
2022-01-14 11:56:51,826 iteration 1328 : loss : 0.057488, loss_ce: 0.018698
2022-01-14 11:56:52,686 iteration 1329 : loss : 0.046153, loss_ce: 0.024406
2022-01-14 11:56:53,615 iteration 1330 : loss : 0.039643, loss_ce: 0.014395
2022-01-14 11:56:54,546 iteration 1331 : loss : 0.035970, loss_ce: 0.012043
2022-01-14 11:56:55,466 iteration 1332 : loss : 0.031811, loss_ce: 0.013439
2022-01-14 11:56:56,440 iteration 1333 : loss : 0.083621, loss_ce: 0.018465
2022-01-14 11:56:57,362 iteration 1334 : loss : 0.032698, loss_ce: 0.013469
2022-01-14 11:56:58,410 iteration 1335 : loss : 0.048145, loss_ce: 0.015808
2022-01-14 11:56:59,374 iteration 1336 : loss : 0.052932, loss_ce: 0.021835
2022-01-14 11:57:00,381 iteration 1337 : loss : 0.069782, loss_ce: 0.034372
2022-01-14 11:57:01,382 iteration 1338 : loss : 0.055771, loss_ce: 0.023121
2022-01-14 11:57:02,360 iteration 1339 : loss : 0.045535, loss_ce: 0.017808
2022-01-14 11:57:03,249 iteration 1340 : loss : 0.045073, loss_ce: 0.015567
2022-01-14 11:57:04,151 iteration 1341 : loss : 0.048127, loss_ce: 0.018963
2022-01-14 11:57:05,075 iteration 1342 : loss : 0.050167, loss_ce: 0.018652
2022-01-14 11:57:05,983 iteration 1343 : loss : 0.035482, loss_ce: 0.012690
 20%|█████▉                        | 79/400 [22:31<1:28:29, 16.54s/it]2022-01-14 11:57:06,922 iteration 1344 : loss : 0.039024, loss_ce: 0.015044
2022-01-14 11:57:07,814 iteration 1345 : loss : 0.047714, loss_ce: 0.023013
2022-01-14 11:57:08,701 iteration 1346 : loss : 0.057126, loss_ce: 0.016253
2022-01-14 11:57:09,704 iteration 1347 : loss : 0.105315, loss_ce: 0.022057
2022-01-14 11:57:10,718 iteration 1348 : loss : 0.040945, loss_ce: 0.016015
2022-01-14 11:57:11,686 iteration 1349 : loss : 0.072170, loss_ce: 0.032257
2022-01-14 11:57:12,662 iteration 1350 : loss : 0.107191, loss_ce: 0.042248
2022-01-14 11:57:13,541 iteration 1351 : loss : 0.047231, loss_ce: 0.016083
2022-01-14 11:57:14,555 iteration 1352 : loss : 0.066679, loss_ce: 0.025468
2022-01-14 11:57:15,413 iteration 1353 : loss : 0.044464, loss_ce: 0.019076
2022-01-14 11:57:16,376 iteration 1354 : loss : 0.035518, loss_ce: 0.015667
2022-01-14 11:57:17,244 iteration 1355 : loss : 0.061233, loss_ce: 0.020530
2022-01-14 11:57:18,212 iteration 1356 : loss : 0.052197, loss_ce: 0.019736
2022-01-14 11:57:19,082 iteration 1357 : loss : 0.054255, loss_ce: 0.032516
2022-01-14 11:57:19,989 iteration 1358 : loss : 0.045727, loss_ce: 0.015370
2022-01-14 11:57:20,860 iteration 1359 : loss : 0.041418, loss_ce: 0.023488
2022-01-14 11:57:20,861 Training Data Eval:
2022-01-14 11:57:25,154   Average segmentation loss on training set: 0.0383
2022-01-14 11:57:25,154 Validation Data Eval:
2022-01-14 11:57:26,597   Average segmentation loss on validation set: 0.0698
2022-01-14 11:57:27,806 Found new lowest validation loss at iteration 1359! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_1BLOCK_best_val_loss_seed2.pth
2022-01-14 11:57:28,719 iteration 1360 : loss : 0.073463, loss_ce: 0.028973
 20%|██████                        | 80/400 [22:54<1:38:07, 18.40s/it]2022-01-14 11:57:29,745 iteration 1361 : loss : 0.093342, loss_ce: 0.030827
2022-01-14 11:57:30,675 iteration 1362 : loss : 0.042498, loss_ce: 0.018564
2022-01-14 11:57:31,652 iteration 1363 : loss : 0.034931, loss_ce: 0.012895
2022-01-14 11:57:32,652 iteration 1364 : loss : 0.063928, loss_ce: 0.020027
2022-01-14 11:57:33,671 iteration 1365 : loss : 0.051648, loss_ce: 0.018140
2022-01-14 11:57:34,619 iteration 1366 : loss : 0.054211, loss_ce: 0.024605
2022-01-14 11:57:35,495 iteration 1367 : loss : 0.044235, loss_ce: 0.020519
2022-01-14 11:57:36,443 iteration 1368 : loss : 0.076290, loss_ce: 0.034135
2022-01-14 11:57:37,357 iteration 1369 : loss : 0.064431, loss_ce: 0.018422
2022-01-14 11:57:38,300 iteration 1370 : loss : 0.046766, loss_ce: 0.016768
2022-01-14 11:57:39,151 iteration 1371 : loss : 0.040083, loss_ce: 0.016552
2022-01-14 11:57:40,106 iteration 1372 : loss : 0.074948, loss_ce: 0.024829
2022-01-14 11:57:41,160 iteration 1373 : loss : 0.063638, loss_ce: 0.032011
2022-01-14 11:57:42,082 iteration 1374 : loss : 0.058629, loss_ce: 0.019785
2022-01-14 11:57:43,048 iteration 1375 : loss : 0.040926, loss_ce: 0.016785
2022-01-14 11:57:43,896 iteration 1376 : loss : 0.038709, loss_ce: 0.016431
2022-01-14 11:57:44,876 iteration 1377 : loss : 0.072591, loss_ce: 0.027468
 20%|██████                        | 81/400 [23:10<1:34:15, 17.73s/it]2022-01-14 11:57:45,950 iteration 1378 : loss : 0.046511, loss_ce: 0.023194
2022-01-14 11:57:46,959 iteration 1379 : loss : 0.071937, loss_ce: 0.022091
2022-01-14 11:57:47,881 iteration 1380 : loss : 0.040205, loss_ce: 0.019476
2022-01-14 11:57:48,839 iteration 1381 : loss : 0.054865, loss_ce: 0.026665
2022-01-14 11:57:49,769 iteration 1382 : loss : 0.049762, loss_ce: 0.021050
2022-01-14 11:57:50,701 iteration 1383 : loss : 0.057949, loss_ce: 0.015506
2022-01-14 11:57:51,726 iteration 1384 : loss : 0.066841, loss_ce: 0.029153
2022-01-14 11:57:52,584 iteration 1385 : loss : 0.036865, loss_ce: 0.013877
2022-01-14 11:57:53,589 iteration 1386 : loss : 0.049327, loss_ce: 0.023977
2022-01-14 11:57:54,486 iteration 1387 : loss : 0.060535, loss_ce: 0.019528
2022-01-14 11:57:55,484 iteration 1388 : loss : 0.052601, loss_ce: 0.019177
2022-01-14 11:57:56,450 iteration 1389 : loss : 0.061384, loss_ce: 0.032606
2022-01-14 11:57:57,314 iteration 1390 : loss : 0.046592, loss_ce: 0.021559
2022-01-14 11:57:58,277 iteration 1391 : loss : 0.062144, loss_ce: 0.018338
2022-01-14 11:57:59,208 iteration 1392 : loss : 0.047343, loss_ce: 0.022660
2022-01-14 11:58:00,130 iteration 1393 : loss : 0.071650, loss_ce: 0.025517
2022-01-14 11:58:01,064 iteration 1394 : loss : 0.048615, loss_ce: 0.013883
 20%|██████▏                       | 82/400 [23:26<1:31:30, 17.26s/it]2022-01-14 11:58:02,123 iteration 1395 : loss : 0.051533, loss_ce: 0.026372
2022-01-14 11:58:02,968 iteration 1396 : loss : 0.048894, loss_ce: 0.022774
2022-01-14 11:58:03,960 iteration 1397 : loss : 0.045955, loss_ce: 0.018818
2022-01-14 11:58:04,803 iteration 1398 : loss : 0.032591, loss_ce: 0.013574
2022-01-14 11:58:05,759 iteration 1399 : loss : 0.038978, loss_ce: 0.017106
2022-01-14 11:58:06,739 iteration 1400 : loss : 0.049914, loss_ce: 0.018887
2022-01-14 11:58:07,642 iteration 1401 : loss : 0.033749, loss_ce: 0.011434
2022-01-14 11:58:08,655 iteration 1402 : loss : 0.044895, loss_ce: 0.015969
2022-01-14 11:58:09,587 iteration 1403 : loss : 0.044225, loss_ce: 0.015371
2022-01-14 11:58:10,607 iteration 1404 : loss : 0.053032, loss_ce: 0.020402
2022-01-14 11:58:11,381 iteration 1405 : loss : 0.037617, loss_ce: 0.012796
2022-01-14 11:58:12,340 iteration 1406 : loss : 0.047261, loss_ce: 0.015491
2022-01-14 11:58:13,239 iteration 1407 : loss : 0.051630, loss_ce: 0.021751
2022-01-14 11:58:14,115 iteration 1408 : loss : 0.052226, loss_ce: 0.022900
2022-01-14 11:58:15,103 iteration 1409 : loss : 0.054019, loss_ce: 0.017251
2022-01-14 11:58:15,992 iteration 1410 : loss : 0.080058, loss_ce: 0.042376
2022-01-14 11:58:16,842 iteration 1411 : loss : 0.032814, loss_ce: 0.013152
 21%|██████▏                       | 83/400 [23:42<1:28:51, 16.82s/it]2022-01-14 11:58:17,833 iteration 1412 : loss : 0.054239, loss_ce: 0.029299
2022-01-14 11:58:18,688 iteration 1413 : loss : 0.034394, loss_ce: 0.012222
2022-01-14 11:58:19,649 iteration 1414 : loss : 0.035131, loss_ce: 0.014596
2022-01-14 11:58:20,508 iteration 1415 : loss : 0.046431, loss_ce: 0.016629
2022-01-14 11:58:21,433 iteration 1416 : loss : 0.039987, loss_ce: 0.014488
2022-01-14 11:58:22,357 iteration 1417 : loss : 0.077211, loss_ce: 0.030826
2022-01-14 11:58:23,296 iteration 1418 : loss : 0.046246, loss_ce: 0.014780
2022-01-14 11:58:24,146 iteration 1419 : loss : 0.040857, loss_ce: 0.016511
2022-01-14 11:58:25,054 iteration 1420 : loss : 0.045241, loss_ce: 0.013090
2022-01-14 11:58:25,969 iteration 1421 : loss : 0.067886, loss_ce: 0.033369
2022-01-14 11:58:26,920 iteration 1422 : loss : 0.060484, loss_ce: 0.025207
2022-01-14 11:58:27,815 iteration 1423 : loss : 0.049177, loss_ce: 0.017736
2022-01-14 11:58:28,650 iteration 1424 : loss : 0.031571, loss_ce: 0.013066
2022-01-14 11:58:29,592 iteration 1425 : loss : 0.062586, loss_ce: 0.021506
2022-01-14 11:58:30,544 iteration 1426 : loss : 0.046920, loss_ce: 0.026222
2022-01-14 11:58:31,472 iteration 1427 : loss : 0.099248, loss_ce: 0.019932
2022-01-14 11:58:32,529 iteration 1428 : loss : 0.057325, loss_ce: 0.021829
 21%|██████▎                       | 84/400 [23:58<1:26:47, 16.48s/it]2022-01-14 11:58:33,549 iteration 1429 : loss : 0.060736, loss_ce: 0.031636
2022-01-14 11:58:34,461 iteration 1430 : loss : 0.038881, loss_ce: 0.015304
2022-01-14 11:58:35,337 iteration 1431 : loss : 0.065006, loss_ce: 0.020452
2022-01-14 11:58:36,267 iteration 1432 : loss : 0.042308, loss_ce: 0.018050
2022-01-14 11:58:37,126 iteration 1433 : loss : 0.040874, loss_ce: 0.018068
2022-01-14 11:58:38,152 iteration 1434 : loss : 0.049053, loss_ce: 0.020316
2022-01-14 11:58:39,130 iteration 1435 : loss : 0.044846, loss_ce: 0.017484
2022-01-14 11:58:40,097 iteration 1436 : loss : 0.053090, loss_ce: 0.027883
2022-01-14 11:58:41,031 iteration 1437 : loss : 0.038818, loss_ce: 0.016776
2022-01-14 11:58:41,932 iteration 1438 : loss : 0.046900, loss_ce: 0.017942
2022-01-14 11:58:42,881 iteration 1439 : loss : 0.064306, loss_ce: 0.021261
2022-01-14 11:58:43,753 iteration 1440 : loss : 0.045113, loss_ce: 0.015230
2022-01-14 11:58:44,698 iteration 1441 : loss : 0.068023, loss_ce: 0.026584
2022-01-14 11:58:45,620 iteration 1442 : loss : 0.045542, loss_ce: 0.014852
2022-01-14 11:58:46,613 iteration 1443 : loss : 0.046375, loss_ce: 0.017040
2022-01-14 11:58:47,538 iteration 1444 : loss : 0.050608, loss_ce: 0.013002
2022-01-14 11:58:47,539 Training Data Eval:
2022-01-14 11:58:51,837   Average segmentation loss on training set: 0.0315
2022-01-14 11:58:51,838 Validation Data Eval:
2022-01-14 11:58:53,288   Average segmentation loss on validation set: 0.0729
2022-01-14 11:58:54,234 iteration 1445 : loss : 0.057637, loss_ce: 0.025697
 21%|██████▍                       | 85/400 [24:20<1:34:45, 18.05s/it]2022-01-14 11:58:55,140 iteration 1446 : loss : 0.039621, loss_ce: 0.014409
2022-01-14 11:58:55,983 iteration 1447 : loss : 0.038243, loss_ce: 0.016564
2022-01-14 11:58:56,952 iteration 1448 : loss : 0.043287, loss_ce: 0.012969
2022-01-14 11:58:57,931 iteration 1449 : loss : 0.058753, loss_ce: 0.021643
2022-01-14 11:58:58,837 iteration 1450 : loss : 0.039590, loss_ce: 0.015161
2022-01-14 11:58:59,791 iteration 1451 : loss : 0.032792, loss_ce: 0.010125
2022-01-14 11:59:00,713 iteration 1452 : loss : 0.054417, loss_ce: 0.032176
2022-01-14 11:59:01,668 iteration 1453 : loss : 0.038311, loss_ce: 0.016517
2022-01-14 11:59:02,605 iteration 1454 : loss : 0.056569, loss_ce: 0.018520
2022-01-14 11:59:03,563 iteration 1455 : loss : 0.043593, loss_ce: 0.014971
2022-01-14 11:59:04,450 iteration 1456 : loss : 0.043107, loss_ce: 0.014559
2022-01-14 11:59:05,445 iteration 1457 : loss : 0.045242, loss_ce: 0.018516
2022-01-14 11:59:06,401 iteration 1458 : loss : 0.033494, loss_ce: 0.014366
2022-01-14 11:59:07,298 iteration 1459 : loss : 0.044010, loss_ce: 0.013800
2022-01-14 11:59:08,222 iteration 1460 : loss : 0.036822, loss_ce: 0.013858
2022-01-14 11:59:09,093 iteration 1461 : loss : 0.045529, loss_ce: 0.018430
2022-01-14 11:59:10,075 iteration 1462 : loss : 0.049261, loss_ce: 0.022987
 22%|██████▍                       | 86/400 [24:35<1:30:59, 17.39s/it]2022-01-14 11:59:11,184 iteration 1463 : loss : 0.075241, loss_ce: 0.022785
2022-01-14 11:59:12,075 iteration 1464 : loss : 0.042235, loss_ce: 0.021397
2022-01-14 11:59:13,146 iteration 1465 : loss : 0.050880, loss_ce: 0.018755
2022-01-14 11:59:14,091 iteration 1466 : loss : 0.044092, loss_ce: 0.016957
2022-01-14 11:59:14,985 iteration 1467 : loss : 0.057472, loss_ce: 0.023290
2022-01-14 11:59:15,904 iteration 1468 : loss : 0.060713, loss_ce: 0.028884
2022-01-14 11:59:16,829 iteration 1469 : loss : 0.066446, loss_ce: 0.025466
2022-01-14 11:59:17,698 iteration 1470 : loss : 0.066201, loss_ce: 0.013732
2022-01-14 11:59:18,626 iteration 1471 : loss : 0.038087, loss_ce: 0.015499
2022-01-14 11:59:19,563 iteration 1472 : loss : 0.057202, loss_ce: 0.021387
2022-01-14 11:59:20,448 iteration 1473 : loss : 0.034141, loss_ce: 0.017288
2022-01-14 11:59:21,410 iteration 1474 : loss : 0.077064, loss_ce: 0.023331
2022-01-14 11:59:22,311 iteration 1475 : loss : 0.048568, loss_ce: 0.022255
2022-01-14 11:59:23,225 iteration 1476 : loss : 0.036659, loss_ce: 0.015265
2022-01-14 11:59:24,238 iteration 1477 : loss : 0.050974, loss_ce: 0.024959
2022-01-14 11:59:25,127 iteration 1478 : loss : 0.061578, loss_ce: 0.019850
2022-01-14 11:59:26,067 iteration 1479 : loss : 0.063852, loss_ce: 0.021584
 22%|██████▌                       | 87/400 [24:51<1:28:31, 16.97s/it]2022-01-14 11:59:26,933 iteration 1480 : loss : 0.031782, loss_ce: 0.012140
2022-01-14 11:59:27,975 iteration 1481 : loss : 0.043862, loss_ce: 0.018119
2022-01-14 11:59:28,901 iteration 1482 : loss : 0.040875, loss_ce: 0.018153
2022-01-14 11:59:29,897 iteration 1483 : loss : 0.048512, loss_ce: 0.020434
2022-01-14 11:59:30,870 iteration 1484 : loss : 0.035225, loss_ce: 0.010649
2022-01-14 11:59:31,826 iteration 1485 : loss : 0.033419, loss_ce: 0.015407
2022-01-14 11:59:32,743 iteration 1486 : loss : 0.046366, loss_ce: 0.016091
2022-01-14 11:59:33,669 iteration 1487 : loss : 0.035099, loss_ce: 0.012570
2022-01-14 11:59:34,534 iteration 1488 : loss : 0.049857, loss_ce: 0.021314
2022-01-14 11:59:35,419 iteration 1489 : loss : 0.042811, loss_ce: 0.018343
2022-01-14 11:59:36,380 iteration 1490 : loss : 0.045238, loss_ce: 0.016760
2022-01-14 11:59:37,199 iteration 1491 : loss : 0.057150, loss_ce: 0.017896
2022-01-14 11:59:38,064 iteration 1492 : loss : 0.039138, loss_ce: 0.016508
2022-01-14 11:59:39,034 iteration 1493 : loss : 0.052506, loss_ce: 0.022075
2022-01-14 11:59:39,949 iteration 1494 : loss : 0.051124, loss_ce: 0.019543
2022-01-14 11:59:40,797 iteration 1495 : loss : 0.033420, loss_ce: 0.008900
2022-01-14 11:59:41,767 iteration 1496 : loss : 0.040402, loss_ce: 0.019578
 22%|██████▌                       | 88/400 [25:07<1:26:15, 16.59s/it]2022-01-14 11:59:42,679 iteration 1497 : loss : 0.030966, loss_ce: 0.012632
2022-01-14 11:59:43,622 iteration 1498 : loss : 0.046015, loss_ce: 0.018855
2022-01-14 11:59:44,484 iteration 1499 : loss : 0.047290, loss_ce: 0.019100
2022-01-14 11:59:45,405 iteration 1500 : loss : 0.055505, loss_ce: 0.030084
2022-01-14 11:59:46,313 iteration 1501 : loss : 0.048424, loss_ce: 0.021412
2022-01-14 11:59:47,301 iteration 1502 : loss : 0.055286, loss_ce: 0.013219
2022-01-14 11:59:48,373 iteration 1503 : loss : 0.093451, loss_ce: 0.030979
2022-01-14 11:59:49,283 iteration 1504 : loss : 0.032190, loss_ce: 0.013741
2022-01-14 11:59:50,251 iteration 1505 : loss : 0.040757, loss_ce: 0.018305
2022-01-14 11:59:51,209 iteration 1506 : loss : 0.046090, loss_ce: 0.021517
2022-01-14 11:59:52,181 iteration 1507 : loss : 0.055311, loss_ce: 0.016643
2022-01-14 11:59:53,148 iteration 1508 : loss : 0.040525, loss_ce: 0.019813
2022-01-14 11:59:54,084 iteration 1509 : loss : 0.066011, loss_ce: 0.028527
2022-01-14 11:59:55,081 iteration 1510 : loss : 0.056183, loss_ce: 0.018826
2022-01-14 11:59:56,096 iteration 1511 : loss : 0.044192, loss_ce: 0.017787
2022-01-14 11:59:57,041 iteration 1512 : loss : 0.049650, loss_ce: 0.014504
2022-01-14 11:59:57,971 iteration 1513 : loss : 0.036104, loss_ce: 0.012994
 22%|██████▋                       | 89/400 [25:23<1:25:22, 16.47s/it]2022-01-14 11:59:59,018 iteration 1514 : loss : 0.040562, loss_ce: 0.014029
2022-01-14 11:59:59,895 iteration 1515 : loss : 0.036726, loss_ce: 0.014532
2022-01-14 12:00:00,833 iteration 1516 : loss : 0.045224, loss_ce: 0.017512
2022-01-14 12:00:01,678 iteration 1517 : loss : 0.037332, loss_ce: 0.013406
2022-01-14 12:00:02,645 iteration 1518 : loss : 0.041735, loss_ce: 0.014592
2022-01-14 12:00:03,656 iteration 1519 : loss : 0.042432, loss_ce: 0.014314
2022-01-14 12:00:04,637 iteration 1520 : loss : 0.047188, loss_ce: 0.020046
2022-01-14 12:00:05,593 iteration 1521 : loss : 0.054297, loss_ce: 0.016188
2022-01-14 12:00:06,489 iteration 1522 : loss : 0.057838, loss_ce: 0.030171
2022-01-14 12:00:07,389 iteration 1523 : loss : 0.056575, loss_ce: 0.015744
2022-01-14 12:00:08,314 iteration 1524 : loss : 0.039346, loss_ce: 0.014883
2022-01-14 12:00:09,172 iteration 1525 : loss : 0.046240, loss_ce: 0.022065
2022-01-14 12:00:10,138 iteration 1526 : loss : 0.061396, loss_ce: 0.029027
2022-01-14 12:00:11,115 iteration 1527 : loss : 0.038475, loss_ce: 0.018063
2022-01-14 12:00:11,984 iteration 1528 : loss : 0.041545, loss_ce: 0.018301
2022-01-14 12:00:12,865 iteration 1529 : loss : 0.046602, loss_ce: 0.018086
2022-01-14 12:00:12,865 Training Data Eval:
2022-01-14 12:00:17,159   Average segmentation loss on training set: 0.0339
2022-01-14 12:00:17,160 Validation Data Eval:
2022-01-14 12:00:18,619   Average segmentation loss on validation set: 0.0653
2022-01-14 12:00:19,832 Found new lowest validation loss at iteration 1529! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_1BLOCK_best_val_loss_seed2.pth
2022-01-14 12:00:20,768 iteration 1530 : loss : 0.058825, loss_ce: 0.027117
 22%|██████▊                       | 90/400 [25:46<1:34:54, 18.37s/it]2022-01-14 12:00:21,773 iteration 1531 : loss : 0.041433, loss_ce: 0.018309
2022-01-14 12:00:22,696 iteration 1532 : loss : 0.047689, loss_ce: 0.017544
2022-01-14 12:00:23,568 iteration 1533 : loss : 0.040554, loss_ce: 0.015283
2022-01-14 12:00:24,470 iteration 1534 : loss : 0.042657, loss_ce: 0.019628
2022-01-14 12:00:25,464 iteration 1535 : loss : 0.036115, loss_ce: 0.014855
2022-01-14 12:00:26,423 iteration 1536 : loss : 0.055572, loss_ce: 0.027625
2022-01-14 12:00:27,346 iteration 1537 : loss : 0.039430, loss_ce: 0.012609
2022-01-14 12:00:28,322 iteration 1538 : loss : 0.057655, loss_ce: 0.024287
2022-01-14 12:00:29,243 iteration 1539 : loss : 0.030953, loss_ce: 0.012761
2022-01-14 12:00:30,161 iteration 1540 : loss : 0.050682, loss_ce: 0.022576
2022-01-14 12:00:31,040 iteration 1541 : loss : 0.033494, loss_ce: 0.014690
2022-01-14 12:00:31,906 iteration 1542 : loss : 0.031790, loss_ce: 0.014080
2022-01-14 12:00:32,803 iteration 1543 : loss : 0.062521, loss_ce: 0.020753
2022-01-14 12:00:33,644 iteration 1544 : loss : 0.037965, loss_ce: 0.015903
2022-01-14 12:00:34,695 iteration 1545 : loss : 0.045686, loss_ce: 0.016577
2022-01-14 12:00:35,567 iteration 1546 : loss : 0.065002, loss_ce: 0.016803
2022-01-14 12:00:36,583 iteration 1547 : loss : 0.033653, loss_ce: 0.012614
 23%|██████▊                       | 91/400 [26:02<1:30:39, 17.60s/it]2022-01-14 12:00:37,592 iteration 1548 : loss : 0.049077, loss_ce: 0.021165
2022-01-14 12:00:38,427 iteration 1549 : loss : 0.033000, loss_ce: 0.013906
2022-01-14 12:00:39,306 iteration 1550 : loss : 0.049022, loss_ce: 0.020076
2022-01-14 12:00:40,120 iteration 1551 : loss : 0.036700, loss_ce: 0.013012
2022-01-14 12:00:41,061 iteration 1552 : loss : 0.034279, loss_ce: 0.011506
2022-01-14 12:00:42,026 iteration 1553 : loss : 0.068953, loss_ce: 0.026233
2022-01-14 12:00:42,988 iteration 1554 : loss : 0.034448, loss_ce: 0.013940
2022-01-14 12:00:43,896 iteration 1555 : loss : 0.049022, loss_ce: 0.020127
2022-01-14 12:00:44,863 iteration 1556 : loss : 0.036140, loss_ce: 0.011360
2022-01-14 12:00:45,768 iteration 1557 : loss : 0.040219, loss_ce: 0.015724
2022-01-14 12:00:46,672 iteration 1558 : loss : 0.044363, loss_ce: 0.020511
2022-01-14 12:00:47,607 iteration 1559 : loss : 0.048514, loss_ce: 0.018320
2022-01-14 12:00:48,476 iteration 1560 : loss : 0.036649, loss_ce: 0.017491
2022-01-14 12:00:49,433 iteration 1561 : loss : 0.045390, loss_ce: 0.017558
2022-01-14 12:00:50,319 iteration 1562 : loss : 0.059052, loss_ce: 0.014885
2022-01-14 12:00:51,296 iteration 1563 : loss : 0.048893, loss_ce: 0.021420
2022-01-14 12:00:52,269 iteration 1564 : loss : 0.039669, loss_ce: 0.016287
 23%|██████▉                       | 92/400 [26:18<1:27:23, 17.03s/it]2022-01-14 12:00:53,209 iteration 1565 : loss : 0.041084, loss_ce: 0.019026
2022-01-14 12:00:54,135 iteration 1566 : loss : 0.036787, loss_ce: 0.013891
2022-01-14 12:00:55,079 iteration 1567 : loss : 0.039536, loss_ce: 0.013232
2022-01-14 12:00:55,979 iteration 1568 : loss : 0.050645, loss_ce: 0.016836
2022-01-14 12:00:56,934 iteration 1569 : loss : 0.044020, loss_ce: 0.021560
2022-01-14 12:00:57,869 iteration 1570 : loss : 0.036433, loss_ce: 0.018602
2022-01-14 12:00:58,738 iteration 1571 : loss : 0.066920, loss_ce: 0.018163
2022-01-14 12:00:59,734 iteration 1572 : loss : 0.060191, loss_ce: 0.018139
2022-01-14 12:01:00,658 iteration 1573 : loss : 0.051890, loss_ce: 0.024692
2022-01-14 12:01:01,537 iteration 1574 : loss : 0.026506, loss_ce: 0.012798
2022-01-14 12:01:02,345 iteration 1575 : loss : 0.049344, loss_ce: 0.019392
2022-01-14 12:01:03,250 iteration 1576 : loss : 0.040660, loss_ce: 0.018152
2022-01-14 12:01:04,147 iteration 1577 : loss : 0.030970, loss_ce: 0.012962
2022-01-14 12:01:05,066 iteration 1578 : loss : 0.061671, loss_ce: 0.023229
2022-01-14 12:01:06,034 iteration 1579 : loss : 0.029708, loss_ce: 0.011578
2022-01-14 12:01:06,916 iteration 1580 : loss : 0.044872, loss_ce: 0.018007
2022-01-14 12:01:07,829 iteration 1581 : loss : 0.054185, loss_ce: 0.019996
 23%|██████▉                       | 93/400 [26:33<1:24:52, 16.59s/it]2022-01-14 12:01:08,856 iteration 1582 : loss : 0.039069, loss_ce: 0.013729
2022-01-14 12:01:09,766 iteration 1583 : loss : 0.042708, loss_ce: 0.012670
2022-01-14 12:01:10,734 iteration 1584 : loss : 0.045064, loss_ce: 0.022516
2022-01-14 12:01:11,655 iteration 1585 : loss : 0.039548, loss_ce: 0.015818
2022-01-14 12:01:12,560 iteration 1586 : loss : 0.045316, loss_ce: 0.018368
2022-01-14 12:01:13,373 iteration 1587 : loss : 0.032579, loss_ce: 0.014133
2022-01-14 12:01:14,336 iteration 1588 : loss : 0.046675, loss_ce: 0.021682
2022-01-14 12:01:15,261 iteration 1589 : loss : 0.043062, loss_ce: 0.017902
2022-01-14 12:01:16,328 iteration 1590 : loss : 0.080324, loss_ce: 0.027626
2022-01-14 12:01:17,211 iteration 1591 : loss : 0.033344, loss_ce: 0.011950
2022-01-14 12:01:18,141 iteration 1592 : loss : 0.055405, loss_ce: 0.020021
2022-01-14 12:01:19,176 iteration 1593 : loss : 0.048955, loss_ce: 0.020338
2022-01-14 12:01:20,193 iteration 1594 : loss : 0.059927, loss_ce: 0.020615
2022-01-14 12:01:21,109 iteration 1595 : loss : 0.035738, loss_ce: 0.013263
2022-01-14 12:01:22,037 iteration 1596 : loss : 0.067932, loss_ce: 0.035352
2022-01-14 12:01:22,965 iteration 1597 : loss : 0.086076, loss_ce: 0.042472
2022-01-14 12:01:23,929 iteration 1598 : loss : 0.046964, loss_ce: 0.019424
 24%|███████                       | 94/400 [26:49<1:23:51, 16.44s/it]2022-01-14 12:01:24,881 iteration 1599 : loss : 0.032038, loss_ce: 0.012990
2022-01-14 12:01:25,819 iteration 1600 : loss : 0.039704, loss_ce: 0.016752
2022-01-14 12:01:26,812 iteration 1601 : loss : 0.041343, loss_ce: 0.016092
2022-01-14 12:01:27,890 iteration 1602 : loss : 0.054635, loss_ce: 0.021974
2022-01-14 12:01:28,816 iteration 1603 : loss : 0.037409, loss_ce: 0.014510
2022-01-14 12:01:29,705 iteration 1604 : loss : 0.040533, loss_ce: 0.015608
2022-01-14 12:01:30,688 iteration 1605 : loss : 0.057033, loss_ce: 0.021486
2022-01-14 12:01:31,595 iteration 1606 : loss : 0.039438, loss_ce: 0.018178
2022-01-14 12:01:32,477 iteration 1607 : loss : 0.031209, loss_ce: 0.012619
2022-01-14 12:01:33,491 iteration 1608 : loss : 0.038340, loss_ce: 0.013644
2022-01-14 12:01:34,413 iteration 1609 : loss : 0.042512, loss_ce: 0.021612
2022-01-14 12:01:35,369 iteration 1610 : loss : 0.044689, loss_ce: 0.019062
2022-01-14 12:01:36,398 iteration 1611 : loss : 0.057383, loss_ce: 0.018289
2022-01-14 12:01:37,326 iteration 1612 : loss : 0.033342, loss_ce: 0.015485
2022-01-14 12:01:38,102 iteration 1613 : loss : 0.046295, loss_ce: 0.020604
2022-01-14 12:01:39,066 iteration 1614 : loss : 0.044511, loss_ce: 0.013232
2022-01-14 12:01:39,066 Training Data Eval:
2022-01-14 12:01:43,359   Average segmentation loss on training set: 0.0298
2022-01-14 12:01:43,360 Validation Data Eval:
2022-01-14 12:01:44,814   Average segmentation loss on validation set: 0.0690
2022-01-14 12:01:45,765 iteration 1615 : loss : 0.034837, loss_ce: 0.013369
 24%|███████▏                      | 95/400 [27:11<1:31:48, 18.06s/it]2022-01-14 12:01:46,773 iteration 1616 : loss : 0.040198, loss_ce: 0.013535
2022-01-14 12:01:47,736 iteration 1617 : loss : 0.041861, loss_ce: 0.012963
2022-01-14 12:01:48,581 iteration 1618 : loss : 0.036067, loss_ce: 0.015377
2022-01-14 12:01:49,430 iteration 1619 : loss : 0.031786, loss_ce: 0.010088
2022-01-14 12:01:50,265 iteration 1620 : loss : 0.036501, loss_ce: 0.009654
2022-01-14 12:01:51,205 iteration 1621 : loss : 0.051422, loss_ce: 0.032332
2022-01-14 12:01:52,236 iteration 1622 : loss : 0.042296, loss_ce: 0.015148
2022-01-14 12:01:53,157 iteration 1623 : loss : 0.084800, loss_ce: 0.044140
2022-01-14 12:01:54,041 iteration 1624 : loss : 0.036390, loss_ce: 0.013531
2022-01-14 12:01:54,945 iteration 1625 : loss : 0.034865, loss_ce: 0.014229
2022-01-14 12:01:55,840 iteration 1626 : loss : 0.035200, loss_ce: 0.016077
2022-01-14 12:01:56,752 iteration 1627 : loss : 0.047997, loss_ce: 0.018830
2022-01-14 12:01:57,759 iteration 1628 : loss : 0.041896, loss_ce: 0.018569
2022-01-14 12:01:58,670 iteration 1629 : loss : 0.030601, loss_ce: 0.011337
2022-01-14 12:01:59,527 iteration 1630 : loss : 0.036960, loss_ce: 0.014158
2022-01-14 12:02:00,587 iteration 1631 : loss : 0.044619, loss_ce: 0.020565
2022-01-14 12:02:01,597 iteration 1632 : loss : 0.042907, loss_ce: 0.015539
 24%|███████▏                      | 96/400 [27:27<1:28:05, 17.39s/it]2022-01-14 12:02:02,623 iteration 1633 : loss : 0.036237, loss_ce: 0.014029
2022-01-14 12:02:03,584 iteration 1634 : loss : 0.046482, loss_ce: 0.016563
2022-01-14 12:02:04,524 iteration 1635 : loss : 0.030881, loss_ce: 0.014622
2022-01-14 12:02:05,537 iteration 1636 : loss : 0.046465, loss_ce: 0.022674
2022-01-14 12:02:06,488 iteration 1637 : loss : 0.050560, loss_ce: 0.022374
2022-01-14 12:02:07,399 iteration 1638 : loss : 0.035673, loss_ce: 0.015262
2022-01-14 12:02:08,434 iteration 1639 : loss : 0.058090, loss_ce: 0.013402
2022-01-14 12:02:09,390 iteration 1640 : loss : 0.062599, loss_ce: 0.017111
2022-01-14 12:02:10,250 iteration 1641 : loss : 0.033401, loss_ce: 0.016374
2022-01-14 12:02:11,160 iteration 1642 : loss : 0.032618, loss_ce: 0.011461
2022-01-14 12:02:12,120 iteration 1643 : loss : 0.030541, loss_ce: 0.008700
2022-01-14 12:02:13,016 iteration 1644 : loss : 0.044121, loss_ce: 0.015754
2022-01-14 12:02:13,932 iteration 1645 : loss : 0.033242, loss_ce: 0.012151
2022-01-14 12:02:14,828 iteration 1646 : loss : 0.042685, loss_ce: 0.020097
2022-01-14 12:02:15,732 iteration 1647 : loss : 0.040919, loss_ce: 0.014357
2022-01-14 12:02:16,670 iteration 1648 : loss : 0.047710, loss_ce: 0.021310
2022-01-14 12:02:17,546 iteration 1649 : loss : 0.043516, loss_ce: 0.018429
 24%|███████▎                      | 97/400 [27:43<1:25:38, 16.96s/it]2022-01-14 12:02:18,565 iteration 1650 : loss : 0.033658, loss_ce: 0.013909
2022-01-14 12:02:19,630 iteration 1651 : loss : 0.059888, loss_ce: 0.020661
2022-01-14 12:02:20,504 iteration 1652 : loss : 0.068482, loss_ce: 0.029116
2022-01-14 12:02:21,370 iteration 1653 : loss : 0.037937, loss_ce: 0.013005
2022-01-14 12:02:22,342 iteration 1654 : loss : 0.075908, loss_ce: 0.019637
2022-01-14 12:02:23,329 iteration 1655 : loss : 0.046330, loss_ce: 0.016361
2022-01-14 12:02:24,222 iteration 1656 : loss : 0.045230, loss_ce: 0.017495
2022-01-14 12:02:25,271 iteration 1657 : loss : 0.062133, loss_ce: 0.019930
2022-01-14 12:02:26,230 iteration 1658 : loss : 0.064361, loss_ce: 0.038204
2022-01-14 12:02:27,100 iteration 1659 : loss : 0.027263, loss_ce: 0.009620
2022-01-14 12:02:28,116 iteration 1660 : loss : 0.047365, loss_ce: 0.019017
2022-01-14 12:02:29,146 iteration 1661 : loss : 0.037487, loss_ce: 0.011728
2022-01-14 12:02:30,077 iteration 1662 : loss : 0.036886, loss_ce: 0.013962
2022-01-14 12:02:30,889 iteration 1663 : loss : 0.033358, loss_ce: 0.017862
2022-01-14 12:02:31,913 iteration 1664 : loss : 0.048219, loss_ce: 0.020258
2022-01-14 12:02:32,881 iteration 1665 : loss : 0.040493, loss_ce: 0.014429
2022-01-14 12:02:33,886 iteration 1666 : loss : 0.041864, loss_ce: 0.017897
 24%|███████▎                      | 98/400 [27:59<1:24:26, 16.78s/it]2022-01-14 12:02:34,915 iteration 1667 : loss : 0.060799, loss_ce: 0.017628
2022-01-14 12:02:35,840 iteration 1668 : loss : 0.050874, loss_ce: 0.014515
2022-01-14 12:02:36,728 iteration 1669 : loss : 0.036017, loss_ce: 0.014764
2022-01-14 12:02:37,660 iteration 1670 : loss : 0.043751, loss_ce: 0.021090
2022-01-14 12:02:38,583 iteration 1671 : loss : 0.036179, loss_ce: 0.013926
2022-01-14 12:02:39,584 iteration 1672 : loss : 0.036345, loss_ce: 0.014345
2022-01-14 12:02:40,523 iteration 1673 : loss : 0.044063, loss_ce: 0.018116
2022-01-14 12:02:41,532 iteration 1674 : loss : 0.041609, loss_ce: 0.022168
2022-01-14 12:02:42,436 iteration 1675 : loss : 0.039830, loss_ce: 0.011257
2022-01-14 12:02:43,360 iteration 1676 : loss : 0.063984, loss_ce: 0.022084
2022-01-14 12:02:44,377 iteration 1677 : loss : 0.055377, loss_ce: 0.026866
2022-01-14 12:02:45,186 iteration 1678 : loss : 0.039876, loss_ce: 0.017628
2022-01-14 12:02:46,064 iteration 1679 : loss : 0.032210, loss_ce: 0.008896
2022-01-14 12:02:47,031 iteration 1680 : loss : 0.035734, loss_ce: 0.017040
2022-01-14 12:02:47,971 iteration 1681 : loss : 0.042482, loss_ce: 0.027832
2022-01-14 12:02:48,944 iteration 1682 : loss : 0.036346, loss_ce: 0.012554
2022-01-14 12:02:49,809 iteration 1683 : loss : 0.028517, loss_ce: 0.009536
 25%|███████▍                      | 99/400 [28:15<1:22:52, 16.52s/it]2022-01-14 12:02:50,828 iteration 1684 : loss : 0.034966, loss_ce: 0.012071
2022-01-14 12:02:51,736 iteration 1685 : loss : 0.055870, loss_ce: 0.018285
2022-01-14 12:02:52,651 iteration 1686 : loss : 0.027174, loss_ce: 0.010218
2022-01-14 12:02:53,499 iteration 1687 : loss : 0.042803, loss_ce: 0.021708
2022-01-14 12:02:54,565 iteration 1688 : loss : 0.032298, loss_ce: 0.013281
2022-01-14 12:02:55,517 iteration 1689 : loss : 0.042803, loss_ce: 0.018070
2022-01-14 12:02:56,503 iteration 1690 : loss : 0.043745, loss_ce: 0.021962
2022-01-14 12:02:57,346 iteration 1691 : loss : 0.084546, loss_ce: 0.020556
2022-01-14 12:02:58,332 iteration 1692 : loss : 0.075254, loss_ce: 0.026852
2022-01-14 12:02:59,126 iteration 1693 : loss : 0.031368, loss_ce: 0.012927
2022-01-14 12:03:00,085 iteration 1694 : loss : 0.033009, loss_ce: 0.013980
2022-01-14 12:03:01,102 iteration 1695 : loss : 0.069111, loss_ce: 0.028969
2022-01-14 12:03:02,118 iteration 1696 : loss : 0.047970, loss_ce: 0.017254
2022-01-14 12:03:03,032 iteration 1697 : loss : 0.051130, loss_ce: 0.019387
2022-01-14 12:03:04,020 iteration 1698 : loss : 0.047231, loss_ce: 0.020470
2022-01-14 12:03:04,952 iteration 1699 : loss : 0.040774, loss_ce: 0.021287
2022-01-14 12:03:04,953 Training Data Eval:
2022-01-14 12:03:09,255   Average segmentation loss on training set: 0.0321
2022-01-14 12:03:09,256 Validation Data Eval:
2022-01-14 12:03:10,706   Average segmentation loss on validation set: 0.0690
2022-01-14 12:03:11,589 iteration 1700 : loss : 0.046704, loss_ce: 0.017582
 25%|███████▎                     | 100/400 [28:37<1:30:29, 18.10s/it]2022-01-14 12:03:12,588 iteration 1701 : loss : 0.033939, loss_ce: 0.014401
2022-01-14 12:03:13,494 iteration 1702 : loss : 0.043884, loss_ce: 0.018507
2022-01-14 12:03:14,499 iteration 1703 : loss : 0.047553, loss_ce: 0.021139
2022-01-14 12:03:15,492 iteration 1704 : loss : 0.054796, loss_ce: 0.022317
2022-01-14 12:03:16,413 iteration 1705 : loss : 0.049173, loss_ce: 0.017700
2022-01-14 12:03:17,392 iteration 1706 : loss : 0.053000, loss_ce: 0.016528
2022-01-14 12:03:18,298 iteration 1707 : loss : 0.050941, loss_ce: 0.020346
2022-01-14 12:03:19,213 iteration 1708 : loss : 0.037709, loss_ce: 0.014625
2022-01-14 12:03:20,311 iteration 1709 : loss : 0.048036, loss_ce: 0.018580
2022-01-14 12:03:21,195 iteration 1710 : loss : 0.033491, loss_ce: 0.015657
2022-01-14 12:03:22,131 iteration 1711 : loss : 0.053209, loss_ce: 0.018701
2022-01-14 12:03:23,082 iteration 1712 : loss : 0.045519, loss_ce: 0.015089
2022-01-14 12:03:24,009 iteration 1713 : loss : 0.047638, loss_ce: 0.016716
2022-01-14 12:03:24,920 iteration 1714 : loss : 0.029101, loss_ce: 0.011262
2022-01-14 12:03:25,919 iteration 1715 : loss : 0.055811, loss_ce: 0.021216
2022-01-14 12:03:26,812 iteration 1716 : loss : 0.054554, loss_ce: 0.017995
2022-01-14 12:03:27,767 iteration 1717 : loss : 0.029480, loss_ce: 0.012417
 25%|███████▎                     | 101/400 [28:53<1:27:19, 17.52s/it]2022-01-14 12:03:28,793 iteration 1718 : loss : 0.035035, loss_ce: 0.012842
2022-01-14 12:03:29,805 iteration 1719 : loss : 0.036865, loss_ce: 0.010010
2022-01-14 12:03:30,785 iteration 1720 : loss : 0.041831, loss_ce: 0.014734
2022-01-14 12:03:31,714 iteration 1721 : loss : 0.051941, loss_ce: 0.023609
2022-01-14 12:03:32,598 iteration 1722 : loss : 0.050953, loss_ce: 0.025471
2022-01-14 12:03:33,484 iteration 1723 : loss : 0.036722, loss_ce: 0.016029
2022-01-14 12:03:34,334 iteration 1724 : loss : 0.036500, loss_ce: 0.016235
2022-01-14 12:03:35,188 iteration 1725 : loss : 0.034564, loss_ce: 0.015588
2022-01-14 12:03:36,240 iteration 1726 : loss : 0.047131, loss_ce: 0.019015
2022-01-14 12:03:37,229 iteration 1727 : loss : 0.070116, loss_ce: 0.024764
2022-01-14 12:03:38,236 iteration 1728 : loss : 0.051126, loss_ce: 0.024110
2022-01-14 12:03:39,137 iteration 1729 : loss : 0.037519, loss_ce: 0.015484
2022-01-14 12:03:40,062 iteration 1730 : loss : 0.036955, loss_ce: 0.012935
2022-01-14 12:03:40,954 iteration 1731 : loss : 0.036801, loss_ce: 0.017532
2022-01-14 12:03:41,894 iteration 1732 : loss : 0.035384, loss_ce: 0.014516
2022-01-14 12:03:42,837 iteration 1733 : loss : 0.041698, loss_ce: 0.014535
2022-01-14 12:03:43,729 iteration 1734 : loss : 0.054873, loss_ce: 0.016439
 26%|███████▍                     | 102/400 [29:09<1:24:40, 17.05s/it]2022-01-14 12:03:44,791 iteration 1735 : loss : 0.028369, loss_ce: 0.009204
2022-01-14 12:03:45,712 iteration 1736 : loss : 0.041093, loss_ce: 0.014920
2022-01-14 12:03:46,671 iteration 1737 : loss : 0.060979, loss_ce: 0.035689
2022-01-14 12:03:47,608 iteration 1738 : loss : 0.030989, loss_ce: 0.011916
2022-01-14 12:03:48,528 iteration 1739 : loss : 0.066099, loss_ce: 0.034564
2022-01-14 12:03:49,436 iteration 1740 : loss : 0.059708, loss_ce: 0.014338
2022-01-14 12:03:50,465 iteration 1741 : loss : 0.041396, loss_ce: 0.014772
2022-01-14 12:03:51,419 iteration 1742 : loss : 0.043178, loss_ce: 0.015709
2022-01-14 12:03:52,350 iteration 1743 : loss : 0.047678, loss_ce: 0.029986
2022-01-14 12:03:53,222 iteration 1744 : loss : 0.046388, loss_ce: 0.016918
2022-01-14 12:03:54,223 iteration 1745 : loss : 0.077871, loss_ce: 0.043220
2022-01-14 12:03:55,136 iteration 1746 : loss : 0.052561, loss_ce: 0.018689
2022-01-14 12:03:56,052 iteration 1747 : loss : 0.075910, loss_ce: 0.027464
2022-01-14 12:03:56,917 iteration 1748 : loss : 0.031719, loss_ce: 0.015381
2022-01-14 12:03:57,880 iteration 1749 : loss : 0.046282, loss_ce: 0.017762
2022-01-14 12:03:58,745 iteration 1750 : loss : 0.052265, loss_ce: 0.028549
2022-01-14 12:03:59,630 iteration 1751 : loss : 0.046473, loss_ce: 0.017621
 26%|███████▍                     | 103/400 [29:25<1:22:42, 16.71s/it]2022-01-14 12:04:00,597 iteration 1752 : loss : 0.047624, loss_ce: 0.022761
2022-01-14 12:04:01,616 iteration 1753 : loss : 0.054031, loss_ce: 0.025754
2022-01-14 12:04:02,578 iteration 1754 : loss : 0.037987, loss_ce: 0.017285
2022-01-14 12:04:03,534 iteration 1755 : loss : 0.045387, loss_ce: 0.014817
2022-01-14 12:04:04,521 iteration 1756 : loss : 0.066075, loss_ce: 0.033567
2022-01-14 12:04:05,469 iteration 1757 : loss : 0.046889, loss_ce: 0.012512
2022-01-14 12:04:06,400 iteration 1758 : loss : 0.044671, loss_ce: 0.018099
2022-01-14 12:04:07,315 iteration 1759 : loss : 0.046657, loss_ce: 0.016254
2022-01-14 12:04:08,292 iteration 1760 : loss : 0.045635, loss_ce: 0.020561
2022-01-14 12:04:09,174 iteration 1761 : loss : 0.031380, loss_ce: 0.014704
2022-01-14 12:04:10,171 iteration 1762 : loss : 0.065101, loss_ce: 0.027632
2022-01-14 12:04:11,046 iteration 1763 : loss : 0.041602, loss_ce: 0.014769
2022-01-14 12:04:12,013 iteration 1764 : loss : 0.118642, loss_ce: 0.033910
2022-01-14 12:04:12,985 iteration 1765 : loss : 0.080817, loss_ce: 0.025918
2022-01-14 12:04:13,869 iteration 1766 : loss : 0.036340, loss_ce: 0.016110
2022-01-14 12:04:14,795 iteration 1767 : loss : 0.051650, loss_ce: 0.021756
2022-01-14 12:04:15,801 iteration 1768 : loss : 0.041074, loss_ce: 0.017173
 26%|███████▌                     | 104/400 [29:41<1:21:37, 16.55s/it]2022-01-14 12:04:16,771 iteration 1769 : loss : 0.042481, loss_ce: 0.013152
2022-01-14 12:04:17,901 iteration 1770 : loss : 0.060271, loss_ce: 0.023674
2022-01-14 12:04:18,808 iteration 1771 : loss : 0.050816, loss_ce: 0.020600
2022-01-14 12:04:19,693 iteration 1772 : loss : 0.030198, loss_ce: 0.008957
2022-01-14 12:04:20,542 iteration 1773 : loss : 0.038263, loss_ce: 0.011378
2022-01-14 12:04:21,475 iteration 1774 : loss : 0.028927, loss_ce: 0.012328
2022-01-14 12:04:22,475 iteration 1775 : loss : 0.048315, loss_ce: 0.022437
2022-01-14 12:04:23,399 iteration 1776 : loss : 0.073245, loss_ce: 0.019548
2022-01-14 12:04:24,301 iteration 1777 : loss : 0.038824, loss_ce: 0.014299
2022-01-14 12:04:25,218 iteration 1778 : loss : 0.044616, loss_ce: 0.014626
2022-01-14 12:04:26,155 iteration 1779 : loss : 0.041836, loss_ce: 0.015917
2022-01-14 12:04:27,062 iteration 1780 : loss : 0.047981, loss_ce: 0.017436
2022-01-14 12:04:27,965 iteration 1781 : loss : 0.044503, loss_ce: 0.023875
2022-01-14 12:04:28,922 iteration 1782 : loss : 0.042824, loss_ce: 0.015965
2022-01-14 12:04:29,805 iteration 1783 : loss : 0.043840, loss_ce: 0.020671
2022-01-14 12:04:30,818 iteration 1784 : loss : 0.032357, loss_ce: 0.012253
2022-01-14 12:04:30,818 Training Data Eval:
2022-01-14 12:04:35,134   Average segmentation loss on training set: 0.0292
2022-01-14 12:04:35,134 Validation Data Eval:
2022-01-14 12:04:36,595   Average segmentation loss on validation set: 0.0649
2022-01-14 12:04:37,779 Found new lowest validation loss at iteration 1784! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_1BLOCK_best_val_loss_seed2.pth
2022-01-14 12:04:38,702 iteration 1785 : loss : 0.050987, loss_ce: 0.019494
 26%|███████▌                     | 105/400 [30:04<1:30:43, 18.45s/it]2022-01-14 12:04:39,826 iteration 1786 : loss : 0.045540, loss_ce: 0.022505
2022-01-14 12:04:40,864 iteration 1787 : loss : 0.036694, loss_ce: 0.014588
2022-01-14 12:04:41,821 iteration 1788 : loss : 0.036922, loss_ce: 0.015744
2022-01-14 12:04:42,763 iteration 1789 : loss : 0.038206, loss_ce: 0.014275
2022-01-14 12:04:43,667 iteration 1790 : loss : 0.033854, loss_ce: 0.015670
2022-01-14 12:04:44,533 iteration 1791 : loss : 0.031236, loss_ce: 0.016033
2022-01-14 12:04:45,493 iteration 1792 : loss : 0.045164, loss_ce: 0.014772
2022-01-14 12:04:46,474 iteration 1793 : loss : 0.051895, loss_ce: 0.026217
2022-01-14 12:04:47,366 iteration 1794 : loss : 0.040986, loss_ce: 0.020521
2022-01-14 12:04:48,329 iteration 1795 : loss : 0.045997, loss_ce: 0.019556
2022-01-14 12:04:49,283 iteration 1796 : loss : 0.035902, loss_ce: 0.014233
2022-01-14 12:04:50,339 iteration 1797 : loss : 0.031931, loss_ce: 0.014642
2022-01-14 12:04:51,295 iteration 1798 : loss : 0.052826, loss_ce: 0.020129
2022-01-14 12:04:52,268 iteration 1799 : loss : 0.044135, loss_ce: 0.017722
2022-01-14 12:04:53,227 iteration 1800 : loss : 0.047506, loss_ce: 0.021122
2022-01-14 12:04:54,207 iteration 1801 : loss : 0.027435, loss_ce: 0.010418
2022-01-14 12:04:55,042 iteration 1802 : loss : 0.054694, loss_ce: 0.015927
 26%|███████▋                     | 106/400 [30:20<1:27:18, 17.82s/it]2022-01-14 12:04:56,069 iteration 1803 : loss : 0.034354, loss_ce: 0.012104
2022-01-14 12:04:56,970 iteration 1804 : loss : 0.057781, loss_ce: 0.018896
2022-01-14 12:04:57,836 iteration 1805 : loss : 0.044176, loss_ce: 0.021225
2022-01-14 12:04:58,706 iteration 1806 : loss : 0.052413, loss_ce: 0.018635
2022-01-14 12:04:59,650 iteration 1807 : loss : 0.049345, loss_ce: 0.016728
2022-01-14 12:05:00,599 iteration 1808 : loss : 0.040752, loss_ce: 0.016395
2022-01-14 12:05:01,521 iteration 1809 : loss : 0.038158, loss_ce: 0.015867
2022-01-14 12:05:02,467 iteration 1810 : loss : 0.039651, loss_ce: 0.016925
2022-01-14 12:05:03,432 iteration 1811 : loss : 0.055919, loss_ce: 0.019916
2022-01-14 12:05:04,460 iteration 1812 : loss : 0.053729, loss_ce: 0.023731
2022-01-14 12:05:05,430 iteration 1813 : loss : 0.072183, loss_ce: 0.023583
2022-01-14 12:05:06,464 iteration 1814 : loss : 0.054692, loss_ce: 0.021830
2022-01-14 12:05:07,424 iteration 1815 : loss : 0.041472, loss_ce: 0.019613
2022-01-14 12:05:08,399 iteration 1816 : loss : 0.057177, loss_ce: 0.020521
2022-01-14 12:05:09,343 iteration 1817 : loss : 0.035715, loss_ce: 0.013407
2022-01-14 12:05:10,350 iteration 1818 : loss : 0.031351, loss_ce: 0.016471
2022-01-14 12:05:11,265 iteration 1819 : loss : 0.034072, loss_ce: 0.014901
 27%|███████▊                     | 107/400 [30:37<1:24:39, 17.34s/it]2022-01-14 12:05:12,288 iteration 1820 : loss : 0.060023, loss_ce: 0.017763
2022-01-14 12:05:13,187 iteration 1821 : loss : 0.035592, loss_ce: 0.012477
2022-01-14 12:05:14,086 iteration 1822 : loss : 0.035822, loss_ce: 0.016973
2022-01-14 12:05:15,065 iteration 1823 : loss : 0.040123, loss_ce: 0.015749
2022-01-14 12:05:15,995 iteration 1824 : loss : 0.038012, loss_ce: 0.011944
2022-01-14 12:05:16,938 iteration 1825 : loss : 0.040924, loss_ce: 0.013961
2022-01-14 12:05:17,789 iteration 1826 : loss : 0.037889, loss_ce: 0.015823
2022-01-14 12:05:18,678 iteration 1827 : loss : 0.052538, loss_ce: 0.014426
2022-01-14 12:05:19,652 iteration 1828 : loss : 0.036620, loss_ce: 0.018384
2022-01-14 12:05:20,595 iteration 1829 : loss : 0.046417, loss_ce: 0.013689
2022-01-14 12:05:21,530 iteration 1830 : loss : 0.040652, loss_ce: 0.016903
2022-01-14 12:05:22,454 iteration 1831 : loss : 0.041535, loss_ce: 0.017656
2022-01-14 12:05:23,373 iteration 1832 : loss : 0.034381, loss_ce: 0.012212
2022-01-14 12:05:24,268 iteration 1833 : loss : 0.042877, loss_ce: 0.026787
2022-01-14 12:05:25,278 iteration 1834 : loss : 0.038796, loss_ce: 0.013574
2022-01-14 12:05:26,124 iteration 1835 : loss : 0.035937, loss_ce: 0.012177
2022-01-14 12:05:27,012 iteration 1836 : loss : 0.050712, loss_ce: 0.020377
 27%|███████▊                     | 108/400 [30:52<1:22:04, 16.87s/it]2022-01-14 12:05:27,930 iteration 1837 : loss : 0.062706, loss_ce: 0.011343
2022-01-14 12:05:28,934 iteration 1838 : loss : 0.044084, loss_ce: 0.020292
2022-01-14 12:05:29,787 iteration 1839 : loss : 0.038869, loss_ce: 0.016148
2022-01-14 12:05:30,729 iteration 1840 : loss : 0.052544, loss_ce: 0.013547
2022-01-14 12:05:31,663 iteration 1841 : loss : 0.045252, loss_ce: 0.015491
2022-01-14 12:05:32,684 iteration 1842 : loss : 0.038547, loss_ce: 0.015974
2022-01-14 12:05:33,599 iteration 1843 : loss : 0.038740, loss_ce: 0.016340
2022-01-14 12:05:34,534 iteration 1844 : loss : 0.042759, loss_ce: 0.019819
2022-01-14 12:05:35,459 iteration 1845 : loss : 0.035327, loss_ce: 0.015262
2022-01-14 12:05:36,400 iteration 1846 : loss : 0.046123, loss_ce: 0.013557
2022-01-14 12:05:37,239 iteration 1847 : loss : 0.031574, loss_ce: 0.011323
2022-01-14 12:05:38,189 iteration 1848 : loss : 0.039092, loss_ce: 0.012142
2022-01-14 12:05:39,119 iteration 1849 : loss : 0.038920, loss_ce: 0.014726
2022-01-14 12:05:40,071 iteration 1850 : loss : 0.038141, loss_ce: 0.013688
2022-01-14 12:05:41,056 iteration 1851 : loss : 0.038897, loss_ce: 0.015797
2022-01-14 12:05:41,889 iteration 1852 : loss : 0.036688, loss_ce: 0.020017
2022-01-14 12:05:42,851 iteration 1853 : loss : 0.040709, loss_ce: 0.019233
 27%|███████▉                     | 109/400 [31:08<1:20:17, 16.55s/it]2022-01-14 12:05:43,878 iteration 1854 : loss : 0.048014, loss_ce: 0.016235
2022-01-14 12:05:44,886 iteration 1855 : loss : 0.048923, loss_ce: 0.017307
2022-01-14 12:05:45,724 iteration 1856 : loss : 0.034518, loss_ce: 0.014684
2022-01-14 12:05:46,566 iteration 1857 : loss : 0.028162, loss_ce: 0.012497
2022-01-14 12:05:47,432 iteration 1858 : loss : 0.026921, loss_ce: 0.012891
2022-01-14 12:05:48,375 iteration 1859 : loss : 0.037178, loss_ce: 0.014212
2022-01-14 12:05:49,333 iteration 1860 : loss : 0.047361, loss_ce: 0.017704
2022-01-14 12:05:50,292 iteration 1861 : loss : 0.034313, loss_ce: 0.016500
2022-01-14 12:05:51,252 iteration 1862 : loss : 0.029537, loss_ce: 0.014449
2022-01-14 12:05:52,237 iteration 1863 : loss : 0.054637, loss_ce: 0.018827
2022-01-14 12:05:53,209 iteration 1864 : loss : 0.033570, loss_ce: 0.012512
2022-01-14 12:05:54,147 iteration 1865 : loss : 0.043340, loss_ce: 0.013179
2022-01-14 12:05:55,065 iteration 1866 : loss : 0.032827, loss_ce: 0.011540
2022-01-14 12:05:55,884 iteration 1867 : loss : 0.028132, loss_ce: 0.009122
2022-01-14 12:05:56,778 iteration 1868 : loss : 0.030552, loss_ce: 0.010346
2022-01-14 12:05:57,668 iteration 1869 : loss : 0.030971, loss_ce: 0.014371
2022-01-14 12:05:57,668 Training Data Eval:
2022-01-14 12:06:01,977   Average segmentation loss on training set: 0.0257
2022-01-14 12:06:01,977 Validation Data Eval:
2022-01-14 12:06:03,438   Average segmentation loss on validation set: 0.0700
2022-01-14 12:06:04,383 iteration 1870 : loss : 0.045280, loss_ce: 0.017459
 28%|███████▉                     | 110/400 [31:30<1:27:14, 18.05s/it]2022-01-14 12:06:05,406 iteration 1871 : loss : 0.037540, loss_ce: 0.009792
2022-01-14 12:06:06,391 iteration 1872 : loss : 0.029756, loss_ce: 0.009853
2022-01-14 12:06:07,365 iteration 1873 : loss : 0.047828, loss_ce: 0.015916
2022-01-14 12:06:08,348 iteration 1874 : loss : 0.034813, loss_ce: 0.012033
2022-01-14 12:06:09,226 iteration 1875 : loss : 0.026654, loss_ce: 0.011651
2022-01-14 12:06:10,088 iteration 1876 : loss : 0.027204, loss_ce: 0.012350
2022-01-14 12:06:11,060 iteration 1877 : loss : 0.030871, loss_ce: 0.011712
2022-01-14 12:06:12,038 iteration 1878 : loss : 0.046138, loss_ce: 0.024333
2022-01-14 12:06:12,977 iteration 1879 : loss : 0.040696, loss_ce: 0.015488
2022-01-14 12:06:13,945 iteration 1880 : loss : 0.039010, loss_ce: 0.016413
2022-01-14 12:06:14,881 iteration 1881 : loss : 0.050489, loss_ce: 0.023959
2022-01-14 12:06:15,900 iteration 1882 : loss : 0.053308, loss_ce: 0.018587
2022-01-14 12:06:16,856 iteration 1883 : loss : 0.022431, loss_ce: 0.008041
2022-01-14 12:06:17,753 iteration 1884 : loss : 0.029012, loss_ce: 0.010911
2022-01-14 12:06:18,609 iteration 1885 : loss : 0.024210, loss_ce: 0.009883
2022-01-14 12:06:19,549 iteration 1886 : loss : 0.050587, loss_ce: 0.019104
2022-01-14 12:06:20,498 iteration 1887 : loss : 0.064705, loss_ce: 0.028570
 28%|████████                     | 111/400 [31:46<1:24:08, 17.47s/it]2022-01-14 12:06:21,610 iteration 1888 : loss : 0.043037, loss_ce: 0.013506
2022-01-14 12:06:22,482 iteration 1889 : loss : 0.046597, loss_ce: 0.014819
2022-01-14 12:06:23,334 iteration 1890 : loss : 0.029388, loss_ce: 0.013539
2022-01-14 12:06:24,203 iteration 1891 : loss : 0.028395, loss_ce: 0.010247
2022-01-14 12:06:25,119 iteration 1892 : loss : 0.031980, loss_ce: 0.015462
2022-01-14 12:06:26,045 iteration 1893 : loss : 0.043238, loss_ce: 0.013028
2022-01-14 12:06:26,969 iteration 1894 : loss : 0.045756, loss_ce: 0.016934
2022-01-14 12:06:27,810 iteration 1895 : loss : 0.023957, loss_ce: 0.009847
2022-01-14 12:06:28,819 iteration 1896 : loss : 0.038234, loss_ce: 0.015458
2022-01-14 12:06:29,759 iteration 1897 : loss : 0.034992, loss_ce: 0.011555
2022-01-14 12:06:30,791 iteration 1898 : loss : 0.031927, loss_ce: 0.014829
2022-01-14 12:06:31,726 iteration 1899 : loss : 0.039649, loss_ce: 0.013004
2022-01-14 12:06:32,607 iteration 1900 : loss : 0.037782, loss_ce: 0.015573
2022-01-14 12:06:33,466 iteration 1901 : loss : 0.028451, loss_ce: 0.009557
2022-01-14 12:06:34,391 iteration 1902 : loss : 0.033465, loss_ce: 0.012833
2022-01-14 12:06:35,343 iteration 1903 : loss : 0.042277, loss_ce: 0.020166
2022-01-14 12:06:36,337 iteration 1904 : loss : 0.027082, loss_ce: 0.010016
 28%|████████                     | 112/400 [32:02<1:21:30, 16.98s/it]2022-01-14 12:06:37,244 iteration 1905 : loss : 0.029679, loss_ce: 0.012794
2022-01-14 12:06:38,219 iteration 1906 : loss : 0.031569, loss_ce: 0.009966
2022-01-14 12:06:39,200 iteration 1907 : loss : 0.027549, loss_ce: 0.011292
2022-01-14 12:06:40,289 iteration 1908 : loss : 0.034532, loss_ce: 0.013409
2022-01-14 12:06:41,140 iteration 1909 : loss : 0.024397, loss_ce: 0.009973
2022-01-14 12:06:42,053 iteration 1910 : loss : 0.030587, loss_ce: 0.011929
2022-01-14 12:06:43,026 iteration 1911 : loss : 0.026873, loss_ce: 0.011451
2022-01-14 12:06:44,080 iteration 1912 : loss : 0.030676, loss_ce: 0.011882
2022-01-14 12:06:45,059 iteration 1913 : loss : 0.044171, loss_ce: 0.014165
2022-01-14 12:06:46,102 iteration 1914 : loss : 0.057304, loss_ce: 0.023542
2022-01-14 12:06:47,034 iteration 1915 : loss : 0.041184, loss_ce: 0.017506
2022-01-14 12:06:47,946 iteration 1916 : loss : 0.032076, loss_ce: 0.010993
2022-01-14 12:06:48,852 iteration 1917 : loss : 0.029423, loss_ce: 0.011882
2022-01-14 12:06:49,838 iteration 1918 : loss : 0.044707, loss_ce: 0.021400
2022-01-14 12:06:50,745 iteration 1919 : loss : 0.037759, loss_ce: 0.011840
2022-01-14 12:06:51,598 iteration 1920 : loss : 0.030812, loss_ce: 0.012878
2022-01-14 12:06:52,592 iteration 1921 : loss : 0.036748, loss_ce: 0.014315
 28%|████████▏                    | 113/400 [32:18<1:20:10, 16.76s/it]2022-01-14 12:06:53,651 iteration 1922 : loss : 0.049171, loss_ce: 0.020734
2022-01-14 12:06:54,544 iteration 1923 : loss : 0.038017, loss_ce: 0.015667
2022-01-14 12:06:55,563 iteration 1924 : loss : 0.047575, loss_ce: 0.015205
2022-01-14 12:06:56,442 iteration 1925 : loss : 0.048038, loss_ce: 0.014002
2022-01-14 12:06:57,414 iteration 1926 : loss : 0.043757, loss_ce: 0.016988
2022-01-14 12:06:58,431 iteration 1927 : loss : 0.029442, loss_ce: 0.013717
2022-01-14 12:06:59,319 iteration 1928 : loss : 0.032593, loss_ce: 0.009292
2022-01-14 12:07:00,431 iteration 1929 : loss : 0.052131, loss_ce: 0.025471
2022-01-14 12:07:01,372 iteration 1930 : loss : 0.033465, loss_ce: 0.015458
2022-01-14 12:07:02,372 iteration 1931 : loss : 0.064144, loss_ce: 0.023295
2022-01-14 12:07:03,339 iteration 1932 : loss : 0.050365, loss_ce: 0.014486
2022-01-14 12:07:04,314 iteration 1933 : loss : 0.048040, loss_ce: 0.020389
2022-01-14 12:07:05,240 iteration 1934 : loss : 0.063970, loss_ce: 0.018493
2022-01-14 12:07:06,197 iteration 1935 : loss : 0.034490, loss_ce: 0.014092
2022-01-14 12:07:07,115 iteration 1936 : loss : 0.031339, loss_ce: 0.012458
2022-01-14 12:07:07,978 iteration 1937 : loss : 0.034170, loss_ce: 0.012257
2022-01-14 12:07:08,943 iteration 1938 : loss : 0.040709, loss_ce: 0.019226
 28%|████████▎                    | 114/400 [32:34<1:19:19, 16.64s/it]2022-01-14 12:07:09,978 iteration 1939 : loss : 0.034601, loss_ce: 0.015581
2022-01-14 12:07:10,846 iteration 1940 : loss : 0.031182, loss_ce: 0.015509
2022-01-14 12:07:11,788 iteration 1941 : loss : 0.026519, loss_ce: 0.009706
2022-01-14 12:07:12,742 iteration 1942 : loss : 0.036390, loss_ce: 0.012989
2022-01-14 12:07:13,647 iteration 1943 : loss : 0.046376, loss_ce: 0.015450
2022-01-14 12:07:14,601 iteration 1944 : loss : 0.037928, loss_ce: 0.014971
2022-01-14 12:07:15,564 iteration 1945 : loss : 0.043550, loss_ce: 0.017588
2022-01-14 12:07:16,468 iteration 1946 : loss : 0.037142, loss_ce: 0.010633
2022-01-14 12:07:17,395 iteration 1947 : loss : 0.039416, loss_ce: 0.009497
2022-01-14 12:07:18,361 iteration 1948 : loss : 0.054263, loss_ce: 0.022449
2022-01-14 12:07:19,249 iteration 1949 : loss : 0.029428, loss_ce: 0.010147
2022-01-14 12:07:20,224 iteration 1950 : loss : 0.052552, loss_ce: 0.016475
2022-01-14 12:07:21,171 iteration 1951 : loss : 0.047376, loss_ce: 0.021406
2022-01-14 12:07:22,109 iteration 1952 : loss : 0.035971, loss_ce: 0.016101
2022-01-14 12:07:22,960 iteration 1953 : loss : 0.039242, loss_ce: 0.022980
2022-01-14 12:07:23,927 iteration 1954 : loss : 0.032250, loss_ce: 0.012353
2022-01-14 12:07:23,928 Training Data Eval:
2022-01-14 12:07:28,225   Average segmentation loss on training set: 0.0314
2022-01-14 12:07:28,225 Validation Data Eval:
2022-01-14 12:07:29,673   Average segmentation loss on validation set: 0.0768
2022-01-14 12:07:30,631 iteration 1955 : loss : 0.032889, loss_ce: 0.012985
 29%|████████▎                    | 115/400 [32:56<1:26:13, 18.15s/it]2022-01-14 12:07:31,608 iteration 1956 : loss : 0.069209, loss_ce: 0.026752
2022-01-14 12:07:32,593 iteration 1957 : loss : 0.044218, loss_ce: 0.020617
2022-01-14 12:07:33,514 iteration 1958 : loss : 0.061281, loss_ce: 0.016772
2022-01-14 12:07:34,423 iteration 1959 : loss : 0.052154, loss_ce: 0.016373
2022-01-14 12:07:35,251 iteration 1960 : loss : 0.030238, loss_ce: 0.011875
2022-01-14 12:07:36,059 iteration 1961 : loss : 0.029817, loss_ce: 0.011132
2022-01-14 12:07:37,044 iteration 1962 : loss : 0.034134, loss_ce: 0.013765
2022-01-14 12:07:37,917 iteration 1963 : loss : 0.035614, loss_ce: 0.013786
2022-01-14 12:07:38,894 iteration 1964 : loss : 0.048182, loss_ce: 0.015238
2022-01-14 12:07:39,735 iteration 1965 : loss : 0.028078, loss_ce: 0.013281
2022-01-14 12:07:40,667 iteration 1966 : loss : 0.047189, loss_ce: 0.019741
2022-01-14 12:07:41,712 iteration 1967 : loss : 0.035753, loss_ce: 0.012371
2022-01-14 12:07:42,831 iteration 1968 : loss : 0.063497, loss_ce: 0.030701
2022-01-14 12:07:43,820 iteration 1969 : loss : 0.052805, loss_ce: 0.021470
2022-01-14 12:07:44,689 iteration 1970 : loss : 0.028681, loss_ce: 0.012129
2022-01-14 12:07:45,630 iteration 1971 : loss : 0.030310, loss_ce: 0.011796
2022-01-14 12:07:46,550 iteration 1972 : loss : 0.039792, loss_ce: 0.013134
 29%|████████▍                    | 116/400 [33:12<1:22:45, 17.48s/it]2022-01-14 12:07:47,481 iteration 1973 : loss : 0.035725, loss_ce: 0.015852
2022-01-14 12:07:48,355 iteration 1974 : loss : 0.037483, loss_ce: 0.015903
2022-01-14 12:07:49,313 iteration 1975 : loss : 0.040296, loss_ce: 0.015023
2022-01-14 12:07:50,204 iteration 1976 : loss : 0.039961, loss_ce: 0.018295
2022-01-14 12:07:51,200 iteration 1977 : loss : 0.035074, loss_ce: 0.012218
2022-01-14 12:07:52,228 iteration 1978 : loss : 0.040142, loss_ce: 0.014542
2022-01-14 12:07:53,103 iteration 1979 : loss : 0.027016, loss_ce: 0.011292
2022-01-14 12:07:53,986 iteration 1980 : loss : 0.029483, loss_ce: 0.010342
2022-01-14 12:07:54,897 iteration 1981 : loss : 0.027777, loss_ce: 0.012828
2022-01-14 12:07:55,897 iteration 1982 : loss : 0.041856, loss_ce: 0.016479
2022-01-14 12:07:56,747 iteration 1983 : loss : 0.044650, loss_ce: 0.014798
2022-01-14 12:07:57,741 iteration 1984 : loss : 0.047299, loss_ce: 0.020312
2022-01-14 12:07:58,678 iteration 1985 : loss : 0.040992, loss_ce: 0.016484
2022-01-14 12:07:59,670 iteration 1986 : loss : 0.029898, loss_ce: 0.010391
2022-01-14 12:08:00,555 iteration 1987 : loss : 0.025650, loss_ce: 0.009539
2022-01-14 12:08:01,411 iteration 1988 : loss : 0.028976, loss_ce: 0.012739
2022-01-14 12:08:02,334 iteration 1989 : loss : 0.054760, loss_ce: 0.016967
 29%|████████▍                    | 117/400 [33:28<1:20:03, 16.97s/it]2022-01-14 12:08:03,329 iteration 1990 : loss : 0.054396, loss_ce: 0.015651
2022-01-14 12:08:04,183 iteration 1991 : loss : 0.028763, loss_ce: 0.011854
2022-01-14 12:08:05,140 iteration 1992 : loss : 0.027587, loss_ce: 0.009442
2022-01-14 12:08:06,093 iteration 1993 : loss : 0.044443, loss_ce: 0.015825
2022-01-14 12:08:07,095 iteration 1994 : loss : 0.041572, loss_ce: 0.017204
2022-01-14 12:08:08,002 iteration 1995 : loss : 0.036179, loss_ce: 0.014475
2022-01-14 12:08:08,979 iteration 1996 : loss : 0.033513, loss_ce: 0.012944
2022-01-14 12:08:09,852 iteration 1997 : loss : 0.029670, loss_ce: 0.012275
2022-01-14 12:08:10,785 iteration 1998 : loss : 0.028083, loss_ce: 0.010801
2022-01-14 12:08:11,728 iteration 1999 : loss : 0.034073, loss_ce: 0.013415
2022-01-14 12:08:12,655 iteration 2000 : loss : 0.056765, loss_ce: 0.031395
2022-01-14 12:08:13,515 iteration 2001 : loss : 0.037731, loss_ce: 0.012220
2022-01-14 12:08:14,506 iteration 2002 : loss : 0.032221, loss_ce: 0.013831
2022-01-14 12:08:15,378 iteration 2003 : loss : 0.035623, loss_ce: 0.010129
2022-01-14 12:08:16,337 iteration 2004 : loss : 0.032197, loss_ce: 0.015975
2022-01-14 12:08:17,225 iteration 2005 : loss : 0.040935, loss_ce: 0.018488
2022-01-14 12:08:18,143 iteration 2006 : loss : 0.038055, loss_ce: 0.012779
 30%|████████▌                    | 118/400 [33:44<1:18:07, 16.62s/it]2022-01-14 12:08:19,210 iteration 2007 : loss : 0.037890, loss_ce: 0.014712
2022-01-14 12:08:20,175 iteration 2008 : loss : 0.029610, loss_ce: 0.013037
2022-01-14 12:08:21,065 iteration 2009 : loss : 0.031099, loss_ce: 0.013262
2022-01-14 12:08:21,983 iteration 2010 : loss : 0.038030, loss_ce: 0.016280
2022-01-14 12:08:22,854 iteration 2011 : loss : 0.050626, loss_ce: 0.015055
2022-01-14 12:08:23,692 iteration 2012 : loss : 0.024397, loss_ce: 0.009020
2022-01-14 12:08:24,577 iteration 2013 : loss : 0.034197, loss_ce: 0.017391
2022-01-14 12:08:25,528 iteration 2014 : loss : 0.026343, loss_ce: 0.010883
2022-01-14 12:08:26,500 iteration 2015 : loss : 0.041654, loss_ce: 0.013472
2022-01-14 12:08:27,495 iteration 2016 : loss : 0.046900, loss_ce: 0.021382
2022-01-14 12:08:28,459 iteration 2017 : loss : 0.043734, loss_ce: 0.017541
2022-01-14 12:08:29,300 iteration 2018 : loss : 0.031436, loss_ce: 0.010212
2022-01-14 12:08:30,235 iteration 2019 : loss : 0.030957, loss_ce: 0.012091
2022-01-14 12:08:31,155 iteration 2020 : loss : 0.050071, loss_ce: 0.018668
2022-01-14 12:08:32,069 iteration 2021 : loss : 0.028870, loss_ce: 0.011002
2022-01-14 12:08:33,006 iteration 2022 : loss : 0.037229, loss_ce: 0.012571
2022-01-14 12:08:33,967 iteration 2023 : loss : 0.034766, loss_ce: 0.012068
 30%|████████▋                    | 119/400 [33:59<1:16:43, 16.38s/it]2022-01-14 12:08:34,985 iteration 2024 : loss : 0.041657, loss_ce: 0.020307
2022-01-14 12:08:36,092 iteration 2025 : loss : 0.059474, loss_ce: 0.021057
2022-01-14 12:08:36,986 iteration 2026 : loss : 0.033683, loss_ce: 0.011470
2022-01-14 12:08:37,967 iteration 2027 : loss : 0.036151, loss_ce: 0.010865
2022-01-14 12:08:38,800 iteration 2028 : loss : 0.026056, loss_ce: 0.011221
2022-01-14 12:08:39,657 iteration 2029 : loss : 0.037296, loss_ce: 0.010561
2022-01-14 12:08:40,585 iteration 2030 : loss : 0.034460, loss_ce: 0.012593
2022-01-14 12:08:41,543 iteration 2031 : loss : 0.035122, loss_ce: 0.012100
2022-01-14 12:08:42,481 iteration 2032 : loss : 0.041103, loss_ce: 0.018858
2022-01-14 12:08:43,303 iteration 2033 : loss : 0.025963, loss_ce: 0.011899
2022-01-14 12:08:44,173 iteration 2034 : loss : 0.033341, loss_ce: 0.011738
2022-01-14 12:08:45,137 iteration 2035 : loss : 0.039282, loss_ce: 0.015298
2022-01-14 12:08:46,020 iteration 2036 : loss : 0.035086, loss_ce: 0.015132
2022-01-14 12:08:46,897 iteration 2037 : loss : 0.031623, loss_ce: 0.014077
2022-01-14 12:08:47,899 iteration 2038 : loss : 0.054761, loss_ce: 0.016764
2022-01-14 12:08:48,869 iteration 2039 : loss : 0.030786, loss_ce: 0.010391
2022-01-14 12:08:48,869 Training Data Eval:
2022-01-14 12:08:53,173   Average segmentation loss on training set: 0.0251
2022-01-14 12:08:53,173 Validation Data Eval:
2022-01-14 12:08:54,619   Average segmentation loss on validation set: 0.0938
2022-01-14 12:08:55,607 iteration 2040 : loss : 0.033510, loss_ce: 0.014799
 30%|████████▋                    | 120/400 [34:21<1:23:49, 17.96s/it]2022-01-14 12:08:56,555 iteration 2041 : loss : 0.027274, loss_ce: 0.012632
2022-01-14 12:08:57,510 iteration 2042 : loss : 0.044668, loss_ce: 0.016625
2022-01-14 12:08:58,439 iteration 2043 : loss : 0.043325, loss_ce: 0.015915
2022-01-14 12:08:59,341 iteration 2044 : loss : 0.027635, loss_ce: 0.013532
2022-01-14 12:09:00,347 iteration 2045 : loss : 0.033414, loss_ce: 0.012275
2022-01-14 12:09:01,287 iteration 2046 : loss : 0.038872, loss_ce: 0.009575
2022-01-14 12:09:02,176 iteration 2047 : loss : 0.031909, loss_ce: 0.012089
2022-01-14 12:09:03,040 iteration 2048 : loss : 0.025277, loss_ce: 0.009760
2022-01-14 12:09:04,004 iteration 2049 : loss : 0.044160, loss_ce: 0.024051
2022-01-14 12:09:04,984 iteration 2050 : loss : 0.029898, loss_ce: 0.009792
2022-01-14 12:09:05,867 iteration 2051 : loss : 0.039244, loss_ce: 0.017241
2022-01-14 12:09:06,863 iteration 2052 : loss : 0.044974, loss_ce: 0.017874
2022-01-14 12:09:07,786 iteration 2053 : loss : 0.033922, loss_ce: 0.014386
2022-01-14 12:09:08,709 iteration 2054 : loss : 0.050951, loss_ce: 0.018599
2022-01-14 12:09:09,638 iteration 2055 : loss : 0.031870, loss_ce: 0.011810
2022-01-14 12:09:10,530 iteration 2056 : loss : 0.027028, loss_ce: 0.009987
2022-01-14 12:09:11,404 iteration 2057 : loss : 0.023404, loss_ce: 0.010219
 30%|████████▊                    | 121/400 [34:37<1:20:29, 17.31s/it]2022-01-14 12:09:12,376 iteration 2058 : loss : 0.037831, loss_ce: 0.018430
2022-01-14 12:09:13,347 iteration 2059 : loss : 0.029650, loss_ce: 0.010411
2022-01-14 12:09:14,361 iteration 2060 : loss : 0.038210, loss_ce: 0.012838
2022-01-14 12:09:15,291 iteration 2061 : loss : 0.031772, loss_ce: 0.016136
2022-01-14 12:09:16,170 iteration 2062 : loss : 0.048141, loss_ce: 0.018162
2022-01-14 12:09:17,291 iteration 2063 : loss : 0.035563, loss_ce: 0.015398
2022-01-14 12:09:18,234 iteration 2064 : loss : 0.037193, loss_ce: 0.013412
2022-01-14 12:09:19,237 iteration 2065 : loss : 0.036509, loss_ce: 0.012557
2022-01-14 12:09:20,168 iteration 2066 : loss : 0.033309, loss_ce: 0.013565
2022-01-14 12:09:21,141 iteration 2067 : loss : 0.037529, loss_ce: 0.013693
2022-01-14 12:09:22,013 iteration 2068 : loss : 0.025725, loss_ce: 0.009209
2022-01-14 12:09:22,949 iteration 2069 : loss : 0.035067, loss_ce: 0.016678
2022-01-14 12:09:23,934 iteration 2070 : loss : 0.044784, loss_ce: 0.018821
2022-01-14 12:09:24,801 iteration 2071 : loss : 0.023880, loss_ce: 0.009991
2022-01-14 12:09:25,681 iteration 2072 : loss : 0.033309, loss_ce: 0.017047
2022-01-14 12:09:26,669 iteration 2073 : loss : 0.045376, loss_ce: 0.018656
2022-01-14 12:09:27,522 iteration 2074 : loss : 0.029111, loss_ce: 0.008671
 30%|████████▊                    | 122/400 [34:53<1:18:32, 16.95s/it]2022-01-14 12:09:28,500 iteration 2075 : loss : 0.030423, loss_ce: 0.012395
2022-01-14 12:09:29,447 iteration 2076 : loss : 0.033731, loss_ce: 0.015166
2022-01-14 12:09:30,415 iteration 2077 : loss : 0.038716, loss_ce: 0.019487
2022-01-14 12:09:31,403 iteration 2078 : loss : 0.041633, loss_ce: 0.016114
2022-01-14 12:09:32,378 iteration 2079 : loss : 0.034389, loss_ce: 0.012176
2022-01-14 12:09:33,265 iteration 2080 : loss : 0.035300, loss_ce: 0.010219
2022-01-14 12:09:34,128 iteration 2081 : loss : 0.033244, loss_ce: 0.010963
2022-01-14 12:09:35,058 iteration 2082 : loss : 0.034960, loss_ce: 0.010117
2022-01-14 12:09:35,951 iteration 2083 : loss : 0.028914, loss_ce: 0.010846
2022-01-14 12:09:36,817 iteration 2084 : loss : 0.031017, loss_ce: 0.014815
2022-01-14 12:09:37,780 iteration 2085 : loss : 0.069919, loss_ce: 0.014496
2022-01-14 12:09:38,833 iteration 2086 : loss : 0.035089, loss_ce: 0.011431
2022-01-14 12:09:39,678 iteration 2087 : loss : 0.033423, loss_ce: 0.011337
2022-01-14 12:09:40,588 iteration 2088 : loss : 0.029819, loss_ce: 0.011488
2022-01-14 12:09:41,523 iteration 2089 : loss : 0.026325, loss_ce: 0.010125
2022-01-14 12:09:42,463 iteration 2090 : loss : 0.038583, loss_ce: 0.019382
2022-01-14 12:09:43,505 iteration 2091 : loss : 0.058509, loss_ce: 0.023532
 31%|████████▉                    | 123/400 [35:09<1:16:55, 16.66s/it]2022-01-14 12:09:44,466 iteration 2092 : loss : 0.037371, loss_ce: 0.012308
2022-01-14 12:09:45,329 iteration 2093 : loss : 0.026245, loss_ce: 0.010878
2022-01-14 12:09:46,298 iteration 2094 : loss : 0.033473, loss_ce: 0.012453
2022-01-14 12:09:47,377 iteration 2095 : loss : 0.032281, loss_ce: 0.013269
2022-01-14 12:09:48,287 iteration 2096 : loss : 0.030389, loss_ce: 0.013421
2022-01-14 12:09:49,186 iteration 2097 : loss : 0.059799, loss_ce: 0.015016
2022-01-14 12:09:50,042 iteration 2098 : loss : 0.038619, loss_ce: 0.013585
2022-01-14 12:09:50,930 iteration 2099 : loss : 0.031637, loss_ce: 0.013966
2022-01-14 12:09:51,902 iteration 2100 : loss : 0.042591, loss_ce: 0.015447
2022-01-14 12:09:52,729 iteration 2101 : loss : 0.038481, loss_ce: 0.010757
2022-01-14 12:09:53,701 iteration 2102 : loss : 0.040549, loss_ce: 0.017256
2022-01-14 12:09:54,582 iteration 2103 : loss : 0.034950, loss_ce: 0.016861
2022-01-14 12:09:55,417 iteration 2104 : loss : 0.031036, loss_ce: 0.010659
2022-01-14 12:09:56,357 iteration 2105 : loss : 0.045963, loss_ce: 0.021069
2022-01-14 12:09:57,295 iteration 2106 : loss : 0.041945, loss_ce: 0.015584
2022-01-14 12:09:58,173 iteration 2107 : loss : 0.027892, loss_ce: 0.009262
2022-01-14 12:09:59,017 iteration 2108 : loss : 0.034367, loss_ce: 0.014107
 31%|████████▉                    | 124/400 [35:24<1:15:04, 16.32s/it]2022-01-14 12:10:00,014 iteration 2109 : loss : 0.056029, loss_ce: 0.015633
2022-01-14 12:10:00,942 iteration 2110 : loss : 0.044109, loss_ce: 0.019970
2022-01-14 12:10:01,934 iteration 2111 : loss : 0.025581, loss_ce: 0.008473
2022-01-14 12:10:02,978 iteration 2112 : loss : 0.034893, loss_ce: 0.014641
2022-01-14 12:10:03,986 iteration 2113 : loss : 0.048790, loss_ce: 0.018450
2022-01-14 12:10:04,942 iteration 2114 : loss : 0.036527, loss_ce: 0.010311
2022-01-14 12:10:05,834 iteration 2115 : loss : 0.034254, loss_ce: 0.010963
2022-01-14 12:10:06,724 iteration 2116 : loss : 0.034748, loss_ce: 0.012579
2022-01-14 12:10:07,754 iteration 2117 : loss : 0.049348, loss_ce: 0.016124
2022-01-14 12:10:08,697 iteration 2118 : loss : 0.038710, loss_ce: 0.017292
2022-01-14 12:10:09,775 iteration 2119 : loss : 0.043277, loss_ce: 0.017268
2022-01-14 12:10:10,745 iteration 2120 : loss : 0.029984, loss_ce: 0.014944
2022-01-14 12:10:11,745 iteration 2121 : loss : 0.053911, loss_ce: 0.024405
2022-01-14 12:10:12,737 iteration 2122 : loss : 0.054341, loss_ce: 0.028543
2022-01-14 12:10:13,593 iteration 2123 : loss : 0.048132, loss_ce: 0.017152
2022-01-14 12:10:14,598 iteration 2124 : loss : 0.043489, loss_ce: 0.017483
2022-01-14 12:10:14,598 Training Data Eval:
2022-01-14 12:10:18,908   Average segmentation loss on training set: 0.0370
2022-01-14 12:10:18,908 Validation Data Eval:
2022-01-14 12:10:20,358   Average segmentation loss on validation set: 0.0768
2022-01-14 12:10:21,268 iteration 2125 : loss : 0.026775, loss_ce: 0.012178
 31%|█████████                    | 125/400 [35:47<1:22:57, 18.10s/it]2022-01-14 12:10:22,280 iteration 2126 : loss : 0.078058, loss_ce: 0.026233
2022-01-14 12:10:23,146 iteration 2127 : loss : 0.027784, loss_ce: 0.011613
2022-01-14 12:10:23,995 iteration 2128 : loss : 0.024946, loss_ce: 0.011171
2022-01-14 12:10:24,997 iteration 2129 : loss : 0.045299, loss_ce: 0.018622
2022-01-14 12:10:25,902 iteration 2130 : loss : 0.038202, loss_ce: 0.014312
2022-01-14 12:10:26,775 iteration 2131 : loss : 0.027507, loss_ce: 0.010835
2022-01-14 12:10:27,725 iteration 2132 : loss : 0.038520, loss_ce: 0.011343
2022-01-14 12:10:28,649 iteration 2133 : loss : 0.037201, loss_ce: 0.014684
2022-01-14 12:10:29,664 iteration 2134 : loss : 0.037603, loss_ce: 0.011596
2022-01-14 12:10:30,510 iteration 2135 : loss : 0.029905, loss_ce: 0.010098
2022-01-14 12:10:31,501 iteration 2136 : loss : 0.048182, loss_ce: 0.018496
2022-01-14 12:10:32,408 iteration 2137 : loss : 0.035773, loss_ce: 0.015459
2022-01-14 12:10:33,423 iteration 2138 : loss : 0.030090, loss_ce: 0.008936
2022-01-14 12:10:34,316 iteration 2139 : loss : 0.038860, loss_ce: 0.018907
2022-01-14 12:10:35,302 iteration 2140 : loss : 0.040046, loss_ce: 0.024229
2022-01-14 12:10:36,261 iteration 2141 : loss : 0.036064, loss_ce: 0.011817
2022-01-14 12:10:37,243 iteration 2142 : loss : 0.062553, loss_ce: 0.019212
 32%|█████████▏                   | 126/400 [36:03<1:19:44, 17.46s/it]2022-01-14 12:10:38,247 iteration 2143 : loss : 0.044855, loss_ce: 0.026869
2022-01-14 12:10:39,203 iteration 2144 : loss : 0.030639, loss_ce: 0.013082
2022-01-14 12:10:40,148 iteration 2145 : loss : 0.040050, loss_ce: 0.015811
2022-01-14 12:10:41,040 iteration 2146 : loss : 0.047262, loss_ce: 0.017485
2022-01-14 12:10:41,906 iteration 2147 : loss : 0.027891, loss_ce: 0.010564
2022-01-14 12:10:42,798 iteration 2148 : loss : 0.028295, loss_ce: 0.010451
2022-01-14 12:10:43,789 iteration 2149 : loss : 0.049238, loss_ce: 0.015813
2022-01-14 12:10:44,677 iteration 2150 : loss : 0.028144, loss_ce: 0.012182
2022-01-14 12:10:45,597 iteration 2151 : loss : 0.034914, loss_ce: 0.012317
2022-01-14 12:10:46,468 iteration 2152 : loss : 0.033034, loss_ce: 0.017089
2022-01-14 12:10:47,385 iteration 2153 : loss : 0.037771, loss_ce: 0.012457
2022-01-14 12:10:48,308 iteration 2154 : loss : 0.033045, loss_ce: 0.011523
2022-01-14 12:10:49,269 iteration 2155 : loss : 0.053175, loss_ce: 0.033245
2022-01-14 12:10:50,136 iteration 2156 : loss : 0.035484, loss_ce: 0.015003
2022-01-14 12:10:51,186 iteration 2157 : loss : 0.044052, loss_ce: 0.018457
2022-01-14 12:10:52,165 iteration 2158 : loss : 0.033256, loss_ce: 0.010184
2022-01-14 12:10:53,135 iteration 2159 : loss : 0.045638, loss_ce: 0.015866
 32%|█████████▏                   | 127/400 [36:19<1:17:17, 16.99s/it]2022-01-14 12:10:54,141 iteration 2160 : loss : 0.042042, loss_ce: 0.014510
2022-01-14 12:10:55,170 iteration 2161 : loss : 0.043115, loss_ce: 0.021401
2022-01-14 12:10:56,171 iteration 2162 : loss : 0.029823, loss_ce: 0.012431
2022-01-14 12:10:57,042 iteration 2163 : loss : 0.034667, loss_ce: 0.012646
2022-01-14 12:10:58,040 iteration 2164 : loss : 0.039676, loss_ce: 0.014764
2022-01-14 12:10:58,991 iteration 2165 : loss : 0.031767, loss_ce: 0.014488
2022-01-14 12:10:59,965 iteration 2166 : loss : 0.040895, loss_ce: 0.010303
2022-01-14 12:11:00,968 iteration 2167 : loss : 0.026565, loss_ce: 0.009350
2022-01-14 12:11:01,901 iteration 2168 : loss : 0.042455, loss_ce: 0.016660
2022-01-14 12:11:02,837 iteration 2169 : loss : 0.039890, loss_ce: 0.015402
2022-01-14 12:11:03,718 iteration 2170 : loss : 0.082033, loss_ce: 0.044974
2022-01-14 12:11:04,673 iteration 2171 : loss : 0.056175, loss_ce: 0.022474
2022-01-14 12:11:05,725 iteration 2172 : loss : 0.036940, loss_ce: 0.011485
2022-01-14 12:11:06,595 iteration 2173 : loss : 0.029669, loss_ce: 0.009871
2022-01-14 12:11:07,435 iteration 2174 : loss : 0.029815, loss_ce: 0.015363
2022-01-14 12:11:08,296 iteration 2175 : loss : 0.026527, loss_ce: 0.009827
2022-01-14 12:11:09,349 iteration 2176 : loss : 0.059737, loss_ce: 0.025752
 32%|█████████▎                   | 128/400 [36:35<1:15:58, 16.76s/it]2022-01-14 12:11:10,349 iteration 2177 : loss : 0.034162, loss_ce: 0.012001
2022-01-14 12:11:11,346 iteration 2178 : loss : 0.038297, loss_ce: 0.016298
2022-01-14 12:11:12,258 iteration 2179 : loss : 0.029637, loss_ce: 0.013985
2022-01-14 12:11:13,183 iteration 2180 : loss : 0.032349, loss_ce: 0.013755
2022-01-14 12:11:14,159 iteration 2181 : loss : 0.033852, loss_ce: 0.015511
2022-01-14 12:11:15,073 iteration 2182 : loss : 0.033837, loss_ce: 0.008962
2022-01-14 12:11:15,937 iteration 2183 : loss : 0.032454, loss_ce: 0.013629
2022-01-14 12:11:16,949 iteration 2184 : loss : 0.025288, loss_ce: 0.009666
2022-01-14 12:11:17,831 iteration 2185 : loss : 0.043429, loss_ce: 0.021330
2022-01-14 12:11:18,736 iteration 2186 : loss : 0.040022, loss_ce: 0.014506
2022-01-14 12:11:19,671 iteration 2187 : loss : 0.025076, loss_ce: 0.009865
2022-01-14 12:11:20,559 iteration 2188 : loss : 0.037877, loss_ce: 0.010509
2022-01-14 12:11:21,549 iteration 2189 : loss : 0.048334, loss_ce: 0.018881
2022-01-14 12:11:22,473 iteration 2190 : loss : 0.046301, loss_ce: 0.015306
2022-01-14 12:11:23,431 iteration 2191 : loss : 0.045292, loss_ce: 0.014973
2022-01-14 12:11:24,319 iteration 2192 : loss : 0.042609, loss_ce: 0.016192
2022-01-14 12:11:25,263 iteration 2193 : loss : 0.038323, loss_ce: 0.016852
 32%|█████████▎                   | 129/400 [36:51<1:14:32, 16.50s/it]2022-01-14 12:11:26,314 iteration 2194 : loss : 0.041289, loss_ce: 0.021436
2022-01-14 12:11:27,202 iteration 2195 : loss : 0.047236, loss_ce: 0.015047
2022-01-14 12:11:28,126 iteration 2196 : loss : 0.029494, loss_ce: 0.012143
2022-01-14 12:11:29,079 iteration 2197 : loss : 0.037960, loss_ce: 0.018882
2022-01-14 12:11:30,036 iteration 2198 : loss : 0.039694, loss_ce: 0.018821
2022-01-14 12:11:30,981 iteration 2199 : loss : 0.035386, loss_ce: 0.015109
2022-01-14 12:11:31,887 iteration 2200 : loss : 0.035758, loss_ce: 0.012740
2022-01-14 12:11:32,770 iteration 2201 : loss : 0.028826, loss_ce: 0.012216
2022-01-14 12:11:33,741 iteration 2202 : loss : 0.068452, loss_ce: 0.017159
2022-01-14 12:11:34,730 iteration 2203 : loss : 0.028264, loss_ce: 0.013622
2022-01-14 12:11:35,620 iteration 2204 : loss : 0.031533, loss_ce: 0.014515
2022-01-14 12:11:36,462 iteration 2205 : loss : 0.025473, loss_ce: 0.011105
2022-01-14 12:11:37,309 iteration 2206 : loss : 0.036049, loss_ce: 0.011908
2022-01-14 12:11:38,191 iteration 2207 : loss : 0.049721, loss_ce: 0.022511
2022-01-14 12:11:39,145 iteration 2208 : loss : 0.032545, loss_ce: 0.008882
2022-01-14 12:11:40,054 iteration 2209 : loss : 0.032212, loss_ce: 0.011225
2022-01-14 12:11:40,054 Training Data Eval:
2022-01-14 12:11:44,358   Average segmentation loss on training set: 0.0253
2022-01-14 12:11:44,358 Validation Data Eval:
2022-01-14 12:11:45,804   Average segmentation loss on validation set: 0.1014
2022-01-14 12:11:46,720 iteration 2210 : loss : 0.040290, loss_ce: 0.012960
 32%|█████████▍                   | 130/400 [37:12<1:20:57, 17.99s/it]2022-01-14 12:11:47,748 iteration 2211 : loss : 0.045514, loss_ce: 0.015383
2022-01-14 12:11:48,709 iteration 2212 : loss : 0.044419, loss_ce: 0.020167
2022-01-14 12:11:49,669 iteration 2213 : loss : 0.051690, loss_ce: 0.021480
2022-01-14 12:11:50,634 iteration 2214 : loss : 0.035220, loss_ce: 0.012954
2022-01-14 12:11:51,606 iteration 2215 : loss : 0.048408, loss_ce: 0.022539
2022-01-14 12:11:52,460 iteration 2216 : loss : 0.054397, loss_ce: 0.021146
2022-01-14 12:11:53,443 iteration 2217 : loss : 0.036051, loss_ce: 0.015851
2022-01-14 12:11:54,319 iteration 2218 : loss : 0.035558, loss_ce: 0.014064
2022-01-14 12:11:55,298 iteration 2219 : loss : 0.034176, loss_ce: 0.013573
2022-01-14 12:11:56,122 iteration 2220 : loss : 0.039062, loss_ce: 0.015268
2022-01-14 12:11:57,006 iteration 2221 : loss : 0.041540, loss_ce: 0.014072
2022-01-14 12:11:57,979 iteration 2222 : loss : 0.041019, loss_ce: 0.015305
2022-01-14 12:11:58,915 iteration 2223 : loss : 0.044617, loss_ce: 0.014363
2022-01-14 12:11:59,919 iteration 2224 : loss : 0.053183, loss_ce: 0.024581
2022-01-14 12:12:00,786 iteration 2225 : loss : 0.021752, loss_ce: 0.007878
2022-01-14 12:12:01,806 iteration 2226 : loss : 0.055793, loss_ce: 0.029723
2022-01-14 12:12:02,720 iteration 2227 : loss : 0.031162, loss_ce: 0.012317
 33%|█████████▍                   | 131/400 [37:28<1:17:58, 17.39s/it]2022-01-14 12:12:03,788 iteration 2228 : loss : 0.028589, loss_ce: 0.013433
2022-01-14 12:12:04,821 iteration 2229 : loss : 0.031253, loss_ce: 0.014464
2022-01-14 12:12:05,805 iteration 2230 : loss : 0.039991, loss_ce: 0.013816
2022-01-14 12:12:06,634 iteration 2231 : loss : 0.019523, loss_ce: 0.008056
2022-01-14 12:12:07,506 iteration 2232 : loss : 0.036823, loss_ce: 0.014348
2022-01-14 12:12:08,404 iteration 2233 : loss : 0.036821, loss_ce: 0.013155
2022-01-14 12:12:09,312 iteration 2234 : loss : 0.034199, loss_ce: 0.012055
2022-01-14 12:12:10,216 iteration 2235 : loss : 0.048950, loss_ce: 0.010791
2022-01-14 12:12:11,270 iteration 2236 : loss : 0.040903, loss_ce: 0.016864
2022-01-14 12:12:12,206 iteration 2237 : loss : 0.026309, loss_ce: 0.011643
2022-01-14 12:12:13,129 iteration 2238 : loss : 0.036432, loss_ce: 0.019358
2022-01-14 12:12:14,068 iteration 2239 : loss : 0.027962, loss_ce: 0.009301
2022-01-14 12:12:15,022 iteration 2240 : loss : 0.032861, loss_ce: 0.010155
2022-01-14 12:12:16,022 iteration 2241 : loss : 0.036067, loss_ce: 0.010773
2022-01-14 12:12:16,991 iteration 2242 : loss : 0.031107, loss_ce: 0.011666
2022-01-14 12:12:18,044 iteration 2243 : loss : 0.047552, loss_ce: 0.012101
2022-01-14 12:12:18,976 iteration 2244 : loss : 0.039198, loss_ce: 0.018529
 33%|█████████▌                   | 132/400 [37:44<1:16:09, 17.05s/it]2022-01-14 12:12:20,087 iteration 2245 : loss : 0.060478, loss_ce: 0.025640
2022-01-14 12:12:20,997 iteration 2246 : loss : 0.037072, loss_ce: 0.016897
2022-01-14 12:12:22,050 iteration 2247 : loss : 0.052458, loss_ce: 0.013628
2022-01-14 12:12:22,996 iteration 2248 : loss : 0.046506, loss_ce: 0.019948
2022-01-14 12:12:23,958 iteration 2249 : loss : 0.037687, loss_ce: 0.013428
2022-01-14 12:12:24,897 iteration 2250 : loss : 0.051868, loss_ce: 0.019505
2022-01-14 12:12:25,753 iteration 2251 : loss : 0.035237, loss_ce: 0.012694
2022-01-14 12:12:26,784 iteration 2252 : loss : 0.053647, loss_ce: 0.017975
2022-01-14 12:12:27,814 iteration 2253 : loss : 0.034441, loss_ce: 0.014548
2022-01-14 12:12:28,742 iteration 2254 : loss : 0.038431, loss_ce: 0.017521
2022-01-14 12:12:29,630 iteration 2255 : loss : 0.039057, loss_ce: 0.013128
2022-01-14 12:12:30,588 iteration 2256 : loss : 0.026713, loss_ce: 0.010199
2022-01-14 12:12:31,503 iteration 2257 : loss : 0.030683, loss_ce: 0.010979
2022-01-14 12:12:32,362 iteration 2258 : loss : 0.026725, loss_ce: 0.011000
2022-01-14 12:12:33,381 iteration 2259 : loss : 0.028969, loss_ce: 0.011321
2022-01-14 12:12:34,276 iteration 2260 : loss : 0.034979, loss_ce: 0.014179
2022-01-14 12:12:35,237 iteration 2261 : loss : 0.029445, loss_ce: 0.012843
 33%|█████████▋                   | 133/400 [38:01<1:14:49, 16.81s/it]2022-01-14 12:12:36,233 iteration 2262 : loss : 0.036098, loss_ce: 0.018119
2022-01-14 12:12:37,177 iteration 2263 : loss : 0.030130, loss_ce: 0.012074
2022-01-14 12:12:38,145 iteration 2264 : loss : 0.045909, loss_ce: 0.018902
2022-01-14 12:12:39,075 iteration 2265 : loss : 0.024738, loss_ce: 0.009343
2022-01-14 12:12:39,977 iteration 2266 : loss : 0.037629, loss_ce: 0.012780
2022-01-14 12:12:40,828 iteration 2267 : loss : 0.023167, loss_ce: 0.009296
2022-01-14 12:12:41,746 iteration 2268 : loss : 0.028836, loss_ce: 0.013659
2022-01-14 12:12:42,642 iteration 2269 : loss : 0.028511, loss_ce: 0.013612
2022-01-14 12:12:43,504 iteration 2270 : loss : 0.027202, loss_ce: 0.009379
2022-01-14 12:12:44,417 iteration 2271 : loss : 0.058063, loss_ce: 0.019695
2022-01-14 12:12:45,390 iteration 2272 : loss : 0.030861, loss_ce: 0.010430
2022-01-14 12:12:46,377 iteration 2273 : loss : 0.033539, loss_ce: 0.013302
2022-01-14 12:12:47,287 iteration 2274 : loss : 0.049639, loss_ce: 0.022693
2022-01-14 12:12:48,206 iteration 2275 : loss : 0.066590, loss_ce: 0.019399
2022-01-14 12:12:49,085 iteration 2276 : loss : 0.050063, loss_ce: 0.024139
2022-01-14 12:12:50,010 iteration 2277 : loss : 0.026937, loss_ce: 0.007824
2022-01-14 12:12:50,977 iteration 2278 : loss : 0.035674, loss_ce: 0.012074
 34%|█████████▋                   | 134/400 [38:16<1:13:06, 16.49s/it]2022-01-14 12:12:51,894 iteration 2279 : loss : 0.024217, loss_ce: 0.008827
2022-01-14 12:12:52,753 iteration 2280 : loss : 0.037850, loss_ce: 0.018033
2022-01-14 12:12:53,676 iteration 2281 : loss : 0.036925, loss_ce: 0.011292
2022-01-14 12:12:54,531 iteration 2282 : loss : 0.038882, loss_ce: 0.012745
2022-01-14 12:12:55,474 iteration 2283 : loss : 0.036461, loss_ce: 0.009742
2022-01-14 12:12:56,328 iteration 2284 : loss : 0.048304, loss_ce: 0.026481
2022-01-14 12:12:57,304 iteration 2285 : loss : 0.040697, loss_ce: 0.016086
2022-01-14 12:12:58,206 iteration 2286 : loss : 0.050749, loss_ce: 0.023803
2022-01-14 12:12:59,134 iteration 2287 : loss : 0.038388, loss_ce: 0.012247
2022-01-14 12:13:00,045 iteration 2288 : loss : 0.097904, loss_ce: 0.018962
2022-01-14 12:13:00,994 iteration 2289 : loss : 0.036755, loss_ce: 0.011645
2022-01-14 12:13:01,939 iteration 2290 : loss : 0.044440, loss_ce: 0.017205
2022-01-14 12:13:02,974 iteration 2291 : loss : 0.043974, loss_ce: 0.018036
2022-01-14 12:13:03,956 iteration 2292 : loss : 0.046924, loss_ce: 0.018030
2022-01-14 12:13:04,894 iteration 2293 : loss : 0.060678, loss_ce: 0.024449
2022-01-14 12:13:05,800 iteration 2294 : loss : 0.038012, loss_ce: 0.016964
2022-01-14 12:13:05,800 Training Data Eval:
2022-01-14 12:13:10,105   Average segmentation loss on training set: 0.1044
2022-01-14 12:13:10,106 Validation Data Eval:
2022-01-14 12:13:11,564   Average segmentation loss on validation set: 0.1505
2022-01-14 12:13:12,494 iteration 2295 : loss : 0.080382, loss_ce: 0.023035
 34%|█████████▊                   | 135/400 [38:38<1:19:29, 18.00s/it]2022-01-14 12:13:13,426 iteration 2296 : loss : 0.037679, loss_ce: 0.014342
2022-01-14 12:13:14,382 iteration 2297 : loss : 0.041342, loss_ce: 0.015020
2022-01-14 12:13:15,318 iteration 2298 : loss : 0.045715, loss_ce: 0.017098
2022-01-14 12:13:16,287 iteration 2299 : loss : 0.052508, loss_ce: 0.016826
2022-01-14 12:13:17,187 iteration 2300 : loss : 0.029945, loss_ce: 0.012336
2022-01-14 12:13:18,113 iteration 2301 : loss : 0.038663, loss_ce: 0.016807
2022-01-14 12:13:19,090 iteration 2302 : loss : 0.050238, loss_ce: 0.019796
2022-01-14 12:13:20,055 iteration 2303 : loss : 0.069284, loss_ce: 0.024297
2022-01-14 12:13:21,017 iteration 2304 : loss : 0.040919, loss_ce: 0.017358
2022-01-14 12:13:21,936 iteration 2305 : loss : 0.044430, loss_ce: 0.018244
2022-01-14 12:13:22,837 iteration 2306 : loss : 0.044199, loss_ce: 0.017225
2022-01-14 12:13:23,847 iteration 2307 : loss : 0.032229, loss_ce: 0.011584
2022-01-14 12:13:24,741 iteration 2308 : loss : 0.034846, loss_ce: 0.014814
2022-01-14 12:13:25,724 iteration 2309 : loss : 0.043596, loss_ce: 0.018356
2022-01-14 12:13:26,686 iteration 2310 : loss : 0.041596, loss_ce: 0.020046
2022-01-14 12:13:27,559 iteration 2311 : loss : 0.034865, loss_ce: 0.013731
2022-01-14 12:13:28,420 iteration 2312 : loss : 0.026283, loss_ce: 0.009521
 34%|█████████▊                   | 136/400 [38:54<1:16:28, 17.38s/it]2022-01-14 12:13:29,396 iteration 2313 : loss : 0.040155, loss_ce: 0.014854
2022-01-14 12:13:30,370 iteration 2314 : loss : 0.028091, loss_ce: 0.009508
2022-01-14 12:13:31,388 iteration 2315 : loss : 0.042206, loss_ce: 0.011700
2022-01-14 12:13:32,246 iteration 2316 : loss : 0.039302, loss_ce: 0.014054
2022-01-14 12:13:33,223 iteration 2317 : loss : 0.044896, loss_ce: 0.012345
2022-01-14 12:13:34,182 iteration 2318 : loss : 0.037329, loss_ce: 0.015823
2022-01-14 12:13:35,127 iteration 2319 : loss : 0.030497, loss_ce: 0.011298
2022-01-14 12:13:36,121 iteration 2320 : loss : 0.039570, loss_ce: 0.018482
2022-01-14 12:13:36,996 iteration 2321 : loss : 0.048444, loss_ce: 0.017425
2022-01-14 12:13:37,921 iteration 2322 : loss : 0.038319, loss_ce: 0.016478
2022-01-14 12:13:38,839 iteration 2323 : loss : 0.049244, loss_ce: 0.022241
2022-01-14 12:13:39,799 iteration 2324 : loss : 0.039039, loss_ce: 0.012281
2022-01-14 12:13:40,705 iteration 2325 : loss : 0.032836, loss_ce: 0.014208
2022-01-14 12:13:41,646 iteration 2326 : loss : 0.037304, loss_ce: 0.016624
2022-01-14 12:13:42,553 iteration 2327 : loss : 0.035275, loss_ce: 0.013941
2022-01-14 12:13:43,516 iteration 2328 : loss : 0.040855, loss_ce: 0.021542
2022-01-14 12:13:44,402 iteration 2329 : loss : 0.023187, loss_ce: 0.009057
 34%|█████████▉                   | 137/400 [39:10<1:14:19, 16.96s/it]2022-01-14 12:13:45,359 iteration 2330 : loss : 0.047505, loss_ce: 0.017552
2022-01-14 12:13:46,277 iteration 2331 : loss : 0.038763, loss_ce: 0.016414
2022-01-14 12:13:47,266 iteration 2332 : loss : 0.051979, loss_ce: 0.020061
2022-01-14 12:13:48,274 iteration 2333 : loss : 0.035996, loss_ce: 0.017528
2022-01-14 12:13:49,198 iteration 2334 : loss : 0.032660, loss_ce: 0.015745
2022-01-14 12:13:50,118 iteration 2335 : loss : 0.036564, loss_ce: 0.011162
2022-01-14 12:13:51,092 iteration 2336 : loss : 0.074076, loss_ce: 0.018113
2022-01-14 12:13:52,088 iteration 2337 : loss : 0.033684, loss_ce: 0.016561
2022-01-14 12:13:53,008 iteration 2338 : loss : 0.033133, loss_ce: 0.013752
2022-01-14 12:13:53,975 iteration 2339 : loss : 0.050643, loss_ce: 0.015481
2022-01-14 12:13:54,977 iteration 2340 : loss : 0.051289, loss_ce: 0.022570
2022-01-14 12:13:55,835 iteration 2341 : loss : 0.026575, loss_ce: 0.006543
2022-01-14 12:13:56,779 iteration 2342 : loss : 0.028903, loss_ce: 0.011389
2022-01-14 12:13:57,771 iteration 2343 : loss : 0.043124, loss_ce: 0.016773
2022-01-14 12:13:58,736 iteration 2344 : loss : 0.035169, loss_ce: 0.014244
2022-01-14 12:13:59,727 iteration 2345 : loss : 0.040614, loss_ce: 0.012866
2022-01-14 12:14:00,675 iteration 2346 : loss : 0.033688, loss_ce: 0.014059
 34%|██████████                   | 138/400 [39:26<1:13:09, 16.75s/it]2022-01-14 12:14:01,680 iteration 2347 : loss : 0.040013, loss_ce: 0.013601
2022-01-14 12:14:02,609 iteration 2348 : loss : 0.041258, loss_ce: 0.014921
2022-01-14 12:14:03,609 iteration 2349 : loss : 0.044100, loss_ce: 0.018832
2022-01-14 12:14:04,517 iteration 2350 : loss : 0.044504, loss_ce: 0.015553
2022-01-14 12:14:05,465 iteration 2351 : loss : 0.092664, loss_ce: 0.016184
2022-01-14 12:14:06,410 iteration 2352 : loss : 0.036520, loss_ce: 0.011435
2022-01-14 12:14:07,408 iteration 2353 : loss : 0.033376, loss_ce: 0.014002
2022-01-14 12:14:08,415 iteration 2354 : loss : 0.040852, loss_ce: 0.016117
2022-01-14 12:14:09,279 iteration 2355 : loss : 0.032398, loss_ce: 0.011779
2022-01-14 12:14:10,222 iteration 2356 : loss : 0.030724, loss_ce: 0.011382
2022-01-14 12:14:11,160 iteration 2357 : loss : 0.046720, loss_ce: 0.015161
2022-01-14 12:14:12,129 iteration 2358 : loss : 0.037053, loss_ce: 0.016764
2022-01-14 12:14:13,196 iteration 2359 : loss : 0.039428, loss_ce: 0.016624
2022-01-14 12:14:14,115 iteration 2360 : loss : 0.040745, loss_ce: 0.018511
2022-01-14 12:14:15,099 iteration 2361 : loss : 0.041412, loss_ce: 0.014046
2022-01-14 12:14:16,153 iteration 2362 : loss : 0.058479, loss_ce: 0.027945
2022-01-14 12:14:17,025 iteration 2363 : loss : 0.030053, loss_ce: 0.013719
 35%|██████████                   | 139/400 [39:42<1:12:21, 16.63s/it]2022-01-14 12:14:17,945 iteration 2364 : loss : 0.065774, loss_ce: 0.023462
2022-01-14 12:14:18,837 iteration 2365 : loss : 0.046904, loss_ce: 0.012499
2022-01-14 12:14:19,798 iteration 2366 : loss : 0.041652, loss_ce: 0.018297
2022-01-14 12:14:20,713 iteration 2367 : loss : 0.033296, loss_ce: 0.017081
2022-01-14 12:14:21,594 iteration 2368 : loss : 0.054972, loss_ce: 0.030130
2022-01-14 12:14:22,554 iteration 2369 : loss : 0.092213, loss_ce: 0.063827
2022-01-14 12:14:23,392 iteration 2370 : loss : 0.078026, loss_ce: 0.041336
2022-01-14 12:14:24,369 iteration 2371 : loss : 0.032645, loss_ce: 0.013203
2022-01-14 12:14:25,278 iteration 2372 : loss : 0.049299, loss_ce: 0.022088
2022-01-14 12:14:26,164 iteration 2373 : loss : 0.039631, loss_ce: 0.017750
2022-01-14 12:14:27,063 iteration 2374 : loss : 0.029319, loss_ce: 0.011108
2022-01-14 12:14:28,033 iteration 2375 : loss : 0.045880, loss_ce: 0.014394
2022-01-14 12:14:29,008 iteration 2376 : loss : 0.036303, loss_ce: 0.012515
2022-01-14 12:14:29,918 iteration 2377 : loss : 0.026736, loss_ce: 0.009787
2022-01-14 12:14:30,839 iteration 2378 : loss : 0.031207, loss_ce: 0.012705
2022-01-14 12:14:31,777 iteration 2379 : loss : 0.036864, loss_ce: 0.019141
2022-01-14 12:14:31,777 Training Data Eval:
2022-01-14 12:14:36,075   Average segmentation loss on training set: 0.0323
2022-01-14 12:14:36,076 Validation Data Eval:
2022-01-14 12:14:37,531   Average segmentation loss on validation set: 0.1042
2022-01-14 12:14:38,403 iteration 2380 : loss : 0.028612, loss_ce: 0.015142
 35%|██████████▏                  | 140/400 [40:04<1:18:14, 18.06s/it]2022-01-14 12:14:39,510 iteration 2381 : loss : 0.050861, loss_ce: 0.015685
2022-01-14 12:14:40,468 iteration 2382 : loss : 0.040642, loss_ce: 0.016722
2022-01-14 12:14:41,387 iteration 2383 : loss : 0.041982, loss_ce: 0.016740
2022-01-14 12:14:42,249 iteration 2384 : loss : 0.037381, loss_ce: 0.013011
2022-01-14 12:14:43,181 iteration 2385 : loss : 0.035610, loss_ce: 0.011908
2022-01-14 12:14:44,138 iteration 2386 : loss : 0.052044, loss_ce: 0.016266
2022-01-14 12:14:45,126 iteration 2387 : loss : 0.031950, loss_ce: 0.012226
2022-01-14 12:14:46,081 iteration 2388 : loss : 0.051395, loss_ce: 0.023760
2022-01-14 12:14:47,027 iteration 2389 : loss : 0.036844, loss_ce: 0.013213
2022-01-14 12:14:47,913 iteration 2390 : loss : 0.048391, loss_ce: 0.019439
2022-01-14 12:14:48,768 iteration 2391 : loss : 0.034134, loss_ce: 0.013033
2022-01-14 12:14:49,857 iteration 2392 : loss : 0.043869, loss_ce: 0.010186
2022-01-14 12:14:50,872 iteration 2393 : loss : 0.038945, loss_ce: 0.015147
2022-01-14 12:14:51,817 iteration 2394 : loss : 0.043963, loss_ce: 0.015742
2022-01-14 12:14:52,817 iteration 2395 : loss : 0.038594, loss_ce: 0.020998
2022-01-14 12:14:53,707 iteration 2396 : loss : 0.036554, loss_ce: 0.017422
2022-01-14 12:14:54,677 iteration 2397 : loss : 0.034518, loss_ce: 0.020321
 35%|██████████▏                  | 141/400 [40:20<1:15:38, 17.52s/it]2022-01-14 12:14:55,649 iteration 2398 : loss : 0.029045, loss_ce: 0.013708
2022-01-14 12:14:56,692 iteration 2399 : loss : 0.057984, loss_ce: 0.025188
2022-01-14 12:14:57,612 iteration 2400 : loss : 0.046552, loss_ce: 0.018366
2022-01-14 12:14:58,693 iteration 2401 : loss : 0.062132, loss_ce: 0.023920
2022-01-14 12:14:59,619 iteration 2402 : loss : 0.055325, loss_ce: 0.024519
2022-01-14 12:15:00,529 iteration 2403 : loss : 0.033000, loss_ce: 0.012335
2022-01-14 12:15:01,422 iteration 2404 : loss : 0.025582, loss_ce: 0.008576
2022-01-14 12:15:02,415 iteration 2405 : loss : 0.043900, loss_ce: 0.015587
2022-01-14 12:15:03,270 iteration 2406 : loss : 0.041152, loss_ce: 0.017416
2022-01-14 12:15:04,196 iteration 2407 : loss : 0.032899, loss_ce: 0.012669
2022-01-14 12:15:05,257 iteration 2408 : loss : 0.037806, loss_ce: 0.012284
2022-01-14 12:15:06,149 iteration 2409 : loss : 0.030210, loss_ce: 0.013174
2022-01-14 12:15:07,030 iteration 2410 : loss : 0.028437, loss_ce: 0.010308
2022-01-14 12:15:07,915 iteration 2411 : loss : 0.025578, loss_ce: 0.009640
2022-01-14 12:15:08,813 iteration 2412 : loss : 0.025654, loss_ce: 0.009707
2022-01-14 12:15:09,676 iteration 2413 : loss : 0.033187, loss_ce: 0.012360
2022-01-14 12:15:10,541 iteration 2414 : loss : 0.024950, loss_ce: 0.009937
 36%|██████████▎                  | 142/400 [40:36<1:13:11, 17.02s/it]2022-01-14 12:15:11,556 iteration 2415 : loss : 0.044487, loss_ce: 0.017038
2022-01-14 12:15:12,469 iteration 2416 : loss : 0.033652, loss_ce: 0.013184
2022-01-14 12:15:13,407 iteration 2417 : loss : 0.026780, loss_ce: 0.013465
2022-01-14 12:15:14,276 iteration 2418 : loss : 0.030298, loss_ce: 0.009756
2022-01-14 12:15:15,206 iteration 2419 : loss : 0.047090, loss_ce: 0.018583
2022-01-14 12:15:16,208 iteration 2420 : loss : 0.031794, loss_ce: 0.013113
2022-01-14 12:15:17,129 iteration 2421 : loss : 0.032457, loss_ce: 0.016296
2022-01-14 12:15:18,063 iteration 2422 : loss : 0.040663, loss_ce: 0.017880
2022-01-14 12:15:18,909 iteration 2423 : loss : 0.032117, loss_ce: 0.013993
2022-01-14 12:15:19,819 iteration 2424 : loss : 0.029429, loss_ce: 0.011757
2022-01-14 12:15:20,783 iteration 2425 : loss : 0.027670, loss_ce: 0.009024
2022-01-14 12:15:21,706 iteration 2426 : loss : 0.035886, loss_ce: 0.013332
2022-01-14 12:15:22,569 iteration 2427 : loss : 0.025886, loss_ce: 0.011203
2022-01-14 12:15:23,463 iteration 2428 : loss : 0.024023, loss_ce: 0.007451
2022-01-14 12:15:24,342 iteration 2429 : loss : 0.036856, loss_ce: 0.010575
2022-01-14 12:15:25,239 iteration 2430 : loss : 0.034700, loss_ce: 0.013523
2022-01-14 12:15:26,194 iteration 2431 : loss : 0.051007, loss_ce: 0.014197
 36%|██████████▎                  | 143/400 [40:52<1:11:09, 16.61s/it]2022-01-14 12:15:27,096 iteration 2432 : loss : 0.024365, loss_ce: 0.007852
2022-01-14 12:15:27,992 iteration 2433 : loss : 0.027977, loss_ce: 0.013008
2022-01-14 12:15:28,944 iteration 2434 : loss : 0.033033, loss_ce: 0.012848
2022-01-14 12:15:29,876 iteration 2435 : loss : 0.031701, loss_ce: 0.014698
2022-01-14 12:15:30,855 iteration 2436 : loss : 0.030702, loss_ce: 0.011611
2022-01-14 12:15:31,790 iteration 2437 : loss : 0.023212, loss_ce: 0.009514
2022-01-14 12:15:32,655 iteration 2438 : loss : 0.024175, loss_ce: 0.008843
2022-01-14 12:15:33,565 iteration 2439 : loss : 0.027192, loss_ce: 0.010538
2022-01-14 12:15:34,482 iteration 2440 : loss : 0.036666, loss_ce: 0.013668
2022-01-14 12:15:35,525 iteration 2441 : loss : 0.063888, loss_ce: 0.020066
2022-01-14 12:15:36,495 iteration 2442 : loss : 0.035036, loss_ce: 0.012885
2022-01-14 12:15:37,480 iteration 2443 : loss : 0.026185, loss_ce: 0.010599
2022-01-14 12:15:38,452 iteration 2444 : loss : 0.036361, loss_ce: 0.013893
2022-01-14 12:15:39,492 iteration 2445 : loss : 0.031269, loss_ce: 0.012349
2022-01-14 12:15:40,395 iteration 2446 : loss : 0.025279, loss_ce: 0.010567
2022-01-14 12:15:41,397 iteration 2447 : loss : 0.030784, loss_ce: 0.011153
2022-01-14 12:15:42,281 iteration 2448 : loss : 0.038189, loss_ce: 0.022327
 36%|██████████▍                  | 144/400 [41:08<1:10:12, 16.46s/it]2022-01-14 12:15:43,266 iteration 2449 : loss : 0.022447, loss_ce: 0.006381
2022-01-14 12:15:44,125 iteration 2450 : loss : 0.030586, loss_ce: 0.011523
2022-01-14 12:15:44,990 iteration 2451 : loss : 0.025722, loss_ce: 0.008819
2022-01-14 12:15:45,900 iteration 2452 : loss : 0.037624, loss_ce: 0.015668
2022-01-14 12:15:46,809 iteration 2453 : loss : 0.043062, loss_ce: 0.021564
2022-01-14 12:15:47,691 iteration 2454 : loss : 0.037996, loss_ce: 0.015123
2022-01-14 12:15:48,714 iteration 2455 : loss : 0.034784, loss_ce: 0.012115
2022-01-14 12:15:49,647 iteration 2456 : loss : 0.026797, loss_ce: 0.013052
2022-01-14 12:15:50,540 iteration 2457 : loss : 0.028582, loss_ce: 0.011992
2022-01-14 12:15:51,480 iteration 2458 : loss : 0.035932, loss_ce: 0.011802
2022-01-14 12:15:52,396 iteration 2459 : loss : 0.024092, loss_ce: 0.008420
2022-01-14 12:15:53,376 iteration 2460 : loss : 0.041699, loss_ce: 0.010861
2022-01-14 12:15:54,353 iteration 2461 : loss : 0.041325, loss_ce: 0.011273
2022-01-14 12:15:55,390 iteration 2462 : loss : 0.033673, loss_ce: 0.014562
2022-01-14 12:15:56,293 iteration 2463 : loss : 0.027264, loss_ce: 0.009746
2022-01-14 12:15:57,217 iteration 2464 : loss : 0.031676, loss_ce: 0.018366
2022-01-14 12:15:57,217 Training Data Eval:
2022-01-14 12:16:01,513   Average segmentation loss on training set: 0.0225
2022-01-14 12:16:01,513 Validation Data Eval:
2022-01-14 12:16:02,967   Average segmentation loss on validation set: 0.0730
2022-01-14 12:16:03,900 iteration 2465 : loss : 0.028576, loss_ce: 0.012761
 36%|██████████▌                  | 145/400 [41:29<1:16:30, 18.00s/it]2022-01-14 12:16:04,919 iteration 2466 : loss : 0.026885, loss_ce: 0.010037
2022-01-14 12:16:05,806 iteration 2467 : loss : 0.033747, loss_ce: 0.012414
2022-01-14 12:16:06,817 iteration 2468 : loss : 0.034215, loss_ce: 0.012228
2022-01-14 12:16:07,682 iteration 2469 : loss : 0.025512, loss_ce: 0.011439
2022-01-14 12:16:08,644 iteration 2470 : loss : 0.046216, loss_ce: 0.019869
2022-01-14 12:16:09,601 iteration 2471 : loss : 0.037465, loss_ce: 0.017218
2022-01-14 12:16:10,551 iteration 2472 : loss : 0.029641, loss_ce: 0.010585
2022-01-14 12:16:11,476 iteration 2473 : loss : 0.023513, loss_ce: 0.009303
2022-01-14 12:16:12,296 iteration 2474 : loss : 0.035677, loss_ce: 0.015972
2022-01-14 12:16:13,267 iteration 2475 : loss : 0.033427, loss_ce: 0.018345
2022-01-14 12:16:14,223 iteration 2476 : loss : 0.038329, loss_ce: 0.013264
2022-01-14 12:16:15,160 iteration 2477 : loss : 0.028089, loss_ce: 0.010376
2022-01-14 12:16:16,073 iteration 2478 : loss : 0.033872, loss_ce: 0.011316
2022-01-14 12:16:17,059 iteration 2479 : loss : 0.033092, loss_ce: 0.010462
2022-01-14 12:16:17,974 iteration 2480 : loss : 0.024721, loss_ce: 0.010466
2022-01-14 12:16:18,860 iteration 2481 : loss : 0.033306, loss_ce: 0.013674
2022-01-14 12:16:19,894 iteration 2482 : loss : 0.039973, loss_ce: 0.015644
 36%|██████████▌                  | 146/400 [41:45<1:13:39, 17.40s/it]2022-01-14 12:16:20,872 iteration 2483 : loss : 0.037167, loss_ce: 0.016253
2022-01-14 12:16:21,832 iteration 2484 : loss : 0.044731, loss_ce: 0.008820
2022-01-14 12:16:22,787 iteration 2485 : loss : 0.040756, loss_ce: 0.015109
2022-01-14 12:16:23,731 iteration 2486 : loss : 0.039097, loss_ce: 0.016021
2022-01-14 12:16:24,604 iteration 2487 : loss : 0.023331, loss_ce: 0.010177
2022-01-14 12:16:25,601 iteration 2488 : loss : 0.032989, loss_ce: 0.018709
2022-01-14 12:16:26,577 iteration 2489 : loss : 0.029882, loss_ce: 0.013014
2022-01-14 12:16:27,579 iteration 2490 : loss : 0.033237, loss_ce: 0.014616
2022-01-14 12:16:28,529 iteration 2491 : loss : 0.035216, loss_ce: 0.011461
2022-01-14 12:16:29,469 iteration 2492 : loss : 0.033222, loss_ce: 0.013301
2022-01-14 12:16:30,352 iteration 2493 : loss : 0.031628, loss_ce: 0.011839
2022-01-14 12:16:31,283 iteration 2494 : loss : 0.036702, loss_ce: 0.013382
2022-01-14 12:16:32,312 iteration 2495 : loss : 0.025533, loss_ce: 0.011428
2022-01-14 12:16:33,113 iteration 2496 : loss : 0.020036, loss_ce: 0.007642
2022-01-14 12:16:33,995 iteration 2497 : loss : 0.031143, loss_ce: 0.011626
2022-01-14 12:16:35,023 iteration 2498 : loss : 0.022725, loss_ce: 0.008723
2022-01-14 12:16:35,971 iteration 2499 : loss : 0.030671, loss_ce: 0.013413
 37%|██████████▋                  | 147/400 [42:01<1:11:42, 17.01s/it]2022-01-14 12:16:36,982 iteration 2500 : loss : 0.028733, loss_ce: 0.009707
2022-01-14 12:16:37,923 iteration 2501 : loss : 0.022830, loss_ce: 0.009307
2022-01-14 12:16:38,882 iteration 2502 : loss : 0.026831, loss_ce: 0.011515
2022-01-14 12:16:39,776 iteration 2503 : loss : 0.030851, loss_ce: 0.015156
2022-01-14 12:16:40,738 iteration 2504 : loss : 0.042240, loss_ce: 0.015062
2022-01-14 12:16:41,661 iteration 2505 : loss : 0.033937, loss_ce: 0.011298
2022-01-14 12:16:42,612 iteration 2506 : loss : 0.026192, loss_ce: 0.011168
2022-01-14 12:16:43,489 iteration 2507 : loss : 0.022368, loss_ce: 0.008713
2022-01-14 12:16:44,331 iteration 2508 : loss : 0.028613, loss_ce: 0.012206
2022-01-14 12:16:45,226 iteration 2509 : loss : 0.024681, loss_ce: 0.010447
2022-01-14 12:16:46,087 iteration 2510 : loss : 0.035038, loss_ce: 0.009893
2022-01-14 12:16:46,995 iteration 2511 : loss : 0.030304, loss_ce: 0.014372
2022-01-14 12:16:47,899 iteration 2512 : loss : 0.054511, loss_ce: 0.029518
2022-01-14 12:16:48,813 iteration 2513 : loss : 0.041750, loss_ce: 0.016921
2022-01-14 12:16:49,746 iteration 2514 : loss : 0.029556, loss_ce: 0.012635
2022-01-14 12:16:50,650 iteration 2515 : loss : 0.035681, loss_ce: 0.011609
2022-01-14 12:16:51,526 iteration 2516 : loss : 0.031674, loss_ce: 0.012031
 37%|██████████▋                  | 148/400 [42:17<1:09:35, 16.57s/it]2022-01-14 12:16:52,486 iteration 2517 : loss : 0.025713, loss_ce: 0.009199
2022-01-14 12:16:53,494 iteration 2518 : loss : 0.027856, loss_ce: 0.011784
2022-01-14 12:16:54,418 iteration 2519 : loss : 0.040852, loss_ce: 0.015245
2022-01-14 12:16:55,319 iteration 2520 : loss : 0.023423, loss_ce: 0.007891
2022-01-14 12:16:56,250 iteration 2521 : loss : 0.025939, loss_ce: 0.012877
2022-01-14 12:16:57,113 iteration 2522 : loss : 0.023842, loss_ce: 0.010034
2022-01-14 12:16:57,917 iteration 2523 : loss : 0.041103, loss_ce: 0.009316
2022-01-14 12:16:58,859 iteration 2524 : loss : 0.025181, loss_ce: 0.011647
2022-01-14 12:16:59,744 iteration 2525 : loss : 0.029377, loss_ce: 0.012829
2022-01-14 12:17:00,606 iteration 2526 : loss : 0.024886, loss_ce: 0.009371
2022-01-14 12:17:01,574 iteration 2527 : loss : 0.031484, loss_ce: 0.012271
2022-01-14 12:17:02,467 iteration 2528 : loss : 0.026424, loss_ce: 0.011318
2022-01-14 12:17:03,399 iteration 2529 : loss : 0.024970, loss_ce: 0.009133
2022-01-14 12:17:04,323 iteration 2530 : loss : 0.031454, loss_ce: 0.010386
2022-01-14 12:17:05,228 iteration 2531 : loss : 0.062560, loss_ce: 0.026157
2022-01-14 12:17:06,189 iteration 2532 : loss : 0.030297, loss_ce: 0.012942
2022-01-14 12:17:07,119 iteration 2533 : loss : 0.036461, loss_ce: 0.022632
 37%|██████████▊                  | 149/400 [42:33<1:08:05, 16.28s/it]2022-01-14 12:17:08,045 iteration 2534 : loss : 0.020092, loss_ce: 0.008986
2022-01-14 12:17:09,002 iteration 2535 : loss : 0.027408, loss_ce: 0.008428
2022-01-14 12:17:09,991 iteration 2536 : loss : 0.030133, loss_ce: 0.013757
2022-01-14 12:17:10,950 iteration 2537 : loss : 0.045291, loss_ce: 0.015496
2022-01-14 12:17:11,948 iteration 2538 : loss : 0.038213, loss_ce: 0.014299
2022-01-14 12:17:12,825 iteration 2539 : loss : 0.028164, loss_ce: 0.011410
2022-01-14 12:17:13,744 iteration 2540 : loss : 0.028416, loss_ce: 0.011047
2022-01-14 12:17:14,799 iteration 2541 : loss : 0.075393, loss_ce: 0.020098
2022-01-14 12:17:15,666 iteration 2542 : loss : 0.029481, loss_ce: 0.010860
2022-01-14 12:17:16,569 iteration 2543 : loss : 0.027968, loss_ce: 0.009841
2022-01-14 12:17:17,566 iteration 2544 : loss : 0.039728, loss_ce: 0.015767
2022-01-14 12:17:18,537 iteration 2545 : loss : 0.030817, loss_ce: 0.015232
2022-01-14 12:17:19,409 iteration 2546 : loss : 0.030073, loss_ce: 0.013715
2022-01-14 12:17:20,340 iteration 2547 : loss : 0.052474, loss_ce: 0.011040
2022-01-14 12:17:21,252 iteration 2548 : loss : 0.033625, loss_ce: 0.013074
2022-01-14 12:17:22,239 iteration 2549 : loss : 0.046456, loss_ce: 0.015744
2022-01-14 12:17:22,240 Training Data Eval:
2022-01-14 12:17:26,552   Average segmentation loss on training set: 0.0291
2022-01-14 12:17:26,553 Validation Data Eval:
2022-01-14 12:17:28,002   Average segmentation loss on validation set: 0.1157
2022-01-14 12:17:28,885 iteration 2550 : loss : 0.047129, loss_ce: 0.027614
 38%|██████████▉                  | 150/400 [42:54<1:14:40, 17.92s/it]2022-01-14 12:17:29,830 iteration 2551 : loss : 0.033119, loss_ce: 0.011386
2022-01-14 12:17:30,754 iteration 2552 : loss : 0.029401, loss_ce: 0.011919
2022-01-14 12:17:31,753 iteration 2553 : loss : 0.042211, loss_ce: 0.014926
2022-01-14 12:17:32,718 iteration 2554 : loss : 0.059772, loss_ce: 0.015071
2022-01-14 12:17:33,623 iteration 2555 : loss : 0.033607, loss_ce: 0.009237
2022-01-14 12:17:34,472 iteration 2556 : loss : 0.023211, loss_ce: 0.010508
2022-01-14 12:17:35,446 iteration 2557 : loss : 0.034258, loss_ce: 0.013096
2022-01-14 12:17:36,421 iteration 2558 : loss : 0.028627, loss_ce: 0.012152
2022-01-14 12:17:37,413 iteration 2559 : loss : 0.067202, loss_ce: 0.013628
2022-01-14 12:17:38,411 iteration 2560 : loss : 0.024095, loss_ce: 0.008922
2022-01-14 12:17:39,326 iteration 2561 : loss : 0.032511, loss_ce: 0.013460
2022-01-14 12:17:40,207 iteration 2562 : loss : 0.032692, loss_ce: 0.016979
2022-01-14 12:17:41,115 iteration 2563 : loss : 0.035948, loss_ce: 0.011152
2022-01-14 12:17:42,040 iteration 2564 : loss : 0.030993, loss_ce: 0.013912
2022-01-14 12:17:42,946 iteration 2565 : loss : 0.044643, loss_ce: 0.013364
2022-01-14 12:17:43,844 iteration 2566 : loss : 0.032146, loss_ce: 0.015276
2022-01-14 12:17:44,871 iteration 2567 : loss : 0.040789, loss_ce: 0.018265
 38%|██████████▉                  | 151/400 [43:10<1:11:58, 17.34s/it]2022-01-14 12:17:45,861 iteration 2568 : loss : 0.027512, loss_ce: 0.012017
2022-01-14 12:17:46,803 iteration 2569 : loss : 0.041678, loss_ce: 0.015190
2022-01-14 12:17:47,696 iteration 2570 : loss : 0.043026, loss_ce: 0.012384
2022-01-14 12:17:48,624 iteration 2571 : loss : 0.042090, loss_ce: 0.018914
2022-01-14 12:17:49,479 iteration 2572 : loss : 0.025130, loss_ce: 0.007351
2022-01-14 12:17:50,359 iteration 2573 : loss : 0.024075, loss_ce: 0.010100
2022-01-14 12:17:51,267 iteration 2574 : loss : 0.049500, loss_ce: 0.021767
2022-01-14 12:17:52,227 iteration 2575 : loss : 0.031250, loss_ce: 0.010831
2022-01-14 12:17:53,265 iteration 2576 : loss : 0.028948, loss_ce: 0.012731
2022-01-14 12:17:54,153 iteration 2577 : loss : 0.032424, loss_ce: 0.011393
2022-01-14 12:17:55,107 iteration 2578 : loss : 0.031641, loss_ce: 0.015958
2022-01-14 12:17:56,011 iteration 2579 : loss : 0.033838, loss_ce: 0.011828
2022-01-14 12:17:56,976 iteration 2580 : loss : 0.025921, loss_ce: 0.007712
2022-01-14 12:17:58,026 iteration 2581 : loss : 0.030408, loss_ce: 0.010910
2022-01-14 12:17:58,838 iteration 2582 : loss : 0.031612, loss_ce: 0.012504
2022-01-14 12:17:59,803 iteration 2583 : loss : 0.028058, loss_ce: 0.009875
2022-01-14 12:18:00,700 iteration 2584 : loss : 0.023152, loss_ce: 0.008794
 38%|███████████                  | 152/400 [43:26<1:09:48, 16.89s/it]2022-01-14 12:18:01,733 iteration 2585 : loss : 0.050376, loss_ce: 0.022600
2022-01-14 12:18:02,668 iteration 2586 : loss : 0.036466, loss_ce: 0.014916
2022-01-14 12:18:03,519 iteration 2587 : loss : 0.019442, loss_ce: 0.007087
2022-01-14 12:18:04,418 iteration 2588 : loss : 0.028130, loss_ce: 0.011643
2022-01-14 12:18:05,264 iteration 2589 : loss : 0.030701, loss_ce: 0.011056
2022-01-14 12:18:06,206 iteration 2590 : loss : 0.051098, loss_ce: 0.015666
2022-01-14 12:18:07,122 iteration 2591 : loss : 0.034405, loss_ce: 0.015525
2022-01-14 12:18:08,023 iteration 2592 : loss : 0.038418, loss_ce: 0.014980
2022-01-14 12:18:08,908 iteration 2593 : loss : 0.046870, loss_ce: 0.019524
2022-01-14 12:18:09,878 iteration 2594 : loss : 0.028350, loss_ce: 0.010585
2022-01-14 12:18:10,920 iteration 2595 : loss : 0.043327, loss_ce: 0.013090
2022-01-14 12:18:11,767 iteration 2596 : loss : 0.027358, loss_ce: 0.008601
2022-01-14 12:18:12,702 iteration 2597 : loss : 0.056243, loss_ce: 0.015760
2022-01-14 12:18:13,590 iteration 2598 : loss : 0.027386, loss_ce: 0.012219
2022-01-14 12:18:14,560 iteration 2599 : loss : 0.026439, loss_ce: 0.012530
2022-01-14 12:18:15,481 iteration 2600 : loss : 0.036813, loss_ce: 0.012212
2022-01-14 12:18:16,424 iteration 2601 : loss : 0.036217, loss_ce: 0.016525
 38%|███████████                  | 153/400 [43:42<1:08:05, 16.54s/it]2022-01-14 12:18:17,432 iteration 2602 : loss : 0.028462, loss_ce: 0.008249
2022-01-14 12:18:18,458 iteration 2603 : loss : 0.037105, loss_ce: 0.015718
2022-01-14 12:18:19,389 iteration 2604 : loss : 0.036739, loss_ce: 0.015678
2022-01-14 12:18:20,178 iteration 2605 : loss : 0.023535, loss_ce: 0.007020
2022-01-14 12:18:21,247 iteration 2606 : loss : 0.047257, loss_ce: 0.015672
2022-01-14 12:18:22,219 iteration 2607 : loss : 0.042404, loss_ce: 0.015771
2022-01-14 12:18:23,153 iteration 2608 : loss : 0.035489, loss_ce: 0.016256
2022-01-14 12:18:24,192 iteration 2609 : loss : 0.052577, loss_ce: 0.018923
2022-01-14 12:18:25,174 iteration 2610 : loss : 0.032493, loss_ce: 0.011147
2022-01-14 12:18:26,128 iteration 2611 : loss : 0.033178, loss_ce: 0.013517
2022-01-14 12:18:27,124 iteration 2612 : loss : 0.055245, loss_ce: 0.024031
2022-01-14 12:18:27,987 iteration 2613 : loss : 0.035571, loss_ce: 0.013963
2022-01-14 12:18:28,991 iteration 2614 : loss : 0.038322, loss_ce: 0.013347
2022-01-14 12:18:29,893 iteration 2615 : loss : 0.037356, loss_ce: 0.013140
2022-01-14 12:18:30,827 iteration 2616 : loss : 0.037399, loss_ce: 0.016833
2022-01-14 12:18:31,743 iteration 2617 : loss : 0.036089, loss_ce: 0.011888
2022-01-14 12:18:32,612 iteration 2618 : loss : 0.027776, loss_ce: 0.011117
 38%|███████████▏                 | 154/400 [43:58<1:07:22, 16.43s/it]2022-01-14 12:18:33,568 iteration 2619 : loss : 0.035327, loss_ce: 0.012289
2022-01-14 12:18:34,470 iteration 2620 : loss : 0.029223, loss_ce: 0.014404
2022-01-14 12:18:35,472 iteration 2621 : loss : 0.037000, loss_ce: 0.013645
2022-01-14 12:18:36,395 iteration 2622 : loss : 0.043542, loss_ce: 0.011440
2022-01-14 12:18:37,352 iteration 2623 : loss : 0.052148, loss_ce: 0.021827
2022-01-14 12:18:38,243 iteration 2624 : loss : 0.022800, loss_ce: 0.007595
2022-01-14 12:18:39,200 iteration 2625 : loss : 0.078970, loss_ce: 0.016690
2022-01-14 12:18:40,151 iteration 2626 : loss : 0.038851, loss_ce: 0.017365
2022-01-14 12:18:41,197 iteration 2627 : loss : 0.042901, loss_ce: 0.017573
2022-01-14 12:18:42,069 iteration 2628 : loss : 0.032950, loss_ce: 0.014228
2022-01-14 12:18:43,095 iteration 2629 : loss : 0.052165, loss_ce: 0.027285
2022-01-14 12:18:44,049 iteration 2630 : loss : 0.053555, loss_ce: 0.021396
2022-01-14 12:18:44,960 iteration 2631 : loss : 0.037480, loss_ce: 0.016809
2022-01-14 12:18:45,885 iteration 2632 : loss : 0.027556, loss_ce: 0.011192
2022-01-14 12:18:46,855 iteration 2633 : loss : 0.040928, loss_ce: 0.021739
2022-01-14 12:18:47,790 iteration 2634 : loss : 0.045329, loss_ce: 0.014151
2022-01-14 12:18:47,790 Training Data Eval:
2022-01-14 12:18:52,086   Average segmentation loss on training set: 0.0245
2022-01-14 12:18:52,086 Validation Data Eval:
2022-01-14 12:18:53,545   Average segmentation loss on validation set: 0.0943
2022-01-14 12:18:54,479 iteration 2635 : loss : 0.025272, loss_ce: 0.009670
 39%|███████████▏                 | 155/400 [44:20<1:13:45, 18.06s/it]2022-01-14 12:18:55,460 iteration 2636 : loss : 0.036312, loss_ce: 0.016244
2022-01-14 12:18:56,471 iteration 2637 : loss : 0.046913, loss_ce: 0.017725
2022-01-14 12:18:57,369 iteration 2638 : loss : 0.045438, loss_ce: 0.017726
2022-01-14 12:18:58,255 iteration 2639 : loss : 0.034973, loss_ce: 0.018430
2022-01-14 12:18:59,154 iteration 2640 : loss : 0.032876, loss_ce: 0.012318
2022-01-14 12:19:00,068 iteration 2641 : loss : 0.040926, loss_ce: 0.018519
2022-01-14 12:19:00,951 iteration 2642 : loss : 0.030225, loss_ce: 0.009881
2022-01-14 12:19:02,000 iteration 2643 : loss : 0.025182, loss_ce: 0.008293
2022-01-14 12:19:02,905 iteration 2644 : loss : 0.030646, loss_ce: 0.011100
2022-01-14 12:19:03,795 iteration 2645 : loss : 0.025932, loss_ce: 0.008745
2022-01-14 12:19:04,924 iteration 2646 : loss : 0.029687, loss_ce: 0.010014
2022-01-14 12:19:05,927 iteration 2647 : loss : 0.047712, loss_ce: 0.019158
2022-01-14 12:19:06,849 iteration 2648 : loss : 0.049355, loss_ce: 0.026176
2022-01-14 12:19:07,798 iteration 2649 : loss : 0.038598, loss_ce: 0.016223
2022-01-14 12:19:08,787 iteration 2650 : loss : 0.028131, loss_ce: 0.009555
2022-01-14 12:19:09,745 iteration 2651 : loss : 0.035022, loss_ce: 0.013227
2022-01-14 12:19:10,602 iteration 2652 : loss : 0.024999, loss_ce: 0.009493
 39%|███████████▎                 | 156/400 [44:36<1:11:05, 17.48s/it]2022-01-14 12:19:11,651 iteration 2653 : loss : 0.027224, loss_ce: 0.013230
2022-01-14 12:19:12,594 iteration 2654 : loss : 0.023961, loss_ce: 0.007546
2022-01-14 12:19:13,631 iteration 2655 : loss : 0.042404, loss_ce: 0.021220
2022-01-14 12:19:14,549 iteration 2656 : loss : 0.028565, loss_ce: 0.009940
2022-01-14 12:19:15,479 iteration 2657 : loss : 0.031290, loss_ce: 0.011670
2022-01-14 12:19:16,279 iteration 2658 : loss : 0.023684, loss_ce: 0.011847
2022-01-14 12:19:17,142 iteration 2659 : loss : 0.059434, loss_ce: 0.013825
2022-01-14 12:19:18,106 iteration 2660 : loss : 0.036662, loss_ce: 0.014068
2022-01-14 12:19:18,999 iteration 2661 : loss : 0.034346, loss_ce: 0.018099
2022-01-14 12:19:19,916 iteration 2662 : loss : 0.031995, loss_ce: 0.014541
2022-01-14 12:19:20,814 iteration 2663 : loss : 0.031727, loss_ce: 0.008649
2022-01-14 12:19:21,848 iteration 2664 : loss : 0.038415, loss_ce: 0.016760
2022-01-14 12:19:22,783 iteration 2665 : loss : 0.035241, loss_ce: 0.013079
2022-01-14 12:19:23,683 iteration 2666 : loss : 0.022687, loss_ce: 0.007789
2022-01-14 12:19:24,677 iteration 2667 : loss : 0.053210, loss_ce: 0.020997
2022-01-14 12:19:25,565 iteration 2668 : loss : 0.029113, loss_ce: 0.009948
2022-01-14 12:19:26,466 iteration 2669 : loss : 0.034837, loss_ce: 0.011878
 39%|███████████▍                 | 157/400 [44:52<1:08:50, 17.00s/it]2022-01-14 12:19:27,490 iteration 2670 : loss : 0.050916, loss_ce: 0.021578
2022-01-14 12:19:28,517 iteration 2671 : loss : 0.051553, loss_ce: 0.017372
2022-01-14 12:19:29,484 iteration 2672 : loss : 0.023640, loss_ce: 0.008843
2022-01-14 12:19:30,360 iteration 2673 : loss : 0.024338, loss_ce: 0.011618
2022-01-14 12:19:31,323 iteration 2674 : loss : 0.031448, loss_ce: 0.013193
2022-01-14 12:19:32,124 iteration 2675 : loss : 0.022895, loss_ce: 0.009964
2022-01-14 12:19:33,190 iteration 2676 : loss : 0.049027, loss_ce: 0.011956
2022-01-14 12:19:34,140 iteration 2677 : loss : 0.033706, loss_ce: 0.013341
2022-01-14 12:19:35,069 iteration 2678 : loss : 0.026019, loss_ce: 0.010141
2022-01-14 12:19:35,987 iteration 2679 : loss : 0.041714, loss_ce: 0.013773
2022-01-14 12:19:36,910 iteration 2680 : loss : 0.029509, loss_ce: 0.011797
2022-01-14 12:19:37,826 iteration 2681 : loss : 0.027526, loss_ce: 0.009111
2022-01-14 12:19:38,773 iteration 2682 : loss : 0.024889, loss_ce: 0.009474
2022-01-14 12:19:39,695 iteration 2683 : loss : 0.041987, loss_ce: 0.012455
2022-01-14 12:19:40,557 iteration 2684 : loss : 0.031584, loss_ce: 0.016923
2022-01-14 12:19:41,495 iteration 2685 : loss : 0.035265, loss_ce: 0.014823
2022-01-14 12:19:42,367 iteration 2686 : loss : 0.030054, loss_ce: 0.013453
 40%|███████████▍                 | 158/400 [45:08<1:07:13, 16.67s/it]2022-01-14 12:19:43,256 iteration 2687 : loss : 0.029883, loss_ce: 0.008802
2022-01-14 12:19:44,180 iteration 2688 : loss : 0.040127, loss_ce: 0.013029
2022-01-14 12:19:45,081 iteration 2689 : loss : 0.030682, loss_ce: 0.010757
2022-01-14 12:19:46,120 iteration 2690 : loss : 0.039882, loss_ce: 0.016679
2022-01-14 12:19:46,982 iteration 2691 : loss : 0.024958, loss_ce: 0.009943
2022-01-14 12:19:47,870 iteration 2692 : loss : 0.029698, loss_ce: 0.009031
2022-01-14 12:19:48,815 iteration 2693 : loss : 0.045008, loss_ce: 0.015630
2022-01-14 12:19:49,839 iteration 2694 : loss : 0.038667, loss_ce: 0.013127
2022-01-14 12:19:50,743 iteration 2695 : loss : 0.023762, loss_ce: 0.010153
2022-01-14 12:19:51,694 iteration 2696 : loss : 0.033438, loss_ce: 0.017322
2022-01-14 12:19:52,545 iteration 2697 : loss : 0.028525, loss_ce: 0.013538
2022-01-14 12:19:53,328 iteration 2698 : loss : 0.020833, loss_ce: 0.009464
2022-01-14 12:19:54,234 iteration 2699 : loss : 0.027744, loss_ce: 0.010419
2022-01-14 12:19:55,221 iteration 2700 : loss : 0.027704, loss_ce: 0.013492
2022-01-14 12:19:56,139 iteration 2701 : loss : 0.027840, loss_ce: 0.011753
2022-01-14 12:19:57,114 iteration 2702 : loss : 0.064812, loss_ce: 0.012919
2022-01-14 12:19:58,020 iteration 2703 : loss : 0.030137, loss_ce: 0.011893
 40%|███████████▌                 | 159/400 [45:23<1:05:43, 16.36s/it]2022-01-14 12:19:59,122 iteration 2704 : loss : 0.031759, loss_ce: 0.013800
2022-01-14 12:19:59,988 iteration 2705 : loss : 0.040723, loss_ce: 0.010715
2022-01-14 12:20:00,871 iteration 2706 : loss : 0.031680, loss_ce: 0.016245
2022-01-14 12:20:01,849 iteration 2707 : loss : 0.029609, loss_ce: 0.008921
2022-01-14 12:20:02,695 iteration 2708 : loss : 0.024506, loss_ce: 0.009550
2022-01-14 12:20:03,601 iteration 2709 : loss : 0.025313, loss_ce: 0.007554
2022-01-14 12:20:04,474 iteration 2710 : loss : 0.028682, loss_ce: 0.009615
2022-01-14 12:20:05,518 iteration 2711 : loss : 0.034094, loss_ce: 0.011615
2022-01-14 12:20:06,384 iteration 2712 : loss : 0.021453, loss_ce: 0.007949
2022-01-14 12:20:07,390 iteration 2713 : loss : 0.043589, loss_ce: 0.014224
2022-01-14 12:20:08,257 iteration 2714 : loss : 0.028679, loss_ce: 0.009397
2022-01-14 12:20:09,198 iteration 2715 : loss : 0.056190, loss_ce: 0.027972
2022-01-14 12:20:10,103 iteration 2716 : loss : 0.029067, loss_ce: 0.009810
2022-01-14 12:20:10,966 iteration 2717 : loss : 0.022129, loss_ce: 0.010167
2022-01-14 12:20:11,820 iteration 2718 : loss : 0.024192, loss_ce: 0.008837
2022-01-14 12:20:12,808 iteration 2719 : loss : 0.074802, loss_ce: 0.025389
2022-01-14 12:20:12,809 Training Data Eval:
2022-01-14 12:20:17,116   Average segmentation loss on training set: 0.0234
2022-01-14 12:20:17,116 Validation Data Eval:
2022-01-14 12:20:18,563   Average segmentation loss on validation set: 0.0799
2022-01-14 12:20:19,415 iteration 2720 : loss : 0.029336, loss_ce: 0.012392
 40%|███████████▌                 | 160/400 [45:45<1:11:29, 17.87s/it]2022-01-14 12:20:20,427 iteration 2721 : loss : 0.029328, loss_ce: 0.010768
2022-01-14 12:20:21,396 iteration 2722 : loss : 0.044594, loss_ce: 0.018549
2022-01-14 12:20:22,334 iteration 2723 : loss : 0.025086, loss_ce: 0.009110
2022-01-14 12:20:23,200 iteration 2724 : loss : 0.035461, loss_ce: 0.011070
2022-01-14 12:20:24,016 iteration 2725 : loss : 0.029037, loss_ce: 0.010443
2022-01-14 12:20:24,907 iteration 2726 : loss : 0.026671, loss_ce: 0.009572
2022-01-14 12:20:25,751 iteration 2727 : loss : 0.023581, loss_ce: 0.007384
2022-01-14 12:20:26,784 iteration 2728 : loss : 0.034222, loss_ce: 0.016387
2022-01-14 12:20:27,724 iteration 2729 : loss : 0.046110, loss_ce: 0.023951
2022-01-14 12:20:28,690 iteration 2730 : loss : 0.028281, loss_ce: 0.011599
2022-01-14 12:20:29,650 iteration 2731 : loss : 0.032261, loss_ce: 0.013777
2022-01-14 12:20:30,641 iteration 2732 : loss : 0.047364, loss_ce: 0.017342
2022-01-14 12:20:31,614 iteration 2733 : loss : 0.034122, loss_ce: 0.012798
2022-01-14 12:20:32,571 iteration 2734 : loss : 0.026512, loss_ce: 0.007530
2022-01-14 12:20:33,410 iteration 2735 : loss : 0.024178, loss_ce: 0.009753
2022-01-14 12:20:34,392 iteration 2736 : loss : 0.032853, loss_ce: 0.015825
2022-01-14 12:20:35,303 iteration 2737 : loss : 0.042265, loss_ce: 0.016847
 40%|███████████▋                 | 161/400 [46:01<1:08:48, 17.27s/it]2022-01-14 12:20:36,282 iteration 2738 : loss : 0.029539, loss_ce: 0.014770
2022-01-14 12:20:37,181 iteration 2739 : loss : 0.027681, loss_ce: 0.013668
2022-01-14 12:20:38,134 iteration 2740 : loss : 0.029897, loss_ce: 0.012592
2022-01-14 12:20:39,091 iteration 2741 : loss : 0.028617, loss_ce: 0.008584
2022-01-14 12:20:39,950 iteration 2742 : loss : 0.025515, loss_ce: 0.009771
2022-01-14 12:20:40,879 iteration 2743 : loss : 0.035055, loss_ce: 0.019612
2022-01-14 12:20:41,910 iteration 2744 : loss : 0.026458, loss_ce: 0.009269
2022-01-14 12:20:42,824 iteration 2745 : loss : 0.023130, loss_ce: 0.009030
2022-01-14 12:20:43,691 iteration 2746 : loss : 0.039334, loss_ce: 0.010540
2022-01-14 12:20:44,619 iteration 2747 : loss : 0.026364, loss_ce: 0.008029
2022-01-14 12:20:45,576 iteration 2748 : loss : 0.027712, loss_ce: 0.010254
2022-01-14 12:20:46,438 iteration 2749 : loss : 0.026789, loss_ce: 0.011218
2022-01-14 12:20:47,397 iteration 2750 : loss : 0.049852, loss_ce: 0.014813
2022-01-14 12:20:48,281 iteration 2751 : loss : 0.027854, loss_ce: 0.010698
2022-01-14 12:20:49,121 iteration 2752 : loss : 0.046922, loss_ce: 0.011146
2022-01-14 12:20:50,143 iteration 2753 : loss : 0.037810, loss_ce: 0.016253
2022-01-14 12:20:51,093 iteration 2754 : loss : 0.026153, loss_ce: 0.010733
 40%|███████████▋                 | 162/400 [46:16<1:06:46, 16.83s/it]2022-01-14 12:20:52,094 iteration 2755 : loss : 0.033583, loss_ce: 0.014911
2022-01-14 12:20:53,010 iteration 2756 : loss : 0.050891, loss_ce: 0.029348
2022-01-14 12:20:53,935 iteration 2757 : loss : 0.025501, loss_ce: 0.009378
2022-01-14 12:20:54,924 iteration 2758 : loss : 0.044922, loss_ce: 0.014508
2022-01-14 12:20:55,873 iteration 2759 : loss : 0.027340, loss_ce: 0.009001
2022-01-14 12:20:56,804 iteration 2760 : loss : 0.032426, loss_ce: 0.011096
2022-01-14 12:20:57,642 iteration 2761 : loss : 0.053062, loss_ce: 0.019689
2022-01-14 12:20:58,505 iteration 2762 : loss : 0.021158, loss_ce: 0.008230
2022-01-14 12:20:59,476 iteration 2763 : loss : 0.041364, loss_ce: 0.013252
2022-01-14 12:21:00,394 iteration 2764 : loss : 0.031540, loss_ce: 0.012435
2022-01-14 12:21:01,323 iteration 2765 : loss : 0.029712, loss_ce: 0.011519
2022-01-14 12:21:02,217 iteration 2766 : loss : 0.027056, loss_ce: 0.010970
2022-01-14 12:21:03,167 iteration 2767 : loss : 0.025664, loss_ce: 0.009494
2022-01-14 12:21:04,034 iteration 2768 : loss : 0.021838, loss_ce: 0.006125
2022-01-14 12:21:04,956 iteration 2769 : loss : 0.021402, loss_ce: 0.009570
2022-01-14 12:21:05,876 iteration 2770 : loss : 0.026157, loss_ce: 0.012579
2022-01-14 12:21:06,778 iteration 2771 : loss : 0.024691, loss_ce: 0.007846
 41%|███████████▊                 | 163/400 [46:32<1:05:07, 16.49s/it]2022-01-14 12:21:07,791 iteration 2772 : loss : 0.026181, loss_ce: 0.012435
2022-01-14 12:21:08,662 iteration 2773 : loss : 0.024928, loss_ce: 0.010022
2022-01-14 12:21:09,502 iteration 2774 : loss : 0.025957, loss_ce: 0.006208
2022-01-14 12:21:10,396 iteration 2775 : loss : 0.020999, loss_ce: 0.007856
2022-01-14 12:21:11,274 iteration 2776 : loss : 0.025490, loss_ce: 0.009894
2022-01-14 12:21:12,189 iteration 2777 : loss : 0.019508, loss_ce: 0.008053
2022-01-14 12:21:13,181 iteration 2778 : loss : 0.061231, loss_ce: 0.023674
2022-01-14 12:21:14,228 iteration 2779 : loss : 0.028159, loss_ce: 0.010123
2022-01-14 12:21:15,099 iteration 2780 : loss : 0.019302, loss_ce: 0.006449
2022-01-14 12:21:16,066 iteration 2781 : loss : 0.035419, loss_ce: 0.012194
2022-01-14 12:21:16,974 iteration 2782 : loss : 0.026240, loss_ce: 0.009199
2022-01-14 12:21:17,852 iteration 2783 : loss : 0.035084, loss_ce: 0.018207
2022-01-14 12:21:18,894 iteration 2784 : loss : 0.028351, loss_ce: 0.008751
2022-01-14 12:21:19,875 iteration 2785 : loss : 0.028916, loss_ce: 0.007698
2022-01-14 12:21:20,843 iteration 2786 : loss : 0.032141, loss_ce: 0.013566
2022-01-14 12:21:21,823 iteration 2787 : loss : 0.020440, loss_ce: 0.008818
2022-01-14 12:21:22,703 iteration 2788 : loss : 0.022644, loss_ce: 0.011732
 41%|███████████▉                 | 164/400 [46:48<1:04:11, 16.32s/it]2022-01-14 12:21:23,659 iteration 2789 : loss : 0.033712, loss_ce: 0.012470
2022-01-14 12:21:24,596 iteration 2790 : loss : 0.030062, loss_ce: 0.008939
2022-01-14 12:21:25,487 iteration 2791 : loss : 0.027098, loss_ce: 0.011773
2022-01-14 12:21:26,472 iteration 2792 : loss : 0.047795, loss_ce: 0.017472
2022-01-14 12:21:27,347 iteration 2793 : loss : 0.025701, loss_ce: 0.010032
2022-01-14 12:21:28,307 iteration 2794 : loss : 0.031115, loss_ce: 0.010203
2022-01-14 12:21:29,183 iteration 2795 : loss : 0.023927, loss_ce: 0.007392
2022-01-14 12:21:30,137 iteration 2796 : loss : 0.036642, loss_ce: 0.014120
2022-01-14 12:21:31,074 iteration 2797 : loss : 0.035412, loss_ce: 0.014339
2022-01-14 12:21:32,064 iteration 2798 : loss : 0.035492, loss_ce: 0.018113
2022-01-14 12:21:32,940 iteration 2799 : loss : 0.017999, loss_ce: 0.007500
2022-01-14 12:21:33,805 iteration 2800 : loss : 0.044604, loss_ce: 0.019664
2022-01-14 12:21:34,651 iteration 2801 : loss : 0.018658, loss_ce: 0.005751
2022-01-14 12:21:35,641 iteration 2802 : loss : 0.028249, loss_ce: 0.009717
2022-01-14 12:21:36,548 iteration 2803 : loss : 0.026107, loss_ce: 0.010789
2022-01-14 12:21:37,437 iteration 2804 : loss : 0.027375, loss_ce: 0.010568
2022-01-14 12:21:37,437 Training Data Eval:
2022-01-14 12:21:41,727   Average segmentation loss on training set: 0.0208
2022-01-14 12:21:41,727 Validation Data Eval:
2022-01-14 12:21:43,178   Average segmentation loss on validation set: 0.0781
2022-01-14 12:21:44,069 iteration 2805 : loss : 0.023711, loss_ce: 0.009692
 41%|███████████▉                 | 165/400 [47:09<1:09:50, 17.83s/it]2022-01-14 12:21:45,174 iteration 2806 : loss : 0.031133, loss_ce: 0.012717
2022-01-14 12:21:46,020 iteration 2807 : loss : 0.020472, loss_ce: 0.007252
2022-01-14 12:21:46,877 iteration 2808 : loss : 0.019147, loss_ce: 0.007398
2022-01-14 12:21:47,824 iteration 2809 : loss : 0.020282, loss_ce: 0.006717
2022-01-14 12:21:48,731 iteration 2810 : loss : 0.031974, loss_ce: 0.016466
2022-01-14 12:21:49,745 iteration 2811 : loss : 0.031481, loss_ce: 0.010354
2022-01-14 12:21:50,757 iteration 2812 : loss : 0.024188, loss_ce: 0.009093
2022-01-14 12:21:51,595 iteration 2813 : loss : 0.026510, loss_ce: 0.010847
2022-01-14 12:21:52,518 iteration 2814 : loss : 0.027598, loss_ce: 0.014311
2022-01-14 12:21:53,501 iteration 2815 : loss : 0.028097, loss_ce: 0.011630
2022-01-14 12:21:54,402 iteration 2816 : loss : 0.024898, loss_ce: 0.008642
2022-01-14 12:21:55,310 iteration 2817 : loss : 0.031081, loss_ce: 0.011913
2022-01-14 12:21:56,315 iteration 2818 : loss : 0.032196, loss_ce: 0.011870
2022-01-14 12:21:57,310 iteration 2819 : loss : 0.026075, loss_ce: 0.011648
2022-01-14 12:21:58,225 iteration 2820 : loss : 0.022655, loss_ce: 0.008750
2022-01-14 12:21:59,169 iteration 2821 : loss : 0.018228, loss_ce: 0.006934
2022-01-14 12:22:00,127 iteration 2822 : loss : 0.054364, loss_ce: 0.009806
 42%|████████████                 | 166/400 [47:26<1:07:28, 17.30s/it]2022-01-14 12:22:01,158 iteration 2823 : loss : 0.024280, loss_ce: 0.008046
2022-01-14 12:22:02,102 iteration 2824 : loss : 0.049602, loss_ce: 0.015820
2022-01-14 12:22:03,064 iteration 2825 : loss : 0.035479, loss_ce: 0.012429
2022-01-14 12:22:03,948 iteration 2826 : loss : 0.026035, loss_ce: 0.010544
2022-01-14 12:22:04,898 iteration 2827 : loss : 0.043544, loss_ce: 0.025821
2022-01-14 12:22:05,797 iteration 2828 : loss : 0.029358, loss_ce: 0.012480
2022-01-14 12:22:06,693 iteration 2829 : loss : 0.034461, loss_ce: 0.010430
2022-01-14 12:22:07,643 iteration 2830 : loss : 0.032555, loss_ce: 0.014569
2022-01-14 12:22:08,556 iteration 2831 : loss : 0.049228, loss_ce: 0.014173
2022-01-14 12:22:09,422 iteration 2832 : loss : 0.034072, loss_ce: 0.013460
2022-01-14 12:22:10,429 iteration 2833 : loss : 0.025062, loss_ce: 0.011059
2022-01-14 12:22:11,353 iteration 2834 : loss : 0.026843, loss_ce: 0.010303
2022-01-14 12:22:12,304 iteration 2835 : loss : 0.040916, loss_ce: 0.015878
2022-01-14 12:22:13,237 iteration 2836 : loss : 0.037664, loss_ce: 0.012591
2022-01-14 12:22:14,219 iteration 2837 : loss : 0.042551, loss_ce: 0.016023
2022-01-14 12:22:15,166 iteration 2838 : loss : 0.029587, loss_ce: 0.009940
2022-01-14 12:22:16,032 iteration 2839 : loss : 0.032257, loss_ce: 0.013093
 42%|████████████                 | 167/400 [47:41<1:05:33, 16.88s/it]2022-01-14 12:22:17,006 iteration 2840 : loss : 0.033423, loss_ce: 0.011418
2022-01-14 12:22:17,892 iteration 2841 : loss : 0.027494, loss_ce: 0.011997
2022-01-14 12:22:18,731 iteration 2842 : loss : 0.022920, loss_ce: 0.008799
2022-01-14 12:22:19,650 iteration 2843 : loss : 0.028308, loss_ce: 0.008602
2022-01-14 12:22:20,621 iteration 2844 : loss : 0.027252, loss_ce: 0.011491
2022-01-14 12:22:21,601 iteration 2845 : loss : 0.022207, loss_ce: 0.007115
2022-01-14 12:22:22,517 iteration 2846 : loss : 0.024112, loss_ce: 0.008251
2022-01-14 12:22:23,465 iteration 2847 : loss : 0.040559, loss_ce: 0.018825
2022-01-14 12:22:24,514 iteration 2848 : loss : 0.039273, loss_ce: 0.017558
2022-01-14 12:22:25,430 iteration 2849 : loss : 0.031486, loss_ce: 0.010724
2022-01-14 12:22:26,317 iteration 2850 : loss : 0.028485, loss_ce: 0.011021
2022-01-14 12:22:27,251 iteration 2851 : loss : 0.030721, loss_ce: 0.014366
2022-01-14 12:22:28,191 iteration 2852 : loss : 0.061427, loss_ce: 0.025145
2022-01-14 12:22:29,083 iteration 2853 : loss : 0.024427, loss_ce: 0.010338
2022-01-14 12:22:30,048 iteration 2854 : loss : 0.030469, loss_ce: 0.012593
2022-01-14 12:22:30,976 iteration 2855 : loss : 0.029561, loss_ce: 0.012433
2022-01-14 12:22:31,972 iteration 2856 : loss : 0.027681, loss_ce: 0.011339
 42%|████████████▏                | 168/400 [47:57<1:04:10, 16.60s/it]2022-01-14 12:22:33,024 iteration 2857 : loss : 0.054023, loss_ce: 0.014537
2022-01-14 12:22:33,982 iteration 2858 : loss : 0.036346, loss_ce: 0.011137
2022-01-14 12:22:34,857 iteration 2859 : loss : 0.020035, loss_ce: 0.006870
2022-01-14 12:22:35,850 iteration 2860 : loss : 0.032166, loss_ce: 0.013615
2022-01-14 12:22:36,735 iteration 2861 : loss : 0.024464, loss_ce: 0.008978
2022-01-14 12:22:37,694 iteration 2862 : loss : 0.030396, loss_ce: 0.010891
2022-01-14 12:22:38,674 iteration 2863 : loss : 0.034427, loss_ce: 0.011937
2022-01-14 12:22:39,634 iteration 2864 : loss : 0.023378, loss_ce: 0.009894
2022-01-14 12:22:40,470 iteration 2865 : loss : 0.026768, loss_ce: 0.010482
2022-01-14 12:22:41,383 iteration 2866 : loss : 0.025897, loss_ce: 0.007744
2022-01-14 12:22:42,371 iteration 2867 : loss : 0.034511, loss_ce: 0.014273
2022-01-14 12:22:43,356 iteration 2868 : loss : 0.023097, loss_ce: 0.008813
2022-01-14 12:22:44,248 iteration 2869 : loss : 0.021983, loss_ce: 0.010007
2022-01-14 12:22:45,193 iteration 2870 : loss : 0.032729, loss_ce: 0.016741
2022-01-14 12:22:46,035 iteration 2871 : loss : 0.020634, loss_ce: 0.009500
2022-01-14 12:22:46,963 iteration 2872 : loss : 0.043606, loss_ce: 0.013732
2022-01-14 12:22:47,940 iteration 2873 : loss : 0.036320, loss_ce: 0.025142
 42%|████████████▎                | 169/400 [48:13<1:03:11, 16.41s/it]2022-01-14 12:22:48,882 iteration 2874 : loss : 0.038339, loss_ce: 0.011614
2022-01-14 12:22:49,715 iteration 2875 : loss : 0.019123, loss_ce: 0.007850
2022-01-14 12:22:50,602 iteration 2876 : loss : 0.022815, loss_ce: 0.009649
2022-01-14 12:22:51,537 iteration 2877 : loss : 0.024000, loss_ce: 0.008028
2022-01-14 12:22:52,495 iteration 2878 : loss : 0.029525, loss_ce: 0.011329
2022-01-14 12:22:53,342 iteration 2879 : loss : 0.030070, loss_ce: 0.014444
2022-01-14 12:22:54,344 iteration 2880 : loss : 0.031448, loss_ce: 0.014463
2022-01-14 12:22:55,255 iteration 2881 : loss : 0.034308, loss_ce: 0.015441
2022-01-14 12:22:56,273 iteration 2882 : loss : 0.040580, loss_ce: 0.010409
2022-01-14 12:22:57,286 iteration 2883 : loss : 0.045151, loss_ce: 0.022237
2022-01-14 12:22:58,270 iteration 2884 : loss : 0.026420, loss_ce: 0.009029
2022-01-14 12:22:59,211 iteration 2885 : loss : 0.033975, loss_ce: 0.018250
2022-01-14 12:23:00,098 iteration 2886 : loss : 0.036240, loss_ce: 0.009016
2022-01-14 12:23:01,019 iteration 2887 : loss : 0.025742, loss_ce: 0.009596
2022-01-14 12:23:02,048 iteration 2888 : loss : 0.033759, loss_ce: 0.012839
2022-01-14 12:23:02,979 iteration 2889 : loss : 0.034501, loss_ce: 0.012727
2022-01-14 12:23:02,980 Training Data Eval:
2022-01-14 12:23:07,266   Average segmentation loss on training set: 0.0202
2022-01-14 12:23:07,267 Validation Data Eval:
2022-01-14 12:23:08,714   Average segmentation loss on validation set: 0.0724
2022-01-14 12:23:09,658 iteration 2890 : loss : 0.035221, loss_ce: 0.013197
 42%|████████████▎                | 170/400 [48:35<1:09:00, 18.00s/it]2022-01-14 12:23:10,708 iteration 2891 : loss : 0.029515, loss_ce: 0.014274
2022-01-14 12:23:11,556 iteration 2892 : loss : 0.020467, loss_ce: 0.010050
2022-01-14 12:23:12,449 iteration 2893 : loss : 0.032046, loss_ce: 0.010242
2022-01-14 12:23:13,383 iteration 2894 : loss : 0.020536, loss_ce: 0.008599
2022-01-14 12:23:14,285 iteration 2895 : loss : 0.023826, loss_ce: 0.007847
2022-01-14 12:23:15,146 iteration 2896 : loss : 0.026094, loss_ce: 0.010184
2022-01-14 12:23:16,061 iteration 2897 : loss : 0.033467, loss_ce: 0.011416
2022-01-14 12:23:16,990 iteration 2898 : loss : 0.030879, loss_ce: 0.015108
2022-01-14 12:23:17,971 iteration 2899 : loss : 0.032812, loss_ce: 0.012357
2022-01-14 12:23:18,828 iteration 2900 : loss : 0.028268, loss_ce: 0.009984
2022-01-14 12:23:19,855 iteration 2901 : loss : 0.022392, loss_ce: 0.007535
2022-01-14 12:23:20,666 iteration 2902 : loss : 0.022919, loss_ce: 0.007835
2022-01-14 12:23:21,625 iteration 2903 : loss : 0.024695, loss_ce: 0.010952
2022-01-14 12:23:22,626 iteration 2904 : loss : 0.048980, loss_ce: 0.016833
2022-01-14 12:23:23,550 iteration 2905 : loss : 0.052057, loss_ce: 0.014693
2022-01-14 12:23:24,538 iteration 2906 : loss : 0.040278, loss_ce: 0.016168
2022-01-14 12:23:25,411 iteration 2907 : loss : 0.022543, loss_ce: 0.009379
 43%|████████████▍                | 171/400 [48:51<1:06:07, 17.33s/it]2022-01-14 12:23:26,397 iteration 2908 : loss : 0.033353, loss_ce: 0.013555
2022-01-14 12:23:27,237 iteration 2909 : loss : 0.022757, loss_ce: 0.005509
2022-01-14 12:23:28,203 iteration 2910 : loss : 0.039863, loss_ce: 0.013920
2022-01-14 12:23:29,150 iteration 2911 : loss : 0.033164, loss_ce: 0.014707
2022-01-14 12:23:30,087 iteration 2912 : loss : 0.025135, loss_ce: 0.008539
2022-01-14 12:23:31,058 iteration 2913 : loss : 0.022252, loss_ce: 0.009106
2022-01-14 12:23:32,000 iteration 2914 : loss : 0.033113, loss_ce: 0.012977
2022-01-14 12:23:32,972 iteration 2915 : loss : 0.024457, loss_ce: 0.008979
2022-01-14 12:23:33,843 iteration 2916 : loss : 0.024812, loss_ce: 0.012707
2022-01-14 12:23:34,832 iteration 2917 : loss : 0.029233, loss_ce: 0.012036
2022-01-14 12:23:35,800 iteration 2918 : loss : 0.029150, loss_ce: 0.009647
2022-01-14 12:23:36,771 iteration 2919 : loss : 0.041337, loss_ce: 0.022044
2022-01-14 12:23:37,707 iteration 2920 : loss : 0.031723, loss_ce: 0.009992
2022-01-14 12:23:38,728 iteration 2921 : loss : 0.026076, loss_ce: 0.007205
2022-01-14 12:23:39,649 iteration 2922 : loss : 0.024729, loss_ce: 0.009762
2022-01-14 12:23:40,630 iteration 2923 : loss : 0.031254, loss_ce: 0.014604
2022-01-14 12:23:41,543 iteration 2924 : loss : 0.026905, loss_ce: 0.009074
 43%|████████████▍                | 172/400 [49:07<1:04:29, 16.97s/it]2022-01-14 12:23:42,613 iteration 2925 : loss : 0.040301, loss_ce: 0.017057
2022-01-14 12:23:43,519 iteration 2926 : loss : 0.022037, loss_ce: 0.006474
2022-01-14 12:23:44,500 iteration 2927 : loss : 0.033820, loss_ce: 0.013585
2022-01-14 12:23:45,570 iteration 2928 : loss : 0.047706, loss_ce: 0.013697
2022-01-14 12:23:46,462 iteration 2929 : loss : 0.024711, loss_ce: 0.008358
2022-01-14 12:23:47,366 iteration 2930 : loss : 0.036575, loss_ce: 0.015128
2022-01-14 12:23:48,216 iteration 2931 : loss : 0.035644, loss_ce: 0.014578
2022-01-14 12:23:49,222 iteration 2932 : loss : 0.026612, loss_ce: 0.009734
2022-01-14 12:23:50,121 iteration 2933 : loss : 0.034818, loss_ce: 0.011407
2022-01-14 12:23:51,112 iteration 2934 : loss : 0.029359, loss_ce: 0.014005
2022-01-14 12:23:52,058 iteration 2935 : loss : 0.044487, loss_ce: 0.013782
2022-01-14 12:23:53,032 iteration 2936 : loss : 0.030033, loss_ce: 0.014693
2022-01-14 12:23:53,954 iteration 2937 : loss : 0.019893, loss_ce: 0.008186
2022-01-14 12:23:54,886 iteration 2938 : loss : 0.026425, loss_ce: 0.010812
2022-01-14 12:23:55,798 iteration 2939 : loss : 0.024495, loss_ce: 0.011829
2022-01-14 12:23:56,765 iteration 2940 : loss : 0.027381, loss_ce: 0.008749
2022-01-14 12:23:57,705 iteration 2941 : loss : 0.039234, loss_ce: 0.011486
 43%|████████████▌                | 173/400 [49:23<1:03:17, 16.73s/it]2022-01-14 12:23:58,719 iteration 2942 : loss : 0.023986, loss_ce: 0.008776
2022-01-14 12:23:59,570 iteration 2943 : loss : 0.021093, loss_ce: 0.008376
2022-01-14 12:24:00,431 iteration 2944 : loss : 0.034323, loss_ce: 0.012273
2022-01-14 12:24:01,423 iteration 2945 : loss : 0.040405, loss_ce: 0.018864
2022-01-14 12:24:02,296 iteration 2946 : loss : 0.026429, loss_ce: 0.010816
2022-01-14 12:24:03,166 iteration 2947 : loss : 0.016763, loss_ce: 0.005149
2022-01-14 12:24:04,068 iteration 2948 : loss : 0.025091, loss_ce: 0.009044
2022-01-14 12:24:05,033 iteration 2949 : loss : 0.024450, loss_ce: 0.009017
2022-01-14 12:24:05,948 iteration 2950 : loss : 0.033364, loss_ce: 0.015447
2022-01-14 12:24:06,807 iteration 2951 : loss : 0.029191, loss_ce: 0.010757
2022-01-14 12:24:07,733 iteration 2952 : loss : 0.031615, loss_ce: 0.008158
2022-01-14 12:24:08,640 iteration 2953 : loss : 0.032047, loss_ce: 0.013370
2022-01-14 12:24:09,610 iteration 2954 : loss : 0.033373, loss_ce: 0.011701
2022-01-14 12:24:10,486 iteration 2955 : loss : 0.023020, loss_ce: 0.010189
2022-01-14 12:24:11,406 iteration 2956 : loss : 0.023582, loss_ce: 0.010953
2022-01-14 12:24:12,342 iteration 2957 : loss : 0.031799, loss_ce: 0.006845
2022-01-14 12:24:13,247 iteration 2958 : loss : 0.037122, loss_ce: 0.010232
 44%|████████████▌                | 174/400 [49:39<1:01:39, 16.37s/it]2022-01-14 12:24:14,327 iteration 2959 : loss : 0.024501, loss_ce: 0.011077
2022-01-14 12:24:15,282 iteration 2960 : loss : 0.028643, loss_ce: 0.010326
2022-01-14 12:24:16,272 iteration 2961 : loss : 0.037853, loss_ce: 0.022058
2022-01-14 12:24:17,155 iteration 2962 : loss : 0.020973, loss_ce: 0.006542
2022-01-14 12:24:18,085 iteration 2963 : loss : 0.024765, loss_ce: 0.009110
2022-01-14 12:24:19,083 iteration 2964 : loss : 0.032896, loss_ce: 0.011118
2022-01-14 12:24:20,038 iteration 2965 : loss : 0.021028, loss_ce: 0.009377
2022-01-14 12:24:20,954 iteration 2966 : loss : 0.022682, loss_ce: 0.007409
2022-01-14 12:24:21,966 iteration 2967 : loss : 0.038763, loss_ce: 0.011694
2022-01-14 12:24:22,873 iteration 2968 : loss : 0.047150, loss_ce: 0.014709
2022-01-14 12:24:23,746 iteration 2969 : loss : 0.024399, loss_ce: 0.007376
2022-01-14 12:24:24,638 iteration 2970 : loss : 0.027435, loss_ce: 0.011726
2022-01-14 12:24:25,585 iteration 2971 : loss : 0.032830, loss_ce: 0.011174
2022-01-14 12:24:26,543 iteration 2972 : loss : 0.024735, loss_ce: 0.009040
2022-01-14 12:24:27,467 iteration 2973 : loss : 0.029762, loss_ce: 0.012201
2022-01-14 12:24:28,522 iteration 2974 : loss : 0.032690, loss_ce: 0.014434
2022-01-14 12:24:28,523 Training Data Eval:
2022-01-14 12:24:32,824   Average segmentation loss on training set: 0.0183
2022-01-14 12:24:32,824 Validation Data Eval:
2022-01-14 12:24:34,273   Average segmentation loss on validation set: 0.0705
2022-01-14 12:24:35,175 iteration 2975 : loss : 0.037895, loss_ce: 0.011757
 44%|████████████▋                | 175/400 [50:01<1:07:39, 18.04s/it]2022-01-14 12:24:36,202 iteration 2976 : loss : 0.033650, loss_ce: 0.014220
2022-01-14 12:24:37,273 iteration 2977 : loss : 0.031818, loss_ce: 0.012120
2022-01-14 12:24:38,201 iteration 2978 : loss : 0.029920, loss_ce: 0.012309
2022-01-14 12:24:39,210 iteration 2979 : loss : 0.032701, loss_ce: 0.009090
2022-01-14 12:24:40,277 iteration 2980 : loss : 0.034402, loss_ce: 0.015076
2022-01-14 12:24:41,213 iteration 2981 : loss : 0.021715, loss_ce: 0.010038
2022-01-14 12:24:42,141 iteration 2982 : loss : 0.030062, loss_ce: 0.011751
2022-01-14 12:24:43,132 iteration 2983 : loss : 0.021733, loss_ce: 0.005340
2022-01-14 12:24:44,090 iteration 2984 : loss : 0.026300, loss_ce: 0.012042
2022-01-14 12:24:45,030 iteration 2985 : loss : 0.027914, loss_ce: 0.012136
2022-01-14 12:24:45,958 iteration 2986 : loss : 0.024603, loss_ce: 0.009113
2022-01-14 12:24:46,864 iteration 2987 : loss : 0.023196, loss_ce: 0.008395
2022-01-14 12:24:47,821 iteration 2988 : loss : 0.023852, loss_ce: 0.009343
2022-01-14 12:24:48,733 iteration 2989 : loss : 0.021383, loss_ce: 0.007453
2022-01-14 12:24:49,671 iteration 2990 : loss : 0.037230, loss_ce: 0.016052
2022-01-14 12:24:50,543 iteration 2991 : loss : 0.019008, loss_ce: 0.005254
2022-01-14 12:24:51,497 iteration 2992 : loss : 0.026904, loss_ce: 0.010890
 44%|████████████▊                | 176/400 [50:17<1:05:25, 17.52s/it]2022-01-14 12:24:52,524 iteration 2993 : loss : 0.032034, loss_ce: 0.011732
2022-01-14 12:24:53,446 iteration 2994 : loss : 0.022919, loss_ce: 0.009400
2022-01-14 12:24:54,404 iteration 2995 : loss : 0.034080, loss_ce: 0.014674
2022-01-14 12:24:55,292 iteration 2996 : loss : 0.026735, loss_ce: 0.009588
2022-01-14 12:24:56,219 iteration 2997 : loss : 0.024993, loss_ce: 0.009388
2022-01-14 12:24:57,188 iteration 2998 : loss : 0.027353, loss_ce: 0.013660
2022-01-14 12:24:58,096 iteration 2999 : loss : 0.034061, loss_ce: 0.011632
2022-01-14 12:24:59,019 iteration 3000 : loss : 0.024319, loss_ce: 0.009076
2022-01-14 12:25:00,026 iteration 3001 : loss : 0.025475, loss_ce: 0.009478
2022-01-14 12:25:01,009 iteration 3002 : loss : 0.034363, loss_ce: 0.014826
2022-01-14 12:25:01,872 iteration 3003 : loss : 0.019230, loss_ce: 0.007944
2022-01-14 12:25:02,773 iteration 3004 : loss : 0.023059, loss_ce: 0.010767
2022-01-14 12:25:03,682 iteration 3005 : loss : 0.029157, loss_ce: 0.012571
2022-01-14 12:25:04,590 iteration 3006 : loss : 0.028600, loss_ce: 0.010142
2022-01-14 12:25:05,530 iteration 3007 : loss : 0.023258, loss_ce: 0.007160
2022-01-14 12:25:06,401 iteration 3008 : loss : 0.021648, loss_ce: 0.007504
2022-01-14 12:25:07,278 iteration 3009 : loss : 0.024908, loss_ce: 0.006095
 44%|████████████▊                | 177/400 [50:33<1:03:10, 17.00s/it]2022-01-14 12:25:08,361 iteration 3010 : loss : 0.038486, loss_ce: 0.012302
2022-01-14 12:25:09,282 iteration 3011 : loss : 0.057091, loss_ce: 0.012717
2022-01-14 12:25:10,153 iteration 3012 : loss : 0.027070, loss_ce: 0.008509
2022-01-14 12:25:11,165 iteration 3013 : loss : 0.023307, loss_ce: 0.007609
2022-01-14 12:25:12,127 iteration 3014 : loss : 0.033053, loss_ce: 0.014588
2022-01-14 12:25:13,054 iteration 3015 : loss : 0.029874, loss_ce: 0.008230
2022-01-14 12:25:13,904 iteration 3016 : loss : 0.020723, loss_ce: 0.006527
2022-01-14 12:25:14,868 iteration 3017 : loss : 0.030036, loss_ce: 0.015301
2022-01-14 12:25:15,894 iteration 3018 : loss : 0.029126, loss_ce: 0.015269
2022-01-14 12:25:16,997 iteration 3019 : loss : 0.030642, loss_ce: 0.012472
2022-01-14 12:25:17,914 iteration 3020 : loss : 0.027116, loss_ce: 0.009842
2022-01-14 12:25:18,842 iteration 3021 : loss : 0.026504, loss_ce: 0.011334
2022-01-14 12:25:19,696 iteration 3022 : loss : 0.020740, loss_ce: 0.010039
2022-01-14 12:25:20,572 iteration 3023 : loss : 0.020675, loss_ce: 0.007758
2022-01-14 12:25:21,509 iteration 3024 : loss : 0.032396, loss_ce: 0.013475
2022-01-14 12:25:22,432 iteration 3025 : loss : 0.027245, loss_ce: 0.011042
2022-01-14 12:25:23,314 iteration 3026 : loss : 0.028010, loss_ce: 0.007604
 44%|████████████▉                | 178/400 [50:49<1:01:49, 16.71s/it]2022-01-14 12:25:24,295 iteration 3027 : loss : 0.036871, loss_ce: 0.018459
2022-01-14 12:25:25,307 iteration 3028 : loss : 0.034692, loss_ce: 0.012105
2022-01-14 12:25:26,205 iteration 3029 : loss : 0.017203, loss_ce: 0.004908
2022-01-14 12:25:27,221 iteration 3030 : loss : 0.024054, loss_ce: 0.006968
2022-01-14 12:25:28,215 iteration 3031 : loss : 0.051798, loss_ce: 0.014665
2022-01-14 12:25:29,221 iteration 3032 : loss : 0.022065, loss_ce: 0.008675
2022-01-14 12:25:30,182 iteration 3033 : loss : 0.032254, loss_ce: 0.011559
2022-01-14 12:25:31,089 iteration 3034 : loss : 0.023089, loss_ce: 0.006148
2022-01-14 12:25:31,966 iteration 3035 : loss : 0.022570, loss_ce: 0.008990
2022-01-14 12:25:32,939 iteration 3036 : loss : 0.027081, loss_ce: 0.012559
2022-01-14 12:25:33,812 iteration 3037 : loss : 0.025794, loss_ce: 0.010662
2022-01-14 12:25:34,670 iteration 3038 : loss : 0.022482, loss_ce: 0.009614
2022-01-14 12:25:35,546 iteration 3039 : loss : 0.021737, loss_ce: 0.007802
2022-01-14 12:25:36,569 iteration 3040 : loss : 0.027711, loss_ce: 0.008033
2022-01-14 12:25:37,410 iteration 3041 : loss : 0.023201, loss_ce: 0.009348
2022-01-14 12:25:38,295 iteration 3042 : loss : 0.021034, loss_ce: 0.010310
2022-01-14 12:25:39,191 iteration 3043 : loss : 0.030682, loss_ce: 0.012704
 45%|████████████▉                | 179/400 [51:05<1:00:38, 16.46s/it]2022-01-14 12:25:40,199 iteration 3044 : loss : 0.023397, loss_ce: 0.008871
2022-01-14 12:25:41,053 iteration 3045 : loss : 0.035582, loss_ce: 0.010951
2022-01-14 12:25:42,048 iteration 3046 : loss : 0.032615, loss_ce: 0.014925
2022-01-14 12:25:43,084 iteration 3047 : loss : 0.023217, loss_ce: 0.007479
2022-01-14 12:25:44,029 iteration 3048 : loss : 0.028591, loss_ce: 0.010411
2022-01-14 12:25:44,991 iteration 3049 : loss : 0.021242, loss_ce: 0.006978
2022-01-14 12:25:45,969 iteration 3050 : loss : 0.024983, loss_ce: 0.006006
2022-01-14 12:25:46,986 iteration 3051 : loss : 0.030043, loss_ce: 0.010279
2022-01-14 12:25:47,933 iteration 3052 : loss : 0.034099, loss_ce: 0.017092
2022-01-14 12:25:48,789 iteration 3053 : loss : 0.029452, loss_ce: 0.010974
2022-01-14 12:25:49,684 iteration 3054 : loss : 0.027854, loss_ce: 0.011856
2022-01-14 12:25:50,529 iteration 3055 : loss : 0.040920, loss_ce: 0.017550
2022-01-14 12:25:51,370 iteration 3056 : loss : 0.020115, loss_ce: 0.006725
2022-01-14 12:25:52,416 iteration 3057 : loss : 0.037597, loss_ce: 0.014694
2022-01-14 12:25:53,310 iteration 3058 : loss : 0.022461, loss_ce: 0.007620
2022-01-14 12:25:54,201 iteration 3059 : loss : 0.022083, loss_ce: 0.012143
2022-01-14 12:25:54,201 Training Data Eval:
2022-01-14 12:25:58,606   Average segmentation loss on training set: 0.0217
2022-01-14 12:25:58,607 Validation Data Eval:
2022-01-14 12:26:00,109   Average segmentation loss on validation set: 0.0640
2022-01-14 12:26:01,331 Found new lowest validation loss at iteration 3059! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_1BLOCK_best_val_loss_seed2.pth
2022-01-14 12:26:02,333 iteration 3060 : loss : 0.041493, loss_ce: 0.013952
 45%|█████████████                | 180/400 [51:28<1:07:41, 18.46s/it]2022-01-14 12:26:03,329 iteration 3061 : loss : 0.027065, loss_ce: 0.007858
2022-01-14 12:26:04,308 iteration 3062 : loss : 0.029105, loss_ce: 0.013269
2022-01-14 12:26:05,226 iteration 3063 : loss : 0.031544, loss_ce: 0.012962
2022-01-14 12:26:06,161 iteration 3064 : loss : 0.051459, loss_ce: 0.027315
2022-01-14 12:26:07,107 iteration 3065 : loss : 0.032266, loss_ce: 0.008448
2022-01-14 12:26:07,999 iteration 3066 : loss : 0.033546, loss_ce: 0.009210
2022-01-14 12:26:08,970 iteration 3067 : loss : 0.035567, loss_ce: 0.015127
2022-01-14 12:26:09,992 iteration 3068 : loss : 0.031642, loss_ce: 0.011829
2022-01-14 12:26:10,847 iteration 3069 : loss : 0.013813, loss_ce: 0.005058
2022-01-14 12:26:11,791 iteration 3070 : loss : 0.028939, loss_ce: 0.010429
2022-01-14 12:26:12,892 iteration 3071 : loss : 0.039453, loss_ce: 0.011917
2022-01-14 12:26:13,816 iteration 3072 : loss : 0.021119, loss_ce: 0.008558
2022-01-14 12:26:14,741 iteration 3073 : loss : 0.026281, loss_ce: 0.008059
2022-01-14 12:26:15,672 iteration 3074 : loss : 0.030982, loss_ce: 0.013727
2022-01-14 12:26:16,622 iteration 3075 : loss : 0.026459, loss_ce: 0.008233
2022-01-14 12:26:17,497 iteration 3076 : loss : 0.018686, loss_ce: 0.007067
2022-01-14 12:26:18,522 iteration 3077 : loss : 0.051915, loss_ce: 0.019592
 45%|█████████████                | 181/400 [51:44<1:04:53, 17.78s/it]2022-01-14 12:26:19,534 iteration 3078 : loss : 0.051498, loss_ce: 0.008447
2022-01-14 12:26:20,446 iteration 3079 : loss : 0.020876, loss_ce: 0.006427
2022-01-14 12:26:21,341 iteration 3080 : loss : 0.022321, loss_ce: 0.006954
2022-01-14 12:26:22,285 iteration 3081 : loss : 0.040217, loss_ce: 0.017064
2022-01-14 12:26:23,199 iteration 3082 : loss : 0.031819, loss_ce: 0.010579
2022-01-14 12:26:24,133 iteration 3083 : loss : 0.045221, loss_ce: 0.015521
2022-01-14 12:26:25,073 iteration 3084 : loss : 0.044333, loss_ce: 0.017078
2022-01-14 12:26:25,936 iteration 3085 : loss : 0.032878, loss_ce: 0.012973
2022-01-14 12:26:26,830 iteration 3086 : loss : 0.039397, loss_ce: 0.019848
2022-01-14 12:26:27,808 iteration 3087 : loss : 0.027429, loss_ce: 0.011832
2022-01-14 12:26:28,716 iteration 3088 : loss : 0.031101, loss_ce: 0.013873
2022-01-14 12:26:29,736 iteration 3089 : loss : 0.053356, loss_ce: 0.019304
2022-01-14 12:26:30,611 iteration 3090 : loss : 0.027048, loss_ce: 0.012226
2022-01-14 12:26:31,558 iteration 3091 : loss : 0.035121, loss_ce: 0.015535
2022-01-14 12:26:32,446 iteration 3092 : loss : 0.034981, loss_ce: 0.015454
2022-01-14 12:26:33,333 iteration 3093 : loss : 0.022742, loss_ce: 0.009306
2022-01-14 12:26:34,251 iteration 3094 : loss : 0.065864, loss_ce: 0.018454
 46%|█████████████▏               | 182/400 [52:00<1:02:22, 17.17s/it]2022-01-14 12:26:35,278 iteration 3095 : loss : 0.023570, loss_ce: 0.009883
2022-01-14 12:26:36,210 iteration 3096 : loss : 0.023862, loss_ce: 0.008961
2022-01-14 12:26:37,166 iteration 3097 : loss : 0.024790, loss_ce: 0.010703
2022-01-14 12:26:38,142 iteration 3098 : loss : 0.035466, loss_ce: 0.010521
2022-01-14 12:26:39,112 iteration 3099 : loss : 0.030586, loss_ce: 0.015073
2022-01-14 12:26:40,028 iteration 3100 : loss : 0.027261, loss_ce: 0.009763
2022-01-14 12:26:40,924 iteration 3101 : loss : 0.018997, loss_ce: 0.007230
2022-01-14 12:26:41,751 iteration 3102 : loss : 0.030479, loss_ce: 0.013505
2022-01-14 12:26:42,720 iteration 3103 : loss : 0.039676, loss_ce: 0.021395
2022-01-14 12:26:43,640 iteration 3104 : loss : 0.035400, loss_ce: 0.016372
2022-01-14 12:26:44,622 iteration 3105 : loss : 0.020704, loss_ce: 0.007953
2022-01-14 12:26:45,567 iteration 3106 : loss : 0.020354, loss_ce: 0.007871
2022-01-14 12:26:46,538 iteration 3107 : loss : 0.023968, loss_ce: 0.009160
2022-01-14 12:26:47,509 iteration 3108 : loss : 0.029741, loss_ce: 0.011613
2022-01-14 12:26:48,357 iteration 3109 : loss : 0.021087, loss_ce: 0.009591
2022-01-14 12:26:49,253 iteration 3110 : loss : 0.025161, loss_ce: 0.009817
2022-01-14 12:26:50,188 iteration 3111 : loss : 0.049413, loss_ce: 0.013823
 46%|█████████████▎               | 183/400 [52:16<1:00:45, 16.80s/it]2022-01-14 12:26:51,133 iteration 3112 : loss : 0.020917, loss_ce: 0.008070
2022-01-14 12:26:52,066 iteration 3113 : loss : 0.049181, loss_ce: 0.020383
2022-01-14 12:26:52,952 iteration 3114 : loss : 0.021995, loss_ce: 0.010164
2022-01-14 12:26:53,916 iteration 3115 : loss : 0.031520, loss_ce: 0.010972
2022-01-14 12:26:54,771 iteration 3116 : loss : 0.022059, loss_ce: 0.008668
2022-01-14 12:26:55,779 iteration 3117 : loss : 0.027876, loss_ce: 0.007856
2022-01-14 12:26:56,708 iteration 3118 : loss : 0.025566, loss_ce: 0.011573
2022-01-14 12:26:57,675 iteration 3119 : loss : 0.020734, loss_ce: 0.008546
2022-01-14 12:26:58,548 iteration 3120 : loss : 0.022698, loss_ce: 0.006945
2022-01-14 12:26:59,513 iteration 3121 : loss : 0.040984, loss_ce: 0.011325
2022-01-14 12:27:00,438 iteration 3122 : loss : 0.040574, loss_ce: 0.018123
2022-01-14 12:27:01,517 iteration 3123 : loss : 0.051043, loss_ce: 0.017373
2022-01-14 12:27:02,419 iteration 3124 : loss : 0.022868, loss_ce: 0.008614
2022-01-14 12:27:03,308 iteration 3125 : loss : 0.017865, loss_ce: 0.007793
2022-01-14 12:27:04,198 iteration 3126 : loss : 0.024453, loss_ce: 0.009229
2022-01-14 12:27:05,103 iteration 3127 : loss : 0.028340, loss_ce: 0.012376
2022-01-14 12:27:06,012 iteration 3128 : loss : 0.038528, loss_ce: 0.008555
 46%|██████████████▎                | 184/400 [52:31<59:25, 16.51s/it]2022-01-14 12:27:06,959 iteration 3129 : loss : 0.031034, loss_ce: 0.010438
2022-01-14 12:27:07,847 iteration 3130 : loss : 0.028460, loss_ce: 0.011730
2022-01-14 12:27:08,827 iteration 3131 : loss : 0.033727, loss_ce: 0.017579
2022-01-14 12:27:09,788 iteration 3132 : loss : 0.026298, loss_ce: 0.009967
2022-01-14 12:27:10,668 iteration 3133 : loss : 0.024346, loss_ce: 0.012542
2022-01-14 12:27:11,636 iteration 3134 : loss : 0.028454, loss_ce: 0.011962
2022-01-14 12:27:12,610 iteration 3135 : loss : 0.038318, loss_ce: 0.009842
2022-01-14 12:27:13,486 iteration 3136 : loss : 0.020722, loss_ce: 0.009215
2022-01-14 12:27:14,362 iteration 3137 : loss : 0.020390, loss_ce: 0.008793
2022-01-14 12:27:15,270 iteration 3138 : loss : 0.026960, loss_ce: 0.010531
2022-01-14 12:27:16,350 iteration 3139 : loss : 0.033008, loss_ce: 0.009880
2022-01-14 12:27:17,323 iteration 3140 : loss : 0.022046, loss_ce: 0.007929
2022-01-14 12:27:18,237 iteration 3141 : loss : 0.030084, loss_ce: 0.014053
2022-01-14 12:27:19,110 iteration 3142 : loss : 0.020736, loss_ce: 0.007767
2022-01-14 12:27:20,065 iteration 3143 : loss : 0.037719, loss_ce: 0.013152
2022-01-14 12:27:21,026 iteration 3144 : loss : 0.046168, loss_ce: 0.009775
2022-01-14 12:27:21,026 Training Data Eval:
2022-01-14 12:27:25,321   Average segmentation loss on training set: 0.0183
2022-01-14 12:27:25,321 Validation Data Eval:
2022-01-14 12:27:26,773   Average segmentation loss on validation set: 0.0635
2022-01-14 12:27:27,990 Found new lowest validation loss at iteration 3144! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_1BLOCK_best_val_loss_seed2.pth
2022-01-14 12:27:28,849 iteration 3145 : loss : 0.023803, loss_ce: 0.010407
 46%|█████████████▍               | 185/400 [52:54<1:05:56, 18.40s/it]2022-01-14 12:27:29,895 iteration 3146 : loss : 0.026801, loss_ce: 0.010469
2022-01-14 12:27:30,900 iteration 3147 : loss : 0.049426, loss_ce: 0.020333
2022-01-14 12:27:31,753 iteration 3148 : loss : 0.023324, loss_ce: 0.009306
2022-01-14 12:27:32,683 iteration 3149 : loss : 0.031750, loss_ce: 0.008920
2022-01-14 12:27:33,595 iteration 3150 : loss : 0.037698, loss_ce: 0.009230
2022-01-14 12:27:34,439 iteration 3151 : loss : 0.019175, loss_ce: 0.008423
2022-01-14 12:27:35,421 iteration 3152 : loss : 0.024736, loss_ce: 0.013241
2022-01-14 12:27:36,336 iteration 3153 : loss : 0.022254, loss_ce: 0.009856
2022-01-14 12:27:37,265 iteration 3154 : loss : 0.034549, loss_ce: 0.009722
2022-01-14 12:27:38,205 iteration 3155 : loss : 0.023842, loss_ce: 0.008613
2022-01-14 12:27:39,177 iteration 3156 : loss : 0.024638, loss_ce: 0.008752
2022-01-14 12:27:40,039 iteration 3157 : loss : 0.029879, loss_ce: 0.007776
2022-01-14 12:27:41,046 iteration 3158 : loss : 0.023873, loss_ce: 0.008907
2022-01-14 12:27:41,976 iteration 3159 : loss : 0.041290, loss_ce: 0.020035
2022-01-14 12:27:42,894 iteration 3160 : loss : 0.023951, loss_ce: 0.009698
2022-01-14 12:27:43,916 iteration 3161 : loss : 0.044204, loss_ce: 0.017180
2022-01-14 12:27:44,951 iteration 3162 : loss : 0.028896, loss_ce: 0.013253
 46%|█████████████▍               | 186/400 [53:10<1:03:10, 17.71s/it]2022-01-14 12:27:45,896 iteration 3163 : loss : 0.028650, loss_ce: 0.009217
2022-01-14 12:27:46,757 iteration 3164 : loss : 0.033042, loss_ce: 0.010252
2022-01-14 12:27:47,661 iteration 3165 : loss : 0.016836, loss_ce: 0.006814
2022-01-14 12:27:48,593 iteration 3166 : loss : 0.022860, loss_ce: 0.010571
2022-01-14 12:27:49,540 iteration 3167 : loss : 0.046316, loss_ce: 0.016164
2022-01-14 12:27:50,417 iteration 3168 : loss : 0.021674, loss_ce: 0.010728
2022-01-14 12:27:51,357 iteration 3169 : loss : 0.027400, loss_ce: 0.009439
2022-01-14 12:27:52,331 iteration 3170 : loss : 0.037902, loss_ce: 0.014905
2022-01-14 12:27:53,333 iteration 3171 : loss : 0.060123, loss_ce: 0.014582
2022-01-14 12:27:54,323 iteration 3172 : loss : 0.025657, loss_ce: 0.011090
2022-01-14 12:27:55,306 iteration 3173 : loss : 0.030115, loss_ce: 0.010570
2022-01-14 12:27:56,282 iteration 3174 : loss : 0.023024, loss_ce: 0.008163
2022-01-14 12:27:57,215 iteration 3175 : loss : 0.021376, loss_ce: 0.007903
2022-01-14 12:27:58,175 iteration 3176 : loss : 0.027822, loss_ce: 0.016036
2022-01-14 12:27:59,064 iteration 3177 : loss : 0.033280, loss_ce: 0.016976
2022-01-14 12:28:00,000 iteration 3178 : loss : 0.031696, loss_ce: 0.008175
2022-01-14 12:28:00,970 iteration 3179 : loss : 0.036816, loss_ce: 0.010279
 47%|█████████████▌               | 187/400 [53:26<1:01:05, 17.21s/it]2022-01-14 12:28:02,033 iteration 3180 : loss : 0.022776, loss_ce: 0.010211
2022-01-14 12:28:02,993 iteration 3181 : loss : 0.025781, loss_ce: 0.009913
2022-01-14 12:28:03,976 iteration 3182 : loss : 0.029978, loss_ce: 0.008958
2022-01-14 12:28:04,963 iteration 3183 : loss : 0.026777, loss_ce: 0.012179
2022-01-14 12:28:05,810 iteration 3184 : loss : 0.018177, loss_ce: 0.007844
2022-01-14 12:28:06,682 iteration 3185 : loss : 0.025687, loss_ce: 0.011022
2022-01-14 12:28:07,568 iteration 3186 : loss : 0.027832, loss_ce: 0.013933
2022-01-14 12:28:08,435 iteration 3187 : loss : 0.015781, loss_ce: 0.005275
2022-01-14 12:28:09,355 iteration 3188 : loss : 0.026948, loss_ce: 0.008485
2022-01-14 12:28:10,210 iteration 3189 : loss : 0.019252, loss_ce: 0.008701
2022-01-14 12:28:11,191 iteration 3190 : loss : 0.035059, loss_ce: 0.011983
2022-01-14 12:28:12,128 iteration 3191 : loss : 0.033693, loss_ce: 0.009477
2022-01-14 12:28:13,048 iteration 3192 : loss : 0.020598, loss_ce: 0.008300
2022-01-14 12:28:13,915 iteration 3193 : loss : 0.025340, loss_ce: 0.010862
2022-01-14 12:28:14,767 iteration 3194 : loss : 0.024821, loss_ce: 0.008387
2022-01-14 12:28:15,653 iteration 3195 : loss : 0.024005, loss_ce: 0.006776
2022-01-14 12:28:16,622 iteration 3196 : loss : 0.030716, loss_ce: 0.008817
 47%|██████████████▌                | 188/400 [53:42<59:08, 16.74s/it]2022-01-14 12:28:17,572 iteration 3197 : loss : 0.023315, loss_ce: 0.008712
2022-01-14 12:28:18,451 iteration 3198 : loss : 0.028187, loss_ce: 0.010773
2022-01-14 12:28:19,301 iteration 3199 : loss : 0.021335, loss_ce: 0.008012
2022-01-14 12:28:20,183 iteration 3200 : loss : 0.023516, loss_ce: 0.010746
2022-01-14 12:28:21,175 iteration 3201 : loss : 0.025815, loss_ce: 0.009443
2022-01-14 12:28:22,127 iteration 3202 : loss : 0.034289, loss_ce: 0.015439
2022-01-14 12:28:22,979 iteration 3203 : loss : 0.026862, loss_ce: 0.005179
2022-01-14 12:28:23,921 iteration 3204 : loss : 0.026381, loss_ce: 0.013670
2022-01-14 12:28:24,851 iteration 3205 : loss : 0.017710, loss_ce: 0.005802
2022-01-14 12:28:25,735 iteration 3206 : loss : 0.023028, loss_ce: 0.009491
2022-01-14 12:28:26,589 iteration 3207 : loss : 0.019657, loss_ce: 0.006459
2022-01-14 12:28:27,471 iteration 3208 : loss : 0.026026, loss_ce: 0.008341
2022-01-14 12:28:28,411 iteration 3209 : loss : 0.020987, loss_ce: 0.007497
2022-01-14 12:28:29,351 iteration 3210 : loss : 0.034126, loss_ce: 0.011417
2022-01-14 12:28:30,327 iteration 3211 : loss : 0.024067, loss_ce: 0.010827
2022-01-14 12:28:31,293 iteration 3212 : loss : 0.021440, loss_ce: 0.009053
2022-01-14 12:28:32,184 iteration 3213 : loss : 0.021191, loss_ce: 0.010168
 47%|██████████████▋                | 189/400 [53:58<57:37, 16.39s/it]2022-01-14 12:28:33,150 iteration 3214 : loss : 0.023211, loss_ce: 0.008812
2022-01-14 12:28:34,027 iteration 3215 : loss : 0.018790, loss_ce: 0.008076
2022-01-14 12:28:34,930 iteration 3216 : loss : 0.028900, loss_ce: 0.011013
2022-01-14 12:28:35,899 iteration 3217 : loss : 0.039642, loss_ce: 0.010597
2022-01-14 12:28:36,780 iteration 3218 : loss : 0.021957, loss_ce: 0.008837
2022-01-14 12:28:37,649 iteration 3219 : loss : 0.022000, loss_ce: 0.006481
2022-01-14 12:28:38,590 iteration 3220 : loss : 0.026034, loss_ce: 0.013373
2022-01-14 12:28:39,515 iteration 3221 : loss : 0.029330, loss_ce: 0.010053
2022-01-14 12:28:40,386 iteration 3222 : loss : 0.021470, loss_ce: 0.007512
2022-01-14 12:28:41,307 iteration 3223 : loss : 0.036871, loss_ce: 0.007957
2022-01-14 12:28:42,218 iteration 3224 : loss : 0.018582, loss_ce: 0.005938
2022-01-14 12:28:43,077 iteration 3225 : loss : 0.026987, loss_ce: 0.009768
2022-01-14 12:28:43,987 iteration 3226 : loss : 0.026941, loss_ce: 0.011055
2022-01-14 12:28:44,918 iteration 3227 : loss : 0.038917, loss_ce: 0.015674
2022-01-14 12:28:45,838 iteration 3228 : loss : 0.029829, loss_ce: 0.012426
2022-01-14 12:28:46,773 iteration 3229 : loss : 0.019396, loss_ce: 0.006940
2022-01-14 12:28:46,773 Training Data Eval:
2022-01-14 12:28:51,064   Average segmentation loss on training set: 0.0220
2022-01-14 12:28:51,065 Validation Data Eval:
2022-01-14 12:28:52,512   Average segmentation loss on validation set: 0.0982
2022-01-14 12:28:53,409 iteration 3230 : loss : 0.022914, loss_ce: 0.012617
 48%|█████████████▊               | 190/400 [54:19<1:02:25, 17.84s/it]2022-01-14 12:28:54,288 iteration 3231 : loss : 0.020434, loss_ce: 0.007545
2022-01-14 12:28:55,223 iteration 3232 : loss : 0.021390, loss_ce: 0.008424
2022-01-14 12:28:56,166 iteration 3233 : loss : 0.028493, loss_ce: 0.008644
2022-01-14 12:28:57,052 iteration 3234 : loss : 0.020541, loss_ce: 0.008151
2022-01-14 12:28:58,008 iteration 3235 : loss : 0.027880, loss_ce: 0.011170
2022-01-14 12:28:58,828 iteration 3236 : loss : 0.022084, loss_ce: 0.010880
2022-01-14 12:28:59,751 iteration 3237 : loss : 0.020836, loss_ce: 0.007462
2022-01-14 12:29:00,688 iteration 3238 : loss : 0.038961, loss_ce: 0.016251
2022-01-14 12:29:01,526 iteration 3239 : loss : 0.021758, loss_ce: 0.009678
2022-01-14 12:29:02,496 iteration 3240 : loss : 0.022486, loss_ce: 0.009331
2022-01-14 12:29:03,516 iteration 3241 : loss : 0.029551, loss_ce: 0.008433
2022-01-14 12:29:04,435 iteration 3242 : loss : 0.025387, loss_ce: 0.010811
2022-01-14 12:29:05,410 iteration 3243 : loss : 0.022284, loss_ce: 0.009152
2022-01-14 12:29:06,274 iteration 3244 : loss : 0.028228, loss_ce: 0.008957
2022-01-14 12:29:07,217 iteration 3245 : loss : 0.039467, loss_ce: 0.012534
2022-01-14 12:29:08,183 iteration 3246 : loss : 0.041117, loss_ce: 0.016559
2022-01-14 12:29:09,223 iteration 3247 : loss : 0.035948, loss_ce: 0.015143
 48%|█████████████▊               | 191/400 [54:35<1:00:01, 17.23s/it]2022-01-14 12:29:10,247 iteration 3248 : loss : 0.032588, loss_ce: 0.009602
2022-01-14 12:29:11,213 iteration 3249 : loss : 0.028183, loss_ce: 0.009061
2022-01-14 12:29:12,146 iteration 3250 : loss : 0.024372, loss_ce: 0.008826
2022-01-14 12:29:13,090 iteration 3251 : loss : 0.019956, loss_ce: 0.006723
2022-01-14 12:29:13,909 iteration 3252 : loss : 0.018432, loss_ce: 0.008473
2022-01-14 12:29:14,814 iteration 3253 : loss : 0.031469, loss_ce: 0.009841
2022-01-14 12:29:15,759 iteration 3254 : loss : 0.041166, loss_ce: 0.021018
2022-01-14 12:29:16,705 iteration 3255 : loss : 0.028769, loss_ce: 0.012234
2022-01-14 12:29:17,681 iteration 3256 : loss : 0.026289, loss_ce: 0.010136
2022-01-14 12:29:18,629 iteration 3257 : loss : 0.037609, loss_ce: 0.016261
2022-01-14 12:29:19,506 iteration 3258 : loss : 0.020378, loss_ce: 0.005579
2022-01-14 12:29:20,445 iteration 3259 : loss : 0.025974, loss_ce: 0.009324
2022-01-14 12:29:21,397 iteration 3260 : loss : 0.024791, loss_ce: 0.009861
2022-01-14 12:29:22,313 iteration 3261 : loss : 0.024090, loss_ce: 0.009161
2022-01-14 12:29:23,320 iteration 3262 : loss : 0.031400, loss_ce: 0.011930
2022-01-14 12:29:24,223 iteration 3263 : loss : 0.025326, loss_ce: 0.010301
2022-01-14 12:29:25,225 iteration 3264 : loss : 0.029279, loss_ce: 0.010001
 48%|██████████████▉                | 192/400 [54:51<58:27, 16.86s/it]2022-01-14 12:29:26,158 iteration 3265 : loss : 0.026407, loss_ce: 0.011814
2022-01-14 12:29:27,116 iteration 3266 : loss : 0.022531, loss_ce: 0.008570
2022-01-14 12:29:28,049 iteration 3267 : loss : 0.018271, loss_ce: 0.005843
2022-01-14 12:29:28,997 iteration 3268 : loss : 0.026679, loss_ce: 0.008571
2022-01-14 12:29:29,857 iteration 3269 : loss : 0.019230, loss_ce: 0.009407
2022-01-14 12:29:30,785 iteration 3270 : loss : 0.026812, loss_ce: 0.011245
2022-01-14 12:29:31,610 iteration 3271 : loss : 0.029323, loss_ce: 0.008718
2022-01-14 12:29:32,616 iteration 3272 : loss : 0.038798, loss_ce: 0.016618
2022-01-14 12:29:33,528 iteration 3273 : loss : 0.026710, loss_ce: 0.011731
2022-01-14 12:29:34,387 iteration 3274 : loss : 0.027840, loss_ce: 0.009948
2022-01-14 12:29:35,264 iteration 3275 : loss : 0.030191, loss_ce: 0.010305
2022-01-14 12:29:36,162 iteration 3276 : loss : 0.025054, loss_ce: 0.007214
2022-01-14 12:29:37,016 iteration 3277 : loss : 0.020093, loss_ce: 0.007372
2022-01-14 12:29:37,927 iteration 3278 : loss : 0.019836, loss_ce: 0.008114
2022-01-14 12:29:38,741 iteration 3279 : loss : 0.024225, loss_ce: 0.013390
2022-01-14 12:29:39,730 iteration 3280 : loss : 0.051681, loss_ce: 0.026095
2022-01-14 12:29:40,646 iteration 3281 : loss : 0.017532, loss_ce: 0.004712
 48%|██████████████▉                | 193/400 [55:06<56:40, 16.43s/it]2022-01-14 12:29:41,665 iteration 3282 : loss : 0.027243, loss_ce: 0.006362
2022-01-14 12:29:42,636 iteration 3283 : loss : 0.028040, loss_ce: 0.010475
2022-01-14 12:29:43,577 iteration 3284 : loss : 0.022831, loss_ce: 0.009779
2022-01-14 12:29:44,540 iteration 3285 : loss : 0.040613, loss_ce: 0.012852
2022-01-14 12:29:45,443 iteration 3286 : loss : 0.023557, loss_ce: 0.006857
2022-01-14 12:29:46,467 iteration 3287 : loss : 0.030383, loss_ce: 0.012556
2022-01-14 12:29:47,338 iteration 3288 : loss : 0.024464, loss_ce: 0.010109
2022-01-14 12:29:48,374 iteration 3289 : loss : 0.024527, loss_ce: 0.010410
2022-01-14 12:29:49,339 iteration 3290 : loss : 0.035984, loss_ce: 0.011221
2022-01-14 12:29:50,352 iteration 3291 : loss : 0.029211, loss_ce: 0.014175
2022-01-14 12:29:51,276 iteration 3292 : loss : 0.024964, loss_ce: 0.009168
2022-01-14 12:29:52,191 iteration 3293 : loss : 0.032420, loss_ce: 0.009204
2022-01-14 12:29:53,203 iteration 3294 : loss : 0.027430, loss_ce: 0.011593
2022-01-14 12:29:54,179 iteration 3295 : loss : 0.022242, loss_ce: 0.009887
2022-01-14 12:29:55,051 iteration 3296 : loss : 0.027939, loss_ce: 0.009961
2022-01-14 12:29:55,946 iteration 3297 : loss : 0.022834, loss_ce: 0.008274
2022-01-14 12:29:56,952 iteration 3298 : loss : 0.030250, loss_ce: 0.012762
 48%|███████████████                | 194/400 [55:22<56:17, 16.39s/it]2022-01-14 12:29:57,858 iteration 3299 : loss : 0.022166, loss_ce: 0.005506
2022-01-14 12:29:58,831 iteration 3300 : loss : 0.025883, loss_ce: 0.007910
2022-01-14 12:29:59,739 iteration 3301 : loss : 0.023089, loss_ce: 0.010517
2022-01-14 12:30:00,642 iteration 3302 : loss : 0.025527, loss_ce: 0.007548
2022-01-14 12:30:01,639 iteration 3303 : loss : 0.021726, loss_ce: 0.009968
2022-01-14 12:30:02,591 iteration 3304 : loss : 0.028116, loss_ce: 0.010646
2022-01-14 12:30:03,502 iteration 3305 : loss : 0.023834, loss_ce: 0.007484
2022-01-14 12:30:04,399 iteration 3306 : loss : 0.019112, loss_ce: 0.005742
2022-01-14 12:30:05,459 iteration 3307 : loss : 0.043937, loss_ce: 0.020524
2022-01-14 12:30:06,430 iteration 3308 : loss : 0.029292, loss_ce: 0.016175
2022-01-14 12:30:07,421 iteration 3309 : loss : 0.022411, loss_ce: 0.011504
2022-01-14 12:30:08,289 iteration 3310 : loss : 0.020949, loss_ce: 0.010692
2022-01-14 12:30:09,321 iteration 3311 : loss : 0.041249, loss_ce: 0.014715
2022-01-14 12:30:10,246 iteration 3312 : loss : 0.034576, loss_ce: 0.008801
2022-01-14 12:30:11,253 iteration 3313 : loss : 0.027219, loss_ce: 0.010980
2022-01-14 12:30:12,197 iteration 3314 : loss : 0.041599, loss_ce: 0.013556
2022-01-14 12:30:12,198 Training Data Eval:
2022-01-14 12:30:16,492   Average segmentation loss on training set: 0.0153
2022-01-14 12:30:16,492 Validation Data Eval:
2022-01-14 12:30:17,941   Average segmentation loss on validation set: 0.0675
2022-01-14 12:30:18,805 iteration 3315 : loss : 0.019431, loss_ce: 0.007627
 49%|██████████████▏              | 195/400 [55:44<1:01:36, 18.03s/it]2022-01-14 12:30:19,751 iteration 3316 : loss : 0.026597, loss_ce: 0.015297
2022-01-14 12:30:20,694 iteration 3317 : loss : 0.023295, loss_ce: 0.010621
2022-01-14 12:30:21,596 iteration 3318 : loss : 0.028094, loss_ce: 0.012614
2022-01-14 12:30:22,474 iteration 3319 : loss : 0.026199, loss_ce: 0.010056
2022-01-14 12:30:23,497 iteration 3320 : loss : 0.044180, loss_ce: 0.019262
2022-01-14 12:30:24,395 iteration 3321 : loss : 0.019024, loss_ce: 0.005818
2022-01-14 12:30:25,354 iteration 3322 : loss : 0.025075, loss_ce: 0.006627
2022-01-14 12:30:26,224 iteration 3323 : loss : 0.019073, loss_ce: 0.006172
2022-01-14 12:30:27,121 iteration 3324 : loss : 0.026705, loss_ce: 0.012248
2022-01-14 12:30:28,088 iteration 3325 : loss : 0.031096, loss_ce: 0.013348
2022-01-14 12:30:28,954 iteration 3326 : loss : 0.038092, loss_ce: 0.013656
2022-01-14 12:30:29,868 iteration 3327 : loss : 0.024731, loss_ce: 0.008350
2022-01-14 12:30:30,847 iteration 3328 : loss : 0.021877, loss_ce: 0.007972
2022-01-14 12:30:31,783 iteration 3329 : loss : 0.024777, loss_ce: 0.009574
2022-01-14 12:30:32,680 iteration 3330 : loss : 0.023936, loss_ce: 0.012082
2022-01-14 12:30:33,532 iteration 3331 : loss : 0.024890, loss_ce: 0.011226
2022-01-14 12:30:34,489 iteration 3332 : loss : 0.025735, loss_ce: 0.008139
 49%|███████████████▏               | 196/400 [56:00<58:54, 17.33s/it]2022-01-14 12:30:35,513 iteration 3333 : loss : 0.026880, loss_ce: 0.010861
2022-01-14 12:30:36,467 iteration 3334 : loss : 0.028936, loss_ce: 0.013911
2022-01-14 12:30:37,503 iteration 3335 : loss : 0.027468, loss_ce: 0.011582
2022-01-14 12:30:38,451 iteration 3336 : loss : 0.024921, loss_ce: 0.008288
2022-01-14 12:30:39,449 iteration 3337 : loss : 0.036670, loss_ce: 0.015089
2022-01-14 12:30:40,462 iteration 3338 : loss : 0.029697, loss_ce: 0.012966
2022-01-14 12:30:41,337 iteration 3339 : loss : 0.023322, loss_ce: 0.009580
2022-01-14 12:30:42,194 iteration 3340 : loss : 0.025058, loss_ce: 0.006467
2022-01-14 12:30:43,120 iteration 3341 : loss : 0.026402, loss_ce: 0.009708
2022-01-14 12:30:44,035 iteration 3342 : loss : 0.020348, loss_ce: 0.009746
2022-01-14 12:30:45,000 iteration 3343 : loss : 0.021664, loss_ce: 0.010376
2022-01-14 12:30:45,934 iteration 3344 : loss : 0.026358, loss_ce: 0.009095
2022-01-14 12:30:46,869 iteration 3345 : loss : 0.026778, loss_ce: 0.010834
2022-01-14 12:30:47,756 iteration 3346 : loss : 0.020580, loss_ce: 0.008978
2022-01-14 12:30:48,637 iteration 3347 : loss : 0.024674, loss_ce: 0.008900
2022-01-14 12:30:49,465 iteration 3348 : loss : 0.021988, loss_ce: 0.008823
2022-01-14 12:30:50,454 iteration 3349 : loss : 0.028125, loss_ce: 0.008021
 49%|███████████████▎               | 197/400 [56:16<57:14, 16.92s/it]2022-01-14 12:30:51,445 iteration 3350 : loss : 0.029442, loss_ce: 0.010665
2022-01-14 12:30:52,430 iteration 3351 : loss : 0.031398, loss_ce: 0.010444
2022-01-14 12:30:53,403 iteration 3352 : loss : 0.043393, loss_ce: 0.022142
2022-01-14 12:30:54,426 iteration 3353 : loss : 0.025668, loss_ce: 0.008566
2022-01-14 12:30:55,312 iteration 3354 : loss : 0.024422, loss_ce: 0.012070
2022-01-14 12:30:56,336 iteration 3355 : loss : 0.035118, loss_ce: 0.014069
2022-01-14 12:30:57,350 iteration 3356 : loss : 0.020785, loss_ce: 0.007444
2022-01-14 12:30:58,265 iteration 3357 : loss : 0.028772, loss_ce: 0.008308
2022-01-14 12:30:59,244 iteration 3358 : loss : 0.017231, loss_ce: 0.007187
2022-01-14 12:31:00,095 iteration 3359 : loss : 0.018915, loss_ce: 0.006857
2022-01-14 12:31:00,993 iteration 3360 : loss : 0.025712, loss_ce: 0.009176
2022-01-14 12:31:01,898 iteration 3361 : loss : 0.026640, loss_ce: 0.009287
2022-01-14 12:31:02,817 iteration 3362 : loss : 0.023512, loss_ce: 0.007990
2022-01-14 12:31:03,794 iteration 3363 : loss : 0.039656, loss_ce: 0.011779
2022-01-14 12:31:04,653 iteration 3364 : loss : 0.018624, loss_ce: 0.007805
2022-01-14 12:31:05,589 iteration 3365 : loss : 0.028157, loss_ce: 0.012166
2022-01-14 12:31:06,432 iteration 3366 : loss : 0.022444, loss_ce: 0.010008
 50%|███████████████▎               | 198/400 [56:32<56:00, 16.64s/it]2022-01-14 12:31:07,421 iteration 3367 : loss : 0.022658, loss_ce: 0.007958
2022-01-14 12:31:08,320 iteration 3368 : loss : 0.017618, loss_ce: 0.007879
2022-01-14 12:31:09,165 iteration 3369 : loss : 0.023156, loss_ce: 0.007591
2022-01-14 12:31:10,128 iteration 3370 : loss : 0.036882, loss_ce: 0.017046
2022-01-14 12:31:11,180 iteration 3371 : loss : 0.039021, loss_ce: 0.016279
2022-01-14 12:31:12,063 iteration 3372 : loss : 0.017552, loss_ce: 0.006924
2022-01-14 12:31:13,011 iteration 3373 : loss : 0.022468, loss_ce: 0.007981
2022-01-14 12:31:13,884 iteration 3374 : loss : 0.017782, loss_ce: 0.005979
2022-01-14 12:31:14,759 iteration 3375 : loss : 0.024580, loss_ce: 0.009068
2022-01-14 12:31:15,689 iteration 3376 : loss : 0.027996, loss_ce: 0.008513
2022-01-14 12:31:16,503 iteration 3377 : loss : 0.016216, loss_ce: 0.006517
2022-01-14 12:31:17,450 iteration 3378 : loss : 0.027238, loss_ce: 0.006140
2022-01-14 12:31:18,473 iteration 3379 : loss : 0.031653, loss_ce: 0.014077
2022-01-14 12:31:19,448 iteration 3380 : loss : 0.025101, loss_ce: 0.007845
2022-01-14 12:31:20,396 iteration 3381 : loss : 0.031659, loss_ce: 0.013335
2022-01-14 12:31:21,354 iteration 3382 : loss : 0.023174, loss_ce: 0.009028
2022-01-14 12:31:22,249 iteration 3383 : loss : 0.021179, loss_ce: 0.008177
 50%|███████████████▍               | 199/400 [56:48<54:54, 16.39s/it]2022-01-14 12:31:23,315 iteration 3384 : loss : 0.032782, loss_ce: 0.011503
2022-01-14 12:31:24,260 iteration 3385 : loss : 0.030117, loss_ce: 0.011875
2022-01-14 12:31:25,144 iteration 3386 : loss : 0.016652, loss_ce: 0.005162
2022-01-14 12:31:26,118 iteration 3387 : loss : 0.030395, loss_ce: 0.011130
2022-01-14 12:31:27,083 iteration 3388 : loss : 0.025790, loss_ce: 0.010494
2022-01-14 12:31:27,965 iteration 3389 : loss : 0.018292, loss_ce: 0.007469
2022-01-14 12:31:28,768 iteration 3390 : loss : 0.018985, loss_ce: 0.007811
2022-01-14 12:31:29,740 iteration 3391 : loss : 0.024616, loss_ce: 0.009586
2022-01-14 12:31:30,711 iteration 3392 : loss : 0.040068, loss_ce: 0.013513
2022-01-14 12:31:31,639 iteration 3393 : loss : 0.022986, loss_ce: 0.009082
2022-01-14 12:31:32,612 iteration 3394 : loss : 0.018543, loss_ce: 0.006629
2022-01-14 12:31:33,468 iteration 3395 : loss : 0.016317, loss_ce: 0.006711
2022-01-14 12:31:34,449 iteration 3396 : loss : 0.021129, loss_ce: 0.008807
2022-01-14 12:31:35,409 iteration 3397 : loss : 0.021421, loss_ce: 0.008658
2022-01-14 12:31:36,375 iteration 3398 : loss : 0.026978, loss_ce: 0.011351
2022-01-14 12:31:37,292 iteration 3399 : loss : 0.024574, loss_ce: 0.009054
2022-01-14 12:31:37,292 Training Data Eval:
2022-01-14 12:31:41,584   Average segmentation loss on training set: 0.0163
2022-01-14 12:31:41,585 Validation Data Eval:
2022-01-14 12:31:43,034   Average segmentation loss on validation set: 0.0642
2022-01-14 12:31:43,876 iteration 3400 : loss : 0.027803, loss_ce: 0.009222
 50%|███████████████▌               | 200/400 [57:09<59:52, 17.96s/it]2022-01-14 12:31:44,882 iteration 3401 : loss : 0.025077, loss_ce: 0.013437
2022-01-14 12:31:45,740 iteration 3402 : loss : 0.017657, loss_ce: 0.007083
2022-01-14 12:31:46,769 iteration 3403 : loss : 0.024521, loss_ce: 0.009163
2022-01-14 12:31:47,772 iteration 3404 : loss : 0.026083, loss_ce: 0.010020
2022-01-14 12:31:48,642 iteration 3405 : loss : 0.031579, loss_ce: 0.008131
2022-01-14 12:31:49,639 iteration 3406 : loss : 0.025025, loss_ce: 0.009637
2022-01-14 12:31:50,549 iteration 3407 : loss : 0.022286, loss_ce: 0.008526
2022-01-14 12:31:51,398 iteration 3408 : loss : 0.020772, loss_ce: 0.007089
2022-01-14 12:31:52,319 iteration 3409 : loss : 0.018192, loss_ce: 0.006264
2022-01-14 12:31:53,283 iteration 3410 : loss : 0.022047, loss_ce: 0.010403
2022-01-14 12:31:54,265 iteration 3411 : loss : 0.034153, loss_ce: 0.013669
2022-01-14 12:31:55,209 iteration 3412 : loss : 0.037060, loss_ce: 0.018679
2022-01-14 12:31:56,138 iteration 3413 : loss : 0.026783, loss_ce: 0.007359
2022-01-14 12:31:57,144 iteration 3414 : loss : 0.024098, loss_ce: 0.009878
2022-01-14 12:31:58,100 iteration 3415 : loss : 0.017141, loss_ce: 0.007687
2022-01-14 12:31:59,098 iteration 3416 : loss : 0.025191, loss_ce: 0.010695
2022-01-14 12:32:00,103 iteration 3417 : loss : 0.027687, loss_ce: 0.008921
 50%|███████████████▌               | 201/400 [57:25<57:50, 17.44s/it]2022-01-14 12:32:01,029 iteration 3418 : loss : 0.017247, loss_ce: 0.005726
2022-01-14 12:32:01,842 iteration 3419 : loss : 0.018583, loss_ce: 0.008467
2022-01-14 12:32:02,726 iteration 3420 : loss : 0.018955, loss_ce: 0.006644
2022-01-14 12:32:03,592 iteration 3421 : loss : 0.017622, loss_ce: 0.006655
2022-01-14 12:32:04,452 iteration 3422 : loss : 0.018995, loss_ce: 0.006158
2022-01-14 12:32:05,411 iteration 3423 : loss : 0.033889, loss_ce: 0.016744
2022-01-14 12:32:06,347 iteration 3424 : loss : 0.030919, loss_ce: 0.013753
2022-01-14 12:32:07,302 iteration 3425 : loss : 0.025036, loss_ce: 0.009167
2022-01-14 12:32:08,131 iteration 3426 : loss : 0.026183, loss_ce: 0.009654
2022-01-14 12:32:09,057 iteration 3427 : loss : 0.025087, loss_ce: 0.006719
2022-01-14 12:32:10,004 iteration 3428 : loss : 0.023316, loss_ce: 0.009592
2022-01-14 12:32:10,895 iteration 3429 : loss : 0.020336, loss_ce: 0.006276
2022-01-14 12:32:11,832 iteration 3430 : loss : 0.025864, loss_ce: 0.011046
2022-01-14 12:32:12,794 iteration 3431 : loss : 0.024350, loss_ce: 0.008175
2022-01-14 12:32:13,812 iteration 3432 : loss : 0.028499, loss_ce: 0.011193
2022-01-14 12:32:14,822 iteration 3433 : loss : 0.031318, loss_ce: 0.010447
2022-01-14 12:32:15,735 iteration 3434 : loss : 0.031999, loss_ce: 0.008867
 50%|███████████████▋               | 202/400 [57:41<55:45, 16.90s/it]2022-01-14 12:32:16,702 iteration 3435 : loss : 0.023127, loss_ce: 0.007307
2022-01-14 12:32:17,693 iteration 3436 : loss : 0.027554, loss_ce: 0.010497
2022-01-14 12:32:18,719 iteration 3437 : loss : 0.025718, loss_ce: 0.009144
2022-01-14 12:32:19,714 iteration 3438 : loss : 0.021239, loss_ce: 0.008639
2022-01-14 12:32:20,585 iteration 3439 : loss : 0.028560, loss_ce: 0.010020
2022-01-14 12:32:21,548 iteration 3440 : loss : 0.022551, loss_ce: 0.008215
2022-01-14 12:32:22,436 iteration 3441 : loss : 0.028049, loss_ce: 0.009447
2022-01-14 12:32:23,366 iteration 3442 : loss : 0.020613, loss_ce: 0.008027
2022-01-14 12:32:24,363 iteration 3443 : loss : 0.022231, loss_ce: 0.008480
2022-01-14 12:32:25,265 iteration 3444 : loss : 0.025340, loss_ce: 0.009005
2022-01-14 12:32:26,193 iteration 3445 : loss : 0.033841, loss_ce: 0.015750
2022-01-14 12:32:27,184 iteration 3446 : loss : 0.040127, loss_ce: 0.022116
2022-01-14 12:32:28,169 iteration 3447 : loss : 0.035709, loss_ce: 0.009548
2022-01-14 12:32:29,028 iteration 3448 : loss : 0.032958, loss_ce: 0.013610
2022-01-14 12:32:29,913 iteration 3449 : loss : 0.022064, loss_ce: 0.008477
2022-01-14 12:32:30,813 iteration 3450 : loss : 0.018554, loss_ce: 0.006435
2022-01-14 12:32:31,716 iteration 3451 : loss : 0.019125, loss_ce: 0.010494
 51%|███████████████▋               | 203/400 [57:57<54:35, 16.63s/it]2022-01-14 12:32:32,610 iteration 3452 : loss : 0.018562, loss_ce: 0.008235
2022-01-14 12:32:33,586 iteration 3453 : loss : 0.035362, loss_ce: 0.014245
2022-01-14 12:32:34,687 iteration 3454 : loss : 0.027505, loss_ce: 0.012317
2022-01-14 12:32:35,599 iteration 3455 : loss : 0.022440, loss_ce: 0.009485
2022-01-14 12:32:36,553 iteration 3456 : loss : 0.037008, loss_ce: 0.009798
2022-01-14 12:32:37,418 iteration 3457 : loss : 0.024096, loss_ce: 0.010010
2022-01-14 12:32:38,277 iteration 3458 : loss : 0.027995, loss_ce: 0.008277
2022-01-14 12:32:39,235 iteration 3459 : loss : 0.023936, loss_ce: 0.011293
2022-01-14 12:32:40,112 iteration 3460 : loss : 0.017815, loss_ce: 0.006940
2022-01-14 12:32:40,971 iteration 3461 : loss : 0.020228, loss_ce: 0.007202
2022-01-14 12:32:41,770 iteration 3462 : loss : 0.019123, loss_ce: 0.008903
2022-01-14 12:32:42,706 iteration 3463 : loss : 0.023646, loss_ce: 0.009739
2022-01-14 12:32:43,648 iteration 3464 : loss : 0.029219, loss_ce: 0.011659
2022-01-14 12:32:44,540 iteration 3465 : loss : 0.025687, loss_ce: 0.011348
2022-01-14 12:32:45,559 iteration 3466 : loss : 0.031465, loss_ce: 0.012223
2022-01-14 12:32:46,404 iteration 3467 : loss : 0.017663, loss_ce: 0.006845
2022-01-14 12:32:47,318 iteration 3468 : loss : 0.025512, loss_ce: 0.009919
 51%|███████████████▊               | 204/400 [58:13<53:17, 16.31s/it]2022-01-14 12:32:48,268 iteration 3469 : loss : 0.024495, loss_ce: 0.009831
2022-01-14 12:32:49,157 iteration 3470 : loss : 0.038279, loss_ce: 0.016698
2022-01-14 12:32:50,163 iteration 3471 : loss : 0.024109, loss_ce: 0.010637
2022-01-14 12:32:51,187 iteration 3472 : loss : 0.023488, loss_ce: 0.008473
2022-01-14 12:32:52,071 iteration 3473 : loss : 0.016296, loss_ce: 0.007429
2022-01-14 12:32:53,057 iteration 3474 : loss : 0.023608, loss_ce: 0.009393
2022-01-14 12:32:54,007 iteration 3475 : loss : 0.019891, loss_ce: 0.009490
2022-01-14 12:32:54,898 iteration 3476 : loss : 0.023805, loss_ce: 0.007495
2022-01-14 12:32:55,812 iteration 3477 : loss : 0.020844, loss_ce: 0.006635
2022-01-14 12:32:56,742 iteration 3478 : loss : 0.028771, loss_ce: 0.017179
2022-01-14 12:32:57,658 iteration 3479 : loss : 0.019762, loss_ce: 0.008629
2022-01-14 12:32:58,538 iteration 3480 : loss : 0.016946, loss_ce: 0.007933
2022-01-14 12:32:59,428 iteration 3481 : loss : 0.027258, loss_ce: 0.008399
2022-01-14 12:33:00,346 iteration 3482 : loss : 0.023091, loss_ce: 0.008420
2022-01-14 12:33:01,343 iteration 3483 : loss : 0.025383, loss_ce: 0.011667
2022-01-14 12:33:02,303 iteration 3484 : loss : 0.022678, loss_ce: 0.007178
2022-01-14 12:33:02,303 Training Data Eval:
2022-01-14 12:33:06,597   Average segmentation loss on training set: 0.0151
2022-01-14 12:33:06,598 Validation Data Eval:
2022-01-14 12:33:08,043   Average segmentation loss on validation set: 0.0690
2022-01-14 12:33:08,947 iteration 3485 : loss : 0.020112, loss_ce: 0.007455
 51%|███████████████▉               | 205/400 [58:34<58:12, 17.91s/it]2022-01-14 12:33:09,957 iteration 3486 : loss : 0.032987, loss_ce: 0.008579
2022-01-14 12:33:10,862 iteration 3487 : loss : 0.021317, loss_ce: 0.008923
2022-01-14 12:33:11,782 iteration 3488 : loss : 0.022558, loss_ce: 0.007161
2022-01-14 12:33:12,576 iteration 3489 : loss : 0.022537, loss_ce: 0.010495
2022-01-14 12:33:13,541 iteration 3490 : loss : 0.028345, loss_ce: 0.011614
2022-01-14 12:33:14,588 iteration 3491 : loss : 0.029608, loss_ce: 0.014812
2022-01-14 12:33:15,529 iteration 3492 : loss : 0.018827, loss_ce: 0.005876
2022-01-14 12:33:16,434 iteration 3493 : loss : 0.026293, loss_ce: 0.009787
2022-01-14 12:33:17,368 iteration 3494 : loss : 0.021419, loss_ce: 0.007175
2022-01-14 12:33:18,304 iteration 3495 : loss : 0.018111, loss_ce: 0.005846
2022-01-14 12:33:19,358 iteration 3496 : loss : 0.036356, loss_ce: 0.013511
2022-01-14 12:33:20,264 iteration 3497 : loss : 0.021730, loss_ce: 0.009074
2022-01-14 12:33:21,248 iteration 3498 : loss : 0.019699, loss_ce: 0.007585
2022-01-14 12:33:22,150 iteration 3499 : loss : 0.022888, loss_ce: 0.012184
2022-01-14 12:33:23,082 iteration 3500 : loss : 0.021423, loss_ce: 0.009252
2022-01-14 12:33:24,109 iteration 3501 : loss : 0.029033, loss_ce: 0.012643
2022-01-14 12:33:25,015 iteration 3502 : loss : 0.020909, loss_ce: 0.010647
 52%|███████████████▉               | 206/400 [58:50<56:07, 17.36s/it]2022-01-14 12:33:26,035 iteration 3503 : loss : 0.036146, loss_ce: 0.010862
2022-01-14 12:33:26,936 iteration 3504 : loss : 0.020172, loss_ce: 0.007325
2022-01-14 12:33:27,856 iteration 3505 : loss : 0.019520, loss_ce: 0.008896
2022-01-14 12:33:28,852 iteration 3506 : loss : 0.028639, loss_ce: 0.009012
2022-01-14 12:33:29,724 iteration 3507 : loss : 0.016889, loss_ce: 0.006823
2022-01-14 12:33:30,632 iteration 3508 : loss : 0.017500, loss_ce: 0.004280
2022-01-14 12:33:31,608 iteration 3509 : loss : 0.022681, loss_ce: 0.009381
2022-01-14 12:33:32,535 iteration 3510 : loss : 0.027809, loss_ce: 0.011400
2022-01-14 12:33:33,663 iteration 3511 : loss : 0.035629, loss_ce: 0.016728
2022-01-14 12:33:34,543 iteration 3512 : loss : 0.019161, loss_ce: 0.006818
2022-01-14 12:33:35,383 iteration 3513 : loss : 0.021956, loss_ce: 0.010063
2022-01-14 12:33:36,295 iteration 3514 : loss : 0.020455, loss_ce: 0.008507
2022-01-14 12:33:37,206 iteration 3515 : loss : 0.024148, loss_ce: 0.011342
2022-01-14 12:33:38,113 iteration 3516 : loss : 0.017573, loss_ce: 0.007847
2022-01-14 12:33:39,041 iteration 3517 : loss : 0.022502, loss_ce: 0.009952
2022-01-14 12:33:40,064 iteration 3518 : loss : 0.026512, loss_ce: 0.008524
2022-01-14 12:33:41,042 iteration 3519 : loss : 0.026405, loss_ce: 0.011595
 52%|████████████████               | 207/400 [59:06<54:33, 16.96s/it]2022-01-14 12:33:41,961 iteration 3520 : loss : 0.024453, loss_ce: 0.007635
2022-01-14 12:33:42,872 iteration 3521 : loss : 0.025034, loss_ce: 0.006305
2022-01-14 12:33:43,743 iteration 3522 : loss : 0.022377, loss_ce: 0.006377
2022-01-14 12:33:44,702 iteration 3523 : loss : 0.026445, loss_ce: 0.013966
2022-01-14 12:33:45,693 iteration 3524 : loss : 0.021356, loss_ce: 0.008239
2022-01-14 12:33:46,587 iteration 3525 : loss : 0.025543, loss_ce: 0.007303
2022-01-14 12:33:47,516 iteration 3526 : loss : 0.021289, loss_ce: 0.010292
2022-01-14 12:33:48,539 iteration 3527 : loss : 0.021828, loss_ce: 0.008566
2022-01-14 12:33:49,449 iteration 3528 : loss : 0.093422, loss_ce: 0.015179
2022-01-14 12:33:50,380 iteration 3529 : loss : 0.021710, loss_ce: 0.007002
2022-01-14 12:33:51,282 iteration 3530 : loss : 0.020835, loss_ce: 0.007050
2022-01-14 12:33:52,208 iteration 3531 : loss : 0.026744, loss_ce: 0.008908
2022-01-14 12:33:53,160 iteration 3532 : loss : 0.027846, loss_ce: 0.012953
2022-01-14 12:33:54,128 iteration 3533 : loss : 0.035208, loss_ce: 0.013230
2022-01-14 12:33:54,987 iteration 3534 : loss : 0.029488, loss_ce: 0.010408
2022-01-14 12:33:55,945 iteration 3535 : loss : 0.038980, loss_ce: 0.017190
2022-01-14 12:33:56,853 iteration 3536 : loss : 0.026441, loss_ce: 0.012014
 52%|████████████████               | 208/400 [59:22<53:09, 16.61s/it]2022-01-14 12:33:57,921 iteration 3537 : loss : 0.035206, loss_ce: 0.018825
2022-01-14 12:33:58,816 iteration 3538 : loss : 0.025000, loss_ce: 0.008260
2022-01-14 12:33:59,708 iteration 3539 : loss : 0.024624, loss_ce: 0.007384
2022-01-14 12:34:00,679 iteration 3540 : loss : 0.041871, loss_ce: 0.019211
2022-01-14 12:34:01,667 iteration 3541 : loss : 0.033099, loss_ce: 0.013100
2022-01-14 12:34:02,624 iteration 3542 : loss : 0.032525, loss_ce: 0.012113
2022-01-14 12:34:03,608 iteration 3543 : loss : 0.026204, loss_ce: 0.011202
2022-01-14 12:34:04,600 iteration 3544 : loss : 0.046369, loss_ce: 0.009731
2022-01-14 12:34:05,605 iteration 3545 : loss : 0.033306, loss_ce: 0.010441
2022-01-14 12:34:06,608 iteration 3546 : loss : 0.025157, loss_ce: 0.008488
2022-01-14 12:34:07,619 iteration 3547 : loss : 0.027083, loss_ce: 0.013396
2022-01-14 12:34:08,515 iteration 3548 : loss : 0.015581, loss_ce: 0.004557
2022-01-14 12:34:09,552 iteration 3549 : loss : 0.044297, loss_ce: 0.021943
2022-01-14 12:34:10,463 iteration 3550 : loss : 0.021011, loss_ce: 0.006461
2022-01-14 12:34:11,343 iteration 3551 : loss : 0.024858, loss_ce: 0.010518
2022-01-14 12:34:12,222 iteration 3552 : loss : 0.027587, loss_ce: 0.013924
2022-01-14 12:34:13,130 iteration 3553 : loss : 0.022231, loss_ce: 0.007917
 52%|████████████████▏              | 209/400 [59:39<52:34, 16.52s/it]2022-01-14 12:34:14,112 iteration 3554 : loss : 0.026836, loss_ce: 0.011712
2022-01-14 12:34:15,010 iteration 3555 : loss : 0.025707, loss_ce: 0.011516
2022-01-14 12:34:16,009 iteration 3556 : loss : 0.024345, loss_ce: 0.012752
2022-01-14 12:34:17,009 iteration 3557 : loss : 0.028324, loss_ce: 0.012096
2022-01-14 12:34:17,932 iteration 3558 : loss : 0.027012, loss_ce: 0.008402
2022-01-14 12:34:18,895 iteration 3559 : loss : 0.032256, loss_ce: 0.009145
2022-01-14 12:34:19,820 iteration 3560 : loss : 0.024678, loss_ce: 0.010876
2022-01-14 12:34:20,657 iteration 3561 : loss : 0.016828, loss_ce: 0.008632
2022-01-14 12:34:21,612 iteration 3562 : loss : 0.027755, loss_ce: 0.010724
2022-01-14 12:34:22,561 iteration 3563 : loss : 0.026655, loss_ce: 0.009960
2022-01-14 12:34:23,544 iteration 3564 : loss : 0.042350, loss_ce: 0.010858
2022-01-14 12:34:24,425 iteration 3565 : loss : 0.033045, loss_ce: 0.007772
2022-01-14 12:34:25,309 iteration 3566 : loss : 0.025742, loss_ce: 0.011132
2022-01-14 12:34:26,315 iteration 3567 : loss : 0.029472, loss_ce: 0.014674
2022-01-14 12:34:27,240 iteration 3568 : loss : 0.027860, loss_ce: 0.008775
2022-01-14 12:34:28,101 iteration 3569 : loss : 0.030138, loss_ce: 0.010946
2022-01-14 12:34:28,102 Training Data Eval:
2022-01-14 12:34:32,398   Average segmentation loss on training set: 0.0186
2022-01-14 12:34:32,398 Validation Data Eval:
2022-01-14 12:34:33,844   Average segmentation loss on validation set: 0.0860
2022-01-14 12:34:34,806 iteration 3570 : loss : 0.025626, loss_ce: 0.007182
 52%|███████████████▏             | 210/400 [1:00:00<57:12, 18.06s/it]2022-01-14 12:34:35,826 iteration 3571 : loss : 0.035855, loss_ce: 0.017246
2022-01-14 12:34:36,690 iteration 3572 : loss : 0.019530, loss_ce: 0.007052
2022-01-14 12:34:37,638 iteration 3573 : loss : 0.038685, loss_ce: 0.011965
2022-01-14 12:34:38,563 iteration 3574 : loss : 0.022299, loss_ce: 0.006836
2022-01-14 12:34:39,434 iteration 3575 : loss : 0.019180, loss_ce: 0.005743
2022-01-14 12:34:40,421 iteration 3576 : loss : 0.027493, loss_ce: 0.007573
2022-01-14 12:34:41,377 iteration 3577 : loss : 0.024193, loss_ce: 0.009381
2022-01-14 12:34:42,197 iteration 3578 : loss : 0.022563, loss_ce: 0.008562
2022-01-14 12:34:43,093 iteration 3579 : loss : 0.025667, loss_ce: 0.010033
2022-01-14 12:34:43,965 iteration 3580 : loss : 0.030109, loss_ce: 0.010859
2022-01-14 12:34:44,826 iteration 3581 : loss : 0.028151, loss_ce: 0.014899
2022-01-14 12:34:45,750 iteration 3582 : loss : 0.021386, loss_ce: 0.007518
2022-01-14 12:34:46,716 iteration 3583 : loss : 0.030031, loss_ce: 0.010415
2022-01-14 12:34:47,632 iteration 3584 : loss : 0.018898, loss_ce: 0.006485
2022-01-14 12:34:48,505 iteration 3585 : loss : 0.024258, loss_ce: 0.007948
2022-01-14 12:34:49,513 iteration 3586 : loss : 0.033295, loss_ce: 0.016184
2022-01-14 12:34:50,428 iteration 3587 : loss : 0.016072, loss_ce: 0.006736
 53%|███████████████▎             | 211/400 [1:00:16<54:35, 17.33s/it]2022-01-14 12:34:51,487 iteration 3588 : loss : 0.025424, loss_ce: 0.011792
2022-01-14 12:34:52,344 iteration 3589 : loss : 0.017768, loss_ce: 0.006110
2022-01-14 12:34:53,236 iteration 3590 : loss : 0.019138, loss_ce: 0.007108
2022-01-14 12:34:54,149 iteration 3591 : loss : 0.018959, loss_ce: 0.006736
2022-01-14 12:34:55,262 iteration 3592 : loss : 0.026354, loss_ce: 0.008414
2022-01-14 12:34:56,162 iteration 3593 : loss : 0.033175, loss_ce: 0.010168
2022-01-14 12:34:57,061 iteration 3594 : loss : 0.026961, loss_ce: 0.009271
2022-01-14 12:34:58,014 iteration 3595 : loss : 0.033918, loss_ce: 0.012040
2022-01-14 12:34:58,929 iteration 3596 : loss : 0.015303, loss_ce: 0.005291
2022-01-14 12:34:59,900 iteration 3597 : loss : 0.030625, loss_ce: 0.010331
2022-01-14 12:35:00,761 iteration 3598 : loss : 0.015038, loss_ce: 0.006492
2022-01-14 12:35:01,751 iteration 3599 : loss : 0.021867, loss_ce: 0.007319
2022-01-14 12:35:02,555 iteration 3600 : loss : 0.019128, loss_ce: 0.007165
2022-01-14 12:35:03,476 iteration 3601 : loss : 0.026636, loss_ce: 0.011317
2022-01-14 12:35:04,339 iteration 3602 : loss : 0.019597, loss_ce: 0.006194
2022-01-14 12:35:05,283 iteration 3603 : loss : 0.025398, loss_ce: 0.012343
2022-01-14 12:35:06,144 iteration 3604 : loss : 0.017120, loss_ce: 0.007709
 53%|███████████████▎             | 212/400 [1:00:32<52:47, 16.85s/it]2022-01-14 12:35:07,134 iteration 3605 : loss : 0.022027, loss_ce: 0.008814
2022-01-14 12:35:08,010 iteration 3606 : loss : 0.033958, loss_ce: 0.015843
2022-01-14 12:35:08,963 iteration 3607 : loss : 0.022470, loss_ce: 0.008353
2022-01-14 12:35:09,853 iteration 3608 : loss : 0.014463, loss_ce: 0.005892
2022-01-14 12:35:10,752 iteration 3609 : loss : 0.017385, loss_ce: 0.007610
2022-01-14 12:35:11,673 iteration 3610 : loss : 0.019213, loss_ce: 0.007140
2022-01-14 12:35:12,517 iteration 3611 : loss : 0.017559, loss_ce: 0.004304
2022-01-14 12:35:13,380 iteration 3612 : loss : 0.016070, loss_ce: 0.005359
2022-01-14 12:35:14,414 iteration 3613 : loss : 0.028981, loss_ce: 0.013347
2022-01-14 12:35:15,277 iteration 3614 : loss : 0.016788, loss_ce: 0.006146
2022-01-14 12:35:16,100 iteration 3615 : loss : 0.016602, loss_ce: 0.005845
2022-01-14 12:35:17,020 iteration 3616 : loss : 0.028240, loss_ce: 0.010661
2022-01-14 12:35:17,981 iteration 3617 : loss : 0.024859, loss_ce: 0.010444
2022-01-14 12:35:18,900 iteration 3618 : loss : 0.016854, loss_ce: 0.006911
2022-01-14 12:35:19,828 iteration 3619 : loss : 0.027674, loss_ce: 0.007341
2022-01-14 12:35:20,685 iteration 3620 : loss : 0.026662, loss_ce: 0.008524
2022-01-14 12:35:21,623 iteration 3621 : loss : 0.024926, loss_ce: 0.009920
 53%|███████████████▍             | 213/400 [1:00:47<51:13, 16.43s/it]2022-01-14 12:35:22,588 iteration 3622 : loss : 0.019083, loss_ce: 0.008514
2022-01-14 12:35:23,589 iteration 3623 : loss : 0.030583, loss_ce: 0.007722
2022-01-14 12:35:24,521 iteration 3624 : loss : 0.016821, loss_ce: 0.006469
2022-01-14 12:35:25,436 iteration 3625 : loss : 0.021309, loss_ce: 0.008512
2022-01-14 12:35:26,312 iteration 3626 : loss : 0.021641, loss_ce: 0.010117
2022-01-14 12:35:27,153 iteration 3627 : loss : 0.020758, loss_ce: 0.007417
2022-01-14 12:35:28,135 iteration 3628 : loss : 0.062986, loss_ce: 0.016189
2022-01-14 12:35:29,186 iteration 3629 : loss : 0.024083, loss_ce: 0.009569
2022-01-14 12:35:30,024 iteration 3630 : loss : 0.021215, loss_ce: 0.008278
2022-01-14 12:35:30,954 iteration 3631 : loss : 0.033640, loss_ce: 0.009955
2022-01-14 12:35:31,972 iteration 3632 : loss : 0.031934, loss_ce: 0.011296
2022-01-14 12:35:32,891 iteration 3633 : loss : 0.017296, loss_ce: 0.006481
2022-01-14 12:35:33,795 iteration 3634 : loss : 0.021631, loss_ce: 0.009997
2022-01-14 12:35:34,816 iteration 3635 : loss : 0.031815, loss_ce: 0.014001
2022-01-14 12:35:35,811 iteration 3636 : loss : 0.031069, loss_ce: 0.007822
2022-01-14 12:35:36,737 iteration 3637 : loss : 0.035345, loss_ce: 0.011647
2022-01-14 12:35:37,658 iteration 3638 : loss : 0.020250, loss_ce: 0.008336
 54%|███████████████▌             | 214/400 [1:01:03<50:34, 16.31s/it]2022-01-14 12:35:38,583 iteration 3639 : loss : 0.019908, loss_ce: 0.008445
2022-01-14 12:35:39,445 iteration 3640 : loss : 0.026500, loss_ce: 0.010323
2022-01-14 12:35:40,307 iteration 3641 : loss : 0.018358, loss_ce: 0.006240
2022-01-14 12:35:41,241 iteration 3642 : loss : 0.031177, loss_ce: 0.009499
2022-01-14 12:35:42,105 iteration 3643 : loss : 0.019899, loss_ce: 0.008659
2022-01-14 12:35:42,986 iteration 3644 : loss : 0.014307, loss_ce: 0.005468
2022-01-14 12:35:43,906 iteration 3645 : loss : 0.025898, loss_ce: 0.008293
2022-01-14 12:35:44,831 iteration 3646 : loss : 0.039710, loss_ce: 0.014693
2022-01-14 12:35:45,759 iteration 3647 : loss : 0.021441, loss_ce: 0.005458
2022-01-14 12:35:46,711 iteration 3648 : loss : 0.033124, loss_ce: 0.014440
2022-01-14 12:35:47,613 iteration 3649 : loss : 0.018329, loss_ce: 0.004835
2022-01-14 12:35:48,546 iteration 3650 : loss : 0.020875, loss_ce: 0.009885
2022-01-14 12:35:49,498 iteration 3651 : loss : 0.029488, loss_ce: 0.009461
2022-01-14 12:35:50,563 iteration 3652 : loss : 0.029270, loss_ce: 0.007302
2022-01-14 12:35:51,456 iteration 3653 : loss : 0.021230, loss_ce: 0.010947
2022-01-14 12:35:52,300 iteration 3654 : loss : 0.017407, loss_ce: 0.008402
2022-01-14 12:35:52,311 Training Data Eval:
2022-01-14 12:35:56,618   Average segmentation loss on training set: 0.0164
2022-01-14 12:35:56,618 Validation Data Eval:
2022-01-14 12:35:58,078   Average segmentation loss on validation set: 0.0579
2022-01-14 12:35:59,275 Found new lowest validation loss at iteration 3654! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_1BLOCK_best_val_loss_seed2.pth
2022-01-14 12:36:00,219 iteration 3655 : loss : 0.021705, loss_ce: 0.008450
 54%|███████████████▌             | 215/400 [1:01:26<56:05, 18.19s/it]2022-01-14 12:36:01,227 iteration 3656 : loss : 0.020198, loss_ce: 0.007126
2022-01-14 12:36:02,103 iteration 3657 : loss : 0.018611, loss_ce: 0.009251
2022-01-14 12:36:03,060 iteration 3658 : loss : 0.021787, loss_ce: 0.010194
2022-01-14 12:36:04,119 iteration 3659 : loss : 0.025633, loss_ce: 0.009320
2022-01-14 12:36:05,052 iteration 3660 : loss : 0.027622, loss_ce: 0.007109
2022-01-14 12:36:05,901 iteration 3661 : loss : 0.020694, loss_ce: 0.008913
2022-01-14 12:36:06,828 iteration 3662 : loss : 0.022934, loss_ce: 0.008290
2022-01-14 12:36:07,736 iteration 3663 : loss : 0.027672, loss_ce: 0.009262
2022-01-14 12:36:08,702 iteration 3664 : loss : 0.018557, loss_ce: 0.006910
2022-01-14 12:36:09,622 iteration 3665 : loss : 0.023897, loss_ce: 0.012069
2022-01-14 12:36:10,548 iteration 3666 : loss : 0.024880, loss_ce: 0.008727
2022-01-14 12:36:11,432 iteration 3667 : loss : 0.035155, loss_ce: 0.017244
2022-01-14 12:36:12,256 iteration 3668 : loss : 0.034300, loss_ce: 0.009865
2022-01-14 12:36:13,232 iteration 3669 : loss : 0.021206, loss_ce: 0.008870
2022-01-14 12:36:14,106 iteration 3670 : loss : 0.025465, loss_ce: 0.010726
2022-01-14 12:36:15,014 iteration 3671 : loss : 0.029949, loss_ce: 0.015342
2022-01-14 12:36:16,056 iteration 3672 : loss : 0.046229, loss_ce: 0.013900
 54%|███████████████▋             | 216/400 [1:01:41<53:37, 17.48s/it]2022-01-14 12:36:17,069 iteration 3673 : loss : 0.021949, loss_ce: 0.009700
2022-01-14 12:36:18,058 iteration 3674 : loss : 0.024455, loss_ce: 0.006942
2022-01-14 12:36:19,090 iteration 3675 : loss : 0.032224, loss_ce: 0.008977
2022-01-14 12:36:19,940 iteration 3676 : loss : 0.017008, loss_ce: 0.006844
2022-01-14 12:36:20,878 iteration 3677 : loss : 0.034347, loss_ce: 0.011766
2022-01-14 12:36:21,888 iteration 3678 : loss : 0.022667, loss_ce: 0.008409
2022-01-14 12:36:22,783 iteration 3679 : loss : 0.027227, loss_ce: 0.012570
2022-01-14 12:36:23,714 iteration 3680 : loss : 0.027984, loss_ce: 0.010560
2022-01-14 12:36:24,624 iteration 3681 : loss : 0.021819, loss_ce: 0.008293
2022-01-14 12:36:25,454 iteration 3682 : loss : 0.021513, loss_ce: 0.007827
2022-01-14 12:36:26,268 iteration 3683 : loss : 0.021942, loss_ce: 0.007306
2022-01-14 12:36:27,251 iteration 3684 : loss : 0.017261, loss_ce: 0.007049
2022-01-14 12:36:28,136 iteration 3685 : loss : 0.021440, loss_ce: 0.006586
2022-01-14 12:36:29,072 iteration 3686 : loss : 0.021368, loss_ce: 0.008462
2022-01-14 12:36:29,961 iteration 3687 : loss : 0.017915, loss_ce: 0.006145
2022-01-14 12:36:30,878 iteration 3688 : loss : 0.022681, loss_ce: 0.011267
2022-01-14 12:36:31,824 iteration 3689 : loss : 0.022989, loss_ce: 0.008009
 54%|███████████████▋             | 217/400 [1:01:57<51:45, 16.97s/it]2022-01-14 12:36:32,820 iteration 3690 : loss : 0.027687, loss_ce: 0.007580
2022-01-14 12:36:33,767 iteration 3691 : loss : 0.024366, loss_ce: 0.005917
2022-01-14 12:36:34,712 iteration 3692 : loss : 0.025812, loss_ce: 0.014988
2022-01-14 12:36:35,562 iteration 3693 : loss : 0.018434, loss_ce: 0.007765
2022-01-14 12:36:36,478 iteration 3694 : loss : 0.031505, loss_ce: 0.013004
2022-01-14 12:36:37,402 iteration 3695 : loss : 0.022368, loss_ce: 0.011088
2022-01-14 12:36:38,311 iteration 3696 : loss : 0.034107, loss_ce: 0.012867
2022-01-14 12:36:39,263 iteration 3697 : loss : 0.026215, loss_ce: 0.008316
2022-01-14 12:36:40,251 iteration 3698 : loss : 0.028931, loss_ce: 0.011231
2022-01-14 12:36:41,122 iteration 3699 : loss : 0.018137, loss_ce: 0.007461
2022-01-14 12:36:42,048 iteration 3700 : loss : 0.024071, loss_ce: 0.007371
2022-01-14 12:36:42,879 iteration 3701 : loss : 0.020595, loss_ce: 0.009187
2022-01-14 12:36:43,813 iteration 3702 : loss : 0.023664, loss_ce: 0.008400
2022-01-14 12:36:44,743 iteration 3703 : loss : 0.017348, loss_ce: 0.008001
2022-01-14 12:36:45,566 iteration 3704 : loss : 0.021728, loss_ce: 0.008225
2022-01-14 12:36:46,562 iteration 3705 : loss : 0.035922, loss_ce: 0.015279
2022-01-14 12:36:47,400 iteration 3706 : loss : 0.018354, loss_ce: 0.005726
 55%|███████████████▊             | 218/400 [1:02:13<50:12, 16.55s/it]2022-01-14 12:36:48,400 iteration 3707 : loss : 0.020360, loss_ce: 0.008676
2022-01-14 12:36:49,239 iteration 3708 : loss : 0.023054, loss_ce: 0.007872
2022-01-14 12:36:50,253 iteration 3709 : loss : 0.028605, loss_ce: 0.008496
2022-01-14 12:36:51,179 iteration 3710 : loss : 0.034439, loss_ce: 0.011870
2022-01-14 12:36:52,057 iteration 3711 : loss : 0.016725, loss_ce: 0.005823
2022-01-14 12:36:52,918 iteration 3712 : loss : 0.018932, loss_ce: 0.008908
2022-01-14 12:36:53,936 iteration 3713 : loss : 0.025627, loss_ce: 0.010378
2022-01-14 12:36:54,876 iteration 3714 : loss : 0.032694, loss_ce: 0.013148
2022-01-14 12:36:55,770 iteration 3715 : loss : 0.018757, loss_ce: 0.009615
2022-01-14 12:36:56,685 iteration 3716 : loss : 0.023382, loss_ce: 0.011761
2022-01-14 12:36:57,628 iteration 3717 : loss : 0.024690, loss_ce: 0.009149
2022-01-14 12:36:58,526 iteration 3718 : loss : 0.019506, loss_ce: 0.007792
2022-01-14 12:36:59,461 iteration 3719 : loss : 0.018609, loss_ce: 0.006649
2022-01-14 12:37:00,485 iteration 3720 : loss : 0.027984, loss_ce: 0.009252
2022-01-14 12:37:01,363 iteration 3721 : loss : 0.021145, loss_ce: 0.007671
2022-01-14 12:37:02,270 iteration 3722 : loss : 0.026583, loss_ce: 0.014290
2022-01-14 12:37:03,267 iteration 3723 : loss : 0.047616, loss_ce: 0.022036
 55%|███████████████▉             | 219/400 [1:02:29<49:18, 16.35s/it]2022-01-14 12:37:04,311 iteration 3724 : loss : 0.027892, loss_ce: 0.011133
2022-01-14 12:37:05,238 iteration 3725 : loss : 0.023805, loss_ce: 0.010456
2022-01-14 12:37:06,310 iteration 3726 : loss : 0.021219, loss_ce: 0.007243
2022-01-14 12:37:07,182 iteration 3727 : loss : 0.019869, loss_ce: 0.006993
2022-01-14 12:37:08,103 iteration 3728 : loss : 0.031055, loss_ce: 0.014970
2022-01-14 12:37:09,094 iteration 3729 : loss : 0.035740, loss_ce: 0.011905
2022-01-14 12:37:09,994 iteration 3730 : loss : 0.030561, loss_ce: 0.009849
2022-01-14 12:37:10,875 iteration 3731 : loss : 0.021811, loss_ce: 0.007891
2022-01-14 12:37:11,808 iteration 3732 : loss : 0.027839, loss_ce: 0.010831
2022-01-14 12:37:12,710 iteration 3733 : loss : 0.037779, loss_ce: 0.010616
2022-01-14 12:37:13,618 iteration 3734 : loss : 0.018951, loss_ce: 0.007184
2022-01-14 12:37:14,582 iteration 3735 : loss : 0.021986, loss_ce: 0.010692
2022-01-14 12:37:15,565 iteration 3736 : loss : 0.026465, loss_ce: 0.007608
2022-01-14 12:37:16,511 iteration 3737 : loss : 0.025458, loss_ce: 0.009966
2022-01-14 12:37:17,445 iteration 3738 : loss : 0.026667, loss_ce: 0.009785
2022-01-14 12:37:18,361 iteration 3739 : loss : 0.030846, loss_ce: 0.010402
2022-01-14 12:37:18,362 Training Data Eval:
2022-01-14 12:37:22,662   Average segmentation loss on training set: 0.0151
2022-01-14 12:37:22,662 Validation Data Eval:
2022-01-14 12:37:24,115   Average segmentation loss on validation set: 0.0737
2022-01-14 12:37:25,099 iteration 3740 : loss : 0.027386, loss_ce: 0.012049
 55%|███████████████▉             | 220/400 [1:02:51<53:58, 17.99s/it]2022-01-14 12:37:26,096 iteration 3741 : loss : 0.024785, loss_ce: 0.009320
2022-01-14 12:37:26,982 iteration 3742 : loss : 0.031835, loss_ce: 0.016913
2022-01-14 12:37:27,882 iteration 3743 : loss : 0.025910, loss_ce: 0.008081
2022-01-14 12:37:28,816 iteration 3744 : loss : 0.019553, loss_ce: 0.008544
2022-01-14 12:37:29,689 iteration 3745 : loss : 0.015654, loss_ce: 0.006014
2022-01-14 12:37:30,653 iteration 3746 : loss : 0.017172, loss_ce: 0.006385
2022-01-14 12:37:31,628 iteration 3747 : loss : 0.024172, loss_ce: 0.005150
2022-01-14 12:37:32,558 iteration 3748 : loss : 0.026236, loss_ce: 0.012475
2022-01-14 12:37:33,470 iteration 3749 : loss : 0.020111, loss_ce: 0.008814
2022-01-14 12:37:34,414 iteration 3750 : loss : 0.023244, loss_ce: 0.009317
2022-01-14 12:37:35,373 iteration 3751 : loss : 0.031071, loss_ce: 0.009360
2022-01-14 12:37:36,312 iteration 3752 : loss : 0.019821, loss_ce: 0.008117
2022-01-14 12:37:37,171 iteration 3753 : loss : 0.027066, loss_ce: 0.007746
2022-01-14 12:37:38,022 iteration 3754 : loss : 0.016801, loss_ce: 0.005428
2022-01-14 12:37:38,907 iteration 3755 : loss : 0.022887, loss_ce: 0.010458
2022-01-14 12:37:39,827 iteration 3756 : loss : 0.034994, loss_ce: 0.012393
2022-01-14 12:37:40,752 iteration 3757 : loss : 0.021766, loss_ce: 0.006929
 55%|████████████████             | 221/400 [1:03:06<51:35, 17.29s/it]2022-01-14 12:37:41,764 iteration 3758 : loss : 0.023294, loss_ce: 0.008982
2022-01-14 12:37:42,692 iteration 3759 : loss : 0.018050, loss_ce: 0.006372
2022-01-14 12:37:43,519 iteration 3760 : loss : 0.018667, loss_ce: 0.006305
2022-01-14 12:37:44,502 iteration 3761 : loss : 0.041673, loss_ce: 0.015301
2022-01-14 12:37:45,425 iteration 3762 : loss : 0.029887, loss_ce: 0.008229
2022-01-14 12:37:46,403 iteration 3763 : loss : 0.042239, loss_ce: 0.016388
2022-01-14 12:37:47,371 iteration 3764 : loss : 0.026722, loss_ce: 0.010748
2022-01-14 12:37:48,311 iteration 3765 : loss : 0.020442, loss_ce: 0.008474
2022-01-14 12:37:49,212 iteration 3766 : loss : 0.019094, loss_ce: 0.007459
2022-01-14 12:37:50,214 iteration 3767 : loss : 0.027010, loss_ce: 0.007958
2022-01-14 12:37:51,155 iteration 3768 : loss : 0.025926, loss_ce: 0.011305
2022-01-14 12:37:52,057 iteration 3769 : loss : 0.018668, loss_ce: 0.008064
2022-01-14 12:37:52,908 iteration 3770 : loss : 0.024200, loss_ce: 0.007657
2022-01-14 12:37:53,782 iteration 3771 : loss : 0.016830, loss_ce: 0.005941
2022-01-14 12:37:54,683 iteration 3772 : loss : 0.023700, loss_ce: 0.008341
2022-01-14 12:37:55,537 iteration 3773 : loss : 0.016561, loss_ce: 0.005929
2022-01-14 12:37:56,411 iteration 3774 : loss : 0.022446, loss_ce: 0.010001
 56%|████████████████             | 222/400 [1:03:22<49:50, 16.80s/it]2022-01-14 12:37:57,354 iteration 3775 : loss : 0.027113, loss_ce: 0.007298
2022-01-14 12:37:58,324 iteration 3776 : loss : 0.039622, loss_ce: 0.019906
2022-01-14 12:37:59,388 iteration 3777 : loss : 0.031506, loss_ce: 0.011726
2022-01-14 12:38:00,267 iteration 3778 : loss : 0.017181, loss_ce: 0.008019
2022-01-14 12:38:01,227 iteration 3779 : loss : 0.023839, loss_ce: 0.009072
2022-01-14 12:38:02,131 iteration 3780 : loss : 0.020052, loss_ce: 0.009058
2022-01-14 12:38:03,043 iteration 3781 : loss : 0.024980, loss_ce: 0.008817
2022-01-14 12:38:04,012 iteration 3782 : loss : 0.037584, loss_ce: 0.013257
2022-01-14 12:38:04,978 iteration 3783 : loss : 0.021571, loss_ce: 0.006985
2022-01-14 12:38:05,958 iteration 3784 : loss : 0.027216, loss_ce: 0.013901
2022-01-14 12:38:06,845 iteration 3785 : loss : 0.027162, loss_ce: 0.009750
2022-01-14 12:38:07,781 iteration 3786 : loss : 0.018791, loss_ce: 0.006313
2022-01-14 12:38:08,763 iteration 3787 : loss : 0.047637, loss_ce: 0.021403
2022-01-14 12:38:09,783 iteration 3788 : loss : 0.027663, loss_ce: 0.011465
2022-01-14 12:38:10,671 iteration 3789 : loss : 0.020567, loss_ce: 0.005963
2022-01-14 12:38:11,623 iteration 3790 : loss : 0.020157, loss_ce: 0.007858
2022-01-14 12:38:12,457 iteration 3791 : loss : 0.018560, loss_ce: 0.007329
 56%|████████████████▏            | 223/400 [1:03:38<48:53, 16.57s/it]2022-01-14 12:38:13,432 iteration 3792 : loss : 0.022930, loss_ce: 0.010358
2022-01-14 12:38:14,366 iteration 3793 : loss : 0.017168, loss_ce: 0.006876
2022-01-14 12:38:15,241 iteration 3794 : loss : 0.020505, loss_ce: 0.007935
2022-01-14 12:38:16,273 iteration 3795 : loss : 0.044449, loss_ce: 0.020281
2022-01-14 12:38:17,240 iteration 3796 : loss : 0.030154, loss_ce: 0.008676
2022-01-14 12:38:18,140 iteration 3797 : loss : 0.018899, loss_ce: 0.006524
2022-01-14 12:38:19,172 iteration 3798 : loss : 0.022611, loss_ce: 0.008556
2022-01-14 12:38:20,053 iteration 3799 : loss : 0.020420, loss_ce: 0.012036
2022-01-14 12:38:21,031 iteration 3800 : loss : 0.023791, loss_ce: 0.008110
2022-01-14 12:38:21,895 iteration 3801 : loss : 0.016752, loss_ce: 0.006125
2022-01-14 12:38:22,820 iteration 3802 : loss : 0.026211, loss_ce: 0.008947
2022-01-14 12:38:23,729 iteration 3803 : loss : 0.017410, loss_ce: 0.007089
2022-01-14 12:38:24,551 iteration 3804 : loss : 0.021080, loss_ce: 0.007907
2022-01-14 12:38:25,508 iteration 3805 : loss : 0.019440, loss_ce: 0.007982
2022-01-14 12:38:26,393 iteration 3806 : loss : 0.023462, loss_ce: 0.007317
2022-01-14 12:38:27,276 iteration 3807 : loss : 0.022391, loss_ce: 0.008629
2022-01-14 12:38:28,217 iteration 3808 : loss : 0.019159, loss_ce: 0.006839
 56%|████████████████▏            | 224/400 [1:03:54<47:54, 16.33s/it]2022-01-14 12:38:29,180 iteration 3809 : loss : 0.017108, loss_ce: 0.006725
2022-01-14 12:38:30,106 iteration 3810 : loss : 0.021065, loss_ce: 0.007869
2022-01-14 12:38:31,160 iteration 3811 : loss : 0.020693, loss_ce: 0.006590
2022-01-14 12:38:32,054 iteration 3812 : loss : 0.023031, loss_ce: 0.008343
2022-01-14 12:38:32,995 iteration 3813 : loss : 0.029369, loss_ce: 0.011058
2022-01-14 12:38:33,840 iteration 3814 : loss : 0.017536, loss_ce: 0.005825
2022-01-14 12:38:34,830 iteration 3815 : loss : 0.043314, loss_ce: 0.017054
2022-01-14 12:38:35,881 iteration 3816 : loss : 0.020632, loss_ce: 0.006963
2022-01-14 12:38:36,815 iteration 3817 : loss : 0.024430, loss_ce: 0.010991
2022-01-14 12:38:37,869 iteration 3818 : loss : 0.021792, loss_ce: 0.008851
2022-01-14 12:38:38,746 iteration 3819 : loss : 0.017759, loss_ce: 0.007678
2022-01-14 12:38:39,716 iteration 3820 : loss : 0.029396, loss_ce: 0.012423
2022-01-14 12:38:40,622 iteration 3821 : loss : 0.019681, loss_ce: 0.009356
2022-01-14 12:38:41,442 iteration 3822 : loss : 0.015028, loss_ce: 0.006221
2022-01-14 12:38:42,315 iteration 3823 : loss : 0.021274, loss_ce: 0.007944
2022-01-14 12:38:43,220 iteration 3824 : loss : 0.025874, loss_ce: 0.009147
2022-01-14 12:38:43,220 Training Data Eval:
2022-01-14 12:38:47,528   Average segmentation loss on training set: 0.0164
2022-01-14 12:38:47,528 Validation Data Eval:
2022-01-14 12:38:48,992   Average segmentation loss on validation set: 0.0742
2022-01-14 12:38:49,865 iteration 3825 : loss : 0.021866, loss_ce: 0.008565
 56%|████████████████▎            | 225/400 [1:04:15<52:17, 17.93s/it]2022-01-14 12:38:50,753 iteration 3826 : loss : 0.022827, loss_ce: 0.008451
2022-01-14 12:38:51,666 iteration 3827 : loss : 0.031048, loss_ce: 0.011586
2022-01-14 12:38:52,633 iteration 3828 : loss : 0.028139, loss_ce: 0.011234
2022-01-14 12:38:53,534 iteration 3829 : loss : 0.024463, loss_ce: 0.011101
2022-01-14 12:38:54,461 iteration 3830 : loss : 0.024987, loss_ce: 0.009626
2022-01-14 12:38:55,432 iteration 3831 : loss : 0.044312, loss_ce: 0.011720
2022-01-14 12:38:56,264 iteration 3832 : loss : 0.019901, loss_ce: 0.008765
2022-01-14 12:38:57,215 iteration 3833 : loss : 0.018323, loss_ce: 0.005937
2022-01-14 12:38:58,117 iteration 3834 : loss : 0.015553, loss_ce: 0.007529
2022-01-14 12:38:59,096 iteration 3835 : loss : 0.019927, loss_ce: 0.009153
2022-01-14 12:39:00,063 iteration 3836 : loss : 0.016952, loss_ce: 0.005578
2022-01-14 12:39:00,908 iteration 3837 : loss : 0.016928, loss_ce: 0.006930
2022-01-14 12:39:01,781 iteration 3838 : loss : 0.017886, loss_ce: 0.005629
2022-01-14 12:39:02,659 iteration 3839 : loss : 0.019617, loss_ce: 0.007120
2022-01-14 12:39:03,475 iteration 3840 : loss : 0.023015, loss_ce: 0.006409
2022-01-14 12:39:04,351 iteration 3841 : loss : 0.017688, loss_ce: 0.006292
2022-01-14 12:39:05,249 iteration 3842 : loss : 0.018021, loss_ce: 0.004168
 56%|████████████████▍            | 226/400 [1:04:31<49:46, 17.16s/it]2022-01-14 12:39:06,267 iteration 3843 : loss : 0.015713, loss_ce: 0.005993
2022-01-14 12:39:07,176 iteration 3844 : loss : 0.025396, loss_ce: 0.010826
2022-01-14 12:39:08,075 iteration 3845 : loss : 0.020144, loss_ce: 0.007670
2022-01-14 12:39:08,984 iteration 3846 : loss : 0.018085, loss_ce: 0.005519
2022-01-14 12:39:09,965 iteration 3847 : loss : 0.016451, loss_ce: 0.007131
2022-01-14 12:39:10,849 iteration 3848 : loss : 0.016970, loss_ce: 0.006707
2022-01-14 12:39:11,706 iteration 3849 : loss : 0.017667, loss_ce: 0.006564
2022-01-14 12:39:12,654 iteration 3850 : loss : 0.037399, loss_ce: 0.009559
2022-01-14 12:39:13,643 iteration 3851 : loss : 0.028779, loss_ce: 0.017266
2022-01-14 12:39:14,545 iteration 3852 : loss : 0.021940, loss_ce: 0.008377
2022-01-14 12:39:15,426 iteration 3853 : loss : 0.016909, loss_ce: 0.008701
2022-01-14 12:39:16,370 iteration 3854 : loss : 0.023306, loss_ce: 0.009434
2022-01-14 12:39:17,338 iteration 3855 : loss : 0.028389, loss_ce: 0.014083
2022-01-14 12:39:18,274 iteration 3856 : loss : 0.023809, loss_ce: 0.008615
2022-01-14 12:39:19,163 iteration 3857 : loss : 0.018883, loss_ce: 0.007429
2022-01-14 12:39:20,117 iteration 3858 : loss : 0.022386, loss_ce: 0.009284
2022-01-14 12:39:21,055 iteration 3859 : loss : 0.019827, loss_ce: 0.005003
 57%|████████████████▍            | 227/400 [1:04:46<48:18, 16.76s/it]2022-01-14 12:39:22,052 iteration 3860 : loss : 0.024994, loss_ce: 0.010910
2022-01-14 12:39:23,052 iteration 3861 : loss : 0.022668, loss_ce: 0.010296
2022-01-14 12:39:23,912 iteration 3862 : loss : 0.016965, loss_ce: 0.007814
2022-01-14 12:39:24,880 iteration 3863 : loss : 0.021845, loss_ce: 0.011674
2022-01-14 12:39:25,867 iteration 3864 : loss : 0.024664, loss_ce: 0.009275
2022-01-14 12:39:26,950 iteration 3865 : loss : 0.030017, loss_ce: 0.014210
2022-01-14 12:39:27,997 iteration 3866 : loss : 0.072620, loss_ce: 0.032127
2022-01-14 12:39:28,910 iteration 3867 : loss : 0.016490, loss_ce: 0.005918
2022-01-14 12:39:29,882 iteration 3868 : loss : 0.021643, loss_ce: 0.008967
2022-01-14 12:39:30,846 iteration 3869 : loss : 0.044966, loss_ce: 0.017035
2022-01-14 12:39:31,853 iteration 3870 : loss : 0.025580, loss_ce: 0.008325
2022-01-14 12:39:32,784 iteration 3871 : loss : 0.028104, loss_ce: 0.008535
2022-01-14 12:39:33,687 iteration 3872 : loss : 0.023610, loss_ce: 0.010590
2022-01-14 12:39:34,618 iteration 3873 : loss : 0.025975, loss_ce: 0.009632
2022-01-14 12:39:35,613 iteration 3874 : loss : 0.020384, loss_ce: 0.007234
2022-01-14 12:39:36,584 iteration 3875 : loss : 0.021591, loss_ce: 0.007309
2022-01-14 12:39:37,502 iteration 3876 : loss : 0.024536, loss_ce: 0.005371
 57%|████████████████▌            | 228/400 [1:05:03<47:46, 16.66s/it]2022-01-14 12:39:38,462 iteration 3877 : loss : 0.015589, loss_ce: 0.005961
2022-01-14 12:39:39,462 iteration 3878 : loss : 0.020525, loss_ce: 0.009397
2022-01-14 12:39:40,396 iteration 3879 : loss : 0.024122, loss_ce: 0.011210
2022-01-14 12:39:41,320 iteration 3880 : loss : 0.017149, loss_ce: 0.006902
2022-01-14 12:39:42,200 iteration 3881 : loss : 0.019330, loss_ce: 0.009727
2022-01-14 12:39:43,199 iteration 3882 : loss : 0.026738, loss_ce: 0.008858
2022-01-14 12:39:44,143 iteration 3883 : loss : 0.036769, loss_ce: 0.018715
2022-01-14 12:39:45,024 iteration 3884 : loss : 0.020955, loss_ce: 0.004052
2022-01-14 12:39:45,881 iteration 3885 : loss : 0.019067, loss_ce: 0.006344
2022-01-14 12:39:46,767 iteration 3886 : loss : 0.023779, loss_ce: 0.009842
2022-01-14 12:39:47,759 iteration 3887 : loss : 0.035265, loss_ce: 0.014797
2022-01-14 12:39:48,674 iteration 3888 : loss : 0.027400, loss_ce: 0.009699
2022-01-14 12:39:49,614 iteration 3889 : loss : 0.024722, loss_ce: 0.011471
2022-01-14 12:39:50,445 iteration 3890 : loss : 0.020508, loss_ce: 0.007151
2022-01-14 12:39:51,384 iteration 3891 : loss : 0.014176, loss_ce: 0.005473
2022-01-14 12:39:52,326 iteration 3892 : loss : 0.038934, loss_ce: 0.009962
2022-01-14 12:39:53,377 iteration 3893 : loss : 0.040025, loss_ce: 0.023370
 57%|████████████████▌            | 229/400 [1:05:19<46:48, 16.43s/it]2022-01-14 12:39:54,302 iteration 3894 : loss : 0.018321, loss_ce: 0.007896
2022-01-14 12:39:55,290 iteration 3895 : loss : 0.028003, loss_ce: 0.010695
2022-01-14 12:39:56,206 iteration 3896 : loss : 0.026205, loss_ce: 0.006553
2022-01-14 12:39:57,169 iteration 3897 : loss : 0.033572, loss_ce: 0.015619
2022-01-14 12:39:58,059 iteration 3898 : loss : 0.020182, loss_ce: 0.007716
2022-01-14 12:39:59,048 iteration 3899 : loss : 0.025625, loss_ce: 0.011508
2022-01-14 12:40:00,057 iteration 3900 : loss : 0.028491, loss_ce: 0.008713
2022-01-14 12:40:00,919 iteration 3901 : loss : 0.020873, loss_ce: 0.006532
2022-01-14 12:40:01,822 iteration 3902 : loss : 0.016106, loss_ce: 0.005882
2022-01-14 12:40:02,752 iteration 3903 : loss : 0.019159, loss_ce: 0.007000
2022-01-14 12:40:03,754 iteration 3904 : loss : 0.022490, loss_ce: 0.007285
2022-01-14 12:40:04,665 iteration 3905 : loss : 0.023154, loss_ce: 0.010494
2022-01-14 12:40:05,555 iteration 3906 : loss : 0.019291, loss_ce: 0.008567
2022-01-14 12:40:06,499 iteration 3907 : loss : 0.037038, loss_ce: 0.012770
2022-01-14 12:40:07,525 iteration 3908 : loss : 0.028464, loss_ce: 0.009994
2022-01-14 12:40:08,498 iteration 3909 : loss : 0.026298, loss_ce: 0.010036
2022-01-14 12:40:08,498 Training Data Eval:
2022-01-14 12:40:12,803   Average segmentation loss on training set: 0.0140
2022-01-14 12:40:12,804 Validation Data Eval:
2022-01-14 12:40:14,263   Average segmentation loss on validation set: 0.0682
2022-01-14 12:40:15,107 iteration 3910 : loss : 0.018571, loss_ce: 0.006514
 57%|████████████████▋            | 230/400 [1:05:41<51:03, 18.02s/it]2022-01-14 12:40:16,034 iteration 3911 : loss : 0.020587, loss_ce: 0.006361
2022-01-14 12:40:16,998 iteration 3912 : loss : 0.024308, loss_ce: 0.010035
2022-01-14 12:40:17,845 iteration 3913 : loss : 0.020264, loss_ce: 0.006220
2022-01-14 12:40:18,672 iteration 3914 : loss : 0.022383, loss_ce: 0.007185
2022-01-14 12:40:19,505 iteration 3915 : loss : 0.020086, loss_ce: 0.007222
2022-01-14 12:40:20,474 iteration 3916 : loss : 0.023367, loss_ce: 0.008320
2022-01-14 12:40:21,478 iteration 3917 : loss : 0.043265, loss_ce: 0.010501
2022-01-14 12:40:22,440 iteration 3918 : loss : 0.028345, loss_ce: 0.012632
2022-01-14 12:40:23,371 iteration 3919 : loss : 0.028650, loss_ce: 0.010361
2022-01-14 12:40:24,325 iteration 3920 : loss : 0.032050, loss_ce: 0.014765
2022-01-14 12:40:25,280 iteration 3921 : loss : 0.028423, loss_ce: 0.011007
2022-01-14 12:40:26,171 iteration 3922 : loss : 0.015396, loss_ce: 0.006364
2022-01-14 12:40:27,092 iteration 3923 : loss : 0.029997, loss_ce: 0.012801
2022-01-14 12:40:28,013 iteration 3924 : loss : 0.032109, loss_ce: 0.012050
2022-01-14 12:40:29,057 iteration 3925 : loss : 0.022788, loss_ce: 0.009049
2022-01-14 12:40:29,999 iteration 3926 : loss : 0.020866, loss_ce: 0.008266
2022-01-14 12:40:30,948 iteration 3927 : loss : 0.030846, loss_ce: 0.011689
 58%|████████████████▋            | 231/400 [1:05:56<48:54, 17.37s/it]2022-01-14 12:40:31,948 iteration 3928 : loss : 0.029409, loss_ce: 0.014657
2022-01-14 12:40:32,974 iteration 3929 : loss : 0.035773, loss_ce: 0.014408
2022-01-14 12:40:34,046 iteration 3930 : loss : 0.031165, loss_ce: 0.012844
2022-01-14 12:40:35,006 iteration 3931 : loss : 0.020937, loss_ce: 0.009416
2022-01-14 12:40:35,971 iteration 3932 : loss : 0.028876, loss_ce: 0.008835
2022-01-14 12:40:36,875 iteration 3933 : loss : 0.031463, loss_ce: 0.007564
2022-01-14 12:40:37,809 iteration 3934 : loss : 0.026575, loss_ce: 0.008589
2022-01-14 12:40:38,771 iteration 3935 : loss : 0.028457, loss_ce: 0.011420
2022-01-14 12:40:39,687 iteration 3936 : loss : 0.017049, loss_ce: 0.006520
2022-01-14 12:40:40,592 iteration 3937 : loss : 0.016489, loss_ce: 0.004473
2022-01-14 12:40:41,486 iteration 3938 : loss : 0.018955, loss_ce: 0.008213
2022-01-14 12:40:42,518 iteration 3939 : loss : 0.025592, loss_ce: 0.009696
2022-01-14 12:40:43,410 iteration 3940 : loss : 0.025555, loss_ce: 0.006853
2022-01-14 12:40:44,338 iteration 3941 : loss : 0.021742, loss_ce: 0.010487
2022-01-14 12:40:45,252 iteration 3942 : loss : 0.028295, loss_ce: 0.012155
2022-01-14 12:40:46,198 iteration 3943 : loss : 0.021633, loss_ce: 0.010324
2022-01-14 12:40:47,143 iteration 3944 : loss : 0.018489, loss_ce: 0.006160
 58%|████████████████▊            | 232/400 [1:06:13<47:37, 17.01s/it]2022-01-14 12:40:48,091 iteration 3945 : loss : 0.016666, loss_ce: 0.007442
2022-01-14 12:40:48,928 iteration 3946 : loss : 0.015262, loss_ce: 0.005733
2022-01-14 12:40:49,874 iteration 3947 : loss : 0.020930, loss_ce: 0.007174
2022-01-14 12:40:50,778 iteration 3948 : loss : 0.020913, loss_ce: 0.009377
2022-01-14 12:40:51,716 iteration 3949 : loss : 0.022824, loss_ce: 0.010454
2022-01-14 12:40:52,647 iteration 3950 : loss : 0.020449, loss_ce: 0.006969
2022-01-14 12:40:53,621 iteration 3951 : loss : 0.026594, loss_ce: 0.010930
2022-01-14 12:40:54,552 iteration 3952 : loss : 0.017624, loss_ce: 0.008331
2022-01-14 12:40:55,460 iteration 3953 : loss : 0.017534, loss_ce: 0.005736
2022-01-14 12:40:56,441 iteration 3954 : loss : 0.024057, loss_ce: 0.010295
2022-01-14 12:40:57,388 iteration 3955 : loss : 0.019752, loss_ce: 0.006558
2022-01-14 12:40:58,301 iteration 3956 : loss : 0.027074, loss_ce: 0.011171
2022-01-14 12:40:59,214 iteration 3957 : loss : 0.020603, loss_ce: 0.008892
2022-01-14 12:41:00,246 iteration 3958 : loss : 0.026842, loss_ce: 0.009607
2022-01-14 12:41:01,149 iteration 3959 : loss : 0.018389, loss_ce: 0.005436
2022-01-14 12:41:02,085 iteration 3960 : loss : 0.018537, loss_ce: 0.004297
2022-01-14 12:41:03,055 iteration 3961 : loss : 0.016426, loss_ce: 0.005595
 58%|████████████████▉            | 233/400 [1:06:28<46:26, 16.68s/it]2022-01-14 12:41:04,173 iteration 3962 : loss : 0.027275, loss_ce: 0.010193
2022-01-14 12:41:05,042 iteration 3963 : loss : 0.022116, loss_ce: 0.009778
2022-01-14 12:41:05,998 iteration 3964 : loss : 0.025273, loss_ce: 0.011672
2022-01-14 12:41:07,036 iteration 3965 : loss : 0.038658, loss_ce: 0.009589
2022-01-14 12:41:07,928 iteration 3966 : loss : 0.019335, loss_ce: 0.006875
2022-01-14 12:41:08,826 iteration 3967 : loss : 0.023431, loss_ce: 0.005955
2022-01-14 12:41:09,822 iteration 3968 : loss : 0.020330, loss_ce: 0.007792
2022-01-14 12:41:10,817 iteration 3969 : loss : 0.017816, loss_ce: 0.007230
2022-01-14 12:41:11,825 iteration 3970 : loss : 0.025363, loss_ce: 0.013953
2022-01-14 12:41:12,721 iteration 3971 : loss : 0.033393, loss_ce: 0.011754
2022-01-14 12:41:13,621 iteration 3972 : loss : 0.022126, loss_ce: 0.008451
2022-01-14 12:41:14,573 iteration 3973 : loss : 0.025317, loss_ce: 0.009322
2022-01-14 12:41:15,565 iteration 3974 : loss : 0.026445, loss_ce: 0.012827
2022-01-14 12:41:16,577 iteration 3975 : loss : 0.021957, loss_ce: 0.008442
2022-01-14 12:41:17,610 iteration 3976 : loss : 0.019421, loss_ce: 0.008575
2022-01-14 12:41:18,543 iteration 3977 : loss : 0.024886, loss_ce: 0.009065
2022-01-14 12:41:19,463 iteration 3978 : loss : 0.019991, loss_ce: 0.007938
 58%|████████████████▉            | 234/400 [1:06:45<45:56, 16.60s/it]2022-01-14 12:41:20,508 iteration 3979 : loss : 0.024697, loss_ce: 0.008146
2022-01-14 12:41:21,470 iteration 3980 : loss : 0.023500, loss_ce: 0.010065
2022-01-14 12:41:22,376 iteration 3981 : loss : 0.018631, loss_ce: 0.006889
2022-01-14 12:41:23,453 iteration 3982 : loss : 0.025234, loss_ce: 0.007774
2022-01-14 12:41:24,394 iteration 3983 : loss : 0.018652, loss_ce: 0.004817
2022-01-14 12:41:25,353 iteration 3984 : loss : 0.020645, loss_ce: 0.007932
2022-01-14 12:41:26,293 iteration 3985 : loss : 0.026146, loss_ce: 0.009140
2022-01-14 12:41:27,186 iteration 3986 : loss : 0.024852, loss_ce: 0.010351
2022-01-14 12:41:28,069 iteration 3987 : loss : 0.018685, loss_ce: 0.008682
2022-01-14 12:41:29,072 iteration 3988 : loss : 0.022913, loss_ce: 0.010173
2022-01-14 12:41:30,018 iteration 3989 : loss : 0.039106, loss_ce: 0.015525
2022-01-14 12:41:30,913 iteration 3990 : loss : 0.016063, loss_ce: 0.005869
2022-01-14 12:41:31,842 iteration 3991 : loss : 0.021053, loss_ce: 0.007198
2022-01-14 12:41:32,906 iteration 3992 : loss : 0.036218, loss_ce: 0.013380
2022-01-14 12:41:33,812 iteration 3993 : loss : 0.020722, loss_ce: 0.010357
2022-01-14 12:41:34,735 iteration 3994 : loss : 0.023989, loss_ce: 0.009538
2022-01-14 12:41:34,735 Training Data Eval:
2022-01-14 12:41:39,037   Average segmentation loss on training set: 0.0141
2022-01-14 12:41:39,037 Validation Data Eval:
2022-01-14 12:41:40,487   Average segmentation loss on validation set: 0.0679
2022-01-14 12:41:41,389 iteration 3995 : loss : 0.022917, loss_ce: 0.006362
 59%|█████████████████            | 235/400 [1:07:07<50:02, 18.20s/it]2022-01-14 12:41:42,451 iteration 3996 : loss : 0.023697, loss_ce: 0.012584
2022-01-14 12:41:43,413 iteration 3997 : loss : 0.022663, loss_ce: 0.007835
2022-01-14 12:41:44,351 iteration 3998 : loss : 0.021836, loss_ce: 0.007255
2022-01-14 12:41:45,356 iteration 3999 : loss : 0.024073, loss_ce: 0.006939
2022-01-14 12:41:46,322 iteration 4000 : loss : 0.022548, loss_ce: 0.008966
2022-01-14 12:41:47,382 iteration 4001 : loss : 0.024463, loss_ce: 0.007382
2022-01-14 12:41:48,315 iteration 4002 : loss : 0.017629, loss_ce: 0.007741
2022-01-14 12:41:49,245 iteration 4003 : loss : 0.023995, loss_ce: 0.009820
2022-01-14 12:41:50,174 iteration 4004 : loss : 0.018133, loss_ce: 0.006462
2022-01-14 12:41:51,132 iteration 4005 : loss : 0.022543, loss_ce: 0.009928
2022-01-14 12:41:52,180 iteration 4006 : loss : 0.029236, loss_ce: 0.007609
2022-01-14 12:41:53,092 iteration 4007 : loss : 0.017106, loss_ce: 0.006864
2022-01-14 12:41:54,045 iteration 4008 : loss : 0.022911, loss_ce: 0.006419
2022-01-14 12:41:54,973 iteration 4009 : loss : 0.016404, loss_ce: 0.006539
2022-01-14 12:41:55,834 iteration 4010 : loss : 0.013050, loss_ce: 0.004842
2022-01-14 12:41:56,815 iteration 4011 : loss : 0.036513, loss_ce: 0.009573
2022-01-14 12:41:57,792 iteration 4012 : loss : 0.021868, loss_ce: 0.010121
 59%|█████████████████            | 236/400 [1:07:23<48:15, 17.66s/it]2022-01-14 12:41:58,768 iteration 4013 : loss : 0.020202, loss_ce: 0.004784
2022-01-14 12:41:59,726 iteration 4014 : loss : 0.023965, loss_ce: 0.007808
2022-01-14 12:42:00,629 iteration 4015 : loss : 0.019562, loss_ce: 0.009422
2022-01-14 12:42:01,593 iteration 4016 : loss : 0.024609, loss_ce: 0.008557
2022-01-14 12:42:02,466 iteration 4017 : loss : 0.026277, loss_ce: 0.011085
2022-01-14 12:42:03,485 iteration 4018 : loss : 0.019754, loss_ce: 0.006945
2022-01-14 12:42:04,491 iteration 4019 : loss : 0.028229, loss_ce: 0.017032
2022-01-14 12:42:05,409 iteration 4020 : loss : 0.027136, loss_ce: 0.008916
2022-01-14 12:42:06,352 iteration 4021 : loss : 0.024416, loss_ce: 0.010228
2022-01-14 12:42:07,282 iteration 4022 : loss : 0.028071, loss_ce: 0.007935
2022-01-14 12:42:08,240 iteration 4023 : loss : 0.022051, loss_ce: 0.010201
2022-01-14 12:42:09,197 iteration 4024 : loss : 0.031871, loss_ce: 0.011164
2022-01-14 12:42:10,117 iteration 4025 : loss : 0.021573, loss_ce: 0.008685
2022-01-14 12:42:11,036 iteration 4026 : loss : 0.021505, loss_ce: 0.010782
2022-01-14 12:42:11,949 iteration 4027 : loss : 0.019796, loss_ce: 0.008299
2022-01-14 12:42:12,875 iteration 4028 : loss : 0.017039, loss_ce: 0.004573
2022-01-14 12:42:13,819 iteration 4029 : loss : 0.026953, loss_ce: 0.011334
 59%|█████████████████▏           | 237/400 [1:07:39<46:38, 17.17s/it]2022-01-14 12:42:14,827 iteration 4030 : loss : 0.030399, loss_ce: 0.012811
2022-01-14 12:42:15,750 iteration 4031 : loss : 0.021591, loss_ce: 0.009479
2022-01-14 12:42:16,741 iteration 4032 : loss : 0.022195, loss_ce: 0.009352
2022-01-14 12:42:17,779 iteration 4033 : loss : 0.031478, loss_ce: 0.009372
2022-01-14 12:42:18,676 iteration 4034 : loss : 0.021004, loss_ce: 0.006566
2022-01-14 12:42:19,624 iteration 4035 : loss : 0.018540, loss_ce: 0.006250
2022-01-14 12:42:20,529 iteration 4036 : loss : 0.017432, loss_ce: 0.005930
2022-01-14 12:42:21,513 iteration 4037 : loss : 0.021426, loss_ce: 0.006994
2022-01-14 12:42:22,450 iteration 4038 : loss : 0.028532, loss_ce: 0.017852
2022-01-14 12:42:23,271 iteration 4039 : loss : 0.016295, loss_ce: 0.007682
2022-01-14 12:42:24,205 iteration 4040 : loss : 0.035266, loss_ce: 0.007937
2022-01-14 12:42:25,230 iteration 4041 : loss : 0.028533, loss_ce: 0.014562
2022-01-14 12:42:26,099 iteration 4042 : loss : 0.018315, loss_ce: 0.007681
2022-01-14 12:42:27,053 iteration 4043 : loss : 0.016725, loss_ce: 0.006164
2022-01-14 12:42:28,001 iteration 4044 : loss : 0.032231, loss_ce: 0.012717
2022-01-14 12:42:28,912 iteration 4045 : loss : 0.024175, loss_ce: 0.009493
2022-01-14 12:42:29,884 iteration 4046 : loss : 0.022978, loss_ce: 0.008331
 60%|█████████████████▎           | 238/400 [1:07:55<45:27, 16.84s/it]2022-01-14 12:42:30,811 iteration 4047 : loss : 0.017645, loss_ce: 0.007839
2022-01-14 12:42:31,730 iteration 4048 : loss : 0.016314, loss_ce: 0.005101
2022-01-14 12:42:32,765 iteration 4049 : loss : 0.023009, loss_ce: 0.008697
2022-01-14 12:42:33,715 iteration 4050 : loss : 0.023861, loss_ce: 0.007620
2022-01-14 12:42:34,673 iteration 4051 : loss : 0.015659, loss_ce: 0.005402
2022-01-14 12:42:35,600 iteration 4052 : loss : 0.021026, loss_ce: 0.006998
2022-01-14 12:42:36,511 iteration 4053 : loss : 0.020059, loss_ce: 0.009297
2022-01-14 12:42:37,400 iteration 4054 : loss : 0.019450, loss_ce: 0.006912
2022-01-14 12:42:38,442 iteration 4055 : loss : 0.026336, loss_ce: 0.008639
2022-01-14 12:42:39,397 iteration 4056 : loss : 0.022428, loss_ce: 0.008064
2022-01-14 12:42:40,403 iteration 4057 : loss : 0.024181, loss_ce: 0.010140
2022-01-14 12:42:41,253 iteration 4058 : loss : 0.020037, loss_ce: 0.010757
2022-01-14 12:42:42,253 iteration 4059 : loss : 0.027707, loss_ce: 0.014540
2022-01-14 12:42:43,216 iteration 4060 : loss : 0.028820, loss_ce: 0.011049
2022-01-14 12:42:44,139 iteration 4061 : loss : 0.032091, loss_ce: 0.007038
2022-01-14 12:42:45,047 iteration 4062 : loss : 0.025462, loss_ce: 0.011432
2022-01-14 12:42:46,111 iteration 4063 : loss : 0.068942, loss_ce: 0.025764
 60%|█████████████████▎           | 239/400 [1:08:12<44:41, 16.66s/it]2022-01-14 12:42:47,120 iteration 4064 : loss : 0.023215, loss_ce: 0.007960
2022-01-14 12:42:48,058 iteration 4065 : loss : 0.021473, loss_ce: 0.008513
2022-01-14 12:42:48,898 iteration 4066 : loss : 0.026488, loss_ce: 0.008184
2022-01-14 12:42:49,788 iteration 4067 : loss : 0.037810, loss_ce: 0.007779
2022-01-14 12:42:50,740 iteration 4068 : loss : 0.023575, loss_ce: 0.009569
2022-01-14 12:42:51,715 iteration 4069 : loss : 0.027796, loss_ce: 0.008504
2022-01-14 12:42:52,678 iteration 4070 : loss : 0.022909, loss_ce: 0.012397
2022-01-14 12:42:53,551 iteration 4071 : loss : 0.024644, loss_ce: 0.010577
2022-01-14 12:42:54,457 iteration 4072 : loss : 0.020680, loss_ce: 0.008133
2022-01-14 12:42:55,420 iteration 4073 : loss : 0.028561, loss_ce: 0.013129
2022-01-14 12:42:56,306 iteration 4074 : loss : 0.026554, loss_ce: 0.008959
2022-01-14 12:42:57,306 iteration 4075 : loss : 0.036582, loss_ce: 0.015566
2022-01-14 12:42:58,244 iteration 4076 : loss : 0.028759, loss_ce: 0.010237
2022-01-14 12:42:59,207 iteration 4077 : loss : 0.021751, loss_ce: 0.009325
2022-01-14 12:43:00,190 iteration 4078 : loss : 0.033678, loss_ce: 0.008562
2022-01-14 12:43:01,139 iteration 4079 : loss : 0.020997, loss_ce: 0.008013
2022-01-14 12:43:01,139 Training Data Eval:
2022-01-14 12:43:05,440   Average segmentation loss on training set: 0.0167
2022-01-14 12:43:05,441 Validation Data Eval:
2022-01-14 12:43:06,909   Average segmentation loss on validation set: 0.0888
2022-01-14 12:43:07,851 iteration 4080 : loss : 0.032790, loss_ce: 0.010732
 60%|█████████████████▍           | 240/400 [1:08:33<48:28, 18.18s/it]2022-01-14 12:43:08,814 iteration 4081 : loss : 0.026915, loss_ce: 0.012921
2022-01-14 12:43:09,835 iteration 4082 : loss : 0.028452, loss_ce: 0.011744
2022-01-14 12:43:10,681 iteration 4083 : loss : 0.026320, loss_ce: 0.013075
2022-01-14 12:43:11,571 iteration 4084 : loss : 0.024663, loss_ce: 0.008497
2022-01-14 12:43:12,483 iteration 4085 : loss : 0.039439, loss_ce: 0.011221
2022-01-14 12:43:13,384 iteration 4086 : loss : 0.026387, loss_ce: 0.008340
2022-01-14 12:43:14,319 iteration 4087 : loss : 0.036494, loss_ce: 0.009618
2022-01-14 12:43:15,264 iteration 4088 : loss : 0.021765, loss_ce: 0.009869
2022-01-14 12:43:16,200 iteration 4089 : loss : 0.039977, loss_ce: 0.015578
2022-01-14 12:43:17,149 iteration 4090 : loss : 0.025689, loss_ce: 0.011662
2022-01-14 12:43:18,136 iteration 4091 : loss : 0.027630, loss_ce: 0.008476
2022-01-14 12:43:19,020 iteration 4092 : loss : 0.026249, loss_ce: 0.007762
2022-01-14 12:43:19,902 iteration 4093 : loss : 0.019058, loss_ce: 0.008350
2022-01-14 12:43:20,911 iteration 4094 : loss : 0.028347, loss_ce: 0.008911
2022-01-14 12:43:21,850 iteration 4095 : loss : 0.024875, loss_ce: 0.007962
2022-01-14 12:43:22,800 iteration 4096 : loss : 0.022358, loss_ce: 0.008734
2022-01-14 12:43:23,787 iteration 4097 : loss : 0.034465, loss_ce: 0.014467
 60%|█████████████████▍           | 241/400 [1:08:49<46:23, 17.51s/it]2022-01-14 12:43:24,792 iteration 4098 : loss : 0.022534, loss_ce: 0.008492
2022-01-14 12:43:25,728 iteration 4099 : loss : 0.023631, loss_ce: 0.007778
2022-01-14 12:43:26,616 iteration 4100 : loss : 0.021038, loss_ce: 0.009315
2022-01-14 12:43:27,570 iteration 4101 : loss : 0.019392, loss_ce: 0.008584
2022-01-14 12:43:28,609 iteration 4102 : loss : 0.034587, loss_ce: 0.014352
2022-01-14 12:43:29,465 iteration 4103 : loss : 0.016419, loss_ce: 0.006653
2022-01-14 12:43:30,421 iteration 4104 : loss : 0.024065, loss_ce: 0.009176
2022-01-14 12:43:31,405 iteration 4105 : loss : 0.026800, loss_ce: 0.010064
2022-01-14 12:43:32,446 iteration 4106 : loss : 0.033941, loss_ce: 0.011323
2022-01-14 12:43:33,392 iteration 4107 : loss : 0.033826, loss_ce: 0.014474
2022-01-14 12:43:34,377 iteration 4108 : loss : 0.040813, loss_ce: 0.015951
2022-01-14 12:43:35,345 iteration 4109 : loss : 0.037545, loss_ce: 0.010104
2022-01-14 12:43:36,347 iteration 4110 : loss : 0.019761, loss_ce: 0.006183
2022-01-14 12:43:37,293 iteration 4111 : loss : 0.022498, loss_ce: 0.006698
2022-01-14 12:43:38,120 iteration 4112 : loss : 0.017185, loss_ce: 0.007229
2022-01-14 12:43:39,126 iteration 4113 : loss : 0.034265, loss_ce: 0.010354
2022-01-14 12:43:40,058 iteration 4114 : loss : 0.029886, loss_ce: 0.012109
 60%|█████████████████▌           | 242/400 [1:09:05<45:07, 17.14s/it]2022-01-14 12:43:41,053 iteration 4115 : loss : 0.023700, loss_ce: 0.006718
2022-01-14 12:43:41,952 iteration 4116 : loss : 0.024932, loss_ce: 0.011472
2022-01-14 12:43:42,831 iteration 4117 : loss : 0.019045, loss_ce: 0.009686
2022-01-14 12:43:43,747 iteration 4118 : loss : 0.036098, loss_ce: 0.009054
2022-01-14 12:43:44,571 iteration 4119 : loss : 0.017474, loss_ce: 0.006723
2022-01-14 12:43:45,591 iteration 4120 : loss : 0.018146, loss_ce: 0.005253
2022-01-14 12:43:46,532 iteration 4121 : loss : 0.020716, loss_ce: 0.008777
2022-01-14 12:43:47,508 iteration 4122 : loss : 0.030052, loss_ce: 0.012068
2022-01-14 12:43:48,483 iteration 4123 : loss : 0.032347, loss_ce: 0.014736
2022-01-14 12:43:49,326 iteration 4124 : loss : 0.018329, loss_ce: 0.007580
2022-01-14 12:43:50,284 iteration 4125 : loss : 0.026515, loss_ce: 0.008482
2022-01-14 12:43:51,337 iteration 4126 : loss : 0.034567, loss_ce: 0.018343
2022-01-14 12:43:52,355 iteration 4127 : loss : 0.029301, loss_ce: 0.014697
2022-01-14 12:43:53,241 iteration 4128 : loss : 0.019026, loss_ce: 0.008334
2022-01-14 12:43:54,301 iteration 4129 : loss : 0.039860, loss_ce: 0.011077
2022-01-14 12:43:55,278 iteration 4130 : loss : 0.024305, loss_ce: 0.008023
2022-01-14 12:43:56,210 iteration 4131 : loss : 0.024334, loss_ce: 0.011369
 61%|█████████████████▌           | 243/400 [1:09:22<44:03, 16.84s/it]2022-01-14 12:43:57,256 iteration 4132 : loss : 0.027637, loss_ce: 0.009519
2022-01-14 12:43:58,142 iteration 4133 : loss : 0.031681, loss_ce: 0.015628
2022-01-14 12:43:59,133 iteration 4134 : loss : 0.015854, loss_ce: 0.006675
2022-01-14 12:44:00,078 iteration 4135 : loss : 0.025738, loss_ce: 0.008325
2022-01-14 12:44:00,998 iteration 4136 : loss : 0.015679, loss_ce: 0.004784
2022-01-14 12:44:01,960 iteration 4137 : loss : 0.021063, loss_ce: 0.010230
2022-01-14 12:44:02,929 iteration 4138 : loss : 0.017745, loss_ce: 0.008951
2022-01-14 12:44:03,874 iteration 4139 : loss : 0.041234, loss_ce: 0.011701
2022-01-14 12:44:04,865 iteration 4140 : loss : 0.024642, loss_ce: 0.007953
2022-01-14 12:44:05,791 iteration 4141 : loss : 0.021206, loss_ce: 0.005238
2022-01-14 12:44:06,699 iteration 4142 : loss : 0.022860, loss_ce: 0.009798
2022-01-14 12:44:07,597 iteration 4143 : loss : 0.021691, loss_ce: 0.007641
2022-01-14 12:44:08,556 iteration 4144 : loss : 0.027133, loss_ce: 0.009692
2022-01-14 12:44:09,473 iteration 4145 : loss : 0.028830, loss_ce: 0.011635
2022-01-14 12:44:10,298 iteration 4146 : loss : 0.017459, loss_ce: 0.004488
2022-01-14 12:44:11,184 iteration 4147 : loss : 0.023709, loss_ce: 0.009925
2022-01-14 12:44:12,112 iteration 4148 : loss : 0.034184, loss_ce: 0.011742
 61%|█████████████████▋           | 244/400 [1:09:38<43:03, 16.56s/it]2022-01-14 12:44:13,114 iteration 4149 : loss : 0.022721, loss_ce: 0.009392
2022-01-14 12:44:14,034 iteration 4150 : loss : 0.019516, loss_ce: 0.007215
2022-01-14 12:44:14,933 iteration 4151 : loss : 0.018254, loss_ce: 0.007393
2022-01-14 12:44:15,950 iteration 4152 : loss : 0.025858, loss_ce: 0.010313
2022-01-14 12:44:16,931 iteration 4153 : loss : 0.032558, loss_ce: 0.013130
2022-01-14 12:44:17,785 iteration 4154 : loss : 0.016451, loss_ce: 0.006495
2022-01-14 12:44:18,675 iteration 4155 : loss : 0.020784, loss_ce: 0.008928
2022-01-14 12:44:19,592 iteration 4156 : loss : 0.021195, loss_ce: 0.007105
2022-01-14 12:44:20,535 iteration 4157 : loss : 0.019801, loss_ce: 0.007736
2022-01-14 12:44:21,426 iteration 4158 : loss : 0.017759, loss_ce: 0.006634
2022-01-14 12:44:22,412 iteration 4159 : loss : 0.019630, loss_ce: 0.008585
2022-01-14 12:44:23,340 iteration 4160 : loss : 0.019894, loss_ce: 0.007519
2022-01-14 12:44:24,251 iteration 4161 : loss : 0.024550, loss_ce: 0.008354
2022-01-14 12:44:25,214 iteration 4162 : loss : 0.020162, loss_ce: 0.006607
2022-01-14 12:44:26,165 iteration 4163 : loss : 0.021475, loss_ce: 0.007433
2022-01-14 12:44:27,077 iteration 4164 : loss : 0.020643, loss_ce: 0.005955
2022-01-14 12:44:27,078 Training Data Eval:
2022-01-14 12:44:31,373   Average segmentation loss on training set: 0.0135
2022-01-14 12:44:31,373 Validation Data Eval:
2022-01-14 12:44:32,831   Average segmentation loss on validation set: 0.0717
2022-01-14 12:44:33,780 iteration 4165 : loss : 0.029899, loss_ce: 0.010963
 61%|█████████████████▊           | 245/400 [1:09:59<46:44, 18.09s/it]2022-01-14 12:44:34,754 iteration 4166 : loss : 0.023410, loss_ce: 0.005578
2022-01-14 12:44:35,648 iteration 4167 : loss : 0.017518, loss_ce: 0.006994
2022-01-14 12:44:36,496 iteration 4168 : loss : 0.022371, loss_ce: 0.006837
2022-01-14 12:44:37,373 iteration 4169 : loss : 0.018952, loss_ce: 0.007937
2022-01-14 12:44:38,391 iteration 4170 : loss : 0.022438, loss_ce: 0.007505
2022-01-14 12:44:39,429 iteration 4171 : loss : 0.028175, loss_ce: 0.010646
2022-01-14 12:44:40,297 iteration 4172 : loss : 0.022101, loss_ce: 0.004438
2022-01-14 12:44:41,231 iteration 4173 : loss : 0.019689, loss_ce: 0.007291
2022-01-14 12:44:42,154 iteration 4174 : loss : 0.018900, loss_ce: 0.008303
2022-01-14 12:44:43,143 iteration 4175 : loss : 0.019570, loss_ce: 0.006700
2022-01-14 12:44:44,076 iteration 4176 : loss : 0.026075, loss_ce: 0.010178
2022-01-14 12:44:45,034 iteration 4177 : loss : 0.023445, loss_ce: 0.007693
2022-01-14 12:44:45,968 iteration 4178 : loss : 0.015910, loss_ce: 0.006708
2022-01-14 12:44:46,974 iteration 4179 : loss : 0.021028, loss_ce: 0.008536
2022-01-14 12:44:47,911 iteration 4180 : loss : 0.027464, loss_ce: 0.008496
2022-01-14 12:44:48,733 iteration 4181 : loss : 0.023946, loss_ce: 0.007595
2022-01-14 12:44:49,683 iteration 4182 : loss : 0.021056, loss_ce: 0.008639
 62%|█████████████████▊           | 246/400 [1:10:15<44:44, 17.43s/it]2022-01-14 12:44:50,682 iteration 4183 : loss : 0.017392, loss_ce: 0.005541
2022-01-14 12:44:51,609 iteration 4184 : loss : 0.020088, loss_ce: 0.007543
2022-01-14 12:44:52,538 iteration 4185 : loss : 0.022325, loss_ce: 0.007724
2022-01-14 12:44:53,419 iteration 4186 : loss : 0.017966, loss_ce: 0.006338
2022-01-14 12:44:54,420 iteration 4187 : loss : 0.024715, loss_ce: 0.008140
2022-01-14 12:44:55,408 iteration 4188 : loss : 0.021004, loss_ce: 0.009660
2022-01-14 12:44:56,374 iteration 4189 : loss : 0.017028, loss_ce: 0.004901
2022-01-14 12:44:57,374 iteration 4190 : loss : 0.024061, loss_ce: 0.008605
2022-01-14 12:44:58,291 iteration 4191 : loss : 0.020878, loss_ce: 0.005957
2022-01-14 12:44:59,228 iteration 4192 : loss : 0.016519, loss_ce: 0.004833
2022-01-14 12:45:00,148 iteration 4193 : loss : 0.016745, loss_ce: 0.005568
2022-01-14 12:45:01,121 iteration 4194 : loss : 0.021663, loss_ce: 0.008630
2022-01-14 12:45:02,201 iteration 4195 : loss : 0.037067, loss_ce: 0.011227
2022-01-14 12:45:03,098 iteration 4196 : loss : 0.014530, loss_ce: 0.007437
2022-01-14 12:45:04,099 iteration 4197 : loss : 0.017433, loss_ce: 0.005215
2022-01-14 12:45:05,064 iteration 4198 : loss : 0.022447, loss_ce: 0.009261
2022-01-14 12:45:05,928 iteration 4199 : loss : 0.023688, loss_ce: 0.012382
 62%|█████████████████▉           | 247/400 [1:10:31<43:33, 17.08s/it]2022-01-14 12:45:06,882 iteration 4200 : loss : 0.024439, loss_ce: 0.009315
2022-01-14 12:45:07,853 iteration 4201 : loss : 0.021098, loss_ce: 0.008135
2022-01-14 12:45:08,710 iteration 4202 : loss : 0.018703, loss_ce: 0.008350
2022-01-14 12:45:09,610 iteration 4203 : loss : 0.017431, loss_ce: 0.007701
2022-01-14 12:45:10,540 iteration 4204 : loss : 0.019631, loss_ce: 0.007343
2022-01-14 12:45:11,433 iteration 4205 : loss : 0.016796, loss_ce: 0.006062
2022-01-14 12:45:12,277 iteration 4206 : loss : 0.020886, loss_ce: 0.006700
2022-01-14 12:45:13,161 iteration 4207 : loss : 0.016801, loss_ce: 0.008072
2022-01-14 12:45:14,060 iteration 4208 : loss : 0.025158, loss_ce: 0.011584
2022-01-14 12:45:15,093 iteration 4209 : loss : 0.032832, loss_ce: 0.009769
2022-01-14 12:45:16,099 iteration 4210 : loss : 0.019702, loss_ce: 0.007644
2022-01-14 12:45:16,876 iteration 4211 : loss : 0.014012, loss_ce: 0.005448
2022-01-14 12:45:17,801 iteration 4212 : loss : 0.025944, loss_ce: 0.011583
2022-01-14 12:45:18,717 iteration 4213 : loss : 0.021729, loss_ce: 0.009829
2022-01-14 12:45:19,712 iteration 4214 : loss : 0.024344, loss_ce: 0.008013
2022-01-14 12:45:20,598 iteration 4215 : loss : 0.016431, loss_ce: 0.005871
2022-01-14 12:45:21,622 iteration 4216 : loss : 0.029955, loss_ce: 0.008764
 62%|█████████████████▉           | 248/400 [1:10:47<42:12, 16.66s/it]2022-01-14 12:45:22,704 iteration 4217 : loss : 0.016893, loss_ce: 0.007095
2022-01-14 12:45:23,560 iteration 4218 : loss : 0.016051, loss_ce: 0.008610
2022-01-14 12:45:24,417 iteration 4219 : loss : 0.019078, loss_ce: 0.007609
2022-01-14 12:45:25,475 iteration 4220 : loss : 0.034759, loss_ce: 0.012405
2022-01-14 12:45:26,431 iteration 4221 : loss : 0.019745, loss_ce: 0.006104
2022-01-14 12:45:27,409 iteration 4222 : loss : 0.018952, loss_ce: 0.007669
2022-01-14 12:45:28,346 iteration 4223 : loss : 0.024872, loss_ce: 0.008822
2022-01-14 12:45:29,270 iteration 4224 : loss : 0.020838, loss_ce: 0.006508
2022-01-14 12:45:30,184 iteration 4225 : loss : 0.021391, loss_ce: 0.007315
2022-01-14 12:45:31,101 iteration 4226 : loss : 0.015873, loss_ce: 0.004952
2022-01-14 12:45:32,145 iteration 4227 : loss : 0.026967, loss_ce: 0.008548
2022-01-14 12:45:33,083 iteration 4228 : loss : 0.020364, loss_ce: 0.007556
2022-01-14 12:45:34,062 iteration 4229 : loss : 0.017623, loss_ce: 0.006518
2022-01-14 12:45:35,003 iteration 4230 : loss : 0.033976, loss_ce: 0.018350
2022-01-14 12:45:35,899 iteration 4231 : loss : 0.019980, loss_ce: 0.006214
2022-01-14 12:45:36,812 iteration 4232 : loss : 0.023071, loss_ce: 0.009513
2022-01-14 12:45:37,736 iteration 4233 : loss : 0.021547, loss_ce: 0.009972
 62%|██████████████████           | 249/400 [1:11:03<41:31, 16.50s/it]2022-01-14 12:45:38,796 iteration 4234 : loss : 0.025928, loss_ce: 0.011334
2022-01-14 12:45:39,718 iteration 4235 : loss : 0.019235, loss_ce: 0.005623
2022-01-14 12:45:40,566 iteration 4236 : loss : 0.015774, loss_ce: 0.007035
2022-01-14 12:45:41,438 iteration 4237 : loss : 0.018633, loss_ce: 0.007649
2022-01-14 12:45:42,353 iteration 4238 : loss : 0.022426, loss_ce: 0.007202
2022-01-14 12:45:43,325 iteration 4239 : loss : 0.021617, loss_ce: 0.007856
2022-01-14 12:45:44,280 iteration 4240 : loss : 0.027095, loss_ce: 0.008702
2022-01-14 12:45:45,201 iteration 4241 : loss : 0.020700, loss_ce: 0.009261
2022-01-14 12:45:46,006 iteration 4242 : loss : 0.014802, loss_ce: 0.005623
2022-01-14 12:45:46,973 iteration 4243 : loss : 0.021659, loss_ce: 0.008215
2022-01-14 12:45:47,846 iteration 4244 : loss : 0.016791, loss_ce: 0.005112
2022-01-14 12:45:48,750 iteration 4245 : loss : 0.014976, loss_ce: 0.005347
2022-01-14 12:45:49,635 iteration 4246 : loss : 0.020086, loss_ce: 0.006930
2022-01-14 12:45:50,547 iteration 4247 : loss : 0.032052, loss_ce: 0.008989
2022-01-14 12:45:51,383 iteration 4248 : loss : 0.016934, loss_ce: 0.007081
2022-01-14 12:45:52,382 iteration 4249 : loss : 0.018094, loss_ce: 0.007219
2022-01-14 12:45:52,382 Training Data Eval:
2022-01-14 12:45:56,682   Average segmentation loss on training set: 0.0133
2022-01-14 12:45:56,682 Validation Data Eval:
2022-01-14 12:45:58,132   Average segmentation loss on validation set: 0.0770
2022-01-14 12:45:59,052 iteration 4250 : loss : 0.020840, loss_ce: 0.008002
 62%|██████████████████▏          | 250/400 [1:11:24<44:51, 17.94s/it]2022-01-14 12:46:00,059 iteration 4251 : loss : 0.017862, loss_ce: 0.005964
2022-01-14 12:46:00,990 iteration 4252 : loss : 0.021925, loss_ce: 0.005217
2022-01-14 12:46:01,952 iteration 4253 : loss : 0.014904, loss_ce: 0.006969
2022-01-14 12:46:02,913 iteration 4254 : loss : 0.024866, loss_ce: 0.008630
2022-01-14 12:46:03,870 iteration 4255 : loss : 0.024706, loss_ce: 0.006838
2022-01-14 12:46:04,756 iteration 4256 : loss : 0.019598, loss_ce: 0.006819
2022-01-14 12:46:05,687 iteration 4257 : loss : 0.022837, loss_ce: 0.010078
2022-01-14 12:46:06,686 iteration 4258 : loss : 0.019903, loss_ce: 0.009210
2022-01-14 12:46:07,519 iteration 4259 : loss : 0.015362, loss_ce: 0.005207
2022-01-14 12:46:08,466 iteration 4260 : loss : 0.022379, loss_ce: 0.006806
2022-01-14 12:46:09,324 iteration 4261 : loss : 0.013174, loss_ce: 0.004156
2022-01-14 12:46:10,237 iteration 4262 : loss : 0.017550, loss_ce: 0.007372
2022-01-14 12:46:11,221 iteration 4263 : loss : 0.019642, loss_ce: 0.006980
2022-01-14 12:46:12,132 iteration 4264 : loss : 0.025587, loss_ce: 0.011024
2022-01-14 12:46:12,929 iteration 4265 : loss : 0.015082, loss_ce: 0.006261
2022-01-14 12:46:13,876 iteration 4266 : loss : 0.021815, loss_ce: 0.006598
2022-01-14 12:46:14,851 iteration 4267 : loss : 0.020189, loss_ce: 0.007318
 63%|██████████████████▏          | 251/400 [1:11:40<42:57, 17.30s/it]2022-01-14 12:46:15,765 iteration 4268 : loss : 0.017684, loss_ce: 0.006981
2022-01-14 12:46:16,610 iteration 4269 : loss : 0.014752, loss_ce: 0.004245
2022-01-14 12:46:17,510 iteration 4270 : loss : 0.023502, loss_ce: 0.007026
2022-01-14 12:46:18,393 iteration 4271 : loss : 0.022842, loss_ce: 0.007964
2022-01-14 12:46:19,298 iteration 4272 : loss : 0.021577, loss_ce: 0.008898
2022-01-14 12:46:20,187 iteration 4273 : loss : 0.018394, loss_ce: 0.008541
2022-01-14 12:46:21,117 iteration 4274 : loss : 0.018646, loss_ce: 0.008173
2022-01-14 12:46:22,013 iteration 4275 : loss : 0.016088, loss_ce: 0.006205
2022-01-14 12:46:22,915 iteration 4276 : loss : 0.020400, loss_ce: 0.006884
2022-01-14 12:46:23,845 iteration 4277 : loss : 0.017989, loss_ce: 0.007990
2022-01-14 12:46:24,756 iteration 4278 : loss : 0.011458, loss_ce: 0.002623
2022-01-14 12:46:25,627 iteration 4279 : loss : 0.017858, loss_ce: 0.007285
2022-01-14 12:46:26,535 iteration 4280 : loss : 0.016100, loss_ce: 0.004248
2022-01-14 12:46:27,465 iteration 4281 : loss : 0.031381, loss_ce: 0.013493
2022-01-14 12:46:28,422 iteration 4282 : loss : 0.028847, loss_ce: 0.009244
2022-01-14 12:46:29,431 iteration 4283 : loss : 0.020288, loss_ce: 0.008931
2022-01-14 12:46:30,451 iteration 4284 : loss : 0.022806, loss_ce: 0.008676
 63%|██████████████████▎          | 252/400 [1:11:56<41:25, 16.79s/it]2022-01-14 12:46:31,380 iteration 4285 : loss : 0.018083, loss_ce: 0.008572
2022-01-14 12:46:32,259 iteration 4286 : loss : 0.018713, loss_ce: 0.006812
2022-01-14 12:46:33,270 iteration 4287 : loss : 0.025183, loss_ce: 0.009434
2022-01-14 12:46:34,145 iteration 4288 : loss : 0.014595, loss_ce: 0.004317
2022-01-14 12:46:35,018 iteration 4289 : loss : 0.018712, loss_ce: 0.008229
2022-01-14 12:46:35,940 iteration 4290 : loss : 0.020345, loss_ce: 0.008712
2022-01-14 12:46:36,933 iteration 4291 : loss : 0.023687, loss_ce: 0.010745
2022-01-14 12:46:37,902 iteration 4292 : loss : 0.023894, loss_ce: 0.014743
2022-01-14 12:46:38,727 iteration 4293 : loss : 0.033146, loss_ce: 0.011135
2022-01-14 12:46:39,608 iteration 4294 : loss : 0.018361, loss_ce: 0.008303
2022-01-14 12:46:40,684 iteration 4295 : loss : 0.025271, loss_ce: 0.009147
2022-01-14 12:46:41,589 iteration 4296 : loss : 0.016025, loss_ce: 0.005547
2022-01-14 12:46:42,456 iteration 4297 : loss : 0.015409, loss_ce: 0.004519
2022-01-14 12:46:43,452 iteration 4298 : loss : 0.015725, loss_ce: 0.004514
2022-01-14 12:46:44,389 iteration 4299 : loss : 0.026768, loss_ce: 0.008067
2022-01-14 12:46:45,421 iteration 4300 : loss : 0.019224, loss_ce: 0.006614
2022-01-14 12:46:46,332 iteration 4301 : loss : 0.027503, loss_ce: 0.010610
 63%|██████████████████▎          | 253/400 [1:12:12<40:27, 16.52s/it]2022-01-14 12:46:47,389 iteration 4302 : loss : 0.019167, loss_ce: 0.007614
2022-01-14 12:46:48,245 iteration 4303 : loss : 0.018462, loss_ce: 0.010108
2022-01-14 12:46:49,161 iteration 4304 : loss : 0.023324, loss_ce: 0.011673
2022-01-14 12:46:50,094 iteration 4305 : loss : 0.020698, loss_ce: 0.005904
2022-01-14 12:46:51,017 iteration 4306 : loss : 0.021335, loss_ce: 0.008497
2022-01-14 12:46:52,021 iteration 4307 : loss : 0.020953, loss_ce: 0.007969
2022-01-14 12:46:52,935 iteration 4308 : loss : 0.019891, loss_ce: 0.007138
2022-01-14 12:46:53,933 iteration 4309 : loss : 0.026321, loss_ce: 0.008340
2022-01-14 12:46:54,796 iteration 4310 : loss : 0.015937, loss_ce: 0.005350
2022-01-14 12:46:55,789 iteration 4311 : loss : 0.033716, loss_ce: 0.015076
2022-01-14 12:46:56,704 iteration 4312 : loss : 0.016927, loss_ce: 0.007688
2022-01-14 12:46:57,689 iteration 4313 : loss : 0.017177, loss_ce: 0.007423
2022-01-14 12:46:58,638 iteration 4314 : loss : 0.022023, loss_ce: 0.007194
2022-01-14 12:46:59,535 iteration 4315 : loss : 0.022440, loss_ce: 0.007676
2022-01-14 12:47:00,436 iteration 4316 : loss : 0.022693, loss_ce: 0.009011
2022-01-14 12:47:01,372 iteration 4317 : loss : 0.016968, loss_ce: 0.007189
2022-01-14 12:47:02,423 iteration 4318 : loss : 0.016690, loss_ce: 0.005832
 64%|██████████████████▍          | 254/400 [1:12:28<39:53, 16.39s/it]2022-01-14 12:47:03,393 iteration 4319 : loss : 0.018411, loss_ce: 0.007068
2022-01-14 12:47:04,216 iteration 4320 : loss : 0.015537, loss_ce: 0.005988
2022-01-14 12:47:05,305 iteration 4321 : loss : 0.023262, loss_ce: 0.010380
2022-01-14 12:47:06,226 iteration 4322 : loss : 0.021508, loss_ce: 0.007978
2022-01-14 12:47:07,150 iteration 4323 : loss : 0.018075, loss_ce: 0.005945
2022-01-14 12:47:08,055 iteration 4324 : loss : 0.015274, loss_ce: 0.006207
2022-01-14 12:47:08,933 iteration 4325 : loss : 0.024201, loss_ce: 0.006486
2022-01-14 12:47:09,908 iteration 4326 : loss : 0.033789, loss_ce: 0.013082
2022-01-14 12:47:10,925 iteration 4327 : loss : 0.019349, loss_ce: 0.008651
2022-01-14 12:47:11,887 iteration 4328 : loss : 0.017782, loss_ce: 0.008214
2022-01-14 12:47:12,789 iteration 4329 : loss : 0.017132, loss_ce: 0.006313
2022-01-14 12:47:13,642 iteration 4330 : loss : 0.017028, loss_ce: 0.007084
2022-01-14 12:47:14,541 iteration 4331 : loss : 0.017893, loss_ce: 0.006664
2022-01-14 12:47:15,401 iteration 4332 : loss : 0.017166, loss_ce: 0.006590
2022-01-14 12:47:16,218 iteration 4333 : loss : 0.015293, loss_ce: 0.005957
2022-01-14 12:47:17,160 iteration 4334 : loss : 0.030485, loss_ce: 0.009887
2022-01-14 12:47:17,160 Training Data Eval:
2022-01-14 12:47:21,449   Average segmentation loss on training set: 0.0122
2022-01-14 12:47:21,449 Validation Data Eval:
2022-01-14 12:47:22,917   Average segmentation loss on validation set: 0.0620
2022-01-14 12:47:23,879 iteration 4335 : loss : 0.027246, loss_ce: 0.005660
 64%|██████████████████▍          | 255/400 [1:12:49<43:16, 17.91s/it]2022-01-14 12:47:24,781 iteration 4336 : loss : 0.018024, loss_ce: 0.007358
2022-01-14 12:47:25,755 iteration 4337 : loss : 0.023940, loss_ce: 0.009813
2022-01-14 12:47:26,714 iteration 4338 : loss : 0.024544, loss_ce: 0.009470
2022-01-14 12:47:27,564 iteration 4339 : loss : 0.021331, loss_ce: 0.005096
2022-01-14 12:47:28,526 iteration 4340 : loss : 0.029379, loss_ce: 0.005115
2022-01-14 12:47:29,439 iteration 4341 : loss : 0.018569, loss_ce: 0.008072
2022-01-14 12:47:30,338 iteration 4342 : loss : 0.016839, loss_ce: 0.006219
2022-01-14 12:47:31,343 iteration 4343 : loss : 0.026782, loss_ce: 0.007920
2022-01-14 12:47:32,239 iteration 4344 : loss : 0.022745, loss_ce: 0.009458
2022-01-14 12:47:33,119 iteration 4345 : loss : 0.017991, loss_ce: 0.007232
2022-01-14 12:47:33,929 iteration 4346 : loss : 0.013665, loss_ce: 0.004397
2022-01-14 12:47:34,914 iteration 4347 : loss : 0.022881, loss_ce: 0.006966
2022-01-14 12:47:35,866 iteration 4348 : loss : 0.020144, loss_ce: 0.009784
2022-01-14 12:47:36,726 iteration 4349 : loss : 0.018435, loss_ce: 0.007949
2022-01-14 12:47:37,578 iteration 4350 : loss : 0.020374, loss_ce: 0.006690
2022-01-14 12:47:38,567 iteration 4351 : loss : 0.017388, loss_ce: 0.007595
2022-01-14 12:47:39,514 iteration 4352 : loss : 0.025772, loss_ce: 0.009343
 64%|██████████████████▌          | 256/400 [1:13:05<41:20, 17.23s/it]2022-01-14 12:47:40,460 iteration 4353 : loss : 0.014681, loss_ce: 0.005688
2022-01-14 12:47:41,445 iteration 4354 : loss : 0.019047, loss_ce: 0.005572
2022-01-14 12:47:42,413 iteration 4355 : loss : 0.013947, loss_ce: 0.004582
2022-01-14 12:47:43,299 iteration 4356 : loss : 0.018785, loss_ce: 0.006590
2022-01-14 12:47:44,309 iteration 4357 : loss : 0.026739, loss_ce: 0.009914
2022-01-14 12:47:45,203 iteration 4358 : loss : 0.019682, loss_ce: 0.008484
2022-01-14 12:47:46,163 iteration 4359 : loss : 0.021994, loss_ce: 0.006241
2022-01-14 12:47:47,021 iteration 4360 : loss : 0.015833, loss_ce: 0.006091
2022-01-14 12:47:47,985 iteration 4361 : loss : 0.024413, loss_ce: 0.009128
2022-01-14 12:47:48,849 iteration 4362 : loss : 0.016654, loss_ce: 0.005394
2022-01-14 12:47:49,782 iteration 4363 : loss : 0.022411, loss_ce: 0.009451
2022-01-14 12:47:50,708 iteration 4364 : loss : 0.018138, loss_ce: 0.007312
2022-01-14 12:47:51,694 iteration 4365 : loss : 0.019615, loss_ce: 0.006225
2022-01-14 12:47:52,579 iteration 4366 : loss : 0.019072, loss_ce: 0.007000
2022-01-14 12:47:53,427 iteration 4367 : loss : 0.031061, loss_ce: 0.015494
2022-01-14 12:47:54,313 iteration 4368 : loss : 0.012093, loss_ce: 0.004298
2022-01-14 12:47:55,285 iteration 4369 : loss : 0.018649, loss_ce: 0.006940
 64%|██████████████████▋          | 257/400 [1:13:21<40:00, 16.79s/it]2022-01-14 12:47:56,227 iteration 4370 : loss : 0.018612, loss_ce: 0.006695
2022-01-14 12:47:57,343 iteration 4371 : loss : 0.030280, loss_ce: 0.010518
2022-01-14 12:47:58,318 iteration 4372 : loss : 0.031233, loss_ce: 0.008646
2022-01-14 12:47:59,289 iteration 4373 : loss : 0.021015, loss_ce: 0.006869
2022-01-14 12:48:00,191 iteration 4374 : loss : 0.030532, loss_ce: 0.012591
2022-01-14 12:48:01,126 iteration 4375 : loss : 0.015621, loss_ce: 0.006213
2022-01-14 12:48:02,084 iteration 4376 : loss : 0.029247, loss_ce: 0.010305
2022-01-14 12:48:02,966 iteration 4377 : loss : 0.021298, loss_ce: 0.008801
2022-01-14 12:48:03,939 iteration 4378 : loss : 0.023698, loss_ce: 0.009981
2022-01-14 12:48:04,824 iteration 4379 : loss : 0.026174, loss_ce: 0.009971
2022-01-14 12:48:05,758 iteration 4380 : loss : 0.017642, loss_ce: 0.005952
2022-01-14 12:48:06,697 iteration 4381 : loss : 0.028112, loss_ce: 0.007309
2022-01-14 12:48:07,756 iteration 4382 : loss : 0.031861, loss_ce: 0.011331
2022-01-14 12:48:08,687 iteration 4383 : loss : 0.020297, loss_ce: 0.006891
2022-01-14 12:48:09,668 iteration 4384 : loss : 0.019459, loss_ce: 0.006611
2022-01-14 12:48:10,667 iteration 4385 : loss : 0.025537, loss_ce: 0.011340
2022-01-14 12:48:11,573 iteration 4386 : loss : 0.019807, loss_ce: 0.005324
 64%|██████████████████▋          | 258/400 [1:13:37<39:22, 16.64s/it]2022-01-14 12:48:12,599 iteration 4387 : loss : 0.046087, loss_ce: 0.009309
2022-01-14 12:48:13,550 iteration 4388 : loss : 0.027284, loss_ce: 0.013592
2022-01-14 12:48:14,494 iteration 4389 : loss : 0.022525, loss_ce: 0.009417
2022-01-14 12:48:15,454 iteration 4390 : loss : 0.024569, loss_ce: 0.009498
2022-01-14 12:48:16,482 iteration 4391 : loss : 0.063354, loss_ce: 0.024153
2022-01-14 12:48:17,432 iteration 4392 : loss : 0.019452, loss_ce: 0.008334
2022-01-14 12:48:18,477 iteration 4393 : loss : 0.035393, loss_ce: 0.017293
2022-01-14 12:48:19,324 iteration 4394 : loss : 0.018514, loss_ce: 0.006633
2022-01-14 12:48:20,265 iteration 4395 : loss : 0.024284, loss_ce: 0.012318
2022-01-14 12:48:21,185 iteration 4396 : loss : 0.030893, loss_ce: 0.011644
2022-01-14 12:48:22,049 iteration 4397 : loss : 0.021403, loss_ce: 0.008618
2022-01-14 12:48:22,969 iteration 4398 : loss : 0.022637, loss_ce: 0.009475
2022-01-14 12:48:23,916 iteration 4399 : loss : 0.030770, loss_ce: 0.007931
2022-01-14 12:48:24,789 iteration 4400 : loss : 0.020008, loss_ce: 0.006498
2022-01-14 12:48:25,758 iteration 4401 : loss : 0.024668, loss_ce: 0.012222
2022-01-14 12:48:26,597 iteration 4402 : loss : 0.022815, loss_ce: 0.007103
2022-01-14 12:48:27,537 iteration 4403 : loss : 0.022735, loss_ce: 0.007017
 65%|██████████████████▊          | 259/400 [1:13:53<38:37, 16.44s/it]2022-01-14 12:48:28,599 iteration 4404 : loss : 0.026171, loss_ce: 0.011744
2022-01-14 12:48:29,538 iteration 4405 : loss : 0.020848, loss_ce: 0.007100
2022-01-14 12:48:30,494 iteration 4406 : loss : 0.026015, loss_ce: 0.012662
2022-01-14 12:48:31,445 iteration 4407 : loss : 0.027406, loss_ce: 0.006676
2022-01-14 12:48:32,338 iteration 4408 : loss : 0.019339, loss_ce: 0.008971
2022-01-14 12:48:33,192 iteration 4409 : loss : 0.032845, loss_ce: 0.013301
2022-01-14 12:48:34,229 iteration 4410 : loss : 0.021386, loss_ce: 0.006717
2022-01-14 12:48:35,187 iteration 4411 : loss : 0.023068, loss_ce: 0.008243
2022-01-14 12:48:36,154 iteration 4412 : loss : 0.021651, loss_ce: 0.007524
2022-01-14 12:48:37,112 iteration 4413 : loss : 0.016772, loss_ce: 0.006994
2022-01-14 12:48:38,006 iteration 4414 : loss : 0.025545, loss_ce: 0.007795
2022-01-14 12:48:38,868 iteration 4415 : loss : 0.015575, loss_ce: 0.006832
2022-01-14 12:48:39,816 iteration 4416 : loss : 0.031346, loss_ce: 0.011927
2022-01-14 12:48:40,754 iteration 4417 : loss : 0.018212, loss_ce: 0.007757
2022-01-14 12:48:41,696 iteration 4418 : loss : 0.019006, loss_ce: 0.007927
2022-01-14 12:48:42,606 iteration 4419 : loss : 0.017714, loss_ce: 0.006782
2022-01-14 12:48:42,606 Training Data Eval:
2022-01-14 12:48:46,899   Average segmentation loss on training set: 0.0133
2022-01-14 12:48:46,899 Validation Data Eval:
2022-01-14 12:48:48,355   Average segmentation loss on validation set: 0.0679
2022-01-14 12:48:49,247 iteration 4420 : loss : 0.015885, loss_ce: 0.004516
 65%|██████████████████▊          | 260/400 [1:14:15<42:02, 18.02s/it]2022-01-14 12:48:50,231 iteration 4421 : loss : 0.019804, loss_ce: 0.005645
2022-01-14 12:48:51,135 iteration 4422 : loss : 0.017238, loss_ce: 0.005821
2022-01-14 12:48:52,031 iteration 4423 : loss : 0.023728, loss_ce: 0.011196
2022-01-14 12:48:53,015 iteration 4424 : loss : 0.021956, loss_ce: 0.008181
2022-01-14 12:48:53,930 iteration 4425 : loss : 0.022881, loss_ce: 0.007552
2022-01-14 12:48:54,838 iteration 4426 : loss : 0.025230, loss_ce: 0.007598
2022-01-14 12:48:55,782 iteration 4427 : loss : 0.020645, loss_ce: 0.009199
2022-01-14 12:48:56,738 iteration 4428 : loss : 0.026490, loss_ce: 0.013660
2022-01-14 12:48:57,545 iteration 4429 : loss : 0.021943, loss_ce: 0.009937
2022-01-14 12:48:58,488 iteration 4430 : loss : 0.022257, loss_ce: 0.010232
2022-01-14 12:48:59,433 iteration 4431 : loss : 0.021792, loss_ce: 0.006988
2022-01-14 12:49:00,432 iteration 4432 : loss : 0.026736, loss_ce: 0.015534
2022-01-14 12:49:01,388 iteration 4433 : loss : 0.019036, loss_ce: 0.004821
2022-01-14 12:49:02,337 iteration 4434 : loss : 0.022861, loss_ce: 0.008354
2022-01-14 12:49:03,215 iteration 4435 : loss : 0.016628, loss_ce: 0.005129
2022-01-14 12:49:04,111 iteration 4436 : loss : 0.024496, loss_ce: 0.012044
2022-01-14 12:49:05,017 iteration 4437 : loss : 0.015578, loss_ce: 0.005245
 65%|██████████████████▉          | 261/400 [1:14:30<40:11, 17.35s/it]2022-01-14 12:49:06,073 iteration 4438 : loss : 0.022100, loss_ce: 0.008217
2022-01-14 12:49:06,926 iteration 4439 : loss : 0.015754, loss_ce: 0.006892
2022-01-14 12:49:07,923 iteration 4440 : loss : 0.021561, loss_ce: 0.010540
2022-01-14 12:49:08,864 iteration 4441 : loss : 0.018379, loss_ce: 0.007684
2022-01-14 12:49:09,924 iteration 4442 : loss : 0.024090, loss_ce: 0.009718
2022-01-14 12:49:10,949 iteration 4443 : loss : 0.025783, loss_ce: 0.011591
2022-01-14 12:49:11,918 iteration 4444 : loss : 0.021288, loss_ce: 0.007682
2022-01-14 12:49:12,827 iteration 4445 : loss : 0.021335, loss_ce: 0.007282
2022-01-14 12:49:13,823 iteration 4446 : loss : 0.047740, loss_ce: 0.010320
2022-01-14 12:49:14,855 iteration 4447 : loss : 0.020368, loss_ce: 0.006229
2022-01-14 12:49:15,769 iteration 4448 : loss : 0.025995, loss_ce: 0.008317
2022-01-14 12:49:16,793 iteration 4449 : loss : 0.029910, loss_ce: 0.013696
2022-01-14 12:49:17,711 iteration 4450 : loss : 0.018175, loss_ce: 0.009238
2022-01-14 12:49:18,660 iteration 4451 : loss : 0.026195, loss_ce: 0.009486
2022-01-14 12:49:19,547 iteration 4452 : loss : 0.022546, loss_ce: 0.005928
2022-01-14 12:49:20,411 iteration 4453 : loss : 0.019480, loss_ce: 0.008660
2022-01-14 12:49:21,317 iteration 4454 : loss : 0.022852, loss_ce: 0.009569
 66%|██████████████████▉          | 262/400 [1:14:47<39:09, 17.03s/it]2022-01-14 12:49:22,255 iteration 4455 : loss : 0.028642, loss_ce: 0.009216
2022-01-14 12:49:23,106 iteration 4456 : loss : 0.025702, loss_ce: 0.007937
2022-01-14 12:49:23,999 iteration 4457 : loss : 0.017462, loss_ce: 0.006842
2022-01-14 12:49:24,884 iteration 4458 : loss : 0.019672, loss_ce: 0.008769
2022-01-14 12:49:25,832 iteration 4459 : loss : 0.046135, loss_ce: 0.011234
2022-01-14 12:49:26,710 iteration 4460 : loss : 0.015425, loss_ce: 0.006195
2022-01-14 12:49:27,593 iteration 4461 : loss : 0.017225, loss_ce: 0.007599
2022-01-14 12:49:28,610 iteration 4462 : loss : 0.028296, loss_ce: 0.009790
2022-01-14 12:49:29,463 iteration 4463 : loss : 0.018180, loss_ce: 0.006731
2022-01-14 12:49:30,368 iteration 4464 : loss : 0.017630, loss_ce: 0.008118
2022-01-14 12:49:31,427 iteration 4465 : loss : 0.035728, loss_ce: 0.007868
2022-01-14 12:49:32,271 iteration 4466 : loss : 0.015878, loss_ce: 0.005745
2022-01-14 12:49:33,222 iteration 4467 : loss : 0.025036, loss_ce: 0.011071
2022-01-14 12:49:34,124 iteration 4468 : loss : 0.022365, loss_ce: 0.007440
2022-01-14 12:49:35,039 iteration 4469 : loss : 0.017280, loss_ce: 0.004728
2022-01-14 12:49:35,943 iteration 4470 : loss : 0.021977, loss_ce: 0.009495
2022-01-14 12:49:36,937 iteration 4471 : loss : 0.036391, loss_ce: 0.008458
 66%|███████████████████          | 263/400 [1:15:02<37:55, 16.61s/it]2022-01-14 12:49:37,884 iteration 4472 : loss : 0.021790, loss_ce: 0.009025
2022-01-14 12:49:38,851 iteration 4473 : loss : 0.024276, loss_ce: 0.008957
2022-01-14 12:49:39,861 iteration 4474 : loss : 0.026377, loss_ce: 0.012414
2022-01-14 12:49:40,824 iteration 4475 : loss : 0.019709, loss_ce: 0.008048
2022-01-14 12:49:41,729 iteration 4476 : loss : 0.021319, loss_ce: 0.007006
2022-01-14 12:49:42,635 iteration 4477 : loss : 0.042537, loss_ce: 0.023067
2022-01-14 12:49:43,657 iteration 4478 : loss : 0.024658, loss_ce: 0.012457
2022-01-14 12:49:44,573 iteration 4479 : loss : 0.020544, loss_ce: 0.010283
2022-01-14 12:49:45,424 iteration 4480 : loss : 0.016803, loss_ce: 0.006163
2022-01-14 12:49:46,406 iteration 4481 : loss : 0.026806, loss_ce: 0.005689
2022-01-14 12:49:47,346 iteration 4482 : loss : 0.017893, loss_ce: 0.005664
2022-01-14 12:49:48,224 iteration 4483 : loss : 0.018406, loss_ce: 0.005577
2022-01-14 12:49:49,255 iteration 4484 : loss : 0.020525, loss_ce: 0.006797
2022-01-14 12:49:50,261 iteration 4485 : loss : 0.026692, loss_ce: 0.013396
2022-01-14 12:49:51,257 iteration 4486 : loss : 0.020225, loss_ce: 0.006906
2022-01-14 12:49:52,141 iteration 4487 : loss : 0.018174, loss_ce: 0.004660
2022-01-14 12:49:53,051 iteration 4488 : loss : 0.023724, loss_ce: 0.008936
 66%|███████████████████▏         | 264/400 [1:15:18<37:18, 16.46s/it]2022-01-14 12:49:54,071 iteration 4489 : loss : 0.023125, loss_ce: 0.009823
2022-01-14 12:49:54,944 iteration 4490 : loss : 0.016371, loss_ce: 0.009012
2022-01-14 12:49:55,902 iteration 4491 : loss : 0.028363, loss_ce: 0.010302
2022-01-14 12:49:56,931 iteration 4492 : loss : 0.018211, loss_ce: 0.008364
2022-01-14 12:49:57,841 iteration 4493 : loss : 0.024730, loss_ce: 0.009263
2022-01-14 12:49:58,775 iteration 4494 : loss : 0.017782, loss_ce: 0.005312
2022-01-14 12:49:59,717 iteration 4495 : loss : 0.022583, loss_ce: 0.008093
2022-01-14 12:50:00,591 iteration 4496 : loss : 0.021144, loss_ce: 0.010994
2022-01-14 12:50:01,590 iteration 4497 : loss : 0.019766, loss_ce: 0.008249
2022-01-14 12:50:02,505 iteration 4498 : loss : 0.023271, loss_ce: 0.007026
2022-01-14 12:50:03,476 iteration 4499 : loss : 0.037371, loss_ce: 0.015602
2022-01-14 12:50:04,341 iteration 4500 : loss : 0.013171, loss_ce: 0.004278
2022-01-14 12:50:05,206 iteration 4501 : loss : 0.021676, loss_ce: 0.006998
2022-01-14 12:50:06,096 iteration 4502 : loss : 0.027748, loss_ce: 0.007639
2022-01-14 12:50:07,075 iteration 4503 : loss : 0.020863, loss_ce: 0.008583
2022-01-14 12:50:07,995 iteration 4504 : loss : 0.018065, loss_ce: 0.006569
2022-01-14 12:50:07,995 Training Data Eval:
2022-01-14 12:50:12,286   Average segmentation loss on training set: 0.0121
2022-01-14 12:50:12,286 Validation Data Eval:
2022-01-14 12:50:13,741   Average segmentation loss on validation set: 0.0683
2022-01-14 12:50:14,692 iteration 4505 : loss : 0.018605, loss_ce: 0.007175
 66%|███████████████████▏         | 265/400 [1:15:40<40:31, 18.01s/it]2022-01-14 12:50:15,650 iteration 4506 : loss : 0.032512, loss_ce: 0.014432
2022-01-14 12:50:16,593 iteration 4507 : loss : 0.014144, loss_ce: 0.006074
2022-01-14 12:50:17,496 iteration 4508 : loss : 0.015363, loss_ce: 0.005220
2022-01-14 12:50:18,381 iteration 4509 : loss : 0.026424, loss_ce: 0.005806
2022-01-14 12:50:19,402 iteration 4510 : loss : 0.024853, loss_ce: 0.008178
2022-01-14 12:50:20,324 iteration 4511 : loss : 0.017736, loss_ce: 0.004970
2022-01-14 12:50:21,316 iteration 4512 : loss : 0.019804, loss_ce: 0.009707
2022-01-14 12:50:22,362 iteration 4513 : loss : 0.035243, loss_ce: 0.011293
2022-01-14 12:50:23,193 iteration 4514 : loss : 0.020923, loss_ce: 0.006928
2022-01-14 12:50:24,098 iteration 4515 : loss : 0.037995, loss_ce: 0.013892
2022-01-14 12:50:24,958 iteration 4516 : loss : 0.015633, loss_ce: 0.006155
2022-01-14 12:50:25,812 iteration 4517 : loss : 0.015948, loss_ce: 0.005876
2022-01-14 12:50:26,768 iteration 4518 : loss : 0.022656, loss_ce: 0.006952
2022-01-14 12:50:27,598 iteration 4519 : loss : 0.014554, loss_ce: 0.005068
2022-01-14 12:50:28,534 iteration 4520 : loss : 0.034214, loss_ce: 0.015075
2022-01-14 12:50:29,428 iteration 4521 : loss : 0.020707, loss_ce: 0.008082
2022-01-14 12:50:30,360 iteration 4522 : loss : 0.023460, loss_ce: 0.010301
 66%|███████████████████▎         | 266/400 [1:15:56<38:40, 17.31s/it]2022-01-14 12:50:31,450 iteration 4523 : loss : 0.017251, loss_ce: 0.006950
2022-01-14 12:50:32,342 iteration 4524 : loss : 0.022258, loss_ce: 0.009153
2022-01-14 12:50:33,187 iteration 4525 : loss : 0.014710, loss_ce: 0.007123
2022-01-14 12:50:34,081 iteration 4526 : loss : 0.020907, loss_ce: 0.005769
2022-01-14 12:50:34,957 iteration 4527 : loss : 0.014674, loss_ce: 0.006042
2022-01-14 12:50:35,895 iteration 4528 : loss : 0.018414, loss_ce: 0.007903
2022-01-14 12:50:36,747 iteration 4529 : loss : 0.024496, loss_ce: 0.008716
2022-01-14 12:50:37,668 iteration 4530 : loss : 0.023249, loss_ce: 0.009458
2022-01-14 12:50:38,708 iteration 4531 : loss : 0.026163, loss_ce: 0.007629
2022-01-14 12:50:39,550 iteration 4532 : loss : 0.013463, loss_ce: 0.004854
2022-01-14 12:50:40,638 iteration 4533 : loss : 0.031504, loss_ce: 0.013173
2022-01-14 12:50:41,519 iteration 4534 : loss : 0.015374, loss_ce: 0.006988
2022-01-14 12:50:42,459 iteration 4535 : loss : 0.052718, loss_ce: 0.033501
2022-01-14 12:50:43,397 iteration 4536 : loss : 0.018063, loss_ce: 0.004740
2022-01-14 12:50:44,287 iteration 4537 : loss : 0.019303, loss_ce: 0.005866
2022-01-14 12:50:45,195 iteration 4538 : loss : 0.022666, loss_ce: 0.011006
2022-01-14 12:50:46,010 iteration 4539 : loss : 0.015725, loss_ce: 0.006021
 67%|███████████████████▎         | 267/400 [1:16:11<37:16, 16.81s/it]2022-01-14 12:50:46,934 iteration 4540 : loss : 0.018791, loss_ce: 0.009560
2022-01-14 12:50:47,855 iteration 4541 : loss : 0.034355, loss_ce: 0.014144
2022-01-14 12:50:48,779 iteration 4542 : loss : 0.027107, loss_ce: 0.008550
2022-01-14 12:50:49,854 iteration 4543 : loss : 0.026197, loss_ce: 0.010445
2022-01-14 12:50:50,725 iteration 4544 : loss : 0.022632, loss_ce: 0.009959
2022-01-14 12:50:51,592 iteration 4545 : loss : 0.015564, loss_ce: 0.006184
2022-01-14 12:50:52,499 iteration 4546 : loss : 0.029688, loss_ce: 0.011395
2022-01-14 12:50:53,419 iteration 4547 : loss : 0.021595, loss_ce: 0.007875
2022-01-14 12:50:54,320 iteration 4548 : loss : 0.016627, loss_ce: 0.007942
2022-01-14 12:50:55,158 iteration 4549 : loss : 0.029482, loss_ce: 0.009739
2022-01-14 12:50:56,170 iteration 4550 : loss : 0.023142, loss_ce: 0.007535
2022-01-14 12:50:57,177 iteration 4551 : loss : 0.023259, loss_ce: 0.009590
2022-01-14 12:50:58,110 iteration 4552 : loss : 0.021490, loss_ce: 0.006706
2022-01-14 12:50:59,008 iteration 4553 : loss : 0.021925, loss_ce: 0.009266
2022-01-14 12:50:59,977 iteration 4554 : loss : 0.020257, loss_ce: 0.005386
2022-01-14 12:51:00,852 iteration 4555 : loss : 0.020397, loss_ce: 0.007018
2022-01-14 12:51:01,773 iteration 4556 : loss : 0.018181, loss_ce: 0.007401
 67%|███████████████████▍         | 268/400 [1:16:27<36:17, 16.50s/it]2022-01-14 12:51:02,753 iteration 4557 : loss : 0.012225, loss_ce: 0.006079
2022-01-14 12:51:03,697 iteration 4558 : loss : 0.028869, loss_ce: 0.013066
2022-01-14 12:51:04,662 iteration 4559 : loss : 0.018856, loss_ce: 0.006281
2022-01-14 12:51:05,592 iteration 4560 : loss : 0.023707, loss_ce: 0.007975
2022-01-14 12:51:06,558 iteration 4561 : loss : 0.029785, loss_ce: 0.007951
2022-01-14 12:51:07,442 iteration 4562 : loss : 0.021142, loss_ce: 0.006302
2022-01-14 12:51:08,405 iteration 4563 : loss : 0.018653, loss_ce: 0.007863
2022-01-14 12:51:09,381 iteration 4564 : loss : 0.031064, loss_ce: 0.011703
2022-01-14 12:51:10,393 iteration 4565 : loss : 0.027433, loss_ce: 0.009495
2022-01-14 12:51:11,367 iteration 4566 : loss : 0.025397, loss_ce: 0.010829
2022-01-14 12:51:12,277 iteration 4567 : loss : 0.018022, loss_ce: 0.006945
2022-01-14 12:51:13,187 iteration 4568 : loss : 0.018658, loss_ce: 0.006084
2022-01-14 12:51:14,207 iteration 4569 : loss : 0.028932, loss_ce: 0.005629
2022-01-14 12:51:15,242 iteration 4570 : loss : 0.039591, loss_ce: 0.018370
2022-01-14 12:51:16,167 iteration 4571 : loss : 0.020562, loss_ce: 0.008874
2022-01-14 12:51:17,033 iteration 4572 : loss : 0.017397, loss_ce: 0.006517
2022-01-14 12:51:17,990 iteration 4573 : loss : 0.029337, loss_ce: 0.013574
 67%|███████████████████▌         | 269/400 [1:16:43<35:50, 16.41s/it]2022-01-14 12:51:18,895 iteration 4574 : loss : 0.019020, loss_ce: 0.008940
2022-01-14 12:51:19,882 iteration 4575 : loss : 0.020483, loss_ce: 0.006215
2022-01-14 12:51:20,915 iteration 4576 : loss : 0.026350, loss_ce: 0.010171
2022-01-14 12:51:21,870 iteration 4577 : loss : 0.029137, loss_ce: 0.010230
2022-01-14 12:51:22,712 iteration 4578 : loss : 0.020822, loss_ce: 0.008753
2022-01-14 12:51:23,701 iteration 4579 : loss : 0.023966, loss_ce: 0.011383
2022-01-14 12:51:24,637 iteration 4580 : loss : 0.016709, loss_ce: 0.006165
2022-01-14 12:51:25,552 iteration 4581 : loss : 0.022694, loss_ce: 0.008534
2022-01-14 12:51:26,463 iteration 4582 : loss : 0.026124, loss_ce: 0.011706
2022-01-14 12:51:27,508 iteration 4583 : loss : 0.030600, loss_ce: 0.007089
2022-01-14 12:51:28,447 iteration 4584 : loss : 0.024228, loss_ce: 0.006977
2022-01-14 12:51:29,327 iteration 4585 : loss : 0.014569, loss_ce: 0.004720
2022-01-14 12:51:30,237 iteration 4586 : loss : 0.023296, loss_ce: 0.010722
2022-01-14 12:51:31,172 iteration 4587 : loss : 0.016227, loss_ce: 0.006130
2022-01-14 12:51:32,192 iteration 4588 : loss : 0.019548, loss_ce: 0.007992
2022-01-14 12:51:33,138 iteration 4589 : loss : 0.025221, loss_ce: 0.011321
2022-01-14 12:51:33,138 Training Data Eval:
2022-01-14 12:51:37,431   Average segmentation loss on training set: 0.0124
2022-01-14 12:51:37,432 Validation Data Eval:
2022-01-14 12:51:38,885   Average segmentation loss on validation set: 0.0800
2022-01-14 12:51:39,865 iteration 4590 : loss : 0.028936, loss_ce: 0.020566
 68%|███████████████████▌         | 270/400 [1:17:05<39:06, 18.05s/it]2022-01-14 12:51:41,027 iteration 4591 : loss : 0.020229, loss_ce: 0.006387
2022-01-14 12:51:41,957 iteration 4592 : loss : 0.019641, loss_ce: 0.007910
2022-01-14 12:51:42,887 iteration 4593 : loss : 0.023460, loss_ce: 0.008304
2022-01-14 12:51:43,835 iteration 4594 : loss : 0.022048, loss_ce: 0.008265
2022-01-14 12:51:44,744 iteration 4595 : loss : 0.016505, loss_ce: 0.006679
2022-01-14 12:51:45,796 iteration 4596 : loss : 0.018732, loss_ce: 0.008466
2022-01-14 12:51:46,672 iteration 4597 : loss : 0.018518, loss_ce: 0.005859
2022-01-14 12:51:47,506 iteration 4598 : loss : 0.018823, loss_ce: 0.005709
2022-01-14 12:51:48,397 iteration 4599 : loss : 0.016512, loss_ce: 0.006708
2022-01-14 12:51:49,339 iteration 4600 : loss : 0.018206, loss_ce: 0.006842
2022-01-14 12:51:50,300 iteration 4601 : loss : 0.016810, loss_ce: 0.008748
2022-01-14 12:51:51,327 iteration 4602 : loss : 0.021470, loss_ce: 0.008806
2022-01-14 12:51:52,343 iteration 4603 : loss : 0.020014, loss_ce: 0.007418
2022-01-14 12:51:53,228 iteration 4604 : loss : 0.020339, loss_ce: 0.006303
2022-01-14 12:51:54,136 iteration 4605 : loss : 0.019888, loss_ce: 0.005994
2022-01-14 12:51:55,052 iteration 4606 : loss : 0.020493, loss_ce: 0.007407
2022-01-14 12:51:55,961 iteration 4607 : loss : 0.019698, loss_ce: 0.008634
 68%|███████████████████▋         | 271/400 [1:17:21<37:32, 17.46s/it]2022-01-14 12:51:56,975 iteration 4608 : loss : 0.016800, loss_ce: 0.006443
2022-01-14 12:51:57,914 iteration 4609 : loss : 0.015893, loss_ce: 0.005217
2022-01-14 12:51:58,874 iteration 4610 : loss : 0.015605, loss_ce: 0.003885
2022-01-14 12:51:59,867 iteration 4611 : loss : 0.029051, loss_ce: 0.013900
2022-01-14 12:52:00,825 iteration 4612 : loss : 0.023522, loss_ce: 0.009458
2022-01-14 12:52:01,774 iteration 4613 : loss : 0.022137, loss_ce: 0.008058
2022-01-14 12:52:02,716 iteration 4614 : loss : 0.014275, loss_ce: 0.004279
2022-01-14 12:52:03,747 iteration 4615 : loss : 0.028810, loss_ce: 0.012983
2022-01-14 12:52:04,619 iteration 4616 : loss : 0.016700, loss_ce: 0.007677
2022-01-14 12:52:05,546 iteration 4617 : loss : 0.028307, loss_ce: 0.009030
2022-01-14 12:52:06,457 iteration 4618 : loss : 0.011379, loss_ce: 0.004319
2022-01-14 12:52:07,412 iteration 4619 : loss : 0.032240, loss_ce: 0.011544
2022-01-14 12:52:08,299 iteration 4620 : loss : 0.025191, loss_ce: 0.010029
2022-01-14 12:52:09,203 iteration 4621 : loss : 0.022685, loss_ce: 0.008714
2022-01-14 12:52:10,156 iteration 4622 : loss : 0.023279, loss_ce: 0.009099
2022-01-14 12:52:11,169 iteration 4623 : loss : 0.015489, loss_ce: 0.006009
2022-01-14 12:52:12,063 iteration 4624 : loss : 0.024000, loss_ce: 0.008297
 68%|███████████████████▋         | 272/400 [1:17:37<36:23, 17.06s/it]2022-01-14 12:52:13,134 iteration 4625 : loss : 0.020788, loss_ce: 0.007022
2022-01-14 12:52:14,102 iteration 4626 : loss : 0.029014, loss_ce: 0.009855
2022-01-14 12:52:15,029 iteration 4627 : loss : 0.016795, loss_ce: 0.007173
2022-01-14 12:52:15,963 iteration 4628 : loss : 0.021067, loss_ce: 0.007025
2022-01-14 12:52:16,822 iteration 4629 : loss : 0.034399, loss_ce: 0.005414
2022-01-14 12:52:17,766 iteration 4630 : loss : 0.013599, loss_ce: 0.006897
2022-01-14 12:52:18,669 iteration 4631 : loss : 0.021966, loss_ce: 0.007372
2022-01-14 12:52:19,612 iteration 4632 : loss : 0.021987, loss_ce: 0.006572
2022-01-14 12:52:20,572 iteration 4633 : loss : 0.016503, loss_ce: 0.004785
2022-01-14 12:52:21,583 iteration 4634 : loss : 0.032830, loss_ce: 0.014163
2022-01-14 12:52:22,395 iteration 4635 : loss : 0.013789, loss_ce: 0.004501
2022-01-14 12:52:23,243 iteration 4636 : loss : 0.013056, loss_ce: 0.004578
2022-01-14 12:52:24,165 iteration 4637 : loss : 0.024672, loss_ce: 0.009686
2022-01-14 12:52:25,091 iteration 4638 : loss : 0.033043, loss_ce: 0.017209
2022-01-14 12:52:26,035 iteration 4639 : loss : 0.016680, loss_ce: 0.005528
2022-01-14 12:52:27,002 iteration 4640 : loss : 0.025768, loss_ce: 0.011082
2022-01-14 12:52:27,944 iteration 4641 : loss : 0.025981, loss_ce: 0.009549
 68%|███████████████████▊         | 273/400 [1:17:53<35:21, 16.70s/it]2022-01-14 12:52:28,932 iteration 4642 : loss : 0.018561, loss_ce: 0.007996
2022-01-14 12:52:29,870 iteration 4643 : loss : 0.034333, loss_ce: 0.012973
2022-01-14 12:52:30,800 iteration 4644 : loss : 0.039424, loss_ce: 0.017979
2022-01-14 12:52:31,694 iteration 4645 : loss : 0.018339, loss_ce: 0.006411
2022-01-14 12:52:32,597 iteration 4646 : loss : 0.025994, loss_ce: 0.012938
2022-01-14 12:52:33,532 iteration 4647 : loss : 0.017645, loss_ce: 0.007258
2022-01-14 12:52:34,404 iteration 4648 : loss : 0.020856, loss_ce: 0.008611
2022-01-14 12:52:35,476 iteration 4649 : loss : 0.026189, loss_ce: 0.009740
2022-01-14 12:52:36,288 iteration 4650 : loss : 0.017019, loss_ce: 0.007025
2022-01-14 12:52:37,225 iteration 4651 : loss : 0.019400, loss_ce: 0.007487
2022-01-14 12:52:38,154 iteration 4652 : loss : 0.020988, loss_ce: 0.007447
2022-01-14 12:52:38,988 iteration 4653 : loss : 0.021177, loss_ce: 0.007395
2022-01-14 12:52:39,850 iteration 4654 : loss : 0.018686, loss_ce: 0.005594
2022-01-14 12:52:40,833 iteration 4655 : loss : 0.023214, loss_ce: 0.007586
2022-01-14 12:52:41,740 iteration 4656 : loss : 0.020513, loss_ce: 0.006121
2022-01-14 12:52:42,679 iteration 4657 : loss : 0.019862, loss_ce: 0.008043
2022-01-14 12:52:43,592 iteration 4658 : loss : 0.020052, loss_ce: 0.006508
 68%|███████████████████▊         | 274/400 [1:18:09<34:24, 16.38s/it]2022-01-14 12:52:44,590 iteration 4659 : loss : 0.017537, loss_ce: 0.006766
2022-01-14 12:52:45,486 iteration 4660 : loss : 0.014634, loss_ce: 0.006166
2022-01-14 12:52:46,480 iteration 4661 : loss : 0.016038, loss_ce: 0.006583
2022-01-14 12:52:47,308 iteration 4662 : loss : 0.013605, loss_ce: 0.006405
2022-01-14 12:52:48,336 iteration 4663 : loss : 0.020415, loss_ce: 0.007397
2022-01-14 12:52:49,252 iteration 4664 : loss : 0.025726, loss_ce: 0.010225
2022-01-14 12:52:50,168 iteration 4665 : loss : 0.018380, loss_ce: 0.007750
2022-01-14 12:52:51,162 iteration 4666 : loss : 0.016403, loss_ce: 0.006809
2022-01-14 12:52:52,160 iteration 4667 : loss : 0.028670, loss_ce: 0.012091
2022-01-14 12:52:53,056 iteration 4668 : loss : 0.016480, loss_ce: 0.006317
2022-01-14 12:52:54,060 iteration 4669 : loss : 0.021076, loss_ce: 0.007781
2022-01-14 12:52:55,003 iteration 4670 : loss : 0.027493, loss_ce: 0.008559
2022-01-14 12:52:55,894 iteration 4671 : loss : 0.013004, loss_ce: 0.004571
2022-01-14 12:52:56,786 iteration 4672 : loss : 0.012664, loss_ce: 0.004520
2022-01-14 12:52:57,617 iteration 4673 : loss : 0.014317, loss_ce: 0.004583
2022-01-14 12:52:58,578 iteration 4674 : loss : 0.025354, loss_ce: 0.007027
2022-01-14 12:52:58,578 Training Data Eval:
2022-01-14 12:53:02,867   Average segmentation loss on training set: 0.0110
2022-01-14 12:53:02,868 Validation Data Eval:
2022-01-14 12:53:04,342   Average segmentation loss on validation set: 0.0727
2022-01-14 12:53:05,221 iteration 4675 : loss : 0.013360, loss_ce: 0.005070
 69%|███████████████████▉         | 275/400 [1:18:31<37:24, 17.96s/it]2022-01-14 12:53:06,236 iteration 4676 : loss : 0.014301, loss_ce: 0.005582
2022-01-14 12:53:07,147 iteration 4677 : loss : 0.014853, loss_ce: 0.005858
2022-01-14 12:53:08,123 iteration 4678 : loss : 0.017419, loss_ce: 0.005561
2022-01-14 12:53:09,163 iteration 4679 : loss : 0.022594, loss_ce: 0.009170
2022-01-14 12:53:10,024 iteration 4680 : loss : 0.016891, loss_ce: 0.006695
2022-01-14 12:53:10,945 iteration 4681 : loss : 0.015867, loss_ce: 0.006673
2022-01-14 12:53:11,853 iteration 4682 : loss : 0.017181, loss_ce: 0.006558
2022-01-14 12:53:12,750 iteration 4683 : loss : 0.016080, loss_ce: 0.005054
2022-01-14 12:53:13,660 iteration 4684 : loss : 0.023165, loss_ce: 0.008014
2022-01-14 12:53:14,635 iteration 4685 : loss : 0.014938, loss_ce: 0.005897
2022-01-14 12:53:15,492 iteration 4686 : loss : 0.027029, loss_ce: 0.010072
2022-01-14 12:53:16,418 iteration 4687 : loss : 0.025926, loss_ce: 0.008079
2022-01-14 12:53:17,234 iteration 4688 : loss : 0.011732, loss_ce: 0.005082
2022-01-14 12:53:18,189 iteration 4689 : loss : 0.019437, loss_ce: 0.007335
2022-01-14 12:53:19,015 iteration 4690 : loss : 0.015145, loss_ce: 0.005322
2022-01-14 12:53:19,934 iteration 4691 : loss : 0.023995, loss_ce: 0.007280
2022-01-14 12:53:20,990 iteration 4692 : loss : 0.023566, loss_ce: 0.009715
 69%|████████████████████         | 276/400 [1:18:46<35:45, 17.30s/it]2022-01-14 12:53:21,964 iteration 4693 : loss : 0.019747, loss_ce: 0.007795
2022-01-14 12:53:22,878 iteration 4694 : loss : 0.017815, loss_ce: 0.005566
2022-01-14 12:53:23,812 iteration 4695 : loss : 0.024487, loss_ce: 0.009781
2022-01-14 12:53:24,768 iteration 4696 : loss : 0.018029, loss_ce: 0.006760
2022-01-14 12:53:25,631 iteration 4697 : loss : 0.021933, loss_ce: 0.009763
2022-01-14 12:53:26,519 iteration 4698 : loss : 0.018783, loss_ce: 0.007282
2022-01-14 12:53:27,438 iteration 4699 : loss : 0.025323, loss_ce: 0.008003
2022-01-14 12:53:28,365 iteration 4700 : loss : 0.026231, loss_ce: 0.010562
2022-01-14 12:53:29,270 iteration 4701 : loss : 0.016832, loss_ce: 0.004208
2022-01-14 12:53:30,269 iteration 4702 : loss : 0.027024, loss_ce: 0.009745
2022-01-14 12:53:31,217 iteration 4703 : loss : 0.026474, loss_ce: 0.012028
2022-01-14 12:53:32,179 iteration 4704 : loss : 0.036618, loss_ce: 0.007867
2022-01-14 12:53:33,149 iteration 4705 : loss : 0.031026, loss_ce: 0.007519
2022-01-14 12:53:33,998 iteration 4706 : loss : 0.013380, loss_ce: 0.005131
2022-01-14 12:53:34,899 iteration 4707 : loss : 0.022594, loss_ce: 0.006584
2022-01-14 12:53:35,830 iteration 4708 : loss : 0.022828, loss_ce: 0.010014
2022-01-14 12:53:36,731 iteration 4709 : loss : 0.027911, loss_ce: 0.010492
 69%|████████████████████         | 277/400 [1:19:02<34:30, 16.83s/it]2022-01-14 12:53:37,679 iteration 4710 : loss : 0.018154, loss_ce: 0.007792
2022-01-14 12:53:38,557 iteration 4711 : loss : 0.017362, loss_ce: 0.005365
2022-01-14 12:53:39,407 iteration 4712 : loss : 0.014927, loss_ce: 0.005306
2022-01-14 12:53:40,352 iteration 4713 : loss : 0.022603, loss_ce: 0.007727
2022-01-14 12:53:41,204 iteration 4714 : loss : 0.016283, loss_ce: 0.005643
2022-01-14 12:53:42,166 iteration 4715 : loss : 0.022219, loss_ce: 0.011224
2022-01-14 12:53:43,140 iteration 4716 : loss : 0.025092, loss_ce: 0.009671
2022-01-14 12:53:44,043 iteration 4717 : loss : 0.019621, loss_ce: 0.007009
2022-01-14 12:53:44,963 iteration 4718 : loss : 0.016552, loss_ce: 0.005592
2022-01-14 12:53:45,863 iteration 4719 : loss : 0.013285, loss_ce: 0.004386
2022-01-14 12:53:46,781 iteration 4720 : loss : 0.016983, loss_ce: 0.008308
2022-01-14 12:53:47,688 iteration 4721 : loss : 0.014443, loss_ce: 0.004305
2022-01-14 12:53:48,683 iteration 4722 : loss : 0.020350, loss_ce: 0.007879
2022-01-14 12:53:49,699 iteration 4723 : loss : 0.021524, loss_ce: 0.007151
2022-01-14 12:53:50,724 iteration 4724 : loss : 0.029870, loss_ce: 0.016129
2022-01-14 12:53:51,598 iteration 4725 : loss : 0.023541, loss_ce: 0.006946
2022-01-14 12:53:52,569 iteration 4726 : loss : 0.027089, loss_ce: 0.006933
 70%|████████████████████▏        | 278/400 [1:19:18<33:37, 16.54s/it]2022-01-14 12:53:53,570 iteration 4727 : loss : 0.019623, loss_ce: 0.006533
2022-01-14 12:53:54,522 iteration 4728 : loss : 0.016605, loss_ce: 0.005680
2022-01-14 12:53:55,396 iteration 4729 : loss : 0.017381, loss_ce: 0.004935
2022-01-14 12:53:56,343 iteration 4730 : loss : 0.019724, loss_ce: 0.008041
2022-01-14 12:53:57,281 iteration 4731 : loss : 0.028979, loss_ce: 0.008577
2022-01-14 12:53:58,217 iteration 4732 : loss : 0.020603, loss_ce: 0.008854
2022-01-14 12:53:59,090 iteration 4733 : loss : 0.017170, loss_ce: 0.006109
2022-01-14 12:53:59,937 iteration 4734 : loss : 0.016097, loss_ce: 0.006062
2022-01-14 12:54:00,933 iteration 4735 : loss : 0.036450, loss_ce: 0.021026
2022-01-14 12:54:01,880 iteration 4736 : loss : 0.022248, loss_ce: 0.009506
2022-01-14 12:54:02,912 iteration 4737 : loss : 0.030048, loss_ce: 0.009688
2022-01-14 12:54:03,912 iteration 4738 : loss : 0.048193, loss_ce: 0.007390
2022-01-14 12:54:04,820 iteration 4739 : loss : 0.019609, loss_ce: 0.007276
2022-01-14 12:54:05,665 iteration 4740 : loss : 0.017288, loss_ce: 0.006995
2022-01-14 12:54:06,578 iteration 4741 : loss : 0.021512, loss_ce: 0.013048
2022-01-14 12:54:07,396 iteration 4742 : loss : 0.020580, loss_ce: 0.006509
2022-01-14 12:54:08,321 iteration 4743 : loss : 0.029647, loss_ce: 0.014534
 70%|████████████████████▏        | 279/400 [1:19:34<32:52, 16.30s/it]2022-01-14 12:54:09,326 iteration 4744 : loss : 0.024360, loss_ce: 0.009518
2022-01-14 12:54:10,265 iteration 4745 : loss : 0.018393, loss_ce: 0.007387
2022-01-14 12:54:11,178 iteration 4746 : loss : 0.017990, loss_ce: 0.007512
2022-01-14 12:54:12,132 iteration 4747 : loss : 0.017997, loss_ce: 0.007507
2022-01-14 12:54:13,178 iteration 4748 : loss : 0.022845, loss_ce: 0.008724
2022-01-14 12:54:14,153 iteration 4749 : loss : 0.017797, loss_ce: 0.004902
2022-01-14 12:54:15,073 iteration 4750 : loss : 0.022901, loss_ce: 0.009490
2022-01-14 12:54:15,917 iteration 4751 : loss : 0.026287, loss_ce: 0.009901
2022-01-14 12:54:16,847 iteration 4752 : loss : 0.021729, loss_ce: 0.005060
2022-01-14 12:54:17,786 iteration 4753 : loss : 0.019663, loss_ce: 0.009490
2022-01-14 12:54:18,729 iteration 4754 : loss : 0.018322, loss_ce: 0.004848
2022-01-14 12:54:19,665 iteration 4755 : loss : 0.020493, loss_ce: 0.008487
2022-01-14 12:54:20,602 iteration 4756 : loss : 0.015926, loss_ce: 0.007037
2022-01-14 12:54:21,537 iteration 4757 : loss : 0.017113, loss_ce: 0.006631
2022-01-14 12:54:22,589 iteration 4758 : loss : 0.020887, loss_ce: 0.007496
2022-01-14 12:54:23,437 iteration 4759 : loss : 0.013592, loss_ce: 0.005069
2022-01-14 12:54:23,438 Training Data Eval:
2022-01-14 12:54:27,741   Average segmentation loss on training set: 0.0126
2022-01-14 12:54:27,741 Validation Data Eval:
2022-01-14 12:54:29,201   Average segmentation loss on validation set: 0.0669
2022-01-14 12:54:30,126 iteration 4760 : loss : 0.019080, loss_ce: 0.006514
 70%|████████████████████▎        | 280/400 [1:19:56<35:54, 17.95s/it]2022-01-14 12:54:31,103 iteration 4761 : loss : 0.013500, loss_ce: 0.005095
2022-01-14 12:54:32,077 iteration 4762 : loss : 0.021246, loss_ce: 0.006006
2022-01-14 12:54:33,035 iteration 4763 : loss : 0.020228, loss_ce: 0.006794
2022-01-14 12:54:34,055 iteration 4764 : loss : 0.019633, loss_ce: 0.006910
2022-01-14 12:54:35,048 iteration 4765 : loss : 0.018700, loss_ce: 0.007363
2022-01-14 12:54:36,106 iteration 4766 : loss : 0.024683, loss_ce: 0.006350
2022-01-14 12:54:37,134 iteration 4767 : loss : 0.022318, loss_ce: 0.010607
2022-01-14 12:54:38,097 iteration 4768 : loss : 0.022459, loss_ce: 0.008947
2022-01-14 12:54:38,958 iteration 4769 : loss : 0.015378, loss_ce: 0.005197
2022-01-14 12:54:39,935 iteration 4770 : loss : 0.018817, loss_ce: 0.008582
2022-01-14 12:54:40,859 iteration 4771 : loss : 0.043279, loss_ce: 0.016881
2022-01-14 12:54:41,734 iteration 4772 : loss : 0.017858, loss_ce: 0.006664
2022-01-14 12:54:42,586 iteration 4773 : loss : 0.014687, loss_ce: 0.006435
2022-01-14 12:54:43,533 iteration 4774 : loss : 0.023705, loss_ce: 0.008607
2022-01-14 12:54:44,402 iteration 4775 : loss : 0.015445, loss_ce: 0.005532
2022-01-14 12:54:45,323 iteration 4776 : loss : 0.023276, loss_ce: 0.009009
2022-01-14 12:54:46,235 iteration 4777 : loss : 0.017759, loss_ce: 0.006255
 70%|████████████████████▎        | 281/400 [1:20:12<34:30, 17.40s/it]2022-01-14 12:54:47,238 iteration 4778 : loss : 0.016000, loss_ce: 0.007211
2022-01-14 12:54:48,127 iteration 4779 : loss : 0.015393, loss_ce: 0.006906
2022-01-14 12:54:48,996 iteration 4780 : loss : 0.018054, loss_ce: 0.008036
2022-01-14 12:54:49,955 iteration 4781 : loss : 0.018068, loss_ce: 0.006334
2022-01-14 12:54:50,933 iteration 4782 : loss : 0.036326, loss_ce: 0.014126
2022-01-14 12:54:51,839 iteration 4783 : loss : 0.018590, loss_ce: 0.007810
2022-01-14 12:54:52,828 iteration 4784 : loss : 0.023478, loss_ce: 0.008108
2022-01-14 12:54:53,754 iteration 4785 : loss : 0.015664, loss_ce: 0.005287
2022-01-14 12:54:54,680 iteration 4786 : loss : 0.013837, loss_ce: 0.005305
2022-01-14 12:54:55,592 iteration 4787 : loss : 0.033572, loss_ce: 0.009860
2022-01-14 12:54:56,558 iteration 4788 : loss : 0.019744, loss_ce: 0.004962
2022-01-14 12:54:57,388 iteration 4789 : loss : 0.013620, loss_ce: 0.005154
2022-01-14 12:54:58,202 iteration 4790 : loss : 0.015146, loss_ce: 0.005469
2022-01-14 12:54:59,146 iteration 4791 : loss : 0.022951, loss_ce: 0.010242
2022-01-14 12:55:00,110 iteration 4792 : loss : 0.018442, loss_ce: 0.006743
2022-01-14 12:55:01,118 iteration 4793 : loss : 0.025967, loss_ce: 0.010184
2022-01-14 12:55:02,026 iteration 4794 : loss : 0.017510, loss_ce: 0.005512
 70%|████████████████████▍        | 282/400 [1:20:27<33:16, 16.92s/it]2022-01-14 12:55:03,047 iteration 4795 : loss : 0.030071, loss_ce: 0.010276
2022-01-14 12:55:03,995 iteration 4796 : loss : 0.023255, loss_ce: 0.006789
2022-01-14 12:55:04,933 iteration 4797 : loss : 0.017343, loss_ce: 0.006777
2022-01-14 12:55:05,870 iteration 4798 : loss : 0.019137, loss_ce: 0.007021
2022-01-14 12:55:06,768 iteration 4799 : loss : 0.018667, loss_ce: 0.004886
2022-01-14 12:55:07,721 iteration 4800 : loss : 0.020347, loss_ce: 0.007975
2022-01-14 12:55:08,620 iteration 4801 : loss : 0.022031, loss_ce: 0.009012
2022-01-14 12:55:09,601 iteration 4802 : loss : 0.031997, loss_ce: 0.015198
2022-01-14 12:55:10,525 iteration 4803 : loss : 0.013299, loss_ce: 0.005443
2022-01-14 12:55:11,480 iteration 4804 : loss : 0.013141, loss_ce: 0.004816
2022-01-14 12:55:12,501 iteration 4805 : loss : 0.020887, loss_ce: 0.008798
2022-01-14 12:55:13,447 iteration 4806 : loss : 0.025253, loss_ce: 0.006194
2022-01-14 12:55:14,313 iteration 4807 : loss : 0.017542, loss_ce: 0.006070
2022-01-14 12:55:15,312 iteration 4808 : loss : 0.016055, loss_ce: 0.005523
2022-01-14 12:55:16,199 iteration 4809 : loss : 0.016345, loss_ce: 0.008347
2022-01-14 12:55:17,126 iteration 4810 : loss : 0.020650, loss_ce: 0.007246
2022-01-14 12:55:18,071 iteration 4811 : loss : 0.020602, loss_ce: 0.007603
 71%|████████████████████▌        | 283/400 [1:20:43<32:28, 16.66s/it]2022-01-14 12:55:19,047 iteration 4812 : loss : 0.021850, loss_ce: 0.007699
2022-01-14 12:55:19,930 iteration 4813 : loss : 0.012435, loss_ce: 0.004731
2022-01-14 12:55:21,001 iteration 4814 : loss : 0.025271, loss_ce: 0.009220
2022-01-14 12:55:21,898 iteration 4815 : loss : 0.014835, loss_ce: 0.005139
2022-01-14 12:55:22,775 iteration 4816 : loss : 0.015322, loss_ce: 0.005684
2022-01-14 12:55:23,641 iteration 4817 : loss : 0.013693, loss_ce: 0.005286
2022-01-14 12:55:24,510 iteration 4818 : loss : 0.027929, loss_ce: 0.012408
2022-01-14 12:55:25,461 iteration 4819 : loss : 0.019130, loss_ce: 0.005916
2022-01-14 12:55:26,342 iteration 4820 : loss : 0.017290, loss_ce: 0.007797
2022-01-14 12:55:27,274 iteration 4821 : loss : 0.015545, loss_ce: 0.005220
2022-01-14 12:55:28,274 iteration 4822 : loss : 0.022044, loss_ce: 0.008571
2022-01-14 12:55:29,215 iteration 4823 : loss : 0.026972, loss_ce: 0.005230
2022-01-14 12:55:30,108 iteration 4824 : loss : 0.019202, loss_ce: 0.005663
2022-01-14 12:55:31,094 iteration 4825 : loss : 0.015581, loss_ce: 0.007379
2022-01-14 12:55:32,219 iteration 4826 : loss : 0.019524, loss_ce: 0.009261
2022-01-14 12:55:33,111 iteration 4827 : loss : 0.016264, loss_ce: 0.008447
2022-01-14 12:55:33,995 iteration 4828 : loss : 0.013684, loss_ce: 0.004773
 71%|████████████████████▌        | 284/400 [1:20:59<31:46, 16.43s/it]2022-01-14 12:55:34,966 iteration 4829 : loss : 0.014319, loss_ce: 0.006433
2022-01-14 12:55:35,933 iteration 4830 : loss : 0.021648, loss_ce: 0.009142
2022-01-14 12:55:36,898 iteration 4831 : loss : 0.019128, loss_ce: 0.009802
2022-01-14 12:55:37,872 iteration 4832 : loss : 0.014286, loss_ce: 0.004760
2022-01-14 12:55:38,800 iteration 4833 : loss : 0.019494, loss_ce: 0.009173
2022-01-14 12:55:39,829 iteration 4834 : loss : 0.019487, loss_ce: 0.007944
2022-01-14 12:55:40,744 iteration 4835 : loss : 0.019929, loss_ce: 0.008189
2022-01-14 12:55:41,634 iteration 4836 : loss : 0.023373, loss_ce: 0.008272
2022-01-14 12:55:42,582 iteration 4837 : loss : 0.016416, loss_ce: 0.004986
2022-01-14 12:55:43,531 iteration 4838 : loss : 0.018374, loss_ce: 0.007430
2022-01-14 12:55:44,361 iteration 4839 : loss : 0.015917, loss_ce: 0.005891
2022-01-14 12:55:45,273 iteration 4840 : loss : 0.024627, loss_ce: 0.007625
2022-01-14 12:55:46,236 iteration 4841 : loss : 0.021119, loss_ce: 0.007652
2022-01-14 12:55:47,161 iteration 4842 : loss : 0.023358, loss_ce: 0.010249
2022-01-14 12:55:48,075 iteration 4843 : loss : 0.021910, loss_ce: 0.006906
2022-01-14 12:55:49,080 iteration 4844 : loss : 0.023888, loss_ce: 0.006894
2022-01-14 12:55:49,081 Training Data Eval:
2022-01-14 12:55:53,382   Average segmentation loss on training set: 0.0109
2022-01-14 12:55:53,382 Validation Data Eval:
2022-01-14 12:55:54,841   Average segmentation loss on validation set: 0.0764
2022-01-14 12:55:55,713 iteration 4845 : loss : 0.015950, loss_ce: 0.005886
 71%|████████████████████▋        | 285/400 [1:21:21<34:32, 18.02s/it]2022-01-14 12:55:56,689 iteration 4846 : loss : 0.019486, loss_ce: 0.007578
2022-01-14 12:55:57,560 iteration 4847 : loss : 0.015798, loss_ce: 0.006095
2022-01-14 12:55:58,605 iteration 4848 : loss : 0.020504, loss_ce: 0.008306
2022-01-14 12:55:59,504 iteration 4849 : loss : 0.013178, loss_ce: 0.004546
2022-01-14 12:56:00,351 iteration 4850 : loss : 0.023517, loss_ce: 0.015330
2022-01-14 12:56:01,383 iteration 4851 : loss : 0.037354, loss_ce: 0.010033
2022-01-14 12:56:02,285 iteration 4852 : loss : 0.017251, loss_ce: 0.008180
2022-01-14 12:56:03,245 iteration 4853 : loss : 0.015677, loss_ce: 0.003584
2022-01-14 12:56:04,326 iteration 4854 : loss : 0.020174, loss_ce: 0.005467
2022-01-14 12:56:05,283 iteration 4855 : loss : 0.018314, loss_ce: 0.006535
2022-01-14 12:56:06,151 iteration 4856 : loss : 0.013986, loss_ce: 0.004606
2022-01-14 12:56:07,137 iteration 4857 : loss : 0.022149, loss_ce: 0.010516
2022-01-14 12:56:08,103 iteration 4858 : loss : 0.027615, loss_ce: 0.010106
2022-01-14 12:56:09,037 iteration 4859 : loss : 0.018062, loss_ce: 0.008481
2022-01-14 12:56:10,004 iteration 4860 : loss : 0.040533, loss_ce: 0.018215
2022-01-14 12:56:10,938 iteration 4861 : loss : 0.018621, loss_ce: 0.007493
2022-01-14 12:56:11,795 iteration 4862 : loss : 0.017915, loss_ce: 0.006404
 72%|████████████████████▋        | 286/400 [1:21:37<33:08, 17.44s/it]2022-01-14 12:56:12,734 iteration 4863 : loss : 0.016221, loss_ce: 0.005700
2022-01-14 12:56:13,694 iteration 4864 : loss : 0.019962, loss_ce: 0.007599
2022-01-14 12:56:14,721 iteration 4865 : loss : 0.029832, loss_ce: 0.007291
2022-01-14 12:56:15,619 iteration 4866 : loss : 0.015006, loss_ce: 0.005659
2022-01-14 12:56:16,560 iteration 4867 : loss : 0.016188, loss_ce: 0.006957
2022-01-14 12:56:17,438 iteration 4868 : loss : 0.016960, loss_ce: 0.007887
2022-01-14 12:56:18,333 iteration 4869 : loss : 0.019519, loss_ce: 0.007438
2022-01-14 12:56:19,351 iteration 4870 : loss : 0.021161, loss_ce: 0.007057
2022-01-14 12:56:20,320 iteration 4871 : loss : 0.013566, loss_ce: 0.005125
2022-01-14 12:56:21,182 iteration 4872 : loss : 0.021680, loss_ce: 0.009564
2022-01-14 12:56:22,016 iteration 4873 : loss : 0.019927, loss_ce: 0.007054
2022-01-14 12:56:22,838 iteration 4874 : loss : 0.013179, loss_ce: 0.005666
2022-01-14 12:56:23,754 iteration 4875 : loss : 0.015455, loss_ce: 0.004585
2022-01-14 12:56:24,618 iteration 4876 : loss : 0.021931, loss_ce: 0.007366
2022-01-14 12:56:25,654 iteration 4877 : loss : 0.020727, loss_ce: 0.007876
2022-01-14 12:56:26,574 iteration 4878 : loss : 0.016553, loss_ce: 0.006203
2022-01-14 12:56:27,492 iteration 4879 : loss : 0.017493, loss_ce: 0.007172
 72%|████████████████████▊        | 287/400 [1:21:53<31:51, 16.92s/it]2022-01-14 12:56:28,555 iteration 4880 : loss : 0.027975, loss_ce: 0.016647
2022-01-14 12:56:29,458 iteration 4881 : loss : 0.023855, loss_ce: 0.007624
2022-01-14 12:56:30,393 iteration 4882 : loss : 0.014975, loss_ce: 0.003940
2022-01-14 12:56:31,327 iteration 4883 : loss : 0.020302, loss_ce: 0.005725
2022-01-14 12:56:32,262 iteration 4884 : loss : 0.013597, loss_ce: 0.007873
2022-01-14 12:56:33,339 iteration 4885 : loss : 0.019452, loss_ce: 0.006056
2022-01-14 12:56:34,327 iteration 4886 : loss : 0.019774, loss_ce: 0.007143
2022-01-14 12:56:35,339 iteration 4887 : loss : 0.017851, loss_ce: 0.006113
2022-01-14 12:56:36,252 iteration 4888 : loss : 0.019545, loss_ce: 0.005644
2022-01-14 12:56:37,173 iteration 4889 : loss : 0.016417, loss_ce: 0.005860
2022-01-14 12:56:38,169 iteration 4890 : loss : 0.026193, loss_ce: 0.008948
2022-01-14 12:56:39,162 iteration 4891 : loss : 0.023510, loss_ce: 0.012283
2022-01-14 12:56:40,025 iteration 4892 : loss : 0.015027, loss_ce: 0.005955
2022-01-14 12:56:40,907 iteration 4893 : loss : 0.013819, loss_ce: 0.006212
2022-01-14 12:56:41,828 iteration 4894 : loss : 0.024494, loss_ce: 0.005512
2022-01-14 12:56:42,706 iteration 4895 : loss : 0.019029, loss_ce: 0.006884
2022-01-14 12:56:43,645 iteration 4896 : loss : 0.018683, loss_ce: 0.006740
 72%|████████████████████▉        | 288/400 [1:22:09<31:08, 16.69s/it]2022-01-14 12:56:44,622 iteration 4897 : loss : 0.026499, loss_ce: 0.011000
2022-01-14 12:56:45,588 iteration 4898 : loss : 0.055692, loss_ce: 0.019579
2022-01-14 12:56:46,375 iteration 4899 : loss : 0.018335, loss_ce: 0.007080
2022-01-14 12:56:47,399 iteration 4900 : loss : 0.029908, loss_ce: 0.011271
2022-01-14 12:56:48,284 iteration 4901 : loss : 0.014172, loss_ce: 0.003497
2022-01-14 12:56:49,286 iteration 4902 : loss : 0.029986, loss_ce: 0.011814
2022-01-14 12:56:50,298 iteration 4903 : loss : 0.029888, loss_ce: 0.014341
2022-01-14 12:56:51,312 iteration 4904 : loss : 0.021611, loss_ce: 0.010442
2022-01-14 12:56:52,265 iteration 4905 : loss : 0.023999, loss_ce: 0.007364
2022-01-14 12:56:53,223 iteration 4906 : loss : 0.023816, loss_ce: 0.009310
2022-01-14 12:56:54,041 iteration 4907 : loss : 0.016674, loss_ce: 0.006848
2022-01-14 12:56:54,916 iteration 4908 : loss : 0.018274, loss_ce: 0.007387
2022-01-14 12:56:55,839 iteration 4909 : loss : 0.025847, loss_ce: 0.008600
2022-01-14 12:56:56,758 iteration 4910 : loss : 0.019634, loss_ce: 0.007263
2022-01-14 12:56:57,629 iteration 4911 : loss : 0.020554, loss_ce: 0.006894
2022-01-14 12:56:58,596 iteration 4912 : loss : 0.028445, loss_ce: 0.010163
2022-01-14 12:56:59,511 iteration 4913 : loss : 0.026764, loss_ce: 0.008691
 72%|████████████████████▉        | 289/400 [1:22:25<30:25, 16.44s/it]2022-01-14 12:57:00,443 iteration 4914 : loss : 0.020218, loss_ce: 0.008183
2022-01-14 12:57:01,395 iteration 4915 : loss : 0.021177, loss_ce: 0.009456
2022-01-14 12:57:02,358 iteration 4916 : loss : 0.043619, loss_ce: 0.013294
2022-01-14 12:57:03,283 iteration 4917 : loss : 0.016158, loss_ce: 0.004754
2022-01-14 12:57:04,220 iteration 4918 : loss : 0.027401, loss_ce: 0.014107
2022-01-14 12:57:05,118 iteration 4919 : loss : 0.019907, loss_ce: 0.010028
2022-01-14 12:57:06,122 iteration 4920 : loss : 0.038745, loss_ce: 0.015931
2022-01-14 12:57:06,984 iteration 4921 : loss : 0.018677, loss_ce: 0.007147
2022-01-14 12:57:07,951 iteration 4922 : loss : 0.016123, loss_ce: 0.005223
2022-01-14 12:57:08,895 iteration 4923 : loss : 0.018994, loss_ce: 0.006841
2022-01-14 12:57:09,826 iteration 4924 : loss : 0.019361, loss_ce: 0.008135
2022-01-14 12:57:10,742 iteration 4925 : loss : 0.025707, loss_ce: 0.008609
2022-01-14 12:57:11,566 iteration 4926 : loss : 0.015138, loss_ce: 0.006966
2022-01-14 12:57:12,495 iteration 4927 : loss : 0.014306, loss_ce: 0.005168
2022-01-14 12:57:13,450 iteration 4928 : loss : 0.018687, loss_ce: 0.008729
2022-01-14 12:57:14,317 iteration 4929 : loss : 0.021379, loss_ce: 0.006185
2022-01-14 12:57:14,317 Training Data Eval:
2022-01-14 12:57:18,618   Average segmentation loss on training set: 0.0133
2022-01-14 12:57:18,619 Validation Data Eval:
2022-01-14 12:57:20,072   Average segmentation loss on validation set: 0.0673
2022-01-14 12:57:21,013 iteration 4930 : loss : 0.022307, loss_ce: 0.006726
 72%|█████████████████████        | 290/400 [1:22:46<32:55, 17.96s/it]2022-01-14 12:57:22,051 iteration 4931 : loss : 0.022016, loss_ce: 0.009973
2022-01-14 12:57:23,002 iteration 4932 : loss : 0.033433, loss_ce: 0.009883
2022-01-14 12:57:23,871 iteration 4933 : loss : 0.017993, loss_ce: 0.006916
2022-01-14 12:57:24,811 iteration 4934 : loss : 0.015669, loss_ce: 0.005043
2022-01-14 12:57:25,716 iteration 4935 : loss : 0.022273, loss_ce: 0.006043
2022-01-14 12:57:26,659 iteration 4936 : loss : 0.017280, loss_ce: 0.006073
2022-01-14 12:57:27,547 iteration 4937 : loss : 0.018617, loss_ce: 0.006054
2022-01-14 12:57:28,408 iteration 4938 : loss : 0.015524, loss_ce: 0.006120
2022-01-14 12:57:29,452 iteration 4939 : loss : 0.028249, loss_ce: 0.011908
2022-01-14 12:57:30,323 iteration 4940 : loss : 0.021485, loss_ce: 0.008395
2022-01-14 12:57:31,255 iteration 4941 : loss : 0.018472, loss_ce: 0.008603
2022-01-14 12:57:32,347 iteration 4942 : loss : 0.017783, loss_ce: 0.005720
2022-01-14 12:57:33,253 iteration 4943 : loss : 0.014827, loss_ce: 0.006146
2022-01-14 12:57:34,145 iteration 4944 : loss : 0.020446, loss_ce: 0.010220
2022-01-14 12:57:35,063 iteration 4945 : loss : 0.016641, loss_ce: 0.006013
2022-01-14 12:57:35,918 iteration 4946 : loss : 0.022313, loss_ce: 0.008254
2022-01-14 12:57:36,918 iteration 4947 : loss : 0.020559, loss_ce: 0.007686
 73%|█████████████████████        | 291/400 [1:23:02<31:30, 17.34s/it]2022-01-14 12:57:37,938 iteration 4948 : loss : 0.019190, loss_ce: 0.006678
2022-01-14 12:57:38,976 iteration 4949 : loss : 0.019191, loss_ce: 0.007553
2022-01-14 12:57:39,859 iteration 4950 : loss : 0.029296, loss_ce: 0.016192
2022-01-14 12:57:40,781 iteration 4951 : loss : 0.021735, loss_ce: 0.008680
2022-01-14 12:57:41,706 iteration 4952 : loss : 0.017280, loss_ce: 0.006112
2022-01-14 12:57:42,714 iteration 4953 : loss : 0.016729, loss_ce: 0.004541
2022-01-14 12:57:43,552 iteration 4954 : loss : 0.018985, loss_ce: 0.005591
2022-01-14 12:57:44,421 iteration 4955 : loss : 0.027425, loss_ce: 0.014843
2022-01-14 12:57:45,400 iteration 4956 : loss : 0.021677, loss_ce: 0.006265
2022-01-14 12:57:46,335 iteration 4957 : loss : 0.017242, loss_ce: 0.007737
2022-01-14 12:57:47,419 iteration 4958 : loss : 0.032034, loss_ce: 0.014969
2022-01-14 12:57:48,443 iteration 4959 : loss : 0.024812, loss_ce: 0.009442
2022-01-14 12:57:49,512 iteration 4960 : loss : 0.025660, loss_ce: 0.009499
2022-01-14 12:57:50,425 iteration 4961 : loss : 0.018987, loss_ce: 0.005247
2022-01-14 12:57:51,365 iteration 4962 : loss : 0.024523, loss_ce: 0.009481
2022-01-14 12:57:52,322 iteration 4963 : loss : 0.017575, loss_ce: 0.005884
2022-01-14 12:57:53,313 iteration 4964 : loss : 0.016099, loss_ce: 0.005296
 73%|█████████████████████▏       | 292/400 [1:23:19<30:42, 17.06s/it]2022-01-14 12:57:54,287 iteration 4965 : loss : 0.015755, loss_ce: 0.004657
2022-01-14 12:57:55,205 iteration 4966 : loss : 0.016910, loss_ce: 0.006492
2022-01-14 12:57:56,143 iteration 4967 : loss : 0.023517, loss_ce: 0.006423
2022-01-14 12:57:57,052 iteration 4968 : loss : 0.029954, loss_ce: 0.007754
2022-01-14 12:57:58,004 iteration 4969 : loss : 0.040150, loss_ce: 0.016739
2022-01-14 12:57:58,978 iteration 4970 : loss : 0.022387, loss_ce: 0.011294
2022-01-14 12:57:59,880 iteration 4971 : loss : 0.018078, loss_ce: 0.006926
2022-01-14 12:58:00,753 iteration 4972 : loss : 0.016486, loss_ce: 0.005153
2022-01-14 12:58:01,640 iteration 4973 : loss : 0.016110, loss_ce: 0.005949
2022-01-14 12:58:02,605 iteration 4974 : loss : 0.016881, loss_ce: 0.008072
2022-01-14 12:58:03,643 iteration 4975 : loss : 0.015811, loss_ce: 0.006071
2022-01-14 12:58:04,540 iteration 4976 : loss : 0.015991, loss_ce: 0.005309
2022-01-14 12:58:05,439 iteration 4977 : loss : 0.018497, loss_ce: 0.007834
2022-01-14 12:58:06,388 iteration 4978 : loss : 0.018859, loss_ce: 0.008470
2022-01-14 12:58:07,270 iteration 4979 : loss : 0.015141, loss_ce: 0.005488
2022-01-14 12:58:08,135 iteration 4980 : loss : 0.012616, loss_ce: 0.004182
2022-01-14 12:58:09,048 iteration 4981 : loss : 0.025425, loss_ce: 0.008880
 73%|█████████████████████▏       | 293/400 [1:23:34<29:42, 16.66s/it]2022-01-14 12:58:10,073 iteration 4982 : loss : 0.032583, loss_ce: 0.009995
2022-01-14 12:58:10,915 iteration 4983 : loss : 0.013453, loss_ce: 0.004297
2022-01-14 12:58:11,855 iteration 4984 : loss : 0.020246, loss_ce: 0.004850
2022-01-14 12:58:12,687 iteration 4985 : loss : 0.011466, loss_ce: 0.003695
2022-01-14 12:58:13,575 iteration 4986 : loss : 0.016514, loss_ce: 0.005852
2022-01-14 12:58:14,503 iteration 4987 : loss : 0.017462, loss_ce: 0.008601
2022-01-14 12:58:15,442 iteration 4988 : loss : 0.018174, loss_ce: 0.008853
2022-01-14 12:58:16,348 iteration 4989 : loss : 0.019918, loss_ce: 0.007796
2022-01-14 12:58:17,308 iteration 4990 : loss : 0.016362, loss_ce: 0.007487
2022-01-14 12:58:18,192 iteration 4991 : loss : 0.020365, loss_ce: 0.007854
2022-01-14 12:58:19,144 iteration 4992 : loss : 0.019819, loss_ce: 0.005872
2022-01-14 12:58:20,082 iteration 4993 : loss : 0.016380, loss_ce: 0.007275
2022-01-14 12:58:21,158 iteration 4994 : loss : 0.026193, loss_ce: 0.011150
2022-01-14 12:58:22,124 iteration 4995 : loss : 0.022032, loss_ce: 0.010549
2022-01-14 12:58:23,006 iteration 4996 : loss : 0.015109, loss_ce: 0.004123
2022-01-14 12:58:23,953 iteration 4997 : loss : 0.016913, loss_ce: 0.006018
2022-01-14 12:58:24,891 iteration 4998 : loss : 0.019399, loss_ce: 0.006847
 74%|█████████████████████▎       | 294/400 [1:23:50<29:00, 16.42s/it]2022-01-14 12:58:25,884 iteration 4999 : loss : 0.017836, loss_ce: 0.006350
2022-01-14 12:58:26,745 iteration 5000 : loss : 0.021160, loss_ce: 0.007361
2022-01-14 12:58:27,710 iteration 5001 : loss : 0.016821, loss_ce: 0.005002
2022-01-14 12:58:28,732 iteration 5002 : loss : 0.022857, loss_ce: 0.006817
2022-01-14 12:58:29,775 iteration 5003 : loss : 0.021620, loss_ce: 0.010814
2022-01-14 12:58:30,700 iteration 5004 : loss : 0.013769, loss_ce: 0.005677
2022-01-14 12:58:31,664 iteration 5005 : loss : 0.020412, loss_ce: 0.007516
2022-01-14 12:58:32,542 iteration 5006 : loss : 0.016238, loss_ce: 0.006087
2022-01-14 12:58:33,480 iteration 5007 : loss : 0.017407, loss_ce: 0.004035
2022-01-14 12:58:34,358 iteration 5008 : loss : 0.015875, loss_ce: 0.005256
2022-01-14 12:58:35,229 iteration 5009 : loss : 0.016453, loss_ce: 0.008411
2022-01-14 12:58:36,191 iteration 5010 : loss : 0.023725, loss_ce: 0.011879
2022-01-14 12:58:37,067 iteration 5011 : loss : 0.014888, loss_ce: 0.006016
2022-01-14 12:58:37,971 iteration 5012 : loss : 0.021459, loss_ce: 0.005927
2022-01-14 12:58:38,992 iteration 5013 : loss : 0.015455, loss_ce: 0.006438
2022-01-14 12:58:39,831 iteration 5014 : loss : 0.018183, loss_ce: 0.006358
2022-01-14 12:58:39,831 Training Data Eval:
2022-01-14 12:58:44,142   Average segmentation loss on training set: 0.0105
2022-01-14 12:58:44,142 Validation Data Eval:
2022-01-14 12:58:45,597   Average segmentation loss on validation set: 0.0657
2022-01-14 12:58:46,482 iteration 5015 : loss : 0.018156, loss_ce: 0.006415
 74%|█████████████████████▍       | 295/400 [1:24:12<31:26, 17.97s/it]2022-01-14 12:58:47,493 iteration 5016 : loss : 0.015397, loss_ce: 0.005941
2022-01-14 12:58:48,308 iteration 5017 : loss : 0.019742, loss_ce: 0.006592
2022-01-14 12:58:49,354 iteration 5018 : loss : 0.025176, loss_ce: 0.012188
2022-01-14 12:58:50,206 iteration 5019 : loss : 0.015447, loss_ce: 0.005551
2022-01-14 12:58:51,165 iteration 5020 : loss : 0.030266, loss_ce: 0.008447
2022-01-14 12:58:52,098 iteration 5021 : loss : 0.020350, loss_ce: 0.007112
2022-01-14 12:58:53,016 iteration 5022 : loss : 0.016482, loss_ce: 0.004714
2022-01-14 12:58:53,940 iteration 5023 : loss : 0.021721, loss_ce: 0.008451
2022-01-14 12:58:54,939 iteration 5024 : loss : 0.027542, loss_ce: 0.010911
2022-01-14 12:58:55,881 iteration 5025 : loss : 0.019520, loss_ce: 0.007366
2022-01-14 12:58:56,887 iteration 5026 : loss : 0.027952, loss_ce: 0.009618
2022-01-14 12:58:57,778 iteration 5027 : loss : 0.020451, loss_ce: 0.006957
2022-01-14 12:58:58,629 iteration 5028 : loss : 0.014955, loss_ce: 0.005976
2022-01-14 12:58:59,615 iteration 5029 : loss : 0.018342, loss_ce: 0.007786
2022-01-14 12:59:00,515 iteration 5030 : loss : 0.014176, loss_ce: 0.005759
2022-01-14 12:59:01,495 iteration 5031 : loss : 0.029909, loss_ce: 0.008366
2022-01-14 12:59:02,349 iteration 5032 : loss : 0.013230, loss_ce: 0.004478
 74%|█████████████████████▍       | 296/400 [1:24:28<30:03, 17.34s/it]2022-01-14 12:59:03,278 iteration 5033 : loss : 0.016046, loss_ce: 0.005443
2022-01-14 12:59:04,150 iteration 5034 : loss : 0.020080, loss_ce: 0.005604
2022-01-14 12:59:05,060 iteration 5035 : loss : 0.024448, loss_ce: 0.009393
2022-01-14 12:59:05,935 iteration 5036 : loss : 0.019991, loss_ce: 0.008580
2022-01-14 12:59:06,844 iteration 5037 : loss : 0.015589, loss_ce: 0.005199
2022-01-14 12:59:07,726 iteration 5038 : loss : 0.016672, loss_ce: 0.004919
2022-01-14 12:59:08,663 iteration 5039 : loss : 0.018088, loss_ce: 0.006441
2022-01-14 12:59:09,628 iteration 5040 : loss : 0.015491, loss_ce: 0.005472
2022-01-14 12:59:10,539 iteration 5041 : loss : 0.017083, loss_ce: 0.006414
2022-01-14 12:59:11,567 iteration 5042 : loss : 0.017569, loss_ce: 0.006238
2022-01-14 12:59:12,384 iteration 5043 : loss : 0.019082, loss_ce: 0.006032
2022-01-14 12:59:13,351 iteration 5044 : loss : 0.014474, loss_ce: 0.004789
2022-01-14 12:59:14,314 iteration 5045 : loss : 0.041128, loss_ce: 0.035628
2022-01-14 12:59:15,250 iteration 5046 : loss : 0.024104, loss_ce: 0.007074
2022-01-14 12:59:16,099 iteration 5047 : loss : 0.012204, loss_ce: 0.003135
2022-01-14 12:59:16,950 iteration 5048 : loss : 0.012432, loss_ce: 0.006115
2022-01-14 12:59:17,782 iteration 5049 : loss : 0.012331, loss_ce: 0.005255
 74%|█████████████████████▌       | 297/400 [1:24:43<28:46, 16.76s/it]2022-01-14 12:59:18,794 iteration 5050 : loss : 0.015246, loss_ce: 0.005035
2022-01-14 12:59:19,808 iteration 5051 : loss : 0.023336, loss_ce: 0.007341
2022-01-14 12:59:20,851 iteration 5052 : loss : 0.017307, loss_ce: 0.006713
2022-01-14 12:59:21,863 iteration 5053 : loss : 0.030333, loss_ce: 0.009944
2022-01-14 12:59:22,765 iteration 5054 : loss : 0.016096, loss_ce: 0.003549
2022-01-14 12:59:23,716 iteration 5055 : loss : 0.016445, loss_ce: 0.006160
2022-01-14 12:59:24,688 iteration 5056 : loss : 0.017499, loss_ce: 0.006930
2022-01-14 12:59:25,711 iteration 5057 : loss : 0.016743, loss_ce: 0.007714
2022-01-14 12:59:26,706 iteration 5058 : loss : 0.019788, loss_ce: 0.008049
2022-01-14 12:59:27,631 iteration 5059 : loss : 0.016648, loss_ce: 0.006499
2022-01-14 12:59:28,590 iteration 5060 : loss : 0.017120, loss_ce: 0.008172
2022-01-14 12:59:29,594 iteration 5061 : loss : 0.017977, loss_ce: 0.006876
2022-01-14 12:59:30,623 iteration 5062 : loss : 0.021684, loss_ce: 0.006825
2022-01-14 12:59:31,660 iteration 5063 : loss : 0.030811, loss_ce: 0.017100
2022-01-14 12:59:32,582 iteration 5064 : loss : 0.017662, loss_ce: 0.006038
2022-01-14 12:59:33,583 iteration 5065 : loss : 0.016553, loss_ce: 0.008048
2022-01-14 12:59:34,460 iteration 5066 : loss : 0.014592, loss_ce: 0.005513
 74%|█████████████████████▌       | 298/400 [1:25:00<28:27, 16.74s/it]2022-01-14 12:59:35,320 iteration 5067 : loss : 0.012839, loss_ce: 0.004790
2022-01-14 12:59:36,301 iteration 5068 : loss : 0.014284, loss_ce: 0.003748
2022-01-14 12:59:37,273 iteration 5069 : loss : 0.019251, loss_ce: 0.009311
2022-01-14 12:59:38,131 iteration 5070 : loss : 0.028750, loss_ce: 0.009634
2022-01-14 12:59:39,116 iteration 5071 : loss : 0.020693, loss_ce: 0.009024
2022-01-14 12:59:39,962 iteration 5072 : loss : 0.013252, loss_ce: 0.004809
2022-01-14 12:59:40,965 iteration 5073 : loss : 0.018412, loss_ce: 0.007438
2022-01-14 12:59:41,850 iteration 5074 : loss : 0.012653, loss_ce: 0.005130
2022-01-14 12:59:42,758 iteration 5075 : loss : 0.019492, loss_ce: 0.007089
2022-01-14 12:59:43,700 iteration 5076 : loss : 0.021857, loss_ce: 0.004458
2022-01-14 12:59:44,644 iteration 5077 : loss : 0.025408, loss_ce: 0.008435
2022-01-14 12:59:45,526 iteration 5078 : loss : 0.021779, loss_ce: 0.009926
2022-01-14 12:59:46,390 iteration 5079 : loss : 0.012800, loss_ce: 0.005336
2022-01-14 12:59:47,279 iteration 5080 : loss : 0.016114, loss_ce: 0.006599
2022-01-14 12:59:48,237 iteration 5081 : loss : 0.020712, loss_ce: 0.006477
2022-01-14 12:59:49,140 iteration 5082 : loss : 0.013561, loss_ce: 0.005039
2022-01-14 12:59:50,086 iteration 5083 : loss : 0.027038, loss_ce: 0.007288
 75%|█████████████████████▋       | 299/400 [1:25:15<27:37, 16.41s/it]2022-01-14 12:59:51,123 iteration 5084 : loss : 0.015558, loss_ce: 0.007112
2022-01-14 12:59:52,151 iteration 5085 : loss : 0.019566, loss_ce: 0.007189
2022-01-14 12:59:53,135 iteration 5086 : loss : 0.013000, loss_ce: 0.004211
2022-01-14 12:59:53,993 iteration 5087 : loss : 0.017486, loss_ce: 0.007703
2022-01-14 12:59:54,868 iteration 5088 : loss : 0.018194, loss_ce: 0.007228
2022-01-14 12:59:55,802 iteration 5089 : loss : 0.017748, loss_ce: 0.005027
2022-01-14 12:59:56,750 iteration 5090 : loss : 0.025214, loss_ce: 0.005077
2022-01-14 12:59:57,764 iteration 5091 : loss : 0.020564, loss_ce: 0.006347
2022-01-14 12:59:58,715 iteration 5092 : loss : 0.025386, loss_ce: 0.009734
2022-01-14 12:59:59,593 iteration 5093 : loss : 0.016234, loss_ce: 0.005134
2022-01-14 13:00:00,531 iteration 5094 : loss : 0.019573, loss_ce: 0.006750
2022-01-14 13:00:01,402 iteration 5095 : loss : 0.016040, loss_ce: 0.006384
2022-01-14 13:00:02,328 iteration 5096 : loss : 0.017757, loss_ce: 0.007571
2022-01-14 13:00:03,180 iteration 5097 : loss : 0.017177, loss_ce: 0.007025
2022-01-14 13:00:04,190 iteration 5098 : loss : 0.020188, loss_ce: 0.006221
2022-01-14 13:00:05,150 iteration 5099 : loss : 0.021448, loss_ce: 0.006806
2022-01-14 13:00:05,150 Training Data Eval:
2022-01-14 13:00:09,452   Average segmentation loss on training set: 0.0113
2022-01-14 13:00:09,452 Validation Data Eval:
2022-01-14 13:00:10,909   Average segmentation loss on validation set: 0.0649
2022-01-14 13:00:11,888 iteration 5100 : loss : 0.037578, loss_ce: 0.013115
 75%|█████████████████████▊       | 300/400 [1:25:37<30:02, 18.02s/it]2022-01-14 13:00:12,997 iteration 5101 : loss : 0.025094, loss_ce: 0.008219
2022-01-14 13:00:13,918 iteration 5102 : loss : 0.016880, loss_ce: 0.005735
2022-01-14 13:00:14,857 iteration 5103 : loss : 0.019140, loss_ce: 0.009527
2022-01-14 13:00:15,864 iteration 5104 : loss : 0.017772, loss_ce: 0.005491
2022-01-14 13:00:16,753 iteration 5105 : loss : 0.019342, loss_ce: 0.007756
2022-01-14 13:00:17,653 iteration 5106 : loss : 0.015076, loss_ce: 0.005515
2022-01-14 13:00:18,655 iteration 5107 : loss : 0.028353, loss_ce: 0.009185
2022-01-14 13:00:19,608 iteration 5108 : loss : 0.020148, loss_ce: 0.011169
2022-01-14 13:00:20,550 iteration 5109 : loss : 0.021470, loss_ce: 0.007547
2022-01-14 13:00:21,432 iteration 5110 : loss : 0.012619, loss_ce: 0.003999
2022-01-14 13:00:22,368 iteration 5111 : loss : 0.015750, loss_ce: 0.005239
2022-01-14 13:00:23,409 iteration 5112 : loss : 0.024057, loss_ce: 0.007299
2022-01-14 13:00:24,346 iteration 5113 : loss : 0.017096, loss_ce: 0.004967
2022-01-14 13:00:25,380 iteration 5114 : loss : 0.017454, loss_ce: 0.006069
2022-01-14 13:00:26,322 iteration 5115 : loss : 0.029766, loss_ce: 0.009878
2022-01-14 13:00:27,229 iteration 5116 : loss : 0.014677, loss_ce: 0.005908
2022-01-14 13:00:28,230 iteration 5117 : loss : 0.019304, loss_ce: 0.009144
 75%|█████████████████████▊       | 301/400 [1:25:54<28:54, 17.52s/it]2022-01-14 13:00:29,268 iteration 5118 : loss : 0.020503, loss_ce: 0.005641
2022-01-14 13:00:30,193 iteration 5119 : loss : 0.016055, loss_ce: 0.006456
2022-01-14 13:00:31,065 iteration 5120 : loss : 0.011714, loss_ce: 0.005031
2022-01-14 13:00:32,057 iteration 5121 : loss : 0.019118, loss_ce: 0.005512
2022-01-14 13:00:33,082 iteration 5122 : loss : 0.018126, loss_ce: 0.008094
2022-01-14 13:00:34,110 iteration 5123 : loss : 0.024730, loss_ce: 0.008489
2022-01-14 13:00:34,983 iteration 5124 : loss : 0.012190, loss_ce: 0.005755
2022-01-14 13:00:35,861 iteration 5125 : loss : 0.022333, loss_ce: 0.007953
2022-01-14 13:00:36,809 iteration 5126 : loss : 0.015551, loss_ce: 0.005709
2022-01-14 13:00:37,732 iteration 5127 : loss : 0.018914, loss_ce: 0.007602
2022-01-14 13:00:38,619 iteration 5128 : loss : 0.016052, loss_ce: 0.004883
2022-01-14 13:00:39,539 iteration 5129 : loss : 0.019536, loss_ce: 0.008601
2022-01-14 13:00:40,472 iteration 5130 : loss : 0.015276, loss_ce: 0.006325
2022-01-14 13:00:41,433 iteration 5131 : loss : 0.013521, loss_ce: 0.005352
2022-01-14 13:00:42,361 iteration 5132 : loss : 0.019016, loss_ce: 0.007024
2022-01-14 13:00:43,347 iteration 5133 : loss : 0.029296, loss_ce: 0.010575
2022-01-14 13:00:44,268 iteration 5134 : loss : 0.015898, loss_ce: 0.003816
 76%|█████████████████████▉       | 302/400 [1:26:10<27:53, 17.07s/it]2022-01-14 13:00:45,218 iteration 5135 : loss : 0.016260, loss_ce: 0.007734
2022-01-14 13:00:46,154 iteration 5136 : loss : 0.013848, loss_ce: 0.005025
2022-01-14 13:00:47,020 iteration 5137 : loss : 0.025687, loss_ce: 0.008601
2022-01-14 13:00:47,973 iteration 5138 : loss : 0.013916, loss_ce: 0.006252
2022-01-14 13:00:49,062 iteration 5139 : loss : 0.020816, loss_ce: 0.008457
2022-01-14 13:00:50,071 iteration 5140 : loss : 0.031921, loss_ce: 0.011906
2022-01-14 13:00:50,948 iteration 5141 : loss : 0.022929, loss_ce: 0.008175
2022-01-14 13:00:51,903 iteration 5142 : loss : 0.014996, loss_ce: 0.005126
2022-01-14 13:00:52,808 iteration 5143 : loss : 0.018049, loss_ce: 0.009830
2022-01-14 13:00:53,829 iteration 5144 : loss : 0.018821, loss_ce: 0.007783
2022-01-14 13:00:54,908 iteration 5145 : loss : 0.020932, loss_ce: 0.007169
2022-01-14 13:00:55,886 iteration 5146 : loss : 0.014645, loss_ce: 0.005024
2022-01-14 13:00:56,736 iteration 5147 : loss : 0.016024, loss_ce: 0.003675
2022-01-14 13:00:57,657 iteration 5148 : loss : 0.016123, loss_ce: 0.005866
2022-01-14 13:00:58,564 iteration 5149 : loss : 0.018825, loss_ce: 0.007353
2022-01-14 13:00:59,455 iteration 5150 : loss : 0.018716, loss_ce: 0.010094
2022-01-14 13:01:00,435 iteration 5151 : loss : 0.016458, loss_ce: 0.007383
 76%|█████████████████████▉       | 303/400 [1:26:26<27:10, 16.81s/it]2022-01-14 13:01:01,411 iteration 5152 : loss : 0.027755, loss_ce: 0.013641
2022-01-14 13:01:02,335 iteration 5153 : loss : 0.015043, loss_ce: 0.005451
2022-01-14 13:01:03,188 iteration 5154 : loss : 0.016716, loss_ce: 0.005714
2022-01-14 13:01:04,045 iteration 5155 : loss : 0.013604, loss_ce: 0.005152
2022-01-14 13:01:04,955 iteration 5156 : loss : 0.026956, loss_ce: 0.008857
2022-01-14 13:01:05,826 iteration 5157 : loss : 0.011262, loss_ce: 0.004161
2022-01-14 13:01:06,710 iteration 5158 : loss : 0.017638, loss_ce: 0.005907
2022-01-14 13:01:07,659 iteration 5159 : loss : 0.017842, loss_ce: 0.007244
2022-01-14 13:01:08,599 iteration 5160 : loss : 0.018132, loss_ce: 0.009213
2022-01-14 13:01:09,534 iteration 5161 : loss : 0.020802, loss_ce: 0.007021
2022-01-14 13:01:10,544 iteration 5162 : loss : 0.014734, loss_ce: 0.003991
2022-01-14 13:01:11,486 iteration 5163 : loss : 0.016636, loss_ce: 0.008574
2022-01-14 13:01:12,374 iteration 5164 : loss : 0.014504, loss_ce: 0.005043
2022-01-14 13:01:13,386 iteration 5165 : loss : 0.020784, loss_ce: 0.006189
2022-01-14 13:01:14,333 iteration 5166 : loss : 0.014868, loss_ce: 0.005461
2022-01-14 13:01:15,325 iteration 5167 : loss : 0.023434, loss_ce: 0.005892
2022-01-14 13:01:16,156 iteration 5168 : loss : 0.012069, loss_ce: 0.005641
 76%|██████████████████████       | 304/400 [1:26:42<26:21, 16.48s/it]2022-01-14 13:01:17,212 iteration 5169 : loss : 0.014534, loss_ce: 0.003987
2022-01-14 13:01:18,123 iteration 5170 : loss : 0.015389, loss_ce: 0.007221
2022-01-14 13:01:19,066 iteration 5171 : loss : 0.018801, loss_ce: 0.005487
2022-01-14 13:01:20,021 iteration 5172 : loss : 0.018649, loss_ce: 0.006784
2022-01-14 13:01:21,049 iteration 5173 : loss : 0.018865, loss_ce: 0.007713
2022-01-14 13:01:21,998 iteration 5174 : loss : 0.014132, loss_ce: 0.003648
2022-01-14 13:01:22,971 iteration 5175 : loss : 0.016413, loss_ce: 0.006244
2022-01-14 13:01:23,997 iteration 5176 : loss : 0.020459, loss_ce: 0.006405
2022-01-14 13:01:24,949 iteration 5177 : loss : 0.020063, loss_ce: 0.007560
2022-01-14 13:01:25,904 iteration 5178 : loss : 0.013213, loss_ce: 0.005523
2022-01-14 13:01:26,815 iteration 5179 : loss : 0.019378, loss_ce: 0.008755
2022-01-14 13:01:27,667 iteration 5180 : loss : 0.014750, loss_ce: 0.006543
2022-01-14 13:01:28,553 iteration 5181 : loss : 0.014264, loss_ce: 0.004352
2022-01-14 13:01:29,462 iteration 5182 : loss : 0.015487, loss_ce: 0.006494
2022-01-14 13:01:30,370 iteration 5183 : loss : 0.015647, loss_ce: 0.005778
2022-01-14 13:01:31,232 iteration 5184 : loss : 0.015909, loss_ce: 0.007277
2022-01-14 13:01:31,232 Training Data Eval:
2022-01-14 13:01:35,530   Average segmentation loss on training set: 0.0095
2022-01-14 13:01:35,531 Validation Data Eval:
2022-01-14 13:01:37,008   Average segmentation loss on validation set: 0.0698
2022-01-14 13:01:37,933 iteration 5185 : loss : 0.011788, loss_ce: 0.004508
 76%|██████████████████████       | 305/400 [1:27:03<28:36, 18.07s/it]2022-01-14 13:01:38,973 iteration 5186 : loss : 0.023412, loss_ce: 0.007295
2022-01-14 13:01:39,862 iteration 5187 : loss : 0.011663, loss_ce: 0.005050
2022-01-14 13:01:40,788 iteration 5188 : loss : 0.014638, loss_ce: 0.004248
2022-01-14 13:01:41,746 iteration 5189 : loss : 0.035401, loss_ce: 0.008511
2022-01-14 13:01:42,803 iteration 5190 : loss : 0.020764, loss_ce: 0.006672
2022-01-14 13:01:43,716 iteration 5191 : loss : 0.015278, loss_ce: 0.005126
2022-01-14 13:01:44,648 iteration 5192 : loss : 0.017935, loss_ce: 0.006449
2022-01-14 13:01:45,629 iteration 5193 : loss : 0.019431, loss_ce: 0.009477
2022-01-14 13:01:46,602 iteration 5194 : loss : 0.016341, loss_ce: 0.004216
2022-01-14 13:01:47,528 iteration 5195 : loss : 0.017270, loss_ce: 0.005019
2022-01-14 13:01:48,587 iteration 5196 : loss : 0.022528, loss_ce: 0.008442
2022-01-14 13:01:49,515 iteration 5197 : loss : 0.014201, loss_ce: 0.004407
2022-01-14 13:01:50,407 iteration 5198 : loss : 0.014060, loss_ce: 0.008088
2022-01-14 13:01:51,473 iteration 5199 : loss : 0.017455, loss_ce: 0.006248
2022-01-14 13:01:52,311 iteration 5200 : loss : 0.015319, loss_ce: 0.006129
2022-01-14 13:01:53,169 iteration 5201 : loss : 0.013621, loss_ce: 0.005561
2022-01-14 13:01:54,082 iteration 5202 : loss : 0.015990, loss_ce: 0.006296
 76%|██████████████████████▏      | 306/400 [1:27:19<27:24, 17.49s/it]2022-01-14 13:01:55,053 iteration 5203 : loss : 0.018126, loss_ce: 0.007640
2022-01-14 13:01:56,055 iteration 5204 : loss : 0.014277, loss_ce: 0.005553
2022-01-14 13:01:57,029 iteration 5205 : loss : 0.049944, loss_ce: 0.015096
2022-01-14 13:01:58,107 iteration 5206 : loss : 0.022196, loss_ce: 0.008373
2022-01-14 13:01:59,096 iteration 5207 : loss : 0.027974, loss_ce: 0.007122
2022-01-14 13:02:00,046 iteration 5208 : loss : 0.016293, loss_ce: 0.007409
2022-01-14 13:02:01,044 iteration 5209 : loss : 0.019269, loss_ce: 0.007224
2022-01-14 13:02:02,035 iteration 5210 : loss : 0.022038, loss_ce: 0.009927
2022-01-14 13:02:02,968 iteration 5211 : loss : 0.017244, loss_ce: 0.006446
2022-01-14 13:02:03,963 iteration 5212 : loss : 0.032305, loss_ce: 0.010793
2022-01-14 13:02:04,895 iteration 5213 : loss : 0.021011, loss_ce: 0.009353
2022-01-14 13:02:05,819 iteration 5214 : loss : 0.013511, loss_ce: 0.005632
2022-01-14 13:02:06,662 iteration 5215 : loss : 0.013175, loss_ce: 0.004451
2022-01-14 13:02:07,563 iteration 5216 : loss : 0.014495, loss_ce: 0.004473
2022-01-14 13:02:08,588 iteration 5217 : loss : 0.020989, loss_ce: 0.007871
2022-01-14 13:02:09,464 iteration 5218 : loss : 0.012428, loss_ce: 0.004188
2022-01-14 13:02:10,399 iteration 5219 : loss : 0.015449, loss_ce: 0.005961
 77%|██████████████████████▎      | 307/400 [1:27:36<26:34, 17.14s/it]2022-01-14 13:02:11,298 iteration 5220 : loss : 0.012580, loss_ce: 0.005358
2022-01-14 13:02:12,158 iteration 5221 : loss : 0.019693, loss_ce: 0.004353
2022-01-14 13:02:13,145 iteration 5222 : loss : 0.016747, loss_ce: 0.004724
2022-01-14 13:02:14,065 iteration 5223 : loss : 0.018408, loss_ce: 0.009119
2022-01-14 13:02:15,086 iteration 5224 : loss : 0.024752, loss_ce: 0.006498
2022-01-14 13:02:15,988 iteration 5225 : loss : 0.013913, loss_ce: 0.005790
2022-01-14 13:02:16,935 iteration 5226 : loss : 0.012605, loss_ce: 0.004997
2022-01-14 13:02:17,898 iteration 5227 : loss : 0.029883, loss_ce: 0.008454
2022-01-14 13:02:18,730 iteration 5228 : loss : 0.011666, loss_ce: 0.003611
2022-01-14 13:02:19,695 iteration 5229 : loss : 0.022004, loss_ce: 0.008061
2022-01-14 13:02:20,562 iteration 5230 : loss : 0.012801, loss_ce: 0.004525
2022-01-14 13:02:21,510 iteration 5231 : loss : 0.022579, loss_ce: 0.008779
2022-01-14 13:02:22,525 iteration 5232 : loss : 0.019217, loss_ce: 0.006310
2022-01-14 13:02:23,327 iteration 5233 : loss : 0.013717, loss_ce: 0.005671
2022-01-14 13:02:24,253 iteration 5234 : loss : 0.018777, loss_ce: 0.008104
2022-01-14 13:02:25,231 iteration 5235 : loss : 0.019347, loss_ce: 0.009006
2022-01-14 13:02:26,258 iteration 5236 : loss : 0.022112, loss_ce: 0.009262
 77%|██████████████████████▎      | 308/400 [1:27:52<25:41, 16.75s/it]2022-01-14 13:02:27,152 iteration 5237 : loss : 0.012317, loss_ce: 0.005595
2022-01-14 13:02:28,078 iteration 5238 : loss : 0.013486, loss_ce: 0.005697
2022-01-14 13:02:28,984 iteration 5239 : loss : 0.013151, loss_ce: 0.004344
2022-01-14 13:02:29,958 iteration 5240 : loss : 0.039316, loss_ce: 0.006901
2022-01-14 13:02:30,908 iteration 5241 : loss : 0.018627, loss_ce: 0.007257
2022-01-14 13:02:31,955 iteration 5242 : loss : 0.021621, loss_ce: 0.009168
2022-01-14 13:02:32,907 iteration 5243 : loss : 0.017145, loss_ce: 0.007445
2022-01-14 13:02:33,827 iteration 5244 : loss : 0.015821, loss_ce: 0.005010
2022-01-14 13:02:34,836 iteration 5245 : loss : 0.020250, loss_ce: 0.006465
2022-01-14 13:02:35,856 iteration 5246 : loss : 0.031131, loss_ce: 0.015720
2022-01-14 13:02:36,783 iteration 5247 : loss : 0.017460, loss_ce: 0.005998
2022-01-14 13:02:37,786 iteration 5248 : loss : 0.022871, loss_ce: 0.010157
2022-01-14 13:02:38,695 iteration 5249 : loss : 0.014340, loss_ce: 0.005043
2022-01-14 13:02:39,614 iteration 5250 : loss : 0.015046, loss_ce: 0.005446
2022-01-14 13:02:40,609 iteration 5251 : loss : 0.019301, loss_ce: 0.007369
2022-01-14 13:02:41,521 iteration 5252 : loss : 0.013142, loss_ce: 0.006370
2022-01-14 13:02:42,412 iteration 5253 : loss : 0.011594, loss_ce: 0.004182
 77%|██████████████████████▍      | 309/400 [1:28:08<25:08, 16.58s/it]2022-01-14 13:02:43,384 iteration 5254 : loss : 0.014135, loss_ce: 0.006298
2022-01-14 13:02:44,366 iteration 5255 : loss : 0.016671, loss_ce: 0.004221
2022-01-14 13:02:45,312 iteration 5256 : loss : 0.020267, loss_ce: 0.008414
2022-01-14 13:02:46,252 iteration 5257 : loss : 0.016603, loss_ce: 0.005608
2022-01-14 13:02:47,100 iteration 5258 : loss : 0.014481, loss_ce: 0.005984
2022-01-14 13:02:47,998 iteration 5259 : loss : 0.023663, loss_ce: 0.008855
2022-01-14 13:02:49,024 iteration 5260 : loss : 0.028228, loss_ce: 0.009133
2022-01-14 13:02:49,950 iteration 5261 : loss : 0.016863, loss_ce: 0.007119
2022-01-14 13:02:50,852 iteration 5262 : loss : 0.016620, loss_ce: 0.006779
2022-01-14 13:02:51,816 iteration 5263 : loss : 0.017509, loss_ce: 0.006736
2022-01-14 13:02:52,784 iteration 5264 : loss : 0.019719, loss_ce: 0.007885
2022-01-14 13:02:53,764 iteration 5265 : loss : 0.018376, loss_ce: 0.007679
2022-01-14 13:02:54,661 iteration 5266 : loss : 0.014108, loss_ce: 0.005404
2022-01-14 13:02:55,688 iteration 5267 : loss : 0.025520, loss_ce: 0.011575
2022-01-14 13:02:56,485 iteration 5268 : loss : 0.011686, loss_ce: 0.002596
2022-01-14 13:02:57,291 iteration 5269 : loss : 0.016529, loss_ce: 0.005819
2022-01-14 13:02:57,292 Training Data Eval:
2022-01-14 13:03:01,602   Average segmentation loss on training set: 0.0099
2022-01-14 13:03:01,603 Validation Data Eval:
2022-01-14 13:03:03,058   Average segmentation loss on validation set: 0.0660
2022-01-14 13:03:03,950 iteration 5270 : loss : 0.019652, loss_ce: 0.002792
 78%|██████████████████████▍      | 310/400 [1:28:29<27:05, 18.06s/it]2022-01-14 13:03:05,054 iteration 5271 : loss : 0.020089, loss_ce: 0.007451
2022-01-14 13:03:06,079 iteration 5272 : loss : 0.024717, loss_ce: 0.009889
2022-01-14 13:03:07,004 iteration 5273 : loss : 0.018508, loss_ce: 0.007836
2022-01-14 13:03:07,946 iteration 5274 : loss : 0.017304, loss_ce: 0.006665
2022-01-14 13:03:08,838 iteration 5275 : loss : 0.014142, loss_ce: 0.005607
2022-01-14 13:03:09,733 iteration 5276 : loss : 0.020813, loss_ce: 0.008661
2022-01-14 13:03:10,746 iteration 5277 : loss : 0.021739, loss_ce: 0.010113
2022-01-14 13:03:11,666 iteration 5278 : loss : 0.021022, loss_ce: 0.005354
2022-01-14 13:03:12,627 iteration 5279 : loss : 0.019840, loss_ce: 0.006603
2022-01-14 13:03:13,496 iteration 5280 : loss : 0.015997, loss_ce: 0.005283
2022-01-14 13:03:14,383 iteration 5281 : loss : 0.013138, loss_ce: 0.006257
2022-01-14 13:03:15,274 iteration 5282 : loss : 0.013922, loss_ce: 0.005336
2022-01-14 13:03:16,142 iteration 5283 : loss : 0.014337, loss_ce: 0.005654
2022-01-14 13:03:17,077 iteration 5284 : loss : 0.013938, loss_ce: 0.005211
2022-01-14 13:03:17,971 iteration 5285 : loss : 0.012945, loss_ce: 0.004546
2022-01-14 13:03:18,843 iteration 5286 : loss : 0.017377, loss_ce: 0.008085
2022-01-14 13:03:19,768 iteration 5287 : loss : 0.014391, loss_ce: 0.005458
 78%|██████████████████████▌      | 311/400 [1:28:45<25:47, 17.39s/it]2022-01-14 13:03:20,770 iteration 5288 : loss : 0.018131, loss_ce: 0.007515
2022-01-14 13:03:21,633 iteration 5289 : loss : 0.034483, loss_ce: 0.015511
2022-01-14 13:03:22,711 iteration 5290 : loss : 0.016788, loss_ce: 0.004536
2022-01-14 13:03:23,658 iteration 5291 : loss : 0.021421, loss_ce: 0.007884
2022-01-14 13:03:24,629 iteration 5292 : loss : 0.026258, loss_ce: 0.004910
2022-01-14 13:03:25,516 iteration 5293 : loss : 0.017612, loss_ce: 0.007287
2022-01-14 13:03:26,497 iteration 5294 : loss : 0.022705, loss_ce: 0.007157
2022-01-14 13:03:27,440 iteration 5295 : loss : 0.021706, loss_ce: 0.006913
2022-01-14 13:03:28,298 iteration 5296 : loss : 0.015906, loss_ce: 0.004620
2022-01-14 13:03:29,200 iteration 5297 : loss : 0.029583, loss_ce: 0.007127
2022-01-14 13:03:30,081 iteration 5298 : loss : 0.013681, loss_ce: 0.006039
2022-01-14 13:03:30,985 iteration 5299 : loss : 0.018145, loss_ce: 0.003175
2022-01-14 13:03:31,873 iteration 5300 : loss : 0.013151, loss_ce: 0.004844
2022-01-14 13:03:32,772 iteration 5301 : loss : 0.015014, loss_ce: 0.003516
2022-01-14 13:03:33,769 iteration 5302 : loss : 0.018756, loss_ce: 0.007979
2022-01-14 13:03:34,743 iteration 5303 : loss : 0.013879, loss_ce: 0.006642
2022-01-14 13:03:35,662 iteration 5304 : loss : 0.020431, loss_ce: 0.011461
 78%|██████████████████████▌      | 312/400 [1:29:01<24:50, 16.94s/it]2022-01-14 13:03:36,571 iteration 5305 : loss : 0.012767, loss_ce: 0.004148
2022-01-14 13:03:37,520 iteration 5306 : loss : 0.028029, loss_ce: 0.012039
2022-01-14 13:03:38,473 iteration 5307 : loss : 0.013743, loss_ce: 0.004883
2022-01-14 13:03:39,389 iteration 5308 : loss : 0.016111, loss_ce: 0.005543
2022-01-14 13:03:40,330 iteration 5309 : loss : 0.022598, loss_ce: 0.011804
2022-01-14 13:03:41,386 iteration 5310 : loss : 0.014459, loss_ce: 0.004631
2022-01-14 13:03:42,305 iteration 5311 : loss : 0.019459, loss_ce: 0.007842
2022-01-14 13:03:43,316 iteration 5312 : loss : 0.021407, loss_ce: 0.009699
2022-01-14 13:03:44,230 iteration 5313 : loss : 0.017242, loss_ce: 0.008339
2022-01-14 13:03:45,161 iteration 5314 : loss : 0.012344, loss_ce: 0.003427
2022-01-14 13:03:46,052 iteration 5315 : loss : 0.016505, loss_ce: 0.005625
2022-01-14 13:03:46,961 iteration 5316 : loss : 0.026692, loss_ce: 0.007021
2022-01-14 13:03:47,862 iteration 5317 : loss : 0.013984, loss_ce: 0.003972
2022-01-14 13:03:48,852 iteration 5318 : loss : 0.017921, loss_ce: 0.006487
2022-01-14 13:03:49,773 iteration 5319 : loss : 0.022184, loss_ce: 0.007748
2022-01-14 13:03:50,636 iteration 5320 : loss : 0.016410, loss_ce: 0.005544
2022-01-14 13:03:51,526 iteration 5321 : loss : 0.021064, loss_ce: 0.008873
 78%|██████████████████████▋      | 313/400 [1:29:17<24:05, 16.62s/it]2022-01-14 13:03:52,450 iteration 5322 : loss : 0.014599, loss_ce: 0.005320
2022-01-14 13:03:53,408 iteration 5323 : loss : 0.023079, loss_ce: 0.006495
2022-01-14 13:03:54,310 iteration 5324 : loss : 0.018664, loss_ce: 0.005827
2022-01-14 13:03:55,300 iteration 5325 : loss : 0.029874, loss_ce: 0.012097
2022-01-14 13:03:56,245 iteration 5326 : loss : 0.018198, loss_ce: 0.006648
2022-01-14 13:03:57,177 iteration 5327 : loss : 0.018752, loss_ce: 0.007065
2022-01-14 13:03:58,123 iteration 5328 : loss : 0.013114, loss_ce: 0.004799
2022-01-14 13:03:59,085 iteration 5329 : loss : 0.018500, loss_ce: 0.009388
2022-01-14 13:04:00,071 iteration 5330 : loss : 0.016322, loss_ce: 0.005612
2022-01-14 13:04:00,933 iteration 5331 : loss : 0.015917, loss_ce: 0.005756
2022-01-14 13:04:01,823 iteration 5332 : loss : 0.021201, loss_ce: 0.008605
2022-01-14 13:04:02,741 iteration 5333 : loss : 0.025289, loss_ce: 0.009159
2022-01-14 13:04:03,637 iteration 5334 : loss : 0.013942, loss_ce: 0.004096
2022-01-14 13:04:04,637 iteration 5335 : loss : 0.055206, loss_ce: 0.022098
2022-01-14 13:04:05,584 iteration 5336 : loss : 0.028366, loss_ce: 0.010450
2022-01-14 13:04:06,490 iteration 5337 : loss : 0.016755, loss_ce: 0.006315
2022-01-14 13:04:07,327 iteration 5338 : loss : 0.013244, loss_ce: 0.004836
 78%|██████████████████████▊      | 314/400 [1:29:33<23:28, 16.37s/it]2022-01-14 13:04:08,301 iteration 5339 : loss : 0.016361, loss_ce: 0.005922
2022-01-14 13:04:09,208 iteration 5340 : loss : 0.014298, loss_ce: 0.007748
2022-01-14 13:04:10,170 iteration 5341 : loss : 0.017382, loss_ce: 0.006840
2022-01-14 13:04:11,144 iteration 5342 : loss : 0.024119, loss_ce: 0.007061
2022-01-14 13:04:12,038 iteration 5343 : loss : 0.018419, loss_ce: 0.006785
2022-01-14 13:04:12,929 iteration 5344 : loss : 0.016702, loss_ce: 0.007503
2022-01-14 13:04:13,776 iteration 5345 : loss : 0.014898, loss_ce: 0.004499
2022-01-14 13:04:14,675 iteration 5346 : loss : 0.017960, loss_ce: 0.006389
2022-01-14 13:04:15,678 iteration 5347 : loss : 0.018128, loss_ce: 0.007617
2022-01-14 13:04:16,640 iteration 5348 : loss : 0.018357, loss_ce: 0.007215
2022-01-14 13:04:17,574 iteration 5349 : loss : 0.017923, loss_ce: 0.008532
2022-01-14 13:04:18,431 iteration 5350 : loss : 0.011858, loss_ce: 0.004202
2022-01-14 13:04:19,407 iteration 5351 : loss : 0.027518, loss_ce: 0.004964
2022-01-14 13:04:20,346 iteration 5352 : loss : 0.016350, loss_ce: 0.006985
2022-01-14 13:04:21,301 iteration 5353 : loss : 0.015892, loss_ce: 0.006452
2022-01-14 13:04:22,177 iteration 5354 : loss : 0.016410, loss_ce: 0.006958
2022-01-14 13:04:22,177 Training Data Eval:
2022-01-14 13:04:26,483   Average segmentation loss on training set: 0.0104
2022-01-14 13:04:26,483 Validation Data Eval:
2022-01-14 13:04:27,926   Average segmentation loss on validation set: 0.0683
2022-01-14 13:04:28,781 iteration 5355 : loss : 0.012306, loss_ce: 0.004618
 79%|██████████████████████▊      | 315/400 [1:29:54<25:21, 17.90s/it]2022-01-14 13:04:29,804 iteration 5356 : loss : 0.023062, loss_ce: 0.011896
2022-01-14 13:04:30,637 iteration 5357 : loss : 0.011680, loss_ce: 0.003439
2022-01-14 13:04:31,559 iteration 5358 : loss : 0.012316, loss_ce: 0.003179
2022-01-14 13:04:32,459 iteration 5359 : loss : 0.015113, loss_ce: 0.008739
2022-01-14 13:04:33,370 iteration 5360 : loss : 0.015168, loss_ce: 0.005380
2022-01-14 13:04:34,382 iteration 5361 : loss : 0.019523, loss_ce: 0.006682
2022-01-14 13:04:35,374 iteration 5362 : loss : 0.017313, loss_ce: 0.010206
2022-01-14 13:04:36,305 iteration 5363 : loss : 0.015284, loss_ce: 0.006260
2022-01-14 13:04:37,121 iteration 5364 : loss : 0.015712, loss_ce: 0.002283
2022-01-14 13:04:38,103 iteration 5365 : loss : 0.014806, loss_ce: 0.005162
2022-01-14 13:04:38,967 iteration 5366 : loss : 0.016736, loss_ce: 0.005844
2022-01-14 13:04:39,928 iteration 5367 : loss : 0.017229, loss_ce: 0.005164
2022-01-14 13:04:40,961 iteration 5368 : loss : 0.032739, loss_ce: 0.013333
2022-01-14 13:04:41,913 iteration 5369 : loss : 0.024543, loss_ce: 0.010659
2022-01-14 13:04:42,847 iteration 5370 : loss : 0.019626, loss_ce: 0.005972
2022-01-14 13:04:43,878 iteration 5371 : loss : 0.017628, loss_ce: 0.005062
2022-01-14 13:04:44,776 iteration 5372 : loss : 0.023104, loss_ce: 0.010394
 79%|██████████████████████▉      | 316/400 [1:30:10<24:15, 17.33s/it]2022-01-14 13:04:45,677 iteration 5373 : loss : 0.013317, loss_ce: 0.005763
2022-01-14 13:04:46,631 iteration 5374 : loss : 0.024688, loss_ce: 0.007986
2022-01-14 13:04:47,501 iteration 5375 : loss : 0.017318, loss_ce: 0.007149
2022-01-14 13:04:48,358 iteration 5376 : loss : 0.013309, loss_ce: 0.004284
2022-01-14 13:04:49,164 iteration 5377 : loss : 0.021350, loss_ce: 0.003370
2022-01-14 13:04:49,969 iteration 5378 : loss : 0.011454, loss_ce: 0.004313
2022-01-14 13:04:50,915 iteration 5379 : loss : 0.020078, loss_ce: 0.006446
2022-01-14 13:04:51,801 iteration 5380 : loss : 0.014784, loss_ce: 0.006103
2022-01-14 13:04:52,724 iteration 5381 : loss : 0.018638, loss_ce: 0.007211
2022-01-14 13:04:53,698 iteration 5382 : loss : 0.020810, loss_ce: 0.005991
2022-01-14 13:04:54,695 iteration 5383 : loss : 0.022423, loss_ce: 0.010386
2022-01-14 13:04:55,607 iteration 5384 : loss : 0.014199, loss_ce: 0.006513
2022-01-14 13:04:56,531 iteration 5385 : loss : 0.018540, loss_ce: 0.008178
2022-01-14 13:04:57,509 iteration 5386 : loss : 0.018884, loss_ce: 0.007252
2022-01-14 13:04:58,432 iteration 5387 : loss : 0.016771, loss_ce: 0.006878
2022-01-14 13:04:59,273 iteration 5388 : loss : 0.013709, loss_ce: 0.005464
2022-01-14 13:05:00,173 iteration 5389 : loss : 0.013990, loss_ce: 0.004989
 79%|██████████████████████▉      | 317/400 [1:30:26<23:09, 16.75s/it]2022-01-14 13:05:01,240 iteration 5390 : loss : 0.036842, loss_ce: 0.011172
2022-01-14 13:05:02,065 iteration 5391 : loss : 0.014450, loss_ce: 0.004809
2022-01-14 13:05:02,996 iteration 5392 : loss : 0.014304, loss_ce: 0.006131
2022-01-14 13:05:03,973 iteration 5393 : loss : 0.032631, loss_ce: 0.010091
2022-01-14 13:05:04,890 iteration 5394 : loss : 0.015816, loss_ce: 0.006276
2022-01-14 13:05:05,753 iteration 5395 : loss : 0.014050, loss_ce: 0.006236
2022-01-14 13:05:06,732 iteration 5396 : loss : 0.019478, loss_ce: 0.006104
2022-01-14 13:05:07,666 iteration 5397 : loss : 0.018287, loss_ce: 0.007659
2022-01-14 13:05:08,483 iteration 5398 : loss : 0.011221, loss_ce: 0.005461
2022-01-14 13:05:09,383 iteration 5399 : loss : 0.012817, loss_ce: 0.005504
2022-01-14 13:05:10,394 iteration 5400 : loss : 0.020793, loss_ce: 0.006307
2022-01-14 13:05:11,347 iteration 5401 : loss : 0.014831, loss_ce: 0.004497
2022-01-14 13:05:12,266 iteration 5402 : loss : 0.014354, loss_ce: 0.005160
2022-01-14 13:05:13,234 iteration 5403 : loss : 0.022590, loss_ce: 0.008393
2022-01-14 13:05:14,128 iteration 5404 : loss : 0.015369, loss_ce: 0.007243
2022-01-14 13:05:14,987 iteration 5405 : loss : 0.015427, loss_ce: 0.005122
2022-01-14 13:05:15,816 iteration 5406 : loss : 0.016319, loss_ce: 0.003790
 80%|███████████████████████      | 318/400 [1:30:41<22:26, 16.42s/it]2022-01-14 13:05:16,889 iteration 5407 : loss : 0.019843, loss_ce: 0.005363
2022-01-14 13:05:17,784 iteration 5408 : loss : 0.016665, loss_ce: 0.004643
2022-01-14 13:05:18,656 iteration 5409 : loss : 0.011680, loss_ce: 0.005555
2022-01-14 13:05:19,578 iteration 5410 : loss : 0.016937, loss_ce: 0.005654
2022-01-14 13:05:20,508 iteration 5411 : loss : 0.017087, loss_ce: 0.006023
2022-01-14 13:05:21,484 iteration 5412 : loss : 0.023820, loss_ce: 0.010268
2022-01-14 13:05:22,339 iteration 5413 : loss : 0.015875, loss_ce: 0.006004
2022-01-14 13:05:23,318 iteration 5414 : loss : 0.027257, loss_ce: 0.009018
2022-01-14 13:05:24,220 iteration 5415 : loss : 0.018466, loss_ce: 0.006467
2022-01-14 13:05:25,202 iteration 5416 : loss : 0.021366, loss_ce: 0.009673
2022-01-14 13:05:26,091 iteration 5417 : loss : 0.018934, loss_ce: 0.007269
2022-01-14 13:05:27,001 iteration 5418 : loss : 0.012825, loss_ce: 0.004111
2022-01-14 13:05:27,897 iteration 5419 : loss : 0.013556, loss_ce: 0.005749
2022-01-14 13:05:28,835 iteration 5420 : loss : 0.019384, loss_ce: 0.008080
2022-01-14 13:05:29,807 iteration 5421 : loss : 0.023820, loss_ce: 0.007594
2022-01-14 13:05:30,754 iteration 5422 : loss : 0.020413, loss_ce: 0.006504
2022-01-14 13:05:31,743 iteration 5423 : loss : 0.024983, loss_ce: 0.008085
 80%|███████████████████████▏     | 319/400 [1:30:57<21:57, 16.27s/it]2022-01-14 13:05:32,756 iteration 5424 : loss : 0.026773, loss_ce: 0.011698
2022-01-14 13:05:33,704 iteration 5425 : loss : 0.020865, loss_ce: 0.007701
2022-01-14 13:05:34,663 iteration 5426 : loss : 0.014324, loss_ce: 0.004003
2022-01-14 13:05:35,721 iteration 5427 : loss : 0.029157, loss_ce: 0.010027
2022-01-14 13:05:36,728 iteration 5428 : loss : 0.021737, loss_ce: 0.008277
2022-01-14 13:05:37,604 iteration 5429 : loss : 0.018287, loss_ce: 0.006836
2022-01-14 13:05:38,443 iteration 5430 : loss : 0.014232, loss_ce: 0.005705
2022-01-14 13:05:39,444 iteration 5431 : loss : 0.020622, loss_ce: 0.007482
2022-01-14 13:05:40,342 iteration 5432 : loss : 0.017074, loss_ce: 0.005671
2022-01-14 13:05:41,401 iteration 5433 : loss : 0.023808, loss_ce: 0.008980
2022-01-14 13:05:42,426 iteration 5434 : loss : 0.021715, loss_ce: 0.006677
2022-01-14 13:05:43,392 iteration 5435 : loss : 0.017742, loss_ce: 0.007322
2022-01-14 13:05:44,397 iteration 5436 : loss : 0.020058, loss_ce: 0.010583
2022-01-14 13:05:45,288 iteration 5437 : loss : 0.016432, loss_ce: 0.004209
2022-01-14 13:05:46,211 iteration 5438 : loss : 0.015995, loss_ce: 0.006960
2022-01-14 13:05:47,180 iteration 5439 : loss : 0.017417, loss_ce: 0.005806
2022-01-14 13:05:47,180 Training Data Eval:
2022-01-14 13:05:51,478   Average segmentation loss on training set: 0.0106
2022-01-14 13:05:51,478 Validation Data Eval:
2022-01-14 13:05:52,936   Average segmentation loss on validation set: 0.0695
2022-01-14 13:05:53,869 iteration 5440 : loss : 0.013890, loss_ce: 0.004840
 80%|███████████████████████▏     | 320/400 [1:31:19<24:02, 18.03s/it]2022-01-14 13:05:54,798 iteration 5441 : loss : 0.013982, loss_ce: 0.006053
2022-01-14 13:05:55,856 iteration 5442 : loss : 0.027985, loss_ce: 0.010020
2022-01-14 13:05:56,828 iteration 5443 : loss : 0.019572, loss_ce: 0.007826
2022-01-14 13:05:57,756 iteration 5444 : loss : 0.017425, loss_ce: 0.008295
2022-01-14 13:05:58,656 iteration 5445 : loss : 0.019912, loss_ce: 0.008234
2022-01-14 13:05:59,580 iteration 5446 : loss : 0.020572, loss_ce: 0.010244
2022-01-14 13:06:00,429 iteration 5447 : loss : 0.014095, loss_ce: 0.002487
2022-01-14 13:06:01,386 iteration 5448 : loss : 0.021089, loss_ce: 0.006969
2022-01-14 13:06:02,286 iteration 5449 : loss : 0.013024, loss_ce: 0.003664
2022-01-14 13:06:03,171 iteration 5450 : loss : 0.017160, loss_ce: 0.005247
2022-01-14 13:06:04,095 iteration 5451 : loss : 0.014054, loss_ce: 0.004085
2022-01-14 13:06:05,032 iteration 5452 : loss : 0.011536, loss_ce: 0.004330
2022-01-14 13:06:05,983 iteration 5453 : loss : 0.014607, loss_ce: 0.004980
2022-01-14 13:06:06,936 iteration 5454 : loss : 0.021565, loss_ce: 0.009375
2022-01-14 13:06:07,868 iteration 5455 : loss : 0.021196, loss_ce: 0.012474
2022-01-14 13:06:08,830 iteration 5456 : loss : 0.015473, loss_ce: 0.004919
2022-01-14 13:06:09,775 iteration 5457 : loss : 0.020906, loss_ce: 0.010318
 80%|███████████████████████▎     | 321/400 [1:31:35<22:53, 17.39s/it]2022-01-14 13:06:10,856 iteration 5458 : loss : 0.021642, loss_ce: 0.005495
2022-01-14 13:06:11,733 iteration 5459 : loss : 0.013031, loss_ce: 0.004294
2022-01-14 13:06:12,646 iteration 5460 : loss : 0.018358, loss_ce: 0.007432
2022-01-14 13:06:13,605 iteration 5461 : loss : 0.017112, loss_ce: 0.006572
2022-01-14 13:06:14,590 iteration 5462 : loss : 0.021182, loss_ce: 0.010058
2022-01-14 13:06:15,473 iteration 5463 : loss : 0.010419, loss_ce: 0.003329
2022-01-14 13:06:16,547 iteration 5464 : loss : 0.022775, loss_ce: 0.008511
2022-01-14 13:06:17,443 iteration 5465 : loss : 0.016452, loss_ce: 0.006076
2022-01-14 13:06:18,319 iteration 5466 : loss : 0.012447, loss_ce: 0.004662
2022-01-14 13:06:19,327 iteration 5467 : loss : 0.012653, loss_ce: 0.004211
2022-01-14 13:06:20,323 iteration 5468 : loss : 0.015662, loss_ce: 0.007269
2022-01-14 13:06:21,319 iteration 5469 : loss : 0.019730, loss_ce: 0.006838
2022-01-14 13:06:22,225 iteration 5470 : loss : 0.013986, loss_ce: 0.006080
2022-01-14 13:06:23,126 iteration 5471 : loss : 0.014183, loss_ce: 0.007215
2022-01-14 13:06:24,127 iteration 5472 : loss : 0.016469, loss_ce: 0.007123
2022-01-14 13:06:25,009 iteration 5473 : loss : 0.013712, loss_ce: 0.003684
2022-01-14 13:06:26,005 iteration 5474 : loss : 0.012691, loss_ce: 0.003901
 80%|███████████████████████▎     | 322/400 [1:31:51<22:09, 17.04s/it]2022-01-14 13:06:26,937 iteration 5475 : loss : 0.015875, loss_ce: 0.006286
2022-01-14 13:06:27,852 iteration 5476 : loss : 0.012965, loss_ce: 0.005506
2022-01-14 13:06:28,829 iteration 5477 : loss : 0.012486, loss_ce: 0.004424
2022-01-14 13:06:29,815 iteration 5478 : loss : 0.018311, loss_ce: 0.007504
2022-01-14 13:06:30,712 iteration 5479 : loss : 0.016371, loss_ce: 0.004233
2022-01-14 13:06:31,620 iteration 5480 : loss : 0.020241, loss_ce: 0.004020
2022-01-14 13:06:32,566 iteration 5481 : loss : 0.021724, loss_ce: 0.008718
2022-01-14 13:06:33,489 iteration 5482 : loss : 0.019306, loss_ce: 0.007386
2022-01-14 13:06:34,367 iteration 5483 : loss : 0.016281, loss_ce: 0.005728
2022-01-14 13:06:35,351 iteration 5484 : loss : 0.018676, loss_ce: 0.007775
2022-01-14 13:06:36,211 iteration 5485 : loss : 0.012619, loss_ce: 0.005821
2022-01-14 13:06:37,276 iteration 5486 : loss : 0.019459, loss_ce: 0.008441
2022-01-14 13:06:38,138 iteration 5487 : loss : 0.014903, loss_ce: 0.007889
2022-01-14 13:06:39,114 iteration 5488 : loss : 0.017350, loss_ce: 0.005302
2022-01-14 13:06:39,989 iteration 5489 : loss : 0.014959, loss_ce: 0.003932
2022-01-14 13:06:40,964 iteration 5490 : loss : 0.017220, loss_ce: 0.006454
2022-01-14 13:06:41,835 iteration 5491 : loss : 0.015286, loss_ce: 0.005107
 81%|███████████████████████▍     | 323/400 [1:32:07<21:24, 16.68s/it]2022-01-14 13:06:42,870 iteration 5492 : loss : 0.017664, loss_ce: 0.007634
2022-01-14 13:06:43,734 iteration 5493 : loss : 0.012813, loss_ce: 0.004322
2022-01-14 13:06:44,631 iteration 5494 : loss : 0.014221, loss_ce: 0.006429
2022-01-14 13:06:45,630 iteration 5495 : loss : 0.021101, loss_ce: 0.005072
2022-01-14 13:06:46,500 iteration 5496 : loss : 0.015755, loss_ce: 0.004914
2022-01-14 13:06:47,427 iteration 5497 : loss : 0.022363, loss_ce: 0.008275
2022-01-14 13:06:48,408 iteration 5498 : loss : 0.014058, loss_ce: 0.005746
2022-01-14 13:06:49,339 iteration 5499 : loss : 0.015211, loss_ce: 0.004131
2022-01-14 13:06:50,247 iteration 5500 : loss : 0.012499, loss_ce: 0.004079
2022-01-14 13:06:51,146 iteration 5501 : loss : 0.012905, loss_ce: 0.004519
2022-01-14 13:06:52,035 iteration 5502 : loss : 0.015496, loss_ce: 0.008277
2022-01-14 13:06:53,068 iteration 5503 : loss : 0.022269, loss_ce: 0.006815
2022-01-14 13:06:54,031 iteration 5504 : loss : 0.015294, loss_ce: 0.006428
2022-01-14 13:06:54,888 iteration 5505 : loss : 0.013395, loss_ce: 0.004822
2022-01-14 13:06:55,771 iteration 5506 : loss : 0.012822, loss_ce: 0.004641
2022-01-14 13:06:56,777 iteration 5507 : loss : 0.020131, loss_ce: 0.007324
2022-01-14 13:06:57,749 iteration 5508 : loss : 0.019263, loss_ce: 0.008170
 81%|███████████████████████▍     | 324/400 [1:32:23<20:50, 16.45s/it]2022-01-14 13:06:58,766 iteration 5509 : loss : 0.019790, loss_ce: 0.009820
2022-01-14 13:06:59,671 iteration 5510 : loss : 0.016170, loss_ce: 0.006458
2022-01-14 13:07:00,606 iteration 5511 : loss : 0.021851, loss_ce: 0.006696
2022-01-14 13:07:01,533 iteration 5512 : loss : 0.017032, loss_ce: 0.007270
2022-01-14 13:07:02,463 iteration 5513 : loss : 0.012975, loss_ce: 0.006669
2022-01-14 13:07:03,449 iteration 5514 : loss : 0.020577, loss_ce: 0.007980
2022-01-14 13:07:04,370 iteration 5515 : loss : 0.011763, loss_ce: 0.004269
2022-01-14 13:07:05,295 iteration 5516 : loss : 0.015015, loss_ce: 0.007282
2022-01-14 13:07:06,262 iteration 5517 : loss : 0.016156, loss_ce: 0.005067
2022-01-14 13:07:07,113 iteration 5518 : loss : 0.012183, loss_ce: 0.003898
2022-01-14 13:07:08,102 iteration 5519 : loss : 0.024700, loss_ce: 0.006739
2022-01-14 13:07:09,024 iteration 5520 : loss : 0.014227, loss_ce: 0.001908
2022-01-14 13:07:10,050 iteration 5521 : loss : 0.023309, loss_ce: 0.010058
2022-01-14 13:07:10,958 iteration 5522 : loss : 0.020245, loss_ce: 0.007047
2022-01-14 13:07:11,938 iteration 5523 : loss : 0.031343, loss_ce: 0.014166
2022-01-14 13:07:12,923 iteration 5524 : loss : 0.025980, loss_ce: 0.010605
2022-01-14 13:07:12,924 Training Data Eval:
2022-01-14 13:07:17,224   Average segmentation loss on training set: 0.0096
2022-01-14 13:07:17,224 Validation Data Eval:
2022-01-14 13:07:18,674   Average segmentation loss on validation set: 0.0624
2022-01-14 13:07:19,718 iteration 5525 : loss : 0.020867, loss_ce: 0.009243
 81%|███████████████████████▌     | 325/400 [1:32:45<22:37, 18.11s/it]2022-01-14 13:07:20,715 iteration 5526 : loss : 0.018111, loss_ce: 0.005548
2022-01-14 13:07:21,575 iteration 5527 : loss : 0.013325, loss_ce: 0.005560
2022-01-14 13:07:22,588 iteration 5528 : loss : 0.023748, loss_ce: 0.008160
2022-01-14 13:07:23,494 iteration 5529 : loss : 0.013567, loss_ce: 0.004872
2022-01-14 13:07:24,367 iteration 5530 : loss : 0.014365, loss_ce: 0.006101
2022-01-14 13:07:25,194 iteration 5531 : loss : 0.012445, loss_ce: 0.003974
2022-01-14 13:07:26,058 iteration 5532 : loss : 0.016664, loss_ce: 0.006421
2022-01-14 13:07:27,003 iteration 5533 : loss : 0.015474, loss_ce: 0.007729
2022-01-14 13:07:27,855 iteration 5534 : loss : 0.012530, loss_ce: 0.004569
2022-01-14 13:07:28,753 iteration 5535 : loss : 0.018310, loss_ce: 0.007397
2022-01-14 13:07:29,702 iteration 5536 : loss : 0.017173, loss_ce: 0.005308
2022-01-14 13:07:30,677 iteration 5537 : loss : 0.017303, loss_ce: 0.007544
2022-01-14 13:07:31,702 iteration 5538 : loss : 0.018252, loss_ce: 0.004936
2022-01-14 13:07:32,625 iteration 5539 : loss : 0.015346, loss_ce: 0.005863
2022-01-14 13:07:33,483 iteration 5540 : loss : 0.013663, loss_ce: 0.005888
2022-01-14 13:07:34,501 iteration 5541 : loss : 0.022942, loss_ce: 0.010294
2022-01-14 13:07:35,444 iteration 5542 : loss : 0.017419, loss_ce: 0.007198
 82%|███████████████████████▋     | 326/400 [1:33:01<21:26, 17.39s/it]2022-01-14 13:07:36,471 iteration 5543 : loss : 0.018107, loss_ce: 0.008224
2022-01-14 13:07:37,366 iteration 5544 : loss : 0.013139, loss_ce: 0.004412
2022-01-14 13:07:38,323 iteration 5545 : loss : 0.019382, loss_ce: 0.007903
2022-01-14 13:07:39,370 iteration 5546 : loss : 0.043902, loss_ce: 0.009612
2022-01-14 13:07:40,333 iteration 5547 : loss : 0.015473, loss_ce: 0.005784
2022-01-14 13:07:41,240 iteration 5548 : loss : 0.020982, loss_ce: 0.005005
2022-01-14 13:07:42,132 iteration 5549 : loss : 0.011935, loss_ce: 0.003304
2022-01-14 13:07:43,093 iteration 5550 : loss : 0.020190, loss_ce: 0.007172
2022-01-14 13:07:43,995 iteration 5551 : loss : 0.025049, loss_ce: 0.012158
2022-01-14 13:07:44,795 iteration 5552 : loss : 0.012674, loss_ce: 0.004527
2022-01-14 13:07:45,738 iteration 5553 : loss : 0.016075, loss_ce: 0.006113
2022-01-14 13:07:46,648 iteration 5554 : loss : 0.014749, loss_ce: 0.006390
2022-01-14 13:07:47,487 iteration 5555 : loss : 0.013236, loss_ce: 0.005722
2022-01-14 13:07:48,480 iteration 5556 : loss : 0.021195, loss_ce: 0.009454
2022-01-14 13:07:49,442 iteration 5557 : loss : 0.012323, loss_ce: 0.005496
2022-01-14 13:07:50,377 iteration 5558 : loss : 0.023081, loss_ce: 0.007160
2022-01-14 13:07:51,299 iteration 5559 : loss : 0.025970, loss_ce: 0.007654
 82%|███████████████████████▋     | 327/400 [1:33:17<20:36, 16.93s/it]2022-01-14 13:07:52,307 iteration 5560 : loss : 0.019202, loss_ce: 0.006814
2022-01-14 13:07:53,198 iteration 5561 : loss : 0.014373, loss_ce: 0.005233
2022-01-14 13:07:54,110 iteration 5562 : loss : 0.015539, loss_ce: 0.006961
2022-01-14 13:07:55,022 iteration 5563 : loss : 0.022146, loss_ce: 0.009919
2022-01-14 13:07:55,980 iteration 5564 : loss : 0.016717, loss_ce: 0.007706
2022-01-14 13:07:56,965 iteration 5565 : loss : 0.022150, loss_ce: 0.008794
2022-01-14 13:07:57,882 iteration 5566 : loss : 0.020051, loss_ce: 0.007878
2022-01-14 13:07:58,854 iteration 5567 : loss : 0.016594, loss_ce: 0.008318
2022-01-14 13:07:59,766 iteration 5568 : loss : 0.020109, loss_ce: 0.007244
2022-01-14 13:08:00,704 iteration 5569 : loss : 0.022268, loss_ce: 0.008114
2022-01-14 13:08:01,567 iteration 5570 : loss : 0.010981, loss_ce: 0.003314
2022-01-14 13:08:02,384 iteration 5571 : loss : 0.011361, loss_ce: 0.004187
2022-01-14 13:08:03,261 iteration 5572 : loss : 0.021106, loss_ce: 0.006857
2022-01-14 13:08:04,113 iteration 5573 : loss : 0.010353, loss_ce: 0.003102
2022-01-14 13:08:05,022 iteration 5574 : loss : 0.014053, loss_ce: 0.004445
2022-01-14 13:08:06,056 iteration 5575 : loss : 0.021121, loss_ce: 0.006086
2022-01-14 13:08:07,023 iteration 5576 : loss : 0.017830, loss_ce: 0.006662
 82%|███████████████████████▊     | 328/400 [1:33:32<19:52, 16.57s/it]2022-01-14 13:08:08,033 iteration 5577 : loss : 0.019604, loss_ce: 0.009444
2022-01-14 13:08:09,016 iteration 5578 : loss : 0.019401, loss_ce: 0.006465
2022-01-14 13:08:10,031 iteration 5579 : loss : 0.021719, loss_ce: 0.010643
2022-01-14 13:08:10,942 iteration 5580 : loss : 0.022801, loss_ce: 0.007841
2022-01-14 13:08:11,814 iteration 5581 : loss : 0.012698, loss_ce: 0.005361
2022-01-14 13:08:12,748 iteration 5582 : loss : 0.014469, loss_ce: 0.003998
2022-01-14 13:08:13,638 iteration 5583 : loss : 0.013047, loss_ce: 0.005341
2022-01-14 13:08:14,620 iteration 5584 : loss : 0.018144, loss_ce: 0.007473
2022-01-14 13:08:15,509 iteration 5585 : loss : 0.014540, loss_ce: 0.004331
2022-01-14 13:08:16,512 iteration 5586 : loss : 0.026669, loss_ce: 0.008566
2022-01-14 13:08:17,383 iteration 5587 : loss : 0.018827, loss_ce: 0.006904
2022-01-14 13:08:18,300 iteration 5588 : loss : 0.014020, loss_ce: 0.005230
2022-01-14 13:08:19,156 iteration 5589 : loss : 0.011912, loss_ce: 0.003574
2022-01-14 13:08:20,035 iteration 5590 : loss : 0.011516, loss_ce: 0.002846
2022-01-14 13:08:20,936 iteration 5591 : loss : 0.013170, loss_ce: 0.005191
2022-01-14 13:08:21,905 iteration 5592 : loss : 0.026910, loss_ce: 0.009795
2022-01-14 13:08:22,870 iteration 5593 : loss : 0.024139, loss_ce: 0.011692
 82%|███████████████████████▊     | 329/400 [1:33:48<19:21, 16.35s/it]2022-01-14 13:08:23,788 iteration 5594 : loss : 0.017420, loss_ce: 0.004570
2022-01-14 13:08:24,750 iteration 5595 : loss : 0.021925, loss_ce: 0.009424
2022-01-14 13:08:25,648 iteration 5596 : loss : 0.015888, loss_ce: 0.005700
2022-01-14 13:08:26,642 iteration 5597 : loss : 0.013074, loss_ce: 0.005264
2022-01-14 13:08:27,490 iteration 5598 : loss : 0.012485, loss_ce: 0.005140
2022-01-14 13:08:28,414 iteration 5599 : loss : 0.018272, loss_ce: 0.007180
2022-01-14 13:08:29,316 iteration 5600 : loss : 0.012741, loss_ce: 0.005321
2022-01-14 13:08:30,208 iteration 5601 : loss : 0.012189, loss_ce: 0.004731
2022-01-14 13:08:31,130 iteration 5602 : loss : 0.022428, loss_ce: 0.010049
2022-01-14 13:08:31,993 iteration 5603 : loss : 0.011472, loss_ce: 0.004557
2022-01-14 13:08:32,940 iteration 5604 : loss : 0.017401, loss_ce: 0.005060
2022-01-14 13:08:33,905 iteration 5605 : loss : 0.016113, loss_ce: 0.006276
2022-01-14 13:08:34,828 iteration 5606 : loss : 0.020801, loss_ce: 0.007267
2022-01-14 13:08:35,755 iteration 5607 : loss : 0.019114, loss_ce: 0.006310
2022-01-14 13:08:36,662 iteration 5608 : loss : 0.014673, loss_ce: 0.004503
2022-01-14 13:08:37,634 iteration 5609 : loss : 0.013762, loss_ce: 0.005810
2022-01-14 13:08:37,635 Training Data Eval:
2022-01-14 13:08:41,941   Average segmentation loss on training set: 0.0093
2022-01-14 13:08:41,941 Validation Data Eval:
2022-01-14 13:08:43,391   Average segmentation loss on validation set: 0.0691
2022-01-14 13:08:44,261 iteration 5610 : loss : 0.013523, loss_ce: 0.004545
 82%|███████████████████████▉     | 330/400 [1:34:10<20:50, 17.86s/it]2022-01-14 13:08:45,208 iteration 5611 : loss : 0.016502, loss_ce: 0.005750
2022-01-14 13:08:46,146 iteration 5612 : loss : 0.018242, loss_ce: 0.004056
2022-01-14 13:08:47,083 iteration 5613 : loss : 0.016766, loss_ce: 0.006001
2022-01-14 13:08:48,004 iteration 5614 : loss : 0.016466, loss_ce: 0.006277
2022-01-14 13:08:48,840 iteration 5615 : loss : 0.009790, loss_ce: 0.004085
2022-01-14 13:08:49,800 iteration 5616 : loss : 0.015356, loss_ce: 0.006667
2022-01-14 13:08:50,770 iteration 5617 : loss : 0.023364, loss_ce: 0.009357
2022-01-14 13:08:51,728 iteration 5618 : loss : 0.020271, loss_ce: 0.008428
2022-01-14 13:08:52,609 iteration 5619 : loss : 0.019553, loss_ce: 0.005660
2022-01-14 13:08:53,610 iteration 5620 : loss : 0.019213, loss_ce: 0.008042
2022-01-14 13:08:54,454 iteration 5621 : loss : 0.015277, loss_ce: 0.005310
2022-01-14 13:08:55,392 iteration 5622 : loss : 0.016761, loss_ce: 0.005999
2022-01-14 13:08:56,401 iteration 5623 : loss : 0.021502, loss_ce: 0.008877
2022-01-14 13:08:57,279 iteration 5624 : loss : 0.015029, loss_ce: 0.003993
2022-01-14 13:08:58,128 iteration 5625 : loss : 0.015403, loss_ce: 0.006779
2022-01-14 13:08:59,032 iteration 5626 : loss : 0.014525, loss_ce: 0.003954
2022-01-14 13:08:59,984 iteration 5627 : loss : 0.016743, loss_ce: 0.006476
 83%|███████████████████████▉     | 331/400 [1:34:25<19:48, 17.22s/it]2022-01-14 13:09:01,078 iteration 5628 : loss : 0.026287, loss_ce: 0.013154
2022-01-14 13:09:01,961 iteration 5629 : loss : 0.014043, loss_ce: 0.006202
2022-01-14 13:09:02,921 iteration 5630 : loss : 0.020030, loss_ce: 0.008858
2022-01-14 13:09:03,837 iteration 5631 : loss : 0.016793, loss_ce: 0.006037
2022-01-14 13:09:04,818 iteration 5632 : loss : 0.018062, loss_ce: 0.008425
2022-01-14 13:09:05,822 iteration 5633 : loss : 0.032301, loss_ce: 0.010406
2022-01-14 13:09:06,768 iteration 5634 : loss : 0.009783, loss_ce: 0.004079
2022-01-14 13:09:07,681 iteration 5635 : loss : 0.017403, loss_ce: 0.007160
2022-01-14 13:09:08,618 iteration 5636 : loss : 0.024756, loss_ce: 0.005819
2022-01-14 13:09:09,539 iteration 5637 : loss : 0.015999, loss_ce: 0.004786
2022-01-14 13:09:10,474 iteration 5638 : loss : 0.018202, loss_ce: 0.008924
2022-01-14 13:09:11,429 iteration 5639 : loss : 0.013477, loss_ce: 0.004639
2022-01-14 13:09:12,390 iteration 5640 : loss : 0.014799, loss_ce: 0.006205
2022-01-14 13:09:13,245 iteration 5641 : loss : 0.016704, loss_ce: 0.004314
2022-01-14 13:09:14,120 iteration 5642 : loss : 0.015143, loss_ce: 0.005854
2022-01-14 13:09:15,037 iteration 5643 : loss : 0.013473, loss_ce: 0.004490
2022-01-14 13:09:15,935 iteration 5644 : loss : 0.013297, loss_ce: 0.005282
 83%|████████████████████████     | 332/400 [1:34:41<19:05, 16.84s/it]2022-01-14 13:09:16,889 iteration 5645 : loss : 0.017074, loss_ce: 0.005820
2022-01-14 13:09:17,808 iteration 5646 : loss : 0.012736, loss_ce: 0.004071
2022-01-14 13:09:18,787 iteration 5647 : loss : 0.022132, loss_ce: 0.007434
2022-01-14 13:09:19,712 iteration 5648 : loss : 0.015768, loss_ce: 0.004598
2022-01-14 13:09:20,629 iteration 5649 : loss : 0.016557, loss_ce: 0.006341
2022-01-14 13:09:21,611 iteration 5650 : loss : 0.019637, loss_ce: 0.005096
2022-01-14 13:09:22,506 iteration 5651 : loss : 0.013550, loss_ce: 0.006333
2022-01-14 13:09:23,401 iteration 5652 : loss : 0.013881, loss_ce: 0.005343
2022-01-14 13:09:24,302 iteration 5653 : loss : 0.014474, loss_ce: 0.005538
2022-01-14 13:09:25,308 iteration 5654 : loss : 0.012129, loss_ce: 0.004751
2022-01-14 13:09:26,224 iteration 5655 : loss : 0.024637, loss_ce: 0.009445
2022-01-14 13:09:27,172 iteration 5656 : loss : 0.023483, loss_ce: 0.010243
2022-01-14 13:09:28,080 iteration 5657 : loss : 0.016585, loss_ce: 0.008421
2022-01-14 13:09:29,057 iteration 5658 : loss : 0.023312, loss_ce: 0.006998
2022-01-14 13:09:30,084 iteration 5659 : loss : 0.012178, loss_ce: 0.005250
2022-01-14 13:09:30,915 iteration 5660 : loss : 0.011566, loss_ce: 0.004318
2022-01-14 13:09:31,878 iteration 5661 : loss : 0.017635, loss_ce: 0.006546
 83%|████████████████████████▏    | 333/400 [1:34:57<18:30, 16.57s/it]2022-01-14 13:09:32,819 iteration 5662 : loss : 0.013577, loss_ce: 0.005391
2022-01-14 13:09:33,776 iteration 5663 : loss : 0.014715, loss_ce: 0.006315
2022-01-14 13:09:34,773 iteration 5664 : loss : 0.019968, loss_ce: 0.007007
2022-01-14 13:09:35,663 iteration 5665 : loss : 0.013219, loss_ce: 0.003885
2022-01-14 13:09:36,667 iteration 5666 : loss : 0.013661, loss_ce: 0.005008
2022-01-14 13:09:37,626 iteration 5667 : loss : 0.021311, loss_ce: 0.006816
2022-01-14 13:09:38,581 iteration 5668 : loss : 0.023302, loss_ce: 0.006875
2022-01-14 13:09:39,591 iteration 5669 : loss : 0.017288, loss_ce: 0.009456
2022-01-14 13:09:40,530 iteration 5670 : loss : 0.016414, loss_ce: 0.005256
2022-01-14 13:09:41,539 iteration 5671 : loss : 0.029189, loss_ce: 0.008456
2022-01-14 13:09:42,372 iteration 5672 : loss : 0.013754, loss_ce: 0.003797
2022-01-14 13:09:43,284 iteration 5673 : loss : 0.015288, loss_ce: 0.006961
2022-01-14 13:09:44,132 iteration 5674 : loss : 0.019373, loss_ce: 0.006449
2022-01-14 13:09:45,177 iteration 5675 : loss : 0.021973, loss_ce: 0.008730
2022-01-14 13:09:46,096 iteration 5676 : loss : 0.015540, loss_ce: 0.007795
2022-01-14 13:09:46,985 iteration 5677 : loss : 0.021162, loss_ce: 0.007546
2022-01-14 13:09:47,906 iteration 5678 : loss : 0.017328, loss_ce: 0.006570
 84%|████████████████████████▏    | 334/400 [1:35:13<18:02, 16.41s/it]2022-01-14 13:09:48,926 iteration 5679 : loss : 0.026966, loss_ce: 0.009518
2022-01-14 13:09:49,824 iteration 5680 : loss : 0.017892, loss_ce: 0.007881
2022-01-14 13:09:50,792 iteration 5681 : loss : 0.017779, loss_ce: 0.005226
2022-01-14 13:09:51,625 iteration 5682 : loss : 0.013037, loss_ce: 0.004406
2022-01-14 13:09:52,459 iteration 5683 : loss : 0.010062, loss_ce: 0.004436
2022-01-14 13:09:53,450 iteration 5684 : loss : 0.015347, loss_ce: 0.007688
2022-01-14 13:09:54,400 iteration 5685 : loss : 0.016951, loss_ce: 0.005742
2022-01-14 13:09:55,336 iteration 5686 : loss : 0.014259, loss_ce: 0.005117
2022-01-14 13:09:56,310 iteration 5687 : loss : 0.016720, loss_ce: 0.004669
2022-01-14 13:09:57,320 iteration 5688 : loss : 0.019153, loss_ce: 0.006442
2022-01-14 13:09:58,217 iteration 5689 : loss : 0.013352, loss_ce: 0.005402
2022-01-14 13:09:59,085 iteration 5690 : loss : 0.013771, loss_ce: 0.004305
2022-01-14 13:10:00,045 iteration 5691 : loss : 0.015086, loss_ce: 0.006730
2022-01-14 13:10:00,967 iteration 5692 : loss : 0.010470, loss_ce: 0.003058
2022-01-14 13:10:01,759 iteration 5693 : loss : 0.012655, loss_ce: 0.005050
2022-01-14 13:10:02,712 iteration 5694 : loss : 0.021325, loss_ce: 0.008675
2022-01-14 13:10:02,712 Training Data Eval:
2022-01-14 13:10:07,025   Average segmentation loss on training set: 0.0093
2022-01-14 13:10:07,026 Validation Data Eval:
2022-01-14 13:10:08,473   Average segmentation loss on validation set: 0.0686
2022-01-14 13:10:09,384 iteration 5695 : loss : 0.018049, loss_ce: 0.008573
 84%|████████████████████████▎    | 335/400 [1:35:35<19:25, 17.93s/it]2022-01-14 13:10:10,385 iteration 5696 : loss : 0.017835, loss_ce: 0.005816
2022-01-14 13:10:11,272 iteration 5697 : loss : 0.011782, loss_ce: 0.003436
2022-01-14 13:10:12,267 iteration 5698 : loss : 0.021807, loss_ce: 0.008694
2022-01-14 13:10:13,272 iteration 5699 : loss : 0.013690, loss_ce: 0.003574
2022-01-14 13:10:14,098 iteration 5700 : loss : 0.011002, loss_ce: 0.005032
2022-01-14 13:10:15,138 iteration 5701 : loss : 0.018983, loss_ce: 0.003319
2022-01-14 13:10:16,108 iteration 5702 : loss : 0.013957, loss_ce: 0.005072
2022-01-14 13:10:17,136 iteration 5703 : loss : 0.019447, loss_ce: 0.008279
2022-01-14 13:10:18,033 iteration 5704 : loss : 0.018994, loss_ce: 0.007812
2022-01-14 13:10:18,926 iteration 5705 : loss : 0.012632, loss_ce: 0.004896
2022-01-14 13:10:19,809 iteration 5706 : loss : 0.013751, loss_ce: 0.005482
2022-01-14 13:10:20,752 iteration 5707 : loss : 0.022685, loss_ce: 0.005632
2022-01-14 13:10:21,677 iteration 5708 : loss : 0.020589, loss_ce: 0.009713
2022-01-14 13:10:22,557 iteration 5709 : loss : 0.013615, loss_ce: 0.004331
2022-01-14 13:10:23,457 iteration 5710 : loss : 0.015789, loss_ce: 0.007600
2022-01-14 13:10:24,390 iteration 5711 : loss : 0.012668, loss_ce: 0.005304
2022-01-14 13:10:25,325 iteration 5712 : loss : 0.013862, loss_ce: 0.006085
 84%|████████████████████████▎    | 336/400 [1:35:51<18:29, 17.33s/it]2022-01-14 13:10:26,309 iteration 5713 : loss : 0.013497, loss_ce: 0.005834
2022-01-14 13:10:27,273 iteration 5714 : loss : 0.019007, loss_ce: 0.006184
2022-01-14 13:10:28,147 iteration 5715 : loss : 0.013901, loss_ce: 0.005199
2022-01-14 13:10:29,132 iteration 5716 : loss : 0.016973, loss_ce: 0.006245
2022-01-14 13:10:29,997 iteration 5717 : loss : 0.010275, loss_ce: 0.003833
2022-01-14 13:10:30,871 iteration 5718 : loss : 0.019845, loss_ce: 0.009188
2022-01-14 13:10:31,842 iteration 5719 : loss : 0.015934, loss_ce: 0.004756
2022-01-14 13:10:32,831 iteration 5720 : loss : 0.024368, loss_ce: 0.013176
2022-01-14 13:10:33,700 iteration 5721 : loss : 0.013514, loss_ce: 0.003728
2022-01-14 13:10:34,677 iteration 5722 : loss : 0.014913, loss_ce: 0.005346
2022-01-14 13:10:35,682 iteration 5723 : loss : 0.024629, loss_ce: 0.009156
2022-01-14 13:10:36,644 iteration 5724 : loss : 0.015965, loss_ce: 0.006807
2022-01-14 13:10:37,562 iteration 5725 : loss : 0.013107, loss_ce: 0.004716
2022-01-14 13:10:38,535 iteration 5726 : loss : 0.012729, loss_ce: 0.005083
2022-01-14 13:10:39,484 iteration 5727 : loss : 0.018834, loss_ce: 0.009181
2022-01-14 13:10:40,375 iteration 5728 : loss : 0.012856, loss_ce: 0.003956
2022-01-14 13:10:41,220 iteration 5729 : loss : 0.013243, loss_ce: 0.003953
 84%|████████████████████████▍    | 337/400 [1:36:07<17:44, 16.90s/it]2022-01-14 13:10:42,307 iteration 5730 : loss : 0.020643, loss_ce: 0.007535
2022-01-14 13:10:43,294 iteration 5731 : loss : 0.023319, loss_ce: 0.008717
2022-01-14 13:10:44,282 iteration 5732 : loss : 0.022594, loss_ce: 0.005324
2022-01-14 13:10:45,203 iteration 5733 : loss : 0.015582, loss_ce: 0.005998
2022-01-14 13:10:46,099 iteration 5734 : loss : 0.009703, loss_ce: 0.003455
2022-01-14 13:10:47,102 iteration 5735 : loss : 0.022291, loss_ce: 0.007171
2022-01-14 13:10:48,105 iteration 5736 : loss : 0.016349, loss_ce: 0.007029
2022-01-14 13:10:49,034 iteration 5737 : loss : 0.013386, loss_ce: 0.004987
2022-01-14 13:10:49,931 iteration 5738 : loss : 0.015225, loss_ce: 0.007056
2022-01-14 13:10:50,880 iteration 5739 : loss : 0.013809, loss_ce: 0.003987
2022-01-14 13:10:51,875 iteration 5740 : loss : 0.021191, loss_ce: 0.008905
2022-01-14 13:10:52,828 iteration 5741 : loss : 0.010678, loss_ce: 0.004020
2022-01-14 13:10:53,716 iteration 5742 : loss : 0.020446, loss_ce: 0.003653
2022-01-14 13:10:54,659 iteration 5743 : loss : 0.014939, loss_ce: 0.004786
2022-01-14 13:10:55,556 iteration 5744 : loss : 0.013924, loss_ce: 0.005744
2022-01-14 13:10:56,515 iteration 5745 : loss : 0.011105, loss_ce: 0.003580
2022-01-14 13:10:57,411 iteration 5746 : loss : 0.015482, loss_ce: 0.007220
 84%|████████████████████████▌    | 338/400 [1:36:23<17:14, 16.69s/it]2022-01-14 13:10:58,435 iteration 5747 : loss : 0.021134, loss_ce: 0.006800
2022-01-14 13:10:59,332 iteration 5748 : loss : 0.016880, loss_ce: 0.006455
2022-01-14 13:11:00,327 iteration 5749 : loss : 0.020728, loss_ce: 0.010024
2022-01-14 13:11:01,284 iteration 5750 : loss : 0.016143, loss_ce: 0.004167
2022-01-14 13:11:02,279 iteration 5751 : loss : 0.020438, loss_ce: 0.007846
2022-01-14 13:11:03,221 iteration 5752 : loss : 0.014934, loss_ce: 0.005445
2022-01-14 13:11:04,204 iteration 5753 : loss : 0.016281, loss_ce: 0.007824
2022-01-14 13:11:05,129 iteration 5754 : loss : 0.013685, loss_ce: 0.004879
2022-01-14 13:11:06,034 iteration 5755 : loss : 0.023242, loss_ce: 0.006153
2022-01-14 13:11:06,914 iteration 5756 : loss : 0.016412, loss_ce: 0.008164
2022-01-14 13:11:07,863 iteration 5757 : loss : 0.015944, loss_ce: 0.004626
2022-01-14 13:11:08,726 iteration 5758 : loss : 0.008141, loss_ce: 0.002418
2022-01-14 13:11:09,716 iteration 5759 : loss : 0.019468, loss_ce: 0.004773
2022-01-14 13:11:10,641 iteration 5760 : loss : 0.013022, loss_ce: 0.004696
2022-01-14 13:11:11,603 iteration 5761 : loss : 0.015021, loss_ce: 0.005163
2022-01-14 13:11:12,609 iteration 5762 : loss : 0.023316, loss_ce: 0.010838
2022-01-14 13:11:13,546 iteration 5763 : loss : 0.026937, loss_ce: 0.010352
 85%|████████████████████████▌    | 339/400 [1:36:39<16:47, 16.52s/it]2022-01-14 13:11:14,608 iteration 5764 : loss : 0.022460, loss_ce: 0.009729
2022-01-14 13:11:15,555 iteration 5765 : loss : 0.022901, loss_ce: 0.006667
2022-01-14 13:11:16,459 iteration 5766 : loss : 0.016132, loss_ce: 0.005049
2022-01-14 13:11:17,444 iteration 5767 : loss : 0.016570, loss_ce: 0.006774
2022-01-14 13:11:18,401 iteration 5768 : loss : 0.028582, loss_ce: 0.007448
2022-01-14 13:11:19,378 iteration 5769 : loss : 0.019260, loss_ce: 0.004932
2022-01-14 13:11:20,353 iteration 5770 : loss : 0.027745, loss_ce: 0.011380
2022-01-14 13:11:21,207 iteration 5771 : loss : 0.011486, loss_ce: 0.004921
2022-01-14 13:11:22,148 iteration 5772 : loss : 0.016073, loss_ce: 0.005777
2022-01-14 13:11:22,998 iteration 5773 : loss : 0.012258, loss_ce: 0.004090
2022-01-14 13:11:23,882 iteration 5774 : loss : 0.014460, loss_ce: 0.005599
2022-01-14 13:11:24,816 iteration 5775 : loss : 0.020050, loss_ce: 0.007300
2022-01-14 13:11:25,631 iteration 5776 : loss : 0.011859, loss_ce: 0.004832
2022-01-14 13:11:26,532 iteration 5777 : loss : 0.014609, loss_ce: 0.005048
2022-01-14 13:11:27,489 iteration 5778 : loss : 0.016403, loss_ce: 0.006990
2022-01-14 13:11:28,428 iteration 5779 : loss : 0.010914, loss_ce: 0.004555
2022-01-14 13:11:28,428 Training Data Eval:
2022-01-14 13:11:32,735   Average segmentation loss on training set: 0.0088
2022-01-14 13:11:32,735 Validation Data Eval:
2022-01-14 13:11:34,192   Average segmentation loss on validation set: 0.0684
2022-01-14 13:11:35,082 iteration 5780 : loss : 0.014262, loss_ce: 0.005435
 85%|████████████████████████▋    | 340/400 [1:37:00<18:01, 18.03s/it]2022-01-14 13:11:36,084 iteration 5781 : loss : 0.019611, loss_ce: 0.007015
2022-01-14 13:11:36,922 iteration 5782 : loss : 0.010677, loss_ce: 0.003754
2022-01-14 13:11:37,870 iteration 5783 : loss : 0.017357, loss_ce: 0.005630
2022-01-14 13:11:38,814 iteration 5784 : loss : 0.012467, loss_ce: 0.003881
2022-01-14 13:11:39,775 iteration 5785 : loss : 0.013173, loss_ce: 0.007134
2022-01-14 13:11:40,775 iteration 5786 : loss : 0.018864, loss_ce: 0.006860
2022-01-14 13:11:41,688 iteration 5787 : loss : 0.018102, loss_ce: 0.005673
2022-01-14 13:11:42,644 iteration 5788 : loss : 0.013934, loss_ce: 0.005337
2022-01-14 13:11:43,575 iteration 5789 : loss : 0.016500, loss_ce: 0.005198
2022-01-14 13:11:44,542 iteration 5790 : loss : 0.018445, loss_ce: 0.007078
2022-01-14 13:11:45,520 iteration 5791 : loss : 0.012601, loss_ce: 0.004881
2022-01-14 13:11:46,537 iteration 5792 : loss : 0.015702, loss_ce: 0.004376
2022-01-14 13:11:47,426 iteration 5793 : loss : 0.013548, loss_ce: 0.005564
2022-01-14 13:11:48,290 iteration 5794 : loss : 0.016396, loss_ce: 0.005649
2022-01-14 13:11:49,195 iteration 5795 : loss : 0.016288, loss_ce: 0.007741
2022-01-14 13:11:50,101 iteration 5796 : loss : 0.013552, loss_ce: 0.005598
2022-01-14 13:11:51,005 iteration 5797 : loss : 0.015780, loss_ce: 0.006299
 85%|████████████████████████▋    | 341/400 [1:37:16<17:06, 17.39s/it]2022-01-14 13:11:51,923 iteration 5798 : loss : 0.018009, loss_ce: 0.006678
2022-01-14 13:11:52,801 iteration 5799 : loss : 0.011054, loss_ce: 0.004247
2022-01-14 13:11:53,618 iteration 5800 : loss : 0.009184, loss_ce: 0.003672
2022-01-14 13:11:54,549 iteration 5801 : loss : 0.014749, loss_ce: 0.006677
2022-01-14 13:11:55,402 iteration 5802 : loss : 0.012765, loss_ce: 0.005495
2022-01-14 13:11:56,356 iteration 5803 : loss : 0.017659, loss_ce: 0.006427
2022-01-14 13:11:57,217 iteration 5804 : loss : 0.015943, loss_ce: 0.005256
2022-01-14 13:11:58,084 iteration 5805 : loss : 0.014287, loss_ce: 0.004408
2022-01-14 13:11:58,938 iteration 5806 : loss : 0.012001, loss_ce: 0.005831
2022-01-14 13:11:59,860 iteration 5807 : loss : 0.016342, loss_ce: 0.005962
2022-01-14 13:12:00,833 iteration 5808 : loss : 0.014704, loss_ce: 0.004720
2022-01-14 13:12:01,824 iteration 5809 : loss : 0.014424, loss_ce: 0.005168
2022-01-14 13:12:02,861 iteration 5810 : loss : 0.019079, loss_ce: 0.005299
2022-01-14 13:12:03,817 iteration 5811 : loss : 0.014083, loss_ce: 0.005201
2022-01-14 13:12:04,727 iteration 5812 : loss : 0.017940, loss_ce: 0.007464
2022-01-14 13:12:05,618 iteration 5813 : loss : 0.011936, loss_ce: 0.003678
2022-01-14 13:12:06,521 iteration 5814 : loss : 0.019775, loss_ce: 0.006010
 86%|████████████████████████▊    | 342/400 [1:37:32<16:16, 16.83s/it]2022-01-14 13:12:07,575 iteration 5815 : loss : 0.021181, loss_ce: 0.008133
2022-01-14 13:12:08,471 iteration 5816 : loss : 0.012222, loss_ce: 0.004445
2022-01-14 13:12:09,477 iteration 5817 : loss : 0.025326, loss_ce: 0.011589
2022-01-14 13:12:10,448 iteration 5818 : loss : 0.014722, loss_ce: 0.005318
2022-01-14 13:12:11,344 iteration 5819 : loss : 0.013730, loss_ce: 0.004249
2022-01-14 13:12:12,234 iteration 5820 : loss : 0.017621, loss_ce: 0.006431
2022-01-14 13:12:13,177 iteration 5821 : loss : 0.019108, loss_ce: 0.007028
2022-01-14 13:12:14,185 iteration 5822 : loss : 0.021035, loss_ce: 0.005848
2022-01-14 13:12:15,053 iteration 5823 : loss : 0.013049, loss_ce: 0.006148
2022-01-14 13:12:16,053 iteration 5824 : loss : 0.026227, loss_ce: 0.006233
2022-01-14 13:12:17,003 iteration 5825 : loss : 0.012383, loss_ce: 0.004525
2022-01-14 13:12:17,953 iteration 5826 : loss : 0.013597, loss_ce: 0.006249
2022-01-14 13:12:18,817 iteration 5827 : loss : 0.030311, loss_ce: 0.014721
2022-01-14 13:12:19,835 iteration 5828 : loss : 0.023973, loss_ce: 0.004539
2022-01-14 13:12:20,768 iteration 5829 : loss : 0.019563, loss_ce: 0.006041
2022-01-14 13:12:21,643 iteration 5830 : loss : 0.013198, loss_ce: 0.004581
2022-01-14 13:12:22,613 iteration 5831 : loss : 0.024736, loss_ce: 0.009090
 86%|████████████████████████▊    | 343/400 [1:37:48<15:46, 16.61s/it]2022-01-14 13:12:23,639 iteration 5832 : loss : 0.019289, loss_ce: 0.008071
2022-01-14 13:12:24,653 iteration 5833 : loss : 0.018148, loss_ce: 0.006139
2022-01-14 13:12:25,581 iteration 5834 : loss : 0.013406, loss_ce: 0.005920
2022-01-14 13:12:26,494 iteration 5835 : loss : 0.017804, loss_ce: 0.006018
2022-01-14 13:12:27,410 iteration 5836 : loss : 0.025345, loss_ce: 0.008228
2022-01-14 13:12:28,416 iteration 5837 : loss : 0.023477, loss_ce: 0.008607
2022-01-14 13:12:29,345 iteration 5838 : loss : 0.015209, loss_ce: 0.004328
2022-01-14 13:12:30,281 iteration 5839 : loss : 0.017848, loss_ce: 0.006001
2022-01-14 13:12:31,203 iteration 5840 : loss : 0.012489, loss_ce: 0.004443
2022-01-14 13:12:32,180 iteration 5841 : loss : 0.022998, loss_ce: 0.008685
2022-01-14 13:12:33,052 iteration 5842 : loss : 0.015275, loss_ce: 0.004720
2022-01-14 13:12:33,908 iteration 5843 : loss : 0.014137, loss_ce: 0.006246
2022-01-14 13:12:34,838 iteration 5844 : loss : 0.020651, loss_ce: 0.007234
2022-01-14 13:12:35,704 iteration 5845 : loss : 0.012146, loss_ce: 0.004389
2022-01-14 13:12:36,575 iteration 5846 : loss : 0.009605, loss_ce: 0.003959
2022-01-14 13:12:37,444 iteration 5847 : loss : 0.019502, loss_ce: 0.008739
2022-01-14 13:12:38,332 iteration 5848 : loss : 0.013486, loss_ce: 0.005107
 86%|████████████████████████▉    | 344/400 [1:38:04<15:15, 16.34s/it]2022-01-14 13:12:39,318 iteration 5849 : loss : 0.021250, loss_ce: 0.005926
2022-01-14 13:12:40,326 iteration 5850 : loss : 0.018570, loss_ce: 0.010234
2022-01-14 13:12:41,292 iteration 5851 : loss : 0.013483, loss_ce: 0.003463
2022-01-14 13:12:42,234 iteration 5852 : loss : 0.013577, loss_ce: 0.006579
2022-01-14 13:12:43,118 iteration 5853 : loss : 0.016605, loss_ce: 0.005298
2022-01-14 13:12:44,095 iteration 5854 : loss : 0.017443, loss_ce: 0.006117
2022-01-14 13:12:45,021 iteration 5855 : loss : 0.013509, loss_ce: 0.006089
2022-01-14 13:12:45,949 iteration 5856 : loss : 0.014431, loss_ce: 0.005622
2022-01-14 13:12:46,901 iteration 5857 : loss : 0.015966, loss_ce: 0.006333
2022-01-14 13:12:47,881 iteration 5858 : loss : 0.013613, loss_ce: 0.004222
2022-01-14 13:12:48,913 iteration 5859 : loss : 0.019506, loss_ce: 0.006862
2022-01-14 13:12:49,837 iteration 5860 : loss : 0.013070, loss_ce: 0.004350
2022-01-14 13:12:50,740 iteration 5861 : loss : 0.014200, loss_ce: 0.005883
2022-01-14 13:12:51,660 iteration 5862 : loss : 0.014917, loss_ce: 0.006050
2022-01-14 13:12:52,604 iteration 5863 : loss : 0.023017, loss_ce: 0.007338
2022-01-14 13:12:53,641 iteration 5864 : loss : 0.013862, loss_ce: 0.005624
2022-01-14 13:12:53,641 Training Data Eval:
2022-01-14 13:12:57,937   Average segmentation loss on training set: 0.0087
2022-01-14 13:12:57,937 Validation Data Eval:
2022-01-14 13:12:59,389   Average segmentation loss on validation set: 0.0649
2022-01-14 13:13:00,405 iteration 5865 : loss : 0.025431, loss_ce: 0.006903
 86%|█████████████████████████    | 345/400 [1:38:26<16:33, 18.06s/it]2022-01-14 13:13:01,318 iteration 5866 : loss : 0.013422, loss_ce: 0.003116
2022-01-14 13:13:02,215 iteration 5867 : loss : 0.011076, loss_ce: 0.004347
2022-01-14 13:13:03,150 iteration 5868 : loss : 0.013034, loss_ce: 0.005357
2022-01-14 13:13:04,042 iteration 5869 : loss : 0.017120, loss_ce: 0.006513
2022-01-14 13:13:05,084 iteration 5870 : loss : 0.018092, loss_ce: 0.006668
2022-01-14 13:13:06,003 iteration 5871 : loss : 0.012422, loss_ce: 0.004370
2022-01-14 13:13:06,891 iteration 5872 : loss : 0.015496, loss_ce: 0.004820
2022-01-14 13:13:07,841 iteration 5873 : loss : 0.019227, loss_ce: 0.010971
2022-01-14 13:13:08,791 iteration 5874 : loss : 0.019610, loss_ce: 0.007882
2022-01-14 13:13:09,716 iteration 5875 : loss : 0.011986, loss_ce: 0.005593
2022-01-14 13:13:10,756 iteration 5876 : loss : 0.016948, loss_ce: 0.006834
2022-01-14 13:13:11,743 iteration 5877 : loss : 0.018394, loss_ce: 0.007521
2022-01-14 13:13:12,618 iteration 5878 : loss : 0.015118, loss_ce: 0.005852
2022-01-14 13:13:13,539 iteration 5879 : loss : 0.014828, loss_ce: 0.005405
2022-01-14 13:13:14,480 iteration 5880 : loss : 0.017817, loss_ce: 0.004455
2022-01-14 13:13:15,374 iteration 5881 : loss : 0.020731, loss_ce: 0.008554
2022-01-14 13:13:16,232 iteration 5882 : loss : 0.018668, loss_ce: 0.006137
 86%|█████████████████████████    | 346/400 [1:38:42<15:38, 17.39s/it]2022-01-14 13:13:17,172 iteration 5883 : loss : 0.014017, loss_ce: 0.004088
2022-01-14 13:13:18,001 iteration 5884 : loss : 0.011295, loss_ce: 0.003898
2022-01-14 13:13:18,991 iteration 5885 : loss : 0.015920, loss_ce: 0.004561
2022-01-14 13:13:19,882 iteration 5886 : loss : 0.019622, loss_ce: 0.005821
2022-01-14 13:13:20,850 iteration 5887 : loss : 0.012001, loss_ce: 0.004619
2022-01-14 13:13:21,783 iteration 5888 : loss : 0.010736, loss_ce: 0.004501
2022-01-14 13:13:22,788 iteration 5889 : loss : 0.014202, loss_ce: 0.004074
2022-01-14 13:13:23,694 iteration 5890 : loss : 0.014778, loss_ce: 0.005756
2022-01-14 13:13:24,616 iteration 5891 : loss : 0.021347, loss_ce: 0.005966
2022-01-14 13:13:25,577 iteration 5892 : loss : 0.034089, loss_ce: 0.010614
2022-01-14 13:13:26,483 iteration 5893 : loss : 0.014191, loss_ce: 0.005951
2022-01-14 13:13:27,347 iteration 5894 : loss : 0.014627, loss_ce: 0.006112
2022-01-14 13:13:28,216 iteration 5895 : loss : 0.017958, loss_ce: 0.007775
2022-01-14 13:13:29,092 iteration 5896 : loss : 0.014365, loss_ce: 0.005396
2022-01-14 13:13:30,019 iteration 5897 : loss : 0.015150, loss_ce: 0.006969
2022-01-14 13:13:30,883 iteration 5898 : loss : 0.020696, loss_ce: 0.007886
2022-01-14 13:13:31,845 iteration 5899 : loss : 0.019133, loss_ce: 0.008462
 87%|█████████████████████████▏   | 347/400 [1:38:57<14:53, 16.85s/it]2022-01-14 13:13:32,736 iteration 5900 : loss : 0.013562, loss_ce: 0.004415
2022-01-14 13:13:33,783 iteration 5901 : loss : 0.016506, loss_ce: 0.007276
2022-01-14 13:13:34,809 iteration 5902 : loss : 0.017424, loss_ce: 0.007921
2022-01-14 13:13:35,727 iteration 5903 : loss : 0.013541, loss_ce: 0.004320
2022-01-14 13:13:36,666 iteration 5904 : loss : 0.012706, loss_ce: 0.005206
2022-01-14 13:13:37,533 iteration 5905 : loss : 0.012894, loss_ce: 0.004555
2022-01-14 13:13:38,447 iteration 5906 : loss : 0.014490, loss_ce: 0.005754
2022-01-14 13:13:39,393 iteration 5907 : loss : 0.013778, loss_ce: 0.004632
2022-01-14 13:13:40,314 iteration 5908 : loss : 0.016790, loss_ce: 0.005993
2022-01-14 13:13:41,191 iteration 5909 : loss : 0.011018, loss_ce: 0.004497
2022-01-14 13:13:42,083 iteration 5910 : loss : 0.015199, loss_ce: 0.006975
2022-01-14 13:13:42,991 iteration 5911 : loss : 0.011988, loss_ce: 0.004673
2022-01-14 13:13:44,050 iteration 5912 : loss : 0.027482, loss_ce: 0.005361
2022-01-14 13:13:44,890 iteration 5913 : loss : 0.015150, loss_ce: 0.004935
2022-01-14 13:13:45,901 iteration 5914 : loss : 0.013119, loss_ce: 0.004716
2022-01-14 13:13:46,894 iteration 5915 : loss : 0.018458, loss_ce: 0.008300
2022-01-14 13:13:47,805 iteration 5916 : loss : 0.014617, loss_ce: 0.005490
 87%|█████████████████████████▏   | 348/400 [1:39:13<14:22, 16.59s/it]2022-01-14 13:13:48,775 iteration 5917 : loss : 0.028789, loss_ce: 0.005992
2022-01-14 13:13:49,763 iteration 5918 : loss : 0.019542, loss_ce: 0.008569
2022-01-14 13:13:50,639 iteration 5919 : loss : 0.011906, loss_ce: 0.006783
2022-01-14 13:13:51,643 iteration 5920 : loss : 0.021323, loss_ce: 0.010191
2022-01-14 13:13:52,560 iteration 5921 : loss : 0.020246, loss_ce: 0.006349
2022-01-14 13:13:53,508 iteration 5922 : loss : 0.015110, loss_ce: 0.006707
2022-01-14 13:13:54,417 iteration 5923 : loss : 0.014189, loss_ce: 0.003539
2022-01-14 13:13:55,304 iteration 5924 : loss : 0.013485, loss_ce: 0.005354
2022-01-14 13:13:56,203 iteration 5925 : loss : 0.011814, loss_ce: 0.003295
2022-01-14 13:13:57,118 iteration 5926 : loss : 0.010920, loss_ce: 0.003739
2022-01-14 13:13:58,108 iteration 5927 : loss : 0.016076, loss_ce: 0.006407
2022-01-14 13:13:58,936 iteration 5928 : loss : 0.011254, loss_ce: 0.004845
2022-01-14 13:13:59,811 iteration 5929 : loss : 0.014725, loss_ce: 0.003990
2022-01-14 13:14:00,743 iteration 5930 : loss : 0.022829, loss_ce: 0.009280
2022-01-14 13:14:01,680 iteration 5931 : loss : 0.025246, loss_ce: 0.012380
2022-01-14 13:14:02,584 iteration 5932 : loss : 0.017536, loss_ce: 0.006621
2022-01-14 13:14:03,461 iteration 5933 : loss : 0.010921, loss_ce: 0.004203
 87%|█████████████████████████▎   | 349/400 [1:39:29<13:51, 16.31s/it]2022-01-14 13:14:04,370 iteration 5934 : loss : 0.019989, loss_ce: 0.009819
2022-01-14 13:14:05,234 iteration 5935 : loss : 0.017532, loss_ce: 0.008256
2022-01-14 13:14:06,081 iteration 5936 : loss : 0.011569, loss_ce: 0.004499
2022-01-14 13:14:07,016 iteration 5937 : loss : 0.018577, loss_ce: 0.007769
2022-01-14 13:14:07,963 iteration 5938 : loss : 0.016290, loss_ce: 0.008081
2022-01-14 13:14:08,968 iteration 5939 : loss : 0.029024, loss_ce: 0.011424
2022-01-14 13:14:09,861 iteration 5940 : loss : 0.010588, loss_ce: 0.003839
2022-01-14 13:14:10,800 iteration 5941 : loss : 0.020313, loss_ce: 0.007327
2022-01-14 13:14:11,733 iteration 5942 : loss : 0.012380, loss_ce: 0.005003
2022-01-14 13:14:12,681 iteration 5943 : loss : 0.015464, loss_ce: 0.006537
2022-01-14 13:14:13,510 iteration 5944 : loss : 0.015743, loss_ce: 0.006498
2022-01-14 13:14:14,528 iteration 5945 : loss : 0.036334, loss_ce: 0.010717
2022-01-14 13:14:15,472 iteration 5946 : loss : 0.013471, loss_ce: 0.005940
2022-01-14 13:14:16,522 iteration 5947 : loss : 0.033266, loss_ce: 0.011692
2022-01-14 13:14:17,522 iteration 5948 : loss : 0.022857, loss_ce: 0.007624
2022-01-14 13:14:18,438 iteration 5949 : loss : 0.013447, loss_ce: 0.003587
2022-01-14 13:14:18,438 Training Data Eval:
2022-01-14 13:14:22,748   Average segmentation loss on training set: 0.0083
2022-01-14 13:14:22,748 Validation Data Eval:
2022-01-14 13:14:24,210   Average segmentation loss on validation set: 0.0664
2022-01-14 13:14:25,070 iteration 5950 : loss : 0.011496, loss_ce: 0.003737
 88%|█████████████████████████▍   | 350/400 [1:39:50<14:54, 17.90s/it]2022-01-14 13:14:25,963 iteration 5951 : loss : 0.017391, loss_ce: 0.005244
2022-01-14 13:14:26,907 iteration 5952 : loss : 0.015043, loss_ce: 0.007269
2022-01-14 13:14:27,944 iteration 5953 : loss : 0.020350, loss_ce: 0.009601
2022-01-14 13:14:28,842 iteration 5954 : loss : 0.017085, loss_ce: 0.004396
2022-01-14 13:14:29,882 iteration 5955 : loss : 0.026412, loss_ce: 0.011174
2022-01-14 13:14:30,784 iteration 5956 : loss : 0.021295, loss_ce: 0.005170
2022-01-14 13:14:31,752 iteration 5957 : loss : 0.017518, loss_ce: 0.007371
2022-01-14 13:14:32,739 iteration 5958 : loss : 0.019920, loss_ce: 0.008127
2022-01-14 13:14:33,705 iteration 5959 : loss : 0.017458, loss_ce: 0.004381
2022-01-14 13:14:34,600 iteration 5960 : loss : 0.018003, loss_ce: 0.004334
2022-01-14 13:14:35,585 iteration 5961 : loss : 0.020722, loss_ce: 0.010232
2022-01-14 13:14:36,544 iteration 5962 : loss : 0.013657, loss_ce: 0.004979
2022-01-14 13:14:37,435 iteration 5963 : loss : 0.022339, loss_ce: 0.007290
2022-01-14 13:14:38,394 iteration 5964 : loss : 0.027418, loss_ce: 0.011164
2022-01-14 13:14:39,345 iteration 5965 : loss : 0.013646, loss_ce: 0.006693
2022-01-14 13:14:40,251 iteration 5966 : loss : 0.010064, loss_ce: 0.003335
2022-01-14 13:14:41,262 iteration 5967 : loss : 0.014876, loss_ce: 0.005382
 88%|█████████████████████████▍   | 351/400 [1:40:07<14:11, 17.38s/it]2022-01-14 13:14:42,226 iteration 5968 : loss : 0.013569, loss_ce: 0.004813
2022-01-14 13:14:43,135 iteration 5969 : loss : 0.017661, loss_ce: 0.007827
2022-01-14 13:14:44,099 iteration 5970 : loss : 0.020346, loss_ce: 0.008401
2022-01-14 13:14:44,992 iteration 5971 : loss : 0.011249, loss_ce: 0.004854
2022-01-14 13:14:45,863 iteration 5972 : loss : 0.018322, loss_ce: 0.004952
2022-01-14 13:14:46,732 iteration 5973 : loss : 0.013734, loss_ce: 0.005658
2022-01-14 13:14:47,654 iteration 5974 : loss : 0.018544, loss_ce: 0.005511
2022-01-14 13:14:48,598 iteration 5975 : loss : 0.017584, loss_ce: 0.011162
2022-01-14 13:14:49,535 iteration 5976 : loss : 0.013857, loss_ce: 0.004304
2022-01-14 13:14:50,402 iteration 5977 : loss : 0.011930, loss_ce: 0.004229
2022-01-14 13:14:51,286 iteration 5978 : loss : 0.013478, loss_ce: 0.004523
2022-01-14 13:14:52,209 iteration 5979 : loss : 0.015005, loss_ce: 0.004147
2022-01-14 13:14:53,211 iteration 5980 : loss : 0.019954, loss_ce: 0.004610
2022-01-14 13:14:54,211 iteration 5981 : loss : 0.025107, loss_ce: 0.009702
2022-01-14 13:14:55,152 iteration 5982 : loss : 0.023772, loss_ce: 0.011578
2022-01-14 13:14:56,099 iteration 5983 : loss : 0.016582, loss_ce: 0.004079
2022-01-14 13:14:57,109 iteration 5984 : loss : 0.014304, loss_ce: 0.004257
 88%|█████████████████████████▌   | 352/400 [1:40:23<13:32, 16.93s/it]2022-01-14 13:14:58,134 iteration 5985 : loss : 0.018455, loss_ce: 0.007153
2022-01-14 13:14:58,958 iteration 5986 : loss : 0.009752, loss_ce: 0.004092
2022-01-14 13:14:59,947 iteration 5987 : loss : 0.036042, loss_ce: 0.014438
2022-01-14 13:15:00,793 iteration 5988 : loss : 0.012036, loss_ce: 0.004715
2022-01-14 13:15:01,709 iteration 5989 : loss : 0.014126, loss_ce: 0.006096
2022-01-14 13:15:02,619 iteration 5990 : loss : 0.023673, loss_ce: 0.005936
2022-01-14 13:15:03,593 iteration 5991 : loss : 0.019927, loss_ce: 0.005426
2022-01-14 13:15:04,582 iteration 5992 : loss : 0.022277, loss_ce: 0.005771
2022-01-14 13:15:05,470 iteration 5993 : loss : 0.023728, loss_ce: 0.008661
2022-01-14 13:15:06,313 iteration 5994 : loss : 0.009763, loss_ce: 0.004164
2022-01-14 13:15:07,300 iteration 5995 : loss : 0.014025, loss_ce: 0.004421
2022-01-14 13:15:08,280 iteration 5996 : loss : 0.015275, loss_ce: 0.008458
2022-01-14 13:15:09,159 iteration 5997 : loss : 0.015147, loss_ce: 0.004338
2022-01-14 13:15:10,212 iteration 5998 : loss : 0.025559, loss_ce: 0.011620
2022-01-14 13:15:11,128 iteration 5999 : loss : 0.018805, loss_ce: 0.006116
2022-01-14 13:15:12,178 iteration 6000 : loss : 0.025655, loss_ce: 0.010189
2022-01-14 13:15:13,048 iteration 6001 : loss : 0.012990, loss_ce: 0.004832
 88%|█████████████████████████▌   | 353/400 [1:40:38<13:01, 16.63s/it]2022-01-14 13:15:13,974 iteration 6002 : loss : 0.015387, loss_ce: 0.005517
2022-01-14 13:15:14,926 iteration 6003 : loss : 0.013207, loss_ce: 0.005807
2022-01-14 13:15:15,826 iteration 6004 : loss : 0.014911, loss_ce: 0.005761
2022-01-14 13:15:16,715 iteration 6005 : loss : 0.014158, loss_ce: 0.004968
2022-01-14 13:15:17,712 iteration 6006 : loss : 0.030529, loss_ce: 0.010343
2022-01-14 13:15:18,592 iteration 6007 : loss : 0.012869, loss_ce: 0.004777
2022-01-14 13:15:19,505 iteration 6008 : loss : 0.015258, loss_ce: 0.005550
2022-01-14 13:15:20,481 iteration 6009 : loss : 0.013437, loss_ce: 0.004017
2022-01-14 13:15:21,352 iteration 6010 : loss : 0.012961, loss_ce: 0.003102
2022-01-14 13:15:22,302 iteration 6011 : loss : 0.022033, loss_ce: 0.006253
2022-01-14 13:15:23,306 iteration 6012 : loss : 0.018317, loss_ce: 0.008729
2022-01-14 13:15:24,213 iteration 6013 : loss : 0.018004, loss_ce: 0.005810
2022-01-14 13:15:25,079 iteration 6014 : loss : 0.012945, loss_ce: 0.004803
2022-01-14 13:15:25,912 iteration 6015 : loss : 0.011885, loss_ce: 0.005420
2022-01-14 13:15:26,803 iteration 6016 : loss : 0.025792, loss_ce: 0.007752
2022-01-14 13:15:27,735 iteration 6017 : loss : 0.012304, loss_ce: 0.005097
2022-01-14 13:15:28,573 iteration 6018 : loss : 0.015106, loss_ce: 0.005684
 88%|█████████████████████████▋   | 354/400 [1:40:54<12:29, 16.30s/it]2022-01-14 13:15:29,606 iteration 6019 : loss : 0.014168, loss_ce: 0.005414
2022-01-14 13:15:30,557 iteration 6020 : loss : 0.016942, loss_ce: 0.005466
2022-01-14 13:15:31,430 iteration 6021 : loss : 0.010344, loss_ce: 0.003742
2022-01-14 13:15:32,392 iteration 6022 : loss : 0.023250, loss_ce: 0.010053
2022-01-14 13:15:33,338 iteration 6023 : loss : 0.012296, loss_ce: 0.005618
2022-01-14 13:15:34,282 iteration 6024 : loss : 0.012333, loss_ce: 0.004761
2022-01-14 13:15:35,147 iteration 6025 : loss : 0.019647, loss_ce: 0.003959
2022-01-14 13:15:36,040 iteration 6026 : loss : 0.015124, loss_ce: 0.005537
2022-01-14 13:15:37,000 iteration 6027 : loss : 0.016778, loss_ce: 0.007010
2022-01-14 13:15:37,876 iteration 6028 : loss : 0.012147, loss_ce: 0.005551
2022-01-14 13:15:38,803 iteration 6029 : loss : 0.019369, loss_ce: 0.008430
2022-01-14 13:15:39,794 iteration 6030 : loss : 0.017130, loss_ce: 0.006430
2022-01-14 13:15:40,748 iteration 6031 : loss : 0.024080, loss_ce: 0.008728
2022-01-14 13:15:41,680 iteration 6032 : loss : 0.022955, loss_ce: 0.007747
2022-01-14 13:15:42,608 iteration 6033 : loss : 0.020327, loss_ce: 0.006712
2022-01-14 13:15:43,465 iteration 6034 : loss : 0.010269, loss_ce: 0.003479
2022-01-14 13:15:43,465 Training Data Eval:
2022-01-14 13:15:47,766   Average segmentation loss on training set: 0.0085
2022-01-14 13:15:47,766 Validation Data Eval:
2022-01-14 13:15:49,221   Average segmentation loss on validation set: 0.0645
2022-01-14 13:15:50,081 iteration 6035 : loss : 0.015353, loss_ce: 0.006474
 89%|█████████████████████████▋   | 355/400 [1:41:15<13:23, 17.86s/it]2022-01-14 13:15:51,077 iteration 6036 : loss : 0.016468, loss_ce: 0.007303
2022-01-14 13:15:51,941 iteration 6037 : loss : 0.012424, loss_ce: 0.004876
2022-01-14 13:15:52,807 iteration 6038 : loss : 0.011747, loss_ce: 0.004274
2022-01-14 13:15:53,624 iteration 6039 : loss : 0.012500, loss_ce: 0.004154
2022-01-14 13:15:54,503 iteration 6040 : loss : 0.013661, loss_ce: 0.003833
2022-01-14 13:15:55,462 iteration 6041 : loss : 0.018638, loss_ce: 0.007559
2022-01-14 13:15:56,334 iteration 6042 : loss : 0.017302, loss_ce: 0.004062
2022-01-14 13:15:57,166 iteration 6043 : loss : 0.010598, loss_ce: 0.002586
2022-01-14 13:15:58,088 iteration 6044 : loss : 0.014317, loss_ce: 0.004362
2022-01-14 13:15:58,969 iteration 6045 : loss : 0.011273, loss_ce: 0.004758
2022-01-14 13:15:59,886 iteration 6046 : loss : 0.011547, loss_ce: 0.004793
2022-01-14 13:16:00,767 iteration 6047 : loss : 0.011576, loss_ce: 0.004227
2022-01-14 13:16:01,727 iteration 6048 : loss : 0.016926, loss_ce: 0.007904
2022-01-14 13:16:02,639 iteration 6049 : loss : 0.016466, loss_ce: 0.008597
2022-01-14 13:16:03,553 iteration 6050 : loss : 0.017738, loss_ce: 0.005850
2022-01-14 13:16:04,585 iteration 6051 : loss : 0.015477, loss_ce: 0.005476
2022-01-14 13:16:05,492 iteration 6052 : loss : 0.013254, loss_ce: 0.005968
 89%|█████████████████████████▊   | 356/400 [1:41:31<12:33, 17.13s/it]2022-01-14 13:16:06,408 iteration 6053 : loss : 0.015561, loss_ce: 0.005263
2022-01-14 13:16:07,252 iteration 6054 : loss : 0.013572, loss_ce: 0.006666
2022-01-14 13:16:08,222 iteration 6055 : loss : 0.016365, loss_ce: 0.005453
2022-01-14 13:16:09,106 iteration 6056 : loss : 0.011547, loss_ce: 0.004273
2022-01-14 13:16:09,982 iteration 6057 : loss : 0.013026, loss_ce: 0.003753
2022-01-14 13:16:10,916 iteration 6058 : loss : 0.019335, loss_ce: 0.006485
2022-01-14 13:16:11,891 iteration 6059 : loss : 0.015247, loss_ce: 0.006850
2022-01-14 13:16:12,959 iteration 6060 : loss : 0.028055, loss_ce: 0.009842
2022-01-14 13:16:13,898 iteration 6061 : loss : 0.012228, loss_ce: 0.004888
2022-01-14 13:16:14,900 iteration 6062 : loss : 0.021675, loss_ce: 0.007991
2022-01-14 13:16:15,775 iteration 6063 : loss : 0.016011, loss_ce: 0.004900
2022-01-14 13:16:16,798 iteration 6064 : loss : 0.019364, loss_ce: 0.007190
2022-01-14 13:16:17,663 iteration 6065 : loss : 0.009260, loss_ce: 0.003460
2022-01-14 13:16:18,521 iteration 6066 : loss : 0.008551, loss_ce: 0.002352
2022-01-14 13:16:19,433 iteration 6067 : loss : 0.016288, loss_ce: 0.007526
2022-01-14 13:16:20,308 iteration 6068 : loss : 0.010365, loss_ce: 0.002722
2022-01-14 13:16:21,197 iteration 6069 : loss : 0.021194, loss_ce: 0.009447
 89%|█████████████████████████▉   | 357/400 [1:41:47<11:58, 16.70s/it]2022-01-14 13:16:22,183 iteration 6070 : loss : 0.009737, loss_ce: 0.004888
2022-01-14 13:16:23,049 iteration 6071 : loss : 0.010032, loss_ce: 0.003276
2022-01-14 13:16:23,918 iteration 6072 : loss : 0.015240, loss_ce: 0.008256
2022-01-14 13:16:24,841 iteration 6073 : loss : 0.013005, loss_ce: 0.004040
2022-01-14 13:16:25,812 iteration 6074 : loss : 0.015065, loss_ce: 0.005497
2022-01-14 13:16:26,648 iteration 6075 : loss : 0.009939, loss_ce: 0.004245
2022-01-14 13:16:27,542 iteration 6076 : loss : 0.016048, loss_ce: 0.003351
2022-01-14 13:16:28,455 iteration 6077 : loss : 0.016012, loss_ce: 0.005679
2022-01-14 13:16:29,449 iteration 6078 : loss : 0.025304, loss_ce: 0.008356
2022-01-14 13:16:30,512 iteration 6079 : loss : 0.021216, loss_ce: 0.008592
2022-01-14 13:16:31,450 iteration 6080 : loss : 0.014806, loss_ce: 0.004927
2022-01-14 13:16:32,423 iteration 6081 : loss : 0.020358, loss_ce: 0.007473
2022-01-14 13:16:33,243 iteration 6082 : loss : 0.020662, loss_ce: 0.004990
2022-01-14 13:16:34,109 iteration 6083 : loss : 0.014402, loss_ce: 0.004283
2022-01-14 13:16:35,027 iteration 6084 : loss : 0.020638, loss_ce: 0.005257
2022-01-14 13:16:35,931 iteration 6085 : loss : 0.016674, loss_ce: 0.005633
2022-01-14 13:16:36,824 iteration 6086 : loss : 0.011218, loss_ce: 0.003635
 90%|█████████████████████████▉   | 358/400 [1:42:02<11:27, 16.38s/it]2022-01-14 13:16:37,736 iteration 6087 : loss : 0.012412, loss_ce: 0.003785
2022-01-14 13:16:38,701 iteration 6088 : loss : 0.014933, loss_ce: 0.005882
2022-01-14 13:16:39,604 iteration 6089 : loss : 0.012804, loss_ce: 0.003896
2022-01-14 13:16:40,463 iteration 6090 : loss : 0.011666, loss_ce: 0.004841
2022-01-14 13:16:41,400 iteration 6091 : loss : 0.011450, loss_ce: 0.003985
2022-01-14 13:16:42,316 iteration 6092 : loss : 0.015492, loss_ce: 0.004881
2022-01-14 13:16:43,232 iteration 6093 : loss : 0.015498, loss_ce: 0.006493
2022-01-14 13:16:44,089 iteration 6094 : loss : 0.024451, loss_ce: 0.008286
2022-01-14 13:16:44,965 iteration 6095 : loss : 0.011945, loss_ce: 0.003762
2022-01-14 13:16:45,893 iteration 6096 : loss : 0.015831, loss_ce: 0.005787
2022-01-14 13:16:46,847 iteration 6097 : loss : 0.014416, loss_ce: 0.006629
2022-01-14 13:16:47,851 iteration 6098 : loss : 0.019275, loss_ce: 0.008180
2022-01-14 13:16:48,829 iteration 6099 : loss : 0.017855, loss_ce: 0.007463
2022-01-14 13:16:49,798 iteration 6100 : loss : 0.016852, loss_ce: 0.008596
2022-01-14 13:16:50,735 iteration 6101 : loss : 0.016524, loss_ce: 0.006715
2022-01-14 13:16:51,701 iteration 6102 : loss : 0.017956, loss_ce: 0.009145
2022-01-14 13:16:52,682 iteration 6103 : loss : 0.016187, loss_ce: 0.005033
 90%|██████████████████████████   | 359/400 [1:42:18<11:05, 16.22s/it]2022-01-14 13:16:53,743 iteration 6104 : loss : 0.015697, loss_ce: 0.006970
2022-01-14 13:16:54,736 iteration 6105 : loss : 0.014186, loss_ce: 0.006777
2022-01-14 13:16:55,665 iteration 6106 : loss : 0.017225, loss_ce: 0.007807
2022-01-14 13:16:56,599 iteration 6107 : loss : 0.016746, loss_ce: 0.006117
2022-01-14 13:16:57,496 iteration 6108 : loss : 0.012406, loss_ce: 0.005175
2022-01-14 13:16:58,390 iteration 6109 : loss : 0.020766, loss_ce: 0.004442
2022-01-14 13:16:59,276 iteration 6110 : loss : 0.012344, loss_ce: 0.005050
2022-01-14 13:17:00,190 iteration 6111 : loss : 0.013851, loss_ce: 0.005943
2022-01-14 13:17:01,104 iteration 6112 : loss : 0.018643, loss_ce: 0.004782
2022-01-14 13:17:02,022 iteration 6113 : loss : 0.013550, loss_ce: 0.005694
2022-01-14 13:17:02,984 iteration 6114 : loss : 0.013670, loss_ce: 0.004314
2022-01-14 13:17:03,896 iteration 6115 : loss : 0.015726, loss_ce: 0.006676
2022-01-14 13:17:04,834 iteration 6116 : loss : 0.018084, loss_ce: 0.005854
2022-01-14 13:17:05,714 iteration 6117 : loss : 0.012370, loss_ce: 0.004868
2022-01-14 13:17:06,585 iteration 6118 : loss : 0.011305, loss_ce: 0.003695
2022-01-14 13:17:07,605 iteration 6119 : loss : 0.019901, loss_ce: 0.008836
2022-01-14 13:17:07,606 Training Data Eval:
2022-01-14 13:17:11,898   Average segmentation loss on training set: 0.0082
2022-01-14 13:17:11,898 Validation Data Eval:
2022-01-14 13:17:13,345   Average segmentation loss on validation set: 0.0686
2022-01-14 13:17:14,245 iteration 6120 : loss : 0.019147, loss_ce: 0.006143
 90%|██████████████████████████   | 360/400 [1:42:40<11:52, 17.82s/it]2022-01-14 13:17:15,203 iteration 6121 : loss : 0.015300, loss_ce: 0.004492
2022-01-14 13:17:16,121 iteration 6122 : loss : 0.015848, loss_ce: 0.007482
2022-01-14 13:17:17,026 iteration 6123 : loss : 0.017090, loss_ce: 0.007024
2022-01-14 13:17:17,887 iteration 6124 : loss : 0.010258, loss_ce: 0.003531
2022-01-14 13:17:18,789 iteration 6125 : loss : 0.026889, loss_ce: 0.010890
2022-01-14 13:17:19,660 iteration 6126 : loss : 0.013295, loss_ce: 0.006987
2022-01-14 13:17:20,623 iteration 6127 : loss : 0.012017, loss_ce: 0.003735
2022-01-14 13:17:21,522 iteration 6128 : loss : 0.016018, loss_ce: 0.004827
2022-01-14 13:17:22,538 iteration 6129 : loss : 0.012899, loss_ce: 0.004876
2022-01-14 13:17:23,427 iteration 6130 : loss : 0.016406, loss_ce: 0.003879
2022-01-14 13:17:24,440 iteration 6131 : loss : 0.020760, loss_ce: 0.011606
2022-01-14 13:17:25,325 iteration 6132 : loss : 0.013688, loss_ce: 0.007257
2022-01-14 13:17:26,275 iteration 6133 : loss : 0.017420, loss_ce: 0.004753
2022-01-14 13:17:27,199 iteration 6134 : loss : 0.014545, loss_ce: 0.004927
2022-01-14 13:17:28,228 iteration 6135 : loss : 0.019786, loss_ce: 0.007210
2022-01-14 13:17:29,128 iteration 6136 : loss : 0.019830, loss_ce: 0.004931
2022-01-14 13:17:30,023 iteration 6137 : loss : 0.014356, loss_ce: 0.005465
 90%|██████████████████████████▏  | 361/400 [1:42:55<11:11, 17.21s/it]2022-01-14 13:17:30,963 iteration 6138 : loss : 0.017526, loss_ce: 0.006269
2022-01-14 13:17:31,871 iteration 6139 : loss : 0.012822, loss_ce: 0.005079
2022-01-14 13:17:32,769 iteration 6140 : loss : 0.022233, loss_ce: 0.009425
2022-01-14 13:17:33,604 iteration 6141 : loss : 0.009794, loss_ce: 0.003664
2022-01-14 13:17:34,425 iteration 6142 : loss : 0.010524, loss_ce: 0.004908
2022-01-14 13:17:35,404 iteration 6143 : loss : 0.016458, loss_ce: 0.004285
2022-01-14 13:17:36,287 iteration 6144 : loss : 0.013939, loss_ce: 0.005370
2022-01-14 13:17:37,180 iteration 6145 : loss : 0.013694, loss_ce: 0.005960
2022-01-14 13:17:38,051 iteration 6146 : loss : 0.014230, loss_ce: 0.004243
2022-01-14 13:17:38,955 iteration 6147 : loss : 0.015008, loss_ce: 0.006099
2022-01-14 13:17:39,919 iteration 6148 : loss : 0.015197, loss_ce: 0.005291
2022-01-14 13:17:40,873 iteration 6149 : loss : 0.016759, loss_ce: 0.005421
2022-01-14 13:17:41,877 iteration 6150 : loss : 0.024038, loss_ce: 0.008305
2022-01-14 13:17:42,865 iteration 6151 : loss : 0.018839, loss_ce: 0.004391
2022-01-14 13:17:43,738 iteration 6152 : loss : 0.012076, loss_ce: 0.005101
2022-01-14 13:17:44,677 iteration 6153 : loss : 0.046962, loss_ce: 0.008891
2022-01-14 13:17:45,645 iteration 6154 : loss : 0.019156, loss_ce: 0.007757
 90%|██████████████████████████▏  | 362/400 [1:43:11<10:35, 16.73s/it]2022-01-14 13:17:46,689 iteration 6155 : loss : 0.028395, loss_ce: 0.009671
2022-01-14 13:17:47,628 iteration 6156 : loss : 0.016085, loss_ce: 0.006766
2022-01-14 13:17:48,563 iteration 6157 : loss : 0.014186, loss_ce: 0.005504
2022-01-14 13:17:49,588 iteration 6158 : loss : 0.017939, loss_ce: 0.005341
2022-01-14 13:17:50,479 iteration 6159 : loss : 0.012876, loss_ce: 0.004213
2022-01-14 13:17:51,361 iteration 6160 : loss : 0.012391, loss_ce: 0.004296
2022-01-14 13:17:52,325 iteration 6161 : loss : 0.019519, loss_ce: 0.006143
2022-01-14 13:17:53,321 iteration 6162 : loss : 0.027997, loss_ce: 0.006634
2022-01-14 13:17:54,256 iteration 6163 : loss : 0.014528, loss_ce: 0.005834
2022-01-14 13:17:55,102 iteration 6164 : loss : 0.012118, loss_ce: 0.003326
2022-01-14 13:17:56,088 iteration 6165 : loss : 0.018648, loss_ce: 0.007376
2022-01-14 13:17:56,978 iteration 6166 : loss : 0.015286, loss_ce: 0.005685
2022-01-14 13:17:57,973 iteration 6167 : loss : 0.017529, loss_ce: 0.008089
2022-01-14 13:17:58,910 iteration 6168 : loss : 0.016108, loss_ce: 0.005979
2022-01-14 13:17:59,823 iteration 6169 : loss : 0.015565, loss_ce: 0.004058
2022-01-14 13:18:00,688 iteration 6170 : loss : 0.012961, loss_ce: 0.006404
2022-01-14 13:18:01,590 iteration 6171 : loss : 0.021407, loss_ce: 0.011304
 91%|██████████████████████████▎  | 363/400 [1:43:27<10:10, 16.50s/it]2022-01-14 13:18:02,554 iteration 6172 : loss : 0.014185, loss_ce: 0.005209
2022-01-14 13:18:03,562 iteration 6173 : loss : 0.031361, loss_ce: 0.007456
2022-01-14 13:18:04,515 iteration 6174 : loss : 0.015229, loss_ce: 0.006673
2022-01-14 13:18:05,554 iteration 6175 : loss : 0.013976, loss_ce: 0.004045
2022-01-14 13:18:06,510 iteration 6176 : loss : 0.019267, loss_ce: 0.007248
2022-01-14 13:18:07,437 iteration 6177 : loss : 0.017892, loss_ce: 0.007094
2022-01-14 13:18:08,376 iteration 6178 : loss : 0.013975, loss_ce: 0.004875
2022-01-14 13:18:09,258 iteration 6179 : loss : 0.020205, loss_ce: 0.006432
2022-01-14 13:18:10,247 iteration 6180 : loss : 0.018431, loss_ce: 0.007982
2022-01-14 13:18:11,117 iteration 6181 : loss : 0.010843, loss_ce: 0.003294
2022-01-14 13:18:12,007 iteration 6182 : loss : 0.013039, loss_ce: 0.003673
2022-01-14 13:18:12,988 iteration 6183 : loss : 0.014725, loss_ce: 0.005855
2022-01-14 13:18:13,945 iteration 6184 : loss : 0.013001, loss_ce: 0.005811
2022-01-14 13:18:14,946 iteration 6185 : loss : 0.023166, loss_ce: 0.006360
2022-01-14 13:18:15,855 iteration 6186 : loss : 0.012089, loss_ce: 0.004200
2022-01-14 13:18:16,800 iteration 6187 : loss : 0.020654, loss_ce: 0.009623
2022-01-14 13:18:17,825 iteration 6188 : loss : 0.019037, loss_ce: 0.008616
 91%|██████████████████████████▍  | 364/400 [1:43:43<09:51, 16.42s/it]2022-01-14 13:18:18,867 iteration 6189 : loss : 0.014696, loss_ce: 0.003341
2022-01-14 13:18:19,873 iteration 6190 : loss : 0.015148, loss_ce: 0.004616
2022-01-14 13:18:20,775 iteration 6191 : loss : 0.013512, loss_ce: 0.006522
2022-01-14 13:18:21,639 iteration 6192 : loss : 0.012733, loss_ce: 0.005618
2022-01-14 13:18:22,533 iteration 6193 : loss : 0.020272, loss_ce: 0.006337
2022-01-14 13:18:23,390 iteration 6194 : loss : 0.015257, loss_ce: 0.005773
2022-01-14 13:18:24,404 iteration 6195 : loss : 0.011945, loss_ce: 0.004262
2022-01-14 13:18:25,304 iteration 6196 : loss : 0.021179, loss_ce: 0.006331
2022-01-14 13:18:26,170 iteration 6197 : loss : 0.011391, loss_ce: 0.005263
2022-01-14 13:18:27,233 iteration 6198 : loss : 0.032831, loss_ce: 0.010711
2022-01-14 13:18:28,147 iteration 6199 : loss : 0.016698, loss_ce: 0.006758
2022-01-14 13:18:29,050 iteration 6200 : loss : 0.012593, loss_ce: 0.005606
2022-01-14 13:18:29,992 iteration 6201 : loss : 0.016666, loss_ce: 0.006444
2022-01-14 13:18:30,854 iteration 6202 : loss : 0.015566, loss_ce: 0.005345
2022-01-14 13:18:31,908 iteration 6203 : loss : 0.019944, loss_ce: 0.007812
2022-01-14 13:18:32,771 iteration 6204 : loss : 0.011539, loss_ce: 0.005323
2022-01-14 13:18:32,771 Training Data Eval:
2022-01-14 13:18:37,075   Average segmentation loss on training set: 0.0083
2022-01-14 13:18:37,076 Validation Data Eval:
2022-01-14 13:18:38,527   Average segmentation loss on validation set: 0.0665
2022-01-14 13:18:39,505 iteration 6205 : loss : 0.020927, loss_ce: 0.007166
 91%|██████████████████████████▍  | 365/400 [1:44:05<10:29, 18.00s/it]2022-01-14 13:18:40,517 iteration 6206 : loss : 0.024074, loss_ce: 0.009976
2022-01-14 13:18:41,467 iteration 6207 : loss : 0.014350, loss_ce: 0.005358
2022-01-14 13:18:42,444 iteration 6208 : loss : 0.022084, loss_ce: 0.007508
2022-01-14 13:18:43,392 iteration 6209 : loss : 0.013872, loss_ce: 0.005019
2022-01-14 13:18:44,341 iteration 6210 : loss : 0.018764, loss_ce: 0.008191
2022-01-14 13:18:45,246 iteration 6211 : loss : 0.015727, loss_ce: 0.007200
2022-01-14 13:18:46,131 iteration 6212 : loss : 0.010852, loss_ce: 0.004110
2022-01-14 13:18:46,961 iteration 6213 : loss : 0.010848, loss_ce: 0.003702
2022-01-14 13:18:47,949 iteration 6214 : loss : 0.018680, loss_ce: 0.007128
2022-01-14 13:18:48,863 iteration 6215 : loss : 0.012642, loss_ce: 0.003496
2022-01-14 13:18:49,804 iteration 6216 : loss : 0.016797, loss_ce: 0.005654
2022-01-14 13:18:50,766 iteration 6217 : loss : 0.021680, loss_ce: 0.009649
2022-01-14 13:18:51,635 iteration 6218 : loss : 0.013366, loss_ce: 0.005419
2022-01-14 13:18:52,585 iteration 6219 : loss : 0.016865, loss_ce: 0.006095
2022-01-14 13:18:53,416 iteration 6220 : loss : 0.011309, loss_ce: 0.002955
2022-01-14 13:18:54,430 iteration 6221 : loss : 0.013753, loss_ce: 0.004300
2022-01-14 13:18:55,355 iteration 6222 : loss : 0.020009, loss_ce: 0.008369
 92%|██████████████████████████▌  | 366/400 [1:44:21<09:49, 17.35s/it]2022-01-14 13:18:56,364 iteration 6223 : loss : 0.014346, loss_ce: 0.006443
2022-01-14 13:18:57,338 iteration 6224 : loss : 0.014469, loss_ce: 0.006749
2022-01-14 13:18:58,293 iteration 6225 : loss : 0.014312, loss_ce: 0.006014
2022-01-14 13:18:59,197 iteration 6226 : loss : 0.017196, loss_ce: 0.006198
2022-01-14 13:19:00,216 iteration 6227 : loss : 0.010771, loss_ce: 0.003468
2022-01-14 13:19:01,109 iteration 6228 : loss : 0.013782, loss_ce: 0.005338
2022-01-14 13:19:02,070 iteration 6229 : loss : 0.021589, loss_ce: 0.007129
2022-01-14 13:19:03,059 iteration 6230 : loss : 0.043630, loss_ce: 0.008947
2022-01-14 13:19:03,931 iteration 6231 : loss : 0.014147, loss_ce: 0.006461
2022-01-14 13:19:04,820 iteration 6232 : loss : 0.018208, loss_ce: 0.005938
2022-01-14 13:19:05,833 iteration 6233 : loss : 0.023868, loss_ce: 0.009895
2022-01-14 13:19:06,746 iteration 6234 : loss : 0.022715, loss_ce: 0.009170
2022-01-14 13:19:07,670 iteration 6235 : loss : 0.013336, loss_ce: 0.004003
2022-01-14 13:19:08,651 iteration 6236 : loss : 0.023277, loss_ce: 0.010101
2022-01-14 13:19:09,577 iteration 6237 : loss : 0.014358, loss_ce: 0.004430
2022-01-14 13:19:10,566 iteration 6238 : loss : 0.015167, loss_ce: 0.006119
2022-01-14 13:19:11,554 iteration 6239 : loss : 0.020341, loss_ce: 0.008710
 92%|██████████████████████████▌  | 367/400 [1:44:37<09:21, 17.01s/it]2022-01-14 13:19:12,496 iteration 6240 : loss : 0.014771, loss_ce: 0.004987
2022-01-14 13:19:13,355 iteration 6241 : loss : 0.013842, loss_ce: 0.005867
2022-01-14 13:19:14,316 iteration 6242 : loss : 0.014292, loss_ce: 0.006331
2022-01-14 13:19:15,222 iteration 6243 : loss : 0.020204, loss_ce: 0.008493
2022-01-14 13:19:16,163 iteration 6244 : loss : 0.016779, loss_ce: 0.005548
2022-01-14 13:19:17,115 iteration 6245 : loss : 0.013674, loss_ce: 0.005169
2022-01-14 13:19:18,016 iteration 6246 : loss : 0.011535, loss_ce: 0.004519
2022-01-14 13:19:18,901 iteration 6247 : loss : 0.012230, loss_ce: 0.004323
2022-01-14 13:19:19,859 iteration 6248 : loss : 0.024605, loss_ce: 0.005466
2022-01-14 13:19:20,828 iteration 6249 : loss : 0.016241, loss_ce: 0.005789
2022-01-14 13:19:21,656 iteration 6250 : loss : 0.011221, loss_ce: 0.002583
2022-01-14 13:19:22,634 iteration 6251 : loss : 0.028785, loss_ce: 0.016302
2022-01-14 13:19:23,482 iteration 6252 : loss : 0.018592, loss_ce: 0.007059
2022-01-14 13:19:24,496 iteration 6253 : loss : 0.015595, loss_ce: 0.005868
2022-01-14 13:19:25,333 iteration 6254 : loss : 0.009444, loss_ce: 0.004143
2022-01-14 13:19:26,408 iteration 6255 : loss : 0.029471, loss_ce: 0.009373
2022-01-14 13:19:27,301 iteration 6256 : loss : 0.027218, loss_ce: 0.010089
 92%|██████████████████████████▋  | 368/400 [1:44:53<08:52, 16.63s/it]2022-01-14 13:19:28,317 iteration 6257 : loss : 0.015253, loss_ce: 0.006057
2022-01-14 13:19:29,226 iteration 6258 : loss : 0.010002, loss_ce: 0.004758
2022-01-14 13:19:30,155 iteration 6259 : loss : 0.013041, loss_ce: 0.006041
2022-01-14 13:19:31,076 iteration 6260 : loss : 0.014564, loss_ce: 0.003951
2022-01-14 13:19:31,944 iteration 6261 : loss : 0.013353, loss_ce: 0.005352
2022-01-14 13:19:32,903 iteration 6262 : loss : 0.015138, loss_ce: 0.006611
2022-01-14 13:19:33,855 iteration 6263 : loss : 0.016795, loss_ce: 0.004222
2022-01-14 13:19:34,767 iteration 6264 : loss : 0.011692, loss_ce: 0.005260
2022-01-14 13:19:35,647 iteration 6265 : loss : 0.013599, loss_ce: 0.005753
2022-01-14 13:19:36,583 iteration 6266 : loss : 0.013248, loss_ce: 0.005466
2022-01-14 13:19:37,495 iteration 6267 : loss : 0.017238, loss_ce: 0.006445
2022-01-14 13:19:38,411 iteration 6268 : loss : 0.014041, loss_ce: 0.004953
2022-01-14 13:19:39,312 iteration 6269 : loss : 0.017735, loss_ce: 0.005545
2022-01-14 13:19:40,253 iteration 6270 : loss : 0.014699, loss_ce: 0.004146
2022-01-14 13:19:41,167 iteration 6271 : loss : 0.016151, loss_ce: 0.003637
2022-01-14 13:19:42,081 iteration 6272 : loss : 0.019467, loss_ce: 0.006004
2022-01-14 13:19:42,927 iteration 6273 : loss : 0.011465, loss_ce: 0.005019
 92%|██████████████████████████▊  | 369/400 [1:45:08<08:26, 16.33s/it]2022-01-14 13:19:43,868 iteration 6274 : loss : 0.017061, loss_ce: 0.005401
2022-01-14 13:19:44,792 iteration 6275 : loss : 0.016460, loss_ce: 0.008706
2022-01-14 13:19:45,684 iteration 6276 : loss : 0.012605, loss_ce: 0.004062
2022-01-14 13:19:46,665 iteration 6277 : loss : 0.022643, loss_ce: 0.006111
2022-01-14 13:19:47,657 iteration 6278 : loss : 0.022841, loss_ce: 0.009720
2022-01-14 13:19:48,710 iteration 6279 : loss : 0.024064, loss_ce: 0.008334
2022-01-14 13:19:49,645 iteration 6280 : loss : 0.016558, loss_ce: 0.007114
2022-01-14 13:19:50,558 iteration 6281 : loss : 0.011966, loss_ce: 0.003801
2022-01-14 13:19:51,432 iteration 6282 : loss : 0.010479, loss_ce: 0.004191
2022-01-14 13:19:52,420 iteration 6283 : loss : 0.025254, loss_ce: 0.006627
2022-01-14 13:19:53,433 iteration 6284 : loss : 0.016194, loss_ce: 0.008536
2022-01-14 13:19:54,362 iteration 6285 : loss : 0.017303, loss_ce: 0.006377
2022-01-14 13:19:55,288 iteration 6286 : loss : 0.011382, loss_ce: 0.005532
2022-01-14 13:19:56,260 iteration 6287 : loss : 0.012255, loss_ce: 0.004382
2022-01-14 13:19:57,280 iteration 6288 : loss : 0.024475, loss_ce: 0.009999
2022-01-14 13:19:58,187 iteration 6289 : loss : 0.015056, loss_ce: 0.005267
2022-01-14 13:19:58,188 Training Data Eval:
2022-01-14 13:20:02,482   Average segmentation loss on training set: 0.0082
2022-01-14 13:20:02,482 Validation Data Eval:
2022-01-14 13:20:03,944   Average segmentation loss on validation set: 0.0742
2022-01-14 13:20:04,823 iteration 6290 : loss : 0.011741, loss_ce: 0.004488
 92%|██████████████████████████▊  | 370/400 [1:45:30<09:00, 18.00s/it]2022-01-14 13:20:05,796 iteration 6291 : loss : 0.012917, loss_ce: 0.003022
2022-01-14 13:20:06,823 iteration 6292 : loss : 0.013938, loss_ce: 0.005305
2022-01-14 13:20:07,731 iteration 6293 : loss : 0.017919, loss_ce: 0.006231
2022-01-14 13:20:08,683 iteration 6294 : loss : 0.015180, loss_ce: 0.006046
2022-01-14 13:20:09,633 iteration 6295 : loss : 0.021211, loss_ce: 0.008268
2022-01-14 13:20:10,544 iteration 6296 : loss : 0.013189, loss_ce: 0.005192
2022-01-14 13:20:11,446 iteration 6297 : loss : 0.017777, loss_ce: 0.004841
2022-01-14 13:20:12,344 iteration 6298 : loss : 0.012819, loss_ce: 0.004409
2022-01-14 13:20:13,321 iteration 6299 : loss : 0.016162, loss_ce: 0.006349
2022-01-14 13:20:14,255 iteration 6300 : loss : 0.013798, loss_ce: 0.005145
2022-01-14 13:20:15,142 iteration 6301 : loss : 0.015355, loss_ce: 0.006477
2022-01-14 13:20:16,022 iteration 6302 : loss : 0.014548, loss_ce: 0.006125
2022-01-14 13:20:16,961 iteration 6303 : loss : 0.015511, loss_ce: 0.006200
2022-01-14 13:20:17,859 iteration 6304 : loss : 0.012529, loss_ce: 0.004942
2022-01-14 13:20:18,707 iteration 6305 : loss : 0.010411, loss_ce: 0.004533
2022-01-14 13:20:19,560 iteration 6306 : loss : 0.011665, loss_ce: 0.004285
2022-01-14 13:20:20,558 iteration 6307 : loss : 0.016421, loss_ce: 0.005077
 93%|██████████████████████████▉  | 371/400 [1:45:46<08:22, 17.32s/it]2022-01-14 13:20:21,508 iteration 6308 : loss : 0.013023, loss_ce: 0.005571
2022-01-14 13:20:22,464 iteration 6309 : loss : 0.017609, loss_ce: 0.006398
2022-01-14 13:20:23,382 iteration 6310 : loss : 0.014156, loss_ce: 0.006665
2022-01-14 13:20:24,269 iteration 6311 : loss : 0.012929, loss_ce: 0.003174
2022-01-14 13:20:25,215 iteration 6312 : loss : 0.012186, loss_ce: 0.004202
2022-01-14 13:20:26,114 iteration 6313 : loss : 0.008567, loss_ce: 0.001952
2022-01-14 13:20:27,067 iteration 6314 : loss : 0.016474, loss_ce: 0.007507
2022-01-14 13:20:28,058 iteration 6315 : loss : 0.018527, loss_ce: 0.006392
2022-01-14 13:20:28,983 iteration 6316 : loss : 0.013496, loss_ce: 0.006277
2022-01-14 13:20:29,939 iteration 6317 : loss : 0.012005, loss_ce: 0.004883
2022-01-14 13:20:30,954 iteration 6318 : loss : 0.017232, loss_ce: 0.007412
2022-01-14 13:20:31,956 iteration 6319 : loss : 0.017184, loss_ce: 0.007472
2022-01-14 13:20:32,992 iteration 6320 : loss : 0.013951, loss_ce: 0.005209
2022-01-14 13:20:33,982 iteration 6321 : loss : 0.022126, loss_ce: 0.009254
2022-01-14 13:20:34,997 iteration 6322 : loss : 0.017004, loss_ce: 0.006491
2022-01-14 13:20:35,790 iteration 6323 : loss : 0.009606, loss_ce: 0.004273
2022-01-14 13:20:36,733 iteration 6324 : loss : 0.014345, loss_ce: 0.003970
 93%|██████████████████████████▉  | 372/400 [1:46:02<07:55, 16.98s/it]2022-01-14 13:20:37,640 iteration 6325 : loss : 0.015360, loss_ce: 0.004596
2022-01-14 13:20:38,484 iteration 6326 : loss : 0.009950, loss_ce: 0.004429
2022-01-14 13:20:39,326 iteration 6327 : loss : 0.010334, loss_ce: 0.003808
2022-01-14 13:20:40,325 iteration 6328 : loss : 0.018078, loss_ce: 0.007857
2022-01-14 13:20:41,361 iteration 6329 : loss : 0.016660, loss_ce: 0.007575
2022-01-14 13:20:42,318 iteration 6330 : loss : 0.013657, loss_ce: 0.006299
2022-01-14 13:20:43,306 iteration 6331 : loss : 0.014484, loss_ce: 0.006204
2022-01-14 13:20:44,204 iteration 6332 : loss : 0.013572, loss_ce: 0.004684
2022-01-14 13:20:45,116 iteration 6333 : loss : 0.012156, loss_ce: 0.004570
2022-01-14 13:20:46,063 iteration 6334 : loss : 0.010578, loss_ce: 0.004217
2022-01-14 13:20:47,157 iteration 6335 : loss : 0.024925, loss_ce: 0.012587
2022-01-14 13:20:48,097 iteration 6336 : loss : 0.017084, loss_ce: 0.006417
2022-01-14 13:20:48,942 iteration 6337 : loss : 0.012878, loss_ce: 0.005005
2022-01-14 13:20:49,960 iteration 6338 : loss : 0.013767, loss_ce: 0.004428
2022-01-14 13:20:50,861 iteration 6339 : loss : 0.012866, loss_ce: 0.004725
2022-01-14 13:20:51,796 iteration 6340 : loss : 0.015678, loss_ce: 0.007876
2022-01-14 13:20:52,748 iteration 6341 : loss : 0.017540, loss_ce: 0.004890
 93%|███████████████████████████  | 373/400 [1:46:18<07:30, 16.69s/it]2022-01-14 13:20:53,863 iteration 6342 : loss : 0.014062, loss_ce: 0.004893
2022-01-14 13:20:54,765 iteration 6343 : loss : 0.013029, loss_ce: 0.003707
2022-01-14 13:20:55,706 iteration 6344 : loss : 0.016274, loss_ce: 0.007246
2022-01-14 13:20:56,660 iteration 6345 : loss : 0.025365, loss_ce: 0.011412
2022-01-14 13:20:57,548 iteration 6346 : loss : 0.011322, loss_ce: 0.002967
2022-01-14 13:20:58,484 iteration 6347 : loss : 0.014277, loss_ce: 0.005104
2022-01-14 13:20:59,536 iteration 6348 : loss : 0.020834, loss_ce: 0.007385
2022-01-14 13:21:00,411 iteration 6349 : loss : 0.011420, loss_ce: 0.004802
2022-01-14 13:21:01,301 iteration 6350 : loss : 0.011560, loss_ce: 0.003079
2022-01-14 13:21:02,196 iteration 6351 : loss : 0.011446, loss_ce: 0.004283
2022-01-14 13:21:03,151 iteration 6352 : loss : 0.011539, loss_ce: 0.004580
2022-01-14 13:21:04,137 iteration 6353 : loss : 0.015686, loss_ce: 0.006125
2022-01-14 13:21:05,145 iteration 6354 : loss : 0.014624, loss_ce: 0.006106
2022-01-14 13:21:06,043 iteration 6355 : loss : 0.011338, loss_ce: 0.005078
2022-01-14 13:21:06,994 iteration 6356 : loss : 0.015084, loss_ce: 0.007014
2022-01-14 13:21:07,893 iteration 6357 : loss : 0.016380, loss_ce: 0.005232
2022-01-14 13:21:08,906 iteration 6358 : loss : 0.024013, loss_ce: 0.008367
 94%|███████████████████████████  | 374/400 [1:46:34<07:09, 16.53s/it]2022-01-14 13:21:09,877 iteration 6359 : loss : 0.014397, loss_ce: 0.004801
2022-01-14 13:21:10,760 iteration 6360 : loss : 0.015241, loss_ce: 0.004273
2022-01-14 13:21:11,710 iteration 6361 : loss : 0.016175, loss_ce: 0.004348
2022-01-14 13:21:12,674 iteration 6362 : loss : 0.014251, loss_ce: 0.006006
2022-01-14 13:21:13,674 iteration 6363 : loss : 0.020498, loss_ce: 0.008401
2022-01-14 13:21:14,547 iteration 6364 : loss : 0.008926, loss_ce: 0.003289
2022-01-14 13:21:15,416 iteration 6365 : loss : 0.010573, loss_ce: 0.004094
2022-01-14 13:21:16,391 iteration 6366 : loss : 0.019984, loss_ce: 0.007958
2022-01-14 13:21:17,301 iteration 6367 : loss : 0.011623, loss_ce: 0.004832
2022-01-14 13:21:18,197 iteration 6368 : loss : 0.016615, loss_ce: 0.006148
2022-01-14 13:21:19,148 iteration 6369 : loss : 0.012478, loss_ce: 0.005563
2022-01-14 13:21:20,126 iteration 6370 : loss : 0.018918, loss_ce: 0.005463
2022-01-14 13:21:21,085 iteration 6371 : loss : 0.017737, loss_ce: 0.006828
2022-01-14 13:21:22,028 iteration 6372 : loss : 0.014107, loss_ce: 0.006555
2022-01-14 13:21:22,821 iteration 6373 : loss : 0.008355, loss_ce: 0.002074
2022-01-14 13:21:23,701 iteration 6374 : loss : 0.009970, loss_ce: 0.003817
2022-01-14 13:21:23,702 Training Data Eval:
2022-01-14 13:21:27,984   Average segmentation loss on training set: 0.0076
2022-01-14 13:21:27,984 Validation Data Eval:
2022-01-14 13:21:29,432   Average segmentation loss on validation set: 0.0640
2022-01-14 13:21:30,340 iteration 6375 : loss : 0.014560, loss_ce: 0.005126
 94%|███████████████████████████▏ | 375/400 [1:46:56<07:30, 18.00s/it]2022-01-14 13:21:31,538 iteration 6376 : loss : 0.021582, loss_ce: 0.008369
2022-01-14 13:21:32,452 iteration 6377 : loss : 0.012971, loss_ce: 0.004920
2022-01-14 13:21:33,354 iteration 6378 : loss : 0.018103, loss_ce: 0.007230
2022-01-14 13:21:34,324 iteration 6379 : loss : 0.018718, loss_ce: 0.004821
2022-01-14 13:21:35,167 iteration 6380 : loss : 0.010117, loss_ce: 0.004638
2022-01-14 13:21:36,011 iteration 6381 : loss : 0.019513, loss_ce: 0.005609
2022-01-14 13:21:36,959 iteration 6382 : loss : 0.018577, loss_ce: 0.007859
2022-01-14 13:21:37,925 iteration 6383 : loss : 0.014343, loss_ce: 0.006476
2022-01-14 13:21:38,833 iteration 6384 : loss : 0.011238, loss_ce: 0.004384
2022-01-14 13:21:39,854 iteration 6385 : loss : 0.015569, loss_ce: 0.006531
2022-01-14 13:21:40,781 iteration 6386 : loss : 0.012783, loss_ce: 0.004639
2022-01-14 13:21:41,839 iteration 6387 : loss : 0.024133, loss_ce: 0.010730
2022-01-14 13:21:42,724 iteration 6388 : loss : 0.010664, loss_ce: 0.004088
2022-01-14 13:21:43,547 iteration 6389 : loss : 0.011216, loss_ce: 0.003324
2022-01-14 13:21:44,455 iteration 6390 : loss : 0.014715, loss_ce: 0.005146
2022-01-14 13:21:45,504 iteration 6391 : loss : 0.019236, loss_ce: 0.005359
2022-01-14 13:21:46,364 iteration 6392 : loss : 0.012657, loss_ce: 0.005912
 94%|███████████████████████████▎ | 376/400 [1:47:12<06:57, 17.41s/it]2022-01-14 13:21:47,351 iteration 6393 : loss : 0.012512, loss_ce: 0.004368
2022-01-14 13:21:48,284 iteration 6394 : loss : 0.017848, loss_ce: 0.005771
2022-01-14 13:21:49,174 iteration 6395 : loss : 0.010737, loss_ce: 0.004812
2022-01-14 13:21:50,211 iteration 6396 : loss : 0.014127, loss_ce: 0.005755
2022-01-14 13:21:51,097 iteration 6397 : loss : 0.013789, loss_ce: 0.005334
2022-01-14 13:21:51,957 iteration 6398 : loss : 0.012389, loss_ce: 0.003961
2022-01-14 13:21:52,901 iteration 6399 : loss : 0.011725, loss_ce: 0.003297
2022-01-14 13:21:53,832 iteration 6400 : loss : 0.012562, loss_ce: 0.005884
2022-01-14 13:21:54,685 iteration 6401 : loss : 0.011164, loss_ce: 0.004381
2022-01-14 13:21:55,605 iteration 6402 : loss : 0.031416, loss_ce: 0.009864
2022-01-14 13:21:56,649 iteration 6403 : loss : 0.014091, loss_ce: 0.005296
2022-01-14 13:21:57,571 iteration 6404 : loss : 0.016287, loss_ce: 0.005511
2022-01-14 13:21:58,476 iteration 6405 : loss : 0.013335, loss_ce: 0.005055
2022-01-14 13:21:59,582 iteration 6406 : loss : 0.015316, loss_ce: 0.006862
2022-01-14 13:22:00,447 iteration 6407 : loss : 0.009863, loss_ce: 0.002764
2022-01-14 13:22:01,366 iteration 6408 : loss : 0.014180, loss_ce: 0.003534
2022-01-14 13:22:02,262 iteration 6409 : loss : 0.014978, loss_ce: 0.005756
 94%|███████████████████████████▎ | 377/400 [1:47:28<06:29, 16.96s/it]2022-01-14 13:22:03,392 iteration 6410 : loss : 0.027422, loss_ce: 0.009304
2022-01-14 13:22:04,428 iteration 6411 : loss : 0.015523, loss_ce: 0.005895
2022-01-14 13:22:05,371 iteration 6412 : loss : 0.014694, loss_ce: 0.006654
2022-01-14 13:22:06,304 iteration 6413 : loss : 0.013518, loss_ce: 0.005192
2022-01-14 13:22:07,273 iteration 6414 : loss : 0.020884, loss_ce: 0.007929
2022-01-14 13:22:08,171 iteration 6415 : loss : 0.012138, loss_ce: 0.003879
2022-01-14 13:22:09,085 iteration 6416 : loss : 0.016502, loss_ce: 0.004024
2022-01-14 13:22:10,041 iteration 6417 : loss : 0.021138, loss_ce: 0.010308
2022-01-14 13:22:11,008 iteration 6418 : loss : 0.015155, loss_ce: 0.005501
2022-01-14 13:22:11,934 iteration 6419 : loss : 0.015233, loss_ce: 0.005373
2022-01-14 13:22:12,909 iteration 6420 : loss : 0.015561, loss_ce: 0.005815
2022-01-14 13:22:13,850 iteration 6421 : loss : 0.011015, loss_ce: 0.004070
2022-01-14 13:22:14,710 iteration 6422 : loss : 0.013349, loss_ce: 0.005206
2022-01-14 13:22:15,682 iteration 6423 : loss : 0.020788, loss_ce: 0.006520
2022-01-14 13:22:16,653 iteration 6424 : loss : 0.016540, loss_ce: 0.008042
2022-01-14 13:22:17,500 iteration 6425 : loss : 0.010458, loss_ce: 0.003723
2022-01-14 13:22:18,453 iteration 6426 : loss : 0.014298, loss_ce: 0.005914
 94%|███████████████████████████▍ | 378/400 [1:47:44<06:07, 16.73s/it]2022-01-14 13:22:19,462 iteration 6427 : loss : 0.015691, loss_ce: 0.006724
2022-01-14 13:22:20,307 iteration 6428 : loss : 0.010369, loss_ce: 0.004868
2022-01-14 13:22:21,272 iteration 6429 : loss : 0.016865, loss_ce: 0.005499
2022-01-14 13:22:22,131 iteration 6430 : loss : 0.010715, loss_ce: 0.002890
2022-01-14 13:22:23,073 iteration 6431 : loss : 0.015593, loss_ce: 0.005289
2022-01-14 13:22:24,016 iteration 6432 : loss : 0.013202, loss_ce: 0.004902
2022-01-14 13:22:25,020 iteration 6433 : loss : 0.013819, loss_ce: 0.005234
2022-01-14 13:22:25,858 iteration 6434 : loss : 0.008429, loss_ce: 0.003024
2022-01-14 13:22:26,784 iteration 6435 : loss : 0.010763, loss_ce: 0.004830
2022-01-14 13:22:27,692 iteration 6436 : loss : 0.013790, loss_ce: 0.005708
2022-01-14 13:22:28,650 iteration 6437 : loss : 0.019925, loss_ce: 0.005447
2022-01-14 13:22:29,631 iteration 6438 : loss : 0.012418, loss_ce: 0.005472
2022-01-14 13:22:30,606 iteration 6439 : loss : 0.010120, loss_ce: 0.003587
2022-01-14 13:22:31,614 iteration 6440 : loss : 0.024402, loss_ce: 0.009282
2022-01-14 13:22:32,578 iteration 6441 : loss : 0.014592, loss_ce: 0.004367
2022-01-14 13:22:33,484 iteration 6442 : loss : 0.015115, loss_ce: 0.006377
2022-01-14 13:22:34,445 iteration 6443 : loss : 0.021966, loss_ce: 0.008832
 95%|███████████████████████████▍ | 379/400 [1:48:00<05:46, 16.50s/it]2022-01-14 13:22:35,498 iteration 6444 : loss : 0.018725, loss_ce: 0.008927
2022-01-14 13:22:36,479 iteration 6445 : loss : 0.014855, loss_ce: 0.005878
2022-01-14 13:22:37,426 iteration 6446 : loss : 0.013345, loss_ce: 0.003432
2022-01-14 13:22:38,355 iteration 6447 : loss : 0.022749, loss_ce: 0.012359
2022-01-14 13:22:39,289 iteration 6448 : loss : 0.012934, loss_ce: 0.005680
2022-01-14 13:22:40,288 iteration 6449 : loss : 0.014336, loss_ce: 0.004669
2022-01-14 13:22:41,169 iteration 6450 : loss : 0.010166, loss_ce: 0.004222
2022-01-14 13:22:42,026 iteration 6451 : loss : 0.011968, loss_ce: 0.004279
2022-01-14 13:22:42,999 iteration 6452 : loss : 0.012957, loss_ce: 0.005512
2022-01-14 13:22:43,940 iteration 6453 : loss : 0.014574, loss_ce: 0.006236
2022-01-14 13:22:44,834 iteration 6454 : loss : 0.015716, loss_ce: 0.004985
2022-01-14 13:22:45,751 iteration 6455 : loss : 0.010119, loss_ce: 0.002799
2022-01-14 13:22:46,796 iteration 6456 : loss : 0.019194, loss_ce: 0.007644
2022-01-14 13:22:47,737 iteration 6457 : loss : 0.015332, loss_ce: 0.004677
2022-01-14 13:22:48,629 iteration 6458 : loss : 0.011663, loss_ce: 0.003785
2022-01-14 13:22:49,498 iteration 6459 : loss : 0.012065, loss_ce: 0.004129
2022-01-14 13:22:49,499 Training Data Eval:
2022-01-14 13:22:53,793   Average segmentation loss on training set: 0.0073
2022-01-14 13:22:53,793 Validation Data Eval:
2022-01-14 13:22:55,245   Average segmentation loss on validation set: 0.0703
2022-01-14 13:22:56,206 iteration 6460 : loss : 0.017110, loss_ce: 0.004698
 95%|███████████████████████████▌ | 380/400 [1:48:22<06:01, 18.08s/it]2022-01-14 13:22:57,181 iteration 6461 : loss : 0.017923, loss_ce: 0.006022
2022-01-14 13:22:58,124 iteration 6462 : loss : 0.015771, loss_ce: 0.005348
2022-01-14 13:22:59,007 iteration 6463 : loss : 0.008933, loss_ce: 0.002515
2022-01-14 13:22:59,873 iteration 6464 : loss : 0.017003, loss_ce: 0.006255
2022-01-14 13:23:00,783 iteration 6465 : loss : 0.016921, loss_ce: 0.005429
2022-01-14 13:23:01,753 iteration 6466 : loss : 0.014948, loss_ce: 0.006053
2022-01-14 13:23:02,748 iteration 6467 : loss : 0.015377, loss_ce: 0.006745
2022-01-14 13:23:03,754 iteration 6468 : loss : 0.017457, loss_ce: 0.009056
2022-01-14 13:23:04,666 iteration 6469 : loss : 0.014350, loss_ce: 0.006460
2022-01-14 13:23:05,569 iteration 6470 : loss : 0.022284, loss_ce: 0.006716
2022-01-14 13:23:06,458 iteration 6471 : loss : 0.012848, loss_ce: 0.004380
2022-01-14 13:23:07,374 iteration 6472 : loss : 0.015040, loss_ce: 0.004118
2022-01-14 13:23:08,221 iteration 6473 : loss : 0.011860, loss_ce: 0.005743
2022-01-14 13:23:09,213 iteration 6474 : loss : 0.015158, loss_ce: 0.007831
2022-01-14 13:23:10,052 iteration 6475 : loss : 0.010546, loss_ce: 0.003809
2022-01-14 13:23:10,940 iteration 6476 : loss : 0.011430, loss_ce: 0.004472
2022-01-14 13:23:11,789 iteration 6477 : loss : 0.012790, loss_ce: 0.004672
 95%|███████████████████████████▌ | 381/400 [1:48:37<05:29, 17.33s/it]2022-01-14 13:23:12,830 iteration 6478 : loss : 0.013942, loss_ce: 0.005419
2022-01-14 13:23:13,927 iteration 6479 : loss : 0.032488, loss_ce: 0.021769
2022-01-14 13:23:14,891 iteration 6480 : loss : 0.022288, loss_ce: 0.004990
2022-01-14 13:23:15,861 iteration 6481 : loss : 0.012264, loss_ce: 0.005127
2022-01-14 13:23:16,829 iteration 6482 : loss : 0.020698, loss_ce: 0.007408
2022-01-14 13:23:17,716 iteration 6483 : loss : 0.014931, loss_ce: 0.004765
2022-01-14 13:23:18,639 iteration 6484 : loss : 0.012692, loss_ce: 0.003323
2022-01-14 13:23:19,585 iteration 6485 : loss : 0.021954, loss_ce: 0.010461
2022-01-14 13:23:20,616 iteration 6486 : loss : 0.015877, loss_ce: 0.006569
2022-01-14 13:23:21,575 iteration 6487 : loss : 0.019345, loss_ce: 0.006695
2022-01-14 13:23:22,391 iteration 6488 : loss : 0.018688, loss_ce: 0.009371
2022-01-14 13:23:23,379 iteration 6489 : loss : 0.025811, loss_ce: 0.004867
2022-01-14 13:23:24,210 iteration 6490 : loss : 0.010528, loss_ce: 0.003899
2022-01-14 13:23:25,192 iteration 6491 : loss : 0.020752, loss_ce: 0.006099
2022-01-14 13:23:26,096 iteration 6492 : loss : 0.011402, loss_ce: 0.004060
2022-01-14 13:23:27,062 iteration 6493 : loss : 0.012896, loss_ce: 0.003508
2022-01-14 13:23:27,994 iteration 6494 : loss : 0.014920, loss_ce: 0.005499
 96%|███████████████████████████▋ | 382/400 [1:48:53<05:05, 16.99s/it]2022-01-14 13:23:29,037 iteration 6495 : loss : 0.011467, loss_ce: 0.003351
2022-01-14 13:23:29,937 iteration 6496 : loss : 0.017146, loss_ce: 0.006709
2022-01-14 13:23:30,902 iteration 6497 : loss : 0.009953, loss_ce: 0.003390
2022-01-14 13:23:31,856 iteration 6498 : loss : 0.018804, loss_ce: 0.008594
2022-01-14 13:23:32,875 iteration 6499 : loss : 0.016671, loss_ce: 0.005881
2022-01-14 13:23:33,863 iteration 6500 : loss : 0.018877, loss_ce: 0.008135
2022-01-14 13:23:34,845 iteration 6501 : loss : 0.019886, loss_ce: 0.004314
2022-01-14 13:23:35,838 iteration 6502 : loss : 0.016802, loss_ce: 0.006356
2022-01-14 13:23:36,855 iteration 6503 : loss : 0.016203, loss_ce: 0.005586
2022-01-14 13:23:37,735 iteration 6504 : loss : 0.010967, loss_ce: 0.005144
2022-01-14 13:23:38,639 iteration 6505 : loss : 0.011522, loss_ce: 0.003014
2022-01-14 13:23:39,559 iteration 6506 : loss : 0.012399, loss_ce: 0.003825
2022-01-14 13:23:40,477 iteration 6507 : loss : 0.014603, loss_ce: 0.005347
2022-01-14 13:23:41,417 iteration 6508 : loss : 0.013890, loss_ce: 0.004631
2022-01-14 13:23:42,341 iteration 6509 : loss : 0.012160, loss_ce: 0.005105
2022-01-14 13:23:43,236 iteration 6510 : loss : 0.013616, loss_ce: 0.004698
2022-01-14 13:23:44,168 iteration 6511 : loss : 0.013402, loss_ce: 0.005960
 96%|███████████████████████████▊ | 383/400 [1:49:10<04:44, 16.75s/it]2022-01-14 13:23:45,155 iteration 6512 : loss : 0.012430, loss_ce: 0.005323
2022-01-14 13:23:46,033 iteration 6513 : loss : 0.018011, loss_ce: 0.006035
2022-01-14 13:23:46,955 iteration 6514 : loss : 0.010342, loss_ce: 0.002451
2022-01-14 13:23:47,879 iteration 6515 : loss : 0.014998, loss_ce: 0.004543
2022-01-14 13:23:48,807 iteration 6516 : loss : 0.012827, loss_ce: 0.003686
2022-01-14 13:23:49,790 iteration 6517 : loss : 0.015567, loss_ce: 0.007281
2022-01-14 13:23:50,658 iteration 6518 : loss : 0.016168, loss_ce: 0.006437
2022-01-14 13:23:51,668 iteration 6519 : loss : 0.022660, loss_ce: 0.007417
2022-01-14 13:23:52,526 iteration 6520 : loss : 0.010840, loss_ce: 0.004652
2022-01-14 13:23:53,501 iteration 6521 : loss : 0.017000, loss_ce: 0.006699
2022-01-14 13:23:54,426 iteration 6522 : loss : 0.022370, loss_ce: 0.009712
2022-01-14 13:23:55,306 iteration 6523 : loss : 0.016131, loss_ce: 0.005568
2022-01-14 13:23:56,222 iteration 6524 : loss : 0.017485, loss_ce: 0.005751
2022-01-14 13:23:57,132 iteration 6525 : loss : 0.012436, loss_ce: 0.004065
2022-01-14 13:23:58,083 iteration 6526 : loss : 0.011218, loss_ce: 0.004107
2022-01-14 13:23:59,056 iteration 6527 : loss : 0.016784, loss_ce: 0.005720
2022-01-14 13:24:00,014 iteration 6528 : loss : 0.016397, loss_ce: 0.006148
 96%|███████████████████████████▊ | 384/400 [1:49:25<04:23, 16.47s/it]2022-01-14 13:24:00,947 iteration 6529 : loss : 0.011932, loss_ce: 0.004383
2022-01-14 13:24:01,802 iteration 6530 : loss : 0.009692, loss_ce: 0.004279
2022-01-14 13:24:02,748 iteration 6531 : loss : 0.016227, loss_ce: 0.003957
2022-01-14 13:24:03,717 iteration 6532 : loss : 0.010448, loss_ce: 0.003328
2022-01-14 13:24:04,612 iteration 6533 : loss : 0.014104, loss_ce: 0.005964
2022-01-14 13:24:05,587 iteration 6534 : loss : 0.017423, loss_ce: 0.004837
2022-01-14 13:24:06,533 iteration 6535 : loss : 0.015619, loss_ce: 0.005743
2022-01-14 13:24:07,481 iteration 6536 : loss : 0.017844, loss_ce: 0.006922
2022-01-14 13:24:08,553 iteration 6537 : loss : 0.021954, loss_ce: 0.006769
2022-01-14 13:24:09,447 iteration 6538 : loss : 0.011360, loss_ce: 0.003669
2022-01-14 13:24:10,485 iteration 6539 : loss : 0.019438, loss_ce: 0.008139
2022-01-14 13:24:11,374 iteration 6540 : loss : 0.015406, loss_ce: 0.006889
2022-01-14 13:24:12,226 iteration 6541 : loss : 0.011147, loss_ce: 0.004284
2022-01-14 13:24:13,140 iteration 6542 : loss : 0.016537, loss_ce: 0.006270
2022-01-14 13:24:14,133 iteration 6543 : loss : 0.011948, loss_ce: 0.004315
2022-01-14 13:24:15,072 iteration 6544 : loss : 0.014627, loss_ce: 0.005715
2022-01-14 13:24:15,073 Training Data Eval:
2022-01-14 13:24:19,365   Average segmentation loss on training set: 0.0073
2022-01-14 13:24:19,366 Validation Data Eval:
2022-01-14 13:24:20,819   Average segmentation loss on validation set: 0.0704
2022-01-14 13:24:21,754 iteration 6545 : loss : 0.010450, loss_ce: 0.002797
 96%|███████████████████████████▉ | 385/400 [1:49:47<04:30, 18.06s/it]2022-01-14 13:24:22,816 iteration 6546 : loss : 0.014793, loss_ce: 0.005467
2022-01-14 13:24:23,684 iteration 6547 : loss : 0.013749, loss_ce: 0.003252
2022-01-14 13:24:24,627 iteration 6548 : loss : 0.020822, loss_ce: 0.007299
2022-01-14 13:24:25,663 iteration 6549 : loss : 0.019504, loss_ce: 0.005887
2022-01-14 13:24:26,598 iteration 6550 : loss : 0.013032, loss_ce: 0.006029
2022-01-14 13:24:27,600 iteration 6551 : loss : 0.024134, loss_ce: 0.010971
2022-01-14 13:24:28,658 iteration 6552 : loss : 0.018980, loss_ce: 0.007071
2022-01-14 13:24:29,591 iteration 6553 : loss : 0.018107, loss_ce: 0.006074
2022-01-14 13:24:30,667 iteration 6554 : loss : 0.032365, loss_ce: 0.010412
2022-01-14 13:24:31,560 iteration 6555 : loss : 0.014561, loss_ce: 0.005717
2022-01-14 13:24:32,517 iteration 6556 : loss : 0.019705, loss_ce: 0.008103
2022-01-14 13:24:33,380 iteration 6557 : loss : 0.009020, loss_ce: 0.003108
2022-01-14 13:24:34,369 iteration 6558 : loss : 0.018050, loss_ce: 0.007761
2022-01-14 13:24:35,230 iteration 6559 : loss : 0.009779, loss_ce: 0.003375
2022-01-14 13:24:36,119 iteration 6560 : loss : 0.014632, loss_ce: 0.006512
2022-01-14 13:24:37,073 iteration 6561 : loss : 0.021994, loss_ce: 0.008646
2022-01-14 13:24:38,009 iteration 6562 : loss : 0.020659, loss_ce: 0.007898
 96%|███████████████████████████▉ | 386/400 [1:50:03<04:05, 17.51s/it]2022-01-14 13:24:39,028 iteration 6563 : loss : 0.014881, loss_ce: 0.006253
2022-01-14 13:24:40,043 iteration 6564 : loss : 0.013072, loss_ce: 0.004071
2022-01-14 13:24:40,917 iteration 6565 : loss : 0.013912, loss_ce: 0.003761
2022-01-14 13:24:41,939 iteration 6566 : loss : 0.018828, loss_ce: 0.006559
2022-01-14 13:24:42,884 iteration 6567 : loss : 0.019212, loss_ce: 0.007831
2022-01-14 13:24:43,798 iteration 6568 : loss : 0.010111, loss_ce: 0.003788
2022-01-14 13:24:44,708 iteration 6569 : loss : 0.016618, loss_ce: 0.004845
2022-01-14 13:24:45,743 iteration 6570 : loss : 0.016488, loss_ce: 0.007332
2022-01-14 13:24:46,594 iteration 6571 : loss : 0.010144, loss_ce: 0.004285
2022-01-14 13:24:47,491 iteration 6572 : loss : 0.018862, loss_ce: 0.006589
2022-01-14 13:24:48,371 iteration 6573 : loss : 0.011570, loss_ce: 0.003784
2022-01-14 13:24:49,315 iteration 6574 : loss : 0.015023, loss_ce: 0.005766
2022-01-14 13:24:50,131 iteration 6575 : loss : 0.009270, loss_ce: 0.003713
2022-01-14 13:24:51,063 iteration 6576 : loss : 0.015631, loss_ce: 0.007246
2022-01-14 13:24:52,012 iteration 6577 : loss : 0.015618, loss_ce: 0.005161
2022-01-14 13:24:52,967 iteration 6578 : loss : 0.014789, loss_ce: 0.006699
2022-01-14 13:24:53,893 iteration 6579 : loss : 0.013397, loss_ce: 0.003426
 97%|████████████████████████████ | 387/400 [1:50:19<03:41, 17.03s/it]2022-01-14 13:24:54,941 iteration 6580 : loss : 0.016200, loss_ce: 0.006064
2022-01-14 13:24:55,893 iteration 6581 : loss : 0.015980, loss_ce: 0.004528
2022-01-14 13:24:56,894 iteration 6582 : loss : 0.018625, loss_ce: 0.008873
2022-01-14 13:24:57,813 iteration 6583 : loss : 0.010135, loss_ce: 0.003672
2022-01-14 13:24:58,769 iteration 6584 : loss : 0.018612, loss_ce: 0.006043
2022-01-14 13:24:59,639 iteration 6585 : loss : 0.010839, loss_ce: 0.003621
2022-01-14 13:25:00,590 iteration 6586 : loss : 0.012678, loss_ce: 0.005454
2022-01-14 13:25:01,441 iteration 6587 : loss : 0.011310, loss_ce: 0.004709
2022-01-14 13:25:02,430 iteration 6588 : loss : 0.015883, loss_ce: 0.005818
2022-01-14 13:25:03,337 iteration 6589 : loss : 0.011856, loss_ce: 0.003671
2022-01-14 13:25:04,250 iteration 6590 : loss : 0.012988, loss_ce: 0.005518
2022-01-14 13:25:05,148 iteration 6591 : loss : 0.016069, loss_ce: 0.008186
2022-01-14 13:25:06,089 iteration 6592 : loss : 0.013515, loss_ce: 0.004334
2022-01-14 13:25:07,097 iteration 6593 : loss : 0.016412, loss_ce: 0.007318
2022-01-14 13:25:08,020 iteration 6594 : loss : 0.011376, loss_ce: 0.004086
2022-01-14 13:25:08,879 iteration 6595 : loss : 0.013824, loss_ce: 0.004158
2022-01-14 13:25:09,747 iteration 6596 : loss : 0.008333, loss_ce: 0.003268
 97%|████████████████████████████▏| 388/400 [1:50:35<03:20, 16.68s/it]2022-01-14 13:25:10,818 iteration 6597 : loss : 0.015004, loss_ce: 0.008089
2022-01-14 13:25:11,818 iteration 6598 : loss : 0.014462, loss_ce: 0.003828
2022-01-14 13:25:12,694 iteration 6599 : loss : 0.012302, loss_ce: 0.004706
2022-01-14 13:25:13,664 iteration 6600 : loss : 0.019650, loss_ce: 0.007553
2022-01-14 13:25:14,537 iteration 6601 : loss : 0.013298, loss_ce: 0.005277
2022-01-14 13:25:15,362 iteration 6602 : loss : 0.008017, loss_ce: 0.002743
2022-01-14 13:25:16,294 iteration 6603 : loss : 0.017789, loss_ce: 0.005758
2022-01-14 13:25:17,309 iteration 6604 : loss : 0.014270, loss_ce: 0.004830
2022-01-14 13:25:18,284 iteration 6605 : loss : 0.014437, loss_ce: 0.005792
2022-01-14 13:25:19,243 iteration 6606 : loss : 0.013055, loss_ce: 0.006647
2022-01-14 13:25:20,143 iteration 6607 : loss : 0.018019, loss_ce: 0.007953
2022-01-14 13:25:21,111 iteration 6608 : loss : 0.013740, loss_ce: 0.004727
2022-01-14 13:25:22,132 iteration 6609 : loss : 0.013076, loss_ce: 0.005520
2022-01-14 13:25:23,049 iteration 6610 : loss : 0.014302, loss_ce: 0.003450
2022-01-14 13:25:23,874 iteration 6611 : loss : 0.012881, loss_ce: 0.006482
2022-01-14 13:25:24,811 iteration 6612 : loss : 0.013506, loss_ce: 0.005038
2022-01-14 13:25:25,800 iteration 6613 : loss : 0.021784, loss_ce: 0.006244
 97%|████████████████████████████▏| 389/400 [1:50:51<03:01, 16.49s/it]2022-01-14 13:25:26,678 iteration 6614 : loss : 0.009020, loss_ce: 0.003485
2022-01-14 13:25:27,615 iteration 6615 : loss : 0.018291, loss_ce: 0.007129
2022-01-14 13:25:28,581 iteration 6616 : loss : 0.014292, loss_ce: 0.005589
2022-01-14 13:25:29,473 iteration 6617 : loss : 0.010632, loss_ce: 0.002088
2022-01-14 13:25:30,410 iteration 6618 : loss : 0.015338, loss_ce: 0.004738
2022-01-14 13:25:31,381 iteration 6619 : loss : 0.011613, loss_ce: 0.004437
2022-01-14 13:25:32,301 iteration 6620 : loss : 0.021552, loss_ce: 0.006491
2022-01-14 13:25:33,155 iteration 6621 : loss : 0.011123, loss_ce: 0.004718
2022-01-14 13:25:33,969 iteration 6622 : loss : 0.010446, loss_ce: 0.003288
2022-01-14 13:25:34,906 iteration 6623 : loss : 0.015056, loss_ce: 0.008098
2022-01-14 13:25:35,703 iteration 6624 : loss : 0.011333, loss_ce: 0.004062
2022-01-14 13:25:36,512 iteration 6625 : loss : 0.008843, loss_ce: 0.003620
2022-01-14 13:25:37,428 iteration 6626 : loss : 0.017989, loss_ce: 0.006493
2022-01-14 13:25:38,295 iteration 6627 : loss : 0.009221, loss_ce: 0.003110
2022-01-14 13:25:39,231 iteration 6628 : loss : 0.016787, loss_ce: 0.005955
2022-01-14 13:25:40,112 iteration 6629 : loss : 0.013721, loss_ce: 0.005686
2022-01-14 13:25:40,112 Training Data Eval:
2022-01-14 13:25:44,413   Average segmentation loss on training set: 0.0072
2022-01-14 13:25:44,414 Validation Data Eval:
2022-01-14 13:25:45,867   Average segmentation loss on validation set: 0.0693
2022-01-14 13:25:46,794 iteration 6630 : loss : 0.025929, loss_ce: 0.010733
 98%|████████████████████████████▎| 390/400 [1:51:12<02:58, 17.84s/it]2022-01-14 13:25:47,675 iteration 6631 : loss : 0.010143, loss_ce: 0.003899
2022-01-14 13:25:48,629 iteration 6632 : loss : 0.018829, loss_ce: 0.004418
2022-01-14 13:25:49,540 iteration 6633 : loss : 0.013787, loss_ce: 0.005127
2022-01-14 13:25:50,413 iteration 6634 : loss : 0.014374, loss_ce: 0.005876
2022-01-14 13:25:51,373 iteration 6635 : loss : 0.009633, loss_ce: 0.003612
2022-01-14 13:25:52,261 iteration 6636 : loss : 0.012359, loss_ce: 0.006432
2022-01-14 13:25:53,206 iteration 6637 : loss : 0.013977, loss_ce: 0.004018
2022-01-14 13:25:54,157 iteration 6638 : loss : 0.010041, loss_ce: 0.002922
2022-01-14 13:25:55,079 iteration 6639 : loss : 0.015582, loss_ce: 0.004761
2022-01-14 13:25:56,037 iteration 6640 : loss : 0.018602, loss_ce: 0.005400
2022-01-14 13:25:56,944 iteration 6641 : loss : 0.015139, loss_ce: 0.006765
2022-01-14 13:25:57,864 iteration 6642 : loss : 0.012819, loss_ce: 0.003909
2022-01-14 13:25:58,865 iteration 6643 : loss : 0.017246, loss_ce: 0.007724
2022-01-14 13:25:59,886 iteration 6644 : loss : 0.016571, loss_ce: 0.006850
2022-01-14 13:26:00,820 iteration 6645 : loss : 0.015674, loss_ce: 0.006550
2022-01-14 13:26:01,761 iteration 6646 : loss : 0.013881, loss_ce: 0.006347
2022-01-14 13:26:02,701 iteration 6647 : loss : 0.018422, loss_ce: 0.003714
 98%|████████████████████████████▎| 391/400 [1:51:28<02:35, 17.26s/it]2022-01-14 13:26:03,724 iteration 6648 : loss : 0.011460, loss_ce: 0.004214
2022-01-14 13:26:04,699 iteration 6649 : loss : 0.021140, loss_ce: 0.005099
2022-01-14 13:26:05,562 iteration 6650 : loss : 0.011784, loss_ce: 0.004427
2022-01-14 13:26:06,468 iteration 6651 : loss : 0.012999, loss_ce: 0.005482
2022-01-14 13:26:07,409 iteration 6652 : loss : 0.011538, loss_ce: 0.004361
2022-01-14 13:26:08,412 iteration 6653 : loss : 0.013551, loss_ce: 0.004322
2022-01-14 13:26:09,492 iteration 6654 : loss : 0.016744, loss_ce: 0.005637
2022-01-14 13:26:10,394 iteration 6655 : loss : 0.010951, loss_ce: 0.004393
2022-01-14 13:26:11,431 iteration 6656 : loss : 0.015314, loss_ce: 0.005037
2022-01-14 13:26:12,377 iteration 6657 : loss : 0.015331, loss_ce: 0.005044
2022-01-14 13:26:13,374 iteration 6658 : loss : 0.018407, loss_ce: 0.007120
2022-01-14 13:26:14,299 iteration 6659 : loss : 0.019009, loss_ce: 0.005331
2022-01-14 13:26:15,223 iteration 6660 : loss : 0.010427, loss_ce: 0.004248
2022-01-14 13:26:16,092 iteration 6661 : loss : 0.010704, loss_ce: 0.003776
2022-01-14 13:26:17,063 iteration 6662 : loss : 0.014801, loss_ce: 0.005237
2022-01-14 13:26:17,955 iteration 6663 : loss : 0.012807, loss_ce: 0.004979
2022-01-14 13:26:18,935 iteration 6664 : loss : 0.012790, loss_ce: 0.005463
 98%|████████████████████████████▍| 392/400 [1:51:44<02:15, 16.95s/it]2022-01-14 13:26:19,920 iteration 6665 : loss : 0.020945, loss_ce: 0.007152
2022-01-14 13:26:20,897 iteration 6666 : loss : 0.012175, loss_ce: 0.004437
2022-01-14 13:26:21,810 iteration 6667 : loss : 0.013601, loss_ce: 0.005293
2022-01-14 13:26:22,894 iteration 6668 : loss : 0.024902, loss_ce: 0.012203
2022-01-14 13:26:23,759 iteration 6669 : loss : 0.013149, loss_ce: 0.004833
2022-01-14 13:26:24,643 iteration 6670 : loss : 0.010088, loss_ce: 0.004018
2022-01-14 13:26:25,531 iteration 6671 : loss : 0.014342, loss_ce: 0.005539
2022-01-14 13:26:26,375 iteration 6672 : loss : 0.011209, loss_ce: 0.002998
2022-01-14 13:26:27,318 iteration 6673 : loss : 0.017230, loss_ce: 0.006244
2022-01-14 13:26:28,245 iteration 6674 : loss : 0.014440, loss_ce: 0.005977
2022-01-14 13:26:29,231 iteration 6675 : loss : 0.012853, loss_ce: 0.003806
2022-01-14 13:26:30,107 iteration 6676 : loss : 0.009744, loss_ce: 0.002910
2022-01-14 13:26:31,012 iteration 6677 : loss : 0.013927, loss_ce: 0.003653
2022-01-14 13:26:31,818 iteration 6678 : loss : 0.008986, loss_ce: 0.003742
2022-01-14 13:26:32,862 iteration 6679 : loss : 0.012878, loss_ce: 0.005791
2022-01-14 13:26:33,796 iteration 6680 : loss : 0.019136, loss_ce: 0.007185
2022-01-14 13:26:34,754 iteration 6681 : loss : 0.013700, loss_ce: 0.006061
 98%|████████████████████████████▍| 393/400 [1:52:00<01:56, 16.61s/it]2022-01-14 13:26:35,767 iteration 6682 : loss : 0.011582, loss_ce: 0.005592
2022-01-14 13:26:36,797 iteration 6683 : loss : 0.010490, loss_ce: 0.003514
2022-01-14 13:26:37,677 iteration 6684 : loss : 0.017379, loss_ce: 0.005139
2022-01-14 13:26:38,648 iteration 6685 : loss : 0.024243, loss_ce: 0.011815
2022-01-14 13:26:39,505 iteration 6686 : loss : 0.014641, loss_ce: 0.007181
2022-01-14 13:26:40,410 iteration 6687 : loss : 0.024243, loss_ce: 0.004918
2022-01-14 13:26:41,371 iteration 6688 : loss : 0.012439, loss_ce: 0.004874
2022-01-14 13:26:42,262 iteration 6689 : loss : 0.010263, loss_ce: 0.003282
2022-01-14 13:26:43,146 iteration 6690 : loss : 0.013195, loss_ce: 0.005209
2022-01-14 13:26:44,119 iteration 6691 : loss : 0.018550, loss_ce: 0.008024
2022-01-14 13:26:45,058 iteration 6692 : loss : 0.020536, loss_ce: 0.005968
2022-01-14 13:26:46,040 iteration 6693 : loss : 0.011505, loss_ce: 0.003505
2022-01-14 13:26:46,980 iteration 6694 : loss : 0.011271, loss_ce: 0.004304
2022-01-14 13:26:47,949 iteration 6695 : loss : 0.011844, loss_ce: 0.004827
2022-01-14 13:26:48,813 iteration 6696 : loss : 0.010867, loss_ce: 0.004673
2022-01-14 13:26:49,780 iteration 6697 : loss : 0.015697, loss_ce: 0.005605
2022-01-14 13:26:50,706 iteration 6698 : loss : 0.011239, loss_ce: 0.003517
 98%|████████████████████████████▌| 394/400 [1:52:16<01:38, 16.42s/it]2022-01-14 13:26:51,652 iteration 6699 : loss : 0.013247, loss_ce: 0.006984
2022-01-14 13:26:52,642 iteration 6700 : loss : 0.018282, loss_ce: 0.009015
2022-01-14 13:26:53,557 iteration 6701 : loss : 0.016776, loss_ce: 0.007335
2022-01-14 13:26:54,438 iteration 6702 : loss : 0.018856, loss_ce: 0.006357
2022-01-14 13:26:55,339 iteration 6703 : loss : 0.014185, loss_ce: 0.005365
2022-01-14 13:26:56,305 iteration 6704 : loss : 0.015287, loss_ce: 0.005349
2022-01-14 13:26:57,183 iteration 6705 : loss : 0.015602, loss_ce: 0.005144
2022-01-14 13:26:58,052 iteration 6706 : loss : 0.009665, loss_ce: 0.004561
2022-01-14 13:26:58,921 iteration 6707 : loss : 0.013627, loss_ce: 0.003818
2022-01-14 13:26:59,752 iteration 6708 : loss : 0.011975, loss_ce: 0.004186
2022-01-14 13:27:00,625 iteration 6709 : loss : 0.015447, loss_ce: 0.006152
2022-01-14 13:27:01,499 iteration 6710 : loss : 0.016781, loss_ce: 0.007217
2022-01-14 13:27:02,370 iteration 6711 : loss : 0.013901, loss_ce: 0.002466
2022-01-14 13:27:03,300 iteration 6712 : loss : 0.014345, loss_ce: 0.005888
2022-01-14 13:27:04,281 iteration 6713 : loss : 0.021084, loss_ce: 0.008552
2022-01-14 13:27:05,229 iteration 6714 : loss : 0.013436, loss_ce: 0.006126
2022-01-14 13:27:05,229 Training Data Eval:
2022-01-14 13:27:09,509   Average segmentation loss on training set: 0.0070
2022-01-14 13:27:09,510 Validation Data Eval:
2022-01-14 13:27:10,958   Average segmentation loss on validation set: 0.0684
2022-01-14 13:27:11,922 iteration 6715 : loss : 0.010507, loss_ce: 0.003994
 99%|████████████████████████████▋| 395/400 [1:52:37<01:29, 17.86s/it]2022-01-14 13:27:12,906 iteration 6716 : loss : 0.009424, loss_ce: 0.003700
2022-01-14 13:27:13,819 iteration 6717 : loss : 0.015512, loss_ce: 0.005807
2022-01-14 13:27:14,670 iteration 6718 : loss : 0.010337, loss_ce: 0.003394
2022-01-14 13:27:15,574 iteration 6719 : loss : 0.011759, loss_ce: 0.003667
2022-01-14 13:27:16,475 iteration 6720 : loss : 0.013359, loss_ce: 0.005024
2022-01-14 13:27:17,419 iteration 6721 : loss : 0.020322, loss_ce: 0.007356
2022-01-14 13:27:18,406 iteration 6722 : loss : 0.015534, loss_ce: 0.005044
2022-01-14 13:27:19,326 iteration 6723 : loss : 0.013827, loss_ce: 0.004998
2022-01-14 13:27:20,226 iteration 6724 : loss : 0.011858, loss_ce: 0.005033
2022-01-14 13:27:21,200 iteration 6725 : loss : 0.011462, loss_ce: 0.004435
2022-01-14 13:27:22,149 iteration 6726 : loss : 0.016732, loss_ce: 0.004925
2022-01-14 13:27:23,121 iteration 6727 : loss : 0.020151, loss_ce: 0.009209
2022-01-14 13:27:24,093 iteration 6728 : loss : 0.016085, loss_ce: 0.008040
2022-01-14 13:27:24,968 iteration 6729 : loss : 0.012306, loss_ce: 0.003851
2022-01-14 13:27:25,869 iteration 6730 : loss : 0.016460, loss_ce: 0.005362
2022-01-14 13:27:26,767 iteration 6731 : loss : 0.011493, loss_ce: 0.004478
2022-01-14 13:27:27,704 iteration 6732 : loss : 0.012607, loss_ce: 0.006113
 99%|████████████████████████████▋| 396/400 [1:52:53<01:08, 17.23s/it]2022-01-14 13:27:28,780 iteration 6733 : loss : 0.013822, loss_ce: 0.006006
2022-01-14 13:27:29,670 iteration 6734 : loss : 0.007193, loss_ce: 0.002167
2022-01-14 13:27:30,619 iteration 6735 : loss : 0.013526, loss_ce: 0.006834
2022-01-14 13:27:31,553 iteration 6736 : loss : 0.010709, loss_ce: 0.003201
2022-01-14 13:27:32,449 iteration 6737 : loss : 0.011353, loss_ce: 0.004974
2022-01-14 13:27:33,371 iteration 6738 : loss : 0.009412, loss_ce: 0.003021
2022-01-14 13:27:34,344 iteration 6739 : loss : 0.015951, loss_ce: 0.006314
2022-01-14 13:27:35,371 iteration 6740 : loss : 0.015480, loss_ce: 0.005271
2022-01-14 13:27:36,244 iteration 6741 : loss : 0.008848, loss_ce: 0.003614
2022-01-14 13:27:37,228 iteration 6742 : loss : 0.015375, loss_ce: 0.006593
2022-01-14 13:27:38,201 iteration 6743 : loss : 0.015942, loss_ce: 0.005033
2022-01-14 13:27:39,231 iteration 6744 : loss : 0.013516, loss_ce: 0.004976
2022-01-14 13:27:40,131 iteration 6745 : loss : 0.014343, loss_ce: 0.004202
2022-01-14 13:27:41,039 iteration 6746 : loss : 0.016568, loss_ce: 0.007122
2022-01-14 13:27:41,967 iteration 6747 : loss : 0.014902, loss_ce: 0.005177
2022-01-14 13:27:42,917 iteration 6748 : loss : 0.015533, loss_ce: 0.005923
2022-01-14 13:27:43,891 iteration 6749 : loss : 0.022161, loss_ce: 0.007027
 99%|████████████████████████████▊| 397/400 [1:53:09<00:50, 16.92s/it]2022-01-14 13:27:44,861 iteration 6750 : loss : 0.013449, loss_ce: 0.004911
2022-01-14 13:27:45,854 iteration 6751 : loss : 0.014329, loss_ce: 0.006295
2022-01-14 13:27:46,844 iteration 6752 : loss : 0.017086, loss_ce: 0.007719
2022-01-14 13:27:47,794 iteration 6753 : loss : 0.015576, loss_ce: 0.005302
2022-01-14 13:27:48,785 iteration 6754 : loss : 0.021497, loss_ce: 0.004987
2022-01-14 13:27:49,718 iteration 6755 : loss : 0.007573, loss_ce: 0.002296
2022-01-14 13:27:50,664 iteration 6756 : loss : 0.014068, loss_ce: 0.005399
2022-01-14 13:27:51,617 iteration 6757 : loss : 0.018331, loss_ce: 0.007008
2022-01-14 13:27:52,504 iteration 6758 : loss : 0.008391, loss_ce: 0.003393
2022-01-14 13:27:53,480 iteration 6759 : loss : 0.014317, loss_ce: 0.005542
2022-01-14 13:27:54,403 iteration 6760 : loss : 0.013724, loss_ce: 0.005615
2022-01-14 13:27:55,385 iteration 6761 : loss : 0.012287, loss_ce: 0.004809
2022-01-14 13:27:56,209 iteration 6762 : loss : 0.008545, loss_ce: 0.003113
2022-01-14 13:27:57,150 iteration 6763 : loss : 0.022746, loss_ce: 0.005673
2022-01-14 13:27:58,058 iteration 6764 : loss : 0.013460, loss_ce: 0.004801
2022-01-14 13:27:58,947 iteration 6765 : loss : 0.011197, loss_ce: 0.003259
2022-01-14 13:27:59,859 iteration 6766 : loss : 0.013703, loss_ce: 0.004711
100%|████████████████████████████▊| 398/400 [1:53:25<00:33, 16.64s/it]2022-01-14 13:28:00,982 iteration 6767 : loss : 0.010760, loss_ce: 0.003478
2022-01-14 13:28:01,852 iteration 6768 : loss : 0.011073, loss_ce: 0.005025
2022-01-14 13:28:02,781 iteration 6769 : loss : 0.012786, loss_ce: 0.004560
2022-01-14 13:28:03,648 iteration 6770 : loss : 0.008773, loss_ce: 0.003388
2022-01-14 13:28:04,555 iteration 6771 : loss : 0.013010, loss_ce: 0.003784
2022-01-14 13:28:05,563 iteration 6772 : loss : 0.019197, loss_ce: 0.005684
2022-01-14 13:28:06,515 iteration 6773 : loss : 0.012033, loss_ce: 0.004773
2022-01-14 13:28:07,443 iteration 6774 : loss : 0.013612, loss_ce: 0.006521
2022-01-14 13:28:08,362 iteration 6775 : loss : 0.014668, loss_ce: 0.005729
2022-01-14 13:28:09,357 iteration 6776 : loss : 0.024980, loss_ce: 0.012130
2022-01-14 13:28:10,294 iteration 6777 : loss : 0.011035, loss_ce: 0.004144
2022-01-14 13:28:11,185 iteration 6778 : loss : 0.013737, loss_ce: 0.004029
2022-01-14 13:28:12,095 iteration 6779 : loss : 0.011178, loss_ce: 0.003506
2022-01-14 13:28:12,938 iteration 6780 : loss : 0.009548, loss_ce: 0.003216
2022-01-14 13:28:13,811 iteration 6781 : loss : 0.015023, loss_ce: 0.007684
2022-01-14 13:28:14,746 iteration 6782 : loss : 0.009768, loss_ce: 0.004319
2022-01-14 13:28:15,679 iteration 6783 : loss : 0.011328, loss_ce: 0.004379
100%|████████████████████████████▉| 399/400 [1:53:41<00:16, 16.39s/it]2022-01-14 13:28:16,779 iteration 6784 : loss : 0.021872, loss_ce: 0.007412
2022-01-14 13:28:17,644 iteration 6785 : loss : 0.017379, loss_ce: 0.007012
2022-01-14 13:28:18,473 iteration 6786 : loss : 0.009889, loss_ce: 0.004016
2022-01-14 13:28:19,432 iteration 6787 : loss : 0.016024, loss_ce: 0.005823
2022-01-14 13:28:20,282 iteration 6788 : loss : 0.035742, loss_ce: 0.008597
2022-01-14 13:28:21,233 iteration 6789 : loss : 0.009406, loss_ce: 0.003915
2022-01-14 13:28:22,194 iteration 6790 : loss : 0.019817, loss_ce: 0.006243
2022-01-14 13:28:23,182 iteration 6791 : loss : 0.019909, loss_ce: 0.006376
2022-01-14 13:28:24,159 iteration 6792 : loss : 0.011881, loss_ce: 0.004552
2022-01-14 13:28:25,101 iteration 6793 : loss : 0.015587, loss_ce: 0.005424
2022-01-14 13:28:26,057 iteration 6794 : loss : 0.011578, loss_ce: 0.004085
2022-01-14 13:28:26,970 iteration 6795 : loss : 0.012860, loss_ce: 0.004986
2022-01-14 13:28:27,906 iteration 6796 : loss : 0.014157, loss_ce: 0.005753
2022-01-14 13:28:28,790 iteration 6797 : loss : 0.011839, loss_ce: 0.003851
2022-01-14 13:28:29,633 iteration 6798 : loss : 0.011173, loss_ce: 0.004063
2022-01-14 13:28:30,556 iteration 6799 : loss : 0.016662, loss_ce: 0.006870
2022-01-14 13:28:30,556 Training Data Eval:
2022-01-14 13:28:34,857   Average segmentation loss on training set: 0.0071
2022-01-14 13:28:34,858 Validation Data Eval:
2022-01-14 13:28:36,311   Average segmentation loss on validation set: 0.0643
2022-01-14 13:28:37,223 iteration 6800 : loss : 0.012790, loss_ce: 0.005431
100%|█████████████████████████████| 400/400 [1:54:03<00:00, 17.93s/it]100%|█████████████████████████████| 400/400 [1:54:03<00:00, 17.11s/it]
