2022-01-13 23:19:46,546 Logging directory: /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/TransUNet/log_dir/trRUNMC_cv1_r3/i2i2l/
2022-01-13 23:19:46,547 Tensorboard directory: /scratch_net/biwidl217_second/arismu/Tensorboard/trRUNMC_cv1_r3/i2i2l/
2022-01-13 23:19:46,547 ============================================================
2022-01-13 23:19:46,547 EXPERIMENT NAME: trRUNMC_cv1_r3/i2i2l/
2022-01-13 23:19:46,547 ============================================================
2022-01-13 23:19:46,547 Loading data...
2022-01-13 23:19:46,547 Reading NCI - RUNMC images...
2022-01-13 23:19:46,547 Data root directory: /itet-stor/arismu/bmicdatasets-originals/Originals/Challenge_Datasets/NCI_Prostate/
2022-01-13 23:19:46,551 Already preprocessed this configuration. Loading now!
2022-01-13 23:19:46,578 Training Images: (256, 256, 286)
2022-01-13 23:19:46,578 Training Labels: (256, 256, 286)
2022-01-13 23:19:46,578 Validation Images: (256, 256, 98)
2022-01-13 23:19:46,578 Validation Labels: (256, 256, 98)
2022-01-13 23:19:46,578 ============================================================
2022-01-13 23:19:46,626 17 iterations per epoch. 6800 max iterations 
  0%|                                         | 0/400 [00:00<?, ?it/s]2022-01-13 23:19:50,340 iteration 1 : loss : 0.926675, loss_ce: 1.121468
2022-01-13 23:19:51,716 iteration 2 : loss : 0.861641, loss_ce: 1.025659
2022-01-13 23:19:53,167 iteration 3 : loss : 0.802068, loss_ce: 0.936024
2022-01-13 23:19:54,592 iteration 4 : loss : 0.762462, loss_ce: 0.843982
2022-01-13 23:19:55,917 iteration 5 : loss : 0.723475, loss_ce: 0.764995
2022-01-13 23:19:57,292 iteration 6 : loss : 0.672132, loss_ce: 0.700466
2022-01-13 23:19:58,731 iteration 7 : loss : 0.628000, loss_ce: 0.636535
2022-01-13 23:20:00,209 iteration 8 : loss : 0.592046, loss_ce: 0.581491
2022-01-13 23:20:01,548 iteration 9 : loss : 0.587448, loss_ce: 0.540600
2022-01-13 23:20:02,908 iteration 10 : loss : 0.547150, loss_ce: 0.498006
2022-01-13 23:20:04,240 iteration 11 : loss : 0.527446, loss_ce: 0.453117
2022-01-13 23:20:05,623 iteration 12 : loss : 0.510852, loss_ce: 0.430850
2022-01-13 23:20:07,064 iteration 13 : loss : 0.479188, loss_ce: 0.409977
2022-01-13 23:20:08,409 iteration 14 : loss : 0.433583, loss_ce: 0.353707
2022-01-13 23:20:09,842 iteration 15 : loss : 0.425327, loss_ce: 0.323986
2022-01-13 23:20:11,221 iteration 16 : loss : 0.432302, loss_ce: 0.311336
2022-01-13 23:20:12,602 iteration 17 : loss : 0.386452, loss_ce: 0.286904
  0%|                               | 1/400 [00:26<2:53:19, 26.06s/it]2022-01-13 23:20:14,052 iteration 18 : loss : 0.387398, loss_ce: 0.259275
2022-01-13 23:20:15,455 iteration 19 : loss : 0.364250, loss_ce: 0.238552
2022-01-13 23:20:16,861 iteration 20 : loss : 0.340637, loss_ce: 0.220712
2022-01-13 23:20:18,322 iteration 21 : loss : 0.339180, loss_ce: 0.213237
2022-01-13 23:20:19,694 iteration 22 : loss : 0.342285, loss_ce: 0.204753
2022-01-13 23:20:21,116 iteration 23 : loss : 0.294520, loss_ce: 0.169861
2022-01-13 23:20:22,451 iteration 24 : loss : 0.317900, loss_ce: 0.193726
2022-01-13 23:20:23,746 iteration 25 : loss : 0.313116, loss_ce: 0.173576
2022-01-13 23:20:25,090 iteration 26 : loss : 0.344006, loss_ce: 0.181995
2022-01-13 23:20:26,503 iteration 27 : loss : 0.269523, loss_ce: 0.147951
2022-01-13 23:20:27,872 iteration 28 : loss : 0.280949, loss_ce: 0.141412
2022-01-13 23:20:29,401 iteration 29 : loss : 0.289800, loss_ce: 0.152321
2022-01-13 23:20:30,834 iteration 30 : loss : 0.281490, loss_ce: 0.137799
2022-01-13 23:20:32,179 iteration 31 : loss : 0.274632, loss_ce: 0.141322
2022-01-13 23:20:33,556 iteration 32 : loss : 0.280150, loss_ce: 0.140405
2022-01-13 23:20:35,021 iteration 33 : loss : 0.284021, loss_ce: 0.151929
2022-01-13 23:20:36,384 iteration 34 : loss : 0.277824, loss_ce: 0.126019
  0%|▏                              | 2/400 [00:49<2:43:51, 24.70s/it]2022-01-13 23:20:37,895 iteration 35 : loss : 0.259418, loss_ce: 0.135793
2022-01-13 23:20:39,294 iteration 36 : loss : 0.262909, loss_ce: 0.127584
2022-01-13 23:20:40,726 iteration 37 : loss : 0.263757, loss_ce: 0.138731
2022-01-13 23:20:42,244 iteration 38 : loss : 0.229047, loss_ce: 0.102691
2022-01-13 23:20:43,647 iteration 39 : loss : 0.330530, loss_ce: 0.146236
2022-01-13 23:20:45,094 iteration 40 : loss : 0.264957, loss_ce: 0.144306
2022-01-13 23:20:46,449 iteration 41 : loss : 0.261650, loss_ce: 0.115226
2022-01-13 23:20:47,966 iteration 42 : loss : 0.243488, loss_ce: 0.118550
2022-01-13 23:20:49,313 iteration 43 : loss : 0.270038, loss_ce: 0.110012
2022-01-13 23:20:50,743 iteration 44 : loss : 0.223664, loss_ce: 0.099373
2022-01-13 23:20:52,179 iteration 45 : loss : 0.342974, loss_ce: 0.146387
2022-01-13 23:20:53,492 iteration 46 : loss : 0.236315, loss_ce: 0.098001
2022-01-13 23:20:54,883 iteration 47 : loss : 0.314506, loss_ce: 0.114304
2022-01-13 23:20:56,302 iteration 48 : loss : 0.223238, loss_ce: 0.102238
2022-01-13 23:20:57,705 iteration 49 : loss : 0.266236, loss_ce: 0.106283
2022-01-13 23:20:59,170 iteration 50 : loss : 0.228024, loss_ce: 0.090651
2022-01-13 23:21:00,581 iteration 51 : loss : 0.246296, loss_ce: 0.123530
  1%|▏                              | 3/400 [01:14<2:41:54, 24.47s/it]2022-01-13 23:21:01,974 iteration 52 : loss : 0.288658, loss_ce: 0.140155
2022-01-13 23:21:03,330 iteration 53 : loss : 0.239238, loss_ce: 0.115053
2022-01-13 23:21:04,793 iteration 54 : loss : 0.201218, loss_ce: 0.094352
2022-01-13 23:21:06,240 iteration 55 : loss : 0.295109, loss_ce: 0.131907
2022-01-13 23:21:07,713 iteration 56 : loss : 0.256253, loss_ce: 0.115003
2022-01-13 23:21:09,144 iteration 57 : loss : 0.215252, loss_ce: 0.092768
2022-01-13 23:21:10,564 iteration 58 : loss : 0.255705, loss_ce: 0.121902
2022-01-13 23:21:11,963 iteration 59 : loss : 0.241074, loss_ce: 0.094607
2022-01-13 23:21:13,425 iteration 60 : loss : 0.278774, loss_ce: 0.110701
2022-01-13 23:21:14,896 iteration 61 : loss : 0.245246, loss_ce: 0.108807
2022-01-13 23:21:16,317 iteration 62 : loss : 0.262494, loss_ce: 0.101530
2022-01-13 23:21:17,654 iteration 63 : loss : 0.217840, loss_ce: 0.098632
2022-01-13 23:21:19,037 iteration 64 : loss : 0.298939, loss_ce: 0.160023
2022-01-13 23:21:20,434 iteration 65 : loss : 0.261288, loss_ce: 0.107270
2022-01-13 23:21:21,874 iteration 66 : loss : 0.255579, loss_ce: 0.120803
2022-01-13 23:21:23,247 iteration 67 : loss : 0.252403, loss_ce: 0.121880
2022-01-13 23:21:24,679 iteration 68 : loss : 0.301464, loss_ce: 0.128137
  1%|▎                              | 4/400 [01:38<2:40:32, 24.32s/it]2022-01-13 23:21:26,145 iteration 69 : loss : 0.262060, loss_ce: 0.107047
2022-01-13 23:21:27,576 iteration 70 : loss : 0.281936, loss_ce: 0.124323
2022-01-13 23:21:28,951 iteration 71 : loss : 0.251891, loss_ce: 0.105495
2022-01-13 23:21:30,398 iteration 72 : loss : 0.251172, loss_ce: 0.094020
2022-01-13 23:21:31,791 iteration 73 : loss : 0.235972, loss_ce: 0.111267
2022-01-13 23:21:33,285 iteration 74 : loss : 0.238260, loss_ce: 0.102717
2022-01-13 23:21:34,694 iteration 75 : loss : 0.254888, loss_ce: 0.130442
2022-01-13 23:21:36,155 iteration 76 : loss : 0.244637, loss_ce: 0.109588
2022-01-13 23:21:37,656 iteration 77 : loss : 0.238427, loss_ce: 0.095805
2022-01-13 23:21:39,111 iteration 78 : loss : 0.212272, loss_ce: 0.099940
2022-01-13 23:21:40,476 iteration 79 : loss : 0.201470, loss_ce: 0.075766
2022-01-13 23:21:41,929 iteration 80 : loss : 0.297234, loss_ce: 0.114645
2022-01-13 23:21:43,319 iteration 81 : loss : 0.198602, loss_ce: 0.073891
2022-01-13 23:21:44,735 iteration 82 : loss : 0.269969, loss_ce: 0.119906
2022-01-13 23:21:46,190 iteration 83 : loss : 0.236406, loss_ce: 0.093131
2022-01-13 23:21:47,566 iteration 84 : loss : 0.252573, loss_ce: 0.122495
2022-01-13 23:21:47,566 Training Data Eval:
2022-01-13 23:21:54,636   Average segmentation loss on training set: 0.2574
2022-01-13 23:21:54,637 Validation Data Eval:
2022-01-13 23:21:57,346   Average segmentation loss on validation set: 0.2839
2022-01-13 23:22:02,992 Found new lowest validation loss at iteration 84! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_1HEAD_best_val_loss_seed2.pth
2022-01-13 23:22:04,480 iteration 85 : loss : 0.202828, loss_ce: 0.090462
  1%|▍                              | 5/400 [02:17<3:16:52, 29.90s/it]2022-01-13 23:22:05,903 iteration 86 : loss : 0.287809, loss_ce: 0.108610
2022-01-13 23:22:07,214 iteration 87 : loss : 0.234461, loss_ce: 0.102508
2022-01-13 23:22:08,565 iteration 88 : loss : 0.224047, loss_ce: 0.086396
2022-01-13 23:22:10,009 iteration 89 : loss : 0.219209, loss_ce: 0.094167
2022-01-13 23:22:11,370 iteration 90 : loss : 0.214839, loss_ce: 0.092733
2022-01-13 23:22:12,775 iteration 91 : loss : 0.272518, loss_ce: 0.111764
2022-01-13 23:22:14,151 iteration 92 : loss : 0.213437, loss_ce: 0.080055
2022-01-13 23:22:15,631 iteration 93 : loss : 0.244430, loss_ce: 0.100124
2022-01-13 23:22:17,086 iteration 94 : loss : 0.213385, loss_ce: 0.102983
2022-01-13 23:22:18,471 iteration 95 : loss : 0.233030, loss_ce: 0.089592
2022-01-13 23:22:19,821 iteration 96 : loss : 0.207843, loss_ce: 0.079616
2022-01-13 23:22:21,157 iteration 97 : loss : 0.190944, loss_ce: 0.076361
2022-01-13 23:22:22,547 iteration 98 : loss : 0.256512, loss_ce: 0.098558
2022-01-13 23:22:24,069 iteration 99 : loss : 0.233493, loss_ce: 0.097091
2022-01-13 23:22:25,592 iteration 100 : loss : 0.242542, loss_ce: 0.098368
2022-01-13 23:22:26,974 iteration 101 : loss : 0.282201, loss_ce: 0.128677
2022-01-13 23:22:28,369 iteration 102 : loss : 0.227907, loss_ce: 0.081541
  2%|▍                              | 6/400 [02:41<3:02:58, 27.86s/it]2022-01-13 23:22:29,846 iteration 103 : loss : 0.227482, loss_ce: 0.087564
2022-01-13 23:22:31,295 iteration 104 : loss : 0.234827, loss_ce: 0.084874
2022-01-13 23:22:32,712 iteration 105 : loss : 0.226290, loss_ce: 0.093456
2022-01-13 23:22:34,148 iteration 106 : loss : 0.225057, loss_ce: 0.086386
2022-01-13 23:22:35,635 iteration 107 : loss : 0.201509, loss_ce: 0.085084
2022-01-13 23:22:37,025 iteration 108 : loss : 0.248668, loss_ce: 0.117622
2022-01-13 23:22:38,450 iteration 109 : loss : 0.186291, loss_ce: 0.075466
2022-01-13 23:22:39,890 iteration 110 : loss : 0.244974, loss_ce: 0.111177
2022-01-13 23:22:41,483 iteration 111 : loss : 0.209971, loss_ce: 0.083097
2022-01-13 23:22:42,857 iteration 112 : loss : 0.254616, loss_ce: 0.095930
2022-01-13 23:22:44,359 iteration 113 : loss : 0.208490, loss_ce: 0.076153
2022-01-13 23:22:45,789 iteration 114 : loss : 0.202116, loss_ce: 0.067842
2022-01-13 23:22:47,129 iteration 115 : loss : 0.185146, loss_ce: 0.068058
2022-01-13 23:22:48,537 iteration 116 : loss : 0.234393, loss_ce: 0.101998
2022-01-13 23:22:49,931 iteration 117 : loss : 0.181508, loss_ce: 0.073869
2022-01-13 23:22:51,388 iteration 118 : loss : 0.235511, loss_ce: 0.087889
2022-01-13 23:22:52,772 iteration 119 : loss : 0.255532, loss_ce: 0.106570
  2%|▌                              | 7/400 [03:06<2:55:05, 26.73s/it]2022-01-13 23:22:54,301 iteration 120 : loss : 0.248827, loss_ce: 0.122338
2022-01-13 23:22:55,744 iteration 121 : loss : 0.255981, loss_ce: 0.108681
2022-01-13 23:22:57,061 iteration 122 : loss : 0.194042, loss_ce: 0.076421
2022-01-13 23:22:58,472 iteration 123 : loss : 0.256896, loss_ce: 0.116788
2022-01-13 23:22:59,857 iteration 124 : loss : 0.213894, loss_ce: 0.080696
2022-01-13 23:23:01,285 iteration 125 : loss : 0.224678, loss_ce: 0.084773
2022-01-13 23:23:02,736 iteration 126 : loss : 0.175315, loss_ce: 0.069498
2022-01-13 23:23:04,211 iteration 127 : loss : 0.234545, loss_ce: 0.095168
2022-01-13 23:23:05,665 iteration 128 : loss : 0.236905, loss_ce: 0.084151
2022-01-13 23:23:07,172 iteration 129 : loss : 0.250179, loss_ce: 0.109202
2022-01-13 23:23:08,509 iteration 130 : loss : 0.199984, loss_ce: 0.075999
2022-01-13 23:23:09,922 iteration 131 : loss : 0.210951, loss_ce: 0.096018
2022-01-13 23:23:11,349 iteration 132 : loss : 0.245075, loss_ce: 0.095814
2022-01-13 23:23:12,797 iteration 133 : loss : 0.312949, loss_ce: 0.161041
2022-01-13 23:23:14,214 iteration 134 : loss : 0.213870, loss_ce: 0.082138
2022-01-13 23:23:15,619 iteration 135 : loss : 0.180204, loss_ce: 0.060967
2022-01-13 23:23:17,137 iteration 136 : loss : 0.191441, loss_ce: 0.084187
  2%|▌                              | 8/400 [03:30<2:49:42, 25.98s/it]2022-01-13 23:23:18,682 iteration 137 : loss : 0.215066, loss_ce: 0.078870
2022-01-13 23:23:20,050 iteration 138 : loss : 0.192425, loss_ce: 0.072158
2022-01-13 23:23:21,575 iteration 139 : loss : 0.207713, loss_ce: 0.059615
2022-01-13 23:23:22,992 iteration 140 : loss : 0.309846, loss_ce: 0.137726
2022-01-13 23:23:24,362 iteration 141 : loss : 0.254046, loss_ce: 0.103980
2022-01-13 23:23:25,776 iteration 142 : loss : 0.206703, loss_ce: 0.077621
2022-01-13 23:23:27,207 iteration 143 : loss : 0.241145, loss_ce: 0.088661
2022-01-13 23:23:28,635 iteration 144 : loss : 0.205240, loss_ce: 0.068353
2022-01-13 23:23:30,080 iteration 145 : loss : 0.229929, loss_ce: 0.106442
2022-01-13 23:23:31,564 iteration 146 : loss : 0.183289, loss_ce: 0.077578
2022-01-13 23:23:33,018 iteration 147 : loss : 0.254379, loss_ce: 0.114763
2022-01-13 23:23:34,540 iteration 148 : loss : 0.219469, loss_ce: 0.094107
2022-01-13 23:23:36,053 iteration 149 : loss : 0.225742, loss_ce: 0.097844
2022-01-13 23:23:37,565 iteration 150 : loss : 0.196059, loss_ce: 0.079998
2022-01-13 23:23:38,956 iteration 151 : loss : 0.197874, loss_ce: 0.103532
2022-01-13 23:23:40,303 iteration 152 : loss : 0.155926, loss_ce: 0.066671
2022-01-13 23:23:41,724 iteration 153 : loss : 0.167829, loss_ce: 0.066570
  2%|▋                              | 9/400 [03:55<2:46:26, 25.54s/it]2022-01-13 23:23:43,227 iteration 154 : loss : 0.235223, loss_ce: 0.108396
2022-01-13 23:23:44,633 iteration 155 : loss : 0.184125, loss_ce: 0.090507
2022-01-13 23:23:46,018 iteration 156 : loss : 0.224724, loss_ce: 0.097013
2022-01-13 23:23:47,384 iteration 157 : loss : 0.184747, loss_ce: 0.075574
2022-01-13 23:23:48,846 iteration 158 : loss : 0.216855, loss_ce: 0.083641
2022-01-13 23:23:50,320 iteration 159 : loss : 0.169651, loss_ce: 0.072072
2022-01-13 23:23:51,698 iteration 160 : loss : 0.204160, loss_ce: 0.081323
2022-01-13 23:23:53,184 iteration 161 : loss : 0.206465, loss_ce: 0.092710
2022-01-13 23:23:54,607 iteration 162 : loss : 0.178830, loss_ce: 0.062952
2022-01-13 23:23:56,014 iteration 163 : loss : 0.231752, loss_ce: 0.097081
2022-01-13 23:23:57,406 iteration 164 : loss : 0.201030, loss_ce: 0.077074
2022-01-13 23:23:58,756 iteration 165 : loss : 0.151592, loss_ce: 0.053832
2022-01-13 23:24:00,187 iteration 166 : loss : 0.247256, loss_ce: 0.135686
2022-01-13 23:24:01,705 iteration 167 : loss : 0.257862, loss_ce: 0.118333
2022-01-13 23:24:03,107 iteration 168 : loss : 0.241626, loss_ce: 0.088482
2022-01-13 23:24:04,528 iteration 169 : loss : 0.192371, loss_ce: 0.076599
2022-01-13 23:24:04,528 Training Data Eval:
2022-01-13 23:24:11,487   Average segmentation loss on training set: 1.0188
2022-01-13 23:24:11,487 Validation Data Eval:
2022-01-13 23:24:13,927   Average segmentation loss on validation set: 0.9511
2022-01-13 23:24:15,437 iteration 170 : loss : 0.203825, loss_ce: 0.085916
  2%|▊                             | 10/400 [04:28<3:02:24, 28.06s/it]2022-01-13 23:24:16,954 iteration 171 : loss : 0.163802, loss_ce: 0.071674
2022-01-13 23:24:18,322 iteration 172 : loss : 0.179818, loss_ce: 0.087592
2022-01-13 23:24:19,778 iteration 173 : loss : 0.198384, loss_ce: 0.077130
2022-01-13 23:24:21,098 iteration 174 : loss : 0.193343, loss_ce: 0.095883
2022-01-13 23:24:22,496 iteration 175 : loss : 0.205509, loss_ce: 0.067201
2022-01-13 23:24:23,890 iteration 176 : loss : 0.186196, loss_ce: 0.082797
2022-01-13 23:24:25,336 iteration 177 : loss : 0.131081, loss_ce: 0.054981
2022-01-13 23:24:26,745 iteration 178 : loss : 0.163720, loss_ce: 0.065573
2022-01-13 23:24:28,079 iteration 179 : loss : 0.143474, loss_ce: 0.054376
2022-01-13 23:24:29,578 iteration 180 : loss : 0.213694, loss_ce: 0.105080
2022-01-13 23:24:31,013 iteration 181 : loss : 0.199730, loss_ce: 0.087535
2022-01-13 23:24:32,411 iteration 182 : loss : 0.194810, loss_ce: 0.084147
2022-01-13 23:24:33,852 iteration 183 : loss : 0.196382, loss_ce: 0.067092
2022-01-13 23:24:35,435 iteration 184 : loss : 0.230808, loss_ce: 0.084674
2022-01-13 23:24:36,991 iteration 185 : loss : 0.221681, loss_ce: 0.092544
2022-01-13 23:24:38,378 iteration 186 : loss : 0.215604, loss_ce: 0.081449
2022-01-13 23:24:39,815 iteration 187 : loss : 0.155988, loss_ce: 0.067321
  3%|▊                             | 11/400 [04:53<2:54:37, 26.93s/it]2022-01-13 23:24:41,234 iteration 188 : loss : 0.187545, loss_ce: 0.082887
2022-01-13 23:24:42,748 iteration 189 : loss : 0.211761, loss_ce: 0.089114
2022-01-13 23:24:44,184 iteration 190 : loss : 0.258744, loss_ce: 0.126505
2022-01-13 23:24:45,604 iteration 191 : loss : 0.148330, loss_ce: 0.063141
2022-01-13 23:24:47,019 iteration 192 : loss : 0.180258, loss_ce: 0.070204
2022-01-13 23:24:48,352 iteration 193 : loss : 0.199642, loss_ce: 0.083479
2022-01-13 23:24:49,790 iteration 194 : loss : 0.165566, loss_ce: 0.069408
2022-01-13 23:24:51,232 iteration 195 : loss : 0.193674, loss_ce: 0.075501
2022-01-13 23:24:52,620 iteration 196 : loss : 0.167503, loss_ce: 0.078738
2022-01-13 23:24:54,066 iteration 197 : loss : 0.179961, loss_ce: 0.062233
2022-01-13 23:24:55,486 iteration 198 : loss : 0.196005, loss_ce: 0.068237
2022-01-13 23:24:56,799 iteration 199 : loss : 0.230766, loss_ce: 0.079151
2022-01-13 23:24:58,186 iteration 200 : loss : 0.254481, loss_ce: 0.124779
2022-01-13 23:24:59,705 iteration 201 : loss : 0.233476, loss_ce: 0.096574
2022-01-13 23:25:01,094 iteration 202 : loss : 0.206434, loss_ce: 0.084781
2022-01-13 23:25:02,451 iteration 203 : loss : 0.248332, loss_ce: 0.134241
2022-01-13 23:25:03,776 iteration 204 : loss : 0.182881, loss_ce: 0.078389
  3%|▉                             | 12/400 [05:17<2:48:21, 26.03s/it]2022-01-13 23:25:05,186 iteration 205 : loss : 0.241833, loss_ce: 0.105409
2022-01-13 23:25:06,605 iteration 206 : loss : 0.271494, loss_ce: 0.127147
2022-01-13 23:25:08,116 iteration 207 : loss : 0.232939, loss_ce: 0.115759
2022-01-13 23:25:09,621 iteration 208 : loss : 0.183288, loss_ce: 0.067993
2022-01-13 23:25:10,980 iteration 209 : loss : 0.190603, loss_ce: 0.079237
2022-01-13 23:25:12,329 iteration 210 : loss : 0.145788, loss_ce: 0.055607
2022-01-13 23:25:13,722 iteration 211 : loss : 0.216194, loss_ce: 0.082240
2022-01-13 23:25:15,037 iteration 212 : loss : 0.213017, loss_ce: 0.074778
2022-01-13 23:25:16,482 iteration 213 : loss : 0.230321, loss_ce: 0.102418
2022-01-13 23:25:17,896 iteration 214 : loss : 0.229765, loss_ce: 0.072503
2022-01-13 23:25:19,245 iteration 215 : loss : 0.183401, loss_ce: 0.074807
2022-01-13 23:25:20,693 iteration 216 : loss : 0.232799, loss_ce: 0.100362
2022-01-13 23:25:22,062 iteration 217 : loss : 0.217874, loss_ce: 0.085568
2022-01-13 23:25:23,456 iteration 218 : loss : 0.165428, loss_ce: 0.066832
2022-01-13 23:25:24,875 iteration 219 : loss : 0.166149, loss_ce: 0.061540
2022-01-13 23:25:26,257 iteration 220 : loss : 0.216103, loss_ce: 0.103674
2022-01-13 23:25:27,670 iteration 221 : loss : 0.144046, loss_ce: 0.067736
  3%|▉                             | 13/400 [05:41<2:43:44, 25.39s/it]2022-01-13 23:25:29,253 iteration 222 : loss : 0.201129, loss_ce: 0.082501
2022-01-13 23:25:30,710 iteration 223 : loss : 0.157654, loss_ce: 0.063088
2022-01-13 23:25:32,033 iteration 224 : loss : 0.188822, loss_ce: 0.081879
2022-01-13 23:25:33,493 iteration 225 : loss : 0.195223, loss_ce: 0.077011
2022-01-13 23:25:34,948 iteration 226 : loss : 0.252746, loss_ce: 0.086064
2022-01-13 23:25:36,401 iteration 227 : loss : 0.231519, loss_ce: 0.094097
2022-01-13 23:25:37,826 iteration 228 : loss : 0.270706, loss_ce: 0.096330
2022-01-13 23:25:39,250 iteration 229 : loss : 0.220765, loss_ce: 0.096261
2022-01-13 23:25:40,685 iteration 230 : loss : 0.239554, loss_ce: 0.102606
2022-01-13 23:25:42,070 iteration 231 : loss : 0.243028, loss_ce: 0.098849
2022-01-13 23:25:43,566 iteration 232 : loss : 0.203423, loss_ce: 0.100957
2022-01-13 23:25:45,032 iteration 233 : loss : 0.182307, loss_ce: 0.091364
2022-01-13 23:25:46,468 iteration 234 : loss : 0.220382, loss_ce: 0.076549
2022-01-13 23:25:47,879 iteration 235 : loss : 0.169676, loss_ce: 0.066491
2022-01-13 23:25:49,257 iteration 236 : loss : 0.218241, loss_ce: 0.103147
2022-01-13 23:25:50,625 iteration 237 : loss : 0.162867, loss_ce: 0.065796
2022-01-13 23:25:51,929 iteration 238 : loss : 0.170287, loss_ce: 0.083979
  4%|█                             | 14/400 [06:05<2:41:05, 25.04s/it]2022-01-13 23:25:53,330 iteration 239 : loss : 0.178877, loss_ce: 0.074919
2022-01-13 23:25:54,786 iteration 240 : loss : 0.224139, loss_ce: 0.115494
2022-01-13 23:25:56,159 iteration 241 : loss : 0.299125, loss_ce: 0.117164
2022-01-13 23:25:57,608 iteration 242 : loss : 0.202145, loss_ce: 0.090055
2022-01-13 23:25:59,084 iteration 243 : loss : 0.214687, loss_ce: 0.093268
2022-01-13 23:26:00,547 iteration 244 : loss : 0.195907, loss_ce: 0.096933
2022-01-13 23:26:01,876 iteration 245 : loss : 0.163070, loss_ce: 0.063326
2022-01-13 23:26:03,312 iteration 246 : loss : 0.199384, loss_ce: 0.082866
2022-01-13 23:26:04,664 iteration 247 : loss : 0.164088, loss_ce: 0.075138
2022-01-13 23:26:05,984 iteration 248 : loss : 0.165006, loss_ce: 0.060389
2022-01-13 23:26:07,503 iteration 249 : loss : 0.190637, loss_ce: 0.066997
2022-01-13 23:26:08,958 iteration 250 : loss : 0.199642, loss_ce: 0.086814
2022-01-13 23:26:10,351 iteration 251 : loss : 0.142139, loss_ce: 0.057884
2022-01-13 23:26:11,750 iteration 252 : loss : 0.191439, loss_ce: 0.097356
2022-01-13 23:26:13,097 iteration 253 : loss : 0.221546, loss_ce: 0.083328
2022-01-13 23:26:14,449 iteration 254 : loss : 0.169698, loss_ce: 0.072490
2022-01-13 23:26:14,449 Training Data Eval:
2022-01-13 23:26:21,447   Average segmentation loss on training set: 0.3417
2022-01-13 23:26:21,447 Validation Data Eval:
2022-01-13 23:26:23,905   Average segmentation loss on validation set: 0.3423
2022-01-13 23:26:25,331 iteration 255 : loss : 0.228214, loss_ce: 0.106731
  4%|█▏                            | 15/400 [06:38<2:56:51, 27.56s/it]2022-01-13 23:26:26,822 iteration 256 : loss : 0.168075, loss_ce: 0.065687
2022-01-13 23:26:28,199 iteration 257 : loss : 0.192931, loss_ce: 0.097071
2022-01-13 23:26:29,740 iteration 258 : loss : 0.198310, loss_ce: 0.071873
2022-01-13 23:26:31,099 iteration 259 : loss : 0.229626, loss_ce: 0.098102
2022-01-13 23:26:32,524 iteration 260 : loss : 0.168776, loss_ce: 0.075318
2022-01-13 23:26:33,990 iteration 261 : loss : 0.221349, loss_ce: 0.103113
2022-01-13 23:26:35,433 iteration 262 : loss : 0.203841, loss_ce: 0.122768
2022-01-13 23:26:36,825 iteration 263 : loss : 0.239150, loss_ce: 0.130024
2022-01-13 23:26:38,201 iteration 264 : loss : 0.203118, loss_ce: 0.084874
2022-01-13 23:26:39,667 iteration 265 : loss : 0.222830, loss_ce: 0.118968
2022-01-13 23:26:41,114 iteration 266 : loss : 0.213900, loss_ce: 0.073228
2022-01-13 23:26:42,506 iteration 267 : loss : 0.197665, loss_ce: 0.087074
2022-01-13 23:26:43,912 iteration 268 : loss : 0.148409, loss_ce: 0.073519
2022-01-13 23:26:45,286 iteration 269 : loss : 0.175672, loss_ce: 0.080970
2022-01-13 23:26:46,612 iteration 270 : loss : 0.201236, loss_ce: 0.081169
2022-01-13 23:26:48,050 iteration 271 : loss : 0.289989, loss_ce: 0.110348
2022-01-13 23:26:49,522 iteration 272 : loss : 0.192451, loss_ce: 0.081897
  4%|█▏                            | 16/400 [07:02<2:49:55, 26.55s/it]2022-01-13 23:26:50,964 iteration 273 : loss : 0.147058, loss_ce: 0.060539
2022-01-13 23:26:52,390 iteration 274 : loss : 0.212136, loss_ce: 0.088306
2022-01-13 23:26:53,786 iteration 275 : loss : 0.150174, loss_ce: 0.064841
2022-01-13 23:26:55,129 iteration 276 : loss : 0.202537, loss_ce: 0.096431
2022-01-13 23:26:56,616 iteration 277 : loss : 0.162799, loss_ce: 0.061796
2022-01-13 23:26:57,939 iteration 278 : loss : 0.296270, loss_ce: 0.116445
2022-01-13 23:26:59,337 iteration 279 : loss : 0.167086, loss_ce: 0.073078
2022-01-13 23:27:00,654 iteration 280 : loss : 0.174692, loss_ce: 0.087902
2022-01-13 23:27:02,057 iteration 281 : loss : 0.154337, loss_ce: 0.060263
2022-01-13 23:27:03,488 iteration 282 : loss : 0.187157, loss_ce: 0.087240
2022-01-13 23:27:04,912 iteration 283 : loss : 0.144982, loss_ce: 0.069796
2022-01-13 23:27:06,257 iteration 284 : loss : 0.112425, loss_ce: 0.047148
2022-01-13 23:27:07,656 iteration 285 : loss : 0.146142, loss_ce: 0.059115
2022-01-13 23:27:09,098 iteration 286 : loss : 0.143434, loss_ce: 0.057857
2022-01-13 23:27:10,443 iteration 287 : loss : 0.200489, loss_ce: 0.083547
2022-01-13 23:27:11,830 iteration 288 : loss : 0.138169, loss_ce: 0.061599
2022-01-13 23:27:13,239 iteration 289 : loss : 0.178741, loss_ce: 0.086654
  4%|█▎                            | 17/400 [07:26<2:44:02, 25.70s/it]2022-01-13 23:27:14,712 iteration 290 : loss : 0.153322, loss_ce: 0.075022
2022-01-13 23:27:16,118 iteration 291 : loss : 0.151615, loss_ce: 0.059725
2022-01-13 23:27:17,512 iteration 292 : loss : 0.114436, loss_ce: 0.045699
2022-01-13 23:27:19,041 iteration 293 : loss : 0.200631, loss_ce: 0.102659
2022-01-13 23:27:20,411 iteration 294 : loss : 0.162797, loss_ce: 0.074995
2022-01-13 23:27:21,769 iteration 295 : loss : 0.207905, loss_ce: 0.078205
2022-01-13 23:27:23,139 iteration 296 : loss : 0.182099, loss_ce: 0.075594
2022-01-13 23:27:24,610 iteration 297 : loss : 0.226263, loss_ce: 0.110300
2022-01-13 23:27:25,958 iteration 298 : loss : 0.210824, loss_ce: 0.082732
2022-01-13 23:27:27,373 iteration 299 : loss : 0.223352, loss_ce: 0.082919
2022-01-13 23:27:28,743 iteration 300 : loss : 0.160861, loss_ce: 0.066045
2022-01-13 23:27:30,133 iteration 301 : loss : 0.193861, loss_ce: 0.076330
2022-01-13 23:27:31,640 iteration 302 : loss : 0.270099, loss_ce: 0.137857
2022-01-13 23:27:33,093 iteration 303 : loss : 0.198219, loss_ce: 0.093435
2022-01-13 23:27:34,496 iteration 304 : loss : 0.153074, loss_ce: 0.067164
2022-01-13 23:27:35,928 iteration 305 : loss : 0.139195, loss_ce: 0.058720
2022-01-13 23:27:37,321 iteration 306 : loss : 0.176390, loss_ce: 0.071020
  4%|█▎                            | 18/400 [07:50<2:40:29, 25.21s/it]2022-01-13 23:27:38,748 iteration 307 : loss : 0.189257, loss_ce: 0.083165
2022-01-13 23:27:40,204 iteration 308 : loss : 0.178953, loss_ce: 0.065691
2022-01-13 23:27:41,604 iteration 309 : loss : 0.210367, loss_ce: 0.097351
2022-01-13 23:27:42,981 iteration 310 : loss : 0.143743, loss_ce: 0.053811
2022-01-13 23:27:44,369 iteration 311 : loss : 0.150936, loss_ce: 0.058668
2022-01-13 23:27:45,802 iteration 312 : loss : 0.223096, loss_ce: 0.069379
2022-01-13 23:27:47,275 iteration 313 : loss : 0.173017, loss_ce: 0.071105
2022-01-13 23:27:48,585 iteration 314 : loss : 0.178024, loss_ce: 0.073709
2022-01-13 23:27:49,949 iteration 315 : loss : 0.176780, loss_ce: 0.078400
2022-01-13 23:27:51,425 iteration 316 : loss : 0.156558, loss_ce: 0.067324
2022-01-13 23:27:52,893 iteration 317 : loss : 0.169592, loss_ce: 0.080051
2022-01-13 23:27:54,277 iteration 318 : loss : 0.193283, loss_ce: 0.101764
2022-01-13 23:27:55,700 iteration 319 : loss : 0.125355, loss_ce: 0.059906
2022-01-13 23:27:57,098 iteration 320 : loss : 0.171490, loss_ce: 0.062057
2022-01-13 23:27:58,456 iteration 321 : loss : 0.157264, loss_ce: 0.060516
2022-01-13 23:27:59,805 iteration 322 : loss : 0.107056, loss_ce: 0.047637
2022-01-13 23:28:01,174 iteration 323 : loss : 0.141663, loss_ce: 0.063233
  5%|█▍                            | 19/400 [08:14<2:37:30, 24.80s/it]2022-01-13 23:28:02,627 iteration 324 : loss : 0.119799, loss_ce: 0.043752
2022-01-13 23:28:04,003 iteration 325 : loss : 0.154675, loss_ce: 0.045372
2022-01-13 23:28:05,353 iteration 326 : loss : 0.267245, loss_ce: 0.117313
2022-01-13 23:28:06,682 iteration 327 : loss : 0.201762, loss_ce: 0.091654
2022-01-13 23:28:08,101 iteration 328 : loss : 0.109595, loss_ce: 0.036881
2022-01-13 23:28:09,565 iteration 329 : loss : 0.180267, loss_ce: 0.067602
2022-01-13 23:28:10,932 iteration 330 : loss : 0.168777, loss_ce: 0.077151
2022-01-13 23:28:12,331 iteration 331 : loss : 0.203507, loss_ce: 0.085040
2022-01-13 23:28:13,638 iteration 332 : loss : 0.104723, loss_ce: 0.044665
2022-01-13 23:28:15,069 iteration 333 : loss : 0.152197, loss_ce: 0.066898
2022-01-13 23:28:16,476 iteration 334 : loss : 0.134976, loss_ce: 0.059387
2022-01-13 23:28:17,926 iteration 335 : loss : 0.167316, loss_ce: 0.086064
2022-01-13 23:28:19,304 iteration 336 : loss : 0.169015, loss_ce: 0.079345
2022-01-13 23:28:20,675 iteration 337 : loss : 0.193856, loss_ce: 0.080104
2022-01-13 23:28:22,063 iteration 338 : loss : 0.144827, loss_ce: 0.069562
2022-01-13 23:28:23,432 iteration 339 : loss : 0.188776, loss_ce: 0.081580
2022-01-13 23:28:23,433 Training Data Eval:
2022-01-13 23:28:30,586   Average segmentation loss on training set: 0.6992
2022-01-13 23:28:30,587 Validation Data Eval:
2022-01-13 23:28:33,016   Average segmentation loss on validation set: 0.6472
2022-01-13 23:28:34,470 iteration 340 : loss : 0.166860, loss_ce: 0.080590
  5%|█▌                            | 20/400 [08:47<2:53:14, 27.35s/it]2022-01-13 23:28:35,911 iteration 341 : loss : 0.099718, loss_ce: 0.044229
2022-01-13 23:28:37,355 iteration 342 : loss : 0.180483, loss_ce: 0.084086
2022-01-13 23:28:38,783 iteration 343 : loss : 0.172145, loss_ce: 0.087632
2022-01-13 23:28:40,161 iteration 344 : loss : 0.118250, loss_ce: 0.052215
2022-01-13 23:28:41,531 iteration 345 : loss : 0.152893, loss_ce: 0.064387
2022-01-13 23:28:42,978 iteration 346 : loss : 0.128733, loss_ce: 0.052139
2022-01-13 23:28:44,414 iteration 347 : loss : 0.140598, loss_ce: 0.060774
2022-01-13 23:28:45,788 iteration 348 : loss : 0.104248, loss_ce: 0.040242
2022-01-13 23:28:47,183 iteration 349 : loss : 0.160114, loss_ce: 0.056215
2022-01-13 23:28:48,602 iteration 350 : loss : 0.168126, loss_ce: 0.073063
2022-01-13 23:28:49,978 iteration 351 : loss : 0.138649, loss_ce: 0.051068
2022-01-13 23:28:51,483 iteration 352 : loss : 0.161701, loss_ce: 0.082408
2022-01-13 23:28:52,970 iteration 353 : loss : 0.150973, loss_ce: 0.066066
2022-01-13 23:28:54,345 iteration 354 : loss : 0.138659, loss_ce: 0.053203
2022-01-13 23:28:55,781 iteration 355 : loss : 0.153443, loss_ce: 0.049140
2022-01-13 23:28:57,177 iteration 356 : loss : 0.135273, loss_ce: 0.042968
2022-01-13 23:28:58,606 iteration 357 : loss : 0.133393, loss_ce: 0.046556
  5%|█▌                            | 21/400 [09:12<2:46:40, 26.39s/it]2022-01-13 23:29:00,155 iteration 358 : loss : 0.199130, loss_ce: 0.109691
2022-01-13 23:29:01,635 iteration 359 : loss : 0.133041, loss_ce: 0.054697
2022-01-13 23:29:03,014 iteration 360 : loss : 0.104651, loss_ce: 0.037465
2022-01-13 23:29:04,437 iteration 361 : loss : 0.181878, loss_ce: 0.069480
2022-01-13 23:29:05,877 iteration 362 : loss : 0.169177, loss_ce: 0.092449
2022-01-13 23:29:07,207 iteration 363 : loss : 0.158004, loss_ce: 0.067685
2022-01-13 23:29:08,617 iteration 364 : loss : 0.228660, loss_ce: 0.085745
2022-01-13 23:29:09,971 iteration 365 : loss : 0.128199, loss_ce: 0.051562
2022-01-13 23:29:11,348 iteration 366 : loss : 0.136556, loss_ce: 0.047262
2022-01-13 23:29:12,763 iteration 367 : loss : 0.181186, loss_ce: 0.074955
2022-01-13 23:29:14,142 iteration 368 : loss : 0.186520, loss_ce: 0.084376
2022-01-13 23:29:15,497 iteration 369 : loss : 0.147545, loss_ce: 0.052667
2022-01-13 23:29:16,904 iteration 370 : loss : 0.202326, loss_ce: 0.095357
2022-01-13 23:29:18,299 iteration 371 : loss : 0.155244, loss_ce: 0.062127
2022-01-13 23:29:19,650 iteration 372 : loss : 0.148181, loss_ce: 0.062264
2022-01-13 23:29:21,048 iteration 373 : loss : 0.122001, loss_ce: 0.047473
2022-01-13 23:29:22,470 iteration 374 : loss : 0.146618, loss_ce: 0.064087
  6%|█▋                            | 22/400 [09:35<2:41:33, 25.64s/it]2022-01-13 23:29:23,979 iteration 375 : loss : 0.115344, loss_ce: 0.052358
2022-01-13 23:29:25,357 iteration 376 : loss : 0.147172, loss_ce: 0.048593
2022-01-13 23:29:26,758 iteration 377 : loss : 0.125279, loss_ce: 0.047107
2022-01-13 23:29:28,242 iteration 378 : loss : 0.149852, loss_ce: 0.055459
2022-01-13 23:29:29,656 iteration 379 : loss : 0.136173, loss_ce: 0.052799
2022-01-13 23:29:31,054 iteration 380 : loss : 0.181022, loss_ce: 0.085110
2022-01-13 23:29:32,500 iteration 381 : loss : 0.168662, loss_ce: 0.062548
2022-01-13 23:29:33,877 iteration 382 : loss : 0.137281, loss_ce: 0.059241
2022-01-13 23:29:35,330 iteration 383 : loss : 0.207113, loss_ce: 0.054839
2022-01-13 23:29:36,726 iteration 384 : loss : 0.115984, loss_ce: 0.049477
2022-01-13 23:29:38,104 iteration 385 : loss : 0.115266, loss_ce: 0.051211
2022-01-13 23:29:39,514 iteration 386 : loss : 0.157812, loss_ce: 0.056158
2022-01-13 23:29:40,864 iteration 387 : loss : 0.103106, loss_ce: 0.040800
2022-01-13 23:29:42,291 iteration 388 : loss : 0.169142, loss_ce: 0.082128
2022-01-13 23:29:43,681 iteration 389 : loss : 0.155821, loss_ce: 0.056620
2022-01-13 23:29:45,078 iteration 390 : loss : 0.160142, loss_ce: 0.084288
2022-01-13 23:29:46,508 iteration 391 : loss : 0.106534, loss_ce: 0.044658
  6%|█▋                            | 23/400 [09:59<2:38:01, 25.15s/it]2022-01-13 23:29:48,016 iteration 392 : loss : 0.147449, loss_ce: 0.063755
2022-01-13 23:29:49,361 iteration 393 : loss : 0.171647, loss_ce: 0.082859
2022-01-13 23:29:50,774 iteration 394 : loss : 0.206817, loss_ce: 0.073954
2022-01-13 23:29:52,120 iteration 395 : loss : 0.151990, loss_ce: 0.056692
2022-01-13 23:29:53,500 iteration 396 : loss : 0.150708, loss_ce: 0.056114
2022-01-13 23:29:54,993 iteration 397 : loss : 0.135722, loss_ce: 0.067680
2022-01-13 23:29:56,371 iteration 398 : loss : 0.142958, loss_ce: 0.052873
2022-01-13 23:29:57,779 iteration 399 : loss : 0.177481, loss_ce: 0.072741
2022-01-13 23:29:59,145 iteration 400 : loss : 0.114215, loss_ce: 0.045380
2022-01-13 23:30:00,554 iteration 401 : loss : 0.109899, loss_ce: 0.047793
2022-01-13 23:30:02,066 iteration 402 : loss : 0.127250, loss_ce: 0.058069
2022-01-13 23:30:03,501 iteration 403 : loss : 0.139133, loss_ce: 0.053631
2022-01-13 23:30:04,879 iteration 404 : loss : 0.125595, loss_ce: 0.044018
2022-01-13 23:30:06,257 iteration 405 : loss : 0.158834, loss_ce: 0.090421
2022-01-13 23:30:07,687 iteration 406 : loss : 0.137849, loss_ce: 0.055742
2022-01-13 23:30:09,139 iteration 407 : loss : 0.119580, loss_ce: 0.046677
2022-01-13 23:30:10,450 iteration 408 : loss : 0.119911, loss_ce: 0.053883
  6%|█▊                            | 24/400 [10:23<2:35:20, 24.79s/it]2022-01-13 23:30:11,973 iteration 409 : loss : 0.158813, loss_ce: 0.055557
2022-01-13 23:30:13,403 iteration 410 : loss : 0.130187, loss_ce: 0.049933
2022-01-13 23:30:14,827 iteration 411 : loss : 0.157170, loss_ce: 0.056173
2022-01-13 23:30:16,213 iteration 412 : loss : 0.126611, loss_ce: 0.052621
2022-01-13 23:30:17,602 iteration 413 : loss : 0.138530, loss_ce: 0.045554
2022-01-13 23:30:18,947 iteration 414 : loss : 0.111742, loss_ce: 0.043535
2022-01-13 23:30:20,416 iteration 415 : loss : 0.184527, loss_ce: 0.078010
2022-01-13 23:30:21,777 iteration 416 : loss : 0.138161, loss_ce: 0.064488
2022-01-13 23:30:23,211 iteration 417 : loss : 0.143898, loss_ce: 0.052229
2022-01-13 23:30:24,537 iteration 418 : loss : 0.128059, loss_ce: 0.075229
2022-01-13 23:30:25,913 iteration 419 : loss : 0.190037, loss_ce: 0.069669
2022-01-13 23:30:27,315 iteration 420 : loss : 0.093769, loss_ce: 0.044137
2022-01-13 23:30:28,771 iteration 421 : loss : 0.198932, loss_ce: 0.107480
2022-01-13 23:30:30,142 iteration 422 : loss : 0.127648, loss_ce: 0.045070
2022-01-13 23:30:31,554 iteration 423 : loss : 0.148000, loss_ce: 0.060542
2022-01-13 23:30:32,985 iteration 424 : loss : 0.155701, loss_ce: 0.068442
2022-01-13 23:30:32,985 Training Data Eval:
2022-01-13 23:30:39,954   Average segmentation loss on training set: 0.2820
2022-01-13 23:30:39,954 Validation Data Eval:
2022-01-13 23:30:42,419   Average segmentation loss on validation set: 0.3752
2022-01-13 23:30:43,890 iteration 425 : loss : 0.192856, loss_ce: 0.081309
  6%|█▉                            | 25/400 [10:57<2:51:08, 27.38s/it]2022-01-13 23:30:45,402 iteration 426 : loss : 0.133099, loss_ce: 0.056057
2022-01-13 23:30:46,825 iteration 427 : loss : 0.140319, loss_ce: 0.050368
2022-01-13 23:30:48,261 iteration 428 : loss : 0.143198, loss_ce: 0.056598
2022-01-13 23:30:49,641 iteration 429 : loss : 0.097314, loss_ce: 0.036052
2022-01-13 23:30:51,053 iteration 430 : loss : 0.161902, loss_ce: 0.064172
2022-01-13 23:30:52,386 iteration 431 : loss : 0.157572, loss_ce: 0.061411
2022-01-13 23:30:53,764 iteration 432 : loss : 0.094738, loss_ce: 0.037808
2022-01-13 23:30:55,166 iteration 433 : loss : 0.120237, loss_ce: 0.037258
2022-01-13 23:30:56,545 iteration 434 : loss : 0.123066, loss_ce: 0.043751
2022-01-13 23:30:57,934 iteration 435 : loss : 0.177860, loss_ce: 0.088484
2022-01-13 23:30:59,365 iteration 436 : loss : 0.163660, loss_ce: 0.068518
2022-01-13 23:31:00,778 iteration 437 : loss : 0.101589, loss_ce: 0.043573
2022-01-13 23:31:02,176 iteration 438 : loss : 0.162472, loss_ce: 0.097602
2022-01-13 23:31:03,572 iteration 439 : loss : 0.125641, loss_ce: 0.062103
2022-01-13 23:31:04,934 iteration 440 : loss : 0.099356, loss_ce: 0.043870
2022-01-13 23:31:06,321 iteration 441 : loss : 0.149551, loss_ce: 0.071810
2022-01-13 23:31:07,695 iteration 442 : loss : 0.184461, loss_ce: 0.073305
  6%|█▉                            | 26/400 [11:21<2:43:59, 26.31s/it]2022-01-13 23:31:09,180 iteration 443 : loss : 0.128059, loss_ce: 0.072638
2022-01-13 23:31:10,569 iteration 444 : loss : 0.160726, loss_ce: 0.065601
2022-01-13 23:31:12,168 iteration 445 : loss : 0.178892, loss_ce: 0.080439
2022-01-13 23:31:13,512 iteration 446 : loss : 0.196768, loss_ce: 0.076651
2022-01-13 23:31:14,993 iteration 447 : loss : 0.130312, loss_ce: 0.056650
2022-01-13 23:31:16,447 iteration 448 : loss : 0.131493, loss_ce: 0.065522
2022-01-13 23:31:17,856 iteration 449 : loss : 0.128884, loss_ce: 0.051592
2022-01-13 23:31:19,209 iteration 450 : loss : 0.132069, loss_ce: 0.056151
2022-01-13 23:31:20,628 iteration 451 : loss : 0.120690, loss_ce: 0.046884
2022-01-13 23:31:22,073 iteration 452 : loss : 0.095604, loss_ce: 0.046873
2022-01-13 23:31:23,513 iteration 453 : loss : 0.096145, loss_ce: 0.033800
2022-01-13 23:31:24,958 iteration 454 : loss : 0.184412, loss_ce: 0.062632
2022-01-13 23:31:26,433 iteration 455 : loss : 0.115578, loss_ce: 0.036207
2022-01-13 23:31:27,812 iteration 456 : loss : 0.171393, loss_ce: 0.055724
2022-01-13 23:31:29,177 iteration 457 : loss : 0.138707, loss_ce: 0.060410
2022-01-13 23:31:30,561 iteration 458 : loss : 0.168344, loss_ce: 0.075520
2022-01-13 23:31:31,978 iteration 459 : loss : 0.108089, loss_ce: 0.044937
  7%|██                            | 27/400 [11:45<2:39:47, 25.70s/it]2022-01-13 23:31:33,392 iteration 460 : loss : 0.150171, loss_ce: 0.052465
2022-01-13 23:31:34,813 iteration 461 : loss : 0.126616, loss_ce: 0.050166
2022-01-13 23:31:36,222 iteration 462 : loss : 0.132030, loss_ce: 0.038609
2022-01-13 23:31:37,538 iteration 463 : loss : 0.100363, loss_ce: 0.046356
2022-01-13 23:31:39,002 iteration 464 : loss : 0.125766, loss_ce: 0.054564
2022-01-13 23:31:40,389 iteration 465 : loss : 0.097310, loss_ce: 0.045985
2022-01-13 23:31:41,819 iteration 466 : loss : 0.141172, loss_ce: 0.066618
2022-01-13 23:31:43,196 iteration 467 : loss : 0.120101, loss_ce: 0.038531
2022-01-13 23:31:44,579 iteration 468 : loss : 0.113670, loss_ce: 0.041618
2022-01-13 23:31:45,936 iteration 469 : loss : 0.158377, loss_ce: 0.053496
2022-01-13 23:31:47,425 iteration 470 : loss : 0.169739, loss_ce: 0.078533
2022-01-13 23:31:48,779 iteration 471 : loss : 0.110176, loss_ce: 0.047347
2022-01-13 23:31:50,238 iteration 472 : loss : 0.180990, loss_ce: 0.071868
2022-01-13 23:31:51,671 iteration 473 : loss : 0.117795, loss_ce: 0.047007
2022-01-13 23:31:53,123 iteration 474 : loss : 0.100838, loss_ce: 0.040095
2022-01-13 23:31:54,546 iteration 475 : loss : 0.164400, loss_ce: 0.049842
2022-01-13 23:31:55,968 iteration 476 : loss : 0.103422, loss_ce: 0.047603
  7%|██                            | 28/400 [12:09<2:36:09, 25.19s/it]2022-01-13 23:31:57,407 iteration 477 : loss : 0.112673, loss_ce: 0.049914
2022-01-13 23:31:58,869 iteration 478 : loss : 0.118983, loss_ce: 0.046903
2022-01-13 23:32:00,211 iteration 479 : loss : 0.117608, loss_ce: 0.047484
2022-01-13 23:32:01,517 iteration 480 : loss : 0.113856, loss_ce: 0.049973
2022-01-13 23:32:02,908 iteration 481 : loss : 0.108819, loss_ce: 0.046430
2022-01-13 23:32:04,356 iteration 482 : loss : 0.118879, loss_ce: 0.045764
2022-01-13 23:32:05,781 iteration 483 : loss : 0.086289, loss_ce: 0.028791
2022-01-13 23:32:07,171 iteration 484 : loss : 0.107640, loss_ce: 0.044381
2022-01-13 23:32:08,500 iteration 485 : loss : 0.075414, loss_ce: 0.029684
2022-01-13 23:32:09,903 iteration 486 : loss : 0.245103, loss_ce: 0.076241
2022-01-13 23:32:11,332 iteration 487 : loss : 0.173539, loss_ce: 0.104041
2022-01-13 23:32:12,835 iteration 488 : loss : 0.200243, loss_ce: 0.078251
2022-01-13 23:32:14,259 iteration 489 : loss : 0.089550, loss_ce: 0.037357
2022-01-13 23:32:15,616 iteration 490 : loss : 0.094595, loss_ce: 0.039067
2022-01-13 23:32:17,088 iteration 491 : loss : 0.122116, loss_ce: 0.049431
2022-01-13 23:32:18,440 iteration 492 : loss : 0.118960, loss_ce: 0.050998
2022-01-13 23:32:19,815 iteration 493 : loss : 0.201713, loss_ce: 0.090484
  7%|██▏                           | 29/400 [12:33<2:33:15, 24.78s/it]2022-01-13 23:32:21,243 iteration 494 : loss : 0.119697, loss_ce: 0.045224
2022-01-13 23:32:22,630 iteration 495 : loss : 0.097025, loss_ce: 0.041049
2022-01-13 23:32:23,953 iteration 496 : loss : 0.111493, loss_ce: 0.050356
2022-01-13 23:32:25,398 iteration 497 : loss : 0.104489, loss_ce: 0.036063
2022-01-13 23:32:26,779 iteration 498 : loss : 0.125715, loss_ce: 0.049231
2022-01-13 23:32:28,263 iteration 499 : loss : 0.128389, loss_ce: 0.059133
2022-01-13 23:32:29,571 iteration 500 : loss : 0.093842, loss_ce: 0.038386
2022-01-13 23:32:30,971 iteration 501 : loss : 0.121511, loss_ce: 0.038198
2022-01-13 23:32:32,347 iteration 502 : loss : 0.142326, loss_ce: 0.049851
2022-01-13 23:32:33,744 iteration 503 : loss : 0.116015, loss_ce: 0.055853
2022-01-13 23:32:35,211 iteration 504 : loss : 0.085100, loss_ce: 0.032002
2022-01-13 23:32:36,704 iteration 505 : loss : 0.088153, loss_ce: 0.036994
2022-01-13 23:32:38,119 iteration 506 : loss : 0.122855, loss_ce: 0.058105
2022-01-13 23:32:39,518 iteration 507 : loss : 0.085782, loss_ce: 0.027995
2022-01-13 23:32:40,945 iteration 508 : loss : 0.113919, loss_ce: 0.037179
2022-01-13 23:32:42,390 iteration 509 : loss : 0.126844, loss_ce: 0.063752
2022-01-13 23:32:42,391 Training Data Eval:
2022-01-13 23:32:49,467   Average segmentation loss on training set: 0.0815
2022-01-13 23:32:49,468 Validation Data Eval:
2022-01-13 23:32:51,890   Average segmentation loss on validation set: 0.1212
2022-01-13 23:32:57,563 Found new lowest validation loss at iteration 509! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_1HEAD_best_val_loss_seed2.pth
2022-01-13 23:32:58,965 iteration 510 : loss : 0.094120, loss_ce: 0.038809
  8%|██▎                           | 30/400 [13:12<2:59:25, 29.10s/it]2022-01-13 23:33:00,379 iteration 511 : loss : 0.099474, loss_ce: 0.033178
2022-01-13 23:33:01,755 iteration 512 : loss : 0.121701, loss_ce: 0.052727
2022-01-13 23:33:03,150 iteration 513 : loss : 0.097348, loss_ce: 0.040248
2022-01-13 23:33:04,580 iteration 514 : loss : 0.106221, loss_ce: 0.041595
2022-01-13 23:33:05,901 iteration 515 : loss : 0.114084, loss_ce: 0.052071
2022-01-13 23:33:07,190 iteration 516 : loss : 0.070785, loss_ce: 0.027604
2022-01-13 23:33:08,674 iteration 517 : loss : 0.094745, loss_ce: 0.046355
2022-01-13 23:33:10,151 iteration 518 : loss : 0.204404, loss_ce: 0.088134
2022-01-13 23:33:11,638 iteration 519 : loss : 0.102989, loss_ce: 0.045494
2022-01-13 23:33:13,037 iteration 520 : loss : 0.105199, loss_ce: 0.048664
2022-01-13 23:33:14,367 iteration 521 : loss : 0.076587, loss_ce: 0.027595
2022-01-13 23:33:15,818 iteration 522 : loss : 0.141580, loss_ce: 0.058393
2022-01-13 23:33:17,199 iteration 523 : loss : 0.099951, loss_ce: 0.034382
2022-01-13 23:33:18,564 iteration 524 : loss : 0.127356, loss_ce: 0.065053
2022-01-13 23:33:19,955 iteration 525 : loss : 0.097280, loss_ce: 0.043271
2022-01-13 23:33:21,386 iteration 526 : loss : 0.095099, loss_ce: 0.040635
2022-01-13 23:33:22,802 iteration 527 : loss : 0.111913, loss_ce: 0.040489
  8%|██▎                           | 31/400 [13:36<2:49:14, 27.52s/it]2022-01-13 23:33:24,247 iteration 528 : loss : 0.097604, loss_ce: 0.048106
2022-01-13 23:33:25,749 iteration 529 : loss : 0.126320, loss_ce: 0.041755
2022-01-13 23:33:27,129 iteration 530 : loss : 0.089015, loss_ce: 0.033610
2022-01-13 23:33:28,476 iteration 531 : loss : 0.095866, loss_ce: 0.035919
2022-01-13 23:33:29,886 iteration 532 : loss : 0.126691, loss_ce: 0.059662
2022-01-13 23:33:31,304 iteration 533 : loss : 0.093800, loss_ce: 0.036379
2022-01-13 23:33:32,686 iteration 534 : loss : 0.108595, loss_ce: 0.041193
2022-01-13 23:33:34,135 iteration 535 : loss : 0.104759, loss_ce: 0.038686
2022-01-13 23:33:35,539 iteration 536 : loss : 0.109352, loss_ce: 0.053196
2022-01-13 23:33:36,918 iteration 537 : loss : 0.150255, loss_ce: 0.065298
2022-01-13 23:33:38,334 iteration 538 : loss : 0.138378, loss_ce: 0.062169
2022-01-13 23:33:39,663 iteration 539 : loss : 0.098769, loss_ce: 0.037647
2022-01-13 23:33:41,199 iteration 540 : loss : 0.120127, loss_ce: 0.061885
2022-01-13 23:33:42,688 iteration 541 : loss : 0.159223, loss_ce: 0.077893
2022-01-13 23:33:44,035 iteration 542 : loss : 0.151811, loss_ce: 0.064071
2022-01-13 23:33:45,449 iteration 543 : loss : 0.093830, loss_ce: 0.038765
2022-01-13 23:33:46,827 iteration 544 : loss : 0.166859, loss_ce: 0.058508
  8%|██▍                           | 32/400 [14:00<2:42:21, 26.47s/it]2022-01-13 23:33:48,370 iteration 545 : loss : 0.098906, loss_ce: 0.044786
2022-01-13 23:33:49,836 iteration 546 : loss : 0.094531, loss_ce: 0.038468
2022-01-13 23:33:51,300 iteration 547 : loss : 0.128026, loss_ce: 0.055303
2022-01-13 23:33:52,658 iteration 548 : loss : 0.181843, loss_ce: 0.072985
2022-01-13 23:33:54,001 iteration 549 : loss : 0.126879, loss_ce: 0.049462
2022-01-13 23:33:55,362 iteration 550 : loss : 0.094228, loss_ce: 0.033245
2022-01-13 23:33:56,713 iteration 551 : loss : 0.116544, loss_ce: 0.032351
2022-01-13 23:33:58,148 iteration 552 : loss : 0.151504, loss_ce: 0.065063
2022-01-13 23:33:59,577 iteration 553 : loss : 0.088804, loss_ce: 0.035094
2022-01-13 23:34:00,983 iteration 554 : loss : 0.135719, loss_ce: 0.058036
2022-01-13 23:34:02,425 iteration 555 : loss : 0.093058, loss_ce: 0.026029
2022-01-13 23:34:03,906 iteration 556 : loss : 0.152378, loss_ce: 0.070505
2022-01-13 23:34:05,265 iteration 557 : loss : 0.118468, loss_ce: 0.061544
2022-01-13 23:34:06,611 iteration 558 : loss : 0.091474, loss_ce: 0.031860
2022-01-13 23:34:07,985 iteration 559 : loss : 0.119388, loss_ce: 0.049530
2022-01-13 23:34:09,438 iteration 560 : loss : 0.114339, loss_ce: 0.055366
2022-01-13 23:34:10,891 iteration 561 : loss : 0.090773, loss_ce: 0.040574
  8%|██▍                           | 33/400 [14:24<2:37:29, 25.75s/it]2022-01-13 23:34:12,383 iteration 562 : loss : 0.146369, loss_ce: 0.049255
2022-01-13 23:34:13,731 iteration 563 : loss : 0.076074, loss_ce: 0.039679
2022-01-13 23:34:15,090 iteration 564 : loss : 0.100127, loss_ce: 0.050487
2022-01-13 23:34:16,515 iteration 565 : loss : 0.097797, loss_ce: 0.043915
2022-01-13 23:34:17,924 iteration 566 : loss : 0.122268, loss_ce: 0.044243
2022-01-13 23:34:19,363 iteration 567 : loss : 0.156955, loss_ce: 0.064611
2022-01-13 23:34:20,781 iteration 568 : loss : 0.119577, loss_ce: 0.033755
2022-01-13 23:34:22,278 iteration 569 : loss : 0.184720, loss_ce: 0.060617
2022-01-13 23:34:23,688 iteration 570 : loss : 0.148523, loss_ce: 0.057331
2022-01-13 23:34:25,128 iteration 571 : loss : 0.096587, loss_ce: 0.039330
2022-01-13 23:34:26,585 iteration 572 : loss : 0.105730, loss_ce: 0.047778
2022-01-13 23:34:27,949 iteration 573 : loss : 0.099216, loss_ce: 0.042235
2022-01-13 23:34:29,450 iteration 574 : loss : 0.115186, loss_ce: 0.040013
2022-01-13 23:34:30,838 iteration 575 : loss : 0.121393, loss_ce: 0.037453
2022-01-13 23:34:32,210 iteration 576 : loss : 0.098530, loss_ce: 0.049378
2022-01-13 23:34:33,768 iteration 577 : loss : 0.138407, loss_ce: 0.066641
2022-01-13 23:34:35,237 iteration 578 : loss : 0.082115, loss_ce: 0.036461
  8%|██▌                           | 34/400 [14:48<2:34:28, 25.32s/it]2022-01-13 23:34:36,652 iteration 579 : loss : 0.094785, loss_ce: 0.042744
2022-01-13 23:34:38,116 iteration 580 : loss : 0.090505, loss_ce: 0.036796
2022-01-13 23:34:39,678 iteration 581 : loss : 0.072835, loss_ce: 0.030919
2022-01-13 23:34:41,025 iteration 582 : loss : 0.097955, loss_ce: 0.043052
2022-01-13 23:34:42,439 iteration 583 : loss : 0.104639, loss_ce: 0.047114
2022-01-13 23:34:43,900 iteration 584 : loss : 0.117426, loss_ce: 0.050199
2022-01-13 23:34:45,269 iteration 585 : loss : 0.110988, loss_ce: 0.038491
2022-01-13 23:34:46,697 iteration 586 : loss : 0.130962, loss_ce: 0.049435
2022-01-13 23:34:48,123 iteration 587 : loss : 0.078494, loss_ce: 0.039289
2022-01-13 23:34:49,475 iteration 588 : loss : 0.119944, loss_ce: 0.041589
2022-01-13 23:34:50,949 iteration 589 : loss : 0.132460, loss_ce: 0.064223
2022-01-13 23:34:52,330 iteration 590 : loss : 0.129506, loss_ce: 0.046682
2022-01-13 23:34:53,712 iteration 591 : loss : 0.110784, loss_ce: 0.042652
2022-01-13 23:34:55,156 iteration 592 : loss : 0.086597, loss_ce: 0.039300
2022-01-13 23:34:56,503 iteration 593 : loss : 0.137658, loss_ce: 0.052087
2022-01-13 23:34:57,946 iteration 594 : loss : 0.105140, loss_ce: 0.037030
2022-01-13 23:34:57,946 Training Data Eval:
2022-01-13 23:35:05,024   Average segmentation loss on training set: 0.0990
2022-01-13 23:35:05,024 Validation Data Eval:
2022-01-13 23:35:07,484   Average segmentation loss on validation set: 0.1719
2022-01-13 23:35:08,929 iteration 595 : loss : 0.156332, loss_ce: 0.056527
  9%|██▋                           | 35/400 [15:22<2:49:20, 27.84s/it]2022-01-13 23:35:10,463 iteration 596 : loss : 0.100555, loss_ce: 0.044229
2022-01-13 23:35:11,876 iteration 597 : loss : 0.078607, loss_ce: 0.033388
2022-01-13 23:35:13,273 iteration 598 : loss : 0.095488, loss_ce: 0.035277
2022-01-13 23:35:14,708 iteration 599 : loss : 0.132868, loss_ce: 0.046720
2022-01-13 23:35:16,162 iteration 600 : loss : 0.080169, loss_ce: 0.027196
2022-01-13 23:35:17,598 iteration 601 : loss : 0.109430, loss_ce: 0.036986
2022-01-13 23:35:18,932 iteration 602 : loss : 0.097704, loss_ce: 0.042427
2022-01-13 23:35:20,332 iteration 603 : loss : 0.125659, loss_ce: 0.043872
2022-01-13 23:35:21,692 iteration 604 : loss : 0.125311, loss_ce: 0.044711
2022-01-13 23:35:23,215 iteration 605 : loss : 0.086553, loss_ce: 0.033190
2022-01-13 23:35:24,591 iteration 606 : loss : 0.130342, loss_ce: 0.062181
2022-01-13 23:35:25,988 iteration 607 : loss : 0.097907, loss_ce: 0.035431
2022-01-13 23:35:27,380 iteration 608 : loss : 0.076241, loss_ce: 0.038051
2022-01-13 23:35:28,761 iteration 609 : loss : 0.102913, loss_ce: 0.037939
2022-01-13 23:35:30,293 iteration 610 : loss : 0.149793, loss_ce: 0.074076
2022-01-13 23:35:31,702 iteration 611 : loss : 0.135720, loss_ce: 0.060356
2022-01-13 23:35:33,062 iteration 612 : loss : 0.094323, loss_ce: 0.039370
  9%|██▋                           | 36/400 [15:46<2:42:07, 26.72s/it]2022-01-13 23:35:34,543 iteration 613 : loss : 0.155454, loss_ce: 0.065648
2022-01-13 23:35:36,004 iteration 614 : loss : 0.124311, loss_ce: 0.055862
2022-01-13 23:35:37,429 iteration 615 : loss : 0.132189, loss_ce: 0.064509
2022-01-13 23:35:38,802 iteration 616 : loss : 0.141829, loss_ce: 0.048070
2022-01-13 23:35:40,238 iteration 617 : loss : 0.164858, loss_ce: 0.065125
2022-01-13 23:35:41,729 iteration 618 : loss : 0.078789, loss_ce: 0.036704
2022-01-13 23:35:43,153 iteration 619 : loss : 0.112255, loss_ce: 0.045216
2022-01-13 23:35:44,634 iteration 620 : loss : 0.087636, loss_ce: 0.038833
2022-01-13 23:35:45,982 iteration 621 : loss : 0.093312, loss_ce: 0.033314
2022-01-13 23:35:47,470 iteration 622 : loss : 0.100722, loss_ce: 0.040829
2022-01-13 23:35:48,969 iteration 623 : loss : 0.121840, loss_ce: 0.060610
2022-01-13 23:35:50,315 iteration 624 : loss : 0.128500, loss_ce: 0.050100
2022-01-13 23:35:51,857 iteration 625 : loss : 0.134120, loss_ce: 0.054820
2022-01-13 23:35:53,259 iteration 626 : loss : 0.135008, loss_ce: 0.061995
2022-01-13 23:35:54,615 iteration 627 : loss : 0.129602, loss_ce: 0.044998
2022-01-13 23:35:55,957 iteration 628 : loss : 0.139913, loss_ce: 0.056776
2022-01-13 23:35:57,404 iteration 629 : loss : 0.065589, loss_ce: 0.028331
  9%|██▊                           | 37/400 [16:10<2:37:21, 26.01s/it]2022-01-13 23:35:58,776 iteration 630 : loss : 0.105207, loss_ce: 0.046294
2022-01-13 23:36:00,175 iteration 631 : loss : 0.124789, loss_ce: 0.052279
2022-01-13 23:36:01,531 iteration 632 : loss : 0.080041, loss_ce: 0.031210
2022-01-13 23:36:02,964 iteration 633 : loss : 0.110105, loss_ce: 0.056871
2022-01-13 23:36:04,382 iteration 634 : loss : 0.063289, loss_ce: 0.029567
2022-01-13 23:36:05,839 iteration 635 : loss : 0.090190, loss_ce: 0.041760
2022-01-13 23:36:07,240 iteration 636 : loss : 0.161994, loss_ce: 0.054789
2022-01-13 23:36:08,639 iteration 637 : loss : 0.104883, loss_ce: 0.045242
2022-01-13 23:36:10,042 iteration 638 : loss : 0.070335, loss_ce: 0.033253
2022-01-13 23:36:11,488 iteration 639 : loss : 0.084769, loss_ce: 0.038043
2022-01-13 23:36:12,936 iteration 640 : loss : 0.109415, loss_ce: 0.034044
2022-01-13 23:36:14,303 iteration 641 : loss : 0.073403, loss_ce: 0.026175
2022-01-13 23:36:15,712 iteration 642 : loss : 0.075089, loss_ce: 0.026800
2022-01-13 23:36:17,089 iteration 643 : loss : 0.108532, loss_ce: 0.034175
2022-01-13 23:36:18,496 iteration 644 : loss : 0.104108, loss_ce: 0.028635
2022-01-13 23:36:19,859 iteration 645 : loss : 0.142901, loss_ce: 0.053353
2022-01-13 23:36:21,297 iteration 646 : loss : 0.106823, loss_ce: 0.043069
 10%|██▊                           | 38/400 [16:34<2:33:06, 25.38s/it]2022-01-13 23:36:22,742 iteration 647 : loss : 0.087089, loss_ce: 0.031076
2022-01-13 23:36:24,190 iteration 648 : loss : 0.121593, loss_ce: 0.047501
2022-01-13 23:36:25,612 iteration 649 : loss : 0.109645, loss_ce: 0.048972
2022-01-13 23:36:26,957 iteration 650 : loss : 0.079255, loss_ce: 0.035572
2022-01-13 23:36:28,366 iteration 651 : loss : 0.131696, loss_ce: 0.063138
2022-01-13 23:36:29,714 iteration 652 : loss : 0.103346, loss_ce: 0.035443
2022-01-13 23:36:31,150 iteration 653 : loss : 0.173323, loss_ce: 0.056151
2022-01-13 23:36:32,615 iteration 654 : loss : 0.155361, loss_ce: 0.057946
2022-01-13 23:36:34,050 iteration 655 : loss : 0.070764, loss_ce: 0.029430
2022-01-13 23:36:35,409 iteration 656 : loss : 0.093729, loss_ce: 0.039167
2022-01-13 23:36:36,815 iteration 657 : loss : 0.075021, loss_ce: 0.032155
2022-01-13 23:36:38,270 iteration 658 : loss : 0.179510, loss_ce: 0.064597
2022-01-13 23:36:39,734 iteration 659 : loss : 0.114509, loss_ce: 0.052210
2022-01-13 23:36:41,160 iteration 660 : loss : 0.115887, loss_ce: 0.043296
2022-01-13 23:36:42,594 iteration 661 : loss : 0.091921, loss_ce: 0.040326
2022-01-13 23:36:43,964 iteration 662 : loss : 0.075509, loss_ce: 0.036252
2022-01-13 23:36:45,362 iteration 663 : loss : 0.104823, loss_ce: 0.037131
 10%|██▉                           | 39/400 [16:58<2:30:19, 24.98s/it]2022-01-13 23:36:46,792 iteration 664 : loss : 0.100339, loss_ce: 0.048620
2022-01-13 23:36:48,172 iteration 665 : loss : 0.097637, loss_ce: 0.043065
2022-01-13 23:36:49,583 iteration 666 : loss : 0.087324, loss_ce: 0.034067
2022-01-13 23:36:50,939 iteration 667 : loss : 0.077225, loss_ce: 0.034612
2022-01-13 23:36:52,384 iteration 668 : loss : 0.093511, loss_ce: 0.039632
2022-01-13 23:36:53,744 iteration 669 : loss : 0.104542, loss_ce: 0.049496
2022-01-13 23:36:55,121 iteration 670 : loss : 0.096515, loss_ce: 0.045288
2022-01-13 23:36:56,560 iteration 671 : loss : 0.081093, loss_ce: 0.028726
2022-01-13 23:36:58,022 iteration 672 : loss : 0.078541, loss_ce: 0.031215
2022-01-13 23:36:59,370 iteration 673 : loss : 0.092598, loss_ce: 0.042993
2022-01-13 23:37:00,788 iteration 674 : loss : 0.096855, loss_ce: 0.042152
2022-01-13 23:37:02,243 iteration 675 : loss : 0.084707, loss_ce: 0.030227
2022-01-13 23:37:03,618 iteration 676 : loss : 0.107743, loss_ce: 0.036335
2022-01-13 23:37:05,027 iteration 677 : loss : 0.103595, loss_ce: 0.047171
2022-01-13 23:37:06,430 iteration 678 : loss : 0.078008, loss_ce: 0.030452
2022-01-13 23:37:07,778 iteration 679 : loss : 0.134126, loss_ce: 0.075066
2022-01-13 23:37:07,778 Training Data Eval:
2022-01-13 23:37:14,891   Average segmentation loss on training set: 0.0665
2022-01-13 23:37:14,891 Validation Data Eval:
2022-01-13 23:37:17,352   Average segmentation loss on validation set: 0.1405
2022-01-13 23:37:18,814 iteration 680 : loss : 0.169888, loss_ce: 0.042429
 10%|███                           | 40/400 [17:32<2:45:07, 27.52s/it]2022-01-13 23:37:20,342 iteration 681 : loss : 0.102595, loss_ce: 0.044228
2022-01-13 23:37:21,738 iteration 682 : loss : 0.072000, loss_ce: 0.025313
2022-01-13 23:37:23,177 iteration 683 : loss : 0.081592, loss_ce: 0.035191
2022-01-13 23:37:24,614 iteration 684 : loss : 0.097073, loss_ce: 0.038340
2022-01-13 23:37:26,094 iteration 685 : loss : 0.082727, loss_ce: 0.032882
2022-01-13 23:37:27,412 iteration 686 : loss : 0.084589, loss_ce: 0.029323
2022-01-13 23:37:28,785 iteration 687 : loss : 0.073135, loss_ce: 0.026296
2022-01-13 23:37:30,263 iteration 688 : loss : 0.114236, loss_ce: 0.047528
2022-01-13 23:37:31,668 iteration 689 : loss : 0.082839, loss_ce: 0.045799
2022-01-13 23:37:33,025 iteration 690 : loss : 0.104777, loss_ce: 0.056399
2022-01-13 23:37:34,506 iteration 691 : loss : 0.090411, loss_ce: 0.038787
2022-01-13 23:37:35,962 iteration 692 : loss : 0.115770, loss_ce: 0.039105
2022-01-13 23:37:37,425 iteration 693 : loss : 0.114477, loss_ce: 0.048101
2022-01-13 23:37:38,830 iteration 694 : loss : 0.084113, loss_ce: 0.032088
2022-01-13 23:37:40,234 iteration 695 : loss : 0.103389, loss_ce: 0.035421
2022-01-13 23:37:41,655 iteration 696 : loss : 0.087619, loss_ce: 0.035519
2022-01-13 23:37:43,072 iteration 697 : loss : 0.133315, loss_ce: 0.050871
 10%|███                           | 41/400 [17:56<2:38:49, 26.54s/it]2022-01-13 23:37:44,527 iteration 698 : loss : 0.099610, loss_ce: 0.034796
2022-01-13 23:37:45,946 iteration 699 : loss : 0.071273, loss_ce: 0.023979
2022-01-13 23:37:47,360 iteration 700 : loss : 0.098508, loss_ce: 0.035945
2022-01-13 23:37:48,761 iteration 701 : loss : 0.121639, loss_ce: 0.046722
2022-01-13 23:37:50,202 iteration 702 : loss : 0.091487, loss_ce: 0.030742
2022-01-13 23:37:51,592 iteration 703 : loss : 0.091373, loss_ce: 0.034353
2022-01-13 23:37:52,989 iteration 704 : loss : 0.126873, loss_ce: 0.041640
2022-01-13 23:37:54,356 iteration 705 : loss : 0.115133, loss_ce: 0.057974
2022-01-13 23:37:55,808 iteration 706 : loss : 0.063802, loss_ce: 0.029414
2022-01-13 23:37:57,254 iteration 707 : loss : 0.126118, loss_ce: 0.072298
2022-01-13 23:37:58,663 iteration 708 : loss : 0.101496, loss_ce: 0.044131
2022-01-13 23:38:00,090 iteration 709 : loss : 0.092190, loss_ce: 0.040120
2022-01-13 23:38:01,518 iteration 710 : loss : 0.122901, loss_ce: 0.040762
2022-01-13 23:38:02,961 iteration 711 : loss : 0.182422, loss_ce: 0.068133
2022-01-13 23:38:04,423 iteration 712 : loss : 0.086793, loss_ce: 0.044166
2022-01-13 23:38:05,788 iteration 713 : loss : 0.103966, loss_ce: 0.051959
2022-01-13 23:38:07,175 iteration 714 : loss : 0.072765, loss_ce: 0.033965
 10%|███▏                          | 42/400 [18:20<2:34:01, 25.81s/it]2022-01-13 23:38:08,622 iteration 715 : loss : 0.088249, loss_ce: 0.040444
2022-01-13 23:38:10,024 iteration 716 : loss : 0.178850, loss_ce: 0.065636
2022-01-13 23:38:11,399 iteration 717 : loss : 0.112557, loss_ce: 0.049307
2022-01-13 23:38:12,702 iteration 718 : loss : 0.087128, loss_ce: 0.038004
2022-01-13 23:38:14,123 iteration 719 : loss : 0.104962, loss_ce: 0.054223
2022-01-13 23:38:15,482 iteration 720 : loss : 0.089673, loss_ce: 0.040844
2022-01-13 23:38:17,026 iteration 721 : loss : 0.119222, loss_ce: 0.048909
2022-01-13 23:38:18,441 iteration 722 : loss : 0.061875, loss_ce: 0.028349
2022-01-13 23:38:19,866 iteration 723 : loss : 0.103249, loss_ce: 0.038959
2022-01-13 23:38:21,365 iteration 724 : loss : 0.100615, loss_ce: 0.043653
2022-01-13 23:38:22,726 iteration 725 : loss : 0.070683, loss_ce: 0.032078
2022-01-13 23:38:24,150 iteration 726 : loss : 0.114102, loss_ce: 0.063611
2022-01-13 23:38:25,536 iteration 727 : loss : 0.051407, loss_ce: 0.021629
2022-01-13 23:38:26,925 iteration 728 : loss : 0.090379, loss_ce: 0.027421
2022-01-13 23:38:28,323 iteration 729 : loss : 0.148392, loss_ce: 0.065463
2022-01-13 23:38:29,767 iteration 730 : loss : 0.091395, loss_ce: 0.031246
2022-01-13 23:38:31,148 iteration 731 : loss : 0.125656, loss_ce: 0.044063
 11%|███▏                          | 43/400 [18:44<2:30:17, 25.26s/it]2022-01-13 23:38:32,673 iteration 732 : loss : 0.081786, loss_ce: 0.031160
2022-01-13 23:38:34,101 iteration 733 : loss : 0.085619, loss_ce: 0.035123
2022-01-13 23:38:35,521 iteration 734 : loss : 0.145602, loss_ce: 0.068796
2022-01-13 23:38:36,974 iteration 735 : loss : 0.111876, loss_ce: 0.040978
2022-01-13 23:38:38,399 iteration 736 : loss : 0.080595, loss_ce: 0.031415
2022-01-13 23:38:39,741 iteration 737 : loss : 0.069562, loss_ce: 0.026717
2022-01-13 23:38:41,218 iteration 738 : loss : 0.090740, loss_ce: 0.035844
2022-01-13 23:38:42,637 iteration 739 : loss : 0.117741, loss_ce: 0.063374
2022-01-13 23:38:44,028 iteration 740 : loss : 0.074979, loss_ce: 0.024765
2022-01-13 23:38:45,471 iteration 741 : loss : 0.083725, loss_ce: 0.038434
2022-01-13 23:38:46,903 iteration 742 : loss : 0.075145, loss_ce: 0.029820
2022-01-13 23:38:48,285 iteration 743 : loss : 0.096119, loss_ce: 0.031764
2022-01-13 23:38:49,721 iteration 744 : loss : 0.068509, loss_ce: 0.029001
2022-01-13 23:38:51,124 iteration 745 : loss : 0.096020, loss_ce: 0.033157
2022-01-13 23:38:52,498 iteration 746 : loss : 0.151858, loss_ce: 0.048471
2022-01-13 23:38:53,908 iteration 747 : loss : 0.091697, loss_ce: 0.041342
2022-01-13 23:38:55,323 iteration 748 : loss : 0.096784, loss_ce: 0.037864
 11%|███▎                          | 44/400 [19:08<2:27:55, 24.93s/it]2022-01-13 23:38:56,751 iteration 749 : loss : 0.125890, loss_ce: 0.040943
2022-01-13 23:38:58,140 iteration 750 : loss : 0.057922, loss_ce: 0.019104
2022-01-13 23:38:59,576 iteration 751 : loss : 0.089828, loss_ce: 0.035991
2022-01-13 23:39:00,944 iteration 752 : loss : 0.098583, loss_ce: 0.041141
2022-01-13 23:39:02,394 iteration 753 : loss : 0.071355, loss_ce: 0.027782
2022-01-13 23:39:03,787 iteration 754 : loss : 0.053323, loss_ce: 0.019790
2022-01-13 23:39:05,195 iteration 755 : loss : 0.075540, loss_ce: 0.032795
2022-01-13 23:39:06,514 iteration 756 : loss : 0.093887, loss_ce: 0.037842
2022-01-13 23:39:07,846 iteration 757 : loss : 0.074744, loss_ce: 0.028379
2022-01-13 23:39:09,244 iteration 758 : loss : 0.106824, loss_ce: 0.042625
2022-01-13 23:39:10,687 iteration 759 : loss : 0.106282, loss_ce: 0.048002
2022-01-13 23:39:12,105 iteration 760 : loss : 0.095477, loss_ce: 0.031290
2022-01-13 23:39:13,550 iteration 761 : loss : 0.100750, loss_ce: 0.044273
2022-01-13 23:39:14,886 iteration 762 : loss : 0.091169, loss_ce: 0.041516
2022-01-13 23:39:16,306 iteration 763 : loss : 0.101822, loss_ce: 0.046168
2022-01-13 23:39:17,661 iteration 764 : loss : 0.092481, loss_ce: 0.034784
2022-01-13 23:39:17,662 Training Data Eval:
2022-01-13 23:39:24,841   Average segmentation loss on training set: 0.0686
2022-01-13 23:39:24,842 Validation Data Eval:
2022-01-13 23:39:27,311   Average segmentation loss on validation set: 0.1247
2022-01-13 23:39:28,651 iteration 765 : loss : 0.069343, loss_ce: 0.029076
 11%|███▍                          | 45/400 [19:42<2:42:25, 27.45s/it]2022-01-13 23:39:30,179 iteration 766 : loss : 0.102658, loss_ce: 0.039485
2022-01-13 23:39:31,737 iteration 767 : loss : 0.132213, loss_ce: 0.059733
2022-01-13 23:39:33,165 iteration 768 : loss : 0.095827, loss_ce: 0.036795
2022-01-13 23:39:34,615 iteration 769 : loss : 0.091495, loss_ce: 0.043814
2022-01-13 23:39:36,082 iteration 770 : loss : 0.106343, loss_ce: 0.056436
2022-01-13 23:39:37,504 iteration 771 : loss : 0.064263, loss_ce: 0.033319
2022-01-13 23:39:38,854 iteration 772 : loss : 0.105304, loss_ce: 0.049920
2022-01-13 23:39:40,251 iteration 773 : loss : 0.125170, loss_ce: 0.045650
2022-01-13 23:39:41,716 iteration 774 : loss : 0.103941, loss_ce: 0.048371
2022-01-13 23:39:43,070 iteration 775 : loss : 0.059117, loss_ce: 0.024691
2022-01-13 23:39:44,446 iteration 776 : loss : 0.129661, loss_ce: 0.039144
2022-01-13 23:39:45,960 iteration 777 : loss : 0.074633, loss_ce: 0.035046
2022-01-13 23:39:47,370 iteration 778 : loss : 0.072739, loss_ce: 0.030894
2022-01-13 23:39:48,763 iteration 779 : loss : 0.119723, loss_ce: 0.043681
2022-01-13 23:39:50,259 iteration 780 : loss : 0.117404, loss_ce: 0.050574
2022-01-13 23:39:51,727 iteration 781 : loss : 0.063330, loss_ce: 0.022442
2022-01-13 23:39:53,120 iteration 782 : loss : 0.073302, loss_ce: 0.027181
 12%|███▍                          | 46/400 [20:06<2:36:41, 26.56s/it]2022-01-13 23:39:54,570 iteration 783 : loss : 0.081832, loss_ce: 0.030060
2022-01-13 23:39:55,923 iteration 784 : loss : 0.060966, loss_ce: 0.023240
2022-01-13 23:39:57,410 iteration 785 : loss : 0.092249, loss_ce: 0.029547
2022-01-13 23:39:58,825 iteration 786 : loss : 0.083812, loss_ce: 0.034871
2022-01-13 23:40:00,293 iteration 787 : loss : 0.144554, loss_ce: 0.067617
2022-01-13 23:40:01,679 iteration 788 : loss : 0.084429, loss_ce: 0.039065
2022-01-13 23:40:03,161 iteration 789 : loss : 0.095501, loss_ce: 0.036073
2022-01-13 23:40:04,629 iteration 790 : loss : 0.057210, loss_ce: 0.022348
2022-01-13 23:40:05,992 iteration 791 : loss : 0.071314, loss_ce: 0.036897
2022-01-13 23:40:07,491 iteration 792 : loss : 0.082706, loss_ce: 0.033198
2022-01-13 23:40:08,929 iteration 793 : loss : 0.097976, loss_ce: 0.035392
2022-01-13 23:40:10,385 iteration 794 : loss : 0.071360, loss_ce: 0.029115
2022-01-13 23:40:11,839 iteration 795 : loss : 0.090288, loss_ce: 0.038093
2022-01-13 23:40:13,325 iteration 796 : loss : 0.082045, loss_ce: 0.031684
2022-01-13 23:40:14,732 iteration 797 : loss : 0.065929, loss_ce: 0.029388
2022-01-13 23:40:16,153 iteration 798 : loss : 0.078034, loss_ce: 0.035903
2022-01-13 23:40:17,670 iteration 799 : loss : 0.131902, loss_ce: 0.046980
 12%|███▌                          | 47/400 [20:31<2:32:41, 25.95s/it]2022-01-13 23:40:19,169 iteration 800 : loss : 0.114719, loss_ce: 0.055512
2022-01-13 23:40:20,576 iteration 801 : loss : 0.094569, loss_ce: 0.028170
2022-01-13 23:40:22,040 iteration 802 : loss : 0.096774, loss_ce: 0.048492
2022-01-13 23:40:23,401 iteration 803 : loss : 0.065946, loss_ce: 0.027119
2022-01-13 23:40:24,938 iteration 804 : loss : 0.126268, loss_ce: 0.043671
2022-01-13 23:40:26,359 iteration 805 : loss : 0.085891, loss_ce: 0.038724
2022-01-13 23:40:27,707 iteration 806 : loss : 0.080589, loss_ce: 0.031197
2022-01-13 23:40:29,109 iteration 807 : loss : 0.053667, loss_ce: 0.026572
2022-01-13 23:40:30,529 iteration 808 : loss : 0.136541, loss_ce: 0.046108
2022-01-13 23:40:32,010 iteration 809 : loss : 0.071929, loss_ce: 0.030419
2022-01-13 23:40:33,367 iteration 810 : loss : 0.075978, loss_ce: 0.029302
2022-01-13 23:40:34,790 iteration 811 : loss : 0.104846, loss_ce: 0.050094
2022-01-13 23:40:36,145 iteration 812 : loss : 0.123727, loss_ce: 0.059980
2022-01-13 23:40:37,631 iteration 813 : loss : 0.078357, loss_ce: 0.033244
2022-01-13 23:40:39,157 iteration 814 : loss : 0.186087, loss_ce: 0.050823
2022-01-13 23:40:40,461 iteration 815 : loss : 0.064602, loss_ce: 0.029726
2022-01-13 23:40:41,955 iteration 816 : loss : 0.117733, loss_ce: 0.046091
 12%|███▌                          | 48/400 [20:55<2:29:19, 25.45s/it]2022-01-13 23:40:43,404 iteration 817 : loss : 0.073910, loss_ce: 0.027980
2022-01-13 23:40:44,801 iteration 818 : loss : 0.073908, loss_ce: 0.033732
2022-01-13 23:40:46,352 iteration 819 : loss : 0.098999, loss_ce: 0.048270
2022-01-13 23:40:47,850 iteration 820 : loss : 0.096733, loss_ce: 0.037428
2022-01-13 23:40:49,301 iteration 821 : loss : 0.102447, loss_ce: 0.040449
2022-01-13 23:40:50,716 iteration 822 : loss : 0.076500, loss_ce: 0.032437
2022-01-13 23:40:52,175 iteration 823 : loss : 0.064345, loss_ce: 0.025852
2022-01-13 23:40:53,537 iteration 824 : loss : 0.084379, loss_ce: 0.029551
2022-01-13 23:40:54,954 iteration 825 : loss : 0.132907, loss_ce: 0.039799
2022-01-13 23:40:56,305 iteration 826 : loss : 0.085703, loss_ce: 0.033328
2022-01-13 23:40:57,735 iteration 827 : loss : 0.105557, loss_ce: 0.041593
2022-01-13 23:40:59,087 iteration 828 : loss : 0.106284, loss_ce: 0.041241
2022-01-13 23:41:00,576 iteration 829 : loss : 0.100582, loss_ce: 0.046780
2022-01-13 23:41:01,959 iteration 830 : loss : 0.119003, loss_ce: 0.056865
2022-01-13 23:41:03,411 iteration 831 : loss : 0.113036, loss_ce: 0.060989
2022-01-13 23:41:04,855 iteration 832 : loss : 0.100268, loss_ce: 0.027001
2022-01-13 23:41:06,269 iteration 833 : loss : 0.085874, loss_ce: 0.036778
 12%|███▋                          | 49/400 [21:19<2:26:53, 25.11s/it]2022-01-13 23:41:07,661 iteration 834 : loss : 0.106915, loss_ce: 0.040800
2022-01-13 23:41:08,989 iteration 835 : loss : 0.083347, loss_ce: 0.026492
2022-01-13 23:41:10,468 iteration 836 : loss : 0.129782, loss_ce: 0.044615
2022-01-13 23:41:11,841 iteration 837 : loss : 0.076006, loss_ce: 0.030384
2022-01-13 23:41:13,267 iteration 838 : loss : 0.116638, loss_ce: 0.059452
2022-01-13 23:41:14,585 iteration 839 : loss : 0.064941, loss_ce: 0.025203
2022-01-13 23:41:15,916 iteration 840 : loss : 0.062615, loss_ce: 0.028696
2022-01-13 23:41:17,271 iteration 841 : loss : 0.111880, loss_ce: 0.044519
2022-01-13 23:41:18,756 iteration 842 : loss : 0.155363, loss_ce: 0.060036
2022-01-13 23:41:20,112 iteration 843 : loss : 0.102092, loss_ce: 0.037023
2022-01-13 23:41:21,558 iteration 844 : loss : 0.077178, loss_ce: 0.031583
2022-01-13 23:41:22,950 iteration 845 : loss : 0.096946, loss_ce: 0.049805
2022-01-13 23:41:24,332 iteration 846 : loss : 0.094121, loss_ce: 0.051147
2022-01-13 23:41:25,795 iteration 847 : loss : 0.128074, loss_ce: 0.043216
2022-01-13 23:41:27,189 iteration 848 : loss : 0.078650, loss_ce: 0.032054
2022-01-13 23:41:28,569 iteration 849 : loss : 0.070575, loss_ce: 0.026321
2022-01-13 23:41:28,569 Training Data Eval:
2022-01-13 23:41:35,633   Average segmentation loss on training set: 0.0964
2022-01-13 23:41:35,634 Validation Data Eval:
2022-01-13 23:41:38,182   Average segmentation loss on validation set: 0.1283
2022-01-13 23:41:39,593 iteration 850 : loss : 0.103761, loss_ce: 0.053973
 12%|███▊                          | 50/400 [21:53<2:40:51, 27.57s/it]2022-01-13 23:41:41,102 iteration 851 : loss : 0.103372, loss_ce: 0.043636
2022-01-13 23:41:42,516 iteration 852 : loss : 0.095795, loss_ce: 0.034256
2022-01-13 23:41:43,942 iteration 853 : loss : 0.076181, loss_ce: 0.026773
2022-01-13 23:41:45,390 iteration 854 : loss : 0.114754, loss_ce: 0.056401
2022-01-13 23:41:46,792 iteration 855 : loss : 0.093876, loss_ce: 0.050538
2022-01-13 23:41:48,256 iteration 856 : loss : 0.104614, loss_ce: 0.047307
2022-01-13 23:41:49,655 iteration 857 : loss : 0.104926, loss_ce: 0.044805
2022-01-13 23:41:51,149 iteration 858 : loss : 0.051618, loss_ce: 0.019183
2022-01-13 23:41:52,435 iteration 859 : loss : 0.073477, loss_ce: 0.022166
2022-01-13 23:41:53,842 iteration 860 : loss : 0.092669, loss_ce: 0.037735
2022-01-13 23:41:55,251 iteration 861 : loss : 0.079992, loss_ce: 0.022660
2022-01-13 23:41:56,668 iteration 862 : loss : 0.111105, loss_ce: 0.053972
2022-01-13 23:41:58,052 iteration 863 : loss : 0.150472, loss_ce: 0.056164
2022-01-13 23:41:59,429 iteration 864 : loss : 0.093085, loss_ce: 0.043252
2022-01-13 23:42:00,847 iteration 865 : loss : 0.083822, loss_ce: 0.030636
2022-01-13 23:42:02,214 iteration 866 : loss : 0.066977, loss_ce: 0.030456
2022-01-13 23:42:03,635 iteration 867 : loss : 0.073532, loss_ce: 0.031262
 13%|███▊                          | 51/400 [22:17<2:34:13, 26.52s/it]2022-01-13 23:42:05,084 iteration 868 : loss : 0.078959, loss_ce: 0.034087
2022-01-13 23:42:06,536 iteration 869 : loss : 0.101642, loss_ce: 0.040946
2022-01-13 23:42:07,880 iteration 870 : loss : 0.079766, loss_ce: 0.038656
2022-01-13 23:42:09,245 iteration 871 : loss : 0.079812, loss_ce: 0.043001
2022-01-13 23:42:10,613 iteration 872 : loss : 0.088422, loss_ce: 0.039042
2022-01-13 23:42:12,041 iteration 873 : loss : 0.107434, loss_ce: 0.051345
2022-01-13 23:42:13,445 iteration 874 : loss : 0.077815, loss_ce: 0.033329
2022-01-13 23:42:14,846 iteration 875 : loss : 0.101763, loss_ce: 0.041451
2022-01-13 23:42:16,259 iteration 876 : loss : 0.062419, loss_ce: 0.025049
2022-01-13 23:42:17,732 iteration 877 : loss : 0.093740, loss_ce: 0.037116
2022-01-13 23:42:19,084 iteration 878 : loss : 0.191430, loss_ce: 0.058529
2022-01-13 23:42:20,467 iteration 879 : loss : 0.156990, loss_ce: 0.048104
2022-01-13 23:42:21,826 iteration 880 : loss : 0.070789, loss_ce: 0.031301
2022-01-13 23:42:23,287 iteration 881 : loss : 0.076836, loss_ce: 0.026070
2022-01-13 23:42:24,705 iteration 882 : loss : 0.084500, loss_ce: 0.029882
2022-01-13 23:42:26,078 iteration 883 : loss : 0.074742, loss_ce: 0.024609
2022-01-13 23:42:27,519 iteration 884 : loss : 0.073252, loss_ce: 0.029071
 13%|███▉                          | 52/400 [22:40<2:29:12, 25.73s/it]2022-01-13 23:42:28,982 iteration 885 : loss : 0.085403, loss_ce: 0.039401
2022-01-13 23:42:30,391 iteration 886 : loss : 0.087023, loss_ce: 0.038597
2022-01-13 23:42:31,798 iteration 887 : loss : 0.122804, loss_ce: 0.050415
2022-01-13 23:42:33,207 iteration 888 : loss : 0.113679, loss_ce: 0.044830
2022-01-13 23:42:34,608 iteration 889 : loss : 0.173561, loss_ce: 0.046709
2022-01-13 23:42:35,983 iteration 890 : loss : 0.090644, loss_ce: 0.034230
2022-01-13 23:42:37,396 iteration 891 : loss : 0.093236, loss_ce: 0.056554
2022-01-13 23:42:38,788 iteration 892 : loss : 0.068317, loss_ce: 0.028878
2022-01-13 23:42:40,168 iteration 893 : loss : 0.055096, loss_ce: 0.024729
2022-01-13 23:42:41,549 iteration 894 : loss : 0.069751, loss_ce: 0.022271
2022-01-13 23:42:42,935 iteration 895 : loss : 0.109644, loss_ce: 0.047712
2022-01-13 23:42:44,289 iteration 896 : loss : 0.108678, loss_ce: 0.047010
2022-01-13 23:42:45,817 iteration 897 : loss : 0.117206, loss_ce: 0.042944
2022-01-13 23:42:47,200 iteration 898 : loss : 0.087766, loss_ce: 0.031470
2022-01-13 23:42:48,649 iteration 899 : loss : 0.081513, loss_ce: 0.027015
2022-01-13 23:42:50,077 iteration 900 : loss : 0.093260, loss_ce: 0.036217
2022-01-13 23:42:51,452 iteration 901 : loss : 0.110810, loss_ce: 0.047312
 13%|███▉                          | 53/400 [23:04<2:25:46, 25.20s/it]2022-01-13 23:42:53,013 iteration 902 : loss : 0.111098, loss_ce: 0.056333
2022-01-13 23:42:54,443 iteration 903 : loss : 0.106043, loss_ce: 0.030268
2022-01-13 23:42:55,836 iteration 904 : loss : 0.099114, loss_ce: 0.041577
2022-01-13 23:42:57,208 iteration 905 : loss : 0.095874, loss_ce: 0.041830
2022-01-13 23:42:58,702 iteration 906 : loss : 0.109241, loss_ce: 0.042674
2022-01-13 23:43:00,067 iteration 907 : loss : 0.066731, loss_ce: 0.028211
2022-01-13 23:43:01,427 iteration 908 : loss : 0.073500, loss_ce: 0.036882
2022-01-13 23:43:02,857 iteration 909 : loss : 0.091398, loss_ce: 0.038485
2022-01-13 23:43:04,326 iteration 910 : loss : 0.095359, loss_ce: 0.040666
2022-01-13 23:43:05,711 iteration 911 : loss : 0.073915, loss_ce: 0.030511
2022-01-13 23:43:07,169 iteration 912 : loss : 0.080804, loss_ce: 0.031437
2022-01-13 23:43:08,561 iteration 913 : loss : 0.101706, loss_ce: 0.039578
2022-01-13 23:43:09,896 iteration 914 : loss : 0.093892, loss_ce: 0.038084
2022-01-13 23:43:11,297 iteration 915 : loss : 0.094715, loss_ce: 0.033488
2022-01-13 23:43:12,751 iteration 916 : loss : 0.084413, loss_ce: 0.029161
2022-01-13 23:43:14,191 iteration 917 : loss : 0.101851, loss_ce: 0.037587
2022-01-13 23:43:15,662 iteration 918 : loss : 0.116349, loss_ce: 0.034846
 14%|████                          | 54/400 [23:29<2:23:33, 24.89s/it]2022-01-13 23:43:17,102 iteration 919 : loss : 0.075282, loss_ce: 0.026924
2022-01-13 23:43:18,557 iteration 920 : loss : 0.072755, loss_ce: 0.033917
2022-01-13 23:43:19,894 iteration 921 : loss : 0.070477, loss_ce: 0.028330
2022-01-13 23:43:21,326 iteration 922 : loss : 0.097346, loss_ce: 0.034240
2022-01-13 23:43:22,665 iteration 923 : loss : 0.057730, loss_ce: 0.022612
2022-01-13 23:43:24,088 iteration 924 : loss : 0.130260, loss_ce: 0.045706
2022-01-13 23:43:25,534 iteration 925 : loss : 0.086112, loss_ce: 0.027256
2022-01-13 23:43:26,949 iteration 926 : loss : 0.062038, loss_ce: 0.023041
2022-01-13 23:43:28,280 iteration 927 : loss : 0.110156, loss_ce: 0.029488
2022-01-13 23:43:29,770 iteration 928 : loss : 0.075195, loss_ce: 0.034601
2022-01-13 23:43:31,158 iteration 929 : loss : 0.052312, loss_ce: 0.020828
2022-01-13 23:43:32,516 iteration 930 : loss : 0.061527, loss_ce: 0.022769
2022-01-13 23:43:33,915 iteration 931 : loss : 0.148230, loss_ce: 0.092781
2022-01-13 23:43:35,332 iteration 932 : loss : 0.091433, loss_ce: 0.047691
2022-01-13 23:43:36,775 iteration 933 : loss : 0.070496, loss_ce: 0.035467
2022-01-13 23:43:38,147 iteration 934 : loss : 0.059166, loss_ce: 0.021252
2022-01-13 23:43:38,148 Training Data Eval:
2022-01-13 23:43:45,253   Average segmentation loss on training set: 0.0514
2022-01-13 23:43:45,253 Validation Data Eval:
2022-01-13 23:43:47,712   Average segmentation loss on validation set: 0.0837
2022-01-13 23:43:53,502 Found new lowest validation loss at iteration 934! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_1HEAD_best_val_loss_seed2.pth
2022-01-13 23:43:54,953 iteration 935 : loss : 0.079888, loss_ce: 0.031981
 14%|████▏                         | 55/400 [24:08<2:47:57, 29.21s/it]2022-01-13 23:43:56,405 iteration 936 : loss : 0.058343, loss_ce: 0.026548
2022-01-13 23:43:57,792 iteration 937 : loss : 0.108220, loss_ce: 0.040056
2022-01-13 23:43:59,199 iteration 938 : loss : 0.068313, loss_ce: 0.035357
2022-01-13 23:44:00,680 iteration 939 : loss : 0.095270, loss_ce: 0.027311
2022-01-13 23:44:02,015 iteration 940 : loss : 0.096826, loss_ce: 0.037733
2022-01-13 23:44:03,373 iteration 941 : loss : 0.078539, loss_ce: 0.027723
2022-01-13 23:44:04,754 iteration 942 : loss : 0.087111, loss_ce: 0.038470
2022-01-13 23:44:06,185 iteration 943 : loss : 0.146809, loss_ce: 0.055266
2022-01-13 23:44:07,577 iteration 944 : loss : 0.131279, loss_ce: 0.056029
2022-01-13 23:44:09,000 iteration 945 : loss : 0.084604, loss_ce: 0.037002
2022-01-13 23:44:10,394 iteration 946 : loss : 0.061076, loss_ce: 0.025464
2022-01-13 23:44:11,788 iteration 947 : loss : 0.068641, loss_ce: 0.025032
2022-01-13 23:44:13,264 iteration 948 : loss : 0.116962, loss_ce: 0.047245
2022-01-13 23:44:14,720 iteration 949 : loss : 0.093698, loss_ce: 0.039890
2022-01-13 23:44:16,202 iteration 950 : loss : 0.088329, loss_ce: 0.032429
2022-01-13 23:44:17,579 iteration 951 : loss : 0.062859, loss_ce: 0.026795
2022-01-13 23:44:19,010 iteration 952 : loss : 0.078445, loss_ce: 0.027658
 14%|████▏                         | 56/400 [24:32<2:38:36, 27.67s/it]2022-01-13 23:44:20,443 iteration 953 : loss : 0.094403, loss_ce: 0.037990
2022-01-13 23:44:21,819 iteration 954 : loss : 0.050297, loss_ce: 0.018827
2022-01-13 23:44:23,238 iteration 955 : loss : 0.087049, loss_ce: 0.029074
2022-01-13 23:44:24,674 iteration 956 : loss : 0.054552, loss_ce: 0.018490
2022-01-13 23:44:26,070 iteration 957 : loss : 0.071423, loss_ce: 0.032071
2022-01-13 23:44:27,488 iteration 958 : loss : 0.078042, loss_ce: 0.034561
2022-01-13 23:44:28,962 iteration 959 : loss : 0.088847, loss_ce: 0.041675
2022-01-13 23:44:30,386 iteration 960 : loss : 0.084311, loss_ce: 0.037864
2022-01-13 23:44:31,793 iteration 961 : loss : 0.086044, loss_ce: 0.035731
2022-01-13 23:44:33,236 iteration 962 : loss : 0.090622, loss_ce: 0.028503
2022-01-13 23:44:34,578 iteration 963 : loss : 0.057359, loss_ce: 0.026145
2022-01-13 23:44:35,991 iteration 964 : loss : 0.086497, loss_ce: 0.028026
2022-01-13 23:44:37,370 iteration 965 : loss : 0.047858, loss_ce: 0.016737
2022-01-13 23:44:38,844 iteration 966 : loss : 0.079021, loss_ce: 0.025600
2022-01-13 23:44:40,272 iteration 967 : loss : 0.072554, loss_ce: 0.031884
2022-01-13 23:44:41,651 iteration 968 : loss : 0.060322, loss_ce: 0.024754
2022-01-13 23:44:43,102 iteration 969 : loss : 0.058988, loss_ce: 0.031545
 14%|████▎                         | 57/400 [24:56<2:32:00, 26.59s/it]2022-01-13 23:44:44,561 iteration 970 : loss : 0.089644, loss_ce: 0.048089
2022-01-13 23:44:46,016 iteration 971 : loss : 0.075104, loss_ce: 0.034062
2022-01-13 23:44:47,434 iteration 972 : loss : 0.075358, loss_ce: 0.029581
2022-01-13 23:44:48,880 iteration 973 : loss : 0.062624, loss_ce: 0.025910
2022-01-13 23:44:50,296 iteration 974 : loss : 0.103565, loss_ce: 0.045073
2022-01-13 23:44:51,660 iteration 975 : loss : 0.077326, loss_ce: 0.025154
2022-01-13 23:44:53,131 iteration 976 : loss : 0.096691, loss_ce: 0.050341
2022-01-13 23:44:54,521 iteration 977 : loss : 0.076662, loss_ce: 0.033158
2022-01-13 23:44:55,938 iteration 978 : loss : 0.054350, loss_ce: 0.020678
2022-01-13 23:44:57,309 iteration 979 : loss : 0.061522, loss_ce: 0.026404
2022-01-13 23:44:58,692 iteration 980 : loss : 0.069902, loss_ce: 0.024268
2022-01-13 23:45:00,052 iteration 981 : loss : 0.038571, loss_ce: 0.013707
2022-01-13 23:45:01,472 iteration 982 : loss : 0.097718, loss_ce: 0.037137
2022-01-13 23:45:02,980 iteration 983 : loss : 0.105872, loss_ce: 0.041705
2022-01-13 23:45:04,453 iteration 984 : loss : 0.068396, loss_ce: 0.032576
2022-01-13 23:45:05,880 iteration 985 : loss : 0.075513, loss_ce: 0.028945
2022-01-13 23:45:07,253 iteration 986 : loss : 0.048280, loss_ce: 0.015375
 14%|████▎                         | 58/400 [25:20<2:27:24, 25.86s/it]2022-01-13 23:45:08,623 iteration 987 : loss : 0.061194, loss_ce: 0.021988
2022-01-13 23:45:10,016 iteration 988 : loss : 0.083998, loss_ce: 0.035525
2022-01-13 23:45:11,427 iteration 989 : loss : 0.053892, loss_ce: 0.019708
2022-01-13 23:45:12,835 iteration 990 : loss : 0.065810, loss_ce: 0.022294
2022-01-13 23:45:14,253 iteration 991 : loss : 0.075599, loss_ce: 0.031947
2022-01-13 23:45:15,652 iteration 992 : loss : 0.084210, loss_ce: 0.035751
2022-01-13 23:45:17,005 iteration 993 : loss : 0.079871, loss_ce: 0.027088
2022-01-13 23:45:18,321 iteration 994 : loss : 0.074696, loss_ce: 0.026869
2022-01-13 23:45:19,827 iteration 995 : loss : 0.122567, loss_ce: 0.052404
2022-01-13 23:45:21,259 iteration 996 : loss : 0.071333, loss_ce: 0.037558
2022-01-13 23:45:22,722 iteration 997 : loss : 0.107794, loss_ce: 0.044330
2022-01-13 23:45:24,172 iteration 998 : loss : 0.075609, loss_ce: 0.030033
2022-01-13 23:45:25,544 iteration 999 : loss : 0.085672, loss_ce: 0.036679
2022-01-13 23:45:27,015 iteration 1000 : loss : 0.079365, loss_ce: 0.042517
2022-01-13 23:45:28,391 iteration 1001 : loss : 0.046546, loss_ce: 0.020682
2022-01-13 23:45:29,844 iteration 1002 : loss : 0.089320, loss_ce: 0.038917
2022-01-13 23:45:31,205 iteration 1003 : loss : 0.110796, loss_ce: 0.031505
 15%|████▍                         | 59/400 [25:44<2:23:42, 25.29s/it]2022-01-13 23:45:32,667 iteration 1004 : loss : 0.069319, loss_ce: 0.024399
2022-01-13 23:45:34,070 iteration 1005 : loss : 0.094623, loss_ce: 0.048083
2022-01-13 23:45:35,581 iteration 1006 : loss : 0.080629, loss_ce: 0.039663
2022-01-13 23:45:37,034 iteration 1007 : loss : 0.091711, loss_ce: 0.042213
2022-01-13 23:45:38,515 iteration 1008 : loss : 0.080499, loss_ce: 0.043405
2022-01-13 23:45:39,919 iteration 1009 : loss : 0.081363, loss_ce: 0.032905
2022-01-13 23:45:41,284 iteration 1010 : loss : 0.055155, loss_ce: 0.017878
2022-01-13 23:45:42,711 iteration 1011 : loss : 0.083054, loss_ce: 0.034765
2022-01-13 23:45:44,189 iteration 1012 : loss : 0.087013, loss_ce: 0.033645
2022-01-13 23:45:45,614 iteration 1013 : loss : 0.067754, loss_ce: 0.026522
2022-01-13 23:45:47,035 iteration 1014 : loss : 0.052215, loss_ce: 0.022545
2022-01-13 23:45:48,584 iteration 1015 : loss : 0.095233, loss_ce: 0.040381
2022-01-13 23:45:49,997 iteration 1016 : loss : 0.078936, loss_ce: 0.033026
2022-01-13 23:45:51,393 iteration 1017 : loss : 0.078126, loss_ce: 0.029418
2022-01-13 23:45:52,859 iteration 1018 : loss : 0.108094, loss_ce: 0.042224
2022-01-13 23:45:54,306 iteration 1019 : loss : 0.093627, loss_ce: 0.038551
2022-01-13 23:45:54,306 Training Data Eval:
2022-01-13 23:46:01,349   Average segmentation loss on training set: 0.0585
2022-01-13 23:46:01,349 Validation Data Eval:
2022-01-13 23:46:03,793   Average segmentation loss on validation set: 0.0765
2022-01-13 23:46:09,546 Found new lowest validation loss at iteration 1019! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_1HEAD_best_val_loss_seed2.pth
2022-01-13 23:46:11,044 iteration 1020 : loss : 0.072500, loss_ce: 0.030222
 15%|████▌                         | 60/400 [26:24<2:48:02, 29.65s/it]2022-01-13 23:46:12,491 iteration 1021 : loss : 0.082025, loss_ce: 0.034826
2022-01-13 23:46:13,970 iteration 1022 : loss : 0.065661, loss_ce: 0.031167
2022-01-13 23:46:15,316 iteration 1023 : loss : 0.076086, loss_ce: 0.032383
2022-01-13 23:46:16,692 iteration 1024 : loss : 0.051080, loss_ce: 0.020072
2022-01-13 23:46:18,126 iteration 1025 : loss : 0.089237, loss_ce: 0.045523
2022-01-13 23:46:19,534 iteration 1026 : loss : 0.089983, loss_ce: 0.025676
2022-01-13 23:46:20,927 iteration 1027 : loss : 0.067827, loss_ce: 0.021621
2022-01-13 23:46:22,400 iteration 1028 : loss : 0.081768, loss_ce: 0.027815
2022-01-13 23:46:23,843 iteration 1029 : loss : 0.081499, loss_ce: 0.028483
2022-01-13 23:46:25,265 iteration 1030 : loss : 0.091844, loss_ce: 0.037992
2022-01-13 23:46:26,761 iteration 1031 : loss : 0.089817, loss_ce: 0.038903
2022-01-13 23:46:28,184 iteration 1032 : loss : 0.075212, loss_ce: 0.033239
2022-01-13 23:46:29,570 iteration 1033 : loss : 0.072884, loss_ce: 0.033651
2022-01-13 23:46:30,920 iteration 1034 : loss : 0.087333, loss_ce: 0.035924
2022-01-13 23:46:32,367 iteration 1035 : loss : 0.101098, loss_ce: 0.047046
2022-01-13 23:46:33,839 iteration 1036 : loss : 0.078230, loss_ce: 0.029554
2022-01-13 23:46:35,165 iteration 1037 : loss : 0.063071, loss_ce: 0.026014
 15%|████▌                         | 61/400 [26:48<2:38:09, 27.99s/it]2022-01-13 23:46:36,585 iteration 1038 : loss : 0.074324, loss_ce: 0.032196
2022-01-13 23:46:37,969 iteration 1039 : loss : 0.055311, loss_ce: 0.023653
2022-01-13 23:46:39,342 iteration 1040 : loss : 0.096904, loss_ce: 0.033099
2022-01-13 23:46:40,736 iteration 1041 : loss : 0.092024, loss_ce: 0.045445
2022-01-13 23:46:42,122 iteration 1042 : loss : 0.076095, loss_ce: 0.041396
2022-01-13 23:46:43,504 iteration 1043 : loss : 0.076719, loss_ce: 0.027316
2022-01-13 23:46:44,955 iteration 1044 : loss : 0.075343, loss_ce: 0.035724
2022-01-13 23:46:46,382 iteration 1045 : loss : 0.096704, loss_ce: 0.045143
2022-01-13 23:46:47,743 iteration 1046 : loss : 0.048957, loss_ce: 0.023203
2022-01-13 23:46:49,033 iteration 1047 : loss : 0.057451, loss_ce: 0.023447
2022-01-13 23:46:50,463 iteration 1048 : loss : 0.060266, loss_ce: 0.026415
2022-01-13 23:46:51,942 iteration 1049 : loss : 0.091313, loss_ce: 0.039041
2022-01-13 23:46:53,365 iteration 1050 : loss : 0.129630, loss_ce: 0.026399
2022-01-13 23:46:54,767 iteration 1051 : loss : 0.061288, loss_ce: 0.025962
2022-01-13 23:46:56,219 iteration 1052 : loss : 0.104441, loss_ce: 0.033933
2022-01-13 23:46:57,647 iteration 1053 : loss : 0.101086, loss_ce: 0.029665
2022-01-13 23:46:59,071 iteration 1054 : loss : 0.082599, loss_ce: 0.033497
 16%|████▋                         | 62/400 [27:12<2:30:46, 26.77s/it]2022-01-13 23:47:00,523 iteration 1055 : loss : 0.055990, loss_ce: 0.017600
2022-01-13 23:47:01,841 iteration 1056 : loss : 0.054786, loss_ce: 0.024037
2022-01-13 23:47:03,285 iteration 1057 : loss : 0.093055, loss_ce: 0.034575
2022-01-13 23:47:04,689 iteration 1058 : loss : 0.106593, loss_ce: 0.036893
2022-01-13 23:47:06,114 iteration 1059 : loss : 0.092445, loss_ce: 0.043846
2022-01-13 23:47:07,491 iteration 1060 : loss : 0.048047, loss_ce: 0.015673
2022-01-13 23:47:09,008 iteration 1061 : loss : 0.098920, loss_ce: 0.050419
2022-01-13 23:47:10,444 iteration 1062 : loss : 0.093914, loss_ce: 0.036221
2022-01-13 23:47:12,007 iteration 1063 : loss : 0.083223, loss_ce: 0.037837
2022-01-13 23:47:13,432 iteration 1064 : loss : 0.101270, loss_ce: 0.033229
2022-01-13 23:47:14,937 iteration 1065 : loss : 0.088312, loss_ce: 0.041879
2022-01-13 23:47:16,305 iteration 1066 : loss : 0.048033, loss_ce: 0.018350
2022-01-13 23:47:17,684 iteration 1067 : loss : 0.063778, loss_ce: 0.028530
2022-01-13 23:47:19,161 iteration 1068 : loss : 0.060777, loss_ce: 0.024506
2022-01-13 23:47:20,590 iteration 1069 : loss : 0.054279, loss_ce: 0.023953
2022-01-13 23:47:22,098 iteration 1070 : loss : 0.134205, loss_ce: 0.042234
2022-01-13 23:47:23,522 iteration 1071 : loss : 0.074376, loss_ce: 0.035744
 16%|████▋                         | 63/400 [27:36<2:26:26, 26.07s/it]2022-01-13 23:47:25,070 iteration 1072 : loss : 0.089193, loss_ce: 0.028491
2022-01-13 23:47:26,503 iteration 1073 : loss : 0.088444, loss_ce: 0.039534
2022-01-13 23:47:27,936 iteration 1074 : loss : 0.078004, loss_ce: 0.033705
2022-01-13 23:47:29,375 iteration 1075 : loss : 0.101762, loss_ce: 0.031251
2022-01-13 23:47:30,791 iteration 1076 : loss : 0.064413, loss_ce: 0.028691
2022-01-13 23:47:32,303 iteration 1077 : loss : 0.094427, loss_ce: 0.031345
2022-01-13 23:47:33,702 iteration 1078 : loss : 0.072555, loss_ce: 0.031429
2022-01-13 23:47:35,207 iteration 1079 : loss : 0.094326, loss_ce: 0.036956
2022-01-13 23:47:36,568 iteration 1080 : loss : 0.044420, loss_ce: 0.014339
2022-01-13 23:47:37,984 iteration 1081 : loss : 0.052671, loss_ce: 0.025967
2022-01-13 23:47:39,463 iteration 1082 : loss : 0.090156, loss_ce: 0.040196
2022-01-13 23:47:40,833 iteration 1083 : loss : 0.074230, loss_ce: 0.028282
2022-01-13 23:47:42,220 iteration 1084 : loss : 0.062365, loss_ce: 0.020023
2022-01-13 23:47:43,674 iteration 1085 : loss : 0.060819, loss_ce: 0.025712
2022-01-13 23:47:45,074 iteration 1086 : loss : 0.073205, loss_ce: 0.035758
2022-01-13 23:47:46,574 iteration 1087 : loss : 0.049164, loss_ce: 0.018615
2022-01-13 23:47:47,990 iteration 1088 : loss : 0.061170, loss_ce: 0.029393
 16%|████▊                         | 64/400 [28:01<2:23:17, 25.59s/it]2022-01-13 23:47:49,424 iteration 1089 : loss : 0.089143, loss_ce: 0.033125
2022-01-13 23:47:50,824 iteration 1090 : loss : 0.073487, loss_ce: 0.024794
2022-01-13 23:47:52,285 iteration 1091 : loss : 0.055910, loss_ce: 0.027403
2022-01-13 23:47:53,699 iteration 1092 : loss : 0.066645, loss_ce: 0.028324
2022-01-13 23:47:55,120 iteration 1093 : loss : 0.056671, loss_ce: 0.024518
2022-01-13 23:47:56,543 iteration 1094 : loss : 0.061111, loss_ce: 0.030180
2022-01-13 23:47:57,977 iteration 1095 : loss : 0.110933, loss_ce: 0.035535
2022-01-13 23:47:59,398 iteration 1096 : loss : 0.056553, loss_ce: 0.024314
2022-01-13 23:48:00,755 iteration 1097 : loss : 0.082889, loss_ce: 0.030332
2022-01-13 23:48:02,117 iteration 1098 : loss : 0.065202, loss_ce: 0.029052
2022-01-13 23:48:03,540 iteration 1099 : loss : 0.071916, loss_ce: 0.027260
2022-01-13 23:48:04,917 iteration 1100 : loss : 0.067855, loss_ce: 0.024333
2022-01-13 23:48:06,287 iteration 1101 : loss : 0.069597, loss_ce: 0.027252
2022-01-13 23:48:07,769 iteration 1102 : loss : 0.092202, loss_ce: 0.030986
2022-01-13 23:48:09,164 iteration 1103 : loss : 0.078188, loss_ce: 0.029843
2022-01-13 23:48:10,505 iteration 1104 : loss : 0.065294, loss_ce: 0.025571
2022-01-13 23:48:10,505 Training Data Eval:
2022-01-13 23:48:17,454   Average segmentation loss on training set: 0.0518
2022-01-13 23:48:17,454 Validation Data Eval:
2022-01-13 23:48:19,999   Average segmentation loss on validation set: 0.0816
2022-01-13 23:48:21,498 iteration 1105 : loss : 0.062359, loss_ce: 0.026690
 16%|████▉                         | 65/400 [28:34<2:36:08, 27.97s/it]2022-01-13 23:48:23,004 iteration 1106 : loss : 0.062512, loss_ce: 0.020273
2022-01-13 23:48:24,509 iteration 1107 : loss : 0.062946, loss_ce: 0.027804
2022-01-13 23:48:25,892 iteration 1108 : loss : 0.046895, loss_ce: 0.017371
2022-01-13 23:48:27,270 iteration 1109 : loss : 0.080008, loss_ce: 0.038644
2022-01-13 23:48:28,700 iteration 1110 : loss : 0.061052, loss_ce: 0.027946
2022-01-13 23:48:30,138 iteration 1111 : loss : 0.082790, loss_ce: 0.048621
2022-01-13 23:48:31,589 iteration 1112 : loss : 0.087270, loss_ce: 0.048852
2022-01-13 23:48:33,002 iteration 1113 : loss : 0.073302, loss_ce: 0.033275
2022-01-13 23:48:34,376 iteration 1114 : loss : 0.080898, loss_ce: 0.031992
2022-01-13 23:48:35,717 iteration 1115 : loss : 0.051820, loss_ce: 0.016869
2022-01-13 23:48:37,220 iteration 1116 : loss : 0.100382, loss_ce: 0.042857
2022-01-13 23:48:38,700 iteration 1117 : loss : 0.087047, loss_ce: 0.034170
2022-01-13 23:48:40,069 iteration 1118 : loss : 0.044823, loss_ce: 0.019674
2022-01-13 23:48:41,437 iteration 1119 : loss : 0.059631, loss_ce: 0.025820
2022-01-13 23:48:42,777 iteration 1120 : loss : 0.081152, loss_ce: 0.028635
2022-01-13 23:48:44,138 iteration 1121 : loss : 0.075606, loss_ce: 0.025659
2022-01-13 23:48:45,511 iteration 1122 : loss : 0.057669, loss_ce: 0.024450
 16%|████▉                         | 66/400 [28:58<2:29:05, 26.78s/it]2022-01-13 23:48:46,977 iteration 1123 : loss : 0.075956, loss_ce: 0.032634
2022-01-13 23:48:48,345 iteration 1124 : loss : 0.072260, loss_ce: 0.038476
2022-01-13 23:48:49,811 iteration 1125 : loss : 0.132735, loss_ce: 0.060297
2022-01-13 23:48:51,320 iteration 1126 : loss : 0.124845, loss_ce: 0.062182
2022-01-13 23:48:52,752 iteration 1127 : loss : 0.153791, loss_ce: 0.081102
2022-01-13 23:48:54,193 iteration 1128 : loss : 0.076236, loss_ce: 0.023864
2022-01-13 23:48:55,586 iteration 1129 : loss : 0.050925, loss_ce: 0.019465
2022-01-13 23:48:57,057 iteration 1130 : loss : 0.084967, loss_ce: 0.041641
2022-01-13 23:48:58,530 iteration 1131 : loss : 0.145415, loss_ce: 0.040955
2022-01-13 23:48:59,961 iteration 1132 : loss : 0.082073, loss_ce: 0.037374
2022-01-13 23:49:01,405 iteration 1133 : loss : 0.073760, loss_ce: 0.030004
2022-01-13 23:49:02,822 iteration 1134 : loss : 0.116600, loss_ce: 0.053227
2022-01-13 23:49:04,179 iteration 1135 : loss : 0.051884, loss_ce: 0.017063
2022-01-13 23:49:05,609 iteration 1136 : loss : 0.061663, loss_ce: 0.024375
2022-01-13 23:49:07,008 iteration 1137 : loss : 0.094734, loss_ce: 0.037982
2022-01-13 23:49:08,499 iteration 1138 : loss : 0.062548, loss_ce: 0.027532
2022-01-13 23:49:09,979 iteration 1139 : loss : 0.066102, loss_ce: 0.028004
 17%|█████                         | 67/400 [29:23<2:24:47, 26.09s/it]2022-01-13 23:49:11,433 iteration 1140 : loss : 0.084804, loss_ce: 0.036383
2022-01-13 23:49:12,877 iteration 1141 : loss : 0.047655, loss_ce: 0.021327
2022-01-13 23:49:14,259 iteration 1142 : loss : 0.055636, loss_ce: 0.023644
2022-01-13 23:49:15,704 iteration 1143 : loss : 0.110029, loss_ce: 0.036416
2022-01-13 23:49:17,178 iteration 1144 : loss : 0.072792, loss_ce: 0.030220
2022-01-13 23:49:18,571 iteration 1145 : loss : 0.063337, loss_ce: 0.019050
2022-01-13 23:49:20,009 iteration 1146 : loss : 0.071131, loss_ce: 0.033209
2022-01-13 23:49:21,357 iteration 1147 : loss : 0.048169, loss_ce: 0.019403
2022-01-13 23:49:22,747 iteration 1148 : loss : 0.068938, loss_ce: 0.031367
2022-01-13 23:49:24,188 iteration 1149 : loss : 0.083839, loss_ce: 0.041223
2022-01-13 23:49:25,599 iteration 1150 : loss : 0.070605, loss_ce: 0.032142
2022-01-13 23:49:26,997 iteration 1151 : loss : 0.064641, loss_ce: 0.020581
2022-01-13 23:49:28,428 iteration 1152 : loss : 0.138472, loss_ce: 0.028986
2022-01-13 23:49:29,840 iteration 1153 : loss : 0.054957, loss_ce: 0.022672
2022-01-13 23:49:31,177 iteration 1154 : loss : 0.067895, loss_ce: 0.029687
2022-01-13 23:49:32,669 iteration 1155 : loss : 0.081893, loss_ce: 0.033579
2022-01-13 23:49:34,097 iteration 1156 : loss : 0.145568, loss_ce: 0.056231
 17%|█████                         | 68/400 [29:47<2:21:03, 25.49s/it]2022-01-13 23:49:35,505 iteration 1157 : loss : 0.060324, loss_ce: 0.026007
2022-01-13 23:49:37,041 iteration 1158 : loss : 0.075018, loss_ce: 0.025104
2022-01-13 23:49:38,502 iteration 1159 : loss : 0.100052, loss_ce: 0.041808
2022-01-13 23:49:39,835 iteration 1160 : loss : 0.050093, loss_ce: 0.022490
2022-01-13 23:49:41,241 iteration 1161 : loss : 0.061033, loss_ce: 0.022443
2022-01-13 23:49:42,645 iteration 1162 : loss : 0.069970, loss_ce: 0.016636
2022-01-13 23:49:44,163 iteration 1163 : loss : 0.100724, loss_ce: 0.035539
2022-01-13 23:49:45,591 iteration 1164 : loss : 0.061771, loss_ce: 0.023080
2022-01-13 23:49:46,945 iteration 1165 : loss : 0.074458, loss_ce: 0.038272
2022-01-13 23:49:48,366 iteration 1166 : loss : 0.049013, loss_ce: 0.024160
2022-01-13 23:49:49,816 iteration 1167 : loss : 0.086948, loss_ce: 0.039018
2022-01-13 23:49:51,178 iteration 1168 : loss : 0.057760, loss_ce: 0.021061
2022-01-13 23:49:52,622 iteration 1169 : loss : 0.078365, loss_ce: 0.025956
2022-01-13 23:49:54,054 iteration 1170 : loss : 0.061361, loss_ce: 0.026235
2022-01-13 23:49:55,415 iteration 1171 : loss : 0.068143, loss_ce: 0.024531
2022-01-13 23:49:56,851 iteration 1172 : loss : 0.055256, loss_ce: 0.022805
2022-01-13 23:49:58,309 iteration 1173 : loss : 0.069164, loss_ce: 0.041949
 17%|█████▏                        | 69/400 [30:11<2:18:32, 25.11s/it]2022-01-13 23:49:59,831 iteration 1174 : loss : 0.062218, loss_ce: 0.021445
2022-01-13 23:50:01,237 iteration 1175 : loss : 0.066070, loss_ce: 0.027675
2022-01-13 23:50:02,709 iteration 1176 : loss : 0.096603, loss_ce: 0.051111
2022-01-13 23:50:04,237 iteration 1177 : loss : 0.120256, loss_ce: 0.052022
2022-01-13 23:50:05,672 iteration 1178 : loss : 0.061641, loss_ce: 0.027303
2022-01-13 23:50:07,020 iteration 1179 : loss : 0.049413, loss_ce: 0.021978
2022-01-13 23:50:08,497 iteration 1180 : loss : 0.085595, loss_ce: 0.035336
2022-01-13 23:50:09,839 iteration 1181 : loss : 0.053200, loss_ce: 0.021452
2022-01-13 23:50:11,353 iteration 1182 : loss : 0.097483, loss_ce: 0.043611
2022-01-13 23:50:12,760 iteration 1183 : loss : 0.065425, loss_ce: 0.033031
2022-01-13 23:50:14,105 iteration 1184 : loss : 0.051257, loss_ce: 0.022189
2022-01-13 23:50:15,544 iteration 1185 : loss : 0.071754, loss_ce: 0.027978
2022-01-13 23:50:16,913 iteration 1186 : loss : 0.066169, loss_ce: 0.025379
2022-01-13 23:50:18,341 iteration 1187 : loss : 0.049355, loss_ce: 0.019400
2022-01-13 23:50:19,705 iteration 1188 : loss : 0.042950, loss_ce: 0.016746
2022-01-13 23:50:21,119 iteration 1189 : loss : 0.075630, loss_ce: 0.030495
2022-01-13 23:50:21,119 Training Data Eval:
2022-01-13 23:50:28,196   Average segmentation loss on training set: 0.0472
2022-01-13 23:50:28,196 Validation Data Eval:
2022-01-13 23:50:30,698   Average segmentation loss on validation set: 0.1288
2022-01-13 23:50:32,147 iteration 1190 : loss : 0.063661, loss_ce: 0.025380
 18%|█████▎                        | 70/400 [30:45<2:32:29, 27.73s/it]2022-01-13 23:50:33,592 iteration 1191 : loss : 0.053313, loss_ce: 0.023839
2022-01-13 23:50:34,971 iteration 1192 : loss : 0.051271, loss_ce: 0.021362
2022-01-13 23:50:36,372 iteration 1193 : loss : 0.076984, loss_ce: 0.027881
2022-01-13 23:50:37,734 iteration 1194 : loss : 0.078803, loss_ce: 0.029789
2022-01-13 23:50:39,177 iteration 1195 : loss : 0.053286, loss_ce: 0.018099
2022-01-13 23:50:40,512 iteration 1196 : loss : 0.053024, loss_ce: 0.018476
2022-01-13 23:50:41,946 iteration 1197 : loss : 0.062327, loss_ce: 0.034958
2022-01-13 23:50:43,357 iteration 1198 : loss : 0.082317, loss_ce: 0.047261
2022-01-13 23:50:44,785 iteration 1199 : loss : 0.074878, loss_ce: 0.030934
2022-01-13 23:50:46,230 iteration 1200 : loss : 0.085665, loss_ce: 0.032562
2022-01-13 23:50:47,659 iteration 1201 : loss : 0.044605, loss_ce: 0.019502
2022-01-13 23:50:49,094 iteration 1202 : loss : 0.054613, loss_ce: 0.026448
2022-01-13 23:50:50,486 iteration 1203 : loss : 0.059658, loss_ce: 0.021881
2022-01-13 23:50:51,891 iteration 1204 : loss : 0.068615, loss_ce: 0.029680
2022-01-13 23:50:53,332 iteration 1205 : loss : 0.092448, loss_ce: 0.053087
2022-01-13 23:50:54,788 iteration 1206 : loss : 0.150606, loss_ce: 0.041741
2022-01-13 23:50:56,177 iteration 1207 : loss : 0.068691, loss_ce: 0.023378
 18%|█████▎                        | 71/400 [31:09<2:25:58, 26.62s/it]2022-01-13 23:50:57,587 iteration 1208 : loss : 0.065285, loss_ce: 0.031286
2022-01-13 23:50:58,990 iteration 1209 : loss : 0.061730, loss_ce: 0.020725
2022-01-13 23:51:00,338 iteration 1210 : loss : 0.064259, loss_ce: 0.021518
2022-01-13 23:51:01,782 iteration 1211 : loss : 0.073104, loss_ce: 0.028834
2022-01-13 23:51:03,148 iteration 1212 : loss : 0.044841, loss_ce: 0.018573
2022-01-13 23:51:04,569 iteration 1213 : loss : 0.085772, loss_ce: 0.024145
2022-01-13 23:51:05,989 iteration 1214 : loss : 0.059929, loss_ce: 0.026366
2022-01-13 23:51:07,380 iteration 1215 : loss : 0.075682, loss_ce: 0.032725
2022-01-13 23:51:08,768 iteration 1216 : loss : 0.051143, loss_ce: 0.020473
2022-01-13 23:51:10,199 iteration 1217 : loss : 0.079479, loss_ce: 0.031296
2022-01-13 23:51:11,500 iteration 1218 : loss : 0.046458, loss_ce: 0.020949
2022-01-13 23:51:12,934 iteration 1219 : loss : 0.072285, loss_ce: 0.026530
2022-01-13 23:51:14,320 iteration 1220 : loss : 0.084118, loss_ce: 0.040810
2022-01-13 23:51:15,821 iteration 1221 : loss : 0.086609, loss_ce: 0.038187
2022-01-13 23:51:17,271 iteration 1222 : loss : 0.074507, loss_ce: 0.028759
2022-01-13 23:51:18,651 iteration 1223 : loss : 0.051229, loss_ce: 0.022221
2022-01-13 23:51:20,078 iteration 1224 : loss : 0.111230, loss_ce: 0.057825
 18%|█████▍                        | 72/400 [31:33<2:21:03, 25.80s/it]2022-01-13 23:51:21,578 iteration 1225 : loss : 0.059068, loss_ce: 0.021175
2022-01-13 23:51:22,983 iteration 1226 : loss : 0.076104, loss_ce: 0.034569
2022-01-13 23:51:24,340 iteration 1227 : loss : 0.059007, loss_ce: 0.019703
2022-01-13 23:51:25,854 iteration 1228 : loss : 0.124911, loss_ce: 0.040605
2022-01-13 23:51:27,307 iteration 1229 : loss : 0.089025, loss_ce: 0.037031
2022-01-13 23:51:28,764 iteration 1230 : loss : 0.093241, loss_ce: 0.049500
2022-01-13 23:51:30,152 iteration 1231 : loss : 0.129496, loss_ce: 0.048373
2022-01-13 23:51:31,635 iteration 1232 : loss : 0.072044, loss_ce: 0.033201
2022-01-13 23:51:33,159 iteration 1233 : loss : 0.079011, loss_ce: 0.039573
2022-01-13 23:51:34,574 iteration 1234 : loss : 0.099706, loss_ce: 0.046084
2022-01-13 23:51:35,970 iteration 1235 : loss : 0.085529, loss_ce: 0.045148
2022-01-13 23:51:37,333 iteration 1236 : loss : 0.055104, loss_ce: 0.019279
2022-01-13 23:51:38,652 iteration 1237 : loss : 0.115383, loss_ce: 0.049301
2022-01-13 23:51:40,051 iteration 1238 : loss : 0.074214, loss_ce: 0.035742
2022-01-13 23:51:41,488 iteration 1239 : loss : 0.073202, loss_ce: 0.030406
2022-01-13 23:51:42,838 iteration 1240 : loss : 0.078595, loss_ce: 0.033061
2022-01-13 23:51:44,361 iteration 1241 : loss : 0.052422, loss_ce: 0.024700
 18%|█████▍                        | 73/400 [31:57<2:18:09, 25.35s/it]2022-01-13 23:51:45,772 iteration 1242 : loss : 0.075978, loss_ce: 0.035608
2022-01-13 23:51:47,120 iteration 1243 : loss : 0.043634, loss_ce: 0.023452
2022-01-13 23:51:48,480 iteration 1244 : loss : 0.063570, loss_ce: 0.024766
2022-01-13 23:51:49,864 iteration 1245 : loss : 0.062885, loss_ce: 0.026794
2022-01-13 23:51:51,271 iteration 1246 : loss : 0.064604, loss_ce: 0.025937
2022-01-13 23:51:52,708 iteration 1247 : loss : 0.077676, loss_ce: 0.028412
2022-01-13 23:51:54,062 iteration 1248 : loss : 0.038494, loss_ce: 0.015089
2022-01-13 23:51:55,466 iteration 1249 : loss : 0.058223, loss_ce: 0.021961
2022-01-13 23:51:56,826 iteration 1250 : loss : 0.063143, loss_ce: 0.024105
2022-01-13 23:51:58,248 iteration 1251 : loss : 0.061063, loss_ce: 0.024936
2022-01-13 23:51:59,657 iteration 1252 : loss : 0.120842, loss_ce: 0.038897
2022-01-13 23:52:01,075 iteration 1253 : loss : 0.065338, loss_ce: 0.031004
2022-01-13 23:52:02,462 iteration 1254 : loss : 0.081859, loss_ce: 0.041174
2022-01-13 23:52:03,894 iteration 1255 : loss : 0.076500, loss_ce: 0.032361
2022-01-13 23:52:05,381 iteration 1256 : loss : 0.067599, loss_ce: 0.024664
2022-01-13 23:52:06,789 iteration 1257 : loss : 0.052760, loss_ce: 0.024905
2022-01-13 23:52:08,282 iteration 1258 : loss : 0.072480, loss_ce: 0.030272
 18%|█████▌                        | 74/400 [32:21<2:15:23, 24.92s/it]2022-01-13 23:52:09,726 iteration 1259 : loss : 0.065293, loss_ce: 0.023546
2022-01-13 23:52:11,175 iteration 1260 : loss : 0.089499, loss_ce: 0.031667
2022-01-13 23:52:12,595 iteration 1261 : loss : 0.049004, loss_ce: 0.022581
2022-01-13 23:52:13,950 iteration 1262 : loss : 0.046124, loss_ce: 0.021189
2022-01-13 23:52:15,408 iteration 1263 : loss : 0.060833, loss_ce: 0.020891
2022-01-13 23:52:16,751 iteration 1264 : loss : 0.066953, loss_ce: 0.032632
2022-01-13 23:52:18,095 iteration 1265 : loss : 0.083005, loss_ce: 0.037287
2022-01-13 23:52:19,414 iteration 1266 : loss : 0.057898, loss_ce: 0.026467
2022-01-13 23:52:20,910 iteration 1267 : loss : 0.063849, loss_ce: 0.023014
2022-01-13 23:52:22,291 iteration 1268 : loss : 0.159859, loss_ce: 0.044607
2022-01-13 23:52:23,740 iteration 1269 : loss : 0.076713, loss_ce: 0.028330
2022-01-13 23:52:25,085 iteration 1270 : loss : 0.062627, loss_ce: 0.023763
2022-01-13 23:52:26,470 iteration 1271 : loss : 0.056844, loss_ce: 0.027098
2022-01-13 23:52:27,861 iteration 1272 : loss : 0.088183, loss_ce: 0.037164
2022-01-13 23:52:29,290 iteration 1273 : loss : 0.057226, loss_ce: 0.029918
2022-01-13 23:52:30,696 iteration 1274 : loss : 0.050641, loss_ce: 0.019139
2022-01-13 23:52:30,696 Training Data Eval:
2022-01-13 23:52:37,882   Average segmentation loss on training set: 0.0500
2022-01-13 23:52:37,882 Validation Data Eval:
2022-01-13 23:52:40,404   Average segmentation loss on validation set: 0.0775
2022-01-13 23:52:41,845 iteration 1275 : loss : 0.061926, loss_ce: 0.019998
 19%|█████▋                        | 75/400 [32:55<2:29:02, 27.51s/it]2022-01-13 23:52:43,416 iteration 1276 : loss : 0.101000, loss_ce: 0.032384
2022-01-13 23:52:44,779 iteration 1277 : loss : 0.045744, loss_ce: 0.019881
2022-01-13 23:52:46,226 iteration 1278 : loss : 0.057810, loss_ce: 0.025596
2022-01-13 23:52:47,527 iteration 1279 : loss : 0.049263, loss_ce: 0.023823
2022-01-13 23:52:48,855 iteration 1280 : loss : 0.060778, loss_ce: 0.030129
2022-01-13 23:52:50,328 iteration 1281 : loss : 0.065371, loss_ce: 0.031858
2022-01-13 23:52:51,689 iteration 1282 : loss : 0.083729, loss_ce: 0.046595
2022-01-13 23:52:53,054 iteration 1283 : loss : 0.056705, loss_ce: 0.021756
2022-01-13 23:52:54,452 iteration 1284 : loss : 0.062886, loss_ce: 0.030835
2022-01-13 23:52:55,993 iteration 1285 : loss : 0.100983, loss_ce: 0.033378
2022-01-13 23:52:57,428 iteration 1286 : loss : 0.064781, loss_ce: 0.022642
2022-01-13 23:52:58,819 iteration 1287 : loss : 0.061494, loss_ce: 0.021741
2022-01-13 23:53:00,233 iteration 1288 : loss : 0.078863, loss_ce: 0.033888
2022-01-13 23:53:01,706 iteration 1289 : loss : 0.072586, loss_ce: 0.028894
2022-01-13 23:53:03,077 iteration 1290 : loss : 0.066926, loss_ce: 0.021654
2022-01-13 23:53:04,473 iteration 1291 : loss : 0.069191, loss_ce: 0.025694
2022-01-13 23:53:05,823 iteration 1292 : loss : 0.041302, loss_ce: 0.015919
 19%|█████▋                        | 76/400 [33:19<2:22:49, 26.45s/it]2022-01-13 23:53:07,282 iteration 1293 : loss : 0.075346, loss_ce: 0.035160
2022-01-13 23:53:08,633 iteration 1294 : loss : 0.084495, loss_ce: 0.034411
2022-01-13 23:53:10,021 iteration 1295 : loss : 0.049332, loss_ce: 0.020679
2022-01-13 23:53:11,444 iteration 1296 : loss : 0.046389, loss_ce: 0.016993
2022-01-13 23:53:12,856 iteration 1297 : loss : 0.054448, loss_ce: 0.019537
2022-01-13 23:53:14,305 iteration 1298 : loss : 0.037693, loss_ce: 0.016950
2022-01-13 23:53:15,691 iteration 1299 : loss : 0.064990, loss_ce: 0.023849
2022-01-13 23:53:17,182 iteration 1300 : loss : 0.117830, loss_ce: 0.036632
2022-01-13 23:53:18,632 iteration 1301 : loss : 0.062581, loss_ce: 0.029317
2022-01-13 23:53:20,101 iteration 1302 : loss : 0.064462, loss_ce: 0.024117
2022-01-13 23:53:21,494 iteration 1303 : loss : 0.060054, loss_ce: 0.028070
2022-01-13 23:53:22,956 iteration 1304 : loss : 0.096578, loss_ce: 0.022238
2022-01-13 23:53:24,373 iteration 1305 : loss : 0.066896, loss_ce: 0.033392
2022-01-13 23:53:25,859 iteration 1306 : loss : 0.081547, loss_ce: 0.036948
2022-01-13 23:53:27,334 iteration 1307 : loss : 0.063356, loss_ce: 0.023490
2022-01-13 23:53:28,765 iteration 1308 : loss : 0.088735, loss_ce: 0.051089
2022-01-13 23:53:30,206 iteration 1309 : loss : 0.062956, loss_ce: 0.018994
 19%|█████▊                        | 77/400 [33:43<2:19:02, 25.83s/it]2022-01-13 23:53:31,700 iteration 1310 : loss : 0.076670, loss_ce: 0.032101
2022-01-13 23:53:33,197 iteration 1311 : loss : 0.060247, loss_ce: 0.024925
2022-01-13 23:53:34,611 iteration 1312 : loss : 0.065598, loss_ce: 0.035418
2022-01-13 23:53:35,977 iteration 1313 : loss : 0.048019, loss_ce: 0.019733
2022-01-13 23:53:37,416 iteration 1314 : loss : 0.041972, loss_ce: 0.017431
2022-01-13 23:53:38,850 iteration 1315 : loss : 0.066650, loss_ce: 0.028476
2022-01-13 23:53:40,229 iteration 1316 : loss : 0.059412, loss_ce: 0.027292
2022-01-13 23:53:41,675 iteration 1317 : loss : 0.062871, loss_ce: 0.033137
2022-01-13 23:53:43,161 iteration 1318 : loss : 0.059608, loss_ce: 0.025471
2022-01-13 23:53:44,536 iteration 1319 : loss : 0.064994, loss_ce: 0.023188
2022-01-13 23:53:45,925 iteration 1320 : loss : 0.057963, loss_ce: 0.019839
2022-01-13 23:53:47,345 iteration 1321 : loss : 0.066728, loss_ce: 0.027115
2022-01-13 23:53:48,843 iteration 1322 : loss : 0.053952, loss_ce: 0.024705
2022-01-13 23:53:50,289 iteration 1323 : loss : 0.042643, loss_ce: 0.018437
2022-01-13 23:53:51,728 iteration 1324 : loss : 0.074669, loss_ce: 0.027586
2022-01-13 23:53:53,175 iteration 1325 : loss : 0.052235, loss_ce: 0.021660
2022-01-13 23:53:54,524 iteration 1326 : loss : 0.067819, loss_ce: 0.025742
 20%|█████▊                        | 78/400 [34:07<2:16:11, 25.38s/it]2022-01-13 23:53:55,994 iteration 1327 : loss : 0.053297, loss_ce: 0.027378
2022-01-13 23:53:57,489 iteration 1328 : loss : 0.070959, loss_ce: 0.024263
2022-01-13 23:53:58,833 iteration 1329 : loss : 0.054469, loss_ce: 0.026688
2022-01-13 23:54:00,224 iteration 1330 : loss : 0.053187, loss_ce: 0.019688
2022-01-13 23:54:01,624 iteration 1331 : loss : 0.042502, loss_ce: 0.014555
2022-01-13 23:54:03,038 iteration 1332 : loss : 0.050253, loss_ce: 0.024150
2022-01-13 23:54:04,487 iteration 1333 : loss : 0.079782, loss_ce: 0.018318
2022-01-13 23:54:05,895 iteration 1334 : loss : 0.044140, loss_ce: 0.019868
2022-01-13 23:54:07,422 iteration 1335 : loss : 0.050018, loss_ce: 0.017777
2022-01-13 23:54:08,853 iteration 1336 : loss : 0.079992, loss_ce: 0.033035
2022-01-13 23:54:10,304 iteration 1337 : loss : 0.059966, loss_ce: 0.029959
2022-01-13 23:54:11,790 iteration 1338 : loss : 0.078407, loss_ce: 0.032869
2022-01-13 23:54:13,228 iteration 1339 : loss : 0.077487, loss_ce: 0.033816
2022-01-13 23:54:14,583 iteration 1340 : loss : 0.049284, loss_ce: 0.016464
2022-01-13 23:54:15,985 iteration 1341 : loss : 0.056578, loss_ce: 0.025518
2022-01-13 23:54:17,390 iteration 1342 : loss : 0.081269, loss_ce: 0.026917
2022-01-13 23:54:18,791 iteration 1343 : loss : 0.052123, loss_ce: 0.018936
 20%|█████▉                        | 79/400 [34:32<2:13:59, 25.04s/it]2022-01-13 23:54:20,261 iteration 1344 : loss : 0.040902, loss_ce: 0.015372
2022-01-13 23:54:21,646 iteration 1345 : loss : 0.055307, loss_ce: 0.026905
2022-01-13 23:54:23,016 iteration 1346 : loss : 0.045844, loss_ce: 0.018936
2022-01-13 23:54:24,500 iteration 1347 : loss : 0.136140, loss_ce: 0.030148
2022-01-13 23:54:25,970 iteration 1348 : loss : 0.052442, loss_ce: 0.022508
2022-01-13 23:54:27,395 iteration 1349 : loss : 0.084141, loss_ce: 0.045045
2022-01-13 23:54:28,846 iteration 1350 : loss : 0.097885, loss_ce: 0.041835
2022-01-13 23:54:30,198 iteration 1351 : loss : 0.079335, loss_ce: 0.027450
2022-01-13 23:54:31,702 iteration 1352 : loss : 0.057087, loss_ce: 0.021544
2022-01-13 23:54:33,048 iteration 1353 : loss : 0.051432, loss_ce: 0.022683
2022-01-13 23:54:34,493 iteration 1354 : loss : 0.053807, loss_ce: 0.022748
2022-01-13 23:54:35,867 iteration 1355 : loss : 0.082201, loss_ce: 0.029092
2022-01-13 23:54:37,327 iteration 1356 : loss : 0.060289, loss_ce: 0.023562
2022-01-13 23:54:38,704 iteration 1357 : loss : 0.066079, loss_ce: 0.041787
2022-01-13 23:54:40,124 iteration 1358 : loss : 0.060364, loss_ce: 0.022594
2022-01-13 23:54:41,474 iteration 1359 : loss : 0.055818, loss_ce: 0.031496
2022-01-13 23:54:41,474 Training Data Eval:
2022-01-13 23:54:48,514   Average segmentation loss on training set: 0.0391
2022-01-13 23:54:48,514 Validation Data Eval:
2022-01-13 23:54:50,945   Average segmentation loss on validation set: 0.0827
2022-01-13 23:54:52,347 iteration 1360 : loss : 0.068746, loss_ce: 0.024308
 20%|██████                        | 80/400 [35:05<2:27:11, 27.60s/it]2022-01-13 23:54:53,856 iteration 1361 : loss : 0.112759, loss_ce: 0.039274
2022-01-13 23:54:55,289 iteration 1362 : loss : 0.061251, loss_ce: 0.026835
2022-01-13 23:54:56,726 iteration 1363 : loss : 0.051128, loss_ce: 0.018504
2022-01-13 23:54:58,209 iteration 1364 : loss : 0.081776, loss_ce: 0.024831
2022-01-13 23:54:59,700 iteration 1365 : loss : 0.062785, loss_ce: 0.025374
2022-01-13 23:55:01,102 iteration 1366 : loss : 0.071265, loss_ce: 0.033211
2022-01-13 23:55:02,472 iteration 1367 : loss : 0.044759, loss_ce: 0.021013
2022-01-13 23:55:03,881 iteration 1368 : loss : 0.048170, loss_ce: 0.019022
2022-01-13 23:55:05,272 iteration 1369 : loss : 0.081177, loss_ce: 0.023898
2022-01-13 23:55:06,699 iteration 1370 : loss : 0.075881, loss_ce: 0.030979
2022-01-13 23:55:08,052 iteration 1371 : loss : 0.053317, loss_ce: 0.021498
2022-01-13 23:55:09,484 iteration 1372 : loss : 0.083083, loss_ce: 0.026255
2022-01-13 23:55:11,000 iteration 1373 : loss : 0.093768, loss_ce: 0.053468
2022-01-13 23:55:12,398 iteration 1374 : loss : 0.070901, loss_ce: 0.023894
2022-01-13 23:55:13,880 iteration 1375 : loss : 0.059041, loss_ce: 0.021918
2022-01-13 23:55:15,211 iteration 1376 : loss : 0.052490, loss_ce: 0.022729
2022-01-13 23:55:16,653 iteration 1377 : loss : 0.081194, loss_ce: 0.031651
 20%|██████                        | 81/400 [35:30<2:21:28, 26.61s/it]2022-01-13 23:55:18,200 iteration 1378 : loss : 0.054932, loss_ce: 0.025959
2022-01-13 23:55:19,660 iteration 1379 : loss : 0.072510, loss_ce: 0.021239
2022-01-13 23:55:21,073 iteration 1380 : loss : 0.058437, loss_ce: 0.027427
2022-01-13 23:55:22,488 iteration 1381 : loss : 0.053366, loss_ce: 0.021442
2022-01-13 23:55:23,889 iteration 1382 : loss : 0.053343, loss_ce: 0.023153
2022-01-13 23:55:25,326 iteration 1383 : loss : 0.068867, loss_ce: 0.020553
2022-01-13 23:55:26,834 iteration 1384 : loss : 0.091721, loss_ce: 0.043467
2022-01-13 23:55:28,189 iteration 1385 : loss : 0.040739, loss_ce: 0.015245
2022-01-13 23:55:29,728 iteration 1386 : loss : 0.086462, loss_ce: 0.039811
2022-01-13 23:55:31,116 iteration 1387 : loss : 0.076382, loss_ce: 0.023933
2022-01-13 23:55:32,570 iteration 1388 : loss : 0.082169, loss_ce: 0.025607
2022-01-13 23:55:34,025 iteration 1389 : loss : 0.070580, loss_ce: 0.034671
2022-01-13 23:55:35,362 iteration 1390 : loss : 0.047438, loss_ce: 0.020585
2022-01-13 23:55:36,779 iteration 1391 : loss : 0.090008, loss_ce: 0.024425
2022-01-13 23:55:38,188 iteration 1392 : loss : 0.073780, loss_ce: 0.034380
2022-01-13 23:55:39,615 iteration 1393 : loss : 0.073785, loss_ce: 0.027516
2022-01-13 23:55:41,044 iteration 1394 : loss : 0.050076, loss_ce: 0.016510
 20%|██████▏                       | 82/400 [35:54<2:17:29, 25.94s/it]2022-01-13 23:55:42,571 iteration 1395 : loss : 0.086757, loss_ce: 0.047225
2022-01-13 23:55:43,932 iteration 1396 : loss : 0.054103, loss_ce: 0.025051
2022-01-13 23:55:45,425 iteration 1397 : loss : 0.053308, loss_ce: 0.020847
2022-01-13 23:55:46,779 iteration 1398 : loss : 0.038470, loss_ce: 0.015606
2022-01-13 23:55:48,227 iteration 1399 : loss : 0.048020, loss_ce: 0.021594
2022-01-13 23:55:49,730 iteration 1400 : loss : 0.058875, loss_ce: 0.023195
2022-01-13 23:55:51,156 iteration 1401 : loss : 0.043693, loss_ce: 0.013538
2022-01-13 23:55:52,641 iteration 1402 : loss : 0.054246, loss_ce: 0.019642
2022-01-13 23:55:54,101 iteration 1403 : loss : 0.054814, loss_ce: 0.020044
2022-01-13 23:55:55,614 iteration 1404 : loss : 0.061195, loss_ce: 0.023016
2022-01-13 23:55:56,905 iteration 1405 : loss : 0.044440, loss_ce: 0.016705
2022-01-13 23:55:58,375 iteration 1406 : loss : 0.064102, loss_ce: 0.022108
2022-01-13 23:55:59,778 iteration 1407 : loss : 0.047093, loss_ce: 0.019592
2022-01-13 23:56:01,146 iteration 1408 : loss : 0.045516, loss_ce: 0.021695
2022-01-13 23:56:02,639 iteration 1409 : loss : 0.091345, loss_ce: 0.023454
2022-01-13 23:56:03,998 iteration 1410 : loss : 0.058002, loss_ce: 0.023724
2022-01-13 23:56:05,320 iteration 1411 : loss : 0.038539, loss_ce: 0.015124
 21%|██████▏                       | 83/400 [36:18<2:14:24, 25.44s/it]2022-01-13 23:56:06,816 iteration 1412 : loss : 0.081694, loss_ce: 0.044275
2022-01-13 23:56:08,147 iteration 1413 : loss : 0.051081, loss_ce: 0.019981
2022-01-13 23:56:09,571 iteration 1414 : loss : 0.049948, loss_ce: 0.023078
2022-01-13 23:56:10,920 iteration 1415 : loss : 0.078109, loss_ce: 0.029941
2022-01-13 23:56:12,319 iteration 1416 : loss : 0.050064, loss_ce: 0.019578
2022-01-13 23:56:13,732 iteration 1417 : loss : 0.081257, loss_ce: 0.032837
2022-01-13 23:56:15,137 iteration 1418 : loss : 0.057138, loss_ce: 0.018049
2022-01-13 23:56:16,480 iteration 1419 : loss : 0.057903, loss_ce: 0.026137
2022-01-13 23:56:17,868 iteration 1420 : loss : 0.057698, loss_ce: 0.017284
2022-01-13 23:56:19,268 iteration 1421 : loss : 0.073288, loss_ce: 0.044516
2022-01-13 23:56:20,706 iteration 1422 : loss : 0.064190, loss_ce: 0.028245
2022-01-13 23:56:22,081 iteration 1423 : loss : 0.079597, loss_ce: 0.028421
2022-01-13 23:56:23,408 iteration 1424 : loss : 0.034611, loss_ce: 0.014715
2022-01-13 23:56:24,855 iteration 1425 : loss : 0.066283, loss_ce: 0.021106
2022-01-13 23:56:26,281 iteration 1426 : loss : 0.064593, loss_ce: 0.036598
2022-01-13 23:56:27,678 iteration 1427 : loss : 0.083677, loss_ce: 0.024038
2022-01-13 23:56:29,188 iteration 1428 : loss : 0.073769, loss_ce: 0.027656
 21%|██████▎                       | 84/400 [36:42<2:11:31, 24.97s/it]2022-01-13 23:56:30,673 iteration 1429 : loss : 0.062506, loss_ce: 0.028777
2022-01-13 23:56:32,061 iteration 1430 : loss : 0.047227, loss_ce: 0.022629
2022-01-13 23:56:33,417 iteration 1431 : loss : 0.057905, loss_ce: 0.018698
2022-01-13 23:56:34,824 iteration 1432 : loss : 0.065644, loss_ce: 0.031221
2022-01-13 23:56:36,176 iteration 1433 : loss : 0.047743, loss_ce: 0.021957
2022-01-13 23:56:37,676 iteration 1434 : loss : 0.057357, loss_ce: 0.023515
2022-01-13 23:56:39,109 iteration 1435 : loss : 0.059025, loss_ce: 0.021720
2022-01-13 23:56:40,575 iteration 1436 : loss : 0.073510, loss_ce: 0.037178
2022-01-13 23:56:41,975 iteration 1437 : loss : 0.043401, loss_ce: 0.019286
2022-01-13 23:56:43,362 iteration 1438 : loss : 0.048621, loss_ce: 0.019312
2022-01-13 23:56:44,785 iteration 1439 : loss : 0.096012, loss_ce: 0.033186
2022-01-13 23:56:46,133 iteration 1440 : loss : 0.046230, loss_ce: 0.015523
2022-01-13 23:56:47,547 iteration 1441 : loss : 0.073091, loss_ce: 0.031578
2022-01-13 23:56:48,942 iteration 1442 : loss : 0.064126, loss_ce: 0.019046
2022-01-13 23:56:50,401 iteration 1443 : loss : 0.082913, loss_ce: 0.034146
2022-01-13 23:56:51,794 iteration 1444 : loss : 0.065067, loss_ce: 0.015091
2022-01-13 23:56:51,794 Training Data Eval:
2022-01-13 23:56:58,826   Average segmentation loss on training set: 0.0417
2022-01-13 23:56:58,826 Validation Data Eval:
2022-01-13 23:57:01,306   Average segmentation loss on validation set: 0.0675
2022-01-13 23:57:06,991 Found new lowest validation loss at iteration 1444! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_1HEAD_best_val_loss_seed2.pth
2022-01-13 23:57:08,477 iteration 1445 : loss : 0.059601, loss_ce: 0.024830
 21%|██████▍                       | 85/400 [37:21<2:33:39, 29.27s/it]2022-01-13 23:57:09,866 iteration 1446 : loss : 0.045899, loss_ce: 0.018385
2022-01-13 23:57:11,182 iteration 1447 : loss : 0.040535, loss_ce: 0.017699
2022-01-13 23:57:12,619 iteration 1448 : loss : 0.082744, loss_ce: 0.024818
2022-01-13 23:57:14,074 iteration 1449 : loss : 0.055889, loss_ce: 0.019363
2022-01-13 23:57:15,446 iteration 1450 : loss : 0.050598, loss_ce: 0.019177
2022-01-13 23:57:16,858 iteration 1451 : loss : 0.050401, loss_ce: 0.016228
2022-01-13 23:57:18,257 iteration 1452 : loss : 0.076301, loss_ce: 0.048731
2022-01-13 23:57:19,677 iteration 1453 : loss : 0.042524, loss_ce: 0.020295
2022-01-13 23:57:21,078 iteration 1454 : loss : 0.061319, loss_ce: 0.019460
2022-01-13 23:57:22,511 iteration 1455 : loss : 0.049400, loss_ce: 0.017995
2022-01-13 23:57:23,871 iteration 1456 : loss : 0.057708, loss_ce: 0.017894
2022-01-13 23:57:25,320 iteration 1457 : loss : 0.045629, loss_ce: 0.021866
2022-01-13 23:57:26,753 iteration 1458 : loss : 0.038085, loss_ce: 0.016969
2022-01-13 23:57:28,118 iteration 1459 : loss : 0.048229, loss_ce: 0.016633
2022-01-13 23:57:29,499 iteration 1460 : loss : 0.074136, loss_ce: 0.030319
2022-01-13 23:57:30,847 iteration 1461 : loss : 0.071700, loss_ce: 0.027709
2022-01-13 23:57:32,301 iteration 1462 : loss : 0.047257, loss_ce: 0.019821
 22%|██████▍                       | 86/400 [37:45<2:24:37, 27.63s/it]2022-01-13 23:57:33,884 iteration 1463 : loss : 0.102821, loss_ce: 0.034953
2022-01-13 23:57:35,235 iteration 1464 : loss : 0.054581, loss_ce: 0.028719
2022-01-13 23:57:36,748 iteration 1465 : loss : 0.059903, loss_ce: 0.018849
2022-01-13 23:57:38,172 iteration 1466 : loss : 0.043521, loss_ce: 0.017029
2022-01-13 23:57:39,534 iteration 1467 : loss : 0.048254, loss_ce: 0.017852
2022-01-13 23:57:40,935 iteration 1468 : loss : 0.061966, loss_ce: 0.030438
2022-01-13 23:57:42,340 iteration 1469 : loss : 0.062719, loss_ce: 0.029274
2022-01-13 23:57:43,683 iteration 1470 : loss : 0.086666, loss_ce: 0.018038
2022-01-13 23:57:45,085 iteration 1471 : loss : 0.044992, loss_ce: 0.020441
2022-01-13 23:57:46,522 iteration 1472 : loss : 0.077671, loss_ce: 0.032958
2022-01-13 23:57:47,878 iteration 1473 : loss : 0.045557, loss_ce: 0.021338
2022-01-13 23:57:49,313 iteration 1474 : loss : 0.092895, loss_ce: 0.031016
2022-01-13 23:57:50,693 iteration 1475 : loss : 0.048328, loss_ce: 0.022773
2022-01-13 23:57:52,061 iteration 1476 : loss : 0.041250, loss_ce: 0.016305
2022-01-13 23:57:53,533 iteration 1477 : loss : 0.043120, loss_ce: 0.020538
2022-01-13 23:57:54,908 iteration 1478 : loss : 0.073188, loss_ce: 0.023481
2022-01-13 23:57:56,303 iteration 1479 : loss : 0.085255, loss_ce: 0.030200
 22%|██████▌                       | 87/400 [38:09<2:18:28, 26.55s/it]2022-01-13 23:57:57,662 iteration 1480 : loss : 0.035372, loss_ce: 0.012567
2022-01-13 23:57:59,194 iteration 1481 : loss : 0.084015, loss_ce: 0.034383
2022-01-13 23:58:00,591 iteration 1482 : loss : 0.045333, loss_ce: 0.020434
2022-01-13 23:58:02,053 iteration 1483 : loss : 0.080162, loss_ce: 0.030883
2022-01-13 23:58:03,504 iteration 1484 : loss : 0.057828, loss_ce: 0.017858
2022-01-13 23:58:04,942 iteration 1485 : loss : 0.039982, loss_ce: 0.018627
2022-01-13 23:58:06,339 iteration 1486 : loss : 0.058254, loss_ce: 0.018687
2022-01-13 23:58:07,749 iteration 1487 : loss : 0.037518, loss_ce: 0.014946
2022-01-13 23:58:09,092 iteration 1488 : loss : 0.048430, loss_ce: 0.021555
2022-01-13 23:58:10,458 iteration 1489 : loss : 0.059850, loss_ce: 0.026812
2022-01-13 23:58:11,916 iteration 1490 : loss : 0.052998, loss_ce: 0.021755
2022-01-13 23:58:13,263 iteration 1491 : loss : 0.065716, loss_ce: 0.019782
2022-01-13 23:58:14,630 iteration 1492 : loss : 0.046486, loss_ce: 0.018893
2022-01-13 23:58:16,098 iteration 1493 : loss : 0.046297, loss_ce: 0.019923
2022-01-13 23:58:17,500 iteration 1494 : loss : 0.051587, loss_ce: 0.018165
2022-01-13 23:58:18,859 iteration 1495 : loss : 0.040298, loss_ce: 0.010784
2022-01-13 23:58:20,337 iteration 1496 : loss : 0.039101, loss_ce: 0.017717
 22%|██████▌                       | 88/400 [38:33<2:14:06, 25.79s/it]2022-01-13 23:58:21,747 iteration 1497 : loss : 0.034135, loss_ce: 0.014243
2022-01-13 23:58:23,199 iteration 1498 : loss : 0.082686, loss_ce: 0.032442
2022-01-13 23:58:24,550 iteration 1499 : loss : 0.060876, loss_ce: 0.020693
2022-01-13 23:58:25,952 iteration 1500 : loss : 0.041551, loss_ce: 0.019201
2022-01-13 23:58:27,334 iteration 1501 : loss : 0.044764, loss_ce: 0.021885
2022-01-13 23:58:28,824 iteration 1502 : loss : 0.067302, loss_ce: 0.018346
2022-01-13 23:58:30,341 iteration 1503 : loss : 0.114644, loss_ce: 0.032350
2022-01-13 23:58:31,731 iteration 1504 : loss : 0.043026, loss_ce: 0.019152
2022-01-13 23:58:33,157 iteration 1505 : loss : 0.050375, loss_ce: 0.020976
2022-01-13 23:58:34,579 iteration 1506 : loss : 0.089888, loss_ce: 0.042660
2022-01-13 23:58:36,019 iteration 1507 : loss : 0.088652, loss_ce: 0.025835
2022-01-13 23:58:37,438 iteration 1508 : loss : 0.061298, loss_ce: 0.032889
2022-01-13 23:58:38,836 iteration 1509 : loss : 0.063682, loss_ce: 0.026250
2022-01-13 23:58:40,336 iteration 1510 : loss : 0.071835, loss_ce: 0.023533
2022-01-13 23:58:41,802 iteration 1511 : loss : 0.043969, loss_ce: 0.016904
2022-01-13 23:58:43,229 iteration 1512 : loss : 0.053468, loss_ce: 0.016770
2022-01-13 23:58:44,633 iteration 1513 : loss : 0.058234, loss_ce: 0.021992
 22%|██████▋                       | 89/400 [38:58<2:11:21, 25.34s/it]2022-01-13 23:58:46,132 iteration 1514 : loss : 0.046341, loss_ce: 0.017116
2022-01-13 23:58:47,494 iteration 1515 : loss : 0.038300, loss_ce: 0.014563
2022-01-13 23:58:48,900 iteration 1516 : loss : 0.065367, loss_ce: 0.024611
2022-01-13 23:58:50,218 iteration 1517 : loss : 0.037335, loss_ce: 0.013803
2022-01-13 23:58:51,661 iteration 1518 : loss : 0.040031, loss_ce: 0.013719
2022-01-13 23:58:53,121 iteration 1519 : loss : 0.053542, loss_ce: 0.018764
2022-01-13 23:58:54,572 iteration 1520 : loss : 0.051095, loss_ce: 0.020748
2022-01-13 23:58:55,987 iteration 1521 : loss : 0.061452, loss_ce: 0.018443
2022-01-13 23:58:57,347 iteration 1522 : loss : 0.064210, loss_ce: 0.031392
2022-01-13 23:58:58,728 iteration 1523 : loss : 0.050048, loss_ce: 0.013652
2022-01-13 23:59:00,145 iteration 1524 : loss : 0.045853, loss_ce: 0.017112
2022-01-13 23:59:01,498 iteration 1525 : loss : 0.057677, loss_ce: 0.023426
2022-01-13 23:59:02,953 iteration 1526 : loss : 0.068237, loss_ce: 0.031852
2022-01-13 23:59:04,392 iteration 1527 : loss : 0.045437, loss_ce: 0.023113
2022-01-13 23:59:05,745 iteration 1528 : loss : 0.037695, loss_ce: 0.017500
2022-01-13 23:59:07,112 iteration 1529 : loss : 0.050497, loss_ce: 0.019972
2022-01-13 23:59:07,112 Training Data Eval:
2022-01-13 23:59:14,155   Average segmentation loss on training set: 0.0505
2022-01-13 23:59:14,156 Validation Data Eval:
2022-01-13 23:59:16,602   Average segmentation loss on validation set: 0.1284
2022-01-13 23:59:18,046 iteration 1530 : loss : 0.071408, loss_ce: 0.033394
 22%|██████▊                       | 90/400 [39:31<2:23:26, 27.76s/it]2022-01-13 23:59:19,537 iteration 1531 : loss : 0.051298, loss_ce: 0.020759
2022-01-13 23:59:20,924 iteration 1532 : loss : 0.064053, loss_ce: 0.024285
2022-01-13 23:59:22,263 iteration 1533 : loss : 0.040323, loss_ce: 0.013581
2022-01-13 23:59:23,646 iteration 1534 : loss : 0.046329, loss_ce: 0.020932
2022-01-13 23:59:25,093 iteration 1535 : loss : 0.055104, loss_ce: 0.021666
2022-01-13 23:59:26,554 iteration 1536 : loss : 0.064047, loss_ce: 0.032113
2022-01-13 23:59:27,939 iteration 1537 : loss : 0.047713, loss_ce: 0.015733
2022-01-13 23:59:29,371 iteration 1538 : loss : 0.046214, loss_ce: 0.019400
2022-01-13 23:59:30,789 iteration 1539 : loss : 0.053318, loss_ce: 0.026309
2022-01-13 23:59:32,173 iteration 1540 : loss : 0.059609, loss_ce: 0.026210
2022-01-13 23:59:33,533 iteration 1541 : loss : 0.036532, loss_ce: 0.016433
2022-01-13 23:59:34,886 iteration 1542 : loss : 0.032856, loss_ce: 0.013846
2022-01-13 23:59:36,253 iteration 1543 : loss : 0.072252, loss_ce: 0.027398
2022-01-13 23:59:37,577 iteration 1544 : loss : 0.039979, loss_ce: 0.015323
2022-01-13 23:59:39,096 iteration 1545 : loss : 0.056517, loss_ce: 0.020473
2022-01-13 23:59:40,440 iteration 1546 : loss : 0.082866, loss_ce: 0.023988
2022-01-13 23:59:41,931 iteration 1547 : loss : 0.055416, loss_ce: 0.023350
 23%|██████▊                       | 91/400 [39:55<2:16:59, 26.60s/it]2022-01-13 23:59:43,405 iteration 1548 : loss : 0.050590, loss_ce: 0.022908
2022-01-13 23:59:44,714 iteration 1549 : loss : 0.036843, loss_ce: 0.015530
2022-01-13 23:59:46,078 iteration 1550 : loss : 0.053960, loss_ce: 0.024826
2022-01-13 23:59:47,359 iteration 1551 : loss : 0.044620, loss_ce: 0.015445
2022-01-13 23:59:48,762 iteration 1552 : loss : 0.049123, loss_ce: 0.018222
2022-01-13 23:59:50,221 iteration 1553 : loss : 0.070506, loss_ce: 0.029197
2022-01-13 23:59:51,640 iteration 1554 : loss : 0.043585, loss_ce: 0.017860
2022-01-13 23:59:53,017 iteration 1555 : loss : 0.056121, loss_ce: 0.023447
2022-01-13 23:59:54,451 iteration 1556 : loss : 0.046578, loss_ce: 0.015239
2022-01-13 23:59:55,833 iteration 1557 : loss : 0.063554, loss_ce: 0.027819
2022-01-13 23:59:57,259 iteration 1558 : loss : 0.059492, loss_ce: 0.032491
2022-01-13 23:59:58,668 iteration 1559 : loss : 0.051248, loss_ce: 0.017525
2022-01-14 00:00:00,013 iteration 1560 : loss : 0.039192, loss_ce: 0.018475
2022-01-14 00:00:01,455 iteration 1561 : loss : 0.047315, loss_ce: 0.018293
2022-01-14 00:00:02,806 iteration 1562 : loss : 0.066252, loss_ce: 0.020799
2022-01-14 00:00:04,253 iteration 1563 : loss : 0.047501, loss_ce: 0.021405
2022-01-14 00:00:05,690 iteration 1564 : loss : 0.042483, loss_ce: 0.018929
 23%|██████▉                       | 92/400 [40:19<2:12:09, 25.75s/it]2022-01-14 00:00:07,109 iteration 1565 : loss : 0.049135, loss_ce: 0.024612
2022-01-14 00:00:08,513 iteration 1566 : loss : 0.050373, loss_ce: 0.019253
2022-01-14 00:00:09,939 iteration 1567 : loss : 0.047634, loss_ce: 0.015756
2022-01-14 00:00:11,301 iteration 1568 : loss : 0.057540, loss_ce: 0.019776
2022-01-14 00:00:12,734 iteration 1569 : loss : 0.038768, loss_ce: 0.016914
2022-01-14 00:00:14,127 iteration 1570 : loss : 0.039165, loss_ce: 0.017990
2022-01-14 00:00:15,481 iteration 1571 : loss : 0.076373, loss_ce: 0.017413
2022-01-14 00:00:16,943 iteration 1572 : loss : 0.066749, loss_ce: 0.021057
2022-01-14 00:00:18,352 iteration 1573 : loss : 0.074505, loss_ce: 0.038120
2022-01-14 00:00:19,710 iteration 1574 : loss : 0.029678, loss_ce: 0.014331
2022-01-14 00:00:21,022 iteration 1575 : loss : 0.047182, loss_ce: 0.017827
2022-01-14 00:00:22,422 iteration 1576 : loss : 0.044521, loss_ce: 0.019573
2022-01-14 00:00:23,836 iteration 1577 : loss : 0.034506, loss_ce: 0.013723
2022-01-14 00:00:25,251 iteration 1578 : loss : 0.057718, loss_ce: 0.019954
2022-01-14 00:00:26,697 iteration 1579 : loss : 0.032511, loss_ce: 0.013320
2022-01-14 00:00:28,066 iteration 1580 : loss : 0.050425, loss_ce: 0.017746
2022-01-14 00:00:29,452 iteration 1581 : loss : 0.045668, loss_ce: 0.016295
 23%|██████▉                       | 93/400 [40:42<2:08:41, 25.15s/it]2022-01-14 00:00:30,983 iteration 1582 : loss : 0.056251, loss_ce: 0.020041
2022-01-14 00:00:32,358 iteration 1583 : loss : 0.065643, loss_ce: 0.019386
2022-01-14 00:00:33,768 iteration 1584 : loss : 0.039597, loss_ce: 0.020512
2022-01-14 00:00:35,166 iteration 1585 : loss : 0.046943, loss_ce: 0.014693
2022-01-14 00:00:36,536 iteration 1586 : loss : 0.047598, loss_ce: 0.020113
2022-01-14 00:00:37,827 iteration 1587 : loss : 0.030119, loss_ce: 0.012828
2022-01-14 00:00:39,263 iteration 1588 : loss : 0.053323, loss_ce: 0.024871
2022-01-14 00:00:40,678 iteration 1589 : loss : 0.038550, loss_ce: 0.015795
2022-01-14 00:00:42,218 iteration 1590 : loss : 0.044765, loss_ce: 0.019450
2022-01-14 00:00:43,579 iteration 1591 : loss : 0.039528, loss_ce: 0.012872
2022-01-14 00:00:44,991 iteration 1592 : loss : 0.053736, loss_ce: 0.019122
2022-01-14 00:00:46,488 iteration 1593 : loss : 0.057209, loss_ce: 0.022338
2022-01-14 00:00:47,959 iteration 1594 : loss : 0.050885, loss_ce: 0.018250
2022-01-14 00:00:49,374 iteration 1595 : loss : 0.034312, loss_ce: 0.011130
2022-01-14 00:00:50,784 iteration 1596 : loss : 0.054895, loss_ce: 0.024555
2022-01-14 00:00:52,176 iteration 1597 : loss : 0.074136, loss_ce: 0.034085
2022-01-14 00:00:53,618 iteration 1598 : loss : 0.062483, loss_ce: 0.026062
 24%|███████                       | 94/400 [41:07<2:06:46, 24.86s/it]2022-01-14 00:00:55,054 iteration 1599 : loss : 0.036591, loss_ce: 0.013939
2022-01-14 00:00:56,458 iteration 1600 : loss : 0.048114, loss_ce: 0.017090
2022-01-14 00:00:57,933 iteration 1601 : loss : 0.065064, loss_ce: 0.027790
2022-01-14 00:00:59,449 iteration 1602 : loss : 0.049106, loss_ce: 0.020096
2022-01-14 00:01:00,864 iteration 1603 : loss : 0.057047, loss_ce: 0.022436
2022-01-14 00:01:02,245 iteration 1604 : loss : 0.043470, loss_ce: 0.016411
2022-01-14 00:01:03,703 iteration 1605 : loss : 0.056689, loss_ce: 0.019738
2022-01-14 00:01:05,118 iteration 1606 : loss : 0.049729, loss_ce: 0.024208
2022-01-14 00:01:06,500 iteration 1607 : loss : 0.034123, loss_ce: 0.014055
2022-01-14 00:01:07,991 iteration 1608 : loss : 0.048707, loss_ce: 0.017462
2022-01-14 00:01:09,426 iteration 1609 : loss : 0.071822, loss_ce: 0.035332
2022-01-14 00:01:10,864 iteration 1610 : loss : 0.040243, loss_ce: 0.015805
2022-01-14 00:01:12,380 iteration 1611 : loss : 0.072218, loss_ce: 0.027217
2022-01-14 00:01:13,783 iteration 1612 : loss : 0.039001, loss_ce: 0.019101
2022-01-14 00:01:15,065 iteration 1613 : loss : 0.059225, loss_ce: 0.028084
2022-01-14 00:01:16,519 iteration 1614 : loss : 0.054671, loss_ce: 0.015016
2022-01-14 00:01:16,519 Training Data Eval:
2022-01-14 00:01:23,654   Average segmentation loss on training set: 0.0335
2022-01-14 00:01:23,654 Validation Data Eval:
2022-01-14 00:01:26,112   Average segmentation loss on validation set: 0.0786
2022-01-14 00:01:27,547 iteration 1615 : loss : 0.045345, loss_ce: 0.016963
 24%|███████▏                      | 95/400 [41:40<2:20:11, 27.58s/it]2022-01-14 00:01:29,072 iteration 1616 : loss : 0.054792, loss_ce: 0.022959
2022-01-14 00:01:30,507 iteration 1617 : loss : 0.059948, loss_ce: 0.017475
2022-01-14 00:01:31,825 iteration 1618 : loss : 0.037820, loss_ce: 0.018472
2022-01-14 00:01:33,156 iteration 1619 : loss : 0.035357, loss_ce: 0.012869
2022-01-14 00:01:34,469 iteration 1620 : loss : 0.046108, loss_ce: 0.015428
2022-01-14 00:01:35,885 iteration 1621 : loss : 0.063095, loss_ce: 0.034631
2022-01-14 00:01:37,403 iteration 1622 : loss : 0.061891, loss_ce: 0.025719
2022-01-14 00:01:38,804 iteration 1623 : loss : 0.062934, loss_ce: 0.028103
2022-01-14 00:01:40,165 iteration 1624 : loss : 0.039851, loss_ce: 0.016232
2022-01-14 00:01:41,541 iteration 1625 : loss : 0.039952, loss_ce: 0.016861
2022-01-14 00:01:42,923 iteration 1626 : loss : 0.038389, loss_ce: 0.016819
2022-01-14 00:01:44,326 iteration 1627 : loss : 0.057744, loss_ce: 0.021476
2022-01-14 00:01:45,812 iteration 1628 : loss : 0.050212, loss_ce: 0.023458
2022-01-14 00:01:47,214 iteration 1629 : loss : 0.037810, loss_ce: 0.016441
2022-01-14 00:01:48,579 iteration 1630 : loss : 0.040567, loss_ce: 0.015967
2022-01-14 00:01:50,108 iteration 1631 : loss : 0.052506, loss_ce: 0.024181
2022-01-14 00:01:51,605 iteration 1632 : loss : 0.045841, loss_ce: 0.018582
 24%|███████▏                      | 96/400 [42:05<2:14:21, 26.52s/it]2022-01-14 00:01:53,108 iteration 1633 : loss : 0.040500, loss_ce: 0.015258
2022-01-14 00:01:54,539 iteration 1634 : loss : 0.049185, loss_ce: 0.016539
2022-01-14 00:01:55,946 iteration 1635 : loss : 0.059033, loss_ce: 0.030215
2022-01-14 00:01:57,412 iteration 1636 : loss : 0.051804, loss_ce: 0.022503
2022-01-14 00:01:58,841 iteration 1637 : loss : 0.049916, loss_ce: 0.017680
2022-01-14 00:02:00,226 iteration 1638 : loss : 0.047289, loss_ce: 0.019283
2022-01-14 00:02:01,714 iteration 1639 : loss : 0.060664, loss_ce: 0.014153
2022-01-14 00:02:03,165 iteration 1640 : loss : 0.058223, loss_ce: 0.014480
2022-01-14 00:02:04,493 iteration 1641 : loss : 0.030480, loss_ce: 0.013156
2022-01-14 00:02:05,864 iteration 1642 : loss : 0.039791, loss_ce: 0.013495
2022-01-14 00:02:07,306 iteration 1643 : loss : 0.038275, loss_ce: 0.010794
2022-01-14 00:02:08,667 iteration 1644 : loss : 0.044995, loss_ce: 0.018192
2022-01-14 00:02:10,044 iteration 1645 : loss : 0.046342, loss_ce: 0.014668
2022-01-14 00:02:11,437 iteration 1646 : loss : 0.046342, loss_ce: 0.021859
2022-01-14 00:02:12,821 iteration 1647 : loss : 0.050129, loss_ce: 0.018017
2022-01-14 00:02:14,249 iteration 1648 : loss : 0.075362, loss_ce: 0.036806
2022-01-14 00:02:15,636 iteration 1649 : loss : 0.051989, loss_ce: 0.022177
 24%|███████▎                      | 97/400 [42:29<2:10:09, 25.78s/it]2022-01-14 00:02:17,142 iteration 1650 : loss : 0.049224, loss_ce: 0.022983
2022-01-14 00:02:18,676 iteration 1651 : loss : 0.058907, loss_ce: 0.020812
2022-01-14 00:02:20,053 iteration 1652 : loss : 0.057045, loss_ce: 0.017816
2022-01-14 00:02:21,436 iteration 1653 : loss : 0.045951, loss_ce: 0.015806
2022-01-14 00:02:22,901 iteration 1654 : loss : 0.092569, loss_ce: 0.026754
2022-01-14 00:02:24,360 iteration 1655 : loss : 0.056123, loss_ce: 0.024231
2022-01-14 00:02:25,746 iteration 1656 : loss : 0.061572, loss_ce: 0.021405
2022-01-14 00:02:27,262 iteration 1657 : loss : 0.074436, loss_ce: 0.026393
2022-01-14 00:02:28,702 iteration 1658 : loss : 0.077462, loss_ce: 0.045786
2022-01-14 00:02:30,040 iteration 1659 : loss : 0.044318, loss_ce: 0.012985
2022-01-14 00:02:31,567 iteration 1660 : loss : 0.053610, loss_ce: 0.017993
2022-01-14 00:02:33,044 iteration 1661 : loss : 0.057901, loss_ce: 0.025136
2022-01-14 00:02:34,439 iteration 1662 : loss : 0.047242, loss_ce: 0.018251
2022-01-14 00:02:35,725 iteration 1663 : loss : 0.040696, loss_ce: 0.020324
2022-01-14 00:02:37,198 iteration 1664 : loss : 0.071489, loss_ce: 0.027643
2022-01-14 00:02:38,643 iteration 1665 : loss : 0.060409, loss_ce: 0.021408
2022-01-14 00:02:40,121 iteration 1666 : loss : 0.058566, loss_ce: 0.024671
 24%|███████▎                      | 98/400 [42:53<2:07:47, 25.39s/it]2022-01-14 00:02:41,641 iteration 1667 : loss : 0.078636, loss_ce: 0.027129
2022-01-14 00:02:43,068 iteration 1668 : loss : 0.061131, loss_ce: 0.023556
2022-01-14 00:02:44,422 iteration 1669 : loss : 0.045337, loss_ce: 0.017665
2022-01-14 00:02:45,835 iteration 1670 : loss : 0.060266, loss_ce: 0.026326
2022-01-14 00:02:47,246 iteration 1671 : loss : 0.042130, loss_ce: 0.017195
2022-01-14 00:02:48,701 iteration 1672 : loss : 0.044597, loss_ce: 0.016198
2022-01-14 00:02:50,121 iteration 1673 : loss : 0.048080, loss_ce: 0.018463
2022-01-14 00:02:51,607 iteration 1674 : loss : 0.060894, loss_ce: 0.029410
2022-01-14 00:02:52,979 iteration 1675 : loss : 0.069891, loss_ce: 0.026914
2022-01-14 00:02:54,372 iteration 1676 : loss : 0.099136, loss_ce: 0.035823
2022-01-14 00:02:55,840 iteration 1677 : loss : 0.061064, loss_ce: 0.026863
2022-01-14 00:02:57,124 iteration 1678 : loss : 0.049889, loss_ce: 0.021545
2022-01-14 00:02:58,498 iteration 1679 : loss : 0.052812, loss_ce: 0.016738
2022-01-14 00:02:59,929 iteration 1680 : loss : 0.050901, loss_ce: 0.023470
2022-01-14 00:03:01,356 iteration 1681 : loss : 0.060696, loss_ce: 0.037418
2022-01-14 00:03:02,794 iteration 1682 : loss : 0.049238, loss_ce: 0.018070
2022-01-14 00:03:04,137 iteration 1683 : loss : 0.038624, loss_ce: 0.013421
 25%|███████▍                      | 99/400 [43:17<2:05:18, 24.98s/it]2022-01-14 00:03:05,635 iteration 1684 : loss : 0.044766, loss_ce: 0.014726
2022-01-14 00:03:07,028 iteration 1685 : loss : 0.048645, loss_ce: 0.016274
2022-01-14 00:03:08,406 iteration 1686 : loss : 0.033404, loss_ce: 0.013020
2022-01-14 00:03:09,745 iteration 1687 : loss : 0.059506, loss_ce: 0.026422
2022-01-14 00:03:11,260 iteration 1688 : loss : 0.037364, loss_ce: 0.016591
2022-01-14 00:03:12,681 iteration 1689 : loss : 0.051870, loss_ce: 0.021390
2022-01-14 00:03:14,130 iteration 1690 : loss : 0.053803, loss_ce: 0.025088
2022-01-14 00:03:15,457 iteration 1691 : loss : 0.090216, loss_ce: 0.023729
2022-01-14 00:03:16,920 iteration 1692 : loss : 0.080336, loss_ce: 0.026101
2022-01-14 00:03:18,196 iteration 1693 : loss : 0.037165, loss_ce: 0.016876
2022-01-14 00:03:19,620 iteration 1694 : loss : 0.029887, loss_ce: 0.012970
2022-01-14 00:03:21,103 iteration 1695 : loss : 0.048760, loss_ce: 0.019730
2022-01-14 00:03:22,564 iteration 1696 : loss : 0.079823, loss_ce: 0.026204
2022-01-14 00:03:23,972 iteration 1697 : loss : 0.046690, loss_ce: 0.018237
2022-01-14 00:03:25,412 iteration 1698 : loss : 0.054326, loss_ce: 0.023592
2022-01-14 00:03:26,816 iteration 1699 : loss : 0.054745, loss_ce: 0.027889
2022-01-14 00:03:26,816 Training Data Eval:
2022-01-14 00:03:33,777   Average segmentation loss on training set: 0.0444
2022-01-14 00:03:33,777 Validation Data Eval:
2022-01-14 00:03:36,278   Average segmentation loss on validation set: 0.1449
2022-01-14 00:03:37,700 iteration 1700 : loss : 0.060893, loss_ce: 0.023284
 25%|███████▎                     | 100/400 [43:51<2:17:45, 27.55s/it]2022-01-14 00:03:39,198 iteration 1701 : loss : 0.038143, loss_ce: 0.016625
2022-01-14 00:03:40,599 iteration 1702 : loss : 0.047907, loss_ce: 0.021249
2022-01-14 00:03:42,085 iteration 1703 : loss : 0.045644, loss_ce: 0.019224
2022-01-14 00:03:43,582 iteration 1704 : loss : 0.062402, loss_ce: 0.030685
2022-01-14 00:03:45,001 iteration 1705 : loss : 0.050133, loss_ce: 0.016725
2022-01-14 00:03:46,473 iteration 1706 : loss : 0.064207, loss_ce: 0.019241
2022-01-14 00:03:47,878 iteration 1707 : loss : 0.046327, loss_ce: 0.017966
2022-01-14 00:03:49,272 iteration 1708 : loss : 0.033892, loss_ce: 0.013498
2022-01-14 00:03:50,844 iteration 1709 : loss : 0.046310, loss_ce: 0.017583
2022-01-14 00:03:52,202 iteration 1710 : loss : 0.043556, loss_ce: 0.020068
2022-01-14 00:03:53,627 iteration 1711 : loss : 0.056476, loss_ce: 0.020005
2022-01-14 00:03:55,076 iteration 1712 : loss : 0.058695, loss_ce: 0.016791
2022-01-14 00:03:56,503 iteration 1713 : loss : 0.066171, loss_ce: 0.022950
2022-01-14 00:03:57,914 iteration 1714 : loss : 0.036122, loss_ce: 0.015785
2022-01-14 00:03:59,384 iteration 1715 : loss : 0.057453, loss_ce: 0.024072
2022-01-14 00:04:00,764 iteration 1716 : loss : 0.060325, loss_ce: 0.019289
2022-01-14 00:04:02,200 iteration 1717 : loss : 0.039776, loss_ce: 0.017603
 25%|███████▎                     | 101/400 [44:15<2:12:44, 26.64s/it]2022-01-14 00:04:03,698 iteration 1718 : loss : 0.052738, loss_ce: 0.020823
2022-01-14 00:04:05,172 iteration 1719 : loss : 0.042922, loss_ce: 0.011628
2022-01-14 00:04:06,625 iteration 1720 : loss : 0.054962, loss_ce: 0.019430
2022-01-14 00:04:08,039 iteration 1721 : loss : 0.064551, loss_ce: 0.030929
2022-01-14 00:04:09,399 iteration 1722 : loss : 0.034098, loss_ce: 0.014812
2022-01-14 00:04:10,783 iteration 1723 : loss : 0.044993, loss_ce: 0.020305
2022-01-14 00:04:12,122 iteration 1724 : loss : 0.036786, loss_ce: 0.016326
2022-01-14 00:04:13,503 iteration 1725 : loss : 0.047652, loss_ce: 0.022442
2022-01-14 00:04:15,055 iteration 1726 : loss : 0.050145, loss_ce: 0.018562
2022-01-14 00:04:16,525 iteration 1727 : loss : 0.058351, loss_ce: 0.021221
2022-01-14 00:04:18,047 iteration 1728 : loss : 0.057509, loss_ce: 0.026356
2022-01-14 00:04:19,423 iteration 1729 : loss : 0.040599, loss_ce: 0.015064
2022-01-14 00:04:20,869 iteration 1730 : loss : 0.050773, loss_ce: 0.019759
2022-01-14 00:04:22,248 iteration 1731 : loss : 0.046220, loss_ce: 0.022812
2022-01-14 00:04:23,673 iteration 1732 : loss : 0.047876, loss_ce: 0.021894
2022-01-14 00:04:25,106 iteration 1733 : loss : 0.045702, loss_ce: 0.015050
2022-01-14 00:04:26,513 iteration 1734 : loss : 0.045675, loss_ce: 0.013040
 26%|███████▍                     | 102/400 [44:39<2:08:49, 25.94s/it]2022-01-14 00:04:28,060 iteration 1735 : loss : 0.034784, loss_ce: 0.010394
2022-01-14 00:04:29,504 iteration 1736 : loss : 0.054503, loss_ce: 0.020917
2022-01-14 00:04:30,933 iteration 1737 : loss : 0.070195, loss_ce: 0.029970
2022-01-14 00:04:32,328 iteration 1738 : loss : 0.070650, loss_ce: 0.026847
2022-01-14 00:04:33,728 iteration 1739 : loss : 0.062874, loss_ce: 0.037938
2022-01-14 00:04:35,107 iteration 1740 : loss : 0.046681, loss_ce: 0.013825
2022-01-14 00:04:36,585 iteration 1741 : loss : 0.037081, loss_ce: 0.012655
2022-01-14 00:04:38,010 iteration 1742 : loss : 0.059811, loss_ce: 0.023722
2022-01-14 00:04:39,407 iteration 1743 : loss : 0.050681, loss_ce: 0.030733
2022-01-14 00:04:40,751 iteration 1744 : loss : 0.049826, loss_ce: 0.017189
2022-01-14 00:04:42,220 iteration 1745 : loss : 0.046442, loss_ce: 0.021419
2022-01-14 00:04:43,611 iteration 1746 : loss : 0.064486, loss_ce: 0.023526
2022-01-14 00:04:44,991 iteration 1747 : loss : 0.052997, loss_ce: 0.021534
2022-01-14 00:04:46,344 iteration 1748 : loss : 0.032482, loss_ce: 0.015695
2022-01-14 00:04:47,774 iteration 1749 : loss : 0.041396, loss_ce: 0.016424
2022-01-14 00:04:49,129 iteration 1750 : loss : 0.043873, loss_ce: 0.022132
2022-01-14 00:04:50,493 iteration 1751 : loss : 0.044634, loss_ce: 0.017704
 26%|███████▍                     | 103/400 [45:03<2:05:29, 25.35s/it]2022-01-14 00:04:51,951 iteration 1752 : loss : 0.063498, loss_ce: 0.029152
2022-01-14 00:04:53,433 iteration 1753 : loss : 0.074135, loss_ce: 0.040042
2022-01-14 00:04:54,873 iteration 1754 : loss : 0.039974, loss_ce: 0.017932
2022-01-14 00:04:56,332 iteration 1755 : loss : 0.049015, loss_ce: 0.016311
2022-01-14 00:04:57,788 iteration 1756 : loss : 0.044244, loss_ce: 0.020040
2022-01-14 00:04:59,210 iteration 1757 : loss : 0.091875, loss_ce: 0.021540
2022-01-14 00:05:00,627 iteration 1758 : loss : 0.051237, loss_ce: 0.022329
2022-01-14 00:05:02,012 iteration 1759 : loss : 0.058723, loss_ce: 0.022020
2022-01-14 00:05:03,462 iteration 1760 : loss : 0.040418, loss_ce: 0.020592
2022-01-14 00:05:04,818 iteration 1761 : loss : 0.037830, loss_ce: 0.018326
2022-01-14 00:05:06,285 iteration 1762 : loss : 0.081288, loss_ce: 0.031446
2022-01-14 00:05:07,659 iteration 1763 : loss : 0.076678, loss_ce: 0.029453
2022-01-14 00:05:09,136 iteration 1764 : loss : 0.103064, loss_ce: 0.030039
2022-01-14 00:05:10,615 iteration 1765 : loss : 0.066222, loss_ce: 0.020873
2022-01-14 00:05:11,984 iteration 1766 : loss : 0.044489, loss_ce: 0.019153
2022-01-14 00:05:13,422 iteration 1767 : loss : 0.057680, loss_ce: 0.022283
2022-01-14 00:05:14,906 iteration 1768 : loss : 0.053193, loss_ce: 0.020945
 26%|███████▌                     | 104/400 [45:28<2:03:40, 25.07s/it]2022-01-14 00:05:16,369 iteration 1769 : loss : 0.036824, loss_ce: 0.012291
2022-01-14 00:05:17,977 iteration 1770 : loss : 0.055062, loss_ce: 0.024327
2022-01-14 00:05:19,380 iteration 1771 : loss : 0.049860, loss_ce: 0.019057
2022-01-14 00:05:20,737 iteration 1772 : loss : 0.038564, loss_ce: 0.011225
2022-01-14 00:05:22,068 iteration 1773 : loss : 0.057415, loss_ce: 0.016692
2022-01-14 00:05:23,466 iteration 1774 : loss : 0.044368, loss_ce: 0.021059
2022-01-14 00:05:24,939 iteration 1775 : loss : 0.057727, loss_ce: 0.026713
2022-01-14 00:05:26,370 iteration 1776 : loss : 0.065209, loss_ce: 0.016744
2022-01-14 00:05:27,771 iteration 1777 : loss : 0.057510, loss_ce: 0.023991
2022-01-14 00:05:29,180 iteration 1778 : loss : 0.048017, loss_ce: 0.016949
2022-01-14 00:05:30,632 iteration 1779 : loss : 0.039639, loss_ce: 0.016509
2022-01-14 00:05:32,032 iteration 1780 : loss : 0.052045, loss_ce: 0.019467
2022-01-14 00:05:33,445 iteration 1781 : loss : 0.055289, loss_ce: 0.029223
2022-01-14 00:05:34,891 iteration 1782 : loss : 0.048440, loss_ce: 0.016605
2022-01-14 00:05:36,287 iteration 1783 : loss : 0.046416, loss_ce: 0.022999
2022-01-14 00:05:37,792 iteration 1784 : loss : 0.044688, loss_ce: 0.017208
2022-01-14 00:05:37,793 Training Data Eval:
2022-01-14 00:05:45,020   Average segmentation loss on training set: 0.0308
2022-01-14 00:05:45,021 Validation Data Eval:
2022-01-14 00:05:47,526   Average segmentation loss on validation set: 0.0700
2022-01-14 00:05:48,987 iteration 1785 : loss : 0.042376, loss_ce: 0.016773
 26%|███████▌                     | 105/400 [46:02<2:16:32, 27.77s/it]2022-01-14 00:05:50,610 iteration 1786 : loss : 0.050880, loss_ce: 0.025361
2022-01-14 00:05:52,125 iteration 1787 : loss : 0.056647, loss_ce: 0.019721
2022-01-14 00:05:53,583 iteration 1788 : loss : 0.047720, loss_ce: 0.022114
2022-01-14 00:05:55,007 iteration 1789 : loss : 0.041888, loss_ce: 0.013627
2022-01-14 00:05:56,426 iteration 1790 : loss : 0.036702, loss_ce: 0.016239
2022-01-14 00:05:57,815 iteration 1791 : loss : 0.029239, loss_ce: 0.013615
2022-01-14 00:05:59,273 iteration 1792 : loss : 0.048323, loss_ce: 0.016474
2022-01-14 00:06:00,739 iteration 1793 : loss : 0.039088, loss_ce: 0.017827
2022-01-14 00:06:02,129 iteration 1794 : loss : 0.037904, loss_ce: 0.017144
2022-01-14 00:06:03,569 iteration 1795 : loss : 0.058359, loss_ce: 0.022718
2022-01-14 00:06:04,985 iteration 1796 : loss : 0.049376, loss_ce: 0.018047
2022-01-14 00:06:06,499 iteration 1797 : loss : 0.044553, loss_ce: 0.019174
2022-01-14 00:06:07,941 iteration 1798 : loss : 0.064909, loss_ce: 0.024621
2022-01-14 00:06:09,390 iteration 1799 : loss : 0.062732, loss_ce: 0.023580
2022-01-14 00:06:10,820 iteration 1800 : loss : 0.059155, loss_ce: 0.024727
2022-01-14 00:06:12,286 iteration 1801 : loss : 0.031401, loss_ce: 0.012778
2022-01-14 00:06:13,636 iteration 1802 : loss : 0.067194, loss_ce: 0.017962
 26%|███████▋                     | 106/400 [46:27<2:11:29, 26.84s/it]2022-01-14 00:06:15,129 iteration 1803 : loss : 0.036178, loss_ce: 0.011990
2022-01-14 00:06:16,531 iteration 1804 : loss : 0.062913, loss_ce: 0.015301
2022-01-14 00:06:17,903 iteration 1805 : loss : 0.040803, loss_ce: 0.017361
2022-01-14 00:06:19,299 iteration 1806 : loss : 0.043230, loss_ce: 0.014189
2022-01-14 00:06:20,740 iteration 1807 : loss : 0.044513, loss_ce: 0.014137
2022-01-14 00:06:22,177 iteration 1808 : loss : 0.064977, loss_ce: 0.023757
2022-01-14 00:06:23,594 iteration 1809 : loss : 0.045078, loss_ce: 0.019478
2022-01-14 00:06:25,044 iteration 1810 : loss : 0.045065, loss_ce: 0.018989
2022-01-14 00:06:26,477 iteration 1811 : loss : 0.046903, loss_ce: 0.017817
2022-01-14 00:06:27,949 iteration 1812 : loss : 0.076059, loss_ce: 0.039377
2022-01-14 00:06:29,405 iteration 1813 : loss : 0.080811, loss_ce: 0.028269
2022-01-14 00:06:30,904 iteration 1814 : loss : 0.079656, loss_ce: 0.028723
2022-01-14 00:06:32,324 iteration 1815 : loss : 0.034039, loss_ce: 0.017081
2022-01-14 00:06:33,806 iteration 1816 : loss : 0.068106, loss_ce: 0.025326
2022-01-14 00:06:35,233 iteration 1817 : loss : 0.068591, loss_ce: 0.020112
2022-01-14 00:06:36,729 iteration 1818 : loss : 0.034824, loss_ce: 0.018554
2022-01-14 00:06:38,112 iteration 1819 : loss : 0.042535, loss_ce: 0.018017
 27%|███████▊                     | 107/400 [46:51<2:07:34, 26.13s/it]2022-01-14 00:06:39,643 iteration 1820 : loss : 0.073279, loss_ce: 0.021412
2022-01-14 00:06:41,014 iteration 1821 : loss : 0.036493, loss_ce: 0.012044
2022-01-14 00:06:42,381 iteration 1822 : loss : 0.050452, loss_ce: 0.024338
2022-01-14 00:06:43,832 iteration 1823 : loss : 0.045487, loss_ce: 0.016789
2022-01-14 00:06:45,240 iteration 1824 : loss : 0.046957, loss_ce: 0.013349
2022-01-14 00:06:46,653 iteration 1825 : loss : 0.053918, loss_ce: 0.017578
2022-01-14 00:06:47,977 iteration 1826 : loss : 0.037526, loss_ce: 0.016827
2022-01-14 00:06:49,334 iteration 1827 : loss : 0.078271, loss_ce: 0.024319
2022-01-14 00:06:50,785 iteration 1828 : loss : 0.045287, loss_ce: 0.023906
2022-01-14 00:06:52,234 iteration 1829 : loss : 0.087567, loss_ce: 0.028165
2022-01-14 00:06:53,639 iteration 1830 : loss : 0.049308, loss_ce: 0.021423
2022-01-14 00:06:55,019 iteration 1831 : loss : 0.042945, loss_ce: 0.019118
2022-01-14 00:06:56,414 iteration 1832 : loss : 0.030608, loss_ce: 0.010757
2022-01-14 00:06:57,787 iteration 1833 : loss : 0.035460, loss_ce: 0.020285
2022-01-14 00:06:59,251 iteration 1834 : loss : 0.039768, loss_ce: 0.014484
2022-01-14 00:07:00,581 iteration 1835 : loss : 0.040877, loss_ce: 0.014582
2022-01-14 00:07:01,954 iteration 1836 : loss : 0.048161, loss_ce: 0.018728
 27%|███████▊                     | 108/400 [47:15<2:03:49, 25.44s/it]2022-01-14 00:07:03,351 iteration 1837 : loss : 0.063128, loss_ce: 0.016231
2022-01-14 00:07:04,811 iteration 1838 : loss : 0.055831, loss_ce: 0.026537
2022-01-14 00:07:06,159 iteration 1839 : loss : 0.053937, loss_ce: 0.027243
2022-01-14 00:07:07,573 iteration 1840 : loss : 0.066326, loss_ce: 0.019530
2022-01-14 00:07:08,987 iteration 1841 : loss : 0.039709, loss_ce: 0.013195
2022-01-14 00:07:10,489 iteration 1842 : loss : 0.038277, loss_ce: 0.016560
2022-01-14 00:07:11,927 iteration 1843 : loss : 0.047950, loss_ce: 0.019698
2022-01-14 00:07:13,344 iteration 1844 : loss : 0.042986, loss_ce: 0.016604
2022-01-14 00:07:14,767 iteration 1845 : loss : 0.041534, loss_ce: 0.018372
2022-01-14 00:07:16,202 iteration 1846 : loss : 0.046072, loss_ce: 0.016281
2022-01-14 00:07:17,515 iteration 1847 : loss : 0.035245, loss_ce: 0.012821
2022-01-14 00:07:18,918 iteration 1848 : loss : 0.048471, loss_ce: 0.016540
2022-01-14 00:07:20,312 iteration 1849 : loss : 0.048258, loss_ce: 0.017913
2022-01-14 00:07:21,735 iteration 1850 : loss : 0.047532, loss_ce: 0.015914
2022-01-14 00:07:23,184 iteration 1851 : loss : 0.049824, loss_ce: 0.023335
2022-01-14 00:07:24,495 iteration 1852 : loss : 0.042545, loss_ce: 0.023645
2022-01-14 00:07:25,925 iteration 1853 : loss : 0.037753, loss_ce: 0.018008
 27%|███████▉                     | 109/400 [47:39<2:01:15, 25.00s/it]2022-01-14 00:07:27,422 iteration 1854 : loss : 0.119191, loss_ce: 0.043321
2022-01-14 00:07:28,869 iteration 1855 : loss : 0.040173, loss_ce: 0.016190
2022-01-14 00:07:30,179 iteration 1856 : loss : 0.049307, loss_ce: 0.020779
2022-01-14 00:07:31,498 iteration 1857 : loss : 0.036752, loss_ce: 0.017496
2022-01-14 00:07:32,847 iteration 1858 : loss : 0.028772, loss_ce: 0.013796
2022-01-14 00:07:34,269 iteration 1859 : loss : 0.037896, loss_ce: 0.014952
2022-01-14 00:07:35,723 iteration 1860 : loss : 0.050604, loss_ce: 0.016914
2022-01-14 00:07:37,165 iteration 1861 : loss : 0.034050, loss_ce: 0.015602
2022-01-14 00:07:38,608 iteration 1862 : loss : 0.031404, loss_ce: 0.015234
2022-01-14 00:07:40,060 iteration 1863 : loss : 0.061961, loss_ce: 0.024379
2022-01-14 00:07:41,510 iteration 1864 : loss : 0.049585, loss_ce: 0.019508
2022-01-14 00:07:42,911 iteration 1865 : loss : 0.047105, loss_ce: 0.015280
2022-01-14 00:07:44,320 iteration 1866 : loss : 0.030445, loss_ce: 0.010913
2022-01-14 00:07:45,632 iteration 1867 : loss : 0.035019, loss_ce: 0.010946
2022-01-14 00:07:47,010 iteration 1868 : loss : 0.039792, loss_ce: 0.013731
2022-01-14 00:07:48,372 iteration 1869 : loss : 0.039345, loss_ce: 0.018815
2022-01-14 00:07:48,372 Training Data Eval:
2022-01-14 00:07:55,430   Average segmentation loss on training set: 0.0487
2022-01-14 00:07:55,431 Validation Data Eval:
2022-01-14 00:07:57,884   Average segmentation loss on validation set: 0.1605
2022-01-14 00:07:59,337 iteration 1870 : loss : 0.051669, loss_ce: 0.019673
 28%|███████▉                     | 110/400 [48:12<2:13:02, 27.53s/it]2022-01-14 00:08:00,848 iteration 1871 : loss : 0.046747, loss_ce: 0.012882
2022-01-14 00:08:02,301 iteration 1872 : loss : 0.031386, loss_ce: 0.010458
2022-01-14 00:08:03,758 iteration 1873 : loss : 0.054794, loss_ce: 0.017114
2022-01-14 00:08:05,196 iteration 1874 : loss : 0.067522, loss_ce: 0.020656
2022-01-14 00:08:06,533 iteration 1875 : loss : 0.028183, loss_ce: 0.011972
2022-01-14 00:08:07,846 iteration 1876 : loss : 0.028876, loss_ce: 0.013621
2022-01-14 00:08:09,285 iteration 1877 : loss : 0.033263, loss_ce: 0.010878
2022-01-14 00:08:10,731 iteration 1878 : loss : 0.053778, loss_ce: 0.029875
2022-01-14 00:08:12,146 iteration 1879 : loss : 0.042543, loss_ce: 0.014191
2022-01-14 00:08:13,570 iteration 1880 : loss : 0.054445, loss_ce: 0.022417
2022-01-14 00:08:14,963 iteration 1881 : loss : 0.075105, loss_ce: 0.042997
2022-01-14 00:08:16,448 iteration 1882 : loss : 0.079632, loss_ce: 0.029049
2022-01-14 00:08:17,865 iteration 1883 : loss : 0.025416, loss_ce: 0.008378
2022-01-14 00:08:19,226 iteration 1884 : loss : 0.031300, loss_ce: 0.011052
2022-01-14 00:08:20,563 iteration 1885 : loss : 0.028752, loss_ce: 0.011017
2022-01-14 00:08:21,972 iteration 1886 : loss : 0.064262, loss_ce: 0.026349
2022-01-14 00:08:23,382 iteration 1887 : loss : 0.066301, loss_ce: 0.028367
 28%|████████                     | 111/400 [48:36<2:07:32, 26.48s/it]2022-01-14 00:08:24,958 iteration 1888 : loss : 0.053477, loss_ce: 0.014995
2022-01-14 00:08:26,307 iteration 1889 : loss : 0.048054, loss_ce: 0.016402
2022-01-14 00:08:27,643 iteration 1890 : loss : 0.039118, loss_ce: 0.017404
2022-01-14 00:08:28,990 iteration 1891 : loss : 0.035381, loss_ce: 0.012654
2022-01-14 00:08:30,383 iteration 1892 : loss : 0.045520, loss_ce: 0.023050
2022-01-14 00:08:31,829 iteration 1893 : loss : 0.038582, loss_ce: 0.012864
2022-01-14 00:08:33,235 iteration 1894 : loss : 0.056079, loss_ce: 0.024079
2022-01-14 00:08:34,581 iteration 1895 : loss : 0.028418, loss_ce: 0.011469
2022-01-14 00:08:36,067 iteration 1896 : loss : 0.054141, loss_ce: 0.021422
2022-01-14 00:08:37,493 iteration 1897 : loss : 0.068749, loss_ce: 0.024226
2022-01-14 00:08:38,968 iteration 1898 : loss : 0.048012, loss_ce: 0.021508
2022-01-14 00:08:40,379 iteration 1899 : loss : 0.043210, loss_ce: 0.013530
2022-01-14 00:08:41,728 iteration 1900 : loss : 0.053176, loss_ce: 0.021043
2022-01-14 00:08:43,054 iteration 1901 : loss : 0.034140, loss_ce: 0.011443
2022-01-14 00:08:44,456 iteration 1902 : loss : 0.041506, loss_ce: 0.016052
2022-01-14 00:08:45,892 iteration 1903 : loss : 0.042315, loss_ce: 0.016458
2022-01-14 00:08:47,358 iteration 1904 : loss : 0.041648, loss_ce: 0.018163
 28%|████████                     | 112/400 [49:00<2:03:30, 25.73s/it]2022-01-14 00:08:48,751 iteration 1905 : loss : 0.038063, loss_ce: 0.016944
2022-01-14 00:08:50,193 iteration 1906 : loss : 0.049150, loss_ce: 0.016426
2022-01-14 00:08:51,662 iteration 1907 : loss : 0.045599, loss_ce: 0.021499
2022-01-14 00:08:53,199 iteration 1908 : loss : 0.046710, loss_ce: 0.017829
2022-01-14 00:08:54,528 iteration 1909 : loss : 0.032838, loss_ce: 0.013257
2022-01-14 00:08:55,910 iteration 1910 : loss : 0.039507, loss_ce: 0.014180
2022-01-14 00:08:57,343 iteration 1911 : loss : 0.028316, loss_ce: 0.012551
2022-01-14 00:08:58,868 iteration 1912 : loss : 0.048559, loss_ce: 0.020259
2022-01-14 00:09:00,303 iteration 1913 : loss : 0.044529, loss_ce: 0.015477
2022-01-14 00:09:01,814 iteration 1914 : loss : 0.047402, loss_ce: 0.018654
2022-01-14 00:09:03,219 iteration 1915 : loss : 0.031988, loss_ce: 0.011956
2022-01-14 00:09:04,598 iteration 1916 : loss : 0.038353, loss_ce: 0.012891
2022-01-14 00:09:05,994 iteration 1917 : loss : 0.032647, loss_ce: 0.013634
2022-01-14 00:09:07,435 iteration 1918 : loss : 0.043818, loss_ce: 0.020677
2022-01-14 00:09:08,806 iteration 1919 : loss : 0.038555, loss_ce: 0.014109
2022-01-14 00:09:10,177 iteration 1920 : loss : 0.037575, loss_ce: 0.016628
2022-01-14 00:09:11,672 iteration 1921 : loss : 0.043359, loss_ce: 0.016246
 28%|████████▏                    | 113/400 [49:25<2:01:02, 25.31s/it]2022-01-14 00:09:13,197 iteration 1922 : loss : 0.044105, loss_ce: 0.018485
2022-01-14 00:09:14,566 iteration 1923 : loss : 0.032084, loss_ce: 0.011899
2022-01-14 00:09:16,027 iteration 1924 : loss : 0.072814, loss_ce: 0.020984
2022-01-14 00:09:17,381 iteration 1925 : loss : 0.065879, loss_ce: 0.017395
2022-01-14 00:09:18,851 iteration 1926 : loss : 0.031499, loss_ce: 0.011095
2022-01-14 00:09:20,320 iteration 1927 : loss : 0.045285, loss_ce: 0.020611
2022-01-14 00:09:21,689 iteration 1928 : loss : 0.043699, loss_ce: 0.013890
2022-01-14 00:09:23,224 iteration 1929 : loss : 0.057242, loss_ce: 0.026285
2022-01-14 00:09:24,633 iteration 1930 : loss : 0.043947, loss_ce: 0.020595
2022-01-14 00:09:26,106 iteration 1931 : loss : 0.054675, loss_ce: 0.020488
2022-01-14 00:09:27,537 iteration 1932 : loss : 0.071805, loss_ce: 0.020444
2022-01-14 00:09:28,990 iteration 1933 : loss : 0.061344, loss_ce: 0.022159
2022-01-14 00:09:30,377 iteration 1934 : loss : 0.061627, loss_ce: 0.018080
2022-01-14 00:09:31,791 iteration 1935 : loss : 0.031445, loss_ce: 0.012538
2022-01-14 00:09:33,193 iteration 1936 : loss : 0.037949, loss_ce: 0.014921
2022-01-14 00:09:34,542 iteration 1937 : loss : 0.038632, loss_ce: 0.012328
2022-01-14 00:09:35,963 iteration 1938 : loss : 0.045609, loss_ce: 0.018943
 28%|████████▎                    | 114/400 [49:49<1:59:10, 25.00s/it]2022-01-14 00:09:37,468 iteration 1939 : loss : 0.049715, loss_ce: 0.018986
2022-01-14 00:09:38,817 iteration 1940 : loss : 0.048936, loss_ce: 0.023706
2022-01-14 00:09:40,235 iteration 1941 : loss : 0.046830, loss_ce: 0.019070
2022-01-14 00:09:41,650 iteration 1942 : loss : 0.040601, loss_ce: 0.013213
2022-01-14 00:09:43,039 iteration 1943 : loss : 0.046227, loss_ce: 0.015859
2022-01-14 00:09:44,459 iteration 1944 : loss : 0.052473, loss_ce: 0.020367
2022-01-14 00:09:45,905 iteration 1945 : loss : 0.042999, loss_ce: 0.018439
2022-01-14 00:09:47,319 iteration 1946 : loss : 0.063938, loss_ce: 0.015255
2022-01-14 00:09:48,777 iteration 1947 : loss : 0.045080, loss_ce: 0.012971
2022-01-14 00:09:50,244 iteration 1948 : loss : 0.040095, loss_ce: 0.017128
2022-01-14 00:09:51,645 iteration 1949 : loss : 0.033102, loss_ce: 0.012697
2022-01-14 00:09:53,113 iteration 1950 : loss : 0.065621, loss_ce: 0.023963
2022-01-14 00:09:54,548 iteration 1951 : loss : 0.037737, loss_ce: 0.015457
2022-01-14 00:09:55,976 iteration 1952 : loss : 0.046390, loss_ce: 0.021797
2022-01-14 00:09:57,309 iteration 1953 : loss : 0.061845, loss_ce: 0.035546
2022-01-14 00:09:58,727 iteration 1954 : loss : 0.039880, loss_ce: 0.020234
2022-01-14 00:09:58,727 Training Data Eval:
2022-01-14 00:10:05,846   Average segmentation loss on training set: 0.0354
2022-01-14 00:10:05,846 Validation Data Eval:
2022-01-14 00:10:08,354   Average segmentation loss on validation set: 0.0766
2022-01-14 00:10:09,830 iteration 1955 : loss : 0.039949, loss_ce: 0.017465
 29%|████████▎                    | 115/400 [50:23<2:11:22, 27.66s/it]2022-01-14 00:10:11,276 iteration 1956 : loss : 0.044364, loss_ce: 0.016524
2022-01-14 00:10:12,736 iteration 1957 : loss : 0.063103, loss_ce: 0.030851
2022-01-14 00:10:14,140 iteration 1958 : loss : 0.065385, loss_ce: 0.023089
2022-01-14 00:10:15,534 iteration 1959 : loss : 0.044084, loss_ce: 0.013708
2022-01-14 00:10:16,864 iteration 1960 : loss : 0.048298, loss_ce: 0.020302
2022-01-14 00:10:18,180 iteration 1961 : loss : 0.032016, loss_ce: 0.013426
2022-01-14 00:10:19,649 iteration 1962 : loss : 0.033446, loss_ce: 0.013804
2022-01-14 00:10:21,022 iteration 1963 : loss : 0.033821, loss_ce: 0.012643
2022-01-14 00:10:22,474 iteration 1964 : loss : 0.048623, loss_ce: 0.017025
2022-01-14 00:10:23,794 iteration 1965 : loss : 0.035648, loss_ce: 0.017689
2022-01-14 00:10:25,207 iteration 1966 : loss : 0.038705, loss_ce: 0.016959
2022-01-14 00:10:26,733 iteration 1967 : loss : 0.038655, loss_ce: 0.015239
2022-01-14 00:10:28,291 iteration 1968 : loss : 0.087552, loss_ce: 0.036410
2022-01-14 00:10:29,751 iteration 1969 : loss : 0.043656, loss_ce: 0.018228
2022-01-14 00:10:31,080 iteration 1970 : loss : 0.034870, loss_ce: 0.013461
2022-01-14 00:10:32,482 iteration 1971 : loss : 0.041818, loss_ce: 0.014814
2022-01-14 00:10:33,894 iteration 1972 : loss : 0.054088, loss_ce: 0.016614
 29%|████████▍                    | 116/400 [50:47<2:05:49, 26.58s/it]2022-01-14 00:10:35,302 iteration 1973 : loss : 0.034639, loss_ce: 0.015929
2022-01-14 00:10:36,654 iteration 1974 : loss : 0.039492, loss_ce: 0.014617
2022-01-14 00:10:38,073 iteration 1975 : loss : 0.051352, loss_ce: 0.019843
2022-01-14 00:10:39,450 iteration 1976 : loss : 0.057503, loss_ce: 0.027988
2022-01-14 00:10:40,901 iteration 1977 : loss : 0.031750, loss_ce: 0.011510
2022-01-14 00:10:42,395 iteration 1978 : loss : 0.047581, loss_ce: 0.016434
2022-01-14 00:10:43,729 iteration 1979 : loss : 0.036434, loss_ce: 0.015033
2022-01-14 00:10:45,071 iteration 1980 : loss : 0.029141, loss_ce: 0.009938
2022-01-14 00:10:46,443 iteration 1981 : loss : 0.031797, loss_ce: 0.015246
2022-01-14 00:10:47,895 iteration 1982 : loss : 0.058632, loss_ce: 0.022774
2022-01-14 00:10:49,223 iteration 1983 : loss : 0.047572, loss_ce: 0.016765
2022-01-14 00:10:50,700 iteration 1984 : loss : 0.052675, loss_ce: 0.021741
2022-01-14 00:10:52,114 iteration 1985 : loss : 0.047621, loss_ce: 0.018838
2022-01-14 00:10:53,579 iteration 1986 : loss : 0.043478, loss_ce: 0.014150
2022-01-14 00:10:54,976 iteration 1987 : loss : 0.029546, loss_ce: 0.010073
2022-01-14 00:10:56,310 iteration 1988 : loss : 0.058350, loss_ce: 0.024101
2022-01-14 00:10:57,704 iteration 1989 : loss : 0.069425, loss_ce: 0.020919
 29%|████████▍                    | 117/400 [51:11<2:01:27, 25.75s/it]2022-01-14 00:10:59,183 iteration 1990 : loss : 0.051481, loss_ce: 0.014578
2022-01-14 00:11:00,512 iteration 1991 : loss : 0.027774, loss_ce: 0.011160
2022-01-14 00:11:01,927 iteration 1992 : loss : 0.031596, loss_ce: 0.011564
2022-01-14 00:11:03,359 iteration 1993 : loss : 0.031206, loss_ce: 0.011027
2022-01-14 00:11:04,812 iteration 1994 : loss : 0.033987, loss_ce: 0.014879
2022-01-14 00:11:06,183 iteration 1995 : loss : 0.034088, loss_ce: 0.013331
2022-01-14 00:11:07,630 iteration 1996 : loss : 0.037161, loss_ce: 0.015094
2022-01-14 00:11:08,974 iteration 1997 : loss : 0.033173, loss_ce: 0.013130
2022-01-14 00:11:10,369 iteration 1998 : loss : 0.030463, loss_ce: 0.011373
2022-01-14 00:11:11,813 iteration 1999 : loss : 0.043952, loss_ce: 0.018884
2022-01-14 00:11:13,204 iteration 2000 : loss : 0.041553, loss_ce: 0.019648
2022-01-14 00:11:14,551 iteration 2001 : loss : 0.055956, loss_ce: 0.018197
2022-01-14 00:11:16,013 iteration 2002 : loss : 0.035446, loss_ce: 0.014011
2022-01-14 00:11:17,357 iteration 2003 : loss : 0.045349, loss_ce: 0.014692
2022-01-14 00:11:18,774 iteration 2004 : loss : 0.040882, loss_ce: 0.020269
2022-01-14 00:11:20,139 iteration 2005 : loss : 0.034995, loss_ce: 0.016934
2022-01-14 00:11:21,519 iteration 2006 : loss : 0.051499, loss_ce: 0.018363
 30%|████████▌                    | 118/400 [51:34<1:58:20, 25.18s/it]2022-01-14 00:11:23,096 iteration 2007 : loss : 0.047173, loss_ce: 0.017097
2022-01-14 00:11:24,524 iteration 2008 : loss : 0.035629, loss_ce: 0.014468
2022-01-14 00:11:25,903 iteration 2009 : loss : 0.031210, loss_ce: 0.013687
2022-01-14 00:11:27,365 iteration 2010 : loss : 0.045280, loss_ce: 0.017536
2022-01-14 00:11:28,749 iteration 2011 : loss : 0.043818, loss_ce: 0.013936
2022-01-14 00:11:30,109 iteration 2012 : loss : 0.029659, loss_ce: 0.011182
2022-01-14 00:11:31,495 iteration 2013 : loss : 0.035813, loss_ce: 0.017841
2022-01-14 00:11:32,925 iteration 2014 : loss : 0.027651, loss_ce: 0.011504
2022-01-14 00:11:34,364 iteration 2015 : loss : 0.051188, loss_ce: 0.017562
2022-01-14 00:11:35,851 iteration 2016 : loss : 0.047219, loss_ce: 0.021208
2022-01-14 00:11:37,277 iteration 2017 : loss : 0.041610, loss_ce: 0.014949
2022-01-14 00:11:38,620 iteration 2018 : loss : 0.036618, loss_ce: 0.012581
2022-01-14 00:11:40,038 iteration 2019 : loss : 0.044914, loss_ce: 0.022143
2022-01-14 00:11:41,430 iteration 2020 : loss : 0.041727, loss_ce: 0.014681
2022-01-14 00:11:42,811 iteration 2021 : loss : 0.027889, loss_ce: 0.009829
2022-01-14 00:11:44,223 iteration 2022 : loss : 0.043048, loss_ce: 0.014595
2022-01-14 00:11:45,632 iteration 2023 : loss : 0.032747, loss_ce: 0.014046
 30%|████████▋                    | 119/400 [51:59<1:56:22, 24.85s/it]2022-01-14 00:11:47,111 iteration 2024 : loss : 0.074928, loss_ce: 0.038769
2022-01-14 00:11:48,680 iteration 2025 : loss : 0.077006, loss_ce: 0.027384
2022-01-14 00:11:50,044 iteration 2026 : loss : 0.033607, loss_ce: 0.011179
2022-01-14 00:11:51,489 iteration 2027 : loss : 0.048685, loss_ce: 0.017294
2022-01-14 00:11:52,822 iteration 2028 : loss : 0.042839, loss_ce: 0.022147
2022-01-14 00:11:54,183 iteration 2029 : loss : 0.042248, loss_ce: 0.011846
2022-01-14 00:11:55,632 iteration 2030 : loss : 0.034650, loss_ce: 0.012365
2022-01-14 00:11:57,079 iteration 2031 : loss : 0.054274, loss_ce: 0.020167
2022-01-14 00:11:58,492 iteration 2032 : loss : 0.040227, loss_ce: 0.018125
2022-01-14 00:11:59,803 iteration 2033 : loss : 0.037199, loss_ce: 0.019105
2022-01-14 00:12:01,177 iteration 2034 : loss : 0.045130, loss_ce: 0.015485
2022-01-14 00:12:02,604 iteration 2035 : loss : 0.046857, loss_ce: 0.017380
2022-01-14 00:12:03,994 iteration 2036 : loss : 0.039337, loss_ce: 0.018124
2022-01-14 00:12:05,383 iteration 2037 : loss : 0.034998, loss_ce: 0.014637
2022-01-14 00:12:06,895 iteration 2038 : loss : 0.063049, loss_ce: 0.019146
2022-01-14 00:12:08,327 iteration 2039 : loss : 0.038159, loss_ce: 0.013697
2022-01-14 00:12:08,327 Training Data Eval:
2022-01-14 00:12:15,397   Average segmentation loss on training set: 0.0272
2022-01-14 00:12:15,397 Validation Data Eval:
2022-01-14 00:12:17,869   Average segmentation loss on validation set: 0.0842
2022-01-14 00:12:19,368 iteration 2040 : loss : 0.040225, loss_ce: 0.017166
 30%|████████▋                    | 120/400 [52:32<2:08:24, 27.52s/it]2022-01-14 00:12:20,791 iteration 2041 : loss : 0.031114, loss_ce: 0.013315
2022-01-14 00:12:22,218 iteration 2042 : loss : 0.050279, loss_ce: 0.017790
2022-01-14 00:12:23,639 iteration 2043 : loss : 0.035383, loss_ce: 0.013445
2022-01-14 00:12:25,014 iteration 2044 : loss : 0.066979, loss_ce: 0.031648
2022-01-14 00:12:26,513 iteration 2045 : loss : 0.050548, loss_ce: 0.018850
2022-01-14 00:12:27,920 iteration 2046 : loss : 0.064976, loss_ce: 0.014122
2022-01-14 00:12:29,288 iteration 2047 : loss : 0.040665, loss_ce: 0.014532
2022-01-14 00:12:30,623 iteration 2048 : loss : 0.045623, loss_ce: 0.018766
2022-01-14 00:12:32,084 iteration 2049 : loss : 0.072580, loss_ce: 0.038853
2022-01-14 00:12:33,519 iteration 2050 : loss : 0.035095, loss_ce: 0.010305
2022-01-14 00:12:34,901 iteration 2051 : loss : 0.037177, loss_ce: 0.015808
2022-01-14 00:12:36,347 iteration 2052 : loss : 0.037408, loss_ce: 0.015873
2022-01-14 00:12:37,768 iteration 2053 : loss : 0.038252, loss_ce: 0.015712
2022-01-14 00:12:39,197 iteration 2054 : loss : 0.041883, loss_ce: 0.016861
2022-01-14 00:12:40,626 iteration 2055 : loss : 0.055223, loss_ce: 0.019472
2022-01-14 00:12:42,017 iteration 2056 : loss : 0.030037, loss_ce: 0.010805
2022-01-14 00:12:43,391 iteration 2057 : loss : 0.040711, loss_ce: 0.015627
 30%|████████▊                    | 121/400 [52:56<2:03:04, 26.47s/it]2022-01-14 00:12:44,848 iteration 2058 : loss : 0.034259, loss_ce: 0.015786
2022-01-14 00:12:46,326 iteration 2059 : loss : 0.064082, loss_ce: 0.020183
2022-01-14 00:12:47,799 iteration 2060 : loss : 0.049914, loss_ce: 0.020226
2022-01-14 00:12:49,200 iteration 2061 : loss : 0.033436, loss_ce: 0.015510
2022-01-14 00:12:50,557 iteration 2062 : loss : 0.045299, loss_ce: 0.017899
2022-01-14 00:12:52,114 iteration 2063 : loss : 0.060390, loss_ce: 0.026707
2022-01-14 00:12:53,541 iteration 2064 : loss : 0.036887, loss_ce: 0.014115
2022-01-14 00:12:55,010 iteration 2065 : loss : 0.070159, loss_ce: 0.030513
2022-01-14 00:12:56,399 iteration 2066 : loss : 0.034862, loss_ce: 0.014271
2022-01-14 00:12:57,879 iteration 2067 : loss : 0.055827, loss_ce: 0.019995
2022-01-14 00:12:59,232 iteration 2068 : loss : 0.029595, loss_ce: 0.011657
2022-01-14 00:13:00,661 iteration 2069 : loss : 0.072547, loss_ce: 0.043900
2022-01-14 00:13:02,140 iteration 2070 : loss : 0.042941, loss_ce: 0.019233
2022-01-14 00:13:03,511 iteration 2071 : loss : 0.031772, loss_ce: 0.012565
2022-01-14 00:13:04,873 iteration 2072 : loss : 0.036036, loss_ce: 0.017577
2022-01-14 00:13:06,331 iteration 2073 : loss : 0.048182, loss_ce: 0.019111
2022-01-14 00:13:07,672 iteration 2074 : loss : 0.039659, loss_ce: 0.012104
 30%|████████▊                    | 122/400 [53:21<1:59:35, 25.81s/it]2022-01-14 00:13:09,121 iteration 2075 : loss : 0.033987, loss_ce: 0.016225
2022-01-14 00:13:10,564 iteration 2076 : loss : 0.040877, loss_ce: 0.019037
2022-01-14 00:13:11,994 iteration 2077 : loss : 0.064930, loss_ce: 0.026755
2022-01-14 00:13:13,454 iteration 2078 : loss : 0.045126, loss_ce: 0.018425
2022-01-14 00:13:14,891 iteration 2079 : loss : 0.041895, loss_ce: 0.016713
2022-01-14 00:13:16,254 iteration 2080 : loss : 0.045563, loss_ce: 0.014965
2022-01-14 00:13:17,587 iteration 2081 : loss : 0.038138, loss_ce: 0.013981
2022-01-14 00:13:18,994 iteration 2082 : loss : 0.049196, loss_ce: 0.011867
2022-01-14 00:13:20,366 iteration 2083 : loss : 0.032336, loss_ce: 0.013115
2022-01-14 00:13:21,702 iteration 2084 : loss : 0.038973, loss_ce: 0.018501
2022-01-14 00:13:23,136 iteration 2085 : loss : 0.053010, loss_ce: 0.010501
2022-01-14 00:13:24,631 iteration 2086 : loss : 0.024416, loss_ce: 0.008833
2022-01-14 00:13:25,955 iteration 2087 : loss : 0.030450, loss_ce: 0.010196
2022-01-14 00:13:27,383 iteration 2088 : loss : 0.032662, loss_ce: 0.012136
2022-01-14 00:13:28,830 iteration 2089 : loss : 0.030880, loss_ce: 0.012144
2022-01-14 00:13:30,258 iteration 2090 : loss : 0.034519, loss_ce: 0.016502
2022-01-14 00:13:31,782 iteration 2091 : loss : 0.056667, loss_ce: 0.024354
 31%|████████▉                    | 123/400 [53:45<1:56:48, 25.30s/it]2022-01-14 00:13:33,227 iteration 2092 : loss : 0.029546, loss_ce: 0.009785
2022-01-14 00:13:34,569 iteration 2093 : loss : 0.022828, loss_ce: 0.009463
2022-01-14 00:13:36,019 iteration 2094 : loss : 0.043994, loss_ce: 0.016259
2022-01-14 00:13:37,583 iteration 2095 : loss : 0.055695, loss_ce: 0.023715
2022-01-14 00:13:38,978 iteration 2096 : loss : 0.028418, loss_ce: 0.011895
2022-01-14 00:13:40,356 iteration 2097 : loss : 0.061869, loss_ce: 0.021930
2022-01-14 00:13:41,687 iteration 2098 : loss : 0.039405, loss_ce: 0.014104
2022-01-14 00:13:43,078 iteration 2099 : loss : 0.026221, loss_ce: 0.010526
2022-01-14 00:13:44,525 iteration 2100 : loss : 0.040195, loss_ce: 0.014491
2022-01-14 00:13:45,829 iteration 2101 : loss : 0.034727, loss_ce: 0.010565
2022-01-14 00:13:47,272 iteration 2102 : loss : 0.039714, loss_ce: 0.016281
2022-01-14 00:13:48,620 iteration 2103 : loss : 0.038408, loss_ce: 0.019303
2022-01-14 00:13:49,931 iteration 2104 : loss : 0.036589, loss_ce: 0.014696
2022-01-14 00:13:51,334 iteration 2105 : loss : 0.039304, loss_ce: 0.015844
2022-01-14 00:13:52,770 iteration 2106 : loss : 0.051090, loss_ce: 0.021839
2022-01-14 00:13:54,145 iteration 2107 : loss : 0.037141, loss_ce: 0.013112
2022-01-14 00:13:55,501 iteration 2108 : loss : 0.029207, loss_ce: 0.011083
 31%|████████▉                    | 124/400 [54:08<1:54:13, 24.83s/it]2022-01-14 00:13:56,983 iteration 2109 : loss : 0.066677, loss_ce: 0.017869
2022-01-14 00:13:58,397 iteration 2110 : loss : 0.054809, loss_ce: 0.023377
2022-01-14 00:13:59,863 iteration 2111 : loss : 0.028756, loss_ce: 0.009946
2022-01-14 00:14:01,361 iteration 2112 : loss : 0.037951, loss_ce: 0.014915
2022-01-14 00:14:02,812 iteration 2113 : loss : 0.043914, loss_ce: 0.015865
2022-01-14 00:14:04,269 iteration 2114 : loss : 0.043922, loss_ce: 0.014537
2022-01-14 00:14:05,627 iteration 2115 : loss : 0.026130, loss_ce: 0.008697
2022-01-14 00:14:06,981 iteration 2116 : loss : 0.036397, loss_ce: 0.011581
2022-01-14 00:14:08,492 iteration 2117 : loss : 0.056428, loss_ce: 0.017847
2022-01-14 00:14:09,906 iteration 2118 : loss : 0.049818, loss_ce: 0.024380
2022-01-14 00:14:11,450 iteration 2119 : loss : 0.036147, loss_ce: 0.016283
2022-01-14 00:14:12,911 iteration 2120 : loss : 0.049856, loss_ce: 0.030590
2022-01-14 00:14:14,378 iteration 2121 : loss : 0.051063, loss_ce: 0.022686
2022-01-14 00:14:15,835 iteration 2122 : loss : 0.064554, loss_ce: 0.036230
2022-01-14 00:14:17,170 iteration 2123 : loss : 0.050222, loss_ce: 0.013738
2022-01-14 00:14:18,661 iteration 2124 : loss : 0.054375, loss_ce: 0.025423
2022-01-14 00:14:18,662 Training Data Eval:
2022-01-14 00:14:25,594   Average segmentation loss on training set: 0.0281
2022-01-14 00:14:25,595 Validation Data Eval:
2022-01-14 00:14:28,000   Average segmentation loss on validation set: 0.0736
2022-01-14 00:14:29,373 iteration 2125 : loss : 0.053251, loss_ce: 0.026216
 31%|█████████                    | 125/400 [54:42<2:06:14, 27.54s/it]2022-01-14 00:14:30,900 iteration 2126 : loss : 0.075305, loss_ce: 0.024769
2022-01-14 00:14:32,263 iteration 2127 : loss : 0.027834, loss_ce: 0.011731
2022-01-14 00:14:33,648 iteration 2128 : loss : 0.035367, loss_ce: 0.014789
2022-01-14 00:14:35,185 iteration 2129 : loss : 0.056523, loss_ce: 0.023732
2022-01-14 00:14:36,601 iteration 2130 : loss : 0.043387, loss_ce: 0.016604
2022-01-14 00:14:37,971 iteration 2131 : loss : 0.027434, loss_ce: 0.011663
2022-01-14 00:14:39,411 iteration 2132 : loss : 0.051217, loss_ce: 0.016919
2022-01-14 00:14:40,807 iteration 2133 : loss : 0.034702, loss_ce: 0.015968
2022-01-14 00:14:42,303 iteration 2134 : loss : 0.059660, loss_ce: 0.019309
2022-01-14 00:14:43,649 iteration 2135 : loss : 0.033954, loss_ce: 0.010732
2022-01-14 00:14:45,113 iteration 2136 : loss : 0.032939, loss_ce: 0.013038
2022-01-14 00:14:46,525 iteration 2137 : loss : 0.034796, loss_ce: 0.013862
2022-01-14 00:14:48,009 iteration 2138 : loss : 0.044621, loss_ce: 0.014264
2022-01-14 00:14:49,406 iteration 2139 : loss : 0.045928, loss_ce: 0.026829
2022-01-14 00:14:50,864 iteration 2140 : loss : 0.067204, loss_ce: 0.043168
2022-01-14 00:14:52,328 iteration 2141 : loss : 0.033124, loss_ce: 0.010500
2022-01-14 00:14:53,777 iteration 2142 : loss : 0.072254, loss_ce: 0.025519
 32%|█████████▏                   | 126/400 [55:07<2:01:28, 26.60s/it]2022-01-14 00:14:55,243 iteration 2143 : loss : 0.043690, loss_ce: 0.023039
2022-01-14 00:14:56,653 iteration 2144 : loss : 0.031262, loss_ce: 0.013183
2022-01-14 00:14:58,061 iteration 2145 : loss : 0.049287, loss_ce: 0.022001
2022-01-14 00:14:59,425 iteration 2146 : loss : 0.046660, loss_ce: 0.017854
2022-01-14 00:15:00,766 iteration 2147 : loss : 0.037887, loss_ce: 0.014449
2022-01-14 00:15:02,161 iteration 2148 : loss : 0.038073, loss_ce: 0.015263
2022-01-14 00:15:03,614 iteration 2149 : loss : 0.074559, loss_ce: 0.024042
2022-01-14 00:15:04,982 iteration 2150 : loss : 0.032687, loss_ce: 0.012894
2022-01-14 00:15:06,377 iteration 2151 : loss : 0.029981, loss_ce: 0.011594
2022-01-14 00:15:07,720 iteration 2152 : loss : 0.037301, loss_ce: 0.017536
2022-01-14 00:15:09,107 iteration 2153 : loss : 0.043888, loss_ce: 0.013853
2022-01-14 00:15:10,505 iteration 2154 : loss : 0.033997, loss_ce: 0.011452
2022-01-14 00:15:11,933 iteration 2155 : loss : 0.058792, loss_ce: 0.036923
2022-01-14 00:15:13,288 iteration 2156 : loss : 0.041426, loss_ce: 0.016035
2022-01-14 00:15:14,788 iteration 2157 : loss : 0.040330, loss_ce: 0.017017
2022-01-14 00:15:16,245 iteration 2158 : loss : 0.044998, loss_ce: 0.015067
2022-01-14 00:15:17,689 iteration 2159 : loss : 0.066116, loss_ce: 0.021856
 32%|█████████▏                   | 127/400 [55:31<1:57:20, 25.79s/it]2022-01-14 00:15:19,160 iteration 2160 : loss : 0.038886, loss_ce: 0.013470
2022-01-14 00:15:20,671 iteration 2161 : loss : 0.055120, loss_ce: 0.030519
2022-01-14 00:15:22,130 iteration 2162 : loss : 0.034231, loss_ce: 0.013767
2022-01-14 00:15:23,473 iteration 2163 : loss : 0.051812, loss_ce: 0.020208
2022-01-14 00:15:24,937 iteration 2164 : loss : 0.048981, loss_ce: 0.018692
2022-01-14 00:15:26,378 iteration 2165 : loss : 0.063799, loss_ce: 0.030907
2022-01-14 00:15:27,818 iteration 2166 : loss : 0.038886, loss_ce: 0.009861
2022-01-14 00:15:29,287 iteration 2167 : loss : 0.037384, loss_ce: 0.013944
2022-01-14 00:15:30,707 iteration 2168 : loss : 0.042476, loss_ce: 0.017877
2022-01-14 00:15:32,144 iteration 2169 : loss : 0.039897, loss_ce: 0.016431
2022-01-14 00:15:33,522 iteration 2170 : loss : 0.061330, loss_ce: 0.026668
2022-01-14 00:15:34,986 iteration 2171 : loss : 0.068047, loss_ce: 0.024316
2022-01-14 00:15:36,506 iteration 2172 : loss : 0.041973, loss_ce: 0.012622
2022-01-14 00:15:37,862 iteration 2173 : loss : 0.035505, loss_ce: 0.011962
2022-01-14 00:15:39,191 iteration 2174 : loss : 0.029274, loss_ce: 0.014092
2022-01-14 00:15:40,551 iteration 2175 : loss : 0.032684, loss_ce: 0.011617
2022-01-14 00:15:42,066 iteration 2176 : loss : 0.053058, loss_ce: 0.022484
 32%|█████████▎                   | 128/400 [55:55<1:55:00, 25.37s/it]2022-01-14 00:15:43,561 iteration 2177 : loss : 0.042828, loss_ce: 0.015207
2022-01-14 00:15:45,025 iteration 2178 : loss : 0.036465, loss_ce: 0.015066
2022-01-14 00:15:46,408 iteration 2179 : loss : 0.037684, loss_ce: 0.017081
2022-01-14 00:15:47,797 iteration 2180 : loss : 0.035052, loss_ce: 0.014467
2022-01-14 00:15:49,280 iteration 2181 : loss : 0.041515, loss_ce: 0.018995
2022-01-14 00:15:50,663 iteration 2182 : loss : 0.048708, loss_ce: 0.012588
2022-01-14 00:15:52,003 iteration 2183 : loss : 0.035258, loss_ce: 0.015376
2022-01-14 00:15:53,481 iteration 2184 : loss : 0.034373, loss_ce: 0.009999
2022-01-14 00:15:54,856 iteration 2185 : loss : 0.041442, loss_ce: 0.020035
2022-01-14 00:15:56,267 iteration 2186 : loss : 0.037339, loss_ce: 0.014450
2022-01-14 00:15:57,682 iteration 2187 : loss : 0.028780, loss_ce: 0.011091
2022-01-14 00:15:59,064 iteration 2188 : loss : 0.043649, loss_ce: 0.011719
2022-01-14 00:16:00,553 iteration 2189 : loss : 0.045029, loss_ce: 0.015964
2022-01-14 00:16:01,960 iteration 2190 : loss : 0.036578, loss_ce: 0.013992
2022-01-14 00:16:03,404 iteration 2191 : loss : 0.087826, loss_ce: 0.022935
2022-01-14 00:16:04,779 iteration 2192 : loss : 0.043796, loss_ce: 0.018393
2022-01-14 00:16:06,205 iteration 2193 : loss : 0.053229, loss_ce: 0.023043
 32%|█████████▎                   | 129/400 [56:19<1:52:54, 25.00s/it]2022-01-14 00:16:07,738 iteration 2194 : loss : 0.047712, loss_ce: 0.024662
2022-01-14 00:16:09,118 iteration 2195 : loss : 0.038685, loss_ce: 0.011678
2022-01-14 00:16:10,507 iteration 2196 : loss : 0.035547, loss_ce: 0.012975
2022-01-14 00:16:11,958 iteration 2197 : loss : 0.038118, loss_ce: 0.018965
2022-01-14 00:16:13,375 iteration 2198 : loss : 0.037230, loss_ce: 0.016323
2022-01-14 00:16:14,779 iteration 2199 : loss : 0.035813, loss_ce: 0.015373
2022-01-14 00:16:16,161 iteration 2200 : loss : 0.044211, loss_ce: 0.014433
2022-01-14 00:16:17,520 iteration 2201 : loss : 0.029697, loss_ce: 0.011109
2022-01-14 00:16:18,965 iteration 2202 : loss : 0.084892, loss_ce: 0.020807
2022-01-14 00:16:20,433 iteration 2203 : loss : 0.032122, loss_ce: 0.017315
2022-01-14 00:16:21,796 iteration 2204 : loss : 0.034941, loss_ce: 0.016458
2022-01-14 00:16:23,115 iteration 2205 : loss : 0.029383, loss_ce: 0.013037
2022-01-14 00:16:24,430 iteration 2206 : loss : 0.039124, loss_ce: 0.011407
2022-01-14 00:16:25,793 iteration 2207 : loss : 0.068140, loss_ce: 0.028073
2022-01-14 00:16:27,202 iteration 2208 : loss : 0.045642, loss_ce: 0.014390
2022-01-14 00:16:28,583 iteration 2209 : loss : 0.047164, loss_ce: 0.015527
2022-01-14 00:16:28,583 Training Data Eval:
2022-01-14 00:16:35,530   Average segmentation loss on training set: 0.0270
2022-01-14 00:16:35,531 Validation Data Eval:
2022-01-14 00:16:37,997   Average segmentation loss on validation set: 0.0798
2022-01-14 00:16:39,448 iteration 2210 : loss : 0.041603, loss_ce: 0.014089
 32%|█████████▍                   | 130/400 [56:52<2:03:37, 27.47s/it]2022-01-14 00:16:40,962 iteration 2211 : loss : 0.042938, loss_ce: 0.014799
2022-01-14 00:16:42,405 iteration 2212 : loss : 0.045223, loss_ce: 0.019208
2022-01-14 00:16:43,832 iteration 2213 : loss : 0.047166, loss_ce: 0.017462
2022-01-14 00:16:45,278 iteration 2214 : loss : 0.038809, loss_ce: 0.012239
2022-01-14 00:16:46,727 iteration 2215 : loss : 0.045439, loss_ce: 0.019079
2022-01-14 00:16:48,058 iteration 2216 : loss : 0.037322, loss_ce: 0.011446
2022-01-14 00:16:49,526 iteration 2217 : loss : 0.054793, loss_ce: 0.022198
2022-01-14 00:16:50,870 iteration 2218 : loss : 0.039167, loss_ce: 0.015893
2022-01-14 00:16:52,324 iteration 2219 : loss : 0.031147, loss_ce: 0.011140
2022-01-14 00:16:53,630 iteration 2220 : loss : 0.042386, loss_ce: 0.014029
2022-01-14 00:16:54,985 iteration 2221 : loss : 0.027465, loss_ce: 0.009539
2022-01-14 00:16:56,436 iteration 2222 : loss : 0.036072, loss_ce: 0.014492
2022-01-14 00:16:57,847 iteration 2223 : loss : 0.043413, loss_ce: 0.014586
2022-01-14 00:16:59,310 iteration 2224 : loss : 0.047751, loss_ce: 0.022485
2022-01-14 00:17:00,688 iteration 2225 : loss : 0.020842, loss_ce: 0.008422
2022-01-14 00:17:02,163 iteration 2226 : loss : 0.047663, loss_ce: 0.020324
2022-01-14 00:17:03,555 iteration 2227 : loss : 0.032121, loss_ce: 0.012950
 33%|█████████▍                   | 131/400 [57:16<1:58:38, 26.46s/it]2022-01-14 00:17:05,069 iteration 2228 : loss : 0.043417, loss_ce: 0.021975
2022-01-14 00:17:06,482 iteration 2229 : loss : 0.039600, loss_ce: 0.015722
2022-01-14 00:17:07,946 iteration 2230 : loss : 0.037436, loss_ce: 0.013625
2022-01-14 00:17:09,249 iteration 2231 : loss : 0.023752, loss_ce: 0.009809
2022-01-14 00:17:10,619 iteration 2232 : loss : 0.038506, loss_ce: 0.016040
2022-01-14 00:17:11,984 iteration 2233 : loss : 0.041166, loss_ce: 0.014262
2022-01-14 00:17:13,360 iteration 2234 : loss : 0.041823, loss_ce: 0.014867
2022-01-14 00:17:14,748 iteration 2235 : loss : 0.089295, loss_ce: 0.021528
2022-01-14 00:17:16,277 iteration 2236 : loss : 0.052391, loss_ce: 0.022067
2022-01-14 00:17:17,687 iteration 2237 : loss : 0.039592, loss_ce: 0.017519
2022-01-14 00:17:19,100 iteration 2238 : loss : 0.042370, loss_ce: 0.020577
2022-01-14 00:17:20,501 iteration 2239 : loss : 0.033864, loss_ce: 0.012673
2022-01-14 00:17:21,970 iteration 2240 : loss : 0.040470, loss_ce: 0.015027
2022-01-14 00:17:23,430 iteration 2241 : loss : 0.041063, loss_ce: 0.012774
2022-01-14 00:17:24,912 iteration 2242 : loss : 0.041382, loss_ce: 0.016052
2022-01-14 00:17:26,419 iteration 2243 : loss : 0.062082, loss_ce: 0.017760
2022-01-14 00:17:27,826 iteration 2244 : loss : 0.041167, loss_ce: 0.020370
 33%|█████████▌                   | 132/400 [57:41<1:55:15, 25.80s/it]2022-01-14 00:17:29,386 iteration 2245 : loss : 0.048336, loss_ce: 0.017130
2022-01-14 00:17:30,760 iteration 2246 : loss : 0.027305, loss_ce: 0.011629
2022-01-14 00:17:32,281 iteration 2247 : loss : 0.066938, loss_ce: 0.018304
2022-01-14 00:17:33,714 iteration 2248 : loss : 0.042795, loss_ce: 0.016830
2022-01-14 00:17:35,138 iteration 2249 : loss : 0.034021, loss_ce: 0.011457
2022-01-14 00:17:36,538 iteration 2250 : loss : 0.055574, loss_ce: 0.022424
2022-01-14 00:17:37,865 iteration 2251 : loss : 0.039323, loss_ce: 0.013452
2022-01-14 00:17:39,399 iteration 2252 : loss : 0.063891, loss_ce: 0.023069
2022-01-14 00:17:40,891 iteration 2253 : loss : 0.049024, loss_ce: 0.023173
2022-01-14 00:17:42,305 iteration 2254 : loss : 0.039314, loss_ce: 0.018072
2022-01-14 00:17:43,670 iteration 2255 : loss : 0.035207, loss_ce: 0.011397
2022-01-14 00:17:45,087 iteration 2256 : loss : 0.031868, loss_ce: 0.013846
2022-01-14 00:17:46,496 iteration 2257 : loss : 0.047020, loss_ce: 0.019403
2022-01-14 00:17:47,831 iteration 2258 : loss : 0.027876, loss_ce: 0.011678
2022-01-14 00:17:49,309 iteration 2259 : loss : 0.067322, loss_ce: 0.035479
2022-01-14 00:17:50,692 iteration 2260 : loss : 0.039872, loss_ce: 0.016302
2022-01-14 00:17:52,121 iteration 2261 : loss : 0.034314, loss_ce: 0.015968
 33%|█████████▋                   | 133/400 [58:05<1:52:48, 25.35s/it]2022-01-14 00:17:53,614 iteration 2262 : loss : 0.039251, loss_ce: 0.016523
2022-01-14 00:17:55,029 iteration 2263 : loss : 0.034281, loss_ce: 0.014805
2022-01-14 00:17:56,475 iteration 2264 : loss : 0.057735, loss_ce: 0.022969
2022-01-14 00:17:57,885 iteration 2265 : loss : 0.031712, loss_ce: 0.012003
2022-01-14 00:17:59,285 iteration 2266 : loss : 0.049762, loss_ce: 0.016251
2022-01-14 00:18:00,647 iteration 2267 : loss : 0.031709, loss_ce: 0.012570
2022-01-14 00:18:02,064 iteration 2268 : loss : 0.033157, loss_ce: 0.014488
2022-01-14 00:18:03,459 iteration 2269 : loss : 0.032243, loss_ce: 0.015049
2022-01-14 00:18:04,843 iteration 2270 : loss : 0.025899, loss_ce: 0.009170
2022-01-14 00:18:06,288 iteration 2271 : loss : 0.059221, loss_ce: 0.027742
2022-01-14 00:18:07,764 iteration 2272 : loss : 0.036117, loss_ce: 0.014444
2022-01-14 00:18:09,226 iteration 2273 : loss : 0.032074, loss_ce: 0.012894
2022-01-14 00:18:10,627 iteration 2274 : loss : 0.060020, loss_ce: 0.024597
2022-01-14 00:18:12,015 iteration 2275 : loss : 0.055699, loss_ce: 0.016932
2022-01-14 00:18:13,364 iteration 2276 : loss : 0.044184, loss_ce: 0.017973
2022-01-14 00:18:14,779 iteration 2277 : loss : 0.030227, loss_ce: 0.009522
2022-01-14 00:18:16,221 iteration 2278 : loss : 0.048735, loss_ce: 0.016273
 34%|█████████▋                   | 134/400 [58:29<1:50:43, 24.98s/it]2022-01-14 00:18:17,632 iteration 2279 : loss : 0.028739, loss_ce: 0.011062
2022-01-14 00:18:18,991 iteration 2280 : loss : 0.034203, loss_ce: 0.014769
2022-01-14 00:18:20,403 iteration 2281 : loss : 0.054510, loss_ce: 0.017735
2022-01-14 00:18:21,749 iteration 2282 : loss : 0.039003, loss_ce: 0.013702
2022-01-14 00:18:23,157 iteration 2283 : loss : 0.061701, loss_ce: 0.020628
2022-01-14 00:18:24,494 iteration 2284 : loss : 0.035854, loss_ce: 0.016161
2022-01-14 00:18:25,942 iteration 2285 : loss : 0.049217, loss_ce: 0.021767
2022-01-14 00:18:27,327 iteration 2286 : loss : 0.045493, loss_ce: 0.019099
2022-01-14 00:18:28,724 iteration 2287 : loss : 0.030180, loss_ce: 0.008031
2022-01-14 00:18:30,145 iteration 2288 : loss : 0.069843, loss_ce: 0.019323
2022-01-14 00:18:31,571 iteration 2289 : loss : 0.042037, loss_ce: 0.011434
2022-01-14 00:18:32,974 iteration 2290 : loss : 0.056398, loss_ce: 0.023554
2022-01-14 00:18:34,496 iteration 2291 : loss : 0.053464, loss_ce: 0.020451
2022-01-14 00:18:35,928 iteration 2292 : loss : 0.035685, loss_ce: 0.013600
2022-01-14 00:18:37,354 iteration 2293 : loss : 0.064035, loss_ce: 0.028107
2022-01-14 00:18:38,765 iteration 2294 : loss : 0.036759, loss_ce: 0.018250
2022-01-14 00:18:38,765 Training Data Eval:
2022-01-14 00:18:45,920   Average segmentation loss on training set: 0.0309
2022-01-14 00:18:45,920 Validation Data Eval:
2022-01-14 00:18:48,368   Average segmentation loss on validation set: 0.0718
2022-01-14 00:18:49,786 iteration 2295 : loss : 0.055222, loss_ce: 0.017128
 34%|█████████▊                   | 135/400 [59:03<2:01:41, 27.55s/it]2022-01-14 00:18:51,221 iteration 2296 : loss : 0.039819, loss_ce: 0.016357
2022-01-14 00:18:52,692 iteration 2297 : loss : 0.035131, loss_ce: 0.011348
2022-01-14 00:18:54,114 iteration 2298 : loss : 0.041209, loss_ce: 0.014982
2022-01-14 00:18:55,579 iteration 2299 : loss : 0.043583, loss_ce: 0.014426
2022-01-14 00:18:56,979 iteration 2300 : loss : 0.030871, loss_ce: 0.013315
2022-01-14 00:18:58,419 iteration 2301 : loss : 0.036663, loss_ce: 0.014460
2022-01-14 00:18:59,892 iteration 2302 : loss : 0.038020, loss_ce: 0.012944
2022-01-14 00:19:01,331 iteration 2303 : loss : 0.053002, loss_ce: 0.015923
2022-01-14 00:19:02,787 iteration 2304 : loss : 0.044721, loss_ce: 0.017567
2022-01-14 00:19:04,172 iteration 2305 : loss : 0.045617, loss_ce: 0.023490
2022-01-14 00:19:05,543 iteration 2306 : loss : 0.034308, loss_ce: 0.013324
2022-01-14 00:19:07,021 iteration 2307 : loss : 0.051614, loss_ce: 0.019125
2022-01-14 00:19:08,388 iteration 2308 : loss : 0.040161, loss_ce: 0.016707
2022-01-14 00:19:09,830 iteration 2309 : loss : 0.046152, loss_ce: 0.020863
2022-01-14 00:19:11,267 iteration 2310 : loss : 0.034145, loss_ce: 0.017115
2022-01-14 00:19:12,638 iteration 2311 : loss : 0.040466, loss_ce: 0.016682
2022-01-14 00:19:13,973 iteration 2312 : loss : 0.027576, loss_ce: 0.010636
 34%|█████████▊                   | 136/400 [59:27<1:56:47, 26.55s/it]2022-01-14 00:19:15,428 iteration 2313 : loss : 0.069863, loss_ce: 0.035236
2022-01-14 00:19:16,864 iteration 2314 : loss : 0.044388, loss_ce: 0.014307
2022-01-14 00:19:18,354 iteration 2315 : loss : 0.064512, loss_ce: 0.020606
2022-01-14 00:19:19,688 iteration 2316 : loss : 0.036119, loss_ce: 0.015207
2022-01-14 00:19:21,164 iteration 2317 : loss : 0.067147, loss_ce: 0.017958
2022-01-14 00:19:22,597 iteration 2318 : loss : 0.043252, loss_ce: 0.016276
2022-01-14 00:19:24,036 iteration 2319 : loss : 0.034121, loss_ce: 0.014068
2022-01-14 00:19:25,502 iteration 2320 : loss : 0.035113, loss_ce: 0.015975
2022-01-14 00:19:26,859 iteration 2321 : loss : 0.040151, loss_ce: 0.013198
2022-01-14 00:19:28,282 iteration 2322 : loss : 0.052194, loss_ce: 0.029322
2022-01-14 00:19:29,683 iteration 2323 : loss : 0.044191, loss_ce: 0.020901
2022-01-14 00:19:31,135 iteration 2324 : loss : 0.044966, loss_ce: 0.021621
2022-01-14 00:19:32,556 iteration 2325 : loss : 0.045822, loss_ce: 0.022441
2022-01-14 00:19:34,005 iteration 2326 : loss : 0.045478, loss_ce: 0.019850
2022-01-14 00:19:35,406 iteration 2327 : loss : 0.032493, loss_ce: 0.012799
2022-01-14 00:19:36,870 iteration 2328 : loss : 0.049936, loss_ce: 0.026089
2022-01-14 00:19:38,250 iteration 2329 : loss : 0.028024, loss_ce: 0.010928
 34%|█████████▉                   | 137/400 [59:51<1:53:21, 25.86s/it]2022-01-14 00:19:39,705 iteration 2330 : loss : 0.030762, loss_ce: 0.011485
2022-01-14 00:19:41,145 iteration 2331 : loss : 0.044341, loss_ce: 0.019501
2022-01-14 00:19:42,606 iteration 2332 : loss : 0.076223, loss_ce: 0.030571
2022-01-14 00:19:44,075 iteration 2333 : loss : 0.038124, loss_ce: 0.018374
2022-01-14 00:19:45,468 iteration 2334 : loss : 0.030054, loss_ce: 0.013547
2022-01-14 00:19:46,861 iteration 2335 : loss : 0.039600, loss_ce: 0.013721
2022-01-14 00:19:48,319 iteration 2336 : loss : 0.072396, loss_ce: 0.018440
2022-01-14 00:19:49,772 iteration 2337 : loss : 0.030639, loss_ce: 0.014355
2022-01-14 00:19:51,179 iteration 2338 : loss : 0.030911, loss_ce: 0.010925
2022-01-14 00:19:52,643 iteration 2339 : loss : 0.036099, loss_ce: 0.011950
2022-01-14 00:19:54,116 iteration 2340 : loss : 0.053584, loss_ce: 0.023899
2022-01-14 00:19:55,457 iteration 2341 : loss : 0.032117, loss_ce: 0.008158
2022-01-14 00:19:56,899 iteration 2342 : loss : 0.034849, loss_ce: 0.013862
2022-01-14 00:19:58,393 iteration 2343 : loss : 0.057909, loss_ce: 0.021758
2022-01-14 00:19:59,839 iteration 2344 : loss : 0.054286, loss_ce: 0.021018
2022-01-14 00:20:01,324 iteration 2345 : loss : 0.046994, loss_ce: 0.015236
2022-01-14 00:20:02,753 iteration 2346 : loss : 0.043986, loss_ce: 0.016902
 34%|█████████▎                 | 138/400 [1:00:16<1:51:08, 25.45s/it]2022-01-14 00:20:04,245 iteration 2347 : loss : 0.039665, loss_ce: 0.012787
2022-01-14 00:20:05,650 iteration 2348 : loss : 0.039093, loss_ce: 0.012427
2022-01-14 00:20:07,122 iteration 2349 : loss : 0.051558, loss_ce: 0.025434
2022-01-14 00:20:08,533 iteration 2350 : loss : 0.043569, loss_ce: 0.014223
2022-01-14 00:20:09,972 iteration 2351 : loss : 0.145445, loss_ce: 0.031361
2022-01-14 00:20:11,394 iteration 2352 : loss : 0.032566, loss_ce: 0.010037
2022-01-14 00:20:12,876 iteration 2353 : loss : 0.037891, loss_ce: 0.017048
2022-01-14 00:20:14,338 iteration 2354 : loss : 0.037868, loss_ce: 0.017357
2022-01-14 00:20:15,676 iteration 2355 : loss : 0.029160, loss_ce: 0.011182
2022-01-14 00:20:17,120 iteration 2356 : loss : 0.032419, loss_ce: 0.012404
2022-01-14 00:20:18,540 iteration 2357 : loss : 0.052823, loss_ce: 0.017244
2022-01-14 00:20:19,991 iteration 2358 : loss : 0.031273, loss_ce: 0.012886
2022-01-14 00:20:21,543 iteration 2359 : loss : 0.062684, loss_ce: 0.021142
2022-01-14 00:20:22,929 iteration 2360 : loss : 0.050198, loss_ce: 0.027698
2022-01-14 00:20:24,368 iteration 2361 : loss : 0.037547, loss_ce: 0.014242
2022-01-14 00:20:25,894 iteration 2362 : loss : 0.070024, loss_ce: 0.030787
2022-01-14 00:20:27,250 iteration 2363 : loss : 0.029400, loss_ce: 0.013403
 35%|█████████▍                 | 139/400 [1:00:40<1:49:28, 25.17s/it]2022-01-14 00:20:28,642 iteration 2364 : loss : 0.087486, loss_ce: 0.019742
2022-01-14 00:20:30,028 iteration 2365 : loss : 0.048440, loss_ce: 0.013736
2022-01-14 00:20:31,460 iteration 2366 : loss : 0.056635, loss_ce: 0.026435
2022-01-14 00:20:32,856 iteration 2367 : loss : 0.061280, loss_ce: 0.034646
2022-01-14 00:20:34,259 iteration 2368 : loss : 0.049120, loss_ce: 0.020201
2022-01-14 00:20:35,693 iteration 2369 : loss : 0.062942, loss_ce: 0.027069
2022-01-14 00:20:37,040 iteration 2370 : loss : 0.051084, loss_ce: 0.020170
2022-01-14 00:20:38,509 iteration 2371 : loss : 0.029736, loss_ce: 0.013011
2022-01-14 00:20:39,910 iteration 2372 : loss : 0.041898, loss_ce: 0.017212
2022-01-14 00:20:41,285 iteration 2373 : loss : 0.039312, loss_ce: 0.015968
2022-01-14 00:20:42,669 iteration 2374 : loss : 0.039832, loss_ce: 0.014422
2022-01-14 00:20:44,117 iteration 2375 : loss : 0.050086, loss_ce: 0.015126
2022-01-14 00:20:45,557 iteration 2376 : loss : 0.040917, loss_ce: 0.014384
2022-01-14 00:20:46,947 iteration 2377 : loss : 0.032319, loss_ce: 0.011879
2022-01-14 00:20:48,352 iteration 2378 : loss : 0.034398, loss_ce: 0.014478
2022-01-14 00:20:49,758 iteration 2379 : loss : 0.046534, loss_ce: 0.027855
2022-01-14 00:20:49,758 Training Data Eval:
2022-01-14 00:20:56,894   Average segmentation loss on training set: 0.0378
2022-01-14 00:20:56,895 Validation Data Eval:
2022-01-14 00:20:59,375   Average segmentation loss on validation set: 0.0830
2022-01-14 00:21:00,764 iteration 2380 : loss : 0.033459, loss_ce: 0.016039
 35%|█████████▍                 | 140/400 [1:01:14<1:59:55, 27.67s/it]2022-01-14 00:21:02,347 iteration 2381 : loss : 0.065278, loss_ce: 0.018978
2022-01-14 00:21:03,770 iteration 2382 : loss : 0.052381, loss_ce: 0.020520
2022-01-14 00:21:05,167 iteration 2383 : loss : 0.041249, loss_ce: 0.016674
2022-01-14 00:21:06,532 iteration 2384 : loss : 0.034038, loss_ce: 0.012961
2022-01-14 00:21:07,956 iteration 2385 : loss : 0.035441, loss_ce: 0.012176
2022-01-14 00:21:09,424 iteration 2386 : loss : 0.036251, loss_ce: 0.011282
2022-01-14 00:21:10,891 iteration 2387 : loss : 0.029174, loss_ce: 0.010768
2022-01-14 00:21:12,323 iteration 2388 : loss : 0.032986, loss_ce: 0.015109
2022-01-14 00:21:13,762 iteration 2389 : loss : 0.028818, loss_ce: 0.009783
2022-01-14 00:21:15,136 iteration 2390 : loss : 0.033674, loss_ce: 0.015135
2022-01-14 00:21:16,486 iteration 2391 : loss : 0.030074, loss_ce: 0.011582
2022-01-14 00:21:18,046 iteration 2392 : loss : 0.034522, loss_ce: 0.009130
2022-01-14 00:21:19,508 iteration 2393 : loss : 0.046131, loss_ce: 0.015560
2022-01-14 00:21:20,926 iteration 2394 : loss : 0.050845, loss_ce: 0.021080
2022-01-14 00:21:22,411 iteration 2395 : loss : 0.035974, loss_ce: 0.015749
2022-01-14 00:21:23,771 iteration 2396 : loss : 0.036195, loss_ce: 0.016510
2022-01-14 00:21:25,252 iteration 2397 : loss : 0.028928, loss_ce: 0.014705
 35%|█████████▌                 | 141/400 [1:01:38<1:55:20, 26.72s/it]2022-01-14 00:21:26,697 iteration 2398 : loss : 0.028879, loss_ce: 0.013299
2022-01-14 00:21:28,185 iteration 2399 : loss : 0.034313, loss_ce: 0.014254
2022-01-14 00:21:29,590 iteration 2400 : loss : 0.043728, loss_ce: 0.017027
2022-01-14 00:21:31,122 iteration 2401 : loss : 0.059874, loss_ce: 0.019765
2022-01-14 00:21:32,519 iteration 2402 : loss : 0.047265, loss_ce: 0.018507
2022-01-14 00:21:33,913 iteration 2403 : loss : 0.033913, loss_ce: 0.013691
2022-01-14 00:21:35,274 iteration 2404 : loss : 0.035130, loss_ce: 0.012170
2022-01-14 00:21:36,727 iteration 2405 : loss : 0.041223, loss_ce: 0.014388
2022-01-14 00:21:38,084 iteration 2406 : loss : 0.049778, loss_ce: 0.020996
2022-01-14 00:21:39,468 iteration 2407 : loss : 0.035626, loss_ce: 0.012044
2022-01-14 00:21:41,014 iteration 2408 : loss : 0.043026, loss_ce: 0.013049
2022-01-14 00:21:42,389 iteration 2409 : loss : 0.039318, loss_ce: 0.014129
2022-01-14 00:21:43,755 iteration 2410 : loss : 0.030259, loss_ce: 0.010435
2022-01-14 00:21:45,111 iteration 2411 : loss : 0.032512, loss_ce: 0.012750
2022-01-14 00:21:46,491 iteration 2412 : loss : 0.029707, loss_ce: 0.011029
2022-01-14 00:21:47,839 iteration 2413 : loss : 0.038418, loss_ce: 0.016111
2022-01-14 00:21:49,183 iteration 2414 : loss : 0.029650, loss_ce: 0.012935
 36%|█████████▌                 | 142/400 [1:02:02<1:51:16, 25.88s/it]2022-01-14 00:21:50,712 iteration 2415 : loss : 0.034487, loss_ce: 0.012926
2022-01-14 00:21:52,123 iteration 2416 : loss : 0.045380, loss_ce: 0.017498
2022-01-14 00:21:53,539 iteration 2417 : loss : 0.027380, loss_ce: 0.013308
2022-01-14 00:21:54,896 iteration 2418 : loss : 0.038549, loss_ce: 0.011680
2022-01-14 00:21:56,301 iteration 2419 : loss : 0.051785, loss_ce: 0.017236
2022-01-14 00:21:57,765 iteration 2420 : loss : 0.031830, loss_ce: 0.013721
2022-01-14 00:21:59,165 iteration 2421 : loss : 0.029952, loss_ce: 0.013153
2022-01-14 00:22:00,571 iteration 2422 : loss : 0.042037, loss_ce: 0.018637
2022-01-14 00:22:01,895 iteration 2423 : loss : 0.036077, loss_ce: 0.016197
2022-01-14 00:22:03,310 iteration 2424 : loss : 0.032199, loss_ce: 0.012850
2022-01-14 00:22:04,733 iteration 2425 : loss : 0.032907, loss_ce: 0.011622
2022-01-14 00:22:06,122 iteration 2426 : loss : 0.059623, loss_ce: 0.025723
2022-01-14 00:22:07,471 iteration 2427 : loss : 0.030843, loss_ce: 0.015317
2022-01-14 00:22:08,849 iteration 2428 : loss : 0.031508, loss_ce: 0.010992
2022-01-14 00:22:10,198 iteration 2429 : loss : 0.061402, loss_ce: 0.020497
2022-01-14 00:22:11,596 iteration 2430 : loss : 0.053701, loss_ce: 0.022918
2022-01-14 00:22:13,020 iteration 2431 : loss : 0.047680, loss_ce: 0.013698
 36%|█████████▋                 | 143/400 [1:02:26<1:48:13, 25.27s/it]2022-01-14 00:22:14,408 iteration 2432 : loss : 0.028426, loss_ce: 0.009633
2022-01-14 00:22:15,784 iteration 2433 : loss : 0.034398, loss_ce: 0.017546
2022-01-14 00:22:17,220 iteration 2434 : loss : 0.038998, loss_ce: 0.016147
2022-01-14 00:22:18,633 iteration 2435 : loss : 0.026248, loss_ce: 0.012326
2022-01-14 00:22:20,127 iteration 2436 : loss : 0.036307, loss_ce: 0.013672
2022-01-14 00:22:21,530 iteration 2437 : loss : 0.041516, loss_ce: 0.018633
2022-01-14 00:22:22,890 iteration 2438 : loss : 0.029280, loss_ce: 0.012785
2022-01-14 00:22:24,314 iteration 2439 : loss : 0.034086, loss_ce: 0.012045
2022-01-14 00:22:25,735 iteration 2440 : loss : 0.028339, loss_ce: 0.011106
2022-01-14 00:22:27,254 iteration 2441 : loss : 0.067756, loss_ce: 0.023255
2022-01-14 00:22:28,699 iteration 2442 : loss : 0.029856, loss_ce: 0.010056
2022-01-14 00:22:30,151 iteration 2443 : loss : 0.036991, loss_ce: 0.014288
2022-01-14 00:22:31,610 iteration 2444 : loss : 0.042317, loss_ce: 0.014579
2022-01-14 00:22:33,113 iteration 2445 : loss : 0.027843, loss_ce: 0.012340
2022-01-14 00:22:34,521 iteration 2446 : loss : 0.040960, loss_ce: 0.019710
2022-01-14 00:22:36,002 iteration 2447 : loss : 0.049485, loss_ce: 0.016657
2022-01-14 00:22:37,374 iteration 2448 : loss : 0.041771, loss_ce: 0.022688
 36%|█████████▋                 | 144/400 [1:02:50<1:46:39, 25.00s/it]2022-01-14 00:22:38,863 iteration 2449 : loss : 0.025478, loss_ce: 0.006985
2022-01-14 00:22:40,208 iteration 2450 : loss : 0.039843, loss_ce: 0.013651
2022-01-14 00:22:41,551 iteration 2451 : loss : 0.031272, loss_ce: 0.010045
2022-01-14 00:22:42,932 iteration 2452 : loss : 0.047226, loss_ce: 0.023218
2022-01-14 00:22:44,323 iteration 2453 : loss : 0.055567, loss_ce: 0.026140
2022-01-14 00:22:45,693 iteration 2454 : loss : 0.044555, loss_ce: 0.016375
2022-01-14 00:22:47,185 iteration 2455 : loss : 0.038177, loss_ce: 0.014391
2022-01-14 00:22:48,591 iteration 2456 : loss : 0.029719, loss_ce: 0.014421
2022-01-14 00:22:49,959 iteration 2457 : loss : 0.057418, loss_ce: 0.028916
2022-01-14 00:22:51,414 iteration 2458 : loss : 0.049352, loss_ce: 0.016536
2022-01-14 00:22:52,825 iteration 2459 : loss : 0.029487, loss_ce: 0.011152
2022-01-14 00:22:54,284 iteration 2460 : loss : 0.057991, loss_ce: 0.017889
2022-01-14 00:22:55,734 iteration 2461 : loss : 0.047844, loss_ce: 0.013935
2022-01-14 00:22:57,238 iteration 2462 : loss : 0.040184, loss_ce: 0.017260
2022-01-14 00:22:58,633 iteration 2463 : loss : 0.036941, loss_ce: 0.015517
2022-01-14 00:23:00,051 iteration 2464 : loss : 0.038488, loss_ce: 0.021355
2022-01-14 00:23:00,051 Training Data Eval:
2022-01-14 00:23:07,195   Average segmentation loss on training set: 0.0318
2022-01-14 00:23:07,195 Validation Data Eval:
2022-01-14 00:23:09,714   Average segmentation loss on validation set: 0.1080
2022-01-14 00:23:11,159 iteration 2465 : loss : 0.041813, loss_ce: 0.020528
 36%|█████████▊                 | 145/400 [1:03:24<1:57:25, 27.63s/it]2022-01-14 00:23:12,666 iteration 2466 : loss : 0.057473, loss_ce: 0.024772
2022-01-14 00:23:14,056 iteration 2467 : loss : 0.022836, loss_ce: 0.008896
2022-01-14 00:23:15,553 iteration 2468 : loss : 0.037152, loss_ce: 0.014454
2022-01-14 00:23:16,904 iteration 2469 : loss : 0.039693, loss_ce: 0.019065
2022-01-14 00:23:18,332 iteration 2470 : loss : 0.050435, loss_ce: 0.020417
2022-01-14 00:23:19,791 iteration 2471 : loss : 0.045564, loss_ce: 0.020589
2022-01-14 00:23:21,219 iteration 2472 : loss : 0.031581, loss_ce: 0.011931
2022-01-14 00:23:22,609 iteration 2473 : loss : 0.027864, loss_ce: 0.011944
2022-01-14 00:23:23,914 iteration 2474 : loss : 0.034348, loss_ce: 0.015652
2022-01-14 00:23:25,356 iteration 2475 : loss : 0.049484, loss_ce: 0.029734
2022-01-14 00:23:26,770 iteration 2476 : loss : 0.044310, loss_ce: 0.015285
2022-01-14 00:23:28,175 iteration 2477 : loss : 0.039000, loss_ce: 0.012210
2022-01-14 00:23:29,561 iteration 2478 : loss : 0.047291, loss_ce: 0.017772
2022-01-14 00:23:30,997 iteration 2479 : loss : 0.034443, loss_ce: 0.010747
2022-01-14 00:23:32,379 iteration 2480 : loss : 0.034673, loss_ce: 0.015096
2022-01-14 00:23:33,742 iteration 2481 : loss : 0.036971, loss_ce: 0.016006
2022-01-14 00:23:35,235 iteration 2482 : loss : 0.061514, loss_ce: 0.024577
 36%|█████████▊                 | 146/400 [1:03:48<1:52:26, 26.56s/it]2022-01-14 00:23:36,701 iteration 2483 : loss : 0.056078, loss_ce: 0.027768
2022-01-14 00:23:38,131 iteration 2484 : loss : 0.072051, loss_ce: 0.014868
2022-01-14 00:23:39,548 iteration 2485 : loss : 0.055640, loss_ce: 0.019303
2022-01-14 00:23:40,974 iteration 2486 : loss : 0.041526, loss_ce: 0.017718
2022-01-14 00:23:42,321 iteration 2487 : loss : 0.026879, loss_ce: 0.011559
2022-01-14 00:23:43,777 iteration 2488 : loss : 0.038554, loss_ce: 0.018332
2022-01-14 00:23:45,236 iteration 2489 : loss : 0.037244, loss_ce: 0.015596
2022-01-14 00:23:46,697 iteration 2490 : loss : 0.051108, loss_ce: 0.023788
2022-01-14 00:23:48,121 iteration 2491 : loss : 0.037915, loss_ce: 0.012054
2022-01-14 00:23:49,553 iteration 2492 : loss : 0.041541, loss_ce: 0.016063
2022-01-14 00:23:50,922 iteration 2493 : loss : 0.030406, loss_ce: 0.011533
2022-01-14 00:23:52,343 iteration 2494 : loss : 0.034173, loss_ce: 0.013583
2022-01-14 00:23:53,834 iteration 2495 : loss : 0.026166, loss_ce: 0.012518
2022-01-14 00:23:55,135 iteration 2496 : loss : 0.020700, loss_ce: 0.007814
2022-01-14 00:23:56,514 iteration 2497 : loss : 0.038845, loss_ce: 0.014389
2022-01-14 00:23:58,063 iteration 2498 : loss : 0.025912, loss_ce: 0.009721
2022-01-14 00:23:59,478 iteration 2499 : loss : 0.031997, loss_ce: 0.014538
 37%|█████████▉                 | 147/400 [1:04:12<1:49:04, 25.87s/it]2022-01-14 00:24:00,980 iteration 2500 : loss : 0.041344, loss_ce: 0.018912
2022-01-14 00:24:02,413 iteration 2501 : loss : 0.029256, loss_ce: 0.011959
2022-01-14 00:24:03,836 iteration 2502 : loss : 0.048527, loss_ce: 0.025360
2022-01-14 00:24:05,230 iteration 2503 : loss : 0.036126, loss_ce: 0.016746
2022-01-14 00:24:06,658 iteration 2504 : loss : 0.051227, loss_ce: 0.016894
2022-01-14 00:24:08,069 iteration 2505 : loss : 0.043253, loss_ce: 0.017346
2022-01-14 00:24:09,496 iteration 2506 : loss : 0.026265, loss_ce: 0.011006
2022-01-14 00:24:10,853 iteration 2507 : loss : 0.030478, loss_ce: 0.012297
2022-01-14 00:24:12,177 iteration 2508 : loss : 0.042986, loss_ce: 0.019877
2022-01-14 00:24:13,561 iteration 2509 : loss : 0.024364, loss_ce: 0.010572
2022-01-14 00:24:14,906 iteration 2510 : loss : 0.044147, loss_ce: 0.013756
2022-01-14 00:24:16,293 iteration 2511 : loss : 0.036784, loss_ce: 0.017494
2022-01-14 00:24:17,682 iteration 2512 : loss : 0.034054, loss_ce: 0.013732
2022-01-14 00:24:19,070 iteration 2513 : loss : 0.050974, loss_ce: 0.018385
2022-01-14 00:24:20,474 iteration 2514 : loss : 0.045986, loss_ce: 0.019531
2022-01-14 00:24:21,855 iteration 2515 : loss : 0.031214, loss_ce: 0.010149
2022-01-14 00:24:23,204 iteration 2516 : loss : 0.037478, loss_ce: 0.017318
 37%|█████████▉                 | 148/400 [1:04:36<1:45:57, 25.23s/it]2022-01-14 00:24:24,634 iteration 2517 : loss : 0.032553, loss_ce: 0.012239
2022-01-14 00:24:26,135 iteration 2518 : loss : 0.062041, loss_ce: 0.027350
2022-01-14 00:24:27,530 iteration 2519 : loss : 0.039309, loss_ce: 0.015002
2022-01-14 00:24:28,913 iteration 2520 : loss : 0.027375, loss_ce: 0.008939
2022-01-14 00:24:30,362 iteration 2521 : loss : 0.029683, loss_ce: 0.013654
2022-01-14 00:24:31,704 iteration 2522 : loss : 0.028341, loss_ce: 0.010958
2022-01-14 00:24:32,998 iteration 2523 : loss : 0.037171, loss_ce: 0.009988
2022-01-14 00:24:34,454 iteration 2524 : loss : 0.024828, loss_ce: 0.011252
2022-01-14 00:24:35,822 iteration 2525 : loss : 0.033078, loss_ce: 0.012560
2022-01-14 00:24:37,188 iteration 2526 : loss : 0.030232, loss_ce: 0.011364
2022-01-14 00:24:38,649 iteration 2527 : loss : 0.029103, loss_ce: 0.011129
2022-01-14 00:24:40,020 iteration 2528 : loss : 0.048279, loss_ce: 0.019570
2022-01-14 00:24:41,449 iteration 2529 : loss : 0.028722, loss_ce: 0.010733
2022-01-14 00:24:42,857 iteration 2530 : loss : 0.046552, loss_ce: 0.014509
2022-01-14 00:24:44,242 iteration 2531 : loss : 0.035281, loss_ce: 0.012183
2022-01-14 00:24:45,671 iteration 2532 : loss : 0.048125, loss_ce: 0.019347
2022-01-14 00:24:47,078 iteration 2533 : loss : 0.042680, loss_ce: 0.024367
 37%|██████████                 | 149/400 [1:05:00<1:43:50, 24.82s/it]2022-01-14 00:24:48,522 iteration 2534 : loss : 0.026519, loss_ce: 0.010601
2022-01-14 00:24:49,952 iteration 2535 : loss : 0.029192, loss_ce: 0.008188
2022-01-14 00:24:51,389 iteration 2536 : loss : 0.040672, loss_ce: 0.018684
2022-01-14 00:24:52,836 iteration 2537 : loss : 0.054768, loss_ce: 0.023251
2022-01-14 00:24:54,304 iteration 2538 : loss : 0.051486, loss_ce: 0.019109
2022-01-14 00:24:55,641 iteration 2539 : loss : 0.033175, loss_ce: 0.014616
2022-01-14 00:24:57,073 iteration 2540 : loss : 0.038102, loss_ce: 0.014756
2022-01-14 00:24:58,597 iteration 2541 : loss : 0.043660, loss_ce: 0.013157
2022-01-14 00:24:59,948 iteration 2542 : loss : 0.029233, loss_ce: 0.010747
2022-01-14 00:25:01,376 iteration 2543 : loss : 0.047631, loss_ce: 0.016318
2022-01-14 00:25:02,853 iteration 2544 : loss : 0.060764, loss_ce: 0.025809
2022-01-14 00:25:04,317 iteration 2545 : loss : 0.038649, loss_ce: 0.020299
2022-01-14 00:25:05,661 iteration 2546 : loss : 0.027386, loss_ce: 0.010812
2022-01-14 00:25:07,060 iteration 2547 : loss : 0.042925, loss_ce: 0.010245
2022-01-14 00:25:08,472 iteration 2548 : loss : 0.047365, loss_ce: 0.018771
2022-01-14 00:25:09,943 iteration 2549 : loss : 0.049688, loss_ce: 0.017701
2022-01-14 00:25:09,943 Training Data Eval:
2022-01-14 00:25:17,111   Average segmentation loss on training set: 0.0301
2022-01-14 00:25:17,112 Validation Data Eval:
2022-01-14 00:25:19,593   Average segmentation loss on validation set: 0.1399
2022-01-14 00:25:21,018 iteration 2550 : loss : 0.061347, loss_ce: 0.036155
 38%|██████████▏                | 150/400 [1:05:34<1:54:47, 27.55s/it]2022-01-14 00:25:22,489 iteration 2551 : loss : 0.044866, loss_ce: 0.016219
2022-01-14 00:25:23,906 iteration 2552 : loss : 0.036950, loss_ce: 0.016026
2022-01-14 00:25:25,383 iteration 2553 : loss : 0.044685, loss_ce: 0.015430
2022-01-14 00:25:26,817 iteration 2554 : loss : 0.044538, loss_ce: 0.013312
2022-01-14 00:25:28,193 iteration 2555 : loss : 0.035982, loss_ce: 0.010446
2022-01-14 00:25:29,541 iteration 2556 : loss : 0.032730, loss_ce: 0.013283
2022-01-14 00:25:31,029 iteration 2557 : loss : 0.036412, loss_ce: 0.016226
2022-01-14 00:25:32,471 iteration 2558 : loss : 0.028452, loss_ce: 0.011974
2022-01-14 00:25:33,949 iteration 2559 : loss : 0.051531, loss_ce: 0.012691
2022-01-14 00:25:35,407 iteration 2560 : loss : 0.038134, loss_ce: 0.015523
2022-01-14 00:25:36,796 iteration 2561 : loss : 0.045857, loss_ce: 0.018014
2022-01-14 00:25:38,150 iteration 2562 : loss : 0.030980, loss_ce: 0.014455
2022-01-14 00:25:39,540 iteration 2563 : loss : 0.044573, loss_ce: 0.013250
2022-01-14 00:25:40,927 iteration 2564 : loss : 0.036696, loss_ce: 0.015699
2022-01-14 00:25:42,316 iteration 2565 : loss : 0.043749, loss_ce: 0.013085
2022-01-14 00:25:43,697 iteration 2566 : loss : 0.036194, loss_ce: 0.016870
2022-01-14 00:25:45,177 iteration 2567 : loss : 0.039729, loss_ce: 0.015623
 38%|██████████▏                | 151/400 [1:05:58<1:50:08, 26.54s/it]2022-01-14 00:25:46,637 iteration 2568 : loss : 0.036034, loss_ce: 0.017136
2022-01-14 00:25:48,053 iteration 2569 : loss : 0.037240, loss_ce: 0.014054
2022-01-14 00:25:49,427 iteration 2570 : loss : 0.051235, loss_ce: 0.013380
2022-01-14 00:25:50,826 iteration 2571 : loss : 0.053010, loss_ce: 0.020059
2022-01-14 00:25:52,179 iteration 2572 : loss : 0.032260, loss_ce: 0.010158
2022-01-14 00:25:53,550 iteration 2573 : loss : 0.026990, loss_ce: 0.010555
2022-01-14 00:25:54,933 iteration 2574 : loss : 0.074690, loss_ce: 0.030470
2022-01-14 00:25:56,360 iteration 2575 : loss : 0.037634, loss_ce: 0.013379
2022-01-14 00:25:57,861 iteration 2576 : loss : 0.045403, loss_ce: 0.021786
2022-01-14 00:25:59,229 iteration 2577 : loss : 0.047447, loss_ce: 0.017572
2022-01-14 00:26:00,665 iteration 2578 : loss : 0.040083, loss_ce: 0.018708
2022-01-14 00:26:02,033 iteration 2579 : loss : 0.040389, loss_ce: 0.012345
2022-01-14 00:26:03,460 iteration 2580 : loss : 0.027279, loss_ce: 0.007923
2022-01-14 00:26:04,984 iteration 2581 : loss : 0.038001, loss_ce: 0.015554
2022-01-14 00:26:06,295 iteration 2582 : loss : 0.032380, loss_ce: 0.012836
2022-01-14 00:26:07,756 iteration 2583 : loss : 0.037874, loss_ce: 0.015468
2022-01-14 00:26:09,152 iteration 2584 : loss : 0.028232, loss_ce: 0.011846
 38%|██████████▎                | 152/400 [1:06:22<1:46:29, 25.77s/it]2022-01-14 00:26:10,646 iteration 2585 : loss : 0.029921, loss_ce: 0.014040
2022-01-14 00:26:12,060 iteration 2586 : loss : 0.035470, loss_ce: 0.016202
2022-01-14 00:26:13,401 iteration 2587 : loss : 0.025834, loss_ce: 0.008680
2022-01-14 00:26:14,780 iteration 2588 : loss : 0.040711, loss_ce: 0.016409
2022-01-14 00:26:16,131 iteration 2589 : loss : 0.030969, loss_ce: 0.011218
2022-01-14 00:26:17,584 iteration 2590 : loss : 0.034702, loss_ce: 0.013576
2022-01-14 00:26:18,994 iteration 2591 : loss : 0.031163, loss_ce: 0.014847
2022-01-14 00:26:20,396 iteration 2592 : loss : 0.039629, loss_ce: 0.014925
2022-01-14 00:26:21,777 iteration 2593 : loss : 0.028317, loss_ce: 0.010465
2022-01-14 00:26:23,206 iteration 2594 : loss : 0.029247, loss_ce: 0.011198
2022-01-14 00:26:24,731 iteration 2595 : loss : 0.049943, loss_ce: 0.014439
2022-01-14 00:26:26,085 iteration 2596 : loss : 0.029452, loss_ce: 0.009400
2022-01-14 00:26:27,511 iteration 2597 : loss : 0.057957, loss_ce: 0.016640
2022-01-14 00:26:28,913 iteration 2598 : loss : 0.028365, loss_ce: 0.011861
2022-01-14 00:26:30,353 iteration 2599 : loss : 0.028447, loss_ce: 0.015473
2022-01-14 00:26:31,754 iteration 2600 : loss : 0.043233, loss_ce: 0.019520
2022-01-14 00:26:33,201 iteration 2601 : loss : 0.028798, loss_ce: 0.011870
 38%|██████████▎                | 153/400 [1:06:46<1:43:57, 25.25s/it]2022-01-14 00:26:34,673 iteration 2602 : loss : 0.037522, loss_ce: 0.012271
2022-01-14 00:26:36,161 iteration 2603 : loss : 0.031614, loss_ce: 0.010659
2022-01-14 00:26:37,574 iteration 2604 : loss : 0.048736, loss_ce: 0.021916
2022-01-14 00:26:38,849 iteration 2605 : loss : 0.025388, loss_ce: 0.007033
2022-01-14 00:26:40,365 iteration 2606 : loss : 0.056144, loss_ce: 0.020545
2022-01-14 00:26:41,818 iteration 2607 : loss : 0.033595, loss_ce: 0.012052
2022-01-14 00:26:43,218 iteration 2608 : loss : 0.034248, loss_ce: 0.014957
2022-01-14 00:26:44,698 iteration 2609 : loss : 0.057866, loss_ce: 0.019101
2022-01-14 00:26:46,154 iteration 2610 : loss : 0.031893, loss_ce: 0.010554
2022-01-14 00:26:47,569 iteration 2611 : loss : 0.037084, loss_ce: 0.013379
2022-01-14 00:26:49,015 iteration 2612 : loss : 0.043052, loss_ce: 0.022226
2022-01-14 00:26:50,375 iteration 2613 : loss : 0.028606, loss_ce: 0.011914
2022-01-14 00:26:51,836 iteration 2614 : loss : 0.042319, loss_ce: 0.013561
2022-01-14 00:26:53,197 iteration 2615 : loss : 0.051764, loss_ce: 0.022379
2022-01-14 00:26:54,640 iteration 2616 : loss : 0.039668, loss_ce: 0.020616
2022-01-14 00:26:56,024 iteration 2617 : loss : 0.037682, loss_ce: 0.013398
2022-01-14 00:26:57,373 iteration 2618 : loss : 0.029147, loss_ce: 0.011539
 38%|██████████▍                | 154/400 [1:07:10<1:42:12, 24.93s/it]2022-01-14 00:26:58,814 iteration 2619 : loss : 0.046663, loss_ce: 0.013086
2022-01-14 00:27:00,178 iteration 2620 : loss : 0.029921, loss_ce: 0.013625
2022-01-14 00:27:01,622 iteration 2621 : loss : 0.041854, loss_ce: 0.014283
2022-01-14 00:27:03,019 iteration 2622 : loss : 0.041879, loss_ce: 0.010913
2022-01-14 00:27:04,437 iteration 2623 : loss : 0.041804, loss_ce: 0.019308
2022-01-14 00:27:05,783 iteration 2624 : loss : 0.027773, loss_ce: 0.008986
2022-01-14 00:27:07,212 iteration 2625 : loss : 0.048488, loss_ce: 0.010009
2022-01-14 00:27:08,633 iteration 2626 : loss : 0.040259, loss_ce: 0.017861
2022-01-14 00:27:10,161 iteration 2627 : loss : 0.038703, loss_ce: 0.013145
2022-01-14 00:27:11,503 iteration 2628 : loss : 0.029911, loss_ce: 0.012690
2022-01-14 00:27:12,950 iteration 2629 : loss : 0.032094, loss_ce: 0.013658
2022-01-14 00:27:14,368 iteration 2630 : loss : 0.029799, loss_ce: 0.011909
2022-01-14 00:27:15,778 iteration 2631 : loss : 0.030888, loss_ce: 0.012099
2022-01-14 00:27:17,163 iteration 2632 : loss : 0.029059, loss_ce: 0.009921
2022-01-14 00:27:18,605 iteration 2633 : loss : 0.038833, loss_ce: 0.019072
2022-01-14 00:27:20,069 iteration 2634 : loss : 0.039140, loss_ce: 0.012537
2022-01-14 00:27:20,069 Training Data Eval:
2022-01-14 00:27:27,182   Average segmentation loss on training set: 0.0218
2022-01-14 00:27:27,183 Validation Data Eval:
2022-01-14 00:27:29,666   Average segmentation loss on validation set: 0.0738
2022-01-14 00:27:31,104 iteration 2635 : loss : 0.025696, loss_ce: 0.009412
 39%|██████████▍                | 155/400 [1:07:44<1:52:34, 27.57s/it]2022-01-14 00:27:32,600 iteration 2636 : loss : 0.041675, loss_ce: 0.018947
2022-01-14 00:27:34,074 iteration 2637 : loss : 0.033606, loss_ce: 0.012704
2022-01-14 00:27:35,443 iteration 2638 : loss : 0.042534, loss_ce: 0.014878
2022-01-14 00:27:36,798 iteration 2639 : loss : 0.035161, loss_ce: 0.017555
2022-01-14 00:27:38,164 iteration 2640 : loss : 0.029994, loss_ce: 0.010470
2022-01-14 00:27:39,545 iteration 2641 : loss : 0.036482, loss_ce: 0.017587
2022-01-14 00:27:40,904 iteration 2642 : loss : 0.027361, loss_ce: 0.009857
2022-01-14 00:27:42,400 iteration 2643 : loss : 0.028948, loss_ce: 0.010190
2022-01-14 00:27:43,769 iteration 2644 : loss : 0.048193, loss_ce: 0.017388
2022-01-14 00:27:45,128 iteration 2645 : loss : 0.023561, loss_ce: 0.008423
2022-01-14 00:27:46,686 iteration 2646 : loss : 0.033840, loss_ce: 0.012195
2022-01-14 00:27:48,153 iteration 2647 : loss : 0.073811, loss_ce: 0.021209
2022-01-14 00:27:49,535 iteration 2648 : loss : 0.040615, loss_ce: 0.016383
2022-01-14 00:27:50,949 iteration 2649 : loss : 0.039585, loss_ce: 0.016097
2022-01-14 00:27:52,457 iteration 2650 : loss : 0.031939, loss_ce: 0.011173
2022-01-14 00:27:53,870 iteration 2651 : loss : 0.031193, loss_ce: 0.012791
2022-01-14 00:27:55,224 iteration 2652 : loss : 0.028727, loss_ce: 0.010349
 39%|██████████▌                | 156/400 [1:08:08<1:47:54, 26.54s/it]2022-01-14 00:27:56,795 iteration 2653 : loss : 0.024539, loss_ce: 0.011270
2022-01-14 00:27:58,212 iteration 2654 : loss : 0.042651, loss_ce: 0.013578
2022-01-14 00:27:59,723 iteration 2655 : loss : 0.031536, loss_ce: 0.015822
2022-01-14 00:28:01,104 iteration 2656 : loss : 0.041547, loss_ce: 0.012751
2022-01-14 00:28:02,499 iteration 2657 : loss : 0.052459, loss_ce: 0.019286
2022-01-14 00:28:03,819 iteration 2658 : loss : 0.027081, loss_ce: 0.012837
2022-01-14 00:28:05,182 iteration 2659 : loss : 0.048015, loss_ce: 0.010229
2022-01-14 00:28:06,641 iteration 2660 : loss : 0.039793, loss_ce: 0.012711
2022-01-14 00:28:08,037 iteration 2661 : loss : 0.026383, loss_ce: 0.011865
2022-01-14 00:28:09,442 iteration 2662 : loss : 0.051627, loss_ce: 0.025081
2022-01-14 00:28:10,816 iteration 2663 : loss : 0.031745, loss_ce: 0.008326
2022-01-14 00:28:12,327 iteration 2664 : loss : 0.048376, loss_ce: 0.018465
2022-01-14 00:28:13,730 iteration 2665 : loss : 0.041861, loss_ce: 0.014040
2022-01-14 00:28:15,091 iteration 2666 : loss : 0.022264, loss_ce: 0.007230
2022-01-14 00:28:16,571 iteration 2667 : loss : 0.069066, loss_ce: 0.030102
2022-01-14 00:28:17,937 iteration 2668 : loss : 0.031320, loss_ce: 0.010874
2022-01-14 00:28:19,302 iteration 2669 : loss : 0.039155, loss_ce: 0.012939
 39%|██████████▌                | 157/400 [1:08:32<1:44:28, 25.80s/it]2022-01-14 00:28:20,812 iteration 2670 : loss : 0.042469, loss_ce: 0.017072
2022-01-14 00:28:22,315 iteration 2671 : loss : 0.060676, loss_ce: 0.021916
2022-01-14 00:28:23,747 iteration 2672 : loss : 0.031100, loss_ce: 0.011826
2022-01-14 00:28:25,103 iteration 2673 : loss : 0.028036, loss_ce: 0.013900
2022-01-14 00:28:26,528 iteration 2674 : loss : 0.038296, loss_ce: 0.017039
2022-01-14 00:28:27,813 iteration 2675 : loss : 0.024172, loss_ce: 0.010769
2022-01-14 00:28:29,338 iteration 2676 : loss : 0.046697, loss_ce: 0.011825
2022-01-14 00:28:30,763 iteration 2677 : loss : 0.040143, loss_ce: 0.014856
2022-01-14 00:28:32,152 iteration 2678 : loss : 0.032947, loss_ce: 0.013577
2022-01-14 00:28:33,576 iteration 2679 : loss : 0.046228, loss_ce: 0.015577
2022-01-14 00:28:34,963 iteration 2680 : loss : 0.030777, loss_ce: 0.011691
2022-01-14 00:28:36,371 iteration 2681 : loss : 0.037855, loss_ce: 0.012703
2022-01-14 00:28:37,790 iteration 2682 : loss : 0.035974, loss_ce: 0.013598
2022-01-14 00:28:39,178 iteration 2683 : loss : 0.052281, loss_ce: 0.012779
2022-01-14 00:28:40,530 iteration 2684 : loss : 0.035477, loss_ce: 0.017890
2022-01-14 00:28:41,944 iteration 2685 : loss : 0.048206, loss_ce: 0.019511
2022-01-14 00:28:43,287 iteration 2686 : loss : 0.033000, loss_ce: 0.014332
 40%|██████████▋                | 158/400 [1:08:56<1:41:51, 25.25s/it]2022-01-14 00:28:44,657 iteration 2687 : loss : 0.037397, loss_ce: 0.010066
2022-01-14 00:28:46,046 iteration 2688 : loss : 0.056153, loss_ce: 0.018654
2022-01-14 00:28:47,415 iteration 2689 : loss : 0.030887, loss_ce: 0.011898
2022-01-14 00:28:48,936 iteration 2690 : loss : 0.051821, loss_ce: 0.025856
2022-01-14 00:28:50,271 iteration 2691 : loss : 0.025345, loss_ce: 0.010012
2022-01-14 00:28:51,621 iteration 2692 : loss : 0.038107, loss_ce: 0.012966
2022-01-14 00:28:53,039 iteration 2693 : loss : 0.055113, loss_ce: 0.018196
2022-01-14 00:28:54,501 iteration 2694 : loss : 0.035258, loss_ce: 0.011460
2022-01-14 00:28:55,864 iteration 2695 : loss : 0.027230, loss_ce: 0.011690
2022-01-14 00:28:57,289 iteration 2696 : loss : 0.032395, loss_ce: 0.014210
2022-01-14 00:28:58,629 iteration 2697 : loss : 0.029195, loss_ce: 0.013496
2022-01-14 00:28:59,922 iteration 2698 : loss : 0.026498, loss_ce: 0.011905
2022-01-14 00:29:01,364 iteration 2699 : loss : 0.036072, loss_ce: 0.015258
2022-01-14 00:29:02,819 iteration 2700 : loss : 0.036673, loss_ce: 0.019048
2022-01-14 00:29:04,220 iteration 2701 : loss : 0.036043, loss_ce: 0.014369
2022-01-14 00:29:05,652 iteration 2702 : loss : 0.079711, loss_ce: 0.015087
2022-01-14 00:29:07,038 iteration 2703 : loss : 0.027143, loss_ce: 0.010141
 40%|██████████▋                | 159/400 [1:09:20<1:39:37, 24.80s/it]2022-01-14 00:29:08,647 iteration 2704 : loss : 0.035800, loss_ce: 0.015841
2022-01-14 00:29:09,996 iteration 2705 : loss : 0.035774, loss_ce: 0.010214
2022-01-14 00:29:11,345 iteration 2706 : loss : 0.047283, loss_ce: 0.022361
2022-01-14 00:29:12,825 iteration 2707 : loss : 0.038077, loss_ce: 0.012869
2022-01-14 00:29:14,150 iteration 2708 : loss : 0.020140, loss_ce: 0.007763
2022-01-14 00:29:15,539 iteration 2709 : loss : 0.045174, loss_ce: 0.012018
2022-01-14 00:29:16,883 iteration 2710 : loss : 0.029557, loss_ce: 0.011133
2022-01-14 00:29:18,365 iteration 2711 : loss : 0.036161, loss_ce: 0.014759
2022-01-14 00:29:19,698 iteration 2712 : loss : 0.024207, loss_ce: 0.010063
2022-01-14 00:29:21,217 iteration 2713 : loss : 0.042997, loss_ce: 0.014766
2022-01-14 00:29:22,552 iteration 2714 : loss : 0.036902, loss_ce: 0.010956
2022-01-14 00:29:23,957 iteration 2715 : loss : 0.036223, loss_ce: 0.018233
2022-01-14 00:29:25,335 iteration 2716 : loss : 0.037713, loss_ce: 0.013992
2022-01-14 00:29:26,671 iteration 2717 : loss : 0.028695, loss_ce: 0.013595
2022-01-14 00:29:28,031 iteration 2718 : loss : 0.029656, loss_ce: 0.011112
2022-01-14 00:29:29,524 iteration 2719 : loss : 0.076232, loss_ce: 0.025752
2022-01-14 00:29:29,524 Training Data Eval:
2022-01-14 00:29:36,576   Average segmentation loss on training set: 0.0243
2022-01-14 00:29:36,577 Validation Data Eval:
2022-01-14 00:29:39,011   Average segmentation loss on validation set: 0.1041
2022-01-14 00:29:40,359 iteration 2720 : loss : 0.029844, loss_ce: 0.012898
 40%|██████████▊                | 160/400 [1:09:53<1:49:25, 27.36s/it]2022-01-14 00:29:41,844 iteration 2721 : loss : 0.036061, loss_ce: 0.015570
2022-01-14 00:29:43,260 iteration 2722 : loss : 0.033068, loss_ce: 0.012924
2022-01-14 00:29:44,682 iteration 2723 : loss : 0.028632, loss_ce: 0.011065
2022-01-14 00:29:46,029 iteration 2724 : loss : 0.049321, loss_ce: 0.018759
2022-01-14 00:29:47,330 iteration 2725 : loss : 0.027221, loss_ce: 0.010494
2022-01-14 00:29:48,682 iteration 2726 : loss : 0.038953, loss_ce: 0.013069
2022-01-14 00:29:50,007 iteration 2727 : loss : 0.026562, loss_ce: 0.009310
2022-01-14 00:29:51,511 iteration 2728 : loss : 0.036311, loss_ce: 0.016461
2022-01-14 00:29:52,905 iteration 2729 : loss : 0.056051, loss_ce: 0.018695
2022-01-14 00:29:54,357 iteration 2730 : loss : 0.030823, loss_ce: 0.012520
2022-01-14 00:29:55,776 iteration 2731 : loss : 0.042542, loss_ce: 0.016517
2022-01-14 00:29:57,254 iteration 2732 : loss : 0.049706, loss_ce: 0.024187
2022-01-14 00:29:58,674 iteration 2733 : loss : 0.047224, loss_ce: 0.018693
2022-01-14 00:30:00,110 iteration 2734 : loss : 0.025670, loss_ce: 0.008089
2022-01-14 00:30:01,426 iteration 2735 : loss : 0.031945, loss_ce: 0.012708
2022-01-14 00:30:02,884 iteration 2736 : loss : 0.041691, loss_ce: 0.021039
2022-01-14 00:30:04,259 iteration 2737 : loss : 0.036371, loss_ce: 0.014120
 40%|██████████▊                | 161/400 [1:10:17<1:44:50, 26.32s/it]2022-01-14 00:30:05,719 iteration 2738 : loss : 0.028569, loss_ce: 0.013095
2022-01-14 00:30:07,091 iteration 2739 : loss : 0.031879, loss_ce: 0.016261
2022-01-14 00:30:08,498 iteration 2740 : loss : 0.031750, loss_ce: 0.012076
2022-01-14 00:30:09,933 iteration 2741 : loss : 0.032025, loss_ce: 0.010464
2022-01-14 00:30:11,258 iteration 2742 : loss : 0.033546, loss_ce: 0.013178
2022-01-14 00:30:12,650 iteration 2743 : loss : 0.051316, loss_ce: 0.028784
2022-01-14 00:30:14,079 iteration 2744 : loss : 0.034847, loss_ce: 0.014035
2022-01-14 00:30:15,505 iteration 2745 : loss : 0.026933, loss_ce: 0.009686
2022-01-14 00:30:16,842 iteration 2746 : loss : 0.061349, loss_ce: 0.019695
2022-01-14 00:30:18,243 iteration 2747 : loss : 0.037406, loss_ce: 0.013536
2022-01-14 00:30:19,690 iteration 2748 : loss : 0.044261, loss_ce: 0.017217
2022-01-14 00:30:21,013 iteration 2749 : loss : 0.029732, loss_ce: 0.012934
2022-01-14 00:30:22,435 iteration 2750 : loss : 0.054097, loss_ce: 0.018491
2022-01-14 00:30:23,801 iteration 2751 : loss : 0.029390, loss_ce: 0.014811
2022-01-14 00:30:25,121 iteration 2752 : loss : 0.059581, loss_ce: 0.010983
2022-01-14 00:30:26,600 iteration 2753 : loss : 0.049333, loss_ce: 0.022097
2022-01-14 00:30:28,052 iteration 2754 : loss : 0.029235, loss_ce: 0.011465
 40%|██████████▉                | 162/400 [1:10:41<1:41:24, 25.56s/it]2022-01-14 00:30:29,502 iteration 2755 : loss : 0.023331, loss_ce: 0.009631
2022-01-14 00:30:30,909 iteration 2756 : loss : 0.055495, loss_ce: 0.030186
2022-01-14 00:30:32,311 iteration 2757 : loss : 0.035952, loss_ce: 0.014547
2022-01-14 00:30:33,761 iteration 2758 : loss : 0.051377, loss_ce: 0.019597
2022-01-14 00:30:35,173 iteration 2759 : loss : 0.037195, loss_ce: 0.010861
2022-01-14 00:30:36,583 iteration 2760 : loss : 0.050311, loss_ce: 0.017074
2022-01-14 00:30:37,892 iteration 2761 : loss : 0.039883, loss_ce: 0.015342
2022-01-14 00:30:39,222 iteration 2762 : loss : 0.028848, loss_ce: 0.010951
2022-01-14 00:30:40,671 iteration 2763 : loss : 0.065411, loss_ce: 0.025252
2022-01-14 00:30:42,065 iteration 2764 : loss : 0.034819, loss_ce: 0.012498
2022-01-14 00:30:43,458 iteration 2765 : loss : 0.054070, loss_ce: 0.020980
2022-01-14 00:30:44,831 iteration 2766 : loss : 0.032333, loss_ce: 0.013270
2022-01-14 00:30:46,258 iteration 2767 : loss : 0.030330, loss_ce: 0.011802
2022-01-14 00:30:47,608 iteration 2768 : loss : 0.036766, loss_ce: 0.011303
2022-01-14 00:30:49,003 iteration 2769 : loss : 0.034796, loss_ce: 0.014955
2022-01-14 00:30:50,405 iteration 2770 : loss : 0.040411, loss_ce: 0.019986
2022-01-14 00:30:51,800 iteration 2771 : loss : 0.041384, loss_ce: 0.015462
 41%|███████████                | 163/400 [1:11:05<1:38:49, 25.02s/it]2022-01-14 00:30:53,342 iteration 2772 : loss : 0.047569, loss_ce: 0.020576
2022-01-14 00:30:54,745 iteration 2773 : loss : 0.034233, loss_ce: 0.014523
2022-01-14 00:30:56,116 iteration 2774 : loss : 0.050299, loss_ce: 0.013437
2022-01-14 00:30:57,560 iteration 2775 : loss : 0.031282, loss_ce: 0.012398
2022-01-14 00:30:58,954 iteration 2776 : loss : 0.030651, loss_ce: 0.011344
2022-01-14 00:31:00,373 iteration 2777 : loss : 0.035239, loss_ce: 0.012030
2022-01-14 00:31:01,838 iteration 2778 : loss : 0.052212, loss_ce: 0.021333
2022-01-14 00:31:03,353 iteration 2779 : loss : 0.054253, loss_ce: 0.022998
2022-01-14 00:31:04,705 iteration 2780 : loss : 0.020287, loss_ce: 0.006677
2022-01-14 00:31:06,135 iteration 2781 : loss : 0.043687, loss_ce: 0.015738
2022-01-14 00:31:07,518 iteration 2782 : loss : 0.033170, loss_ce: 0.011879
2022-01-14 00:31:08,879 iteration 2783 : loss : 0.082974, loss_ce: 0.051859
2022-01-14 00:31:10,375 iteration 2784 : loss : 0.035457, loss_ce: 0.012222
2022-01-14 00:31:11,848 iteration 2785 : loss : 0.036967, loss_ce: 0.012024
2022-01-14 00:31:13,291 iteration 2786 : loss : 0.032692, loss_ce: 0.013548
2022-01-14 00:31:14,730 iteration 2787 : loss : 0.028986, loss_ce: 0.011433
2022-01-14 00:31:16,096 iteration 2788 : loss : 0.028944, loss_ce: 0.014957
 41%|███████████                | 164/400 [1:11:29<1:37:33, 24.80s/it]2022-01-14 00:31:17,518 iteration 2789 : loss : 0.039688, loss_ce: 0.018110
2022-01-14 00:31:18,939 iteration 2790 : loss : 0.034441, loss_ce: 0.012505
2022-01-14 00:31:20,309 iteration 2791 : loss : 0.030391, loss_ce: 0.011479
2022-01-14 00:31:21,769 iteration 2792 : loss : 0.065167, loss_ce: 0.026288
2022-01-14 00:31:23,118 iteration 2793 : loss : 0.036166, loss_ce: 0.016016
2022-01-14 00:31:24,557 iteration 2794 : loss : 0.031337, loss_ce: 0.010774
2022-01-14 00:31:25,906 iteration 2795 : loss : 0.033341, loss_ce: 0.009944
2022-01-14 00:31:27,358 iteration 2796 : loss : 0.044338, loss_ce: 0.017126
2022-01-14 00:31:28,779 iteration 2797 : loss : 0.039539, loss_ce: 0.016463
2022-01-14 00:31:30,246 iteration 2798 : loss : 0.047172, loss_ce: 0.023116
2022-01-14 00:31:31,596 iteration 2799 : loss : 0.030182, loss_ce: 0.013158
2022-01-14 00:31:32,929 iteration 2800 : loss : 0.053608, loss_ce: 0.020159
2022-01-14 00:31:34,253 iteration 2801 : loss : 0.027599, loss_ce: 0.008412
2022-01-14 00:31:35,707 iteration 2802 : loss : 0.037960, loss_ce: 0.013310
2022-01-14 00:31:37,094 iteration 2803 : loss : 0.040354, loss_ce: 0.018885
2022-01-14 00:31:38,464 iteration 2804 : loss : 0.031963, loss_ce: 0.011717
2022-01-14 00:31:38,464 Training Data Eval:
2022-01-14 00:31:45,382   Average segmentation loss on training set: 0.0304
2022-01-14 00:31:45,382 Validation Data Eval:
2022-01-14 00:31:47,829   Average segmentation loss on validation set: 0.1022
2022-01-14 00:31:49,266 iteration 2805 : loss : 0.038873, loss_ce: 0.015375
 41%|███████████▏               | 165/400 [1:12:02<1:46:58, 27.31s/it]2022-01-14 00:31:50,875 iteration 2806 : loss : 0.057065, loss_ce: 0.024501
2022-01-14 00:31:52,234 iteration 2807 : loss : 0.045383, loss_ce: 0.018218
2022-01-14 00:31:53,599 iteration 2808 : loss : 0.034844, loss_ce: 0.013823
2022-01-14 00:31:55,011 iteration 2809 : loss : 0.029669, loss_ce: 0.010607
2022-01-14 00:31:56,391 iteration 2810 : loss : 0.044409, loss_ce: 0.022203
2022-01-14 00:31:57,888 iteration 2811 : loss : 0.042215, loss_ce: 0.015245
2022-01-14 00:31:59,381 iteration 2812 : loss : 0.045908, loss_ce: 0.018952
2022-01-14 00:32:00,692 iteration 2813 : loss : 0.029443, loss_ce: 0.012457
2022-01-14 00:32:02,114 iteration 2814 : loss : 0.034972, loss_ce: 0.016610
2022-01-14 00:32:03,549 iteration 2815 : loss : 0.051817, loss_ce: 0.017685
2022-01-14 00:32:04,923 iteration 2816 : loss : 0.038591, loss_ce: 0.016296
2022-01-14 00:32:06,304 iteration 2817 : loss : 0.052476, loss_ce: 0.027680
2022-01-14 00:32:07,821 iteration 2818 : loss : 0.039601, loss_ce: 0.014349
2022-01-14 00:32:09,275 iteration 2819 : loss : 0.035042, loss_ce: 0.016053
2022-01-14 00:32:10,658 iteration 2820 : loss : 0.038757, loss_ce: 0.014143
2022-01-14 00:32:12,072 iteration 2821 : loss : 0.020167, loss_ce: 0.008248
2022-01-14 00:32:13,528 iteration 2822 : loss : 0.069179, loss_ce: 0.014698
 42%|███████████▏               | 166/400 [1:12:26<1:42:56, 26.39s/it]2022-01-14 00:32:15,034 iteration 2823 : loss : 0.032893, loss_ce: 0.012946
2022-01-14 00:32:16,466 iteration 2824 : loss : 0.048825, loss_ce: 0.015240
2022-01-14 00:32:17,884 iteration 2825 : loss : 0.040831, loss_ce: 0.013078
2022-01-14 00:32:19,245 iteration 2826 : loss : 0.030205, loss_ce: 0.011117
2022-01-14 00:32:20,689 iteration 2827 : loss : 0.044047, loss_ce: 0.021734
2022-01-14 00:32:22,058 iteration 2828 : loss : 0.055510, loss_ce: 0.028744
2022-01-14 00:32:23,429 iteration 2829 : loss : 0.049821, loss_ce: 0.016572
2022-01-14 00:32:24,858 iteration 2830 : loss : 0.031990, loss_ce: 0.014924
2022-01-14 00:32:26,239 iteration 2831 : loss : 0.053984, loss_ce: 0.016851
2022-01-14 00:32:27,588 iteration 2832 : loss : 0.032579, loss_ce: 0.013769
2022-01-14 00:32:29,082 iteration 2833 : loss : 0.032056, loss_ce: 0.012906
2022-01-14 00:32:30,506 iteration 2834 : loss : 0.035696, loss_ce: 0.014631
2022-01-14 00:32:31,932 iteration 2835 : loss : 0.044442, loss_ce: 0.019255
2022-01-14 00:32:33,369 iteration 2836 : loss : 0.036760, loss_ce: 0.014467
2022-01-14 00:32:34,813 iteration 2837 : loss : 0.027716, loss_ce: 0.010362
2022-01-14 00:32:36,244 iteration 2838 : loss : 0.034498, loss_ce: 0.011747
2022-01-14 00:32:37,590 iteration 2839 : loss : 0.034271, loss_ce: 0.014851
 42%|███████████▎               | 167/400 [1:12:51<1:39:46, 25.69s/it]2022-01-14 00:32:39,042 iteration 2840 : loss : 0.041247, loss_ce: 0.014409
2022-01-14 00:32:40,389 iteration 2841 : loss : 0.031523, loss_ce: 0.013578
2022-01-14 00:32:41,704 iteration 2842 : loss : 0.027169, loss_ce: 0.010823
2022-01-14 00:32:43,090 iteration 2843 : loss : 0.041948, loss_ce: 0.015519
2022-01-14 00:32:44,545 iteration 2844 : loss : 0.035975, loss_ce: 0.014608
2022-01-14 00:32:46,003 iteration 2845 : loss : 0.035754, loss_ce: 0.012073
2022-01-14 00:32:47,387 iteration 2846 : loss : 0.032463, loss_ce: 0.011762
2022-01-14 00:32:48,810 iteration 2847 : loss : 0.036169, loss_ce: 0.015552
2022-01-14 00:32:50,299 iteration 2848 : loss : 0.056185, loss_ce: 0.029060
2022-01-14 00:32:51,686 iteration 2849 : loss : 0.047692, loss_ce: 0.018826
2022-01-14 00:32:53,089 iteration 2850 : loss : 0.036351, loss_ce: 0.014130
2022-01-14 00:32:54,528 iteration 2851 : loss : 0.027294, loss_ce: 0.011734
2022-01-14 00:32:55,953 iteration 2852 : loss : 0.034722, loss_ce: 0.015321
2022-01-14 00:32:57,348 iteration 2853 : loss : 0.027502, loss_ce: 0.011524
2022-01-14 00:32:58,806 iteration 2854 : loss : 0.045414, loss_ce: 0.021153
2022-01-14 00:33:00,208 iteration 2855 : loss : 0.042424, loss_ce: 0.020977
2022-01-14 00:33:01,675 iteration 2856 : loss : 0.036780, loss_ce: 0.016152
 42%|███████████▎               | 168/400 [1:13:15<1:37:29, 25.21s/it]2022-01-14 00:33:03,189 iteration 2857 : loss : 0.046295, loss_ce: 0.014090
2022-01-14 00:33:04,604 iteration 2858 : loss : 0.066499, loss_ce: 0.023001
2022-01-14 00:33:05,948 iteration 2859 : loss : 0.023086, loss_ce: 0.008355
2022-01-14 00:33:07,420 iteration 2860 : loss : 0.061086, loss_ce: 0.027205
2022-01-14 00:33:08,773 iteration 2861 : loss : 0.031424, loss_ce: 0.010802
2022-01-14 00:33:10,192 iteration 2862 : loss : 0.031743, loss_ce: 0.011742
2022-01-14 00:33:11,677 iteration 2863 : loss : 0.060943, loss_ce: 0.021657
2022-01-14 00:33:13,093 iteration 2864 : loss : 0.031724, loss_ce: 0.015746
2022-01-14 00:33:14,429 iteration 2865 : loss : 0.031858, loss_ce: 0.012912
2022-01-14 00:33:15,815 iteration 2866 : loss : 0.029089, loss_ce: 0.008791
2022-01-14 00:33:17,271 iteration 2867 : loss : 0.049825, loss_ce: 0.021724
2022-01-14 00:33:18,713 iteration 2868 : loss : 0.025155, loss_ce: 0.010183
2022-01-14 00:33:20,083 iteration 2869 : loss : 0.026816, loss_ce: 0.012095
2022-01-14 00:33:21,534 iteration 2870 : loss : 0.051358, loss_ce: 0.025612
2022-01-14 00:33:22,887 iteration 2871 : loss : 0.022741, loss_ce: 0.010511
2022-01-14 00:33:24,311 iteration 2872 : loss : 0.048255, loss_ce: 0.015711
2022-01-14 00:33:25,787 iteration 2873 : loss : 0.032411, loss_ce: 0.015989
 42%|███████████▍               | 169/400 [1:13:39<1:35:48, 24.89s/it]2022-01-14 00:33:27,244 iteration 2874 : loss : 0.042225, loss_ce: 0.013670
2022-01-14 00:33:28,591 iteration 2875 : loss : 0.025217, loss_ce: 0.009653
2022-01-14 00:33:29,977 iteration 2876 : loss : 0.024373, loss_ce: 0.009828
2022-01-14 00:33:31,384 iteration 2877 : loss : 0.038477, loss_ce: 0.013721
2022-01-14 00:33:32,825 iteration 2878 : loss : 0.041863, loss_ce: 0.016107
2022-01-14 00:33:34,168 iteration 2879 : loss : 0.028750, loss_ce: 0.014314
2022-01-14 00:33:35,635 iteration 2880 : loss : 0.056082, loss_ce: 0.027949
2022-01-14 00:33:37,030 iteration 2881 : loss : 0.036570, loss_ce: 0.016612
2022-01-14 00:33:38,511 iteration 2882 : loss : 0.091566, loss_ce: 0.032704
2022-01-14 00:33:39,992 iteration 2883 : loss : 0.038516, loss_ce: 0.016400
2022-01-14 00:33:41,473 iteration 2884 : loss : 0.032972, loss_ce: 0.010082
2022-01-14 00:33:42,878 iteration 2885 : loss : 0.042117, loss_ce: 0.019468
2022-01-14 00:33:44,246 iteration 2886 : loss : 0.039352, loss_ce: 0.012849
2022-01-14 00:33:45,628 iteration 2887 : loss : 0.026020, loss_ce: 0.009091
2022-01-14 00:33:47,110 iteration 2888 : loss : 0.042959, loss_ce: 0.014293
2022-01-14 00:33:48,542 iteration 2889 : loss : 0.040996, loss_ce: 0.015187
2022-01-14 00:33:48,542 Training Data Eval:
2022-01-14 00:33:55,658   Average segmentation loss on training set: 0.0214
2022-01-14 00:33:55,658 Validation Data Eval:
2022-01-14 00:33:58,099   Average segmentation loss on validation set: 0.0970
2022-01-14 00:33:59,582 iteration 2890 : loss : 0.038058, loss_ce: 0.014194
 42%|███████████▍               | 170/400 [1:14:13<1:45:37, 27.56s/it]2022-01-14 00:34:01,107 iteration 2891 : loss : 0.035070, loss_ce: 0.017331
2022-01-14 00:34:02,452 iteration 2892 : loss : 0.028648, loss_ce: 0.014713
2022-01-14 00:34:03,832 iteration 2893 : loss : 0.039481, loss_ce: 0.011905
2022-01-14 00:34:05,252 iteration 2894 : loss : 0.021618, loss_ce: 0.009018
2022-01-14 00:34:06,626 iteration 2895 : loss : 0.027641, loss_ce: 0.008463
2022-01-14 00:34:07,988 iteration 2896 : loss : 0.027628, loss_ce: 0.010847
2022-01-14 00:34:09,366 iteration 2897 : loss : 0.039356, loss_ce: 0.014923
2022-01-14 00:34:10,758 iteration 2898 : loss : 0.039747, loss_ce: 0.020591
2022-01-14 00:34:12,213 iteration 2899 : loss : 0.036023, loss_ce: 0.013010
2022-01-14 00:34:13,553 iteration 2900 : loss : 0.024309, loss_ce: 0.007856
2022-01-14 00:34:15,035 iteration 2901 : loss : 0.026370, loss_ce: 0.008580
2022-01-14 00:34:16,337 iteration 2902 : loss : 0.029154, loss_ce: 0.009578
2022-01-14 00:34:17,755 iteration 2903 : loss : 0.033795, loss_ce: 0.016233
2022-01-14 00:34:19,211 iteration 2904 : loss : 0.043786, loss_ce: 0.012752
2022-01-14 00:34:20,622 iteration 2905 : loss : 0.030571, loss_ce: 0.011555
2022-01-14 00:34:22,074 iteration 2906 : loss : 0.032437, loss_ce: 0.011332
2022-01-14 00:34:23,435 iteration 2907 : loss : 0.036261, loss_ce: 0.017891
 43%|███████████▌               | 171/400 [1:14:36<1:40:55, 26.44s/it]2022-01-14 00:34:24,898 iteration 2908 : loss : 0.028938, loss_ce: 0.011617
2022-01-14 00:34:26,226 iteration 2909 : loss : 0.032975, loss_ce: 0.007147
2022-01-14 00:34:27,659 iteration 2910 : loss : 0.062701, loss_ce: 0.022244
2022-01-14 00:34:29,064 iteration 2911 : loss : 0.040818, loss_ce: 0.016590
2022-01-14 00:34:30,453 iteration 2912 : loss : 0.027638, loss_ce: 0.010321
2022-01-14 00:34:31,907 iteration 2913 : loss : 0.025898, loss_ce: 0.010936
2022-01-14 00:34:33,320 iteration 2914 : loss : 0.033827, loss_ce: 0.014020
2022-01-14 00:34:34,768 iteration 2915 : loss : 0.032798, loss_ce: 0.011182
2022-01-14 00:34:36,128 iteration 2916 : loss : 0.025962, loss_ce: 0.013719
2022-01-14 00:34:37,580 iteration 2917 : loss : 0.045952, loss_ce: 0.021053
2022-01-14 00:34:39,007 iteration 2918 : loss : 0.043039, loss_ce: 0.016174
2022-01-14 00:34:40,441 iteration 2919 : loss : 0.074350, loss_ce: 0.039123
2022-01-14 00:34:41,860 iteration 2920 : loss : 0.039877, loss_ce: 0.011974
2022-01-14 00:34:43,356 iteration 2921 : loss : 0.032036, loss_ce: 0.009831
2022-01-14 00:34:44,738 iteration 2922 : loss : 0.034271, loss_ce: 0.015402
2022-01-14 00:34:46,174 iteration 2923 : loss : 0.042042, loss_ce: 0.016552
2022-01-14 00:34:47,559 iteration 2924 : loss : 0.031400, loss_ce: 0.011516
 43%|███████████▌               | 172/400 [1:15:00<1:37:51, 25.75s/it]2022-01-14 00:34:49,114 iteration 2925 : loss : 0.040643, loss_ce: 0.015965
2022-01-14 00:34:50,501 iteration 2926 : loss : 0.042148, loss_ce: 0.014774
2022-01-14 00:34:51,965 iteration 2927 : loss : 0.043214, loss_ce: 0.022734
2022-01-14 00:34:53,500 iteration 2928 : loss : 0.055651, loss_ce: 0.021057
2022-01-14 00:34:54,874 iteration 2929 : loss : 0.022219, loss_ce: 0.007548
2022-01-14 00:34:56,248 iteration 2930 : loss : 0.046486, loss_ce: 0.022800
2022-01-14 00:34:57,584 iteration 2931 : loss : 0.043860, loss_ce: 0.019220
2022-01-14 00:34:59,051 iteration 2932 : loss : 0.024318, loss_ce: 0.009017
2022-01-14 00:35:00,429 iteration 2933 : loss : 0.035001, loss_ce: 0.013186
2022-01-14 00:35:01,897 iteration 2934 : loss : 0.031619, loss_ce: 0.014071
2022-01-14 00:35:03,308 iteration 2935 : loss : 0.062135, loss_ce: 0.019850
2022-01-14 00:35:04,789 iteration 2936 : loss : 0.027095, loss_ce: 0.012078
2022-01-14 00:35:06,173 iteration 2937 : loss : 0.027078, loss_ce: 0.011343
2022-01-14 00:35:07,572 iteration 2938 : loss : 0.025080, loss_ce: 0.010106
2022-01-14 00:35:08,974 iteration 2939 : loss : 0.028844, loss_ce: 0.013187
2022-01-14 00:35:10,406 iteration 2940 : loss : 0.034382, loss_ce: 0.010633
2022-01-14 00:35:11,797 iteration 2941 : loss : 0.034647, loss_ce: 0.012337
 43%|███████████▋               | 173/400 [1:15:25<1:35:42, 25.30s/it]2022-01-14 00:35:13,317 iteration 2942 : loss : 0.025441, loss_ce: 0.010283
2022-01-14 00:35:14,628 iteration 2943 : loss : 0.023234, loss_ce: 0.009633
2022-01-14 00:35:15,963 iteration 2944 : loss : 0.032109, loss_ce: 0.011058
2022-01-14 00:35:17,432 iteration 2945 : loss : 0.037137, loss_ce: 0.017002
2022-01-14 00:35:18,786 iteration 2946 : loss : 0.027026, loss_ce: 0.011348
2022-01-14 00:35:20,130 iteration 2947 : loss : 0.024061, loss_ce: 0.007638
2022-01-14 00:35:21,531 iteration 2948 : loss : 0.037474, loss_ce: 0.014463
2022-01-14 00:35:22,955 iteration 2949 : loss : 0.024319, loss_ce: 0.008921
2022-01-14 00:35:24,344 iteration 2950 : loss : 0.031610, loss_ce: 0.014136
2022-01-14 00:35:25,689 iteration 2951 : loss : 0.025881, loss_ce: 0.009409
2022-01-14 00:35:27,079 iteration 2952 : loss : 0.031771, loss_ce: 0.009258
2022-01-14 00:35:28,476 iteration 2953 : loss : 0.035162, loss_ce: 0.012404
2022-01-14 00:35:29,895 iteration 2954 : loss : 0.055971, loss_ce: 0.016130
2022-01-14 00:35:31,245 iteration 2955 : loss : 0.042624, loss_ce: 0.018609
2022-01-14 00:35:32,648 iteration 2956 : loss : 0.024835, loss_ce: 0.010915
2022-01-14 00:35:34,036 iteration 2957 : loss : 0.040572, loss_ce: 0.010636
2022-01-14 00:35:35,428 iteration 2958 : loss : 0.046907, loss_ce: 0.016327
 44%|███████████▋               | 174/400 [1:15:48<1:33:23, 24.79s/it]2022-01-14 00:35:36,983 iteration 2959 : loss : 0.029144, loss_ce: 0.013475
2022-01-14 00:35:38,402 iteration 2960 : loss : 0.032014, loss_ce: 0.011503
2022-01-14 00:35:39,862 iteration 2961 : loss : 0.026895, loss_ce: 0.012420
2022-01-14 00:35:41,213 iteration 2962 : loss : 0.034392, loss_ce: 0.012097
2022-01-14 00:35:42,595 iteration 2963 : loss : 0.033094, loss_ce: 0.012773
2022-01-14 00:35:44,065 iteration 2964 : loss : 0.045947, loss_ce: 0.017780
2022-01-14 00:35:45,465 iteration 2965 : loss : 0.023298, loss_ce: 0.010350
2022-01-14 00:35:46,850 iteration 2966 : loss : 0.037432, loss_ce: 0.011583
2022-01-14 00:35:48,313 iteration 2967 : loss : 0.060704, loss_ce: 0.019074
2022-01-14 00:35:49,701 iteration 2968 : loss : 0.044223, loss_ce: 0.018673
2022-01-14 00:35:51,055 iteration 2969 : loss : 0.043207, loss_ce: 0.012169
2022-01-14 00:35:52,422 iteration 2970 : loss : 0.035192, loss_ce: 0.015374
2022-01-14 00:35:53,837 iteration 2971 : loss : 0.041346, loss_ce: 0.015586
2022-01-14 00:35:55,266 iteration 2972 : loss : 0.031235, loss_ce: 0.010944
2022-01-14 00:35:56,655 iteration 2973 : loss : 0.063461, loss_ce: 0.033606
2022-01-14 00:35:58,188 iteration 2974 : loss : 0.034269, loss_ce: 0.014620
2022-01-14 00:35:58,189 Training Data Eval:
2022-01-14 00:36:05,106   Average segmentation loss on training set: 0.0223
2022-01-14 00:36:05,107 Validation Data Eval:
2022-01-14 00:36:07,498   Average segmentation loss on validation set: 0.0785
2022-01-14 00:36:08,872 iteration 2975 : loss : 0.033034, loss_ce: 0.012653
 44%|███████████▊               | 175/400 [1:16:22<1:42:43, 27.39s/it]2022-01-14 00:36:10,377 iteration 2976 : loss : 0.049725, loss_ce: 0.019005
2022-01-14 00:36:11,907 iteration 2977 : loss : 0.031715, loss_ce: 0.012051
2022-01-14 00:36:13,339 iteration 2978 : loss : 0.032369, loss_ce: 0.013119
2022-01-14 00:36:14,811 iteration 2979 : loss : 0.051211, loss_ce: 0.014472
2022-01-14 00:36:16,384 iteration 2980 : loss : 0.042929, loss_ce: 0.017776
2022-01-14 00:36:17,781 iteration 2981 : loss : 0.026068, loss_ce: 0.011687
2022-01-14 00:36:19,182 iteration 2982 : loss : 0.025993, loss_ce: 0.009817
2022-01-14 00:36:20,622 iteration 2983 : loss : 0.025282, loss_ce: 0.007008
2022-01-14 00:36:22,038 iteration 2984 : loss : 0.025250, loss_ce: 0.010195
2022-01-14 00:36:23,460 iteration 2985 : loss : 0.028938, loss_ce: 0.013233
2022-01-14 00:36:24,850 iteration 2986 : loss : 0.048241, loss_ce: 0.021859
2022-01-14 00:36:26,230 iteration 2987 : loss : 0.030345, loss_ce: 0.011087
2022-01-14 00:36:27,651 iteration 2988 : loss : 0.030218, loss_ce: 0.013153
2022-01-14 00:36:29,012 iteration 2989 : loss : 0.024486, loss_ce: 0.008786
2022-01-14 00:36:30,429 iteration 2990 : loss : 0.039195, loss_ce: 0.017613
2022-01-14 00:36:31,785 iteration 2991 : loss : 0.028471, loss_ce: 0.007910
2022-01-14 00:36:33,201 iteration 2992 : loss : 0.030595, loss_ce: 0.013332
 44%|███████████▉               | 176/400 [1:16:46<1:38:50, 26.47s/it]2022-01-14 00:36:34,685 iteration 2993 : loss : 0.036229, loss_ce: 0.014074
2022-01-14 00:36:36,070 iteration 2994 : loss : 0.032928, loss_ce: 0.011666
2022-01-14 00:36:37,520 iteration 2995 : loss : 0.033855, loss_ce: 0.013688
2022-01-14 00:36:38,912 iteration 2996 : loss : 0.029661, loss_ce: 0.010455
2022-01-14 00:36:40,310 iteration 2997 : loss : 0.027526, loss_ce: 0.009537
2022-01-14 00:36:41,742 iteration 2998 : loss : 0.026941, loss_ce: 0.012581
2022-01-14 00:36:43,139 iteration 2999 : loss : 0.034275, loss_ce: 0.011936
2022-01-14 00:36:44,538 iteration 3000 : loss : 0.023767, loss_ce: 0.009142
2022-01-14 00:36:46,012 iteration 3001 : loss : 0.029153, loss_ce: 0.011321
2022-01-14 00:36:47,458 iteration 3002 : loss : 0.027230, loss_ce: 0.011247
2022-01-14 00:36:48,795 iteration 3003 : loss : 0.022963, loss_ce: 0.009265
2022-01-14 00:36:50,181 iteration 3004 : loss : 0.021871, loss_ce: 0.009789
2022-01-14 00:36:51,555 iteration 3005 : loss : 0.029662, loss_ce: 0.011210
2022-01-14 00:36:52,935 iteration 3006 : loss : 0.038077, loss_ce: 0.013268
2022-01-14 00:36:54,336 iteration 3007 : loss : 0.030839, loss_ce: 0.009732
2022-01-14 00:36:55,683 iteration 3008 : loss : 0.027996, loss_ce: 0.010280
2022-01-14 00:36:57,038 iteration 3009 : loss : 0.027676, loss_ce: 0.007351
 44%|███████████▉               | 177/400 [1:17:10<1:35:26, 25.68s/it]2022-01-14 00:36:58,575 iteration 3010 : loss : 0.044262, loss_ce: 0.015305
2022-01-14 00:36:59,963 iteration 3011 : loss : 0.046327, loss_ce: 0.012097
2022-01-14 00:37:01,316 iteration 3012 : loss : 0.031545, loss_ce: 0.009969
2022-01-14 00:37:02,809 iteration 3013 : loss : 0.037635, loss_ce: 0.014048
2022-01-14 00:37:04,234 iteration 3014 : loss : 0.040183, loss_ce: 0.018140
2022-01-14 00:37:05,657 iteration 3015 : loss : 0.028558, loss_ce: 0.008966
2022-01-14 00:37:06,992 iteration 3016 : loss : 0.022324, loss_ce: 0.007011
2022-01-14 00:37:08,445 iteration 3017 : loss : 0.036664, loss_ce: 0.018495
2022-01-14 00:37:09,943 iteration 3018 : loss : 0.026496, loss_ce: 0.013250
2022-01-14 00:37:11,483 iteration 3019 : loss : 0.042918, loss_ce: 0.018535
2022-01-14 00:37:12,876 iteration 3020 : loss : 0.029741, loss_ce: 0.009802
2022-01-14 00:37:14,264 iteration 3021 : loss : 0.034904, loss_ce: 0.014075
2022-01-14 00:37:15,589 iteration 3022 : loss : 0.024462, loss_ce: 0.011539
2022-01-14 00:37:16,952 iteration 3023 : loss : 0.026136, loss_ce: 0.009268
2022-01-14 00:37:18,368 iteration 3024 : loss : 0.034987, loss_ce: 0.014480
2022-01-14 00:37:19,792 iteration 3025 : loss : 0.026141, loss_ce: 0.010220
2022-01-14 00:37:21,201 iteration 3026 : loss : 0.035143, loss_ce: 0.011405
 44%|████████████               | 178/400 [1:17:34<1:33:19, 25.23s/it]2022-01-14 00:37:22,702 iteration 3027 : loss : 0.045429, loss_ce: 0.020281
2022-01-14 00:37:24,213 iteration 3028 : loss : 0.031844, loss_ce: 0.012516
2022-01-14 00:37:25,600 iteration 3029 : loss : 0.022075, loss_ce: 0.006606
2022-01-14 00:37:27,079 iteration 3030 : loss : 0.030267, loss_ce: 0.010010
2022-01-14 00:37:28,582 iteration 3031 : loss : 0.037195, loss_ce: 0.013773
2022-01-14 00:37:30,065 iteration 3032 : loss : 0.042059, loss_ce: 0.015600
2022-01-14 00:37:31,526 iteration 3033 : loss : 0.033218, loss_ce: 0.012187
2022-01-14 00:37:32,939 iteration 3034 : loss : 0.028300, loss_ce: 0.008472
2022-01-14 00:37:34,311 iteration 3035 : loss : 0.027630, loss_ce: 0.011342
2022-01-14 00:37:35,790 iteration 3036 : loss : 0.034873, loss_ce: 0.016618
2022-01-14 00:37:37,172 iteration 3037 : loss : 0.032020, loss_ce: 0.012652
2022-01-14 00:37:38,537 iteration 3038 : loss : 0.029269, loss_ce: 0.015346
2022-01-14 00:37:39,932 iteration 3039 : loss : 0.024047, loss_ce: 0.008687
2022-01-14 00:37:41,458 iteration 3040 : loss : 0.068988, loss_ce: 0.021861
2022-01-14 00:37:42,785 iteration 3041 : loss : 0.022113, loss_ce: 0.008414
2022-01-14 00:37:44,162 iteration 3042 : loss : 0.032341, loss_ce: 0.016578
2022-01-14 00:37:45,560 iteration 3043 : loss : 0.025330, loss_ce: 0.009957
 45%|████████████               | 179/400 [1:17:58<1:31:57, 24.97s/it]2022-01-14 00:37:47,072 iteration 3044 : loss : 0.036014, loss_ce: 0.013616
2022-01-14 00:37:48,430 iteration 3045 : loss : 0.034589, loss_ce: 0.011501
2022-01-14 00:37:49,956 iteration 3046 : loss : 0.035447, loss_ce: 0.015028
2022-01-14 00:37:51,475 iteration 3047 : loss : 0.028057, loss_ce: 0.009529
2022-01-14 00:37:52,948 iteration 3048 : loss : 0.036127, loss_ce: 0.012912
2022-01-14 00:37:54,406 iteration 3049 : loss : 0.026776, loss_ce: 0.007983
2022-01-14 00:37:55,868 iteration 3050 : loss : 0.048271, loss_ce: 0.011883
2022-01-14 00:37:57,382 iteration 3051 : loss : 0.030608, loss_ce: 0.013266
2022-01-14 00:37:58,825 iteration 3052 : loss : 0.038999, loss_ce: 0.021239
2022-01-14 00:38:00,155 iteration 3053 : loss : 0.022316, loss_ce: 0.008034
2022-01-14 00:38:01,533 iteration 3054 : loss : 0.032946, loss_ce: 0.012114
2022-01-14 00:38:02,869 iteration 3055 : loss : 0.042341, loss_ce: 0.014820
2022-01-14 00:38:04,212 iteration 3056 : loss : 0.018908, loss_ce: 0.006871
2022-01-14 00:38:05,754 iteration 3057 : loss : 0.039845, loss_ce: 0.015498
2022-01-14 00:38:07,111 iteration 3058 : loss : 0.022177, loss_ce: 0.007498
2022-01-14 00:38:08,472 iteration 3059 : loss : 0.025370, loss_ce: 0.013174
2022-01-14 00:38:08,472 Training Data Eval:
2022-01-14 00:38:15,513   Average segmentation loss on training set: 0.0201
2022-01-14 00:38:15,514 Validation Data Eval:
2022-01-14 00:38:17,950   Average segmentation loss on validation set: 0.0768
2022-01-14 00:38:19,389 iteration 3060 : loss : 0.035334, loss_ce: 0.013115
 45%|████████████▏              | 180/400 [1:18:32<1:41:17, 27.62s/it]2022-01-14 00:38:20,877 iteration 3061 : loss : 0.042274, loss_ce: 0.010513
2022-01-14 00:38:22,341 iteration 3062 : loss : 0.034917, loss_ce: 0.015859
2022-01-14 00:38:23,732 iteration 3063 : loss : 0.024537, loss_ce: 0.009790
2022-01-14 00:38:25,145 iteration 3064 : loss : 0.037183, loss_ce: 0.018875
2022-01-14 00:38:26,576 iteration 3065 : loss : 0.028147, loss_ce: 0.007234
2022-01-14 00:38:27,944 iteration 3066 : loss : 0.033929, loss_ce: 0.009937
2022-01-14 00:38:29,414 iteration 3067 : loss : 0.025060, loss_ce: 0.010116
2022-01-14 00:38:30,886 iteration 3068 : loss : 0.033986, loss_ce: 0.012953
2022-01-14 00:38:32,242 iteration 3069 : loss : 0.021227, loss_ce: 0.007854
2022-01-14 00:38:33,640 iteration 3070 : loss : 0.046220, loss_ce: 0.016242
2022-01-14 00:38:35,174 iteration 3071 : loss : 0.060547, loss_ce: 0.022000
2022-01-14 00:38:36,574 iteration 3072 : loss : 0.023778, loss_ce: 0.008641
2022-01-14 00:38:37,951 iteration 3073 : loss : 0.033296, loss_ce: 0.010720
2022-01-14 00:38:39,338 iteration 3074 : loss : 0.032449, loss_ce: 0.013001
2022-01-14 00:38:40,773 iteration 3075 : loss : 0.038272, loss_ce: 0.012213
2022-01-14 00:38:42,117 iteration 3076 : loss : 0.020638, loss_ce: 0.007435
2022-01-14 00:38:43,598 iteration 3077 : loss : 0.054907, loss_ce: 0.016898
 45%|████████████▏              | 181/400 [1:18:57<1:37:05, 26.60s/it]2022-01-14 00:38:45,102 iteration 3078 : loss : 0.051752, loss_ce: 0.010914
2022-01-14 00:38:46,478 iteration 3079 : loss : 0.023599, loss_ce: 0.006931
2022-01-14 00:38:47,874 iteration 3080 : loss : 0.025112, loss_ce: 0.007496
2022-01-14 00:38:49,274 iteration 3081 : loss : 0.035516, loss_ce: 0.015317
2022-01-14 00:38:50,671 iteration 3082 : loss : 0.045243, loss_ce: 0.014406
2022-01-14 00:38:52,081 iteration 3083 : loss : 0.045384, loss_ce: 0.018246
2022-01-14 00:38:53,509 iteration 3084 : loss : 0.037650, loss_ce: 0.015896
2022-01-14 00:38:54,851 iteration 3085 : loss : 0.025999, loss_ce: 0.010066
2022-01-14 00:38:56,241 iteration 3086 : loss : 0.041318, loss_ce: 0.022060
2022-01-14 00:38:57,684 iteration 3087 : loss : 0.026000, loss_ce: 0.010366
2022-01-14 00:38:59,079 iteration 3088 : loss : 0.037425, loss_ce: 0.016072
2022-01-14 00:39:00,572 iteration 3089 : loss : 0.058106, loss_ce: 0.022895
2022-01-14 00:39:01,923 iteration 3090 : loss : 0.030575, loss_ce: 0.012683
2022-01-14 00:39:03,394 iteration 3091 : loss : 0.046494, loss_ce: 0.022025
2022-01-14 00:39:04,776 iteration 3092 : loss : 0.035420, loss_ce: 0.015456
2022-01-14 00:39:06,133 iteration 3093 : loss : 0.025147, loss_ce: 0.011180
2022-01-14 00:39:07,539 iteration 3094 : loss : 0.060501, loss_ce: 0.018181
 46%|████████████▎              | 182/400 [1:19:20<1:33:44, 25.80s/it]2022-01-14 00:39:09,051 iteration 3095 : loss : 0.025591, loss_ce: 0.010714
2022-01-14 00:39:10,486 iteration 3096 : loss : 0.043847, loss_ce: 0.016703
2022-01-14 00:39:11,953 iteration 3097 : loss : 0.032111, loss_ce: 0.013362
2022-01-14 00:39:13,405 iteration 3098 : loss : 0.036509, loss_ce: 0.010617
2022-01-14 00:39:14,858 iteration 3099 : loss : 0.038929, loss_ce: 0.017249
2022-01-14 00:39:16,275 iteration 3100 : loss : 0.026995, loss_ce: 0.008640
2022-01-14 00:39:17,647 iteration 3101 : loss : 0.023206, loss_ce: 0.008610
2022-01-14 00:39:18,992 iteration 3102 : loss : 0.027564, loss_ce: 0.010936
2022-01-14 00:39:20,454 iteration 3103 : loss : 0.040192, loss_ce: 0.017560
2022-01-14 00:39:21,858 iteration 3104 : loss : 0.030687, loss_ce: 0.010070
2022-01-14 00:39:23,315 iteration 3105 : loss : 0.021339, loss_ce: 0.007920
2022-01-14 00:39:24,740 iteration 3106 : loss : 0.026136, loss_ce: 0.009439
2022-01-14 00:39:26,217 iteration 3107 : loss : 0.054931, loss_ce: 0.021970
2022-01-14 00:39:27,690 iteration 3108 : loss : 0.032594, loss_ce: 0.011588
2022-01-14 00:39:29,039 iteration 3109 : loss : 0.030524, loss_ce: 0.016404
2022-01-14 00:39:30,421 iteration 3110 : loss : 0.028760, loss_ce: 0.011460
2022-01-14 00:39:31,850 iteration 3111 : loss : 0.039565, loss_ce: 0.010261
 46%|████████████▎              | 183/400 [1:19:45<1:31:42, 25.36s/it]2022-01-14 00:39:33,263 iteration 3112 : loss : 0.023538, loss_ce: 0.009170
2022-01-14 00:39:34,707 iteration 3113 : loss : 0.036405, loss_ce: 0.014370
2022-01-14 00:39:36,100 iteration 3114 : loss : 0.023710, loss_ce: 0.010937
2022-01-14 00:39:37,565 iteration 3115 : loss : 0.028644, loss_ce: 0.010133
2022-01-14 00:39:38,924 iteration 3116 : loss : 0.024184, loss_ce: 0.009841
2022-01-14 00:39:40,444 iteration 3117 : loss : 0.074759, loss_ce: 0.019630
2022-01-14 00:39:41,892 iteration 3118 : loss : 0.031121, loss_ce: 0.014440
2022-01-14 00:39:43,342 iteration 3119 : loss : 0.027295, loss_ce: 0.012191
2022-01-14 00:39:44,713 iteration 3120 : loss : 0.026667, loss_ce: 0.007489
2022-01-14 00:39:46,165 iteration 3121 : loss : 0.042447, loss_ce: 0.013268
2022-01-14 00:39:47,585 iteration 3122 : loss : 0.033561, loss_ce: 0.016262
2022-01-14 00:39:49,098 iteration 3123 : loss : 0.059164, loss_ce: 0.025234
2022-01-14 00:39:50,466 iteration 3124 : loss : 0.034821, loss_ce: 0.013997
2022-01-14 00:39:51,851 iteration 3125 : loss : 0.017960, loss_ce: 0.007618
2022-01-14 00:39:53,247 iteration 3126 : loss : 0.025832, loss_ce: 0.010765
2022-01-14 00:39:54,643 iteration 3127 : loss : 0.029847, loss_ce: 0.012862
2022-01-14 00:39:56,047 iteration 3128 : loss : 0.038583, loss_ce: 0.010196
 46%|████████████▍              | 184/400 [1:20:09<1:30:01, 25.01s/it]2022-01-14 00:39:57,491 iteration 3129 : loss : 0.029558, loss_ce: 0.010660
2022-01-14 00:39:58,876 iteration 3130 : loss : 0.027460, loss_ce: 0.010436
2022-01-14 00:40:00,334 iteration 3131 : loss : 0.029315, loss_ce: 0.013337
2022-01-14 00:40:01,790 iteration 3132 : loss : 0.028486, loss_ce: 0.010420
2022-01-14 00:40:03,173 iteration 3133 : loss : 0.025400, loss_ce: 0.011312
2022-01-14 00:40:04,622 iteration 3134 : loss : 0.028385, loss_ce: 0.012558
2022-01-14 00:40:06,081 iteration 3135 : loss : 0.049934, loss_ce: 0.010617
2022-01-14 00:40:07,442 iteration 3136 : loss : 0.022759, loss_ce: 0.010806
2022-01-14 00:40:08,800 iteration 3137 : loss : 0.025411, loss_ce: 0.009978
2022-01-14 00:40:10,190 iteration 3138 : loss : 0.023582, loss_ce: 0.008778
2022-01-14 00:40:11,715 iteration 3139 : loss : 0.074226, loss_ce: 0.024087
2022-01-14 00:40:13,144 iteration 3140 : loss : 0.041706, loss_ce: 0.018266
2022-01-14 00:40:14,556 iteration 3141 : loss : 0.030224, loss_ce: 0.013024
2022-01-14 00:40:15,888 iteration 3142 : loss : 0.025360, loss_ce: 0.009933
2022-01-14 00:40:17,304 iteration 3143 : loss : 0.039900, loss_ce: 0.013243
2022-01-14 00:40:18,777 iteration 3144 : loss : 0.067289, loss_ce: 0.015251
2022-01-14 00:40:18,778 Training Data Eval:
2022-01-14 00:40:25,914   Average segmentation loss on training set: 0.0205
2022-01-14 00:40:25,914 Validation Data Eval:
2022-01-14 00:40:28,422   Average segmentation loss on validation set: 0.0742
2022-01-14 00:40:29,809 iteration 3145 : loss : 0.024907, loss_ce: 0.011097
 46%|████████████▍              | 185/400 [1:20:43<1:39:01, 27.63s/it]2022-01-14 00:40:31,380 iteration 3146 : loss : 0.030796, loss_ce: 0.013447
2022-01-14 00:40:32,864 iteration 3147 : loss : 0.041710, loss_ce: 0.021613
2022-01-14 00:40:34,219 iteration 3148 : loss : 0.022371, loss_ce: 0.007658
2022-01-14 00:40:35,646 iteration 3149 : loss : 0.042542, loss_ce: 0.011518
2022-01-14 00:40:37,084 iteration 3150 : loss : 0.032405, loss_ce: 0.009389
2022-01-14 00:40:38,426 iteration 3151 : loss : 0.021629, loss_ce: 0.009728
2022-01-14 00:40:39,904 iteration 3152 : loss : 0.031355, loss_ce: 0.016787
2022-01-14 00:40:41,317 iteration 3153 : loss : 0.030232, loss_ce: 0.014522
2022-01-14 00:40:42,749 iteration 3154 : loss : 0.034420, loss_ce: 0.009595
2022-01-14 00:40:44,182 iteration 3155 : loss : 0.026925, loss_ce: 0.008657
2022-01-14 00:40:45,635 iteration 3156 : loss : 0.024518, loss_ce: 0.009274
2022-01-14 00:40:46,989 iteration 3157 : loss : 0.032083, loss_ce: 0.009147
2022-01-14 00:40:48,471 iteration 3158 : loss : 0.025776, loss_ce: 0.009784
2022-01-14 00:40:49,900 iteration 3159 : loss : 0.040090, loss_ce: 0.020804
2022-01-14 00:40:51,305 iteration 3160 : loss : 0.028078, loss_ce: 0.013258
2022-01-14 00:40:52,787 iteration 3161 : loss : 0.039235, loss_ce: 0.016183
2022-01-14 00:40:54,287 iteration 3162 : loss : 0.034365, loss_ce: 0.017429
 46%|████████████▌              | 186/400 [1:21:07<1:35:11, 26.69s/it]2022-01-14 00:40:55,698 iteration 3163 : loss : 0.040910, loss_ce: 0.012178
2022-01-14 00:40:57,053 iteration 3164 : loss : 0.039205, loss_ce: 0.011041
2022-01-14 00:40:58,443 iteration 3165 : loss : 0.016002, loss_ce: 0.006851
2022-01-14 00:40:59,835 iteration 3166 : loss : 0.030397, loss_ce: 0.014830
2022-01-14 00:41:01,243 iteration 3167 : loss : 0.039534, loss_ce: 0.014707
2022-01-14 00:41:02,602 iteration 3168 : loss : 0.020659, loss_ce: 0.009638
2022-01-14 00:41:04,000 iteration 3169 : loss : 0.029250, loss_ce: 0.008753
2022-01-14 00:41:05,419 iteration 3170 : loss : 0.037712, loss_ce: 0.015761
2022-01-14 00:41:06,890 iteration 3171 : loss : 0.039099, loss_ce: 0.010360
2022-01-14 00:41:08,340 iteration 3172 : loss : 0.025471, loss_ce: 0.009834
2022-01-14 00:41:09,766 iteration 3173 : loss : 0.024934, loss_ce: 0.008556
2022-01-14 00:41:11,243 iteration 3174 : loss : 0.031516, loss_ce: 0.011359
2022-01-14 00:41:12,641 iteration 3175 : loss : 0.025332, loss_ce: 0.009248
2022-01-14 00:41:14,053 iteration 3176 : loss : 0.024513, loss_ce: 0.012349
2022-01-14 00:41:15,422 iteration 3177 : loss : 0.022469, loss_ce: 0.009959
2022-01-14 00:41:16,833 iteration 3178 : loss : 0.031386, loss_ce: 0.008086
2022-01-14 00:41:18,288 iteration 3179 : loss : 0.039452, loss_ce: 0.009882
 47%|████████████▌              | 187/400 [1:21:31<1:31:52, 25.88s/it]2022-01-14 00:41:19,825 iteration 3180 : loss : 0.020381, loss_ce: 0.008498
2022-01-14 00:41:21,238 iteration 3181 : loss : 0.031461, loss_ce: 0.012903
2022-01-14 00:41:22,701 iteration 3182 : loss : 0.045578, loss_ce: 0.021936
2022-01-14 00:41:24,187 iteration 3183 : loss : 0.036691, loss_ce: 0.014615
2022-01-14 00:41:25,550 iteration 3184 : loss : 0.023645, loss_ce: 0.011275
2022-01-14 00:41:26,944 iteration 3185 : loss : 0.044227, loss_ce: 0.017898
2022-01-14 00:41:28,355 iteration 3186 : loss : 0.036726, loss_ce: 0.017656
2022-01-14 00:41:29,724 iteration 3187 : loss : 0.044009, loss_ce: 0.015996
2022-01-14 00:41:31,135 iteration 3188 : loss : 0.044657, loss_ce: 0.015139
2022-01-14 00:41:32,503 iteration 3189 : loss : 0.035005, loss_ce: 0.017537
2022-01-14 00:41:33,942 iteration 3190 : loss : 0.086205, loss_ce: 0.038492
2022-01-14 00:41:35,364 iteration 3191 : loss : 0.054506, loss_ce: 0.020834
2022-01-14 00:41:36,769 iteration 3192 : loss : 0.047453, loss_ce: 0.019408
2022-01-14 00:41:38,120 iteration 3193 : loss : 0.038242, loss_ce: 0.016414
2022-01-14 00:41:39,486 iteration 3194 : loss : 0.044503, loss_ce: 0.016237
2022-01-14 00:41:40,878 iteration 3195 : loss : 0.052342, loss_ce: 0.018462
2022-01-14 00:41:42,311 iteration 3196 : loss : 0.041289, loss_ce: 0.012058
 47%|████████████▋              | 188/400 [1:21:55<1:29:29, 25.33s/it]2022-01-14 00:41:43,761 iteration 3197 : loss : 0.040790, loss_ce: 0.012734
2022-01-14 00:41:45,142 iteration 3198 : loss : 0.073580, loss_ce: 0.032319
2022-01-14 00:41:46,503 iteration 3199 : loss : 0.048101, loss_ce: 0.017289
2022-01-14 00:41:47,881 iteration 3200 : loss : 0.034530, loss_ce: 0.014650
2022-01-14 00:41:49,312 iteration 3201 : loss : 0.060811, loss_ce: 0.032330
2022-01-14 00:41:50,748 iteration 3202 : loss : 0.058195, loss_ce: 0.026158
2022-01-14 00:41:52,085 iteration 3203 : loss : 0.092787, loss_ce: 0.017895
2022-01-14 00:41:53,520 iteration 3204 : loss : 0.061447, loss_ce: 0.032745
2022-01-14 00:41:54,990 iteration 3205 : loss : 0.038286, loss_ce: 0.014636
2022-01-14 00:41:56,373 iteration 3206 : loss : 0.037592, loss_ce: 0.016500
2022-01-14 00:41:57,737 iteration 3207 : loss : 0.039397, loss_ce: 0.014110
2022-01-14 00:41:59,115 iteration 3208 : loss : 0.060657, loss_ce: 0.021653
2022-01-14 00:42:00,553 iteration 3209 : loss : 0.037109, loss_ce: 0.014008
2022-01-14 00:42:01,979 iteration 3210 : loss : 0.061959, loss_ce: 0.026521
2022-01-14 00:42:03,444 iteration 3211 : loss : 0.045044, loss_ce: 0.021021
2022-01-14 00:42:04,879 iteration 3212 : loss : 0.041833, loss_ce: 0.021062
2022-01-14 00:42:06,268 iteration 3213 : loss : 0.032435, loss_ce: 0.014716
 47%|████████████▊              | 189/400 [1:22:19<1:27:37, 24.92s/it]2022-01-14 00:42:07,722 iteration 3214 : loss : 0.036705, loss_ce: 0.015029
2022-01-14 00:42:09,085 iteration 3215 : loss : 0.034216, loss_ce: 0.016080
2022-01-14 00:42:10,479 iteration 3216 : loss : 0.032261, loss_ce: 0.014650
2022-01-14 00:42:11,931 iteration 3217 : loss : 0.053586, loss_ce: 0.016816
2022-01-14 00:42:13,295 iteration 3218 : loss : 0.031438, loss_ce: 0.013289
2022-01-14 00:42:14,670 iteration 3219 : loss : 0.025171, loss_ce: 0.008239
2022-01-14 00:42:16,090 iteration 3220 : loss : 0.057982, loss_ce: 0.027269
2022-01-14 00:42:17,504 iteration 3221 : loss : 0.033066, loss_ce: 0.011724
2022-01-14 00:42:18,850 iteration 3222 : loss : 0.023633, loss_ce: 0.008777
2022-01-14 00:42:20,282 iteration 3223 : loss : 0.051933, loss_ce: 0.012073
2022-01-14 00:42:21,677 iteration 3224 : loss : 0.032260, loss_ce: 0.012858
2022-01-14 00:42:23,014 iteration 3225 : loss : 0.038354, loss_ce: 0.013024
2022-01-14 00:42:24,417 iteration 3226 : loss : 0.032938, loss_ce: 0.014708
2022-01-14 00:42:25,831 iteration 3227 : loss : 0.037253, loss_ce: 0.013576
2022-01-14 00:42:27,232 iteration 3228 : loss : 0.048483, loss_ce: 0.022930
2022-01-14 00:42:28,674 iteration 3229 : loss : 0.029718, loss_ce: 0.010956
2022-01-14 00:42:28,674 Training Data Eval:
2022-01-14 00:42:35,783   Average segmentation loss on training set: 0.0311
2022-01-14 00:42:35,784 Validation Data Eval:
2022-01-14 00:42:38,271   Average segmentation loss on validation set: 0.1303
2022-01-14 00:42:39,686 iteration 3230 : loss : 0.030215, loss_ce: 0.014853
 48%|████████████▊              | 190/400 [1:22:53<1:36:07, 27.46s/it]2022-01-14 00:42:41,081 iteration 3231 : loss : 0.032740, loss_ce: 0.011511
2022-01-14 00:42:42,518 iteration 3232 : loss : 0.033016, loss_ce: 0.013183
2022-01-14 00:42:43,927 iteration 3233 : loss : 0.040389, loss_ce: 0.010322
2022-01-14 00:42:45,291 iteration 3234 : loss : 0.030814, loss_ce: 0.011229
2022-01-14 00:42:46,713 iteration 3235 : loss : 0.035277, loss_ce: 0.015767
2022-01-14 00:42:48,043 iteration 3236 : loss : 0.027026, loss_ce: 0.015034
2022-01-14 00:42:49,415 iteration 3237 : loss : 0.028084, loss_ce: 0.010569
2022-01-14 00:42:50,836 iteration 3238 : loss : 0.029353, loss_ce: 0.012656
2022-01-14 00:42:52,180 iteration 3239 : loss : 0.027947, loss_ce: 0.011627
2022-01-14 00:42:53,629 iteration 3240 : loss : 0.039043, loss_ce: 0.014784
2022-01-14 00:42:55,127 iteration 3241 : loss : 0.051765, loss_ce: 0.015958
2022-01-14 00:42:56,548 iteration 3242 : loss : 0.031404, loss_ce: 0.013342
2022-01-14 00:42:57,985 iteration 3243 : loss : 0.036523, loss_ce: 0.015193
2022-01-14 00:42:59,344 iteration 3244 : loss : 0.030882, loss_ce: 0.009725
2022-01-14 00:43:00,771 iteration 3245 : loss : 0.039536, loss_ce: 0.014069
2022-01-14 00:43:02,205 iteration 3246 : loss : 0.040035, loss_ce: 0.012379
2022-01-14 00:43:03,731 iteration 3247 : loss : 0.058291, loss_ce: 0.018154
 48%|████████████▉              | 191/400 [1:23:17<1:32:05, 26.44s/it]2022-01-14 00:43:05,241 iteration 3248 : loss : 0.051324, loss_ce: 0.019379
2022-01-14 00:43:06,681 iteration 3249 : loss : 0.059702, loss_ce: 0.021631
2022-01-14 00:43:08,130 iteration 3250 : loss : 0.028035, loss_ce: 0.009765
2022-01-14 00:43:09,570 iteration 3251 : loss : 0.030477, loss_ce: 0.010113
2022-01-14 00:43:10,901 iteration 3252 : loss : 0.022482, loss_ce: 0.010598
2022-01-14 00:43:12,329 iteration 3253 : loss : 0.050587, loss_ce: 0.016311
2022-01-14 00:43:13,795 iteration 3254 : loss : 0.044927, loss_ce: 0.020692
2022-01-14 00:43:15,227 iteration 3255 : loss : 0.033198, loss_ce: 0.013095
2022-01-14 00:43:16,683 iteration 3256 : loss : 0.033115, loss_ce: 0.012342
2022-01-14 00:43:18,143 iteration 3257 : loss : 0.043227, loss_ce: 0.018213
2022-01-14 00:43:19,506 iteration 3258 : loss : 0.030001, loss_ce: 0.009901
2022-01-14 00:43:20,921 iteration 3259 : loss : 0.045072, loss_ce: 0.020024
2022-01-14 00:43:22,354 iteration 3260 : loss : 0.037898, loss_ce: 0.016070
2022-01-14 00:43:23,766 iteration 3261 : loss : 0.027502, loss_ce: 0.011058
2022-01-14 00:43:25,249 iteration 3262 : loss : 0.053289, loss_ce: 0.018378
2022-01-14 00:43:26,621 iteration 3263 : loss : 0.042713, loss_ce: 0.019487
2022-01-14 00:43:28,105 iteration 3264 : loss : 0.048051, loss_ce: 0.018695
 48%|████████████▉              | 192/400 [1:23:41<1:29:30, 25.82s/it]2022-01-14 00:43:29,529 iteration 3265 : loss : 0.039174, loss_ce: 0.017660
2022-01-14 00:43:30,950 iteration 3266 : loss : 0.025770, loss_ce: 0.008882
2022-01-14 00:43:32,371 iteration 3267 : loss : 0.024688, loss_ce: 0.009136
2022-01-14 00:43:33,775 iteration 3268 : loss : 0.035973, loss_ce: 0.013396
2022-01-14 00:43:35,123 iteration 3269 : loss : 0.030339, loss_ce: 0.015071
2022-01-14 00:43:36,528 iteration 3270 : loss : 0.042371, loss_ce: 0.017966
2022-01-14 00:43:37,846 iteration 3271 : loss : 0.021771, loss_ce: 0.007620
2022-01-14 00:43:39,303 iteration 3272 : loss : 0.031883, loss_ce: 0.012721
2022-01-14 00:43:40,694 iteration 3273 : loss : 0.030267, loss_ce: 0.012595
2022-01-14 00:43:42,023 iteration 3274 : loss : 0.039323, loss_ce: 0.014646
2022-01-14 00:43:43,387 iteration 3275 : loss : 0.027432, loss_ce: 0.010518
2022-01-14 00:43:44,757 iteration 3276 : loss : 0.038181, loss_ce: 0.010315
2022-01-14 00:43:46,091 iteration 3277 : loss : 0.024571, loss_ce: 0.008629
2022-01-14 00:43:47,465 iteration 3278 : loss : 0.034245, loss_ce: 0.014747
2022-01-14 00:43:48,757 iteration 3279 : loss : 0.031243, loss_ce: 0.017922
2022-01-14 00:43:50,224 iteration 3280 : loss : 0.027917, loss_ce: 0.011226
2022-01-14 00:43:51,609 iteration 3281 : loss : 0.017775, loss_ce: 0.005298
 48%|█████████████              | 193/400 [1:24:05<1:26:40, 25.12s/it]2022-01-14 00:43:53,091 iteration 3282 : loss : 0.025170, loss_ce: 0.006231
2022-01-14 00:43:54,544 iteration 3283 : loss : 0.034636, loss_ce: 0.014965
2022-01-14 00:43:55,954 iteration 3284 : loss : 0.024012, loss_ce: 0.010079
2022-01-14 00:43:57,412 iteration 3285 : loss : 0.039502, loss_ce: 0.013291
2022-01-14 00:43:58,809 iteration 3286 : loss : 0.031863, loss_ce: 0.009019
2022-01-14 00:44:00,280 iteration 3287 : loss : 0.049810, loss_ce: 0.024622
2022-01-14 00:44:01,630 iteration 3288 : loss : 0.028751, loss_ce: 0.013528
2022-01-14 00:44:03,122 iteration 3289 : loss : 0.028656, loss_ce: 0.011489
2022-01-14 00:44:04,578 iteration 3290 : loss : 0.034152, loss_ce: 0.012051
2022-01-14 00:44:06,053 iteration 3291 : loss : 0.097916, loss_ce: 0.059942
2022-01-14 00:44:07,445 iteration 3292 : loss : 0.035216, loss_ce: 0.011964
2022-01-14 00:44:08,848 iteration 3293 : loss : 0.046752, loss_ce: 0.015583
2022-01-14 00:44:10,333 iteration 3294 : loss : 0.036559, loss_ce: 0.015958
2022-01-14 00:44:11,766 iteration 3295 : loss : 0.029194, loss_ce: 0.012965
2022-01-14 00:44:13,119 iteration 3296 : loss : 0.041228, loss_ce: 0.017299
2022-01-14 00:44:14,479 iteration 3297 : loss : 0.035271, loss_ce: 0.013383
2022-01-14 00:44:15,970 iteration 3298 : loss : 0.032591, loss_ce: 0.015972
 48%|█████████████              | 194/400 [1:24:29<1:25:28, 24.90s/it]2022-01-14 00:44:17,357 iteration 3299 : loss : 0.027948, loss_ce: 0.007579
2022-01-14 00:44:18,783 iteration 3300 : loss : 0.031540, loss_ce: 0.011682
2022-01-14 00:44:20,193 iteration 3301 : loss : 0.034394, loss_ce: 0.014476
2022-01-14 00:44:21,562 iteration 3302 : loss : 0.035180, loss_ce: 0.012224
2022-01-14 00:44:23,012 iteration 3303 : loss : 0.035878, loss_ce: 0.016832
2022-01-14 00:44:24,465 iteration 3304 : loss : 0.037230, loss_ce: 0.015123
2022-01-14 00:44:25,849 iteration 3305 : loss : 0.032262, loss_ce: 0.011467
2022-01-14 00:44:27,242 iteration 3306 : loss : 0.036040, loss_ce: 0.010470
2022-01-14 00:44:28,768 iteration 3307 : loss : 0.051541, loss_ce: 0.022942
2022-01-14 00:44:30,225 iteration 3308 : loss : 0.031943, loss_ce: 0.014044
2022-01-14 00:44:31,689 iteration 3309 : loss : 0.031190, loss_ce: 0.013757
2022-01-14 00:44:33,038 iteration 3310 : loss : 0.024793, loss_ce: 0.013310
2022-01-14 00:44:34,513 iteration 3311 : loss : 0.054101, loss_ce: 0.018361
2022-01-14 00:44:35,923 iteration 3312 : loss : 0.065883, loss_ce: 0.020578
2022-01-14 00:44:37,388 iteration 3313 : loss : 0.041598, loss_ce: 0.016300
2022-01-14 00:44:38,798 iteration 3314 : loss : 0.052233, loss_ce: 0.014554
2022-01-14 00:44:38,798 Training Data Eval:
2022-01-14 00:44:45,929   Average segmentation loss on training set: 0.0223
2022-01-14 00:44:45,929 Validation Data Eval:
2022-01-14 00:44:48,374   Average segmentation loss on validation set: 0.0822
2022-01-14 00:44:49,734 iteration 3315 : loss : 0.028515, loss_ce: 0.011997
 49%|█████████████▏             | 195/400 [1:25:03<1:34:09, 27.56s/it]2022-01-14 00:44:51,160 iteration 3316 : loss : 0.036481, loss_ce: 0.014262
2022-01-14 00:44:52,564 iteration 3317 : loss : 0.033143, loss_ce: 0.015616
2022-01-14 00:44:53,939 iteration 3318 : loss : 0.050156, loss_ce: 0.023069
2022-01-14 00:44:55,284 iteration 3319 : loss : 0.030743, loss_ce: 0.010671
2022-01-14 00:44:56,762 iteration 3320 : loss : 0.055871, loss_ce: 0.022416
2022-01-14 00:44:58,126 iteration 3321 : loss : 0.037269, loss_ce: 0.014276
2022-01-14 00:44:59,588 iteration 3322 : loss : 0.044907, loss_ce: 0.015054
2022-01-14 00:45:00,925 iteration 3323 : loss : 0.033515, loss_ce: 0.012454
2022-01-14 00:45:02,352 iteration 3324 : loss : 0.037574, loss_ce: 0.017462
2022-01-14 00:45:03,815 iteration 3325 : loss : 0.038427, loss_ce: 0.014977
2022-01-14 00:45:05,182 iteration 3326 : loss : 0.035074, loss_ce: 0.012632
2022-01-14 00:45:06,599 iteration 3327 : loss : 0.029783, loss_ce: 0.010054
2022-01-14 00:45:08,087 iteration 3328 : loss : 0.033420, loss_ce: 0.011235
2022-01-14 00:45:09,507 iteration 3329 : loss : 0.041548, loss_ce: 0.018194
2022-01-14 00:45:10,912 iteration 3330 : loss : 0.035305, loss_ce: 0.020240
2022-01-14 00:45:12,271 iteration 3331 : loss : 0.036153, loss_ce: 0.015187
2022-01-14 00:45:13,722 iteration 3332 : loss : 0.037412, loss_ce: 0.012245
 49%|█████████████▏             | 196/400 [1:25:27<1:30:02, 26.48s/it]2022-01-14 00:45:15,264 iteration 3333 : loss : 0.043697, loss_ce: 0.016372
2022-01-14 00:45:16,708 iteration 3334 : loss : 0.044888, loss_ce: 0.022128
2022-01-14 00:45:18,208 iteration 3335 : loss : 0.052466, loss_ce: 0.023347
2022-01-14 00:45:19,617 iteration 3336 : loss : 0.087522, loss_ce: 0.031553
2022-01-14 00:45:21,066 iteration 3337 : loss : 0.105352, loss_ce: 0.047718
2022-01-14 00:45:22,602 iteration 3338 : loss : 0.076907, loss_ce: 0.039594
2022-01-14 00:45:23,959 iteration 3339 : loss : 0.042487, loss_ce: 0.017627
2022-01-14 00:45:25,311 iteration 3340 : loss : 0.112251, loss_ce: 0.036456
2022-01-14 00:45:26,733 iteration 3341 : loss : 0.079042, loss_ce: 0.033497
2022-01-14 00:45:28,142 iteration 3342 : loss : 0.063311, loss_ce: 0.028926
2022-01-14 00:45:29,589 iteration 3343 : loss : 0.071712, loss_ce: 0.035293
2022-01-14 00:45:31,011 iteration 3344 : loss : 0.092887, loss_ce: 0.030396
2022-01-14 00:45:32,424 iteration 3345 : loss : 0.065754, loss_ce: 0.036357
2022-01-14 00:45:33,782 iteration 3346 : loss : 0.053615, loss_ce: 0.024221
2022-01-14 00:45:35,150 iteration 3347 : loss : 0.049769, loss_ce: 0.020178
2022-01-14 00:45:36,469 iteration 3348 : loss : 0.055845, loss_ce: 0.025976
2022-01-14 00:45:37,919 iteration 3349 : loss : 0.100039, loss_ce: 0.034145
 49%|█████████████▎             | 197/400 [1:25:51<1:27:17, 25.80s/it]2022-01-14 00:45:39,390 iteration 3350 : loss : 0.081826, loss_ce: 0.034822
2022-01-14 00:45:40,833 iteration 3351 : loss : 0.052520, loss_ce: 0.019805
2022-01-14 00:45:42,268 iteration 3352 : loss : 0.098813, loss_ce: 0.052115
2022-01-14 00:45:43,755 iteration 3353 : loss : 0.057169, loss_ce: 0.015514
2022-01-14 00:45:45,125 iteration 3354 : loss : 0.044209, loss_ce: 0.020833
2022-01-14 00:45:46,600 iteration 3355 : loss : 0.052623, loss_ce: 0.018824
2022-01-14 00:45:48,054 iteration 3356 : loss : 0.032517, loss_ce: 0.013263
2022-01-14 00:45:49,435 iteration 3357 : loss : 0.051777, loss_ce: 0.016789
2022-01-14 00:45:50,895 iteration 3358 : loss : 0.042707, loss_ce: 0.021053
2022-01-14 00:45:52,220 iteration 3359 : loss : 0.066251, loss_ce: 0.024878
2022-01-14 00:45:53,589 iteration 3360 : loss : 0.043367, loss_ce: 0.018018
2022-01-14 00:45:54,999 iteration 3361 : loss : 0.035311, loss_ce: 0.013749
2022-01-14 00:45:56,402 iteration 3362 : loss : 0.048945, loss_ce: 0.017756
2022-01-14 00:45:57,900 iteration 3363 : loss : 0.053056, loss_ce: 0.017507
2022-01-14 00:45:59,257 iteration 3364 : loss : 0.045435, loss_ce: 0.022549
2022-01-14 00:46:00,699 iteration 3365 : loss : 0.050400, loss_ce: 0.020602
2022-01-14 00:46:02,050 iteration 3366 : loss : 0.028744, loss_ce: 0.012213
 50%|█████████████▎             | 198/400 [1:26:15<1:25:10, 25.30s/it]2022-01-14 00:46:03,538 iteration 3367 : loss : 0.036046, loss_ce: 0.014545
2022-01-14 00:46:04,928 iteration 3368 : loss : 0.040303, loss_ce: 0.018766
2022-01-14 00:46:06,274 iteration 3369 : loss : 0.038092, loss_ce: 0.011963
2022-01-14 00:46:07,748 iteration 3370 : loss : 0.041750, loss_ce: 0.020320
2022-01-14 00:46:09,259 iteration 3371 : loss : 0.050578, loss_ce: 0.019435
2022-01-14 00:46:10,627 iteration 3372 : loss : 0.029132, loss_ce: 0.012560
2022-01-14 00:46:12,040 iteration 3373 : loss : 0.037637, loss_ce: 0.014004
2022-01-14 00:46:13,404 iteration 3374 : loss : 0.033595, loss_ce: 0.015242
2022-01-14 00:46:14,786 iteration 3375 : loss : 0.053311, loss_ce: 0.021213
2022-01-14 00:46:16,192 iteration 3376 : loss : 0.037517, loss_ce: 0.012283
2022-01-14 00:46:17,506 iteration 3377 : loss : 0.023194, loss_ce: 0.009603
2022-01-14 00:46:18,956 iteration 3378 : loss : 0.058018, loss_ce: 0.014743
2022-01-14 00:46:20,442 iteration 3379 : loss : 0.048762, loss_ce: 0.022613
2022-01-14 00:46:21,882 iteration 3380 : loss : 0.038128, loss_ce: 0.011904
2022-01-14 00:46:23,343 iteration 3381 : loss : 0.052587, loss_ce: 0.019914
2022-01-14 00:46:24,753 iteration 3382 : loss : 0.033141, loss_ce: 0.013472
2022-01-14 00:46:26,116 iteration 3383 : loss : 0.029320, loss_ce: 0.011942
 50%|█████████████▍             | 199/400 [1:26:39<1:23:30, 24.93s/it]2022-01-14 00:46:27,658 iteration 3384 : loss : 0.037607, loss_ce: 0.012566
2022-01-14 00:46:29,088 iteration 3385 : loss : 0.075663, loss_ce: 0.030189
2022-01-14 00:46:30,448 iteration 3386 : loss : 0.024183, loss_ce: 0.008259
2022-01-14 00:46:31,931 iteration 3387 : loss : 0.039263, loss_ce: 0.016817
2022-01-14 00:46:33,353 iteration 3388 : loss : 0.039086, loss_ce: 0.019753
2022-01-14 00:46:34,733 iteration 3389 : loss : 0.021817, loss_ce: 0.008754
2022-01-14 00:46:36,013 iteration 3390 : loss : 0.028184, loss_ce: 0.010291
2022-01-14 00:46:37,446 iteration 3391 : loss : 0.032586, loss_ce: 0.012675
2022-01-14 00:46:38,888 iteration 3392 : loss : 0.052161, loss_ce: 0.016620
2022-01-14 00:46:40,298 iteration 3393 : loss : 0.033736, loss_ce: 0.014790
2022-01-14 00:46:41,726 iteration 3394 : loss : 0.028290, loss_ce: 0.011129
2022-01-14 00:46:43,068 iteration 3395 : loss : 0.024188, loss_ce: 0.010134
2022-01-14 00:46:44,513 iteration 3396 : loss : 0.029584, loss_ce: 0.012215
2022-01-14 00:46:45,934 iteration 3397 : loss : 0.030162, loss_ce: 0.012688
2022-01-14 00:46:47,380 iteration 3398 : loss : 0.032462, loss_ce: 0.013900
2022-01-14 00:46:48,765 iteration 3399 : loss : 0.041803, loss_ce: 0.015984
2022-01-14 00:46:48,765 Training Data Eval:
2022-01-14 00:46:55,691   Average segmentation loss on training set: 0.0248
2022-01-14 00:46:55,691 Validation Data Eval:
2022-01-14 00:46:58,137   Average segmentation loss on validation set: 0.0773
2022-01-14 00:46:59,521 iteration 3400 : loss : 0.033096, loss_ce: 0.010069
 50%|█████████████▌             | 200/400 [1:27:12<1:31:34, 27.47s/it]2022-01-14 00:47:01,018 iteration 3401 : loss : 0.052798, loss_ce: 0.030922
2022-01-14 00:47:02,362 iteration 3402 : loss : 0.031150, loss_ce: 0.013254
2022-01-14 00:47:03,856 iteration 3403 : loss : 0.039238, loss_ce: 0.016221
2022-01-14 00:47:05,306 iteration 3404 : loss : 0.037611, loss_ce: 0.015898
2022-01-14 00:47:06,661 iteration 3405 : loss : 0.050527, loss_ce: 0.017711
2022-01-14 00:47:08,123 iteration 3406 : loss : 0.036797, loss_ce: 0.015730
2022-01-14 00:47:09,502 iteration 3407 : loss : 0.031723, loss_ce: 0.013718
2022-01-14 00:47:10,832 iteration 3408 : loss : 0.036233, loss_ce: 0.013503
2022-01-14 00:47:12,222 iteration 3409 : loss : 0.031398, loss_ce: 0.011376
2022-01-14 00:47:13,653 iteration 3410 : loss : 0.028602, loss_ce: 0.012279
2022-01-14 00:47:15,110 iteration 3411 : loss : 0.060999, loss_ce: 0.026485
2022-01-14 00:47:16,537 iteration 3412 : loss : 0.033460, loss_ce: 0.015057
2022-01-14 00:47:17,975 iteration 3413 : loss : 0.026757, loss_ce: 0.007187
2022-01-14 00:47:19,461 iteration 3414 : loss : 0.046646, loss_ce: 0.017231
2022-01-14 00:47:20,919 iteration 3415 : loss : 0.028375, loss_ce: 0.013556
2022-01-14 00:47:22,405 iteration 3416 : loss : 0.028746, loss_ce: 0.010801
2022-01-14 00:47:23,877 iteration 3417 : loss : 0.032706, loss_ce: 0.010350
 50%|█████████████▌             | 201/400 [1:27:37<1:28:00, 26.53s/it]2022-01-14 00:47:25,295 iteration 3418 : loss : 0.028854, loss_ce: 0.008965
2022-01-14 00:47:26,607 iteration 3419 : loss : 0.026401, loss_ce: 0.011790
2022-01-14 00:47:27,961 iteration 3420 : loss : 0.022585, loss_ce: 0.007839
2022-01-14 00:47:29,313 iteration 3421 : loss : 0.022283, loss_ce: 0.009121
2022-01-14 00:47:30,643 iteration 3422 : loss : 0.025479, loss_ce: 0.009211
2022-01-14 00:47:32,054 iteration 3423 : loss : 0.037316, loss_ce: 0.018612
2022-01-14 00:47:33,476 iteration 3424 : loss : 0.038858, loss_ce: 0.016928
2022-01-14 00:47:34,893 iteration 3425 : loss : 0.034746, loss_ce: 0.012429
2022-01-14 00:47:36,194 iteration 3426 : loss : 0.034371, loss_ce: 0.013251
2022-01-14 00:47:37,603 iteration 3427 : loss : 0.034178, loss_ce: 0.009454
2022-01-14 00:47:39,019 iteration 3428 : loss : 0.045091, loss_ce: 0.019334
2022-01-14 00:47:40,374 iteration 3429 : loss : 0.025707, loss_ce: 0.008706
2022-01-14 00:47:41,820 iteration 3430 : loss : 0.025363, loss_ce: 0.010860
2022-01-14 00:47:43,228 iteration 3431 : loss : 0.028232, loss_ce: 0.010012
2022-01-14 00:47:44,707 iteration 3432 : loss : 0.047702, loss_ce: 0.019948
2022-01-14 00:47:46,159 iteration 3433 : loss : 0.036523, loss_ce: 0.011131
2022-01-14 00:47:47,557 iteration 3434 : loss : 0.040107, loss_ce: 0.011316
 50%|█████████████▋             | 202/400 [1:28:00<1:24:44, 25.68s/it]2022-01-14 00:47:49,017 iteration 3435 : loss : 0.031384, loss_ce: 0.012400
2022-01-14 00:47:50,498 iteration 3436 : loss : 0.042242, loss_ce: 0.017429
2022-01-14 00:47:51,986 iteration 3437 : loss : 0.029535, loss_ce: 0.010411
2022-01-14 00:47:53,455 iteration 3438 : loss : 0.040452, loss_ce: 0.015335
2022-01-14 00:47:54,804 iteration 3439 : loss : 0.031601, loss_ce: 0.013018
2022-01-14 00:47:56,256 iteration 3440 : loss : 0.035492, loss_ce: 0.012623
2022-01-14 00:47:57,630 iteration 3441 : loss : 0.030306, loss_ce: 0.010641
2022-01-14 00:47:59,064 iteration 3442 : loss : 0.033972, loss_ce: 0.014495
2022-01-14 00:48:00,556 iteration 3443 : loss : 0.043231, loss_ce: 0.017384
2022-01-14 00:48:01,936 iteration 3444 : loss : 0.039887, loss_ce: 0.012720
2022-01-14 00:48:03,385 iteration 3445 : loss : 0.042936, loss_ce: 0.019411
2022-01-14 00:48:04,838 iteration 3446 : loss : 0.029859, loss_ce: 0.013703
2022-01-14 00:48:06,294 iteration 3447 : loss : 0.109462, loss_ce: 0.051552
2022-01-14 00:48:07,628 iteration 3448 : loss : 0.027973, loss_ce: 0.011596
2022-01-14 00:48:08,981 iteration 3449 : loss : 0.026579, loss_ce: 0.010510
2022-01-14 00:48:10,355 iteration 3450 : loss : 0.028231, loss_ce: 0.009706
2022-01-14 00:48:11,739 iteration 3451 : loss : 0.028136, loss_ce: 0.016030
 51%|█████████████▋             | 203/400 [1:28:25<1:22:50, 25.23s/it]2022-01-14 00:48:13,145 iteration 3452 : loss : 0.021736, loss_ce: 0.009975
2022-01-14 00:48:14,602 iteration 3453 : loss : 0.054296, loss_ce: 0.018444
2022-01-14 00:48:16,152 iteration 3454 : loss : 0.051152, loss_ce: 0.022565
2022-01-14 00:48:17,533 iteration 3455 : loss : 0.029060, loss_ce: 0.012176
2022-01-14 00:48:18,969 iteration 3456 : loss : 0.065122, loss_ce: 0.020146
2022-01-14 00:48:20,316 iteration 3457 : loss : 0.031388, loss_ce: 0.013197
2022-01-14 00:48:21,649 iteration 3458 : loss : 0.038523, loss_ce: 0.013471
2022-01-14 00:48:23,122 iteration 3459 : loss : 0.031563, loss_ce: 0.013910
2022-01-14 00:48:24,461 iteration 3460 : loss : 0.024975, loss_ce: 0.009977
2022-01-14 00:48:25,805 iteration 3461 : loss : 0.025468, loss_ce: 0.009388
2022-01-14 00:48:27,114 iteration 3462 : loss : 0.022279, loss_ce: 0.010428
2022-01-14 00:48:28,554 iteration 3463 : loss : 0.042203, loss_ce: 0.019110
2022-01-14 00:48:29,972 iteration 3464 : loss : 0.039814, loss_ce: 0.016971
2022-01-14 00:48:31,345 iteration 3465 : loss : 0.024511, loss_ce: 0.009647
2022-01-14 00:48:32,818 iteration 3466 : loss : 0.039085, loss_ce: 0.016563
2022-01-14 00:48:34,144 iteration 3467 : loss : 0.023761, loss_ce: 0.009461
2022-01-14 00:48:35,532 iteration 3468 : loss : 0.039723, loss_ce: 0.012343
 51%|█████████████▊             | 204/400 [1:28:48<1:21:00, 24.80s/it]2022-01-14 00:48:36,963 iteration 3469 : loss : 0.025811, loss_ce: 0.010023
2022-01-14 00:48:38,358 iteration 3470 : loss : 0.037156, loss_ce: 0.014384
2022-01-14 00:48:39,813 iteration 3471 : loss : 0.034856, loss_ce: 0.014495
2022-01-14 00:48:41,298 iteration 3472 : loss : 0.052370, loss_ce: 0.020574
2022-01-14 00:48:42,661 iteration 3473 : loss : 0.022775, loss_ce: 0.010433
2022-01-14 00:48:44,113 iteration 3474 : loss : 0.037519, loss_ce: 0.013913
2022-01-14 00:48:45,529 iteration 3475 : loss : 0.032285, loss_ce: 0.014444
2022-01-14 00:48:46,910 iteration 3476 : loss : 0.048365, loss_ce: 0.019693
2022-01-14 00:48:48,290 iteration 3477 : loss : 0.024356, loss_ce: 0.008482
2022-01-14 00:48:49,709 iteration 3478 : loss : 0.029798, loss_ce: 0.013472
2022-01-14 00:48:51,094 iteration 3479 : loss : 0.025361, loss_ce: 0.010711
2022-01-14 00:48:52,444 iteration 3480 : loss : 0.023613, loss_ce: 0.011740
2022-01-14 00:48:53,818 iteration 3481 : loss : 0.047544, loss_ce: 0.013409
2022-01-14 00:48:55,198 iteration 3482 : loss : 0.028488, loss_ce: 0.011315
2022-01-14 00:48:56,662 iteration 3483 : loss : 0.029966, loss_ce: 0.011870
2022-01-14 00:48:58,085 iteration 3484 : loss : 0.038408, loss_ce: 0.012125
2022-01-14 00:48:58,086 Training Data Eval:
2022-01-14 00:49:05,111   Average segmentation loss on training set: 0.0281
2022-01-14 00:49:05,111 Validation Data Eval:
2022-01-14 00:49:07,559   Average segmentation loss on validation set: 0.0988
2022-01-14 00:49:08,967 iteration 3485 : loss : 0.035237, loss_ce: 0.013986
 51%|█████████████▊             | 205/400 [1:29:22<1:29:01, 27.39s/it]2022-01-14 00:49:10,443 iteration 3486 : loss : 0.034722, loss_ce: 0.008562
2022-01-14 00:49:11,832 iteration 3487 : loss : 0.057937, loss_ce: 0.029917
2022-01-14 00:49:13,234 iteration 3488 : loss : 0.032787, loss_ce: 0.009727
2022-01-14 00:49:14,517 iteration 3489 : loss : 0.031114, loss_ce: 0.013975
2022-01-14 00:49:15,941 iteration 3490 : loss : 0.038884, loss_ce: 0.015379
2022-01-14 00:49:17,468 iteration 3491 : loss : 0.040696, loss_ce: 0.020003
2022-01-14 00:49:18,881 iteration 3492 : loss : 0.027264, loss_ce: 0.008605
2022-01-14 00:49:20,267 iteration 3493 : loss : 0.069922, loss_ce: 0.025344
2022-01-14 00:49:21,694 iteration 3494 : loss : 0.027620, loss_ce: 0.010606
2022-01-14 00:49:23,135 iteration 3495 : loss : 0.020826, loss_ce: 0.006797
2022-01-14 00:49:24,685 iteration 3496 : loss : 0.043572, loss_ce: 0.016897
2022-01-14 00:49:26,093 iteration 3497 : loss : 0.029328, loss_ce: 0.012105
2022-01-14 00:49:27,582 iteration 3498 : loss : 0.028318, loss_ce: 0.012175
2022-01-14 00:49:28,970 iteration 3499 : loss : 0.028580, loss_ce: 0.014661
2022-01-14 00:49:30,385 iteration 3500 : loss : 0.030125, loss_ce: 0.012800
2022-01-14 00:49:31,880 iteration 3501 : loss : 0.032372, loss_ce: 0.013116
2022-01-14 00:49:33,309 iteration 3502 : loss : 0.029217, loss_ce: 0.014466
 52%|█████████████▉             | 206/400 [1:29:46<1:25:36, 26.47s/it]2022-01-14 00:49:34,798 iteration 3503 : loss : 0.044673, loss_ce: 0.011298
2022-01-14 00:49:36,187 iteration 3504 : loss : 0.022843, loss_ce: 0.007481
2022-01-14 00:49:37,578 iteration 3505 : loss : 0.025794, loss_ce: 0.011357
2022-01-14 00:49:39,042 iteration 3506 : loss : 0.028082, loss_ce: 0.009845
2022-01-14 00:49:40,386 iteration 3507 : loss : 0.028990, loss_ce: 0.013319
2022-01-14 00:49:41,779 iteration 3508 : loss : 0.029897, loss_ce: 0.007301
2022-01-14 00:49:43,232 iteration 3509 : loss : 0.043481, loss_ce: 0.018238
2022-01-14 00:49:44,643 iteration 3510 : loss : 0.031350, loss_ce: 0.013218
2022-01-14 00:49:46,264 iteration 3511 : loss : 0.050834, loss_ce: 0.022291
2022-01-14 00:49:47,617 iteration 3512 : loss : 0.026979, loss_ce: 0.010033
2022-01-14 00:49:48,952 iteration 3513 : loss : 0.023874, loss_ce: 0.009672
2022-01-14 00:49:50,375 iteration 3514 : loss : 0.031910, loss_ce: 0.014410
2022-01-14 00:49:51,778 iteration 3515 : loss : 0.028766, loss_ce: 0.013659
2022-01-14 00:49:53,163 iteration 3516 : loss : 0.021136, loss_ce: 0.009636
2022-01-14 00:49:54,589 iteration 3517 : loss : 0.023311, loss_ce: 0.010899
2022-01-14 00:49:56,074 iteration 3518 : loss : 0.048779, loss_ce: 0.015941
2022-01-14 00:49:57,528 iteration 3519 : loss : 0.033138, loss_ce: 0.013038
 52%|█████████████▉             | 207/400 [1:30:10<1:22:58, 25.80s/it]2022-01-14 00:49:58,914 iteration 3520 : loss : 0.036392, loss_ce: 0.012077
2022-01-14 00:50:00,298 iteration 3521 : loss : 0.039284, loss_ce: 0.009566
2022-01-14 00:50:01,660 iteration 3522 : loss : 0.036912, loss_ce: 0.013661
2022-01-14 00:50:03,110 iteration 3523 : loss : 0.029180, loss_ce: 0.016119
2022-01-14 00:50:04,594 iteration 3524 : loss : 0.036145, loss_ce: 0.014440
2022-01-14 00:50:05,980 iteration 3525 : loss : 0.030349, loss_ce: 0.008959
2022-01-14 00:50:07,397 iteration 3526 : loss : 0.034158, loss_ce: 0.021102
2022-01-14 00:50:08,875 iteration 3527 : loss : 0.035411, loss_ce: 0.013568
2022-01-14 00:50:10,261 iteration 3528 : loss : 0.134125, loss_ce: 0.032020
2022-01-14 00:50:11,652 iteration 3529 : loss : 0.032203, loss_ce: 0.011317
2022-01-14 00:50:13,042 iteration 3530 : loss : 0.027225, loss_ce: 0.010619
2022-01-14 00:50:14,454 iteration 3531 : loss : 0.036350, loss_ce: 0.015240
2022-01-14 00:50:15,870 iteration 3532 : loss : 0.026535, loss_ce: 0.011362
2022-01-14 00:50:17,298 iteration 3533 : loss : 0.045687, loss_ce: 0.017254
2022-01-14 00:50:18,644 iteration 3534 : loss : 0.031718, loss_ce: 0.011492
2022-01-14 00:50:20,056 iteration 3535 : loss : 0.029493, loss_ce: 0.011097
2022-01-14 00:50:21,431 iteration 3536 : loss : 0.027826, loss_ce: 0.010902
 52%|██████████████             | 208/400 [1:30:34<1:20:43, 25.23s/it]2022-01-14 00:50:22,990 iteration 3537 : loss : 0.027467, loss_ce: 0.013590
2022-01-14 00:50:24,360 iteration 3538 : loss : 0.028592, loss_ce: 0.010945
2022-01-14 00:50:25,723 iteration 3539 : loss : 0.039754, loss_ce: 0.014779
2022-01-14 00:50:27,175 iteration 3540 : loss : 0.038294, loss_ce: 0.016357
2022-01-14 00:50:28,615 iteration 3541 : loss : 0.042379, loss_ce: 0.023105
2022-01-14 00:50:30,056 iteration 3542 : loss : 0.031356, loss_ce: 0.012192
2022-01-14 00:50:31,532 iteration 3543 : loss : 0.030878, loss_ce: 0.013177
2022-01-14 00:50:32,996 iteration 3544 : loss : 0.052835, loss_ce: 0.010659
2022-01-14 00:50:34,476 iteration 3545 : loss : 0.039295, loss_ce: 0.013184
2022-01-14 00:50:35,922 iteration 3546 : loss : 0.051068, loss_ce: 0.018118
2022-01-14 00:50:37,421 iteration 3547 : loss : 0.035391, loss_ce: 0.015607
2022-01-14 00:50:38,782 iteration 3548 : loss : 0.016656, loss_ce: 0.005092
2022-01-14 00:50:40,287 iteration 3549 : loss : 0.046894, loss_ce: 0.024594
2022-01-14 00:50:41,676 iteration 3550 : loss : 0.025464, loss_ce: 0.010005
2022-01-14 00:50:43,035 iteration 3551 : loss : 0.030308, loss_ce: 0.012907
2022-01-14 00:50:44,405 iteration 3552 : loss : 0.038302, loss_ce: 0.018104
2022-01-14 00:50:45,824 iteration 3553 : loss : 0.022037, loss_ce: 0.008081
 52%|██████████████             | 209/400 [1:30:59<1:19:31, 24.98s/it]2022-01-14 00:50:47,303 iteration 3554 : loss : 0.027825, loss_ce: 0.011807
2022-01-14 00:50:48,712 iteration 3555 : loss : 0.032070, loss_ce: 0.013740
2022-01-14 00:50:50,186 iteration 3556 : loss : 0.033002, loss_ce: 0.018596
2022-01-14 00:50:51,668 iteration 3557 : loss : 0.031220, loss_ce: 0.014480
2022-01-14 00:50:53,076 iteration 3558 : loss : 0.029149, loss_ce: 0.010509
2022-01-14 00:50:54,496 iteration 3559 : loss : 0.052106, loss_ce: 0.019091
2022-01-14 00:50:55,884 iteration 3560 : loss : 0.029634, loss_ce: 0.011364
2022-01-14 00:50:57,210 iteration 3561 : loss : 0.018739, loss_ce: 0.009482
2022-01-14 00:50:58,632 iteration 3562 : loss : 0.039207, loss_ce: 0.018360
2022-01-14 00:51:00,033 iteration 3563 : loss : 0.031150, loss_ce: 0.012156
2022-01-14 00:51:01,494 iteration 3564 : loss : 0.053868, loss_ce: 0.014307
2022-01-14 00:51:02,839 iteration 3565 : loss : 0.030359, loss_ce: 0.008650
2022-01-14 00:51:04,185 iteration 3566 : loss : 0.029258, loss_ce: 0.011365
2022-01-14 00:51:05,673 iteration 3567 : loss : 0.039372, loss_ce: 0.018844
2022-01-14 00:51:07,060 iteration 3568 : loss : 0.029443, loss_ce: 0.010950
2022-01-14 00:51:08,417 iteration 3569 : loss : 0.030937, loss_ce: 0.011307
2022-01-14 00:51:08,417 Training Data Eval:
2022-01-14 00:51:15,489   Average segmentation loss on training set: 0.0196
2022-01-14 00:51:15,489 Validation Data Eval:
2022-01-14 00:51:17,966   Average segmentation loss on validation set: 0.1203
2022-01-14 00:51:19,435 iteration 3570 : loss : 0.032582, loss_ce: 0.009873
 52%|██████████████▏            | 210/400 [1:31:32<1:27:18, 27.57s/it]2022-01-14 00:51:20,927 iteration 3571 : loss : 0.026012, loss_ce: 0.012819
2022-01-14 00:51:22,265 iteration 3572 : loss : 0.023720, loss_ce: 0.009424
2022-01-14 00:51:23,686 iteration 3573 : loss : 0.047415, loss_ce: 0.021900
2022-01-14 00:51:25,081 iteration 3574 : loss : 0.019366, loss_ce: 0.005166
2022-01-14 00:51:26,423 iteration 3575 : loss : 0.022473, loss_ce: 0.007643
2022-01-14 00:51:27,874 iteration 3576 : loss : 0.029965, loss_ce: 0.009858
2022-01-14 00:51:29,286 iteration 3577 : loss : 0.027724, loss_ce: 0.010471
2022-01-14 00:51:30,601 iteration 3578 : loss : 0.035451, loss_ce: 0.013609
2022-01-14 00:51:31,990 iteration 3579 : loss : 0.024936, loss_ce: 0.010270
2022-01-14 00:51:33,355 iteration 3580 : loss : 0.043559, loss_ce: 0.018483
2022-01-14 00:51:34,713 iteration 3581 : loss : 0.026802, loss_ce: 0.014947
2022-01-14 00:51:36,126 iteration 3582 : loss : 0.018776, loss_ce: 0.006915
2022-01-14 00:51:37,580 iteration 3583 : loss : 0.030762, loss_ce: 0.009980
2022-01-14 00:51:39,027 iteration 3584 : loss : 0.026261, loss_ce: 0.009308
2022-01-14 00:51:40,405 iteration 3585 : loss : 0.030230, loss_ce: 0.010992
2022-01-14 00:51:41,882 iteration 3586 : loss : 0.031764, loss_ce: 0.015087
2022-01-14 00:51:43,304 iteration 3587 : loss : 0.021933, loss_ce: 0.008906
 53%|██████████████▏            | 211/400 [1:31:56<1:23:20, 26.46s/it]2022-01-14 00:51:44,834 iteration 3588 : loss : 0.019772, loss_ce: 0.009070
2022-01-14 00:51:46,184 iteration 3589 : loss : 0.023770, loss_ce: 0.008243
2022-01-14 00:51:47,582 iteration 3590 : loss : 0.031059, loss_ce: 0.013268
2022-01-14 00:51:48,994 iteration 3591 : loss : 0.032153, loss_ce: 0.012427
2022-01-14 00:51:50,587 iteration 3592 : loss : 0.037071, loss_ce: 0.015927
2022-01-14 00:51:51,958 iteration 3593 : loss : 0.041875, loss_ce: 0.014524
2022-01-14 00:51:53,339 iteration 3594 : loss : 0.028574, loss_ce: 0.010259
2022-01-14 00:51:54,775 iteration 3595 : loss : 0.036170, loss_ce: 0.013059
2022-01-14 00:51:56,169 iteration 3596 : loss : 0.020205, loss_ce: 0.007205
2022-01-14 00:51:57,616 iteration 3597 : loss : 0.044017, loss_ce: 0.017866
2022-01-14 00:51:58,990 iteration 3598 : loss : 0.022334, loss_ce: 0.009247
2022-01-14 00:52:00,450 iteration 3599 : loss : 0.027055, loss_ce: 0.009286
2022-01-14 00:52:01,772 iteration 3600 : loss : 0.022341, loss_ce: 0.008489
2022-01-14 00:52:03,212 iteration 3601 : loss : 0.025497, loss_ce: 0.009592
2022-01-14 00:52:04,581 iteration 3602 : loss : 0.026452, loss_ce: 0.009005
2022-01-14 00:52:06,017 iteration 3603 : loss : 0.030300, loss_ce: 0.014522
2022-01-14 00:52:07,388 iteration 3604 : loss : 0.019594, loss_ce: 0.008470
 53%|██████████████▎            | 212/400 [1:32:20<1:20:40, 25.75s/it]2022-01-14 00:52:08,873 iteration 3605 : loss : 0.023522, loss_ce: 0.008871
2022-01-14 00:52:10,255 iteration 3606 : loss : 0.024512, loss_ce: 0.012092
2022-01-14 00:52:11,707 iteration 3607 : loss : 0.035256, loss_ce: 0.014025
2022-01-14 00:52:13,101 iteration 3608 : loss : 0.024445, loss_ce: 0.009119
2022-01-14 00:52:14,469 iteration 3609 : loss : 0.021039, loss_ce: 0.009221
2022-01-14 00:52:15,888 iteration 3610 : loss : 0.027779, loss_ce: 0.011255
2022-01-14 00:52:17,228 iteration 3611 : loss : 0.025838, loss_ce: 0.006903
2022-01-14 00:52:18,582 iteration 3612 : loss : 0.021142, loss_ce: 0.007411
2022-01-14 00:52:20,089 iteration 3613 : loss : 0.044027, loss_ce: 0.019697
2022-01-14 00:52:21,432 iteration 3614 : loss : 0.018586, loss_ce: 0.007247
2022-01-14 00:52:22,743 iteration 3615 : loss : 0.021575, loss_ce: 0.007461
2022-01-14 00:52:24,156 iteration 3616 : loss : 0.041609, loss_ce: 0.015489
2022-01-14 00:52:25,598 iteration 3617 : loss : 0.026297, loss_ce: 0.010736
2022-01-14 00:52:27,011 iteration 3618 : loss : 0.028297, loss_ce: 0.012794
2022-01-14 00:52:28,417 iteration 3619 : loss : 0.041780, loss_ce: 0.010937
2022-01-14 00:52:29,805 iteration 3620 : loss : 0.028621, loss_ce: 0.009431
2022-01-14 00:52:31,213 iteration 3621 : loss : 0.029607, loss_ce: 0.010942
 53%|██████████████▍            | 213/400 [1:32:44<1:18:26, 25.17s/it]2022-01-14 00:52:32,676 iteration 3622 : loss : 0.029481, loss_ce: 0.013379
2022-01-14 00:52:34,123 iteration 3623 : loss : 0.024872, loss_ce: 0.005364
2022-01-14 00:52:35,511 iteration 3624 : loss : 0.020529, loss_ce: 0.008590
2022-01-14 00:52:36,890 iteration 3625 : loss : 0.024916, loss_ce: 0.009933
2022-01-14 00:52:38,243 iteration 3626 : loss : 0.022621, loss_ce: 0.010846
2022-01-14 00:52:39,572 iteration 3627 : loss : 0.023474, loss_ce: 0.008625
2022-01-14 00:52:41,009 iteration 3628 : loss : 0.044652, loss_ce: 0.013494
2022-01-14 00:52:42,571 iteration 3629 : loss : 0.024338, loss_ce: 0.010154
2022-01-14 00:52:43,880 iteration 3630 : loss : 0.026398, loss_ce: 0.009901
2022-01-14 00:52:45,271 iteration 3631 : loss : 0.028381, loss_ce: 0.009009
2022-01-14 00:52:46,801 iteration 3632 : loss : 0.028061, loss_ce: 0.009387
2022-01-14 00:52:48,190 iteration 3633 : loss : 0.024936, loss_ce: 0.009970
2022-01-14 00:52:49,565 iteration 3634 : loss : 0.023762, loss_ce: 0.010277
2022-01-14 00:52:51,060 iteration 3635 : loss : 0.034545, loss_ce: 0.013865
2022-01-14 00:52:52,510 iteration 3636 : loss : 0.034080, loss_ce: 0.010797
2022-01-14 00:52:53,919 iteration 3637 : loss : 0.045522, loss_ce: 0.018195
2022-01-14 00:52:55,302 iteration 3638 : loss : 0.022996, loss_ce: 0.009436
 54%|██████████████▍            | 214/400 [1:33:08<1:17:01, 24.85s/it]2022-01-14 00:52:56,697 iteration 3639 : loss : 0.020579, loss_ce: 0.008233
2022-01-14 00:52:58,040 iteration 3640 : loss : 0.025647, loss_ce: 0.010077
2022-01-14 00:52:59,365 iteration 3641 : loss : 0.021130, loss_ce: 0.007188
2022-01-14 00:53:00,757 iteration 3642 : loss : 0.025965, loss_ce: 0.007397
2022-01-14 00:53:02,096 iteration 3643 : loss : 0.028978, loss_ce: 0.010985
2022-01-14 00:53:03,444 iteration 3644 : loss : 0.016626, loss_ce: 0.006200
2022-01-14 00:53:04,824 iteration 3645 : loss : 0.025483, loss_ce: 0.007951
2022-01-14 00:53:06,227 iteration 3646 : loss : 0.030972, loss_ce: 0.013453
2022-01-14 00:53:07,620 iteration 3647 : loss : 0.020853, loss_ce: 0.005584
2022-01-14 00:53:09,040 iteration 3648 : loss : 0.036384, loss_ce: 0.015913
2022-01-14 00:53:10,424 iteration 3649 : loss : 0.021291, loss_ce: 0.005684
2022-01-14 00:53:11,851 iteration 3650 : loss : 0.035150, loss_ce: 0.019761
2022-01-14 00:53:13,315 iteration 3651 : loss : 0.038656, loss_ce: 0.011577
2022-01-14 00:53:14,852 iteration 3652 : loss : 0.054034, loss_ce: 0.014782
2022-01-14 00:53:16,215 iteration 3653 : loss : 0.024052, loss_ce: 0.012209
2022-01-14 00:53:17,572 iteration 3654 : loss : 0.019012, loss_ce: 0.009166
2022-01-14 00:53:17,572 Training Data Eval:
2022-01-14 00:53:24,675   Average segmentation loss on training set: 0.0178
2022-01-14 00:53:24,676 Validation Data Eval:
2022-01-14 00:53:27,171   Average segmentation loss on validation set: 0.0730
2022-01-14 00:53:28,625 iteration 3655 : loss : 0.026230, loss_ce: 0.010942
 54%|██████████████▌            | 215/400 [1:33:42<1:24:27, 27.39s/it]2022-01-14 00:53:30,169 iteration 3656 : loss : 0.031649, loss_ce: 0.014436
2022-01-14 00:53:31,530 iteration 3657 : loss : 0.022054, loss_ce: 0.010695
2022-01-14 00:53:32,987 iteration 3658 : loss : 0.031172, loss_ce: 0.014351
2022-01-14 00:53:34,494 iteration 3659 : loss : 0.031107, loss_ce: 0.011573
2022-01-14 00:53:35,892 iteration 3660 : loss : 0.044504, loss_ce: 0.011845
2022-01-14 00:53:37,256 iteration 3661 : loss : 0.019590, loss_ce: 0.008107
2022-01-14 00:53:38,687 iteration 3662 : loss : 0.022571, loss_ce: 0.008325
2022-01-14 00:53:40,091 iteration 3663 : loss : 0.031461, loss_ce: 0.010702
2022-01-14 00:53:41,566 iteration 3664 : loss : 0.018371, loss_ce: 0.006418
2022-01-14 00:53:42,976 iteration 3665 : loss : 0.029709, loss_ce: 0.013473
2022-01-14 00:53:44,369 iteration 3666 : loss : 0.031393, loss_ce: 0.013149
2022-01-14 00:53:45,771 iteration 3667 : loss : 0.035848, loss_ce: 0.017546
2022-01-14 00:53:47,105 iteration 3668 : loss : 0.023117, loss_ce: 0.004384
2022-01-14 00:53:48,555 iteration 3669 : loss : 0.027856, loss_ce: 0.013208
2022-01-14 00:53:49,916 iteration 3670 : loss : 0.022034, loss_ce: 0.008626
2022-01-14 00:53:51,308 iteration 3671 : loss : 0.029389, loss_ce: 0.014892
2022-01-14 00:53:52,850 iteration 3672 : loss : 0.041822, loss_ce: 0.010892
 54%|██████████████▌            | 216/400 [1:34:06<1:21:05, 26.44s/it]2022-01-14 00:53:54,326 iteration 3673 : loss : 0.024340, loss_ce: 0.010591
2022-01-14 00:53:55,771 iteration 3674 : loss : 0.033084, loss_ce: 0.008337
2022-01-14 00:53:57,283 iteration 3675 : loss : 0.038156, loss_ce: 0.010897
2022-01-14 00:53:58,610 iteration 3676 : loss : 0.020100, loss_ce: 0.007862
2022-01-14 00:54:00,013 iteration 3677 : loss : 0.032053, loss_ce: 0.011618
2022-01-14 00:54:01,498 iteration 3678 : loss : 0.034978, loss_ce: 0.010653
2022-01-14 00:54:02,883 iteration 3679 : loss : 0.019660, loss_ce: 0.007217
2022-01-14 00:54:04,282 iteration 3680 : loss : 0.047964, loss_ce: 0.019931
2022-01-14 00:54:05,679 iteration 3681 : loss : 0.024337, loss_ce: 0.011523
2022-01-14 00:54:06,985 iteration 3682 : loss : 0.023766, loss_ce: 0.009469
2022-01-14 00:54:08,286 iteration 3683 : loss : 0.023257, loss_ce: 0.008652
2022-01-14 00:54:09,727 iteration 3684 : loss : 0.031805, loss_ce: 0.013810
2022-01-14 00:54:11,096 iteration 3685 : loss : 0.025246, loss_ce: 0.007251
2022-01-14 00:54:12,499 iteration 3686 : loss : 0.025941, loss_ce: 0.010911
2022-01-14 00:54:13,860 iteration 3687 : loss : 0.023925, loss_ce: 0.009138
2022-01-14 00:54:15,270 iteration 3688 : loss : 0.022738, loss_ce: 0.011261
2022-01-14 00:54:16,689 iteration 3689 : loss : 0.026976, loss_ce: 0.009508
 54%|██████████████▋            | 217/400 [1:34:30<1:18:15, 25.66s/it]2022-01-14 00:54:18,146 iteration 3690 : loss : 0.051815, loss_ce: 0.016298
2022-01-14 00:54:19,584 iteration 3691 : loss : 0.035104, loss_ce: 0.011180
2022-01-14 00:54:20,992 iteration 3692 : loss : 0.031282, loss_ce: 0.015761
2022-01-14 00:54:22,325 iteration 3693 : loss : 0.025733, loss_ce: 0.010368
2022-01-14 00:54:23,725 iteration 3694 : loss : 0.042154, loss_ce: 0.016731
2022-01-14 00:54:25,123 iteration 3695 : loss : 0.025488, loss_ce: 0.012642
2022-01-14 00:54:26,497 iteration 3696 : loss : 0.039977, loss_ce: 0.012353
2022-01-14 00:54:27,936 iteration 3697 : loss : 0.039119, loss_ce: 0.010884
2022-01-14 00:54:29,408 iteration 3698 : loss : 0.049842, loss_ce: 0.023013
2022-01-14 00:54:30,749 iteration 3699 : loss : 0.018877, loss_ce: 0.007663
2022-01-14 00:54:32,159 iteration 3700 : loss : 0.023134, loss_ce: 0.007338
2022-01-14 00:54:33,464 iteration 3701 : loss : 0.031283, loss_ce: 0.015826
2022-01-14 00:54:34,867 iteration 3702 : loss : 0.025164, loss_ce: 0.009767
2022-01-14 00:54:36,280 iteration 3703 : loss : 0.029254, loss_ce: 0.014550
2022-01-14 00:54:37,580 iteration 3704 : loss : 0.026499, loss_ce: 0.009942
2022-01-14 00:54:39,030 iteration 3705 : loss : 0.033723, loss_ce: 0.012621
2022-01-14 00:54:40,346 iteration 3706 : loss : 0.027773, loss_ce: 0.010205
 55%|██████████████▋            | 218/400 [1:34:53<1:16:00, 25.06s/it]2022-01-14 00:54:41,815 iteration 3707 : loss : 0.023147, loss_ce: 0.011596
2022-01-14 00:54:43,128 iteration 3708 : loss : 0.032084, loss_ce: 0.012494
2022-01-14 00:54:44,638 iteration 3709 : loss : 0.068027, loss_ce: 0.028079
2022-01-14 00:54:46,028 iteration 3710 : loss : 0.031920, loss_ce: 0.010647
2022-01-14 00:54:47,386 iteration 3711 : loss : 0.022362, loss_ce: 0.007320
2022-01-14 00:54:48,721 iteration 3712 : loss : 0.027460, loss_ce: 0.012584
2022-01-14 00:54:50,198 iteration 3713 : loss : 0.030359, loss_ce: 0.010940
2022-01-14 00:54:51,591 iteration 3714 : loss : 0.047011, loss_ce: 0.019755
2022-01-14 00:54:52,953 iteration 3715 : loss : 0.019810, loss_ce: 0.008271
2022-01-14 00:54:54,336 iteration 3716 : loss : 0.034765, loss_ce: 0.022149
2022-01-14 00:54:55,787 iteration 3717 : loss : 0.027051, loss_ce: 0.011084
2022-01-14 00:54:57,153 iteration 3718 : loss : 0.021863, loss_ce: 0.008716
2022-01-14 00:54:58,563 iteration 3719 : loss : 0.034845, loss_ce: 0.012303
2022-01-14 00:55:00,056 iteration 3720 : loss : 0.037579, loss_ce: 0.011938
2022-01-14 00:55:01,433 iteration 3721 : loss : 0.022290, loss_ce: 0.008998
2022-01-14 00:55:02,812 iteration 3722 : loss : 0.035457, loss_ce: 0.017348
2022-01-14 00:55:04,261 iteration 3723 : loss : 0.075192, loss_ce: 0.016040
 55%|██████████████▊            | 219/400 [1:35:17<1:14:33, 24.72s/it]2022-01-14 00:55:05,777 iteration 3724 : loss : 0.030493, loss_ce: 0.013109
2022-01-14 00:55:07,182 iteration 3725 : loss : 0.050319, loss_ce: 0.020773
2022-01-14 00:55:08,696 iteration 3726 : loss : 0.029492, loss_ce: 0.010889
2022-01-14 00:55:10,059 iteration 3727 : loss : 0.023937, loss_ce: 0.007961
2022-01-14 00:55:11,453 iteration 3728 : loss : 0.038497, loss_ce: 0.020145
2022-01-14 00:55:12,906 iteration 3729 : loss : 0.041280, loss_ce: 0.015105
2022-01-14 00:55:14,282 iteration 3730 : loss : 0.053901, loss_ce: 0.015446
2022-01-14 00:55:15,624 iteration 3731 : loss : 0.038330, loss_ce: 0.012335
2022-01-14 00:55:17,027 iteration 3732 : loss : 0.048439, loss_ce: 0.021593
2022-01-14 00:55:18,397 iteration 3733 : loss : 0.040878, loss_ce: 0.014226
2022-01-14 00:55:19,813 iteration 3734 : loss : 0.034759, loss_ce: 0.014077
2022-01-14 00:55:21,245 iteration 3735 : loss : 0.051444, loss_ce: 0.022850
2022-01-14 00:55:22,689 iteration 3736 : loss : 0.080905, loss_ce: 0.026092
2022-01-14 00:55:24,109 iteration 3737 : loss : 0.035418, loss_ce: 0.015094
2022-01-14 00:55:25,499 iteration 3738 : loss : 0.052826, loss_ce: 0.018005
2022-01-14 00:55:26,894 iteration 3739 : loss : 0.039101, loss_ce: 0.015717
2022-01-14 00:55:26,895 Training Data Eval:
2022-01-14 00:55:33,824   Average segmentation loss on training set: 0.0532
2022-01-14 00:55:33,825 Validation Data Eval:
2022-01-14 00:55:36,348   Average segmentation loss on validation set: 0.1378
2022-01-14 00:55:37,842 iteration 3740 : loss : 0.037702, loss_ce: 0.012312
 55%|██████████████▊            | 220/400 [1:35:51<1:22:07, 27.38s/it]2022-01-14 00:55:39,328 iteration 3741 : loss : 0.034919, loss_ce: 0.014137
2022-01-14 00:55:40,686 iteration 3742 : loss : 0.040109, loss_ce: 0.018040
2022-01-14 00:55:42,071 iteration 3743 : loss : 0.052656, loss_ce: 0.020223
2022-01-14 00:55:43,485 iteration 3744 : loss : 0.036957, loss_ce: 0.019635
2022-01-14 00:55:44,829 iteration 3745 : loss : 0.027887, loss_ce: 0.010399
2022-01-14 00:55:46,265 iteration 3746 : loss : 0.028460, loss_ce: 0.011523
2022-01-14 00:55:47,715 iteration 3747 : loss : 0.066140, loss_ce: 0.011015
2022-01-14 00:55:49,110 iteration 3748 : loss : 0.042555, loss_ce: 0.020410
2022-01-14 00:55:50,499 iteration 3749 : loss : 0.032074, loss_ce: 0.013112
2022-01-14 00:55:51,920 iteration 3750 : loss : 0.043004, loss_ce: 0.017866
2022-01-14 00:55:53,334 iteration 3751 : loss : 0.040054, loss_ce: 0.010821
2022-01-14 00:55:54,739 iteration 3752 : loss : 0.056053, loss_ce: 0.024345
2022-01-14 00:55:56,094 iteration 3753 : loss : 0.038273, loss_ce: 0.008855
2022-01-14 00:55:57,426 iteration 3754 : loss : 0.024644, loss_ce: 0.007770
2022-01-14 00:55:58,782 iteration 3755 : loss : 0.032611, loss_ce: 0.014517
2022-01-14 00:56:00,171 iteration 3756 : loss : 0.034671, loss_ce: 0.011856
2022-01-14 00:56:01,586 iteration 3757 : loss : 0.034750, loss_ce: 0.012191
 55%|██████████████▉            | 221/400 [1:36:15<1:18:25, 26.29s/it]2022-01-14 00:56:03,065 iteration 3758 : loss : 0.044415, loss_ce: 0.019888
2022-01-14 00:56:04,469 iteration 3759 : loss : 0.031021, loss_ce: 0.010706
2022-01-14 00:56:05,780 iteration 3760 : loss : 0.027784, loss_ce: 0.009546
2022-01-14 00:56:07,227 iteration 3761 : loss : 0.047283, loss_ce: 0.018957
2022-01-14 00:56:08,626 iteration 3762 : loss : 0.050053, loss_ce: 0.016063
2022-01-14 00:56:10,100 iteration 3763 : loss : 0.040363, loss_ce: 0.015743
2022-01-14 00:56:11,547 iteration 3764 : loss : 0.063071, loss_ce: 0.029077
2022-01-14 00:56:12,953 iteration 3765 : loss : 0.024366, loss_ce: 0.010447
2022-01-14 00:56:14,384 iteration 3766 : loss : 0.036508, loss_ce: 0.013149
2022-01-14 00:56:15,840 iteration 3767 : loss : 0.046494, loss_ce: 0.014114
2022-01-14 00:56:17,263 iteration 3768 : loss : 0.030139, loss_ce: 0.014226
2022-01-14 00:56:18,632 iteration 3769 : loss : 0.030765, loss_ce: 0.013225
2022-01-14 00:56:19,963 iteration 3770 : loss : 0.030073, loss_ce: 0.011457
2022-01-14 00:56:21,310 iteration 3771 : loss : 0.022883, loss_ce: 0.009123
2022-01-14 00:56:22,699 iteration 3772 : loss : 0.033283, loss_ce: 0.011839
2022-01-14 00:56:24,028 iteration 3773 : loss : 0.022312, loss_ce: 0.008870
2022-01-14 00:56:25,364 iteration 3774 : loss : 0.027910, loss_ce: 0.011636
 56%|██████████████▉            | 222/400 [1:36:38<1:15:44, 25.53s/it]2022-01-14 00:56:26,782 iteration 3775 : loss : 0.029664, loss_ce: 0.010014
2022-01-14 00:56:28,228 iteration 3776 : loss : 0.047576, loss_ce: 0.022957
2022-01-14 00:56:29,739 iteration 3777 : loss : 0.042080, loss_ce: 0.012930
2022-01-14 00:56:31,112 iteration 3778 : loss : 0.026604, loss_ce: 0.014276
2022-01-14 00:56:32,582 iteration 3779 : loss : 0.029145, loss_ce: 0.012429
2022-01-14 00:56:33,976 iteration 3780 : loss : 0.030115, loss_ce: 0.015101
2022-01-14 00:56:35,377 iteration 3781 : loss : 0.031093, loss_ce: 0.012729
2022-01-14 00:56:36,828 iteration 3782 : loss : 0.030893, loss_ce: 0.011413
2022-01-14 00:56:38,283 iteration 3783 : loss : 0.026411, loss_ce: 0.008947
2022-01-14 00:56:39,744 iteration 3784 : loss : 0.032406, loss_ce: 0.015011
2022-01-14 00:56:41,145 iteration 3785 : loss : 0.037814, loss_ce: 0.014074
2022-01-14 00:56:42,577 iteration 3786 : loss : 0.022883, loss_ce: 0.008469
2022-01-14 00:56:44,074 iteration 3787 : loss : 0.057092, loss_ce: 0.030581
2022-01-14 00:56:45,547 iteration 3788 : loss : 0.038816, loss_ce: 0.014095
2022-01-14 00:56:46,904 iteration 3789 : loss : 0.028216, loss_ce: 0.008265
2022-01-14 00:56:48,328 iteration 3790 : loss : 0.033078, loss_ce: 0.012243
2022-01-14 00:56:49,645 iteration 3791 : loss : 0.035319, loss_ce: 0.012446
 56%|███████████████            | 223/400 [1:37:03<1:14:12, 25.16s/it]2022-01-14 00:56:51,094 iteration 3792 : loss : 0.023596, loss_ce: 0.010152
2022-01-14 00:56:52,491 iteration 3793 : loss : 0.024191, loss_ce: 0.010330
2022-01-14 00:56:53,841 iteration 3794 : loss : 0.024910, loss_ce: 0.009161
2022-01-14 00:56:55,344 iteration 3795 : loss : 0.034328, loss_ce: 0.014582
2022-01-14 00:56:56,769 iteration 3796 : loss : 0.055050, loss_ce: 0.016074
2022-01-14 00:56:58,148 iteration 3797 : loss : 0.031034, loss_ce: 0.009996
2022-01-14 00:56:59,644 iteration 3798 : loss : 0.028978, loss_ce: 0.012565
2022-01-14 00:57:00,995 iteration 3799 : loss : 0.024788, loss_ce: 0.013261
2022-01-14 00:57:02,442 iteration 3800 : loss : 0.025520, loss_ce: 0.008694
2022-01-14 00:57:03,816 iteration 3801 : loss : 0.022440, loss_ce: 0.008860
2022-01-14 00:57:05,207 iteration 3802 : loss : 0.027668, loss_ce: 0.007591
2022-01-14 00:57:06,592 iteration 3803 : loss : 0.025571, loss_ce: 0.010120
2022-01-14 00:57:07,894 iteration 3804 : loss : 0.031688, loss_ce: 0.014020
2022-01-14 00:57:09,324 iteration 3805 : loss : 0.026337, loss_ce: 0.011479
2022-01-14 00:57:10,679 iteration 3806 : loss : 0.028110, loss_ce: 0.008726
2022-01-14 00:57:12,049 iteration 3807 : loss : 0.030022, loss_ce: 0.012855
2022-01-14 00:57:13,473 iteration 3808 : loss : 0.023644, loss_ce: 0.008918
 56%|███████████████            | 224/400 [1:37:26<1:12:37, 24.76s/it]2022-01-14 00:57:14,938 iteration 3809 : loss : 0.025934, loss_ce: 0.009953
2022-01-14 00:57:16,349 iteration 3810 : loss : 0.026336, loss_ce: 0.010372
2022-01-14 00:57:17,880 iteration 3811 : loss : 0.029633, loss_ce: 0.009595
2022-01-14 00:57:19,253 iteration 3812 : loss : 0.025406, loss_ce: 0.009104
2022-01-14 00:57:20,670 iteration 3813 : loss : 0.039146, loss_ce: 0.013332
2022-01-14 00:57:22,015 iteration 3814 : loss : 0.021670, loss_ce: 0.007455
2022-01-14 00:57:23,477 iteration 3815 : loss : 0.032101, loss_ce: 0.013138
2022-01-14 00:57:24,980 iteration 3816 : loss : 0.031509, loss_ce: 0.011182
2022-01-14 00:57:26,408 iteration 3817 : loss : 0.027692, loss_ce: 0.013576
2022-01-14 00:57:27,922 iteration 3818 : loss : 0.031983, loss_ce: 0.013447
2022-01-14 00:57:29,269 iteration 3819 : loss : 0.023477, loss_ce: 0.011139
2022-01-14 00:57:30,721 iteration 3820 : loss : 0.029476, loss_ce: 0.012881
2022-01-14 00:57:32,127 iteration 3821 : loss : 0.029311, loss_ce: 0.013954
2022-01-14 00:57:33,446 iteration 3822 : loss : 0.020448, loss_ce: 0.008156
2022-01-14 00:57:34,813 iteration 3823 : loss : 0.025933, loss_ce: 0.009394
2022-01-14 00:57:36,215 iteration 3824 : loss : 0.023672, loss_ce: 0.009483
2022-01-14 00:57:36,215 Training Data Eval:
2022-01-14 00:57:43,355   Average segmentation loss on training set: 0.0181
2022-01-14 00:57:43,356 Validation Data Eval:
2022-01-14 00:57:45,832   Average segmentation loss on validation set: 0.0723
2022-01-14 00:57:47,214 iteration 3825 : loss : 0.030665, loss_ce: 0.012302
 56%|███████████████▏           | 225/400 [1:38:00<1:20:04, 27.45s/it]2022-01-14 00:57:48,590 iteration 3826 : loss : 0.020897, loss_ce: 0.009364
2022-01-14 00:57:49,997 iteration 3827 : loss : 0.021763, loss_ce: 0.007805
2022-01-14 00:57:51,416 iteration 3828 : loss : 0.027139, loss_ce: 0.011238
2022-01-14 00:57:52,821 iteration 3829 : loss : 0.049292, loss_ce: 0.024174
2022-01-14 00:57:54,242 iteration 3830 : loss : 0.047578, loss_ce: 0.021137
2022-01-14 00:57:55,716 iteration 3831 : loss : 0.037518, loss_ce: 0.008741
2022-01-14 00:57:57,035 iteration 3832 : loss : 0.018887, loss_ce: 0.006418
2022-01-14 00:57:58,459 iteration 3833 : loss : 0.020298, loss_ce: 0.006721
2022-01-14 00:57:59,839 iteration 3834 : loss : 0.017901, loss_ce: 0.009122
2022-01-14 00:58:01,278 iteration 3835 : loss : 0.024367, loss_ce: 0.011429
2022-01-14 00:58:02,745 iteration 3836 : loss : 0.028062, loss_ce: 0.011137
2022-01-14 00:58:04,064 iteration 3837 : loss : 0.019860, loss_ce: 0.007827
2022-01-14 00:58:05,418 iteration 3838 : loss : 0.031644, loss_ce: 0.012702
2022-01-14 00:58:06,798 iteration 3839 : loss : 0.032504, loss_ce: 0.011792
2022-01-14 00:58:08,145 iteration 3840 : loss : 0.030693, loss_ce: 0.008338
2022-01-14 00:58:09,554 iteration 3841 : loss : 0.027946, loss_ce: 0.008765
2022-01-14 00:58:10,944 iteration 3842 : loss : 0.027820, loss_ce: 0.006816
 56%|███████████████▎           | 226/400 [1:38:24<1:16:22, 26.33s/it]2022-01-14 00:58:12,460 iteration 3843 : loss : 0.019335, loss_ce: 0.008036
2022-01-14 00:58:13,888 iteration 3844 : loss : 0.026850, loss_ce: 0.013023
2022-01-14 00:58:15,282 iteration 3845 : loss : 0.030686, loss_ce: 0.011761
2022-01-14 00:58:16,696 iteration 3846 : loss : 0.021619, loss_ce: 0.006829
2022-01-14 00:58:18,142 iteration 3847 : loss : 0.019729, loss_ce: 0.008083
2022-01-14 00:58:19,535 iteration 3848 : loss : 0.019838, loss_ce: 0.007982
2022-01-14 00:58:20,898 iteration 3849 : loss : 0.019767, loss_ce: 0.007535
2022-01-14 00:58:22,349 iteration 3850 : loss : 0.040938, loss_ce: 0.010965
2022-01-14 00:58:23,792 iteration 3851 : loss : 0.029762, loss_ce: 0.016106
2022-01-14 00:58:25,179 iteration 3852 : loss : 0.026560, loss_ce: 0.008662
2022-01-14 00:58:26,531 iteration 3853 : loss : 0.022910, loss_ce: 0.011489
2022-01-14 00:58:27,965 iteration 3854 : loss : 0.033631, loss_ce: 0.015774
2022-01-14 00:58:29,375 iteration 3855 : loss : 0.029962, loss_ce: 0.011218
2022-01-14 00:58:30,793 iteration 3856 : loss : 0.024395, loss_ce: 0.008411
2022-01-14 00:58:32,149 iteration 3857 : loss : 0.019045, loss_ce: 0.007888
2022-01-14 00:58:33,596 iteration 3858 : loss : 0.022059, loss_ce: 0.007830
2022-01-14 00:58:35,033 iteration 3859 : loss : 0.025705, loss_ce: 0.006035
 57%|███████████████▎           | 227/400 [1:38:48<1:13:59, 25.66s/it]2022-01-14 00:58:36,508 iteration 3860 : loss : 0.021390, loss_ce: 0.009216
2022-01-14 00:58:37,998 iteration 3861 : loss : 0.028323, loss_ce: 0.013657
2022-01-14 00:58:39,355 iteration 3862 : loss : 0.020355, loss_ce: 0.009399
2022-01-14 00:58:40,817 iteration 3863 : loss : 0.029450, loss_ce: 0.013881
2022-01-14 00:58:42,294 iteration 3864 : loss : 0.023546, loss_ce: 0.009065
2022-01-14 00:58:43,829 iteration 3865 : loss : 0.035359, loss_ce: 0.016456
2022-01-14 00:58:45,370 iteration 3866 : loss : 0.028235, loss_ce: 0.012229
2022-01-14 00:58:46,747 iteration 3867 : loss : 0.019663, loss_ce: 0.007812
2022-01-14 00:58:48,177 iteration 3868 : loss : 0.023494, loss_ce: 0.009517
2022-01-14 00:58:49,618 iteration 3869 : loss : 0.030283, loss_ce: 0.011691
2022-01-14 00:58:51,077 iteration 3870 : loss : 0.034737, loss_ce: 0.013398
2022-01-14 00:58:52,471 iteration 3871 : loss : 0.030642, loss_ce: 0.008119
2022-01-14 00:58:53,859 iteration 3872 : loss : 0.024914, loss_ce: 0.010870
2022-01-14 00:58:55,239 iteration 3873 : loss : 0.029059, loss_ce: 0.010832
2022-01-14 00:58:56,687 iteration 3874 : loss : 0.023538, loss_ce: 0.008020
2022-01-14 00:58:58,141 iteration 3875 : loss : 0.019887, loss_ce: 0.007449
2022-01-14 00:58:59,519 iteration 3876 : loss : 0.028385, loss_ce: 0.005818
 57%|███████████████▍           | 228/400 [1:39:12<1:12:33, 25.31s/it]2022-01-14 00:59:00,937 iteration 3877 : loss : 0.024417, loss_ce: 0.009773
2022-01-14 00:59:02,412 iteration 3878 : loss : 0.024080, loss_ce: 0.010595
2022-01-14 00:59:03,828 iteration 3879 : loss : 0.027309, loss_ce: 0.012323
2022-01-14 00:59:05,213 iteration 3880 : loss : 0.025335, loss_ce: 0.010746
2022-01-14 00:59:06,574 iteration 3881 : loss : 0.020760, loss_ce: 0.010210
2022-01-14 00:59:08,030 iteration 3882 : loss : 0.043765, loss_ce: 0.015996
2022-01-14 00:59:09,464 iteration 3883 : loss : 0.050797, loss_ce: 0.027731
2022-01-14 00:59:10,828 iteration 3884 : loss : 0.047594, loss_ce: 0.007424
2022-01-14 00:59:12,167 iteration 3885 : loss : 0.020506, loss_ce: 0.006777
2022-01-14 00:59:13,517 iteration 3886 : loss : 0.027488, loss_ce: 0.008933
2022-01-14 00:59:14,986 iteration 3887 : loss : 0.035494, loss_ce: 0.013852
2022-01-14 00:59:16,386 iteration 3888 : loss : 0.029721, loss_ce: 0.009725
2022-01-14 00:59:17,789 iteration 3889 : loss : 0.035111, loss_ce: 0.015168
2022-01-14 00:59:19,103 iteration 3890 : loss : 0.028516, loss_ce: 0.009239
2022-01-14 00:59:20,507 iteration 3891 : loss : 0.016697, loss_ce: 0.006086
2022-01-14 00:59:21,920 iteration 3892 : loss : 0.046461, loss_ce: 0.015766
2022-01-14 00:59:23,456 iteration 3893 : loss : 0.035372, loss_ce: 0.017365
 57%|███████████████▍           | 229/400 [1:39:36<1:10:57, 24.90s/it]2022-01-14 00:59:24,914 iteration 3894 : loss : 0.019957, loss_ce: 0.008831
2022-01-14 00:59:26,437 iteration 3895 : loss : 0.030858, loss_ce: 0.012030
2022-01-14 00:59:27,859 iteration 3896 : loss : 0.052278, loss_ce: 0.013526
2022-01-14 00:59:29,318 iteration 3897 : loss : 0.045640, loss_ce: 0.020023
2022-01-14 00:59:30,714 iteration 3898 : loss : 0.022616, loss_ce: 0.008444
2022-01-14 00:59:32,164 iteration 3899 : loss : 0.039082, loss_ce: 0.015098
2022-01-14 00:59:33,660 iteration 3900 : loss : 0.036694, loss_ce: 0.011914
2022-01-14 00:59:35,029 iteration 3901 : loss : 0.023334, loss_ce: 0.007436
2022-01-14 00:59:36,410 iteration 3902 : loss : 0.022329, loss_ce: 0.008026
2022-01-14 00:59:37,820 iteration 3903 : loss : 0.025003, loss_ce: 0.008367
2022-01-14 00:59:39,301 iteration 3904 : loss : 0.037874, loss_ce: 0.011181
2022-01-14 00:59:40,696 iteration 3905 : loss : 0.025103, loss_ce: 0.010874
2022-01-14 00:59:42,063 iteration 3906 : loss : 0.024724, loss_ce: 0.011317
2022-01-14 00:59:43,487 iteration 3907 : loss : 0.040752, loss_ce: 0.012676
2022-01-14 00:59:44,961 iteration 3908 : loss : 0.038021, loss_ce: 0.013896
2022-01-14 00:59:46,407 iteration 3909 : loss : 0.027103, loss_ce: 0.010136
2022-01-14 00:59:46,407 Training Data Eval:
2022-01-14 00:59:53,517   Average segmentation loss on training set: 0.0180
2022-01-14 00:59:53,518 Validation Data Eval:
2022-01-14 00:59:56,055   Average segmentation loss on validation set: 0.0768
2022-01-14 00:59:57,420 iteration 3910 : loss : 0.018986, loss_ce: 0.006021
 57%|███████████████▌           | 230/400 [1:40:10<1:18:14, 27.62s/it]2022-01-14 00:59:58,865 iteration 3911 : loss : 0.021033, loss_ce: 0.006686
2022-01-14 01:00:00,354 iteration 3912 : loss : 0.035587, loss_ce: 0.013687
2022-01-14 01:00:01,711 iteration 3913 : loss : 0.027670, loss_ce: 0.009004
2022-01-14 01:00:03,062 iteration 3914 : loss : 0.022434, loss_ce: 0.008146
2022-01-14 01:00:04,425 iteration 3915 : loss : 0.020471, loss_ce: 0.006870
2022-01-14 01:00:05,896 iteration 3916 : loss : 0.028892, loss_ce: 0.010545
2022-01-14 01:00:07,361 iteration 3917 : loss : 0.040005, loss_ce: 0.009428
2022-01-14 01:00:08,828 iteration 3918 : loss : 0.032077, loss_ce: 0.012299
2022-01-14 01:00:10,228 iteration 3919 : loss : 0.024747, loss_ce: 0.009457
2022-01-14 01:00:11,650 iteration 3920 : loss : 0.023745, loss_ce: 0.010584
2022-01-14 01:00:13,081 iteration 3921 : loss : 0.031477, loss_ce: 0.010575
2022-01-14 01:00:14,439 iteration 3922 : loss : 0.017708, loss_ce: 0.007660
2022-01-14 01:00:15,835 iteration 3923 : loss : 0.030950, loss_ce: 0.012905
2022-01-14 01:00:17,247 iteration 3924 : loss : 0.037142, loss_ce: 0.017692
2022-01-14 01:00:18,783 iteration 3925 : loss : 0.031691, loss_ce: 0.013457
2022-01-14 01:00:20,196 iteration 3926 : loss : 0.039409, loss_ce: 0.011098
2022-01-14 01:00:21,610 iteration 3927 : loss : 0.027085, loss_ce: 0.010066
 58%|███████████████▌           | 231/400 [1:40:35<1:14:53, 26.59s/it]2022-01-14 01:00:23,078 iteration 3928 : loss : 0.023749, loss_ce: 0.009541
2022-01-14 01:00:24,570 iteration 3929 : loss : 0.027997, loss_ce: 0.012017
2022-01-14 01:00:26,115 iteration 3930 : loss : 0.057312, loss_ce: 0.022628
2022-01-14 01:00:27,534 iteration 3931 : loss : 0.026167, loss_ce: 0.011999
2022-01-14 01:00:29,004 iteration 3932 : loss : 0.024633, loss_ce: 0.007361
2022-01-14 01:00:30,377 iteration 3933 : loss : 0.039357, loss_ce: 0.010877
2022-01-14 01:00:31,772 iteration 3934 : loss : 0.032275, loss_ce: 0.010207
2022-01-14 01:00:33,233 iteration 3935 : loss : 0.030099, loss_ce: 0.011553
2022-01-14 01:00:34,611 iteration 3936 : loss : 0.020162, loss_ce: 0.008413
2022-01-14 01:00:36,015 iteration 3937 : loss : 0.026627, loss_ce: 0.009688
2022-01-14 01:00:37,380 iteration 3938 : loss : 0.035592, loss_ce: 0.018112
2022-01-14 01:00:38,861 iteration 3939 : loss : 0.031830, loss_ce: 0.011744
2022-01-14 01:00:40,247 iteration 3940 : loss : 0.020652, loss_ce: 0.005558
2022-01-14 01:00:41,637 iteration 3941 : loss : 0.023818, loss_ce: 0.010828
2022-01-14 01:00:43,019 iteration 3942 : loss : 0.033938, loss_ce: 0.014754
2022-01-14 01:00:44,462 iteration 3943 : loss : 0.024805, loss_ce: 0.011214
2022-01-14 01:00:45,872 iteration 3944 : loss : 0.023099, loss_ce: 0.006742
 58%|███████████████▋           | 232/400 [1:40:59<1:12:29, 25.89s/it]2022-01-14 01:00:47,316 iteration 3945 : loss : 0.018187, loss_ce: 0.008138
2022-01-14 01:00:48,660 iteration 3946 : loss : 0.016111, loss_ce: 0.006039
2022-01-14 01:00:50,043 iteration 3947 : loss : 0.022709, loss_ce: 0.007916
2022-01-14 01:00:51,421 iteration 3948 : loss : 0.023834, loss_ce: 0.009591
2022-01-14 01:00:52,842 iteration 3949 : loss : 0.045387, loss_ce: 0.021791
2022-01-14 01:00:54,231 iteration 3950 : loss : 0.022381, loss_ce: 0.008267
2022-01-14 01:00:55,675 iteration 3951 : loss : 0.048875, loss_ce: 0.020478
2022-01-14 01:00:57,061 iteration 3952 : loss : 0.020734, loss_ce: 0.009109
2022-01-14 01:00:58,449 iteration 3953 : loss : 0.021238, loss_ce: 0.006537
2022-01-14 01:00:59,905 iteration 3954 : loss : 0.028149, loss_ce: 0.010904
2022-01-14 01:01:01,320 iteration 3955 : loss : 0.028623, loss_ce: 0.010071
2022-01-14 01:01:02,699 iteration 3956 : loss : 0.032874, loss_ce: 0.013755
2022-01-14 01:01:04,090 iteration 3957 : loss : 0.024430, loss_ce: 0.010615
2022-01-14 01:01:05,570 iteration 3958 : loss : 0.032516, loss_ce: 0.013648
2022-01-14 01:01:06,963 iteration 3959 : loss : 0.019260, loss_ce: 0.005841
2022-01-14 01:01:08,409 iteration 3960 : loss : 0.022228, loss_ce: 0.005168
2022-01-14 01:01:09,865 iteration 3961 : loss : 0.019552, loss_ce: 0.007142
 58%|███████████████▋           | 233/400 [1:41:23<1:10:28, 25.32s/it]2022-01-14 01:01:11,479 iteration 3962 : loss : 0.048488, loss_ce: 0.021016
2022-01-14 01:01:12,816 iteration 3963 : loss : 0.024102, loss_ce: 0.010347
2022-01-14 01:01:14,404 iteration 3964 : loss : 0.026511, loss_ce: 0.010383
2022-01-14 01:01:15,895 iteration 3965 : loss : 0.027700, loss_ce: 0.008527
2022-01-14 01:01:17,285 iteration 3966 : loss : 0.020848, loss_ce: 0.007882
2022-01-14 01:01:18,694 iteration 3967 : loss : 0.031110, loss_ce: 0.008469
2022-01-14 01:01:20,176 iteration 3968 : loss : 0.026270, loss_ce: 0.010027
2022-01-14 01:01:21,646 iteration 3969 : loss : 0.030682, loss_ce: 0.015519
2022-01-14 01:01:23,142 iteration 3970 : loss : 0.031874, loss_ce: 0.017122
2022-01-14 01:01:24,509 iteration 3971 : loss : 0.021046, loss_ce: 0.007176
2022-01-14 01:01:25,908 iteration 3972 : loss : 0.026326, loss_ce: 0.010125
2022-01-14 01:01:27,323 iteration 3973 : loss : 0.027535, loss_ce: 0.010216
2022-01-14 01:01:28,805 iteration 3974 : loss : 0.041013, loss_ce: 0.019322
2022-01-14 01:01:30,302 iteration 3975 : loss : 0.021816, loss_ce: 0.008483
2022-01-14 01:01:31,794 iteration 3976 : loss : 0.033211, loss_ce: 0.018445
2022-01-14 01:01:33,190 iteration 3977 : loss : 0.029406, loss_ce: 0.010748
2022-01-14 01:01:34,630 iteration 3978 : loss : 0.022429, loss_ce: 0.009705
 58%|███████████████▊           | 234/400 [1:41:48<1:09:35, 25.16s/it]2022-01-14 01:01:36,095 iteration 3979 : loss : 0.032861, loss_ce: 0.011261
2022-01-14 01:01:37,530 iteration 3980 : loss : 0.026188, loss_ce: 0.012975
2022-01-14 01:01:38,900 iteration 3981 : loss : 0.022834, loss_ce: 0.008477
2022-01-14 01:01:40,431 iteration 3982 : loss : 0.044236, loss_ce: 0.019117
2022-01-14 01:01:41,848 iteration 3983 : loss : 0.033271, loss_ce: 0.008258
2022-01-14 01:01:43,294 iteration 3984 : loss : 0.024523, loss_ce: 0.009553
2022-01-14 01:01:44,699 iteration 3985 : loss : 0.025696, loss_ce: 0.009077
2022-01-14 01:01:46,075 iteration 3986 : loss : 0.020235, loss_ce: 0.008229
2022-01-14 01:01:47,444 iteration 3987 : loss : 0.019619, loss_ce: 0.008682
2022-01-14 01:01:48,893 iteration 3988 : loss : 0.025652, loss_ce: 0.011515
2022-01-14 01:01:50,316 iteration 3989 : loss : 0.038170, loss_ce: 0.016050
2022-01-14 01:01:51,704 iteration 3990 : loss : 0.021642, loss_ce: 0.008476
2022-01-14 01:01:53,134 iteration 3991 : loss : 0.037267, loss_ce: 0.015285
2022-01-14 01:01:54,663 iteration 3992 : loss : 0.046650, loss_ce: 0.013987
2022-01-14 01:01:56,062 iteration 3993 : loss : 0.030409, loss_ce: 0.016713
2022-01-14 01:01:57,478 iteration 3994 : loss : 0.020597, loss_ce: 0.008091
2022-01-14 01:01:57,478 Training Data Eval:
2022-01-14 01:02:04,638   Average segmentation loss on training set: 0.0157
2022-01-14 01:02:04,639 Validation Data Eval:
2022-01-14 01:02:07,132   Average segmentation loss on validation set: 0.0834
2022-01-14 01:02:08,534 iteration 3995 : loss : 0.025779, loss_ce: 0.007643
 59%|███████████████▊           | 235/400 [1:42:21<1:16:23, 27.78s/it]2022-01-14 01:02:10,077 iteration 3996 : loss : 0.033725, loss_ce: 0.020750
2022-01-14 01:02:11,531 iteration 3997 : loss : 0.022110, loss_ce: 0.007866
2022-01-14 01:02:12,919 iteration 3998 : loss : 0.025514, loss_ce: 0.009988
2022-01-14 01:02:14,381 iteration 3999 : loss : 0.023761, loss_ce: 0.007731
2022-01-14 01:02:15,795 iteration 4000 : loss : 0.023015, loss_ce: 0.010308
2022-01-14 01:02:17,301 iteration 4001 : loss : 0.030300, loss_ce: 0.009747
2022-01-14 01:02:18,717 iteration 4002 : loss : 0.018593, loss_ce: 0.009389
2022-01-14 01:02:20,112 iteration 4003 : loss : 0.028832, loss_ce: 0.011088
2022-01-14 01:02:21,499 iteration 4004 : loss : 0.027752, loss_ce: 0.009313
2022-01-14 01:02:22,921 iteration 4005 : loss : 0.037598, loss_ce: 0.017590
2022-01-14 01:02:24,418 iteration 4006 : loss : 0.028035, loss_ce: 0.009815
2022-01-14 01:02:25,795 iteration 4007 : loss : 0.019210, loss_ce: 0.007408
2022-01-14 01:02:27,216 iteration 4008 : loss : 0.023722, loss_ce: 0.007718
2022-01-14 01:02:28,602 iteration 4009 : loss : 0.022292, loss_ce: 0.008383
2022-01-14 01:02:29,932 iteration 4010 : loss : 0.017128, loss_ce: 0.006151
2022-01-14 01:02:31,390 iteration 4011 : loss : 0.034218, loss_ce: 0.010140
2022-01-14 01:02:32,829 iteration 4012 : loss : 0.030982, loss_ce: 0.013292
 59%|███████████████▉           | 236/400 [1:42:46<1:13:04, 26.73s/it]2022-01-14 01:02:34,287 iteration 4013 : loss : 0.027802, loss_ce: 0.008236
2022-01-14 01:02:35,733 iteration 4014 : loss : 0.027284, loss_ce: 0.007738
2022-01-14 01:02:37,101 iteration 4015 : loss : 0.027134, loss_ce: 0.014209
2022-01-14 01:02:38,538 iteration 4016 : loss : 0.035745, loss_ce: 0.012598
2022-01-14 01:02:39,898 iteration 4017 : loss : 0.024361, loss_ce: 0.009740
2022-01-14 01:02:41,396 iteration 4018 : loss : 0.029291, loss_ce: 0.009733
2022-01-14 01:02:42,856 iteration 4019 : loss : 0.034597, loss_ce: 0.015993
2022-01-14 01:02:44,238 iteration 4020 : loss : 0.022307, loss_ce: 0.007602
2022-01-14 01:02:45,658 iteration 4021 : loss : 0.032200, loss_ce: 0.010663
2022-01-14 01:02:47,053 iteration 4022 : loss : 0.033712, loss_ce: 0.011374
2022-01-14 01:02:48,481 iteration 4023 : loss : 0.029273, loss_ce: 0.014502
2022-01-14 01:02:49,899 iteration 4024 : loss : 0.038373, loss_ce: 0.011200
2022-01-14 01:02:51,276 iteration 4025 : loss : 0.033821, loss_ce: 0.013383
2022-01-14 01:02:52,670 iteration 4026 : loss : 0.026603, loss_ce: 0.015065
2022-01-14 01:02:54,049 iteration 4027 : loss : 0.021162, loss_ce: 0.007957
2022-01-14 01:02:55,438 iteration 4028 : loss : 0.021521, loss_ce: 0.005971
2022-01-14 01:02:56,874 iteration 4029 : loss : 0.026139, loss_ce: 0.010038
 59%|███████████████▉           | 237/400 [1:43:10<1:10:25, 25.92s/it]2022-01-14 01:02:58,350 iteration 4030 : loss : 0.025478, loss_ce: 0.010375
2022-01-14 01:02:59,743 iteration 4031 : loss : 0.025999, loss_ce: 0.010445
2022-01-14 01:03:01,195 iteration 4032 : loss : 0.021264, loss_ce: 0.007540
2022-01-14 01:03:02,691 iteration 4033 : loss : 0.028312, loss_ce: 0.008336
2022-01-14 01:03:04,078 iteration 4034 : loss : 0.026695, loss_ce: 0.010829
2022-01-14 01:03:05,492 iteration 4035 : loss : 0.023504, loss_ce: 0.008626
2022-01-14 01:03:06,884 iteration 4036 : loss : 0.018478, loss_ce: 0.006401
2022-01-14 01:03:08,335 iteration 4037 : loss : 0.025216, loss_ce: 0.008678
2022-01-14 01:03:09,743 iteration 4038 : loss : 0.028068, loss_ce: 0.016035
2022-01-14 01:03:11,049 iteration 4039 : loss : 0.019370, loss_ce: 0.009239
2022-01-14 01:03:12,437 iteration 4040 : loss : 0.031001, loss_ce: 0.007509
2022-01-14 01:03:13,945 iteration 4041 : loss : 0.043473, loss_ce: 0.020989
2022-01-14 01:03:15,285 iteration 4042 : loss : 0.020544, loss_ce: 0.009255
2022-01-14 01:03:16,700 iteration 4043 : loss : 0.019334, loss_ce: 0.007150
2022-01-14 01:03:18,123 iteration 4044 : loss : 0.034080, loss_ce: 0.012172
2022-01-14 01:03:19,501 iteration 4045 : loss : 0.026399, loss_ce: 0.009617
2022-01-14 01:03:20,964 iteration 4046 : loss : 0.028647, loss_ce: 0.008386
 60%|████████████████           | 238/400 [1:43:34<1:08:31, 25.38s/it]2022-01-14 01:03:22,455 iteration 4047 : loss : 0.018429, loss_ce: 0.007857
2022-01-14 01:03:23,890 iteration 4048 : loss : 0.017401, loss_ce: 0.005289
2022-01-14 01:03:25,414 iteration 4049 : loss : 0.029737, loss_ce: 0.010924
2022-01-14 01:03:26,866 iteration 4050 : loss : 0.026464, loss_ce: 0.007692
2022-01-14 01:03:28,312 iteration 4051 : loss : 0.015838, loss_ce: 0.005122
2022-01-14 01:03:29,739 iteration 4052 : loss : 0.023083, loss_ce: 0.006978
2022-01-14 01:03:31,162 iteration 4053 : loss : 0.022841, loss_ce: 0.011209
2022-01-14 01:03:32,558 iteration 4054 : loss : 0.030005, loss_ce: 0.011207
2022-01-14 01:03:34,078 iteration 4055 : loss : 0.022946, loss_ce: 0.006798
2022-01-14 01:03:35,524 iteration 4056 : loss : 0.027236, loss_ce: 0.008426
2022-01-14 01:03:36,988 iteration 4057 : loss : 0.033834, loss_ce: 0.017040
2022-01-14 01:03:38,318 iteration 4058 : loss : 0.020929, loss_ce: 0.009296
2022-01-14 01:03:39,791 iteration 4059 : loss : 0.021905, loss_ce: 0.009403
2022-01-14 01:03:41,223 iteration 4060 : loss : 0.024559, loss_ce: 0.008565
2022-01-14 01:03:42,624 iteration 4061 : loss : 0.053640, loss_ce: 0.009346
2022-01-14 01:03:44,015 iteration 4062 : loss : 0.024152, loss_ce: 0.009956
2022-01-14 01:03:45,523 iteration 4063 : loss : 0.043674, loss_ce: 0.013794
 60%|████████████████▏          | 239/400 [1:43:58<1:07:26, 25.13s/it]2022-01-14 01:03:46,987 iteration 4064 : loss : 0.025862, loss_ce: 0.008335
2022-01-14 01:03:48,382 iteration 4065 : loss : 0.024572, loss_ce: 0.008362
2022-01-14 01:03:49,700 iteration 4066 : loss : 0.018303, loss_ce: 0.006008
2022-01-14 01:03:51,054 iteration 4067 : loss : 0.040799, loss_ce: 0.007461
2022-01-14 01:03:52,473 iteration 4068 : loss : 0.027102, loss_ce: 0.009830
2022-01-14 01:03:53,916 iteration 4069 : loss : 0.024336, loss_ce: 0.008141
2022-01-14 01:03:55,356 iteration 4070 : loss : 0.025411, loss_ce: 0.013496
2022-01-14 01:03:56,698 iteration 4071 : loss : 0.020016, loss_ce: 0.008686
2022-01-14 01:03:58,094 iteration 4072 : loss : 0.022310, loss_ce: 0.009510
2022-01-14 01:03:59,516 iteration 4073 : loss : 0.038046, loss_ce: 0.017973
2022-01-14 01:04:00,874 iteration 4074 : loss : 0.033342, loss_ce: 0.010948
2022-01-14 01:04:02,317 iteration 4075 : loss : 0.043248, loss_ce: 0.016092
2022-01-14 01:04:03,758 iteration 4076 : loss : 0.023577, loss_ce: 0.007857
2022-01-14 01:04:05,188 iteration 4077 : loss : 0.021254, loss_ce: 0.009288
2022-01-14 01:04:06,664 iteration 4078 : loss : 0.027752, loss_ce: 0.008052
2022-01-14 01:04:08,093 iteration 4079 : loss : 0.022799, loss_ce: 0.007900
2022-01-14 01:04:08,093 Training Data Eval:
2022-01-14 01:04:15,048   Average segmentation loss on training set: 0.0151
2022-01-14 01:04:15,048 Validation Data Eval:
2022-01-14 01:04:17,580   Average segmentation loss on validation set: 0.0646
2022-01-14 01:04:23,326 Found new lowest validation loss at iteration 4079! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_1HEAD_best_val_loss_seed2.pth
2022-01-14 01:04:24,780 iteration 4080 : loss : 0.026479, loss_ce: 0.008941
 60%|████████████████▏          | 240/400 [1:44:38<1:18:18, 29.37s/it]2022-01-14 01:04:26,224 iteration 4081 : loss : 0.033864, loss_ce: 0.016851
2022-01-14 01:04:27,715 iteration 4082 : loss : 0.026935, loss_ce: 0.010506
2022-01-14 01:04:29,038 iteration 4083 : loss : 0.038712, loss_ce: 0.023479
2022-01-14 01:04:30,396 iteration 4084 : loss : 0.029179, loss_ce: 0.008920
2022-01-14 01:04:31,849 iteration 4085 : loss : 0.029373, loss_ce: 0.008237
2022-01-14 01:04:33,215 iteration 4086 : loss : 0.023197, loss_ce: 0.008209
2022-01-14 01:04:34,606 iteration 4087 : loss : 0.022693, loss_ce: 0.007486
2022-01-14 01:04:36,029 iteration 4088 : loss : 0.026450, loss_ce: 0.013114
2022-01-14 01:04:37,448 iteration 4089 : loss : 0.035624, loss_ce: 0.014086
2022-01-14 01:04:38,861 iteration 4090 : loss : 0.025501, loss_ce: 0.010974
2022-01-14 01:04:40,304 iteration 4091 : loss : 0.034028, loss_ce: 0.012737
2022-01-14 01:04:41,649 iteration 4092 : loss : 0.025517, loss_ce: 0.006849
2022-01-14 01:04:43,025 iteration 4093 : loss : 0.024079, loss_ce: 0.009869
2022-01-14 01:04:44,487 iteration 4094 : loss : 0.036859, loss_ce: 0.010102
2022-01-14 01:04:45,889 iteration 4095 : loss : 0.025200, loss_ce: 0.007157
2022-01-14 01:04:47,336 iteration 4096 : loss : 0.030790, loss_ce: 0.012098
2022-01-14 01:04:48,781 iteration 4097 : loss : 0.038914, loss_ce: 0.014436
 60%|████████████████▎          | 241/400 [1:45:02<1:13:33, 27.76s/it]2022-01-14 01:04:50,270 iteration 4098 : loss : 0.019900, loss_ce: 0.007816
2022-01-14 01:04:51,670 iteration 4099 : loss : 0.030631, loss_ce: 0.010266
2022-01-14 01:04:53,024 iteration 4100 : loss : 0.022935, loss_ce: 0.009942
2022-01-14 01:04:54,466 iteration 4101 : loss : 0.021745, loss_ce: 0.010047
2022-01-14 01:04:55,941 iteration 4102 : loss : 0.039347, loss_ce: 0.015572
2022-01-14 01:04:57,275 iteration 4103 : loss : 0.023791, loss_ce: 0.009577
2022-01-14 01:04:58,697 iteration 4104 : loss : 0.030701, loss_ce: 0.013242
2022-01-14 01:05:00,141 iteration 4105 : loss : 0.026088, loss_ce: 0.008802
2022-01-14 01:05:01,657 iteration 4106 : loss : 0.028997, loss_ce: 0.010399
2022-01-14 01:05:03,090 iteration 4107 : loss : 0.026240, loss_ce: 0.010678
2022-01-14 01:05:04,547 iteration 4108 : loss : 0.034672, loss_ce: 0.015077
2022-01-14 01:05:05,972 iteration 4109 : loss : 0.043497, loss_ce: 0.011128
2022-01-14 01:05:07,427 iteration 4110 : loss : 0.025536, loss_ce: 0.008135
2022-01-14 01:05:08,855 iteration 4111 : loss : 0.024389, loss_ce: 0.007059
2022-01-14 01:05:10,154 iteration 4112 : loss : 0.015802, loss_ce: 0.006255
2022-01-14 01:05:11,634 iteration 4113 : loss : 0.032345, loss_ce: 0.013414
2022-01-14 01:05:13,041 iteration 4114 : loss : 0.030532, loss_ce: 0.011998
 60%|████████████████▎          | 242/400 [1:45:26<1:10:20, 26.71s/it]2022-01-14 01:05:14,490 iteration 4115 : loss : 0.022682, loss_ce: 0.005974
2022-01-14 01:05:15,870 iteration 4116 : loss : 0.023483, loss_ce: 0.010396
2022-01-14 01:05:17,214 iteration 4117 : loss : 0.020268, loss_ce: 0.009721
2022-01-14 01:05:18,597 iteration 4118 : loss : 0.024021, loss_ce: 0.006994
2022-01-14 01:05:19,904 iteration 4119 : loss : 0.018728, loss_ce: 0.007127
2022-01-14 01:05:21,411 iteration 4120 : loss : 0.026771, loss_ce: 0.008791
2022-01-14 01:05:22,812 iteration 4121 : loss : 0.019919, loss_ce: 0.008160
2022-01-14 01:05:24,249 iteration 4122 : loss : 0.035066, loss_ce: 0.010256
2022-01-14 01:05:25,674 iteration 4123 : loss : 0.022451, loss_ce: 0.009204
2022-01-14 01:05:27,008 iteration 4124 : loss : 0.019833, loss_ce: 0.007388
2022-01-14 01:05:28,445 iteration 4125 : loss : 0.030268, loss_ce: 0.010199
2022-01-14 01:05:29,962 iteration 4126 : loss : 0.024683, loss_ce: 0.011210
2022-01-14 01:05:31,441 iteration 4127 : loss : 0.024981, loss_ce: 0.011040
2022-01-14 01:05:32,811 iteration 4128 : loss : 0.025932, loss_ce: 0.011137
2022-01-14 01:05:34,350 iteration 4129 : loss : 0.043912, loss_ce: 0.013158
2022-01-14 01:05:35,803 iteration 4130 : loss : 0.024423, loss_ce: 0.007752
2022-01-14 01:05:37,203 iteration 4131 : loss : 0.025570, loss_ce: 0.011328
 61%|████████████████▍          | 243/400 [1:45:50<1:07:53, 25.94s/it]2022-01-14 01:05:38,706 iteration 4132 : loss : 0.038198, loss_ce: 0.012874
2022-01-14 01:05:40,054 iteration 4133 : loss : 0.022225, loss_ce: 0.010966
2022-01-14 01:05:41,530 iteration 4134 : loss : 0.015904, loss_ce: 0.006619
2022-01-14 01:05:42,939 iteration 4135 : loss : 0.033943, loss_ce: 0.011632
2022-01-14 01:05:44,340 iteration 4136 : loss : 0.019141, loss_ce: 0.005521
2022-01-14 01:05:45,759 iteration 4137 : loss : 0.031691, loss_ce: 0.015511
2022-01-14 01:05:47,186 iteration 4138 : loss : 0.030143, loss_ce: 0.015237
2022-01-14 01:05:48,637 iteration 4139 : loss : 0.035357, loss_ce: 0.007835
2022-01-14 01:05:50,094 iteration 4140 : loss : 0.036482, loss_ce: 0.012087
2022-01-14 01:05:51,521 iteration 4141 : loss : 0.023085, loss_ce: 0.005810
2022-01-14 01:05:52,922 iteration 4142 : loss : 0.034497, loss_ce: 0.013082
2022-01-14 01:05:54,297 iteration 4143 : loss : 0.040778, loss_ce: 0.014871
2022-01-14 01:05:55,729 iteration 4144 : loss : 0.026777, loss_ce: 0.009178
2022-01-14 01:05:57,136 iteration 4145 : loss : 0.032070, loss_ce: 0.012089
2022-01-14 01:05:58,476 iteration 4146 : loss : 0.023543, loss_ce: 0.006483
2022-01-14 01:05:59,862 iteration 4147 : loss : 0.023240, loss_ce: 0.008540
2022-01-14 01:06:01,294 iteration 4148 : loss : 0.039755, loss_ce: 0.014351
 61%|████████████████▍          | 244/400 [1:46:14<1:06:00, 25.39s/it]2022-01-14 01:06:02,775 iteration 4149 : loss : 0.032183, loss_ce: 0.012142
2022-01-14 01:06:04,176 iteration 4150 : loss : 0.025469, loss_ce: 0.008776
2022-01-14 01:06:05,569 iteration 4151 : loss : 0.021400, loss_ce: 0.008742
2022-01-14 01:06:07,045 iteration 4152 : loss : 0.022274, loss_ce: 0.008185
2022-01-14 01:06:08,503 iteration 4153 : loss : 0.027742, loss_ce: 0.012213
2022-01-14 01:06:09,842 iteration 4154 : loss : 0.020300, loss_ce: 0.008093
2022-01-14 01:06:11,199 iteration 4155 : loss : 0.017056, loss_ce: 0.007638
2022-01-14 01:06:12,607 iteration 4156 : loss : 0.026086, loss_ce: 0.008991
2022-01-14 01:06:14,012 iteration 4157 : loss : 0.019388, loss_ce: 0.007402
2022-01-14 01:06:15,408 iteration 4158 : loss : 0.018819, loss_ce: 0.006932
2022-01-14 01:06:16,902 iteration 4159 : loss : 0.023274, loss_ce: 0.011863
2022-01-14 01:06:18,328 iteration 4160 : loss : 0.026562, loss_ce: 0.010152
2022-01-14 01:06:19,724 iteration 4161 : loss : 0.020893, loss_ce: 0.006398
2022-01-14 01:06:21,158 iteration 4162 : loss : 0.026804, loss_ce: 0.009818
2022-01-14 01:06:22,589 iteration 4163 : loss : 0.022631, loss_ce: 0.008158
2022-01-14 01:06:23,990 iteration 4164 : loss : 0.021436, loss_ce: 0.006011
2022-01-14 01:06:23,990 Training Data Eval:
2022-01-14 01:06:31,098   Average segmentation loss on training set: 0.0144
2022-01-14 01:06:31,098 Validation Data Eval:
2022-01-14 01:06:33,548   Average segmentation loss on validation set: 0.0754
2022-01-14 01:06:35,000 iteration 4165 : loss : 0.024628, loss_ce: 0.008369
 61%|████████████████▌          | 245/400 [1:46:48<1:12:02, 27.89s/it]2022-01-14 01:06:36,512 iteration 4166 : loss : 0.032005, loss_ce: 0.008097
2022-01-14 01:06:37,896 iteration 4167 : loss : 0.018588, loss_ce: 0.007737
2022-01-14 01:06:39,245 iteration 4168 : loss : 0.018229, loss_ce: 0.005337
2022-01-14 01:06:40,643 iteration 4169 : loss : 0.020813, loss_ce: 0.008817
2022-01-14 01:06:42,146 iteration 4170 : loss : 0.037722, loss_ce: 0.013449
2022-01-14 01:06:43,688 iteration 4171 : loss : 0.035546, loss_ce: 0.013852
2022-01-14 01:06:45,053 iteration 4172 : loss : 0.019893, loss_ce: 0.004557
2022-01-14 01:06:46,471 iteration 4173 : loss : 0.025376, loss_ce: 0.009026
2022-01-14 01:06:47,914 iteration 4174 : loss : 0.031683, loss_ce: 0.013875
2022-01-14 01:06:49,360 iteration 4175 : loss : 0.023036, loss_ce: 0.008059
2022-01-14 01:06:50,787 iteration 4176 : loss : 0.029408, loss_ce: 0.011947
2022-01-14 01:06:52,226 iteration 4177 : loss : 0.026191, loss_ce: 0.008432
2022-01-14 01:06:53,623 iteration 4178 : loss : 0.025685, loss_ce: 0.010912
2022-01-14 01:06:55,112 iteration 4179 : loss : 0.023254, loss_ce: 0.009320
2022-01-14 01:06:56,513 iteration 4180 : loss : 0.039462, loss_ce: 0.011880
2022-01-14 01:06:57,817 iteration 4181 : loss : 0.042772, loss_ce: 0.012176
2022-01-14 01:06:59,266 iteration 4182 : loss : 0.027132, loss_ce: 0.012148
 62%|████████████████▌          | 246/400 [1:47:12<1:08:46, 26.80s/it]2022-01-14 01:07:00,728 iteration 4183 : loss : 0.032427, loss_ce: 0.011895
2022-01-14 01:07:02,142 iteration 4184 : loss : 0.022395, loss_ce: 0.008253
2022-01-14 01:07:03,563 iteration 4185 : loss : 0.021805, loss_ce: 0.007446
2022-01-14 01:07:04,952 iteration 4186 : loss : 0.021065, loss_ce: 0.007711
2022-01-14 01:07:06,444 iteration 4187 : loss : 0.043325, loss_ce: 0.015144
2022-01-14 01:07:07,912 iteration 4188 : loss : 0.075533, loss_ce: 0.045538
2022-01-14 01:07:09,346 iteration 4189 : loss : 0.025797, loss_ce: 0.007684
2022-01-14 01:07:10,836 iteration 4190 : loss : 0.070680, loss_ce: 0.024156
2022-01-14 01:07:12,220 iteration 4191 : loss : 0.033306, loss_ce: 0.011516
2022-01-14 01:07:13,646 iteration 4192 : loss : 0.035290, loss_ce: 0.011090
2022-01-14 01:07:15,066 iteration 4193 : loss : 0.026266, loss_ce: 0.009540
2022-01-14 01:07:16,500 iteration 4194 : loss : 0.048961, loss_ce: 0.024263
2022-01-14 01:07:18,073 iteration 4195 : loss : 0.094014, loss_ce: 0.037609
2022-01-14 01:07:19,439 iteration 4196 : loss : 0.030273, loss_ce: 0.015454
2022-01-14 01:07:20,904 iteration 4197 : loss : 0.040171, loss_ce: 0.016420
2022-01-14 01:07:22,335 iteration 4198 : loss : 0.048777, loss_ce: 0.022790
2022-01-14 01:07:23,678 iteration 4199 : loss : 0.041496, loss_ce: 0.014921
 62%|████████████████▋          | 247/400 [1:47:37<1:06:30, 26.08s/it]2022-01-14 01:07:25,115 iteration 4200 : loss : 0.032947, loss_ce: 0.010636
2022-01-14 01:07:26,550 iteration 4201 : loss : 0.044238, loss_ce: 0.016350
2022-01-14 01:07:27,890 iteration 4202 : loss : 0.023745, loss_ce: 0.010006
2022-01-14 01:07:29,257 iteration 4203 : loss : 0.024224, loss_ce: 0.009954
2022-01-14 01:07:30,657 iteration 4204 : loss : 0.051467, loss_ce: 0.024514
2022-01-14 01:07:32,020 iteration 4205 : loss : 0.029583, loss_ce: 0.011764
2022-01-14 01:07:33,331 iteration 4206 : loss : 0.026849, loss_ce: 0.010007
2022-01-14 01:07:34,694 iteration 4207 : loss : 0.023895, loss_ce: 0.010357
2022-01-14 01:07:36,068 iteration 4208 : loss : 0.028091, loss_ce: 0.010952
2022-01-14 01:07:37,567 iteration 4209 : loss : 0.031785, loss_ce: 0.010259
2022-01-14 01:07:39,053 iteration 4210 : loss : 0.037910, loss_ce: 0.016496
2022-01-14 01:07:40,320 iteration 4211 : loss : 0.019878, loss_ce: 0.008217
2022-01-14 01:07:41,709 iteration 4212 : loss : 0.028216, loss_ce: 0.012616
2022-01-14 01:07:43,119 iteration 4213 : loss : 0.027143, loss_ce: 0.012620
2022-01-14 01:07:44,564 iteration 4214 : loss : 0.034476, loss_ce: 0.011763
2022-01-14 01:07:45,945 iteration 4215 : loss : 0.029762, loss_ce: 0.012618
2022-01-14 01:07:47,442 iteration 4216 : loss : 0.040057, loss_ce: 0.014108
 62%|████████████████▋          | 248/400 [1:48:00<1:04:18, 25.39s/it]2022-01-14 01:07:48,989 iteration 4217 : loss : 0.025210, loss_ce: 0.011229
2022-01-14 01:07:50,322 iteration 4218 : loss : 0.018872, loss_ce: 0.009281
2022-01-14 01:07:51,660 iteration 4219 : loss : 0.023012, loss_ce: 0.009003
2022-01-14 01:07:53,168 iteration 4220 : loss : 0.041968, loss_ce: 0.017156
2022-01-14 01:07:54,613 iteration 4221 : loss : 0.027926, loss_ce: 0.009491
2022-01-14 01:07:56,048 iteration 4222 : loss : 0.025951, loss_ce: 0.009959
2022-01-14 01:07:57,467 iteration 4223 : loss : 0.031731, loss_ce: 0.012802
2022-01-14 01:07:58,862 iteration 4224 : loss : 0.033851, loss_ce: 0.012104
2022-01-14 01:08:00,230 iteration 4225 : loss : 0.021928, loss_ce: 0.008008
2022-01-14 01:08:01,621 iteration 4226 : loss : 0.024295, loss_ce: 0.008099
2022-01-14 01:08:03,115 iteration 4227 : loss : 0.047511, loss_ce: 0.015546
2022-01-14 01:08:04,514 iteration 4228 : loss : 0.021859, loss_ce: 0.008296
2022-01-14 01:08:05,965 iteration 4229 : loss : 0.026300, loss_ce: 0.010650
2022-01-14 01:08:07,371 iteration 4230 : loss : 0.032104, loss_ce: 0.016785
2022-01-14 01:08:08,746 iteration 4231 : loss : 0.029306, loss_ce: 0.012542
2022-01-14 01:08:10,120 iteration 4232 : loss : 0.034305, loss_ce: 0.014163
2022-01-14 01:08:11,513 iteration 4233 : loss : 0.025658, loss_ce: 0.011631
 62%|████████████████▊          | 249/400 [1:48:24<1:02:53, 24.99s/it]2022-01-14 01:08:13,045 iteration 4234 : loss : 0.035339, loss_ce: 0.017933
2022-01-14 01:08:14,432 iteration 4235 : loss : 0.033182, loss_ce: 0.011566
2022-01-14 01:08:15,777 iteration 4236 : loss : 0.020180, loss_ce: 0.008287
2022-01-14 01:08:17,132 iteration 4237 : loss : 0.023471, loss_ce: 0.010714
2022-01-14 01:08:18,508 iteration 4238 : loss : 0.021704, loss_ce: 0.007704
2022-01-14 01:08:19,959 iteration 4239 : loss : 0.022568, loss_ce: 0.008513
2022-01-14 01:08:21,376 iteration 4240 : loss : 0.041573, loss_ce: 0.013958
2022-01-14 01:08:22,771 iteration 4241 : loss : 0.046933, loss_ce: 0.022548
2022-01-14 01:08:24,062 iteration 4242 : loss : 0.021802, loss_ce: 0.008127
2022-01-14 01:08:25,475 iteration 4243 : loss : 0.037337, loss_ce: 0.015565
2022-01-14 01:08:26,820 iteration 4244 : loss : 0.023172, loss_ce: 0.007191
2022-01-14 01:08:28,212 iteration 4245 : loss : 0.026678, loss_ce: 0.011332
2022-01-14 01:08:29,570 iteration 4246 : loss : 0.021988, loss_ce: 0.007297
2022-01-14 01:08:30,953 iteration 4247 : loss : 0.022173, loss_ce: 0.006113
2022-01-14 01:08:32,273 iteration 4248 : loss : 0.033739, loss_ce: 0.015340
2022-01-14 01:08:33,723 iteration 4249 : loss : 0.024600, loss_ce: 0.009483
2022-01-14 01:08:33,723 Training Data Eval:
2022-01-14 01:08:40,810   Average segmentation loss on training set: 0.0170
2022-01-14 01:08:40,810 Validation Data Eval:
2022-01-14 01:08:43,320   Average segmentation loss on validation set: 0.0912
2022-01-14 01:08:44,782 iteration 4250 : loss : 0.021439, loss_ce: 0.008213
 62%|████████████████▉          | 250/400 [1:48:58<1:08:41, 27.48s/it]2022-01-14 01:08:46,293 iteration 4251 : loss : 0.024678, loss_ce: 0.008118
2022-01-14 01:08:47,695 iteration 4252 : loss : 0.025019, loss_ce: 0.006630
2022-01-14 01:08:49,118 iteration 4253 : loss : 0.018300, loss_ce: 0.008419
2022-01-14 01:08:50,560 iteration 4254 : loss : 0.022011, loss_ce: 0.008032
2022-01-14 01:08:51,980 iteration 4255 : loss : 0.034318, loss_ce: 0.009628
2022-01-14 01:08:53,345 iteration 4256 : loss : 0.041465, loss_ce: 0.017542
2022-01-14 01:08:54,763 iteration 4257 : loss : 0.029893, loss_ce: 0.014279
2022-01-14 01:08:56,235 iteration 4258 : loss : 0.035236, loss_ce: 0.014935
2022-01-14 01:08:57,568 iteration 4259 : loss : 0.019242, loss_ce: 0.006610
2022-01-14 01:08:59,008 iteration 4260 : loss : 0.028141, loss_ce: 0.008843
2022-01-14 01:09:00,356 iteration 4261 : loss : 0.017337, loss_ce: 0.005535
2022-01-14 01:09:01,746 iteration 4262 : loss : 0.020804, loss_ce: 0.009015
2022-01-14 01:09:03,178 iteration 4263 : loss : 0.031510, loss_ce: 0.013414
2022-01-14 01:09:04,560 iteration 4264 : loss : 0.035430, loss_ce: 0.018447
2022-01-14 01:09:05,862 iteration 4265 : loss : 0.017995, loss_ce: 0.007818
2022-01-14 01:09:07,281 iteration 4266 : loss : 0.026847, loss_ce: 0.008090
2022-01-14 01:09:08,708 iteration 4267 : loss : 0.035833, loss_ce: 0.013511
 63%|████████████████▉          | 251/400 [1:49:22<1:05:34, 26.41s/it]2022-01-14 01:09:10,094 iteration 4268 : loss : 0.025316, loss_ce: 0.010051
2022-01-14 01:09:11,426 iteration 4269 : loss : 0.018329, loss_ce: 0.005115
2022-01-14 01:09:12,805 iteration 4270 : loss : 0.038550, loss_ce: 0.010349
2022-01-14 01:09:14,193 iteration 4271 : loss : 0.022049, loss_ce: 0.007807
2022-01-14 01:09:15,585 iteration 4272 : loss : 0.035920, loss_ce: 0.016688
2022-01-14 01:09:16,945 iteration 4273 : loss : 0.025981, loss_ce: 0.010282
2022-01-14 01:09:18,361 iteration 4274 : loss : 0.026510, loss_ce: 0.013542
2022-01-14 01:09:19,757 iteration 4275 : loss : 0.017341, loss_ce: 0.006618
2022-01-14 01:09:21,139 iteration 4276 : loss : 0.034775, loss_ce: 0.013796
2022-01-14 01:09:22,565 iteration 4277 : loss : 0.028698, loss_ce: 0.012184
2022-01-14 01:09:23,974 iteration 4278 : loss : 0.016412, loss_ce: 0.004194
2022-01-14 01:09:25,354 iteration 4279 : loss : 0.021610, loss_ce: 0.009251
2022-01-14 01:09:26,791 iteration 4280 : loss : 0.029666, loss_ce: 0.008566
2022-01-14 01:09:28,204 iteration 4281 : loss : 0.033480, loss_ce: 0.014764
2022-01-14 01:09:29,658 iteration 4282 : loss : 0.042681, loss_ce: 0.013520
2022-01-14 01:09:31,155 iteration 4283 : loss : 0.033337, loss_ce: 0.019790
2022-01-14 01:09:32,632 iteration 4284 : loss : 0.028939, loss_ce: 0.011437
 63%|█████████████████          | 252/400 [1:49:46<1:03:18, 25.67s/it]2022-01-14 01:09:34,045 iteration 4285 : loss : 0.018478, loss_ce: 0.008613
2022-01-14 01:09:35,405 iteration 4286 : loss : 0.021502, loss_ce: 0.007717
2022-01-14 01:09:36,812 iteration 4287 : loss : 0.034843, loss_ce: 0.018209
2022-01-14 01:09:38,177 iteration 4288 : loss : 0.021989, loss_ce: 0.007659
2022-01-14 01:09:39,543 iteration 4289 : loss : 0.022853, loss_ce: 0.010578
2022-01-14 01:09:40,940 iteration 4290 : loss : 0.020944, loss_ce: 0.008783
2022-01-14 01:09:42,412 iteration 4291 : loss : 0.023104, loss_ce: 0.011101
2022-01-14 01:09:43,837 iteration 4292 : loss : 0.023671, loss_ce: 0.011554
2022-01-14 01:09:45,134 iteration 4293 : loss : 0.021161, loss_ce: 0.008207
2022-01-14 01:09:46,499 iteration 4294 : loss : 0.023497, loss_ce: 0.010336
2022-01-14 01:09:48,027 iteration 4295 : loss : 0.037445, loss_ce: 0.014551
2022-01-14 01:09:49,393 iteration 4296 : loss : 0.025429, loss_ce: 0.010379
2022-01-14 01:09:50,758 iteration 4297 : loss : 0.027088, loss_ce: 0.008941
2022-01-14 01:09:52,207 iteration 4298 : loss : 0.025417, loss_ce: 0.008572
2022-01-14 01:09:53,637 iteration 4299 : loss : 0.025792, loss_ce: 0.007734
2022-01-14 01:09:55,130 iteration 4300 : loss : 0.043047, loss_ce: 0.015401
2022-01-14 01:09:56,536 iteration 4301 : loss : 0.046549, loss_ce: 0.014297
 63%|█████████████████          | 253/400 [1:50:09<1:01:34, 25.13s/it]2022-01-14 01:09:58,082 iteration 4302 : loss : 0.033752, loss_ce: 0.013853
2022-01-14 01:09:59,420 iteration 4303 : loss : 0.022929, loss_ce: 0.010986
2022-01-14 01:10:00,824 iteration 4304 : loss : 0.029293, loss_ce: 0.011884
2022-01-14 01:10:02,247 iteration 4305 : loss : 0.026685, loss_ce: 0.007700
2022-01-14 01:10:03,640 iteration 4306 : loss : 0.020968, loss_ce: 0.006465
2022-01-14 01:10:05,112 iteration 4307 : loss : 0.027277, loss_ce: 0.009716
2022-01-14 01:10:06,506 iteration 4308 : loss : 0.022173, loss_ce: 0.008977
2022-01-14 01:10:07,938 iteration 4309 : loss : 0.035491, loss_ce: 0.013149
2022-01-14 01:10:09,276 iteration 4310 : loss : 0.019433, loss_ce: 0.006389
2022-01-14 01:10:10,773 iteration 4311 : loss : 0.032521, loss_ce: 0.013017
2022-01-14 01:10:12,148 iteration 4312 : loss : 0.030209, loss_ce: 0.014192
2022-01-14 01:10:13,604 iteration 4313 : loss : 0.026303, loss_ce: 0.011739
2022-01-14 01:10:15,031 iteration 4314 : loss : 0.042488, loss_ce: 0.013735
2022-01-14 01:10:16,394 iteration 4315 : loss : 0.021609, loss_ce: 0.007801
2022-01-14 01:10:17,771 iteration 4316 : loss : 0.022727, loss_ce: 0.008227
2022-01-14 01:10:19,175 iteration 4317 : loss : 0.021117, loss_ce: 0.009114
2022-01-14 01:10:20,663 iteration 4318 : loss : 0.034079, loss_ce: 0.013737
 64%|█████████████████▏         | 254/400 [1:50:34<1:00:25, 24.84s/it]2022-01-14 01:10:22,107 iteration 4319 : loss : 0.025457, loss_ce: 0.008934
2022-01-14 01:10:23,410 iteration 4320 : loss : 0.023569, loss_ce: 0.009627
2022-01-14 01:10:24,940 iteration 4321 : loss : 0.028267, loss_ce: 0.015820
2022-01-14 01:10:26,350 iteration 4322 : loss : 0.023168, loss_ce: 0.008132
2022-01-14 01:10:27,765 iteration 4323 : loss : 0.032332, loss_ce: 0.010129
2022-01-14 01:10:29,166 iteration 4324 : loss : 0.021597, loss_ce: 0.010330
2022-01-14 01:10:30,593 iteration 4325 : loss : 0.027117, loss_ce: 0.007889
2022-01-14 01:10:32,057 iteration 4326 : loss : 0.031907, loss_ce: 0.009584
2022-01-14 01:10:33,560 iteration 4327 : loss : 0.022222, loss_ce: 0.009517
2022-01-14 01:10:34,992 iteration 4328 : loss : 0.019102, loss_ce: 0.008026
2022-01-14 01:10:36,366 iteration 4329 : loss : 0.020548, loss_ce: 0.008198
2022-01-14 01:10:37,718 iteration 4330 : loss : 0.020067, loss_ce: 0.008664
2022-01-14 01:10:39,097 iteration 4331 : loss : 0.018906, loss_ce: 0.007669
2022-01-14 01:10:40,446 iteration 4332 : loss : 0.019400, loss_ce: 0.006763
2022-01-14 01:10:41,760 iteration 4333 : loss : 0.016208, loss_ce: 0.006619
2022-01-14 01:10:43,192 iteration 4334 : loss : 0.018223, loss_ce: 0.006484
2022-01-14 01:10:43,192 Training Data Eval:
2022-01-14 01:10:50,242   Average segmentation loss on training set: 0.0140
2022-01-14 01:10:50,243 Validation Data Eval:
2022-01-14 01:10:52,725   Average segmentation loss on validation set: 0.0709
2022-01-14 01:10:54,211 iteration 4335 : loss : 0.062618, loss_ce: 0.015954
 64%|█████████████████▏         | 255/400 [1:51:07<1:06:19, 27.45s/it]2022-01-14 01:10:55,644 iteration 4336 : loss : 0.018122, loss_ce: 0.007172
2022-01-14 01:10:57,091 iteration 4337 : loss : 0.021629, loss_ce: 0.008078
2022-01-14 01:10:58,517 iteration 4338 : loss : 0.022520, loss_ce: 0.008272
2022-01-14 01:10:59,848 iteration 4339 : loss : 0.025786, loss_ce: 0.006299
2022-01-14 01:11:01,251 iteration 4340 : loss : 0.021373, loss_ce: 0.003968
2022-01-14 01:11:02,633 iteration 4341 : loss : 0.023377, loss_ce: 0.009708
2022-01-14 01:11:04,038 iteration 4342 : loss : 0.034902, loss_ce: 0.016242
2022-01-14 01:11:05,511 iteration 4343 : loss : 0.046982, loss_ce: 0.016943
2022-01-14 01:11:06,893 iteration 4344 : loss : 0.021806, loss_ce: 0.008326
2022-01-14 01:11:08,274 iteration 4345 : loss : 0.018246, loss_ce: 0.007329
2022-01-14 01:11:09,599 iteration 4346 : loss : 0.014893, loss_ce: 0.004807
2022-01-14 01:11:11,082 iteration 4347 : loss : 0.045978, loss_ce: 0.013570
2022-01-14 01:11:12,554 iteration 4348 : loss : 0.028006, loss_ce: 0.014588
2022-01-14 01:11:13,896 iteration 4349 : loss : 0.024073, loss_ce: 0.010077
2022-01-14 01:11:15,250 iteration 4350 : loss : 0.020636, loss_ce: 0.006638
2022-01-14 01:11:16,741 iteration 4351 : loss : 0.034627, loss_ce: 0.018350
2022-01-14 01:11:18,165 iteration 4352 : loss : 0.025270, loss_ce: 0.010569
 64%|█████████████████▎         | 256/400 [1:51:31<1:03:21, 26.40s/it]2022-01-14 01:11:19,597 iteration 4353 : loss : 0.025302, loss_ce: 0.010678
2022-01-14 01:11:21,049 iteration 4354 : loss : 0.022042, loss_ce: 0.006884
2022-01-14 01:11:22,467 iteration 4355 : loss : 0.022079, loss_ce: 0.008534
2022-01-14 01:11:23,829 iteration 4356 : loss : 0.026981, loss_ce: 0.011236
2022-01-14 01:11:25,289 iteration 4357 : loss : 0.026323, loss_ce: 0.009511
2022-01-14 01:11:26,650 iteration 4358 : loss : 0.021975, loss_ce: 0.008494
2022-01-14 01:11:28,088 iteration 4359 : loss : 0.023008, loss_ce: 0.007489
2022-01-14 01:11:29,431 iteration 4360 : loss : 0.024778, loss_ce: 0.009980
2022-01-14 01:11:30,880 iteration 4361 : loss : 0.037197, loss_ce: 0.015544
2022-01-14 01:11:32,223 iteration 4362 : loss : 0.028334, loss_ce: 0.008292
2022-01-14 01:11:33,660 iteration 4363 : loss : 0.024612, loss_ce: 0.010207
2022-01-14 01:11:35,050 iteration 4364 : loss : 0.017395, loss_ce: 0.007518
2022-01-14 01:11:36,494 iteration 4365 : loss : 0.029515, loss_ce: 0.008667
2022-01-14 01:11:37,849 iteration 4366 : loss : 0.020225, loss_ce: 0.008209
2022-01-14 01:11:39,173 iteration 4367 : loss : 0.018961, loss_ce: 0.008595
2022-01-14 01:11:40,542 iteration 4368 : loss : 0.017625, loss_ce: 0.006778
2022-01-14 01:11:41,988 iteration 4369 : loss : 0.035268, loss_ce: 0.014526
 64%|█████████████████▎         | 257/400 [1:51:55<1:01:04, 25.63s/it]2022-01-14 01:11:43,396 iteration 4370 : loss : 0.030686, loss_ce: 0.010456
2022-01-14 01:11:44,969 iteration 4371 : loss : 0.026674, loss_ce: 0.010398
2022-01-14 01:11:46,406 iteration 4372 : loss : 0.045323, loss_ce: 0.011225
2022-01-14 01:11:47,838 iteration 4373 : loss : 0.041213, loss_ce: 0.012606
2022-01-14 01:11:49,217 iteration 4374 : loss : 0.028033, loss_ce: 0.011401
2022-01-14 01:11:50,615 iteration 4375 : loss : 0.018558, loss_ce: 0.007302
2022-01-14 01:11:52,035 iteration 4376 : loss : 0.024473, loss_ce: 0.008457
2022-01-14 01:11:53,398 iteration 4377 : loss : 0.016888, loss_ce: 0.006021
2022-01-14 01:11:54,830 iteration 4378 : loss : 0.022543, loss_ce: 0.010210
2022-01-14 01:11:56,197 iteration 4379 : loss : 0.022236, loss_ce: 0.008612
2022-01-14 01:11:57,611 iteration 4380 : loss : 0.023979, loss_ce: 0.007608
2022-01-14 01:11:59,026 iteration 4381 : loss : 0.039140, loss_ce: 0.010618
2022-01-14 01:12:00,536 iteration 4382 : loss : 0.030738, loss_ce: 0.011483
2022-01-14 01:12:01,927 iteration 4383 : loss : 0.027824, loss_ce: 0.009501
2022-01-14 01:12:03,368 iteration 4384 : loss : 0.018230, loss_ce: 0.006098
2022-01-14 01:12:04,845 iteration 4385 : loss : 0.024588, loss_ce: 0.011924
2022-01-14 01:12:06,217 iteration 4386 : loss : 0.026689, loss_ce: 0.007755
 64%|██████████████████▋          | 258/400 [1:52:19<59:39, 25.21s/it]2022-01-14 01:12:07,747 iteration 4387 : loss : 0.025327, loss_ce: 0.006779
2022-01-14 01:12:09,168 iteration 4388 : loss : 0.023125, loss_ce: 0.010658
2022-01-14 01:12:10,583 iteration 4389 : loss : 0.020463, loss_ce: 0.008675
2022-01-14 01:12:12,035 iteration 4390 : loss : 0.024446, loss_ce: 0.010860
2022-01-14 01:12:13,505 iteration 4391 : loss : 0.039387, loss_ce: 0.020492
2022-01-14 01:12:14,949 iteration 4392 : loss : 0.023363, loss_ce: 0.009279
2022-01-14 01:12:16,443 iteration 4393 : loss : 0.025008, loss_ce: 0.011940
2022-01-14 01:12:17,771 iteration 4394 : loss : 0.016321, loss_ce: 0.006247
2022-01-14 01:12:19,187 iteration 4395 : loss : 0.015802, loss_ce: 0.006789
2022-01-14 01:12:20,593 iteration 4396 : loss : 0.029762, loss_ce: 0.010501
2022-01-14 01:12:21,928 iteration 4397 : loss : 0.015505, loss_ce: 0.005228
2022-01-14 01:12:23,335 iteration 4398 : loss : 0.032817, loss_ce: 0.014680
2022-01-14 01:12:24,790 iteration 4399 : loss : 0.025854, loss_ce: 0.007556
2022-01-14 01:12:26,129 iteration 4400 : loss : 0.019628, loss_ce: 0.006303
2022-01-14 01:12:27,570 iteration 4401 : loss : 0.028940, loss_ce: 0.014350
2022-01-14 01:12:28,887 iteration 4402 : loss : 0.020211, loss_ce: 0.007056
2022-01-14 01:12:30,299 iteration 4403 : loss : 0.027856, loss_ce: 0.008686
 65%|██████████████████▊          | 259/400 [1:52:43<58:26, 24.87s/it]2022-01-14 01:12:31,822 iteration 4404 : loss : 0.025409, loss_ce: 0.010238
2022-01-14 01:12:33,216 iteration 4405 : loss : 0.037954, loss_ce: 0.020497
2022-01-14 01:12:34,660 iteration 4406 : loss : 0.022511, loss_ce: 0.009756
2022-01-14 01:12:36,072 iteration 4407 : loss : 0.042905, loss_ce: 0.010508
2022-01-14 01:12:37,439 iteration 4408 : loss : 0.030156, loss_ce: 0.015912
2022-01-14 01:12:38,781 iteration 4409 : loss : 0.026273, loss_ce: 0.009011
2022-01-14 01:12:40,260 iteration 4410 : loss : 0.040768, loss_ce: 0.016512
2022-01-14 01:12:41,686 iteration 4411 : loss : 0.029668, loss_ce: 0.010762
2022-01-14 01:12:43,115 iteration 4412 : loss : 0.021995, loss_ce: 0.007039
2022-01-14 01:12:44,564 iteration 4413 : loss : 0.018333, loss_ce: 0.007710
2022-01-14 01:12:45,965 iteration 4414 : loss : 0.031317, loss_ce: 0.010389
2022-01-14 01:12:47,315 iteration 4415 : loss : 0.018224, loss_ce: 0.008327
2022-01-14 01:12:48,733 iteration 4416 : loss : 0.034386, loss_ce: 0.013026
2022-01-14 01:12:50,167 iteration 4417 : loss : 0.026567, loss_ce: 0.011586
2022-01-14 01:12:51,573 iteration 4418 : loss : 0.021770, loss_ce: 0.007786
2022-01-14 01:12:52,950 iteration 4419 : loss : 0.017672, loss_ce: 0.006786
2022-01-14 01:12:52,950 Training Data Eval:
2022-01-14 01:12:59,926   Average segmentation loss on training set: 0.0148
2022-01-14 01:12:59,926 Validation Data Eval:
2022-01-14 01:13:02,387   Average segmentation loss on validation set: 0.0697
2022-01-14 01:13:03,797 iteration 4420 : loss : 0.016832, loss_ce: 0.005129
 65%|█████████████████▌         | 260/400 [1:53:17<1:04:03, 27.46s/it]2022-01-14 01:13:05,269 iteration 4421 : loss : 0.062269, loss_ce: 0.018101
2022-01-14 01:13:06,666 iteration 4422 : loss : 0.018113, loss_ce: 0.006599
2022-01-14 01:13:08,043 iteration 4423 : loss : 0.031064, loss_ce: 0.010731
2022-01-14 01:13:09,474 iteration 4424 : loss : 0.031868, loss_ce: 0.011987
2022-01-14 01:13:10,882 iteration 4425 : loss : 0.027166, loss_ce: 0.008051
2022-01-14 01:13:12,272 iteration 4426 : loss : 0.018125, loss_ce: 0.004971
2022-01-14 01:13:13,672 iteration 4427 : loss : 0.032225, loss_ce: 0.014724
2022-01-14 01:13:15,110 iteration 4428 : loss : 0.026343, loss_ce: 0.011223
2022-01-14 01:13:16,408 iteration 4429 : loss : 0.021770, loss_ce: 0.009000
2022-01-14 01:13:17,813 iteration 4430 : loss : 0.025121, loss_ce: 0.012196
2022-01-14 01:13:19,269 iteration 4431 : loss : 0.036161, loss_ce: 0.012274
2022-01-14 01:13:20,729 iteration 4432 : loss : 0.026142, loss_ce: 0.010660
2022-01-14 01:13:22,153 iteration 4433 : loss : 0.036885, loss_ce: 0.010747
2022-01-14 01:13:23,591 iteration 4434 : loss : 0.026867, loss_ce: 0.011664
2022-01-14 01:13:24,934 iteration 4435 : loss : 0.025528, loss_ce: 0.008253
2022-01-14 01:13:26,317 iteration 4436 : loss : 0.022304, loss_ce: 0.011724
2022-01-14 01:13:27,699 iteration 4437 : loss : 0.019251, loss_ce: 0.006948
 65%|█████████████████▌         | 261/400 [1:53:41<1:01:08, 26.39s/it]2022-01-14 01:13:29,239 iteration 4438 : loss : 0.030101, loss_ce: 0.012034
2022-01-14 01:13:30,567 iteration 4439 : loss : 0.019762, loss_ce: 0.009048
2022-01-14 01:13:32,028 iteration 4440 : loss : 0.019803, loss_ce: 0.008586
2022-01-14 01:13:33,425 iteration 4441 : loss : 0.026631, loss_ce: 0.011345
2022-01-14 01:13:34,929 iteration 4442 : loss : 0.026456, loss_ce: 0.011177
2022-01-14 01:13:36,398 iteration 4443 : loss : 0.029224, loss_ce: 0.013049
2022-01-14 01:13:37,839 iteration 4444 : loss : 0.026116, loss_ce: 0.009633
2022-01-14 01:13:39,211 iteration 4445 : loss : 0.023342, loss_ce: 0.008106
2022-01-14 01:13:40,662 iteration 4446 : loss : 0.046167, loss_ce: 0.009628
2022-01-14 01:13:42,152 iteration 4447 : loss : 0.021995, loss_ce: 0.007367
2022-01-14 01:13:43,530 iteration 4448 : loss : 0.022497, loss_ce: 0.007949
2022-01-14 01:13:45,045 iteration 4449 : loss : 0.031114, loss_ce: 0.013433
2022-01-14 01:13:46,432 iteration 4450 : loss : 0.022213, loss_ce: 0.010298
2022-01-14 01:13:47,861 iteration 4451 : loss : 0.018437, loss_ce: 0.006488
2022-01-14 01:13:49,235 iteration 4452 : loss : 0.029771, loss_ce: 0.009976
2022-01-14 01:13:50,581 iteration 4453 : loss : 0.017466, loss_ce: 0.006788
2022-01-14 01:13:51,952 iteration 4454 : loss : 0.023342, loss_ce: 0.008894
 66%|██████████████████▉          | 262/400 [1:54:05<59:13, 25.75s/it]2022-01-14 01:13:53,394 iteration 4455 : loss : 0.025834, loss_ce: 0.008740
2022-01-14 01:13:54,726 iteration 4456 : loss : 0.023936, loss_ce: 0.008064
2022-01-14 01:13:56,122 iteration 4457 : loss : 0.024298, loss_ce: 0.011673
2022-01-14 01:13:57,508 iteration 4458 : loss : 0.020167, loss_ce: 0.008242
2022-01-14 01:13:58,936 iteration 4459 : loss : 0.043308, loss_ce: 0.012155
2022-01-14 01:14:00,288 iteration 4460 : loss : 0.017272, loss_ce: 0.006484
2022-01-14 01:14:01,681 iteration 4461 : loss : 0.021995, loss_ce: 0.009448
2022-01-14 01:14:03,166 iteration 4462 : loss : 0.035325, loss_ce: 0.012061
2022-01-14 01:14:04,535 iteration 4463 : loss : 0.024717, loss_ce: 0.008700
2022-01-14 01:14:05,915 iteration 4464 : loss : 0.020183, loss_ce: 0.008417
2022-01-14 01:14:07,425 iteration 4465 : loss : 0.066297, loss_ce: 0.010462
2022-01-14 01:14:08,777 iteration 4466 : loss : 0.017609, loss_ce: 0.006809
2022-01-14 01:14:10,208 iteration 4467 : loss : 0.021841, loss_ce: 0.009456
2022-01-14 01:14:11,602 iteration 4468 : loss : 0.033899, loss_ce: 0.010181
2022-01-14 01:14:13,005 iteration 4469 : loss : 0.024908, loss_ce: 0.007636
2022-01-14 01:14:14,400 iteration 4470 : loss : 0.036257, loss_ce: 0.017609
2022-01-14 01:14:15,858 iteration 4471 : loss : 0.051897, loss_ce: 0.011876
 66%|███████████████████          | 263/400 [1:54:29<57:31, 25.20s/it]2022-01-14 01:14:17,302 iteration 4472 : loss : 0.035281, loss_ce: 0.015338
2022-01-14 01:14:18,754 iteration 4473 : loss : 0.021815, loss_ce: 0.007658
2022-01-14 01:14:20,273 iteration 4474 : loss : 0.026392, loss_ce: 0.012969
2022-01-14 01:14:21,701 iteration 4475 : loss : 0.019071, loss_ce: 0.007520
2022-01-14 01:14:23,072 iteration 4476 : loss : 0.025943, loss_ce: 0.008781
2022-01-14 01:14:24,453 iteration 4477 : loss : 0.019735, loss_ce: 0.007921
2022-01-14 01:14:25,933 iteration 4478 : loss : 0.037811, loss_ce: 0.021337
2022-01-14 01:14:27,325 iteration 4479 : loss : 0.020857, loss_ce: 0.009487
2022-01-14 01:14:28,665 iteration 4480 : loss : 0.021362, loss_ce: 0.007912
2022-01-14 01:14:30,115 iteration 4481 : loss : 0.038665, loss_ce: 0.009558
2022-01-14 01:14:31,522 iteration 4482 : loss : 0.020728, loss_ce: 0.006926
2022-01-14 01:14:32,873 iteration 4483 : loss : 0.026013, loss_ce: 0.007056
2022-01-14 01:14:34,337 iteration 4484 : loss : 0.031120, loss_ce: 0.008751
2022-01-14 01:14:35,805 iteration 4485 : loss : 0.033830, loss_ce: 0.016551
2022-01-14 01:14:37,268 iteration 4486 : loss : 0.026071, loss_ce: 0.007860
2022-01-14 01:14:38,629 iteration 4487 : loss : 0.021484, loss_ce: 0.005592
2022-01-14 01:14:40,026 iteration 4488 : loss : 0.040488, loss_ce: 0.013919
 66%|███████████████████▏         | 264/400 [1:54:53<56:24, 24.89s/it]2022-01-14 01:14:41,535 iteration 4489 : loss : 0.029393, loss_ce: 0.013704
2022-01-14 01:14:42,897 iteration 4490 : loss : 0.019934, loss_ce: 0.009818
2022-01-14 01:14:44,365 iteration 4491 : loss : 0.041761, loss_ce: 0.015450
2022-01-14 01:14:45,850 iteration 4492 : loss : 0.025444, loss_ce: 0.010958
2022-01-14 01:14:47,240 iteration 4493 : loss : 0.030823, loss_ce: 0.011940
2022-01-14 01:14:48,672 iteration 4494 : loss : 0.033361, loss_ce: 0.010436
2022-01-14 01:14:50,099 iteration 4495 : loss : 0.048177, loss_ce: 0.018149
2022-01-14 01:14:51,478 iteration 4496 : loss : 0.019587, loss_ce: 0.009021
2022-01-14 01:14:52,969 iteration 4497 : loss : 0.030620, loss_ce: 0.014220
2022-01-14 01:14:54,372 iteration 4498 : loss : 0.039300, loss_ce: 0.012724
2022-01-14 01:14:55,800 iteration 4499 : loss : 0.039094, loss_ce: 0.016555
2022-01-14 01:14:57,140 iteration 4500 : loss : 0.018383, loss_ce: 0.006334
2022-01-14 01:14:58,496 iteration 4501 : loss : 0.027938, loss_ce: 0.008897
2022-01-14 01:14:59,864 iteration 4502 : loss : 0.027626, loss_ce: 0.008847
2022-01-14 01:15:01,358 iteration 4503 : loss : 0.020614, loss_ce: 0.008258
2022-01-14 01:15:02,759 iteration 4504 : loss : 0.027586, loss_ce: 0.010834
2022-01-14 01:15:02,759 Training Data Eval:
2022-01-14 01:15:09,891   Average segmentation loss on training set: 0.0156
2022-01-14 01:15:09,891 Validation Data Eval:
2022-01-14 01:15:12,386   Average segmentation loss on validation set: 0.0957
2022-01-14 01:15:13,873 iteration 4505 : loss : 0.022949, loss_ce: 0.009500
 66%|█████████████████▉         | 265/400 [1:55:27<1:02:02, 27.58s/it]2022-01-14 01:15:15,324 iteration 4506 : loss : 0.035842, loss_ce: 0.014976
2022-01-14 01:15:16,751 iteration 4507 : loss : 0.022987, loss_ce: 0.010100
2022-01-14 01:15:18,146 iteration 4508 : loss : 0.018923, loss_ce: 0.006259
2022-01-14 01:15:19,514 iteration 4509 : loss : 0.047576, loss_ce: 0.009219
2022-01-14 01:15:20,991 iteration 4510 : loss : 0.027595, loss_ce: 0.008332
2022-01-14 01:15:22,414 iteration 4511 : loss : 0.035450, loss_ce: 0.009737
2022-01-14 01:15:23,881 iteration 4512 : loss : 0.032331, loss_ce: 0.016858
2022-01-14 01:15:25,389 iteration 4513 : loss : 0.039343, loss_ce: 0.015597
2022-01-14 01:15:26,713 iteration 4514 : loss : 0.026371, loss_ce: 0.008096
2022-01-14 01:15:28,091 iteration 4515 : loss : 0.035946, loss_ce: 0.014270
2022-01-14 01:15:29,421 iteration 4516 : loss : 0.016975, loss_ce: 0.006688
2022-01-14 01:15:30,785 iteration 4517 : loss : 0.016889, loss_ce: 0.006939
2022-01-14 01:15:32,215 iteration 4518 : loss : 0.045054, loss_ce: 0.013913
2022-01-14 01:15:33,546 iteration 4519 : loss : 0.015563, loss_ce: 0.005119
2022-01-14 01:15:34,998 iteration 4520 : loss : 0.029786, loss_ce: 0.011424
2022-01-14 01:15:36,356 iteration 4521 : loss : 0.032203, loss_ce: 0.013454
2022-01-14 01:15:37,760 iteration 4522 : loss : 0.031887, loss_ce: 0.013117
 66%|███████████████████▎         | 266/400 [1:55:51<59:07, 26.47s/it]2022-01-14 01:15:39,308 iteration 4523 : loss : 0.025214, loss_ce: 0.010217
2022-01-14 01:15:40,672 iteration 4524 : loss : 0.037439, loss_ce: 0.013107
2022-01-14 01:15:41,996 iteration 4525 : loss : 0.027510, loss_ce: 0.013205
2022-01-14 01:15:43,394 iteration 4526 : loss : 0.022955, loss_ce: 0.006820
2022-01-14 01:15:44,776 iteration 4527 : loss : 0.020161, loss_ce: 0.008855
2022-01-14 01:15:46,191 iteration 4528 : loss : 0.024533, loss_ce: 0.009526
2022-01-14 01:15:47,546 iteration 4529 : loss : 0.019056, loss_ce: 0.006639
2022-01-14 01:15:48,953 iteration 4530 : loss : 0.023555, loss_ce: 0.009452
2022-01-14 01:15:50,440 iteration 4531 : loss : 0.034388, loss_ce: 0.011984
2022-01-14 01:15:51,771 iteration 4532 : loss : 0.016994, loss_ce: 0.006069
2022-01-14 01:15:53,306 iteration 4533 : loss : 0.050908, loss_ce: 0.023386
2022-01-14 01:15:54,658 iteration 4534 : loss : 0.017211, loss_ce: 0.008001
2022-01-14 01:15:56,095 iteration 4535 : loss : 0.021689, loss_ce: 0.009791
2022-01-14 01:15:57,506 iteration 4536 : loss : 0.020144, loss_ce: 0.006067
2022-01-14 01:15:58,865 iteration 4537 : loss : 0.038365, loss_ce: 0.010645
2022-01-14 01:16:00,246 iteration 4538 : loss : 0.021653, loss_ce: 0.009120
2022-01-14 01:16:01,546 iteration 4539 : loss : 0.018431, loss_ce: 0.007003
 67%|███████████████████▎         | 267/400 [1:56:14<56:53, 25.67s/it]2022-01-14 01:16:02,944 iteration 4540 : loss : 0.020609, loss_ce: 0.009072
2022-01-14 01:16:04,328 iteration 4541 : loss : 0.034562, loss_ce: 0.014115
2022-01-14 01:16:05,733 iteration 4542 : loss : 0.036496, loss_ce: 0.009813
2022-01-14 01:16:07,277 iteration 4543 : loss : 0.024389, loss_ce: 0.008806
2022-01-14 01:16:08,623 iteration 4544 : loss : 0.025130, loss_ce: 0.010771
2022-01-14 01:16:09,971 iteration 4545 : loss : 0.016359, loss_ce: 0.006430
2022-01-14 01:16:11,341 iteration 4546 : loss : 0.026748, loss_ce: 0.009422
2022-01-14 01:16:12,740 iteration 4547 : loss : 0.025085, loss_ce: 0.009314
2022-01-14 01:16:14,120 iteration 4548 : loss : 0.046408, loss_ce: 0.019351
2022-01-14 01:16:15,435 iteration 4549 : loss : 0.028331, loss_ce: 0.007635
2022-01-14 01:16:16,916 iteration 4550 : loss : 0.021987, loss_ce: 0.006885
2022-01-14 01:16:18,440 iteration 4551 : loss : 0.029445, loss_ce: 0.010078
2022-01-14 01:16:19,845 iteration 4552 : loss : 0.025273, loss_ce: 0.008272
2022-01-14 01:16:21,239 iteration 4553 : loss : 0.025334, loss_ce: 0.011491
2022-01-14 01:16:22,707 iteration 4554 : loss : 0.025372, loss_ce: 0.007005
2022-01-14 01:16:24,065 iteration 4555 : loss : 0.020443, loss_ce: 0.006973
2022-01-14 01:16:25,474 iteration 4556 : loss : 0.038571, loss_ce: 0.018159
 67%|███████████████████▍         | 268/400 [1:56:38<55:19, 25.14s/it]2022-01-14 01:16:26,938 iteration 4557 : loss : 0.018976, loss_ce: 0.009314
2022-01-14 01:16:28,350 iteration 4558 : loss : 0.031595, loss_ce: 0.013258
2022-01-14 01:16:29,800 iteration 4559 : loss : 0.019137, loss_ce: 0.005734
2022-01-14 01:16:31,199 iteration 4560 : loss : 0.026526, loss_ce: 0.007773
2022-01-14 01:16:32,627 iteration 4561 : loss : 0.031070, loss_ce: 0.007644
2022-01-14 01:16:34,001 iteration 4562 : loss : 0.022681, loss_ce: 0.007246
2022-01-14 01:16:35,418 iteration 4563 : loss : 0.033334, loss_ce: 0.016154
2022-01-14 01:16:36,853 iteration 4564 : loss : 0.030478, loss_ce: 0.011410
2022-01-14 01:16:38,352 iteration 4565 : loss : 0.030672, loss_ce: 0.010330
2022-01-14 01:16:39,798 iteration 4566 : loss : 0.033532, loss_ce: 0.013894
2022-01-14 01:16:41,183 iteration 4567 : loss : 0.023689, loss_ce: 0.009370
2022-01-14 01:16:42,581 iteration 4568 : loss : 0.021848, loss_ce: 0.007297
2022-01-14 01:16:44,055 iteration 4569 : loss : 0.051217, loss_ce: 0.011470
2022-01-14 01:16:45,571 iteration 4570 : loss : 0.038933, loss_ce: 0.018950
2022-01-14 01:16:46,957 iteration 4571 : loss : 0.024960, loss_ce: 0.009982
2022-01-14 01:16:48,288 iteration 4572 : loss : 0.020545, loss_ce: 0.008492
2022-01-14 01:16:49,728 iteration 4573 : loss : 0.024531, loss_ce: 0.010736
 67%|███████████████████▌         | 269/400 [1:57:03<54:18, 24.88s/it]2022-01-14 01:16:51,107 iteration 4574 : loss : 0.019442, loss_ce: 0.008608
2022-01-14 01:16:52,547 iteration 4575 : loss : 0.023343, loss_ce: 0.007028
2022-01-14 01:16:54,078 iteration 4576 : loss : 0.028592, loss_ce: 0.011850
2022-01-14 01:16:55,498 iteration 4577 : loss : 0.021051, loss_ce: 0.006745
2022-01-14 01:16:56,837 iteration 4578 : loss : 0.024366, loss_ce: 0.011472
2022-01-14 01:16:58,312 iteration 4579 : loss : 0.019425, loss_ce: 0.006861
2022-01-14 01:16:59,723 iteration 4580 : loss : 0.018695, loss_ce: 0.007853
2022-01-14 01:17:01,152 iteration 4581 : loss : 0.029214, loss_ce: 0.011512
2022-01-14 01:17:02,553 iteration 4582 : loss : 0.032354, loss_ce: 0.012668
2022-01-14 01:17:04,073 iteration 4583 : loss : 0.034958, loss_ce: 0.007937
2022-01-14 01:17:05,494 iteration 4584 : loss : 0.030724, loss_ce: 0.008840
2022-01-14 01:17:06,859 iteration 4585 : loss : 0.019126, loss_ce: 0.006522
2022-01-14 01:17:08,259 iteration 4586 : loss : 0.016795, loss_ce: 0.008056
2022-01-14 01:17:09,663 iteration 4587 : loss : 0.018917, loss_ce: 0.007149
2022-01-14 01:17:11,130 iteration 4588 : loss : 0.022512, loss_ce: 0.008868
2022-01-14 01:17:12,550 iteration 4589 : loss : 0.020344, loss_ce: 0.008863
2022-01-14 01:17:12,550 Training Data Eval:
2022-01-14 01:17:19,664   Average segmentation loss on training set: 0.0149
2022-01-14 01:17:19,665 Validation Data Eval:
2022-01-14 01:17:22,169   Average segmentation loss on validation set: 0.0726
2022-01-14 01:17:23,646 iteration 4590 : loss : 0.045477, loss_ce: 0.026309
 68%|███████████████████▌         | 270/400 [1:57:37<59:46, 27.59s/it]2022-01-14 01:17:25,287 iteration 4591 : loss : 0.030908, loss_ce: 0.010867
2022-01-14 01:17:26,685 iteration 4592 : loss : 0.023840, loss_ce: 0.010467
2022-01-14 01:17:28,098 iteration 4593 : loss : 0.026339, loss_ce: 0.010470
2022-01-14 01:17:29,509 iteration 4594 : loss : 0.028060, loss_ce: 0.009758
2022-01-14 01:17:30,904 iteration 4595 : loss : 0.018635, loss_ce: 0.007803
2022-01-14 01:17:32,418 iteration 4596 : loss : 0.023071, loss_ce: 0.009255
2022-01-14 01:17:33,762 iteration 4597 : loss : 0.042701, loss_ce: 0.012801
2022-01-14 01:17:35,071 iteration 4598 : loss : 0.025794, loss_ce: 0.010168
2022-01-14 01:17:36,438 iteration 4599 : loss : 0.033852, loss_ce: 0.014710
2022-01-14 01:17:37,875 iteration 4600 : loss : 0.025833, loss_ce: 0.009125
2022-01-14 01:17:39,301 iteration 4601 : loss : 0.030352, loss_ce: 0.014504
2022-01-14 01:17:40,799 iteration 4602 : loss : 0.027645, loss_ce: 0.011204
2022-01-14 01:17:42,292 iteration 4603 : loss : 0.028421, loss_ce: 0.009802
2022-01-14 01:17:43,643 iteration 4604 : loss : 0.029769, loss_ce: 0.010479
2022-01-14 01:17:45,039 iteration 4605 : loss : 0.023672, loss_ce: 0.006957
2022-01-14 01:17:46,422 iteration 4606 : loss : 0.031009, loss_ce: 0.010942
2022-01-14 01:17:47,801 iteration 4607 : loss : 0.035912, loss_ce: 0.014484
 68%|███████████████████▋         | 271/400 [1:58:01<57:05, 26.56s/it]2022-01-14 01:17:49,296 iteration 4608 : loss : 0.035153, loss_ce: 0.011232
2022-01-14 01:17:50,736 iteration 4609 : loss : 0.034015, loss_ce: 0.011404
2022-01-14 01:17:52,156 iteration 4610 : loss : 0.034777, loss_ce: 0.010372
2022-01-14 01:17:53,630 iteration 4611 : loss : 0.058743, loss_ce: 0.020007
2022-01-14 01:17:55,037 iteration 4612 : loss : 0.063937, loss_ce: 0.035655
2022-01-14 01:17:56,447 iteration 4613 : loss : 0.040536, loss_ce: 0.018898
2022-01-14 01:17:57,859 iteration 4614 : loss : 0.032249, loss_ce: 0.010546
2022-01-14 01:17:59,376 iteration 4615 : loss : 0.050544, loss_ce: 0.022247
2022-01-14 01:18:00,729 iteration 4616 : loss : 0.036686, loss_ce: 0.017647
2022-01-14 01:18:02,143 iteration 4617 : loss : 0.049818, loss_ce: 0.017981
2022-01-14 01:18:03,511 iteration 4618 : loss : 0.027143, loss_ce: 0.012040
2022-01-14 01:18:04,946 iteration 4619 : loss : 0.039282, loss_ce: 0.015506
2022-01-14 01:18:06,319 iteration 4620 : loss : 0.038784, loss_ce: 0.014802
2022-01-14 01:18:07,691 iteration 4621 : loss : 0.037809, loss_ce: 0.014267
2022-01-14 01:18:09,121 iteration 4622 : loss : 0.031810, loss_ce: 0.012549
2022-01-14 01:18:10,524 iteration 4623 : loss : 0.031091, loss_ce: 0.014235
2022-01-14 01:18:11,894 iteration 4624 : loss : 0.030985, loss_ce: 0.010988
 68%|███████████████████▋         | 272/400 [1:58:25<55:04, 25.82s/it]2022-01-14 01:18:13,418 iteration 4625 : loss : 0.059072, loss_ce: 0.018993
2022-01-14 01:18:14,866 iteration 4626 : loss : 0.033535, loss_ce: 0.011609
2022-01-14 01:18:16,255 iteration 4627 : loss : 0.023396, loss_ce: 0.011385
2022-01-14 01:18:17,650 iteration 4628 : loss : 0.026864, loss_ce: 0.009328
2022-01-14 01:18:19,007 iteration 4629 : loss : 0.051735, loss_ce: 0.009579
2022-01-14 01:18:20,416 iteration 4630 : loss : 0.024003, loss_ce: 0.012586
2022-01-14 01:18:21,783 iteration 4631 : loss : 0.028920, loss_ce: 0.012831
2022-01-14 01:18:23,203 iteration 4632 : loss : 0.022841, loss_ce: 0.007397
2022-01-14 01:18:24,621 iteration 4633 : loss : 0.025978, loss_ce: 0.009584
2022-01-14 01:18:26,113 iteration 4634 : loss : 0.035649, loss_ce: 0.016694
2022-01-14 01:18:27,396 iteration 4635 : loss : 0.018819, loss_ce: 0.005935
2022-01-14 01:18:28,720 iteration 4636 : loss : 0.017448, loss_ce: 0.006508
2022-01-14 01:18:30,123 iteration 4637 : loss : 0.041052, loss_ce: 0.013626
2022-01-14 01:18:31,510 iteration 4638 : loss : 0.026635, loss_ce: 0.010894
2022-01-14 01:18:32,933 iteration 4639 : loss : 0.035162, loss_ce: 0.012529
2022-01-14 01:18:34,387 iteration 4640 : loss : 0.035448, loss_ce: 0.015370
2022-01-14 01:18:35,791 iteration 4641 : loss : 0.054197, loss_ce: 0.023646
 68%|███████████████████▊         | 273/400 [1:58:49<53:25, 25.24s/it]2022-01-14 01:18:37,245 iteration 4642 : loss : 0.032723, loss_ce: 0.013415
2022-01-14 01:18:38,648 iteration 4643 : loss : 0.036265, loss_ce: 0.013936
2022-01-14 01:18:40,057 iteration 4644 : loss : 0.050858, loss_ce: 0.024080
2022-01-14 01:18:41,433 iteration 4645 : loss : 0.034277, loss_ce: 0.012958
2022-01-14 01:18:42,819 iteration 4646 : loss : 0.033836, loss_ce: 0.014864
2022-01-14 01:18:44,223 iteration 4647 : loss : 0.024993, loss_ce: 0.010258
2022-01-14 01:18:45,602 iteration 4648 : loss : 0.020498, loss_ce: 0.009236
2022-01-14 01:18:47,155 iteration 4649 : loss : 0.026202, loss_ce: 0.010243
2022-01-14 01:18:48,468 iteration 4650 : loss : 0.021961, loss_ce: 0.010010
2022-01-14 01:18:49,934 iteration 4651 : loss : 0.031465, loss_ce: 0.011461
2022-01-14 01:18:51,344 iteration 4652 : loss : 0.024039, loss_ce: 0.008966
2022-01-14 01:18:52,702 iteration 4653 : loss : 0.023305, loss_ce: 0.008830
2022-01-14 01:18:54,062 iteration 4654 : loss : 0.031663, loss_ce: 0.010072
2022-01-14 01:18:55,523 iteration 4655 : loss : 0.031580, loss_ce: 0.010426
2022-01-14 01:18:56,935 iteration 4656 : loss : 0.032998, loss_ce: 0.010498
2022-01-14 01:18:58,338 iteration 4657 : loss : 0.031056, loss_ce: 0.011605
2022-01-14 01:18:59,727 iteration 4658 : loss : 0.017042, loss_ce: 0.006179
 68%|███████████████████▊         | 274/400 [1:59:13<52:10, 24.85s/it]2022-01-14 01:19:01,215 iteration 4659 : loss : 0.028588, loss_ce: 0.012967
2022-01-14 01:19:02,582 iteration 4660 : loss : 0.020889, loss_ce: 0.007982
2022-01-14 01:19:04,069 iteration 4661 : loss : 0.024903, loss_ce: 0.010249
2022-01-14 01:19:05,389 iteration 4662 : loss : 0.016743, loss_ce: 0.007999
2022-01-14 01:19:06,887 iteration 4663 : loss : 0.030502, loss_ce: 0.011435
2022-01-14 01:19:08,320 iteration 4664 : loss : 0.032861, loss_ce: 0.013308
2022-01-14 01:19:09,714 iteration 4665 : loss : 0.025653, loss_ce: 0.010948
2022-01-14 01:19:11,174 iteration 4666 : loss : 0.023228, loss_ce: 0.009393
2022-01-14 01:19:12,673 iteration 4667 : loss : 0.043510, loss_ce: 0.017869
2022-01-14 01:19:14,078 iteration 4668 : loss : 0.018559, loss_ce: 0.007531
2022-01-14 01:19:15,561 iteration 4669 : loss : 0.026068, loss_ce: 0.010070
2022-01-14 01:19:16,990 iteration 4670 : loss : 0.032432, loss_ce: 0.009597
2022-01-14 01:19:18,372 iteration 4671 : loss : 0.017420, loss_ce: 0.006267
2022-01-14 01:19:19,772 iteration 4672 : loss : 0.016199, loss_ce: 0.005874
2022-01-14 01:19:21,113 iteration 4673 : loss : 0.018470, loss_ce: 0.006516
2022-01-14 01:19:22,558 iteration 4674 : loss : 0.033472, loss_ce: 0.011044
2022-01-14 01:19:22,558 Training Data Eval:
2022-01-14 01:19:29,681   Average segmentation loss on training set: 0.0158
2022-01-14 01:19:29,681 Validation Data Eval:
2022-01-14 01:19:32,151   Average segmentation loss on validation set: 0.0780
2022-01-14 01:19:33,523 iteration 4675 : loss : 0.016181, loss_ce: 0.006477
 69%|███████████████████▉         | 275/400 [1:59:47<57:25, 27.56s/it]2022-01-14 01:19:35,102 iteration 4676 : loss : 0.018013, loss_ce: 0.007653
2022-01-14 01:19:36,480 iteration 4677 : loss : 0.018199, loss_ce: 0.007604
2022-01-14 01:19:37,958 iteration 4678 : loss : 0.028307, loss_ce: 0.009187
2022-01-14 01:19:39,450 iteration 4679 : loss : 0.023326, loss_ce: 0.008720
2022-01-14 01:19:40,791 iteration 4680 : loss : 0.022125, loss_ce: 0.008523
2022-01-14 01:19:42,209 iteration 4681 : loss : 0.021983, loss_ce: 0.009128
2022-01-14 01:19:43,595 iteration 4682 : loss : 0.019763, loss_ce: 0.007310
2022-01-14 01:19:44,966 iteration 4683 : loss : 0.017465, loss_ce: 0.005541
2022-01-14 01:19:46,386 iteration 4684 : loss : 0.022541, loss_ce: 0.007993
2022-01-14 01:19:47,852 iteration 4685 : loss : 0.016379, loss_ce: 0.006262
2022-01-14 01:19:49,230 iteration 4686 : loss : 0.027183, loss_ce: 0.010399
2022-01-14 01:19:50,638 iteration 4687 : loss : 0.025937, loss_ce: 0.007411
2022-01-14 01:19:51,967 iteration 4688 : loss : 0.014486, loss_ce: 0.006083
2022-01-14 01:19:53,413 iteration 4689 : loss : 0.031929, loss_ce: 0.011156
2022-01-14 01:19:54,740 iteration 4690 : loss : 0.018581, loss_ce: 0.006241
2022-01-14 01:19:56,150 iteration 4691 : loss : 0.028220, loss_ce: 0.008042
2022-01-14 01:19:57,669 iteration 4692 : loss : 0.027690, loss_ce: 0.009789
 69%|████████████████████         | 276/400 [2:00:11<54:47, 26.51s/it]2022-01-14 01:19:59,131 iteration 4693 : loss : 0.021479, loss_ce: 0.008715
2022-01-14 01:20:00,542 iteration 4694 : loss : 0.043291, loss_ce: 0.014886
2022-01-14 01:20:02,001 iteration 4695 : loss : 0.025233, loss_ce: 0.009737
2022-01-14 01:20:03,433 iteration 4696 : loss : 0.026832, loss_ce: 0.009161
2022-01-14 01:20:04,804 iteration 4697 : loss : 0.027544, loss_ce: 0.010489
2022-01-14 01:20:06,188 iteration 4698 : loss : 0.022238, loss_ce: 0.009151
2022-01-14 01:20:07,594 iteration 4699 : loss : 0.022048, loss_ce: 0.006345
2022-01-14 01:20:08,993 iteration 4700 : loss : 0.027648, loss_ce: 0.012779
2022-01-14 01:20:10,389 iteration 4701 : loss : 0.017774, loss_ce: 0.005287
2022-01-14 01:20:11,858 iteration 4702 : loss : 0.024963, loss_ce: 0.007922
2022-01-14 01:20:13,275 iteration 4703 : loss : 0.041746, loss_ce: 0.020135
2022-01-14 01:20:14,698 iteration 4704 : loss : 0.043684, loss_ce: 0.009056
2022-01-14 01:20:16,128 iteration 4705 : loss : 0.030224, loss_ce: 0.009574
2022-01-14 01:20:17,453 iteration 4706 : loss : 0.020808, loss_ce: 0.006926
2022-01-14 01:20:18,820 iteration 4707 : loss : 0.026485, loss_ce: 0.007518
2022-01-14 01:20:20,205 iteration 4708 : loss : 0.032107, loss_ce: 0.013963
2022-01-14 01:20:21,579 iteration 4709 : loss : 0.025596, loss_ce: 0.011133
 69%|████████████████████         | 277/400 [2:00:35<52:44, 25.73s/it]2022-01-14 01:20:23,004 iteration 4710 : loss : 0.022355, loss_ce: 0.008749
2022-01-14 01:20:24,347 iteration 4711 : loss : 0.020517, loss_ce: 0.006405
2022-01-14 01:20:25,654 iteration 4712 : loss : 0.016778, loss_ce: 0.005834
2022-01-14 01:20:27,045 iteration 4713 : loss : 0.021673, loss_ce: 0.006516
2022-01-14 01:20:28,363 iteration 4714 : loss : 0.018956, loss_ce: 0.007588
2022-01-14 01:20:29,771 iteration 4715 : loss : 0.026042, loss_ce: 0.012982
2022-01-14 01:20:31,222 iteration 4716 : loss : 0.025371, loss_ce: 0.010150
2022-01-14 01:20:32,591 iteration 4717 : loss : 0.037077, loss_ce: 0.014069
2022-01-14 01:20:34,003 iteration 4718 : loss : 0.020079, loss_ce: 0.007982
2022-01-14 01:20:35,383 iteration 4719 : loss : 0.018854, loss_ce: 0.007049
2022-01-14 01:20:36,765 iteration 4720 : loss : 0.024440, loss_ce: 0.012686
2022-01-14 01:20:38,135 iteration 4721 : loss : 0.025655, loss_ce: 0.007971
2022-01-14 01:20:39,611 iteration 4722 : loss : 0.028566, loss_ce: 0.013058
2022-01-14 01:20:41,103 iteration 4723 : loss : 0.031679, loss_ce: 0.010274
2022-01-14 01:20:42,605 iteration 4724 : loss : 0.034221, loss_ce: 0.018503
2022-01-14 01:20:43,963 iteration 4725 : loss : 0.020787, loss_ce: 0.007010
2022-01-14 01:20:45,393 iteration 4726 : loss : 0.035805, loss_ce: 0.012147
 70%|████████████████████▏        | 278/400 [2:00:58<51:08, 25.16s/it]2022-01-14 01:20:46,879 iteration 4727 : loss : 0.027272, loss_ce: 0.009014
2022-01-14 01:20:48,307 iteration 4728 : loss : 0.019609, loss_ce: 0.007365
2022-01-14 01:20:49,664 iteration 4729 : loss : 0.019418, loss_ce: 0.005864
2022-01-14 01:20:51,076 iteration 4730 : loss : 0.025285, loss_ce: 0.010284
2022-01-14 01:20:52,484 iteration 4731 : loss : 0.023514, loss_ce: 0.006724
2022-01-14 01:20:53,893 iteration 4732 : loss : 0.024249, loss_ce: 0.009330
2022-01-14 01:20:55,235 iteration 4733 : loss : 0.022702, loss_ce: 0.007227
2022-01-14 01:20:56,573 iteration 4734 : loss : 0.018084, loss_ce: 0.006494
2022-01-14 01:20:58,049 iteration 4735 : loss : 0.027518, loss_ce: 0.013150
2022-01-14 01:20:59,463 iteration 4736 : loss : 0.021979, loss_ce: 0.008624
2022-01-14 01:21:00,955 iteration 4737 : loss : 0.040738, loss_ce: 0.014774
2022-01-14 01:21:02,423 iteration 4738 : loss : 0.048718, loss_ce: 0.010266
2022-01-14 01:21:03,804 iteration 4739 : loss : 0.019078, loss_ce: 0.007115
2022-01-14 01:21:05,139 iteration 4740 : loss : 0.017534, loss_ce: 0.007568
2022-01-14 01:21:06,532 iteration 4741 : loss : 0.027935, loss_ce: 0.016884
2022-01-14 01:21:07,849 iteration 4742 : loss : 0.016435, loss_ce: 0.006099
2022-01-14 01:21:09,258 iteration 4743 : loss : 0.018275, loss_ce: 0.006440
 70%|████████████████████▏        | 279/400 [2:01:22<49:57, 24.77s/it]2022-01-14 01:21:10,767 iteration 4744 : loss : 0.032897, loss_ce: 0.017734
2022-01-14 01:21:12,238 iteration 4745 : loss : 0.024184, loss_ce: 0.010934
2022-01-14 01:21:13,702 iteration 4746 : loss : 0.023204, loss_ce: 0.008967
2022-01-14 01:21:15,181 iteration 4747 : loss : 0.024119, loss_ce: 0.009637
2022-01-14 01:21:16,720 iteration 4748 : loss : 0.024969, loss_ce: 0.010988
2022-01-14 01:21:18,195 iteration 4749 : loss : 0.029923, loss_ce: 0.009153
2022-01-14 01:21:19,607 iteration 4750 : loss : 0.021779, loss_ce: 0.009640
2022-01-14 01:21:20,974 iteration 4751 : loss : 0.020281, loss_ce: 0.007304
2022-01-14 01:21:22,382 iteration 4752 : loss : 0.027689, loss_ce: 0.007305
2022-01-14 01:21:23,824 iteration 4753 : loss : 0.018475, loss_ce: 0.008285
2022-01-14 01:21:25,254 iteration 4754 : loss : 0.025773, loss_ce: 0.008100
2022-01-14 01:21:26,694 iteration 4755 : loss : 0.021277, loss_ce: 0.007019
2022-01-14 01:21:28,096 iteration 4756 : loss : 0.018518, loss_ce: 0.007845
2022-01-14 01:21:29,502 iteration 4757 : loss : 0.019433, loss_ce: 0.008685
2022-01-14 01:21:31,016 iteration 4758 : loss : 0.028095, loss_ce: 0.008525
2022-01-14 01:21:32,356 iteration 4759 : loss : 0.016110, loss_ce: 0.005964
2022-01-14 01:21:32,356 Training Data Eval:
2022-01-14 01:21:39,342   Average segmentation loss on training set: 0.0148
2022-01-14 01:21:39,343 Validation Data Eval:
2022-01-14 01:21:41,849   Average segmentation loss on validation set: 0.0755
2022-01-14 01:21:43,301 iteration 4760 : loss : 0.035607, loss_ce: 0.011470
 70%|████████████████████▎        | 280/400 [2:01:56<55:06, 27.55s/it]2022-01-14 01:21:44,802 iteration 4761 : loss : 0.024662, loss_ce: 0.011483
2022-01-14 01:21:46,268 iteration 4762 : loss : 0.022009, loss_ce: 0.006371
2022-01-14 01:21:47,712 iteration 4763 : loss : 0.029597, loss_ce: 0.010306
2022-01-14 01:21:49,200 iteration 4764 : loss : 0.030937, loss_ce: 0.010364
2022-01-14 01:21:50,660 iteration 4765 : loss : 0.026774, loss_ce: 0.010179
2022-01-14 01:21:52,189 iteration 4766 : loss : 0.039033, loss_ce: 0.012837
2022-01-14 01:21:53,715 iteration 4767 : loss : 0.027706, loss_ce: 0.014563
2022-01-14 01:21:55,173 iteration 4768 : loss : 0.036230, loss_ce: 0.014674
2022-01-14 01:21:56,538 iteration 4769 : loss : 0.018326, loss_ce: 0.006329
2022-01-14 01:21:58,009 iteration 4770 : loss : 0.020882, loss_ce: 0.009914
2022-01-14 01:21:59,442 iteration 4771 : loss : 0.055912, loss_ce: 0.019105
2022-01-14 01:22:00,839 iteration 4772 : loss : 0.024409, loss_ce: 0.009958
2022-01-14 01:22:02,215 iteration 4773 : loss : 0.018610, loss_ce: 0.007966
2022-01-14 01:22:03,717 iteration 4774 : loss : 0.038534, loss_ce: 0.013606
2022-01-14 01:22:05,090 iteration 4775 : loss : 0.019966, loss_ce: 0.007631
2022-01-14 01:22:06,507 iteration 4776 : loss : 0.023561, loss_ce: 0.008659
2022-01-14 01:22:07,921 iteration 4777 : loss : 0.027382, loss_ce: 0.010625
 70%|████████████████████▎        | 281/400 [2:02:21<52:53, 26.67s/it]2022-01-14 01:22:09,431 iteration 4778 : loss : 0.019965, loss_ce: 0.008921
2022-01-14 01:22:10,786 iteration 4779 : loss : 0.017795, loss_ce: 0.008002
2022-01-14 01:22:12,142 iteration 4780 : loss : 0.021221, loss_ce: 0.008827
2022-01-14 01:22:13,583 iteration 4781 : loss : 0.024082, loss_ce: 0.008244
2022-01-14 01:22:15,021 iteration 4782 : loss : 0.031650, loss_ce: 0.012900
2022-01-14 01:22:16,407 iteration 4783 : loss : 0.022912, loss_ce: 0.009693
2022-01-14 01:22:17,875 iteration 4784 : loss : 0.030434, loss_ce: 0.010875
2022-01-14 01:22:19,273 iteration 4785 : loss : 0.018115, loss_ce: 0.007524
2022-01-14 01:22:20,667 iteration 4786 : loss : 0.014984, loss_ce: 0.005919
2022-01-14 01:22:22,048 iteration 4787 : loss : 0.045186, loss_ce: 0.012272
2022-01-14 01:22:23,485 iteration 4788 : loss : 0.023147, loss_ce: 0.006690
2022-01-14 01:22:24,783 iteration 4789 : loss : 0.015617, loss_ce: 0.006065
2022-01-14 01:22:26,084 iteration 4790 : loss : 0.013400, loss_ce: 0.005015
2022-01-14 01:22:27,506 iteration 4791 : loss : 0.029042, loss_ce: 0.013174
2022-01-14 01:22:28,927 iteration 4792 : loss : 0.029265, loss_ce: 0.011279
2022-01-14 01:22:30,411 iteration 4793 : loss : 0.021513, loss_ce: 0.007286
2022-01-14 01:22:31,788 iteration 4794 : loss : 0.022352, loss_ce: 0.005927
 70%|████████████████████▍        | 282/400 [2:02:45<50:48, 25.83s/it]2022-01-14 01:22:33,282 iteration 4795 : loss : 0.024416, loss_ce: 0.008066
2022-01-14 01:22:34,724 iteration 4796 : loss : 0.023254, loss_ce: 0.005297
2022-01-14 01:22:36,142 iteration 4797 : loss : 0.018012, loss_ce: 0.007256
2022-01-14 01:22:37,603 iteration 4798 : loss : 0.023218, loss_ce: 0.008549
2022-01-14 01:22:38,998 iteration 4799 : loss : 0.022015, loss_ce: 0.005063
2022-01-14 01:22:40,419 iteration 4800 : loss : 0.026268, loss_ce: 0.008871
2022-01-14 01:22:41,804 iteration 4801 : loss : 0.019575, loss_ce: 0.008551
2022-01-14 01:22:43,280 iteration 4802 : loss : 0.021148, loss_ce: 0.007942
2022-01-14 01:22:44,682 iteration 4803 : loss : 0.016393, loss_ce: 0.006223
2022-01-14 01:22:46,106 iteration 4804 : loss : 0.016384, loss_ce: 0.006264
2022-01-14 01:22:47,604 iteration 4805 : loss : 0.029142, loss_ce: 0.010970
2022-01-14 01:22:49,052 iteration 4806 : loss : 0.033233, loss_ce: 0.008651
2022-01-14 01:22:50,398 iteration 4807 : loss : 0.020134, loss_ce: 0.005317
2022-01-14 01:22:51,847 iteration 4808 : loss : 0.021095, loss_ce: 0.007237
2022-01-14 01:22:53,209 iteration 4809 : loss : 0.015510, loss_ce: 0.007382
2022-01-14 01:22:54,614 iteration 4810 : loss : 0.023684, loss_ce: 0.008317
2022-01-14 01:22:56,046 iteration 4811 : loss : 0.030030, loss_ce: 0.010571
 71%|████████████████████▌        | 283/400 [2:03:09<49:26, 25.36s/it]2022-01-14 01:22:57,508 iteration 4812 : loss : 0.024930, loss_ce: 0.008500
2022-01-14 01:22:58,872 iteration 4813 : loss : 0.016692, loss_ce: 0.006714
2022-01-14 01:23:00,389 iteration 4814 : loss : 0.041061, loss_ce: 0.017343
2022-01-14 01:23:01,776 iteration 4815 : loss : 0.017760, loss_ce: 0.006145
2022-01-14 01:23:03,165 iteration 4816 : loss : 0.027326, loss_ce: 0.010125
2022-01-14 01:23:04,540 iteration 4817 : loss : 0.016440, loss_ce: 0.006211
2022-01-14 01:23:05,919 iteration 4818 : loss : 0.025221, loss_ce: 0.009005
2022-01-14 01:23:07,345 iteration 4819 : loss : 0.021199, loss_ce: 0.006514
2022-01-14 01:23:08,718 iteration 4820 : loss : 0.019869, loss_ce: 0.008313
2022-01-14 01:23:10,114 iteration 4821 : loss : 0.019634, loss_ce: 0.006250
2022-01-14 01:23:11,564 iteration 4822 : loss : 0.023243, loss_ce: 0.008887
2022-01-14 01:23:12,989 iteration 4823 : loss : 0.030193, loss_ce: 0.006963
2022-01-14 01:23:14,351 iteration 4824 : loss : 0.019502, loss_ce: 0.006259
2022-01-14 01:23:15,803 iteration 4825 : loss : 0.019291, loss_ce: 0.009057
2022-01-14 01:23:17,384 iteration 4826 : loss : 0.028141, loss_ce: 0.012159
2022-01-14 01:23:18,745 iteration 4827 : loss : 0.019871, loss_ce: 0.010166
2022-01-14 01:23:20,104 iteration 4828 : loss : 0.018004, loss_ce: 0.006361
 71%|████████████████████▌        | 284/400 [2:03:33<48:15, 24.97s/it]2022-01-14 01:23:21,526 iteration 4829 : loss : 0.016328, loss_ce: 0.007856
2022-01-14 01:23:22,970 iteration 4830 : loss : 0.028556, loss_ce: 0.013296
2022-01-14 01:23:24,412 iteration 4831 : loss : 0.020556, loss_ce: 0.010171
2022-01-14 01:23:25,840 iteration 4832 : loss : 0.024915, loss_ce: 0.009926
2022-01-14 01:23:27,234 iteration 4833 : loss : 0.027706, loss_ce: 0.013470
2022-01-14 01:23:28,721 iteration 4834 : loss : 0.018318, loss_ce: 0.006681
2022-01-14 01:23:30,100 iteration 4835 : loss : 0.022969, loss_ce: 0.010041
2022-01-14 01:23:31,469 iteration 4836 : loss : 0.027048, loss_ce: 0.007956
2022-01-14 01:23:32,885 iteration 4837 : loss : 0.020257, loss_ce: 0.006108
2022-01-14 01:23:34,296 iteration 4838 : loss : 0.031130, loss_ce: 0.012756
2022-01-14 01:23:35,593 iteration 4839 : loss : 0.020911, loss_ce: 0.008342
2022-01-14 01:23:36,972 iteration 4840 : loss : 0.025316, loss_ce: 0.009222
2022-01-14 01:23:38,403 iteration 4841 : loss : 0.026652, loss_ce: 0.011112
2022-01-14 01:23:39,831 iteration 4842 : loss : 0.037187, loss_ce: 0.019149
2022-01-14 01:23:41,225 iteration 4843 : loss : 0.020483, loss_ce: 0.007004
2022-01-14 01:23:42,670 iteration 4844 : loss : 0.021123, loss_ce: 0.005747
2022-01-14 01:23:42,670 Training Data Eval:
2022-01-14 01:23:49,698   Average segmentation loss on training set: 0.0126
2022-01-14 01:23:49,698 Validation Data Eval:
2022-01-14 01:23:52,184   Average segmentation loss on validation set: 0.0819
2022-01-14 01:23:53,593 iteration 4845 : loss : 0.018654, loss_ce: 0.006460
 71%|████████████████████▋        | 285/400 [2:04:07<52:45, 27.53s/it]2022-01-14 01:23:55,078 iteration 4846 : loss : 0.021204, loss_ce: 0.009529
2022-01-14 01:23:56,449 iteration 4847 : loss : 0.014190, loss_ce: 0.004783
2022-01-14 01:23:57,958 iteration 4848 : loss : 0.022713, loss_ce: 0.009960
2022-01-14 01:23:59,347 iteration 4849 : loss : 0.020679, loss_ce: 0.007189
2022-01-14 01:24:00,715 iteration 4850 : loss : 0.015631, loss_ce: 0.007184
2022-01-14 01:24:02,234 iteration 4851 : loss : 0.028907, loss_ce: 0.007667
2022-01-14 01:24:03,651 iteration 4852 : loss : 0.018935, loss_ce: 0.008778
2022-01-14 01:24:05,107 iteration 4853 : loss : 0.020337, loss_ce: 0.005262
2022-01-14 01:24:06,641 iteration 4854 : loss : 0.025620, loss_ce: 0.008628
2022-01-14 01:24:08,080 iteration 4855 : loss : 0.025258, loss_ce: 0.009173
2022-01-14 01:24:09,426 iteration 4856 : loss : 0.023241, loss_ce: 0.007448
2022-01-14 01:24:10,893 iteration 4857 : loss : 0.019315, loss_ce: 0.008997
2022-01-14 01:24:12,341 iteration 4858 : loss : 0.025597, loss_ce: 0.010556
2022-01-14 01:24:13,767 iteration 4859 : loss : 0.017581, loss_ce: 0.008173
2022-01-14 01:24:15,231 iteration 4860 : loss : 0.039107, loss_ce: 0.015797
2022-01-14 01:24:16,652 iteration 4861 : loss : 0.020794, loss_ce: 0.008606
2022-01-14 01:24:18,021 iteration 4862 : loss : 0.017277, loss_ce: 0.006812
 72%|████████████████████▋        | 286/400 [2:04:31<50:31, 26.60s/it]2022-01-14 01:24:19,474 iteration 4863 : loss : 0.018896, loss_ce: 0.006101
2022-01-14 01:24:20,952 iteration 4864 : loss : 0.040568, loss_ce: 0.014852
2022-01-14 01:24:22,468 iteration 4865 : loss : 0.034687, loss_ce: 0.009972
2022-01-14 01:24:23,862 iteration 4866 : loss : 0.017164, loss_ce: 0.007055
2022-01-14 01:24:25,277 iteration 4867 : loss : 0.020033, loss_ce: 0.008861
2022-01-14 01:24:26,657 iteration 4868 : loss : 0.031630, loss_ce: 0.017896
2022-01-14 01:24:28,039 iteration 4869 : loss : 0.019244, loss_ce: 0.007389
2022-01-14 01:24:29,527 iteration 4870 : loss : 0.025361, loss_ce: 0.008655
2022-01-14 01:24:30,962 iteration 4871 : loss : 0.019022, loss_ce: 0.007408
2022-01-14 01:24:32,298 iteration 4872 : loss : 0.021538, loss_ce: 0.007838
2022-01-14 01:24:33,629 iteration 4873 : loss : 0.020835, loss_ce: 0.007313
2022-01-14 01:24:34,944 iteration 4874 : loss : 0.014071, loss_ce: 0.006020
2022-01-14 01:24:36,357 iteration 4875 : loss : 0.015852, loss_ce: 0.005509
2022-01-14 01:24:37,698 iteration 4876 : loss : 0.017639, loss_ce: 0.006085
2022-01-14 01:24:39,238 iteration 4877 : loss : 0.024558, loss_ce: 0.010366
2022-01-14 01:24:40,664 iteration 4878 : loss : 0.026377, loss_ce: 0.008680
2022-01-14 01:24:42,059 iteration 4879 : loss : 0.020598, loss_ce: 0.008104
 72%|████████████████████▊        | 287/400 [2:04:55<48:38, 25.83s/it]2022-01-14 01:24:43,600 iteration 4880 : loss : 0.036607, loss_ce: 0.021032
2022-01-14 01:24:44,972 iteration 4881 : loss : 0.029122, loss_ce: 0.009540
2022-01-14 01:24:46,361 iteration 4882 : loss : 0.017129, loss_ce: 0.004952
2022-01-14 01:24:47,768 iteration 4883 : loss : 0.020754, loss_ce: 0.006663
2022-01-14 01:24:49,179 iteration 4884 : loss : 0.017550, loss_ce: 0.011001
2022-01-14 01:24:50,708 iteration 4885 : loss : 0.021150, loss_ce: 0.006409
2022-01-14 01:24:52,178 iteration 4886 : loss : 0.019792, loss_ce: 0.006617
2022-01-14 01:24:53,649 iteration 4887 : loss : 0.036190, loss_ce: 0.012901
2022-01-14 01:24:55,033 iteration 4888 : loss : 0.025917, loss_ce: 0.007429
2022-01-14 01:24:56,435 iteration 4889 : loss : 0.023571, loss_ce: 0.008209
2022-01-14 01:24:57,893 iteration 4890 : loss : 0.031188, loss_ce: 0.011834
2022-01-14 01:24:59,363 iteration 4891 : loss : 0.021383, loss_ce: 0.011595
2022-01-14 01:25:00,733 iteration 4892 : loss : 0.020214, loss_ce: 0.008088
2022-01-14 01:25:02,091 iteration 4893 : loss : 0.019367, loss_ce: 0.009156
2022-01-14 01:25:03,485 iteration 4894 : loss : 0.021800, loss_ce: 0.005715
2022-01-14 01:25:04,866 iteration 4895 : loss : 0.024144, loss_ce: 0.010307
2022-01-14 01:25:06,282 iteration 4896 : loss : 0.021795, loss_ce: 0.007919
 72%|████████████████████▉        | 288/400 [2:05:19<47:18, 25.34s/it]2022-01-14 01:25:07,750 iteration 4897 : loss : 0.027879, loss_ce: 0.011332
2022-01-14 01:25:09,200 iteration 4898 : loss : 0.030033, loss_ce: 0.011160
2022-01-14 01:25:10,491 iteration 4899 : loss : 0.017933, loss_ce: 0.007142
2022-01-14 01:25:12,013 iteration 4900 : loss : 0.024215, loss_ce: 0.009552
2022-01-14 01:25:13,398 iteration 4901 : loss : 0.017423, loss_ce: 0.004561
2022-01-14 01:25:14,857 iteration 4902 : loss : 0.028156, loss_ce: 0.009877
2022-01-14 01:25:16,371 iteration 4903 : loss : 0.025951, loss_ce: 0.011931
2022-01-14 01:25:17,837 iteration 4904 : loss : 0.028664, loss_ce: 0.014098
2022-01-14 01:25:19,258 iteration 4905 : loss : 0.030084, loss_ce: 0.009510
2022-01-14 01:25:20,692 iteration 4906 : loss : 0.035160, loss_ce: 0.013394
2022-01-14 01:25:21,999 iteration 4907 : loss : 0.016225, loss_ce: 0.005967
2022-01-14 01:25:23,345 iteration 4908 : loss : 0.019839, loss_ce: 0.008053
2022-01-14 01:25:24,752 iteration 4909 : loss : 0.015486, loss_ce: 0.005337
2022-01-14 01:25:26,135 iteration 4910 : loss : 0.019793, loss_ce: 0.007386
2022-01-14 01:25:27,486 iteration 4911 : loss : 0.022705, loss_ce: 0.007462
2022-01-14 01:25:28,934 iteration 4912 : loss : 0.028328, loss_ce: 0.009460
2022-01-14 01:25:30,329 iteration 4913 : loss : 0.021291, loss_ce: 0.006529
 72%|████████████████████▉        | 289/400 [2:05:43<46:10, 24.96s/it]2022-01-14 01:25:31,722 iteration 4914 : loss : 0.022591, loss_ce: 0.009023
2022-01-14 01:25:33,139 iteration 4915 : loss : 0.024112, loss_ce: 0.011937
2022-01-14 01:25:34,586 iteration 4916 : loss : 0.037673, loss_ce: 0.013524
2022-01-14 01:25:35,984 iteration 4917 : loss : 0.018483, loss_ce: 0.006405
2022-01-14 01:25:37,392 iteration 4918 : loss : 0.022879, loss_ce: 0.009217
2022-01-14 01:25:38,771 iteration 4919 : loss : 0.014896, loss_ce: 0.006088
2022-01-14 01:25:40,250 iteration 4920 : loss : 0.040616, loss_ce: 0.014752
2022-01-14 01:25:41,583 iteration 4921 : loss : 0.019404, loss_ce: 0.006594
2022-01-14 01:25:43,019 iteration 4922 : loss : 0.019080, loss_ce: 0.006149
2022-01-14 01:25:44,440 iteration 4923 : loss : 0.019303, loss_ce: 0.006620
2022-01-14 01:25:45,861 iteration 4924 : loss : 0.026139, loss_ce: 0.014379
2022-01-14 01:25:47,246 iteration 4925 : loss : 0.022560, loss_ce: 0.008493
2022-01-14 01:25:48,580 iteration 4926 : loss : 0.015874, loss_ce: 0.006969
2022-01-14 01:25:50,023 iteration 4927 : loss : 0.015982, loss_ce: 0.005384
2022-01-14 01:25:51,457 iteration 4928 : loss : 0.019247, loss_ce: 0.009241
2022-01-14 01:25:52,837 iteration 4929 : loss : 0.021535, loss_ce: 0.006031
2022-01-14 01:25:52,837 Training Data Eval:
2022-01-14 01:25:59,934   Average segmentation loss on training set: 0.0133
2022-01-14 01:25:59,934 Validation Data Eval:
2022-01-14 01:26:02,385   Average segmentation loss on validation set: 0.0757
2022-01-14 01:26:03,816 iteration 4930 : loss : 0.018379, loss_ce: 0.005924
 72%|█████████████████████        | 290/400 [2:06:17<50:27, 27.52s/it]2022-01-14 01:26:05,348 iteration 4931 : loss : 0.024231, loss_ce: 0.011023
2022-01-14 01:26:06,793 iteration 4932 : loss : 0.023768, loss_ce: 0.007412
2022-01-14 01:26:08,159 iteration 4933 : loss : 0.024661, loss_ce: 0.010026
2022-01-14 01:26:09,578 iteration 4934 : loss : 0.022786, loss_ce: 0.009207
2022-01-14 01:26:10,962 iteration 4935 : loss : 0.028240, loss_ce: 0.008107
2022-01-14 01:26:12,397 iteration 4936 : loss : 0.020206, loss_ce: 0.008113
2022-01-14 01:26:13,754 iteration 4937 : loss : 0.021887, loss_ce: 0.006513
2022-01-14 01:26:15,091 iteration 4938 : loss : 0.018374, loss_ce: 0.007274
2022-01-14 01:26:16,608 iteration 4939 : loss : 0.034114, loss_ce: 0.014767
2022-01-14 01:26:17,960 iteration 4940 : loss : 0.018874, loss_ce: 0.007704
2022-01-14 01:26:19,360 iteration 4941 : loss : 0.022874, loss_ce: 0.008782
2022-01-14 01:26:20,942 iteration 4942 : loss : 0.040885, loss_ce: 0.017865
2022-01-14 01:26:22,315 iteration 4943 : loss : 0.023015, loss_ce: 0.009342
2022-01-14 01:26:23,701 iteration 4944 : loss : 0.024301, loss_ce: 0.013774
2022-01-14 01:26:25,114 iteration 4945 : loss : 0.015838, loss_ce: 0.006172
2022-01-14 01:26:26,463 iteration 4946 : loss : 0.019002, loss_ce: 0.006946
2022-01-14 01:26:27,931 iteration 4947 : loss : 0.028731, loss_ce: 0.012378
 73%|█████████████████████        | 291/400 [2:06:41<48:07, 26.49s/it]2022-01-14 01:26:29,420 iteration 4948 : loss : 0.025332, loss_ce: 0.009172
2022-01-14 01:26:30,933 iteration 4949 : loss : 0.038911, loss_ce: 0.017762
2022-01-14 01:26:32,324 iteration 4950 : loss : 0.028739, loss_ce: 0.014249
2022-01-14 01:26:33,745 iteration 4951 : loss : 0.027494, loss_ce: 0.009826
2022-01-14 01:26:35,158 iteration 4952 : loss : 0.018694, loss_ce: 0.006858
2022-01-14 01:26:36,654 iteration 4953 : loss : 0.026816, loss_ce: 0.008132
2022-01-14 01:26:37,980 iteration 4954 : loss : 0.022572, loss_ce: 0.007503
2022-01-14 01:26:39,350 iteration 4955 : loss : 0.017208, loss_ce: 0.008147
2022-01-14 01:26:40,809 iteration 4956 : loss : 0.023341, loss_ce: 0.006952
2022-01-14 01:26:42,213 iteration 4957 : loss : 0.018847, loss_ce: 0.007613
2022-01-14 01:26:43,779 iteration 4958 : loss : 0.029382, loss_ce: 0.013763
2022-01-14 01:26:45,255 iteration 4959 : loss : 0.021803, loss_ce: 0.009328
2022-01-14 01:26:46,783 iteration 4960 : loss : 0.024562, loss_ce: 0.011159
2022-01-14 01:26:48,171 iteration 4961 : loss : 0.033284, loss_ce: 0.009623
2022-01-14 01:26:49,569 iteration 4962 : loss : 0.018359, loss_ce: 0.007786
2022-01-14 01:26:51,019 iteration 4963 : loss : 0.028899, loss_ce: 0.009510
2022-01-14 01:26:52,462 iteration 4964 : loss : 0.015684, loss_ce: 0.004971
 73%|█████████████████████▏       | 292/400 [2:07:05<46:37, 25.91s/it]2022-01-14 01:26:53,889 iteration 4965 : loss : 0.022754, loss_ce: 0.007115
2022-01-14 01:26:55,306 iteration 4966 : loss : 0.020763, loss_ce: 0.008215
2022-01-14 01:26:56,709 iteration 4967 : loss : 0.022016, loss_ce: 0.006129
2022-01-14 01:26:58,122 iteration 4968 : loss : 0.026393, loss_ce: 0.006389
2022-01-14 01:26:59,550 iteration 4969 : loss : 0.025435, loss_ce: 0.010056
2022-01-14 01:27:00,986 iteration 4970 : loss : 0.039141, loss_ce: 0.022852
2022-01-14 01:27:02,363 iteration 4971 : loss : 0.018365, loss_ce: 0.007603
2022-01-14 01:27:03,751 iteration 4972 : loss : 0.020447, loss_ce: 0.006628
2022-01-14 01:27:05,168 iteration 4973 : loss : 0.022192, loss_ce: 0.006980
2022-01-14 01:27:06,609 iteration 4974 : loss : 0.017568, loss_ce: 0.008713
2022-01-14 01:27:08,120 iteration 4975 : loss : 0.022241, loss_ce: 0.008310
2022-01-14 01:27:09,495 iteration 4976 : loss : 0.030081, loss_ce: 0.009261
2022-01-14 01:27:10,903 iteration 4977 : loss : 0.022409, loss_ce: 0.009632
2022-01-14 01:27:12,337 iteration 4978 : loss : 0.037733, loss_ce: 0.016581
2022-01-14 01:27:13,720 iteration 4979 : loss : 0.020547, loss_ce: 0.007349
2022-01-14 01:27:15,079 iteration 4980 : loss : 0.013498, loss_ce: 0.004634
2022-01-14 01:27:16,494 iteration 4981 : loss : 0.021665, loss_ce: 0.007842
 73%|█████████████████████▏       | 293/400 [2:07:29<45:12, 25.35s/it]2022-01-14 01:27:18,015 iteration 4982 : loss : 0.036279, loss_ce: 0.009690
2022-01-14 01:27:19,375 iteration 4983 : loss : 0.016846, loss_ce: 0.005888
2022-01-14 01:27:20,855 iteration 4984 : loss : 0.016824, loss_ce: 0.004972
2022-01-14 01:27:22,200 iteration 4985 : loss : 0.014026, loss_ce: 0.004807
2022-01-14 01:27:23,578 iteration 4986 : loss : 0.019399, loss_ce: 0.006740
2022-01-14 01:27:24,998 iteration 4987 : loss : 0.019469, loss_ce: 0.009041
2022-01-14 01:27:26,433 iteration 4988 : loss : 0.022585, loss_ce: 0.010521
2022-01-14 01:27:27,825 iteration 4989 : loss : 0.030740, loss_ce: 0.013448
2022-01-14 01:27:29,268 iteration 4990 : loss : 0.025675, loss_ce: 0.011913
2022-01-14 01:27:30,660 iteration 4991 : loss : 0.020863, loss_ce: 0.007147
2022-01-14 01:27:32,080 iteration 4992 : loss : 0.033066, loss_ce: 0.010822
2022-01-14 01:27:33,496 iteration 4993 : loss : 0.022649, loss_ce: 0.010454
2022-01-14 01:27:35,026 iteration 4994 : loss : 0.050388, loss_ce: 0.026580
2022-01-14 01:27:36,484 iteration 4995 : loss : 0.023237, loss_ce: 0.010859
2022-01-14 01:27:37,872 iteration 4996 : loss : 0.019159, loss_ce: 0.005814
2022-01-14 01:27:39,319 iteration 4997 : loss : 0.023758, loss_ce: 0.009501
2022-01-14 01:27:40,763 iteration 4998 : loss : 0.021356, loss_ce: 0.008974
 74%|█████████████████████▎       | 294/400 [2:07:54<44:12, 25.02s/it]2022-01-14 01:27:42,263 iteration 4999 : loss : 0.019787, loss_ce: 0.007270
2022-01-14 01:27:43,635 iteration 5000 : loss : 0.019388, loss_ce: 0.006074
2022-01-14 01:27:45,110 iteration 5001 : loss : 0.031755, loss_ce: 0.009627
2022-01-14 01:27:46,629 iteration 5002 : loss : 0.027951, loss_ce: 0.007886
2022-01-14 01:27:48,134 iteration 5003 : loss : 0.027372, loss_ce: 0.015001
2022-01-14 01:27:49,528 iteration 5004 : loss : 0.017541, loss_ce: 0.008120
2022-01-14 01:27:50,973 iteration 5005 : loss : 0.022711, loss_ce: 0.009843
2022-01-14 01:27:52,317 iteration 5006 : loss : 0.020124, loss_ce: 0.007054
2022-01-14 01:27:53,746 iteration 5007 : loss : 0.025030, loss_ce: 0.005717
2022-01-14 01:27:55,096 iteration 5008 : loss : 0.019192, loss_ce: 0.005869
2022-01-14 01:27:56,439 iteration 5009 : loss : 0.019674, loss_ce: 0.009997
2022-01-14 01:27:57,891 iteration 5010 : loss : 0.020077, loss_ce: 0.008576
2022-01-14 01:27:59,252 iteration 5011 : loss : 0.016051, loss_ce: 0.006502
2022-01-14 01:28:00,641 iteration 5012 : loss : 0.023997, loss_ce: 0.006867
2022-01-14 01:28:02,149 iteration 5013 : loss : 0.030658, loss_ce: 0.016016
2022-01-14 01:28:03,502 iteration 5014 : loss : 0.018694, loss_ce: 0.006937
2022-01-14 01:28:03,503 Training Data Eval:
2022-01-14 01:28:10,717   Average segmentation loss on training set: 0.0136
2022-01-14 01:28:10,717 Validation Data Eval:
2022-01-14 01:28:13,251   Average segmentation loss on validation set: 0.0820
2022-01-14 01:28:14,670 iteration 5015 : loss : 0.020677, loss_ce: 0.007870
 74%|█████████████████████▍       | 295/400 [2:08:28<48:26, 27.69s/it]2022-01-14 01:28:16,180 iteration 5016 : loss : 0.023952, loss_ce: 0.009394
2022-01-14 01:28:17,488 iteration 5017 : loss : 0.021584, loss_ce: 0.007387
2022-01-14 01:28:18,979 iteration 5018 : loss : 0.021059, loss_ce: 0.010226
2022-01-14 01:28:20,314 iteration 5019 : loss : 0.018071, loss_ce: 0.006740
2022-01-14 01:28:21,762 iteration 5020 : loss : 0.025671, loss_ce: 0.007673
2022-01-14 01:28:23,159 iteration 5021 : loss : 0.036381, loss_ce: 0.014031
2022-01-14 01:28:24,580 iteration 5022 : loss : 0.022198, loss_ce: 0.007996
2022-01-14 01:28:25,999 iteration 5023 : loss : 0.020900, loss_ce: 0.009466
2022-01-14 01:28:27,480 iteration 5024 : loss : 0.025830, loss_ce: 0.010106
2022-01-14 01:28:28,916 iteration 5025 : loss : 0.024445, loss_ce: 0.008621
2022-01-14 01:28:30,378 iteration 5026 : loss : 0.041347, loss_ce: 0.013345
2022-01-14 01:28:31,755 iteration 5027 : loss : 0.023220, loss_ce: 0.008311
2022-01-14 01:28:33,123 iteration 5028 : loss : 0.017920, loss_ce: 0.007390
2022-01-14 01:28:34,605 iteration 5029 : loss : 0.031631, loss_ce: 0.011343
2022-01-14 01:28:35,990 iteration 5030 : loss : 0.019526, loss_ce: 0.008132
2022-01-14 01:28:37,464 iteration 5031 : loss : 0.037075, loss_ce: 0.013493
2022-01-14 01:28:38,805 iteration 5032 : loss : 0.020421, loss_ce: 0.008209
 74%|█████████████████████▍       | 296/400 [2:08:52<46:08, 26.62s/it]2022-01-14 01:28:40,215 iteration 5033 : loss : 0.023975, loss_ce: 0.009028
2022-01-14 01:28:41,602 iteration 5034 : loss : 0.027938, loss_ce: 0.007819
2022-01-14 01:28:43,007 iteration 5035 : loss : 0.022580, loss_ce: 0.007958
2022-01-14 01:28:44,380 iteration 5036 : loss : 0.019952, loss_ce: 0.008082
2022-01-14 01:28:45,797 iteration 5037 : loss : 0.021443, loss_ce: 0.007269
2022-01-14 01:28:47,166 iteration 5038 : loss : 0.021223, loss_ce: 0.006435
2022-01-14 01:28:48,587 iteration 5039 : loss : 0.033508, loss_ce: 0.012714
2022-01-14 01:28:50,032 iteration 5040 : loss : 0.026026, loss_ce: 0.010620
2022-01-14 01:28:51,436 iteration 5041 : loss : 0.029623, loss_ce: 0.012487
2022-01-14 01:28:52,927 iteration 5042 : loss : 0.029884, loss_ce: 0.010179
2022-01-14 01:28:54,236 iteration 5043 : loss : 0.026478, loss_ce: 0.008304
2022-01-14 01:28:55,691 iteration 5044 : loss : 0.026055, loss_ce: 0.009796
2022-01-14 01:28:57,133 iteration 5045 : loss : 0.030221, loss_ce: 0.015497
2022-01-14 01:28:58,567 iteration 5046 : loss : 0.031552, loss_ce: 0.007546
2022-01-14 01:28:59,925 iteration 5047 : loss : 0.014603, loss_ce: 0.004222
2022-01-14 01:29:01,277 iteration 5048 : loss : 0.023135, loss_ce: 0.013055
2022-01-14 01:29:02,612 iteration 5049 : loss : 0.021205, loss_ce: 0.010524
 74%|█████████████████████▌       | 297/400 [2:09:16<44:14, 25.78s/it]2022-01-14 01:29:04,116 iteration 5050 : loss : 0.019747, loss_ce: 0.006603
2022-01-14 01:29:05,601 iteration 5051 : loss : 0.029797, loss_ce: 0.010582
2022-01-14 01:29:07,122 iteration 5052 : loss : 0.038563, loss_ce: 0.015950
2022-01-14 01:29:08,603 iteration 5053 : loss : 0.029621, loss_ce: 0.009697
2022-01-14 01:29:09,981 iteration 5054 : loss : 0.024819, loss_ce: 0.006080
2022-01-14 01:29:11,418 iteration 5055 : loss : 0.019002, loss_ce: 0.006542
2022-01-14 01:29:12,838 iteration 5056 : loss : 0.021428, loss_ce: 0.008414
2022-01-14 01:29:14,319 iteration 5057 : loss : 0.041989, loss_ce: 0.021529
2022-01-14 01:29:15,826 iteration 5058 : loss : 0.027867, loss_ce: 0.010610
2022-01-14 01:29:17,220 iteration 5059 : loss : 0.018442, loss_ce: 0.007371
2022-01-14 01:29:18,664 iteration 5060 : loss : 0.023898, loss_ce: 0.012162
2022-01-14 01:29:20,147 iteration 5061 : loss : 0.022556, loss_ce: 0.008908
2022-01-14 01:29:21,646 iteration 5062 : loss : 0.030470, loss_ce: 0.012423
2022-01-14 01:29:23,155 iteration 5063 : loss : 0.037045, loss_ce: 0.012149
2022-01-14 01:29:24,543 iteration 5064 : loss : 0.019216, loss_ce: 0.006357
2022-01-14 01:29:26,005 iteration 5065 : loss : 0.024769, loss_ce: 0.011956
2022-01-14 01:29:27,360 iteration 5066 : loss : 0.018386, loss_ce: 0.007312
 74%|█████████████████████▌       | 298/400 [2:09:40<43:17, 25.47s/it]2022-01-14 01:29:28,697 iteration 5067 : loss : 0.020595, loss_ce: 0.007112
2022-01-14 01:29:30,136 iteration 5068 : loss : 0.026399, loss_ce: 0.006237
2022-01-14 01:29:31,565 iteration 5069 : loss : 0.018979, loss_ce: 0.008849
2022-01-14 01:29:32,913 iteration 5070 : loss : 0.022145, loss_ce: 0.007274
2022-01-14 01:29:34,354 iteration 5071 : loss : 0.028692, loss_ce: 0.013023
2022-01-14 01:29:35,684 iteration 5072 : loss : 0.018146, loss_ce: 0.006523
2022-01-14 01:29:37,160 iteration 5073 : loss : 0.024764, loss_ce: 0.010559
2022-01-14 01:29:38,538 iteration 5074 : loss : 0.032240, loss_ce: 0.015074
2022-01-14 01:29:39,934 iteration 5075 : loss : 0.024078, loss_ce: 0.009875
2022-01-14 01:29:41,359 iteration 5076 : loss : 0.026910, loss_ce: 0.005286
2022-01-14 01:29:42,776 iteration 5077 : loss : 0.028581, loss_ce: 0.010891
2022-01-14 01:29:44,140 iteration 5078 : loss : 0.022681, loss_ce: 0.010588
2022-01-14 01:29:45,486 iteration 5079 : loss : 0.016908, loss_ce: 0.007253
2022-01-14 01:29:46,864 iteration 5080 : loss : 0.017428, loss_ce: 0.006645
2022-01-14 01:29:48,329 iteration 5081 : loss : 0.022573, loss_ce: 0.006441
2022-01-14 01:29:49,721 iteration 5082 : loss : 0.016608, loss_ce: 0.006208
2022-01-14 01:29:51,155 iteration 5083 : loss : 0.026371, loss_ce: 0.006120
 75%|█████████████████████▋       | 299/400 [2:10:04<42:01, 24.97s/it]2022-01-14 01:29:52,668 iteration 5084 : loss : 0.022728, loss_ce: 0.011005
2022-01-14 01:29:54,153 iteration 5085 : loss : 0.029086, loss_ce: 0.009921
2022-01-14 01:29:55,616 iteration 5086 : loss : 0.015995, loss_ce: 0.004861
2022-01-14 01:29:56,958 iteration 5087 : loss : 0.018753, loss_ce: 0.008048
2022-01-14 01:29:58,309 iteration 5088 : loss : 0.020630, loss_ce: 0.008439
2022-01-14 01:29:59,751 iteration 5089 : loss : 0.020375, loss_ce: 0.005930
2022-01-14 01:30:01,176 iteration 5090 : loss : 0.017134, loss_ce: 0.003758
2022-01-14 01:30:02,640 iteration 5091 : loss : 0.029289, loss_ce: 0.010712
2022-01-14 01:30:04,082 iteration 5092 : loss : 0.029013, loss_ce: 0.010995
2022-01-14 01:30:05,439 iteration 5093 : loss : 0.027569, loss_ce: 0.007371
2022-01-14 01:30:06,878 iteration 5094 : loss : 0.033772, loss_ce: 0.012010
2022-01-14 01:30:08,234 iteration 5095 : loss : 0.018534, loss_ce: 0.007438
2022-01-14 01:30:09,623 iteration 5096 : loss : 0.021641, loss_ce: 0.011171
2022-01-14 01:30:10,962 iteration 5097 : loss : 0.020030, loss_ce: 0.009000
2022-01-14 01:30:12,465 iteration 5098 : loss : 0.030980, loss_ce: 0.009698
2022-01-14 01:30:13,892 iteration 5099 : loss : 0.025251, loss_ce: 0.007478
2022-01-14 01:30:13,892 Training Data Eval:
2022-01-14 01:30:20,952   Average segmentation loss on training set: 0.0133
2022-01-14 01:30:20,952 Validation Data Eval:
2022-01-14 01:30:23,463   Average segmentation loss on validation set: 0.0821
2022-01-14 01:30:24,983 iteration 5100 : loss : 0.025498, loss_ce: 0.006717
 75%|█████████████████████▊       | 300/400 [2:10:38<46:02, 27.63s/it]2022-01-14 01:30:26,539 iteration 5101 : loss : 0.029243, loss_ce: 0.012579
2022-01-14 01:30:27,925 iteration 5102 : loss : 0.022900, loss_ce: 0.008931
2022-01-14 01:30:29,340 iteration 5103 : loss : 0.038587, loss_ce: 0.020888
2022-01-14 01:30:30,807 iteration 5104 : loss : 0.022759, loss_ce: 0.007279
2022-01-14 01:30:32,179 iteration 5105 : loss : 0.020117, loss_ce: 0.007989
2022-01-14 01:30:33,560 iteration 5106 : loss : 0.017336, loss_ce: 0.006357
2022-01-14 01:30:35,020 iteration 5107 : loss : 0.023234, loss_ce: 0.006669
2022-01-14 01:30:36,459 iteration 5108 : loss : 0.023037, loss_ce: 0.010971
2022-01-14 01:30:37,860 iteration 5109 : loss : 0.026649, loss_ce: 0.009511
2022-01-14 01:30:39,209 iteration 5110 : loss : 0.016927, loss_ce: 0.005277
2022-01-14 01:30:40,642 iteration 5111 : loss : 0.023992, loss_ce: 0.009094
2022-01-14 01:30:42,136 iteration 5112 : loss : 0.019551, loss_ce: 0.006437
2022-01-14 01:30:43,558 iteration 5113 : loss : 0.020355, loss_ce: 0.006755
2022-01-14 01:30:45,045 iteration 5114 : loss : 0.030786, loss_ce: 0.014577
2022-01-14 01:30:46,439 iteration 5115 : loss : 0.023162, loss_ce: 0.007109
2022-01-14 01:30:47,817 iteration 5116 : loss : 0.015690, loss_ce: 0.006181
2022-01-14 01:30:49,253 iteration 5117 : loss : 0.026344, loss_ce: 0.011380
 75%|█████████████████████▊       | 301/400 [2:11:02<43:56, 26.63s/it]2022-01-14 01:30:50,786 iteration 5118 : loss : 0.029366, loss_ce: 0.008262
2022-01-14 01:30:52,185 iteration 5119 : loss : 0.020002, loss_ce: 0.008068
2022-01-14 01:30:53,528 iteration 5120 : loss : 0.015213, loss_ce: 0.006328
2022-01-14 01:30:54,978 iteration 5121 : loss : 0.020937, loss_ce: 0.005595
2022-01-14 01:30:56,476 iteration 5122 : loss : 0.022292, loss_ce: 0.009238
2022-01-14 01:30:57,948 iteration 5123 : loss : 0.036442, loss_ce: 0.012266
2022-01-14 01:30:59,306 iteration 5124 : loss : 0.016559, loss_ce: 0.007937
2022-01-14 01:31:00,651 iteration 5125 : loss : 0.018773, loss_ce: 0.006326
2022-01-14 01:31:02,072 iteration 5126 : loss : 0.036253, loss_ce: 0.013290
2022-01-14 01:31:03,455 iteration 5127 : loss : 0.025947, loss_ce: 0.011040
2022-01-14 01:31:04,808 iteration 5128 : loss : 0.020140, loss_ce: 0.006938
2022-01-14 01:31:06,233 iteration 5129 : loss : 0.019663, loss_ce: 0.007741
2022-01-14 01:31:07,621 iteration 5130 : loss : 0.017376, loss_ce: 0.006922
2022-01-14 01:31:09,047 iteration 5131 : loss : 0.017369, loss_ce: 0.006743
2022-01-14 01:31:10,438 iteration 5132 : loss : 0.021823, loss_ce: 0.007822
2022-01-14 01:31:11,907 iteration 5133 : loss : 0.035798, loss_ce: 0.016592
2022-01-14 01:31:13,302 iteration 5134 : loss : 0.021795, loss_ce: 0.005504
 76%|█████████████████████▉       | 302/400 [2:11:26<42:12, 25.84s/it]2022-01-14 01:31:14,737 iteration 5135 : loss : 0.021960, loss_ce: 0.010127
2022-01-14 01:31:16,141 iteration 5136 : loss : 0.015587, loss_ce: 0.004831
2022-01-14 01:31:17,478 iteration 5137 : loss : 0.018190, loss_ce: 0.006380
2022-01-14 01:31:18,902 iteration 5138 : loss : 0.015050, loss_ce: 0.006911
2022-01-14 01:31:20,426 iteration 5139 : loss : 0.024871, loss_ce: 0.010368
2022-01-14 01:31:21,891 iteration 5140 : loss : 0.052631, loss_ce: 0.016840
2022-01-14 01:31:23,253 iteration 5141 : loss : 0.026603, loss_ce: 0.008774
2022-01-14 01:31:24,667 iteration 5142 : loss : 0.021767, loss_ce: 0.006309
2022-01-14 01:31:26,049 iteration 5143 : loss : 0.016569, loss_ce: 0.007969
2022-01-14 01:31:27,545 iteration 5144 : loss : 0.020427, loss_ce: 0.008995
2022-01-14 01:31:29,076 iteration 5145 : loss : 0.016257, loss_ce: 0.004722
2022-01-14 01:31:30,539 iteration 5146 : loss : 0.014681, loss_ce: 0.004614
2022-01-14 01:31:31,877 iteration 5147 : loss : 0.017264, loss_ce: 0.004161
2022-01-14 01:31:33,282 iteration 5148 : loss : 0.020632, loss_ce: 0.007082
2022-01-14 01:31:34,659 iteration 5149 : loss : 0.024068, loss_ce: 0.008573
2022-01-14 01:31:36,039 iteration 5150 : loss : 0.019568, loss_ce: 0.010519
2022-01-14 01:31:37,496 iteration 5151 : loss : 0.022771, loss_ce: 0.009926
 76%|█████████████████████▉       | 303/400 [2:11:50<40:59, 25.35s/it]2022-01-14 01:31:38,939 iteration 5152 : loss : 0.020323, loss_ce: 0.008562
2022-01-14 01:31:40,355 iteration 5153 : loss : 0.019953, loss_ce: 0.007289
2022-01-14 01:31:41,682 iteration 5154 : loss : 0.015142, loss_ce: 0.005038
2022-01-14 01:31:43,044 iteration 5155 : loss : 0.016581, loss_ce: 0.005864
2022-01-14 01:31:44,477 iteration 5156 : loss : 0.028204, loss_ce: 0.007630
2022-01-14 01:31:45,848 iteration 5157 : loss : 0.012763, loss_ce: 0.004867
2022-01-14 01:31:47,220 iteration 5158 : loss : 0.014526, loss_ce: 0.005224
2022-01-14 01:31:48,657 iteration 5159 : loss : 0.019546, loss_ce: 0.007909
2022-01-14 01:31:50,061 iteration 5160 : loss : 0.017466, loss_ce: 0.007822
2022-01-14 01:31:51,485 iteration 5161 : loss : 0.022492, loss_ce: 0.008013
2022-01-14 01:31:52,963 iteration 5162 : loss : 0.015658, loss_ce: 0.004022
2022-01-14 01:31:54,386 iteration 5163 : loss : 0.019467, loss_ce: 0.010784
2022-01-14 01:31:55,747 iteration 5164 : loss : 0.015160, loss_ce: 0.005488
2022-01-14 01:31:57,217 iteration 5165 : loss : 0.023620, loss_ce: 0.007895
2022-01-14 01:31:58,635 iteration 5166 : loss : 0.016893, loss_ce: 0.005809
2022-01-14 01:32:00,100 iteration 5167 : loss : 0.025679, loss_ce: 0.006800
2022-01-14 01:32:01,409 iteration 5168 : loss : 0.015183, loss_ce: 0.007054
 76%|██████████████████████       | 304/400 [2:12:14<39:52, 24.92s/it]2022-01-14 01:32:02,914 iteration 5169 : loss : 0.019743, loss_ce: 0.005186
2022-01-14 01:32:04,303 iteration 5170 : loss : 0.016908, loss_ce: 0.008728
2022-01-14 01:32:05,698 iteration 5171 : loss : 0.028338, loss_ce: 0.008841
2022-01-14 01:32:07,128 iteration 5172 : loss : 0.029366, loss_ce: 0.010161
2022-01-14 01:32:08,605 iteration 5173 : loss : 0.025547, loss_ce: 0.010050
2022-01-14 01:32:10,010 iteration 5174 : loss : 0.014023, loss_ce: 0.003957
2022-01-14 01:32:11,466 iteration 5175 : loss : 0.018972, loss_ce: 0.006351
2022-01-14 01:32:12,949 iteration 5176 : loss : 0.029586, loss_ce: 0.010647
2022-01-14 01:32:14,380 iteration 5177 : loss : 0.030389, loss_ce: 0.013494
2022-01-14 01:32:15,800 iteration 5178 : loss : 0.026638, loss_ce: 0.015008
2022-01-14 01:32:17,180 iteration 5179 : loss : 0.040175, loss_ce: 0.020795
2022-01-14 01:32:18,522 iteration 5180 : loss : 0.033540, loss_ce: 0.016485
2022-01-14 01:32:19,883 iteration 5181 : loss : 0.026222, loss_ce: 0.009508
2022-01-14 01:32:21,268 iteration 5182 : loss : 0.032752, loss_ce: 0.014413
2022-01-14 01:32:22,658 iteration 5183 : loss : 0.028103, loss_ce: 0.009840
2022-01-14 01:32:24,016 iteration 5184 : loss : 0.026412, loss_ce: 0.012721
2022-01-14 01:32:24,016 Training Data Eval:
2022-01-14 01:32:31,190   Average segmentation loss on training set: 0.0250
2022-01-14 01:32:31,190 Validation Data Eval:
2022-01-14 01:32:33,703   Average segmentation loss on validation set: 0.1256
2022-01-14 01:32:35,138 iteration 5185 : loss : 0.018648, loss_ce: 0.008515
 76%|██████████████████████       | 305/400 [2:12:48<43:38, 27.56s/it]2022-01-14 01:32:36,657 iteration 5186 : loss : 0.040059, loss_ce: 0.013980
2022-01-14 01:32:38,006 iteration 5187 : loss : 0.028479, loss_ce: 0.013377
2022-01-14 01:32:39,413 iteration 5188 : loss : 0.029112, loss_ce: 0.008550
2022-01-14 01:32:40,833 iteration 5189 : loss : 0.047033, loss_ce: 0.017255
2022-01-14 01:32:42,352 iteration 5190 : loss : 0.047257, loss_ce: 0.015732
2022-01-14 01:32:43,733 iteration 5191 : loss : 0.034236, loss_ce: 0.013412
2022-01-14 01:32:45,149 iteration 5192 : loss : 0.034923, loss_ce: 0.014953
2022-01-14 01:32:46,630 iteration 5193 : loss : 0.027050, loss_ce: 0.014496
2022-01-14 01:32:48,083 iteration 5194 : loss : 0.040136, loss_ce: 0.012497
2022-01-14 01:32:49,488 iteration 5195 : loss : 0.051564, loss_ce: 0.016452
2022-01-14 01:32:50,999 iteration 5196 : loss : 0.035034, loss_ce: 0.013233
2022-01-14 01:32:52,404 iteration 5197 : loss : 0.049048, loss_ce: 0.014540
2022-01-14 01:32:53,781 iteration 5198 : loss : 0.024828, loss_ce: 0.013403
2022-01-14 01:32:55,288 iteration 5199 : loss : 0.032913, loss_ce: 0.013046
2022-01-14 01:32:56,612 iteration 5200 : loss : 0.034625, loss_ce: 0.015906
2022-01-14 01:32:57,952 iteration 5201 : loss : 0.029527, loss_ce: 0.012263
2022-01-14 01:32:59,338 iteration 5202 : loss : 0.027610, loss_ce: 0.010382
 76%|██████████████████████▏      | 306/400 [2:13:12<41:36, 26.55s/it]2022-01-14 01:33:00,776 iteration 5203 : loss : 0.029642, loss_ce: 0.011118
2022-01-14 01:33:02,278 iteration 5204 : loss : 0.022421, loss_ce: 0.009053
2022-01-14 01:33:03,713 iteration 5205 : loss : 0.055014, loss_ce: 0.015918
2022-01-14 01:33:05,253 iteration 5206 : loss : 0.036666, loss_ce: 0.013875
2022-01-14 01:33:06,708 iteration 5207 : loss : 0.092042, loss_ce: 0.017743
2022-01-14 01:33:08,122 iteration 5208 : loss : 0.029945, loss_ce: 0.013167
2022-01-14 01:33:09,595 iteration 5209 : loss : 0.022237, loss_ce: 0.008592
2022-01-14 01:33:11,043 iteration 5210 : loss : 0.024544, loss_ce: 0.011887
2022-01-14 01:33:12,437 iteration 5211 : loss : 0.031255, loss_ce: 0.013957
2022-01-14 01:33:13,905 iteration 5212 : loss : 0.031022, loss_ce: 0.008864
2022-01-14 01:33:15,287 iteration 5213 : loss : 0.031183, loss_ce: 0.013444
2022-01-14 01:33:16,702 iteration 5214 : loss : 0.020626, loss_ce: 0.009706
2022-01-14 01:33:18,053 iteration 5215 : loss : 0.018844, loss_ce: 0.006901
2022-01-14 01:33:19,446 iteration 5216 : loss : 0.027323, loss_ce: 0.009104
2022-01-14 01:33:20,923 iteration 5217 : loss : 0.038168, loss_ce: 0.016177
2022-01-14 01:33:22,295 iteration 5218 : loss : 0.022639, loss_ce: 0.007775
2022-01-14 01:33:23,714 iteration 5219 : loss : 0.026255, loss_ce: 0.010518
 77%|██████████████████████▎      | 307/400 [2:13:37<40:08, 25.90s/it]2022-01-14 01:33:25,119 iteration 5220 : loss : 0.019359, loss_ce: 0.008385
2022-01-14 01:33:26,473 iteration 5221 : loss : 0.026264, loss_ce: 0.006687
2022-01-14 01:33:27,926 iteration 5222 : loss : 0.030108, loss_ce: 0.009889
2022-01-14 01:33:29,325 iteration 5223 : loss : 0.028645, loss_ce: 0.013690
2022-01-14 01:33:30,807 iteration 5224 : loss : 0.046191, loss_ce: 0.008343
2022-01-14 01:33:32,181 iteration 5225 : loss : 0.027273, loss_ce: 0.011834
2022-01-14 01:33:33,618 iteration 5226 : loss : 0.021968, loss_ce: 0.009555
2022-01-14 01:33:35,038 iteration 5227 : loss : 0.022322, loss_ce: 0.007768
2022-01-14 01:33:36,367 iteration 5228 : loss : 0.017625, loss_ce: 0.005935
2022-01-14 01:33:37,809 iteration 5229 : loss : 0.049354, loss_ce: 0.020537
2022-01-14 01:33:39,157 iteration 5230 : loss : 0.017838, loss_ce: 0.006783
2022-01-14 01:33:40,584 iteration 5231 : loss : 0.021791, loss_ce: 0.006240
2022-01-14 01:33:42,100 iteration 5232 : loss : 0.031295, loss_ce: 0.009730
2022-01-14 01:33:43,402 iteration 5233 : loss : 0.017638, loss_ce: 0.007270
2022-01-14 01:33:44,819 iteration 5234 : loss : 0.034070, loss_ce: 0.017404
2022-01-14 01:33:46,277 iteration 5235 : loss : 0.028632, loss_ce: 0.013921
2022-01-14 01:33:47,772 iteration 5236 : loss : 0.049112, loss_ce: 0.023338
 77%|██████████████████████▎      | 308/400 [2:14:01<38:51, 25.35s/it]2022-01-14 01:33:49,171 iteration 5237 : loss : 0.017773, loss_ce: 0.008151
2022-01-14 01:33:50,595 iteration 5238 : loss : 0.019583, loss_ce: 0.007903
2022-01-14 01:33:51,978 iteration 5239 : loss : 0.020053, loss_ce: 0.007104
2022-01-14 01:33:53,432 iteration 5240 : loss : 0.050702, loss_ce: 0.008908
2022-01-14 01:33:54,867 iteration 5241 : loss : 0.029384, loss_ce: 0.010656
2022-01-14 01:33:56,370 iteration 5242 : loss : 0.023943, loss_ce: 0.011221
2022-01-14 01:33:57,811 iteration 5243 : loss : 0.026209, loss_ce: 0.012858
2022-01-14 01:33:59,213 iteration 5244 : loss : 0.027158, loss_ce: 0.009774
2022-01-14 01:34:00,679 iteration 5245 : loss : 0.030046, loss_ce: 0.010644
2022-01-14 01:34:02,115 iteration 5246 : loss : 0.035637, loss_ce: 0.015703
2022-01-14 01:34:03,537 iteration 5247 : loss : 0.033516, loss_ce: 0.011223
2022-01-14 01:34:05,025 iteration 5248 : loss : 0.031345, loss_ce: 0.016819
2022-01-14 01:34:06,433 iteration 5249 : loss : 0.028049, loss_ce: 0.011420
2022-01-14 01:34:07,877 iteration 5250 : loss : 0.018665, loss_ce: 0.006788
2022-01-14 01:34:09,352 iteration 5251 : loss : 0.028000, loss_ce: 0.011760
2022-01-14 01:34:10,764 iteration 5252 : loss : 0.017823, loss_ce: 0.008728
2022-01-14 01:34:12,178 iteration 5253 : loss : 0.020796, loss_ce: 0.008848
 77%|██████████████████████▍      | 309/400 [2:14:25<38:00, 25.06s/it]2022-01-14 01:34:13,642 iteration 5254 : loss : 0.022650, loss_ce: 0.010561
2022-01-14 01:34:15,139 iteration 5255 : loss : 0.024191, loss_ce: 0.006044
2022-01-14 01:34:16,583 iteration 5256 : loss : 0.023483, loss_ce: 0.009678
2022-01-14 01:34:18,042 iteration 5257 : loss : 0.024674, loss_ce: 0.010743
2022-01-14 01:34:19,402 iteration 5258 : loss : 0.019306, loss_ce: 0.007714
2022-01-14 01:34:20,815 iteration 5259 : loss : 0.029404, loss_ce: 0.011012
2022-01-14 01:34:22,327 iteration 5260 : loss : 0.043098, loss_ce: 0.013612
2022-01-14 01:34:23,750 iteration 5261 : loss : 0.022424, loss_ce: 0.010697
2022-01-14 01:34:25,133 iteration 5262 : loss : 0.021224, loss_ce: 0.008500
2022-01-14 01:34:26,567 iteration 5263 : loss : 0.023413, loss_ce: 0.008538
2022-01-14 01:34:28,016 iteration 5264 : loss : 0.024733, loss_ce: 0.009270
2022-01-14 01:34:29,461 iteration 5265 : loss : 0.026057, loss_ce: 0.011707
2022-01-14 01:34:30,832 iteration 5266 : loss : 0.018400, loss_ce: 0.007235
2022-01-14 01:34:32,323 iteration 5267 : loss : 0.021952, loss_ce: 0.010065
2022-01-14 01:34:33,598 iteration 5268 : loss : 0.018364, loss_ce: 0.004324
2022-01-14 01:34:34,888 iteration 5269 : loss : 0.020740, loss_ce: 0.007321
2022-01-14 01:34:34,888 Training Data Eval:
2022-01-14 01:34:42,046   Average segmentation loss on training set: 0.0139
2022-01-14 01:34:42,046 Validation Data Eval:
2022-01-14 01:34:44,558   Average segmentation loss on validation set: 0.0706
2022-01-14 01:34:45,995 iteration 5270 : loss : 0.030571, loss_ce: 0.004398
 78%|██████████████████████▍      | 310/400 [2:14:59<41:32, 27.69s/it]2022-01-14 01:34:47,605 iteration 5271 : loss : 0.022506, loss_ce: 0.007561
2022-01-14 01:34:49,090 iteration 5272 : loss : 0.033976, loss_ce: 0.014613
2022-01-14 01:34:50,498 iteration 5273 : loss : 0.023573, loss_ce: 0.010540
2022-01-14 01:34:51,922 iteration 5274 : loss : 0.027393, loss_ce: 0.010549
2022-01-14 01:34:53,289 iteration 5275 : loss : 0.021357, loss_ce: 0.007871
2022-01-14 01:34:54,689 iteration 5276 : loss : 0.023412, loss_ce: 0.007774
2022-01-14 01:34:56,212 iteration 5277 : loss : 0.031390, loss_ce: 0.012597
2022-01-14 01:34:57,599 iteration 5278 : loss : 0.024663, loss_ce: 0.005040
2022-01-14 01:34:59,039 iteration 5279 : loss : 0.025840, loss_ce: 0.008034
2022-01-14 01:35:00,387 iteration 5280 : loss : 0.021832, loss_ce: 0.005871
2022-01-14 01:35:01,764 iteration 5281 : loss : 0.018273, loss_ce: 0.007921
2022-01-14 01:35:03,123 iteration 5282 : loss : 0.023523, loss_ce: 0.009086
2022-01-14 01:35:04,477 iteration 5283 : loss : 0.020887, loss_ce: 0.008769
2022-01-14 01:35:05,896 iteration 5284 : loss : 0.016671, loss_ce: 0.006083
2022-01-14 01:35:07,267 iteration 5285 : loss : 0.020372, loss_ce: 0.008150
2022-01-14 01:35:08,606 iteration 5286 : loss : 0.023856, loss_ce: 0.011086
2022-01-14 01:35:10,027 iteration 5287 : loss : 0.017285, loss_ce: 0.006211
 78%|██████████████████████▌      | 311/400 [2:15:23<39:26, 26.59s/it]2022-01-14 01:35:11,489 iteration 5288 : loss : 0.018650, loss_ce: 0.008582
2022-01-14 01:35:12,840 iteration 5289 : loss : 0.041986, loss_ce: 0.018377
2022-01-14 01:35:14,372 iteration 5290 : loss : 0.025334, loss_ce: 0.006681
2022-01-14 01:35:15,819 iteration 5291 : loss : 0.025861, loss_ce: 0.010763
2022-01-14 01:35:17,242 iteration 5292 : loss : 0.020478, loss_ce: 0.005444
2022-01-14 01:35:18,599 iteration 5293 : loss : 0.025957, loss_ce: 0.010051
2022-01-14 01:35:20,039 iteration 5294 : loss : 0.028352, loss_ce: 0.009258
2022-01-14 01:35:21,444 iteration 5295 : loss : 0.023994, loss_ce: 0.008558
2022-01-14 01:35:22,786 iteration 5296 : loss : 0.024241, loss_ce: 0.007843
2022-01-14 01:35:24,157 iteration 5297 : loss : 0.020809, loss_ce: 0.006467
2022-01-14 01:35:25,507 iteration 5298 : loss : 0.017309, loss_ce: 0.008512
2022-01-14 01:35:26,883 iteration 5299 : loss : 0.020810, loss_ce: 0.004053
2022-01-14 01:35:28,239 iteration 5300 : loss : 0.015058, loss_ce: 0.005904
2022-01-14 01:35:29,609 iteration 5301 : loss : 0.022933, loss_ce: 0.006127
2022-01-14 01:35:31,099 iteration 5302 : loss : 0.023217, loss_ce: 0.010359
2022-01-14 01:35:32,530 iteration 5303 : loss : 0.021684, loss_ce: 0.010459
2022-01-14 01:35:33,921 iteration 5304 : loss : 0.024896, loss_ce: 0.012860
 78%|██████████████████████▌      | 312/400 [2:15:47<37:48, 25.78s/it]2022-01-14 01:35:35,319 iteration 5305 : loss : 0.012247, loss_ce: 0.004216
2022-01-14 01:35:36,756 iteration 5306 : loss : 0.036079, loss_ce: 0.016588
2022-01-14 01:35:38,211 iteration 5307 : loss : 0.023406, loss_ce: 0.008696
2022-01-14 01:35:39,589 iteration 5308 : loss : 0.031510, loss_ce: 0.009236
2022-01-14 01:35:40,999 iteration 5309 : loss : 0.026445, loss_ce: 0.013361
2022-01-14 01:35:42,525 iteration 5310 : loss : 0.020105, loss_ce: 0.006604
2022-01-14 01:35:43,912 iteration 5311 : loss : 0.029478, loss_ce: 0.013372
2022-01-14 01:35:45,375 iteration 5312 : loss : 0.023987, loss_ce: 0.010254
2022-01-14 01:35:46,759 iteration 5313 : loss : 0.019827, loss_ce: 0.010202
2022-01-14 01:35:48,151 iteration 5314 : loss : 0.020978, loss_ce: 0.007026
2022-01-14 01:35:49,511 iteration 5315 : loss : 0.018989, loss_ce: 0.007456
2022-01-14 01:35:50,903 iteration 5316 : loss : 0.017073, loss_ce: 0.005031
2022-01-14 01:35:52,271 iteration 5317 : loss : 0.022563, loss_ce: 0.007172
2022-01-14 01:35:53,730 iteration 5318 : loss : 0.023116, loss_ce: 0.008489
2022-01-14 01:35:55,111 iteration 5319 : loss : 0.025574, loss_ce: 0.009242
2022-01-14 01:35:56,455 iteration 5320 : loss : 0.019652, loss_ce: 0.006415
2022-01-14 01:35:57,827 iteration 5321 : loss : 0.020664, loss_ce: 0.008695
 78%|██████████████████████▋      | 313/400 [2:16:11<36:34, 25.22s/it]2022-01-14 01:35:59,219 iteration 5322 : loss : 0.026410, loss_ce: 0.009633
2022-01-14 01:36:00,642 iteration 5323 : loss : 0.026008, loss_ce: 0.007253
2022-01-14 01:36:02,028 iteration 5324 : loss : 0.018800, loss_ce: 0.006961
2022-01-14 01:36:03,476 iteration 5325 : loss : 0.021527, loss_ce: 0.009131
2022-01-14 01:36:04,929 iteration 5326 : loss : 0.026609, loss_ce: 0.009683
2022-01-14 01:36:06,344 iteration 5327 : loss : 0.017695, loss_ce: 0.006765
2022-01-14 01:36:07,768 iteration 5328 : loss : 0.013799, loss_ce: 0.005031
2022-01-14 01:36:09,213 iteration 5329 : loss : 0.028680, loss_ce: 0.014844
2022-01-14 01:36:10,658 iteration 5330 : loss : 0.016938, loss_ce: 0.005223
2022-01-14 01:36:12,006 iteration 5331 : loss : 0.019885, loss_ce: 0.007927
2022-01-14 01:36:13,363 iteration 5332 : loss : 0.019703, loss_ce: 0.008420
2022-01-14 01:36:14,742 iteration 5333 : loss : 0.027056, loss_ce: 0.009669
2022-01-14 01:36:16,119 iteration 5334 : loss : 0.015219, loss_ce: 0.004654
2022-01-14 01:36:17,604 iteration 5335 : loss : 0.034109, loss_ce: 0.013250
2022-01-14 01:36:19,010 iteration 5336 : loss : 0.028602, loss_ce: 0.010250
2022-01-14 01:36:20,426 iteration 5337 : loss : 0.018020, loss_ce: 0.006687
2022-01-14 01:36:21,748 iteration 5338 : loss : 0.015755, loss_ce: 0.005859
 78%|██████████████████████▊      | 314/400 [2:16:35<35:35, 24.83s/it]2022-01-14 01:36:23,224 iteration 5339 : loss : 0.020621, loss_ce: 0.007081
2022-01-14 01:36:24,659 iteration 5340 : loss : 0.017585, loss_ce: 0.010278
2022-01-14 01:36:26,085 iteration 5341 : loss : 0.020480, loss_ce: 0.008625
2022-01-14 01:36:27,542 iteration 5342 : loss : 0.022335, loss_ce: 0.006612
2022-01-14 01:36:28,903 iteration 5343 : loss : 0.027831, loss_ce: 0.009494
2022-01-14 01:36:30,265 iteration 5344 : loss : 0.017856, loss_ce: 0.008053
2022-01-14 01:36:31,611 iteration 5345 : loss : 0.020673, loss_ce: 0.006403
2022-01-14 01:36:32,983 iteration 5346 : loss : 0.023503, loss_ce: 0.008162
2022-01-14 01:36:34,464 iteration 5347 : loss : 0.018094, loss_ce: 0.008087
2022-01-14 01:36:35,907 iteration 5348 : loss : 0.017333, loss_ce: 0.006617
2022-01-14 01:36:37,300 iteration 5349 : loss : 0.014957, loss_ce: 0.006716
2022-01-14 01:36:38,647 iteration 5350 : loss : 0.015193, loss_ce: 0.005272
2022-01-14 01:36:40,136 iteration 5351 : loss : 0.032093, loss_ce: 0.005116
2022-01-14 01:36:41,555 iteration 5352 : loss : 0.015778, loss_ce: 0.005863
2022-01-14 01:36:43,029 iteration 5353 : loss : 0.021998, loss_ce: 0.009388
2022-01-14 01:36:44,388 iteration 5354 : loss : 0.023724, loss_ce: 0.008509
2022-01-14 01:36:44,388 Training Data Eval:
2022-01-14 01:36:51,481   Average segmentation loss on training set: 0.0134
2022-01-14 01:36:51,482 Validation Data Eval:
2022-01-14 01:36:53,937   Average segmentation loss on validation set: 0.0746
2022-01-14 01:36:55,298 iteration 5355 : loss : 0.028062, loss_ce: 0.014232
 79%|██████████████████████▊      | 315/400 [2:17:08<38:53, 27.45s/it]2022-01-14 01:36:56,826 iteration 5356 : loss : 0.034086, loss_ce: 0.014281
2022-01-14 01:36:58,143 iteration 5357 : loss : 0.013845, loss_ce: 0.004081
2022-01-14 01:36:59,550 iteration 5358 : loss : 0.018020, loss_ce: 0.004420
2022-01-14 01:37:00,941 iteration 5359 : loss : 0.020703, loss_ce: 0.011369
2022-01-14 01:37:02,330 iteration 5360 : loss : 0.017301, loss_ce: 0.005766
2022-01-14 01:37:03,801 iteration 5361 : loss : 0.037272, loss_ce: 0.011463
2022-01-14 01:37:05,243 iteration 5362 : loss : 0.025839, loss_ce: 0.014141
2022-01-14 01:37:06,641 iteration 5363 : loss : 0.020487, loss_ce: 0.007943
2022-01-14 01:37:07,965 iteration 5364 : loss : 0.022053, loss_ce: 0.003511
2022-01-14 01:37:09,419 iteration 5365 : loss : 0.019457, loss_ce: 0.006459
2022-01-14 01:37:10,774 iteration 5366 : loss : 0.027878, loss_ce: 0.008533
2022-01-14 01:37:12,216 iteration 5367 : loss : 0.028292, loss_ce: 0.006194
2022-01-14 01:37:13,696 iteration 5368 : loss : 0.023742, loss_ce: 0.008809
2022-01-14 01:37:15,132 iteration 5369 : loss : 0.036793, loss_ce: 0.016653
2022-01-14 01:37:16,544 iteration 5370 : loss : 0.032340, loss_ce: 0.009990
2022-01-14 01:37:18,039 iteration 5371 : loss : 0.018056, loss_ce: 0.005300
2022-01-14 01:37:19,416 iteration 5372 : loss : 0.020290, loss_ce: 0.008431
 79%|██████████████████████▉      | 316/400 [2:17:32<37:01, 26.45s/it]2022-01-14 01:37:20,799 iteration 5373 : loss : 0.014459, loss_ce: 0.006510
2022-01-14 01:37:22,225 iteration 5374 : loss : 0.021677, loss_ce: 0.007158
2022-01-14 01:37:23,578 iteration 5375 : loss : 0.018033, loss_ce: 0.006375
2022-01-14 01:37:24,914 iteration 5376 : loss : 0.016683, loss_ce: 0.005140
2022-01-14 01:37:26,215 iteration 5377 : loss : 0.023961, loss_ce: 0.003633
2022-01-14 01:37:27,528 iteration 5378 : loss : 0.014999, loss_ce: 0.005504
2022-01-14 01:37:28,959 iteration 5379 : loss : 0.019312, loss_ce: 0.006064
2022-01-14 01:37:30,345 iteration 5380 : loss : 0.018924, loss_ce: 0.007455
2022-01-14 01:37:31,778 iteration 5381 : loss : 0.018979, loss_ce: 0.007933
2022-01-14 01:37:33,232 iteration 5382 : loss : 0.022083, loss_ce: 0.006391
2022-01-14 01:37:34,717 iteration 5383 : loss : 0.020898, loss_ce: 0.008205
2022-01-14 01:37:36,120 iteration 5384 : loss : 0.019937, loss_ce: 0.009311
2022-01-14 01:37:37,537 iteration 5385 : loss : 0.020356, loss_ce: 0.008589
2022-01-14 01:37:39,029 iteration 5386 : loss : 0.019672, loss_ce: 0.007690
2022-01-14 01:37:40,451 iteration 5387 : loss : 0.029521, loss_ce: 0.012171
2022-01-14 01:37:41,782 iteration 5388 : loss : 0.017436, loss_ce: 0.006516
2022-01-14 01:37:43,191 iteration 5389 : loss : 0.020544, loss_ce: 0.006772
 79%|██████████████████████▉      | 317/400 [2:17:56<35:28, 25.64s/it]2022-01-14 01:37:44,722 iteration 5390 : loss : 0.027684, loss_ce: 0.010392
2022-01-14 01:37:46,034 iteration 5391 : loss : 0.017995, loss_ce: 0.006393
2022-01-14 01:37:47,479 iteration 5392 : loss : 0.019482, loss_ce: 0.007936
2022-01-14 01:37:48,911 iteration 5393 : loss : 0.033676, loss_ce: 0.010998
2022-01-14 01:37:50,297 iteration 5394 : loss : 0.017153, loss_ce: 0.006725
2022-01-14 01:37:51,641 iteration 5395 : loss : 0.027533, loss_ce: 0.012315
2022-01-14 01:37:53,091 iteration 5396 : loss : 0.029004, loss_ce: 0.010282
2022-01-14 01:37:54,504 iteration 5397 : loss : 0.028718, loss_ce: 0.011808
2022-01-14 01:37:55,821 iteration 5398 : loss : 0.013882, loss_ce: 0.006788
2022-01-14 01:37:57,193 iteration 5399 : loss : 0.014008, loss_ce: 0.006223
2022-01-14 01:37:58,661 iteration 5400 : loss : 0.033628, loss_ce: 0.009471
2022-01-14 01:38:00,117 iteration 5401 : loss : 0.024794, loss_ce: 0.009039
2022-01-14 01:38:01,496 iteration 5402 : loss : 0.015178, loss_ce: 0.005577
2022-01-14 01:38:02,926 iteration 5403 : loss : 0.064297, loss_ce: 0.016937
2022-01-14 01:38:04,296 iteration 5404 : loss : 0.019716, loss_ce: 0.008888
2022-01-14 01:38:05,640 iteration 5405 : loss : 0.016125, loss_ce: 0.005523
2022-01-14 01:38:06,955 iteration 5406 : loss : 0.021188, loss_ce: 0.004990
 80%|███████████████████████      | 318/400 [2:18:20<34:16, 25.08s/it]2022-01-14 01:38:08,495 iteration 5407 : loss : 0.020867, loss_ce: 0.006481
2022-01-14 01:38:09,875 iteration 5408 : loss : 0.021016, loss_ce: 0.006382
2022-01-14 01:38:11,224 iteration 5409 : loss : 0.016833, loss_ce: 0.007604
2022-01-14 01:38:12,612 iteration 5410 : loss : 0.019300, loss_ce: 0.006134
2022-01-14 01:38:14,072 iteration 5411 : loss : 0.021809, loss_ce: 0.007778
2022-01-14 01:38:15,516 iteration 5412 : loss : 0.025219, loss_ce: 0.011412
2022-01-14 01:38:16,893 iteration 5413 : loss : 0.023452, loss_ce: 0.008964
2022-01-14 01:38:18,357 iteration 5414 : loss : 0.020009, loss_ce: 0.006990
2022-01-14 01:38:19,751 iteration 5415 : loss : 0.023667, loss_ce: 0.008596
2022-01-14 01:38:21,217 iteration 5416 : loss : 0.017732, loss_ce: 0.007569
2022-01-14 01:38:22,576 iteration 5417 : loss : 0.023623, loss_ce: 0.008641
2022-01-14 01:38:23,963 iteration 5418 : loss : 0.020121, loss_ce: 0.007947
2022-01-14 01:38:25,351 iteration 5419 : loss : 0.017673, loss_ce: 0.008584
2022-01-14 01:38:26,759 iteration 5420 : loss : 0.015479, loss_ce: 0.006932
2022-01-14 01:38:28,180 iteration 5421 : loss : 0.026239, loss_ce: 0.008635
2022-01-14 01:38:29,602 iteration 5422 : loss : 0.022161, loss_ce: 0.006960
2022-01-14 01:38:31,047 iteration 5423 : loss : 0.032218, loss_ce: 0.009091
 80%|███████████████████████▏     | 319/400 [2:18:44<33:27, 24.78s/it]2022-01-14 01:38:32,531 iteration 5424 : loss : 0.023043, loss_ce: 0.009104
2022-01-14 01:38:33,956 iteration 5425 : loss : 0.025616, loss_ce: 0.010128
2022-01-14 01:38:35,376 iteration 5426 : loss : 0.023920, loss_ce: 0.007657
2022-01-14 01:38:36,894 iteration 5427 : loss : 0.021234, loss_ce: 0.007391
2022-01-14 01:38:38,365 iteration 5428 : loss : 0.027463, loss_ce: 0.009959
2022-01-14 01:38:39,717 iteration 5429 : loss : 0.016655, loss_ce: 0.006525
2022-01-14 01:38:41,036 iteration 5430 : loss : 0.016506, loss_ce: 0.006771
2022-01-14 01:38:42,504 iteration 5431 : loss : 0.027918, loss_ce: 0.009369
2022-01-14 01:38:43,862 iteration 5432 : loss : 0.023556, loss_ce: 0.007674
2022-01-14 01:38:45,393 iteration 5433 : loss : 0.024196, loss_ce: 0.008399
2022-01-14 01:38:46,869 iteration 5434 : loss : 0.029418, loss_ce: 0.010040
2022-01-14 01:38:48,304 iteration 5435 : loss : 0.021078, loss_ce: 0.008169
2022-01-14 01:38:49,747 iteration 5436 : loss : 0.026706, loss_ce: 0.013735
2022-01-14 01:38:51,102 iteration 5437 : loss : 0.018706, loss_ce: 0.004611
2022-01-14 01:38:52,514 iteration 5438 : loss : 0.021408, loss_ce: 0.009176
2022-01-14 01:38:53,939 iteration 5439 : loss : 0.024335, loss_ce: 0.007591
2022-01-14 01:38:53,939 Training Data Eval:
2022-01-14 01:39:00,947   Average segmentation loss on training set: 0.0121
2022-01-14 01:39:00,948 Validation Data Eval:
2022-01-14 01:39:03,472   Average segmentation loss on validation set: 0.0801
2022-01-14 01:39:04,947 iteration 5440 : loss : 0.022174, loss_ce: 0.008779
 80%|███████████████████████▏     | 320/400 [2:19:18<36:41, 27.52s/it]2022-01-14 01:39:06,364 iteration 5441 : loss : 0.016633, loss_ce: 0.007038
2022-01-14 01:39:07,890 iteration 5442 : loss : 0.034082, loss_ce: 0.013390
2022-01-14 01:39:09,335 iteration 5443 : loss : 0.022011, loss_ce: 0.007262
2022-01-14 01:39:10,729 iteration 5444 : loss : 0.016148, loss_ce: 0.007765
2022-01-14 01:39:12,106 iteration 5445 : loss : 0.024521, loss_ce: 0.010643
2022-01-14 01:39:13,500 iteration 5446 : loss : 0.021704, loss_ce: 0.008179
2022-01-14 01:39:14,839 iteration 5447 : loss : 0.022514, loss_ce: 0.003916
2022-01-14 01:39:16,279 iteration 5448 : loss : 0.021289, loss_ce: 0.007378
2022-01-14 01:39:17,672 iteration 5449 : loss : 0.019872, loss_ce: 0.005251
2022-01-14 01:39:19,051 iteration 5450 : loss : 0.022033, loss_ce: 0.006804
2022-01-14 01:39:20,476 iteration 5451 : loss : 0.015392, loss_ce: 0.004374
2022-01-14 01:39:21,889 iteration 5452 : loss : 0.017236, loss_ce: 0.007457
2022-01-14 01:39:23,331 iteration 5453 : loss : 0.019254, loss_ce: 0.006938
2022-01-14 01:39:24,770 iteration 5454 : loss : 0.024952, loss_ce: 0.010808
2022-01-14 01:39:26,179 iteration 5455 : loss : 0.027282, loss_ce: 0.014703
2022-01-14 01:39:27,609 iteration 5456 : loss : 0.023467, loss_ce: 0.006358
2022-01-14 01:39:29,050 iteration 5457 : loss : 0.029452, loss_ce: 0.011775
 80%|███████████████████████▎     | 321/400 [2:19:42<34:52, 26.49s/it]2022-01-14 01:39:30,579 iteration 5458 : loss : 0.023856, loss_ce: 0.007090
2022-01-14 01:39:31,938 iteration 5459 : loss : 0.016291, loss_ce: 0.005798
2022-01-14 01:39:33,339 iteration 5460 : loss : 0.035399, loss_ce: 0.014993
2022-01-14 01:39:34,756 iteration 5461 : loss : 0.022867, loss_ce: 0.009326
2022-01-14 01:39:36,217 iteration 5462 : loss : 0.020766, loss_ce: 0.009247
2022-01-14 01:39:37,576 iteration 5463 : loss : 0.014977, loss_ce: 0.004777
2022-01-14 01:39:39,107 iteration 5464 : loss : 0.033305, loss_ce: 0.012157
2022-01-14 01:39:40,493 iteration 5465 : loss : 0.025359, loss_ce: 0.011131
2022-01-14 01:39:41,882 iteration 5466 : loss : 0.019318, loss_ce: 0.007746
2022-01-14 01:39:43,367 iteration 5467 : loss : 0.019497, loss_ce: 0.007423
2022-01-14 01:39:44,835 iteration 5468 : loss : 0.019990, loss_ce: 0.009471
2022-01-14 01:39:46,295 iteration 5469 : loss : 0.031175, loss_ce: 0.013984
2022-01-14 01:39:47,690 iteration 5470 : loss : 0.019740, loss_ce: 0.009741
2022-01-14 01:39:49,065 iteration 5471 : loss : 0.018245, loss_ce: 0.008947
2022-01-14 01:39:50,523 iteration 5472 : loss : 0.022287, loss_ce: 0.009661
2022-01-14 01:39:51,912 iteration 5473 : loss : 0.025165, loss_ce: 0.008294
2022-01-14 01:39:53,365 iteration 5474 : loss : 0.027335, loss_ce: 0.008402
 80%|███████████████████████▎     | 322/400 [2:20:06<33:35, 25.84s/it]2022-01-14 01:39:54,779 iteration 5475 : loss : 0.020176, loss_ce: 0.008666
2022-01-14 01:39:56,166 iteration 5476 : loss : 0.016814, loss_ce: 0.008650
2022-01-14 01:39:57,606 iteration 5477 : loss : 0.013921, loss_ce: 0.005165
2022-01-14 01:39:59,062 iteration 5478 : loss : 0.031247, loss_ce: 0.013786
2022-01-14 01:40:00,466 iteration 5479 : loss : 0.017940, loss_ce: 0.004678
2022-01-14 01:40:01,861 iteration 5480 : loss : 0.022267, loss_ce: 0.005586
2022-01-14 01:40:03,273 iteration 5481 : loss : 0.024661, loss_ce: 0.009490
2022-01-14 01:40:04,692 iteration 5482 : loss : 0.024808, loss_ce: 0.008615
2022-01-14 01:40:06,037 iteration 5483 : loss : 0.027882, loss_ce: 0.012410
2022-01-14 01:40:07,494 iteration 5484 : loss : 0.021796, loss_ce: 0.008802
2022-01-14 01:40:08,838 iteration 5485 : loss : 0.017506, loss_ce: 0.008953
2022-01-14 01:40:10,356 iteration 5486 : loss : 0.025476, loss_ce: 0.007728
2022-01-14 01:40:11,705 iteration 5487 : loss : 0.016667, loss_ce: 0.008240
2022-01-14 01:40:13,149 iteration 5488 : loss : 0.019175, loss_ce: 0.005131
2022-01-14 01:40:14,496 iteration 5489 : loss : 0.026859, loss_ce: 0.006790
2022-01-14 01:40:15,937 iteration 5490 : loss : 0.022490, loss_ce: 0.008445
2022-01-14 01:40:17,302 iteration 5491 : loss : 0.034433, loss_ce: 0.010339
 81%|███████████████████████▍     | 323/400 [2:20:30<32:25, 25.27s/it]2022-01-14 01:40:18,779 iteration 5492 : loss : 0.023368, loss_ce: 0.011808
2022-01-14 01:40:20,132 iteration 5493 : loss : 0.015143, loss_ce: 0.005122
2022-01-14 01:40:21,513 iteration 5494 : loss : 0.018703, loss_ce: 0.008746
2022-01-14 01:40:22,980 iteration 5495 : loss : 0.027764, loss_ce: 0.005832
2022-01-14 01:40:24,345 iteration 5496 : loss : 0.014036, loss_ce: 0.004370
2022-01-14 01:40:25,767 iteration 5497 : loss : 0.022380, loss_ce: 0.009520
2022-01-14 01:40:27,209 iteration 5498 : loss : 0.024623, loss_ce: 0.011354
2022-01-14 01:40:28,632 iteration 5499 : loss : 0.023979, loss_ce: 0.006075
2022-01-14 01:40:30,048 iteration 5500 : loss : 0.016069, loss_ce: 0.005296
2022-01-14 01:40:31,437 iteration 5501 : loss : 0.016315, loss_ce: 0.005879
2022-01-14 01:40:32,829 iteration 5502 : loss : 0.015958, loss_ce: 0.007360
2022-01-14 01:40:34,359 iteration 5503 : loss : 0.027881, loss_ce: 0.007885
2022-01-14 01:40:35,794 iteration 5504 : loss : 0.036701, loss_ce: 0.021315
2022-01-14 01:40:37,145 iteration 5505 : loss : 0.018782, loss_ce: 0.006135
2022-01-14 01:40:38,537 iteration 5506 : loss : 0.017156, loss_ce: 0.006663
2022-01-14 01:40:40,046 iteration 5507 : loss : 0.024617, loss_ce: 0.008839
2022-01-14 01:40:41,505 iteration 5508 : loss : 0.034695, loss_ce: 0.015135
 81%|███████████████████████▍     | 324/400 [2:20:54<31:36, 24.95s/it]2022-01-14 01:40:42,997 iteration 5509 : loss : 0.020526, loss_ce: 0.008847
2022-01-14 01:40:44,385 iteration 5510 : loss : 0.016598, loss_ce: 0.006369
2022-01-14 01:40:45,798 iteration 5511 : loss : 0.027755, loss_ce: 0.010033
2022-01-14 01:40:47,184 iteration 5512 : loss : 0.020318, loss_ce: 0.008775
2022-01-14 01:40:48,576 iteration 5513 : loss : 0.014948, loss_ce: 0.007793
2022-01-14 01:40:50,040 iteration 5514 : loss : 0.026672, loss_ce: 0.011949
2022-01-14 01:40:51,432 iteration 5515 : loss : 0.027229, loss_ce: 0.013009
2022-01-14 01:40:52,832 iteration 5516 : loss : 0.016696, loss_ce: 0.008717
2022-01-14 01:40:54,258 iteration 5517 : loss : 0.035698, loss_ce: 0.011653
2022-01-14 01:40:55,581 iteration 5518 : loss : 0.018058, loss_ce: 0.006616
2022-01-14 01:40:57,060 iteration 5519 : loss : 0.043533, loss_ce: 0.014836
2022-01-14 01:40:58,457 iteration 5520 : loss : 0.015836, loss_ce: 0.002639
2022-01-14 01:40:59,940 iteration 5521 : loss : 0.020904, loss_ce: 0.006505
2022-01-14 01:41:01,350 iteration 5522 : loss : 0.020310, loss_ce: 0.006570
2022-01-14 01:41:02,800 iteration 5523 : loss : 0.029197, loss_ce: 0.013702
2022-01-14 01:41:04,263 iteration 5524 : loss : 0.019757, loss_ce: 0.006918
2022-01-14 01:41:04,263 Training Data Eval:
2022-01-14 01:41:11,192   Average segmentation loss on training set: 0.0115
2022-01-14 01:41:11,192 Validation Data Eval:
2022-01-14 01:41:13,658   Average segmentation loss on validation set: 0.0838
2022-01-14 01:41:15,195 iteration 5525 : loss : 0.040088, loss_ce: 0.020788
 81%|███████████████████████▌     | 325/400 [2:21:28<34:27, 27.57s/it]2022-01-14 01:41:16,661 iteration 5526 : loss : 0.027599, loss_ce: 0.008199
2022-01-14 01:41:17,993 iteration 5527 : loss : 0.020767, loss_ce: 0.009261
2022-01-14 01:41:19,478 iteration 5528 : loss : 0.037634, loss_ce: 0.011909
2022-01-14 01:41:20,847 iteration 5529 : loss : 0.016793, loss_ce: 0.006078
2022-01-14 01:41:22,207 iteration 5530 : loss : 0.015774, loss_ce: 0.006297
2022-01-14 01:41:23,534 iteration 5531 : loss : 0.014394, loss_ce: 0.004180
2022-01-14 01:41:24,893 iteration 5532 : loss : 0.019946, loss_ce: 0.007962
2022-01-14 01:41:26,342 iteration 5533 : loss : 0.024622, loss_ce: 0.009894
2022-01-14 01:41:27,692 iteration 5534 : loss : 0.017493, loss_ce: 0.006361
2022-01-14 01:41:29,074 iteration 5535 : loss : 0.022944, loss_ce: 0.010021
2022-01-14 01:41:30,544 iteration 5536 : loss : 0.026481, loss_ce: 0.008236
2022-01-14 01:41:31,997 iteration 5537 : loss : 0.028847, loss_ce: 0.013074
2022-01-14 01:41:33,492 iteration 5538 : loss : 0.025392, loss_ce: 0.006563
2022-01-14 01:41:34,927 iteration 5539 : loss : 0.026342, loss_ce: 0.009705
2022-01-14 01:41:36,274 iteration 5540 : loss : 0.021219, loss_ce: 0.008809
2022-01-14 01:41:37,806 iteration 5541 : loss : 0.062529, loss_ce: 0.038954
2022-01-14 01:41:39,245 iteration 5542 : loss : 0.034064, loss_ce: 0.014870
 82%|███████████████████████▋     | 326/400 [2:21:52<32:42, 26.51s/it]2022-01-14 01:41:40,764 iteration 5543 : loss : 0.026434, loss_ce: 0.013667
2022-01-14 01:41:42,147 iteration 5544 : loss : 0.020519, loss_ce: 0.008099
2022-01-14 01:41:43,585 iteration 5545 : loss : 0.027512, loss_ce: 0.012749
2022-01-14 01:41:45,073 iteration 5546 : loss : 0.045244, loss_ce: 0.010999
2022-01-14 01:41:46,537 iteration 5547 : loss : 0.024767, loss_ce: 0.010282
2022-01-14 01:41:47,917 iteration 5548 : loss : 0.030857, loss_ce: 0.007038
2022-01-14 01:41:49,291 iteration 5549 : loss : 0.019677, loss_ce: 0.005501
2022-01-14 01:41:50,730 iteration 5550 : loss : 0.031045, loss_ce: 0.010083
2022-01-14 01:41:52,095 iteration 5551 : loss : 0.036178, loss_ce: 0.017325
2022-01-14 01:41:53,378 iteration 5552 : loss : 0.024971, loss_ce: 0.007706
2022-01-14 01:41:54,790 iteration 5553 : loss : 0.034617, loss_ce: 0.013420
2022-01-14 01:41:56,170 iteration 5554 : loss : 0.019283, loss_ce: 0.008178
2022-01-14 01:41:57,486 iteration 5555 : loss : 0.020649, loss_ce: 0.009143
2022-01-14 01:41:58,948 iteration 5556 : loss : 0.037751, loss_ce: 0.012784
2022-01-14 01:42:00,375 iteration 5557 : loss : 0.023444, loss_ce: 0.011609
2022-01-14 01:42:01,772 iteration 5558 : loss : 0.026932, loss_ce: 0.008869
2022-01-14 01:42:03,176 iteration 5559 : loss : 0.032954, loss_ce: 0.009689
 82%|███████████████████████▋     | 327/400 [2:22:16<31:19, 25.74s/it]2022-01-14 01:42:04,643 iteration 5560 : loss : 0.023436, loss_ce: 0.007959
2022-01-14 01:42:06,008 iteration 5561 : loss : 0.029397, loss_ce: 0.010519
2022-01-14 01:42:07,404 iteration 5562 : loss : 0.017794, loss_ce: 0.008096
2022-01-14 01:42:08,774 iteration 5563 : loss : 0.022728, loss_ce: 0.009861
2022-01-14 01:42:10,200 iteration 5564 : loss : 0.040139, loss_ce: 0.020264
2022-01-14 01:42:11,659 iteration 5565 : loss : 0.029796, loss_ce: 0.014082
2022-01-14 01:42:13,081 iteration 5566 : loss : 0.024297, loss_ce: 0.009845
2022-01-14 01:42:14,535 iteration 5567 : loss : 0.018901, loss_ce: 0.009916
2022-01-14 01:42:15,932 iteration 5568 : loss : 0.027727, loss_ce: 0.010854
2022-01-14 01:42:17,345 iteration 5569 : loss : 0.023641, loss_ce: 0.007738
2022-01-14 01:42:18,711 iteration 5570 : loss : 0.019698, loss_ce: 0.006116
2022-01-14 01:42:20,018 iteration 5571 : loss : 0.014485, loss_ce: 0.005565
2022-01-14 01:42:21,380 iteration 5572 : loss : 0.030605, loss_ce: 0.009360
2022-01-14 01:42:22,708 iteration 5573 : loss : 0.017937, loss_ce: 0.005311
2022-01-14 01:42:24,100 iteration 5574 : loss : 0.023714, loss_ce: 0.010333
2022-01-14 01:42:25,584 iteration 5575 : loss : 0.033388, loss_ce: 0.011148
2022-01-14 01:42:27,027 iteration 5576 : loss : 0.022288, loss_ce: 0.007609
 82%|███████████████████████▊     | 328/400 [2:22:40<30:12, 25.17s/it]2022-01-14 01:42:28,498 iteration 5577 : loss : 0.021222, loss_ce: 0.009575
2022-01-14 01:42:29,940 iteration 5578 : loss : 0.027604, loss_ce: 0.011119
2022-01-14 01:42:31,412 iteration 5579 : loss : 0.026091, loss_ce: 0.011634
2022-01-14 01:42:32,785 iteration 5580 : loss : 0.025080, loss_ce: 0.010196
2022-01-14 01:42:34,151 iteration 5581 : loss : 0.016849, loss_ce: 0.006593
2022-01-14 01:42:35,575 iteration 5582 : loss : 0.022689, loss_ce: 0.006510
2022-01-14 01:42:36,968 iteration 5583 : loss : 0.016982, loss_ce: 0.006742
2022-01-14 01:42:38,434 iteration 5584 : loss : 0.030993, loss_ce: 0.014423
2022-01-14 01:42:39,811 iteration 5585 : loss : 0.018884, loss_ce: 0.005308
2022-01-14 01:42:41,303 iteration 5586 : loss : 0.028942, loss_ce: 0.009805
2022-01-14 01:42:42,660 iteration 5587 : loss : 0.022285, loss_ce: 0.007825
2022-01-14 01:42:44,053 iteration 5588 : loss : 0.019163, loss_ce: 0.007345
2022-01-14 01:42:45,424 iteration 5589 : loss : 0.024250, loss_ce: 0.007806
2022-01-14 01:42:46,819 iteration 5590 : loss : 0.018512, loss_ce: 0.004529
2022-01-14 01:42:48,208 iteration 5591 : loss : 0.017129, loss_ce: 0.006790
2022-01-14 01:42:49,692 iteration 5592 : loss : 0.024874, loss_ce: 0.007569
2022-01-14 01:42:51,119 iteration 5593 : loss : 0.039133, loss_ce: 0.016957
 82%|███████████████████████▊     | 329/400 [2:23:04<29:24, 24.85s/it]2022-01-14 01:42:52,581 iteration 5594 : loss : 0.023153, loss_ce: 0.006380
2022-01-14 01:42:54,022 iteration 5595 : loss : 0.027105, loss_ce: 0.012870
2022-01-14 01:42:55,395 iteration 5596 : loss : 0.019607, loss_ce: 0.007447
2022-01-14 01:42:56,897 iteration 5597 : loss : 0.017899, loss_ce: 0.007551
2022-01-14 01:42:58,231 iteration 5598 : loss : 0.015199, loss_ce: 0.006217
2022-01-14 01:42:59,617 iteration 5599 : loss : 0.024487, loss_ce: 0.009329
2022-01-14 01:43:00,997 iteration 5600 : loss : 0.015205, loss_ce: 0.005981
2022-01-14 01:43:02,369 iteration 5601 : loss : 0.020915, loss_ce: 0.010703
2022-01-14 01:43:03,779 iteration 5602 : loss : 0.015930, loss_ce: 0.007073
2022-01-14 01:43:05,118 iteration 5603 : loss : 0.013774, loss_ce: 0.005482
2022-01-14 01:43:06,543 iteration 5604 : loss : 0.026250, loss_ce: 0.005932
2022-01-14 01:43:07,968 iteration 5605 : loss : 0.025791, loss_ce: 0.010917
2022-01-14 01:43:09,392 iteration 5606 : loss : 0.021470, loss_ce: 0.007365
2022-01-14 01:43:10,820 iteration 5607 : loss : 0.015892, loss_ce: 0.005038
2022-01-14 01:43:12,238 iteration 5608 : loss : 0.036430, loss_ce: 0.009673
2022-01-14 01:43:13,703 iteration 5609 : loss : 0.040276, loss_ce: 0.019111
2022-01-14 01:43:13,703 Training Data Eval:
2022-01-14 01:43:20,849   Average segmentation loss on training set: 0.0127
2022-01-14 01:43:20,849 Validation Data Eval:
2022-01-14 01:43:23,330   Average segmentation loss on validation set: 0.0770
2022-01-14 01:43:24,724 iteration 5610 : loss : 0.016975, loss_ce: 0.005901
 82%|███████████████████████▉     | 330/400 [2:23:38<32:03, 27.47s/it]2022-01-14 01:43:26,198 iteration 5611 : loss : 0.020281, loss_ce: 0.007492
2022-01-14 01:43:27,630 iteration 5612 : loss : 0.036438, loss_ce: 0.008367
2022-01-14 01:43:29,056 iteration 5613 : loss : 0.019848, loss_ce: 0.007607
2022-01-14 01:43:30,493 iteration 5614 : loss : 0.023589, loss_ce: 0.009018
2022-01-14 01:43:31,839 iteration 5615 : loss : 0.012503, loss_ce: 0.005448
2022-01-14 01:43:33,293 iteration 5616 : loss : 0.018432, loss_ce: 0.008102
2022-01-14 01:43:34,779 iteration 5617 : loss : 0.028478, loss_ce: 0.011833
2022-01-14 01:43:36,206 iteration 5618 : loss : 0.032872, loss_ce: 0.012830
2022-01-14 01:43:37,586 iteration 5619 : loss : 0.041138, loss_ce: 0.010170
2022-01-14 01:43:39,079 iteration 5620 : loss : 0.017634, loss_ce: 0.007226
2022-01-14 01:43:40,412 iteration 5621 : loss : 0.023474, loss_ce: 0.008144
2022-01-14 01:43:41,825 iteration 5622 : loss : 0.023077, loss_ce: 0.009018
2022-01-14 01:43:43,323 iteration 5623 : loss : 0.028345, loss_ce: 0.011019
2022-01-14 01:43:44,682 iteration 5624 : loss : 0.019724, loss_ce: 0.005453
2022-01-14 01:43:46,039 iteration 5625 : loss : 0.022555, loss_ce: 0.009916
2022-01-14 01:43:47,428 iteration 5626 : loss : 0.017629, loss_ce: 0.005620
2022-01-14 01:43:48,848 iteration 5627 : loss : 0.026050, loss_ce: 0.009851
 83%|███████████████████████▉     | 331/400 [2:24:02<30:26, 26.47s/it]2022-01-14 01:43:50,397 iteration 5628 : loss : 0.027889, loss_ce: 0.013113
2022-01-14 01:43:51,757 iteration 5629 : loss : 0.017683, loss_ce: 0.007339
2022-01-14 01:43:53,180 iteration 5630 : loss : 0.018896, loss_ce: 0.007384
2022-01-14 01:43:54,566 iteration 5631 : loss : 0.018525, loss_ce: 0.006629
2022-01-14 01:43:56,017 iteration 5632 : loss : 0.023695, loss_ce: 0.010961
2022-01-14 01:43:57,502 iteration 5633 : loss : 0.028241, loss_ce: 0.008121
2022-01-14 01:43:58,917 iteration 5634 : loss : 0.013024, loss_ce: 0.005183
2022-01-14 01:44:00,299 iteration 5635 : loss : 0.021705, loss_ce: 0.008544
2022-01-14 01:44:01,708 iteration 5636 : loss : 0.021872, loss_ce: 0.006166
2022-01-14 01:44:03,110 iteration 5637 : loss : 0.017058, loss_ce: 0.005191
2022-01-14 01:44:04,558 iteration 5638 : loss : 0.019008, loss_ce: 0.007598
2022-01-14 01:44:06,005 iteration 5639 : loss : 0.016329, loss_ce: 0.005920
2022-01-14 01:44:07,452 iteration 5640 : loss : 0.027708, loss_ce: 0.011146
2022-01-14 01:44:08,796 iteration 5641 : loss : 0.023141, loss_ce: 0.006313
2022-01-14 01:44:10,150 iteration 5642 : loss : 0.016557, loss_ce: 0.006007
2022-01-14 01:44:11,557 iteration 5643 : loss : 0.017958, loss_ce: 0.006099
2022-01-14 01:44:12,947 iteration 5644 : loss : 0.015451, loss_ce: 0.006260
 83%|████████████████████████     | 332/400 [2:24:26<29:11, 25.76s/it]2022-01-14 01:44:14,375 iteration 5645 : loss : 0.026221, loss_ce: 0.008213
2022-01-14 01:44:15,766 iteration 5646 : loss : 0.014040, loss_ce: 0.004534
2022-01-14 01:44:17,197 iteration 5647 : loss : 0.020474, loss_ce: 0.006746
2022-01-14 01:44:18,603 iteration 5648 : loss : 0.024746, loss_ce: 0.007439
2022-01-14 01:44:19,993 iteration 5649 : loss : 0.017501, loss_ce: 0.006621
2022-01-14 01:44:21,444 iteration 5650 : loss : 0.026093, loss_ce: 0.008266
2022-01-14 01:44:22,822 iteration 5651 : loss : 0.031286, loss_ce: 0.016249
2022-01-14 01:44:24,191 iteration 5652 : loss : 0.017158, loss_ce: 0.006937
2022-01-14 01:44:25,568 iteration 5653 : loss : 0.020993, loss_ce: 0.009680
2022-01-14 01:44:27,033 iteration 5654 : loss : 0.015383, loss_ce: 0.005976
2022-01-14 01:44:28,426 iteration 5655 : loss : 0.024178, loss_ce: 0.010203
2022-01-14 01:44:29,845 iteration 5656 : loss : 0.023829, loss_ce: 0.011797
2022-01-14 01:44:31,219 iteration 5657 : loss : 0.026064, loss_ce: 0.013085
2022-01-14 01:44:32,691 iteration 5658 : loss : 0.036731, loss_ce: 0.011072
2022-01-14 01:44:34,169 iteration 5659 : loss : 0.018271, loss_ce: 0.007244
2022-01-14 01:44:35,477 iteration 5660 : loss : 0.013493, loss_ce: 0.005058
2022-01-14 01:44:36,919 iteration 5661 : loss : 0.024082, loss_ce: 0.009305
 83%|████████████████████████▏    | 333/400 [2:24:50<28:09, 25.22s/it]2022-01-14 01:44:38,327 iteration 5662 : loss : 0.015925, loss_ce: 0.006901
2022-01-14 01:44:39,761 iteration 5663 : loss : 0.015438, loss_ce: 0.006925
2022-01-14 01:44:41,223 iteration 5664 : loss : 0.028685, loss_ce: 0.011485
2022-01-14 01:44:42,600 iteration 5665 : loss : 0.020635, loss_ce: 0.004745
2022-01-14 01:44:44,070 iteration 5666 : loss : 0.018649, loss_ce: 0.006528
2022-01-14 01:44:45,501 iteration 5667 : loss : 0.020488, loss_ce: 0.006745
2022-01-14 01:44:46,918 iteration 5668 : loss : 0.040269, loss_ce: 0.014620
2022-01-14 01:44:48,388 iteration 5669 : loss : 0.021058, loss_ce: 0.009882
2022-01-14 01:44:49,805 iteration 5670 : loss : 0.022727, loss_ce: 0.008079
2022-01-14 01:44:51,301 iteration 5671 : loss : 0.030668, loss_ce: 0.008321
2022-01-14 01:44:52,620 iteration 5672 : loss : 0.017678, loss_ce: 0.005069
2022-01-14 01:44:54,013 iteration 5673 : loss : 0.017782, loss_ce: 0.007752
2022-01-14 01:44:55,371 iteration 5674 : loss : 0.023722, loss_ce: 0.008545
2022-01-14 01:44:56,902 iteration 5675 : loss : 0.030486, loss_ce: 0.012057
2022-01-14 01:44:58,297 iteration 5676 : loss : 0.023460, loss_ce: 0.012035
2022-01-14 01:44:59,663 iteration 5677 : loss : 0.018488, loss_ce: 0.006779
2022-01-14 01:45:01,055 iteration 5678 : loss : 0.024914, loss_ce: 0.009728
 84%|████████████████████████▏    | 334/400 [2:25:14<27:23, 24.90s/it]2022-01-14 01:45:02,553 iteration 5679 : loss : 0.021153, loss_ce: 0.007460
2022-01-14 01:45:03,957 iteration 5680 : loss : 0.014414, loss_ce: 0.006327
2022-01-14 01:45:05,418 iteration 5681 : loss : 0.021421, loss_ce: 0.005980
2022-01-14 01:45:06,773 iteration 5682 : loss : 0.014845, loss_ce: 0.004839
2022-01-14 01:45:08,108 iteration 5683 : loss : 0.012141, loss_ce: 0.005430
2022-01-14 01:45:09,571 iteration 5684 : loss : 0.025432, loss_ce: 0.013947
2022-01-14 01:45:11,014 iteration 5685 : loss : 0.020679, loss_ce: 0.006884
2022-01-14 01:45:12,420 iteration 5686 : loss : 0.018913, loss_ce: 0.006806
2022-01-14 01:45:13,853 iteration 5687 : loss : 0.031066, loss_ce: 0.007728
2022-01-14 01:45:15,341 iteration 5688 : loss : 0.027498, loss_ce: 0.009989
2022-01-14 01:45:16,730 iteration 5689 : loss : 0.018600, loss_ce: 0.008402
2022-01-14 01:45:18,092 iteration 5690 : loss : 0.014559, loss_ce: 0.004615
2022-01-14 01:45:19,539 iteration 5691 : loss : 0.018753, loss_ce: 0.008311
2022-01-14 01:45:20,956 iteration 5692 : loss : 0.015298, loss_ce: 0.004360
2022-01-14 01:45:22,265 iteration 5693 : loss : 0.014812, loss_ce: 0.006159
2022-01-14 01:45:23,711 iteration 5694 : loss : 0.022581, loss_ce: 0.008743
2022-01-14 01:45:23,711 Training Data Eval:
2022-01-14 01:45:30,964   Average segmentation loss on training set: 0.0111
2022-01-14 01:45:30,964 Validation Data Eval:
2022-01-14 01:45:33,490   Average segmentation loss on validation set: 0.0717
2022-01-14 01:45:34,930 iteration 5695 : loss : 0.022534, loss_ce: 0.010487
 84%|████████████████████████▎    | 335/400 [2:25:48<29:53, 27.59s/it]2022-01-14 01:45:36,431 iteration 5696 : loss : 0.023024, loss_ce: 0.007762
2022-01-14 01:45:37,802 iteration 5697 : loss : 0.017107, loss_ce: 0.005409
2022-01-14 01:45:39,291 iteration 5698 : loss : 0.020927, loss_ce: 0.007290
2022-01-14 01:45:40,768 iteration 5699 : loss : 0.022291, loss_ce: 0.006628
2022-01-14 01:45:42,075 iteration 5700 : loss : 0.016009, loss_ce: 0.007021
2022-01-14 01:45:43,588 iteration 5701 : loss : 0.067742, loss_ce: 0.010049
2022-01-14 01:45:45,019 iteration 5702 : loss : 0.019089, loss_ce: 0.007399
2022-01-14 01:45:46,487 iteration 5703 : loss : 0.017231, loss_ce: 0.007403
2022-01-14 01:45:47,866 iteration 5704 : loss : 0.021941, loss_ce: 0.009582
2022-01-14 01:45:49,246 iteration 5705 : loss : 0.018498, loss_ce: 0.007538
2022-01-14 01:45:50,625 iteration 5706 : loss : 0.015577, loss_ce: 0.005392
2022-01-14 01:45:52,070 iteration 5707 : loss : 0.021812, loss_ce: 0.005494
2022-01-14 01:45:53,476 iteration 5708 : loss : 0.017789, loss_ce: 0.008551
2022-01-14 01:45:54,860 iteration 5709 : loss : 0.015938, loss_ce: 0.005264
2022-01-14 01:45:56,261 iteration 5710 : loss : 0.024198, loss_ce: 0.012253
2022-01-14 01:45:57,678 iteration 5711 : loss : 0.013131, loss_ce: 0.005768
2022-01-14 01:45:59,090 iteration 5712 : loss : 0.021135, loss_ce: 0.008740
 84%|████████████████████████▎    | 336/400 [2:26:12<28:20, 26.56s/it]2022-01-14 01:46:00,587 iteration 5713 : loss : 0.014619, loss_ce: 0.006339
2022-01-14 01:46:02,020 iteration 5714 : loss : 0.020572, loss_ce: 0.006430
2022-01-14 01:46:03,372 iteration 5715 : loss : 0.018659, loss_ce: 0.007664
2022-01-14 01:46:04,833 iteration 5716 : loss : 0.024679, loss_ce: 0.008920
2022-01-14 01:46:06,198 iteration 5717 : loss : 0.015329, loss_ce: 0.005010
2022-01-14 01:46:07,566 iteration 5718 : loss : 0.040078, loss_ce: 0.016140
2022-01-14 01:46:09,011 iteration 5719 : loss : 0.030113, loss_ce: 0.008290
2022-01-14 01:46:10,477 iteration 5720 : loss : 0.032803, loss_ce: 0.013322
2022-01-14 01:46:11,851 iteration 5721 : loss : 0.017369, loss_ce: 0.005125
2022-01-14 01:46:13,296 iteration 5722 : loss : 0.021265, loss_ce: 0.007897
2022-01-14 01:46:14,755 iteration 5723 : loss : 0.028191, loss_ce: 0.011590
2022-01-14 01:46:16,180 iteration 5724 : loss : 0.021763, loss_ce: 0.008964
2022-01-14 01:46:17,568 iteration 5725 : loss : 0.018664, loss_ce: 0.007396
2022-01-14 01:46:19,016 iteration 5726 : loss : 0.017156, loss_ce: 0.006460
2022-01-14 01:46:20,425 iteration 5727 : loss : 0.020327, loss_ce: 0.010069
2022-01-14 01:46:21,784 iteration 5728 : loss : 0.014730, loss_ce: 0.004724
2022-01-14 01:46:23,104 iteration 5729 : loss : 0.017398, loss_ce: 0.005700
 84%|████████████████████████▍    | 337/400 [2:26:36<27:05, 25.80s/it]2022-01-14 01:46:24,663 iteration 5730 : loss : 0.030778, loss_ce: 0.010448
2022-01-14 01:46:26,128 iteration 5731 : loss : 0.033380, loss_ce: 0.011968
2022-01-14 01:46:27,576 iteration 5732 : loss : 0.025723, loss_ce: 0.005943
2022-01-14 01:46:28,988 iteration 5733 : loss : 0.018995, loss_ce: 0.006988
2022-01-14 01:46:30,350 iteration 5734 : loss : 0.012082, loss_ce: 0.004335
2022-01-14 01:46:31,853 iteration 5735 : loss : 0.031791, loss_ce: 0.011353
2022-01-14 01:46:33,328 iteration 5736 : loss : 0.018105, loss_ce: 0.007610
2022-01-14 01:46:34,733 iteration 5737 : loss : 0.019316, loss_ce: 0.007549
2022-01-14 01:46:36,110 iteration 5738 : loss : 0.019387, loss_ce: 0.008407
2022-01-14 01:46:37,540 iteration 5739 : loss : 0.013966, loss_ce: 0.004044
2022-01-14 01:46:38,993 iteration 5740 : loss : 0.021109, loss_ce: 0.008451
2022-01-14 01:46:40,402 iteration 5741 : loss : 0.015752, loss_ce: 0.006653
2022-01-14 01:46:41,787 iteration 5742 : loss : 0.024066, loss_ce: 0.004520
2022-01-14 01:46:43,214 iteration 5743 : loss : 0.024913, loss_ce: 0.008433
2022-01-14 01:46:44,576 iteration 5744 : loss : 0.018122, loss_ce: 0.007951
2022-01-14 01:46:45,996 iteration 5745 : loss : 0.014796, loss_ce: 0.004832
2022-01-14 01:46:47,368 iteration 5746 : loss : 0.025213, loss_ce: 0.011451
 84%|████████████████████████▌    | 338/400 [2:27:00<26:10, 25.34s/it]2022-01-14 01:46:48,858 iteration 5747 : loss : 0.027090, loss_ce: 0.010055
2022-01-14 01:46:50,230 iteration 5748 : loss : 0.025513, loss_ce: 0.012163
2022-01-14 01:46:51,684 iteration 5749 : loss : 0.030620, loss_ce: 0.013900
2022-01-14 01:46:53,099 iteration 5750 : loss : 0.015247, loss_ce: 0.004053
2022-01-14 01:46:54,554 iteration 5751 : loss : 0.019227, loss_ce: 0.007251
2022-01-14 01:46:55,978 iteration 5752 : loss : 0.034728, loss_ce: 0.011409
2022-01-14 01:46:57,417 iteration 5753 : loss : 0.020661, loss_ce: 0.013203
2022-01-14 01:46:58,806 iteration 5754 : loss : 0.021589, loss_ce: 0.007952
2022-01-14 01:47:00,188 iteration 5755 : loss : 0.021886, loss_ce: 0.006721
2022-01-14 01:47:01,558 iteration 5756 : loss : 0.019590, loss_ce: 0.009446
2022-01-14 01:47:02,968 iteration 5757 : loss : 0.017959, loss_ce: 0.005525
2022-01-14 01:47:04,310 iteration 5758 : loss : 0.011119, loss_ce: 0.003305
2022-01-14 01:47:05,782 iteration 5759 : loss : 0.020816, loss_ce: 0.005396
2022-01-14 01:47:07,171 iteration 5760 : loss : 0.024972, loss_ce: 0.010500
2022-01-14 01:47:08,595 iteration 5761 : loss : 0.021490, loss_ce: 0.006754
2022-01-14 01:47:10,076 iteration 5762 : loss : 0.021318, loss_ce: 0.009250
2022-01-14 01:47:11,519 iteration 5763 : loss : 0.028141, loss_ce: 0.010635
 85%|████████████████████████▌    | 339/400 [2:27:24<25:23, 24.98s/it]2022-01-14 01:47:13,076 iteration 5764 : loss : 0.025536, loss_ce: 0.011575
2022-01-14 01:47:14,550 iteration 5765 : loss : 0.024552, loss_ce: 0.008323
2022-01-14 01:47:15,936 iteration 5766 : loss : 0.015107, loss_ce: 0.005438
2022-01-14 01:47:17,390 iteration 5767 : loss : 0.021229, loss_ce: 0.008740
2022-01-14 01:47:18,847 iteration 5768 : loss : 0.034712, loss_ce: 0.011138
2022-01-14 01:47:20,277 iteration 5769 : loss : 0.016659, loss_ce: 0.004947
2022-01-14 01:47:21,726 iteration 5770 : loss : 0.033861, loss_ce: 0.012905
2022-01-14 01:47:23,051 iteration 5771 : loss : 0.012705, loss_ce: 0.005227
2022-01-14 01:47:24,462 iteration 5772 : loss : 0.027150, loss_ce: 0.011813
2022-01-14 01:47:25,793 iteration 5773 : loss : 0.014814, loss_ce: 0.005130
2022-01-14 01:47:27,166 iteration 5774 : loss : 0.013559, loss_ce: 0.005236
2022-01-14 01:47:28,606 iteration 5775 : loss : 0.027999, loss_ce: 0.011109
2022-01-14 01:47:29,906 iteration 5776 : loss : 0.015467, loss_ce: 0.006137
2022-01-14 01:47:31,282 iteration 5777 : loss : 0.014735, loss_ce: 0.005369
2022-01-14 01:47:32,715 iteration 5778 : loss : 0.018098, loss_ce: 0.006166
2022-01-14 01:47:34,136 iteration 5779 : loss : 0.013293, loss_ce: 0.005574
2022-01-14 01:47:34,136 Training Data Eval:
2022-01-14 01:47:41,142   Average segmentation loss on training set: 0.0110
2022-01-14 01:47:41,142 Validation Data Eval:
2022-01-14 01:47:43,586   Average segmentation loss on validation set: 0.0743
2022-01-14 01:47:44,989 iteration 5780 : loss : 0.019491, loss_ce: 0.007732
 85%|████████████████████████▋    | 340/400 [2:27:58<27:31, 27.53s/it]2022-01-14 01:47:46,473 iteration 5781 : loss : 0.019155, loss_ce: 0.007478
2022-01-14 01:47:47,807 iteration 5782 : loss : 0.012401, loss_ce: 0.004245
2022-01-14 01:47:49,237 iteration 5783 : loss : 0.018785, loss_ce: 0.005709
2022-01-14 01:47:50,677 iteration 5784 : loss : 0.016227, loss_ce: 0.005386
2022-01-14 01:47:52,117 iteration 5785 : loss : 0.017038, loss_ce: 0.008214
2022-01-14 01:47:53,601 iteration 5786 : loss : 0.026519, loss_ce: 0.011802
2022-01-14 01:47:55,021 iteration 5787 : loss : 0.019810, loss_ce: 0.005905
2022-01-14 01:47:56,470 iteration 5788 : loss : 0.020048, loss_ce: 0.007559
2022-01-14 01:47:57,900 iteration 5789 : loss : 0.019798, loss_ce: 0.006167
2022-01-14 01:47:59,347 iteration 5790 : loss : 0.022144, loss_ce: 0.009656
2022-01-14 01:48:00,815 iteration 5791 : loss : 0.013002, loss_ce: 0.005169
2022-01-14 01:48:02,297 iteration 5792 : loss : 0.023251, loss_ce: 0.006641
2022-01-14 01:48:03,687 iteration 5793 : loss : 0.019026, loss_ce: 0.007557
2022-01-14 01:48:05,098 iteration 5794 : loss : 0.016158, loss_ce: 0.005062
2022-01-14 01:48:06,503 iteration 5795 : loss : 0.016421, loss_ce: 0.007968
2022-01-14 01:48:07,918 iteration 5796 : loss : 0.018665, loss_ce: 0.007737
2022-01-14 01:48:09,305 iteration 5797 : loss : 0.016620, loss_ce: 0.006197
 85%|████████████████████████▋    | 341/400 [2:28:22<26:07, 26.56s/it]2022-01-14 01:48:10,709 iteration 5798 : loss : 0.017911, loss_ce: 0.005938
2022-01-14 01:48:12,064 iteration 5799 : loss : 0.017013, loss_ce: 0.006632
2022-01-14 01:48:13,367 iteration 5800 : loss : 0.010833, loss_ce: 0.004316
2022-01-14 01:48:14,765 iteration 5801 : loss : 0.025054, loss_ce: 0.010217
2022-01-14 01:48:16,115 iteration 5802 : loss : 0.014795, loss_ce: 0.006288
2022-01-14 01:48:17,560 iteration 5803 : loss : 0.020262, loss_ce: 0.007123
2022-01-14 01:48:18,920 iteration 5804 : loss : 0.027810, loss_ce: 0.008582
2022-01-14 01:48:20,262 iteration 5805 : loss : 0.014563, loss_ce: 0.005496
2022-01-14 01:48:21,588 iteration 5806 : loss : 0.012575, loss_ce: 0.005640
2022-01-14 01:48:23,020 iteration 5807 : loss : 0.022454, loss_ce: 0.007977
2022-01-14 01:48:24,457 iteration 5808 : loss : 0.032265, loss_ce: 0.010295
2022-01-14 01:48:25,900 iteration 5809 : loss : 0.020991, loss_ce: 0.007748
2022-01-14 01:48:27,402 iteration 5810 : loss : 0.031521, loss_ce: 0.011447
2022-01-14 01:48:28,849 iteration 5811 : loss : 0.022474, loss_ce: 0.008403
2022-01-14 01:48:30,260 iteration 5812 : loss : 0.018433, loss_ce: 0.008638
2022-01-14 01:48:31,637 iteration 5813 : loss : 0.015172, loss_ce: 0.004801
2022-01-14 01:48:33,013 iteration 5814 : loss : 0.037307, loss_ce: 0.011477
 86%|████████████████████████▊    | 342/400 [2:28:46<24:51, 25.71s/it]2022-01-14 01:48:34,546 iteration 5815 : loss : 0.022413, loss_ce: 0.008183
2022-01-14 01:48:35,967 iteration 5816 : loss : 0.019253, loss_ce: 0.007560
2022-01-14 01:48:37,432 iteration 5817 : loss : 0.022103, loss_ce: 0.009832
2022-01-14 01:48:38,884 iteration 5818 : loss : 0.024915, loss_ce: 0.009150
2022-01-14 01:48:40,263 iteration 5819 : loss : 0.015652, loss_ce: 0.004451
2022-01-14 01:48:41,624 iteration 5820 : loss : 0.022094, loss_ce: 0.008511
2022-01-14 01:48:43,051 iteration 5821 : loss : 0.016080, loss_ce: 0.005476
2022-01-14 01:48:44,521 iteration 5822 : loss : 0.023517, loss_ce: 0.008746
2022-01-14 01:48:45,862 iteration 5823 : loss : 0.015165, loss_ce: 0.007167
2022-01-14 01:48:47,361 iteration 5824 : loss : 0.029488, loss_ce: 0.007165
2022-01-14 01:48:48,772 iteration 5825 : loss : 0.017377, loss_ce: 0.006014
2022-01-14 01:48:50,178 iteration 5826 : loss : 0.020079, loss_ce: 0.009296
2022-01-14 01:48:51,530 iteration 5827 : loss : 0.024542, loss_ce: 0.010044
2022-01-14 01:48:53,000 iteration 5828 : loss : 0.030180, loss_ce: 0.006825
2022-01-14 01:48:54,403 iteration 5829 : loss : 0.014035, loss_ce: 0.004950
2022-01-14 01:48:55,762 iteration 5830 : loss : 0.016620, loss_ce: 0.005598
2022-01-14 01:48:57,219 iteration 5831 : loss : 0.021620, loss_ce: 0.008745
 86%|████████████████████████▊    | 343/400 [2:29:10<23:59, 25.26s/it]2022-01-14 01:48:58,728 iteration 5832 : loss : 0.024690, loss_ce: 0.010956
2022-01-14 01:49:00,190 iteration 5833 : loss : 0.027164, loss_ce: 0.008612
2022-01-14 01:49:01,582 iteration 5834 : loss : 0.041236, loss_ce: 0.029154
2022-01-14 01:49:02,981 iteration 5835 : loss : 0.018626, loss_ce: 0.006926
2022-01-14 01:49:04,352 iteration 5836 : loss : 0.024231, loss_ce: 0.009137
2022-01-14 01:49:05,809 iteration 5837 : loss : 0.028355, loss_ce: 0.010535
2022-01-14 01:49:07,227 iteration 5838 : loss : 0.020826, loss_ce: 0.005972
2022-01-14 01:49:08,626 iteration 5839 : loss : 0.028231, loss_ce: 0.010761
2022-01-14 01:49:10,013 iteration 5840 : loss : 0.016718, loss_ce: 0.005266
2022-01-14 01:49:11,468 iteration 5841 : loss : 0.019283, loss_ce: 0.006149
2022-01-14 01:49:12,810 iteration 5842 : loss : 0.016651, loss_ce: 0.005280
2022-01-14 01:49:14,153 iteration 5843 : loss : 0.018670, loss_ce: 0.007010
2022-01-14 01:49:15,567 iteration 5844 : loss : 0.021227, loss_ce: 0.008211
2022-01-14 01:49:16,916 iteration 5845 : loss : 0.014359, loss_ce: 0.004887
2022-01-14 01:49:18,289 iteration 5846 : loss : 0.019593, loss_ce: 0.007705
2022-01-14 01:49:19,682 iteration 5847 : loss : 0.017609, loss_ce: 0.008112
2022-01-14 01:49:21,076 iteration 5848 : loss : 0.014061, loss_ce: 0.005072
 86%|████████████████████████▉    | 344/400 [2:29:34<23:10, 24.84s/it]2022-01-14 01:49:22,552 iteration 5849 : loss : 0.020575, loss_ce: 0.006163
2022-01-14 01:49:24,011 iteration 5850 : loss : 0.033077, loss_ce: 0.016318
2022-01-14 01:49:25,444 iteration 5851 : loss : 0.015472, loss_ce: 0.004037
2022-01-14 01:49:26,905 iteration 5852 : loss : 0.019560, loss_ce: 0.008158
2022-01-14 01:49:28,260 iteration 5853 : loss : 0.017972, loss_ce: 0.005817
2022-01-14 01:49:29,717 iteration 5854 : loss : 0.020863, loss_ce: 0.007261
2022-01-14 01:49:31,110 iteration 5855 : loss : 0.016485, loss_ce: 0.007470
2022-01-14 01:49:32,500 iteration 5856 : loss : 0.033275, loss_ce: 0.014307
2022-01-14 01:49:33,931 iteration 5857 : loss : 0.014832, loss_ce: 0.005709
2022-01-14 01:49:35,363 iteration 5858 : loss : 0.018475, loss_ce: 0.005404
2022-01-14 01:49:36,845 iteration 5859 : loss : 0.034258, loss_ce: 0.011971
2022-01-14 01:49:38,268 iteration 5860 : loss : 0.016278, loss_ce: 0.005670
2022-01-14 01:49:39,642 iteration 5861 : loss : 0.026062, loss_ce: 0.011614
2022-01-14 01:49:41,052 iteration 5862 : loss : 0.018464, loss_ce: 0.007754
2022-01-14 01:49:42,472 iteration 5863 : loss : 0.030939, loss_ce: 0.010342
2022-01-14 01:49:43,962 iteration 5864 : loss : 0.019035, loss_ce: 0.008410
2022-01-14 01:49:43,962 Training Data Eval:
2022-01-14 01:49:50,889   Average segmentation loss on training set: 0.0110
2022-01-14 01:49:50,890 Validation Data Eval:
2022-01-14 01:49:53,282   Average segmentation loss on validation set: 0.0715
2022-01-14 01:49:54,785 iteration 5865 : loss : 0.029168, loss_ce: 0.009197
 86%|█████████████████████████    | 345/400 [2:30:08<25:12, 27.50s/it]2022-01-14 01:49:56,196 iteration 5866 : loss : 0.018639, loss_ce: 0.004895
2022-01-14 01:49:57,577 iteration 5867 : loss : 0.014449, loss_ce: 0.005853
2022-01-14 01:49:59,025 iteration 5868 : loss : 0.016562, loss_ce: 0.006485
2022-01-14 01:50:00,411 iteration 5869 : loss : 0.033540, loss_ce: 0.010123
2022-01-14 01:50:01,927 iteration 5870 : loss : 0.030057, loss_ce: 0.012678
2022-01-14 01:50:03,314 iteration 5871 : loss : 0.017655, loss_ce: 0.006216
2022-01-14 01:50:04,680 iteration 5872 : loss : 0.021057, loss_ce: 0.006596
2022-01-14 01:50:06,115 iteration 5873 : loss : 0.025596, loss_ce: 0.015194
2022-01-14 01:50:07,535 iteration 5874 : loss : 0.022444, loss_ce: 0.008387
2022-01-14 01:50:08,979 iteration 5875 : loss : 0.016128, loss_ce: 0.007268
2022-01-14 01:50:10,470 iteration 5876 : loss : 0.018015, loss_ce: 0.006931
2022-01-14 01:50:11,926 iteration 5877 : loss : 0.034465, loss_ce: 0.017321
2022-01-14 01:50:13,301 iteration 5878 : loss : 0.016938, loss_ce: 0.005087
2022-01-14 01:50:14,698 iteration 5879 : loss : 0.022526, loss_ce: 0.008663
2022-01-14 01:50:16,125 iteration 5880 : loss : 0.017273, loss_ce: 0.004226
2022-01-14 01:50:17,493 iteration 5881 : loss : 0.014197, loss_ce: 0.005673
2022-01-14 01:50:18,833 iteration 5882 : loss : 0.017651, loss_ce: 0.006341
 86%|█████████████████████████    | 346/400 [2:30:32<23:48, 26.46s/it]2022-01-14 01:50:20,255 iteration 5883 : loss : 0.015140, loss_ce: 0.004232
2022-01-14 01:50:21,573 iteration 5884 : loss : 0.013838, loss_ce: 0.005360
2022-01-14 01:50:23,022 iteration 5885 : loss : 0.021250, loss_ce: 0.005357
2022-01-14 01:50:24,406 iteration 5886 : loss : 0.021792, loss_ce: 0.006652
2022-01-14 01:50:25,853 iteration 5887 : loss : 0.021371, loss_ce: 0.009868
2022-01-14 01:50:27,256 iteration 5888 : loss : 0.010695, loss_ce: 0.004110
2022-01-14 01:50:28,744 iteration 5889 : loss : 0.015441, loss_ce: 0.004721
2022-01-14 01:50:30,126 iteration 5890 : loss : 0.018303, loss_ce: 0.007526
2022-01-14 01:50:31,520 iteration 5891 : loss : 0.030715, loss_ce: 0.010353
2022-01-14 01:50:32,952 iteration 5892 : loss : 0.020623, loss_ce: 0.006362
2022-01-14 01:50:34,323 iteration 5893 : loss : 0.030255, loss_ce: 0.013985
2022-01-14 01:50:35,670 iteration 5894 : loss : 0.021029, loss_ce: 0.009129
2022-01-14 01:50:37,024 iteration 5895 : loss : 0.014138, loss_ce: 0.006024
2022-01-14 01:50:38,392 iteration 5896 : loss : 0.020146, loss_ce: 0.008472
2022-01-14 01:50:39,810 iteration 5897 : loss : 0.021956, loss_ce: 0.009474
2022-01-14 01:50:41,186 iteration 5898 : loss : 0.018206, loss_ce: 0.005660
2022-01-14 01:50:42,630 iteration 5899 : loss : 0.031802, loss_ce: 0.014766
 87%|█████████████████████████▏   | 347/400 [2:30:56<22:40, 25.66s/it]2022-01-14 01:50:44,043 iteration 5900 : loss : 0.018100, loss_ce: 0.006507
2022-01-14 01:50:45,561 iteration 5901 : loss : 0.021230, loss_ce: 0.008199
2022-01-14 01:50:47,067 iteration 5902 : loss : 0.026142, loss_ce: 0.012267
2022-01-14 01:50:48,479 iteration 5903 : loss : 0.017310, loss_ce: 0.005514
2022-01-14 01:50:49,913 iteration 5904 : loss : 0.018474, loss_ce: 0.008200
2022-01-14 01:50:51,288 iteration 5905 : loss : 0.016012, loss_ce: 0.005646
2022-01-14 01:50:52,699 iteration 5906 : loss : 0.019311, loss_ce: 0.007631
2022-01-14 01:50:54,134 iteration 5907 : loss : 0.034987, loss_ce: 0.010417
2022-01-14 01:50:55,556 iteration 5908 : loss : 0.019691, loss_ce: 0.006318
2022-01-14 01:50:56,941 iteration 5909 : loss : 0.013885, loss_ce: 0.005699
2022-01-14 01:50:58,338 iteration 5910 : loss : 0.016311, loss_ce: 0.007202
2022-01-14 01:50:59,757 iteration 5911 : loss : 0.015329, loss_ce: 0.005583
2022-01-14 01:51:01,274 iteration 5912 : loss : 0.050655, loss_ce: 0.009523
2022-01-14 01:51:02,609 iteration 5913 : loss : 0.019096, loss_ce: 0.006516
2022-01-14 01:51:04,090 iteration 5914 : loss : 0.023468, loss_ce: 0.008331
2022-01-14 01:51:05,527 iteration 5915 : loss : 0.022337, loss_ce: 0.010008
2022-01-14 01:51:06,927 iteration 5916 : loss : 0.017313, loss_ce: 0.007053
 87%|█████████████████████████▏   | 348/400 [2:31:20<21:53, 25.25s/it]2022-01-14 01:51:08,380 iteration 5917 : loss : 0.020186, loss_ce: 0.005144
2022-01-14 01:51:09,860 iteration 5918 : loss : 0.026387, loss_ce: 0.010887
2022-01-14 01:51:11,216 iteration 5919 : loss : 0.015160, loss_ce: 0.008946
2022-01-14 01:51:12,721 iteration 5920 : loss : 0.025510, loss_ce: 0.010083
2022-01-14 01:51:14,103 iteration 5921 : loss : 0.016906, loss_ce: 0.005085
2022-01-14 01:51:15,543 iteration 5922 : loss : 0.019443, loss_ce: 0.009187
2022-01-14 01:51:16,927 iteration 5923 : loss : 0.021734, loss_ce: 0.005351
2022-01-14 01:51:18,280 iteration 5924 : loss : 0.014049, loss_ce: 0.005447
2022-01-14 01:51:19,677 iteration 5925 : loss : 0.014928, loss_ce: 0.004613
2022-01-14 01:51:21,096 iteration 5926 : loss : 0.014252, loss_ce: 0.005325
2022-01-14 01:51:22,562 iteration 5927 : loss : 0.042800, loss_ce: 0.014560
2022-01-14 01:51:23,873 iteration 5928 : loss : 0.015056, loss_ce: 0.006161
2022-01-14 01:51:25,235 iteration 5929 : loss : 0.026829, loss_ce: 0.007238
2022-01-14 01:51:26,640 iteration 5930 : loss : 0.017081, loss_ce: 0.005986
2022-01-14 01:51:28,047 iteration 5931 : loss : 0.015258, loss_ce: 0.006332
2022-01-14 01:51:29,447 iteration 5932 : loss : 0.023752, loss_ce: 0.009023
2022-01-14 01:51:30,796 iteration 5933 : loss : 0.019166, loss_ce: 0.008210
 87%|█████████████████████████▎   | 349/400 [2:31:44<21:06, 24.84s/it]2022-01-14 01:51:32,178 iteration 5934 : loss : 0.016720, loss_ce: 0.005289
2022-01-14 01:51:33,505 iteration 5935 : loss : 0.017425, loss_ce: 0.007991
2022-01-14 01:51:34,834 iteration 5936 : loss : 0.019871, loss_ce: 0.008018
2022-01-14 01:51:36,252 iteration 5937 : loss : 0.030938, loss_ce: 0.013360
2022-01-14 01:51:37,671 iteration 5938 : loss : 0.019107, loss_ce: 0.009621
2022-01-14 01:51:39,127 iteration 5939 : loss : 0.022254, loss_ce: 0.009366
2022-01-14 01:51:40,482 iteration 5940 : loss : 0.013228, loss_ce: 0.004953
2022-01-14 01:51:41,922 iteration 5941 : loss : 0.023882, loss_ce: 0.008361
2022-01-14 01:51:43,320 iteration 5942 : loss : 0.022383, loss_ce: 0.008942
2022-01-14 01:51:44,754 iteration 5943 : loss : 0.021229, loss_ce: 0.007738
2022-01-14 01:51:46,069 iteration 5944 : loss : 0.018603, loss_ce: 0.007261
2022-01-14 01:51:47,584 iteration 5945 : loss : 0.040154, loss_ce: 0.012307
2022-01-14 01:51:48,994 iteration 5946 : loss : 0.016415, loss_ce: 0.007018
2022-01-14 01:51:50,522 iteration 5947 : loss : 0.040387, loss_ce: 0.011032
2022-01-14 01:51:51,983 iteration 5948 : loss : 0.022506, loss_ce: 0.007852
2022-01-14 01:51:53,376 iteration 5949 : loss : 0.020056, loss_ce: 0.005488
2022-01-14 01:51:53,376 Training Data Eval:
2022-01-14 01:52:00,295   Average segmentation loss on training set: 0.0103
2022-01-14 01:52:00,296 Validation Data Eval:
2022-01-14 01:52:02,688   Average segmentation loss on validation set: 0.0751
2022-01-14 01:52:04,024 iteration 5950 : loss : 0.012739, loss_ce: 0.004095
 88%|█████████████████████████▍   | 350/400 [2:32:17<22:47, 27.36s/it]2022-01-14 01:52:05,420 iteration 5951 : loss : 0.025780, loss_ce: 0.007832
2022-01-14 01:52:06,867 iteration 5952 : loss : 0.017889, loss_ce: 0.008330
2022-01-14 01:52:08,392 iteration 5953 : loss : 0.041085, loss_ce: 0.024967
2022-01-14 01:52:09,803 iteration 5954 : loss : 0.019688, loss_ce: 0.005469
2022-01-14 01:52:11,312 iteration 5955 : loss : 0.031261, loss_ce: 0.012106
2022-01-14 01:52:12,689 iteration 5956 : loss : 0.036996, loss_ce: 0.008479
2022-01-14 01:52:14,135 iteration 5957 : loss : 0.030490, loss_ce: 0.016067
2022-01-14 01:52:15,571 iteration 5958 : loss : 0.027141, loss_ce: 0.012330
2022-01-14 01:52:17,012 iteration 5959 : loss : 0.017342, loss_ce: 0.004414
2022-01-14 01:52:18,376 iteration 5960 : loss : 0.019681, loss_ce: 0.005917
2022-01-14 01:52:19,805 iteration 5961 : loss : 0.032066, loss_ce: 0.016826
2022-01-14 01:52:21,249 iteration 5962 : loss : 0.019424, loss_ce: 0.007020
2022-01-14 01:52:22,604 iteration 5963 : loss : 0.020502, loss_ce: 0.008542
2022-01-14 01:52:24,071 iteration 5964 : loss : 0.024453, loss_ce: 0.009915
2022-01-14 01:52:25,487 iteration 5965 : loss : 0.016061, loss_ce: 0.007916
2022-01-14 01:52:26,859 iteration 5966 : loss : 0.012479, loss_ce: 0.004352
2022-01-14 01:52:28,346 iteration 5967 : loss : 0.022108, loss_ce: 0.008038
 88%|█████████████████████████▍   | 351/400 [2:32:41<21:35, 26.44s/it]2022-01-14 01:52:29,774 iteration 5968 : loss : 0.023479, loss_ce: 0.008777
2022-01-14 01:52:31,165 iteration 5969 : loss : 0.015791, loss_ce: 0.007487
2022-01-14 01:52:32,588 iteration 5970 : loss : 0.017838, loss_ce: 0.007698
2022-01-14 01:52:33,943 iteration 5971 : loss : 0.016879, loss_ce: 0.006875
2022-01-14 01:52:35,292 iteration 5972 : loss : 0.017586, loss_ce: 0.004689
2022-01-14 01:52:36,635 iteration 5973 : loss : 0.022352, loss_ce: 0.009372
2022-01-14 01:52:38,017 iteration 5974 : loss : 0.023075, loss_ce: 0.006227
2022-01-14 01:52:39,435 iteration 5975 : loss : 0.021252, loss_ce: 0.012600
2022-01-14 01:52:40,858 iteration 5976 : loss : 0.025662, loss_ce: 0.008763
2022-01-14 01:52:42,196 iteration 5977 : loss : 0.018863, loss_ce: 0.007325
2022-01-14 01:52:43,580 iteration 5978 : loss : 0.018569, loss_ce: 0.007395
2022-01-14 01:52:44,967 iteration 5979 : loss : 0.015714, loss_ce: 0.004296
2022-01-14 01:52:46,425 iteration 5980 : loss : 0.025576, loss_ce: 0.005777
2022-01-14 01:52:47,890 iteration 5981 : loss : 0.025261, loss_ce: 0.010693
2022-01-14 01:52:49,294 iteration 5982 : loss : 0.024364, loss_ce: 0.012447
2022-01-14 01:52:50,717 iteration 5983 : loss : 0.039350, loss_ce: 0.009165
2022-01-14 01:52:52,176 iteration 5984 : loss : 0.025244, loss_ce: 0.008368
 88%|█████████████████████████▌   | 352/400 [2:33:05<20:31, 25.66s/it]2022-01-14 01:52:53,692 iteration 5985 : loss : 0.023023, loss_ce: 0.009518
2022-01-14 01:52:54,993 iteration 5986 : loss : 0.012860, loss_ce: 0.005973
2022-01-14 01:52:56,434 iteration 5987 : loss : 0.028371, loss_ce: 0.006965
2022-01-14 01:52:57,768 iteration 5988 : loss : 0.014742, loss_ce: 0.005874
2022-01-14 01:52:59,170 iteration 5989 : loss : 0.014191, loss_ce: 0.005196
2022-01-14 01:53:00,547 iteration 5990 : loss : 0.021509, loss_ce: 0.006680
2022-01-14 01:53:02,026 iteration 5991 : loss : 0.024957, loss_ce: 0.007059
2022-01-14 01:53:03,479 iteration 5992 : loss : 0.050024, loss_ce: 0.016655
2022-01-14 01:53:04,875 iteration 5993 : loss : 0.025774, loss_ce: 0.010580
2022-01-14 01:53:06,206 iteration 5994 : loss : 0.020639, loss_ce: 0.009575
2022-01-14 01:53:07,692 iteration 5995 : loss : 0.017361, loss_ce: 0.005437
2022-01-14 01:53:09,145 iteration 5996 : loss : 0.013843, loss_ce: 0.006981
2022-01-14 01:53:10,495 iteration 5997 : loss : 0.017023, loss_ce: 0.005113
2022-01-14 01:53:12,014 iteration 5998 : loss : 0.022789, loss_ce: 0.008151
2022-01-14 01:53:13,383 iteration 5999 : loss : 0.028736, loss_ce: 0.010856
2022-01-14 01:53:14,885 iteration 6000 : loss : 0.027134, loss_ce: 0.011938
2022-01-14 01:53:16,250 iteration 6001 : loss : 0.012863, loss_ce: 0.004833
 88%|█████████████████████████▌   | 353/400 [2:33:29<19:43, 25.18s/it]2022-01-14 01:53:17,658 iteration 6002 : loss : 0.019507, loss_ce: 0.006967
2022-01-14 01:53:19,080 iteration 6003 : loss : 0.013933, loss_ce: 0.006261
2022-01-14 01:53:20,479 iteration 6004 : loss : 0.017285, loss_ce: 0.006408
2022-01-14 01:53:21,849 iteration 6005 : loss : 0.024365, loss_ce: 0.009023
2022-01-14 01:53:23,302 iteration 6006 : loss : 0.019379, loss_ce: 0.006286
2022-01-14 01:53:24,651 iteration 6007 : loss : 0.015252, loss_ce: 0.005739
2022-01-14 01:53:26,030 iteration 6008 : loss : 0.017460, loss_ce: 0.005826
2022-01-14 01:53:27,479 iteration 6009 : loss : 0.021195, loss_ce: 0.006858
2022-01-14 01:53:28,820 iteration 6010 : loss : 0.020745, loss_ce: 0.004889
2022-01-14 01:53:30,243 iteration 6011 : loss : 0.036808, loss_ce: 0.009303
2022-01-14 01:53:31,711 iteration 6012 : loss : 0.024295, loss_ce: 0.010843
2022-01-14 01:53:33,093 iteration 6013 : loss : 0.031952, loss_ce: 0.012022
2022-01-14 01:53:34,467 iteration 6014 : loss : 0.016795, loss_ce: 0.005751
2022-01-14 01:53:35,815 iteration 6015 : loss : 0.014693, loss_ce: 0.007593
2022-01-14 01:53:37,204 iteration 6016 : loss : 0.012742, loss_ce: 0.003914
2022-01-14 01:53:38,631 iteration 6017 : loss : 0.018698, loss_ce: 0.006149
2022-01-14 01:53:39,968 iteration 6018 : loss : 0.017082, loss_ce: 0.006814
 88%|█████████████████████████▋   | 354/400 [2:33:53<18:58, 24.74s/it]2022-01-14 01:53:41,473 iteration 6019 : loss : 0.016608, loss_ce: 0.005767
2022-01-14 01:53:42,908 iteration 6020 : loss : 0.024489, loss_ce: 0.007396
2022-01-14 01:53:44,264 iteration 6021 : loss : 0.014493, loss_ce: 0.005308
2022-01-14 01:53:45,699 iteration 6022 : loss : 0.015534, loss_ce: 0.006115
2022-01-14 01:53:47,131 iteration 6023 : loss : 0.015696, loss_ce: 0.006804
2022-01-14 01:53:48,530 iteration 6024 : loss : 0.013436, loss_ce: 0.005395
2022-01-14 01:53:49,878 iteration 6025 : loss : 0.022282, loss_ce: 0.004861
2022-01-14 01:53:51,254 iteration 6026 : loss : 0.019569, loss_ce: 0.006949
2022-01-14 01:53:52,693 iteration 6027 : loss : 0.015721, loss_ce: 0.006740
2022-01-14 01:53:54,046 iteration 6028 : loss : 0.016309, loss_ce: 0.006804
2022-01-14 01:53:55,456 iteration 6029 : loss : 0.025525, loss_ce: 0.014164
2022-01-14 01:53:56,901 iteration 6030 : loss : 0.030060, loss_ce: 0.011661
2022-01-14 01:53:58,348 iteration 6031 : loss : 0.026282, loss_ce: 0.008127
2022-01-14 01:53:59,755 iteration 6032 : loss : 0.023719, loss_ce: 0.006673
2022-01-14 01:54:01,149 iteration 6033 : loss : 0.026777, loss_ce: 0.009158
2022-01-14 01:54:02,513 iteration 6034 : loss : 0.011707, loss_ce: 0.004206
2022-01-14 01:54:02,513 Training Data Eval:
2022-01-14 01:54:09,573   Average segmentation loss on training set: 0.0103
2022-01-14 01:54:09,574 Validation Data Eval:
2022-01-14 01:54:12,019   Average segmentation loss on validation set: 0.0725
2022-01-14 01:54:13,392 iteration 6035 : loss : 0.020422, loss_ce: 0.009983
 89%|█████████████████████████▋   | 355/400 [2:34:26<20:30, 27.35s/it]2022-01-14 01:54:14,876 iteration 6036 : loss : 0.018042, loss_ce: 0.009728
2022-01-14 01:54:16,235 iteration 6037 : loss : 0.012843, loss_ce: 0.005385
2022-01-14 01:54:17,609 iteration 6038 : loss : 0.017285, loss_ce: 0.006531
2022-01-14 01:54:18,931 iteration 6039 : loss : 0.013523, loss_ce: 0.004655
2022-01-14 01:54:20,319 iteration 6040 : loss : 0.018012, loss_ce: 0.005177
2022-01-14 01:54:21,779 iteration 6041 : loss : 0.021109, loss_ce: 0.008229
2022-01-14 01:54:23,150 iteration 6042 : loss : 0.018203, loss_ce: 0.004386
2022-01-14 01:54:24,501 iteration 6043 : loss : 0.013335, loss_ce: 0.003445
2022-01-14 01:54:25,936 iteration 6044 : loss : 0.016154, loss_ce: 0.004556
2022-01-14 01:54:27,320 iteration 6045 : loss : 0.016751, loss_ce: 0.006614
2022-01-14 01:54:28,747 iteration 6046 : loss : 0.021715, loss_ce: 0.010102
2022-01-14 01:54:30,134 iteration 6047 : loss : 0.013317, loss_ce: 0.004916
2022-01-14 01:54:31,573 iteration 6048 : loss : 0.028910, loss_ce: 0.014377
2022-01-14 01:54:32,969 iteration 6049 : loss : 0.015322, loss_ce: 0.007534
2022-01-14 01:54:34,371 iteration 6050 : loss : 0.019002, loss_ce: 0.006328
2022-01-14 01:54:35,868 iteration 6051 : loss : 0.019527, loss_ce: 0.007399
2022-01-14 01:54:37,259 iteration 6052 : loss : 0.018125, loss_ce: 0.009123
 89%|█████████████████████████▊   | 356/400 [2:34:50<19:17, 26.30s/it]2022-01-14 01:54:38,678 iteration 6053 : loss : 0.019903, loss_ce: 0.007489
2022-01-14 01:54:40,028 iteration 6054 : loss : 0.025523, loss_ce: 0.013634
2022-01-14 01:54:41,502 iteration 6055 : loss : 0.020128, loss_ce: 0.007267
2022-01-14 01:54:42,892 iteration 6056 : loss : 0.013889, loss_ce: 0.005337
2022-01-14 01:54:44,259 iteration 6057 : loss : 0.019756, loss_ce: 0.006689
2022-01-14 01:54:45,694 iteration 6058 : loss : 0.018933, loss_ce: 0.005038
2022-01-14 01:54:47,149 iteration 6059 : loss : 0.016020, loss_ce: 0.007248
2022-01-14 01:54:48,723 iteration 6060 : loss : 0.043932, loss_ce: 0.015029
2022-01-14 01:54:50,125 iteration 6061 : loss : 0.014145, loss_ce: 0.005846
2022-01-14 01:54:51,597 iteration 6062 : loss : 0.025851, loss_ce: 0.008760
2022-01-14 01:54:52,968 iteration 6063 : loss : 0.018072, loss_ce: 0.005397
2022-01-14 01:54:54,429 iteration 6064 : loss : 0.019175, loss_ce: 0.008573
2022-01-14 01:54:55,767 iteration 6065 : loss : 0.011677, loss_ce: 0.004376
2022-01-14 01:54:57,122 iteration 6066 : loss : 0.012188, loss_ce: 0.003595
2022-01-14 01:54:58,519 iteration 6067 : loss : 0.016831, loss_ce: 0.007094
2022-01-14 01:54:59,866 iteration 6068 : loss : 0.013151, loss_ce: 0.003720
2022-01-14 01:55:01,233 iteration 6069 : loss : 0.025923, loss_ce: 0.011051
 89%|█████████████████████████▉   | 357/400 [2:35:14<18:21, 25.61s/it]2022-01-14 01:55:02,694 iteration 6070 : loss : 0.011377, loss_ce: 0.005863
2022-01-14 01:55:04,052 iteration 6071 : loss : 0.013873, loss_ce: 0.004636
2022-01-14 01:55:05,434 iteration 6072 : loss : 0.014713, loss_ce: 0.007069
2022-01-14 01:55:06,845 iteration 6073 : loss : 0.023030, loss_ce: 0.006599
2022-01-14 01:55:08,287 iteration 6074 : loss : 0.016796, loss_ce: 0.006188
2022-01-14 01:55:09,621 iteration 6075 : loss : 0.012808, loss_ce: 0.005526
2022-01-14 01:55:11,023 iteration 6076 : loss : 0.016252, loss_ce: 0.003906
2022-01-14 01:55:12,469 iteration 6077 : loss : 0.018948, loss_ce: 0.008617
2022-01-14 01:55:13,943 iteration 6078 : loss : 0.018274, loss_ce: 0.006409
2022-01-14 01:55:15,477 iteration 6079 : loss : 0.017526, loss_ce: 0.007243
2022-01-14 01:55:16,881 iteration 6080 : loss : 0.018702, loss_ce: 0.006452
2022-01-14 01:55:18,316 iteration 6081 : loss : 0.025490, loss_ce: 0.009432
2022-01-14 01:55:19,653 iteration 6082 : loss : 0.017435, loss_ce: 0.004795
2022-01-14 01:55:21,012 iteration 6083 : loss : 0.017644, loss_ce: 0.005195
2022-01-14 01:55:22,398 iteration 6084 : loss : 0.023967, loss_ce: 0.005373
2022-01-14 01:55:23,793 iteration 6085 : loss : 0.022173, loss_ce: 0.007992
2022-01-14 01:55:25,190 iteration 6086 : loss : 0.017757, loss_ce: 0.005507
 90%|█████████████████████████▉   | 358/400 [2:35:38<17:34, 25.11s/it]2022-01-14 01:55:26,574 iteration 6087 : loss : 0.016287, loss_ce: 0.005168
2022-01-14 01:55:28,006 iteration 6088 : loss : 0.014966, loss_ce: 0.005505
2022-01-14 01:55:29,384 iteration 6089 : loss : 0.015050, loss_ce: 0.004697
2022-01-14 01:55:30,679 iteration 6090 : loss : 0.014180, loss_ce: 0.005904
2022-01-14 01:55:32,086 iteration 6091 : loss : 0.014648, loss_ce: 0.004957
2022-01-14 01:55:33,512 iteration 6092 : loss : 0.016166, loss_ce: 0.004980
2022-01-14 01:55:34,903 iteration 6093 : loss : 0.024180, loss_ce: 0.010915
2022-01-14 01:55:36,267 iteration 6094 : loss : 0.024172, loss_ce: 0.009095
2022-01-14 01:55:37,654 iteration 6095 : loss : 0.019448, loss_ce: 0.006223
2022-01-14 01:55:39,086 iteration 6096 : loss : 0.018368, loss_ce: 0.005918
2022-01-14 01:55:40,513 iteration 6097 : loss : 0.013683, loss_ce: 0.005440
2022-01-14 01:55:42,018 iteration 6098 : loss : 0.022312, loss_ce: 0.010319
2022-01-14 01:55:43,455 iteration 6099 : loss : 0.015646, loss_ce: 0.006601
2022-01-14 01:55:44,873 iteration 6100 : loss : 0.018854, loss_ce: 0.010298
2022-01-14 01:55:46,297 iteration 6101 : loss : 0.026179, loss_ce: 0.009848
2022-01-14 01:55:47,728 iteration 6102 : loss : 0.023808, loss_ce: 0.012424
2022-01-14 01:55:49,175 iteration 6103 : loss : 0.030011, loss_ce: 0.009143
 90%|██████████████████████████   | 359/400 [2:36:02<16:55, 24.78s/it]2022-01-14 01:55:50,697 iteration 6104 : loss : 0.022102, loss_ce: 0.008921
2022-01-14 01:55:52,155 iteration 6105 : loss : 0.015215, loss_ce: 0.007014
2022-01-14 01:55:53,603 iteration 6106 : loss : 0.021225, loss_ce: 0.009534
2022-01-14 01:55:55,016 iteration 6107 : loss : 0.019219, loss_ce: 0.007006
2022-01-14 01:55:56,395 iteration 6108 : loss : 0.018603, loss_ce: 0.008531
2022-01-14 01:55:57,791 iteration 6109 : loss : 0.017749, loss_ce: 0.004145
2022-01-14 01:55:59,148 iteration 6110 : loss : 0.019779, loss_ce: 0.009586
2022-01-14 01:56:00,521 iteration 6111 : loss : 0.026617, loss_ce: 0.012188
2022-01-14 01:56:01,921 iteration 6112 : loss : 0.026828, loss_ce: 0.007582
2022-01-14 01:56:03,326 iteration 6113 : loss : 0.016032, loss_ce: 0.006722
2022-01-14 01:56:04,761 iteration 6114 : loss : 0.019902, loss_ce: 0.006181
2022-01-14 01:56:06,158 iteration 6115 : loss : 0.022285, loss_ce: 0.010367
2022-01-14 01:56:07,560 iteration 6116 : loss : 0.021479, loss_ce: 0.007426
2022-01-14 01:56:08,906 iteration 6117 : loss : 0.015046, loss_ce: 0.005679
2022-01-14 01:56:10,239 iteration 6118 : loss : 0.012602, loss_ce: 0.003873
2022-01-14 01:56:11,731 iteration 6119 : loss : 0.023723, loss_ce: 0.011332
2022-01-14 01:56:11,732 Training Data Eval:
2022-01-14 01:56:18,854   Average segmentation loss on training set: 0.0099
2022-01-14 01:56:18,854 Validation Data Eval:
2022-01-14 01:56:21,326   Average segmentation loss on validation set: 0.0758
2022-01-14 01:56:22,746 iteration 6120 : loss : 0.025757, loss_ce: 0.007354
 90%|██████████████████████████   | 360/400 [2:36:36<18:16, 27.41s/it]2022-01-14 01:56:24,213 iteration 6121 : loss : 0.035121, loss_ce: 0.014879
2022-01-14 01:56:25,604 iteration 6122 : loss : 0.016965, loss_ce: 0.007235
2022-01-14 01:56:26,987 iteration 6123 : loss : 0.023427, loss_ce: 0.009207
2022-01-14 01:56:28,332 iteration 6124 : loss : 0.013875, loss_ce: 0.005107
2022-01-14 01:56:29,716 iteration 6125 : loss : 0.031140, loss_ce: 0.013759
2022-01-14 01:56:31,058 iteration 6126 : loss : 0.014227, loss_ce: 0.007469
2022-01-14 01:56:32,489 iteration 6127 : loss : 0.013461, loss_ce: 0.004238
2022-01-14 01:56:33,855 iteration 6128 : loss : 0.015791, loss_ce: 0.005152
2022-01-14 01:56:35,329 iteration 6129 : loss : 0.015856, loss_ce: 0.006367
2022-01-14 01:56:36,700 iteration 6130 : loss : 0.015855, loss_ce: 0.003979
2022-01-14 01:56:38,169 iteration 6131 : loss : 0.019322, loss_ce: 0.010060
2022-01-14 01:56:39,560 iteration 6132 : loss : 0.023232, loss_ce: 0.013161
2022-01-14 01:56:41,024 iteration 6133 : loss : 0.024402, loss_ce: 0.006662
2022-01-14 01:56:42,446 iteration 6134 : loss : 0.024773, loss_ce: 0.007757
2022-01-14 01:56:43,952 iteration 6135 : loss : 0.023890, loss_ce: 0.007458
2022-01-14 01:56:45,342 iteration 6136 : loss : 0.025179, loss_ce: 0.006795
2022-01-14 01:56:46,700 iteration 6137 : loss : 0.019964, loss_ce: 0.008628
 90%|██████████████████████████▏  | 361/400 [2:37:00<17:08, 26.37s/it]2022-01-14 01:56:48,129 iteration 6138 : loss : 0.024257, loss_ce: 0.007798
2022-01-14 01:56:49,510 iteration 6139 : loss : 0.017305, loss_ce: 0.007055
2022-01-14 01:56:50,877 iteration 6140 : loss : 0.016144, loss_ce: 0.007207
2022-01-14 01:56:52,216 iteration 6141 : loss : 0.013081, loss_ce: 0.005098
2022-01-14 01:56:53,548 iteration 6142 : loss : 0.011913, loss_ce: 0.005220
2022-01-14 01:56:54,982 iteration 6143 : loss : 0.016648, loss_ce: 0.004534
2022-01-14 01:56:56,362 iteration 6144 : loss : 0.015213, loss_ce: 0.006136
2022-01-14 01:56:57,734 iteration 6145 : loss : 0.014966, loss_ce: 0.006556
2022-01-14 01:56:59,080 iteration 6146 : loss : 0.022559, loss_ce: 0.007162
2022-01-14 01:57:00,468 iteration 6147 : loss : 0.016421, loss_ce: 0.006959
2022-01-14 01:57:01,932 iteration 6148 : loss : 0.017070, loss_ce: 0.006106
2022-01-14 01:57:03,369 iteration 6149 : loss : 0.020587, loss_ce: 0.007698
2022-01-14 01:57:04,862 iteration 6150 : loss : 0.020522, loss_ce: 0.006233
2022-01-14 01:57:06,351 iteration 6151 : loss : 0.045022, loss_ce: 0.011237
2022-01-14 01:57:07,721 iteration 6152 : loss : 0.015542, loss_ce: 0.006187
2022-01-14 01:57:09,166 iteration 6153 : loss : 0.047366, loss_ce: 0.008460
2022-01-14 01:57:10,600 iteration 6154 : loss : 0.021482, loss_ce: 0.009174
 90%|██████████████████████████▏  | 362/400 [2:37:24<16:13, 25.63s/it]2022-01-14 01:57:12,114 iteration 6155 : loss : 0.019944, loss_ce: 0.006931
2022-01-14 01:57:13,575 iteration 6156 : loss : 0.021828, loss_ce: 0.009040
2022-01-14 01:57:15,006 iteration 6157 : loss : 0.024601, loss_ce: 0.009489
2022-01-14 01:57:16,514 iteration 6158 : loss : 0.019882, loss_ce: 0.005374
2022-01-14 01:57:17,891 iteration 6159 : loss : 0.014815, loss_ce: 0.004737
2022-01-14 01:57:19,287 iteration 6160 : loss : 0.029488, loss_ce: 0.010521
2022-01-14 01:57:20,754 iteration 6161 : loss : 0.018926, loss_ce: 0.005943
2022-01-14 01:57:22,217 iteration 6162 : loss : 0.041060, loss_ce: 0.010283
2022-01-14 01:57:23,624 iteration 6163 : loss : 0.021633, loss_ce: 0.008780
2022-01-14 01:57:24,972 iteration 6164 : loss : 0.013200, loss_ce: 0.003838
2022-01-14 01:57:26,441 iteration 6165 : loss : 0.023547, loss_ce: 0.008798
2022-01-14 01:57:27,823 iteration 6166 : loss : 0.014258, loss_ce: 0.005131
2022-01-14 01:57:29,302 iteration 6167 : loss : 0.024039, loss_ce: 0.012176
2022-01-14 01:57:30,718 iteration 6168 : loss : 0.022458, loss_ce: 0.008257
2022-01-14 01:57:32,150 iteration 6169 : loss : 0.052760, loss_ce: 0.014140
2022-01-14 01:57:33,519 iteration 6170 : loss : 0.015331, loss_ce: 0.007370
2022-01-14 01:57:34,905 iteration 6171 : loss : 0.025436, loss_ce: 0.011644
 91%|██████████████████████████▎  | 363/400 [2:37:48<15:33, 25.23s/it]2022-01-14 01:57:36,361 iteration 6172 : loss : 0.020032, loss_ce: 0.008458
2022-01-14 01:57:37,842 iteration 6173 : loss : 0.028660, loss_ce: 0.006941
2022-01-14 01:57:39,272 iteration 6174 : loss : 0.014908, loss_ce: 0.005515
2022-01-14 01:57:40,797 iteration 6175 : loss : 0.023970, loss_ce: 0.008085
2022-01-14 01:57:42,214 iteration 6176 : loss : 0.015809, loss_ce: 0.005654
2022-01-14 01:57:43,602 iteration 6177 : loss : 0.014767, loss_ce: 0.006289
2022-01-14 01:57:45,029 iteration 6178 : loss : 0.015900, loss_ce: 0.005887
2022-01-14 01:57:46,394 iteration 6179 : loss : 0.018147, loss_ce: 0.005648
2022-01-14 01:57:47,844 iteration 6180 : loss : 0.021235, loss_ce: 0.009015
2022-01-14 01:57:49,231 iteration 6181 : loss : 0.013049, loss_ce: 0.004212
2022-01-14 01:57:50,622 iteration 6182 : loss : 0.015897, loss_ce: 0.004929
2022-01-14 01:57:52,084 iteration 6183 : loss : 0.016688, loss_ce: 0.006311
2022-01-14 01:57:53,531 iteration 6184 : loss : 0.020484, loss_ce: 0.009288
2022-01-14 01:57:54,998 iteration 6185 : loss : 0.028978, loss_ce: 0.009340
2022-01-14 01:57:56,407 iteration 6186 : loss : 0.014764, loss_ce: 0.005735
2022-01-14 01:57:57,858 iteration 6187 : loss : 0.017184, loss_ce: 0.008109
2022-01-14 01:57:59,339 iteration 6188 : loss : 0.024250, loss_ce: 0.011199
 91%|██████████████████████████▍  | 364/400 [2:38:12<14:59, 25.00s/it]2022-01-14 01:58:00,859 iteration 6189 : loss : 0.034790, loss_ce: 0.007813
2022-01-14 01:58:02,324 iteration 6190 : loss : 0.021560, loss_ce: 0.006122
2022-01-14 01:58:03,693 iteration 6191 : loss : 0.018327, loss_ce: 0.010854
2022-01-14 01:58:05,023 iteration 6192 : loss : 0.012395, loss_ce: 0.004730
2022-01-14 01:58:06,417 iteration 6193 : loss : 0.020326, loss_ce: 0.006363
2022-01-14 01:58:07,760 iteration 6194 : loss : 0.016620, loss_ce: 0.007144
2022-01-14 01:58:09,227 iteration 6195 : loss : 0.015796, loss_ce: 0.005201
2022-01-14 01:58:10,606 iteration 6196 : loss : 0.016931, loss_ce: 0.006471
2022-01-14 01:58:11,955 iteration 6197 : loss : 0.017715, loss_ce: 0.008989
2022-01-14 01:58:13,465 iteration 6198 : loss : 0.034144, loss_ce: 0.008392
2022-01-14 01:58:14,843 iteration 6199 : loss : 0.020472, loss_ce: 0.009247
2022-01-14 01:58:16,226 iteration 6200 : loss : 0.017574, loss_ce: 0.007490
2022-01-14 01:58:17,628 iteration 6201 : loss : 0.016342, loss_ce: 0.006224
2022-01-14 01:58:18,962 iteration 6202 : loss : 0.014290, loss_ce: 0.005416
2022-01-14 01:58:20,532 iteration 6203 : loss : 0.034428, loss_ce: 0.015935
2022-01-14 01:58:21,865 iteration 6204 : loss : 0.012836, loss_ce: 0.005636
2022-01-14 01:58:21,865 Training Data Eval:
2022-01-14 01:58:28,798   Average segmentation loss on training set: 0.0101
2022-01-14 01:58:28,799 Validation Data Eval:
2022-01-14 01:58:31,276   Average segmentation loss on validation set: 0.0749
2022-01-14 01:58:32,761 iteration 6205 : loss : 0.023701, loss_ce: 0.007400
 91%|██████████████████████████▍  | 365/400 [2:38:46<16:03, 27.53s/it]2022-01-14 01:58:34,261 iteration 6206 : loss : 0.025692, loss_ce: 0.011474
2022-01-14 01:58:35,679 iteration 6207 : loss : 0.017977, loss_ce: 0.007577
2022-01-14 01:58:37,135 iteration 6208 : loss : 0.029506, loss_ce: 0.009755
2022-01-14 01:58:38,533 iteration 6209 : loss : 0.017505, loss_ce: 0.006707
2022-01-14 01:58:39,937 iteration 6210 : loss : 0.017287, loss_ce: 0.006566
2022-01-14 01:58:41,324 iteration 6211 : loss : 0.017226, loss_ce: 0.008259
2022-01-14 01:58:42,682 iteration 6212 : loss : 0.017294, loss_ce: 0.006260
2022-01-14 01:58:43,984 iteration 6213 : loss : 0.014375, loss_ce: 0.004893
2022-01-14 01:58:45,469 iteration 6214 : loss : 0.034099, loss_ce: 0.010776
2022-01-14 01:58:46,866 iteration 6215 : loss : 0.016680, loss_ce: 0.005144
2022-01-14 01:58:48,289 iteration 6216 : loss : 0.020374, loss_ce: 0.006265
2022-01-14 01:58:49,729 iteration 6217 : loss : 0.027997, loss_ce: 0.011930
2022-01-14 01:58:51,096 iteration 6218 : loss : 0.015755, loss_ce: 0.006429
2022-01-14 01:58:52,537 iteration 6219 : loss : 0.022603, loss_ce: 0.007226
2022-01-14 01:58:53,863 iteration 6220 : loss : 0.013089, loss_ce: 0.003401
2022-01-14 01:58:55,342 iteration 6221 : loss : 0.015068, loss_ce: 0.004640
2022-01-14 01:58:56,766 iteration 6222 : loss : 0.012949, loss_ce: 0.005706
 92%|██████████████████████████▌  | 366/400 [2:39:10<14:59, 26.47s/it]2022-01-14 01:58:58,240 iteration 6223 : loss : 0.019701, loss_ce: 0.008733
2022-01-14 01:58:59,697 iteration 6224 : loss : 0.023344, loss_ce: 0.015764
2022-01-14 01:59:01,113 iteration 6225 : loss : 0.013550, loss_ce: 0.006172
2022-01-14 01:59:02,517 iteration 6226 : loss : 0.018308, loss_ce: 0.006468
2022-01-14 01:59:04,007 iteration 6227 : loss : 0.015369, loss_ce: 0.005248
2022-01-14 01:59:05,389 iteration 6228 : loss : 0.019950, loss_ce: 0.007470
2022-01-14 01:59:06,825 iteration 6229 : loss : 0.017018, loss_ce: 0.005316
2022-01-14 01:59:08,267 iteration 6230 : loss : 0.036929, loss_ce: 0.007936
2022-01-14 01:59:09,609 iteration 6231 : loss : 0.028281, loss_ce: 0.014296
2022-01-14 01:59:10,990 iteration 6232 : loss : 0.018730, loss_ce: 0.006717
2022-01-14 01:59:12,457 iteration 6233 : loss : 0.030243, loss_ce: 0.011037
2022-01-14 01:59:13,838 iteration 6234 : loss : 0.019814, loss_ce: 0.008206
2022-01-14 01:59:15,238 iteration 6235 : loss : 0.021518, loss_ce: 0.006267
2022-01-14 01:59:16,705 iteration 6236 : loss : 0.027729, loss_ce: 0.010569
2022-01-14 01:59:18,152 iteration 6237 : loss : 0.021280, loss_ce: 0.006742
2022-01-14 01:59:19,655 iteration 6238 : loss : 0.016566, loss_ce: 0.006582
2022-01-14 01:59:21,142 iteration 6239 : loss : 0.024366, loss_ce: 0.009590
 92%|██████████████████████████▌  | 367/400 [2:39:34<14:12, 25.84s/it]2022-01-14 01:59:22,579 iteration 6240 : loss : 0.021587, loss_ce: 0.007332
2022-01-14 01:59:23,940 iteration 6241 : loss : 0.015924, loss_ce: 0.006879
2022-01-14 01:59:25,373 iteration 6242 : loss : 0.016391, loss_ce: 0.007545
2022-01-14 01:59:26,781 iteration 6243 : loss : 0.019195, loss_ce: 0.007375
2022-01-14 01:59:28,184 iteration 6244 : loss : 0.032250, loss_ce: 0.011954
2022-01-14 01:59:29,607 iteration 6245 : loss : 0.016922, loss_ce: 0.007271
2022-01-14 01:59:31,013 iteration 6246 : loss : 0.014567, loss_ce: 0.005827
2022-01-14 01:59:32,411 iteration 6247 : loss : 0.014411, loss_ce: 0.004509
2022-01-14 01:59:33,857 iteration 6248 : loss : 0.026984, loss_ce: 0.006624
2022-01-14 01:59:35,317 iteration 6249 : loss : 0.023875, loss_ce: 0.008701
2022-01-14 01:59:36,644 iteration 6250 : loss : 0.014823, loss_ce: 0.003670
2022-01-14 01:59:38,104 iteration 6251 : loss : 0.042114, loss_ce: 0.033489
2022-01-14 01:59:39,465 iteration 6252 : loss : 0.012678, loss_ce: 0.004031
2022-01-14 01:59:40,975 iteration 6253 : loss : 0.021491, loss_ce: 0.008196
2022-01-14 01:59:42,310 iteration 6254 : loss : 0.010415, loss_ce: 0.004433
2022-01-14 01:59:43,884 iteration 6255 : loss : 0.055382, loss_ce: 0.023096
2022-01-14 01:59:45,257 iteration 6256 : loss : 0.020200, loss_ce: 0.007970
 92%|██████████████████████████▋  | 368/400 [2:39:58<13:30, 25.32s/it]2022-01-14 01:59:46,777 iteration 6257 : loss : 0.022247, loss_ce: 0.010089
2022-01-14 01:59:48,171 iteration 6258 : loss : 0.011377, loss_ce: 0.005340
2022-01-14 01:59:49,613 iteration 6259 : loss : 0.017839, loss_ce: 0.008435
2022-01-14 01:59:51,053 iteration 6260 : loss : 0.022505, loss_ce: 0.005674
2022-01-14 01:59:52,440 iteration 6261 : loss : 0.014374, loss_ce: 0.005719
2022-01-14 01:59:53,888 iteration 6262 : loss : 0.025028, loss_ce: 0.010388
2022-01-14 01:59:55,381 iteration 6263 : loss : 0.017139, loss_ce: 0.004189
2022-01-14 01:59:56,782 iteration 6264 : loss : 0.015111, loss_ce: 0.006865
2022-01-14 01:59:58,149 iteration 6265 : loss : 0.017214, loss_ce: 0.007378
2022-01-14 01:59:59,575 iteration 6266 : loss : 0.014203, loss_ce: 0.006066
2022-01-14 02:00:00,973 iteration 6267 : loss : 0.024384, loss_ce: 0.009009
2022-01-14 02:00:02,357 iteration 6268 : loss : 0.024488, loss_ce: 0.008501
2022-01-14 02:00:03,719 iteration 6269 : loss : 0.028207, loss_ce: 0.008868
2022-01-14 02:00:05,149 iteration 6270 : loss : 0.015916, loss_ce: 0.004663
2022-01-14 02:00:06,537 iteration 6271 : loss : 0.023298, loss_ce: 0.005059
2022-01-14 02:00:07,909 iteration 6272 : loss : 0.011554, loss_ce: 0.003155
2022-01-14 02:00:09,251 iteration 6273 : loss : 0.013187, loss_ce: 0.005171
 92%|██████████████████████████▊  | 369/400 [2:40:22<12:52, 24.92s/it]2022-01-14 02:00:10,708 iteration 6274 : loss : 0.023881, loss_ce: 0.008231
2022-01-14 02:00:12,117 iteration 6275 : loss : 0.026677, loss_ce: 0.011909
2022-01-14 02:00:13,519 iteration 6276 : loss : 0.016806, loss_ce: 0.005542
2022-01-14 02:00:14,961 iteration 6277 : loss : 0.020602, loss_ce: 0.005754
2022-01-14 02:00:16,421 iteration 6278 : loss : 0.023592, loss_ce: 0.008714
2022-01-14 02:00:17,958 iteration 6279 : loss : 0.030642, loss_ce: 0.009685
2022-01-14 02:00:19,365 iteration 6280 : loss : 0.017588, loss_ce: 0.008349
2022-01-14 02:00:20,744 iteration 6281 : loss : 0.012570, loss_ce: 0.004115
2022-01-14 02:00:22,113 iteration 6282 : loss : 0.014116, loss_ce: 0.005504
2022-01-14 02:00:23,560 iteration 6283 : loss : 0.018168, loss_ce: 0.005620
2022-01-14 02:00:25,045 iteration 6284 : loss : 0.022942, loss_ce: 0.012634
2022-01-14 02:00:26,439 iteration 6285 : loss : 0.025637, loss_ce: 0.008951
2022-01-14 02:00:27,861 iteration 6286 : loss : 0.016602, loss_ce: 0.009146
2022-01-14 02:00:29,312 iteration 6287 : loss : 0.013674, loss_ce: 0.004804
2022-01-14 02:00:30,772 iteration 6288 : loss : 0.019129, loss_ce: 0.006410
2022-01-14 02:00:32,142 iteration 6289 : loss : 0.016267, loss_ce: 0.005536
2022-01-14 02:00:32,143 Training Data Eval:
2022-01-14 02:00:39,056   Average segmentation loss on training set: 0.0100
2022-01-14 02:00:39,056 Validation Data Eval:
2022-01-14 02:00:41,465   Average segmentation loss on validation set: 0.0778
2022-01-14 02:00:42,831 iteration 6290 : loss : 0.014417, loss_ce: 0.004990
 92%|██████████████████████████▊  | 370/400 [2:40:56<13:45, 27.52s/it]2022-01-14 02:00:44,275 iteration 6291 : loss : 0.023172, loss_ce: 0.004958
2022-01-14 02:00:45,766 iteration 6292 : loss : 0.013151, loss_ce: 0.004667
2022-01-14 02:00:47,158 iteration 6293 : loss : 0.014893, loss_ce: 0.006074
2022-01-14 02:00:48,581 iteration 6294 : loss : 0.019119, loss_ce: 0.008439
2022-01-14 02:00:50,017 iteration 6295 : loss : 0.029648, loss_ce: 0.011500
2022-01-14 02:00:51,423 iteration 6296 : loss : 0.012549, loss_ce: 0.004373
2022-01-14 02:00:52,811 iteration 6297 : loss : 0.016354, loss_ce: 0.004465
2022-01-14 02:00:54,189 iteration 6298 : loss : 0.014633, loss_ce: 0.005339
2022-01-14 02:00:55,621 iteration 6299 : loss : 0.019533, loss_ce: 0.006739
2022-01-14 02:00:57,014 iteration 6300 : loss : 0.015595, loss_ce: 0.005835
2022-01-14 02:00:58,384 iteration 6301 : loss : 0.022849, loss_ce: 0.008645
2022-01-14 02:00:59,728 iteration 6302 : loss : 0.015218, loss_ce: 0.006147
2022-01-14 02:01:01,139 iteration 6303 : loss : 0.015684, loss_ce: 0.006968
2022-01-14 02:01:02,516 iteration 6304 : loss : 0.015982, loss_ce: 0.006162
2022-01-14 02:01:03,838 iteration 6305 : loss : 0.013241, loss_ce: 0.005852
2022-01-14 02:01:05,173 iteration 6306 : loss : 0.016677, loss_ce: 0.005864
2022-01-14 02:01:06,641 iteration 6307 : loss : 0.034728, loss_ce: 0.012905
 93%|██████████████████████████▉  | 371/400 [2:41:20<12:45, 26.41s/it]2022-01-14 02:01:08,063 iteration 6308 : loss : 0.014014, loss_ce: 0.005625
2022-01-14 02:01:09,494 iteration 6309 : loss : 0.020546, loss_ce: 0.007732
2022-01-14 02:01:10,902 iteration 6310 : loss : 0.022232, loss_ce: 0.008947
2022-01-14 02:01:12,268 iteration 6311 : loss : 0.037036, loss_ce: 0.008864
2022-01-14 02:01:13,693 iteration 6312 : loss : 0.017703, loss_ce: 0.006303
2022-01-14 02:01:15,062 iteration 6313 : loss : 0.016681, loss_ce: 0.005324
2022-01-14 02:01:16,512 iteration 6314 : loss : 0.022769, loss_ce: 0.008737
2022-01-14 02:01:17,964 iteration 6315 : loss : 0.019860, loss_ce: 0.007087
2022-01-14 02:01:19,366 iteration 6316 : loss : 0.018729, loss_ce: 0.009352
2022-01-14 02:01:20,788 iteration 6317 : loss : 0.013663, loss_ce: 0.005380
2022-01-14 02:01:22,253 iteration 6318 : loss : 0.018705, loss_ce: 0.007934
2022-01-14 02:01:23,768 iteration 6319 : loss : 0.020022, loss_ce: 0.005926
2022-01-14 02:01:25,263 iteration 6320 : loss : 0.016903, loss_ce: 0.006111
2022-01-14 02:01:26,722 iteration 6321 : loss : 0.027730, loss_ce: 0.011762
2022-01-14 02:01:28,193 iteration 6322 : loss : 0.021323, loss_ce: 0.008924
2022-01-14 02:01:29,471 iteration 6323 : loss : 0.012385, loss_ce: 0.005438
2022-01-14 02:01:30,871 iteration 6324 : loss : 0.017943, loss_ce: 0.005435
 93%|██████████████████████████▉  | 372/400 [2:41:44<12:01, 25.76s/it]2022-01-14 02:01:32,265 iteration 6325 : loss : 0.014575, loss_ce: 0.005146
2022-01-14 02:01:33,594 iteration 6326 : loss : 0.014722, loss_ce: 0.008023
2022-01-14 02:01:34,907 iteration 6327 : loss : 0.013114, loss_ce: 0.004758
2022-01-14 02:01:36,366 iteration 6328 : loss : 0.020535, loss_ce: 0.009133
2022-01-14 02:01:37,872 iteration 6329 : loss : 0.017889, loss_ce: 0.006898
2022-01-14 02:01:39,287 iteration 6330 : loss : 0.014700, loss_ce: 0.005440
2022-01-14 02:01:40,760 iteration 6331 : loss : 0.026581, loss_ce: 0.014952
2022-01-14 02:01:42,138 iteration 6332 : loss : 0.016798, loss_ce: 0.006251
2022-01-14 02:01:43,524 iteration 6333 : loss : 0.017352, loss_ce: 0.006358
2022-01-14 02:01:44,945 iteration 6334 : loss : 0.015292, loss_ce: 0.006175
2022-01-14 02:01:46,486 iteration 6335 : loss : 0.023986, loss_ce: 0.011586
2022-01-14 02:01:47,929 iteration 6336 : loss : 0.018504, loss_ce: 0.006513
2022-01-14 02:01:49,252 iteration 6337 : loss : 0.014010, loss_ce: 0.005547
2022-01-14 02:01:50,741 iteration 6338 : loss : 0.020137, loss_ce: 0.006129
2022-01-14 02:01:52,109 iteration 6339 : loss : 0.014827, loss_ce: 0.005053
2022-01-14 02:01:53,520 iteration 6340 : loss : 0.018010, loss_ce: 0.009215
2022-01-14 02:01:54,949 iteration 6341 : loss : 0.018508, loss_ce: 0.004850
 93%|███████████████████████████  | 373/400 [2:42:08<11:21, 25.25s/it]2022-01-14 02:01:56,506 iteration 6342 : loss : 0.022947, loss_ce: 0.009601
2022-01-14 02:01:57,910 iteration 6343 : loss : 0.015785, loss_ce: 0.004728
2022-01-14 02:01:59,318 iteration 6344 : loss : 0.017902, loss_ce: 0.007550
2022-01-14 02:02:00,735 iteration 6345 : loss : 0.024980, loss_ce: 0.013053
2022-01-14 02:02:02,091 iteration 6346 : loss : 0.013279, loss_ce: 0.003667
2022-01-14 02:02:03,483 iteration 6347 : loss : 0.025722, loss_ce: 0.009711
2022-01-14 02:02:05,000 iteration 6348 : loss : 0.021982, loss_ce: 0.007651
2022-01-14 02:02:06,345 iteration 6349 : loss : 0.013325, loss_ce: 0.005409
2022-01-14 02:02:07,713 iteration 6350 : loss : 0.014632, loss_ce: 0.004283
2022-01-14 02:02:09,089 iteration 6351 : loss : 0.015355, loss_ce: 0.005424
2022-01-14 02:02:10,532 iteration 6352 : loss : 0.015535, loss_ce: 0.006502
2022-01-14 02:02:11,990 iteration 6353 : loss : 0.019013, loss_ce: 0.007492
2022-01-14 02:02:13,487 iteration 6354 : loss : 0.017808, loss_ce: 0.006233
2022-01-14 02:02:14,864 iteration 6355 : loss : 0.019353, loss_ce: 0.008696
2022-01-14 02:02:16,284 iteration 6356 : loss : 0.022519, loss_ce: 0.010126
2022-01-14 02:02:17,659 iteration 6357 : loss : 0.025251, loss_ce: 0.008903
2022-01-14 02:02:19,145 iteration 6358 : loss : 0.026330, loss_ce: 0.009319
 94%|███████████████████████████  | 374/400 [2:42:32<10:48, 24.94s/it]2022-01-14 02:02:20,605 iteration 6359 : loss : 0.016816, loss_ce: 0.005498
2022-01-14 02:02:21,961 iteration 6360 : loss : 0.016367, loss_ce: 0.004580
2022-01-14 02:02:23,384 iteration 6361 : loss : 0.020459, loss_ce: 0.004334
2022-01-14 02:02:24,807 iteration 6362 : loss : 0.019320, loss_ce: 0.009831
2022-01-14 02:02:26,311 iteration 6363 : loss : 0.020468, loss_ce: 0.008591
2022-01-14 02:02:27,660 iteration 6364 : loss : 0.011684, loss_ce: 0.004716
2022-01-14 02:02:28,993 iteration 6365 : loss : 0.015747, loss_ce: 0.006209
2022-01-14 02:02:30,450 iteration 6366 : loss : 0.021087, loss_ce: 0.008848
2022-01-14 02:02:31,850 iteration 6367 : loss : 0.016305, loss_ce: 0.006470
2022-01-14 02:02:33,259 iteration 6368 : loss : 0.020873, loss_ce: 0.009391
2022-01-14 02:02:34,740 iteration 6369 : loss : 0.015152, loss_ce: 0.006701
2022-01-14 02:02:36,209 iteration 6370 : loss : 0.024182, loss_ce: 0.006294
2022-01-14 02:02:37,687 iteration 6371 : loss : 0.015422, loss_ce: 0.005786
2022-01-14 02:02:39,118 iteration 6372 : loss : 0.016719, loss_ce: 0.008208
2022-01-14 02:02:40,420 iteration 6373 : loss : 0.010578, loss_ce: 0.002569
2022-01-14 02:02:41,809 iteration 6374 : loss : 0.013101, loss_ce: 0.005317
2022-01-14 02:02:41,810 Training Data Eval:
2022-01-14 02:02:48,923   Average segmentation loss on training set: 0.0096
2022-01-14 02:02:48,924 Validation Data Eval:
2022-01-14 02:02:51,374   Average segmentation loss on validation set: 0.0712
2022-01-14 02:02:52,782 iteration 6375 : loss : 0.024261, loss_ce: 0.009977
 94%|███████████████████████████▏ | 375/400 [2:43:06<11:28, 27.55s/it]2022-01-14 02:02:54,461 iteration 6376 : loss : 0.028339, loss_ce: 0.012544
2022-01-14 02:02:55,862 iteration 6377 : loss : 0.016309, loss_ce: 0.005770
2022-01-14 02:02:57,231 iteration 6378 : loss : 0.017692, loss_ce: 0.006265
2022-01-14 02:02:58,665 iteration 6379 : loss : 0.023791, loss_ce: 0.004534
2022-01-14 02:02:59,985 iteration 6380 : loss : 0.012983, loss_ce: 0.005920
2022-01-14 02:03:01,306 iteration 6381 : loss : 0.016891, loss_ce: 0.006190
2022-01-14 02:03:02,734 iteration 6382 : loss : 0.023601, loss_ce: 0.009459
2022-01-14 02:03:04,161 iteration 6383 : loss : 0.017358, loss_ce: 0.006007
2022-01-14 02:03:05,541 iteration 6384 : loss : 0.016283, loss_ce: 0.006651
2022-01-14 02:03:07,036 iteration 6385 : loss : 0.027749, loss_ce: 0.011278
2022-01-14 02:03:08,429 iteration 6386 : loss : 0.017314, loss_ce: 0.006172
2022-01-14 02:03:09,958 iteration 6387 : loss : 0.070150, loss_ce: 0.037371
2022-01-14 02:03:11,334 iteration 6388 : loss : 0.011198, loss_ce: 0.003824
2022-01-14 02:03:12,629 iteration 6389 : loss : 0.013757, loss_ce: 0.004385
2022-01-14 02:03:14,010 iteration 6390 : loss : 0.014924, loss_ce: 0.005398
2022-01-14 02:03:15,509 iteration 6391 : loss : 0.029471, loss_ce: 0.006149
2022-01-14 02:03:16,841 iteration 6392 : loss : 0.014266, loss_ce: 0.006745
 94%|███████████████████████████▎ | 376/400 [2:43:30<10:36, 26.50s/it]2022-01-14 02:03:18,305 iteration 6393 : loss : 0.016254, loss_ce: 0.005766
2022-01-14 02:03:19,721 iteration 6394 : loss : 0.018000, loss_ce: 0.005469
2022-01-14 02:03:21,083 iteration 6395 : loss : 0.012218, loss_ce: 0.005676
2022-01-14 02:03:22,576 iteration 6396 : loss : 0.016323, loss_ce: 0.006846
2022-01-14 02:03:23,935 iteration 6397 : loss : 0.019516, loss_ce: 0.007292
2022-01-14 02:03:25,279 iteration 6398 : loss : 0.012059, loss_ce: 0.003845
2022-01-14 02:03:26,677 iteration 6399 : loss : 0.018244, loss_ce: 0.005771
2022-01-14 02:03:28,073 iteration 6400 : loss : 0.017891, loss_ce: 0.007881
2022-01-14 02:03:29,405 iteration 6401 : loss : 0.013562, loss_ce: 0.005092
2022-01-14 02:03:30,800 iteration 6402 : loss : 0.019809, loss_ce: 0.008761
2022-01-14 02:03:32,307 iteration 6403 : loss : 0.017554, loss_ce: 0.006479
2022-01-14 02:03:33,707 iteration 6404 : loss : 0.030386, loss_ce: 0.008520
2022-01-14 02:03:35,091 iteration 6405 : loss : 0.022389, loss_ce: 0.008461
2022-01-14 02:03:36,670 iteration 6406 : loss : 0.034561, loss_ce: 0.016756
2022-01-14 02:03:38,012 iteration 6407 : loss : 0.020630, loss_ce: 0.005861
2022-01-14 02:03:39,404 iteration 6408 : loss : 0.017787, loss_ce: 0.004036
2022-01-14 02:03:40,784 iteration 6409 : loss : 0.017070, loss_ce: 0.006621
 94%|███████████████████████████▎ | 377/400 [2:43:54<09:51, 25.73s/it]2022-01-14 02:03:42,360 iteration 6410 : loss : 0.036452, loss_ce: 0.018622
2022-01-14 02:03:43,876 iteration 6411 : loss : 0.019823, loss_ce: 0.007703
2022-01-14 02:03:45,291 iteration 6412 : loss : 0.018130, loss_ce: 0.007796
2022-01-14 02:03:46,701 iteration 6413 : loss : 0.013164, loss_ce: 0.004383
2022-01-14 02:03:48,135 iteration 6414 : loss : 0.018597, loss_ce: 0.006723
2022-01-14 02:03:49,511 iteration 6415 : loss : 0.020036, loss_ce: 0.006428
2022-01-14 02:03:50,900 iteration 6416 : loss : 0.022918, loss_ce: 0.005787
2022-01-14 02:03:52,327 iteration 6417 : loss : 0.033745, loss_ce: 0.016521
2022-01-14 02:03:53,771 iteration 6418 : loss : 0.017737, loss_ce: 0.006267
2022-01-14 02:03:55,163 iteration 6419 : loss : 0.014556, loss_ce: 0.004593
2022-01-14 02:03:56,608 iteration 6420 : loss : 0.026613, loss_ce: 0.008393
2022-01-14 02:03:58,025 iteration 6421 : loss : 0.011199, loss_ce: 0.004011
2022-01-14 02:03:59,353 iteration 6422 : loss : 0.013279, loss_ce: 0.005567
2022-01-14 02:04:00,806 iteration 6423 : loss : 0.020151, loss_ce: 0.006486
2022-01-14 02:04:02,247 iteration 6424 : loss : 0.017340, loss_ce: 0.007970
2022-01-14 02:04:03,568 iteration 6425 : loss : 0.015185, loss_ce: 0.005343
2022-01-14 02:04:05,018 iteration 6426 : loss : 0.020341, loss_ce: 0.010751
 94%|███████████████████████████▍ | 378/400 [2:44:18<09:16, 25.28s/it]2022-01-14 02:04:06,490 iteration 6427 : loss : 0.018032, loss_ce: 0.008013
2022-01-14 02:04:07,818 iteration 6428 : loss : 0.013767, loss_ce: 0.006330
2022-01-14 02:04:09,248 iteration 6429 : loss : 0.022048, loss_ce: 0.008053
2022-01-14 02:04:10,583 iteration 6430 : loss : 0.015504, loss_ce: 0.004623
2022-01-14 02:04:12,000 iteration 6431 : loss : 0.017587, loss_ce: 0.005460
2022-01-14 02:04:13,403 iteration 6432 : loss : 0.016400, loss_ce: 0.006695
2022-01-14 02:04:14,870 iteration 6433 : loss : 0.016117, loss_ce: 0.005384
2022-01-14 02:04:16,190 iteration 6434 : loss : 0.012630, loss_ce: 0.004531
2022-01-14 02:04:17,584 iteration 6435 : loss : 0.016181, loss_ce: 0.008076
2022-01-14 02:04:18,966 iteration 6436 : loss : 0.015581, loss_ce: 0.006339
2022-01-14 02:04:20,396 iteration 6437 : loss : 0.025196, loss_ce: 0.007337
2022-01-14 02:04:21,825 iteration 6438 : loss : 0.016958, loss_ce: 0.006642
2022-01-14 02:04:23,274 iteration 6439 : loss : 0.022100, loss_ce: 0.011820
2022-01-14 02:04:24,742 iteration 6440 : loss : 0.023102, loss_ce: 0.009406
2022-01-14 02:04:26,168 iteration 6441 : loss : 0.015447, loss_ce: 0.004085
2022-01-14 02:04:27,563 iteration 6442 : loss : 0.024861, loss_ce: 0.012631
2022-01-14 02:04:28,989 iteration 6443 : loss : 0.022050, loss_ce: 0.008645
 95%|███████████████████████████▍ | 379/400 [2:44:42<08:42, 24.89s/it]2022-01-14 02:04:30,515 iteration 6444 : loss : 0.018893, loss_ce: 0.007725
2022-01-14 02:04:31,987 iteration 6445 : loss : 0.017497, loss_ce: 0.007470
2022-01-14 02:04:33,412 iteration 6446 : loss : 0.014856, loss_ce: 0.003870
2022-01-14 02:04:34,806 iteration 6447 : loss : 0.018826, loss_ce: 0.010057
2022-01-14 02:04:36,209 iteration 6448 : loss : 0.018158, loss_ce: 0.008606
2022-01-14 02:04:37,687 iteration 6449 : loss : 0.015159, loss_ce: 0.005123
2022-01-14 02:04:39,042 iteration 6450 : loss : 0.013462, loss_ce: 0.005513
2022-01-14 02:04:40,376 iteration 6451 : loss : 0.015324, loss_ce: 0.005533
2022-01-14 02:04:41,815 iteration 6452 : loss : 0.017146, loss_ce: 0.007924
2022-01-14 02:04:43,220 iteration 6453 : loss : 0.015684, loss_ce: 0.006297
2022-01-14 02:04:44,607 iteration 6454 : loss : 0.017691, loss_ce: 0.006146
2022-01-14 02:04:45,997 iteration 6455 : loss : 0.018776, loss_ce: 0.005927
2022-01-14 02:04:47,499 iteration 6456 : loss : 0.028676, loss_ce: 0.013062
2022-01-14 02:04:48,929 iteration 6457 : loss : 0.016868, loss_ce: 0.005761
2022-01-14 02:04:50,292 iteration 6458 : loss : 0.015549, loss_ce: 0.004608
2022-01-14 02:04:51,629 iteration 6459 : loss : 0.013813, loss_ce: 0.004699
2022-01-14 02:04:51,630 Training Data Eval:
2022-01-14 02:04:58,618   Average segmentation loss on training set: 0.0094
2022-01-14 02:04:58,618 Validation Data Eval:
2022-01-14 02:05:01,080   Average segmentation loss on validation set: 0.0766
2022-01-14 02:05:02,558 iteration 6460 : loss : 0.022771, loss_ce: 0.006084
 95%|███████████████████████████▌ | 380/400 [2:45:15<09:09, 27.50s/it]2022-01-14 02:05:04,035 iteration 6461 : loss : 0.024609, loss_ce: 0.005674
2022-01-14 02:05:05,465 iteration 6462 : loss : 0.013245, loss_ce: 0.004575
2022-01-14 02:05:06,827 iteration 6463 : loss : 0.010903, loss_ce: 0.003175
2022-01-14 02:05:08,179 iteration 6464 : loss : 0.013952, loss_ce: 0.004607
2022-01-14 02:05:09,573 iteration 6465 : loss : 0.023061, loss_ce: 0.007290
2022-01-14 02:05:10,995 iteration 6466 : loss : 0.018873, loss_ce: 0.007596
2022-01-14 02:05:12,446 iteration 6467 : loss : 0.021395, loss_ce: 0.009765
2022-01-14 02:05:13,927 iteration 6468 : loss : 0.026394, loss_ce: 0.012750
2022-01-14 02:05:15,324 iteration 6469 : loss : 0.017426, loss_ce: 0.008429
2022-01-14 02:05:16,708 iteration 6470 : loss : 0.024733, loss_ce: 0.007460
2022-01-14 02:05:18,082 iteration 6471 : loss : 0.017014, loss_ce: 0.005609
2022-01-14 02:05:19,464 iteration 6472 : loss : 0.015158, loss_ce: 0.004418
2022-01-14 02:05:20,811 iteration 6473 : loss : 0.016579, loss_ce: 0.008282
2022-01-14 02:05:22,272 iteration 6474 : loss : 0.020401, loss_ce: 0.011010
2022-01-14 02:05:23,624 iteration 6475 : loss : 0.013185, loss_ce: 0.005058
2022-01-14 02:05:25,029 iteration 6476 : loss : 0.014753, loss_ce: 0.005403
2022-01-14 02:05:26,383 iteration 6477 : loss : 0.013621, loss_ce: 0.004917
 95%|███████████████████████████▌ | 381/400 [2:45:39<08:21, 26.39s/it]2022-01-14 02:05:27,901 iteration 6478 : loss : 0.018165, loss_ce: 0.007492
2022-01-14 02:05:29,454 iteration 6479 : loss : 0.017468, loss_ce: 0.009127
2022-01-14 02:05:30,890 iteration 6480 : loss : 0.031853, loss_ce: 0.007092
2022-01-14 02:05:32,334 iteration 6481 : loss : 0.017213, loss_ce: 0.007175
2022-01-14 02:05:33,755 iteration 6482 : loss : 0.023522, loss_ce: 0.010314
2022-01-14 02:05:35,154 iteration 6483 : loss : 0.017887, loss_ce: 0.007590
2022-01-14 02:05:36,554 iteration 6484 : loss : 0.018706, loss_ce: 0.005733
2022-01-14 02:05:37,974 iteration 6485 : loss : 0.020274, loss_ce: 0.009858
2022-01-14 02:05:39,477 iteration 6486 : loss : 0.017836, loss_ce: 0.006186
2022-01-14 02:05:40,899 iteration 6487 : loss : 0.017343, loss_ce: 0.005428
2022-01-14 02:05:42,204 iteration 6488 : loss : 0.012127, loss_ce: 0.005122
2022-01-14 02:05:43,668 iteration 6489 : loss : 0.014671, loss_ce: 0.003968
2022-01-14 02:05:44,974 iteration 6490 : loss : 0.016288, loss_ce: 0.006548
2022-01-14 02:05:46,397 iteration 6491 : loss : 0.021275, loss_ce: 0.006237
2022-01-14 02:05:47,786 iteration 6492 : loss : 0.012924, loss_ce: 0.004380
2022-01-14 02:05:49,220 iteration 6493 : loss : 0.025227, loss_ce: 0.006646
2022-01-14 02:05:50,615 iteration 6494 : loss : 0.016766, loss_ce: 0.005830
 96%|███████████████████████████▋ | 382/400 [2:46:04<07:43, 25.75s/it]2022-01-14 02:05:52,145 iteration 6495 : loss : 0.015249, loss_ce: 0.005112
2022-01-14 02:05:53,544 iteration 6496 : loss : 0.017648, loss_ce: 0.006214
2022-01-14 02:05:54,984 iteration 6497 : loss : 0.014040, loss_ce: 0.004845
2022-01-14 02:05:56,430 iteration 6498 : loss : 0.022543, loss_ce: 0.011517
2022-01-14 02:05:57,939 iteration 6499 : loss : 0.026549, loss_ce: 0.008325
2022-01-14 02:05:59,400 iteration 6500 : loss : 0.023542, loss_ce: 0.009770
2022-01-14 02:06:00,871 iteration 6501 : loss : 0.016894, loss_ce: 0.004405
2022-01-14 02:06:02,323 iteration 6502 : loss : 0.022506, loss_ce: 0.008733
2022-01-14 02:06:03,844 iteration 6503 : loss : 0.024743, loss_ce: 0.009152
2022-01-14 02:06:05,194 iteration 6504 : loss : 0.012426, loss_ce: 0.006163
2022-01-14 02:06:06,571 iteration 6505 : loss : 0.014339, loss_ce: 0.003952
2022-01-14 02:06:07,969 iteration 6506 : loss : 0.018237, loss_ce: 0.005047
2022-01-14 02:06:09,356 iteration 6507 : loss : 0.020232, loss_ce: 0.008095
2022-01-14 02:06:10,754 iteration 6508 : loss : 0.012676, loss_ce: 0.004052
2022-01-14 02:06:12,166 iteration 6509 : loss : 0.014779, loss_ce: 0.005722
2022-01-14 02:06:13,532 iteration 6510 : loss : 0.014457, loss_ce: 0.005086
2022-01-14 02:06:14,924 iteration 6511 : loss : 0.021763, loss_ce: 0.008869
 96%|███████████████████████████▊ | 383/400 [2:46:28<07:10, 25.31s/it]2022-01-14 02:06:16,393 iteration 6512 : loss : 0.014925, loss_ce: 0.006236
2022-01-14 02:06:17,731 iteration 6513 : loss : 0.012755, loss_ce: 0.004707
2022-01-14 02:06:19,112 iteration 6514 : loss : 0.012351, loss_ce: 0.002860
2022-01-14 02:06:20,521 iteration 6515 : loss : 0.016128, loss_ce: 0.004545
2022-01-14 02:06:21,916 iteration 6516 : loss : 0.016355, loss_ce: 0.005207
2022-01-14 02:06:23,387 iteration 6517 : loss : 0.023752, loss_ce: 0.012116
2022-01-14 02:06:24,735 iteration 6518 : loss : 0.019138, loss_ce: 0.007881
2022-01-14 02:06:26,202 iteration 6519 : loss : 0.023659, loss_ce: 0.007133
2022-01-14 02:06:27,534 iteration 6520 : loss : 0.018582, loss_ce: 0.009819
2022-01-14 02:06:28,974 iteration 6521 : loss : 0.015574, loss_ce: 0.007221
2022-01-14 02:06:30,361 iteration 6522 : loss : 0.014201, loss_ce: 0.005877
2022-01-14 02:06:31,713 iteration 6523 : loss : 0.016992, loss_ce: 0.005756
2022-01-14 02:06:33,112 iteration 6524 : loss : 0.022479, loss_ce: 0.008257
2022-01-14 02:06:34,486 iteration 6525 : loss : 0.012960, loss_ce: 0.004553
2022-01-14 02:06:35,923 iteration 6526 : loss : 0.013986, loss_ce: 0.005240
2022-01-14 02:06:37,383 iteration 6527 : loss : 0.016019, loss_ce: 0.005254
2022-01-14 02:06:38,804 iteration 6528 : loss : 0.017974, loss_ce: 0.007290
 96%|███████████████████████████▊ | 384/400 [2:46:52<06:38, 24.88s/it]2022-01-14 02:06:40,222 iteration 6529 : loss : 0.014374, loss_ce: 0.005018
2022-01-14 02:06:41,538 iteration 6530 : loss : 0.012471, loss_ce: 0.005591
2022-01-14 02:06:42,953 iteration 6531 : loss : 0.012755, loss_ce: 0.003167
2022-01-14 02:06:44,402 iteration 6532 : loss : 0.017187, loss_ce: 0.005987
2022-01-14 02:06:45,763 iteration 6533 : loss : 0.026570, loss_ce: 0.010898
2022-01-14 02:06:47,217 iteration 6534 : loss : 0.019159, loss_ce: 0.005060
2022-01-14 02:06:48,629 iteration 6535 : loss : 0.020296, loss_ce: 0.007099
2022-01-14 02:06:50,086 iteration 6536 : loss : 0.017907, loss_ce: 0.006411
2022-01-14 02:06:51,596 iteration 6537 : loss : 0.027519, loss_ce: 0.008336
2022-01-14 02:06:52,954 iteration 6538 : loss : 0.015328, loss_ce: 0.005314
2022-01-14 02:06:54,488 iteration 6539 : loss : 0.025905, loss_ce: 0.008469
2022-01-14 02:06:55,844 iteration 6540 : loss : 0.017301, loss_ce: 0.007586
2022-01-14 02:06:57,179 iteration 6541 : loss : 0.012721, loss_ce: 0.004738
2022-01-14 02:06:58,557 iteration 6542 : loss : 0.019576, loss_ce: 0.008252
2022-01-14 02:07:00,036 iteration 6543 : loss : 0.018609, loss_ce: 0.007280
2022-01-14 02:07:01,434 iteration 6544 : loss : 0.023354, loss_ce: 0.008734
2022-01-14 02:07:01,434 Training Data Eval:
2022-01-14 02:07:08,351   Average segmentation loss on training set: 0.0093
2022-01-14 02:07:08,352 Validation Data Eval:
2022-01-14 02:07:10,770   Average segmentation loss on validation set: 0.0785
2022-01-14 02:07:12,226 iteration 6545 : loss : 0.014947, loss_ce: 0.004357
 96%|███████████████████████████▉ | 385/400 [2:47:25<06:51, 27.45s/it]2022-01-14 02:07:13,774 iteration 6546 : loss : 0.014708, loss_ce: 0.004993
2022-01-14 02:07:15,129 iteration 6547 : loss : 0.014680, loss_ce: 0.003235
2022-01-14 02:07:16,541 iteration 6548 : loss : 0.030595, loss_ce: 0.009720
2022-01-14 02:07:18,039 iteration 6549 : loss : 0.024437, loss_ce: 0.007570
2022-01-14 02:07:19,436 iteration 6550 : loss : 0.017890, loss_ce: 0.008553
2022-01-14 02:07:20,895 iteration 6551 : loss : 0.022369, loss_ce: 0.010111
2022-01-14 02:07:22,428 iteration 6552 : loss : 0.016830, loss_ce: 0.006620
2022-01-14 02:07:23,819 iteration 6553 : loss : 0.019095, loss_ce: 0.007217
2022-01-14 02:07:25,378 iteration 6554 : loss : 0.028838, loss_ce: 0.010353
2022-01-14 02:07:26,738 iteration 6555 : loss : 0.027356, loss_ce: 0.010737
2022-01-14 02:07:28,159 iteration 6556 : loss : 0.019496, loss_ce: 0.006980
2022-01-14 02:07:29,517 iteration 6557 : loss : 0.013829, loss_ce: 0.004845
2022-01-14 02:07:30,994 iteration 6558 : loss : 0.021423, loss_ce: 0.009380
2022-01-14 02:07:32,360 iteration 6559 : loss : 0.013561, loss_ce: 0.004956
2022-01-14 02:07:33,738 iteration 6560 : loss : 0.012730, loss_ce: 0.005743
2022-01-14 02:07:35,162 iteration 6561 : loss : 0.022736, loss_ce: 0.007830
2022-01-14 02:07:36,587 iteration 6562 : loss : 0.017673, loss_ce: 0.006789
 96%|███████████████████████████▉ | 386/400 [2:47:50<06:11, 26.52s/it]2022-01-14 02:07:38,065 iteration 6563 : loss : 0.016209, loss_ce: 0.007207
2022-01-14 02:07:39,555 iteration 6564 : loss : 0.016315, loss_ce: 0.005738
2022-01-14 02:07:40,922 iteration 6565 : loss : 0.019933, loss_ce: 0.005188
2022-01-14 02:07:42,407 iteration 6566 : loss : 0.021767, loss_ce: 0.007570
2022-01-14 02:07:43,854 iteration 6567 : loss : 0.046845, loss_ce: 0.015428
2022-01-14 02:07:45,269 iteration 6568 : loss : 0.013258, loss_ce: 0.004758
2022-01-14 02:07:46,652 iteration 6569 : loss : 0.018624, loss_ce: 0.005571
2022-01-14 02:07:48,174 iteration 6570 : loss : 0.033120, loss_ce: 0.013888
2022-01-14 02:07:49,519 iteration 6571 : loss : 0.012668, loss_ce: 0.005370
2022-01-14 02:07:50,914 iteration 6572 : loss : 0.015546, loss_ce: 0.005859
2022-01-14 02:07:52,286 iteration 6573 : loss : 0.013574, loss_ce: 0.004409
2022-01-14 02:07:53,711 iteration 6574 : loss : 0.017135, loss_ce: 0.006141
2022-01-14 02:07:55,036 iteration 6575 : loss : 0.010782, loss_ce: 0.004412
2022-01-14 02:07:56,481 iteration 6576 : loss : 0.015339, loss_ce: 0.006047
2022-01-14 02:07:57,938 iteration 6577 : loss : 0.017200, loss_ce: 0.005780
2022-01-14 02:07:59,381 iteration 6578 : loss : 0.025871, loss_ce: 0.015734
2022-01-14 02:08:00,787 iteration 6579 : loss : 0.017704, loss_ce: 0.004333
 97%|████████████████████████████ | 387/400 [2:48:14<05:35, 25.82s/it]2022-01-14 02:08:02,288 iteration 6580 : loss : 0.017750, loss_ce: 0.006339
2022-01-14 02:08:03,745 iteration 6581 : loss : 0.026034, loss_ce: 0.007233
2022-01-14 02:08:05,197 iteration 6582 : loss : 0.019752, loss_ce: 0.009413
2022-01-14 02:08:06,601 iteration 6583 : loss : 0.016793, loss_ce: 0.008170
2022-01-14 02:08:08,041 iteration 6584 : loss : 0.015667, loss_ce: 0.005985
2022-01-14 02:08:09,401 iteration 6585 : loss : 0.014365, loss_ce: 0.004984
2022-01-14 02:08:10,819 iteration 6586 : loss : 0.021165, loss_ce: 0.007628
2022-01-14 02:08:12,170 iteration 6587 : loss : 0.015281, loss_ce: 0.006119
2022-01-14 02:08:13,618 iteration 6588 : loss : 0.022729, loss_ce: 0.007898
2022-01-14 02:08:15,012 iteration 6589 : loss : 0.018939, loss_ce: 0.006465
2022-01-14 02:08:16,399 iteration 6590 : loss : 0.014908, loss_ce: 0.006361
2022-01-14 02:08:17,755 iteration 6591 : loss : 0.015215, loss_ce: 0.007256
2022-01-14 02:08:19,153 iteration 6592 : loss : 0.019558, loss_ce: 0.006694
2022-01-14 02:08:20,622 iteration 6593 : loss : 0.026433, loss_ce: 0.012959
2022-01-14 02:08:22,010 iteration 6594 : loss : 0.017731, loss_ce: 0.007110
2022-01-14 02:08:23,360 iteration 6595 : loss : 0.014228, loss_ce: 0.004500
2022-01-14 02:08:24,747 iteration 6596 : loss : 0.010593, loss_ce: 0.004151
 97%|████████████████████████████▏| 388/400 [2:48:38<05:03, 25.27s/it]2022-01-14 02:08:26,269 iteration 6597 : loss : 0.018173, loss_ce: 0.008799
2022-01-14 02:08:27,729 iteration 6598 : loss : 0.027086, loss_ce: 0.006577
2022-01-14 02:08:29,092 iteration 6599 : loss : 0.017076, loss_ce: 0.007972
2022-01-14 02:08:30,530 iteration 6600 : loss : 0.023821, loss_ce: 0.009223
2022-01-14 02:08:31,877 iteration 6601 : loss : 0.014063, loss_ce: 0.005512
2022-01-14 02:08:33,180 iteration 6602 : loss : 0.010675, loss_ce: 0.003779
2022-01-14 02:08:34,598 iteration 6603 : loss : 0.035637, loss_ce: 0.013927
2022-01-14 02:08:36,076 iteration 6604 : loss : 0.024450, loss_ce: 0.009080
2022-01-14 02:08:37,526 iteration 6605 : loss : 0.019052, loss_ce: 0.006601
2022-01-14 02:08:38,956 iteration 6606 : loss : 0.020289, loss_ce: 0.009206
2022-01-14 02:08:40,356 iteration 6607 : loss : 0.018506, loss_ce: 0.005213
2022-01-14 02:08:41,830 iteration 6608 : loss : 0.025681, loss_ce: 0.012863
2022-01-14 02:08:43,315 iteration 6609 : loss : 0.016000, loss_ce: 0.006351
2022-01-14 02:08:44,736 iteration 6610 : loss : 0.021188, loss_ce: 0.005724
2022-01-14 02:08:46,071 iteration 6611 : loss : 0.013674, loss_ce: 0.005850
2022-01-14 02:08:47,499 iteration 6612 : loss : 0.019750, loss_ce: 0.008538
2022-01-14 02:08:48,975 iteration 6613 : loss : 0.020347, loss_ce: 0.006039
 97%|████████████████████████████▏| 389/400 [2:49:02<04:34, 24.96s/it]2022-01-14 02:08:50,346 iteration 6614 : loss : 0.013387, loss_ce: 0.005329
2022-01-14 02:08:51,793 iteration 6615 : loss : 0.025648, loss_ce: 0.009971
2022-01-14 02:08:53,250 iteration 6616 : loss : 0.016523, loss_ce: 0.006934
2022-01-14 02:08:54,618 iteration 6617 : loss : 0.014861, loss_ce: 0.003047
2022-01-14 02:08:56,025 iteration 6618 : loss : 0.015962, loss_ce: 0.005459
2022-01-14 02:08:57,478 iteration 6619 : loss : 0.015875, loss_ce: 0.005898
2022-01-14 02:08:58,880 iteration 6620 : loss : 0.018958, loss_ce: 0.006143
2022-01-14 02:09:00,218 iteration 6621 : loss : 0.015136, loss_ce: 0.006730
2022-01-14 02:09:01,533 iteration 6622 : loss : 0.011481, loss_ce: 0.003692
2022-01-14 02:09:02,954 iteration 6623 : loss : 0.019472, loss_ce: 0.008357
2022-01-14 02:09:04,257 iteration 6624 : loss : 0.012946, loss_ce: 0.004704
2022-01-14 02:09:05,565 iteration 6625 : loss : 0.011171, loss_ce: 0.004489
2022-01-14 02:09:06,970 iteration 6626 : loss : 0.022136, loss_ce: 0.008005
2022-01-14 02:09:08,313 iteration 6627 : loss : 0.011176, loss_ce: 0.003788
2022-01-14 02:09:09,738 iteration 6628 : loss : 0.026064, loss_ce: 0.009779
2022-01-14 02:09:11,101 iteration 6629 : loss : 0.011807, loss_ce: 0.004467
2022-01-14 02:09:11,101 Training Data Eval:
2022-01-14 02:09:18,201   Average segmentation loss on training set: 0.0092
2022-01-14 02:09:18,202 Validation Data Eval:
2022-01-14 02:09:20,708   Average segmentation loss on validation set: 0.0756
2022-01-14 02:09:22,134 iteration 6630 : loss : 0.019602, loss_ce: 0.008708
 98%|████████████████████████████▎| 390/400 [2:49:35<04:34, 27.41s/it]2022-01-14 02:09:23,501 iteration 6631 : loss : 0.011244, loss_ce: 0.004385
2022-01-14 02:09:24,944 iteration 6632 : loss : 0.022574, loss_ce: 0.004567
2022-01-14 02:09:26,331 iteration 6633 : loss : 0.037317, loss_ce: 0.014597
2022-01-14 02:09:27,686 iteration 6634 : loss : 0.015770, loss_ce: 0.006565
2022-01-14 02:09:29,142 iteration 6635 : loss : 0.014598, loss_ce: 0.005595
2022-01-14 02:09:30,498 iteration 6636 : loss : 0.014113, loss_ce: 0.007124
2022-01-14 02:09:31,913 iteration 6637 : loss : 0.019656, loss_ce: 0.006197
2022-01-14 02:09:33,337 iteration 6638 : loss : 0.010827, loss_ce: 0.003204
2022-01-14 02:09:34,743 iteration 6639 : loss : 0.021446, loss_ce: 0.007105
2022-01-14 02:09:36,161 iteration 6640 : loss : 0.019602, loss_ce: 0.006433
2022-01-14 02:09:37,563 iteration 6641 : loss : 0.016333, loss_ce: 0.006705
2022-01-14 02:09:38,950 iteration 6642 : loss : 0.013987, loss_ce: 0.004184
2022-01-14 02:09:40,407 iteration 6643 : loss : 0.034922, loss_ce: 0.013017
2022-01-14 02:09:41,887 iteration 6644 : loss : 0.022424, loss_ce: 0.010996
2022-01-14 02:09:43,290 iteration 6645 : loss : 0.025158, loss_ce: 0.009601
2022-01-14 02:09:44,731 iteration 6646 : loss : 0.019606, loss_ce: 0.008744
2022-01-14 02:09:46,166 iteration 6647 : loss : 0.032318, loss_ce: 0.005954
 98%|████████████████████████████▎| 391/400 [2:49:59<03:57, 26.40s/it]2022-01-14 02:09:47,665 iteration 6648 : loss : 0.016919, loss_ce: 0.006228
2022-01-14 02:09:49,145 iteration 6649 : loss : 0.028839, loss_ce: 0.010725
2022-01-14 02:09:50,503 iteration 6650 : loss : 0.017418, loss_ce: 0.007159
2022-01-14 02:09:51,877 iteration 6651 : loss : 0.015972, loss_ce: 0.007142
2022-01-14 02:09:53,312 iteration 6652 : loss : 0.014555, loss_ce: 0.006099
2022-01-14 02:09:54,784 iteration 6653 : loss : 0.022098, loss_ce: 0.006928
2022-01-14 02:09:56,309 iteration 6654 : loss : 0.017010, loss_ce: 0.005761
2022-01-14 02:09:57,708 iteration 6655 : loss : 0.014069, loss_ce: 0.005805
2022-01-14 02:09:59,192 iteration 6656 : loss : 0.022200, loss_ce: 0.007240
2022-01-14 02:10:00,621 iteration 6657 : loss : 0.023420, loss_ce: 0.007459
2022-01-14 02:10:02,095 iteration 6658 : loss : 0.021899, loss_ce: 0.008141
2022-01-14 02:10:03,503 iteration 6659 : loss : 0.030157, loss_ce: 0.010835
2022-01-14 02:10:04,899 iteration 6660 : loss : 0.015556, loss_ce: 0.005827
2022-01-14 02:10:06,265 iteration 6661 : loss : 0.015326, loss_ce: 0.005612
2022-01-14 02:10:07,705 iteration 6662 : loss : 0.019195, loss_ce: 0.006942
2022-01-14 02:10:09,076 iteration 6663 : loss : 0.015260, loss_ce: 0.006475
2022-01-14 02:10:10,534 iteration 6664 : loss : 0.013575, loss_ce: 0.006260
 98%|████████████████████████████▍| 392/400 [2:50:23<03:26, 25.79s/it]2022-01-14 02:10:12,019 iteration 6665 : loss : 0.028844, loss_ce: 0.010880
2022-01-14 02:10:13,456 iteration 6666 : loss : 0.014041, loss_ce: 0.004558
2022-01-14 02:10:14,873 iteration 6667 : loss : 0.023543, loss_ce: 0.010032
2022-01-14 02:10:16,428 iteration 6668 : loss : 0.024062, loss_ce: 0.014871
2022-01-14 02:10:17,779 iteration 6669 : loss : 0.019662, loss_ce: 0.006718
2022-01-14 02:10:19,142 iteration 6670 : loss : 0.013225, loss_ce: 0.005342
2022-01-14 02:10:20,515 iteration 6671 : loss : 0.021470, loss_ce: 0.010760
2022-01-14 02:10:21,830 iteration 6672 : loss : 0.012373, loss_ce: 0.003429
2022-01-14 02:10:23,267 iteration 6673 : loss : 0.019034, loss_ce: 0.007596
2022-01-14 02:10:24,674 iteration 6674 : loss : 0.018579, loss_ce: 0.007654
2022-01-14 02:10:26,128 iteration 6675 : loss : 0.018001, loss_ce: 0.005833
2022-01-14 02:10:27,475 iteration 6676 : loss : 0.010820, loss_ce: 0.003323
2022-01-14 02:10:28,854 iteration 6677 : loss : 0.016094, loss_ce: 0.004230
2022-01-14 02:10:30,137 iteration 6678 : loss : 0.011771, loss_ce: 0.005050
2022-01-14 02:10:31,673 iteration 6679 : loss : 0.020460, loss_ce: 0.009044
2022-01-14 02:10:33,071 iteration 6680 : loss : 0.017017, loss_ce: 0.006531
2022-01-14 02:10:34,533 iteration 6681 : loss : 0.017607, loss_ce: 0.008226
 98%|████████████████████████████▍| 393/400 [2:50:47<02:56, 25.25s/it]2022-01-14 02:10:35,999 iteration 6682 : loss : 0.014568, loss_ce: 0.006967
2022-01-14 02:10:37,500 iteration 6683 : loss : 0.015140, loss_ce: 0.005098
2022-01-14 02:10:38,871 iteration 6684 : loss : 0.014385, loss_ce: 0.004333
2022-01-14 02:10:40,333 iteration 6685 : loss : 0.020802, loss_ce: 0.008980
2022-01-14 02:10:41,678 iteration 6686 : loss : 0.013340, loss_ce: 0.006108
2022-01-14 02:10:43,076 iteration 6687 : loss : 0.039360, loss_ce: 0.010726
2022-01-14 02:10:44,549 iteration 6688 : loss : 0.024450, loss_ce: 0.010413
2022-01-14 02:10:45,957 iteration 6689 : loss : 0.015877, loss_ce: 0.006732
2022-01-14 02:10:47,370 iteration 6690 : loss : 0.017728, loss_ce: 0.006770
2022-01-14 02:10:48,854 iteration 6691 : loss : 0.021492, loss_ce: 0.009143
2022-01-14 02:10:50,304 iteration 6692 : loss : 0.021089, loss_ce: 0.006025
2022-01-14 02:10:51,784 iteration 6693 : loss : 0.012617, loss_ce: 0.003945
2022-01-14 02:10:53,217 iteration 6694 : loss : 0.015436, loss_ce: 0.006011
2022-01-14 02:10:54,693 iteration 6695 : loss : 0.046060, loss_ce: 0.028781
2022-01-14 02:10:56,054 iteration 6696 : loss : 0.013018, loss_ce: 0.006118
2022-01-14 02:10:57,504 iteration 6697 : loss : 0.017821, loss_ce: 0.006670
2022-01-14 02:10:58,932 iteration 6698 : loss : 0.013370, loss_ce: 0.004232
 98%|████████████████████████████▌| 394/400 [2:51:12<02:29, 25.00s/it]2022-01-14 02:11:00,382 iteration 6699 : loss : 0.018642, loss_ce: 0.009872
2022-01-14 02:11:01,859 iteration 6700 : loss : 0.019616, loss_ce: 0.007929
2022-01-14 02:11:03,271 iteration 6701 : loss : 0.017624, loss_ce: 0.007174
2022-01-14 02:11:04,665 iteration 6702 : loss : 0.017333, loss_ce: 0.005742
2022-01-14 02:11:06,064 iteration 6703 : loss : 0.012655, loss_ce: 0.004184
2022-01-14 02:11:07,529 iteration 6704 : loss : 0.016105, loss_ce: 0.005215
2022-01-14 02:11:08,924 iteration 6705 : loss : 0.031344, loss_ce: 0.010642
2022-01-14 02:11:10,311 iteration 6706 : loss : 0.012435, loss_ce: 0.006036
2022-01-14 02:11:11,695 iteration 6707 : loss : 0.017414, loss_ce: 0.004940
2022-01-14 02:11:13,034 iteration 6708 : loss : 0.014702, loss_ce: 0.005117
2022-01-14 02:11:14,393 iteration 6709 : loss : 0.015531, loss_ce: 0.005196
2022-01-14 02:11:15,768 iteration 6710 : loss : 0.019717, loss_ce: 0.008492
2022-01-14 02:11:17,135 iteration 6711 : loss : 0.026324, loss_ce: 0.005841
2022-01-14 02:11:18,562 iteration 6712 : loss : 0.033756, loss_ce: 0.011866
2022-01-14 02:11:20,033 iteration 6713 : loss : 0.019441, loss_ce: 0.007493
2022-01-14 02:11:21,475 iteration 6714 : loss : 0.016722, loss_ce: 0.007478
2022-01-14 02:11:21,475 Training Data Eval:
2022-01-14 02:11:28,525   Average segmentation loss on training set: 0.0089
2022-01-14 02:11:28,525 Validation Data Eval:
2022-01-14 02:11:30,962   Average segmentation loss on validation set: 0.0767
2022-01-14 02:11:32,438 iteration 6715 : loss : 0.033508, loss_ce: 0.010581
 99%|████████████████████████████▋| 395/400 [2:51:45<02:17, 27.55s/it]2022-01-14 02:11:33,926 iteration 6716 : loss : 0.018653, loss_ce: 0.008438
2022-01-14 02:11:35,330 iteration 6717 : loss : 0.025209, loss_ce: 0.009999
2022-01-14 02:11:36,692 iteration 6718 : loss : 0.012482, loss_ce: 0.004268
2022-01-14 02:11:38,082 iteration 6719 : loss : 0.013040, loss_ce: 0.004176
2022-01-14 02:11:39,500 iteration 6720 : loss : 0.015406, loss_ce: 0.005903
2022-01-14 02:11:40,939 iteration 6721 : loss : 0.030768, loss_ce: 0.012171
2022-01-14 02:11:42,389 iteration 6722 : loss : 0.024747, loss_ce: 0.006719
2022-01-14 02:11:43,788 iteration 6723 : loss : 0.016754, loss_ce: 0.005973
2022-01-14 02:11:45,166 iteration 6724 : loss : 0.017283, loss_ce: 0.008717
2022-01-14 02:11:46,620 iteration 6725 : loss : 0.014458, loss_ce: 0.005705
2022-01-14 02:11:48,070 iteration 6726 : loss : 0.021324, loss_ce: 0.006826
2022-01-14 02:11:49,527 iteration 6727 : loss : 0.018006, loss_ce: 0.008190
2022-01-14 02:11:50,978 iteration 6728 : loss : 0.016890, loss_ce: 0.008631
2022-01-14 02:11:52,356 iteration 6729 : loss : 0.021587, loss_ce: 0.006727
2022-01-14 02:11:53,763 iteration 6730 : loss : 0.019277, loss_ce: 0.006381
2022-01-14 02:11:55,156 iteration 6731 : loss : 0.016512, loss_ce: 0.008212
2022-01-14 02:11:56,584 iteration 6732 : loss : 0.013362, loss_ce: 0.006291
 99%|████████████████████████████▋| 396/400 [2:52:10<01:46, 26.53s/it]2022-01-14 02:11:58,108 iteration 6733 : loss : 0.020944, loss_ce: 0.009897
2022-01-14 02:11:59,490 iteration 6734 : loss : 0.009309, loss_ce: 0.002803
2022-01-14 02:12:00,949 iteration 6735 : loss : 0.017679, loss_ce: 0.009190
2022-01-14 02:12:02,389 iteration 6736 : loss : 0.019261, loss_ce: 0.005768
2022-01-14 02:12:03,773 iteration 6737 : loss : 0.013039, loss_ce: 0.006171
2022-01-14 02:12:05,183 iteration 6738 : loss : 0.011677, loss_ce: 0.004054
2022-01-14 02:12:06,625 iteration 6739 : loss : 0.019557, loss_ce: 0.007038
2022-01-14 02:12:08,103 iteration 6740 : loss : 0.020304, loss_ce: 0.007388
2022-01-14 02:12:09,458 iteration 6741 : loss : 0.013391, loss_ce: 0.006145
2022-01-14 02:12:10,909 iteration 6742 : loss : 0.018206, loss_ce: 0.007792
2022-01-14 02:12:12,332 iteration 6743 : loss : 0.017967, loss_ce: 0.006629
2022-01-14 02:12:13,819 iteration 6744 : loss : 0.014491, loss_ce: 0.005893
2022-01-14 02:12:15,197 iteration 6745 : loss : 0.019842, loss_ce: 0.006022
2022-01-14 02:12:16,575 iteration 6746 : loss : 0.020473, loss_ce: 0.007631
2022-01-14 02:12:17,958 iteration 6747 : loss : 0.018408, loss_ce: 0.006430
2022-01-14 02:12:19,368 iteration 6748 : loss : 0.014468, loss_ce: 0.005614
2022-01-14 02:12:20,822 iteration 6749 : loss : 0.016714, loss_ce: 0.005671
 99%|████████████████████████████▊| 397/400 [2:52:34<01:17, 25.84s/it]2022-01-14 02:12:22,273 iteration 6750 : loss : 0.016588, loss_ce: 0.006036
2022-01-14 02:12:23,720 iteration 6751 : loss : 0.020567, loss_ce: 0.010382
2022-01-14 02:12:25,170 iteration 6752 : loss : 0.045137, loss_ce: 0.023855
2022-01-14 02:12:26,600 iteration 6753 : loss : 0.022693, loss_ce: 0.008891
2022-01-14 02:12:28,062 iteration 6754 : loss : 0.019454, loss_ce: 0.004787
2022-01-14 02:12:29,485 iteration 6755 : loss : 0.009767, loss_ce: 0.003089
2022-01-14 02:12:30,915 iteration 6756 : loss : 0.015641, loss_ce: 0.005920
2022-01-14 02:12:32,354 iteration 6757 : loss : 0.019250, loss_ce: 0.008408
2022-01-14 02:12:33,732 iteration 6758 : loss : 0.012631, loss_ce: 0.004886
2022-01-14 02:12:35,173 iteration 6759 : loss : 0.015353, loss_ce: 0.005604
2022-01-14 02:12:36,579 iteration 6760 : loss : 0.020718, loss_ce: 0.008452
2022-01-14 02:12:38,027 iteration 6761 : loss : 0.015135, loss_ce: 0.006528
2022-01-14 02:12:39,328 iteration 6762 : loss : 0.012110, loss_ce: 0.004437
2022-01-14 02:12:40,737 iteration 6763 : loss : 0.019982, loss_ce: 0.005235
2022-01-14 02:12:42,132 iteration 6764 : loss : 0.014437, loss_ce: 0.005014
2022-01-14 02:12:43,525 iteration 6765 : loss : 0.015044, loss_ce: 0.005557
2022-01-14 02:12:44,901 iteration 6766 : loss : 0.015032, loss_ce: 0.005495
100%|████████████████████████████▊| 398/400 [2:52:58<00:50, 25.31s/it]2022-01-14 02:12:46,491 iteration 6767 : loss : 0.016070, loss_ce: 0.005066
2022-01-14 02:12:47,840 iteration 6768 : loss : 0.016137, loss_ce: 0.006854
2022-01-14 02:12:49,231 iteration 6769 : loss : 0.028683, loss_ce: 0.009238
2022-01-14 02:12:50,567 iteration 6770 : loss : 0.010626, loss_ce: 0.004165
2022-01-14 02:12:51,983 iteration 6771 : loss : 0.015042, loss_ce: 0.004675
2022-01-14 02:12:53,459 iteration 6772 : loss : 0.025184, loss_ce: 0.007358
2022-01-14 02:12:54,876 iteration 6773 : loss : 0.014102, loss_ce: 0.005817
2022-01-14 02:12:56,289 iteration 6774 : loss : 0.014827, loss_ce: 0.006193
2022-01-14 02:12:57,714 iteration 6775 : loss : 0.019641, loss_ce: 0.007459
2022-01-14 02:12:59,174 iteration 6776 : loss : 0.036694, loss_ce: 0.019444
2022-01-14 02:13:00,601 iteration 6777 : loss : 0.014408, loss_ce: 0.005177
2022-01-14 02:13:01,972 iteration 6778 : loss : 0.015648, loss_ce: 0.004730
2022-01-14 02:13:03,372 iteration 6779 : loss : 0.013014, loss_ce: 0.003896
2022-01-14 02:13:04,714 iteration 6780 : loss : 0.011895, loss_ce: 0.003935
2022-01-14 02:13:06,079 iteration 6781 : loss : 0.016563, loss_ce: 0.008572
2022-01-14 02:13:07,482 iteration 6782 : loss : 0.012832, loss_ce: 0.005196
2022-01-14 02:13:08,902 iteration 6783 : loss : 0.015199, loss_ce: 0.006113
100%|████████████████████████████▉| 399/400 [2:53:22<00:24, 24.92s/it]2022-01-14 02:13:10,453 iteration 6784 : loss : 0.024736, loss_ce: 0.008403
2022-01-14 02:13:11,787 iteration 6785 : loss : 0.016130, loss_ce: 0.006989
2022-01-14 02:13:13,097 iteration 6786 : loss : 0.013776, loss_ce: 0.006255
2022-01-14 02:13:14,522 iteration 6787 : loss : 0.019857, loss_ce: 0.007013
2022-01-14 02:13:15,879 iteration 6788 : loss : 0.017687, loss_ce: 0.004155
2022-01-14 02:13:17,335 iteration 6789 : loss : 0.012622, loss_ce: 0.005173
2022-01-14 02:13:18,779 iteration 6790 : loss : 0.016023, loss_ce: 0.004471
2022-01-14 02:13:20,236 iteration 6791 : loss : 0.025117, loss_ce: 0.007543
2022-01-14 02:13:21,688 iteration 6792 : loss : 0.018198, loss_ce: 0.008337
2022-01-14 02:13:23,086 iteration 6793 : loss : 0.015977, loss_ce: 0.005650
2022-01-14 02:13:24,500 iteration 6794 : loss : 0.015271, loss_ce: 0.006061
2022-01-14 02:13:25,898 iteration 6795 : loss : 0.013301, loss_ce: 0.004842
2022-01-14 02:13:27,291 iteration 6796 : loss : 0.020672, loss_ce: 0.006605
2022-01-14 02:13:28,643 iteration 6797 : loss : 0.015110, loss_ce: 0.005671
2022-01-14 02:13:29,970 iteration 6798 : loss : 0.013704, loss_ce: 0.005045
2022-01-14 02:13:31,379 iteration 6799 : loss : 0.024496, loss_ce: 0.012040
2022-01-14 02:13:31,379 Training Data Eval:
2022-01-14 02:13:38,473   Average segmentation loss on training set: 0.0091
2022-01-14 02:13:38,473 Validation Data Eval:
2022-01-14 02:13:40,941   Average segmentation loss on validation set: 0.0740
2022-01-14 02:13:42,350 iteration 6800 : loss : 0.020754, loss_ce: 0.010241
100%|█████████████████████████████| 400/400 [2:53:55<00:00, 27.48s/it]100%|█████████████████████████████| 400/400 [2:53:55<00:00, 26.09s/it]
