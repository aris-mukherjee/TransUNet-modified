2022-01-14 11:35:24,308 Logging directory: /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/TransUNet/log_dir/trRUNMC_cv1_r3/i2i2l/
2022-01-14 11:35:24,309 Tensorboard directory: /scratch_net/biwidl217_second/arismu/Tensorboard/trRUNMC_cv1_r3/i2i2l/
2022-01-14 11:35:24,309 ============================================================
2022-01-14 11:35:24,309 EXPERIMENT NAME: trRUNMC_cv1_r3/i2i2l/
2022-01-14 11:35:24,309 ============================================================
2022-01-14 11:35:24,309 Loading data...
2022-01-14 11:35:24,309 Reading NCI - RUNMC images...
2022-01-14 11:35:24,309 Data root directory: /itet-stor/arismu/bmicdatasets-originals/Originals/Challenge_Datasets/NCI_Prostate/
2022-01-14 11:35:24,311 Already preprocessed this configuration. Loading now!
2022-01-14 11:35:24,329 Training Images: (256, 256, 286)
2022-01-14 11:35:24,329 Training Labels: (256, 256, 286)
2022-01-14 11:35:24,329 Validation Images: (256, 256, 98)
2022-01-14 11:35:24,329 Validation Labels: (256, 256, 98)
2022-01-14 11:35:24,329 ============================================================
2022-01-14 11:35:26,016 17 iterations per epoch. 6800 max iterations 
  0%|                                         | 0/400 [00:00<?, ?it/s]2022-01-14 11:35:27,051 iteration 1 : loss : 0.748680, loss_ce: 0.813152
2022-01-14 11:35:27,926 iteration 2 : loss : 0.687758, loss_ce: 0.727867
2022-01-14 11:35:28,905 iteration 3 : loss : 0.644251, loss_ce: 0.646115
2022-01-14 11:35:29,793 iteration 4 : loss : 0.600084, loss_ce: 0.570941
2022-01-14 11:35:30,684 iteration 5 : loss : 0.559824, loss_ce: 0.516192
2022-01-14 11:35:31,594 iteration 6 : loss : 0.526839, loss_ce: 0.458064
2022-01-14 11:35:32,554 iteration 7 : loss : 0.490368, loss_ce: 0.421747
2022-01-14 11:35:33,468 iteration 8 : loss : 0.480446, loss_ce: 0.370247
2022-01-14 11:35:34,403 iteration 9 : loss : 0.456436, loss_ce: 0.383615
2022-01-14 11:35:35,364 iteration 10 : loss : 0.436094, loss_ce: 0.302628
2022-01-14 11:35:36,379 iteration 11 : loss : 0.418611, loss_ce: 0.302606
2022-01-14 11:35:37,282 iteration 12 : loss : 0.416003, loss_ce: 0.272010
2022-01-14 11:35:38,166 iteration 13 : loss : 0.408004, loss_ce: 0.249446
2022-01-14 11:35:39,026 iteration 14 : loss : 0.375357, loss_ce: 0.228955
2022-01-14 11:35:39,957 iteration 15 : loss : 0.364658, loss_ce: 0.213437
2022-01-14 11:35:40,865 iteration 16 : loss : 0.395476, loss_ce: 0.222023
2022-01-14 11:35:41,773 iteration 17 : loss : 0.343946, loss_ce: 0.199376
  0%|                               | 1/400 [00:15<1:45:15, 15.83s/it]2022-01-14 11:35:42,783 iteration 18 : loss : 0.364464, loss_ce: 0.170381
2022-01-14 11:35:43,624 iteration 19 : loss : 0.320745, loss_ce: 0.159173
2022-01-14 11:35:44,598 iteration 20 : loss : 0.311882, loss_ce: 0.148953
2022-01-14 11:35:45,484 iteration 21 : loss : 0.339197, loss_ce: 0.136809
2022-01-14 11:35:46,387 iteration 22 : loss : 0.308100, loss_ce: 0.152919
2022-01-14 11:35:47,374 iteration 23 : loss : 0.289898, loss_ce: 0.117346
2022-01-14 11:35:48,283 iteration 24 : loss : 0.295944, loss_ce: 0.130030
2022-01-14 11:35:49,242 iteration 25 : loss : 0.367401, loss_ce: 0.196670
2022-01-14 11:35:50,132 iteration 26 : loss : 0.291184, loss_ce: 0.130555
2022-01-14 11:35:50,969 iteration 27 : loss : 0.288526, loss_ce: 0.138692
2022-01-14 11:35:51,815 iteration 28 : loss : 0.284272, loss_ce: 0.128383
2022-01-14 11:35:52,759 iteration 29 : loss : 0.291261, loss_ce: 0.125235
2022-01-14 11:35:53,698 iteration 30 : loss : 0.299136, loss_ce: 0.134548
2022-01-14 11:35:54,548 iteration 31 : loss : 0.274481, loss_ce: 0.123652
2022-01-14 11:35:55,512 iteration 32 : loss : 0.293203, loss_ce: 0.152360
2022-01-14 11:35:56,460 iteration 33 : loss : 0.303167, loss_ce: 0.155718
2022-01-14 11:35:57,414 iteration 34 : loss : 0.296312, loss_ce: 0.159455
  0%|▏                              | 2/400 [00:31<1:44:14, 15.71s/it]2022-01-14 11:35:58,435 iteration 35 : loss : 0.292272, loss_ce: 0.129828
2022-01-14 11:35:59,408 iteration 36 : loss : 0.281006, loss_ce: 0.125793
2022-01-14 11:36:00,406 iteration 37 : loss : 0.289655, loss_ce: 0.108107
2022-01-14 11:36:01,297 iteration 38 : loss : 0.272417, loss_ce: 0.117868
2022-01-14 11:36:02,202 iteration 39 : loss : 0.254395, loss_ce: 0.107853
2022-01-14 11:36:03,168 iteration 40 : loss : 0.273053, loss_ce: 0.131331
2022-01-14 11:36:04,125 iteration 41 : loss : 0.332483, loss_ce: 0.159657
2022-01-14 11:36:05,063 iteration 42 : loss : 0.264269, loss_ce: 0.128631
2022-01-14 11:36:05,915 iteration 43 : loss : 0.247991, loss_ce: 0.105997
2022-01-14 11:36:06,905 iteration 44 : loss : 0.234070, loss_ce: 0.102949
2022-01-14 11:36:07,826 iteration 45 : loss : 0.233816, loss_ce: 0.106000
2022-01-14 11:36:08,753 iteration 46 : loss : 0.266394, loss_ce: 0.110154
2022-01-14 11:36:09,717 iteration 47 : loss : 0.224167, loss_ce: 0.090156
2022-01-14 11:36:10,652 iteration 48 : loss : 0.225337, loss_ce: 0.092739
2022-01-14 11:36:11,631 iteration 49 : loss : 0.338847, loss_ce: 0.161592
2022-01-14 11:36:12,515 iteration 50 : loss : 0.333260, loss_ce: 0.142852
2022-01-14 11:36:13,374 iteration 51 : loss : 0.277089, loss_ce: 0.120597
  1%|▏                              | 3/400 [00:47<1:44:42, 15.83s/it]2022-01-14 11:36:14,399 iteration 52 : loss : 0.290214, loss_ce: 0.133905
2022-01-14 11:36:15,347 iteration 53 : loss : 0.262356, loss_ce: 0.122276
2022-01-14 11:36:16,267 iteration 54 : loss : 0.252804, loss_ce: 0.106404
2022-01-14 11:36:17,220 iteration 55 : loss : 0.288379, loss_ce: 0.141828
2022-01-14 11:36:18,182 iteration 56 : loss : 0.277691, loss_ce: 0.123768
2022-01-14 11:36:19,192 iteration 57 : loss : 0.227230, loss_ce: 0.096351
2022-01-14 11:36:20,226 iteration 58 : loss : 0.309571, loss_ce: 0.126899
2022-01-14 11:36:21,230 iteration 59 : loss : 0.224503, loss_ce: 0.105286
2022-01-14 11:36:22,257 iteration 60 : loss : 0.306352, loss_ce: 0.131349
2022-01-14 11:36:23,265 iteration 61 : loss : 0.262594, loss_ce: 0.127002
2022-01-14 11:36:24,265 iteration 62 : loss : 0.332077, loss_ce: 0.130377
2022-01-14 11:36:25,194 iteration 63 : loss : 0.312710, loss_ce: 0.149944
2022-01-14 11:36:26,180 iteration 64 : loss : 0.337286, loss_ce: 0.141036
2022-01-14 11:36:27,120 iteration 65 : loss : 0.271497, loss_ce: 0.091467
2022-01-14 11:36:28,097 iteration 66 : loss : 0.272527, loss_ce: 0.106299
2022-01-14 11:36:29,149 iteration 67 : loss : 0.262827, loss_ce: 0.088160
2022-01-14 11:36:30,167 iteration 68 : loss : 0.261746, loss_ce: 0.112338
  1%|▎                              | 4/400 [01:04<1:46:56, 16.20s/it]2022-01-14 11:36:31,245 iteration 69 : loss : 0.245234, loss_ce: 0.102104
2022-01-14 11:36:32,335 iteration 70 : loss : 0.229702, loss_ce: 0.097039
2022-01-14 11:36:33,304 iteration 71 : loss : 0.252593, loss_ce: 0.108499
2022-01-14 11:36:34,316 iteration 72 : loss : 0.223304, loss_ce: 0.095339
2022-01-14 11:36:35,272 iteration 73 : loss : 0.247397, loss_ce: 0.119585
2022-01-14 11:36:36,198 iteration 74 : loss : 0.228145, loss_ce: 0.096137
2022-01-14 11:36:37,156 iteration 75 : loss : 0.221038, loss_ce: 0.090469
2022-01-14 11:36:38,106 iteration 76 : loss : 0.246768, loss_ce: 0.102440
2022-01-14 11:36:38,980 iteration 77 : loss : 0.242702, loss_ce: 0.113437
2022-01-14 11:36:40,009 iteration 78 : loss : 0.275128, loss_ce: 0.126266
2022-01-14 11:36:40,961 iteration 79 : loss : 0.264537, loss_ce: 0.102586
2022-01-14 11:36:41,898 iteration 80 : loss : 0.275654, loss_ce: 0.129739
2022-01-14 11:36:42,828 iteration 81 : loss : 0.271027, loss_ce: 0.123070
2022-01-14 11:36:43,781 iteration 82 : loss : 0.227718, loss_ce: 0.090543
2022-01-14 11:36:44,731 iteration 83 : loss : 0.264791, loss_ce: 0.097451
2022-01-14 11:36:45,776 iteration 84 : loss : 0.266713, loss_ce: 0.144782
2022-01-14 11:36:45,776 Training Data Eval:
2022-01-14 11:36:50,592   Average segmentation loss on training set: 0.7387
2022-01-14 11:36:50,592 Validation Data Eval:
2022-01-14 11:36:52,209   Average segmentation loss on validation set: 0.7190
2022-01-14 11:36:53,388 Found new lowest validation loss at iteration 84! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_1BLOCK_best_val_loss_seed1234.pth
2022-01-14 11:36:54,350 iteration 85 : loss : 0.296868, loss_ce: 0.129717
  1%|▍                              | 5/400 [01:28<2:05:36, 19.08s/it]2022-01-14 11:36:55,406 iteration 86 : loss : 0.297961, loss_ce: 0.112211
2022-01-14 11:36:56,521 iteration 87 : loss : 0.255970, loss_ce: 0.114094
2022-01-14 11:36:57,461 iteration 88 : loss : 0.241796, loss_ce: 0.110422
2022-01-14 11:36:58,476 iteration 89 : loss : 0.270599, loss_ce: 0.113286
2022-01-14 11:36:59,481 iteration 90 : loss : 0.243362, loss_ce: 0.103151
2022-01-14 11:37:00,546 iteration 91 : loss : 0.237286, loss_ce: 0.122151
2022-01-14 11:37:01,471 iteration 92 : loss : 0.228567, loss_ce: 0.106337
2022-01-14 11:37:02,442 iteration 93 : loss : 0.256492, loss_ce: 0.094220
2022-01-14 11:37:03,422 iteration 94 : loss : 0.248126, loss_ce: 0.100648
2022-01-14 11:37:04,532 iteration 95 : loss : 0.255617, loss_ce: 0.117879
2022-01-14 11:37:05,500 iteration 96 : loss : 0.235282, loss_ce: 0.100685
2022-01-14 11:37:06,469 iteration 97 : loss : 0.274187, loss_ce: 0.112675
2022-01-14 11:37:07,451 iteration 98 : loss : 0.270583, loss_ce: 0.118573
2022-01-14 11:37:08,511 iteration 99 : loss : 0.220568, loss_ce: 0.094422
2022-01-14 11:37:09,520 iteration 100 : loss : 0.237232, loss_ce: 0.099270
2022-01-14 11:37:10,508 iteration 101 : loss : 0.189938, loss_ce: 0.074582
2022-01-14 11:37:11,430 iteration 102 : loss : 0.238189, loss_ce: 0.096243
  2%|▍                              | 6/400 [01:45<2:00:51, 18.40s/it]2022-01-14 11:37:12,580 iteration 103 : loss : 0.226376, loss_ce: 0.099657
2022-01-14 11:37:13,652 iteration 104 : loss : 0.266521, loss_ce: 0.115645
2022-01-14 11:37:14,768 iteration 105 : loss : 0.260251, loss_ce: 0.104734
2022-01-14 11:37:15,723 iteration 106 : loss : 0.264705, loss_ce: 0.107568
2022-01-14 11:37:16,857 iteration 107 : loss : 0.221935, loss_ce: 0.096534
2022-01-14 11:37:17,789 iteration 108 : loss : 0.271184, loss_ce: 0.109635
2022-01-14 11:37:18,754 iteration 109 : loss : 0.209125, loss_ce: 0.087917
2022-01-14 11:37:19,667 iteration 110 : loss : 0.196438, loss_ce: 0.084633
2022-01-14 11:37:20,685 iteration 111 : loss : 0.263059, loss_ce: 0.124798
2022-01-14 11:37:21,608 iteration 112 : loss : 0.228601, loss_ce: 0.094278
2022-01-14 11:37:22,600 iteration 113 : loss : 0.258302, loss_ce: 0.131286
2022-01-14 11:37:23,552 iteration 114 : loss : 0.257825, loss_ce: 0.092156
2022-01-14 11:37:24,529 iteration 115 : loss : 0.214634, loss_ce: 0.094415
2022-01-14 11:37:25,585 iteration 116 : loss : 0.276249, loss_ce: 0.124185
2022-01-14 11:37:26,613 iteration 117 : loss : 0.237065, loss_ce: 0.104296
2022-01-14 11:37:27,604 iteration 118 : loss : 0.285026, loss_ce: 0.128073
2022-01-14 11:37:28,610 iteration 119 : loss : 0.221380, loss_ce: 0.084226
  2%|▌                              | 7/400 [02:02<1:57:56, 18.01s/it]2022-01-14 11:37:29,623 iteration 120 : loss : 0.342407, loss_ce: 0.166427
2022-01-14 11:37:30,552 iteration 121 : loss : 0.215544, loss_ce: 0.096685
2022-01-14 11:37:31,589 iteration 122 : loss : 0.262007, loss_ce: 0.107978
2022-01-14 11:37:32,593 iteration 123 : loss : 0.224050, loss_ce: 0.098308
2022-01-14 11:37:33,571 iteration 124 : loss : 0.245548, loss_ce: 0.101634
2022-01-14 11:37:34,511 iteration 125 : loss : 0.242426, loss_ce: 0.117197
2022-01-14 11:37:35,518 iteration 126 : loss : 0.250108, loss_ce: 0.090662
2022-01-14 11:37:36,453 iteration 127 : loss : 0.228729, loss_ce: 0.096841
2022-01-14 11:37:37,413 iteration 128 : loss : 0.219001, loss_ce: 0.085185
2022-01-14 11:37:38,447 iteration 129 : loss : 0.206511, loss_ce: 0.075480
2022-01-14 11:37:39,421 iteration 130 : loss : 0.207564, loss_ce: 0.079326
2022-01-14 11:37:40,486 iteration 131 : loss : 0.236621, loss_ce: 0.121414
2022-01-14 11:37:41,573 iteration 132 : loss : 0.201669, loss_ce: 0.060428
2022-01-14 11:37:42,532 iteration 133 : loss : 0.190165, loss_ce: 0.077014
2022-01-14 11:37:43,586 iteration 134 : loss : 0.205925, loss_ce: 0.080782
2022-01-14 11:37:44,657 iteration 135 : loss : 0.230414, loss_ce: 0.098812
2022-01-14 11:37:45,645 iteration 136 : loss : 0.158773, loss_ce: 0.074417
  2%|▌                              | 8/400 [02:19<1:55:35, 17.69s/it]2022-01-14 11:37:46,754 iteration 137 : loss : 0.229604, loss_ce: 0.083359
2022-01-14 11:37:47,711 iteration 138 : loss : 0.236001, loss_ce: 0.129045
2022-01-14 11:37:48,727 iteration 139 : loss : 0.297480, loss_ce: 0.135632
2022-01-14 11:37:49,716 iteration 140 : loss : 0.221590, loss_ce: 0.087783
2022-01-14 11:37:50,756 iteration 141 : loss : 0.236219, loss_ce: 0.125020
2022-01-14 11:37:51,811 iteration 142 : loss : 0.237591, loss_ce: 0.101130
2022-01-14 11:37:52,885 iteration 143 : loss : 0.204137, loss_ce: 0.094209
2022-01-14 11:37:53,922 iteration 144 : loss : 0.228794, loss_ce: 0.094789
2022-01-14 11:37:54,907 iteration 145 : loss : 0.238627, loss_ce: 0.102759
2022-01-14 11:37:55,932 iteration 146 : loss : 0.197743, loss_ce: 0.103314
2022-01-14 11:37:56,965 iteration 147 : loss : 0.214354, loss_ce: 0.090478
2022-01-14 11:37:57,874 iteration 148 : loss : 0.232181, loss_ce: 0.108614
2022-01-14 11:37:58,850 iteration 149 : loss : 0.290779, loss_ce: 0.132379
2022-01-14 11:37:59,806 iteration 150 : loss : 0.248538, loss_ce: 0.085985
2022-01-14 11:38:00,771 iteration 151 : loss : 0.249175, loss_ce: 0.114883
2022-01-14 11:38:01,743 iteration 152 : loss : 0.240712, loss_ce: 0.084798
2022-01-14 11:38:02,764 iteration 153 : loss : 0.271082, loss_ce: 0.119296
  2%|▋                              | 9/400 [02:36<1:54:08, 17.52s/it]2022-01-14 11:38:03,760 iteration 154 : loss : 0.299461, loss_ce: 0.133960
2022-01-14 11:38:04,759 iteration 155 : loss : 0.224654, loss_ce: 0.081634
2022-01-14 11:38:05,832 iteration 156 : loss : 0.239927, loss_ce: 0.092591
2022-01-14 11:38:06,841 iteration 157 : loss : 0.287341, loss_ce: 0.112985
2022-01-14 11:38:07,963 iteration 158 : loss : 0.251187, loss_ce: 0.103458
2022-01-14 11:38:08,847 iteration 159 : loss : 0.217214, loss_ce: 0.087179
2022-01-14 11:38:09,918 iteration 160 : loss : 0.179981, loss_ce: 0.061327
2022-01-14 11:38:10,977 iteration 161 : loss : 0.246345, loss_ce: 0.095357
2022-01-14 11:38:12,040 iteration 162 : loss : 0.216985, loss_ce: 0.105240
2022-01-14 11:38:13,034 iteration 163 : loss : 0.238161, loss_ce: 0.096811
2022-01-14 11:38:14,048 iteration 164 : loss : 0.205783, loss_ce: 0.073947
2022-01-14 11:38:15,032 iteration 165 : loss : 0.287979, loss_ce: 0.121104
2022-01-14 11:38:16,000 iteration 166 : loss : 0.249621, loss_ce: 0.099544
2022-01-14 11:38:16,987 iteration 167 : loss : 0.206368, loss_ce: 0.077608
2022-01-14 11:38:18,020 iteration 168 : loss : 0.276002, loss_ce: 0.143076
2022-01-14 11:38:19,021 iteration 169 : loss : 0.208407, loss_ce: 0.111921
2022-01-14 11:38:19,021 Training Data Eval:
2022-01-14 11:38:23,834   Average segmentation loss on training set: 0.2472
2022-01-14 11:38:23,834 Validation Data Eval:
2022-01-14 11:38:25,448   Average segmentation loss on validation set: 0.2310
2022-01-14 11:38:26,650 Found new lowest validation loss at iteration 169! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_1BLOCK_best_val_loss_seed1234.pth
2022-01-14 11:38:27,713 iteration 170 : loss : 0.202508, loss_ce: 0.092428
  2%|▊                             | 10/400 [03:01<2:08:44, 19.81s/it]2022-01-14 11:38:28,774 iteration 171 : loss : 0.236369, loss_ce: 0.106551
2022-01-14 11:38:29,796 iteration 172 : loss : 0.244237, loss_ce: 0.111804
2022-01-14 11:38:30,839 iteration 173 : loss : 0.211019, loss_ce: 0.098327
2022-01-14 11:38:31,796 iteration 174 : loss : 0.242180, loss_ce: 0.112395
2022-01-14 11:38:32,737 iteration 175 : loss : 0.308371, loss_ce: 0.136406
2022-01-14 11:38:33,750 iteration 176 : loss : 0.228825, loss_ce: 0.111459
2022-01-14 11:38:34,733 iteration 177 : loss : 0.248969, loss_ce: 0.089850
2022-01-14 11:38:35,720 iteration 178 : loss : 0.178199, loss_ce: 0.081165
2022-01-14 11:38:36,706 iteration 179 : loss : 0.260083, loss_ce: 0.109515
2022-01-14 11:38:37,671 iteration 180 : loss : 0.201858, loss_ce: 0.077493
2022-01-14 11:38:38,686 iteration 181 : loss : 0.234180, loss_ce: 0.101962
2022-01-14 11:38:39,643 iteration 182 : loss : 0.173097, loss_ce: 0.073772
2022-01-14 11:38:40,580 iteration 183 : loss : 0.213344, loss_ce: 0.078712
2022-01-14 11:38:41,479 iteration 184 : loss : 0.219978, loss_ce: 0.081128
2022-01-14 11:38:42,502 iteration 185 : loss : 0.280536, loss_ce: 0.092673
2022-01-14 11:38:43,528 iteration 186 : loss : 0.271279, loss_ce: 0.116777
2022-01-14 11:38:44,580 iteration 187 : loss : 0.261609, loss_ce: 0.101294
  3%|▊                             | 11/400 [03:18<2:02:34, 18.91s/it]2022-01-14 11:38:45,655 iteration 188 : loss : 0.289476, loss_ce: 0.125220
2022-01-14 11:38:46,665 iteration 189 : loss : 0.223637, loss_ce: 0.092577
2022-01-14 11:38:47,679 iteration 190 : loss : 0.188682, loss_ce: 0.067428
2022-01-14 11:38:48,653 iteration 191 : loss : 0.178235, loss_ce: 0.069887
2022-01-14 11:38:49,580 iteration 192 : loss : 0.212961, loss_ce: 0.099997
2022-01-14 11:38:50,631 iteration 193 : loss : 0.248364, loss_ce: 0.123501
2022-01-14 11:38:51,613 iteration 194 : loss : 0.280589, loss_ce: 0.093033
2022-01-14 11:38:52,572 iteration 195 : loss : 0.232192, loss_ce: 0.103711
2022-01-14 11:38:53,483 iteration 196 : loss : 0.214152, loss_ce: 0.081283
2022-01-14 11:38:54,479 iteration 197 : loss : 0.277286, loss_ce: 0.117644
2022-01-14 11:38:55,504 iteration 198 : loss : 0.172208, loss_ce: 0.075161
2022-01-14 11:38:56,457 iteration 199 : loss : 0.239968, loss_ce: 0.098395
2022-01-14 11:38:57,426 iteration 200 : loss : 0.218837, loss_ce: 0.098997
2022-01-14 11:38:58,431 iteration 201 : loss : 0.178034, loss_ce: 0.075763
2022-01-14 11:38:59,454 iteration 202 : loss : 0.220155, loss_ce: 0.109928
2022-01-14 11:39:00,401 iteration 203 : loss : 0.185505, loss_ce: 0.075741
2022-01-14 11:39:01,486 iteration 204 : loss : 0.203513, loss_ce: 0.077846
  3%|▉                             | 12/400 [03:35<1:58:20, 18.30s/it]2022-01-14 11:39:02,500 iteration 205 : loss : 0.180902, loss_ce: 0.068321
2022-01-14 11:39:03,482 iteration 206 : loss : 0.187716, loss_ce: 0.063558
2022-01-14 11:39:04,488 iteration 207 : loss : 0.192286, loss_ce: 0.078373
2022-01-14 11:39:05,455 iteration 208 : loss : 0.241426, loss_ce: 0.076608
2022-01-14 11:39:06,515 iteration 209 : loss : 0.313645, loss_ce: 0.157837
2022-01-14 11:39:07,419 iteration 210 : loss : 0.175794, loss_ce: 0.063017
2022-01-14 11:39:08,445 iteration 211 : loss : 0.226696, loss_ce: 0.098761
2022-01-14 11:39:09,455 iteration 212 : loss : 0.221311, loss_ce: 0.089753
2022-01-14 11:39:10,555 iteration 213 : loss : 0.166870, loss_ce: 0.081635
2022-01-14 11:39:11,550 iteration 214 : loss : 0.228759, loss_ce: 0.083613
2022-01-14 11:39:12,547 iteration 215 : loss : 0.250719, loss_ce: 0.107095
2022-01-14 11:39:13,700 iteration 216 : loss : 0.262063, loss_ce: 0.110064
2022-01-14 11:39:14,798 iteration 217 : loss : 0.196974, loss_ce: 0.075714
2022-01-14 11:39:15,818 iteration 218 : loss : 0.203814, loss_ce: 0.087950
2022-01-14 11:39:16,717 iteration 219 : loss : 0.236525, loss_ce: 0.097972
2022-01-14 11:39:17,732 iteration 220 : loss : 0.176060, loss_ce: 0.078275
2022-01-14 11:39:18,732 iteration 221 : loss : 0.261841, loss_ce: 0.105237
  3%|▉                             | 13/400 [03:52<1:55:58, 17.98s/it]2022-01-14 11:39:19,802 iteration 222 : loss : 0.233963, loss_ce: 0.114554
2022-01-14 11:39:20,844 iteration 223 : loss : 0.182285, loss_ce: 0.080219
2022-01-14 11:39:21,841 iteration 224 : loss : 0.303382, loss_ce: 0.150592
2022-01-14 11:39:22,937 iteration 225 : loss : 0.295279, loss_ce: 0.092999
2022-01-14 11:39:23,929 iteration 226 : loss : 0.217547, loss_ce: 0.081042
2022-01-14 11:39:24,968 iteration 227 : loss : 0.243567, loss_ce: 0.100857
2022-01-14 11:39:25,962 iteration 228 : loss : 0.238385, loss_ce: 0.097567
2022-01-14 11:39:26,907 iteration 229 : loss : 0.210472, loss_ce: 0.067787
2022-01-14 11:39:27,909 iteration 230 : loss : 0.183646, loss_ce: 0.069666
2022-01-14 11:39:29,035 iteration 231 : loss : 0.282724, loss_ce: 0.120107
2022-01-14 11:39:30,072 iteration 232 : loss : 0.186671, loss_ce: 0.077552
2022-01-14 11:39:31,023 iteration 233 : loss : 0.269733, loss_ce: 0.121725
2022-01-14 11:39:32,086 iteration 234 : loss : 0.249725, loss_ce: 0.102340
2022-01-14 11:39:33,064 iteration 235 : loss : 0.221175, loss_ce: 0.097189
2022-01-14 11:39:34,084 iteration 236 : loss : 0.224519, loss_ce: 0.090592
2022-01-14 11:39:35,062 iteration 237 : loss : 0.185579, loss_ce: 0.071994
2022-01-14 11:39:36,077 iteration 238 : loss : 0.231153, loss_ce: 0.108186
  4%|█                             | 14/400 [04:10<1:54:26, 17.79s/it]2022-01-14 11:39:37,075 iteration 239 : loss : 0.217278, loss_ce: 0.071840
2022-01-14 11:39:38,102 iteration 240 : loss : 0.205648, loss_ce: 0.093816
2022-01-14 11:39:39,133 iteration 241 : loss : 0.226161, loss_ce: 0.087964
2022-01-14 11:39:40,147 iteration 242 : loss : 0.233900, loss_ce: 0.125323
2022-01-14 11:39:41,287 iteration 243 : loss : 0.232681, loss_ce: 0.100396
2022-01-14 11:39:42,234 iteration 244 : loss : 0.260691, loss_ce: 0.081742
2022-01-14 11:39:43,246 iteration 245 : loss : 0.178853, loss_ce: 0.088712
2022-01-14 11:39:44,295 iteration 246 : loss : 0.192081, loss_ce: 0.086697
2022-01-14 11:39:45,282 iteration 247 : loss : 0.235433, loss_ce: 0.090093
2022-01-14 11:39:46,269 iteration 248 : loss : 0.178612, loss_ce: 0.064671
2022-01-14 11:39:47,239 iteration 249 : loss : 0.218502, loss_ce: 0.115580
2022-01-14 11:39:48,224 iteration 250 : loss : 0.237317, loss_ce: 0.092508
2022-01-14 11:39:49,153 iteration 251 : loss : 0.259600, loss_ce: 0.088149
2022-01-14 11:39:50,135 iteration 252 : loss : 0.134526, loss_ce: 0.058085
2022-01-14 11:39:51,151 iteration 253 : loss : 0.210721, loss_ce: 0.081755
2022-01-14 11:39:52,227 iteration 254 : loss : 0.313230, loss_ce: 0.114413
2022-01-14 11:39:52,227 Training Data Eval:
2022-01-14 11:39:57,027   Average segmentation loss on training set: 0.2505
2022-01-14 11:39:57,027 Validation Data Eval:
2022-01-14 11:39:58,640   Average segmentation loss on validation set: 0.2444
2022-01-14 11:39:59,647 iteration 255 : loss : 0.204972, loss_ce: 0.089179
  4%|█▏                            | 15/400 [04:33<2:05:20, 19.53s/it]2022-01-14 11:40:00,725 iteration 256 : loss : 0.210959, loss_ce: 0.088569
2022-01-14 11:40:01,776 iteration 257 : loss : 0.189203, loss_ce: 0.077509
2022-01-14 11:40:02,880 iteration 258 : loss : 0.207632, loss_ce: 0.082478
2022-01-14 11:40:03,805 iteration 259 : loss : 0.172285, loss_ce: 0.080267
2022-01-14 11:40:04,905 iteration 260 : loss : 0.203981, loss_ce: 0.092374
2022-01-14 11:40:05,921 iteration 261 : loss : 0.260647, loss_ce: 0.098960
2022-01-14 11:40:07,021 iteration 262 : loss : 0.203169, loss_ce: 0.087413
2022-01-14 11:40:08,024 iteration 263 : loss : 0.192672, loss_ce: 0.077891
2022-01-14 11:40:09,058 iteration 264 : loss : 0.247583, loss_ce: 0.119877
2022-01-14 11:40:10,022 iteration 265 : loss : 0.150786, loss_ce: 0.060851
2022-01-14 11:40:11,052 iteration 266 : loss : 0.182536, loss_ce: 0.082358
2022-01-14 11:40:12,045 iteration 267 : loss : 0.196273, loss_ce: 0.062054
2022-01-14 11:40:13,057 iteration 268 : loss : 0.227435, loss_ce: 0.098527
2022-01-14 11:40:14,261 iteration 269 : loss : 0.235737, loss_ce: 0.080206
2022-01-14 11:40:15,406 iteration 270 : loss : 0.184410, loss_ce: 0.078142
2022-01-14 11:40:16,290 iteration 271 : loss : 0.215534, loss_ce: 0.064973
2022-01-14 11:40:17,297 iteration 272 : loss : 0.202386, loss_ce: 0.099865
  4%|█▏                            | 16/400 [04:51<2:01:23, 18.97s/it]2022-01-14 11:40:18,307 iteration 273 : loss : 0.183126, loss_ce: 0.064913
2022-01-14 11:40:19,245 iteration 274 : loss : 0.139762, loss_ce: 0.056180
2022-01-14 11:40:20,190 iteration 275 : loss : 0.162674, loss_ce: 0.064002
2022-01-14 11:40:21,198 iteration 276 : loss : 0.139032, loss_ce: 0.064805
2022-01-14 11:40:22,229 iteration 277 : loss : 0.164372, loss_ce: 0.061124
2022-01-14 11:40:23,107 iteration 278 : loss : 0.206925, loss_ce: 0.073647
2022-01-14 11:40:24,054 iteration 279 : loss : 0.224405, loss_ce: 0.080110
2022-01-14 11:40:24,994 iteration 280 : loss : 0.191204, loss_ce: 0.084250
2022-01-14 11:40:25,994 iteration 281 : loss : 0.200350, loss_ce: 0.085725
2022-01-14 11:40:26,971 iteration 282 : loss : 0.248541, loss_ce: 0.086531
2022-01-14 11:40:27,925 iteration 283 : loss : 0.183753, loss_ce: 0.088139
2022-01-14 11:40:28,976 iteration 284 : loss : 0.268382, loss_ce: 0.136593
2022-01-14 11:40:29,911 iteration 285 : loss : 0.197863, loss_ce: 0.068712
2022-01-14 11:40:30,860 iteration 286 : loss : 0.173209, loss_ce: 0.075153
2022-01-14 11:40:31,927 iteration 287 : loss : 0.184901, loss_ce: 0.085609
2022-01-14 11:40:32,975 iteration 288 : loss : 0.224432, loss_ce: 0.094308
2022-01-14 11:40:33,946 iteration 289 : loss : 0.200828, loss_ce: 0.078122
  4%|█▎                            | 17/400 [05:07<1:56:36, 18.27s/it]2022-01-14 11:40:35,004 iteration 290 : loss : 0.178520, loss_ce: 0.065010
2022-01-14 11:40:35,956 iteration 291 : loss : 0.215281, loss_ce: 0.090817
2022-01-14 11:40:36,918 iteration 292 : loss : 0.170990, loss_ce: 0.069027
2022-01-14 11:40:37,886 iteration 293 : loss : 0.217723, loss_ce: 0.094507
2022-01-14 11:40:38,889 iteration 294 : loss : 0.196922, loss_ce: 0.081123
2022-01-14 11:40:39,980 iteration 295 : loss : 0.238097, loss_ce: 0.089933
2022-01-14 11:40:40,949 iteration 296 : loss : 0.195234, loss_ce: 0.065563
2022-01-14 11:40:41,944 iteration 297 : loss : 0.164039, loss_ce: 0.062524
2022-01-14 11:40:42,904 iteration 298 : loss : 0.177559, loss_ce: 0.064697
2022-01-14 11:40:43,892 iteration 299 : loss : 0.191284, loss_ce: 0.067509
2022-01-14 11:40:44,883 iteration 300 : loss : 0.197872, loss_ce: 0.071839
2022-01-14 11:40:45,890 iteration 301 : loss : 0.267587, loss_ce: 0.147838
2022-01-14 11:40:46,948 iteration 302 : loss : 0.187933, loss_ce: 0.084284
2022-01-14 11:40:47,995 iteration 303 : loss : 0.230665, loss_ce: 0.099170
2022-01-14 11:40:49,021 iteration 304 : loss : 0.249027, loss_ce: 0.123201
2022-01-14 11:40:50,077 iteration 305 : loss : 0.195038, loss_ce: 0.091253
2022-01-14 11:40:51,138 iteration 306 : loss : 0.155112, loss_ce: 0.075462
  4%|█▎                            | 18/400 [05:25<1:54:15, 17.95s/it]2022-01-14 11:40:52,214 iteration 307 : loss : 0.209794, loss_ce: 0.081465
2022-01-14 11:40:53,177 iteration 308 : loss : 0.194292, loss_ce: 0.092689
2022-01-14 11:40:54,201 iteration 309 : loss : 0.283029, loss_ce: 0.107094
2022-01-14 11:40:55,246 iteration 310 : loss : 0.192320, loss_ce: 0.082551
2022-01-14 11:40:56,216 iteration 311 : loss : 0.174288, loss_ce: 0.056615
2022-01-14 11:40:57,221 iteration 312 : loss : 0.167383, loss_ce: 0.084422
2022-01-14 11:40:58,233 iteration 313 : loss : 0.207732, loss_ce: 0.106744
2022-01-14 11:40:59,176 iteration 314 : loss : 0.164353, loss_ce: 0.073008
2022-01-14 11:41:00,177 iteration 315 : loss : 0.189631, loss_ce: 0.070580
2022-01-14 11:41:01,227 iteration 316 : loss : 0.202908, loss_ce: 0.076081
2022-01-14 11:41:02,239 iteration 317 : loss : 0.229101, loss_ce: 0.102134
2022-01-14 11:41:03,277 iteration 318 : loss : 0.231461, loss_ce: 0.099747
2022-01-14 11:41:04,240 iteration 319 : loss : 0.199371, loss_ce: 0.080677
2022-01-14 11:41:05,361 iteration 320 : loss : 0.167183, loss_ce: 0.062302
2022-01-14 11:41:06,456 iteration 321 : loss : 0.207770, loss_ce: 0.068189
2022-01-14 11:41:07,476 iteration 322 : loss : 0.251143, loss_ce: 0.119883
2022-01-14 11:41:08,569 iteration 323 : loss : 0.202591, loss_ce: 0.065248
  5%|█▍                            | 19/400 [05:42<1:52:58, 17.79s/it]2022-01-14 11:41:09,648 iteration 324 : loss : 0.183173, loss_ce: 0.072863
2022-01-14 11:41:10,674 iteration 325 : loss : 0.229397, loss_ce: 0.084360
2022-01-14 11:41:11,724 iteration 326 : loss : 0.168382, loss_ce: 0.073945
2022-01-14 11:41:12,861 iteration 327 : loss : 0.210684, loss_ce: 0.090040
2022-01-14 11:41:13,856 iteration 328 : loss : 0.191084, loss_ce: 0.080759
2022-01-14 11:41:14,900 iteration 329 : loss : 0.217289, loss_ce: 0.110874
2022-01-14 11:41:15,959 iteration 330 : loss : 0.201760, loss_ce: 0.089862
2022-01-14 11:41:16,919 iteration 331 : loss : 0.195002, loss_ce: 0.092857
2022-01-14 11:41:17,902 iteration 332 : loss : 0.159098, loss_ce: 0.059139
2022-01-14 11:41:18,930 iteration 333 : loss : 0.130870, loss_ce: 0.061501
2022-01-14 11:41:19,939 iteration 334 : loss : 0.171306, loss_ce: 0.074585
2022-01-14 11:41:20,915 iteration 335 : loss : 0.233713, loss_ce: 0.086674
2022-01-14 11:41:21,981 iteration 336 : loss : 0.182525, loss_ce: 0.063671
2022-01-14 11:41:22,981 iteration 337 : loss : 0.154581, loss_ce: 0.048655
2022-01-14 11:41:23,947 iteration 338 : loss : 0.261301, loss_ce: 0.128514
2022-01-14 11:41:24,919 iteration 339 : loss : 0.188009, loss_ce: 0.066960
2022-01-14 11:41:24,919 Training Data Eval:
2022-01-14 11:41:29,763   Average segmentation loss on training set: 0.2206
2022-01-14 11:41:29,763 Validation Data Eval:
2022-01-14 11:41:31,384   Average segmentation loss on validation set: 0.2987
2022-01-14 11:41:32,428 iteration 340 : loss : 0.198931, loss_ce: 0.093791
  5%|█▌                            | 20/400 [06:06<2:04:11, 19.61s/it]2022-01-14 11:41:33,537 iteration 341 : loss : 0.176404, loss_ce: 0.071838
2022-01-14 11:41:34,574 iteration 342 : loss : 0.170906, loss_ce: 0.057756
2022-01-14 11:41:35,583 iteration 343 : loss : 0.197151, loss_ce: 0.077043
2022-01-14 11:41:36,631 iteration 344 : loss : 0.220779, loss_ce: 0.096524
2022-01-14 11:41:37,634 iteration 345 : loss : 0.157328, loss_ce: 0.054795
2022-01-14 11:41:38,706 iteration 346 : loss : 0.213512, loss_ce: 0.087519
2022-01-14 11:41:39,657 iteration 347 : loss : 0.198184, loss_ce: 0.090001
2022-01-14 11:41:40,716 iteration 348 : loss : 0.223867, loss_ce: 0.095805
2022-01-14 11:41:41,848 iteration 349 : loss : 0.188684, loss_ce: 0.095725
2022-01-14 11:41:42,846 iteration 350 : loss : 0.173402, loss_ce: 0.069570
2022-01-14 11:41:43,909 iteration 351 : loss : 0.190395, loss_ce: 0.086608
2022-01-14 11:41:44,956 iteration 352 : loss : 0.181223, loss_ce: 0.073951
2022-01-14 11:41:45,912 iteration 353 : loss : 0.161858, loss_ce: 0.059974
2022-01-14 11:41:46,923 iteration 354 : loss : 0.202443, loss_ce: 0.071360
2022-01-14 11:41:47,986 iteration 355 : loss : 0.206952, loss_ce: 0.080748
2022-01-14 11:41:49,115 iteration 356 : loss : 0.162338, loss_ce: 0.075702
2022-01-14 11:41:50,054 iteration 357 : loss : 0.139183, loss_ce: 0.058896
  5%|█▌                            | 21/400 [06:24<2:00:06, 19.02s/it]2022-01-14 11:41:51,159 iteration 358 : loss : 0.198018, loss_ce: 0.089751
2022-01-14 11:41:52,253 iteration 359 : loss : 0.197410, loss_ce: 0.077912
2022-01-14 11:41:53,207 iteration 360 : loss : 0.163702, loss_ce: 0.058000
2022-01-14 11:41:54,255 iteration 361 : loss : 0.209702, loss_ce: 0.078853
2022-01-14 11:41:55,345 iteration 362 : loss : 0.160856, loss_ce: 0.047820
2022-01-14 11:41:56,457 iteration 363 : loss : 0.188861, loss_ce: 0.065400
2022-01-14 11:41:57,500 iteration 364 : loss : 0.168022, loss_ce: 0.064956
2022-01-14 11:41:58,415 iteration 365 : loss : 0.193835, loss_ce: 0.091748
2022-01-14 11:41:59,464 iteration 366 : loss : 0.215317, loss_ce: 0.093972
2022-01-14 11:42:00,405 iteration 367 : loss : 0.184886, loss_ce: 0.077006
2022-01-14 11:42:01,464 iteration 368 : loss : 0.167909, loss_ce: 0.061136
2022-01-14 11:42:02,558 iteration 369 : loss : 0.196395, loss_ce: 0.063609
2022-01-14 11:42:03,634 iteration 370 : loss : 0.151708, loss_ce: 0.072678
2022-01-14 11:42:04,662 iteration 371 : loss : 0.219919, loss_ce: 0.076915
2022-01-14 11:42:05,694 iteration 372 : loss : 0.245150, loss_ce: 0.126259
2022-01-14 11:42:06,661 iteration 373 : loss : 0.198422, loss_ce: 0.071005
2022-01-14 11:42:07,727 iteration 374 : loss : 0.176283, loss_ce: 0.070628
  6%|█▋                            | 22/400 [06:41<1:57:17, 18.62s/it]2022-01-14 11:42:08,886 iteration 375 : loss : 0.297118, loss_ce: 0.132208
2022-01-14 11:42:09,865 iteration 376 : loss : 0.119006, loss_ce: 0.041694
2022-01-14 11:42:10,875 iteration 377 : loss : 0.154870, loss_ce: 0.053220
2022-01-14 11:42:11,984 iteration 378 : loss : 0.165825, loss_ce: 0.061416
2022-01-14 11:42:12,921 iteration 379 : loss : 0.155292, loss_ce: 0.066390
2022-01-14 11:42:13,981 iteration 380 : loss : 0.149465, loss_ce: 0.055470
2022-01-14 11:42:14,996 iteration 381 : loss : 0.115649, loss_ce: 0.039421
2022-01-14 11:42:15,931 iteration 382 : loss : 0.164482, loss_ce: 0.074137
2022-01-14 11:42:16,945 iteration 383 : loss : 0.190521, loss_ce: 0.078447
2022-01-14 11:42:17,990 iteration 384 : loss : 0.134632, loss_ce: 0.053501
2022-01-14 11:42:19,002 iteration 385 : loss : 0.116137, loss_ce: 0.050005
2022-01-14 11:42:20,023 iteration 386 : loss : 0.161743, loss_ce: 0.054401
2022-01-14 11:42:21,066 iteration 387 : loss : 0.230982, loss_ce: 0.080503
2022-01-14 11:42:22,123 iteration 388 : loss : 0.188174, loss_ce: 0.075621
2022-01-14 11:42:23,176 iteration 389 : loss : 0.265796, loss_ce: 0.130280
2022-01-14 11:42:24,173 iteration 390 : loss : 0.146232, loss_ce: 0.063039
2022-01-14 11:42:25,167 iteration 391 : loss : 0.244061, loss_ce: 0.144209
  6%|█▋                            | 23/400 [06:59<1:54:42, 18.26s/it]2022-01-14 11:42:26,277 iteration 392 : loss : 0.172163, loss_ce: 0.102521
2022-01-14 11:42:27,257 iteration 393 : loss : 0.146815, loss_ce: 0.052814
2022-01-14 11:42:28,325 iteration 394 : loss : 0.131287, loss_ce: 0.046842
2022-01-14 11:42:29,386 iteration 395 : loss : 0.169234, loss_ce: 0.076224
2022-01-14 11:42:30,381 iteration 396 : loss : 0.162739, loss_ce: 0.059922
2022-01-14 11:42:31,394 iteration 397 : loss : 0.175358, loss_ce: 0.076974
2022-01-14 11:42:32,414 iteration 398 : loss : 0.133940, loss_ce: 0.054158
2022-01-14 11:42:33,312 iteration 399 : loss : 0.180848, loss_ce: 0.073208
2022-01-14 11:42:34,318 iteration 400 : loss : 0.168636, loss_ce: 0.061589
2022-01-14 11:42:35,378 iteration 401 : loss : 0.182313, loss_ce: 0.083612
2022-01-14 11:42:36,357 iteration 402 : loss : 0.125400, loss_ce: 0.055597
2022-01-14 11:42:37,332 iteration 403 : loss : 0.144595, loss_ce: 0.056212
2022-01-14 11:42:38,363 iteration 404 : loss : 0.177477, loss_ce: 0.081233
2022-01-14 11:42:39,441 iteration 405 : loss : 0.170657, loss_ce: 0.069642
2022-01-14 11:42:40,419 iteration 406 : loss : 0.171887, loss_ce: 0.067423
2022-01-14 11:42:41,367 iteration 407 : loss : 0.168135, loss_ce: 0.064859
2022-01-14 11:42:42,373 iteration 408 : loss : 0.194604, loss_ce: 0.068822
  6%|█▊                            | 24/400 [07:16<1:52:27, 17.95s/it]2022-01-14 11:42:43,509 iteration 409 : loss : 0.165182, loss_ce: 0.085098
2022-01-14 11:42:44,533 iteration 410 : loss : 0.164022, loss_ce: 0.061306
2022-01-14 11:42:45,528 iteration 411 : loss : 0.304119, loss_ce: 0.101394
2022-01-14 11:42:46,435 iteration 412 : loss : 0.141399, loss_ce: 0.052588
2022-01-14 11:42:47,430 iteration 413 : loss : 0.180538, loss_ce: 0.068268
2022-01-14 11:42:48,378 iteration 414 : loss : 0.214641, loss_ce: 0.106691
2022-01-14 11:42:49,274 iteration 415 : loss : 0.124834, loss_ce: 0.048813
2022-01-14 11:42:50,263 iteration 416 : loss : 0.176028, loss_ce: 0.085748
2022-01-14 11:42:51,215 iteration 417 : loss : 0.235593, loss_ce: 0.098399
2022-01-14 11:42:52,268 iteration 418 : loss : 0.162963, loss_ce: 0.071216
2022-01-14 11:42:53,236 iteration 419 : loss : 0.158099, loss_ce: 0.081799
2022-01-14 11:42:54,243 iteration 420 : loss : 0.151568, loss_ce: 0.062516
2022-01-14 11:42:55,188 iteration 421 : loss : 0.185493, loss_ce: 0.078335
2022-01-14 11:42:56,131 iteration 422 : loss : 0.188603, loss_ce: 0.080748
2022-01-14 11:42:57,085 iteration 423 : loss : 0.174774, loss_ce: 0.058396
2022-01-14 11:42:58,094 iteration 424 : loss : 0.162873, loss_ce: 0.077335
2022-01-14 11:42:58,095 Training Data Eval:
2022-01-14 11:43:02,909   Average segmentation loss on training set: 0.1491
2022-01-14 11:43:02,909 Validation Data Eval:
2022-01-14 11:43:04,526   Average segmentation loss on validation set: 0.1731
2022-01-14 11:43:05,816 Found new lowest validation loss at iteration 424! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_1BLOCK_best_val_loss_seed1234.pth
2022-01-14 11:43:06,809 iteration 425 : loss : 0.197601, loss_ce: 0.074248
  6%|█▉                            | 25/400 [07:40<2:04:19, 19.89s/it]2022-01-14 11:43:07,811 iteration 426 : loss : 0.140222, loss_ce: 0.045460
2022-01-14 11:43:08,843 iteration 427 : loss : 0.155035, loss_ce: 0.051276
2022-01-14 11:43:09,841 iteration 428 : loss : 0.220613, loss_ce: 0.085595
2022-01-14 11:43:10,788 iteration 429 : loss : 0.219777, loss_ce: 0.119613
2022-01-14 11:43:11,730 iteration 430 : loss : 0.170421, loss_ce: 0.064118
2022-01-14 11:43:12,696 iteration 431 : loss : 0.274642, loss_ce: 0.115164
2022-01-14 11:43:13,721 iteration 432 : loss : 0.141996, loss_ce: 0.054667
2022-01-14 11:43:14,778 iteration 433 : loss : 0.135541, loss_ce: 0.056821
2022-01-14 11:43:15,780 iteration 434 : loss : 0.136727, loss_ce: 0.056318
2022-01-14 11:43:16,718 iteration 435 : loss : 0.148088, loss_ce: 0.068076
2022-01-14 11:43:17,690 iteration 436 : loss : 0.136367, loss_ce: 0.061522
2022-01-14 11:43:18,667 iteration 437 : loss : 0.260019, loss_ce: 0.141419
2022-01-14 11:43:19,595 iteration 438 : loss : 0.185128, loss_ce: 0.072334
2022-01-14 11:43:20,591 iteration 439 : loss : 0.177139, loss_ce: 0.057692
2022-01-14 11:43:21,563 iteration 440 : loss : 0.215483, loss_ce: 0.084424
2022-01-14 11:43:22,600 iteration 441 : loss : 0.170550, loss_ce: 0.070199
2022-01-14 11:43:23,620 iteration 442 : loss : 0.154255, loss_ce: 0.073209
  6%|█▉                            | 26/400 [07:57<1:58:14, 18.97s/it]2022-01-14 11:43:24,658 iteration 443 : loss : 0.191537, loss_ce: 0.093236
2022-01-14 11:43:25,602 iteration 444 : loss : 0.150896, loss_ce: 0.062135
2022-01-14 11:43:26,584 iteration 445 : loss : 0.196698, loss_ce: 0.069775
2022-01-14 11:43:27,703 iteration 446 : loss : 0.162639, loss_ce: 0.067201
2022-01-14 11:43:28,759 iteration 447 : loss : 0.157019, loss_ce: 0.079419
2022-01-14 11:43:29,798 iteration 448 : loss : 0.280612, loss_ce: 0.091782
2022-01-14 11:43:30,810 iteration 449 : loss : 0.186959, loss_ce: 0.091532
2022-01-14 11:43:31,789 iteration 450 : loss : 0.158292, loss_ce: 0.058326
2022-01-14 11:43:32,870 iteration 451 : loss : 0.100744, loss_ce: 0.039605
2022-01-14 11:43:33,907 iteration 452 : loss : 0.138639, loss_ce: 0.061175
2022-01-14 11:43:34,931 iteration 453 : loss : 0.191966, loss_ce: 0.077839
2022-01-14 11:43:35,955 iteration 454 : loss : 0.182864, loss_ce: 0.065962
2022-01-14 11:43:37,011 iteration 455 : loss : 0.134796, loss_ce: 0.051118
2022-01-14 11:43:38,069 iteration 456 : loss : 0.161050, loss_ce: 0.052662
2022-01-14 11:43:39,084 iteration 457 : loss : 0.171469, loss_ce: 0.068575
2022-01-14 11:43:40,161 iteration 458 : loss : 0.202370, loss_ce: 0.093028
2022-01-14 11:43:41,100 iteration 459 : loss : 0.148543, loss_ce: 0.055886
  7%|██                            | 27/400 [08:15<1:55:08, 18.52s/it]2022-01-14 11:43:42,173 iteration 460 : loss : 0.201971, loss_ce: 0.104906
2022-01-14 11:43:43,191 iteration 461 : loss : 0.170536, loss_ce: 0.084626
2022-01-14 11:43:44,178 iteration 462 : loss : 0.211048, loss_ce: 0.090617
2022-01-14 11:43:45,240 iteration 463 : loss : 0.154504, loss_ce: 0.067893
2022-01-14 11:43:46,251 iteration 464 : loss : 0.146449, loss_ce: 0.057186
2022-01-14 11:43:47,209 iteration 465 : loss : 0.149843, loss_ce: 0.047145
2022-01-14 11:43:48,203 iteration 466 : loss : 0.131676, loss_ce: 0.045696
2022-01-14 11:43:49,180 iteration 467 : loss : 0.152674, loss_ce: 0.054492
2022-01-14 11:43:50,305 iteration 468 : loss : 0.188517, loss_ce: 0.087655
2022-01-14 11:43:51,290 iteration 469 : loss : 0.166462, loss_ce: 0.056800
2022-01-14 11:43:52,292 iteration 470 : loss : 0.184458, loss_ce: 0.067832
2022-01-14 11:43:53,285 iteration 471 : loss : 0.178842, loss_ce: 0.060867
2022-01-14 11:43:54,334 iteration 472 : loss : 0.177288, loss_ce: 0.068543
2022-01-14 11:43:55,474 iteration 473 : loss : 0.196050, loss_ce: 0.086418
2022-01-14 11:43:56,566 iteration 474 : loss : 0.212209, loss_ce: 0.097757
2022-01-14 11:43:57,547 iteration 475 : loss : 0.123034, loss_ce: 0.046504
2022-01-14 11:43:58,613 iteration 476 : loss : 0.204187, loss_ce: 0.104785
  7%|██                            | 28/400 [08:32<1:52:57, 18.22s/it]2022-01-14 11:43:59,670 iteration 477 : loss : 0.175982, loss_ce: 0.060441
2022-01-14 11:44:00,716 iteration 478 : loss : 0.116245, loss_ce: 0.040835
2022-01-14 11:44:01,711 iteration 479 : loss : 0.163346, loss_ce: 0.076478
2022-01-14 11:44:02,730 iteration 480 : loss : 0.158127, loss_ce: 0.074655
2022-01-14 11:44:03,652 iteration 481 : loss : 0.177619, loss_ce: 0.075465
2022-01-14 11:44:04,664 iteration 482 : loss : 0.164057, loss_ce: 0.042329
2022-01-14 11:44:05,691 iteration 483 : loss : 0.189469, loss_ce: 0.063434
2022-01-14 11:44:06,742 iteration 484 : loss : 0.214435, loss_ce: 0.102329
2022-01-14 11:44:07,730 iteration 485 : loss : 0.128734, loss_ce: 0.054178
2022-01-14 11:44:08,708 iteration 486 : loss : 0.184649, loss_ce: 0.056742
2022-01-14 11:44:09,766 iteration 487 : loss : 0.135182, loss_ce: 0.051978
2022-01-14 11:44:10,710 iteration 488 : loss : 0.135984, loss_ce: 0.056340
2022-01-14 11:44:11,711 iteration 489 : loss : 0.169548, loss_ce: 0.073875
2022-01-14 11:44:12,610 iteration 490 : loss : 0.165472, loss_ce: 0.067913
2022-01-14 11:44:13,618 iteration 491 : loss : 0.172896, loss_ce: 0.072561
2022-01-14 11:44:14,603 iteration 492 : loss : 0.133949, loss_ce: 0.062275
2022-01-14 11:44:15,633 iteration 493 : loss : 0.173324, loss_ce: 0.083782
  7%|██▏                           | 29/400 [08:49<1:50:25, 17.86s/it]2022-01-14 11:44:16,698 iteration 494 : loss : 0.149302, loss_ce: 0.067100
2022-01-14 11:44:17,743 iteration 495 : loss : 0.172028, loss_ce: 0.062684
2022-01-14 11:44:18,731 iteration 496 : loss : 0.241367, loss_ce: 0.121315
2022-01-14 11:44:19,754 iteration 497 : loss : 0.143055, loss_ce: 0.063896
2022-01-14 11:44:20,875 iteration 498 : loss : 0.195713, loss_ce: 0.091406
2022-01-14 11:44:21,813 iteration 499 : loss : 0.119165, loss_ce: 0.052543
2022-01-14 11:44:22,765 iteration 500 : loss : 0.162068, loss_ce: 0.061962
2022-01-14 11:44:23,716 iteration 501 : loss : 0.156708, loss_ce: 0.065915
2022-01-14 11:44:24,780 iteration 502 : loss : 0.134102, loss_ce: 0.054303
2022-01-14 11:44:25,748 iteration 503 : loss : 0.160009, loss_ce: 0.053537
2022-01-14 11:44:26,778 iteration 504 : loss : 0.139167, loss_ce: 0.050942
2022-01-14 11:44:27,732 iteration 505 : loss : 0.122655, loss_ce: 0.044044
2022-01-14 11:44:28,819 iteration 506 : loss : 0.161141, loss_ce: 0.066214
2022-01-14 11:44:29,825 iteration 507 : loss : 0.212745, loss_ce: 0.083823
2022-01-14 11:44:30,830 iteration 508 : loss : 0.193754, loss_ce: 0.083964
2022-01-14 11:44:31,874 iteration 509 : loss : 0.144024, loss_ce: 0.055434
2022-01-14 11:44:31,874 Training Data Eval:
2022-01-14 11:44:36,684   Average segmentation loss on training set: 0.1118
2022-01-14 11:44:36,684 Validation Data Eval:
2022-01-14 11:44:38,301   Average segmentation loss on validation set: 0.1538
2022-01-14 11:44:39,487 Found new lowest validation loss at iteration 509! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_1BLOCK_best_val_loss_seed1234.pth
2022-01-14 11:44:40,518 iteration 510 : loss : 0.122153, loss_ce: 0.060505
  8%|██▎                           | 30/400 [09:14<2:03:06, 19.96s/it]2022-01-14 11:44:41,588 iteration 511 : loss : 0.224864, loss_ce: 0.105166
2022-01-14 11:44:42,543 iteration 512 : loss : 0.198710, loss_ce: 0.086412
2022-01-14 11:44:43,514 iteration 513 : loss : 0.106176, loss_ce: 0.035472
2022-01-14 11:44:44,506 iteration 514 : loss : 0.129653, loss_ce: 0.053400
2022-01-14 11:44:45,484 iteration 515 : loss : 0.168649, loss_ce: 0.065236
2022-01-14 11:44:46,511 iteration 516 : loss : 0.113098, loss_ce: 0.043922
2022-01-14 11:44:47,565 iteration 517 : loss : 0.200003, loss_ce: 0.097040
2022-01-14 11:44:48,514 iteration 518 : loss : 0.135180, loss_ce: 0.050135
2022-01-14 11:44:49,513 iteration 519 : loss : 0.150875, loss_ce: 0.067413
2022-01-14 11:44:50,459 iteration 520 : loss : 0.119104, loss_ce: 0.047330
2022-01-14 11:44:51,453 iteration 521 : loss : 0.139540, loss_ce: 0.048199
2022-01-14 11:44:52,486 iteration 522 : loss : 0.120834, loss_ce: 0.043905
2022-01-14 11:44:53,556 iteration 523 : loss : 0.125491, loss_ce: 0.053587
2022-01-14 11:44:54,658 iteration 524 : loss : 0.130474, loss_ce: 0.050151
2022-01-14 11:44:55,659 iteration 525 : loss : 0.177952, loss_ce: 0.080448
2022-01-14 11:44:56,656 iteration 526 : loss : 0.142038, loss_ce: 0.061580
2022-01-14 11:44:57,651 iteration 527 : loss : 0.157128, loss_ce: 0.054299
  8%|██▎                           | 31/400 [09:31<1:57:34, 19.12s/it]2022-01-14 11:44:58,677 iteration 528 : loss : 0.142791, loss_ce: 0.061742
2022-01-14 11:44:59,684 iteration 529 : loss : 0.182644, loss_ce: 0.058675
2022-01-14 11:45:00,645 iteration 530 : loss : 0.152120, loss_ce: 0.061990
2022-01-14 11:45:01,586 iteration 531 : loss : 0.157761, loss_ce: 0.054372
2022-01-14 11:45:02,548 iteration 532 : loss : 0.139891, loss_ce: 0.065636
2022-01-14 11:45:03,645 iteration 533 : loss : 0.127250, loss_ce: 0.047776
2022-01-14 11:45:04,602 iteration 534 : loss : 0.128485, loss_ce: 0.056425
2022-01-14 11:45:05,647 iteration 535 : loss : 0.118654, loss_ce: 0.046455
2022-01-14 11:45:06,725 iteration 536 : loss : 0.195374, loss_ce: 0.096027
2022-01-14 11:45:07,822 iteration 537 : loss : 0.175831, loss_ce: 0.059844
2022-01-14 11:45:08,848 iteration 538 : loss : 0.149701, loss_ce: 0.068363
2022-01-14 11:45:09,836 iteration 539 : loss : 0.164650, loss_ce: 0.074661
2022-01-14 11:45:10,857 iteration 540 : loss : 0.157987, loss_ce: 0.054220
2022-01-14 11:45:11,836 iteration 541 : loss : 0.146745, loss_ce: 0.065648
2022-01-14 11:45:12,833 iteration 542 : loss : 0.196326, loss_ce: 0.093789
2022-01-14 11:45:13,778 iteration 543 : loss : 0.123699, loss_ce: 0.052113
2022-01-14 11:45:14,781 iteration 544 : loss : 0.154075, loss_ce: 0.059678
  8%|██▍                           | 32/400 [09:48<1:53:35, 18.52s/it]2022-01-14 11:45:15,855 iteration 545 : loss : 0.126370, loss_ce: 0.060256
2022-01-14 11:45:16,849 iteration 546 : loss : 0.142381, loss_ce: 0.050881
2022-01-14 11:45:17,842 iteration 547 : loss : 0.148311, loss_ce: 0.060231
2022-01-14 11:45:18,826 iteration 548 : loss : 0.197190, loss_ce: 0.076991
2022-01-14 11:45:19,842 iteration 549 : loss : 0.174288, loss_ce: 0.075017
2022-01-14 11:45:20,808 iteration 550 : loss : 0.137428, loss_ce: 0.062898
2022-01-14 11:45:21,796 iteration 551 : loss : 0.147148, loss_ce: 0.068281
2022-01-14 11:45:22,762 iteration 552 : loss : 0.162052, loss_ce: 0.073555
2022-01-14 11:45:23,792 iteration 553 : loss : 0.189292, loss_ce: 0.072266
2022-01-14 11:45:24,730 iteration 554 : loss : 0.126393, loss_ce: 0.068341
2022-01-14 11:45:25,723 iteration 555 : loss : 0.119292, loss_ce: 0.037866
2022-01-14 11:45:26,766 iteration 556 : loss : 0.162927, loss_ce: 0.072013
2022-01-14 11:45:27,685 iteration 557 : loss : 0.164359, loss_ce: 0.055753
2022-01-14 11:45:28,716 iteration 558 : loss : 0.150775, loss_ce: 0.041417
2022-01-14 11:45:29,705 iteration 559 : loss : 0.149012, loss_ce: 0.055030
2022-01-14 11:45:30,717 iteration 560 : loss : 0.179580, loss_ce: 0.047626
2022-01-14 11:45:31,752 iteration 561 : loss : 0.191560, loss_ce: 0.095424
  8%|██▍                           | 33/400 [10:05<1:50:27, 18.06s/it]2022-01-14 11:45:32,926 iteration 562 : loss : 0.181488, loss_ce: 0.091045
2022-01-14 11:45:33,835 iteration 563 : loss : 0.127579, loss_ce: 0.057943
2022-01-14 11:45:34,855 iteration 564 : loss : 0.146170, loss_ce: 0.068522
2022-01-14 11:45:35,875 iteration 565 : loss : 0.137962, loss_ce: 0.057428
2022-01-14 11:45:36,925 iteration 566 : loss : 0.128495, loss_ce: 0.056606
2022-01-14 11:45:37,899 iteration 567 : loss : 0.124506, loss_ce: 0.044905
2022-01-14 11:45:38,864 iteration 568 : loss : 0.198453, loss_ce: 0.073382
2022-01-14 11:45:39,855 iteration 569 : loss : 0.175992, loss_ce: 0.071245
2022-01-14 11:45:40,884 iteration 570 : loss : 0.113789, loss_ce: 0.054886
2022-01-14 11:45:41,858 iteration 571 : loss : 0.219940, loss_ce: 0.095712
2022-01-14 11:45:42,871 iteration 572 : loss : 0.112836, loss_ce: 0.038275
2022-01-14 11:45:43,842 iteration 573 : loss : 0.110545, loss_ce: 0.042951
2022-01-14 11:45:44,845 iteration 574 : loss : 0.180216, loss_ce: 0.077052
2022-01-14 11:45:45,903 iteration 575 : loss : 0.141134, loss_ce: 0.047251
2022-01-14 11:45:46,943 iteration 576 : loss : 0.139526, loss_ce: 0.061970
2022-01-14 11:45:47,942 iteration 577 : loss : 0.117798, loss_ce: 0.049616
2022-01-14 11:45:48,896 iteration 578 : loss : 0.145995, loss_ce: 0.063336
  8%|██▌                           | 34/400 [10:22<1:48:27, 17.78s/it]2022-01-14 11:45:50,125 iteration 579 : loss : 0.149070, loss_ce: 0.057759
2022-01-14 11:45:51,152 iteration 580 : loss : 0.172414, loss_ce: 0.068432
2022-01-14 11:45:52,204 iteration 581 : loss : 0.182233, loss_ce: 0.058562
2022-01-14 11:45:53,195 iteration 582 : loss : 0.130944, loss_ce: 0.051642
2022-01-14 11:45:54,201 iteration 583 : loss : 0.225185, loss_ce: 0.074464
2022-01-14 11:45:55,168 iteration 584 : loss : 0.109382, loss_ce: 0.046808
2022-01-14 11:45:56,217 iteration 585 : loss : 0.141362, loss_ce: 0.055298
2022-01-14 11:45:57,176 iteration 586 : loss : 0.176918, loss_ce: 0.066310
2022-01-14 11:45:58,129 iteration 587 : loss : 0.132021, loss_ce: 0.059100
2022-01-14 11:45:59,151 iteration 588 : loss : 0.130017, loss_ce: 0.046945
2022-01-14 11:46:00,135 iteration 589 : loss : 0.119549, loss_ce: 0.045473
2022-01-14 11:46:01,135 iteration 590 : loss : 0.136913, loss_ce: 0.048668
2022-01-14 11:46:02,142 iteration 591 : loss : 0.147140, loss_ce: 0.054207
2022-01-14 11:46:03,148 iteration 592 : loss : 0.121990, loss_ce: 0.048815
2022-01-14 11:46:04,183 iteration 593 : loss : 0.095172, loss_ce: 0.037256
2022-01-14 11:46:05,194 iteration 594 : loss : 0.125998, loss_ce: 0.051093
2022-01-14 11:46:05,194 Training Data Eval:
2022-01-14 11:46:10,003   Average segmentation loss on training set: 0.3188
2022-01-14 11:46:10,003 Validation Data Eval:
2022-01-14 11:46:11,623   Average segmentation loss on validation set: 0.2804
2022-01-14 11:46:12,679 iteration 595 : loss : 0.197849, loss_ce: 0.102967
  9%|██▋                           | 35/400 [10:46<1:59:07, 19.58s/it]2022-01-14 11:46:13,739 iteration 596 : loss : 0.118870, loss_ce: 0.047330
2022-01-14 11:46:14,707 iteration 597 : loss : 0.168162, loss_ce: 0.058002
2022-01-14 11:46:15,674 iteration 598 : loss : 0.115538, loss_ce: 0.043414
2022-01-14 11:46:16,659 iteration 599 : loss : 0.130202, loss_ce: 0.050786
2022-01-14 11:46:17,639 iteration 600 : loss : 0.144942, loss_ce: 0.068334
2022-01-14 11:46:18,645 iteration 601 : loss : 0.122282, loss_ce: 0.042936
2022-01-14 11:46:19,665 iteration 602 : loss : 0.137218, loss_ce: 0.057599
2022-01-14 11:46:20,595 iteration 603 : loss : 0.165678, loss_ce: 0.053757
2022-01-14 11:46:21,541 iteration 604 : loss : 0.103817, loss_ce: 0.040607
2022-01-14 11:46:22,471 iteration 605 : loss : 0.115082, loss_ce: 0.041639
2022-01-14 11:46:23,594 iteration 606 : loss : 0.105011, loss_ce: 0.044755
2022-01-14 11:46:24,581 iteration 607 : loss : 0.171504, loss_ce: 0.064958
2022-01-14 11:46:25,576 iteration 608 : loss : 0.150956, loss_ce: 0.069577
2022-01-14 11:46:26,493 iteration 609 : loss : 0.137592, loss_ce: 0.061578
2022-01-14 11:46:27,532 iteration 610 : loss : 0.104901, loss_ce: 0.043399
2022-01-14 11:46:28,625 iteration 611 : loss : 0.169934, loss_ce: 0.078036
2022-01-14 11:46:29,644 iteration 612 : loss : 0.089130, loss_ce: 0.029664
  9%|██▋                           | 36/400 [11:03<1:54:02, 18.80s/it]2022-01-14 11:46:30,729 iteration 613 : loss : 0.121232, loss_ce: 0.048107
2022-01-14 11:46:31,690 iteration 614 : loss : 0.138336, loss_ce: 0.047253
2022-01-14 11:46:32,647 iteration 615 : loss : 0.209719, loss_ce: 0.098700
2022-01-14 11:46:33,722 iteration 616 : loss : 0.145058, loss_ce: 0.065989
2022-01-14 11:46:34,685 iteration 617 : loss : 0.141922, loss_ce: 0.068910
2022-01-14 11:46:35,694 iteration 618 : loss : 0.169390, loss_ce: 0.046896
2022-01-14 11:46:36,702 iteration 619 : loss : 0.231585, loss_ce: 0.105584
2022-01-14 11:46:37,839 iteration 620 : loss : 0.213360, loss_ce: 0.065329
2022-01-14 11:46:38,865 iteration 621 : loss : 0.131207, loss_ce: 0.046578
2022-01-14 11:46:39,989 iteration 622 : loss : 0.141956, loss_ce: 0.054208
2022-01-14 11:46:41,089 iteration 623 : loss : 0.177432, loss_ce: 0.088544
2022-01-14 11:46:42,080 iteration 624 : loss : 0.148080, loss_ce: 0.048845
2022-01-14 11:46:43,037 iteration 625 : loss : 0.122589, loss_ce: 0.051662
2022-01-14 11:46:44,091 iteration 626 : loss : 0.115165, loss_ce: 0.050350
2022-01-14 11:46:45,147 iteration 627 : loss : 0.176282, loss_ce: 0.070911
2022-01-14 11:46:46,244 iteration 628 : loss : 0.158147, loss_ce: 0.058179
2022-01-14 11:46:47,234 iteration 629 : loss : 0.105728, loss_ce: 0.043116
  9%|██▊                           | 37/400 [11:21<1:51:32, 18.44s/it]2022-01-14 11:46:48,325 iteration 630 : loss : 0.090348, loss_ce: 0.039929
2022-01-14 11:46:49,303 iteration 631 : loss : 0.090238, loss_ce: 0.039864
2022-01-14 11:46:50,285 iteration 632 : loss : 0.151295, loss_ce: 0.061195
2022-01-14 11:46:51,369 iteration 633 : loss : 0.136176, loss_ce: 0.054810
2022-01-14 11:46:52,377 iteration 634 : loss : 0.172854, loss_ce: 0.068357
2022-01-14 11:46:53,475 iteration 635 : loss : 0.141345, loss_ce: 0.056250
2022-01-14 11:46:54,497 iteration 636 : loss : 0.148536, loss_ce: 0.058969
2022-01-14 11:46:55,434 iteration 637 : loss : 0.160762, loss_ce: 0.065667
2022-01-14 11:46:56,510 iteration 638 : loss : 0.191743, loss_ce: 0.053554
2022-01-14 11:46:57,475 iteration 639 : loss : 0.122584, loss_ce: 0.054242
2022-01-14 11:46:58,414 iteration 640 : loss : 0.157580, loss_ce: 0.044061
2022-01-14 11:46:59,357 iteration 641 : loss : 0.162174, loss_ce: 0.065926
2022-01-14 11:47:00,310 iteration 642 : loss : 0.139189, loss_ce: 0.034214
2022-01-14 11:47:01,295 iteration 643 : loss : 0.155407, loss_ce: 0.060638
2022-01-14 11:47:02,290 iteration 644 : loss : 0.127484, loss_ce: 0.054267
2022-01-14 11:47:03,248 iteration 645 : loss : 0.139281, loss_ce: 0.045335
2022-01-14 11:47:04,312 iteration 646 : loss : 0.138799, loss_ce: 0.060921
 10%|██▊                           | 38/400 [11:38<1:48:45, 18.03s/it]2022-01-14 11:47:05,347 iteration 647 : loss : 0.175438, loss_ce: 0.078244
2022-01-14 11:47:06,346 iteration 648 : loss : 0.134854, loss_ce: 0.058855
2022-01-14 11:47:07,373 iteration 649 : loss : 0.118678, loss_ce: 0.048108
2022-01-14 11:47:08,447 iteration 650 : loss : 0.156584, loss_ce: 0.061954
2022-01-14 11:47:09,450 iteration 651 : loss : 0.089874, loss_ce: 0.037533
2022-01-14 11:47:10,351 iteration 652 : loss : 0.086925, loss_ce: 0.032269
2022-01-14 11:47:11,425 iteration 653 : loss : 0.146133, loss_ce: 0.056678
2022-01-14 11:47:12,415 iteration 654 : loss : 0.122092, loss_ce: 0.047551
2022-01-14 11:47:13,414 iteration 655 : loss : 0.173637, loss_ce: 0.063016
2022-01-14 11:47:14,421 iteration 656 : loss : 0.144495, loss_ce: 0.056532
2022-01-14 11:47:15,494 iteration 657 : loss : 0.082524, loss_ce: 0.031931
2022-01-14 11:47:16,524 iteration 658 : loss : 0.143259, loss_ce: 0.043475
2022-01-14 11:47:17,564 iteration 659 : loss : 0.161182, loss_ce: 0.071742
2022-01-14 11:47:18,542 iteration 660 : loss : 0.119990, loss_ce: 0.051061
2022-01-14 11:47:19,577 iteration 661 : loss : 0.125109, loss_ce: 0.048465
2022-01-14 11:47:20,679 iteration 662 : loss : 0.192156, loss_ce: 0.049805
2022-01-14 11:47:21,684 iteration 663 : loss : 0.122920, loss_ce: 0.053720
 10%|██▉                           | 39/400 [11:55<1:47:16, 17.83s/it]2022-01-14 11:47:22,767 iteration 664 : loss : 0.123541, loss_ce: 0.058396
2022-01-14 11:47:23,695 iteration 665 : loss : 0.162521, loss_ce: 0.071015
2022-01-14 11:47:24,684 iteration 666 : loss : 0.091224, loss_ce: 0.034138
2022-01-14 11:47:25,716 iteration 667 : loss : 0.089431, loss_ce: 0.038786
2022-01-14 11:47:26,737 iteration 668 : loss : 0.152691, loss_ce: 0.055716
2022-01-14 11:47:27,717 iteration 669 : loss : 0.112764, loss_ce: 0.046261
2022-01-14 11:47:28,843 iteration 670 : loss : 0.111350, loss_ce: 0.037848
2022-01-14 11:47:29,826 iteration 671 : loss : 0.176590, loss_ce: 0.059473
2022-01-14 11:47:30,897 iteration 672 : loss : 0.137381, loss_ce: 0.047688
2022-01-14 11:47:31,944 iteration 673 : loss : 0.112361, loss_ce: 0.042828
2022-01-14 11:47:32,977 iteration 674 : loss : 0.114092, loss_ce: 0.049796
2022-01-14 11:47:34,038 iteration 675 : loss : 0.137636, loss_ce: 0.053033
2022-01-14 11:47:35,031 iteration 676 : loss : 0.118255, loss_ce: 0.043718
2022-01-14 11:47:36,041 iteration 677 : loss : 0.092479, loss_ce: 0.040433
2022-01-14 11:47:37,078 iteration 678 : loss : 0.158374, loss_ce: 0.054517
2022-01-14 11:47:38,090 iteration 679 : loss : 0.131293, loss_ce: 0.062551
2022-01-14 11:47:38,090 Training Data Eval:
2022-01-14 11:47:42,906   Average segmentation loss on training set: 0.1011
2022-01-14 11:47:42,906 Validation Data Eval:
2022-01-14 11:47:44,523   Average segmentation loss on validation set: 0.1442
2022-01-14 11:47:45,768 Found new lowest validation loss at iteration 679! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_1BLOCK_best_val_loss_seed1234.pth
2022-01-14 11:47:46,778 iteration 680 : loss : 0.116975, loss_ce: 0.044589
 10%|███                           | 40/400 [12:20<2:00:04, 20.01s/it]2022-01-14 11:47:47,861 iteration 681 : loss : 0.086488, loss_ce: 0.034424
2022-01-14 11:47:48,788 iteration 682 : loss : 0.167674, loss_ce: 0.052880
2022-01-14 11:47:49,788 iteration 683 : loss : 0.127258, loss_ce: 0.056799
2022-01-14 11:47:50,748 iteration 684 : loss : 0.095414, loss_ce: 0.031750
2022-01-14 11:47:51,807 iteration 685 : loss : 0.103713, loss_ce: 0.039643
2022-01-14 11:47:52,807 iteration 686 : loss : 0.150698, loss_ce: 0.054658
2022-01-14 11:47:53,803 iteration 687 : loss : 0.109085, loss_ce: 0.047167
2022-01-14 11:47:54,780 iteration 688 : loss : 0.106643, loss_ce: 0.040183
2022-01-14 11:47:55,814 iteration 689 : loss : 0.095197, loss_ce: 0.039075
2022-01-14 11:47:56,806 iteration 690 : loss : 0.104820, loss_ce: 0.038109
2022-01-14 11:47:57,814 iteration 691 : loss : 0.122221, loss_ce: 0.049339
2022-01-14 11:47:58,874 iteration 692 : loss : 0.107203, loss_ce: 0.036686
2022-01-14 11:47:59,817 iteration 693 : loss : 0.096556, loss_ce: 0.042685
2022-01-14 11:48:00,827 iteration 694 : loss : 0.112674, loss_ce: 0.048045
2022-01-14 11:48:01,788 iteration 695 : loss : 0.144065, loss_ce: 0.066754
2022-01-14 11:48:02,849 iteration 696 : loss : 0.119434, loss_ce: 0.056403
2022-01-14 11:48:03,849 iteration 697 : loss : 0.106104, loss_ce: 0.044226
 10%|███                           | 41/400 [12:37<1:54:27, 19.13s/it]2022-01-14 11:48:04,877 iteration 698 : loss : 0.124062, loss_ce: 0.038922
2022-01-14 11:48:05,918 iteration 699 : loss : 0.134869, loss_ce: 0.057925
2022-01-14 11:48:06,902 iteration 700 : loss : 0.122120, loss_ce: 0.054879
2022-01-14 11:48:07,879 iteration 701 : loss : 0.153623, loss_ce: 0.076141
2022-01-14 11:48:08,948 iteration 702 : loss : 0.126069, loss_ce: 0.045436
2022-01-14 11:48:10,032 iteration 703 : loss : 0.094364, loss_ce: 0.043908
2022-01-14 11:48:10,970 iteration 704 : loss : 0.098404, loss_ce: 0.038938
2022-01-14 11:48:11,966 iteration 705 : loss : 0.108653, loss_ce: 0.040183
2022-01-14 11:48:12,980 iteration 706 : loss : 0.094986, loss_ce: 0.035125
2022-01-14 11:48:13,917 iteration 707 : loss : 0.080547, loss_ce: 0.035040
2022-01-14 11:48:14,914 iteration 708 : loss : 0.084170, loss_ce: 0.030190
2022-01-14 11:48:15,913 iteration 709 : loss : 0.117848, loss_ce: 0.050284
2022-01-14 11:48:16,945 iteration 710 : loss : 0.096560, loss_ce: 0.036670
2022-01-14 11:48:17,968 iteration 711 : loss : 0.118516, loss_ce: 0.052903
2022-01-14 11:48:19,055 iteration 712 : loss : 0.082534, loss_ce: 0.029554
2022-01-14 11:48:20,049 iteration 713 : loss : 0.095579, loss_ce: 0.041282
2022-01-14 11:48:21,118 iteration 714 : loss : 0.117230, loss_ce: 0.039077
 10%|███▏                          | 42/400 [12:55<1:50:48, 18.57s/it]2022-01-14 11:48:22,226 iteration 715 : loss : 0.101334, loss_ce: 0.037182
2022-01-14 11:48:23,275 iteration 716 : loss : 0.085843, loss_ce: 0.036300
2022-01-14 11:48:24,277 iteration 717 : loss : 0.123881, loss_ce: 0.042160
2022-01-14 11:48:25,292 iteration 718 : loss : 0.115578, loss_ce: 0.052582
2022-01-14 11:48:26,358 iteration 719 : loss : 0.112954, loss_ce: 0.042643
2022-01-14 11:48:27,366 iteration 720 : loss : 0.096842, loss_ce: 0.035482
2022-01-14 11:48:28,365 iteration 721 : loss : 0.139413, loss_ce: 0.046435
2022-01-14 11:48:29,351 iteration 722 : loss : 0.127138, loss_ce: 0.042680
2022-01-14 11:48:30,390 iteration 723 : loss : 0.128682, loss_ce: 0.057855
2022-01-14 11:48:31,367 iteration 724 : loss : 0.163437, loss_ce: 0.088523
2022-01-14 11:48:32,427 iteration 725 : loss : 0.104897, loss_ce: 0.041092
2022-01-14 11:48:33,421 iteration 726 : loss : 0.131860, loss_ce: 0.054861
2022-01-14 11:48:34,352 iteration 727 : loss : 0.089257, loss_ce: 0.035589
2022-01-14 11:48:35,384 iteration 728 : loss : 0.101915, loss_ce: 0.044577
2022-01-14 11:48:36,437 iteration 729 : loss : 0.072380, loss_ce: 0.031215
2022-01-14 11:48:37,459 iteration 730 : loss : 0.097452, loss_ce: 0.038419
2022-01-14 11:48:38,375 iteration 731 : loss : 0.085988, loss_ce: 0.034698
 11%|███▏                          | 43/400 [13:12<1:48:09, 18.18s/it]2022-01-14 11:48:39,373 iteration 732 : loss : 0.117558, loss_ce: 0.053152
2022-01-14 11:48:40,296 iteration 733 : loss : 0.131702, loss_ce: 0.071603
2022-01-14 11:48:41,335 iteration 734 : loss : 0.107195, loss_ce: 0.042650
2022-01-14 11:48:42,319 iteration 735 : loss : 0.111321, loss_ce: 0.043769
2022-01-14 11:48:43,282 iteration 736 : loss : 0.110274, loss_ce: 0.046057
2022-01-14 11:48:44,393 iteration 737 : loss : 0.106954, loss_ce: 0.055271
2022-01-14 11:48:45,309 iteration 738 : loss : 0.117719, loss_ce: 0.063416
2022-01-14 11:48:46,335 iteration 739 : loss : 0.117539, loss_ce: 0.037395
2022-01-14 11:48:47,314 iteration 740 : loss : 0.095338, loss_ce: 0.035385
2022-01-14 11:48:48,279 iteration 741 : loss : 0.101828, loss_ce: 0.038780
2022-01-14 11:48:49,201 iteration 742 : loss : 0.131398, loss_ce: 0.058874
2022-01-14 11:48:50,207 iteration 743 : loss : 0.104775, loss_ce: 0.037726
2022-01-14 11:48:51,242 iteration 744 : loss : 0.121349, loss_ce: 0.052533
2022-01-14 11:48:52,221 iteration 745 : loss : 0.151375, loss_ce: 0.030329
2022-01-14 11:48:53,186 iteration 746 : loss : 0.106966, loss_ce: 0.041729
2022-01-14 11:48:54,147 iteration 747 : loss : 0.145724, loss_ce: 0.066036
2022-01-14 11:48:55,094 iteration 748 : loss : 0.100399, loss_ce: 0.045015
 11%|███▎                          | 44/400 [13:29<1:45:15, 17.74s/it]2022-01-14 11:48:56,086 iteration 749 : loss : 0.254103, loss_ce: 0.064825
2022-01-14 11:48:57,057 iteration 750 : loss : 0.107717, loss_ce: 0.040947
2022-01-14 11:48:58,064 iteration 751 : loss : 0.110308, loss_ce: 0.040472
2022-01-14 11:48:59,045 iteration 752 : loss : 0.164784, loss_ce: 0.087772
2022-01-14 11:48:59,992 iteration 753 : loss : 0.130730, loss_ce: 0.061163
2022-01-14 11:49:00,955 iteration 754 : loss : 0.133816, loss_ce: 0.050636
2022-01-14 11:49:01,861 iteration 755 : loss : 0.128380, loss_ce: 0.065757
2022-01-14 11:49:02,776 iteration 756 : loss : 0.091163, loss_ce: 0.033091
2022-01-14 11:49:03,755 iteration 757 : loss : 0.128320, loss_ce: 0.064173
2022-01-14 11:49:04,831 iteration 758 : loss : 0.111504, loss_ce: 0.045377
2022-01-14 11:49:05,958 iteration 759 : loss : 0.152995, loss_ce: 0.056643
2022-01-14 11:49:06,935 iteration 760 : loss : 0.110850, loss_ce: 0.064604
2022-01-14 11:49:07,955 iteration 761 : loss : 0.100689, loss_ce: 0.042733
2022-01-14 11:49:09,000 iteration 762 : loss : 0.118783, loss_ce: 0.043375
2022-01-14 11:49:10,043 iteration 763 : loss : 0.090757, loss_ce: 0.035950
2022-01-14 11:49:11,011 iteration 764 : loss : 0.120090, loss_ce: 0.050651
2022-01-14 11:49:11,012 Training Data Eval:
2022-01-14 11:49:15,827   Average segmentation loss on training set: 0.1076
2022-01-14 11:49:15,827 Validation Data Eval:
2022-01-14 11:49:17,443   Average segmentation loss on validation set: 0.1628
2022-01-14 11:49:18,594 iteration 765 : loss : 0.110439, loss_ce: 0.042605
 11%|███▍                          | 45/400 [13:52<1:55:11, 19.47s/it]2022-01-14 11:49:19,709 iteration 766 : loss : 0.150399, loss_ce: 0.064674
2022-01-14 11:49:20,744 iteration 767 : loss : 0.121348, loss_ce: 0.046556
2022-01-14 11:49:21,766 iteration 768 : loss : 0.120155, loss_ce: 0.042696
2022-01-14 11:49:22,805 iteration 769 : loss : 0.104417, loss_ce: 0.041775
2022-01-14 11:49:23,726 iteration 770 : loss : 0.091678, loss_ce: 0.036436
2022-01-14 11:49:24,734 iteration 771 : loss : 0.147348, loss_ce: 0.037106
2022-01-14 11:49:25,747 iteration 772 : loss : 0.103640, loss_ce: 0.041050
2022-01-14 11:49:26,775 iteration 773 : loss : 0.131657, loss_ce: 0.036752
2022-01-14 11:49:27,881 iteration 774 : loss : 0.110413, loss_ce: 0.046486
2022-01-14 11:49:28,860 iteration 775 : loss : 0.122333, loss_ce: 0.068462
2022-01-14 11:49:29,815 iteration 776 : loss : 0.134942, loss_ce: 0.053345
2022-01-14 11:49:30,992 iteration 777 : loss : 0.182483, loss_ce: 0.087923
2022-01-14 11:49:31,923 iteration 778 : loss : 0.166082, loss_ce: 0.056330
2022-01-14 11:49:32,978 iteration 779 : loss : 0.120823, loss_ce: 0.051249
2022-01-14 11:49:34,038 iteration 780 : loss : 0.114120, loss_ce: 0.040197
2022-01-14 11:49:34,997 iteration 781 : loss : 0.111136, loss_ce: 0.052335
2022-01-14 11:49:35,914 iteration 782 : loss : 0.097962, loss_ce: 0.047004
 12%|███▍                          | 46/400 [14:09<1:51:03, 18.82s/it]2022-01-14 11:49:36,958 iteration 783 : loss : 0.133849, loss_ce: 0.055109
2022-01-14 11:49:37,921 iteration 784 : loss : 0.100134, loss_ce: 0.037182
2022-01-14 11:49:38,925 iteration 785 : loss : 0.126643, loss_ce: 0.057526
2022-01-14 11:49:39,903 iteration 786 : loss : 0.136029, loss_ce: 0.047443
2022-01-14 11:49:40,895 iteration 787 : loss : 0.107873, loss_ce: 0.050734
2022-01-14 11:49:41,953 iteration 788 : loss : 0.110702, loss_ce: 0.047335
2022-01-14 11:49:42,865 iteration 789 : loss : 0.119149, loss_ce: 0.044325
2022-01-14 11:49:43,905 iteration 790 : loss : 0.119282, loss_ce: 0.042543
2022-01-14 11:49:44,896 iteration 791 : loss : 0.087686, loss_ce: 0.033542
2022-01-14 11:49:45,830 iteration 792 : loss : 0.114772, loss_ce: 0.053556
2022-01-14 11:49:46,889 iteration 793 : loss : 0.098461, loss_ce: 0.050308
2022-01-14 11:49:47,801 iteration 794 : loss : 0.079203, loss_ce: 0.033189
2022-01-14 11:49:48,735 iteration 795 : loss : 0.094369, loss_ce: 0.038260
2022-01-14 11:49:49,672 iteration 796 : loss : 0.089828, loss_ce: 0.043824
2022-01-14 11:49:50,704 iteration 797 : loss : 0.142190, loss_ce: 0.054529
2022-01-14 11:49:51,678 iteration 798 : loss : 0.104473, loss_ce: 0.033339
2022-01-14 11:49:52,598 iteration 799 : loss : 0.111982, loss_ce: 0.062671
 12%|███▌                          | 47/400 [14:26<1:46:58, 18.18s/it]2022-01-14 11:49:53,748 iteration 800 : loss : 0.130933, loss_ce: 0.054395
2022-01-14 11:49:54,765 iteration 801 : loss : 0.105259, loss_ce: 0.043990
2022-01-14 11:49:55,762 iteration 802 : loss : 0.118348, loss_ce: 0.039740
2022-01-14 11:49:56,776 iteration 803 : loss : 0.108689, loss_ce: 0.056769
2022-01-14 11:49:57,855 iteration 804 : loss : 0.173625, loss_ce: 0.077485
2022-01-14 11:49:59,008 iteration 805 : loss : 0.073741, loss_ce: 0.023538
2022-01-14 11:49:59,985 iteration 806 : loss : 0.107144, loss_ce: 0.043527
2022-01-14 11:50:00,929 iteration 807 : loss : 0.091150, loss_ce: 0.035734
2022-01-14 11:50:01,961 iteration 808 : loss : 0.140296, loss_ce: 0.062592
2022-01-14 11:50:02,968 iteration 809 : loss : 0.092084, loss_ce: 0.035854
2022-01-14 11:50:03,930 iteration 810 : loss : 0.122265, loss_ce: 0.043145
2022-01-14 11:50:04,861 iteration 811 : loss : 0.128062, loss_ce: 0.071512
2022-01-14 11:50:05,827 iteration 812 : loss : 0.084518, loss_ce: 0.038251
2022-01-14 11:50:06,819 iteration 813 : loss : 0.122765, loss_ce: 0.039121
2022-01-14 11:50:07,930 iteration 814 : loss : 0.147900, loss_ce: 0.051518
2022-01-14 11:50:08,989 iteration 815 : loss : 0.131425, loss_ce: 0.057490
2022-01-14 11:50:10,000 iteration 816 : loss : 0.095210, loss_ce: 0.033598
 12%|███▌                          | 48/400 [14:44<1:45:17, 17.95s/it]2022-01-14 11:50:11,046 iteration 817 : loss : 0.099079, loss_ce: 0.042119
2022-01-14 11:50:11,987 iteration 818 : loss : 0.085777, loss_ce: 0.034739
2022-01-14 11:50:12,978 iteration 819 : loss : 0.084321, loss_ce: 0.030670
2022-01-14 11:50:13,902 iteration 820 : loss : 0.070307, loss_ce: 0.032510
2022-01-14 11:50:14,954 iteration 821 : loss : 0.092998, loss_ce: 0.035652
2022-01-14 11:50:15,991 iteration 822 : loss : 0.131554, loss_ce: 0.049403
2022-01-14 11:50:16,939 iteration 823 : loss : 0.080907, loss_ce: 0.033379
2022-01-14 11:50:17,882 iteration 824 : loss : 0.144524, loss_ce: 0.060981
2022-01-14 11:50:18,873 iteration 825 : loss : 0.086466, loss_ce: 0.035321
2022-01-14 11:50:19,853 iteration 826 : loss : 0.125254, loss_ce: 0.036163
2022-01-14 11:50:20,839 iteration 827 : loss : 0.151395, loss_ce: 0.055684
2022-01-14 11:50:21,821 iteration 828 : loss : 0.082273, loss_ce: 0.030848
2022-01-14 11:50:22,831 iteration 829 : loss : 0.112014, loss_ce: 0.044515
2022-01-14 11:50:23,876 iteration 830 : loss : 0.083538, loss_ce: 0.027762
2022-01-14 11:50:24,864 iteration 831 : loss : 0.142263, loss_ce: 0.070726
2022-01-14 11:50:25,831 iteration 832 : loss : 0.078632, loss_ce: 0.028038
2022-01-14 11:50:26,876 iteration 833 : loss : 0.136284, loss_ce: 0.069265
 12%|███▋                          | 49/400 [15:00<1:43:06, 17.63s/it]2022-01-14 11:50:27,933 iteration 834 : loss : 0.098847, loss_ce: 0.038910
2022-01-14 11:50:28,836 iteration 835 : loss : 0.106547, loss_ce: 0.031424
2022-01-14 11:50:29,841 iteration 836 : loss : 0.099358, loss_ce: 0.044483
2022-01-14 11:50:30,781 iteration 837 : loss : 0.074618, loss_ce: 0.036506
2022-01-14 11:50:31,732 iteration 838 : loss : 0.089475, loss_ce: 0.037345
2022-01-14 11:50:32,743 iteration 839 : loss : 0.090822, loss_ce: 0.040756
2022-01-14 11:50:33,718 iteration 840 : loss : 0.106698, loss_ce: 0.037697
2022-01-14 11:50:34,660 iteration 841 : loss : 0.095407, loss_ce: 0.038389
2022-01-14 11:50:35,635 iteration 842 : loss : 0.080074, loss_ce: 0.034034
2022-01-14 11:50:36,714 iteration 843 : loss : 0.095394, loss_ce: 0.034697
2022-01-14 11:50:37,688 iteration 844 : loss : 0.103547, loss_ce: 0.034726
2022-01-14 11:50:38,703 iteration 845 : loss : 0.127428, loss_ce: 0.041765
2022-01-14 11:50:39,816 iteration 846 : loss : 0.089360, loss_ce: 0.038810
2022-01-14 11:50:40,832 iteration 847 : loss : 0.099442, loss_ce: 0.043174
2022-01-14 11:50:41,738 iteration 848 : loss : 0.084915, loss_ce: 0.035131
2022-01-14 11:50:42,749 iteration 849 : loss : 0.105282, loss_ce: 0.038824
2022-01-14 11:50:42,750 Training Data Eval:
2022-01-14 11:50:47,562   Average segmentation loss on training set: 0.0838
2022-01-14 11:50:47,562 Validation Data Eval:
2022-01-14 11:50:49,174   Average segmentation loss on validation set: 0.1367
2022-01-14 11:50:50,370 Found new lowest validation loss at iteration 849! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_1BLOCK_best_val_loss_seed1234.pth
2022-01-14 11:50:51,408 iteration 850 : loss : 0.119687, loss_ce: 0.043631
 12%|███▊                          | 50/400 [15:25<1:54:54, 19.70s/it]2022-01-14 11:50:52,479 iteration 851 : loss : 0.080613, loss_ce: 0.032615
2022-01-14 11:50:53,447 iteration 852 : loss : 0.071511, loss_ce: 0.029486
2022-01-14 11:50:54,509 iteration 853 : loss : 0.084265, loss_ce: 0.035411
2022-01-14 11:50:55,527 iteration 854 : loss : 0.071480, loss_ce: 0.020076
2022-01-14 11:50:56,542 iteration 855 : loss : 0.109889, loss_ce: 0.043236
2022-01-14 11:50:57,581 iteration 856 : loss : 0.083582, loss_ce: 0.030186
2022-01-14 11:50:58,549 iteration 857 : loss : 0.072500, loss_ce: 0.031311
2022-01-14 11:50:59,452 iteration 858 : loss : 0.087663, loss_ce: 0.042281
2022-01-14 11:51:00,430 iteration 859 : loss : 0.100816, loss_ce: 0.033638
2022-01-14 11:51:01,365 iteration 860 : loss : 0.108444, loss_ce: 0.032519
2022-01-14 11:51:02,425 iteration 861 : loss : 0.098319, loss_ce: 0.041322
2022-01-14 11:51:03,343 iteration 862 : loss : 0.099539, loss_ce: 0.035464
2022-01-14 11:51:04,404 iteration 863 : loss : 0.115672, loss_ce: 0.063705
2022-01-14 11:51:05,429 iteration 864 : loss : 0.089410, loss_ce: 0.039374
2022-01-14 11:51:06,343 iteration 865 : loss : 0.090577, loss_ce: 0.034089
2022-01-14 11:51:07,393 iteration 866 : loss : 0.101984, loss_ce: 0.045904
2022-01-14 11:51:08,320 iteration 867 : loss : 0.066118, loss_ce: 0.023131
 13%|███▊                          | 51/400 [15:42<1:49:42, 18.86s/it]2022-01-14 11:51:09,405 iteration 868 : loss : 0.133904, loss_ce: 0.043013
2022-01-14 11:51:10,402 iteration 869 : loss : 0.087697, loss_ce: 0.035072
2022-01-14 11:51:11,307 iteration 870 : loss : 0.079718, loss_ce: 0.028241
2022-01-14 11:51:12,251 iteration 871 : loss : 0.073403, loss_ce: 0.028399
2022-01-14 11:51:13,213 iteration 872 : loss : 0.083581, loss_ce: 0.038285
2022-01-14 11:51:14,278 iteration 873 : loss : 0.093525, loss_ce: 0.037641
2022-01-14 11:51:15,186 iteration 874 : loss : 0.071890, loss_ce: 0.032123
2022-01-14 11:51:16,315 iteration 875 : loss : 0.117663, loss_ce: 0.046189
2022-01-14 11:51:17,305 iteration 876 : loss : 0.056324, loss_ce: 0.026161
2022-01-14 11:51:18,195 iteration 877 : loss : 0.076930, loss_ce: 0.027863
2022-01-14 11:51:19,226 iteration 878 : loss : 0.093085, loss_ce: 0.041941
2022-01-14 11:51:20,187 iteration 879 : loss : 0.137869, loss_ce: 0.072778
2022-01-14 11:51:21,198 iteration 880 : loss : 0.078243, loss_ce: 0.028507
2022-01-14 11:51:22,157 iteration 881 : loss : 0.118018, loss_ce: 0.048920
2022-01-14 11:51:23,194 iteration 882 : loss : 0.099644, loss_ce: 0.038883
2022-01-14 11:51:24,185 iteration 883 : loss : 0.098670, loss_ce: 0.044869
2022-01-14 11:51:25,269 iteration 884 : loss : 0.108046, loss_ce: 0.050358
 13%|███▉                          | 52/400 [15:59<1:46:04, 18.29s/it]2022-01-14 11:51:26,388 iteration 885 : loss : 0.116100, loss_ce: 0.054327
2022-01-14 11:51:27,411 iteration 886 : loss : 0.097712, loss_ce: 0.035989
2022-01-14 11:51:28,444 iteration 887 : loss : 0.132631, loss_ce: 0.054621
2022-01-14 11:51:29,447 iteration 888 : loss : 0.079152, loss_ce: 0.029347
2022-01-14 11:51:30,519 iteration 889 : loss : 0.085153, loss_ce: 0.027640
2022-01-14 11:51:31,633 iteration 890 : loss : 0.097138, loss_ce: 0.035154
2022-01-14 11:51:32,642 iteration 891 : loss : 0.075774, loss_ce: 0.029936
2022-01-14 11:51:33,639 iteration 892 : loss : 0.074029, loss_ce: 0.037291
2022-01-14 11:51:34,616 iteration 893 : loss : 0.074536, loss_ce: 0.026451
2022-01-14 11:51:35,712 iteration 894 : loss : 0.096278, loss_ce: 0.035285
2022-01-14 11:51:36,676 iteration 895 : loss : 0.147963, loss_ce: 0.054628
2022-01-14 11:51:37,735 iteration 896 : loss : 0.129587, loss_ce: 0.053717
2022-01-14 11:51:38,825 iteration 897 : loss : 0.109181, loss_ce: 0.050017
2022-01-14 11:51:39,811 iteration 898 : loss : 0.102684, loss_ce: 0.057347
2022-01-14 11:51:40,793 iteration 899 : loss : 0.093974, loss_ce: 0.041999
2022-01-14 11:51:41,734 iteration 900 : loss : 0.071427, loss_ce: 0.033319
2022-01-14 11:51:42,699 iteration 901 : loss : 0.121257, loss_ce: 0.048064
 13%|███▉                          | 53/400 [16:16<1:44:15, 18.03s/it]2022-01-14 11:51:43,797 iteration 902 : loss : 0.102726, loss_ce: 0.040084
2022-01-14 11:51:44,884 iteration 903 : loss : 0.077852, loss_ce: 0.029373
2022-01-14 11:51:45,913 iteration 904 : loss : 0.107594, loss_ce: 0.034717
2022-01-14 11:51:46,928 iteration 905 : loss : 0.128056, loss_ce: 0.060620
2022-01-14 11:51:47,927 iteration 906 : loss : 0.073872, loss_ce: 0.036211
2022-01-14 11:51:48,990 iteration 907 : loss : 0.098056, loss_ce: 0.033141
2022-01-14 11:51:49,894 iteration 908 : loss : 0.106454, loss_ce: 0.045415
2022-01-14 11:51:50,911 iteration 909 : loss : 0.109765, loss_ce: 0.047621
2022-01-14 11:51:51,838 iteration 910 : loss : 0.110974, loss_ce: 0.039874
2022-01-14 11:51:52,827 iteration 911 : loss : 0.076054, loss_ce: 0.031888
2022-01-14 11:51:53,805 iteration 912 : loss : 0.070285, loss_ce: 0.025597
2022-01-14 11:51:54,774 iteration 913 : loss : 0.101345, loss_ce: 0.034343
2022-01-14 11:51:55,755 iteration 914 : loss : 0.108432, loss_ce: 0.048449
2022-01-14 11:51:56,707 iteration 915 : loss : 0.137017, loss_ce: 0.040983
2022-01-14 11:51:57,665 iteration 916 : loss : 0.056012, loss_ce: 0.021354
2022-01-14 11:51:58,685 iteration 917 : loss : 0.103324, loss_ce: 0.042682
2022-01-14 11:51:59,726 iteration 918 : loss : 0.092107, loss_ce: 0.034036
 14%|████                          | 54/400 [16:33<1:42:13, 17.73s/it]2022-01-14 11:52:00,819 iteration 919 : loss : 0.067179, loss_ce: 0.030251
2022-01-14 11:52:01,833 iteration 920 : loss : 0.082172, loss_ce: 0.036364
2022-01-14 11:52:02,874 iteration 921 : loss : 0.105945, loss_ce: 0.042722
2022-01-14 11:52:03,930 iteration 922 : loss : 0.153701, loss_ce: 0.072190
2022-01-14 11:52:04,903 iteration 923 : loss : 0.062124, loss_ce: 0.029234
2022-01-14 11:52:05,949 iteration 924 : loss : 0.106595, loss_ce: 0.033257
2022-01-14 11:52:06,910 iteration 925 : loss : 0.064202, loss_ce: 0.023285
2022-01-14 11:52:07,958 iteration 926 : loss : 0.072245, loss_ce: 0.031959
2022-01-14 11:52:08,886 iteration 927 : loss : 0.099616, loss_ce: 0.035587
2022-01-14 11:52:09,871 iteration 928 : loss : 0.076360, loss_ce: 0.035154
2022-01-14 11:52:10,929 iteration 929 : loss : 0.110247, loss_ce: 0.041279
2022-01-14 11:52:11,951 iteration 930 : loss : 0.089747, loss_ce: 0.036930
2022-01-14 11:52:12,967 iteration 931 : loss : 0.121564, loss_ce: 0.030297
2022-01-14 11:52:13,965 iteration 932 : loss : 0.079685, loss_ce: 0.029074
2022-01-14 11:52:14,930 iteration 933 : loss : 0.100626, loss_ce: 0.035857
2022-01-14 11:52:15,921 iteration 934 : loss : 0.070909, loss_ce: 0.033246
2022-01-14 11:52:15,921 Training Data Eval:
2022-01-14 11:52:20,739   Average segmentation loss on training set: 0.0832
2022-01-14 11:52:20,739 Validation Data Eval:
2022-01-14 11:52:22,353   Average segmentation loss on validation set: 0.1336
2022-01-14 11:52:23,608 Found new lowest validation loss at iteration 934! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_1BLOCK_best_val_loss_seed1234.pth
2022-01-14 11:52:24,738 iteration 935 : loss : 0.138640, loss_ce: 0.042581
 14%|████▏                         | 55/400 [16:58<1:54:29, 19.91s/it]2022-01-14 11:52:25,769 iteration 936 : loss : 0.071212, loss_ce: 0.023255
2022-01-14 11:52:26,780 iteration 937 : loss : 0.071368, loss_ce: 0.025116
2022-01-14 11:52:27,820 iteration 938 : loss : 0.069302, loss_ce: 0.026044
2022-01-14 11:52:28,773 iteration 939 : loss : 0.072325, loss_ce: 0.024247
2022-01-14 11:52:29,783 iteration 940 : loss : 0.098438, loss_ce: 0.040113
2022-01-14 11:52:30,886 iteration 941 : loss : 0.090033, loss_ce: 0.034624
2022-01-14 11:52:31,844 iteration 942 : loss : 0.066547, loss_ce: 0.024888
2022-01-14 11:52:32,819 iteration 943 : loss : 0.079840, loss_ce: 0.035937
2022-01-14 11:52:33,773 iteration 944 : loss : 0.081323, loss_ce: 0.028410
2022-01-14 11:52:34,740 iteration 945 : loss : 0.075411, loss_ce: 0.030393
2022-01-14 11:52:35,704 iteration 946 : loss : 0.058973, loss_ce: 0.027350
2022-01-14 11:52:36,656 iteration 947 : loss : 0.082478, loss_ce: 0.034366
2022-01-14 11:52:37,602 iteration 948 : loss : 0.086950, loss_ce: 0.032666
2022-01-14 11:52:38,582 iteration 949 : loss : 0.081596, loss_ce: 0.028354
2022-01-14 11:52:39,550 iteration 950 : loss : 0.110048, loss_ce: 0.053181
2022-01-14 11:52:40,576 iteration 951 : loss : 0.073377, loss_ce: 0.046484
2022-01-14 11:52:41,518 iteration 952 : loss : 0.091744, loss_ce: 0.039964
 14%|████▏                         | 56/400 [17:15<1:48:51, 18.99s/it]2022-01-14 11:52:42,632 iteration 953 : loss : 0.123754, loss_ce: 0.046766
2022-01-14 11:52:43,671 iteration 954 : loss : 0.068558, loss_ce: 0.028060
2022-01-14 11:52:44,592 iteration 955 : loss : 0.047338, loss_ce: 0.020703
2022-01-14 11:52:45,615 iteration 956 : loss : 0.071847, loss_ce: 0.029432
2022-01-14 11:52:46,628 iteration 957 : loss : 0.083307, loss_ce: 0.032742
2022-01-14 11:52:47,657 iteration 958 : loss : 0.088334, loss_ce: 0.027813
2022-01-14 11:52:48,751 iteration 959 : loss : 0.093667, loss_ce: 0.044432
2022-01-14 11:52:49,900 iteration 960 : loss : 0.082493, loss_ce: 0.038839
2022-01-14 11:52:50,863 iteration 961 : loss : 0.109829, loss_ce: 0.035909
2022-01-14 11:52:51,828 iteration 962 : loss : 0.088265, loss_ce: 0.026625
2022-01-14 11:52:52,901 iteration 963 : loss : 0.083881, loss_ce: 0.034413
2022-01-14 11:52:53,942 iteration 964 : loss : 0.091647, loss_ce: 0.046002
2022-01-14 11:52:54,919 iteration 965 : loss : 0.073697, loss_ce: 0.031779
2022-01-14 11:52:55,914 iteration 966 : loss : 0.065969, loss_ce: 0.027796
2022-01-14 11:52:56,924 iteration 967 : loss : 0.084896, loss_ce: 0.033107
2022-01-14 11:52:57,874 iteration 968 : loss : 0.131129, loss_ce: 0.048400
2022-01-14 11:52:58,889 iteration 969 : loss : 0.060893, loss_ce: 0.025025
 14%|████▎                         | 57/400 [17:32<1:45:41, 18.49s/it]2022-01-14 11:52:59,923 iteration 970 : loss : 0.081740, loss_ce: 0.038438
2022-01-14 11:53:00,943 iteration 971 : loss : 0.102277, loss_ce: 0.033138
2022-01-14 11:53:01,879 iteration 972 : loss : 0.071830, loss_ce: 0.031945
2022-01-14 11:53:02,893 iteration 973 : loss : 0.072979, loss_ce: 0.023024
2022-01-14 11:53:03,834 iteration 974 : loss : 0.097329, loss_ce: 0.042934
2022-01-14 11:53:04,881 iteration 975 : loss : 0.092523, loss_ce: 0.034061
2022-01-14 11:53:05,864 iteration 976 : loss : 0.080331, loss_ce: 0.033049
2022-01-14 11:53:06,848 iteration 977 : loss : 0.068112, loss_ce: 0.026203
2022-01-14 11:53:07,862 iteration 978 : loss : 0.062506, loss_ce: 0.024068
2022-01-14 11:53:08,831 iteration 979 : loss : 0.111585, loss_ce: 0.055338
2022-01-14 11:53:09,803 iteration 980 : loss : 0.057870, loss_ce: 0.019860
2022-01-14 11:53:10,890 iteration 981 : loss : 0.072046, loss_ce: 0.033586
2022-01-14 11:53:11,864 iteration 982 : loss : 0.081452, loss_ce: 0.040572
2022-01-14 11:53:12,912 iteration 983 : loss : 0.129025, loss_ce: 0.043897
2022-01-14 11:53:13,836 iteration 984 : loss : 0.082783, loss_ce: 0.036085
2022-01-14 11:53:14,836 iteration 985 : loss : 0.070361, loss_ce: 0.023108
2022-01-14 11:53:15,892 iteration 986 : loss : 0.100420, loss_ce: 0.036839
 14%|████▎                         | 58/400 [17:49<1:42:51, 18.05s/it]2022-01-14 11:53:17,011 iteration 987 : loss : 0.079112, loss_ce: 0.036854
2022-01-14 11:53:18,035 iteration 988 : loss : 0.085378, loss_ce: 0.038798
2022-01-14 11:53:19,044 iteration 989 : loss : 0.080358, loss_ce: 0.035695
2022-01-14 11:53:20,037 iteration 990 : loss : 0.091076, loss_ce: 0.040362
2022-01-14 11:53:21,025 iteration 991 : loss : 0.071019, loss_ce: 0.030513
2022-01-14 11:53:22,109 iteration 992 : loss : 0.082112, loss_ce: 0.040229
2022-01-14 11:53:23,135 iteration 993 : loss : 0.063450, loss_ce: 0.022945
2022-01-14 11:53:24,243 iteration 994 : loss : 0.078493, loss_ce: 0.033636
2022-01-14 11:53:25,258 iteration 995 : loss : 0.115936, loss_ce: 0.037531
2022-01-14 11:53:26,318 iteration 996 : loss : 0.051150, loss_ce: 0.023009
2022-01-14 11:53:27,383 iteration 997 : loss : 0.102309, loss_ce: 0.043793
2022-01-14 11:53:28,338 iteration 998 : loss : 0.105072, loss_ce: 0.029912
2022-01-14 11:53:29,388 iteration 999 : loss : 0.078055, loss_ce: 0.032523
2022-01-14 11:53:30,352 iteration 1000 : loss : 0.072928, loss_ce: 0.022870
2022-01-14 11:53:31,325 iteration 1001 : loss : 0.132720, loss_ce: 0.035199
2022-01-14 11:53:32,423 iteration 1002 : loss : 0.081712, loss_ce: 0.034487
2022-01-14 11:53:33,501 iteration 1003 : loss : 0.101102, loss_ce: 0.041481
 15%|████▍                         | 59/400 [18:07<1:41:48, 17.91s/it]2022-01-14 11:53:34,562 iteration 1004 : loss : 0.126404, loss_ce: 0.060188
2022-01-14 11:53:35,550 iteration 1005 : loss : 0.092257, loss_ce: 0.039529
2022-01-14 11:53:36,640 iteration 1006 : loss : 0.094644, loss_ce: 0.041923
2022-01-14 11:53:37,604 iteration 1007 : loss : 0.078900, loss_ce: 0.040789
2022-01-14 11:53:38,555 iteration 1008 : loss : 0.176068, loss_ce: 0.081971
2022-01-14 11:53:39,513 iteration 1009 : loss : 0.088984, loss_ce: 0.031153
2022-01-14 11:53:40,472 iteration 1010 : loss : 0.092270, loss_ce: 0.035896
2022-01-14 11:53:41,519 iteration 1011 : loss : 0.079877, loss_ce: 0.034405
2022-01-14 11:53:42,501 iteration 1012 : loss : 0.050553, loss_ce: 0.018959
2022-01-14 11:53:43,439 iteration 1013 : loss : 0.079862, loss_ce: 0.027642
2022-01-14 11:53:44,446 iteration 1014 : loss : 0.084477, loss_ce: 0.034013
2022-01-14 11:53:45,375 iteration 1015 : loss : 0.072395, loss_ce: 0.031108
2022-01-14 11:53:46,385 iteration 1016 : loss : 0.080691, loss_ce: 0.035216
2022-01-14 11:53:47,292 iteration 1017 : loss : 0.065250, loss_ce: 0.025678
2022-01-14 11:53:48,198 iteration 1018 : loss : 0.089744, loss_ce: 0.037802
2022-01-14 11:53:49,180 iteration 1019 : loss : 0.105412, loss_ce: 0.042190
2022-01-14 11:53:49,180 Training Data Eval:
2022-01-14 11:53:54,000   Average segmentation loss on training set: 0.0794
2022-01-14 11:53:54,001 Validation Data Eval:
2022-01-14 11:53:55,613   Average segmentation loss on validation set: 0.1475
2022-01-14 11:53:56,551 iteration 1020 : loss : 0.071285, loss_ce: 0.023011
 15%|████▌                         | 60/400 [18:30<1:50:14, 19.46s/it]2022-01-14 11:53:57,676 iteration 1021 : loss : 0.126483, loss_ce: 0.035315
2022-01-14 11:53:58,658 iteration 1022 : loss : 0.081394, loss_ce: 0.038105
2022-01-14 11:53:59,654 iteration 1023 : loss : 0.132449, loss_ce: 0.034690
2022-01-14 11:54:00,705 iteration 1024 : loss : 0.054495, loss_ce: 0.021195
2022-01-14 11:54:01,748 iteration 1025 : loss : 0.063984, loss_ce: 0.028382
2022-01-14 11:54:02,653 iteration 1026 : loss : 0.065527, loss_ce: 0.025114
2022-01-14 11:54:03,697 iteration 1027 : loss : 0.085843, loss_ce: 0.027763
2022-01-14 11:54:04,729 iteration 1028 : loss : 0.102844, loss_ce: 0.040159
2022-01-14 11:54:05,710 iteration 1029 : loss : 0.068028, loss_ce: 0.030262
2022-01-14 11:54:06,703 iteration 1030 : loss : 0.073477, loss_ce: 0.028392
2022-01-14 11:54:07,751 iteration 1031 : loss : 0.103126, loss_ce: 0.040954
2022-01-14 11:54:08,771 iteration 1032 : loss : 0.091306, loss_ce: 0.046166
2022-01-14 11:54:09,739 iteration 1033 : loss : 0.078551, loss_ce: 0.029554
2022-01-14 11:54:10,801 iteration 1034 : loss : 0.084235, loss_ce: 0.029551
2022-01-14 11:54:11,820 iteration 1035 : loss : 0.064282, loss_ce: 0.028041
2022-01-14 11:54:12,845 iteration 1036 : loss : 0.070206, loss_ce: 0.030023
2022-01-14 11:54:13,813 iteration 1037 : loss : 0.092532, loss_ce: 0.036881
 15%|████▌                         | 61/400 [18:47<1:46:11, 18.79s/it]2022-01-14 11:54:14,889 iteration 1038 : loss : 0.063361, loss_ce: 0.025878
2022-01-14 11:54:15,885 iteration 1039 : loss : 0.062837, loss_ce: 0.029400
2022-01-14 11:54:16,918 iteration 1040 : loss : 0.094880, loss_ce: 0.041720
2022-01-14 11:54:17,935 iteration 1041 : loss : 0.055953, loss_ce: 0.023734
2022-01-14 11:54:18,958 iteration 1042 : loss : 0.061577, loss_ce: 0.027278
2022-01-14 11:54:19,964 iteration 1043 : loss : 0.123711, loss_ce: 0.037907
2022-01-14 11:54:20,997 iteration 1044 : loss : 0.074895, loss_ce: 0.026317
2022-01-14 11:54:21,914 iteration 1045 : loss : 0.058895, loss_ce: 0.026619
2022-01-14 11:54:22,862 iteration 1046 : loss : 0.104010, loss_ce: 0.026499
2022-01-14 11:54:23,909 iteration 1047 : loss : 0.094647, loss_ce: 0.032868
2022-01-14 11:54:24,915 iteration 1048 : loss : 0.070493, loss_ce: 0.028318
2022-01-14 11:54:25,921 iteration 1049 : loss : 0.113779, loss_ce: 0.040269
2022-01-14 11:54:26,978 iteration 1050 : loss : 0.114824, loss_ce: 0.031134
2022-01-14 11:54:27,971 iteration 1051 : loss : 0.085562, loss_ce: 0.033269
2022-01-14 11:54:28,967 iteration 1052 : loss : 0.106286, loss_ce: 0.040237
2022-01-14 11:54:29,891 iteration 1053 : loss : 0.087012, loss_ce: 0.025519
2022-01-14 11:54:30,957 iteration 1054 : loss : 0.074898, loss_ce: 0.032280
 16%|████▋                         | 62/400 [19:05<1:43:06, 18.30s/it]2022-01-14 11:54:32,017 iteration 1055 : loss : 0.070927, loss_ce: 0.024104
2022-01-14 11:54:32,986 iteration 1056 : loss : 0.073948, loss_ce: 0.035548
2022-01-14 11:54:33,961 iteration 1057 : loss : 0.099529, loss_ce: 0.042875
2022-01-14 11:54:34,952 iteration 1058 : loss : 0.086346, loss_ce: 0.040730
2022-01-14 11:54:35,868 iteration 1059 : loss : 0.084743, loss_ce: 0.031181
2022-01-14 11:54:36,853 iteration 1060 : loss : 0.071379, loss_ce: 0.029132
2022-01-14 11:54:37,878 iteration 1061 : loss : 0.078072, loss_ce: 0.031335
2022-01-14 11:54:38,890 iteration 1062 : loss : 0.083011, loss_ce: 0.037373
2022-01-14 11:54:39,956 iteration 1063 : loss : 0.108328, loss_ce: 0.033888
2022-01-14 11:54:40,948 iteration 1064 : loss : 0.089801, loss_ce: 0.026641
2022-01-14 11:54:41,882 iteration 1065 : loss : 0.076699, loss_ce: 0.028263
2022-01-14 11:54:42,916 iteration 1066 : loss : 0.067068, loss_ce: 0.026758
2022-01-14 11:54:43,897 iteration 1067 : loss : 0.158522, loss_ce: 0.043367
2022-01-14 11:54:44,942 iteration 1068 : loss : 0.087389, loss_ce: 0.042410
2022-01-14 11:54:45,964 iteration 1069 : loss : 0.098936, loss_ce: 0.044385
2022-01-14 11:54:46,954 iteration 1070 : loss : 0.069720, loss_ce: 0.028864
2022-01-14 11:54:47,936 iteration 1071 : loss : 0.083223, loss_ce: 0.036047
 16%|████▋                         | 63/400 [19:21<1:40:33, 17.90s/it]2022-01-14 11:54:49,097 iteration 1072 : loss : 0.078349, loss_ce: 0.026873
2022-01-14 11:54:50,078 iteration 1073 : loss : 0.169969, loss_ce: 0.048550
2022-01-14 11:54:51,062 iteration 1074 : loss : 0.077095, loss_ce: 0.029121
2022-01-14 11:54:52,090 iteration 1075 : loss : 0.096160, loss_ce: 0.036028
2022-01-14 11:54:53,031 iteration 1076 : loss : 0.062101, loss_ce: 0.023725
2022-01-14 11:54:54,011 iteration 1077 : loss : 0.077570, loss_ce: 0.028604
2022-01-14 11:54:55,071 iteration 1078 : loss : 0.109990, loss_ce: 0.058538
2022-01-14 11:54:56,028 iteration 1079 : loss : 0.070003, loss_ce: 0.029732
2022-01-14 11:54:56,991 iteration 1080 : loss : 0.062959, loss_ce: 0.026194
2022-01-14 11:54:58,017 iteration 1081 : loss : 0.076340, loss_ce: 0.025922
2022-01-14 11:54:59,038 iteration 1082 : loss : 0.078130, loss_ce: 0.041846
2022-01-14 11:55:00,084 iteration 1083 : loss : 0.083263, loss_ce: 0.038661
2022-01-14 11:55:01,059 iteration 1084 : loss : 0.109702, loss_ce: 0.071437
2022-01-14 11:55:02,127 iteration 1085 : loss : 0.082298, loss_ce: 0.035289
2022-01-14 11:55:03,101 iteration 1086 : loss : 0.074166, loss_ce: 0.030987
2022-01-14 11:55:04,094 iteration 1087 : loss : 0.076814, loss_ce: 0.032057
2022-01-14 11:55:05,152 iteration 1088 : loss : 0.064122, loss_ce: 0.028847
 16%|████▊                         | 64/400 [19:39<1:39:06, 17.70s/it]2022-01-14 11:55:06,181 iteration 1089 : loss : 0.090198, loss_ce: 0.037872
2022-01-14 11:55:07,156 iteration 1090 : loss : 0.086082, loss_ce: 0.043359
2022-01-14 11:55:08,153 iteration 1091 : loss : 0.063899, loss_ce: 0.029863
2022-01-14 11:55:09,148 iteration 1092 : loss : 0.062610, loss_ce: 0.024369
2022-01-14 11:55:10,162 iteration 1093 : loss : 0.088818, loss_ce: 0.032562
2022-01-14 11:55:11,227 iteration 1094 : loss : 0.067695, loss_ce: 0.025781
2022-01-14 11:55:12,185 iteration 1095 : loss : 0.055543, loss_ce: 0.023869
2022-01-14 11:55:13,282 iteration 1096 : loss : 0.085134, loss_ce: 0.038293
2022-01-14 11:55:14,300 iteration 1097 : loss : 0.081492, loss_ce: 0.039282
2022-01-14 11:55:15,259 iteration 1098 : loss : 0.053500, loss_ce: 0.023483
2022-01-14 11:55:16,278 iteration 1099 : loss : 0.080640, loss_ce: 0.025491
2022-01-14 11:55:17,353 iteration 1100 : loss : 0.069984, loss_ce: 0.026106
2022-01-14 11:55:18,349 iteration 1101 : loss : 0.076661, loss_ce: 0.033471
2022-01-14 11:55:19,433 iteration 1102 : loss : 0.099799, loss_ce: 0.032587
2022-01-14 11:55:20,417 iteration 1103 : loss : 0.079007, loss_ce: 0.026371
2022-01-14 11:55:21,403 iteration 1104 : loss : 0.080866, loss_ce: 0.031676
2022-01-14 11:55:21,403 Training Data Eval:
2022-01-14 11:55:26,220   Average segmentation loss on training set: 0.0670
2022-01-14 11:55:26,220 Validation Data Eval:
2022-01-14 11:55:27,840   Average segmentation loss on validation set: 0.1245
2022-01-14 11:55:29,021 Found new lowest validation loss at iteration 1104! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_1BLOCK_best_val_loss_seed1234.pth
2022-01-14 11:55:30,074 iteration 1105 : loss : 0.070854, loss_ce: 0.021510
 16%|████▉                         | 65/400 [20:04<1:50:54, 19.86s/it]2022-01-14 11:55:31,058 iteration 1106 : loss : 0.088695, loss_ce: 0.034883
2022-01-14 11:55:32,031 iteration 1107 : loss : 0.090097, loss_ce: 0.045359
2022-01-14 11:55:33,038 iteration 1108 : loss : 0.116070, loss_ce: 0.038774
2022-01-14 11:55:33,975 iteration 1109 : loss : 0.070147, loss_ce: 0.029417
2022-01-14 11:55:34,983 iteration 1110 : loss : 0.090766, loss_ce: 0.041165
2022-01-14 11:55:35,956 iteration 1111 : loss : 0.051561, loss_ce: 0.020542
2022-01-14 11:55:36,931 iteration 1112 : loss : 0.067288, loss_ce: 0.028024
2022-01-14 11:55:37,892 iteration 1113 : loss : 0.096951, loss_ce: 0.037868
2022-01-14 11:55:38,941 iteration 1114 : loss : 0.098881, loss_ce: 0.042229
2022-01-14 11:55:40,059 iteration 1115 : loss : 0.093634, loss_ce: 0.041427
2022-01-14 11:55:41,112 iteration 1116 : loss : 0.086025, loss_ce: 0.029764
2022-01-14 11:55:42,235 iteration 1117 : loss : 0.050164, loss_ce: 0.020453
2022-01-14 11:55:43,280 iteration 1118 : loss : 0.099500, loss_ce: 0.032324
2022-01-14 11:55:44,251 iteration 1119 : loss : 0.064758, loss_ce: 0.026862
2022-01-14 11:55:45,213 iteration 1120 : loss : 0.075488, loss_ce: 0.026995
2022-01-14 11:55:46,225 iteration 1121 : loss : 0.090199, loss_ce: 0.029451
2022-01-14 11:55:47,224 iteration 1122 : loss : 0.096133, loss_ce: 0.047906
 16%|████▉                         | 66/400 [20:21<1:46:02, 19.05s/it]2022-01-14 11:55:48,260 iteration 1123 : loss : 0.090735, loss_ce: 0.030409
2022-01-14 11:55:49,293 iteration 1124 : loss : 0.076803, loss_ce: 0.033797
2022-01-14 11:55:50,292 iteration 1125 : loss : 0.057877, loss_ce: 0.019177
2022-01-14 11:55:51,275 iteration 1126 : loss : 0.079038, loss_ce: 0.029591
2022-01-14 11:55:52,245 iteration 1127 : loss : 0.096600, loss_ce: 0.040195
2022-01-14 11:55:53,294 iteration 1128 : loss : 0.092994, loss_ce: 0.035364
2022-01-14 11:55:54,350 iteration 1129 : loss : 0.089540, loss_ce: 0.030955
2022-01-14 11:55:55,330 iteration 1130 : loss : 0.080469, loss_ce: 0.036028
2022-01-14 11:55:56,309 iteration 1131 : loss : 0.080589, loss_ce: 0.035822
2022-01-14 11:55:57,348 iteration 1132 : loss : 0.057784, loss_ce: 0.024951
2022-01-14 11:55:58,290 iteration 1133 : loss : 0.064174, loss_ce: 0.030331
2022-01-14 11:55:59,288 iteration 1134 : loss : 0.087436, loss_ce: 0.031684
2022-01-14 11:56:00,250 iteration 1135 : loss : 0.079348, loss_ce: 0.037898
2022-01-14 11:56:01,234 iteration 1136 : loss : 0.058259, loss_ce: 0.021617
2022-01-14 11:56:02,225 iteration 1137 : loss : 0.108623, loss_ce: 0.049663
2022-01-14 11:56:03,257 iteration 1138 : loss : 0.076086, loss_ce: 0.031750
2022-01-14 11:56:04,264 iteration 1139 : loss : 0.093209, loss_ce: 0.033384
 17%|█████                         | 67/400 [20:38<1:42:22, 18.45s/it]2022-01-14 11:56:05,318 iteration 1140 : loss : 0.111665, loss_ce: 0.050836
2022-01-14 11:56:06,276 iteration 1141 : loss : 0.084562, loss_ce: 0.034270
2022-01-14 11:56:07,336 iteration 1142 : loss : 0.093776, loss_ce: 0.041843
2022-01-14 11:56:08,330 iteration 1143 : loss : 0.093685, loss_ce: 0.034326
2022-01-14 11:56:09,359 iteration 1144 : loss : 0.131302, loss_ce: 0.077611
2022-01-14 11:56:10,309 iteration 1145 : loss : 0.080725, loss_ce: 0.034195
2022-01-14 11:56:11,317 iteration 1146 : loss : 0.126789, loss_ce: 0.067046
2022-01-14 11:56:12,227 iteration 1147 : loss : 0.060754, loss_ce: 0.022197
2022-01-14 11:56:13,269 iteration 1148 : loss : 0.091835, loss_ce: 0.032235
2022-01-14 11:56:14,210 iteration 1149 : loss : 0.076194, loss_ce: 0.036061
2022-01-14 11:56:15,207 iteration 1150 : loss : 0.064074, loss_ce: 0.026441
2022-01-14 11:56:16,241 iteration 1151 : loss : 0.076163, loss_ce: 0.027237
2022-01-14 11:56:17,368 iteration 1152 : loss : 0.102069, loss_ce: 0.042158
2022-01-14 11:56:18,281 iteration 1153 : loss : 0.066675, loss_ce: 0.025255
2022-01-14 11:56:19,311 iteration 1154 : loss : 0.091302, loss_ce: 0.033973
2022-01-14 11:56:20,269 iteration 1155 : loss : 0.115659, loss_ce: 0.037883
2022-01-14 11:56:21,317 iteration 1156 : loss : 0.114716, loss_ce: 0.055792
 17%|█████                         | 68/400 [20:55<1:39:45, 18.03s/it]2022-01-14 11:56:22,353 iteration 1157 : loss : 0.150215, loss_ce: 0.047680
2022-01-14 11:56:23,364 iteration 1158 : loss : 0.069575, loss_ce: 0.025675
2022-01-14 11:56:24,434 iteration 1159 : loss : 0.060207, loss_ce: 0.019032
2022-01-14 11:56:25,559 iteration 1160 : loss : 0.133165, loss_ce: 0.057170
2022-01-14 11:56:26,626 iteration 1161 : loss : 0.054906, loss_ce: 0.024942
2022-01-14 11:56:27,661 iteration 1162 : loss : 0.068908, loss_ce: 0.024430
2022-01-14 11:56:28,638 iteration 1163 : loss : 0.098524, loss_ce: 0.045511
2022-01-14 11:56:29,626 iteration 1164 : loss : 0.090752, loss_ce: 0.035718
2022-01-14 11:56:30,618 iteration 1165 : loss : 0.082441, loss_ce: 0.038621
2022-01-14 11:56:31,686 iteration 1166 : loss : 0.056143, loss_ce: 0.022953
2022-01-14 11:56:32,648 iteration 1167 : loss : 0.063359, loss_ce: 0.030394
2022-01-14 11:56:33,626 iteration 1168 : loss : 0.061472, loss_ce: 0.028158
2022-01-14 11:56:34,590 iteration 1169 : loss : 0.079350, loss_ce: 0.031891
2022-01-14 11:56:35,557 iteration 1170 : loss : 0.083350, loss_ce: 0.033746
2022-01-14 11:56:36,571 iteration 1171 : loss : 0.091754, loss_ce: 0.032126
2022-01-14 11:56:37,577 iteration 1172 : loss : 0.092024, loss_ce: 0.045287
2022-01-14 11:56:38,611 iteration 1173 : loss : 0.080598, loss_ce: 0.029069
 17%|█████▏                        | 69/400 [21:12<1:38:14, 17.81s/it]2022-01-14 11:56:39,685 iteration 1174 : loss : 0.101157, loss_ce: 0.037273
2022-01-14 11:56:40,683 iteration 1175 : loss : 0.064946, loss_ce: 0.024168
2022-01-14 11:56:41,672 iteration 1176 : loss : 0.058218, loss_ce: 0.023220
2022-01-14 11:56:42,629 iteration 1177 : loss : 0.056619, loss_ce: 0.023387
2022-01-14 11:56:43,656 iteration 1178 : loss : 0.064613, loss_ce: 0.020199
2022-01-14 11:56:44,735 iteration 1179 : loss : 0.075402, loss_ce: 0.032710
2022-01-14 11:56:45,702 iteration 1180 : loss : 0.076912, loss_ce: 0.035181
2022-01-14 11:56:46,690 iteration 1181 : loss : 0.070337, loss_ce: 0.028166
2022-01-14 11:56:47,699 iteration 1182 : loss : 0.063745, loss_ce: 0.024208
2022-01-14 11:56:48,651 iteration 1183 : loss : 0.078680, loss_ce: 0.033387
2022-01-14 11:56:49,616 iteration 1184 : loss : 0.052199, loss_ce: 0.024651
2022-01-14 11:56:50,656 iteration 1185 : loss : 0.078016, loss_ce: 0.031045
2022-01-14 11:56:51,618 iteration 1186 : loss : 0.067956, loss_ce: 0.032903
2022-01-14 11:56:52,674 iteration 1187 : loss : 0.072741, loss_ce: 0.027292
2022-01-14 11:56:53,630 iteration 1188 : loss : 0.077239, loss_ce: 0.028615
2022-01-14 11:56:54,698 iteration 1189 : loss : 0.090105, loss_ce: 0.047239
2022-01-14 11:56:54,699 Training Data Eval:
2022-01-14 11:56:59,516   Average segmentation loss on training set: 0.0687
2022-01-14 11:56:59,516 Validation Data Eval:
2022-01-14 11:57:01,137   Average segmentation loss on validation set: 0.0939
2022-01-14 11:57:02,324 Found new lowest validation loss at iteration 1189! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_1BLOCK_best_val_loss_seed1234.pth
2022-01-14 11:57:03,367 iteration 1190 : loss : 0.076730, loss_ce: 0.034801
 18%|█████▎                        | 70/400 [21:37<1:49:25, 19.90s/it]2022-01-14 11:57:04,489 iteration 1191 : loss : 0.064639, loss_ce: 0.024342
2022-01-14 11:57:05,440 iteration 1192 : loss : 0.054474, loss_ce: 0.026240
2022-01-14 11:57:06,510 iteration 1193 : loss : 0.113819, loss_ce: 0.040171
2022-01-14 11:57:07,491 iteration 1194 : loss : 0.067247, loss_ce: 0.020938
2022-01-14 11:57:08,434 iteration 1195 : loss : 0.054345, loss_ce: 0.026022
2022-01-14 11:57:09,378 iteration 1196 : loss : 0.063661, loss_ce: 0.029833
2022-01-14 11:57:10,289 iteration 1197 : loss : 0.055476, loss_ce: 0.022838
2022-01-14 11:57:11,326 iteration 1198 : loss : 0.064242, loss_ce: 0.032101
2022-01-14 11:57:12,328 iteration 1199 : loss : 0.064202, loss_ce: 0.024743
2022-01-14 11:57:13,309 iteration 1200 : loss : 0.088196, loss_ce: 0.028526
2022-01-14 11:57:14,247 iteration 1201 : loss : 0.056248, loss_ce: 0.025467
2022-01-14 11:57:15,264 iteration 1202 : loss : 0.073764, loss_ce: 0.028622
2022-01-14 11:57:16,270 iteration 1203 : loss : 0.085442, loss_ce: 0.028620
2022-01-14 11:57:17,262 iteration 1204 : loss : 0.077260, loss_ce: 0.026779
2022-01-14 11:57:18,264 iteration 1205 : loss : 0.082965, loss_ce: 0.035007
2022-01-14 11:57:19,271 iteration 1206 : loss : 0.067006, loss_ce: 0.026721
2022-01-14 11:57:20,315 iteration 1207 : loss : 0.041022, loss_ce: 0.014475
 18%|█████▎                        | 71/400 [21:54<1:44:14, 19.01s/it]2022-01-14 11:57:21,415 iteration 1208 : loss : 0.072627, loss_ce: 0.034018
2022-01-14 11:57:22,424 iteration 1209 : loss : 0.062893, loss_ce: 0.026771
2022-01-14 11:57:23,429 iteration 1210 : loss : 0.062692, loss_ce: 0.026395
2022-01-14 11:57:24,374 iteration 1211 : loss : 0.043032, loss_ce: 0.017075
2022-01-14 11:57:25,301 iteration 1212 : loss : 0.087314, loss_ce: 0.027017
2022-01-14 11:57:26,408 iteration 1213 : loss : 0.081309, loss_ce: 0.033749
2022-01-14 11:57:27,403 iteration 1214 : loss : 0.064875, loss_ce: 0.025927
2022-01-14 11:57:28,403 iteration 1215 : loss : 0.110999, loss_ce: 0.047769
2022-01-14 11:57:29,518 iteration 1216 : loss : 0.090598, loss_ce: 0.030079
2022-01-14 11:57:30,528 iteration 1217 : loss : 0.048708, loss_ce: 0.015448
2022-01-14 11:57:31,483 iteration 1218 : loss : 0.057955, loss_ce: 0.021003
2022-01-14 11:57:32,405 iteration 1219 : loss : 0.082708, loss_ce: 0.028143
2022-01-14 11:57:33,387 iteration 1220 : loss : 0.078449, loss_ce: 0.036959
2022-01-14 11:57:34,341 iteration 1221 : loss : 0.130946, loss_ce: 0.043762
2022-01-14 11:57:35,393 iteration 1222 : loss : 0.092417, loss_ce: 0.032128
2022-01-14 11:57:36,364 iteration 1223 : loss : 0.084034, loss_ce: 0.037551
2022-01-14 11:57:37,396 iteration 1224 : loss : 0.100309, loss_ce: 0.045853
 18%|█████▍                        | 72/400 [22:11<1:40:45, 18.43s/it]2022-01-14 11:57:38,425 iteration 1225 : loss : 0.073222, loss_ce: 0.031390
2022-01-14 11:57:39,457 iteration 1226 : loss : 0.085750, loss_ce: 0.039278
2022-01-14 11:57:40,404 iteration 1227 : loss : 0.087834, loss_ce: 0.033139
2022-01-14 11:57:41,388 iteration 1228 : loss : 0.071927, loss_ce: 0.026194
2022-01-14 11:57:42,314 iteration 1229 : loss : 0.082437, loss_ce: 0.026292
2022-01-14 11:57:43,265 iteration 1230 : loss : 0.071242, loss_ce: 0.027486
2022-01-14 11:57:44,296 iteration 1231 : loss : 0.094921, loss_ce: 0.039140
2022-01-14 11:57:45,249 iteration 1232 : loss : 0.083760, loss_ce: 0.035757
2022-01-14 11:57:46,214 iteration 1233 : loss : 0.050705, loss_ce: 0.021960
2022-01-14 11:57:47,245 iteration 1234 : loss : 0.078100, loss_ce: 0.032688
2022-01-14 11:57:48,265 iteration 1235 : loss : 0.097333, loss_ce: 0.029536
2022-01-14 11:57:49,217 iteration 1236 : loss : 0.063562, loss_ce: 0.025141
2022-01-14 11:57:50,119 iteration 1237 : loss : 0.110685, loss_ce: 0.052657
2022-01-14 11:57:51,151 iteration 1238 : loss : 0.077502, loss_ce: 0.025741
2022-01-14 11:57:52,091 iteration 1239 : loss : 0.055359, loss_ce: 0.020096
2022-01-14 11:57:53,035 iteration 1240 : loss : 0.059390, loss_ce: 0.026942
2022-01-14 11:57:53,979 iteration 1241 : loss : 0.082550, loss_ce: 0.041949
 18%|█████▍                        | 73/400 [22:28<1:37:25, 17.88s/it]2022-01-14 11:57:55,055 iteration 1242 : loss : 0.084279, loss_ce: 0.045740
2022-01-14 11:57:56,010 iteration 1243 : loss : 0.091302, loss_ce: 0.028923
2022-01-14 11:57:56,971 iteration 1244 : loss : 0.071095, loss_ce: 0.028708
2022-01-14 11:57:57,974 iteration 1245 : loss : 0.095235, loss_ce: 0.037855
2022-01-14 11:57:58,974 iteration 1246 : loss : 0.068107, loss_ce: 0.022547
2022-01-14 11:57:59,927 iteration 1247 : loss : 0.078316, loss_ce: 0.030956
2022-01-14 11:58:00,935 iteration 1248 : loss : 0.083960, loss_ce: 0.031616
2022-01-14 11:58:01,884 iteration 1249 : loss : 0.053530, loss_ce: 0.016814
2022-01-14 11:58:02,970 iteration 1250 : loss : 0.082782, loss_ce: 0.034737
2022-01-14 11:58:04,088 iteration 1251 : loss : 0.080045, loss_ce: 0.039276
2022-01-14 11:58:05,175 iteration 1252 : loss : 0.061285, loss_ce: 0.027094
2022-01-14 11:58:06,091 iteration 1253 : loss : 0.071688, loss_ce: 0.026952
2022-01-14 11:58:07,080 iteration 1254 : loss : 0.071538, loss_ce: 0.037590
2022-01-14 11:58:08,082 iteration 1255 : loss : 0.067241, loss_ce: 0.025292
2022-01-14 11:58:09,055 iteration 1256 : loss : 0.073339, loss_ce: 0.029806
2022-01-14 11:58:10,040 iteration 1257 : loss : 0.114959, loss_ce: 0.034452
2022-01-14 11:58:11,047 iteration 1258 : loss : 0.057932, loss_ce: 0.023978
 18%|█████▌                        | 74/400 [22:45<1:35:48, 17.63s/it]2022-01-14 11:58:12,050 iteration 1259 : loss : 0.055434, loss_ce: 0.025282
2022-01-14 11:58:13,094 iteration 1260 : loss : 0.049609, loss_ce: 0.021342
2022-01-14 11:58:14,067 iteration 1261 : loss : 0.047801, loss_ce: 0.015400
2022-01-14 11:58:15,145 iteration 1262 : loss : 0.065036, loss_ce: 0.027843
2022-01-14 11:58:16,246 iteration 1263 : loss : 0.132161, loss_ce: 0.063019
2022-01-14 11:58:17,223 iteration 1264 : loss : 0.053733, loss_ce: 0.024905
2022-01-14 11:58:18,269 iteration 1265 : loss : 0.065332, loss_ce: 0.033891
2022-01-14 11:58:19,315 iteration 1266 : loss : 0.080219, loss_ce: 0.033840
2022-01-14 11:58:20,340 iteration 1267 : loss : 0.070581, loss_ce: 0.027422
2022-01-14 11:58:21,307 iteration 1268 : loss : 0.088062, loss_ce: 0.034220
2022-01-14 11:58:22,380 iteration 1269 : loss : 0.115357, loss_ce: 0.030802
2022-01-14 11:58:23,414 iteration 1270 : loss : 0.058657, loss_ce: 0.026198
2022-01-14 11:58:24,405 iteration 1271 : loss : 0.075001, loss_ce: 0.032460
2022-01-14 11:58:25,317 iteration 1272 : loss : 0.071712, loss_ce: 0.024336
2022-01-14 11:58:26,284 iteration 1273 : loss : 0.068193, loss_ce: 0.025007
2022-01-14 11:58:27,273 iteration 1274 : loss : 0.075014, loss_ce: 0.023111
2022-01-14 11:58:27,273 Training Data Eval:
2022-01-14 11:58:32,091   Average segmentation loss on training set: 0.0650
2022-01-14 11:58:32,092 Validation Data Eval:
2022-01-14 11:58:33,715   Average segmentation loss on validation set: 0.1378
2022-01-14 11:58:34,696 iteration 1275 : loss : 0.066215, loss_ce: 0.023204
 19%|█████▋                        | 75/400 [23:08<1:45:16, 19.44s/it]2022-01-14 11:58:35,658 iteration 1276 : loss : 0.057908, loss_ce: 0.022729
2022-01-14 11:58:36,758 iteration 1277 : loss : 0.063095, loss_ce: 0.022751
2022-01-14 11:58:37,714 iteration 1278 : loss : 0.048303, loss_ce: 0.016635
2022-01-14 11:58:38,801 iteration 1279 : loss : 0.062987, loss_ce: 0.025728
2022-01-14 11:58:39,849 iteration 1280 : loss : 0.065352, loss_ce: 0.027849
2022-01-14 11:58:40,853 iteration 1281 : loss : 0.076993, loss_ce: 0.041816
2022-01-14 11:58:41,791 iteration 1282 : loss : 0.040238, loss_ce: 0.017877
2022-01-14 11:58:42,837 iteration 1283 : loss : 0.102914, loss_ce: 0.029122
2022-01-14 11:58:43,787 iteration 1284 : loss : 0.059612, loss_ce: 0.023459
2022-01-14 11:58:44,850 iteration 1285 : loss : 0.057607, loss_ce: 0.020115
2022-01-14 11:58:45,948 iteration 1286 : loss : 0.125079, loss_ce: 0.029996
2022-01-14 11:58:46,926 iteration 1287 : loss : 0.045476, loss_ce: 0.023629
2022-01-14 11:58:47,881 iteration 1288 : loss : 0.069595, loss_ce: 0.032162
2022-01-14 11:58:48,872 iteration 1289 : loss : 0.073631, loss_ce: 0.030330
2022-01-14 11:58:49,901 iteration 1290 : loss : 0.082718, loss_ce: 0.029602
2022-01-14 11:58:50,940 iteration 1291 : loss : 0.088720, loss_ce: 0.038838
2022-01-14 11:58:51,993 iteration 1292 : loss : 0.078404, loss_ce: 0.027640
 19%|█████▋                        | 76/400 [23:26<1:41:30, 18.80s/it]2022-01-14 11:58:53,087 iteration 1293 : loss : 0.055051, loss_ce: 0.020589
2022-01-14 11:58:54,122 iteration 1294 : loss : 0.077909, loss_ce: 0.032468
2022-01-14 11:58:55,193 iteration 1295 : loss : 0.092508, loss_ce: 0.030355
2022-01-14 11:58:56,216 iteration 1296 : loss : 0.082028, loss_ce: 0.028972
2022-01-14 11:58:57,174 iteration 1297 : loss : 0.076150, loss_ce: 0.037155
2022-01-14 11:58:58,105 iteration 1298 : loss : 0.049701, loss_ce: 0.018786
2022-01-14 11:58:59,106 iteration 1299 : loss : 0.060822, loss_ce: 0.031061
2022-01-14 11:59:00,091 iteration 1300 : loss : 0.080240, loss_ce: 0.026869
2022-01-14 11:59:01,117 iteration 1301 : loss : 0.049316, loss_ce: 0.018392
2022-01-14 11:59:02,091 iteration 1302 : loss : 0.063960, loss_ce: 0.029894
2022-01-14 11:59:03,066 iteration 1303 : loss : 0.072211, loss_ce: 0.030938
2022-01-14 11:59:04,072 iteration 1304 : loss : 0.054759, loss_ce: 0.020428
2022-01-14 11:59:05,065 iteration 1305 : loss : 0.082609, loss_ce: 0.036559
2022-01-14 11:59:06,098 iteration 1306 : loss : 0.083456, loss_ce: 0.026839
2022-01-14 11:59:07,130 iteration 1307 : loss : 0.057946, loss_ce: 0.028667
2022-01-14 11:59:08,138 iteration 1308 : loss : 0.108532, loss_ce: 0.027545
2022-01-14 11:59:09,073 iteration 1309 : loss : 0.078789, loss_ce: 0.030118
 19%|█████▊                        | 77/400 [23:43<1:38:25, 18.28s/it]2022-01-14 11:59:10,213 iteration 1310 : loss : 0.083004, loss_ce: 0.030993
2022-01-14 11:59:11,189 iteration 1311 : loss : 0.053591, loss_ce: 0.025283
2022-01-14 11:59:12,158 iteration 1312 : loss : 0.041722, loss_ce: 0.015322
2022-01-14 11:59:13,123 iteration 1313 : loss : 0.081290, loss_ce: 0.027866
2022-01-14 11:59:14,122 iteration 1314 : loss : 0.081570, loss_ce: 0.044992
2022-01-14 11:59:15,145 iteration 1315 : loss : 0.078725, loss_ce: 0.030671
2022-01-14 11:59:16,253 iteration 1316 : loss : 0.077315, loss_ce: 0.034715
2022-01-14 11:59:17,242 iteration 1317 : loss : 0.078705, loss_ce: 0.042835
2022-01-14 11:59:18,326 iteration 1318 : loss : 0.162377, loss_ce: 0.033188
2022-01-14 11:59:19,368 iteration 1319 : loss : 0.070727, loss_ce: 0.033065
2022-01-14 11:59:20,351 iteration 1320 : loss : 0.056650, loss_ce: 0.022827
2022-01-14 11:59:21,365 iteration 1321 : loss : 0.096526, loss_ce: 0.029458
2022-01-14 11:59:22,309 iteration 1322 : loss : 0.080408, loss_ce: 0.037490
2022-01-14 11:59:23,292 iteration 1323 : loss : 0.065248, loss_ce: 0.024334
2022-01-14 11:59:24,312 iteration 1324 : loss : 0.064676, loss_ce: 0.027429
2022-01-14 11:59:25,367 iteration 1325 : loss : 0.074562, loss_ce: 0.028050
2022-01-14 11:59:26,276 iteration 1326 : loss : 0.064521, loss_ce: 0.023893
 20%|█████▊                        | 78/400 [24:00<1:36:22, 17.96s/it]2022-01-14 11:59:27,303 iteration 1327 : loss : 0.108272, loss_ce: 0.038023
2022-01-14 11:59:28,320 iteration 1328 : loss : 0.090606, loss_ce: 0.045876
2022-01-14 11:59:29,311 iteration 1329 : loss : 0.058160, loss_ce: 0.024466
2022-01-14 11:59:30,274 iteration 1330 : loss : 0.115607, loss_ce: 0.031574
2022-01-14 11:59:31,205 iteration 1331 : loss : 0.092731, loss_ce: 0.051616
2022-01-14 11:59:32,150 iteration 1332 : loss : 0.065131, loss_ce: 0.022642
2022-01-14 11:59:33,123 iteration 1333 : loss : 0.078597, loss_ce: 0.026591
2022-01-14 11:59:34,115 iteration 1334 : loss : 0.086552, loss_ce: 0.034242
2022-01-14 11:59:35,078 iteration 1335 : loss : 0.075120, loss_ce: 0.028177
2022-01-14 11:59:36,045 iteration 1336 : loss : 0.070051, loss_ce: 0.028688
2022-01-14 11:59:37,099 iteration 1337 : loss : 0.082333, loss_ce: 0.037240
2022-01-14 11:59:38,130 iteration 1338 : loss : 0.068837, loss_ce: 0.024640
2022-01-14 11:59:39,151 iteration 1339 : loss : 0.076534, loss_ce: 0.036925
2022-01-14 11:59:40,170 iteration 1340 : loss : 0.069958, loss_ce: 0.034261
2022-01-14 11:59:41,176 iteration 1341 : loss : 0.069396, loss_ce: 0.025789
2022-01-14 11:59:42,162 iteration 1342 : loss : 0.085830, loss_ce: 0.036486
2022-01-14 11:59:43,102 iteration 1343 : loss : 0.055889, loss_ce: 0.023641
 20%|█████▉                        | 79/400 [24:17<1:34:15, 17.62s/it]2022-01-14 11:59:44,154 iteration 1344 : loss : 0.076529, loss_ce: 0.032274
2022-01-14 11:59:45,223 iteration 1345 : loss : 0.086000, loss_ce: 0.033963
2022-01-14 11:59:46,203 iteration 1346 : loss : 0.078114, loss_ce: 0.035394
2022-01-14 11:59:47,276 iteration 1347 : loss : 0.041110, loss_ce: 0.017650
2022-01-14 11:59:48,384 iteration 1348 : loss : 0.084124, loss_ce: 0.033498
2022-01-14 11:59:49,388 iteration 1349 : loss : 0.068539, loss_ce: 0.029509
2022-01-14 11:59:50,385 iteration 1350 : loss : 0.079477, loss_ce: 0.039589
2022-01-14 11:59:51,380 iteration 1351 : loss : 0.070135, loss_ce: 0.033778
2022-01-14 11:59:52,430 iteration 1352 : loss : 0.059345, loss_ce: 0.028251
2022-01-14 11:59:53,455 iteration 1353 : loss : 0.098411, loss_ce: 0.040456
2022-01-14 11:59:54,497 iteration 1354 : loss : 0.102833, loss_ce: 0.039601
2022-01-14 11:59:55,608 iteration 1355 : loss : 0.182756, loss_ce: 0.051124
2022-01-14 11:59:56,638 iteration 1356 : loss : 0.084484, loss_ce: 0.038527
2022-01-14 11:59:57,673 iteration 1357 : loss : 0.073466, loss_ce: 0.026903
2022-01-14 11:59:58,728 iteration 1358 : loss : 0.066792, loss_ce: 0.030746
2022-01-14 11:59:59,726 iteration 1359 : loss : 0.079015, loss_ce: 0.034183
2022-01-14 11:59:59,726 Training Data Eval:
2022-01-14 12:00:04,541   Average segmentation loss on training set: 0.1852
2022-01-14 12:00:04,541 Validation Data Eval:
2022-01-14 12:00:06,155   Average segmentation loss on validation set: 0.3291
2022-01-14 12:00:07,206 iteration 1360 : loss : 0.088157, loss_ce: 0.025566
 20%|██████                        | 80/400 [24:41<1:44:20, 19.56s/it]2022-01-14 12:00:08,363 iteration 1361 : loss : 0.070228, loss_ce: 0.028489
2022-01-14 12:00:09,379 iteration 1362 : loss : 0.080884, loss_ce: 0.029191
2022-01-14 12:00:10,538 iteration 1363 : loss : 0.104088, loss_ce: 0.042625
2022-01-14 12:00:11,418 iteration 1364 : loss : 0.115901, loss_ce: 0.032666
2022-01-14 12:00:12,481 iteration 1365 : loss : 0.083683, loss_ce: 0.037598
2022-01-14 12:00:13,503 iteration 1366 : loss : 0.078233, loss_ce: 0.036905
2022-01-14 12:00:14,494 iteration 1367 : loss : 0.060907, loss_ce: 0.024575
2022-01-14 12:00:15,501 iteration 1368 : loss : 0.050440, loss_ce: 0.024929
2022-01-14 12:00:16,473 iteration 1369 : loss : 0.059522, loss_ce: 0.020576
2022-01-14 12:00:17,514 iteration 1370 : loss : 0.089172, loss_ce: 0.043966
2022-01-14 12:00:18,490 iteration 1371 : loss : 0.060447, loss_ce: 0.023286
2022-01-14 12:00:19,460 iteration 1372 : loss : 0.080848, loss_ce: 0.031261
2022-01-14 12:00:20,420 iteration 1373 : loss : 0.066922, loss_ce: 0.027047
2022-01-14 12:00:21,432 iteration 1374 : loss : 0.068219, loss_ce: 0.021527
2022-01-14 12:00:22,451 iteration 1375 : loss : 0.078534, loss_ce: 0.039398
2022-01-14 12:00:23,458 iteration 1376 : loss : 0.079469, loss_ce: 0.027450
2022-01-14 12:00:24,443 iteration 1377 : loss : 0.050301, loss_ce: 0.020417
 20%|██████                        | 81/400 [24:58<1:40:18, 18.87s/it]2022-01-14 12:00:25,431 iteration 1378 : loss : 0.076699, loss_ce: 0.028564
2022-01-14 12:00:26,476 iteration 1379 : loss : 0.055406, loss_ce: 0.023272
2022-01-14 12:00:27,485 iteration 1380 : loss : 0.064810, loss_ce: 0.027043
2022-01-14 12:00:28,566 iteration 1381 : loss : 0.073120, loss_ce: 0.031760
2022-01-14 12:00:29,490 iteration 1382 : loss : 0.057534, loss_ce: 0.023580
2022-01-14 12:00:30,560 iteration 1383 : loss : 0.064941, loss_ce: 0.025808
2022-01-14 12:00:31,572 iteration 1384 : loss : 0.076776, loss_ce: 0.027069
2022-01-14 12:00:32,513 iteration 1385 : loss : 0.072610, loss_ce: 0.029914
2022-01-14 12:00:33,482 iteration 1386 : loss : 0.052350, loss_ce: 0.022266
2022-01-14 12:00:34,465 iteration 1387 : loss : 0.073739, loss_ce: 0.028898
2022-01-14 12:00:35,462 iteration 1388 : loss : 0.085433, loss_ce: 0.027085
2022-01-14 12:00:36,455 iteration 1389 : loss : 0.062184, loss_ce: 0.024978
2022-01-14 12:00:37,496 iteration 1390 : loss : 0.057129, loss_ce: 0.022894
2022-01-14 12:00:38,569 iteration 1391 : loss : 0.059057, loss_ce: 0.021835
2022-01-14 12:00:39,610 iteration 1392 : loss : 0.060789, loss_ce: 0.031766
2022-01-14 12:00:40,580 iteration 1393 : loss : 0.061208, loss_ce: 0.023076
2022-01-14 12:00:41,636 iteration 1394 : loss : 0.071477, loss_ce: 0.031033
 20%|██████▏                       | 82/400 [25:15<1:37:19, 18.36s/it]2022-01-14 12:00:42,678 iteration 1395 : loss : 0.072948, loss_ce: 0.027266
2022-01-14 12:00:43,652 iteration 1396 : loss : 0.071277, loss_ce: 0.034518
2022-01-14 12:00:44,712 iteration 1397 : loss : 0.067414, loss_ce: 0.029539
2022-01-14 12:00:45,783 iteration 1398 : loss : 0.064108, loss_ce: 0.028392
2022-01-14 12:00:46,707 iteration 1399 : loss : 0.064085, loss_ce: 0.031668
2022-01-14 12:00:47,622 iteration 1400 : loss : 0.065858, loss_ce: 0.024846
2022-01-14 12:00:48,676 iteration 1401 : loss : 0.085867, loss_ce: 0.033471
2022-01-14 12:00:49,687 iteration 1402 : loss : 0.059184, loss_ce: 0.025588
2022-01-14 12:00:50,633 iteration 1403 : loss : 0.050383, loss_ce: 0.020402
2022-01-14 12:00:51,575 iteration 1404 : loss : 0.034248, loss_ce: 0.016360
2022-01-14 12:00:52,567 iteration 1405 : loss : 0.069815, loss_ce: 0.028279
2022-01-14 12:00:53,569 iteration 1406 : loss : 0.069087, loss_ce: 0.024101
2022-01-14 12:00:54,615 iteration 1407 : loss : 0.046718, loss_ce: 0.019480
2022-01-14 12:00:55,619 iteration 1408 : loss : 0.072487, loss_ce: 0.024966
2022-01-14 12:00:56,624 iteration 1409 : loss : 0.078246, loss_ce: 0.030490
2022-01-14 12:00:57,698 iteration 1410 : loss : 0.040888, loss_ce: 0.018411
2022-01-14 12:00:58,674 iteration 1411 : loss : 0.056705, loss_ce: 0.017935
 21%|██████▏                       | 83/400 [25:32<1:34:55, 17.97s/it]2022-01-14 12:00:59,699 iteration 1412 : loss : 0.068283, loss_ce: 0.025244
2022-01-14 12:01:00,763 iteration 1413 : loss : 0.078172, loss_ce: 0.025033
2022-01-14 12:01:01,746 iteration 1414 : loss : 0.041481, loss_ce: 0.013788
2022-01-14 12:01:02,791 iteration 1415 : loss : 0.059089, loss_ce: 0.016575
2022-01-14 12:01:03,773 iteration 1416 : loss : 0.053536, loss_ce: 0.020265
2022-01-14 12:01:04,747 iteration 1417 : loss : 0.055412, loss_ce: 0.017010
2022-01-14 12:01:05,719 iteration 1418 : loss : 0.070833, loss_ce: 0.028471
2022-01-14 12:01:06,661 iteration 1419 : loss : 0.050700, loss_ce: 0.021025
2022-01-14 12:01:07,704 iteration 1420 : loss : 0.077444, loss_ce: 0.032866
2022-01-14 12:01:08,782 iteration 1421 : loss : 0.078392, loss_ce: 0.031503
2022-01-14 12:01:09,807 iteration 1422 : loss : 0.035924, loss_ce: 0.011244
2022-01-14 12:01:10,743 iteration 1423 : loss : 0.056091, loss_ce: 0.022648
2022-01-14 12:01:11,769 iteration 1424 : loss : 0.053110, loss_ce: 0.022858
2022-01-14 12:01:12,788 iteration 1425 : loss : 0.034980, loss_ce: 0.014742
2022-01-14 12:01:13,741 iteration 1426 : loss : 0.060910, loss_ce: 0.026886
2022-01-14 12:01:14,734 iteration 1427 : loss : 0.071202, loss_ce: 0.024337
2022-01-14 12:01:15,640 iteration 1428 : loss : 0.073385, loss_ce: 0.028837
 21%|██████▎                       | 84/400 [25:49<1:33:03, 17.67s/it]2022-01-14 12:01:16,775 iteration 1429 : loss : 0.075461, loss_ce: 0.039069
2022-01-14 12:01:17,734 iteration 1430 : loss : 0.179905, loss_ce: 0.049116
2022-01-14 12:01:18,728 iteration 1431 : loss : 0.074726, loss_ce: 0.032943
2022-01-14 12:01:19,738 iteration 1432 : loss : 0.061986, loss_ce: 0.027670
2022-01-14 12:01:20,786 iteration 1433 : loss : 0.058063, loss_ce: 0.018605
2022-01-14 12:01:21,764 iteration 1434 : loss : 0.067547, loss_ce: 0.029289
2022-01-14 12:01:22,788 iteration 1435 : loss : 0.076700, loss_ce: 0.035700
2022-01-14 12:01:23,827 iteration 1436 : loss : 0.080438, loss_ce: 0.032104
2022-01-14 12:01:24,881 iteration 1437 : loss : 0.077586, loss_ce: 0.029788
2022-01-14 12:01:25,898 iteration 1438 : loss : 0.062271, loss_ce: 0.029518
2022-01-14 12:01:26,956 iteration 1439 : loss : 0.072133, loss_ce: 0.026361
2022-01-14 12:01:27,994 iteration 1440 : loss : 0.062730, loss_ce: 0.029915
2022-01-14 12:01:28,982 iteration 1441 : loss : 0.048632, loss_ce: 0.020752
2022-01-14 12:01:29,989 iteration 1442 : loss : 0.047002, loss_ce: 0.019309
2022-01-14 12:01:31,020 iteration 1443 : loss : 0.106192, loss_ce: 0.040962
2022-01-14 12:01:32,028 iteration 1444 : loss : 0.144834, loss_ce: 0.044425
2022-01-14 12:01:32,028 Training Data Eval:
2022-01-14 12:01:36,840   Average segmentation loss on training set: 0.0585
2022-01-14 12:01:36,841 Validation Data Eval:
2022-01-14 12:01:38,446   Average segmentation loss on validation set: 0.0855
2022-01-14 12:01:39,656 Found new lowest validation loss at iteration 1444! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_1BLOCK_best_val_loss_seed1234.pth
2022-01-14 12:01:40,699 iteration 1445 : loss : 0.059063, loss_ce: 0.020583
 21%|██████▍                       | 85/400 [26:14<1:44:22, 19.88s/it]2022-01-14 12:01:41,840 iteration 1446 : loss : 0.055619, loss_ce: 0.018409
2022-01-14 12:01:42,825 iteration 1447 : loss : 0.058177, loss_ce: 0.020535
2022-01-14 12:01:43,767 iteration 1448 : loss : 0.069133, loss_ce: 0.035806
2022-01-14 12:01:44,798 iteration 1449 : loss : 0.081767, loss_ce: 0.032276
2022-01-14 12:01:45,903 iteration 1450 : loss : 0.070945, loss_ce: 0.033513
2022-01-14 12:01:47,016 iteration 1451 : loss : 0.084764, loss_ce: 0.030040
2022-01-14 12:01:47,990 iteration 1452 : loss : 0.047690, loss_ce: 0.015044
2022-01-14 12:01:48,973 iteration 1453 : loss : 0.075343, loss_ce: 0.035145
2022-01-14 12:01:50,002 iteration 1454 : loss : 0.080693, loss_ce: 0.031206
2022-01-14 12:01:50,971 iteration 1455 : loss : 0.048255, loss_ce: 0.020878
2022-01-14 12:01:52,049 iteration 1456 : loss : 0.142060, loss_ce: 0.045738
2022-01-14 12:01:53,048 iteration 1457 : loss : 0.071454, loss_ce: 0.031121
2022-01-14 12:01:54,037 iteration 1458 : loss : 0.071529, loss_ce: 0.023534
2022-01-14 12:01:54,994 iteration 1459 : loss : 0.063260, loss_ce: 0.018271
2022-01-14 12:01:56,064 iteration 1460 : loss : 0.095298, loss_ce: 0.043417
2022-01-14 12:01:57,077 iteration 1461 : loss : 0.067072, loss_ce: 0.029059
2022-01-14 12:01:58,131 iteration 1462 : loss : 0.079150, loss_ce: 0.034263
 22%|██████▍                       | 86/400 [26:32<1:40:12, 19.15s/it]2022-01-14 12:01:59,180 iteration 1463 : loss : 0.060649, loss_ce: 0.026546
2022-01-14 12:02:00,153 iteration 1464 : loss : 0.066047, loss_ce: 0.028964
2022-01-14 12:02:01,182 iteration 1465 : loss : 0.078326, loss_ce: 0.027007
2022-01-14 12:02:02,213 iteration 1466 : loss : 0.058678, loss_ce: 0.025867
2022-01-14 12:02:03,229 iteration 1467 : loss : 0.063010, loss_ce: 0.028836
2022-01-14 12:02:04,219 iteration 1468 : loss : 0.053107, loss_ce: 0.025596
2022-01-14 12:02:05,224 iteration 1469 : loss : 0.059668, loss_ce: 0.023369
2022-01-14 12:02:06,259 iteration 1470 : loss : 0.099754, loss_ce: 0.037007
2022-01-14 12:02:07,282 iteration 1471 : loss : 0.075686, loss_ce: 0.043370
2022-01-14 12:02:08,184 iteration 1472 : loss : 0.049940, loss_ce: 0.018836
2022-01-14 12:02:09,265 iteration 1473 : loss : 0.062637, loss_ce: 0.022482
2022-01-14 12:02:10,313 iteration 1474 : loss : 0.083646, loss_ce: 0.027949
2022-01-14 12:02:11,310 iteration 1475 : loss : 0.054296, loss_ce: 0.028546
2022-01-14 12:02:12,396 iteration 1476 : loss : 0.113348, loss_ce: 0.037352
2022-01-14 12:02:13,455 iteration 1477 : loss : 0.058867, loss_ce: 0.019774
2022-01-14 12:02:14,537 iteration 1478 : loss : 0.064780, loss_ce: 0.026662
2022-01-14 12:02:15,499 iteration 1479 : loss : 0.066468, loss_ce: 0.023477
 22%|██████▌                       | 87/400 [26:49<1:37:06, 18.61s/it]2022-01-14 12:02:16,561 iteration 1480 : loss : 0.068522, loss_ce: 0.024659
2022-01-14 12:02:17,539 iteration 1481 : loss : 0.059602, loss_ce: 0.024333
2022-01-14 12:02:18,533 iteration 1482 : loss : 0.063263, loss_ce: 0.024987
2022-01-14 12:02:19,613 iteration 1483 : loss : 0.055125, loss_ce: 0.021434
2022-01-14 12:02:20,756 iteration 1484 : loss : 0.076848, loss_ce: 0.026249
2022-01-14 12:02:21,824 iteration 1485 : loss : 0.054476, loss_ce: 0.024232
2022-01-14 12:02:22,812 iteration 1486 : loss : 0.069322, loss_ce: 0.024785
2022-01-14 12:02:23,816 iteration 1487 : loss : 0.086776, loss_ce: 0.037732
2022-01-14 12:02:24,836 iteration 1488 : loss : 0.079001, loss_ce: 0.030349
2022-01-14 12:02:25,862 iteration 1489 : loss : 0.043930, loss_ce: 0.016714
2022-01-14 12:02:26,905 iteration 1490 : loss : 0.082246, loss_ce: 0.032737
2022-01-14 12:02:27,991 iteration 1491 : loss : 0.064964, loss_ce: 0.027092
2022-01-14 12:02:28,966 iteration 1492 : loss : 0.057208, loss_ce: 0.022940
2022-01-14 12:02:30,015 iteration 1493 : loss : 0.063957, loss_ce: 0.020988
2022-01-14 12:02:30,995 iteration 1494 : loss : 0.068130, loss_ce: 0.027498
2022-01-14 12:02:31,978 iteration 1495 : loss : 0.069551, loss_ce: 0.029349
2022-01-14 12:02:32,984 iteration 1496 : loss : 0.092966, loss_ce: 0.035018
 22%|██████▌                       | 88/400 [27:07<1:35:01, 18.27s/it]2022-01-14 12:02:33,998 iteration 1497 : loss : 0.093632, loss_ce: 0.053946
2022-01-14 12:02:34,970 iteration 1498 : loss : 0.054140, loss_ce: 0.016963
2022-01-14 12:02:36,004 iteration 1499 : loss : 0.063042, loss_ce: 0.025942
2022-01-14 12:02:36,945 iteration 1500 : loss : 0.071686, loss_ce: 0.023348
2022-01-14 12:02:37,937 iteration 1501 : loss : 0.053762, loss_ce: 0.018552
2022-01-14 12:02:38,974 iteration 1502 : loss : 0.059892, loss_ce: 0.023430
2022-01-14 12:02:39,959 iteration 1503 : loss : 0.036696, loss_ce: 0.016830
2022-01-14 12:02:40,943 iteration 1504 : loss : 0.060334, loss_ce: 0.019858
2022-01-14 12:02:41,882 iteration 1505 : loss : 0.044079, loss_ce: 0.015736
2022-01-14 12:02:42,871 iteration 1506 : loss : 0.084189, loss_ce: 0.031674
2022-01-14 12:02:43,866 iteration 1507 : loss : 0.069284, loss_ce: 0.023768
2022-01-14 12:02:44,832 iteration 1508 : loss : 0.092985, loss_ce: 0.045987
2022-01-14 12:02:45,816 iteration 1509 : loss : 0.063346, loss_ce: 0.023144
2022-01-14 12:02:46,767 iteration 1510 : loss : 0.042305, loss_ce: 0.015882
2022-01-14 12:02:47,783 iteration 1511 : loss : 0.054874, loss_ce: 0.026934
2022-01-14 12:02:48,744 iteration 1512 : loss : 0.054629, loss_ce: 0.021360
2022-01-14 12:02:49,753 iteration 1513 : loss : 0.062112, loss_ce: 0.031373
 22%|██████▋                       | 89/400 [27:23<1:32:22, 17.82s/it]2022-01-14 12:02:50,779 iteration 1514 : loss : 0.061930, loss_ce: 0.022292
2022-01-14 12:02:51,776 iteration 1515 : loss : 0.051760, loss_ce: 0.019860
2022-01-14 12:02:52,793 iteration 1516 : loss : 0.088253, loss_ce: 0.036873
2022-01-14 12:02:53,781 iteration 1517 : loss : 0.051503, loss_ce: 0.024194
2022-01-14 12:02:54,806 iteration 1518 : loss : 0.047737, loss_ce: 0.015181
2022-01-14 12:02:55,787 iteration 1519 : loss : 0.053864, loss_ce: 0.021185
2022-01-14 12:02:56,756 iteration 1520 : loss : 0.053305, loss_ce: 0.019010
2022-01-14 12:02:57,731 iteration 1521 : loss : 0.060497, loss_ce: 0.022962
2022-01-14 12:02:58,828 iteration 1522 : loss : 0.058123, loss_ce: 0.019701
2022-01-14 12:02:59,777 iteration 1523 : loss : 0.067948, loss_ce: 0.030688
2022-01-14 12:03:00,797 iteration 1524 : loss : 0.084813, loss_ce: 0.033289
2022-01-14 12:03:01,769 iteration 1525 : loss : 0.047853, loss_ce: 0.020927
2022-01-14 12:03:02,873 iteration 1526 : loss : 0.051270, loss_ce: 0.023045
2022-01-14 12:03:03,936 iteration 1527 : loss : 0.081046, loss_ce: 0.036167
2022-01-14 12:03:04,976 iteration 1528 : loss : 0.058532, loss_ce: 0.024863
2022-01-14 12:03:05,944 iteration 1529 : loss : 0.054491, loss_ce: 0.019854
2022-01-14 12:03:05,944 Training Data Eval:
2022-01-14 12:03:10,762   Average segmentation loss on training set: 0.0425
2022-01-14 12:03:10,763 Validation Data Eval:
2022-01-14 12:03:12,378   Average segmentation loss on validation set: 0.1057
2022-01-14 12:03:13,361 iteration 1530 : loss : 0.079049, loss_ce: 0.033367
 22%|██████▊                       | 90/400 [27:47<1:41:03, 19.56s/it]2022-01-14 12:03:14,534 iteration 1531 : loss : 0.061456, loss_ce: 0.023883
2022-01-14 12:03:15,579 iteration 1532 : loss : 0.065818, loss_ce: 0.022467
2022-01-14 12:03:16,547 iteration 1533 : loss : 0.050155, loss_ce: 0.020447
2022-01-14 12:03:17,606 iteration 1534 : loss : 0.078857, loss_ce: 0.025797
2022-01-14 12:03:18,597 iteration 1535 : loss : 0.042918, loss_ce: 0.016937
2022-01-14 12:03:19,567 iteration 1536 : loss : 0.092152, loss_ce: 0.053679
2022-01-14 12:03:20,526 iteration 1537 : loss : 0.063654, loss_ce: 0.021305
2022-01-14 12:03:21,470 iteration 1538 : loss : 0.161248, loss_ce: 0.033118
2022-01-14 12:03:22,456 iteration 1539 : loss : 0.059982, loss_ce: 0.024253
2022-01-14 12:03:23,450 iteration 1540 : loss : 0.062925, loss_ce: 0.029408
2022-01-14 12:03:24,362 iteration 1541 : loss : 0.047080, loss_ce: 0.016031
2022-01-14 12:03:25,364 iteration 1542 : loss : 0.060526, loss_ce: 0.029357
2022-01-14 12:03:26,335 iteration 1543 : loss : 0.048777, loss_ce: 0.018159
2022-01-14 12:03:27,266 iteration 1544 : loss : 0.051481, loss_ce: 0.018474
2022-01-14 12:03:28,248 iteration 1545 : loss : 0.062773, loss_ce: 0.026350
2022-01-14 12:03:29,224 iteration 1546 : loss : 0.066628, loss_ce: 0.029779
2022-01-14 12:03:30,200 iteration 1547 : loss : 0.061689, loss_ce: 0.023396
 23%|██████▊                       | 91/400 [28:04<1:36:31, 18.74s/it]2022-01-14 12:03:31,253 iteration 1548 : loss : 0.051685, loss_ce: 0.019001
2022-01-14 12:03:32,193 iteration 1549 : loss : 0.040035, loss_ce: 0.017483
2022-01-14 12:03:33,286 iteration 1550 : loss : 0.055861, loss_ce: 0.022876
2022-01-14 12:03:34,275 iteration 1551 : loss : 0.059486, loss_ce: 0.025124
2022-01-14 12:03:35,271 iteration 1552 : loss : 0.066160, loss_ce: 0.031375
2022-01-14 12:03:36,183 iteration 1553 : loss : 0.038566, loss_ce: 0.020595
2022-01-14 12:03:37,132 iteration 1554 : loss : 0.074450, loss_ce: 0.027466
2022-01-14 12:03:38,180 iteration 1555 : loss : 0.052725, loss_ce: 0.018228
2022-01-14 12:03:39,301 iteration 1556 : loss : 0.046838, loss_ce: 0.017955
2022-01-14 12:03:40,373 iteration 1557 : loss : 0.099854, loss_ce: 0.027554
2022-01-14 12:03:41,381 iteration 1558 : loss : 0.072729, loss_ce: 0.022338
2022-01-14 12:03:42,478 iteration 1559 : loss : 0.080870, loss_ce: 0.034871
2022-01-14 12:03:43,458 iteration 1560 : loss : 0.069615, loss_ce: 0.019680
2022-01-14 12:03:44,440 iteration 1561 : loss : 0.069316, loss_ce: 0.024978
2022-01-14 12:03:45,448 iteration 1562 : loss : 0.057244, loss_ce: 0.024615
2022-01-14 12:03:46,474 iteration 1563 : loss : 0.066868, loss_ce: 0.039257
2022-01-14 12:03:47,481 iteration 1564 : loss : 0.081157, loss_ce: 0.026987
 23%|██████▉                       | 92/400 [28:21<1:33:58, 18.31s/it]2022-01-14 12:03:48,564 iteration 1565 : loss : 0.046520, loss_ce: 0.018839
2022-01-14 12:03:49,544 iteration 1566 : loss : 0.089372, loss_ce: 0.035377
2022-01-14 12:03:50,577 iteration 1567 : loss : 0.076622, loss_ce: 0.022200
2022-01-14 12:03:51,678 iteration 1568 : loss : 0.072975, loss_ce: 0.033210
2022-01-14 12:03:52,655 iteration 1569 : loss : 0.049302, loss_ce: 0.022555
2022-01-14 12:03:53,675 iteration 1570 : loss : 0.057908, loss_ce: 0.024319
2022-01-14 12:03:54,660 iteration 1571 : loss : 0.049877, loss_ce: 0.022285
2022-01-14 12:03:55,657 iteration 1572 : loss : 0.060577, loss_ce: 0.026157
2022-01-14 12:03:56,662 iteration 1573 : loss : 0.091848, loss_ce: 0.028752
2022-01-14 12:03:57,669 iteration 1574 : loss : 0.054760, loss_ce: 0.029168
2022-01-14 12:03:58,691 iteration 1575 : loss : 0.069349, loss_ce: 0.027156
2022-01-14 12:03:59,671 iteration 1576 : loss : 0.046407, loss_ce: 0.016697
2022-01-14 12:04:00,625 iteration 1577 : loss : 0.098162, loss_ce: 0.037605
2022-01-14 12:04:01,528 iteration 1578 : loss : 0.046168, loss_ce: 0.018621
2022-01-14 12:04:02,509 iteration 1579 : loss : 0.035818, loss_ce: 0.013319
2022-01-14 12:04:03,555 iteration 1580 : loss : 0.049538, loss_ce: 0.016331
2022-01-14 12:04:04,578 iteration 1581 : loss : 0.051943, loss_ce: 0.020392
 23%|██████▉                       | 93/400 [28:38<1:31:48, 17.94s/it]2022-01-14 12:04:05,686 iteration 1582 : loss : 0.067955, loss_ce: 0.037258
2022-01-14 12:04:06,687 iteration 1583 : loss : 0.063108, loss_ce: 0.019143
2022-01-14 12:04:07,638 iteration 1584 : loss : 0.064140, loss_ce: 0.020308
2022-01-14 12:04:08,616 iteration 1585 : loss : 0.043343, loss_ce: 0.018997
2022-01-14 12:04:09,534 iteration 1586 : loss : 0.048194, loss_ce: 0.022590
2022-01-14 12:04:10,498 iteration 1587 : loss : 0.062403, loss_ce: 0.023232
2022-01-14 12:04:11,472 iteration 1588 : loss : 0.037760, loss_ce: 0.011802
2022-01-14 12:04:12,467 iteration 1589 : loss : 0.052336, loss_ce: 0.021267
2022-01-14 12:04:13,542 iteration 1590 : loss : 0.077871, loss_ce: 0.023999
2022-01-14 12:04:14,520 iteration 1591 : loss : 0.050734, loss_ce: 0.025830
2022-01-14 12:04:15,436 iteration 1592 : loss : 0.034535, loss_ce: 0.015637
2022-01-14 12:04:16,442 iteration 1593 : loss : 0.066221, loss_ce: 0.021447
2022-01-14 12:04:17,426 iteration 1594 : loss : 0.065633, loss_ce: 0.020829
2022-01-14 12:04:18,370 iteration 1595 : loss : 0.048904, loss_ce: 0.025037
2022-01-14 12:04:19,285 iteration 1596 : loss : 0.068131, loss_ce: 0.024735
2022-01-14 12:04:20,290 iteration 1597 : loss : 0.096065, loss_ce: 0.026208
2022-01-14 12:04:21,314 iteration 1598 : loss : 0.073892, loss_ce: 0.025667
 24%|███████                       | 94/400 [28:55<1:29:39, 17.58s/it]2022-01-14 12:04:22,404 iteration 1599 : loss : 0.054687, loss_ce: 0.023705
2022-01-14 12:04:23,381 iteration 1600 : loss : 0.040890, loss_ce: 0.019255
2022-01-14 12:04:24,408 iteration 1601 : loss : 0.065365, loss_ce: 0.025304
2022-01-14 12:04:25,420 iteration 1602 : loss : 0.077755, loss_ce: 0.021626
2022-01-14 12:04:26,408 iteration 1603 : loss : 0.052070, loss_ce: 0.022256
2022-01-14 12:04:27,382 iteration 1604 : loss : 0.060449, loss_ce: 0.015625
2022-01-14 12:04:28,365 iteration 1605 : loss : 0.076872, loss_ce: 0.028850
2022-01-14 12:04:29,376 iteration 1606 : loss : 0.040216, loss_ce: 0.016804
2022-01-14 12:04:30,362 iteration 1607 : loss : 0.059936, loss_ce: 0.023960
2022-01-14 12:04:31,441 iteration 1608 : loss : 0.083092, loss_ce: 0.038147
2022-01-14 12:04:32,419 iteration 1609 : loss : 0.046345, loss_ce: 0.016176
2022-01-14 12:04:33,504 iteration 1610 : loss : 0.048693, loss_ce: 0.018367
2022-01-14 12:04:34,587 iteration 1611 : loss : 0.056025, loss_ce: 0.027698
2022-01-14 12:04:35,682 iteration 1612 : loss : 0.039459, loss_ce: 0.016550
2022-01-14 12:04:36,693 iteration 1613 : loss : 0.064775, loss_ce: 0.023509
2022-01-14 12:04:37,786 iteration 1614 : loss : 0.055524, loss_ce: 0.024657
2022-01-14 12:04:37,786 Training Data Eval:
2022-01-14 12:04:42,600   Average segmentation loss on training set: 0.0639
2022-01-14 12:04:42,600 Validation Data Eval:
2022-01-14 12:04:44,214   Average segmentation loss on validation set: 0.0835
2022-01-14 12:04:45,413 Found new lowest validation loss at iteration 1614! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_1BLOCK_best_val_loss_seed1234.pth
2022-01-14 12:04:46,460 iteration 1615 : loss : 0.066774, loss_ce: 0.021351
 24%|███████▏                      | 95/400 [29:20<1:40:54, 19.85s/it]2022-01-14 12:04:47,521 iteration 1616 : loss : 0.057073, loss_ce: 0.022947
2022-01-14 12:04:48,508 iteration 1617 : loss : 0.047294, loss_ce: 0.021546
2022-01-14 12:04:49,451 iteration 1618 : loss : 0.056961, loss_ce: 0.017581
2022-01-14 12:04:50,438 iteration 1619 : loss : 0.066923, loss_ce: 0.037239
2022-01-14 12:04:51,546 iteration 1620 : loss : 0.065430, loss_ce: 0.022257
2022-01-14 12:04:52,656 iteration 1621 : loss : 0.054026, loss_ce: 0.020047
2022-01-14 12:04:53,655 iteration 1622 : loss : 0.071365, loss_ce: 0.027950
2022-01-14 12:04:54,609 iteration 1623 : loss : 0.077579, loss_ce: 0.024290
2022-01-14 12:04:55,634 iteration 1624 : loss : 0.057109, loss_ce: 0.023083
2022-01-14 12:04:56,572 iteration 1625 : loss : 0.039424, loss_ce: 0.014021
2022-01-14 12:04:57,550 iteration 1626 : loss : 0.046624, loss_ce: 0.019128
2022-01-14 12:04:58,663 iteration 1627 : loss : 0.064385, loss_ce: 0.025171
2022-01-14 12:04:59,754 iteration 1628 : loss : 0.059139, loss_ce: 0.025414
2022-01-14 12:05:00,730 iteration 1629 : loss : 0.038638, loss_ce: 0.014886
2022-01-14 12:05:01,682 iteration 1630 : loss : 0.034436, loss_ce: 0.013748
2022-01-14 12:05:02,638 iteration 1631 : loss : 0.072993, loss_ce: 0.023121
2022-01-14 12:05:03,604 iteration 1632 : loss : 0.036089, loss_ce: 0.015300
 24%|███████▏                      | 96/400 [29:37<1:36:27, 19.04s/it]2022-01-14 12:05:04,662 iteration 1633 : loss : 0.061815, loss_ce: 0.022359
2022-01-14 12:05:05,683 iteration 1634 : loss : 0.066857, loss_ce: 0.027650
2022-01-14 12:05:06,661 iteration 1635 : loss : 0.067352, loss_ce: 0.023623
2022-01-14 12:05:07,592 iteration 1636 : loss : 0.042934, loss_ce: 0.021654
2022-01-14 12:05:08,617 iteration 1637 : loss : 0.049892, loss_ce: 0.018183
2022-01-14 12:05:09,614 iteration 1638 : loss : 0.058975, loss_ce: 0.024922
2022-01-14 12:05:10,664 iteration 1639 : loss : 0.049529, loss_ce: 0.020908
2022-01-14 12:05:11,633 iteration 1640 : loss : 0.066869, loss_ce: 0.021786
2022-01-14 12:05:12,707 iteration 1641 : loss : 0.048374, loss_ce: 0.017436
2022-01-14 12:05:13,659 iteration 1642 : loss : 0.044889, loss_ce: 0.016478
2022-01-14 12:05:14,591 iteration 1643 : loss : 0.047345, loss_ce: 0.017182
2022-01-14 12:05:15,641 iteration 1644 : loss : 0.050096, loss_ce: 0.020186
2022-01-14 12:05:16,725 iteration 1645 : loss : 0.041495, loss_ce: 0.018334
2022-01-14 12:05:17,688 iteration 1646 : loss : 0.052478, loss_ce: 0.019922
2022-01-14 12:05:18,669 iteration 1647 : loss : 0.065453, loss_ce: 0.025706
2022-01-14 12:05:19,585 iteration 1648 : loss : 0.043521, loss_ce: 0.018491
2022-01-14 12:05:20,520 iteration 1649 : loss : 0.047914, loss_ce: 0.019750
 24%|███████▎                      | 97/400 [29:54<1:32:55, 18.40s/it]2022-01-14 12:05:21,713 iteration 1650 : loss : 0.068346, loss_ce: 0.035843
2022-01-14 12:05:22,693 iteration 1651 : loss : 0.084122, loss_ce: 0.033237
2022-01-14 12:05:23,703 iteration 1652 : loss : 0.068892, loss_ce: 0.020367
2022-01-14 12:05:24,669 iteration 1653 : loss : 0.044689, loss_ce: 0.017361
2022-01-14 12:05:25,647 iteration 1654 : loss : 0.056118, loss_ce: 0.017919
2022-01-14 12:05:26,594 iteration 1655 : loss : 0.062328, loss_ce: 0.024114
2022-01-14 12:05:27,628 iteration 1656 : loss : 0.063174, loss_ce: 0.026596
2022-01-14 12:05:28,608 iteration 1657 : loss : 0.051320, loss_ce: 0.023145
2022-01-14 12:05:29,661 iteration 1658 : loss : 0.068766, loss_ce: 0.041490
2022-01-14 12:05:30,740 iteration 1659 : loss : 0.050995, loss_ce: 0.022802
2022-01-14 12:05:31,748 iteration 1660 : loss : 0.037008, loss_ce: 0.013892
2022-01-14 12:05:32,690 iteration 1661 : loss : 0.050514, loss_ce: 0.017867
2022-01-14 12:05:33,725 iteration 1662 : loss : 0.044662, loss_ce: 0.015812
2022-01-14 12:05:34,782 iteration 1663 : loss : 0.044246, loss_ce: 0.020064
2022-01-14 12:05:35,782 iteration 1664 : loss : 0.056576, loss_ce: 0.020767
2022-01-14 12:05:36,761 iteration 1665 : loss : 0.053501, loss_ce: 0.025879
2022-01-14 12:05:37,775 iteration 1666 : loss : 0.049584, loss_ce: 0.014093
 24%|███████▎                      | 98/400 [30:11<1:30:52, 18.05s/it]2022-01-14 12:05:38,782 iteration 1667 : loss : 0.049881, loss_ce: 0.025358
2022-01-14 12:05:39,853 iteration 1668 : loss : 0.066640, loss_ce: 0.022784
2022-01-14 12:05:40,888 iteration 1669 : loss : 0.062871, loss_ce: 0.021680
2022-01-14 12:05:41,815 iteration 1670 : loss : 0.034856, loss_ce: 0.011857
2022-01-14 12:05:42,758 iteration 1671 : loss : 0.041073, loss_ce: 0.017305
2022-01-14 12:05:43,817 iteration 1672 : loss : 0.055027, loss_ce: 0.021730
2022-01-14 12:05:44,852 iteration 1673 : loss : 0.055661, loss_ce: 0.017462
2022-01-14 12:05:45,946 iteration 1674 : loss : 0.063864, loss_ce: 0.022977
2022-01-14 12:05:46,929 iteration 1675 : loss : 0.060476, loss_ce: 0.019388
2022-01-14 12:05:47,998 iteration 1676 : loss : 0.049494, loss_ce: 0.021846
2022-01-14 12:05:49,020 iteration 1677 : loss : 0.084619, loss_ce: 0.025122
2022-01-14 12:05:50,061 iteration 1678 : loss : 0.047269, loss_ce: 0.020297
2022-01-14 12:05:51,044 iteration 1679 : loss : 0.093464, loss_ce: 0.052786
2022-01-14 12:05:52,071 iteration 1680 : loss : 0.066949, loss_ce: 0.032493
2022-01-14 12:05:53,057 iteration 1681 : loss : 0.050378, loss_ce: 0.020706
2022-01-14 12:05:54,058 iteration 1682 : loss : 0.054338, loss_ce: 0.024394
2022-01-14 12:05:55,025 iteration 1683 : loss : 0.062167, loss_ce: 0.030069
 25%|███████▍                      | 99/400 [30:29<1:29:22, 17.82s/it]2022-01-14 12:05:56,111 iteration 1684 : loss : 0.063391, loss_ce: 0.025385
2022-01-14 12:05:57,072 iteration 1685 : loss : 0.051481, loss_ce: 0.023281
2022-01-14 12:05:58,002 iteration 1686 : loss : 0.040996, loss_ce: 0.014956
2022-01-14 12:05:58,967 iteration 1687 : loss : 0.064333, loss_ce: 0.027908
2022-01-14 12:05:59,976 iteration 1688 : loss : 0.051585, loss_ce: 0.024490
2022-01-14 12:06:00,936 iteration 1689 : loss : 0.061499, loss_ce: 0.020213
2022-01-14 12:06:01,965 iteration 1690 : loss : 0.097868, loss_ce: 0.036697
2022-01-14 12:06:02,954 iteration 1691 : loss : 0.040441, loss_ce: 0.015820
2022-01-14 12:06:04,002 iteration 1692 : loss : 0.076454, loss_ce: 0.030045
2022-01-14 12:06:05,062 iteration 1693 : loss : 0.039958, loss_ce: 0.017798
2022-01-14 12:06:06,090 iteration 1694 : loss : 0.044365, loss_ce: 0.015648
2022-01-14 12:06:07,014 iteration 1695 : loss : 0.046266, loss_ce: 0.015014
2022-01-14 12:06:07,995 iteration 1696 : loss : 0.054782, loss_ce: 0.019984
2022-01-14 12:06:09,039 iteration 1697 : loss : 0.072727, loss_ce: 0.023138
2022-01-14 12:06:10,026 iteration 1698 : loss : 0.039377, loss_ce: 0.011489
2022-01-14 12:06:10,926 iteration 1699 : loss : 0.056889, loss_ce: 0.031025
2022-01-14 12:06:10,926 Training Data Eval:
2022-01-14 12:06:15,749   Average segmentation loss on training set: 0.0366
2022-01-14 12:06:15,749 Validation Data Eval:
2022-01-14 12:06:17,366   Average segmentation loss on validation set: 0.1024
2022-01-14 12:06:18,380 iteration 1700 : loss : 0.054752, loss_ce: 0.016195
 25%|███████▎                     | 100/400 [30:52<1:37:22, 19.48s/it]2022-01-14 12:06:19,474 iteration 1701 : loss : 0.061154, loss_ce: 0.028119
2022-01-14 12:06:20,479 iteration 1702 : loss : 0.042438, loss_ce: 0.017556
2022-01-14 12:06:21,422 iteration 1703 : loss : 0.047834, loss_ce: 0.020109
2022-01-14 12:06:22,489 iteration 1704 : loss : 0.048339, loss_ce: 0.018089
2022-01-14 12:06:23,488 iteration 1705 : loss : 0.047394, loss_ce: 0.020650
2022-01-14 12:06:24,508 iteration 1706 : loss : 0.057499, loss_ce: 0.029392
2022-01-14 12:06:25,504 iteration 1707 : loss : 0.052972, loss_ce: 0.019923
2022-01-14 12:06:26,531 iteration 1708 : loss : 0.048048, loss_ce: 0.015942
2022-01-14 12:06:27,464 iteration 1709 : loss : 0.046638, loss_ce: 0.019503
2022-01-14 12:06:28,384 iteration 1710 : loss : 0.041559, loss_ce: 0.018903
2022-01-14 12:06:29,384 iteration 1711 : loss : 0.049144, loss_ce: 0.017441
2022-01-14 12:06:30,331 iteration 1712 : loss : 0.038702, loss_ce: 0.012587
2022-01-14 12:06:31,264 iteration 1713 : loss : 0.042126, loss_ce: 0.015382
2022-01-14 12:06:32,343 iteration 1714 : loss : 0.072519, loss_ce: 0.024119
2022-01-14 12:06:33,379 iteration 1715 : loss : 0.076488, loss_ce: 0.022973
2022-01-14 12:06:34,462 iteration 1716 : loss : 0.057842, loss_ce: 0.020405
2022-01-14 12:06:35,459 iteration 1717 : loss : 0.049879, loss_ce: 0.019011
 25%|███████▎                     | 101/400 [31:09<1:33:29, 18.76s/it]2022-01-14 12:06:36,484 iteration 1718 : loss : 0.050396, loss_ce: 0.017868
2022-01-14 12:06:37,498 iteration 1719 : loss : 0.061504, loss_ce: 0.026306
2022-01-14 12:06:38,404 iteration 1720 : loss : 0.044413, loss_ce: 0.015296
2022-01-14 12:06:39,388 iteration 1721 : loss : 0.056947, loss_ce: 0.025345
2022-01-14 12:06:40,430 iteration 1722 : loss : 0.061304, loss_ce: 0.020350
2022-01-14 12:06:41,425 iteration 1723 : loss : 0.075258, loss_ce: 0.031021
2022-01-14 12:06:42,466 iteration 1724 : loss : 0.041480, loss_ce: 0.013846
2022-01-14 12:06:43,586 iteration 1725 : loss : 0.082571, loss_ce: 0.030446
2022-01-14 12:06:44,657 iteration 1726 : loss : 0.066519, loss_ce: 0.019214
2022-01-14 12:06:45,665 iteration 1727 : loss : 0.043378, loss_ce: 0.022339
2022-01-14 12:06:46,649 iteration 1728 : loss : 0.050155, loss_ce: 0.016168
2022-01-14 12:06:47,638 iteration 1729 : loss : 0.050823, loss_ce: 0.024763
2022-01-14 12:06:48,652 iteration 1730 : loss : 0.042852, loss_ce: 0.016445
2022-01-14 12:06:49,723 iteration 1731 : loss : 0.057466, loss_ce: 0.019201
2022-01-14 12:06:50,729 iteration 1732 : loss : 0.035731, loss_ce: 0.017722
2022-01-14 12:06:51,804 iteration 1733 : loss : 0.067090, loss_ce: 0.031192
2022-01-14 12:06:52,761 iteration 1734 : loss : 0.047306, loss_ce: 0.016660
 26%|███████▍                     | 102/400 [31:26<1:30:59, 18.32s/it]2022-01-14 12:06:53,775 iteration 1735 : loss : 0.056439, loss_ce: 0.021781
2022-01-14 12:06:54,760 iteration 1736 : loss : 0.035915, loss_ce: 0.015064
2022-01-14 12:06:55,758 iteration 1737 : loss : 0.052228, loss_ce: 0.024126
2022-01-14 12:06:56,730 iteration 1738 : loss : 0.043703, loss_ce: 0.015667
2022-01-14 12:06:57,826 iteration 1739 : loss : 0.055224, loss_ce: 0.024935
2022-01-14 12:06:58,864 iteration 1740 : loss : 0.060997, loss_ce: 0.023192
2022-01-14 12:06:59,855 iteration 1741 : loss : 0.048443, loss_ce: 0.017965
2022-01-14 12:07:00,955 iteration 1742 : loss : 0.056845, loss_ce: 0.026865
2022-01-14 12:07:01,945 iteration 1743 : loss : 0.052311, loss_ce: 0.014260
2022-01-14 12:07:02,973 iteration 1744 : loss : 0.048623, loss_ce: 0.019126
2022-01-14 12:07:04,119 iteration 1745 : loss : 0.070404, loss_ce: 0.042043
2022-01-14 12:07:05,112 iteration 1746 : loss : 0.046075, loss_ce: 0.020617
2022-01-14 12:07:06,091 iteration 1747 : loss : 0.045975, loss_ce: 0.019349
2022-01-14 12:07:07,095 iteration 1748 : loss : 0.052166, loss_ce: 0.022037
2022-01-14 12:07:08,093 iteration 1749 : loss : 0.054281, loss_ce: 0.018183
2022-01-14 12:07:09,041 iteration 1750 : loss : 0.052167, loss_ce: 0.024415
2022-01-14 12:07:10,127 iteration 1751 : loss : 0.086288, loss_ce: 0.035195
 26%|███████▍                     | 103/400 [31:44<1:29:15, 18.03s/it]2022-01-14 12:07:11,157 iteration 1752 : loss : 0.037376, loss_ce: 0.014240
2022-01-14 12:07:12,121 iteration 1753 : loss : 0.049225, loss_ce: 0.023743
2022-01-14 12:07:13,097 iteration 1754 : loss : 0.042583, loss_ce: 0.016914
2022-01-14 12:07:14,087 iteration 1755 : loss : 0.056401, loss_ce: 0.026000
2022-01-14 12:07:15,098 iteration 1756 : loss : 0.058781, loss_ce: 0.025920
2022-01-14 12:07:16,166 iteration 1757 : loss : 0.056995, loss_ce: 0.027140
2022-01-14 12:07:17,206 iteration 1758 : loss : 0.087304, loss_ce: 0.030867
2022-01-14 12:07:18,137 iteration 1759 : loss : 0.067733, loss_ce: 0.024129
2022-01-14 12:07:19,121 iteration 1760 : loss : 0.057168, loss_ce: 0.022829
2022-01-14 12:07:20,076 iteration 1761 : loss : 0.048704, loss_ce: 0.018885
2022-01-14 12:07:21,067 iteration 1762 : loss : 0.072631, loss_ce: 0.030385
2022-01-14 12:07:21,985 iteration 1763 : loss : 0.068817, loss_ce: 0.030261
2022-01-14 12:07:23,082 iteration 1764 : loss : 0.068306, loss_ce: 0.020808
2022-01-14 12:07:24,095 iteration 1765 : loss : 0.098430, loss_ce: 0.034423
2022-01-14 12:07:25,149 iteration 1766 : loss : 0.059576, loss_ce: 0.023471
2022-01-14 12:07:26,170 iteration 1767 : loss : 0.068670, loss_ce: 0.029258
2022-01-14 12:07:27,161 iteration 1768 : loss : 0.067410, loss_ce: 0.027210
 26%|███████▌                     | 104/400 [32:01<1:27:30, 17.74s/it]2022-01-14 12:07:28,256 iteration 1769 : loss : 0.086237, loss_ce: 0.030852
2022-01-14 12:07:29,242 iteration 1770 : loss : 0.057600, loss_ce: 0.022070
2022-01-14 12:07:30,197 iteration 1771 : loss : 0.039544, loss_ce: 0.013168
2022-01-14 12:07:31,257 iteration 1772 : loss : 0.088406, loss_ce: 0.042260
2022-01-14 12:07:32,284 iteration 1773 : loss : 0.060330, loss_ce: 0.023582
2022-01-14 12:07:33,254 iteration 1774 : loss : 0.053434, loss_ce: 0.019509
2022-01-14 12:07:34,230 iteration 1775 : loss : 0.055754, loss_ce: 0.021322
2022-01-14 12:07:35,196 iteration 1776 : loss : 0.063054, loss_ce: 0.022267
2022-01-14 12:07:36,142 iteration 1777 : loss : 0.050003, loss_ce: 0.019521
2022-01-14 12:07:37,178 iteration 1778 : loss : 0.081085, loss_ce: 0.036538
2022-01-14 12:07:38,178 iteration 1779 : loss : 0.058831, loss_ce: 0.024524
2022-01-14 12:07:39,200 iteration 1780 : loss : 0.104390, loss_ce: 0.040202
2022-01-14 12:07:40,221 iteration 1781 : loss : 0.065060, loss_ce: 0.025249
2022-01-14 12:07:41,149 iteration 1782 : loss : 0.089190, loss_ce: 0.024709
2022-01-14 12:07:42,107 iteration 1783 : loss : 0.079276, loss_ce: 0.035511
2022-01-14 12:07:43,133 iteration 1784 : loss : 0.080605, loss_ce: 0.040212
2022-01-14 12:07:43,134 Training Data Eval:
2022-01-14 12:07:47,949   Average segmentation loss on training set: 0.0488
2022-01-14 12:07:47,950 Validation Data Eval:
2022-01-14 12:07:49,558   Average segmentation loss on validation set: 0.0823
2022-01-14 12:07:50,775 Found new lowest validation loss at iteration 1784! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_1BLOCK_best_val_loss_seed1234.pth
2022-01-14 12:07:51,802 iteration 1785 : loss : 0.077939, loss_ce: 0.046657
 26%|███████▌                     | 105/400 [32:25<1:37:23, 19.81s/it]2022-01-14 12:07:52,899 iteration 1786 : loss : 0.070732, loss_ce: 0.020527
2022-01-14 12:07:53,844 iteration 1787 : loss : 0.070933, loss_ce: 0.016527
2022-01-14 12:07:54,854 iteration 1788 : loss : 0.054720, loss_ce: 0.019241
2022-01-14 12:07:55,870 iteration 1789 : loss : 0.052173, loss_ce: 0.025554
2022-01-14 12:07:57,012 iteration 1790 : loss : 0.057754, loss_ce: 0.019345
2022-01-14 12:07:58,030 iteration 1791 : loss : 0.053762, loss_ce: 0.023763
2022-01-14 12:07:59,053 iteration 1792 : loss : 0.047639, loss_ce: 0.016984
2022-01-14 12:08:00,086 iteration 1793 : loss : 0.079420, loss_ce: 0.028734
2022-01-14 12:08:01,073 iteration 1794 : loss : 0.059172, loss_ce: 0.030504
2022-01-14 12:08:01,976 iteration 1795 : loss : 0.044305, loss_ce: 0.018139
2022-01-14 12:08:03,049 iteration 1796 : loss : 0.055834, loss_ce: 0.023638
2022-01-14 12:08:04,009 iteration 1797 : loss : 0.051264, loss_ce: 0.021356
2022-01-14 12:08:05,018 iteration 1798 : loss : 0.049452, loss_ce: 0.018557
2022-01-14 12:08:06,082 iteration 1799 : loss : 0.067359, loss_ce: 0.024896
2022-01-14 12:08:07,027 iteration 1800 : loss : 0.057604, loss_ce: 0.017943
2022-01-14 12:08:08,025 iteration 1801 : loss : 0.079189, loss_ce: 0.024467
2022-01-14 12:08:09,069 iteration 1802 : loss : 0.056696, loss_ce: 0.021921
 26%|███████▋                     | 106/400 [32:43<1:33:18, 19.04s/it]2022-01-14 12:08:10,172 iteration 1803 : loss : 0.059383, loss_ce: 0.023022
2022-01-14 12:08:11,112 iteration 1804 : loss : 0.045750, loss_ce: 0.015985
2022-01-14 12:08:12,236 iteration 1805 : loss : 0.072217, loss_ce: 0.025253
2022-01-14 12:08:13,331 iteration 1806 : loss : 0.072789, loss_ce: 0.038043
2022-01-14 12:08:14,331 iteration 1807 : loss : 0.064175, loss_ce: 0.026701
2022-01-14 12:08:15,374 iteration 1808 : loss : 0.048104, loss_ce: 0.020926
2022-01-14 12:08:16,354 iteration 1809 : loss : 0.047776, loss_ce: 0.022855
2022-01-14 12:08:17,417 iteration 1810 : loss : 0.061920, loss_ce: 0.035826
2022-01-14 12:08:18,401 iteration 1811 : loss : 0.057164, loss_ce: 0.019276
2022-01-14 12:08:19,378 iteration 1812 : loss : 0.052599, loss_ce: 0.018047
2022-01-14 12:08:20,379 iteration 1813 : loss : 0.056439, loss_ce: 0.026591
2022-01-14 12:08:21,355 iteration 1814 : loss : 0.057114, loss_ce: 0.019123
2022-01-14 12:08:22,427 iteration 1815 : loss : 0.070975, loss_ce: 0.025593
2022-01-14 12:08:23,442 iteration 1816 : loss : 0.041068, loss_ce: 0.016031
2022-01-14 12:08:24,520 iteration 1817 : loss : 0.059836, loss_ce: 0.021743
2022-01-14 12:08:25,474 iteration 1818 : loss : 0.035278, loss_ce: 0.013195
2022-01-14 12:08:26,534 iteration 1819 : loss : 0.071234, loss_ce: 0.028395
 27%|███████▊                     | 107/400 [33:00<1:30:41, 18.57s/it]2022-01-14 12:08:27,496 iteration 1820 : loss : 0.041351, loss_ce: 0.017818
2022-01-14 12:08:28,612 iteration 1821 : loss : 0.067511, loss_ce: 0.023701
2022-01-14 12:08:29,662 iteration 1822 : loss : 0.059640, loss_ce: 0.027729
2022-01-14 12:08:30,740 iteration 1823 : loss : 0.089298, loss_ce: 0.035999
2022-01-14 12:08:31,775 iteration 1824 : loss : 0.086895, loss_ce: 0.026130
2022-01-14 12:08:32,737 iteration 1825 : loss : 0.054571, loss_ce: 0.022752
2022-01-14 12:08:33,807 iteration 1826 : loss : 0.046189, loss_ce: 0.014158
2022-01-14 12:08:34,772 iteration 1827 : loss : 0.035129, loss_ce: 0.011961
2022-01-14 12:08:35,793 iteration 1828 : loss : 0.054800, loss_ce: 0.020631
2022-01-14 12:08:36,768 iteration 1829 : loss : 0.064676, loss_ce: 0.031875
2022-01-14 12:08:37,854 iteration 1830 : loss : 0.070851, loss_ce: 0.024622
2022-01-14 12:08:38,871 iteration 1831 : loss : 0.059916, loss_ce: 0.024451
2022-01-14 12:08:39,849 iteration 1832 : loss : 0.049308, loss_ce: 0.018800
2022-01-14 12:08:40,796 iteration 1833 : loss : 0.049052, loss_ce: 0.022505
2022-01-14 12:08:41,791 iteration 1834 : loss : 0.052862, loss_ce: 0.018051
2022-01-14 12:08:42,796 iteration 1835 : loss : 0.042315, loss_ce: 0.016281
2022-01-14 12:08:43,766 iteration 1836 : loss : 0.080901, loss_ce: 0.033015
 27%|███████▊                     | 108/400 [33:17<1:28:25, 18.17s/it]2022-01-14 12:08:44,865 iteration 1837 : loss : 0.063309, loss_ce: 0.023392
2022-01-14 12:08:45,793 iteration 1838 : loss : 0.040733, loss_ce: 0.018288
2022-01-14 12:08:46,755 iteration 1839 : loss : 0.059685, loss_ce: 0.023852
2022-01-14 12:08:47,778 iteration 1840 : loss : 0.036717, loss_ce: 0.015483
2022-01-14 12:08:48,727 iteration 1841 : loss : 0.053401, loss_ce: 0.021651
2022-01-14 12:08:49,711 iteration 1842 : loss : 0.041041, loss_ce: 0.013441
2022-01-14 12:08:50,732 iteration 1843 : loss : 0.034463, loss_ce: 0.016216
2022-01-14 12:08:51,719 iteration 1844 : loss : 0.042829, loss_ce: 0.013296
2022-01-14 12:08:52,693 iteration 1845 : loss : 0.034668, loss_ce: 0.010551
2022-01-14 12:08:53,762 iteration 1846 : loss : 0.038026, loss_ce: 0.017058
2022-01-14 12:08:54,729 iteration 1847 : loss : 0.049039, loss_ce: 0.018170
2022-01-14 12:08:55,717 iteration 1848 : loss : 0.056161, loss_ce: 0.021595
2022-01-14 12:08:56,682 iteration 1849 : loss : 0.059428, loss_ce: 0.023329
2022-01-14 12:08:57,800 iteration 1850 : loss : 0.070826, loss_ce: 0.028463
2022-01-14 12:08:58,801 iteration 1851 : loss : 0.077711, loss_ce: 0.023939
2022-01-14 12:08:59,825 iteration 1852 : loss : 0.060868, loss_ce: 0.027606
2022-01-14 12:09:00,797 iteration 1853 : loss : 0.055519, loss_ce: 0.023831
 27%|███████▉                     | 109/400 [33:34<1:26:28, 17.83s/it]2022-01-14 12:09:01,829 iteration 1854 : loss : 0.042142, loss_ce: 0.015815
2022-01-14 12:09:02,875 iteration 1855 : loss : 0.048625, loss_ce: 0.019857
2022-01-14 12:09:03,932 iteration 1856 : loss : 0.062078, loss_ce: 0.019906
2022-01-14 12:09:04,995 iteration 1857 : loss : 0.053457, loss_ce: 0.018024
2022-01-14 12:09:06,012 iteration 1858 : loss : 0.074123, loss_ce: 0.036355
2022-01-14 12:09:07,035 iteration 1859 : loss : 0.046454, loss_ce: 0.018597
2022-01-14 12:09:08,003 iteration 1860 : loss : 0.050606, loss_ce: 0.017789
2022-01-14 12:09:09,071 iteration 1861 : loss : 0.052347, loss_ce: 0.019920
2022-01-14 12:09:10,029 iteration 1862 : loss : 0.044842, loss_ce: 0.021435
2022-01-14 12:09:11,028 iteration 1863 : loss : 0.059314, loss_ce: 0.027643
2022-01-14 12:09:12,058 iteration 1864 : loss : 0.079010, loss_ce: 0.023193
2022-01-14 12:09:12,967 iteration 1865 : loss : 0.044550, loss_ce: 0.020399
2022-01-14 12:09:14,033 iteration 1866 : loss : 0.034808, loss_ce: 0.016548
2022-01-14 12:09:15,035 iteration 1867 : loss : 0.040166, loss_ce: 0.017677
2022-01-14 12:09:16,002 iteration 1868 : loss : 0.060686, loss_ce: 0.026464
2022-01-14 12:09:16,967 iteration 1869 : loss : 0.078708, loss_ce: 0.026792
2022-01-14 12:09:16,967 Training Data Eval:
2022-01-14 12:09:21,786   Average segmentation loss on training set: 0.0339
2022-01-14 12:09:21,786 Validation Data Eval:
2022-01-14 12:09:23,407   Average segmentation loss on validation set: 0.0829
2022-01-14 12:09:24,445 iteration 1870 : loss : 0.051199, loss_ce: 0.017648
 28%|███████▉                     | 110/400 [33:58<1:34:36, 19.58s/it]2022-01-14 12:09:25,552 iteration 1871 : loss : 0.044378, loss_ce: 0.018660
2022-01-14 12:09:26,656 iteration 1872 : loss : 0.107465, loss_ce: 0.034776
2022-01-14 12:09:27,608 iteration 1873 : loss : 0.059152, loss_ce: 0.021768
2022-01-14 12:09:28,677 iteration 1874 : loss : 0.067597, loss_ce: 0.033964
2022-01-14 12:09:29,600 iteration 1875 : loss : 0.046642, loss_ce: 0.017092
2022-01-14 12:09:30,678 iteration 1876 : loss : 0.038021, loss_ce: 0.011420
2022-01-14 12:09:31,722 iteration 1877 : loss : 0.074790, loss_ce: 0.031123
2022-01-14 12:09:32,696 iteration 1878 : loss : 0.043477, loss_ce: 0.016170
2022-01-14 12:09:33,662 iteration 1879 : loss : 0.043096, loss_ce: 0.016027
2022-01-14 12:09:34,624 iteration 1880 : loss : 0.062886, loss_ce: 0.028776
2022-01-14 12:09:35,619 iteration 1881 : loss : 0.056610, loss_ce: 0.021413
2022-01-14 12:09:36,570 iteration 1882 : loss : 0.053476, loss_ce: 0.019038
2022-01-14 12:09:37,487 iteration 1883 : loss : 0.051602, loss_ce: 0.017434
2022-01-14 12:09:38,524 iteration 1884 : loss : 0.054946, loss_ce: 0.022699
2022-01-14 12:09:39,439 iteration 1885 : loss : 0.038529, loss_ce: 0.015630
2022-01-14 12:09:40,511 iteration 1886 : loss : 0.061433, loss_ce: 0.028215
2022-01-14 12:09:41,579 iteration 1887 : loss : 0.056427, loss_ce: 0.026989
 28%|████████                     | 111/400 [34:15<1:30:44, 18.84s/it]2022-01-14 12:09:42,620 iteration 1888 : loss : 0.057091, loss_ce: 0.024968
2022-01-14 12:09:43,677 iteration 1889 : loss : 0.055812, loss_ce: 0.022419
2022-01-14 12:09:44,722 iteration 1890 : loss : 0.048497, loss_ce: 0.015644
2022-01-14 12:09:45,772 iteration 1891 : loss : 0.048874, loss_ce: 0.018235
2022-01-14 12:09:46,787 iteration 1892 : loss : 0.055151, loss_ce: 0.025035
2022-01-14 12:09:47,808 iteration 1893 : loss : 0.064098, loss_ce: 0.037920
2022-01-14 12:09:48,802 iteration 1894 : loss : 0.083307, loss_ce: 0.045405
2022-01-14 12:09:49,791 iteration 1895 : loss : 0.068944, loss_ce: 0.019886
2022-01-14 12:09:50,916 iteration 1896 : loss : 0.074900, loss_ce: 0.038582
2022-01-14 12:09:51,910 iteration 1897 : loss : 0.074304, loss_ce: 0.025260
2022-01-14 12:09:52,981 iteration 1898 : loss : 0.059716, loss_ce: 0.020332
2022-01-14 12:09:53,984 iteration 1899 : loss : 0.050775, loss_ce: 0.024710
2022-01-14 12:09:54,909 iteration 1900 : loss : 0.043763, loss_ce: 0.020282
2022-01-14 12:09:55,908 iteration 1901 : loss : 0.049655, loss_ce: 0.019746
2022-01-14 12:09:56,931 iteration 1902 : loss : 0.044271, loss_ce: 0.018180
2022-01-14 12:09:57,980 iteration 1903 : loss : 0.056642, loss_ce: 0.015495
2022-01-14 12:09:59,080 iteration 1904 : loss : 0.055994, loss_ce: 0.019758
 28%|████████                     | 112/400 [34:33<1:28:29, 18.44s/it]2022-01-14 12:10:00,093 iteration 1905 : loss : 0.039727, loss_ce: 0.016110
2022-01-14 12:10:01,158 iteration 1906 : loss : 0.043598, loss_ce: 0.015618
2022-01-14 12:10:02,271 iteration 1907 : loss : 0.056441, loss_ce: 0.021389
2022-01-14 12:10:03,315 iteration 1908 : loss : 0.045084, loss_ce: 0.019236
2022-01-14 12:10:04,389 iteration 1909 : loss : 0.056560, loss_ce: 0.027472
2022-01-14 12:10:05,449 iteration 1910 : loss : 0.060283, loss_ce: 0.027318
2022-01-14 12:10:06,578 iteration 1911 : loss : 0.054235, loss_ce: 0.023163
2022-01-14 12:10:07,628 iteration 1912 : loss : 0.043517, loss_ce: 0.013527
2022-01-14 12:10:08,628 iteration 1913 : loss : 0.039664, loss_ce: 0.014729
2022-01-14 12:10:09,595 iteration 1914 : loss : 0.037176, loss_ce: 0.016011
2022-01-14 12:10:10,605 iteration 1915 : loss : 0.072402, loss_ce: 0.028152
2022-01-14 12:10:11,606 iteration 1916 : loss : 0.053658, loss_ce: 0.021016
2022-01-14 12:10:12,635 iteration 1917 : loss : 0.056612, loss_ce: 0.020183
2022-01-14 12:10:13,599 iteration 1918 : loss : 0.051363, loss_ce: 0.022906
2022-01-14 12:10:14,593 iteration 1919 : loss : 0.038143, loss_ce: 0.018565
2022-01-14 12:10:15,591 iteration 1920 : loss : 0.045795, loss_ce: 0.016061
2022-01-14 12:10:16,631 iteration 1921 : loss : 0.057826, loss_ce: 0.022828
 28%|████████▏                    | 113/400 [34:50<1:26:55, 18.17s/it]2022-01-14 12:10:17,642 iteration 1922 : loss : 0.046810, loss_ce: 0.016510
2022-01-14 12:10:18,569 iteration 1923 : loss : 0.028058, loss_ce: 0.011683
2022-01-14 12:10:19,588 iteration 1924 : loss : 0.076693, loss_ce: 0.047663
2022-01-14 12:10:20,538 iteration 1925 : loss : 0.050395, loss_ce: 0.022891
2022-01-14 12:10:21,504 iteration 1926 : loss : 0.045195, loss_ce: 0.019610
2022-01-14 12:10:22,539 iteration 1927 : loss : 0.063612, loss_ce: 0.029269
2022-01-14 12:10:23,588 iteration 1928 : loss : 0.050176, loss_ce: 0.020547
2022-01-14 12:10:24,562 iteration 1929 : loss : 0.044292, loss_ce: 0.021859
2022-01-14 12:10:25,561 iteration 1930 : loss : 0.053929, loss_ce: 0.017651
2022-01-14 12:10:26,536 iteration 1931 : loss : 0.056580, loss_ce: 0.017066
2022-01-14 12:10:27,544 iteration 1932 : loss : 0.051361, loss_ce: 0.015773
2022-01-14 12:10:28,548 iteration 1933 : loss : 0.052433, loss_ce: 0.020016
2022-01-14 12:10:29,430 iteration 1934 : loss : 0.034495, loss_ce: 0.015580
2022-01-14 12:10:30,397 iteration 1935 : loss : 0.049545, loss_ce: 0.021972
2022-01-14 12:10:31,434 iteration 1936 : loss : 0.033440, loss_ce: 0.012126
2022-01-14 12:10:32,464 iteration 1937 : loss : 0.036989, loss_ce: 0.014190
2022-01-14 12:10:33,502 iteration 1938 : loss : 0.058725, loss_ce: 0.022415
 28%|████████▎                    | 114/400 [35:07<1:24:46, 17.79s/it]2022-01-14 12:10:34,506 iteration 1939 : loss : 0.031744, loss_ce: 0.013882
2022-01-14 12:10:35,481 iteration 1940 : loss : 0.030799, loss_ce: 0.011957
2022-01-14 12:10:36,529 iteration 1941 : loss : 0.039483, loss_ce: 0.017315
2022-01-14 12:10:37,523 iteration 1942 : loss : 0.056828, loss_ce: 0.018949
2022-01-14 12:10:38,445 iteration 1943 : loss : 0.035763, loss_ce: 0.013036
2022-01-14 12:10:39,413 iteration 1944 : loss : 0.035512, loss_ce: 0.013365
2022-01-14 12:10:40,394 iteration 1945 : loss : 0.039553, loss_ce: 0.020193
2022-01-14 12:10:41,379 iteration 1946 : loss : 0.049594, loss_ce: 0.018714
2022-01-14 12:10:42,355 iteration 1947 : loss : 0.063286, loss_ce: 0.022718
2022-01-14 12:10:43,325 iteration 1948 : loss : 0.040124, loss_ce: 0.018335
2022-01-14 12:10:44,248 iteration 1949 : loss : 0.044601, loss_ce: 0.025250
2022-01-14 12:10:45,280 iteration 1950 : loss : 0.049297, loss_ce: 0.018866
2022-01-14 12:10:46,374 iteration 1951 : loss : 0.064607, loss_ce: 0.025092
2022-01-14 12:10:47,320 iteration 1952 : loss : 0.054890, loss_ce: 0.016329
2022-01-14 12:10:48,332 iteration 1953 : loss : 0.049437, loss_ce: 0.025404
2022-01-14 12:10:49,401 iteration 1954 : loss : 0.062268, loss_ce: 0.021508
2022-01-14 12:10:49,402 Training Data Eval:
2022-01-14 12:10:54,210   Average segmentation loss on training set: 0.0353
2022-01-14 12:10:54,211 Validation Data Eval:
2022-01-14 12:10:55,827   Average segmentation loss on validation set: 0.0953
2022-01-14 12:10:56,801 iteration 1955 : loss : 0.034702, loss_ce: 0.013570
 29%|████████▎                    | 115/400 [35:30<1:32:19, 19.44s/it]2022-01-14 12:10:57,905 iteration 1956 : loss : 0.054215, loss_ce: 0.020448
2022-01-14 12:10:58,849 iteration 1957 : loss : 0.033417, loss_ce: 0.013329
2022-01-14 12:10:59,829 iteration 1958 : loss : 0.038006, loss_ce: 0.018130
2022-01-14 12:11:00,907 iteration 1959 : loss : 0.063540, loss_ce: 0.015885
2022-01-14 12:11:01,881 iteration 1960 : loss : 0.055168, loss_ce: 0.017606
2022-01-14 12:11:02,882 iteration 1961 : loss : 0.062049, loss_ce: 0.024381
2022-01-14 12:11:03,868 iteration 1962 : loss : 0.064837, loss_ce: 0.025435
2022-01-14 12:11:04,882 iteration 1963 : loss : 0.055197, loss_ce: 0.023733
2022-01-14 12:11:05,864 iteration 1964 : loss : 0.061994, loss_ce: 0.018436
2022-01-14 12:11:06,829 iteration 1965 : loss : 0.045184, loss_ce: 0.020169
2022-01-14 12:11:07,783 iteration 1966 : loss : 0.037091, loss_ce: 0.017960
2022-01-14 12:11:08,725 iteration 1967 : loss : 0.055634, loss_ce: 0.018402
2022-01-14 12:11:09,649 iteration 1968 : loss : 0.036763, loss_ce: 0.018406
2022-01-14 12:11:10,673 iteration 1969 : loss : 0.041054, loss_ce: 0.018087
2022-01-14 12:11:11,798 iteration 1970 : loss : 0.046423, loss_ce: 0.017387
2022-01-14 12:11:12,705 iteration 1971 : loss : 0.039891, loss_ce: 0.013193
2022-01-14 12:11:13,811 iteration 1972 : loss : 0.052288, loss_ce: 0.021506
 29%|████████▍                    | 116/400 [35:47<1:28:33, 18.71s/it]2022-01-14 12:11:14,788 iteration 1973 : loss : 0.035092, loss_ce: 0.013969
2022-01-14 12:11:15,717 iteration 1974 : loss : 0.040477, loss_ce: 0.017190
2022-01-14 12:11:16,791 iteration 1975 : loss : 0.043638, loss_ce: 0.018372
2022-01-14 12:11:17,712 iteration 1976 : loss : 0.047442, loss_ce: 0.020650
2022-01-14 12:11:18,791 iteration 1977 : loss : 0.072422, loss_ce: 0.030740
2022-01-14 12:11:19,794 iteration 1978 : loss : 0.051896, loss_ce: 0.019858
2022-01-14 12:11:20,770 iteration 1979 : loss : 0.049821, loss_ce: 0.024950
2022-01-14 12:11:21,804 iteration 1980 : loss : 0.044403, loss_ce: 0.014796
2022-01-14 12:11:22,754 iteration 1981 : loss : 0.040232, loss_ce: 0.015711
2022-01-14 12:11:23,805 iteration 1982 : loss : 0.041090, loss_ce: 0.013948
2022-01-14 12:11:24,890 iteration 1983 : loss : 0.048403, loss_ce: 0.019829
2022-01-14 12:11:25,859 iteration 1984 : loss : 0.046007, loss_ce: 0.013645
2022-01-14 12:11:26,833 iteration 1985 : loss : 0.037287, loss_ce: 0.013483
2022-01-14 12:11:27,792 iteration 1986 : loss : 0.060515, loss_ce: 0.022227
2022-01-14 12:11:28,744 iteration 1987 : loss : 0.026375, loss_ce: 0.010295
2022-01-14 12:11:29,825 iteration 1988 : loss : 0.043859, loss_ce: 0.017948
2022-01-14 12:11:30,820 iteration 1989 : loss : 0.036059, loss_ce: 0.016881
 29%|████████▍                    | 117/400 [36:04<1:25:49, 18.20s/it]2022-01-14 12:11:31,865 iteration 1990 : loss : 0.057617, loss_ce: 0.020609
2022-01-14 12:11:32,777 iteration 1991 : loss : 0.042550, loss_ce: 0.018047
2022-01-14 12:11:33,803 iteration 1992 : loss : 0.040420, loss_ce: 0.017106
2022-01-14 12:11:34,784 iteration 1993 : loss : 0.060641, loss_ce: 0.015417
2022-01-14 12:11:35,810 iteration 1994 : loss : 0.049337, loss_ce: 0.020361
2022-01-14 12:11:36,804 iteration 1995 : loss : 0.050203, loss_ce: 0.018346
2022-01-14 12:11:37,815 iteration 1996 : loss : 0.044872, loss_ce: 0.019354
2022-01-14 12:11:38,819 iteration 1997 : loss : 0.044469, loss_ce: 0.021066
2022-01-14 12:11:39,846 iteration 1998 : loss : 0.048886, loss_ce: 0.022207
2022-01-14 12:11:40,864 iteration 1999 : loss : 0.048666, loss_ce: 0.020366
2022-01-14 12:11:41,990 iteration 2000 : loss : 0.080274, loss_ce: 0.022046
2022-01-14 12:11:43,002 iteration 2001 : loss : 0.054242, loss_ce: 0.019782
2022-01-14 12:11:43,928 iteration 2002 : loss : 0.048617, loss_ce: 0.021485
2022-01-14 12:11:44,802 iteration 2003 : loss : 0.035483, loss_ce: 0.018214
2022-01-14 12:11:45,758 iteration 2004 : loss : 0.064266, loss_ce: 0.020431
2022-01-14 12:11:46,798 iteration 2005 : loss : 0.037278, loss_ce: 0.012155
2022-01-14 12:11:47,820 iteration 2006 : loss : 0.062328, loss_ce: 0.018792
 30%|████████▌                    | 118/400 [36:21<1:23:50, 17.84s/it]2022-01-14 12:11:48,930 iteration 2007 : loss : 0.043694, loss_ce: 0.015668
2022-01-14 12:11:50,042 iteration 2008 : loss : 0.052681, loss_ce: 0.016951
2022-01-14 12:11:51,050 iteration 2009 : loss : 0.048763, loss_ce: 0.019627
2022-01-14 12:11:52,048 iteration 2010 : loss : 0.059432, loss_ce: 0.026481
2022-01-14 12:11:53,141 iteration 2011 : loss : 0.052776, loss_ce: 0.020450
2022-01-14 12:11:54,152 iteration 2012 : loss : 0.054015, loss_ce: 0.026380
2022-01-14 12:11:55,079 iteration 2013 : loss : 0.035014, loss_ce: 0.015450
2022-01-14 12:11:56,053 iteration 2014 : loss : 0.049683, loss_ce: 0.016138
2022-01-14 12:11:57,087 iteration 2015 : loss : 0.038082, loss_ce: 0.015471
2022-01-14 12:11:58,071 iteration 2016 : loss : 0.059118, loss_ce: 0.022276
2022-01-14 12:11:59,110 iteration 2017 : loss : 0.034536, loss_ce: 0.011910
2022-01-14 12:12:00,216 iteration 2018 : loss : 0.060125, loss_ce: 0.028218
2022-01-14 12:12:01,208 iteration 2019 : loss : 0.053866, loss_ce: 0.020502
2022-01-14 12:12:02,182 iteration 2020 : loss : 0.033382, loss_ce: 0.012082
2022-01-14 12:12:03,203 iteration 2021 : loss : 0.062990, loss_ce: 0.022563
2022-01-14 12:12:04,231 iteration 2022 : loss : 0.041420, loss_ce: 0.018038
2022-01-14 12:12:05,293 iteration 2023 : loss : 0.051096, loss_ce: 0.020103
 30%|████████▋                    | 119/400 [36:39<1:23:01, 17.73s/it]2022-01-14 12:12:06,301 iteration 2024 : loss : 0.055571, loss_ce: 0.017379
2022-01-14 12:12:07,318 iteration 2025 : loss : 0.036101, loss_ce: 0.015887
2022-01-14 12:12:08,370 iteration 2026 : loss : 0.042124, loss_ce: 0.017755
2022-01-14 12:12:09,362 iteration 2027 : loss : 0.037508, loss_ce: 0.010807
2022-01-14 12:12:10,314 iteration 2028 : loss : 0.029519, loss_ce: 0.014908
2022-01-14 12:12:11,294 iteration 2029 : loss : 0.049208, loss_ce: 0.021992
2022-01-14 12:12:12,259 iteration 2030 : loss : 0.042742, loss_ce: 0.018393
2022-01-14 12:12:13,257 iteration 2031 : loss : 0.038288, loss_ce: 0.013924
2022-01-14 12:12:14,340 iteration 2032 : loss : 0.063072, loss_ce: 0.025361
2022-01-14 12:12:15,451 iteration 2033 : loss : 0.050220, loss_ce: 0.022215
2022-01-14 12:12:16,417 iteration 2034 : loss : 0.038909, loss_ce: 0.015123
2022-01-14 12:12:17,429 iteration 2035 : loss : 0.052269, loss_ce: 0.019080
2022-01-14 12:12:18,483 iteration 2036 : loss : 0.055762, loss_ce: 0.031874
2022-01-14 12:12:19,483 iteration 2037 : loss : 0.068556, loss_ce: 0.023495
2022-01-14 12:12:20,526 iteration 2038 : loss : 0.046654, loss_ce: 0.017766
2022-01-14 12:12:21,617 iteration 2039 : loss : 0.058570, loss_ce: 0.019821
2022-01-14 12:12:21,617 Training Data Eval:
2022-01-14 12:12:26,418   Average segmentation loss on training set: 0.0358
2022-01-14 12:12:26,418 Validation Data Eval:
2022-01-14 12:12:28,025   Average segmentation loss on validation set: 0.0890
2022-01-14 12:12:29,090 iteration 2040 : loss : 0.052935, loss_ce: 0.020034
 30%|████████▋                    | 120/400 [37:03<1:31:15, 19.55s/it]2022-01-14 12:12:30,203 iteration 2041 : loss : 0.070198, loss_ce: 0.019873
2022-01-14 12:12:31,178 iteration 2042 : loss : 0.045680, loss_ce: 0.018061
2022-01-14 12:12:32,154 iteration 2043 : loss : 0.063120, loss_ce: 0.020884
2022-01-14 12:12:33,146 iteration 2044 : loss : 0.052316, loss_ce: 0.020600
2022-01-14 12:12:34,115 iteration 2045 : loss : 0.031010, loss_ce: 0.009833
2022-01-14 12:12:35,123 iteration 2046 : loss : 0.047693, loss_ce: 0.022786
2022-01-14 12:12:36,096 iteration 2047 : loss : 0.054003, loss_ce: 0.023199
2022-01-14 12:12:37,102 iteration 2048 : loss : 0.036323, loss_ce: 0.013526
2022-01-14 12:12:38,076 iteration 2049 : loss : 0.047407, loss_ce: 0.011353
2022-01-14 12:12:39,101 iteration 2050 : loss : 0.056198, loss_ce: 0.026209
2022-01-14 12:12:40,116 iteration 2051 : loss : 0.051567, loss_ce: 0.025403
2022-01-14 12:12:41,059 iteration 2052 : loss : 0.047553, loss_ce: 0.019168
2022-01-14 12:12:42,067 iteration 2053 : loss : 0.072101, loss_ce: 0.026907
2022-01-14 12:12:43,042 iteration 2054 : loss : 0.034904, loss_ce: 0.013928
2022-01-14 12:12:44,025 iteration 2055 : loss : 0.054715, loss_ce: 0.018791
2022-01-14 12:12:45,063 iteration 2056 : loss : 0.038270, loss_ce: 0.016906
2022-01-14 12:12:46,016 iteration 2057 : loss : 0.047373, loss_ce: 0.023808
 30%|████████▊                    | 121/400 [37:20<1:27:13, 18.76s/it]2022-01-14 12:12:47,073 iteration 2058 : loss : 0.054905, loss_ce: 0.027644
2022-01-14 12:12:48,137 iteration 2059 : loss : 0.062826, loss_ce: 0.027219
2022-01-14 12:12:49,055 iteration 2060 : loss : 0.043627, loss_ce: 0.016082
2022-01-14 12:12:50,084 iteration 2061 : loss : 0.062721, loss_ce: 0.026405
2022-01-14 12:12:51,063 iteration 2062 : loss : 0.047750, loss_ce: 0.021329
2022-01-14 12:12:52,050 iteration 2063 : loss : 0.095109, loss_ce: 0.021410
2022-01-14 12:12:52,996 iteration 2064 : loss : 0.039731, loss_ce: 0.014026
2022-01-14 12:12:53,975 iteration 2065 : loss : 0.046295, loss_ce: 0.014478
2022-01-14 12:12:54,971 iteration 2066 : loss : 0.041657, loss_ce: 0.014769
2022-01-14 12:12:55,997 iteration 2067 : loss : 0.039874, loss_ce: 0.014561
2022-01-14 12:12:57,055 iteration 2068 : loss : 0.053115, loss_ce: 0.025801
2022-01-14 12:12:58,028 iteration 2069 : loss : 0.039119, loss_ce: 0.010780
2022-01-14 12:12:59,070 iteration 2070 : loss : 0.048894, loss_ce: 0.019834
2022-01-14 12:13:00,129 iteration 2071 : loss : 0.046210, loss_ce: 0.017908
2022-01-14 12:13:01,139 iteration 2072 : loss : 0.046454, loss_ce: 0.018216
2022-01-14 12:13:02,201 iteration 2073 : loss : 0.040003, loss_ce: 0.014234
2022-01-14 12:13:03,240 iteration 2074 : loss : 0.048853, loss_ce: 0.025358
 30%|████████▊                    | 122/400 [37:37<1:24:48, 18.30s/it]2022-01-14 12:13:04,271 iteration 2075 : loss : 0.040530, loss_ce: 0.013151
2022-01-14 12:13:05,280 iteration 2076 : loss : 0.058766, loss_ce: 0.017848
2022-01-14 12:13:06,306 iteration 2077 : loss : 0.061247, loss_ce: 0.025443
2022-01-14 12:13:07,431 iteration 2078 : loss : 0.047056, loss_ce: 0.016558
2022-01-14 12:13:08,416 iteration 2079 : loss : 0.043887, loss_ce: 0.015184
2022-01-14 12:13:09,480 iteration 2080 : loss : 0.059956, loss_ce: 0.023920
2022-01-14 12:13:10,397 iteration 2081 : loss : 0.043062, loss_ce: 0.015280
2022-01-14 12:13:11,293 iteration 2082 : loss : 0.027466, loss_ce: 0.010604
2022-01-14 12:13:12,282 iteration 2083 : loss : 0.058756, loss_ce: 0.031118
2022-01-14 12:13:13,265 iteration 2084 : loss : 0.056393, loss_ce: 0.028111
2022-01-14 12:13:14,213 iteration 2085 : loss : 0.047147, loss_ce: 0.015104
2022-01-14 12:13:15,198 iteration 2086 : loss : 0.050484, loss_ce: 0.018853
2022-01-14 12:13:16,153 iteration 2087 : loss : 0.049518, loss_ce: 0.019805
2022-01-14 12:13:17,214 iteration 2088 : loss : 0.070186, loss_ce: 0.034429
2022-01-14 12:13:18,251 iteration 2089 : loss : 0.042372, loss_ce: 0.018869
2022-01-14 12:13:19,183 iteration 2090 : loss : 0.042290, loss_ce: 0.017784
2022-01-14 12:13:20,225 iteration 2091 : loss : 0.052243, loss_ce: 0.024043
 31%|████████▉                    | 123/400 [37:54<1:22:39, 17.91s/it]2022-01-14 12:13:21,211 iteration 2092 : loss : 0.040481, loss_ce: 0.018001
2022-01-14 12:13:22,184 iteration 2093 : loss : 0.061373, loss_ce: 0.026350
2022-01-14 12:13:23,185 iteration 2094 : loss : 0.050778, loss_ce: 0.016653
2022-01-14 12:13:24,124 iteration 2095 : loss : 0.032146, loss_ce: 0.015235
2022-01-14 12:13:25,204 iteration 2096 : loss : 0.049601, loss_ce: 0.023935
2022-01-14 12:13:26,221 iteration 2097 : loss : 0.100112, loss_ce: 0.042073
2022-01-14 12:13:27,224 iteration 2098 : loss : 0.075319, loss_ce: 0.031370
2022-01-14 12:13:28,241 iteration 2099 : loss : 0.033060, loss_ce: 0.010963
2022-01-14 12:13:29,278 iteration 2100 : loss : 0.048046, loss_ce: 0.026310
2022-01-14 12:13:30,342 iteration 2101 : loss : 0.045262, loss_ce: 0.017105
2022-01-14 12:13:31,396 iteration 2102 : loss : 0.063407, loss_ce: 0.035610
2022-01-14 12:13:32,320 iteration 2103 : loss : 0.048519, loss_ce: 0.023310
2022-01-14 12:13:33,264 iteration 2104 : loss : 0.081351, loss_ce: 0.023755
2022-01-14 12:13:34,353 iteration 2105 : loss : 0.061551, loss_ce: 0.019141
2022-01-14 12:13:35,323 iteration 2106 : loss : 0.038024, loss_ce: 0.016738
2022-01-14 12:13:36,403 iteration 2107 : loss : 0.041192, loss_ce: 0.015279
2022-01-14 12:13:37,422 iteration 2108 : loss : 0.063356, loss_ce: 0.023566
 31%|████████▉                    | 124/400 [38:11<1:21:23, 17.69s/it]2022-01-14 12:13:38,476 iteration 2109 : loss : 0.050422, loss_ce: 0.022234
2022-01-14 12:13:39,513 iteration 2110 : loss : 0.044787, loss_ce: 0.016679
2022-01-14 12:13:40,602 iteration 2111 : loss : 0.062941, loss_ce: 0.016758
2022-01-14 12:13:41,623 iteration 2112 : loss : 0.071583, loss_ce: 0.028610
2022-01-14 12:13:42,599 iteration 2113 : loss : 0.054194, loss_ce: 0.029435
2022-01-14 12:13:43,639 iteration 2114 : loss : 0.042662, loss_ce: 0.020158
2022-01-14 12:13:44,673 iteration 2115 : loss : 0.072607, loss_ce: 0.022886
2022-01-14 12:13:45,693 iteration 2116 : loss : 0.046487, loss_ce: 0.016782
2022-01-14 12:13:46,705 iteration 2117 : loss : 0.040142, loss_ce: 0.015479
2022-01-14 12:13:47,748 iteration 2118 : loss : 0.066526, loss_ce: 0.022495
2022-01-14 12:13:48,796 iteration 2119 : loss : 0.080498, loss_ce: 0.036871
2022-01-14 12:13:49,808 iteration 2120 : loss : 0.070961, loss_ce: 0.022974
2022-01-14 12:13:50,719 iteration 2121 : loss : 0.041715, loss_ce: 0.016130
2022-01-14 12:13:51,701 iteration 2122 : loss : 0.043771, loss_ce: 0.015321
2022-01-14 12:13:52,758 iteration 2123 : loss : 0.064016, loss_ce: 0.031519
2022-01-14 12:13:53,839 iteration 2124 : loss : 0.054071, loss_ce: 0.022640
2022-01-14 12:13:53,839 Training Data Eval:
2022-01-14 12:13:58,662   Average segmentation loss on training set: 0.0432
2022-01-14 12:13:58,662 Validation Data Eval:
2022-01-14 12:14:00,275   Average segmentation loss on validation set: 0.1286
2022-01-14 12:14:01,290 iteration 2125 : loss : 0.054436, loss_ce: 0.025618
 31%|█████████                    | 125/400 [38:35<1:29:35, 19.55s/it]2022-01-14 12:14:02,399 iteration 2126 : loss : 0.039303, loss_ce: 0.014286
2022-01-14 12:14:03,428 iteration 2127 : loss : 0.057425, loss_ce: 0.026305
2022-01-14 12:14:04,452 iteration 2128 : loss : 0.039558, loss_ce: 0.012702
2022-01-14 12:14:05,421 iteration 2129 : loss : 0.058194, loss_ce: 0.022892
2022-01-14 12:14:06,469 iteration 2130 : loss : 0.089808, loss_ce: 0.027139
2022-01-14 12:14:07,458 iteration 2131 : loss : 0.050694, loss_ce: 0.016825
2022-01-14 12:14:08,458 iteration 2132 : loss : 0.038657, loss_ce: 0.013488
2022-01-14 12:14:09,527 iteration 2133 : loss : 0.071715, loss_ce: 0.023601
2022-01-14 12:14:10,461 iteration 2134 : loss : 0.035698, loss_ce: 0.017575
2022-01-14 12:14:11,465 iteration 2135 : loss : 0.043312, loss_ce: 0.016571
2022-01-14 12:14:12,456 iteration 2136 : loss : 0.039309, loss_ce: 0.016793
2022-01-14 12:14:13,459 iteration 2137 : loss : 0.056511, loss_ce: 0.021712
2022-01-14 12:14:14,422 iteration 2138 : loss : 0.039939, loss_ce: 0.016395
2022-01-14 12:14:15,463 iteration 2139 : loss : 0.042657, loss_ce: 0.021687
2022-01-14 12:14:16,464 iteration 2140 : loss : 0.046081, loss_ce: 0.022017
2022-01-14 12:14:17,532 iteration 2141 : loss : 0.043278, loss_ce: 0.014958
2022-01-14 12:14:18,498 iteration 2142 : loss : 0.047790, loss_ce: 0.016291
 32%|█████████▏                   | 126/400 [38:52<1:26:03, 18.85s/it]2022-01-14 12:14:19,491 iteration 2143 : loss : 0.042542, loss_ce: 0.017722
2022-01-14 12:14:20,510 iteration 2144 : loss : 0.044678, loss_ce: 0.014572
2022-01-14 12:14:21,549 iteration 2145 : loss : 0.039853, loss_ce: 0.013080
2022-01-14 12:14:22,505 iteration 2146 : loss : 0.027863, loss_ce: 0.012337
2022-01-14 12:14:23,524 iteration 2147 : loss : 0.051165, loss_ce: 0.017286
2022-01-14 12:14:24,504 iteration 2148 : loss : 0.042888, loss_ce: 0.017976
2022-01-14 12:14:25,505 iteration 2149 : loss : 0.044311, loss_ce: 0.016754
2022-01-14 12:14:26,479 iteration 2150 : loss : 0.031644, loss_ce: 0.012076
2022-01-14 12:14:27,539 iteration 2151 : loss : 0.058125, loss_ce: 0.024955
2022-01-14 12:14:28,498 iteration 2152 : loss : 0.036625, loss_ce: 0.017836
2022-01-14 12:14:29,444 iteration 2153 : loss : 0.034140, loss_ce: 0.014025
2022-01-14 12:14:30,572 iteration 2154 : loss : 0.073379, loss_ce: 0.023960
2022-01-14 12:14:31,579 iteration 2155 : loss : 0.044071, loss_ce: 0.015743
2022-01-14 12:14:32,531 iteration 2156 : loss : 0.046140, loss_ce: 0.019398
2022-01-14 12:14:33,679 iteration 2157 : loss : 0.121276, loss_ce: 0.035220
2022-01-14 12:14:34,777 iteration 2158 : loss : 0.055166, loss_ce: 0.025107
2022-01-14 12:14:35,803 iteration 2159 : loss : 0.073655, loss_ce: 0.021289
 32%|█████████▏                   | 127/400 [39:09<1:23:37, 18.38s/it]2022-01-14 12:14:36,821 iteration 2160 : loss : 0.042179, loss_ce: 0.015790
2022-01-14 12:14:37,765 iteration 2161 : loss : 0.039857, loss_ce: 0.012562
2022-01-14 12:14:38,744 iteration 2162 : loss : 0.048508, loss_ce: 0.020407
2022-01-14 12:14:39,711 iteration 2163 : loss : 0.035692, loss_ce: 0.012861
2022-01-14 12:14:40,744 iteration 2164 : loss : 0.039637, loss_ce: 0.017725
2022-01-14 12:14:41,764 iteration 2165 : loss : 0.071047, loss_ce: 0.023137
2022-01-14 12:14:42,721 iteration 2166 : loss : 0.041438, loss_ce: 0.018340
2022-01-14 12:14:43,646 iteration 2167 : loss : 0.038923, loss_ce: 0.014472
2022-01-14 12:14:44,617 iteration 2168 : loss : 0.036142, loss_ce: 0.014433
2022-01-14 12:14:45,633 iteration 2169 : loss : 0.062547, loss_ce: 0.022322
2022-01-14 12:14:46,524 iteration 2170 : loss : 0.038763, loss_ce: 0.011415
2022-01-14 12:14:47,495 iteration 2171 : loss : 0.048189, loss_ce: 0.017888
2022-01-14 12:14:48,457 iteration 2172 : loss : 0.067292, loss_ce: 0.024298
2022-01-14 12:14:49,410 iteration 2173 : loss : 0.057547, loss_ce: 0.016265
2022-01-14 12:14:50,404 iteration 2174 : loss : 0.046471, loss_ce: 0.018667
2022-01-14 12:14:51,479 iteration 2175 : loss : 0.043353, loss_ce: 0.018045
2022-01-14 12:14:52,400 iteration 2176 : loss : 0.037741, loss_ce: 0.017702
 32%|█████████▎                   | 128/400 [39:26<1:20:54, 17.85s/it]2022-01-14 12:14:53,388 iteration 2177 : loss : 0.066765, loss_ce: 0.036237
2022-01-14 12:14:54,382 iteration 2178 : loss : 0.057661, loss_ce: 0.020719
2022-01-14 12:14:55,450 iteration 2179 : loss : 0.042486, loss_ce: 0.015600
2022-01-14 12:14:56,487 iteration 2180 : loss : 0.040474, loss_ce: 0.015178
2022-01-14 12:14:57,417 iteration 2181 : loss : 0.039711, loss_ce: 0.015099
2022-01-14 12:14:58,408 iteration 2182 : loss : 0.043687, loss_ce: 0.016604
2022-01-14 12:14:59,419 iteration 2183 : loss : 0.056246, loss_ce: 0.016710
2022-01-14 12:15:00,360 iteration 2184 : loss : 0.044490, loss_ce: 0.021688
2022-01-14 12:15:01,303 iteration 2185 : loss : 0.037090, loss_ce: 0.014299
2022-01-14 12:15:02,383 iteration 2186 : loss : 0.047271, loss_ce: 0.017882
2022-01-14 12:15:03,475 iteration 2187 : loss : 0.053693, loss_ce: 0.016047
2022-01-14 12:15:04,635 iteration 2188 : loss : 0.053742, loss_ce: 0.028548
2022-01-14 12:15:05,772 iteration 2189 : loss : 0.077077, loss_ce: 0.026675
2022-01-14 12:15:06,787 iteration 2190 : loss : 0.054783, loss_ce: 0.023034
2022-01-14 12:15:07,814 iteration 2191 : loss : 0.034817, loss_ce: 0.011962
2022-01-14 12:15:08,783 iteration 2192 : loss : 0.038157, loss_ce: 0.014055
2022-01-14 12:15:09,807 iteration 2193 : loss : 0.052377, loss_ce: 0.021033
 32%|█████████▎                   | 129/400 [39:43<1:20:01, 17.72s/it]2022-01-14 12:15:10,901 iteration 2194 : loss : 0.044694, loss_ce: 0.019342
2022-01-14 12:15:11,928 iteration 2195 : loss : 0.065795, loss_ce: 0.043794
2022-01-14 12:15:12,980 iteration 2196 : loss : 0.039930, loss_ce: 0.017297
2022-01-14 12:15:14,064 iteration 2197 : loss : 0.048798, loss_ce: 0.016506
2022-01-14 12:15:15,068 iteration 2198 : loss : 0.063916, loss_ce: 0.018274
2022-01-14 12:15:16,080 iteration 2199 : loss : 0.034526, loss_ce: 0.015970
2022-01-14 12:15:17,201 iteration 2200 : loss : 0.138271, loss_ce: 0.023544
2022-01-14 12:15:18,153 iteration 2201 : loss : 0.040532, loss_ce: 0.014424
2022-01-14 12:15:19,267 iteration 2202 : loss : 0.047474, loss_ce: 0.020900
2022-01-14 12:15:20,298 iteration 2203 : loss : 0.055801, loss_ce: 0.018426
2022-01-14 12:15:21,238 iteration 2204 : loss : 0.033741, loss_ce: 0.011387
2022-01-14 12:15:22,253 iteration 2205 : loss : 0.043460, loss_ce: 0.019256
2022-01-14 12:15:23,346 iteration 2206 : loss : 0.064835, loss_ce: 0.024341
2022-01-14 12:15:24,386 iteration 2207 : loss : 0.057546, loss_ce: 0.021037
2022-01-14 12:15:25,450 iteration 2208 : loss : 0.058143, loss_ce: 0.016599
2022-01-14 12:15:26,459 iteration 2209 : loss : 0.064710, loss_ce: 0.019685
2022-01-14 12:15:26,459 Training Data Eval:
2022-01-14 12:15:31,270   Average segmentation loss on training set: 0.0301
2022-01-14 12:15:31,270 Validation Data Eval:
2022-01-14 12:15:32,891   Average segmentation loss on validation set: 0.0803
2022-01-14 12:15:34,085 Found new lowest validation loss at iteration 2209! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_1BLOCK_best_val_loss_seed1234.pth
2022-01-14 12:15:35,115 iteration 2210 : loss : 0.048871, loss_ce: 0.024425
 32%|█████████▍                   | 130/400 [40:09<1:29:57, 19.99s/it]2022-01-14 12:15:36,174 iteration 2211 : loss : 0.030650, loss_ce: 0.008499
2022-01-14 12:15:37,129 iteration 2212 : loss : 0.056296, loss_ce: 0.025093
2022-01-14 12:15:38,136 iteration 2213 : loss : 0.048324, loss_ce: 0.013399
2022-01-14 12:15:39,059 iteration 2214 : loss : 0.049299, loss_ce: 0.016693
2022-01-14 12:15:39,978 iteration 2215 : loss : 0.032755, loss_ce: 0.012225
2022-01-14 12:15:40,940 iteration 2216 : loss : 0.052739, loss_ce: 0.025117
2022-01-14 12:15:41,883 iteration 2217 : loss : 0.044605, loss_ce: 0.021532
2022-01-14 12:15:42,855 iteration 2218 : loss : 0.036454, loss_ce: 0.014703
2022-01-14 12:15:43,883 iteration 2219 : loss : 0.054629, loss_ce: 0.024507
2022-01-14 12:15:44,967 iteration 2220 : loss : 0.039960, loss_ce: 0.019039
2022-01-14 12:15:46,034 iteration 2221 : loss : 0.043369, loss_ce: 0.014155
2022-01-14 12:15:46,952 iteration 2222 : loss : 0.041943, loss_ce: 0.016890
2022-01-14 12:15:47,895 iteration 2223 : loss : 0.050002, loss_ce: 0.018571
2022-01-14 12:15:48,956 iteration 2224 : loss : 0.044611, loss_ce: 0.019137
2022-01-14 12:15:49,980 iteration 2225 : loss : 0.039268, loss_ce: 0.013713
2022-01-14 12:15:51,052 iteration 2226 : loss : 0.045206, loss_ce: 0.018824
2022-01-14 12:15:52,102 iteration 2227 : loss : 0.070558, loss_ce: 0.020570
 33%|█████████▍                   | 131/400 [40:26<1:25:35, 19.09s/it]2022-01-14 12:15:53,234 iteration 2228 : loss : 0.038950, loss_ce: 0.016975
2022-01-14 12:15:54,250 iteration 2229 : loss : 0.041481, loss_ce: 0.016407
2022-01-14 12:15:55,402 iteration 2230 : loss : 0.055281, loss_ce: 0.023063
2022-01-14 12:15:56,397 iteration 2231 : loss : 0.074847, loss_ce: 0.041232
2022-01-14 12:15:57,385 iteration 2232 : loss : 0.045172, loss_ce: 0.020335
2022-01-14 12:15:58,575 iteration 2233 : loss : 0.065185, loss_ce: 0.017189
2022-01-14 12:15:59,613 iteration 2234 : loss : 0.042645, loss_ce: 0.011021
2022-01-14 12:16:00,624 iteration 2235 : loss : 0.050895, loss_ce: 0.020808
2022-01-14 12:16:01,617 iteration 2236 : loss : 0.031070, loss_ce: 0.013259
2022-01-14 12:16:02,633 iteration 2237 : loss : 0.037380, loss_ce: 0.016761
2022-01-14 12:16:03,586 iteration 2238 : loss : 0.044133, loss_ce: 0.013780
2022-01-14 12:16:04,567 iteration 2239 : loss : 0.067738, loss_ce: 0.025642
2022-01-14 12:16:05,489 iteration 2240 : loss : 0.064424, loss_ce: 0.019707
2022-01-14 12:16:06,480 iteration 2241 : loss : 0.040493, loss_ce: 0.014236
2022-01-14 12:16:07,545 iteration 2242 : loss : 0.059489, loss_ce: 0.020297
2022-01-14 12:16:08,584 iteration 2243 : loss : 0.063210, loss_ce: 0.032466
2022-01-14 12:16:09,567 iteration 2244 : loss : 0.030707, loss_ce: 0.010824
 33%|█████████▌                   | 132/400 [40:43<1:23:05, 18.60s/it]2022-01-14 12:16:10,616 iteration 2245 : loss : 0.045488, loss_ce: 0.013325
2022-01-14 12:16:11,527 iteration 2246 : loss : 0.029370, loss_ce: 0.008200
2022-01-14 12:16:12,531 iteration 2247 : loss : 0.053837, loss_ce: 0.028521
2022-01-14 12:16:13,595 iteration 2248 : loss : 0.062601, loss_ce: 0.027155
2022-01-14 12:16:14,595 iteration 2249 : loss : 0.040333, loss_ce: 0.018503
2022-01-14 12:16:15,600 iteration 2250 : loss : 0.033081, loss_ce: 0.011233
2022-01-14 12:16:16,634 iteration 2251 : loss : 0.057765, loss_ce: 0.022333
2022-01-14 12:16:17,643 iteration 2252 : loss : 0.052126, loss_ce: 0.017967
2022-01-14 12:16:18,746 iteration 2253 : loss : 0.075612, loss_ce: 0.032331
2022-01-14 12:16:19,800 iteration 2254 : loss : 0.035023, loss_ce: 0.015631
2022-01-14 12:16:20,804 iteration 2255 : loss : 0.035297, loss_ce: 0.014485
2022-01-14 12:16:21,791 iteration 2256 : loss : 0.043964, loss_ce: 0.019290
2022-01-14 12:16:22,746 iteration 2257 : loss : 0.062083, loss_ce: 0.022898
2022-01-14 12:16:23,696 iteration 2258 : loss : 0.074915, loss_ce: 0.028540
2022-01-14 12:16:24,760 iteration 2259 : loss : 0.050353, loss_ce: 0.023924
2022-01-14 12:16:25,693 iteration 2260 : loss : 0.037202, loss_ce: 0.015971
2022-01-14 12:16:26,709 iteration 2261 : loss : 0.055508, loss_ce: 0.024623
 33%|█████████▋                   | 133/400 [41:00<1:20:50, 18.17s/it]2022-01-14 12:16:27,715 iteration 2262 : loss : 0.042777, loss_ce: 0.022316
2022-01-14 12:16:28,778 iteration 2263 : loss : 0.097081, loss_ce: 0.034324
2022-01-14 12:16:29,875 iteration 2264 : loss : 0.035734, loss_ce: 0.009493
2022-01-14 12:16:30,914 iteration 2265 : loss : 0.033553, loss_ce: 0.011967
2022-01-14 12:16:31,891 iteration 2266 : loss : 0.040704, loss_ce: 0.016203
2022-01-14 12:16:32,870 iteration 2267 : loss : 0.034294, loss_ce: 0.014072
2022-01-14 12:16:33,870 iteration 2268 : loss : 0.043361, loss_ce: 0.016056
2022-01-14 12:16:34,833 iteration 2269 : loss : 0.042018, loss_ce: 0.023560
2022-01-14 12:16:35,830 iteration 2270 : loss : 0.053044, loss_ce: 0.019774
2022-01-14 12:16:36,800 iteration 2271 : loss : 0.051221, loss_ce: 0.019241
2022-01-14 12:16:37,787 iteration 2272 : loss : 0.045755, loss_ce: 0.023351
2022-01-14 12:16:38,813 iteration 2273 : loss : 0.031861, loss_ce: 0.009753
2022-01-14 12:16:39,833 iteration 2274 : loss : 0.047688, loss_ce: 0.016391
2022-01-14 12:16:40,896 iteration 2275 : loss : 0.085205, loss_ce: 0.032878
2022-01-14 12:16:41,846 iteration 2276 : loss : 0.038606, loss_ce: 0.015759
2022-01-14 12:16:42,861 iteration 2277 : loss : 0.045135, loss_ce: 0.016527
2022-01-14 12:16:43,816 iteration 2278 : loss : 0.027420, loss_ce: 0.010526
 34%|█████████▋                   | 134/400 [41:17<1:19:07, 17.85s/it]2022-01-14 12:16:44,811 iteration 2279 : loss : 0.095964, loss_ce: 0.039316
2022-01-14 12:16:45,819 iteration 2280 : loss : 0.034765, loss_ce: 0.015707
2022-01-14 12:16:46,814 iteration 2281 : loss : 0.063656, loss_ce: 0.017042
2022-01-14 12:16:47,842 iteration 2282 : loss : 0.035105, loss_ce: 0.012074
2022-01-14 12:16:48,915 iteration 2283 : loss : 0.063878, loss_ce: 0.026214
2022-01-14 12:16:49,892 iteration 2284 : loss : 0.043600, loss_ce: 0.018586
2022-01-14 12:16:50,874 iteration 2285 : loss : 0.032092, loss_ce: 0.011227
2022-01-14 12:16:51,863 iteration 2286 : loss : 0.030486, loss_ce: 0.011464
2022-01-14 12:16:52,854 iteration 2287 : loss : 0.039012, loss_ce: 0.015050
2022-01-14 12:16:53,886 iteration 2288 : loss : 0.034288, loss_ce: 0.012906
2022-01-14 12:16:54,838 iteration 2289 : loss : 0.037615, loss_ce: 0.010565
2022-01-14 12:16:55,891 iteration 2290 : loss : 0.037163, loss_ce: 0.017629
2022-01-14 12:16:56,882 iteration 2291 : loss : 0.034109, loss_ce: 0.012950
2022-01-14 12:16:57,865 iteration 2292 : loss : 0.054790, loss_ce: 0.025095
2022-01-14 12:16:58,785 iteration 2293 : loss : 0.038515, loss_ce: 0.019397
2022-01-14 12:16:59,816 iteration 2294 : loss : 0.054894, loss_ce: 0.021079
2022-01-14 12:16:59,816 Training Data Eval:
2022-01-14 12:17:04,646   Average segmentation loss on training set: 0.0268
2022-01-14 12:17:04,647 Validation Data Eval:
2022-01-14 12:17:06,263   Average segmentation loss on validation set: 0.0758
2022-01-14 12:17:07,452 Found new lowest validation loss at iteration 2294! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_1BLOCK_best_val_loss_seed1234.pth
2022-01-14 12:17:08,530 iteration 2295 : loss : 0.042862, loss_ce: 0.020068
 34%|█████████▊                   | 135/400 [41:42<1:27:55, 19.91s/it]2022-01-14 12:17:09,512 iteration 2296 : loss : 0.026606, loss_ce: 0.011247
2022-01-14 12:17:10,494 iteration 2297 : loss : 0.034797, loss_ce: 0.016204
2022-01-14 12:17:11,477 iteration 2298 : loss : 0.031136, loss_ce: 0.012679
2022-01-14 12:17:12,549 iteration 2299 : loss : 0.068442, loss_ce: 0.032200
2022-01-14 12:17:13,520 iteration 2300 : loss : 0.038411, loss_ce: 0.018529
2022-01-14 12:17:14,591 iteration 2301 : loss : 0.040354, loss_ce: 0.011323
2022-01-14 12:17:15,630 iteration 2302 : loss : 0.067563, loss_ce: 0.019886
2022-01-14 12:17:16,645 iteration 2303 : loss : 0.033609, loss_ce: 0.011509
2022-01-14 12:17:17,725 iteration 2304 : loss : 0.032568, loss_ce: 0.010942
2022-01-14 12:17:18,762 iteration 2305 : loss : 0.042348, loss_ce: 0.016782
2022-01-14 12:17:19,869 iteration 2306 : loss : 0.043992, loss_ce: 0.019113
2022-01-14 12:17:20,863 iteration 2307 : loss : 0.063556, loss_ce: 0.021383
2022-01-14 12:17:21,826 iteration 2308 : loss : 0.034973, loss_ce: 0.011659
2022-01-14 12:17:22,799 iteration 2309 : loss : 0.042617, loss_ce: 0.019491
2022-01-14 12:17:23,865 iteration 2310 : loss : 0.072112, loss_ce: 0.027588
2022-01-14 12:17:24,790 iteration 2311 : loss : 0.054230, loss_ce: 0.018604
2022-01-14 12:17:25,798 iteration 2312 : loss : 0.059339, loss_ce: 0.023400
 34%|█████████▊                   | 136/400 [41:59<1:24:05, 19.11s/it]2022-01-14 12:17:26,891 iteration 2313 : loss : 0.050987, loss_ce: 0.020651
2022-01-14 12:17:27,793 iteration 2314 : loss : 0.038640, loss_ce: 0.011953
2022-01-14 12:17:28,743 iteration 2315 : loss : 0.033329, loss_ce: 0.011372
2022-01-14 12:17:29,824 iteration 2316 : loss : 0.060724, loss_ce: 0.029282
2022-01-14 12:17:30,761 iteration 2317 : loss : 0.067201, loss_ce: 0.022618
2022-01-14 12:17:31,743 iteration 2318 : loss : 0.040716, loss_ce: 0.020382
2022-01-14 12:17:32,744 iteration 2319 : loss : 0.055544, loss_ce: 0.026698
2022-01-14 12:17:33,818 iteration 2320 : loss : 0.034327, loss_ce: 0.014451
2022-01-14 12:17:34,812 iteration 2321 : loss : 0.043761, loss_ce: 0.017957
2022-01-14 12:17:35,821 iteration 2322 : loss : 0.041564, loss_ce: 0.017961
2022-01-14 12:17:36,731 iteration 2323 : loss : 0.033777, loss_ce: 0.014559
2022-01-14 12:17:37,711 iteration 2324 : loss : 0.037734, loss_ce: 0.017350
2022-01-14 12:17:38,591 iteration 2325 : loss : 0.031550, loss_ce: 0.014918
2022-01-14 12:17:39,566 iteration 2326 : loss : 0.068982, loss_ce: 0.016396
2022-01-14 12:17:40,527 iteration 2327 : loss : 0.039768, loss_ce: 0.015402
2022-01-14 12:17:41,519 iteration 2328 : loss : 0.053476, loss_ce: 0.022979
2022-01-14 12:17:42,459 iteration 2329 : loss : 0.047001, loss_ce: 0.018369
 34%|█████████▉                   | 137/400 [42:16<1:20:34, 18.38s/it]2022-01-14 12:17:43,522 iteration 2330 : loss : 0.055438, loss_ce: 0.021740
2022-01-14 12:17:44,470 iteration 2331 : loss : 0.041368, loss_ce: 0.014856
2022-01-14 12:17:45,541 iteration 2332 : loss : 0.046586, loss_ce: 0.019508
2022-01-14 12:17:46,535 iteration 2333 : loss : 0.040559, loss_ce: 0.018288
2022-01-14 12:17:47,659 iteration 2334 : loss : 0.031074, loss_ce: 0.012403
2022-01-14 12:17:48,780 iteration 2335 : loss : 0.048423, loss_ce: 0.020297
2022-01-14 12:17:49,855 iteration 2336 : loss : 0.051975, loss_ce: 0.023031
2022-01-14 12:17:50,860 iteration 2337 : loss : 0.062681, loss_ce: 0.025034
2022-01-14 12:17:51,895 iteration 2338 : loss : 0.045781, loss_ce: 0.018350
2022-01-14 12:17:52,921 iteration 2339 : loss : 0.050953, loss_ce: 0.019104
2022-01-14 12:17:53,863 iteration 2340 : loss : 0.038527, loss_ce: 0.015667
2022-01-14 12:17:54,883 iteration 2341 : loss : 0.044770, loss_ce: 0.019598
2022-01-14 12:17:55,912 iteration 2342 : loss : 0.037326, loss_ce: 0.013769
2022-01-14 12:17:57,036 iteration 2343 : loss : 0.051173, loss_ce: 0.018719
2022-01-14 12:17:57,994 iteration 2344 : loss : 0.066022, loss_ce: 0.022999
2022-01-14 12:17:58,962 iteration 2345 : loss : 0.056426, loss_ce: 0.031024
2022-01-14 12:17:59,949 iteration 2346 : loss : 0.059400, loss_ce: 0.023615
 34%|██████████                   | 138/400 [42:33<1:19:05, 18.11s/it]2022-01-14 12:18:01,099 iteration 2347 : loss : 0.055709, loss_ce: 0.026043
2022-01-14 12:18:02,123 iteration 2348 : loss : 0.034546, loss_ce: 0.012440
2022-01-14 12:18:03,097 iteration 2349 : loss : 0.037107, loss_ce: 0.015280
2022-01-14 12:18:04,084 iteration 2350 : loss : 0.056015, loss_ce: 0.016190
2022-01-14 12:18:05,157 iteration 2351 : loss : 0.081157, loss_ce: 0.037758
2022-01-14 12:18:06,115 iteration 2352 : loss : 0.029953, loss_ce: 0.014095
2022-01-14 12:18:07,079 iteration 2353 : loss : 0.036787, loss_ce: 0.015198
2022-01-14 12:18:08,029 iteration 2354 : loss : 0.027010, loss_ce: 0.012363
2022-01-14 12:18:08,993 iteration 2355 : loss : 0.044622, loss_ce: 0.015286
2022-01-14 12:18:10,042 iteration 2356 : loss : 0.051751, loss_ce: 0.021218
2022-01-14 12:18:11,060 iteration 2357 : loss : 0.055177, loss_ce: 0.019560
2022-01-14 12:18:12,079 iteration 2358 : loss : 0.042376, loss_ce: 0.017795
2022-01-14 12:18:13,052 iteration 2359 : loss : 0.061903, loss_ce: 0.021002
2022-01-14 12:18:14,003 iteration 2360 : loss : 0.065037, loss_ce: 0.022194
2022-01-14 12:18:14,995 iteration 2361 : loss : 0.040892, loss_ce: 0.014407
2022-01-14 12:18:16,112 iteration 2362 : loss : 0.059208, loss_ce: 0.025137
2022-01-14 12:18:17,118 iteration 2363 : loss : 0.045961, loss_ce: 0.019214
 35%|██████████                   | 139/400 [42:51<1:17:33, 17.83s/it]2022-01-14 12:18:18,255 iteration 2364 : loss : 0.030159, loss_ce: 0.010743
2022-01-14 12:18:19,348 iteration 2365 : loss : 0.035156, loss_ce: 0.013146
2022-01-14 12:18:20,402 iteration 2366 : loss : 0.053620, loss_ce: 0.022949
2022-01-14 12:18:21,354 iteration 2367 : loss : 0.038684, loss_ce: 0.008420
2022-01-14 12:18:22,308 iteration 2368 : loss : 0.029754, loss_ce: 0.012182
2022-01-14 12:18:23,315 iteration 2369 : loss : 0.048318, loss_ce: 0.015576
2022-01-14 12:18:24,304 iteration 2370 : loss : 0.053575, loss_ce: 0.021126
2022-01-14 12:18:25,335 iteration 2371 : loss : 0.027785, loss_ce: 0.011079
2022-01-14 12:18:26,292 iteration 2372 : loss : 0.030648, loss_ce: 0.010055
2022-01-14 12:18:27,271 iteration 2373 : loss : 0.038611, loss_ce: 0.015529
2022-01-14 12:18:28,217 iteration 2374 : loss : 0.037431, loss_ce: 0.014772
2022-01-14 12:18:29,176 iteration 2375 : loss : 0.030835, loss_ce: 0.010499
2022-01-14 12:18:30,187 iteration 2376 : loss : 0.045530, loss_ce: 0.021099
2022-01-14 12:18:31,196 iteration 2377 : loss : 0.036152, loss_ce: 0.016394
2022-01-14 12:18:32,204 iteration 2378 : loss : 0.031143, loss_ce: 0.012506
2022-01-14 12:18:33,245 iteration 2379 : loss : 0.040804, loss_ce: 0.017641
2022-01-14 12:18:33,245 Training Data Eval:
2022-01-14 12:18:38,065   Average segmentation loss on training set: 0.0274
2022-01-14 12:18:38,066 Validation Data Eval:
2022-01-14 12:18:39,681   Average segmentation loss on validation set: 0.0823
2022-01-14 12:18:40,645 iteration 2380 : loss : 0.029328, loss_ce: 0.013801
 35%|██████████▏                  | 140/400 [43:14<1:24:39, 19.54s/it]2022-01-14 12:18:41,652 iteration 2381 : loss : 0.038740, loss_ce: 0.013916
2022-01-14 12:18:42,684 iteration 2382 : loss : 0.038336, loss_ce: 0.014054
2022-01-14 12:18:43,644 iteration 2383 : loss : 0.031227, loss_ce: 0.011261
2022-01-14 12:18:44,688 iteration 2384 : loss : 0.054864, loss_ce: 0.026375
2022-01-14 12:18:45,745 iteration 2385 : loss : 0.059002, loss_ce: 0.021694
2022-01-14 12:18:46,735 iteration 2386 : loss : 0.034474, loss_ce: 0.010688
2022-01-14 12:18:47,699 iteration 2387 : loss : 0.040596, loss_ce: 0.014062
2022-01-14 12:18:48,697 iteration 2388 : loss : 0.041655, loss_ce: 0.018152
2022-01-14 12:18:49,630 iteration 2389 : loss : 0.019584, loss_ce: 0.006472
2022-01-14 12:18:50,639 iteration 2390 : loss : 0.040942, loss_ce: 0.021202
2022-01-14 12:18:51,618 iteration 2391 : loss : 0.043663, loss_ce: 0.025909
2022-01-14 12:18:52,650 iteration 2392 : loss : 0.057105, loss_ce: 0.028268
2022-01-14 12:18:53,674 iteration 2393 : loss : 0.057547, loss_ce: 0.017815
2022-01-14 12:18:54,584 iteration 2394 : loss : 0.032580, loss_ce: 0.011036
2022-01-14 12:18:55,633 iteration 2395 : loss : 0.037343, loss_ce: 0.017223
2022-01-14 12:18:56,587 iteration 2396 : loss : 0.031044, loss_ce: 0.014478
2022-01-14 12:18:57,610 iteration 2397 : loss : 0.038508, loss_ce: 0.015452
 35%|██████████▏                  | 141/400 [43:31<1:21:00, 18.77s/it]2022-01-14 12:18:58,657 iteration 2398 : loss : 0.046425, loss_ce: 0.017741
2022-01-14 12:18:59,622 iteration 2399 : loss : 0.050003, loss_ce: 0.016151
2022-01-14 12:19:00,688 iteration 2400 : loss : 0.050691, loss_ce: 0.026209
2022-01-14 12:19:01,692 iteration 2401 : loss : 0.035298, loss_ce: 0.013157
2022-01-14 12:19:02,742 iteration 2402 : loss : 0.037206, loss_ce: 0.018643
2022-01-14 12:19:03,709 iteration 2403 : loss : 0.042574, loss_ce: 0.019264
2022-01-14 12:19:04,656 iteration 2404 : loss : 0.032893, loss_ce: 0.014926
2022-01-14 12:19:05,571 iteration 2405 : loss : 0.038275, loss_ce: 0.014150
2022-01-14 12:19:06,692 iteration 2406 : loss : 0.050223, loss_ce: 0.015387
2022-01-14 12:19:07,628 iteration 2407 : loss : 0.043256, loss_ce: 0.025443
2022-01-14 12:19:08,572 iteration 2408 : loss : 0.031119, loss_ce: 0.013545
2022-01-14 12:19:09,621 iteration 2409 : loss : 0.031425, loss_ce: 0.010477
2022-01-14 12:19:10,680 iteration 2410 : loss : 0.055722, loss_ce: 0.021232
2022-01-14 12:19:11,709 iteration 2411 : loss : 0.054077, loss_ce: 0.015519
2022-01-14 12:19:12,666 iteration 2412 : loss : 0.024797, loss_ce: 0.009897
2022-01-14 12:19:13,732 iteration 2413 : loss : 0.048716, loss_ce: 0.019812
2022-01-14 12:19:14,742 iteration 2414 : loss : 0.035691, loss_ce: 0.014626
 36%|██████████▎                  | 142/400 [43:48<1:18:34, 18.27s/it]2022-01-14 12:19:15,819 iteration 2415 : loss : 0.050558, loss_ce: 0.017726
2022-01-14 12:19:16,807 iteration 2416 : loss : 0.037708, loss_ce: 0.014574
2022-01-14 12:19:17,807 iteration 2417 : loss : 0.037050, loss_ce: 0.012147
2022-01-14 12:19:18,888 iteration 2418 : loss : 0.037760, loss_ce: 0.013603
2022-01-14 12:19:19,902 iteration 2419 : loss : 0.042490, loss_ce: 0.021741
2022-01-14 12:19:21,006 iteration 2420 : loss : 0.059660, loss_ce: 0.028329
2022-01-14 12:19:22,092 iteration 2421 : loss : 0.045174, loss_ce: 0.014928
2022-01-14 12:19:23,163 iteration 2422 : loss : 0.042004, loss_ce: 0.016635
2022-01-14 12:19:24,170 iteration 2423 : loss : 0.039112, loss_ce: 0.015044
2022-01-14 12:19:25,157 iteration 2424 : loss : 0.044696, loss_ce: 0.018755
2022-01-14 12:19:26,263 iteration 2425 : loss : 0.063933, loss_ce: 0.017679
2022-01-14 12:19:27,250 iteration 2426 : loss : 0.044647, loss_ce: 0.012263
2022-01-14 12:19:28,161 iteration 2427 : loss : 0.035232, loss_ce: 0.015546
2022-01-14 12:19:29,121 iteration 2428 : loss : 0.039725, loss_ce: 0.010799
2022-01-14 12:19:30,082 iteration 2429 : loss : 0.038606, loss_ce: 0.014560
2022-01-14 12:19:31,044 iteration 2430 : loss : 0.022822, loss_ce: 0.009058
2022-01-14 12:19:32,038 iteration 2431 : loss : 0.039637, loss_ce: 0.021801
 36%|██████████▎                  | 143/400 [44:06<1:17:01, 17.98s/it]2022-01-14 12:19:33,053 iteration 2432 : loss : 0.037234, loss_ce: 0.011993
2022-01-14 12:19:34,035 iteration 2433 : loss : 0.038258, loss_ce: 0.013879
2022-01-14 12:19:35,035 iteration 2434 : loss : 0.043369, loss_ce: 0.015171
2022-01-14 12:19:36,121 iteration 2435 : loss : 0.048379, loss_ce: 0.025586
2022-01-14 12:19:37,037 iteration 2436 : loss : 0.030082, loss_ce: 0.012608
2022-01-14 12:19:38,077 iteration 2437 : loss : 0.029947, loss_ce: 0.011125
2022-01-14 12:19:39,141 iteration 2438 : loss : 0.048435, loss_ce: 0.015812
2022-01-14 12:19:40,177 iteration 2439 : loss : 0.040729, loss_ce: 0.015212
2022-01-14 12:19:41,227 iteration 2440 : loss : 0.059317, loss_ce: 0.024607
2022-01-14 12:19:42,215 iteration 2441 : loss : 0.035530, loss_ce: 0.013376
2022-01-14 12:19:43,193 iteration 2442 : loss : 0.037960, loss_ce: 0.013868
2022-01-14 12:19:44,125 iteration 2443 : loss : 0.035414, loss_ce: 0.014047
2022-01-14 12:19:45,122 iteration 2444 : loss : 0.038476, loss_ce: 0.016231
2022-01-14 12:19:46,132 iteration 2445 : loss : 0.032181, loss_ce: 0.012404
2022-01-14 12:19:47,218 iteration 2446 : loss : 0.036980, loss_ce: 0.017252
2022-01-14 12:19:48,158 iteration 2447 : loss : 0.030432, loss_ce: 0.009942
2022-01-14 12:19:49,208 iteration 2448 : loss : 0.036465, loss_ce: 0.014778
 36%|██████████▍                  | 144/400 [44:23<1:15:40, 17.74s/it]2022-01-14 12:19:50,201 iteration 2449 : loss : 0.044563, loss_ce: 0.016227
2022-01-14 12:19:51,138 iteration 2450 : loss : 0.027287, loss_ce: 0.014286
2022-01-14 12:19:52,118 iteration 2451 : loss : 0.028841, loss_ce: 0.008927
2022-01-14 12:19:53,073 iteration 2452 : loss : 0.037400, loss_ce: 0.012679
2022-01-14 12:19:54,079 iteration 2453 : loss : 0.039742, loss_ce: 0.014439
2022-01-14 12:19:55,051 iteration 2454 : loss : 0.045003, loss_ce: 0.016304
2022-01-14 12:19:56,002 iteration 2455 : loss : 0.041877, loss_ce: 0.018828
2022-01-14 12:19:56,967 iteration 2456 : loss : 0.037455, loss_ce: 0.016035
2022-01-14 12:19:57,937 iteration 2457 : loss : 0.034913, loss_ce: 0.013775
2022-01-14 12:19:58,880 iteration 2458 : loss : 0.033897, loss_ce: 0.013388
2022-01-14 12:19:59,781 iteration 2459 : loss : 0.024510, loss_ce: 0.009560
2022-01-14 12:20:00,741 iteration 2460 : loss : 0.049645, loss_ce: 0.012106
2022-01-14 12:20:01,798 iteration 2461 : loss : 0.034510, loss_ce: 0.011517
2022-01-14 12:20:02,817 iteration 2462 : loss : 0.049816, loss_ce: 0.018514
2022-01-14 12:20:03,793 iteration 2463 : loss : 0.032976, loss_ce: 0.014501
2022-01-14 12:20:04,817 iteration 2464 : loss : 0.031058, loss_ce: 0.010729
2022-01-14 12:20:04,817 Training Data Eval:
2022-01-14 12:20:09,632   Average segmentation loss on training set: 0.0252
2022-01-14 12:20:09,633 Validation Data Eval:
2022-01-14 12:20:11,247   Average segmentation loss on validation set: 0.0634
2022-01-14 12:20:12,433 Found new lowest validation loss at iteration 2464! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_1BLOCK_best_val_loss_seed1234.pth
2022-01-14 12:20:13,413 iteration 2465 : loss : 0.031148, loss_ce: 0.012954
 36%|██████████▌                  | 145/400 [44:47<1:23:38, 19.68s/it]2022-01-14 12:20:14,525 iteration 2466 : loss : 0.047584, loss_ce: 0.019252
2022-01-14 12:20:15,595 iteration 2467 : loss : 0.045581, loss_ce: 0.018968
2022-01-14 12:20:16,568 iteration 2468 : loss : 0.034503, loss_ce: 0.013502
2022-01-14 12:20:17,511 iteration 2469 : loss : 0.029334, loss_ce: 0.012335
2022-01-14 12:20:18,491 iteration 2470 : loss : 0.048979, loss_ce: 0.015588
2022-01-14 12:20:19,576 iteration 2471 : loss : 0.059497, loss_ce: 0.022713
2022-01-14 12:20:20,546 iteration 2472 : loss : 0.051047, loss_ce: 0.019328
2022-01-14 12:20:21,596 iteration 2473 : loss : 0.051822, loss_ce: 0.020944
2022-01-14 12:20:22,558 iteration 2474 : loss : 0.031755, loss_ce: 0.011221
2022-01-14 12:20:23,552 iteration 2475 : loss : 0.040229, loss_ce: 0.014949
2022-01-14 12:20:24,495 iteration 2476 : loss : 0.046462, loss_ce: 0.022530
2022-01-14 12:20:25,572 iteration 2477 : loss : 0.057189, loss_ce: 0.025392
2022-01-14 12:20:26,603 iteration 2478 : loss : 0.043206, loss_ce: 0.015204
2022-01-14 12:20:27,518 iteration 2479 : loss : 0.055436, loss_ce: 0.016885
2022-01-14 12:20:28,522 iteration 2480 : loss : 0.044423, loss_ce: 0.017258
2022-01-14 12:20:29,582 iteration 2481 : loss : 0.040110, loss_ce: 0.012633
2022-01-14 12:20:30,554 iteration 2482 : loss : 0.030083, loss_ce: 0.013499
 36%|██████████▌                  | 146/400 [45:04<1:20:04, 18.92s/it]2022-01-14 12:20:31,687 iteration 2483 : loss : 0.052274, loss_ce: 0.025371
2022-01-14 12:20:32,711 iteration 2484 : loss : 0.043091, loss_ce: 0.009182
2022-01-14 12:20:33,670 iteration 2485 : loss : 0.034707, loss_ce: 0.015960
2022-01-14 12:20:34,654 iteration 2486 : loss : 0.028504, loss_ce: 0.011390
2022-01-14 12:20:35,635 iteration 2487 : loss : 0.037773, loss_ce: 0.013093
2022-01-14 12:20:36,695 iteration 2488 : loss : 0.038662, loss_ce: 0.017134
2022-01-14 12:20:37,681 iteration 2489 : loss : 0.037706, loss_ce: 0.015625
2022-01-14 12:20:38,728 iteration 2490 : loss : 0.042287, loss_ce: 0.018127
2022-01-14 12:20:39,806 iteration 2491 : loss : 0.042521, loss_ce: 0.018118
2022-01-14 12:20:40,715 iteration 2492 : loss : 0.027344, loss_ce: 0.010848
2022-01-14 12:20:41,728 iteration 2493 : loss : 0.040946, loss_ce: 0.016294
2022-01-14 12:20:42,707 iteration 2494 : loss : 0.051926, loss_ce: 0.016827
2022-01-14 12:20:43,677 iteration 2495 : loss : 0.060039, loss_ce: 0.037014
2022-01-14 12:20:44,861 iteration 2496 : loss : 0.050398, loss_ce: 0.013838
2022-01-14 12:20:45,911 iteration 2497 : loss : 0.055027, loss_ce: 0.018381
2022-01-14 12:20:46,969 iteration 2498 : loss : 0.038711, loss_ce: 0.015668
2022-01-14 12:20:47,909 iteration 2499 : loss : 0.028541, loss_ce: 0.007460
 37%|██████████▋                  | 147/400 [45:21<1:17:47, 18.45s/it]2022-01-14 12:20:48,944 iteration 2500 : loss : 0.039839, loss_ce: 0.015080
2022-01-14 12:20:49,928 iteration 2501 : loss : 0.031647, loss_ce: 0.009556
2022-01-14 12:20:50,994 iteration 2502 : loss : 0.051659, loss_ce: 0.020008
2022-01-14 12:20:51,934 iteration 2503 : loss : 0.038290, loss_ce: 0.013616
2022-01-14 12:20:52,892 iteration 2504 : loss : 0.045271, loss_ce: 0.016012
2022-01-14 12:20:53,923 iteration 2505 : loss : 0.046413, loss_ce: 0.019981
2022-01-14 12:20:54,915 iteration 2506 : loss : 0.040746, loss_ce: 0.012139
2022-01-14 12:20:55,865 iteration 2507 : loss : 0.035323, loss_ce: 0.015851
2022-01-14 12:20:56,835 iteration 2508 : loss : 0.029151, loss_ce: 0.009773
2022-01-14 12:20:57,806 iteration 2509 : loss : 0.032751, loss_ce: 0.010948
2022-01-14 12:20:58,764 iteration 2510 : loss : 0.029853, loss_ce: 0.012936
2022-01-14 12:20:59,764 iteration 2511 : loss : 0.030143, loss_ce: 0.013631
2022-01-14 12:21:00,777 iteration 2512 : loss : 0.042562, loss_ce: 0.015697
2022-01-14 12:21:01,826 iteration 2513 : loss : 0.048552, loss_ce: 0.017619
2022-01-14 12:21:02,834 iteration 2514 : loss : 0.041613, loss_ce: 0.014015
2022-01-14 12:21:03,824 iteration 2515 : loss : 0.031232, loss_ce: 0.017382
2022-01-14 12:21:04,804 iteration 2516 : loss : 0.029515, loss_ce: 0.014700
 37%|██████████▋                  | 148/400 [45:38<1:15:31, 17.98s/it]2022-01-14 12:21:05,832 iteration 2517 : loss : 0.032483, loss_ce: 0.012831
2022-01-14 12:21:06,831 iteration 2518 : loss : 0.057748, loss_ce: 0.019850
2022-01-14 12:21:07,854 iteration 2519 : loss : 0.047148, loss_ce: 0.019620
2022-01-14 12:21:08,852 iteration 2520 : loss : 0.044451, loss_ce: 0.016542
2022-01-14 12:21:09,831 iteration 2521 : loss : 0.034523, loss_ce: 0.013372
2022-01-14 12:21:10,838 iteration 2522 : loss : 0.042992, loss_ce: 0.023028
2022-01-14 12:21:11,883 iteration 2523 : loss : 0.050938, loss_ce: 0.010683
2022-01-14 12:21:12,857 iteration 2524 : loss : 0.032138, loss_ce: 0.013104
2022-01-14 12:21:13,863 iteration 2525 : loss : 0.032934, loss_ce: 0.014212
2022-01-14 12:21:14,890 iteration 2526 : loss : 0.042245, loss_ce: 0.016079
2022-01-14 12:21:15,892 iteration 2527 : loss : 0.038218, loss_ce: 0.014890
2022-01-14 12:21:16,911 iteration 2528 : loss : 0.040750, loss_ce: 0.016069
2022-01-14 12:21:17,916 iteration 2529 : loss : 0.053020, loss_ce: 0.021869
2022-01-14 12:21:18,926 iteration 2530 : loss : 0.028729, loss_ce: 0.012956
2022-01-14 12:21:19,999 iteration 2531 : loss : 0.048977, loss_ce: 0.018338
2022-01-14 12:21:20,993 iteration 2532 : loss : 0.040806, loss_ce: 0.013239
2022-01-14 12:21:22,002 iteration 2533 : loss : 0.045775, loss_ce: 0.013714
 37%|██████████▊                  | 149/400 [45:56<1:14:13, 17.74s/it]2022-01-14 12:21:22,989 iteration 2534 : loss : 0.035410, loss_ce: 0.016746
2022-01-14 12:21:24,063 iteration 2535 : loss : 0.038624, loss_ce: 0.014508
2022-01-14 12:21:25,027 iteration 2536 : loss : 0.033205, loss_ce: 0.015439
2022-01-14 12:21:25,993 iteration 2537 : loss : 0.030448, loss_ce: 0.012652
2022-01-14 12:21:26,889 iteration 2538 : loss : 0.026249, loss_ce: 0.011811
2022-01-14 12:21:27,904 iteration 2539 : loss : 0.034940, loss_ce: 0.015158
2022-01-14 12:21:28,852 iteration 2540 : loss : 0.029928, loss_ce: 0.009624
2022-01-14 12:21:29,820 iteration 2541 : loss : 0.030204, loss_ce: 0.012316
2022-01-14 12:21:30,750 iteration 2542 : loss : 0.027051, loss_ce: 0.009511
2022-01-14 12:21:31,685 iteration 2543 : loss : 0.030587, loss_ce: 0.010543
2022-01-14 12:21:32,679 iteration 2544 : loss : 0.043324, loss_ce: 0.016007
2022-01-14 12:21:33,784 iteration 2545 : loss : 0.044472, loss_ce: 0.017864
2022-01-14 12:21:34,911 iteration 2546 : loss : 0.050190, loss_ce: 0.022627
2022-01-14 12:21:35,856 iteration 2547 : loss : 0.028471, loss_ce: 0.013379
2022-01-14 12:21:36,882 iteration 2548 : loss : 0.033097, loss_ce: 0.015889
2022-01-14 12:21:37,890 iteration 2549 : loss : 0.036712, loss_ce: 0.011122
2022-01-14 12:21:37,890 Training Data Eval:
2022-01-14 12:21:42,702   Average segmentation loss on training set: 0.0265
2022-01-14 12:21:42,702 Validation Data Eval:
2022-01-14 12:21:44,310   Average segmentation loss on validation set: 0.0853
2022-01-14 12:21:45,268 iteration 2550 : loss : 0.040090, loss_ce: 0.012510
 38%|██████████▉                  | 150/400 [46:19<1:20:51, 19.41s/it]2022-01-14 12:21:46,299 iteration 2551 : loss : 0.030436, loss_ce: 0.013861
2022-01-14 12:21:47,348 iteration 2552 : loss : 0.027835, loss_ce: 0.011142
2022-01-14 12:21:48,274 iteration 2553 : loss : 0.021633, loss_ce: 0.007243
2022-01-14 12:21:49,274 iteration 2554 : loss : 0.035497, loss_ce: 0.012710
2022-01-14 12:21:50,256 iteration 2555 : loss : 0.035797, loss_ce: 0.010033
2022-01-14 12:21:51,303 iteration 2556 : loss : 0.039428, loss_ce: 0.019038
2022-01-14 12:21:52,284 iteration 2557 : loss : 0.042512, loss_ce: 0.019477
2022-01-14 12:21:53,286 iteration 2558 : loss : 0.049133, loss_ce: 0.031534
2022-01-14 12:21:54,363 iteration 2559 : loss : 0.034728, loss_ce: 0.014088
2022-01-14 12:21:55,354 iteration 2560 : loss : 0.034914, loss_ce: 0.018028
2022-01-14 12:21:56,437 iteration 2561 : loss : 0.028783, loss_ce: 0.010252
2022-01-14 12:21:57,458 iteration 2562 : loss : 0.034176, loss_ce: 0.013307
2022-01-14 12:21:58,493 iteration 2563 : loss : 0.039135, loss_ce: 0.016641
2022-01-14 12:21:59,450 iteration 2564 : loss : 0.038653, loss_ce: 0.017012
2022-01-14 12:22:00,409 iteration 2565 : loss : 0.036773, loss_ce: 0.014237
2022-01-14 12:22:01,388 iteration 2566 : loss : 0.046739, loss_ce: 0.022569
2022-01-14 12:22:02,395 iteration 2567 : loss : 0.073476, loss_ce: 0.023822
 38%|██████████▉                  | 151/400 [46:36<1:17:41, 18.72s/it]2022-01-14 12:22:03,471 iteration 2568 : loss : 0.039095, loss_ce: 0.018077
2022-01-14 12:22:04,446 iteration 2569 : loss : 0.029447, loss_ce: 0.013958
2022-01-14 12:22:05,424 iteration 2570 : loss : 0.034269, loss_ce: 0.012122
2022-01-14 12:22:06,407 iteration 2571 : loss : 0.024874, loss_ce: 0.011247
2022-01-14 12:22:07,341 iteration 2572 : loss : 0.063442, loss_ce: 0.019770
2022-01-14 12:22:08,284 iteration 2573 : loss : 0.035729, loss_ce: 0.013591
2022-01-14 12:22:09,261 iteration 2574 : loss : 0.045316, loss_ce: 0.015353
2022-01-14 12:22:10,368 iteration 2575 : loss : 0.048739, loss_ce: 0.021553
2022-01-14 12:22:11,381 iteration 2576 : loss : 0.031302, loss_ce: 0.012556
2022-01-14 12:22:12,383 iteration 2577 : loss : 0.052670, loss_ce: 0.021262
2022-01-14 12:22:13,391 iteration 2578 : loss : 0.047462, loss_ce: 0.014852
2022-01-14 12:22:14,329 iteration 2579 : loss : 0.052269, loss_ce: 0.011829
2022-01-14 12:22:15,382 iteration 2580 : loss : 0.050568, loss_ce: 0.012693
2022-01-14 12:22:16,427 iteration 2581 : loss : 0.037233, loss_ce: 0.014592
2022-01-14 12:22:17,500 iteration 2582 : loss : 0.035142, loss_ce: 0.011943
2022-01-14 12:22:18,488 iteration 2583 : loss : 0.031778, loss_ce: 0.011490
2022-01-14 12:22:19,401 iteration 2584 : loss : 0.030909, loss_ce: 0.011530
 38%|███████████                  | 152/400 [46:53<1:15:15, 18.21s/it]2022-01-14 12:22:20,451 iteration 2585 : loss : 0.027162, loss_ce: 0.009479
2022-01-14 12:22:21,453 iteration 2586 : loss : 0.048955, loss_ce: 0.021871
2022-01-14 12:22:22,386 iteration 2587 : loss : 0.039371, loss_ce: 0.013546
2022-01-14 12:22:23,355 iteration 2588 : loss : 0.042781, loss_ce: 0.019347
2022-01-14 12:22:24,391 iteration 2589 : loss : 0.041872, loss_ce: 0.015282
2022-01-14 12:22:25,440 iteration 2590 : loss : 0.039719, loss_ce: 0.015482
2022-01-14 12:22:26,402 iteration 2591 : loss : 0.029875, loss_ce: 0.009469
2022-01-14 12:22:27,365 iteration 2592 : loss : 0.035752, loss_ce: 0.012128
2022-01-14 12:22:28,336 iteration 2593 : loss : 0.034071, loss_ce: 0.014488
2022-01-14 12:22:29,460 iteration 2594 : loss : 0.045591, loss_ce: 0.020192
2022-01-14 12:22:30,498 iteration 2595 : loss : 0.046474, loss_ce: 0.018313
2022-01-14 12:22:31,461 iteration 2596 : loss : 0.027281, loss_ce: 0.012340
2022-01-14 12:22:32,403 iteration 2597 : loss : 0.034705, loss_ce: 0.012826
2022-01-14 12:22:33,376 iteration 2598 : loss : 0.029540, loss_ce: 0.012176
2022-01-14 12:22:34,354 iteration 2599 : loss : 0.029074, loss_ce: 0.008029
2022-01-14 12:22:35,334 iteration 2600 : loss : 0.030070, loss_ce: 0.010900
2022-01-14 12:22:36,268 iteration 2601 : loss : 0.027752, loss_ce: 0.011181
 38%|███████████                  | 153/400 [47:10<1:13:18, 17.81s/it]2022-01-14 12:22:37,356 iteration 2602 : loss : 0.041852, loss_ce: 0.018088
2022-01-14 12:22:38,280 iteration 2603 : loss : 0.025539, loss_ce: 0.010373
2022-01-14 12:22:39,258 iteration 2604 : loss : 0.032434, loss_ce: 0.011718
2022-01-14 12:22:40,380 iteration 2605 : loss : 0.028927, loss_ce: 0.009825
2022-01-14 12:22:41,370 iteration 2606 : loss : 0.041367, loss_ce: 0.017981
2022-01-14 12:22:42,368 iteration 2607 : loss : 0.034453, loss_ce: 0.015212
2022-01-14 12:22:43,308 iteration 2608 : loss : 0.032514, loss_ce: 0.015391
2022-01-14 12:22:44,262 iteration 2609 : loss : 0.032492, loss_ce: 0.009936
2022-01-14 12:22:45,370 iteration 2610 : loss : 0.055513, loss_ce: 0.021872
2022-01-14 12:22:46,337 iteration 2611 : loss : 0.038040, loss_ce: 0.013942
2022-01-14 12:22:47,235 iteration 2612 : loss : 0.030015, loss_ce: 0.014144
2022-01-14 12:22:48,196 iteration 2613 : loss : 0.046717, loss_ce: 0.017242
2022-01-14 12:22:49,241 iteration 2614 : loss : 0.041530, loss_ce: 0.014139
2022-01-14 12:22:50,199 iteration 2615 : loss : 0.035642, loss_ce: 0.014024
2022-01-14 12:22:51,162 iteration 2616 : loss : 0.029991, loss_ce: 0.011399
2022-01-14 12:22:52,238 iteration 2617 : loss : 0.045399, loss_ce: 0.013667
2022-01-14 12:22:53,258 iteration 2618 : loss : 0.044584, loss_ce: 0.020315
 38%|███████████▏                 | 154/400 [47:27<1:11:59, 17.56s/it]2022-01-14 12:22:54,362 iteration 2619 : loss : 0.083599, loss_ce: 0.023370
2022-01-14 12:22:55,329 iteration 2620 : loss : 0.036253, loss_ce: 0.015091
2022-01-14 12:22:56,348 iteration 2621 : loss : 0.034639, loss_ce: 0.011519
2022-01-14 12:22:57,368 iteration 2622 : loss : 0.037987, loss_ce: 0.018887
2022-01-14 12:22:58,397 iteration 2623 : loss : 0.040479, loss_ce: 0.018810
2022-01-14 12:22:59,349 iteration 2624 : loss : 0.029148, loss_ce: 0.009549
2022-01-14 12:23:00,325 iteration 2625 : loss : 0.028598, loss_ce: 0.011818
2022-01-14 12:23:01,384 iteration 2626 : loss : 0.045582, loss_ce: 0.019396
2022-01-14 12:23:02,405 iteration 2627 : loss : 0.061234, loss_ce: 0.016973
2022-01-14 12:23:03,355 iteration 2628 : loss : 0.034047, loss_ce: 0.012484
2022-01-14 12:23:04,407 iteration 2629 : loss : 0.039260, loss_ce: 0.014542
2022-01-14 12:23:05,345 iteration 2630 : loss : 0.024082, loss_ce: 0.007556
2022-01-14 12:23:06,352 iteration 2631 : loss : 0.031139, loss_ce: 0.014495
2022-01-14 12:23:07,372 iteration 2632 : loss : 0.045697, loss_ce: 0.016846
2022-01-14 12:23:08,332 iteration 2633 : loss : 0.027356, loss_ce: 0.013519
2022-01-14 12:23:09,348 iteration 2634 : loss : 0.036033, loss_ce: 0.013811
2022-01-14 12:23:09,348 Training Data Eval:
2022-01-14 12:23:14,162   Average segmentation loss on training set: 0.0268
2022-01-14 12:23:14,162 Validation Data Eval:
2022-01-14 12:23:15,779   Average segmentation loss on validation set: 0.0722
2022-01-14 12:23:16,840 iteration 2635 : loss : 0.041390, loss_ce: 0.018454
 39%|███████████▏                 | 155/400 [47:50<1:19:04, 19.36s/it]2022-01-14 12:23:17,853 iteration 2636 : loss : 0.027554, loss_ce: 0.009058
2022-01-14 12:23:18,978 iteration 2637 : loss : 0.049188, loss_ce: 0.017169
2022-01-14 12:23:19,984 iteration 2638 : loss : 0.027736, loss_ce: 0.010620
2022-01-14 12:23:20,869 iteration 2639 : loss : 0.027289, loss_ce: 0.010438
2022-01-14 12:23:21,812 iteration 2640 : loss : 0.038809, loss_ce: 0.015136
2022-01-14 12:23:22,886 iteration 2641 : loss : 0.048790, loss_ce: 0.021307
2022-01-14 12:23:23,929 iteration 2642 : loss : 0.045935, loss_ce: 0.014817
2022-01-14 12:23:24,963 iteration 2643 : loss : 0.044747, loss_ce: 0.014057
2022-01-14 12:23:25,924 iteration 2644 : loss : 0.037552, loss_ce: 0.011518
2022-01-14 12:23:26,881 iteration 2645 : loss : 0.036040, loss_ce: 0.018328
2022-01-14 12:23:27,850 iteration 2646 : loss : 0.038407, loss_ce: 0.012439
2022-01-14 12:23:28,894 iteration 2647 : loss : 0.038393, loss_ce: 0.016933
2022-01-14 12:23:29,814 iteration 2648 : loss : 0.020542, loss_ce: 0.009211
2022-01-14 12:23:30,847 iteration 2649 : loss : 0.035142, loss_ce: 0.015796
2022-01-14 12:23:31,876 iteration 2650 : loss : 0.051736, loss_ce: 0.025067
2022-01-14 12:23:32,840 iteration 2651 : loss : 0.043390, loss_ce: 0.013810
2022-01-14 12:23:33,832 iteration 2652 : loss : 0.036952, loss_ce: 0.018474
 39%|███████████▎                 | 156/400 [48:07<1:15:51, 18.65s/it]2022-01-14 12:23:34,972 iteration 2653 : loss : 0.040953, loss_ce: 0.014741
2022-01-14 12:23:35,964 iteration 2654 : loss : 0.034068, loss_ce: 0.012641
2022-01-14 12:23:36,903 iteration 2655 : loss : 0.027985, loss_ce: 0.011774
2022-01-14 12:23:37,823 iteration 2656 : loss : 0.027763, loss_ce: 0.012889
2022-01-14 12:23:38,760 iteration 2657 : loss : 0.029014, loss_ce: 0.010253
2022-01-14 12:23:39,716 iteration 2658 : loss : 0.027636, loss_ce: 0.010929
2022-01-14 12:23:40,826 iteration 2659 : loss : 0.036714, loss_ce: 0.016943
2022-01-14 12:23:41,817 iteration 2660 : loss : 0.031385, loss_ce: 0.011602
2022-01-14 12:23:42,732 iteration 2661 : loss : 0.028879, loss_ce: 0.010893
2022-01-14 12:23:43,773 iteration 2662 : loss : 0.035256, loss_ce: 0.014459
2022-01-14 12:23:44,724 iteration 2663 : loss : 0.034869, loss_ce: 0.014057
2022-01-14 12:23:45,779 iteration 2664 : loss : 0.031327, loss_ce: 0.011377
2022-01-14 12:23:46,755 iteration 2665 : loss : 0.033602, loss_ce: 0.011948
2022-01-14 12:23:47,756 iteration 2666 : loss : 0.049257, loss_ce: 0.017404
2022-01-14 12:23:48,781 iteration 2667 : loss : 0.027648, loss_ce: 0.010209
2022-01-14 12:23:49,796 iteration 2668 : loss : 0.033292, loss_ce: 0.011933
2022-01-14 12:23:50,834 iteration 2669 : loss : 0.040149, loss_ce: 0.018492
 39%|███████████▍                 | 157/400 [48:24<1:13:32, 18.16s/it]2022-01-14 12:23:51,913 iteration 2670 : loss : 0.050384, loss_ce: 0.013120
2022-01-14 12:23:52,927 iteration 2671 : loss : 0.038192, loss_ce: 0.010530
2022-01-14 12:23:53,955 iteration 2672 : loss : 0.023126, loss_ce: 0.009088
2022-01-14 12:23:55,005 iteration 2673 : loss : 0.039653, loss_ce: 0.014314
2022-01-14 12:23:55,965 iteration 2674 : loss : 0.033314, loss_ce: 0.015675
2022-01-14 12:23:57,022 iteration 2675 : loss : 0.044669, loss_ce: 0.017997
2022-01-14 12:23:58,034 iteration 2676 : loss : 0.031617, loss_ce: 0.008599
2022-01-14 12:23:58,971 iteration 2677 : loss : 0.026933, loss_ce: 0.011795
2022-01-14 12:23:59,894 iteration 2678 : loss : 0.029785, loss_ce: 0.009244
2022-01-14 12:24:00,906 iteration 2679 : loss : 0.042721, loss_ce: 0.019248
2022-01-14 12:24:01,955 iteration 2680 : loss : 0.030889, loss_ce: 0.013374
2022-01-14 12:24:02,939 iteration 2681 : loss : 0.027431, loss_ce: 0.013271
2022-01-14 12:24:03,875 iteration 2682 : loss : 0.029281, loss_ce: 0.012563
2022-01-14 12:24:04,875 iteration 2683 : loss : 0.030802, loss_ce: 0.014401
2022-01-14 12:24:05,866 iteration 2684 : loss : 0.044966, loss_ce: 0.012065
2022-01-14 12:24:06,864 iteration 2685 : loss : 0.032101, loss_ce: 0.014063
2022-01-14 12:24:07,849 iteration 2686 : loss : 0.030921, loss_ce: 0.010022
 40%|███████████▍                 | 158/400 [48:41<1:11:51, 17.82s/it]2022-01-14 12:24:08,880 iteration 2687 : loss : 0.019583, loss_ce: 0.008461
2022-01-14 12:24:09,857 iteration 2688 : loss : 0.041811, loss_ce: 0.015499
2022-01-14 12:24:10,741 iteration 2689 : loss : 0.026213, loss_ce: 0.009577
2022-01-14 12:24:11,719 iteration 2690 : loss : 0.030058, loss_ce: 0.012185
2022-01-14 12:24:12,726 iteration 2691 : loss : 0.025270, loss_ce: 0.007810
2022-01-14 12:24:13,711 iteration 2692 : loss : 0.032968, loss_ce: 0.010742
2022-01-14 12:24:14,665 iteration 2693 : loss : 0.032346, loss_ce: 0.011152
2022-01-14 12:24:15,567 iteration 2694 : loss : 0.033912, loss_ce: 0.011907
2022-01-14 12:24:16,599 iteration 2695 : loss : 0.041921, loss_ce: 0.016762
2022-01-14 12:24:17,688 iteration 2696 : loss : 0.048657, loss_ce: 0.018072
2022-01-14 12:24:18,738 iteration 2697 : loss : 0.040559, loss_ce: 0.022519
2022-01-14 12:24:19,717 iteration 2698 : loss : 0.024935, loss_ce: 0.010027
2022-01-14 12:24:20,672 iteration 2699 : loss : 0.031037, loss_ce: 0.010752
2022-01-14 12:24:21,629 iteration 2700 : loss : 0.037420, loss_ce: 0.011112
2022-01-14 12:24:22,625 iteration 2701 : loss : 0.040764, loss_ce: 0.017960
2022-01-14 12:24:23,649 iteration 2702 : loss : 0.053851, loss_ce: 0.014441
2022-01-14 12:24:24,681 iteration 2703 : loss : 0.045768, loss_ce: 0.016992
 40%|███████████▌                 | 159/400 [48:58<1:10:22, 17.52s/it]2022-01-14 12:24:25,678 iteration 2704 : loss : 0.024100, loss_ce: 0.008070
2022-01-14 12:24:26,620 iteration 2705 : loss : 0.030494, loss_ce: 0.010394
2022-01-14 12:24:27,651 iteration 2706 : loss : 0.049051, loss_ce: 0.027350
2022-01-14 12:24:28,639 iteration 2707 : loss : 0.026744, loss_ce: 0.009158
2022-01-14 12:24:29,612 iteration 2708 : loss : 0.052148, loss_ce: 0.015381
2022-01-14 12:24:30,668 iteration 2709 : loss : 0.036830, loss_ce: 0.010480
2022-01-14 12:24:31,706 iteration 2710 : loss : 0.050342, loss_ce: 0.020053
2022-01-14 12:24:32,673 iteration 2711 : loss : 0.026152, loss_ce: 0.009376
2022-01-14 12:24:33,652 iteration 2712 : loss : 0.043034, loss_ce: 0.017690
2022-01-14 12:24:34,659 iteration 2713 : loss : 0.034027, loss_ce: 0.011935
2022-01-14 12:24:35,661 iteration 2714 : loss : 0.033727, loss_ce: 0.013342
2022-01-14 12:24:36,650 iteration 2715 : loss : 0.040823, loss_ce: 0.022608
2022-01-14 12:24:37,626 iteration 2716 : loss : 0.036517, loss_ce: 0.009482
2022-01-14 12:24:38,557 iteration 2717 : loss : 0.030205, loss_ce: 0.010610
2022-01-14 12:24:39,577 iteration 2718 : loss : 0.033182, loss_ce: 0.012103
2022-01-14 12:24:40,535 iteration 2719 : loss : 0.022531, loss_ce: 0.010118
2022-01-14 12:24:40,536 Training Data Eval:
2022-01-14 12:24:45,352   Average segmentation loss on training set: 0.0232
2022-01-14 12:24:45,352 Validation Data Eval:
2022-01-14 12:24:46,969   Average segmentation loss on validation set: 0.0656
2022-01-14 12:24:47,942 iteration 2720 : loss : 0.027111, loss_ce: 0.011550
 40%|███████████▌                 | 160/400 [49:21<1:16:57, 19.24s/it]2022-01-14 12:24:48,995 iteration 2721 : loss : 0.036598, loss_ce: 0.011804
2022-01-14 12:24:50,009 iteration 2722 : loss : 0.026140, loss_ce: 0.011134
2022-01-14 12:24:51,073 iteration 2723 : loss : 0.052848, loss_ce: 0.023980
2022-01-14 12:24:52,013 iteration 2724 : loss : 0.039863, loss_ce: 0.013359
2022-01-14 12:24:52,980 iteration 2725 : loss : 0.051415, loss_ce: 0.016312
2022-01-14 12:24:54,073 iteration 2726 : loss : 0.029607, loss_ce: 0.009690
2022-01-14 12:24:55,066 iteration 2727 : loss : 0.053262, loss_ce: 0.019430
2022-01-14 12:24:56,106 iteration 2728 : loss : 0.026902, loss_ce: 0.010782
2022-01-14 12:24:57,129 iteration 2729 : loss : 0.082131, loss_ce: 0.035391
2022-01-14 12:24:58,186 iteration 2730 : loss : 0.033379, loss_ce: 0.012925
2022-01-14 12:24:59,166 iteration 2731 : loss : 0.035762, loss_ce: 0.013316
2022-01-14 12:25:00,069 iteration 2732 : loss : 0.027071, loss_ce: 0.011354
2022-01-14 12:25:01,048 iteration 2733 : loss : 0.026714, loss_ce: 0.012810
2022-01-14 12:25:02,046 iteration 2734 : loss : 0.087795, loss_ce: 0.020506
2022-01-14 12:25:03,046 iteration 2735 : loss : 0.032297, loss_ce: 0.016750
2022-01-14 12:25:04,024 iteration 2736 : loss : 0.036862, loss_ce: 0.012469
2022-01-14 12:25:05,003 iteration 2737 : loss : 0.048429, loss_ce: 0.014438
 40%|███████████▋                 | 161/400 [49:39<1:14:02, 18.59s/it]2022-01-14 12:25:06,098 iteration 2738 : loss : 0.053881, loss_ce: 0.022809
2022-01-14 12:25:07,040 iteration 2739 : loss : 0.038691, loss_ce: 0.010521
2022-01-14 12:25:08,111 iteration 2740 : loss : 0.058316, loss_ce: 0.028301
2022-01-14 12:25:09,100 iteration 2741 : loss : 0.048532, loss_ce: 0.020896
2022-01-14 12:25:10,101 iteration 2742 : loss : 0.040641, loss_ce: 0.017388
2022-01-14 12:25:11,037 iteration 2743 : loss : 0.044688, loss_ce: 0.017159
2022-01-14 12:25:12,018 iteration 2744 : loss : 0.031062, loss_ce: 0.012471
2022-01-14 12:25:12,966 iteration 2745 : loss : 0.045069, loss_ce: 0.014602
2022-01-14 12:25:14,050 iteration 2746 : loss : 0.106035, loss_ce: 0.030507
2022-01-14 12:25:15,011 iteration 2747 : loss : 0.029479, loss_ce: 0.011156
2022-01-14 12:25:16,050 iteration 2748 : loss : 0.030628, loss_ce: 0.007949
2022-01-14 12:25:17,119 iteration 2749 : loss : 0.035440, loss_ce: 0.013376
2022-01-14 12:25:18,103 iteration 2750 : loss : 0.037592, loss_ce: 0.015241
2022-01-14 12:25:19,112 iteration 2751 : loss : 0.049528, loss_ce: 0.015385
2022-01-14 12:25:20,208 iteration 2752 : loss : 0.039920, loss_ce: 0.016889
2022-01-14 12:25:21,303 iteration 2753 : loss : 0.049147, loss_ce: 0.020588
2022-01-14 12:25:22,312 iteration 2754 : loss : 0.034500, loss_ce: 0.016711
 40%|███████████▋                 | 162/400 [49:56<1:12:12, 18.20s/it]2022-01-14 12:25:23,237 iteration 2755 : loss : 0.024756, loss_ce: 0.008228
2022-01-14 12:25:24,242 iteration 2756 : loss : 0.032599, loss_ce: 0.014431
2022-01-14 12:25:25,240 iteration 2757 : loss : 0.028476, loss_ce: 0.012063
2022-01-14 12:25:26,232 iteration 2758 : loss : 0.029791, loss_ce: 0.011436
2022-01-14 12:25:27,222 iteration 2759 : loss : 0.034416, loss_ce: 0.014100
2022-01-14 12:25:28,215 iteration 2760 : loss : 0.043190, loss_ce: 0.017086
2022-01-14 12:25:29,242 iteration 2761 : loss : 0.044637, loss_ce: 0.015652
2022-01-14 12:25:30,228 iteration 2762 : loss : 0.034308, loss_ce: 0.014945
2022-01-14 12:25:31,251 iteration 2763 : loss : 0.063918, loss_ce: 0.023189
2022-01-14 12:25:32,184 iteration 2764 : loss : 0.025795, loss_ce: 0.009949
2022-01-14 12:25:33,288 iteration 2765 : loss : 0.028423, loss_ce: 0.009301
2022-01-14 12:25:34,213 iteration 2766 : loss : 0.040797, loss_ce: 0.014883
2022-01-14 12:25:35,220 iteration 2767 : loss : 0.045039, loss_ce: 0.018511
2022-01-14 12:25:36,192 iteration 2768 : loss : 0.032086, loss_ce: 0.010090
2022-01-14 12:25:37,117 iteration 2769 : loss : 0.026771, loss_ce: 0.012145
2022-01-14 12:25:38,073 iteration 2770 : loss : 0.030368, loss_ce: 0.013589
2022-01-14 12:25:39,059 iteration 2771 : loss : 0.041592, loss_ce: 0.017581
 41%|███████████▊                 | 163/400 [50:13<1:10:10, 17.77s/it]2022-01-14 12:25:40,038 iteration 2772 : loss : 0.036033, loss_ce: 0.013021
2022-01-14 12:25:41,036 iteration 2773 : loss : 0.027266, loss_ce: 0.011284
2022-01-14 12:25:42,034 iteration 2774 : loss : 0.048905, loss_ce: 0.010443
2022-01-14 12:25:43,039 iteration 2775 : loss : 0.045940, loss_ce: 0.018884
2022-01-14 12:25:44,011 iteration 2776 : loss : 0.031267, loss_ce: 0.012609
2022-01-14 12:25:45,058 iteration 2777 : loss : 0.021991, loss_ce: 0.007548
2022-01-14 12:25:46,008 iteration 2778 : loss : 0.025257, loss_ce: 0.008539
2022-01-14 12:25:46,961 iteration 2779 : loss : 0.026122, loss_ce: 0.009870
2022-01-14 12:25:47,936 iteration 2780 : loss : 0.027382, loss_ce: 0.014057
2022-01-14 12:25:49,044 iteration 2781 : loss : 0.036923, loss_ce: 0.014973
2022-01-14 12:25:50,118 iteration 2782 : loss : 0.032978, loss_ce: 0.015310
2022-01-14 12:25:51,098 iteration 2783 : loss : 0.034759, loss_ce: 0.011759
2022-01-14 12:25:51,986 iteration 2784 : loss : 0.031965, loss_ce: 0.008628
2022-01-14 12:25:52,923 iteration 2785 : loss : 0.025716, loss_ce: 0.011871
2022-01-14 12:25:53,851 iteration 2786 : loss : 0.026234, loss_ce: 0.010967
2022-01-14 12:25:54,799 iteration 2787 : loss : 0.024907, loss_ce: 0.010096
2022-01-14 12:25:55,913 iteration 2788 : loss : 0.036536, loss_ce: 0.015424
 41%|███████████▉                 | 164/400 [50:29<1:08:48, 17.49s/it]2022-01-14 12:25:56,979 iteration 2789 : loss : 0.027067, loss_ce: 0.008432
2022-01-14 12:25:58,064 iteration 2790 : loss : 0.048821, loss_ce: 0.017543
2022-01-14 12:25:59,000 iteration 2791 : loss : 0.025073, loss_ce: 0.007520
2022-01-14 12:25:59,979 iteration 2792 : loss : 0.030333, loss_ce: 0.011181
2022-01-14 12:26:00,971 iteration 2793 : loss : 0.032463, loss_ce: 0.011091
2022-01-14 12:26:02,021 iteration 2794 : loss : 0.036802, loss_ce: 0.018281
2022-01-14 12:26:03,003 iteration 2795 : loss : 0.036829, loss_ce: 0.014933
2022-01-14 12:26:03,965 iteration 2796 : loss : 0.034260, loss_ce: 0.010914
2022-01-14 12:26:04,994 iteration 2797 : loss : 0.034612, loss_ce: 0.016582
2022-01-14 12:26:06,003 iteration 2798 : loss : 0.036563, loss_ce: 0.011512
2022-01-14 12:26:07,080 iteration 2799 : loss : 0.039886, loss_ce: 0.013477
2022-01-14 12:26:08,093 iteration 2800 : loss : 0.038254, loss_ce: 0.018649
2022-01-14 12:26:09,002 iteration 2801 : loss : 0.052441, loss_ce: 0.014786
2022-01-14 12:26:09,954 iteration 2802 : loss : 0.021726, loss_ce: 0.007985
2022-01-14 12:26:10,963 iteration 2803 : loss : 0.046640, loss_ce: 0.019688
2022-01-14 12:26:11,872 iteration 2804 : loss : 0.034471, loss_ce: 0.013874
2022-01-14 12:26:11,873 Training Data Eval:
2022-01-14 12:26:16,688   Average segmentation loss on training set: 0.0235
2022-01-14 12:26:16,688 Validation Data Eval:
2022-01-14 12:26:18,295   Average segmentation loss on validation set: 0.0755
2022-01-14 12:26:19,381 iteration 2805 : loss : 0.046011, loss_ce: 0.014726
 41%|███████████▉                 | 165/400 [50:53<1:15:32, 19.29s/it]2022-01-14 12:26:20,505 iteration 2806 : loss : 0.038726, loss_ce: 0.014939
2022-01-14 12:26:21,575 iteration 2807 : loss : 0.049451, loss_ce: 0.012935
2022-01-14 12:26:22,617 iteration 2808 : loss : 0.033810, loss_ce: 0.010765
2022-01-14 12:26:23,633 iteration 2809 : loss : 0.038728, loss_ce: 0.014987
2022-01-14 12:26:24,557 iteration 2810 : loss : 0.039458, loss_ce: 0.012932
2022-01-14 12:26:25,591 iteration 2811 : loss : 0.034405, loss_ce: 0.017493
2022-01-14 12:26:26,519 iteration 2812 : loss : 0.022151, loss_ce: 0.009202
2022-01-14 12:26:27,577 iteration 2813 : loss : 0.038468, loss_ce: 0.015955
2022-01-14 12:26:28,593 iteration 2814 : loss : 0.044228, loss_ce: 0.018332
2022-01-14 12:26:29,585 iteration 2815 : loss : 0.035685, loss_ce: 0.016600
2022-01-14 12:26:30,574 iteration 2816 : loss : 0.033672, loss_ce: 0.011679
2022-01-14 12:26:31,643 iteration 2817 : loss : 0.085119, loss_ce: 0.018676
2022-01-14 12:26:32,697 iteration 2818 : loss : 0.043837, loss_ce: 0.019376
2022-01-14 12:26:33,673 iteration 2819 : loss : 0.035823, loss_ce: 0.015421
2022-01-14 12:26:34,763 iteration 2820 : loss : 0.035949, loss_ce: 0.012991
2022-01-14 12:26:35,836 iteration 2821 : loss : 0.054400, loss_ce: 0.020657
2022-01-14 12:26:36,874 iteration 2822 : loss : 0.030143, loss_ce: 0.009567
 42%|████████████                 | 166/400 [51:10<1:13:07, 18.75s/it]2022-01-14 12:26:38,035 iteration 2823 : loss : 0.051256, loss_ce: 0.019876
2022-01-14 12:26:39,008 iteration 2824 : loss : 0.034993, loss_ce: 0.016863
2022-01-14 12:26:40,017 iteration 2825 : loss : 0.037173, loss_ce: 0.014681
2022-01-14 12:26:41,120 iteration 2826 : loss : 0.046123, loss_ce: 0.018535
2022-01-14 12:26:42,240 iteration 2827 : loss : 0.052386, loss_ce: 0.015485
2022-01-14 12:26:43,269 iteration 2828 : loss : 0.047152, loss_ce: 0.015654
2022-01-14 12:26:44,263 iteration 2829 : loss : 0.047023, loss_ce: 0.023477
2022-01-14 12:26:45,250 iteration 2830 : loss : 0.034138, loss_ce: 0.011109
2022-01-14 12:26:46,154 iteration 2831 : loss : 0.023645, loss_ce: 0.010283
2022-01-14 12:26:47,281 iteration 2832 : loss : 0.035899, loss_ce: 0.014848
2022-01-14 12:26:48,264 iteration 2833 : loss : 0.029959, loss_ce: 0.010368
2022-01-14 12:26:49,320 iteration 2834 : loss : 0.043865, loss_ce: 0.014511
2022-01-14 12:26:50,347 iteration 2835 : loss : 0.042526, loss_ce: 0.012401
2022-01-14 12:26:51,342 iteration 2836 : loss : 0.034737, loss_ce: 0.012299
2022-01-14 12:26:52,403 iteration 2837 : loss : 0.035962, loss_ce: 0.013885
2022-01-14 12:26:53,343 iteration 2838 : loss : 0.029596, loss_ce: 0.012913
2022-01-14 12:26:54,377 iteration 2839 : loss : 0.025119, loss_ce: 0.008920
 42%|████████████                 | 167/400 [51:28<1:11:21, 18.37s/it]2022-01-14 12:26:55,495 iteration 2840 : loss : 0.031470, loss_ce: 0.010803
2022-01-14 12:26:56,482 iteration 2841 : loss : 0.039451, loss_ce: 0.012706
2022-01-14 12:26:57,464 iteration 2842 : loss : 0.026763, loss_ce: 0.009216
2022-01-14 12:26:58,506 iteration 2843 : loss : 0.034735, loss_ce: 0.009957
2022-01-14 12:26:59,519 iteration 2844 : loss : 0.041284, loss_ce: 0.019022
2022-01-14 12:27:00,512 iteration 2845 : loss : 0.030645, loss_ce: 0.011347
2022-01-14 12:27:01,515 iteration 2846 : loss : 0.022618, loss_ce: 0.007931
2022-01-14 12:27:02,392 iteration 2847 : loss : 0.021042, loss_ce: 0.011104
2022-01-14 12:27:03,398 iteration 2848 : loss : 0.039921, loss_ce: 0.014392
2022-01-14 12:27:04,450 iteration 2849 : loss : 0.035132, loss_ce: 0.012608
2022-01-14 12:27:05,491 iteration 2850 : loss : 0.046196, loss_ce: 0.018038
2022-01-14 12:27:06,544 iteration 2851 : loss : 0.026543, loss_ce: 0.010083
2022-01-14 12:27:07,560 iteration 2852 : loss : 0.040687, loss_ce: 0.011626
2022-01-14 12:27:08,618 iteration 2853 : loss : 0.028372, loss_ce: 0.010461
2022-01-14 12:27:09,649 iteration 2854 : loss : 0.030608, loss_ce: 0.011961
2022-01-14 12:27:10,611 iteration 2855 : loss : 0.027200, loss_ce: 0.011921
2022-01-14 12:27:11,648 iteration 2856 : loss : 0.034510, loss_ce: 0.016274
 42%|████████████▏                | 168/400 [51:45<1:09:45, 18.04s/it]2022-01-14 12:27:12,614 iteration 2857 : loss : 0.026266, loss_ce: 0.008721
2022-01-14 12:27:13,625 iteration 2858 : loss : 0.028052, loss_ce: 0.012580
2022-01-14 12:27:14,595 iteration 2859 : loss : 0.031277, loss_ce: 0.013004
2022-01-14 12:27:15,627 iteration 2860 : loss : 0.037685, loss_ce: 0.011352
2022-01-14 12:27:16,540 iteration 2861 : loss : 0.027708, loss_ce: 0.012128
2022-01-14 12:27:17,623 iteration 2862 : loss : 0.075929, loss_ce: 0.021756
2022-01-14 12:27:18,573 iteration 2863 : loss : 0.039773, loss_ce: 0.009620
2022-01-14 12:27:19,597 iteration 2864 : loss : 0.032445, loss_ce: 0.013077
2022-01-14 12:27:20,635 iteration 2865 : loss : 0.036190, loss_ce: 0.012806
2022-01-14 12:27:21,616 iteration 2866 : loss : 0.029035, loss_ce: 0.012313
2022-01-14 12:27:22,726 iteration 2867 : loss : 0.040735, loss_ce: 0.016020
2022-01-14 12:27:23,687 iteration 2868 : loss : 0.030566, loss_ce: 0.009996
2022-01-14 12:27:24,768 iteration 2869 : loss : 0.036123, loss_ce: 0.015110
2022-01-14 12:27:25,796 iteration 2870 : loss : 0.035114, loss_ce: 0.010908
2022-01-14 12:27:26,764 iteration 2871 : loss : 0.027726, loss_ce: 0.010799
2022-01-14 12:27:27,688 iteration 2872 : loss : 0.033026, loss_ce: 0.013255
2022-01-14 12:27:28,732 iteration 2873 : loss : 0.043880, loss_ce: 0.010843
 42%|████████████▎                | 169/400 [52:02<1:08:22, 17.76s/it]2022-01-14 12:27:29,832 iteration 2874 : loss : 0.029745, loss_ce: 0.009557
2022-01-14 12:27:30,854 iteration 2875 : loss : 0.034064, loss_ce: 0.014562
2022-01-14 12:27:31,863 iteration 2876 : loss : 0.053693, loss_ce: 0.021163
2022-01-14 12:27:32,924 iteration 2877 : loss : 0.074158, loss_ce: 0.025478
2022-01-14 12:27:33,925 iteration 2878 : loss : 0.031937, loss_ce: 0.014026
2022-01-14 12:27:34,973 iteration 2879 : loss : 0.030048, loss_ce: 0.010715
2022-01-14 12:27:36,032 iteration 2880 : loss : 0.036003, loss_ce: 0.013680
2022-01-14 12:27:37,041 iteration 2881 : loss : 0.028754, loss_ce: 0.011867
2022-01-14 12:27:38,106 iteration 2882 : loss : 0.038109, loss_ce: 0.017264
2022-01-14 12:27:39,081 iteration 2883 : loss : 0.053720, loss_ce: 0.024959
2022-01-14 12:27:40,066 iteration 2884 : loss : 0.036996, loss_ce: 0.014379
2022-01-14 12:27:41,086 iteration 2885 : loss : 0.034096, loss_ce: 0.013512
2022-01-14 12:27:42,002 iteration 2886 : loss : 0.051097, loss_ce: 0.016896
2022-01-14 12:27:43,071 iteration 2887 : loss : 0.039394, loss_ce: 0.020277
2022-01-14 12:27:44,085 iteration 2888 : loss : 0.045589, loss_ce: 0.011547
2022-01-14 12:27:45,202 iteration 2889 : loss : 0.031735, loss_ce: 0.012235
2022-01-14 12:27:45,202 Training Data Eval:
2022-01-14 12:27:50,006   Average segmentation loss on training set: 0.0224
2022-01-14 12:27:50,007 Validation Data Eval:
2022-01-14 12:27:51,615   Average segmentation loss on validation set: 0.0591
2022-01-14 12:27:52,811 Found new lowest validation loss at iteration 2889! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_1BLOCK_best_val_loss_seed1234.pth
2022-01-14 12:27:53,865 iteration 2890 : loss : 0.029412, loss_ce: 0.009831
 42%|████████████▎                | 170/400 [52:27<1:16:32, 19.97s/it]2022-01-14 12:27:54,951 iteration 2891 : loss : 0.042970, loss_ce: 0.018133
2022-01-14 12:27:56,036 iteration 2892 : loss : 0.037052, loss_ce: 0.009216
2022-01-14 12:27:57,004 iteration 2893 : loss : 0.034231, loss_ce: 0.012528
2022-01-14 12:27:58,084 iteration 2894 : loss : 0.036975, loss_ce: 0.010537
2022-01-14 12:27:59,143 iteration 2895 : loss : 0.043562, loss_ce: 0.020093
2022-01-14 12:28:00,114 iteration 2896 : loss : 0.020910, loss_ce: 0.007297
2022-01-14 12:28:01,119 iteration 2897 : loss : 0.036453, loss_ce: 0.014410
2022-01-14 12:28:02,068 iteration 2898 : loss : 0.038445, loss_ce: 0.020054
2022-01-14 12:28:03,097 iteration 2899 : loss : 0.045641, loss_ce: 0.014618
2022-01-14 12:28:04,092 iteration 2900 : loss : 0.026678, loss_ce: 0.008890
2022-01-14 12:28:05,103 iteration 2901 : loss : 0.037378, loss_ce: 0.012260
2022-01-14 12:28:06,035 iteration 2902 : loss : 0.042205, loss_ce: 0.016319
2022-01-14 12:28:06,998 iteration 2903 : loss : 0.034894, loss_ce: 0.018084
2022-01-14 12:28:07,954 iteration 2904 : loss : 0.026735, loss_ce: 0.010074
2022-01-14 12:28:08,883 iteration 2905 : loss : 0.032780, loss_ce: 0.016967
2022-01-14 12:28:09,916 iteration 2906 : loss : 0.043513, loss_ce: 0.021650
2022-01-14 12:28:10,878 iteration 2907 : loss : 0.030880, loss_ce: 0.011485
 43%|████████████▍                | 171/400 [52:44<1:12:50, 19.08s/it]2022-01-14 12:28:11,966 iteration 2908 : loss : 0.066931, loss_ce: 0.031603
2022-01-14 12:28:13,020 iteration 2909 : loss : 0.032286, loss_ce: 0.016661
2022-01-14 12:28:14,029 iteration 2910 : loss : 0.032718, loss_ce: 0.013798
2022-01-14 12:28:15,081 iteration 2911 : loss : 0.033172, loss_ce: 0.010365
2022-01-14 12:28:16,060 iteration 2912 : loss : 0.032326, loss_ce: 0.012347
2022-01-14 12:28:17,136 iteration 2913 : loss : 0.036680, loss_ce: 0.014733
2022-01-14 12:28:18,116 iteration 2914 : loss : 0.037761, loss_ce: 0.013653
2022-01-14 12:28:19,100 iteration 2915 : loss : 0.026910, loss_ce: 0.011801
2022-01-14 12:28:20,112 iteration 2916 : loss : 0.027319, loss_ce: 0.010911
2022-01-14 12:28:21,045 iteration 2917 : loss : 0.027751, loss_ce: 0.012069
2022-01-14 12:28:22,003 iteration 2918 : loss : 0.023895, loss_ce: 0.006727
2022-01-14 12:28:22,999 iteration 2919 : loss : 0.029807, loss_ce: 0.008929
2022-01-14 12:28:24,019 iteration 2920 : loss : 0.031753, loss_ce: 0.011883
2022-01-14 12:28:25,006 iteration 2921 : loss : 0.033741, loss_ce: 0.014207
2022-01-14 12:28:25,938 iteration 2922 : loss : 0.049255, loss_ce: 0.016130
2022-01-14 12:28:26,904 iteration 2923 : loss : 0.031748, loss_ce: 0.011136
2022-01-14 12:28:27,904 iteration 2924 : loss : 0.040242, loss_ce: 0.013885
 43%|████████████▍                | 172/400 [53:01<1:10:10, 18.47s/it]2022-01-14 12:28:28,855 iteration 2925 : loss : 0.025364, loss_ce: 0.012081
2022-01-14 12:28:29,928 iteration 2926 : loss : 0.037136, loss_ce: 0.015405
2022-01-14 12:28:30,920 iteration 2927 : loss : 0.026139, loss_ce: 0.009704
2022-01-14 12:28:31,801 iteration 2928 : loss : 0.033794, loss_ce: 0.009918
2022-01-14 12:28:32,767 iteration 2929 : loss : 0.028105, loss_ce: 0.012060
2022-01-14 12:28:33,837 iteration 2930 : loss : 0.034602, loss_ce: 0.015000
2022-01-14 12:28:34,808 iteration 2931 : loss : 0.029491, loss_ce: 0.011227
2022-01-14 12:28:35,756 iteration 2932 : loss : 0.027732, loss_ce: 0.009636
2022-01-14 12:28:36,829 iteration 2933 : loss : 0.035908, loss_ce: 0.011957
2022-01-14 12:28:37,822 iteration 2934 : loss : 0.039088, loss_ce: 0.013749
2022-01-14 12:28:38,829 iteration 2935 : loss : 0.028287, loss_ce: 0.009139
2022-01-14 12:28:39,815 iteration 2936 : loss : 0.023608, loss_ce: 0.006572
2022-01-14 12:28:40,831 iteration 2937 : loss : 0.029668, loss_ce: 0.013048
2022-01-14 12:28:41,870 iteration 2938 : loss : 0.042346, loss_ce: 0.013457
2022-01-14 12:28:42,910 iteration 2939 : loss : 0.028336, loss_ce: 0.010355
2022-01-14 12:28:44,014 iteration 2940 : loss : 0.069317, loss_ce: 0.036483
2022-01-14 12:28:44,962 iteration 2941 : loss : 0.025513, loss_ce: 0.008696
 43%|████████████▌                | 173/400 [53:19<1:08:16, 18.05s/it]2022-01-14 12:28:45,966 iteration 2942 : loss : 0.025105, loss_ce: 0.008254
2022-01-14 12:28:46,990 iteration 2943 : loss : 0.042992, loss_ce: 0.012702
2022-01-14 12:28:47,949 iteration 2944 : loss : 0.026141, loss_ce: 0.012766
2022-01-14 12:28:48,951 iteration 2945 : loss : 0.036788, loss_ce: 0.010486
2022-01-14 12:28:49,848 iteration 2946 : loss : 0.026988, loss_ce: 0.011301
2022-01-14 12:28:50,812 iteration 2947 : loss : 0.028205, loss_ce: 0.011331
2022-01-14 12:28:51,770 iteration 2948 : loss : 0.029961, loss_ce: 0.008167
2022-01-14 12:28:52,834 iteration 2949 : loss : 0.039224, loss_ce: 0.014560
2022-01-14 12:28:53,856 iteration 2950 : loss : 0.028075, loss_ce: 0.012456
2022-01-14 12:28:54,894 iteration 2951 : loss : 0.029000, loss_ce: 0.011934
2022-01-14 12:28:55,921 iteration 2952 : loss : 0.026891, loss_ce: 0.009240
2022-01-14 12:28:56,978 iteration 2953 : loss : 0.036618, loss_ce: 0.017902
2022-01-14 12:28:58,074 iteration 2954 : loss : 0.077003, loss_ce: 0.023430
2022-01-14 12:28:59,038 iteration 2955 : loss : 0.031122, loss_ce: 0.013613
2022-01-14 12:29:00,012 iteration 2956 : loss : 0.033263, loss_ce: 0.015045
2022-01-14 12:29:00,954 iteration 2957 : loss : 0.043400, loss_ce: 0.015463
2022-01-14 12:29:01,965 iteration 2958 : loss : 0.035034, loss_ce: 0.017026
 44%|████████████▌                | 174/400 [53:35<1:06:46, 17.73s/it]2022-01-14 12:29:02,994 iteration 2959 : loss : 0.024807, loss_ce: 0.008593
2022-01-14 12:29:03,973 iteration 2960 : loss : 0.029814, loss_ce: 0.013207
2022-01-14 12:29:04,979 iteration 2961 : loss : 0.035468, loss_ce: 0.012196
2022-01-14 12:29:06,124 iteration 2962 : loss : 0.026216, loss_ce: 0.009140
2022-01-14 12:29:07,144 iteration 2963 : loss : 0.044302, loss_ce: 0.015818
2022-01-14 12:29:08,053 iteration 2964 : loss : 0.030324, loss_ce: 0.009994
2022-01-14 12:29:09,057 iteration 2965 : loss : 0.027219, loss_ce: 0.013651
2022-01-14 12:29:10,097 iteration 2966 : loss : 0.041382, loss_ce: 0.014882
2022-01-14 12:29:11,087 iteration 2967 : loss : 0.041969, loss_ce: 0.016763
2022-01-14 12:29:12,090 iteration 2968 : loss : 0.043847, loss_ce: 0.018230
2022-01-14 12:29:13,067 iteration 2969 : loss : 0.041438, loss_ce: 0.019035
2022-01-14 12:29:14,073 iteration 2970 : loss : 0.033491, loss_ce: 0.012459
2022-01-14 12:29:15,052 iteration 2971 : loss : 0.029431, loss_ce: 0.011580
2022-01-14 12:29:16,037 iteration 2972 : loss : 0.032071, loss_ce: 0.014803
2022-01-14 12:29:16,980 iteration 2973 : loss : 0.029993, loss_ce: 0.007233
2022-01-14 12:29:18,029 iteration 2974 : loss : 0.047009, loss_ce: 0.016078
2022-01-14 12:29:18,030 Training Data Eval:
2022-01-14 12:29:22,834   Average segmentation loss on training set: 0.0209
2022-01-14 12:29:22,835 Validation Data Eval:
2022-01-14 12:29:24,452   Average segmentation loss on validation set: 0.0698
2022-01-14 12:29:25,419 iteration 2975 : loss : 0.024232, loss_ce: 0.009750
 44%|████████████▋                | 175/400 [53:59<1:12:55, 19.45s/it]2022-01-14 12:29:26,390 iteration 2976 : loss : 0.025260, loss_ce: 0.010277
2022-01-14 12:29:27,419 iteration 2977 : loss : 0.034448, loss_ce: 0.017368
2022-01-14 12:29:28,433 iteration 2978 : loss : 0.029513, loss_ce: 0.009892
2022-01-14 12:29:29,487 iteration 2979 : loss : 0.037077, loss_ce: 0.013102
2022-01-14 12:29:30,524 iteration 2980 : loss : 0.043672, loss_ce: 0.011788
2022-01-14 12:29:31,625 iteration 2981 : loss : 0.039860, loss_ce: 0.017279
2022-01-14 12:29:32,630 iteration 2982 : loss : 0.030406, loss_ce: 0.012242
2022-01-14 12:29:33,642 iteration 2983 : loss : 0.027685, loss_ce: 0.010445
2022-01-14 12:29:34,655 iteration 2984 : loss : 0.033188, loss_ce: 0.011858
2022-01-14 12:29:35,694 iteration 2985 : loss : 0.038353, loss_ce: 0.015164
2022-01-14 12:29:36,637 iteration 2986 : loss : 0.026724, loss_ce: 0.011185
2022-01-14 12:29:37,641 iteration 2987 : loss : 0.046740, loss_ce: 0.015863
2022-01-14 12:29:38,688 iteration 2988 : loss : 0.029863, loss_ce: 0.012312
2022-01-14 12:29:39,724 iteration 2989 : loss : 0.038156, loss_ce: 0.013984
2022-01-14 12:29:40,665 iteration 2990 : loss : 0.028399, loss_ce: 0.012025
2022-01-14 12:29:41,658 iteration 2991 : loss : 0.027608, loss_ce: 0.010508
2022-01-14 12:29:42,723 iteration 2992 : loss : 0.027394, loss_ce: 0.011049
 44%|████████████▊                | 176/400 [54:16<1:10:12, 18.80s/it]2022-01-14 12:29:43,725 iteration 2993 : loss : 0.028802, loss_ce: 0.013623
2022-01-14 12:29:44,742 iteration 2994 : loss : 0.050529, loss_ce: 0.014304
2022-01-14 12:29:45,718 iteration 2995 : loss : 0.030975, loss_ce: 0.012180
2022-01-14 12:29:46,712 iteration 2996 : loss : 0.026240, loss_ce: 0.012199
2022-01-14 12:29:47,701 iteration 2997 : loss : 0.036921, loss_ce: 0.011106
2022-01-14 12:29:48,706 iteration 2998 : loss : 0.029049, loss_ce: 0.012256
2022-01-14 12:29:49,754 iteration 2999 : loss : 0.061192, loss_ce: 0.014112
2022-01-14 12:29:50,829 iteration 3000 : loss : 0.038472, loss_ce: 0.015888
2022-01-14 12:29:51,901 iteration 3001 : loss : 0.048418, loss_ce: 0.013435
2022-01-14 12:29:52,852 iteration 3002 : loss : 0.028504, loss_ce: 0.012201
2022-01-14 12:29:53,826 iteration 3003 : loss : 0.033343, loss_ce: 0.012822
2022-01-14 12:29:54,810 iteration 3004 : loss : 0.021878, loss_ce: 0.009274
2022-01-14 12:29:55,821 iteration 3005 : loss : 0.037492, loss_ce: 0.016067
2022-01-14 12:29:56,861 iteration 3006 : loss : 0.027788, loss_ce: 0.012157
2022-01-14 12:29:57,884 iteration 3007 : loss : 0.033159, loss_ce: 0.013622
2022-01-14 12:29:58,912 iteration 3008 : loss : 0.032484, loss_ce: 0.010890
2022-01-14 12:29:59,840 iteration 3009 : loss : 0.032429, loss_ce: 0.013188
 44%|████████████▊                | 177/400 [54:33<1:08:00, 18.30s/it]2022-01-14 12:30:01,007 iteration 3010 : loss : 0.040844, loss_ce: 0.013601
2022-01-14 12:30:02,052 iteration 3011 : loss : 0.033980, loss_ce: 0.016253
2022-01-14 12:30:03,008 iteration 3012 : loss : 0.023711, loss_ce: 0.009871
2022-01-14 12:30:03,944 iteration 3013 : loss : 0.039023, loss_ce: 0.012138
2022-01-14 12:30:04,955 iteration 3014 : loss : 0.037489, loss_ce: 0.014160
2022-01-14 12:30:05,941 iteration 3015 : loss : 0.037392, loss_ce: 0.009971
2022-01-14 12:30:06,925 iteration 3016 : loss : 0.037587, loss_ce: 0.013584
2022-01-14 12:30:07,890 iteration 3017 : loss : 0.027011, loss_ce: 0.014436
2022-01-14 12:30:08,853 iteration 3018 : loss : 0.020042, loss_ce: 0.009059
2022-01-14 12:30:09,780 iteration 3019 : loss : 0.043667, loss_ce: 0.016520
2022-01-14 12:30:10,794 iteration 3020 : loss : 0.031330, loss_ce: 0.010319
2022-01-14 12:30:11,798 iteration 3021 : loss : 0.020597, loss_ce: 0.007160
2022-01-14 12:30:12,775 iteration 3022 : loss : 0.027896, loss_ce: 0.011190
2022-01-14 12:30:13,782 iteration 3023 : loss : 0.047685, loss_ce: 0.016423
2022-01-14 12:30:14,860 iteration 3024 : loss : 0.040675, loss_ce: 0.019278
2022-01-14 12:30:15,911 iteration 3025 : loss : 0.045613, loss_ce: 0.017498
2022-01-14 12:30:16,864 iteration 3026 : loss : 0.026290, loss_ce: 0.010200
 44%|████████████▉                | 178/400 [54:50<1:06:17, 17.91s/it]2022-01-14 12:30:17,968 iteration 3027 : loss : 0.047192, loss_ce: 0.016180
2022-01-14 12:30:18,923 iteration 3028 : loss : 0.025623, loss_ce: 0.010477
2022-01-14 12:30:19,937 iteration 3029 : loss : 0.028631, loss_ce: 0.012758
2022-01-14 12:30:20,903 iteration 3030 : loss : 0.027423, loss_ce: 0.012446
2022-01-14 12:30:21,900 iteration 3031 : loss : 0.035360, loss_ce: 0.013755
2022-01-14 12:30:22,860 iteration 3032 : loss : 0.038505, loss_ce: 0.015433
2022-01-14 12:30:23,892 iteration 3033 : loss : 0.039240, loss_ce: 0.012783
2022-01-14 12:30:24,939 iteration 3034 : loss : 0.027439, loss_ce: 0.010085
2022-01-14 12:30:25,954 iteration 3035 : loss : 0.028731, loss_ce: 0.012423
2022-01-14 12:30:26,930 iteration 3036 : loss : 0.038170, loss_ce: 0.020862
2022-01-14 12:30:27,923 iteration 3037 : loss : 0.030668, loss_ce: 0.011338
2022-01-14 12:30:28,951 iteration 3038 : loss : 0.027544, loss_ce: 0.009848
2022-01-14 12:30:29,887 iteration 3039 : loss : 0.029134, loss_ce: 0.009676
2022-01-14 12:30:30,891 iteration 3040 : loss : 0.032324, loss_ce: 0.008330
2022-01-14 12:30:31,934 iteration 3041 : loss : 0.027843, loss_ce: 0.010072
2022-01-14 12:30:32,931 iteration 3042 : loss : 0.030403, loss_ce: 0.014385
2022-01-14 12:30:34,112 iteration 3043 : loss : 0.033585, loss_ce: 0.010357
 45%|████████████▉                | 179/400 [55:08<1:05:15, 17.72s/it]2022-01-14 12:30:35,193 iteration 3044 : loss : 0.043625, loss_ce: 0.019903
2022-01-14 12:30:36,139 iteration 3045 : loss : 0.028717, loss_ce: 0.010826
2022-01-14 12:30:37,108 iteration 3046 : loss : 0.027226, loss_ce: 0.008706
2022-01-14 12:30:38,212 iteration 3047 : loss : 0.032896, loss_ce: 0.017228
2022-01-14 12:30:39,172 iteration 3048 : loss : 0.032062, loss_ce: 0.011111
2022-01-14 12:30:40,172 iteration 3049 : loss : 0.037798, loss_ce: 0.014876
2022-01-14 12:30:41,201 iteration 3050 : loss : 0.025462, loss_ce: 0.011114
2022-01-14 12:30:42,208 iteration 3051 : loss : 0.035427, loss_ce: 0.008892
2022-01-14 12:30:43,198 iteration 3052 : loss : 0.028071, loss_ce: 0.009798
2022-01-14 12:30:44,286 iteration 3053 : loss : 0.026950, loss_ce: 0.011263
2022-01-14 12:30:45,241 iteration 3054 : loss : 0.026744, loss_ce: 0.006957
2022-01-14 12:30:46,262 iteration 3055 : loss : 0.044995, loss_ce: 0.014269
2022-01-14 12:30:47,233 iteration 3056 : loss : 0.023690, loss_ce: 0.009173
2022-01-14 12:30:48,171 iteration 3057 : loss : 0.030492, loss_ce: 0.012136
2022-01-14 12:30:49,184 iteration 3058 : loss : 0.029218, loss_ce: 0.011777
2022-01-14 12:30:50,217 iteration 3059 : loss : 0.031701, loss_ce: 0.008663
2022-01-14 12:30:50,217 Training Data Eval:
2022-01-14 12:30:55,023   Average segmentation loss on training set: 0.0216
2022-01-14 12:30:55,023 Validation Data Eval:
2022-01-14 12:30:56,645   Average segmentation loss on validation set: 0.0730
2022-01-14 12:30:57,600 iteration 3060 : loss : 0.027442, loss_ce: 0.013703
 45%|█████████████                | 180/400 [55:31<1:11:18, 19.45s/it]2022-01-14 12:30:58,575 iteration 3061 : loss : 0.023416, loss_ce: 0.009093
2022-01-14 12:30:59,565 iteration 3062 : loss : 0.040492, loss_ce: 0.016679
2022-01-14 12:31:00,596 iteration 3063 : loss : 0.047513, loss_ce: 0.018244
2022-01-14 12:31:01,638 iteration 3064 : loss : 0.029779, loss_ce: 0.013214
2022-01-14 12:31:02,539 iteration 3065 : loss : 0.023170, loss_ce: 0.008109
2022-01-14 12:31:03,499 iteration 3066 : loss : 0.034345, loss_ce: 0.017555
2022-01-14 12:31:04,519 iteration 3067 : loss : 0.043351, loss_ce: 0.021107
2022-01-14 12:31:05,525 iteration 3068 : loss : 0.043693, loss_ce: 0.012198
2022-01-14 12:31:06,520 iteration 3069 : loss : 0.056105, loss_ce: 0.014523
2022-01-14 12:31:07,525 iteration 3070 : loss : 0.022881, loss_ce: 0.009026
2022-01-14 12:31:08,468 iteration 3071 : loss : 0.028721, loss_ce: 0.013329
2022-01-14 12:31:09,407 iteration 3072 : loss : 0.027171, loss_ce: 0.009998
2022-01-14 12:31:10,383 iteration 3073 : loss : 0.022091, loss_ce: 0.007981
2022-01-14 12:31:11,445 iteration 3074 : loss : 0.033314, loss_ce: 0.012467
2022-01-14 12:31:12,476 iteration 3075 : loss : 0.038386, loss_ce: 0.012844
2022-01-14 12:31:13,545 iteration 3076 : loss : 0.044901, loss_ce: 0.015874
2022-01-14 12:31:14,498 iteration 3077 : loss : 0.033120, loss_ce: 0.012055
 45%|█████████████                | 181/400 [55:48<1:08:11, 18.68s/it]2022-01-14 12:31:15,497 iteration 3078 : loss : 0.030752, loss_ce: 0.012434
2022-01-14 12:31:16,598 iteration 3079 : loss : 0.036626, loss_ce: 0.013760
2022-01-14 12:31:17,519 iteration 3080 : loss : 0.038886, loss_ce: 0.011362
2022-01-14 12:31:18,538 iteration 3081 : loss : 0.028742, loss_ce: 0.009340
2022-01-14 12:31:19,519 iteration 3082 : loss : 0.039290, loss_ce: 0.009700
2022-01-14 12:31:20,573 iteration 3083 : loss : 0.028712, loss_ce: 0.010288
2022-01-14 12:31:21,457 iteration 3084 : loss : 0.025571, loss_ce: 0.010918
2022-01-14 12:31:22,467 iteration 3085 : loss : 0.028122, loss_ce: 0.012612
2022-01-14 12:31:23,555 iteration 3086 : loss : 0.032258, loss_ce: 0.015898
2022-01-14 12:31:24,528 iteration 3087 : loss : 0.036771, loss_ce: 0.013689
2022-01-14 12:31:25,535 iteration 3088 : loss : 0.027954, loss_ce: 0.008890
2022-01-14 12:31:26,617 iteration 3089 : loss : 0.050593, loss_ce: 0.016392
2022-01-14 12:31:27,537 iteration 3090 : loss : 0.029427, loss_ce: 0.012783
2022-01-14 12:31:28,529 iteration 3091 : loss : 0.033037, loss_ce: 0.016263
2022-01-14 12:31:29,668 iteration 3092 : loss : 0.033938, loss_ce: 0.014767
2022-01-14 12:31:30,632 iteration 3093 : loss : 0.027280, loss_ce: 0.011505
2022-01-14 12:31:31,639 iteration 3094 : loss : 0.041216, loss_ce: 0.016388
 46%|█████████████▏               | 182/400 [56:05<1:06:12, 18.22s/it]2022-01-14 12:31:32,688 iteration 3095 : loss : 0.033780, loss_ce: 0.013489
2022-01-14 12:31:33,698 iteration 3096 : loss : 0.029804, loss_ce: 0.012132
2022-01-14 12:31:34,676 iteration 3097 : loss : 0.028330, loss_ce: 0.010965
2022-01-14 12:31:35,628 iteration 3098 : loss : 0.032327, loss_ce: 0.013582
2022-01-14 12:31:36,621 iteration 3099 : loss : 0.024773, loss_ce: 0.008182
2022-01-14 12:31:37,565 iteration 3100 : loss : 0.027033, loss_ce: 0.009473
2022-01-14 12:31:38,608 iteration 3101 : loss : 0.025867, loss_ce: 0.008887
2022-01-14 12:31:39,602 iteration 3102 : loss : 0.031651, loss_ce: 0.012119
2022-01-14 12:31:40,609 iteration 3103 : loss : 0.042049, loss_ce: 0.018043
2022-01-14 12:31:41,560 iteration 3104 : loss : 0.026271, loss_ce: 0.011306
2022-01-14 12:31:42,489 iteration 3105 : loss : 0.022950, loss_ce: 0.009678
2022-01-14 12:31:43,468 iteration 3106 : loss : 0.029266, loss_ce: 0.014137
2022-01-14 12:31:44,436 iteration 3107 : loss : 0.023271, loss_ce: 0.006417
2022-01-14 12:31:45,445 iteration 3108 : loss : 0.038654, loss_ce: 0.012583
2022-01-14 12:31:46,478 iteration 3109 : loss : 0.028482, loss_ce: 0.009225
2022-01-14 12:31:47,596 iteration 3110 : loss : 0.049554, loss_ce: 0.022936
2022-01-14 12:31:48,606 iteration 3111 : loss : 0.027592, loss_ce: 0.010762
 46%|█████████████▎               | 183/400 [56:22<1:04:31, 17.84s/it]2022-01-14 12:31:49,673 iteration 3112 : loss : 0.027047, loss_ce: 0.010116
2022-01-14 12:31:50,630 iteration 3113 : loss : 0.032570, loss_ce: 0.014318
2022-01-14 12:31:51,666 iteration 3114 : loss : 0.060088, loss_ce: 0.018769
2022-01-14 12:31:52,669 iteration 3115 : loss : 0.023631, loss_ce: 0.010092
2022-01-14 12:31:53,655 iteration 3116 : loss : 0.025241, loss_ce: 0.011307
2022-01-14 12:31:54,720 iteration 3117 : loss : 0.024668, loss_ce: 0.010613
2022-01-14 12:31:55,698 iteration 3118 : loss : 0.033026, loss_ce: 0.011573
2022-01-14 12:31:56,795 iteration 3119 : loss : 0.054536, loss_ce: 0.019886
2022-01-14 12:31:57,740 iteration 3120 : loss : 0.026403, loss_ce: 0.010097
2022-01-14 12:31:58,799 iteration 3121 : loss : 0.033054, loss_ce: 0.014399
2022-01-14 12:31:59,775 iteration 3122 : loss : 0.035822, loss_ce: 0.009638
2022-01-14 12:32:00,825 iteration 3123 : loss : 0.033241, loss_ce: 0.012896
2022-01-14 12:32:01,747 iteration 3124 : loss : 0.023385, loss_ce: 0.009536
2022-01-14 12:32:02,733 iteration 3125 : loss : 0.044034, loss_ce: 0.013956
2022-01-14 12:32:03,788 iteration 3126 : loss : 0.027987, loss_ce: 0.013069
2022-01-14 12:32:04,850 iteration 3127 : loss : 0.028194, loss_ce: 0.010013
2022-01-14 12:32:05,907 iteration 3128 : loss : 0.033281, loss_ce: 0.010621
 46%|█████████████▎               | 184/400 [56:39<1:03:39, 17.68s/it]2022-01-14 12:32:06,935 iteration 3129 : loss : 0.034547, loss_ce: 0.012652
2022-01-14 12:32:08,026 iteration 3130 : loss : 0.044065, loss_ce: 0.020962
2022-01-14 12:32:09,015 iteration 3131 : loss : 0.032585, loss_ce: 0.011614
2022-01-14 12:32:10,013 iteration 3132 : loss : 0.030359, loss_ce: 0.009421
2022-01-14 12:32:11,013 iteration 3133 : loss : 0.076491, loss_ce: 0.039882
2022-01-14 12:32:11,982 iteration 3134 : loss : 0.025662, loss_ce: 0.012108
2022-01-14 12:32:12,979 iteration 3135 : loss : 0.035780, loss_ce: 0.016834
2022-01-14 12:32:13,951 iteration 3136 : loss : 0.030199, loss_ce: 0.012557
2022-01-14 12:32:15,055 iteration 3137 : loss : 0.030667, loss_ce: 0.013325
2022-01-14 12:32:16,112 iteration 3138 : loss : 0.051994, loss_ce: 0.020505
2022-01-14 12:32:17,049 iteration 3139 : loss : 0.029601, loss_ce: 0.011231
2022-01-14 12:32:17,990 iteration 3140 : loss : 0.035219, loss_ce: 0.015796
2022-01-14 12:32:19,004 iteration 3141 : loss : 0.039467, loss_ce: 0.018062
2022-01-14 12:32:19,982 iteration 3142 : loss : 0.040792, loss_ce: 0.014403
2022-01-14 12:32:21,029 iteration 3143 : loss : 0.030016, loss_ce: 0.010526
2022-01-14 12:32:22,013 iteration 3144 : loss : 0.028593, loss_ce: 0.011177
2022-01-14 12:32:22,013 Training Data Eval:
2022-01-14 12:32:26,830   Average segmentation loss on training set: 0.0288
2022-01-14 12:32:26,830 Validation Data Eval:
2022-01-14 12:32:28,445   Average segmentation loss on validation set: 0.1346
2022-01-14 12:32:29,395 iteration 3145 : loss : 0.028790, loss_ce: 0.011836
 46%|█████████████▍               | 185/400 [57:03<1:09:35, 19.42s/it]2022-01-14 12:32:30,585 iteration 3146 : loss : 0.050529, loss_ce: 0.017068
2022-01-14 12:32:31,629 iteration 3147 : loss : 0.050417, loss_ce: 0.025379
2022-01-14 12:32:32,571 iteration 3148 : loss : 0.028304, loss_ce: 0.010588
2022-01-14 12:32:33,619 iteration 3149 : loss : 0.033852, loss_ce: 0.009629
2022-01-14 12:32:34,653 iteration 3150 : loss : 0.032947, loss_ce: 0.009702
2022-01-14 12:32:35,684 iteration 3151 : loss : 0.036893, loss_ce: 0.013449
2022-01-14 12:32:36,708 iteration 3152 : loss : 0.040563, loss_ce: 0.015268
2022-01-14 12:32:37,716 iteration 3153 : loss : 0.047855, loss_ce: 0.023087
2022-01-14 12:32:38,793 iteration 3154 : loss : 0.059641, loss_ce: 0.020243
2022-01-14 12:32:39,838 iteration 3155 : loss : 0.031718, loss_ce: 0.011449
2022-01-14 12:32:40,781 iteration 3156 : loss : 0.032223, loss_ce: 0.012223
2022-01-14 12:32:41,797 iteration 3157 : loss : 0.031994, loss_ce: 0.013262
2022-01-14 12:32:42,751 iteration 3158 : loss : 0.045414, loss_ce: 0.011371
2022-01-14 12:32:43,775 iteration 3159 : loss : 0.045175, loss_ce: 0.022656
2022-01-14 12:32:44,804 iteration 3160 : loss : 0.029801, loss_ce: 0.012728
2022-01-14 12:32:45,878 iteration 3161 : loss : 0.029673, loss_ce: 0.011284
2022-01-14 12:32:46,886 iteration 3162 : loss : 0.043017, loss_ce: 0.017359
 46%|█████████████▍               | 186/400 [57:20<1:07:12, 18.85s/it]2022-01-14 12:32:47,904 iteration 3163 : loss : 0.033508, loss_ce: 0.011877
2022-01-14 12:32:49,012 iteration 3164 : loss : 0.048095, loss_ce: 0.020938
2022-01-14 12:32:50,064 iteration 3165 : loss : 0.028344, loss_ce: 0.011040
2022-01-14 12:32:51,028 iteration 3166 : loss : 0.039354, loss_ce: 0.016778
2022-01-14 12:32:52,078 iteration 3167 : loss : 0.032071, loss_ce: 0.011815
2022-01-14 12:32:53,080 iteration 3168 : loss : 0.037460, loss_ce: 0.015226
2022-01-14 12:32:54,111 iteration 3169 : loss : 0.044307, loss_ce: 0.019416
2022-01-14 12:32:55,122 iteration 3170 : loss : 0.037766, loss_ce: 0.018048
2022-01-14 12:32:56,010 iteration 3171 : loss : 0.026320, loss_ce: 0.008451
2022-01-14 12:32:56,974 iteration 3172 : loss : 0.031229, loss_ce: 0.012709
2022-01-14 12:32:57,975 iteration 3173 : loss : 0.046870, loss_ce: 0.017159
2022-01-14 12:32:58,942 iteration 3174 : loss : 0.030569, loss_ce: 0.012565
2022-01-14 12:32:59,878 iteration 3175 : loss : 0.049306, loss_ce: 0.017520
2022-01-14 12:33:00,949 iteration 3176 : loss : 0.053417, loss_ce: 0.013967
2022-01-14 12:33:01,949 iteration 3177 : loss : 0.039200, loss_ce: 0.016253
2022-01-14 12:33:03,036 iteration 3178 : loss : 0.034427, loss_ce: 0.010112
2022-01-14 12:33:04,050 iteration 3179 : loss : 0.033415, loss_ce: 0.016645
 47%|█████████████▌               | 187/400 [57:38<1:05:06, 18.34s/it]2022-01-14 12:33:05,126 iteration 3180 : loss : 0.063481, loss_ce: 0.030226
2022-01-14 12:33:06,100 iteration 3181 : loss : 0.045044, loss_ce: 0.019101
2022-01-14 12:33:07,045 iteration 3182 : loss : 0.028155, loss_ce: 0.013011
2022-01-14 12:33:08,099 iteration 3183 : loss : 0.037532, loss_ce: 0.013648
2022-01-14 12:33:09,099 iteration 3184 : loss : 0.035570, loss_ce: 0.014338
2022-01-14 12:33:10,109 iteration 3185 : loss : 0.039097, loss_ce: 0.012956
2022-01-14 12:33:11,146 iteration 3186 : loss : 0.039039, loss_ce: 0.015136
2022-01-14 12:33:12,191 iteration 3187 : loss : 0.024680, loss_ce: 0.009965
2022-01-14 12:33:13,246 iteration 3188 : loss : 0.032230, loss_ce: 0.012281
2022-01-14 12:33:14,248 iteration 3189 : loss : 0.027339, loss_ce: 0.010945
2022-01-14 12:33:15,351 iteration 3190 : loss : 0.042476, loss_ce: 0.017139
2022-01-14 12:33:16,403 iteration 3191 : loss : 0.040172, loss_ce: 0.015409
2022-01-14 12:33:17,343 iteration 3192 : loss : 0.030711, loss_ce: 0.007235
2022-01-14 12:33:18,343 iteration 3193 : loss : 0.026831, loss_ce: 0.011125
2022-01-14 12:33:19,464 iteration 3194 : loss : 0.041642, loss_ce: 0.017832
2022-01-14 12:33:20,477 iteration 3195 : loss : 0.030566, loss_ce: 0.014627
2022-01-14 12:33:21,485 iteration 3196 : loss : 0.034802, loss_ce: 0.016975
 47%|█████████████▋               | 188/400 [57:55<1:03:49, 18.07s/it]2022-01-14 12:33:22,533 iteration 3197 : loss : 0.025467, loss_ce: 0.010978
2022-01-14 12:33:23,584 iteration 3198 : loss : 0.039084, loss_ce: 0.019705
2022-01-14 12:33:24,618 iteration 3199 : loss : 0.025461, loss_ce: 0.006621
2022-01-14 12:33:25,667 iteration 3200 : loss : 0.041450, loss_ce: 0.013850
2022-01-14 12:33:26,715 iteration 3201 : loss : 0.031407, loss_ce: 0.011583
2022-01-14 12:33:27,767 iteration 3202 : loss : 0.054188, loss_ce: 0.017499
2022-01-14 12:33:28,704 iteration 3203 : loss : 0.026246, loss_ce: 0.012457
2022-01-14 12:33:29,626 iteration 3204 : loss : 0.024060, loss_ce: 0.009508
2022-01-14 12:33:30,546 iteration 3205 : loss : 0.030907, loss_ce: 0.010235
2022-01-14 12:33:31,430 iteration 3206 : loss : 0.029245, loss_ce: 0.009686
2022-01-14 12:33:32,458 iteration 3207 : loss : 0.036532, loss_ce: 0.012997
2022-01-14 12:33:33,454 iteration 3208 : loss : 0.034196, loss_ce: 0.012320
2022-01-14 12:33:34,427 iteration 3209 : loss : 0.057040, loss_ce: 0.024409
2022-01-14 12:33:35,453 iteration 3210 : loss : 0.032802, loss_ce: 0.014431
2022-01-14 12:33:36,397 iteration 3211 : loss : 0.031248, loss_ce: 0.008551
2022-01-14 12:33:37,468 iteration 3212 : loss : 0.047234, loss_ce: 0.024151
2022-01-14 12:33:38,548 iteration 3213 : loss : 0.031507, loss_ce: 0.010006
 47%|█████████████▋               | 189/400 [58:12<1:02:28, 17.77s/it]2022-01-14 12:33:39,553 iteration 3214 : loss : 0.022693, loss_ce: 0.010554
2022-01-14 12:33:40,549 iteration 3215 : loss : 0.029288, loss_ce: 0.012120
2022-01-14 12:33:41,546 iteration 3216 : loss : 0.054735, loss_ce: 0.023062
2022-01-14 12:33:42,576 iteration 3217 : loss : 0.030564, loss_ce: 0.012270
2022-01-14 12:33:43,591 iteration 3218 : loss : 0.035027, loss_ce: 0.009679
2022-01-14 12:33:44,585 iteration 3219 : loss : 0.051942, loss_ce: 0.020309
2022-01-14 12:33:45,538 iteration 3220 : loss : 0.025171, loss_ce: 0.011286
2022-01-14 12:33:46,631 iteration 3221 : loss : 0.052977, loss_ce: 0.023826
2022-01-14 12:33:47,601 iteration 3222 : loss : 0.026176, loss_ce: 0.007254
2022-01-14 12:33:48,624 iteration 3223 : loss : 0.026167, loss_ce: 0.009428
2022-01-14 12:33:49,711 iteration 3224 : loss : 0.044640, loss_ce: 0.013544
2022-01-14 12:33:50,718 iteration 3225 : loss : 0.047625, loss_ce: 0.023766
2022-01-14 12:33:51,722 iteration 3226 : loss : 0.030842, loss_ce: 0.014476
2022-01-14 12:33:52,737 iteration 3227 : loss : 0.027933, loss_ce: 0.011225
2022-01-14 12:33:53,711 iteration 3228 : loss : 0.034802, loss_ce: 0.010201
2022-01-14 12:33:54,655 iteration 3229 : loss : 0.037209, loss_ce: 0.011670
2022-01-14 12:33:54,655 Training Data Eval:
2022-01-14 12:33:59,469   Average segmentation loss on training set: 0.0208
2022-01-14 12:33:59,470 Validation Data Eval:
2022-01-14 12:34:01,082   Average segmentation loss on validation set: 0.0810
2022-01-14 12:34:02,010 iteration 3230 : loss : 0.036501, loss_ce: 0.013555
 48%|█████████████▊               | 190/400 [58:36<1:08:09, 19.48s/it]2022-01-14 12:34:03,022 iteration 3231 : loss : 0.035706, loss_ce: 0.009056
2022-01-14 12:34:03,998 iteration 3232 : loss : 0.027104, loss_ce: 0.008270
2022-01-14 12:34:05,002 iteration 3233 : loss : 0.034748, loss_ce: 0.016891
2022-01-14 12:34:06,026 iteration 3234 : loss : 0.030032, loss_ce: 0.011265
2022-01-14 12:34:07,048 iteration 3235 : loss : 0.053508, loss_ce: 0.018523
2022-01-14 12:34:08,033 iteration 3236 : loss : 0.021822, loss_ce: 0.011259
2022-01-14 12:34:09,132 iteration 3237 : loss : 0.034836, loss_ce: 0.016177
2022-01-14 12:34:10,148 iteration 3238 : loss : 0.026489, loss_ce: 0.012987
2022-01-14 12:34:11,151 iteration 3239 : loss : 0.027293, loss_ce: 0.010999
2022-01-14 12:34:12,101 iteration 3240 : loss : 0.033191, loss_ce: 0.008335
2022-01-14 12:34:13,027 iteration 3241 : loss : 0.031213, loss_ce: 0.007703
2022-01-14 12:34:14,029 iteration 3242 : loss : 0.032327, loss_ce: 0.012802
2022-01-14 12:34:14,961 iteration 3243 : loss : 0.036898, loss_ce: 0.013344
2022-01-14 12:34:15,980 iteration 3244 : loss : 0.029480, loss_ce: 0.011059
2022-01-14 12:34:16,937 iteration 3245 : loss : 0.022943, loss_ce: 0.010345
2022-01-14 12:34:18,000 iteration 3246 : loss : 0.039659, loss_ce: 0.024039
2022-01-14 12:34:18,965 iteration 3247 : loss : 0.034194, loss_ce: 0.013940
 48%|█████████████▊               | 191/400 [58:53<1:05:12, 18.72s/it]2022-01-14 12:34:19,974 iteration 3248 : loss : 0.031905, loss_ce: 0.013829
2022-01-14 12:34:20,923 iteration 3249 : loss : 0.026266, loss_ce: 0.009698
2022-01-14 12:34:21,896 iteration 3250 : loss : 0.043228, loss_ce: 0.015118
2022-01-14 12:34:22,875 iteration 3251 : loss : 0.023014, loss_ce: 0.009625
2022-01-14 12:34:23,878 iteration 3252 : loss : 0.026951, loss_ce: 0.009807
2022-01-14 12:34:24,856 iteration 3253 : loss : 0.024010, loss_ce: 0.010475
2022-01-14 12:34:25,825 iteration 3254 : loss : 0.034368, loss_ce: 0.011105
2022-01-14 12:34:26,736 iteration 3255 : loss : 0.029687, loss_ce: 0.012429
2022-01-14 12:34:27,710 iteration 3256 : loss : 0.031565, loss_ce: 0.010343
2022-01-14 12:34:28,657 iteration 3257 : loss : 0.023337, loss_ce: 0.009353
2022-01-14 12:34:29,661 iteration 3258 : loss : 0.032702, loss_ce: 0.013178
2022-01-14 12:34:30,601 iteration 3259 : loss : 0.029006, loss_ce: 0.011370
2022-01-14 12:34:31,608 iteration 3260 : loss : 0.028929, loss_ce: 0.011706
2022-01-14 12:34:32,572 iteration 3261 : loss : 0.047342, loss_ce: 0.013437
2022-01-14 12:34:33,599 iteration 3262 : loss : 0.034047, loss_ce: 0.013080
2022-01-14 12:34:34,700 iteration 3263 : loss : 0.028053, loss_ce: 0.008768
2022-01-14 12:34:35,708 iteration 3264 : loss : 0.030423, loss_ce: 0.014082
 48%|█████████████▉               | 192/400 [59:09<1:02:50, 18.13s/it]2022-01-14 12:34:36,706 iteration 3265 : loss : 0.021354, loss_ce: 0.008957
2022-01-14 12:34:37,750 iteration 3266 : loss : 0.034999, loss_ce: 0.013905
2022-01-14 12:34:38,762 iteration 3267 : loss : 0.026984, loss_ce: 0.010530
2022-01-14 12:34:39,714 iteration 3268 : loss : 0.021409, loss_ce: 0.007573
2022-01-14 12:34:40,766 iteration 3269 : loss : 0.034424, loss_ce: 0.015909
2022-01-14 12:34:41,850 iteration 3270 : loss : 0.034369, loss_ce: 0.009881
2022-01-14 12:34:42,895 iteration 3271 : loss : 0.031218, loss_ce: 0.009860
2022-01-14 12:34:43,942 iteration 3272 : loss : 0.028330, loss_ce: 0.010883
2022-01-14 12:34:44,878 iteration 3273 : loss : 0.027848, loss_ce: 0.008847
2022-01-14 12:34:45,862 iteration 3274 : loss : 0.025168, loss_ce: 0.013796
2022-01-14 12:34:46,915 iteration 3275 : loss : 0.037006, loss_ce: 0.010680
2022-01-14 12:34:47,890 iteration 3276 : loss : 0.026277, loss_ce: 0.011735
2022-01-14 12:34:48,918 iteration 3277 : loss : 0.028621, loss_ce: 0.014556
2022-01-14 12:34:49,920 iteration 3278 : loss : 0.032753, loss_ce: 0.011250
2022-01-14 12:34:50,882 iteration 3279 : loss : 0.031859, loss_ce: 0.012578
2022-01-14 12:34:51,863 iteration 3280 : loss : 0.033067, loss_ce: 0.011194
2022-01-14 12:34:52,800 iteration 3281 : loss : 0.021760, loss_ce: 0.006442
 48%|█████████████▉               | 193/400 [59:26<1:01:27, 17.81s/it]2022-01-14 12:34:53,884 iteration 3282 : loss : 0.039777, loss_ce: 0.016705
2022-01-14 12:34:54,878 iteration 3283 : loss : 0.021303, loss_ce: 0.007145
2022-01-14 12:34:55,875 iteration 3284 : loss : 0.032219, loss_ce: 0.013291
2022-01-14 12:34:56,860 iteration 3285 : loss : 0.032326, loss_ce: 0.012659
2022-01-14 12:34:57,846 iteration 3286 : loss : 0.024914, loss_ce: 0.009250
2022-01-14 12:34:58,853 iteration 3287 : loss : 0.035858, loss_ce: 0.012603
2022-01-14 12:34:59,796 iteration 3288 : loss : 0.036668, loss_ce: 0.018508
2022-01-14 12:35:00,751 iteration 3289 : loss : 0.035384, loss_ce: 0.010888
2022-01-14 12:35:01,804 iteration 3290 : loss : 0.045481, loss_ce: 0.013169
2022-01-14 12:35:02,861 iteration 3291 : loss : 0.045432, loss_ce: 0.016351
2022-01-14 12:35:03,876 iteration 3292 : loss : 0.027812, loss_ce: 0.008217
2022-01-14 12:35:04,866 iteration 3293 : loss : 0.036025, loss_ce: 0.012718
2022-01-14 12:35:05,830 iteration 3294 : loss : 0.024230, loss_ce: 0.010128
2022-01-14 12:35:06,908 iteration 3295 : loss : 0.055607, loss_ce: 0.025922
2022-01-14 12:35:07,927 iteration 3296 : loss : 0.028760, loss_ce: 0.008141
2022-01-14 12:35:08,852 iteration 3297 : loss : 0.021580, loss_ce: 0.008614
2022-01-14 12:35:09,885 iteration 3298 : loss : 0.030249, loss_ce: 0.012389
 48%|██████████████               | 194/400 [59:43<1:00:24, 17.60s/it]2022-01-14 12:35:10,872 iteration 3299 : loss : 0.025103, loss_ce: 0.010777
2022-01-14 12:35:11,839 iteration 3300 : loss : 0.039321, loss_ce: 0.013184
2022-01-14 12:35:12,886 iteration 3301 : loss : 0.031654, loss_ce: 0.013567
2022-01-14 12:35:13,877 iteration 3302 : loss : 0.028797, loss_ce: 0.011958
2022-01-14 12:35:14,849 iteration 3303 : loss : 0.027432, loss_ce: 0.011710
2022-01-14 12:35:15,846 iteration 3304 : loss : 0.024870, loss_ce: 0.008949
2022-01-14 12:35:16,865 iteration 3305 : loss : 0.026639, loss_ce: 0.009282
2022-01-14 12:35:17,907 iteration 3306 : loss : 0.031877, loss_ce: 0.012039
2022-01-14 12:35:18,875 iteration 3307 : loss : 0.030207, loss_ce: 0.010754
2022-01-14 12:35:19,877 iteration 3308 : loss : 0.030685, loss_ce: 0.012900
2022-01-14 12:35:20,866 iteration 3309 : loss : 0.036556, loss_ce: 0.008765
2022-01-14 12:35:21,935 iteration 3310 : loss : 0.056392, loss_ce: 0.020034
2022-01-14 12:35:23,023 iteration 3311 : loss : 0.024652, loss_ce: 0.008804
2022-01-14 12:35:23,969 iteration 3312 : loss : 0.029763, loss_ce: 0.009919
2022-01-14 12:35:24,928 iteration 3313 : loss : 0.023296, loss_ce: 0.008163
2022-01-14 12:35:25,988 iteration 3314 : loss : 0.032945, loss_ce: 0.012099
2022-01-14 12:35:25,988 Training Data Eval:
2022-01-14 12:35:30,807   Average segmentation loss on training set: 0.0205
2022-01-14 12:35:30,807 Validation Data Eval:
2022-01-14 12:35:32,436   Average segmentation loss on validation set: 0.0692
2022-01-14 12:35:33,378 iteration 3315 : loss : 0.021632, loss_ce: 0.009900
 49%|█████████████▏             | 195/400 [1:00:07<1:06:09, 19.37s/it]2022-01-14 12:35:34,382 iteration 3316 : loss : 0.018849, loss_ce: 0.007006
2022-01-14 12:35:35,344 iteration 3317 : loss : 0.036582, loss_ce: 0.013236
2022-01-14 12:35:36,432 iteration 3318 : loss : 0.026946, loss_ce: 0.010736
2022-01-14 12:35:37,399 iteration 3319 : loss : 0.032915, loss_ce: 0.011523
2022-01-14 12:35:38,379 iteration 3320 : loss : 0.026938, loss_ce: 0.010903
2022-01-14 12:35:39,382 iteration 3321 : loss : 0.021852, loss_ce: 0.006573
2022-01-14 12:35:40,387 iteration 3322 : loss : 0.047991, loss_ce: 0.021969
2022-01-14 12:35:41,335 iteration 3323 : loss : 0.025250, loss_ce: 0.007900
2022-01-14 12:35:42,403 iteration 3324 : loss : 0.044480, loss_ce: 0.023895
2022-01-14 12:35:43,349 iteration 3325 : loss : 0.037221, loss_ce: 0.011351
2022-01-14 12:35:44,371 iteration 3326 : loss : 0.033035, loss_ce: 0.014159
2022-01-14 12:35:45,461 iteration 3327 : loss : 0.049949, loss_ce: 0.016124
2022-01-14 12:35:46,458 iteration 3328 : loss : 0.029380, loss_ce: 0.011393
2022-01-14 12:35:47,425 iteration 3329 : loss : 0.025495, loss_ce: 0.010851
2022-01-14 12:35:48,411 iteration 3330 : loss : 0.041336, loss_ce: 0.015744
2022-01-14 12:35:49,420 iteration 3331 : loss : 0.028459, loss_ce: 0.010885
2022-01-14 12:35:50,332 iteration 3332 : loss : 0.019377, loss_ce: 0.008609
 49%|█████████████▏             | 196/400 [1:00:24<1:03:23, 18.64s/it]2022-01-14 12:35:51,366 iteration 3333 : loss : 0.022826, loss_ce: 0.008687
2022-01-14 12:35:52,374 iteration 3334 : loss : 0.018053, loss_ce: 0.008518
2022-01-14 12:35:53,288 iteration 3335 : loss : 0.019559, loss_ce: 0.008491
2022-01-14 12:35:54,279 iteration 3336 : loss : 0.026984, loss_ce: 0.008843
2022-01-14 12:35:55,318 iteration 3337 : loss : 0.031505, loss_ce: 0.011760
2022-01-14 12:35:56,406 iteration 3338 : loss : 0.036268, loss_ce: 0.019123
2022-01-14 12:35:57,393 iteration 3339 : loss : 0.039618, loss_ce: 0.010634
2022-01-14 12:35:58,358 iteration 3340 : loss : 0.023626, loss_ce: 0.008456
2022-01-14 12:35:59,364 iteration 3341 : loss : 0.020276, loss_ce: 0.007389
2022-01-14 12:36:00,409 iteration 3342 : loss : 0.047960, loss_ce: 0.024380
2022-01-14 12:36:01,425 iteration 3343 : loss : 0.030543, loss_ce: 0.011714
2022-01-14 12:36:02,431 iteration 3344 : loss : 0.043808, loss_ce: 0.014517
2022-01-14 12:36:03,401 iteration 3345 : loss : 0.020324, loss_ce: 0.007074
2022-01-14 12:36:04,399 iteration 3346 : loss : 0.026662, loss_ce: 0.012658
2022-01-14 12:36:05,424 iteration 3347 : loss : 0.045535, loss_ce: 0.012621
2022-01-14 12:36:06,513 iteration 3348 : loss : 0.031157, loss_ce: 0.010284
2022-01-14 12:36:07,537 iteration 3349 : loss : 0.031066, loss_ce: 0.013269
 49%|█████████████▎             | 197/400 [1:00:41<1:01:36, 18.21s/it]2022-01-14 12:36:08,560 iteration 3350 : loss : 0.021593, loss_ce: 0.007863
2022-01-14 12:36:09,509 iteration 3351 : loss : 0.025192, loss_ce: 0.010026
2022-01-14 12:36:10,479 iteration 3352 : loss : 0.028524, loss_ce: 0.011058
2022-01-14 12:36:11,492 iteration 3353 : loss : 0.028960, loss_ce: 0.010750
2022-01-14 12:36:12,503 iteration 3354 : loss : 0.019910, loss_ce: 0.006313
2022-01-14 12:36:13,567 iteration 3355 : loss : 0.033723, loss_ce: 0.017993
2022-01-14 12:36:14,617 iteration 3356 : loss : 0.032747, loss_ce: 0.010110
2022-01-14 12:36:15,676 iteration 3357 : loss : 0.029795, loss_ce: 0.008847
2022-01-14 12:36:16,745 iteration 3358 : loss : 0.033543, loss_ce: 0.011214
2022-01-14 12:36:17,775 iteration 3359 : loss : 0.023199, loss_ce: 0.009140
2022-01-14 12:36:18,873 iteration 3360 : loss : 0.029487, loss_ce: 0.012779
2022-01-14 12:36:19,824 iteration 3361 : loss : 0.036698, loss_ce: 0.010282
2022-01-14 12:36:20,784 iteration 3362 : loss : 0.031840, loss_ce: 0.012753
2022-01-14 12:36:21,733 iteration 3363 : loss : 0.023760, loss_ce: 0.011049
2022-01-14 12:36:22,748 iteration 3364 : loss : 0.023013, loss_ce: 0.008066
2022-01-14 12:36:23,700 iteration 3365 : loss : 0.027473, loss_ce: 0.014685
2022-01-14 12:36:24,684 iteration 3366 : loss : 0.029743, loss_ce: 0.011772
 50%|█████████████▎             | 198/400 [1:00:58<1:00:14, 17.89s/it]2022-01-14 12:36:25,735 iteration 3367 : loss : 0.029786, loss_ce: 0.009161
2022-01-14 12:36:26,725 iteration 3368 : loss : 0.034479, loss_ce: 0.017369
2022-01-14 12:36:27,746 iteration 3369 : loss : 0.024990, loss_ce: 0.008667
2022-01-14 12:36:28,768 iteration 3370 : loss : 0.038925, loss_ce: 0.018619
2022-01-14 12:36:29,677 iteration 3371 : loss : 0.018209, loss_ce: 0.007215
2022-01-14 12:36:30,652 iteration 3372 : loss : 0.023442, loss_ce: 0.012194
2022-01-14 12:36:31,638 iteration 3373 : loss : 0.025171, loss_ce: 0.013701
2022-01-14 12:36:32,576 iteration 3374 : loss : 0.019114, loss_ce: 0.008129
2022-01-14 12:36:33,524 iteration 3375 : loss : 0.026385, loss_ce: 0.011353
2022-01-14 12:36:34,483 iteration 3376 : loss : 0.028877, loss_ce: 0.010802
2022-01-14 12:36:35,517 iteration 3377 : loss : 0.030951, loss_ce: 0.011149
2022-01-14 12:36:36,505 iteration 3378 : loss : 0.030247, loss_ce: 0.010630
2022-01-14 12:36:37,417 iteration 3379 : loss : 0.020177, loss_ce: 0.009059
2022-01-14 12:36:38,474 iteration 3380 : loss : 0.041753, loss_ce: 0.017017
2022-01-14 12:36:39,402 iteration 3381 : loss : 0.062681, loss_ce: 0.011598
2022-01-14 12:36:40,398 iteration 3382 : loss : 0.032294, loss_ce: 0.011365
2022-01-14 12:36:41,376 iteration 3383 : loss : 0.026122, loss_ce: 0.009043
 50%|██████████████▍              | 199/400 [1:01:15<58:44, 17.53s/it]2022-01-14 12:36:42,377 iteration 3384 : loss : 0.030113, loss_ce: 0.010773
2022-01-14 12:36:43,416 iteration 3385 : loss : 0.035334, loss_ce: 0.015442
2022-01-14 12:36:44,470 iteration 3386 : loss : 0.047555, loss_ce: 0.024457
2022-01-14 12:36:45,504 iteration 3387 : loss : 0.031947, loss_ce: 0.012917
2022-01-14 12:36:46,445 iteration 3388 : loss : 0.027901, loss_ce: 0.011463
2022-01-14 12:36:47,469 iteration 3389 : loss : 0.031970, loss_ce: 0.012794
2022-01-14 12:36:48,397 iteration 3390 : loss : 0.030765, loss_ce: 0.008206
2022-01-14 12:36:49,485 iteration 3391 : loss : 0.040794, loss_ce: 0.013423
2022-01-14 12:36:50,516 iteration 3392 : loss : 0.030970, loss_ce: 0.012135
2022-01-14 12:36:51,540 iteration 3393 : loss : 0.031817, loss_ce: 0.011800
2022-01-14 12:36:52,447 iteration 3394 : loss : 0.030354, loss_ce: 0.010590
2022-01-14 12:36:53,545 iteration 3395 : loss : 0.036932, loss_ce: 0.013006
2022-01-14 12:36:54,567 iteration 3396 : loss : 0.037947, loss_ce: 0.015337
2022-01-14 12:36:55,540 iteration 3397 : loss : 0.028223, loss_ce: 0.012157
2022-01-14 12:36:56,569 iteration 3398 : loss : 0.027011, loss_ce: 0.008991
2022-01-14 12:36:57,577 iteration 3399 : loss : 0.023888, loss_ce: 0.010493
2022-01-14 12:36:57,577 Training Data Eval:
2022-01-14 12:37:02,382   Average segmentation loss on training set: 0.0209
2022-01-14 12:37:02,383 Validation Data Eval:
2022-01-14 12:37:03,995   Average segmentation loss on validation set: 0.0780
2022-01-14 12:37:04,988 iteration 3400 : loss : 0.029287, loss_ce: 0.008510
 50%|█████████████▌             | 200/400 [1:01:39<1:04:31, 19.36s/it]2022-01-14 12:37:06,184 iteration 3401 : loss : 0.032879, loss_ce: 0.015298
2022-01-14 12:37:07,234 iteration 3402 : loss : 0.039406, loss_ce: 0.013983
2022-01-14 12:37:08,203 iteration 3403 : loss : 0.029991, loss_ce: 0.014935
2022-01-14 12:37:09,175 iteration 3404 : loss : 0.022777, loss_ce: 0.007701
2022-01-14 12:37:10,152 iteration 3405 : loss : 0.027490, loss_ce: 0.010084
2022-01-14 12:37:11,195 iteration 3406 : loss : 0.044715, loss_ce: 0.014889
2022-01-14 12:37:12,200 iteration 3407 : loss : 0.030407, loss_ce: 0.012826
2022-01-14 12:37:13,248 iteration 3408 : loss : 0.022957, loss_ce: 0.008385
2022-01-14 12:37:14,276 iteration 3409 : loss : 0.055447, loss_ce: 0.028941
2022-01-14 12:37:15,301 iteration 3410 : loss : 0.026437, loss_ce: 0.010210
2022-01-14 12:37:16,360 iteration 3411 : loss : 0.027912, loss_ce: 0.010531
2022-01-14 12:37:17,305 iteration 3412 : loss : 0.032639, loss_ce: 0.011349
2022-01-14 12:37:18,231 iteration 3413 : loss : 0.020798, loss_ce: 0.008848
2022-01-14 12:37:19,248 iteration 3414 : loss : 0.040777, loss_ce: 0.011729
2022-01-14 12:37:20,287 iteration 3415 : loss : 0.029243, loss_ce: 0.011462
2022-01-14 12:37:21,328 iteration 3416 : loss : 0.036040, loss_ce: 0.012010
2022-01-14 12:37:22,411 iteration 3417 : loss : 0.044880, loss_ce: 0.017141
 50%|█████████████▌             | 201/400 [1:01:56<1:02:16, 18.77s/it]2022-01-14 12:37:23,483 iteration 3418 : loss : 0.031421, loss_ce: 0.014794
2022-01-14 12:37:24,527 iteration 3419 : loss : 0.027166, loss_ce: 0.009663
2022-01-14 12:37:25,624 iteration 3420 : loss : 0.034648, loss_ce: 0.010170
2022-01-14 12:37:26,649 iteration 3421 : loss : 0.033229, loss_ce: 0.011867
2022-01-14 12:37:27,596 iteration 3422 : loss : 0.024810, loss_ce: 0.007272
2022-01-14 12:37:28,595 iteration 3423 : loss : 0.021207, loss_ce: 0.008335
2022-01-14 12:37:29,597 iteration 3424 : loss : 0.030030, loss_ce: 0.012984
2022-01-14 12:37:30,546 iteration 3425 : loss : 0.042040, loss_ce: 0.020995
2022-01-14 12:37:31,556 iteration 3426 : loss : 0.033336, loss_ce: 0.011021
2022-01-14 12:37:32,584 iteration 3427 : loss : 0.043172, loss_ce: 0.014261
2022-01-14 12:37:33,606 iteration 3428 : loss : 0.041015, loss_ce: 0.016881
2022-01-14 12:37:34,654 iteration 3429 : loss : 0.032551, loss_ce: 0.011590
2022-01-14 12:37:35,707 iteration 3430 : loss : 0.026837, loss_ce: 0.011530
2022-01-14 12:37:36,634 iteration 3431 : loss : 0.032309, loss_ce: 0.011631
2022-01-14 12:37:37,597 iteration 3432 : loss : 0.025092, loss_ce: 0.008429
2022-01-14 12:37:38,559 iteration 3433 : loss : 0.027233, loss_ce: 0.009263
2022-01-14 12:37:39,604 iteration 3434 : loss : 0.039347, loss_ce: 0.014605
 50%|█████████████▋             | 202/400 [1:02:13<1:00:23, 18.30s/it]2022-01-14 12:37:40,582 iteration 3435 : loss : 0.028968, loss_ce: 0.008090
2022-01-14 12:37:41,551 iteration 3436 : loss : 0.026974, loss_ce: 0.010554
2022-01-14 12:37:42,649 iteration 3437 : loss : 0.039549, loss_ce: 0.018458
2022-01-14 12:37:43,718 iteration 3438 : loss : 0.028099, loss_ce: 0.012721
2022-01-14 12:37:44,768 iteration 3439 : loss : 0.033589, loss_ce: 0.011982
2022-01-14 12:37:45,738 iteration 3440 : loss : 0.021613, loss_ce: 0.008313
2022-01-14 12:37:46,733 iteration 3441 : loss : 0.028133, loss_ce: 0.010661
2022-01-14 12:37:47,845 iteration 3442 : loss : 0.039924, loss_ce: 0.012180
2022-01-14 12:37:48,890 iteration 3443 : loss : 0.027446, loss_ce: 0.009506
2022-01-14 12:37:49,935 iteration 3444 : loss : 0.036072, loss_ce: 0.014974
2022-01-14 12:37:50,944 iteration 3445 : loss : 0.048569, loss_ce: 0.017109
2022-01-14 12:37:51,937 iteration 3446 : loss : 0.028382, loss_ce: 0.012174
2022-01-14 12:37:52,952 iteration 3447 : loss : 0.026075, loss_ce: 0.009698
2022-01-14 12:37:54,015 iteration 3448 : loss : 0.038852, loss_ce: 0.011969
2022-01-14 12:37:55,043 iteration 3449 : loss : 0.036349, loss_ce: 0.015255
2022-01-14 12:37:56,049 iteration 3450 : loss : 0.045534, loss_ce: 0.023095
2022-01-14 12:37:57,133 iteration 3451 : loss : 0.034256, loss_ce: 0.014247
 51%|██████████████▋              | 203/400 [1:02:31<59:19, 18.07s/it]2022-01-14 12:37:58,186 iteration 3452 : loss : 0.024095, loss_ce: 0.009363
2022-01-14 12:37:59,168 iteration 3453 : loss : 0.035653, loss_ce: 0.016256
2022-01-14 12:38:00,133 iteration 3454 : loss : 0.029673, loss_ce: 0.010370
2022-01-14 12:38:01,207 iteration 3455 : loss : 0.028584, loss_ce: 0.012648
2022-01-14 12:38:02,176 iteration 3456 : loss : 0.032059, loss_ce: 0.011314
2022-01-14 12:38:03,275 iteration 3457 : loss : 0.032172, loss_ce: 0.011824
2022-01-14 12:38:04,316 iteration 3458 : loss : 0.034051, loss_ce: 0.014142
2022-01-14 12:38:05,314 iteration 3459 : loss : 0.031043, loss_ce: 0.012627
2022-01-14 12:38:06,304 iteration 3460 : loss : 0.030461, loss_ce: 0.013928
2022-01-14 12:38:07,298 iteration 3461 : loss : 0.027227, loss_ce: 0.009939
2022-01-14 12:38:08,282 iteration 3462 : loss : 0.049473, loss_ce: 0.025474
2022-01-14 12:38:09,318 iteration 3463 : loss : 0.034324, loss_ce: 0.013395
2022-01-14 12:38:10,264 iteration 3464 : loss : 0.022129, loss_ce: 0.008188
2022-01-14 12:38:11,307 iteration 3465 : loss : 0.030737, loss_ce: 0.011009
2022-01-14 12:38:12,325 iteration 3466 : loss : 0.026473, loss_ce: 0.009242
2022-01-14 12:38:13,327 iteration 3467 : loss : 0.035662, loss_ce: 0.017473
2022-01-14 12:38:14,315 iteration 3468 : loss : 0.028839, loss_ce: 0.011828
 51%|██████████████▊              | 204/400 [1:02:48<58:09, 17.80s/it]2022-01-14 12:38:15,341 iteration 3469 : loss : 0.038760, loss_ce: 0.010392
2022-01-14 12:38:16,398 iteration 3470 : loss : 0.037540, loss_ce: 0.013214
2022-01-14 12:38:17,327 iteration 3471 : loss : 0.026620, loss_ce: 0.011423
2022-01-14 12:38:18,347 iteration 3472 : loss : 0.030961, loss_ce: 0.013461
2022-01-14 12:38:19,462 iteration 3473 : loss : 0.040025, loss_ce: 0.016902
2022-01-14 12:38:20,462 iteration 3474 : loss : 0.031089, loss_ce: 0.009772
2022-01-14 12:38:21,535 iteration 3475 : loss : 0.072334, loss_ce: 0.022495
2022-01-14 12:38:22,504 iteration 3476 : loss : 0.025747, loss_ce: 0.008456
2022-01-14 12:38:23,537 iteration 3477 : loss : 0.027633, loss_ce: 0.008838
2022-01-14 12:38:24,538 iteration 3478 : loss : 0.039434, loss_ce: 0.014396
2022-01-14 12:38:25,501 iteration 3479 : loss : 0.031271, loss_ce: 0.012174
2022-01-14 12:38:26,418 iteration 3480 : loss : 0.027959, loss_ce: 0.011424
2022-01-14 12:38:27,404 iteration 3481 : loss : 0.033484, loss_ce: 0.012546
2022-01-14 12:38:28,397 iteration 3482 : loss : 0.024803, loss_ce: 0.009542
2022-01-14 12:38:29,451 iteration 3483 : loss : 0.036678, loss_ce: 0.015117
2022-01-14 12:38:30,367 iteration 3484 : loss : 0.027781, loss_ce: 0.010907
2022-01-14 12:38:30,367 Training Data Eval:
2022-01-14 12:38:35,175   Average segmentation loss on training set: 0.0252
2022-01-14 12:38:35,176 Validation Data Eval:
2022-01-14 12:38:36,794   Average segmentation loss on validation set: 0.0865
2022-01-14 12:38:37,876 iteration 3485 : loss : 0.042935, loss_ce: 0.018935
 51%|█████████████▊             | 205/400 [1:03:11<1:03:28, 19.53s/it]2022-01-14 12:38:38,932 iteration 3486 : loss : 0.037636, loss_ce: 0.015135
2022-01-14 12:38:39,874 iteration 3487 : loss : 0.025920, loss_ce: 0.011332
2022-01-14 12:38:40,848 iteration 3488 : loss : 0.043658, loss_ce: 0.018688
2022-01-14 12:38:41,838 iteration 3489 : loss : 0.037856, loss_ce: 0.014146
2022-01-14 12:38:42,852 iteration 3490 : loss : 0.040738, loss_ce: 0.015835
2022-01-14 12:38:43,905 iteration 3491 : loss : 0.034647, loss_ce: 0.014014
2022-01-14 12:38:44,841 iteration 3492 : loss : 0.036091, loss_ce: 0.011935
2022-01-14 12:38:45,940 iteration 3493 : loss : 0.039796, loss_ce: 0.015435
2022-01-14 12:38:46,968 iteration 3494 : loss : 0.022961, loss_ce: 0.006714
2022-01-14 12:38:47,960 iteration 3495 : loss : 0.031185, loss_ce: 0.010443
2022-01-14 12:38:48,997 iteration 3496 : loss : 0.027767, loss_ce: 0.012519
2022-01-14 12:38:50,026 iteration 3497 : loss : 0.034648, loss_ce: 0.014181
2022-01-14 12:38:51,135 iteration 3498 : loss : 0.029517, loss_ce: 0.011665
2022-01-14 12:38:52,103 iteration 3499 : loss : 0.027306, loss_ce: 0.010457
2022-01-14 12:38:53,020 iteration 3500 : loss : 0.018537, loss_ce: 0.005989
2022-01-14 12:38:53,974 iteration 3501 : loss : 0.030397, loss_ce: 0.012779
2022-01-14 12:38:54,984 iteration 3502 : loss : 0.027561, loss_ce: 0.010408
 52%|█████████████▉             | 206/400 [1:03:29<1:00:47, 18.80s/it]2022-01-14 12:38:56,052 iteration 3503 : loss : 0.028772, loss_ce: 0.010541
2022-01-14 12:38:57,028 iteration 3504 : loss : 0.022196, loss_ce: 0.007253
2022-01-14 12:38:57,930 iteration 3505 : loss : 0.020328, loss_ce: 0.009537
2022-01-14 12:38:58,949 iteration 3506 : loss : 0.029836, loss_ce: 0.009127
2022-01-14 12:38:59,929 iteration 3507 : loss : 0.028858, loss_ce: 0.008640
2022-01-14 12:39:01,039 iteration 3508 : loss : 0.041052, loss_ce: 0.016950
2022-01-14 12:39:02,058 iteration 3509 : loss : 0.024212, loss_ce: 0.009980
2022-01-14 12:39:03,009 iteration 3510 : loss : 0.032771, loss_ce: 0.013578
2022-01-14 12:39:03,949 iteration 3511 : loss : 0.021116, loss_ce: 0.010042
2022-01-14 12:39:05,016 iteration 3512 : loss : 0.044932, loss_ce: 0.013097
2022-01-14 12:39:06,021 iteration 3513 : loss : 0.032534, loss_ce: 0.008867
2022-01-14 12:39:07,138 iteration 3514 : loss : 0.030224, loss_ce: 0.014184
2022-01-14 12:39:08,119 iteration 3515 : loss : 0.027939, loss_ce: 0.009021
2022-01-14 12:39:09,090 iteration 3516 : loss : 0.022955, loss_ce: 0.008737
2022-01-14 12:39:10,073 iteration 3517 : loss : 0.028205, loss_ce: 0.011401
2022-01-14 12:39:11,062 iteration 3518 : loss : 0.031750, loss_ce: 0.014074
2022-01-14 12:39:12,083 iteration 3519 : loss : 0.026915, loss_ce: 0.010978
 52%|███████████████              | 207/400 [1:03:46<58:50, 18.29s/it]2022-01-14 12:39:13,151 iteration 3520 : loss : 0.030477, loss_ce: 0.012290
2022-01-14 12:39:14,119 iteration 3521 : loss : 0.032600, loss_ce: 0.014745
2022-01-14 12:39:15,051 iteration 3522 : loss : 0.025578, loss_ce: 0.012694
2022-01-14 12:39:16,031 iteration 3523 : loss : 0.024938, loss_ce: 0.009774
2022-01-14 12:39:17,055 iteration 3524 : loss : 0.023180, loss_ce: 0.009426
2022-01-14 12:39:18,154 iteration 3525 : loss : 0.026841, loss_ce: 0.010682
2022-01-14 12:39:19,178 iteration 3526 : loss : 0.025701, loss_ce: 0.009797
2022-01-14 12:39:20,220 iteration 3527 : loss : 0.039925, loss_ce: 0.012331
2022-01-14 12:39:21,347 iteration 3528 : loss : 0.039721, loss_ce: 0.016725
2022-01-14 12:39:22,378 iteration 3529 : loss : 0.035109, loss_ce: 0.008972
2022-01-14 12:39:23,409 iteration 3530 : loss : 0.019983, loss_ce: 0.007710
2022-01-14 12:39:24,364 iteration 3531 : loss : 0.031308, loss_ce: 0.009903
2022-01-14 12:39:25,439 iteration 3532 : loss : 0.039089, loss_ce: 0.017043
2022-01-14 12:39:26,424 iteration 3533 : loss : 0.026219, loss_ce: 0.007900
2022-01-14 12:39:27,449 iteration 3534 : loss : 0.042287, loss_ce: 0.017749
2022-01-14 12:39:28,522 iteration 3535 : loss : 0.035182, loss_ce: 0.012901
2022-01-14 12:39:29,560 iteration 3536 : loss : 0.032138, loss_ce: 0.012631
 52%|███████████████              | 208/400 [1:04:03<57:44, 18.05s/it]2022-01-14 12:39:30,542 iteration 3537 : loss : 0.024903, loss_ce: 0.010280
2022-01-14 12:39:31,473 iteration 3538 : loss : 0.028634, loss_ce: 0.012242
2022-01-14 12:39:32,425 iteration 3539 : loss : 0.021130, loss_ce: 0.009019
2022-01-14 12:39:33,319 iteration 3540 : loss : 0.025044, loss_ce: 0.007337
2022-01-14 12:39:34,399 iteration 3541 : loss : 0.046646, loss_ce: 0.020427
2022-01-14 12:39:35,395 iteration 3542 : loss : 0.037102, loss_ce: 0.015872
2022-01-14 12:39:36,507 iteration 3543 : loss : 0.038440, loss_ce: 0.012563
2022-01-14 12:39:37,434 iteration 3544 : loss : 0.018651, loss_ce: 0.007190
2022-01-14 12:39:38,421 iteration 3545 : loss : 0.024550, loss_ce: 0.011248
2022-01-14 12:39:39,349 iteration 3546 : loss : 0.024689, loss_ce: 0.008519
2022-01-14 12:39:40,345 iteration 3547 : loss : 0.041081, loss_ce: 0.020643
2022-01-14 12:39:41,291 iteration 3548 : loss : 0.040677, loss_ce: 0.013573
2022-01-14 12:39:42,292 iteration 3549 : loss : 0.033838, loss_ce: 0.012529
2022-01-14 12:39:43,328 iteration 3550 : loss : 0.025902, loss_ce: 0.011171
2022-01-14 12:39:44,394 iteration 3551 : loss : 0.036284, loss_ce: 0.011450
2022-01-14 12:39:45,457 iteration 3552 : loss : 0.055952, loss_ce: 0.019573
2022-01-14 12:39:46,518 iteration 3553 : loss : 0.029396, loss_ce: 0.012365
 52%|███████████████▏             | 209/400 [1:04:20<56:24, 17.72s/it]2022-01-14 12:39:47,589 iteration 3554 : loss : 0.046878, loss_ce: 0.020105
2022-01-14 12:39:48,563 iteration 3555 : loss : 0.024204, loss_ce: 0.007445
2022-01-14 12:39:49,538 iteration 3556 : loss : 0.026972, loss_ce: 0.012133
2022-01-14 12:39:50,624 iteration 3557 : loss : 0.039540, loss_ce: 0.012031
2022-01-14 12:39:51,579 iteration 3558 : loss : 0.047167, loss_ce: 0.011423
2022-01-14 12:39:52,563 iteration 3559 : loss : 0.031514, loss_ce: 0.007738
2022-01-14 12:39:53,453 iteration 3560 : loss : 0.024846, loss_ce: 0.011944
2022-01-14 12:39:54,532 iteration 3561 : loss : 0.027025, loss_ce: 0.009309
2022-01-14 12:39:55,495 iteration 3562 : loss : 0.028491, loss_ce: 0.010525
2022-01-14 12:39:56,520 iteration 3563 : loss : 0.029718, loss_ce: 0.010488
2022-01-14 12:39:57,524 iteration 3564 : loss : 0.033060, loss_ce: 0.011198
2022-01-14 12:39:58,633 iteration 3565 : loss : 0.060643, loss_ce: 0.021855
2022-01-14 12:39:59,653 iteration 3566 : loss : 0.037186, loss_ce: 0.014625
2022-01-14 12:40:00,748 iteration 3567 : loss : 0.032631, loss_ce: 0.014582
2022-01-14 12:40:01,812 iteration 3568 : loss : 0.041193, loss_ce: 0.017626
2022-01-14 12:40:02,868 iteration 3569 : loss : 0.060573, loss_ce: 0.014787
2022-01-14 12:40:02,869 Training Data Eval:
2022-01-14 12:40:07,679   Average segmentation loss on training set: 0.0212
2022-01-14 12:40:07,679 Validation Data Eval:
2022-01-14 12:40:09,298   Average segmentation loss on validation set: 0.0813
2022-01-14 12:40:10,324 iteration 3570 : loss : 0.041747, loss_ce: 0.015808
 52%|██████████████▏            | 210/400 [1:04:44<1:01:53, 19.55s/it]2022-01-14 12:40:11,377 iteration 3571 : loss : 0.025424, loss_ce: 0.010914
2022-01-14 12:40:12,380 iteration 3572 : loss : 0.035402, loss_ce: 0.010598
2022-01-14 12:40:13,376 iteration 3573 : loss : 0.041954, loss_ce: 0.016654
2022-01-14 12:40:14,344 iteration 3574 : loss : 0.020031, loss_ce: 0.008222
2022-01-14 12:40:15,319 iteration 3575 : loss : 0.027207, loss_ce: 0.011291
2022-01-14 12:40:16,328 iteration 3576 : loss : 0.037647, loss_ce: 0.012017
2022-01-14 12:40:17,379 iteration 3577 : loss : 0.022979, loss_ce: 0.010012
2022-01-14 12:40:18,434 iteration 3578 : loss : 0.038324, loss_ce: 0.013590
2022-01-14 12:40:19,413 iteration 3579 : loss : 0.037089, loss_ce: 0.015229
2022-01-14 12:40:20,443 iteration 3580 : loss : 0.041414, loss_ce: 0.014405
2022-01-14 12:40:21,405 iteration 3581 : loss : 0.030820, loss_ce: 0.007470
2022-01-14 12:40:22,393 iteration 3582 : loss : 0.022619, loss_ce: 0.009366
2022-01-14 12:40:23,429 iteration 3583 : loss : 0.033638, loss_ce: 0.014613
2022-01-14 12:40:24,396 iteration 3584 : loss : 0.033318, loss_ce: 0.012975
2022-01-14 12:40:25,382 iteration 3585 : loss : 0.028741, loss_ce: 0.012218
2022-01-14 12:40:26,319 iteration 3586 : loss : 0.031291, loss_ce: 0.011744
2022-01-14 12:40:27,304 iteration 3587 : loss : 0.031316, loss_ce: 0.014119
 53%|███████████████▎             | 211/400 [1:05:01<59:08, 18.78s/it]2022-01-14 12:40:28,271 iteration 3588 : loss : 0.024536, loss_ce: 0.009018
2022-01-14 12:40:29,301 iteration 3589 : loss : 0.038220, loss_ce: 0.013929
2022-01-14 12:40:30,295 iteration 3590 : loss : 0.031417, loss_ce: 0.013135
2022-01-14 12:40:31,272 iteration 3591 : loss : 0.038572, loss_ce: 0.017745
2022-01-14 12:40:32,328 iteration 3592 : loss : 0.026459, loss_ce: 0.010050
2022-01-14 12:40:33,347 iteration 3593 : loss : 0.037954, loss_ce: 0.010532
2022-01-14 12:40:34,365 iteration 3594 : loss : 0.022830, loss_ce: 0.006605
2022-01-14 12:40:35,493 iteration 3595 : loss : 0.068973, loss_ce: 0.014882
2022-01-14 12:40:36,423 iteration 3596 : loss : 0.026078, loss_ce: 0.010698
2022-01-14 12:40:37,499 iteration 3597 : loss : 0.038087, loss_ce: 0.015390
2022-01-14 12:40:38,495 iteration 3598 : loss : 0.032669, loss_ce: 0.015653
2022-01-14 12:40:39,504 iteration 3599 : loss : 0.038571, loss_ce: 0.016161
2022-01-14 12:40:40,489 iteration 3600 : loss : 0.025671, loss_ce: 0.012825
2022-01-14 12:40:41,493 iteration 3601 : loss : 0.028957, loss_ce: 0.013026
2022-01-14 12:40:42,466 iteration 3602 : loss : 0.028517, loss_ce: 0.012682
2022-01-14 12:40:43,418 iteration 3603 : loss : 0.024141, loss_ce: 0.009081
2022-01-14 12:40:44,362 iteration 3604 : loss : 0.018602, loss_ce: 0.006935
 53%|███████████████▎             | 212/400 [1:05:18<57:13, 18.26s/it]2022-01-14 12:40:45,404 iteration 3605 : loss : 0.021460, loss_ce: 0.008372
2022-01-14 12:40:46,396 iteration 3606 : loss : 0.030486, loss_ce: 0.011241
2022-01-14 12:40:47,330 iteration 3607 : loss : 0.026505, loss_ce: 0.009387
2022-01-14 12:40:48,264 iteration 3608 : loss : 0.028370, loss_ce: 0.013055
2022-01-14 12:40:49,283 iteration 3609 : loss : 0.037760, loss_ce: 0.012006
2022-01-14 12:40:50,246 iteration 3610 : loss : 0.028796, loss_ce: 0.012290
2022-01-14 12:40:51,276 iteration 3611 : loss : 0.029027, loss_ce: 0.016264
2022-01-14 12:40:52,324 iteration 3612 : loss : 0.024809, loss_ce: 0.008437
2022-01-14 12:40:53,327 iteration 3613 : loss : 0.033361, loss_ce: 0.010169
2022-01-14 12:40:54,366 iteration 3614 : loss : 0.027685, loss_ce: 0.008835
2022-01-14 12:40:55,336 iteration 3615 : loss : 0.028096, loss_ce: 0.008078
2022-01-14 12:40:56,399 iteration 3616 : loss : 0.031897, loss_ce: 0.011217
2022-01-14 12:40:57,375 iteration 3617 : loss : 0.038644, loss_ce: 0.017659
2022-01-14 12:40:58,367 iteration 3618 : loss : 0.028934, loss_ce: 0.013517
2022-01-14 12:40:59,357 iteration 3619 : loss : 0.022844, loss_ce: 0.008844
2022-01-14 12:41:00,389 iteration 3620 : loss : 0.028995, loss_ce: 0.012626
2022-01-14 12:41:01,368 iteration 3621 : loss : 0.034654, loss_ce: 0.016347
 53%|███████████████▍             | 213/400 [1:05:35<55:44, 17.88s/it]2022-01-14 12:41:02,482 iteration 3622 : loss : 0.028477, loss_ce: 0.009593
2022-01-14 12:41:03,478 iteration 3623 : loss : 0.031875, loss_ce: 0.013741
2022-01-14 12:41:04,546 iteration 3624 : loss : 0.021753, loss_ce: 0.006893
2022-01-14 12:41:05,611 iteration 3625 : loss : 0.033247, loss_ce: 0.014593
2022-01-14 12:41:06,606 iteration 3626 : loss : 0.028792, loss_ce: 0.011088
2022-01-14 12:41:07,646 iteration 3627 : loss : 0.029290, loss_ce: 0.014062
2022-01-14 12:41:08,668 iteration 3628 : loss : 0.028948, loss_ce: 0.009074
2022-01-14 12:41:09,746 iteration 3629 : loss : 0.026080, loss_ce: 0.011228
2022-01-14 12:41:10,747 iteration 3630 : loss : 0.023145, loss_ce: 0.009637
2022-01-14 12:41:11,679 iteration 3631 : loss : 0.025230, loss_ce: 0.009791
2022-01-14 12:41:12,614 iteration 3632 : loss : 0.021880, loss_ce: 0.010329
2022-01-14 12:41:13,664 iteration 3633 : loss : 0.048971, loss_ce: 0.019542
2022-01-14 12:41:14,652 iteration 3634 : loss : 0.027818, loss_ce: 0.010963
2022-01-14 12:41:15,605 iteration 3635 : loss : 0.032120, loss_ce: 0.009847
2022-01-14 12:41:16,557 iteration 3636 : loss : 0.026751, loss_ce: 0.010871
2022-01-14 12:41:17,609 iteration 3637 : loss : 0.045003, loss_ce: 0.013041
2022-01-14 12:41:18,552 iteration 3638 : loss : 0.023781, loss_ce: 0.007840
 54%|███████████████▌             | 214/400 [1:05:52<54:47, 17.68s/it]2022-01-14 12:41:19,586 iteration 3639 : loss : 0.021451, loss_ce: 0.009735
2022-01-14 12:41:20,624 iteration 3640 : loss : 0.027553, loss_ce: 0.010038
2022-01-14 12:41:21,627 iteration 3641 : loss : 0.030927, loss_ce: 0.010035
2022-01-14 12:41:22,666 iteration 3642 : loss : 0.026111, loss_ce: 0.011131
2022-01-14 12:41:23,657 iteration 3643 : loss : 0.032315, loss_ce: 0.015213
2022-01-14 12:41:24,638 iteration 3644 : loss : 0.025194, loss_ce: 0.011317
2022-01-14 12:41:25,595 iteration 3645 : loss : 0.024234, loss_ce: 0.009942
2022-01-14 12:41:26,599 iteration 3646 : loss : 0.025104, loss_ce: 0.009592
2022-01-14 12:41:27,641 iteration 3647 : loss : 0.035525, loss_ce: 0.014728
2022-01-14 12:41:28,749 iteration 3648 : loss : 0.032699, loss_ce: 0.014266
2022-01-14 12:41:29,765 iteration 3649 : loss : 0.047723, loss_ce: 0.017645
2022-01-14 12:41:30,763 iteration 3650 : loss : 0.026879, loss_ce: 0.009261
2022-01-14 12:41:31,783 iteration 3651 : loss : 0.042119, loss_ce: 0.014997
2022-01-14 12:41:32,751 iteration 3652 : loss : 0.023168, loss_ce: 0.010010
2022-01-14 12:41:33,812 iteration 3653 : loss : 0.039915, loss_ce: 0.008169
2022-01-14 12:41:34,826 iteration 3654 : loss : 0.023548, loss_ce: 0.006864
2022-01-14 12:41:34,826 Training Data Eval:
2022-01-14 12:41:39,643   Average segmentation loss on training set: 0.0177
2022-01-14 12:41:39,643 Validation Data Eval:
2022-01-14 12:41:41,258   Average segmentation loss on validation set: 0.0640
2022-01-14 12:41:42,160 iteration 3655 : loss : 0.024979, loss_ce: 0.010375
 54%|███████████████▌             | 215/400 [1:06:16<59:59, 19.45s/it]2022-01-14 12:41:43,269 iteration 3656 : loss : 0.059873, loss_ce: 0.012440
2022-01-14 12:41:44,237 iteration 3657 : loss : 0.029720, loss_ce: 0.014281
2022-01-14 12:41:45,236 iteration 3658 : loss : 0.025222, loss_ce: 0.009814
2022-01-14 12:41:46,273 iteration 3659 : loss : 0.033047, loss_ce: 0.008236
2022-01-14 12:41:47,369 iteration 3660 : loss : 0.068253, loss_ce: 0.024927
2022-01-14 12:41:48,482 iteration 3661 : loss : 0.033879, loss_ce: 0.014178
2022-01-14 12:41:49,404 iteration 3662 : loss : 0.022676, loss_ce: 0.008175
2022-01-14 12:41:50,366 iteration 3663 : loss : 0.021288, loss_ce: 0.007063
2022-01-14 12:41:51,355 iteration 3664 : loss : 0.034415, loss_ce: 0.010955
2022-01-14 12:41:52,342 iteration 3665 : loss : 0.023856, loss_ce: 0.010184
2022-01-14 12:41:53,456 iteration 3666 : loss : 0.045581, loss_ce: 0.020158
2022-01-14 12:41:54,501 iteration 3667 : loss : 0.042156, loss_ce: 0.017533
2022-01-14 12:41:55,547 iteration 3668 : loss : 0.028266, loss_ce: 0.011100
2022-01-14 12:41:56,559 iteration 3669 : loss : 0.033137, loss_ce: 0.014724
2022-01-14 12:41:57,534 iteration 3670 : loss : 0.040537, loss_ce: 0.012068
2022-01-14 12:41:58,573 iteration 3671 : loss : 0.034488, loss_ce: 0.012483
2022-01-14 12:41:59,526 iteration 3672 : loss : 0.030093, loss_ce: 0.013312
 54%|███████████████▋             | 216/400 [1:06:33<57:44, 18.83s/it]2022-01-14 12:42:00,610 iteration 3673 : loss : 0.027920, loss_ce: 0.013286
2022-01-14 12:42:01,618 iteration 3674 : loss : 0.031591, loss_ce: 0.013305
2022-01-14 12:42:02,601 iteration 3675 : loss : 0.022404, loss_ce: 0.011480
2022-01-14 12:42:03,580 iteration 3676 : loss : 0.024829, loss_ce: 0.008560
2022-01-14 12:42:04,561 iteration 3677 : loss : 0.022224, loss_ce: 0.011084
2022-01-14 12:42:05,654 iteration 3678 : loss : 0.035133, loss_ce: 0.012142
2022-01-14 12:42:06,639 iteration 3679 : loss : 0.032388, loss_ce: 0.013609
2022-01-14 12:42:07,609 iteration 3680 : loss : 0.034934, loss_ce: 0.012300
2022-01-14 12:42:08,654 iteration 3681 : loss : 0.026933, loss_ce: 0.009785
2022-01-14 12:42:09,636 iteration 3682 : loss : 0.026218, loss_ce: 0.010623
2022-01-14 12:42:10,687 iteration 3683 : loss : 0.074655, loss_ce: 0.009561
2022-01-14 12:42:11,657 iteration 3684 : loss : 0.015154, loss_ce: 0.004638
2022-01-14 12:42:12,632 iteration 3685 : loss : 0.031487, loss_ce: 0.012550
2022-01-14 12:42:13,648 iteration 3686 : loss : 0.051398, loss_ce: 0.021420
2022-01-14 12:42:14,647 iteration 3687 : loss : 0.033963, loss_ce: 0.010257
2022-01-14 12:42:15,632 iteration 3688 : loss : 0.052669, loss_ce: 0.028626
2022-01-14 12:42:16,561 iteration 3689 : loss : 0.031993, loss_ce: 0.010980
 54%|███████████████▋             | 217/400 [1:06:50<55:47, 18.29s/it]2022-01-14 12:42:17,573 iteration 3690 : loss : 0.025325, loss_ce: 0.005597
2022-01-14 12:42:18,647 iteration 3691 : loss : 0.050629, loss_ce: 0.010517
2022-01-14 12:42:19,648 iteration 3692 : loss : 0.028873, loss_ce: 0.012018
2022-01-14 12:42:20,716 iteration 3693 : loss : 0.035364, loss_ce: 0.013661
2022-01-14 12:42:21,722 iteration 3694 : loss : 0.022134, loss_ce: 0.009672
2022-01-14 12:42:22,679 iteration 3695 : loss : 0.028119, loss_ce: 0.011155
2022-01-14 12:42:23,726 iteration 3696 : loss : 0.030891, loss_ce: 0.015109
2022-01-14 12:42:24,718 iteration 3697 : loss : 0.026332, loss_ce: 0.008001
2022-01-14 12:42:25,722 iteration 3698 : loss : 0.033930, loss_ce: 0.012665
2022-01-14 12:42:26,791 iteration 3699 : loss : 0.047713, loss_ce: 0.017041
2022-01-14 12:42:27,793 iteration 3700 : loss : 0.027229, loss_ce: 0.011942
2022-01-14 12:42:28,768 iteration 3701 : loss : 0.023620, loss_ce: 0.009136
2022-01-14 12:42:29,733 iteration 3702 : loss : 0.044269, loss_ce: 0.017560
2022-01-14 12:42:30,837 iteration 3703 : loss : 0.035641, loss_ce: 0.015473
2022-01-14 12:42:31,803 iteration 3704 : loss : 0.021464, loss_ce: 0.006541
2022-01-14 12:42:32,760 iteration 3705 : loss : 0.024862, loss_ce: 0.008132
2022-01-14 12:42:33,710 iteration 3706 : loss : 0.022060, loss_ce: 0.006446
 55%|███████████████▊             | 218/400 [1:07:07<54:26, 17.95s/it]2022-01-14 12:42:34,753 iteration 3707 : loss : 0.050955, loss_ce: 0.015848
2022-01-14 12:42:35,754 iteration 3708 : loss : 0.028178, loss_ce: 0.011387
2022-01-14 12:42:36,755 iteration 3709 : loss : 0.022750, loss_ce: 0.007049
2022-01-14 12:42:37,798 iteration 3710 : loss : 0.030640, loss_ce: 0.009686
2022-01-14 12:42:38,771 iteration 3711 : loss : 0.022743, loss_ce: 0.007939
2022-01-14 12:42:39,792 iteration 3712 : loss : 0.031236, loss_ce: 0.009623
2022-01-14 12:42:40,776 iteration 3713 : loss : 0.023014, loss_ce: 0.008543
2022-01-14 12:42:41,738 iteration 3714 : loss : 0.024561, loss_ce: 0.008061
2022-01-14 12:42:42,741 iteration 3715 : loss : 0.042136, loss_ce: 0.017334
2022-01-14 12:42:43,699 iteration 3716 : loss : 0.026908, loss_ce: 0.009794
2022-01-14 12:42:44,709 iteration 3717 : loss : 0.027270, loss_ce: 0.012259
2022-01-14 12:42:45,764 iteration 3718 : loss : 0.028408, loss_ce: 0.012597
2022-01-14 12:42:46,714 iteration 3719 : loss : 0.025734, loss_ce: 0.007081
2022-01-14 12:42:47,738 iteration 3720 : loss : 0.022088, loss_ce: 0.011415
2022-01-14 12:42:48,748 iteration 3721 : loss : 0.026623, loss_ce: 0.011171
2022-01-14 12:42:49,732 iteration 3722 : loss : 0.024967, loss_ce: 0.009714
2022-01-14 12:42:50,693 iteration 3723 : loss : 0.027585, loss_ce: 0.008932
 55%|███████████████▉             | 219/400 [1:07:24<53:16, 17.66s/it]2022-01-14 12:42:51,678 iteration 3724 : loss : 0.019845, loss_ce: 0.009540
2022-01-14 12:42:52,633 iteration 3725 : loss : 0.031957, loss_ce: 0.014093
2022-01-14 12:42:53,683 iteration 3726 : loss : 0.025073, loss_ce: 0.011784
2022-01-14 12:42:54,688 iteration 3727 : loss : 0.019160, loss_ce: 0.007628
2022-01-14 12:42:55,701 iteration 3728 : loss : 0.027320, loss_ce: 0.007357
2022-01-14 12:42:56,658 iteration 3729 : loss : 0.035048, loss_ce: 0.010165
2022-01-14 12:42:57,638 iteration 3730 : loss : 0.022747, loss_ce: 0.009075
2022-01-14 12:42:58,614 iteration 3731 : loss : 0.025063, loss_ce: 0.008940
2022-01-14 12:42:59,640 iteration 3732 : loss : 0.034858, loss_ce: 0.013419
2022-01-14 12:43:00,593 iteration 3733 : loss : 0.024711, loss_ce: 0.009724
2022-01-14 12:43:01,603 iteration 3734 : loss : 0.021344, loss_ce: 0.009068
2022-01-14 12:43:02,601 iteration 3735 : loss : 0.033330, loss_ce: 0.008471
2022-01-14 12:43:03,648 iteration 3736 : loss : 0.028518, loss_ce: 0.013241
2022-01-14 12:43:04,604 iteration 3737 : loss : 0.021902, loss_ce: 0.007264
2022-01-14 12:43:05,589 iteration 3738 : loss : 0.019715, loss_ce: 0.006766
2022-01-14 12:43:06,537 iteration 3739 : loss : 0.025165, loss_ce: 0.009824
2022-01-14 12:43:06,537 Training Data Eval:
2022-01-14 12:43:11,359   Average segmentation loss on training set: 0.0179
2022-01-14 12:43:11,359 Validation Data Eval:
2022-01-14 12:43:12,984   Average segmentation loss on validation set: 0.0609
2022-01-14 12:43:14,125 iteration 3740 : loss : 0.037042, loss_ce: 0.020252
 55%|███████████████▉             | 220/400 [1:07:48<58:09, 19.39s/it]2022-01-14 12:43:15,305 iteration 3741 : loss : 0.048148, loss_ce: 0.015114
2022-01-14 12:43:16,299 iteration 3742 : loss : 0.026619, loss_ce: 0.012930
2022-01-14 12:43:17,296 iteration 3743 : loss : 0.025690, loss_ce: 0.009247
2022-01-14 12:43:18,342 iteration 3744 : loss : 0.042542, loss_ce: 0.014773
2022-01-14 12:43:19,406 iteration 3745 : loss : 0.025146, loss_ce: 0.008443
2022-01-14 12:43:20,474 iteration 3746 : loss : 0.026045, loss_ce: 0.010212
2022-01-14 12:43:21,464 iteration 3747 : loss : 0.023731, loss_ce: 0.007424
2022-01-14 12:43:22,441 iteration 3748 : loss : 0.026901, loss_ce: 0.014023
2022-01-14 12:43:23,488 iteration 3749 : loss : 0.044058, loss_ce: 0.014011
2022-01-14 12:43:24,571 iteration 3750 : loss : 0.029057, loss_ce: 0.010968
2022-01-14 12:43:25,597 iteration 3751 : loss : 0.032786, loss_ce: 0.010799
2022-01-14 12:43:26,580 iteration 3752 : loss : 0.028863, loss_ce: 0.007688
2022-01-14 12:43:27,534 iteration 3753 : loss : 0.030092, loss_ce: 0.009524
2022-01-14 12:43:28,535 iteration 3754 : loss : 0.025189, loss_ce: 0.009414
2022-01-14 12:43:29,582 iteration 3755 : loss : 0.022817, loss_ce: 0.010544
2022-01-14 12:43:30,511 iteration 3756 : loss : 0.023463, loss_ce: 0.010048
2022-01-14 12:43:31,458 iteration 3757 : loss : 0.022970, loss_ce: 0.009812
 55%|████████████████             | 221/400 [1:08:05<56:00, 18.77s/it]2022-01-14 12:43:32,589 iteration 3758 : loss : 0.021371, loss_ce: 0.006696
2022-01-14 12:43:33,546 iteration 3759 : loss : 0.020831, loss_ce: 0.007220
2022-01-14 12:43:34,521 iteration 3760 : loss : 0.020528, loss_ce: 0.008241
2022-01-14 12:43:35,556 iteration 3761 : loss : 0.023501, loss_ce: 0.009624
2022-01-14 12:43:36,614 iteration 3762 : loss : 0.023983, loss_ce: 0.011519
2022-01-14 12:43:37,710 iteration 3763 : loss : 0.044874, loss_ce: 0.016025
2022-01-14 12:43:38,711 iteration 3764 : loss : 0.032817, loss_ce: 0.012384
2022-01-14 12:43:39,663 iteration 3765 : loss : 0.020089, loss_ce: 0.008631
2022-01-14 12:43:40,711 iteration 3766 : loss : 0.043273, loss_ce: 0.013118
2022-01-14 12:43:41,708 iteration 3767 : loss : 0.018428, loss_ce: 0.006414
2022-01-14 12:43:42,666 iteration 3768 : loss : 0.030372, loss_ce: 0.009654
2022-01-14 12:43:43,631 iteration 3769 : loss : 0.023745, loss_ce: 0.010633
2022-01-14 12:43:44,659 iteration 3770 : loss : 0.053574, loss_ce: 0.011946
2022-01-14 12:43:45,782 iteration 3771 : loss : 0.040213, loss_ce: 0.020298
2022-01-14 12:43:46,847 iteration 3772 : loss : 0.028632, loss_ce: 0.007064
2022-01-14 12:43:47,873 iteration 3773 : loss : 0.019909, loss_ce: 0.007568
2022-01-14 12:43:48,938 iteration 3774 : loss : 0.052229, loss_ce: 0.025502
 56%|████████████████             | 222/400 [1:08:22<54:32, 18.38s/it]2022-01-14 12:43:49,973 iteration 3775 : loss : 0.023576, loss_ce: 0.009311
2022-01-14 12:43:50,896 iteration 3776 : loss : 0.033286, loss_ce: 0.014918
2022-01-14 12:43:51,877 iteration 3777 : loss : 0.025260, loss_ce: 0.007445
2022-01-14 12:43:52,835 iteration 3778 : loss : 0.020754, loss_ce: 0.008560
2022-01-14 12:43:53,794 iteration 3779 : loss : 0.019389, loss_ce: 0.008632
2022-01-14 12:43:54,808 iteration 3780 : loss : 0.025152, loss_ce: 0.009385
2022-01-14 12:43:55,817 iteration 3781 : loss : 0.026311, loss_ce: 0.011133
2022-01-14 12:43:56,837 iteration 3782 : loss : 0.071529, loss_ce: 0.015566
2022-01-14 12:43:57,855 iteration 3783 : loss : 0.019269, loss_ce: 0.009530
2022-01-14 12:43:58,883 iteration 3784 : loss : 0.025306, loss_ce: 0.012107
2022-01-14 12:43:59,852 iteration 3785 : loss : 0.026831, loss_ce: 0.010775
2022-01-14 12:44:00,818 iteration 3786 : loss : 0.021148, loss_ce: 0.007956
2022-01-14 12:44:01,776 iteration 3787 : loss : 0.025453, loss_ce: 0.008285
2022-01-14 12:44:02,836 iteration 3788 : loss : 0.037933, loss_ce: 0.009238
2022-01-14 12:44:03,830 iteration 3789 : loss : 0.028843, loss_ce: 0.007841
2022-01-14 12:44:04,869 iteration 3790 : loss : 0.029743, loss_ce: 0.011542
2022-01-14 12:44:05,891 iteration 3791 : loss : 0.033572, loss_ce: 0.015233
 56%|████████████████▏            | 223/400 [1:08:39<52:58, 17.96s/it]2022-01-14 12:44:06,912 iteration 3792 : loss : 0.018744, loss_ce: 0.006595
2022-01-14 12:44:07,956 iteration 3793 : loss : 0.026556, loss_ce: 0.007881
2022-01-14 12:44:08,977 iteration 3794 : loss : 0.039367, loss_ce: 0.017472
2022-01-14 12:44:09,975 iteration 3795 : loss : 0.022336, loss_ce: 0.007387
2022-01-14 12:44:10,884 iteration 3796 : loss : 0.020975, loss_ce: 0.007025
2022-01-14 12:44:11,857 iteration 3797 : loss : 0.026150, loss_ce: 0.009375
2022-01-14 12:44:12,787 iteration 3798 : loss : 0.026436, loss_ce: 0.009759
2022-01-14 12:44:13,764 iteration 3799 : loss : 0.025802, loss_ce: 0.008690
2022-01-14 12:44:14,745 iteration 3800 : loss : 0.018947, loss_ce: 0.005260
2022-01-14 12:44:15,727 iteration 3801 : loss : 0.040593, loss_ce: 0.010166
2022-01-14 12:44:16,690 iteration 3802 : loss : 0.032872, loss_ce: 0.015532
2022-01-14 12:44:17,681 iteration 3803 : loss : 0.022529, loss_ce: 0.007697
2022-01-14 12:44:18,670 iteration 3804 : loss : 0.033895, loss_ce: 0.012480
2022-01-14 12:44:19,634 iteration 3805 : loss : 0.025492, loss_ce: 0.010247
2022-01-14 12:44:20,594 iteration 3806 : loss : 0.030819, loss_ce: 0.014777
2022-01-14 12:44:21,618 iteration 3807 : loss : 0.033191, loss_ce: 0.013367
2022-01-14 12:44:22,620 iteration 3808 : loss : 0.021916, loss_ce: 0.008741
 56%|████████████████▏            | 224/400 [1:08:56<51:35, 17.59s/it]2022-01-14 12:44:23,607 iteration 3809 : loss : 0.020564, loss_ce: 0.007244
2022-01-14 12:44:24,576 iteration 3810 : loss : 0.021232, loss_ce: 0.008542
2022-01-14 12:44:25,562 iteration 3811 : loss : 0.022217, loss_ce: 0.007008
2022-01-14 12:44:26,564 iteration 3812 : loss : 0.034000, loss_ce: 0.017515
2022-01-14 12:44:27,542 iteration 3813 : loss : 0.029798, loss_ce: 0.013814
2022-01-14 12:44:28,568 iteration 3814 : loss : 0.028605, loss_ce: 0.009674
2022-01-14 12:44:29,566 iteration 3815 : loss : 0.033806, loss_ce: 0.012904
2022-01-14 12:44:30,586 iteration 3816 : loss : 0.026688, loss_ce: 0.010819
2022-01-14 12:44:31,535 iteration 3817 : loss : 0.020574, loss_ce: 0.007780
2022-01-14 12:44:32,560 iteration 3818 : loss : 0.025354, loss_ce: 0.011694
2022-01-14 12:44:33,604 iteration 3819 : loss : 0.029885, loss_ce: 0.011716
2022-01-14 12:44:34,631 iteration 3820 : loss : 0.024556, loss_ce: 0.009368
2022-01-14 12:44:35,661 iteration 3821 : loss : 0.028911, loss_ce: 0.011253
2022-01-14 12:44:36,625 iteration 3822 : loss : 0.030244, loss_ce: 0.010312
2022-01-14 12:44:37,704 iteration 3823 : loss : 0.026106, loss_ce: 0.007650
2022-01-14 12:44:38,715 iteration 3824 : loss : 0.030874, loss_ce: 0.012007
2022-01-14 12:44:38,715 Training Data Eval:
2022-01-14 12:44:43,532   Average segmentation loss on training set: 0.0170
2022-01-14 12:44:43,532 Validation Data Eval:
2022-01-14 12:44:45,156   Average segmentation loss on validation set: 0.0790
2022-01-14 12:44:46,229 iteration 3825 : loss : 0.025788, loss_ce: 0.008906
 56%|████████████████▎            | 225/400 [1:09:20<56:33, 19.39s/it]2022-01-14 12:44:47,296 iteration 3826 : loss : 0.022402, loss_ce: 0.009769
2022-01-14 12:44:48,247 iteration 3827 : loss : 0.028572, loss_ce: 0.010203
2022-01-14 12:44:49,259 iteration 3828 : loss : 0.024380, loss_ce: 0.009366
2022-01-14 12:44:50,261 iteration 3829 : loss : 0.025362, loss_ce: 0.008029
2022-01-14 12:44:51,222 iteration 3830 : loss : 0.017371, loss_ce: 0.006676
2022-01-14 12:44:52,169 iteration 3831 : loss : 0.021600, loss_ce: 0.007494
2022-01-14 12:44:53,115 iteration 3832 : loss : 0.021589, loss_ce: 0.005243
2022-01-14 12:44:54,112 iteration 3833 : loss : 0.021338, loss_ce: 0.010677
2022-01-14 12:44:55,148 iteration 3834 : loss : 0.029916, loss_ce: 0.013719
2022-01-14 12:44:56,164 iteration 3835 : loss : 0.034311, loss_ce: 0.012663
2022-01-14 12:44:57,165 iteration 3836 : loss : 0.023219, loss_ce: 0.009593
2022-01-14 12:44:58,185 iteration 3837 : loss : 0.029160, loss_ce: 0.009353
2022-01-14 12:44:59,267 iteration 3838 : loss : 0.023695, loss_ce: 0.008282
2022-01-14 12:45:00,258 iteration 3839 : loss : 0.022393, loss_ce: 0.009842
2022-01-14 12:45:01,269 iteration 3840 : loss : 0.033066, loss_ce: 0.008793
2022-01-14 12:45:02,237 iteration 3841 : loss : 0.020459, loss_ce: 0.007424
2022-01-14 12:45:03,267 iteration 3842 : loss : 0.032281, loss_ce: 0.015232
 56%|████████████████▍            | 226/400 [1:09:37<54:11, 18.69s/it]2022-01-14 12:45:04,307 iteration 3843 : loss : 0.021484, loss_ce: 0.008276
2022-01-14 12:45:05,344 iteration 3844 : loss : 0.028155, loss_ce: 0.007671
2022-01-14 12:45:06,367 iteration 3845 : loss : 0.020135, loss_ce: 0.009186
2022-01-14 12:45:07,324 iteration 3846 : loss : 0.018547, loss_ce: 0.006737
2022-01-14 12:45:08,301 iteration 3847 : loss : 0.045609, loss_ce: 0.016355
2022-01-14 12:45:09,349 iteration 3848 : loss : 0.021089, loss_ce: 0.009868
2022-01-14 12:45:10,454 iteration 3849 : loss : 0.025704, loss_ce: 0.011474
2022-01-14 12:45:11,532 iteration 3850 : loss : 0.050482, loss_ce: 0.011635
2022-01-14 12:45:12,541 iteration 3851 : loss : 0.018097, loss_ce: 0.007817
2022-01-14 12:45:13,563 iteration 3852 : loss : 0.036084, loss_ce: 0.010606
2022-01-14 12:45:14,526 iteration 3853 : loss : 0.022850, loss_ce: 0.006142
2022-01-14 12:45:15,561 iteration 3854 : loss : 0.032633, loss_ce: 0.010946
2022-01-14 12:45:16,700 iteration 3855 : loss : 0.023040, loss_ce: 0.008449
2022-01-14 12:45:17,583 iteration 3856 : loss : 0.021230, loss_ce: 0.009719
2022-01-14 12:45:18,568 iteration 3857 : loss : 0.036548, loss_ce: 0.016751
2022-01-14 12:45:19,477 iteration 3858 : loss : 0.026329, loss_ce: 0.009985
2022-01-14 12:45:20,465 iteration 3859 : loss : 0.020306, loss_ce: 0.008883
 57%|████████████████▍            | 227/400 [1:09:54<52:35, 18.24s/it]2022-01-14 12:45:21,513 iteration 3860 : loss : 0.029230, loss_ce: 0.010185
2022-01-14 12:45:22,580 iteration 3861 : loss : 0.046412, loss_ce: 0.020785
2022-01-14 12:45:23,605 iteration 3862 : loss : 0.033191, loss_ce: 0.012489
2022-01-14 12:45:24,625 iteration 3863 : loss : 0.030476, loss_ce: 0.011754
2022-01-14 12:45:25,669 iteration 3864 : loss : 0.027207, loss_ce: 0.010587
2022-01-14 12:45:26,668 iteration 3865 : loss : 0.023970, loss_ce: 0.008283
2022-01-14 12:45:27,776 iteration 3866 : loss : 0.029291, loss_ce: 0.009081
2022-01-14 12:45:28,765 iteration 3867 : loss : 0.030248, loss_ce: 0.011165
2022-01-14 12:45:29,819 iteration 3868 : loss : 0.032591, loss_ce: 0.010648
2022-01-14 12:45:30,858 iteration 3869 : loss : 0.027789, loss_ce: 0.014316
2022-01-14 12:45:31,929 iteration 3870 : loss : 0.021506, loss_ce: 0.007483
2022-01-14 12:45:32,965 iteration 3871 : loss : 0.056269, loss_ce: 0.023447
2022-01-14 12:45:33,933 iteration 3872 : loss : 0.023487, loss_ce: 0.010009
2022-01-14 12:45:34,896 iteration 3873 : loss : 0.023677, loss_ce: 0.011851
2022-01-14 12:45:35,918 iteration 3874 : loss : 0.026223, loss_ce: 0.010978
2022-01-14 12:45:36,934 iteration 3875 : loss : 0.029784, loss_ce: 0.011323
2022-01-14 12:45:37,954 iteration 3876 : loss : 0.027869, loss_ce: 0.008708
 57%|████████████████▌            | 228/400 [1:10:11<51:38, 18.02s/it]2022-01-14 12:45:38,989 iteration 3877 : loss : 0.025394, loss_ce: 0.009813
2022-01-14 12:45:40,024 iteration 3878 : loss : 0.021693, loss_ce: 0.007912
2022-01-14 12:45:40,996 iteration 3879 : loss : 0.021665, loss_ce: 0.008755
2022-01-14 12:45:42,029 iteration 3880 : loss : 0.029724, loss_ce: 0.011404
2022-01-14 12:45:43,001 iteration 3881 : loss : 0.027805, loss_ce: 0.011771
2022-01-14 12:45:44,085 iteration 3882 : loss : 0.064450, loss_ce: 0.021098
2022-01-14 12:45:45,146 iteration 3883 : loss : 0.033142, loss_ce: 0.011650
2022-01-14 12:45:46,178 iteration 3884 : loss : 0.021924, loss_ce: 0.008408
2022-01-14 12:45:47,227 iteration 3885 : loss : 0.064388, loss_ce: 0.015764
2022-01-14 12:45:48,275 iteration 3886 : loss : 0.041853, loss_ce: 0.015425
2022-01-14 12:45:49,229 iteration 3887 : loss : 0.022965, loss_ce: 0.008114
2022-01-14 12:45:50,269 iteration 3888 : loss : 0.042075, loss_ce: 0.019856
2022-01-14 12:45:51,286 iteration 3889 : loss : 0.022028, loss_ce: 0.009271
2022-01-14 12:45:52,403 iteration 3890 : loss : 0.028391, loss_ce: 0.010385
2022-01-14 12:45:53,386 iteration 3891 : loss : 0.034725, loss_ce: 0.013651
2022-01-14 12:45:54,403 iteration 3892 : loss : 0.029403, loss_ce: 0.014264
2022-01-14 12:45:55,444 iteration 3893 : loss : 0.036106, loss_ce: 0.012909
 57%|████████████████▌            | 229/400 [1:10:29<50:53, 17.86s/it]2022-01-14 12:45:56,492 iteration 3894 : loss : 0.020992, loss_ce: 0.005980
2022-01-14 12:45:57,453 iteration 3895 : loss : 0.028566, loss_ce: 0.010901
2022-01-14 12:45:58,457 iteration 3896 : loss : 0.033871, loss_ce: 0.015075
2022-01-14 12:45:59,501 iteration 3897 : loss : 0.032276, loss_ce: 0.014737
2022-01-14 12:46:00,541 iteration 3898 : loss : 0.038945, loss_ce: 0.013202
2022-01-14 12:46:01,478 iteration 3899 : loss : 0.026932, loss_ce: 0.010165
2022-01-14 12:46:02,446 iteration 3900 : loss : 0.028303, loss_ce: 0.011562
2022-01-14 12:46:03,397 iteration 3901 : loss : 0.026613, loss_ce: 0.010781
2022-01-14 12:46:04,356 iteration 3902 : loss : 0.024948, loss_ce: 0.009512
2022-01-14 12:46:05,280 iteration 3903 : loss : 0.024198, loss_ce: 0.007662
2022-01-14 12:46:06,259 iteration 3904 : loss : 0.029289, loss_ce: 0.008792
2022-01-14 12:46:07,241 iteration 3905 : loss : 0.039005, loss_ce: 0.013520
2022-01-14 12:46:08,154 iteration 3906 : loss : 0.019397, loss_ce: 0.008140
2022-01-14 12:46:09,052 iteration 3907 : loss : 0.020302, loss_ce: 0.007436
2022-01-14 12:46:09,975 iteration 3908 : loss : 0.025360, loss_ce: 0.009853
2022-01-14 12:46:10,959 iteration 3909 : loss : 0.027248, loss_ce: 0.014442
2022-01-14 12:46:10,959 Training Data Eval:
2022-01-14 12:46:15,785   Average segmentation loss on training set: 0.0159
2022-01-14 12:46:15,786 Validation Data Eval:
2022-01-14 12:46:17,402   Average segmentation loss on validation set: 0.0716
2022-01-14 12:46:18,462 iteration 3910 : loss : 0.023926, loss_ce: 0.007946
 57%|████████████████▋            | 230/400 [1:10:52<54:59, 19.41s/it]2022-01-14 12:46:19,476 iteration 3911 : loss : 0.022197, loss_ce: 0.010395
2022-01-14 12:46:20,504 iteration 3912 : loss : 0.025621, loss_ce: 0.009217
2022-01-14 12:46:21,491 iteration 3913 : loss : 0.029476, loss_ce: 0.011043
2022-01-14 12:46:22,471 iteration 3914 : loss : 0.020809, loss_ce: 0.009202
2022-01-14 12:46:23,452 iteration 3915 : loss : 0.029083, loss_ce: 0.013057
2022-01-14 12:46:24,401 iteration 3916 : loss : 0.019921, loss_ce: 0.007195
2022-01-14 12:46:25,423 iteration 3917 : loss : 0.027447, loss_ce: 0.011107
2022-01-14 12:46:26,444 iteration 3918 : loss : 0.057094, loss_ce: 0.014143
2022-01-14 12:46:27,570 iteration 3919 : loss : 0.038147, loss_ce: 0.011783
2022-01-14 12:46:28,530 iteration 3920 : loss : 0.024690, loss_ce: 0.010661
2022-01-14 12:46:29,518 iteration 3921 : loss : 0.020437, loss_ce: 0.008120
2022-01-14 12:46:30,548 iteration 3922 : loss : 0.023602, loss_ce: 0.008212
2022-01-14 12:46:31,522 iteration 3923 : loss : 0.019108, loss_ce: 0.009233
2022-01-14 12:46:32,467 iteration 3924 : loss : 0.026850, loss_ce: 0.006562
2022-01-14 12:46:33,531 iteration 3925 : loss : 0.043409, loss_ce: 0.016043
2022-01-14 12:46:34,572 iteration 3926 : loss : 0.029413, loss_ce: 0.009967
2022-01-14 12:46:35,562 iteration 3927 : loss : 0.025981, loss_ce: 0.009763
 58%|████████████████▋            | 231/400 [1:11:09<52:42, 18.71s/it]2022-01-14 12:46:36,665 iteration 3928 : loss : 0.040809, loss_ce: 0.021902
2022-01-14 12:46:37,671 iteration 3929 : loss : 0.020681, loss_ce: 0.009962
2022-01-14 12:46:38,723 iteration 3930 : loss : 0.021926, loss_ce: 0.008413
2022-01-14 12:46:39,764 iteration 3931 : loss : 0.025197, loss_ce: 0.011302
2022-01-14 12:46:40,801 iteration 3932 : loss : 0.035392, loss_ce: 0.011222
2022-01-14 12:46:41,885 iteration 3933 : loss : 0.023254, loss_ce: 0.009515
2022-01-14 12:46:42,921 iteration 3934 : loss : 0.021875, loss_ce: 0.009263
2022-01-14 12:46:43,849 iteration 3935 : loss : 0.018462, loss_ce: 0.007530
2022-01-14 12:46:44,974 iteration 3936 : loss : 0.024737, loss_ce: 0.009821
2022-01-14 12:46:45,934 iteration 3937 : loss : 0.027121, loss_ce: 0.012337
2022-01-14 12:46:46,984 iteration 3938 : loss : 0.098262, loss_ce: 0.016782
2022-01-14 12:46:47,911 iteration 3939 : loss : 0.033156, loss_ce: 0.009412
2022-01-14 12:46:48,881 iteration 3940 : loss : 0.026974, loss_ce: 0.009544
2022-01-14 12:46:49,876 iteration 3941 : loss : 0.024622, loss_ce: 0.009903
2022-01-14 12:46:50,931 iteration 3942 : loss : 0.029153, loss_ce: 0.011470
2022-01-14 12:46:51,894 iteration 3943 : loss : 0.060148, loss_ce: 0.010357
2022-01-14 12:46:52,949 iteration 3944 : loss : 0.039705, loss_ce: 0.013636
 58%|████████████████▊            | 232/400 [1:11:26<51:17, 18.32s/it]2022-01-14 12:46:54,025 iteration 3945 : loss : 0.034275, loss_ce: 0.014927
2022-01-14 12:46:54,933 iteration 3946 : loss : 0.023383, loss_ce: 0.011578
2022-01-14 12:46:55,915 iteration 3947 : loss : 0.021577, loss_ce: 0.006963
2022-01-14 12:46:57,046 iteration 3948 : loss : 0.027788, loss_ce: 0.008419
2022-01-14 12:46:58,092 iteration 3949 : loss : 0.044516, loss_ce: 0.013924
2022-01-14 12:46:59,158 iteration 3950 : loss : 0.024489, loss_ce: 0.007274
2022-01-14 12:47:00,099 iteration 3951 : loss : 0.022000, loss_ce: 0.009351
2022-01-14 12:47:01,139 iteration 3952 : loss : 0.025131, loss_ce: 0.008943
2022-01-14 12:47:02,196 iteration 3953 : loss : 0.035029, loss_ce: 0.011711
2022-01-14 12:47:03,186 iteration 3954 : loss : 0.027552, loss_ce: 0.009652
2022-01-14 12:47:04,170 iteration 3955 : loss : 0.017887, loss_ce: 0.006137
2022-01-14 12:47:05,294 iteration 3956 : loss : 0.040490, loss_ce: 0.014456
2022-01-14 12:47:06,265 iteration 3957 : loss : 0.022605, loss_ce: 0.009442
2022-01-14 12:47:07,242 iteration 3958 : loss : 0.023163, loss_ce: 0.008742
2022-01-14 12:47:08,323 iteration 3959 : loss : 0.039495, loss_ce: 0.012548
2022-01-14 12:47:09,300 iteration 3960 : loss : 0.022239, loss_ce: 0.010216
2022-01-14 12:47:10,295 iteration 3961 : loss : 0.033649, loss_ce: 0.016788
 58%|████████████████▉            | 233/400 [1:11:44<50:09, 18.02s/it]2022-01-14 12:47:11,381 iteration 3962 : loss : 0.030774, loss_ce: 0.011538
2022-01-14 12:47:12,381 iteration 3963 : loss : 0.035744, loss_ce: 0.016688
2022-01-14 12:47:13,468 iteration 3964 : loss : 0.034583, loss_ce: 0.017240
2022-01-14 12:47:14,425 iteration 3965 : loss : 0.028699, loss_ce: 0.008228
2022-01-14 12:47:15,475 iteration 3966 : loss : 0.035418, loss_ce: 0.012741
2022-01-14 12:47:16,483 iteration 3967 : loss : 0.022252, loss_ce: 0.008053
2022-01-14 12:47:17,385 iteration 3968 : loss : 0.030513, loss_ce: 0.009159
2022-01-14 12:47:18,397 iteration 3969 : loss : 0.026948, loss_ce: 0.007914
2022-01-14 12:47:19,377 iteration 3970 : loss : 0.031232, loss_ce: 0.011958
2022-01-14 12:47:20,274 iteration 3971 : loss : 0.020459, loss_ce: 0.008327
2022-01-14 12:47:21,301 iteration 3972 : loss : 0.025278, loss_ce: 0.007549
2022-01-14 12:47:22,250 iteration 3973 : loss : 0.033294, loss_ce: 0.018152
2022-01-14 12:47:23,160 iteration 3974 : loss : 0.019685, loss_ce: 0.006288
2022-01-14 12:47:24,167 iteration 3975 : loss : 0.027238, loss_ce: 0.010965
2022-01-14 12:47:25,228 iteration 3976 : loss : 0.027244, loss_ce: 0.010888
2022-01-14 12:47:26,286 iteration 3977 : loss : 0.023140, loss_ce: 0.009467
2022-01-14 12:47:27,373 iteration 3978 : loss : 0.039595, loss_ce: 0.013940
 58%|████████████████▉            | 234/400 [1:12:01<49:04, 17.74s/it]2022-01-14 12:47:28,431 iteration 3979 : loss : 0.027253, loss_ce: 0.009680
2022-01-14 12:47:29,466 iteration 3980 : loss : 0.026171, loss_ce: 0.008621
2022-01-14 12:47:30,447 iteration 3981 : loss : 0.030684, loss_ce: 0.013158
2022-01-14 12:47:31,345 iteration 3982 : loss : 0.019419, loss_ce: 0.007012
2022-01-14 12:47:32,264 iteration 3983 : loss : 0.023194, loss_ce: 0.010495
2022-01-14 12:47:33,221 iteration 3984 : loss : 0.023477, loss_ce: 0.009712
2022-01-14 12:47:34,232 iteration 3985 : loss : 0.039244, loss_ce: 0.023102
2022-01-14 12:47:35,312 iteration 3986 : loss : 0.025107, loss_ce: 0.010855
2022-01-14 12:47:36,342 iteration 3987 : loss : 0.036699, loss_ce: 0.014340
2022-01-14 12:47:37,345 iteration 3988 : loss : 0.025685, loss_ce: 0.011624
2022-01-14 12:47:38,317 iteration 3989 : loss : 0.028106, loss_ce: 0.006337
2022-01-14 12:47:39,288 iteration 3990 : loss : 0.042367, loss_ce: 0.014937
2022-01-14 12:47:40,338 iteration 3991 : loss : 0.032943, loss_ce: 0.007493
2022-01-14 12:47:41,351 iteration 3992 : loss : 0.040152, loss_ce: 0.014230
2022-01-14 12:47:42,396 iteration 3993 : loss : 0.028257, loss_ce: 0.010420
2022-01-14 12:47:43,372 iteration 3994 : loss : 0.021228, loss_ce: 0.009914
2022-01-14 12:47:43,372 Training Data Eval:
2022-01-14 12:47:48,194   Average segmentation loss on training set: 0.0172
2022-01-14 12:47:48,195 Validation Data Eval:
2022-01-14 12:47:49,816   Average segmentation loss on validation set: 0.0863
2022-01-14 12:47:50,756 iteration 3995 : loss : 0.023532, loss_ce: 0.010128
 59%|█████████████████            | 235/400 [1:12:24<53:26, 19.44s/it]2022-01-14 12:47:51,879 iteration 3996 : loss : 0.023816, loss_ce: 0.007162
2022-01-14 12:47:52,823 iteration 3997 : loss : 0.039729, loss_ce: 0.011718
2022-01-14 12:47:53,845 iteration 3998 : loss : 0.052757, loss_ce: 0.029456
2022-01-14 12:47:54,826 iteration 3999 : loss : 0.023038, loss_ce: 0.005830
2022-01-14 12:47:55,873 iteration 4000 : loss : 0.024087, loss_ce: 0.012131
2022-01-14 12:47:56,804 iteration 4001 : loss : 0.023376, loss_ce: 0.008761
2022-01-14 12:47:57,801 iteration 4002 : loss : 0.022567, loss_ce: 0.009192
2022-01-14 12:47:58,806 iteration 4003 : loss : 0.024354, loss_ce: 0.010274
2022-01-14 12:47:59,836 iteration 4004 : loss : 0.038688, loss_ce: 0.012124
2022-01-14 12:48:00,835 iteration 4005 : loss : 0.031041, loss_ce: 0.015810
2022-01-14 12:48:01,779 iteration 4006 : loss : 0.027733, loss_ce: 0.012022
2022-01-14 12:48:02,827 iteration 4007 : loss : 0.032002, loss_ce: 0.009916
2022-01-14 12:48:03,788 iteration 4008 : loss : 0.022300, loss_ce: 0.008739
2022-01-14 12:48:04,783 iteration 4009 : loss : 0.023637, loss_ce: 0.009998
2022-01-14 12:48:05,842 iteration 4010 : loss : 0.050185, loss_ce: 0.022606
2022-01-14 12:48:06,787 iteration 4011 : loss : 0.026051, loss_ce: 0.007457
2022-01-14 12:48:07,854 iteration 4012 : loss : 0.029692, loss_ce: 0.011880
 59%|█████████████████            | 236/400 [1:12:41<51:12, 18.73s/it]2022-01-14 12:48:08,985 iteration 4013 : loss : 0.032687, loss_ce: 0.010325
2022-01-14 12:48:09,931 iteration 4014 : loss : 0.021014, loss_ce: 0.006491
2022-01-14 12:48:10,980 iteration 4015 : loss : 0.046384, loss_ce: 0.024594
2022-01-14 12:48:12,023 iteration 4016 : loss : 0.023455, loss_ce: 0.008815
2022-01-14 12:48:13,082 iteration 4017 : loss : 0.029357, loss_ce: 0.008906
2022-01-14 12:48:14,042 iteration 4018 : loss : 0.021662, loss_ce: 0.007813
2022-01-14 12:48:15,031 iteration 4019 : loss : 0.022989, loss_ce: 0.011109
2022-01-14 12:48:15,981 iteration 4020 : loss : 0.033933, loss_ce: 0.020297
2022-01-14 12:48:16,949 iteration 4021 : loss : 0.020776, loss_ce: 0.009191
2022-01-14 12:48:17,973 iteration 4022 : loss : 0.022900, loss_ce: 0.011758
2022-01-14 12:48:18,973 iteration 4023 : loss : 0.019549, loss_ce: 0.006760
2022-01-14 12:48:19,913 iteration 4024 : loss : 0.023401, loss_ce: 0.007916
2022-01-14 12:48:20,874 iteration 4025 : loss : 0.022531, loss_ce: 0.007976
2022-01-14 12:48:21,900 iteration 4026 : loss : 0.023017, loss_ce: 0.010656
2022-01-14 12:48:22,920 iteration 4027 : loss : 0.027802, loss_ce: 0.009967
2022-01-14 12:48:23,970 iteration 4028 : loss : 0.031384, loss_ce: 0.011488
2022-01-14 12:48:24,924 iteration 4029 : loss : 0.030603, loss_ce: 0.014059
 59%|█████████████████▏           | 237/400 [1:12:58<49:32, 18.23s/it]2022-01-14 12:48:26,047 iteration 4030 : loss : 0.034591, loss_ce: 0.017148
2022-01-14 12:48:27,070 iteration 4031 : loss : 0.031148, loss_ce: 0.011923
2022-01-14 12:48:28,064 iteration 4032 : loss : 0.033071, loss_ce: 0.014739
2022-01-14 12:48:29,058 iteration 4033 : loss : 0.030058, loss_ce: 0.009889
2022-01-14 12:48:29,991 iteration 4034 : loss : 0.030816, loss_ce: 0.009253
2022-01-14 12:48:30,962 iteration 4035 : loss : 0.018841, loss_ce: 0.006236
2022-01-14 12:48:31,988 iteration 4036 : loss : 0.036115, loss_ce: 0.012821
2022-01-14 12:48:32,934 iteration 4037 : loss : 0.020024, loss_ce: 0.009538
2022-01-14 12:48:33,989 iteration 4038 : loss : 0.027720, loss_ce: 0.009054
2022-01-14 12:48:35,077 iteration 4039 : loss : 0.023699, loss_ce: 0.008348
2022-01-14 12:48:36,167 iteration 4040 : loss : 0.045022, loss_ce: 0.025769
2022-01-14 12:48:37,228 iteration 4041 : loss : 0.032647, loss_ce: 0.009702
2022-01-14 12:48:38,193 iteration 4042 : loss : 0.022254, loss_ce: 0.007475
2022-01-14 12:48:39,203 iteration 4043 : loss : 0.178256, loss_ce: 0.007398
2022-01-14 12:48:40,167 iteration 4044 : loss : 0.026722, loss_ce: 0.010881
2022-01-14 12:48:41,153 iteration 4045 : loss : 0.021297, loss_ce: 0.009580
2022-01-14 12:48:42,202 iteration 4046 : loss : 0.023995, loss_ce: 0.010590
 60%|█████████████████▎           | 238/400 [1:13:16<48:27, 17.95s/it]2022-01-14 12:48:43,343 iteration 4047 : loss : 0.021142, loss_ce: 0.009651
2022-01-14 12:48:44,390 iteration 4048 : loss : 0.026257, loss_ce: 0.009536
2022-01-14 12:48:45,356 iteration 4049 : loss : 0.024981, loss_ce: 0.009620
2022-01-14 12:48:46,391 iteration 4050 : loss : 0.026869, loss_ce: 0.010293
2022-01-14 12:48:47,499 iteration 4051 : loss : 0.073110, loss_ce: 0.011376
2022-01-14 12:48:48,439 iteration 4052 : loss : 0.035168, loss_ce: 0.013631
2022-01-14 12:48:49,352 iteration 4053 : loss : 0.024268, loss_ce: 0.008259
2022-01-14 12:48:50,300 iteration 4054 : loss : 0.037070, loss_ce: 0.011801
2022-01-14 12:48:51,282 iteration 4055 : loss : 0.023798, loss_ce: 0.010433
2022-01-14 12:48:52,292 iteration 4056 : loss : 0.043145, loss_ce: 0.020791
2022-01-14 12:48:53,241 iteration 4057 : loss : 0.032834, loss_ce: 0.008546
2022-01-14 12:48:54,229 iteration 4058 : loss : 0.022705, loss_ce: 0.007576
2022-01-14 12:48:55,331 iteration 4059 : loss : 0.036877, loss_ce: 0.016763
2022-01-14 12:48:56,342 iteration 4060 : loss : 0.032786, loss_ce: 0.012254
2022-01-14 12:48:57,340 iteration 4061 : loss : 0.033889, loss_ce: 0.014247
2022-01-14 12:48:58,369 iteration 4062 : loss : 0.030172, loss_ce: 0.012739
2022-01-14 12:48:59,382 iteration 4063 : loss : 0.037412, loss_ce: 0.011864
 60%|█████████████████▎           | 239/400 [1:13:33<47:31, 17.71s/it]2022-01-14 12:49:00,412 iteration 4064 : loss : 0.043137, loss_ce: 0.010779
2022-01-14 12:49:01,380 iteration 4065 : loss : 0.021329, loss_ce: 0.007190
2022-01-14 12:49:02,451 iteration 4066 : loss : 0.037823, loss_ce: 0.017393
2022-01-14 12:49:03,418 iteration 4067 : loss : 0.022006, loss_ce: 0.009415
2022-01-14 12:49:04,414 iteration 4068 : loss : 0.032652, loss_ce: 0.012277
2022-01-14 12:49:05,439 iteration 4069 : loss : 0.021848, loss_ce: 0.009258
2022-01-14 12:49:06,458 iteration 4070 : loss : 0.020503, loss_ce: 0.008220
2022-01-14 12:49:07,516 iteration 4071 : loss : 0.030891, loss_ce: 0.012494
2022-01-14 12:49:08,510 iteration 4072 : loss : 0.021734, loss_ce: 0.007508
2022-01-14 12:49:09,471 iteration 4073 : loss : 0.025086, loss_ce: 0.008990
2022-01-14 12:49:10,463 iteration 4074 : loss : 0.031522, loss_ce: 0.013792
2022-01-14 12:49:11,511 iteration 4075 : loss : 0.022459, loss_ce: 0.007547
2022-01-14 12:49:12,467 iteration 4076 : loss : 0.025334, loss_ce: 0.009600
2022-01-14 12:49:13,456 iteration 4077 : loss : 0.018638, loss_ce: 0.006597
2022-01-14 12:49:14,509 iteration 4078 : loss : 0.038267, loss_ce: 0.016976
2022-01-14 12:49:15,542 iteration 4079 : loss : 0.023826, loss_ce: 0.011184
2022-01-14 12:49:15,542 Training Data Eval:
2022-01-14 12:49:20,355   Average segmentation loss on training set: 0.0169
2022-01-14 12:49:20,356 Validation Data Eval:
2022-01-14 12:49:21,969   Average segmentation loss on validation set: 0.0733
2022-01-14 12:49:23,013 iteration 4080 : loss : 0.032001, loss_ce: 0.014062
 60%|█████████████████▍           | 240/400 [1:13:57<51:58, 19.49s/it]2022-01-14 12:49:24,098 iteration 4081 : loss : 0.034233, loss_ce: 0.011339
2022-01-14 12:49:25,111 iteration 4082 : loss : 0.022675, loss_ce: 0.009070
2022-01-14 12:49:26,059 iteration 4083 : loss : 0.019585, loss_ce: 0.008357
2022-01-14 12:49:27,054 iteration 4084 : loss : 0.021614, loss_ce: 0.006361
2022-01-14 12:49:28,003 iteration 4085 : loss : 0.032360, loss_ce: 0.009738
2022-01-14 12:49:29,116 iteration 4086 : loss : 0.033494, loss_ce: 0.011292
2022-01-14 12:49:30,134 iteration 4087 : loss : 0.055472, loss_ce: 0.008248
2022-01-14 12:49:31,069 iteration 4088 : loss : 0.021990, loss_ce: 0.010252
2022-01-14 12:49:32,060 iteration 4089 : loss : 0.036109, loss_ce: 0.011176
2022-01-14 12:49:32,965 iteration 4090 : loss : 0.022708, loss_ce: 0.007386
2022-01-14 12:49:33,949 iteration 4091 : loss : 0.031888, loss_ce: 0.010616
2022-01-14 12:49:34,953 iteration 4092 : loss : 0.042095, loss_ce: 0.014420
2022-01-14 12:49:35,966 iteration 4093 : loss : 0.055204, loss_ce: 0.022859
2022-01-14 12:49:36,933 iteration 4094 : loss : 0.023589, loss_ce: 0.008943
2022-01-14 12:49:37,946 iteration 4095 : loss : 0.049794, loss_ce: 0.022929
2022-01-14 12:49:38,910 iteration 4096 : loss : 0.021951, loss_ce: 0.012364
2022-01-14 12:49:39,885 iteration 4097 : loss : 0.025062, loss_ce: 0.009667
 60%|█████████████████▍           | 241/400 [1:14:13<49:34, 18.71s/it]2022-01-14 12:49:40,916 iteration 4098 : loss : 0.027200, loss_ce: 0.010844
2022-01-14 12:49:41,877 iteration 4099 : loss : 0.029955, loss_ce: 0.008018
2022-01-14 12:49:42,876 iteration 4100 : loss : 0.028647, loss_ce: 0.011242
2022-01-14 12:49:43,915 iteration 4101 : loss : 0.031245, loss_ce: 0.010232
2022-01-14 12:49:44,958 iteration 4102 : loss : 0.029540, loss_ce: 0.012680
2022-01-14 12:49:45,984 iteration 4103 : loss : 0.036440, loss_ce: 0.016041
2022-01-14 12:49:46,994 iteration 4104 : loss : 0.030229, loss_ce: 0.013736
2022-01-14 12:49:48,008 iteration 4105 : loss : 0.029629, loss_ce: 0.015863
2022-01-14 12:49:48,989 iteration 4106 : loss : 0.026461, loss_ce: 0.010888
2022-01-14 12:49:49,967 iteration 4107 : loss : 0.020667, loss_ce: 0.007841
2022-01-14 12:49:50,960 iteration 4108 : loss : 0.022415, loss_ce: 0.009420
2022-01-14 12:49:51,899 iteration 4109 : loss : 0.022165, loss_ce: 0.007386
2022-01-14 12:49:52,926 iteration 4110 : loss : 0.031702, loss_ce: 0.012829
2022-01-14 12:49:54,071 iteration 4111 : loss : 0.033038, loss_ce: 0.015971
2022-01-14 12:49:55,037 iteration 4112 : loss : 0.022613, loss_ce: 0.008728
2022-01-14 12:49:56,081 iteration 4113 : loss : 0.035992, loss_ce: 0.010874
2022-01-14 12:49:57,077 iteration 4114 : loss : 0.026565, loss_ce: 0.013397
 60%|█████████████████▌           | 242/400 [1:14:31<48:03, 18.25s/it]2022-01-14 12:49:58,093 iteration 4115 : loss : 0.027282, loss_ce: 0.011582
2022-01-14 12:49:59,147 iteration 4116 : loss : 0.028040, loss_ce: 0.008924
2022-01-14 12:50:00,090 iteration 4117 : loss : 0.018589, loss_ce: 0.006764
2022-01-14 12:50:01,143 iteration 4118 : loss : 0.034776, loss_ce: 0.014851
2022-01-14 12:50:02,253 iteration 4119 : loss : 0.045149, loss_ce: 0.011577
2022-01-14 12:50:03,278 iteration 4120 : loss : 0.025802, loss_ce: 0.006590
2022-01-14 12:50:04,243 iteration 4121 : loss : 0.025738, loss_ce: 0.008505
2022-01-14 12:50:05,235 iteration 4122 : loss : 0.026956, loss_ce: 0.007897
2022-01-14 12:50:06,178 iteration 4123 : loss : 0.015157, loss_ce: 0.006142
2022-01-14 12:50:07,212 iteration 4124 : loss : 0.027809, loss_ce: 0.014500
2022-01-14 12:50:08,235 iteration 4125 : loss : 0.036339, loss_ce: 0.021839
2022-01-14 12:50:09,254 iteration 4126 : loss : 0.026331, loss_ce: 0.009887
2022-01-14 12:50:10,212 iteration 4127 : loss : 0.016855, loss_ce: 0.008009
2022-01-14 12:50:11,317 iteration 4128 : loss : 0.049988, loss_ce: 0.015720
2022-01-14 12:50:12,257 iteration 4129 : loss : 0.029430, loss_ce: 0.006576
2022-01-14 12:50:13,184 iteration 4130 : loss : 0.021684, loss_ce: 0.006486
2022-01-14 12:50:14,157 iteration 4131 : loss : 0.018994, loss_ce: 0.007832
 61%|█████████████████▌           | 243/400 [1:14:48<46:50, 17.90s/it]2022-01-14 12:50:15,257 iteration 4132 : loss : 0.031291, loss_ce: 0.008830
2022-01-14 12:50:16,268 iteration 4133 : loss : 0.023265, loss_ce: 0.006986
2022-01-14 12:50:17,307 iteration 4134 : loss : 0.033764, loss_ce: 0.014057
2022-01-14 12:50:18,235 iteration 4135 : loss : 0.024679, loss_ce: 0.011366
2022-01-14 12:50:19,223 iteration 4136 : loss : 0.030454, loss_ce: 0.014528
2022-01-14 12:50:20,149 iteration 4137 : loss : 0.022003, loss_ce: 0.007502
2022-01-14 12:50:21,170 iteration 4138 : loss : 0.019538, loss_ce: 0.007881
2022-01-14 12:50:22,194 iteration 4139 : loss : 0.025692, loss_ce: 0.012554
2022-01-14 12:50:23,210 iteration 4140 : loss : 0.017115, loss_ce: 0.007455
2022-01-14 12:50:24,226 iteration 4141 : loss : 0.025163, loss_ce: 0.008743
2022-01-14 12:50:25,291 iteration 4142 : loss : 0.032745, loss_ce: 0.010876
2022-01-14 12:50:26,201 iteration 4143 : loss : 0.032854, loss_ce: 0.009708
2022-01-14 12:50:27,131 iteration 4144 : loss : 0.021118, loss_ce: 0.004751
2022-01-14 12:50:28,175 iteration 4145 : loss : 0.023659, loss_ce: 0.010665
2022-01-14 12:50:29,145 iteration 4146 : loss : 0.017394, loss_ce: 0.007006
2022-01-14 12:50:30,158 iteration 4147 : loss : 0.022980, loss_ce: 0.009500
2022-01-14 12:50:31,154 iteration 4148 : loss : 0.045490, loss_ce: 0.021473
 61%|█████████████████▋           | 244/400 [1:15:05<45:50, 17.63s/it]2022-01-14 12:50:32,127 iteration 4149 : loss : 0.022831, loss_ce: 0.008311
2022-01-14 12:50:33,134 iteration 4150 : loss : 0.023824, loss_ce: 0.007976
2022-01-14 12:50:34,177 iteration 4151 : loss : 0.025562, loss_ce: 0.009267
2022-01-14 12:50:35,182 iteration 4152 : loss : 0.020916, loss_ce: 0.007834
2022-01-14 12:50:36,107 iteration 4153 : loss : 0.016357, loss_ce: 0.006045
2022-01-14 12:50:37,118 iteration 4154 : loss : 0.019258, loss_ce: 0.006795
2022-01-14 12:50:38,101 iteration 4155 : loss : 0.020953, loss_ce: 0.006574
2022-01-14 12:50:39,038 iteration 4156 : loss : 0.018525, loss_ce: 0.006725
2022-01-14 12:50:40,084 iteration 4157 : loss : 0.034708, loss_ce: 0.020398
2022-01-14 12:50:41,045 iteration 4158 : loss : 0.019994, loss_ce: 0.007258
2022-01-14 12:50:42,017 iteration 4159 : loss : 0.018139, loss_ce: 0.008089
2022-01-14 12:50:43,116 iteration 4160 : loss : 0.042042, loss_ce: 0.017369
2022-01-14 12:50:44,193 iteration 4161 : loss : 0.029334, loss_ce: 0.008922
2022-01-14 12:50:45,274 iteration 4162 : loss : 0.034954, loss_ce: 0.011540
2022-01-14 12:50:46,334 iteration 4163 : loss : 0.036162, loss_ce: 0.019217
2022-01-14 12:50:47,345 iteration 4164 : loss : 0.022904, loss_ce: 0.008524
2022-01-14 12:50:47,346 Training Data Eval:
2022-01-14 12:50:52,172   Average segmentation loss on training set: 0.0189
2022-01-14 12:50:52,172 Validation Data Eval:
2022-01-14 12:50:53,788   Average segmentation loss on validation set: 0.0740
2022-01-14 12:50:54,811 iteration 4165 : loss : 0.043114, loss_ce: 0.012926
 61%|█████████████████▊           | 245/400 [1:15:28<50:12, 19.44s/it]2022-01-14 12:50:55,852 iteration 4166 : loss : 0.021892, loss_ce: 0.008740
2022-01-14 12:50:56,774 iteration 4167 : loss : 0.025408, loss_ce: 0.008827
2022-01-14 12:50:57,722 iteration 4168 : loss : 0.016416, loss_ce: 0.006557
2022-01-14 12:50:58,670 iteration 4169 : loss : 0.018711, loss_ce: 0.009019
2022-01-14 12:50:59,769 iteration 4170 : loss : 0.031949, loss_ce: 0.014203
2022-01-14 12:51:00,703 iteration 4171 : loss : 0.019377, loss_ce: 0.005980
2022-01-14 12:51:01,689 iteration 4172 : loss : 0.020549, loss_ce: 0.009313
2022-01-14 12:51:02,716 iteration 4173 : loss : 0.019739, loss_ce: 0.005412
2022-01-14 12:51:03,687 iteration 4174 : loss : 0.027779, loss_ce: 0.008697
2022-01-14 12:51:04,630 iteration 4175 : loss : 0.021509, loss_ce: 0.008231
2022-01-14 12:51:05,603 iteration 4176 : loss : 0.020924, loss_ce: 0.008584
2022-01-14 12:51:06,635 iteration 4177 : loss : 0.022303, loss_ce: 0.006479
2022-01-14 12:51:07,584 iteration 4178 : loss : 0.022860, loss_ce: 0.008709
2022-01-14 12:51:08,552 iteration 4179 : loss : 0.024392, loss_ce: 0.011446
2022-01-14 12:51:09,516 iteration 4180 : loss : 0.018419, loss_ce: 0.005671
2022-01-14 12:51:10,494 iteration 4181 : loss : 0.023118, loss_ce: 0.009531
2022-01-14 12:51:11,484 iteration 4182 : loss : 0.021183, loss_ce: 0.005209
 62%|█████████████████▊           | 246/400 [1:15:45<47:45, 18.61s/it]2022-01-14 12:51:12,549 iteration 4183 : loss : 0.021646, loss_ce: 0.007141
2022-01-14 12:51:13,576 iteration 4184 : loss : 0.019053, loss_ce: 0.008790
2022-01-14 12:51:14,570 iteration 4185 : loss : 0.023022, loss_ce: 0.009880
2022-01-14 12:51:15,548 iteration 4186 : loss : 0.018827, loss_ce: 0.005609
2022-01-14 12:51:16,586 iteration 4187 : loss : 0.038762, loss_ce: 0.013262
2022-01-14 12:51:17,546 iteration 4188 : loss : 0.030086, loss_ce: 0.008809
2022-01-14 12:51:18,643 iteration 4189 : loss : 0.024031, loss_ce: 0.009733
2022-01-14 12:51:19,695 iteration 4190 : loss : 0.037606, loss_ce: 0.016823
2022-01-14 12:51:20,757 iteration 4191 : loss : 0.031400, loss_ce: 0.012992
2022-01-14 12:51:21,663 iteration 4192 : loss : 0.019790, loss_ce: 0.006223
2022-01-14 12:51:22,674 iteration 4193 : loss : 0.030447, loss_ce: 0.013845
2022-01-14 12:51:23,714 iteration 4194 : loss : 0.020649, loss_ce: 0.007274
2022-01-14 12:51:24,701 iteration 4195 : loss : 0.024306, loss_ce: 0.006947
2022-01-14 12:51:25,735 iteration 4196 : loss : 0.019059, loss_ce: 0.007812
2022-01-14 12:51:26,715 iteration 4197 : loss : 0.023404, loss_ce: 0.006876
2022-01-14 12:51:27,699 iteration 4198 : loss : 0.019507, loss_ce: 0.007468
2022-01-14 12:51:28,635 iteration 4199 : loss : 0.021827, loss_ce: 0.008374
 62%|█████████████████▉           | 247/400 [1:16:02<46:20, 18.17s/it]2022-01-14 12:51:29,686 iteration 4200 : loss : 0.020933, loss_ce: 0.007488
2022-01-14 12:51:30,714 iteration 4201 : loss : 0.039844, loss_ce: 0.020965
2022-01-14 12:51:31,734 iteration 4202 : loss : 0.023702, loss_ce: 0.009346
2022-01-14 12:51:32,828 iteration 4203 : loss : 0.022520, loss_ce: 0.010200
2022-01-14 12:51:33,810 iteration 4204 : loss : 0.020959, loss_ce: 0.008545
2022-01-14 12:51:34,796 iteration 4205 : loss : 0.020344, loss_ce: 0.007961
2022-01-14 12:51:35,913 iteration 4206 : loss : 0.036449, loss_ce: 0.011656
2022-01-14 12:51:36,962 iteration 4207 : loss : 0.029083, loss_ce: 0.010841
2022-01-14 12:51:37,876 iteration 4208 : loss : 0.016455, loss_ce: 0.006074
2022-01-14 12:51:38,841 iteration 4209 : loss : 0.022895, loss_ce: 0.010509
2022-01-14 12:51:39,810 iteration 4210 : loss : 0.022716, loss_ce: 0.009845
2022-01-14 12:51:40,826 iteration 4211 : loss : 0.028030, loss_ce: 0.012006
2022-01-14 12:51:41,870 iteration 4212 : loss : 0.022394, loss_ce: 0.008279
2022-01-14 12:51:42,835 iteration 4213 : loss : 0.026597, loss_ce: 0.007389
2022-01-14 12:51:43,869 iteration 4214 : loss : 0.029328, loss_ce: 0.010356
2022-01-14 12:51:44,857 iteration 4215 : loss : 0.028126, loss_ce: 0.011545
2022-01-14 12:51:45,843 iteration 4216 : loss : 0.022184, loss_ce: 0.007571
 62%|█████████████████▉           | 248/400 [1:16:19<45:18, 17.88s/it]2022-01-14 12:51:46,947 iteration 4217 : loss : 0.024979, loss_ce: 0.008559
2022-01-14 12:51:47,926 iteration 4218 : loss : 0.021668, loss_ce: 0.007825
2022-01-14 12:51:48,888 iteration 4219 : loss : 0.024032, loss_ce: 0.008328
2022-01-14 12:51:49,792 iteration 4220 : loss : 0.025039, loss_ce: 0.005892
2022-01-14 12:51:50,871 iteration 4221 : loss : 0.021856, loss_ce: 0.009474
2022-01-14 12:51:51,953 iteration 4222 : loss : 0.045073, loss_ce: 0.015828
2022-01-14 12:51:52,925 iteration 4223 : loss : 0.020306, loss_ce: 0.007807
2022-01-14 12:51:53,984 iteration 4224 : loss : 0.031884, loss_ce: 0.007387
2022-01-14 12:51:55,010 iteration 4225 : loss : 0.023126, loss_ce: 0.006121
2022-01-14 12:51:56,064 iteration 4226 : loss : 0.023057, loss_ce: 0.010225
2022-01-14 12:51:57,086 iteration 4227 : loss : 0.021123, loss_ce: 0.008156
2022-01-14 12:51:58,039 iteration 4228 : loss : 0.023920, loss_ce: 0.013168
2022-01-14 12:51:59,027 iteration 4229 : loss : 0.024702, loss_ce: 0.010747
2022-01-14 12:52:00,008 iteration 4230 : loss : 0.039786, loss_ce: 0.022772
2022-01-14 12:52:01,048 iteration 4231 : loss : 0.022152, loss_ce: 0.008536
2022-01-14 12:52:02,088 iteration 4232 : loss : 0.022252, loss_ce: 0.006663
2022-01-14 12:52:03,084 iteration 4233 : loss : 0.028515, loss_ce: 0.013843
 62%|██████████████████           | 249/400 [1:16:37<44:31, 17.69s/it]2022-01-14 12:52:04,062 iteration 4234 : loss : 0.025600, loss_ce: 0.005968
2022-01-14 12:52:04,996 iteration 4235 : loss : 0.014311, loss_ce: 0.005496
2022-01-14 12:52:06,013 iteration 4236 : loss : 0.020381, loss_ce: 0.008609
2022-01-14 12:52:06,965 iteration 4237 : loss : 0.027296, loss_ce: 0.012275
2022-01-14 12:52:07,950 iteration 4238 : loss : 0.027193, loss_ce: 0.013291
2022-01-14 12:52:09,073 iteration 4239 : loss : 0.030102, loss_ce: 0.013125
2022-01-14 12:52:10,083 iteration 4240 : loss : 0.023030, loss_ce: 0.007455
2022-01-14 12:52:10,996 iteration 4241 : loss : 0.020027, loss_ce: 0.008991
2022-01-14 12:52:11,997 iteration 4242 : loss : 0.033774, loss_ce: 0.010840
2022-01-14 12:52:12,972 iteration 4243 : loss : 0.022690, loss_ce: 0.008735
2022-01-14 12:52:13,892 iteration 4244 : loss : 0.016899, loss_ce: 0.007855
2022-01-14 12:52:14,937 iteration 4245 : loss : 0.024976, loss_ce: 0.010469
2022-01-14 12:52:16,014 iteration 4246 : loss : 0.024642, loss_ce: 0.007297
2022-01-14 12:52:17,041 iteration 4247 : loss : 0.024999, loss_ce: 0.011907
2022-01-14 12:52:17,983 iteration 4248 : loss : 0.030186, loss_ce: 0.013101
2022-01-14 12:52:19,037 iteration 4249 : loss : 0.035770, loss_ce: 0.013587
2022-01-14 12:52:19,037 Training Data Eval:
2022-01-14 12:52:23,849   Average segmentation loss on training set: 0.0155
2022-01-14 12:52:23,849 Validation Data Eval:
2022-01-14 12:52:25,461   Average segmentation loss on validation set: 0.0859
2022-01-14 12:52:26,447 iteration 4250 : loss : 0.025546, loss_ce: 0.008972
 62%|██████████████████▏          | 250/400 [1:17:00<48:28, 19.39s/it]2022-01-14 12:52:27,563 iteration 4251 : loss : 0.036311, loss_ce: 0.010190
2022-01-14 12:52:28,606 iteration 4252 : loss : 0.022254, loss_ce: 0.009995
2022-01-14 12:52:29,635 iteration 4253 : loss : 0.041428, loss_ce: 0.013443
2022-01-14 12:52:30,673 iteration 4254 : loss : 0.020041, loss_ce: 0.007729
2022-01-14 12:52:31,719 iteration 4255 : loss : 0.027880, loss_ce: 0.009939
2022-01-14 12:52:32,627 iteration 4256 : loss : 0.021484, loss_ce: 0.009620
2022-01-14 12:52:33,617 iteration 4257 : loss : 0.026711, loss_ce: 0.009982
2022-01-14 12:52:34,541 iteration 4258 : loss : 0.021235, loss_ce: 0.007332
2022-01-14 12:52:35,556 iteration 4259 : loss : 0.025836, loss_ce: 0.010590
2022-01-14 12:52:36,577 iteration 4260 : loss : 0.024932, loss_ce: 0.007890
2022-01-14 12:52:37,602 iteration 4261 : loss : 0.024219, loss_ce: 0.010070
2022-01-14 12:52:38,564 iteration 4262 : loss : 0.018594, loss_ce: 0.007648
2022-01-14 12:52:39,587 iteration 4263 : loss : 0.024218, loss_ce: 0.009565
2022-01-14 12:52:40,645 iteration 4264 : loss : 0.027347, loss_ce: 0.012018
2022-01-14 12:52:41,635 iteration 4265 : loss : 0.033907, loss_ce: 0.007709
2022-01-14 12:52:42,659 iteration 4266 : loss : 0.024741, loss_ce: 0.007295
2022-01-14 12:52:43,703 iteration 4267 : loss : 0.025330, loss_ce: 0.009184
 63%|██████████████████▏          | 251/400 [1:17:17<46:33, 18.75s/it]2022-01-14 12:52:44,764 iteration 4268 : loss : 0.021753, loss_ce: 0.004990
2022-01-14 12:52:45,747 iteration 4269 : loss : 0.034367, loss_ce: 0.013457
2022-01-14 12:52:46,709 iteration 4270 : loss : 0.020103, loss_ce: 0.009871
2022-01-14 12:52:47,630 iteration 4271 : loss : 0.019365, loss_ce: 0.007026
2022-01-14 12:52:48,615 iteration 4272 : loss : 0.021102, loss_ce: 0.009657
2022-01-14 12:52:49,547 iteration 4273 : loss : 0.016384, loss_ce: 0.006724
2022-01-14 12:52:50,626 iteration 4274 : loss : 0.033342, loss_ce: 0.014907
2022-01-14 12:52:51,601 iteration 4275 : loss : 0.026669, loss_ce: 0.008983
2022-01-14 12:52:52,645 iteration 4276 : loss : 0.026425, loss_ce: 0.008196
2022-01-14 12:52:53,693 iteration 4277 : loss : 0.026209, loss_ce: 0.008100
2022-01-14 12:52:54,736 iteration 4278 : loss : 0.025667, loss_ce: 0.008729
2022-01-14 12:52:55,714 iteration 4279 : loss : 0.024810, loss_ce: 0.012208
2022-01-14 12:52:56,724 iteration 4280 : loss : 0.024196, loss_ce: 0.007213
2022-01-14 12:52:57,729 iteration 4281 : loss : 0.033041, loss_ce: 0.011878
2022-01-14 12:52:58,661 iteration 4282 : loss : 0.026252, loss_ce: 0.009217
2022-01-14 12:52:59,643 iteration 4283 : loss : 0.031162, loss_ce: 0.009502
2022-01-14 12:53:00,602 iteration 4284 : loss : 0.019550, loss_ce: 0.007235
 63%|██████████████████▎          | 252/400 [1:17:34<44:52, 18.19s/it]2022-01-14 12:53:01,591 iteration 4285 : loss : 0.028248, loss_ce: 0.007600
2022-01-14 12:53:02,634 iteration 4286 : loss : 0.026330, loss_ce: 0.009824
2022-01-14 12:53:03,589 iteration 4287 : loss : 0.019850, loss_ce: 0.008613
2022-01-14 12:53:04,540 iteration 4288 : loss : 0.022318, loss_ce: 0.010832
2022-01-14 12:53:05,539 iteration 4289 : loss : 0.019415, loss_ce: 0.007525
2022-01-14 12:53:06,521 iteration 4290 : loss : 0.034747, loss_ce: 0.007607
2022-01-14 12:53:07,538 iteration 4291 : loss : 0.037105, loss_ce: 0.014208
2022-01-14 12:53:08,550 iteration 4292 : loss : 0.033213, loss_ce: 0.015517
2022-01-14 12:53:09,548 iteration 4293 : loss : 0.029707, loss_ce: 0.008748
2022-01-14 12:53:10,519 iteration 4294 : loss : 0.030224, loss_ce: 0.010126
2022-01-14 12:53:11,621 iteration 4295 : loss : 0.029648, loss_ce: 0.009952
2022-01-14 12:53:12,700 iteration 4296 : loss : 0.020029, loss_ce: 0.006386
2022-01-14 12:53:13,723 iteration 4297 : loss : 0.023730, loss_ce: 0.008988
2022-01-14 12:53:14,689 iteration 4298 : loss : 0.017867, loss_ce: 0.009012
2022-01-14 12:53:15,730 iteration 4299 : loss : 0.022836, loss_ce: 0.011008
2022-01-14 12:53:16,802 iteration 4300 : loss : 0.040481, loss_ce: 0.017254
2022-01-14 12:53:17,866 iteration 4301 : loss : 0.021803, loss_ce: 0.009103
 63%|██████████████████▎          | 253/400 [1:17:51<43:53, 17.92s/it]2022-01-14 12:53:18,971 iteration 4302 : loss : 0.029176, loss_ce: 0.013967
2022-01-14 12:53:20,028 iteration 4303 : loss : 0.039330, loss_ce: 0.008357
2022-01-14 12:53:20,991 iteration 4304 : loss : 0.019038, loss_ce: 0.007201
2022-01-14 12:53:21,964 iteration 4305 : loss : 0.028169, loss_ce: 0.011184
2022-01-14 12:53:22,942 iteration 4306 : loss : 0.017899, loss_ce: 0.004996
2022-01-14 12:53:23,879 iteration 4307 : loss : 0.015152, loss_ce: 0.006705
2022-01-14 12:53:24,906 iteration 4308 : loss : 0.026911, loss_ce: 0.008196
2022-01-14 12:53:25,974 iteration 4309 : loss : 0.025409, loss_ce: 0.009295
2022-01-14 12:53:26,984 iteration 4310 : loss : 0.020684, loss_ce: 0.008771
2022-01-14 12:53:27,997 iteration 4311 : loss : 0.027409, loss_ce: 0.009576
2022-01-14 12:53:28,941 iteration 4312 : loss : 0.024435, loss_ce: 0.009015
2022-01-14 12:53:29,899 iteration 4313 : loss : 0.018410, loss_ce: 0.008875
2022-01-14 12:53:30,859 iteration 4314 : loss : 0.025339, loss_ce: 0.008426
2022-01-14 12:53:31,883 iteration 4315 : loss : 0.026691, loss_ce: 0.009544
2022-01-14 12:53:32,867 iteration 4316 : loss : 0.032872, loss_ce: 0.009903
2022-01-14 12:53:33,917 iteration 4317 : loss : 0.029887, loss_ce: 0.011527
2022-01-14 12:53:34,863 iteration 4318 : loss : 0.017321, loss_ce: 0.006339
 64%|██████████████████▍          | 254/400 [1:18:08<42:55, 17.64s/it]2022-01-14 12:53:35,958 iteration 4319 : loss : 0.021931, loss_ce: 0.006980
2022-01-14 12:53:36,991 iteration 4320 : loss : 0.026368, loss_ce: 0.010736
2022-01-14 12:53:37,893 iteration 4321 : loss : 0.018653, loss_ce: 0.005541
2022-01-14 12:53:38,885 iteration 4322 : loss : 0.023986, loss_ce: 0.007913
2022-01-14 12:53:39,824 iteration 4323 : loss : 0.018823, loss_ce: 0.009574
2022-01-14 12:53:40,922 iteration 4324 : loss : 0.026740, loss_ce: 0.011734
2022-01-14 12:53:41,922 iteration 4325 : loss : 0.023078, loss_ce: 0.009594
2022-01-14 12:53:42,892 iteration 4326 : loss : 0.020059, loss_ce: 0.009408
2022-01-14 12:53:43,924 iteration 4327 : loss : 0.026597, loss_ce: 0.006761
2022-01-14 12:53:44,885 iteration 4328 : loss : 0.035575, loss_ce: 0.014188
2022-01-14 12:53:45,944 iteration 4329 : loss : 0.043016, loss_ce: 0.011412
2022-01-14 12:53:46,974 iteration 4330 : loss : 0.018294, loss_ce: 0.008436
2022-01-14 12:53:48,056 iteration 4331 : loss : 0.041717, loss_ce: 0.010792
2022-01-14 12:53:49,093 iteration 4332 : loss : 0.029853, loss_ce: 0.009736
2022-01-14 12:53:50,163 iteration 4333 : loss : 0.037856, loss_ce: 0.020766
2022-01-14 12:53:51,175 iteration 4334 : loss : 0.024672, loss_ce: 0.011984
2022-01-14 12:53:51,175 Training Data Eval:
2022-01-14 12:53:55,982   Average segmentation loss on training set: 0.0163
2022-01-14 12:53:55,982 Validation Data Eval:
2022-01-14 12:53:57,592   Average segmentation loss on validation set: 0.0809
2022-01-14 12:53:58,626 iteration 4335 : loss : 0.027618, loss_ce: 0.006367
 64%|██████████████████▍          | 255/400 [1:18:32<47:04, 19.48s/it]2022-01-14 12:53:59,573 iteration 4336 : loss : 0.016261, loss_ce: 0.007623
2022-01-14 12:54:00,641 iteration 4337 : loss : 0.023223, loss_ce: 0.009762
2022-01-14 12:54:01,634 iteration 4338 : loss : 0.023996, loss_ce: 0.009453
2022-01-14 12:54:02,590 iteration 4339 : loss : 0.021360, loss_ce: 0.008068
2022-01-14 12:54:03,627 iteration 4340 : loss : 0.024300, loss_ce: 0.010056
2022-01-14 12:54:04,570 iteration 4341 : loss : 0.020275, loss_ce: 0.006519
2022-01-14 12:54:05,607 iteration 4342 : loss : 0.038197, loss_ce: 0.010131
2022-01-14 12:54:06,639 iteration 4343 : loss : 0.035060, loss_ce: 0.009528
2022-01-14 12:54:07,663 iteration 4344 : loss : 0.027344, loss_ce: 0.012977
2022-01-14 12:54:08,751 iteration 4345 : loss : 0.027968, loss_ce: 0.012407
2022-01-14 12:54:09,685 iteration 4346 : loss : 0.027791, loss_ce: 0.009357
2022-01-14 12:54:10,682 iteration 4347 : loss : 0.026592, loss_ce: 0.013737
2022-01-14 12:54:11,628 iteration 4348 : loss : 0.019219, loss_ce: 0.009385
2022-01-14 12:54:12,532 iteration 4349 : loss : 0.018058, loss_ce: 0.004758
2022-01-14 12:54:13,436 iteration 4350 : loss : 0.028993, loss_ce: 0.008682
2022-01-14 12:54:14,448 iteration 4351 : loss : 0.029391, loss_ce: 0.009133
2022-01-14 12:54:15,443 iteration 4352 : loss : 0.021687, loss_ce: 0.009545
 64%|██████████████████▌          | 256/400 [1:18:49<44:49, 18.68s/it]2022-01-14 12:54:16,447 iteration 4353 : loss : 0.022312, loss_ce: 0.007293
2022-01-14 12:54:17,522 iteration 4354 : loss : 0.024547, loss_ce: 0.010812
2022-01-14 12:54:18,572 iteration 4355 : loss : 0.022224, loss_ce: 0.008253
2022-01-14 12:54:19,656 iteration 4356 : loss : 0.031523, loss_ce: 0.006774
2022-01-14 12:54:20,695 iteration 4357 : loss : 0.020686, loss_ce: 0.009260
2022-01-14 12:54:21,757 iteration 4358 : loss : 0.033933, loss_ce: 0.011865
2022-01-14 12:54:22,779 iteration 4359 : loss : 0.020773, loss_ce: 0.006499
2022-01-14 12:54:23,765 iteration 4360 : loss : 0.025070, loss_ce: 0.011084
2022-01-14 12:54:24,823 iteration 4361 : loss : 0.022634, loss_ce: 0.008587
2022-01-14 12:54:25,830 iteration 4362 : loss : 0.025757, loss_ce: 0.010965
2022-01-14 12:54:26,829 iteration 4363 : loss : 0.020997, loss_ce: 0.007850
2022-01-14 12:54:27,852 iteration 4364 : loss : 0.022535, loss_ce: 0.008510
2022-01-14 12:54:28,940 iteration 4365 : loss : 0.031982, loss_ce: 0.013974
2022-01-14 12:54:29,891 iteration 4366 : loss : 0.020123, loss_ce: 0.005712
2022-01-14 12:54:30,785 iteration 4367 : loss : 0.021483, loss_ce: 0.008813
2022-01-14 12:54:31,710 iteration 4368 : loss : 0.021433, loss_ce: 0.007053
2022-01-14 12:54:32,715 iteration 4369 : loss : 0.019274, loss_ce: 0.007252
 64%|██████████████████▋          | 257/400 [1:19:06<43:30, 18.26s/it]2022-01-14 12:54:33,774 iteration 4370 : loss : 0.029981, loss_ce: 0.010829
2022-01-14 12:54:34,789 iteration 4371 : loss : 0.027983, loss_ce: 0.013158
2022-01-14 12:54:35,816 iteration 4372 : loss : 0.020211, loss_ce: 0.008200
2022-01-14 12:54:36,846 iteration 4373 : loss : 0.021324, loss_ce: 0.010693
2022-01-14 12:54:37,879 iteration 4374 : loss : 0.020516, loss_ce: 0.007957
2022-01-14 12:54:38,941 iteration 4375 : loss : 0.027040, loss_ce: 0.013117
2022-01-14 12:54:39,916 iteration 4376 : loss : 0.020259, loss_ce: 0.007612
2022-01-14 12:54:40,889 iteration 4377 : loss : 0.025045, loss_ce: 0.007135
2022-01-14 12:54:41,820 iteration 4378 : loss : 0.016213, loss_ce: 0.005821
2022-01-14 12:54:42,759 iteration 4379 : loss : 0.019050, loss_ce: 0.006418
2022-01-14 12:54:43,672 iteration 4380 : loss : 0.018370, loss_ce: 0.006169
2022-01-14 12:54:44,698 iteration 4381 : loss : 0.029033, loss_ce: 0.010700
2022-01-14 12:54:45,694 iteration 4382 : loss : 0.033114, loss_ce: 0.006853
2022-01-14 12:54:46,663 iteration 4383 : loss : 0.021604, loss_ce: 0.006257
2022-01-14 12:54:47,714 iteration 4384 : loss : 0.040566, loss_ce: 0.015779
2022-01-14 12:54:48,762 iteration 4385 : loss : 0.032156, loss_ce: 0.010449
2022-01-14 12:54:49,720 iteration 4386 : loss : 0.026549, loss_ce: 0.014591
 64%|██████████████████▋          | 258/400 [1:19:23<42:19, 17.88s/it]2022-01-14 12:54:50,709 iteration 4387 : loss : 0.018668, loss_ce: 0.005784
2022-01-14 12:54:51,707 iteration 4388 : loss : 0.027541, loss_ce: 0.012045
2022-01-14 12:54:52,706 iteration 4389 : loss : 0.034328, loss_ce: 0.011163
2022-01-14 12:54:53,645 iteration 4390 : loss : 0.018695, loss_ce: 0.005987
2022-01-14 12:54:54,662 iteration 4391 : loss : 0.030623, loss_ce: 0.009750
2022-01-14 12:54:55,657 iteration 4392 : loss : 0.019112, loss_ce: 0.005750
2022-01-14 12:54:56,729 iteration 4393 : loss : 0.024331, loss_ce: 0.010374
2022-01-14 12:54:57,762 iteration 4394 : loss : 0.025392, loss_ce: 0.010732
2022-01-14 12:54:58,861 iteration 4395 : loss : 0.025180, loss_ce: 0.009520
2022-01-14 12:54:59,830 iteration 4396 : loss : 0.021351, loss_ce: 0.007587
2022-01-14 12:55:00,931 iteration 4397 : loss : 0.028614, loss_ce: 0.014720
2022-01-14 12:55:01,883 iteration 4398 : loss : 0.019758, loss_ce: 0.008074
2022-01-14 12:55:02,937 iteration 4399 : loss : 0.034887, loss_ce: 0.012260
2022-01-14 12:55:03,953 iteration 4400 : loss : 0.036513, loss_ce: 0.011126
2022-01-14 12:55:05,091 iteration 4401 : loss : 0.029860, loss_ce: 0.010952
2022-01-14 12:55:06,106 iteration 4402 : loss : 0.030862, loss_ce: 0.009466
2022-01-14 12:55:07,128 iteration 4403 : loss : 0.021672, loss_ce: 0.007241
 65%|██████████████████▊          | 259/400 [1:19:41<41:41, 17.74s/it]2022-01-14 12:55:08,151 iteration 4404 : loss : 0.024139, loss_ce: 0.010561
2022-01-14 12:55:09,190 iteration 4405 : loss : 0.025718, loss_ce: 0.010800
2022-01-14 12:55:10,223 iteration 4406 : loss : 0.019576, loss_ce: 0.008430
2022-01-14 12:55:11,290 iteration 4407 : loss : 0.031571, loss_ce: 0.011114
2022-01-14 12:55:12,299 iteration 4408 : loss : 0.024000, loss_ce: 0.009512
2022-01-14 12:55:13,327 iteration 4409 : loss : 0.023167, loss_ce: 0.008375
2022-01-14 12:55:14,474 iteration 4410 : loss : 0.031693, loss_ce: 0.010471
2022-01-14 12:55:15,528 iteration 4411 : loss : 0.028806, loss_ce: 0.012386
2022-01-14 12:55:16,531 iteration 4412 : loss : 0.037275, loss_ce: 0.014053
2022-01-14 12:55:17,566 iteration 4413 : loss : 0.020915, loss_ce: 0.007512
2022-01-14 12:55:18,513 iteration 4414 : loss : 0.022700, loss_ce: 0.007325
2022-01-14 12:55:19,560 iteration 4415 : loss : 0.027266, loss_ce: 0.008363
2022-01-14 12:55:20,626 iteration 4416 : loss : 0.044350, loss_ce: 0.013722
2022-01-14 12:55:21,629 iteration 4417 : loss : 0.020755, loss_ce: 0.007522
2022-01-14 12:55:22,645 iteration 4418 : loss : 0.019852, loss_ce: 0.009048
2022-01-14 12:55:23,699 iteration 4419 : loss : 0.023894, loss_ce: 0.007547
2022-01-14 12:55:23,700 Training Data Eval:
2022-01-14 12:55:28,514   Average segmentation loss on training set: 0.0149
2022-01-14 12:55:28,514 Validation Data Eval:
2022-01-14 12:55:30,127   Average segmentation loss on validation set: 0.0684
2022-01-14 12:55:31,071 iteration 4420 : loss : 0.015897, loss_ce: 0.007017
 65%|██████████████████▊          | 260/400 [1:20:05<45:44, 19.60s/it]2022-01-14 12:55:32,106 iteration 4421 : loss : 0.022210, loss_ce: 0.007685
2022-01-14 12:55:33,132 iteration 4422 : loss : 0.023872, loss_ce: 0.009623
2022-01-14 12:55:34,203 iteration 4423 : loss : 0.036761, loss_ce: 0.014806
2022-01-14 12:55:35,148 iteration 4424 : loss : 0.019504, loss_ce: 0.006202
2022-01-14 12:55:36,083 iteration 4425 : loss : 0.019760, loss_ce: 0.006981
2022-01-14 12:55:37,140 iteration 4426 : loss : 0.022084, loss_ce: 0.009522
2022-01-14 12:55:38,087 iteration 4427 : loss : 0.017332, loss_ce: 0.007162
2022-01-14 12:55:38,986 iteration 4428 : loss : 0.015967, loss_ce: 0.007470
2022-01-14 12:55:39,907 iteration 4429 : loss : 0.021306, loss_ce: 0.007308
2022-01-14 12:55:40,831 iteration 4430 : loss : 0.017618, loss_ce: 0.007383
2022-01-14 12:55:41,839 iteration 4431 : loss : 0.031449, loss_ce: 0.013057
2022-01-14 12:55:42,875 iteration 4432 : loss : 0.035791, loss_ce: 0.013360
2022-01-14 12:55:43,847 iteration 4433 : loss : 0.030571, loss_ce: 0.008048
2022-01-14 12:55:44,779 iteration 4434 : loss : 0.017043, loss_ce: 0.007366
2022-01-14 12:55:45,770 iteration 4435 : loss : 0.023714, loss_ce: 0.005486
2022-01-14 12:55:46,757 iteration 4436 : loss : 0.017664, loss_ce: 0.006779
2022-01-14 12:55:47,807 iteration 4437 : loss : 0.036259, loss_ce: 0.012777
 65%|██████████████████▉          | 261/400 [1:20:21<43:25, 18.74s/it]2022-01-14 12:55:48,929 iteration 4438 : loss : 0.027429, loss_ce: 0.007098
2022-01-14 12:55:49,958 iteration 4439 : loss : 0.019423, loss_ce: 0.006891
2022-01-14 12:55:50,967 iteration 4440 : loss : 0.019772, loss_ce: 0.007196
2022-01-14 12:55:52,076 iteration 4441 : loss : 0.020318, loss_ce: 0.006616
2022-01-14 12:55:53,137 iteration 4442 : loss : 0.022584, loss_ce: 0.011374
2022-01-14 12:55:54,164 iteration 4443 : loss : 0.021151, loss_ce: 0.007409
2022-01-14 12:55:55,100 iteration 4444 : loss : 0.029409, loss_ce: 0.009174
2022-01-14 12:55:56,089 iteration 4445 : loss : 0.044306, loss_ce: 0.018542
2022-01-14 12:55:57,122 iteration 4446 : loss : 0.023332, loss_ce: 0.009959
2022-01-14 12:55:58,104 iteration 4447 : loss : 0.022532, loss_ce: 0.007993
2022-01-14 12:55:59,128 iteration 4448 : loss : 0.042128, loss_ce: 0.014865
2022-01-14 12:56:00,132 iteration 4449 : loss : 0.030651, loss_ce: 0.012393
2022-01-14 12:56:01,191 iteration 4450 : loss : 0.047967, loss_ce: 0.013522
2022-01-14 12:56:02,158 iteration 4451 : loss : 0.021994, loss_ce: 0.008728
2022-01-14 12:56:03,171 iteration 4452 : loss : 0.021386, loss_ce: 0.009263
2022-01-14 12:56:04,143 iteration 4453 : loss : 0.026213, loss_ce: 0.009994
2022-01-14 12:56:05,112 iteration 4454 : loss : 0.023348, loss_ce: 0.009465
 66%|██████████████████▉          | 262/400 [1:20:39<42:06, 18.31s/it]2022-01-14 12:56:06,193 iteration 4455 : loss : 0.023130, loss_ce: 0.007560
2022-01-14 12:56:07,111 iteration 4456 : loss : 0.019458, loss_ce: 0.007472
2022-01-14 12:56:08,127 iteration 4457 : loss : 0.023207, loss_ce: 0.010362
2022-01-14 12:56:09,222 iteration 4458 : loss : 0.035713, loss_ce: 0.015609
2022-01-14 12:56:10,383 iteration 4459 : loss : 0.029958, loss_ce: 0.013707
2022-01-14 12:56:11,355 iteration 4460 : loss : 0.020719, loss_ce: 0.007231
2022-01-14 12:56:12,370 iteration 4461 : loss : 0.030293, loss_ce: 0.009859
2022-01-14 12:56:13,419 iteration 4462 : loss : 0.024670, loss_ce: 0.010834
2022-01-14 12:56:14,410 iteration 4463 : loss : 0.048143, loss_ce: 0.027640
2022-01-14 12:56:15,385 iteration 4464 : loss : 0.017892, loss_ce: 0.006059
2022-01-14 12:56:16,307 iteration 4465 : loss : 0.022492, loss_ce: 0.005270
2022-01-14 12:56:17,252 iteration 4466 : loss : 0.017055, loss_ce: 0.005103
2022-01-14 12:56:18,248 iteration 4467 : loss : 0.033242, loss_ce: 0.018218
2022-01-14 12:56:19,276 iteration 4468 : loss : 0.019491, loss_ce: 0.008267
2022-01-14 12:56:20,353 iteration 4469 : loss : 0.035555, loss_ce: 0.016908
2022-01-14 12:56:21,407 iteration 4470 : loss : 0.025729, loss_ce: 0.011440
2022-01-14 12:56:22,486 iteration 4471 : loss : 0.031634, loss_ce: 0.011473
 66%|███████████████████          | 263/400 [1:20:56<41:09, 18.03s/it]2022-01-14 12:56:23,509 iteration 4472 : loss : 0.016988, loss_ce: 0.008130
2022-01-14 12:56:24,464 iteration 4473 : loss : 0.034443, loss_ce: 0.013327
2022-01-14 12:56:25,467 iteration 4474 : loss : 0.022791, loss_ce: 0.010867
2022-01-14 12:56:26,457 iteration 4475 : loss : 0.022765, loss_ce: 0.007319
2022-01-14 12:56:27,418 iteration 4476 : loss : 0.028502, loss_ce: 0.009231
2022-01-14 12:56:28,392 iteration 4477 : loss : 0.023246, loss_ce: 0.010634
2022-01-14 12:56:29,507 iteration 4478 : loss : 0.027100, loss_ce: 0.013209
2022-01-14 12:56:30,509 iteration 4479 : loss : 0.028166, loss_ce: 0.007811
2022-01-14 12:56:31,526 iteration 4480 : loss : 0.021417, loss_ce: 0.007765
2022-01-14 12:56:32,480 iteration 4481 : loss : 0.018666, loss_ce: 0.007051
2022-01-14 12:56:33,421 iteration 4482 : loss : 0.018340, loss_ce: 0.005417
2022-01-14 12:56:34,384 iteration 4483 : loss : 0.027081, loss_ce: 0.008402
2022-01-14 12:56:35,383 iteration 4484 : loss : 0.019265, loss_ce: 0.006431
2022-01-14 12:56:36,310 iteration 4485 : loss : 0.022960, loss_ce: 0.010443
2022-01-14 12:56:37,361 iteration 4486 : loss : 0.017111, loss_ce: 0.006441
2022-01-14 12:56:38,392 iteration 4487 : loss : 0.028414, loss_ce: 0.013203
2022-01-14 12:56:39,345 iteration 4488 : loss : 0.017204, loss_ce: 0.006521
 66%|███████████████████▏         | 264/400 [1:21:13<40:03, 17.68s/it]2022-01-14 12:56:40,437 iteration 4489 : loss : 0.019302, loss_ce: 0.008442
2022-01-14 12:56:41,427 iteration 4490 : loss : 0.020378, loss_ce: 0.008787
2022-01-14 12:56:42,521 iteration 4491 : loss : 0.029446, loss_ce: 0.010284
2022-01-14 12:56:43,490 iteration 4492 : loss : 0.021979, loss_ce: 0.005907
2022-01-14 12:56:44,572 iteration 4493 : loss : 0.031372, loss_ce: 0.019211
2022-01-14 12:56:45,536 iteration 4494 : loss : 0.022116, loss_ce: 0.007304
2022-01-14 12:56:46,547 iteration 4495 : loss : 0.039244, loss_ce: 0.008996
2022-01-14 12:56:47,564 iteration 4496 : loss : 0.022270, loss_ce: 0.006751
2022-01-14 12:56:48,460 iteration 4497 : loss : 0.020595, loss_ce: 0.009355
2022-01-14 12:56:49,451 iteration 4498 : loss : 0.020158, loss_ce: 0.006182
2022-01-14 12:56:50,412 iteration 4499 : loss : 0.018944, loss_ce: 0.008113
2022-01-14 12:56:51,402 iteration 4500 : loss : 0.019900, loss_ce: 0.007328
2022-01-14 12:56:52,370 iteration 4501 : loss : 0.027596, loss_ce: 0.014323
2022-01-14 12:56:53,345 iteration 4502 : loss : 0.023220, loss_ce: 0.007446
2022-01-14 12:56:54,419 iteration 4503 : loss : 0.023468, loss_ce: 0.008856
2022-01-14 12:56:55,330 iteration 4504 : loss : 0.018987, loss_ce: 0.007563
2022-01-14 12:56:55,330 Training Data Eval:
2022-01-14 12:57:00,154   Average segmentation loss on training set: 0.0136
2022-01-14 12:57:00,155 Validation Data Eval:
2022-01-14 12:57:01,777   Average segmentation loss on validation set: 0.0654
2022-01-14 12:57:02,778 iteration 4505 : loss : 0.021334, loss_ce: 0.007273
 66%|███████████████████▏         | 265/400 [1:21:36<43:39, 19.41s/it]2022-01-14 12:57:03,858 iteration 4506 : loss : 0.025473, loss_ce: 0.009242
2022-01-14 12:57:04,925 iteration 4507 : loss : 0.021140, loss_ce: 0.007922
2022-01-14 12:57:05,933 iteration 4508 : loss : 0.019702, loss_ce: 0.006515
2022-01-14 12:57:06,870 iteration 4509 : loss : 0.017974, loss_ce: 0.005847
2022-01-14 12:57:07,873 iteration 4510 : loss : 0.016485, loss_ce: 0.005621
2022-01-14 12:57:08,965 iteration 4511 : loss : 0.026405, loss_ce: 0.012601
2022-01-14 12:57:09,873 iteration 4512 : loss : 0.017171, loss_ce: 0.006059
2022-01-14 12:57:10,844 iteration 4513 : loss : 0.017110, loss_ce: 0.006153
2022-01-14 12:57:11,807 iteration 4514 : loss : 0.023415, loss_ce: 0.009275
2022-01-14 12:57:12,789 iteration 4515 : loss : 0.018101, loss_ce: 0.007292
2022-01-14 12:57:13,792 iteration 4516 : loss : 0.022111, loss_ce: 0.009268
2022-01-14 12:57:14,822 iteration 4517 : loss : 0.030522, loss_ce: 0.014357
2022-01-14 12:57:15,801 iteration 4518 : loss : 0.025371, loss_ce: 0.010542
2022-01-14 12:57:16,728 iteration 4519 : loss : 0.026870, loss_ce: 0.009777
2022-01-14 12:57:17,725 iteration 4520 : loss : 0.024176, loss_ce: 0.007269
2022-01-14 12:57:18,734 iteration 4521 : loss : 0.020996, loss_ce: 0.008220
2022-01-14 12:57:19,785 iteration 4522 : loss : 0.026818, loss_ce: 0.009754
 66%|███████████████████▎         | 266/400 [1:21:53<41:44, 18.69s/it]2022-01-14 12:57:20,911 iteration 4523 : loss : 0.024892, loss_ce: 0.013074
2022-01-14 12:57:21,926 iteration 4524 : loss : 0.024602, loss_ce: 0.008818
2022-01-14 12:57:22,956 iteration 4525 : loss : 0.022625, loss_ce: 0.009473
2022-01-14 12:57:23,955 iteration 4526 : loss : 0.021831, loss_ce: 0.006650
2022-01-14 12:57:24,879 iteration 4527 : loss : 0.021219, loss_ce: 0.006973
2022-01-14 12:57:25,839 iteration 4528 : loss : 0.024255, loss_ce: 0.008200
2022-01-14 12:57:26,852 iteration 4529 : loss : 0.017463, loss_ce: 0.007910
2022-01-14 12:57:27,812 iteration 4530 : loss : 0.022548, loss_ce: 0.005978
2022-01-14 12:57:28,810 iteration 4531 : loss : 0.021270, loss_ce: 0.007284
2022-01-14 12:57:29,835 iteration 4532 : loss : 0.014516, loss_ce: 0.004680
2022-01-14 12:57:30,804 iteration 4533 : loss : 0.022203, loss_ce: 0.009427
2022-01-14 12:57:31,783 iteration 4534 : loss : 0.026840, loss_ce: 0.007839
2022-01-14 12:57:32,808 iteration 4535 : loss : 0.028198, loss_ce: 0.010044
2022-01-14 12:57:33,826 iteration 4536 : loss : 0.017288, loss_ce: 0.007196
2022-01-14 12:57:34,837 iteration 4537 : loss : 0.021696, loss_ce: 0.008763
2022-01-14 12:57:35,838 iteration 4538 : loss : 0.022178, loss_ce: 0.008027
2022-01-14 12:57:36,835 iteration 4539 : loss : 0.014989, loss_ce: 0.005769
 67%|███████████████████▎         | 267/400 [1:22:10<40:20, 18.20s/it]2022-01-14 12:57:37,865 iteration 4540 : loss : 0.014801, loss_ce: 0.005293
2022-01-14 12:57:38,893 iteration 4541 : loss : 0.028025, loss_ce: 0.016879
2022-01-14 12:57:39,842 iteration 4542 : loss : 0.019301, loss_ce: 0.006859
2022-01-14 12:57:40,810 iteration 4543 : loss : 0.018576, loss_ce: 0.006327
2022-01-14 12:57:41,762 iteration 4544 : loss : 0.017132, loss_ce: 0.006018
2022-01-14 12:57:42,818 iteration 4545 : loss : 0.020432, loss_ce: 0.008694
2022-01-14 12:57:43,924 iteration 4546 : loss : 0.028296, loss_ce: 0.012809
2022-01-14 12:57:45,023 iteration 4547 : loss : 0.023764, loss_ce: 0.009010
2022-01-14 12:57:45,968 iteration 4548 : loss : 0.023242, loss_ce: 0.008521
2022-01-14 12:57:46,917 iteration 4549 : loss : 0.030583, loss_ce: 0.006787
2022-01-14 12:57:47,928 iteration 4550 : loss : 0.020516, loss_ce: 0.007472
2022-01-14 12:57:48,951 iteration 4551 : loss : 0.020684, loss_ce: 0.008213
2022-01-14 12:57:50,032 iteration 4552 : loss : 0.026618, loss_ce: 0.007946
2022-01-14 12:57:51,050 iteration 4553 : loss : 0.026793, loss_ce: 0.008006
2022-01-14 12:57:52,004 iteration 4554 : loss : 0.023150, loss_ce: 0.010408
2022-01-14 12:57:52,987 iteration 4555 : loss : 0.022486, loss_ce: 0.009111
2022-01-14 12:57:53,972 iteration 4556 : loss : 0.023481, loss_ce: 0.007113
 67%|███████████████████▍         | 268/400 [1:22:28<39:19, 17.88s/it]2022-01-14 12:57:54,999 iteration 4557 : loss : 0.018781, loss_ce: 0.007664
2022-01-14 12:57:56,033 iteration 4558 : loss : 0.022745, loss_ce: 0.007855
2022-01-14 12:57:57,098 iteration 4559 : loss : 0.023313, loss_ce: 0.009226
2022-01-14 12:57:58,130 iteration 4560 : loss : 0.024490, loss_ce: 0.012975
2022-01-14 12:57:59,090 iteration 4561 : loss : 0.017194, loss_ce: 0.005788
2022-01-14 12:58:00,096 iteration 4562 : loss : 0.025642, loss_ce: 0.010308
2022-01-14 12:58:01,074 iteration 4563 : loss : 0.026263, loss_ce: 0.007929
2022-01-14 12:58:02,043 iteration 4564 : loss : 0.017995, loss_ce: 0.007374
2022-01-14 12:58:03,029 iteration 4565 : loss : 0.027225, loss_ce: 0.010417
2022-01-14 12:58:04,042 iteration 4566 : loss : 0.020451, loss_ce: 0.007260
2022-01-14 12:58:05,037 iteration 4567 : loss : 0.024112, loss_ce: 0.009583
2022-01-14 12:58:05,959 iteration 4568 : loss : 0.017156, loss_ce: 0.005452
2022-01-14 12:58:06,900 iteration 4569 : loss : 0.033534, loss_ce: 0.013281
2022-01-14 12:58:07,851 iteration 4570 : loss : 0.018572, loss_ce: 0.006069
2022-01-14 12:58:08,880 iteration 4571 : loss : 0.020759, loss_ce: 0.009417
2022-01-14 12:58:09,904 iteration 4572 : loss : 0.022248, loss_ce: 0.007622
2022-01-14 12:58:10,949 iteration 4573 : loss : 0.025224, loss_ce: 0.008034
 67%|███████████████████▌         | 269/400 [1:22:44<38:26, 17.60s/it]2022-01-14 12:58:11,935 iteration 4574 : loss : 0.014640, loss_ce: 0.004815
2022-01-14 12:58:12,951 iteration 4575 : loss : 0.016916, loss_ce: 0.004465
2022-01-14 12:58:13,878 iteration 4576 : loss : 0.020453, loss_ce: 0.008461
2022-01-14 12:58:14,821 iteration 4577 : loss : 0.018262, loss_ce: 0.008846
2022-01-14 12:58:15,807 iteration 4578 : loss : 0.019905, loss_ce: 0.007204
2022-01-14 12:58:16,755 iteration 4579 : loss : 0.015064, loss_ce: 0.007149
2022-01-14 12:58:17,723 iteration 4580 : loss : 0.018815, loss_ce: 0.007208
2022-01-14 12:58:18,715 iteration 4581 : loss : 0.019791, loss_ce: 0.008293
2022-01-14 12:58:19,704 iteration 4582 : loss : 0.025325, loss_ce: 0.010257
2022-01-14 12:58:20,687 iteration 4583 : loss : 0.022170, loss_ce: 0.008214
2022-01-14 12:58:21,658 iteration 4584 : loss : 0.019407, loss_ce: 0.007096
2022-01-14 12:58:22,669 iteration 4585 : loss : 0.030561, loss_ce: 0.009597
2022-01-14 12:58:23,608 iteration 4586 : loss : 0.016990, loss_ce: 0.006736
2022-01-14 12:58:24,570 iteration 4587 : loss : 0.019026, loss_ce: 0.005665
2022-01-14 12:58:25,531 iteration 4588 : loss : 0.026792, loss_ce: 0.009049
2022-01-14 12:58:26,541 iteration 4589 : loss : 0.019588, loss_ce: 0.006461
2022-01-14 12:58:26,541 Training Data Eval:
2022-01-14 12:58:31,349   Average segmentation loss on training set: 0.0130
2022-01-14 12:58:31,349 Validation Data Eval:
2022-01-14 12:58:32,964   Average segmentation loss on validation set: 0.0646
2022-01-14 12:58:33,935 iteration 4590 : loss : 0.023229, loss_ce: 0.010903
 68%|███████████████████▌         | 270/400 [1:23:07<41:39, 19.22s/it]2022-01-14 12:58:34,985 iteration 4591 : loss : 0.035024, loss_ce: 0.008917
2022-01-14 12:58:36,027 iteration 4592 : loss : 0.019804, loss_ce: 0.007454
2022-01-14 12:58:37,046 iteration 4593 : loss : 0.020127, loss_ce: 0.008732
2022-01-14 12:58:38,104 iteration 4594 : loss : 0.037072, loss_ce: 0.010385
2022-01-14 12:58:39,095 iteration 4595 : loss : 0.022282, loss_ce: 0.006626
2022-01-14 12:58:40,064 iteration 4596 : loss : 0.019064, loss_ce: 0.005055
2022-01-14 12:58:41,076 iteration 4597 : loss : 0.017386, loss_ce: 0.007888
2022-01-14 12:58:42,138 iteration 4598 : loss : 0.026384, loss_ce: 0.009360
2022-01-14 12:58:43,175 iteration 4599 : loss : 0.017570, loss_ce: 0.008258
2022-01-14 12:58:44,156 iteration 4600 : loss : 0.033123, loss_ce: 0.010583
2022-01-14 12:58:45,177 iteration 4601 : loss : 0.020213, loss_ce: 0.009984
2022-01-14 12:58:46,270 iteration 4602 : loss : 0.026332, loss_ce: 0.006930
2022-01-14 12:58:47,289 iteration 4603 : loss : 0.021015, loss_ce: 0.007349
2022-01-14 12:58:48,332 iteration 4604 : loss : 0.020120, loss_ce: 0.008841
2022-01-14 12:58:49,389 iteration 4605 : loss : 0.039266, loss_ce: 0.007110
2022-01-14 12:58:50,433 iteration 4606 : loss : 0.022085, loss_ce: 0.008726
2022-01-14 12:58:51,480 iteration 4607 : loss : 0.026032, loss_ce: 0.013738
 68%|███████████████████▋         | 271/400 [1:23:25<40:14, 18.72s/it]2022-01-14 12:58:52,494 iteration 4608 : loss : 0.014803, loss_ce: 0.005527
2022-01-14 12:58:53,502 iteration 4609 : loss : 0.057917, loss_ce: 0.026614
2022-01-14 12:58:54,450 iteration 4610 : loss : 0.023413, loss_ce: 0.007894
2022-01-14 12:58:55,399 iteration 4611 : loss : 0.027153, loss_ce: 0.011175
2022-01-14 12:58:56,325 iteration 4612 : loss : 0.018058, loss_ce: 0.005197
2022-01-14 12:58:57,326 iteration 4613 : loss : 0.026044, loss_ce: 0.008481
2022-01-14 12:58:58,329 iteration 4614 : loss : 0.018501, loss_ce: 0.007833
2022-01-14 12:58:59,373 iteration 4615 : loss : 0.016338, loss_ce: 0.005317
2022-01-14 12:59:00,480 iteration 4616 : loss : 0.021965, loss_ce: 0.009349
2022-01-14 12:59:01,497 iteration 4617 : loss : 0.026601, loss_ce: 0.014818
2022-01-14 12:59:02,445 iteration 4618 : loss : 0.018146, loss_ce: 0.005378
2022-01-14 12:59:03,405 iteration 4619 : loss : 0.017892, loss_ce: 0.007515
2022-01-14 12:59:04,461 iteration 4620 : loss : 0.045222, loss_ce: 0.013948
2022-01-14 12:59:05,451 iteration 4621 : loss : 0.026733, loss_ce: 0.012602
2022-01-14 12:59:06,452 iteration 4622 : loss : 0.028764, loss_ce: 0.008284
2022-01-14 12:59:07,440 iteration 4623 : loss : 0.025551, loss_ce: 0.008927
2022-01-14 12:59:08,447 iteration 4624 : loss : 0.018932, loss_ce: 0.008857
 68%|███████████████████▋         | 272/400 [1:23:42<38:48, 18.19s/it]2022-01-14 12:59:09,543 iteration 4625 : loss : 0.021123, loss_ce: 0.007618
2022-01-14 12:59:10,611 iteration 4626 : loss : 0.022184, loss_ce: 0.010084
2022-01-14 12:59:11,718 iteration 4627 : loss : 0.023641, loss_ce: 0.009470
2022-01-14 12:59:12,695 iteration 4628 : loss : 0.018979, loss_ce: 0.006984
2022-01-14 12:59:13,629 iteration 4629 : loss : 0.020122, loss_ce: 0.006097
2022-01-14 12:59:14,616 iteration 4630 : loss : 0.016689, loss_ce: 0.006364
2022-01-14 12:59:15,619 iteration 4631 : loss : 0.020781, loss_ce: 0.006734
2022-01-14 12:59:16,620 iteration 4632 : loss : 0.021822, loss_ce: 0.006469
2022-01-14 12:59:17,599 iteration 4633 : loss : 0.017818, loss_ce: 0.006407
2022-01-14 12:59:18,589 iteration 4634 : loss : 0.016027, loss_ce: 0.007174
2022-01-14 12:59:19,506 iteration 4635 : loss : 0.015029, loss_ce: 0.006125
2022-01-14 12:59:20,580 iteration 4636 : loss : 0.030981, loss_ce: 0.011272
2022-01-14 12:59:21,551 iteration 4637 : loss : 0.024340, loss_ce: 0.007847
2022-01-14 12:59:22,665 iteration 4638 : loss : 0.029721, loss_ce: 0.012409
2022-01-14 12:59:23,710 iteration 4639 : loss : 0.031795, loss_ce: 0.014200
2022-01-14 12:59:24,829 iteration 4640 : loss : 0.036384, loss_ce: 0.015408
2022-01-14 12:59:25,874 iteration 4641 : loss : 0.030104, loss_ce: 0.010055
 68%|███████████████████▊         | 273/400 [1:23:59<38:01, 17.96s/it]2022-01-14 12:59:26,961 iteration 4642 : loss : 0.033177, loss_ce: 0.005950
2022-01-14 12:59:27,967 iteration 4643 : loss : 0.018190, loss_ce: 0.006679
2022-01-14 12:59:29,030 iteration 4644 : loss : 0.020448, loss_ce: 0.006646
2022-01-14 12:59:30,096 iteration 4645 : loss : 0.023886, loss_ce: 0.010944
2022-01-14 12:59:31,126 iteration 4646 : loss : 0.044344, loss_ce: 0.018828
2022-01-14 12:59:32,055 iteration 4647 : loss : 0.018798, loss_ce: 0.006344
2022-01-14 12:59:33,025 iteration 4648 : loss : 0.034221, loss_ce: 0.009812
2022-01-14 12:59:34,035 iteration 4649 : loss : 0.019916, loss_ce: 0.008511
2022-01-14 12:59:35,088 iteration 4650 : loss : 0.026478, loss_ce: 0.008135
2022-01-14 12:59:36,043 iteration 4651 : loss : 0.024295, loss_ce: 0.010539
2022-01-14 12:59:37,130 iteration 4652 : loss : 0.023524, loss_ce: 0.009016
2022-01-14 12:59:38,109 iteration 4653 : loss : 0.025130, loss_ce: 0.010618
2022-01-14 12:59:39,090 iteration 4654 : loss : 0.030821, loss_ce: 0.009079
2022-01-14 12:59:40,154 iteration 4655 : loss : 0.022016, loss_ce: 0.008974
2022-01-14 12:59:41,241 iteration 4656 : loss : 0.024917, loss_ce: 0.012785
2022-01-14 12:59:42,294 iteration 4657 : loss : 0.025824, loss_ce: 0.012198
2022-01-14 12:59:43,336 iteration 4658 : loss : 0.029678, loss_ce: 0.011532
 68%|███████████████████▊         | 274/400 [1:24:17<37:24, 17.81s/it]2022-01-14 12:59:44,428 iteration 4659 : loss : 0.027190, loss_ce: 0.012112
2022-01-14 12:59:45,490 iteration 4660 : loss : 0.031705, loss_ce: 0.013630
2022-01-14 12:59:46,527 iteration 4661 : loss : 0.029995, loss_ce: 0.011207
2022-01-14 12:59:47,488 iteration 4662 : loss : 0.018578, loss_ce: 0.006759
2022-01-14 12:59:48,516 iteration 4663 : loss : 0.023825, loss_ce: 0.009808
2022-01-14 12:59:49,496 iteration 4664 : loss : 0.016053, loss_ce: 0.005669
2022-01-14 12:59:50,489 iteration 4665 : loss : 0.022235, loss_ce: 0.007521
2022-01-14 12:59:51,389 iteration 4666 : loss : 0.015266, loss_ce: 0.005412
2022-01-14 12:59:52,347 iteration 4667 : loss : 0.022428, loss_ce: 0.008186
2022-01-14 12:59:53,472 iteration 4668 : loss : 0.031285, loss_ce: 0.015136
2022-01-14 12:59:54,434 iteration 4669 : loss : 0.019821, loss_ce: 0.009260
2022-01-14 12:59:55,400 iteration 4670 : loss : 0.024762, loss_ce: 0.011707
2022-01-14 12:59:56,350 iteration 4671 : loss : 0.016836, loss_ce: 0.005283
2022-01-14 12:59:57,445 iteration 4672 : loss : 0.028601, loss_ce: 0.011696
2022-01-14 12:59:58,505 iteration 4673 : loss : 0.021072, loss_ce: 0.008778
2022-01-14 12:59:59,441 iteration 4674 : loss : 0.021335, loss_ce: 0.006273
2022-01-14 12:59:59,441 Training Data Eval:
2022-01-14 13:00:04,259   Average segmentation loss on training set: 0.0138
2022-01-14 13:00:04,259 Validation Data Eval:
2022-01-14 13:00:05,877   Average segmentation loss on validation set: 0.0679
2022-01-14 13:00:06,926 iteration 4675 : loss : 0.028821, loss_ce: 0.010886
 69%|███████████████████▉         | 275/400 [1:24:40<40:43, 19.55s/it]2022-01-14 13:00:08,078 iteration 4676 : loss : 0.023905, loss_ce: 0.008722
2022-01-14 13:00:09,064 iteration 4677 : loss : 0.025371, loss_ce: 0.008905
2022-01-14 13:00:10,089 iteration 4678 : loss : 0.025425, loss_ce: 0.007740
2022-01-14 13:00:11,172 iteration 4679 : loss : 0.045718, loss_ce: 0.011764
2022-01-14 13:00:12,173 iteration 4680 : loss : 0.016713, loss_ce: 0.006486
2022-01-14 13:00:13,159 iteration 4681 : loss : 0.042242, loss_ce: 0.011561
2022-01-14 13:00:14,130 iteration 4682 : loss : 0.022774, loss_ce: 0.008224
2022-01-14 13:00:15,031 iteration 4683 : loss : 0.022714, loss_ce: 0.006220
2022-01-14 13:00:16,079 iteration 4684 : loss : 0.020399, loss_ce: 0.009682
2022-01-14 13:00:17,107 iteration 4685 : loss : 0.027627, loss_ce: 0.009374
2022-01-14 13:00:18,105 iteration 4686 : loss : 0.024847, loss_ce: 0.008025
2022-01-14 13:00:19,079 iteration 4687 : loss : 0.024047, loss_ce: 0.009821
2022-01-14 13:00:20,008 iteration 4688 : loss : 0.015749, loss_ce: 0.006752
2022-01-14 13:00:20,945 iteration 4689 : loss : 0.018501, loss_ce: 0.009278
2022-01-14 13:00:21,902 iteration 4690 : loss : 0.024203, loss_ce: 0.009738
2022-01-14 13:00:22,947 iteration 4691 : loss : 0.036569, loss_ce: 0.021773
2022-01-14 13:00:23,930 iteration 4692 : loss : 0.027096, loss_ce: 0.008358
 69%|████████████████████         | 276/400 [1:24:57<38:49, 18.78s/it]2022-01-14 13:00:25,049 iteration 4693 : loss : 0.032246, loss_ce: 0.011763
2022-01-14 13:00:26,073 iteration 4694 : loss : 0.046451, loss_ce: 0.014488
2022-01-14 13:00:26,934 iteration 4695 : loss : 0.015681, loss_ce: 0.005503
2022-01-14 13:00:27,999 iteration 4696 : loss : 0.024474, loss_ce: 0.009480
2022-01-14 13:00:28,966 iteration 4697 : loss : 0.032797, loss_ce: 0.011156
2022-01-14 13:00:29,966 iteration 4698 : loss : 0.022309, loss_ce: 0.010290
2022-01-14 13:00:31,027 iteration 4699 : loss : 0.026724, loss_ce: 0.013510
2022-01-14 13:00:31,981 iteration 4700 : loss : 0.021387, loss_ce: 0.009588
2022-01-14 13:00:33,091 iteration 4701 : loss : 0.026872, loss_ce: 0.011241
2022-01-14 13:00:34,067 iteration 4702 : loss : 0.022624, loss_ce: 0.009607
2022-01-14 13:00:35,024 iteration 4703 : loss : 0.026728, loss_ce: 0.007494
2022-01-14 13:00:36,016 iteration 4704 : loss : 0.020569, loss_ce: 0.007250
2022-01-14 13:00:36,886 iteration 4705 : loss : 0.015513, loss_ce: 0.006718
2022-01-14 13:00:37,874 iteration 4706 : loss : 0.024038, loss_ce: 0.005612
2022-01-14 13:00:38,921 iteration 4707 : loss : 0.019879, loss_ce: 0.007661
2022-01-14 13:00:39,980 iteration 4708 : loss : 0.022242, loss_ce: 0.007309
2022-01-14 13:00:41,014 iteration 4709 : loss : 0.028358, loss_ce: 0.009229
 69%|████████████████████         | 277/400 [1:25:15<37:27, 18.27s/it]2022-01-14 13:00:42,105 iteration 4710 : loss : 0.043219, loss_ce: 0.008934
2022-01-14 13:00:43,256 iteration 4711 : loss : 0.029024, loss_ce: 0.010033
2022-01-14 13:00:44,242 iteration 4712 : loss : 0.028031, loss_ce: 0.012631
2022-01-14 13:00:45,234 iteration 4713 : loss : 0.018700, loss_ce: 0.006980
2022-01-14 13:00:46,247 iteration 4714 : loss : 0.023324, loss_ce: 0.007944
2022-01-14 13:00:47,312 iteration 4715 : loss : 0.027668, loss_ce: 0.010546
2022-01-14 13:00:48,340 iteration 4716 : loss : 0.021376, loss_ce: 0.008344
2022-01-14 13:00:49,338 iteration 4717 : loss : 0.019781, loss_ce: 0.007356
2022-01-14 13:00:50,280 iteration 4718 : loss : 0.018107, loss_ce: 0.006510
2022-01-14 13:00:51,221 iteration 4719 : loss : 0.018216, loss_ce: 0.007563
2022-01-14 13:00:52,185 iteration 4720 : loss : 0.021076, loss_ce: 0.008764
2022-01-14 13:00:53,165 iteration 4721 : loss : 0.018179, loss_ce: 0.007367
2022-01-14 13:00:54,216 iteration 4722 : loss : 0.034622, loss_ce: 0.015575
2022-01-14 13:00:55,211 iteration 4723 : loss : 0.016516, loss_ce: 0.005889
2022-01-14 13:00:56,142 iteration 4724 : loss : 0.019207, loss_ce: 0.006900
2022-01-14 13:00:57,070 iteration 4725 : loss : 0.020557, loss_ce: 0.008056
2022-01-14 13:00:58,061 iteration 4726 : loss : 0.023887, loss_ce: 0.009814
 70%|████████████████████▏        | 278/400 [1:25:32<36:24, 17.91s/it]2022-01-14 13:00:59,169 iteration 4727 : loss : 0.021590, loss_ce: 0.007358
2022-01-14 13:01:00,113 iteration 4728 : loss : 0.019289, loss_ce: 0.007429
2022-01-14 13:01:01,072 iteration 4729 : loss : 0.019647, loss_ce: 0.006577
2022-01-14 13:01:02,032 iteration 4730 : loss : 0.015526, loss_ce: 0.004915
2022-01-14 13:01:03,079 iteration 4731 : loss : 0.022704, loss_ce: 0.007441
2022-01-14 13:01:04,087 iteration 4732 : loss : 0.021534, loss_ce: 0.006630
2022-01-14 13:01:05,086 iteration 4733 : loss : 0.023334, loss_ce: 0.007713
2022-01-14 13:01:06,061 iteration 4734 : loss : 0.018766, loss_ce: 0.006586
2022-01-14 13:01:07,147 iteration 4735 : loss : 0.021803, loss_ce: 0.008003
2022-01-14 13:01:08,082 iteration 4736 : loss : 0.021106, loss_ce: 0.009726
2022-01-14 13:01:09,151 iteration 4737 : loss : 0.027154, loss_ce: 0.010381
2022-01-14 13:01:10,146 iteration 4738 : loss : 0.016179, loss_ce: 0.005567
2022-01-14 13:01:11,140 iteration 4739 : loss : 0.020171, loss_ce: 0.007237
2022-01-14 13:01:12,183 iteration 4740 : loss : 0.031015, loss_ce: 0.016153
2022-01-14 13:01:13,162 iteration 4741 : loss : 0.021035, loss_ce: 0.006623
2022-01-14 13:01:14,144 iteration 4742 : loss : 0.018989, loss_ce: 0.009273
2022-01-14 13:01:15,220 iteration 4743 : loss : 0.024169, loss_ce: 0.008327
 70%|████████████████████▏        | 279/400 [1:25:49<35:39, 17.68s/it]2022-01-14 13:01:16,331 iteration 4744 : loss : 0.020165, loss_ce: 0.007014
2022-01-14 13:01:17,339 iteration 4745 : loss : 0.030455, loss_ce: 0.007736
2022-01-14 13:01:18,303 iteration 4746 : loss : 0.016380, loss_ce: 0.008430
2022-01-14 13:01:19,278 iteration 4747 : loss : 0.022736, loss_ce: 0.008116
2022-01-14 13:01:20,289 iteration 4748 : loss : 0.019615, loss_ce: 0.007450
2022-01-14 13:01:21,304 iteration 4749 : loss : 0.022702, loss_ce: 0.007774
2022-01-14 13:01:22,352 iteration 4750 : loss : 0.023751, loss_ce: 0.008758
2022-01-14 13:01:23,327 iteration 4751 : loss : 0.034264, loss_ce: 0.013114
2022-01-14 13:01:24,352 iteration 4752 : loss : 0.017183, loss_ce: 0.006148
2022-01-14 13:01:25,400 iteration 4753 : loss : 0.022042, loss_ce: 0.006981
2022-01-14 13:01:26,424 iteration 4754 : loss : 0.019198, loss_ce: 0.006156
2022-01-14 13:01:27,536 iteration 4755 : loss : 0.020661, loss_ce: 0.006114
2022-01-14 13:01:28,506 iteration 4756 : loss : 0.016516, loss_ce: 0.008082
2022-01-14 13:01:29,489 iteration 4757 : loss : 0.021754, loss_ce: 0.008747
2022-01-14 13:01:30,452 iteration 4758 : loss : 0.022536, loss_ce: 0.006578
2022-01-14 13:01:31,444 iteration 4759 : loss : 0.017635, loss_ce: 0.005814
2022-01-14 13:01:31,444 Training Data Eval:
2022-01-14 13:01:36,256   Average segmentation loss on training set: 0.0135
2022-01-14 13:01:36,256 Validation Data Eval:
2022-01-14 13:01:37,866   Average segmentation loss on validation set: 0.0804
2022-01-14 13:01:38,835 iteration 4760 : loss : 0.019860, loss_ce: 0.008387
 70%|████████████████████▎        | 280/400 [1:26:12<38:55, 19.46s/it]2022-01-14 13:01:39,876 iteration 4761 : loss : 0.019823, loss_ce: 0.006177
2022-01-14 13:01:40,904 iteration 4762 : loss : 0.019840, loss_ce: 0.007598
2022-01-14 13:01:41,848 iteration 4763 : loss : 0.017705, loss_ce: 0.007268
2022-01-14 13:01:42,879 iteration 4764 : loss : 0.021110, loss_ce: 0.008376
2022-01-14 13:01:43,856 iteration 4765 : loss : 0.020848, loss_ce: 0.008930
2022-01-14 13:01:44,915 iteration 4766 : loss : 0.023743, loss_ce: 0.008176
2022-01-14 13:01:45,937 iteration 4767 : loss : 0.016344, loss_ce: 0.006068
2022-01-14 13:01:46,892 iteration 4768 : loss : 0.021997, loss_ce: 0.008090
2022-01-14 13:01:47,925 iteration 4769 : loss : 0.028450, loss_ce: 0.010041
2022-01-14 13:01:48,969 iteration 4770 : loss : 0.017515, loss_ce: 0.006518
2022-01-14 13:01:49,911 iteration 4771 : loss : 0.017489, loss_ce: 0.005519
2022-01-14 13:01:50,960 iteration 4772 : loss : 0.023501, loss_ce: 0.009094
2022-01-14 13:01:51,996 iteration 4773 : loss : 0.028401, loss_ce: 0.010554
2022-01-14 13:01:53,020 iteration 4774 : loss : 0.022006, loss_ce: 0.010607
2022-01-14 13:01:53,983 iteration 4775 : loss : 0.026203, loss_ce: 0.007581
2022-01-14 13:01:54,970 iteration 4776 : loss : 0.021335, loss_ce: 0.012485
2022-01-14 13:01:56,101 iteration 4777 : loss : 0.025853, loss_ce: 0.012246
 70%|████████████████████▎        | 281/400 [1:26:30<37:17, 18.80s/it]2022-01-14 13:01:57,090 iteration 4778 : loss : 0.013715, loss_ce: 0.004030
2022-01-14 13:01:58,068 iteration 4779 : loss : 0.028717, loss_ce: 0.009890
2022-01-14 13:01:58,994 iteration 4780 : loss : 0.016870, loss_ce: 0.005729
2022-01-14 13:01:59,963 iteration 4781 : loss : 0.027754, loss_ce: 0.007636
2022-01-14 13:02:01,018 iteration 4782 : loss : 0.034183, loss_ce: 0.016176
2022-01-14 13:02:02,018 iteration 4783 : loss : 0.017635, loss_ce: 0.007776
2022-01-14 13:02:02,957 iteration 4784 : loss : 0.015413, loss_ce: 0.006276
2022-01-14 13:02:04,024 iteration 4785 : loss : 0.019132, loss_ce: 0.006534
2022-01-14 13:02:05,047 iteration 4786 : loss : 0.021524, loss_ce: 0.006955
2022-01-14 13:02:06,069 iteration 4787 : loss : 0.046145, loss_ce: 0.014165
2022-01-14 13:02:07,103 iteration 4788 : loss : 0.018811, loss_ce: 0.006243
2022-01-14 13:02:08,045 iteration 4789 : loss : 0.017636, loss_ce: 0.008266
2022-01-14 13:02:09,144 iteration 4790 : loss : 0.033037, loss_ce: 0.012020
2022-01-14 13:02:10,124 iteration 4791 : loss : 0.022843, loss_ce: 0.010240
2022-01-14 13:02:11,171 iteration 4792 : loss : 0.028017, loss_ce: 0.007027
2022-01-14 13:02:12,129 iteration 4793 : loss : 0.018528, loss_ce: 0.006681
2022-01-14 13:02:13,042 iteration 4794 : loss : 0.022198, loss_ce: 0.006486
 70%|████████████████████▍        | 282/400 [1:26:47<35:52, 18.24s/it]2022-01-14 13:02:14,118 iteration 4795 : loss : 0.021487, loss_ce: 0.006297
2022-01-14 13:02:15,133 iteration 4796 : loss : 0.023236, loss_ce: 0.008685
2022-01-14 13:02:16,161 iteration 4797 : loss : 0.021837, loss_ce: 0.009894
2022-01-14 13:02:17,235 iteration 4798 : loss : 0.025645, loss_ce: 0.008866
2022-01-14 13:02:18,235 iteration 4799 : loss : 0.017379, loss_ce: 0.005627
2022-01-14 13:02:19,240 iteration 4800 : loss : 0.035834, loss_ce: 0.011816
2022-01-14 13:02:20,321 iteration 4801 : loss : 0.019849, loss_ce: 0.007938
2022-01-14 13:02:21,252 iteration 4802 : loss : 0.015101, loss_ce: 0.006076
2022-01-14 13:02:22,227 iteration 4803 : loss : 0.025100, loss_ce: 0.009743
2022-01-14 13:02:23,300 iteration 4804 : loss : 0.041805, loss_ce: 0.009552
2022-01-14 13:02:24,365 iteration 4805 : loss : 0.025783, loss_ce: 0.009241
2022-01-14 13:02:25,437 iteration 4806 : loss : 0.021731, loss_ce: 0.009803
2022-01-14 13:02:26,371 iteration 4807 : loss : 0.022262, loss_ce: 0.009483
2022-01-14 13:02:27,296 iteration 4808 : loss : 0.021173, loss_ce: 0.008997
2022-01-14 13:02:28,304 iteration 4809 : loss : 0.037679, loss_ce: 0.019852
2022-01-14 13:02:29,300 iteration 4810 : loss : 0.027543, loss_ce: 0.007540
2022-01-14 13:02:30,317 iteration 4811 : loss : 0.017713, loss_ce: 0.007224
 71%|████████████████████▌        | 283/400 [1:27:04<35:00, 17.95s/it]2022-01-14 13:02:31,315 iteration 4812 : loss : 0.019620, loss_ce: 0.007955
2022-01-14 13:02:32,332 iteration 4813 : loss : 0.015808, loss_ce: 0.003401
2022-01-14 13:02:33,381 iteration 4814 : loss : 0.029586, loss_ce: 0.006628
2022-01-14 13:02:34,317 iteration 4815 : loss : 0.018405, loss_ce: 0.007932
2022-01-14 13:02:35,424 iteration 4816 : loss : 0.028098, loss_ce: 0.013348
2022-01-14 13:02:36,410 iteration 4817 : loss : 0.022275, loss_ce: 0.008677
2022-01-14 13:02:37,387 iteration 4818 : loss : 0.016983, loss_ce: 0.006230
2022-01-14 13:02:38,301 iteration 4819 : loss : 0.018136, loss_ce: 0.007458
2022-01-14 13:02:39,266 iteration 4820 : loss : 0.021007, loss_ce: 0.007731
2022-01-14 13:02:40,351 iteration 4821 : loss : 0.026507, loss_ce: 0.012436
2022-01-14 13:02:41,425 iteration 4822 : loss : 0.019806, loss_ce: 0.006196
2022-01-14 13:02:42,422 iteration 4823 : loss : 0.020677, loss_ce: 0.008310
2022-01-14 13:02:43,454 iteration 4824 : loss : 0.022671, loss_ce: 0.009208
2022-01-14 13:02:44,433 iteration 4825 : loss : 0.021481, loss_ce: 0.008793
2022-01-14 13:02:45,405 iteration 4826 : loss : 0.017881, loss_ce: 0.005664
2022-01-14 13:02:46,387 iteration 4827 : loss : 0.015693, loss_ce: 0.006074
2022-01-14 13:02:47,349 iteration 4828 : loss : 0.018781, loss_ce: 0.007656
 71%|████████████████████▌        | 284/400 [1:27:21<34:10, 17.68s/it]2022-01-14 13:02:48,351 iteration 4829 : loss : 0.020044, loss_ce: 0.006870
2022-01-14 13:02:49,379 iteration 4830 : loss : 0.017603, loss_ce: 0.007760
2022-01-14 13:02:50,390 iteration 4831 : loss : 0.025116, loss_ce: 0.010606
2022-01-14 13:02:51,375 iteration 4832 : loss : 0.015743, loss_ce: 0.004851
2022-01-14 13:02:52,411 iteration 4833 : loss : 0.032841, loss_ce: 0.014776
2022-01-14 13:02:53,349 iteration 4834 : loss : 0.016632, loss_ce: 0.005536
2022-01-14 13:02:54,462 iteration 4835 : loss : 0.017743, loss_ce: 0.007795
2022-01-14 13:02:55,475 iteration 4836 : loss : 0.025238, loss_ce: 0.007333
2022-01-14 13:02:56,523 iteration 4837 : loss : 0.021936, loss_ce: 0.006466
2022-01-14 13:02:57,499 iteration 4838 : loss : 0.019688, loss_ce: 0.006277
2022-01-14 13:02:58,523 iteration 4839 : loss : 0.021201, loss_ce: 0.008351
2022-01-14 13:02:59,523 iteration 4840 : loss : 0.019099, loss_ce: 0.009696
2022-01-14 13:03:00,451 iteration 4841 : loss : 0.013007, loss_ce: 0.004054
2022-01-14 13:03:01,455 iteration 4842 : loss : 0.016686, loss_ce: 0.005936
2022-01-14 13:03:02,549 iteration 4843 : loss : 0.018212, loss_ce: 0.005688
2022-01-14 13:03:03,553 iteration 4844 : loss : 0.021398, loss_ce: 0.007561
2022-01-14 13:03:03,553 Training Data Eval:
2022-01-14 13:03:08,353   Average segmentation loss on training set: 0.0125
2022-01-14 13:03:08,354 Validation Data Eval:
2022-01-14 13:03:09,973   Average segmentation loss on validation set: 0.0748
2022-01-14 13:03:11,012 iteration 4845 : loss : 0.021028, loss_ce: 0.008798
 71%|████████████████████▋        | 285/400 [1:27:45<37:19, 19.47s/it]2022-01-14 13:03:12,071 iteration 4846 : loss : 0.026750, loss_ce: 0.008792
2022-01-14 13:03:13,037 iteration 4847 : loss : 0.025032, loss_ce: 0.007764
2022-01-14 13:03:14,081 iteration 4848 : loss : 0.024576, loss_ce: 0.013991
2022-01-14 13:03:15,109 iteration 4849 : loss : 0.017629, loss_ce: 0.004591
2022-01-14 13:03:16,080 iteration 4850 : loss : 0.019726, loss_ce: 0.005536
2022-01-14 13:03:17,197 iteration 4851 : loss : 0.032685, loss_ce: 0.014411
2022-01-14 13:03:18,190 iteration 4852 : loss : 0.025820, loss_ce: 0.010436
2022-01-14 13:03:19,204 iteration 4853 : loss : 0.017619, loss_ce: 0.007584
2022-01-14 13:03:20,213 iteration 4854 : loss : 0.018529, loss_ce: 0.007449
2022-01-14 13:03:21,182 iteration 4855 : loss : 0.024847, loss_ce: 0.006567
2022-01-14 13:03:22,271 iteration 4856 : loss : 0.031968, loss_ce: 0.012327
2022-01-14 13:03:23,241 iteration 4857 : loss : 0.013322, loss_ce: 0.005005
2022-01-14 13:03:24,321 iteration 4858 : loss : 0.026859, loss_ce: 0.010811
2022-01-14 13:03:25,266 iteration 4859 : loss : 0.014403, loss_ce: 0.005711
2022-01-14 13:03:26,314 iteration 4860 : loss : 0.027066, loss_ce: 0.011643
2022-01-14 13:03:27,284 iteration 4861 : loss : 0.021033, loss_ce: 0.006981
2022-01-14 13:03:28,323 iteration 4862 : loss : 0.018534, loss_ce: 0.008367
 72%|████████████████████▋        | 286/400 [1:28:02<35:45, 18.82s/it]2022-01-14 13:03:29,459 iteration 4863 : loss : 0.026546, loss_ce: 0.007646
2022-01-14 13:03:30,458 iteration 4864 : loss : 0.017401, loss_ce: 0.006122
2022-01-14 13:03:31,432 iteration 4865 : loss : 0.020327, loss_ce: 0.008776
2022-01-14 13:03:32,496 iteration 4866 : loss : 0.021355, loss_ce: 0.007659
2022-01-14 13:03:33,513 iteration 4867 : loss : 0.019164, loss_ce: 0.006318
2022-01-14 13:03:34,420 iteration 4868 : loss : 0.016794, loss_ce: 0.006873
2022-01-14 13:03:35,519 iteration 4869 : loss : 0.023884, loss_ce: 0.010732
2022-01-14 13:03:36,514 iteration 4870 : loss : 0.016754, loss_ce: 0.005874
2022-01-14 13:03:37,610 iteration 4871 : loss : 0.037249, loss_ce: 0.012101
2022-01-14 13:03:38,544 iteration 4872 : loss : 0.014878, loss_ce: 0.004865
2022-01-14 13:03:39,636 iteration 4873 : loss : 0.019882, loss_ce: 0.007527
2022-01-14 13:03:40,664 iteration 4874 : loss : 0.028416, loss_ce: 0.008553
2022-01-14 13:03:41,652 iteration 4875 : loss : 0.026362, loss_ce: 0.010650
2022-01-14 13:03:42,567 iteration 4876 : loss : 0.020239, loss_ce: 0.006074
2022-01-14 13:03:43,614 iteration 4877 : loss : 0.025617, loss_ce: 0.012746
2022-01-14 13:03:44,695 iteration 4878 : loss : 0.031708, loss_ce: 0.010782
2022-01-14 13:03:45,699 iteration 4879 : loss : 0.016066, loss_ce: 0.005474
 72%|████████████████████▊        | 287/400 [1:28:19<34:37, 18.39s/it]2022-01-14 13:03:46,732 iteration 4880 : loss : 0.019935, loss_ce: 0.008373
2022-01-14 13:03:47,675 iteration 4881 : loss : 0.017518, loss_ce: 0.006985
2022-01-14 13:03:48,585 iteration 4882 : loss : 0.016760, loss_ce: 0.006794
2022-01-14 13:03:49,602 iteration 4883 : loss : 0.023855, loss_ce: 0.010090
2022-01-14 13:03:50,640 iteration 4884 : loss : 0.021102, loss_ce: 0.006456
2022-01-14 13:03:51,563 iteration 4885 : loss : 0.015006, loss_ce: 0.005698
2022-01-14 13:03:52,555 iteration 4886 : loss : 0.019918, loss_ce: 0.005717
2022-01-14 13:03:53,487 iteration 4887 : loss : 0.016722, loss_ce: 0.004680
2022-01-14 13:03:54,504 iteration 4888 : loss : 0.031455, loss_ce: 0.008278
2022-01-14 13:03:55,505 iteration 4889 : loss : 0.024401, loss_ce: 0.011266
2022-01-14 13:03:56,456 iteration 4890 : loss : 0.017357, loss_ce: 0.008891
2022-01-14 13:03:57,339 iteration 4891 : loss : 0.013368, loss_ce: 0.004766
2022-01-14 13:03:58,369 iteration 4892 : loss : 0.020032, loss_ce: 0.007761
2022-01-14 13:03:59,366 iteration 4893 : loss : 0.025146, loss_ce: 0.011156
2022-01-14 13:04:00,349 iteration 4894 : loss : 0.018119, loss_ce: 0.008198
2022-01-14 13:04:01,324 iteration 4895 : loss : 0.016507, loss_ce: 0.003525
2022-01-14 13:04:02,277 iteration 4896 : loss : 0.028869, loss_ce: 0.008264
 72%|████████████████████▉        | 288/400 [1:28:36<33:18, 17.85s/it]2022-01-14 13:04:03,294 iteration 4897 : loss : 0.016926, loss_ce: 0.006179
2022-01-14 13:04:04,349 iteration 4898 : loss : 0.022093, loss_ce: 0.009918
2022-01-14 13:04:05,347 iteration 4899 : loss : 0.016846, loss_ce: 0.005241
2022-01-14 13:04:06,302 iteration 4900 : loss : 0.022266, loss_ce: 0.008724
2022-01-14 13:04:07,273 iteration 4901 : loss : 0.031903, loss_ce: 0.008532
2022-01-14 13:04:08,242 iteration 4902 : loss : 0.013182, loss_ce: 0.004781
2022-01-14 13:04:09,259 iteration 4903 : loss : 0.016676, loss_ce: 0.007498
2022-01-14 13:04:10,151 iteration 4904 : loss : 0.016952, loss_ce: 0.005560
2022-01-14 13:04:11,104 iteration 4905 : loss : 0.023105, loss_ce: 0.005969
2022-01-14 13:04:12,128 iteration 4906 : loss : 0.021800, loss_ce: 0.009023
2022-01-14 13:04:13,075 iteration 4907 : loss : 0.017891, loss_ce: 0.006478
2022-01-14 13:04:14,139 iteration 4908 : loss : 0.021579, loss_ce: 0.009155
2022-01-14 13:04:15,160 iteration 4909 : loss : 0.020250, loss_ce: 0.006962
2022-01-14 13:04:16,139 iteration 4910 : loss : 0.016265, loss_ce: 0.007661
2022-01-14 13:04:17,104 iteration 4911 : loss : 0.012819, loss_ce: 0.004900
2022-01-14 13:04:18,095 iteration 4912 : loss : 0.018109, loss_ce: 0.008261
2022-01-14 13:04:19,077 iteration 4913 : loss : 0.027900, loss_ce: 0.011137
 72%|████████████████████▉        | 289/400 [1:28:53<32:26, 17.53s/it]2022-01-14 13:04:20,205 iteration 4914 : loss : 0.022067, loss_ce: 0.008395
2022-01-14 13:04:21,167 iteration 4915 : loss : 0.017348, loss_ce: 0.006314
2022-01-14 13:04:22,136 iteration 4916 : loss : 0.014824, loss_ce: 0.004253
2022-01-14 13:04:23,136 iteration 4917 : loss : 0.025912, loss_ce: 0.007182
2022-01-14 13:04:24,161 iteration 4918 : loss : 0.020453, loss_ce: 0.007028
2022-01-14 13:04:25,305 iteration 4919 : loss : 0.038892, loss_ce: 0.018466
2022-01-14 13:04:26,290 iteration 4920 : loss : 0.017874, loss_ce: 0.007039
2022-01-14 13:04:27,240 iteration 4921 : loss : 0.021626, loss_ce: 0.012040
2022-01-14 13:04:28,167 iteration 4922 : loss : 0.016189, loss_ce: 0.004055
2022-01-14 13:04:29,201 iteration 4923 : loss : 0.023622, loss_ce: 0.008739
2022-01-14 13:04:30,264 iteration 4924 : loss : 0.031757, loss_ce: 0.014961
2022-01-14 13:04:31,285 iteration 4925 : loss : 0.022634, loss_ce: 0.008437
2022-01-14 13:04:32,339 iteration 4926 : loss : 0.024181, loss_ce: 0.011248
2022-01-14 13:04:33,325 iteration 4927 : loss : 0.016928, loss_ce: 0.005600
2022-01-14 13:04:34,384 iteration 4928 : loss : 0.034487, loss_ce: 0.011083
2022-01-14 13:04:35,464 iteration 4929 : loss : 0.028559, loss_ce: 0.012597
2022-01-14 13:04:35,464 Training Data Eval:
2022-01-14 13:04:40,279   Average segmentation loss on training set: 0.0134
2022-01-14 13:04:40,279 Validation Data Eval:
2022-01-14 13:04:41,900   Average segmentation loss on validation set: 0.0656
2022-01-14 13:04:42,902 iteration 4930 : loss : 0.023158, loss_ce: 0.006513
 72%|█████████████████████        | 290/400 [1:29:16<35:36, 19.42s/it]2022-01-14 13:04:43,944 iteration 4931 : loss : 0.019389, loss_ce: 0.008009
2022-01-14 13:04:44,975 iteration 4932 : loss : 0.029060, loss_ce: 0.013206
2022-01-14 13:04:45,914 iteration 4933 : loss : 0.018346, loss_ce: 0.008928
2022-01-14 13:04:46,975 iteration 4934 : loss : 0.030301, loss_ce: 0.010916
2022-01-14 13:04:47,972 iteration 4935 : loss : 0.027519, loss_ce: 0.008404
2022-01-14 13:04:48,993 iteration 4936 : loss : 0.020727, loss_ce: 0.007657
2022-01-14 13:04:50,003 iteration 4937 : loss : 0.015792, loss_ce: 0.006503
2022-01-14 13:04:51,054 iteration 4938 : loss : 0.039051, loss_ce: 0.012936
2022-01-14 13:04:52,103 iteration 4939 : loss : 0.022792, loss_ce: 0.007605
2022-01-14 13:04:53,089 iteration 4940 : loss : 0.023030, loss_ce: 0.009568
2022-01-14 13:04:54,117 iteration 4941 : loss : 0.025981, loss_ce: 0.010486
2022-01-14 13:04:55,135 iteration 4942 : loss : 0.021161, loss_ce: 0.006911
2022-01-14 13:04:56,232 iteration 4943 : loss : 0.043207, loss_ce: 0.010620
2022-01-14 13:04:57,236 iteration 4944 : loss : 0.023952, loss_ce: 0.006759
2022-01-14 13:04:58,279 iteration 4945 : loss : 0.023493, loss_ce: 0.008942
2022-01-14 13:04:59,345 iteration 4946 : loss : 0.026461, loss_ce: 0.007275
2022-01-14 13:05:00,341 iteration 4947 : loss : 0.022965, loss_ce: 0.008077
 73%|█████████████████████        | 291/400 [1:29:34<34:12, 18.83s/it]2022-01-14 13:05:01,428 iteration 4948 : loss : 0.025586, loss_ce: 0.008102
2022-01-14 13:05:02,408 iteration 4949 : loss : 0.040979, loss_ce: 0.016018
2022-01-14 13:05:03,450 iteration 4950 : loss : 0.023140, loss_ce: 0.009109
2022-01-14 13:05:04,481 iteration 4951 : loss : 0.022018, loss_ce: 0.007158
2022-01-14 13:05:05,503 iteration 4952 : loss : 0.016725, loss_ce: 0.008454
2022-01-14 13:05:06,545 iteration 4953 : loss : 0.017281, loss_ce: 0.007201
2022-01-14 13:05:07,555 iteration 4954 : loss : 0.017324, loss_ce: 0.006199
2022-01-14 13:05:08,494 iteration 4955 : loss : 0.021949, loss_ce: 0.006592
2022-01-14 13:05:09,488 iteration 4956 : loss : 0.025198, loss_ce: 0.008891
2022-01-14 13:05:10,398 iteration 4957 : loss : 0.017230, loss_ce: 0.006529
2022-01-14 13:05:11,411 iteration 4958 : loss : 0.024399, loss_ce: 0.011812
2022-01-14 13:05:12,416 iteration 4959 : loss : 0.023391, loss_ce: 0.007668
2022-01-14 13:05:13,342 iteration 4960 : loss : 0.019080, loss_ce: 0.007014
2022-01-14 13:05:14,350 iteration 4961 : loss : 0.017655, loss_ce: 0.006494
2022-01-14 13:05:15,293 iteration 4962 : loss : 0.027747, loss_ce: 0.005490
2022-01-14 13:05:16,268 iteration 4963 : loss : 0.018689, loss_ce: 0.007316
2022-01-14 13:05:17,317 iteration 4964 : loss : 0.030795, loss_ce: 0.012608
 73%|█████████████████████▏       | 292/400 [1:29:51<32:53, 18.27s/it]2022-01-14 13:05:18,447 iteration 4965 : loss : 0.028447, loss_ce: 0.013803
2022-01-14 13:05:19,509 iteration 4966 : loss : 0.019811, loss_ce: 0.007882
2022-01-14 13:05:20,525 iteration 4967 : loss : 0.028546, loss_ce: 0.012974
2022-01-14 13:05:21,560 iteration 4968 : loss : 0.026756, loss_ce: 0.012011
2022-01-14 13:05:22,675 iteration 4969 : loss : 0.032228, loss_ce: 0.009268
2022-01-14 13:05:23,634 iteration 4970 : loss : 0.019350, loss_ce: 0.008529
2022-01-14 13:05:24,612 iteration 4971 : loss : 0.023615, loss_ce: 0.012905
2022-01-14 13:05:25,649 iteration 4972 : loss : 0.024866, loss_ce: 0.010785
2022-01-14 13:05:26,657 iteration 4973 : loss : 0.020025, loss_ce: 0.007329
2022-01-14 13:05:27,786 iteration 4974 : loss : 0.023173, loss_ce: 0.007430
2022-01-14 13:05:28,781 iteration 4975 : loss : 0.017370, loss_ce: 0.005066
2022-01-14 13:05:29,730 iteration 4976 : loss : 0.017425, loss_ce: 0.007053
2022-01-14 13:05:30,761 iteration 4977 : loss : 0.022772, loss_ce: 0.004694
2022-01-14 13:05:31,749 iteration 4978 : loss : 0.016643, loss_ce: 0.004267
2022-01-14 13:05:32,745 iteration 4979 : loss : 0.020672, loss_ce: 0.007881
2022-01-14 13:05:33,757 iteration 4980 : loss : 0.029301, loss_ce: 0.008250
2022-01-14 13:05:34,752 iteration 4981 : loss : 0.033493, loss_ce: 0.009518
 73%|█████████████████████▏       | 293/400 [1:30:08<32:08, 18.02s/it]2022-01-14 13:05:35,790 iteration 4982 : loss : 0.018202, loss_ce: 0.008762
2022-01-14 13:05:36,774 iteration 4983 : loss : 0.018595, loss_ce: 0.007893
2022-01-14 13:05:37,878 iteration 4984 : loss : 0.027716, loss_ce: 0.012926
2022-01-14 13:05:38,810 iteration 4985 : loss : 0.017345, loss_ce: 0.004762
2022-01-14 13:05:39,888 iteration 4986 : loss : 0.029251, loss_ce: 0.014380
2022-01-14 13:05:40,837 iteration 4987 : loss : 0.018087, loss_ce: 0.005453
2022-01-14 13:05:41,851 iteration 4988 : loss : 0.023586, loss_ce: 0.006980
2022-01-14 13:05:42,903 iteration 4989 : loss : 0.020892, loss_ce: 0.007393
2022-01-14 13:05:43,986 iteration 4990 : loss : 0.027227, loss_ce: 0.011338
2022-01-14 13:05:45,010 iteration 4991 : loss : 0.028262, loss_ce: 0.009053
2022-01-14 13:05:45,930 iteration 4992 : loss : 0.015699, loss_ce: 0.007307
2022-01-14 13:05:46,916 iteration 4993 : loss : 0.023313, loss_ce: 0.008263
2022-01-14 13:05:47,866 iteration 4994 : loss : 0.018758, loss_ce: 0.006471
2022-01-14 13:05:48,834 iteration 4995 : loss : 0.022882, loss_ce: 0.009260
2022-01-14 13:05:49,889 iteration 4996 : loss : 0.021838, loss_ce: 0.006016
2022-01-14 13:05:50,819 iteration 4997 : loss : 0.017261, loss_ce: 0.005196
2022-01-14 13:05:51,761 iteration 4998 : loss : 0.016971, loss_ce: 0.006469
 74%|█████████████████████▎       | 294/400 [1:30:25<31:18, 17.72s/it]2022-01-14 13:05:52,785 iteration 4999 : loss : 0.016490, loss_ce: 0.005944
2022-01-14 13:05:53,763 iteration 5000 : loss : 0.016588, loss_ce: 0.006751
2022-01-14 13:05:54,751 iteration 5001 : loss : 0.020261, loss_ce: 0.007973
2022-01-14 13:05:55,730 iteration 5002 : loss : 0.013721, loss_ce: 0.004474
2022-01-14 13:05:56,756 iteration 5003 : loss : 0.029792, loss_ce: 0.006088
2022-01-14 13:05:57,743 iteration 5004 : loss : 0.028626, loss_ce: 0.009858
2022-01-14 13:05:58,736 iteration 5005 : loss : 0.027509, loss_ce: 0.014762
2022-01-14 13:05:59,786 iteration 5006 : loss : 0.020470, loss_ce: 0.008284
2022-01-14 13:06:00,820 iteration 5007 : loss : 0.028148, loss_ce: 0.012552
2022-01-14 13:06:01,867 iteration 5008 : loss : 0.021967, loss_ce: 0.008332
2022-01-14 13:06:02,917 iteration 5009 : loss : 0.019637, loss_ce: 0.005894
2022-01-14 13:06:03,952 iteration 5010 : loss : 0.022936, loss_ce: 0.008137
2022-01-14 13:06:04,934 iteration 5011 : loss : 0.032128, loss_ce: 0.013597
2022-01-14 13:06:05,947 iteration 5012 : loss : 0.022187, loss_ce: 0.008217
2022-01-14 13:06:06,888 iteration 5013 : loss : 0.019049, loss_ce: 0.007307
2022-01-14 13:06:07,877 iteration 5014 : loss : 0.022596, loss_ce: 0.007822
2022-01-14 13:06:07,877 Training Data Eval:
2022-01-14 13:06:12,692   Average segmentation loss on training set: 0.0126
2022-01-14 13:06:12,692 Validation Data Eval:
2022-01-14 13:06:14,311   Average segmentation loss on validation set: 0.0704
2022-01-14 13:06:15,301 iteration 5015 : loss : 0.020488, loss_ce: 0.006788
 74%|█████████████████████▍       | 295/400 [1:30:49<34:03, 19.46s/it]2022-01-14 13:06:16,350 iteration 5016 : loss : 0.023977, loss_ce: 0.010655
2022-01-14 13:06:17,322 iteration 5017 : loss : 0.017527, loss_ce: 0.005660
2022-01-14 13:06:18,315 iteration 5018 : loss : 0.022452, loss_ce: 0.009235
2022-01-14 13:06:19,329 iteration 5019 : loss : 0.016764, loss_ce: 0.005149
2022-01-14 13:06:20,348 iteration 5020 : loss : 0.023272, loss_ce: 0.006221
2022-01-14 13:06:21,393 iteration 5021 : loss : 0.020801, loss_ce: 0.011178
2022-01-14 13:06:22,342 iteration 5022 : loss : 0.017862, loss_ce: 0.005929
2022-01-14 13:06:23,339 iteration 5023 : loss : 0.026085, loss_ce: 0.007373
2022-01-14 13:06:24,431 iteration 5024 : loss : 0.051370, loss_ce: 0.012579
2022-01-14 13:06:25,497 iteration 5025 : loss : 0.052802, loss_ce: 0.009164
2022-01-14 13:06:26,514 iteration 5026 : loss : 0.018438, loss_ce: 0.006428
2022-01-14 13:06:27,483 iteration 5027 : loss : 0.023019, loss_ce: 0.010012
2022-01-14 13:06:28,465 iteration 5028 : loss : 0.023650, loss_ce: 0.009530
2022-01-14 13:06:29,553 iteration 5029 : loss : 0.034875, loss_ce: 0.009288
2022-01-14 13:06:30,556 iteration 5030 : loss : 0.024245, loss_ce: 0.012052
2022-01-14 13:06:31,621 iteration 5031 : loss : 0.036591, loss_ce: 0.019802
2022-01-14 13:06:32,629 iteration 5032 : loss : 0.026714, loss_ce: 0.012243
 74%|█████████████████████▍       | 296/400 [1:31:06<32:37, 18.82s/it]2022-01-14 13:06:33,805 iteration 5033 : loss : 0.028816, loss_ce: 0.008642
2022-01-14 13:06:34,793 iteration 5034 : loss : 0.025590, loss_ce: 0.006795
2022-01-14 13:06:35,764 iteration 5035 : loss : 0.019584, loss_ce: 0.008220
2022-01-14 13:06:36,741 iteration 5036 : loss : 0.025388, loss_ce: 0.009353
2022-01-14 13:06:37,748 iteration 5037 : loss : 0.028011, loss_ce: 0.010363
2022-01-14 13:06:38,720 iteration 5038 : loss : 0.028089, loss_ce: 0.006271
2022-01-14 13:06:39,807 iteration 5039 : loss : 0.021427, loss_ce: 0.010239
2022-01-14 13:06:40,819 iteration 5040 : loss : 0.018323, loss_ce: 0.005735
2022-01-14 13:06:41,887 iteration 5041 : loss : 0.018314, loss_ce: 0.007017
2022-01-14 13:06:42,855 iteration 5042 : loss : 0.016124, loss_ce: 0.006251
2022-01-14 13:06:43,859 iteration 5043 : loss : 0.017209, loss_ce: 0.007679
2022-01-14 13:06:44,877 iteration 5044 : loss : 0.022890, loss_ce: 0.010272
2022-01-14 13:06:45,939 iteration 5045 : loss : 0.024567, loss_ce: 0.009744
2022-01-14 13:06:46,961 iteration 5046 : loss : 0.028150, loss_ce: 0.007844
2022-01-14 13:06:47,948 iteration 5047 : loss : 0.024182, loss_ce: 0.007015
2022-01-14 13:06:48,924 iteration 5048 : loss : 0.017766, loss_ce: 0.007226
2022-01-14 13:06:49,900 iteration 5049 : loss : 0.015617, loss_ce: 0.006012
 74%|█████████████████████▌       | 297/400 [1:31:23<31:30, 18.36s/it]2022-01-14 13:06:50,968 iteration 5050 : loss : 0.021001, loss_ce: 0.006370
2022-01-14 13:06:51,956 iteration 5051 : loss : 0.025208, loss_ce: 0.008527
2022-01-14 13:06:52,945 iteration 5052 : loss : 0.020294, loss_ce: 0.009053
2022-01-14 13:06:53,929 iteration 5053 : loss : 0.014798, loss_ce: 0.005874
2022-01-14 13:06:54,929 iteration 5054 : loss : 0.017077, loss_ce: 0.005095
2022-01-14 13:06:55,914 iteration 5055 : loss : 0.018829, loss_ce: 0.006032
2022-01-14 13:06:56,890 iteration 5056 : loss : 0.029168, loss_ce: 0.007169
2022-01-14 13:06:57,940 iteration 5057 : loss : 0.017658, loss_ce: 0.009332
2022-01-14 13:06:59,004 iteration 5058 : loss : 0.026558, loss_ce: 0.011862
2022-01-14 13:06:59,893 iteration 5059 : loss : 0.020586, loss_ce: 0.005124
2022-01-14 13:07:00,891 iteration 5060 : loss : 0.028788, loss_ce: 0.008001
2022-01-14 13:07:01,919 iteration 5061 : loss : 0.024534, loss_ce: 0.009319
2022-01-14 13:07:02,935 iteration 5062 : loss : 0.026689, loss_ce: 0.008120
2022-01-14 13:07:03,999 iteration 5063 : loss : 0.020779, loss_ce: 0.008963
2022-01-14 13:07:04,966 iteration 5064 : loss : 0.022912, loss_ce: 0.009113
2022-01-14 13:07:05,939 iteration 5065 : loss : 0.023711, loss_ce: 0.008126
2022-01-14 13:07:06,945 iteration 5066 : loss : 0.017864, loss_ce: 0.008919
 74%|█████████████████████▌       | 298/400 [1:31:40<30:32, 17.96s/it]2022-01-14 13:07:08,091 iteration 5067 : loss : 0.024750, loss_ce: 0.010765
2022-01-14 13:07:09,117 iteration 5068 : loss : 0.020654, loss_ce: 0.007759
2022-01-14 13:07:10,146 iteration 5069 : loss : 0.030034, loss_ce: 0.009040
2022-01-14 13:07:11,134 iteration 5070 : loss : 0.019603, loss_ce: 0.005762
2022-01-14 13:07:12,200 iteration 5071 : loss : 0.022448, loss_ce: 0.008085
2022-01-14 13:07:13,089 iteration 5072 : loss : 0.016946, loss_ce: 0.005618
2022-01-14 13:07:14,077 iteration 5073 : loss : 0.018713, loss_ce: 0.008792
2022-01-14 13:07:15,114 iteration 5074 : loss : 0.022519, loss_ce: 0.007415
2022-01-14 13:07:16,118 iteration 5075 : loss : 0.018614, loss_ce: 0.007383
2022-01-14 13:07:17,173 iteration 5076 : loss : 0.018039, loss_ce: 0.007303
2022-01-14 13:07:18,150 iteration 5077 : loss : 0.017534, loss_ce: 0.006232
2022-01-14 13:07:19,167 iteration 5078 : loss : 0.017845, loss_ce: 0.004940
2022-01-14 13:07:20,144 iteration 5079 : loss : 0.019865, loss_ce: 0.007485
2022-01-14 13:07:21,152 iteration 5080 : loss : 0.021437, loss_ce: 0.007224
2022-01-14 13:07:22,184 iteration 5081 : loss : 0.021231, loss_ce: 0.009234
2022-01-14 13:07:23,242 iteration 5082 : loss : 0.030717, loss_ce: 0.016194
2022-01-14 13:07:24,275 iteration 5083 : loss : 0.020202, loss_ce: 0.006485
 75%|█████████████████████▋       | 299/400 [1:31:58<29:55, 17.77s/it]2022-01-14 13:07:25,316 iteration 5084 : loss : 0.019892, loss_ce: 0.006205
2022-01-14 13:07:26,320 iteration 5085 : loss : 0.032966, loss_ce: 0.011487
2022-01-14 13:07:27,290 iteration 5086 : loss : 0.014958, loss_ce: 0.005355
2022-01-14 13:07:28,342 iteration 5087 : loss : 0.024272, loss_ce: 0.009775
2022-01-14 13:07:29,363 iteration 5088 : loss : 0.019854, loss_ce: 0.007304
2022-01-14 13:07:30,323 iteration 5089 : loss : 0.016880, loss_ce: 0.005393
2022-01-14 13:07:31,294 iteration 5090 : loss : 0.016516, loss_ce: 0.005452
2022-01-14 13:07:32,388 iteration 5091 : loss : 0.037150, loss_ce: 0.016121
2022-01-14 13:07:33,392 iteration 5092 : loss : 0.014602, loss_ce: 0.006993
2022-01-14 13:07:34,365 iteration 5093 : loss : 0.017620, loss_ce: 0.008127
2022-01-14 13:07:35,315 iteration 5094 : loss : 0.014342, loss_ce: 0.005229
2022-01-14 13:07:36,356 iteration 5095 : loss : 0.021816, loss_ce: 0.008480
2022-01-14 13:07:37,309 iteration 5096 : loss : 0.015092, loss_ce: 0.006369
2022-01-14 13:07:38,273 iteration 5097 : loss : 0.017430, loss_ce: 0.008136
2022-01-14 13:07:39,290 iteration 5098 : loss : 0.029325, loss_ce: 0.010766
2022-01-14 13:07:40,280 iteration 5099 : loss : 0.015677, loss_ce: 0.005336
2022-01-14 13:07:40,280 Training Data Eval:
2022-01-14 13:07:45,091   Average segmentation loss on training set: 0.0115
2022-01-14 13:07:45,092 Validation Data Eval:
2022-01-14 13:07:46,703   Average segmentation loss on validation set: 0.0714
2022-01-14 13:07:47,694 iteration 5100 : loss : 0.014724, loss_ce: 0.006929
 75%|█████████████████████▊       | 300/400 [1:32:21<32:26, 19.47s/it]2022-01-14 13:07:48,767 iteration 5101 : loss : 0.016681, loss_ce: 0.007052
2022-01-14 13:07:49,733 iteration 5102 : loss : 0.014101, loss_ce: 0.005868
2022-01-14 13:07:50,718 iteration 5103 : loss : 0.016380, loss_ce: 0.006615
2022-01-14 13:07:51,790 iteration 5104 : loss : 0.017487, loss_ce: 0.007125
2022-01-14 13:07:52,768 iteration 5105 : loss : 0.022964, loss_ce: 0.007792
2022-01-14 13:07:53,838 iteration 5106 : loss : 0.017330, loss_ce: 0.006215
2022-01-14 13:07:54,789 iteration 5107 : loss : 0.021344, loss_ce: 0.008120
2022-01-14 13:07:55,816 iteration 5108 : loss : 0.021860, loss_ce: 0.007265
2022-01-14 13:07:56,817 iteration 5109 : loss : 0.032682, loss_ce: 0.008529
2022-01-14 13:07:57,806 iteration 5110 : loss : 0.018499, loss_ce: 0.007724
2022-01-14 13:07:58,834 iteration 5111 : loss : 0.016781, loss_ce: 0.005276
2022-01-14 13:07:59,785 iteration 5112 : loss : 0.019666, loss_ce: 0.006400
2022-01-14 13:08:00,846 iteration 5113 : loss : 0.048459, loss_ce: 0.008138
2022-01-14 13:08:01,831 iteration 5114 : loss : 0.018606, loss_ce: 0.008938
2022-01-14 13:08:02,793 iteration 5115 : loss : 0.023651, loss_ce: 0.007074
2022-01-14 13:08:03,762 iteration 5116 : loss : 0.017230, loss_ce: 0.006651
2022-01-14 13:08:04,821 iteration 5117 : loss : 0.024979, loss_ce: 0.013776
 75%|█████████████████████▊       | 301/400 [1:32:38<30:58, 18.77s/it]2022-01-14 13:08:05,948 iteration 5118 : loss : 0.022992, loss_ce: 0.008325
2022-01-14 13:08:06,967 iteration 5119 : loss : 0.021301, loss_ce: 0.006698
2022-01-14 13:08:07,936 iteration 5120 : loss : 0.029837, loss_ce: 0.008133
2022-01-14 13:08:08,934 iteration 5121 : loss : 0.032458, loss_ce: 0.012715
2022-01-14 13:08:09,891 iteration 5122 : loss : 0.030619, loss_ce: 0.011890
2022-01-14 13:08:10,881 iteration 5123 : loss : 0.022138, loss_ce: 0.005847
2022-01-14 13:08:11,902 iteration 5124 : loss : 0.016892, loss_ce: 0.006607
2022-01-14 13:08:12,808 iteration 5125 : loss : 0.021181, loss_ce: 0.010130
2022-01-14 13:08:13,755 iteration 5126 : loss : 0.023162, loss_ce: 0.007922
2022-01-14 13:08:14,794 iteration 5127 : loss : 0.025898, loss_ce: 0.008220
2022-01-14 13:08:15,765 iteration 5128 : loss : 0.016896, loss_ce: 0.006986
2022-01-14 13:08:16,780 iteration 5129 : loss : 0.026999, loss_ce: 0.007986
2022-01-14 13:08:17,780 iteration 5130 : loss : 0.020166, loss_ce: 0.006621
2022-01-14 13:08:18,698 iteration 5131 : loss : 0.013011, loss_ce: 0.004687
2022-01-14 13:08:19,684 iteration 5132 : loss : 0.018272, loss_ce: 0.007940
2022-01-14 13:08:20,663 iteration 5133 : loss : 0.033546, loss_ce: 0.008947
2022-01-14 13:08:21,604 iteration 5134 : loss : 0.020647, loss_ce: 0.008781
 76%|█████████████████████▉       | 302/400 [1:32:55<29:40, 18.17s/it]2022-01-14 13:08:22,803 iteration 5135 : loss : 0.024171, loss_ce: 0.009853
2022-01-14 13:08:23,803 iteration 5136 : loss : 0.025663, loss_ce: 0.007682
2022-01-14 13:08:24,848 iteration 5137 : loss : 0.022414, loss_ce: 0.007266
2022-01-14 13:08:25,808 iteration 5138 : loss : 0.017593, loss_ce: 0.007558
2022-01-14 13:08:26,803 iteration 5139 : loss : 0.015200, loss_ce: 0.005552
2022-01-14 13:08:27,885 iteration 5140 : loss : 0.017590, loss_ce: 0.006868
2022-01-14 13:08:28,842 iteration 5141 : loss : 0.020872, loss_ce: 0.007301
2022-01-14 13:08:29,857 iteration 5142 : loss : 0.023409, loss_ce: 0.007930
2022-01-14 13:08:30,781 iteration 5143 : loss : 0.019472, loss_ce: 0.007282
2022-01-14 13:08:31,809 iteration 5144 : loss : 0.018835, loss_ce: 0.009841
2022-01-14 13:08:32,724 iteration 5145 : loss : 0.013884, loss_ce: 0.004428
2022-01-14 13:08:33,789 iteration 5146 : loss : 0.021886, loss_ce: 0.008963
2022-01-14 13:08:34,851 iteration 5147 : loss : 0.018286, loss_ce: 0.006645
2022-01-14 13:08:35,827 iteration 5148 : loss : 0.020286, loss_ce: 0.008041
2022-01-14 13:08:36,803 iteration 5149 : loss : 0.025771, loss_ce: 0.006954
2022-01-14 13:08:37,778 iteration 5150 : loss : 0.021460, loss_ce: 0.009093
2022-01-14 13:08:38,780 iteration 5151 : loss : 0.031037, loss_ce: 0.005129
 76%|█████████████████████▉       | 303/400 [1:33:12<28:53, 17.87s/it]2022-01-14 13:08:39,791 iteration 5152 : loss : 0.018092, loss_ce: 0.003730
2022-01-14 13:08:40,697 iteration 5153 : loss : 0.013755, loss_ce: 0.005576
2022-01-14 13:08:41,764 iteration 5154 : loss : 0.026790, loss_ce: 0.010056
2022-01-14 13:08:42,701 iteration 5155 : loss : 0.012905, loss_ce: 0.004511
2022-01-14 13:08:43,678 iteration 5156 : loss : 0.020502, loss_ce: 0.007841
2022-01-14 13:08:44,604 iteration 5157 : loss : 0.015122, loss_ce: 0.004873
2022-01-14 13:08:45,573 iteration 5158 : loss : 0.019181, loss_ce: 0.006345
2022-01-14 13:08:46,615 iteration 5159 : loss : 0.018396, loss_ce: 0.006496
2022-01-14 13:08:47,549 iteration 5160 : loss : 0.019011, loss_ce: 0.006184
2022-01-14 13:08:48,526 iteration 5161 : loss : 0.016251, loss_ce: 0.006421
2022-01-14 13:08:49,461 iteration 5162 : loss : 0.018610, loss_ce: 0.007924
2022-01-14 13:08:50,467 iteration 5163 : loss : 0.018890, loss_ce: 0.007960
2022-01-14 13:08:51,487 iteration 5164 : loss : 0.019610, loss_ce: 0.009038
2022-01-14 13:08:52,422 iteration 5165 : loss : 0.019640, loss_ce: 0.006291
2022-01-14 13:08:53,414 iteration 5166 : loss : 0.017495, loss_ce: 0.007618
2022-01-14 13:08:54,424 iteration 5167 : loss : 0.024335, loss_ce: 0.008425
2022-01-14 13:08:55,474 iteration 5168 : loss : 0.027022, loss_ce: 0.011273
 76%|██████████████████████       | 304/400 [1:33:29<28:01, 17.52s/it]2022-01-14 13:08:56,635 iteration 5169 : loss : 0.024818, loss_ce: 0.011116
2022-01-14 13:08:57,579 iteration 5170 : loss : 0.017880, loss_ce: 0.005166
2022-01-14 13:08:58,633 iteration 5171 : loss : 0.015715, loss_ce: 0.006384
2022-01-14 13:08:59,555 iteration 5172 : loss : 0.016389, loss_ce: 0.004714
2022-01-14 13:09:00,422 iteration 5173 : loss : 0.013359, loss_ce: 0.005633
2022-01-14 13:09:01,478 iteration 5174 : loss : 0.024168, loss_ce: 0.007827
2022-01-14 13:09:02,433 iteration 5175 : loss : 0.017417, loss_ce: 0.007866
2022-01-14 13:09:03,547 iteration 5176 : loss : 0.018820, loss_ce: 0.006681
2022-01-14 13:09:04,501 iteration 5177 : loss : 0.017732, loss_ce: 0.007137
2022-01-14 13:09:05,477 iteration 5178 : loss : 0.014666, loss_ce: 0.004464
2022-01-14 13:09:06,521 iteration 5179 : loss : 0.017704, loss_ce: 0.005627
2022-01-14 13:09:07,517 iteration 5180 : loss : 0.021943, loss_ce: 0.008191
2022-01-14 13:09:08,470 iteration 5181 : loss : 0.025760, loss_ce: 0.008456
2022-01-14 13:09:09,464 iteration 5182 : loss : 0.024985, loss_ce: 0.010175
2022-01-14 13:09:10,432 iteration 5183 : loss : 0.019480, loss_ce: 0.008442
2022-01-14 13:09:11,384 iteration 5184 : loss : 0.022170, loss_ce: 0.007855
2022-01-14 13:09:11,384 Training Data Eval:
2022-01-14 13:09:16,196   Average segmentation loss on training set: 0.0117
2022-01-14 13:09:16,197 Validation Data Eval:
2022-01-14 13:09:17,807   Average segmentation loss on validation set: 0.0742
2022-01-14 13:09:18,782 iteration 5185 : loss : 0.023938, loss_ce: 0.008655
 76%|██████████████████████       | 305/400 [1:33:52<30:29, 19.26s/it]2022-01-14 13:09:19,849 iteration 5186 : loss : 0.018197, loss_ce: 0.009457
2022-01-14 13:09:20,791 iteration 5187 : loss : 0.019920, loss_ce: 0.007566
2022-01-14 13:09:21,744 iteration 5188 : loss : 0.014844, loss_ce: 0.006099
2022-01-14 13:09:22,700 iteration 5189 : loss : 0.014323, loss_ce: 0.006738
2022-01-14 13:09:23,639 iteration 5190 : loss : 0.021727, loss_ce: 0.010331
2022-01-14 13:09:24,680 iteration 5191 : loss : 0.022258, loss_ce: 0.006214
2022-01-14 13:09:25,704 iteration 5192 : loss : 0.016555, loss_ce: 0.005400
2022-01-14 13:09:26,646 iteration 5193 : loss : 0.013795, loss_ce: 0.004576
2022-01-14 13:09:27,668 iteration 5194 : loss : 0.028344, loss_ce: 0.011216
2022-01-14 13:09:28,627 iteration 5195 : loss : 0.016697, loss_ce: 0.005535
2022-01-14 13:09:29,521 iteration 5196 : loss : 0.014735, loss_ce: 0.003674
2022-01-14 13:09:30,516 iteration 5197 : loss : 0.014050, loss_ce: 0.004441
2022-01-14 13:09:31,463 iteration 5198 : loss : 0.015824, loss_ce: 0.007609
2022-01-14 13:09:32,473 iteration 5199 : loss : 0.014194, loss_ce: 0.004507
2022-01-14 13:09:33,458 iteration 5200 : loss : 0.019920, loss_ce: 0.005866
2022-01-14 13:09:34,467 iteration 5201 : loss : 0.019739, loss_ce: 0.005916
2022-01-14 13:09:35,535 iteration 5202 : loss : 0.025264, loss_ce: 0.011743
 76%|██████████████████████▏      | 306/400 [1:34:09<28:59, 18.50s/it]2022-01-14 13:09:36,550 iteration 5203 : loss : 0.013554, loss_ce: 0.004917
2022-01-14 13:09:37,515 iteration 5204 : loss : 0.017449, loss_ce: 0.007158
2022-01-14 13:09:38,626 iteration 5205 : loss : 0.023060, loss_ce: 0.009301
2022-01-14 13:09:39,613 iteration 5206 : loss : 0.018867, loss_ce: 0.006504
2022-01-14 13:09:40,611 iteration 5207 : loss : 0.022593, loss_ce: 0.009538
2022-01-14 13:09:41,679 iteration 5208 : loss : 0.021589, loss_ce: 0.008994
2022-01-14 13:09:42,621 iteration 5209 : loss : 0.015349, loss_ce: 0.006419
2022-01-14 13:09:43,653 iteration 5210 : loss : 0.017092, loss_ce: 0.006064
2022-01-14 13:09:44,663 iteration 5211 : loss : 0.015822, loss_ce: 0.006340
2022-01-14 13:09:45,658 iteration 5212 : loss : 0.015543, loss_ce: 0.005469
2022-01-14 13:09:46,547 iteration 5213 : loss : 0.014037, loss_ce: 0.005354
2022-01-14 13:09:47,626 iteration 5214 : loss : 0.023383, loss_ce: 0.010796
2022-01-14 13:09:48,648 iteration 5215 : loss : 0.020891, loss_ce: 0.006941
2022-01-14 13:09:49,702 iteration 5216 : loss : 0.018047, loss_ce: 0.005991
2022-01-14 13:09:50,784 iteration 5217 : loss : 0.018907, loss_ce: 0.006734
2022-01-14 13:09:51,742 iteration 5218 : loss : 0.017019, loss_ce: 0.003231
2022-01-14 13:09:52,826 iteration 5219 : loss : 0.018620, loss_ce: 0.005815
 77%|██████████████████████▎      | 307/400 [1:34:26<28:07, 18.14s/it]2022-01-14 13:09:53,865 iteration 5220 : loss : 0.018335, loss_ce: 0.005767
2022-01-14 13:09:54,848 iteration 5221 : loss : 0.032964, loss_ce: 0.012098
2022-01-14 13:09:55,787 iteration 5222 : loss : 0.021610, loss_ce: 0.008227
2022-01-14 13:09:56,830 iteration 5223 : loss : 0.018347, loss_ce: 0.007234
2022-01-14 13:09:57,815 iteration 5224 : loss : 0.017085, loss_ce: 0.005319
2022-01-14 13:09:58,864 iteration 5225 : loss : 0.019660, loss_ce: 0.006263
2022-01-14 13:09:59,844 iteration 5226 : loss : 0.020362, loss_ce: 0.006907
2022-01-14 13:10:00,920 iteration 5227 : loss : 0.019898, loss_ce: 0.008757
2022-01-14 13:10:01,880 iteration 5228 : loss : 0.019714, loss_ce: 0.005329
2022-01-14 13:10:03,001 iteration 5229 : loss : 0.022245, loss_ce: 0.009645
2022-01-14 13:10:03,894 iteration 5230 : loss : 0.012801, loss_ce: 0.005578
2022-01-14 13:10:04,913 iteration 5231 : loss : 0.023791, loss_ce: 0.009372
2022-01-14 13:10:05,912 iteration 5232 : loss : 0.018975, loss_ce: 0.006014
2022-01-14 13:10:06,942 iteration 5233 : loss : 0.018038, loss_ce: 0.006533
2022-01-14 13:10:07,905 iteration 5234 : loss : 0.016871, loss_ce: 0.007343
2022-01-14 13:10:08,908 iteration 5235 : loss : 0.018939, loss_ce: 0.006476
2022-01-14 13:10:09,946 iteration 5236 : loss : 0.023190, loss_ce: 0.008523
 77%|██████████████████████▎      | 308/400 [1:34:43<27:20, 17.83s/it]2022-01-14 13:10:10,882 iteration 5237 : loss : 0.012658, loss_ce: 0.005333
2022-01-14 13:10:11,915 iteration 5238 : loss : 0.023184, loss_ce: 0.009255
2022-01-14 13:10:12,935 iteration 5239 : loss : 0.020443, loss_ce: 0.006218
2022-01-14 13:10:13,971 iteration 5240 : loss : 0.172874, loss_ce: 0.003851
2022-01-14 13:10:14,937 iteration 5241 : loss : 0.015696, loss_ce: 0.006304
2022-01-14 13:10:15,930 iteration 5242 : loss : 0.023833, loss_ce: 0.009882
2022-01-14 13:10:17,009 iteration 5243 : loss : 0.021043, loss_ce: 0.006548
2022-01-14 13:10:18,041 iteration 5244 : loss : 0.025928, loss_ce: 0.014087
2022-01-14 13:10:19,049 iteration 5245 : loss : 0.018522, loss_ce: 0.006262
2022-01-14 13:10:20,072 iteration 5246 : loss : 0.021660, loss_ce: 0.006479
2022-01-14 13:10:20,994 iteration 5247 : loss : 0.014461, loss_ce: 0.005755
2022-01-14 13:10:22,033 iteration 5248 : loss : 0.016489, loss_ce: 0.005237
2022-01-14 13:10:23,114 iteration 5249 : loss : 0.019775, loss_ce: 0.006475
2022-01-14 13:10:24,141 iteration 5250 : loss : 0.020237, loss_ce: 0.009805
2022-01-14 13:10:25,062 iteration 5251 : loss : 0.014040, loss_ce: 0.005000
2022-01-14 13:10:26,066 iteration 5252 : loss : 0.015187, loss_ce: 0.006057
2022-01-14 13:10:27,090 iteration 5253 : loss : 0.042151, loss_ce: 0.008444
 77%|██████████████████████▍      | 309/400 [1:35:01<26:44, 17.63s/it]2022-01-14 13:10:28,142 iteration 5254 : loss : 0.013153, loss_ce: 0.004287
2022-01-14 13:10:29,139 iteration 5255 : loss : 0.022663, loss_ce: 0.012687
2022-01-14 13:10:30,073 iteration 5256 : loss : 0.017907, loss_ce: 0.007461
2022-01-14 13:10:31,081 iteration 5257 : loss : 0.016127, loss_ce: 0.006434
2022-01-14 13:10:32,126 iteration 5258 : loss : 0.024983, loss_ce: 0.005972
2022-01-14 13:10:33,078 iteration 5259 : loss : 0.020640, loss_ce: 0.005263
2022-01-14 13:10:34,095 iteration 5260 : loss : 0.016160, loss_ce: 0.005791
2022-01-14 13:10:35,118 iteration 5261 : loss : 0.023074, loss_ce: 0.010558
2022-01-14 13:10:36,115 iteration 5262 : loss : 0.014687, loss_ce: 0.006016
2022-01-14 13:10:37,158 iteration 5263 : loss : 0.019141, loss_ce: 0.008009
2022-01-14 13:10:38,102 iteration 5264 : loss : 0.013154, loss_ce: 0.005346
2022-01-14 13:10:39,137 iteration 5265 : loss : 0.020356, loss_ce: 0.006650
2022-01-14 13:10:40,222 iteration 5266 : loss : 0.020896, loss_ce: 0.006606
2022-01-14 13:10:41,225 iteration 5267 : loss : 0.029922, loss_ce: 0.007716
2022-01-14 13:10:42,241 iteration 5268 : loss : 0.025263, loss_ce: 0.008193
2022-01-14 13:10:43,349 iteration 5269 : loss : 0.018090, loss_ce: 0.004869
2022-01-14 13:10:43,350 Training Data Eval:
2022-01-14 13:10:48,168   Average segmentation loss on training set: 0.0109
2022-01-14 13:10:48,168 Validation Data Eval:
2022-01-14 13:10:49,783   Average segmentation loss on validation set: 0.0700
2022-01-14 13:10:50,773 iteration 5270 : loss : 0.019346, loss_ce: 0.009112
 78%|██████████████████████▍      | 310/400 [1:35:24<29:09, 19.44s/it]2022-01-14 13:10:51,798 iteration 5271 : loss : 0.016453, loss_ce: 0.006463
2022-01-14 13:10:52,818 iteration 5272 : loss : 0.025481, loss_ce: 0.011971
2022-01-14 13:10:53,781 iteration 5273 : loss : 0.016721, loss_ce: 0.004972
2022-01-14 13:10:54,754 iteration 5274 : loss : 0.016731, loss_ce: 0.006225
2022-01-14 13:10:55,673 iteration 5275 : loss : 0.013884, loss_ce: 0.006119
2022-01-14 13:10:56,694 iteration 5276 : loss : 0.025849, loss_ce: 0.011392
2022-01-14 13:10:57,701 iteration 5277 : loss : 0.021489, loss_ce: 0.008721
2022-01-14 13:10:58,613 iteration 5278 : loss : 0.015595, loss_ce: 0.006316
2022-01-14 13:10:59,604 iteration 5279 : loss : 0.016853, loss_ce: 0.007401
2022-01-14 13:11:00,727 iteration 5280 : loss : 0.027238, loss_ce: 0.010944
2022-01-14 13:11:01,704 iteration 5281 : loss : 0.015753, loss_ce: 0.005344
2022-01-14 13:11:02,637 iteration 5282 : loss : 0.015029, loss_ce: 0.004815
2022-01-14 13:11:03,636 iteration 5283 : loss : 0.021003, loss_ce: 0.006686
2022-01-14 13:11:04,649 iteration 5284 : loss : 0.031753, loss_ce: 0.010924
2022-01-14 13:11:05,636 iteration 5285 : loss : 0.017435, loss_ce: 0.007409
2022-01-14 13:11:06,549 iteration 5286 : loss : 0.014113, loss_ce: 0.005659
2022-01-14 13:11:07,528 iteration 5287 : loss : 0.017431, loss_ce: 0.003338
 78%|██████████████████████▌      | 311/400 [1:35:41<27:38, 18.64s/it]2022-01-14 13:11:08,618 iteration 5288 : loss : 0.021969, loss_ce: 0.008647
2022-01-14 13:11:09,647 iteration 5289 : loss : 0.034696, loss_ce: 0.019582
2022-01-14 13:11:10,631 iteration 5290 : loss : 0.025555, loss_ce: 0.007545
2022-01-14 13:11:11,600 iteration 5291 : loss : 0.028352, loss_ce: 0.013245
2022-01-14 13:11:12,630 iteration 5292 : loss : 0.017566, loss_ce: 0.006551
2022-01-14 13:11:13,641 iteration 5293 : loss : 0.023008, loss_ce: 0.009434
2022-01-14 13:11:14,684 iteration 5294 : loss : 0.022644, loss_ce: 0.008661
2022-01-14 13:11:15,780 iteration 5295 : loss : 0.024876, loss_ce: 0.008674
2022-01-14 13:11:16,820 iteration 5296 : loss : 0.025508, loss_ce: 0.006843
2022-01-14 13:11:17,861 iteration 5297 : loss : 0.015704, loss_ce: 0.005174
2022-01-14 13:11:18,905 iteration 5298 : loss : 0.022078, loss_ce: 0.009213
2022-01-14 13:11:19,941 iteration 5299 : loss : 0.022956, loss_ce: 0.007674
2022-01-14 13:11:21,001 iteration 5300 : loss : 0.021280, loss_ce: 0.008462
2022-01-14 13:11:21,942 iteration 5301 : loss : 0.017495, loss_ce: 0.006175
2022-01-14 13:11:22,882 iteration 5302 : loss : 0.016195, loss_ce: 0.008171
2022-01-14 13:11:23,834 iteration 5303 : loss : 0.016639, loss_ce: 0.006048
2022-01-14 13:11:24,764 iteration 5304 : loss : 0.015802, loss_ce: 0.005484
 78%|██████████████████████▌      | 312/400 [1:35:58<26:43, 18.22s/it]2022-01-14 13:11:25,848 iteration 5305 : loss : 0.020625, loss_ce: 0.007011
2022-01-14 13:11:26,945 iteration 5306 : loss : 0.022802, loss_ce: 0.010003
2022-01-14 13:11:28,058 iteration 5307 : loss : 0.023292, loss_ce: 0.008302
2022-01-14 13:11:29,131 iteration 5308 : loss : 0.026614, loss_ce: 0.007731
2022-01-14 13:11:30,200 iteration 5309 : loss : 0.031495, loss_ce: 0.011984
2022-01-14 13:11:31,180 iteration 5310 : loss : 0.017041, loss_ce: 0.007894
2022-01-14 13:11:32,142 iteration 5311 : loss : 0.025669, loss_ce: 0.005651
2022-01-14 13:11:33,206 iteration 5312 : loss : 0.022820, loss_ce: 0.010211
2022-01-14 13:11:34,312 iteration 5313 : loss : 0.036723, loss_ce: 0.010451
2022-01-14 13:11:35,327 iteration 5314 : loss : 0.016939, loss_ce: 0.005507
2022-01-14 13:11:36,393 iteration 5315 : loss : 0.037338, loss_ce: 0.007885
2022-01-14 13:11:37,443 iteration 5316 : loss : 0.018500, loss_ce: 0.006413
2022-01-14 13:11:38,440 iteration 5317 : loss : 0.016523, loss_ce: 0.007466
2022-01-14 13:11:39,409 iteration 5318 : loss : 0.018662, loss_ce: 0.007270
2022-01-14 13:11:40,474 iteration 5319 : loss : 0.020913, loss_ce: 0.009002
2022-01-14 13:11:41,520 iteration 5320 : loss : 0.029238, loss_ce: 0.012967
2022-01-14 13:11:42,590 iteration 5321 : loss : 0.029419, loss_ce: 0.012382
 78%|██████████████████████▋      | 313/400 [1:36:16<26:14, 18.10s/it]2022-01-14 13:11:43,577 iteration 5322 : loss : 0.013754, loss_ce: 0.005611
2022-01-14 13:11:44,591 iteration 5323 : loss : 0.023673, loss_ce: 0.009021
2022-01-14 13:11:45,529 iteration 5324 : loss : 0.020362, loss_ce: 0.006475
2022-01-14 13:11:46,494 iteration 5325 : loss : 0.023517, loss_ce: 0.005403
2022-01-14 13:11:47,531 iteration 5326 : loss : 0.018439, loss_ce: 0.006114
2022-01-14 13:11:48,494 iteration 5327 : loss : 0.015849, loss_ce: 0.005862
2022-01-14 13:11:49,476 iteration 5328 : loss : 0.015888, loss_ce: 0.007184
2022-01-14 13:11:50,524 iteration 5329 : loss : 0.024558, loss_ce: 0.008286
2022-01-14 13:11:51,547 iteration 5330 : loss : 0.026744, loss_ce: 0.010568
2022-01-14 13:11:52,540 iteration 5331 : loss : 0.016814, loss_ce: 0.005511
2022-01-14 13:11:53,549 iteration 5332 : loss : 0.025279, loss_ce: 0.008955
2022-01-14 13:11:54,587 iteration 5333 : loss : 0.019861, loss_ce: 0.008678
2022-01-14 13:11:55,609 iteration 5334 : loss : 0.040077, loss_ce: 0.016580
2022-01-14 13:11:56,652 iteration 5335 : loss : 0.019224, loss_ce: 0.005604
2022-01-14 13:11:57,679 iteration 5336 : loss : 0.019119, loss_ce: 0.007951
2022-01-14 13:11:58,650 iteration 5337 : loss : 0.016976, loss_ce: 0.006632
2022-01-14 13:11:59,619 iteration 5338 : loss : 0.017523, loss_ce: 0.007594
 78%|██████████████████████▊      | 314/400 [1:36:33<25:28, 17.77s/it]2022-01-14 13:12:00,832 iteration 5339 : loss : 0.027106, loss_ce: 0.011418
2022-01-14 13:12:01,888 iteration 5340 : loss : 0.038883, loss_ce: 0.022119
2022-01-14 13:12:02,914 iteration 5341 : loss : 0.024230, loss_ce: 0.004696
2022-01-14 13:12:03,935 iteration 5342 : loss : 0.016381, loss_ce: 0.008854
2022-01-14 13:12:04,913 iteration 5343 : loss : 0.018815, loss_ce: 0.005958
2022-01-14 13:12:05,941 iteration 5344 : loss : 0.019934, loss_ce: 0.006706
2022-01-14 13:12:06,942 iteration 5345 : loss : 0.019820, loss_ce: 0.006642
2022-01-14 13:12:07,987 iteration 5346 : loss : 0.024175, loss_ce: 0.007470
2022-01-14 13:12:09,034 iteration 5347 : loss : 0.026871, loss_ce: 0.009028
2022-01-14 13:12:10,093 iteration 5348 : loss : 0.017791, loss_ce: 0.004862
2022-01-14 13:12:11,113 iteration 5349 : loss : 0.023774, loss_ce: 0.008709
2022-01-14 13:12:12,050 iteration 5350 : loss : 0.014650, loss_ce: 0.005550
2022-01-14 13:12:12,996 iteration 5351 : loss : 0.027647, loss_ce: 0.009680
2022-01-14 13:12:14,039 iteration 5352 : loss : 0.036250, loss_ce: 0.016604
2022-01-14 13:12:15,086 iteration 5353 : loss : 0.014179, loss_ce: 0.004972
2022-01-14 13:12:16,057 iteration 5354 : loss : 0.020321, loss_ce: 0.009945
2022-01-14 13:12:16,057 Training Data Eval:
2022-01-14 13:12:20,868   Average segmentation loss on training set: 0.0123
2022-01-14 13:12:20,869 Validation Data Eval:
2022-01-14 13:12:22,486   Average segmentation loss on validation set: 0.0734
2022-01-14 13:12:23,420 iteration 5355 : loss : 0.018964, loss_ce: 0.007085
 79%|██████████████████████▊      | 315/400 [1:36:57<27:44, 19.59s/it]2022-01-14 13:12:24,489 iteration 5356 : loss : 0.019255, loss_ce: 0.008340
2022-01-14 13:12:25,428 iteration 5357 : loss : 0.020217, loss_ce: 0.004720
2022-01-14 13:12:26,570 iteration 5358 : loss : 0.035334, loss_ce: 0.017754
2022-01-14 13:12:27,501 iteration 5359 : loss : 0.014128, loss_ce: 0.005259
2022-01-14 13:12:28,521 iteration 5360 : loss : 0.021387, loss_ce: 0.008591
2022-01-14 13:12:29,536 iteration 5361 : loss : 0.027012, loss_ce: 0.008911
2022-01-14 13:12:30,569 iteration 5362 : loss : 0.020292, loss_ce: 0.005919
2022-01-14 13:12:31,574 iteration 5363 : loss : 0.023831, loss_ce: 0.009890
2022-01-14 13:12:32,577 iteration 5364 : loss : 0.022535, loss_ce: 0.004443
2022-01-14 13:12:33,561 iteration 5365 : loss : 0.015507, loss_ce: 0.005831
2022-01-14 13:12:34,588 iteration 5366 : loss : 0.026982, loss_ce: 0.012905
2022-01-14 13:12:35,644 iteration 5367 : loss : 0.018070, loss_ce: 0.008074
2022-01-14 13:12:36,632 iteration 5368 : loss : 0.015877, loss_ce: 0.007307
2022-01-14 13:12:37,647 iteration 5369 : loss : 0.014871, loss_ce: 0.005136
2022-01-14 13:12:38,633 iteration 5370 : loss : 0.012835, loss_ce: 0.004920
2022-01-14 13:12:39,645 iteration 5371 : loss : 0.020761, loss_ce: 0.010226
2022-01-14 13:12:40,620 iteration 5372 : loss : 0.019066, loss_ce: 0.005887
 79%|██████████████████████▉      | 316/400 [1:37:14<26:25, 18.87s/it]2022-01-14 13:12:41,684 iteration 5373 : loss : 0.015864, loss_ce: 0.007610
2022-01-14 13:12:42,650 iteration 5374 : loss : 0.017671, loss_ce: 0.007237
2022-01-14 13:12:43,674 iteration 5375 : loss : 0.013196, loss_ce: 0.004140
2022-01-14 13:12:44,655 iteration 5376 : loss : 0.017701, loss_ce: 0.006309
2022-01-14 13:12:45,623 iteration 5377 : loss : 0.013992, loss_ce: 0.004753
2022-01-14 13:12:46,630 iteration 5378 : loss : 0.019784, loss_ce: 0.006893
2022-01-14 13:12:47,568 iteration 5379 : loss : 0.013023, loss_ce: 0.004586
2022-01-14 13:12:48,574 iteration 5380 : loss : 0.018595, loss_ce: 0.007549
2022-01-14 13:12:49,548 iteration 5381 : loss : 0.015341, loss_ce: 0.006098
2022-01-14 13:12:50,570 iteration 5382 : loss : 0.016108, loss_ce: 0.004778
2022-01-14 13:12:51,655 iteration 5383 : loss : 0.028524, loss_ce: 0.013399
2022-01-14 13:12:52,811 iteration 5384 : loss : 0.033220, loss_ce: 0.013559
2022-01-14 13:12:53,791 iteration 5385 : loss : 0.015730, loss_ce: 0.006093
2022-01-14 13:12:54,713 iteration 5386 : loss : 0.014033, loss_ce: 0.004540
2022-01-14 13:12:55,684 iteration 5387 : loss : 0.019135, loss_ce: 0.008702
2022-01-14 13:12:56,733 iteration 5388 : loss : 0.044413, loss_ce: 0.015719
2022-01-14 13:12:57,851 iteration 5389 : loss : 0.030018, loss_ce: 0.011774
 79%|██████████████████████▉      | 317/400 [1:37:31<25:25, 18.38s/it]2022-01-14 13:12:58,890 iteration 5390 : loss : 0.021605, loss_ce: 0.007385
2022-01-14 13:12:59,935 iteration 5391 : loss : 0.019061, loss_ce: 0.006547
2022-01-14 13:13:00,991 iteration 5392 : loss : 0.020460, loss_ce: 0.010952
2022-01-14 13:13:01,996 iteration 5393 : loss : 0.030891, loss_ce: 0.008522
2022-01-14 13:13:02,969 iteration 5394 : loss : 0.019736, loss_ce: 0.008835
2022-01-14 13:13:03,996 iteration 5395 : loss : 0.024125, loss_ce: 0.008245
2022-01-14 13:13:04,953 iteration 5396 : loss : 0.018060, loss_ce: 0.009831
2022-01-14 13:13:06,023 iteration 5397 : loss : 0.020273, loss_ce: 0.006615
2022-01-14 13:13:07,043 iteration 5398 : loss : 0.020297, loss_ce: 0.008219
2022-01-14 13:13:07,982 iteration 5399 : loss : 0.031393, loss_ce: 0.009279
2022-01-14 13:13:09,072 iteration 5400 : loss : 0.043900, loss_ce: 0.012569
2022-01-14 13:13:10,107 iteration 5401 : loss : 0.018429, loss_ce: 0.007916
2022-01-14 13:13:11,117 iteration 5402 : loss : 0.022060, loss_ce: 0.007412
2022-01-14 13:13:12,090 iteration 5403 : loss : 0.018603, loss_ce: 0.007123
2022-01-14 13:13:13,046 iteration 5404 : loss : 0.018534, loss_ce: 0.005066
2022-01-14 13:13:14,020 iteration 5405 : loss : 0.018402, loss_ce: 0.007454
2022-01-14 13:13:15,062 iteration 5406 : loss : 0.017044, loss_ce: 0.004354
 80%|███████████████████████      | 318/400 [1:37:49<24:38, 18.02s/it]2022-01-14 13:13:16,165 iteration 5407 : loss : 0.023320, loss_ce: 0.008094
2022-01-14 13:13:17,168 iteration 5408 : loss : 0.026195, loss_ce: 0.008202
2022-01-14 13:13:18,249 iteration 5409 : loss : 0.026417, loss_ce: 0.011855
2022-01-14 13:13:19,220 iteration 5410 : loss : 0.024854, loss_ce: 0.011426
2022-01-14 13:13:20,217 iteration 5411 : loss : 0.021287, loss_ce: 0.008837
2022-01-14 13:13:21,228 iteration 5412 : loss : 0.018671, loss_ce: 0.008555
2022-01-14 13:13:22,204 iteration 5413 : loss : 0.020050, loss_ce: 0.009056
2022-01-14 13:13:23,222 iteration 5414 : loss : 0.022699, loss_ce: 0.008967
2022-01-14 13:13:24,318 iteration 5415 : loss : 0.027197, loss_ce: 0.010295
2022-01-14 13:13:25,263 iteration 5416 : loss : 0.012818, loss_ce: 0.004324
2022-01-14 13:13:26,296 iteration 5417 : loss : 0.015473, loss_ce: 0.004792
2022-01-14 13:13:27,280 iteration 5418 : loss : 0.029206, loss_ce: 0.011015
2022-01-14 13:13:28,308 iteration 5419 : loss : 0.023547, loss_ce: 0.006369
2022-01-14 13:13:29,374 iteration 5420 : loss : 0.020024, loss_ce: 0.006743
2022-01-14 13:13:30,402 iteration 5421 : loss : 0.019756, loss_ce: 0.008461
2022-01-14 13:13:31,292 iteration 5422 : loss : 0.014297, loss_ce: 0.006403
2022-01-14 13:13:32,324 iteration 5423 : loss : 0.046412, loss_ce: 0.016203
 80%|███████████████████████▏     | 319/400 [1:38:06<24:01, 17.80s/it]2022-01-14 13:13:33,448 iteration 5424 : loss : 0.023680, loss_ce: 0.008469
2022-01-14 13:13:34,415 iteration 5425 : loss : 0.015481, loss_ce: 0.004822
2022-01-14 13:13:35,414 iteration 5426 : loss : 0.019447, loss_ce: 0.005786
2022-01-14 13:13:36,329 iteration 5427 : loss : 0.018421, loss_ce: 0.006704
2022-01-14 13:13:37,297 iteration 5428 : loss : 0.020311, loss_ce: 0.008889
2022-01-14 13:13:38,310 iteration 5429 : loss : 0.015849, loss_ce: 0.005716
2022-01-14 13:13:39,315 iteration 5430 : loss : 0.016920, loss_ce: 0.007324
2022-01-14 13:13:40,256 iteration 5431 : loss : 0.019483, loss_ce: 0.006499
2022-01-14 13:13:41,321 iteration 5432 : loss : 0.017817, loss_ce: 0.009111
2022-01-14 13:13:42,377 iteration 5433 : loss : 0.022189, loss_ce: 0.009161
2022-01-14 13:13:43,325 iteration 5434 : loss : 0.019768, loss_ce: 0.008188
2022-01-14 13:13:44,394 iteration 5435 : loss : 0.023122, loss_ce: 0.009731
2022-01-14 13:13:45,445 iteration 5436 : loss : 0.014808, loss_ce: 0.005993
2022-01-14 13:13:46,497 iteration 5437 : loss : 0.040736, loss_ce: 0.009062
2022-01-14 13:13:47,546 iteration 5438 : loss : 0.022820, loss_ce: 0.009895
2022-01-14 13:13:48,529 iteration 5439 : loss : 0.024217, loss_ce: 0.009896
2022-01-14 13:13:48,530 Training Data Eval:
2022-01-14 13:13:53,329   Average segmentation loss on training set: 0.0111
2022-01-14 13:13:53,329 Validation Data Eval:
2022-01-14 13:13:54,940   Average segmentation loss on validation set: 0.0738
2022-01-14 13:13:55,880 iteration 5440 : loss : 0.017960, loss_ce: 0.007029
 80%|███████████████████████▏     | 320/400 [1:38:29<26:01, 19.52s/it]2022-01-14 13:13:56,910 iteration 5441 : loss : 0.021775, loss_ce: 0.007380
2022-01-14 13:13:57,859 iteration 5442 : loss : 0.017880, loss_ce: 0.005988
2022-01-14 13:13:58,848 iteration 5443 : loss : 0.017152, loss_ce: 0.006281
2022-01-14 13:13:59,768 iteration 5444 : loss : 0.017112, loss_ce: 0.006011
2022-01-14 13:14:00,772 iteration 5445 : loss : 0.022315, loss_ce: 0.008302
2022-01-14 13:14:01,726 iteration 5446 : loss : 0.019091, loss_ce: 0.008664
2022-01-14 13:14:02,803 iteration 5447 : loss : 0.022775, loss_ce: 0.008739
2022-01-14 13:14:03,752 iteration 5448 : loss : 0.015004, loss_ce: 0.005671
2022-01-14 13:14:04,757 iteration 5449 : loss : 0.050680, loss_ce: 0.034877
2022-01-14 13:14:05,750 iteration 5450 : loss : 0.020331, loss_ce: 0.008213
2022-01-14 13:14:06,685 iteration 5451 : loss : 0.015388, loss_ce: 0.005158
2022-01-14 13:14:07,692 iteration 5452 : loss : 0.017440, loss_ce: 0.006596
2022-01-14 13:14:08,642 iteration 5453 : loss : 0.014581, loss_ce: 0.006079
2022-01-14 13:14:09,693 iteration 5454 : loss : 0.024227, loss_ce: 0.012042
2022-01-14 13:14:10,719 iteration 5455 : loss : 0.028358, loss_ce: 0.008694
2022-01-14 13:14:11,725 iteration 5456 : loss : 0.020060, loss_ce: 0.004561
2022-01-14 13:14:12,677 iteration 5457 : loss : 0.014603, loss_ce: 0.004680
 80%|███████████████████████▎     | 321/400 [1:38:46<24:38, 18.71s/it]2022-01-14 13:14:13,711 iteration 5458 : loss : 0.021330, loss_ce: 0.006422
2022-01-14 13:14:14,647 iteration 5459 : loss : 0.017518, loss_ce: 0.007966
2022-01-14 13:14:15,642 iteration 5460 : loss : 0.016910, loss_ce: 0.006647
2022-01-14 13:14:16,626 iteration 5461 : loss : 0.018332, loss_ce: 0.007594
2022-01-14 13:14:17,603 iteration 5462 : loss : 0.016919, loss_ce: 0.006102
2022-01-14 13:14:18,609 iteration 5463 : loss : 0.020957, loss_ce: 0.006176
2022-01-14 13:14:19,614 iteration 5464 : loss : 0.020334, loss_ce: 0.008512
2022-01-14 13:14:20,686 iteration 5465 : loss : 0.021477, loss_ce: 0.007401
2022-01-14 13:14:21,746 iteration 5466 : loss : 0.026259, loss_ce: 0.010347
2022-01-14 13:14:22,771 iteration 5467 : loss : 0.024510, loss_ce: 0.011429
2022-01-14 13:14:23,792 iteration 5468 : loss : 0.016187, loss_ce: 0.006129
2022-01-14 13:14:24,722 iteration 5469 : loss : 0.014735, loss_ce: 0.005875
2022-01-14 13:14:25,702 iteration 5470 : loss : 0.020094, loss_ce: 0.010198
2022-01-14 13:14:26,684 iteration 5471 : loss : 0.022935, loss_ce: 0.005918
2022-01-14 13:14:27,703 iteration 5472 : loss : 0.024448, loss_ce: 0.007617
2022-01-14 13:14:28,642 iteration 5473 : loss : 0.016884, loss_ce: 0.006226
2022-01-14 13:14:29,589 iteration 5474 : loss : 0.016138, loss_ce: 0.005366
 80%|███████████████████████▎     | 322/400 [1:39:03<23:37, 18.17s/it]2022-01-14 13:14:30,660 iteration 5475 : loss : 0.020494, loss_ce: 0.005113
2022-01-14 13:14:31,718 iteration 5476 : loss : 0.020545, loss_ce: 0.009380
2022-01-14 13:14:32,716 iteration 5477 : loss : 0.029861, loss_ce: 0.004655
2022-01-14 13:14:33,636 iteration 5478 : loss : 0.020087, loss_ce: 0.005835
2022-01-14 13:14:34,623 iteration 5479 : loss : 0.013348, loss_ce: 0.005576
2022-01-14 13:14:35,607 iteration 5480 : loss : 0.018921, loss_ce: 0.005825
2022-01-14 13:14:36,568 iteration 5481 : loss : 0.017723, loss_ce: 0.005915
2022-01-14 13:14:37,651 iteration 5482 : loss : 0.051034, loss_ce: 0.010339
2022-01-14 13:14:38,568 iteration 5483 : loss : 0.014095, loss_ce: 0.005477
2022-01-14 13:14:39,575 iteration 5484 : loss : 0.018369, loss_ce: 0.007462
2022-01-14 13:14:40,568 iteration 5485 : loss : 0.015865, loss_ce: 0.006310
2022-01-14 13:14:41,562 iteration 5486 : loss : 0.024559, loss_ce: 0.011266
2022-01-14 13:14:42,576 iteration 5487 : loss : 0.017273, loss_ce: 0.006887
2022-01-14 13:14:43,534 iteration 5488 : loss : 0.018810, loss_ce: 0.008735
2022-01-14 13:14:44,484 iteration 5489 : loss : 0.015153, loss_ce: 0.007975
2022-01-14 13:14:45,547 iteration 5490 : loss : 0.031204, loss_ce: 0.013332
2022-01-14 13:14:46,513 iteration 5491 : loss : 0.017899, loss_ce: 0.005909
 81%|███████████████████████▍     | 323/400 [1:39:20<22:50, 17.79s/it]2022-01-14 13:14:47,479 iteration 5492 : loss : 0.014720, loss_ce: 0.005397
2022-01-14 13:14:48,497 iteration 5493 : loss : 0.023461, loss_ce: 0.007026
2022-01-14 13:14:49,453 iteration 5494 : loss : 0.017407, loss_ce: 0.005849
2022-01-14 13:14:50,454 iteration 5495 : loss : 0.014588, loss_ce: 0.003963
2022-01-14 13:14:51,468 iteration 5496 : loss : 0.019168, loss_ce: 0.005859
2022-01-14 13:14:52,482 iteration 5497 : loss : 0.015667, loss_ce: 0.006070
2022-01-14 13:14:53,527 iteration 5498 : loss : 0.023404, loss_ce: 0.007607
2022-01-14 13:14:54,554 iteration 5499 : loss : 0.039115, loss_ce: 0.021045
2022-01-14 13:14:55,491 iteration 5500 : loss : 0.018260, loss_ce: 0.007705
2022-01-14 13:14:56,494 iteration 5501 : loss : 0.020126, loss_ce: 0.007357
2022-01-14 13:14:57,449 iteration 5502 : loss : 0.011710, loss_ce: 0.004955
2022-01-14 13:14:58,436 iteration 5503 : loss : 0.017753, loss_ce: 0.004607
2022-01-14 13:14:59,394 iteration 5504 : loss : 0.016556, loss_ce: 0.006057
2022-01-14 13:15:00,382 iteration 5505 : loss : 0.022636, loss_ce: 0.009001
2022-01-14 13:15:01,405 iteration 5506 : loss : 0.020298, loss_ce: 0.008725
2022-01-14 13:15:02,397 iteration 5507 : loss : 0.024101, loss_ce: 0.011036
2022-01-14 13:15:03,420 iteration 5508 : loss : 0.021202, loss_ce: 0.006994
 81%|███████████████████████▍     | 324/400 [1:39:37<22:12, 17.53s/it]2022-01-14 13:15:04,475 iteration 5509 : loss : 0.021785, loss_ce: 0.006752
2022-01-14 13:15:05,552 iteration 5510 : loss : 0.014695, loss_ce: 0.005300
2022-01-14 13:15:06,528 iteration 5511 : loss : 0.016611, loss_ce: 0.006090
2022-01-14 13:15:07,571 iteration 5512 : loss : 0.025650, loss_ce: 0.010150
2022-01-14 13:15:08,543 iteration 5513 : loss : 0.014107, loss_ce: 0.006052
2022-01-14 13:15:09,469 iteration 5514 : loss : 0.011211, loss_ce: 0.003671
2022-01-14 13:15:10,525 iteration 5515 : loss : 0.026662, loss_ce: 0.006041
2022-01-14 13:15:11,499 iteration 5516 : loss : 0.018721, loss_ce: 0.007244
2022-01-14 13:15:12,501 iteration 5517 : loss : 0.016854, loss_ce: 0.007357
2022-01-14 13:15:13,500 iteration 5518 : loss : 0.020697, loss_ce: 0.007011
2022-01-14 13:15:14,514 iteration 5519 : loss : 0.028403, loss_ce: 0.010486
2022-01-14 13:15:15,512 iteration 5520 : loss : 0.016990, loss_ce: 0.007553
2022-01-14 13:15:16,527 iteration 5521 : loss : 0.017954, loss_ce: 0.006279
2022-01-14 13:15:17,523 iteration 5522 : loss : 0.028439, loss_ce: 0.012094
2022-01-14 13:15:18,491 iteration 5523 : loss : 0.013090, loss_ce: 0.004333
2022-01-14 13:15:19,463 iteration 5524 : loss : 0.022664, loss_ce: 0.010049
2022-01-14 13:15:19,463 Training Data Eval:
2022-01-14 13:15:24,274   Average segmentation loss on training set: 0.0107
2022-01-14 13:15:24,274 Validation Data Eval:
2022-01-14 13:15:25,887   Average segmentation loss on validation set: 0.0695
2022-01-14 13:15:26,876 iteration 5525 : loss : 0.020551, loss_ce: 0.010085
 81%|███████████████████████▌     | 325/400 [1:40:00<24:08, 19.31s/it]2022-01-14 13:15:27,974 iteration 5526 : loss : 0.019297, loss_ce: 0.006961
2022-01-14 13:15:28,976 iteration 5527 : loss : 0.021328, loss_ce: 0.009295
2022-01-14 13:15:29,966 iteration 5528 : loss : 0.023597, loss_ce: 0.008631
2022-01-14 13:15:30,989 iteration 5529 : loss : 0.021938, loss_ce: 0.009082
2022-01-14 13:15:31,926 iteration 5530 : loss : 0.015953, loss_ce: 0.007085
2022-01-14 13:15:32,890 iteration 5531 : loss : 0.018071, loss_ce: 0.007775
2022-01-14 13:15:33,838 iteration 5532 : loss : 0.012130, loss_ce: 0.005252
2022-01-14 13:15:34,891 iteration 5533 : loss : 0.022542, loss_ce: 0.007081
2022-01-14 13:15:35,883 iteration 5534 : loss : 0.016694, loss_ce: 0.006327
2022-01-14 13:15:36,936 iteration 5535 : loss : 0.019604, loss_ce: 0.007560
2022-01-14 13:15:38,027 iteration 5536 : loss : 0.019923, loss_ce: 0.008887
2022-01-14 13:15:39,056 iteration 5537 : loss : 0.029772, loss_ce: 0.008725
2022-01-14 13:15:40,071 iteration 5538 : loss : 0.019564, loss_ce: 0.007836
2022-01-14 13:15:41,173 iteration 5539 : loss : 0.027359, loss_ce: 0.007933
2022-01-14 13:15:42,146 iteration 5540 : loss : 0.015840, loss_ce: 0.007108
2022-01-14 13:15:43,155 iteration 5541 : loss : 0.020357, loss_ce: 0.006284
2022-01-14 13:15:44,132 iteration 5542 : loss : 0.015255, loss_ce: 0.005526
 82%|███████████████████████▋     | 326/400 [1:40:18<23:03, 18.69s/it]2022-01-14 13:15:45,213 iteration 5543 : loss : 0.017591, loss_ce: 0.006146
2022-01-14 13:15:46,221 iteration 5544 : loss : 0.015360, loss_ce: 0.006782
2022-01-14 13:15:47,194 iteration 5545 : loss : 0.018650, loss_ce: 0.006771
2022-01-14 13:15:48,141 iteration 5546 : loss : 0.027875, loss_ce: 0.009854
2022-01-14 13:15:49,136 iteration 5547 : loss : 0.016582, loss_ce: 0.006025
2022-01-14 13:15:50,185 iteration 5548 : loss : 0.027594, loss_ce: 0.008535
2022-01-14 13:15:51,128 iteration 5549 : loss : 0.019867, loss_ce: 0.008354
2022-01-14 13:15:52,103 iteration 5550 : loss : 0.015171, loss_ce: 0.005293
2022-01-14 13:15:53,103 iteration 5551 : loss : 0.014800, loss_ce: 0.006335
2022-01-14 13:15:54,040 iteration 5552 : loss : 0.022139, loss_ce: 0.010482
2022-01-14 13:15:55,046 iteration 5553 : loss : 0.025114, loss_ce: 0.009381
2022-01-14 13:15:56,088 iteration 5554 : loss : 0.013887, loss_ce: 0.004099
2022-01-14 13:15:57,127 iteration 5555 : loss : 0.033748, loss_ce: 0.009023
2022-01-14 13:15:58,054 iteration 5556 : loss : 0.017170, loss_ce: 0.006732
2022-01-14 13:15:59,106 iteration 5557 : loss : 0.041745, loss_ce: 0.010545
2022-01-14 13:16:00,112 iteration 5558 : loss : 0.015644, loss_ce: 0.004997
2022-01-14 13:16:01,021 iteration 5559 : loss : 0.015665, loss_ce: 0.006472
 82%|███████████████████████▋     | 327/400 [1:40:35<22:04, 18.15s/it]2022-01-14 13:16:02,249 iteration 5560 : loss : 0.024652, loss_ce: 0.009186
2022-01-14 13:16:03,239 iteration 5561 : loss : 0.017061, loss_ce: 0.005705
2022-01-14 13:16:04,233 iteration 5562 : loss : 0.021318, loss_ce: 0.007395
2022-01-14 13:16:05,221 iteration 5563 : loss : 0.014012, loss_ce: 0.006172
2022-01-14 13:16:06,306 iteration 5564 : loss : 0.019032, loss_ce: 0.006040
2022-01-14 13:16:07,309 iteration 5565 : loss : 0.016795, loss_ce: 0.006532
2022-01-14 13:16:08,350 iteration 5566 : loss : 0.019451, loss_ce: 0.010243
2022-01-14 13:16:09,457 iteration 5567 : loss : 0.018361, loss_ce: 0.008966
2022-01-14 13:16:10,495 iteration 5568 : loss : 0.022050, loss_ce: 0.007109
2022-01-14 13:16:11,547 iteration 5569 : loss : 0.021220, loss_ce: 0.009144
2022-01-14 13:16:12,565 iteration 5570 : loss : 0.015124, loss_ce: 0.004972
2022-01-14 13:16:13,610 iteration 5571 : loss : 0.021460, loss_ce: 0.009154
2022-01-14 13:16:14,610 iteration 5572 : loss : 0.019384, loss_ce: 0.007968
2022-01-14 13:16:15,598 iteration 5573 : loss : 0.013727, loss_ce: 0.004490
2022-01-14 13:16:16,702 iteration 5574 : loss : 0.020517, loss_ce: 0.007220
2022-01-14 13:16:17,598 iteration 5575 : loss : 0.012198, loss_ce: 0.005437
2022-01-14 13:16:18,477 iteration 5576 : loss : 0.014050, loss_ce: 0.004369
 82%|███████████████████████▊     | 328/400 [1:40:52<21:31, 17.94s/it]2022-01-14 13:16:19,526 iteration 5577 : loss : 0.014799, loss_ce: 0.004621
2022-01-14 13:16:20,495 iteration 5578 : loss : 0.016412, loss_ce: 0.004483
2022-01-14 13:16:21,484 iteration 5579 : loss : 0.013469, loss_ce: 0.004223
2022-01-14 13:16:22,532 iteration 5580 : loss : 0.012253, loss_ce: 0.004192
2022-01-14 13:16:23,513 iteration 5581 : loss : 0.015126, loss_ce: 0.005198
2022-01-14 13:16:24,547 iteration 5582 : loss : 0.019322, loss_ce: 0.005909
2022-01-14 13:16:25,527 iteration 5583 : loss : 0.018011, loss_ce: 0.004785
2022-01-14 13:16:26,610 iteration 5584 : loss : 0.020406, loss_ce: 0.009021
2022-01-14 13:16:27,589 iteration 5585 : loss : 0.020272, loss_ce: 0.007562
2022-01-14 13:16:28,590 iteration 5586 : loss : 0.020144, loss_ce: 0.009570
2022-01-14 13:16:29,595 iteration 5587 : loss : 0.016272, loss_ce: 0.007199
2022-01-14 13:16:30,672 iteration 5588 : loss : 0.021138, loss_ce: 0.008441
2022-01-14 13:16:31,724 iteration 5589 : loss : 0.029876, loss_ce: 0.010757
2022-01-14 13:16:32,733 iteration 5590 : loss : 0.019280, loss_ce: 0.007723
2022-01-14 13:16:33,736 iteration 5591 : loss : 0.015172, loss_ce: 0.006776
2022-01-14 13:16:34,724 iteration 5592 : loss : 0.016010, loss_ce: 0.005079
2022-01-14 13:16:35,707 iteration 5593 : loss : 0.016565, loss_ce: 0.009139
 82%|███████████████████████▊     | 329/400 [1:41:09<20:58, 17.73s/it]2022-01-14 13:16:36,798 iteration 5594 : loss : 0.012753, loss_ce: 0.004418
2022-01-14 13:16:37,780 iteration 5595 : loss : 0.015539, loss_ce: 0.006493
2022-01-14 13:16:38,762 iteration 5596 : loss : 0.011064, loss_ce: 0.003264
2022-01-14 13:16:39,780 iteration 5597 : loss : 0.014809, loss_ce: 0.004729
2022-01-14 13:16:40,850 iteration 5598 : loss : 0.028300, loss_ce: 0.011539
2022-01-14 13:16:41,892 iteration 5599 : loss : 0.014844, loss_ce: 0.005477
2022-01-14 13:16:42,930 iteration 5600 : loss : 0.017687, loss_ce: 0.008652
2022-01-14 13:16:43,969 iteration 5601 : loss : 0.019592, loss_ce: 0.005760
2022-01-14 13:16:44,936 iteration 5602 : loss : 0.026243, loss_ce: 0.006935
2022-01-14 13:16:45,990 iteration 5603 : loss : 0.021490, loss_ce: 0.011105
2022-01-14 13:16:46,958 iteration 5604 : loss : 0.015995, loss_ce: 0.007132
2022-01-14 13:16:47,928 iteration 5605 : loss : 0.018860, loss_ce: 0.006913
2022-01-14 13:16:48,995 iteration 5606 : loss : 0.026347, loss_ce: 0.009278
2022-01-14 13:16:49,998 iteration 5607 : loss : 0.022576, loss_ce: 0.008045
2022-01-14 13:16:51,125 iteration 5608 : loss : 0.024467, loss_ce: 0.012063
2022-01-14 13:16:52,098 iteration 5609 : loss : 0.016475, loss_ce: 0.007391
2022-01-14 13:16:52,098 Training Data Eval:
2022-01-14 13:16:56,913   Average segmentation loss on training set: 0.0109
2022-01-14 13:16:56,914 Validation Data Eval:
2022-01-14 13:16:58,524   Average segmentation loss on validation set: 0.0709
2022-01-14 13:16:59,550 iteration 5610 : loss : 0.018950, loss_ce: 0.008744
 82%|███████████████████████▉     | 330/400 [1:41:33<22:49, 19.56s/it]2022-01-14 13:17:00,646 iteration 5611 : loss : 0.022410, loss_ce: 0.010374
2022-01-14 13:17:01,653 iteration 5612 : loss : 0.014533, loss_ce: 0.004483
2022-01-14 13:17:02,644 iteration 5613 : loss : 0.015157, loss_ce: 0.005858
2022-01-14 13:17:03,634 iteration 5614 : loss : 0.017088, loss_ce: 0.005337
2022-01-14 13:17:04,658 iteration 5615 : loss : 0.018539, loss_ce: 0.006870
2022-01-14 13:17:05,700 iteration 5616 : loss : 0.018622, loss_ce: 0.006509
2022-01-14 13:17:06,706 iteration 5617 : loss : 0.013828, loss_ce: 0.004958
2022-01-14 13:17:07,659 iteration 5618 : loss : 0.016478, loss_ce: 0.007037
2022-01-14 13:17:08,701 iteration 5619 : loss : 0.024308, loss_ce: 0.008667
2022-01-14 13:17:09,755 iteration 5620 : loss : 0.015588, loss_ce: 0.004443
2022-01-14 13:17:10,726 iteration 5621 : loss : 0.017778, loss_ce: 0.006658
2022-01-14 13:17:11,805 iteration 5622 : loss : 0.020578, loss_ce: 0.008193
2022-01-14 13:17:12,769 iteration 5623 : loss : 0.021250, loss_ce: 0.006682
2022-01-14 13:17:13,792 iteration 5624 : loss : 0.013313, loss_ce: 0.005410
2022-01-14 13:17:14,829 iteration 5625 : loss : 0.019201, loss_ce: 0.007518
2022-01-14 13:17:15,836 iteration 5626 : loss : 0.019103, loss_ce: 0.007054
2022-01-14 13:17:16,833 iteration 5627 : loss : 0.026455, loss_ce: 0.006629
 83%|███████████████████████▉     | 331/400 [1:41:50<21:42, 18.88s/it]2022-01-14 13:17:17,794 iteration 5628 : loss : 0.014358, loss_ce: 0.005093
2022-01-14 13:17:18,819 iteration 5629 : loss : 0.016805, loss_ce: 0.007706
2022-01-14 13:17:19,815 iteration 5630 : loss : 0.019642, loss_ce: 0.005509
2022-01-14 13:17:20,915 iteration 5631 : loss : 0.023005, loss_ce: 0.011157
2022-01-14 13:17:21,842 iteration 5632 : loss : 0.018731, loss_ce: 0.008033
2022-01-14 13:17:22,887 iteration 5633 : loss : 0.022877, loss_ce: 0.008322
2022-01-14 13:17:23,845 iteration 5634 : loss : 0.031934, loss_ce: 0.012673
2022-01-14 13:17:24,867 iteration 5635 : loss : 0.022333, loss_ce: 0.006551
2022-01-14 13:17:25,810 iteration 5636 : loss : 0.015339, loss_ce: 0.006467
2022-01-14 13:17:26,830 iteration 5637 : loss : 0.020094, loss_ce: 0.008229
2022-01-14 13:17:27,723 iteration 5638 : loss : 0.014858, loss_ce: 0.004573
2022-01-14 13:17:28,664 iteration 5639 : loss : 0.022941, loss_ce: 0.006534
2022-01-14 13:17:29,640 iteration 5640 : loss : 0.016393, loss_ce: 0.007479
2022-01-14 13:17:30,675 iteration 5641 : loss : 0.016403, loss_ce: 0.008412
2022-01-14 13:17:31,658 iteration 5642 : loss : 0.020340, loss_ce: 0.003605
2022-01-14 13:17:32,709 iteration 5643 : loss : 0.015095, loss_ce: 0.004058
2022-01-14 13:17:33,732 iteration 5644 : loss : 0.027326, loss_ce: 0.009626
 83%|████████████████████████     | 332/400 [1:42:07<20:43, 18.29s/it]2022-01-14 13:17:34,892 iteration 5645 : loss : 0.028109, loss_ce: 0.012038
2022-01-14 13:17:35,859 iteration 5646 : loss : 0.023777, loss_ce: 0.008371
2022-01-14 13:17:36,857 iteration 5647 : loss : 0.018967, loss_ce: 0.009862
2022-01-14 13:17:37,896 iteration 5648 : loss : 0.025316, loss_ce: 0.008174
2022-01-14 13:17:38,943 iteration 5649 : loss : 0.021767, loss_ce: 0.009901
2022-01-14 13:17:39,960 iteration 5650 : loss : 0.016316, loss_ce: 0.006189
2022-01-14 13:17:40,956 iteration 5651 : loss : 0.024172, loss_ce: 0.013070
2022-01-14 13:17:41,884 iteration 5652 : loss : 0.017180, loss_ce: 0.006568
2022-01-14 13:17:42,864 iteration 5653 : loss : 0.023837, loss_ce: 0.008409
2022-01-14 13:17:43,803 iteration 5654 : loss : 0.016121, loss_ce: 0.004319
2022-01-14 13:17:44,823 iteration 5655 : loss : 0.026485, loss_ce: 0.009160
2022-01-14 13:17:45,816 iteration 5656 : loss : 0.016480, loss_ce: 0.005409
2022-01-14 13:17:46,814 iteration 5657 : loss : 0.016739, loss_ce: 0.006419
2022-01-14 13:17:47,810 iteration 5658 : loss : 0.018288, loss_ce: 0.009094
2022-01-14 13:17:48,785 iteration 5659 : loss : 0.015528, loss_ce: 0.004272
2022-01-14 13:17:49,724 iteration 5660 : loss : 0.014601, loss_ce: 0.005161
2022-01-14 13:17:50,807 iteration 5661 : loss : 0.018217, loss_ce: 0.006207
 83%|████████████████████████▏    | 333/400 [1:42:24<20:00, 17.92s/it]2022-01-14 13:17:51,868 iteration 5662 : loss : 0.024117, loss_ce: 0.005545
2022-01-14 13:17:52,872 iteration 5663 : loss : 0.025514, loss_ce: 0.009769
2022-01-14 13:17:53,895 iteration 5664 : loss : 0.025268, loss_ce: 0.008380
2022-01-14 13:17:54,810 iteration 5665 : loss : 0.018090, loss_ce: 0.006294
2022-01-14 13:17:55,831 iteration 5666 : loss : 0.019781, loss_ce: 0.007481
2022-01-14 13:17:56,871 iteration 5667 : loss : 0.016132, loss_ce: 0.006046
2022-01-14 13:17:57,864 iteration 5668 : loss : 0.015324, loss_ce: 0.006876
2022-01-14 13:17:58,902 iteration 5669 : loss : 0.023059, loss_ce: 0.010852
2022-01-14 13:17:59,919 iteration 5670 : loss : 0.013385, loss_ce: 0.004490
2022-01-14 13:18:00,930 iteration 5671 : loss : 0.015440, loss_ce: 0.005285
2022-01-14 13:18:01,929 iteration 5672 : loss : 0.017838, loss_ce: 0.004731
2022-01-14 13:18:02,896 iteration 5673 : loss : 0.017212, loss_ce: 0.005446
2022-01-14 13:18:03,971 iteration 5674 : loss : 0.018320, loss_ce: 0.008993
2022-01-14 13:18:04,942 iteration 5675 : loss : 0.016591, loss_ce: 0.007740
2022-01-14 13:18:06,000 iteration 5676 : loss : 0.029953, loss_ce: 0.010703
2022-01-14 13:18:07,045 iteration 5677 : loss : 0.017842, loss_ce: 0.009366
2022-01-14 13:18:08,065 iteration 5678 : loss : 0.021711, loss_ce: 0.008733
 84%|████████████████████████▏    | 334/400 [1:42:42<19:29, 17.72s/it]2022-01-14 13:18:09,134 iteration 5679 : loss : 0.027985, loss_ce: 0.012692
2022-01-14 13:18:10,035 iteration 5680 : loss : 0.013973, loss_ce: 0.003805
2022-01-14 13:18:11,088 iteration 5681 : loss : 0.019009, loss_ce: 0.005937
2022-01-14 13:18:12,134 iteration 5682 : loss : 0.027319, loss_ce: 0.014145
2022-01-14 13:18:13,103 iteration 5683 : loss : 0.015151, loss_ce: 0.005263
2022-01-14 13:18:14,061 iteration 5684 : loss : 0.014909, loss_ce: 0.008217
2022-01-14 13:18:15,079 iteration 5685 : loss : 0.020531, loss_ce: 0.009275
2022-01-14 13:18:16,057 iteration 5686 : loss : 0.018060, loss_ce: 0.006796
2022-01-14 13:18:17,052 iteration 5687 : loss : 0.018027, loss_ce: 0.007174
2022-01-14 13:18:18,146 iteration 5688 : loss : 0.020155, loss_ce: 0.007896
2022-01-14 13:18:19,157 iteration 5689 : loss : 0.024495, loss_ce: 0.008389
2022-01-14 13:18:20,171 iteration 5690 : loss : 0.020139, loss_ce: 0.009322
2022-01-14 13:18:21,203 iteration 5691 : loss : 0.027812, loss_ce: 0.012733
2022-01-14 13:18:22,228 iteration 5692 : loss : 0.017889, loss_ce: 0.007548
2022-01-14 13:18:23,236 iteration 5693 : loss : 0.026317, loss_ce: 0.006816
2022-01-14 13:18:24,221 iteration 5694 : loss : 0.017879, loss_ce: 0.007963
2022-01-14 13:18:24,221 Training Data Eval:
2022-01-14 13:18:29,024   Average segmentation loss on training set: 0.0107
2022-01-14 13:18:29,024 Validation Data Eval:
2022-01-14 13:18:30,635   Average segmentation loss on validation set: 0.0669
2022-01-14 13:18:31,583 iteration 5695 : loss : 0.014161, loss_ce: 0.004568
 84%|████████████████████████▎    | 335/400 [1:43:05<21:04, 19.46s/it]2022-01-14 13:18:32,587 iteration 5696 : loss : 0.014548, loss_ce: 0.007176
2022-01-14 13:18:33,528 iteration 5697 : loss : 0.015305, loss_ce: 0.006913
2022-01-14 13:18:34,574 iteration 5698 : loss : 0.019629, loss_ce: 0.006316
2022-01-14 13:18:35,502 iteration 5699 : loss : 0.014660, loss_ce: 0.006213
2022-01-14 13:18:36,477 iteration 5700 : loss : 0.016365, loss_ce: 0.005520
2022-01-14 13:18:37,417 iteration 5701 : loss : 0.012477, loss_ce: 0.005575
2022-01-14 13:18:38,508 iteration 5702 : loss : 0.017367, loss_ce: 0.006571
2022-01-14 13:18:39,539 iteration 5703 : loss : 0.025706, loss_ce: 0.012274
2022-01-14 13:18:40,552 iteration 5704 : loss : 0.015359, loss_ce: 0.005822
2022-01-14 13:18:41,577 iteration 5705 : loss : 0.015104, loss_ce: 0.005158
2022-01-14 13:18:42,493 iteration 5706 : loss : 0.014255, loss_ce: 0.005310
2022-01-14 13:18:43,561 iteration 5707 : loss : 0.018445, loss_ce: 0.005702
2022-01-14 13:18:44,506 iteration 5708 : loss : 0.014921, loss_ce: 0.005379
2022-01-14 13:18:45,506 iteration 5709 : loss : 0.015999, loss_ce: 0.005404
2022-01-14 13:18:46,492 iteration 5710 : loss : 0.025850, loss_ce: 0.008305
2022-01-14 13:18:47,418 iteration 5711 : loss : 0.015405, loss_ce: 0.005206
2022-01-14 13:18:48,425 iteration 5712 : loss : 0.021283, loss_ce: 0.010051
 84%|████████████████████████▎    | 336/400 [1:43:22<19:55, 18.68s/it]2022-01-14 13:18:49,524 iteration 5713 : loss : 0.018870, loss_ce: 0.006149
2022-01-14 13:18:50,574 iteration 5714 : loss : 0.020462, loss_ce: 0.007520
2022-01-14 13:18:51,635 iteration 5715 : loss : 0.015018, loss_ce: 0.006538
2022-01-14 13:18:52,613 iteration 5716 : loss : 0.014152, loss_ce: 0.005552
2022-01-14 13:18:53,695 iteration 5717 : loss : 0.021698, loss_ce: 0.009452
2022-01-14 13:18:54,643 iteration 5718 : loss : 0.014234, loss_ce: 0.004623
2022-01-14 13:18:55,587 iteration 5719 : loss : 0.014866, loss_ce: 0.006495
2022-01-14 13:18:56,629 iteration 5720 : loss : 0.017239, loss_ce: 0.006555
2022-01-14 13:18:57,644 iteration 5721 : loss : 0.038792, loss_ce: 0.019507
2022-01-14 13:18:58,644 iteration 5722 : loss : 0.017937, loss_ce: 0.007452
2022-01-14 13:18:59,655 iteration 5723 : loss : 0.025167, loss_ce: 0.008271
2022-01-14 13:19:00,695 iteration 5724 : loss : 0.018021, loss_ce: 0.005838
2022-01-14 13:19:01,699 iteration 5725 : loss : 0.016171, loss_ce: 0.006133
2022-01-14 13:19:02,655 iteration 5726 : loss : 0.023074, loss_ce: 0.005577
2022-01-14 13:19:03,672 iteration 5727 : loss : 0.016250, loss_ce: 0.005415
2022-01-14 13:19:04,652 iteration 5728 : loss : 0.018620, loss_ce: 0.005918
2022-01-14 13:19:05,723 iteration 5729 : loss : 0.017173, loss_ce: 0.006893
 84%|████████████████████████▍    | 337/400 [1:43:39<19:10, 18.26s/it]2022-01-14 13:19:06,734 iteration 5730 : loss : 0.014910, loss_ce: 0.006857
2022-01-14 13:19:07,785 iteration 5731 : loss : 0.016821, loss_ce: 0.007529
2022-01-14 13:19:08,742 iteration 5732 : loss : 0.013523, loss_ce: 0.005551
2022-01-14 13:19:09,803 iteration 5733 : loss : 0.028734, loss_ce: 0.008148
2022-01-14 13:19:10,848 iteration 5734 : loss : 0.018804, loss_ce: 0.009108
2022-01-14 13:19:11,819 iteration 5735 : loss : 0.014941, loss_ce: 0.004837
2022-01-14 13:19:12,786 iteration 5736 : loss : 0.018009, loss_ce: 0.007710
2022-01-14 13:19:13,854 iteration 5737 : loss : 0.031068, loss_ce: 0.009886
2022-01-14 13:19:14,818 iteration 5738 : loss : 0.015834, loss_ce: 0.005573
2022-01-14 13:19:15,781 iteration 5739 : loss : 0.019235, loss_ce: 0.007068
2022-01-14 13:19:16,775 iteration 5740 : loss : 0.022509, loss_ce: 0.008365
2022-01-14 13:19:17,776 iteration 5741 : loss : 0.015125, loss_ce: 0.006999
2022-01-14 13:19:18,790 iteration 5742 : loss : 0.013713, loss_ce: 0.002636
2022-01-14 13:19:19,816 iteration 5743 : loss : 0.013806, loss_ce: 0.006088
2022-01-14 13:19:20,870 iteration 5744 : loss : 0.021887, loss_ce: 0.010439
2022-01-14 13:19:21,926 iteration 5745 : loss : 0.019339, loss_ce: 0.007640
2022-01-14 13:19:22,889 iteration 5746 : loss : 0.015606, loss_ce: 0.004138
 84%|████████████████████████▌    | 338/400 [1:43:56<18:31, 17.93s/it]2022-01-14 13:19:23,949 iteration 5747 : loss : 0.014981, loss_ce: 0.005528
2022-01-14 13:19:24,970 iteration 5748 : loss : 0.016876, loss_ce: 0.006592
2022-01-14 13:19:25,979 iteration 5749 : loss : 0.024263, loss_ce: 0.008109
2022-01-14 13:19:26,982 iteration 5750 : loss : 0.017931, loss_ce: 0.005947
2022-01-14 13:19:27,924 iteration 5751 : loss : 0.017994, loss_ce: 0.006019
2022-01-14 13:19:28,901 iteration 5752 : loss : 0.016810, loss_ce: 0.004890
2022-01-14 13:19:29,940 iteration 5753 : loss : 0.014077, loss_ce: 0.005308
2022-01-14 13:19:30,993 iteration 5754 : loss : 0.016348, loss_ce: 0.004657
2022-01-14 13:19:31,994 iteration 5755 : loss : 0.014613, loss_ce: 0.004599
2022-01-14 13:19:32,962 iteration 5756 : loss : 0.016402, loss_ce: 0.006537
2022-01-14 13:19:33,854 iteration 5757 : loss : 0.012333, loss_ce: 0.004867
2022-01-14 13:19:34,901 iteration 5758 : loss : 0.020639, loss_ce: 0.008722
2022-01-14 13:19:35,954 iteration 5759 : loss : 0.016222, loss_ce: 0.006986
2022-01-14 13:19:37,041 iteration 5760 : loss : 0.016538, loss_ce: 0.008971
2022-01-14 13:19:38,141 iteration 5761 : loss : 0.026625, loss_ce: 0.010583
2022-01-14 13:19:39,092 iteration 5762 : loss : 0.012239, loss_ce: 0.005149
2022-01-14 13:19:40,132 iteration 5763 : loss : 0.016086, loss_ce: 0.006475
 85%|████████████████████████▌    | 339/400 [1:44:14<18:01, 17.72s/it]2022-01-14 13:19:41,196 iteration 5764 : loss : 0.019184, loss_ce: 0.006953
2022-01-14 13:19:42,268 iteration 5765 : loss : 0.032194, loss_ce: 0.006943
2022-01-14 13:19:43,298 iteration 5766 : loss : 0.031572, loss_ce: 0.016749
2022-01-14 13:19:44,298 iteration 5767 : loss : 0.015207, loss_ce: 0.007607
2022-01-14 13:19:45,403 iteration 5768 : loss : 0.020969, loss_ce: 0.007456
2022-01-14 13:19:46,455 iteration 5769 : loss : 0.030772, loss_ce: 0.011327
2022-01-14 13:19:47,421 iteration 5770 : loss : 0.013291, loss_ce: 0.004818
2022-01-14 13:19:48,443 iteration 5771 : loss : 0.027067, loss_ce: 0.010232
2022-01-14 13:19:49,441 iteration 5772 : loss : 0.015773, loss_ce: 0.005236
2022-01-14 13:19:50,376 iteration 5773 : loss : 0.015679, loss_ce: 0.004948
2022-01-14 13:19:51,292 iteration 5774 : loss : 0.017049, loss_ce: 0.004437
2022-01-14 13:19:52,303 iteration 5775 : loss : 0.022512, loss_ce: 0.009703
2022-01-14 13:19:53,374 iteration 5776 : loss : 0.019034, loss_ce: 0.008671
2022-01-14 13:19:54,295 iteration 5777 : loss : 0.017749, loss_ce: 0.007373
2022-01-14 13:19:55,265 iteration 5778 : loss : 0.019937, loss_ce: 0.005495
2022-01-14 13:19:56,245 iteration 5779 : loss : 0.011348, loss_ce: 0.003772
2022-01-14 13:19:56,246 Training Data Eval:
2022-01-14 13:20:01,059   Average segmentation loss on training set: 0.0100
2022-01-14 13:20:01,059 Validation Data Eval:
2022-01-14 13:20:02,669   Average segmentation loss on validation set: 0.0726
2022-01-14 13:20:03,652 iteration 5780 : loss : 0.016500, loss_ce: 0.005589
 85%|████████████████████████▋    | 340/400 [1:44:37<19:27, 19.47s/it]2022-01-14 13:20:04,677 iteration 5781 : loss : 0.018383, loss_ce: 0.004587
2022-01-14 13:20:05,740 iteration 5782 : loss : 0.023449, loss_ce: 0.008454
2022-01-14 13:20:06,738 iteration 5783 : loss : 0.018166, loss_ce: 0.006462
2022-01-14 13:20:07,760 iteration 5784 : loss : 0.015784, loss_ce: 0.007975
2022-01-14 13:20:08,716 iteration 5785 : loss : 0.012878, loss_ce: 0.004579
2022-01-14 13:20:09,682 iteration 5786 : loss : 0.014466, loss_ce: 0.006255
2022-01-14 13:20:10,642 iteration 5787 : loss : 0.013568, loss_ce: 0.005127
2022-01-14 13:20:11,761 iteration 5788 : loss : 0.027528, loss_ce: 0.011566
2022-01-14 13:20:12,780 iteration 5789 : loss : 0.013712, loss_ce: 0.004668
2022-01-14 13:20:13,782 iteration 5790 : loss : 0.016914, loss_ce: 0.005150
2022-01-14 13:20:14,738 iteration 5791 : loss : 0.013988, loss_ce: 0.004926
2022-01-14 13:20:15,764 iteration 5792 : loss : 0.026509, loss_ce: 0.011800
2022-01-14 13:20:16,874 iteration 5793 : loss : 0.019571, loss_ce: 0.006923
2022-01-14 13:20:17,895 iteration 5794 : loss : 0.016802, loss_ce: 0.006843
2022-01-14 13:20:18,894 iteration 5795 : loss : 0.014975, loss_ce: 0.005104
2022-01-14 13:20:19,851 iteration 5796 : loss : 0.012823, loss_ce: 0.003322
2022-01-14 13:20:20,873 iteration 5797 : loss : 0.017741, loss_ce: 0.007147
 85%|████████████████████████▋    | 341/400 [1:44:54<18:28, 18.79s/it]2022-01-14 13:20:21,966 iteration 5798 : loss : 0.018898, loss_ce: 0.007509
2022-01-14 13:20:22,979 iteration 5799 : loss : 0.016593, loss_ce: 0.005826
2022-01-14 13:20:23,970 iteration 5800 : loss : 0.016857, loss_ce: 0.007151
2022-01-14 13:20:24,960 iteration 5801 : loss : 0.018657, loss_ce: 0.006578
2022-01-14 13:20:25,897 iteration 5802 : loss : 0.018417, loss_ce: 0.006192
2022-01-14 13:20:26,865 iteration 5803 : loss : 0.018223, loss_ce: 0.008497
2022-01-14 13:20:27,864 iteration 5804 : loss : 0.016479, loss_ce: 0.006503
2022-01-14 13:20:28,952 iteration 5805 : loss : 0.015867, loss_ce: 0.005613
2022-01-14 13:20:29,937 iteration 5806 : loss : 0.017835, loss_ce: 0.005471
2022-01-14 13:20:31,012 iteration 5807 : loss : 0.023542, loss_ce: 0.009478
2022-01-14 13:20:32,035 iteration 5808 : loss : 0.020869, loss_ce: 0.010508
2022-01-14 13:20:32,974 iteration 5809 : loss : 0.011952, loss_ce: 0.002843
2022-01-14 13:20:33,936 iteration 5810 : loss : 0.018518, loss_ce: 0.006126
2022-01-14 13:20:34,865 iteration 5811 : loss : 0.016171, loss_ce: 0.004741
2022-01-14 13:20:35,861 iteration 5812 : loss : 0.015721, loss_ce: 0.005227
2022-01-14 13:20:36,795 iteration 5813 : loss : 0.018798, loss_ce: 0.010181
2022-01-14 13:20:37,807 iteration 5814 : loss : 0.018082, loss_ce: 0.007690
 86%|████████████████████████▊    | 342/400 [1:45:11<17:37, 18.24s/it]2022-01-14 13:20:38,801 iteration 5815 : loss : 0.013046, loss_ce: 0.004361
2022-01-14 13:20:39,786 iteration 5816 : loss : 0.013510, loss_ce: 0.006166
2022-01-14 13:20:40,755 iteration 5817 : loss : 0.013614, loss_ce: 0.004998
2022-01-14 13:20:41,662 iteration 5818 : loss : 0.014047, loss_ce: 0.005761
2022-01-14 13:20:42,708 iteration 5819 : loss : 0.014661, loss_ce: 0.005565
2022-01-14 13:20:43,779 iteration 5820 : loss : 0.019331, loss_ce: 0.008481
2022-01-14 13:20:44,709 iteration 5821 : loss : 0.012025, loss_ce: 0.003915
2022-01-14 13:20:45,665 iteration 5822 : loss : 0.012104, loss_ce: 0.005399
2022-01-14 13:20:46,759 iteration 5823 : loss : 0.015489, loss_ce: 0.006184
2022-01-14 13:20:47,761 iteration 5824 : loss : 0.016445, loss_ce: 0.005015
2022-01-14 13:20:48,810 iteration 5825 : loss : 0.020126, loss_ce: 0.006949
2022-01-14 13:20:49,849 iteration 5826 : loss : 0.023901, loss_ce: 0.005509
2022-01-14 13:20:50,850 iteration 5827 : loss : 0.016871, loss_ce: 0.004911
2022-01-14 13:20:51,946 iteration 5828 : loss : 0.019075, loss_ce: 0.006902
2022-01-14 13:20:52,940 iteration 5829 : loss : 0.012784, loss_ce: 0.005004
2022-01-14 13:20:53,903 iteration 5830 : loss : 0.024498, loss_ce: 0.009922
2022-01-14 13:20:54,879 iteration 5831 : loss : 0.018049, loss_ce: 0.006155
 86%|████████████████████████▊    | 343/400 [1:45:28<16:59, 17.88s/it]2022-01-14 13:20:55,938 iteration 5832 : loss : 0.014039, loss_ce: 0.003929
2022-01-14 13:20:56,978 iteration 5833 : loss : 0.014421, loss_ce: 0.006250
2022-01-14 13:20:57,921 iteration 5834 : loss : 0.018470, loss_ce: 0.007000
2022-01-14 13:20:58,871 iteration 5835 : loss : 0.020173, loss_ce: 0.006026
2022-01-14 13:20:59,911 iteration 5836 : loss : 0.020589, loss_ce: 0.011067
2022-01-14 13:21:00,906 iteration 5837 : loss : 0.025482, loss_ce: 0.005103
2022-01-14 13:21:01,814 iteration 5838 : loss : 0.011879, loss_ce: 0.003432
2022-01-14 13:21:02,800 iteration 5839 : loss : 0.016328, loss_ce: 0.005453
2022-01-14 13:21:03,835 iteration 5840 : loss : 0.023816, loss_ce: 0.009214
2022-01-14 13:21:04,804 iteration 5841 : loss : 0.016804, loss_ce: 0.007228
2022-01-14 13:21:05,773 iteration 5842 : loss : 0.009355, loss_ce: 0.003604
2022-01-14 13:21:06,737 iteration 5843 : loss : 0.017760, loss_ce: 0.007945
2022-01-14 13:21:07,867 iteration 5844 : loss : 0.028402, loss_ce: 0.007833
2022-01-14 13:21:08,862 iteration 5845 : loss : 0.024070, loss_ce: 0.009863
2022-01-14 13:21:09,869 iteration 5846 : loss : 0.036290, loss_ce: 0.016508
2022-01-14 13:21:10,885 iteration 5847 : loss : 0.016492, loss_ce: 0.006565
2022-01-14 13:21:11,880 iteration 5848 : loss : 0.017400, loss_ce: 0.006303
 86%|████████████████████████▉    | 344/400 [1:45:45<16:26, 17.62s/it]2022-01-14 13:21:12,941 iteration 5849 : loss : 0.018094, loss_ce: 0.007227
2022-01-14 13:21:13,882 iteration 5850 : loss : 0.013322, loss_ce: 0.005471
2022-01-14 13:21:14,879 iteration 5851 : loss : 0.015791, loss_ce: 0.006909
2022-01-14 13:21:15,851 iteration 5852 : loss : 0.016081, loss_ce: 0.005995
2022-01-14 13:21:16,766 iteration 5853 : loss : 0.015220, loss_ce: 0.004497
2022-01-14 13:21:17,727 iteration 5854 : loss : 0.024046, loss_ce: 0.009062
2022-01-14 13:21:18,787 iteration 5855 : loss : 0.016960, loss_ce: 0.007368
2022-01-14 13:21:19,787 iteration 5856 : loss : 0.019633, loss_ce: 0.008418
2022-01-14 13:21:20,797 iteration 5857 : loss : 0.014064, loss_ce: 0.005022
2022-01-14 13:21:21,720 iteration 5858 : loss : 0.014802, loss_ce: 0.005595
2022-01-14 13:21:22,759 iteration 5859 : loss : 0.016428, loss_ce: 0.006656
2022-01-14 13:21:23,804 iteration 5860 : loss : 0.020338, loss_ce: 0.005793
2022-01-14 13:21:24,783 iteration 5861 : loss : 0.016764, loss_ce: 0.004741
2022-01-14 13:21:25,807 iteration 5862 : loss : 0.015436, loss_ce: 0.007303
2022-01-14 13:21:26,715 iteration 5863 : loss : 0.017576, loss_ce: 0.007475
2022-01-14 13:21:27,713 iteration 5864 : loss : 0.018737, loss_ce: 0.005784
2022-01-14 13:21:27,714 Training Data Eval:
2022-01-14 13:21:32,539   Average segmentation loss on training set: 0.0098
2022-01-14 13:21:32,539 Validation Data Eval:
2022-01-14 13:21:34,153   Average segmentation loss on validation set: 0.0715
2022-01-14 13:21:35,088 iteration 5865 : loss : 0.022249, loss_ce: 0.007131
 86%|█████████████████████████    | 345/400 [1:46:09<17:41, 19.30s/it]2022-01-14 13:21:36,279 iteration 5866 : loss : 0.014962, loss_ce: 0.006034
2022-01-14 13:21:37,327 iteration 5867 : loss : 0.018272, loss_ce: 0.006677
2022-01-14 13:21:38,364 iteration 5868 : loss : 0.030346, loss_ce: 0.010536
2022-01-14 13:21:39,327 iteration 5869 : loss : 0.014333, loss_ce: 0.006284
2022-01-14 13:21:40,410 iteration 5870 : loss : 0.022456, loss_ce: 0.005495
2022-01-14 13:21:41,436 iteration 5871 : loss : 0.011757, loss_ce: 0.003935
2022-01-14 13:21:42,470 iteration 5872 : loss : 0.023443, loss_ce: 0.008774
2022-01-14 13:21:43,586 iteration 5873 : loss : 0.030645, loss_ce: 0.011168
2022-01-14 13:21:44,547 iteration 5874 : loss : 0.026634, loss_ce: 0.010828
2022-01-14 13:21:45,523 iteration 5875 : loss : 0.015119, loss_ce: 0.007411
2022-01-14 13:21:46,527 iteration 5876 : loss : 0.018940, loss_ce: 0.007385
2022-01-14 13:21:47,529 iteration 5877 : loss : 0.018651, loss_ce: 0.007058
2022-01-14 13:21:48,557 iteration 5878 : loss : 0.016240, loss_ce: 0.006631
2022-01-14 13:21:49,518 iteration 5879 : loss : 0.025029, loss_ce: 0.009522
2022-01-14 13:21:50,613 iteration 5880 : loss : 0.020349, loss_ce: 0.005961
2022-01-14 13:21:51,555 iteration 5881 : loss : 0.016584, loss_ce: 0.007900
2022-01-14 13:21:52,532 iteration 5882 : loss : 0.014906, loss_ce: 0.006843
 86%|█████████████████████████    | 346/400 [1:46:26<16:51, 18.74s/it]2022-01-14 13:21:53,560 iteration 5883 : loss : 0.018353, loss_ce: 0.007268
2022-01-14 13:21:54,527 iteration 5884 : loss : 0.013639, loss_ce: 0.005828
2022-01-14 13:21:55,643 iteration 5885 : loss : 0.035439, loss_ce: 0.012494
2022-01-14 13:21:56,586 iteration 5886 : loss : 0.016048, loss_ce: 0.004619
2022-01-14 13:21:57,555 iteration 5887 : loss : 0.017415, loss_ce: 0.007959
2022-01-14 13:21:58,645 iteration 5888 : loss : 0.017870, loss_ce: 0.006021
2022-01-14 13:21:59,726 iteration 5889 : loss : 0.016289, loss_ce: 0.006495
2022-01-14 13:22:00,744 iteration 5890 : loss : 0.014993, loss_ce: 0.005084
2022-01-14 13:22:01,802 iteration 5891 : loss : 0.025856, loss_ce: 0.008370
2022-01-14 13:22:02,901 iteration 5892 : loss : 0.021544, loss_ce: 0.008778
2022-01-14 13:22:03,870 iteration 5893 : loss : 0.013333, loss_ce: 0.004333
2022-01-14 13:22:04,955 iteration 5894 : loss : 0.023113, loss_ce: 0.009497
2022-01-14 13:22:05,992 iteration 5895 : loss : 0.029188, loss_ce: 0.008408
2022-01-14 13:22:06,988 iteration 5896 : loss : 0.019241, loss_ce: 0.009218
2022-01-14 13:22:08,064 iteration 5897 : loss : 0.028458, loss_ce: 0.012796
2022-01-14 13:22:09,112 iteration 5898 : loss : 0.012807, loss_ce: 0.004253
2022-01-14 13:22:10,087 iteration 5899 : loss : 0.016386, loss_ce: 0.006385
 87%|█████████████████████████▏   | 347/400 [1:46:44<16:14, 18.38s/it]2022-01-14 13:22:11,166 iteration 5900 : loss : 0.015887, loss_ce: 0.004881
2022-01-14 13:22:12,246 iteration 5901 : loss : 0.019866, loss_ce: 0.007843
2022-01-14 13:22:13,250 iteration 5902 : loss : 0.025781, loss_ce: 0.010028
2022-01-14 13:22:14,318 iteration 5903 : loss : 0.016953, loss_ce: 0.008211
2022-01-14 13:22:15,312 iteration 5904 : loss : 0.017337, loss_ce: 0.006929
2022-01-14 13:22:16,370 iteration 5905 : loss : 0.022689, loss_ce: 0.005684
2022-01-14 13:22:17,327 iteration 5906 : loss : 0.017127, loss_ce: 0.006349
2022-01-14 13:22:18,365 iteration 5907 : loss : 0.013898, loss_ce: 0.004681
2022-01-14 13:22:19,377 iteration 5908 : loss : 0.015158, loss_ce: 0.005808
2022-01-14 13:22:20,292 iteration 5909 : loss : 0.016488, loss_ce: 0.004263
2022-01-14 13:22:21,300 iteration 5910 : loss : 0.020430, loss_ce: 0.006906
2022-01-14 13:22:22,348 iteration 5911 : loss : 0.031691, loss_ce: 0.013271
2022-01-14 13:22:23,294 iteration 5912 : loss : 0.015356, loss_ce: 0.005043
2022-01-14 13:22:24,273 iteration 5913 : loss : 0.016222, loss_ce: 0.007452
2022-01-14 13:22:25,281 iteration 5914 : loss : 0.024094, loss_ce: 0.007494
2022-01-14 13:22:26,200 iteration 5915 : loss : 0.014288, loss_ce: 0.005770
2022-01-14 13:22:27,243 iteration 5916 : loss : 0.022946, loss_ce: 0.007796
 87%|█████████████████████████▏   | 348/400 [1:47:01<15:36, 18.01s/it]2022-01-14 13:22:28,270 iteration 5917 : loss : 0.014556, loss_ce: 0.005956
2022-01-14 13:22:29,207 iteration 5918 : loss : 0.017903, loss_ce: 0.006452
2022-01-14 13:22:30,250 iteration 5919 : loss : 0.020760, loss_ce: 0.009607
2022-01-14 13:22:31,303 iteration 5920 : loss : 0.027520, loss_ce: 0.014561
2022-01-14 13:22:32,446 iteration 5921 : loss : 0.023961, loss_ce: 0.007438
2022-01-14 13:22:33,430 iteration 5922 : loss : 0.014697, loss_ce: 0.004077
2022-01-14 13:22:34,449 iteration 5923 : loss : 0.028563, loss_ce: 0.010088
2022-01-14 13:22:35,555 iteration 5924 : loss : 0.023189, loss_ce: 0.004759
2022-01-14 13:22:36,574 iteration 5925 : loss : 0.015795, loss_ce: 0.005267
2022-01-14 13:22:37,583 iteration 5926 : loss : 0.021653, loss_ce: 0.008867
2022-01-14 13:22:38,608 iteration 5927 : loss : 0.019266, loss_ce: 0.008740
2022-01-14 13:22:39,548 iteration 5928 : loss : 0.013892, loss_ce: 0.003570
2022-01-14 13:22:40,490 iteration 5929 : loss : 0.014314, loss_ce: 0.006712
2022-01-14 13:22:41,432 iteration 5930 : loss : 0.016187, loss_ce: 0.007165
2022-01-14 13:22:42,440 iteration 5931 : loss : 0.022735, loss_ce: 0.006271
2022-01-14 13:22:43,486 iteration 5932 : loss : 0.021166, loss_ce: 0.008550
2022-01-14 13:22:44,474 iteration 5933 : loss : 0.018325, loss_ce: 0.006566
 87%|█████████████████████████▎   | 349/400 [1:47:18<15:06, 17.78s/it]2022-01-14 13:22:45,483 iteration 5934 : loss : 0.014250, loss_ce: 0.004646
2022-01-14 13:22:46,618 iteration 5935 : loss : 0.017289, loss_ce: 0.005775
2022-01-14 13:22:47,624 iteration 5936 : loss : 0.012092, loss_ce: 0.004681
2022-01-14 13:22:48,594 iteration 5937 : loss : 0.018954, loss_ce: 0.007098
2022-01-14 13:22:49,515 iteration 5938 : loss : 0.010099, loss_ce: 0.003801
2022-01-14 13:22:50,545 iteration 5939 : loss : 0.012827, loss_ce: 0.005491
2022-01-14 13:22:51,488 iteration 5940 : loss : 0.013507, loss_ce: 0.005485
2022-01-14 13:22:52,446 iteration 5941 : loss : 0.016770, loss_ce: 0.006474
2022-01-14 13:22:53,412 iteration 5942 : loss : 0.017495, loss_ce: 0.008964
2022-01-14 13:22:54,417 iteration 5943 : loss : 0.017059, loss_ce: 0.004522
2022-01-14 13:22:55,428 iteration 5944 : loss : 0.017219, loss_ce: 0.008671
2022-01-14 13:22:56,401 iteration 5945 : loss : 0.016450, loss_ce: 0.003311
2022-01-14 13:22:57,503 iteration 5946 : loss : 0.022551, loss_ce: 0.008269
2022-01-14 13:22:58,535 iteration 5947 : loss : 0.021274, loss_ce: 0.008390
2022-01-14 13:22:59,507 iteration 5948 : loss : 0.022529, loss_ce: 0.007552
2022-01-14 13:23:00,574 iteration 5949 : loss : 0.017052, loss_ce: 0.005374
2022-01-14 13:23:00,574 Training Data Eval:
2022-01-14 13:23:05,381   Average segmentation loss on training set: 0.0097
2022-01-14 13:23:05,381 Validation Data Eval:
2022-01-14 13:23:06,998   Average segmentation loss on validation set: 0.0734
2022-01-14 13:23:08,011 iteration 5950 : loss : 0.016538, loss_ce: 0.005757
 88%|█████████████████████████▍   | 350/400 [1:47:42<16:15, 19.51s/it]2022-01-14 13:23:09,025 iteration 5951 : loss : 0.014091, loss_ce: 0.004999
2022-01-14 13:23:10,032 iteration 5952 : loss : 0.015736, loss_ce: 0.005783
2022-01-14 13:23:11,037 iteration 5953 : loss : 0.020017, loss_ce: 0.007814
2022-01-14 13:23:12,002 iteration 5954 : loss : 0.017652, loss_ce: 0.005930
2022-01-14 13:23:12,996 iteration 5955 : loss : 0.016559, loss_ce: 0.005141
2022-01-14 13:23:14,023 iteration 5956 : loss : 0.019357, loss_ce: 0.010481
2022-01-14 13:23:15,034 iteration 5957 : loss : 0.014265, loss_ce: 0.005616
2022-01-14 13:23:15,990 iteration 5958 : loss : 0.015396, loss_ce: 0.006064
2022-01-14 13:23:16,974 iteration 5959 : loss : 0.018174, loss_ce: 0.006872
2022-01-14 13:23:17,922 iteration 5960 : loss : 0.018417, loss_ce: 0.005365
2022-01-14 13:23:18,863 iteration 5961 : loss : 0.014863, loss_ce: 0.003394
2022-01-14 13:23:19,845 iteration 5962 : loss : 0.017255, loss_ce: 0.004120
2022-01-14 13:23:20,878 iteration 5963 : loss : 0.018238, loss_ce: 0.007766
2022-01-14 13:23:21,851 iteration 5964 : loss : 0.011683, loss_ce: 0.005059
2022-01-14 13:23:22,788 iteration 5965 : loss : 0.013148, loss_ce: 0.005847
2022-01-14 13:23:23,832 iteration 5966 : loss : 0.025914, loss_ce: 0.006269
2022-01-14 13:23:24,845 iteration 5967 : loss : 0.015829, loss_ce: 0.006436
 88%|█████████████████████████▍   | 351/400 [1:47:58<15:16, 18.70s/it]2022-01-14 13:23:25,972 iteration 5968 : loss : 0.022887, loss_ce: 0.006258
2022-01-14 13:23:26,948 iteration 5969 : loss : 0.018625, loss_ce: 0.007683
2022-01-14 13:23:27,980 iteration 5970 : loss : 0.018510, loss_ce: 0.007699
2022-01-14 13:23:28,913 iteration 5971 : loss : 0.016265, loss_ce: 0.006043
2022-01-14 13:23:29,817 iteration 5972 : loss : 0.011582, loss_ce: 0.003696
2022-01-14 13:23:30,824 iteration 5973 : loss : 0.019701, loss_ce: 0.009923
2022-01-14 13:23:31,919 iteration 5974 : loss : 0.032693, loss_ce: 0.014523
2022-01-14 13:23:32,868 iteration 5975 : loss : 0.018468, loss_ce: 0.006619
2022-01-14 13:23:33,838 iteration 5976 : loss : 0.017645, loss_ce: 0.005290
2022-01-14 13:23:34,783 iteration 5977 : loss : 0.021305, loss_ce: 0.004953
2022-01-14 13:23:35,720 iteration 5978 : loss : 0.012381, loss_ce: 0.005789
2022-01-14 13:23:36,706 iteration 5979 : loss : 0.011895, loss_ce: 0.005124
2022-01-14 13:23:37,738 iteration 5980 : loss : 0.017381, loss_ce: 0.005813
2022-01-14 13:23:38,696 iteration 5981 : loss : 0.020099, loss_ce: 0.009423
2022-01-14 13:23:39,688 iteration 5982 : loss : 0.020552, loss_ce: 0.008268
2022-01-14 13:23:40,746 iteration 5983 : loss : 0.017203, loss_ce: 0.005280
2022-01-14 13:23:41,714 iteration 5984 : loss : 0.023436, loss_ce: 0.008642
 88%|█████████████████████████▌   | 352/400 [1:48:15<14:31, 18.16s/it]2022-01-14 13:23:42,772 iteration 5985 : loss : 0.013897, loss_ce: 0.004102
2022-01-14 13:23:43,680 iteration 5986 : loss : 0.012566, loss_ce: 0.003910
2022-01-14 13:23:44,697 iteration 5987 : loss : 0.017193, loss_ce: 0.007147
2022-01-14 13:23:45,743 iteration 5988 : loss : 0.028655, loss_ce: 0.011297
2022-01-14 13:23:46,755 iteration 5989 : loss : 0.015673, loss_ce: 0.005897
2022-01-14 13:23:47,725 iteration 5990 : loss : 0.022351, loss_ce: 0.007676
2022-01-14 13:23:48,741 iteration 5991 : loss : 0.017653, loss_ce: 0.006040
2022-01-14 13:23:49,748 iteration 5992 : loss : 0.024556, loss_ce: 0.009604
2022-01-14 13:23:50,735 iteration 5993 : loss : 0.015830, loss_ce: 0.006707
2022-01-14 13:23:51,775 iteration 5994 : loss : 0.020917, loss_ce: 0.009440
2022-01-14 13:23:52,758 iteration 5995 : loss : 0.019034, loss_ce: 0.007913
2022-01-14 13:23:53,711 iteration 5996 : loss : 0.014707, loss_ce: 0.004108
2022-01-14 13:23:54,726 iteration 5997 : loss : 0.017490, loss_ce: 0.006502
2022-01-14 13:23:55,798 iteration 5998 : loss : 0.023015, loss_ce: 0.008637
2022-01-14 13:23:56,898 iteration 5999 : loss : 0.022597, loss_ce: 0.009250
2022-01-14 13:23:57,916 iteration 6000 : loss : 0.020141, loss_ce: 0.008811
2022-01-14 13:23:58,838 iteration 6001 : loss : 0.015784, loss_ce: 0.007046
 88%|█████████████████████████▌   | 353/400 [1:48:32<13:58, 17.85s/it]2022-01-14 13:23:59,915 iteration 6002 : loss : 0.020157, loss_ce: 0.009011
2022-01-14 13:24:00,882 iteration 6003 : loss : 0.014297, loss_ce: 0.005064
2022-01-14 13:24:01,930 iteration 6004 : loss : 0.018339, loss_ce: 0.008787
2022-01-14 13:24:02,959 iteration 6005 : loss : 0.017679, loss_ce: 0.006038
2022-01-14 13:24:04,060 iteration 6006 : loss : 0.022652, loss_ce: 0.008450
2022-01-14 13:24:05,080 iteration 6007 : loss : 0.011980, loss_ce: 0.004832
2022-01-14 13:24:06,122 iteration 6008 : loss : 0.017025, loss_ce: 0.006414
2022-01-14 13:24:07,043 iteration 6009 : loss : 0.012424, loss_ce: 0.005779
2022-01-14 13:24:07,986 iteration 6010 : loss : 0.014198, loss_ce: 0.005821
2022-01-14 13:24:09,022 iteration 6011 : loss : 0.017381, loss_ce: 0.005611
2022-01-14 13:24:10,083 iteration 6012 : loss : 0.016185, loss_ce: 0.003608
2022-01-14 13:24:11,121 iteration 6013 : loss : 0.018468, loss_ce: 0.006621
2022-01-14 13:24:12,149 iteration 6014 : loss : 0.020539, loss_ce: 0.005232
2022-01-14 13:24:13,115 iteration 6015 : loss : 0.014596, loss_ce: 0.005846
2022-01-14 13:24:14,116 iteration 6016 : loss : 0.014377, loss_ce: 0.005039
2022-01-14 13:24:15,114 iteration 6017 : loss : 0.013864, loss_ce: 0.006543
2022-01-14 13:24:16,134 iteration 6018 : loss : 0.023812, loss_ce: 0.009288
 88%|█████████████████████████▋   | 354/400 [1:48:50<13:33, 17.68s/it]2022-01-14 13:24:17,199 iteration 6019 : loss : 0.021458, loss_ce: 0.010545
2022-01-14 13:24:18,179 iteration 6020 : loss : 0.014422, loss_ce: 0.006165
2022-01-14 13:24:19,193 iteration 6021 : loss : 0.019977, loss_ce: 0.004993
2022-01-14 13:24:20,137 iteration 6022 : loss : 0.016041, loss_ce: 0.006743
2022-01-14 13:24:21,169 iteration 6023 : loss : 0.015580, loss_ce: 0.005928
2022-01-14 13:24:22,148 iteration 6024 : loss : 0.023332, loss_ce: 0.007336
2022-01-14 13:24:23,117 iteration 6025 : loss : 0.015779, loss_ce: 0.006491
2022-01-14 13:24:24,139 iteration 6026 : loss : 0.016544, loss_ce: 0.005381
2022-01-14 13:24:25,155 iteration 6027 : loss : 0.020441, loss_ce: 0.007196
2022-01-14 13:24:26,186 iteration 6028 : loss : 0.015984, loss_ce: 0.006298
2022-01-14 13:24:27,166 iteration 6029 : loss : 0.019278, loss_ce: 0.005343
2022-01-14 13:24:28,094 iteration 6030 : loss : 0.013911, loss_ce: 0.006211
2022-01-14 13:24:29,106 iteration 6031 : loss : 0.015061, loss_ce: 0.006956
2022-01-14 13:24:30,054 iteration 6032 : loss : 0.017643, loss_ce: 0.005134
2022-01-14 13:24:31,097 iteration 6033 : loss : 0.020860, loss_ce: 0.007608
2022-01-14 13:24:32,105 iteration 6034 : loss : 0.014205, loss_ce: 0.005612
2022-01-14 13:24:32,105 Training Data Eval:
2022-01-14 13:24:36,929   Average segmentation loss on training set: 0.0093
2022-01-14 13:24:36,929 Validation Data Eval:
2022-01-14 13:24:38,541   Average segmentation loss on validation set: 0.0619
2022-01-14 13:24:39,422 iteration 6035 : loss : 0.011150, loss_ce: 0.004319
 89%|█████████████████████████▋   | 355/400 [1:49:13<14:31, 19.37s/it]2022-01-14 13:24:40,577 iteration 6036 : loss : 0.024961, loss_ce: 0.007274
2022-01-14 13:24:41,630 iteration 6037 : loss : 0.022484, loss_ce: 0.007923
2022-01-14 13:24:42,613 iteration 6038 : loss : 0.014716, loss_ce: 0.005365
2022-01-14 13:24:43,580 iteration 6039 : loss : 0.014210, loss_ce: 0.004479
2022-01-14 13:24:44,587 iteration 6040 : loss : 0.016340, loss_ce: 0.005814
2022-01-14 13:24:45,557 iteration 6041 : loss : 0.014850, loss_ce: 0.004846
2022-01-14 13:24:46,581 iteration 6042 : loss : 0.015822, loss_ce: 0.007856
2022-01-14 13:24:47,533 iteration 6043 : loss : 0.012768, loss_ce: 0.005651
2022-01-14 13:24:48,472 iteration 6044 : loss : 0.012499, loss_ce: 0.005280
2022-01-14 13:24:49,543 iteration 6045 : loss : 0.021475, loss_ce: 0.008392
2022-01-14 13:24:50,485 iteration 6046 : loss : 0.016467, loss_ce: 0.007086
2022-01-14 13:24:51,420 iteration 6047 : loss : 0.011202, loss_ce: 0.004555
2022-01-14 13:24:52,481 iteration 6048 : loss : 0.024477, loss_ce: 0.006235
2022-01-14 13:24:53,415 iteration 6049 : loss : 0.013670, loss_ce: 0.004846
2022-01-14 13:24:54,348 iteration 6050 : loss : 0.015892, loss_ce: 0.004375
2022-01-14 13:24:55,276 iteration 6051 : loss : 0.011167, loss_ce: 0.004574
2022-01-14 13:24:56,299 iteration 6052 : loss : 0.024196, loss_ce: 0.012397
 89%|█████████████████████████▊   | 356/400 [1:49:30<13:39, 18.62s/it]2022-01-14 13:24:57,346 iteration 6053 : loss : 0.016860, loss_ce: 0.005617
2022-01-14 13:24:58,318 iteration 6054 : loss : 0.014028, loss_ce: 0.004720
2022-01-14 13:24:59,348 iteration 6055 : loss : 0.014855, loss_ce: 0.006589
2022-01-14 13:25:00,332 iteration 6056 : loss : 0.014103, loss_ce: 0.004308
2022-01-14 13:25:01,255 iteration 6057 : loss : 0.019966, loss_ce: 0.007088
2022-01-14 13:25:02,197 iteration 6058 : loss : 0.012611, loss_ce: 0.006616
2022-01-14 13:25:03,245 iteration 6059 : loss : 0.019357, loss_ce: 0.006064
2022-01-14 13:25:04,252 iteration 6060 : loss : 0.016985, loss_ce: 0.004976
2022-01-14 13:25:05,203 iteration 6061 : loss : 0.020238, loss_ce: 0.010363
2022-01-14 13:25:06,345 iteration 6062 : loss : 0.029635, loss_ce: 0.009831
2022-01-14 13:25:07,315 iteration 6063 : loss : 0.014834, loss_ce: 0.006138
2022-01-14 13:25:08,304 iteration 6064 : loss : 0.010699, loss_ce: 0.003449
2022-01-14 13:25:09,362 iteration 6065 : loss : 0.022900, loss_ce: 0.009038
2022-01-14 13:25:10,311 iteration 6066 : loss : 0.015669, loss_ce: 0.006193
2022-01-14 13:25:11,359 iteration 6067 : loss : 0.029143, loss_ce: 0.009837
2022-01-14 13:25:12,382 iteration 6068 : loss : 0.011706, loss_ce: 0.002224
2022-01-14 13:25:13,506 iteration 6069 : loss : 0.017539, loss_ce: 0.007604
 89%|█████████████████████████▉   | 357/400 [1:49:47<13:02, 18.19s/it]2022-01-14 13:25:14,613 iteration 6070 : loss : 0.015978, loss_ce: 0.007361
2022-01-14 13:25:15,649 iteration 6071 : loss : 0.013022, loss_ce: 0.005458
2022-01-14 13:25:16,662 iteration 6072 : loss : 0.015393, loss_ce: 0.005941
2022-01-14 13:25:17,695 iteration 6073 : loss : 0.016535, loss_ce: 0.004627
2022-01-14 13:25:18,627 iteration 6074 : loss : 0.029567, loss_ce: 0.011855
2022-01-14 13:25:19,694 iteration 6075 : loss : 0.018933, loss_ce: 0.008171
2022-01-14 13:25:20,729 iteration 6076 : loss : 0.013270, loss_ce: 0.005475
2022-01-14 13:25:21,627 iteration 6077 : loss : 0.011428, loss_ce: 0.004102
2022-01-14 13:25:22,628 iteration 6078 : loss : 0.018360, loss_ce: 0.010359
2022-01-14 13:25:23,723 iteration 6079 : loss : 0.018605, loss_ce: 0.008216
2022-01-14 13:25:24,667 iteration 6080 : loss : 0.012988, loss_ce: 0.004700
2022-01-14 13:25:25,770 iteration 6081 : loss : 0.022144, loss_ce: 0.009027
2022-01-14 13:25:26,786 iteration 6082 : loss : 0.016597, loss_ce: 0.004275
2022-01-14 13:25:27,853 iteration 6083 : loss : 0.012896, loss_ce: 0.003309
2022-01-14 13:25:28,822 iteration 6084 : loss : 0.014782, loss_ce: 0.003892
2022-01-14 13:25:29,794 iteration 6085 : loss : 0.016654, loss_ce: 0.006973
2022-01-14 13:25:30,987 iteration 6086 : loss : 0.025228, loss_ce: 0.006424
 90%|█████████████████████████▉   | 358/400 [1:50:05<12:35, 17.98s/it]2022-01-14 13:25:32,008 iteration 6087 : loss : 0.015424, loss_ce: 0.005727
2022-01-14 13:25:33,046 iteration 6088 : loss : 0.015857, loss_ce: 0.006774
2022-01-14 13:25:34,047 iteration 6089 : loss : 0.014945, loss_ce: 0.007324
2022-01-14 13:25:35,048 iteration 6090 : loss : 0.014324, loss_ce: 0.004717
2022-01-14 13:25:36,062 iteration 6091 : loss : 0.011468, loss_ce: 0.004307
2022-01-14 13:25:37,096 iteration 6092 : loss : 0.011340, loss_ce: 0.004545
2022-01-14 13:25:38,024 iteration 6093 : loss : 0.013258, loss_ce: 0.004487
2022-01-14 13:25:38,984 iteration 6094 : loss : 0.015083, loss_ce: 0.005225
2022-01-14 13:25:40,024 iteration 6095 : loss : 0.017649, loss_ce: 0.006510
2022-01-14 13:25:41,071 iteration 6096 : loss : 0.018623, loss_ce: 0.005823
2022-01-14 13:25:42,008 iteration 6097 : loss : 0.015227, loss_ce: 0.006432
2022-01-14 13:25:43,029 iteration 6098 : loss : 0.024299, loss_ce: 0.009948
2022-01-14 13:25:44,098 iteration 6099 : loss : 0.021200, loss_ce: 0.005621
2022-01-14 13:25:45,211 iteration 6100 : loss : 0.029883, loss_ce: 0.010865
2022-01-14 13:25:46,285 iteration 6101 : loss : 0.015311, loss_ce: 0.005334
2022-01-14 13:25:47,260 iteration 6102 : loss : 0.027189, loss_ce: 0.009660
2022-01-14 13:25:48,153 iteration 6103 : loss : 0.009638, loss_ce: 0.003473
 90%|██████████████████████████   | 359/400 [1:50:22<12:07, 17.74s/it]2022-01-14 13:25:49,288 iteration 6104 : loss : 0.026428, loss_ce: 0.009286
2022-01-14 13:25:50,243 iteration 6105 : loss : 0.016825, loss_ce: 0.006108
2022-01-14 13:25:51,162 iteration 6106 : loss : 0.013150, loss_ce: 0.004426
2022-01-14 13:25:52,114 iteration 6107 : loss : 0.019707, loss_ce: 0.008635
2022-01-14 13:25:53,181 iteration 6108 : loss : 0.015935, loss_ce: 0.004805
2022-01-14 13:25:54,160 iteration 6109 : loss : 0.011546, loss_ce: 0.004389
2022-01-14 13:25:55,200 iteration 6110 : loss : 0.025643, loss_ce: 0.013581
2022-01-14 13:25:56,286 iteration 6111 : loss : 0.019002, loss_ce: 0.006892
2022-01-14 13:25:57,334 iteration 6112 : loss : 0.014783, loss_ce: 0.005328
2022-01-14 13:25:58,426 iteration 6113 : loss : 0.018066, loss_ce: 0.007110
2022-01-14 13:25:59,429 iteration 6114 : loss : 0.019873, loss_ce: 0.008232
2022-01-14 13:26:00,541 iteration 6115 : loss : 0.018675, loss_ce: 0.006331
2022-01-14 13:26:01,596 iteration 6116 : loss : 0.014116, loss_ce: 0.006158
2022-01-14 13:26:02,581 iteration 6117 : loss : 0.022334, loss_ce: 0.010232
2022-01-14 13:26:03,646 iteration 6118 : loss : 0.016237, loss_ce: 0.006388
2022-01-14 13:26:04,658 iteration 6119 : loss : 0.045639, loss_ce: 0.016154
2022-01-14 13:26:04,658 Training Data Eval:
2022-01-14 13:26:09,516   Average segmentation loss on training set: 0.0092
2022-01-14 13:26:09,516 Validation Data Eval:
2022-01-14 13:26:11,146   Average segmentation loss on validation set: 0.0681
2022-01-14 13:26:12,146 iteration 6120 : loss : 0.014375, loss_ce: 0.006765
 90%|██████████████████████████   | 360/400 [1:50:46<13:04, 19.61s/it]2022-01-14 13:26:13,252 iteration 6121 : loss : 0.015784, loss_ce: 0.006641
2022-01-14 13:26:14,322 iteration 6122 : loss : 0.022540, loss_ce: 0.008897
2022-01-14 13:26:15,430 iteration 6123 : loss : 0.018559, loss_ce: 0.007116
2022-01-14 13:26:16,459 iteration 6124 : loss : 0.015107, loss_ce: 0.004348
2022-01-14 13:26:17,589 iteration 6125 : loss : 0.022486, loss_ce: 0.006465
2022-01-14 13:26:18,608 iteration 6126 : loss : 0.021640, loss_ce: 0.004648
2022-01-14 13:26:19,610 iteration 6127 : loss : 0.014549, loss_ce: 0.005405
2022-01-14 13:26:20,711 iteration 6128 : loss : 0.020686, loss_ce: 0.006252
2022-01-14 13:26:21,744 iteration 6129 : loss : 0.013898, loss_ce: 0.005943
2022-01-14 13:26:22,865 iteration 6130 : loss : 0.021908, loss_ce: 0.008348
2022-01-14 13:26:23,912 iteration 6131 : loss : 0.021611, loss_ce: 0.010796
2022-01-14 13:26:24,945 iteration 6132 : loss : 0.023769, loss_ce: 0.005880
2022-01-14 13:26:25,924 iteration 6133 : loss : 0.012838, loss_ce: 0.006232
2022-01-14 13:26:26,881 iteration 6134 : loss : 0.010582, loss_ce: 0.004473
2022-01-14 13:26:27,830 iteration 6135 : loss : 0.011838, loss_ce: 0.004311
2022-01-14 13:26:28,872 iteration 6136 : loss : 0.015844, loss_ce: 0.005072
2022-01-14 13:26:29,866 iteration 6137 : loss : 0.013621, loss_ce: 0.005025
 90%|██████████████████████████▏  | 361/400 [1:51:03<12:22, 19.05s/it]2022-01-14 13:26:30,895 iteration 6138 : loss : 0.012037, loss_ce: 0.004252
2022-01-14 13:26:31,958 iteration 6139 : loss : 0.015802, loss_ce: 0.006360
2022-01-14 13:26:32,960 iteration 6140 : loss : 0.012584, loss_ce: 0.004426
2022-01-14 13:26:34,007 iteration 6141 : loss : 0.018532, loss_ce: 0.006721
2022-01-14 13:26:35,195 iteration 6142 : loss : 0.015463, loss_ce: 0.005319
2022-01-14 13:26:36,147 iteration 6143 : loss : 0.016700, loss_ce: 0.008220
2022-01-14 13:26:37,184 iteration 6144 : loss : 0.014006, loss_ce: 0.006053
2022-01-14 13:26:38,223 iteration 6145 : loss : 0.017440, loss_ce: 0.006408
2022-01-14 13:26:39,235 iteration 6146 : loss : 0.015629, loss_ce: 0.006888
2022-01-14 13:26:40,247 iteration 6147 : loss : 0.016953, loss_ce: 0.004149
2022-01-14 13:26:41,217 iteration 6148 : loss : 0.012113, loss_ce: 0.003608
2022-01-14 13:26:42,177 iteration 6149 : loss : 0.022013, loss_ce: 0.009274
2022-01-14 13:26:43,160 iteration 6150 : loss : 0.020158, loss_ce: 0.006345
2022-01-14 13:26:44,167 iteration 6151 : loss : 0.021644, loss_ce: 0.004889
2022-01-14 13:26:45,130 iteration 6152 : loss : 0.015345, loss_ce: 0.005981
2022-01-14 13:26:46,213 iteration 6153 : loss : 0.022591, loss_ce: 0.010566
2022-01-14 13:26:47,334 iteration 6154 : loss : 0.023509, loss_ce: 0.008989
 90%|██████████████████████████▏  | 362/400 [1:51:21<11:45, 18.57s/it]2022-01-14 13:26:48,381 iteration 6155 : loss : 0.017232, loss_ce: 0.007493
2022-01-14 13:26:49,394 iteration 6156 : loss : 0.011820, loss_ce: 0.004907
2022-01-14 13:26:50,471 iteration 6157 : loss : 0.017100, loss_ce: 0.005486
2022-01-14 13:26:51,456 iteration 6158 : loss : 0.014965, loss_ce: 0.005201
2022-01-14 13:26:52,402 iteration 6159 : loss : 0.013126, loss_ce: 0.005546
2022-01-14 13:26:53,621 iteration 6160 : loss : 0.031259, loss_ce: 0.016576
2022-01-14 13:26:54,561 iteration 6161 : loss : 0.015069, loss_ce: 0.004897
2022-01-14 13:26:55,601 iteration 6162 : loss : 0.012486, loss_ce: 0.004527
2022-01-14 13:26:56,613 iteration 6163 : loss : 0.013571, loss_ce: 0.005471
2022-01-14 13:26:57,588 iteration 6164 : loss : 0.013737, loss_ce: 0.003823
2022-01-14 13:26:58,612 iteration 6165 : loss : 0.017890, loss_ce: 0.006793
2022-01-14 13:26:59,674 iteration 6166 : loss : 0.017237, loss_ce: 0.007973
2022-01-14 13:27:00,603 iteration 6167 : loss : 0.012625, loss_ce: 0.004193
2022-01-14 13:27:01,740 iteration 6168 : loss : 0.028314, loss_ce: 0.009185
2022-01-14 13:27:02,746 iteration 6169 : loss : 0.013872, loss_ce: 0.005775
2022-01-14 13:27:03,799 iteration 6170 : loss : 0.015616, loss_ce: 0.006692
2022-01-14 13:27:04,810 iteration 6171 : loss : 0.023309, loss_ce: 0.006729
 91%|██████████████████████████▎  | 363/400 [1:51:38<11:14, 18.24s/it]2022-01-14 13:27:05,884 iteration 6172 : loss : 0.017204, loss_ce: 0.005794
2022-01-14 13:27:06,804 iteration 6173 : loss : 0.011493, loss_ce: 0.004049
2022-01-14 13:27:07,793 iteration 6174 : loss : 0.015582, loss_ce: 0.007851
2022-01-14 13:27:08,741 iteration 6175 : loss : 0.011294, loss_ce: 0.003304
2022-01-14 13:27:09,785 iteration 6176 : loss : 0.018563, loss_ce: 0.009884
2022-01-14 13:27:10,923 iteration 6177 : loss : 0.020341, loss_ce: 0.010420
2022-01-14 13:27:12,007 iteration 6178 : loss : 0.018073, loss_ce: 0.005786
2022-01-14 13:27:13,063 iteration 6179 : loss : 0.019772, loss_ce: 0.006494
2022-01-14 13:27:14,125 iteration 6180 : loss : 0.027577, loss_ce: 0.004161
2022-01-14 13:27:15,121 iteration 6181 : loss : 0.017643, loss_ce: 0.006949
2022-01-14 13:27:16,167 iteration 6182 : loss : 0.013441, loss_ce: 0.005221
2022-01-14 13:27:17,141 iteration 6183 : loss : 0.018075, loss_ce: 0.005919
2022-01-14 13:27:18,111 iteration 6184 : loss : 0.012777, loss_ce: 0.004524
2022-01-14 13:27:19,185 iteration 6185 : loss : 0.025700, loss_ce: 0.007700
2022-01-14 13:27:20,135 iteration 6186 : loss : 0.013568, loss_ce: 0.005426
2022-01-14 13:27:21,098 iteration 6187 : loss : 0.018689, loss_ce: 0.005440
2022-01-14 13:27:22,060 iteration 6188 : loss : 0.016769, loss_ce: 0.005779
 91%|██████████████████████████▍  | 364/400 [1:51:56<10:46, 17.95s/it]2022-01-14 13:27:23,229 iteration 6189 : loss : 0.017670, loss_ce: 0.006644
2022-01-14 13:27:24,256 iteration 6190 : loss : 0.012748, loss_ce: 0.004645
2022-01-14 13:27:25,359 iteration 6191 : loss : 0.022264, loss_ce: 0.007340
2022-01-14 13:27:26,421 iteration 6192 : loss : 0.015415, loss_ce: 0.005164
2022-01-14 13:27:27,393 iteration 6193 : loss : 0.011187, loss_ce: 0.003553
2022-01-14 13:27:28,461 iteration 6194 : loss : 0.014423, loss_ce: 0.005437
2022-01-14 13:27:29,560 iteration 6195 : loss : 0.019010, loss_ce: 0.007094
2022-01-14 13:27:30,532 iteration 6196 : loss : 0.015140, loss_ce: 0.005111
2022-01-14 13:27:31,656 iteration 6197 : loss : 0.017971, loss_ce: 0.006076
2022-01-14 13:27:32,790 iteration 6198 : loss : 0.017286, loss_ce: 0.006348
2022-01-14 13:27:33,780 iteration 6199 : loss : 0.013714, loss_ce: 0.005082
2022-01-14 13:27:34,838 iteration 6200 : loss : 0.017284, loss_ce: 0.007960
2022-01-14 13:27:35,871 iteration 6201 : loss : 0.017481, loss_ce: 0.006564
2022-01-14 13:27:36,881 iteration 6202 : loss : 0.014342, loss_ce: 0.004274
2022-01-14 13:27:37,880 iteration 6203 : loss : 0.019068, loss_ce: 0.006103
2022-01-14 13:27:38,945 iteration 6204 : loss : 0.017310, loss_ce: 0.006800
2022-01-14 13:27:38,945 Training Data Eval:
2022-01-14 13:27:43,801   Average segmentation loss on training set: 0.0094
2022-01-14 13:27:43,801 Validation Data Eval:
2022-01-14 13:27:45,428   Average segmentation loss on validation set: 0.0656
2022-01-14 13:27:46,551 iteration 6205 : loss : 0.020400, loss_ce: 0.009957
 91%|██████████████████████████▍  | 365/400 [1:52:20<11:36, 19.91s/it]2022-01-14 13:27:47,660 iteration 6206 : loss : 0.016765, loss_ce: 0.007727
2022-01-14 13:27:48,687 iteration 6207 : loss : 0.022259, loss_ce: 0.010388
2022-01-14 13:27:49,732 iteration 6208 : loss : 0.016080, loss_ce: 0.005525
2022-01-14 13:27:50,784 iteration 6209 : loss : 0.020357, loss_ce: 0.007290
2022-01-14 13:27:51,779 iteration 6210 : loss : 0.019254, loss_ce: 0.006793
2022-01-14 13:27:52,728 iteration 6211 : loss : 0.012372, loss_ce: 0.004285
2022-01-14 13:27:53,716 iteration 6212 : loss : 0.016383, loss_ce: 0.005823
2022-01-14 13:27:54,736 iteration 6213 : loss : 0.011702, loss_ce: 0.004420
2022-01-14 13:27:55,739 iteration 6214 : loss : 0.012400, loss_ce: 0.004671
2022-01-14 13:27:56,814 iteration 6215 : loss : 0.019143, loss_ce: 0.007007
2022-01-14 13:27:57,828 iteration 6216 : loss : 0.015101, loss_ce: 0.006845
2022-01-14 13:27:58,771 iteration 6217 : loss : 0.016301, loss_ce: 0.006187
2022-01-14 13:27:59,803 iteration 6218 : loss : 0.016365, loss_ce: 0.005670
2022-01-14 13:28:00,803 iteration 6219 : loss : 0.013225, loss_ce: 0.004384
2022-01-14 13:28:01,784 iteration 6220 : loss : 0.012004, loss_ce: 0.002767
2022-01-14 13:28:02,831 iteration 6221 : loss : 0.020494, loss_ce: 0.005459
2022-01-14 13:28:03,798 iteration 6222 : loss : 0.013684, loss_ce: 0.006320
 92%|██████████████████████████▌  | 366/400 [1:52:37<10:49, 19.11s/it]2022-01-14 13:28:04,912 iteration 6223 : loss : 0.020514, loss_ce: 0.009774
2022-01-14 13:28:05,929 iteration 6224 : loss : 0.017349, loss_ce: 0.006785
2022-01-14 13:28:06,952 iteration 6225 : loss : 0.035833, loss_ce: 0.014096
2022-01-14 13:28:07,931 iteration 6226 : loss : 0.012530, loss_ce: 0.004137
2022-01-14 13:28:08,888 iteration 6227 : loss : 0.013508, loss_ce: 0.005357
2022-01-14 13:28:09,915 iteration 6228 : loss : 0.025409, loss_ce: 0.010287
2022-01-14 13:28:10,949 iteration 6229 : loss : 0.010950, loss_ce: 0.005104
2022-01-14 13:28:12,007 iteration 6230 : loss : 0.026782, loss_ce: 0.008607
2022-01-14 13:28:13,085 iteration 6231 : loss : 0.019798, loss_ce: 0.007884
2022-01-14 13:28:14,124 iteration 6232 : loss : 0.021773, loss_ce: 0.010655
2022-01-14 13:28:15,137 iteration 6233 : loss : 0.014716, loss_ce: 0.006035
2022-01-14 13:28:16,136 iteration 6234 : loss : 0.022874, loss_ce: 0.004496
2022-01-14 13:28:17,102 iteration 6235 : loss : 0.016013, loss_ce: 0.008379
2022-01-14 13:28:18,126 iteration 6236 : loss : 0.015707, loss_ce: 0.008246
2022-01-14 13:28:19,172 iteration 6237 : loss : 0.017204, loss_ce: 0.007830
2022-01-14 13:28:20,279 iteration 6238 : loss : 0.017754, loss_ce: 0.005103
2022-01-14 13:28:21,320 iteration 6239 : loss : 0.013764, loss_ce: 0.004085
 92%|██████████████████████████▌  | 367/400 [1:52:55<10:14, 18.63s/it]2022-01-14 13:28:22,380 iteration 6240 : loss : 0.011552, loss_ce: 0.003556
2022-01-14 13:28:23,351 iteration 6241 : loss : 0.011699, loss_ce: 0.005509
2022-01-14 13:28:24,448 iteration 6242 : loss : 0.017383, loss_ce: 0.005119
2022-01-14 13:28:25,458 iteration 6243 : loss : 0.012070, loss_ce: 0.004839
2022-01-14 13:28:26,568 iteration 6244 : loss : 0.014553, loss_ce: 0.005906
2022-01-14 13:28:27,574 iteration 6245 : loss : 0.016681, loss_ce: 0.005985
2022-01-14 13:28:28,569 iteration 6246 : loss : 0.016231, loss_ce: 0.007349
2022-01-14 13:28:29,609 iteration 6247 : loss : 0.018452, loss_ce: 0.004156
2022-01-14 13:28:30,612 iteration 6248 : loss : 0.013695, loss_ce: 0.005348
2022-01-14 13:28:31,609 iteration 6249 : loss : 0.015358, loss_ce: 0.004628
2022-01-14 13:28:32,663 iteration 6250 : loss : 0.014551, loss_ce: 0.005513
2022-01-14 13:28:33,790 iteration 6251 : loss : 0.019515, loss_ce: 0.007345
2022-01-14 13:28:34,765 iteration 6252 : loss : 0.013812, loss_ce: 0.005868
2022-01-14 13:28:35,844 iteration 6253 : loss : 0.016798, loss_ce: 0.005660
2022-01-14 13:28:36,834 iteration 6254 : loss : 0.013816, loss_ce: 0.006032
2022-01-14 13:28:37,872 iteration 6255 : loss : 0.014523, loss_ce: 0.005428
2022-01-14 13:28:38,988 iteration 6256 : loss : 0.018701, loss_ce: 0.007550
 92%|██████████████████████████▋  | 368/400 [1:53:13<09:47, 18.34s/it]2022-01-14 13:28:40,126 iteration 6257 : loss : 0.025074, loss_ce: 0.007518
2022-01-14 13:28:41,204 iteration 6258 : loss : 0.016829, loss_ce: 0.006678
2022-01-14 13:28:42,313 iteration 6259 : loss : 0.020520, loss_ce: 0.008073
2022-01-14 13:28:43,326 iteration 6260 : loss : 0.017050, loss_ce: 0.007095
2022-01-14 13:28:44,329 iteration 6261 : loss : 0.014539, loss_ce: 0.005481
2022-01-14 13:28:45,382 iteration 6262 : loss : 0.019071, loss_ce: 0.005879
2022-01-14 13:28:46,425 iteration 6263 : loss : 0.023056, loss_ce: 0.005292
2022-01-14 13:28:47,465 iteration 6264 : loss : 0.013965, loss_ce: 0.005470
2022-01-14 13:28:48,516 iteration 6265 : loss : 0.016549, loss_ce: 0.006077
2022-01-14 13:28:49,514 iteration 6266 : loss : 0.026837, loss_ce: 0.013189
2022-01-14 13:28:50,493 iteration 6267 : loss : 0.014557, loss_ce: 0.006843
2022-01-14 13:28:51,512 iteration 6268 : loss : 0.012596, loss_ce: 0.004877
2022-01-14 13:28:52,388 iteration 6269 : loss : 0.011492, loss_ce: 0.004011
2022-01-14 13:28:53,385 iteration 6270 : loss : 0.013078, loss_ce: 0.006330
2022-01-14 13:28:54,384 iteration 6271 : loss : 0.013890, loss_ce: 0.003957
2022-01-14 13:28:55,456 iteration 6272 : loss : 0.018222, loss_ce: 0.006455
2022-01-14 13:28:56,523 iteration 6273 : loss : 0.017297, loss_ce: 0.006629
 92%|██████████████████████████▊  | 369/400 [1:53:30<09:21, 18.10s/it]2022-01-14 13:28:57,764 iteration 6274 : loss : 0.018320, loss_ce: 0.005926
2022-01-14 13:28:58,812 iteration 6275 : loss : 0.012485, loss_ce: 0.006164
2022-01-14 13:28:59,847 iteration 6276 : loss : 0.013127, loss_ce: 0.005108
2022-01-14 13:29:00,827 iteration 6277 : loss : 0.014322, loss_ce: 0.003959
2022-01-14 13:29:01,869 iteration 6278 : loss : 0.016061, loss_ce: 0.005262
2022-01-14 13:29:02,882 iteration 6279 : loss : 0.021656, loss_ce: 0.008250
2022-01-14 13:29:03,873 iteration 6280 : loss : 0.018586, loss_ce: 0.006576
2022-01-14 13:29:05,036 iteration 6281 : loss : 0.027662, loss_ce: 0.008293
2022-01-14 13:29:06,051 iteration 6282 : loss : 0.012014, loss_ce: 0.004974
2022-01-14 13:29:07,031 iteration 6283 : loss : 0.013779, loss_ce: 0.005596
2022-01-14 13:29:08,063 iteration 6284 : loss : 0.016694, loss_ce: 0.006899
2022-01-14 13:29:09,141 iteration 6285 : loss : 0.017029, loss_ce: 0.006190
2022-01-14 13:29:10,135 iteration 6286 : loss : 0.019544, loss_ce: 0.006039
2022-01-14 13:29:11,133 iteration 6287 : loss : 0.022781, loss_ce: 0.006239
2022-01-14 13:29:12,063 iteration 6288 : loss : 0.010906, loss_ce: 0.003537
2022-01-14 13:29:13,103 iteration 6289 : loss : 0.014442, loss_ce: 0.005945
2022-01-14 13:29:13,103 Training Data Eval:
2022-01-14 13:29:17,958   Average segmentation loss on training set: 0.0088
2022-01-14 13:29:17,958 Validation Data Eval:
2022-01-14 13:29:19,586   Average segmentation loss on validation set: 0.0668
2022-01-14 13:29:20,661 iteration 6290 : loss : 0.021989, loss_ce: 0.009189
 92%|██████████████████████████▊  | 370/400 [1:53:54<09:57, 19.91s/it]2022-01-14 13:29:21,745 iteration 6291 : loss : 0.012089, loss_ce: 0.004643
2022-01-14 13:29:22,766 iteration 6292 : loss : 0.016309, loss_ce: 0.005082
2022-01-14 13:29:23,817 iteration 6293 : loss : 0.018078, loss_ce: 0.008451
2022-01-14 13:29:24,885 iteration 6294 : loss : 0.022877, loss_ce: 0.006543
2022-01-14 13:29:25,905 iteration 6295 : loss : 0.013459, loss_ce: 0.005626
2022-01-14 13:29:27,016 iteration 6296 : loss : 0.020976, loss_ce: 0.008203
2022-01-14 13:29:28,056 iteration 6297 : loss : 0.021122, loss_ce: 0.007191
2022-01-14 13:29:29,139 iteration 6298 : loss : 0.021562, loss_ce: 0.007818
2022-01-14 13:29:30,163 iteration 6299 : loss : 0.015107, loss_ce: 0.005460
2022-01-14 13:29:31,155 iteration 6300 : loss : 0.015355, loss_ce: 0.004612
2022-01-14 13:29:32,135 iteration 6301 : loss : 0.015322, loss_ce: 0.008150
2022-01-14 13:29:33,176 iteration 6302 : loss : 0.015890, loss_ce: 0.005597
2022-01-14 13:29:34,101 iteration 6303 : loss : 0.012529, loss_ce: 0.002764
2022-01-14 13:29:35,037 iteration 6304 : loss : 0.016284, loss_ce: 0.005248
2022-01-14 13:29:36,080 iteration 6305 : loss : 0.019367, loss_ce: 0.008781
2022-01-14 13:29:37,076 iteration 6306 : loss : 0.057468, loss_ce: 0.013892
2022-01-14 13:29:38,089 iteration 6307 : loss : 0.015202, loss_ce: 0.007236
 93%|██████████████████████████▉  | 371/400 [1:54:12<09:15, 19.17s/it]2022-01-14 13:29:39,118 iteration 6308 : loss : 0.015541, loss_ce: 0.003395
2022-01-14 13:29:40,150 iteration 6309 : loss : 0.020304, loss_ce: 0.008124
2022-01-14 13:29:41,161 iteration 6310 : loss : 0.015966, loss_ce: 0.007039
2022-01-14 13:29:42,192 iteration 6311 : loss : 0.012859, loss_ce: 0.005876
2022-01-14 13:29:43,246 iteration 6312 : loss : 0.022410, loss_ce: 0.006802
2022-01-14 13:29:44,353 iteration 6313 : loss : 0.021770, loss_ce: 0.010144
2022-01-14 13:29:45,367 iteration 6314 : loss : 0.011140, loss_ce: 0.003537
2022-01-14 13:29:46,346 iteration 6315 : loss : 0.017106, loss_ce: 0.006141
2022-01-14 13:29:47,364 iteration 6316 : loss : 0.014882, loss_ce: 0.005686
2022-01-14 13:29:48,368 iteration 6317 : loss : 0.014826, loss_ce: 0.004289
2022-01-14 13:29:49,460 iteration 6318 : loss : 0.016517, loss_ce: 0.006178
2022-01-14 13:29:50,501 iteration 6319 : loss : 0.014691, loss_ce: 0.005523
2022-01-14 13:29:51,509 iteration 6320 : loss : 0.015205, loss_ce: 0.006019
2022-01-14 13:29:52,594 iteration 6321 : loss : 0.020022, loss_ce: 0.009538
2022-01-14 13:29:53,685 iteration 6322 : loss : 0.018177, loss_ce: 0.008915
2022-01-14 13:29:54,879 iteration 6323 : loss : 0.023005, loss_ce: 0.006786
2022-01-14 13:29:55,993 iteration 6324 : loss : 0.017179, loss_ce: 0.008487
 93%|██████████████████████████▉  | 372/400 [1:54:30<08:46, 18.79s/it]2022-01-14 13:29:57,121 iteration 6325 : loss : 0.015005, loss_ce: 0.003997
2022-01-14 13:29:58,111 iteration 6326 : loss : 0.017151, loss_ce: 0.007175
2022-01-14 13:29:59,124 iteration 6327 : loss : 0.020046, loss_ce: 0.005739
2022-01-14 13:30:00,196 iteration 6328 : loss : 0.011495, loss_ce: 0.005205
2022-01-14 13:30:01,142 iteration 6329 : loss : 0.012801, loss_ce: 0.005916
2022-01-14 13:30:02,146 iteration 6330 : loss : 0.016145, loss_ce: 0.006102
2022-01-14 13:30:03,243 iteration 6331 : loss : 0.018648, loss_ce: 0.006515
2022-01-14 13:30:04,341 iteration 6332 : loss : 0.013776, loss_ce: 0.003761
2022-01-14 13:30:05,378 iteration 6333 : loss : 0.011844, loss_ce: 0.005384
2022-01-14 13:30:06,407 iteration 6334 : loss : 0.019516, loss_ce: 0.004675
2022-01-14 13:30:07,532 iteration 6335 : loss : 0.018378, loss_ce: 0.008204
2022-01-14 13:30:08,531 iteration 6336 : loss : 0.016309, loss_ce: 0.006547
2022-01-14 13:30:09,582 iteration 6337 : loss : 0.018950, loss_ce: 0.006298
2022-01-14 13:30:10,628 iteration 6338 : loss : 0.017362, loss_ce: 0.005263
2022-01-14 13:30:11,662 iteration 6339 : loss : 0.014679, loss_ce: 0.004970
2022-01-14 13:30:12,704 iteration 6340 : loss : 0.018640, loss_ce: 0.008237
2022-01-14 13:30:13,656 iteration 6341 : loss : 0.011501, loss_ce: 0.003835
 93%|███████████████████████████  | 373/400 [1:54:47<08:18, 18.45s/it]2022-01-14 13:30:14,828 iteration 6342 : loss : 0.015721, loss_ce: 0.005064
2022-01-14 13:30:15,861 iteration 6343 : loss : 0.012658, loss_ce: 0.004736
2022-01-14 13:30:16,879 iteration 6344 : loss : 0.017198, loss_ce: 0.004709
2022-01-14 13:30:17,892 iteration 6345 : loss : 0.019391, loss_ce: 0.002504
2022-01-14 13:30:18,946 iteration 6346 : loss : 0.031926, loss_ce: 0.009004
2022-01-14 13:30:20,007 iteration 6347 : loss : 0.016712, loss_ce: 0.006011
2022-01-14 13:30:20,922 iteration 6348 : loss : 0.010293, loss_ce: 0.004419
2022-01-14 13:30:21,995 iteration 6349 : loss : 0.017695, loss_ce: 0.007749
2022-01-14 13:30:23,171 iteration 6350 : loss : 0.024013, loss_ce: 0.009431
2022-01-14 13:30:24,295 iteration 6351 : loss : 0.015904, loss_ce: 0.007376
2022-01-14 13:30:25,355 iteration 6352 : loss : 0.019423, loss_ce: 0.005545
2022-01-14 13:30:26,396 iteration 6353 : loss : 0.020888, loss_ce: 0.008232
2022-01-14 13:30:27,433 iteration 6354 : loss : 0.015990, loss_ce: 0.006378
2022-01-14 13:30:28,446 iteration 6355 : loss : 0.016544, loss_ce: 0.005497
2022-01-14 13:30:29,557 iteration 6356 : loss : 0.022659, loss_ce: 0.006086
2022-01-14 13:30:30,560 iteration 6357 : loss : 0.017883, loss_ce: 0.006064
2022-01-14 13:30:31,720 iteration 6358 : loss : 0.020760, loss_ce: 0.008886
 94%|███████████████████████████  | 374/400 [1:55:05<07:56, 18.34s/it]2022-01-14 13:30:32,887 iteration 6359 : loss : 0.022383, loss_ce: 0.006121
2022-01-14 13:30:33,871 iteration 6360 : loss : 0.016419, loss_ce: 0.006455
2022-01-14 13:30:34,946 iteration 6361 : loss : 0.013318, loss_ce: 0.004375
2022-01-14 13:30:36,038 iteration 6362 : loss : 0.015959, loss_ce: 0.006229
2022-01-14 13:30:37,145 iteration 6363 : loss : 0.026384, loss_ce: 0.011168
2022-01-14 13:30:38,145 iteration 6364 : loss : 0.017505, loss_ce: 0.005386
2022-01-14 13:30:39,189 iteration 6365 : loss : 0.015342, loss_ce: 0.006867
2022-01-14 13:30:40,333 iteration 6366 : loss : 0.025877, loss_ce: 0.009995
2022-01-14 13:30:41,509 iteration 6367 : loss : 0.025744, loss_ce: 0.009714
2022-01-14 13:30:42,609 iteration 6368 : loss : 0.020100, loss_ce: 0.008124
2022-01-14 13:30:43,655 iteration 6369 : loss : 0.016545, loss_ce: 0.006645
2022-01-14 13:30:44,701 iteration 6370 : loss : 0.014854, loss_ce: 0.004836
2022-01-14 13:30:45,850 iteration 6371 : loss : 0.026901, loss_ce: 0.007849
2022-01-14 13:30:46,845 iteration 6372 : loss : 0.010140, loss_ce: 0.004000
2022-01-14 13:30:47,837 iteration 6373 : loss : 0.014799, loss_ce: 0.005516
2022-01-14 13:30:48,877 iteration 6374 : loss : 0.019957, loss_ce: 0.008170
2022-01-14 13:30:48,877 Training Data Eval:
2022-01-14 13:30:53,744   Average segmentation loss on training set: 0.0089
2022-01-14 13:30:53,744 Validation Data Eval:
2022-01-14 13:30:55,374   Average segmentation loss on validation set: 0.0671
2022-01-14 13:30:56,420 iteration 6375 : loss : 0.020769, loss_ce: 0.006871
 94%|███████████████████████████▏ | 375/400 [1:55:30<08:26, 20.24s/it]2022-01-14 13:30:57,595 iteration 6376 : loss : 0.020841, loss_ce: 0.006681
2022-01-14 13:30:58,655 iteration 6377 : loss : 0.014417, loss_ce: 0.005067
2022-01-14 13:30:59,577 iteration 6378 : loss : 0.014725, loss_ce: 0.007029
2022-01-14 13:31:00,614 iteration 6379 : loss : 0.025029, loss_ce: 0.005769
2022-01-14 13:31:01,613 iteration 6380 : loss : 0.014556, loss_ce: 0.005235
2022-01-14 13:31:02,607 iteration 6381 : loss : 0.010643, loss_ce: 0.003289
2022-01-14 13:31:03,526 iteration 6382 : loss : 0.012767, loss_ce: 0.004273
2022-01-14 13:31:04,606 iteration 6383 : loss : 0.017304, loss_ce: 0.006073
2022-01-14 13:31:05,603 iteration 6384 : loss : 0.015771, loss_ce: 0.005882
2022-01-14 13:31:06,668 iteration 6385 : loss : 0.017634, loss_ce: 0.005591
2022-01-14 13:31:07,758 iteration 6386 : loss : 0.016964, loss_ce: 0.005189
2022-01-14 13:31:08,903 iteration 6387 : loss : 0.015952, loss_ce: 0.006987
2022-01-14 13:31:10,000 iteration 6388 : loss : 0.015491, loss_ce: 0.006837
2022-01-14 13:31:10,903 iteration 6389 : loss : 0.012510, loss_ce: 0.004300
2022-01-14 13:31:11,934 iteration 6390 : loss : 0.022315, loss_ce: 0.011856
2022-01-14 13:31:12,919 iteration 6391 : loss : 0.011863, loss_ce: 0.006215
2022-01-14 13:31:14,023 iteration 6392 : loss : 0.026999, loss_ce: 0.010242
 94%|███████████████████████████▎ | 376/400 [1:55:48<07:46, 19.45s/it]2022-01-14 13:31:15,117 iteration 6393 : loss : 0.015037, loss_ce: 0.005673
2022-01-14 13:31:16,216 iteration 6394 : loss : 0.018262, loss_ce: 0.006756
2022-01-14 13:31:17,228 iteration 6395 : loss : 0.013902, loss_ce: 0.004429
2022-01-14 13:31:18,263 iteration 6396 : loss : 0.014784, loss_ce: 0.005433
2022-01-14 13:31:19,310 iteration 6397 : loss : 0.019837, loss_ce: 0.007220
2022-01-14 13:31:20,371 iteration 6398 : loss : 0.012832, loss_ce: 0.004524
2022-01-14 13:31:21,399 iteration 6399 : loss : 0.019930, loss_ce: 0.006429
2022-01-14 13:31:22,407 iteration 6400 : loss : 0.013405, loss_ce: 0.005394
2022-01-14 13:31:23,474 iteration 6401 : loss : 0.013358, loss_ce: 0.005003
2022-01-14 13:31:24,491 iteration 6402 : loss : 0.014246, loss_ce: 0.007272
2022-01-14 13:31:25,620 iteration 6403 : loss : 0.021291, loss_ce: 0.009624
2022-01-14 13:31:26,633 iteration 6404 : loss : 0.012774, loss_ce: 0.005381
2022-01-14 13:31:27,621 iteration 6405 : loss : 0.021912, loss_ce: 0.006284
2022-01-14 13:31:28,823 iteration 6406 : loss : 0.032255, loss_ce: 0.007851
2022-01-14 13:31:29,871 iteration 6407 : loss : 0.019009, loss_ce: 0.005470
2022-01-14 13:31:30,778 iteration 6408 : loss : 0.010772, loss_ce: 0.003799
2022-01-14 13:31:31,784 iteration 6409 : loss : 0.017385, loss_ce: 0.007522
 94%|███████████████████████████▎ | 377/400 [1:56:05<07:15, 18.94s/it]2022-01-14 13:31:32,832 iteration 6410 : loss : 0.012643, loss_ce: 0.003899
2022-01-14 13:31:33,879 iteration 6411 : loss : 0.017926, loss_ce: 0.006914
2022-01-14 13:31:34,934 iteration 6412 : loss : 0.012625, loss_ce: 0.004467
2022-01-14 13:31:35,952 iteration 6413 : loss : 0.020554, loss_ce: 0.008648
2022-01-14 13:31:36,936 iteration 6414 : loss : 0.015126, loss_ce: 0.005925
2022-01-14 13:31:37,901 iteration 6415 : loss : 0.011995, loss_ce: 0.003871
2022-01-14 13:31:38,930 iteration 6416 : loss : 0.011200, loss_ce: 0.004210
2022-01-14 13:31:39,880 iteration 6417 : loss : 0.015751, loss_ce: 0.006130
2022-01-14 13:31:40,867 iteration 6418 : loss : 0.015633, loss_ce: 0.005698
2022-01-14 13:31:41,987 iteration 6419 : loss : 0.028628, loss_ce: 0.012364
2022-01-14 13:31:43,097 iteration 6420 : loss : 0.017548, loss_ce: 0.004284
2022-01-14 13:31:44,170 iteration 6421 : loss : 0.013750, loss_ce: 0.005604
2022-01-14 13:31:45,196 iteration 6422 : loss : 0.017603, loss_ce: 0.005160
2022-01-14 13:31:46,256 iteration 6423 : loss : 0.014470, loss_ce: 0.005421
2022-01-14 13:31:47,394 iteration 6424 : loss : 0.021572, loss_ce: 0.011898
2022-01-14 13:31:48,408 iteration 6425 : loss : 0.018817, loss_ce: 0.006137
2022-01-14 13:31:49,525 iteration 6426 : loss : 0.020641, loss_ce: 0.007603
 94%|███████████████████████████▍ | 378/400 [1:56:23<06:48, 18.58s/it]2022-01-14 13:31:50,656 iteration 6427 : loss : 0.012148, loss_ce: 0.003806
2022-01-14 13:31:51,697 iteration 6428 : loss : 0.016496, loss_ce: 0.005105
2022-01-14 13:31:52,736 iteration 6429 : loss : 0.015401, loss_ce: 0.004791
2022-01-14 13:31:53,832 iteration 6430 : loss : 0.014820, loss_ce: 0.006184
2022-01-14 13:31:54,790 iteration 6431 : loss : 0.011968, loss_ce: 0.004542
2022-01-14 13:31:55,825 iteration 6432 : loss : 0.013438, loss_ce: 0.005180
2022-01-14 13:31:56,848 iteration 6433 : loss : 0.018918, loss_ce: 0.006272
2022-01-14 13:31:57,831 iteration 6434 : loss : 0.017224, loss_ce: 0.007378
2022-01-14 13:31:58,848 iteration 6435 : loss : 0.014437, loss_ce: 0.005140
2022-01-14 13:31:59,841 iteration 6436 : loss : 0.013074, loss_ce: 0.005348
2022-01-14 13:32:00,860 iteration 6437 : loss : 0.017188, loss_ce: 0.005961
2022-01-14 13:32:01,934 iteration 6438 : loss : 0.021372, loss_ce: 0.005956
2022-01-14 13:32:02,913 iteration 6439 : loss : 0.013723, loss_ce: 0.006465
2022-01-14 13:32:03,979 iteration 6440 : loss : 0.017287, loss_ce: 0.008285
2022-01-14 13:32:04,933 iteration 6441 : loss : 0.014823, loss_ce: 0.007192
2022-01-14 13:32:05,974 iteration 6442 : loss : 0.013395, loss_ce: 0.004291
2022-01-14 13:32:06,908 iteration 6443 : loss : 0.012376, loss_ce: 0.004047
 95%|███████████████████████████▍ | 379/400 [1:56:40<06:22, 18.23s/it]2022-01-14 13:32:08,013 iteration 6444 : loss : 0.013478, loss_ce: 0.006107
2022-01-14 13:32:09,039 iteration 6445 : loss : 0.015278, loss_ce: 0.006497
2022-01-14 13:32:10,083 iteration 6446 : loss : 0.016829, loss_ce: 0.007050
2022-01-14 13:32:11,138 iteration 6447 : loss : 0.038649, loss_ce: 0.007603
2022-01-14 13:32:12,212 iteration 6448 : loss : 0.015204, loss_ce: 0.005695
2022-01-14 13:32:13,208 iteration 6449 : loss : 0.016557, loss_ce: 0.003518
2022-01-14 13:32:14,182 iteration 6450 : loss : 0.015365, loss_ce: 0.006869
2022-01-14 13:32:15,213 iteration 6451 : loss : 0.013614, loss_ce: 0.004208
2022-01-14 13:32:16,323 iteration 6452 : loss : 0.025543, loss_ce: 0.007801
2022-01-14 13:32:17,317 iteration 6453 : loss : 0.017868, loss_ce: 0.006273
2022-01-14 13:32:18,271 iteration 6454 : loss : 0.014774, loss_ce: 0.005566
2022-01-14 13:32:19,360 iteration 6455 : loss : 0.015511, loss_ce: 0.007659
2022-01-14 13:32:20,388 iteration 6456 : loss : 0.015342, loss_ce: 0.005769
2022-01-14 13:32:21,448 iteration 6457 : loss : 0.016638, loss_ce: 0.005808
2022-01-14 13:32:22,418 iteration 6458 : loss : 0.016194, loss_ce: 0.005853
2022-01-14 13:32:23,429 iteration 6459 : loss : 0.009924, loss_ce: 0.002355
2022-01-14 13:32:23,429 Training Data Eval:
2022-01-14 13:32:28,288   Average segmentation loss on training set: 0.0089
2022-01-14 13:32:28,289 Validation Data Eval:
2022-01-14 13:32:29,901   Average segmentation loss on validation set: 0.0690
2022-01-14 13:32:30,964 iteration 6460 : loss : 0.021287, loss_ce: 0.009675
 95%|███████████████████████████▌ | 380/400 [1:57:05<06:39, 19.97s/it]2022-01-14 13:32:32,120 iteration 6461 : loss : 0.031528, loss_ce: 0.012570
2022-01-14 13:32:33,112 iteration 6462 : loss : 0.012791, loss_ce: 0.005468
2022-01-14 13:32:34,196 iteration 6463 : loss : 0.017502, loss_ce: 0.007993
2022-01-14 13:32:35,228 iteration 6464 : loss : 0.016230, loss_ce: 0.004889
2022-01-14 13:32:36,299 iteration 6465 : loss : 0.015578, loss_ce: 0.005763
2022-01-14 13:32:37,271 iteration 6466 : loss : 0.013201, loss_ce: 0.004268
2022-01-14 13:32:38,269 iteration 6467 : loss : 0.015796, loss_ce: 0.005553
2022-01-14 13:32:39,364 iteration 6468 : loss : 0.017071, loss_ce: 0.005284
2022-01-14 13:32:40,370 iteration 6469 : loss : 0.013768, loss_ce: 0.005606
2022-01-14 13:32:41,358 iteration 6470 : loss : 0.016628, loss_ce: 0.005596
2022-01-14 13:32:42,397 iteration 6471 : loss : 0.013546, loss_ce: 0.005013
2022-01-14 13:32:43,428 iteration 6472 : loss : 0.024687, loss_ce: 0.008162
2022-01-14 13:32:44,420 iteration 6473 : loss : 0.013760, loss_ce: 0.004489
2022-01-14 13:32:45,519 iteration 6474 : loss : 0.015325, loss_ce: 0.007806
2022-01-14 13:32:46,568 iteration 6475 : loss : 0.032417, loss_ce: 0.019328
2022-01-14 13:32:47,470 iteration 6476 : loss : 0.013814, loss_ce: 0.004852
2022-01-14 13:32:48,598 iteration 6477 : loss : 0.019772, loss_ce: 0.007855
 95%|███████████████████████████▌ | 381/400 [1:57:22<06:06, 19.27s/it]2022-01-14 13:32:49,743 iteration 6478 : loss : 0.019257, loss_ce: 0.006527
2022-01-14 13:32:50,740 iteration 6479 : loss : 0.018912, loss_ce: 0.006475
2022-01-14 13:32:51,751 iteration 6480 : loss : 0.013763, loss_ce: 0.006415
2022-01-14 13:32:52,803 iteration 6481 : loss : 0.017141, loss_ce: 0.007608
2022-01-14 13:32:53,746 iteration 6482 : loss : 0.012364, loss_ce: 0.004223
2022-01-14 13:32:54,801 iteration 6483 : loss : 0.018995, loss_ce: 0.004660
2022-01-14 13:32:55,775 iteration 6484 : loss : 0.014532, loss_ce: 0.005437
2022-01-14 13:32:56,786 iteration 6485 : loss : 0.014278, loss_ce: 0.006066
2022-01-14 13:32:57,867 iteration 6486 : loss : 0.014248, loss_ce: 0.004875
2022-01-14 13:32:59,007 iteration 6487 : loss : 0.020180, loss_ce: 0.008546
2022-01-14 13:33:00,075 iteration 6488 : loss : 0.018195, loss_ce: 0.006116
2022-01-14 13:33:01,052 iteration 6489 : loss : 0.011253, loss_ce: 0.005514
2022-01-14 13:33:02,100 iteration 6490 : loss : 0.017762, loss_ce: 0.005564
2022-01-14 13:33:03,098 iteration 6491 : loss : 0.014140, loss_ce: 0.005610
2022-01-14 13:33:04,208 iteration 6492 : loss : 0.016521, loss_ce: 0.006609
2022-01-14 13:33:05,262 iteration 6493 : loss : 0.024784, loss_ce: 0.008943
2022-01-14 13:33:06,174 iteration 6494 : loss : 0.009222, loss_ce: 0.003702
 96%|███████████████████████████▋ | 382/400 [1:57:40<05:37, 18.76s/it]2022-01-14 13:33:07,224 iteration 6495 : loss : 0.014220, loss_ce: 0.005531
2022-01-14 13:33:08,243 iteration 6496 : loss : 0.022285, loss_ce: 0.005471
2022-01-14 13:33:09,313 iteration 6497 : loss : 0.013913, loss_ce: 0.004797
2022-01-14 13:33:10,375 iteration 6498 : loss : 0.019585, loss_ce: 0.006200
2022-01-14 13:33:11,446 iteration 6499 : loss : 0.014847, loss_ce: 0.005290
2022-01-14 13:33:12,451 iteration 6500 : loss : 0.013263, loss_ce: 0.005245
2022-01-14 13:33:13,501 iteration 6501 : loss : 0.024168, loss_ce: 0.007400
2022-01-14 13:33:14,591 iteration 6502 : loss : 0.015428, loss_ce: 0.008033
2022-01-14 13:33:15,583 iteration 6503 : loss : 0.009387, loss_ce: 0.002390
2022-01-14 13:33:16,544 iteration 6504 : loss : 0.011578, loss_ce: 0.003914
2022-01-14 13:33:17,426 iteration 6505 : loss : 0.011546, loss_ce: 0.005391
2022-01-14 13:33:18,419 iteration 6506 : loss : 0.015414, loss_ce: 0.004481
2022-01-14 13:33:19,513 iteration 6507 : loss : 0.019879, loss_ce: 0.009186
2022-01-14 13:33:20,569 iteration 6508 : loss : 0.016231, loss_ce: 0.006023
2022-01-14 13:33:21,606 iteration 6509 : loss : 0.015601, loss_ce: 0.006411
2022-01-14 13:33:22,660 iteration 6510 : loss : 0.012112, loss_ce: 0.003951
2022-01-14 13:33:23,591 iteration 6511 : loss : 0.011906, loss_ce: 0.004476
 96%|███████████████████████████▊ | 383/400 [1:57:57<05:12, 18.36s/it]2022-01-14 13:33:24,633 iteration 6512 : loss : 0.016746, loss_ce: 0.005028
2022-01-14 13:33:25,664 iteration 6513 : loss : 0.015280, loss_ce: 0.004980
2022-01-14 13:33:26,807 iteration 6514 : loss : 0.013993, loss_ce: 0.004431
2022-01-14 13:33:27,904 iteration 6515 : loss : 0.015661, loss_ce: 0.005591
2022-01-14 13:33:28,965 iteration 6516 : loss : 0.018693, loss_ce: 0.008110
2022-01-14 13:33:29,980 iteration 6517 : loss : 0.015515, loss_ce: 0.003679
2022-01-14 13:33:31,010 iteration 6518 : loss : 0.012812, loss_ce: 0.004421
2022-01-14 13:33:32,019 iteration 6519 : loss : 0.014683, loss_ce: 0.004371
2022-01-14 13:33:33,087 iteration 6520 : loss : 0.017183, loss_ce: 0.005624
2022-01-14 13:33:34,077 iteration 6521 : loss : 0.023749, loss_ce: 0.010145
2022-01-14 13:33:35,117 iteration 6522 : loss : 0.014785, loss_ce: 0.005751
2022-01-14 13:33:36,060 iteration 6523 : loss : 0.010997, loss_ce: 0.004533
2022-01-14 13:33:37,136 iteration 6524 : loss : 0.018797, loss_ce: 0.009574
2022-01-14 13:33:38,178 iteration 6525 : loss : 0.017219, loss_ce: 0.007062
2022-01-14 13:33:39,215 iteration 6526 : loss : 0.017169, loss_ce: 0.007179
2022-01-14 13:33:40,157 iteration 6527 : loss : 0.012436, loss_ce: 0.005342
2022-01-14 13:33:41,139 iteration 6528 : loss : 0.012951, loss_ce: 0.004112
 96%|███████████████████████████▊ | 384/400 [1:58:15<04:49, 18.12s/it]2022-01-14 13:33:42,280 iteration 6529 : loss : 0.017568, loss_ce: 0.005785
2022-01-14 13:33:43,332 iteration 6530 : loss : 0.012366, loss_ce: 0.004195
2022-01-14 13:33:44,286 iteration 6531 : loss : 0.011776, loss_ce: 0.003138
2022-01-14 13:33:45,340 iteration 6532 : loss : 0.015497, loss_ce: 0.005949
2022-01-14 13:33:46,281 iteration 6533 : loss : 0.009473, loss_ce: 0.003624
2022-01-14 13:33:47,302 iteration 6534 : loss : 0.016725, loss_ce: 0.007724
2022-01-14 13:33:48,348 iteration 6535 : loss : 0.017059, loss_ce: 0.006492
2022-01-14 13:33:49,402 iteration 6536 : loss : 0.015232, loss_ce: 0.005099
2022-01-14 13:33:50,442 iteration 6537 : loss : 0.014505, loss_ce: 0.004442
2022-01-14 13:33:51,504 iteration 6538 : loss : 0.013641, loss_ce: 0.004458
2022-01-14 13:33:52,587 iteration 6539 : loss : 0.014582, loss_ce: 0.006101
2022-01-14 13:33:53,524 iteration 6540 : loss : 0.010724, loss_ce: 0.004415
2022-01-14 13:33:54,509 iteration 6541 : loss : 0.028774, loss_ce: 0.021497
2022-01-14 13:33:55,639 iteration 6542 : loss : 0.012932, loss_ce: 0.004173
2022-01-14 13:33:56,630 iteration 6543 : loss : 0.012245, loss_ce: 0.004296
2022-01-14 13:33:57,688 iteration 6544 : loss : 0.020128, loss_ce: 0.007491
2022-01-14 13:33:57,688 Training Data Eval:
2022-01-14 13:34:02,535   Average segmentation loss on training set: 0.0082
2022-01-14 13:34:02,535 Validation Data Eval:
2022-01-14 13:34:04,172   Average segmentation loss on validation set: 0.0708
2022-01-14 13:34:05,284 iteration 6545 : loss : 0.016051, loss_ce: 0.005923
 96%|███████████████████████████▉ | 385/400 [1:58:39<04:58, 19.92s/it]2022-01-14 13:34:06,527 iteration 6546 : loss : 0.017722, loss_ce: 0.007714
2022-01-14 13:34:07,553 iteration 6547 : loss : 0.013601, loss_ce: 0.005617
2022-01-14 13:34:08,614 iteration 6548 : loss : 0.012444, loss_ce: 0.005272
2022-01-14 13:34:09,602 iteration 6549 : loss : 0.015119, loss_ce: 0.005663
2022-01-14 13:34:10,679 iteration 6550 : loss : 0.023323, loss_ce: 0.009023
2022-01-14 13:34:11,783 iteration 6551 : loss : 0.033144, loss_ce: 0.012425
2022-01-14 13:34:12,943 iteration 6552 : loss : 0.021098, loss_ce: 0.007921
2022-01-14 13:34:14,118 iteration 6553 : loss : 0.020677, loss_ce: 0.006756
2022-01-14 13:34:15,189 iteration 6554 : loss : 0.015988, loss_ce: 0.005085
2022-01-14 13:34:16,224 iteration 6555 : loss : 0.013171, loss_ce: 0.006195
2022-01-14 13:34:17,258 iteration 6556 : loss : 0.019778, loss_ce: 0.005754
2022-01-14 13:34:18,174 iteration 6557 : loss : 0.009438, loss_ce: 0.003798
2022-01-14 13:34:19,192 iteration 6558 : loss : 0.019547, loss_ce: 0.005640
2022-01-14 13:34:20,128 iteration 6559 : loss : 0.012468, loss_ce: 0.004448
2022-01-14 13:34:21,142 iteration 6560 : loss : 0.015665, loss_ce: 0.006826
2022-01-14 13:34:22,200 iteration 6561 : loss : 0.015053, loss_ce: 0.004664
2022-01-14 13:34:23,170 iteration 6562 : loss : 0.013719, loss_ce: 0.005125
 96%|███████████████████████████▉ | 386/400 [1:58:57<04:30, 19.32s/it]2022-01-14 13:34:24,401 iteration 6563 : loss : 0.027046, loss_ce: 0.012333
2022-01-14 13:34:25,410 iteration 6564 : loss : 0.019857, loss_ce: 0.007568
2022-01-14 13:34:26,380 iteration 6565 : loss : 0.027709, loss_ce: 0.006135
2022-01-14 13:34:27,340 iteration 6566 : loss : 0.011300, loss_ce: 0.004388
2022-01-14 13:34:28,274 iteration 6567 : loss : 0.014610, loss_ce: 0.005850
2022-01-14 13:34:29,270 iteration 6568 : loss : 0.012505, loss_ce: 0.005115
2022-01-14 13:34:30,301 iteration 6569 : loss : 0.011403, loss_ce: 0.004332
2022-01-14 13:34:31,271 iteration 6570 : loss : 0.010632, loss_ce: 0.004978
2022-01-14 13:34:32,266 iteration 6571 : loss : 0.013185, loss_ce: 0.003788
2022-01-14 13:34:33,199 iteration 6572 : loss : 0.011121, loss_ce: 0.004738
2022-01-14 13:34:34,299 iteration 6573 : loss : 0.017199, loss_ce: 0.005534
2022-01-14 13:34:35,415 iteration 6574 : loss : 0.010625, loss_ce: 0.003930
2022-01-14 13:34:36,536 iteration 6575 : loss : 0.040681, loss_ce: 0.008722
2022-01-14 13:34:37,523 iteration 6576 : loss : 0.014835, loss_ce: 0.006383
2022-01-14 13:34:38,564 iteration 6577 : loss : 0.030400, loss_ce: 0.005926
2022-01-14 13:34:39,526 iteration 6578 : loss : 0.015518, loss_ce: 0.006055
2022-01-14 13:34:40,554 iteration 6579 : loss : 0.014646, loss_ce: 0.004985
 97%|████████████████████████████ | 387/400 [1:59:14<04:03, 18.73s/it]2022-01-14 13:34:41,643 iteration 6580 : loss : 0.015737, loss_ce: 0.004524
2022-01-14 13:34:42,641 iteration 6581 : loss : 0.014739, loss_ce: 0.005077
2022-01-14 13:34:43,736 iteration 6582 : loss : 0.022316, loss_ce: 0.008401
2022-01-14 13:34:44,769 iteration 6583 : loss : 0.016652, loss_ce: 0.006568
2022-01-14 13:34:45,817 iteration 6584 : loss : 0.017351, loss_ce: 0.007454
2022-01-14 13:34:46,910 iteration 6585 : loss : 0.014242, loss_ce: 0.004419
2022-01-14 13:34:47,972 iteration 6586 : loss : 0.018283, loss_ce: 0.006023
2022-01-14 13:34:48,986 iteration 6587 : loss : 0.011233, loss_ce: 0.004929
2022-01-14 13:34:50,028 iteration 6588 : loss : 0.016484, loss_ce: 0.006622
2022-01-14 13:34:50,988 iteration 6589 : loss : 0.013908, loss_ce: 0.005348
2022-01-14 13:34:52,075 iteration 6590 : loss : 0.016396, loss_ce: 0.007674
2022-01-14 13:34:53,168 iteration 6591 : loss : 0.025536, loss_ce: 0.009965
2022-01-14 13:34:54,166 iteration 6592 : loss : 0.012405, loss_ce: 0.004784
2022-01-14 13:34:55,276 iteration 6593 : loss : 0.021561, loss_ce: 0.004811
2022-01-14 13:34:56,292 iteration 6594 : loss : 0.016832, loss_ce: 0.008934
2022-01-14 13:34:57,291 iteration 6595 : loss : 0.012096, loss_ce: 0.003788
2022-01-14 13:34:58,378 iteration 6596 : loss : 0.020996, loss_ce: 0.007682
 97%|████████████████████████████▏| 388/400 [1:59:32<03:41, 18.46s/it]2022-01-14 13:34:59,450 iteration 6597 : loss : 0.015259, loss_ce: 0.006318
2022-01-14 13:35:00,417 iteration 6598 : loss : 0.038533, loss_ce: 0.006211
2022-01-14 13:35:01,482 iteration 6599 : loss : 0.014504, loss_ce: 0.005208
2022-01-14 13:35:02,381 iteration 6600 : loss : 0.010239, loss_ce: 0.004163
2022-01-14 13:35:03,391 iteration 6601 : loss : 0.015167, loss_ce: 0.005649
2022-01-14 13:35:04,364 iteration 6602 : loss : 0.020411, loss_ce: 0.006768
2022-01-14 13:35:05,385 iteration 6603 : loss : 0.018201, loss_ce: 0.005886
2022-01-14 13:35:06,313 iteration 6604 : loss : 0.009300, loss_ce: 0.003838
2022-01-14 13:35:07,342 iteration 6605 : loss : 0.013229, loss_ce: 0.004324
2022-01-14 13:35:08,393 iteration 6606 : loss : 0.016193, loss_ce: 0.007181
2022-01-14 13:35:09,446 iteration 6607 : loss : 0.018807, loss_ce: 0.008401
2022-01-14 13:35:10,494 iteration 6608 : loss : 0.016850, loss_ce: 0.008292
2022-01-14 13:35:11,469 iteration 6609 : loss : 0.014377, loss_ce: 0.005170
2022-01-14 13:35:12,455 iteration 6610 : loss : 0.014434, loss_ce: 0.006085
2022-01-14 13:35:13,444 iteration 6611 : loss : 0.012022, loss_ce: 0.002892
2022-01-14 13:35:14,516 iteration 6612 : loss : 0.025111, loss_ce: 0.011471
2022-01-14 13:35:15,416 iteration 6613 : loss : 0.012461, loss_ce: 0.004593
 97%|████████████████████████████▏| 389/400 [1:59:49<03:18, 18.03s/it]2022-01-14 13:35:16,496 iteration 6614 : loss : 0.014927, loss_ce: 0.005698
2022-01-14 13:35:17,531 iteration 6615 : loss : 0.014504, loss_ce: 0.006829
2022-01-14 13:35:18,546 iteration 6616 : loss : 0.014741, loss_ce: 0.004006
2022-01-14 13:35:19,727 iteration 6617 : loss : 0.017056, loss_ce: 0.006110
2022-01-14 13:35:20,780 iteration 6618 : loss : 0.014656, loss_ce: 0.003894
2022-01-14 13:35:21,905 iteration 6619 : loss : 0.021788, loss_ce: 0.008691
2022-01-14 13:35:22,991 iteration 6620 : loss : 0.034933, loss_ce: 0.018130
2022-01-14 13:35:23,999 iteration 6621 : loss : 0.017306, loss_ce: 0.005216
2022-01-14 13:35:25,009 iteration 6622 : loss : 0.014966, loss_ce: 0.007173
2022-01-14 13:35:26,018 iteration 6623 : loss : 0.019036, loss_ce: 0.006747
2022-01-14 13:35:27,081 iteration 6624 : loss : 0.022084, loss_ce: 0.009131
2022-01-14 13:35:28,180 iteration 6625 : loss : 0.018501, loss_ce: 0.007197
2022-01-14 13:35:29,201 iteration 6626 : loss : 0.014608, loss_ce: 0.003558
2022-01-14 13:35:30,128 iteration 6627 : loss : 0.013544, loss_ce: 0.004239
2022-01-14 13:35:31,134 iteration 6628 : loss : 0.014198, loss_ce: 0.006254
2022-01-14 13:35:32,200 iteration 6629 : loss : 0.012401, loss_ce: 0.006038
2022-01-14 13:35:32,200 Training Data Eval:
2022-01-14 13:35:37,048   Average segmentation loss on training set: 0.0086
2022-01-14 13:35:37,048 Validation Data Eval:
2022-01-14 13:35:38,677   Average segmentation loss on validation set: 0.0720
2022-01-14 13:35:39,744 iteration 6630 : loss : 0.020141, loss_ce: 0.005958
 98%|████████████████████████████▎| 390/400 [2:00:13<03:19, 19.92s/it]2022-01-14 13:35:40,921 iteration 6631 : loss : 0.016737, loss_ce: 0.006486
2022-01-14 13:35:41,965 iteration 6632 : loss : 0.015416, loss_ce: 0.006490
2022-01-14 13:35:43,001 iteration 6633 : loss : 0.019303, loss_ce: 0.004748
2022-01-14 13:35:43,887 iteration 6634 : loss : 0.011033, loss_ce: 0.003576
2022-01-14 13:35:44,851 iteration 6635 : loss : 0.022421, loss_ce: 0.006189
2022-01-14 13:35:45,941 iteration 6636 : loss : 0.018038, loss_ce: 0.007205
2022-01-14 13:35:47,000 iteration 6637 : loss : 0.019308, loss_ce: 0.008937
2022-01-14 13:35:48,082 iteration 6638 : loss : 0.017239, loss_ce: 0.005914
2022-01-14 13:35:49,194 iteration 6639 : loss : 0.023184, loss_ce: 0.007775
2022-01-14 13:35:50,204 iteration 6640 : loss : 0.014514, loss_ce: 0.004231
2022-01-14 13:35:51,179 iteration 6641 : loss : 0.014314, loss_ce: 0.007424
2022-01-14 13:35:52,291 iteration 6642 : loss : 0.015600, loss_ce: 0.006947
2022-01-14 13:35:53,347 iteration 6643 : loss : 0.015677, loss_ce: 0.007337
2022-01-14 13:35:54,374 iteration 6644 : loss : 0.018044, loss_ce: 0.005720
2022-01-14 13:35:55,331 iteration 6645 : loss : 0.010313, loss_ce: 0.004262
2022-01-14 13:35:56,329 iteration 6646 : loss : 0.013877, loss_ce: 0.005642
2022-01-14 13:35:57,247 iteration 6647 : loss : 0.012153, loss_ce: 0.003787
 98%|████████████████████████████▎| 391/400 [2:00:31<02:52, 19.19s/it]2022-01-14 13:35:58,279 iteration 6648 : loss : 0.011755, loss_ce: 0.003773
2022-01-14 13:35:59,372 iteration 6649 : loss : 0.017050, loss_ce: 0.006992
2022-01-14 13:36:00,328 iteration 6650 : loss : 0.016348, loss_ce: 0.005957
2022-01-14 13:36:01,305 iteration 6651 : loss : 0.010789, loss_ce: 0.003723
2022-01-14 13:36:02,408 iteration 6652 : loss : 0.024143, loss_ce: 0.011525
2022-01-14 13:36:03,497 iteration 6653 : loss : 0.014374, loss_ce: 0.006086
2022-01-14 13:36:04,484 iteration 6654 : loss : 0.013623, loss_ce: 0.005422
2022-01-14 13:36:05,530 iteration 6655 : loss : 0.012956, loss_ce: 0.005022
2022-01-14 13:36:06,594 iteration 6656 : loss : 0.013402, loss_ce: 0.005503
2022-01-14 13:36:07,721 iteration 6657 : loss : 0.020924, loss_ce: 0.008760
2022-01-14 13:36:08,777 iteration 6658 : loss : 0.020974, loss_ce: 0.007901
2022-01-14 13:36:09,849 iteration 6659 : loss : 0.015577, loss_ce: 0.006197
2022-01-14 13:36:10,837 iteration 6660 : loss : 0.012883, loss_ce: 0.004311
2022-01-14 13:36:11,773 iteration 6661 : loss : 0.010788, loss_ce: 0.003948
2022-01-14 13:36:12,816 iteration 6662 : loss : 0.011462, loss_ce: 0.003803
2022-01-14 13:36:13,904 iteration 6663 : loss : 0.019660, loss_ce: 0.008160
2022-01-14 13:36:14,923 iteration 6664 : loss : 0.019876, loss_ce: 0.005772
 98%|████████████████████████████▍| 392/400 [2:00:48<02:29, 18.74s/it]2022-01-14 13:36:16,035 iteration 6665 : loss : 0.017442, loss_ce: 0.006146
2022-01-14 13:36:17,085 iteration 6666 : loss : 0.019350, loss_ce: 0.006818
2022-01-14 13:36:18,073 iteration 6667 : loss : 0.016264, loss_ce: 0.005615
2022-01-14 13:36:18,982 iteration 6668 : loss : 0.009543, loss_ce: 0.003857
2022-01-14 13:36:20,016 iteration 6669 : loss : 0.015547, loss_ce: 0.005173
2022-01-14 13:36:20,969 iteration 6670 : loss : 0.014387, loss_ce: 0.005059
2022-01-14 13:36:22,084 iteration 6671 : loss : 0.015395, loss_ce: 0.007189
2022-01-14 13:36:23,107 iteration 6672 : loss : 0.017476, loss_ce: 0.009165
2022-01-14 13:36:24,226 iteration 6673 : loss : 0.016625, loss_ce: 0.007571
2022-01-14 13:36:25,318 iteration 6674 : loss : 0.017685, loss_ce: 0.006791
2022-01-14 13:36:26,313 iteration 6675 : loss : 0.015073, loss_ce: 0.004621
2022-01-14 13:36:27,255 iteration 6676 : loss : 0.009987, loss_ce: 0.003803
2022-01-14 13:36:28,287 iteration 6677 : loss : 0.012401, loss_ce: 0.002993
2022-01-14 13:36:29,413 iteration 6678 : loss : 0.020019, loss_ce: 0.010436
2022-01-14 13:36:30,473 iteration 6679 : loss : 0.016848, loss_ce: 0.005903
2022-01-14 13:36:31,480 iteration 6680 : loss : 0.019873, loss_ce: 0.008437
2022-01-14 13:36:32,448 iteration 6681 : loss : 0.014501, loss_ce: 0.005119
 98%|████████████████████████████▍| 393/400 [2:01:06<02:08, 18.38s/it]2022-01-14 13:36:33,530 iteration 6682 : loss : 0.015599, loss_ce: 0.004894
2022-01-14 13:36:34,600 iteration 6683 : loss : 0.027019, loss_ce: 0.008354
2022-01-14 13:36:35,646 iteration 6684 : loss : 0.041590, loss_ce: 0.004443
2022-01-14 13:36:36,659 iteration 6685 : loss : 0.012448, loss_ce: 0.004815
2022-01-14 13:36:37,704 iteration 6686 : loss : 0.015267, loss_ce: 0.004789
2022-01-14 13:36:38,760 iteration 6687 : loss : 0.022377, loss_ce: 0.008805
2022-01-14 13:36:39,804 iteration 6688 : loss : 0.021610, loss_ce: 0.007714
2022-01-14 13:36:40,792 iteration 6689 : loss : 0.014164, loss_ce: 0.005804
2022-01-14 13:36:41,897 iteration 6690 : loss : 0.016800, loss_ce: 0.006454
2022-01-14 13:36:42,862 iteration 6691 : loss : 0.012267, loss_ce: 0.004477
2022-01-14 13:36:43,821 iteration 6692 : loss : 0.012597, loss_ce: 0.006989
2022-01-14 13:36:44,864 iteration 6693 : loss : 0.015594, loss_ce: 0.007628
2022-01-14 13:36:45,805 iteration 6694 : loss : 0.010122, loss_ce: 0.004265
2022-01-14 13:36:46,799 iteration 6695 : loss : 0.013291, loss_ce: 0.004013
2022-01-14 13:36:47,818 iteration 6696 : loss : 0.016713, loss_ce: 0.009421
2022-01-14 13:36:48,845 iteration 6697 : loss : 0.014166, loss_ce: 0.005357
2022-01-14 13:36:49,773 iteration 6698 : loss : 0.021221, loss_ce: 0.007026
 98%|████████████████████████████▌| 394/400 [2:01:23<01:48, 18.06s/it]2022-01-14 13:36:50,871 iteration 6699 : loss : 0.023256, loss_ce: 0.006291
2022-01-14 13:36:51,958 iteration 6700 : loss : 0.020046, loss_ce: 0.008120
2022-01-14 13:36:53,077 iteration 6701 : loss : 0.030110, loss_ce: 0.009257
2022-01-14 13:36:54,061 iteration 6702 : loss : 0.014546, loss_ce: 0.004559
2022-01-14 13:36:55,189 iteration 6703 : loss : 0.015885, loss_ce: 0.004963
2022-01-14 13:36:56,228 iteration 6704 : loss : 0.015552, loss_ce: 0.007659
2022-01-14 13:36:57,188 iteration 6705 : loss : 0.011853, loss_ce: 0.003629
2022-01-14 13:36:58,176 iteration 6706 : loss : 0.021656, loss_ce: 0.007095
2022-01-14 13:36:59,213 iteration 6707 : loss : 0.012449, loss_ce: 0.004293
2022-01-14 13:37:00,142 iteration 6708 : loss : 0.010567, loss_ce: 0.003371
2022-01-14 13:37:01,104 iteration 6709 : loss : 0.013827, loss_ce: 0.003815
2022-01-14 13:37:02,136 iteration 6710 : loss : 0.017318, loss_ce: 0.005848
2022-01-14 13:37:03,153 iteration 6711 : loss : 0.012864, loss_ce: 0.005455
2022-01-14 13:37:04,212 iteration 6712 : loss : 0.015476, loss_ce: 0.005719
2022-01-14 13:37:05,200 iteration 6713 : loss : 0.023743, loss_ce: 0.007263
2022-01-14 13:37:06,203 iteration 6714 : loss : 0.016066, loss_ce: 0.006332
2022-01-14 13:37:06,203 Training Data Eval:
2022-01-14 13:37:11,052   Average segmentation loss on training set: 0.0084
2022-01-14 13:37:11,052 Validation Data Eval:
2022-01-14 13:37:12,683   Average segmentation loss on validation set: 0.0706
2022-01-14 13:37:13,650 iteration 6715 : loss : 0.008905, loss_ce: 0.002600
 99%|████████████████████████████▋| 395/400 [2:01:47<01:39, 19.80s/it]2022-01-14 13:37:14,650 iteration 6716 : loss : 0.010535, loss_ce: 0.003584
2022-01-14 13:37:15,705 iteration 6717 : loss : 0.017862, loss_ce: 0.005508
2022-01-14 13:37:16,796 iteration 6718 : loss : 0.023908, loss_ce: 0.011465
2022-01-14 13:37:17,878 iteration 6719 : loss : 0.023145, loss_ce: 0.008511
2022-01-14 13:37:18,941 iteration 6720 : loss : 0.025189, loss_ce: 0.004752
2022-01-14 13:37:20,002 iteration 6721 : loss : 0.014122, loss_ce: 0.006121
2022-01-14 13:37:21,002 iteration 6722 : loss : 0.016239, loss_ce: 0.008143
2022-01-14 13:37:22,033 iteration 6723 : loss : 0.017627, loss_ce: 0.006853
2022-01-14 13:37:22,995 iteration 6724 : loss : 0.016642, loss_ce: 0.007632
2022-01-14 13:37:24,012 iteration 6725 : loss : 0.012273, loss_ce: 0.004292
2022-01-14 13:37:24,945 iteration 6726 : loss : 0.009912, loss_ce: 0.003526
2022-01-14 13:37:26,083 iteration 6727 : loss : 0.018649, loss_ce: 0.006012
2022-01-14 13:37:27,059 iteration 6728 : loss : 0.015045, loss_ce: 0.005760
2022-01-14 13:37:28,140 iteration 6729 : loss : 0.018274, loss_ce: 0.006290
2022-01-14 13:37:29,269 iteration 6730 : loss : 0.017555, loss_ce: 0.006745
2022-01-14 13:37:30,358 iteration 6731 : loss : 0.016697, loss_ce: 0.005535
2022-01-14 13:37:31,379 iteration 6732 : loss : 0.020442, loss_ce: 0.013191
 99%|████████████████████████████▋| 396/400 [2:02:05<01:16, 19.18s/it]2022-01-14 13:37:32,399 iteration 6733 : loss : 0.010226, loss_ce: 0.004353
2022-01-14 13:37:33,412 iteration 6734 : loss : 0.015660, loss_ce: 0.003778
2022-01-14 13:37:34,466 iteration 6735 : loss : 0.022281, loss_ce: 0.008849
2022-01-14 13:37:35,479 iteration 6736 : loss : 0.015914, loss_ce: 0.008509
2022-01-14 13:37:36,440 iteration 6737 : loss : 0.014374, loss_ce: 0.007007
2022-01-14 13:37:37,386 iteration 6738 : loss : 0.011671, loss_ce: 0.003717
2022-01-14 13:37:38,414 iteration 6739 : loss : 0.013135, loss_ce: 0.005727
2022-01-14 13:37:39,475 iteration 6740 : loss : 0.018743, loss_ce: 0.006457
2022-01-14 13:37:40,502 iteration 6741 : loss : 0.016581, loss_ce: 0.006481
2022-01-14 13:37:41,492 iteration 6742 : loss : 0.015981, loss_ce: 0.007233
2022-01-14 13:37:42,444 iteration 6743 : loss : 0.012507, loss_ce: 0.002893
2022-01-14 13:37:43,515 iteration 6744 : loss : 0.015329, loss_ce: 0.006208
2022-01-14 13:37:44,532 iteration 6745 : loss : 0.016587, loss_ce: 0.006852
2022-01-14 13:37:45,481 iteration 6746 : loss : 0.009052, loss_ce: 0.002730
2022-01-14 13:37:46,453 iteration 6747 : loss : 0.011817, loss_ce: 0.003991
2022-01-14 13:37:47,499 iteration 6748 : loss : 0.011047, loss_ce: 0.004393
2022-01-14 13:37:48,498 iteration 6749 : loss : 0.012234, loss_ce: 0.003361
 99%|████████████████████████████▊| 397/400 [2:02:22<00:55, 18.56s/it]2022-01-14 13:37:49,569 iteration 6750 : loss : 0.011349, loss_ce: 0.005103
2022-01-14 13:37:50,663 iteration 6751 : loss : 0.011697, loss_ce: 0.004705
2022-01-14 13:37:51,601 iteration 6752 : loss : 0.013531, loss_ce: 0.004282
2022-01-14 13:37:52,623 iteration 6753 : loss : 0.015638, loss_ce: 0.006615
2022-01-14 13:37:53,669 iteration 6754 : loss : 0.011801, loss_ce: 0.004221
2022-01-14 13:37:54,649 iteration 6755 : loss : 0.016080, loss_ce: 0.004734
2022-01-14 13:37:55,629 iteration 6756 : loss : 0.015664, loss_ce: 0.005935
2022-01-14 13:37:56,728 iteration 6757 : loss : 0.013987, loss_ce: 0.004249
2022-01-14 13:37:57,713 iteration 6758 : loss : 0.013490, loss_ce: 0.005872
2022-01-14 13:37:58,754 iteration 6759 : loss : 0.016086, loss_ce: 0.007425
2022-01-14 13:37:59,857 iteration 6760 : loss : 0.034064, loss_ce: 0.005134
2022-01-14 13:38:00,876 iteration 6761 : loss : 0.014946, loss_ce: 0.006065
2022-01-14 13:38:01,872 iteration 6762 : loss : 0.015055, loss_ce: 0.004502
2022-01-14 13:38:02,947 iteration 6763 : loss : 0.022695, loss_ce: 0.008874
2022-01-14 13:38:03,928 iteration 6764 : loss : 0.017137, loss_ce: 0.006787
2022-01-14 13:38:05,012 iteration 6765 : loss : 0.015040, loss_ce: 0.005613
2022-01-14 13:38:05,998 iteration 6766 : loss : 0.011099, loss_ce: 0.004903
100%|████████████████████████████▊| 398/400 [2:02:40<00:36, 18.24s/it]2022-01-14 13:38:07,070 iteration 6767 : loss : 0.025512, loss_ce: 0.009380
2022-01-14 13:38:08,190 iteration 6768 : loss : 0.021231, loss_ce: 0.007011
2022-01-14 13:38:09,238 iteration 6769 : loss : 0.015053, loss_ce: 0.006355
2022-01-14 13:38:10,233 iteration 6770 : loss : 0.017290, loss_ce: 0.009314
2022-01-14 13:38:11,353 iteration 6771 : loss : 0.019470, loss_ce: 0.004298
2022-01-14 13:38:12,338 iteration 6772 : loss : 0.012478, loss_ce: 0.004372
2022-01-14 13:38:13,214 iteration 6773 : loss : 0.011620, loss_ce: 0.003434
2022-01-14 13:38:14,259 iteration 6774 : loss : 0.021668, loss_ce: 0.006365
2022-01-14 13:38:15,321 iteration 6775 : loss : 0.018344, loss_ce: 0.006034
2022-01-14 13:38:16,328 iteration 6776 : loss : 0.022924, loss_ce: 0.007139
2022-01-14 13:38:17,441 iteration 6777 : loss : 0.015897, loss_ce: 0.007876
2022-01-14 13:38:18,455 iteration 6778 : loss : 0.016582, loss_ce: 0.006117
2022-01-14 13:38:19,575 iteration 6779 : loss : 0.017478, loss_ce: 0.006518
2022-01-14 13:38:20,620 iteration 6780 : loss : 0.013473, loss_ce: 0.006177
2022-01-14 13:38:21,705 iteration 6781 : loss : 0.016732, loss_ce: 0.008168
2022-01-14 13:38:22,790 iteration 6782 : loss : 0.015199, loss_ce: 0.005915
2022-01-14 13:38:23,780 iteration 6783 : loss : 0.015118, loss_ce: 0.005016
100%|████████████████████████████▉| 399/400 [2:02:57<00:18, 18.11s/it]2022-01-14 13:38:24,954 iteration 6784 : loss : 0.016578, loss_ce: 0.005675
2022-01-14 13:38:26,012 iteration 6785 : loss : 0.015969, loss_ce: 0.005347
2022-01-14 13:38:26,983 iteration 6786 : loss : 0.016746, loss_ce: 0.009234
2022-01-14 13:38:27,966 iteration 6787 : loss : 0.012103, loss_ce: 0.003827
2022-01-14 13:38:29,010 iteration 6788 : loss : 0.016654, loss_ce: 0.007289
2022-01-14 13:38:30,035 iteration 6789 : loss : 0.023047, loss_ce: 0.006538
2022-01-14 13:38:31,035 iteration 6790 : loss : 0.011168, loss_ce: 0.004463
2022-01-14 13:38:32,077 iteration 6791 : loss : 0.013144, loss_ce: 0.004790
2022-01-14 13:38:33,038 iteration 6792 : loss : 0.013110, loss_ce: 0.005760
2022-01-14 13:38:34,135 iteration 6793 : loss : 0.022084, loss_ce: 0.007868
2022-01-14 13:38:35,169 iteration 6794 : loss : 0.023403, loss_ce: 0.007375
2022-01-14 13:38:36,227 iteration 6795 : loss : 0.016701, loss_ce: 0.005969
2022-01-14 13:38:37,316 iteration 6796 : loss : 0.016409, loss_ce: 0.008727
2022-01-14 13:38:38,250 iteration 6797 : loss : 0.013013, loss_ce: 0.004237
2022-01-14 13:38:39,315 iteration 6798 : loss : 0.017261, loss_ce: 0.005192
2022-01-14 13:38:40,441 iteration 6799 : loss : 0.017880, loss_ce: 0.007809
2022-01-14 13:38:40,441 Training Data Eval:
2022-01-14 13:38:45,293   Average segmentation loss on training set: 0.0081
2022-01-14 13:38:45,293 Validation Data Eval:
2022-01-14 13:38:46,916   Average segmentation loss on validation set: 0.0646
2022-01-14 13:38:47,877 iteration 6800 : loss : 0.011595, loss_ce: 0.002979
100%|█████████████████████████████| 400/400 [2:03:21<00:00, 19.90s/it]100%|█████████████████████████████| 400/400 [2:03:21<00:00, 18.50s/it]
