2022-01-08 15:10:05,742 Logging directory: /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/TransUNet/log_dir/trRUNMC_cv1_r3/i2i2l/
2022-01-08 15:10:05,743 Tensorboard directory: /scratch_net/biwidl217_second/arismu/Tensorboard/trRUNMC_cv1_r3/i2i2l/
2022-01-08 15:10:05,743 ============================================================
2022-01-08 15:10:05,743 EXPERIMENT NAME: trRUNMC_cv1_r3/i2i2l/
2022-01-08 15:10:05,743 ============================================================
2022-01-08 15:10:05,743 Loading data...
2022-01-08 15:10:05,743 Reading NCI - RUNMC images...
2022-01-08 15:10:05,743 Data root directory: /itet-stor/arismu/bmicdatasets-originals/Originals/Challenge_Datasets/NCI_Prostate/
2022-01-08 15:10:05,746 Already preprocessed this configuration. Loading now!
2022-01-08 15:10:05,768 Training Images: (256, 256, 286)
2022-01-08 15:10:05,768 Training Labels: (256, 256, 286)
2022-01-08 15:10:05,768 Validation Images: (256, 256, 98)
2022-01-08 15:10:05,768 Validation Labels: (256, 256, 98)
2022-01-08 15:10:05,768 ============================================================
2022-01-08 15:10:05,806 17 iterations per epoch. 6800 max iterations 

  0%|                                         | 0/400 [00:00<?, ?it/s]2022-01-08 15:10:08,589 iteration 1 : loss : 0.983959, loss_ce: 1.213958
2022-01-08 15:10:09,917 iteration 2 : loss : 0.921545, loss_ce: 1.113424
2022-01-08 15:10:11,346 iteration 3 : loss : 0.867283, loss_ce: 1.019460
2022-01-08 15:10:12,687 iteration 4 : loss : 0.814795, loss_ce: 0.929417
2022-01-08 15:10:14,032 iteration 5 : loss : 0.765683, loss_ce: 0.856626
2022-01-08 15:10:15,390 iteration 6 : loss : 0.729262, loss_ce: 0.789449
2022-01-08 15:10:16,798 iteration 7 : loss : 0.685050, loss_ce: 0.731423
2022-01-08 15:10:18,165 iteration 8 : loss : 0.671901, loss_ce: 0.677119
2022-01-08 15:10:19,549 iteration 9 : loss : 0.607787, loss_ce: 0.635780
2022-01-08 15:10:20,960 iteration 10 : loss : 0.603912, loss_ce: 0.571899
2022-01-08 15:10:22,469 iteration 11 : loss : 0.563664, loss_ce: 0.538025
2022-01-08 15:10:23,825 iteration 12 : loss : 0.537268, loss_ce: 0.488297
2022-01-08 15:10:25,163 iteration 13 : loss : 0.524651, loss_ce: 0.456168
2022-01-08 15:10:26,473 iteration 14 : loss : 0.498677, loss_ce: 0.424242
2022-01-08 15:10:27,858 iteration 15 : loss : 0.465141, loss_ce: 0.382043
2022-01-08 15:10:29,223 iteration 16 : loss : 0.472704, loss_ce: 0.373010
2022-01-08 15:10:30,583 iteration 17 : loss : 0.418961, loss_ce: 0.339284

  0%|                               | 1/400 [00:24<2:45:23, 24.87s/it]2022-01-08 15:10:32,067 iteration 18 : loss : 0.444618, loss_ce: 0.305755
2022-01-08 15:10:33,367 iteration 19 : loss : 0.380038, loss_ce: 0.268748
2022-01-08 15:10:34,803 iteration 20 : loss : 0.370923, loss_ce: 0.248937
2022-01-08 15:10:36,144 iteration 21 : loss : 0.390607, loss_ce: 0.233337
2022-01-08 15:10:37,507 iteration 22 : loss : 0.337968, loss_ce: 0.224182
2022-01-08 15:10:38,945 iteration 23 : loss : 0.357494, loss_ce: 0.206096
2022-01-08 15:10:40,308 iteration 24 : loss : 0.327827, loss_ce: 0.197805
2022-01-08 15:10:41,726 iteration 25 : loss : 0.387638, loss_ce: 0.238404
2022-01-08 15:10:43,069 iteration 26 : loss : 0.308542, loss_ce: 0.172282
2022-01-08 15:10:44,363 iteration 27 : loss : 0.305954, loss_ce: 0.177673
2022-01-08 15:10:45,669 iteration 28 : loss : 0.298469, loss_ce: 0.165344
2022-01-08 15:10:47,071 iteration 29 : loss : 0.300476, loss_ce: 0.161381
2022-01-08 15:10:48,467 iteration 30 : loss : 0.287566, loss_ce: 0.151590
2022-01-08 15:10:49,775 iteration 31 : loss : 0.272798, loss_ce: 0.143602
2022-01-08 15:10:51,190 iteration 32 : loss : 0.301674, loss_ce: 0.169474
2022-01-08 15:10:52,593 iteration 33 : loss : 0.288182, loss_ce: 0.154164
2022-01-08 15:10:53,989 iteration 34 : loss : 0.282969, loss_ce: 0.161600

  0%|▏                              | 2/400 [00:48<2:39:09, 23.99s/it]2022-01-08 15:10:55,451 iteration 35 : loss : 0.268951, loss_ce: 0.128546
2022-01-08 15:10:56,865 iteration 36 : loss : 0.271770, loss_ce: 0.142325
2022-01-08 15:10:58,286 iteration 37 : loss : 0.282182, loss_ce: 0.127846
2022-01-08 15:10:59,624 iteration 38 : loss : 0.256172, loss_ce: 0.123143
2022-01-08 15:11:00,976 iteration 39 : loss : 0.239111, loss_ce: 0.112878
2022-01-08 15:11:02,400 iteration 40 : loss : 0.267463, loss_ce: 0.134296
2022-01-08 15:11:03,817 iteration 41 : loss : 0.313498, loss_ce: 0.156737
2022-01-08 15:11:05,212 iteration 42 : loss : 0.267792, loss_ce: 0.138115
2022-01-08 15:11:06,517 iteration 43 : loss : 0.271590, loss_ce: 0.130667
2022-01-08 15:11:07,961 iteration 44 : loss : 0.218687, loss_ce: 0.106115
2022-01-08 15:11:09,335 iteration 45 : loss : 0.213230, loss_ce: 0.097300
2022-01-08 15:11:10,725 iteration 46 : loss : 0.254878, loss_ce: 0.101425
2022-01-08 15:11:12,150 iteration 47 : loss : 0.212343, loss_ce: 0.084699
2022-01-08 15:11:13,544 iteration 48 : loss : 0.230507, loss_ce: 0.096842
2022-01-08 15:11:14,978 iteration 49 : loss : 0.287099, loss_ce: 0.134600
2022-01-08 15:11:16,316 iteration 50 : loss : 0.355344, loss_ce: 0.164369
2022-01-08 15:11:17,635 iteration 51 : loss : 0.261338, loss_ce: 0.118098

  1%|▏                              | 3/400 [01:11<2:37:41, 23.83s/it]2022-01-08 15:11:19,121 iteration 52 : loss : 0.277836, loss_ce: 0.138874
2022-01-08 15:11:20,532 iteration 53 : loss : 0.251365, loss_ce: 0.111661
2022-01-08 15:11:21,912 iteration 54 : loss : 0.248736, loss_ce: 0.102224
2022-01-08 15:11:23,302 iteration 55 : loss : 0.312669, loss_ce: 0.155932
2022-01-08 15:11:24,678 iteration 56 : loss : 0.275569, loss_ce: 0.123514
2022-01-08 15:11:26,074 iteration 57 : loss : 0.248814, loss_ce: 0.103111
2022-01-08 15:11:27,474 iteration 58 : loss : 0.286345, loss_ce: 0.125708
2022-01-08 15:11:28,837 iteration 59 : loss : 0.215975, loss_ce: 0.098517
2022-01-08 15:11:30,234 iteration 60 : loss : 0.251372, loss_ce: 0.102996
2022-01-08 15:11:31,619 iteration 61 : loss : 0.247618, loss_ce: 0.113841
2022-01-08 15:11:32,995 iteration 62 : loss : 0.332186, loss_ce: 0.125363
2022-01-08 15:11:34,300 iteration 63 : loss : 0.309855, loss_ce: 0.146834
2022-01-08 15:11:35,661 iteration 64 : loss : 0.320357, loss_ce: 0.144273
2022-01-08 15:11:36,978 iteration 65 : loss : 0.241726, loss_ce: 0.093627
2022-01-08 15:11:38,328 iteration 66 : loss : 0.217895, loss_ce: 0.095596
2022-01-08 15:11:39,756 iteration 67 : loss : 0.255855, loss_ce: 0.090682
2022-01-08 15:11:41,125 iteration 68 : loss : 0.227292, loss_ce: 0.094085

  1%|▎                              | 4/400 [01:35<2:36:22, 23.69s/it]2022-01-08 15:11:42,578 iteration 69 : loss : 0.213732, loss_ce: 0.087656
2022-01-08 15:11:44,028 iteration 70 : loss : 0.228625, loss_ce: 0.094716
2022-01-08 15:11:45,368 iteration 71 : loss : 0.238278, loss_ce: 0.096036
2022-01-08 15:11:46,754 iteration 72 : loss : 0.218594, loss_ce: 0.089299
2022-01-08 15:11:48,084 iteration 73 : loss : 0.244631, loss_ce: 0.119287
2022-01-08 15:11:49,387 iteration 74 : loss : 0.212968, loss_ce: 0.088254
2022-01-08 15:11:50,723 iteration 75 : loss : 0.225734, loss_ce: 0.095819
2022-01-08 15:11:52,048 iteration 76 : loss : 0.226089, loss_ce: 0.092445
2022-01-08 15:11:53,299 iteration 77 : loss : 0.242526, loss_ce: 0.108235
2022-01-08 15:11:54,654 iteration 78 : loss : 0.261080, loss_ce: 0.115475
2022-01-08 15:11:55,983 iteration 79 : loss : 0.289658, loss_ce: 0.107354
2022-01-08 15:11:57,302 iteration 80 : loss : 0.240080, loss_ce: 0.106705
2022-01-08 15:11:58,607 iteration 81 : loss : 0.226432, loss_ce: 0.092972
2022-01-08 15:11:59,942 iteration 82 : loss : 0.239444, loss_ce: 0.091550
2022-01-08 15:12:01,269 iteration 83 : loss : 0.248704, loss_ce: 0.090672
2022-01-08 15:12:02,688 iteration 84 : loss : 0.257917, loss_ce: 0.129930
2022-01-08 15:12:02,688 Training Data Eval:
2022-01-08 15:12:09,521   Average segmentation loss on training set: 0.5125
2022-01-08 15:12:09,522 Validation Data Eval:
2022-01-08 15:12:12,020   Average segmentation loss on validation set: 0.4766
2022-01-08 15:12:17,736 Found new lowest validation loss at iteration 84! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_KEYS_best_val_loss_seed1234.pth
2022-01-08 15:12:19,136 iteration 85 : loss : 0.241873, loss_ce: 0.095181

  1%|▍                              | 5/400 [02:13<3:09:57, 28.85s/it]2022-01-08 15:12:20,559 iteration 86 : loss : 0.241019, loss_ce: 0.082647
2022-01-08 15:12:22,042 iteration 87 : loss : 0.213587, loss_ce: 0.087718
2022-01-08 15:12:23,357 iteration 88 : loss : 0.243653, loss_ce: 0.096079
2022-01-08 15:12:24,745 iteration 89 : loss : 0.232820, loss_ce: 0.093284
2022-01-08 15:12:26,124 iteration 90 : loss : 0.220420, loss_ce: 0.088393
2022-01-08 15:12:27,568 iteration 91 : loss : 0.224163, loss_ce: 0.110421
2022-01-08 15:12:28,873 iteration 92 : loss : 0.214548, loss_ce: 0.090115
2022-01-08 15:12:30,223 iteration 93 : loss : 0.265892, loss_ce: 0.093313
2022-01-08 15:12:31,582 iteration 94 : loss : 0.226852, loss_ce: 0.088501
2022-01-08 15:12:33,064 iteration 95 : loss : 0.250225, loss_ce: 0.116811
2022-01-08 15:12:34,403 iteration 96 : loss : 0.222481, loss_ce: 0.092315
2022-01-08 15:12:35,749 iteration 97 : loss : 0.241775, loss_ce: 0.094220
2022-01-08 15:12:37,108 iteration 98 : loss : 0.246565, loss_ce: 0.100643
2022-01-08 15:12:38,546 iteration 99 : loss : 0.221338, loss_ce: 0.091322
2022-01-08 15:12:39,936 iteration 100 : loss : 0.244028, loss_ce: 0.100835
2022-01-08 15:12:41,300 iteration 101 : loss : 0.204890, loss_ce: 0.080746
2022-01-08 15:12:42,602 iteration 102 : loss : 0.240116, loss_ce: 0.099886

  2%|▍                              | 6/400 [02:36<2:57:28, 27.03s/it]2022-01-08 15:12:44,122 iteration 103 : loss : 0.209020, loss_ce: 0.092404
2022-01-08 15:12:45,568 iteration 104 : loss : 0.262654, loss_ce: 0.113256
2022-01-08 15:12:47,056 iteration 105 : loss : 0.275005, loss_ce: 0.118461
2022-01-08 15:12:48,387 iteration 106 : loss : 0.248150, loss_ce: 0.103370
2022-01-08 15:12:49,898 iteration 107 : loss : 0.213723, loss_ce: 0.094319
2022-01-08 15:12:51,207 iteration 108 : loss : 0.262750, loss_ce: 0.107921
2022-01-08 15:12:52,551 iteration 109 : loss : 0.201650, loss_ce: 0.082998
2022-01-08 15:12:53,840 iteration 110 : loss : 0.198709, loss_ce: 0.080282
2022-01-08 15:12:55,223 iteration 111 : loss : 0.249929, loss_ce: 0.106370
2022-01-08 15:12:56,523 iteration 112 : loss : 0.202142, loss_ce: 0.078162
2022-01-08 15:12:57,886 iteration 113 : loss : 0.245772, loss_ce: 0.113525
2022-01-08 15:12:59,216 iteration 114 : loss : 0.249825, loss_ce: 0.088047
2022-01-08 15:13:00,566 iteration 115 : loss : 0.228968, loss_ce: 0.095393
2022-01-08 15:13:01,969 iteration 116 : loss : 0.227214, loss_ce: 0.093819
2022-01-08 15:13:03,371 iteration 117 : loss : 0.207950, loss_ce: 0.090764
2022-01-08 15:13:04,737 iteration 118 : loss : 0.227386, loss_ce: 0.096092
2022-01-08 15:13:06,124 iteration 119 : loss : 0.207511, loss_ce: 0.075639

  2%|▌                              | 7/400 [03:00<2:49:32, 25.88s/it]2022-01-08 15:13:07,516 iteration 120 : loss : 0.327842, loss_ce: 0.156528
2022-01-08 15:13:08,827 iteration 121 : loss : 0.213162, loss_ce: 0.086691
2022-01-08 15:13:10,240 iteration 122 : loss : 0.224098, loss_ce: 0.085614
2022-01-08 15:13:11,619 iteration 123 : loss : 0.221997, loss_ce: 0.087770
2022-01-08 15:13:12,972 iteration 124 : loss : 0.217871, loss_ce: 0.077329
2022-01-08 15:13:14,294 iteration 125 : loss : 0.218750, loss_ce: 0.100817
2022-01-08 15:13:15,671 iteration 126 : loss : 0.230438, loss_ce: 0.082771
2022-01-08 15:13:16,985 iteration 127 : loss : 0.219019, loss_ce: 0.089911
2022-01-08 15:13:18,323 iteration 128 : loss : 0.202790, loss_ce: 0.080482
2022-01-08 15:13:19,730 iteration 129 : loss : 0.209772, loss_ce: 0.078772
2022-01-08 15:13:21,082 iteration 130 : loss : 0.201388, loss_ce: 0.076324
2022-01-08 15:13:22,521 iteration 131 : loss : 0.243594, loss_ce: 0.107869
2022-01-08 15:13:23,986 iteration 132 : loss : 0.213436, loss_ce: 0.057293
2022-01-08 15:13:25,324 iteration 133 : loss : 0.184455, loss_ce: 0.063258
2022-01-08 15:13:26,751 iteration 134 : loss : 0.195717, loss_ce: 0.072320
2022-01-08 15:13:28,190 iteration 135 : loss : 0.205726, loss_ce: 0.085136
2022-01-08 15:13:29,547 iteration 136 : loss : 0.177071, loss_ce: 0.070707

  2%|▌                              | 8/400 [03:23<2:43:57, 25.10s/it]2022-01-08 15:13:31,032 iteration 137 : loss : 0.223912, loss_ce: 0.077182
2022-01-08 15:13:32,368 iteration 138 : loss : 0.242144, loss_ce: 0.125874
2022-01-08 15:13:33,761 iteration 139 : loss : 0.231813, loss_ce: 0.101749
2022-01-08 15:13:35,128 iteration 140 : loss : 0.220644, loss_ce: 0.079504
2022-01-08 15:13:36,535 iteration 141 : loss : 0.210767, loss_ce: 0.093700
2022-01-08 15:13:37,953 iteration 142 : loss : 0.207106, loss_ce: 0.080071
2022-01-08 15:13:39,397 iteration 143 : loss : 0.261090, loss_ce: 0.111750
2022-01-08 15:13:40,814 iteration 144 : loss : 0.200077, loss_ce: 0.076555
2022-01-08 15:13:42,188 iteration 145 : loss : 0.224574, loss_ce: 0.084805
2022-01-08 15:13:43,585 iteration 146 : loss : 0.178399, loss_ce: 0.075342
2022-01-08 15:13:44,999 iteration 147 : loss : 0.188267, loss_ce: 0.071594
2022-01-08 15:13:46,285 iteration 148 : loss : 0.216237, loss_ce: 0.087904
2022-01-08 15:13:47,631 iteration 149 : loss : 0.261880, loss_ce: 0.115772
2022-01-08 15:13:48,956 iteration 150 : loss : 0.256011, loss_ce: 0.091587
2022-01-08 15:13:50,288 iteration 151 : loss : 0.235676, loss_ce: 0.100887
2022-01-08 15:13:51,630 iteration 152 : loss : 0.224855, loss_ce: 0.069866
2022-01-08 15:13:53,018 iteration 153 : loss : 0.244359, loss_ce: 0.102257

  2%|▋                              | 9/400 [03:47<2:40:14, 24.59s/it]2022-01-08 15:13:54,392 iteration 154 : loss : 0.287517, loss_ce: 0.122335
2022-01-08 15:13:55,771 iteration 155 : loss : 0.205966, loss_ce: 0.070309
2022-01-08 15:13:57,218 iteration 156 : loss : 0.207459, loss_ce: 0.077007
2022-01-08 15:13:58,603 iteration 157 : loss : 0.226550, loss_ce: 0.081200
2022-01-08 15:14:00,098 iteration 158 : loss : 0.209294, loss_ce: 0.084902
2022-01-08 15:14:01,361 iteration 159 : loss : 0.193917, loss_ce: 0.077901
2022-01-08 15:14:02,805 iteration 160 : loss : 0.187712, loss_ce: 0.062069
2022-01-08 15:14:04,240 iteration 161 : loss : 0.263060, loss_ce: 0.103761
2022-01-08 15:14:05,677 iteration 162 : loss : 0.236420, loss_ce: 0.112279
2022-01-08 15:14:07,046 iteration 163 : loss : 0.227350, loss_ce: 0.088689
2022-01-08 15:14:08,437 iteration 164 : loss : 0.198659, loss_ce: 0.064285
2022-01-08 15:14:09,801 iteration 165 : loss : 0.238013, loss_ce: 0.095608
2022-01-08 15:14:11,148 iteration 166 : loss : 0.205373, loss_ce: 0.070780
2022-01-08 15:14:12,511 iteration 167 : loss : 0.213949, loss_ce: 0.074821
2022-01-08 15:14:13,914 iteration 168 : loss : 0.219455, loss_ce: 0.100183
2022-01-08 15:14:15,285 iteration 169 : loss : 0.214173, loss_ce: 0.098124
2022-01-08 15:14:15,285 Training Data Eval:
2022-01-08 15:14:22,110   Average segmentation loss on training set: 0.3863
2022-01-08 15:14:22,111 Validation Data Eval:
2022-01-08 15:14:24,454   Average segmentation loss on validation set: 0.4510
2022-01-08 15:14:30,198 Found new lowest validation loss at iteration 169! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_KEYS_best_val_loss_seed1234.pth
2022-01-08 15:14:31,698 iteration 170 : loss : 0.190464, loss_ce: 0.078371

  2%|▊                             | 10/400 [04:25<3:08:04, 28.94s/it]2022-01-08 15:14:33,139 iteration 171 : loss : 0.217940, loss_ce: 0.092421
2022-01-08 15:14:34,533 iteration 172 : loss : 0.200047, loss_ce: 0.082944
2022-01-08 15:14:35,949 iteration 173 : loss : 0.181465, loss_ce: 0.072615
2022-01-08 15:14:37,281 iteration 174 : loss : 0.213585, loss_ce: 0.092019
2022-01-08 15:14:38,596 iteration 175 : loss : 0.272685, loss_ce: 0.115362
2022-01-08 15:14:39,989 iteration 176 : loss : 0.211240, loss_ce: 0.102269
2022-01-08 15:14:41,353 iteration 177 : loss : 0.224884, loss_ce: 0.093606
2022-01-08 15:14:42,720 iteration 178 : loss : 0.172280, loss_ce: 0.070501
2022-01-08 15:14:44,083 iteration 179 : loss : 0.244874, loss_ce: 0.101608
2022-01-08 15:14:45,424 iteration 180 : loss : 0.199532, loss_ce: 0.074399
2022-01-08 15:14:46,820 iteration 181 : loss : 0.188016, loss_ce: 0.075484
2022-01-08 15:14:48,155 iteration 182 : loss : 0.175262, loss_ce: 0.071234
2022-01-08 15:14:49,474 iteration 183 : loss : 0.191145, loss_ce: 0.064129
2022-01-08 15:14:50,748 iteration 184 : loss : 0.199271, loss_ce: 0.071382
2022-01-08 15:14:52,137 iteration 185 : loss : 0.240095, loss_ce: 0.085280
2022-01-08 15:14:53,533 iteration 186 : loss : 0.217197, loss_ce: 0.097194
2022-01-08 15:14:54,961 iteration 187 : loss : 0.196208, loss_ce: 0.081821

  3%|▊                             | 11/400 [04:49<2:56:20, 27.20s/it]2022-01-08 15:14:56,414 iteration 188 : loss : 0.223315, loss_ce: 0.084480
2022-01-08 15:14:57,805 iteration 189 : loss : 0.230148, loss_ce: 0.094599
2022-01-08 15:14:59,195 iteration 190 : loss : 0.251310, loss_ce: 0.096048
2022-01-08 15:15:00,544 iteration 191 : loss : 0.206582, loss_ce: 0.075842
2022-01-08 15:15:01,844 iteration 192 : loss : 0.229622, loss_ce: 0.096888
2022-01-08 15:15:03,264 iteration 193 : loss : 0.183148, loss_ce: 0.069070
2022-01-08 15:15:04,623 iteration 194 : loss : 0.234275, loss_ce: 0.067595
2022-01-08 15:15:05,956 iteration 195 : loss : 0.226104, loss_ce: 0.088619
2022-01-08 15:15:07,243 iteration 196 : loss : 0.211512, loss_ce: 0.073938
2022-01-08 15:15:08,619 iteration 197 : loss : 0.194733, loss_ce: 0.081636
2022-01-08 15:15:10,019 iteration 198 : loss : 0.170086, loss_ce: 0.075782
2022-01-08 15:15:11,353 iteration 199 : loss : 0.214007, loss_ce: 0.089360
2022-01-08 15:15:12,704 iteration 200 : loss : 0.185254, loss_ce: 0.075486
2022-01-08 15:15:14,090 iteration 201 : loss : 0.137456, loss_ce: 0.053471
2022-01-08 15:15:15,498 iteration 202 : loss : 0.177924, loss_ce: 0.081333
2022-01-08 15:15:16,828 iteration 203 : loss : 0.153840, loss_ce: 0.059493
2022-01-08 15:15:18,285 iteration 204 : loss : 0.229344, loss_ce: 0.087598

  3%|▉                             | 12/400 [05:12<2:48:15, 26.02s/it]2022-01-08 15:15:19,676 iteration 205 : loss : 0.164099, loss_ce: 0.059882
2022-01-08 15:15:21,035 iteration 206 : loss : 0.168041, loss_ce: 0.052095
2022-01-08 15:15:22,420 iteration 207 : loss : 0.186495, loss_ce: 0.079504
2022-01-08 15:15:23,770 iteration 208 : loss : 0.172568, loss_ce: 0.046299
2022-01-08 15:15:25,211 iteration 209 : loss : 0.231983, loss_ce: 0.112397
2022-01-08 15:15:26,492 iteration 210 : loss : 0.256667, loss_ce: 0.088974
2022-01-08 15:15:27,897 iteration 211 : loss : 0.220932, loss_ce: 0.110978
2022-01-08 15:15:29,282 iteration 212 : loss : 0.241515, loss_ce: 0.099410
2022-01-08 15:15:30,762 iteration 213 : loss : 0.179986, loss_ce: 0.091950
2022-01-08 15:15:32,137 iteration 214 : loss : 0.222758, loss_ce: 0.079931
2022-01-08 15:15:33,512 iteration 215 : loss : 0.238853, loss_ce: 0.091450
2022-01-08 15:15:35,037 iteration 216 : loss : 0.265025, loss_ce: 0.099987
2022-01-08 15:15:36,502 iteration 217 : loss : 0.240452, loss_ce: 0.089572
2022-01-08 15:15:37,890 iteration 218 : loss : 0.210237, loss_ce: 0.087129
2022-01-08 15:15:39,165 iteration 219 : loss : 0.214562, loss_ce: 0.088310
2022-01-08 15:15:40,562 iteration 220 : loss : 0.181712, loss_ce: 0.080367
2022-01-08 15:15:41,935 iteration 221 : loss : 0.241436, loss_ce: 0.093764

  3%|▉                             | 13/400 [05:36<2:43:12, 25.30s/it]2022-01-08 15:15:43,386 iteration 222 : loss : 0.212863, loss_ce: 0.103399
2022-01-08 15:15:44,827 iteration 223 : loss : 0.194461, loss_ce: 0.087003
2022-01-08 15:15:46,225 iteration 224 : loss : 0.305378, loss_ce: 0.167169
2022-01-08 15:15:47,722 iteration 225 : loss : 0.319314, loss_ce: 0.111926
2022-01-08 15:15:49,110 iteration 226 : loss : 0.269880, loss_ce: 0.107525
2022-01-08 15:15:50,551 iteration 227 : loss : 0.284985, loss_ce: 0.133138
2022-01-08 15:15:51,937 iteration 228 : loss : 0.249046, loss_ce: 0.115733
2022-01-08 15:15:53,278 iteration 229 : loss : 0.205854, loss_ce: 0.072750
2022-01-08 15:15:54,665 iteration 230 : loss : 0.192518, loss_ce: 0.084098
2022-01-08 15:15:56,084 iteration 231 : loss : 0.307633, loss_ce: 0.129041
2022-01-08 15:15:57,497 iteration 232 : loss : 0.193605, loss_ce: 0.083035
2022-01-08 15:15:58,852 iteration 233 : loss : 0.264375, loss_ce: 0.123334
2022-01-08 15:16:00,344 iteration 234 : loss : 0.200204, loss_ce: 0.074546
2022-01-08 15:16:01,703 iteration 235 : loss : 0.186255, loss_ce: 0.081392
2022-01-08 15:16:03,128 iteration 236 : loss : 0.190916, loss_ce: 0.074173
2022-01-08 15:16:04,496 iteration 237 : loss : 0.170051, loss_ce: 0.065553
2022-01-08 15:16:05,880 iteration 238 : loss : 0.193689, loss_ce: 0.093335

  4%|█                             | 14/400 [06:00<2:40:09, 24.89s/it]2022-01-08 15:16:07,261 iteration 239 : loss : 0.216186, loss_ce: 0.071144
2022-01-08 15:16:08,672 iteration 240 : loss : 0.175439, loss_ce: 0.083399
2022-01-08 15:16:10,077 iteration 241 : loss : 0.186152, loss_ce: 0.079232
2022-01-08 15:16:11,465 iteration 242 : loss : 0.230365, loss_ce: 0.119612
2022-01-08 15:16:12,992 iteration 243 : loss : 0.214369, loss_ce: 0.084916
2022-01-08 15:16:14,320 iteration 244 : loss : 0.239281, loss_ce: 0.058587
2022-01-08 15:16:15,708 iteration 245 : loss : 0.184152, loss_ce: 0.084142
2022-01-08 15:16:17,138 iteration 246 : loss : 0.163802, loss_ce: 0.067351
2022-01-08 15:16:18,501 iteration 247 : loss : 0.193959, loss_ce: 0.061162
2022-01-08 15:16:19,861 iteration 248 : loss : 0.168015, loss_ce: 0.054931
2022-01-08 15:16:21,208 iteration 249 : loss : 0.213776, loss_ce: 0.108160
2022-01-08 15:16:22,570 iteration 250 : loss : 0.214832, loss_ce: 0.087288
2022-01-08 15:16:23,880 iteration 251 : loss : 0.216781, loss_ce: 0.078075
2022-01-08 15:16:25,237 iteration 252 : loss : 0.138350, loss_ce: 0.060833
2022-01-08 15:16:26,632 iteration 253 : loss : 0.187798, loss_ce: 0.071623
2022-01-08 15:16:28,083 iteration 254 : loss : 0.272097, loss_ce: 0.091146
2022-01-08 15:16:28,083 Training Data Eval:
2022-01-08 15:16:34,919   Average segmentation loss on training set: 0.1592
2022-01-08 15:16:34,919 Validation Data Eval:
2022-01-08 15:16:37,278   Average segmentation loss on validation set: 0.1622
2022-01-08 15:16:43,171 Found new lowest validation loss at iteration 254! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_KEYS_best_val_loss_seed1234.pth
2022-01-08 15:16:44,587 iteration 255 : loss : 0.175230, loss_ce: 0.076035

  4%|█▏                            | 15/400 [06:38<3:06:27, 29.06s/it]2022-01-08 15:16:46,039 iteration 256 : loss : 0.200158, loss_ce: 0.079125
2022-01-08 15:16:47,462 iteration 257 : loss : 0.166410, loss_ce: 0.062228
2022-01-08 15:16:48,932 iteration 258 : loss : 0.174388, loss_ce: 0.068041
2022-01-08 15:16:50,229 iteration 259 : loss : 0.180399, loss_ce: 0.078712
2022-01-08 15:16:51,659 iteration 260 : loss : 0.167335, loss_ce: 0.074853
2022-01-08 15:16:53,048 iteration 261 : loss : 0.231276, loss_ce: 0.078236
2022-01-08 15:16:54,524 iteration 262 : loss : 0.182209, loss_ce: 0.075802
2022-01-08 15:16:55,901 iteration 263 : loss : 0.171369, loss_ce: 0.067948
2022-01-08 15:16:57,307 iteration 264 : loss : 0.213844, loss_ce: 0.092677
2022-01-08 15:16:58,649 iteration 265 : loss : 0.150321, loss_ce: 0.062139
2022-01-08 15:17:00,059 iteration 266 : loss : 0.160670, loss_ce: 0.071313
2022-01-08 15:17:01,430 iteration 267 : loss : 0.201203, loss_ce: 0.064087
2022-01-08 15:17:02,813 iteration 268 : loss : 0.213091, loss_ce: 0.096229
2022-01-08 15:17:04,388 iteration 269 : loss : 0.177548, loss_ce: 0.064307
2022-01-08 15:17:05,868 iteration 270 : loss : 0.154333, loss_ce: 0.063793
2022-01-08 15:17:07,127 iteration 271 : loss : 0.165517, loss_ce: 0.047660
2022-01-08 15:17:08,507 iteration 272 : loss : 0.169485, loss_ce: 0.081589

  4%|█▏                            | 16/400 [07:02<2:56:04, 27.51s/it]2022-01-08 15:17:09,898 iteration 273 : loss : 0.150260, loss_ce: 0.054865
2022-01-08 15:17:11,212 iteration 274 : loss : 0.135943, loss_ce: 0.049995
2022-01-08 15:17:12,535 iteration 275 : loss : 0.135961, loss_ce: 0.054130
2022-01-08 15:17:13,916 iteration 276 : loss : 0.143725, loss_ce: 0.068819
2022-01-08 15:17:15,317 iteration 277 : loss : 0.139109, loss_ce: 0.052820
2022-01-08 15:17:16,568 iteration 278 : loss : 0.174401, loss_ce: 0.060413
2022-01-08 15:17:17,885 iteration 279 : loss : 0.184960, loss_ce: 0.066288
2022-01-08 15:17:19,194 iteration 280 : loss : 0.173849, loss_ce: 0.074021
2022-01-08 15:17:20,565 iteration 281 : loss : 0.151536, loss_ce: 0.066341
2022-01-08 15:17:21,913 iteration 282 : loss : 0.242103, loss_ce: 0.103503
2022-01-08 15:17:23,241 iteration 283 : loss : 0.178417, loss_ce: 0.085742
2022-01-08 15:17:24,669 iteration 284 : loss : 0.184190, loss_ce: 0.072321
2022-01-08 15:17:26,021 iteration 285 : loss : 0.185813, loss_ce: 0.065030
2022-01-08 15:17:27,353 iteration 286 : loss : 0.164909, loss_ce: 0.072289
2022-01-08 15:17:28,799 iteration 287 : loss : 0.209799, loss_ce: 0.094152
2022-01-08 15:17:30,223 iteration 288 : loss : 0.200130, loss_ce: 0.079296
2022-01-08 15:17:31,571 iteration 289 : loss : 0.171236, loss_ce: 0.063431

  4%|█▎                            | 17/400 [07:25<2:47:03, 26.17s/it]2022-01-08 15:17:33,007 iteration 290 : loss : 0.150446, loss_ce: 0.056035
2022-01-08 15:17:34,340 iteration 291 : loss : 0.168116, loss_ce: 0.070712
2022-01-08 15:17:35,681 iteration 292 : loss : 0.167598, loss_ce: 0.064855
2022-01-08 15:17:37,028 iteration 293 : loss : 0.194109, loss_ce: 0.081720
2022-01-08 15:17:38,405 iteration 294 : loss : 0.175997, loss_ce: 0.070052
2022-01-08 15:17:39,874 iteration 295 : loss : 0.192680, loss_ce: 0.061771
2022-01-08 15:17:41,218 iteration 296 : loss : 0.148461, loss_ce: 0.053674
2022-01-08 15:17:42,596 iteration 297 : loss : 0.139989, loss_ce: 0.049084
2022-01-08 15:17:43,933 iteration 298 : loss : 0.137642, loss_ce: 0.048879
2022-01-08 15:17:45,296 iteration 299 : loss : 0.148664, loss_ce: 0.052325
2022-01-08 15:17:46,665 iteration 300 : loss : 0.185448, loss_ce: 0.057629
2022-01-08 15:17:48,047 iteration 301 : loss : 0.268972, loss_ce: 0.157381
2022-01-08 15:17:49,479 iteration 302 : loss : 0.150833, loss_ce: 0.061518
2022-01-08 15:17:50,891 iteration 303 : loss : 0.177519, loss_ce: 0.072187
2022-01-08 15:17:52,282 iteration 304 : loss : 0.246000, loss_ce: 0.122228
2022-01-08 15:17:53,707 iteration 305 : loss : 0.166423, loss_ce: 0.069580
2022-01-08 15:17:55,170 iteration 306 : loss : 0.138905, loss_ce: 0.067468

  4%|█▎                            | 18/400 [07:49<2:41:43, 25.40s/it]2022-01-08 15:17:56,617 iteration 307 : loss : 0.163118, loss_ce: 0.063023
2022-01-08 15:17:57,952 iteration 308 : loss : 0.164472, loss_ce: 0.088607
2022-01-08 15:17:59,343 iteration 309 : loss : 0.257067, loss_ce: 0.117725
2022-01-08 15:18:00,758 iteration 310 : loss : 0.153955, loss_ce: 0.064964
2022-01-08 15:18:02,094 iteration 311 : loss : 0.167334, loss_ce: 0.053530
2022-01-08 15:18:03,460 iteration 312 : loss : 0.135167, loss_ce: 0.059254
2022-01-08 15:18:04,838 iteration 313 : loss : 0.171692, loss_ce: 0.082831
2022-01-08 15:18:06,142 iteration 314 : loss : 0.124930, loss_ce: 0.057044
2022-01-08 15:18:07,493 iteration 315 : loss : 0.156778, loss_ce: 0.062628
2022-01-08 15:18:08,879 iteration 316 : loss : 0.163412, loss_ce: 0.066027
2022-01-08 15:18:10,250 iteration 317 : loss : 0.206629, loss_ce: 0.081921
2022-01-08 15:18:11,640 iteration 318 : loss : 0.169642, loss_ce: 0.067549
2022-01-08 15:18:12,959 iteration 319 : loss : 0.149448, loss_ce: 0.061787
2022-01-08 15:18:14,406 iteration 320 : loss : 0.137632, loss_ce: 0.054796
2022-01-08 15:18:15,816 iteration 321 : loss : 0.166557, loss_ce: 0.049847
2022-01-08 15:18:17,182 iteration 322 : loss : 0.222493, loss_ce: 0.092052
2022-01-08 15:18:18,611 iteration 323 : loss : 0.171293, loss_ce: 0.049498

  5%|█▍                            | 19/400 [08:12<2:37:33, 24.81s/it]2022-01-08 15:18:20,040 iteration 324 : loss : 0.167065, loss_ce: 0.064474
2022-01-08 15:18:21,418 iteration 325 : loss : 0.158552, loss_ce: 0.047094
2022-01-08 15:18:22,825 iteration 326 : loss : 0.128370, loss_ce: 0.058569
2022-01-08 15:18:24,299 iteration 327 : loss : 0.180789, loss_ce: 0.067739
2022-01-08 15:18:25,665 iteration 328 : loss : 0.204445, loss_ce: 0.092326
2022-01-08 15:18:27,075 iteration 329 : loss : 0.174258, loss_ce: 0.084018
2022-01-08 15:18:28,498 iteration 330 : loss : 0.142937, loss_ce: 0.059101
2022-01-08 15:18:29,832 iteration 331 : loss : 0.138638, loss_ce: 0.066187
2022-01-08 15:18:31,192 iteration 332 : loss : 0.126023, loss_ce: 0.046682
2022-01-08 15:18:32,591 iteration 333 : loss : 0.112799, loss_ce: 0.050510
2022-01-08 15:18:33,971 iteration 334 : loss : 0.148616, loss_ce: 0.062889
2022-01-08 15:18:35,322 iteration 335 : loss : 0.196455, loss_ce: 0.065527
2022-01-08 15:18:36,748 iteration 336 : loss : 0.120538, loss_ce: 0.041060
2022-01-08 15:18:38,120 iteration 337 : loss : 0.141540, loss_ce: 0.043829
2022-01-08 15:18:39,451 iteration 338 : loss : 0.193709, loss_ce: 0.095728
2022-01-08 15:18:40,787 iteration 339 : loss : 0.173079, loss_ce: 0.054643
2022-01-08 15:18:40,788 Training Data Eval:
2022-01-08 15:18:47,615   Average segmentation loss on training set: 0.2844
2022-01-08 15:18:47,615 Validation Data Eval:
2022-01-08 15:18:49,971   Average segmentation loss on validation set: 0.3249
2022-01-08 15:18:51,388 iteration 340 : loss : 0.173000, loss_ce: 0.069806

  5%|█▌                            | 20/400 [08:45<2:52:16, 27.20s/it]2022-01-08 15:18:52,863 iteration 341 : loss : 0.136199, loss_ce: 0.065255
2022-01-08 15:18:54,267 iteration 342 : loss : 0.138115, loss_ce: 0.046311
2022-01-08 15:18:55,637 iteration 343 : loss : 0.180149, loss_ce: 0.071197
2022-01-08 15:18:57,044 iteration 344 : loss : 0.187846, loss_ce: 0.074972
2022-01-08 15:18:58,415 iteration 345 : loss : 0.119970, loss_ce: 0.038916
2022-01-08 15:18:59,848 iteration 346 : loss : 0.179333, loss_ce: 0.067039
2022-01-08 15:19:01,172 iteration 347 : loss : 0.128354, loss_ce: 0.057997
2022-01-08 15:19:02,568 iteration 348 : loss : 0.146369, loss_ce: 0.056492
2022-01-08 15:19:04,069 iteration 349 : loss : 0.155399, loss_ce: 0.074421
2022-01-08 15:19:05,439 iteration 350 : loss : 0.137154, loss_ce: 0.055411
2022-01-08 15:19:06,865 iteration 351 : loss : 0.149995, loss_ce: 0.068169
2022-01-08 15:19:08,271 iteration 352 : loss : 0.150737, loss_ce: 0.059565
2022-01-08 15:19:09,595 iteration 353 : loss : 0.125494, loss_ce: 0.046851
2022-01-08 15:19:10,974 iteration 354 : loss : 0.165561, loss_ce: 0.054464
2022-01-08 15:19:12,399 iteration 355 : loss : 0.174872, loss_ce: 0.076236
2022-01-08 15:19:13,897 iteration 356 : loss : 0.154555, loss_ce: 0.067037
2022-01-08 15:19:15,214 iteration 357 : loss : 0.150038, loss_ce: 0.057717

  5%|█▌                            | 21/400 [09:09<2:45:25, 26.19s/it]2022-01-08 15:19:16,680 iteration 358 : loss : 0.144541, loss_ce: 0.061416
2022-01-08 15:19:18,129 iteration 359 : loss : 0.157881, loss_ce: 0.060354
2022-01-08 15:19:19,450 iteration 360 : loss : 0.121058, loss_ce: 0.045130
2022-01-08 15:19:20,861 iteration 361 : loss : 0.210957, loss_ce: 0.080569
2022-01-08 15:19:22,322 iteration 362 : loss : 0.144191, loss_ce: 0.039419
2022-01-08 15:19:23,775 iteration 363 : loss : 0.171104, loss_ce: 0.066537
2022-01-08 15:19:25,182 iteration 364 : loss : 0.149339, loss_ce: 0.055785
2022-01-08 15:19:26,469 iteration 365 : loss : 0.176527, loss_ce: 0.074613
2022-01-08 15:19:27,880 iteration 366 : loss : 0.173666, loss_ce: 0.080550
2022-01-08 15:19:29,195 iteration 367 : loss : 0.144754, loss_ce: 0.057531
2022-01-08 15:19:30,612 iteration 368 : loss : 0.158560, loss_ce: 0.054591
2022-01-08 15:19:32,067 iteration 369 : loss : 0.208708, loss_ce: 0.069929
2022-01-08 15:19:33,504 iteration 370 : loss : 0.138502, loss_ce: 0.070347
2022-01-08 15:19:34,900 iteration 371 : loss : 0.233995, loss_ce: 0.076838
2022-01-08 15:19:36,306 iteration 372 : loss : 0.224759, loss_ce: 0.112582
2022-01-08 15:19:37,639 iteration 373 : loss : 0.167984, loss_ce: 0.056099
2022-01-08 15:19:39,001 iteration 374 : loss : 0.172470, loss_ce: 0.066864

  6%|█▋                            | 22/400 [09:33<2:40:28, 25.47s/it]2022-01-08 15:19:40,494 iteration 375 : loss : 0.248672, loss_ce: 0.106418
2022-01-08 15:19:41,829 iteration 376 : loss : 0.105870, loss_ce: 0.035222
2022-01-08 15:19:43,191 iteration 377 : loss : 0.136372, loss_ce: 0.041606
2022-01-08 15:19:44,636 iteration 378 : loss : 0.193603, loss_ce: 0.088951
2022-01-08 15:19:45,939 iteration 379 : loss : 0.134319, loss_ce: 0.051528
2022-01-08 15:19:47,344 iteration 380 : loss : 0.137113, loss_ce: 0.046945
2022-01-08 15:19:48,711 iteration 381 : loss : 0.106440, loss_ce: 0.034198
2022-01-08 15:19:50,008 iteration 382 : loss : 0.146336, loss_ce: 0.062791
2022-01-08 15:19:51,376 iteration 383 : loss : 0.179415, loss_ce: 0.065019
2022-01-08 15:19:52,769 iteration 384 : loss : 0.120895, loss_ce: 0.047568
2022-01-08 15:19:54,145 iteration 385 : loss : 0.107658, loss_ce: 0.046172
2022-01-08 15:19:55,531 iteration 386 : loss : 0.145893, loss_ce: 0.048779
2022-01-08 15:19:56,927 iteration 387 : loss : 0.187247, loss_ce: 0.065126
2022-01-08 15:19:58,341 iteration 388 : loss : 0.135357, loss_ce: 0.051502
2022-01-08 15:19:59,750 iteration 389 : loss : 0.220423, loss_ce: 0.102128
2022-01-08 15:20:01,111 iteration 390 : loss : 0.118513, loss_ce: 0.048271
2022-01-08 15:20:02,500 iteration 391 : loss : 0.194873, loss_ce: 0.105969

  6%|█▋                            | 23/400 [09:56<2:36:17, 24.87s/it]2022-01-08 15:20:03,957 iteration 392 : loss : 0.147448, loss_ce: 0.084038
2022-01-08 15:20:05,298 iteration 393 : loss : 0.127931, loss_ce: 0.043394
2022-01-08 15:20:06,725 iteration 394 : loss : 0.151123, loss_ce: 0.060501
2022-01-08 15:20:08,125 iteration 395 : loss : 0.159591, loss_ce: 0.064480
2022-01-08 15:20:09,477 iteration 396 : loss : 0.127433, loss_ce: 0.049902
2022-01-08 15:20:10,856 iteration 397 : loss : 0.156802, loss_ce: 0.066731
2022-01-08 15:20:12,256 iteration 398 : loss : 0.112467, loss_ce: 0.044081
2022-01-08 15:20:13,535 iteration 399 : loss : 0.154958, loss_ce: 0.058347
2022-01-08 15:20:14,920 iteration 400 : loss : 0.154141, loss_ce: 0.055429
2022-01-08 15:20:16,353 iteration 401 : loss : 0.153058, loss_ce: 0.064009
2022-01-08 15:20:17,707 iteration 402 : loss : 0.119571, loss_ce: 0.052458
2022-01-08 15:20:19,063 iteration 403 : loss : 0.106792, loss_ce: 0.040514
2022-01-08 15:20:20,473 iteration 404 : loss : 0.157275, loss_ce: 0.067996
2022-01-08 15:20:21,917 iteration 405 : loss : 0.161031, loss_ce: 0.070786
2022-01-08 15:20:23,271 iteration 406 : loss : 0.158924, loss_ce: 0.066660
2022-01-08 15:20:24,587 iteration 407 : loss : 0.134919, loss_ce: 0.049976
2022-01-08 15:20:25,946 iteration 408 : loss : 0.154086, loss_ce: 0.051244

  6%|█▊                            | 24/400 [10:20<2:33:13, 24.45s/it]2022-01-08 15:20:27,415 iteration 409 : loss : 0.136658, loss_ce: 0.060234
2022-01-08 15:20:28,815 iteration 410 : loss : 0.128988, loss_ce: 0.044041
2022-01-08 15:20:30,188 iteration 411 : loss : 0.264887, loss_ce: 0.077874
2022-01-08 15:20:31,477 iteration 412 : loss : 0.118441, loss_ce: 0.040804
2022-01-08 15:20:32,845 iteration 413 : loss : 0.141032, loss_ce: 0.049586
2022-01-08 15:20:34,165 iteration 414 : loss : 0.190992, loss_ce: 0.099614
2022-01-08 15:20:35,436 iteration 415 : loss : 0.119378, loss_ce: 0.046412
2022-01-08 15:20:36,791 iteration 416 : loss : 0.150616, loss_ce: 0.077353
2022-01-08 15:20:38,118 iteration 417 : loss : 0.203053, loss_ce: 0.073947
2022-01-08 15:20:39,543 iteration 418 : loss : 0.121505, loss_ce: 0.048146
2022-01-08 15:20:40,887 iteration 419 : loss : 0.165127, loss_ce: 0.085267
2022-01-08 15:20:42,270 iteration 420 : loss : 0.130061, loss_ce: 0.051888
2022-01-08 15:20:43,598 iteration 421 : loss : 0.176173, loss_ce: 0.072660
2022-01-08 15:20:44,920 iteration 422 : loss : 0.196634, loss_ce: 0.083154
2022-01-08 15:20:46,250 iteration 423 : loss : 0.153778, loss_ce: 0.046765
2022-01-08 15:20:47,633 iteration 424 : loss : 0.141351, loss_ce: 0.052151
2022-01-08 15:20:47,633 Training Data Eval:
2022-01-08 15:20:54,470   Average segmentation loss on training set: 0.1329
2022-01-08 15:20:54,470 Validation Data Eval:
2022-01-08 15:20:56,826   Average segmentation loss on validation set: 0.1707
2022-01-08 15:20:58,174 iteration 425 : loss : 0.138613, loss_ce: 0.055900

  6%|█▉                            | 25/400 [10:52<2:47:23, 26.78s/it]2022-01-08 15:20:59,559 iteration 426 : loss : 0.142126, loss_ce: 0.043260
2022-01-08 15:21:00,967 iteration 427 : loss : 0.114818, loss_ce: 0.040586
2022-01-08 15:21:02,344 iteration 428 : loss : 0.144533, loss_ce: 0.057980
2022-01-08 15:21:03,667 iteration 429 : loss : 0.178357, loss_ce: 0.090121
2022-01-08 15:21:04,978 iteration 430 : loss : 0.144178, loss_ce: 0.049064
2022-01-08 15:21:06,321 iteration 431 : loss : 0.218926, loss_ce: 0.080615
2022-01-08 15:21:07,721 iteration 432 : loss : 0.099131, loss_ce: 0.040235
2022-01-08 15:21:09,156 iteration 433 : loss : 0.130102, loss_ce: 0.051826
2022-01-08 15:21:10,538 iteration 434 : loss : 0.129113, loss_ce: 0.050859
2022-01-08 15:21:11,853 iteration 435 : loss : 0.156187, loss_ce: 0.068702
2022-01-08 15:21:13,201 iteration 436 : loss : 0.132470, loss_ce: 0.060633
2022-01-08 15:21:14,554 iteration 437 : loss : 0.180426, loss_ce: 0.083322
2022-01-08 15:21:15,860 iteration 438 : loss : 0.145265, loss_ce: 0.049075
2022-01-08 15:21:17,237 iteration 439 : loss : 0.158174, loss_ce: 0.047808
2022-01-08 15:21:18,589 iteration 440 : loss : 0.157160, loss_ce: 0.061230
2022-01-08 15:21:20,001 iteration 441 : loss : 0.132787, loss_ce: 0.048397
2022-01-08 15:21:21,399 iteration 442 : loss : 0.150193, loss_ce: 0.067181

  6%|█▉                            | 26/400 [11:15<2:40:17, 25.71s/it]2022-01-08 15:21:22,801 iteration 443 : loss : 0.143072, loss_ce: 0.070494
2022-01-08 15:21:24,124 iteration 444 : loss : 0.136875, loss_ce: 0.050673
2022-01-08 15:21:25,480 iteration 445 : loss : 0.208028, loss_ce: 0.077164
2022-01-08 15:21:26,969 iteration 446 : loss : 0.157198, loss_ce: 0.059028
2022-01-08 15:21:28,401 iteration 447 : loss : 0.101581, loss_ce: 0.055702
2022-01-08 15:21:29,816 iteration 448 : loss : 0.245527, loss_ce: 0.077670
2022-01-08 15:21:31,195 iteration 449 : loss : 0.143321, loss_ce: 0.067122
2022-01-08 15:21:32,554 iteration 450 : loss : 0.155792, loss_ce: 0.058614
2022-01-08 15:21:34,000 iteration 451 : loss : 0.118282, loss_ce: 0.048283
2022-01-08 15:21:35,406 iteration 452 : loss : 0.112150, loss_ce: 0.043283
2022-01-08 15:21:36,806 iteration 453 : loss : 0.156545, loss_ce: 0.059926
2022-01-08 15:21:38,205 iteration 454 : loss : 0.161105, loss_ce: 0.048707
2022-01-08 15:21:39,641 iteration 455 : loss : 0.123167, loss_ce: 0.044109
2022-01-08 15:21:41,033 iteration 456 : loss : 0.120425, loss_ce: 0.038811
2022-01-08 15:21:42,419 iteration 457 : loss : 0.159721, loss_ce: 0.058544
2022-01-08 15:21:43,867 iteration 458 : loss : 0.147883, loss_ce: 0.071270
2022-01-08 15:21:45,185 iteration 459 : loss : 0.112775, loss_ce: 0.039189

  7%|██                            | 27/400 [11:39<2:36:15, 25.14s/it]2022-01-08 15:21:46,642 iteration 460 : loss : 0.155124, loss_ce: 0.071906
2022-01-08 15:21:48,038 iteration 461 : loss : 0.121796, loss_ce: 0.058358
2022-01-08 15:21:49,404 iteration 462 : loss : 0.126812, loss_ce: 0.053307
2022-01-08 15:21:50,845 iteration 463 : loss : 0.141844, loss_ce: 0.070521
2022-01-08 15:21:52,228 iteration 464 : loss : 0.106075, loss_ce: 0.036506
2022-01-08 15:21:53,563 iteration 465 : loss : 0.153637, loss_ce: 0.051692
2022-01-08 15:21:54,931 iteration 466 : loss : 0.129799, loss_ce: 0.048897
2022-01-08 15:21:56,280 iteration 467 : loss : 0.147979, loss_ce: 0.049949
2022-01-08 15:21:57,748 iteration 468 : loss : 0.163985, loss_ce: 0.064263
2022-01-08 15:21:59,107 iteration 469 : loss : 0.146230, loss_ce: 0.047530
2022-01-08 15:22:00,479 iteration 470 : loss : 0.157862, loss_ce: 0.058103
2022-01-08 15:22:01,845 iteration 471 : loss : 0.132678, loss_ce: 0.044078
2022-01-08 15:22:03,263 iteration 472 : loss : 0.132621, loss_ce: 0.060856
2022-01-08 15:22:04,774 iteration 473 : loss : 0.160139, loss_ce: 0.069614
2022-01-08 15:22:06,246 iteration 474 : loss : 0.199957, loss_ce: 0.091989
2022-01-08 15:22:07,605 iteration 475 : loss : 0.109547, loss_ce: 0.043735
2022-01-08 15:22:09,041 iteration 476 : loss : 0.145529, loss_ce: 0.069175

  7%|██                            | 28/400 [12:03<2:33:27, 24.75s/it]2022-01-08 15:22:10,471 iteration 477 : loss : 0.152810, loss_ce: 0.048314
2022-01-08 15:22:11,893 iteration 478 : loss : 0.093241, loss_ce: 0.031049
2022-01-08 15:22:13,261 iteration 479 : loss : 0.127754, loss_ce: 0.051790
2022-01-08 15:22:14,650 iteration 480 : loss : 0.129392, loss_ce: 0.055465
2022-01-08 15:22:15,947 iteration 481 : loss : 0.174689, loss_ce: 0.066786
2022-01-08 15:22:17,339 iteration 482 : loss : 0.166263, loss_ce: 0.046781
2022-01-08 15:22:18,738 iteration 483 : loss : 0.172875, loss_ce: 0.057066
2022-01-08 15:22:20,155 iteration 484 : loss : 0.190463, loss_ce: 0.077264
2022-01-08 15:22:21,513 iteration 485 : loss : 0.105644, loss_ce: 0.045323
2022-01-08 15:22:22,861 iteration 486 : loss : 0.160193, loss_ce: 0.049728
2022-01-08 15:22:24,291 iteration 487 : loss : 0.122061, loss_ce: 0.047846
2022-01-08 15:22:25,615 iteration 488 : loss : 0.118094, loss_ce: 0.047557
2022-01-08 15:22:26,994 iteration 489 : loss : 0.135905, loss_ce: 0.059306
2022-01-08 15:22:28,269 iteration 490 : loss : 0.174490, loss_ce: 0.068716
2022-01-08 15:22:29,650 iteration 491 : loss : 0.122311, loss_ce: 0.050652
2022-01-08 15:22:31,011 iteration 492 : loss : 0.103992, loss_ce: 0.046491
2022-01-08 15:22:32,411 iteration 493 : loss : 0.155915, loss_ce: 0.067723

  7%|██▏                           | 29/400 [12:26<2:30:29, 24.34s/it]2022-01-08 15:22:33,838 iteration 494 : loss : 0.129528, loss_ce: 0.056578
2022-01-08 15:22:35,248 iteration 495 : loss : 0.125093, loss_ce: 0.039134
2022-01-08 15:22:36,616 iteration 496 : loss : 0.155167, loss_ce: 0.069188
2022-01-08 15:22:38,017 iteration 497 : loss : 0.145978, loss_ce: 0.063773
2022-01-08 15:22:39,451 iteration 498 : loss : 0.149305, loss_ce: 0.069441
2022-01-08 15:22:40,762 iteration 499 : loss : 0.099678, loss_ce: 0.043028
2022-01-08 15:22:42,088 iteration 500 : loss : 0.120406, loss_ce: 0.049085
2022-01-08 15:22:43,413 iteration 501 : loss : 0.135445, loss_ce: 0.056912
2022-01-08 15:22:44,840 iteration 502 : loss : 0.107034, loss_ce: 0.042627
2022-01-08 15:22:46,180 iteration 503 : loss : 0.162156, loss_ce: 0.054605
2022-01-08 15:22:47,580 iteration 504 : loss : 0.135443, loss_ce: 0.047110
2022-01-08 15:22:48,908 iteration 505 : loss : 0.087710, loss_ce: 0.031973
2022-01-08 15:22:50,364 iteration 506 : loss : 0.099220, loss_ce: 0.040652
2022-01-08 15:22:51,751 iteration 507 : loss : 0.167428, loss_ce: 0.059644
2022-01-08 15:22:53,131 iteration 508 : loss : 0.173866, loss_ce: 0.076389
2022-01-08 15:22:54,551 iteration 509 : loss : 0.115253, loss_ce: 0.035102
2022-01-08 15:22:54,551 Training Data Eval:
2022-01-08 15:23:01,367   Average segmentation loss on training set: 0.1097
2022-01-08 15:23:01,368 Validation Data Eval:
2022-01-08 15:23:03,724   Average segmentation loss on validation set: 0.1373
2022-01-08 15:23:09,427 Found new lowest validation loss at iteration 509! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_KEYS_best_val_loss_seed1234.pth
2022-01-08 15:23:10,923 iteration 510 : loss : 0.114551, loss_ce: 0.045176

  8%|██▎                           | 30/400 [13:05<2:56:17, 28.59s/it]2022-01-08 15:23:12,365 iteration 511 : loss : 0.182273, loss_ce: 0.086836
2022-01-08 15:23:13,697 iteration 512 : loss : 0.218825, loss_ce: 0.098569
2022-01-08 15:23:15,044 iteration 513 : loss : 0.086744, loss_ce: 0.027692
2022-01-08 15:23:16,408 iteration 514 : loss : 0.097903, loss_ce: 0.039363
2022-01-08 15:23:17,755 iteration 515 : loss : 0.141330, loss_ce: 0.056068
2022-01-08 15:23:19,153 iteration 516 : loss : 0.093129, loss_ce: 0.033309
2022-01-08 15:23:20,578 iteration 517 : loss : 0.137830, loss_ce: 0.063442
2022-01-08 15:23:21,906 iteration 518 : loss : 0.147977, loss_ce: 0.051868
2022-01-08 15:23:23,281 iteration 519 : loss : 0.131455, loss_ce: 0.055570
2022-01-08 15:23:24,605 iteration 520 : loss : 0.104315, loss_ce: 0.041205
2022-01-08 15:23:25,976 iteration 521 : loss : 0.116257, loss_ce: 0.045078
2022-01-08 15:23:27,386 iteration 522 : loss : 0.119545, loss_ce: 0.042850
2022-01-08 15:23:28,834 iteration 523 : loss : 0.110211, loss_ce: 0.046910
2022-01-08 15:23:30,302 iteration 524 : loss : 0.109331, loss_ce: 0.044779
2022-01-08 15:23:31,674 iteration 525 : loss : 0.184481, loss_ce: 0.087529
2022-01-08 15:23:33,045 iteration 526 : loss : 0.149391, loss_ce: 0.072373
2022-01-08 15:23:34,418 iteration 527 : loss : 0.115636, loss_ce: 0.040559

  8%|██▎                           | 31/400 [13:28<2:46:25, 27.06s/it]2022-01-08 15:23:35,831 iteration 528 : loss : 0.118717, loss_ce: 0.049428
2022-01-08 15:23:37,217 iteration 529 : loss : 0.129294, loss_ce: 0.039716
2022-01-08 15:23:38,554 iteration 530 : loss : 0.120719, loss_ce: 0.046757
2022-01-08 15:23:39,876 iteration 531 : loss : 0.116590, loss_ce: 0.038006
2022-01-08 15:23:41,215 iteration 532 : loss : 0.128408, loss_ce: 0.055083
2022-01-08 15:23:42,679 iteration 533 : loss : 0.078796, loss_ce: 0.030280
2022-01-08 15:23:44,003 iteration 534 : loss : 0.093686, loss_ce: 0.044390
2022-01-08 15:23:45,418 iteration 535 : loss : 0.093225, loss_ce: 0.036830
2022-01-08 15:23:46,870 iteration 536 : loss : 0.183052, loss_ce: 0.084825
2022-01-08 15:23:48,336 iteration 537 : loss : 0.159482, loss_ce: 0.047320
2022-01-08 15:23:49,734 iteration 538 : loss : 0.133212, loss_ce: 0.059011
2022-01-08 15:23:51,093 iteration 539 : loss : 0.133450, loss_ce: 0.054739
2022-01-08 15:23:52,487 iteration 540 : loss : 0.120389, loss_ce: 0.041380
2022-01-08 15:23:53,843 iteration 541 : loss : 0.114285, loss_ce: 0.050413
2022-01-08 15:23:55,213 iteration 542 : loss : 0.145464, loss_ce: 0.059963
2022-01-08 15:23:56,535 iteration 543 : loss : 0.091434, loss_ce: 0.034958
2022-01-08 15:23:57,890 iteration 544 : loss : 0.088029, loss_ce: 0.031757

  8%|██▍                           | 32/400 [13:52<2:39:22, 25.98s/it]2022-01-08 15:23:59,339 iteration 545 : loss : 0.090606, loss_ce: 0.042112
2022-01-08 15:24:00,712 iteration 546 : loss : 0.106874, loss_ce: 0.035301
2022-01-08 15:24:02,086 iteration 547 : loss : 0.137868, loss_ce: 0.050590
2022-01-08 15:24:03,452 iteration 548 : loss : 0.197294, loss_ce: 0.073165
2022-01-08 15:24:04,851 iteration 549 : loss : 0.091757, loss_ce: 0.041258
2022-01-08 15:24:06,195 iteration 550 : loss : 0.145374, loss_ce: 0.065769
2022-01-08 15:24:07,559 iteration 551 : loss : 0.090842, loss_ce: 0.038566
2022-01-08 15:24:08,906 iteration 552 : loss : 0.118435, loss_ce: 0.044022
2022-01-08 15:24:10,311 iteration 553 : loss : 0.153243, loss_ce: 0.057156
2022-01-08 15:24:11,629 iteration 554 : loss : 0.083425, loss_ce: 0.038224
2022-01-08 15:24:12,991 iteration 555 : loss : 0.114333, loss_ce: 0.035490
2022-01-08 15:24:14,400 iteration 556 : loss : 0.143946, loss_ce: 0.064414
2022-01-08 15:24:15,696 iteration 557 : loss : 0.122145, loss_ce: 0.043504
2022-01-08 15:24:17,109 iteration 558 : loss : 0.142264, loss_ce: 0.045245
2022-01-08 15:24:18,474 iteration 559 : loss : 0.142725, loss_ce: 0.052763
2022-01-08 15:24:19,860 iteration 560 : loss : 0.132969, loss_ce: 0.033446
2022-01-08 15:24:21,274 iteration 561 : loss : 0.161600, loss_ce: 0.068976

  8%|██▍                           | 33/400 [14:15<2:34:10, 25.21s/it]2022-01-08 15:24:22,811 iteration 562 : loss : 0.127602, loss_ce: 0.056936
2022-01-08 15:24:24,102 iteration 563 : loss : 0.109192, loss_ce: 0.048942
2022-01-08 15:24:25,496 iteration 564 : loss : 0.158820, loss_ce: 0.078399
2022-01-08 15:24:26,891 iteration 565 : loss : 0.112863, loss_ce: 0.053141
2022-01-08 15:24:28,317 iteration 566 : loss : 0.129025, loss_ce: 0.060071
2022-01-08 15:24:29,667 iteration 567 : loss : 0.118382, loss_ce: 0.042139
2022-01-08 15:24:31,012 iteration 568 : loss : 0.197389, loss_ce: 0.066471
2022-01-08 15:24:32,381 iteration 569 : loss : 0.171260, loss_ce: 0.072902
2022-01-08 15:24:33,791 iteration 570 : loss : 0.092196, loss_ce: 0.040724
2022-01-08 15:24:35,146 iteration 571 : loss : 0.212228, loss_ce: 0.089756
2022-01-08 15:24:36,537 iteration 572 : loss : 0.105791, loss_ce: 0.036884
2022-01-08 15:24:37,881 iteration 573 : loss : 0.133562, loss_ce: 0.057064
2022-01-08 15:24:39,258 iteration 574 : loss : 0.131666, loss_ce: 0.047938
2022-01-08 15:24:40,694 iteration 575 : loss : 0.150392, loss_ce: 0.045127
2022-01-08 15:24:42,113 iteration 576 : loss : 0.120524, loss_ce: 0.053720
2022-01-08 15:24:43,487 iteration 577 : loss : 0.095478, loss_ce: 0.039198
2022-01-08 15:24:44,818 iteration 578 : loss : 0.138211, loss_ce: 0.055304

  8%|██▌                           | 34/400 [14:39<2:30:42, 24.71s/it]2022-01-08 15:24:46,411 iteration 579 : loss : 0.148444, loss_ce: 0.075263
2022-01-08 15:24:47,834 iteration 580 : loss : 0.122477, loss_ce: 0.049417
2022-01-08 15:24:49,259 iteration 581 : loss : 0.147170, loss_ce: 0.044912
2022-01-08 15:24:50,629 iteration 582 : loss : 0.112792, loss_ce: 0.045750
2022-01-08 15:24:52,012 iteration 583 : loss : 0.234860, loss_ce: 0.085897
2022-01-08 15:24:53,356 iteration 584 : loss : 0.101450, loss_ce: 0.045706
2022-01-08 15:24:54,778 iteration 585 : loss : 0.093210, loss_ce: 0.037971
2022-01-08 15:24:56,118 iteration 586 : loss : 0.192784, loss_ce: 0.081266
2022-01-08 15:24:57,450 iteration 587 : loss : 0.108594, loss_ce: 0.045034
2022-01-08 15:24:58,849 iteration 588 : loss : 0.126920, loss_ce: 0.043504
2022-01-08 15:25:00,212 iteration 589 : loss : 0.102924, loss_ce: 0.037191
2022-01-08 15:25:01,585 iteration 590 : loss : 0.131960, loss_ce: 0.046791
2022-01-08 15:25:02,968 iteration 591 : loss : 0.123208, loss_ce: 0.046791
2022-01-08 15:25:04,349 iteration 592 : loss : 0.120397, loss_ce: 0.044165
2022-01-08 15:25:05,754 iteration 593 : loss : 0.073122, loss_ce: 0.027269
2022-01-08 15:25:07,145 iteration 594 : loss : 0.117345, loss_ce: 0.046150
2022-01-08 15:25:07,145 Training Data Eval:
2022-01-08 15:25:13,986   Average segmentation loss on training set: 0.1064
2022-01-08 15:25:13,986 Validation Data Eval:
2022-01-08 15:25:16,351   Average segmentation loss on validation set: 0.1316
2022-01-08 15:25:22,188 Found new lowest validation loss at iteration 594! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_KEYS_best_val_loss_seed1234.pth
2022-01-08 15:25:23,686 iteration 595 : loss : 0.172385, loss_ce: 0.080622

  9%|██▋                           | 35/400 [15:17<2:56:08, 28.95s/it]2022-01-08 15:25:25,120 iteration 596 : loss : 0.106129, loss_ce: 0.041929
2022-01-08 15:25:26,463 iteration 597 : loss : 0.125295, loss_ce: 0.037962
2022-01-08 15:25:27,796 iteration 598 : loss : 0.102135, loss_ce: 0.035701
2022-01-08 15:25:29,150 iteration 599 : loss : 0.131121, loss_ce: 0.049667
2022-01-08 15:25:30,505 iteration 600 : loss : 0.110830, loss_ce: 0.048895
2022-01-08 15:25:31,886 iteration 601 : loss : 0.118192, loss_ce: 0.046543
2022-01-08 15:25:33,281 iteration 602 : loss : 0.092469, loss_ce: 0.040223
2022-01-08 15:25:34,592 iteration 603 : loss : 0.104276, loss_ce: 0.039053
2022-01-08 15:25:35,913 iteration 604 : loss : 0.121362, loss_ce: 0.042819
2022-01-08 15:25:37,221 iteration 605 : loss : 0.131428, loss_ce: 0.049732
2022-01-08 15:25:38,716 iteration 606 : loss : 0.095423, loss_ce: 0.041981
2022-01-08 15:25:40,080 iteration 607 : loss : 0.145630, loss_ce: 0.060084
2022-01-08 15:25:41,447 iteration 608 : loss : 0.114494, loss_ce: 0.047591
2022-01-08 15:25:42,744 iteration 609 : loss : 0.104302, loss_ce: 0.039536
2022-01-08 15:25:44,158 iteration 610 : loss : 0.092114, loss_ce: 0.036352
2022-01-08 15:25:45,630 iteration 611 : loss : 0.143176, loss_ce: 0.061125
2022-01-08 15:25:47,026 iteration 612 : loss : 0.101849, loss_ce: 0.032966

  9%|██▋                           | 36/400 [15:41<2:45:27, 27.27s/it]2022-01-08 15:25:48,492 iteration 613 : loss : 0.120639, loss_ce: 0.043500
2022-01-08 15:25:49,864 iteration 614 : loss : 0.117625, loss_ce: 0.038318
2022-01-08 15:25:51,192 iteration 615 : loss : 0.137823, loss_ce: 0.060726
2022-01-08 15:25:52,638 iteration 616 : loss : 0.091656, loss_ce: 0.039799
2022-01-08 15:25:53,973 iteration 617 : loss : 0.112081, loss_ce: 0.052786
2022-01-08 15:25:55,357 iteration 618 : loss : 0.178369, loss_ce: 0.047991
2022-01-08 15:25:56,740 iteration 619 : loss : 0.179866, loss_ce: 0.061785
2022-01-08 15:25:58,212 iteration 620 : loss : 0.226168, loss_ce: 0.081433
2022-01-08 15:25:59,594 iteration 621 : loss : 0.087073, loss_ce: 0.036530
2022-01-08 15:26:01,088 iteration 622 : loss : 0.119437, loss_ce: 0.049110
2022-01-08 15:26:02,562 iteration 623 : loss : 0.129652, loss_ce: 0.061444
2022-01-08 15:26:03,933 iteration 624 : loss : 0.118956, loss_ce: 0.036670
2022-01-08 15:26:05,264 iteration 625 : loss : 0.105195, loss_ce: 0.046202
2022-01-08 15:26:06,681 iteration 626 : loss : 0.107588, loss_ce: 0.043305
2022-01-08 15:26:08,109 iteration 627 : loss : 0.159942, loss_ce: 0.058033
2022-01-08 15:26:09,580 iteration 628 : loss : 0.119714, loss_ce: 0.046258
2022-01-08 15:26:10,948 iteration 629 : loss : 0.081446, loss_ce: 0.030803

  9%|██▊                           | 37/400 [16:05<2:38:54, 26.27s/it]2022-01-08 15:26:12,418 iteration 630 : loss : 0.087419, loss_ce: 0.037363
2022-01-08 15:26:13,773 iteration 631 : loss : 0.068658, loss_ce: 0.033415
2022-01-08 15:26:15,128 iteration 632 : loss : 0.135376, loss_ce: 0.048517
2022-01-08 15:26:16,577 iteration 633 : loss : 0.089766, loss_ce: 0.037543
2022-01-08 15:26:17,961 iteration 634 : loss : 0.143627, loss_ce: 0.053908
2022-01-08 15:26:19,433 iteration 635 : loss : 0.103420, loss_ce: 0.043870
2022-01-08 15:26:20,849 iteration 636 : loss : 0.107121, loss_ce: 0.041499
2022-01-08 15:26:22,181 iteration 637 : loss : 0.114640, loss_ce: 0.049602
2022-01-08 15:26:23,634 iteration 638 : loss : 0.144120, loss_ce: 0.043815
2022-01-08 15:26:25,009 iteration 639 : loss : 0.100136, loss_ce: 0.041272
2022-01-08 15:26:26,323 iteration 640 : loss : 0.158935, loss_ce: 0.041886
2022-01-08 15:26:27,638 iteration 641 : loss : 0.128761, loss_ce: 0.049219
2022-01-08 15:26:28,972 iteration 642 : loss : 0.123525, loss_ce: 0.033374
2022-01-08 15:26:30,325 iteration 643 : loss : 0.115486, loss_ce: 0.041658
2022-01-08 15:26:31,695 iteration 644 : loss : 0.111028, loss_ce: 0.044306
2022-01-08 15:26:33,027 iteration 645 : loss : 0.098763, loss_ce: 0.029961
2022-01-08 15:26:34,456 iteration 646 : loss : 0.112561, loss_ce: 0.053932

 10%|██▊                           | 38/400 [16:28<2:33:28, 25.44s/it]2022-01-08 15:26:35,873 iteration 647 : loss : 0.139196, loss_ce: 0.060296
2022-01-08 15:26:37,248 iteration 648 : loss : 0.104021, loss_ce: 0.045317
2022-01-08 15:26:38,651 iteration 649 : loss : 0.093906, loss_ce: 0.039577
2022-01-08 15:26:40,095 iteration 650 : loss : 0.097420, loss_ce: 0.038780
2022-01-08 15:26:41,467 iteration 651 : loss : 0.090048, loss_ce: 0.036789
2022-01-08 15:26:42,746 iteration 652 : loss : 0.078513, loss_ce: 0.029678
2022-01-08 15:26:44,183 iteration 653 : loss : 0.134304, loss_ce: 0.050089
2022-01-08 15:26:45,511 iteration 654 : loss : 0.117669, loss_ce: 0.047217
2022-01-08 15:26:46,883 iteration 655 : loss : 0.162125, loss_ce: 0.054734
2022-01-08 15:26:48,265 iteration 656 : loss : 0.122158, loss_ce: 0.042907
2022-01-08 15:26:49,713 iteration 657 : loss : 0.082522, loss_ce: 0.030813
2022-01-08 15:26:51,113 iteration 658 : loss : 0.118320, loss_ce: 0.034086
2022-01-08 15:26:52,519 iteration 659 : loss : 0.116216, loss_ce: 0.045278
2022-01-08 15:26:53,868 iteration 660 : loss : 0.091404, loss_ce: 0.040646
2022-01-08 15:26:55,265 iteration 661 : loss : 0.097234, loss_ce: 0.037861
2022-01-08 15:26:56,737 iteration 662 : loss : 0.164104, loss_ce: 0.037515
2022-01-08 15:26:58,121 iteration 663 : loss : 0.104172, loss_ce: 0.041862

 10%|██▉                           | 39/400 [16:52<2:29:49, 24.90s/it]2022-01-08 15:26:59,571 iteration 664 : loss : 0.082609, loss_ce: 0.031631
2022-01-08 15:27:00,875 iteration 665 : loss : 0.088656, loss_ce: 0.038466
2022-01-08 15:27:02,237 iteration 666 : loss : 0.072515, loss_ce: 0.027293
2022-01-08 15:27:03,645 iteration 667 : loss : 0.074671, loss_ce: 0.035786
2022-01-08 15:27:05,063 iteration 668 : loss : 0.115215, loss_ce: 0.039224
2022-01-08 15:27:06,415 iteration 669 : loss : 0.112034, loss_ce: 0.031316
2022-01-08 15:27:07,910 iteration 670 : loss : 0.092533, loss_ce: 0.035128
2022-01-08 15:27:09,267 iteration 671 : loss : 0.093121, loss_ce: 0.030670
2022-01-08 15:27:10,714 iteration 672 : loss : 0.094746, loss_ce: 0.034643
2022-01-08 15:27:12,141 iteration 673 : loss : 0.090437, loss_ce: 0.038171
2022-01-08 15:27:13,545 iteration 674 : loss : 0.078769, loss_ce: 0.035537
2022-01-08 15:27:14,978 iteration 675 : loss : 0.134533, loss_ce: 0.059682
2022-01-08 15:27:16,351 iteration 676 : loss : 0.096439, loss_ce: 0.038143
2022-01-08 15:27:17,737 iteration 677 : loss : 0.063833, loss_ce: 0.029152
2022-01-08 15:27:19,153 iteration 678 : loss : 0.107475, loss_ce: 0.039011
2022-01-08 15:27:20,544 iteration 679 : loss : 0.160898, loss_ce: 0.072790
2022-01-08 15:27:20,544 Training Data Eval:
2022-01-08 15:27:27,384   Average segmentation loss on training set: 0.0778
2022-01-08 15:27:27,384 Validation Data Eval:
2022-01-08 15:27:29,750   Average segmentation loss on validation set: 0.1185
2022-01-08 15:27:35,492 Found new lowest validation loss at iteration 679! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_KEYS_best_val_loss_seed1234.pth
2022-01-08 15:27:36,961 iteration 680 : loss : 0.099336, loss_ce: 0.035623

 10%|███                           | 40/400 [17:31<2:54:31, 29.09s/it]2022-01-08 15:27:38,414 iteration 681 : loss : 0.070512, loss_ce: 0.026252
2022-01-08 15:27:39,717 iteration 682 : loss : 0.130397, loss_ce: 0.042673
2022-01-08 15:27:41,092 iteration 683 : loss : 0.096213, loss_ce: 0.041999
2022-01-08 15:27:42,431 iteration 684 : loss : 0.081187, loss_ce: 0.028970
2022-01-08 15:27:43,869 iteration 685 : loss : 0.101345, loss_ce: 0.037531
2022-01-08 15:27:45,247 iteration 686 : loss : 0.138104, loss_ce: 0.056923
2022-01-08 15:27:46,620 iteration 687 : loss : 0.099553, loss_ce: 0.046332
2022-01-08 15:27:47,973 iteration 688 : loss : 0.085981, loss_ce: 0.032467
2022-01-08 15:27:49,369 iteration 689 : loss : 0.087413, loss_ce: 0.039061
2022-01-08 15:27:50,735 iteration 690 : loss : 0.088389, loss_ce: 0.031887
2022-01-08 15:27:52,129 iteration 691 : loss : 0.098120, loss_ce: 0.037694
2022-01-08 15:27:53,563 iteration 692 : loss : 0.083194, loss_ce: 0.029404
2022-01-08 15:27:54,882 iteration 693 : loss : 0.096427, loss_ce: 0.044389
2022-01-08 15:27:56,266 iteration 694 : loss : 0.089760, loss_ce: 0.036926
2022-01-08 15:27:57,605 iteration 695 : loss : 0.109666, loss_ce: 0.047276
2022-01-08 15:27:59,042 iteration 696 : loss : 0.085908, loss_ce: 0.034821
2022-01-08 15:28:00,421 iteration 697 : loss : 0.082664, loss_ce: 0.033632

 10%|███                           | 41/400 [17:54<2:43:57, 27.40s/it]2022-01-08 15:28:01,831 iteration 698 : loss : 0.101372, loss_ce: 0.031983
2022-01-08 15:28:03,246 iteration 699 : loss : 0.117975, loss_ce: 0.052174
2022-01-08 15:28:04,598 iteration 700 : loss : 0.139442, loss_ce: 0.071518
2022-01-08 15:28:05,953 iteration 701 : loss : 0.137517, loss_ce: 0.075439
2022-01-08 15:28:07,363 iteration 702 : loss : 0.139452, loss_ce: 0.052089
2022-01-08 15:28:08,822 iteration 703 : loss : 0.066801, loss_ce: 0.030619
2022-01-08 15:28:10,142 iteration 704 : loss : 0.077677, loss_ce: 0.030674
2022-01-08 15:28:11,518 iteration 705 : loss : 0.108398, loss_ce: 0.039437
2022-01-08 15:28:12,905 iteration 706 : loss : 0.094459, loss_ce: 0.037667
2022-01-08 15:28:14,220 iteration 707 : loss : 0.081322, loss_ce: 0.034653
2022-01-08 15:28:15,585 iteration 708 : loss : 0.062586, loss_ce: 0.022675
2022-01-08 15:28:16,955 iteration 709 : loss : 0.133299, loss_ce: 0.067776
2022-01-08 15:28:18,360 iteration 710 : loss : 0.092146, loss_ce: 0.038159
2022-01-08 15:28:19,765 iteration 711 : loss : 0.100888, loss_ce: 0.044932
2022-01-08 15:28:21,225 iteration 712 : loss : 0.077059, loss_ce: 0.030864
2022-01-08 15:28:22,593 iteration 713 : loss : 0.069112, loss_ce: 0.030034
2022-01-08 15:28:24,033 iteration 714 : loss : 0.105771, loss_ce: 0.033802

 10%|███▏                          | 42/400 [18:18<2:36:42, 26.26s/it]2022-01-08 15:28:25,517 iteration 715 : loss : 0.092268, loss_ce: 0.033105
2022-01-08 15:28:26,945 iteration 716 : loss : 0.073467, loss_ce: 0.031482
2022-01-08 15:28:28,323 iteration 717 : loss : 0.090683, loss_ce: 0.031787
2022-01-08 15:28:29,718 iteration 718 : loss : 0.114262, loss_ce: 0.051075
2022-01-08 15:28:31,159 iteration 719 : loss : 0.098810, loss_ce: 0.037938
2022-01-08 15:28:32,539 iteration 720 : loss : 0.099750, loss_ce: 0.035238
2022-01-08 15:28:33,915 iteration 721 : loss : 0.104889, loss_ce: 0.035138
2022-01-08 15:28:35,279 iteration 722 : loss : 0.117071, loss_ce: 0.039958
2022-01-08 15:28:36,695 iteration 723 : loss : 0.100107, loss_ce: 0.044465
2022-01-08 15:28:38,054 iteration 724 : loss : 0.110364, loss_ce: 0.047980
2022-01-08 15:28:39,490 iteration 725 : loss : 0.087501, loss_ce: 0.034951
2022-01-08 15:28:40,861 iteration 726 : loss : 0.099632, loss_ce: 0.037888
2022-01-08 15:28:42,169 iteration 727 : loss : 0.071799, loss_ce: 0.028467
2022-01-08 15:28:43,588 iteration 728 : loss : 0.082554, loss_ce: 0.034300
2022-01-08 15:28:45,039 iteration 729 : loss : 0.067347, loss_ce: 0.028787
2022-01-08 15:28:46,470 iteration 730 : loss : 0.088835, loss_ce: 0.035553
2022-01-08 15:28:47,782 iteration 731 : loss : 0.067180, loss_ce: 0.023675

 11%|███▏                          | 43/400 [18:42<2:31:47, 25.51s/it]2022-01-08 15:28:49,184 iteration 732 : loss : 0.088216, loss_ce: 0.039491
2022-01-08 15:28:50,496 iteration 733 : loss : 0.095562, loss_ce: 0.048667
2022-01-08 15:28:51,945 iteration 734 : loss : 0.075109, loss_ce: 0.032475
2022-01-08 15:28:53,334 iteration 735 : loss : 0.089646, loss_ce: 0.036491
2022-01-08 15:28:54,701 iteration 736 : loss : 0.097786, loss_ce: 0.045585
2022-01-08 15:28:56,198 iteration 737 : loss : 0.085532, loss_ce: 0.036061
2022-01-08 15:28:57,497 iteration 738 : loss : 0.088695, loss_ce: 0.042402
2022-01-08 15:28:58,905 iteration 739 : loss : 0.095639, loss_ce: 0.030682
2022-01-08 15:29:00,271 iteration 740 : loss : 0.094611, loss_ce: 0.037496
2022-01-08 15:29:01,610 iteration 741 : loss : 0.085881, loss_ce: 0.033111
2022-01-08 15:29:02,909 iteration 742 : loss : 0.092585, loss_ce: 0.041104
2022-01-08 15:29:04,286 iteration 743 : loss : 0.082869, loss_ce: 0.029406
2022-01-08 15:29:05,692 iteration 744 : loss : 0.079383, loss_ce: 0.028311
2022-01-08 15:29:07,030 iteration 745 : loss : 0.141054, loss_ce: 0.031979
2022-01-08 15:29:08,374 iteration 746 : loss : 0.092471, loss_ce: 0.036127
2022-01-08 15:29:09,718 iteration 747 : loss : 0.116910, loss_ce: 0.056158
2022-01-08 15:29:11,044 iteration 748 : loss : 0.077660, loss_ce: 0.031146

 11%|███▎                          | 44/400 [19:05<2:27:21, 24.84s/it]2022-01-08 15:29:12,421 iteration 749 : loss : 0.175478, loss_ce: 0.032243
2022-01-08 15:29:13,774 iteration 750 : loss : 0.064006, loss_ce: 0.024317
2022-01-08 15:29:15,159 iteration 751 : loss : 0.054746, loss_ce: 0.016776
2022-01-08 15:29:16,508 iteration 752 : loss : 0.170805, loss_ce: 0.088308
2022-01-08 15:29:17,828 iteration 753 : loss : 0.118673, loss_ce: 0.056926
2022-01-08 15:29:19,161 iteration 754 : loss : 0.122261, loss_ce: 0.045295
2022-01-08 15:29:20,442 iteration 755 : loss : 0.093247, loss_ce: 0.044169
2022-01-08 15:29:21,737 iteration 756 : loss : 0.073239, loss_ce: 0.026800
2022-01-08 15:29:23,091 iteration 757 : loss : 0.106402, loss_ce: 0.044442
2022-01-08 15:29:24,541 iteration 758 : loss : 0.088650, loss_ce: 0.041653
2022-01-08 15:29:26,044 iteration 759 : loss : 0.103008, loss_ce: 0.039181
2022-01-08 15:29:27,398 iteration 760 : loss : 0.105057, loss_ce: 0.059807
2022-01-08 15:29:28,793 iteration 761 : loss : 0.094148, loss_ce: 0.040072
2022-01-08 15:29:30,206 iteration 762 : loss : 0.101739, loss_ce: 0.039254
2022-01-08 15:29:31,623 iteration 763 : loss : 0.091605, loss_ce: 0.041502
2022-01-08 15:29:32,971 iteration 764 : loss : 0.092308, loss_ce: 0.038864
2022-01-08 15:29:32,971 Training Data Eval:
2022-01-08 15:29:39,836   Average segmentation loss on training set: 0.1585
2022-01-08 15:29:39,836 Validation Data Eval:
2022-01-08 15:29:42,218   Average segmentation loss on validation set: 0.1604
2022-01-08 15:29:43,790 iteration 765 : loss : 0.101037, loss_ce: 0.040283

 11%|███▍                          | 45/400 [19:38<2:40:59, 27.21s/it]2022-01-08 15:29:45,343 iteration 766 : loss : 0.108843, loss_ce: 0.043366
2022-01-08 15:29:46,754 iteration 767 : loss : 0.100420, loss_ce: 0.039630
2022-01-08 15:29:48,150 iteration 768 : loss : 0.112748, loss_ce: 0.035895
2022-01-08 15:29:49,591 iteration 769 : loss : 0.092949, loss_ce: 0.041462
2022-01-08 15:29:50,892 iteration 770 : loss : 0.082855, loss_ce: 0.032152
2022-01-08 15:29:52,277 iteration 771 : loss : 0.146166, loss_ce: 0.042088
2022-01-08 15:29:53,664 iteration 772 : loss : 0.071866, loss_ce: 0.026194
2022-01-08 15:29:55,069 iteration 773 : loss : 0.108312, loss_ce: 0.029132
2022-01-08 15:29:56,553 iteration 774 : loss : 0.100030, loss_ce: 0.040316
2022-01-08 15:29:57,909 iteration 775 : loss : 0.093369, loss_ce: 0.050568
2022-01-08 15:29:59,244 iteration 776 : loss : 0.087553, loss_ce: 0.030620
2022-01-08 15:30:00,788 iteration 777 : loss : 0.115479, loss_ce: 0.050424
2022-01-08 15:30:02,095 iteration 778 : loss : 0.159074, loss_ce: 0.056250
2022-01-08 15:30:03,525 iteration 779 : loss : 0.095422, loss_ce: 0.044187
2022-01-08 15:30:04,963 iteration 780 : loss : 0.077608, loss_ce: 0.029248
2022-01-08 15:30:06,299 iteration 781 : loss : 0.090240, loss_ce: 0.044975
2022-01-08 15:30:07,594 iteration 782 : loss : 0.075222, loss_ce: 0.037102

 12%|███▍                          | 46/400 [20:01<2:34:29, 26.19s/it]2022-01-08 15:30:09,009 iteration 783 : loss : 0.107994, loss_ce: 0.050646
2022-01-08 15:30:10,350 iteration 784 : loss : 0.096392, loss_ce: 0.031681
2022-01-08 15:30:11,726 iteration 785 : loss : 0.101300, loss_ce: 0.044159
2022-01-08 15:30:13,078 iteration 786 : loss : 0.104753, loss_ce: 0.037093
2022-01-08 15:30:14,439 iteration 787 : loss : 0.078815, loss_ce: 0.031449
2022-01-08 15:30:15,864 iteration 788 : loss : 0.083092, loss_ce: 0.034259
2022-01-08 15:30:17,157 iteration 789 : loss : 0.111770, loss_ce: 0.040338
2022-01-08 15:30:18,572 iteration 790 : loss : 0.087306, loss_ce: 0.028129
2022-01-08 15:30:19,942 iteration 791 : loss : 0.077886, loss_ce: 0.028216
2022-01-08 15:30:21,255 iteration 792 : loss : 0.073938, loss_ce: 0.027581
2022-01-08 15:30:22,690 iteration 793 : loss : 0.092689, loss_ce: 0.041162
2022-01-08 15:30:23,976 iteration 794 : loss : 0.062555, loss_ce: 0.026555
2022-01-08 15:30:25,282 iteration 795 : loss : 0.085309, loss_ce: 0.034279
2022-01-08 15:30:26,597 iteration 796 : loss : 0.079237, loss_ce: 0.039820
2022-01-08 15:30:28,004 iteration 797 : loss : 0.124936, loss_ce: 0.050534
2022-01-08 15:30:29,352 iteration 798 : loss : 0.087211, loss_ce: 0.028679
2022-01-08 15:30:30,653 iteration 799 : loss : 0.078628, loss_ce: 0.040793

 12%|███▌                          | 47/400 [20:24<2:28:32, 25.25s/it]2022-01-08 15:30:32,176 iteration 800 : loss : 0.092494, loss_ce: 0.035877
2022-01-08 15:30:33,570 iteration 801 : loss : 0.085198, loss_ce: 0.035427
2022-01-08 15:30:34,945 iteration 802 : loss : 0.089032, loss_ce: 0.032014
2022-01-08 15:30:36,334 iteration 803 : loss : 0.081773, loss_ce: 0.042100
2022-01-08 15:30:37,787 iteration 804 : loss : 0.119577, loss_ce: 0.055959
2022-01-08 15:30:39,304 iteration 805 : loss : 0.066160, loss_ce: 0.022452
2022-01-08 15:30:40,660 iteration 806 : loss : 0.080115, loss_ce: 0.034578
2022-01-08 15:30:41,978 iteration 807 : loss : 0.079579, loss_ce: 0.030634
2022-01-08 15:30:43,387 iteration 808 : loss : 0.088316, loss_ce: 0.039083
2022-01-08 15:30:44,768 iteration 809 : loss : 0.101361, loss_ce: 0.039525
2022-01-08 15:30:46,107 iteration 810 : loss : 0.085103, loss_ce: 0.031326
2022-01-08 15:30:47,415 iteration 811 : loss : 0.106088, loss_ce: 0.066926
2022-01-08 15:30:48,754 iteration 812 : loss : 0.076791, loss_ce: 0.034398
2022-01-08 15:30:50,120 iteration 813 : loss : 0.113952, loss_ce: 0.034000
2022-01-08 15:30:51,597 iteration 814 : loss : 0.119845, loss_ce: 0.042850
2022-01-08 15:30:53,031 iteration 815 : loss : 0.114577, loss_ce: 0.050276
2022-01-08 15:30:54,417 iteration 816 : loss : 0.080372, loss_ce: 0.028958

 12%|███▌                          | 48/400 [20:48<2:25:30, 24.80s/it]2022-01-08 15:30:55,835 iteration 817 : loss : 0.084707, loss_ce: 0.036464
2022-01-08 15:30:57,156 iteration 818 : loss : 0.078150, loss_ce: 0.032948
2022-01-08 15:30:58,527 iteration 819 : loss : 0.073319, loss_ce: 0.023989
2022-01-08 15:30:59,831 iteration 820 : loss : 0.055040, loss_ce: 0.020868
2022-01-08 15:31:01,260 iteration 821 : loss : 0.067896, loss_ce: 0.023220
2022-01-08 15:31:02,667 iteration 822 : loss : 0.123488, loss_ce: 0.053077
2022-01-08 15:31:03,989 iteration 823 : loss : 0.076464, loss_ce: 0.028774
2022-01-08 15:31:05,304 iteration 824 : loss : 0.077908, loss_ce: 0.031781
2022-01-08 15:31:06,668 iteration 825 : loss : 0.072960, loss_ce: 0.027817
2022-01-08 15:31:08,022 iteration 826 : loss : 0.147062, loss_ce: 0.050068
2022-01-08 15:31:09,382 iteration 827 : loss : 0.137043, loss_ce: 0.041218
2022-01-08 15:31:10,742 iteration 828 : loss : 0.079039, loss_ce: 0.032063
2022-01-08 15:31:12,128 iteration 829 : loss : 0.089559, loss_ce: 0.034922
2022-01-08 15:31:13,549 iteration 830 : loss : 0.074607, loss_ce: 0.030041
2022-01-08 15:31:14,914 iteration 831 : loss : 0.097262, loss_ce: 0.040659
2022-01-08 15:31:16,263 iteration 832 : loss : 0.065692, loss_ce: 0.023116
2022-01-08 15:31:17,680 iteration 833 : loss : 0.095555, loss_ce: 0.044201

 12%|███▋                          | 49/400 [21:11<2:22:23, 24.34s/it]2022-01-08 15:31:19,108 iteration 834 : loss : 0.077596, loss_ce: 0.030673
2022-01-08 15:31:20,388 iteration 835 : loss : 0.094307, loss_ce: 0.028125
2022-01-08 15:31:21,766 iteration 836 : loss : 0.071766, loss_ce: 0.031982
2022-01-08 15:31:23,082 iteration 837 : loss : 0.064634, loss_ce: 0.033224
2022-01-08 15:31:24,373 iteration 838 : loss : 0.072228, loss_ce: 0.028027
2022-01-08 15:31:25,759 iteration 839 : loss : 0.082676, loss_ce: 0.033920
2022-01-08 15:31:27,143 iteration 840 : loss : 0.083518, loss_ce: 0.026065
2022-01-08 15:31:28,462 iteration 841 : loss : 0.090343, loss_ce: 0.037393
2022-01-08 15:31:29,810 iteration 842 : loss : 0.095865, loss_ce: 0.036597
2022-01-08 15:31:31,261 iteration 843 : loss : 0.077660, loss_ce: 0.027582
2022-01-08 15:31:32,613 iteration 844 : loss : 0.077715, loss_ce: 0.026579
2022-01-08 15:31:34,004 iteration 845 : loss : 0.098140, loss_ce: 0.038398
2022-01-08 15:31:35,493 iteration 846 : loss : 0.086769, loss_ce: 0.040543
2022-01-08 15:31:36,881 iteration 847 : loss : 0.060676, loss_ce: 0.022756
2022-01-08 15:31:38,161 iteration 848 : loss : 0.064377, loss_ce: 0.027012
2022-01-08 15:31:39,542 iteration 849 : loss : 0.075884, loss_ce: 0.027692
2022-01-08 15:31:39,542 Training Data Eval:
2022-01-08 15:31:46,380   Average segmentation loss on training set: 0.0608
2022-01-08 15:31:46,380 Validation Data Eval:
2022-01-08 15:31:48,741   Average segmentation loss on validation set: 0.0921
2022-01-08 15:31:54,434 Found new lowest validation loss at iteration 849! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_KEYS_best_val_loss_seed1234.pth
2022-01-08 15:31:55,909 iteration 850 : loss : 0.106767, loss_ce: 0.042955

 12%|███▊                          | 50/400 [21:50<2:46:17, 28.51s/it]2022-01-08 15:31:57,352 iteration 851 : loss : 0.096680, loss_ce: 0.037026
2022-01-08 15:31:58,694 iteration 852 : loss : 0.073919, loss_ce: 0.032219
2022-01-08 15:32:00,130 iteration 853 : loss : 0.083400, loss_ce: 0.032504
2022-01-08 15:32:01,529 iteration 854 : loss : 0.061539, loss_ce: 0.018399
2022-01-08 15:32:02,916 iteration 855 : loss : 0.082891, loss_ce: 0.035599
2022-01-08 15:32:04,324 iteration 856 : loss : 0.087285, loss_ce: 0.031694
2022-01-08 15:32:05,664 iteration 857 : loss : 0.073491, loss_ce: 0.034340
2022-01-08 15:32:06,942 iteration 858 : loss : 0.070116, loss_ce: 0.033977
2022-01-08 15:32:08,295 iteration 859 : loss : 0.102645, loss_ce: 0.038873
2022-01-08 15:32:09,606 iteration 860 : loss : 0.088094, loss_ce: 0.029762
2022-01-08 15:32:11,034 iteration 861 : loss : 0.080483, loss_ce: 0.032089
2022-01-08 15:32:12,330 iteration 862 : loss : 0.090585, loss_ce: 0.030884
2022-01-08 15:32:13,770 iteration 863 : loss : 0.090008, loss_ce: 0.040611
2022-01-08 15:32:15,172 iteration 864 : loss : 0.075314, loss_ce: 0.029958
2022-01-08 15:32:16,470 iteration 865 : loss : 0.077550, loss_ce: 0.030196
2022-01-08 15:32:17,895 iteration 866 : loss : 0.098425, loss_ce: 0.045151
2022-01-08 15:32:19,196 iteration 867 : loss : 0.051236, loss_ce: 0.018663

 13%|███▊                          | 51/400 [22:13<2:36:41, 26.94s/it]2022-01-08 15:32:20,652 iteration 868 : loss : 0.123169, loss_ce: 0.038397
2022-01-08 15:32:22,017 iteration 869 : loss : 0.087233, loss_ce: 0.034729
2022-01-08 15:32:23,295 iteration 870 : loss : 0.053299, loss_ce: 0.021129
2022-01-08 15:32:24,608 iteration 871 : loss : 0.066218, loss_ce: 0.027656
2022-01-08 15:32:25,942 iteration 872 : loss : 0.062466, loss_ce: 0.033403
2022-01-08 15:32:27,374 iteration 873 : loss : 0.079215, loss_ce: 0.026651
2022-01-08 15:32:28,659 iteration 874 : loss : 0.060909, loss_ce: 0.025840
2022-01-08 15:32:30,165 iteration 875 : loss : 0.106247, loss_ce: 0.040357
2022-01-08 15:32:31,532 iteration 876 : loss : 0.046450, loss_ce: 0.022016
2022-01-08 15:32:32,804 iteration 877 : loss : 0.054413, loss_ce: 0.021269
2022-01-08 15:32:34,209 iteration 878 : loss : 0.066725, loss_ce: 0.026397
2022-01-08 15:32:35,549 iteration 879 : loss : 0.090598, loss_ce: 0.040704
2022-01-08 15:32:36,938 iteration 880 : loss : 0.068922, loss_ce: 0.022621
2022-01-08 15:32:38,271 iteration 881 : loss : 0.088598, loss_ce: 0.034496
2022-01-08 15:32:39,674 iteration 882 : loss : 0.077423, loss_ce: 0.025330
2022-01-08 15:32:41,036 iteration 883 : loss : 0.075472, loss_ce: 0.034207
2022-01-08 15:32:42,494 iteration 884 : loss : 0.077988, loss_ce: 0.036572

 13%|███▉                          | 52/400 [22:36<2:29:55, 25.85s/it]2022-01-08 15:32:43,956 iteration 885 : loss : 0.079240, loss_ce: 0.031939
2022-01-08 15:32:45,356 iteration 886 : loss : 0.074470, loss_ce: 0.024664
2022-01-08 15:32:46,765 iteration 887 : loss : 0.117791, loss_ce: 0.047051
2022-01-08 15:32:48,141 iteration 888 : loss : 0.063188, loss_ce: 0.025878
2022-01-08 15:32:49,608 iteration 889 : loss : 0.089678, loss_ce: 0.028797
2022-01-08 15:32:51,083 iteration 890 : loss : 0.118658, loss_ce: 0.048878
2022-01-08 15:32:52,465 iteration 891 : loss : 0.049889, loss_ce: 0.017312
2022-01-08 15:32:53,838 iteration 892 : loss : 0.060422, loss_ce: 0.030034
2022-01-08 15:32:55,188 iteration 893 : loss : 0.061510, loss_ce: 0.022569
2022-01-08 15:32:56,659 iteration 894 : loss : 0.090245, loss_ce: 0.034965
2022-01-08 15:32:57,998 iteration 895 : loss : 0.100183, loss_ce: 0.033858
2022-01-08 15:32:59,429 iteration 896 : loss : 0.087920, loss_ce: 0.033628
2022-01-08 15:33:00,879 iteration 897 : loss : 0.095169, loss_ce: 0.043099
2022-01-08 15:33:02,232 iteration 898 : loss : 0.073283, loss_ce: 0.035301
2022-01-08 15:33:03,588 iteration 899 : loss : 0.070358, loss_ce: 0.028901
2022-01-08 15:33:04,904 iteration 900 : loss : 0.065313, loss_ce: 0.030223
2022-01-08 15:33:06,244 iteration 901 : loss : 0.088894, loss_ce: 0.031259

 13%|███▉                          | 53/400 [23:00<2:25:50, 25.22s/it]2022-01-08 15:33:07,704 iteration 902 : loss : 0.076632, loss_ce: 0.033460
2022-01-08 15:33:09,165 iteration 903 : loss : 0.094052, loss_ce: 0.031735
2022-01-08 15:33:10,571 iteration 904 : loss : 0.086880, loss_ce: 0.026968
2022-01-08 15:33:11,962 iteration 905 : loss : 0.097838, loss_ce: 0.042820
2022-01-08 15:33:13,327 iteration 906 : loss : 0.070342, loss_ce: 0.031506
2022-01-08 15:33:14,756 iteration 907 : loss : 0.071553, loss_ce: 0.022161
2022-01-08 15:33:16,040 iteration 908 : loss : 0.061874, loss_ce: 0.023043
2022-01-08 15:33:17,433 iteration 909 : loss : 0.082275, loss_ce: 0.037138
2022-01-08 15:33:18,739 iteration 910 : loss : 0.111091, loss_ce: 0.045807
2022-01-08 15:33:20,102 iteration 911 : loss : 0.053891, loss_ce: 0.021185
2022-01-08 15:33:21,459 iteration 912 : loss : 0.065786, loss_ce: 0.024172
2022-01-08 15:33:22,802 iteration 913 : loss : 0.075332, loss_ce: 0.026420
2022-01-08 15:33:24,158 iteration 914 : loss : 0.089615, loss_ce: 0.040145
2022-01-08 15:33:25,484 iteration 915 : loss : 0.113115, loss_ce: 0.033570
2022-01-08 15:33:26,817 iteration 916 : loss : 0.064807, loss_ce: 0.022345
2022-01-08 15:33:28,210 iteration 917 : loss : 0.087764, loss_ce: 0.034339
2022-01-08 15:33:29,614 iteration 918 : loss : 0.095105, loss_ce: 0.035363

 14%|████                          | 54/400 [23:23<2:22:12, 24.66s/it]2022-01-08 15:33:31,078 iteration 919 : loss : 0.054220, loss_ce: 0.022429
2022-01-08 15:33:32,468 iteration 920 : loss : 0.064346, loss_ce: 0.028540
2022-01-08 15:33:33,885 iteration 921 : loss : 0.074344, loss_ce: 0.028096
2022-01-08 15:33:35,314 iteration 922 : loss : 0.087421, loss_ce: 0.047401
2022-01-08 15:33:36,661 iteration 923 : loss : 0.056905, loss_ce: 0.024025
2022-01-08 15:33:38,085 iteration 924 : loss : 0.139983, loss_ce: 0.045916
2022-01-08 15:33:39,419 iteration 925 : loss : 0.046975, loss_ce: 0.016918
2022-01-08 15:33:40,836 iteration 926 : loss : 0.065776, loss_ce: 0.027504
2022-01-08 15:33:42,142 iteration 927 : loss : 0.073887, loss_ce: 0.026084
2022-01-08 15:33:43,502 iteration 928 : loss : 0.058307, loss_ce: 0.025453
2022-01-08 15:33:44,923 iteration 929 : loss : 0.092745, loss_ce: 0.028735
2022-01-08 15:33:46,309 iteration 930 : loss : 0.067839, loss_ce: 0.027502
2022-01-08 15:33:47,700 iteration 931 : loss : 0.092611, loss_ce: 0.021844
2022-01-08 15:33:49,074 iteration 932 : loss : 0.073097, loss_ce: 0.024115
2022-01-08 15:33:50,419 iteration 933 : loss : 0.086363, loss_ce: 0.035278
2022-01-08 15:33:51,787 iteration 934 : loss : 0.054862, loss_ce: 0.021836
2022-01-08 15:33:51,787 Training Data Eval:
2022-01-08 15:33:58,615   Average segmentation loss on training set: 0.0514
2022-01-08 15:33:58,615 Validation Data Eval:
2022-01-08 15:34:00,974   Average segmentation loss on validation set: 0.0971
2022-01-08 15:34:02,441 iteration 935 : loss : 0.092383, loss_ce: 0.027383

 14%|████▏                         | 55/400 [23:56<2:35:53, 27.11s/it]2022-01-08 15:34:03,845 iteration 936 : loss : 0.062644, loss_ce: 0.020506
2022-01-08 15:34:05,237 iteration 937 : loss : 0.050852, loss_ce: 0.015965
2022-01-08 15:34:06,653 iteration 938 : loss : 0.054424, loss_ce: 0.019605
2022-01-08 15:34:07,984 iteration 939 : loss : 0.062435, loss_ce: 0.022296
2022-01-08 15:34:09,373 iteration 940 : loss : 0.075390, loss_ce: 0.030217
2022-01-08 15:34:10,849 iteration 941 : loss : 0.100661, loss_ce: 0.038442
2022-01-08 15:34:12,184 iteration 942 : loss : 0.061031, loss_ce: 0.022468
2022-01-08 15:34:13,538 iteration 943 : loss : 0.054917, loss_ce: 0.024176
2022-01-08 15:34:14,867 iteration 944 : loss : 0.071651, loss_ce: 0.027926
2022-01-08 15:34:16,206 iteration 945 : loss : 0.063688, loss_ce: 0.022799
2022-01-08 15:34:17,544 iteration 946 : loss : 0.054259, loss_ce: 0.022240
2022-01-08 15:34:18,872 iteration 947 : loss : 0.067134, loss_ce: 0.021347
2022-01-08 15:34:20,193 iteration 948 : loss : 0.085678, loss_ce: 0.030066
2022-01-08 15:34:21,546 iteration 949 : loss : 0.070784, loss_ce: 0.024782
2022-01-08 15:34:22,894 iteration 950 : loss : 0.080642, loss_ce: 0.035951
2022-01-08 15:34:24,294 iteration 951 : loss : 0.068983, loss_ce: 0.037480
2022-01-08 15:34:25,610 iteration 952 : loss : 0.068590, loss_ce: 0.029466

 14%|████▏                         | 56/400 [24:19<2:28:39, 25.93s/it]2022-01-08 15:34:27,054 iteration 953 : loss : 0.090737, loss_ce: 0.034758
2022-01-08 15:34:28,468 iteration 954 : loss : 0.069702, loss_ce: 0.029195
2022-01-08 15:34:29,767 iteration 955 : loss : 0.053671, loss_ce: 0.023034
2022-01-08 15:34:31,172 iteration 956 : loss : 0.065573, loss_ce: 0.027459
2022-01-08 15:34:32,558 iteration 957 : loss : 0.076591, loss_ce: 0.025827
2022-01-08 15:34:33,956 iteration 958 : loss : 0.074084, loss_ce: 0.024596
2022-01-08 15:34:35,420 iteration 959 : loss : 0.072277, loss_ce: 0.032018
2022-01-08 15:34:36,942 iteration 960 : loss : 0.065083, loss_ce: 0.027988
2022-01-08 15:34:38,284 iteration 961 : loss : 0.098125, loss_ce: 0.028046
2022-01-08 15:34:39,594 iteration 962 : loss : 0.066126, loss_ce: 0.019829
2022-01-08 15:34:41,038 iteration 963 : loss : 0.090060, loss_ce: 0.035111
2022-01-08 15:34:42,447 iteration 964 : loss : 0.072405, loss_ce: 0.039039
2022-01-08 15:34:43,830 iteration 965 : loss : 0.062740, loss_ce: 0.027078
2022-01-08 15:34:45,200 iteration 966 : loss : 0.073830, loss_ce: 0.032683
2022-01-08 15:34:46,589 iteration 967 : loss : 0.063135, loss_ce: 0.026593
2022-01-08 15:34:47,915 iteration 968 : loss : 0.117984, loss_ce: 0.039970
2022-01-08 15:34:49,335 iteration 969 : loss : 0.067024, loss_ce: 0.028521

 14%|████▎                         | 57/400 [24:43<2:24:27, 25.27s/it]2022-01-08 15:34:50,742 iteration 970 : loss : 0.067497, loss_ce: 0.033974
2022-01-08 15:34:52,135 iteration 971 : loss : 0.092762, loss_ce: 0.029867
2022-01-08 15:34:53,450 iteration 972 : loss : 0.072391, loss_ce: 0.032120
2022-01-08 15:34:54,841 iteration 973 : loss : 0.082594, loss_ce: 0.027981
2022-01-08 15:34:56,158 iteration 974 : loss : 0.075453, loss_ce: 0.030760
2022-01-08 15:34:57,578 iteration 975 : loss : 0.066544, loss_ce: 0.021100
2022-01-08 15:34:58,923 iteration 976 : loss : 0.053762, loss_ce: 0.021359
2022-01-08 15:35:00,284 iteration 977 : loss : 0.055909, loss_ce: 0.018706
2022-01-08 15:35:01,676 iteration 978 : loss : 0.052205, loss_ce: 0.019248
2022-01-08 15:35:03,024 iteration 979 : loss : 0.095115, loss_ce: 0.044002
2022-01-08 15:35:04,375 iteration 980 : loss : 0.068947, loss_ce: 0.021767
2022-01-08 15:35:05,836 iteration 981 : loss : 0.080104, loss_ce: 0.036583
2022-01-08 15:35:07,183 iteration 982 : loss : 0.066418, loss_ce: 0.032863
2022-01-08 15:35:08,605 iteration 983 : loss : 0.106121, loss_ce: 0.034237
2022-01-08 15:35:09,905 iteration 984 : loss : 0.077237, loss_ce: 0.036416
2022-01-08 15:35:11,272 iteration 985 : loss : 0.054751, loss_ce: 0.017787
2022-01-08 15:35:12,694 iteration 986 : loss : 0.080667, loss_ce: 0.029743

 14%|████▎                         | 58/400 [25:06<2:20:46, 24.70s/it]2022-01-08 15:35:14,196 iteration 987 : loss : 0.057425, loss_ce: 0.027089
2022-01-08 15:35:15,601 iteration 988 : loss : 0.068929, loss_ce: 0.034201
2022-01-08 15:35:16,987 iteration 989 : loss : 0.093317, loss_ce: 0.034674
2022-01-08 15:35:18,360 iteration 990 : loss : 0.070957, loss_ce: 0.031794
2022-01-08 15:35:19,723 iteration 991 : loss : 0.070126, loss_ce: 0.029188
2022-01-08 15:35:21,172 iteration 992 : loss : 0.065873, loss_ce: 0.028143
2022-01-08 15:35:22,573 iteration 993 : loss : 0.070521, loss_ce: 0.026468
2022-01-08 15:35:24,056 iteration 994 : loss : 0.066446, loss_ce: 0.029684
2022-01-08 15:35:25,448 iteration 995 : loss : 0.090678, loss_ce: 0.031994
2022-01-08 15:35:26,882 iteration 996 : loss : 0.047450, loss_ce: 0.022832
2022-01-08 15:35:28,318 iteration 997 : loss : 0.096967, loss_ce: 0.033634
2022-01-08 15:35:29,649 iteration 998 : loss : 0.077305, loss_ce: 0.023570
2022-01-08 15:35:31,074 iteration 999 : loss : 0.071003, loss_ce: 0.025841
2022-01-08 15:35:32,410 iteration 1000 : loss : 0.073747, loss_ce: 0.022675
2022-01-08 15:35:33,758 iteration 1001 : loss : 0.104448, loss_ce: 0.030011
2022-01-08 15:35:35,225 iteration 1002 : loss : 0.086084, loss_ce: 0.038842
2022-01-08 15:35:36,679 iteration 1003 : loss : 0.094710, loss_ce: 0.037839

 15%|████▍                         | 59/400 [25:30<2:19:08, 24.48s/it]2022-01-08 15:35:38,118 iteration 1004 : loss : 0.126873, loss_ce: 0.054264
2022-01-08 15:35:39,483 iteration 1005 : loss : 0.074875, loss_ce: 0.027500
2022-01-08 15:35:40,943 iteration 1006 : loss : 0.100975, loss_ce: 0.041845
2022-01-08 15:35:42,281 iteration 1007 : loss : 0.067134, loss_ce: 0.032840
2022-01-08 15:35:43,606 iteration 1008 : loss : 0.156809, loss_ce: 0.078266
2022-01-08 15:35:44,941 iteration 1009 : loss : 0.089590, loss_ce: 0.038885
2022-01-08 15:35:46,275 iteration 1010 : loss : 0.089942, loss_ce: 0.035542
2022-01-08 15:35:47,700 iteration 1011 : loss : 0.078161, loss_ce: 0.032058
2022-01-08 15:35:49,061 iteration 1012 : loss : 0.062004, loss_ce: 0.023936
2022-01-08 15:35:50,383 iteration 1013 : loss : 0.067381, loss_ce: 0.023354
2022-01-08 15:35:51,765 iteration 1014 : loss : 0.125576, loss_ce: 0.048991
2022-01-08 15:35:53,076 iteration 1015 : loss : 0.061871, loss_ce: 0.023085
2022-01-08 15:35:54,461 iteration 1016 : loss : 0.071911, loss_ce: 0.033444
2022-01-08 15:35:55,744 iteration 1017 : loss : 0.053572, loss_ce: 0.020519
2022-01-08 15:35:57,027 iteration 1018 : loss : 0.085039, loss_ce: 0.037432
2022-01-08 15:35:58,381 iteration 1019 : loss : 0.075759, loss_ce: 0.032159
2022-01-08 15:35:58,381 Training Data Eval:
2022-01-08 15:36:05,206   Average segmentation loss on training set: 0.0571
2022-01-08 15:36:05,207 Validation Data Eval:
2022-01-08 15:36:07,564   Average segmentation loss on validation set: 0.0928
2022-01-08 15:36:08,881 iteration 1020 : loss : 0.057034, loss_ce: 0.019547

 15%|████▌                         | 60/400 [26:03<2:31:52, 26.80s/it]2022-01-08 15:36:10,383 iteration 1021 : loss : 0.106627, loss_ce: 0.026425
2022-01-08 15:36:11,747 iteration 1022 : loss : 0.098166, loss_ce: 0.047804
2022-01-08 15:36:13,118 iteration 1023 : loss : 0.083321, loss_ce: 0.025734
2022-01-08 15:36:14,551 iteration 1024 : loss : 0.050423, loss_ce: 0.018333
2022-01-08 15:36:16,000 iteration 1025 : loss : 0.056807, loss_ce: 0.024795
2022-01-08 15:36:17,286 iteration 1026 : loss : 0.052128, loss_ce: 0.019533
2022-01-08 15:36:18,701 iteration 1027 : loss : 0.083424, loss_ce: 0.026003
2022-01-08 15:36:20,107 iteration 1028 : loss : 0.091803, loss_ce: 0.044630
2022-01-08 15:36:21,470 iteration 1029 : loss : 0.053016, loss_ce: 0.023218
2022-01-08 15:36:22,843 iteration 1030 : loss : 0.060077, loss_ce: 0.023291
2022-01-08 15:36:24,270 iteration 1031 : loss : 0.082529, loss_ce: 0.035542
2022-01-08 15:36:25,669 iteration 1032 : loss : 0.076356, loss_ce: 0.036835
2022-01-08 15:36:27,015 iteration 1033 : loss : 0.065553, loss_ce: 0.023535
2022-01-08 15:36:28,500 iteration 1034 : loss : 0.086316, loss_ce: 0.031601
2022-01-08 15:36:29,893 iteration 1035 : loss : 0.059150, loss_ce: 0.024862
2022-01-08 15:36:31,288 iteration 1036 : loss : 0.062705, loss_ce: 0.025296
2022-01-08 15:36:32,631 iteration 1037 : loss : 0.071891, loss_ce: 0.027978

 15%|████▌                         | 61/400 [26:26<2:26:13, 25.88s/it]2022-01-08 15:36:34,077 iteration 1038 : loss : 0.054791, loss_ce: 0.022904
2022-01-08 15:36:35,451 iteration 1039 : loss : 0.063455, loss_ce: 0.031400
2022-01-08 15:36:36,864 iteration 1040 : loss : 0.101357, loss_ce: 0.047385
2022-01-08 15:36:38,262 iteration 1041 : loss : 0.076223, loss_ce: 0.031768
2022-01-08 15:36:39,660 iteration 1042 : loss : 0.068696, loss_ce: 0.027658
2022-01-08 15:36:41,047 iteration 1043 : loss : 0.078028, loss_ce: 0.024832
2022-01-08 15:36:42,450 iteration 1044 : loss : 0.051566, loss_ce: 0.019501
2022-01-08 15:36:43,743 iteration 1045 : loss : 0.057340, loss_ce: 0.025615
2022-01-08 15:36:45,065 iteration 1046 : loss : 0.100403, loss_ce: 0.025509
2022-01-08 15:36:46,479 iteration 1047 : loss : 0.077857, loss_ce: 0.027315
2022-01-08 15:36:47,854 iteration 1048 : loss : 0.075573, loss_ce: 0.026516
2022-01-08 15:36:49,237 iteration 1049 : loss : 0.106337, loss_ce: 0.044816
2022-01-08 15:36:50,662 iteration 1050 : loss : 0.092812, loss_ce: 0.029046
2022-01-08 15:36:52,030 iteration 1051 : loss : 0.076820, loss_ce: 0.031918
2022-01-08 15:36:53,404 iteration 1052 : loss : 0.123629, loss_ce: 0.045232
2022-01-08 15:36:54,706 iteration 1053 : loss : 0.063938, loss_ce: 0.019502
2022-01-08 15:36:56,149 iteration 1054 : loss : 0.075777, loss_ce: 0.034331

 16%|████▋                         | 62/400 [26:50<2:21:49, 25.18s/it]2022-01-08 15:36:57,585 iteration 1055 : loss : 0.057592, loss_ce: 0.018351
2022-01-08 15:36:58,931 iteration 1056 : loss : 0.061519, loss_ce: 0.031007
2022-01-08 15:37:00,285 iteration 1057 : loss : 0.106088, loss_ce: 0.055539
2022-01-08 15:37:01,652 iteration 1058 : loss : 0.068904, loss_ce: 0.032087
2022-01-08 15:37:02,949 iteration 1059 : loss : 0.070098, loss_ce: 0.027433
2022-01-08 15:37:04,312 iteration 1060 : loss : 0.052219, loss_ce: 0.022141
2022-01-08 15:37:05,747 iteration 1061 : loss : 0.049658, loss_ce: 0.021864
2022-01-08 15:37:07,140 iteration 1062 : loss : 0.073254, loss_ce: 0.028350
2022-01-08 15:37:08,578 iteration 1063 : loss : 0.115151, loss_ce: 0.041487
2022-01-08 15:37:09,949 iteration 1064 : loss : 0.077611, loss_ce: 0.024170
2022-01-08 15:37:11,262 iteration 1065 : loss : 0.062988, loss_ce: 0.028986
2022-01-08 15:37:12,672 iteration 1066 : loss : 0.066021, loss_ce: 0.026027
2022-01-08 15:37:14,027 iteration 1067 : loss : 0.138004, loss_ce: 0.033297
2022-01-08 15:37:15,450 iteration 1068 : loss : 0.070720, loss_ce: 0.033469
2022-01-08 15:37:16,847 iteration 1069 : loss : 0.089690, loss_ce: 0.036576
2022-01-08 15:37:18,214 iteration 1070 : loss : 0.061842, loss_ce: 0.024952
2022-01-08 15:37:19,574 iteration 1071 : loss : 0.072056, loss_ce: 0.028963

 16%|████▋                         | 63/400 [27:13<2:18:26, 24.65s/it]2022-01-08 15:37:21,101 iteration 1072 : loss : 0.070124, loss_ce: 0.020404
2022-01-08 15:37:22,456 iteration 1073 : loss : 0.072968, loss_ce: 0.017161
2022-01-08 15:37:23,815 iteration 1074 : loss : 0.077700, loss_ce: 0.035660
2022-01-08 15:37:25,214 iteration 1075 : loss : 0.058203, loss_ce: 0.020374
2022-01-08 15:37:26,535 iteration 1076 : loss : 0.055827, loss_ce: 0.020430
2022-01-08 15:37:27,889 iteration 1077 : loss : 0.053617, loss_ce: 0.018733
2022-01-08 15:37:29,321 iteration 1078 : loss : 0.089390, loss_ce: 0.043485
2022-01-08 15:37:30,654 iteration 1079 : loss : 0.057916, loss_ce: 0.023914
2022-01-08 15:37:31,977 iteration 1080 : loss : 0.046371, loss_ce: 0.020627
2022-01-08 15:37:33,377 iteration 1081 : loss : 0.089080, loss_ce: 0.030526
2022-01-08 15:37:34,770 iteration 1082 : loss : 0.062837, loss_ce: 0.033290
2022-01-08 15:37:36,194 iteration 1083 : loss : 0.068210, loss_ce: 0.030024
2022-01-08 15:37:37,545 iteration 1084 : loss : 0.072434, loss_ce: 0.040050
2022-01-08 15:37:38,987 iteration 1085 : loss : 0.071307, loss_ce: 0.031727
2022-01-08 15:37:40,341 iteration 1086 : loss : 0.063218, loss_ce: 0.024468
2022-01-08 15:37:41,711 iteration 1087 : loss : 0.061775, loss_ce: 0.027017
2022-01-08 15:37:43,140 iteration 1088 : loss : 0.064848, loss_ce: 0.030151

 16%|████▊                         | 64/400 [27:37<2:16:13, 24.33s/it]2022-01-08 15:37:44,549 iteration 1089 : loss : 0.076746, loss_ce: 0.031793
2022-01-08 15:37:45,898 iteration 1090 : loss : 0.057195, loss_ce: 0.027245
2022-01-08 15:37:47,273 iteration 1091 : loss : 0.049013, loss_ce: 0.023274
2022-01-08 15:37:48,647 iteration 1092 : loss : 0.068118, loss_ce: 0.033532
2022-01-08 15:37:50,039 iteration 1093 : loss : 0.080332, loss_ce: 0.030140
2022-01-08 15:37:51,475 iteration 1094 : loss : 0.055654, loss_ce: 0.021855
2022-01-08 15:37:52,806 iteration 1095 : loss : 0.046824, loss_ce: 0.020703
2022-01-08 15:37:54,277 iteration 1096 : loss : 0.060927, loss_ce: 0.025414
2022-01-08 15:37:55,670 iteration 1097 : loss : 0.066483, loss_ce: 0.025907
2022-01-08 15:37:57,008 iteration 1098 : loss : 0.053735, loss_ce: 0.026587
2022-01-08 15:37:58,407 iteration 1099 : loss : 0.080196, loss_ce: 0.024952
2022-01-08 15:37:59,859 iteration 1100 : loss : 0.060958, loss_ce: 0.022578
2022-01-08 15:38:01,227 iteration 1101 : loss : 0.056972, loss_ce: 0.024717
2022-01-08 15:38:02,677 iteration 1102 : loss : 0.111186, loss_ce: 0.039096
2022-01-08 15:38:04,039 iteration 1103 : loss : 0.064772, loss_ce: 0.022472
2022-01-08 15:38:05,433 iteration 1104 : loss : 0.082548, loss_ce: 0.035164
2022-01-08 15:38:05,433 Training Data Eval:
2022-01-08 15:38:12,273   Average segmentation loss on training set: 0.0586
2022-01-08 15:38:12,274 Validation Data Eval:
2022-01-08 15:38:14,639   Average segmentation loss on validation set: 0.1111
2022-01-08 15:38:16,063 iteration 1105 : loss : 0.064203, loss_ce: 0.020586

 16%|████▉                         | 65/400 [28:10<2:30:12, 26.90s/it]2022-01-08 15:38:17,423 iteration 1106 : loss : 0.062023, loss_ce: 0.024344
2022-01-08 15:38:18,775 iteration 1107 : loss : 0.061299, loss_ce: 0.030718
2022-01-08 15:38:20,152 iteration 1108 : loss : 0.113290, loss_ce: 0.035957
2022-01-08 15:38:21,462 iteration 1109 : loss : 0.065428, loss_ce: 0.025071
2022-01-08 15:38:22,836 iteration 1110 : loss : 0.058872, loss_ce: 0.027463
2022-01-08 15:38:24,182 iteration 1111 : loss : 0.044160, loss_ce: 0.018829
2022-01-08 15:38:25,534 iteration 1112 : loss : 0.071248, loss_ce: 0.030814
2022-01-08 15:38:26,870 iteration 1113 : loss : 0.060124, loss_ce: 0.020391
2022-01-08 15:38:28,294 iteration 1114 : loss : 0.063391, loss_ce: 0.027582
2022-01-08 15:38:29,785 iteration 1115 : loss : 0.088362, loss_ce: 0.041896
2022-01-08 15:38:31,205 iteration 1116 : loss : 0.089267, loss_ce: 0.025535
2022-01-08 15:38:32,694 iteration 1117 : loss : 0.052265, loss_ce: 0.017503
2022-01-08 15:38:34,117 iteration 1118 : loss : 0.072655, loss_ce: 0.023124
2022-01-08 15:38:35,464 iteration 1119 : loss : 0.055005, loss_ce: 0.023857
2022-01-08 15:38:36,804 iteration 1120 : loss : 0.075436, loss_ce: 0.024245
2022-01-08 15:38:38,191 iteration 1121 : loss : 0.075879, loss_ce: 0.023685
2022-01-08 15:38:39,570 iteration 1122 : loss : 0.074865, loss_ce: 0.033854

 16%|████▉                         | 66/400 [28:33<2:24:05, 25.88s/it]2022-01-08 15:38:40,964 iteration 1123 : loss : 0.093447, loss_ce: 0.029902
2022-01-08 15:38:42,369 iteration 1124 : loss : 0.048712, loss_ce: 0.022760
2022-01-08 15:38:43,734 iteration 1125 : loss : 0.055313, loss_ce: 0.017972
2022-01-08 15:38:45,093 iteration 1126 : loss : 0.078284, loss_ce: 0.031845
2022-01-08 15:38:46,438 iteration 1127 : loss : 0.077953, loss_ce: 0.031555
2022-01-08 15:38:47,865 iteration 1128 : loss : 0.099940, loss_ce: 0.046039
2022-01-08 15:38:49,295 iteration 1129 : loss : 0.083581, loss_ce: 0.031522
2022-01-08 15:38:50,652 iteration 1130 : loss : 0.057595, loss_ce: 0.026442
2022-01-08 15:38:52,006 iteration 1131 : loss : 0.054777, loss_ce: 0.022830
2022-01-08 15:38:53,414 iteration 1132 : loss : 0.063424, loss_ce: 0.027085
2022-01-08 15:38:54,726 iteration 1133 : loss : 0.041996, loss_ce: 0.018769
2022-01-08 15:38:56,100 iteration 1134 : loss : 0.072447, loss_ce: 0.022718
2022-01-08 15:38:57,436 iteration 1135 : loss : 0.099045, loss_ce: 0.042727
2022-01-08 15:38:58,797 iteration 1136 : loss : 0.040281, loss_ce: 0.014971
2022-01-08 15:39:00,144 iteration 1137 : loss : 0.092202, loss_ce: 0.038211
2022-01-08 15:39:01,558 iteration 1138 : loss : 0.063335, loss_ce: 0.027401
2022-01-08 15:39:02,946 iteration 1139 : loss : 0.072467, loss_ce: 0.026866

 17%|█████                         | 67/400 [28:57<2:19:29, 25.13s/it]2022-01-08 15:39:04,383 iteration 1140 : loss : 0.077037, loss_ce: 0.033034
2022-01-08 15:39:05,715 iteration 1141 : loss : 0.068813, loss_ce: 0.025320
2022-01-08 15:39:07,145 iteration 1142 : loss : 0.058941, loss_ce: 0.023579
2022-01-08 15:39:08,515 iteration 1143 : loss : 0.056376, loss_ce: 0.021829
2022-01-08 15:39:09,919 iteration 1144 : loss : 0.079621, loss_ce: 0.036138
2022-01-08 15:39:11,248 iteration 1145 : loss : 0.055714, loss_ce: 0.019304
2022-01-08 15:39:12,632 iteration 1146 : loss : 0.085377, loss_ce: 0.035825
2022-01-08 15:39:13,924 iteration 1147 : loss : 0.056282, loss_ce: 0.018343
2022-01-08 15:39:15,345 iteration 1148 : loss : 0.072683, loss_ce: 0.024243
2022-01-08 15:39:16,669 iteration 1149 : loss : 0.053591, loss_ce: 0.025556
2022-01-08 15:39:18,044 iteration 1150 : loss : 0.056146, loss_ce: 0.024104
2022-01-08 15:39:19,444 iteration 1151 : loss : 0.054054, loss_ce: 0.020118
2022-01-08 15:39:20,935 iteration 1152 : loss : 0.069088, loss_ce: 0.025445
2022-01-08 15:39:22,225 iteration 1153 : loss : 0.057076, loss_ce: 0.021014
2022-01-08 15:39:23,628 iteration 1154 : loss : 0.076489, loss_ce: 0.025303
2022-01-08 15:39:24,966 iteration 1155 : loss : 0.063971, loss_ce: 0.020201
2022-01-08 15:39:26,386 iteration 1156 : loss : 0.087845, loss_ce: 0.046647

 17%|█████                         | 68/400 [29:20<2:16:14, 24.62s/it]2022-01-08 15:39:27,797 iteration 1157 : loss : 0.115147, loss_ce: 0.034418
2022-01-08 15:39:29,184 iteration 1158 : loss : 0.051362, loss_ce: 0.016718
2022-01-08 15:39:30,633 iteration 1159 : loss : 0.045438, loss_ce: 0.014960
2022-01-08 15:39:32,118 iteration 1160 : loss : 0.086876, loss_ce: 0.037060
2022-01-08 15:39:33,550 iteration 1161 : loss : 0.060852, loss_ce: 0.025725
2022-01-08 15:39:34,958 iteration 1162 : loss : 0.065577, loss_ce: 0.022695
2022-01-08 15:39:36,309 iteration 1163 : loss : 0.079135, loss_ce: 0.036890
2022-01-08 15:39:37,674 iteration 1164 : loss : 0.080157, loss_ce: 0.031222
2022-01-08 15:39:39,040 iteration 1165 : loss : 0.079410, loss_ce: 0.039498
2022-01-08 15:39:40,485 iteration 1166 : loss : 0.054228, loss_ce: 0.020041
2022-01-08 15:39:41,823 iteration 1167 : loss : 0.056827, loss_ce: 0.026669
2022-01-08 15:39:43,182 iteration 1168 : loss : 0.061158, loss_ce: 0.025709
2022-01-08 15:39:44,520 iteration 1169 : loss : 0.059473, loss_ce: 0.026074
2022-01-08 15:39:45,862 iteration 1170 : loss : 0.070083, loss_ce: 0.028348
2022-01-08 15:39:47,247 iteration 1171 : loss : 0.075683, loss_ce: 0.027114
2022-01-08 15:39:48,625 iteration 1172 : loss : 0.062930, loss_ce: 0.025630
2022-01-08 15:39:50,030 iteration 1173 : loss : 0.069403, loss_ce: 0.023603

 17%|█████▏                        | 69/400 [29:44<2:14:12, 24.33s/it]2022-01-08 15:39:51,493 iteration 1174 : loss : 0.073317, loss_ce: 0.025088
2022-01-08 15:39:52,867 iteration 1175 : loss : 0.047989, loss_ce: 0.021231
2022-01-08 15:39:54,231 iteration 1176 : loss : 0.059179, loss_ce: 0.022805
2022-01-08 15:39:55,565 iteration 1177 : loss : 0.065445, loss_ce: 0.029364
2022-01-08 15:39:56,969 iteration 1178 : loss : 0.041546, loss_ce: 0.012676
2022-01-08 15:39:58,422 iteration 1179 : loss : 0.062572, loss_ce: 0.024530
2022-01-08 15:39:59,768 iteration 1180 : loss : 0.078169, loss_ce: 0.036083
2022-01-08 15:40:01,130 iteration 1181 : loss : 0.061572, loss_ce: 0.021655
2022-01-08 15:40:02,510 iteration 1182 : loss : 0.070163, loss_ce: 0.026703
2022-01-08 15:40:03,836 iteration 1183 : loss : 0.064937, loss_ce: 0.024040
2022-01-08 15:40:05,172 iteration 1184 : loss : 0.047059, loss_ce: 0.021838
2022-01-08 15:40:06,582 iteration 1185 : loss : 0.059105, loss_ce: 0.023664
2022-01-08 15:40:07,923 iteration 1186 : loss : 0.046459, loss_ce: 0.020749
2022-01-08 15:40:09,354 iteration 1187 : loss : 0.052696, loss_ce: 0.017931
2022-01-08 15:40:10,688 iteration 1188 : loss : 0.073989, loss_ce: 0.027492
2022-01-08 15:40:12,128 iteration 1189 : loss : 0.070038, loss_ce: 0.030838
2022-01-08 15:40:12,128 Training Data Eval:
2022-01-08 15:40:18,963   Average segmentation loss on training set: 0.0434
2022-01-08 15:40:18,963 Validation Data Eval:
2022-01-08 15:40:21,329   Average segmentation loss on validation set: 0.0950
2022-01-08 15:40:22,702 iteration 1190 : loss : 0.067868, loss_ce: 0.030820

 18%|█████▎                        | 70/400 [30:16<2:27:35, 26.84s/it]2022-01-08 15:40:24,240 iteration 1191 : loss : 0.070003, loss_ce: 0.031439
2022-01-08 15:40:25,569 iteration 1192 : loss : 0.046805, loss_ce: 0.022495
2022-01-08 15:40:27,016 iteration 1193 : loss : 0.071972, loss_ce: 0.022198
2022-01-08 15:40:28,373 iteration 1194 : loss : 0.054621, loss_ce: 0.018340
2022-01-08 15:40:29,695 iteration 1195 : loss : 0.055451, loss_ce: 0.023516
2022-01-08 15:40:31,016 iteration 1196 : loss : 0.047787, loss_ce: 0.020730
2022-01-08 15:40:32,304 iteration 1197 : loss : 0.049203, loss_ce: 0.017827
2022-01-08 15:40:33,715 iteration 1198 : loss : 0.051816, loss_ce: 0.023365
2022-01-08 15:40:35,084 iteration 1199 : loss : 0.060650, loss_ce: 0.021855
2022-01-08 15:40:36,433 iteration 1200 : loss : 0.124809, loss_ce: 0.050319
2022-01-08 15:40:37,753 iteration 1201 : loss : 0.056393, loss_ce: 0.025461
2022-01-08 15:40:39,139 iteration 1202 : loss : 0.056789, loss_ce: 0.020529
2022-01-08 15:40:40,521 iteration 1203 : loss : 0.064552, loss_ce: 0.022559
2022-01-08 15:40:41,891 iteration 1204 : loss : 0.067012, loss_ce: 0.024281
2022-01-08 15:40:43,266 iteration 1205 : loss : 0.084635, loss_ce: 0.034134
2022-01-08 15:40:44,649 iteration 1206 : loss : 0.056163, loss_ce: 0.019876
2022-01-08 15:40:46,072 iteration 1207 : loss : 0.055704, loss_ce: 0.016630

 18%|█████▎                        | 71/400 [30:40<2:21:27, 25.80s/it]2022-01-08 15:40:47,536 iteration 1208 : loss : 0.060206, loss_ce: 0.030187
2022-01-08 15:40:48,918 iteration 1209 : loss : 0.047596, loss_ce: 0.017407
2022-01-08 15:40:50,295 iteration 1210 : loss : 0.053588, loss_ce: 0.020652
2022-01-08 15:40:51,619 iteration 1211 : loss : 0.045440, loss_ce: 0.020446
2022-01-08 15:40:52,927 iteration 1212 : loss : 0.087499, loss_ce: 0.025241
2022-01-08 15:40:54,410 iteration 1213 : loss : 0.064563, loss_ce: 0.027601
2022-01-08 15:40:55,782 iteration 1214 : loss : 0.053914, loss_ce: 0.022416
2022-01-08 15:40:57,161 iteration 1215 : loss : 0.094960, loss_ce: 0.039075
2022-01-08 15:40:58,651 iteration 1216 : loss : 0.049343, loss_ce: 0.017033
2022-01-08 15:41:00,034 iteration 1217 : loss : 0.042611, loss_ce: 0.014018
2022-01-08 15:41:01,366 iteration 1218 : loss : 0.048324, loss_ce: 0.018252
2022-01-08 15:41:02,673 iteration 1219 : loss : 0.051393, loss_ce: 0.017811
2022-01-08 15:41:04,030 iteration 1220 : loss : 0.061788, loss_ce: 0.022352
2022-01-08 15:41:05,365 iteration 1221 : loss : 0.072197, loss_ce: 0.029553
2022-01-08 15:41:06,827 iteration 1222 : loss : 0.064483, loss_ce: 0.020410
2022-01-08 15:41:08,177 iteration 1223 : loss : 0.052447, loss_ce: 0.022894
2022-01-08 15:41:09,585 iteration 1224 : loss : 0.084645, loss_ce: 0.032720

 18%|█████▍                        | 72/400 [31:03<2:17:16, 25.11s/it]2022-01-08 15:41:10,995 iteration 1225 : loss : 0.042352, loss_ce: 0.016939
2022-01-08 15:41:12,401 iteration 1226 : loss : 0.074115, loss_ce: 0.027497
2022-01-08 15:41:13,722 iteration 1227 : loss : 0.055063, loss_ce: 0.021351
2022-01-08 15:41:15,078 iteration 1228 : loss : 0.043812, loss_ce: 0.016833
2022-01-08 15:41:16,381 iteration 1229 : loss : 0.064495, loss_ce: 0.021128
2022-01-08 15:41:17,705 iteration 1230 : loss : 0.057608, loss_ce: 0.022427
2022-01-08 15:41:19,102 iteration 1231 : loss : 0.064276, loss_ce: 0.031389
2022-01-08 15:41:20,428 iteration 1232 : loss : 0.051424, loss_ce: 0.019738
2022-01-08 15:41:21,765 iteration 1233 : loss : 0.040533, loss_ce: 0.016811
2022-01-08 15:41:23,207 iteration 1234 : loss : 0.045114, loss_ce: 0.018790
2022-01-08 15:41:24,600 iteration 1235 : loss : 0.082024, loss_ce: 0.023515
2022-01-08 15:41:25,929 iteration 1236 : loss : 0.056286, loss_ce: 0.021125
2022-01-08 15:41:27,212 iteration 1237 : loss : 0.073255, loss_ce: 0.029736
2022-01-08 15:41:28,618 iteration 1238 : loss : 0.053478, loss_ce: 0.019365
2022-01-08 15:41:29,934 iteration 1239 : loss : 0.047662, loss_ce: 0.019984
2022-01-08 15:41:31,257 iteration 1240 : loss : 0.044901, loss_ce: 0.018837
2022-01-08 15:41:32,583 iteration 1241 : loss : 0.062897, loss_ce: 0.030366

 18%|█████▍                        | 73/400 [31:26<2:13:23, 24.48s/it]2022-01-08 15:41:34,028 iteration 1242 : loss : 0.062353, loss_ce: 0.037339
2022-01-08 15:41:35,359 iteration 1243 : loss : 0.099732, loss_ce: 0.037664
2022-01-08 15:41:36,695 iteration 1244 : loss : 0.078458, loss_ce: 0.034506
2022-01-08 15:41:38,076 iteration 1245 : loss : 0.065488, loss_ce: 0.021977
2022-01-08 15:41:39,449 iteration 1246 : loss : 0.060600, loss_ce: 0.021182
2022-01-08 15:41:40,781 iteration 1247 : loss : 0.048878, loss_ce: 0.020996
2022-01-08 15:41:42,167 iteration 1248 : loss : 0.059629, loss_ce: 0.019030
2022-01-08 15:41:43,492 iteration 1249 : loss : 0.041614, loss_ce: 0.013270
2022-01-08 15:41:44,950 iteration 1250 : loss : 0.083605, loss_ce: 0.035507
2022-01-08 15:41:46,439 iteration 1251 : loss : 0.061415, loss_ce: 0.031590
2022-01-08 15:41:47,832 iteration 1252 : loss : 0.047686, loss_ce: 0.019495
2022-01-08 15:41:49,124 iteration 1253 : loss : 0.042200, loss_ce: 0.014123
2022-01-08 15:41:50,490 iteration 1254 : loss : 0.053414, loss_ce: 0.024577
2022-01-08 15:41:51,869 iteration 1255 : loss : 0.054097, loss_ce: 0.020431
2022-01-08 15:41:53,218 iteration 1256 : loss : 0.067785, loss_ce: 0.029200
2022-01-08 15:41:54,581 iteration 1257 : loss : 0.081594, loss_ce: 0.019936
2022-01-08 15:41:55,960 iteration 1258 : loss : 0.051501, loss_ce: 0.022092

 18%|█████▌                        | 74/400 [31:50<2:11:11, 24.14s/it]2022-01-08 15:41:57,345 iteration 1259 : loss : 0.053609, loss_ce: 0.023631
2022-01-08 15:41:58,762 iteration 1260 : loss : 0.046320, loss_ce: 0.020280
2022-01-08 15:42:00,109 iteration 1261 : loss : 0.051417, loss_ce: 0.017213
2022-01-08 15:42:01,554 iteration 1262 : loss : 0.063453, loss_ce: 0.021498
2022-01-08 15:42:03,029 iteration 1263 : loss : 0.076462, loss_ce: 0.027311
2022-01-08 15:42:04,382 iteration 1264 : loss : 0.043397, loss_ce: 0.019240
2022-01-08 15:42:05,806 iteration 1265 : loss : 0.051993, loss_ce: 0.026774
2022-01-08 15:42:07,227 iteration 1266 : loss : 0.063245, loss_ce: 0.023699
2022-01-08 15:42:08,622 iteration 1267 : loss : 0.055193, loss_ce: 0.022703
2022-01-08 15:42:09,965 iteration 1268 : loss : 0.075984, loss_ce: 0.023339
2022-01-08 15:42:11,404 iteration 1269 : loss : 0.106626, loss_ce: 0.028447
2022-01-08 15:42:12,809 iteration 1270 : loss : 0.047833, loss_ce: 0.019772
2022-01-08 15:42:14,175 iteration 1271 : loss : 0.057192, loss_ce: 0.024825
2022-01-08 15:42:15,470 iteration 1272 : loss : 0.054762, loss_ce: 0.017754
2022-01-08 15:42:16,814 iteration 1273 : loss : 0.053309, loss_ce: 0.018905
2022-01-08 15:42:18,182 iteration 1274 : loss : 0.052228, loss_ce: 0.014436
2022-01-08 15:42:18,182 Training Data Eval:
2022-01-08 15:42:25,012   Average segmentation loss on training set: 0.0643
2022-01-08 15:42:25,013 Validation Data Eval:
2022-01-08 15:42:27,377   Average segmentation loss on validation set: 0.1531
2022-01-08 15:42:28,732 iteration 1275 : loss : 0.052687, loss_ce: 0.019583

 19%|█████▋                        | 75/400 [32:22<2:24:48, 26.73s/it]2022-01-08 15:42:30,077 iteration 1276 : loss : 0.047785, loss_ce: 0.019530
2022-01-08 15:42:31,548 iteration 1277 : loss : 0.050532, loss_ce: 0.018601
2022-01-08 15:42:32,880 iteration 1278 : loss : 0.037502, loss_ce: 0.013157
2022-01-08 15:42:34,338 iteration 1279 : loss : 0.043860, loss_ce: 0.014620
2022-01-08 15:42:35,726 iteration 1280 : loss : 0.062858, loss_ce: 0.030994
2022-01-08 15:42:37,106 iteration 1281 : loss : 0.071320, loss_ce: 0.032016
2022-01-08 15:42:38,421 iteration 1282 : loss : 0.030772, loss_ce: 0.013852
2022-01-08 15:42:39,843 iteration 1283 : loss : 0.067640, loss_ce: 0.020790
2022-01-08 15:42:41,167 iteration 1284 : loss : 0.059265, loss_ce: 0.024732
2022-01-08 15:42:42,598 iteration 1285 : loss : 0.052387, loss_ce: 0.020443
2022-01-08 15:42:44,060 iteration 1286 : loss : 0.126401, loss_ce: 0.036709
2022-01-08 15:42:45,416 iteration 1287 : loss : 0.043007, loss_ce: 0.022144
2022-01-08 15:42:46,749 iteration 1288 : loss : 0.055471, loss_ce: 0.026253
2022-01-08 15:42:48,118 iteration 1289 : loss : 0.070547, loss_ce: 0.026697
2022-01-08 15:42:49,525 iteration 1290 : loss : 0.065698, loss_ce: 0.024471
2022-01-08 15:42:50,939 iteration 1291 : loss : 0.065388, loss_ce: 0.026636
2022-01-08 15:42:52,371 iteration 1292 : loss : 0.058907, loss_ce: 0.020948

 19%|█████▋                        | 76/400 [32:46<2:19:20, 25.81s/it]2022-01-08 15:42:53,829 iteration 1293 : loss : 0.050885, loss_ce: 0.017731
2022-01-08 15:42:55,233 iteration 1294 : loss : 0.079535, loss_ce: 0.028055
2022-01-08 15:42:56,683 iteration 1295 : loss : 0.055528, loss_ce: 0.016838
2022-01-08 15:42:58,084 iteration 1296 : loss : 0.079132, loss_ce: 0.025516
2022-01-08 15:42:59,419 iteration 1297 : loss : 0.052969, loss_ce: 0.029723
2022-01-08 15:43:00,727 iteration 1298 : loss : 0.039053, loss_ce: 0.015419
2022-01-08 15:43:02,109 iteration 1299 : loss : 0.059585, loss_ce: 0.033683
2022-01-08 15:43:03,473 iteration 1300 : loss : 0.047601, loss_ce: 0.016205
2022-01-08 15:43:04,876 iteration 1301 : loss : 0.034778, loss_ce: 0.013459
2022-01-08 15:43:06,224 iteration 1302 : loss : 0.049842, loss_ce: 0.021481
2022-01-08 15:43:07,579 iteration 1303 : loss : 0.048956, loss_ce: 0.020004
2022-01-08 15:43:08,957 iteration 1304 : loss : 0.067712, loss_ce: 0.029331
2022-01-08 15:43:10,326 iteration 1305 : loss : 0.075430, loss_ce: 0.029761
2022-01-08 15:43:11,735 iteration 1306 : loss : 0.085961, loss_ce: 0.024965
2022-01-08 15:43:13,144 iteration 1307 : loss : 0.051361, loss_ce: 0.027068
2022-01-08 15:43:14,526 iteration 1308 : loss : 0.063922, loss_ce: 0.017866
2022-01-08 15:43:15,835 iteration 1309 : loss : 0.052902, loss_ce: 0.018696

 19%|█████▊                        | 77/400 [33:10<2:15:08, 25.10s/it]2022-01-08 15:43:17,330 iteration 1310 : loss : 0.058037, loss_ce: 0.022306
2022-01-08 15:43:18,681 iteration 1311 : loss : 0.054214, loss_ce: 0.025215
2022-01-08 15:43:20,019 iteration 1312 : loss : 0.035034, loss_ce: 0.014324
2022-01-08 15:43:21,364 iteration 1313 : loss : 0.063357, loss_ce: 0.017748
2022-01-08 15:43:22,735 iteration 1314 : loss : 0.060368, loss_ce: 0.031790
2022-01-08 15:43:24,132 iteration 1315 : loss : 0.056203, loss_ce: 0.023367
2022-01-08 15:43:25,615 iteration 1316 : loss : 0.056141, loss_ce: 0.021535
2022-01-08 15:43:26,982 iteration 1317 : loss : 0.060403, loss_ce: 0.030759
2022-01-08 15:43:28,436 iteration 1318 : loss : 0.171467, loss_ce: 0.031080
2022-01-08 15:43:29,847 iteration 1319 : loss : 0.059149, loss_ce: 0.024660
2022-01-08 15:43:31,203 iteration 1320 : loss : 0.046415, loss_ce: 0.019205
2022-01-08 15:43:32,599 iteration 1321 : loss : 0.086869, loss_ce: 0.031899
2022-01-08 15:43:33,922 iteration 1322 : loss : 0.066814, loss_ce: 0.031279
2022-01-08 15:43:35,282 iteration 1323 : loss : 0.075209, loss_ce: 0.025836
2022-01-08 15:43:36,677 iteration 1324 : loss : 0.050579, loss_ce: 0.019707
2022-01-08 15:43:38,110 iteration 1325 : loss : 0.065861, loss_ce: 0.024384
2022-01-08 15:43:39,395 iteration 1326 : loss : 0.056321, loss_ce: 0.022161

 20%|█████▊                        | 78/400 [33:33<2:12:14, 24.64s/it]2022-01-08 15:43:40,791 iteration 1327 : loss : 0.066517, loss_ce: 0.024252
2022-01-08 15:43:42,186 iteration 1328 : loss : 0.073727, loss_ce: 0.033519
2022-01-08 15:43:43,558 iteration 1329 : loss : 0.043800, loss_ce: 0.018912
2022-01-08 15:43:44,901 iteration 1330 : loss : 0.087077, loss_ce: 0.026667
2022-01-08 15:43:46,210 iteration 1331 : loss : 0.059212, loss_ce: 0.030592
2022-01-08 15:43:47,534 iteration 1332 : loss : 0.049143, loss_ce: 0.015364
2022-01-08 15:43:48,885 iteration 1333 : loss : 0.046107, loss_ce: 0.013154
2022-01-08 15:43:50,257 iteration 1334 : loss : 0.052706, loss_ce: 0.019731
2022-01-08 15:43:51,599 iteration 1335 : loss : 0.055608, loss_ce: 0.019492
2022-01-08 15:43:52,941 iteration 1336 : loss : 0.039689, loss_ce: 0.015011
2022-01-08 15:43:54,362 iteration 1337 : loss : 0.073011, loss_ce: 0.033172
2022-01-08 15:43:55,767 iteration 1338 : loss : 0.053147, loss_ce: 0.017680
2022-01-08 15:43:57,160 iteration 1339 : loss : 0.050831, loss_ce: 0.023730
2022-01-08 15:43:58,558 iteration 1340 : loss : 0.073845, loss_ce: 0.033407
2022-01-08 15:43:59,939 iteration 1341 : loss : 0.061645, loss_ce: 0.025065
2022-01-08 15:44:01,299 iteration 1342 : loss : 0.070016, loss_ce: 0.027843
2022-01-08 15:44:02,615 iteration 1343 : loss : 0.043910, loss_ce: 0.016269

 20%|█████▉                        | 79/400 [33:56<2:09:32, 24.21s/it]2022-01-08 15:44:04,039 iteration 1344 : loss : 0.072914, loss_ce: 0.028613
2022-01-08 15:44:05,483 iteration 1345 : loss : 0.067988, loss_ce: 0.028350
2022-01-08 15:44:06,835 iteration 1346 : loss : 0.074810, loss_ce: 0.033151
2022-01-08 15:44:08,272 iteration 1347 : loss : 0.037872, loss_ce: 0.015263
2022-01-08 15:44:09,790 iteration 1348 : loss : 0.075378, loss_ce: 0.030436
2022-01-08 15:44:11,167 iteration 1349 : loss : 0.064600, loss_ce: 0.026438
2022-01-08 15:44:12,540 iteration 1350 : loss : 0.062913, loss_ce: 0.026938
2022-01-08 15:44:13,913 iteration 1351 : loss : 0.052426, loss_ce: 0.024448
2022-01-08 15:44:15,340 iteration 1352 : loss : 0.052102, loss_ce: 0.022155
2022-01-08 15:44:16,740 iteration 1353 : loss : 0.078910, loss_ce: 0.025860
2022-01-08 15:44:18,159 iteration 1354 : loss : 0.062693, loss_ce: 0.023440
2022-01-08 15:44:19,633 iteration 1355 : loss : 0.092472, loss_ce: 0.021292
2022-01-08 15:44:21,036 iteration 1356 : loss : 0.051632, loss_ce: 0.021139
2022-01-08 15:44:22,445 iteration 1357 : loss : 0.049753, loss_ce: 0.022059
2022-01-08 15:44:23,875 iteration 1358 : loss : 0.067230, loss_ce: 0.030825
2022-01-08 15:44:25,249 iteration 1359 : loss : 0.065873, loss_ce: 0.030710
2022-01-08 15:44:25,249 Training Data Eval:
2022-01-08 15:44:32,117   Average segmentation loss on training set: 0.0423
2022-01-08 15:44:32,117 Validation Data Eval:
2022-01-08 15:44:34,483   Average segmentation loss on validation set: 0.0842
2022-01-08 15:44:40,283 Found new lowest validation loss at iteration 1359! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_KEYS_best_val_loss_seed1234.pth
2022-01-08 15:44:41,792 iteration 1360 : loss : 0.047483, loss_ce: 0.011866

 20%|██████                        | 80/400 [34:36<2:33:04, 28.70s/it]2022-01-08 15:44:43,319 iteration 1361 : loss : 0.060558, loss_ce: 0.025298
2022-01-08 15:44:44,719 iteration 1362 : loss : 0.058521, loss_ce: 0.017760
2022-01-08 15:44:46,280 iteration 1363 : loss : 0.086672, loss_ce: 0.038145
2022-01-08 15:44:47,540 iteration 1364 : loss : 0.059293, loss_ce: 0.016216
2022-01-08 15:44:48,982 iteration 1365 : loss : 0.057486, loss_ce: 0.023361
2022-01-08 15:44:50,379 iteration 1366 : loss : 0.070059, loss_ce: 0.028062
2022-01-08 15:44:51,753 iteration 1367 : loss : 0.043639, loss_ce: 0.017207
2022-01-08 15:44:53,142 iteration 1368 : loss : 0.044206, loss_ce: 0.020208
2022-01-08 15:44:54,506 iteration 1369 : loss : 0.056360, loss_ce: 0.020935
2022-01-08 15:44:55,946 iteration 1370 : loss : 0.066868, loss_ce: 0.032927
2022-01-08 15:44:57,297 iteration 1371 : loss : 0.043376, loss_ce: 0.015938
2022-01-08 15:44:58,669 iteration 1372 : loss : 0.053641, loss_ce: 0.021240
2022-01-08 15:45:00,019 iteration 1373 : loss : 0.069409, loss_ce: 0.028414
2022-01-08 15:45:01,412 iteration 1374 : loss : 0.064833, loss_ce: 0.022753
2022-01-08 15:45:02,814 iteration 1375 : loss : 0.082761, loss_ce: 0.045084
2022-01-08 15:45:04,208 iteration 1376 : loss : 0.058470, loss_ce: 0.018453
2022-01-08 15:45:05,574 iteration 1377 : loss : 0.034471, loss_ce: 0.013600

 20%|██████                        | 81/400 [34:59<2:24:46, 27.23s/it]2022-01-08 15:45:06,949 iteration 1378 : loss : 0.050002, loss_ce: 0.021779
2022-01-08 15:45:08,389 iteration 1379 : loss : 0.043194, loss_ce: 0.017628
2022-01-08 15:45:09,808 iteration 1380 : loss : 0.063345, loss_ce: 0.029445
2022-01-08 15:45:11,284 iteration 1381 : loss : 0.052837, loss_ce: 0.021471
2022-01-08 15:45:12,601 iteration 1382 : loss : 0.043229, loss_ce: 0.017253
2022-01-08 15:45:14,057 iteration 1383 : loss : 0.054714, loss_ce: 0.018875
2022-01-08 15:45:15,447 iteration 1384 : loss : 0.059054, loss_ce: 0.022360
2022-01-08 15:45:16,774 iteration 1385 : loss : 0.064567, loss_ce: 0.021531
2022-01-08 15:45:18,130 iteration 1386 : loss : 0.037571, loss_ce: 0.014956
2022-01-08 15:45:19,488 iteration 1387 : loss : 0.046919, loss_ce: 0.017113
2022-01-08 15:45:20,871 iteration 1388 : loss : 0.062037, loss_ce: 0.018360
2022-01-08 15:45:22,255 iteration 1389 : loss : 0.055127, loss_ce: 0.021062
2022-01-08 15:45:23,678 iteration 1390 : loss : 0.069169, loss_ce: 0.027410
2022-01-08 15:45:25,126 iteration 1391 : loss : 0.050151, loss_ce: 0.018619
2022-01-08 15:45:26,551 iteration 1392 : loss : 0.058883, loss_ce: 0.028253
2022-01-08 15:45:27,916 iteration 1393 : loss : 0.053703, loss_ce: 0.018578
2022-01-08 15:45:29,361 iteration 1394 : loss : 0.051415, loss_ce: 0.022319

 20%|██████▏                       | 82/400 [35:23<2:18:49, 26.19s/it]2022-01-08 15:45:30,791 iteration 1395 : loss : 0.055349, loss_ce: 0.020992
2022-01-08 15:45:32,151 iteration 1396 : loss : 0.050822, loss_ce: 0.024891
2022-01-08 15:45:33,598 iteration 1397 : loss : 0.061763, loss_ce: 0.024065
2022-01-08 15:45:35,047 iteration 1398 : loss : 0.054250, loss_ce: 0.023171
2022-01-08 15:45:36,355 iteration 1399 : loss : 0.050523, loss_ce: 0.021402
2022-01-08 15:45:37,659 iteration 1400 : loss : 0.045539, loss_ce: 0.014702
2022-01-08 15:45:39,096 iteration 1401 : loss : 0.059107, loss_ce: 0.020165
2022-01-08 15:45:40,503 iteration 1402 : loss : 0.052702, loss_ce: 0.020638
2022-01-08 15:45:41,831 iteration 1403 : loss : 0.061352, loss_ce: 0.022852
2022-01-08 15:45:43,156 iteration 1404 : loss : 0.032685, loss_ce: 0.013721
2022-01-08 15:45:44,576 iteration 1405 : loss : 0.063774, loss_ce: 0.020580
2022-01-08 15:45:45,959 iteration 1406 : loss : 0.062128, loss_ce: 0.021605
2022-01-08 15:45:47,378 iteration 1407 : loss : 0.036703, loss_ce: 0.013985
2022-01-08 15:45:48,748 iteration 1408 : loss : 0.053892, loss_ce: 0.017845
2022-01-08 15:45:50,131 iteration 1409 : loss : 0.085350, loss_ce: 0.026396
2022-01-08 15:45:51,577 iteration 1410 : loss : 0.039699, loss_ce: 0.016624
2022-01-08 15:45:52,928 iteration 1411 : loss : 0.050694, loss_ce: 0.017577

 21%|██████▏                       | 83/400 [35:47<2:14:13, 25.41s/it]2022-01-08 15:45:54,331 iteration 1412 : loss : 0.056500, loss_ce: 0.020952
2022-01-08 15:45:55,769 iteration 1413 : loss : 0.066704, loss_ce: 0.020874
2022-01-08 15:45:57,132 iteration 1414 : loss : 0.045298, loss_ce: 0.016761
2022-01-08 15:45:58,551 iteration 1415 : loss : 0.083015, loss_ce: 0.025236
2022-01-08 15:45:59,910 iteration 1416 : loss : 0.053847, loss_ce: 0.021470
2022-01-08 15:46:01,260 iteration 1417 : loss : 0.061132, loss_ce: 0.021534
2022-01-08 15:46:02,607 iteration 1418 : loss : 0.064866, loss_ce: 0.030165
2022-01-08 15:46:03,921 iteration 1419 : loss : 0.051043, loss_ce: 0.018834
2022-01-08 15:46:05,334 iteration 1420 : loss : 0.052957, loss_ce: 0.018787
2022-01-08 15:46:06,790 iteration 1421 : loss : 0.076828, loss_ce: 0.031936
2022-01-08 15:46:08,191 iteration 1422 : loss : 0.046297, loss_ce: 0.016505
2022-01-08 15:46:09,534 iteration 1423 : loss : 0.056988, loss_ce: 0.026244
2022-01-08 15:46:10,934 iteration 1424 : loss : 0.047453, loss_ce: 0.021370
2022-01-08 15:46:12,329 iteration 1425 : loss : 0.037182, loss_ce: 0.015551
2022-01-08 15:46:13,662 iteration 1426 : loss : 0.062887, loss_ce: 0.027816
2022-01-08 15:46:15,032 iteration 1427 : loss : 0.058207, loss_ce: 0.020791
2022-01-08 15:46:16,313 iteration 1428 : loss : 0.063065, loss_ce: 0.023368

 21%|██████▎                       | 84/400 [36:10<2:10:37, 24.80s/it]2022-01-08 15:46:17,818 iteration 1429 : loss : 0.061337, loss_ce: 0.026736
2022-01-08 15:46:19,151 iteration 1430 : loss : 0.138745, loss_ce: 0.040576
2022-01-08 15:46:20,523 iteration 1431 : loss : 0.059042, loss_ce: 0.026008
2022-01-08 15:46:21,911 iteration 1432 : loss : 0.054836, loss_ce: 0.022537
2022-01-08 15:46:23,336 iteration 1433 : loss : 0.061574, loss_ce: 0.020693
2022-01-08 15:46:24,692 iteration 1434 : loss : 0.047781, loss_ce: 0.020582
2022-01-08 15:46:26,093 iteration 1435 : loss : 0.051872, loss_ce: 0.020050
2022-01-08 15:46:27,503 iteration 1436 : loss : 0.050497, loss_ce: 0.020521
2022-01-08 15:46:28,921 iteration 1437 : loss : 0.046472, loss_ce: 0.013972
2022-01-08 15:46:30,305 iteration 1438 : loss : 0.050145, loss_ce: 0.022500
2022-01-08 15:46:31,734 iteration 1439 : loss : 0.069479, loss_ce: 0.031139
2022-01-08 15:46:33,150 iteration 1440 : loss : 0.048057, loss_ce: 0.021088
2022-01-08 15:46:34,515 iteration 1441 : loss : 0.035349, loss_ce: 0.015153
2022-01-08 15:46:35,901 iteration 1442 : loss : 0.052906, loss_ce: 0.022750
2022-01-08 15:46:37,313 iteration 1443 : loss : 0.061778, loss_ce: 0.024441
2022-01-08 15:46:38,698 iteration 1444 : loss : 0.106079, loss_ce: 0.026019
2022-01-08 15:46:38,698 Training Data Eval:
2022-01-08 15:46:45,524   Average segmentation loss on training set: 0.0373
2022-01-08 15:46:45,524 Validation Data Eval:
2022-01-08 15:46:47,880   Average segmentation loss on validation set: 0.0748
2022-01-08 15:46:53,705 Found new lowest validation loss at iteration 1444! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_KEYS_best_val_loss_seed1234.pth
2022-01-08 15:46:55,130 iteration 1445 : loss : 0.039178, loss_ce: 0.011869

 21%|██████▍                       | 85/400 [36:49<2:32:15, 29.00s/it]2022-01-08 15:46:56,638 iteration 1446 : loss : 0.046355, loss_ce: 0.016204
2022-01-08 15:46:57,994 iteration 1447 : loss : 0.053479, loss_ce: 0.017403
2022-01-08 15:46:59,308 iteration 1448 : loss : 0.057720, loss_ce: 0.031047
2022-01-08 15:47:00,706 iteration 1449 : loss : 0.066135, loss_ce: 0.023512
2022-01-08 15:47:02,179 iteration 1450 : loss : 0.065514, loss_ce: 0.038173
2022-01-08 15:47:03,660 iteration 1451 : loss : 0.043170, loss_ce: 0.017376
2022-01-08 15:47:05,006 iteration 1452 : loss : 0.053486, loss_ce: 0.017565
2022-01-08 15:47:06,363 iteration 1453 : loss : 0.056696, loss_ce: 0.026131
2022-01-08 15:47:07,762 iteration 1454 : loss : 0.063487, loss_ce: 0.022896
2022-01-08 15:47:09,108 iteration 1455 : loss : 0.041070, loss_ce: 0.017901
2022-01-08 15:47:10,565 iteration 1456 : loss : 0.078629, loss_ce: 0.024090
2022-01-08 15:47:11,939 iteration 1457 : loss : 0.053728, loss_ce: 0.024525
2022-01-08 15:47:13,305 iteration 1458 : loss : 0.055286, loss_ce: 0.021097
2022-01-08 15:47:14,638 iteration 1459 : loss : 0.061165, loss_ce: 0.015897
2022-01-08 15:47:16,077 iteration 1460 : loss : 0.087233, loss_ce: 0.039657
2022-01-08 15:47:17,458 iteration 1461 : loss : 0.057653, loss_ce: 0.025508
2022-01-08 15:47:18,882 iteration 1462 : loss : 0.042091, loss_ce: 0.018314

 22%|██████▍                       | 86/400 [37:13<2:23:33, 27.43s/it]2022-01-08 15:47:20,309 iteration 1463 : loss : 0.043912, loss_ce: 0.020051
2022-01-08 15:47:21,663 iteration 1464 : loss : 0.046689, loss_ce: 0.018155
2022-01-08 15:47:23,071 iteration 1465 : loss : 0.064068, loss_ce: 0.018037
2022-01-08 15:47:24,475 iteration 1466 : loss : 0.042444, loss_ce: 0.018131
2022-01-08 15:47:25,864 iteration 1467 : loss : 0.050967, loss_ce: 0.022641
2022-01-08 15:47:27,218 iteration 1468 : loss : 0.039672, loss_ce: 0.017815
2022-01-08 15:47:28,592 iteration 1469 : loss : 0.048503, loss_ce: 0.017431
2022-01-08 15:47:29,999 iteration 1470 : loss : 0.059180, loss_ce: 0.024056
2022-01-08 15:47:31,403 iteration 1471 : loss : 0.072752, loss_ce: 0.044095
2022-01-08 15:47:32,684 iteration 1472 : loss : 0.042929, loss_ce: 0.014400
2022-01-08 15:47:34,144 iteration 1473 : loss : 0.052876, loss_ce: 0.018880
2022-01-08 15:47:35,569 iteration 1474 : loss : 0.062242, loss_ce: 0.021149
2022-01-08 15:47:36,941 iteration 1475 : loss : 0.047975, loss_ce: 0.022717
2022-01-08 15:47:38,404 iteration 1476 : loss : 0.071868, loss_ce: 0.023917
2022-01-08 15:47:39,824 iteration 1477 : loss : 0.049491, loss_ce: 0.016558
2022-01-08 15:47:41,281 iteration 1478 : loss : 0.058931, loss_ce: 0.023159
2022-01-08 15:47:42,618 iteration 1479 : loss : 0.053497, loss_ce: 0.016902

 22%|██████▌                       | 87/400 [37:36<2:17:19, 26.32s/it]2022-01-08 15:47:44,054 iteration 1480 : loss : 0.053197, loss_ce: 0.018468
2022-01-08 15:47:45,408 iteration 1481 : loss : 0.049823, loss_ce: 0.019520
2022-01-08 15:47:46,777 iteration 1482 : loss : 0.051575, loss_ce: 0.021856
2022-01-08 15:47:48,225 iteration 1483 : loss : 0.050222, loss_ce: 0.018355
2022-01-08 15:47:49,728 iteration 1484 : loss : 0.099531, loss_ce: 0.034035
2022-01-08 15:47:51,171 iteration 1485 : loss : 0.045130, loss_ce: 0.019809
2022-01-08 15:47:52,536 iteration 1486 : loss : 0.047468, loss_ce: 0.018506
2022-01-08 15:47:53,917 iteration 1487 : loss : 0.051611, loss_ce: 0.021165
2022-01-08 15:47:55,311 iteration 1488 : loss : 0.044948, loss_ce: 0.017556
2022-01-08 15:47:56,713 iteration 1489 : loss : 0.032782, loss_ce: 0.012997
2022-01-08 15:47:58,138 iteration 1490 : loss : 0.061772, loss_ce: 0.023848
2022-01-08 15:47:59,590 iteration 1491 : loss : 0.046117, loss_ce: 0.019143
2022-01-08 15:48:00,933 iteration 1492 : loss : 0.039505, loss_ce: 0.016357
2022-01-08 15:48:02,354 iteration 1493 : loss : 0.053125, loss_ce: 0.021153
2022-01-08 15:48:03,712 iteration 1494 : loss : 0.038944, loss_ce: 0.016385
2022-01-08 15:48:05,074 iteration 1495 : loss : 0.048482, loss_ce: 0.020119
2022-01-08 15:48:06,454 iteration 1496 : loss : 0.074665, loss_ce: 0.022303

 22%|██████▌                       | 88/400 [38:00<2:12:59, 25.57s/it]2022-01-08 15:48:07,846 iteration 1497 : loss : 0.052134, loss_ce: 0.022549
2022-01-08 15:48:09,201 iteration 1498 : loss : 0.047348, loss_ce: 0.014448
2022-01-08 15:48:10,614 iteration 1499 : loss : 0.059966, loss_ce: 0.027433
2022-01-08 15:48:11,924 iteration 1500 : loss : 0.067993, loss_ce: 0.021277
2022-01-08 15:48:13,286 iteration 1501 : loss : 0.043732, loss_ce: 0.013381
2022-01-08 15:48:14,693 iteration 1502 : loss : 0.062650, loss_ce: 0.023959
2022-01-08 15:48:16,048 iteration 1503 : loss : 0.030931, loss_ce: 0.013727
2022-01-08 15:48:17,408 iteration 1504 : loss : 0.045027, loss_ce: 0.016310
2022-01-08 15:48:18,723 iteration 1505 : loss : 0.044899, loss_ce: 0.015247
2022-01-08 15:48:20,090 iteration 1506 : loss : 0.068353, loss_ce: 0.027998
2022-01-08 15:48:21,465 iteration 1507 : loss : 0.069318, loss_ce: 0.024409
2022-01-08 15:48:22,808 iteration 1508 : loss : 0.057980, loss_ce: 0.027419
2022-01-08 15:48:24,166 iteration 1509 : loss : 0.065365, loss_ce: 0.022937
2022-01-08 15:48:25,497 iteration 1510 : loss : 0.034590, loss_ce: 0.012797
2022-01-08 15:48:26,884 iteration 1511 : loss : 0.042204, loss_ce: 0.020719
2022-01-08 15:48:28,214 iteration 1512 : loss : 0.046848, loss_ce: 0.019219
2022-01-08 15:48:29,602 iteration 1513 : loss : 0.055643, loss_ce: 0.026300

 22%|██████▋                       | 89/400 [38:23<2:08:47, 24.85s/it]2022-01-08 15:48:31,007 iteration 1514 : loss : 0.052255, loss_ce: 0.018111
2022-01-08 15:48:32,377 iteration 1515 : loss : 0.051358, loss_ce: 0.023446
2022-01-08 15:48:33,767 iteration 1516 : loss : 0.055826, loss_ce: 0.020346
2022-01-08 15:48:35,130 iteration 1517 : loss : 0.051576, loss_ce: 0.025290
2022-01-08 15:48:36,530 iteration 1518 : loss : 0.056250, loss_ce: 0.018587
2022-01-08 15:48:37,879 iteration 1519 : loss : 0.041832, loss_ce: 0.015961
2022-01-08 15:48:39,219 iteration 1520 : loss : 0.047837, loss_ce: 0.017769
2022-01-08 15:48:40,572 iteration 1521 : loss : 0.052232, loss_ce: 0.019149
2022-01-08 15:48:42,039 iteration 1522 : loss : 0.052399, loss_ce: 0.015874
2022-01-08 15:48:43,360 iteration 1523 : loss : 0.050056, loss_ce: 0.024803
2022-01-08 15:48:44,755 iteration 1524 : loss : 0.062192, loss_ce: 0.022417
2022-01-08 15:48:46,105 iteration 1525 : loss : 0.043381, loss_ce: 0.018683
2022-01-08 15:48:47,535 iteration 1526 : loss : 0.043280, loss_ce: 0.018858
2022-01-08 15:48:48,968 iteration 1527 : loss : 0.072244, loss_ce: 0.038914
2022-01-08 15:48:50,385 iteration 1528 : loss : 0.071390, loss_ce: 0.028822
2022-01-08 15:48:51,729 iteration 1529 : loss : 0.048397, loss_ce: 0.020429
2022-01-08 15:48:51,730 Training Data Eval:
2022-01-08 15:48:58,556   Average segmentation loss on training set: 0.0359
2022-01-08 15:48:58,556 Validation Data Eval:
2022-01-08 15:49:00,909   Average segmentation loss on validation set: 0.0978
2022-01-08 15:49:02,274 iteration 1530 : loss : 0.058066, loss_ce: 0.027321

 22%|██████▊                       | 90/400 [38:56<2:20:30, 27.20s/it]2022-01-08 15:49:03,823 iteration 1531 : loss : 0.054308, loss_ce: 0.020567
2022-01-08 15:49:05,241 iteration 1532 : loss : 0.076272, loss_ce: 0.031734
2022-01-08 15:49:06,580 iteration 1533 : loss : 0.038995, loss_ce: 0.016727
2022-01-08 15:49:08,005 iteration 1534 : loss : 0.069247, loss_ce: 0.031187
2022-01-08 15:49:09,367 iteration 1535 : loss : 0.044215, loss_ce: 0.017967
2022-01-08 15:49:10,712 iteration 1536 : loss : 0.074861, loss_ce: 0.037302
2022-01-08 15:49:12,049 iteration 1537 : loss : 0.065849, loss_ce: 0.022628
2022-01-08 15:49:13,373 iteration 1538 : loss : 0.160732, loss_ce: 0.029805
2022-01-08 15:49:14,739 iteration 1539 : loss : 0.041591, loss_ce: 0.015523
2022-01-08 15:49:16,110 iteration 1540 : loss : 0.050579, loss_ce: 0.020972
2022-01-08 15:49:17,404 iteration 1541 : loss : 0.035892, loss_ce: 0.011935
2022-01-08 15:49:18,781 iteration 1542 : loss : 0.066470, loss_ce: 0.028275
2022-01-08 15:49:20,130 iteration 1543 : loss : 0.048484, loss_ce: 0.015087
2022-01-08 15:49:21,440 iteration 1544 : loss : 0.043450, loss_ce: 0.017059
2022-01-08 15:49:22,802 iteration 1545 : loss : 0.070138, loss_ce: 0.030102
2022-01-08 15:49:24,155 iteration 1546 : loss : 0.051115, loss_ce: 0.021520
2022-01-08 15:49:25,504 iteration 1547 : loss : 0.056408, loss_ce: 0.019243

 23%|██████▊                       | 91/400 [39:19<2:13:55, 26.01s/it]2022-01-08 15:49:26,947 iteration 1548 : loss : 0.042199, loss_ce: 0.014684
2022-01-08 15:49:28,261 iteration 1549 : loss : 0.045286, loss_ce: 0.018754
2022-01-08 15:49:29,719 iteration 1550 : loss : 0.059177, loss_ce: 0.027633
2022-01-08 15:49:31,090 iteration 1551 : loss : 0.064692, loss_ce: 0.026375
2022-01-08 15:49:32,465 iteration 1552 : loss : 0.049071, loss_ce: 0.021863
2022-01-08 15:49:33,754 iteration 1553 : loss : 0.035720, loss_ce: 0.018305
2022-01-08 15:49:35,084 iteration 1554 : loss : 0.066322, loss_ce: 0.026651
2022-01-08 15:49:36,511 iteration 1555 : loss : 0.058948, loss_ce: 0.021665
2022-01-08 15:49:38,002 iteration 1556 : loss : 0.095099, loss_ce: 0.037717
2022-01-08 15:49:39,438 iteration 1557 : loss : 0.088038, loss_ce: 0.024518
2022-01-08 15:49:40,825 iteration 1558 : loss : 0.065046, loss_ce: 0.019654
2022-01-08 15:49:42,301 iteration 1559 : loss : 0.058422, loss_ce: 0.025874
2022-01-08 15:49:43,657 iteration 1560 : loss : 0.059144, loss_ce: 0.016756
2022-01-08 15:49:45,015 iteration 1561 : loss : 0.064005, loss_ce: 0.021786
2022-01-08 15:49:46,403 iteration 1562 : loss : 0.060892, loss_ce: 0.027336
2022-01-08 15:49:47,764 iteration 1563 : loss : 0.050626, loss_ce: 0.024286
2022-01-08 15:49:49,142 iteration 1564 : loss : 0.049966, loss_ce: 0.016418

 23%|██████▉                       | 92/400 [39:43<2:09:51, 25.30s/it]2022-01-08 15:49:50,598 iteration 1565 : loss : 0.055988, loss_ce: 0.022191
2022-01-08 15:49:51,956 iteration 1566 : loss : 0.071247, loss_ce: 0.031046
2022-01-08 15:49:53,364 iteration 1567 : loss : 0.075046, loss_ce: 0.020501
2022-01-08 15:49:54,837 iteration 1568 : loss : 0.057651, loss_ce: 0.025024
2022-01-08 15:49:56,192 iteration 1569 : loss : 0.054382, loss_ce: 0.023026
2022-01-08 15:49:57,581 iteration 1570 : loss : 0.061138, loss_ce: 0.029952
2022-01-08 15:49:58,943 iteration 1571 : loss : 0.052916, loss_ce: 0.023293
2022-01-08 15:50:00,315 iteration 1572 : loss : 0.058755, loss_ce: 0.026545
2022-01-08 15:50:01,702 iteration 1573 : loss : 0.075692, loss_ce: 0.023091
2022-01-08 15:50:03,087 iteration 1574 : loss : 0.044336, loss_ce: 0.020128
2022-01-08 15:50:04,487 iteration 1575 : loss : 0.054646, loss_ce: 0.021171
2022-01-08 15:50:05,847 iteration 1576 : loss : 0.069186, loss_ce: 0.022285
2022-01-08 15:50:07,178 iteration 1577 : loss : 0.064006, loss_ce: 0.022604
2022-01-08 15:50:08,460 iteration 1578 : loss : 0.038435, loss_ce: 0.015609
2022-01-08 15:50:09,821 iteration 1579 : loss : 0.042008, loss_ce: 0.015591
2022-01-08 15:50:11,214 iteration 1580 : loss : 0.048405, loss_ce: 0.015104
2022-01-08 15:50:12,608 iteration 1581 : loss : 0.047438, loss_ce: 0.018525

 23%|██████▉                       | 93/400 [40:06<2:06:37, 24.75s/it]2022-01-08 15:50:14,078 iteration 1582 : loss : 0.047405, loss_ce: 0.021915
2022-01-08 15:50:15,457 iteration 1583 : loss : 0.062818, loss_ce: 0.018893
2022-01-08 15:50:16,790 iteration 1584 : loss : 0.040246, loss_ce: 0.013105
2022-01-08 15:50:18,146 iteration 1585 : loss : 0.044112, loss_ce: 0.019650
2022-01-08 15:50:19,442 iteration 1586 : loss : 0.040390, loss_ce: 0.018350
2022-01-08 15:50:20,786 iteration 1587 : loss : 0.044843, loss_ce: 0.016426
2022-01-08 15:50:22,134 iteration 1588 : loss : 0.038560, loss_ce: 0.012253
2022-01-08 15:50:23,543 iteration 1589 : loss : 0.045344, loss_ce: 0.017973
2022-01-08 15:50:24,990 iteration 1590 : loss : 0.056204, loss_ce: 0.020893
2022-01-08 15:50:26,342 iteration 1591 : loss : 0.050524, loss_ce: 0.023769
2022-01-08 15:50:27,632 iteration 1592 : loss : 0.036212, loss_ce: 0.016673
2022-01-08 15:50:29,010 iteration 1593 : loss : 0.044983, loss_ce: 0.014352
2022-01-08 15:50:30,368 iteration 1594 : loss : 0.048745, loss_ce: 0.016456
2022-01-08 15:50:31,688 iteration 1595 : loss : 0.047326, loss_ce: 0.024468
2022-01-08 15:50:32,984 iteration 1596 : loss : 0.051556, loss_ce: 0.017389
2022-01-08 15:50:34,366 iteration 1597 : loss : 0.074941, loss_ce: 0.018387
2022-01-08 15:50:35,771 iteration 1598 : loss : 0.053257, loss_ce: 0.018338

 24%|███████                       | 94/400 [40:30<2:03:46, 24.27s/it]2022-01-08 15:50:37,240 iteration 1599 : loss : 0.043113, loss_ce: 0.017975
2022-01-08 15:50:38,596 iteration 1600 : loss : 0.051311, loss_ce: 0.022629
2022-01-08 15:50:39,999 iteration 1601 : loss : 0.056920, loss_ce: 0.020783
2022-01-08 15:50:41,383 iteration 1602 : loss : 0.071058, loss_ce: 0.020196
2022-01-08 15:50:42,745 iteration 1603 : loss : 0.059185, loss_ce: 0.025661
2022-01-08 15:50:44,094 iteration 1604 : loss : 0.066606, loss_ce: 0.020876
2022-01-08 15:50:45,449 iteration 1605 : loss : 0.069692, loss_ce: 0.025916
2022-01-08 15:50:46,825 iteration 1606 : loss : 0.039762, loss_ce: 0.015798
2022-01-08 15:50:48,192 iteration 1607 : loss : 0.054065, loss_ce: 0.016342
2022-01-08 15:50:49,641 iteration 1608 : loss : 0.079862, loss_ce: 0.032400
2022-01-08 15:50:50,993 iteration 1609 : loss : 0.047263, loss_ce: 0.018109
2022-01-08 15:50:52,447 iteration 1610 : loss : 0.069582, loss_ce: 0.025319
2022-01-08 15:50:53,899 iteration 1611 : loss : 0.054564, loss_ce: 0.026281
2022-01-08 15:50:55,371 iteration 1612 : loss : 0.042456, loss_ce: 0.015586
2022-01-08 15:50:56,754 iteration 1613 : loss : 0.050747, loss_ce: 0.018299
2022-01-08 15:50:58,188 iteration 1614 : loss : 0.058541, loss_ce: 0.025785
2022-01-08 15:50:58,188 Training Data Eval:
2022-01-08 15:51:05,030   Average segmentation loss on training set: 0.0539
2022-01-08 15:51:05,031 Validation Data Eval:
2022-01-08 15:51:07,396   Average segmentation loss on validation set: 0.0791
2022-01-08 15:51:08,816 iteration 1615 : loss : 0.065697, loss_ce: 0.025086

 24%|███████▏                      | 95/400 [41:03<2:16:45, 26.90s/it]2022-01-08 15:51:10,249 iteration 1616 : loss : 0.048206, loss_ce: 0.019034
2022-01-08 15:51:11,614 iteration 1617 : loss : 0.045877, loss_ce: 0.019321
2022-01-08 15:51:12,935 iteration 1618 : loss : 0.049774, loss_ce: 0.017607
2022-01-08 15:51:14,302 iteration 1619 : loss : 0.057416, loss_ce: 0.032290
2022-01-08 15:51:15,790 iteration 1620 : loss : 0.051310, loss_ce: 0.016615
2022-01-08 15:51:17,278 iteration 1621 : loss : 0.046111, loss_ce: 0.016851
2022-01-08 15:51:18,651 iteration 1622 : loss : 0.056972, loss_ce: 0.023819
2022-01-08 15:51:19,982 iteration 1623 : loss : 0.045889, loss_ce: 0.014837
2022-01-08 15:51:21,379 iteration 1624 : loss : 0.049684, loss_ce: 0.017733
2022-01-08 15:51:22,690 iteration 1625 : loss : 0.038136, loss_ce: 0.013948
2022-01-08 15:51:24,041 iteration 1626 : loss : 0.040152, loss_ce: 0.015692
2022-01-08 15:51:25,524 iteration 1627 : loss : 0.060709, loss_ce: 0.022662
2022-01-08 15:51:26,987 iteration 1628 : loss : 0.053823, loss_ce: 0.021880
2022-01-08 15:51:28,340 iteration 1629 : loss : 0.046924, loss_ce: 0.016847
2022-01-08 15:51:29,668 iteration 1630 : loss : 0.035039, loss_ce: 0.013123
2022-01-08 15:51:31,001 iteration 1631 : loss : 0.053692, loss_ce: 0.016656
2022-01-08 15:51:32,345 iteration 1632 : loss : 0.040864, loss_ce: 0.016369

 24%|███████▏                      | 96/400 [41:26<2:11:10, 25.89s/it]2022-01-08 15:51:33,774 iteration 1633 : loss : 0.061409, loss_ce: 0.020714
2022-01-08 15:51:35,171 iteration 1634 : loss : 0.053213, loss_ce: 0.018762
2022-01-08 15:51:36,520 iteration 1635 : loss : 0.056091, loss_ce: 0.018417
2022-01-08 15:51:37,819 iteration 1636 : loss : 0.040060, loss_ce: 0.019861
2022-01-08 15:51:39,209 iteration 1637 : loss : 0.051986, loss_ce: 0.015622
2022-01-08 15:51:40,576 iteration 1638 : loss : 0.048162, loss_ce: 0.024103
2022-01-08 15:51:42,001 iteration 1639 : loss : 0.050958, loss_ce: 0.021907
2022-01-08 15:51:43,346 iteration 1640 : loss : 0.051708, loss_ce: 0.017063
2022-01-08 15:51:44,796 iteration 1641 : loss : 0.055296, loss_ce: 0.021759
2022-01-08 15:51:46,125 iteration 1642 : loss : 0.041113, loss_ce: 0.014494
2022-01-08 15:51:47,436 iteration 1643 : loss : 0.044584, loss_ce: 0.015003
2022-01-08 15:51:48,858 iteration 1644 : loss : 0.053189, loss_ce: 0.021328
2022-01-08 15:51:50,320 iteration 1645 : loss : 0.063977, loss_ce: 0.032491
2022-01-08 15:51:51,659 iteration 1646 : loss : 0.059672, loss_ce: 0.021399
2022-01-08 15:51:53,015 iteration 1647 : loss : 0.077679, loss_ce: 0.025962
2022-01-08 15:51:54,312 iteration 1648 : loss : 0.037670, loss_ce: 0.016028
2022-01-08 15:51:55,622 iteration 1649 : loss : 0.040560, loss_ce: 0.016198

 24%|███████▎                      | 97/400 [41:49<2:06:47, 25.11s/it]2022-01-08 15:51:57,164 iteration 1650 : loss : 0.082767, loss_ce: 0.049583
2022-01-08 15:51:58,521 iteration 1651 : loss : 0.052026, loss_ce: 0.014434
2022-01-08 15:51:59,908 iteration 1652 : loss : 0.096301, loss_ce: 0.028633
2022-01-08 15:52:01,252 iteration 1653 : loss : 0.047350, loss_ce: 0.015302
2022-01-08 15:52:02,610 iteration 1654 : loss : 0.050562, loss_ce: 0.016401
2022-01-08 15:52:03,935 iteration 1655 : loss : 0.047955, loss_ce: 0.018136
2022-01-08 15:52:05,345 iteration 1656 : loss : 0.047015, loss_ce: 0.019567
2022-01-08 15:52:06,707 iteration 1657 : loss : 0.034403, loss_ce: 0.014357
2022-01-08 15:52:08,129 iteration 1658 : loss : 0.067963, loss_ce: 0.039559
2022-01-08 15:52:09,580 iteration 1659 : loss : 0.057077, loss_ce: 0.026287
2022-01-08 15:52:10,969 iteration 1660 : loss : 0.037810, loss_ce: 0.015183
2022-01-08 15:52:12,290 iteration 1661 : loss : 0.049895, loss_ce: 0.019174
2022-01-08 15:52:13,702 iteration 1662 : loss : 0.054204, loss_ce: 0.021274
2022-01-08 15:52:15,136 iteration 1663 : loss : 0.042117, loss_ce: 0.019570
2022-01-08 15:52:16,514 iteration 1664 : loss : 0.050219, loss_ce: 0.017392
2022-01-08 15:52:17,873 iteration 1665 : loss : 0.052840, loss_ce: 0.026175
2022-01-08 15:52:19,261 iteration 1666 : loss : 0.053700, loss_ce: 0.018324

 24%|███████▎                      | 98/400 [42:13<2:04:08, 24.66s/it]2022-01-08 15:52:20,642 iteration 1667 : loss : 0.040730, loss_ce: 0.019277
2022-01-08 15:52:22,090 iteration 1668 : loss : 0.048768, loss_ce: 0.015091
2022-01-08 15:52:23,503 iteration 1669 : loss : 0.045733, loss_ce: 0.015430
2022-01-08 15:52:24,810 iteration 1670 : loss : 0.033298, loss_ce: 0.011096
2022-01-08 15:52:26,130 iteration 1671 : loss : 0.046011, loss_ce: 0.021055
2022-01-08 15:52:27,564 iteration 1672 : loss : 0.077152, loss_ce: 0.028439
2022-01-08 15:52:28,974 iteration 1673 : loss : 0.040367, loss_ce: 0.012628
2022-01-08 15:52:30,438 iteration 1674 : loss : 0.057122, loss_ce: 0.023366
2022-01-08 15:52:31,788 iteration 1675 : loss : 0.071845, loss_ce: 0.024110
2022-01-08 15:52:33,223 iteration 1676 : loss : 0.047541, loss_ce: 0.022454
2022-01-08 15:52:34,619 iteration 1677 : loss : 0.108717, loss_ce: 0.033891
2022-01-08 15:52:36,037 iteration 1678 : loss : 0.049494, loss_ce: 0.023634
2022-01-08 15:52:37,397 iteration 1679 : loss : 0.083870, loss_ce: 0.045156
2022-01-08 15:52:38,797 iteration 1680 : loss : 0.044425, loss_ce: 0.020709
2022-01-08 15:52:40,158 iteration 1681 : loss : 0.057022, loss_ce: 0.020443
2022-01-08 15:52:41,532 iteration 1682 : loss : 0.061696, loss_ce: 0.028992
2022-01-08 15:52:42,877 iteration 1683 : loss : 0.055175, loss_ce: 0.026253

 25%|███████▍                      | 99/400 [42:37<2:02:10, 24.35s/it]2022-01-08 15:52:44,340 iteration 1684 : loss : 0.062699, loss_ce: 0.025549
2022-01-08 15:52:45,680 iteration 1685 : loss : 0.043789, loss_ce: 0.021513
2022-01-08 15:52:46,988 iteration 1686 : loss : 0.045083, loss_ce: 0.018778
2022-01-08 15:52:48,333 iteration 1687 : loss : 0.037512, loss_ce: 0.015800
2022-01-08 15:52:49,716 iteration 1688 : loss : 0.053626, loss_ce: 0.025544
2022-01-08 15:52:51,053 iteration 1689 : loss : 0.045335, loss_ce: 0.016792
2022-01-08 15:52:52,448 iteration 1690 : loss : 0.066928, loss_ce: 0.027256
2022-01-08 15:52:53,810 iteration 1691 : loss : 0.041503, loss_ce: 0.018603
2022-01-08 15:52:55,230 iteration 1692 : loss : 0.061738, loss_ce: 0.021384
2022-01-08 15:52:56,667 iteration 1693 : loss : 0.054581, loss_ce: 0.027489
2022-01-08 15:52:58,073 iteration 1694 : loss : 0.040650, loss_ce: 0.015668
2022-01-08 15:52:59,377 iteration 1695 : loss : 0.045522, loss_ce: 0.015282
2022-01-08 15:53:00,734 iteration 1696 : loss : 0.072660, loss_ce: 0.028590
2022-01-08 15:53:02,150 iteration 1697 : loss : 0.058108, loss_ce: 0.016831
2022-01-08 15:53:03,510 iteration 1698 : loss : 0.037924, loss_ce: 0.011976
2022-01-08 15:53:04,787 iteration 1699 : loss : 0.042177, loss_ce: 0.019615
2022-01-08 15:53:04,788 Training Data Eval:
2022-01-08 15:53:11,633   Average segmentation loss on training set: 0.0339
2022-01-08 15:53:11,633 Validation Data Eval:
2022-01-08 15:53:14,001   Average segmentation loss on validation set: 0.0988
2022-01-08 15:53:15,388 iteration 1700 : loss : 0.059638, loss_ce: 0.018742

 25%|███████▎                     | 100/400 [43:09<2:13:59, 26.80s/it]2022-01-08 15:53:16,851 iteration 1701 : loss : 0.048327, loss_ce: 0.023154
2022-01-08 15:53:18,234 iteration 1702 : loss : 0.044150, loss_ce: 0.017985
2022-01-08 15:53:19,553 iteration 1703 : loss : 0.041054, loss_ce: 0.017879
2022-01-08 15:53:20,999 iteration 1704 : loss : 0.039181, loss_ce: 0.015746
2022-01-08 15:53:22,373 iteration 1705 : loss : 0.042264, loss_ce: 0.019281
2022-01-08 15:53:23,760 iteration 1706 : loss : 0.043171, loss_ce: 0.021152
2022-01-08 15:53:25,128 iteration 1707 : loss : 0.048873, loss_ce: 0.016361
2022-01-08 15:53:26,533 iteration 1708 : loss : 0.045453, loss_ce: 0.014859
2022-01-08 15:53:27,843 iteration 1709 : loss : 0.036932, loss_ce: 0.015682
2022-01-08 15:53:29,135 iteration 1710 : loss : 0.043639, loss_ce: 0.018331
2022-01-08 15:53:30,513 iteration 1711 : loss : 0.048542, loss_ce: 0.016685
2022-01-08 15:53:31,834 iteration 1712 : loss : 0.041446, loss_ce: 0.014853
2022-01-08 15:53:33,148 iteration 1713 : loss : 0.041057, loss_ce: 0.014345
2022-01-08 15:53:34,597 iteration 1714 : loss : 0.066794, loss_ce: 0.020667
2022-01-08 15:53:36,002 iteration 1715 : loss : 0.056215, loss_ce: 0.015828
2022-01-08 15:53:37,447 iteration 1716 : loss : 0.060495, loss_ce: 0.019903
2022-01-08 15:53:38,820 iteration 1717 : loss : 0.053013, loss_ce: 0.021684

 25%|███████▎                     | 101/400 [43:33<2:08:31, 25.79s/it]2022-01-08 15:53:40,225 iteration 1718 : loss : 0.048818, loss_ce: 0.015963
2022-01-08 15:53:41,617 iteration 1719 : loss : 0.056241, loss_ce: 0.025044
2022-01-08 15:53:42,900 iteration 1720 : loss : 0.034551, loss_ce: 0.011455
2022-01-08 15:53:44,263 iteration 1721 : loss : 0.051116, loss_ce: 0.022672
2022-01-08 15:53:45,684 iteration 1722 : loss : 0.057654, loss_ce: 0.017918
2022-01-08 15:53:47,052 iteration 1723 : loss : 0.069687, loss_ce: 0.027587
2022-01-08 15:53:48,455 iteration 1724 : loss : 0.040894, loss_ce: 0.013569
2022-01-08 15:53:49,939 iteration 1725 : loss : 0.061334, loss_ce: 0.020417
2022-01-08 15:53:51,388 iteration 1726 : loss : 0.073035, loss_ce: 0.023108
2022-01-08 15:53:52,775 iteration 1727 : loss : 0.037887, loss_ce: 0.018698
2022-01-08 15:53:54,138 iteration 1728 : loss : 0.050691, loss_ce: 0.017751
2022-01-08 15:53:55,502 iteration 1729 : loss : 0.045038, loss_ce: 0.018441
2022-01-08 15:53:56,893 iteration 1730 : loss : 0.043764, loss_ce: 0.017193
2022-01-08 15:53:58,330 iteration 1731 : loss : 0.052116, loss_ce: 0.018969
2022-01-08 15:53:59,708 iteration 1732 : loss : 0.041895, loss_ce: 0.019534
2022-01-08 15:54:01,156 iteration 1733 : loss : 0.039702, loss_ce: 0.015203
2022-01-08 15:54:02,492 iteration 1734 : loss : 0.035308, loss_ce: 0.012266

 26%|███████▍                     | 102/400 [43:56<2:04:55, 25.15s/it]2022-01-08 15:54:03,883 iteration 1735 : loss : 0.061174, loss_ce: 0.020722
2022-01-08 15:54:05,245 iteration 1736 : loss : 0.034461, loss_ce: 0.013142
2022-01-08 15:54:06,636 iteration 1737 : loss : 0.037926, loss_ce: 0.014943
2022-01-08 15:54:07,996 iteration 1738 : loss : 0.054146, loss_ce: 0.017664
2022-01-08 15:54:09,481 iteration 1739 : loss : 0.055606, loss_ce: 0.023329
2022-01-08 15:54:10,918 iteration 1740 : loss : 0.054579, loss_ce: 0.019844
2022-01-08 15:54:12,301 iteration 1741 : loss : 0.044494, loss_ce: 0.014578
2022-01-08 15:54:13,804 iteration 1742 : loss : 0.047751, loss_ce: 0.020986
2022-01-08 15:54:15,183 iteration 1743 : loss : 0.050346, loss_ce: 0.016718
2022-01-08 15:54:16,602 iteration 1744 : loss : 0.033824, loss_ce: 0.012734
2022-01-08 15:54:18,143 iteration 1745 : loss : 0.044487, loss_ce: 0.022862
2022-01-08 15:54:19,526 iteration 1746 : loss : 0.033430, loss_ce: 0.013079
2022-01-08 15:54:20,878 iteration 1747 : loss : 0.036996, loss_ce: 0.015769
2022-01-08 15:54:22,259 iteration 1748 : loss : 0.035057, loss_ce: 0.013786
2022-01-08 15:54:23,636 iteration 1749 : loss : 0.042708, loss_ce: 0.013684
2022-01-08 15:54:24,962 iteration 1750 : loss : 0.043814, loss_ce: 0.019553
2022-01-08 15:54:26,424 iteration 1751 : loss : 0.033983, loss_ce: 0.011856

 26%|███████▍                     | 103/400 [44:20<2:02:41, 24.79s/it]2022-01-08 15:54:27,832 iteration 1752 : loss : 0.042875, loss_ce: 0.015463
2022-01-08 15:54:29,170 iteration 1753 : loss : 0.039364, loss_ce: 0.018181
2022-01-08 15:54:30,524 iteration 1754 : loss : 0.035800, loss_ce: 0.013477
2022-01-08 15:54:31,893 iteration 1755 : loss : 0.040759, loss_ce: 0.016571
2022-01-08 15:54:33,316 iteration 1756 : loss : 0.060223, loss_ce: 0.026284
2022-01-08 15:54:34,756 iteration 1757 : loss : 0.063991, loss_ce: 0.027801
2022-01-08 15:54:36,178 iteration 1758 : loss : 0.053633, loss_ce: 0.022139
2022-01-08 15:54:37,487 iteration 1759 : loss : 0.078103, loss_ce: 0.024445
2022-01-08 15:54:38,849 iteration 1760 : loss : 0.045224, loss_ce: 0.017970
2022-01-08 15:54:40,186 iteration 1761 : loss : 0.037735, loss_ce: 0.014878
2022-01-08 15:54:41,554 iteration 1762 : loss : 0.050842, loss_ce: 0.017999
2022-01-08 15:54:42,851 iteration 1763 : loss : 0.054186, loss_ce: 0.022463
2022-01-08 15:54:44,312 iteration 1764 : loss : 0.032156, loss_ce: 0.009198
2022-01-08 15:54:45,692 iteration 1765 : loss : 0.060696, loss_ce: 0.021675
2022-01-08 15:54:47,127 iteration 1766 : loss : 0.047999, loss_ce: 0.018881
2022-01-08 15:54:48,527 iteration 1767 : loss : 0.035317, loss_ce: 0.014336
2022-01-08 15:54:49,894 iteration 1768 : loss : 0.075333, loss_ce: 0.030782

 26%|███████▌                     | 104/400 [44:44<2:00:20, 24.39s/it]2022-01-08 15:54:51,363 iteration 1769 : loss : 0.042671, loss_ce: 0.015918
2022-01-08 15:54:52,724 iteration 1770 : loss : 0.036956, loss_ce: 0.012581
2022-01-08 15:54:54,059 iteration 1771 : loss : 0.026786, loss_ce: 0.008823
2022-01-08 15:54:55,488 iteration 1772 : loss : 0.048941, loss_ce: 0.021118
2022-01-08 15:54:56,883 iteration 1773 : loss : 0.047263, loss_ce: 0.019969
2022-01-08 15:54:58,230 iteration 1774 : loss : 0.051999, loss_ce: 0.017576
2022-01-08 15:54:59,585 iteration 1775 : loss : 0.045854, loss_ce: 0.015710
2022-01-08 15:55:00,930 iteration 1776 : loss : 0.055240, loss_ce: 0.019345
2022-01-08 15:55:02,254 iteration 1777 : loss : 0.033270, loss_ce: 0.013158
2022-01-08 15:55:03,669 iteration 1778 : loss : 0.048700, loss_ce: 0.021281
2022-01-08 15:55:05,046 iteration 1779 : loss : 0.045879, loss_ce: 0.020363
2022-01-08 15:55:06,445 iteration 1780 : loss : 0.060448, loss_ce: 0.018075
2022-01-08 15:55:07,843 iteration 1781 : loss : 0.049091, loss_ce: 0.016111
2022-01-08 15:55:09,148 iteration 1782 : loss : 0.092831, loss_ce: 0.021796
2022-01-08 15:55:10,488 iteration 1783 : loss : 0.053134, loss_ce: 0.021359
2022-01-08 15:55:11,883 iteration 1784 : loss : 0.055496, loss_ce: 0.026696
2022-01-08 15:55:11,883 Training Data Eval:
2022-01-08 15:55:18,723   Average segmentation loss on training set: 0.0324
2022-01-08 15:55:18,723 Validation Data Eval:
2022-01-08 15:55:21,085   Average segmentation loss on validation set: 0.0945
2022-01-08 15:55:22,453 iteration 1785 : loss : 0.047906, loss_ce: 0.023404

 26%|███████▌                     | 105/400 [45:16<2:11:58, 26.84s/it]2022-01-08 15:55:23,926 iteration 1786 : loss : 0.053327, loss_ce: 0.018303
2022-01-08 15:55:25,249 iteration 1787 : loss : 0.038204, loss_ce: 0.009563
2022-01-08 15:55:26,632 iteration 1788 : loss : 0.040958, loss_ce: 0.014604
2022-01-08 15:55:28,024 iteration 1789 : loss : 0.044658, loss_ce: 0.021517
2022-01-08 15:55:29,535 iteration 1790 : loss : 0.037120, loss_ce: 0.010814
2022-01-08 15:55:30,932 iteration 1791 : loss : 0.047709, loss_ce: 0.020139
2022-01-08 15:55:32,333 iteration 1792 : loss : 0.044205, loss_ce: 0.017369
2022-01-08 15:55:33,742 iteration 1793 : loss : 0.055453, loss_ce: 0.021554
2022-01-08 15:55:35,109 iteration 1794 : loss : 0.046425, loss_ce: 0.024333
2022-01-08 15:55:36,396 iteration 1795 : loss : 0.032739, loss_ce: 0.012592
2022-01-08 15:55:37,834 iteration 1796 : loss : 0.043205, loss_ce: 0.019414
2022-01-08 15:55:39,164 iteration 1797 : loss : 0.047814, loss_ce: 0.019654
2022-01-08 15:55:40,549 iteration 1798 : loss : 0.051792, loss_ce: 0.017331
2022-01-08 15:55:41,986 iteration 1799 : loss : 0.046636, loss_ce: 0.017869
2022-01-08 15:55:43,313 iteration 1800 : loss : 0.038628, loss_ce: 0.012962
2022-01-08 15:55:44,691 iteration 1801 : loss : 0.057513, loss_ce: 0.019723
2022-01-08 15:55:46,111 iteration 1802 : loss : 0.051920, loss_ce: 0.020683

 26%|███████▋                     | 106/400 [45:40<2:06:49, 25.88s/it]2022-01-08 15:55:47,586 iteration 1803 : loss : 0.054378, loss_ce: 0.023487
2022-01-08 15:55:48,903 iteration 1804 : loss : 0.060761, loss_ce: 0.023368
2022-01-08 15:55:50,398 iteration 1805 : loss : 0.054475, loss_ce: 0.018954
2022-01-08 15:55:51,855 iteration 1806 : loss : 0.048274, loss_ce: 0.024052
2022-01-08 15:55:53,229 iteration 1807 : loss : 0.054816, loss_ce: 0.026388
2022-01-08 15:55:54,643 iteration 1808 : loss : 0.043201, loss_ce: 0.018083
2022-01-08 15:55:56,001 iteration 1809 : loss : 0.041621, loss_ce: 0.018397
2022-01-08 15:55:57,408 iteration 1810 : loss : 0.051828, loss_ce: 0.024469
2022-01-08 15:55:58,767 iteration 1811 : loss : 0.040876, loss_ce: 0.013227
2022-01-08 15:56:00,120 iteration 1812 : loss : 0.034258, loss_ce: 0.010959
2022-01-08 15:56:01,500 iteration 1813 : loss : 0.040765, loss_ce: 0.018252
2022-01-08 15:56:02,856 iteration 1814 : loss : 0.038616, loss_ce: 0.014712
2022-01-08 15:56:04,306 iteration 1815 : loss : 0.064818, loss_ce: 0.022492
2022-01-08 15:56:05,699 iteration 1816 : loss : 0.032449, loss_ce: 0.013091
2022-01-08 15:56:07,154 iteration 1817 : loss : 0.056230, loss_ce: 0.025675
2022-01-08 15:56:08,485 iteration 1818 : loss : 0.031033, loss_ce: 0.010795
2022-01-08 15:56:09,909 iteration 1819 : loss : 0.059994, loss_ce: 0.023220

 27%|███████▊                     | 107/400 [46:04<2:03:21, 25.26s/it]2022-01-08 15:56:11,244 iteration 1820 : loss : 0.033834, loss_ce: 0.014670
2022-01-08 15:56:12,723 iteration 1821 : loss : 0.039884, loss_ce: 0.013599
2022-01-08 15:56:14,152 iteration 1822 : loss : 0.070386, loss_ce: 0.034725
2022-01-08 15:56:15,605 iteration 1823 : loss : 0.045041, loss_ce: 0.015777
2022-01-08 15:56:17,014 iteration 1824 : loss : 0.059875, loss_ce: 0.016079
2022-01-08 15:56:18,350 iteration 1825 : loss : 0.032390, loss_ce: 0.012484
2022-01-08 15:56:19,794 iteration 1826 : loss : 0.039101, loss_ce: 0.013292
2022-01-08 15:56:21,129 iteration 1827 : loss : 0.038956, loss_ce: 0.016426
2022-01-08 15:56:22,516 iteration 1828 : loss : 0.036272, loss_ce: 0.014296
2022-01-08 15:56:23,862 iteration 1829 : loss : 0.045401, loss_ce: 0.021801
2022-01-08 15:56:25,321 iteration 1830 : loss : 0.057693, loss_ce: 0.023179
2022-01-08 15:56:26,714 iteration 1831 : loss : 0.045113, loss_ce: 0.019502
2022-01-08 15:56:28,067 iteration 1832 : loss : 0.050747, loss_ce: 0.020238
2022-01-08 15:56:29,390 iteration 1833 : loss : 0.037764, loss_ce: 0.016914
2022-01-08 15:56:30,758 iteration 1834 : loss : 0.042230, loss_ce: 0.014213
2022-01-08 15:56:32,139 iteration 1835 : loss : 0.038195, loss_ce: 0.013739
2022-01-08 15:56:33,480 iteration 1836 : loss : 0.040236, loss_ce: 0.012847

 27%|███████▊                     | 108/400 [46:27<2:00:28, 24.75s/it]2022-01-08 15:56:34,954 iteration 1837 : loss : 0.036650, loss_ce: 0.012508
2022-01-08 15:56:36,258 iteration 1838 : loss : 0.042266, loss_ce: 0.018947
2022-01-08 15:56:37,596 iteration 1839 : loss : 0.049720, loss_ce: 0.019111
2022-01-08 15:56:38,988 iteration 1840 : loss : 0.050604, loss_ce: 0.022735
2022-01-08 15:56:40,310 iteration 1841 : loss : 0.058814, loss_ce: 0.029362
2022-01-08 15:56:41,669 iteration 1842 : loss : 0.034279, loss_ce: 0.010322
2022-01-08 15:56:43,064 iteration 1843 : loss : 0.031478, loss_ce: 0.014816
2022-01-08 15:56:44,427 iteration 1844 : loss : 0.052289, loss_ce: 0.016298
2022-01-08 15:56:45,776 iteration 1845 : loss : 0.031448, loss_ce: 0.009904
2022-01-08 15:56:47,221 iteration 1846 : loss : 0.042017, loss_ce: 0.017070
2022-01-08 15:56:48,563 iteration 1847 : loss : 0.035407, loss_ce: 0.012766
2022-01-08 15:56:49,930 iteration 1848 : loss : 0.045951, loss_ce: 0.017894
2022-01-08 15:56:51,274 iteration 1849 : loss : 0.054367, loss_ce: 0.028808
2022-01-08 15:56:52,767 iteration 1850 : loss : 0.068620, loss_ce: 0.027668
2022-01-08 15:56:54,141 iteration 1851 : loss : 0.068298, loss_ce: 0.020727
2022-01-08 15:56:55,539 iteration 1852 : loss : 0.038207, loss_ce: 0.015972
2022-01-08 15:56:56,890 iteration 1853 : loss : 0.045610, loss_ce: 0.018835

 27%|███████▉                     | 109/400 [46:51<1:58:06, 24.35s/it]2022-01-08 15:56:58,300 iteration 1854 : loss : 0.041853, loss_ce: 0.014640
2022-01-08 15:56:59,727 iteration 1855 : loss : 0.052560, loss_ce: 0.022313
2022-01-08 15:57:01,159 iteration 1856 : loss : 0.057555, loss_ce: 0.017802
2022-01-08 15:57:02,606 iteration 1857 : loss : 0.034535, loss_ce: 0.013513
2022-01-08 15:57:04,000 iteration 1858 : loss : 0.045583, loss_ce: 0.019297
2022-01-08 15:57:05,400 iteration 1859 : loss : 0.046349, loss_ce: 0.018335
2022-01-08 15:57:06,743 iteration 1860 : loss : 0.045728, loss_ce: 0.013763
2022-01-08 15:57:08,183 iteration 1861 : loss : 0.045366, loss_ce: 0.016301
2022-01-08 15:57:09,519 iteration 1862 : loss : 0.036484, loss_ce: 0.017551
2022-01-08 15:57:10,897 iteration 1863 : loss : 0.049848, loss_ce: 0.021850
2022-01-08 15:57:12,305 iteration 1864 : loss : 0.057705, loss_ce: 0.015402
2022-01-08 15:57:13,598 iteration 1865 : loss : 0.037340, loss_ce: 0.016446
2022-01-08 15:57:15,040 iteration 1866 : loss : 0.031882, loss_ce: 0.015434
2022-01-08 15:57:16,423 iteration 1867 : loss : 0.031170, loss_ce: 0.012578
2022-01-08 15:57:17,766 iteration 1868 : loss : 0.047087, loss_ce: 0.019458
2022-01-08 15:57:19,103 iteration 1869 : loss : 0.066609, loss_ce: 0.020574
2022-01-08 15:57:19,103 Training Data Eval:
2022-01-08 15:57:25,948   Average segmentation loss on training set: 0.0421
2022-01-08 15:57:25,948 Validation Data Eval:
2022-01-08 15:57:28,316   Average segmentation loss on validation set: 0.0821
2022-01-08 15:57:29,728 iteration 1870 : loss : 0.042729, loss_ce: 0.015501

 28%|███████▉                     | 110/400 [47:23<2:10:00, 26.90s/it]2022-01-08 15:57:31,207 iteration 1871 : loss : 0.036169, loss_ce: 0.013787
2022-01-08 15:57:32,687 iteration 1872 : loss : 0.052011, loss_ce: 0.017637
2022-01-08 15:57:34,017 iteration 1873 : loss : 0.038067, loss_ce: 0.015973
2022-01-08 15:57:35,459 iteration 1874 : loss : 0.057472, loss_ce: 0.030886
2022-01-08 15:57:36,755 iteration 1875 : loss : 0.034708, loss_ce: 0.013550
2022-01-08 15:57:38,202 iteration 1876 : loss : 0.032526, loss_ce: 0.008923
2022-01-08 15:57:39,623 iteration 1877 : loss : 0.073997, loss_ce: 0.035110
2022-01-08 15:57:40,975 iteration 1878 : loss : 0.041247, loss_ce: 0.018594
2022-01-08 15:57:42,321 iteration 1879 : loss : 0.040388, loss_ce: 0.015493
2022-01-08 15:57:43,661 iteration 1880 : loss : 0.044513, loss_ce: 0.021429
2022-01-08 15:57:45,039 iteration 1881 : loss : 0.043763, loss_ce: 0.015169
2022-01-08 15:57:46,369 iteration 1882 : loss : 0.070171, loss_ce: 0.029739
2022-01-08 15:57:47,663 iteration 1883 : loss : 0.053194, loss_ce: 0.018673
2022-01-08 15:57:49,068 iteration 1884 : loss : 0.046836, loss_ce: 0.018328
2022-01-08 15:57:50,361 iteration 1885 : loss : 0.035040, loss_ce: 0.014099
2022-01-08 15:57:51,813 iteration 1886 : loss : 0.040457, loss_ce: 0.017352
2022-01-08 15:57:53,257 iteration 1887 : loss : 0.047671, loss_ce: 0.020272

 28%|████████                     | 111/400 [47:47<2:04:40, 25.88s/it]2022-01-08 15:57:54,675 iteration 1888 : loss : 0.041459, loss_ce: 0.018086
2022-01-08 15:57:56,110 iteration 1889 : loss : 0.038775, loss_ce: 0.016577
2022-01-08 15:57:57,525 iteration 1890 : loss : 0.045114, loss_ce: 0.018028
2022-01-08 15:57:58,945 iteration 1891 : loss : 0.044009, loss_ce: 0.015588
2022-01-08 15:58:00,339 iteration 1892 : loss : 0.041232, loss_ce: 0.018128
2022-01-08 15:58:01,738 iteration 1893 : loss : 0.060547, loss_ce: 0.037846
2022-01-08 15:58:03,109 iteration 1894 : loss : 0.043229, loss_ce: 0.018320
2022-01-08 15:58:04,473 iteration 1895 : loss : 0.042662, loss_ce: 0.012853
2022-01-08 15:58:05,964 iteration 1896 : loss : 0.050631, loss_ce: 0.024329
2022-01-08 15:58:07,330 iteration 1897 : loss : 0.057593, loss_ce: 0.018062
2022-01-08 15:58:08,762 iteration 1898 : loss : 0.035163, loss_ce: 0.012745
2022-01-08 15:58:10,135 iteration 1899 : loss : 0.042832, loss_ce: 0.020741
2022-01-08 15:58:11,440 iteration 1900 : loss : 0.035765, loss_ce: 0.015732
2022-01-08 15:58:12,814 iteration 1901 : loss : 0.043539, loss_ce: 0.017356
2022-01-08 15:58:14,215 iteration 1902 : loss : 0.046962, loss_ce: 0.022964
2022-01-08 15:58:15,639 iteration 1903 : loss : 0.056849, loss_ce: 0.020514
2022-01-08 15:58:17,117 iteration 1904 : loss : 0.059335, loss_ce: 0.021963

 28%|████████                     | 112/400 [48:11<2:01:19, 25.28s/it]2022-01-08 15:58:18,507 iteration 1905 : loss : 0.038864, loss_ce: 0.017039
2022-01-08 15:58:19,939 iteration 1906 : loss : 0.037139, loss_ce: 0.012659
2022-01-08 15:58:21,427 iteration 1907 : loss : 0.037527, loss_ce: 0.015075
2022-01-08 15:58:22,843 iteration 1908 : loss : 0.046606, loss_ce: 0.020552
2022-01-08 15:58:24,286 iteration 1909 : loss : 0.040320, loss_ce: 0.020258
2022-01-08 15:58:25,720 iteration 1910 : loss : 0.044364, loss_ce: 0.022997
2022-01-08 15:58:27,219 iteration 1911 : loss : 0.034506, loss_ce: 0.013884
2022-01-08 15:58:28,645 iteration 1912 : loss : 0.050629, loss_ce: 0.013690
2022-01-08 15:58:30,020 iteration 1913 : loss : 0.042048, loss_ce: 0.015464
2022-01-08 15:58:31,359 iteration 1914 : loss : 0.040195, loss_ce: 0.018680
2022-01-08 15:58:32,743 iteration 1915 : loss : 0.050212, loss_ce: 0.017502
2022-01-08 15:58:34,119 iteration 1916 : loss : 0.044888, loss_ce: 0.019202
2022-01-08 15:58:35,527 iteration 1917 : loss : 0.049602, loss_ce: 0.019216
2022-01-08 15:58:36,865 iteration 1918 : loss : 0.053078, loss_ce: 0.022757
2022-01-08 15:58:38,229 iteration 1919 : loss : 0.039826, loss_ce: 0.018553
2022-01-08 15:58:39,598 iteration 1920 : loss : 0.034533, loss_ce: 0.012260
2022-01-08 15:58:41,011 iteration 1921 : loss : 0.053922, loss_ce: 0.023194

 28%|████████▏                    | 113/400 [48:35<1:58:55, 24.86s/it]2022-01-08 15:58:42,397 iteration 1922 : loss : 0.060336, loss_ce: 0.022503
2022-01-08 15:58:43,703 iteration 1923 : loss : 0.024502, loss_ce: 0.010256
2022-01-08 15:58:45,103 iteration 1924 : loss : 0.069409, loss_ce: 0.035015
2022-01-08 15:58:46,429 iteration 1925 : loss : 0.048492, loss_ce: 0.020932
2022-01-08 15:58:47,771 iteration 1926 : loss : 0.033004, loss_ce: 0.013642
2022-01-08 15:58:49,183 iteration 1927 : loss : 0.050667, loss_ce: 0.018279
2022-01-08 15:58:50,605 iteration 1928 : loss : 0.035384, loss_ce: 0.014000
2022-01-08 15:58:51,953 iteration 1929 : loss : 0.036509, loss_ce: 0.016855
2022-01-08 15:58:53,331 iteration 1930 : loss : 0.064385, loss_ce: 0.024191
2022-01-08 15:58:54,681 iteration 1931 : loss : 0.051436, loss_ce: 0.015325
2022-01-08 15:58:56,053 iteration 1932 : loss : 0.050435, loss_ce: 0.015327
2022-01-08 15:58:57,431 iteration 1933 : loss : 0.044115, loss_ce: 0.016039
2022-01-08 15:58:58,691 iteration 1934 : loss : 0.030764, loss_ce: 0.013335
2022-01-08 15:59:00,036 iteration 1935 : loss : 0.046843, loss_ce: 0.022436
2022-01-08 15:59:01,453 iteration 1936 : loss : 0.038889, loss_ce: 0.014398
2022-01-08 15:59:02,854 iteration 1937 : loss : 0.040016, loss_ce: 0.016309
2022-01-08 15:59:04,261 iteration 1938 : loss : 0.044569, loss_ce: 0.013819

 28%|████████▎                    | 114/400 [48:58<1:56:12, 24.38s/it]2022-01-08 15:59:05,629 iteration 1939 : loss : 0.033506, loss_ce: 0.016213
2022-01-08 15:59:06,980 iteration 1940 : loss : 0.028183, loss_ce: 0.011062
2022-01-08 15:59:08,402 iteration 1941 : loss : 0.041864, loss_ce: 0.017780
2022-01-08 15:59:09,809 iteration 1942 : loss : 0.050910, loss_ce: 0.016864
2022-01-08 15:59:11,110 iteration 1943 : loss : 0.044133, loss_ce: 0.014258
2022-01-08 15:59:12,450 iteration 1944 : loss : 0.042103, loss_ce: 0.016009
2022-01-08 15:59:13,805 iteration 1945 : loss : 0.036861, loss_ce: 0.018582
2022-01-08 15:59:15,165 iteration 1946 : loss : 0.048361, loss_ce: 0.018895
2022-01-08 15:59:16,514 iteration 1947 : loss : 0.052474, loss_ce: 0.020274
2022-01-08 15:59:17,858 iteration 1948 : loss : 0.035833, loss_ce: 0.015187
2022-01-08 15:59:19,157 iteration 1949 : loss : 0.032861, loss_ce: 0.016821
2022-01-08 15:59:20,562 iteration 1950 : loss : 0.046945, loss_ce: 0.019110
2022-01-08 15:59:22,035 iteration 1951 : loss : 0.047058, loss_ce: 0.017029
2022-01-08 15:59:23,360 iteration 1952 : loss : 0.040374, loss_ce: 0.011483
2022-01-08 15:59:24,750 iteration 1953 : loss : 0.049878, loss_ce: 0.027524
2022-01-08 15:59:26,196 iteration 1954 : loss : 0.054466, loss_ce: 0.020475
2022-01-08 15:59:26,196 Training Data Eval:
2022-01-08 15:59:33,045   Average segmentation loss on training set: 0.0293
2022-01-08 15:59:33,045 Validation Data Eval:
2022-01-08 15:59:35,414   Average segmentation loss on validation set: 0.0705
2022-01-08 15:59:41,173 Found new lowest validation loss at iteration 1954! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_KEYS_best_val_loss_seed1234.pth
2022-01-08 15:59:42,598 iteration 1955 : loss : 0.030943, loss_ce: 0.012087

 29%|████████▎                    | 115/400 [49:36<2:15:41, 28.57s/it]2022-01-08 15:59:44,076 iteration 1956 : loss : 0.044832, loss_ce: 0.017782
2022-01-08 15:59:45,394 iteration 1957 : loss : 0.032961, loss_ce: 0.012827
2022-01-08 15:59:46,737 iteration 1958 : loss : 0.041711, loss_ce: 0.019928
2022-01-08 15:59:48,183 iteration 1959 : loss : 0.060878, loss_ce: 0.016101
2022-01-08 15:59:49,530 iteration 1960 : loss : 0.041832, loss_ce: 0.013032
2022-01-08 15:59:50,907 iteration 1961 : loss : 0.044807, loss_ce: 0.017356
2022-01-08 15:59:52,266 iteration 1962 : loss : 0.031486, loss_ce: 0.013535
2022-01-08 15:59:53,656 iteration 1963 : loss : 0.041931, loss_ce: 0.016856
2022-01-08 15:59:55,011 iteration 1964 : loss : 0.044243, loss_ce: 0.013371
2022-01-08 15:59:56,350 iteration 1965 : loss : 0.036430, loss_ce: 0.017387
2022-01-08 15:59:57,678 iteration 1966 : loss : 0.052620, loss_ce: 0.021878
2022-01-08 15:59:58,998 iteration 1967 : loss : 0.052407, loss_ce: 0.015351
2022-01-08 16:00:00,304 iteration 1968 : loss : 0.040771, loss_ce: 0.022794
2022-01-08 16:00:01,702 iteration 1969 : loss : 0.036500, loss_ce: 0.013826
2022-01-08 16:00:03,200 iteration 1970 : loss : 0.041455, loss_ce: 0.014850
2022-01-08 16:00:04,494 iteration 1971 : loss : 0.031823, loss_ce: 0.009676
2022-01-08 16:00:05,974 iteration 1972 : loss : 0.059707, loss_ce: 0.019586

 29%|████████▍                    | 116/400 [50:00<2:07:50, 27.01s/it]2022-01-08 16:00:07,328 iteration 1973 : loss : 0.029814, loss_ce: 0.011126
2022-01-08 16:00:08,633 iteration 1974 : loss : 0.039468, loss_ce: 0.016123
2022-01-08 16:00:10,072 iteration 1975 : loss : 0.044053, loss_ce: 0.016132
2022-01-08 16:00:11,368 iteration 1976 : loss : 0.047639, loss_ce: 0.019170
2022-01-08 16:00:12,817 iteration 1977 : loss : 0.057596, loss_ce: 0.023709
2022-01-08 16:00:14,154 iteration 1978 : loss : 0.049679, loss_ce: 0.020233
2022-01-08 16:00:15,508 iteration 1979 : loss : 0.042671, loss_ce: 0.021196
2022-01-08 16:00:16,918 iteration 1980 : loss : 0.046605, loss_ce: 0.018006
2022-01-08 16:00:18,243 iteration 1981 : loss : 0.035067, loss_ce: 0.013295
2022-01-08 16:00:19,667 iteration 1982 : loss : 0.039195, loss_ce: 0.013110
2022-01-08 16:00:21,128 iteration 1983 : loss : 0.041498, loss_ce: 0.017649
2022-01-08 16:00:22,470 iteration 1984 : loss : 0.036106, loss_ce: 0.010769
2022-01-08 16:00:23,818 iteration 1985 : loss : 0.045991, loss_ce: 0.016385
2022-01-08 16:00:25,150 iteration 1986 : loss : 0.043860, loss_ce: 0.016574
2022-01-08 16:00:26,477 iteration 1987 : loss : 0.029896, loss_ce: 0.011895
2022-01-08 16:00:27,928 iteration 1988 : loss : 0.033507, loss_ce: 0.014052
2022-01-08 16:00:29,298 iteration 1989 : loss : 0.038791, loss_ce: 0.016790

 29%|████████▍                    | 117/400 [50:23<2:02:09, 25.90s/it]2022-01-08 16:00:30,717 iteration 1990 : loss : 0.043889, loss_ce: 0.015898
2022-01-08 16:00:32,011 iteration 1991 : loss : 0.032153, loss_ce: 0.014230
2022-01-08 16:00:33,411 iteration 1992 : loss : 0.038115, loss_ce: 0.016611
2022-01-08 16:00:34,767 iteration 1993 : loss : 0.049763, loss_ce: 0.014481
2022-01-08 16:00:36,166 iteration 1994 : loss : 0.032559, loss_ce: 0.012661
2022-01-08 16:00:37,537 iteration 1995 : loss : 0.047868, loss_ce: 0.015828
2022-01-08 16:00:38,919 iteration 1996 : loss : 0.033348, loss_ce: 0.013944
2022-01-08 16:00:40,299 iteration 1997 : loss : 0.046528, loss_ce: 0.020472
2022-01-08 16:00:41,699 iteration 1998 : loss : 0.053414, loss_ce: 0.025472
2022-01-08 16:00:43,093 iteration 1999 : loss : 0.038208, loss_ce: 0.016506
2022-01-08 16:00:44,586 iteration 2000 : loss : 0.054283, loss_ce: 0.014633
2022-01-08 16:00:45,966 iteration 2001 : loss : 0.034873, loss_ce: 0.012999
2022-01-08 16:00:47,268 iteration 2002 : loss : 0.034979, loss_ce: 0.014690
2022-01-08 16:00:48,522 iteration 2003 : loss : 0.027254, loss_ce: 0.013138
2022-01-08 16:00:49,849 iteration 2004 : loss : 0.058922, loss_ce: 0.016861
2022-01-08 16:00:51,253 iteration 2005 : loss : 0.026645, loss_ce: 0.008817
2022-01-08 16:00:52,649 iteration 2006 : loss : 0.068447, loss_ce: 0.021286

 30%|████████▌                    | 118/400 [50:46<1:58:08, 25.14s/it]2022-01-08 16:00:54,137 iteration 2007 : loss : 0.059086, loss_ce: 0.019757
2022-01-08 16:00:55,627 iteration 2008 : loss : 0.054527, loss_ce: 0.016716
2022-01-08 16:00:57,005 iteration 2009 : loss : 0.044962, loss_ce: 0.016775
2022-01-08 16:00:58,410 iteration 2010 : loss : 0.040377, loss_ce: 0.017697
2022-01-08 16:00:59,867 iteration 2011 : loss : 0.052469, loss_ce: 0.019854
2022-01-08 16:01:01,250 iteration 2012 : loss : 0.039621, loss_ce: 0.019388
2022-01-08 16:01:02,554 iteration 2013 : loss : 0.033306, loss_ce: 0.013314
2022-01-08 16:01:03,906 iteration 2014 : loss : 0.038575, loss_ce: 0.011600
2022-01-08 16:01:05,318 iteration 2015 : loss : 0.035385, loss_ce: 0.014468
2022-01-08 16:01:06,679 iteration 2016 : loss : 0.054474, loss_ce: 0.016633
2022-01-08 16:01:08,094 iteration 2017 : loss : 0.028705, loss_ce: 0.008241
2022-01-08 16:01:09,573 iteration 2018 : loss : 0.047847, loss_ce: 0.020111
2022-01-08 16:01:10,939 iteration 2019 : loss : 0.045017, loss_ce: 0.014430
2022-01-08 16:01:12,283 iteration 2020 : loss : 0.031692, loss_ce: 0.011336
2022-01-08 16:01:13,679 iteration 2021 : loss : 0.046980, loss_ce: 0.016043
2022-01-08 16:01:15,080 iteration 2022 : loss : 0.043383, loss_ce: 0.021010
2022-01-08 16:01:16,519 iteration 2023 : loss : 0.051239, loss_ce: 0.019889

 30%|████████▋                    | 119/400 [51:10<1:55:56, 24.76s/it]2022-01-08 16:01:17,909 iteration 2024 : loss : 0.037361, loss_ce: 0.011802
2022-01-08 16:01:19,300 iteration 2025 : loss : 0.037493, loss_ce: 0.017802
2022-01-08 16:01:20,734 iteration 2026 : loss : 0.042820, loss_ce: 0.018414
2022-01-08 16:01:22,098 iteration 2027 : loss : 0.026504, loss_ce: 0.006999
2022-01-08 16:01:23,423 iteration 2028 : loss : 0.035550, loss_ce: 0.019436
2022-01-08 16:01:24,770 iteration 2029 : loss : 0.037505, loss_ce: 0.015405
2022-01-08 16:01:26,108 iteration 2030 : loss : 0.042664, loss_ce: 0.016421
2022-01-08 16:01:27,480 iteration 2031 : loss : 0.044491, loss_ce: 0.017163
2022-01-08 16:01:28,941 iteration 2032 : loss : 0.049886, loss_ce: 0.020678
2022-01-08 16:01:30,428 iteration 2033 : loss : 0.046083, loss_ce: 0.019883
2022-01-08 16:01:31,770 iteration 2034 : loss : 0.029507, loss_ce: 0.012206
2022-01-08 16:01:33,149 iteration 2035 : loss : 0.043278, loss_ce: 0.014863
2022-01-08 16:01:34,568 iteration 2036 : loss : 0.041869, loss_ce: 0.020310
2022-01-08 16:01:35,939 iteration 2037 : loss : 0.068531, loss_ce: 0.015189
2022-01-08 16:01:37,357 iteration 2038 : loss : 0.054252, loss_ce: 0.019132
2022-01-08 16:01:38,822 iteration 2039 : loss : 0.045848, loss_ce: 0.016307
2022-01-08 16:01:38,822 Training Data Eval:
2022-01-08 16:01:45,649   Average segmentation loss on training set: 0.0297
2022-01-08 16:01:45,650 Validation Data Eval:
2022-01-08 16:01:48,006   Average segmentation loss on validation set: 0.1048
2022-01-08 16:01:49,444 iteration 2040 : loss : 0.071452, loss_ce: 0.027153

 30%|████████▋                    | 120/400 [51:43<2:06:58, 27.21s/it]2022-01-08 16:01:50,921 iteration 2041 : loss : 0.047061, loss_ce: 0.010252
2022-01-08 16:01:52,273 iteration 2042 : loss : 0.039568, loss_ce: 0.014654
2022-01-08 16:01:53,628 iteration 2043 : loss : 0.030131, loss_ce: 0.010568
2022-01-08 16:01:54,997 iteration 2044 : loss : 0.067445, loss_ce: 0.029907
2022-01-08 16:01:56,338 iteration 2045 : loss : 0.036946, loss_ce: 0.011838
2022-01-08 16:01:57,723 iteration 2046 : loss : 0.038270, loss_ce: 0.017229
2022-01-08 16:01:59,074 iteration 2047 : loss : 0.035165, loss_ce: 0.014850
2022-01-08 16:02:00,455 iteration 2048 : loss : 0.034776, loss_ce: 0.014827
2022-01-08 16:02:01,803 iteration 2049 : loss : 0.061121, loss_ce: 0.017612
2022-01-08 16:02:03,193 iteration 2050 : loss : 0.057671, loss_ce: 0.025600
2022-01-08 16:02:04,581 iteration 2051 : loss : 0.042301, loss_ce: 0.018721
2022-01-08 16:02:05,903 iteration 2052 : loss : 0.062527, loss_ce: 0.028296
2022-01-08 16:02:07,290 iteration 2053 : loss : 0.053483, loss_ce: 0.016998
2022-01-08 16:02:08,639 iteration 2054 : loss : 0.033268, loss_ce: 0.013298
2022-01-08 16:02:09,999 iteration 2055 : loss : 0.059208, loss_ce: 0.018965
2022-01-08 16:02:11,411 iteration 2056 : loss : 0.039965, loss_ce: 0.017183
2022-01-08 16:02:12,743 iteration 2057 : loss : 0.041994, loss_ce: 0.016762

 30%|████████▊                    | 121/400 [52:06<2:01:03, 26.03s/it]2022-01-08 16:02:14,177 iteration 2058 : loss : 0.046095, loss_ce: 0.022729
2022-01-08 16:02:15,605 iteration 2059 : loss : 0.066776, loss_ce: 0.025907
2022-01-08 16:02:16,900 iteration 2060 : loss : 0.041378, loss_ce: 0.016289
2022-01-08 16:02:18,304 iteration 2061 : loss : 0.056307, loss_ce: 0.021705
2022-01-08 16:02:19,660 iteration 2062 : loss : 0.043496, loss_ce: 0.019110
2022-01-08 16:02:21,023 iteration 2063 : loss : 0.067093, loss_ce: 0.017418
2022-01-08 16:02:22,344 iteration 2064 : loss : 0.029945, loss_ce: 0.011323
2022-01-08 16:02:23,693 iteration 2065 : loss : 0.036718, loss_ce: 0.011964
2022-01-08 16:02:25,062 iteration 2066 : loss : 0.055591, loss_ce: 0.017665
2022-01-08 16:02:26,465 iteration 2067 : loss : 0.032786, loss_ce: 0.012128
2022-01-08 16:02:27,900 iteration 2068 : loss : 0.030536, loss_ce: 0.013131
2022-01-08 16:02:29,249 iteration 2069 : loss : 0.037201, loss_ce: 0.010515
2022-01-08 16:02:30,666 iteration 2070 : loss : 0.043821, loss_ce: 0.017966
2022-01-08 16:02:32,099 iteration 2071 : loss : 0.057542, loss_ce: 0.020971
2022-01-08 16:02:33,486 iteration 2072 : loss : 0.045630, loss_ce: 0.017747
2022-01-08 16:02:34,917 iteration 2073 : loss : 0.042849, loss_ce: 0.012556
2022-01-08 16:02:36,328 iteration 2074 : loss : 0.033660, loss_ce: 0.017127

 30%|████████▊                    | 122/400 [52:30<1:57:13, 25.30s/it]2022-01-08 16:02:37,737 iteration 2075 : loss : 0.040547, loss_ce: 0.016021
2022-01-08 16:02:39,121 iteration 2076 : loss : 0.028483, loss_ce: 0.007762
2022-01-08 16:02:40,523 iteration 2077 : loss : 0.033484, loss_ce: 0.013705
2022-01-08 16:02:42,022 iteration 2078 : loss : 0.044358, loss_ce: 0.013763
2022-01-08 16:02:43,379 iteration 2079 : loss : 0.050839, loss_ce: 0.016932
2022-01-08 16:02:44,809 iteration 2080 : loss : 0.037624, loss_ce: 0.014850
2022-01-08 16:02:46,140 iteration 2081 : loss : 0.039720, loss_ce: 0.015330
2022-01-08 16:02:47,416 iteration 2082 : loss : 0.025787, loss_ce: 0.009382
2022-01-08 16:02:48,773 iteration 2083 : loss : 0.056243, loss_ce: 0.030564
2022-01-08 16:02:50,132 iteration 2084 : loss : 0.054841, loss_ce: 0.027268
2022-01-08 16:02:51,457 iteration 2085 : loss : 0.042834, loss_ce: 0.013778
2022-01-08 16:02:52,822 iteration 2086 : loss : 0.045210, loss_ce: 0.019749
2022-01-08 16:02:54,158 iteration 2087 : loss : 0.043190, loss_ce: 0.018245
2022-01-08 16:02:55,596 iteration 2088 : loss : 0.036221, loss_ce: 0.014487
2022-01-08 16:02:57,010 iteration 2089 : loss : 0.034288, loss_ce: 0.017136
2022-01-08 16:02:58,324 iteration 2090 : loss : 0.036122, loss_ce: 0.016559
2022-01-08 16:02:59,735 iteration 2091 : loss : 0.040370, loss_ce: 0.017332

 31%|████████▉                    | 123/400 [52:53<1:54:10, 24.73s/it]2022-01-08 16:03:01,098 iteration 2092 : loss : 0.026382, loss_ce: 0.011596
2022-01-08 16:03:02,449 iteration 2093 : loss : 0.049975, loss_ce: 0.020490
2022-01-08 16:03:03,823 iteration 2094 : loss : 0.066362, loss_ce: 0.019511
2022-01-08 16:03:05,140 iteration 2095 : loss : 0.025932, loss_ce: 0.011313
2022-01-08 16:03:06,588 iteration 2096 : loss : 0.043144, loss_ce: 0.020311
2022-01-08 16:03:07,979 iteration 2097 : loss : 0.070665, loss_ce: 0.024686
2022-01-08 16:03:09,357 iteration 2098 : loss : 0.050105, loss_ce: 0.016600
2022-01-08 16:03:10,747 iteration 2099 : loss : 0.033100, loss_ce: 0.009917
2022-01-08 16:03:12,157 iteration 2100 : loss : 0.050535, loss_ce: 0.027991
2022-01-08 16:03:13,551 iteration 2101 : loss : 0.037760, loss_ce: 0.012756
2022-01-08 16:03:14,972 iteration 2102 : loss : 0.048955, loss_ce: 0.027768
2022-01-08 16:03:16,268 iteration 2103 : loss : 0.034716, loss_ce: 0.015835
2022-01-08 16:03:17,583 iteration 2104 : loss : 0.058010, loss_ce: 0.016788
2022-01-08 16:03:19,045 iteration 2105 : loss : 0.105847, loss_ce: 0.044526
2022-01-08 16:03:20,387 iteration 2106 : loss : 0.030013, loss_ce: 0.012179
2022-01-08 16:03:21,842 iteration 2107 : loss : 0.030994, loss_ce: 0.012283
2022-01-08 16:03:23,238 iteration 2108 : loss : 0.077418, loss_ce: 0.029715

 31%|████████▉                    | 124/400 [53:17<1:52:04, 24.36s/it]2022-01-08 16:03:24,673 iteration 2109 : loss : 0.074191, loss_ce: 0.031734
2022-01-08 16:03:26,086 iteration 2110 : loss : 0.044261, loss_ce: 0.017784
2022-01-08 16:03:27,549 iteration 2111 : loss : 0.080210, loss_ce: 0.030349
2022-01-08 16:03:28,942 iteration 2112 : loss : 0.065469, loss_ce: 0.027410
2022-01-08 16:03:30,287 iteration 2113 : loss : 0.055026, loss_ce: 0.028514
2022-01-08 16:03:31,696 iteration 2114 : loss : 0.060043, loss_ce: 0.029318
2022-01-08 16:03:33,098 iteration 2115 : loss : 0.059661, loss_ce: 0.019611
2022-01-08 16:03:34,498 iteration 2116 : loss : 0.057540, loss_ce: 0.020534
2022-01-08 16:03:35,885 iteration 2117 : loss : 0.046564, loss_ce: 0.016982
2022-01-08 16:03:37,306 iteration 2118 : loss : 0.064382, loss_ce: 0.018457
2022-01-08 16:03:38,730 iteration 2119 : loss : 0.052522, loss_ce: 0.018411
2022-01-08 16:03:40,115 iteration 2120 : loss : 0.059519, loss_ce: 0.016314
2022-01-08 16:03:41,403 iteration 2121 : loss : 0.054113, loss_ce: 0.020654
2022-01-08 16:03:42,758 iteration 2122 : loss : 0.043103, loss_ce: 0.016578
2022-01-08 16:03:44,193 iteration 2123 : loss : 0.067656, loss_ce: 0.030522
2022-01-08 16:03:45,647 iteration 2124 : loss : 0.063091, loss_ce: 0.031894
2022-01-08 16:03:45,647 Training Data Eval:
2022-01-08 16:03:52,485   Average segmentation loss on training set: 0.0415
2022-01-08 16:03:52,485 Validation Data Eval:
2022-01-08 16:03:54,842   Average segmentation loss on validation set: 0.0826
2022-01-08 16:03:56,238 iteration 2125 : loss : 0.083365, loss_ce: 0.052240

 31%|█████████                    | 125/400 [53:50<2:03:33, 26.96s/it]2022-01-08 16:03:57,724 iteration 2126 : loss : 0.044168, loss_ce: 0.020185
2022-01-08 16:03:59,132 iteration 2127 : loss : 0.089753, loss_ce: 0.054644
2022-01-08 16:04:00,537 iteration 2128 : loss : 0.042589, loss_ce: 0.014602
2022-01-08 16:04:01,883 iteration 2129 : loss : 0.055183, loss_ce: 0.021936
2022-01-08 16:04:03,300 iteration 2130 : loss : 0.084407, loss_ce: 0.030521
2022-01-08 16:04:04,663 iteration 2131 : loss : 0.054809, loss_ce: 0.016955
2022-01-08 16:04:06,041 iteration 2132 : loss : 0.041010, loss_ce: 0.015242
2022-01-08 16:04:07,486 iteration 2133 : loss : 0.065516, loss_ce: 0.022187
2022-01-08 16:04:08,803 iteration 2134 : loss : 0.045004, loss_ce: 0.020397
2022-01-08 16:04:10,182 iteration 2135 : loss : 0.050282, loss_ce: 0.019201
2022-01-08 16:04:11,549 iteration 2136 : loss : 0.049746, loss_ce: 0.020667
2022-01-08 16:04:12,924 iteration 2137 : loss : 0.055643, loss_ce: 0.022050
2022-01-08 16:04:14,260 iteration 2138 : loss : 0.043019, loss_ce: 0.016557
2022-01-08 16:04:15,673 iteration 2139 : loss : 0.036905, loss_ce: 0.018099
2022-01-08 16:04:17,048 iteration 2140 : loss : 0.049221, loss_ce: 0.020225
2022-01-08 16:04:18,489 iteration 2141 : loss : 0.040301, loss_ce: 0.012597
2022-01-08 16:04:19,835 iteration 2142 : loss : 0.041007, loss_ce: 0.013725

 32%|█████████▏                   | 126/400 [54:14<1:58:29, 25.95s/it]2022-01-08 16:04:21,204 iteration 2143 : loss : 0.044915, loss_ce: 0.017126
2022-01-08 16:04:22,605 iteration 2144 : loss : 0.054800, loss_ce: 0.017881
2022-01-08 16:04:24,009 iteration 2145 : loss : 0.060595, loss_ce: 0.022427
2022-01-08 16:04:25,336 iteration 2146 : loss : 0.027270, loss_ce: 0.013126
2022-01-08 16:04:26,726 iteration 2147 : loss : 0.054127, loss_ce: 0.018790
2022-01-08 16:04:28,078 iteration 2148 : loss : 0.042329, loss_ce: 0.017737
2022-01-08 16:04:29,468 iteration 2149 : loss : 0.054687, loss_ce: 0.025688
2022-01-08 16:04:30,843 iteration 2150 : loss : 0.039579, loss_ce: 0.014867
2022-01-08 16:04:32,285 iteration 2151 : loss : 0.053919, loss_ce: 0.020615
2022-01-08 16:04:33,630 iteration 2152 : loss : 0.048298, loss_ce: 0.019813
2022-01-08 16:04:34,960 iteration 2153 : loss : 0.035174, loss_ce: 0.013600
2022-01-08 16:04:36,469 iteration 2154 : loss : 0.054975, loss_ce: 0.017656
2022-01-08 16:04:37,862 iteration 2155 : loss : 0.038382, loss_ce: 0.015184
2022-01-08 16:04:39,202 iteration 2156 : loss : 0.045758, loss_ce: 0.021905
2022-01-08 16:04:40,728 iteration 2157 : loss : 0.058315, loss_ce: 0.018484
2022-01-08 16:04:42,229 iteration 2158 : loss : 0.050015, loss_ce: 0.023569
2022-01-08 16:04:43,641 iteration 2159 : loss : 0.068726, loss_ce: 0.021883

 32%|█████████▏                   | 127/400 [54:37<1:55:07, 25.30s/it]2022-01-08 16:04:45,056 iteration 2160 : loss : 0.047225, loss_ce: 0.018939
2022-01-08 16:04:46,392 iteration 2161 : loss : 0.038330, loss_ce: 0.014492
2022-01-08 16:04:47,757 iteration 2162 : loss : 0.056579, loss_ce: 0.020205
2022-01-08 16:04:49,110 iteration 2163 : loss : 0.033163, loss_ce: 0.012935
2022-01-08 16:04:50,533 iteration 2164 : loss : 0.034184, loss_ce: 0.016800
2022-01-08 16:04:51,938 iteration 2165 : loss : 0.064203, loss_ce: 0.020719
2022-01-08 16:04:53,278 iteration 2166 : loss : 0.042978, loss_ce: 0.018655
2022-01-08 16:04:54,588 iteration 2167 : loss : 0.036676, loss_ce: 0.013512
2022-01-08 16:04:55,945 iteration 2168 : loss : 0.035888, loss_ce: 0.014555
2022-01-08 16:04:57,362 iteration 2169 : loss : 0.042667, loss_ce: 0.014840
2022-01-08 16:04:58,644 iteration 2170 : loss : 0.031175, loss_ce: 0.010111
2022-01-08 16:05:00,003 iteration 2171 : loss : 0.044143, loss_ce: 0.016861
2022-01-08 16:05:01,357 iteration 2172 : loss : 0.055395, loss_ce: 0.019651
2022-01-08 16:05:02,697 iteration 2173 : loss : 0.040598, loss_ce: 0.010941
2022-01-08 16:05:04,086 iteration 2174 : loss : 0.060482, loss_ce: 0.023861
2022-01-08 16:05:05,620 iteration 2175 : loss : 0.045257, loss_ce: 0.023393
2022-01-08 16:05:06,908 iteration 2176 : loss : 0.033917, loss_ce: 0.016215

 32%|█████████▎                   | 128/400 [55:01<1:51:57, 24.70s/it]2022-01-08 16:05:08,284 iteration 2177 : loss : 0.059309, loss_ce: 0.033177
2022-01-08 16:05:09,651 iteration 2178 : loss : 0.038020, loss_ce: 0.011989
2022-01-08 16:05:11,090 iteration 2179 : loss : 0.052980, loss_ce: 0.015497
2022-01-08 16:05:12,502 iteration 2180 : loss : 0.035930, loss_ce: 0.015959
2022-01-08 16:05:13,810 iteration 2181 : loss : 0.034923, loss_ce: 0.013223
2022-01-08 16:05:15,179 iteration 2182 : loss : 0.056204, loss_ce: 0.019262
2022-01-08 16:05:16,562 iteration 2183 : loss : 0.071440, loss_ce: 0.018796
2022-01-08 16:05:17,883 iteration 2184 : loss : 0.045506, loss_ce: 0.021604
2022-01-08 16:05:19,205 iteration 2185 : loss : 0.031341, loss_ce: 0.012078
2022-01-08 16:05:20,646 iteration 2186 : loss : 0.037552, loss_ce: 0.014262
2022-01-08 16:05:22,109 iteration 2187 : loss : 0.043201, loss_ce: 0.015409
2022-01-08 16:05:23,634 iteration 2188 : loss : 0.056061, loss_ce: 0.031537
2022-01-08 16:05:25,148 iteration 2189 : loss : 0.051765, loss_ce: 0.018392
2022-01-08 16:05:26,539 iteration 2190 : loss : 0.044326, loss_ce: 0.018090
2022-01-08 16:05:27,936 iteration 2191 : loss : 0.026903, loss_ce: 0.009935
2022-01-08 16:05:29,281 iteration 2192 : loss : 0.035824, loss_ce: 0.013804
2022-01-08 16:05:30,671 iteration 2193 : loss : 0.037068, loss_ce: 0.014656

 32%|█████████▎                   | 129/400 [55:24<1:50:16, 24.42s/it]2022-01-08 16:05:32,136 iteration 2194 : loss : 0.050229, loss_ce: 0.021358
2022-01-08 16:05:33,533 iteration 2195 : loss : 0.044430, loss_ce: 0.019453
2022-01-08 16:05:34,959 iteration 2196 : loss : 0.036153, loss_ce: 0.015183
2022-01-08 16:05:36,421 iteration 2197 : loss : 0.031756, loss_ce: 0.011238
2022-01-08 16:05:37,800 iteration 2198 : loss : 0.048311, loss_ce: 0.017024
2022-01-08 16:05:39,185 iteration 2199 : loss : 0.036998, loss_ce: 0.017213
2022-01-08 16:05:40,639 iteration 2200 : loss : 0.066698, loss_ce: 0.013872
2022-01-08 16:05:41,964 iteration 2201 : loss : 0.033368, loss_ce: 0.012286
2022-01-08 16:05:43,443 iteration 2202 : loss : 0.036956, loss_ce: 0.015465
2022-01-08 16:05:44,848 iteration 2203 : loss : 0.033236, loss_ce: 0.010123
2022-01-08 16:05:46,165 iteration 2204 : loss : 0.033132, loss_ce: 0.010070
2022-01-08 16:05:47,554 iteration 2205 : loss : 0.049995, loss_ce: 0.024008
2022-01-08 16:05:49,020 iteration 2206 : loss : 0.058403, loss_ce: 0.025207
2022-01-08 16:05:50,431 iteration 2207 : loss : 0.041552, loss_ce: 0.013709
2022-01-08 16:05:51,871 iteration 2208 : loss : 0.062799, loss_ce: 0.017992
2022-01-08 16:05:53,253 iteration 2209 : loss : 0.052948, loss_ce: 0.017745
2022-01-08 16:05:53,254 Training Data Eval:
2022-01-08 16:06:00,079   Average segmentation loss on training set: 0.0272
2022-01-08 16:06:00,080 Validation Data Eval:
2022-01-08 16:06:02,437   Average segmentation loss on validation set: 0.0629
2022-01-08 16:06:08,170 Found new lowest validation loss at iteration 2209! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_KEYS_best_val_loss_seed1234.pth
2022-01-08 16:06:09,629 iteration 2210 : loss : 0.041919, loss_ce: 0.021063

 32%|█████████▍                   | 130/400 [56:03<2:09:30, 28.78s/it]2022-01-08 16:06:11,061 iteration 2211 : loss : 0.039995, loss_ce: 0.010522
2022-01-08 16:06:12,387 iteration 2212 : loss : 0.040121, loss_ce: 0.017422
2022-01-08 16:06:13,764 iteration 2213 : loss : 0.055969, loss_ce: 0.015845
2022-01-08 16:06:15,066 iteration 2214 : loss : 0.041962, loss_ce: 0.014206
2022-01-08 16:06:16,361 iteration 2215 : loss : 0.029185, loss_ce: 0.011236
2022-01-08 16:06:17,706 iteration 2216 : loss : 0.043946, loss_ce: 0.020629
2022-01-08 16:06:19,025 iteration 2217 : loss : 0.044472, loss_ce: 0.022216
2022-01-08 16:06:20,369 iteration 2218 : loss : 0.029272, loss_ce: 0.010379
2022-01-08 16:06:21,765 iteration 2219 : loss : 0.043951, loss_ce: 0.020259
2022-01-08 16:06:23,216 iteration 2220 : loss : 0.041660, loss_ce: 0.021114
2022-01-08 16:06:24,658 iteration 2221 : loss : 0.037994, loss_ce: 0.012664
2022-01-08 16:06:25,952 iteration 2222 : loss : 0.042705, loss_ce: 0.017855
2022-01-08 16:06:27,275 iteration 2223 : loss : 0.040312, loss_ce: 0.013838
2022-01-08 16:06:28,713 iteration 2224 : loss : 0.051648, loss_ce: 0.023531
2022-01-08 16:06:30,106 iteration 2225 : loss : 0.039761, loss_ce: 0.014409
2022-01-08 16:06:31,550 iteration 2226 : loss : 0.041112, loss_ce: 0.019296
2022-01-08 16:06:32,970 iteration 2227 : loss : 0.058595, loss_ce: 0.019678

 33%|█████████▍                   | 131/400 [56:27<2:01:42, 27.15s/it]2022-01-08 16:06:34,476 iteration 2228 : loss : 0.049046, loss_ce: 0.022285
2022-01-08 16:06:35,871 iteration 2229 : loss : 0.043550, loss_ce: 0.015892
2022-01-08 16:06:37,388 iteration 2230 : loss : 0.049083, loss_ce: 0.019308
2022-01-08 16:06:38,757 iteration 2231 : loss : 0.061262, loss_ce: 0.036763
2022-01-08 16:06:40,122 iteration 2232 : loss : 0.036799, loss_ce: 0.015878
2022-01-08 16:06:41,683 iteration 2233 : loss : 0.065450, loss_ce: 0.016528
2022-01-08 16:06:43,095 iteration 2234 : loss : 0.048426, loss_ce: 0.014059
2022-01-08 16:06:44,477 iteration 2235 : loss : 0.038245, loss_ce: 0.015127
2022-01-08 16:06:45,843 iteration 2236 : loss : 0.031417, loss_ce: 0.013614
2022-01-08 16:06:47,242 iteration 2237 : loss : 0.038353, loss_ce: 0.016682
2022-01-08 16:06:48,572 iteration 2238 : loss : 0.039104, loss_ce: 0.011410
2022-01-08 16:06:49,930 iteration 2239 : loss : 0.029701, loss_ce: 0.008172
2022-01-08 16:06:51,228 iteration 2240 : loss : 0.054915, loss_ce: 0.015920
2022-01-08 16:06:52,594 iteration 2241 : loss : 0.032144, loss_ce: 0.011305
2022-01-08 16:06:54,033 iteration 2242 : loss : 0.045283, loss_ce: 0.015772
2022-01-08 16:06:55,443 iteration 2243 : loss : 0.061757, loss_ce: 0.029994
2022-01-08 16:06:56,804 iteration 2244 : loss : 0.025605, loss_ce: 0.008663

 33%|█████████▌                   | 132/400 [56:51<1:56:48, 26.15s/it]2022-01-08 16:06:58,227 iteration 2245 : loss : 0.038212, loss_ce: 0.012207
2022-01-08 16:06:59,514 iteration 2246 : loss : 0.032174, loss_ce: 0.009148
2022-01-08 16:07:00,896 iteration 2247 : loss : 0.034956, loss_ce: 0.015186
2022-01-08 16:07:02,340 iteration 2248 : loss : 0.056905, loss_ce: 0.026145
2022-01-08 16:07:03,717 iteration 2249 : loss : 0.029638, loss_ce: 0.014445
2022-01-08 16:07:05,099 iteration 2250 : loss : 0.034469, loss_ce: 0.011414
2022-01-08 16:07:06,508 iteration 2251 : loss : 0.033754, loss_ce: 0.015474
2022-01-08 16:07:07,888 iteration 2252 : loss : 0.050901, loss_ce: 0.017996
2022-01-08 16:07:09,360 iteration 2253 : loss : 0.067873, loss_ce: 0.027578
2022-01-08 16:07:10,791 iteration 2254 : loss : 0.031205, loss_ce: 0.012329
2022-01-08 16:07:12,169 iteration 2255 : loss : 0.033553, loss_ce: 0.010735
2022-01-08 16:07:13,534 iteration 2256 : loss : 0.035553, loss_ce: 0.015107
2022-01-08 16:07:14,866 iteration 2257 : loss : 0.045563, loss_ce: 0.014017
2022-01-08 16:07:16,189 iteration 2258 : loss : 0.048149, loss_ce: 0.018373
2022-01-08 16:07:17,622 iteration 2259 : loss : 0.032506, loss_ce: 0.013567
2022-01-08 16:07:18,936 iteration 2260 : loss : 0.033003, loss_ce: 0.012970
2022-01-08 16:07:20,330 iteration 2261 : loss : 0.056835, loss_ce: 0.023533

 33%|█████████▋                   | 133/400 [57:14<1:52:52, 25.36s/it]2022-01-08 16:07:21,712 iteration 2262 : loss : 0.032226, loss_ce: 0.016958
2022-01-08 16:07:23,155 iteration 2263 : loss : 0.045320, loss_ce: 0.014935
2022-01-08 16:07:24,622 iteration 2264 : loss : 0.038299, loss_ce: 0.011911
2022-01-08 16:07:26,053 iteration 2265 : loss : 0.027785, loss_ce: 0.010970
2022-01-08 16:07:27,423 iteration 2266 : loss : 0.036735, loss_ce: 0.015946
2022-01-08 16:07:28,814 iteration 2267 : loss : 0.030154, loss_ce: 0.009941
2022-01-08 16:07:30,202 iteration 2268 : loss : 0.035430, loss_ce: 0.013377
2022-01-08 16:07:31,557 iteration 2269 : loss : 0.033123, loss_ce: 0.017125
2022-01-08 16:07:32,936 iteration 2270 : loss : 0.039319, loss_ce: 0.011751
2022-01-08 16:07:34,285 iteration 2271 : loss : 0.032569, loss_ce: 0.012193
2022-01-08 16:07:35,649 iteration 2272 : loss : 0.043284, loss_ce: 0.020779
2022-01-08 16:07:37,048 iteration 2273 : loss : 0.042183, loss_ce: 0.015578
2022-01-08 16:07:38,445 iteration 2274 : loss : 0.062038, loss_ce: 0.016472
2022-01-08 16:07:39,882 iteration 2275 : loss : 0.044319, loss_ce: 0.015361
2022-01-08 16:07:41,213 iteration 2276 : loss : 0.031102, loss_ce: 0.013211
2022-01-08 16:07:42,595 iteration 2277 : loss : 0.037870, loss_ce: 0.012990
2022-01-08 16:07:43,928 iteration 2278 : loss : 0.028616, loss_ce: 0.010166

 34%|█████████▋                   | 134/400 [57:38<1:50:05, 24.83s/it]2022-01-08 16:07:45,335 iteration 2279 : loss : 0.097943, loss_ce: 0.043463
2022-01-08 16:07:46,713 iteration 2280 : loss : 0.040382, loss_ce: 0.017447
2022-01-08 16:07:48,083 iteration 2281 : loss : 0.052711, loss_ce: 0.013047
2022-01-08 16:07:49,486 iteration 2282 : loss : 0.032337, loss_ce: 0.013496
2022-01-08 16:07:50,933 iteration 2283 : loss : 0.039810, loss_ce: 0.016110
2022-01-08 16:07:52,287 iteration 2284 : loss : 0.042352, loss_ce: 0.019697
2022-01-08 16:07:53,650 iteration 2285 : loss : 0.030568, loss_ce: 0.011941
2022-01-08 16:07:55,009 iteration 2286 : loss : 0.026188, loss_ce: 0.010147
2022-01-08 16:07:56,369 iteration 2287 : loss : 0.030743, loss_ce: 0.012135
2022-01-08 16:07:57,777 iteration 2288 : loss : 0.033536, loss_ce: 0.012404
2022-01-08 16:07:59,110 iteration 2289 : loss : 0.035822, loss_ce: 0.010200
2022-01-08 16:08:00,542 iteration 2290 : loss : 0.031514, loss_ce: 0.013886
2022-01-08 16:08:01,912 iteration 2291 : loss : 0.026832, loss_ce: 0.010187
2022-01-08 16:08:03,265 iteration 2292 : loss : 0.037032, loss_ce: 0.015916
2022-01-08 16:08:04,565 iteration 2293 : loss : 0.030663, loss_ce: 0.015296
2022-01-08 16:08:05,971 iteration 2294 : loss : 0.059146, loss_ce: 0.021723
2022-01-08 16:08:05,971 Training Data Eval:
2022-01-08 16:08:12,812   Average segmentation loss on training set: 0.0319
2022-01-08 16:08:12,812 Validation Data Eval:
2022-01-08 16:08:15,173   Average segmentation loss on validation set: 0.0696
2022-01-08 16:08:16,623 iteration 2295 : loss : 0.054911, loss_ce: 0.029631

 34%|█████████▊                   | 135/400 [58:10<2:00:06, 27.19s/it]2022-01-08 16:08:17,983 iteration 2296 : loss : 0.026815, loss_ce: 0.010435
2022-01-08 16:08:19,346 iteration 2297 : loss : 0.031348, loss_ce: 0.013317
2022-01-08 16:08:20,712 iteration 2298 : loss : 0.025799, loss_ce: 0.010874
2022-01-08 16:08:22,155 iteration 2299 : loss : 0.055505, loss_ce: 0.029517
2022-01-08 16:08:23,499 iteration 2300 : loss : 0.031502, loss_ce: 0.013170
2022-01-08 16:08:24,947 iteration 2301 : loss : 0.036273, loss_ce: 0.011332
2022-01-08 16:08:26,365 iteration 2302 : loss : 0.060410, loss_ce: 0.018876
2022-01-08 16:08:27,762 iteration 2303 : loss : 0.038259, loss_ce: 0.013862
2022-01-08 16:08:29,221 iteration 2304 : loss : 0.042271, loss_ce: 0.016075
2022-01-08 16:08:30,642 iteration 2305 : loss : 0.051227, loss_ce: 0.021245
2022-01-08 16:08:32,119 iteration 2306 : loss : 0.066157, loss_ce: 0.032452
2022-01-08 16:08:33,484 iteration 2307 : loss : 0.050805, loss_ce: 0.016725
2022-01-08 16:08:34,826 iteration 2308 : loss : 0.036397, loss_ce: 0.012435
2022-01-08 16:08:36,177 iteration 2309 : loss : 0.041742, loss_ce: 0.022049
2022-01-08 16:08:37,619 iteration 2310 : loss : 0.038586, loss_ce: 0.017091
2022-01-08 16:08:38,923 iteration 2311 : loss : 0.044148, loss_ce: 0.014652
2022-01-08 16:08:40,306 iteration 2312 : loss : 0.041033, loss_ce: 0.018171

 34%|█████████▊                   | 136/400 [58:34<1:54:59, 26.14s/it]2022-01-08 16:08:41,778 iteration 2313 : loss : 0.044512, loss_ce: 0.016010
2022-01-08 16:08:43,061 iteration 2314 : loss : 0.028027, loss_ce: 0.008651
2022-01-08 16:08:44,391 iteration 2315 : loss : 0.030064, loss_ce: 0.010323
2022-01-08 16:08:45,845 iteration 2316 : loss : 0.079030, loss_ce: 0.039417
2022-01-08 16:08:47,160 iteration 2317 : loss : 0.038495, loss_ce: 0.012697
2022-01-08 16:08:48,513 iteration 2318 : loss : 0.039000, loss_ce: 0.017118
2022-01-08 16:08:49,885 iteration 2319 : loss : 0.040510, loss_ce: 0.017328
2022-01-08 16:08:51,336 iteration 2320 : loss : 0.035001, loss_ce: 0.014226
2022-01-08 16:08:52,707 iteration 2321 : loss : 0.040728, loss_ce: 0.016593
2022-01-08 16:08:54,091 iteration 2322 : loss : 0.033200, loss_ce: 0.014057
2022-01-08 16:08:55,382 iteration 2323 : loss : 0.042893, loss_ce: 0.017880
2022-01-08 16:08:56,740 iteration 2324 : loss : 0.034748, loss_ce: 0.015347
2022-01-08 16:08:58,001 iteration 2325 : loss : 0.031648, loss_ce: 0.013581
2022-01-08 16:08:59,353 iteration 2326 : loss : 0.046549, loss_ce: 0.012681
2022-01-08 16:09:00,683 iteration 2327 : loss : 0.038895, loss_ce: 0.014887
2022-01-08 16:09:02,049 iteration 2328 : loss : 0.041392, loss_ce: 0.017950
2022-01-08 16:09:03,372 iteration 2329 : loss : 0.032197, loss_ce: 0.013384

 34%|█████████▉                   | 137/400 [58:57<1:50:32, 25.22s/it]2022-01-08 16:09:04,812 iteration 2330 : loss : 0.050848, loss_ce: 0.021626
2022-01-08 16:09:06,140 iteration 2331 : loss : 0.039247, loss_ce: 0.015481
2022-01-08 16:09:07,584 iteration 2332 : loss : 0.040696, loss_ce: 0.015695
2022-01-08 16:09:08,958 iteration 2333 : loss : 0.052245, loss_ce: 0.023108
2022-01-08 16:09:10,457 iteration 2334 : loss : 0.033630, loss_ce: 0.013859
2022-01-08 16:09:11,943 iteration 2335 : loss : 0.044934, loss_ce: 0.019148
2022-01-08 16:09:13,393 iteration 2336 : loss : 0.032173, loss_ce: 0.014188
2022-01-08 16:09:14,780 iteration 2337 : loss : 0.056289, loss_ce: 0.021449
2022-01-08 16:09:16,191 iteration 2338 : loss : 0.046335, loss_ce: 0.016517
2022-01-08 16:09:17,593 iteration 2339 : loss : 0.045916, loss_ce: 0.017244
2022-01-08 16:09:18,918 iteration 2340 : loss : 0.034581, loss_ce: 0.013066
2022-01-08 16:09:20,313 iteration 2341 : loss : 0.031082, loss_ce: 0.012761
2022-01-08 16:09:21,717 iteration 2342 : loss : 0.037810, loss_ce: 0.015302
2022-01-08 16:09:23,218 iteration 2343 : loss : 0.036287, loss_ce: 0.012875
2022-01-08 16:09:24,554 iteration 2344 : loss : 0.056017, loss_ce: 0.018074
2022-01-08 16:09:25,903 iteration 2345 : loss : 0.063038, loss_ce: 0.030067
2022-01-08 16:09:27,270 iteration 2346 : loss : 0.050580, loss_ce: 0.020189

 34%|██████████                   | 138/400 [59:21<1:48:23, 24.82s/it]2022-01-08 16:09:28,790 iteration 2347 : loss : 0.050430, loss_ce: 0.020210
2022-01-08 16:09:30,189 iteration 2348 : loss : 0.034376, loss_ce: 0.013810
2022-01-08 16:09:31,545 iteration 2349 : loss : 0.039997, loss_ce: 0.014581
2022-01-08 16:09:32,912 iteration 2350 : loss : 0.053838, loss_ce: 0.014165
2022-01-08 16:09:34,412 iteration 2351 : loss : 0.041207, loss_ce: 0.017054
2022-01-08 16:09:35,789 iteration 2352 : loss : 0.028532, loss_ce: 0.014736
2022-01-08 16:09:37,160 iteration 2353 : loss : 0.037583, loss_ce: 0.015782
2022-01-08 16:09:38,497 iteration 2354 : loss : 0.022848, loss_ce: 0.010321
2022-01-08 16:09:39,848 iteration 2355 : loss : 0.038223, loss_ce: 0.012874
2022-01-08 16:09:41,278 iteration 2356 : loss : 0.039855, loss_ce: 0.015459
2022-01-08 16:09:42,663 iteration 2357 : loss : 0.059938, loss_ce: 0.021306
2022-01-08 16:09:44,050 iteration 2358 : loss : 0.035262, loss_ce: 0.013393
2022-01-08 16:09:45,397 iteration 2359 : loss : 0.049216, loss_ce: 0.015253
2022-01-08 16:09:46,724 iteration 2360 : loss : 0.042446, loss_ce: 0.012270
2022-01-08 16:09:48,091 iteration 2361 : loss : 0.038186, loss_ce: 0.012931
2022-01-08 16:09:49,582 iteration 2362 : loss : 0.045757, loss_ce: 0.019916
2022-01-08 16:09:50,962 iteration 2363 : loss : 0.031737, loss_ce: 0.014837

 35%|██████████                   | 139/400 [59:45<1:46:30, 24.48s/it]2022-01-08 16:09:52,474 iteration 2364 : loss : 0.030383, loss_ce: 0.011407
2022-01-08 16:09:53,941 iteration 2365 : loss : 0.045339, loss_ce: 0.016176
2022-01-08 16:09:55,364 iteration 2366 : loss : 0.053587, loss_ce: 0.019916
2022-01-08 16:09:56,692 iteration 2367 : loss : 0.029856, loss_ce: 0.007282
2022-01-08 16:09:58,020 iteration 2368 : loss : 0.032887, loss_ce: 0.014412
2022-01-08 16:09:59,402 iteration 2369 : loss : 0.044476, loss_ce: 0.012567
2022-01-08 16:10:00,766 iteration 2370 : loss : 0.047484, loss_ce: 0.020040
2022-01-08 16:10:02,174 iteration 2371 : loss : 0.028710, loss_ce: 0.010693
2022-01-08 16:10:03,510 iteration 2372 : loss : 0.035356, loss_ce: 0.010157
2022-01-08 16:10:04,871 iteration 2373 : loss : 0.040949, loss_ce: 0.014447
2022-01-08 16:10:06,193 iteration 2374 : loss : 0.034557, loss_ce: 0.013658
2022-01-08 16:10:07,535 iteration 2375 : loss : 0.035157, loss_ce: 0.012576
2022-01-08 16:10:08,927 iteration 2376 : loss : 0.042726, loss_ce: 0.021060
2022-01-08 16:10:10,317 iteration 2377 : loss : 0.039591, loss_ce: 0.017118
2022-01-08 16:10:11,703 iteration 2378 : loss : 0.026140, loss_ce: 0.010243
2022-01-08 16:10:13,114 iteration 2379 : loss : 0.034782, loss_ce: 0.014852
2022-01-08 16:10:13,115 Training Data Eval:
2022-01-08 16:10:19,963   Average segmentation loss on training set: 0.0275
2022-01-08 16:10:19,963 Validation Data Eval:
2022-01-08 16:10:22,325   Average segmentation loss on validation set: 0.0704
2022-01-08 16:10:23,661 iteration 2380 : loss : 0.027520, loss_ce: 0.013055

 35%|█████████▍                 | 140/400 [1:00:17<1:56:45, 26.94s/it]2022-01-08 16:10:25,040 iteration 2381 : loss : 0.034839, loss_ce: 0.012971
2022-01-08 16:10:26,447 iteration 2382 : loss : 0.035790, loss_ce: 0.012280
2022-01-08 16:10:27,782 iteration 2383 : loss : 0.026805, loss_ce: 0.008712
2022-01-08 16:10:29,206 iteration 2384 : loss : 0.047351, loss_ce: 0.019640
2022-01-08 16:10:30,641 iteration 2385 : loss : 0.057810, loss_ce: 0.019665
2022-01-08 16:10:32,009 iteration 2386 : loss : 0.033719, loss_ce: 0.010717
2022-01-08 16:10:33,353 iteration 2387 : loss : 0.034707, loss_ce: 0.011775
2022-01-08 16:10:34,731 iteration 2388 : loss : 0.036683, loss_ce: 0.015150
2022-01-08 16:10:36,044 iteration 2389 : loss : 0.018153, loss_ce: 0.006093
2022-01-08 16:10:37,429 iteration 2390 : loss : 0.034327, loss_ce: 0.017028
2022-01-08 16:10:38,788 iteration 2391 : loss : 0.031079, loss_ce: 0.017246
2022-01-08 16:10:40,190 iteration 2392 : loss : 0.044269, loss_ce: 0.014779
2022-01-08 16:10:41,588 iteration 2393 : loss : 0.050410, loss_ce: 0.016586
2022-01-08 16:10:42,874 iteration 2394 : loss : 0.032272, loss_ce: 0.010729
2022-01-08 16:10:44,299 iteration 2395 : loss : 0.030544, loss_ce: 0.014952
2022-01-08 16:10:45,630 iteration 2396 : loss : 0.024870, loss_ce: 0.011187
2022-01-08 16:10:47,030 iteration 2397 : loss : 0.034392, loss_ce: 0.012000

 35%|█████████▌                 | 141/400 [1:00:41<1:51:41, 25.88s/it]2022-01-08 16:10:48,451 iteration 2398 : loss : 0.040138, loss_ce: 0.014149
2022-01-08 16:10:49,793 iteration 2399 : loss : 0.031696, loss_ce: 0.009298
2022-01-08 16:10:51,227 iteration 2400 : loss : 0.032247, loss_ce: 0.014940
2022-01-08 16:10:52,605 iteration 2401 : loss : 0.025413, loss_ce: 0.007935
2022-01-08 16:10:54,031 iteration 2402 : loss : 0.035470, loss_ce: 0.019056
2022-01-08 16:10:55,373 iteration 2403 : loss : 0.031444, loss_ce: 0.012292
2022-01-08 16:10:56,692 iteration 2404 : loss : 0.034118, loss_ce: 0.016738
2022-01-08 16:10:57,986 iteration 2405 : loss : 0.042767, loss_ce: 0.018916
2022-01-08 16:10:59,484 iteration 2406 : loss : 0.050045, loss_ce: 0.014255
2022-01-08 16:11:00,797 iteration 2407 : loss : 0.033146, loss_ce: 0.015971
2022-01-08 16:11:02,119 iteration 2408 : loss : 0.021423, loss_ce: 0.008894
2022-01-08 16:11:03,541 iteration 2409 : loss : 0.030086, loss_ce: 0.009924
2022-01-08 16:11:04,968 iteration 2410 : loss : 0.037429, loss_ce: 0.013777
2022-01-08 16:11:06,373 iteration 2411 : loss : 0.054599, loss_ce: 0.017723
2022-01-08 16:11:07,706 iteration 2412 : loss : 0.022470, loss_ce: 0.008984
2022-01-08 16:11:09,151 iteration 2413 : loss : 0.047989, loss_ce: 0.023668
2022-01-08 16:11:10,536 iteration 2414 : loss : 0.034537, loss_ce: 0.014661

 36%|█████████▌                 | 142/400 [1:01:04<1:48:12, 25.16s/it]2022-01-08 16:11:11,988 iteration 2415 : loss : 0.036131, loss_ce: 0.012212
2022-01-08 16:11:13,346 iteration 2416 : loss : 0.023694, loss_ce: 0.008296
2022-01-08 16:11:14,721 iteration 2417 : loss : 0.024775, loss_ce: 0.008591
2022-01-08 16:11:16,179 iteration 2418 : loss : 0.034849, loss_ce: 0.012862
2022-01-08 16:11:17,569 iteration 2419 : loss : 0.051490, loss_ce: 0.033400
2022-01-08 16:11:19,047 iteration 2420 : loss : 0.042423, loss_ce: 0.018288
2022-01-08 16:11:20,505 iteration 2421 : loss : 0.038338, loss_ce: 0.013099
2022-01-08 16:11:21,940 iteration 2422 : loss : 0.044037, loss_ce: 0.017036
2022-01-08 16:11:23,317 iteration 2423 : loss : 0.027508, loss_ce: 0.009367
2022-01-08 16:11:24,676 iteration 2424 : loss : 0.030916, loss_ce: 0.012613
2022-01-08 16:11:26,158 iteration 2425 : loss : 0.038390, loss_ce: 0.012496
2022-01-08 16:11:27,518 iteration 2426 : loss : 0.040771, loss_ce: 0.013135
2022-01-08 16:11:28,808 iteration 2427 : loss : 0.027646, loss_ce: 0.011993
2022-01-08 16:11:30,142 iteration 2428 : loss : 0.033646, loss_ce: 0.009659
2022-01-08 16:11:31,479 iteration 2429 : loss : 0.036281, loss_ce: 0.013250
2022-01-08 16:11:32,822 iteration 2430 : loss : 0.022818, loss_ce: 0.008881
2022-01-08 16:11:34,192 iteration 2431 : loss : 0.032068, loss_ce: 0.017308

 36%|█████████▋                 | 143/400 [1:01:28<1:45:50, 24.71s/it]2022-01-08 16:11:35,583 iteration 2432 : loss : 0.038290, loss_ce: 0.012001
2022-01-08 16:11:36,943 iteration 2433 : loss : 0.037632, loss_ce: 0.016601
2022-01-08 16:11:38,319 iteration 2434 : loss : 0.028264, loss_ce: 0.009326
2022-01-08 16:11:39,774 iteration 2435 : loss : 0.039061, loss_ce: 0.021317
2022-01-08 16:11:41,071 iteration 2436 : loss : 0.033062, loss_ce: 0.014282
2022-01-08 16:11:42,488 iteration 2437 : loss : 0.029123, loss_ce: 0.010699
2022-01-08 16:11:43,915 iteration 2438 : loss : 0.034488, loss_ce: 0.011046
2022-01-08 16:11:45,333 iteration 2439 : loss : 0.057502, loss_ce: 0.017502
2022-01-08 16:11:46,758 iteration 2440 : loss : 0.037816, loss_ce: 0.014872
2022-01-08 16:11:48,124 iteration 2441 : loss : 0.031904, loss_ce: 0.010284
2022-01-08 16:11:49,478 iteration 2442 : loss : 0.029923, loss_ce: 0.011838
2022-01-08 16:11:50,781 iteration 2443 : loss : 0.032814, loss_ce: 0.012185
2022-01-08 16:11:52,153 iteration 2444 : loss : 0.030477, loss_ce: 0.011371
2022-01-08 16:11:53,538 iteration 2445 : loss : 0.032744, loss_ce: 0.012647
2022-01-08 16:11:54,995 iteration 2446 : loss : 0.029571, loss_ce: 0.014447
2022-01-08 16:11:56,310 iteration 2447 : loss : 0.039977, loss_ce: 0.011119
2022-01-08 16:11:57,728 iteration 2448 : loss : 0.028163, loss_ce: 0.010076

 36%|█████████▋                 | 144/400 [1:01:51<1:43:55, 24.36s/it]2022-01-08 16:11:59,095 iteration 2449 : loss : 0.037717, loss_ce: 0.014210
2022-01-08 16:12:00,409 iteration 2450 : loss : 0.026238, loss_ce: 0.013195
2022-01-08 16:12:01,759 iteration 2451 : loss : 0.027698, loss_ce: 0.008239
2022-01-08 16:12:03,087 iteration 2452 : loss : 0.035054, loss_ce: 0.011479
2022-01-08 16:12:04,467 iteration 2453 : loss : 0.035855, loss_ce: 0.011971
2022-01-08 16:12:05,822 iteration 2454 : loss : 0.036483, loss_ce: 0.013238
2022-01-08 16:12:07,151 iteration 2455 : loss : 0.037079, loss_ce: 0.017735
2022-01-08 16:12:08,466 iteration 2456 : loss : 0.034483, loss_ce: 0.016309
2022-01-08 16:12:09,816 iteration 2457 : loss : 0.028891, loss_ce: 0.011988
2022-01-08 16:12:11,138 iteration 2458 : loss : 0.030507, loss_ce: 0.012060
2022-01-08 16:12:12,420 iteration 2459 : loss : 0.021900, loss_ce: 0.008515
2022-01-08 16:12:13,756 iteration 2460 : loss : 0.031720, loss_ce: 0.009334
2022-01-08 16:12:15,189 iteration 2461 : loss : 0.031424, loss_ce: 0.011457
2022-01-08 16:12:16,580 iteration 2462 : loss : 0.046552, loss_ce: 0.014887
2022-01-08 16:12:17,932 iteration 2463 : loss : 0.029285, loss_ce: 0.012673
2022-01-08 16:12:19,325 iteration 2464 : loss : 0.023921, loss_ce: 0.008939
2022-01-08 16:12:19,326 Training Data Eval:
2022-01-08 16:12:26,177   Average segmentation loss on training set: 0.0230
2022-01-08 16:12:26,177 Validation Data Eval:
2022-01-08 16:12:28,537   Average segmentation loss on validation set: 0.0727
2022-01-08 16:12:29,888 iteration 2465 : loss : 0.029265, loss_ce: 0.011204

 36%|█████████▊                 | 145/400 [1:02:24<1:53:28, 26.70s/it]2022-01-08 16:12:31,371 iteration 2466 : loss : 0.041039, loss_ce: 0.016933
2022-01-08 16:12:32,820 iteration 2467 : loss : 0.035527, loss_ce: 0.014275
2022-01-08 16:12:34,173 iteration 2468 : loss : 0.028373, loss_ce: 0.009605
2022-01-08 16:12:35,494 iteration 2469 : loss : 0.023181, loss_ce: 0.009096
2022-01-08 16:12:36,853 iteration 2470 : loss : 0.031993, loss_ce: 0.010845
2022-01-08 16:12:38,304 iteration 2471 : loss : 0.045760, loss_ce: 0.014235
2022-01-08 16:12:39,643 iteration 2472 : loss : 0.046215, loss_ce: 0.017410
2022-01-08 16:12:41,066 iteration 2473 : loss : 0.039899, loss_ce: 0.016938
2022-01-08 16:12:42,400 iteration 2474 : loss : 0.027062, loss_ce: 0.009044
2022-01-08 16:12:43,771 iteration 2475 : loss : 0.033838, loss_ce: 0.011367
2022-01-08 16:12:45,089 iteration 2476 : loss : 0.050404, loss_ce: 0.028904
2022-01-08 16:12:46,540 iteration 2477 : loss : 0.061294, loss_ce: 0.022536
2022-01-08 16:12:47,948 iteration 2478 : loss : 0.035365, loss_ce: 0.013189
2022-01-08 16:12:49,244 iteration 2479 : loss : 0.030146, loss_ce: 0.009763
2022-01-08 16:12:50,623 iteration 2480 : loss : 0.066246, loss_ce: 0.031311
2022-01-08 16:12:52,049 iteration 2481 : loss : 0.030410, loss_ce: 0.012022
2022-01-08 16:12:53,395 iteration 2482 : loss : 0.025451, loss_ce: 0.011221

 36%|█████████▊                 | 146/400 [1:02:47<1:48:58, 25.74s/it]2022-01-08 16:12:54,904 iteration 2483 : loss : 0.053174, loss_ce: 0.023714
2022-01-08 16:12:56,306 iteration 2484 : loss : 0.052850, loss_ce: 0.012959
2022-01-08 16:12:57,643 iteration 2485 : loss : 0.037880, loss_ce: 0.015474
2022-01-08 16:12:59,005 iteration 2486 : loss : 0.031001, loss_ce: 0.012440
2022-01-08 16:13:00,363 iteration 2487 : loss : 0.045266, loss_ce: 0.015093
2022-01-08 16:13:01,790 iteration 2488 : loss : 0.040204, loss_ce: 0.017886
2022-01-08 16:13:03,152 iteration 2489 : loss : 0.032594, loss_ce: 0.013649
2022-01-08 16:13:04,568 iteration 2490 : loss : 0.036607, loss_ce: 0.015512
2022-01-08 16:13:06,024 iteration 2491 : loss : 0.035222, loss_ce: 0.014428
2022-01-08 16:13:07,309 iteration 2492 : loss : 0.034252, loss_ce: 0.011705
2022-01-08 16:13:08,696 iteration 2493 : loss : 0.034567, loss_ce: 0.014512
2022-01-08 16:13:10,055 iteration 2494 : loss : 0.034210, loss_ce: 0.009861
2022-01-08 16:13:11,403 iteration 2495 : loss : 0.031909, loss_ce: 0.014467
2022-01-08 16:13:12,953 iteration 2496 : loss : 0.037174, loss_ce: 0.010112
2022-01-08 16:13:14,375 iteration 2497 : loss : 0.045620, loss_ce: 0.014403
2022-01-08 16:13:15,801 iteration 2498 : loss : 0.038389, loss_ce: 0.015254
2022-01-08 16:13:17,117 iteration 2499 : loss : 0.030391, loss_ce: 0.007722

 37%|█████████▉                 | 147/400 [1:03:11<1:45:59, 25.14s/it]2022-01-08 16:13:18,532 iteration 2500 : loss : 0.028522, loss_ce: 0.009975
2022-01-08 16:13:19,894 iteration 2501 : loss : 0.028865, loss_ce: 0.007778
2022-01-08 16:13:21,334 iteration 2502 : loss : 0.062792, loss_ce: 0.025177
2022-01-08 16:13:22,653 iteration 2503 : loss : 0.034434, loss_ce: 0.012332
2022-01-08 16:13:23,986 iteration 2504 : loss : 0.027794, loss_ce: 0.010049
2022-01-08 16:13:25,394 iteration 2505 : loss : 0.042157, loss_ce: 0.015391
2022-01-08 16:13:26,761 iteration 2506 : loss : 0.039460, loss_ce: 0.013858
2022-01-08 16:13:28,081 iteration 2507 : loss : 0.031810, loss_ce: 0.014185
2022-01-08 16:13:29,426 iteration 2508 : loss : 0.034469, loss_ce: 0.011920
2022-01-08 16:13:30,781 iteration 2509 : loss : 0.027888, loss_ce: 0.009592
2022-01-08 16:13:32,115 iteration 2510 : loss : 0.024615, loss_ce: 0.010688
2022-01-08 16:13:33,495 iteration 2511 : loss : 0.027853, loss_ce: 0.011525
2022-01-08 16:13:34,891 iteration 2512 : loss : 0.032312, loss_ce: 0.012210
2022-01-08 16:13:36,319 iteration 2513 : loss : 0.042984, loss_ce: 0.013285
2022-01-08 16:13:37,700 iteration 2514 : loss : 0.033272, loss_ce: 0.009956
2022-01-08 16:13:39,063 iteration 2515 : loss : 0.029839, loss_ce: 0.018700
2022-01-08 16:13:40,413 iteration 2516 : loss : 0.025882, loss_ce: 0.011647

 37%|█████████▉                 | 148/400 [1:03:34<1:43:15, 24.58s/it]2022-01-08 16:13:41,820 iteration 2517 : loss : 0.026613, loss_ce: 0.010073
2022-01-08 16:13:43,193 iteration 2518 : loss : 0.050984, loss_ce: 0.015178
2022-01-08 16:13:44,587 iteration 2519 : loss : 0.033600, loss_ce: 0.013345
2022-01-08 16:13:45,958 iteration 2520 : loss : 0.038118, loss_ce: 0.016561
2022-01-08 16:13:47,311 iteration 2521 : loss : 0.025015, loss_ce: 0.008987
2022-01-08 16:13:48,691 iteration 2522 : loss : 0.035192, loss_ce: 0.017343
2022-01-08 16:13:50,114 iteration 2523 : loss : 0.046845, loss_ce: 0.010818
2022-01-08 16:13:51,469 iteration 2524 : loss : 0.032236, loss_ce: 0.013443
2022-01-08 16:13:52,852 iteration 2525 : loss : 0.038033, loss_ce: 0.015537
2022-01-08 16:13:54,253 iteration 2526 : loss : 0.032976, loss_ce: 0.012326
2022-01-08 16:13:55,631 iteration 2527 : loss : 0.038074, loss_ce: 0.013412
2022-01-08 16:13:57,026 iteration 2528 : loss : 0.042117, loss_ce: 0.014023
2022-01-08 16:13:58,410 iteration 2529 : loss : 0.043394, loss_ce: 0.015783
2022-01-08 16:13:59,795 iteration 2530 : loss : 0.030003, loss_ce: 0.013979
2022-01-08 16:14:01,242 iteration 2531 : loss : 0.054672, loss_ce: 0.021740
2022-01-08 16:14:02,614 iteration 2532 : loss : 0.038514, loss_ce: 0.013008
2022-01-08 16:14:03,998 iteration 2533 : loss : 0.044178, loss_ce: 0.013309

 37%|██████████                 | 149/400 [1:03:58<1:41:34, 24.28s/it]2022-01-08 16:14:05,358 iteration 2534 : loss : 0.029801, loss_ce: 0.012190
2022-01-08 16:14:06,803 iteration 2535 : loss : 0.049339, loss_ce: 0.017807
2022-01-08 16:14:08,146 iteration 2536 : loss : 0.034638, loss_ce: 0.016001
2022-01-08 16:14:09,491 iteration 2537 : loss : 0.025336, loss_ce: 0.009943
2022-01-08 16:14:10,767 iteration 2538 : loss : 0.027237, loss_ce: 0.011400
2022-01-08 16:14:12,159 iteration 2539 : loss : 0.037597, loss_ce: 0.015568
2022-01-08 16:14:13,485 iteration 2540 : loss : 0.024734, loss_ce: 0.007371
2022-01-08 16:14:14,835 iteration 2541 : loss : 0.035177, loss_ce: 0.015820
2022-01-08 16:14:16,142 iteration 2542 : loss : 0.020561, loss_ce: 0.007065
2022-01-08 16:14:17,456 iteration 2543 : loss : 0.035625, loss_ce: 0.013785
2022-01-08 16:14:18,827 iteration 2544 : loss : 0.029956, loss_ce: 0.010413
2022-01-08 16:14:20,309 iteration 2545 : loss : 0.037632, loss_ce: 0.014720
2022-01-08 16:14:21,803 iteration 2546 : loss : 0.048423, loss_ce: 0.019191
2022-01-08 16:14:23,122 iteration 2547 : loss : 0.025467, loss_ce: 0.012223
2022-01-08 16:14:24,525 iteration 2548 : loss : 0.029100, loss_ce: 0.012445
2022-01-08 16:14:25,908 iteration 2549 : loss : 0.054015, loss_ce: 0.019899
2022-01-08 16:14:25,908 Training Data Eval:
2022-01-08 16:14:32,717   Average segmentation loss on training set: 0.0220
2022-01-08 16:14:32,717 Validation Data Eval:
2022-01-08 16:14:35,070   Average segmentation loss on validation set: 0.0643
2022-01-08 16:14:36,404 iteration 2550 : loss : 0.040211, loss_ce: 0.013213

 38%|██████████▏                | 150/400 [1:04:30<1:51:20, 26.72s/it]2022-01-08 16:14:37,811 iteration 2551 : loss : 0.024808, loss_ce: 0.011700
2022-01-08 16:14:39,235 iteration 2552 : loss : 0.029357, loss_ce: 0.012918
2022-01-08 16:14:40,543 iteration 2553 : loss : 0.019752, loss_ce: 0.006592
2022-01-08 16:14:41,913 iteration 2554 : loss : 0.028238, loss_ce: 0.011339
2022-01-08 16:14:43,269 iteration 2555 : loss : 0.035392, loss_ce: 0.011129
2022-01-08 16:14:44,686 iteration 2556 : loss : 0.038958, loss_ce: 0.016718
2022-01-08 16:14:46,043 iteration 2557 : loss : 0.035077, loss_ce: 0.015305
2022-01-08 16:14:47,423 iteration 2558 : loss : 0.030228, loss_ce: 0.015356
2022-01-08 16:14:48,877 iteration 2559 : loss : 0.040889, loss_ce: 0.016461
2022-01-08 16:14:50,248 iteration 2560 : loss : 0.027417, loss_ce: 0.013364
2022-01-08 16:14:51,700 iteration 2561 : loss : 0.037500, loss_ce: 0.012538
2022-01-08 16:14:53,088 iteration 2562 : loss : 0.040117, loss_ce: 0.018527
2022-01-08 16:14:54,492 iteration 2563 : loss : 0.033242, loss_ce: 0.014595
2022-01-08 16:14:55,826 iteration 2564 : loss : 0.032994, loss_ce: 0.014760
2022-01-08 16:14:57,162 iteration 2565 : loss : 0.057222, loss_ce: 0.030155
2022-01-08 16:14:58,511 iteration 2566 : loss : 0.033333, loss_ce: 0.012447
2022-01-08 16:14:59,891 iteration 2567 : loss : 0.062262, loss_ce: 0.020222

 38%|██████████▏                | 151/400 [1:04:54<1:46:51, 25.75s/it]2022-01-08 16:15:01,344 iteration 2568 : loss : 0.040770, loss_ce: 0.020527
2022-01-08 16:15:02,702 iteration 2569 : loss : 0.028689, loss_ce: 0.012435
2022-01-08 16:15:04,065 iteration 2570 : loss : 0.038306, loss_ce: 0.015657
2022-01-08 16:15:05,427 iteration 2571 : loss : 0.022933, loss_ce: 0.008827
2022-01-08 16:15:06,736 iteration 2572 : loss : 0.031634, loss_ce: 0.008155
2022-01-08 16:15:08,055 iteration 2573 : loss : 0.030133, loss_ce: 0.012035
2022-01-08 16:15:09,402 iteration 2574 : loss : 0.033070, loss_ce: 0.011107
2022-01-08 16:15:10,875 iteration 2575 : loss : 0.051750, loss_ce: 0.020695
2022-01-08 16:15:12,264 iteration 2576 : loss : 0.029838, loss_ce: 0.012376
2022-01-08 16:15:13,644 iteration 2577 : loss : 0.056584, loss_ce: 0.021138
2022-01-08 16:15:15,032 iteration 2578 : loss : 0.035807, loss_ce: 0.011464
2022-01-08 16:15:16,352 iteration 2579 : loss : 0.030625, loss_ce: 0.007549
2022-01-08 16:15:17,782 iteration 2580 : loss : 0.035827, loss_ce: 0.008266
2022-01-08 16:15:19,198 iteration 2581 : loss : 0.049338, loss_ce: 0.023355
2022-01-08 16:15:20,644 iteration 2582 : loss : 0.034222, loss_ce: 0.012691
2022-01-08 16:15:22,007 iteration 2583 : loss : 0.022898, loss_ce: 0.008190
2022-01-08 16:15:23,295 iteration 2584 : loss : 0.033931, loss_ce: 0.013221

 38%|██████████▎                | 152/400 [1:05:17<1:43:32, 25.05s/it]2022-01-08 16:15:24,722 iteration 2585 : loss : 0.027454, loss_ce: 0.008603
2022-01-08 16:15:26,102 iteration 2586 : loss : 0.033855, loss_ce: 0.014560
2022-01-08 16:15:27,411 iteration 2587 : loss : 0.033293, loss_ce: 0.012605
2022-01-08 16:15:28,756 iteration 2588 : loss : 0.032042, loss_ce: 0.014849
2022-01-08 16:15:30,162 iteration 2589 : loss : 0.042825, loss_ce: 0.017669
2022-01-08 16:15:31,579 iteration 2590 : loss : 0.043161, loss_ce: 0.018081
2022-01-08 16:15:32,914 iteration 2591 : loss : 0.028211, loss_ce: 0.009070
2022-01-08 16:15:34,255 iteration 2592 : loss : 0.031177, loss_ce: 0.010648
2022-01-08 16:15:35,600 iteration 2593 : loss : 0.033024, loss_ce: 0.015423
2022-01-08 16:15:37,089 iteration 2594 : loss : 0.052575, loss_ce: 0.020533
2022-01-08 16:15:38,496 iteration 2595 : loss : 0.041608, loss_ce: 0.015439
2022-01-08 16:15:39,836 iteration 2596 : loss : 0.027058, loss_ce: 0.012528
2022-01-08 16:15:41,152 iteration 2597 : loss : 0.033273, loss_ce: 0.011997
2022-01-08 16:15:42,496 iteration 2598 : loss : 0.029515, loss_ce: 0.012482
2022-01-08 16:15:43,853 iteration 2599 : loss : 0.048957, loss_ce: 0.011737
2022-01-08 16:15:45,210 iteration 2600 : loss : 0.032234, loss_ce: 0.011993
2022-01-08 16:15:46,527 iteration 2601 : loss : 0.028549, loss_ce: 0.011496

 38%|██████████▎                | 153/400 [1:05:40<1:40:52, 24.50s/it]2022-01-08 16:15:47,981 iteration 2602 : loss : 0.034457, loss_ce: 0.014165
2022-01-08 16:15:49,282 iteration 2603 : loss : 0.025583, loss_ce: 0.010715
2022-01-08 16:15:50,633 iteration 2604 : loss : 0.026773, loss_ce: 0.009430
2022-01-08 16:15:52,119 iteration 2605 : loss : 0.027785, loss_ce: 0.009480
2022-01-08 16:15:53,484 iteration 2606 : loss : 0.029807, loss_ce: 0.012534
2022-01-08 16:15:54,859 iteration 2607 : loss : 0.028905, loss_ce: 0.011226
2022-01-08 16:15:56,176 iteration 2608 : loss : 0.029138, loss_ce: 0.014343
2022-01-08 16:15:57,509 iteration 2609 : loss : 0.042886, loss_ce: 0.012490
2022-01-08 16:15:58,989 iteration 2610 : loss : 0.048587, loss_ce: 0.020910
2022-01-08 16:16:00,332 iteration 2611 : loss : 0.037709, loss_ce: 0.012998
2022-01-08 16:16:01,604 iteration 2612 : loss : 0.025732, loss_ce: 0.012766
2022-01-08 16:16:02,946 iteration 2613 : loss : 0.040296, loss_ce: 0.014652
2022-01-08 16:16:04,370 iteration 2614 : loss : 0.052405, loss_ce: 0.017329
2022-01-08 16:16:05,710 iteration 2615 : loss : 0.036255, loss_ce: 0.013924
2022-01-08 16:16:07,054 iteration 2616 : loss : 0.032484, loss_ce: 0.012030
2022-01-08 16:16:08,498 iteration 2617 : loss : 0.037373, loss_ce: 0.011501
2022-01-08 16:16:09,885 iteration 2618 : loss : 0.044198, loss_ce: 0.021660

 38%|██████████▍                | 154/400 [1:06:04<1:39:03, 24.16s/it]2022-01-08 16:16:11,363 iteration 2619 : loss : 0.032599, loss_ce: 0.009845
2022-01-08 16:16:12,706 iteration 2620 : loss : 0.032332, loss_ce: 0.013426
2022-01-08 16:16:14,101 iteration 2621 : loss : 0.029727, loss_ce: 0.010552
2022-01-08 16:16:15,499 iteration 2622 : loss : 0.030592, loss_ce: 0.014989
2022-01-08 16:16:16,902 iteration 2623 : loss : 0.059963, loss_ce: 0.029443
2022-01-08 16:16:18,236 iteration 2624 : loss : 0.036576, loss_ce: 0.013267
2022-01-08 16:16:19,582 iteration 2625 : loss : 0.025649, loss_ce: 0.010273
2022-01-08 16:16:21,011 iteration 2626 : loss : 0.031675, loss_ce: 0.014009
2022-01-08 16:16:22,404 iteration 2627 : loss : 0.046791, loss_ce: 0.012588
2022-01-08 16:16:23,737 iteration 2628 : loss : 0.026803, loss_ce: 0.009753
2022-01-08 16:16:25,166 iteration 2629 : loss : 0.042690, loss_ce: 0.013457
2022-01-08 16:16:26,485 iteration 2630 : loss : 0.029298, loss_ce: 0.009893
2022-01-08 16:16:27,872 iteration 2631 : loss : 0.037973, loss_ce: 0.018243
2022-01-08 16:16:29,268 iteration 2632 : loss : 0.036443, loss_ce: 0.016021
2022-01-08 16:16:30,605 iteration 2633 : loss : 0.030312, loss_ce: 0.013008
2022-01-08 16:16:31,995 iteration 2634 : loss : 0.036122, loss_ce: 0.012888
2022-01-08 16:16:31,995 Training Data Eval:
2022-01-08 16:16:38,815   Average segmentation loss on training set: 0.0244
2022-01-08 16:16:38,815 Validation Data Eval:
2022-01-08 16:16:41,174   Average segmentation loss on validation set: 0.0663
2022-01-08 16:16:42,612 iteration 2635 : loss : 0.048335, loss_ce: 0.020946

 39%|██████████▍                | 155/400 [1:06:36<1:49:08, 26.73s/it]2022-01-08 16:16:44,005 iteration 2636 : loss : 0.024492, loss_ce: 0.007650
2022-01-08 16:16:45,499 iteration 2637 : loss : 0.054592, loss_ce: 0.015451
2022-01-08 16:16:46,880 iteration 2638 : loss : 0.029045, loss_ce: 0.011761
2022-01-08 16:16:48,146 iteration 2639 : loss : 0.025660, loss_ce: 0.009218
2022-01-08 16:16:49,468 iteration 2640 : loss : 0.031735, loss_ce: 0.011802
2022-01-08 16:16:50,916 iteration 2641 : loss : 0.043024, loss_ce: 0.016578
2022-01-08 16:16:52,335 iteration 2642 : loss : 0.062194, loss_ce: 0.018587
2022-01-08 16:16:53,751 iteration 2643 : loss : 0.035169, loss_ce: 0.011931
2022-01-08 16:16:55,088 iteration 2644 : loss : 0.034396, loss_ce: 0.010706
2022-01-08 16:16:56,425 iteration 2645 : loss : 0.033867, loss_ce: 0.019472
2022-01-08 16:16:57,772 iteration 2646 : loss : 0.033345, loss_ce: 0.009794
2022-01-08 16:16:59,184 iteration 2647 : loss : 0.036767, loss_ce: 0.013441
2022-01-08 16:17:00,479 iteration 2648 : loss : 0.023297, loss_ce: 0.010076
2022-01-08 16:17:01,884 iteration 2649 : loss : 0.045691, loss_ce: 0.019671
2022-01-08 16:17:03,284 iteration 2650 : loss : 0.036489, loss_ce: 0.013867
2022-01-08 16:17:04,626 iteration 2651 : loss : 0.037299, loss_ce: 0.013353
2022-01-08 16:17:05,994 iteration 2652 : loss : 0.027210, loss_ce: 0.012534

 39%|██████████▌                | 156/400 [1:07:00<1:44:37, 25.73s/it]2022-01-08 16:17:07,515 iteration 2653 : loss : 0.041277, loss_ce: 0.016457
2022-01-08 16:17:08,885 iteration 2654 : loss : 0.032372, loss_ce: 0.013613
2022-01-08 16:17:10,201 iteration 2655 : loss : 0.024597, loss_ce: 0.008775
2022-01-08 16:17:11,499 iteration 2656 : loss : 0.029330, loss_ce: 0.012897
2022-01-08 16:17:12,812 iteration 2657 : loss : 0.024564, loss_ce: 0.008186
2022-01-08 16:17:14,147 iteration 2658 : loss : 0.022376, loss_ce: 0.008983
2022-01-08 16:17:15,627 iteration 2659 : loss : 0.040317, loss_ce: 0.019714
2022-01-08 16:17:16,988 iteration 2660 : loss : 0.027688, loss_ce: 0.009595
2022-01-08 16:17:18,275 iteration 2661 : loss : 0.027879, loss_ce: 0.010673
2022-01-08 16:17:19,690 iteration 2662 : loss : 0.034508, loss_ce: 0.013878
2022-01-08 16:17:21,015 iteration 2663 : loss : 0.038501, loss_ce: 0.014168
2022-01-08 16:17:22,438 iteration 2664 : loss : 0.024114, loss_ce: 0.008095
2022-01-08 16:17:23,792 iteration 2665 : loss : 0.034110, loss_ce: 0.012133
2022-01-08 16:17:25,168 iteration 2666 : loss : 0.033736, loss_ce: 0.010870
2022-01-08 16:17:26,568 iteration 2667 : loss : 0.028016, loss_ce: 0.009630
2022-01-08 16:17:27,960 iteration 2668 : loss : 0.051272, loss_ce: 0.018351
2022-01-08 16:17:29,377 iteration 2669 : loss : 0.028911, loss_ce: 0.010901

 39%|██████████▌                | 157/400 [1:07:23<1:41:20, 25.02s/it]2022-01-08 16:17:30,827 iteration 2670 : loss : 0.041817, loss_ce: 0.010553
2022-01-08 16:17:32,215 iteration 2671 : loss : 0.034468, loss_ce: 0.009309
2022-01-08 16:17:33,613 iteration 2672 : loss : 0.025306, loss_ce: 0.009345
2022-01-08 16:17:35,042 iteration 2673 : loss : 0.046396, loss_ce: 0.018257
2022-01-08 16:17:36,380 iteration 2674 : loss : 0.030590, loss_ce: 0.014491
2022-01-08 16:17:37,803 iteration 2675 : loss : 0.034956, loss_ce: 0.012351
2022-01-08 16:17:39,190 iteration 2676 : loss : 0.029586, loss_ce: 0.007776
2022-01-08 16:17:40,505 iteration 2677 : loss : 0.020475, loss_ce: 0.008727
2022-01-08 16:17:41,805 iteration 2678 : loss : 0.024381, loss_ce: 0.008053
2022-01-08 16:17:43,195 iteration 2679 : loss : 0.035024, loss_ce: 0.015656
2022-01-08 16:17:44,621 iteration 2680 : loss : 0.044822, loss_ce: 0.018790
2022-01-08 16:17:45,983 iteration 2681 : loss : 0.036551, loss_ce: 0.016554
2022-01-08 16:17:47,299 iteration 2682 : loss : 0.023657, loss_ce: 0.009820
2022-01-08 16:17:48,677 iteration 2683 : loss : 0.030772, loss_ce: 0.014572
2022-01-08 16:17:50,044 iteration 2684 : loss : 0.046216, loss_ce: 0.012811
2022-01-08 16:17:51,414 iteration 2685 : loss : 0.035012, loss_ce: 0.018562
2022-01-08 16:17:52,774 iteration 2686 : loss : 0.031607, loss_ce: 0.012576

 40%|██████████▋                | 158/400 [1:07:47<1:38:57, 24.54s/it]2022-01-08 16:17:54,176 iteration 2687 : loss : 0.021696, loss_ce: 0.010063
2022-01-08 16:17:55,524 iteration 2688 : loss : 0.036326, loss_ce: 0.011769
2022-01-08 16:17:56,789 iteration 2689 : loss : 0.023997, loss_ce: 0.009388
2022-01-08 16:17:58,137 iteration 2690 : loss : 0.029914, loss_ce: 0.012492
2022-01-08 16:17:59,516 iteration 2691 : loss : 0.026435, loss_ce: 0.009672
2022-01-08 16:18:00,875 iteration 2692 : loss : 0.031342, loss_ce: 0.010750
2022-01-08 16:18:02,208 iteration 2693 : loss : 0.034695, loss_ce: 0.015480
2022-01-08 16:18:03,491 iteration 2694 : loss : 0.025734, loss_ce: 0.009918
2022-01-08 16:18:04,899 iteration 2695 : loss : 0.035535, loss_ce: 0.013335
2022-01-08 16:18:06,364 iteration 2696 : loss : 0.050133, loss_ce: 0.019720
2022-01-08 16:18:07,792 iteration 2697 : loss : 0.036891, loss_ce: 0.019783
2022-01-08 16:18:09,109 iteration 2698 : loss : 0.022967, loss_ce: 0.008804
2022-01-08 16:18:10,437 iteration 2699 : loss : 0.025340, loss_ce: 0.008554
2022-01-08 16:18:11,768 iteration 2700 : loss : 0.033509, loss_ce: 0.010355
2022-01-08 16:18:13,137 iteration 2701 : loss : 0.030310, loss_ce: 0.013384
2022-01-08 16:18:14,537 iteration 2702 : loss : 0.047255, loss_ce: 0.011123
2022-01-08 16:18:15,948 iteration 2703 : loss : 0.042565, loss_ce: 0.014095

 40%|██████████▋                | 159/400 [1:08:10<1:36:54, 24.13s/it]2022-01-08 16:18:17,324 iteration 2704 : loss : 0.023192, loss_ce: 0.007296
2022-01-08 16:18:18,644 iteration 2705 : loss : 0.025663, loss_ce: 0.008914
2022-01-08 16:18:20,038 iteration 2706 : loss : 0.047223, loss_ce: 0.023419
2022-01-08 16:18:21,403 iteration 2707 : loss : 0.026768, loss_ce: 0.010028
2022-01-08 16:18:22,752 iteration 2708 : loss : 0.038237, loss_ce: 0.012884
2022-01-08 16:18:24,185 iteration 2709 : loss : 0.034975, loss_ce: 0.012129
2022-01-08 16:18:25,598 iteration 2710 : loss : 0.049982, loss_ce: 0.022517
2022-01-08 16:18:26,942 iteration 2711 : loss : 0.029901, loss_ce: 0.010091
2022-01-08 16:18:28,293 iteration 2712 : loss : 0.055217, loss_ce: 0.020819
2022-01-08 16:18:29,673 iteration 2713 : loss : 0.025643, loss_ce: 0.009021
2022-01-08 16:18:31,044 iteration 2714 : loss : 0.035957, loss_ce: 0.014775
2022-01-08 16:18:32,402 iteration 2715 : loss : 0.031128, loss_ce: 0.016419
2022-01-08 16:18:33,754 iteration 2716 : loss : 0.048953, loss_ce: 0.013397
2022-01-08 16:18:35,065 iteration 2717 : loss : 0.028796, loss_ce: 0.011325
2022-01-08 16:18:36,458 iteration 2718 : loss : 0.036988, loss_ce: 0.013110
2022-01-08 16:18:37,792 iteration 2719 : loss : 0.025136, loss_ce: 0.011692
2022-01-08 16:18:37,792 Training Data Eval:
2022-01-08 16:18:44,625   Average segmentation loss on training set: 0.0257
2022-01-08 16:18:44,626 Validation Data Eval:
2022-01-08 16:18:46,983   Average segmentation loss on validation set: 0.0731
2022-01-08 16:18:48,328 iteration 2720 : loss : 0.041267, loss_ce: 0.023577

 40%|██████████▊                | 160/400 [1:08:42<1:46:23, 26.60s/it]2022-01-08 16:18:49,753 iteration 2721 : loss : 0.033786, loss_ce: 0.011792
2022-01-08 16:18:51,146 iteration 2722 : loss : 0.029450, loss_ce: 0.016412
2022-01-08 16:18:52,590 iteration 2723 : loss : 0.033090, loss_ce: 0.014708
2022-01-08 16:18:53,905 iteration 2724 : loss : 0.036717, loss_ce: 0.012659
2022-01-08 16:18:55,255 iteration 2725 : loss : 0.038960, loss_ce: 0.012438
2022-01-08 16:18:56,688 iteration 2726 : loss : 0.046691, loss_ce: 0.016620
2022-01-08 16:18:58,050 iteration 2727 : loss : 0.030285, loss_ce: 0.010614
2022-01-08 16:18:59,460 iteration 2728 : loss : 0.038686, loss_ce: 0.017132
2022-01-08 16:19:00,863 iteration 2729 : loss : 0.053028, loss_ce: 0.025593
2022-01-08 16:19:02,297 iteration 2730 : loss : 0.044332, loss_ce: 0.020318
2022-01-08 16:19:03,658 iteration 2731 : loss : 0.039612, loss_ce: 0.014872
2022-01-08 16:19:04,942 iteration 2732 : loss : 0.023821, loss_ce: 0.009307
2022-01-08 16:19:06,301 iteration 2733 : loss : 0.022368, loss_ce: 0.010472
2022-01-08 16:19:07,678 iteration 2734 : loss : 0.054203, loss_ce: 0.013843
2022-01-08 16:19:09,057 iteration 2735 : loss : 0.026275, loss_ce: 0.012668
2022-01-08 16:19:10,407 iteration 2736 : loss : 0.038092, loss_ce: 0.012323
2022-01-08 16:19:11,758 iteration 2737 : loss : 0.046342, loss_ce: 0.013250

 40%|██████████▊                | 161/400 [1:09:06<1:42:10, 25.65s/it]2022-01-08 16:19:13,219 iteration 2738 : loss : 0.043868, loss_ce: 0.021001
2022-01-08 16:19:14,538 iteration 2739 : loss : 0.047512, loss_ce: 0.011879
2022-01-08 16:19:15,984 iteration 2740 : loss : 0.040174, loss_ce: 0.015537
2022-01-08 16:19:17,349 iteration 2741 : loss : 0.036242, loss_ce: 0.015918
2022-01-08 16:19:18,727 iteration 2742 : loss : 0.041237, loss_ce: 0.016862
2022-01-08 16:19:20,041 iteration 2743 : loss : 0.036309, loss_ce: 0.012948
2022-01-08 16:19:21,423 iteration 2744 : loss : 0.029865, loss_ce: 0.009750
2022-01-08 16:19:22,748 iteration 2745 : loss : 0.026362, loss_ce: 0.008263
2022-01-08 16:19:24,206 iteration 2746 : loss : 0.067845, loss_ce: 0.018596
2022-01-08 16:19:25,546 iteration 2747 : loss : 0.027638, loss_ce: 0.010510
2022-01-08 16:19:26,960 iteration 2748 : loss : 0.026254, loss_ce: 0.007444
2022-01-08 16:19:28,397 iteration 2749 : loss : 0.036724, loss_ce: 0.014677
2022-01-08 16:19:29,750 iteration 2750 : loss : 0.028142, loss_ce: 0.011389
2022-01-08 16:19:31,116 iteration 2751 : loss : 0.054865, loss_ce: 0.014975
2022-01-08 16:19:32,579 iteration 2752 : loss : 0.043999, loss_ce: 0.017823
2022-01-08 16:19:34,048 iteration 2753 : loss : 0.031273, loss_ce: 0.013920
2022-01-08 16:19:35,434 iteration 2754 : loss : 0.037359, loss_ce: 0.020792

 40%|██████████▉                | 162/400 [1:09:29<1:39:23, 25.06s/it]2022-01-08 16:19:36,732 iteration 2755 : loss : 0.030217, loss_ce: 0.009981
2022-01-08 16:19:38,117 iteration 2756 : loss : 0.042687, loss_ce: 0.019195
2022-01-08 16:19:39,486 iteration 2757 : loss : 0.032044, loss_ce: 0.012732
2022-01-08 16:19:40,849 iteration 2758 : loss : 0.034128, loss_ce: 0.012284
2022-01-08 16:19:42,216 iteration 2759 : loss : 0.042281, loss_ce: 0.016632
2022-01-08 16:19:43,585 iteration 2760 : loss : 0.029873, loss_ce: 0.012818
2022-01-08 16:19:44,987 iteration 2761 : loss : 0.030733, loss_ce: 0.011093
2022-01-08 16:19:46,352 iteration 2762 : loss : 0.022349, loss_ce: 0.009301
2022-01-08 16:19:47,746 iteration 2763 : loss : 0.048418, loss_ce: 0.013593
2022-01-08 16:19:49,058 iteration 2764 : loss : 0.030353, loss_ce: 0.010214
2022-01-08 16:19:50,525 iteration 2765 : loss : 0.028332, loss_ce: 0.010440
2022-01-08 16:19:51,825 iteration 2766 : loss : 0.041468, loss_ce: 0.015117
2022-01-08 16:19:53,200 iteration 2767 : loss : 0.031565, loss_ce: 0.013921
2022-01-08 16:19:54,543 iteration 2768 : loss : 0.036789, loss_ce: 0.012106
2022-01-08 16:19:55,846 iteration 2769 : loss : 0.025031, loss_ce: 0.010915
2022-01-08 16:19:57,175 iteration 2770 : loss : 0.047873, loss_ce: 0.022167
2022-01-08 16:19:58,531 iteration 2771 : loss : 0.027718, loss_ce: 0.011330

 41%|███████████                | 163/400 [1:09:52<1:36:39, 24.47s/it]2022-01-08 16:19:59,887 iteration 2772 : loss : 0.043048, loss_ce: 0.014465
2022-01-08 16:20:01,263 iteration 2773 : loss : 0.029694, loss_ce: 0.011896
2022-01-08 16:20:02,637 iteration 2774 : loss : 0.031544, loss_ce: 0.008171
2022-01-08 16:20:04,016 iteration 2775 : loss : 0.034156, loss_ce: 0.015930
2022-01-08 16:20:05,364 iteration 2776 : loss : 0.029734, loss_ce: 0.010565
2022-01-08 16:20:06,785 iteration 2777 : loss : 0.024612, loss_ce: 0.008773
2022-01-08 16:20:08,112 iteration 2778 : loss : 0.034250, loss_ce: 0.012167
2022-01-08 16:20:09,444 iteration 2779 : loss : 0.023539, loss_ce: 0.009192
2022-01-08 16:20:10,797 iteration 2780 : loss : 0.025090, loss_ce: 0.011405
2022-01-08 16:20:12,275 iteration 2781 : loss : 0.039354, loss_ce: 0.017658
2022-01-08 16:20:13,718 iteration 2782 : loss : 0.033317, loss_ce: 0.014205
2022-01-08 16:20:15,076 iteration 2783 : loss : 0.033125, loss_ce: 0.010866
2022-01-08 16:20:16,342 iteration 2784 : loss : 0.036413, loss_ce: 0.010666
2022-01-08 16:20:17,658 iteration 2785 : loss : 0.025699, loss_ce: 0.011412
2022-01-08 16:20:18,993 iteration 2786 : loss : 0.024110, loss_ce: 0.009557
2022-01-08 16:20:20,318 iteration 2787 : loss : 0.025469, loss_ce: 0.009581
2022-01-08 16:20:21,810 iteration 2788 : loss : 0.032968, loss_ce: 0.012725

 41%|███████████                | 164/400 [1:10:16<1:34:50, 24.11s/it]2022-01-08 16:20:23,289 iteration 2789 : loss : 0.027455, loss_ce: 0.008020
2022-01-08 16:20:24,763 iteration 2790 : loss : 0.035328, loss_ce: 0.014206
2022-01-08 16:20:26,082 iteration 2791 : loss : 0.021187, loss_ce: 0.007344
2022-01-08 16:20:27,448 iteration 2792 : loss : 0.027970, loss_ce: 0.011308
2022-01-08 16:20:28,826 iteration 2793 : loss : 0.028367, loss_ce: 0.009944
2022-01-08 16:20:30,267 iteration 2794 : loss : 0.042653, loss_ce: 0.021434
2022-01-08 16:20:31,640 iteration 2795 : loss : 0.034217, loss_ce: 0.012585
2022-01-08 16:20:32,991 iteration 2796 : loss : 0.038089, loss_ce: 0.014220
2022-01-08 16:20:34,421 iteration 2797 : loss : 0.030682, loss_ce: 0.014260
2022-01-08 16:20:35,824 iteration 2798 : loss : 0.033267, loss_ce: 0.009752
2022-01-08 16:20:37,301 iteration 2799 : loss : 0.035478, loss_ce: 0.012616
2022-01-08 16:20:38,687 iteration 2800 : loss : 0.029831, loss_ce: 0.015119
2022-01-08 16:20:39,975 iteration 2801 : loss : 0.042936, loss_ce: 0.012945
2022-01-08 16:20:41,297 iteration 2802 : loss : 0.022441, loss_ce: 0.008380
2022-01-08 16:20:42,679 iteration 2803 : loss : 0.032388, loss_ce: 0.011576
2022-01-08 16:20:43,967 iteration 2804 : loss : 0.035230, loss_ce: 0.015534
2022-01-08 16:20:43,967 Training Data Eval:
2022-01-08 16:20:50,809   Average segmentation loss on training set: 0.0193
2022-01-08 16:20:50,809 Validation Data Eval:
2022-01-08 16:20:53,170   Average segmentation loss on validation set: 0.0659
2022-01-08 16:20:54,646 iteration 2805 : loss : 0.042626, loss_ce: 0.017223

 41%|███████████▏               | 165/400 [1:10:48<1:44:42, 26.73s/it]2022-01-08 16:20:56,167 iteration 2806 : loss : 0.024443, loss_ce: 0.010706
2022-01-08 16:20:57,634 iteration 2807 : loss : 0.042155, loss_ce: 0.010934
2022-01-08 16:20:59,074 iteration 2808 : loss : 0.041166, loss_ce: 0.015079
2022-01-08 16:21:00,473 iteration 2809 : loss : 0.027438, loss_ce: 0.010243
2022-01-08 16:21:01,784 iteration 2810 : loss : 0.042149, loss_ce: 0.013771
2022-01-08 16:21:03,206 iteration 2811 : loss : 0.025930, loss_ce: 0.012454
2022-01-08 16:21:04,518 iteration 2812 : loss : 0.021263, loss_ce: 0.008672
2022-01-08 16:21:05,966 iteration 2813 : loss : 0.036336, loss_ce: 0.015702
2022-01-08 16:21:07,357 iteration 2814 : loss : 0.029796, loss_ce: 0.010723
2022-01-08 16:21:08,736 iteration 2815 : loss : 0.026146, loss_ce: 0.011746
2022-01-08 16:21:10,107 iteration 2816 : loss : 0.025543, loss_ce: 0.008516
2022-01-08 16:21:11,562 iteration 2817 : loss : 0.038454, loss_ce: 0.007198
2022-01-08 16:21:13,023 iteration 2818 : loss : 0.037553, loss_ce: 0.014287
2022-01-08 16:21:14,383 iteration 2819 : loss : 0.029146, loss_ce: 0.013383
2022-01-08 16:21:15,862 iteration 2820 : loss : 0.044060, loss_ce: 0.012155
2022-01-08 16:21:17,309 iteration 2821 : loss : 0.048630, loss_ce: 0.016710
2022-01-08 16:21:18,734 iteration 2822 : loss : 0.029647, loss_ce: 0.010768

 42%|███████████▏               | 166/400 [1:11:12<1:41:09, 25.94s/it]2022-01-08 16:21:20,279 iteration 2823 : loss : 0.041761, loss_ce: 0.017207
2022-01-08 16:21:21,628 iteration 2824 : loss : 0.026945, loss_ce: 0.013269
2022-01-08 16:21:23,015 iteration 2825 : loss : 0.028890, loss_ce: 0.011414
2022-01-08 16:21:24,502 iteration 2826 : loss : 0.045447, loss_ce: 0.019481
2022-01-08 16:21:26,005 iteration 2827 : loss : 0.045711, loss_ce: 0.014190
2022-01-08 16:21:27,417 iteration 2828 : loss : 0.030309, loss_ce: 0.010192
2022-01-08 16:21:28,800 iteration 2829 : loss : 0.035990, loss_ce: 0.017825
2022-01-08 16:21:30,171 iteration 2830 : loss : 0.033774, loss_ce: 0.012132
2022-01-08 16:21:31,453 iteration 2831 : loss : 0.025074, loss_ce: 0.010627
2022-01-08 16:21:32,966 iteration 2832 : loss : 0.026208, loss_ce: 0.012257
2022-01-08 16:21:34,336 iteration 2833 : loss : 0.034831, loss_ce: 0.012695
2022-01-08 16:21:35,782 iteration 2834 : loss : 0.054405, loss_ce: 0.018988
2022-01-08 16:21:37,203 iteration 2835 : loss : 0.047753, loss_ce: 0.013636
2022-01-08 16:21:38,580 iteration 2836 : loss : 0.033323, loss_ce: 0.011671
2022-01-08 16:21:40,023 iteration 2837 : loss : 0.048818, loss_ce: 0.023188
2022-01-08 16:21:41,346 iteration 2838 : loss : 0.023965, loss_ce: 0.010645
2022-01-08 16:21:42,761 iteration 2839 : loss : 0.026239, loss_ce: 0.010276

 42%|███████████▎               | 167/400 [1:11:37<1:38:29, 25.36s/it]2022-01-08 16:21:44,256 iteration 2840 : loss : 0.030890, loss_ce: 0.011412
2022-01-08 16:21:45,621 iteration 2841 : loss : 0.031331, loss_ce: 0.009542
2022-01-08 16:21:46,986 iteration 2842 : loss : 0.025919, loss_ce: 0.008346
2022-01-08 16:21:48,413 iteration 2843 : loss : 0.032471, loss_ce: 0.009686
2022-01-08 16:21:49,806 iteration 2844 : loss : 0.031263, loss_ce: 0.012297
2022-01-08 16:21:51,180 iteration 2845 : loss : 0.029326, loss_ce: 0.011091
2022-01-08 16:21:52,561 iteration 2846 : loss : 0.022741, loss_ce: 0.007839
2022-01-08 16:21:53,818 iteration 2847 : loss : 0.018405, loss_ce: 0.009488
2022-01-08 16:21:55,201 iteration 2848 : loss : 0.034510, loss_ce: 0.012181
2022-01-08 16:21:56,630 iteration 2849 : loss : 0.034151, loss_ce: 0.013099
2022-01-08 16:21:58,042 iteration 2850 : loss : 0.037022, loss_ce: 0.012188
2022-01-08 16:21:59,467 iteration 2851 : loss : 0.028132, loss_ce: 0.010242
2022-01-08 16:22:00,865 iteration 2852 : loss : 0.043801, loss_ce: 0.010307
2022-01-08 16:22:02,302 iteration 2853 : loss : 0.024566, loss_ce: 0.008678
2022-01-08 16:22:03,711 iteration 2854 : loss : 0.036857, loss_ce: 0.014218
2022-01-08 16:22:05,055 iteration 2855 : loss : 0.035492, loss_ce: 0.018610
2022-01-08 16:22:06,467 iteration 2856 : loss : 0.037249, loss_ce: 0.017765

 42%|███████████▎               | 168/400 [1:12:00<1:36:09, 24.87s/it]2022-01-08 16:22:07,820 iteration 2857 : loss : 0.022956, loss_ce: 0.007909
2022-01-08 16:22:09,213 iteration 2858 : loss : 0.023534, loss_ce: 0.009991
2022-01-08 16:22:10,571 iteration 2859 : loss : 0.021425, loss_ce: 0.008693
2022-01-08 16:22:11,999 iteration 2860 : loss : 0.046246, loss_ce: 0.015199
2022-01-08 16:22:13,299 iteration 2861 : loss : 0.026346, loss_ce: 0.011355
2022-01-08 16:22:14,779 iteration 2862 : loss : 0.068613, loss_ce: 0.021297
2022-01-08 16:22:16,118 iteration 2863 : loss : 0.032921, loss_ce: 0.009784
2022-01-08 16:22:17,533 iteration 2864 : loss : 0.024326, loss_ce: 0.009190
2022-01-08 16:22:18,961 iteration 2865 : loss : 0.034235, loss_ce: 0.016233
2022-01-08 16:22:20,317 iteration 2866 : loss : 0.029056, loss_ce: 0.010557
2022-01-08 16:22:21,795 iteration 2867 : loss : 0.041368, loss_ce: 0.015116
2022-01-08 16:22:23,155 iteration 2868 : loss : 0.027338, loss_ce: 0.009098
2022-01-08 16:22:24,659 iteration 2869 : loss : 0.038211, loss_ce: 0.014984
2022-01-08 16:22:26,074 iteration 2870 : loss : 0.024190, loss_ce: 0.008120
2022-01-08 16:22:27,429 iteration 2871 : loss : 0.024874, loss_ce: 0.009669
2022-01-08 16:22:28,732 iteration 2872 : loss : 0.029902, loss_ce: 0.011505
2022-01-08 16:22:30,157 iteration 2873 : loss : 0.030113, loss_ce: 0.009266

 42%|███████████▍               | 169/400 [1:12:24<1:34:23, 24.52s/it]2022-01-08 16:22:31,630 iteration 2874 : loss : 0.034080, loss_ce: 0.011183
2022-01-08 16:22:33,018 iteration 2875 : loss : 0.032577, loss_ce: 0.012013
2022-01-08 16:22:34,404 iteration 2876 : loss : 0.033858, loss_ce: 0.013719
2022-01-08 16:22:35,838 iteration 2877 : loss : 0.039898, loss_ce: 0.012159
2022-01-08 16:22:37,217 iteration 2878 : loss : 0.033788, loss_ce: 0.016051
2022-01-08 16:22:38,643 iteration 2879 : loss : 0.023704, loss_ce: 0.008212
2022-01-08 16:22:40,078 iteration 2880 : loss : 0.037353, loss_ce: 0.012087
2022-01-08 16:22:41,466 iteration 2881 : loss : 0.026895, loss_ce: 0.010936
2022-01-08 16:22:42,899 iteration 2882 : loss : 0.028998, loss_ce: 0.014292
2022-01-08 16:22:44,249 iteration 2883 : loss : 0.044375, loss_ce: 0.022086
2022-01-08 16:22:45,610 iteration 2884 : loss : 0.025833, loss_ce: 0.010601
2022-01-08 16:22:47,011 iteration 2885 : loss : 0.026666, loss_ce: 0.010527
2022-01-08 16:22:48,306 iteration 2886 : loss : 0.037549, loss_ce: 0.011428
2022-01-08 16:22:49,749 iteration 2887 : loss : 0.050342, loss_ce: 0.024923
2022-01-08 16:22:51,138 iteration 2888 : loss : 0.050571, loss_ce: 0.011910
2022-01-08 16:22:52,620 iteration 2889 : loss : 0.026278, loss_ce: 0.008713
2022-01-08 16:22:52,620 Training Data Eval:
2022-01-08 16:22:59,442   Average segmentation loss on training set: 0.0214
2022-01-08 16:22:59,443 Validation Data Eval:
2022-01-08 16:23:01,794   Average segmentation loss on validation set: 0.0624
2022-01-08 16:23:07,513 Found new lowest validation loss at iteration 2889! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_KEYS_best_val_loss_seed1234.pth
2022-01-08 16:23:09,000 iteration 2890 : loss : 0.023170, loss_ce: 0.007850

 42%|███████████▍               | 170/400 [1:13:03<1:50:26, 28.81s/it]2022-01-08 16:23:10,458 iteration 2891 : loss : 0.027898, loss_ce: 0.011982
2022-01-08 16:23:11,913 iteration 2892 : loss : 0.028932, loss_ce: 0.007664
2022-01-08 16:23:13,248 iteration 2893 : loss : 0.030827, loss_ce: 0.008347
2022-01-08 16:23:14,693 iteration 2894 : loss : 0.039098, loss_ce: 0.010945
2022-01-08 16:23:16,128 iteration 2895 : loss : 0.034395, loss_ce: 0.015776
2022-01-08 16:23:17,474 iteration 2896 : loss : 0.025798, loss_ce: 0.007689
2022-01-08 16:23:18,855 iteration 2897 : loss : 0.041362, loss_ce: 0.018599
2022-01-08 16:23:20,175 iteration 2898 : loss : 0.028133, loss_ce: 0.012650
2022-01-08 16:23:21,581 iteration 2899 : loss : 0.028118, loss_ce: 0.010153
2022-01-08 16:23:22,948 iteration 2900 : loss : 0.020867, loss_ce: 0.006618
2022-01-08 16:23:24,332 iteration 2901 : loss : 0.033646, loss_ce: 0.008634
2022-01-08 16:23:25,639 iteration 2902 : loss : 0.027776, loss_ce: 0.010209
2022-01-08 16:23:26,977 iteration 2903 : loss : 0.027018, loss_ce: 0.012259
2022-01-08 16:23:28,304 iteration 2904 : loss : 0.025556, loss_ce: 0.010532
2022-01-08 16:23:29,606 iteration 2905 : loss : 0.029080, loss_ce: 0.014132
2022-01-08 16:23:31,016 iteration 2906 : loss : 0.031177, loss_ce: 0.015661
2022-01-08 16:23:32,352 iteration 2907 : loss : 0.025380, loss_ce: 0.008951

 43%|███████████▌               | 171/400 [1:13:26<1:43:43, 27.18s/it]2022-01-08 16:23:33,817 iteration 2908 : loss : 0.036690, loss_ce: 0.018222
2022-01-08 16:23:35,245 iteration 2909 : loss : 0.028341, loss_ce: 0.013077
2022-01-08 16:23:36,629 iteration 2910 : loss : 0.027996, loss_ce: 0.010532
2022-01-08 16:23:38,052 iteration 2911 : loss : 0.030553, loss_ce: 0.010729
2022-01-08 16:23:39,404 iteration 2912 : loss : 0.024751, loss_ce: 0.009478
2022-01-08 16:23:40,841 iteration 2913 : loss : 0.034718, loss_ce: 0.013609
2022-01-08 16:23:42,195 iteration 2914 : loss : 0.036597, loss_ce: 0.012950
2022-01-08 16:23:43,557 iteration 2915 : loss : 0.022274, loss_ce: 0.009378
2022-01-08 16:23:44,951 iteration 2916 : loss : 0.022947, loss_ce: 0.009107
2022-01-08 16:23:46,260 iteration 2917 : loss : 0.028452, loss_ce: 0.012968
2022-01-08 16:23:47,596 iteration 2918 : loss : 0.026022, loss_ce: 0.006041
2022-01-08 16:23:48,967 iteration 2919 : loss : 0.030228, loss_ce: 0.009084
2022-01-08 16:23:50,360 iteration 2920 : loss : 0.032022, loss_ce: 0.012325
2022-01-08 16:23:51,722 iteration 2921 : loss : 0.025539, loss_ce: 0.010794
2022-01-08 16:23:53,025 iteration 2922 : loss : 0.028088, loss_ce: 0.009968
2022-01-08 16:23:54,368 iteration 2923 : loss : 0.028113, loss_ce: 0.008805
2022-01-08 16:23:55,742 iteration 2924 : loss : 0.036379, loss_ce: 0.012571

 43%|███████████▌               | 172/400 [1:13:49<1:38:56, 26.04s/it]2022-01-08 16:23:57,074 iteration 2925 : loss : 0.021080, loss_ce: 0.010531
2022-01-08 16:23:58,528 iteration 2926 : loss : 0.032040, loss_ce: 0.014312
2022-01-08 16:23:59,900 iteration 2927 : loss : 0.025114, loss_ce: 0.010048
2022-01-08 16:24:01,162 iteration 2928 : loss : 0.027335, loss_ce: 0.008053
2022-01-08 16:24:02,504 iteration 2929 : loss : 0.022509, loss_ce: 0.009709
2022-01-08 16:24:03,951 iteration 2930 : loss : 0.031986, loss_ce: 0.015072
2022-01-08 16:24:05,300 iteration 2931 : loss : 0.027100, loss_ce: 0.009773
2022-01-08 16:24:06,625 iteration 2932 : loss : 0.034082, loss_ce: 0.011508
2022-01-08 16:24:08,066 iteration 2933 : loss : 0.029373, loss_ce: 0.009900
2022-01-08 16:24:09,435 iteration 2934 : loss : 0.031169, loss_ce: 0.010178
2022-01-08 16:24:10,818 iteration 2935 : loss : 0.024260, loss_ce: 0.008280
2022-01-08 16:24:12,181 iteration 2936 : loss : 0.022787, loss_ce: 0.006631
2022-01-08 16:24:13,574 iteration 2937 : loss : 0.024654, loss_ce: 0.011979
2022-01-08 16:24:14,991 iteration 2938 : loss : 0.031500, loss_ce: 0.008871
2022-01-08 16:24:16,456 iteration 2939 : loss : 0.028329, loss_ce: 0.010387
2022-01-08 16:24:17,956 iteration 2940 : loss : 0.035408, loss_ce: 0.017053
2022-01-08 16:24:19,299 iteration 2941 : loss : 0.021461, loss_ce: 0.007922

 43%|███████████▋               | 173/400 [1:14:13<1:35:42, 25.30s/it]2022-01-08 16:24:20,697 iteration 2942 : loss : 0.021714, loss_ce: 0.007064
2022-01-08 16:24:22,118 iteration 2943 : loss : 0.034671, loss_ce: 0.011086
2022-01-08 16:24:23,469 iteration 2944 : loss : 0.024966, loss_ce: 0.013408
2022-01-08 16:24:24,874 iteration 2945 : loss : 0.024611, loss_ce: 0.006502
2022-01-08 16:24:26,159 iteration 2946 : loss : 0.022757, loss_ce: 0.009228
2022-01-08 16:24:27,514 iteration 2947 : loss : 0.033258, loss_ce: 0.014704
2022-01-08 16:24:28,858 iteration 2948 : loss : 0.024612, loss_ce: 0.006536
2022-01-08 16:24:30,339 iteration 2949 : loss : 0.033275, loss_ce: 0.013604
2022-01-08 16:24:31,747 iteration 2950 : loss : 0.023613, loss_ce: 0.009894
2022-01-08 16:24:33,213 iteration 2951 : loss : 0.026044, loss_ce: 0.010876
2022-01-08 16:24:34,638 iteration 2952 : loss : 0.025953, loss_ce: 0.008895
2022-01-08 16:24:36,106 iteration 2953 : loss : 0.034794, loss_ce: 0.015462
2022-01-08 16:24:37,633 iteration 2954 : loss : 0.052891, loss_ce: 0.014038
2022-01-08 16:24:38,987 iteration 2955 : loss : 0.023393, loss_ce: 0.009937
2022-01-08 16:24:40,341 iteration 2956 : loss : 0.023326, loss_ce: 0.010373
2022-01-08 16:24:41,669 iteration 2957 : loss : 0.026874, loss_ce: 0.011048
2022-01-08 16:24:43,060 iteration 2958 : loss : 0.033315, loss_ce: 0.015725

 44%|███████████▋               | 174/400 [1:14:37<1:33:31, 24.83s/it]2022-01-08 16:24:44,479 iteration 2959 : loss : 0.029818, loss_ce: 0.009895
2022-01-08 16:24:45,858 iteration 2960 : loss : 0.026653, loss_ce: 0.011955
2022-01-08 16:24:47,282 iteration 2961 : loss : 0.028543, loss_ce: 0.010438
2022-01-08 16:24:48,811 iteration 2962 : loss : 0.026871, loss_ce: 0.009152
2022-01-08 16:24:50,214 iteration 2963 : loss : 0.028360, loss_ce: 0.010422
2022-01-08 16:24:51,520 iteration 2964 : loss : 0.022643, loss_ce: 0.007717
2022-01-08 16:24:52,922 iteration 2965 : loss : 0.023375, loss_ce: 0.011678
2022-01-08 16:24:54,358 iteration 2966 : loss : 0.028470, loss_ce: 0.009025
2022-01-08 16:24:55,734 iteration 2967 : loss : 0.040149, loss_ce: 0.019471
2022-01-08 16:24:57,127 iteration 2968 : loss : 0.030956, loss_ce: 0.011999
2022-01-08 16:24:58,500 iteration 2969 : loss : 0.029284, loss_ce: 0.014771
2022-01-08 16:24:59,905 iteration 2970 : loss : 0.031442, loss_ce: 0.012276
2022-01-08 16:25:01,276 iteration 2971 : loss : 0.022744, loss_ce: 0.009404
2022-01-08 16:25:02,663 iteration 2972 : loss : 0.027466, loss_ce: 0.011973
2022-01-08 16:25:03,999 iteration 2973 : loss : 0.024214, loss_ce: 0.005987
2022-01-08 16:25:05,445 iteration 2974 : loss : 0.048445, loss_ce: 0.015381
2022-01-08 16:25:05,445 Training Data Eval:
2022-01-08 16:25:12,318   Average segmentation loss on training set: 0.0181
2022-01-08 16:25:12,318 Validation Data Eval:
2022-01-08 16:25:14,696   Average segmentation loss on validation set: 0.0627
2022-01-08 16:25:16,073 iteration 2975 : loss : 0.020137, loss_ce: 0.007918

 44%|███████████▊               | 175/400 [1:15:10<1:42:20, 27.29s/it]2022-01-08 16:25:17,442 iteration 2976 : loss : 0.021437, loss_ce: 0.009403
2022-01-08 16:25:18,885 iteration 2977 : loss : 0.036663, loss_ce: 0.017748
2022-01-08 16:25:20,319 iteration 2978 : loss : 0.025263, loss_ce: 0.008010
2022-01-08 16:25:21,793 iteration 2979 : loss : 0.029902, loss_ce: 0.010979
2022-01-08 16:25:23,250 iteration 2980 : loss : 0.033820, loss_ce: 0.010307
2022-01-08 16:25:24,787 iteration 2981 : loss : 0.046174, loss_ce: 0.020042
2022-01-08 16:25:26,212 iteration 2982 : loss : 0.021217, loss_ce: 0.007846
2022-01-08 16:25:27,637 iteration 2983 : loss : 0.030100, loss_ce: 0.010028
2022-01-08 16:25:29,050 iteration 2984 : loss : 0.037529, loss_ce: 0.012037
2022-01-08 16:25:30,534 iteration 2985 : loss : 0.029850, loss_ce: 0.010587
2022-01-08 16:25:31,880 iteration 2986 : loss : 0.022982, loss_ce: 0.010007
2022-01-08 16:25:33,299 iteration 2987 : loss : 0.036309, loss_ce: 0.011374
2022-01-08 16:25:34,770 iteration 2988 : loss : 0.025100, loss_ce: 0.009242
2022-01-08 16:25:36,244 iteration 2989 : loss : 0.058576, loss_ce: 0.027276
2022-01-08 16:25:37,594 iteration 2990 : loss : 0.027358, loss_ce: 0.011674
2022-01-08 16:25:39,002 iteration 2991 : loss : 0.030927, loss_ce: 0.012186
2022-01-08 16:25:40,503 iteration 2992 : loss : 0.025913, loss_ce: 0.011116

 44%|███████████▉               | 176/400 [1:15:34<1:38:40, 26.43s/it]2022-01-08 16:25:41,920 iteration 2993 : loss : 0.024570, loss_ce: 0.012068
2022-01-08 16:25:43,373 iteration 2994 : loss : 0.059991, loss_ce: 0.014494
2022-01-08 16:25:44,778 iteration 2995 : loss : 0.023433, loss_ce: 0.008172
2022-01-08 16:25:46,181 iteration 2996 : loss : 0.021405, loss_ce: 0.010077
2022-01-08 16:25:47,584 iteration 2997 : loss : 0.032876, loss_ce: 0.009959
2022-01-08 16:25:49,009 iteration 2998 : loss : 0.025355, loss_ce: 0.010298
2022-01-08 16:25:50,493 iteration 2999 : loss : 0.065369, loss_ce: 0.013261
2022-01-08 16:25:51,996 iteration 3000 : loss : 0.034867, loss_ce: 0.014775
2022-01-08 16:25:53,509 iteration 3001 : loss : 0.043648, loss_ce: 0.010517
2022-01-08 16:25:54,890 iteration 3002 : loss : 0.024090, loss_ce: 0.009786
2022-01-08 16:25:56,290 iteration 3003 : loss : 0.027355, loss_ce: 0.010387
2022-01-08 16:25:57,681 iteration 3004 : loss : 0.024209, loss_ce: 0.009994
2022-01-08 16:25:59,099 iteration 3005 : loss : 0.036351, loss_ce: 0.015715
2022-01-08 16:26:00,553 iteration 3006 : loss : 0.031482, loss_ce: 0.011817
2022-01-08 16:26:02,001 iteration 3007 : loss : 0.029175, loss_ce: 0.011907
2022-01-08 16:26:03,452 iteration 3008 : loss : 0.043767, loss_ce: 0.016898
2022-01-08 16:26:04,784 iteration 3009 : loss : 0.026142, loss_ce: 0.010711

 44%|███████████▉               | 177/400 [1:15:59<1:35:50, 25.79s/it]2022-01-08 16:26:06,395 iteration 3010 : loss : 0.037878, loss_ce: 0.013794
2022-01-08 16:26:07,858 iteration 3011 : loss : 0.031215, loss_ce: 0.013988
2022-01-08 16:26:09,217 iteration 3012 : loss : 0.021376, loss_ce: 0.009136
2022-01-08 16:26:10,551 iteration 3013 : loss : 0.031135, loss_ce: 0.009942
2022-01-08 16:26:11,975 iteration 3014 : loss : 0.028506, loss_ce: 0.010391
2022-01-08 16:26:13,374 iteration 3015 : loss : 0.032503, loss_ce: 0.008243
2022-01-08 16:26:14,771 iteration 3016 : loss : 0.039245, loss_ce: 0.013772
2022-01-08 16:26:16,139 iteration 3017 : loss : 0.026518, loss_ce: 0.013764
2022-01-08 16:26:17,511 iteration 3018 : loss : 0.020121, loss_ce: 0.008760
2022-01-08 16:26:18,833 iteration 3019 : loss : 0.025769, loss_ce: 0.009080
2022-01-08 16:26:20,274 iteration 3020 : loss : 0.037289, loss_ce: 0.013304
2022-01-08 16:26:21,693 iteration 3021 : loss : 0.018573, loss_ce: 0.006157
2022-01-08 16:26:23,077 iteration 3022 : loss : 0.024542, loss_ce: 0.008182
2022-01-08 16:26:24,501 iteration 3023 : loss : 0.031267, loss_ce: 0.010684
2022-01-08 16:26:26,006 iteration 3024 : loss : 0.031721, loss_ce: 0.013239
2022-01-08 16:26:27,483 iteration 3025 : loss : 0.035993, loss_ce: 0.015145
2022-01-08 16:26:28,840 iteration 3026 : loss : 0.022629, loss_ce: 0.009676

 44%|████████████               | 178/400 [1:16:23<1:33:29, 25.27s/it]2022-01-08 16:26:30,370 iteration 3027 : loss : 0.041172, loss_ce: 0.016052
2022-01-08 16:26:31,731 iteration 3028 : loss : 0.023968, loss_ce: 0.009615
2022-01-08 16:26:33,161 iteration 3029 : loss : 0.030720, loss_ce: 0.014729
2022-01-08 16:26:34,532 iteration 3030 : loss : 0.020810, loss_ce: 0.009257
2022-01-08 16:26:35,940 iteration 3031 : loss : 0.037554, loss_ce: 0.015569
2022-01-08 16:26:37,301 iteration 3032 : loss : 0.031697, loss_ce: 0.010778
2022-01-08 16:26:38,746 iteration 3033 : loss : 0.047770, loss_ce: 0.018178
2022-01-08 16:26:40,212 iteration 3034 : loss : 0.049009, loss_ce: 0.016909
2022-01-08 16:26:41,645 iteration 3035 : loss : 0.022066, loss_ce: 0.009380
2022-01-08 16:26:43,032 iteration 3036 : loss : 0.033734, loss_ce: 0.017778
2022-01-08 16:26:44,446 iteration 3037 : loss : 0.026133, loss_ce: 0.010078
2022-01-08 16:26:45,897 iteration 3038 : loss : 0.028084, loss_ce: 0.008816
2022-01-08 16:26:47,237 iteration 3039 : loss : 0.048322, loss_ce: 0.014084
2022-01-08 16:26:48,656 iteration 3040 : loss : 0.033337, loss_ce: 0.008836
2022-01-08 16:26:50,112 iteration 3041 : loss : 0.028213, loss_ce: 0.011396
2022-01-08 16:26:51,525 iteration 3042 : loss : 0.032576, loss_ce: 0.015231
2022-01-08 16:26:53,137 iteration 3043 : loss : 0.044973, loss_ce: 0.013864

 45%|████████████               | 179/400 [1:16:47<1:31:59, 24.98s/it]2022-01-08 16:26:54,629 iteration 3044 : loss : 0.034042, loss_ce: 0.013052
2022-01-08 16:26:55,980 iteration 3045 : loss : 0.030917, loss_ce: 0.011207
2022-01-08 16:26:57,360 iteration 3046 : loss : 0.024570, loss_ce: 0.008928
2022-01-08 16:26:58,892 iteration 3047 : loss : 0.038763, loss_ce: 0.025292
2022-01-08 16:27:00,256 iteration 3048 : loss : 0.026611, loss_ce: 0.008856
2022-01-08 16:27:01,674 iteration 3049 : loss : 0.030254, loss_ce: 0.012760
2022-01-08 16:27:03,126 iteration 3050 : loss : 0.030106, loss_ce: 0.013226
2022-01-08 16:27:04,549 iteration 3051 : loss : 0.037876, loss_ce: 0.009345
2022-01-08 16:27:05,946 iteration 3052 : loss : 0.026615, loss_ce: 0.009141
2022-01-08 16:27:07,455 iteration 3053 : loss : 0.019948, loss_ce: 0.007739
2022-01-08 16:27:08,855 iteration 3054 : loss : 0.025140, loss_ce: 0.007555
2022-01-08 16:27:10,293 iteration 3055 : loss : 0.035310, loss_ce: 0.013854
2022-01-08 16:27:11,677 iteration 3056 : loss : 0.029831, loss_ce: 0.012301
2022-01-08 16:27:13,019 iteration 3057 : loss : 0.029055, loss_ce: 0.013129
2022-01-08 16:27:14,446 iteration 3058 : loss : 0.028440, loss_ce: 0.011542
2022-01-08 16:27:15,901 iteration 3059 : loss : 0.023928, loss_ce: 0.008004
2022-01-08 16:27:15,901 Training Data Eval:
2022-01-08 16:27:22,790   Average segmentation loss on training set: 0.0204
2022-01-08 16:27:22,790 Validation Data Eval:
2022-01-08 16:27:25,174   Average segmentation loss on validation set: 0.0749
2022-01-08 16:27:26,536 iteration 3060 : loss : 0.024687, loss_ce: 0.012431

 45%|████████████▏              | 180/400 [1:17:20<1:40:50, 27.50s/it]2022-01-08 16:27:27,908 iteration 3061 : loss : 0.022288, loss_ce: 0.008441
2022-01-08 16:27:29,312 iteration 3062 : loss : 0.025749, loss_ce: 0.009572
2022-01-08 16:27:30,763 iteration 3063 : loss : 0.043653, loss_ce: 0.015163
2022-01-08 16:27:32,213 iteration 3064 : loss : 0.021102, loss_ce: 0.008660
2022-01-08 16:27:33,514 iteration 3065 : loss : 0.023928, loss_ce: 0.008075
2022-01-08 16:27:34,881 iteration 3066 : loss : 0.031140, loss_ce: 0.015673
2022-01-08 16:27:36,313 iteration 3067 : loss : 0.044388, loss_ce: 0.024116
2022-01-08 16:27:37,737 iteration 3068 : loss : 0.036408, loss_ce: 0.011749
2022-01-08 16:27:39,145 iteration 3069 : loss : 0.034529, loss_ce: 0.008706
2022-01-08 16:27:40,562 iteration 3070 : loss : 0.026148, loss_ce: 0.010137
2022-01-08 16:27:41,906 iteration 3071 : loss : 0.022671, loss_ce: 0.009135
2022-01-08 16:27:43,240 iteration 3072 : loss : 0.023575, loss_ce: 0.009466
2022-01-08 16:27:44,622 iteration 3073 : loss : 0.026133, loss_ce: 0.011236
2022-01-08 16:27:46,110 iteration 3074 : loss : 0.037449, loss_ce: 0.015724
2022-01-08 16:27:47,557 iteration 3075 : loss : 0.028249, loss_ce: 0.009759
2022-01-08 16:27:49,039 iteration 3076 : loss : 0.032768, loss_ce: 0.012633
2022-01-08 16:27:50,401 iteration 3077 : loss : 0.051501, loss_ce: 0.020682

 45%|████████████▏              | 181/400 [1:17:44<1:36:23, 26.41s/it]2022-01-08 16:27:51,805 iteration 3078 : loss : 0.028462, loss_ce: 0.012040
2022-01-08 16:27:53,342 iteration 3079 : loss : 0.023782, loss_ce: 0.008110
2022-01-08 16:27:54,670 iteration 3080 : loss : 0.025961, loss_ce: 0.007285
2022-01-08 16:27:56,111 iteration 3081 : loss : 0.025432, loss_ce: 0.009860
2022-01-08 16:27:57,497 iteration 3082 : loss : 0.036099, loss_ce: 0.008580
2022-01-08 16:27:58,968 iteration 3083 : loss : 0.029468, loss_ce: 0.011656
2022-01-08 16:28:00,245 iteration 3084 : loss : 0.025035, loss_ce: 0.012706
2022-01-08 16:28:01,678 iteration 3085 : loss : 0.028196, loss_ce: 0.012965
2022-01-08 16:28:03,203 iteration 3086 : loss : 0.044448, loss_ce: 0.023717
2022-01-08 16:28:04,588 iteration 3087 : loss : 0.032068, loss_ce: 0.012855
2022-01-08 16:28:06,015 iteration 3088 : loss : 0.024121, loss_ce: 0.007145
2022-01-08 16:28:07,536 iteration 3089 : loss : 0.047412, loss_ce: 0.016088
2022-01-08 16:28:08,863 iteration 3090 : loss : 0.026351, loss_ce: 0.011558
2022-01-08 16:28:10,274 iteration 3091 : loss : 0.034158, loss_ce: 0.014757
2022-01-08 16:28:11,843 iteration 3092 : loss : 0.036867, loss_ce: 0.014446
2022-01-08 16:28:13,217 iteration 3093 : loss : 0.025299, loss_ce: 0.011459
2022-01-08 16:28:14,639 iteration 3094 : loss : 0.026410, loss_ce: 0.011610

 46%|████████████▎              | 182/400 [1:18:08<1:33:35, 25.76s/it]2022-01-08 16:28:16,102 iteration 3095 : loss : 0.025591, loss_ce: 0.009956
2022-01-08 16:28:17,533 iteration 3096 : loss : 0.028299, loss_ce: 0.012428
2022-01-08 16:28:18,928 iteration 3097 : loss : 0.025353, loss_ce: 0.009688
2022-01-08 16:28:20,292 iteration 3098 : loss : 0.021362, loss_ce: 0.008575
2022-01-08 16:28:21,699 iteration 3099 : loss : 0.021853, loss_ce: 0.006931
2022-01-08 16:28:23,045 iteration 3100 : loss : 0.022303, loss_ce: 0.007081
2022-01-08 16:28:24,511 iteration 3101 : loss : 0.024791, loss_ce: 0.008603
2022-01-08 16:28:25,919 iteration 3102 : loss : 0.029017, loss_ce: 0.010702
2022-01-08 16:28:27,340 iteration 3103 : loss : 0.040952, loss_ce: 0.016466
2022-01-08 16:28:28,704 iteration 3104 : loss : 0.027092, loss_ce: 0.013266
2022-01-08 16:28:30,041 iteration 3105 : loss : 0.021383, loss_ce: 0.009669
2022-01-08 16:28:31,434 iteration 3106 : loss : 0.025729, loss_ce: 0.011331
2022-01-08 16:28:32,812 iteration 3107 : loss : 0.027524, loss_ce: 0.008178
2022-01-08 16:28:34,245 iteration 3108 : loss : 0.041058, loss_ce: 0.013318
2022-01-08 16:28:35,691 iteration 3109 : loss : 0.036128, loss_ce: 0.012603
2022-01-08 16:28:37,144 iteration 3110 : loss : 0.028380, loss_ce: 0.013579
2022-01-08 16:28:38,576 iteration 3111 : loss : 0.033252, loss_ce: 0.013339

 46%|████████████▎              | 183/400 [1:18:32<1:31:10, 25.21s/it]2022-01-08 16:28:40,070 iteration 3112 : loss : 0.031222, loss_ce: 0.011528
2022-01-08 16:28:41,433 iteration 3113 : loss : 0.029447, loss_ce: 0.011657
2022-01-08 16:28:42,898 iteration 3114 : loss : 0.034150, loss_ce: 0.010719
2022-01-08 16:28:44,319 iteration 3115 : loss : 0.032242, loss_ce: 0.015212
2022-01-08 16:28:45,725 iteration 3116 : loss : 0.022762, loss_ce: 0.010642
2022-01-08 16:28:47,208 iteration 3117 : loss : 0.024574, loss_ce: 0.009661
2022-01-08 16:28:48,594 iteration 3118 : loss : 0.050308, loss_ce: 0.021111
2022-01-08 16:28:50,119 iteration 3119 : loss : 0.029468, loss_ce: 0.008817
2022-01-08 16:28:51,469 iteration 3120 : loss : 0.019952, loss_ce: 0.008182
2022-01-08 16:28:52,953 iteration 3121 : loss : 0.025462, loss_ce: 0.011578
2022-01-08 16:28:54,344 iteration 3122 : loss : 0.028361, loss_ce: 0.008156
2022-01-08 16:28:55,817 iteration 3123 : loss : 0.028483, loss_ce: 0.012443
2022-01-08 16:28:57,143 iteration 3124 : loss : 0.021464, loss_ce: 0.008555
2022-01-08 16:28:58,543 iteration 3125 : loss : 0.028316, loss_ce: 0.008653
2022-01-08 16:29:00,013 iteration 3126 : loss : 0.023870, loss_ce: 0.011410
2022-01-08 16:29:01,508 iteration 3127 : loss : 0.035257, loss_ce: 0.011739
2022-01-08 16:29:03,002 iteration 3128 : loss : 0.035746, loss_ce: 0.014168

 46%|████████████▍              | 184/400 [1:18:57<1:29:55, 24.98s/it]2022-01-08 16:29:04,440 iteration 3129 : loss : 0.024996, loss_ce: 0.009298
2022-01-08 16:29:05,957 iteration 3130 : loss : 0.040316, loss_ce: 0.014098
2022-01-08 16:29:07,352 iteration 3131 : loss : 0.033880, loss_ce: 0.014570
2022-01-08 16:29:08,767 iteration 3132 : loss : 0.023853, loss_ce: 0.007406
2022-01-08 16:29:10,183 iteration 3133 : loss : 0.052354, loss_ce: 0.023337
2022-01-08 16:29:11,558 iteration 3134 : loss : 0.021867, loss_ce: 0.009671
2022-01-08 16:29:12,969 iteration 3135 : loss : 0.032446, loss_ce: 0.013676
2022-01-08 16:29:14,351 iteration 3136 : loss : 0.022496, loss_ce: 0.009901
2022-01-08 16:29:15,894 iteration 3137 : loss : 0.037221, loss_ce: 0.018613
2022-01-08 16:29:17,381 iteration 3138 : loss : 0.050838, loss_ce: 0.018185
2022-01-08 16:29:18,726 iteration 3139 : loss : 0.028304, loss_ce: 0.010262
2022-01-08 16:29:20,075 iteration 3140 : loss : 0.029070, loss_ce: 0.012634
2022-01-08 16:29:21,508 iteration 3141 : loss : 0.035378, loss_ce: 0.014899
2022-01-08 16:29:22,893 iteration 3142 : loss : 0.035539, loss_ce: 0.011632
2022-01-08 16:29:24,362 iteration 3143 : loss : 0.035378, loss_ce: 0.012262
2022-01-08 16:29:25,793 iteration 3144 : loss : 0.027597, loss_ce: 0.011372
2022-01-08 16:29:25,793 Training Data Eval:
2022-01-08 16:29:32,682   Average segmentation loss on training set: 0.0191
2022-01-08 16:29:32,682 Validation Data Eval:
2022-01-08 16:29:35,052   Average segmentation loss on validation set: 0.1165
2022-01-08 16:29:36,414 iteration 3145 : loss : 0.021752, loss_ce: 0.008805

 46%|████████████▍              | 185/400 [1:19:30<1:38:33, 27.51s/it]2022-01-08 16:29:38,051 iteration 3146 : loss : 0.042815, loss_ce: 0.013615
2022-01-08 16:29:39,521 iteration 3147 : loss : 0.024833, loss_ce: 0.011317
2022-01-08 16:29:40,867 iteration 3148 : loss : 0.020073, loss_ce: 0.007051
2022-01-08 16:29:42,324 iteration 3149 : loss : 0.048559, loss_ce: 0.015963
2022-01-08 16:29:43,774 iteration 3150 : loss : 0.025978, loss_ce: 0.008952
2022-01-08 16:29:45,228 iteration 3151 : loss : 0.051313, loss_ce: 0.020879
2022-01-08 16:29:46,676 iteration 3152 : loss : 0.031092, loss_ce: 0.010589
2022-01-08 16:29:48,103 iteration 3153 : loss : 0.031194, loss_ce: 0.016064
2022-01-08 16:29:49,609 iteration 3154 : loss : 0.034925, loss_ce: 0.011074
2022-01-08 16:29:51,076 iteration 3155 : loss : 0.024696, loss_ce: 0.008399
2022-01-08 16:29:52,424 iteration 3156 : loss : 0.026934, loss_ce: 0.008778
2022-01-08 16:29:53,855 iteration 3157 : loss : 0.028849, loss_ce: 0.011338
2022-01-08 16:29:55,215 iteration 3158 : loss : 0.037622, loss_ce: 0.008794
2022-01-08 16:29:56,665 iteration 3159 : loss : 0.034395, loss_ce: 0.016864
2022-01-08 16:29:58,114 iteration 3160 : loss : 0.030568, loss_ce: 0.013070
2022-01-08 16:29:59,620 iteration 3161 : loss : 0.032332, loss_ce: 0.011347
2022-01-08 16:30:01,050 iteration 3162 : loss : 0.042075, loss_ce: 0.012041

 46%|████████████▌              | 186/400 [1:19:55<1:35:02, 26.65s/it]2022-01-08 16:30:02,473 iteration 3163 : loss : 0.028981, loss_ce: 0.009640
2022-01-08 16:30:04,009 iteration 3164 : loss : 0.035160, loss_ce: 0.014662
2022-01-08 16:30:05,479 iteration 3165 : loss : 0.027737, loss_ce: 0.010998
2022-01-08 16:30:06,849 iteration 3166 : loss : 0.030032, loss_ce: 0.012406
2022-01-08 16:30:08,328 iteration 3167 : loss : 0.027056, loss_ce: 0.009268
2022-01-08 16:30:09,750 iteration 3168 : loss : 0.026010, loss_ce: 0.011125
2022-01-08 16:30:11,201 iteration 3169 : loss : 0.042862, loss_ce: 0.017301
2022-01-08 16:30:12,620 iteration 3170 : loss : 0.027583, loss_ce: 0.012422
2022-01-08 16:30:13,903 iteration 3171 : loss : 0.026513, loss_ce: 0.007103
2022-01-08 16:30:15,278 iteration 3172 : loss : 0.030772, loss_ce: 0.013650
2022-01-08 16:30:16,691 iteration 3173 : loss : 0.041943, loss_ce: 0.017562
2022-01-08 16:30:18,072 iteration 3174 : loss : 0.029406, loss_ce: 0.011756
2022-01-08 16:30:19,409 iteration 3175 : loss : 0.063992, loss_ce: 0.025677
2022-01-08 16:30:20,915 iteration 3176 : loss : 0.043724, loss_ce: 0.012075
2022-01-08 16:30:22,335 iteration 3177 : loss : 0.035478, loss_ce: 0.015358
2022-01-08 16:30:23,858 iteration 3178 : loss : 0.026819, loss_ce: 0.007672
2022-01-08 16:30:25,289 iteration 3179 : loss : 0.026048, loss_ce: 0.012558

 47%|████████████▌              | 187/400 [1:20:19<1:32:01, 25.92s/it]2022-01-08 16:30:26,778 iteration 3180 : loss : 0.042662, loss_ce: 0.017125
2022-01-08 16:30:28,163 iteration 3181 : loss : 0.025525, loss_ce: 0.010417
2022-01-08 16:30:29,518 iteration 3182 : loss : 0.035639, loss_ce: 0.019197
2022-01-08 16:30:30,998 iteration 3183 : loss : 0.046726, loss_ce: 0.016114
2022-01-08 16:30:32,412 iteration 3184 : loss : 0.027234, loss_ce: 0.009565
2022-01-08 16:30:33,842 iteration 3185 : loss : 0.027342, loss_ce: 0.008165
2022-01-08 16:30:35,307 iteration 3186 : loss : 0.025433, loss_ce: 0.010537
2022-01-08 16:30:36,784 iteration 3187 : loss : 0.024777, loss_ce: 0.010218
2022-01-08 16:30:38,259 iteration 3188 : loss : 0.026292, loss_ce: 0.009678
2022-01-08 16:30:39,669 iteration 3189 : loss : 0.023898, loss_ce: 0.008956
2022-01-08 16:30:41,203 iteration 3190 : loss : 0.028842, loss_ce: 0.009790
2022-01-08 16:30:42,683 iteration 3191 : loss : 0.031390, loss_ce: 0.012389
2022-01-08 16:30:44,031 iteration 3192 : loss : 0.032158, loss_ce: 0.007295
2022-01-08 16:30:45,448 iteration 3193 : loss : 0.022852, loss_ce: 0.009137
2022-01-08 16:30:47,003 iteration 3194 : loss : 0.040188, loss_ce: 0.017029
2022-01-08 16:30:48,431 iteration 3195 : loss : 0.024781, loss_ce: 0.009876
2022-01-08 16:30:49,855 iteration 3196 : loss : 0.034626, loss_ce: 0.016006

 47%|████████████▋              | 188/400 [1:20:44<1:30:09, 25.52s/it]2022-01-08 16:30:51,321 iteration 3197 : loss : 0.019628, loss_ce: 0.008046
2022-01-08 16:30:52,787 iteration 3198 : loss : 0.030709, loss_ce: 0.014045
2022-01-08 16:30:54,238 iteration 3199 : loss : 0.030014, loss_ce: 0.010872
2022-01-08 16:30:55,714 iteration 3200 : loss : 0.031824, loss_ce: 0.010146
2022-01-08 16:30:57,184 iteration 3201 : loss : 0.026468, loss_ce: 0.008996
2022-01-08 16:30:58,661 iteration 3202 : loss : 0.039357, loss_ce: 0.012363
2022-01-08 16:30:59,996 iteration 3203 : loss : 0.022801, loss_ce: 0.010018
2022-01-08 16:31:01,316 iteration 3204 : loss : 0.022315, loss_ce: 0.009335
2022-01-08 16:31:02,634 iteration 3205 : loss : 0.030341, loss_ce: 0.008796
2022-01-08 16:31:03,913 iteration 3206 : loss : 0.020747, loss_ce: 0.006562
2022-01-08 16:31:05,356 iteration 3207 : loss : 0.028843, loss_ce: 0.010434
2022-01-08 16:31:06,763 iteration 3208 : loss : 0.032254, loss_ce: 0.013213
2022-01-08 16:31:08,142 iteration 3209 : loss : 0.032011, loss_ce: 0.010481
2022-01-08 16:31:09,584 iteration 3210 : loss : 0.022545, loss_ce: 0.009663
2022-01-08 16:31:10,934 iteration 3211 : loss : 0.025019, loss_ce: 0.006935
2022-01-08 16:31:12,433 iteration 3212 : loss : 0.044540, loss_ce: 0.018688
2022-01-08 16:31:13,949 iteration 3213 : loss : 0.034384, loss_ce: 0.011692

 47%|████████████▊              | 189/400 [1:21:08<1:28:13, 25.09s/it]2022-01-08 16:31:15,371 iteration 3214 : loss : 0.019565, loss_ce: 0.008669
2022-01-08 16:31:16,782 iteration 3215 : loss : 0.022780, loss_ce: 0.009310
2022-01-08 16:31:18,203 iteration 3216 : loss : 0.030072, loss_ce: 0.012292
2022-01-08 16:31:19,653 iteration 3217 : loss : 0.034632, loss_ce: 0.013895
2022-01-08 16:31:21,078 iteration 3218 : loss : 0.036911, loss_ce: 0.011202
2022-01-08 16:31:22,483 iteration 3219 : loss : 0.041101, loss_ce: 0.015746
2022-01-08 16:31:23,844 iteration 3220 : loss : 0.017168, loss_ce: 0.006981
2022-01-08 16:31:25,374 iteration 3221 : loss : 0.042587, loss_ce: 0.019124
2022-01-08 16:31:26,760 iteration 3222 : loss : 0.021076, loss_ce: 0.004880
2022-01-08 16:31:28,207 iteration 3223 : loss : 0.022526, loss_ce: 0.008024
2022-01-08 16:31:29,725 iteration 3224 : loss : 0.040887, loss_ce: 0.011630
2022-01-08 16:31:31,145 iteration 3225 : loss : 0.034286, loss_ce: 0.018441
2022-01-08 16:31:32,564 iteration 3226 : loss : 0.023407, loss_ce: 0.008980
2022-01-08 16:31:33,997 iteration 3227 : loss : 0.046473, loss_ce: 0.019088
2022-01-08 16:31:35,379 iteration 3228 : loss : 0.027805, loss_ce: 0.008443
2022-01-08 16:31:36,725 iteration 3229 : loss : 0.032748, loss_ce: 0.009118
2022-01-08 16:31:36,725 Training Data Eval:
2022-01-08 16:31:43,634   Average segmentation loss on training set: 0.0221
2022-01-08 16:31:43,635 Validation Data Eval:
2022-01-08 16:31:46,012   Average segmentation loss on validation set: 0.0753
2022-01-08 16:31:47,341 iteration 3230 : loss : 0.035242, loss_ce: 0.012704

 48%|████████████▊              | 190/400 [1:21:41<1:36:31, 27.58s/it]2022-01-08 16:31:48,767 iteration 3231 : loss : 0.044721, loss_ce: 0.009749
2022-01-08 16:31:50,150 iteration 3232 : loss : 0.022660, loss_ce: 0.007306
2022-01-08 16:31:51,584 iteration 3233 : loss : 0.027446, loss_ce: 0.011649
2022-01-08 16:31:53,029 iteration 3234 : loss : 0.019446, loss_ce: 0.007221
2022-01-08 16:31:54,464 iteration 3235 : loss : 0.038411, loss_ce: 0.014144
2022-01-08 16:31:55,811 iteration 3236 : loss : 0.021256, loss_ce: 0.010444
2022-01-08 16:31:57,336 iteration 3237 : loss : 0.027866, loss_ce: 0.012508
2022-01-08 16:31:58,758 iteration 3238 : loss : 0.025877, loss_ce: 0.012066
2022-01-08 16:32:00,178 iteration 3239 : loss : 0.024192, loss_ce: 0.009334
2022-01-08 16:32:01,537 iteration 3240 : loss : 0.037080, loss_ce: 0.009927
2022-01-08 16:32:02,870 iteration 3241 : loss : 0.027204, loss_ce: 0.007152
2022-01-08 16:32:04,297 iteration 3242 : loss : 0.034365, loss_ce: 0.013978
2022-01-08 16:32:05,637 iteration 3243 : loss : 0.033569, loss_ce: 0.010890
2022-01-08 16:32:07,081 iteration 3244 : loss : 0.025585, loss_ce: 0.009853
2022-01-08 16:32:08,450 iteration 3245 : loss : 0.019028, loss_ce: 0.008383
2022-01-08 16:32:09,936 iteration 3246 : loss : 0.034687, loss_ce: 0.018731
2022-01-08 16:32:11,307 iteration 3247 : loss : 0.025208, loss_ce: 0.010219

 48%|████████████▉              | 191/400 [1:22:05<1:32:17, 26.50s/it]2022-01-08 16:32:12,725 iteration 3248 : loss : 0.026724, loss_ce: 0.010891
2022-01-08 16:32:14,078 iteration 3249 : loss : 0.020118, loss_ce: 0.007072
2022-01-08 16:32:15,470 iteration 3250 : loss : 0.025763, loss_ce: 0.008386
2022-01-08 16:32:16,864 iteration 3251 : loss : 0.021433, loss_ce: 0.009769
2022-01-08 16:32:18,287 iteration 3252 : loss : 0.022437, loss_ce: 0.007514
2022-01-08 16:32:19,677 iteration 3253 : loss : 0.021166, loss_ce: 0.009593
2022-01-08 16:32:21,055 iteration 3254 : loss : 0.021320, loss_ce: 0.007698
2022-01-08 16:32:22,371 iteration 3255 : loss : 0.028185, loss_ce: 0.011860
2022-01-08 16:32:23,763 iteration 3256 : loss : 0.018940, loss_ce: 0.006016
2022-01-08 16:32:25,124 iteration 3257 : loss : 0.023825, loss_ce: 0.010610
2022-01-08 16:32:26,543 iteration 3258 : loss : 0.031789, loss_ce: 0.013018
2022-01-08 16:32:27,889 iteration 3259 : loss : 0.026042, loss_ce: 0.010520
2022-01-08 16:32:29,304 iteration 3260 : loss : 0.022527, loss_ce: 0.008750
2022-01-08 16:32:30,679 iteration 3261 : loss : 0.033326, loss_ce: 0.008162
2022-01-08 16:32:32,130 iteration 3262 : loss : 0.026943, loss_ce: 0.009722
2022-01-08 16:32:33,671 iteration 3263 : loss : 0.033626, loss_ce: 0.010544
2022-01-08 16:32:35,099 iteration 3264 : loss : 0.034846, loss_ce: 0.014290

 48%|████████████▉              | 192/400 [1:22:29<1:29:02, 25.69s/it]2022-01-08 16:32:36,508 iteration 3265 : loss : 0.021162, loss_ce: 0.008977
2022-01-08 16:32:37,979 iteration 3266 : loss : 0.038442, loss_ce: 0.017796
2022-01-08 16:32:39,417 iteration 3267 : loss : 0.025158, loss_ce: 0.011758
2022-01-08 16:32:40,780 iteration 3268 : loss : 0.025843, loss_ce: 0.009558
2022-01-08 16:32:42,256 iteration 3269 : loss : 0.031102, loss_ce: 0.012942
2022-01-08 16:32:43,765 iteration 3270 : loss : 0.025710, loss_ce: 0.008353
2022-01-08 16:32:45,240 iteration 3271 : loss : 0.024488, loss_ce: 0.007886
2022-01-08 16:32:46,712 iteration 3272 : loss : 0.020934, loss_ce: 0.008279
2022-01-08 16:32:48,056 iteration 3273 : loss : 0.021834, loss_ce: 0.006802
2022-01-08 16:32:49,458 iteration 3274 : loss : 0.023319, loss_ce: 0.011500
2022-01-08 16:32:50,939 iteration 3275 : loss : 0.025885, loss_ce: 0.007507
2022-01-08 16:32:52,322 iteration 3276 : loss : 0.024363, loss_ce: 0.009610
2022-01-08 16:32:53,771 iteration 3277 : loss : 0.025447, loss_ce: 0.012591
2022-01-08 16:32:55,190 iteration 3278 : loss : 0.024219, loss_ce: 0.008262
2022-01-08 16:32:56,558 iteration 3279 : loss : 0.024634, loss_ce: 0.009463
2022-01-08 16:32:57,950 iteration 3280 : loss : 0.022670, loss_ce: 0.007479
2022-01-08 16:32:59,300 iteration 3281 : loss : 0.017568, loss_ce: 0.005244

 48%|█████████████              | 193/400 [1:22:53<1:27:04, 25.24s/it]2022-01-08 16:33:00,801 iteration 3282 : loss : 0.028885, loss_ce: 0.011063
2022-01-08 16:33:02,206 iteration 3283 : loss : 0.021971, loss_ce: 0.007652
2022-01-08 16:33:03,616 iteration 3284 : loss : 0.036791, loss_ce: 0.014298
2022-01-08 16:33:05,008 iteration 3285 : loss : 0.042659, loss_ce: 0.021175
2022-01-08 16:33:06,406 iteration 3286 : loss : 0.019738, loss_ce: 0.007074
2022-01-08 16:33:07,837 iteration 3287 : loss : 0.023694, loss_ce: 0.008721
2022-01-08 16:33:09,182 iteration 3288 : loss : 0.029177, loss_ce: 0.016335
2022-01-08 16:33:10,545 iteration 3289 : loss : 0.024524, loss_ce: 0.007018
2022-01-08 16:33:12,016 iteration 3290 : loss : 0.032525, loss_ce: 0.008669
2022-01-08 16:33:13,498 iteration 3291 : loss : 0.025481, loss_ce: 0.008883
2022-01-08 16:33:14,930 iteration 3292 : loss : 0.028825, loss_ce: 0.008775
2022-01-08 16:33:16,338 iteration 3293 : loss : 0.019985, loss_ce: 0.008864
2022-01-08 16:33:17,719 iteration 3294 : loss : 0.028978, loss_ce: 0.011976
2022-01-08 16:33:19,234 iteration 3295 : loss : 0.034931, loss_ce: 0.013255
2022-01-08 16:33:20,684 iteration 3296 : loss : 0.026173, loss_ce: 0.007705
2022-01-08 16:33:22,018 iteration 3297 : loss : 0.019079, loss_ce: 0.007423
2022-01-08 16:33:23,477 iteration 3298 : loss : 0.039468, loss_ce: 0.017922

 48%|█████████████              | 194/400 [1:23:17<1:25:33, 24.92s/it]2022-01-08 16:33:24,861 iteration 3299 : loss : 0.022539, loss_ce: 0.009058
2022-01-08 16:33:26,238 iteration 3300 : loss : 0.032587, loss_ce: 0.012138
2022-01-08 16:33:27,714 iteration 3301 : loss : 0.024831, loss_ce: 0.010573
2022-01-08 16:33:29,123 iteration 3302 : loss : 0.022490, loss_ce: 0.008316
2022-01-08 16:33:30,510 iteration 3303 : loss : 0.021239, loss_ce: 0.008247
2022-01-08 16:33:31,927 iteration 3304 : loss : 0.026801, loss_ce: 0.009656
2022-01-08 16:33:33,364 iteration 3305 : loss : 0.023706, loss_ce: 0.007312
2022-01-08 16:33:34,832 iteration 3306 : loss : 0.033002, loss_ce: 0.014470
2022-01-08 16:33:36,210 iteration 3307 : loss : 0.021229, loss_ce: 0.008766
2022-01-08 16:33:37,631 iteration 3308 : loss : 0.026341, loss_ce: 0.011134
2022-01-08 16:33:39,032 iteration 3309 : loss : 0.037841, loss_ce: 0.006988
2022-01-08 16:33:40,523 iteration 3310 : loss : 0.041984, loss_ce: 0.017713
2022-01-08 16:33:42,046 iteration 3311 : loss : 0.027897, loss_ce: 0.009692
2022-01-08 16:33:43,399 iteration 3312 : loss : 0.027023, loss_ce: 0.009000
2022-01-08 16:33:44,774 iteration 3313 : loss : 0.020343, loss_ce: 0.007260
2022-01-08 16:33:46,262 iteration 3314 : loss : 0.028168, loss_ce: 0.009785
2022-01-08 16:33:46,263 Training Data Eval:
2022-01-08 16:33:53,188   Average segmentation loss on training set: 0.0188
2022-01-08 16:33:53,188 Validation Data Eval:
2022-01-08 16:33:55,592   Average segmentation loss on validation set: 0.0748
2022-01-08 16:33:56,942 iteration 3315 : loss : 0.025203, loss_ce: 0.012618

 49%|█████████████▏             | 195/400 [1:23:51<1:33:54, 27.48s/it]2022-01-08 16:33:58,352 iteration 3316 : loss : 0.018180, loss_ce: 0.006818
2022-01-08 16:33:59,724 iteration 3317 : loss : 0.033215, loss_ce: 0.012384
2022-01-08 16:34:01,243 iteration 3318 : loss : 0.037181, loss_ce: 0.014928
2022-01-08 16:34:02,625 iteration 3319 : loss : 0.026818, loss_ce: 0.009542
2022-01-08 16:34:04,016 iteration 3320 : loss : 0.026627, loss_ce: 0.009549
2022-01-08 16:34:05,441 iteration 3321 : loss : 0.023402, loss_ce: 0.007318
2022-01-08 16:34:06,858 iteration 3322 : loss : 0.033438, loss_ce: 0.014244
2022-01-08 16:34:08,209 iteration 3323 : loss : 0.028379, loss_ce: 0.009386
2022-01-08 16:34:09,715 iteration 3324 : loss : 0.039424, loss_ce: 0.014309
2022-01-08 16:34:11,080 iteration 3325 : loss : 0.035311, loss_ce: 0.010674
2022-01-08 16:34:12,525 iteration 3326 : loss : 0.025651, loss_ce: 0.009409
2022-01-08 16:34:14,047 iteration 3327 : loss : 0.042499, loss_ce: 0.014822
2022-01-08 16:34:15,463 iteration 3328 : loss : 0.037045, loss_ce: 0.012956
2022-01-08 16:34:16,841 iteration 3329 : loss : 0.022242, loss_ce: 0.009379
2022-01-08 16:34:18,241 iteration 3330 : loss : 0.035819, loss_ce: 0.013636
2022-01-08 16:34:19,674 iteration 3331 : loss : 0.019475, loss_ce: 0.007182
2022-01-08 16:34:21,074 iteration 3332 : loss : 0.020156, loss_ce: 0.009967

 49%|█████████████▏             | 196/400 [1:24:15<1:30:02, 26.48s/it]2022-01-08 16:34:22,521 iteration 3333 : loss : 0.021063, loss_ce: 0.008199
2022-01-08 16:34:23,950 iteration 3334 : loss : 0.018905, loss_ce: 0.008800
2022-01-08 16:34:25,265 iteration 3335 : loss : 0.018574, loss_ce: 0.007820
2022-01-08 16:34:26,672 iteration 3336 : loss : 0.040756, loss_ce: 0.013789
2022-01-08 16:34:28,141 iteration 3337 : loss : 0.026102, loss_ce: 0.010497
2022-01-08 16:34:29,660 iteration 3338 : loss : 0.030098, loss_ce: 0.016179
2022-01-08 16:34:31,063 iteration 3339 : loss : 0.027609, loss_ce: 0.008325
2022-01-08 16:34:32,441 iteration 3340 : loss : 0.020552, loss_ce: 0.007872
2022-01-08 16:34:33,841 iteration 3341 : loss : 0.020156, loss_ce: 0.007552
2022-01-08 16:34:35,302 iteration 3342 : loss : 0.054479, loss_ce: 0.027573
2022-01-08 16:34:36,737 iteration 3343 : loss : 0.028623, loss_ce: 0.009857
2022-01-08 16:34:38,161 iteration 3344 : loss : 0.035052, loss_ce: 0.014598
2022-01-08 16:34:39,546 iteration 3345 : loss : 0.023041, loss_ce: 0.008389
2022-01-08 16:34:40,975 iteration 3346 : loss : 0.025110, loss_ce: 0.011380
2022-01-08 16:34:42,427 iteration 3347 : loss : 0.038315, loss_ce: 0.009147
2022-01-08 16:34:43,945 iteration 3348 : loss : 0.036715, loss_ce: 0.012383
2022-01-08 16:34:45,378 iteration 3349 : loss : 0.042530, loss_ce: 0.017617

 49%|█████████████▎             | 197/400 [1:24:39<1:27:22, 25.83s/it]2022-01-08 16:34:46,808 iteration 3350 : loss : 0.022894, loss_ce: 0.009385
2022-01-08 16:34:48,166 iteration 3351 : loss : 0.025740, loss_ce: 0.010757
2022-01-08 16:34:49,551 iteration 3352 : loss : 0.024573, loss_ce: 0.009565
2022-01-08 16:34:50,986 iteration 3353 : loss : 0.027507, loss_ce: 0.011985
2022-01-08 16:34:52,419 iteration 3354 : loss : 0.021973, loss_ce: 0.006521
2022-01-08 16:34:53,913 iteration 3355 : loss : 0.029302, loss_ce: 0.015801
2022-01-08 16:34:55,387 iteration 3356 : loss : 0.033651, loss_ce: 0.008453
2022-01-08 16:34:56,868 iteration 3357 : loss : 0.034806, loss_ce: 0.012210
2022-01-08 16:34:58,363 iteration 3358 : loss : 0.033549, loss_ce: 0.011436
2022-01-08 16:34:59,839 iteration 3359 : loss : 0.026819, loss_ce: 0.011284
2022-01-08 16:35:01,366 iteration 3360 : loss : 0.026917, loss_ce: 0.011899
2022-01-08 16:35:02,726 iteration 3361 : loss : 0.033302, loss_ce: 0.009737
2022-01-08 16:35:04,095 iteration 3362 : loss : 0.024672, loss_ce: 0.010458
2022-01-08 16:35:05,455 iteration 3363 : loss : 0.024435, loss_ce: 0.011158
2022-01-08 16:35:06,889 iteration 3364 : loss : 0.031894, loss_ce: 0.013231
2022-01-08 16:35:08,252 iteration 3365 : loss : 0.022460, loss_ce: 0.011030
2022-01-08 16:35:09,648 iteration 3366 : loss : 0.021845, loss_ce: 0.008112

 50%|█████████████▎             | 198/400 [1:25:03<1:25:22, 25.36s/it]2022-01-08 16:35:11,114 iteration 3367 : loss : 0.028182, loss_ce: 0.008245
2022-01-08 16:35:12,518 iteration 3368 : loss : 0.025969, loss_ce: 0.013029
2022-01-08 16:35:13,950 iteration 3369 : loss : 0.018046, loss_ce: 0.006475
2022-01-08 16:35:15,399 iteration 3370 : loss : 0.026063, loss_ce: 0.011755
2022-01-08 16:35:16,709 iteration 3371 : loss : 0.016807, loss_ce: 0.006547
2022-01-08 16:35:18,102 iteration 3372 : loss : 0.038499, loss_ce: 0.019485
2022-01-08 16:35:19,507 iteration 3373 : loss : 0.021187, loss_ce: 0.010772
2022-01-08 16:35:20,849 iteration 3374 : loss : 0.023278, loss_ce: 0.009663
2022-01-08 16:35:22,207 iteration 3375 : loss : 0.022201, loss_ce: 0.009287
2022-01-08 16:35:23,582 iteration 3376 : loss : 0.055659, loss_ce: 0.026988
2022-01-08 16:35:25,044 iteration 3377 : loss : 0.026513, loss_ce: 0.008840
2022-01-08 16:35:26,450 iteration 3378 : loss : 0.036706, loss_ce: 0.013196
2022-01-08 16:35:27,760 iteration 3379 : loss : 0.020328, loss_ce: 0.008858
2022-01-08 16:35:29,241 iteration 3380 : loss : 0.034995, loss_ce: 0.013726
2022-01-08 16:35:30,580 iteration 3381 : loss : 0.060042, loss_ce: 0.010068
2022-01-08 16:35:31,989 iteration 3382 : loss : 0.036371, loss_ce: 0.013440
2022-01-08 16:35:33,385 iteration 3383 : loss : 0.030816, loss_ce: 0.010029

 50%|█████████████▍             | 199/400 [1:25:27<1:23:19, 24.87s/it]2022-01-08 16:35:34,794 iteration 3384 : loss : 0.053017, loss_ce: 0.015819
2022-01-08 16:35:36,262 iteration 3385 : loss : 0.037332, loss_ce: 0.015420
2022-01-08 16:35:37,741 iteration 3386 : loss : 0.040036, loss_ce: 0.019914
2022-01-08 16:35:39,199 iteration 3387 : loss : 0.046382, loss_ce: 0.017317
2022-01-08 16:35:40,539 iteration 3388 : loss : 0.030940, loss_ce: 0.012385
2022-01-08 16:35:41,977 iteration 3389 : loss : 0.048257, loss_ce: 0.019710
2022-01-08 16:35:43,342 iteration 3390 : loss : 0.034751, loss_ce: 0.011009
2022-01-08 16:35:44,867 iteration 3391 : loss : 0.052129, loss_ce: 0.016643
2022-01-08 16:35:46,323 iteration 3392 : loss : 0.032673, loss_ce: 0.012268
2022-01-08 16:35:47,776 iteration 3393 : loss : 0.038294, loss_ce: 0.015267
2022-01-08 16:35:49,089 iteration 3394 : loss : 0.029492, loss_ce: 0.011149
2022-01-08 16:35:50,620 iteration 3395 : loss : 0.046235, loss_ce: 0.015946
2022-01-08 16:35:52,053 iteration 3396 : loss : 0.047838, loss_ce: 0.017879
2022-01-08 16:35:53,442 iteration 3397 : loss : 0.031164, loss_ce: 0.012783
2022-01-08 16:35:54,896 iteration 3398 : loss : 0.029411, loss_ce: 0.009123
2022-01-08 16:35:56,325 iteration 3399 : loss : 0.026029, loss_ce: 0.011623
2022-01-08 16:35:56,325 Training Data Eval:
2022-01-08 16:36:03,241   Average segmentation loss on training set: 0.0216
2022-01-08 16:36:03,242 Validation Data Eval:
2022-01-08 16:36:05,620   Average segmentation loss on validation set: 0.0902
2022-01-08 16:36:07,032 iteration 3400 : loss : 0.030912, loss_ce: 0.009722

 50%|█████████████▌             | 200/400 [1:26:01<1:31:40, 27.50s/it]2022-01-08 16:36:08,661 iteration 3401 : loss : 0.030846, loss_ce: 0.012681
2022-01-08 16:36:10,142 iteration 3402 : loss : 0.025599, loss_ce: 0.009048
2022-01-08 16:36:11,521 iteration 3403 : loss : 0.028349, loss_ce: 0.013808
2022-01-08 16:36:12,905 iteration 3404 : loss : 0.024766, loss_ce: 0.008023
2022-01-08 16:36:14,301 iteration 3405 : loss : 0.039785, loss_ce: 0.016827
2022-01-08 16:36:15,766 iteration 3406 : loss : 0.041168, loss_ce: 0.014347
2022-01-08 16:36:17,185 iteration 3407 : loss : 0.039200, loss_ce: 0.017760
2022-01-08 16:36:18,623 iteration 3408 : loss : 0.028590, loss_ce: 0.009964
2022-01-08 16:36:20,082 iteration 3409 : loss : 0.030802, loss_ce: 0.012725
2022-01-08 16:36:21,528 iteration 3410 : loss : 0.030428, loss_ce: 0.011715
2022-01-08 16:36:23,011 iteration 3411 : loss : 0.034476, loss_ce: 0.016087
2022-01-08 16:36:24,365 iteration 3412 : loss : 0.041388, loss_ce: 0.013015
2022-01-08 16:36:25,700 iteration 3413 : loss : 0.021888, loss_ce: 0.010097
2022-01-08 16:36:27,140 iteration 3414 : loss : 0.031786, loss_ce: 0.007992
2022-01-08 16:36:28,610 iteration 3415 : loss : 0.024977, loss_ce: 0.009928
2022-01-08 16:36:30,079 iteration 3416 : loss : 0.027091, loss_ce: 0.009255
2022-01-08 16:36:31,599 iteration 3417 : loss : 0.048182, loss_ce: 0.017344

 50%|█████████████▌             | 201/400 [1:26:25<1:28:17, 26.62s/it]2022-01-08 16:36:33,090 iteration 3418 : loss : 0.022214, loss_ce: 0.010381
2022-01-08 16:36:34,547 iteration 3419 : loss : 0.034321, loss_ce: 0.010569
2022-01-08 16:36:36,077 iteration 3420 : loss : 0.033751, loss_ce: 0.010407
2022-01-08 16:36:37,534 iteration 3421 : loss : 0.029067, loss_ce: 0.011520
2022-01-08 16:36:38,892 iteration 3422 : loss : 0.024633, loss_ce: 0.007624
2022-01-08 16:36:40,304 iteration 3423 : loss : 0.025114, loss_ce: 0.010309
2022-01-08 16:36:41,719 iteration 3424 : loss : 0.029480, loss_ce: 0.011438
2022-01-08 16:36:43,076 iteration 3425 : loss : 0.025801, loss_ce: 0.011896
2022-01-08 16:36:44,500 iteration 3426 : loss : 0.032935, loss_ce: 0.010113
2022-01-08 16:36:45,943 iteration 3427 : loss : 0.028899, loss_ce: 0.008735
2022-01-08 16:36:47,386 iteration 3428 : loss : 0.026082, loss_ce: 0.009523
2022-01-08 16:36:48,858 iteration 3429 : loss : 0.024138, loss_ce: 0.008472
2022-01-08 16:36:50,340 iteration 3430 : loss : 0.031711, loss_ce: 0.012606
2022-01-08 16:36:51,669 iteration 3431 : loss : 0.026350, loss_ce: 0.012100
2022-01-08 16:36:53,036 iteration 3432 : loss : 0.027856, loss_ce: 0.009052
2022-01-08 16:36:54,405 iteration 3433 : loss : 0.027706, loss_ce: 0.008773
2022-01-08 16:36:55,870 iteration 3434 : loss : 0.035717, loss_ce: 0.011136

 50%|█████████████▋             | 202/400 [1:26:50<1:25:31, 25.92s/it]2022-01-08 16:36:57,250 iteration 3435 : loss : 0.024893, loss_ce: 0.007287
2022-01-08 16:36:58,629 iteration 3436 : loss : 0.026160, loss_ce: 0.011980
2022-01-08 16:37:00,157 iteration 3437 : loss : 0.031542, loss_ce: 0.014596
2022-01-08 16:37:01,658 iteration 3438 : loss : 0.023088, loss_ce: 0.009589
2022-01-08 16:37:03,143 iteration 3439 : loss : 0.023876, loss_ce: 0.008829
2022-01-08 16:37:04,528 iteration 3440 : loss : 0.020128, loss_ce: 0.007458
2022-01-08 16:37:05,937 iteration 3441 : loss : 0.023268, loss_ce: 0.009861
2022-01-08 16:37:07,485 iteration 3442 : loss : 0.031856, loss_ce: 0.010165
2022-01-08 16:37:08,963 iteration 3443 : loss : 0.027670, loss_ce: 0.010001
2022-01-08 16:37:10,441 iteration 3444 : loss : 0.038088, loss_ce: 0.012416
2022-01-08 16:37:11,868 iteration 3445 : loss : 0.032079, loss_ce: 0.009547
2022-01-08 16:37:13,276 iteration 3446 : loss : 0.027262, loss_ce: 0.011642
2022-01-08 16:37:14,672 iteration 3447 : loss : 0.029336, loss_ce: 0.010895
2022-01-08 16:37:16,152 iteration 3448 : loss : 0.031114, loss_ce: 0.008895
2022-01-08 16:37:17,599 iteration 3449 : loss : 0.034177, loss_ce: 0.014282
2022-01-08 16:37:19,018 iteration 3450 : loss : 0.033753, loss_ce: 0.014515
2022-01-08 16:37:20,539 iteration 3451 : loss : 0.027256, loss_ce: 0.011336

 51%|█████████████▋             | 203/400 [1:27:14<1:23:51, 25.54s/it]2022-01-08 16:37:22,017 iteration 3452 : loss : 0.022812, loss_ce: 0.007730
2022-01-08 16:37:23,416 iteration 3453 : loss : 0.022226, loss_ce: 0.008452
2022-01-08 16:37:24,788 iteration 3454 : loss : 0.024133, loss_ce: 0.007998
2022-01-08 16:37:26,283 iteration 3455 : loss : 0.027395, loss_ce: 0.012150
2022-01-08 16:37:27,655 iteration 3456 : loss : 0.020382, loss_ce: 0.006894
2022-01-08 16:37:29,193 iteration 3457 : loss : 0.030220, loss_ce: 0.012824
2022-01-08 16:37:30,662 iteration 3458 : loss : 0.028119, loss_ce: 0.011919
2022-01-08 16:37:32,087 iteration 3459 : loss : 0.022036, loss_ce: 0.008689
2022-01-08 16:37:33,496 iteration 3460 : loss : 0.027446, loss_ce: 0.011809
2022-01-08 16:37:34,911 iteration 3461 : loss : 0.022959, loss_ce: 0.007760
2022-01-08 16:37:36,325 iteration 3462 : loss : 0.025392, loss_ce: 0.012919
2022-01-08 16:37:37,786 iteration 3463 : loss : 0.031444, loss_ce: 0.011853
2022-01-08 16:37:39,138 iteration 3464 : loss : 0.019594, loss_ce: 0.007445
2022-01-08 16:37:40,612 iteration 3465 : loss : 0.027958, loss_ce: 0.009042
2022-01-08 16:37:42,055 iteration 3466 : loss : 0.021008, loss_ce: 0.007421
2022-01-08 16:37:43,475 iteration 3467 : loss : 0.023986, loss_ce: 0.012396
2022-01-08 16:37:44,884 iteration 3468 : loss : 0.026260, loss_ce: 0.011313

 51%|█████████████▊             | 204/400 [1:27:39<1:22:15, 25.18s/it]2022-01-08 16:37:46,323 iteration 3469 : loss : 0.026346, loss_ce: 0.008092
2022-01-08 16:37:47,800 iteration 3470 : loss : 0.033919, loss_ce: 0.012248
2022-01-08 16:37:49,135 iteration 3471 : loss : 0.022436, loss_ce: 0.008111
2022-01-08 16:37:50,570 iteration 3472 : loss : 0.028428, loss_ce: 0.012079
2022-01-08 16:37:52,123 iteration 3473 : loss : 0.027810, loss_ce: 0.012078
2022-01-08 16:37:53,545 iteration 3474 : loss : 0.039683, loss_ce: 0.012155
2022-01-08 16:37:55,044 iteration 3475 : loss : 0.052350, loss_ce: 0.011966
2022-01-08 16:37:56,425 iteration 3476 : loss : 0.025875, loss_ce: 0.007543
2022-01-08 16:37:57,876 iteration 3477 : loss : 0.026921, loss_ce: 0.008268
2022-01-08 16:37:59,292 iteration 3478 : loss : 0.020547, loss_ce: 0.008043
2022-01-08 16:38:00,664 iteration 3479 : loss : 0.025959, loss_ce: 0.010820
2022-01-08 16:38:01,982 iteration 3480 : loss : 0.020951, loss_ce: 0.008938
2022-01-08 16:38:03,382 iteration 3481 : loss : 0.026431, loss_ce: 0.009796
2022-01-08 16:38:04,789 iteration 3482 : loss : 0.034460, loss_ce: 0.013412
2022-01-08 16:38:06,279 iteration 3483 : loss : 0.033864, loss_ce: 0.016868
2022-01-08 16:38:07,595 iteration 3484 : loss : 0.026472, loss_ce: 0.010389
2022-01-08 16:38:07,595 Training Data Eval:
2022-01-08 16:38:14,518   Average segmentation loss on training set: 0.0179
2022-01-08 16:38:14,518 Validation Data Eval:
2022-01-08 16:38:16,912   Average segmentation loss on validation set: 0.0671
2022-01-08 16:38:18,435 iteration 3485 : loss : 0.040628, loss_ce: 0.018924

 51%|█████████████▊             | 205/400 [1:28:12<1:30:00, 27.70s/it]2022-01-08 16:38:19,905 iteration 3486 : loss : 0.031116, loss_ce: 0.015557
2022-01-08 16:38:21,254 iteration 3487 : loss : 0.020611, loss_ce: 0.008859
2022-01-08 16:38:22,640 iteration 3488 : loss : 0.037979, loss_ce: 0.014357
2022-01-08 16:38:24,043 iteration 3489 : loss : 0.027309, loss_ce: 0.010051
2022-01-08 16:38:25,478 iteration 3490 : loss : 0.029142, loss_ce: 0.011916
2022-01-08 16:38:26,962 iteration 3491 : loss : 0.036132, loss_ce: 0.015323
2022-01-08 16:38:28,305 iteration 3492 : loss : 0.030194, loss_ce: 0.011926
2022-01-08 16:38:29,838 iteration 3493 : loss : 0.031764, loss_ce: 0.013280
2022-01-08 16:38:31,296 iteration 3494 : loss : 0.028166, loss_ce: 0.008174
2022-01-08 16:38:32,701 iteration 3495 : loss : 0.026960, loss_ce: 0.009788
2022-01-08 16:38:34,151 iteration 3496 : loss : 0.020054, loss_ce: 0.007879
2022-01-08 16:38:35,605 iteration 3497 : loss : 0.039653, loss_ce: 0.015802
2022-01-08 16:38:37,148 iteration 3498 : loss : 0.023210, loss_ce: 0.010042
2022-01-08 16:38:38,528 iteration 3499 : loss : 0.038567, loss_ce: 0.014504
2022-01-08 16:38:39,848 iteration 3500 : loss : 0.020148, loss_ce: 0.006688
2022-01-08 16:38:41,212 iteration 3501 : loss : 0.025492, loss_ce: 0.009349
2022-01-08 16:38:42,642 iteration 3502 : loss : 0.035953, loss_ce: 0.012311

 52%|█████████████▉             | 206/400 [1:28:36<1:26:09, 26.65s/it]2022-01-08 16:38:44,142 iteration 3503 : loss : 0.028885, loss_ce: 0.011318
2022-01-08 16:38:45,529 iteration 3504 : loss : 0.017993, loss_ce: 0.005607
2022-01-08 16:38:46,834 iteration 3505 : loss : 0.022522, loss_ce: 0.010950
2022-01-08 16:38:48,269 iteration 3506 : loss : 0.031017, loss_ce: 0.009935
2022-01-08 16:38:49,659 iteration 3507 : loss : 0.030389, loss_ce: 0.009594
2022-01-08 16:38:51,205 iteration 3508 : loss : 0.033028, loss_ce: 0.013944
2022-01-08 16:38:52,644 iteration 3509 : loss : 0.021989, loss_ce: 0.008303
2022-01-08 16:38:53,999 iteration 3510 : loss : 0.031265, loss_ce: 0.013377
2022-01-08 16:38:55,345 iteration 3511 : loss : 0.019395, loss_ce: 0.008881
2022-01-08 16:38:56,838 iteration 3512 : loss : 0.031643, loss_ce: 0.009450
2022-01-08 16:38:58,282 iteration 3513 : loss : 0.028746, loss_ce: 0.008764
2022-01-08 16:38:59,843 iteration 3514 : loss : 0.043814, loss_ce: 0.024582
2022-01-08 16:39:01,234 iteration 3515 : loss : 0.025281, loss_ce: 0.007394
2022-01-08 16:39:02,620 iteration 3516 : loss : 0.017787, loss_ce: 0.006700
2022-01-08 16:39:04,010 iteration 3517 : loss : 0.044350, loss_ce: 0.022097
2022-01-08 16:39:05,403 iteration 3518 : loss : 0.023049, loss_ce: 0.010979
2022-01-08 16:39:06,843 iteration 3519 : loss : 0.024538, loss_ce: 0.008185

 52%|█████████████▉             | 207/400 [1:29:01<1:23:21, 25.91s/it]2022-01-08 16:39:08,330 iteration 3520 : loss : 0.029593, loss_ce: 0.010288
2022-01-08 16:39:09,706 iteration 3521 : loss : 0.034176, loss_ce: 0.014823
2022-01-08 16:39:11,044 iteration 3522 : loss : 0.020114, loss_ce: 0.009561
2022-01-08 16:39:12,433 iteration 3523 : loss : 0.017634, loss_ce: 0.006295
2022-01-08 16:39:13,886 iteration 3524 : loss : 0.022722, loss_ce: 0.010675
2022-01-08 16:39:15,414 iteration 3525 : loss : 0.027273, loss_ce: 0.010329
2022-01-08 16:39:16,858 iteration 3526 : loss : 0.030899, loss_ce: 0.011784
2022-01-08 16:39:18,330 iteration 3527 : loss : 0.029049, loss_ce: 0.009444
2022-01-08 16:39:19,903 iteration 3528 : loss : 0.028364, loss_ce: 0.011868
2022-01-08 16:39:21,360 iteration 3529 : loss : 0.029596, loss_ce: 0.007724
2022-01-08 16:39:22,814 iteration 3530 : loss : 0.019190, loss_ce: 0.007871
2022-01-08 16:39:24,180 iteration 3531 : loss : 0.026704, loss_ce: 0.007882
2022-01-08 16:39:25,679 iteration 3532 : loss : 0.025155, loss_ce: 0.010147
2022-01-08 16:39:27,078 iteration 3533 : loss : 0.022622, loss_ce: 0.006961
2022-01-08 16:39:28,529 iteration 3534 : loss : 0.037207, loss_ce: 0.015357
2022-01-08 16:39:30,040 iteration 3535 : loss : 0.029234, loss_ce: 0.013303
2022-01-08 16:39:31,498 iteration 3536 : loss : 0.022596, loss_ce: 0.008434

 52%|██████████████             | 208/400 [1:29:25<1:21:42, 25.53s/it]2022-01-08 16:39:32,880 iteration 3537 : loss : 0.020489, loss_ce: 0.008222
2022-01-08 16:39:34,209 iteration 3538 : loss : 0.024839, loss_ce: 0.009235
2022-01-08 16:39:35,571 iteration 3539 : loss : 0.018622, loss_ce: 0.008502
2022-01-08 16:39:36,866 iteration 3540 : loss : 0.021490, loss_ce: 0.006842
2022-01-08 16:39:38,357 iteration 3541 : loss : 0.036188, loss_ce: 0.013753
2022-01-08 16:39:39,767 iteration 3542 : loss : 0.023186, loss_ce: 0.010314
2022-01-08 16:39:41,318 iteration 3543 : loss : 0.047484, loss_ce: 0.012894
2022-01-08 16:39:42,647 iteration 3544 : loss : 0.019173, loss_ce: 0.007751
2022-01-08 16:39:44,055 iteration 3545 : loss : 0.020779, loss_ce: 0.008712
2022-01-08 16:39:45,386 iteration 3546 : loss : 0.023821, loss_ce: 0.008620
2022-01-08 16:39:46,796 iteration 3547 : loss : 0.021187, loss_ce: 0.009172
2022-01-08 16:39:48,148 iteration 3548 : loss : 0.026510, loss_ce: 0.009612
2022-01-08 16:39:49,567 iteration 3549 : loss : 0.030365, loss_ce: 0.012050
2022-01-08 16:39:51,030 iteration 3550 : loss : 0.021829, loss_ce: 0.008736
2022-01-08 16:39:52,524 iteration 3551 : loss : 0.030935, loss_ce: 0.010117
2022-01-08 16:39:54,005 iteration 3552 : loss : 0.045716, loss_ce: 0.012348
2022-01-08 16:39:55,499 iteration 3553 : loss : 0.036248, loss_ce: 0.015351

 52%|██████████████             | 209/400 [1:29:49<1:19:49, 25.08s/it]2022-01-08 16:39:56,995 iteration 3554 : loss : 0.027270, loss_ce: 0.010987
2022-01-08 16:39:58,383 iteration 3555 : loss : 0.020626, loss_ce: 0.006505
2022-01-08 16:39:59,772 iteration 3556 : loss : 0.022704, loss_ce: 0.009464
2022-01-08 16:40:01,290 iteration 3557 : loss : 0.031407, loss_ce: 0.009291
2022-01-08 16:40:02,655 iteration 3558 : loss : 0.040830, loss_ce: 0.010333
2022-01-08 16:40:04,054 iteration 3559 : loss : 0.024191, loss_ce: 0.007375
2022-01-08 16:40:05,346 iteration 3560 : loss : 0.018080, loss_ce: 0.008608
2022-01-08 16:40:06,846 iteration 3561 : loss : 0.028115, loss_ce: 0.009819
2022-01-08 16:40:08,224 iteration 3562 : loss : 0.021527, loss_ce: 0.007929
2022-01-08 16:40:09,667 iteration 3563 : loss : 0.028549, loss_ce: 0.009634
2022-01-08 16:40:11,097 iteration 3564 : loss : 0.030935, loss_ce: 0.010941
2022-01-08 16:40:12,639 iteration 3565 : loss : 0.046543, loss_ce: 0.018898
2022-01-08 16:40:14,065 iteration 3566 : loss : 0.025279, loss_ce: 0.008659
2022-01-08 16:40:15,574 iteration 3567 : loss : 0.034182, loss_ce: 0.015415
2022-01-08 16:40:17,063 iteration 3568 : loss : 0.031640, loss_ce: 0.010891
2022-01-08 16:40:18,556 iteration 3569 : loss : 0.032343, loss_ce: 0.007976
2022-01-08 16:40:18,556 Training Data Eval:
2022-01-08 16:40:25,468   Average segmentation loss on training set: 0.0185
2022-01-08 16:40:25,469 Validation Data Eval:
2022-01-08 16:40:27,849   Average segmentation loss on validation set: 0.0980
2022-01-08 16:40:29,287 iteration 3570 : loss : 0.028966, loss_ce: 0.011743

 52%|██████████████▏            | 210/400 [1:30:23<1:27:40, 27.69s/it]2022-01-08 16:40:30,756 iteration 3571 : loss : 0.030225, loss_ce: 0.011784
2022-01-08 16:40:32,178 iteration 3572 : loss : 0.017955, loss_ce: 0.004734
2022-01-08 16:40:33,597 iteration 3573 : loss : 0.032532, loss_ce: 0.013006
2022-01-08 16:40:34,973 iteration 3574 : loss : 0.018245, loss_ce: 0.007922
2022-01-08 16:40:36,361 iteration 3575 : loss : 0.025123, loss_ce: 0.010606
2022-01-08 16:40:37,794 iteration 3576 : loss : 0.035391, loss_ce: 0.012097
2022-01-08 16:40:39,263 iteration 3577 : loss : 0.020551, loss_ce: 0.008861
2022-01-08 16:40:40,735 iteration 3578 : loss : 0.039264, loss_ce: 0.017109
2022-01-08 16:40:42,124 iteration 3579 : loss : 0.028768, loss_ce: 0.010443
2022-01-08 16:40:43,576 iteration 3580 : loss : 0.023411, loss_ce: 0.007328
2022-01-08 16:40:44,947 iteration 3581 : loss : 0.033087, loss_ce: 0.009812
2022-01-08 16:40:46,359 iteration 3582 : loss : 0.021927, loss_ce: 0.008799
2022-01-08 16:40:47,823 iteration 3583 : loss : 0.024339, loss_ce: 0.009749
2022-01-08 16:40:49,196 iteration 3584 : loss : 0.021967, loss_ce: 0.008510
2022-01-08 16:40:50,596 iteration 3585 : loss : 0.023824, loss_ce: 0.008426
2022-01-08 16:40:51,938 iteration 3586 : loss : 0.023037, loss_ce: 0.008099
2022-01-08 16:40:53,334 iteration 3587 : loss : 0.029713, loss_ce: 0.012962

 53%|██████████████▏            | 211/400 [1:30:47<1:23:46, 26.60s/it]2022-01-08 16:40:54,700 iteration 3588 : loss : 0.019626, loss_ce: 0.007041
2022-01-08 16:40:56,150 iteration 3589 : loss : 0.037116, loss_ce: 0.011810
2022-01-08 16:40:57,561 iteration 3590 : loss : 0.022813, loss_ce: 0.010016
2022-01-08 16:40:58,958 iteration 3591 : loss : 0.020735, loss_ce: 0.006571
2022-01-08 16:41:00,439 iteration 3592 : loss : 0.022837, loss_ce: 0.009908
2022-01-08 16:41:01,870 iteration 3593 : loss : 0.031329, loss_ce: 0.008810
2022-01-08 16:41:03,301 iteration 3594 : loss : 0.019171, loss_ce: 0.006038
2022-01-08 16:41:04,868 iteration 3595 : loss : 0.049892, loss_ce: 0.009943
2022-01-08 16:41:06,202 iteration 3596 : loss : 0.026124, loss_ce: 0.011157
2022-01-08 16:41:07,713 iteration 3597 : loss : 0.031658, loss_ce: 0.012083
2022-01-08 16:41:09,126 iteration 3598 : loss : 0.028610, loss_ce: 0.018220
2022-01-08 16:41:10,558 iteration 3599 : loss : 0.032469, loss_ce: 0.013287
2022-01-08 16:41:11,949 iteration 3600 : loss : 0.028275, loss_ce: 0.012984
2022-01-08 16:41:13,365 iteration 3601 : loss : 0.032037, loss_ce: 0.014036
2022-01-08 16:41:14,745 iteration 3602 : loss : 0.025395, loss_ce: 0.011295
2022-01-08 16:41:16,106 iteration 3603 : loss : 0.017096, loss_ce: 0.006042
2022-01-08 16:41:17,454 iteration 3604 : loss : 0.023634, loss_ce: 0.010549

 53%|██████████████▎            | 212/400 [1:31:11<1:21:00, 25.86s/it]2022-01-08 16:41:18,904 iteration 3605 : loss : 0.023066, loss_ce: 0.009135
2022-01-08 16:41:20,310 iteration 3606 : loss : 0.026012, loss_ce: 0.010214
2022-01-08 16:41:21,649 iteration 3607 : loss : 0.020847, loss_ce: 0.007674
2022-01-08 16:41:22,989 iteration 3608 : loss : 0.025304, loss_ce: 0.010658
2022-01-08 16:41:24,428 iteration 3609 : loss : 0.038783, loss_ce: 0.011115
2022-01-08 16:41:25,802 iteration 3610 : loss : 0.026287, loss_ce: 0.011370
2022-01-08 16:41:27,247 iteration 3611 : loss : 0.026804, loss_ce: 0.011516
2022-01-08 16:41:28,723 iteration 3612 : loss : 0.028018, loss_ce: 0.009120
2022-01-08 16:41:30,139 iteration 3613 : loss : 0.026052, loss_ce: 0.008350
2022-01-08 16:41:31,606 iteration 3614 : loss : 0.028172, loss_ce: 0.010536
2022-01-08 16:41:32,988 iteration 3615 : loss : 0.024108, loss_ce: 0.007809
2022-01-08 16:41:34,482 iteration 3616 : loss : 0.035424, loss_ce: 0.013304
2022-01-08 16:41:35,869 iteration 3617 : loss : 0.028425, loss_ce: 0.011548
2022-01-08 16:41:37,276 iteration 3618 : loss : 0.032938, loss_ce: 0.016734
2022-01-08 16:41:38,669 iteration 3619 : loss : 0.023518, loss_ce: 0.008369
2022-01-08 16:41:40,117 iteration 3620 : loss : 0.034869, loss_ce: 0.015559
2022-01-08 16:41:41,508 iteration 3621 : loss : 0.030218, loss_ce: 0.012446

 53%|██████████████▍            | 213/400 [1:31:35<1:18:53, 25.31s/it]2022-01-08 16:41:43,051 iteration 3622 : loss : 0.034294, loss_ce: 0.013764
2022-01-08 16:41:44,466 iteration 3623 : loss : 0.021113, loss_ce: 0.008550
2022-01-08 16:41:45,964 iteration 3624 : loss : 0.021585, loss_ce: 0.006738
2022-01-08 16:41:47,452 iteration 3625 : loss : 0.031977, loss_ce: 0.013590
2022-01-08 16:41:48,864 iteration 3626 : loss : 0.023146, loss_ce: 0.008910
2022-01-08 16:41:50,326 iteration 3627 : loss : 0.023463, loss_ce: 0.010715
2022-01-08 16:41:51,759 iteration 3628 : loss : 0.025021, loss_ce: 0.007427
2022-01-08 16:41:53,265 iteration 3629 : loss : 0.023098, loss_ce: 0.009960
2022-01-08 16:41:54,683 iteration 3630 : loss : 0.020369, loss_ce: 0.008466
2022-01-08 16:41:56,024 iteration 3631 : loss : 0.020800, loss_ce: 0.009485
2022-01-08 16:41:57,364 iteration 3632 : loss : 0.018225, loss_ce: 0.008238
2022-01-08 16:41:58,843 iteration 3633 : loss : 0.036485, loss_ce: 0.013981
2022-01-08 16:42:00,251 iteration 3634 : loss : 0.020726, loss_ce: 0.008224
2022-01-08 16:42:01,649 iteration 3635 : loss : 0.028829, loss_ce: 0.009601
2022-01-08 16:42:03,008 iteration 3636 : loss : 0.026482, loss_ce: 0.012070
2022-01-08 16:42:04,486 iteration 3637 : loss : 0.030600, loss_ce: 0.009944
2022-01-08 16:42:05,835 iteration 3638 : loss : 0.019406, loss_ce: 0.006692

 54%|██████████████▍            | 214/400 [1:32:00<1:17:33, 25.02s/it]2022-01-08 16:42:07,282 iteration 3639 : loss : 0.020439, loss_ce: 0.009071
2022-01-08 16:42:08,740 iteration 3640 : loss : 0.028384, loss_ce: 0.010220
2022-01-08 16:42:10,161 iteration 3641 : loss : 0.022978, loss_ce: 0.006935
2022-01-08 16:42:11,620 iteration 3642 : loss : 0.023670, loss_ce: 0.010593
2022-01-08 16:42:13,030 iteration 3643 : loss : 0.027372, loss_ce: 0.012965
2022-01-08 16:42:14,422 iteration 3644 : loss : 0.024564, loss_ce: 0.011602
2022-01-08 16:42:15,795 iteration 3645 : loss : 0.021837, loss_ce: 0.008928
2022-01-08 16:42:17,219 iteration 3646 : loss : 0.017024, loss_ce: 0.006077
2022-01-08 16:42:18,679 iteration 3647 : loss : 0.028840, loss_ce: 0.011070
2022-01-08 16:42:20,214 iteration 3648 : loss : 0.032021, loss_ce: 0.013259
2022-01-08 16:42:21,652 iteration 3649 : loss : 0.027711, loss_ce: 0.010613
2022-01-08 16:42:23,067 iteration 3650 : loss : 0.019663, loss_ce: 0.006415
2022-01-08 16:42:24,506 iteration 3651 : loss : 0.021810, loss_ce: 0.008677
2022-01-08 16:42:25,886 iteration 3652 : loss : 0.018975, loss_ce: 0.008153
2022-01-08 16:42:27,370 iteration 3653 : loss : 0.046141, loss_ce: 0.010371
2022-01-08 16:42:28,795 iteration 3654 : loss : 0.020187, loss_ce: 0.006763
2022-01-08 16:42:28,795 Training Data Eval:
2022-01-08 16:42:35,702   Average segmentation loss on training set: 0.0154
2022-01-08 16:42:35,703 Validation Data Eval:
2022-01-08 16:42:38,081   Average segmentation loss on validation set: 0.0732
2022-01-08 16:42:39,380 iteration 3655 : loss : 0.020745, loss_ce: 0.007334

 54%|██████████████▌            | 215/400 [1:32:33<1:25:01, 27.58s/it]2022-01-08 16:42:40,918 iteration 3656 : loss : 0.042038, loss_ce: 0.009547
2022-01-08 16:42:42,302 iteration 3657 : loss : 0.020094, loss_ce: 0.009716
2022-01-08 16:42:43,718 iteration 3658 : loss : 0.024301, loss_ce: 0.011022
2022-01-08 16:42:45,177 iteration 3659 : loss : 0.028810, loss_ce: 0.008942
2022-01-08 16:42:46,702 iteration 3660 : loss : 0.048466, loss_ce: 0.017827
2022-01-08 16:42:48,252 iteration 3661 : loss : 0.026018, loss_ce: 0.010811
2022-01-08 16:42:49,578 iteration 3662 : loss : 0.021632, loss_ce: 0.007999
2022-01-08 16:42:50,954 iteration 3663 : loss : 0.021576, loss_ce: 0.007027
2022-01-08 16:42:52,347 iteration 3664 : loss : 0.031790, loss_ce: 0.009534
2022-01-08 16:42:53,751 iteration 3665 : loss : 0.016574, loss_ce: 0.007120
2022-01-08 16:42:55,290 iteration 3666 : loss : 0.033797, loss_ce: 0.014527
2022-01-08 16:42:56,757 iteration 3667 : loss : 0.028564, loss_ce: 0.010965
2022-01-08 16:42:58,228 iteration 3668 : loss : 0.023302, loss_ce: 0.009451
2022-01-08 16:42:59,657 iteration 3669 : loss : 0.027017, loss_ce: 0.013083
2022-01-08 16:43:01,048 iteration 3670 : loss : 0.035574, loss_ce: 0.010204
2022-01-08 16:43:02,520 iteration 3671 : loss : 0.028278, loss_ce: 0.010177
2022-01-08 16:43:03,886 iteration 3672 : loss : 0.025254, loss_ce: 0.009683

 54%|██████████████▌            | 216/400 [1:32:58<1:21:44, 26.65s/it]2022-01-08 16:43:05,368 iteration 3673 : loss : 0.021958, loss_ce: 0.010325
2022-01-08 16:43:06,793 iteration 3674 : loss : 0.025302, loss_ce: 0.010411
2022-01-08 16:43:08,190 iteration 3675 : loss : 0.017903, loss_ce: 0.009056
2022-01-08 16:43:09,587 iteration 3676 : loss : 0.024180, loss_ce: 0.006830
2022-01-08 16:43:10,980 iteration 3677 : loss : 0.021163, loss_ce: 0.009467
2022-01-08 16:43:12,482 iteration 3678 : loss : 0.031161, loss_ce: 0.011375
2022-01-08 16:43:13,879 iteration 3679 : loss : 0.024926, loss_ce: 0.008961
2022-01-08 16:43:15,260 iteration 3680 : loss : 0.029018, loss_ce: 0.008467
2022-01-08 16:43:16,734 iteration 3681 : loss : 0.021204, loss_ce: 0.007441
2022-01-08 16:43:18,125 iteration 3682 : loss : 0.023682, loss_ce: 0.008817
2022-01-08 16:43:19,609 iteration 3683 : loss : 0.047750, loss_ce: 0.005965
2022-01-08 16:43:20,987 iteration 3684 : loss : 0.013311, loss_ce: 0.003854
2022-01-08 16:43:22,372 iteration 3685 : loss : 0.033065, loss_ce: 0.012680
2022-01-08 16:43:23,806 iteration 3686 : loss : 0.022553, loss_ce: 0.008168
2022-01-08 16:43:25,220 iteration 3687 : loss : 0.035060, loss_ce: 0.012576
2022-01-08 16:43:26,622 iteration 3688 : loss : 0.045928, loss_ce: 0.023548
2022-01-08 16:43:27,955 iteration 3689 : loss : 0.030497, loss_ce: 0.012046

 54%|██████████████▋            | 217/400 [1:33:22<1:18:56, 25.88s/it]2022-01-08 16:43:29,373 iteration 3690 : loss : 0.019067, loss_ce: 0.004625
2022-01-08 16:43:30,879 iteration 3691 : loss : 0.042078, loss_ce: 0.009488
2022-01-08 16:43:32,302 iteration 3692 : loss : 0.025632, loss_ce: 0.012595
2022-01-08 16:43:33,797 iteration 3693 : loss : 0.034663, loss_ce: 0.013204
2022-01-08 16:43:35,229 iteration 3694 : loss : 0.018769, loss_ce: 0.008112
2022-01-08 16:43:36,589 iteration 3695 : loss : 0.021677, loss_ce: 0.008678
2022-01-08 16:43:38,052 iteration 3696 : loss : 0.026608, loss_ce: 0.013502
2022-01-08 16:43:39,458 iteration 3697 : loss : 0.028084, loss_ce: 0.007924
2022-01-08 16:43:40,880 iteration 3698 : loss : 0.032097, loss_ce: 0.010459
2022-01-08 16:43:42,368 iteration 3699 : loss : 0.032305, loss_ce: 0.011368
2022-01-08 16:43:43,785 iteration 3700 : loss : 0.024342, loss_ce: 0.011124
2022-01-08 16:43:45,166 iteration 3701 : loss : 0.020420, loss_ce: 0.008330
2022-01-08 16:43:46,538 iteration 3702 : loss : 0.026303, loss_ce: 0.011381
2022-01-08 16:43:48,082 iteration 3703 : loss : 0.037553, loss_ce: 0.018184
2022-01-08 16:43:49,455 iteration 3704 : loss : 0.025589, loss_ce: 0.007724
2022-01-08 16:43:50,816 iteration 3705 : loss : 0.023967, loss_ce: 0.008020
2022-01-08 16:43:52,167 iteration 3706 : loss : 0.023216, loss_ce: 0.005718

 55%|██████████████▋            | 218/400 [1:33:46<1:16:58, 25.38s/it]2022-01-08 16:43:53,636 iteration 3707 : loss : 0.035257, loss_ce: 0.013664
2022-01-08 16:43:55,057 iteration 3708 : loss : 0.023960, loss_ce: 0.009492
2022-01-08 16:43:56,475 iteration 3709 : loss : 0.026527, loss_ce: 0.008116
2022-01-08 16:43:57,945 iteration 3710 : loss : 0.030060, loss_ce: 0.010674
2022-01-08 16:43:59,332 iteration 3711 : loss : 0.018342, loss_ce: 0.006655
2022-01-08 16:44:00,779 iteration 3712 : loss : 0.026815, loss_ce: 0.008900
2022-01-08 16:44:02,142 iteration 3713 : loss : 0.028250, loss_ce: 0.010580
2022-01-08 16:44:03,519 iteration 3714 : loss : 0.016673, loss_ce: 0.005929
2022-01-08 16:44:04,947 iteration 3715 : loss : 0.030812, loss_ce: 0.012230
2022-01-08 16:44:06,316 iteration 3716 : loss : 0.022645, loss_ce: 0.008428
2022-01-08 16:44:07,747 iteration 3717 : loss : 0.024393, loss_ce: 0.009506
2022-01-08 16:44:09,221 iteration 3718 : loss : 0.028403, loss_ce: 0.012505
2022-01-08 16:44:10,573 iteration 3719 : loss : 0.028022, loss_ce: 0.007504
2022-01-08 16:44:12,000 iteration 3720 : loss : 0.020940, loss_ce: 0.010033
2022-01-08 16:44:13,418 iteration 3721 : loss : 0.024846, loss_ce: 0.009115
2022-01-08 16:44:14,814 iteration 3722 : loss : 0.022360, loss_ce: 0.008550
2022-01-08 16:44:16,181 iteration 3723 : loss : 0.025609, loss_ce: 0.006960

 55%|██████████████▊            | 219/400 [1:34:10<1:15:19, 24.97s/it]2022-01-08 16:44:17,572 iteration 3724 : loss : 0.019443, loss_ce: 0.009047
2022-01-08 16:44:18,936 iteration 3725 : loss : 0.021486, loss_ce: 0.008991
2022-01-08 16:44:20,420 iteration 3726 : loss : 0.027699, loss_ce: 0.013334
2022-01-08 16:44:21,839 iteration 3727 : loss : 0.022964, loss_ce: 0.009149
2022-01-08 16:44:23,268 iteration 3728 : loss : 0.029184, loss_ce: 0.008167
2022-01-08 16:44:24,629 iteration 3729 : loss : 0.017595, loss_ce: 0.004880
2022-01-08 16:44:26,021 iteration 3730 : loss : 0.023893, loss_ce: 0.010485
2022-01-08 16:44:27,407 iteration 3731 : loss : 0.019805, loss_ce: 0.006783
2022-01-08 16:44:28,847 iteration 3732 : loss : 0.029530, loss_ce: 0.010792
2022-01-08 16:44:30,205 iteration 3733 : loss : 0.024300, loss_ce: 0.009551
2022-01-08 16:44:31,634 iteration 3734 : loss : 0.024367, loss_ce: 0.012282
2022-01-08 16:44:33,048 iteration 3735 : loss : 0.028691, loss_ce: 0.008716
2022-01-08 16:44:34,524 iteration 3736 : loss : 0.036863, loss_ce: 0.018334
2022-01-08 16:44:35,923 iteration 3737 : loss : 0.025445, loss_ce: 0.007682
2022-01-08 16:44:37,326 iteration 3738 : loss : 0.024792, loss_ce: 0.008320
2022-01-08 16:44:38,680 iteration 3739 : loss : 0.026505, loss_ce: 0.011030
2022-01-08 16:44:38,680 Training Data Eval:
2022-01-08 16:44:45,598   Average segmentation loss on training set: 0.0155
2022-01-08 16:44:45,598 Validation Data Eval:
2022-01-08 16:44:47,979   Average segmentation loss on validation set: 0.0647
2022-01-08 16:44:49,565 iteration 3740 : loss : 0.032539, loss_ce: 0.014341

 55%|██████████████▊            | 220/400 [1:34:43<1:22:28, 27.49s/it]2022-01-08 16:44:51,203 iteration 3741 : loss : 0.038840, loss_ce: 0.011770
2022-01-08 16:44:52,607 iteration 3742 : loss : 0.025271, loss_ce: 0.011517
2022-01-08 16:44:54,017 iteration 3743 : loss : 0.028812, loss_ce: 0.010162
2022-01-08 16:44:55,481 iteration 3744 : loss : 0.031163, loss_ce: 0.012789
2022-01-08 16:44:56,968 iteration 3745 : loss : 0.030654, loss_ce: 0.012108
2022-01-08 16:44:58,464 iteration 3746 : loss : 0.026927, loss_ce: 0.010801
2022-01-08 16:44:59,872 iteration 3747 : loss : 0.023814, loss_ce: 0.007585
2022-01-08 16:45:01,260 iteration 3748 : loss : 0.023837, loss_ce: 0.010867
2022-01-08 16:45:02,732 iteration 3749 : loss : 0.025210, loss_ce: 0.008195
2022-01-08 16:45:04,236 iteration 3750 : loss : 0.024748, loss_ce: 0.008471
2022-01-08 16:45:05,687 iteration 3751 : loss : 0.032937, loss_ce: 0.009711
2022-01-08 16:45:07,076 iteration 3752 : loss : 0.033069, loss_ce: 0.009385
2022-01-08 16:45:08,446 iteration 3753 : loss : 0.021372, loss_ce: 0.006513
2022-01-08 16:45:09,873 iteration 3754 : loss : 0.019017, loss_ce: 0.006785
2022-01-08 16:45:11,349 iteration 3755 : loss : 0.019250, loss_ce: 0.008755
2022-01-08 16:45:12,686 iteration 3756 : loss : 0.025145, loss_ce: 0.010945
2022-01-08 16:45:14,042 iteration 3757 : loss : 0.022263, loss_ce: 0.009060

 55%|██████████████▉            | 221/400 [1:35:08<1:19:19, 26.59s/it]2022-01-08 16:45:15,606 iteration 3758 : loss : 0.031309, loss_ce: 0.011796
2022-01-08 16:45:16,973 iteration 3759 : loss : 0.019969, loss_ce: 0.006883
2022-01-08 16:45:18,364 iteration 3760 : loss : 0.019488, loss_ce: 0.007792
2022-01-08 16:45:19,821 iteration 3761 : loss : 0.025450, loss_ce: 0.010005
2022-01-08 16:45:21,307 iteration 3762 : loss : 0.028674, loss_ce: 0.014088
2022-01-08 16:45:22,837 iteration 3763 : loss : 0.024146, loss_ce: 0.008042
2022-01-08 16:45:24,247 iteration 3764 : loss : 0.031499, loss_ce: 0.011538
2022-01-08 16:45:25,609 iteration 3765 : loss : 0.022624, loss_ce: 0.009711
2022-01-08 16:45:27,079 iteration 3766 : loss : 0.041331, loss_ce: 0.013105
2022-01-08 16:45:28,489 iteration 3767 : loss : 0.017952, loss_ce: 0.006571
2022-01-08 16:45:29,857 iteration 3768 : loss : 0.024525, loss_ce: 0.007352
2022-01-08 16:45:31,233 iteration 3769 : loss : 0.020399, loss_ce: 0.008843
2022-01-08 16:45:32,683 iteration 3770 : loss : 0.027742, loss_ce: 0.005679
2022-01-08 16:45:34,244 iteration 3771 : loss : 0.030344, loss_ce: 0.010644
2022-01-08 16:45:35,734 iteration 3772 : loss : 0.024084, loss_ce: 0.006751
2022-01-08 16:45:37,180 iteration 3773 : loss : 0.018962, loss_ce: 0.007609
2022-01-08 16:45:38,675 iteration 3774 : loss : 0.039637, loss_ce: 0.019450

 56%|██████████████▉            | 222/400 [1:35:32<1:17:08, 26.00s/it]2022-01-08 16:45:40,131 iteration 3775 : loss : 0.029949, loss_ce: 0.011452
2022-01-08 16:45:41,456 iteration 3776 : loss : 0.023859, loss_ce: 0.010231
2022-01-08 16:45:42,853 iteration 3777 : loss : 0.024090, loss_ce: 0.005953
2022-01-08 16:45:44,218 iteration 3778 : loss : 0.019079, loss_ce: 0.007548
2022-01-08 16:45:45,584 iteration 3779 : loss : 0.019026, loss_ce: 0.008339
2022-01-08 16:45:47,010 iteration 3780 : loss : 0.024336, loss_ce: 0.009235
2022-01-08 16:45:48,433 iteration 3781 : loss : 0.025670, loss_ce: 0.011103
2022-01-08 16:45:49,870 iteration 3782 : loss : 0.067469, loss_ce: 0.010365
2022-01-08 16:45:51,307 iteration 3783 : loss : 0.019299, loss_ce: 0.008858
2022-01-08 16:45:52,758 iteration 3784 : loss : 0.024456, loss_ce: 0.010238
2022-01-08 16:45:54,141 iteration 3785 : loss : 0.037591, loss_ce: 0.014976
2022-01-08 16:45:55,517 iteration 3786 : loss : 0.021791, loss_ce: 0.008385
2022-01-08 16:45:56,911 iteration 3787 : loss : 0.023304, loss_ce: 0.008285
2022-01-08 16:45:58,408 iteration 3788 : loss : 0.032019, loss_ce: 0.007417
2022-01-08 16:45:59,820 iteration 3789 : loss : 0.023316, loss_ce: 0.006212
2022-01-08 16:46:01,269 iteration 3790 : loss : 0.031594, loss_ce: 0.010769
2022-01-08 16:46:02,713 iteration 3791 : loss : 0.026624, loss_ce: 0.011436

 56%|███████████████            | 223/400 [1:35:56<1:14:58, 25.41s/it]2022-01-08 16:46:04,148 iteration 3792 : loss : 0.015947, loss_ce: 0.005459
2022-01-08 16:46:05,615 iteration 3793 : loss : 0.024475, loss_ce: 0.007268
2022-01-08 16:46:07,068 iteration 3794 : loss : 0.032137, loss_ce: 0.013166
2022-01-08 16:46:08,484 iteration 3795 : loss : 0.018569, loss_ce: 0.005684
2022-01-08 16:46:09,787 iteration 3796 : loss : 0.017117, loss_ce: 0.005722
2022-01-08 16:46:11,167 iteration 3797 : loss : 0.023843, loss_ce: 0.007218
2022-01-08 16:46:12,497 iteration 3798 : loss : 0.018659, loss_ce: 0.006703
2022-01-08 16:46:13,885 iteration 3799 : loss : 0.022103, loss_ce: 0.007134
2022-01-08 16:46:15,272 iteration 3800 : loss : 0.017402, loss_ce: 0.005145
2022-01-08 16:46:16,663 iteration 3801 : loss : 0.028180, loss_ce: 0.006893
2022-01-08 16:46:18,029 iteration 3802 : loss : 0.021792, loss_ce: 0.010152
2022-01-08 16:46:19,425 iteration 3803 : loss : 0.016432, loss_ce: 0.005606
2022-01-08 16:46:20,831 iteration 3804 : loss : 0.024808, loss_ce: 0.009929
2022-01-08 16:46:22,211 iteration 3805 : loss : 0.029623, loss_ce: 0.013316
2022-01-08 16:46:23,579 iteration 3806 : loss : 0.029239, loss_ce: 0.013972
2022-01-08 16:46:25,028 iteration 3807 : loss : 0.019290, loss_ce: 0.006901
2022-01-08 16:46:26,448 iteration 3808 : loss : 0.025202, loss_ce: 0.010052

 56%|███████████████            | 224/400 [1:36:20<1:13:03, 24.91s/it]2022-01-08 16:46:27,848 iteration 3809 : loss : 0.015679, loss_ce: 0.005310
2022-01-08 16:46:29,226 iteration 3810 : loss : 0.019735, loss_ce: 0.007592
2022-01-08 16:46:30,628 iteration 3811 : loss : 0.018406, loss_ce: 0.005359
2022-01-08 16:46:32,050 iteration 3812 : loss : 0.023417, loss_ce: 0.011568
2022-01-08 16:46:33,447 iteration 3813 : loss : 0.019815, loss_ce: 0.009247
2022-01-08 16:46:34,889 iteration 3814 : loss : 0.038140, loss_ce: 0.014999
2022-01-08 16:46:36,298 iteration 3815 : loss : 0.025800, loss_ce: 0.010552
2022-01-08 16:46:37,732 iteration 3816 : loss : 0.019237, loss_ce: 0.007085
2022-01-08 16:46:39,088 iteration 3817 : loss : 0.020410, loss_ce: 0.007126
2022-01-08 16:46:40,539 iteration 3818 : loss : 0.017901, loss_ce: 0.007866
2022-01-08 16:46:42,006 iteration 3819 : loss : 0.019605, loss_ce: 0.008751
2022-01-08 16:46:43,448 iteration 3820 : loss : 0.025436, loss_ce: 0.008593
2022-01-08 16:46:44,895 iteration 3821 : loss : 0.034286, loss_ce: 0.013275
2022-01-08 16:46:46,277 iteration 3822 : loss : 0.026922, loss_ce: 0.009544
2022-01-08 16:46:47,806 iteration 3823 : loss : 0.026134, loss_ce: 0.006335
2022-01-08 16:46:49,248 iteration 3824 : loss : 0.039124, loss_ce: 0.011720
2022-01-08 16:46:49,249 Training Data Eval:
2022-01-08 16:46:56,171   Average segmentation loss on training set: 0.0147
2022-01-08 16:46:56,171 Validation Data Eval:
2022-01-08 16:46:58,558   Average segmentation loss on validation set: 0.0703
2022-01-08 16:47:00,056 iteration 3825 : loss : 0.024207, loss_ce: 0.009206

 56%|███████████████▏           | 225/400 [1:36:54<1:20:15, 27.52s/it]2022-01-08 16:47:01,549 iteration 3826 : loss : 0.020685, loss_ce: 0.008785
2022-01-08 16:47:02,913 iteration 3827 : loss : 0.018596, loss_ce: 0.006361
2022-01-08 16:47:04,348 iteration 3828 : loss : 0.023567, loss_ce: 0.009342
2022-01-08 16:47:05,772 iteration 3829 : loss : 0.023307, loss_ce: 0.006929
2022-01-08 16:47:07,144 iteration 3830 : loss : 0.015411, loss_ce: 0.005430
2022-01-08 16:47:08,497 iteration 3831 : loss : 0.017768, loss_ce: 0.006006
2022-01-08 16:47:09,850 iteration 3832 : loss : 0.020302, loss_ce: 0.004565
2022-01-08 16:47:11,261 iteration 3833 : loss : 0.018084, loss_ce: 0.008559
2022-01-08 16:47:12,713 iteration 3834 : loss : 0.028980, loss_ce: 0.012833
2022-01-08 16:47:14,150 iteration 3835 : loss : 0.027668, loss_ce: 0.010622
2022-01-08 16:47:15,570 iteration 3836 : loss : 0.024352, loss_ce: 0.009862
2022-01-08 16:47:17,014 iteration 3837 : loss : 0.027065, loss_ce: 0.010250
2022-01-08 16:47:18,536 iteration 3838 : loss : 0.021937, loss_ce: 0.006950
2022-01-08 16:47:19,951 iteration 3839 : loss : 0.021764, loss_ce: 0.010141
2022-01-08 16:47:21,376 iteration 3840 : loss : 0.023070, loss_ce: 0.006338
2022-01-08 16:47:22,756 iteration 3841 : loss : 0.026854, loss_ce: 0.009132
2022-01-08 16:47:24,199 iteration 3842 : loss : 0.029295, loss_ce: 0.015124

 56%|███████████████▎           | 226/400 [1:37:18<1:16:51, 26.51s/it]2022-01-08 16:47:25,633 iteration 3843 : loss : 0.022058, loss_ce: 0.008219
2022-01-08 16:47:27,087 iteration 3844 : loss : 0.027781, loss_ce: 0.009036
2022-01-08 16:47:28,534 iteration 3845 : loss : 0.021888, loss_ce: 0.009892
2022-01-08 16:47:29,903 iteration 3846 : loss : 0.017131, loss_ce: 0.006171
2022-01-08 16:47:31,292 iteration 3847 : loss : 0.029620, loss_ce: 0.010036
2022-01-08 16:47:32,759 iteration 3848 : loss : 0.028277, loss_ce: 0.014236
2022-01-08 16:47:34,298 iteration 3849 : loss : 0.040003, loss_ce: 0.016506
2022-01-08 16:47:35,814 iteration 3850 : loss : 0.068992, loss_ce: 0.021508
2022-01-08 16:47:37,245 iteration 3851 : loss : 0.019597, loss_ce: 0.008731
2022-01-08 16:47:38,687 iteration 3852 : loss : 0.039408, loss_ce: 0.014290
2022-01-08 16:47:40,055 iteration 3853 : loss : 0.047212, loss_ce: 0.014648
2022-01-08 16:47:41,508 iteration 3854 : loss : 0.030952, loss_ce: 0.009171
2022-01-08 16:47:43,076 iteration 3855 : loss : 0.027332, loss_ce: 0.012057
2022-01-08 16:47:44,355 iteration 3856 : loss : 0.022703, loss_ce: 0.010047
2022-01-08 16:47:45,748 iteration 3857 : loss : 0.035826, loss_ce: 0.017107
2022-01-08 16:47:47,061 iteration 3858 : loss : 0.031326, loss_ce: 0.012926
2022-01-08 16:47:48,463 iteration 3859 : loss : 0.024819, loss_ce: 0.011209

 57%|███████████████▎           | 227/400 [1:37:42<1:14:29, 25.83s/it]2022-01-08 16:47:49,935 iteration 3860 : loss : 0.025025, loss_ce: 0.009999
2022-01-08 16:47:51,436 iteration 3861 : loss : 0.036567, loss_ce: 0.017731
2022-01-08 16:47:52,885 iteration 3862 : loss : 0.040580, loss_ce: 0.016919
2022-01-08 16:47:54,325 iteration 3863 : loss : 0.023106, loss_ce: 0.008289
2022-01-08 16:47:55,790 iteration 3864 : loss : 0.034455, loss_ce: 0.015212
2022-01-08 16:47:57,199 iteration 3865 : loss : 0.044216, loss_ce: 0.016764
2022-01-08 16:47:58,747 iteration 3866 : loss : 0.035003, loss_ce: 0.011720
2022-01-08 16:48:00,152 iteration 3867 : loss : 0.026500, loss_ce: 0.010088
2022-01-08 16:48:01,631 iteration 3868 : loss : 0.086545, loss_ce: 0.047399
2022-01-08 16:48:03,091 iteration 3869 : loss : 0.032446, loss_ce: 0.014326
2022-01-08 16:48:04,570 iteration 3870 : loss : 0.024885, loss_ce: 0.008894
2022-01-08 16:48:06,023 iteration 3871 : loss : 0.030311, loss_ce: 0.009461
2022-01-08 16:48:07,402 iteration 3872 : loss : 0.027089, loss_ce: 0.010150
2022-01-08 16:48:08,776 iteration 3873 : loss : 0.020744, loss_ce: 0.010252
2022-01-08 16:48:10,219 iteration 3874 : loss : 0.033930, loss_ce: 0.013909
2022-01-08 16:48:11,653 iteration 3875 : loss : 0.052720, loss_ce: 0.020561
2022-01-08 16:48:13,099 iteration 3876 : loss : 0.030725, loss_ce: 0.009619

 57%|███████████████▍           | 228/400 [1:38:07<1:13:01, 25.48s/it]2022-01-08 16:48:14,542 iteration 3877 : loss : 0.030697, loss_ce: 0.013097
2022-01-08 16:48:15,994 iteration 3878 : loss : 0.028330, loss_ce: 0.010393
2022-01-08 16:48:17,381 iteration 3879 : loss : 0.024943, loss_ce: 0.008888
2022-01-08 16:48:18,841 iteration 3880 : loss : 0.022989, loss_ce: 0.010439
2022-01-08 16:48:20,227 iteration 3881 : loss : 0.023349, loss_ce: 0.010612
2022-01-08 16:48:21,745 iteration 3882 : loss : 0.042822, loss_ce: 0.011095
2022-01-08 16:48:23,230 iteration 3883 : loss : 0.028211, loss_ce: 0.009403
2022-01-08 16:48:24,677 iteration 3884 : loss : 0.039832, loss_ce: 0.015208
2022-01-08 16:48:26,154 iteration 3885 : loss : 0.043664, loss_ce: 0.014152
2022-01-08 16:48:27,631 iteration 3886 : loss : 0.031495, loss_ce: 0.011592
2022-01-08 16:48:28,996 iteration 3887 : loss : 0.023269, loss_ce: 0.008792
2022-01-08 16:48:30,460 iteration 3888 : loss : 0.030290, loss_ce: 0.013958
2022-01-08 16:48:31,890 iteration 3889 : loss : 0.023670, loss_ce: 0.009602
2022-01-08 16:48:33,438 iteration 3890 : loss : 0.048895, loss_ce: 0.014227
2022-01-08 16:48:34,832 iteration 3891 : loss : 0.036451, loss_ce: 0.013156
2022-01-08 16:48:36,259 iteration 3892 : loss : 0.022206, loss_ce: 0.009273
2022-01-08 16:48:37,719 iteration 3893 : loss : 0.045112, loss_ce: 0.014309

 57%|███████████████▍           | 229/400 [1:38:31<1:11:52, 25.22s/it]2022-01-08 16:48:39,182 iteration 3894 : loss : 0.018025, loss_ce: 0.005155
2022-01-08 16:48:40,587 iteration 3895 : loss : 0.029476, loss_ce: 0.011430
2022-01-08 16:48:42,007 iteration 3896 : loss : 0.029363, loss_ce: 0.012229
2022-01-08 16:48:43,477 iteration 3897 : loss : 0.027265, loss_ce: 0.011673
2022-01-08 16:48:44,932 iteration 3898 : loss : 0.040624, loss_ce: 0.012721
2022-01-08 16:48:46,277 iteration 3899 : loss : 0.026452, loss_ce: 0.009769
2022-01-08 16:48:47,656 iteration 3900 : loss : 0.030759, loss_ce: 0.012275
2022-01-08 16:48:49,021 iteration 3901 : loss : 0.025241, loss_ce: 0.010283
2022-01-08 16:48:50,390 iteration 3902 : loss : 0.035635, loss_ce: 0.016065
2022-01-08 16:48:51,724 iteration 3903 : loss : 0.025778, loss_ce: 0.007379
2022-01-08 16:48:53,139 iteration 3904 : loss : 0.030139, loss_ce: 0.009936
2022-01-08 16:48:54,534 iteration 3905 : loss : 0.025104, loss_ce: 0.007831
2022-01-08 16:48:55,848 iteration 3906 : loss : 0.017344, loss_ce: 0.007155
2022-01-08 16:48:57,147 iteration 3907 : loss : 0.017857, loss_ce: 0.006323
2022-01-08 16:48:58,472 iteration 3908 : loss : 0.019410, loss_ce: 0.007144
2022-01-08 16:48:59,872 iteration 3909 : loss : 0.035095, loss_ce: 0.020740
2022-01-08 16:48:59,872 Training Data Eval:
2022-01-08 16:49:06,787   Average segmentation loss on training set: 0.0159
2022-01-08 16:49:06,788 Validation Data Eval:
2022-01-08 16:49:09,165   Average segmentation loss on validation set: 0.0732
2022-01-08 16:49:10,646 iteration 3910 : loss : 0.021235, loss_ce: 0.007323

 57%|███████████████▌           | 230/400 [1:39:04<1:18:00, 27.53s/it]2022-01-08 16:49:12,081 iteration 3911 : loss : 0.021300, loss_ce: 0.008612
2022-01-08 16:49:13,529 iteration 3912 : loss : 0.023435, loss_ce: 0.008875
2022-01-08 16:49:14,932 iteration 3913 : loss : 0.020406, loss_ce: 0.008317
2022-01-08 16:49:16,335 iteration 3914 : loss : 0.015994, loss_ce: 0.007252
2022-01-08 16:49:17,727 iteration 3915 : loss : 0.029279, loss_ce: 0.012987
2022-01-08 16:49:19,086 iteration 3916 : loss : 0.018950, loss_ce: 0.006260
2022-01-08 16:49:20,536 iteration 3917 : loss : 0.030143, loss_ce: 0.011973
2022-01-08 16:49:21,972 iteration 3918 : loss : 0.030007, loss_ce: 0.010149
2022-01-08 16:49:23,531 iteration 3919 : loss : 0.035985, loss_ce: 0.012678
2022-01-08 16:49:24,896 iteration 3920 : loss : 0.019614, loss_ce: 0.007701
2022-01-08 16:49:26,294 iteration 3921 : loss : 0.021694, loss_ce: 0.009059
2022-01-08 16:49:27,755 iteration 3922 : loss : 0.025915, loss_ce: 0.009936
2022-01-08 16:49:29,145 iteration 3923 : loss : 0.019363, loss_ce: 0.009595
2022-01-08 16:49:30,497 iteration 3924 : loss : 0.024715, loss_ce: 0.006695
2022-01-08 16:49:31,993 iteration 3925 : loss : 0.031075, loss_ce: 0.010234
2022-01-08 16:49:33,462 iteration 3926 : loss : 0.020430, loss_ce: 0.007230
2022-01-08 16:49:34,867 iteration 3927 : loss : 0.023174, loss_ce: 0.009820

 58%|███████████████▌           | 231/400 [1:39:29<1:14:45, 26.54s/it]2022-01-08 16:49:36,393 iteration 3928 : loss : 0.042969, loss_ce: 0.024451
2022-01-08 16:49:37,813 iteration 3929 : loss : 0.030007, loss_ce: 0.015090
2022-01-08 16:49:39,289 iteration 3930 : loss : 0.026660, loss_ce: 0.010028
2022-01-08 16:49:40,759 iteration 3931 : loss : 0.019767, loss_ce: 0.007581
2022-01-08 16:49:42,222 iteration 3932 : loss : 0.032801, loss_ce: 0.010006
2022-01-08 16:49:43,736 iteration 3933 : loss : 0.029085, loss_ce: 0.011899
2022-01-08 16:49:45,185 iteration 3934 : loss : 0.022395, loss_ce: 0.009910
2022-01-08 16:49:46,523 iteration 3935 : loss : 0.032910, loss_ce: 0.014065
2022-01-08 16:49:48,084 iteration 3936 : loss : 0.023199, loss_ce: 0.009592
2022-01-08 16:49:49,455 iteration 3937 : loss : 0.025727, loss_ce: 0.011733
2022-01-08 16:49:50,929 iteration 3938 : loss : 0.058186, loss_ce: 0.010137
2022-01-08 16:49:52,260 iteration 3939 : loss : 0.031414, loss_ce: 0.008997
2022-01-08 16:49:53,640 iteration 3940 : loss : 0.022559, loss_ce: 0.008224
2022-01-08 16:49:55,047 iteration 3941 : loss : 0.025368, loss_ce: 0.010943
2022-01-08 16:49:56,521 iteration 3942 : loss : 0.039755, loss_ce: 0.016695
2022-01-08 16:49:57,894 iteration 3943 : loss : 0.022418, loss_ce: 0.005009
2022-01-08 16:49:59,378 iteration 3944 : loss : 0.038523, loss_ce: 0.013976

 58%|███████████████▋           | 232/400 [1:39:53<1:12:36, 25.93s/it]2022-01-08 16:50:00,877 iteration 3945 : loss : 0.041342, loss_ce: 0.019530
2022-01-08 16:50:02,182 iteration 3946 : loss : 0.018616, loss_ce: 0.008705
2022-01-08 16:50:03,576 iteration 3947 : loss : 0.024476, loss_ce: 0.007343
2022-01-08 16:50:05,142 iteration 3948 : loss : 0.043463, loss_ce: 0.014324
2022-01-08 16:50:06,610 iteration 3949 : loss : 0.032360, loss_ce: 0.012837
2022-01-08 16:50:08,104 iteration 3950 : loss : 0.035227, loss_ce: 0.012216
2022-01-08 16:50:09,458 iteration 3951 : loss : 0.020785, loss_ce: 0.009503
2022-01-08 16:50:10,923 iteration 3952 : loss : 0.020037, loss_ce: 0.007832
2022-01-08 16:50:12,416 iteration 3953 : loss : 0.048498, loss_ce: 0.019022
2022-01-08 16:50:13,824 iteration 3954 : loss : 0.036361, loss_ce: 0.010147
2022-01-08 16:50:15,219 iteration 3955 : loss : 0.017001, loss_ce: 0.006047
2022-01-08 16:50:16,777 iteration 3956 : loss : 0.032978, loss_ce: 0.013827
2022-01-08 16:50:18,154 iteration 3957 : loss : 0.022230, loss_ce: 0.009549
2022-01-08 16:50:19,537 iteration 3958 : loss : 0.023304, loss_ce: 0.008605
2022-01-08 16:50:21,046 iteration 3959 : loss : 0.030045, loss_ce: 0.011342
2022-01-08 16:50:22,436 iteration 3960 : loss : 0.022144, loss_ce: 0.010672
2022-01-08 16:50:23,850 iteration 3961 : loss : 0.030343, loss_ce: 0.013264

 58%|███████████████▋           | 233/400 [1:40:18<1:10:57, 25.49s/it]2022-01-08 16:50:25,360 iteration 3962 : loss : 0.028289, loss_ce: 0.010590
2022-01-08 16:50:26,773 iteration 3963 : loss : 0.022014, loss_ce: 0.009963
2022-01-08 16:50:28,289 iteration 3964 : loss : 0.039312, loss_ce: 0.016292
2022-01-08 16:50:29,655 iteration 3965 : loss : 0.023362, loss_ce: 0.007044
2022-01-08 16:50:31,119 iteration 3966 : loss : 0.028192, loss_ce: 0.010013
2022-01-08 16:50:32,546 iteration 3967 : loss : 0.026464, loss_ce: 0.009810
2022-01-08 16:50:33,847 iteration 3968 : loss : 0.024444, loss_ce: 0.007815
2022-01-08 16:50:35,276 iteration 3969 : loss : 0.028003, loss_ce: 0.008313
2022-01-08 16:50:36,673 iteration 3970 : loss : 0.024386, loss_ce: 0.008106
2022-01-08 16:50:37,965 iteration 3971 : loss : 0.020486, loss_ce: 0.007909
2022-01-08 16:50:39,408 iteration 3972 : loss : 0.029788, loss_ce: 0.008603
2022-01-08 16:50:40,766 iteration 3973 : loss : 0.040217, loss_ce: 0.022781
2022-01-08 16:50:42,079 iteration 3974 : loss : 0.018869, loss_ce: 0.005705
2022-01-08 16:50:43,506 iteration 3975 : loss : 0.025456, loss_ce: 0.009558
2022-01-08 16:50:44,993 iteration 3976 : loss : 0.028084, loss_ce: 0.010094
2022-01-08 16:50:46,480 iteration 3977 : loss : 0.026348, loss_ce: 0.012329
2022-01-08 16:50:47,994 iteration 3978 : loss : 0.040226, loss_ce: 0.014007

 58%|███████████████▊           | 234/400 [1:40:42<1:09:24, 25.09s/it]2022-01-08 16:50:49,475 iteration 3979 : loss : 0.027551, loss_ce: 0.010213
2022-01-08 16:50:50,943 iteration 3980 : loss : 0.025741, loss_ce: 0.008256
2022-01-08 16:50:52,336 iteration 3981 : loss : 0.024147, loss_ce: 0.010022
2022-01-08 16:50:53,634 iteration 3982 : loss : 0.019446, loss_ce: 0.006875
2022-01-08 16:50:54,961 iteration 3983 : loss : 0.018444, loss_ce: 0.008145
2022-01-08 16:50:56,330 iteration 3984 : loss : 0.030644, loss_ce: 0.015959
2022-01-08 16:50:57,764 iteration 3985 : loss : 0.043218, loss_ce: 0.028857
2022-01-08 16:50:59,279 iteration 3986 : loss : 0.028791, loss_ce: 0.012324
2022-01-08 16:51:00,732 iteration 3987 : loss : 0.038243, loss_ce: 0.017277
2022-01-08 16:51:02,143 iteration 3988 : loss : 0.028663, loss_ce: 0.012442
2022-01-08 16:51:03,530 iteration 3989 : loss : 0.043003, loss_ce: 0.013911
2022-01-08 16:51:04,947 iteration 3990 : loss : 0.043079, loss_ce: 0.013276
2022-01-08 16:51:06,422 iteration 3991 : loss : 0.027900, loss_ce: 0.007812
2022-01-08 16:51:07,856 iteration 3992 : loss : 0.058055, loss_ce: 0.021106
2022-01-08 16:51:09,327 iteration 3993 : loss : 0.042598, loss_ce: 0.016439
2022-01-08 16:51:10,719 iteration 3994 : loss : 0.017847, loss_ce: 0.008628
2022-01-08 16:51:10,719 Training Data Eval:
2022-01-08 16:51:17,648   Average segmentation loss on training set: 0.0188
2022-01-08 16:51:17,649 Validation Data Eval:
2022-01-08 16:51:20,042   Average segmentation loss on validation set: 0.0749
2022-01-08 16:51:21,388 iteration 3995 : loss : 0.028092, loss_ce: 0.013231

 59%|███████████████▊           | 235/400 [1:41:15<1:15:50, 27.58s/it]2022-01-08 16:51:22,935 iteration 3996 : loss : 0.020917, loss_ce: 0.006684
2022-01-08 16:51:24,284 iteration 3997 : loss : 0.020584, loss_ce: 0.007562
2022-01-08 16:51:25,721 iteration 3998 : loss : 0.028886, loss_ce: 0.013212
2022-01-08 16:51:27,116 iteration 3999 : loss : 0.020811, loss_ce: 0.005435
2022-01-08 16:51:28,584 iteration 4000 : loss : 0.038389, loss_ce: 0.022055
2022-01-08 16:51:29,928 iteration 4001 : loss : 0.022861, loss_ce: 0.010148
2022-01-08 16:51:31,341 iteration 4002 : loss : 0.020635, loss_ce: 0.008654
2022-01-08 16:51:32,763 iteration 4003 : loss : 0.025106, loss_ce: 0.010950
2022-01-08 16:51:34,222 iteration 4004 : loss : 0.028105, loss_ce: 0.008701
2022-01-08 16:51:35,639 iteration 4005 : loss : 0.027214, loss_ce: 0.012800
2022-01-08 16:51:36,991 iteration 4006 : loss : 0.020031, loss_ce: 0.008539
2022-01-08 16:51:38,460 iteration 4007 : loss : 0.030636, loss_ce: 0.009988
2022-01-08 16:51:39,827 iteration 4008 : loss : 0.021028, loss_ce: 0.007876
2022-01-08 16:51:41,232 iteration 4009 : loss : 0.036304, loss_ce: 0.016429
2022-01-08 16:51:42,715 iteration 4010 : loss : 0.034816, loss_ce: 0.017226
2022-01-08 16:51:44,069 iteration 4011 : loss : 0.020671, loss_ce: 0.006173
2022-01-08 16:51:45,566 iteration 4012 : loss : 0.023088, loss_ce: 0.009301

 59%|███████████████▉           | 236/400 [1:41:39<1:12:35, 26.56s/it]2022-01-08 16:51:47,138 iteration 4013 : loss : 0.060766, loss_ce: 0.025292
2022-01-08 16:51:48,497 iteration 4014 : loss : 0.027928, loss_ce: 0.011109
2022-01-08 16:51:49,967 iteration 4015 : loss : 0.033640, loss_ce: 0.014692
2022-01-08 16:51:51,429 iteration 4016 : loss : 0.022641, loss_ce: 0.008717
2022-01-08 16:51:52,913 iteration 4017 : loss : 0.036830, loss_ce: 0.012229
2022-01-08 16:51:54,278 iteration 4018 : loss : 0.031519, loss_ce: 0.011159
2022-01-08 16:51:55,683 iteration 4019 : loss : 0.030465, loss_ce: 0.016595
2022-01-08 16:51:57,036 iteration 4020 : loss : 0.025796, loss_ce: 0.015924
2022-01-08 16:51:58,410 iteration 4021 : loss : 0.020214, loss_ce: 0.008206
2022-01-08 16:51:59,855 iteration 4022 : loss : 0.033271, loss_ce: 0.017209
2022-01-08 16:52:01,271 iteration 4023 : loss : 0.021280, loss_ce: 0.007671
2022-01-08 16:52:02,646 iteration 4024 : loss : 0.022183, loss_ce: 0.008236
2022-01-08 16:52:04,007 iteration 4025 : loss : 0.019242, loss_ce: 0.007020
2022-01-08 16:52:05,448 iteration 4026 : loss : 0.021112, loss_ce: 0.009350
2022-01-08 16:52:06,893 iteration 4027 : loss : 0.031123, loss_ce: 0.011493
2022-01-08 16:52:08,369 iteration 4028 : loss : 0.024805, loss_ce: 0.007782
2022-01-08 16:52:09,731 iteration 4029 : loss : 0.031453, loss_ce: 0.014930

 59%|███████████████▉           | 237/400 [1:42:03<1:10:12, 25.84s/it]2022-01-08 16:52:11,273 iteration 4030 : loss : 0.046648, loss_ce: 0.019473
2022-01-08 16:52:12,715 iteration 4031 : loss : 0.037090, loss_ce: 0.013701
2022-01-08 16:52:14,125 iteration 4032 : loss : 0.029208, loss_ce: 0.013614
2022-01-08 16:52:15,537 iteration 4033 : loss : 0.035081, loss_ce: 0.011656
2022-01-08 16:52:16,875 iteration 4034 : loss : 0.026407, loss_ce: 0.008550
2022-01-08 16:52:18,261 iteration 4035 : loss : 0.017227, loss_ce: 0.005117
2022-01-08 16:52:19,709 iteration 4036 : loss : 0.030291, loss_ce: 0.010481
2022-01-08 16:52:21,068 iteration 4037 : loss : 0.019464, loss_ce: 0.009177
2022-01-08 16:52:22,554 iteration 4038 : loss : 0.031160, loss_ce: 0.011084
2022-01-08 16:52:24,076 iteration 4039 : loss : 0.022969, loss_ce: 0.008846
2022-01-08 16:52:25,587 iteration 4040 : loss : 0.034727, loss_ce: 0.018055
2022-01-08 16:52:27,072 iteration 4041 : loss : 0.019348, loss_ce: 0.007248
2022-01-08 16:52:28,449 iteration 4042 : loss : 0.034564, loss_ce: 0.012268
2022-01-08 16:52:29,872 iteration 4043 : loss : 0.183255, loss_ce: 0.010668
2022-01-08 16:52:31,250 iteration 4044 : loss : 0.023853, loss_ce: 0.009202
2022-01-08 16:52:32,649 iteration 4045 : loss : 0.019231, loss_ce: 0.008952
2022-01-08 16:52:34,123 iteration 4046 : loss : 0.023965, loss_ce: 0.011292

 60%|████████████████           | 238/400 [1:42:28<1:08:35, 25.41s/it]2022-01-08 16:52:35,690 iteration 4047 : loss : 0.023607, loss_ce: 0.011575
2022-01-08 16:52:37,163 iteration 4048 : loss : 0.021634, loss_ce: 0.007792
2022-01-08 16:52:38,543 iteration 4049 : loss : 0.020038, loss_ce: 0.007177
2022-01-08 16:52:39,998 iteration 4050 : loss : 0.029155, loss_ce: 0.011729
2022-01-08 16:52:41,546 iteration 4051 : loss : 0.062402, loss_ce: 0.009943
2022-01-08 16:52:42,894 iteration 4052 : loss : 0.024866, loss_ce: 0.008170
2022-01-08 16:52:44,205 iteration 4053 : loss : 0.021731, loss_ce: 0.006878
2022-01-08 16:52:45,565 iteration 4054 : loss : 0.034162, loss_ce: 0.010310
2022-01-08 16:52:46,966 iteration 4055 : loss : 0.025069, loss_ce: 0.010952
2022-01-08 16:52:48,390 iteration 4056 : loss : 0.034668, loss_ce: 0.017254
2022-01-08 16:52:49,751 iteration 4057 : loss : 0.026119, loss_ce: 0.007115
2022-01-08 16:52:51,151 iteration 4058 : loss : 0.024445, loss_ce: 0.007832
2022-01-08 16:52:52,681 iteration 4059 : loss : 0.026607, loss_ce: 0.011450
2022-01-08 16:52:54,120 iteration 4060 : loss : 0.024170, loss_ce: 0.010648
2022-01-08 16:52:55,539 iteration 4061 : loss : 0.036105, loss_ce: 0.015253
2022-01-08 16:52:56,996 iteration 4062 : loss : 0.033994, loss_ce: 0.014062
2022-01-08 16:52:58,429 iteration 4063 : loss : 0.043394, loss_ce: 0.012096

 60%|████████████████▏          | 239/400 [1:42:52<1:07:16, 25.07s/it]2022-01-08 16:52:59,878 iteration 4064 : loss : 0.030539, loss_ce: 0.008426
2022-01-08 16:53:01,260 iteration 4065 : loss : 0.018520, loss_ce: 0.005957
2022-01-08 16:53:02,758 iteration 4066 : loss : 0.032369, loss_ce: 0.012575
2022-01-08 16:53:04,131 iteration 4067 : loss : 0.021844, loss_ce: 0.009179
2022-01-08 16:53:05,544 iteration 4068 : loss : 0.024504, loss_ce: 0.008972
2022-01-08 16:53:06,987 iteration 4069 : loss : 0.022285, loss_ce: 0.009162
2022-01-08 16:53:08,426 iteration 4070 : loss : 0.024537, loss_ce: 0.009451
2022-01-08 16:53:09,918 iteration 4071 : loss : 0.029747, loss_ce: 0.011042
2022-01-08 16:53:11,328 iteration 4072 : loss : 0.020900, loss_ce: 0.006703
2022-01-08 16:53:12,701 iteration 4073 : loss : 0.029407, loss_ce: 0.009670
2022-01-08 16:53:14,109 iteration 4074 : loss : 0.030076, loss_ce: 0.012925
2022-01-08 16:53:15,573 iteration 4075 : loss : 0.019192, loss_ce: 0.006435
2022-01-08 16:53:16,934 iteration 4076 : loss : 0.023800, loss_ce: 0.009064
2022-01-08 16:53:18,336 iteration 4077 : loss : 0.018909, loss_ce: 0.006676
2022-01-08 16:53:19,805 iteration 4078 : loss : 0.027245, loss_ce: 0.010237
2022-01-08 16:53:21,261 iteration 4079 : loss : 0.020245, loss_ce: 0.008882
2022-01-08 16:53:21,261 Training Data Eval:
2022-01-08 16:53:28,183   Average segmentation loss on training set: 0.0162
2022-01-08 16:53:28,184 Validation Data Eval:
2022-01-08 16:53:30,565   Average segmentation loss on validation set: 0.0683
2022-01-08 16:53:32,038 iteration 4080 : loss : 0.025503, loss_ce: 0.011474

 60%|████████████████▏          | 240/400 [1:43:26<1:13:42, 27.64s/it]2022-01-08 16:53:33,550 iteration 4081 : loss : 0.029786, loss_ce: 0.011082
2022-01-08 16:53:34,973 iteration 4082 : loss : 0.017626, loss_ce: 0.006850
2022-01-08 16:53:36,334 iteration 4083 : loss : 0.021773, loss_ce: 0.009777
2022-01-08 16:53:37,753 iteration 4084 : loss : 0.030811, loss_ce: 0.008842
2022-01-08 16:53:39,112 iteration 4085 : loss : 0.023292, loss_ce: 0.007170
2022-01-08 16:53:40,668 iteration 4086 : loss : 0.042604, loss_ce: 0.013620
2022-01-08 16:53:42,108 iteration 4087 : loss : 0.028557, loss_ce: 0.006438
2022-01-08 16:53:43,449 iteration 4088 : loss : 0.030338, loss_ce: 0.017495
2022-01-08 16:53:44,855 iteration 4089 : loss : 0.026234, loss_ce: 0.009526
2022-01-08 16:53:46,169 iteration 4090 : loss : 0.020165, loss_ce: 0.006307
2022-01-08 16:53:47,568 iteration 4091 : loss : 0.038416, loss_ce: 0.014400
2022-01-08 16:53:48,989 iteration 4092 : loss : 0.018676, loss_ce: 0.007100
2022-01-08 16:53:50,412 iteration 4093 : loss : 0.034268, loss_ce: 0.013453
2022-01-08 16:53:51,793 iteration 4094 : loss : 0.023054, loss_ce: 0.009232
2022-01-08 16:53:53,222 iteration 4095 : loss : 0.026957, loss_ce: 0.011140
2022-01-08 16:53:54,595 iteration 4096 : loss : 0.023758, loss_ce: 0.012847
2022-01-08 16:53:55,984 iteration 4097 : loss : 0.019349, loss_ce: 0.006990

 60%|████████████████▎          | 241/400 [1:43:50<1:10:18, 26.53s/it]2022-01-08 16:53:57,433 iteration 4098 : loss : 0.021102, loss_ce: 0.008398
2022-01-08 16:53:58,803 iteration 4099 : loss : 0.029711, loss_ce: 0.008171
2022-01-08 16:54:00,223 iteration 4100 : loss : 0.022319, loss_ce: 0.007919
2022-01-08 16:54:01,693 iteration 4101 : loss : 0.029630, loss_ce: 0.009590
2022-01-08 16:54:03,153 iteration 4102 : loss : 0.032532, loss_ce: 0.014512
2022-01-08 16:54:04,595 iteration 4103 : loss : 0.034394, loss_ce: 0.017950
2022-01-08 16:54:06,017 iteration 4104 : loss : 0.036361, loss_ce: 0.015769
2022-01-08 16:54:07,459 iteration 4105 : loss : 0.020552, loss_ce: 0.009097
2022-01-08 16:54:08,858 iteration 4106 : loss : 0.020999, loss_ce: 0.008672
2022-01-08 16:54:10,249 iteration 4107 : loss : 0.015620, loss_ce: 0.005854
2022-01-08 16:54:11,666 iteration 4108 : loss : 0.021732, loss_ce: 0.009149
2022-01-08 16:54:13,012 iteration 4109 : loss : 0.021981, loss_ce: 0.008336
2022-01-08 16:54:14,461 iteration 4110 : loss : 0.023411, loss_ce: 0.009213
2022-01-08 16:54:16,051 iteration 4111 : loss : 0.025328, loss_ce: 0.013016
2022-01-08 16:54:17,433 iteration 4112 : loss : 0.022799, loss_ce: 0.007869
2022-01-08 16:54:18,900 iteration 4113 : loss : 0.038019, loss_ce: 0.010960
2022-01-08 16:54:20,310 iteration 4114 : loss : 0.020293, loss_ce: 0.008790

 60%|████████████████▎          | 242/400 [1:44:14<1:08:06, 25.87s/it]2022-01-08 16:54:21,732 iteration 4115 : loss : 0.019766, loss_ce: 0.009806
2022-01-08 16:54:23,214 iteration 4116 : loss : 0.021850, loss_ce: 0.007617
2022-01-08 16:54:24,564 iteration 4117 : loss : 0.015669, loss_ce: 0.005861
2022-01-08 16:54:26,046 iteration 4118 : loss : 0.020272, loss_ce: 0.009391
2022-01-08 16:54:27,595 iteration 4119 : loss : 0.041493, loss_ce: 0.011604
2022-01-08 16:54:29,042 iteration 4120 : loss : 0.020327, loss_ce: 0.006260
2022-01-08 16:54:30,410 iteration 4121 : loss : 0.016477, loss_ce: 0.005200
2022-01-08 16:54:31,814 iteration 4122 : loss : 0.057415, loss_ce: 0.015451
2022-01-08 16:54:33,161 iteration 4123 : loss : 0.012830, loss_ce: 0.005249
2022-01-08 16:54:34,615 iteration 4124 : loss : 0.023574, loss_ce: 0.011139
2022-01-08 16:54:36,062 iteration 4125 : loss : 0.032767, loss_ce: 0.020037
2022-01-08 16:54:37,492 iteration 4126 : loss : 0.023354, loss_ce: 0.010332
2022-01-08 16:54:38,858 iteration 4127 : loss : 0.014640, loss_ce: 0.007177
2022-01-08 16:54:40,387 iteration 4128 : loss : 0.044546, loss_ce: 0.013389
2022-01-08 16:54:41,736 iteration 4129 : loss : 0.036329, loss_ce: 0.009732
2022-01-08 16:54:43,069 iteration 4130 : loss : 0.022595, loss_ce: 0.006875
2022-01-08 16:54:44,455 iteration 4131 : loss : 0.019972, loss_ce: 0.009393

 61%|████████████████▍          | 243/400 [1:44:38<1:06:20, 25.35s/it]2022-01-08 16:54:45,986 iteration 4132 : loss : 0.031338, loss_ce: 0.008754
2022-01-08 16:54:47,421 iteration 4133 : loss : 0.018817, loss_ce: 0.006122
2022-01-08 16:54:48,878 iteration 4134 : loss : 0.035862, loss_ce: 0.017092
2022-01-08 16:54:50,207 iteration 4135 : loss : 0.025918, loss_ce: 0.011056
2022-01-08 16:54:51,611 iteration 4136 : loss : 0.040874, loss_ce: 0.023174
2022-01-08 16:54:52,942 iteration 4137 : loss : 0.019006, loss_ce: 0.006964
2022-01-08 16:54:54,392 iteration 4138 : loss : 0.020938, loss_ce: 0.008427
2022-01-08 16:54:55,836 iteration 4139 : loss : 0.019861, loss_ce: 0.008285
2022-01-08 16:54:57,276 iteration 4140 : loss : 0.021186, loss_ce: 0.009204
2022-01-08 16:54:58,710 iteration 4141 : loss : 0.021886, loss_ce: 0.007713
2022-01-08 16:55:00,205 iteration 4142 : loss : 0.027542, loss_ce: 0.009512
2022-01-08 16:55:01,516 iteration 4143 : loss : 0.018587, loss_ce: 0.006309
2022-01-08 16:55:02,849 iteration 4144 : loss : 0.016889, loss_ce: 0.003921
2022-01-08 16:55:04,324 iteration 4145 : loss : 0.023960, loss_ce: 0.008898
2022-01-08 16:55:05,710 iteration 4146 : loss : 0.016546, loss_ce: 0.006959
2022-01-08 16:55:07,135 iteration 4147 : loss : 0.021403, loss_ce: 0.007444
2022-01-08 16:55:08,514 iteration 4148 : loss : 0.033821, loss_ce: 0.012000

 61%|████████████████▍          | 244/400 [1:45:02<1:04:54, 24.97s/it]2022-01-08 16:55:09,894 iteration 4149 : loss : 0.018310, loss_ce: 0.005881
2022-01-08 16:55:11,317 iteration 4150 : loss : 0.018537, loss_ce: 0.005561
2022-01-08 16:55:12,791 iteration 4151 : loss : 0.021601, loss_ce: 0.007695
2022-01-08 16:55:14,215 iteration 4152 : loss : 0.021862, loss_ce: 0.008987
2022-01-08 16:55:15,542 iteration 4153 : loss : 0.015740, loss_ce: 0.006019
2022-01-08 16:55:16,970 iteration 4154 : loss : 0.016702, loss_ce: 0.005889
2022-01-08 16:55:18,366 iteration 4155 : loss : 0.023989, loss_ce: 0.006975
2022-01-08 16:55:19,704 iteration 4156 : loss : 0.016005, loss_ce: 0.005197
2022-01-08 16:55:21,178 iteration 4157 : loss : 0.023477, loss_ce: 0.011353
2022-01-08 16:55:22,551 iteration 4158 : loss : 0.022009, loss_ce: 0.007974
2022-01-08 16:55:23,935 iteration 4159 : loss : 0.014856, loss_ce: 0.006271
2022-01-08 16:55:25,471 iteration 4160 : loss : 0.029447, loss_ce: 0.011760
2022-01-08 16:55:26,980 iteration 4161 : loss : 0.029743, loss_ce: 0.010217
2022-01-08 16:55:28,479 iteration 4162 : loss : 0.029271, loss_ce: 0.010428
2022-01-08 16:55:29,961 iteration 4163 : loss : 0.025263, loss_ce: 0.012621
2022-01-08 16:55:31,384 iteration 4164 : loss : 0.025249, loss_ce: 0.010607
2022-01-08 16:55:31,385 Training Data Eval:
2022-01-08 16:55:38,315   Average segmentation loss on training set: 0.0169
2022-01-08 16:55:38,315 Validation Data Eval:
2022-01-08 16:55:40,693   Average segmentation loss on validation set: 0.0732
2022-01-08 16:55:42,137 iteration 4165 : loss : 0.030911, loss_ce: 0.010350

 61%|████████████████▌          | 245/400 [1:45:36<1:11:11, 27.56s/it]2022-01-08 16:55:43,597 iteration 4166 : loss : 0.020123, loss_ce: 0.007777
2022-01-08 16:55:44,930 iteration 4167 : loss : 0.025251, loss_ce: 0.006722
2022-01-08 16:55:46,284 iteration 4168 : loss : 0.017983, loss_ce: 0.008517
2022-01-08 16:55:47,641 iteration 4169 : loss : 0.015835, loss_ce: 0.007049
2022-01-08 16:55:49,174 iteration 4170 : loss : 0.029065, loss_ce: 0.013385
2022-01-08 16:55:50,506 iteration 4171 : loss : 0.016713, loss_ce: 0.005213
2022-01-08 16:55:51,899 iteration 4172 : loss : 0.019481, loss_ce: 0.009162
2022-01-08 16:55:53,347 iteration 4173 : loss : 0.025448, loss_ce: 0.007575
2022-01-08 16:55:54,731 iteration 4174 : loss : 0.016460, loss_ce: 0.004766
2022-01-08 16:55:56,084 iteration 4175 : loss : 0.016735, loss_ce: 0.006468
2022-01-08 16:55:57,472 iteration 4176 : loss : 0.024671, loss_ce: 0.010667
2022-01-08 16:55:58,918 iteration 4177 : loss : 0.018591, loss_ce: 0.005761
2022-01-08 16:56:00,282 iteration 4178 : loss : 0.019736, loss_ce: 0.007572
2022-01-08 16:56:01,669 iteration 4179 : loss : 0.021623, loss_ce: 0.009713
2022-01-08 16:56:03,042 iteration 4180 : loss : 0.015555, loss_ce: 0.004916
2022-01-08 16:56:04,430 iteration 4181 : loss : 0.019440, loss_ce: 0.008198
2022-01-08 16:56:05,843 iteration 4182 : loss : 0.018453, loss_ce: 0.004336

 62%|████████████████▌          | 246/400 [1:46:00<1:07:46, 26.41s/it]2022-01-08 16:56:07,331 iteration 4183 : loss : 0.019546, loss_ce: 0.007003
2022-01-08 16:56:08,782 iteration 4184 : loss : 0.021143, loss_ce: 0.009052
2022-01-08 16:56:10,192 iteration 4185 : loss : 0.021243, loss_ce: 0.008741
2022-01-08 16:56:11,579 iteration 4186 : loss : 0.017282, loss_ce: 0.004631
2022-01-08 16:56:13,035 iteration 4187 : loss : 0.029998, loss_ce: 0.010738
2022-01-08 16:56:14,399 iteration 4188 : loss : 0.022336, loss_ce: 0.007010
2022-01-08 16:56:15,938 iteration 4189 : loss : 0.028206, loss_ce: 0.012540
2022-01-08 16:56:17,420 iteration 4190 : loss : 0.028743, loss_ce: 0.012113
2022-01-08 16:56:18,914 iteration 4191 : loss : 0.050295, loss_ce: 0.019722
2022-01-08 16:56:20,218 iteration 4192 : loss : 0.020642, loss_ce: 0.005821
2022-01-08 16:56:21,647 iteration 4193 : loss : 0.026884, loss_ce: 0.013037
2022-01-08 16:56:23,113 iteration 4194 : loss : 0.022242, loss_ce: 0.007745
2022-01-08 16:56:24,509 iteration 4195 : loss : 0.025420, loss_ce: 0.007205
2022-01-08 16:56:25,971 iteration 4196 : loss : 0.017463, loss_ce: 0.007273
2022-01-08 16:56:27,365 iteration 4197 : loss : 0.019739, loss_ce: 0.005670
2022-01-08 16:56:28,762 iteration 4198 : loss : 0.018947, loss_ce: 0.007804
2022-01-08 16:56:30,100 iteration 4199 : loss : 0.016345, loss_ce: 0.006409

 62%|████████████████▋          | 247/400 [1:46:24<1:05:41, 25.76s/it]2022-01-08 16:56:31,572 iteration 4200 : loss : 0.021003, loss_ce: 0.007930
2022-01-08 16:56:33,017 iteration 4201 : loss : 0.020885, loss_ce: 0.008821
2022-01-08 16:56:34,462 iteration 4202 : loss : 0.017305, loss_ce: 0.007262
2022-01-08 16:56:35,990 iteration 4203 : loss : 0.019257, loss_ce: 0.008069
2022-01-08 16:56:37,383 iteration 4204 : loss : 0.019175, loss_ce: 0.008215
2022-01-08 16:56:38,790 iteration 4205 : loss : 0.017175, loss_ce: 0.006506
2022-01-08 16:56:40,339 iteration 4206 : loss : 0.029500, loss_ce: 0.009939
2022-01-08 16:56:41,807 iteration 4207 : loss : 0.020618, loss_ce: 0.008296
2022-01-08 16:56:43,124 iteration 4208 : loss : 0.013717, loss_ce: 0.005029
2022-01-08 16:56:44,500 iteration 4209 : loss : 0.023499, loss_ce: 0.009943
2022-01-08 16:56:45,877 iteration 4210 : loss : 0.024239, loss_ce: 0.011071
2022-01-08 16:56:47,310 iteration 4211 : loss : 0.021736, loss_ce: 0.008440
2022-01-08 16:56:48,784 iteration 4212 : loss : 0.022333, loss_ce: 0.009631
2022-01-08 16:56:50,155 iteration 4213 : loss : 0.022318, loss_ce: 0.006460
2022-01-08 16:56:51,613 iteration 4214 : loss : 0.024771, loss_ce: 0.007334
2022-01-08 16:56:53,010 iteration 4215 : loss : 0.032119, loss_ce: 0.009399
2022-01-08 16:56:54,404 iteration 4216 : loss : 0.016997, loss_ce: 0.005685

 62%|████████████████▋          | 248/400 [1:46:48<1:04:09, 25.32s/it]2022-01-08 16:56:55,918 iteration 4217 : loss : 0.021831, loss_ce: 0.007395
2022-01-08 16:56:57,309 iteration 4218 : loss : 0.021998, loss_ce: 0.007685
2022-01-08 16:56:58,678 iteration 4219 : loss : 0.019952, loss_ce: 0.007712
2022-01-08 16:56:59,982 iteration 4220 : loss : 0.019953, loss_ce: 0.005092
2022-01-08 16:57:01,494 iteration 4221 : loss : 0.031074, loss_ce: 0.014018
2022-01-08 16:57:03,011 iteration 4222 : loss : 0.025941, loss_ce: 0.007471
2022-01-08 16:57:04,395 iteration 4223 : loss : 0.018426, loss_ce: 0.006052
2022-01-08 16:57:05,871 iteration 4224 : loss : 0.029151, loss_ce: 0.007254
2022-01-08 16:57:07,308 iteration 4225 : loss : 0.024588, loss_ce: 0.007558
2022-01-08 16:57:08,771 iteration 4226 : loss : 0.018203, loss_ce: 0.007773
2022-01-08 16:57:10,216 iteration 4227 : loss : 0.019153, loss_ce: 0.007719
2022-01-08 16:57:11,579 iteration 4228 : loss : 0.021290, loss_ce: 0.010672
2022-01-08 16:57:12,986 iteration 4229 : loss : 0.022493, loss_ce: 0.007827
2022-01-08 16:57:14,379 iteration 4230 : loss : 0.027039, loss_ce: 0.013285
2022-01-08 16:57:15,844 iteration 4231 : loss : 0.020104, loss_ce: 0.007800
2022-01-08 16:57:17,306 iteration 4232 : loss : 0.034061, loss_ce: 0.010628
2022-01-08 16:57:18,706 iteration 4233 : loss : 0.025982, loss_ce: 0.012752

 62%|████████████████▊          | 249/400 [1:47:12<1:02:57, 25.02s/it]2022-01-08 16:57:20,085 iteration 4234 : loss : 0.036463, loss_ce: 0.007635
2022-01-08 16:57:21,421 iteration 4235 : loss : 0.013151, loss_ce: 0.004750
2022-01-08 16:57:22,862 iteration 4236 : loss : 0.021523, loss_ce: 0.009627
2022-01-08 16:57:24,222 iteration 4237 : loss : 0.027724, loss_ce: 0.013153
2022-01-08 16:57:25,621 iteration 4238 : loss : 0.024288, loss_ce: 0.012566
2022-01-08 16:57:27,185 iteration 4239 : loss : 0.028047, loss_ce: 0.010228
2022-01-08 16:57:28,613 iteration 4240 : loss : 0.023762, loss_ce: 0.007434
2022-01-08 16:57:29,929 iteration 4241 : loss : 0.018476, loss_ce: 0.008334
2022-01-08 16:57:31,347 iteration 4242 : loss : 0.022651, loss_ce: 0.007106
2022-01-08 16:57:32,729 iteration 4243 : loss : 0.022990, loss_ce: 0.009342
2022-01-08 16:57:34,047 iteration 4244 : loss : 0.017601, loss_ce: 0.008347
2022-01-08 16:57:35,509 iteration 4245 : loss : 0.024758, loss_ce: 0.009767
2022-01-08 16:57:37,015 iteration 4246 : loss : 0.020297, loss_ce: 0.005010
2022-01-08 16:57:38,466 iteration 4247 : loss : 0.021044, loss_ce: 0.008585
2022-01-08 16:57:39,816 iteration 4248 : loss : 0.022564, loss_ce: 0.009394
2022-01-08 16:57:41,303 iteration 4249 : loss : 0.028210, loss_ce: 0.008014
2022-01-08 16:57:41,304 Training Data Eval:
2022-01-08 16:57:48,221   Average segmentation loss on training set: 0.0141
2022-01-08 16:57:48,221 Validation Data Eval:
2022-01-08 16:57:50,596   Average segmentation loss on validation set: 0.1004
2022-01-08 16:57:51,998 iteration 4250 : loss : 0.023723, loss_ce: 0.008901

 62%|████████████████▉          | 250/400 [1:47:46<1:08:44, 27.50s/it]2022-01-08 16:57:53,537 iteration 4251 : loss : 0.022483, loss_ce: 0.005425
2022-01-08 16:57:55,005 iteration 4252 : loss : 0.019707, loss_ce: 0.008645
2022-01-08 16:57:56,422 iteration 4253 : loss : 0.029524, loss_ce: 0.011048
2022-01-08 16:57:57,883 iteration 4254 : loss : 0.016149, loss_ce: 0.006052
2022-01-08 16:57:59,357 iteration 4255 : loss : 0.020365, loss_ce: 0.007430
2022-01-08 16:58:00,671 iteration 4256 : loss : 0.018169, loss_ce: 0.008357
2022-01-08 16:58:02,080 iteration 4257 : loss : 0.027572, loss_ce: 0.009651
2022-01-08 16:58:03,409 iteration 4258 : loss : 0.029953, loss_ce: 0.009755
2022-01-08 16:58:04,843 iteration 4259 : loss : 0.029160, loss_ce: 0.014146
2022-01-08 16:58:06,283 iteration 4260 : loss : 0.027059, loss_ce: 0.008126
2022-01-08 16:58:07,720 iteration 4261 : loss : 0.022306, loss_ce: 0.008289
2022-01-08 16:58:09,090 iteration 4262 : loss : 0.017445, loss_ce: 0.007444
2022-01-08 16:58:10,522 iteration 4263 : loss : 0.026436, loss_ce: 0.011375
2022-01-08 16:58:11,999 iteration 4264 : loss : 0.030215, loss_ce: 0.013033
2022-01-08 16:58:13,406 iteration 4265 : loss : 0.030698, loss_ce: 0.008544
2022-01-08 16:58:14,856 iteration 4266 : loss : 0.026420, loss_ce: 0.008834
2022-01-08 16:58:16,335 iteration 4267 : loss : 0.027818, loss_ce: 0.011058

 63%|████████████████▉          | 251/400 [1:48:10<1:05:55, 26.55s/it]2022-01-08 16:58:17,816 iteration 4268 : loss : 0.017971, loss_ce: 0.004022
2022-01-08 16:58:19,211 iteration 4269 : loss : 0.022164, loss_ce: 0.007343
2022-01-08 16:58:20,591 iteration 4270 : loss : 0.028185, loss_ce: 0.013706
2022-01-08 16:58:21,920 iteration 4271 : loss : 0.017823, loss_ce: 0.006772
2022-01-08 16:58:23,321 iteration 4272 : loss : 0.021535, loss_ce: 0.011092
2022-01-08 16:58:24,653 iteration 4273 : loss : 0.022117, loss_ce: 0.009784
2022-01-08 16:58:26,154 iteration 4274 : loss : 0.029006, loss_ce: 0.014986
2022-01-08 16:58:27,541 iteration 4275 : loss : 0.019012, loss_ce: 0.006828
2022-01-08 16:58:29,010 iteration 4276 : loss : 0.038952, loss_ce: 0.009143
2022-01-08 16:58:30,481 iteration 4277 : loss : 0.022527, loss_ce: 0.007343
2022-01-08 16:58:31,948 iteration 4278 : loss : 0.041591, loss_ce: 0.013337
2022-01-08 16:58:33,345 iteration 4279 : loss : 0.021016, loss_ce: 0.010541
2022-01-08 16:58:34,770 iteration 4280 : loss : 0.022523, loss_ce: 0.007620
2022-01-08 16:58:36,199 iteration 4281 : loss : 0.026793, loss_ce: 0.007612
2022-01-08 16:58:37,538 iteration 4282 : loss : 0.018971, loss_ce: 0.007176
2022-01-08 16:58:38,931 iteration 4283 : loss : 0.035248, loss_ce: 0.012923
2022-01-08 16:58:40,300 iteration 4284 : loss : 0.024165, loss_ce: 0.009621

 63%|█████████████████          | 252/400 [1:48:34<1:03:34, 25.77s/it]2022-01-08 16:58:41,703 iteration 4285 : loss : 0.021572, loss_ce: 0.006496
2022-01-08 16:58:43,165 iteration 4286 : loss : 0.032846, loss_ce: 0.012787
2022-01-08 16:58:44,524 iteration 4287 : loss : 0.023640, loss_ce: 0.010770
2022-01-08 16:58:45,884 iteration 4288 : loss : 0.019667, loss_ce: 0.008766
2022-01-08 16:58:47,301 iteration 4289 : loss : 0.022999, loss_ce: 0.009614
2022-01-08 16:58:48,702 iteration 4290 : loss : 0.022068, loss_ce: 0.005248
2022-01-08 16:58:50,144 iteration 4291 : loss : 0.027512, loss_ce: 0.009444
2022-01-08 16:58:51,580 iteration 4292 : loss : 0.023984, loss_ce: 0.010239
2022-01-08 16:58:53,003 iteration 4293 : loss : 0.020078, loss_ce: 0.006678
2022-01-08 16:58:54,384 iteration 4294 : loss : 0.017079, loss_ce: 0.004281
2022-01-08 16:58:55,913 iteration 4295 : loss : 0.028666, loss_ce: 0.010098
2022-01-08 16:58:57,328 iteration 4296 : loss : 0.027999, loss_ce: 0.008829
2022-01-08 16:58:58,768 iteration 4297 : loss : 0.032988, loss_ce: 0.011139
2022-01-08 16:59:00,147 iteration 4298 : loss : 0.023118, loss_ce: 0.011905
2022-01-08 16:59:01,618 iteration 4299 : loss : 0.023580, loss_ce: 0.010705
2022-01-08 16:59:03,121 iteration 4300 : loss : 0.035402, loss_ce: 0.013988
2022-01-08 16:59:04,618 iteration 4301 : loss : 0.019077, loss_ce: 0.007891

 63%|█████████████████          | 253/400 [1:48:58<1:02:05, 25.34s/it]2022-01-08 16:59:06,152 iteration 4302 : loss : 0.024523, loss_ce: 0.010150
2022-01-08 16:59:07,642 iteration 4303 : loss : 0.031351, loss_ce: 0.006803
2022-01-08 16:59:09,013 iteration 4304 : loss : 0.017217, loss_ce: 0.006721
2022-01-08 16:59:10,407 iteration 4305 : loss : 0.018065, loss_ce: 0.007295
2022-01-08 16:59:11,795 iteration 4306 : loss : 0.016170, loss_ce: 0.005446
2022-01-08 16:59:13,142 iteration 4307 : loss : 0.015725, loss_ce: 0.007294
2022-01-08 16:59:14,588 iteration 4308 : loss : 0.021970, loss_ce: 0.008669
2022-01-08 16:59:16,079 iteration 4309 : loss : 0.021429, loss_ce: 0.007571
2022-01-08 16:59:17,498 iteration 4310 : loss : 0.018487, loss_ce: 0.008148
2022-01-08 16:59:18,868 iteration 4311 : loss : 0.024074, loss_ce: 0.008542
2022-01-08 16:59:20,222 iteration 4312 : loss : 0.021175, loss_ce: 0.008528
2022-01-08 16:59:21,592 iteration 4313 : loss : 0.016910, loss_ce: 0.008130
2022-01-08 16:59:22,964 iteration 4314 : loss : 0.018948, loss_ce: 0.005901
2022-01-08 16:59:24,413 iteration 4315 : loss : 0.021155, loss_ce: 0.007258
2022-01-08 16:59:25,786 iteration 4316 : loss : 0.018501, loss_ce: 0.006470
2022-01-08 16:59:27,259 iteration 4317 : loss : 0.018864, loss_ce: 0.007035
2022-01-08 16:59:28,609 iteration 4318 : loss : 0.018240, loss_ce: 0.007045

 64%|█████████████████▏         | 254/400 [1:49:22<1:00:39, 24.93s/it]2022-01-08 16:59:30,128 iteration 4319 : loss : 0.022494, loss_ce: 0.007451
2022-01-08 16:59:31,589 iteration 4320 : loss : 0.031355, loss_ce: 0.011851
2022-01-08 16:59:32,892 iteration 4321 : loss : 0.018578, loss_ce: 0.005341
2022-01-08 16:59:34,306 iteration 4322 : loss : 0.021680, loss_ce: 0.007500
2022-01-08 16:59:35,654 iteration 4323 : loss : 0.019106, loss_ce: 0.009676
2022-01-08 16:59:37,192 iteration 4324 : loss : 0.024643, loss_ce: 0.010933
2022-01-08 16:59:38,610 iteration 4325 : loss : 0.017999, loss_ce: 0.007652
2022-01-08 16:59:39,995 iteration 4326 : loss : 0.017019, loss_ce: 0.008117
2022-01-08 16:59:41,442 iteration 4327 : loss : 0.019958, loss_ce: 0.005102
2022-01-08 16:59:42,811 iteration 4328 : loss : 0.034388, loss_ce: 0.013236
2022-01-08 16:59:44,289 iteration 4329 : loss : 0.030685, loss_ce: 0.006560
2022-01-08 16:59:45,743 iteration 4330 : loss : 0.018970, loss_ce: 0.008347
2022-01-08 16:59:47,254 iteration 4331 : loss : 0.038867, loss_ce: 0.010096
2022-01-08 16:59:48,718 iteration 4332 : loss : 0.033388, loss_ce: 0.010075
2022-01-08 16:59:50,217 iteration 4333 : loss : 0.029221, loss_ce: 0.013116
2022-01-08 16:59:51,641 iteration 4334 : loss : 0.022369, loss_ce: 0.011306
2022-01-08 16:59:51,641 Training Data Eval:
2022-01-08 16:59:58,563   Average segmentation loss on training set: 0.0158
2022-01-08 16:59:58,564 Validation Data Eval:
2022-01-08 17:00:00,947   Average segmentation loss on validation set: 0.0952
2022-01-08 17:00:02,412 iteration 4335 : loss : 0.025664, loss_ce: 0.006478

 64%|█████████████████▏         | 255/400 [1:49:56<1:06:41, 27.60s/it]2022-01-08 17:00:03,783 iteration 4336 : loss : 0.015555, loss_ce: 0.007317
2022-01-08 17:00:05,287 iteration 4337 : loss : 0.033494, loss_ce: 0.013675
2022-01-08 17:00:06,704 iteration 4338 : loss : 0.019910, loss_ce: 0.006648
2022-01-08 17:00:08,066 iteration 4339 : loss : 0.027194, loss_ce: 0.010419
2022-01-08 17:00:09,516 iteration 4340 : loss : 0.024497, loss_ce: 0.009890
2022-01-08 17:00:10,864 iteration 4341 : loss : 0.017205, loss_ce: 0.005478
2022-01-08 17:00:12,321 iteration 4342 : loss : 0.021286, loss_ce: 0.005833
2022-01-08 17:00:13,779 iteration 4343 : loss : 0.026808, loss_ce: 0.007344
2022-01-08 17:00:15,233 iteration 4344 : loss : 0.021079, loss_ce: 0.010797
2022-01-08 17:00:16,754 iteration 4345 : loss : 0.023942, loss_ce: 0.010775
2022-01-08 17:00:18,094 iteration 4346 : loss : 0.026210, loss_ce: 0.007734
2022-01-08 17:00:19,511 iteration 4347 : loss : 0.015849, loss_ce: 0.007385
2022-01-08 17:00:20,861 iteration 4348 : loss : 0.016560, loss_ce: 0.007728
2022-01-08 17:00:22,160 iteration 4349 : loss : 0.015376, loss_ce: 0.004104
2022-01-08 17:00:23,469 iteration 4350 : loss : 0.021935, loss_ce: 0.007368
2022-01-08 17:00:24,907 iteration 4351 : loss : 0.023021, loss_ce: 0.008078
2022-01-08 17:00:26,316 iteration 4352 : loss : 0.029471, loss_ce: 0.014482

 64%|█████████████████▎         | 256/400 [1:50:20<1:03:34, 26.49s/it]2022-01-08 17:00:27,733 iteration 4353 : loss : 0.019095, loss_ce: 0.005701
2022-01-08 17:00:29,232 iteration 4354 : loss : 0.022631, loss_ce: 0.010488
2022-01-08 17:00:30,706 iteration 4355 : loss : 0.020728, loss_ce: 0.007580
2022-01-08 17:00:32,217 iteration 4356 : loss : 0.026237, loss_ce: 0.005942
2022-01-08 17:00:33,681 iteration 4357 : loss : 0.020830, loss_ce: 0.009121
2022-01-08 17:00:35,175 iteration 4358 : loss : 0.033162, loss_ce: 0.013174
2022-01-08 17:00:36,625 iteration 4359 : loss : 0.020370, loss_ce: 0.006957
2022-01-08 17:00:38,029 iteration 4360 : loss : 0.029191, loss_ce: 0.012503
2022-01-08 17:00:39,514 iteration 4361 : loss : 0.025209, loss_ce: 0.008917
2022-01-08 17:00:40,929 iteration 4362 : loss : 0.020609, loss_ce: 0.009345
2022-01-08 17:00:42,341 iteration 4363 : loss : 0.018607, loss_ce: 0.008256
2022-01-08 17:00:43,790 iteration 4364 : loss : 0.027682, loss_ce: 0.010529
2022-01-08 17:00:45,311 iteration 4365 : loss : 0.030904, loss_ce: 0.016039
2022-01-08 17:00:46,671 iteration 4366 : loss : 0.018409, loss_ce: 0.005325
2022-01-08 17:00:47,970 iteration 4367 : loss : 0.019914, loss_ce: 0.008105
2022-01-08 17:00:49,299 iteration 4368 : loss : 0.017988, loss_ce: 0.005939
2022-01-08 17:00:50,721 iteration 4369 : loss : 0.022464, loss_ce: 0.007720

 64%|█████████████████▎         | 257/400 [1:50:44<1:01:38, 25.86s/it]2022-01-08 17:00:52,206 iteration 4370 : loss : 0.030515, loss_ce: 0.011748
2022-01-08 17:00:53,671 iteration 4371 : loss : 0.030136, loss_ce: 0.013974
2022-01-08 17:00:55,120 iteration 4372 : loss : 0.024966, loss_ce: 0.008844
2022-01-08 17:00:56,563 iteration 4373 : loss : 0.020965, loss_ce: 0.010123
2022-01-08 17:00:58,024 iteration 4374 : loss : 0.028298, loss_ce: 0.009866
2022-01-08 17:00:59,479 iteration 4375 : loss : 0.030184, loss_ce: 0.013012
2022-01-08 17:01:00,867 iteration 4376 : loss : 0.022785, loss_ce: 0.008365
2022-01-08 17:01:02,256 iteration 4377 : loss : 0.022625, loss_ce: 0.006396
2022-01-08 17:01:03,596 iteration 4378 : loss : 0.016268, loss_ce: 0.006038
2022-01-08 17:01:04,939 iteration 4379 : loss : 0.022587, loss_ce: 0.007856
2022-01-08 17:01:06,258 iteration 4380 : loss : 0.018363, loss_ce: 0.006215
2022-01-08 17:01:07,700 iteration 4381 : loss : 0.023115, loss_ce: 0.008193
2022-01-08 17:01:09,108 iteration 4382 : loss : 0.035455, loss_ce: 0.006963
2022-01-08 17:01:10,490 iteration 4383 : loss : 0.024265, loss_ce: 0.007138
2022-01-08 17:01:11,974 iteration 4384 : loss : 0.021480, loss_ce: 0.009306
2022-01-08 17:01:13,452 iteration 4385 : loss : 0.022050, loss_ce: 0.007231
2022-01-08 17:01:14,819 iteration 4386 : loss : 0.020168, loss_ce: 0.009456

 64%|██████████████████▋          | 258/400 [1:51:09<59:57, 25.34s/it]2022-01-08 17:01:16,215 iteration 4387 : loss : 0.021751, loss_ce: 0.007017
2022-01-08 17:01:17,631 iteration 4388 : loss : 0.028632, loss_ce: 0.013090
2022-01-08 17:01:19,049 iteration 4389 : loss : 0.026951, loss_ce: 0.008281
2022-01-08 17:01:20,396 iteration 4390 : loss : 0.015180, loss_ce: 0.004872
2022-01-08 17:01:21,820 iteration 4391 : loss : 0.024925, loss_ce: 0.007572
2022-01-08 17:01:23,224 iteration 4392 : loss : 0.017752, loss_ce: 0.005662
2022-01-08 17:01:24,718 iteration 4393 : loss : 0.022497, loss_ce: 0.010490
2022-01-08 17:01:26,183 iteration 4394 : loss : 0.020363, loss_ce: 0.008295
2022-01-08 17:01:27,717 iteration 4395 : loss : 0.037486, loss_ce: 0.013229
2022-01-08 17:01:29,099 iteration 4396 : loss : 0.020859, loss_ce: 0.008281
2022-01-08 17:01:30,636 iteration 4397 : loss : 0.024323, loss_ce: 0.011509
2022-01-08 17:01:31,998 iteration 4398 : loss : 0.019646, loss_ce: 0.008310
2022-01-08 17:01:33,468 iteration 4399 : loss : 0.025914, loss_ce: 0.009872
2022-01-08 17:01:34,904 iteration 4400 : loss : 0.034057, loss_ce: 0.010727
2022-01-08 17:01:36,492 iteration 4401 : loss : 0.036828, loss_ce: 0.012989
2022-01-08 17:01:37,929 iteration 4402 : loss : 0.026891, loss_ce: 0.008574
2022-01-08 17:01:39,381 iteration 4403 : loss : 0.022601, loss_ce: 0.008244

 65%|██████████████████▊          | 259/400 [1:51:33<58:59, 25.10s/it]2022-01-08 17:01:40,820 iteration 4404 : loss : 0.020844, loss_ce: 0.009033
2022-01-08 17:01:42,286 iteration 4405 : loss : 0.020962, loss_ce: 0.009043
2022-01-08 17:01:43,741 iteration 4406 : loss : 0.020987, loss_ce: 0.008948
2022-01-08 17:01:45,240 iteration 4407 : loss : 0.031808, loss_ce: 0.011272
2022-01-08 17:01:46,633 iteration 4408 : loss : 0.016536, loss_ce: 0.006897
2022-01-08 17:01:48,089 iteration 4409 : loss : 0.020057, loss_ce: 0.006932
2022-01-08 17:01:49,683 iteration 4410 : loss : 0.025225, loss_ce: 0.007932
2022-01-08 17:01:51,164 iteration 4411 : loss : 0.025582, loss_ce: 0.011146
2022-01-08 17:01:52,588 iteration 4412 : loss : 0.019372, loss_ce: 0.007083
2022-01-08 17:01:54,045 iteration 4413 : loss : 0.018416, loss_ce: 0.006260
2022-01-08 17:01:55,398 iteration 4414 : loss : 0.017369, loss_ce: 0.005237
2022-01-08 17:01:56,861 iteration 4415 : loss : 0.017939, loss_ce: 0.005902
2022-01-08 17:01:58,357 iteration 4416 : loss : 0.029223, loss_ce: 0.012500
2022-01-08 17:01:59,784 iteration 4417 : loss : 0.021721, loss_ce: 0.006223
2022-01-08 17:02:01,221 iteration 4418 : loss : 0.022083, loss_ce: 0.010422
2022-01-08 17:02:02,702 iteration 4419 : loss : 0.026033, loss_ce: 0.007719
2022-01-08 17:02:02,702 Training Data Eval:
2022-01-08 17:02:09,624   Average segmentation loss on training set: 0.0138
2022-01-08 17:02:09,625 Validation Data Eval:
2022-01-08 17:02:12,004   Average segmentation loss on validation set: 0.0845
2022-01-08 17:02:13,352 iteration 4420 : loss : 0.016368, loss_ce: 0.007386

 65%|█████████████████▌         | 260/400 [1:52:07<1:04:46, 27.76s/it]2022-01-08 17:02:14,799 iteration 4421 : loss : 0.017494, loss_ce: 0.005622
2022-01-08 17:02:16,235 iteration 4422 : loss : 0.030969, loss_ce: 0.015273
2022-01-08 17:02:17,724 iteration 4423 : loss : 0.021128, loss_ce: 0.008190
2022-01-08 17:02:19,080 iteration 4424 : loss : 0.016526, loss_ce: 0.005334
2022-01-08 17:02:20,424 iteration 4425 : loss : 0.018497, loss_ce: 0.006383
2022-01-08 17:02:21,902 iteration 4426 : loss : 0.016231, loss_ce: 0.006663
2022-01-08 17:02:23,256 iteration 4427 : loss : 0.015390, loss_ce: 0.006604
2022-01-08 17:02:24,559 iteration 4428 : loss : 0.015517, loss_ce: 0.007426
2022-01-08 17:02:25,885 iteration 4429 : loss : 0.020451, loss_ce: 0.006750
2022-01-08 17:02:27,217 iteration 4430 : loss : 0.016988, loss_ce: 0.007515
2022-01-08 17:02:28,649 iteration 4431 : loss : 0.025711, loss_ce: 0.011662
2022-01-08 17:02:30,108 iteration 4432 : loss : 0.025571, loss_ce: 0.010072
2022-01-08 17:02:31,496 iteration 4433 : loss : 0.027550, loss_ce: 0.006563
2022-01-08 17:02:32,838 iteration 4434 : loss : 0.013173, loss_ce: 0.005851
2022-01-08 17:02:34,252 iteration 4435 : loss : 0.032027, loss_ce: 0.009861
2022-01-08 17:02:35,653 iteration 4436 : loss : 0.017293, loss_ce: 0.007014
2022-01-08 17:02:37,125 iteration 4437 : loss : 0.025243, loss_ce: 0.008222

 65%|█████████████████▌         | 261/400 [1:52:31<1:01:32, 26.57s/it]2022-01-08 17:02:38,669 iteration 4438 : loss : 0.024078, loss_ce: 0.007037
2022-01-08 17:02:40,122 iteration 4439 : loss : 0.027326, loss_ce: 0.009546
2022-01-08 17:02:41,551 iteration 4440 : loss : 0.018511, loss_ce: 0.006573
2022-01-08 17:02:43,099 iteration 4441 : loss : 0.020620, loss_ce: 0.006705
2022-01-08 17:02:44,593 iteration 4442 : loss : 0.018191, loss_ce: 0.008863
2022-01-08 17:02:46,043 iteration 4443 : loss : 0.025974, loss_ce: 0.008532
2022-01-08 17:02:47,382 iteration 4444 : loss : 0.020995, loss_ce: 0.006382
2022-01-08 17:02:48,777 iteration 4445 : loss : 0.024160, loss_ce: 0.010526
2022-01-08 17:02:50,225 iteration 4446 : loss : 0.023242, loss_ce: 0.010179
2022-01-08 17:02:51,612 iteration 4447 : loss : 0.016063, loss_ce: 0.005141
2022-01-08 17:02:53,060 iteration 4448 : loss : 0.036511, loss_ce: 0.013407
2022-01-08 17:02:54,483 iteration 4449 : loss : 0.019887, loss_ce: 0.007835
2022-01-08 17:02:55,970 iteration 4450 : loss : 0.019526, loss_ce: 0.006562
2022-01-08 17:02:57,356 iteration 4451 : loss : 0.018521, loss_ce: 0.006612
2022-01-08 17:02:58,791 iteration 4452 : loss : 0.018813, loss_ce: 0.008115
2022-01-08 17:03:00,174 iteration 4453 : loss : 0.018682, loss_ce: 0.006808
2022-01-08 17:03:01,556 iteration 4454 : loss : 0.021265, loss_ce: 0.008650

 66%|██████████████████▉          | 262/400 [1:52:55<59:37, 25.92s/it]2022-01-08 17:03:03,049 iteration 4455 : loss : 0.019834, loss_ce: 0.004781
2022-01-08 17:03:04,364 iteration 4456 : loss : 0.017348, loss_ce: 0.007087
2022-01-08 17:03:05,802 iteration 4457 : loss : 0.020566, loss_ce: 0.008433
2022-01-08 17:03:07,331 iteration 4458 : loss : 0.036027, loss_ce: 0.014693
2022-01-08 17:03:08,942 iteration 4459 : loss : 0.028429, loss_ce: 0.012771
2022-01-08 17:03:10,321 iteration 4460 : loss : 0.022586, loss_ce: 0.007638
2022-01-08 17:03:11,744 iteration 4461 : loss : 0.029715, loss_ce: 0.009385
2022-01-08 17:03:13,214 iteration 4462 : loss : 0.024703, loss_ce: 0.010637
2022-01-08 17:03:14,618 iteration 4463 : loss : 0.035115, loss_ce: 0.015435
2022-01-08 17:03:16,006 iteration 4464 : loss : 0.021044, loss_ce: 0.007500
2022-01-08 17:03:17,335 iteration 4465 : loss : 0.019427, loss_ce: 0.004584
2022-01-08 17:03:18,691 iteration 4466 : loss : 0.028874, loss_ce: 0.010494
2022-01-08 17:03:20,113 iteration 4467 : loss : 0.039068, loss_ce: 0.016441
2022-01-08 17:03:21,567 iteration 4468 : loss : 0.022063, loss_ce: 0.010048
2022-01-08 17:03:23,069 iteration 4469 : loss : 0.033472, loss_ce: 0.014581
2022-01-08 17:03:24,547 iteration 4470 : loss : 0.019006, loss_ce: 0.007918
2022-01-08 17:03:26,055 iteration 4471 : loss : 0.025992, loss_ce: 0.007079

 66%|███████████████████          | 263/400 [1:53:20<58:12, 25.49s/it]2022-01-08 17:03:27,498 iteration 4472 : loss : 0.016868, loss_ce: 0.007101
2022-01-08 17:03:28,864 iteration 4473 : loss : 0.021714, loss_ce: 0.008922
2022-01-08 17:03:30,296 iteration 4474 : loss : 0.018028, loss_ce: 0.008824
2022-01-08 17:03:31,706 iteration 4475 : loss : 0.025320, loss_ce: 0.007057
2022-01-08 17:03:33,085 iteration 4476 : loss : 0.017588, loss_ce: 0.005446
2022-01-08 17:03:34,474 iteration 4477 : loss : 0.019416, loss_ce: 0.008305
2022-01-08 17:03:36,017 iteration 4478 : loss : 0.025619, loss_ce: 0.013058
2022-01-08 17:03:37,435 iteration 4479 : loss : 0.020828, loss_ce: 0.006203
2022-01-08 17:03:38,871 iteration 4480 : loss : 0.021245, loss_ce: 0.007927
2022-01-08 17:03:40,230 iteration 4481 : loss : 0.022771, loss_ce: 0.008465
2022-01-08 17:03:41,581 iteration 4482 : loss : 0.020420, loss_ce: 0.006143
2022-01-08 17:03:42,957 iteration 4483 : loss : 0.019127, loss_ce: 0.006410
2022-01-08 17:03:44,375 iteration 4484 : loss : 0.015804, loss_ce: 0.005526
2022-01-08 17:03:45,706 iteration 4485 : loss : 0.015617, loss_ce: 0.006535
2022-01-08 17:03:47,183 iteration 4486 : loss : 0.018266, loss_ce: 0.006644
2022-01-08 17:03:48,635 iteration 4487 : loss : 0.026309, loss_ce: 0.010265
2022-01-08 17:03:49,994 iteration 4488 : loss : 0.033924, loss_ce: 0.011017

 66%|███████████████████▏         | 264/400 [1:53:44<56:43, 25.03s/it]2022-01-08 17:03:51,507 iteration 4489 : loss : 0.021016, loss_ce: 0.009916
2022-01-08 17:03:52,914 iteration 4490 : loss : 0.021152, loss_ce: 0.009735
2022-01-08 17:03:54,450 iteration 4491 : loss : 0.027397, loss_ce: 0.010758
2022-01-08 17:03:55,832 iteration 4492 : loss : 0.019835, loss_ce: 0.005143
2022-01-08 17:03:57,346 iteration 4493 : loss : 0.025740, loss_ce: 0.015846
2022-01-08 17:03:58,722 iteration 4494 : loss : 0.019628, loss_ce: 0.006338
2022-01-08 17:04:00,156 iteration 4495 : loss : 0.023689, loss_ce: 0.006127
2022-01-08 17:04:01,591 iteration 4496 : loss : 0.017674, loss_ce: 0.005109
2022-01-08 17:04:02,890 iteration 4497 : loss : 0.020351, loss_ce: 0.009229
2022-01-08 17:04:04,301 iteration 4498 : loss : 0.021792, loss_ce: 0.006957
2022-01-08 17:04:05,673 iteration 4499 : loss : 0.017254, loss_ce: 0.007080
2022-01-08 17:04:07,085 iteration 4500 : loss : 0.019341, loss_ce: 0.006700
2022-01-08 17:04:08,469 iteration 4501 : loss : 0.018145, loss_ce: 0.008238
2022-01-08 17:04:09,864 iteration 4502 : loss : 0.021181, loss_ce: 0.007026
2022-01-08 17:04:11,368 iteration 4503 : loss : 0.018020, loss_ce: 0.005880
2022-01-08 17:04:12,684 iteration 4504 : loss : 0.016449, loss_ce: 0.006900
2022-01-08 17:04:12,684 Training Data Eval:
2022-01-08 17:04:19,610   Average segmentation loss on training set: 0.0124
2022-01-08 17:04:19,611 Validation Data Eval:
2022-01-08 17:04:22,002   Average segmentation loss on validation set: 0.0683
2022-01-08 17:04:23,417 iteration 4505 : loss : 0.020287, loss_ce: 0.007172

 66%|█████████████████▉         | 265/400 [1:54:17<1:01:59, 27.55s/it]2022-01-08 17:04:24,923 iteration 4506 : loss : 0.030317, loss_ce: 0.010980
2022-01-08 17:04:26,427 iteration 4507 : loss : 0.023659, loss_ce: 0.008490
2022-01-08 17:04:27,851 iteration 4508 : loss : 0.017982, loss_ce: 0.005102
2022-01-08 17:04:29,194 iteration 4509 : loss : 0.015675, loss_ce: 0.005232
2022-01-08 17:04:30,606 iteration 4510 : loss : 0.013439, loss_ce: 0.004191
2022-01-08 17:04:32,121 iteration 4511 : loss : 0.024370, loss_ce: 0.011017
2022-01-08 17:04:33,433 iteration 4512 : loss : 0.016672, loss_ce: 0.005728
2022-01-08 17:04:34,819 iteration 4513 : loss : 0.016418, loss_ce: 0.005712
2022-01-08 17:04:36,195 iteration 4514 : loss : 0.023283, loss_ce: 0.009138
2022-01-08 17:04:37,593 iteration 4515 : loss : 0.015377, loss_ce: 0.006117
2022-01-08 17:04:39,014 iteration 4516 : loss : 0.024514, loss_ce: 0.012831
2022-01-08 17:04:40,465 iteration 4517 : loss : 0.021802, loss_ce: 0.008217
2022-01-08 17:04:41,853 iteration 4518 : loss : 0.024324, loss_ce: 0.010085
2022-01-08 17:04:43,183 iteration 4519 : loss : 0.024738, loss_ce: 0.010235
2022-01-08 17:04:44,600 iteration 4520 : loss : 0.020977, loss_ce: 0.005429
2022-01-08 17:04:46,029 iteration 4521 : loss : 0.023012, loss_ce: 0.009424
2022-01-08 17:04:47,507 iteration 4522 : loss : 0.026029, loss_ce: 0.008455

 66%|███████████████████▎         | 266/400 [1:54:41<59:12, 26.51s/it]2022-01-08 17:04:49,076 iteration 4523 : loss : 0.036604, loss_ce: 0.018744
2022-01-08 17:04:50,513 iteration 4524 : loss : 0.018974, loss_ce: 0.006983
2022-01-08 17:04:51,968 iteration 4525 : loss : 0.021986, loss_ce: 0.009441
2022-01-08 17:04:53,378 iteration 4526 : loss : 0.015430, loss_ce: 0.004419
2022-01-08 17:04:54,708 iteration 4527 : loss : 0.021100, loss_ce: 0.007268
2022-01-08 17:04:56,075 iteration 4528 : loss : 0.017559, loss_ce: 0.005630
2022-01-08 17:04:57,511 iteration 4529 : loss : 0.018263, loss_ce: 0.007939
2022-01-08 17:04:58,882 iteration 4530 : loss : 0.022569, loss_ce: 0.006098
2022-01-08 17:05:00,303 iteration 4531 : loss : 0.016987, loss_ce: 0.005623
2022-01-08 17:05:01,753 iteration 4532 : loss : 0.019052, loss_ce: 0.005977
2022-01-08 17:05:03,136 iteration 4533 : loss : 0.020546, loss_ce: 0.008982
2022-01-08 17:05:04,527 iteration 4534 : loss : 0.035101, loss_ce: 0.009542
2022-01-08 17:05:05,976 iteration 4535 : loss : 0.017755, loss_ce: 0.006679
2022-01-08 17:05:07,413 iteration 4536 : loss : 0.017014, loss_ce: 0.006985
2022-01-08 17:05:08,834 iteration 4537 : loss : 0.027517, loss_ce: 0.010786
2022-01-08 17:05:10,240 iteration 4538 : loss : 0.018816, loss_ce: 0.006860
2022-01-08 17:05:11,648 iteration 4539 : loss : 0.023264, loss_ce: 0.009354

 67%|███████████████████▎         | 267/400 [1:55:05<57:11, 25.80s/it]2022-01-08 17:05:13,085 iteration 4540 : loss : 0.014362, loss_ce: 0.005255
2022-01-08 17:05:14,532 iteration 4541 : loss : 0.020255, loss_ce: 0.009385
2022-01-08 17:05:15,895 iteration 4542 : loss : 0.019103, loss_ce: 0.006876
2022-01-08 17:05:17,278 iteration 4543 : loss : 0.022687, loss_ce: 0.008670
2022-01-08 17:05:18,641 iteration 4544 : loss : 0.019973, loss_ce: 0.006137
2022-01-08 17:05:20,123 iteration 4545 : loss : 0.020812, loss_ce: 0.008844
2022-01-08 17:05:21,669 iteration 4546 : loss : 0.026756, loss_ce: 0.010912
2022-01-08 17:05:23,193 iteration 4547 : loss : 0.023476, loss_ce: 0.008566
2022-01-08 17:05:24,541 iteration 4548 : loss : 0.016581, loss_ce: 0.005988
2022-01-08 17:05:25,895 iteration 4549 : loss : 0.018737, loss_ce: 0.005978
2022-01-08 17:05:27,316 iteration 4550 : loss : 0.017494, loss_ce: 0.006703
2022-01-08 17:05:28,759 iteration 4551 : loss : 0.020613, loss_ce: 0.009028
2022-01-08 17:05:30,278 iteration 4552 : loss : 0.026694, loss_ce: 0.007699
2022-01-08 17:05:31,721 iteration 4553 : loss : 0.018751, loss_ce: 0.006908
2022-01-08 17:05:33,083 iteration 4554 : loss : 0.021944, loss_ce: 0.009853
2022-01-08 17:05:34,481 iteration 4555 : loss : 0.015902, loss_ce: 0.006016
2022-01-08 17:05:35,878 iteration 4556 : loss : 0.025413, loss_ce: 0.008129

 67%|███████████████████▍         | 268/400 [1:55:30<55:43, 25.33s/it]2022-01-08 17:05:37,309 iteration 4557 : loss : 0.024103, loss_ce: 0.012821
2022-01-08 17:05:38,759 iteration 4558 : loss : 0.021532, loss_ce: 0.007371
2022-01-08 17:05:40,260 iteration 4559 : loss : 0.021764, loss_ce: 0.008343
2022-01-08 17:05:41,721 iteration 4560 : loss : 0.026088, loss_ce: 0.015191
2022-01-08 17:05:43,092 iteration 4561 : loss : 0.014951, loss_ce: 0.005041
2022-01-08 17:05:44,518 iteration 4562 : loss : 0.026258, loss_ce: 0.009808
2022-01-08 17:05:45,911 iteration 4563 : loss : 0.020852, loss_ce: 0.007404
2022-01-08 17:05:47,291 iteration 4564 : loss : 0.019817, loss_ce: 0.008491
2022-01-08 17:05:48,700 iteration 4565 : loss : 0.020478, loss_ce: 0.008390
2022-01-08 17:05:50,125 iteration 4566 : loss : 0.020066, loss_ce: 0.007996
2022-01-08 17:05:51,530 iteration 4567 : loss : 0.026598, loss_ce: 0.010190
2022-01-08 17:05:52,849 iteration 4568 : loss : 0.016157, loss_ce: 0.005207
2022-01-08 17:05:54,199 iteration 4569 : loss : 0.016607, loss_ce: 0.006618
2022-01-08 17:05:55,559 iteration 4570 : loss : 0.019962, loss_ce: 0.007593
2022-01-08 17:05:57,007 iteration 4571 : loss : 0.026895, loss_ce: 0.012401
2022-01-08 17:05:58,457 iteration 4572 : loss : 0.030742, loss_ce: 0.012352
2022-01-08 17:05:59,929 iteration 4573 : loss : 0.027496, loss_ce: 0.008821

 67%|███████████████████▌         | 269/400 [1:55:54<54:27, 24.94s/it]2022-01-08 17:06:01,328 iteration 4574 : loss : 0.014526, loss_ce: 0.004748
2022-01-08 17:06:02,768 iteration 4575 : loss : 0.022476, loss_ce: 0.005909
2022-01-08 17:06:04,098 iteration 4576 : loss : 0.014951, loss_ce: 0.006315
2022-01-08 17:06:05,446 iteration 4577 : loss : 0.016415, loss_ce: 0.007587
2022-01-08 17:06:06,848 iteration 4578 : loss : 0.020303, loss_ce: 0.008393
2022-01-08 17:06:08,210 iteration 4579 : loss : 0.014853, loss_ce: 0.006843
2022-01-08 17:06:09,589 iteration 4580 : loss : 0.018677, loss_ce: 0.007573
2022-01-08 17:06:10,997 iteration 4581 : loss : 0.033915, loss_ce: 0.014459
2022-01-08 17:06:12,400 iteration 4582 : loss : 0.023146, loss_ce: 0.008822
2022-01-08 17:06:13,810 iteration 4583 : loss : 0.025893, loss_ce: 0.009327
2022-01-08 17:06:15,193 iteration 4584 : loss : 0.014815, loss_ce: 0.005146
2022-01-08 17:06:16,627 iteration 4585 : loss : 0.022975, loss_ce: 0.007741
2022-01-08 17:06:17,971 iteration 4586 : loss : 0.018822, loss_ce: 0.007873
2022-01-08 17:06:19,334 iteration 4587 : loss : 0.017975, loss_ce: 0.005599
2022-01-08 17:06:20,707 iteration 4588 : loss : 0.029435, loss_ce: 0.009915
2022-01-08 17:06:22,130 iteration 4589 : loss : 0.021820, loss_ce: 0.007836
2022-01-08 17:06:22,130 Training Data Eval:
2022-01-08 17:06:29,041   Average segmentation loss on training set: 0.0134
2022-01-08 17:06:29,041 Validation Data Eval:
2022-01-08 17:06:31,422   Average segmentation loss on validation set: 0.0732
2022-01-08 17:06:32,831 iteration 4590 : loss : 0.022110, loss_ce: 0.010459

 68%|███████████████████▌         | 270/400 [1:56:27<59:13, 27.33s/it]2022-01-08 17:06:34,299 iteration 4591 : loss : 0.034369, loss_ce: 0.009734
2022-01-08 17:06:35,769 iteration 4592 : loss : 0.019513, loss_ce: 0.006589
2022-01-08 17:06:37,214 iteration 4593 : loss : 0.020525, loss_ce: 0.009781
2022-01-08 17:06:38,701 iteration 4594 : loss : 0.043615, loss_ce: 0.013982
2022-01-08 17:06:40,104 iteration 4595 : loss : 0.022697, loss_ce: 0.007997
2022-01-08 17:06:41,488 iteration 4596 : loss : 0.020780, loss_ce: 0.006015
2022-01-08 17:06:42,913 iteration 4597 : loss : 0.018229, loss_ce: 0.007933
2022-01-08 17:06:44,395 iteration 4598 : loss : 0.027080, loss_ce: 0.009598
2022-01-08 17:06:45,849 iteration 4599 : loss : 0.019439, loss_ce: 0.008650
2022-01-08 17:06:47,239 iteration 4600 : loss : 0.032281, loss_ce: 0.009132
2022-01-08 17:06:48,683 iteration 4601 : loss : 0.025002, loss_ce: 0.009832
2022-01-08 17:06:50,212 iteration 4602 : loss : 0.027314, loss_ce: 0.007321
2022-01-08 17:06:51,644 iteration 4603 : loss : 0.028547, loss_ce: 0.010266
2022-01-08 17:06:53,110 iteration 4604 : loss : 0.022037, loss_ce: 0.010362
2022-01-08 17:06:54,590 iteration 4605 : loss : 0.043254, loss_ce: 0.008669
2022-01-08 17:06:56,066 iteration 4606 : loss : 0.023142, loss_ce: 0.008837
2022-01-08 17:06:57,542 iteration 4607 : loss : 0.022793, loss_ce: 0.012896

 68%|███████████████████▋         | 271/400 [1:56:51<57:04, 26.55s/it]2022-01-08 17:06:58,975 iteration 4608 : loss : 0.014697, loss_ce: 0.005679
2022-01-08 17:07:00,399 iteration 4609 : loss : 0.029055, loss_ce: 0.011634
2022-01-08 17:07:01,755 iteration 4610 : loss : 0.020777, loss_ce: 0.007070
2022-01-08 17:07:03,106 iteration 4611 : loss : 0.020220, loss_ce: 0.007772
2022-01-08 17:07:04,433 iteration 4612 : loss : 0.017755, loss_ce: 0.005160
2022-01-08 17:07:05,838 iteration 4613 : loss : 0.024013, loss_ce: 0.008775
2022-01-08 17:07:07,256 iteration 4614 : loss : 0.015840, loss_ce: 0.007280
2022-01-08 17:07:08,722 iteration 4615 : loss : 0.018571, loss_ce: 0.007482
2022-01-08 17:07:10,268 iteration 4616 : loss : 0.022351, loss_ce: 0.010048
2022-01-08 17:07:11,709 iteration 4617 : loss : 0.021449, loss_ce: 0.007774
2022-01-08 17:07:13,068 iteration 4618 : loss : 0.016956, loss_ce: 0.004966
2022-01-08 17:07:14,436 iteration 4619 : loss : 0.014294, loss_ce: 0.006039
2022-01-08 17:07:15,918 iteration 4620 : loss : 0.019963, loss_ce: 0.006183
2022-01-08 17:07:17,328 iteration 4621 : loss : 0.021944, loss_ce: 0.011168
2022-01-08 17:07:18,750 iteration 4622 : loss : 0.045795, loss_ce: 0.017478
2022-01-08 17:07:20,152 iteration 4623 : loss : 0.017768, loss_ce: 0.005326
2022-01-08 17:07:21,575 iteration 4624 : loss : 0.018034, loss_ce: 0.008193

 68%|███████████████████▋         | 272/400 [1:57:15<55:01, 25.79s/it]2022-01-08 17:07:23,094 iteration 4625 : loss : 0.016481, loss_ce: 0.006271
2022-01-08 17:07:24,584 iteration 4626 : loss : 0.036193, loss_ce: 0.018539
2022-01-08 17:07:26,119 iteration 4627 : loss : 0.023711, loss_ce: 0.010144
2022-01-08 17:07:27,509 iteration 4628 : loss : 0.020899, loss_ce: 0.007305
2022-01-08 17:07:28,847 iteration 4629 : loss : 0.017784, loss_ce: 0.006140
2022-01-08 17:07:30,247 iteration 4630 : loss : 0.016624, loss_ce: 0.006205
2022-01-08 17:07:31,669 iteration 4631 : loss : 0.020306, loss_ce: 0.007605
2022-01-08 17:07:33,090 iteration 4632 : loss : 0.029229, loss_ce: 0.008715
2022-01-08 17:07:34,480 iteration 4633 : loss : 0.018124, loss_ce: 0.005586
2022-01-08 17:07:35,842 iteration 4634 : loss : 0.014465, loss_ce: 0.006497
2022-01-08 17:07:37,162 iteration 4635 : loss : 0.013725, loss_ce: 0.005102
2022-01-08 17:07:38,672 iteration 4636 : loss : 0.026163, loss_ce: 0.009560
2022-01-08 17:07:40,059 iteration 4637 : loss : 0.017405, loss_ce: 0.005222
2022-01-08 17:07:41,602 iteration 4638 : loss : 0.022354, loss_ce: 0.010098
2022-01-08 17:07:43,076 iteration 4639 : loss : 0.027388, loss_ce: 0.009375
2022-01-08 17:07:44,638 iteration 4640 : loss : 0.033548, loss_ce: 0.011046
2022-01-08 17:07:46,112 iteration 4641 : loss : 0.026930, loss_ce: 0.009596

 68%|███████████████████▊         | 273/400 [1:57:40<53:47, 25.42s/it]2022-01-08 17:07:47,578 iteration 4642 : loss : 0.021470, loss_ce: 0.005080
2022-01-08 17:07:48,993 iteration 4643 : loss : 0.023925, loss_ce: 0.007664
2022-01-08 17:07:50,477 iteration 4644 : loss : 0.021839, loss_ce: 0.007240
2022-01-08 17:07:51,979 iteration 4645 : loss : 0.020079, loss_ce: 0.009366
2022-01-08 17:07:53,429 iteration 4646 : loss : 0.036107, loss_ce: 0.011258
2022-01-08 17:07:54,765 iteration 4647 : loss : 0.016822, loss_ce: 0.005610
2022-01-08 17:07:56,148 iteration 4648 : loss : 0.025492, loss_ce: 0.008595
2022-01-08 17:07:57,573 iteration 4649 : loss : 0.018649, loss_ce: 0.007764
2022-01-08 17:07:59,053 iteration 4650 : loss : 0.035661, loss_ce: 0.011284
2022-01-08 17:08:00,411 iteration 4651 : loss : 0.016465, loss_ce: 0.007256
2022-01-08 17:08:01,924 iteration 4652 : loss : 0.023793, loss_ce: 0.009221
2022-01-08 17:08:03,323 iteration 4653 : loss : 0.022192, loss_ce: 0.008949
2022-01-08 17:08:04,722 iteration 4654 : loss : 0.027038, loss_ce: 0.009790
2022-01-08 17:08:06,220 iteration 4655 : loss : 0.025408, loss_ce: 0.009880
2022-01-08 17:08:07,742 iteration 4656 : loss : 0.025610, loss_ce: 0.010609
2022-01-08 17:08:09,221 iteration 4657 : loss : 0.034679, loss_ce: 0.016389
2022-01-08 17:08:10,686 iteration 4658 : loss : 0.023093, loss_ce: 0.008686

 68%|███████████████████▊         | 274/400 [1:58:04<52:50, 25.16s/it]2022-01-08 17:08:12,206 iteration 4659 : loss : 0.021822, loss_ce: 0.009445
2022-01-08 17:08:13,697 iteration 4660 : loss : 0.027595, loss_ce: 0.012881
2022-01-08 17:08:15,155 iteration 4661 : loss : 0.025674, loss_ce: 0.008805
2022-01-08 17:08:16,523 iteration 4662 : loss : 0.015943, loss_ce: 0.005258
2022-01-08 17:08:17,978 iteration 4663 : loss : 0.022418, loss_ce: 0.009176
2022-01-08 17:08:19,373 iteration 4664 : loss : 0.015723, loss_ce: 0.005646
2022-01-08 17:08:20,781 iteration 4665 : loss : 0.019956, loss_ce: 0.006824
2022-01-08 17:08:22,084 iteration 4666 : loss : 0.015101, loss_ce: 0.005146
2022-01-08 17:08:23,455 iteration 4667 : loss : 0.015398, loss_ce: 0.005821
2022-01-08 17:08:25,014 iteration 4668 : loss : 0.043122, loss_ce: 0.018923
2022-01-08 17:08:26,378 iteration 4669 : loss : 0.015325, loss_ce: 0.006596
2022-01-08 17:08:27,753 iteration 4670 : loss : 0.026245, loss_ce: 0.010595
2022-01-08 17:08:29,108 iteration 4671 : loss : 0.032731, loss_ce: 0.009227
2022-01-08 17:08:30,632 iteration 4672 : loss : 0.029024, loss_ce: 0.010785
2022-01-08 17:08:32,123 iteration 4673 : loss : 0.036306, loss_ce: 0.014384
2022-01-08 17:08:33,465 iteration 4674 : loss : 0.015976, loss_ce: 0.004177
2022-01-08 17:08:33,465 Training Data Eval:
2022-01-08 17:08:40,384   Average segmentation loss on training set: 0.0128
2022-01-08 17:08:40,385 Validation Data Eval:
2022-01-08 17:08:42,779   Average segmentation loss on validation set: 0.0643
2022-01-08 17:08:44,257 iteration 4675 : loss : 0.017666, loss_ce: 0.007170

 69%|███████████████████▉         | 275/400 [1:58:38<57:40, 27.69s/it]2022-01-08 17:08:45,837 iteration 4676 : loss : 0.023065, loss_ce: 0.007393
2022-01-08 17:08:47,240 iteration 4677 : loss : 0.026488, loss_ce: 0.008827
2022-01-08 17:08:48,682 iteration 4678 : loss : 0.026924, loss_ce: 0.008235
2022-01-08 17:08:50,188 iteration 4679 : loss : 0.031270, loss_ce: 0.009708
2022-01-08 17:08:51,607 iteration 4680 : loss : 0.017498, loss_ce: 0.006825
2022-01-08 17:08:53,010 iteration 4681 : loss : 0.025199, loss_ce: 0.007681
2022-01-08 17:08:54,395 iteration 4682 : loss : 0.016507, loss_ce: 0.006409
2022-01-08 17:08:55,696 iteration 4683 : loss : 0.023191, loss_ce: 0.006122
2022-01-08 17:08:57,178 iteration 4684 : loss : 0.021780, loss_ce: 0.009817
2022-01-08 17:08:58,634 iteration 4685 : loss : 0.040497, loss_ce: 0.013711
2022-01-08 17:09:00,045 iteration 4686 : loss : 0.017118, loss_ce: 0.004700
2022-01-08 17:09:01,434 iteration 4687 : loss : 0.016873, loss_ce: 0.007524
2022-01-08 17:09:02,762 iteration 4688 : loss : 0.014953, loss_ce: 0.006324
2022-01-08 17:09:04,094 iteration 4689 : loss : 0.013226, loss_ce: 0.005537
2022-01-08 17:09:05,454 iteration 4690 : loss : 0.022148, loss_ce: 0.008786
2022-01-08 17:09:06,912 iteration 4691 : loss : 0.034964, loss_ce: 0.018315
2022-01-08 17:09:08,299 iteration 4692 : loss : 0.021016, loss_ce: 0.006136

 69%|████████████████████         | 276/400 [1:59:02<54:57, 26.59s/it]2022-01-08 17:09:09,852 iteration 4693 : loss : 0.021566, loss_ce: 0.007900
2022-01-08 17:09:11,302 iteration 4694 : loss : 0.069896, loss_ce: 0.021586
2022-01-08 17:09:12,553 iteration 4695 : loss : 0.013462, loss_ce: 0.004470
2022-01-08 17:09:14,046 iteration 4696 : loss : 0.024155, loss_ce: 0.008027
2022-01-08 17:09:15,426 iteration 4697 : loss : 0.019788, loss_ce: 0.007120
2022-01-08 17:09:16,841 iteration 4698 : loss : 0.021392, loss_ce: 0.009958
2022-01-08 17:09:18,328 iteration 4699 : loss : 0.017736, loss_ce: 0.007872
2022-01-08 17:09:19,692 iteration 4700 : loss : 0.022335, loss_ce: 0.010259
2022-01-08 17:09:21,225 iteration 4701 : loss : 0.023525, loss_ce: 0.010074
2022-01-08 17:09:22,621 iteration 4702 : loss : 0.018366, loss_ce: 0.007680
2022-01-08 17:09:23,987 iteration 4703 : loss : 0.022454, loss_ce: 0.006236
2022-01-08 17:09:25,401 iteration 4704 : loss : 0.023599, loss_ce: 0.008103
2022-01-08 17:09:26,665 iteration 4705 : loss : 0.012886, loss_ce: 0.005528
2022-01-08 17:09:28,069 iteration 4706 : loss : 0.018737, loss_ce: 0.004392
2022-01-08 17:09:29,544 iteration 4707 : loss : 0.023079, loss_ce: 0.008286
2022-01-08 17:09:31,033 iteration 4708 : loss : 0.018305, loss_ce: 0.006069
2022-01-08 17:09:32,494 iteration 4709 : loss : 0.027794, loss_ce: 0.010101

 69%|████████████████████         | 277/400 [1:59:26<53:02, 25.87s/it]2022-01-08 17:09:34,007 iteration 4710 : loss : 0.038838, loss_ce: 0.006197
2022-01-08 17:09:35,596 iteration 4711 : loss : 0.024009, loss_ce: 0.008860
2022-01-08 17:09:36,998 iteration 4712 : loss : 0.021627, loss_ce: 0.007935
2022-01-08 17:09:38,406 iteration 4713 : loss : 0.018207, loss_ce: 0.006666
2022-01-08 17:09:39,825 iteration 4714 : loss : 0.019205, loss_ce: 0.006266
2022-01-08 17:09:41,273 iteration 4715 : loss : 0.027445, loss_ce: 0.011062
2022-01-08 17:09:42,683 iteration 4716 : loss : 0.019469, loss_ce: 0.007214
2022-01-08 17:09:44,063 iteration 4717 : loss : 0.018396, loss_ce: 0.006592
2022-01-08 17:09:45,386 iteration 4718 : loss : 0.014186, loss_ce: 0.005058
2022-01-08 17:09:46,712 iteration 4719 : loss : 0.019095, loss_ce: 0.009145
2022-01-08 17:09:48,053 iteration 4720 : loss : 0.016579, loss_ce: 0.006804
2022-01-08 17:09:49,414 iteration 4721 : loss : 0.020440, loss_ce: 0.007909
2022-01-08 17:09:50,852 iteration 4722 : loss : 0.026590, loss_ce: 0.007946
2022-01-08 17:09:52,232 iteration 4723 : loss : 0.015254, loss_ce: 0.005370
2022-01-08 17:09:53,550 iteration 4724 : loss : 0.015940, loss_ce: 0.005966
2022-01-08 17:09:54,867 iteration 4725 : loss : 0.016611, loss_ce: 0.006474
2022-01-08 17:09:56,262 iteration 4726 : loss : 0.019633, loss_ce: 0.008021

 70%|████████████████████▏        | 278/400 [1:59:50<51:19, 25.24s/it]2022-01-08 17:09:57,799 iteration 4727 : loss : 0.026058, loss_ce: 0.007581
2022-01-08 17:09:59,153 iteration 4728 : loss : 0.018373, loss_ce: 0.007391
2022-01-08 17:10:00,520 iteration 4729 : loss : 0.020339, loss_ce: 0.008443
2022-01-08 17:10:01,854 iteration 4730 : loss : 0.014886, loss_ce: 0.005853
2022-01-08 17:10:03,280 iteration 4731 : loss : 0.020216, loss_ce: 0.006737
2022-01-08 17:10:04,671 iteration 4732 : loss : 0.020396, loss_ce: 0.006150
2022-01-08 17:10:06,053 iteration 4733 : loss : 0.015274, loss_ce: 0.005691
2022-01-08 17:10:07,436 iteration 4734 : loss : 0.017644, loss_ce: 0.006153
2022-01-08 17:10:08,930 iteration 4735 : loss : 0.022481, loss_ce: 0.007317
2022-01-08 17:10:10,259 iteration 4736 : loss : 0.017387, loss_ce: 0.007435
2022-01-08 17:10:11,704 iteration 4737 : loss : 0.027685, loss_ce: 0.011870
2022-01-08 17:10:13,077 iteration 4738 : loss : 0.014670, loss_ce: 0.005008
2022-01-08 17:10:14,451 iteration 4739 : loss : 0.017948, loss_ce: 0.006097
2022-01-08 17:10:15,874 iteration 4740 : loss : 0.030575, loss_ce: 0.012877
2022-01-08 17:10:17,230 iteration 4741 : loss : 0.024983, loss_ce: 0.008640
2022-01-08 17:10:18,592 iteration 4742 : loss : 0.020221, loss_ce: 0.010817
2022-01-08 17:10:20,044 iteration 4743 : loss : 0.026322, loss_ce: 0.008322

 70%|████████████████████▏        | 279/400 [2:00:14<50:01, 24.80s/it]2022-01-08 17:10:21,539 iteration 4744 : loss : 0.022988, loss_ce: 0.009422
2022-01-08 17:10:22,922 iteration 4745 : loss : 0.019799, loss_ce: 0.005722
2022-01-08 17:10:24,260 iteration 4746 : loss : 0.016567, loss_ce: 0.007947
2022-01-08 17:10:25,613 iteration 4747 : loss : 0.018714, loss_ce: 0.006318
2022-01-08 17:10:27,001 iteration 4748 : loss : 0.016768, loss_ce: 0.005848
2022-01-08 17:10:28,392 iteration 4749 : loss : 0.027037, loss_ce: 0.010773
2022-01-08 17:10:29,825 iteration 4750 : loss : 0.019870, loss_ce: 0.007312
2022-01-08 17:10:31,183 iteration 4751 : loss : 0.021339, loss_ce: 0.007871
2022-01-08 17:10:32,591 iteration 4752 : loss : 0.016394, loss_ce: 0.005511
2022-01-08 17:10:34,016 iteration 4753 : loss : 0.018132, loss_ce: 0.006544
2022-01-08 17:10:35,421 iteration 4754 : loss : 0.015371, loss_ce: 0.005497
2022-01-08 17:10:36,904 iteration 4755 : loss : 0.025453, loss_ce: 0.007729
2022-01-08 17:10:38,256 iteration 4756 : loss : 0.019480, loss_ce: 0.009957
2022-01-08 17:10:39,619 iteration 4757 : loss : 0.022851, loss_ce: 0.008643
2022-01-08 17:10:40,958 iteration 4758 : loss : 0.020094, loss_ce: 0.005978
2022-01-08 17:10:42,330 iteration 4759 : loss : 0.013912, loss_ce: 0.004963
2022-01-08 17:10:42,330 Training Data Eval:
2022-01-08 17:10:49,180   Average segmentation loss on training set: 0.0123
2022-01-08 17:10:49,180 Validation Data Eval:
2022-01-08 17:10:51,537   Average segmentation loss on validation set: 0.0755
2022-01-08 17:10:52,889 iteration 4760 : loss : 0.016599, loss_ce: 0.006943

 70%|████████████████████▎        | 280/400 [2:00:47<54:25, 27.22s/it]2022-01-08 17:10:54,315 iteration 4761 : loss : 0.024118, loss_ce: 0.008221
2022-01-08 17:10:55,721 iteration 4762 : loss : 0.024046, loss_ce: 0.007569
2022-01-08 17:10:57,045 iteration 4763 : loss : 0.014545, loss_ce: 0.005788
2022-01-08 17:10:58,455 iteration 4764 : loss : 0.024585, loss_ce: 0.007708
2022-01-08 17:10:59,815 iteration 4765 : loss : 0.020093, loss_ce: 0.008758
2022-01-08 17:11:01,253 iteration 4766 : loss : 0.022067, loss_ce: 0.007901
2022-01-08 17:11:02,657 iteration 4767 : loss : 0.015342, loss_ce: 0.006116
2022-01-08 17:11:03,995 iteration 4768 : loss : 0.019203, loss_ce: 0.006456
2022-01-08 17:11:05,411 iteration 4769 : loss : 0.025789, loss_ce: 0.009329
2022-01-08 17:11:06,836 iteration 4770 : loss : 0.020167, loss_ce: 0.008223
2022-01-08 17:11:08,157 iteration 4771 : loss : 0.017441, loss_ce: 0.005554
2022-01-08 17:11:09,580 iteration 4772 : loss : 0.028245, loss_ce: 0.012987
2022-01-08 17:11:10,993 iteration 4773 : loss : 0.025456, loss_ce: 0.009089
2022-01-08 17:11:12,394 iteration 4774 : loss : 0.017355, loss_ce: 0.007313
2022-01-08 17:11:13,739 iteration 4775 : loss : 0.030938, loss_ce: 0.008698
2022-01-08 17:11:15,111 iteration 4776 : loss : 0.016417, loss_ce: 0.008656
2022-01-08 17:11:16,622 iteration 4777 : loss : 0.024656, loss_ce: 0.009601

 70%|████████████████████▎        | 281/400 [2:01:10<51:54, 26.17s/it]2022-01-08 17:11:17,988 iteration 4778 : loss : 0.013043, loss_ce: 0.003440
2022-01-08 17:11:19,347 iteration 4779 : loss : 0.021372, loss_ce: 0.007168
2022-01-08 17:11:20,650 iteration 4780 : loss : 0.013359, loss_ce: 0.004627
2022-01-08 17:11:22,000 iteration 4781 : loss : 0.025391, loss_ce: 0.007248
2022-01-08 17:11:23,428 iteration 4782 : loss : 0.035882, loss_ce: 0.021571
2022-01-08 17:11:24,809 iteration 4783 : loss : 0.020602, loss_ce: 0.010571
2022-01-08 17:11:26,130 iteration 4784 : loss : 0.014512, loss_ce: 0.006187
2022-01-08 17:11:27,577 iteration 4785 : loss : 0.020871, loss_ce: 0.007234
2022-01-08 17:11:28,981 iteration 4786 : loss : 0.018697, loss_ce: 0.006339
2022-01-08 17:11:30,386 iteration 4787 : loss : 0.019134, loss_ce: 0.005983
2022-01-08 17:11:31,796 iteration 4788 : loss : 0.023183, loss_ce: 0.008784
2022-01-08 17:11:33,118 iteration 4789 : loss : 0.015623, loss_ce: 0.007737
2022-01-08 17:11:34,586 iteration 4790 : loss : 0.021436, loss_ce: 0.007420
2022-01-08 17:11:35,948 iteration 4791 : loss : 0.021454, loss_ce: 0.010246
2022-01-08 17:11:37,379 iteration 4792 : loss : 0.026398, loss_ce: 0.009909
2022-01-08 17:11:38,723 iteration 4793 : loss : 0.015917, loss_ce: 0.005539
2022-01-08 17:11:40,016 iteration 4794 : loss : 0.022715, loss_ce: 0.006149

 70%|████████████████████▍        | 282/400 [2:01:34<49:49, 25.34s/it]2022-01-08 17:11:41,476 iteration 4795 : loss : 0.020951, loss_ce: 0.006475
2022-01-08 17:11:42,871 iteration 4796 : loss : 0.039583, loss_ce: 0.014359
2022-01-08 17:11:44,276 iteration 4797 : loss : 0.024304, loss_ce: 0.010304
2022-01-08 17:11:45,722 iteration 4798 : loss : 0.028376, loss_ce: 0.008700
2022-01-08 17:11:47,102 iteration 4799 : loss : 0.014787, loss_ce: 0.004954
2022-01-08 17:11:48,489 iteration 4800 : loss : 0.024925, loss_ce: 0.007677
2022-01-08 17:11:49,946 iteration 4801 : loss : 0.020954, loss_ce: 0.007703
2022-01-08 17:11:51,253 iteration 4802 : loss : 0.013337, loss_ce: 0.005369
2022-01-08 17:11:52,607 iteration 4803 : loss : 0.026017, loss_ce: 0.011194
2022-01-08 17:11:54,053 iteration 4804 : loss : 0.045221, loss_ce: 0.009551
2022-01-08 17:11:55,491 iteration 4805 : loss : 0.027824, loss_ce: 0.010706
2022-01-08 17:11:56,936 iteration 4806 : loss : 0.019474, loss_ce: 0.008411
2022-01-08 17:11:58,247 iteration 4807 : loss : 0.019970, loss_ce: 0.008490
2022-01-08 17:11:59,552 iteration 4808 : loss : 0.015415, loss_ce: 0.006576
2022-01-08 17:12:00,942 iteration 4809 : loss : 0.027565, loss_ce: 0.012907
2022-01-08 17:12:02,318 iteration 4810 : loss : 0.020519, loss_ce: 0.005617
2022-01-08 17:12:03,710 iteration 4811 : loss : 0.017162, loss_ce: 0.006178

 71%|████████████████████▌        | 283/400 [2:01:57<48:26, 24.84s/it]2022-01-08 17:12:05,091 iteration 4812 : loss : 0.014948, loss_ce: 0.005900
2022-01-08 17:12:06,487 iteration 4813 : loss : 0.018455, loss_ce: 0.004317
2022-01-08 17:12:07,909 iteration 4814 : loss : 0.027660, loss_ce: 0.006850
2022-01-08 17:12:09,228 iteration 4815 : loss : 0.015304, loss_ce: 0.006503
2022-01-08 17:12:10,710 iteration 4816 : loss : 0.021194, loss_ce: 0.008832
2022-01-08 17:12:12,074 iteration 4817 : loss : 0.021977, loss_ce: 0.009288
2022-01-08 17:12:13,433 iteration 4818 : loss : 0.016246, loss_ce: 0.006089
2022-01-08 17:12:14,730 iteration 4819 : loss : 0.016818, loss_ce: 0.006471
2022-01-08 17:12:16,076 iteration 4820 : loss : 0.018156, loss_ce: 0.006723
2022-01-08 17:12:17,539 iteration 4821 : loss : 0.023996, loss_ce: 0.011279
2022-01-08 17:12:18,994 iteration 4822 : loss : 0.020958, loss_ce: 0.006953
2022-01-08 17:12:20,369 iteration 4823 : loss : 0.022070, loss_ce: 0.010162
2022-01-08 17:12:21,775 iteration 4824 : loss : 0.022075, loss_ce: 0.008630
2022-01-08 17:12:23,131 iteration 4825 : loss : 0.022947, loss_ce: 0.008708
2022-01-08 17:12:24,481 iteration 4826 : loss : 0.018597, loss_ce: 0.005582
2022-01-08 17:12:25,841 iteration 4827 : loss : 0.017054, loss_ce: 0.006637
2022-01-08 17:12:27,184 iteration 4828 : loss : 0.017628, loss_ce: 0.006392

 71%|████████████████████▌        | 284/400 [2:02:21<47:14, 24.43s/it]2022-01-08 17:12:28,564 iteration 4829 : loss : 0.020130, loss_ce: 0.006545
2022-01-08 17:12:29,972 iteration 4830 : loss : 0.019666, loss_ce: 0.008533
2022-01-08 17:12:31,364 iteration 4831 : loss : 0.018454, loss_ce: 0.007138
2022-01-08 17:12:32,729 iteration 4832 : loss : 0.018353, loss_ce: 0.005850
2022-01-08 17:12:34,143 iteration 4833 : loss : 0.023456, loss_ce: 0.008571
2022-01-08 17:12:35,460 iteration 4834 : loss : 0.018752, loss_ce: 0.006660
2022-01-08 17:12:36,945 iteration 4835 : loss : 0.023117, loss_ce: 0.011436
2022-01-08 17:12:38,334 iteration 4836 : loss : 0.018961, loss_ce: 0.005526
2022-01-08 17:12:39,758 iteration 4837 : loss : 0.020268, loss_ce: 0.005094
2022-01-08 17:12:41,117 iteration 4838 : loss : 0.014014, loss_ce: 0.004271
2022-01-08 17:12:42,520 iteration 4839 : loss : 0.021470, loss_ce: 0.007794
2022-01-08 17:12:43,900 iteration 4840 : loss : 0.021793, loss_ce: 0.010255
2022-01-08 17:12:45,213 iteration 4841 : loss : 0.012065, loss_ce: 0.003780
2022-01-08 17:12:46,598 iteration 4842 : loss : 0.021512, loss_ce: 0.009215
2022-01-08 17:12:48,061 iteration 4843 : loss : 0.022881, loss_ce: 0.006856
2022-01-08 17:12:49,439 iteration 4844 : loss : 0.028259, loss_ce: 0.009254
2022-01-08 17:12:49,439 Training Data Eval:
2022-01-08 17:12:56,281   Average segmentation loss on training set: 0.0116
2022-01-08 17:12:56,281 Validation Data Eval:
2022-01-08 17:12:58,643   Average segmentation loss on validation set: 0.0743
2022-01-08 17:13:00,058 iteration 4845 : loss : 0.017893, loss_ce: 0.008534

 71%|████████████████████▋        | 285/400 [2:02:54<51:41, 26.97s/it]2022-01-08 17:13:01,460 iteration 4846 : loss : 0.022821, loss_ce: 0.009333
2022-01-08 17:13:02,807 iteration 4847 : loss : 0.019767, loss_ce: 0.006787
2022-01-08 17:13:04,246 iteration 4848 : loss : 0.030421, loss_ce: 0.015138
2022-01-08 17:13:05,672 iteration 4849 : loss : 0.021750, loss_ce: 0.006335
2022-01-08 17:13:07,037 iteration 4850 : loss : 0.016397, loss_ce: 0.004661
2022-01-08 17:13:08,549 iteration 4851 : loss : 0.015734, loss_ce: 0.006430
2022-01-08 17:13:09,937 iteration 4852 : loss : 0.017736, loss_ce: 0.006884
2022-01-08 17:13:11,345 iteration 4853 : loss : 0.017986, loss_ce: 0.007460
2022-01-08 17:13:12,751 iteration 4854 : loss : 0.016961, loss_ce: 0.006446
2022-01-08 17:13:14,120 iteration 4855 : loss : 0.025409, loss_ce: 0.006968
2022-01-08 17:13:15,615 iteration 4856 : loss : 0.021855, loss_ce: 0.007997
2022-01-08 17:13:16,985 iteration 4857 : loss : 0.013089, loss_ce: 0.004873
2022-01-08 17:13:18,442 iteration 4858 : loss : 0.017841, loss_ce: 0.006516
2022-01-08 17:13:19,765 iteration 4859 : loss : 0.011924, loss_ce: 0.004752
2022-01-08 17:13:21,185 iteration 4860 : loss : 0.021725, loss_ce: 0.010278
2022-01-08 17:13:22,541 iteration 4861 : loss : 0.021291, loss_ce: 0.006560
2022-01-08 17:13:23,962 iteration 4862 : loss : 0.018488, loss_ce: 0.009023

 72%|████████████████████▋        | 286/400 [2:03:18<49:29, 26.05s/it]2022-01-08 17:13:25,478 iteration 4863 : loss : 0.018916, loss_ce: 0.005436
2022-01-08 17:13:26,857 iteration 4864 : loss : 0.013460, loss_ce: 0.004708
2022-01-08 17:13:28,216 iteration 4865 : loss : 0.014038, loss_ce: 0.006453
2022-01-08 17:13:29,658 iteration 4866 : loss : 0.017889, loss_ce: 0.005237
2022-01-08 17:13:31,050 iteration 4867 : loss : 0.018753, loss_ce: 0.006029
2022-01-08 17:13:32,337 iteration 4868 : loss : 0.018082, loss_ce: 0.007601
2022-01-08 17:13:33,806 iteration 4869 : loss : 0.026007, loss_ce: 0.012192
2022-01-08 17:13:35,180 iteration 4870 : loss : 0.012875, loss_ce: 0.004441
2022-01-08 17:13:36,653 iteration 4871 : loss : 0.030121, loss_ce: 0.010578
2022-01-08 17:13:37,968 iteration 4872 : loss : 0.013529, loss_ce: 0.003977
2022-01-08 17:13:39,438 iteration 4873 : loss : 0.015766, loss_ce: 0.005656
2022-01-08 17:13:40,845 iteration 4874 : loss : 0.031298, loss_ce: 0.010140
2022-01-08 17:13:42,215 iteration 4875 : loss : 0.024113, loss_ce: 0.009556
2022-01-08 17:13:43,516 iteration 4876 : loss : 0.023810, loss_ce: 0.007190
2022-01-08 17:13:44,943 iteration 4877 : loss : 0.023949, loss_ce: 0.012207
2022-01-08 17:13:46,399 iteration 4878 : loss : 0.033197, loss_ce: 0.013770
2022-01-08 17:13:47,781 iteration 4879 : loss : 0.012684, loss_ce: 0.004282

 72%|████████████████████▊        | 287/400 [2:03:42<47:47, 25.38s/it]2022-01-08 17:13:49,194 iteration 4880 : loss : 0.018591, loss_ce: 0.008229
2022-01-08 17:13:50,520 iteration 4881 : loss : 0.015697, loss_ce: 0.006325
2022-01-08 17:13:51,817 iteration 4882 : loss : 0.015042, loss_ce: 0.006294
2022-01-08 17:13:53,215 iteration 4883 : loss : 0.029579, loss_ce: 0.012454
2022-01-08 17:13:54,635 iteration 4884 : loss : 0.016943, loss_ce: 0.005074
2022-01-08 17:13:55,918 iteration 4885 : loss : 0.013777, loss_ce: 0.005233
2022-01-08 17:13:57,288 iteration 4886 : loss : 0.022248, loss_ce: 0.005568
2022-01-08 17:13:58,604 iteration 4887 : loss : 0.013071, loss_ce: 0.004001
2022-01-08 17:14:00,002 iteration 4888 : loss : 0.029192, loss_ce: 0.008213
2022-01-08 17:14:01,382 iteration 4889 : loss : 0.027815, loss_ce: 0.015483
2022-01-08 17:14:02,719 iteration 4890 : loss : 0.019282, loss_ce: 0.009480
2022-01-08 17:14:03,989 iteration 4891 : loss : 0.013304, loss_ce: 0.005029
2022-01-08 17:14:05,403 iteration 4892 : loss : 0.017313, loss_ce: 0.007379
2022-01-08 17:14:06,782 iteration 4893 : loss : 0.019610, loss_ce: 0.008479
2022-01-08 17:14:08,145 iteration 4894 : loss : 0.015846, loss_ce: 0.007426
2022-01-08 17:14:09,497 iteration 4895 : loss : 0.033409, loss_ce: 0.007726
2022-01-08 17:14:10,829 iteration 4896 : loss : 0.020216, loss_ce: 0.005622

 72%|████████████████████▉        | 288/400 [2:04:05<46:04, 24.68s/it]2022-01-08 17:14:12,231 iteration 4897 : loss : 0.017169, loss_ce: 0.006738
2022-01-08 17:14:13,663 iteration 4898 : loss : 0.027424, loss_ce: 0.012527
2022-01-08 17:14:15,042 iteration 4899 : loss : 0.014973, loss_ce: 0.004061
2022-01-08 17:14:16,378 iteration 4900 : loss : 0.022852, loss_ce: 0.009314
2022-01-08 17:14:17,730 iteration 4901 : loss : 0.041549, loss_ce: 0.010336
2022-01-08 17:14:19,077 iteration 4902 : loss : 0.015596, loss_ce: 0.005388
2022-01-08 17:14:20,470 iteration 4903 : loss : 0.018661, loss_ce: 0.008724
2022-01-08 17:14:21,745 iteration 4904 : loss : 0.016831, loss_ce: 0.004866
2022-01-08 17:14:23,070 iteration 4905 : loss : 0.025248, loss_ce: 0.005960
2022-01-08 17:14:24,468 iteration 4906 : loss : 0.019919, loss_ce: 0.007762
2022-01-08 17:14:25,800 iteration 4907 : loss : 0.028455, loss_ce: 0.011014
2022-01-08 17:14:27,240 iteration 4908 : loss : 0.025815, loss_ce: 0.010988
2022-01-08 17:14:28,640 iteration 4909 : loss : 0.017113, loss_ce: 0.005553
2022-01-08 17:14:29,970 iteration 4910 : loss : 0.017287, loss_ce: 0.008750
2022-01-08 17:14:31,314 iteration 4911 : loss : 0.012978, loss_ce: 0.004578
2022-01-08 17:14:32,687 iteration 4912 : loss : 0.018877, loss_ce: 0.008307
2022-01-08 17:14:34,050 iteration 4913 : loss : 0.020067, loss_ce: 0.007706

 72%|████████████████████▉        | 289/400 [2:04:28<44:50, 24.24s/it]2022-01-08 17:14:35,516 iteration 4914 : loss : 0.020454, loss_ce: 0.007147
2022-01-08 17:14:36,852 iteration 4915 : loss : 0.018205, loss_ce: 0.006788
2022-01-08 17:14:38,200 iteration 4916 : loss : 0.014932, loss_ce: 0.004131
2022-01-08 17:14:39,576 iteration 4917 : loss : 0.013467, loss_ce: 0.004253
2022-01-08 17:14:40,972 iteration 4918 : loss : 0.023685, loss_ce: 0.009954
2022-01-08 17:14:42,491 iteration 4919 : loss : 0.030610, loss_ce: 0.013865
2022-01-08 17:14:43,852 iteration 4920 : loss : 0.013951, loss_ce: 0.005309
2022-01-08 17:14:45,187 iteration 4921 : loss : 0.018776, loss_ce: 0.010037
2022-01-08 17:14:46,497 iteration 4922 : loss : 0.014660, loss_ce: 0.003829
2022-01-08 17:14:47,908 iteration 4923 : loss : 0.019258, loss_ce: 0.006873
2022-01-08 17:14:49,352 iteration 4924 : loss : 0.030128, loss_ce: 0.014536
2022-01-08 17:14:50,749 iteration 4925 : loss : 0.029891, loss_ce: 0.009708
2022-01-08 17:14:52,178 iteration 4926 : loss : 0.026584, loss_ce: 0.016544
2022-01-08 17:14:53,537 iteration 4927 : loss : 0.017106, loss_ce: 0.005624
2022-01-08 17:14:54,967 iteration 4928 : loss : 0.034251, loss_ce: 0.013341
2022-01-08 17:14:56,422 iteration 4929 : loss : 0.026367, loss_ce: 0.011599
2022-01-08 17:14:56,423 Training Data Eval:
2022-01-08 17:15:03,274   Average segmentation loss on training set: 0.0124
2022-01-08 17:15:03,275 Validation Data Eval:
2022-01-08 17:15:05,642   Average segmentation loss on validation set: 0.0683
2022-01-08 17:15:07,026 iteration 4930 : loss : 0.016897, loss_ce: 0.005619

 72%|█████████████████████        | 290/400 [2:05:01<49:14, 26.86s/it]2022-01-08 17:15:08,441 iteration 4931 : loss : 0.018990, loss_ce: 0.008386
2022-01-08 17:15:09,847 iteration 4932 : loss : 0.019877, loss_ce: 0.010036
2022-01-08 17:15:11,163 iteration 4933 : loss : 0.014439, loss_ce: 0.006831
2022-01-08 17:15:12,595 iteration 4934 : loss : 0.022266, loss_ce: 0.007143
2022-01-08 17:15:13,969 iteration 4935 : loss : 0.018707, loss_ce: 0.006865
2022-01-08 17:15:15,368 iteration 4936 : loss : 0.023605, loss_ce: 0.008129
2022-01-08 17:15:16,753 iteration 4937 : loss : 0.014142, loss_ce: 0.005746
2022-01-08 17:15:18,187 iteration 4938 : loss : 0.029304, loss_ce: 0.011848
2022-01-08 17:15:19,614 iteration 4939 : loss : 0.024042, loss_ce: 0.008887
2022-01-08 17:15:20,977 iteration 4940 : loss : 0.020591, loss_ce: 0.008564
2022-01-08 17:15:22,370 iteration 4941 : loss : 0.026707, loss_ce: 0.012658
2022-01-08 17:15:23,762 iteration 4942 : loss : 0.018342, loss_ce: 0.005956
2022-01-08 17:15:25,235 iteration 4943 : loss : 0.032516, loss_ce: 0.007148
2022-01-08 17:15:26,618 iteration 4944 : loss : 0.019736, loss_ce: 0.006475
2022-01-08 17:15:28,041 iteration 4945 : loss : 0.019117, loss_ce: 0.007255
2022-01-08 17:15:29,482 iteration 4946 : loss : 0.024629, loss_ce: 0.006970
2022-01-08 17:15:30,847 iteration 4947 : loss : 0.020042, loss_ce: 0.006714

 73%|█████████████████████        | 291/400 [2:05:25<47:08, 25.95s/it]2022-01-08 17:15:32,307 iteration 4948 : loss : 0.024117, loss_ce: 0.009613
2022-01-08 17:15:33,666 iteration 4949 : loss : 0.028525, loss_ce: 0.010865
2022-01-08 17:15:35,090 iteration 4950 : loss : 0.019667, loss_ce: 0.007644
2022-01-08 17:15:36,497 iteration 4951 : loss : 0.022450, loss_ce: 0.006806
2022-01-08 17:15:37,900 iteration 4952 : loss : 0.014648, loss_ce: 0.007978
2022-01-08 17:15:39,320 iteration 4953 : loss : 0.024490, loss_ce: 0.009158
2022-01-08 17:15:40,679 iteration 4954 : loss : 0.016217, loss_ce: 0.005546
2022-01-08 17:15:42,002 iteration 4955 : loss : 0.020706, loss_ce: 0.006730
2022-01-08 17:15:43,368 iteration 4956 : loss : 0.024201, loss_ce: 0.008627
2022-01-08 17:15:44,657 iteration 4957 : loss : 0.016203, loss_ce: 0.006437
2022-01-08 17:15:46,044 iteration 4958 : loss : 0.020434, loss_ce: 0.010372
2022-01-08 17:15:47,429 iteration 4959 : loss : 0.026822, loss_ce: 0.010418
2022-01-08 17:15:48,739 iteration 4960 : loss : 0.018335, loss_ce: 0.006755
2022-01-08 17:15:50,127 iteration 4961 : loss : 0.016821, loss_ce: 0.007621
2022-01-08 17:15:51,449 iteration 4962 : loss : 0.021977, loss_ce: 0.005047
2022-01-08 17:15:52,800 iteration 4963 : loss : 0.015664, loss_ce: 0.005895
2022-01-08 17:15:54,224 iteration 4964 : loss : 0.022909, loss_ce: 0.007823

 73%|█████████████████████▏       | 292/400 [2:05:48<45:19, 25.18s/it]2022-01-08 17:15:55,723 iteration 4965 : loss : 0.024230, loss_ce: 0.009289
2022-01-08 17:15:57,159 iteration 4966 : loss : 0.031056, loss_ce: 0.014014
2022-01-08 17:15:58,551 iteration 4967 : loss : 0.019286, loss_ce: 0.008515
2022-01-08 17:15:59,962 iteration 4968 : loss : 0.021332, loss_ce: 0.010712
2022-01-08 17:16:01,448 iteration 4969 : loss : 0.036590, loss_ce: 0.010304
2022-01-08 17:16:02,788 iteration 4970 : loss : 0.015394, loss_ce: 0.006695
2022-01-08 17:16:04,144 iteration 4971 : loss : 0.017637, loss_ce: 0.009146
2022-01-08 17:16:05,557 iteration 4972 : loss : 0.023931, loss_ce: 0.010844
2022-01-08 17:16:06,948 iteration 4973 : loss : 0.018629, loss_ce: 0.006705
2022-01-08 17:16:08,451 iteration 4974 : loss : 0.020040, loss_ce: 0.006775
2022-01-08 17:16:09,819 iteration 4975 : loss : 0.014657, loss_ce: 0.003796
2022-01-08 17:16:11,139 iteration 4976 : loss : 0.014580, loss_ce: 0.005801
2022-01-08 17:16:12,548 iteration 4977 : loss : 0.029420, loss_ce: 0.006921
2022-01-08 17:16:13,917 iteration 4978 : loss : 0.028024, loss_ce: 0.006406
2022-01-08 17:16:15,295 iteration 4979 : loss : 0.019510, loss_ce: 0.006911
2022-01-08 17:16:16,684 iteration 4980 : loss : 0.019135, loss_ce: 0.005382
2022-01-08 17:16:18,056 iteration 4981 : loss : 0.017077, loss_ce: 0.005996

 73%|█████████████████████▏       | 293/400 [2:06:12<44:10, 24.78s/it]2022-01-08 17:16:19,471 iteration 4982 : loss : 0.019426, loss_ce: 0.009272
2022-01-08 17:16:20,828 iteration 4983 : loss : 0.018181, loss_ce: 0.006721
2022-01-08 17:16:22,298 iteration 4984 : loss : 0.018774, loss_ce: 0.006193
2022-01-08 17:16:23,608 iteration 4985 : loss : 0.012913, loss_ce: 0.003461
2022-01-08 17:16:25,103 iteration 4986 : loss : 0.029000, loss_ce: 0.014037
2022-01-08 17:16:26,432 iteration 4987 : loss : 0.019082, loss_ce: 0.005377
2022-01-08 17:16:27,827 iteration 4988 : loss : 0.019717, loss_ce: 0.005722
2022-01-08 17:16:29,258 iteration 4989 : loss : 0.022681, loss_ce: 0.007953
2022-01-08 17:16:30,722 iteration 4990 : loss : 0.024642, loss_ce: 0.012301
2022-01-08 17:16:32,116 iteration 4991 : loss : 0.020700, loss_ce: 0.006388
2022-01-08 17:16:33,416 iteration 4992 : loss : 0.015655, loss_ce: 0.007454
2022-01-08 17:16:34,772 iteration 4993 : loss : 0.018335, loss_ce: 0.006463
2022-01-08 17:16:36,099 iteration 4994 : loss : 0.019643, loss_ce: 0.006061
2022-01-08 17:16:37,442 iteration 4995 : loss : 0.017356, loss_ce: 0.007551
2022-01-08 17:16:38,873 iteration 4996 : loss : 0.023185, loss_ce: 0.007792
2022-01-08 17:16:40,181 iteration 4997 : loss : 0.015390, loss_ce: 0.004518
2022-01-08 17:16:41,504 iteration 4998 : loss : 0.015733, loss_ce: 0.006336

 74%|█████████████████████▎       | 294/400 [2:06:35<43:03, 24.38s/it]2022-01-08 17:16:42,897 iteration 4999 : loss : 0.016503, loss_ce: 0.006459
2022-01-08 17:16:44,253 iteration 5000 : loss : 0.016212, loss_ce: 0.006316
2022-01-08 17:16:45,615 iteration 5001 : loss : 0.015172, loss_ce: 0.006465
2022-01-08 17:16:46,970 iteration 5002 : loss : 0.014512, loss_ce: 0.004510
2022-01-08 17:16:48,369 iteration 5003 : loss : 0.034386, loss_ce: 0.005997
2022-01-08 17:16:49,736 iteration 5004 : loss : 0.019234, loss_ce: 0.007919
2022-01-08 17:16:51,109 iteration 5005 : loss : 0.022367, loss_ce: 0.009710
2022-01-08 17:16:52,540 iteration 5006 : loss : 0.018104, loss_ce: 0.006899
2022-01-08 17:16:53,950 iteration 5007 : loss : 0.030821, loss_ce: 0.017432
2022-01-08 17:16:55,368 iteration 5008 : loss : 0.038671, loss_ce: 0.014591
2022-01-08 17:16:56,784 iteration 5009 : loss : 0.017739, loss_ce: 0.004621
2022-01-08 17:16:58,190 iteration 5010 : loss : 0.022798, loss_ce: 0.007346
2022-01-08 17:16:59,548 iteration 5011 : loss : 0.016243, loss_ce: 0.007364
2022-01-08 17:17:00,940 iteration 5012 : loss : 0.020676, loss_ce: 0.008090
2022-01-08 17:17:02,261 iteration 5013 : loss : 0.017487, loss_ce: 0.007301
2022-01-08 17:17:03,631 iteration 5014 : loss : 0.027483, loss_ce: 0.010436
2022-01-08 17:17:03,632 Training Data Eval:
2022-01-08 17:17:10,466   Average segmentation loss on training set: 0.0126
2022-01-08 17:17:10,467 Validation Data Eval:
2022-01-08 17:17:12,834   Average segmentation loss on validation set: 0.0684
2022-01-08 17:17:14,208 iteration 5015 : loss : 0.019431, loss_ce: 0.006411

 74%|█████████████████████▍       | 295/400 [2:07:08<47:01, 26.87s/it]2022-01-08 17:17:15,639 iteration 5016 : loss : 0.018315, loss_ce: 0.008536
2022-01-08 17:17:16,992 iteration 5017 : loss : 0.016473, loss_ce: 0.006708
2022-01-08 17:17:18,358 iteration 5018 : loss : 0.022545, loss_ce: 0.011503
2022-01-08 17:17:19,749 iteration 5019 : loss : 0.018534, loss_ce: 0.006231
2022-01-08 17:17:21,148 iteration 5020 : loss : 0.028278, loss_ce: 0.008601
2022-01-08 17:17:22,567 iteration 5021 : loss : 0.020515, loss_ce: 0.009620
2022-01-08 17:17:23,895 iteration 5022 : loss : 0.018058, loss_ce: 0.005933
2022-01-08 17:17:25,272 iteration 5023 : loss : 0.032707, loss_ce: 0.008398
2022-01-08 17:17:26,738 iteration 5024 : loss : 0.032995, loss_ce: 0.008341
2022-01-08 17:17:28,184 iteration 5025 : loss : 0.029539, loss_ce: 0.004812
2022-01-08 17:17:29,573 iteration 5026 : loss : 0.020154, loss_ce: 0.007466
2022-01-08 17:17:30,918 iteration 5027 : loss : 0.016083, loss_ce: 0.006664
2022-01-08 17:17:32,275 iteration 5028 : loss : 0.025243, loss_ce: 0.009674
2022-01-08 17:17:33,733 iteration 5029 : loss : 0.053883, loss_ce: 0.008665
2022-01-08 17:17:35,113 iteration 5030 : loss : 0.020970, loss_ce: 0.010538
2022-01-08 17:17:36,555 iteration 5031 : loss : 0.023906, loss_ce: 0.011482
2022-01-08 17:17:37,941 iteration 5032 : loss : 0.022130, loss_ce: 0.010296

 74%|█████████████████████▍       | 296/400 [2:07:32<44:56, 25.93s/it]2022-01-08 17:17:39,490 iteration 5033 : loss : 0.022704, loss_ce: 0.008214
2022-01-08 17:17:40,853 iteration 5034 : loss : 0.023426, loss_ce: 0.007404
2022-01-08 17:17:42,205 iteration 5035 : loss : 0.025337, loss_ce: 0.009497
2022-01-08 17:17:43,556 iteration 5036 : loss : 0.023831, loss_ce: 0.007668
2022-01-08 17:17:44,939 iteration 5037 : loss : 0.026026, loss_ce: 0.010088
2022-01-08 17:17:46,290 iteration 5038 : loss : 0.023374, loss_ce: 0.005470
2022-01-08 17:17:47,749 iteration 5039 : loss : 0.020480, loss_ce: 0.009647
2022-01-08 17:17:49,137 iteration 5040 : loss : 0.016324, loss_ce: 0.005166
2022-01-08 17:17:50,580 iteration 5041 : loss : 0.017811, loss_ce: 0.006535
2022-01-08 17:17:51,925 iteration 5042 : loss : 0.016670, loss_ce: 0.006266
2022-01-08 17:17:53,305 iteration 5043 : loss : 0.016137, loss_ce: 0.006962
2022-01-08 17:17:54,689 iteration 5044 : loss : 0.034621, loss_ce: 0.017596
2022-01-08 17:17:56,121 iteration 5045 : loss : 0.023225, loss_ce: 0.009201
2022-01-08 17:17:57,523 iteration 5046 : loss : 0.024428, loss_ce: 0.007108
2022-01-08 17:17:58,890 iteration 5047 : loss : 0.028361, loss_ce: 0.008057
2022-01-08 17:18:00,241 iteration 5048 : loss : 0.016009, loss_ce: 0.006759
2022-01-08 17:18:01,599 iteration 5049 : loss : 0.015893, loss_ce: 0.006458

 74%|█████████████████████▌       | 297/400 [2:07:55<43:20, 25.25s/it]2022-01-08 17:18:03,051 iteration 5050 : loss : 0.026423, loss_ce: 0.007624
2022-01-08 17:18:04,416 iteration 5051 : loss : 0.022864, loss_ce: 0.009370
2022-01-08 17:18:05,788 iteration 5052 : loss : 0.018597, loss_ce: 0.008268
2022-01-08 17:18:07,150 iteration 5053 : loss : 0.015353, loss_ce: 0.006421
2022-01-08 17:18:08,533 iteration 5054 : loss : 0.014193, loss_ce: 0.004557
2022-01-08 17:18:09,894 iteration 5055 : loss : 0.017216, loss_ce: 0.005647
2022-01-08 17:18:11,239 iteration 5056 : loss : 0.037978, loss_ce: 0.009836
2022-01-08 17:18:12,664 iteration 5057 : loss : 0.025484, loss_ce: 0.013693
2022-01-08 17:18:14,108 iteration 5058 : loss : 0.032411, loss_ce: 0.014748
2022-01-08 17:18:15,377 iteration 5059 : loss : 0.016760, loss_ce: 0.004180
2022-01-08 17:18:16,752 iteration 5060 : loss : 0.034401, loss_ce: 0.008855
2022-01-08 17:18:18,156 iteration 5061 : loss : 0.016477, loss_ce: 0.006513
2022-01-08 17:18:19,551 iteration 5062 : loss : 0.026476, loss_ce: 0.009461
2022-01-08 17:18:20,986 iteration 5063 : loss : 0.020363, loss_ce: 0.008220
2022-01-08 17:18:22,331 iteration 5064 : loss : 0.016347, loss_ce: 0.006960
2022-01-08 17:18:23,680 iteration 5065 : loss : 0.019547, loss_ce: 0.007346
2022-01-08 17:18:25,065 iteration 5066 : loss : 0.018022, loss_ce: 0.008816

 74%|█████████████████████▌       | 298/400 [2:08:19<42:00, 24.71s/it]2022-01-08 17:18:26,589 iteration 5067 : loss : 0.020455, loss_ce: 0.007355
2022-01-08 17:18:27,991 iteration 5068 : loss : 0.030074, loss_ce: 0.011692
2022-01-08 17:18:29,392 iteration 5069 : loss : 0.024997, loss_ce: 0.008112
2022-01-08 17:18:30,757 iteration 5070 : loss : 0.017726, loss_ce: 0.004904
2022-01-08 17:18:32,202 iteration 5071 : loss : 0.018863, loss_ce: 0.007710
2022-01-08 17:18:33,472 iteration 5072 : loss : 0.016438, loss_ce: 0.005378
2022-01-08 17:18:34,838 iteration 5073 : loss : 0.021868, loss_ce: 0.010330
2022-01-08 17:18:36,250 iteration 5074 : loss : 0.027885, loss_ce: 0.007794
2022-01-08 17:18:37,628 iteration 5075 : loss : 0.015078, loss_ce: 0.005985
2022-01-08 17:18:39,057 iteration 5076 : loss : 0.020569, loss_ce: 0.009098
2022-01-08 17:18:40,410 iteration 5077 : loss : 0.015868, loss_ce: 0.005629
2022-01-08 17:18:41,798 iteration 5078 : loss : 0.014747, loss_ce: 0.003977
2022-01-08 17:18:43,149 iteration 5079 : loss : 0.016909, loss_ce: 0.006889
2022-01-08 17:18:44,537 iteration 5080 : loss : 0.020605, loss_ce: 0.006787
2022-01-08 17:18:45,951 iteration 5081 : loss : 0.029776, loss_ce: 0.016848
2022-01-08 17:18:47,389 iteration 5082 : loss : 0.026520, loss_ce: 0.013573
2022-01-08 17:18:48,796 iteration 5083 : loss : 0.019439, loss_ce: 0.005991

 75%|█████████████████████▋       | 299/400 [2:08:43<41:06, 24.42s/it]2022-01-08 17:18:50,208 iteration 5084 : loss : 0.015406, loss_ce: 0.005378
2022-01-08 17:18:51,588 iteration 5085 : loss : 0.019524, loss_ce: 0.006882
2022-01-08 17:18:52,934 iteration 5086 : loss : 0.019037, loss_ce: 0.008107
2022-01-08 17:18:54,359 iteration 5087 : loss : 0.030337, loss_ce: 0.013816
2022-01-08 17:18:55,758 iteration 5088 : loss : 0.020703, loss_ce: 0.007194
2022-01-08 17:18:57,094 iteration 5089 : loss : 0.017093, loss_ce: 0.006402
2022-01-08 17:18:58,442 iteration 5090 : loss : 0.029070, loss_ce: 0.011169
2022-01-08 17:18:59,914 iteration 5091 : loss : 0.034982, loss_ce: 0.014480
2022-01-08 17:19:01,298 iteration 5092 : loss : 0.014908, loss_ce: 0.007375
2022-01-08 17:19:02,640 iteration 5093 : loss : 0.017611, loss_ce: 0.008483
2022-01-08 17:19:03,961 iteration 5094 : loss : 0.014134, loss_ce: 0.005366
2022-01-08 17:19:05,378 iteration 5095 : loss : 0.023188, loss_ce: 0.009411
2022-01-08 17:19:06,713 iteration 5096 : loss : 0.020826, loss_ce: 0.006705
2022-01-08 17:19:08,051 iteration 5097 : loss : 0.018707, loss_ce: 0.008381
2022-01-08 17:19:09,444 iteration 5098 : loss : 0.018389, loss_ce: 0.005756
2022-01-08 17:19:10,809 iteration 5099 : loss : 0.014150, loss_ce: 0.004546
2022-01-08 17:19:10,809 Training Data Eval:
2022-01-08 17:19:17,648   Average segmentation loss on training set: 0.0119
2022-01-08 17:19:17,648 Validation Data Eval:
2022-01-08 17:19:20,008   Average segmentation loss on validation set: 0.0639
2022-01-08 17:19:21,380 iteration 5100 : loss : 0.015537, loss_ce: 0.007487

 75%|█████████████████████▊       | 300/400 [2:09:15<44:46, 26.87s/it]2022-01-08 17:19:22,828 iteration 5101 : loss : 0.016778, loss_ce: 0.007494
2022-01-08 17:19:24,172 iteration 5102 : loss : 0.022216, loss_ce: 0.010789
2022-01-08 17:19:25,534 iteration 5103 : loss : 0.019454, loss_ce: 0.008059
2022-01-08 17:19:26,975 iteration 5104 : loss : 0.024689, loss_ce: 0.010116
2022-01-08 17:19:28,300 iteration 5105 : loss : 0.016625, loss_ce: 0.005630
2022-01-08 17:19:29,746 iteration 5106 : loss : 0.023111, loss_ce: 0.008527
2022-01-08 17:19:31,072 iteration 5107 : loss : 0.015573, loss_ce: 0.005722
2022-01-08 17:19:32,472 iteration 5108 : loss : 0.026788, loss_ce: 0.008782
2022-01-08 17:19:33,853 iteration 5109 : loss : 0.021110, loss_ce: 0.005892
2022-01-08 17:19:35,222 iteration 5110 : loss : 0.020381, loss_ce: 0.009106
2022-01-08 17:19:36,627 iteration 5111 : loss : 0.014691, loss_ce: 0.004693
2022-01-08 17:19:37,957 iteration 5112 : loss : 0.016956, loss_ce: 0.005321
2022-01-08 17:19:39,391 iteration 5113 : loss : 0.033617, loss_ce: 0.005892
2022-01-08 17:19:40,750 iteration 5114 : loss : 0.017107, loss_ce: 0.008542
2022-01-08 17:19:42,092 iteration 5115 : loss : 0.019050, loss_ce: 0.004817
2022-01-08 17:19:43,436 iteration 5116 : loss : 0.013739, loss_ce: 0.005571
2022-01-08 17:19:44,868 iteration 5117 : loss : 0.020082, loss_ce: 0.009891

 75%|█████████████████████▊       | 301/400 [2:09:39<42:39, 25.86s/it]2022-01-08 17:19:46,312 iteration 5118 : loss : 0.013379, loss_ce: 0.005068
2022-01-08 17:19:47,702 iteration 5119 : loss : 0.020292, loss_ce: 0.006305
2022-01-08 17:19:49,046 iteration 5120 : loss : 0.023568, loss_ce: 0.008033
2022-01-08 17:19:50,422 iteration 5121 : loss : 0.017163, loss_ce: 0.007852
2022-01-08 17:19:51,756 iteration 5122 : loss : 0.024586, loss_ce: 0.009457
2022-01-08 17:19:53,124 iteration 5123 : loss : 0.031188, loss_ce: 0.008666
2022-01-08 17:19:54,522 iteration 5124 : loss : 0.029198, loss_ce: 0.018746
2022-01-08 17:19:55,814 iteration 5125 : loss : 0.017992, loss_ce: 0.008740
2022-01-08 17:19:57,134 iteration 5126 : loss : 0.019617, loss_ce: 0.006322
2022-01-08 17:19:58,547 iteration 5127 : loss : 0.028935, loss_ce: 0.009416
2022-01-08 17:19:59,899 iteration 5128 : loss : 0.016217, loss_ce: 0.007116
2022-01-08 17:20:01,293 iteration 5129 : loss : 0.030056, loss_ce: 0.009515
2022-01-08 17:20:02,669 iteration 5130 : loss : 0.018827, loss_ce: 0.006444
2022-01-08 17:20:03,967 iteration 5131 : loss : 0.012057, loss_ce: 0.004247
2022-01-08 17:20:05,331 iteration 5132 : loss : 0.019072, loss_ce: 0.007594
2022-01-08 17:20:06,665 iteration 5133 : loss : 0.019608, loss_ce: 0.005342
2022-01-08 17:20:07,985 iteration 5134 : loss : 0.016832, loss_ce: 0.006881

 76%|█████████████████████▉       | 302/400 [2:10:02<40:53, 25.03s/it]2022-01-08 17:20:09,557 iteration 5135 : loss : 0.028120, loss_ce: 0.014200
2022-01-08 17:20:10,930 iteration 5136 : loss : 0.027673, loss_ce: 0.010058
2022-01-08 17:20:12,351 iteration 5137 : loss : 0.023134, loss_ce: 0.007868
2022-01-08 17:20:13,691 iteration 5138 : loss : 0.018616, loss_ce: 0.008486
2022-01-08 17:20:15,067 iteration 5139 : loss : 0.014572, loss_ce: 0.005677
2022-01-08 17:20:16,528 iteration 5140 : loss : 0.016931, loss_ce: 0.007079
2022-01-08 17:20:17,864 iteration 5141 : loss : 0.019383, loss_ce: 0.006717
2022-01-08 17:20:19,250 iteration 5142 : loss : 0.029566, loss_ce: 0.009982
2022-01-08 17:20:20,555 iteration 5143 : loss : 0.016167, loss_ce: 0.006202
2022-01-08 17:20:21,955 iteration 5144 : loss : 0.019984, loss_ce: 0.010587
2022-01-08 17:20:23,246 iteration 5145 : loss : 0.013090, loss_ce: 0.004137
2022-01-08 17:20:24,690 iteration 5146 : loss : 0.025366, loss_ce: 0.011030
2022-01-08 17:20:26,131 iteration 5147 : loss : 0.016682, loss_ce: 0.006181
2022-01-08 17:20:27,489 iteration 5148 : loss : 0.016360, loss_ce: 0.007128
2022-01-08 17:20:28,844 iteration 5149 : loss : 0.023842, loss_ce: 0.006617
2022-01-08 17:20:30,203 iteration 5150 : loss : 0.019354, loss_ce: 0.007639
2022-01-08 17:20:31,582 iteration 5151 : loss : 0.041909, loss_ce: 0.007126

 76%|█████████████████████▉       | 303/400 [2:10:25<39:46, 24.60s/it]2022-01-08 17:20:32,969 iteration 5152 : loss : 0.018145, loss_ce: 0.004312
2022-01-08 17:20:34,250 iteration 5153 : loss : 0.012401, loss_ce: 0.004985
2022-01-08 17:20:35,685 iteration 5154 : loss : 0.019337, loss_ce: 0.007502
2022-01-08 17:20:37,001 iteration 5155 : loss : 0.011196, loss_ce: 0.003934
2022-01-08 17:20:38,354 iteration 5156 : loss : 0.016810, loss_ce: 0.006666
2022-01-08 17:20:39,663 iteration 5157 : loss : 0.012604, loss_ce: 0.004095
2022-01-08 17:20:41,012 iteration 5158 : loss : 0.018011, loss_ce: 0.006231
2022-01-08 17:20:42,434 iteration 5159 : loss : 0.019347, loss_ce: 0.006571
2022-01-08 17:20:43,749 iteration 5160 : loss : 0.012627, loss_ce: 0.004683
2022-01-08 17:20:45,107 iteration 5161 : loss : 0.023606, loss_ce: 0.012309
2022-01-08 17:20:46,426 iteration 5162 : loss : 0.015077, loss_ce: 0.006298
2022-01-08 17:20:47,807 iteration 5163 : loss : 0.015212, loss_ce: 0.005843
2022-01-08 17:20:49,199 iteration 5164 : loss : 0.019509, loss_ce: 0.009525
2022-01-08 17:20:50,504 iteration 5165 : loss : 0.015462, loss_ce: 0.004876
2022-01-08 17:20:51,868 iteration 5166 : loss : 0.016086, loss_ce: 0.006804
2022-01-08 17:20:53,247 iteration 5167 : loss : 0.022327, loss_ce: 0.007718
2022-01-08 17:20:54,669 iteration 5168 : loss : 0.019877, loss_ce: 0.006987

 76%|██████████████████████       | 304/400 [2:10:48<38:38, 24.15s/it]2022-01-08 17:20:56,211 iteration 5169 : loss : 0.044976, loss_ce: 0.019437
2022-01-08 17:20:57,534 iteration 5170 : loss : 0.018981, loss_ce: 0.005771
2022-01-08 17:20:58,965 iteration 5171 : loss : 0.016029, loss_ce: 0.006206
2022-01-08 17:21:00,269 iteration 5172 : loss : 0.014011, loss_ce: 0.003797
2022-01-08 17:21:01,522 iteration 5173 : loss : 0.012164, loss_ce: 0.005188
2022-01-08 17:21:02,960 iteration 5174 : loss : 0.021320, loss_ce: 0.007150
2022-01-08 17:21:04,297 iteration 5175 : loss : 0.014707, loss_ce: 0.006730
2022-01-08 17:21:05,795 iteration 5176 : loss : 0.017284, loss_ce: 0.005423
2022-01-08 17:21:07,132 iteration 5177 : loss : 0.022382, loss_ce: 0.009447
2022-01-08 17:21:08,485 iteration 5178 : loss : 0.013529, loss_ce: 0.004143
2022-01-08 17:21:09,906 iteration 5179 : loss : 0.018977, loss_ce: 0.005606
2022-01-08 17:21:11,276 iteration 5180 : loss : 0.019007, loss_ce: 0.007254
2022-01-08 17:21:12,608 iteration 5181 : loss : 0.012692, loss_ce: 0.002708
2022-01-08 17:21:14,016 iteration 5182 : loss : 0.019391, loss_ce: 0.007287
2022-01-08 17:21:15,363 iteration 5183 : loss : 0.032785, loss_ce: 0.015471
2022-01-08 17:21:16,696 iteration 5184 : loss : 0.017331, loss_ce: 0.006774
2022-01-08 17:21:16,697 Training Data Eval:
2022-01-08 17:21:23,552   Average segmentation loss on training set: 0.0103
2022-01-08 17:21:23,552 Validation Data Eval:
2022-01-08 17:21:25,913   Average segmentation loss on validation set: 0.0667
2022-01-08 17:21:27,271 iteration 5185 : loss : 0.017908, loss_ce: 0.006608

 76%|██████████████████████       | 305/400 [2:11:21<42:15, 26.69s/it]2022-01-08 17:21:28,721 iteration 5186 : loss : 0.017051, loss_ce: 0.008063
2022-01-08 17:21:30,042 iteration 5187 : loss : 0.015216, loss_ce: 0.006095
2022-01-08 17:21:31,369 iteration 5188 : loss : 0.016798, loss_ce: 0.007566
2022-01-08 17:21:32,707 iteration 5189 : loss : 0.014487, loss_ce: 0.006627
2022-01-08 17:21:34,027 iteration 5190 : loss : 0.018084, loss_ce: 0.008169
2022-01-08 17:21:35,441 iteration 5191 : loss : 0.029520, loss_ce: 0.009902
2022-01-08 17:21:36,839 iteration 5192 : loss : 0.019109, loss_ce: 0.007276
2022-01-08 17:21:38,161 iteration 5193 : loss : 0.010945, loss_ce: 0.003680
2022-01-08 17:21:39,561 iteration 5194 : loss : 0.022278, loss_ce: 0.009153
2022-01-08 17:21:40,902 iteration 5195 : loss : 0.014804, loss_ce: 0.004874
2022-01-08 17:21:42,178 iteration 5196 : loss : 0.012289, loss_ce: 0.003116
2022-01-08 17:21:43,490 iteration 5197 : loss : 0.014486, loss_ce: 0.004759
2022-01-08 17:21:44,814 iteration 5198 : loss : 0.014529, loss_ce: 0.007228
2022-01-08 17:21:46,204 iteration 5199 : loss : 0.014965, loss_ce: 0.004748
2022-01-08 17:21:47,566 iteration 5200 : loss : 0.019127, loss_ce: 0.005430
2022-01-08 17:21:48,946 iteration 5201 : loss : 0.027790, loss_ce: 0.013245
2022-01-08 17:21:50,392 iteration 5202 : loss : 0.018118, loss_ce: 0.008273

 76%|██████████████████████▏      | 306/400 [2:11:44<40:07, 25.61s/it]2022-01-08 17:21:51,782 iteration 5203 : loss : 0.013370, loss_ce: 0.004802
2022-01-08 17:21:53,129 iteration 5204 : loss : 0.022213, loss_ce: 0.009419
2022-01-08 17:21:54,618 iteration 5205 : loss : 0.026225, loss_ce: 0.010373
2022-01-08 17:21:55,983 iteration 5206 : loss : 0.015488, loss_ce: 0.005479
2022-01-08 17:21:57,355 iteration 5207 : loss : 0.017334, loss_ce: 0.007451
2022-01-08 17:21:58,795 iteration 5208 : loss : 0.022673, loss_ce: 0.009244
2022-01-08 17:22:00,121 iteration 5209 : loss : 0.017099, loss_ce: 0.006831
2022-01-08 17:22:01,535 iteration 5210 : loss : 0.019867, loss_ce: 0.007066
2022-01-08 17:22:02,953 iteration 5211 : loss : 0.016651, loss_ce: 0.006514
2022-01-08 17:22:04,329 iteration 5212 : loss : 0.022869, loss_ce: 0.007900
2022-01-08 17:22:05,598 iteration 5213 : loss : 0.013063, loss_ce: 0.004901
2022-01-08 17:22:07,058 iteration 5214 : loss : 0.032107, loss_ce: 0.016999
2022-01-08 17:22:08,458 iteration 5215 : loss : 0.021073, loss_ce: 0.007881
2022-01-08 17:22:09,885 iteration 5216 : loss : 0.017731, loss_ce: 0.005565
2022-01-08 17:22:11,340 iteration 5217 : loss : 0.017305, loss_ce: 0.006275
2022-01-08 17:22:12,674 iteration 5218 : loss : 0.020332, loss_ce: 0.003614
2022-01-08 17:22:14,135 iteration 5219 : loss : 0.017960, loss_ce: 0.006482

 77%|██████████████████████▎      | 307/400 [2:12:08<38:50, 25.05s/it]2022-01-08 17:22:15,558 iteration 5220 : loss : 0.023889, loss_ce: 0.006795
2022-01-08 17:22:16,922 iteration 5221 : loss : 0.017999, loss_ce: 0.005647
2022-01-08 17:22:18,240 iteration 5222 : loss : 0.013429, loss_ce: 0.005080
2022-01-08 17:22:19,653 iteration 5223 : loss : 0.015933, loss_ce: 0.006161
2022-01-08 17:22:21,014 iteration 5224 : loss : 0.019918, loss_ce: 0.007511
2022-01-08 17:22:22,437 iteration 5225 : loss : 0.015556, loss_ce: 0.004210
2022-01-08 17:22:23,797 iteration 5226 : loss : 0.017289, loss_ce: 0.007948
2022-01-08 17:22:25,254 iteration 5227 : loss : 0.019330, loss_ce: 0.008846
2022-01-08 17:22:26,596 iteration 5228 : loss : 0.014931, loss_ce: 0.004783
2022-01-08 17:22:28,082 iteration 5229 : loss : 0.021855, loss_ce: 0.008701
2022-01-08 17:22:29,351 iteration 5230 : loss : 0.012159, loss_ce: 0.005293
2022-01-08 17:22:30,741 iteration 5231 : loss : 0.025113, loss_ce: 0.009532
2022-01-08 17:22:32,122 iteration 5232 : loss : 0.018979, loss_ce: 0.005365
2022-01-08 17:22:33,531 iteration 5233 : loss : 0.016149, loss_ce: 0.006350
2022-01-08 17:22:34,872 iteration 5234 : loss : 0.014889, loss_ce: 0.006223
2022-01-08 17:22:36,253 iteration 5235 : loss : 0.015275, loss_ce: 0.005344
2022-01-08 17:22:37,668 iteration 5236 : loss : 0.017229, loss_ce: 0.006018

 77%|██████████████████████▎      | 308/400 [2:12:31<37:42, 24.60s/it]2022-01-08 17:22:38,984 iteration 5237 : loss : 0.012523, loss_ce: 0.005209
2022-01-08 17:22:40,385 iteration 5238 : loss : 0.014733, loss_ce: 0.006076
2022-01-08 17:22:41,773 iteration 5239 : loss : 0.018338, loss_ce: 0.005669
2022-01-08 17:22:43,188 iteration 5240 : loss : 0.171858, loss_ce: 0.003156
2022-01-08 17:22:44,530 iteration 5241 : loss : 0.014590, loss_ce: 0.006263
2022-01-08 17:22:45,904 iteration 5242 : loss : 0.022806, loss_ce: 0.010421
2022-01-08 17:22:47,358 iteration 5243 : loss : 0.017704, loss_ce: 0.005344
2022-01-08 17:22:48,770 iteration 5244 : loss : 0.014465, loss_ce: 0.005424
2022-01-08 17:22:50,159 iteration 5245 : loss : 0.021048, loss_ce: 0.007051
2022-01-08 17:22:51,559 iteration 5246 : loss : 0.029630, loss_ce: 0.008143
2022-01-08 17:22:52,863 iteration 5247 : loss : 0.012788, loss_ce: 0.005088
2022-01-08 17:22:54,273 iteration 5248 : loss : 0.015195, loss_ce: 0.004884
2022-01-08 17:22:55,728 iteration 5249 : loss : 0.025000, loss_ce: 0.008725
2022-01-08 17:22:57,139 iteration 5250 : loss : 0.021003, loss_ce: 0.010092
2022-01-08 17:22:58,445 iteration 5251 : loss : 0.014468, loss_ce: 0.004853
2022-01-08 17:22:59,826 iteration 5252 : loss : 0.014780, loss_ce: 0.006143
2022-01-08 17:23:01,230 iteration 5253 : loss : 0.027923, loss_ce: 0.007604

 77%|██████████████████████▍      | 309/400 [2:12:55<36:50, 24.29s/it]2022-01-08 17:23:02,661 iteration 5254 : loss : 0.011704, loss_ce: 0.004022
2022-01-08 17:23:04,035 iteration 5255 : loss : 0.015729, loss_ce: 0.008168
2022-01-08 17:23:05,348 iteration 5256 : loss : 0.012607, loss_ce: 0.005296
2022-01-08 17:23:06,728 iteration 5257 : loss : 0.018091, loss_ce: 0.007296
2022-01-08 17:23:08,144 iteration 5258 : loss : 0.017391, loss_ce: 0.005359
2022-01-08 17:23:09,470 iteration 5259 : loss : 0.017680, loss_ce: 0.004463
2022-01-08 17:23:10,858 iteration 5260 : loss : 0.013454, loss_ce: 0.005128
2022-01-08 17:23:12,252 iteration 5261 : loss : 0.024815, loss_ce: 0.009723
2022-01-08 17:23:13,632 iteration 5262 : loss : 0.012545, loss_ce: 0.005114
2022-01-08 17:23:15,017 iteration 5263 : loss : 0.028493, loss_ce: 0.013781
2022-01-08 17:23:16,340 iteration 5264 : loss : 0.012481, loss_ce: 0.005185
2022-01-08 17:23:17,750 iteration 5265 : loss : 0.017543, loss_ce: 0.006703
2022-01-08 17:23:19,210 iteration 5266 : loss : 0.019360, loss_ce: 0.006610
2022-01-08 17:23:20,584 iteration 5267 : loss : 0.022489, loss_ce: 0.006820
2022-01-08 17:23:21,975 iteration 5268 : loss : 0.025004, loss_ce: 0.006854
2022-01-08 17:23:23,455 iteration 5269 : loss : 0.016939, loss_ce: 0.004820
2022-01-08 17:23:23,455 Training Data Eval:
2022-01-08 17:23:30,277   Average segmentation loss on training set: 0.0104
2022-01-08 17:23:30,278 Validation Data Eval:
2022-01-08 17:23:32,638   Average segmentation loss on validation set: 0.0733
2022-01-08 17:23:34,008 iteration 5270 : loss : 0.016339, loss_ce: 0.007935

 78%|██████████████████████▍      | 310/400 [2:13:28<40:14, 26.83s/it]2022-01-08 17:23:35,406 iteration 5271 : loss : 0.016709, loss_ce: 0.007133
2022-01-08 17:23:36,801 iteration 5272 : loss : 0.026041, loss_ce: 0.013254
2022-01-08 17:23:38,144 iteration 5273 : loss : 0.013701, loss_ce: 0.003922
2022-01-08 17:23:39,498 iteration 5274 : loss : 0.016785, loss_ce: 0.007468
2022-01-08 17:23:40,796 iteration 5275 : loss : 0.013230, loss_ce: 0.005833
2022-01-08 17:23:42,188 iteration 5276 : loss : 0.019191, loss_ce: 0.007975
2022-01-08 17:23:43,563 iteration 5277 : loss : 0.015062, loss_ce: 0.005265
2022-01-08 17:23:44,853 iteration 5278 : loss : 0.013298, loss_ce: 0.005355
2022-01-08 17:23:46,224 iteration 5279 : loss : 0.013836, loss_ce: 0.006010
2022-01-08 17:23:47,723 iteration 5280 : loss : 0.018301, loss_ce: 0.006428
2022-01-08 17:23:49,079 iteration 5281 : loss : 0.014291, loss_ce: 0.004615
2022-01-08 17:23:50,389 iteration 5282 : loss : 0.012304, loss_ce: 0.003710
2022-01-08 17:23:51,768 iteration 5283 : loss : 0.026355, loss_ce: 0.009361
2022-01-08 17:23:53,160 iteration 5284 : loss : 0.020503, loss_ce: 0.005188
2022-01-08 17:23:54,526 iteration 5285 : loss : 0.014034, loss_ce: 0.005842
2022-01-08 17:23:55,818 iteration 5286 : loss : 0.012789, loss_ce: 0.005286
2022-01-08 17:23:57,174 iteration 5287 : loss : 0.015316, loss_ce: 0.003322

 78%|██████████████████████▌      | 311/400 [2:13:51<38:10, 25.73s/it]2022-01-08 17:23:58,632 iteration 5288 : loss : 0.019568, loss_ce: 0.007658
2022-01-08 17:24:00,038 iteration 5289 : loss : 0.018273, loss_ce: 0.006251
2022-01-08 17:24:01,400 iteration 5290 : loss : 0.019886, loss_ce: 0.005208
2022-01-08 17:24:02,748 iteration 5291 : loss : 0.025699, loss_ce: 0.010797
2022-01-08 17:24:04,191 iteration 5292 : loss : 0.016393, loss_ce: 0.005933
2022-01-08 17:24:05,581 iteration 5293 : loss : 0.015144, loss_ce: 0.006277
2022-01-08 17:24:06,996 iteration 5294 : loss : 0.017681, loss_ce: 0.006820
2022-01-08 17:24:08,461 iteration 5295 : loss : 0.029094, loss_ce: 0.009546
2022-01-08 17:24:09,878 iteration 5296 : loss : 0.020646, loss_ce: 0.005564
2022-01-08 17:24:11,300 iteration 5297 : loss : 0.012969, loss_ce: 0.004025
2022-01-08 17:24:12,722 iteration 5298 : loss : 0.022859, loss_ce: 0.008780
2022-01-08 17:24:14,138 iteration 5299 : loss : 0.015451, loss_ce: 0.005453
2022-01-08 17:24:15,568 iteration 5300 : loss : 0.025118, loss_ce: 0.008163
2022-01-08 17:24:16,883 iteration 5301 : loss : 0.015100, loss_ce: 0.005447
2022-01-08 17:24:18,205 iteration 5302 : loss : 0.014092, loss_ce: 0.006685
2022-01-08 17:24:19,534 iteration 5303 : loss : 0.015151, loss_ce: 0.005745
2022-01-08 17:24:20,842 iteration 5304 : loss : 0.014782, loss_ce: 0.005458

 78%|██████████████████████▌      | 312/400 [2:14:15<36:50, 25.12s/it]2022-01-08 17:24:22,295 iteration 5305 : loss : 0.022059, loss_ce: 0.008759
2022-01-08 17:24:23,764 iteration 5306 : loss : 0.026936, loss_ce: 0.011255
2022-01-08 17:24:25,250 iteration 5307 : loss : 0.022331, loss_ce: 0.007575
2022-01-08 17:24:26,702 iteration 5308 : loss : 0.018917, loss_ce: 0.007306
2022-01-08 17:24:28,146 iteration 5309 : loss : 0.026740, loss_ce: 0.013182
2022-01-08 17:24:29,504 iteration 5310 : loss : 0.018015, loss_ce: 0.008208
2022-01-08 17:24:30,841 iteration 5311 : loss : 0.023366, loss_ce: 0.007002
2022-01-08 17:24:32,276 iteration 5312 : loss : 0.027462, loss_ce: 0.013310
2022-01-08 17:24:33,756 iteration 5313 : loss : 0.024881, loss_ce: 0.008549
2022-01-08 17:24:35,151 iteration 5314 : loss : 0.016243, loss_ce: 0.006033
2022-01-08 17:24:36,596 iteration 5315 : loss : 0.031049, loss_ce: 0.007648
2022-01-08 17:24:38,026 iteration 5316 : loss : 0.016032, loss_ce: 0.005993
2022-01-08 17:24:39,403 iteration 5317 : loss : 0.015308, loss_ce: 0.007202
2022-01-08 17:24:40,750 iteration 5318 : loss : 0.016046, loss_ce: 0.006170
2022-01-08 17:24:42,188 iteration 5319 : loss : 0.019897, loss_ce: 0.007901
2022-01-08 17:24:43,606 iteration 5320 : loss : 0.020335, loss_ce: 0.008679
2022-01-08 17:24:45,052 iteration 5321 : loss : 0.043833, loss_ce: 0.024711

 78%|██████████████████████▋      | 313/400 [2:14:39<36:01, 24.84s/it]2022-01-08 17:24:46,422 iteration 5322 : loss : 0.014875, loss_ce: 0.006772
2022-01-08 17:24:47,817 iteration 5323 : loss : 0.023038, loss_ce: 0.009464
2022-01-08 17:24:49,175 iteration 5324 : loss : 0.016111, loss_ce: 0.005602
2022-01-08 17:24:50,518 iteration 5325 : loss : 0.030671, loss_ce: 0.006563
2022-01-08 17:24:51,927 iteration 5326 : loss : 0.020729, loss_ce: 0.006933
2022-01-08 17:24:53,266 iteration 5327 : loss : 0.016126, loss_ce: 0.005435
2022-01-08 17:24:54,623 iteration 5328 : loss : 0.017415, loss_ce: 0.008534
2022-01-08 17:24:56,048 iteration 5329 : loss : 0.022277, loss_ce: 0.007886
2022-01-08 17:24:57,450 iteration 5330 : loss : 0.019364, loss_ce: 0.006755
2022-01-08 17:24:58,825 iteration 5331 : loss : 0.014679, loss_ce: 0.004694
2022-01-08 17:25:00,208 iteration 5332 : loss : 0.024965, loss_ce: 0.007770
2022-01-08 17:25:01,624 iteration 5333 : loss : 0.015854, loss_ce: 0.007027
2022-01-08 17:25:03,022 iteration 5334 : loss : 0.029789, loss_ce: 0.012827
2022-01-08 17:25:04,441 iteration 5335 : loss : 0.020853, loss_ce: 0.006613
2022-01-08 17:25:05,833 iteration 5336 : loss : 0.014274, loss_ce: 0.005153
2022-01-08 17:25:07,177 iteration 5337 : loss : 0.015806, loss_ce: 0.006120
2022-01-08 17:25:08,521 iteration 5338 : loss : 0.017026, loss_ce: 0.007122

 78%|██████████████████████▊      | 314/400 [2:15:02<35:00, 24.43s/it]2022-01-08 17:25:10,106 iteration 5339 : loss : 0.020701, loss_ce: 0.008647
2022-01-08 17:25:11,542 iteration 5340 : loss : 0.026801, loss_ce: 0.015881
2022-01-08 17:25:12,948 iteration 5341 : loss : 0.027623, loss_ce: 0.006707
2022-01-08 17:25:14,343 iteration 5342 : loss : 0.015839, loss_ce: 0.007859
2022-01-08 17:25:15,729 iteration 5343 : loss : 0.014043, loss_ce: 0.004426
2022-01-08 17:25:17,127 iteration 5344 : loss : 0.021563, loss_ce: 0.006771
2022-01-08 17:25:18,497 iteration 5345 : loss : 0.016860, loss_ce: 0.005727
2022-01-08 17:25:19,920 iteration 5346 : loss : 0.017497, loss_ce: 0.005310
2022-01-08 17:25:21,342 iteration 5347 : loss : 0.015811, loss_ce: 0.004747
2022-01-08 17:25:22,780 iteration 5348 : loss : 0.017295, loss_ce: 0.004255
2022-01-08 17:25:24,173 iteration 5349 : loss : 0.023535, loss_ce: 0.007976
2022-01-08 17:25:25,486 iteration 5350 : loss : 0.014808, loss_ce: 0.006176
2022-01-08 17:25:26,810 iteration 5351 : loss : 0.021143, loss_ce: 0.008435
2022-01-08 17:25:28,232 iteration 5352 : loss : 0.019473, loss_ce: 0.007316
2022-01-08 17:25:29,660 iteration 5353 : loss : 0.011739, loss_ce: 0.004010
2022-01-08 17:25:31,013 iteration 5354 : loss : 0.018547, loss_ce: 0.008416
2022-01-08 17:25:31,013 Training Data Eval:
2022-01-08 17:25:37,873   Average segmentation loss on training set: 0.0115
2022-01-08 17:25:37,873 Validation Data Eval:
2022-01-08 17:25:40,242   Average segmentation loss on validation set: 0.0744
2022-01-08 17:25:41,558 iteration 5355 : loss : 0.017121, loss_ce: 0.006137

 79%|██████████████████████▊      | 315/400 [2:15:35<38:16, 27.01s/it]2022-01-08 17:25:43,008 iteration 5356 : loss : 0.017917, loss_ce: 0.008869
2022-01-08 17:25:44,324 iteration 5357 : loss : 0.016559, loss_ce: 0.003725
2022-01-08 17:25:45,832 iteration 5358 : loss : 0.028609, loss_ce: 0.012477
2022-01-08 17:25:47,139 iteration 5359 : loss : 0.015586, loss_ce: 0.006094
2022-01-08 17:25:48,536 iteration 5360 : loss : 0.018677, loss_ce: 0.007519
2022-01-08 17:25:49,933 iteration 5361 : loss : 0.022165, loss_ce: 0.009176
2022-01-08 17:25:51,344 iteration 5362 : loss : 0.032301, loss_ce: 0.012443
2022-01-08 17:25:52,729 iteration 5363 : loss : 0.029782, loss_ce: 0.011233
2022-01-08 17:25:54,115 iteration 5364 : loss : 0.024009, loss_ce: 0.004420
2022-01-08 17:25:55,478 iteration 5365 : loss : 0.018100, loss_ce: 0.006934
2022-01-08 17:25:56,874 iteration 5366 : loss : 0.021128, loss_ce: 0.007695
2022-01-08 17:25:58,301 iteration 5367 : loss : 0.014923, loss_ce: 0.005879
2022-01-08 17:25:59,663 iteration 5368 : loss : 0.013673, loss_ce: 0.006393
2022-01-08 17:26:01,058 iteration 5369 : loss : 0.013989, loss_ce: 0.005005
2022-01-08 17:26:02,426 iteration 5370 : loss : 0.013473, loss_ce: 0.005101
2022-01-08 17:26:03,818 iteration 5371 : loss : 0.033436, loss_ce: 0.016498
2022-01-08 17:26:05,174 iteration 5372 : loss : 0.017861, loss_ce: 0.005682

 79%|██████████████████████▉      | 316/400 [2:15:59<36:23, 25.99s/it]2022-01-08 17:26:06,617 iteration 5373 : loss : 0.018189, loss_ce: 0.009169
2022-01-08 17:26:07,961 iteration 5374 : loss : 0.017685, loss_ce: 0.007595
2022-01-08 17:26:09,360 iteration 5375 : loss : 0.013505, loss_ce: 0.004453
2022-01-08 17:26:10,718 iteration 5376 : loss : 0.017180, loss_ce: 0.005873
2022-01-08 17:26:12,058 iteration 5377 : loss : 0.013746, loss_ce: 0.004278
2022-01-08 17:26:13,440 iteration 5378 : loss : 0.017744, loss_ce: 0.005888
2022-01-08 17:26:14,756 iteration 5379 : loss : 0.012446, loss_ce: 0.004500
2022-01-08 17:26:16,131 iteration 5380 : loss : 0.018687, loss_ce: 0.007394
2022-01-08 17:26:17,480 iteration 5381 : loss : 0.017878, loss_ce: 0.008171
2022-01-08 17:26:18,875 iteration 5382 : loss : 0.021565, loss_ce: 0.006407
2022-01-08 17:26:20,334 iteration 5383 : loss : 0.020841, loss_ce: 0.010086
2022-01-08 17:26:21,865 iteration 5384 : loss : 0.016755, loss_ce: 0.006519
2022-01-08 17:26:23,224 iteration 5385 : loss : 0.016857, loss_ce: 0.006372
2022-01-08 17:26:24,525 iteration 5386 : loss : 0.012061, loss_ce: 0.004059
2022-01-08 17:26:25,874 iteration 5387 : loss : 0.020020, loss_ce: 0.009133
2022-01-08 17:26:27,294 iteration 5388 : loss : 0.016447, loss_ce: 0.005135
2022-01-08 17:26:28,784 iteration 5389 : loss : 0.035910, loss_ce: 0.014705

 79%|██████████████████████▉      | 317/400 [2:16:23<34:58, 25.28s/it]2022-01-08 17:26:30,205 iteration 5390 : loss : 0.022815, loss_ce: 0.007360
2022-01-08 17:26:31,627 iteration 5391 : loss : 0.020321, loss_ce: 0.006501
2022-01-08 17:26:33,065 iteration 5392 : loss : 0.021365, loss_ce: 0.011111
2022-01-08 17:26:34,450 iteration 5393 : loss : 0.022677, loss_ce: 0.008828
2022-01-08 17:26:35,803 iteration 5394 : loss : 0.016259, loss_ce: 0.007527
2022-01-08 17:26:37,207 iteration 5395 : loss : 0.018677, loss_ce: 0.005551
2022-01-08 17:26:38,541 iteration 5396 : loss : 0.017010, loss_ce: 0.008025
2022-01-08 17:26:39,978 iteration 5397 : loss : 0.019500, loss_ce: 0.006382
2022-01-08 17:26:41,369 iteration 5398 : loss : 0.020412, loss_ce: 0.009125
2022-01-08 17:26:42,683 iteration 5399 : loss : 0.024946, loss_ce: 0.007129
2022-01-08 17:26:44,146 iteration 5400 : loss : 0.027450, loss_ce: 0.007490
2022-01-08 17:26:45,559 iteration 5401 : loss : 0.025355, loss_ce: 0.011567
2022-01-08 17:26:46,950 iteration 5402 : loss : 0.017877, loss_ce: 0.006199
2022-01-08 17:26:48,303 iteration 5403 : loss : 0.019441, loss_ce: 0.008178
2022-01-08 17:26:49,640 iteration 5404 : loss : 0.019470, loss_ce: 0.005223
2022-01-08 17:26:50,992 iteration 5405 : loss : 0.017683, loss_ce: 0.006729
2022-01-08 17:26:52,412 iteration 5406 : loss : 0.017021, loss_ce: 0.004831

 80%|███████████████████████      | 318/400 [2:16:46<33:51, 24.78s/it]2022-01-08 17:26:53,882 iteration 5407 : loss : 0.022789, loss_ce: 0.006992
2022-01-08 17:26:55,265 iteration 5408 : loss : 0.020358, loss_ce: 0.006299
2022-01-08 17:26:56,723 iteration 5409 : loss : 0.018171, loss_ce: 0.007704
2022-01-08 17:26:58,069 iteration 5410 : loss : 0.021459, loss_ce: 0.009945
2022-01-08 17:26:59,445 iteration 5411 : loss : 0.017081, loss_ce: 0.006784
2022-01-08 17:27:00,837 iteration 5412 : loss : 0.017838, loss_ce: 0.008507
2022-01-08 17:27:02,192 iteration 5413 : loss : 0.019942, loss_ce: 0.009549
2022-01-08 17:27:03,582 iteration 5414 : loss : 0.015868, loss_ce: 0.005918
2022-01-08 17:27:05,045 iteration 5415 : loss : 0.027693, loss_ce: 0.012306
2022-01-08 17:27:06,369 iteration 5416 : loss : 0.011992, loss_ce: 0.003862
2022-01-08 17:27:07,780 iteration 5417 : loss : 0.016135, loss_ce: 0.005300
2022-01-08 17:27:09,143 iteration 5418 : loss : 0.021250, loss_ce: 0.008673
2022-01-08 17:27:10,550 iteration 5419 : loss : 0.019293, loss_ce: 0.005021
2022-01-08 17:27:11,994 iteration 5420 : loss : 0.021511, loss_ce: 0.008037
2022-01-08 17:27:13,399 iteration 5421 : loss : 0.017870, loss_ce: 0.008494
2022-01-08 17:27:14,666 iteration 5422 : loss : 0.011714, loss_ce: 0.004773
2022-01-08 17:27:16,073 iteration 5423 : loss : 0.027508, loss_ce: 0.006751

 80%|███████████████████████▏     | 319/400 [2:17:10<32:59, 24.44s/it]2022-01-08 17:27:17,567 iteration 5424 : loss : 0.015844, loss_ce: 0.005339
2022-01-08 17:27:18,911 iteration 5425 : loss : 0.017970, loss_ce: 0.005910
2022-01-08 17:27:20,282 iteration 5426 : loss : 0.018262, loss_ce: 0.004864
2022-01-08 17:27:21,573 iteration 5427 : loss : 0.018838, loss_ce: 0.007129
2022-01-08 17:27:22,918 iteration 5428 : loss : 0.017440, loss_ce: 0.007100
2022-01-08 17:27:24,308 iteration 5429 : loss : 0.014972, loss_ce: 0.005700
2022-01-08 17:27:25,689 iteration 5430 : loss : 0.016201, loss_ce: 0.007118
2022-01-08 17:27:27,010 iteration 5431 : loss : 0.016156, loss_ce: 0.005897
2022-01-08 17:27:28,454 iteration 5432 : loss : 0.017269, loss_ce: 0.007238
2022-01-08 17:27:29,883 iteration 5433 : loss : 0.018802, loss_ce: 0.007458
2022-01-08 17:27:31,215 iteration 5434 : loss : 0.016336, loss_ce: 0.006722
2022-01-08 17:27:32,658 iteration 5435 : loss : 0.017116, loss_ce: 0.007127
2022-01-08 17:27:34,058 iteration 5436 : loss : 0.013850, loss_ce: 0.005181
2022-01-08 17:27:35,482 iteration 5437 : loss : 0.029438, loss_ce: 0.006203
2022-01-08 17:27:36,907 iteration 5438 : loss : 0.015703, loss_ce: 0.006642
2022-01-08 17:27:38,269 iteration 5439 : loss : 0.017196, loss_ce: 0.007800
2022-01-08 17:27:38,270 Training Data Eval:
2022-01-08 17:27:45,092   Average segmentation loss on training set: 0.0099
2022-01-08 17:27:45,092 Validation Data Eval:
2022-01-08 17:27:47,452   Average segmentation loss on validation set: 0.0899
2022-01-08 17:27:48,776 iteration 5440 : loss : 0.018114, loss_ce: 0.005489

 80%|███████████████████████▏     | 320/400 [2:17:43<35:53, 26.92s/it]2022-01-08 17:27:50,185 iteration 5441 : loss : 0.013976, loss_ce: 0.005083
2022-01-08 17:27:51,509 iteration 5442 : loss : 0.014671, loss_ce: 0.005008
2022-01-08 17:27:52,869 iteration 5443 : loss : 0.015090, loss_ce: 0.004869
2022-01-08 17:27:54,163 iteration 5444 : loss : 0.012799, loss_ce: 0.003867
2022-01-08 17:27:55,549 iteration 5445 : loss : 0.017095, loss_ce: 0.005965
2022-01-08 17:27:56,877 iteration 5446 : loss : 0.027804, loss_ce: 0.013071
2022-01-08 17:27:58,333 iteration 5447 : loss : 0.025096, loss_ce: 0.007800
2022-01-08 17:27:59,658 iteration 5448 : loss : 0.013760, loss_ce: 0.005558
2022-01-08 17:28:01,043 iteration 5449 : loss : 0.021880, loss_ce: 0.012611
2022-01-08 17:28:02,415 iteration 5450 : loss : 0.024596, loss_ce: 0.013915
2022-01-08 17:28:03,730 iteration 5451 : loss : 0.016351, loss_ce: 0.005599
2022-01-08 17:28:05,113 iteration 5452 : loss : 0.021266, loss_ce: 0.008388
2022-01-08 17:28:06,442 iteration 5453 : loss : 0.016461, loss_ce: 0.007087
2022-01-08 17:28:07,866 iteration 5454 : loss : 0.018247, loss_ce: 0.009863
2022-01-08 17:28:09,264 iteration 5455 : loss : 0.017903, loss_ce: 0.006030
2022-01-08 17:28:10,645 iteration 5456 : loss : 0.015237, loss_ce: 0.003808
2022-01-08 17:28:11,975 iteration 5457 : loss : 0.018387, loss_ce: 0.006263

 80%|███████████████████████▎     | 321/400 [2:18:06<33:58, 25.81s/it]2022-01-08 17:28:13,388 iteration 5458 : loss : 0.021720, loss_ce: 0.007529
2022-01-08 17:28:14,703 iteration 5459 : loss : 0.014568, loss_ce: 0.006612
2022-01-08 17:28:16,076 iteration 5460 : loss : 0.014859, loss_ce: 0.005304
2022-01-08 17:28:17,439 iteration 5461 : loss : 0.020083, loss_ce: 0.007270
2022-01-08 17:28:18,793 iteration 5462 : loss : 0.016626, loss_ce: 0.006107
2022-01-08 17:28:20,222 iteration 5463 : loss : 0.022736, loss_ce: 0.007090
2022-01-08 17:28:21,610 iteration 5464 : loss : 0.018761, loss_ce: 0.008200
2022-01-08 17:28:23,051 iteration 5465 : loss : 0.026823, loss_ce: 0.009613
2022-01-08 17:28:24,484 iteration 5466 : loss : 0.018400, loss_ce: 0.006418
2022-01-08 17:28:25,888 iteration 5467 : loss : 0.022816, loss_ce: 0.008776
2022-01-08 17:28:27,289 iteration 5468 : loss : 0.017328, loss_ce: 0.007279
2022-01-08 17:28:28,598 iteration 5469 : loss : 0.015401, loss_ce: 0.005161
2022-01-08 17:28:29,959 iteration 5470 : loss : 0.010392, loss_ce: 0.003819
2022-01-08 17:28:31,324 iteration 5471 : loss : 0.028610, loss_ce: 0.008228
2022-01-08 17:28:32,720 iteration 5472 : loss : 0.020274, loss_ce: 0.007319
2022-01-08 17:28:34,041 iteration 5473 : loss : 0.012496, loss_ce: 0.004499
2022-01-08 17:28:35,373 iteration 5474 : loss : 0.015827, loss_ce: 0.005439

 80%|███████████████████████▎     | 322/400 [2:18:29<32:36, 25.08s/it]2022-01-08 17:28:36,819 iteration 5475 : loss : 0.017472, loss_ce: 0.004771
2022-01-08 17:28:38,249 iteration 5476 : loss : 0.017713, loss_ce: 0.007669
2022-01-08 17:28:39,623 iteration 5477 : loss : 0.023289, loss_ce: 0.003606
2022-01-08 17:28:40,923 iteration 5478 : loss : 0.017209, loss_ce: 0.005064
2022-01-08 17:28:42,312 iteration 5479 : loss : 0.013337, loss_ce: 0.005484
2022-01-08 17:28:43,671 iteration 5480 : loss : 0.020022, loss_ce: 0.006297
2022-01-08 17:28:45,016 iteration 5481 : loss : 0.016306, loss_ce: 0.005655
2022-01-08 17:28:46,474 iteration 5482 : loss : 0.034699, loss_ce: 0.008279
2022-01-08 17:28:47,772 iteration 5483 : loss : 0.013597, loss_ce: 0.005193
2022-01-08 17:28:49,164 iteration 5484 : loss : 0.020575, loss_ce: 0.008211
2022-01-08 17:28:50,534 iteration 5485 : loss : 0.023762, loss_ce: 0.012421
2022-01-08 17:28:51,899 iteration 5486 : loss : 0.026332, loss_ce: 0.011042
2022-01-08 17:28:53,287 iteration 5487 : loss : 0.016669, loss_ce: 0.006189
2022-01-08 17:28:54,627 iteration 5488 : loss : 0.014879, loss_ce: 0.006366
2022-01-08 17:28:55,957 iteration 5489 : loss : 0.013956, loss_ce: 0.007254
2022-01-08 17:28:57,399 iteration 5490 : loss : 0.017661, loss_ce: 0.007069
2022-01-08 17:28:58,746 iteration 5491 : loss : 0.014503, loss_ce: 0.004437

 81%|███████████████████████▍     | 323/400 [2:18:52<31:31, 24.57s/it]2022-01-08 17:29:00,088 iteration 5492 : loss : 0.015432, loss_ce: 0.005848
2022-01-08 17:29:01,485 iteration 5493 : loss : 0.021777, loss_ce: 0.006490
2022-01-08 17:29:02,816 iteration 5494 : loss : 0.017884, loss_ce: 0.006497
2022-01-08 17:29:04,190 iteration 5495 : loss : 0.015440, loss_ce: 0.005072
2022-01-08 17:29:05,573 iteration 5496 : loss : 0.019409, loss_ce: 0.005677
2022-01-08 17:29:06,963 iteration 5497 : loss : 0.014797, loss_ce: 0.005999
2022-01-08 17:29:08,388 iteration 5498 : loss : 0.024062, loss_ce: 0.007401
2022-01-08 17:29:09,789 iteration 5499 : loss : 0.021722, loss_ce: 0.011898
2022-01-08 17:29:11,100 iteration 5500 : loss : 0.014950, loss_ce: 0.006396
2022-01-08 17:29:12,479 iteration 5501 : loss : 0.018073, loss_ce: 0.007446
2022-01-08 17:29:13,809 iteration 5502 : loss : 0.010993, loss_ce: 0.004771
2022-01-08 17:29:15,173 iteration 5503 : loss : 0.014203, loss_ce: 0.003786
2022-01-08 17:29:16,505 iteration 5504 : loss : 0.015763, loss_ce: 0.005596
2022-01-08 17:29:17,871 iteration 5505 : loss : 0.019557, loss_ce: 0.008294
2022-01-08 17:29:19,270 iteration 5506 : loss : 0.015286, loss_ce: 0.005652
2022-01-08 17:29:20,637 iteration 5507 : loss : 0.016448, loss_ce: 0.007936
2022-01-08 17:29:22,016 iteration 5508 : loss : 0.020127, loss_ce: 0.006798

 81%|███████████████████████▍     | 324/400 [2:19:16<30:37, 24.18s/it]2022-01-08 17:29:23,461 iteration 5509 : loss : 0.049133, loss_ce: 0.012629
2022-01-08 17:29:24,917 iteration 5510 : loss : 0.015124, loss_ce: 0.005344
2022-01-08 17:29:26,271 iteration 5511 : loss : 0.015336, loss_ce: 0.005578
2022-01-08 17:29:27,695 iteration 5512 : loss : 0.022818, loss_ce: 0.009850
2022-01-08 17:29:29,045 iteration 5513 : loss : 0.017694, loss_ce: 0.008770
2022-01-08 17:29:30,352 iteration 5514 : loss : 0.011081, loss_ce: 0.003700
2022-01-08 17:29:31,783 iteration 5515 : loss : 0.024686, loss_ce: 0.004865
2022-01-08 17:29:33,136 iteration 5516 : loss : 0.017002, loss_ce: 0.006121
2022-01-08 17:29:34,518 iteration 5517 : loss : 0.014826, loss_ce: 0.006255
2022-01-08 17:29:35,896 iteration 5518 : loss : 0.021687, loss_ce: 0.007564
2022-01-08 17:29:37,288 iteration 5519 : loss : 0.026318, loss_ce: 0.011039
2022-01-08 17:29:38,664 iteration 5520 : loss : 0.017760, loss_ce: 0.006699
2022-01-08 17:29:40,057 iteration 5521 : loss : 0.019585, loss_ce: 0.006670
2022-01-08 17:29:41,430 iteration 5522 : loss : 0.018716, loss_ce: 0.005567
2022-01-08 17:29:42,777 iteration 5523 : loss : 0.010548, loss_ce: 0.003653
2022-01-08 17:29:44,157 iteration 5524 : loss : 0.018737, loss_ce: 0.007645
2022-01-08 17:29:44,157 Training Data Eval:
2022-01-08 17:29:50,992   Average segmentation loss on training set: 0.0103
2022-01-08 17:29:50,992 Validation Data Eval:
2022-01-08 17:29:53,354   Average segmentation loss on validation set: 0.0738
2022-01-08 17:29:54,719 iteration 5525 : loss : 0.019481, loss_ce: 0.009323

 81%|███████████████████████▌     | 325/400 [2:19:48<33:25, 26.74s/it]2022-01-08 17:29:56,196 iteration 5526 : loss : 0.017869, loss_ce: 0.006957
2022-01-08 17:29:57,579 iteration 5527 : loss : 0.017056, loss_ce: 0.007690
2022-01-08 17:29:58,951 iteration 5528 : loss : 0.023970, loss_ce: 0.009526
2022-01-08 17:30:00,356 iteration 5529 : loss : 0.024890, loss_ce: 0.009769
2022-01-08 17:30:01,676 iteration 5530 : loss : 0.017389, loss_ce: 0.008784
2022-01-08 17:30:03,027 iteration 5531 : loss : 0.019168, loss_ce: 0.007878
2022-01-08 17:30:04,401 iteration 5532 : loss : 0.011205, loss_ce: 0.004509
2022-01-08 17:30:05,831 iteration 5533 : loss : 0.019998, loss_ce: 0.005703
2022-01-08 17:30:07,199 iteration 5534 : loss : 0.016169, loss_ce: 0.005610
2022-01-08 17:30:08,631 iteration 5535 : loss : 0.024948, loss_ce: 0.009027
2022-01-08 17:30:10,099 iteration 5536 : loss : 0.023957, loss_ce: 0.010534
2022-01-08 17:30:11,514 iteration 5537 : loss : 0.023894, loss_ce: 0.007914
2022-01-08 17:30:12,901 iteration 5538 : loss : 0.019145, loss_ce: 0.007496
2022-01-08 17:30:14,376 iteration 5539 : loss : 0.016927, loss_ce: 0.003951
2022-01-08 17:30:15,724 iteration 5540 : loss : 0.013427, loss_ce: 0.005998
2022-01-08 17:30:17,108 iteration 5541 : loss : 0.015990, loss_ce: 0.005652
2022-01-08 17:30:18,466 iteration 5542 : loss : 0.015026, loss_ce: 0.005731

 82%|███████████████████████▋     | 326/400 [2:20:12<31:52, 25.84s/it]2022-01-08 17:30:19,921 iteration 5543 : loss : 0.018980, loss_ce: 0.006193
2022-01-08 17:30:21,307 iteration 5544 : loss : 0.018118, loss_ce: 0.007890
2022-01-08 17:30:22,662 iteration 5545 : loss : 0.025036, loss_ce: 0.011586
2022-01-08 17:30:23,986 iteration 5546 : loss : 0.016943, loss_ce: 0.005481
2022-01-08 17:30:25,362 iteration 5547 : loss : 0.018773, loss_ce: 0.007884
2022-01-08 17:30:26,788 iteration 5548 : loss : 0.015246, loss_ce: 0.004909
2022-01-08 17:30:28,104 iteration 5549 : loss : 0.016018, loss_ce: 0.006167
2022-01-08 17:30:29,456 iteration 5550 : loss : 0.016193, loss_ce: 0.006277
2022-01-08 17:30:30,833 iteration 5551 : loss : 0.015339, loss_ce: 0.006863
2022-01-08 17:30:32,150 iteration 5552 : loss : 0.012899, loss_ce: 0.004846
2022-01-08 17:30:33,540 iteration 5553 : loss : 0.019567, loss_ce: 0.007468
2022-01-08 17:30:34,957 iteration 5554 : loss : 0.017040, loss_ce: 0.005251
2022-01-08 17:30:36,379 iteration 5555 : loss : 0.032325, loss_ce: 0.008412
2022-01-08 17:30:37,685 iteration 5556 : loss : 0.016254, loss_ce: 0.006552
2022-01-08 17:30:39,114 iteration 5557 : loss : 0.031906, loss_ce: 0.010762
2022-01-08 17:30:40,495 iteration 5558 : loss : 0.018925, loss_ce: 0.006144
2022-01-08 17:30:41,786 iteration 5559 : loss : 0.014618, loss_ce: 0.006390

 82%|███████████████████████▋     | 327/400 [2:20:36<30:31, 25.08s/it]2022-01-08 17:30:43,380 iteration 5560 : loss : 0.037511, loss_ce: 0.016106
2022-01-08 17:30:44,745 iteration 5561 : loss : 0.016815, loss_ce: 0.005760
2022-01-08 17:30:46,107 iteration 5562 : loss : 0.023065, loss_ce: 0.007139
2022-01-08 17:30:47,475 iteration 5563 : loss : 0.013508, loss_ce: 0.005319
2022-01-08 17:30:48,941 iteration 5564 : loss : 0.018784, loss_ce: 0.006093
2022-01-08 17:30:50,320 iteration 5565 : loss : 0.012264, loss_ce: 0.004816
2022-01-08 17:30:51,742 iteration 5566 : loss : 0.013623, loss_ce: 0.005689
2022-01-08 17:30:53,212 iteration 5567 : loss : 0.018042, loss_ce: 0.008680
2022-01-08 17:30:54,588 iteration 5568 : loss : 0.029647, loss_ce: 0.010662
2022-01-08 17:30:56,009 iteration 5569 : loss : 0.028746, loss_ce: 0.012814
2022-01-08 17:30:57,405 iteration 5570 : loss : 0.018368, loss_ce: 0.006302
2022-01-08 17:30:58,827 iteration 5571 : loss : 0.017280, loss_ce: 0.006719
2022-01-08 17:31:00,207 iteration 5572 : loss : 0.014947, loss_ce: 0.005438
2022-01-08 17:31:01,572 iteration 5573 : loss : 0.013761, loss_ce: 0.004363
2022-01-08 17:31:03,048 iteration 5574 : loss : 0.019248, loss_ce: 0.006595
2022-01-08 17:31:04,327 iteration 5575 : loss : 0.010946, loss_ce: 0.004731
2022-01-08 17:31:05,584 iteration 5576 : loss : 0.014268, loss_ce: 0.004364

 82%|███████████████████████▊     | 328/400 [2:20:59<29:38, 24.70s/it]2022-01-08 17:31:07,004 iteration 5577 : loss : 0.016117, loss_ce: 0.005458
2022-01-08 17:31:08,350 iteration 5578 : loss : 0.016504, loss_ce: 0.004339
2022-01-08 17:31:09,717 iteration 5579 : loss : 0.014017, loss_ce: 0.004086
2022-01-08 17:31:11,139 iteration 5580 : loss : 0.018839, loss_ce: 0.008691
2022-01-08 17:31:12,494 iteration 5581 : loss : 0.013832, loss_ce: 0.004859
2022-01-08 17:31:13,906 iteration 5582 : loss : 0.018776, loss_ce: 0.005556
2022-01-08 17:31:15,264 iteration 5583 : loss : 0.019682, loss_ce: 0.005257
2022-01-08 17:31:16,722 iteration 5584 : loss : 0.021684, loss_ce: 0.009174
2022-01-08 17:31:18,079 iteration 5585 : loss : 0.018441, loss_ce: 0.007463
2022-01-08 17:31:19,454 iteration 5586 : loss : 0.016225, loss_ce: 0.007095
2022-01-08 17:31:20,831 iteration 5587 : loss : 0.023272, loss_ce: 0.010908
2022-01-08 17:31:22,278 iteration 5588 : loss : 0.018050, loss_ce: 0.006812
2022-01-08 17:31:23,705 iteration 5589 : loss : 0.021116, loss_ce: 0.009030
2022-01-08 17:31:25,093 iteration 5590 : loss : 0.016147, loss_ce: 0.006063
2022-01-08 17:31:26,477 iteration 5591 : loss : 0.018791, loss_ce: 0.009219
2022-01-08 17:31:27,843 iteration 5592 : loss : 0.015251, loss_ce: 0.005070
2022-01-08 17:31:29,203 iteration 5593 : loss : 0.013647, loss_ce: 0.007678

 82%|███████████████████████▊     | 329/400 [2:21:23<28:50, 24.37s/it]2022-01-08 17:31:30,668 iteration 5594 : loss : 0.018533, loss_ce: 0.006507
2022-01-08 17:31:32,026 iteration 5595 : loss : 0.015923, loss_ce: 0.007555
2022-01-08 17:31:33,377 iteration 5596 : loss : 0.010903, loss_ce: 0.003048
2022-01-08 17:31:34,769 iteration 5597 : loss : 0.013712, loss_ce: 0.004494
2022-01-08 17:31:36,220 iteration 5598 : loss : 0.021091, loss_ce: 0.009164
2022-01-08 17:31:37,644 iteration 5599 : loss : 0.015321, loss_ce: 0.005492
2022-01-08 17:31:39,059 iteration 5600 : loss : 0.018165, loss_ce: 0.007340
2022-01-08 17:31:40,476 iteration 5601 : loss : 0.015783, loss_ce: 0.004542
2022-01-08 17:31:41,818 iteration 5602 : loss : 0.019178, loss_ce: 0.004785
2022-01-08 17:31:43,244 iteration 5603 : loss : 0.019835, loss_ce: 0.008668
2022-01-08 17:31:44,593 iteration 5604 : loss : 0.014930, loss_ce: 0.006604
2022-01-08 17:31:45,945 iteration 5605 : loss : 0.017131, loss_ce: 0.005882
2022-01-08 17:31:47,389 iteration 5606 : loss : 0.020149, loss_ce: 0.006340
2022-01-08 17:31:48,769 iteration 5607 : loss : 0.020343, loss_ce: 0.007797
2022-01-08 17:31:50,266 iteration 5608 : loss : 0.022706, loss_ce: 0.011687
2022-01-08 17:31:51,611 iteration 5609 : loss : 0.016068, loss_ce: 0.006859
2022-01-08 17:31:51,611 Training Data Eval:
2022-01-08 17:31:58,443   Average segmentation loss on training set: 0.0097
2022-01-08 17:31:58,444 Validation Data Eval:
2022-01-08 17:32:00,802   Average segmentation loss on validation set: 0.0786
2022-01-08 17:32:02,201 iteration 5610 : loss : 0.018382, loss_ce: 0.009183

 82%|███████████████████████▉     | 330/400 [2:21:56<31:27, 26.96s/it]2022-01-08 17:32:03,672 iteration 5611 : loss : 0.016378, loss_ce: 0.006670
2022-01-08 17:32:05,063 iteration 5612 : loss : 0.039159, loss_ce: 0.020391
2022-01-08 17:32:06,432 iteration 5613 : loss : 0.018256, loss_ce: 0.008147
2022-01-08 17:32:07,798 iteration 5614 : loss : 0.018751, loss_ce: 0.006030
2022-01-08 17:32:09,199 iteration 5615 : loss : 0.017033, loss_ce: 0.006243
2022-01-08 17:32:10,616 iteration 5616 : loss : 0.016743, loss_ce: 0.006967
2022-01-08 17:32:11,995 iteration 5617 : loss : 0.015359, loss_ce: 0.005920
2022-01-08 17:32:13,323 iteration 5618 : loss : 0.016040, loss_ce: 0.006711
2022-01-08 17:32:14,740 iteration 5619 : loss : 0.019261, loss_ce: 0.007245
2022-01-08 17:32:16,167 iteration 5620 : loss : 0.016995, loss_ce: 0.005005
2022-01-08 17:32:17,515 iteration 5621 : loss : 0.017759, loss_ce: 0.006950
2022-01-08 17:32:18,973 iteration 5622 : loss : 0.029574, loss_ce: 0.014370
2022-01-08 17:32:20,318 iteration 5623 : loss : 0.022535, loss_ce: 0.006546
2022-01-08 17:32:21,719 iteration 5624 : loss : 0.015787, loss_ce: 0.006834
2022-01-08 17:32:23,132 iteration 5625 : loss : 0.019026, loss_ce: 0.008243
2022-01-08 17:32:24,511 iteration 5626 : loss : 0.019187, loss_ce: 0.007295
2022-01-08 17:32:25,882 iteration 5627 : loss : 0.018654, loss_ce: 0.005812

 83%|███████████████████████▉     | 331/400 [2:22:20<29:52, 25.98s/it]2022-01-08 17:32:27,224 iteration 5628 : loss : 0.015845, loss_ce: 0.006362
2022-01-08 17:32:28,630 iteration 5629 : loss : 0.014130, loss_ce: 0.006152
2022-01-08 17:32:30,002 iteration 5630 : loss : 0.013044, loss_ce: 0.004393
2022-01-08 17:32:31,481 iteration 5631 : loss : 0.022397, loss_ce: 0.010296
2022-01-08 17:32:32,787 iteration 5632 : loss : 0.022828, loss_ce: 0.012023
2022-01-08 17:32:34,208 iteration 5633 : loss : 0.024148, loss_ce: 0.010083
2022-01-08 17:32:35,548 iteration 5634 : loss : 0.012688, loss_ce: 0.004784
2022-01-08 17:32:36,955 iteration 5635 : loss : 0.016666, loss_ce: 0.004858
2022-01-08 17:32:38,276 iteration 5636 : loss : 0.012942, loss_ce: 0.005761
2022-01-08 17:32:39,671 iteration 5637 : loss : 0.017483, loss_ce: 0.007480
2022-01-08 17:32:40,944 iteration 5638 : loss : 0.012358, loss_ce: 0.003912
2022-01-08 17:32:42,267 iteration 5639 : loss : 0.017141, loss_ce: 0.005315
2022-01-08 17:32:43,622 iteration 5640 : loss : 0.015601, loss_ce: 0.007733
2022-01-08 17:32:45,033 iteration 5641 : loss : 0.013350, loss_ce: 0.006309
2022-01-08 17:32:46,394 iteration 5642 : loss : 0.014250, loss_ce: 0.002650
2022-01-08 17:32:47,812 iteration 5643 : loss : 0.014103, loss_ce: 0.003923
2022-01-08 17:32:49,214 iteration 5644 : loss : 0.019248, loss_ce: 0.006507

 83%|████████████████████████     | 332/400 [2:22:43<28:32, 25.19s/it]2022-01-08 17:32:50,754 iteration 5645 : loss : 0.020605, loss_ce: 0.008372
2022-01-08 17:32:52,104 iteration 5646 : loss : 0.020560, loss_ce: 0.007301
2022-01-08 17:32:53,484 iteration 5647 : loss : 0.019695, loss_ce: 0.009241
2022-01-08 17:32:54,900 iteration 5648 : loss : 0.021554, loss_ce: 0.006275
2022-01-08 17:32:56,317 iteration 5649 : loss : 0.018174, loss_ce: 0.008405
2022-01-08 17:32:57,705 iteration 5650 : loss : 0.020282, loss_ce: 0.007617
2022-01-08 17:32:59,077 iteration 5651 : loss : 0.023959, loss_ce: 0.011679
2022-01-08 17:33:00,382 iteration 5652 : loss : 0.014889, loss_ce: 0.005760
2022-01-08 17:33:01,739 iteration 5653 : loss : 0.014025, loss_ce: 0.005153
2022-01-08 17:33:03,062 iteration 5654 : loss : 0.014538, loss_ce: 0.004049
2022-01-08 17:33:04,454 iteration 5655 : loss : 0.020874, loss_ce: 0.007455
2022-01-08 17:33:05,825 iteration 5656 : loss : 0.015469, loss_ce: 0.004933
2022-01-08 17:33:07,199 iteration 5657 : loss : 0.017162, loss_ce: 0.006715
2022-01-08 17:33:08,574 iteration 5658 : loss : 0.029810, loss_ce: 0.015608
2022-01-08 17:33:09,929 iteration 5659 : loss : 0.026171, loss_ce: 0.007746
2022-01-08 17:33:11,251 iteration 5660 : loss : 0.010990, loss_ce: 0.004157
2022-01-08 17:33:12,712 iteration 5661 : loss : 0.020305, loss_ce: 0.006835

 83%|████████████████████████▏    | 333/400 [2:23:06<27:33, 24.68s/it]2022-01-08 17:33:14,150 iteration 5662 : loss : 0.016033, loss_ce: 0.004367
2022-01-08 17:33:15,527 iteration 5663 : loss : 0.015326, loss_ce: 0.006220
2022-01-08 17:33:16,921 iteration 5664 : loss : 0.029647, loss_ce: 0.008718
2022-01-08 17:33:18,217 iteration 5665 : loss : 0.015019, loss_ce: 0.005225
2022-01-08 17:33:19,615 iteration 5666 : loss : 0.014897, loss_ce: 0.004877
2022-01-08 17:33:21,034 iteration 5667 : loss : 0.016675, loss_ce: 0.006544
2022-01-08 17:33:22,406 iteration 5668 : loss : 0.015133, loss_ce: 0.006859
2022-01-08 17:33:23,823 iteration 5669 : loss : 0.015785, loss_ce: 0.007431
2022-01-08 17:33:25,222 iteration 5670 : loss : 0.013404, loss_ce: 0.004822
2022-01-08 17:33:26,613 iteration 5671 : loss : 0.013814, loss_ce: 0.004809
2022-01-08 17:33:27,987 iteration 5672 : loss : 0.016684, loss_ce: 0.004840
2022-01-08 17:33:29,330 iteration 5673 : loss : 0.016865, loss_ce: 0.005076
2022-01-08 17:33:30,778 iteration 5674 : loss : 0.017071, loss_ce: 0.008068
2022-01-08 17:33:32,129 iteration 5675 : loss : 0.016053, loss_ce: 0.006431
2022-01-08 17:33:33,569 iteration 5676 : loss : 0.024431, loss_ce: 0.008797
2022-01-08 17:33:34,990 iteration 5677 : loss : 0.013575, loss_ce: 0.006767
2022-01-08 17:33:36,387 iteration 5678 : loss : 0.018573, loss_ce: 0.006595

 84%|████████████████████████▏    | 334/400 [2:23:30<26:48, 24.37s/it]2022-01-08 17:33:37,827 iteration 5679 : loss : 0.020054, loss_ce: 0.008688
2022-01-08 17:33:39,111 iteration 5680 : loss : 0.013365, loss_ce: 0.003406
2022-01-08 17:33:40,538 iteration 5681 : loss : 0.016656, loss_ce: 0.005530
2022-01-08 17:33:41,966 iteration 5682 : loss : 0.032798, loss_ce: 0.015152
2022-01-08 17:33:43,315 iteration 5683 : loss : 0.011481, loss_ce: 0.003729
2022-01-08 17:33:44,653 iteration 5684 : loss : 0.013355, loss_ce: 0.007095
2022-01-08 17:33:46,051 iteration 5685 : loss : 0.018315, loss_ce: 0.008408
2022-01-08 17:33:47,407 iteration 5686 : loss : 0.019477, loss_ce: 0.007659
2022-01-08 17:33:48,778 iteration 5687 : loss : 0.011567, loss_ce: 0.004745
2022-01-08 17:33:50,244 iteration 5688 : loss : 0.019175, loss_ce: 0.006769
2022-01-08 17:33:51,628 iteration 5689 : loss : 0.018611, loss_ce: 0.005606
2022-01-08 17:33:53,018 iteration 5690 : loss : 0.016363, loss_ce: 0.007376
2022-01-08 17:33:54,427 iteration 5691 : loss : 0.016542, loss_ce: 0.007077
2022-01-08 17:33:55,831 iteration 5692 : loss : 0.019378, loss_ce: 0.008800
2022-01-08 17:33:57,218 iteration 5693 : loss : 0.019753, loss_ce: 0.005147
2022-01-08 17:33:58,580 iteration 5694 : loss : 0.020811, loss_ce: 0.009475
2022-01-08 17:33:58,580 Training Data Eval:
2022-01-08 17:34:05,409   Average segmentation loss on training set: 0.0094
2022-01-08 17:34:05,409 Validation Data Eval:
2022-01-08 17:34:07,764   Average segmentation loss on validation set: 0.0657
2022-01-08 17:34:09,087 iteration 5695 : loss : 0.013282, loss_ce: 0.004471

 84%|████████████████████████▎    | 335/400 [2:24:03<29:06, 26.87s/it]2022-01-08 17:34:10,477 iteration 5696 : loss : 0.012970, loss_ce: 0.006394
2022-01-08 17:34:11,798 iteration 5697 : loss : 0.013046, loss_ce: 0.005700
2022-01-08 17:34:13,215 iteration 5698 : loss : 0.017494, loss_ce: 0.005683
2022-01-08 17:34:14,521 iteration 5699 : loss : 0.013862, loss_ce: 0.006103
2022-01-08 17:34:15,872 iteration 5700 : loss : 0.013952, loss_ce: 0.004816
2022-01-08 17:34:17,188 iteration 5701 : loss : 0.011184, loss_ce: 0.004733
2022-01-08 17:34:18,653 iteration 5702 : loss : 0.016047, loss_ce: 0.006599
2022-01-08 17:34:20,062 iteration 5703 : loss : 0.017653, loss_ce: 0.006831
2022-01-08 17:34:21,454 iteration 5704 : loss : 0.021999, loss_ce: 0.007282
2022-01-08 17:34:22,857 iteration 5705 : loss : 0.018267, loss_ce: 0.005966
2022-01-08 17:34:24,150 iteration 5706 : loss : 0.013560, loss_ce: 0.005203
2022-01-08 17:34:25,501 iteration 5707 : loss : 0.013965, loss_ce: 0.004825
2022-01-08 17:34:26,826 iteration 5708 : loss : 0.014461, loss_ce: 0.005154
2022-01-08 17:34:28,205 iteration 5709 : loss : 0.016118, loss_ce: 0.006809
2022-01-08 17:34:29,572 iteration 5710 : loss : 0.014076, loss_ce: 0.004482
2022-01-08 17:34:30,879 iteration 5711 : loss : 0.016094, loss_ce: 0.005316
2022-01-08 17:34:32,265 iteration 5712 : loss : 0.020391, loss_ce: 0.008185

 84%|████████████████████████▎    | 336/400 [2:24:26<27:29, 25.77s/it]2022-01-08 17:34:33,743 iteration 5713 : loss : 0.018478, loss_ce: 0.005554
2022-01-08 17:34:35,163 iteration 5714 : loss : 0.023684, loss_ce: 0.008292
2022-01-08 17:34:36,595 iteration 5715 : loss : 0.013908, loss_ce: 0.005838
2022-01-08 17:34:37,953 iteration 5716 : loss : 0.019396, loss_ce: 0.007338
2022-01-08 17:34:39,417 iteration 5717 : loss : 0.021022, loss_ce: 0.008652
2022-01-08 17:34:40,746 iteration 5718 : loss : 0.016488, loss_ce: 0.005236
2022-01-08 17:34:42,069 iteration 5719 : loss : 0.015817, loss_ce: 0.007086
2022-01-08 17:34:43,485 iteration 5720 : loss : 0.016147, loss_ce: 0.006184
2022-01-08 17:34:44,878 iteration 5721 : loss : 0.019398, loss_ce: 0.009094
2022-01-08 17:34:46,247 iteration 5722 : loss : 0.016801, loss_ce: 0.008682
2022-01-08 17:34:47,631 iteration 5723 : loss : 0.020908, loss_ce: 0.008186
2022-01-08 17:34:49,051 iteration 5724 : loss : 0.014060, loss_ce: 0.004899
2022-01-08 17:34:50,430 iteration 5725 : loss : 0.016799, loss_ce: 0.006494
2022-01-08 17:34:51,760 iteration 5726 : loss : 0.019981, loss_ce: 0.005041
2022-01-08 17:34:53,150 iteration 5727 : loss : 0.015849, loss_ce: 0.004823
2022-01-08 17:34:54,503 iteration 5728 : loss : 0.018985, loss_ce: 0.005965
2022-01-08 17:34:55,945 iteration 5729 : loss : 0.014793, loss_ce: 0.005936

 84%|████████████████████████▍    | 337/400 [2:24:50<26:23, 25.14s/it]2022-01-08 17:34:57,334 iteration 5730 : loss : 0.013258, loss_ce: 0.005952
2022-01-08 17:34:58,758 iteration 5731 : loss : 0.017055, loss_ce: 0.007608
2022-01-08 17:35:00,089 iteration 5732 : loss : 0.014293, loss_ce: 0.005192
2022-01-08 17:35:01,520 iteration 5733 : loss : 0.025338, loss_ce: 0.007031
2022-01-08 17:35:02,943 iteration 5734 : loss : 0.021243, loss_ce: 0.008376
2022-01-08 17:35:04,292 iteration 5735 : loss : 0.023145, loss_ce: 0.006170
2022-01-08 17:35:05,641 iteration 5736 : loss : 0.022433, loss_ce: 0.009408
2022-01-08 17:35:07,094 iteration 5737 : loss : 0.021708, loss_ce: 0.008655
2022-01-08 17:35:08,438 iteration 5738 : loss : 0.014665, loss_ce: 0.004980
2022-01-08 17:35:09,775 iteration 5739 : loss : 0.011578, loss_ce: 0.004060
2022-01-08 17:35:11,144 iteration 5740 : loss : 0.019550, loss_ce: 0.007935
2022-01-08 17:35:12,518 iteration 5741 : loss : 0.022096, loss_ce: 0.009544
2022-01-08 17:35:13,906 iteration 5742 : loss : 0.019866, loss_ce: 0.004035
2022-01-08 17:35:15,309 iteration 5743 : loss : 0.018524, loss_ce: 0.007773
2022-01-08 17:35:16,739 iteration 5744 : loss : 0.023137, loss_ce: 0.010839
2022-01-08 17:35:18,171 iteration 5745 : loss : 0.014553, loss_ce: 0.006236
2022-01-08 17:35:19,544 iteration 5746 : loss : 0.015925, loss_ce: 0.004532

 84%|████████████████████████▌    | 338/400 [2:25:13<25:30, 24.68s/it]2022-01-08 17:35:20,984 iteration 5747 : loss : 0.016122, loss_ce: 0.005735
2022-01-08 17:35:22,379 iteration 5748 : loss : 0.019774, loss_ce: 0.007969
2022-01-08 17:35:23,759 iteration 5749 : loss : 0.022117, loss_ce: 0.008479
2022-01-08 17:35:25,132 iteration 5750 : loss : 0.013846, loss_ce: 0.005023
2022-01-08 17:35:26,451 iteration 5751 : loss : 0.015376, loss_ce: 0.004704
2022-01-08 17:35:27,803 iteration 5752 : loss : 0.015901, loss_ce: 0.004647
2022-01-08 17:35:29,218 iteration 5753 : loss : 0.013723, loss_ce: 0.005299
2022-01-08 17:35:30,651 iteration 5754 : loss : 0.023550, loss_ce: 0.007386
2022-01-08 17:35:32,027 iteration 5755 : loss : 0.011177, loss_ce: 0.003628
2022-01-08 17:35:33,374 iteration 5756 : loss : 0.014066, loss_ce: 0.004758
2022-01-08 17:35:34,648 iteration 5757 : loss : 0.011447, loss_ce: 0.004461
2022-01-08 17:35:36,071 iteration 5758 : loss : 0.019022, loss_ce: 0.007956
2022-01-08 17:35:37,502 iteration 5759 : loss : 0.018621, loss_ce: 0.009284
2022-01-08 17:35:38,966 iteration 5760 : loss : 0.020119, loss_ce: 0.012794
2022-01-08 17:35:40,441 iteration 5761 : loss : 0.023123, loss_ce: 0.009714
2022-01-08 17:35:41,772 iteration 5762 : loss : 0.013502, loss_ce: 0.006105
2022-01-08 17:35:43,194 iteration 5763 : loss : 0.012921, loss_ce: 0.005129

 85%|████████████████████████▌    | 339/400 [2:25:37<24:46, 24.37s/it]2022-01-08 17:35:44,676 iteration 5764 : loss : 0.015942, loss_ce: 0.005881
2022-01-08 17:35:46,116 iteration 5765 : loss : 0.030633, loss_ce: 0.007475
2022-01-08 17:35:47,522 iteration 5766 : loss : 0.017902, loss_ce: 0.008706
2022-01-08 17:35:48,900 iteration 5767 : loss : 0.014067, loss_ce: 0.007156
2022-01-08 17:35:50,380 iteration 5768 : loss : 0.017034, loss_ce: 0.006214
2022-01-08 17:35:51,809 iteration 5769 : loss : 0.024476, loss_ce: 0.009134
2022-01-08 17:35:53,156 iteration 5770 : loss : 0.012224, loss_ce: 0.004481
2022-01-08 17:35:54,555 iteration 5771 : loss : 0.019450, loss_ce: 0.007077
2022-01-08 17:35:55,923 iteration 5772 : loss : 0.019165, loss_ce: 0.007336
2022-01-08 17:35:57,239 iteration 5773 : loss : 0.013337, loss_ce: 0.004193
2022-01-08 17:35:58,532 iteration 5774 : loss : 0.014250, loss_ce: 0.003609
2022-01-08 17:35:59,924 iteration 5775 : loss : 0.016065, loss_ce: 0.006741
2022-01-08 17:36:01,374 iteration 5776 : loss : 0.021068, loss_ce: 0.009885
2022-01-08 17:36:02,674 iteration 5777 : loss : 0.016028, loss_ce: 0.007231
2022-01-08 17:36:04,022 iteration 5778 : loss : 0.020823, loss_ce: 0.006582
2022-01-08 17:36:05,381 iteration 5779 : loss : 0.012006, loss_ce: 0.003894
2022-01-08 17:36:05,381 Training Data Eval:
2022-01-08 17:36:12,216   Average segmentation loss on training set: 0.0092
2022-01-08 17:36:12,216 Validation Data Eval:
2022-01-08 17:36:14,575   Average segmentation loss on validation set: 0.0788
2022-01-08 17:36:15,943 iteration 5780 : loss : 0.017738, loss_ce: 0.006615

 85%|████████████████████████▋    | 340/400 [2:26:10<26:53, 26.88s/it]2022-01-08 17:36:17,345 iteration 5781 : loss : 0.024753, loss_ce: 0.006732
2022-01-08 17:36:18,782 iteration 5782 : loss : 0.034894, loss_ce: 0.012557
2022-01-08 17:36:20,155 iteration 5783 : loss : 0.016957, loss_ce: 0.006109
2022-01-08 17:36:21,553 iteration 5784 : loss : 0.015989, loss_ce: 0.008008
2022-01-08 17:36:22,888 iteration 5785 : loss : 0.011607, loss_ce: 0.004191
2022-01-08 17:36:24,234 iteration 5786 : loss : 0.014339, loss_ce: 0.006019
2022-01-08 17:36:25,576 iteration 5787 : loss : 0.012193, loss_ce: 0.004619
2022-01-08 17:36:27,076 iteration 5788 : loss : 0.021503, loss_ce: 0.008802
2022-01-08 17:36:28,471 iteration 5789 : loss : 0.016589, loss_ce: 0.006781
2022-01-08 17:36:29,854 iteration 5790 : loss : 0.014433, loss_ce: 0.004331
2022-01-08 17:36:31,191 iteration 5791 : loss : 0.013479, loss_ce: 0.004863
2022-01-08 17:36:32,598 iteration 5792 : loss : 0.019889, loss_ce: 0.008189
2022-01-08 17:36:34,079 iteration 5793 : loss : 0.017321, loss_ce: 0.006779
2022-01-08 17:36:35,476 iteration 5794 : loss : 0.016162, loss_ce: 0.005975
2022-01-08 17:36:36,852 iteration 5795 : loss : 0.015423, loss_ce: 0.005406
2022-01-08 17:36:38,186 iteration 5796 : loss : 0.012910, loss_ce: 0.003345
2022-01-08 17:36:39,588 iteration 5797 : loss : 0.019468, loss_ce: 0.008247

 85%|████████████████████████▋    | 341/400 [2:26:33<25:28, 25.91s/it]2022-01-08 17:36:41,062 iteration 5798 : loss : 0.028508, loss_ce: 0.011347
2022-01-08 17:36:42,457 iteration 5799 : loss : 0.017476, loss_ce: 0.006316
2022-01-08 17:36:43,826 iteration 5800 : loss : 0.014652, loss_ce: 0.005628
2022-01-08 17:36:45,200 iteration 5801 : loss : 0.014248, loss_ce: 0.004734
2022-01-08 17:36:46,516 iteration 5802 : loss : 0.011517, loss_ce: 0.004704
2022-01-08 17:36:47,864 iteration 5803 : loss : 0.014026, loss_ce: 0.006436
2022-01-08 17:36:49,238 iteration 5804 : loss : 0.019693, loss_ce: 0.007948
2022-01-08 17:36:50,699 iteration 5805 : loss : 0.014595, loss_ce: 0.004862
2022-01-08 17:36:52,064 iteration 5806 : loss : 0.020826, loss_ce: 0.005863
2022-01-08 17:36:53,519 iteration 5807 : loss : 0.018539, loss_ce: 0.007048
2022-01-08 17:36:54,920 iteration 5808 : loss : 0.017970, loss_ce: 0.007769
2022-01-08 17:36:56,242 iteration 5809 : loss : 0.010345, loss_ce: 0.002506
2022-01-08 17:36:57,584 iteration 5810 : loss : 0.014983, loss_ce: 0.005021
2022-01-08 17:36:58,895 iteration 5811 : loss : 0.010615, loss_ce: 0.003033
2022-01-08 17:37:00,272 iteration 5812 : loss : 0.014930, loss_ce: 0.005430
2022-01-08 17:37:01,586 iteration 5813 : loss : 0.015258, loss_ce: 0.006727
2022-01-08 17:37:02,973 iteration 5814 : loss : 0.017958, loss_ce: 0.008978

 86%|████████████████████████▊    | 342/400 [2:26:57<24:19, 25.16s/it]2022-01-08 17:37:04,343 iteration 5815 : loss : 0.011688, loss_ce: 0.003766
2022-01-08 17:37:05,694 iteration 5816 : loss : 0.011554, loss_ce: 0.005319
2022-01-08 17:37:07,039 iteration 5817 : loss : 0.012085, loss_ce: 0.004260
2022-01-08 17:37:08,319 iteration 5818 : loss : 0.022556, loss_ce: 0.009105
2022-01-08 17:37:09,736 iteration 5819 : loss : 0.032621, loss_ce: 0.011784
2022-01-08 17:37:11,186 iteration 5820 : loss : 0.018739, loss_ce: 0.008271
2022-01-08 17:37:12,492 iteration 5821 : loss : 0.013106, loss_ce: 0.004426
2022-01-08 17:37:13,825 iteration 5822 : loss : 0.010801, loss_ce: 0.004634
2022-01-08 17:37:15,292 iteration 5823 : loss : 0.020177, loss_ce: 0.008763
2022-01-08 17:37:16,664 iteration 5824 : loss : 0.014135, loss_ce: 0.003989
2022-01-08 17:37:18,078 iteration 5825 : loss : 0.016693, loss_ce: 0.005902
2022-01-08 17:37:19,493 iteration 5826 : loss : 0.019079, loss_ce: 0.004252
2022-01-08 17:37:20,872 iteration 5827 : loss : 0.021218, loss_ce: 0.006593
2022-01-08 17:37:22,342 iteration 5828 : loss : 0.027445, loss_ce: 0.009514
2022-01-08 17:37:23,712 iteration 5829 : loss : 0.014035, loss_ce: 0.005781
2022-01-08 17:37:25,053 iteration 5830 : loss : 0.020937, loss_ce: 0.008449
2022-01-08 17:37:26,406 iteration 5831 : loss : 0.014514, loss_ce: 0.004909

 86%|████████████████████████▊    | 343/400 [2:27:20<23:24, 24.64s/it]2022-01-08 17:37:27,838 iteration 5832 : loss : 0.011805, loss_ce: 0.003399
2022-01-08 17:37:29,245 iteration 5833 : loss : 0.017291, loss_ce: 0.007349
2022-01-08 17:37:30,563 iteration 5834 : loss : 0.016142, loss_ce: 0.005653
2022-01-08 17:37:31,887 iteration 5835 : loss : 0.017635, loss_ce: 0.004901
2022-01-08 17:37:33,305 iteration 5836 : loss : 0.024373, loss_ce: 0.011570
2022-01-08 17:37:34,679 iteration 5837 : loss : 0.015417, loss_ce: 0.003208
2022-01-08 17:37:35,966 iteration 5838 : loss : 0.010345, loss_ce: 0.003044
2022-01-08 17:37:37,331 iteration 5839 : loss : 0.015166, loss_ce: 0.004899
2022-01-08 17:37:38,745 iteration 5840 : loss : 0.021480, loss_ce: 0.008927
2022-01-08 17:37:40,091 iteration 5841 : loss : 0.015451, loss_ce: 0.007287
2022-01-08 17:37:41,439 iteration 5842 : loss : 0.009777, loss_ce: 0.003602
2022-01-08 17:37:42,779 iteration 5843 : loss : 0.015458, loss_ce: 0.006134
2022-01-08 17:37:44,282 iteration 5844 : loss : 0.027764, loss_ce: 0.007258
2022-01-08 17:37:45,655 iteration 5845 : loss : 0.018913, loss_ce: 0.007668
2022-01-08 17:37:47,044 iteration 5846 : loss : 0.026538, loss_ce: 0.012177
2022-01-08 17:37:48,437 iteration 5847 : loss : 0.017279, loss_ce: 0.006868
2022-01-08 17:37:49,808 iteration 5848 : loss : 0.015612, loss_ce: 0.005505

 86%|████████████████████████▉    | 344/400 [2:27:44<22:39, 24.27s/it]2022-01-08 17:37:51,242 iteration 5849 : loss : 0.016139, loss_ce: 0.006705
2022-01-08 17:37:52,559 iteration 5850 : loss : 0.011568, loss_ce: 0.004656
2022-01-08 17:37:53,929 iteration 5851 : loss : 0.019376, loss_ce: 0.007550
2022-01-08 17:37:55,279 iteration 5852 : loss : 0.012859, loss_ce: 0.004685
2022-01-08 17:37:56,577 iteration 5853 : loss : 0.016902, loss_ce: 0.005896
2022-01-08 17:37:57,915 iteration 5854 : loss : 0.016664, loss_ce: 0.005394
2022-01-08 17:37:59,352 iteration 5855 : loss : 0.020140, loss_ce: 0.008710
2022-01-08 17:38:00,730 iteration 5856 : loss : 0.016032, loss_ce: 0.007334
2022-01-08 17:38:02,117 iteration 5857 : loss : 0.015746, loss_ce: 0.005090
2022-01-08 17:38:03,417 iteration 5858 : loss : 0.012821, loss_ce: 0.004800
2022-01-08 17:38:04,831 iteration 5859 : loss : 0.016485, loss_ce: 0.006314
2022-01-08 17:38:06,249 iteration 5860 : loss : 0.018462, loss_ce: 0.005360
2022-01-08 17:38:07,597 iteration 5861 : loss : 0.015597, loss_ce: 0.004708
2022-01-08 17:38:08,991 iteration 5862 : loss : 0.014445, loss_ce: 0.006647
2022-01-08 17:38:10,280 iteration 5863 : loss : 0.015161, loss_ce: 0.006102
2022-01-08 17:38:11,654 iteration 5864 : loss : 0.022693, loss_ce: 0.006541
2022-01-08 17:38:11,655 Training Data Eval:
2022-01-08 17:38:18,496   Average segmentation loss on training set: 0.0091
2022-01-08 17:38:18,497 Validation Data Eval:
2022-01-08 17:38:20,863   Average segmentation loss on validation set: 0.0789
2022-01-08 17:38:22,177 iteration 5865 : loss : 0.016641, loss_ce: 0.004959

 86%|█████████████████████████    | 345/400 [2:28:16<24:28, 26.70s/it]2022-01-08 17:38:23,678 iteration 5866 : loss : 0.014442, loss_ce: 0.005955
2022-01-08 17:38:25,102 iteration 5867 : loss : 0.017145, loss_ce: 0.005889
2022-01-08 17:38:26,517 iteration 5868 : loss : 0.017812, loss_ce: 0.006123
2022-01-08 17:38:27,819 iteration 5869 : loss : 0.025405, loss_ce: 0.010634
2022-01-08 17:38:29,276 iteration 5870 : loss : 0.018891, loss_ce: 0.005026
2022-01-08 17:38:30,684 iteration 5871 : loss : 0.011985, loss_ce: 0.003890
2022-01-08 17:38:32,100 iteration 5872 : loss : 0.020912, loss_ce: 0.007105
2022-01-08 17:38:33,597 iteration 5873 : loss : 0.024383, loss_ce: 0.009085
2022-01-08 17:38:34,941 iteration 5874 : loss : 0.015177, loss_ce: 0.005131
2022-01-08 17:38:36,298 iteration 5875 : loss : 0.014321, loss_ce: 0.006644
2022-01-08 17:38:37,683 iteration 5876 : loss : 0.015654, loss_ce: 0.005889
2022-01-08 17:38:39,061 iteration 5877 : loss : 0.016122, loss_ce: 0.005353
2022-01-08 17:38:40,463 iteration 5878 : loss : 0.015096, loss_ce: 0.006513
2022-01-08 17:38:41,802 iteration 5879 : loss : 0.012902, loss_ce: 0.005266
2022-01-08 17:38:43,277 iteration 5880 : loss : 0.021579, loss_ce: 0.005253
2022-01-08 17:38:44,601 iteration 5881 : loss : 0.011116, loss_ce: 0.004230
2022-01-08 17:38:45,958 iteration 5882 : loss : 0.014512, loss_ce: 0.006546

 86%|█████████████████████████    | 346/400 [2:28:40<23:14, 25.82s/it]2022-01-08 17:38:47,369 iteration 5883 : loss : 0.013300, loss_ce: 0.004320
2022-01-08 17:38:48,718 iteration 5884 : loss : 0.014615, loss_ce: 0.006425
2022-01-08 17:38:50,209 iteration 5885 : loss : 0.029061, loss_ce: 0.010421
2022-01-08 17:38:51,529 iteration 5886 : loss : 0.014410, loss_ce: 0.004236
2022-01-08 17:38:52,877 iteration 5887 : loss : 0.015350, loss_ce: 0.006101
2022-01-08 17:38:54,333 iteration 5888 : loss : 0.022111, loss_ce: 0.007783
2022-01-08 17:38:55,788 iteration 5889 : loss : 0.017348, loss_ce: 0.006186
2022-01-08 17:38:57,187 iteration 5890 : loss : 0.013486, loss_ce: 0.005002
2022-01-08 17:38:58,620 iteration 5891 : loss : 0.024713, loss_ce: 0.008829
2022-01-08 17:39:00,099 iteration 5892 : loss : 0.016641, loss_ce: 0.006212
2022-01-08 17:39:01,448 iteration 5893 : loss : 0.012522, loss_ce: 0.003998
2022-01-08 17:39:02,913 iteration 5894 : loss : 0.021316, loss_ce: 0.010915
2022-01-08 17:39:04,321 iteration 5895 : loss : 0.031667, loss_ce: 0.011545
2022-01-08 17:39:05,691 iteration 5896 : loss : 0.013143, loss_ce: 0.006339
2022-01-08 17:39:07,140 iteration 5897 : loss : 0.023269, loss_ce: 0.009497
2022-01-08 17:39:08,566 iteration 5898 : loss : 0.013911, loss_ce: 0.005055
2022-01-08 17:39:09,921 iteration 5899 : loss : 0.013804, loss_ce: 0.005001

 87%|█████████████████████████▏   | 347/400 [2:29:04<22:19, 25.26s/it]2022-01-08 17:39:11,378 iteration 5900 : loss : 0.014268, loss_ce: 0.004735
2022-01-08 17:39:12,835 iteration 5901 : loss : 0.038081, loss_ce: 0.012786
2022-01-08 17:39:14,215 iteration 5902 : loss : 0.015086, loss_ce: 0.005961
2022-01-08 17:39:15,659 iteration 5903 : loss : 0.028303, loss_ce: 0.012763
2022-01-08 17:39:17,027 iteration 5904 : loss : 0.018213, loss_ce: 0.006616
2022-01-08 17:39:18,456 iteration 5905 : loss : 0.021301, loss_ce: 0.005520
2022-01-08 17:39:19,788 iteration 5906 : loss : 0.016352, loss_ce: 0.006280
2022-01-08 17:39:21,200 iteration 5907 : loss : 0.010677, loss_ce: 0.003440
2022-01-08 17:39:22,588 iteration 5908 : loss : 0.016283, loss_ce: 0.005134
2022-01-08 17:39:23,887 iteration 5909 : loss : 0.023226, loss_ce: 0.005691
2022-01-08 17:39:25,284 iteration 5910 : loss : 0.018040, loss_ce: 0.005825
2022-01-08 17:39:26,716 iteration 5911 : loss : 0.018046, loss_ce: 0.007171
2022-01-08 17:39:28,042 iteration 5912 : loss : 0.014911, loss_ce: 0.004604
2022-01-08 17:39:29,403 iteration 5913 : loss : 0.025745, loss_ce: 0.010477
2022-01-08 17:39:30,797 iteration 5914 : loss : 0.020527, loss_ce: 0.007725
2022-01-08 17:39:32,101 iteration 5915 : loss : 0.026551, loss_ce: 0.009642
2022-01-08 17:39:33,532 iteration 5916 : loss : 0.023360, loss_ce: 0.008435

 87%|█████████████████████████▏   | 348/400 [2:29:27<21:27, 24.77s/it]2022-01-08 17:39:34,942 iteration 5917 : loss : 0.016599, loss_ce: 0.006457
2022-01-08 17:39:36,262 iteration 5918 : loss : 0.014621, loss_ce: 0.005643
2022-01-08 17:39:37,672 iteration 5919 : loss : 0.022329, loss_ce: 0.010302
2022-01-08 17:39:39,097 iteration 5920 : loss : 0.020683, loss_ce: 0.010993
2022-01-08 17:39:40,611 iteration 5921 : loss : 0.024959, loss_ce: 0.006893
2022-01-08 17:39:41,974 iteration 5922 : loss : 0.013998, loss_ce: 0.003602
2022-01-08 17:39:43,372 iteration 5923 : loss : 0.016730, loss_ce: 0.005212
2022-01-08 17:39:44,854 iteration 5924 : loss : 0.031788, loss_ce: 0.006656
2022-01-08 17:39:46,246 iteration 5925 : loss : 0.013684, loss_ce: 0.004521
2022-01-08 17:39:47,625 iteration 5926 : loss : 0.018338, loss_ce: 0.008299
2022-01-08 17:39:49,022 iteration 5927 : loss : 0.019322, loss_ce: 0.007937
2022-01-08 17:39:50,348 iteration 5928 : loss : 0.014336, loss_ce: 0.003605
2022-01-08 17:39:51,668 iteration 5929 : loss : 0.013503, loss_ce: 0.006216
2022-01-08 17:39:52,990 iteration 5930 : loss : 0.014792, loss_ce: 0.006713
2022-01-08 17:39:54,377 iteration 5931 : loss : 0.022744, loss_ce: 0.006014
2022-01-08 17:39:55,797 iteration 5932 : loss : 0.015133, loss_ce: 0.004713
2022-01-08 17:39:57,163 iteration 5933 : loss : 0.017560, loss_ce: 0.006151

 87%|█████████████████████████▎   | 349/400 [2:29:51<20:45, 24.42s/it]2022-01-08 17:39:58,548 iteration 5934 : loss : 0.014131, loss_ce: 0.004868
2022-01-08 17:40:00,051 iteration 5935 : loss : 0.020575, loss_ce: 0.007504
2022-01-08 17:40:01,433 iteration 5936 : loss : 0.012674, loss_ce: 0.005048
2022-01-08 17:40:02,782 iteration 5937 : loss : 0.015551, loss_ce: 0.005213
2022-01-08 17:40:04,086 iteration 5938 : loss : 0.009575, loss_ce: 0.003474
2022-01-08 17:40:05,491 iteration 5939 : loss : 0.015787, loss_ce: 0.005990
2022-01-08 17:40:06,811 iteration 5940 : loss : 0.012770, loss_ce: 0.004990
2022-01-08 17:40:08,150 iteration 5941 : loss : 0.018835, loss_ce: 0.008636
2022-01-08 17:40:09,496 iteration 5942 : loss : 0.014627, loss_ce: 0.005650
2022-01-08 17:40:10,881 iteration 5943 : loss : 0.012978, loss_ce: 0.003317
2022-01-08 17:40:12,266 iteration 5944 : loss : 0.016431, loss_ce: 0.007496
2022-01-08 17:40:13,612 iteration 5945 : loss : 0.016974, loss_ce: 0.004056
2022-01-08 17:40:15,080 iteration 5946 : loss : 0.020267, loss_ce: 0.007688
2022-01-08 17:40:16,489 iteration 5947 : loss : 0.017745, loss_ce: 0.006400
2022-01-08 17:40:17,844 iteration 5948 : loss : 0.019039, loss_ce: 0.007048
2022-01-08 17:40:19,286 iteration 5949 : loss : 0.017482, loss_ce: 0.006007
2022-01-08 17:40:19,286 Training Data Eval:
2022-01-08 17:40:26,119   Average segmentation loss on training set: 0.0091
2022-01-08 17:40:26,119 Validation Data Eval:
2022-01-08 17:40:28,486   Average segmentation loss on validation set: 0.0771
2022-01-08 17:40:29,872 iteration 5950 : loss : 0.012500, loss_ce: 0.004307

 88%|█████████████████████████▍   | 350/400 [2:30:24<22:25, 26.91s/it]2022-01-08 17:40:31,257 iteration 5951 : loss : 0.017995, loss_ce: 0.005102
2022-01-08 17:40:32,635 iteration 5952 : loss : 0.014089, loss_ce: 0.005100
2022-01-08 17:40:34,015 iteration 5953 : loss : 0.020387, loss_ce: 0.008121
2022-01-08 17:40:35,357 iteration 5954 : loss : 0.021953, loss_ce: 0.007792
2022-01-08 17:40:36,727 iteration 5955 : loss : 0.017124, loss_ce: 0.005599
2022-01-08 17:40:38,126 iteration 5956 : loss : 0.021738, loss_ce: 0.011123
2022-01-08 17:40:39,516 iteration 5957 : loss : 0.016347, loss_ce: 0.007547
2022-01-08 17:40:40,851 iteration 5958 : loss : 0.015284, loss_ce: 0.006894
2022-01-08 17:40:42,218 iteration 5959 : loss : 0.015897, loss_ce: 0.006201
2022-01-08 17:40:43,549 iteration 5960 : loss : 0.014735, loss_ce: 0.004962
2022-01-08 17:40:44,874 iteration 5961 : loss : 0.015296, loss_ce: 0.003461
2022-01-08 17:40:46,237 iteration 5962 : loss : 0.023534, loss_ce: 0.006126
2022-01-08 17:40:47,642 iteration 5963 : loss : 0.015510, loss_ce: 0.005827
2022-01-08 17:40:48,992 iteration 5964 : loss : 0.013408, loss_ce: 0.006797
2022-01-08 17:40:50,306 iteration 5965 : loss : 0.015908, loss_ce: 0.007167
2022-01-08 17:40:51,725 iteration 5966 : loss : 0.017879, loss_ce: 0.005597
2022-01-08 17:40:53,121 iteration 5967 : loss : 0.013707, loss_ce: 0.005577

 88%|█████████████████████████▍   | 351/400 [2:30:47<21:04, 25.81s/it]2022-01-08 17:40:54,630 iteration 5968 : loss : 0.017263, loss_ce: 0.006417
2022-01-08 17:40:55,987 iteration 5969 : loss : 0.018920, loss_ce: 0.008810
2022-01-08 17:40:57,397 iteration 5970 : loss : 0.019841, loss_ce: 0.009100
2022-01-08 17:40:58,713 iteration 5971 : loss : 0.011401, loss_ce: 0.003411
2022-01-08 17:40:59,999 iteration 5972 : loss : 0.011361, loss_ce: 0.003528
2022-01-08 17:41:01,379 iteration 5973 : loss : 0.016376, loss_ce: 0.007787
2022-01-08 17:41:02,847 iteration 5974 : loss : 0.031336, loss_ce: 0.012658
2022-01-08 17:41:04,173 iteration 5975 : loss : 0.015485, loss_ce: 0.005221
2022-01-08 17:41:05,519 iteration 5976 : loss : 0.015135, loss_ce: 0.004523
2022-01-08 17:41:06,847 iteration 5977 : loss : 0.016145, loss_ce: 0.004685
2022-01-08 17:41:08,165 iteration 5978 : loss : 0.018338, loss_ce: 0.008267
2022-01-08 17:41:09,528 iteration 5979 : loss : 0.011745, loss_ce: 0.005110
2022-01-08 17:41:10,937 iteration 5980 : loss : 0.013574, loss_ce: 0.004777
2022-01-08 17:41:12,277 iteration 5981 : loss : 0.022950, loss_ce: 0.009572
2022-01-08 17:41:13,648 iteration 5982 : loss : 0.014743, loss_ce: 0.005743
2022-01-08 17:41:15,079 iteration 5983 : loss : 0.024169, loss_ce: 0.007081
2022-01-08 17:41:16,424 iteration 5984 : loss : 0.017747, loss_ce: 0.006012

 88%|█████████████████████████▌   | 352/400 [2:31:10<20:02, 25.06s/it]2022-01-08 17:41:17,864 iteration 5985 : loss : 0.012206, loss_ce: 0.003523
2022-01-08 17:41:19,156 iteration 5986 : loss : 0.013615, loss_ce: 0.004065
2022-01-08 17:41:20,550 iteration 5987 : loss : 0.024168, loss_ce: 0.011735
2022-01-08 17:41:21,974 iteration 5988 : loss : 0.025279, loss_ce: 0.010288
2022-01-08 17:41:23,363 iteration 5989 : loss : 0.013274, loss_ce: 0.005034
2022-01-08 17:41:24,713 iteration 5990 : loss : 0.015112, loss_ce: 0.005295
2022-01-08 17:41:26,108 iteration 5991 : loss : 0.022554, loss_ce: 0.008126
2022-01-08 17:41:27,496 iteration 5992 : loss : 0.018027, loss_ce: 0.007163
2022-01-08 17:41:28,867 iteration 5993 : loss : 0.014923, loss_ce: 0.006583
2022-01-08 17:41:30,284 iteration 5994 : loss : 0.028328, loss_ce: 0.012802
2022-01-08 17:41:31,648 iteration 5995 : loss : 0.013317, loss_ce: 0.005085
2022-01-08 17:41:32,980 iteration 5996 : loss : 0.011982, loss_ce: 0.003488
2022-01-08 17:41:34,378 iteration 5997 : loss : 0.017605, loss_ce: 0.006316
2022-01-08 17:41:35,826 iteration 5998 : loss : 0.017218, loss_ce: 0.006353
2022-01-08 17:41:37,304 iteration 5999 : loss : 0.023059, loss_ce: 0.008052
2022-01-08 17:41:38,697 iteration 6000 : loss : 0.018219, loss_ce: 0.007631
2022-01-08 17:41:39,997 iteration 6001 : loss : 0.014037, loss_ce: 0.006730

 88%|█████████████████████████▌   | 353/400 [2:31:34<19:16, 24.61s/it]2022-01-08 17:41:41,446 iteration 6002 : loss : 0.015631, loss_ce: 0.005459
2022-01-08 17:41:42,792 iteration 6003 : loss : 0.017480, loss_ce: 0.005683
2022-01-08 17:41:44,215 iteration 6004 : loss : 0.014484, loss_ce: 0.006356
2022-01-08 17:41:45,617 iteration 6005 : loss : 0.018555, loss_ce: 0.006971
2022-01-08 17:41:47,100 iteration 6006 : loss : 0.028217, loss_ce: 0.009530
2022-01-08 17:41:48,498 iteration 6007 : loss : 0.010292, loss_ce: 0.004126
2022-01-08 17:41:49,925 iteration 6008 : loss : 0.017717, loss_ce: 0.006584
2022-01-08 17:41:51,224 iteration 6009 : loss : 0.012838, loss_ce: 0.006041
2022-01-08 17:41:52,541 iteration 6010 : loss : 0.012433, loss_ce: 0.005145
2022-01-08 17:41:53,947 iteration 6011 : loss : 0.024601, loss_ce: 0.007227
2022-01-08 17:41:55,384 iteration 6012 : loss : 0.023024, loss_ce: 0.005525
2022-01-08 17:41:56,797 iteration 6013 : loss : 0.019024, loss_ce: 0.006653
2022-01-08 17:41:58,203 iteration 6014 : loss : 0.018560, loss_ce: 0.004842
2022-01-08 17:41:59,549 iteration 6015 : loss : 0.014466, loss_ce: 0.005810
2022-01-08 17:42:00,923 iteration 6016 : loss : 0.015094, loss_ce: 0.005537
2022-01-08 17:42:02,293 iteration 6017 : loss : 0.013965, loss_ce: 0.005933
2022-01-08 17:42:03,690 iteration 6018 : loss : 0.015102, loss_ce: 0.005346

 88%|█████████████████████████▋   | 354/400 [2:31:57<18:39, 24.34s/it]2022-01-08 17:42:05,140 iteration 6019 : loss : 0.018182, loss_ce: 0.009279
2022-01-08 17:42:06,545 iteration 6020 : loss : 0.013459, loss_ce: 0.006398
2022-01-08 17:42:07,938 iteration 6021 : loss : 0.024071, loss_ce: 0.006576
2022-01-08 17:42:09,260 iteration 6022 : loss : 0.015596, loss_ce: 0.006455
2022-01-08 17:42:10,670 iteration 6023 : loss : 0.016432, loss_ce: 0.006181
2022-01-08 17:42:12,055 iteration 6024 : loss : 0.018369, loss_ce: 0.005950
2022-01-08 17:42:13,397 iteration 6025 : loss : 0.016970, loss_ce: 0.006883
2022-01-08 17:42:14,793 iteration 6026 : loss : 0.016812, loss_ce: 0.005595
2022-01-08 17:42:16,181 iteration 6027 : loss : 0.020768, loss_ce: 0.007586
2022-01-08 17:42:17,590 iteration 6028 : loss : 0.016939, loss_ce: 0.006679
2022-01-08 17:42:18,946 iteration 6029 : loss : 0.015459, loss_ce: 0.003972
2022-01-08 17:42:20,291 iteration 6030 : loss : 0.013726, loss_ce: 0.006108
2022-01-08 17:42:21,684 iteration 6031 : loss : 0.015408, loss_ce: 0.007373
2022-01-08 17:42:23,009 iteration 6032 : loss : 0.015314, loss_ce: 0.005058
2022-01-08 17:42:24,427 iteration 6033 : loss : 0.015451, loss_ce: 0.005374
2022-01-08 17:42:25,808 iteration 6034 : loss : 0.016027, loss_ce: 0.006436
2022-01-08 17:42:25,808 Training Data Eval:
2022-01-08 17:42:32,643   Average segmentation loss on training set: 0.0087
2022-01-08 17:42:32,643 Validation Data Eval:
2022-01-08 17:42:34,996   Average segmentation loss on validation set: 0.0627
2022-01-08 17:42:36,263 iteration 6035 : loss : 0.010792, loss_ce: 0.004124

 89%|█████████████████████████▋   | 355/400 [2:32:30<20:06, 26.81s/it]2022-01-08 17:42:37,845 iteration 6036 : loss : 0.031533, loss_ce: 0.008577
2022-01-08 17:42:39,259 iteration 6037 : loss : 0.019987, loss_ce: 0.005926
2022-01-08 17:42:40,620 iteration 6038 : loss : 0.013076, loss_ce: 0.004466
2022-01-08 17:42:41,964 iteration 6039 : loss : 0.013787, loss_ce: 0.004028
2022-01-08 17:42:43,348 iteration 6040 : loss : 0.022170, loss_ce: 0.007548
2022-01-08 17:42:44,686 iteration 6041 : loss : 0.011993, loss_ce: 0.004167
2022-01-08 17:42:46,076 iteration 6042 : loss : 0.012029, loss_ce: 0.005402
2022-01-08 17:42:47,400 iteration 6043 : loss : 0.014081, loss_ce: 0.007023
2022-01-08 17:42:48,708 iteration 6044 : loss : 0.016170, loss_ce: 0.008621
2022-01-08 17:42:50,146 iteration 6045 : loss : 0.019095, loss_ce: 0.007316
2022-01-08 17:42:51,462 iteration 6046 : loss : 0.016317, loss_ce: 0.007356
2022-01-08 17:42:52,782 iteration 6047 : loss : 0.010786, loss_ce: 0.004425
2022-01-08 17:42:54,222 iteration 6048 : loss : 0.017517, loss_ce: 0.005256
2022-01-08 17:42:55,528 iteration 6049 : loss : 0.014859, loss_ce: 0.005246
2022-01-08 17:42:56,827 iteration 6050 : loss : 0.015726, loss_ce: 0.004123
2022-01-08 17:42:58,130 iteration 6051 : loss : 0.011572, loss_ce: 0.004620
2022-01-08 17:42:59,524 iteration 6052 : loss : 0.013342, loss_ce: 0.004883

 89%|█████████████████████████▊   | 356/400 [2:32:53<18:52, 25.74s/it]2022-01-08 17:43:00,924 iteration 6053 : loss : 0.016708, loss_ce: 0.005923
2022-01-08 17:43:02,262 iteration 6054 : loss : 0.014967, loss_ce: 0.004800
2022-01-08 17:43:03,652 iteration 6055 : loss : 0.016141, loss_ce: 0.007647
2022-01-08 17:43:05,007 iteration 6056 : loss : 0.016620, loss_ce: 0.005220
2022-01-08 17:43:06,300 iteration 6057 : loss : 0.013660, loss_ce: 0.005302
2022-01-08 17:43:07,613 iteration 6058 : loss : 0.010654, loss_ce: 0.005458
2022-01-08 17:43:09,036 iteration 6059 : loss : 0.020131, loss_ce: 0.007684
2022-01-08 17:43:10,416 iteration 6060 : loss : 0.015018, loss_ce: 0.004606
2022-01-08 17:43:11,740 iteration 6061 : loss : 0.014941, loss_ce: 0.007196
2022-01-08 17:43:13,232 iteration 6062 : loss : 0.025463, loss_ce: 0.008340
2022-01-08 17:43:14,562 iteration 6063 : loss : 0.013834, loss_ce: 0.006028
2022-01-08 17:43:15,897 iteration 6064 : loss : 0.013665, loss_ce: 0.004895
2022-01-08 17:43:17,291 iteration 6065 : loss : 0.018512, loss_ce: 0.007392
2022-01-08 17:43:18,599 iteration 6066 : loss : 0.012752, loss_ce: 0.005078
2022-01-08 17:43:19,989 iteration 6067 : loss : 0.021538, loss_ce: 0.008541
2022-01-08 17:43:21,356 iteration 6068 : loss : 0.014742, loss_ce: 0.002600
2022-01-08 17:43:22,805 iteration 6069 : loss : 0.021235, loss_ce: 0.009401

 89%|█████████████████████████▉   | 357/400 [2:33:17<17:55, 25.00s/it]2022-01-08 17:43:24,244 iteration 6070 : loss : 0.016028, loss_ce: 0.007381
2022-01-08 17:43:25,618 iteration 6071 : loss : 0.013032, loss_ce: 0.005230
2022-01-08 17:43:26,980 iteration 6072 : loss : 0.018712, loss_ce: 0.007326
2022-01-08 17:43:28,352 iteration 6073 : loss : 0.015868, loss_ce: 0.003999
2022-01-08 17:43:29,643 iteration 6074 : loss : 0.011657, loss_ce: 0.005191
2022-01-08 17:43:31,044 iteration 6075 : loss : 0.019845, loss_ce: 0.009165
2022-01-08 17:43:32,419 iteration 6076 : loss : 0.012687, loss_ce: 0.005097
2022-01-08 17:43:33,684 iteration 6077 : loss : 0.011525, loss_ce: 0.004093
2022-01-08 17:43:35,036 iteration 6078 : loss : 0.014536, loss_ce: 0.007110
2022-01-08 17:43:36,472 iteration 6079 : loss : 0.015290, loss_ce: 0.006463
2022-01-08 17:43:37,778 iteration 6080 : loss : 0.012720, loss_ce: 0.004587
2022-01-08 17:43:39,223 iteration 6081 : loss : 0.023375, loss_ce: 0.009452
2022-01-08 17:43:40,585 iteration 6082 : loss : 0.016348, loss_ce: 0.003445
2022-01-08 17:43:41,994 iteration 6083 : loss : 0.013341, loss_ce: 0.003654
2022-01-08 17:43:43,325 iteration 6084 : loss : 0.018608, loss_ce: 0.005134
2022-01-08 17:43:44,655 iteration 6085 : loss : 0.013210, loss_ce: 0.005261
2022-01-08 17:43:46,173 iteration 6086 : loss : 0.027310, loss_ce: 0.007912

 90%|█████████████████████████▉   | 358/400 [2:33:40<17:09, 24.51s/it]2022-01-08 17:43:47,550 iteration 6087 : loss : 0.012369, loss_ce: 0.004799
2022-01-08 17:43:48,928 iteration 6088 : loss : 0.013037, loss_ce: 0.005769
2022-01-08 17:43:50,282 iteration 6089 : loss : 0.013983, loss_ce: 0.006710
2022-01-08 17:43:51,638 iteration 6090 : loss : 0.016234, loss_ce: 0.003981
2022-01-08 17:43:53,002 iteration 6091 : loss : 0.012779, loss_ce: 0.005240
2022-01-08 17:43:54,380 iteration 6092 : loss : 0.010541, loss_ce: 0.004220
2022-01-08 17:43:55,673 iteration 6093 : loss : 0.016008, loss_ce: 0.005620
2022-01-08 17:43:56,991 iteration 6094 : loss : 0.014542, loss_ce: 0.005186
2022-01-08 17:43:58,381 iteration 6095 : loss : 0.016400, loss_ce: 0.006314
2022-01-08 17:43:59,774 iteration 6096 : loss : 0.016343, loss_ce: 0.005773
2022-01-08 17:44:01,076 iteration 6097 : loss : 0.011840, loss_ce: 0.005332
2022-01-08 17:44:02,453 iteration 6098 : loss : 0.023913, loss_ce: 0.010211
2022-01-08 17:44:03,862 iteration 6099 : loss : 0.025482, loss_ce: 0.005541
2022-01-08 17:44:05,304 iteration 6100 : loss : 0.020441, loss_ce: 0.006182
2022-01-08 17:44:06,718 iteration 6101 : loss : 0.012139, loss_ce: 0.004331
2022-01-08 17:44:08,054 iteration 6102 : loss : 0.022293, loss_ce: 0.009877
2022-01-08 17:44:09,321 iteration 6103 : loss : 0.009580, loss_ce: 0.003597

 90%|██████████████████████████   | 359/400 [2:34:03<16:28, 24.11s/it]2022-01-08 17:44:10,792 iteration 6104 : loss : 0.016306, loss_ce: 0.004672
2022-01-08 17:44:12,115 iteration 6105 : loss : 0.015893, loss_ce: 0.005770
2022-01-08 17:44:13,404 iteration 6106 : loss : 0.012193, loss_ce: 0.004231
2022-01-08 17:44:14,720 iteration 6107 : loss : 0.012888, loss_ce: 0.003908
2022-01-08 17:44:16,130 iteration 6108 : loss : 0.013766, loss_ce: 0.004222
2022-01-08 17:44:17,477 iteration 6109 : loss : 0.015589, loss_ce: 0.005456
2022-01-08 17:44:18,860 iteration 6110 : loss : 0.019769, loss_ce: 0.011242
2022-01-08 17:44:20,283 iteration 6111 : loss : 0.017804, loss_ce: 0.006474
2022-01-08 17:44:21,688 iteration 6112 : loss : 0.013402, loss_ce: 0.004739
2022-01-08 17:44:23,120 iteration 6113 : loss : 0.019728, loss_ce: 0.006520
2022-01-08 17:44:24,476 iteration 6114 : loss : 0.017493, loss_ce: 0.007118
2022-01-08 17:44:25,925 iteration 6115 : loss : 0.029919, loss_ce: 0.010140
2022-01-08 17:44:27,326 iteration 6116 : loss : 0.012366, loss_ce: 0.005164
2022-01-08 17:44:28,665 iteration 6117 : loss : 0.016476, loss_ce: 0.006638
2022-01-08 17:44:30,073 iteration 6118 : loss : 0.018134, loss_ce: 0.007545
2022-01-08 17:44:31,430 iteration 6119 : loss : 0.021030, loss_ce: 0.006332
2022-01-08 17:44:31,430 Training Data Eval:
2022-01-08 17:44:38,262   Average segmentation loss on training set: 0.0087
2022-01-08 17:44:38,263 Validation Data Eval:
2022-01-08 17:44:40,621   Average segmentation loss on validation set: 0.0683
2022-01-08 17:44:41,977 iteration 6120 : loss : 0.014866, loss_ce: 0.006665

 90%|██████████████████████████   | 360/400 [2:34:36<17:46, 26.67s/it]2022-01-08 17:44:43,422 iteration 6121 : loss : 0.014826, loss_ce: 0.006536
2022-01-08 17:44:44,832 iteration 6122 : loss : 0.019133, loss_ce: 0.007167
2022-01-08 17:44:46,282 iteration 6123 : loss : 0.020755, loss_ce: 0.008246
2022-01-08 17:44:47,665 iteration 6124 : loss : 0.014165, loss_ce: 0.004243
2022-01-08 17:44:49,131 iteration 6125 : loss : 0.028634, loss_ce: 0.010169
2022-01-08 17:44:50,496 iteration 6126 : loss : 0.020472, loss_ce: 0.004629
2022-01-08 17:44:51,842 iteration 6127 : loss : 0.014573, loss_ce: 0.005509
2022-01-08 17:44:53,287 iteration 6128 : loss : 0.018882, loss_ce: 0.006223
2022-01-08 17:44:54,668 iteration 6129 : loss : 0.016285, loss_ce: 0.008463
2022-01-08 17:44:56,129 iteration 6130 : loss : 0.015055, loss_ce: 0.005989
2022-01-08 17:44:57,522 iteration 6131 : loss : 0.015692, loss_ce: 0.008162
2022-01-08 17:44:58,911 iteration 6132 : loss : 0.017930, loss_ce: 0.003848
2022-01-08 17:45:00,244 iteration 6133 : loss : 0.011991, loss_ce: 0.005754
2022-01-08 17:45:01,543 iteration 6134 : loss : 0.010857, loss_ce: 0.004505
2022-01-08 17:45:02,850 iteration 6135 : loss : 0.012854, loss_ce: 0.005364
2022-01-08 17:45:04,237 iteration 6136 : loss : 0.012923, loss_ce: 0.004319
2022-01-08 17:45:05,589 iteration 6137 : loss : 0.016696, loss_ce: 0.005912

 90%|██████████████████████████▏  | 361/400 [2:34:59<16:44, 25.75s/it]2022-01-08 17:45:06,975 iteration 6138 : loss : 0.011291, loss_ce: 0.003985
2022-01-08 17:45:08,378 iteration 6139 : loss : 0.014441, loss_ce: 0.005957
2022-01-08 17:45:09,740 iteration 6140 : loss : 0.012853, loss_ce: 0.004501
2022-01-08 17:45:11,143 iteration 6141 : loss : 0.016110, loss_ce: 0.006124
2022-01-08 17:45:12,657 iteration 6142 : loss : 0.025167, loss_ce: 0.007815
2022-01-08 17:45:13,976 iteration 6143 : loss : 0.014438, loss_ce: 0.007369
2022-01-08 17:45:15,363 iteration 6144 : loss : 0.010692, loss_ce: 0.004437
2022-01-08 17:45:16,751 iteration 6145 : loss : 0.022352, loss_ce: 0.006933
2022-01-08 17:45:18,118 iteration 6146 : loss : 0.014607, loss_ce: 0.005973
2022-01-08 17:45:19,487 iteration 6147 : loss : 0.013219, loss_ce: 0.003179
2022-01-08 17:45:20,810 iteration 6148 : loss : 0.010044, loss_ce: 0.003158
2022-01-08 17:45:22,129 iteration 6149 : loss : 0.017248, loss_ce: 0.005901
2022-01-08 17:45:23,472 iteration 6150 : loss : 0.035795, loss_ce: 0.010154
2022-01-08 17:45:24,835 iteration 6151 : loss : 0.018268, loss_ce: 0.004259
2022-01-08 17:45:26,160 iteration 6152 : loss : 0.014821, loss_ce: 0.005660
2022-01-08 17:45:27,587 iteration 6153 : loss : 0.016717, loss_ce: 0.006664
2022-01-08 17:45:29,054 iteration 6154 : loss : 0.019973, loss_ce: 0.007916

 90%|██████████████████████████▏  | 362/400 [2:35:23<15:52, 25.06s/it]2022-01-08 17:45:30,463 iteration 6155 : loss : 0.016915, loss_ce: 0.007736
2022-01-08 17:45:31,827 iteration 6156 : loss : 0.012336, loss_ce: 0.005413
2022-01-08 17:45:33,244 iteration 6157 : loss : 0.017084, loss_ce: 0.005517
2022-01-08 17:45:34,592 iteration 6158 : loss : 0.014195, loss_ce: 0.004648
2022-01-08 17:45:35,880 iteration 6159 : loss : 0.009733, loss_ce: 0.003936
2022-01-08 17:45:37,426 iteration 6160 : loss : 0.021982, loss_ce: 0.010635
2022-01-08 17:45:38,726 iteration 6161 : loss : 0.015877, loss_ce: 0.004840
2022-01-08 17:45:40,117 iteration 6162 : loss : 0.013081, loss_ce: 0.005057
2022-01-08 17:45:41,479 iteration 6163 : loss : 0.012191, loss_ce: 0.004483
2022-01-08 17:45:42,815 iteration 6164 : loss : 0.014315, loss_ce: 0.004403
2022-01-08 17:45:44,196 iteration 6165 : loss : 0.017761, loss_ce: 0.005601
2022-01-08 17:45:45,598 iteration 6166 : loss : 0.023495, loss_ce: 0.011700
2022-01-08 17:45:46,895 iteration 6167 : loss : 0.012043, loss_ce: 0.003832
2022-01-08 17:45:48,363 iteration 6168 : loss : 0.034014, loss_ce: 0.009850
2022-01-08 17:45:49,722 iteration 6169 : loss : 0.015637, loss_ce: 0.007424
2022-01-08 17:45:51,123 iteration 6170 : loss : 0.012233, loss_ce: 0.005036
2022-01-08 17:45:52,492 iteration 6171 : loss : 0.014082, loss_ce: 0.003898

 91%|██████████████████████████▎  | 363/400 [2:35:46<15:09, 24.58s/it]2022-01-08 17:45:53,915 iteration 6172 : loss : 0.014583, loss_ce: 0.005069
2022-01-08 17:45:55,198 iteration 6173 : loss : 0.010717, loss_ce: 0.003783
2022-01-08 17:45:56,541 iteration 6174 : loss : 0.014253, loss_ce: 0.006506
2022-01-08 17:45:57,845 iteration 6175 : loss : 0.010358, loss_ce: 0.002958
2022-01-08 17:45:59,234 iteration 6176 : loss : 0.015393, loss_ce: 0.007834
2022-01-08 17:46:00,697 iteration 6177 : loss : 0.017283, loss_ce: 0.007884
2022-01-08 17:46:02,124 iteration 6178 : loss : 0.014720, loss_ce: 0.005012
2022-01-08 17:46:03,531 iteration 6179 : loss : 0.017439, loss_ce: 0.005402
2022-01-08 17:46:04,935 iteration 6180 : loss : 0.026319, loss_ce: 0.004314
2022-01-08 17:46:06,281 iteration 6181 : loss : 0.017360, loss_ce: 0.006667
2022-01-08 17:46:07,671 iteration 6182 : loss : 0.012389, loss_ce: 0.004686
2022-01-08 17:46:09,004 iteration 6183 : loss : 0.017750, loss_ce: 0.006256
2022-01-08 17:46:10,328 iteration 6184 : loss : 0.013443, loss_ce: 0.005344
2022-01-08 17:46:11,742 iteration 6185 : loss : 0.027850, loss_ce: 0.008642
2022-01-08 17:46:13,052 iteration 6186 : loss : 0.012152, loss_ce: 0.004337
2022-01-08 17:46:14,379 iteration 6187 : loss : 0.016697, loss_ce: 0.004837
2022-01-08 17:46:15,700 iteration 6188 : loss : 0.014911, loss_ce: 0.005871

 91%|██████████████████████████▍  | 364/400 [2:36:09<14:30, 24.17s/it]2022-01-08 17:46:17,208 iteration 6189 : loss : 0.023577, loss_ce: 0.008666
2022-01-08 17:46:18,591 iteration 6190 : loss : 0.012199, loss_ce: 0.004479
2022-01-08 17:46:20,028 iteration 6191 : loss : 0.012329, loss_ce: 0.003558
2022-01-08 17:46:21,435 iteration 6192 : loss : 0.014847, loss_ce: 0.005247
2022-01-08 17:46:22,772 iteration 6193 : loss : 0.011209, loss_ce: 0.003466
2022-01-08 17:46:24,184 iteration 6194 : loss : 0.012223, loss_ce: 0.004598
2022-01-08 17:46:25,625 iteration 6195 : loss : 0.021500, loss_ce: 0.007353
2022-01-08 17:46:26,959 iteration 6196 : loss : 0.018875, loss_ce: 0.006118
2022-01-08 17:46:28,416 iteration 6197 : loss : 0.024003, loss_ce: 0.007878
2022-01-08 17:46:29,881 iteration 6198 : loss : 0.026886, loss_ce: 0.012342
2022-01-08 17:46:31,226 iteration 6199 : loss : 0.011579, loss_ce: 0.004451
2022-01-08 17:46:32,628 iteration 6200 : loss : 0.022191, loss_ce: 0.008650
2022-01-08 17:46:34,003 iteration 6201 : loss : 0.016742, loss_ce: 0.007596
2022-01-08 17:46:35,364 iteration 6202 : loss : 0.016144, loss_ce: 0.004811
2022-01-08 17:46:36,717 iteration 6203 : loss : 0.018323, loss_ce: 0.006266
2022-01-08 17:46:38,132 iteration 6204 : loss : 0.014747, loss_ce: 0.008125
2022-01-08 17:46:38,132 Training Data Eval:
2022-01-08 17:46:44,960   Average segmentation loss on training set: 0.0083
2022-01-08 17:46:44,960 Validation Data Eval:
2022-01-08 17:46:47,314   Average segmentation loss on validation set: 0.0643
2022-01-08 17:46:48,780 iteration 6205 : loss : 0.027471, loss_ce: 0.017220

 91%|██████████████████████████▍  | 365/400 [2:36:43<15:39, 26.84s/it]2022-01-08 17:46:50,233 iteration 6206 : loss : 0.013800, loss_ce: 0.005822
2022-01-08 17:46:51,615 iteration 6207 : loss : 0.017507, loss_ce: 0.009566
2022-01-08 17:46:53,014 iteration 6208 : loss : 0.014396, loss_ce: 0.005115
2022-01-08 17:46:54,409 iteration 6209 : loss : 0.027979, loss_ce: 0.010507
2022-01-08 17:46:55,761 iteration 6210 : loss : 0.016330, loss_ce: 0.005801
2022-01-08 17:46:57,080 iteration 6211 : loss : 0.012663, loss_ce: 0.004535
2022-01-08 17:46:58,424 iteration 6212 : loss : 0.014227, loss_ce: 0.005354
2022-01-08 17:46:59,793 iteration 6213 : loss : 0.012174, loss_ce: 0.004819
2022-01-08 17:47:01,145 iteration 6214 : loss : 0.010140, loss_ce: 0.003770
2022-01-08 17:47:02,569 iteration 6215 : loss : 0.017727, loss_ce: 0.006605
2022-01-08 17:47:03,927 iteration 6216 : loss : 0.014755, loss_ce: 0.005391
2022-01-08 17:47:05,228 iteration 6217 : loss : 0.014978, loss_ce: 0.005145
2022-01-08 17:47:06,601 iteration 6218 : loss : 0.016864, loss_ce: 0.006966
2022-01-08 17:47:07,961 iteration 6219 : loss : 0.013785, loss_ce: 0.004495
2022-01-08 17:47:09,298 iteration 6220 : loss : 0.012437, loss_ce: 0.002818
2022-01-08 17:47:10,687 iteration 6221 : loss : 0.012674, loss_ce: 0.003686
2022-01-08 17:47:12,010 iteration 6222 : loss : 0.011286, loss_ce: 0.005363

 92%|██████████████████████████▌  | 366/400 [2:37:06<14:35, 25.76s/it]2022-01-08 17:47:13,468 iteration 6223 : loss : 0.018416, loss_ce: 0.008609
2022-01-08 17:47:14,831 iteration 6224 : loss : 0.015292, loss_ce: 0.005682
2022-01-08 17:47:16,210 iteration 6225 : loss : 0.016824, loss_ce: 0.005335
2022-01-08 17:47:17,544 iteration 6226 : loss : 0.013244, loss_ce: 0.004493
2022-01-08 17:47:18,860 iteration 6227 : loss : 0.012653, loss_ce: 0.004988
2022-01-08 17:47:20,235 iteration 6228 : loss : 0.014223, loss_ce: 0.005747
2022-01-08 17:47:21,616 iteration 6229 : loss : 0.010461, loss_ce: 0.004685
2022-01-08 17:47:23,018 iteration 6230 : loss : 0.014433, loss_ce: 0.004151
2022-01-08 17:47:24,439 iteration 6231 : loss : 0.017825, loss_ce: 0.007385
2022-01-08 17:47:25,829 iteration 6232 : loss : 0.013349, loss_ce: 0.005325
2022-01-08 17:47:27,200 iteration 6233 : loss : 0.014909, loss_ce: 0.006510
2022-01-08 17:47:28,547 iteration 6234 : loss : 0.016658, loss_ce: 0.003831
2022-01-08 17:47:29,874 iteration 6235 : loss : 0.015230, loss_ce: 0.008604
2022-01-08 17:47:31,244 iteration 6236 : loss : 0.013094, loss_ce: 0.006581
2022-01-08 17:47:32,633 iteration 6237 : loss : 0.018341, loss_ce: 0.008544
2022-01-08 17:47:34,072 iteration 6238 : loss : 0.013296, loss_ce: 0.003982
2022-01-08 17:47:35,452 iteration 6239 : loss : 0.012054, loss_ce: 0.003278

 92%|██████████████████████████▌  | 367/400 [2:37:29<13:47, 25.06s/it]2022-01-08 17:47:36,865 iteration 6240 : loss : 0.009411, loss_ce: 0.002747
2022-01-08 17:47:38,195 iteration 6241 : loss : 0.011768, loss_ce: 0.005817
2022-01-08 17:47:39,637 iteration 6242 : loss : 0.018980, loss_ce: 0.006287
2022-01-08 17:47:41,001 iteration 6243 : loss : 0.010495, loss_ce: 0.004166
2022-01-08 17:47:42,452 iteration 6244 : loss : 0.014415, loss_ce: 0.005181
2022-01-08 17:47:43,816 iteration 6245 : loss : 0.015146, loss_ce: 0.005386
2022-01-08 17:47:45,170 iteration 6246 : loss : 0.014370, loss_ce: 0.005579
2022-01-08 17:47:46,562 iteration 6247 : loss : 0.014895, loss_ce: 0.003429
2022-01-08 17:47:47,920 iteration 6248 : loss : 0.014789, loss_ce: 0.004888
2022-01-08 17:47:49,279 iteration 6249 : loss : 0.029963, loss_ce: 0.009290
2022-01-08 17:47:50,678 iteration 6250 : loss : 0.020583, loss_ce: 0.008804
2022-01-08 17:47:52,136 iteration 6251 : loss : 0.015179, loss_ce: 0.006049
2022-01-08 17:47:53,471 iteration 6252 : loss : 0.013482, loss_ce: 0.006244
2022-01-08 17:47:54,918 iteration 6253 : loss : 0.014925, loss_ce: 0.005992
2022-01-08 17:47:56,270 iteration 6254 : loss : 0.014496, loss_ce: 0.006423
2022-01-08 17:47:57,658 iteration 6255 : loss : 0.013171, loss_ce: 0.005248
2022-01-08 17:47:59,102 iteration 6256 : loss : 0.017691, loss_ce: 0.007463

 92%|██████████████████████████▋  | 368/400 [2:37:53<13:08, 24.64s/it]2022-01-08 17:48:00,578 iteration 6257 : loss : 0.015071, loss_ce: 0.004617
2022-01-08 17:48:02,003 iteration 6258 : loss : 0.017817, loss_ce: 0.007857
2022-01-08 17:48:03,442 iteration 6259 : loss : 0.014935, loss_ce: 0.005862
2022-01-08 17:48:04,804 iteration 6260 : loss : 0.015421, loss_ce: 0.006291
2022-01-08 17:48:06,163 iteration 6261 : loss : 0.013734, loss_ce: 0.004838
2022-01-08 17:48:07,557 iteration 6262 : loss : 0.017380, loss_ce: 0.004615
2022-01-08 17:48:08,947 iteration 6263 : loss : 0.016590, loss_ce: 0.003781
2022-01-08 17:48:10,343 iteration 6264 : loss : 0.016005, loss_ce: 0.006388
2022-01-08 17:48:11,734 iteration 6265 : loss : 0.013623, loss_ce: 0.005249
2022-01-08 17:48:13,090 iteration 6266 : loss : 0.014570, loss_ce: 0.007577
2022-01-08 17:48:14,429 iteration 6267 : loss : 0.013362, loss_ce: 0.005608
2022-01-08 17:48:15,804 iteration 6268 : loss : 0.012609, loss_ce: 0.004910
2022-01-08 17:48:17,053 iteration 6269 : loss : 0.011109, loss_ce: 0.003723
2022-01-08 17:48:18,409 iteration 6270 : loss : 0.011806, loss_ce: 0.005085
2022-01-08 17:48:19,768 iteration 6271 : loss : 0.015619, loss_ce: 0.004281
2022-01-08 17:48:21,182 iteration 6272 : loss : 0.015460, loss_ce: 0.005554
2022-01-08 17:48:22,583 iteration 6273 : loss : 0.012641, loss_ce: 0.004945

 92%|██████████████████████████▊  | 369/400 [2:38:16<12:33, 24.29s/it]2022-01-08 17:48:24,138 iteration 6274 : loss : 0.021909, loss_ce: 0.007558
2022-01-08 17:48:25,539 iteration 6275 : loss : 0.016033, loss_ce: 0.009333
2022-01-08 17:48:26,923 iteration 6276 : loss : 0.012721, loss_ce: 0.004949
2022-01-08 17:48:28,261 iteration 6277 : loss : 0.011511, loss_ce: 0.003362
2022-01-08 17:48:29,645 iteration 6278 : loss : 0.013854, loss_ce: 0.004999
2022-01-08 17:48:31,008 iteration 6279 : loss : 0.021130, loss_ce: 0.013083
2022-01-08 17:48:32,347 iteration 6280 : loss : 0.016968, loss_ce: 0.006215
2022-01-08 17:48:33,826 iteration 6281 : loss : 0.026303, loss_ce: 0.006056
2022-01-08 17:48:35,190 iteration 6282 : loss : 0.011579, loss_ce: 0.004646
2022-01-08 17:48:36,529 iteration 6283 : loss : 0.012599, loss_ce: 0.005393
2022-01-08 17:48:37,905 iteration 6284 : loss : 0.015489, loss_ce: 0.006753
2022-01-08 17:48:39,318 iteration 6285 : loss : 0.015242, loss_ce: 0.006002
2022-01-08 17:48:40,668 iteration 6286 : loss : 0.015915, loss_ce: 0.004680
2022-01-08 17:48:42,016 iteration 6287 : loss : 0.016660, loss_ce: 0.005027
2022-01-08 17:48:43,308 iteration 6288 : loss : 0.010321, loss_ce: 0.003447
2022-01-08 17:48:44,695 iteration 6289 : loss : 0.012743, loss_ce: 0.005476
2022-01-08 17:48:44,695 Training Data Eval:
2022-01-08 17:48:51,526   Average segmentation loss on training set: 0.0081
2022-01-08 17:48:51,526 Validation Data Eval:
2022-01-08 17:48:53,888   Average segmentation loss on validation set: 0.0643
2022-01-08 17:48:55,295 iteration 6290 : loss : 0.017916, loss_ce: 0.008185

 92%|██████████████████████████▊  | 370/400 [2:38:49<13:24, 26.82s/it]2022-01-08 17:48:56,715 iteration 6291 : loss : 0.014651, loss_ce: 0.006147
2022-01-08 17:48:58,090 iteration 6292 : loss : 0.015115, loss_ce: 0.005124
2022-01-08 17:48:59,488 iteration 6293 : loss : 0.023851, loss_ce: 0.011780
2022-01-08 17:49:00,902 iteration 6294 : loss : 0.021207, loss_ce: 0.006373
2022-01-08 17:49:02,268 iteration 6295 : loss : 0.012260, loss_ce: 0.005308
2022-01-08 17:49:03,713 iteration 6296 : loss : 0.014107, loss_ce: 0.004807
2022-01-08 17:49:05,101 iteration 6297 : loss : 0.021111, loss_ce: 0.006993
2022-01-08 17:49:06,517 iteration 6298 : loss : 0.038527, loss_ce: 0.015940
2022-01-08 17:49:07,886 iteration 6299 : loss : 0.013472, loss_ce: 0.004552
2022-01-08 17:49:09,235 iteration 6300 : loss : 0.012105, loss_ce: 0.004318
2022-01-08 17:49:10,577 iteration 6301 : loss : 0.015174, loss_ce: 0.009030
2022-01-08 17:49:11,967 iteration 6302 : loss : 0.014359, loss_ce: 0.004853
2022-01-08 17:49:13,254 iteration 6303 : loss : 0.011368, loss_ce: 0.002604
2022-01-08 17:49:14,552 iteration 6304 : loss : 0.012680, loss_ce: 0.003935
2022-01-08 17:49:15,938 iteration 6305 : loss : 0.019461, loss_ce: 0.008274
2022-01-08 17:49:17,289 iteration 6306 : loss : 0.016083, loss_ce: 0.003908
2022-01-08 17:49:18,646 iteration 6307 : loss : 0.011843, loss_ce: 0.005381

 93%|██████████████████████████▉  | 371/400 [2:39:12<12:27, 25.78s/it]2022-01-08 17:49:20,021 iteration 6308 : loss : 0.013135, loss_ce: 0.002861
2022-01-08 17:49:21,401 iteration 6309 : loss : 0.017347, loss_ce: 0.007476
2022-01-08 17:49:22,762 iteration 6310 : loss : 0.016564, loss_ce: 0.007145
2022-01-08 17:49:24,143 iteration 6311 : loss : 0.012608, loss_ce: 0.004942
2022-01-08 17:49:25,535 iteration 6312 : loss : 0.021780, loss_ce: 0.007273
2022-01-08 17:49:26,976 iteration 6313 : loss : 0.015673, loss_ce: 0.006111
2022-01-08 17:49:28,341 iteration 6314 : loss : 0.014418, loss_ce: 0.005397
2022-01-08 17:49:29,677 iteration 6315 : loss : 0.012865, loss_ce: 0.004361
2022-01-08 17:49:31,040 iteration 6316 : loss : 0.013600, loss_ce: 0.004612
2022-01-08 17:49:32,399 iteration 6317 : loss : 0.015708, loss_ce: 0.004399
2022-01-08 17:49:33,828 iteration 6318 : loss : 0.020273, loss_ce: 0.007309
2022-01-08 17:49:35,220 iteration 6319 : loss : 0.013654, loss_ce: 0.004761
2022-01-08 17:49:36,579 iteration 6320 : loss : 0.015663, loss_ce: 0.005411
2022-01-08 17:49:37,998 iteration 6321 : loss : 0.014559, loss_ce: 0.006879
2022-01-08 17:49:39,426 iteration 6322 : loss : 0.020962, loss_ce: 0.010899
2022-01-08 17:49:40,934 iteration 6323 : loss : 0.014362, loss_ce: 0.004284
2022-01-08 17:49:42,386 iteration 6324 : loss : 0.016812, loss_ce: 0.008020

 93%|██████████████████████████▉  | 372/400 [2:39:36<11:44, 25.17s/it]2022-01-08 17:49:43,851 iteration 6325 : loss : 0.014814, loss_ce: 0.004435
2022-01-08 17:49:45,204 iteration 6326 : loss : 0.014327, loss_ce: 0.005960
2022-01-08 17:49:46,572 iteration 6327 : loss : 0.014590, loss_ce: 0.004917
2022-01-08 17:49:47,997 iteration 6328 : loss : 0.012275, loss_ce: 0.005850
2022-01-08 17:49:49,306 iteration 6329 : loss : 0.012702, loss_ce: 0.006247
2022-01-08 17:49:50,667 iteration 6330 : loss : 0.016664, loss_ce: 0.006971
2022-01-08 17:49:52,095 iteration 6331 : loss : 0.013366, loss_ce: 0.004841
2022-01-08 17:49:53,500 iteration 6332 : loss : 0.013645, loss_ce: 0.003682
2022-01-08 17:49:54,875 iteration 6333 : loss : 0.009969, loss_ce: 0.004379
2022-01-08 17:49:56,247 iteration 6334 : loss : 0.019230, loss_ce: 0.005359
2022-01-08 17:49:57,706 iteration 6335 : loss : 0.017200, loss_ce: 0.008078
2022-01-08 17:49:59,055 iteration 6336 : loss : 0.012568, loss_ce: 0.005040
2022-01-08 17:50:00,447 iteration 6337 : loss : 0.013234, loss_ce: 0.004325
2022-01-08 17:50:01,851 iteration 6338 : loss : 0.020433, loss_ce: 0.005536
2022-01-08 17:50:03,221 iteration 6339 : loss : 0.013156, loss_ce: 0.004274
2022-01-08 17:50:04,595 iteration 6340 : loss : 0.018853, loss_ce: 0.009245
2022-01-08 17:50:05,895 iteration 6341 : loss : 0.012078, loss_ce: 0.004220

 93%|███████████████████████████  | 373/400 [2:40:00<11:06, 24.67s/it]2022-01-08 17:50:07,369 iteration 6342 : loss : 0.020253, loss_ce: 0.005253
2022-01-08 17:50:08,725 iteration 6343 : loss : 0.011559, loss_ce: 0.004704
2022-01-08 17:50:10,076 iteration 6344 : loss : 0.015260, loss_ce: 0.004698
2022-01-08 17:50:11,418 iteration 6345 : loss : 0.016533, loss_ce: 0.002628
2022-01-08 17:50:12,802 iteration 6346 : loss : 0.020821, loss_ce: 0.006313
2022-01-08 17:50:14,182 iteration 6347 : loss : 0.015596, loss_ce: 0.005802
2022-01-08 17:50:15,468 iteration 6348 : loss : 0.009653, loss_ce: 0.003990
2022-01-08 17:50:16,849 iteration 6349 : loss : 0.014273, loss_ce: 0.006378
2022-01-08 17:50:18,329 iteration 6350 : loss : 0.024827, loss_ce: 0.008667
2022-01-08 17:50:19,758 iteration 6351 : loss : 0.016502, loss_ce: 0.007295
2022-01-08 17:50:21,132 iteration 6352 : loss : 0.024034, loss_ce: 0.007756
2022-01-08 17:50:22,513 iteration 6353 : loss : 0.024442, loss_ce: 0.008994
2022-01-08 17:50:23,888 iteration 6354 : loss : 0.021151, loss_ce: 0.009234
2022-01-08 17:50:25,238 iteration 6355 : loss : 0.015183, loss_ce: 0.005153
2022-01-08 17:50:26,667 iteration 6356 : loss : 0.021252, loss_ce: 0.005973
2022-01-08 17:50:28,044 iteration 6357 : loss : 0.016610, loss_ce: 0.005867
2022-01-08 17:50:29,521 iteration 6358 : loss : 0.016835, loss_ce: 0.007443

 94%|███████████████████████████  | 374/400 [2:40:23<10:33, 24.36s/it]2022-01-08 17:50:31,013 iteration 6359 : loss : 0.020319, loss_ce: 0.005455
2022-01-08 17:50:32,340 iteration 6360 : loss : 0.013984, loss_ce: 0.006156
2022-01-08 17:50:33,742 iteration 6361 : loss : 0.013964, loss_ce: 0.004459
2022-01-08 17:50:35,151 iteration 6362 : loss : 0.022899, loss_ce: 0.011556
2022-01-08 17:50:36,579 iteration 6363 : loss : 0.026205, loss_ce: 0.010680
2022-01-08 17:50:37,921 iteration 6364 : loss : 0.012719, loss_ce: 0.003640
2022-01-08 17:50:39,309 iteration 6365 : loss : 0.015163, loss_ce: 0.008257
2022-01-08 17:50:40,773 iteration 6366 : loss : 0.017712, loss_ce: 0.006993
2022-01-08 17:50:42,259 iteration 6367 : loss : 0.021025, loss_ce: 0.008010
2022-01-08 17:50:43,687 iteration 6368 : loss : 0.018951, loss_ce: 0.007885
2022-01-08 17:50:45,066 iteration 6369 : loss : 0.012220, loss_ce: 0.004963
2022-01-08 17:50:46,454 iteration 6370 : loss : 0.012384, loss_ce: 0.004049
2022-01-08 17:50:47,925 iteration 6371 : loss : 0.023062, loss_ce: 0.008243
2022-01-08 17:50:49,269 iteration 6372 : loss : 0.011458, loss_ce: 0.004896
2022-01-08 17:50:50,606 iteration 6373 : loss : 0.011213, loss_ce: 0.004015
2022-01-08 17:50:51,987 iteration 6374 : loss : 0.017295, loss_ce: 0.006570
2022-01-08 17:50:51,987 Training Data Eval:
2022-01-08 17:50:58,821   Average segmentation loss on training set: 0.0081
2022-01-08 17:50:58,822 Validation Data Eval:
2022-01-08 17:51:01,180   Average segmentation loss on validation set: 0.0635
2022-01-08 17:51:02,564 iteration 6375 : loss : 0.019772, loss_ce: 0.006602

 94%|███████████████████████████▏ | 375/400 [2:40:56<11:14, 26.96s/it]2022-01-08 17:51:04,031 iteration 6376 : loss : 0.019811, loss_ce: 0.005910
2022-01-08 17:51:05,423 iteration 6377 : loss : 0.012469, loss_ce: 0.004478
2022-01-08 17:51:06,708 iteration 6378 : loss : 0.011332, loss_ce: 0.004830
2022-01-08 17:51:08,074 iteration 6379 : loss : 0.020658, loss_ce: 0.004632
2022-01-08 17:51:09,414 iteration 6380 : loss : 0.014887, loss_ce: 0.005296
2022-01-08 17:51:10,747 iteration 6381 : loss : 0.009529, loss_ce: 0.003079
2022-01-08 17:51:12,031 iteration 6382 : loss : 0.013619, loss_ce: 0.005187
2022-01-08 17:51:13,436 iteration 6383 : loss : 0.017108, loss_ce: 0.006314
2022-01-08 17:51:14,777 iteration 6384 : loss : 0.013378, loss_ce: 0.005811
2022-01-08 17:51:16,179 iteration 6385 : loss : 0.015148, loss_ce: 0.004963
2022-01-08 17:51:17,600 iteration 6386 : loss : 0.022991, loss_ce: 0.007198
2022-01-08 17:51:19,067 iteration 6387 : loss : 0.016576, loss_ce: 0.006667
2022-01-08 17:51:20,475 iteration 6388 : loss : 0.017503, loss_ce: 0.007059
2022-01-08 17:51:21,744 iteration 6389 : loss : 0.011785, loss_ce: 0.003960
2022-01-08 17:51:23,116 iteration 6390 : loss : 0.013590, loss_ce: 0.005857
2022-01-08 17:51:24,446 iteration 6391 : loss : 0.014939, loss_ce: 0.009001
2022-01-08 17:51:25,880 iteration 6392 : loss : 0.018075, loss_ce: 0.004910

 94%|███████████████████████████▎ | 376/400 [2:41:20<10:20, 25.87s/it]2022-01-08 17:51:27,308 iteration 6393 : loss : 0.013511, loss_ce: 0.004858
2022-01-08 17:51:28,727 iteration 6394 : loss : 0.013900, loss_ce: 0.004851
2022-01-08 17:51:30,086 iteration 6395 : loss : 0.014177, loss_ce: 0.004079
2022-01-08 17:51:31,453 iteration 6396 : loss : 0.012242, loss_ce: 0.004418
2022-01-08 17:51:32,845 iteration 6397 : loss : 0.014381, loss_ce: 0.006035
2022-01-08 17:51:34,250 iteration 6398 : loss : 0.014766, loss_ce: 0.004977
2022-01-08 17:51:35,619 iteration 6399 : loss : 0.024397, loss_ce: 0.007598
2022-01-08 17:51:36,974 iteration 6400 : loss : 0.011391, loss_ce: 0.004699
2022-01-08 17:51:38,377 iteration 6401 : loss : 0.013998, loss_ce: 0.005432
2022-01-08 17:51:39,738 iteration 6402 : loss : 0.014211, loss_ce: 0.007259
2022-01-08 17:51:41,185 iteration 6403 : loss : 0.015370, loss_ce: 0.006321
2022-01-08 17:51:42,544 iteration 6404 : loss : 0.011970, loss_ce: 0.005023
2022-01-08 17:51:43,886 iteration 6405 : loss : 0.018562, loss_ce: 0.005439
2022-01-08 17:51:45,407 iteration 6406 : loss : 0.031259, loss_ce: 0.007281
2022-01-08 17:51:46,813 iteration 6407 : loss : 0.028328, loss_ce: 0.007671
2022-01-08 17:51:48,090 iteration 6408 : loss : 0.010837, loss_ce: 0.003796
2022-01-08 17:51:49,447 iteration 6409 : loss : 0.011612, loss_ce: 0.004748

 94%|███████████████████████████▎ | 377/400 [2:41:43<09:39, 25.18s/it]2022-01-08 17:51:50,843 iteration 6410 : loss : 0.011906, loss_ce: 0.003599
2022-01-08 17:51:52,242 iteration 6411 : loss : 0.015416, loss_ce: 0.006237
2022-01-08 17:51:53,641 iteration 6412 : loss : 0.014480, loss_ce: 0.004759
2022-01-08 17:51:55,004 iteration 6413 : loss : 0.020825, loss_ce: 0.008213
2022-01-08 17:51:56,353 iteration 6414 : loss : 0.013136, loss_ce: 0.005425
2022-01-08 17:51:57,681 iteration 6415 : loss : 0.011609, loss_ce: 0.004014
2022-01-08 17:51:59,060 iteration 6416 : loss : 0.009845, loss_ce: 0.003786
2022-01-08 17:52:00,377 iteration 6417 : loss : 0.012148, loss_ce: 0.004660
2022-01-08 17:52:01,726 iteration 6418 : loss : 0.013730, loss_ce: 0.005149
2022-01-08 17:52:03,185 iteration 6419 : loss : 0.020929, loss_ce: 0.008053
2022-01-08 17:52:04,675 iteration 6420 : loss : 0.023759, loss_ce: 0.005537
2022-01-08 17:52:06,084 iteration 6421 : loss : 0.017996, loss_ce: 0.007616
2022-01-08 17:52:07,466 iteration 6422 : loss : 0.016761, loss_ce: 0.005007
2022-01-08 17:52:08,871 iteration 6423 : loss : 0.015564, loss_ce: 0.005824
2022-01-08 17:52:10,340 iteration 6424 : loss : 0.024194, loss_ce: 0.014104
2022-01-08 17:52:11,706 iteration 6425 : loss : 0.019175, loss_ce: 0.005444
2022-01-08 17:52:13,151 iteration 6426 : loss : 0.032013, loss_ce: 0.011550

 94%|███████████████████████████▍ | 378/400 [2:42:07<09:04, 24.73s/it]2022-01-08 17:52:14,614 iteration 6427 : loss : 0.012856, loss_ce: 0.004483
2022-01-08 17:52:16,002 iteration 6428 : loss : 0.014567, loss_ce: 0.004435
2022-01-08 17:52:17,388 iteration 6429 : loss : 0.018183, loss_ce: 0.005647
2022-01-08 17:52:18,812 iteration 6430 : loss : 0.017685, loss_ce: 0.007173
2022-01-08 17:52:20,127 iteration 6431 : loss : 0.014844, loss_ce: 0.005315
2022-01-08 17:52:21,517 iteration 6432 : loss : 0.011631, loss_ce: 0.004449
2022-01-08 17:52:22,893 iteration 6433 : loss : 0.012776, loss_ce: 0.004126
2022-01-08 17:52:24,232 iteration 6434 : loss : 0.014090, loss_ce: 0.005291
2022-01-08 17:52:25,600 iteration 6435 : loss : 0.017561, loss_ce: 0.006847
2022-01-08 17:52:26,955 iteration 6436 : loss : 0.013159, loss_ce: 0.005782
2022-01-08 17:52:28,331 iteration 6437 : loss : 0.012569, loss_ce: 0.003959
2022-01-08 17:52:29,741 iteration 6438 : loss : 0.015025, loss_ce: 0.004305
2022-01-08 17:52:31,078 iteration 6439 : loss : 0.016470, loss_ce: 0.009770
2022-01-08 17:52:32,491 iteration 6440 : loss : 0.016924, loss_ce: 0.008044
2022-01-08 17:52:33,807 iteration 6441 : loss : 0.011380, loss_ce: 0.004907
2022-01-08 17:52:35,195 iteration 6442 : loss : 0.013061, loss_ce: 0.003918
2022-01-08 17:52:36,499 iteration 6443 : loss : 0.010866, loss_ce: 0.003427

 95%|███████████████████████████▍ | 379/400 [2:42:30<08:30, 24.32s/it]2022-01-08 17:52:37,946 iteration 6444 : loss : 0.012968, loss_ce: 0.006043
2022-01-08 17:52:39,320 iteration 6445 : loss : 0.012813, loss_ce: 0.005217
2022-01-08 17:52:40,713 iteration 6446 : loss : 0.018857, loss_ce: 0.007718
2022-01-08 17:52:42,116 iteration 6447 : loss : 0.038283, loss_ce: 0.007841
2022-01-08 17:52:43,527 iteration 6448 : loss : 0.019515, loss_ce: 0.006956
2022-01-08 17:52:44,876 iteration 6449 : loss : 0.014233, loss_ce: 0.003086
2022-01-08 17:52:46,206 iteration 6450 : loss : 0.014078, loss_ce: 0.006283
2022-01-08 17:52:47,587 iteration 6451 : loss : 0.017249, loss_ce: 0.007322
2022-01-08 17:52:49,027 iteration 6452 : loss : 0.020968, loss_ce: 0.006708
2022-01-08 17:52:50,380 iteration 6453 : loss : 0.016672, loss_ce: 0.006028
2022-01-08 17:52:51,695 iteration 6454 : loss : 0.017564, loss_ce: 0.006549
2022-01-08 17:52:53,107 iteration 6455 : loss : 0.019023, loss_ce: 0.010761
2022-01-08 17:52:54,474 iteration 6456 : loss : 0.020937, loss_ce: 0.007209
2022-01-08 17:52:55,867 iteration 6457 : loss : 0.020280, loss_ce: 0.007229
2022-01-08 17:52:57,194 iteration 6458 : loss : 0.013578, loss_ce: 0.005071
2022-01-08 17:52:58,550 iteration 6459 : loss : 0.010405, loss_ce: 0.002678
2022-01-08 17:52:58,550 Training Data Eval:
2022-01-08 17:53:05,409   Average segmentation loss on training set: 0.0080
2022-01-08 17:53:05,409 Validation Data Eval:
2022-01-08 17:53:07,767   Average segmentation loss on validation set: 0.0746
2022-01-08 17:53:09,180 iteration 6460 : loss : 0.022437, loss_ce: 0.011287

 95%|███████████████████████████▌ | 380/400 [2:43:03<08:56, 26.83s/it]2022-01-08 17:53:10,670 iteration 6461 : loss : 0.015431, loss_ce: 0.006296
2022-01-08 17:53:12,022 iteration 6462 : loss : 0.011802, loss_ce: 0.004588
2022-01-08 17:53:13,451 iteration 6463 : loss : 0.020883, loss_ce: 0.009436
2022-01-08 17:53:14,825 iteration 6464 : loss : 0.016574, loss_ce: 0.004795
2022-01-08 17:53:16,242 iteration 6465 : loss : 0.014750, loss_ce: 0.005193
2022-01-08 17:53:17,574 iteration 6466 : loss : 0.012270, loss_ce: 0.003888
2022-01-08 17:53:18,928 iteration 6467 : loss : 0.012945, loss_ce: 0.004711
2022-01-08 17:53:20,359 iteration 6468 : loss : 0.015162, loss_ce: 0.005346
2022-01-08 17:53:21,721 iteration 6469 : loss : 0.017438, loss_ce: 0.007883
2022-01-08 17:53:23,064 iteration 6470 : loss : 0.012016, loss_ce: 0.003470
2022-01-08 17:53:24,439 iteration 6471 : loss : 0.013618, loss_ce: 0.005345
2022-01-08 17:53:25,823 iteration 6472 : loss : 0.017235, loss_ce: 0.005549
2022-01-08 17:53:27,167 iteration 6473 : loss : 0.017188, loss_ce: 0.007056
2022-01-08 17:53:28,602 iteration 6474 : loss : 0.012325, loss_ce: 0.006026
2022-01-08 17:53:29,996 iteration 6475 : loss : 0.022391, loss_ce: 0.011966
2022-01-08 17:53:31,265 iteration 6476 : loss : 0.012149, loss_ce: 0.004609
2022-01-08 17:53:32,726 iteration 6477 : loss : 0.023503, loss_ce: 0.008537

 95%|███████████████████████████▌ | 381/400 [2:43:26<08:10, 25.84s/it]2022-01-08 17:53:34,216 iteration 6478 : loss : 0.018489, loss_ce: 0.005477
2022-01-08 17:53:35,575 iteration 6479 : loss : 0.022951, loss_ce: 0.007837
2022-01-08 17:53:36,936 iteration 6480 : loss : 0.012893, loss_ce: 0.006244
2022-01-08 17:53:38,342 iteration 6481 : loss : 0.024569, loss_ce: 0.009932
2022-01-08 17:53:39,653 iteration 6482 : loss : 0.012713, loss_ce: 0.004731
2022-01-08 17:53:41,052 iteration 6483 : loss : 0.034393, loss_ce: 0.010919
2022-01-08 17:53:42,390 iteration 6484 : loss : 0.014185, loss_ce: 0.006344
2022-01-08 17:53:43,752 iteration 6485 : loss : 0.024988, loss_ce: 0.010293
2022-01-08 17:53:45,177 iteration 6486 : loss : 0.017027, loss_ce: 0.006275
2022-01-08 17:53:46,649 iteration 6487 : loss : 0.021908, loss_ce: 0.009968
2022-01-08 17:53:48,057 iteration 6488 : loss : 0.018376, loss_ce: 0.007880
2022-01-08 17:53:49,400 iteration 6489 : loss : 0.010458, loss_ce: 0.005063
2022-01-08 17:53:50,792 iteration 6490 : loss : 0.016555, loss_ce: 0.005147
2022-01-08 17:53:52,146 iteration 6491 : loss : 0.013300, loss_ce: 0.005290
2022-01-08 17:53:53,601 iteration 6492 : loss : 0.013339, loss_ce: 0.004369
2022-01-08 17:53:55,001 iteration 6493 : loss : 0.021875, loss_ce: 0.007735
2022-01-08 17:53:56,280 iteration 6494 : loss : 0.009073, loss_ce: 0.003593

 96%|███████████████████████████▋ | 382/400 [2:43:50<07:32, 25.16s/it]2022-01-08 17:53:57,679 iteration 6495 : loss : 0.013486, loss_ce: 0.005509
2022-01-08 17:53:59,053 iteration 6496 : loss : 0.024714, loss_ce: 0.007897
2022-01-08 17:54:00,463 iteration 6497 : loss : 0.011438, loss_ce: 0.004622
2022-01-08 17:54:01,878 iteration 6498 : loss : 0.020024, loss_ce: 0.006966
2022-01-08 17:54:03,288 iteration 6499 : loss : 0.014578, loss_ce: 0.005760
2022-01-08 17:54:04,652 iteration 6500 : loss : 0.017757, loss_ce: 0.006174
2022-01-08 17:54:06,050 iteration 6501 : loss : 0.016539, loss_ce: 0.006389
2022-01-08 17:54:07,476 iteration 6502 : loss : 0.016257, loss_ce: 0.008508
2022-01-08 17:54:08,824 iteration 6503 : loss : 0.010824, loss_ce: 0.003152
2022-01-08 17:54:10,146 iteration 6504 : loss : 0.012696, loss_ce: 0.004677
2022-01-08 17:54:11,402 iteration 6505 : loss : 0.010884, loss_ce: 0.004983
2022-01-08 17:54:12,754 iteration 6506 : loss : 0.016499, loss_ce: 0.004062
2022-01-08 17:54:14,192 iteration 6507 : loss : 0.018011, loss_ce: 0.008414
2022-01-08 17:54:15,598 iteration 6508 : loss : 0.013794, loss_ce: 0.005146
2022-01-08 17:54:16,986 iteration 6509 : loss : 0.015593, loss_ce: 0.005722
2022-01-08 17:54:18,380 iteration 6510 : loss : 0.013458, loss_ce: 0.004627
2022-01-08 17:54:19,682 iteration 6511 : loss : 0.011068, loss_ce: 0.004066

 96%|███████████████████████████▊ | 383/400 [2:44:13<06:58, 24.63s/it]2022-01-08 17:54:21,090 iteration 6512 : loss : 0.016253, loss_ce: 0.005348
2022-01-08 17:54:22,465 iteration 6513 : loss : 0.013335, loss_ce: 0.004533
2022-01-08 17:54:23,938 iteration 6514 : loss : 0.018158, loss_ce: 0.005638
2022-01-08 17:54:25,366 iteration 6515 : loss : 0.019027, loss_ce: 0.006823
2022-01-08 17:54:26,775 iteration 6516 : loss : 0.018842, loss_ce: 0.008131
2022-01-08 17:54:28,141 iteration 6517 : loss : 0.019814, loss_ce: 0.003862
2022-01-08 17:54:29,521 iteration 6518 : loss : 0.011281, loss_ce: 0.003910
2022-01-08 17:54:30,891 iteration 6519 : loss : 0.019654, loss_ce: 0.005538
2022-01-08 17:54:32,314 iteration 6520 : loss : 0.016212, loss_ce: 0.005274
2022-01-08 17:54:33,653 iteration 6521 : loss : 0.015454, loss_ce: 0.006694
2022-01-08 17:54:35,046 iteration 6522 : loss : 0.010134, loss_ce: 0.004048
2022-01-08 17:54:36,352 iteration 6523 : loss : 0.009751, loss_ce: 0.003903
2022-01-08 17:54:37,770 iteration 6524 : loss : 0.017201, loss_ce: 0.007801
2022-01-08 17:54:39,156 iteration 6525 : loss : 0.017483, loss_ce: 0.006669
2022-01-08 17:54:40,534 iteration 6526 : loss : 0.013926, loss_ce: 0.005324
2022-01-08 17:54:41,840 iteration 6527 : loss : 0.012114, loss_ce: 0.005286
2022-01-08 17:54:43,174 iteration 6528 : loss : 0.012553, loss_ce: 0.003742

 96%|███████████████████████████▊ | 384/400 [2:44:37<06:28, 24.29s/it]2022-01-08 17:54:44,658 iteration 6529 : loss : 0.020260, loss_ce: 0.006360
2022-01-08 17:54:46,056 iteration 6530 : loss : 0.013913, loss_ce: 0.004596
2022-01-08 17:54:47,376 iteration 6531 : loss : 0.013756, loss_ce: 0.004101
2022-01-08 17:54:48,776 iteration 6532 : loss : 0.013294, loss_ce: 0.005182
2022-01-08 17:54:50,082 iteration 6533 : loss : 0.009141, loss_ce: 0.003532
2022-01-08 17:54:51,461 iteration 6534 : loss : 0.018589, loss_ce: 0.008531
2022-01-08 17:54:52,848 iteration 6535 : loss : 0.013720, loss_ce: 0.005066
2022-01-08 17:54:54,249 iteration 6536 : loss : 0.012596, loss_ce: 0.004198
2022-01-08 17:54:55,643 iteration 6537 : loss : 0.019915, loss_ce: 0.006390
2022-01-08 17:54:57,045 iteration 6538 : loss : 0.019278, loss_ce: 0.005684
2022-01-08 17:54:58,462 iteration 6539 : loss : 0.014211, loss_ce: 0.005861
2022-01-08 17:54:59,759 iteration 6540 : loss : 0.010261, loss_ce: 0.004224
2022-01-08 17:55:01,100 iteration 6541 : loss : 0.024353, loss_ce: 0.014431
2022-01-08 17:55:02,563 iteration 6542 : loss : 0.013873, loss_ce: 0.004108
2022-01-08 17:55:03,908 iteration 6543 : loss : 0.011405, loss_ce: 0.003853
2022-01-08 17:55:05,319 iteration 6544 : loss : 0.014790, loss_ce: 0.005484
2022-01-08 17:55:05,320 Training Data Eval:
2022-01-08 17:55:12,157   Average segmentation loss on training set: 0.0076
2022-01-08 17:55:12,158 Validation Data Eval:
2022-01-08 17:55:14,523   Average segmentation loss on validation set: 0.0747
2022-01-08 17:55:15,970 iteration 6545 : loss : 0.015077, loss_ce: 0.005622

 96%|███████████████████████████▉ | 385/400 [2:45:10<06:42, 26.84s/it]2022-01-08 17:55:17,540 iteration 6546 : loss : 0.018672, loss_ce: 0.008070
2022-01-08 17:55:18,913 iteration 6547 : loss : 0.014940, loss_ce: 0.007386
2022-01-08 17:55:20,319 iteration 6548 : loss : 0.012100, loss_ce: 0.005102
2022-01-08 17:55:21,664 iteration 6549 : loss : 0.016918, loss_ce: 0.006415
2022-01-08 17:55:23,076 iteration 6550 : loss : 0.018135, loss_ce: 0.006505
2022-01-08 17:55:24,518 iteration 6551 : loss : 0.013124, loss_ce: 0.005568
2022-01-08 17:55:25,997 iteration 6552 : loss : 0.021002, loss_ce: 0.010439
2022-01-08 17:55:27,505 iteration 6553 : loss : 0.021265, loss_ce: 0.006352
2022-01-08 17:55:28,913 iteration 6554 : loss : 0.016229, loss_ce: 0.005723
2022-01-08 17:55:30,299 iteration 6555 : loss : 0.011973, loss_ce: 0.005434
2022-01-08 17:55:31,681 iteration 6556 : loss : 0.021675, loss_ce: 0.006900
2022-01-08 17:55:32,962 iteration 6557 : loss : 0.009284, loss_ce: 0.003731
2022-01-08 17:55:34,329 iteration 6558 : loss : 0.025105, loss_ce: 0.009344
2022-01-08 17:55:35,629 iteration 6559 : loss : 0.012382, loss_ce: 0.004166
2022-01-08 17:55:37,001 iteration 6560 : loss : 0.014753, loss_ce: 0.007265
2022-01-08 17:55:38,415 iteration 6561 : loss : 0.020669, loss_ce: 0.006255
2022-01-08 17:55:39,750 iteration 6562 : loss : 0.013052, loss_ce: 0.004762

 96%|███████████████████████████▉ | 386/400 [2:45:34<06:02, 25.92s/it]2022-01-08 17:55:41,309 iteration 6563 : loss : 0.021029, loss_ce: 0.008882
2022-01-08 17:55:42,670 iteration 6564 : loss : 0.014475, loss_ce: 0.006407
2022-01-08 17:55:43,996 iteration 6565 : loss : 0.015881, loss_ce: 0.003747
2022-01-08 17:55:45,317 iteration 6566 : loss : 0.011640, loss_ce: 0.004713
2022-01-08 17:55:46,612 iteration 6567 : loss : 0.012123, loss_ce: 0.005028
2022-01-08 17:55:47,957 iteration 6568 : loss : 0.012933, loss_ce: 0.005489
2022-01-08 17:55:49,330 iteration 6569 : loss : 0.011215, loss_ce: 0.004242
2022-01-08 17:55:50,654 iteration 6570 : loss : 0.010593, loss_ce: 0.004661
2022-01-08 17:55:52,008 iteration 6571 : loss : 0.016531, loss_ce: 0.004635
2022-01-08 17:55:53,307 iteration 6572 : loss : 0.011269, loss_ce: 0.004842
2022-01-08 17:55:54,740 iteration 6573 : loss : 0.019106, loss_ce: 0.006100
2022-01-08 17:55:56,181 iteration 6574 : loss : 0.011961, loss_ce: 0.005097
2022-01-08 17:55:57,638 iteration 6575 : loss : 0.033233, loss_ce: 0.008975
2022-01-08 17:55:58,980 iteration 6576 : loss : 0.013274, loss_ce: 0.005414
2022-01-08 17:56:00,374 iteration 6577 : loss : 0.025908, loss_ce: 0.008607
2022-01-08 17:56:01,704 iteration 6578 : loss : 0.013046, loss_ce: 0.005003
2022-01-08 17:56:03,085 iteration 6579 : loss : 0.012377, loss_ce: 0.004095

 97%|████████████████████████████ | 387/400 [2:45:57<05:26, 25.14s/it]2022-01-08 17:56:04,525 iteration 6580 : loss : 0.016523, loss_ce: 0.005231
2022-01-08 17:56:05,877 iteration 6581 : loss : 0.017824, loss_ce: 0.005783
2022-01-08 17:56:07,317 iteration 6582 : loss : 0.015397, loss_ce: 0.005514
2022-01-08 17:56:08,698 iteration 6583 : loss : 0.015749, loss_ce: 0.005625
2022-01-08 17:56:10,095 iteration 6584 : loss : 0.014356, loss_ce: 0.005521
2022-01-08 17:56:11,525 iteration 6585 : loss : 0.015934, loss_ce: 0.004649
2022-01-08 17:56:12,931 iteration 6586 : loss : 0.016995, loss_ce: 0.005365
2022-01-08 17:56:14,299 iteration 6587 : loss : 0.012145, loss_ce: 0.004856
2022-01-08 17:56:15,688 iteration 6588 : loss : 0.015774, loss_ce: 0.006602
2022-01-08 17:56:17,007 iteration 6589 : loss : 0.013787, loss_ce: 0.005162
2022-01-08 17:56:18,441 iteration 6590 : loss : 0.016123, loss_ce: 0.007561
2022-01-08 17:56:19,875 iteration 6591 : loss : 0.020171, loss_ce: 0.007660
2022-01-08 17:56:21,224 iteration 6592 : loss : 0.011788, loss_ce: 0.004403
2022-01-08 17:56:22,669 iteration 6593 : loss : 0.028959, loss_ce: 0.006327
2022-01-08 17:56:24,036 iteration 6594 : loss : 0.014256, loss_ce: 0.006863
2022-01-08 17:56:25,389 iteration 6595 : loss : 0.011696, loss_ce: 0.004336
2022-01-08 17:56:26,817 iteration 6596 : loss : 0.020302, loss_ce: 0.007186

 97%|████████████████████████████▏| 388/400 [2:46:21<04:56, 24.72s/it]2022-01-08 17:56:28,247 iteration 6597 : loss : 0.014659, loss_ce: 0.006269
2022-01-08 17:56:29,571 iteration 6598 : loss : 0.018957, loss_ce: 0.005012
2022-01-08 17:56:30,963 iteration 6599 : loss : 0.021746, loss_ce: 0.011234
2022-01-08 17:56:32,231 iteration 6600 : loss : 0.009717, loss_ce: 0.003989
2022-01-08 17:56:33,593 iteration 6601 : loss : 0.011152, loss_ce: 0.003808
2022-01-08 17:56:34,928 iteration 6602 : loss : 0.012971, loss_ce: 0.004467
2022-01-08 17:56:36,296 iteration 6603 : loss : 0.015942, loss_ce: 0.006196
2022-01-08 17:56:37,591 iteration 6604 : loss : 0.009021, loss_ce: 0.003762
2022-01-08 17:56:38,965 iteration 6605 : loss : 0.013869, loss_ce: 0.004755
2022-01-08 17:56:40,368 iteration 6606 : loss : 0.015092, loss_ce: 0.006778
2022-01-08 17:56:41,765 iteration 6607 : loss : 0.016776, loss_ce: 0.008021
2022-01-08 17:56:43,162 iteration 6608 : loss : 0.010960, loss_ce: 0.004498
2022-01-08 17:56:44,489 iteration 6609 : loss : 0.015354, loss_ce: 0.005834
2022-01-08 17:56:45,834 iteration 6610 : loss : 0.016015, loss_ce: 0.006801
2022-01-08 17:56:47,175 iteration 6611 : loss : 0.011175, loss_ce: 0.002595
2022-01-08 17:56:48,587 iteration 6612 : loss : 0.023966, loss_ce: 0.009958
2022-01-08 17:56:49,851 iteration 6613 : loss : 0.011954, loss_ce: 0.004611

 97%|████████████████████████████▏| 389/400 [2:46:44<04:26, 24.22s/it]2022-01-08 17:56:51,281 iteration 6614 : loss : 0.012861, loss_ce: 0.005180
2022-01-08 17:56:52,666 iteration 6615 : loss : 0.012572, loss_ce: 0.005320
2022-01-08 17:56:54,027 iteration 6616 : loss : 0.013022, loss_ce: 0.003715
2022-01-08 17:56:55,524 iteration 6617 : loss : 0.017355, loss_ce: 0.006170
2022-01-08 17:56:56,915 iteration 6618 : loss : 0.022032, loss_ce: 0.006036
2022-01-08 17:56:58,378 iteration 6619 : loss : 0.030186, loss_ce: 0.011656
2022-01-08 17:56:59,799 iteration 6620 : loss : 0.024110, loss_ce: 0.011408
2022-01-08 17:57:01,159 iteration 6621 : loss : 0.017610, loss_ce: 0.005094
2022-01-08 17:57:02,521 iteration 6622 : loss : 0.014881, loss_ce: 0.007384
2022-01-08 17:57:03,887 iteration 6623 : loss : 0.019147, loss_ce: 0.006240
2022-01-08 17:57:05,297 iteration 6624 : loss : 0.032072, loss_ce: 0.014357
2022-01-08 17:57:06,760 iteration 6625 : loss : 0.012228, loss_ce: 0.004497
2022-01-08 17:57:08,126 iteration 6626 : loss : 0.015275, loss_ce: 0.004133
2022-01-08 17:57:09,421 iteration 6627 : loss : 0.013106, loss_ce: 0.004372
2022-01-08 17:57:10,788 iteration 6628 : loss : 0.013246, loss_ce: 0.006345
2022-01-08 17:57:12,145 iteration 6629 : loss : 0.013329, loss_ce: 0.006306
2022-01-08 17:57:12,145 Training Data Eval:
2022-01-08 17:57:18,975   Average segmentation loss on training set: 0.0080
2022-01-08 17:57:18,976 Validation Data Eval:
2022-01-08 17:57:21,329   Average segmentation loss on validation set: 0.0726
2022-01-08 17:57:22,740 iteration 6630 : loss : 0.013114, loss_ce: 0.003924

 98%|████████████████████████████▎| 390/400 [2:47:16<04:28, 26.82s/it]2022-01-08 17:57:24,245 iteration 6631 : loss : 0.014533, loss_ce: 0.004833
2022-01-08 17:57:25,631 iteration 6632 : loss : 0.015593, loss_ce: 0.006795
2022-01-08 17:57:27,016 iteration 6633 : loss : 0.014504, loss_ce: 0.003701
2022-01-08 17:57:28,272 iteration 6634 : loss : 0.010290, loss_ce: 0.003161
2022-01-08 17:57:29,598 iteration 6635 : loss : 0.014016, loss_ce: 0.003400
2022-01-08 17:57:31,020 iteration 6636 : loss : 0.013911, loss_ce: 0.005370
2022-01-08 17:57:32,421 iteration 6637 : loss : 0.010249, loss_ce: 0.004287
2022-01-08 17:57:33,843 iteration 6638 : loss : 0.017273, loss_ce: 0.007004
2022-01-08 17:57:35,294 iteration 6639 : loss : 0.020775, loss_ce: 0.008173
2022-01-08 17:57:36,658 iteration 6640 : loss : 0.014445, loss_ce: 0.004133
2022-01-08 17:57:37,995 iteration 6641 : loss : 0.011487, loss_ce: 0.005737
2022-01-08 17:57:39,437 iteration 6642 : loss : 0.014808, loss_ce: 0.006281
2022-01-08 17:57:40,840 iteration 6643 : loss : 0.015978, loss_ce: 0.006236
2022-01-08 17:57:42,220 iteration 6644 : loss : 0.017232, loss_ce: 0.005849
2022-01-08 17:57:43,540 iteration 6645 : loss : 0.010167, loss_ce: 0.004238
2022-01-08 17:57:44,892 iteration 6646 : loss : 0.013408, loss_ce: 0.005470
2022-01-08 17:57:46,177 iteration 6647 : loss : 0.011104, loss_ce: 0.003642

 98%|████████████████████████████▎| 391/400 [2:47:40<03:52, 25.80s/it]2022-01-08 17:57:47,563 iteration 6648 : loss : 0.013839, loss_ce: 0.004352
2022-01-08 17:57:48,992 iteration 6649 : loss : 0.014120, loss_ce: 0.006076
2022-01-08 17:57:50,304 iteration 6650 : loss : 0.014329, loss_ce: 0.005356
2022-01-08 17:57:51,634 iteration 6651 : loss : 0.011414, loss_ce: 0.003815
2022-01-08 17:57:53,075 iteration 6652 : loss : 0.013194, loss_ce: 0.004844
2022-01-08 17:57:54,511 iteration 6653 : loss : 0.017238, loss_ce: 0.007931
2022-01-08 17:57:55,849 iteration 6654 : loss : 0.013451, loss_ce: 0.005182
2022-01-08 17:57:57,241 iteration 6655 : loss : 0.013272, loss_ce: 0.005638
2022-01-08 17:57:58,645 iteration 6656 : loss : 0.011150, loss_ce: 0.004210
2022-01-08 17:58:00,114 iteration 6657 : loss : 0.013919, loss_ce: 0.004764
2022-01-08 17:58:01,514 iteration 6658 : loss : 0.026327, loss_ce: 0.008876
2022-01-08 17:58:02,935 iteration 6659 : loss : 0.015628, loss_ce: 0.005262
2022-01-08 17:58:04,274 iteration 6660 : loss : 0.021945, loss_ce: 0.007329
2022-01-08 17:58:05,573 iteration 6661 : loss : 0.009807, loss_ce: 0.003589
2022-01-08 17:58:06,962 iteration 6662 : loss : 0.011687, loss_ce: 0.004278
2022-01-08 17:58:08,393 iteration 6663 : loss : 0.014646, loss_ce: 0.005689
2022-01-08 17:58:09,757 iteration 6664 : loss : 0.020904, loss_ce: 0.006160

 98%|████████████████████████████▍| 392/400 [2:48:04<03:21, 25.14s/it]2022-01-08 17:58:11,213 iteration 6665 : loss : 0.015015, loss_ce: 0.005136
2022-01-08 17:58:12,607 iteration 6666 : loss : 0.015174, loss_ce: 0.005338
2022-01-08 17:58:13,947 iteration 6667 : loss : 0.014009, loss_ce: 0.004858
2022-01-08 17:58:15,226 iteration 6668 : loss : 0.009396, loss_ce: 0.003791
2022-01-08 17:58:16,613 iteration 6669 : loss : 0.023156, loss_ce: 0.007863
2022-01-08 17:58:17,925 iteration 6670 : loss : 0.014735, loss_ce: 0.004848
2022-01-08 17:58:19,368 iteration 6671 : loss : 0.014314, loss_ce: 0.005270
2022-01-08 17:58:20,737 iteration 6672 : loss : 0.014253, loss_ce: 0.007223
2022-01-08 17:58:22,186 iteration 6673 : loss : 0.014648, loss_ce: 0.006463
2022-01-08 17:58:23,624 iteration 6674 : loss : 0.017414, loss_ce: 0.006569
2022-01-08 17:58:24,971 iteration 6675 : loss : 0.020248, loss_ce: 0.006465
2022-01-08 17:58:26,278 iteration 6676 : loss : 0.010160, loss_ce: 0.003574
2022-01-08 17:58:27,665 iteration 6677 : loss : 0.011571, loss_ce: 0.002638
2022-01-08 17:58:29,128 iteration 6678 : loss : 0.019179, loss_ce: 0.008295
2022-01-08 17:58:30,531 iteration 6679 : loss : 0.012732, loss_ce: 0.003868
2022-01-08 17:58:31,892 iteration 6680 : loss : 0.017358, loss_ce: 0.007915
2022-01-08 17:58:33,221 iteration 6681 : loss : 0.013490, loss_ce: 0.004636

 98%|████████████████████████████▍| 393/400 [2:48:27<02:52, 24.64s/it]2022-01-08 17:58:34,647 iteration 6682 : loss : 0.012218, loss_ce: 0.003724
2022-01-08 17:58:36,065 iteration 6683 : loss : 0.018674, loss_ce: 0.005847
2022-01-08 17:58:37,462 iteration 6684 : loss : 0.040698, loss_ce: 0.006870
2022-01-08 17:58:38,825 iteration 6685 : loss : 0.014819, loss_ce: 0.004800
2022-01-08 17:58:40,216 iteration 6686 : loss : 0.013236, loss_ce: 0.004492
2022-01-08 17:58:41,607 iteration 6687 : loss : 0.017902, loss_ce: 0.007085
2022-01-08 17:58:42,998 iteration 6688 : loss : 0.016539, loss_ce: 0.006137
2022-01-08 17:58:44,349 iteration 6689 : loss : 0.015283, loss_ce: 0.006576
2022-01-08 17:58:45,787 iteration 6690 : loss : 0.022180, loss_ce: 0.008092
2022-01-08 17:58:47,109 iteration 6691 : loss : 0.012255, loss_ce: 0.004758
2022-01-08 17:58:48,432 iteration 6692 : loss : 0.014400, loss_ce: 0.008530
2022-01-08 17:58:49,819 iteration 6693 : loss : 0.013184, loss_ce: 0.004883
2022-01-08 17:58:51,126 iteration 6694 : loss : 0.010404, loss_ce: 0.004426
2022-01-08 17:58:52,474 iteration 6695 : loss : 0.013956, loss_ce: 0.003797
2022-01-08 17:58:53,838 iteration 6696 : loss : 0.014688, loss_ce: 0.007714
2022-01-08 17:58:55,215 iteration 6697 : loss : 0.015862, loss_ce: 0.005663
2022-01-08 17:58:56,514 iteration 6698 : loss : 0.012401, loss_ce: 0.004224

 98%|████████████████████████████▌| 394/400 [2:48:50<02:25, 24.23s/it]2022-01-08 17:58:57,958 iteration 6699 : loss : 0.013800, loss_ce: 0.004507
2022-01-08 17:58:59,385 iteration 6700 : loss : 0.017381, loss_ce: 0.006813
2022-01-08 17:59:00,839 iteration 6701 : loss : 0.033030, loss_ce: 0.009467
2022-01-08 17:59:02,186 iteration 6702 : loss : 0.012584, loss_ce: 0.004002
2022-01-08 17:59:03,655 iteration 6703 : loss : 0.016866, loss_ce: 0.005129
2022-01-08 17:59:05,041 iteration 6704 : loss : 0.031869, loss_ce: 0.021988
2022-01-08 17:59:06,361 iteration 6705 : loss : 0.012433, loss_ce: 0.004134
2022-01-08 17:59:07,709 iteration 6706 : loss : 0.014091, loss_ce: 0.005085
2022-01-08 17:59:09,074 iteration 6707 : loss : 0.012796, loss_ce: 0.004508
2022-01-08 17:59:10,367 iteration 6708 : loss : 0.011131, loss_ce: 0.003290
2022-01-08 17:59:11,694 iteration 6709 : loss : 0.013978, loss_ce: 0.003928
2022-01-08 17:59:13,072 iteration 6710 : loss : 0.015711, loss_ce: 0.006037
2022-01-08 17:59:14,439 iteration 6711 : loss : 0.017293, loss_ce: 0.006928
2022-01-08 17:59:15,853 iteration 6712 : loss : 0.013974, loss_ce: 0.005682
2022-01-08 17:59:17,197 iteration 6713 : loss : 0.014088, loss_ce: 0.004648
2022-01-08 17:59:18,556 iteration 6714 : loss : 0.013047, loss_ce: 0.005471
2022-01-08 17:59:18,556 Training Data Eval:
2022-01-08 17:59:25,375   Average segmentation loss on training set: 0.0078
2022-01-08 17:59:25,376 Validation Data Eval:
2022-01-08 17:59:27,730   Average segmentation loss on validation set: 0.0747
2022-01-08 17:59:29,065 iteration 6715 : loss : 0.008989, loss_ce: 0.002616

 99%|████████████████████████████▋| 395/400 [2:49:23<02:13, 26.73s/it]2022-01-08 17:59:30,418 iteration 6716 : loss : 0.010027, loss_ce: 0.003287
2022-01-08 17:59:31,816 iteration 6717 : loss : 0.015852, loss_ce: 0.004382
2022-01-08 17:59:33,257 iteration 6718 : loss : 0.029832, loss_ce: 0.015078
2022-01-08 17:59:34,674 iteration 6719 : loss : 0.024100, loss_ce: 0.008588
2022-01-08 17:59:36,075 iteration 6720 : loss : 0.032106, loss_ce: 0.005630
2022-01-08 17:59:37,482 iteration 6721 : loss : 0.018938, loss_ce: 0.008128
2022-01-08 17:59:38,837 iteration 6722 : loss : 0.015334, loss_ce: 0.007579
2022-01-08 17:59:40,219 iteration 6723 : loss : 0.016857, loss_ce: 0.006473
2022-01-08 17:59:41,542 iteration 6724 : loss : 0.012476, loss_ce: 0.004945
2022-01-08 17:59:42,906 iteration 6725 : loss : 0.009387, loss_ce: 0.003116
2022-01-08 17:59:44,198 iteration 6726 : loss : 0.009856, loss_ce: 0.003292
2022-01-08 17:59:45,662 iteration 6727 : loss : 0.021031, loss_ce: 0.006886
2022-01-08 17:59:46,996 iteration 6728 : loss : 0.012736, loss_ce: 0.004660
2022-01-08 17:59:48,419 iteration 6729 : loss : 0.016360, loss_ce: 0.005438
2022-01-08 17:59:49,887 iteration 6730 : loss : 0.014583, loss_ce: 0.006451
2022-01-08 17:59:51,305 iteration 6731 : loss : 0.016511, loss_ce: 0.005608
2022-01-08 17:59:52,677 iteration 6732 : loss : 0.010829, loss_ce: 0.005070

 99%|████████████████████████████▋| 396/400 [2:49:46<01:43, 25.79s/it]2022-01-08 17:59:54,057 iteration 6733 : loss : 0.009427, loss_ce: 0.003765
2022-01-08 17:59:55,418 iteration 6734 : loss : 0.015024, loss_ce: 0.003758
2022-01-08 17:59:56,820 iteration 6735 : loss : 0.014095, loss_ce: 0.004844
2022-01-08 17:59:58,176 iteration 6736 : loss : 0.012712, loss_ce: 0.005893
2022-01-08 17:59:59,499 iteration 6737 : loss : 0.012874, loss_ce: 0.006868
2022-01-08 18:00:00,809 iteration 6738 : loss : 0.012463, loss_ce: 0.003863
2022-01-08 18:00:02,179 iteration 6739 : loss : 0.012771, loss_ce: 0.005665
2022-01-08 18:00:03,580 iteration 6740 : loss : 0.027007, loss_ce: 0.009827
2022-01-08 18:00:04,973 iteration 6741 : loss : 0.018233, loss_ce: 0.007683
2022-01-08 18:00:06,326 iteration 6742 : loss : 0.014639, loss_ce: 0.007178
2022-01-08 18:00:07,642 iteration 6743 : loss : 0.012027, loss_ce: 0.002754
2022-01-08 18:00:09,054 iteration 6744 : loss : 0.016858, loss_ce: 0.006517
2022-01-08 18:00:10,420 iteration 6745 : loss : 0.014680, loss_ce: 0.006352
2022-01-08 18:00:11,725 iteration 6746 : loss : 0.011083, loss_ce: 0.003083
2022-01-08 18:00:13,057 iteration 6747 : loss : 0.012776, loss_ce: 0.004317
2022-01-08 18:00:14,448 iteration 6748 : loss : 0.009416, loss_ce: 0.003874
2022-01-08 18:00:15,801 iteration 6749 : loss : 0.011250, loss_ce: 0.003290

 99%|████████████████████████████▊| 397/400 [2:50:10<01:14, 24.99s/it]2022-01-08 18:00:17,222 iteration 6750 : loss : 0.010605, loss_ce: 0.004633
2022-01-08 18:00:18,655 iteration 6751 : loss : 0.011477, loss_ce: 0.004543
2022-01-08 18:00:19,962 iteration 6752 : loss : 0.012183, loss_ce: 0.003773
2022-01-08 18:00:21,332 iteration 6753 : loss : 0.015101, loss_ce: 0.007013
2022-01-08 18:00:22,732 iteration 6754 : loss : 0.011692, loss_ce: 0.004352
2022-01-08 18:00:24,069 iteration 6755 : loss : 0.013905, loss_ce: 0.004135
2022-01-08 18:00:25,405 iteration 6756 : loss : 0.015458, loss_ce: 0.007113
2022-01-08 18:00:26,842 iteration 6757 : loss : 0.012807, loss_ce: 0.004003
2022-01-08 18:00:28,183 iteration 6758 : loss : 0.018250, loss_ce: 0.007687
2022-01-08 18:00:29,564 iteration 6759 : loss : 0.012378, loss_ce: 0.005462
2022-01-08 18:00:31,003 iteration 6760 : loss : 0.026367, loss_ce: 0.004911
2022-01-08 18:00:32,371 iteration 6761 : loss : 0.015229, loss_ce: 0.005474
2022-01-08 18:00:33,724 iteration 6762 : loss : 0.013073, loss_ce: 0.003963
2022-01-08 18:00:35,146 iteration 6763 : loss : 0.014662, loss_ce: 0.005661
2022-01-08 18:00:36,483 iteration 6764 : loss : 0.018376, loss_ce: 0.008172
2022-01-08 18:00:37,906 iteration 6765 : loss : 0.011905, loss_ce: 0.003985
2022-01-08 18:00:39,279 iteration 6766 : loss : 0.011337, loss_ce: 0.005224

100%|████████████████████████████▊| 398/400 [2:50:33<00:49, 24.54s/it]2022-01-08 18:00:40,697 iteration 6767 : loss : 0.014628, loss_ce: 0.004944
2022-01-08 18:00:42,147 iteration 6768 : loss : 0.015283, loss_ce: 0.005535
2022-01-08 18:00:43,538 iteration 6769 : loss : 0.013201, loss_ce: 0.005527
2022-01-08 18:00:44,892 iteration 6770 : loss : 0.013885, loss_ce: 0.006738
2022-01-08 18:00:46,355 iteration 6771 : loss : 0.018974, loss_ce: 0.004327
2022-01-08 18:00:47,694 iteration 6772 : loss : 0.016279, loss_ce: 0.007584
2022-01-08 18:00:48,943 iteration 6773 : loss : 0.010565, loss_ce: 0.003169
2022-01-08 18:00:50,339 iteration 6774 : loss : 0.022806, loss_ce: 0.005999
2022-01-08 18:00:51,735 iteration 6775 : loss : 0.021364, loss_ce: 0.009187
2022-01-08 18:00:53,093 iteration 6776 : loss : 0.017009, loss_ce: 0.005526
2022-01-08 18:00:54,541 iteration 6777 : loss : 0.014847, loss_ce: 0.007363
2022-01-08 18:00:55,903 iteration 6778 : loss : 0.009208, loss_ce: 0.003078
2022-01-08 18:00:57,355 iteration 6779 : loss : 0.017675, loss_ce: 0.006863
2022-01-08 18:00:58,744 iteration 6780 : loss : 0.012680, loss_ce: 0.005219
2022-01-08 18:01:00,164 iteration 6781 : loss : 0.014776, loss_ce: 0.006420
2022-01-08 18:01:01,586 iteration 6782 : loss : 0.017239, loss_ce: 0.006060
2022-01-08 18:01:02,936 iteration 6783 : loss : 0.014647, loss_ce: 0.004536

100%|████████████████████████████▉| 399/400 [2:50:57<00:24, 24.27s/it]2022-01-08 18:01:04,438 iteration 6784 : loss : 0.017907, loss_ce: 0.005879
2022-01-08 18:01:05,840 iteration 6785 : loss : 0.015912, loss_ce: 0.004921
2022-01-08 18:01:07,169 iteration 6786 : loss : 0.010197, loss_ce: 0.003589
2022-01-08 18:01:08,507 iteration 6787 : loss : 0.010715, loss_ce: 0.003453
2022-01-08 18:01:09,898 iteration 6788 : loss : 0.013477, loss_ce: 0.005470
2022-01-08 18:01:11,272 iteration 6789 : loss : 0.018916, loss_ce: 0.005300
2022-01-08 18:01:12,621 iteration 6790 : loss : 0.013788, loss_ce: 0.006099
2022-01-08 18:01:14,011 iteration 6791 : loss : 0.013574, loss_ce: 0.005278
2022-01-08 18:01:15,335 iteration 6792 : loss : 0.013793, loss_ce: 0.006597
2022-01-08 18:01:16,770 iteration 6793 : loss : 0.018301, loss_ce: 0.006283
2022-01-08 18:01:18,142 iteration 6794 : loss : 0.017213, loss_ce: 0.005788
2022-01-08 18:01:19,552 iteration 6795 : loss : 0.015166, loss_ce: 0.005402
2022-01-08 18:01:20,975 iteration 6796 : loss : 0.012391, loss_ce: 0.006267
2022-01-08 18:01:22,274 iteration 6797 : loss : 0.011673, loss_ce: 0.003662
2022-01-08 18:01:23,681 iteration 6798 : loss : 0.013847, loss_ce: 0.004504
2022-01-08 18:01:25,149 iteration 6799 : loss : 0.017756, loss_ce: 0.008882
2022-01-08 18:01:25,149 Training Data Eval:
2022-01-08 18:01:31,980   Average segmentation loss on training set: 0.0075
2022-01-08 18:01:31,981 Validation Data Eval:
2022-01-08 18:01:34,334   Average segmentation loss on validation set: 0.0715
2022-01-08 18:01:35,658 iteration 6800 : loss : 0.010574, loss_ce: 0.002759

100%|█████████████████████████████| 400/400 [2:51:29<00:00, 26.81s/it]
100%|█████████████████████████████| 400/400 [2:51:29<00:00, 25.72s/it]
